Journal Artificial Intelligence Research 16 (2002) 167-207Submitted 3/01; published 3/02Learning Geometrically-Constrained Hidden Markov ModelsRobot Navigation: Bridging Topological-Geometrical GapHagit Shatkayhagit.shatkay@celera.comInformatics Research Group,Celera Genomics, Rockville, MD 20850Leslie Pack KaelblingArtificial Intelligence LaboratoryMassachusetts Institute Technology, Cambridge, 02139lpk@ai.mit.educome place streets marked.windows lighted mostly they're darked.place could sprain elbow chin!dare stay out? dare go in?...go in, turn left right...right-and-three-quarters? or, maybe, quite?...Simple it's not, I'm afraid find,mind-maker-upper make mind.Oh, Places You'll Go, Dr. Seuss.AbstractHidden Markov models (hmms) partially observable Markov decision processes(pomdps) provide useful tools modeling dynamical systems. particularlyuseful representing topology environments road networks ocebuildings, typical robot navigation planning. work presenteddescribes formal framework incorporating readily available odometric information geometrical constraints models algorithm learnsthem. taking advantage information, learning hmms/pomdps madegenerate better solutions require fewer iterations, robust facedata reduction. Experimental results, obtained simulated real robotdata, demonstrate effectiveness approach.1 Introductionwork concerned robots need perform tasks structured environments.robot moving environment suffers two main limitations: noisy sensors preventconfidently knowing is, noisy effectors prevent knowingcertainty actions take it. concentrate structured environments,turn characterized two main properties: environments consist vast uneventful uninteresting areas, interspersed relatively interesting positionssituations. Consider instance robot delivering bagel oce building. interestingsituations doors intersections building hallways, well variousc 2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiShatkay & Kaelblingpositions bagel might respect robot's arm (e.g., robot holdingbagel, puts down, etc.) aspects environment, desk positionsoces, inconsequential bagel delivery task.natural way represent combination environment robot's interactionsit, probabilistic automaton, states represent interesting situations,edges states represent actions leading one situation another. Probabilitydistributions transitions possible observations robot may perceivesituation model robot's noisy effectors sensors, respectively.models formally known pomdp (partially observable Markov decision process) models, proven useful robot planning acting inherent world uncertainty (Simmons & Koenig, 1995; Nourbakhsh, Powers, & Birchfield, 1995; Cassandra, Kaelbling, & Kurien, 1996).Despite much work using models, task learning directly automaticallydata widely addressed. Research concerning immediate topic dateconsists mostly work done Simmons Koenig (1996b). assumption underlyingwork human provides rather accurate topological model statesconnections, exact probability distributions learned top model,using version Baum-Welch algorithm (Rabiner, 1989). Another interesting approachacquisition topological models Thrun Bucken (1996a,1996b; Thrun, 1999),focused extracting deterministic topological maps previously acquired geometricalgrid-based maps, latter learned directly data. discussionrelated research geometrical topological approaches, probabilisticdeterministic versions, given next section.work reported first successful attempt aware learn purely probabilistictopological models, directly completely recorded data, without using previous humanprovided grid-based models. based using weak geometric information, recordedrobot, help learn topology environment, represent probabilisticmodel. Therefore, directly bridges historically perceived gap topologicalgeometrical information, addresses claim presented Thrun's work (1999)main shortcoming topological approach failure utilize inherent geometrylearnt environment.robots equipped wheel encoders enable odometer record changerobot's position moves environment. data typically noisyinaccurate. oors environment rarely smooth, wheels robotalways aligned neither motors, mechanics imperfect, resulting slippagedrift. effects accumulate, mark initial position robot,try estimate current position based summing long sequence odometric recordings,resulting estimate incorrect. is, raw recorded odometric informationeffective tool, itself, determining absolute location robotenvironment.approach aimed determining absolute locations, idea underlyingweak odometric information, despite noise inaccuracy, still provides geometrical cueshelp distinguish different states, well identify revisitationstate. Hence, information enhances ability learn topological models. However,168fiLearning Geometrically-Constrained HMMsuse geometrical information requires careful treatment geometrical constraintsdirectional data. demonstrate existing models algorithms extendedtake advantage noisy odometric data geometrical constraints. geometricalinformation directly incorporated probabilistic topological framework, producingsignificant improvement standard Baum-Welch algorithm, without need humanprovided model.rest paper organized follows: Section 2 provides survey previous workarea learning maps robot navigation, brie refers earlier work learningautomata; Section 3 presents formal framework work; Section 4 presents mainaspects iterative learning algorithm, Section 5 describes strategies selectinginitial point iterative process begins; Section 6 presents experimental resultsobtained simulated real robot data traditionally hard-to-learn environments.experiments demonstrate algorithm indeed converges better models feweriterations standard Baum-Welch method, robust face data reduction.2 Approaches Learning Maps Modelswork presented lies intersection theoretical area learning computational models|in particular, learning automata data sequences|and applied areamap acquisition robot navigation. concentrate surveying work latterarea, pointing distinction approach predecessors. brie reviewresults automata computational learning theory. comprehensive reviewtheoretical results given Shatkay (1999).2.1 Modeling Environments Robot Navigationcontext maps models robot navigation, distinction usually made twoprincipal kinds maps: geometric topological. Geometric maps describe environmentcollection objects occupied positions space, geometric relationships amongthem. topological framework less concerned geometrical positions, modelsworld collection states connectivity, is, states reachablestates actions lead one state next.draw additional distinction, world-centric1 maps provide \objective"description environment independent agent using map, robot-centric modelscapture interaction particular \subjective" agent environment.learning map, agent needs take account noisy sensors actuators tryobtain objectively correct map agents could use well. Similarly, agentsusing map need compensate limitations order assess positionaccording map. learning model captures interaction, agent acquiringmodel one also using it. Hence, noisy sensors actuators specific agentected model. different model likely needed different agents.related work described below, especially within geometrical framework, centeredaround learning objective maps world rather agent-specific models. shall pointsurvey work concerned latter kind models.work focuses acquiring purely topological models, less concerned learninggeometrical relationships locations objects, objective maps, although geometrical1. thank Sebastian Thrun terminology.169fiShatkay & Kaelblingrelationships serve aid acquisition process. concept state usedtopological framework general concept geometrical location, since stateinclude information battery level, arm position etc. information,great importance planning, non-geometrical nature therefore cannot readilycaptured purely geometrical framework. following sections provide survey workdone within geometrical framework within topological framework, wellcombinations two approaches.2.2 Geometric MapsGeometric maps provide description environment terms objects placedpositions. example, grid-based maps instance geometric approach.grid-based map, environment modeled grid (an array), positiongrid either vacant occupied object (binary values placed array).approach refined ect uncertainty world, grid cellscontain occupancy probabilities rather binary values. lot work donelearning grid-based maps robot navigation use sonar readingsinterpretation, Moravec Elfes others (Moravec & Elfes, 1985; Moravec, 1988; Elfes,1989; Asada, 1991).underlying assumption learning maps robot tell (or find out)grid obtains sonar reading indicating object, thereforeplace object correctly grid. similar localization assumption, requiring robotidentify geometrical location, underlies geometric mapping techniques Leonardet al. (1991), Smith et al. (1991), Thrun et al. (1998b) Dissanayake et al. (2001), evenexplicit grid part model. Explicit localization hard satisfy.Leonard et al. (1991) Smith et al. (1991) address issue use geometricalbeacons estimate location robot. known Kalman filter method,Gaussian probability distribution used model robot's possible current location, basedobservations collected current point, (without allowing refinement previousposition estimates based later observations). Research area recently extendedtwo directions: Leonard Feder (2000) partition task learning one large maplearning multiple smaller map-sections, thus addressing issue computational eciency.Dissanayake et al. (2001) conduct theoretical study approach show convergenceproperties. latter may lead computational eciency identifying casessteady-state solution readily obtained, accordingly bounding number steps requiredalgorithms reach useful solution cases.Work Thrun et al. (1998a) uses similar probabilistic approach obtaining grid-based maps.work refined (Thrun et al., 1998b) first learn location significant landmarksenvironment fill details complete geometrical grid, based laser rangescans. latter work extends approach Smith et al. , using observations obtainedlocation visited, order derive probability distributionpossible locations. achieve this, authors use forward-backward procedure similarone used Baum-Welch algorithm (Rabiner, 1989), order determine possiblelocations observed data. approach resembles use forwardbackward estimation procedure, probabilistic basis, aiming obtaining maximumlikelihood map environment. still significantly differs initialassumptions final results. data assumed provided learner includes170fiLearning Geometrically-Constrained HMMsmotion model perceptual model robot. consist transitionobservation probabilities within grid. components learnt algorithm,although grid context coarser-grained, topological framework. end resultalgorithm probabilistic grid-based map, probabilistic topological model,explained next section.addition concerned locations, rather richer notion state,fundamental drawback geometrical maps fine granularity high accuracy. Geometrical maps, particularly grid-based ones, tend give accurate detailed pictureenvironment. cases necessary robot know exact location termsmetric coordinates, metric maps indeed best choice. However, many planning tasksrequire fine granularity accurate measurements, better facilitatedabstract representation world. example, robot needs deliver bageloce oce b, needs map depicting relative location respectb, passageways two oces, perhaps landmarks help orientgets lost. reasonably well-operating low-level obstacle avoidance mechanismhelp bypass ower pots chairs might encounter way, objectsneed part environment map. driver traveling cities needsknow neither longitude latitude coordinates globe, location specifichouses along way, robot need know exact location within buildingexact location various items environment, order get one pointanother. Hence, effort obtaining detailed maps usually justified. additionmaps large, makes planning|even though planning polynomialsize map|inecient.2.3 Topological Maps Modelsalternative detailed geometric maps abstract topological maps.maps specify topology important landmarks situations (states), routes transitions (arcs) them. concerned less physical location landmarks,topological relationships situations. Typically, less complexsupport much ecient planning metric maps. Topological maps built lowerlevel abstractions allow robot move along arcs (perhaps wall- road-following),recognize properties locations, distinguish significant locations states;exible allowing general notion state, possibly including informationnon-geometrical aspects robot's situation.two typical strategies deriving topological maps: one learn topologicalmap directly; first learn geometric map, derive topological modelprocess analysis.nice example second approach provided Thrun Bucken (1996a, 1996b; Thrun,1999), use occupancy-grid techniques build initial map. strategy appropriateprimary cues decomposition abstraction map geometric. However,many cases, nodes topological map defined terms sensory data (e.g.,labels door whether robot holding bagel). Learning geometric map firstalso relies odometric abilities robot; weak space large,dicult derive consistent map.171fiShatkay & Kaelblingcontrast, work concentrates learning topological model directly, assuming abstraction robot's perception action abilities already done. abstractionsmanually encoded lower level robot navigational software, describedSection 6. Work Pierce Kuipers (1997) discusses automatic method extractingabstract states features raw perceptual information.Kuipers Byun (1991) provide strategy learning deterministic topological maps. workswell domains noise robot's perception action abstractedaway, learning single visits nodes traversals arcs. strong underlying assumptionstrategies, building map, current state reliably identifiedbased local information, based distance traversed previous well-identifiedstate. methods unable handle situations long sequences actionsobservations necessary disambiguate robot's state.Mataric (1990) provides alternative approach learning deterministic topological maps,represented distributed graphs. learning process relies assumptioncurrent state distinguished states based local information includescompass sonar readings. Uncertainty modeled probability distributions.Instead, matching current readings already existing states required exact,thresholds tolerated error set empirically. Another difference work presentedhere, learn complete probabilistic topology environment, Mataric'swork overall topology graph assumed advance linear list, additionaledges added learning process. probability distribution associatededges, mechanism choosing edge take determined part goal seekingprocess, part model itself.Engelson McDermott (1992) learn \diktiometric" maps (topological maps metric relations nodes) experience. uncertainty model use interval-based ratherprobabilistic, learned representation deterministic. Ad hoc routines handle problems resulting failures uncertainty representation.prefer learn combined model world robot's interaction world;allows robust planning takes account likelihood error sensing action.work closely related Koenig Simmons (1996b, 1996a), learn pomdpmodels (stochastic topological models) robot hallway environment. also recognizediculty learning good model without initial information; solve problemusing human-provided topological map, together constraints structuremodel. modified version Baum-Welch algorithm learns parametersmodel. also developed incremental version Baum-Welch used on-line.models contain weak metric information, representing hallways chains one-metersegments allowing learning algorithm select probable chain length.method effective, results large models size proportional hallways' length,strongly depends quality human-provided initial model.2.4 Learning Automata DataInformally speaking, automaton consists set states set transitions leadone state another. context work, automaton states correspondstates modeled environments, transitions, state changes due actionsperformed environment. transition automaton tagged symbol172fiLearning Geometrically-Constrained HMMsinput alphabet, , corresponding action input system caused statetransition. Classical automata theory (e.g., Hopcroft & Ullman, 1979) distinguishesdeterministic non-deterministic automata. If, alphabet symbol ff, singleedge tagged it, going state, automaton deterministic. Otherwise,transition states uniquely determined input symbol automatonnon-deterministic. augment transition edge non-deterministic automatonprobability taking given certain input, ff, resulting automaton called probabilistic.basic problem learning finite deterministic automata given data roughlydescribed follows: Given set positive set negative example strings,respectively, alphabet , fixed number states k, construct minimal deterministicfinite automaton k states accepts accept . problemshown np-complete (Gold, 1978). Despite hardness, positive resultsshown possible various special settings. Angluin (1987) showed oracleanswer membership queries provide counterexamples conjectures automaton,polynomial time learning algorithm positive negative examples. RivestSchapire (1987, 1989), provide several effective methods, various settings, learndeterministic automata correct high probability. work dealslearning noise-free data, Basye, Dean Kaelbling (1995) presented several algorithmsthat, high probability, learn input-output deterministic automata, data observedlearner corrupted various forms noise.cases, learned automaton deterministic rather probabilistic. basiclearning problem probabilistic context find automaton assignsdistribution true one data sequences, using training data , generatedtrue automaton. Another form learning problem finding probabilisticautomaton assigns maximum likelihood training data ; is, automatonmaximizes Pr(S j).Abe Warmuth (1992) show finding probabilistic automaton 2 states, evensmall error respect true model allowed probability (the probablyapproximately correct, PAC, learning model), cannot done polynomial time polynomial number examples, unless np = rp. work arises broadly acceptedconjecture, yet proven, learning hidden Markov Models hard evenpac sense. two ways address hardness: one restrict classprobabilistic models learned, learn unrestricted hidden Markov modelsgood practical results pac guarantees quality result.Work Ron et al. (1994, 1995, 1998) pursues first approach, learning restricted classesautomata, namely, acyclic probabilistic finite automata, probabilistic finite sux automata.classes useful various applications related natural language processing,learned polynomial time within pac framework.second approach, one predominantly taken work, learn modelmember complete unrestricted class hidden Markov models. weak guaranteesexist goodness model, learning procedure may directed obtainpractically good results. approach based guessing automaton (model), usingiterative procedure make automaton fit better training data. One algorithmcommonly used purpose Baum-Welch algorithm (Baum, Petrie, Soules, & Weiss,1970), presented detail Rabiner (1989). iterative updates model173fiShatkay & Kaelblingbased gathering sucient statistics data given current automaton,update procedure guaranteed converge model locally maximizes likelihoodfunction Pr(datajmodel). Since maximum local, model might close enoughtrue automaton data generated, challenging problem findways force algorithm converging higher-likelihood maxima, least makeconverge faster, facilitating multiple guesses initial models, thus raising probabilityconverging higher-likelihood maxima. approach one taken workpresented here.assume, throughout paper, number states model learningknown. strong assumption since methods learning numberstates. Regularization methods deciding number states model parameters,discussed, instance, Vapnik's book (1995). address issue here.rest work describes approach learning topological models. use noisyodometric information readily available robots. geometrical informationtypically used topological mapping methods. demonstrate topological modelalgorithm used learn extended directly incorporate weak odometricinformation. show so, avoid use human-provided priorimodels still learn stochastic environment models eciently effectively.3 Models Assumptionssection describes formal framework work. starts introducing classichidden Markov model. model extended accommodate noisy odometric informationnave form, ignoring information robot's heading orientation, lateradapted accommodate heading information.concentrate describing models algorithms learning hmms, ratherpomdps. means robot decisions make regarding next actionevery state; one action executed state. experiments, human operator gave action command associated state robot gathering data.Note action necessarily one every state, e.g., robot toldalways turn right state 1 move forward state 2. However, state one action taken. extension complete pomdps, implemented,learning hmm possible actions; straightforward although notationallycumbersome, thus limit discussion hmms.3.1 HMMs { Basicshidden Markov model consists states, transitions, observations probabilistic behavior,formally defined tuple = hS; O; A; B; i, satisfying following conditions:= fs0 ; : : : ; sN ,1 g finite set N states.= fo0 ; : : : ; oM ,1g finite set possible observation values.174fiLearning Geometrically-Constrained HMMsstochastic transition matrix, Ai;j = Pr(qt+1 = sj jqt = si), 0 i; j N ,1.NX,1qt state time t. every state si ,j =0Ai;j = 1.Ai;j holds transition probability state si state sj .B stochastic observation matrix, Bj;k = Pr(vt = ok jqt = sj ), 0 j N , 1;MX,10 k , 1. vt observation recorded time t. every state sj ,Bj;k = 1.Bj;k holds probability observing ok state sj .k=0stochastic initial distribution vector, = Pr(q0 = si), 0 N , 1.NX,1i=0= 1.holds probability state si time 0, starting record observations.model corresponds world whose actual state given time t, qt 2 , hiddendirectly observable, observable aspects state, vt 2 O, detectedrecorded state visited time t. agent moves one hidden statenext according probability distribution encoded matrix A. observed informationstate governed probability matrix B . Although work concerneddiscrete observations, extension continuous observations straightforwardwell addressed work hidden Markov models (Liporace, 1982; Juang, 1985).Simply stated, problem learning hmm \reverse engineering" hidden Markovmodel stochastic system sampled data, generated system. formalizelearning task Section 4.1. next section extends hmms account geometricinformation.3.2 Adding Odometry Hidden Markov Modelsworld composed finite set states. fundamental distinctionframework term state term location. state robotdirectly correspond location. state may include information, robot'sbattery level orientation location. robot standing entrance oce 101facing right different state robot standing place facing left; similarly,robot standing bagel arm different state robotposition without bagel.dynamics world described state-transition distributions specify probability making transitions one state next result certain action.finite set observations perceived state; relative frequencyobservation described probability distribution depends current state.model, observations multi-dimensional; observation vector values,chosen finite domain. is, factorize observation associated stateseveral components. instance, demonstrated Section 6.1, view observationrecorded robot standing oce environment consisting three components,corresponding three cardinal directions: front, left right. example, observation vector thus 3-dimensional. assumed vector's components conditionallyindependent, given state.175fiShatkay & Kaelblingaddition components, state assumed associated positionmetric space. Whenever state transition made, robot records odometry vector,estimates position current state relative previous one. time assume odometry vector consists readings along x coordinates global coordinate system, readings corrupted independent normal noise. latterindependence assumption strict one, relaxed introducing complete covariance matrix, although done work. Section 3.3 extend odometry vector include information heading robot, drop global coordinateframework.Note odometric relationship characterizes transition rather state and,described below, receives different treatment observations associatedstates.two important assumptions underlying treatment odometric relationsstates: First, inherent \true" odometric relation position everytwo states world; second, robot moves one state next,normal, 0-mean noise around correct expected odometric reading along odometricdimension. noise ects two kinds odometric error sources:{ lack precision discretization real world states (e.g. ratherlarge area robot stand regarded \the doorway AIlab").{ lack precision odometric measures recorded robot, due slippage,friction, disalignment wheels, imprecision measuring instruments, etc.formally introduce odometric information hidden Markov model framework,define augmented hidden Markov model tuple = hS; O; A; B; R; i, where:= fs0 ; : : : ; sN ,1 g finite set N states.= Qli=1 Oi finite set observation vectors length l. ith elementobservation vector chosen finite set Oi .stochastic transition matrix, Ai;j = Pr(qt+1 = sj jqt = si), 0 i; j N , 1.NX,1qt state time t. every state si , Ai;j = 1.j =0Ai;j holds transition probability state si state sj .B array l stochastic observation matrices, Bi;j;k = Pr(Vt [i] = ok jqt = sj );1 l; 0 j N , 1; ok 2 Oi ; Vt observation vector time t; Vt [i] ithcomponent.Bi;j;k holds probability observing ok along ith component observationvector, state sj .R relation matrix, specifying pair states, si sj , mean varianceD-dimensional2 odometric relation them. (Ri;j [m]) mean mth2. time consider 2, corresponding (x; y) readings.176fiLearning Geometrically-Constrained HMMscomponent relation si sj 2 (Ri;j [m]), variance. Furthermore,R geometrically consistent: component m, relation (a; b) = (Ra;b [m])must directed metric, satisfying following properties states a, b, c:defm(a; a) = 0;m(a; b) = ,m(b; a) (anti-symmetry);m(a; c) = (a; b) + m(b; c) (additivity ) :representation odometric relations ects two assumptions, previously stated,regarding nature odometric information. \true" odometric relationposition every two states represented mean. noise around correctexpected odometric relation, accounting lack precision real-worlddiscretization inaccuracy measurement, represented variance.stochastic initial probability vector describing distribution initial state.simplicity assumed form h0; : : : ; 0; 1; 0; : : : ; 0i, implyingone designated initial state, si , robot always started.model extends standard hidden Markov model described Section 3.1 two ways:facilitates observations factored components, represented vectors.components assumed conditionally independent givenstate. factorization, together conditional independence assumption, allowssimple calculation probability complete observation vectorprobabilities components. therefore results fewer probabilistic parameterslearnt model view observation vector, consisting possiblecombination component-values single \atomic" observation.introduces odometric relation matrix R constraints components. UsingR constraints it, explained Section 4, proven useful learningmodel parameters, demonstrated Section 6.3.3 Handling Directional Dataextend model accommodate directional changes addition positionalchanges. two issues stemming directional changes moving environment: need non-traditional distributions model directional changes, needcorrect cumulative rotational error severely interferes location estimationwithin global coordinate framework. detailed discussion two problemssolution given earlier paper authors (Shatkay & Kaelbling, 1998). sakecompleteness, brie review two issues here.3.3.1 Circular Distributionsrobot's change direction moves environment expressed termsangular change respect original heading. Since angular measures inherently circular, treating \normally distributed", using standard procedures obtainingsucient statistics data adequate. trivial example, average177fiShatkay & Kaelbling1<x 1, y1><x 2, y2><x 3, y3>1173 01790-13231x-1Figure 1: Simple average two angles, depictedvectors unit circle. average angleformed dashed vector.Figure 2: Directional data represented anglesvectors unit circle.two angular readings, 173 ,179 , using simple average obtain angle ,3 ,far intuitive 180 , illustrated Figure 1.address circularity issue, use von Mises distribution, circular versionnormal distribution, model change heading two states, explained below.collection changes heading within two dimensional space represented termseither Cartesian polar coordinates. Using Cartesian system, n changes headingsrecorded sequence 2-dimensional vectors, (hx1 ; y1 i; : : : hxn ; yn i), unit circle,shown Figure 2. changes also represented corresponding anglesradii center unit circle X axis, (1 ; : : : ; n ), respectively.relationship two representations is:xi = cos(i ); yi = sin(i ) ; (1 n) :vector mean n points, hx; yi, calculated as:Pn cos( )Pn sin( ):=1i=1x==;nn(1)Using polar coordinates, express mean vector terms angle, , length, a,(except case x = = 0):= arctan( xy );= (x2 + 2 ) :12angle mean angle, length measure (between 0 1)concentrated sample angles around . closer 1, concentratedsample around mean, corresponds smaller sample variance.Intuitively, satisfactory circular version normal distribution would meanmaximum likelihood estimate average angle calculated above. wayanalogous Gauss' derivation Normal distribution, von Mises developed circularversion (Gumbel, Greenwood, & Durand, 1953; Mardia, 1972), defined follows:Definition: circular random variable, , 0 2, said von Misesdistribution parameters , 0 2 > 0, probability density178fiLearning Geometrically-Constrained HMMsfunction is:f;() = 2I1 () e cos(,) ;0I0 () modified Bessel function first kind order 0:I0 () =1 1 1X2r2 ( 2 ) :r!r=0(2)parameters correspond distribution's mean concentration respectively.circular-normal distributions exist, von Mises desirable estimationprocedure alluded earlier: Given set heading samples, angles 1 ; : : : n , von Misesdistribution, maximum likelihood estimate is:= arctan( xy ) ;y, x defined Equation 1.maximum likelihood estimate concentration parameter, , satisfies:nI1 () = max[ 1 XI0 ()n i=1 cos(i , ); 0] ;I1 modified Bessel function first kind order 1:I1 () =1X1 ( 1 )2r+1 :r=0 r!(r + 1)! 2(3)information estimation procedure beyond scope paperfound elsewhere (Gumbel et al., 1953; Mardia, 1972).conclude, assume change heading von Mises-distributed, around meanconcentration parameter . assumption ected model learning proceduresexplained later Section 4.2.3. change heading h (a; b); (a; b)i pairstates (a; b) completes set parameters included relation matrix Rintroduced earlier Section 3.2.3.3.2 Cumulative Rotational Errortend think environment consisting landmarks fixed global coordinatesystem corridors transitions connecting landmarks. idea underlies typicalmaps constructed used everyday life. However, view environment mayproblematic robots involved.Conceptually, robot two levels operates; abstract level, centerscorridors, follows walls avoids obstacles, physical level motorsturn wheels robot moves. physical level many inaccuracies manifestthemselves: wheels unaligned resulting drift rightleft, one motor slightly faster another resulting similar drifts, obstacleone wheels cause robot rotate around slightly, uneven oors may cause179fiShatkay & Kaelbling- actual position- recorded positionFigure 3: robot moving along solid arrow, correcting drift direction dashedarrow. dotted arrow marks recorded change position.robot slip certain direction. addition, measuring instrumentation odometricinformation may accurate itself. abstract level, corrective actionsconstantly executed overcome physical drift drag. example, left wheelmisaligned drags robot leftwards, corrective action moving right constantlytaken higher level keep robot centered corridor.phenomena described significant effect odometry recorded robot,data interpreted respect one global framework. example, consider robotdepicted Figure 3. drifts left , moving one state next,corrects moving right order maintain centered corridor.Let us assume states 5 meters apart along center corridor, centercorridor aligned axis global coordinate system. robot steps backforth corridor one state next. Whenever robot reaches state,odometry reading changes hx; y; along hX; Y; headingi dimensions, respectively.robot proceeds, deviation respect X axis becomes severe. Thus,going several transitions, odometric changes recorded every pairstates, taken respect global coordinate system, become larger larger. Similarproblems inconsistent odometric changes recorded pairs states arise alongodometric dimensions. especially severe inconsistencies arise respectheading, since lead mistakenly switching movement along Xaxes, well confusion forwards backwards movement (when deviationheading around 90 180 respectively).early work (Shatkay & Kaelbling, 1997) assumed perpendicularity corridors,taken advantage robot collected data. Odometric readings recordedrespect global coordinate system, robot could re-align originturn. trajectory odometry recorded perpendicularity assumptionrobot Ramona, along x axes given Figure 4. sequence shown recordedrobot drove repeatedly around loop corridors. details datagathering process provided Section 6. contrast, Figure 5 shows trajectory anothersequence odometric readings recorded Ramona, driving corridors, withoutusing perpendicularity assumption. data collected latter setting subjectedcumulative rotational error.180fiLearning Geometrically-Constrained HMMs30001200250010002000800150060010004002005002004006008001000-2500 -2000 -1500 -1000 -500Figure 4: Sequence gathered Ramona, perpendicularity assumed.5001000Figure 5: Sequence gathered Ramona, per-pendicularity assumed.data handled state-relative coordinate systems (Shatkay & Kaelbling, 1998).latter implies state si coordinate system, shown Figure 6:origin anchored si , axis aligned robot's heading state (denotedbold arrows figure), X axis perpendicular it. contrast globalcoordinate system anchored initial starting state. Within global coordinatesystem, relations recorded may vary greatly among multiple instances transitionpair states. using state-relative system, recorded learnedrelationship pair states, hsi ; sj i, reliable, despite fact basedmultiple transitions recorded si sj .state-relative coordinate systems, geometric relation stored Rij , (which introduced Section 3.2), expressed pair states, si sj , respectcoordinate system associated state si. Accordingly, constraints imposed xcomponents relation matrix must specified respect explicit coordinatesystem used, explained below.Given pair states b, denote hx;yi (a; b) vector h(Ra;b [x]); (Ra;b [y])i. Letus define Tab transformation maps hxa ; ya point represented respectcoordinate system state a, point represented respect coordinatesystem state b, hxb ; yb i.explicitly, let ab mean change heading state state b. Applying Tabvector h xyaa results vector h xybb follows:* +* + *xbxx cos(ab ) , ya sin(ab )= Tab =ybyaxa sin(ab ) + ya cos(ab )+:consistency constraints within framework must restated as:hx;yi(a; a) = h0; 0i;hx;yi(a; b) = ,Tba[hx;yi(b; a)] (anti-symmetry);hx;yi(a; c) = hx;yi (a; b) + Tba[hx;yi (b; c)] (additivity).181fiShatkay & KaelblingxSjSixFigure 6: robot state Si , faces -axis direction; relation Si ,Sj wrt Si 's coordinatesystem.consistency constraints ones need enforced learning algorithmconstructs hmm. important note transformationconstitute set additional parameters need learnt. Rather, calculated termsheading-change parameter, , already integral part relation matrixdefined Sections 3.2 3.3.1.introduced basic formal model use representing environmentsrobot's interaction them. following section state learning problemdescribe basic algorithm learning model data.4 Learning HMMs Odometric Informationsection formalizes learning problem hmms, discusses odometric informationincorporated learning algorithm. overview complete algorithm providedAppendix paper.4.1 Learning Problemlearning problem hidden Markov models generally stated follows: Givenexperience sequence E, find hidden Markov model could generated sequence\useful" \close original" according criterion. explicit common statisticalapproach look model maximizes likelihood data sequence E givenmodel. Formally stated, maximizes Pr(Ej). However, given complicated landscapetypical likelihood functions multi-parameter domain, obtaining maximum likelihoodmodel feasible. studied practical methods, particular well-known BaumWelch algorithm (Rabiner (1989) references therein) guarantee local-maximumlikelihood model.Another way evaluating quality learned model comparing true model.note stochastic models (such hmms) induce probability distribution observation sequences given length. Kullback-Leibler (Kullback & Leibler, 1951) divergencelearned distribution true one commonly used measure estimating good182fiLearning Geometrically-Constrained HMMslearned model is. Obtaining model minimizes measure possible learning goal.culprit practice, learn model data, \groundtruth" model compare learned model with. Still, evaluate learning algorithmsmeasuring well perform data obtained known models. reasonable expect algorithm learns well data generated model have,perform well data generated unknown model, assuming models indeed formsuitable representation true generating process. discuss Kullback-Leibler (kl)divergence detail Section 6.2 context evaluating experimental results.summarize, learning problem address work obtaining modelattempting (locally) maximize likelihood, evaluating results basedkl-divergence respect true underlying distribution, distributionavailable.4.2 Learning Algorithmlearning algorithm starts initial model 0 given experience sequence E;returns revised model , (locally) maximizes likelihood P (Ej). experiencesequence E length ; element, Et , 0 (T , 1), pair hrt ; Vt i, rtobserved relation vector along x, dimensions, states qt,1 qt , Vtobservation vector time t.algorithm extends standard Baum-Welch algorithm deal relational information factored observation sets. Baum-Welch algorithm expectationmaximization (em) algorithm (Dempster, Laird, & Rubin, 1977); alternatesE-step computing state-occupation state-transition probabilities, ,time sequence given E current model ,M-step finding new model, , maximizes P (Ej; ; ),providing monotone convergence likelihood function P (Ej) local maximum.However, extension introduces additional component, namely, relation matrix R.viewed two kinds observations: state observations (as ordinary hmm |distinction observe integer vectors rather integers) transition observations (the odometry relations states). latter must satisfy geometrical constraints.Hence, extension standard update formulae, described below, required.4.2.1 State-Occupation ProbabilitiesFollowing Rabiner (1989), first compute forward (ff) backward (fi ) matrices. fft (i)denotes probability density value observing E0 Et qt = si , given ; fit (i)probability density observing Et+1 ET ,1 given qt = si . Formally:fft (i) = Pr(E0 ; : : : ; Et ; qt = sij) ;fit (i) = Pr(Et+1 ; : : : ; ET ,1 jqt = si ; ) :measurements continuous (as case R), matrices containprobability density values rather probabilities.forward procedure calculating ff matrix initialized(b = 1ff0 (i) = 00 otherwise;183fiShatkay & Kaelblingcontinued 0 < , 1fft (j ) =NX,1i=0fft,1 (i)Ai;j f (rt jRi;j )bjt :(4)expression f (rt jRi;j ) denotes density point rt according distribution representedmeans variances entry i; j Qrelation matrix R, bjt probabilityjobserving vector vt state sj ; is, bt = li=0 Bi;j;vt[i] .backward procedure calculating fi matrix initialized fiT ,1 (j )=1, continued0 t<T , 1NX,1fit (i) = fit+1 (j )Ai;j f (rt+1 jRi;j )bjt+1 :(5)j =0Given ff fi , compute given time point state-occupation statetransition probabilities, . state-occupation probabilities, (i), representingprobability state si time given experience sequence current model,computed follows::(6)(i) = Pr(qt = si jE; ) = PNff,t1(i)fit (i)j =0 fft (j )fit (j )Similarly, (i; j ), state-transition probabilities state state j time givenexperience sequence current model, computed as:(i; j ) = Pr(qt = si ; qt+1 = sj jE; )fft (i)Ai;j bjt+1 f (rt+1 jRi;j )fit+1 (j ):(7)=NX,1 NX,1i=0 j =0fft (i)Ai;j bjt+1 f (rt+1 jRi;j )fit+1 (j )essentially formulae appearing Rabiner's tutorial (Rabiner, 1989),also take account density odometric relations.next phase algorithm, goal find new model, , maximizes likelihood conditioned current transition observation probabilities, Pr(Ej; ; ). Usually,simply done using maximum-likelihood estimation probability distributionsB computing expected transition observation frequencies. model must alsocompute new relation matrix, R, constraint remain geometrically consistent.rest section use notation v denote reestimated value, vdenotes current value.4.2.2 Updating Transition Observation ParametersB matrices straightforwardly reestimated. Ai;j expected numbertransitions si sj divided expected number transitions si , B i;j;kexpected number times ok observed along ith dimension state sj , dividedexpected number times sj :PT ,1PT ,2 (i; j )=0; B i;j;k = t=0PT[V,t1[i]=ok ] (j ) :(8)Ai;j = PT ,2t=0 (i)t=0 (i)expression c denotes indicator function value 1 condition c true 0 otherwise.184fiLearning Geometrically-Constrained HMMs7.5PQ5P2.5-8-6-4-22468-2.5-5-6-4-2246-7.5QFigure 7: Examples two sets normally distributed points constrained means, 1 2dimensions.4.2.3 Updating Relation Parametersreestimating relation matrix, R, geometrical constraints induce interdependenciesamong optimal mean estimates well optimal variance estimates meanestimates. Parameter estimation form constraints almost untreated mainstream statistics (Bartels, 1984) found previous existing solutions estimationproblem addressed here. illustration issues involved estimation constraintsconsider following estimation problem 2 normal means:Example 4.1 data consists two sample sets points P = fp1; p2 ; : : : ; pn g Q =fq1; q2 ; : : : ; qk g, independently drawn two distinct normal distributions means P ; Qvariances P2 ; Q2 , respectively. asked find maximum likelihood estimatestwo distribution parameters. Moreover, told means two distributionsrelated, Q = ,P , illustrated Figure 7. latter constraint, tasksimple (DeGroot, 1986), have:Pn pPn; 2 = i=1 (pi , P )2 ;P = i=1Pnnsimilarly Q Q2 . However, constraint P = ,Q requires finding single mean, ,setting one negated value, ,. Intuitively, choosing maximumlikelihood single mean, concentrated sample effect,varied sample \submissive." Thus, overall sample deviation meanswould minimized likelihood data maximized. Therefore, mutualdependence estimation mean estimation variance.Since samples independently drawn, joint likelihood function is:,(pi ,P )2nPf (P; QjP ; Q; P2 ; Q2 ) = e pi=1 2P2 2Yk ej =1,(qj ,Q )2Qp2 22Q:taking derivatives joint log-likelihood function, respect P , P Q,equating 0, using constraint Q = ,P , obtain following set mutualequations maximum likelihood estimators:PP(Q2 ni=1 pi) , (P2 kj=1 qj )P =; Q = ,P ;nQ2 + kP2Pk (q + )2Pn (p , )2P=122P =; Q = j =1 j P :nk185fiShatkay & Kaelblingsubstituting expressions P Q expression P , obtain cubic equation cumbersome, still solvable (in simple case). solution provides maximum likelihood estimate mean variance constraint Q = ,P :2proceed actual update relation matrix constraints. clarity,initially discuss first two geometrical constraints, discuss additivity constraintSection 4.3. Recall concentrate enforcement global constraints, appropriateperpendicularity assumption, although idea applied case staterelative constraints.Zero distances states trivially enforced, setting diagonalentries R matrix 0, small variance.Anti-symmetry within global coordinate system enforced using data recorded alongtransition state sj si well state si sj reestimating (Ri;j ).demonstrated Example 4.1, variance taken account, leading followingset mutual equations:mi;j=( mi;j )2 =PT ,2rt[m]t (i;j ) , rt [m]t(j;i)((i;j )2j;i )2PT ,2 t(mi;j) + t(mj;i)t=0 (i;j )2 (j;i )2PT ,2[ (i; j )(r [m] , )2 ]t=0PT ,2 t(i; j ) i;j :t=0t=0;(9)(10)x dimensions, (m = x; y), amounts complicated still solvable cubicequation. However, general case, accounting orientation robot,also complete additivity enforced, obtain closed form reestimationformulae.avoid hardships, use lag-behind update rule; yet-unupdated estimatevariance used calculating new estimate mean, new mean estimateused update variance, using Equation 10.3 Thus, mean updated using varianceparameter lags behind update process, reestimation Equation (9) needsuse rather follows: PT ,2 h rt [m]t (i;j) rt [m]t (j;i)2 , j;i)2t=0:(11)mi;j = PT ,2(hi;jt ()i;j) ((j;i)t=0)2 + (j;i)2i;j(shown (Shatkay, 1999), lag-behind policy instance generalized em (McLachlan & Krishnan, 1997). latter guarantees monotone convergence local maximumlikelihood function, even \maximization" step increases rather strictly maximizes expected likelihood data given current model.Similarly, reestimation formula von Mises mean () concentration () parametersheading change states si sj solution equations:0 TX1,BB [sin(rt [])(t (i; j )i;j , t(j; i)j;i)] CCCC= arctan BB@ TX,[cos(rt [])(t (i; j )i;j + (j; i)j;i )]2i;j=02t=03. similar approach, termed one step late update, taken others applying em highly non-linear optimization problems (McLachlan & Krishnan, 1997).186fiLearning Geometrically-Constrained HMMsI1 [i;j ]= maxI0 [i;j ]" PT ,#2(i; j ) cos(rt [] , i;j )]t=0 [tP; 0,2 (i; j )t=0;(12)I0 I1 modified Bessel functions defined Equations 2 3 Section 3.3.1.Again, avoid need solve mutual equations, take advantage lag-behind strategy, updating mean using current estimates concentration parameters, i;j ; j;i,follows:PT ,2[sin(r [])( (i; j ) , (j; i) )] !i;jj;ii;j = arctan PTt=0(13),2 [cos(r [])( (i; j ) + (j; i) )] ;i;jj;it=0calculating new concentration parameters based newly updated mean,solution Equation 12, use lookup-tables.possible alternative lag-behind approach update mean though assumption j;i = i;j holds. assumption, variance terms Equation 9 cancel out,mean update independent variance again. variances updatedstated Equation 10, without assuming constraints them. approach takenearlier stages work (Shatkay & Kaelbling, 1997, 1998). lag-behind strategysuperior, according experiments, due instance generalized em.4.3 Enforcing AdditivityNote additivity constraint directly implies two geometrical constraints4 . Thus,enforcing results complete geometrical consistency. present method directlyenforcing additivity reestimation procedure along x dimensions.heading dimension describe complete geometrical consistency achievedprojection anti-symmetric estimates onto geometrically-consistent space. before,simplify presentation, focus case global coordinate systems. basicidea applies state-relative coordinate systems, relationship used recover meanij individual state coordinates complex.4.3.1 Additivity x, dimensionsmain observation underlying approach additivity constraint resultfact states embedded geometrical space. is, assuming N states,s0; : : : ; sN ,1, points X , axes, x0 ; : : : ; xN ,1 , y0 ; : : : ; yN ,1 , 0 ; : : : ; N ,1,respectively, state, si , associated coordinates hxi ; yi ; i. Assumingone global coordinate system, mean odometric relation state si state sjexpressed as: hxj , xi ; yj , yi ; j , i.maximization phase em iteration, rather try maximize respectN 2 odometric relation vectors, hXij , Yij , ij i, reparameterize problem. Specifically,express odometric relation function two N state positions, maximizerespect unconstrained, N state positions. instance, X dimension, rathersearch N 2 maximum likelihood estimates xij , use maximization step findN 1-dimensional points, x0 ; : : : ; xN ,1 . calculate xij = xj , xi . Moreover, sinceinterested finding best relationships xi xj , fix one4. f(a; a)= (a; a) + (a; a)g ) ((a; a)=0) ; f((a; a)=0) ; ((a; a)= (a; b)+(b; a))g ) ((a; b) = ,(b; a)).187fiShatkay & Kaelblingxi 's 0 (e.g. x0 = 0), find optimal estimates remaining N , 1 state positions.variance reestimation remains before, lag-behind policy used eliminateinterdependency update mean variance parameters.4.3.2 Additive Heading EstimationUnfortunately, reparameterization described feasible estimation changesheading, due von Mises distribution assumption heading measures. reparameterizing ij j , trying maximize likelihood function respectparameters, obtain set N,1 trigonometric equations terms form cos(j ) sin(i )enable simple solution.alternative, possible use anti-symmetric reestimation procedure describedearlier, followed perpendicular projection operator, mapping resulting headings vectorh00 ; : : : ; ij ; : : : ; N ,1;N ,1i, 0 i; j N ,1, satisfy additivity, onto vectorheadings within additive linear vector space. Simple orthogonal projection satisfactorywithin setting, since simply looks additive vector closest non-additive one.procedure ignores fact entries non-additive vector basedlot observations, therefore reliable, other, less reliable ones, basedhardly data all. Intuitively, would like keep estimates well accountedintact, adapt less reliable estimates meet additivity constraint. precisely,heading-change estimates states better accounted others,sense transitionsstates higher expected counts transitionPstates (higher (i; j )). would like project non-additive headingestimates vector onto subspace additive vector space, vectorsvalues non-additiveP vector entries well-accounted for, is,highest values (i; j ). diculty latter subspace linear vectorspace (for instance, satisfy closure scalar multiplication), projectionoperator linear spaces cannot applied directly. Still, set vectors formane vector space, project onto using algebraic technique, explained below.5DefinitionRn n-dimensional ane space vectors va2A, set vectors:def, va = fua , va jua 2 Ag linear space.Hence, pick vector ane space, va 2A, define translation Ta : ! V ,V linear space, V = , va . translation trivially extended vectorv0 2 Rn , defining Ta (v0 ) = v0 , va . order project vector v 2 Rn onto A, applytranslation Ta v project Ta (v) onto V , results vector P (Ta (v)) V .applying inverse transform Ta,1 it, obtain projection v A, demonstratedFigure 8. linear space figure two dimensional vector space fhx; yij = ,xg,ane space fhx; yij = ,x + 4g. transform Ta consists subtracting vectorh0; 4i. solid arrow corresponds direct projection vector v onto point P (v)ane space. dotted arrows represent projection via translation v Ta (v),projection latter onto linear vector space, inverse translation result,P (Ta (v)), onto ane space.1115. Many thanks John Hughes introducing us technique.188fiLearning Geometrically-Constrained HMMs6<x,-x+4>4P(v)v2-22-24Ta (v)P(Ta (v))<x,-x>-4Figure 8: Projecting v onto ane vector space fhx; yij = ,x + 4g.Although procedure preserving additivity headings formally proven preserve monotone convergence likelihood function towards local maximum, extensiveexperiments consisting hundreds runs shown monotone convergence preserved.5 Choosing Initial ModelTypically, instances Baum-Welch algorithm, initial model picked uniformlyrandom space possible models, perhaps trying multiple initial models find different local likelihood maxima. alternative approach reported (Shatkay & Kaelbling,1997) based clustering accumulated odometric information using simple k-meansalgorithm (Duda & Hart, 1973), taking clusters states observationsrecorded, obtain state observation counts estimate model parameters.perpendicularity assumed collecting data, shown Figure 4, k-meansalgorithm assigns cluster (state) odometric readings recorded close locations,leading reasonable initial models. However, assumption dropped, illustratedFigure 5, cumulative rotational error distorts odometric location recorded withinglobal coordinate system, location assigned state multiple visitsvaries greatly would recognized \the same" simple location-based clusteringalgorithm. overcome this, developed alternative initialization heuristics, calltag-based initialization. based directly recorded relations states, ratherstates' absolute location. clarity, description consists mostly illustrativeexample, concentrates case global consistency constraints enforced.Given sequence observations odometric readings E, begin clustering odometricreadings buckets. number buckets number distinct state transitionsrecorded sequence. goal stage bucket contain odometricreadings close along three dimensions.achieve this, start fixing predetermined, small standard deviation value along x,y, dimensions. Denote standard deviation values x ; ; respectively, (typicallyx = ). first odometric reading assigned bucket 0 mean bucketset value reading. rest process subsequent odometricreadings examined. next reading within 1:5 standard deviations alongthree dimensions mean existing non-empty bucket, add bucket189fiShatkay & Kaelbling< 2, 94, 92 >< -4, 102, 91 ><1994, 0, 88 >< 1998, -5, 90 >< 3, -93, 86 >< -2, -106, 91 >< -1999, -1, 94 >< -2003, 7, 87 >1:2:3:4:<-1, 98, 91.5><1996, -2.5, 89><0.5, -99.5, 88.5><-2001, 3, 90.5>3412Figure 9: bucket assignment example sequence.update bucket mean accordingly. not, assign empty bucket set meanbucket reading.Intuitively, using heuristic resulting buckets tightly concentratedmean. note clustering algorithms (Duda & Hart, 1973) could usedbucketing stage.Example 5.1 would like learn 4-state model sequence odometric readings,hx; y; follows:h2 94 92i; h1994 0 88i; h3 , 93 86i; h,1999 1 94i;h,4 102 91i; h1998 , 5 90i; h,2 , 106 91i; h,2003 7 87i :first stage place readings buckets. Suppose standard deviation constant20. placement shown Figure 9. mean value associated bucket shownwell.2next stage algorithm state-tagging phase, odometric reading,rt , assigned pair states, si; sj , denoting origin state (from transition tookplace) destination state (to transition led), respectively. conjunction,mean entries, ij , relation matrix, R, populated.Example 5.1 (cont.) Returning sequence above, process demonstrated Figure 10. assume data recording starts state 0, odometric changeself transitions 0, small standard deviation (we use 20 well).shown part figure.Since first element sequence, h2 94 92i, two standard deviations awaymean [0][0] entry relation row state 0 populated, pick 1next state populate mean [0][1] mean bucket 1,h2 94 92i belongs. maintain geometrical consistency mean [1][0] set ,[0][1],shown part B figure. populated 2 off-diagonal entries, statesequence h0; 1i. entry [0][1] matrix becomes associated bucket 1,information recorded helping tagging future odometric readings belongingbucket.next odometric reading, h1994 0 88i, standard deviations populated meanrow 1 (where 1 current believed state). Hence, pick new state 2, set mean[1][2] 2|the mean bucket 2|to reading belongs (Figure 10 C). entry[1][2] recorded associated bucket 2. preserve anti-symmetry additivity, [2][1]set ,[1][2]. [0][2] set sum [0][1] + [1][2], [2][0] set ,[0][2].190fiLearning Geometrically-Constrained HMMs001B230<0,0,0>101<0,0,0><0,0,0>223<-1,<0,0,0> 98,91.5>< 1,-98,-91.5><0,0,0><0,0,0>23<0,0,0>31<0,0,0>S: 0S: 0. 1Bucket(R[0][1]) = 1C00121230<-1,<1995,95.5,<0,0,0> 98,91.5> -179.5><1996,< 1,-98,<0,0,0> -2.5,-91.5>89>01<-1995, <-1996,-95.5,2.5,<0,0,0>179.5> -89>323<0,0,0>S: 0, 1, 2123<-1,<1995, <1995.5,95.5,-4,<0,0,0> 98,91.5> -179.5> -91><1996, <1996.5,< 1,-98,-102,<0,0,0> -2.5,-91.5>89>177.5><-1995, <-1996,< 0.5,-95.5,2.5,<0,0,0> -99.5,179.5> -89>88.5><-1995.5, <-1996.5, <-0.5,99.5, <0,0,0>4,102,-177.5> -88.5>91>S: 0,1,2,3Bucket(R[2][3]) = 3Bucket(R[1][2]) = 2S: 0,1,2,3,0Bucket(R[3][0]) = 4,..., S:0, 1, 2, 3, 0, 1, 2, 3, 0Figure 10: Populating odometric relation matrix creating state tagging sequence.Similarly, [2][3] updated mean bucket 3, causing setting [3][2], [1][3],[0][3], [3][1], [3][0]. Bucket 3 associated [2][3].stage odometric table fully populated, shown part Figure 10. statesequence point is: h0; 1; 2; 3i. next reading, h,1999 ,1 94i, within one standarddeviation [3][0] therefore next state 0. Entry [3][0] associated bucket 4,(the bucket reading assigned), state sequence becomes: h0; 1; 2; 3; 0i.next reading, bucket 1, associated relation state 0 taggedbucket 1, namely, state 1. repeating last two readings, final state transitionsequence becomes h0; 1; 2; 3; 0; 1; 2; 3; 0i:2Note process described illustration simplified. general case,need take account rotational error data, use state-relative coordinatesystems, therefore populate entries transformed anti-symmetry additivityconstraints:hx;yi(a; b) = ,Tba [hx;yi(b; a)] ;hx;yi(a; c) = hx;yi(a; b) + Tba [hx;yi(b; c)],defined Section 3.3.2.191fiShatkay & Kaelblingpossible end tagging algorithm, rows columns relationmatrix still unpopulated. happens little data learnnumber states provided algorithm large respect actual model.cases either \trim" model, using number populated rows numberstates, pick random odometric readings populate rest table, improvingestimates later. Note first approach suggests method learning number statesmodel given, starting gross over-estimate number, truncating number populated rows odometric table initialization performed.state-transition sequence obtained, rest initialization algorithmk-means based initialization, deriving state-transition counts state-transitionsequence, assigning observations states assumption state sequencecorrect, obtaining state-transition observation probabilities. initialization phaseincur much computational overhead, equivalent time-wise performing oneadditional iteration em procedure.6 Experiments Resultsgoal work described far use odometry improve learning topologicalmodels, using fewer iterations less data. tested algorithm simple robotnavigation world. experiments consist running algorithm data obtainedsimulated model data gathered mobile robot, Ramona. amountdata gathered Ramona used proof concept sucient statisticalanalysis. latter, use data obtained simulated model. gathered dataused algorithms without perpendicularity assumption (see Section 3.3.2),results provided settings.6.1 Robot Domainrobot used experiments, Ramona, modified RWI B21 robot. cylindricalsynchro-drive base, 24 ultrasonic sensors 24 infrared sensors, situated evenly aroundcircumference. infrared sensors used mostly short-range obstacle avoidance.ultrasonic sensors longer ranged, used obtaining (noisy) observationsenvironment. experiments described here, robot follows prescribed pathcorridors oce environment department. Thus, decision-makinginvolved, hmm sucient model, rather complete pomdp.Low-level software6 provides level abstraction allows robot move hallwaysintersection intersection turn ninety degrees left right. softwareuses sonar data distinguish doors, openings, intersections along path, stoprobot's current action whenever landmark detected. stop|either duenatural termination action due landmark detection|is considered robot\state".stop, ultrasonic data interpretation allows robot perceive, threecardinal directions, (front, left right), whether open space, door, wall,something unknown.Encoders robot's wheels allow estimate pose (position orientation) respect pose previous intersection. recording sonar-based observations6. low-level software written maintained James Kurien.192fiLearning Geometrically-Constrained HMMs35467892121310119823426 722 2021430191054132 14114 1516181724253836373534401126 2730 31120161514292839333213Figure 11: True model corridors Ramona traversed. Arrows represent prescribed path direction.Figure 12: True model prescribed pathsimulated hallway environment.odometric information, robot goes execute next prescribed action.action command issued manually human operator. course, action performance perception routines subject error. path Ramona followed consists4 connected corridors building, include 17 states, shown Figure 11.simulation, manually generated hmm representing prescribed path robotcomplete oce environment department, consisting 44 states,associated transition, observation, odometric distributions. transition probabilitiesect action failure rate 5 , 10%. is, probability movingcurrent state correct next state environment, predetermined action0:85 0:95. probability self transition typically 0:05 0:15.small probability (typically smaller 0:02) sometimes assigned transitions.experience real robot proves reasonable transition model, sincetypically robot moves next state correctly, error occurssignificant frequency move all, due sonar interpretation indicatingbarrier actually none. action command repeated robot usuallyperforms action correctly, moving expected next state. observation distributiontypically assigns probabilities 0:85 , 0:95 true observation perceivedrobot state, probabilities 0:05 , 0:15 observations mightperceived. example, door actually perceived, door typically assignedprobability 0:85,0:9, wall assigned probability 0:09,0:1 open space assignedprobability 0:01 perceived. standard deviation around odometric readings5% mean.Figure 12 shows hmm corresponding simulated hallway environment. Observationsorientation omitted figure clarity. Nodes correspond statesenvironment, directed edges correspond corridors; arrows point directioncorridors traversed. interpretation figures providedfollowing section.193fiShatkay & Kaelbling6.2 Evaluation Methodnumber different ways evaluating results model-learning algorithm.None completely satisfactory, give insight utility results.domain, transitions observations usually take place, thereforelikely others. Furthermore, relational information gives us rough estimatemetric locations states. get qualitative sense plausibility learntmodel, extract essential map learnt model, consisting states,likely transitions metric measures associated them, ask whether mapcorresponds essential map underlying true world.Figures 11 12 essential versions true models, Figures 15 17, shownlater, essential versions representative learnt ones (obtained sequences gatheredperpendicularity assumption). Black dots represent physical locations states,state assigned unique number. Multiple state numbers associated singlelocation typically correspond different orientations robot location. largerblack circle represents initial state. Solid arrows represent likely non-self transitionsstates. Dashed arrows represent transitions probability 0:2higher. Typically, due predetermined path taken, connectivitymodeled environment low, therefore transitions represented dashed arrowsalmost likely likely ones. Note length arrows, within plot,significant represents length corridors, drawn scale.important note figures provide complete representation models.First, lack observation orientation information. stress fact figuresserve visual aid plot true model. looking good topologicalmodel rather geometrical model. figures provide geometrical embeddingtopological model. However, even geometry, described relation matrix,different, topology, described transition observation matrices, still valid.Traditionally, simulation experiments, learnt model quantitatively comparedactual model generated data. models induces probability distributionstrings observations; asymmetric Kullback-Leibler divergence (Kullback & Leibler,1951) two distributions measure good learnt model respecttrue model. Given true probability distribution P = fp1 ; :::; pn g learnt oneQ = fq1; :::; qn g, kl divergence Q respect P is:D(P jjQ) =defnXi=1pi log2 pqi :report results terms sampled version kl divergence, described JuangRabiner (1985). based generating sequences sucient length (5 sequences 1000observations case) according distribution induced true model, comparinglog-likelihood according learnt model true model log-likelihood. totaldifference log-likelihood divided total number observations, accumulatedsequences, giving number roughly measures difference log-likelihoodper observation. Formally stated, let M1 true model M2 learnt one. generatingK sequences S1 ; : : : ; SK , length , true model, M1 , sampled kl-divergence,Ds is:KX[log(Pr(Si jM1 )) , log(Pr(Si jM2 ))]=1Ds(M1 jjM2 ) =:KT194fiLearning Geometrically-Constrained HMMs100012005001000800-1500 -1250 -1000 -750-500-250600-500400-1000200200400600800-15001000Figure 13: Sequence gathered Ramona,perpendicularity assumed.Figure 14: Sequence generated simulator, perpendicularity assumed.ignore odometric information applying kl measure, thus allowing comparisonpurely topological models learnt without odometry.6.3 Results within Global Frameworklet Ramona go around path depicted Figure 11 collect sequence300 observations, assuming perpendicularity environment, is, every turningpoint angle turn 90 . Thus turn Ramona realigns odometric readingsinitial X axes. Figure 13 plots sequence metric coordinates, gatheredway, accumulating consecutive odometric readings, projected hx; yi. appliedlearning algorithm data 30 times. 10 runs started k-means-basedinitial model, 10 started tag-based initial model, 10 started random initialmodel. addition also ran standard Baum-Welch algorithm, ignoring odometricinformation, 10 times. (Note non-determinism even using biased initialmodels, since k-means clustering starts random seeds, low7 random noise addeddata algorithms avoid numerical instabilities, thus multiple runs give multipleresults). report results obtained using tag-based method,appropriate initialization method general case. results contrastedobtained odometric information used all. comparison four settingsreader referred complete report work (Shatkay, 1999).Figure 15 shows essential representations typical learnt models starting tag-basedinitial model. geometry learnt model strongly corresponds true environment, states' positions learnt correctly. Although figureshow it, learnt observation distributions state usually match well trueobservations.demonstrate effect odometry quality learnt topological model, contrastplotted models learnt using odometry representative topological model learnt without7. random number -1cm 1cm added recorded distances typically several meterslong.195fiShatkay & Kaelbling34563456787859079221281101091116215311111314161112161215014140mona traversed.6413Figure 15: Learnt model corridors Ra1513Figure 16: topology model learntwithout use odometry.use odometric information. Figure 16 shows topology typical model learnt withoutuse odometric information. case, arcs represent topological relationships,length meaningful. initial state shown bold circle. cleartopology learnt match characteristic loop topology true environment.obtaining statistically sucient information, generated 5 data sequences, length1000, using Monte Carlo sampling hidden Markov model whose projection shownFigure 12. One sequences depicted Figure 14. figure demonstratesnoise model used simulation indeed compatible noise pattern associatedreal robot data. used four different settings learning algorithm:starting biased, tag-based, initial model using odometric information;starting biased, k-means-based, initial model using odometric information;starting initial model picked uniformly random, using odometric information;starting random initial model without using odometric information (standard BaumWelch).sequence four algorithmic settings ran algorithm 10 times.keep discussion focused, concentrate first last settingsreader referred extensive report (Shatkay, 1999) complete discussion.experiments, N set 44, \correct" number states; generalization, necessary use cross-validation regularization methods select modelcomplexity. Section 5 also suggests one possible heuristic obtaining estimate numberstates.Figure 17 shows essential version one learnt model, obtained sequence shownFigure 14, using tag-based initialization. note learnt model completely196fiLearning Geometrically-Constrained HMMs26141516 27131225332423786229032 31 21529 171828342 14 32019 30111035 3643 423741383940Figure 17: Learnt model simulated hallway environment.accurate respect true model. However, obvious correspondencegroups states learnt true models, transitions (as wellobservations, shown) learnt correctly. quality geometrylearnt model simulated large environment varies, geometrical resultsuniformly good case learning smaller environment real robot data.environment gets large, global relations remote states, ectedgeometrical consistency constraints, become harder learn. Still, topologylearnt model demonstrated statistical experiments good.Table 1 lists kl divergence true learnt model, well numberruns convergence reached, 5 sequences settinguses odometric information tag-based initialization learning algorithmuse odometric information, averaged 10 runs per sequence. stress kldivergence measure calculated based new data sequences generated truemodel, described Section 6.2. 5 sequences models learntparticipate testing process.kl divergence respect true model models learnt using odometry, 5-6times smaller models learnt without odometric data. standard deviation aroundmeans 0.2 kl distances models learnt odometry 1.5 noodometry setting. check significance results used simple two-sample t-test.models learnt using odometric information statistically significantly (p 0:0005) loweraverage kl divergence others.Seq. #klOdo Iter #klOdo Iter #10.98116.706.351124.121.29020.904.863126.031.11522.305.926113.041.24112.706.261107.451.24127.504.802122.9Table 1: Average results two learning settings five training sequences.197fiShatkay & Kaelblingaddition, number iterations required convergence learning using odometricinformation roughly 4-5 times smaller required ignoring information.Again, t-test verifies significance result.three initialization settings, models learnt topologically somewhat inferior (andhigh statistical significance), terms kl divergence, learnt withoutenforcing additivity, reported earlier papers (Shatkay & Kaelbling, 1997, 1998). likelyresult strong constraints enforced learning process, preventalgorithm searching better areas learning-space, restrict reach poor localmaxima. geometry looks superior cases, significantly better. However,seems less variability quality geometrical models across multiple runsadditivity enforced.details extensive comparison different initialization methodsbeyond scope paper, point studies small large modelsshow large models long data sequences involved, random initialization oftenresults lower KL-divergence tag-based initialization.strong bias tag-based initialization, lead peaked models comparedless-peaked distributions associated true model. Random initialization leads attermodels. KL-divergence strongly penalizes models much peakedtrue ones, randomly initialized models often closer, terms measure, truemodels peaked ones learnt initial models. learning small models,sucient training data available, tag-based initialization results modelsclearly superior random ones. Again, reader referred complete reportwork (Shatkay, 1999) comparative study initialization methods varioussettings.6.4 Results within Relative Frameworkapplied algorithm described Section 4.3, extended accommodate state-relativeconstraints (as listed Section 3.3.2). data used gathered robotenvironment, generated simulated model (Figures 11, 12).However, data generated without assuming perpendicularity. means xcoordinates realigned turn global x axes, rather,recorded \as-is." evaluation methods stay described above.Figure 18 shows projection odometric readings Ramona recorded alongx dimensions, traversing environment. obtaining statistically sucientinformation, generated 5 data sequences, length 800, using Monte Carlo samplinghidden Markov model whose projection shown Figure 12. One sequencesdepicted Figure 19.Figure 20 shows typical model obtained applying algorithm enforcing completegeometrical consistency, robot data shown Figure 18, using tag-based initialization.note rectangular geometry environment preserved, although state 0participate loop. explained observing corresponding area trueenvironment depicted Figure 11, consisting 4 states clustered bottom leftcorner (0, 14, 15 16). Due relatively large number states close togetherarea true environment, recognized ever returned particularlystate 0 loop. Therefore, one transition recorded state 0 state198fiLearning Geometrically-Constrained HMMs300015002500100020005001500-1500-1000-5005001000-500500-1000-1500-2500 -2000 -1500 -1000 -5005001000Figure 18: Sequence gathered Ramona,Figure 19: Sequence generated simula-perpendicularity assumed.tor, perpendicularity assumed.151416113122113405106798Figure 20: Learnt model corridors Ramona traversed. Initialization tag-based.1 according expected transition counts calculated algorithm. projectingangles maintain additivity, (as described Section 4.3.2), angle state 0 1therefore compromised, allowing geometrical consistency maintain rectangular geometryamong regularly visited states.purpose quantitatively evaluating learning algorithm list Table 2 kldivergence true learnt model, well number iterations convergence reached, 5 simulation sequences with/without odometric information,averaged 10 runs per sequence. table demonstrates kl divergence respect true model models learnt using odometric data, 8 times smallermodels learnt without it. check significance results use simpletwo-sample t-test. models learnt using odometric information highly statistically significantly (p 0:0005) lower average kl divergence others. addition, number199fiShatkay & KaelblingSeq. #klOdo Iter #klOdo Iter #123451.46 1.18 1.20 1.02 1.2211.8 36.8 30.7 24.6 33.36.91 9.93 10.03 9.54 12.43113.3 113.1 102.0 104.2 112.5Table 2: Average results 2 learning settings 5 training sequences.iterations required convergence learning using odometric information smallerrequired ignoring information. Again, t-test verifies significance (p < 0:005)result.important point number iterations, although much lower, automatically imply algorithm runs less time non-odometric Baum-Welch.major bottleneck caused need compute within forward-backward calculations,described Section 4.2.1, values normal von-Mises densities. require calculation exponent terms rather simple multiplications, slowingiteration, current nave implementation. However, solve augmentingprogram look-up tables obtaining relevant values rather calculating them.addition, take advantage symmetry relations table cutamount calculation required. also possible use fact many odometric relations remain unchanged (particularly later iterations algorithm) one iterationnext, therefore values cached shared iterations ratherrecalculated iteration.6.5 Reducing Amount DataLearning hmms obviously requires visiting states transitioning multiple times,gather sucient data robust statistical estimation. Intuitively, exploiting odometric datahelp reduce number visits needed obtaining reliable model.examine uence reduction length data sequences quality learntmodels, took one 5 sequences used prefixes length 100 800 (the completesequence), increments 100, training sequences. ran two algorithmic settings8 prefix sequences, 10 times repeatedly. used kl-divergence describedevaluate resulting models respect true model. prefixlength averaged kl-divergence 10 runs.plot Figure 21 depicts average kl-divergence function sequence lengthtwo settings. demonstrates that, terms kl divergence, algorithm,uses odometric information, robust face data reduction, (down 200 datapoints). contrast, learning without use odometry quickly deteriorates amountdata reduced.note data sequence twice \wide" odometry usednot; is, information element sequence odometry datarecorded. However, effort recording additional odometric information negligible,well rewarded fact fewer observations less exploration requiredobtaining data sequence sucient adequate learning.200fiLearning Geometrically-Constrained HMMs504030OdometryKL2010Odometry Used0200400Seq. Length600800Figure 21: Average kl divergence function sequence length.7 ConclusionsOdometric information, often readily available robotics domain, makes possiblelearn hidden Markov models eciently effectively, using shorter training sequences.importantly, contrast traditional perception viewing topologicalgeometric models two distinct types entities, shown odometric informationdirectly incorporated traditional topological hmm model, maintainingconvergence reestimation algorithm local maximum likelihood function.method uses odometric information two ways. first choose initial model,based odometric information. iterative procedure, extends Baum-Welchalgorithm, used learn topological model environment learningadditional set constrained geometric parameters. additional set constrained parameters constitutes extension basic hmm/pomdp model transitions observations.Even though primarily interested underlying topological model (transitionobservation probabilities), experiments demonstrate use odometric relationsreduce number iterations amount data required algorithm, improveresulting model.initialization procedure enforcement additivity constraint relativelysmall models prove helpful topologically geometrically. extensive study (Shatkay,1999) shows long data sequences, generated large models, enforcing antisymmetry rather additivity, leads better topological models.cases, initialization always good, additivity may over-constrain learningunfavorable area. Learning large models may benefit enforcing anti-symmetryfirst iterations, complete additivity later iterations. Alternatively, may usealgorithm, enforcing additivity, learn separate models small portions environment,combining later one complete model. similar idea combining small modelfragments complete map environments applied, context geometricalmaps, recent work Leonard Feder (2000).201fiShatkay & Kaelblingwork presented demonstrates domain-specific information constraintsenforced part statistical estimation process, resulting better models, requiringshorter data sequences. strongly believe idea applied domainsrobotics. particular, acquisition hmms use molecular biology may greatly benefitexploiting geometrical (and other) constraints molecular structures. Similarly, temporalconstraints may exploited domains pomdps appropriate decision-support,air-trac control medicine.Acknowledgmentsthank Sebastian Thrun insightful comments throughout work, John Hughes Luis Ortizhelpful advice, Anthony Cassandra code generating random distributions, Bill Smartsustaining Ramona Jim Kurien providing low level code driving her. presentationpaper benefited comments made anonymous referees grateful.work done authors Computer Science department Brown University,supported DARPA/Rome Labs Planning Initiative grant F30602-95-1-0020, NSF grantsIRI-9453383 IRI-9312395, Brown University Graduate Research Fellowship.202fiLearning Geometrically-Constrained HMMsAppendix A. Overview Odometric Learning Algorithmalgorithm takes input experience sequence E = hr; V i, consisting odometricsequence r observation sequence V , defined beginning Section 4.2.number states also assumed given.Learn Odometric HMM(E)1 Initialize matrices A; B; R(See Section 5)2 max change 13 ( max change > )4 Calculate Forward probabilities, ff(Equation 4)5Calculate Backward probabilities, fi(Equation 5)6Calculate state-occupation probabilities, (Equation 6)7Calculate State-transition probabilities, ; (Equation 7)8Old A; Old B B9Reestimate (A)(Equation 8, left)10B Reestimate (B )(Equation 8, right)11R Reestimate (R )(Equations 12 13)xx12hR ; R Reestimate(R ; R ) (Equations 10 11)13max change MAX(Get Max Change(A; Old );Get Max Change(B; Old B ))equations referenced Step 12 correspond updates perpendicularity assumption, global framework used. See (Shatkay, 1999) update formulae withinstate-relative framework.additivity enforced, step 11 followed projection reestimated R onto additiveane space, described Section 4.3.2. addition, step 12 substituted proceduredescribed Section 4.3.1. reader referred (Shatkay, 1999) detail.Get Max Change function takes two matrices returns maximal element-wiseabsolute difference them. constant set denote margin error changesparameters. change parameters \small enough", model regarded\unchanged".203fiShatkay & KaelblingReferencesAbe, N., & Warmuth, M. K. (1992). computational complexity approximating distributions probabilistic automata. Machine Learning, 9 (2), 205{260.Angluin, D. (1987). Learning regular sets queries counterexamples. InformationComputation, 75, 87{106.Asada, M. (1991). Map building mobile robot sensory data. Iyengar, S. S., &Elfes, A. (Eds.), Autonomous Mobile Robots, pp. 312{322. IEEE Computer Society Press.Bartels, R. (1984). Estimation bidirectional mixture von Mises distributions. Biometrics,40, 777{784.Basye, K., Dean, T., & Kaelbling, L. P. (1995). Learning dynamics: System identificationperceptually challenged agents. Artificial Intelligence, 72 (1).Baum, L. E., Petrie, T., Soules, G., & Weiss, N. (1970). maximization technique occurringstatistical analysis probabilistic functions Markov chains. AnnalsMathematical Statistics, 41 (1), 164{171.Cassandra, A. R., Kaelbling, L. P., & Kurien, J. A. (1996). Acting uncertainty: DiscreteBayesian models mobile-robot navigation. Proceedings IEEE/RSJ InternationalConference Intelligent Robots Systems.DeGroot, M. H. (1986). Probability Statistics (2nd edition). Addison-Wesley.Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood incompletedata via EM algorithm. Journal Royal Statistical Society, 39 (1), 1{38.Dissanayake, G., Newman, P., Clark, S., Durrant-Whyte, H. F., & Csorba, M. (2001). solutionsimultaneous localization map building (SLAM) problem. IEEE TransactionsRobotics Automation, 17 (3).Duda, R. O., & Hart, P. E. (1973). Unsupervised Learning Clustering, chap. 6. John WileySons.Elfes, A. (1989). Using occupancy grids mobile robot perception navigation. Computer,Special Issue Autonomous Intelligent Machines, 22 (6), 46{57.Engelson, S. P., & McDermott, D. V. (1992). Error correction mobile robot map learning.Proceedings IEEE International Conference Robotics Automation, pp.2555{2560, Nice, France.Gold, E. M. (1978). Complexity automaton identification given data. InformationControl, 37, 302{320.Gumbel, E. G., Greenwood, J. A., & Durand, D. (1953). circular normal distribution:Theory tables. American Statistical Society Journal, 48, 131{152.Hopcroft, J. E., & Ullman, J. D. (1979). Introduction Automata Theory, Languages,Computation. Addison & Wesley.204fiLearning Geometrically-Constrained HMMsJuang, B. H. (1985). Maximum likelihood estimation mixture multivariate stochastic observations Markov chains. AT&T Technical Journal, 64 (6).Juang, B. H., & Rabiner, L. R. (1985). probabilistic distance measure hidden Markovmodels. AT&T Technical Journal, 64 (2), 391{408.Koenig, S., & Simmons, R. G. (1996a). Passive distance learning robot navigation.Proceedings Thirteenth International Conference Machine Learning, pp. 266{274.Koenig, S., & Simmons, R. G. (1996b). Unsupervised learning probabilistic models robotnavigation. Proceedings IEEE International Conference Robotics Automation.Kuipers, B., & Byun, Y.-T. (1991). robot exploration mapping strategy based semantic hierarchy spatial representations. Journal Robotics Autonomous Systems,8, 47{63.Kullback, S., & Leibler, R. A. (1951). information suciency. Annals MathematicalStatistics, 22 (1), 79{86.Leonard, J., Durrant-Whyte, H. F., & Cox, I. J. (1991). Dynamic map building autonomous mobile robot. Iyengar, S. S., & Elfes, A. (Eds.), Autonomous Mobile Robots,pp. 331{338. IEEE Computer Society Press.Leonard, J. J., & Feder, H. J. S. (2000). computationally ecient method large-scale concurrent mapping localization. Hollerbach, J., & Kodischek, D. (Eds.), ProceedingsNinth International Symposium Robotics Research.Liporace, L. A. (1982). Maximum likelihood estimation multivariate observations Markovsources. IEEE Transactions Information Theory, 28 (5).Mardia, K. V. (1972). Statistics Directional Data. Academic Press.Mataric, M. J. (1990). distributed model mobile robot environment-learning navigation. Master's thesis, MIT, Artificial Intelligence Laboratory.McLachlan, G. J., & Krishnan, T. (1997). EM Algorithm Extensions. John Wiley &Sons.Moravec, H. P. (1988). Sensor fusion certainty grids mobile robots. AI Magazine, 9 (2),61{74.Moravec, H. P., & Elfes, A. (1985). High resolution maps wide angle sonar. ProceedingsInternational Conference Robotics Automation, pp. 116{121.Nourbakhsh, I., Powers, R., & Birchfield, S. (1995). Dervish: oce-navigating robot. AIMagazine, 16 (1), 53{60.Pierce, D., & Kuipers, B. (1997). Map learning uninterpreted sensors effectors. Artificial Intelligence, 92 (1-2), 169{227.205fiShatkay & KaelblingRabiner, L. R. (1989). tutorial hidden Markov models selected applications speechrecognition. Proceedings IEEE, 77 (2), 257{285.Rivest, R. L., & Schapire, R. E. (1987). Diversity based inference finite automata.Proceedings IEEE Twenty Eighth Annual Symposium Foundations ComputerScience, pp. 78{87, Los Angeles, California.Rivest, R. L., & Schapire, R. E. (1989). Inference finite automata using homing sequences.Proceedings Twenty First Annual Symposium Theory Computing, pp. 411{420,Seattle, Washington.Ron, D., Singer, Y., & Tishbi, N. (1994). Learning probabilistic automata variable memory length. Proceedings Seventh Annual Workshop Computational LearningTheory, pp. 35{46.Ron, D., Singer, Y., & Tishbi, N. (1995). learnability usage acyclic probabilisticfinite automata. Proceedings Eighth Annual Workshop Computational LearningTheory, pp. 31{40.Ron, D., Singer, Y., & Tishby, N. (1998). learnability usage acyclic probabilisticfinite automata. Journal Computer Systems Science, 56 (2).Shatkay, H. (1999). Learning Models Robot Navigation. Ph.D. thesis, Department Computer Science, Brown University, Providence, RI.Shatkay, H., & Kaelbling, L. P. (1997). Learning topological maps weak local odometricinformation. Proceedings Fifteenth International Joint Conference ArtificialIntelligence, Nagoya, Japan.Shatkay, H., & Kaelbling, L. P. (1998). Heading right direction. ProceedingsFifteenth International Conference Machine Learning, Madison, Wisconsin.Simmons, R. G., & Koenig, S. (1995). Probabilistic navigation partially observable environments. Proceedings International Joint Conference Artificial Intelligence.Smith, R., Self, M., & Cheeseman, P. (1991). stochastic map uncertain spatial relationships. Iyengar, S. S., & Elfes, A. (Eds.), Autonomous Mobile Robots, pp. 323{330. IEEEComputer Society Press.Thrun, S. (1999). Learning metric-topological maps indoor mobile robot navigation. AIJournal, 1, 21{71.Thrun, S., & Bucken, A. (1996a). Integrating grid-based topological maps mobile robotnavigation. Proceedings Thirteenth National Conference Artificial Intelligence,pp. 944{950.Thrun, S., & Bucken, A. (1996b). Learning maps indoor mobile robot navigation. Tech. rep.CMU-CS-96-121, School Computer Science, Carnegie Mellon University, Pittsburgh,PA.Thrun, S., Burgard, W., & Fox, D. (1998a). probabilistic approach concurrent map acquisition localization mobile robots. Machine Learning, 31, 29{53.206fiLearning Geometrically-Constrained HMMsThrun, S., Gutmann, J.-S., Fox, D., Burgard, W., & Kuipers, B. J. (1998b). Integrating topological metric maps mobile robot navigation: statistical approach. ProceedingsFifteenth National Conference Artificial Intelligence, pp. 989{995.Vapnik, V. N. (1995). Nature Statistical Learning Theory. Springer.207fiJournal Artificial Intelligence Research 16 (2002) 389-423Submitted 2/02; published 6/02Communicative Multiagent Team Decision Problem:Analyzing Teamwork Theories ModelsDavid V. PynadathMilind TambeInformation Sciences Institute Computer Science Departmentpynadath@isi.edutambe@usc.eduUniversity Southern California4676 Admiralty Way, Marina del Rey, CA 90292 USAAbstractDespite significant progress multiagent teamwork, existing research address optimality prescriptions complexity teamwork problem. Without characterization optimality-complexity tradeoffs, impossible determinewhether assumptions approximations made particular theory gain enougheciency justify losses overall performance. provide tool use multiagent researchers evaluating tradeoff, present unified framework, COMmunicative Multiagent Team Decision Problem (COM-MTDP). COM-MTDP modelcombines extends existing multiagent theories, decentralized partially observable Markov decision processes economic team theory. addition generalityrepresentation, COM-MTDPs also support analysis optimality teamperformance computational complexity agents' decision problem. analyzing complexity, present breakdown computational complexity constructingoptimal teams various classes problem domains, along dimensions observability communication cost. analyzing optimality, exploit COM-MTDP'sability encode existing teamwork theories models encode two instantiationsjoint intentions theory taken literature. Furthermore, COM-MTDP modelprovides basis development novel team coordination algorithms. derivedomain-independent criterion optimal communication provide comparative analysis two joint intentions instantiations respect optimal policy.implemented reusable, domain-independent software package based COM-MTDPsanalyze teamwork coordination strategies, demonstrate use encodingevaluating two joint intentions strategies within example domain.1. Introductioncentral challenge control coordination distributed agents enablingwork together, team, toward common goal. teamwork critical vastrange domains|for future teams orbiting spacecraft, sensors tracking targets, unmanned vehicles urban battlefields, software agents assisting organizations rapidcrisis response, etc. Research teamwork theory built foundations successfulpractical agent team implementations domains. forefront theories basedbelief-desire-intentions (BDI) frameworks, joint intentions (Cohen & Levesque,1991b, 1991a; Levesque, Cohen, & Nunes, 1990), SharedPlans (Grosz, 1996; Grosz & Kraus,1996; Grosz & Sidner, 1990), others (Sonenberg, Tidhar, Werner, Kinny, Ljungberg,& Rao, 1994; Dunin-Keplicz & Verbrugge, 1996), provided prescriptions co c 2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiPynadath & Tambeordination practical systems. theories inspired construction practical, domain-independent teamwork models architectures (Jennings, 1995; Pynadath,Tambe, Chauvat, & Cavedon, 1999; Rich & Sidner, 1997; Tambe, 1997; Yen, Yin, Ioerger,Miller, Xu, & Volz, 2001), successfully applied range complex domains.Yet, two key shortcomings limit scalability BDI-based theories implementations. First, techniques quantitative evaluation degreeoptimality coordination behavior. optimal teamwork may impracticalreal-world domains, analysis would aid us comparison different theories/modelsidentifying feasible improvements. One key reason diculty quantitativeevaluation existing teamwork theories ignore various uncertainties costs real-world environments. instance, joint intentions theory (Cohen &Levesque, 1991b) prescribes team members attain mutual beliefs key circumstances,ignores cost attaining mutual belief (e.g., via communication). Implementations blindly follow prescriptions could engage highly suboptimal coordination.hand, practical systems addressed costs uncertainties real-worldenvironments. instance, STEAM (Tambe, 1997; Tambe & Zhang, 1998) extends jointintentions decision-theoretic communication selectivity. Unfortunately, pragmatism approaches often necessarily leads lack theoretical rigor, remainsunanswered whether STEAM's selectivity best agent do, whether evennecessary all. second key shortcoming existing teamwork research lackcharacterization computational complexity various aspects teamwork decisions. Understanding computational advantages practical coordination prescriptioncould potentially justify use prescription approximation optimalityparticular domains.address shortcomings, propose new complementary framework, COMmunicative Multiagent Team Decision Problem (COM-MTDP), inspired work economic team theory (Marschak & Radner, 1971; Yoshikawa, 1978; Ho, 1980).COM-MTDP model borrows theory developed another field, make severalcontributions applying extending original theory, notably adding explicitmodels communication system dynamics. extensions, COM-MTDPgeneralizes recently developed multiagent decision frameworks, decentralizedPOMDPs (Bernstein, Zilberstein, & Immerman, 2000).definition team (like economic team theory) assumes teammembers common goal work sel essly towards goal (i.e.,private goals own). terms decision-theoretic framework,assume team members share joint utility function|that is,team member's individual preferences exactly preferences members and,thus, team whole. definition may appear \bare-bones" definitionteam, since include common concepts assumptions literatureconstitutes team (e.g., teammates form joint commitment (Cohen & Levesque,1991b), attain mutual belief upon termination joint goal, intend teammates succeed tasks (Grosz & Kraus, 1996), etc.). COM-MTDP perspective,view concepts intermediate concepts, means agents improveteam's overall performance, rather ends themselves. hypothesisinvestigation COM-MTDP-based analysis provide concrete justifications390fiThe Communicative Multiagent Team Decision Problemconcepts. example, mutual belief inherent value, COM-MTDPmodel quantify improved performance would expect teamattains mutual belief important aspects execution.generally, paper demonstrates three new types teamwork analyses madepossible COM-MTDP model. First, analyze computational complexityteamwork within subclasses problem domains. instance, researchers advocated teamwork without communication (Goldberg & Mataric, 1997). use COMMTDP model show that, general, problem constructing optimal teams withoutcommunication NEXP-complete, allowing free communication reduces problemPSPACE-complete. paper presents breakdown complexity optimalteamwork problem domains classified along dimensions observability communication cost.Second, COM-MTDP model provides powerful tool comparing optimalitydifferent coordination prescriptions across classes domains. Indeed, illustrateencode existing team coordination strategies within COM-MTDP evaluation.analysis, selected two joint intentions-based approaches literature: oneusing approach realized within GRATE* joint responsibility model (Jennings,1995), another based STEAM (Tambe, 1997). encoding, deriveconditions team coordination strategies generate optimal team behavior,complexity decision problems addressed them. Furthermore, alsoderive novel team coordination algorithm outperforms existing strategiesoptimality, though eciency. end result well-grounded characterizationcomplexity-optimality tradeoff among various means team coordination.Third, use COM-MTDP model empirically analyze specific domaininterest. implemented reusable, domain-independent algorithms allow oneevaluate optimality behavior generated different prescriptive policies withinproblem domain represented COM-MTDP. apply algorithms exampledomain empirically evaluate aforementioned team coordination strategies, characterizing optimality strategy function properties underlyingdomain. instance, Jennings reports experimental results (Jennings, 1995) indicatingjoint responsibility teamwork model leads lower waste community effortcompeting methods accomplishing teamwork. COM-MTDP model,able demonstrate benefits Jennings' approach many configurations example domain. However, precisely characterizing types domains showedbenefits, also identified domains competing methods may actually performbetter. addition, use COM-MTDP model re-create explain previouswork noted instance suboptimality STEAM-based, real-world implementation (Tambe, 1997). previous work treated suboptimality anomalous,COM-MTDP re-evaluation domain demonstrated observed suboptimalitysymptom STEAM's general propensity towards extraneous communicationsignificant range domain types. algorithms example domain modelavailable public use Online Appendix 1.Section 2 presents COM-MTDP model's representation places contextrelated multiagent models literature. Section 3 uses COM-MTDP modeldefine characterize complexity designing optimal agent teams. Section 4 analyzes391fiPynadath & Tambeoptimality existing team coordination algorithms derives novel coordinationalgorithm. Section 5 presents empirical results applying COM-MTDP algorithmsexample domain. Section 6 summarizes results, Section 7 identifiespromising future directions.2. COM-MTDP Modelsection defines describes COM-MTDP model ability representimportant aspects multiagent teamwork. begin Section 2.1 definingunderlying multiagent team decision problem explicit communication. Section 2.2defines complete COM-MTDP model extension explicitly represent communication. Section 2.3 provides illustration COM-MTDP model representsexecution team agents. Finally, Section 2.4 describes related models multiagentcoordination shows COM-MTDP model generalizes them.2.1 Multiagent Team Decision ProblemsGiven team sel ess agents, ff, intend perform joint task, wish evaluatepossible policies behavior. represent multiagent team decision problem (MTDP)model tuple, hS; Aff; P;ff ; ; Bff ; Ri. taken underlying componentsmodel initial team decision model (Ho, 1980), extendedhandle dynamic decisions time easily represent multiagent domains (inparticular, agent beliefs). assume model common knowledgeteam members. words, agents believe model, believebelieve model, etc.2.1.1 World States:= 1 m: set world states, expressed factored representation (across product separate features).state world state team's environment (e.g., terrain, locationenemy). Thus, represents domain individual feature environment,represents domain possible combinations values individualfeatures.2.1.2 Domain-Level Actions:AfffAi gi2ff set actions agent perform change environment, implicitlydefining set combined actions, Aff Qi2ff Ai (corresponding team theory's decisionvariables).Extension Dynamic Problem: P original team decision problem focusedone-shot, static problem. extend original concept componenttime series random variables. effects domain-level actions (e.g., ying actionchanges helicopter's position) obey probabilistic distribution, given function P :Aff ! [0; 1]. words, initial state time t, combined action392fiThe Communicative Multiagent Team Decision Problemtaken time t, final state s0 time + 1, Pr(S t+1 = s0jS = s; Atff = a) = P (s; a; s0).given definition P assumes world dynamics obey Markov assumption.2.1.3 Agent Observations:fffigi2ff set observations agent, i, experience world, implicitlydefining combined observation,ff Qi2ffi.may include elements correspondingindirect evidence state (e.g., sensor readings) actions agents (e.g.,movement helicopters). original team-theoretic framework, informationstructure represented observation process agents set deterministicfunctions, Oi : !i.Extension Allowable Information Structures: extend informationstructure representation allow uncertain observations. use general stochasticmodel, borrowed partially observable Markov decision process model (Smallwood &Sondik, 1973), joint observation function: (s; a; !) = Pr(tff = !jS = s; Atff 1 =a). function models sensors, representing errors, noise, etc. cases,Qseparate joint distribution individual observation functions: i2ff Oi ,Oi (s; a; !) = Pr(ti = !jS = s; Atff 1 = a). Thus, probability distributionspecified forms richer information structure used model. makeuseful distinctions different classes information structures:Collective Partial Observability general case, make assumptions observations.Collective Observability unique world state fort combined observationsteam: 8! 2ff, 9s 2 8s0 6= s, Pr(ff = !jS = s0) = 0. setdomains collectively observable strict subset domainscollectively partially observable.Individual Observability unique world state individual agent's observations: 8! 2i, 9s 2 8s0 6= s, Pr(ti = !jS = s0) = 0. setdomains individually observable strict subset domainscollectively observable.Non-Observability agents receive feedback world: 9! 2i,8s 2 8a 2 Aff , Pr(ti = !jS = s; Atff 1 = a) = 1. assumption holdsopen-loop systems, come frequent consideration classical planning (Boutilier, Dean, & Hanks, 1999).2.1.4 Policy (Strategy) SpaceiA domain-level policy (or strategy, original team theory specification) mapagent's belief state action. original formalism, agent's beliefs corresponddirectly observations (i.e., iA :! Ai).Extension Richer Belief State Space: Bff generalize set possible strategies capture complex mental states agents. agent, 2 ff, formsbelief state, bti 2 Bi, based observations seen time t, Bi circumscribes393fiPynadath & Tambeset possible belief states agent. Thus, define set possible domainlevel policies mappings belief states actions, iA : QBi ! Ai . define setpossible combinedt belief states agents Bff i2ff Bi. correspondingrandom variable, bff, represents agents' combined belief state time t. elaboratedifferent types belief states mapping observations belief states (i.e.,state estimator function) Section 2.2.1.2.1.5 Reward Function:Rcommon reward function central notion teamwork MTDP: R : Aff !R. function represents team's joint preferences states cost domainlevel actions (e.g., destroying enemy good, returning home base 10%original force bad). assume that, sel ess team members, agent sharespreferences individual level well. Therefore, team member wants exactlybest team whole.2.2 Extension Explicit Communication: ffmake explicit separation domain-level actions (Aff) communicativeactions. defined section, communicative actions affect receiving agents' individual belief states, but, unlike domain-level actions, directly change worldstate. Although distinction sometimes blurry real-world domains, makeexplicit separation isolate, much possible, effects two typesactions. leverage gained separation provides basis informative,analytical results presented rest paper. capture separation, extendinitial MTDP model communicative multiagent team decision problem (COMMTDP), define tuple, hS; Aff; ff ; P;ff; Off; B ff; Ri, new component,ff, extended reward function, R.2.2.1 Communication: fffigi2ff set possible messages agent, implicitly defining set combinedcommunications, ff Qi2ff i. agent, i, may communicate message x 2teammates, interpret communication updating belief states response.first step work, assume agents receive messages instantaneouslycorrectly (i.e., lag noise communication channels). modelcommon knowledge among team members, agent sent message,knows team members received message, team members knowknows received message, on.communication, divide decision epoch two phases: pre-communication post-communication phases, denoted subscripts , respectively.particular, agents update belief states two distinct points within decision epoch: upon receiving observationti (producing pre-communication belief state bti ), upon receiving agents' messages (producing postcommunication belief state bti). distinction allows us differentiate beliefstate used agents selecting communication actions \up-to-date"belief state used selecting domain-level actions. also distinguish394fiThe Communicative Multiagent Team Decision Problemseparate state-estimator functions used update phase:b0i =SEi0 ()(1)1bi =SEi (bi ;)(2)bi =SEi (bi ; ff )(3)SEi : Bi! Bi pre-communication state estimator agent i,SEi : Bi ff ! Bi post-communication state estimator agent i. initialstate estimator, SEi0 : ; ! Bi, specifies agent's prior beliefs, observationsmade. these, also make obvious definitions correspondingestimators combined belief states: SE ff, SE ff, SE 0ff.paper, first step, assume agents perfect recall.words, agents recall observations, well communicationagents. Thus, belief states representtheir entire histories sequences observations received messages: Bi =ff, X denotes set possiblesequences (of length) elements X . agents realize perfect recallfollowing state estimator functions:SEi0 () = hi(4)0 0 ff1 1 ffffSEi (; ff ; : : : ;; ff;)0 0 ff1 1 ffffff=; ffff ; : : :;; ffff;iffff;(5)0011SEi (; ff ; : : : ;; ff ;; ; ff )=0i ; 0ffff ; : : : ;ti ; tffffff(6)words, SEi0 initializes agent i's belief state empty history, SEi appendsnew observation agent i's belief state, SEi appends new messages agent i's beliefstate. paper's assumptions perfect recall, three state-estimator functionstake constant time. However, potentially allow complex functions (thoughcomplexity results presented hold state-estimator functions take polynomialtime). instance, although assume perfect, synchronous, instantaneous communication here, could potentially use post-communication state estimator modelnoise, temporal delays, asynchrony, cognitive burden, etc. present communicationchannel.extend definition policy behavior include communication policy,: Bi ! , analogous Section 2.1.4's domain-level policy. define joint policies,ff ffA , combined policies across agents ff.2.2.2 Extended Reward Function:Rextend team's reward function also represent cost communicative acts (e.g.,communication channels may associated cost): R : Aff ff ! R. assumecost communication domain-level actions independent other,decompose reward function two components: communication-level reward,R : ff ! R, domain-level reward, RA : Aff ! R. total rewardsum two component values: R(s; a; ) = RA(s; a) + R(s; ). assume395fiPynadath & Tambecommunication inherent benefit may instead cost,states, 2 , messages, 2 ff , reward never positive: R(s; ) 0. However,although assign communication explicit value, significant implicit valueeffect agents' belief states and, subsequently, future actions.observability function, parameterize communication costs associatedmessage transmissions:General Communication: make assumptions communication.Free Communication: R(s; ) = 0 2 ff, 2 . words,communication actions effect agents' reward.communication: ff = ;, i.e., explicit communication. Alternatively, communication may prohibitively expensive, 8 2 ff , 2 , R(s; ) = 1.free-communication case appears literature, researchers wish focusissues communication cost. Although, real-world domains rarely exhibitideal conditions, may able model domains approximately freecommunication sucient degree. addition, analyzing extreme case gives usunderstanding benefit communication, even results apply acrossdomains. also identify no-communication case decision problemsinterest researchers well (Goldberg & Mataric, 1997). course, even ff = ;,possible domain-level actions Aff implicit communicativevalue acting signals convey information agents. However, stilllabel agent teams communication purposes work here, sincemany results exploit explicit separation domain- communication-levelactions.2.3 Model Illustrationview evolving state Markov chain separate stages domain-levelcommunication-level actions. words, agent team member, 2 ff beginsinitial state, 0, initial belief states, b0i = SEi0 (). agent receivesobservation0i drawn according probability distribution (S 0; null;0ff) (thereactions yet). Then, agent updates belief state, b0i = SEi (b0i ;0i ).Next, agent 2 ff selects message according communication policy, 0i =(b0i ), defining combined communication, 0ff . agent interprets communications others updating belief state, b0i = SEi (b0i ; 0ff ).selects actionaccordingdomain-levelpolicy,A0i = iA(b0i ), definingcombined action A0ff . central assumption teamwork, agent receivesjoint reward, R0 = R(S 0 ; A0ff ; 0ff). world moves new state, 1 ,according distribution, P (S 0 ; A0ff ). Again, agent receives observation1idrawnaccording distribution (S 1 ; A0ff ;1ff), updates belief state,b1i = SEi (b0i ;1i ).process continues, agents choosing communication- domain-level actions,observing effects, updating beliefs. Thus, addition time series worldstates, 0; 1 ; : : : ; , agents determine time series communication-level396fiThe Communicative Multiagent Team Decision Problemdomain-level actions, 0ff ; 1ff ; : : : ; tff A1ff; A1ff ; : : : ; Atff , respectively. alsotime series observations agent i,0i ;1i ; : : : ;ti. Likewise, treatcombined observations,0ff ;1ff; : : : ;tff, similar time series random variables.Finally, agents receive series rewards, R0; R1 ; : : : ; Rt. define value,V , policies, ffA ff , expected reward received executingpolicies. finite horizon, , value equivalent following:VT(ffA; ff ) = E"Xt=0fifiRt fififi#ffA ; ff(7)2.4 Related WorkCOM-MTDP model subsumes many existing multiagent models, presented Table 1 (i.e., map instance models corresponding COM-MTDP).generality enables us perform novel analyses real-world teamwork domains,demonstrated Section 4's use COM-MTDP model analyzing optimalitycommunication decisions.2.4.1 Decentralized POMDPsmodel observability world dynamics, COM-MTDP model closely parallels structure decentralized partially observable Markov decision process (DECPOMDP) (Bernstein et al., 2000). Following notational conventions, DEC-POMDPtuple, hS; Aff ; P;ff; ; Ri. set possible messages, ff, DECPOMDP falls class domains communication. DEC-POMDP observational model, O, general enough capture collectively partially observable domains.2.4.2 Partially Observable Identical Payoff Stochastic GamesStochastic games provide rich framework multiagent decision making agentsmay individual goals preferences. identical payoff stochastic game(IPSG) restricts agents share single payoff function, appropriate modelingsingle, global reward function team context. partially observable IPSG(POIPSG) (Peshkin, Kim, Meuleau, & Kaelbling, 2000) tuple, hS; Aff ; P;ff; Off; Ri,similar DEC-POMDP model. words, observation function, ,general enough support collectively partially observable domains, communication.2.4.3 Multiagent MDPsAnother relevant model multiagent Markov decision process (MMDP) (Boutilier,1996), tuple, hS; Aff; P; Ri, notation. Like DEC-POMDP, MMDPcommunication. addition, MMDP multiagent extension completelyobservable MDP model, assumes environment individually observable.397fiPynadath & TambeModelffDEC-POMDP communication collective partial observabilityPOIPSGcommunication collective partial observabilityMMDPcommunicationindividual observabilityXuan-Lesser general communicationcollective observabilityTable 1: Existing models COM-MTDP subsets.2.4.4 Xuan-Lesser FrameworkCOM-MTDP's separation communication actions similar previouswork multiagent decision models (Xuan, Lesser, & Zilberstein, 2001), supportedgeneral communication. However, Xuan-Lesser model generalizes beyond individually observable environments, supports subset collectively observable environments. particular, Xuan-Lesser framework cannot represent agents receivelocal observations common world state, observations different agents couldpotentially interdependent.3. COM-MTDP Complexity Analysisuse COM-MTDP model prove results complexity constructing optimal agent teams (i.e., teams coordinate produce optimal behaviorproblem domain). problem facing agents (or designer agents)construct joint policies, ff ffA, maximize joint reward,represented expected value, V (ffA; ff). results presented,assume values model instance (e.g., transition probabilities, rewards)rational numbers, express particular instance finite-sized input.Theorem 1 decision problem whether exist policies, ff ffA , givenCOM-MTDP, general communication collective partial observability, yieldtotal reward least K finite horizon NEXP-complete jffj 2 (i.e.,one agent).Proof: prove COM-MTDP decision problem NEXP-hard, reduce DECPOMDP (Bernstein et al., 2000) COM-MTDP communication copyingmodel featuresgiven DEC-POMDP.words,ffgiven DEC-POMDP, S; fA gi=1; P; fgi=1 ; O; R , construct COM-MTDP,hS 0 ; fA0i gmi=1 ; 0ff; P 0 ; f0igmi=1 ; O0ff; B 0ff; R0 i, follows:S0 =A0i = Ai0 = ;P 0 (s; ha1 ; : : : ; ; s0 ) = P (s0 js; a1 ; : : : ; )398fiThe Communicative Multiagent Team Decision Problem0i =O0ff (s; ha1 ; : : : ; ; h!1 ; : : : ; !m i) = O(!1 ; : : : ; !m ja1 ; : : : ; ; s)Bi0 = [Tj=1()j(i.e., observation sequences length finite horizon)R0 (s; ha1 ; : : : ; ; ) = R(s; a1 ; : : : ; )DEC-POMDP assumes perfect recall, use state estimator functionsEquations 5 6. Since communication COM-MTDP, fixedsilent policy, ff. translate domain-level policy, ffA, DEC-POMDPjoint policy, , follows:ff(oi1 ; : : : ; oit ) iA ( oi1 ; : : : ; oit )(8)expected utility following joint policy, , within DEC-POMDP identicalfollowing ff ffA within constructed COM-MTDP. Thus, existspolicy expected utility greater K COM-MTDPexists one DEC-POMDP. decision problem DEC-POMDP knownNEXP-complete, COM-MTDP problem must NEXP-hard.show COM-MTDP NEXP, proof proceeds similarlyDEC-POMDP. words, guess joint policy, ff , writeexponential time (we assume jS j). take COM-MTDP plus policygenerate (in exponential time) corresponding MDP state space spacepossible combined belief states agents. use dynamic programmingdetermine (in exponential time) whether ff generates expected reward least K .2remainder section, examine effect communication complexity constructing team policies generate optimal behavior. start examiningcase condition free communication, would expect benefitcommunication greatest. begin with, suppose agent capablecommunicating entire observation (i.e.,i). analyze complexityteam decision problem, first prove agents exploit capabilitycommunicate true observation, long incur cost so:Theorem 2 free communication, consider team agents using communicationpolicy: (bti )ti . domain-level policy ffA maximizes V (ffA ; ff ),combined policy dominant policies. words, policies, 0ffA0ff , V ( ffA ; ff ) V ( 0ffA ; 0ff ).Proof: Suppose communication policy, 0ff, specifies somethingcomplete communication (e.g., keeping quiet, lying). Supposedomain-level policy, 0ffA , allows team attain expected reward, K ,used combination 0ff. Then, construct domain-level policy, ffA ,team attains expected reward, K , used conjunctioncomplete-communication policy, ff , defined statement Theorem 2.Thet communication policy, 0ff, produces different set belief states (denoted b0 tib0i) ff (denoted bti bti ). particular, use state estimator399fiPynadath & Tambefunctions, SEi0 SEi0 defined Equations 5 6 generate b0ti b0ti .belief state complete history observation communication pairsagent. hand, complete communication ff, state estimatorfunctions Equations 5 6 reduce to:ffffSEi (0ff ; : : : ;tff 1 ;ti ) =0ff ; : : : ;tff 1 ;ti(9)0ffffSEi (ff ; : : : ;tff 1 ;ti ; tff ) =0ff ; : : : ;tff 1 ; tff=0ff ; : : : ;tff 1;tff ff(10)Thus, ffA defined different set belief states 0ffA . order determineequivalent ffA, must first define recursive mapping, m, translates beliefstates defined ff defined 0ff :ffffffmi (bti ) =mi bti1 ;tff = mi bti1 ;ti ;tff**++EE= mi(bti1 );ti ; 0ff = mi(bti1 );ti; 0j=*(mi bti1*);ti;j 2ffj 2ff(( (j0 SEj0 mj btj 1);tj ))++(11)Given mapping, specify: iA(bti) = iA0 (mi(bti )). Executing domainlevel policy, conjunction communication policy, ff , results identicalbehavior execution alternate policies, 0ffA 0ff . Therefore, team followingpolicies, ffA ff achieve expected value K , 0ffA0ff . 2Given dominance complete-communication policy, proveproblem constructing teams coordinate optimally simpler communicationfree.Theorem 3 decision problem determining whether exist policies, ffffA , given COM-MTDP free communication collective partial observability, yield total reward least K finite horizon PSPACE-complete.Proof: prove problem PSPACE-hard, reduce single-agent POMDPCOM-MTDP. particular, given POMDP, hS; A; P;; O; Ri, constructCOM-MTDP, hS 0 ; A01 ; 01; P 0 ;01; O10 ; B10 ; R0 i, single-agent team (i.e., ff = f1g):S0 =A01 =01 = ;P 0 (s; ha1 ; s0 ) = P (s; a1 ; s0 )01 =400fiThe Communicative Multiagent Team Decision ProblemO10 (s; ha1 ; h!1 i) = O(s; a1 ; !1 )B10 =[Tj=1()j(i.e., observation sequences length finite horizon)RA0 (s; ha1 i) = R(s; a1 )R0 (s; ) =0COM-MTDP satisfies assumption free communication. POMDP assumesperfect recall, use state estimator functions Equations 5 6.proof Theorem 1, show exists policy expected utility greaterK COM-MTDP exists one POMDP. decisionproblem POMDP known PSPACE-hard (Papadimitriou & Tsitsiklis, 1987),COM-MTDP problem free communication must PSPACE-hard.show problem PSPACE, take COM-MTDP free communication reduce single-agent POMDP. particular, given COM-MTDP,hS; Aff; ff ; P;ff; Off; B ff; Ri, construct single-agent POMDP, hS 0; A0 ; P 0 ;0; O0 ;R0 i, follows:S0 =0 = AffP 0 (s; a; s0 ) = P (s; a; s0 )0 =ffO0 (s; a; ! ) = (s; a; ! )R0 (s; a) = RA (s; a)Theorem 2, need consider complete-communication policyCOM-MTDP policy zero reward. Therefore, decision problemCOM-MTDP simply find domain-level policy produces expected rewardexceeding K . Given full communication, state estimator functions COM-MTDP(as shown proof Theorem 2) reduce Equation 10. policy POMDPspecifies action every history observations: 0 : [Tj=1(0 )j ! A0 .history observations single-agent POMDP corresponds belief statesCOM-MTDP full communication. Therefore, translate POMDP-policy, 0 ,equivalent domain-level policy COM-MTDP:(h! 0 ; ! 1 ; : : : ; ! i) 0 (h! 0 ; ! 1 ; : : : ; ! i)(12)team following perform exact domain-level actions single agentfollowing 0 . Thus, exists policy expected utility greater K COMMTDP exists one POMDP. decision problem POMDPknown PSPACE (Papadimitriou & Tsitsiklis, 1987), COM-MTDP problem(under free communication) must PSPACE well. 2401fiPynadath & TambeTheorem 4decision problem determining whether exist policies, ffffA , given COM-MTDP free communication collective observability,yield total reward least K finite horizon P-complete.Proof: proof follows Theorem 3, reduction MDPdecision problem, rather POMDP. MDP decision problem P-complete (Papadimitriou & Tsitsiklis, 1987). 2Theorem 5 decision problem determining whether exist policies, ffffA , given COM-MTDP individual observability, yield total rewardleast K finite horizon (given integers K ) P-complete.Proof: proof follows Theorem 4, except reduce problemMDP regardless communication policy team uses. 2Theorem 6 decision problem determining whether exist policies, ffffA , given COM-MTDP non-observability, yield total reward least Kfinite horizon (given integers K ) NP-complete.Proof: proof follows Theorem 4, except reduce problemsingle-agent non-observable MDP (NOMDP) regardless communicationpolicy team uses. particular, agents equally ignorant state,communication effect. NOMDP decision problem NP-complete (Papadimitriou & Tsitsiklis, 1987). 2Thus, used COM-MTDP framework characterize diculty problemdomains agent teamwork along dimensions communication cost observability.Table 2 summarizes results, use deciding concentrateenergies attacking teamwork problems. use results draw conclusionschallenges designers multiagent teams:greatest challenges lie domains either collective observabilitycollective partial observability nonzero communication cost.collective observability collective partial observability, teamwork withoutcommunication highly intractable, but, free communication, complexitybecomes par single-agent planning problems.Agent team designers much gain increasing observational capabilitiesteam (e.g., adding new sensor agents) reduction complexitygained making domain collectively observable.Furthermore, results Theorems 3 4 hold domain resultTheorem 2 holds (i.e., complete communication dominant policy).Therefore, perfectly free communication may rare, results showinvestment communication teamwork pay significant simplificationoptimal teamwork.402fiThe Communicative Multiagent Team Decision ProblemIndividually CollectivelyCollectivelyObservable Observable Partially ObservableComm. P-complete NEXP-complete NEXP-completeGeneral Comm. P-complete NEXP-complete NEXP-completeFree Comm. P-complete P-completePSPACE-completeNonObservableNP-CompleteNP-CompleteNP-CompleteTable 2: Time complexity COM-MTDPs.hand, world individually observable non-observable, com-munication makes difference performance.noted even conditions problem P-complete,complexity optimal teamwork polynomial number statesworld, may still impractically high.complexity results pertain finding policies optimal subjectdomain properties. find different expected rewards optimal policiesdifferent observability communication properties. instance, cuttingagents' sensors makes domain non-observable reduces complexitygenerating optimal policy NEXP NP, would expect associateddrop expected reward achieved team.4. Evaluating Team CoordinationTable 2 shows providing optimal domain-level communication policies teamsdicult challenge. Many systems alleviate diculty domain experts provide domain-level plans (Tambe, 1997; Tidhar, 1993). Then, problem agentsreduces generating appropriate team coordination, ff , ensure properly execute domain-level plans, ffA. section, demonstrate COM-MTDPframework's ability analyze existing teamwork approaches literature. methodology analysis begins encoding teamwork method communicationlevel policy. words, translate method algorithm maps agentbeliefs (e.g., observation sequences) communication decisions. evaluate performance policy, instantiate COM-MTDP represents states,transition probabilities, reward function domain interest. methodologyprovides evaluation policy terms expected reward earned teamfollowing policy specified domain.demonstrate methodology using COM-MTDP framework analyze jointintentions theory (Cohen & Levesque, 1991b, 1991a; Levesque et al., 1990), providescommon basis many existing approaches team coordination. Section 4.1 models twokey instantiations joint intentions taken literature (Jennings, 1995; Tambe, 1997)COM-MTDP communication policies. Section 4.2 analyzes conditionspolicies generate optimal behavior provides third candidate policy makescommunication decisions locally optimal within context joint intentions.403fiPynadath & Tambeaddition providing results particular team coordination strategies investigated,section also illustrates general methodology one use COM-MTDPframework encode evaluate coordination strategies proposed existing multiagentresearch.4.1 Joint Intentions COM-MTDPJoint intention theory provides prescriptive framework multiagent coordinationteam setting. make claims optimality teamwork, providestheoretical justifications prescriptions, grounded attainment mutual beliefamong team members. use COM-MTDP framework identify domainproperties attaining mutual belief generates optimal behavior quantifyprecisely suboptimal performance otherwise.Joint intentions theory requires team members jointly commit joint persistentgoal, G. also requires team member privately believes G achieved(or unachievable irrelevant), must attain mutual belief throughout teamachievement (or unachievability irrelevance). encode prescriptionjoint intentions theory within COM-MTDP model, first specify joint goal, G,subset states, G , desired goal achieved (or unachievable irrelevant).Presumably, prescription indicates joint intentions specifically intended individually observable environments. Upon achieving goal individuallyobservable environment, agent would simultaneously observe 2 G.assumption COM-MTDP model components (including Off) commonknowledge team, agent would also simultaneously come believe teammates observed 2 G, teammates believe believesteam members observed 2 G, on. Thus, team immediatelyattains mutual belief achievement goal individual observability withoutadditional communication necessary team.Instead, joint intention framework aims domains degree unobservability. domains, agents must signal agents, either communication informative domain-level action, attain mutual belief. However,also assume joint intention theory focus domains free communication,Theorem 2 shows simply agents communicate everything,time, without need complex prescriptions.joint intention framework specify precise communication policyattainment mutual belief. paper, focus communication casegoal achievement, methodology extends handle unachievability irrelevancewell. One well-known approach (Jennings, 1995) applied joint intentions theoryagents communicate achievement joint goal, G, soon believe Gtrue. instantiate behavior Jennings' agents within COM-MTDP, constructcommunication policy, Jff, specifies agent sends special message, G,first believes G holds. Following joint intentions' assumption sincerity (Smith &Cohen, 1996), require agents never select special G message beliefstate unless believe G true certainty. requirementassumption team's common knowledge communication model, assume404fiThe Communicative Multiagent Team Decision Problemagents immediately accept special message, G, true,agents know team members accept message true, on. Thus,team attains mutual belief G true immediately upon receiving message, G.construct communication policy, Jff , constant time.STEAM algorithm another instantiation joint intentions successseveral real-world domains (Tambe, 1997; Pynadath et al., 1999; Tambe, Pynadath, Chauvat, Das, & Kaminka, 2000; Pynadath & Tambe, 2002). Unlike Jennings' instantiation,STEAM teamwork model includes decision-theoretic communication selectivity. domainspecification includes two parameters joint commitment, G: , probabilitymiscoordinated termination G; Cmt , cost miscoordinated termination G.context, \miscoordinated termination" means agents immediately observeteam achieved G rest not. STEAM's domain specification alsoincludes third parameter, Cc, represent cost communication fact (e.g.,achievement G). Using parameters, STEAM algorithm evaluates whetherexpected cost miscoordination outweighs cost communication. STEAM expressescriterion following inequality: Cmt > Cc. define communicationpolicy, Sff based criterion: inequality holds, agent observedachievement G send message, G; otherwise, not. constructSff constant time.4.2 Locally Optimal PolicyAlthough STEAM policy selective Jennings', remains unansweredwhether optimally selective, researchers continue struggle questionagents communicate (Yen et al., 2001). reports suboptimal(in particular, excessive) communication STEAM characterized phenomenonexceptional circumstance, also possible STEAM's optimal performanceexception. use COM-MTDP model derive analytical characterization optimal communication here, Section 5 provides empirical one creating algorithmusing characterization.policies, Jff, Sff consider sending G agent first believesG achieved. agent relevant belief, make different choices,consider optimal decision point. domain individuallyobservable, certain agents may unaware achievement G. sendingG message, unaware agents may unnecessarily continue performing actionspursuit achieving G. performance extraneous actions could potentiallyincur costs lead lower utility one would expect sending G message.decision send G matters team achieves G one agentcomes know fact. define random variable, TG, earliest timeagent knows fact. denote agent KG agent knowsachievement time TG . KG = i, agent, i, TG = t0 , agentpre-communication belief state, bti0 = fi , indicates G achieved.precisely quantify difference agent sending G message time TG vs.405fiPynadath & Tambenever sending it, define following value:(t0; i; fi ) E"TX0t=0"TX0Efifi= G; TG = t0 ; KG =Rt0 +t fifi ti0fit=0fifiRt0 +t fifi ti0fii; bti0=fi#= null; TG = t0 ; KG = i; bti0 = fi#(13)assume that, times TG, agents follow communication policy,never specifies G. Thus, measures difference expected rewardhinges agent i's specific decision send send G time t0 . Given definition,locally optimal agent send special message, G, time t0,0. define communication policy, ff+ , communication policyfollowing ff agents times, except agent belief state fi ,agent sends message . definition, ff+G , policy agentcommunicates achievement G, ff+null policy not.Therefore, alternatively describe agent i's decision criterion choosing ff+Gff+null 0.Unfortunately, Equation 13 identifies exact criterion locally optimal communication, criterion yet operational. words, directly implementcommunication policy agents. Furthermore, Equation 13 hides underlying complexity computation involved, one key goals analysis.Therefore, use COM-MTDP model derive operational expression 0.simplicity, define notational shorthand various sequences combinationsvalues. define partial sequence random variables, X <t , sequence random variables times t: X 0 , X 1 , : : : , X 1 . make similar definitions>t , X , etc.). expression, (S )T , denotes crossrelational operators (i.e., XQproduct states world, Tt=0 , distinguished time-indexed randomvariable, , denotes value state time . notation, st0 [t], specifieselement slot within vector st0 . define function, , shorthand withinprobability expressions. allows us compactly represent particular subsequenceworld agent belief states occurring, conditioned current situation, follows:fiPrt; t0ff ; s; fi Pr(S t;t0 = s; bff t;t0 = fi fiTG = t0 ; KG = i; bti0 = fi )(14)Informally, (ht; t0i ; s; fi ) represents event world belief states timet0 correspond specified sequences, fi , respectively, conditionedagent first know G's achievement time t0 belief state, fi . definefunction, fi, map pre-communication belief state post-communicationbelief state arises communication policy:fi (fi ; ff ) SE ff (fi ; ff (fi ))(15)definition fi well-defined function deterministic naturepolicy, ff, state-estimator function, SE ff .ff ,406fiThe Communicative Multiagent Team Decision ProblemTheorem 7assume that, upon achievement G, communication Gpossible, condition (t0 ,i,fi ) 0 holds if:XXPr((h0; t0 ; st0 ; fit0 ))st0 2(S )t0 fi0 2B ff00B@XXfiPr (ht0 ; ; st0 ; fit0 ) fifiti0 = G ; (h0; t0 ; st0 ; fit0 )+1st0 2(S )T t0 +1 fi0 2B ff 0XRA st0 [t]; ffA fi fi t0 [t]; ff+Gt=t0fiXXPr (ht0 ; ; st0 ; fit0 ) fifiti0 = null; (h0; t0 ; st0 ; fit0 )+1st0 2(S )T t0 +1 fi0 2B ff 0!XRA st0 [t]; ffA fi fi 0 [t]; ff+nullt=t0X Xs2G fi2BffPr ((ht0 ; t0 ; s; fi)) R (s; G )(16)Proof: complete proof following theorem appears Online Appendix 1.definition Equation 13 difference two expectations,expectation sum possible trajectories agent team. trajectory mustincludes sequence possible world states, since agents' reward point timedepends particular state world time. agents' reward also dependsactions (both domain- communication-level). actions deterministic,given agents' policies, ffA , belief states. Thus, addition summingpossible states world, must also sum possible states agents'407fiPynadath & Tambebeliefs (both pre- post-communication):(t0; i; fi )XXX=Pr = sT ; b = fi ; b = fiTsT 2(S )T fi 2(B)T fi 2(B)Tjti0 = G; TG = t0; KG = i; bti0 = fiXXXXt=0sT 2(S )T fi 2(B)T fi 2(B)TR(sT [t]; (fi [t]); (fi [t]))Pr= sT ; b = fi ; bT = fiTjti0 = null; TG = t0; KG = i; bti0 = fiXt=0R(sT [t]; (fi [t]); (fi [t]))(17)rewrite summations simply using various shorthand notations:=XXsT 2(S )T fi 2(B)TPr((h0; ; s; fi )jti0 = G)XXXt=0sT 2(S )T fi 2(B)TR(sT [t]; (fi (fi [t]; G )); G (fi [t]))Pr((h0; ; s; fi )jti0 = null)Xt=0R(sT [t]; (fi (fi [t]; null)); null(fi [t]))(18)remaining derivation exploits Markovian assumptions rearrange summationscancel like terms produce theorem's result. 2Theorem 7 states, informally, prefer sending G whenever cost execution achieving G outweighs cost communication fact Gachieved. precisely, outer summations left-hand side inequalityiterate possible past histories world belief states, producing probabilitydistribution possible states team time t0. state,expression inside parentheses computes difference domain-level reward,possible future sequences world belief states, sending sending G.theorem's assumption communication G possible Gachieved, ignore communication costs future. However, relaxassumption, extend left-hand side straightforward manner longer408fiThe Communicative Multiagent Team Decision ProblemIndividuallyObservableComm.(1)General Comm.(1)Free Comm.(1)CollectivelyCollectivelyNonObservable Partially Observable Observable(1)(1)(1)O((jS j jff j) )O((jS j jff j) )(1)(1)(1)(1)Table 3: Time complexity locally optimal decision.expression accounts difference future communication costs well. Thus,left-hand side captures intuition that, communicating, team incurcost agents unaware G's achievement. right-hand sideinequality summation cost sending G message possible current statesbelief states.use Theorem 7 derive locally optimal communication decision acrossvarious classes problem domains. communication, cannot send G.free communication, right-hand side 0, inequality always true, knowprefer sending G. assumptions communication, determinationcomplicated. domain individually observable, left-hand side becomes0, agents know G achieved (and thus differenceexecution sending G). Therefore, inequality always false (unless freecommunication), prefer sending G . environment individuallyobservable communication available free, then, locally optimal timet0 , agent must evaluate Inequality 16 full complexity. Since inequality sumsrewards possible sequences states observations, time complexitycorresponding algorithm O((jS jjffj)T ). complexity unacceptablereal-world problems, still provides exponential savings searching entire policyspace globally optimal policy, agent could potentially send G timesTG. Table 3 provides table complexity required determine locallyoptimal policy various domain properties.show although Theorem 7's algorithm locally optimal communication provides significant computational savings finding global optimum, stilloutperforms existing teamwork models, exemplified Jff Sff policies. First,use criterion Theorem 7 evaluate optimality policy, Jff .(t0; i; fi ) 0 possible times t0, agents i, belief states fi consistentachievement goal G, locally optimal policy always specifysending G. words, Jff identical locally optimal policy. However,inequality Theorem 7 ever false, Jff even locally, let alone globally,optimal.Second, also use Theorem 7 evaluate STEAM viewing STEAM's inequality,Cmt > Cc, crude approximation Inequality 16. fact, clear correspondence terms two inequalities. left-hand side Inequality 16computes exact expected cost miscoordination. However, unlike STEAM's monolithicparameter, optimal criterion evaluates complete probability distributionpossible states miscoordination considering possible past sequences consistent409fiPynadath & Tambeagent's current beliefs. Likewise, unlike STEAM's monolithic Cmt parameter, optimal criterion looks ahead possible future sequences states determine trueexpected cost miscoordination. Furthermore, view STEAM's parameter, Cc,approximation communication cost computed right-hand side Inequality 16.Again, STEAM uses single parameter, optimal criterion computes expectedcost possible states world.STEAM exibility representation, Cmt , , Ccnecessarily fixed across entire domain. instance, Cmt may vary basedspecific joint plan agents may jointly committed (i.e., maydifferent Cmt goal G). Thus, Theorem 7 suggests significant additional exibility computing Cmt explicit lookahead, optimal criterion derivedCOM-MTDP model also provides justification overall structure behind STEAM'sapproximate criterion. Furthermore, STEAM's emphasis on-line computation makescomputational complexity Inequality 16 (as presented Table 3) unacceptable,approximation error may acceptable given gains eciency. specific domain,use empirical evaluation (as demonstrated next section) quantify erroreciency precisely judge tradeoff.5. Empirical Policy Evaluationaddition providing analytical results general classes problem domains,COM-MTDP framework also supports analysis specific domains. Given particularproblem domain, construct optimal communication policy or, complexitycomputing optimal policy prohibitive, instead evaluate compare candidateapproximate policies. provide reusable tool evaluations, implementedCOM-MTDP model Python class domain-independent methods evaluation arbitrary policies generation locally optimal policies usingTheorem 7 globally optimal policies brute-force search policy space.software available Online Appendix 1.section presents results COM-MTDP analysis example domain involvingagent-piloted helicopters, focus key communication decision faced manymultiagent frameworks (as described Section 4), vary cost communicationdegree observability generate space distinct domains different implicationsagents' performance. evaluating communication policies various configurations particular testbed domain, demonstrate methodology oneuse COM-MTDP framework model problem domain evaluate candidatecommunication policies it.5.1 Experimental SetupConsider two helicopters must across enemy territory destination, illustrated Figure 1. first, piloted agent Transport, transport vehiclelimited firepower. second, piloted agent Escort, escort vehicle significantfirepower. Somewhere along path enemy radar unit, location unknown(a priori) agents. Escort capable destroying radar unit upon encounteringit. However, Transport not, escape detection radar unit traveling410fiThe Communicative Multiagent Team Decision ProblemFigure 1: Illustration helicopter team scenario.low altitude (nap-of-the-earth ight), though lower speed typical,higher altitude. scenario, Escort worry detection, given superiorfirepower; therefore, fast speed typical altitude.two agents form top-level joint commitment, GD , reach destination.incentive agents communicate achievement goal, sinceeventually reach destination certainty. However, servicetop-level goal, GD , two agents also adopt joint commitment, GR, destroyingradar unit. consider problem facing Escort respect communicatingachievement goal, GR. Escort communicates achievement GR, Transportknows safe normal altitude (thus reaching destination sooner).Escort communicate achievement GR, still chanceTransport observe event anyway. Transport observe achievementGR , must nap-of-the-earth whole distance, team receives lowerreward later arrival. Therefore, Escort must weigh increase expectedreward cost communication.COM-MTDP model scenario (presented Figures 2, 3 4), worldstate position (along straight line origin destination) Transport,Escort, enemy radar. enemy randomly selected position somewhereagents' initial position destination. Transport possiblecommunication actions, choose two domain-level actions: ying nap-ofthe-earth ying normal speed altitude. Escort two domain-level actions:ying normal speed destroying radar. Escort also option communicating special message, GR , indicating radar destroyed. tablesFigures 2, 3 4, \" symbol represents wild-card (or \don't care") entry.Escort arrives radar, observes presence certaintydestroy achieve GR. likelihood Transport's observing radar's destructionfunction distance radar. vary function's observability parameter411fiPynadath & TambeffAffff= fEscort (E ); Transport (T )g= E RPosition Escort: E = f0; 1; : : : ; 8; 9; DestinationgPosition Transport: = f0; 0:5; : : : ; 9; 9:5; Destination;DestroyedgPosition Radar: R = f1; 2; : : : ; 8; Destroyedg= AE = f y; destroy; waitg f y-NOE; y-normal; waitg= E = fclear (GR ); nullg fnullgE0; : : : ; 90; : : : ; 90; : : : ; 9:5; DestroyedRA0DestinationrTDestination 0; : : : ; 9:5; DestroyedDestination+ rTDestinationR (s; hnull; nulli) = 0R (s; hGR ; nulli) = r 2 [0; 1]Figure 2: COM-MTDP model states, actions, rewards helicopter scenario.RA (hE ; ; R ; a)=( Figure 4) within range [0; 1] generate distinct domain configurations (0 meansTransport never observe radar's destruction; 1 means Transport alwaysobserve it). observability 1, achieve mutual belief achievementGR soon occurs (following argument presented Section 4.1). However,observability less 1, chance agents achieve mutual beliefsimply common observation. helicopters receive fixed reward time stepspent destination. Thus, fixed time horizon, earlier helicopters reachthere, greater team's reward. Since ying nap-of-the-earth slower normalspeed, Transport switch normal ying soon either observes GRachieved Escort sends message, GR . Sending message free,impose variable communication cost (r Figure 2), also within range [0; 1].constructed COM-MTDP models scenario combination observability communication cost within range [0; 1] 0.1 increments. combination,applied Jennings STEAM policies, well completely silent policy.domain, policy, Jff , dictates Escort always communicate GR upon destroyingradar. STEAM, vary Cc parameters observability communication cost parameters, respectively. used two different settings (low medium)cost miscoordination, Cmt . Following published STEAM algorithm (Tambe,1997), Escort sends message GR STEAM's inequality Cmt > Cc, holds.Thus, two different settings, low medium, Cmt generate two distinct communication policies; high setting strictly dominated two settings domain.also constructed evaluated locally globally optimal policies. applyingpolicies, used COM-MTDP model compute expected reward receivedteam following selected policy. uniquely determine expectedreward given candidate communication policy particular observability communication cost parameters, well COM-MTDP model specified Figures 2, 3,4.412fiThe Communicative Multiagent Team Decision ProblemP (hE0; 0; R0 ; haE ; ; hE1; 1; R1 i) =PE (E 0 ; aE ; E 1 ) PT (hT 0 ; R0 ; ; 1 ) PR (hE 0 ; R0 ; aE ; R1 )Escort: Initial distribution, Pr(0E = 0) = 1E 0aEE 1PEDestination Destination 10; : : : ; 8E 0 + 110; : : : ; 8 destroy E0 + 1 19Destination 19destroy Destination 1waitE 01Transport: Initial distribution, Pr(0T = 0) = 10R0DestinationDestroyed0; : : : ; 9y-NOE9:5y-NOE0; : : : ; 8:5 Destroyed y-normal9; 9:5Destroyed y-normal6= Destroyed y-normalwait1DestinationDestroyed0 + 0:5Destination0 + 1DestinationDestroyed0PT11111111Radar: Initial distribution, 8 2 f1; 2; : : : ; 8g, P r(0R = ) = 0:125E 0R0aER1PRE0 destroy Destroyed 16= destroyR016= E0R01Figure 3: COM-MTDP model transition probabilities helicopter scenario (excludeszero probability rows).413fiPynadath & Tambeff =E{E = E, agent Escort's possible observations radarconsist= fpresent; destroyed; nullg{= ERT , agent Transport's possible observations radarconsistRT = fdestroyed; nullg(s; haE ; ; h!E ; !T i) = OE (s; haE ; ; !E ) OT (s; haE ; ; !T ){ OE (hE ; ; R ; haE ; ; ; ; !RE i) =ERaE!REOEdestroyed destroy destroyed 1destroyed 6= destroy null1R 1; : : : ; 9present 16= R 1; : : : ; 9null1{ OT (hE ; ; R ; haE ; ; ; ; !RT i) =R0; : : : ; 9:50; : : : ; 9:50; : : : ; 9:5aE!RTdestroy destroyeddestroynull 16= destroy nulldestroyednullOTe (R )(1 )e (R )(1 )112 [0; 1]Figure 4: COM-MTDP model observability helicopter scenario. tables excludezero probability rows input feature columns independent. example, agents' observation functions independenttransport's selected action, neither table includes column.414fiThe Communicative Multiagent Team Decision ProblemFigure 5: Suboptimality silent Jennings policies.Figure 6: Suboptimality STEAM policy low medium costs miscoordination.5.2 Experimental ResultsFigures 5 6 plot much utility team expect lose following Jennings,silent, two STEAM policies instead locally optimal communication policy(thus, higher values mean worse performance). immediately see Jenningssilent policies significantly suboptimal many possible domain configurations.example, surprisingly, surface policy, Jff, peaks (i.e., poorly)communication cost high observability high, silentpolicy poorly exactly opposite conditions.Previously published results (Jennings, 1995) demonstrated Jennings policyled better team performance reducing waste effort produced alternate policieslike silent one. earlier results focused single domain, Figure 5 partiallyconfirms conclusion shows superiority Jennings policysilent policy extends broad range possible domain configurations.hand, COM-MTDP results also show significant subclass domains (e.g.,communication cost observability high) Jennings policy actuallyinferior silent policy. Thus, COM-MTDP model, characterizetypes domains Jennings policy outperforms silent policy vice versa.415fiPynadath & TambeFigure 6 shows expected value lost following two STEAM policies.view STEAM trying intelligently interpolate Jennings silent policiesbased particular domain properties. fact, low setting Cmt , seetwo thresholds, one along dimension, STEAM switches followingJennings silent policies, suboptimality highest thresholds.medium setting Cmt , STEAM exhibit threshold along dimensioncommunication cost, due increased cost miscoordination. settings,STEAM's performance generally follows better two fixed policies, maximum suboptimality (0.587 settings) significantly lower silent(0.700) Jennings' (1.000) policies. Furthermore, STEAM outperforms two policiesaverage, across space domain configurations, evidenced mean suboptimality 0.063 low Cmt 0.083 medium Cmt . values significantlylower silent policy's mean 0.160 Jennings' policy's mean 0.161. Thus,able quantify savings provided STEAM less selective policieswithin example domain.However, within given domain configuration, STEAM must either always nevercommunicate, exibility leads significant suboptimality across wide rangedomain configurations. hand, Figure 6 also shows domainconfigurations STEAM locally optimal. relatively small-scale experimentaltestbed, need incur STEAM's suboptimality, agents computesuperior locally optimal policy 5 seconds. larger-scale domains,hand, increased complexity locally optimal policies may render executioninfeasible. domains, STEAM's constant-time execution would potentially makepreferable alternative. analysis suggests possible spectrum algorithms makedifferent optimality-eciency tradeoffs.understand cause STEAM's suboptimality, examine performancedeeply Figures 7 8, plot expected number messages sent usingSTEAM (with low medium Cmt ) vs. locally optimal policy, observabilityvalues 0.3 0.7. STEAM's expected number messages either 0 1, STEAMmake two (instantaneous) transitions them: one threshold valuealong observability communication cost dimensions.Figures 7 8, see optimal policy exible STEAMspecifying communication contingent Escort's beliefs beyond simply achievementGR. example, consider messages sent low Cmt Figure 7, STEAMmatches locally optimal policy extremes communication cost dimension.Even communication cost high, still worth sending message GR statesTransport still far destination. Thus, surface optimal policy,makes gradual transition always communicating never communicating.thus view STEAM's surface crude approximation optimal surface, subjectSTEAM's fewer degrees freedom.also use Figures 7 8 identify domain conditions jointintentions theory's prescription attaining mutual belief optimal. particular,domain observability less 1, agents attain mutual beliefwithout communication. Figures 7 8, many domain configurationslocally optimal policy expected send fewer 1 GR message.416fiThe Communicative Multiagent Team Decision ProblemFigure 7: Expected number messages sent STEAM locally optimal policiesobservability 0.3.Figure 8: Expected number messages sent STEAM locally optimal policiesobservability 0.7. settings, STEAM sends 0 messages.417fiPynadath & TambeFigure 9: Suboptimality locally optimal policy.configurations represents domain locally optimal policy attainmutual belief least one case. Therefore, attaining mutual belief suboptimalconfigurations!experiments illustrate STEAM, despite decision-theoretic communicationselectivity, may communicate suboptimally significant class domain configurations. Previous work STEAM-based, real-world, agent-team implementations informallynoted suboptimality isolated configuration within realistic helicopter transport domain (Tambe, 1997). Unfortunately, previous work treated suboptimality(where agents communicated necessary) isolated aberration,investigation degree suboptimality, conditionssuboptimality may occur practice. re-created conditions within experimental testbed section using medium Cmt . resulting experiments (as shownFigure 7) illustrated observed suboptimality isolated phenomenon,but, fact, STEAM general propensity towards extraneous communicationsituations involving low observability (i.e., low likelihood mutual belief) high communication costs. result matches situation \aberration" occurredrealistic domain.locally optimal policy suboptimal respect globally optimalpolicy, see Figure 9. domain configurations high observability,globally optimal policy escort wait additional time step destroyingradar communicate transport continues ying nap-of-the-earth.escort cannot directly observe method ight transport chosen,measure change transport's position (since maintains historypast observations) thus infer method ight complete accuracy. sense,escort following globally optimal policy performing plan recognition analyzetransport's possible beliefs. particularly noteworthy domain specificationexplicitly encode recognition capability. fact, algorithm findingglobally optimal policy even make assumptions made locallyobservable policy (i.e., single agent deciding whether communicate not, regardingsingle message, single point time); rather, general-purpose search algorithmtraverses policy space \discovers" possible means inference own.418fiThe Communicative Multiagent Team Decision Problemexpect COM-MTDP analysis provide automatic method discoveringnovel communication policies type domains, even modeling real-worldproblems.Indeed, exploiting discovery capability within example domain, globallyoptimal policy gains slight advantage expected utility locally optimal policy,mean difference 0.011, standard deviation 0.027, maximum 0.120.hand, domain-independent code never requires 5 seconds computelocally optimal policy testbed, domain-independent search algorithmalways required 150 minutes find globally optimal policy. Thus,Theorem 7, used COM-MTDP model construct communication policythat, testbed domain, performs almost optimally outperforms existing teamwork theories, substantial computational savings finding globally optimalpolicy. Although results hold isolated communication decision, expectrelative performance policies stay even multiple decisions,exibility suboptimal policies exacerbate losses (i.e., shapesgraphs would stay roughly same, suboptimality magnitudes would increase).6. SummaryCOM-MTDP model novel framework complements existing teamwork researchproviding previously lacking capability analyze optimality complexityteam decisions. grounded within economic team theory, COM-MTDP's extensions include communication dynamism allow subsume many existing multiagentmodels. able exploit COM-MTDP's ability represent broad classesmultiagent team domains derive complexity results optimal agent teamworkarbitrary problem domains. also used model identify domain propertiessimplify complexity.COM-MTDP framework provides general methodology analysis acrossgeneral domain subclasses specific domain instantiations. demonstrated Section 4,express important existing teamwork theories within COM-MTDP frameworkderive broadly applicable theoretical results optimality. Section 5 demonstratesmethodology analysis specific domain. encoding teamwork problemCOM-MTDP, use leverage general-purpose software tools (availableOnline Appendix 1) evaluate optimality teamwork based potentiallyexisting theory, demonstrated paper using two leading instantiations jointintentions theory. combining theory practice, use theoretical resultsderived using COM-MTDP framework basis new algorithms extendsoftware tools, translating Theorem 7 Section 4 implementedalgorithm locally optimal communication Section 5. expect COM-MTDPframework, theorems complexity results, reusable software form basisanalysis teamwork, others field.419fiPynadath & Tambe7. Future Work COM-MTDP Team Analysisinitial COM-MTDP results promising, remain least three key areasfuture progress COM-MTDPs critical. First, analysis using COM-MTDPs (suchone presented Section 5) requires knowledge rewards, transition probabilities, observation probabilities, well competing policies governing agentbehavior. may always possible model domain agents'policies readily available. Indeed, proposed team-analysis techniques (Nair, Tambe,Marsella, & Raines, 2002b; Raines, Tambe, & Marsella, 2000), require priori handcoding models, rather acquire automatically machine learninglarge numbers runs. Also, interests combating computational complexityimproved understandability, researchers emphasize need multiple modelsmultiple levels abstraction, rather focusing single model (Nair et al., 2002b).instance, one level model may focus analysis individual agents' actions support team, another level may focus interactions among subteamsteam. potentially extend COM-MTDP model directions(i.e., machine learning model parameters, hierarchical representations teamprovide multiple levels abstraction).Second, important extend COM-MTDP analysis aspects teamworkbeyond communication. instance, team formation (where agents may assigned specific roles within team) reformation (where failure individual agents leads rolereassignment within team) key problems teamwork appear suitableCOM-MTDP analysis. analysis may require extensions COM-MTDP framework (e.g., explicit modeling roles). Ongoing research (Nair, Tambe, & Marsella, 2002a)begun investigating impact extensions applications domainsRoboCup Rescue (Kitano, Tadokoro, Noda, Matsubara, Takahashi, Shinjoh, & Shimada, 1999). Analysis complex team behaviors may require extensionsCOM-MTDP model explicitly account additional aspects teamwork (e.g.,notions authority structure within teams).Third, extending COM-MTDP analysis beyond teamwork model types coordination may require relaxation COM-MTDP's assumption sel ess agents receivingjoint reward. complex organizations may require modeling non-jointrewards. Indeed, enriching COM-MTDP model manner may enable analysis seminal work multiagent coordination tradition PGPGPGP (Decker & Lesser, 1995; Durfee & Lesser, 1991). enriched models may firstrequire new advances mathematical foundations COM-MTDP framework,ultimately contribute towards emerging sciences agents multiagent systems.Acknowledgmentsarticle significantly extended version paper, \Multiagent Teamwork: AnalyzingOptimality Complexity Key Theories Models", authors,Proceedings International Joint Conference Autonomous Agents Multi-AgentSystems, 2002. article extends initial content providing proofs missingoriginal paper, well new theoretical results, detailed description experimental420fiThe Communicative Multiagent Team Decision Problemsetup, new experimental results, additional discussion explanations key points.research supported DARPA award No. F30602-98-2-0108, ControlAgent Based Systems program, managed AFRL/Rome Research Site. wouldlike thank Daniel Bernstein, Ashish Goel, Daniel Marcu, Stacy Marsella, Ranjit Nair,Paul Rosenbloom valuable discussion feedback. also thank anonymousreviewers helpful comments suggestions.ReferencesBernstein, D. S., Zilberstein, S., & Immerman, N. (2000). complexity decentralizedcontrol Markov decision processes. Proceedings Conference UncertaintyArtificial Intelligence, pp. 32{37.Boutilier, C. (1996). Planning, learning coordination multiagent decision processes.Proceedings Conference Theoretical Aspects Rationality Knowledge,pp. 195{210.Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research,11, 1{93.Cohen, P. R., & Levesque, H. J. (1991a). Confirmation joint action. ProceedingsInternational Joint Conference Artificial Intelligence.Cohen, P. R., & Levesque, H. J. (1991b). Teamwork. Nous, 25 (4), 487{512.Decker, K., & Lesser, V. (1995). Designing family coordination algorithms. Proceedings International Conference Multi-Agent Systems.Dunin-Keplicz, B., & Verbrugge, R. (1996). Collective commitments. InternationalConference Multi-Agent Systems, pp. 56{63.Durfee, E., & Lesser, V. (1991). Partial global planning: coordination frameworkdistributed planning. IEEE transactions Systems, Man Cybernetics, 21 (5).Goldberg, D., & Mataric, M. J. (1997). Interference tool designing evaluating multi-robot controllers. Proceedings National Conference ArtificialIntelligence, pp. 637{642.Grosz, B. (1996). Collaborating systems. Artificial Intelligence Magazine, 17 (2), 67{85.Grosz, B., & Kraus, S. (1996). Collaborative plans complex group actions. ArtificialIntelligence, 86, 269{358.Grosz, B. J., & Sidner, C. L. (1990). Plans discourse. Cohen, P. R., Morgan,J., & Pollack, M. E. (Eds.), Intentions Communication, pp. 417{444. MIT Press,Cambridge, MA.Ho, Y.-C. (1980). Team decision theory information structures. ProceedingsIEEE, 68 (6), 644{654.Jennings, N. (1995). Controlling cooperative problem solving industrial multi-agentsystems using joint intentions. Artificial Intelligence, 75, 195{240.421fiPynadath & TambeKitano, H., Tadokoro, S., Noda, I., Matsubara, H., Takahashi, T., Shinjoh, A., & Shimada,S. (1999). Robocuprescue: Search rescue large-scale disasters domainmultiagent research. Proceedings IEEE International Conference Systems,Man Cybernetics.Levesque, H. J., Cohen, P. R., & Nunes, J. (1990). acting together. ProceedingsNational Conference Artificial Intelligence.Marschak, J., & Radner, R. (1971). Economic Theory Teams. Yale University Press,New Haven, CT.Nair, R., Tambe, M., & Marsella, S. (2002a). Team formation reformation multiagent domains like robocup rescue. Proceedings International SymposiumRoboCup.Nair, R., Tambe, M., Marsella, S., & Raines, T. (2002b). Automated assistants analyzingteam behaviors. Journal Autonomous Agents Multiagent Systems, appear.Papadimitriou, C. H., & Tsitsiklis, J. N. (1987). complexity Markov decision processes. Mathematics Operation Research, 12 (3), 441{450.Peshkin, L., Kim, K.-E., Meuleau, N., & Kaelbling, L. P. (2000). Learning cooperate viapolicy search. Proceedings Conference Uncertainty Artificial Intelligence, pp. 489{496.Pynadath, D. V., & Tambe, M. (2002). automated teamwork infrastructure heterogeneous software agents humans. Journal Autonomous Agents MultiAgent Systems: Special Issue Infrastructure Requirements Building Research Grade Multi-Agent Systems, appear.Pynadath, D. V., Tambe, M., Chauvat, N., & Cavedon, L. (1999). Toward team-orientedprogramming. Jennings, N. R., & Lesperance, Y. (Eds.), Intelligent Agents VI:Agent Theories, Architectures Languages, pp. 233{247. Springer-Verlag.Raines, T., Tambe, M., & Marsella, S. (2000). Automated agents help humans understand team behaviors. Proceedings International Conference AutonomousAgents.Rich, C., & Sidner, C. (1997). COLLAGEN: agents collaborate people.Proceedings International Conference Autonomous Agents.Smallwood, R. D., & Sondik, E. J. (1973). optimal control partially observableMarkov processes finite horizon. Operations Research, 21, 1071{1088.Smith, I. A., & Cohen, P. R. (1996). Toward semantics agent communicationslanguage based speech-acts. Proceedings National Conference ArtificialIntelligence, pp. 24{31.Sonenberg, E., Tidhar, G., Werner, E., Kinny, D., Ljungberg, M., & Rao, A. (1994). Plannedteam activity. Tech. rep. 26, Australian AI Institute.Tambe, M. (1997). Towards exible teamwork. Journal Artificial Intelligence Research,7, 83{124.422fiThe Communicative Multiagent Team Decision ProblemTambe, M., Pynadath, D. V., Chauvat, N., Das, A., & Kaminka, G. A. (2000). Adaptiveagent integration architectures heterogeneous team members. ProceedingsInternational Conference Multi-Agent Systems, pp. 301{308.Tambe, M., & Zhang, W. (1998). Towards exible teamwork persistent teams. Proceedings International Conference Multi-Agent Systems, pp. 277{284.Tidhar, G. (1993). Team-oriented programming: Preliminary report. Tech. rep. 41, Australian Artificial Intelligence Institute.Xuan, P., Lesser, V., & Zilberstein, S. (2001). Communication decisions multi-agentcooperation: Model experiments. Proceedings International ConferenceAutonomous Agents, pp. 616{623.Yen, J., Yin, J., Ioerger, T. R., Miller, M. S., Xu, D., & Volz, R. A. (2001). CAST:Collaborative agents simulating teamwork. Proceedings InternationalJoint Conference Artificial Intelligence, pp. 1135{1142.Yoshikawa, T. (1978). Decomposition dynamic team decision problems. IEEE Transactions Automatic Control, AC-23 (4), 627{632.423fiJournal Artificial Intelligence Research 16 (2002) 359-387Submitted 12/01; published 6/02Collective Intelligence, Data Routing Braess' ParadoxDavid H. WolpertNASA Ames Research Center, Mailstop 269-2Moffett Field, CA 94035Kagan TumerNASA Ames Research Center, Mailstop 269-3Moffett Field, CA 94035dhw@ptolemy.arc.nasa.govkagan@ptolemy.arc.nasa.govAbstractconsider problem designing utility functions utility-maximizingagents multi-agent system (MAS) work synergistically maximize globalutility. particular problem domain explore control network routingplacing agents routers network. Conventional approaches taskagents use Ideal Shortest Path routing Algorithm (ISPA). demonstratemany cases, due side-effects one agent's actions another agent's performance,agents use ISPA's suboptimal far global aggregate cost concerned, evenused route infinitesimally small amounts trac. utilityfunctions individual agents \aligned" global utility, intuitivelyspeaking. particular example present instance Braess' paradoxadding new links network whose agents use ISPA results decreaseoverall throughput. also demonstrate load-balancing, agents'decisions collectively made optimize global cost incurred trac currentlyrouted, suboptimal far global cost averaged across time concerned.also due \side-effects", case current routing decision future trac.mathematics Collective Intelligence (COIN) concerned precisely issueavoiding deleterious side-effects multi-agent systems, time space.present key concepts mathematics use derive algorithmwhose ideal version better performance agents useISPA, even infinitesimal limit. present experiments verifying this, alsoshowing machine-learning-based version COIN algorithm costsimprecisely estimated via empirical means (a version potentially applicable realworld) also outperforms ISPA, despite access less informationISPA. particular, COIN algorithm almost always avoids Braess' paradox.1. Introductionlong history AI research design distributed computational systems,stretching Distributed AI (Huhns, 1987) current work multi-agent systems(MAS's) (Claus & Boutilier, 1998; Hu & Wellman, 1998a; Jennings, Sycara, & Wooldridge,1998; Sandholm, Larson, Anderson, Shehory, & Tohme, 1998; Sycara, 1998).individual agents system personal utility functions tryingmaximize also `world utility' rates possible dynamic historiesoverall system, MAS constitutes `collective'. paper particularlyconcerned agents use machine learning techniques (e.g., Reinforcement Learningc 2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiWolpert & Tumer(RL) Kaelbing, Littman, & Moore, 1996; Sutton & Barto, 1998; Sutton, 1988; Watkins &Dayan, 1992) try maximize utilities.field Collective Intelligence (COIN) concerned central design problemcollectives (Wolpert, Tumer, & Frank, 1999; Wolpert & Tumer, 1999): How, withoutdetailed modeling overall system, one set utility functions individualagents COIN overall dynamics reliably robustly achieves large valuesprovided world utility? words, leverage assumptionlearners individually fairly good do, collective wholeperform well? 1example question looms large problem optimizeow certain entities (e.g., information packets, cars) sources destinations acrossnetwork routing nodes. concerned version problem\optimization" consists minimizing aggregate cost incurred entities owingdestinations, agent controls routing decisions nodenetwork. problem underlies distributed control large array real-worlddomains, including internet routing, voice/video communication, trac ows, etc.COIN perspective, problem reduces question goals one oughtprovide router's agent agent's self-interestedly pursuing utilityresults maximal throughput entire system (\incentive engineering").paper investigate application recently developed COIN techniques,routing domain. Like work concerning COINs, techniques designedbroadly applicable, particular designed routing domain.Accordingly, performance domain serves good preliminary indicationgeneral usefulness.ground discussion, concentrate telecommunications data routingproblem entities routed packets. Currently, many real-world algorithmsproblem based Shortest Path Algorithm (SPA). algorithmrouting node network controlled agent maintains \routing table"\shortest paths" (i.e., sequences links minimal total incurred costs) nodepossible destination nodes net. moment agent satisfiesrouting requests particular destination node sending packetsassociated shortest path. Many Ideal SPA (ISPA) algorithms exist eciently computingshortest path agent-to-agent path-cost communication available coststraversing agent's node unvarying time, e.g., Dijkstra's Algorithm (Ahuja,Magnanti, & Orlin, 1993; Bertsekas & Gallager, 1992; Deo & Pang, 1984; Dijkstra, 1959).non-infinitesimal amount trac routed particular destinationmoment agent, agent's sending trac single pathresult minimal cost, matter single path chosen. However mustchoose single path trac, routing decisions agentsfixed, tautologically using ISPA agent chooses best path, fartrac routing concerned. Accordingly, limit routing infinitesimally1. lack detailed modeling ensures face problems \brittleness" sometimesaccompany mismatch real world assumptions concerning built non-adaptive,\hard-wired" agents large MAS's. turn, lack modeling causes us concentrateadaptive, RL-based agents.360fiCollective Intelligence, Data Routing Braess' Paradoxsmall amount trac, agents' strategies \background", ISPAoptimal (least aggregate incurred cost) routing strategy trac associatedsingle agent considered individually.One might hope generally, agent must allot trac singlepath agents' trac decisions fixed, choosing path viaISPA would choice minimizes total incurred cost trac across net,least limit infinitesimally little trac. case though, usingSPA agent concerned deleterious side-effects actionscosts trac routed agents (Korilis, Lazar, & Orda, 1997a; Wolpert et al.,1999). problem made worse agents allowed changedecisions response agent's decision. extreme case, elaborated below,agents try minimize personal costs via ISPA's, agents wouldactually receive higher cost would case alternative set strategies.instance famous Tragedy Commons (TOC) (Hardin, 1968).Deleterious side-effects need restricted extend space; also extendtime. Indeed, consider algorithm agents given moment makerouting decisions optimize global cost incurred trac currently routed,algorithm often called \load-balancing" (LB) (Heusse, Snyers, Guerin, & Kuntz, 1998).definition, LB avoids deleterious side-effects space result TOCcosts incurred trac currently routed. However, due side-effectstime, even conventional LB suboptimal far global cost averaged acrosstime concerned. Intuitively, one would use \load-balancing time" ensuretruly optimal performance. even one could somehow construct distributed protocolgoverning agents caused implement LB, still one wouldgotten theme act perfectly coordinated fashion. diculties makeappropriate domain investigate well COIN techniques work practice.Real-world SPA's (RSPA) work applying ISPA estimated costs traversingpath every agent. Typically estimates error agent-to-agentcommunication instantaneous, therefore routing tables may baseddate information. generally though, even communication instantaneous,cost traverse agent's node may different time packet arrivesnode. Accordingly, general performance RSPA's boundedassociated ISPA. paper wish investigate topics, ratherhighlight issue side-effects. Accordingly \rig game" experimentalcomparisons favor SPA, using ISPA's rather RSPA's.general, even without side-effects, determining optimal solution ow problem(e.g., determining loads link need maximize throughputnon-cooperative data network) nontractable (Ahuja et al., 1993; Orda, Rom, & Sidi,1993b). Therefore, concern providing good solutions avoiddiculties ISPA side-effects. aim present algorithmsfind best possible (perfectly load-balanced time) solution. Previous workusing machine learning improve routing sometimes resulted better performance(non-idealized) SPA's (Littman & Boyan, 1993; Boyan & Littman, 1994; Stone, 2000;Marbach, Mihatsch, Schulte, & Tsisiklis, 1998). work grappledcentral COIN design problem however.361fiWolpert & TumerSection 2 discuss SPA's deficiencies particular manifestationsBraess' paradox. Then, Section 3 present theory collective intelligence,approach promises overcome deficiencies. discuss routing modeluse experiments, show theory COINs appliedmodel provide alternative shortest path algorithms Section 3. Section 5present simulation results model comparing ISPA COINs. resultsdemonstrate networks running ISPA, per packet costs much 32% higher networks running algorithms based COIN theory. particular, eventhough access imprecise estimates costs (a handicap holdISPA), COIN-based algorithm almost always avoids Braess' paradox, stark contrastISPA. cost incurred ISPA's presumably lower boundSPA privy instantaneous communication, implication COINsoutperform real-world SPA's. conclude techniques field collectiveintelligence highly effective designing utility functions members MASensure work coordinated ecient manner optimize overall performance.2. Suboptimality Shortest Path Routing Braess Paradoxsection first demonstrate suboptimality SPA multipleagents making simultaneous routing decisions, agent knows ahead timeother's choice, therefore know ahead time exactly costs be.demonstrate suboptimality hold even one agent makingdecision, knows decisions others previously made. Next presentBraess' paradox, particularly pointed instance effects (for discussionBraess' paradox SPA routing, see Bass, 1992; Cohen & Kelly, 1990; Cohen & Jeffries,1997; Hogg, 1995; Glance & Hogg, 1995; Korilis, Lazar, & Orda, 1999).2.1 Suboptimality SPAPerhaps simplest example individual greed part agents leadcollective detriment occurs two agents determine shortest pathshared link limited capacity, second option slightlyless preferable. case, using common link degrades performanceparties, since due limited capacity performance link quickly fallsecond option.precisely, consider case shared link cost given x3traversed x packets, router optional second link destinationcost trac x traverse second link 2x. Acting alone, singlepacket send, would send packet shared link (cost 1).However so, incur larger cost (cost 8) usedsecond choices (cost 4). Without knowing ahead time(information conventionally contained routing tables), agents necessarilymistaken cost estimates therefore make incorrect routing decisions. this, evenlimit differentially small packets, use SPA lead wrong routing decision.362fiCollective Intelligence, Data Routing Braess' Paradox2.2 Suboptimality ISPAanalyze situation routers may know loadsacting optimize delays experienced packets alone. Consider networkshown Figure 1. Two source routers X send one packet time, Xsending either intermediate router B , sending either B C . typenetwork may arise many different topologies subnetwork. Accordingly, dicultiesassociated network also apply many complex topologies.JJJJJJBJJJJJCJJXJJJFigure 1: Independent decisions sourceLet xA , xB , yB , yC , packet quantities particular fixed time t, A, B ,C , originating X , indicated. t, source one packet send.variables binary, xA + xB = yB + yC = 1. Vi (zi ) cost,per packet, single instant t, router i, total number packetsinstant router zi . total cost incurred packets time t, G(~x; ~y),equals xA VA (xA ) + (xB + yB )VB (xB + yB ) + (yC )VC (yC ).ISPA, X chooses xA xB = 1 minimize cost incurredX's packet alone, gX (~x) xA VA (xA ) + xB VB (xB + yB ). ISPA ignoresyB VB (xB + yB ) term, i.e., ignores \side effects" X 's decision. Real-world SPA'stypically try approximate X choose either B according whetherVA (0) VB (yB ) smaller, two values estimated via pings, example.right thing point view minimizing global cost courseinstead X minimize G(~x; ~y), precisely, components G(~x; ~y)depend X . Writing case, X ought act minimize xA VA (xA ) + (xB +yB )VB (xB + yB ). Due constraint xA + xB = 1, means sending iffVA (1) < (yB + 1)VB (yB + 1) yB VB (yB ), differs ISPA result Xconcerned full cost going router B , portion costpacket receives.context example, G-minimizing algorithm constitutes \load-balancing"(LB). Note long sgn[VA (0) VB (yB ) yB VB0 (yB )] 6= sgn[VA (0) VB (yB )], evenlimit infinitesimally small trac (so xA + xB equals infinitesimal ),ISPA LB still disagree. LB considers side-effects current routing decisionstrac currently routed. However consider side-effects routingdecisions future trac, even LB may optimize global cost averaged across time,363fiWolpert & Tumerdepending details system. However use \effect sets" COINsaccount even delayed side-effects2 .2.3 Braess' ParadoxLet us conclude section illustration Braess' paradox (Bass, 1992; Cohen& Kelly, 1990; Cohen & Jeffries, 1997; Glance & Hogg, 1995; Hogg, 1995; Korilis, Lazar,& Orda, 1997b; Korilis et al., 1999), phenomenon dramatically underscoresineciency ISPA. apparent \paradox" perhaps best illustratedhighway trac example first given Bass (Bass, 1992): two highways connectingtowns D. cost associated traversing either highway (either terms tolls,delays) V1 + V2 , illustrated Net Figure 2. x = 1 (a single traveler)either path, total accrued cost 61 units. hand, six travelers split equallyamong two paths, incur cost 83 units get destinations. Now,suppose new highway built connecting two branches, shown Net B Figure 2.Further, note cost associated taking highway particularly high (infact load higher 1, highway lower cost highwaysystem). benefit highway illustrated dramatically reduced cost incurredsingle traveler: taking short-cut, one traveler traverse networkcost 31 units (2 V1 + V3 ). Adding new road seemingly reduced traversal costdramatically.V2V1"ybDb""bby""byV1V2bb"yV2"bb ""b"ySV1NetFigure 2: Hex network V1 = 10x ;"ybDb""bb"y"byV1V3yb"yV2bb"bb"yS""V2Net B= 50 + x ;V3= 10 + xHowever consider happens six travelers highways net B.agent uses ISPA, equilibrium three possible paths contains twotravelers.3 Due overlaps paths however, results traveler incurringcost 92 units, higher incurred new highwaybuilt. net effect adding new road increase cost incurred every traveler.phenomenon known Braess' paradox.2. detailed discussion proof suboptimality LB shown appendix A. Since LBused current systems hard imagine ever used, experiments consider it;discussed pedagogical reasons.3. mind Nash equilibrium problem, traveler (or equivalently,router) gain advantage changing strategies.364fiCollective Intelligence, Data Routing Braess' Paradox3. Mathematics Collective IntelligenceOne common solution types side-effect problems particular agentsnetwork (e.g., \network manager" Korilis, Lazar, & Orda, 1995) dictate certainchoices agents. solution incur major brittleness scaling problemshowever. Another kind approach, avoids problems centralized manager,provide agents extra incentives induce take actionsundesirable strict SPA sense. incentive form \taxes"\tolls" added costs associated traversing particular links discourageuse links. schemes tolls superimposed agents' goalsspecial case general approach replacing goal agent newgoal. new goals specifically tailored collectively met systemmaximizes throughput. priori, agent's goal need particular relationSPA-type cost incurred agent's packets. Intuitively, approach, provideagent goal \aligned" global objective, separate concerngoal's relation SPA-type cost incurred trac routed agent.section, summarize salient aspects Collective Intelligences (COIN) (Wolpert,Wheeler, & Tumer, 2000; Wolpert & Tumer, 1999). paper consider systemsconsist set agents, connected network, evolving across set discrete, consecutive time steps, 2 f0; 1; :::g. Without loss generality, let relevant characteristicsagent time | including internal parameters time well externallyvisible actions | encapsulated Euclidean vector ;t components ;t;i .call \state" agent time t, let ;t state agents time t,state agent across time.World utility, G( ), function state agents across time.agent uses Machine Learning (ML) algorithm \try increase" privateutility, write private utility g ( ), generally, allow utilityvary time, g; ( ).assume encompasses physically relevant variables, dynamicssystem deterministic (though course imprecisely known anyone tryingcontrol system). Note means characteristics agent = 0affects ensuing dynamics system must included ;0 . ML-basedagents, includes particular algorithmic specification private utility, typicallyphysical form computer code (the mathematics generalized beyondML-based agents, elaborated Wolpert & Tumer, 1999).focus case goal, COIN designers, maximize world utilityproper selection private utility functions. Intuitively, idea chooseprivate utilities aligned world utility, also propertyrelatively easy us configure agent associated privateutilityPachieves large value. paper, utilities consider form Rt ( ;t )Preward functions Rt (simply Rt ( ;t ) non-time-varying utilities). on,consider world utilities whose associated set fRt g time-translationsone another. particular, shown below, overall network throughput expressibleway.365fiWolpert & Tumerneed formal definition concept private utilities \aligned"Constructing formalization subtle exercise. example, consider systemsworld utility sum private utilities individual agents. mightseem reasonable candidate example \aligned" utilities. However systemsexamples general class systems \weakly trivial". well-knownweakly trivial systems individual agent greedily trying maximizeutility lead tragedy commons (Hardin, 1968; Crowe, 1969) actuallyminimize G.particular, case privateutilities independentPPtime G = g . Evidently, minimum, G = g sucient ensure\aligned" utilities; alternative formalization concept needed.Note simple network discussed Section 2.1, utilities weakly trivial,since G(~x; ~y) = gX (~x) + gy (~y ). provides another perspective suboptimalityISPA network.G.careful alternative formalization notion aligned utilities concept\factored" systems. system factored time following holdsagent individually: change time state alone, propagated acrosstime, result increased value g; ( ) results increaseG( ) (Wolpert & Tumer, 1999).factored system, side-effects change 's = state increasesprivate utility cannot decrease world utility. restrictions though effectschange private utilities agents and/or times. particular, don'tpreclude agent's algorithm two different times \working cross-purposes"other, long moments agent working improve G. game-theoreticterms, factored systems optimal global behavior corresponds agents' alwaysprivate utility Nash equilibrium (Fudenberg & Tirole, 1991). sense,tragedy commons factored system. trivial example, systemfactored g; = G 8, system conventionally called `team game'.Furthermore, system factored respect private utilities fg; g, wantagent state time induces high value associated privateutility possible (given initial states agents). Assume ML-basedable achieve fairly large values private utilities likely set time, i.e., assume given private utility g; , rest components ;set 's algorithm way achieve relatively high value g; .problem becomes determining fg; g agents best able achieve highg (subject other's actions) also causing dynamics factored Gfg; g.Define effect set agent-time pair (; ) , C(eff; ) ( ), set agents0 ;t forward dynamics system non-zero partial derivativerespect state agent = . Intuitively, (; )'s effect set set statesagents 0 ;t would affected change state agent time .Next, set agents (0 ; t), define CL ( ) \virtual" vector formedclamping components vector delineated arbitrary fixed value,366fiCollective Intelligence, Data Routing Braess' Paradoxpaper set 0. 4 operation creates new state vector (e.g., worldline)clamped components worldline (e.g., one player's action particular timestep) \zeroed" (e.g., removed system).value wonderful life utility (WLU short) defined as:W LU ( )G( )G(CL ( )):(1)particular, interested WLU effect set agent-time pair (; ).WLU difference actual world utility virtual world utilityagent-time pairs affected (; ) clamped zero staterest left unchanged.Since clamping ~0, loosely view (; )'s effect set WLU analogouschange world utility would arisen (; ) \had never existed", hencename utility - cf. Frank Capra movie. Note however, CL purely\fictional", counter-factual operator, produces new without taking accountsystem's dynamics. sequence states agent-time pairs clampedconstructing WLU need consistent dynamical laws system.dynamics-independence crucial strength WLU. means evaluateWLU try infer system would evolved agent 's stateset ~0 time system evolved there. long know , extendingtime, , function G, know value WLU.mentioned above, regardless system dynamics, g; = G 8 meanssystem factored time .Theorem: Regardless system dynamics, settingfactored system time .g;=W LUC eff(; )8 resultsProof: second term, G(CLC eff ( )) is, definition, independent ; . Therefore(; )change (; ) component affect first term, G( ). Thereforeeffect change value world utility effectvalue wonderful life utility. QED.Since factoredness distinguish team game wonderful life utilities,need means deciding use choice fg; g. determinethis, note since agent operating large system, may experience dicultydiscerning effects actions G G sensitively depends agentssystem. Therefore may diculty learning past experienceachieve high g; g; = G. particular, routing large networks, privaterewards given world reward functions means provide routerreward time step need provide full throughput entire networkstep. usually infeasible practice. Even weren't though, usingprivate utilities would mean routers face dicult task trying discern4. choice clamping parameter used associated COIN affect performance. Howeverwithin wide ranges, doesn't affect whether COIN outperforms alternatives like team games.367fiWolpert & Tumereffect actions rewards, therefore would likely unable learnbest routing strategies.problem mitigated using effect set WLU private utility, sincesubtraction clamped term removes much \noise" activity agents,leaving underlying \signal" agent question affects utility (thisreasoning formalized concept \learnability" Wolpert & Tumer, 1999). Accordingly, one would expect setting private utilities WLU's ought result betterperformance g; = G 8; . primary theoretical considerationleverage COIN techniques investigated paper.practice, sometimes able estimate \primary", prominentportion effect set. Technically, associated WLU effect set WLU,therefore exactly factored. However assuming associated WLU close enoughfactored, would expect advantage learnability WLU stillresult better performance would using g; = G 8; (see Wolpert et al., 2000;Wolpert & Tumer, 1999). Indeed, sake improving learnability, sometimeselect exclude certain agent-time pairs estimate effect set (; ), evensure affected ; . case expectchanges G due varying ; \mediated" agent-time pairsrelatively insignificant, therefore effectively constitute noise learning process,effect learnability important effect factoredness.4. Collective Intelligence Network Routingsection, use theory summarized Section 3 derive individual goalsrouter, form private utility functions maximized appropriate choicerouting decisions. routers tried achieve maximizations using algorithmsrequire limited knowledge state network (in particular knowledgereadily available routers common real data networks). simulationsrouter used Memory Based (MB) machine learning algorithm (nearest neighbor) makerouting decisions. precisely, potential routing decision, routers lookpast state closely closely matches current state (e.g., load).assign "estimated" utility value potential routing decision select actionhighest estimated utility value. call algorithm MB COIN5 .4.1 Model Descriptionapply COIN formalism network routing model, must formally describeset deterministically evolving vectors ;t . model used paper,time step trac router set pairs integer-valued trac amountsassociated ultimate destination tags. time step t, router r sumsinteger-valued components current trac time step (one component5. Relatively minor details algorithm concerning exploration/exploitation issues along \steering" parameter discussed end section.368fiCollective Intelligence, Data Routing Braess' Paradoxultimate destination) get instantaneous load. write load as:zr (t)Xxr;d (t);index runs ultimate destinations, xr;d (t) total trac timegoing r towards d. instantaneous load time evaluated, routersends trac next downstream routers, manner governed underlyingrouting algorithm. indicate \next routers" writing:xr;d (t)=Xr0xr;d;r0 (t);r0 next router trac (r; d), i.e., first stop path followedrouter r ultimate destination d. routed trac goes nextdownstream routers, cycle repeats itself, trac reaches destinations.simulations, simplicity, trac introduced system (atsource routers) beginning successive disjoint waves L consecutive time stepseach6 . use (t) indicate either integer-valued wave number associated timeset times wave, context indicates.real network, cost traversing router depends \after-effects" recentinstantaneous loads, well current instantaneous load. simulate effect,use time-averaged values load router rather instantaneous load determinecost packet incurs traversing router. formally, define router'swindowed load, Zr (t), running average router's load value windowprevious W timesteps (W always set integer multiple L):Zr (t)W1Xt0 =t W +1zr (t0 )=XXr;d (t);value Xr;d (t) setXr;d (t)=1XW 0=t W +1xr;d (t0 )):Intuitively, large enough W , using window determine costs across routersmeans typically costs change substantially time scales significantlylarger individual routing decisions. Formally, windowed loadargument load-to-cost function, V (), provides cost accrued timepacket traversing router timestep. is, time t, costpacket traverse router r given V (Zr (t))7 . Note model, costsaccrued routers, links. Also note simplicity physicallyinstantiate cost temporal delay crossing router. Different routers different6. L always chosen minimal number necessary trac reach destinationnext wave trac initiated.7. also introduce \dummy routers" denoted V0 () = 0 help translating mathematicssimulations. Omitting effect simulations.369fiWolpert & TumerV (), ect fact real networks differences router software hardware(response time, queue length, processing speed etc). simplicity, Wrouters however. definitions, world utility givenG( )==Xt;rXt;r;d=Xt;r;d=Xt;r;dzr (t) Vr (Zr (t))xr;d (t)Vr (Zr (t))0xr;d (t)Vr @xr;d (t)Vr1XXW 0=t W +1 d0Xd01xr;d0 (t0 )A!Xr;d0 (t)(2):equation G explicitly demonstratesthat, claimed above, representationPexpress G( ) sum rewards, Rt ( ;t ), R( ;t ) written functionpair (r; d)-indexed vectors:Rt (xr;d (t); Xr;d (t))=Xr;dxr;d (t)VrXd0!Xr;d0 (t):Also claimed, Rt temporal translations one another.Given model, components ;t must identified valuesxr;d;r0 (t) 8 r; d; r 0 t, since x's set actions agents take. Sincearguments G must components , also include Xr;d (t) 8r; d; components;t . Formally, routing based ML agents, internal parameters ML agentsmust also included . parameters affect routing,turn affected it. evolve deterministically, since includes routingvariables, must also contain internal parameters agents. won't needexplicitly delineate variables however, mostly phrase discussionthough internal parameters.values fxr;d;r0 (t 1)g 8r; d; r0 specify values fxr;d (t)g 8r; directly. Therefore, concert fxr;d (t0 < t)g, also set fXr;d (t)g directly. Moreoversimulations decisions fxr;d;r0 (t)g 8r; d; r0 fixed routingalgorithms timesPgiven fixed function fxr;d (t)g fZr (t) = d0 Xr;d0 (t)g. pointfact map set fxr;d;r0 (t 1); Xr;d0 (t)g 8r; d; r0 full set fxr;d;r0 (t)g 8r; d; r0 ,fxr;d (t)g. Accordingly, xr;d;r0 undergo deterministic evolution. Sincevalues across time set values Xr;d (t) across time, see entire setcomponents ;t undergo deterministic evolution representation, required.evaluating wonderful life utility need group components ;tdisjoint agents . two types agent, types indexedrouter-destination pairs. agent index (r; d), first agent type variableXr;d (t), second agent type Euclidean vector components indexed r 0 ,(xr;d )r0 (t). setting \actions" concerned setting states agentssecond type. Accordingly, learners associated agents second370fiCollective Intelligence, Data Routing Braess' Paradoxtype. Unless explicitly indicated otherwise, implicitly secondtype agent mind whenever refer \agent" use symbol .4.2 ISPA Routing COIN RoutingBased COIN formalism presented Section 3 model described above,present ISPA COIN-based routing algorithms. time step t, ISPA accesswindowed loads time step 1 (i.e., access Zr (t 1) 8r), assumesvalues remain times t. Note large window sizestimes close t, assumption arbitrarily accurate. Using assumption,ISPA, router sends packets along path calculates minimize costsaccumulated packets.COIN-based routing algorithms, contrast, direct accessZr . evaluate WLU agent (r; d) time , algorithm mustestimate (primary members the) associated effect set. means determiningcomponents ; will, dynamics system, changed alteringcomponents vector xr;d( ).first approximation, ignore effects trac changing xr;d;r0 ( ) may\mediated" learning algorithms running system. is,ignore changes arise due effects changing xr;d;r0 ( ) rewards,changes induce changes future training sets, turn get mappedchanges fxr;d;r0 (t)g (and therefore fXr;d (t)g) via learning algorithms runningagents.another approximation, ignore effects mediated routing algorithms'observations state network. is, ignore changes fxr00 ;d0 ;r000 (t)gvarying xr;d ( ) may cause due associated changes state network perceived(r00 ; d0 )'s routing algorithm, changes turn cause algorithm modify routingdecisions accordingly. consider behavior routing algorithms(potentially) directly affected xr;d ( ) (potentially) route packetsthat, time , passed r way d. particular ignore effectsxr;d ( ) fxr00 ;d0 =6 d;r000 (t)g.Since packets routed wave arrive destinations end wave,approximations mean xr00 ;d00 ;r000 (t) estimate xr;d ( )'seffect set wave . ones are, potentially, directlyaffected fxr;d;r0 (t)g \chaining together" sequence xr00 ;d00 ;r000 (t) getpackets xr;d (t) ultimate destination. Due wave nature simulationsthough, xr00 ;d00 ;r000 (t) within 's wave affected xr;d ( ) d00 = d.reasons coding simplicity, concern whether < withingiven wave exclude xr00 ;d00 ;r000 (t) accordingly. words, within 'swave treated equally.one set members xr;d ( )'s effect set fxr00 ;d;r000 (t) 8r00; d; r000 ; 2 ( )g. Notemembers relatively unaffected xr;d ( ) (e.g., r00 farnet away r). simplicity, try determine excludethem. keeping xr00 ;d;r000 (t < ), inclusion extra agents estimateeffect set hurt learnability, general hurt factoredness. Therefore371fiWolpert & Tumerdelay quickly learners determine optimal policies, won't affectquality (for G) policies finally arrived at. Note also trying determinewhether particular xr00 ;d;r000 (t 2 ( )) included xr;d ( )'s effect set wouldmean, part, determining whether packets routed (r; d) would reached r00(r; d) made routing decision different one actually made. wouldnon-trivial exercise, general.contrast case xr00 ;d0 ;r000 (t), Xr00 ;d0 (t) future 'swave affected xr;d (t) also excluded approximationsfar. particular, Xr00 ;d (t) either r00 = r r00 one hop away r1directly affected xr;d (t), 2 [Wi=0 ( + iL)) (cf. definition X variables).simplicity, restrict consideration Xr00 ;d variables routerr, r00 = r.final estimate effect set clearly rather poor | presumably results betterpresented would accrue use accurate effect set. However it'sworth bearing mind \self-stabilizing" nature choice effect sets,used conjunction effect set WLU's. nature mediated learningalgorithms. one assigns utility function two agents, reward oneagent gets determined part one does. modifiesbehavior try increase reward, first agent modifying behaviorway dependent agent does. words, two agents givenWLU estimated other's effect set, ipso factoother's effect set.Using estimate effect set, WLU (; ) given differencetotal cost accrued 's wave agents network cost accruedagents agents sharing 's destination \erased." precisely, agentdestination following effect set WLU's, g; :g; ( )==G( )Xt;r0 ;d0=G(CLC eff ( ))(; )xr0 ;d0 (t) Vr0Vr0Xd00Xd0!XXr0 ;d0 (t)[ Xr0 ;d00 (t) (1t;r0 ;d0(t2[xr0 ;d0 (t)(1W 1i=0 ((t2 ( ))I (d0 = d))+ iL))I (d00 = d)) ]!01XXXX@xr0 ;d0 (t) Vr0 (Xr0 ;d00 (t))xr0 ;d0 (t) Vr0 (Xr0 ;d00 (t))Ad0d00d0 6=dd00 6=dt2( ) r001XX XXX@+xr0 ;d0 (t) [Vr0 (Xr0 ;d00 (t)) Vr0 (Xr0 ;d00 (t))]A(3)000000W1r=6t2[( +iL)X Xi=1(:) indicator function equals 1 argument true, 0 otherwise.allow learner receive feedback concerning actions wave immediatelyfollowing wave rather wait W L time steps, approximate secondsum last equality, one times following 's wave, zero. anotherway view resultant expression, rather approximation effect372fiCollective Intelligence, Data Routing Braess' Paradoxset WLU. view exact WLU approximation effect set,approximation ignores effects future windowed loads clamping current traclevel. Regardless view adopt, presumably better performance could achievedimplement approximation.Given approximation, WLU becomes wave-indexed time-translation-invariantWL \reward function" (WLR):g; ( ;t2( ) )XXt2( );r0d0=Xd0 6=dxr0 ;d0 (t) Vr0 (xr0 ;d0 (t) Vr0 (Xd00Xd00 6=dXr0 ;d00 (t))1Xr0 ;d00 (t))A :(4)Notice trac going router r0 6= r destination d0 6= affects valueWLR agent (r; d). ects fact WLR takes account side-effects(r; d)'s actions agents. Note also r0 -indexed term contributingWLR computed associated router r0 separately, information availablerouter. Subsequently terms propagated network ,much way routing tables updates propagated.Given choice private utility, must next specify COIN-based routingalgorithm collects initial data (in conjunction utility) usedguide initial routing decisions every agent one routing option mustmake. experiments data collected preliminary running ISPA.preliminary stage, routing decisions made using ISPA, resultingactions \scored" using WLR given Equation 3. use ISPA generaterouting decisions initial data since likely practice kind SPArouting algorithm running prior \turning on" COIN algorithm. Alternatelyone generate initial data's routing decisions routers make randomdecisions, implement sequence decisions \sweeps" across gridpossible set actions. data collected stage provides us initialinput-output training sets used machine learning algorithm agent:router-destination agent, inputs identified windowed loads outgoing links,associated WLR values destination question outputs.sucient initial data collected using ISPA, system switches usingCOIN algorithm make subsequent routing decisions. stage, agent routespackets along link estimates (based training set) would provide bestWLR. perform estimation, MB COIN makes use single-nearest-neighboralgorithm learner. algorithm simply guesses output would ensuecandidate input output element training setnearest neighbor (in input space) candidate input.8 words,learner finds training set input-output pair whose input value (loads outgoing links)8. simple learning algorithm, use demonstrate potential practicalfeasibility COIN-based routing algorithm. performance presumably improvedsophisticated learning algorithms (e.g., Q-learning Sutton & Barto, 1998; Watkins & Dayan, 1992)used.373fiWolpert & Tumerclosest would result potential routing decision. learnerassigns WLR associated training data pair estimate WLRwould result said routing decision. WLR values used choose amongpotential routing decisions. input-output data generated algorithmadding training set generated.routing algorithm, routers estimate routing decisions (asected loads individual time steps) affect WLR values (basedmany agents' loads). also possible calculate exactly routing decisions affectrouters' WLR's if, unlike MB COIN, full knowledge loadsagents system. way similar ISPA, router evaluate exactWLR value would ensue candidate actions, assumptionwindowed loads routers one wave futurenow. call algorithm directly maximizing WLR (an algorithm call fullknowledge COIN, FK COIN).Note assumption behind FK COIN, action chooses wave ( )maximizes WLR also maximize world reward. words, WL rewardperfectly factored respect (wave-indexed) world reward, even though associatedutilities related way (due inaccuracy estimate effect set). Duefactoredness, FK COIN equivalent load balancing world rewards. SinceLB general results inferior performance compared LB time, since FKCOIN equivalent LB, one might expect performance suboptimal. Intuitively,suboptimality ects fact one choose action regardeffect current reward, also concern reward future waves.language COIN framework, suboptimality viewed restatementfact inexactly estimated effect set, system perfectly factored.learning algorithm MB COIN described extraordinarily crude. addition, associated scheme choosing action purely exploitative, explorationwhatsoever. Rather choose particular sophisticated scheme tunefit simulations, emulated using sophisticated algorithms general.modifying MB COIN algorithm occasionally FK COIN determinerouter's action rather purely greedy learner outlined above. steering parameter discussed Section 5.5 determines often routing decision basedMB COIN opposed FK COIN.5. Simulation Resultspractice, dicult implement either FK COIN LB. section useexperiments investigate behavior algorithms conceivably used practice.precisely, based model routing algorithms discussed above, performed simulations compare performance ISPA MB COIN across varietynetworks, varying size five eighteen routers. cases trac insertednetwork regular, non-stochastic manner sources. results reportaveraged 20 runs. report error bars lower 0:05.Sections 5.1 - 5.4 analyze trac patterns four networks ISPA suffersBraess' paradox. contrast, MB COIN almost never falls prey paradox374fiCollective Intelligence, Data Routing Braess' Paradoxnetworks (or networks investigated MB COIN significantlysusceptible Braess' paradox). Section 5.5 discuss effect MBCOIN's performance \steering" parameter determines intelligenceMB COIN.95.1 Bootes Networkfirst network type investigate shown Figure 3. many senses trivialnetwork, Net A, sources even choices make. loads introduced sources change time listed Tables 1 2, alongperformances algorithms.@D@V1@@@yV2@@AA@y@V0AyV0AAy@yS1S2y@D@V1@@@yV2@@AAyV3 AyV0@yV0@@yS1S2 AyNetNet BFigure 3: Bootes NetworkLoads (S1 ; S2 ) Net1,1B2,1B2,2B4,2BISPA MB COIN6.356.358.355.938.078.0710.407.889.559.5510.889.7110.4110.4111.5510.41Table 1: Average Per Packet Cost BOOTES2 networks V1 = 10 + log(1 + x) ;4x2 ; V3 = log(1 + x) .V2=MB COIN results identical ISPA results absence additionallink (Network A). However, Braess' paradox arises ISPA, additionnew link network B degrades performance ISPA six eight tracregimes load-to-cost functions investigated. MB COIN hand9. Sections 5.1 - 5.4, steering parameter set 0.5.375fiWolpert & TumerLoads (S1 ; S2 ) Net ISPA MB COIN1,130.3530.35B 20.3520.352,235.5535.55B 40.5534.994,241.0741.07B 50.4744.136,344.6344.63B 51.4044.63Table 2: Average Per Packet Cost BOOTES4 network10x ; V3 = log(1 + x) .V1= 50 + log(1 + x) ;V2=hurt addition new link once, manages gainfully exploit seven times.behavior analyzed infinitesimally, MB COIN either uses additionallink eciently chooses ignore seven cases. Moreover, MB COIN'sperformance additional link always better ISPA's. example, addingnew link causes degradation performance much 30 % (loads = f2; 1g)ISPA, whereas load vector MB COIN performance improves 7 %.5.2 Hex Networksection revisit network first discussed Section 2.1 (redrawn Figure 4include dummy agents). Table 3 give full results load-to-delay functionsdiscussed section. use load-to-cost functions qualitatively similardiscussed Section 2.1, incorporate non-linearities better representreal router characteristics. load-to-cost function associated results reportedTable 4.V2V0V1"ybDb""bby""byV1yV0bb"yV2"bb ""b"ySNetV2V0V1"ybDb""bb"y"byV1Vy3 yV0yb"yV2bb"bb"yS""Figure 4: Hex networkNet Bnetwork demonstrates addition new link may beneficiallow trac cases, leads bottlenecks higher trac regimes. ISPA although376fiCollective Intelligence, Data Routing Braess' Paradoxper packet cost loads 1 2 drop drastically new link added, perpacket cost increases higher loads. MB COIN hand uses newlink eciently. Notice MB COIN's performance slightly worseISPA absence additional link. caused MB COIN uselearner estimate WLU values potential actions whereas ISPA simplydirect access information needs (costs link).Load Net ISPA MB COIN155.5055.56B 31.0031.00261.0061.10B 52.0051.69366.5066.65B 73.0064.45472.0072.25B 87.3773.41Table 3: Average Per Packet Cost HEX network V1 = 50+ x ;.V2= 10x ;V3= 10+ xLoad Net ISPA MB COIN155.4155.44B 20.6920.69260.6960.80B 41.1041.10365.9266.10B 61.3959.19471.1071.41B 81.6169.88Table 4: Average Per Packet Cost HEX network10x ; V3 = log(1 + x) .V1= 50 + log(1 + x) ;V2=5.3 Butter Networknext network investigate shown Figure 5. extension simplenetwork discussed Section 5.1. doubled size networkthree sources route packets two destinations (packets originatingS1 go D1 , packets originating S2 S3 go D2 ). Initially two halvesnetwork minimal contact, addition extra link two sourcestwo two halves network share common router potential shortest path.377fiWolpert & TumerTTyD2TTTTyTTyV1V2V3yV1V0 TyV0 Ty@@@yS3S1 TyS2D1TTyD2TTTTyTTyV1V2V3V0 Ty V3 V0 Tyy@V1@S2 Ty @yS3S1D1NetNet BFigure 5: Butter NetworkTable 5 presents two sets results: first present results uniform tracthree sources, results asymmetric trac. first case, Braess'paradox apparent ISPA: adding new link beneficial network lowload levels average per packet cost reduced nearly 20%, deleterioushigher levels. MB COIN, hand, provides benefits added linklow trac levels, without suffering deleterious effects higher load levels.Loads (S1 ; S2 ; S3 ) Net ISPA MB COIN1,1,1112.1112.7B92.192.32,2,2123.3124.0B 133.3122.54,4,4144.8142.6B 156.5142.33,2,181.882.5B99.581.06,4,296.094.1B 105.394.09,6,3105.598.2B 106.798.8Table 5: Average Per Packet Cost BUTTERFLY network V1 = 50+ log(1+ x) ;10x ; V3 = log(1 + x).V2=asymmetric trac patterns, added link causes drop performanceISPA, especially low overall trac levels. true MB COIN. Notice alsohigh, asymmetric trac regime, ISPA performs significantly worseMB COIN even without added link, showing bottleneck occurs right sidenetwork alone (similar Braess' paradox observed Section 5.1).378fiCollective Intelligence, Data Routing Braess' Paradox5.4 Ray Networknetworks trac regimes discussed far sources routersone routing option. final network investigate larger networknumber routers multiply options significantly higher previousnetworks. Figure 6 shows initial network (Net A) \augmented" network (NetB), new links added. original network relatively choicesrouters, packets directed toward destinations along \conduits." newlinks added augmented networks provide new choices (crossing patterns)could beneficial certain original conduits experience large costs.V2V0V1bDb1 ""ybDb2"y""b"by" V1 y"" bbyV1 bbyV2"V0yV0yV0yVyVV2JJJJ 21JJJ%yV3V3 Jeee%%e%S1S2NetV2V0V1"ybDb1 ""ybDb2"""bb"yc" V1 "y" bbyV1 b#byV2yVc3 cy yV0 V0 #y#V3 yV0Vc2cyc ##yV#2yVJJc # JJ1J#c#c JV3 Jeye #yV3 V3cy %J%yV3%e%eS2S1Figure 6: Ray networkNet BTable 6 shows simulation results networks (S1 S2 send packets D1D2 respectively). low load levels ISPA MB COIN use new linkseffectively, although MB COIN performs slightly worse. mainly causeddiculty encountered simple learner (single nearest neighbor algorithm) quicklylearning trac patterns large network. Unlike ISPA however, MB COINavoids Braess' paradox cases except high trac regime. Moreover, eventhere, effect significantly milder encountered ISPA.5.5 Steering MB COINfinal aspect COIN-based routing investigate impact choicevalue steering parameter. parameter controls amount explorationalgorithm performs determines \intelligence" MB COIN estimatingsurface directly calculated FK COIN. Figures 7 - 8, FK COIN resultscorrespond setting steering parameter MB COIN 1:0. providesupper bound performance achieved though MB COIN.HEX network (Figure 7), performance worst setting MB COIN,corresponds steering, comparable ISPA. contrast, moderate steering379fiWolpert & TumerLoads S1 andS2 ) Net ISPA MB COIN2,2143.6143.7B 124.4126.93,3154.6154.9B 165.5151.04,4165.4166.0B 197.7165.66,6186.7187.4B 205.1191.6Table 6: Average Per Packet Cost RAY network10x ; V3 = 10 + log(1 + x).= 50 + log(1 + x) ;V2=18080Per Packet DelayPer Packet Delay85V1ISPAFK COINMB COIN757065ISPAFK COINMB COIN17016015014000.1 0.2 0.3 0.4Steering Parameter0.500.1 0.2 0.3 0.4Steering Parameter0.5Figure 7: Impact steering Hex4 (left) Ray4 (right) networks.(0.5) results similar FK COIN, learner informationwork (arising extra parts input space represented trainingset due occasional use FK COIN), bridges gap suboptimalalgorithm susceptible Braess' paradox one eciently avoids paradox.RAY network (Figure 7), value steering parameter critical.steering all, MB COIN performs poorly network | even worseISPA. surprising many routing choices affectperformance, simple memory-based learner needs proper \seeding" ableperform well. Even minimal steering though, MB COIN quickly outperformsISPA.Finally, Butter Bootes networks (Figure 8) MB COIN needslittle steering perform well. Although Butter network performanceMB COIN improves slightly information, significantly better ISPAacross board.380fi105Per Packet DelayPer Packet DelayCollective Intelligence, Data Routing Braess' ParadoxISPAFK COINMB COIN1009540ISPAFK COINMB COIN359000.1 0.2 0.3 0.4Steering Parameter0.500.1 0.2 0.3 0.4Steering Parameter0.5Figure 8: Impact steering Butter y4 (left) Bootes4 (right) networks.6. ConclusionEffective routing network fundamental problem many fields, including datacommunications transportation. Using shortest path algorithm (SPA)routers determine router's decisions popular approach problem. Howevercertain circumstances suffers number undesirable effects. One effectBraess' paradox, pattern introduced trac network, increasingcapacity network results lower overall throughput, due harmful sideeffects decisions made router trac rest system. Eventheoretical load-balancing algorithm, addresses effects producedecisions optimal single moment time, still suffer side-effectsresult sub-optimal performance. effects extend across time(i.e., affects performance later) well space.Collective Intelligence approach novel way controlling distributed systemsavoid deleterious side-effects routing decisions. central idea learningalgorithms control autonomous agents constitute overall distributed system.Collective Intelligence (COIN), central issue determine personalobjectives assigned autonomous agents. One wants choosegoals greedy pursuit goals associated learning algorithms leadsdesirable behavior overall system. paper summarized mathematicsdesigning goals derived routing algorithm based mathematics.ran computer simulations compare COIN-based algorithm ideal SPA(whose performance upper-bounds real-world SPA's) routing. COIN-based algorithm severely handicapped. estimation \effect sets" used algorithmexceedingly crude. addition, learning algorithms agents particularlyunsophisticated, therefore able effectively maximize individual performances. contrast, ideal SPA access information concerning statesystem (real-world-implementable) COIN did, information real-worldSPA could access.381fiWolpert & TumerDespite biases favor ideal SPA, experiments ideal SPA inducedaverage costs much 32 % higher COIN-based algorithm. FurthermoreCOIN-based algorithm almost always avoided Braess' paradox seriously diminishedperformance SPA.techniques also successfully employed many other, non-routingdomains, coordination autonomous rovers (Tumer, Agogino, & Wolpert, 2002),combinatorial optimization, \congestion games" (Wolpert & Tumer, 2001), controldata-upload planet (Wolpert, Sill, & Tumer, 2001). conclude resultstechniques field collective intelligence highly effective designingutility functions members MAS ensure work coordinatedecient manner optimize overall performance. currently investigating extensionsCOIN algorithm involve novel goals agents, goals \learnable" learning algorithms. also expanding simulations larger networksusing commercial event driven simulator. Future work focus making approximation current trac levels affect future windowed loads (Equation 3).also involve investigating better estimates effect sets, particular includingagents destination one's effect set, generally using\fine-grained" representation agents, example including packet's originatingsource, allow fine-grained effect set (and resultant WLU).Acknowledgmentsauthors thank Joe Sill reviewers helpful comments.Appendix A. Suboptimality Load-Balancingappendix present existence proof suboptimality Load-Balancing(LB) explicitly constructing situation conventional LB suboptimal.Consider system discrete time, source agent X considerationmust route one packet (fixed) destination time step. Presumetrac source agent X enters agents X sends to,trac coming X sole source costs associated X 's outbound links. Let(t) number times agent sent packet link W time stepspreceding t, take s(t) = A; B mean router uses link B , respectively,time t. Model queue backups like cost send packet linktime CA (S (t)=W ), cost router instead send packetlink B CB (1 (t)=W ), simplicity assume CA (:) CB (:)monotonically increasing functions arguments.Restrict attention agents work s(t) = iff (t) k realvalued threshold k. LB algorithm choose s(t) = iff CA (S (t)=W ) CB (1(t)=W ). LB algorithm's behavior indistinguishable kind thresholdalgorithm, k set CA (k=W ) = CB (1 k=W ). (We implicitly assume CA (:)CB (:) chosen solution exists 1 < k < W 1.) question382fiCollective Intelligence, Data Routing Braess' Paradoxk optimize total averaged cost across time, particular kkLB , k LB uses.go one time step next, routing decision made W time stepsago drops computation (t), routing decision made newlyincluded. general, (t + 1) = (t) + 1 router used time used link Btime W time steps past. hand, (t + 1) = (t) 1 routerused B used W time steps ago, (t + 1) = (t) routing decisionmade routing decision W time steps ago. general, (t)change -1, 0, +1 go one time step next.Consider cases 1 < k < W 1, eventually router must choose A,subsequent time router switches B . time s(t 1) =s(t ) = B . implies (t 1) k; (t ) > k. Define value (t 1) k .Note (t ) = k + 1, k 1 < k k.time t0 , (t0 ) = k + 1, s(t0 + 1) = B , possible next values(t0 + 1) = k (t0 + 1) = k + 1, depending old decision s(t W ) getsdropped window. Similarly, (t0 ) = k , s(t0 + 1) = A, possiblenext values (t0 + 1) = k (t0 + 1) = k + 1, depending old decisiondropped. see (t0 ) 2 fk ; k + 1g, stays forever.means relationship k k , interval Wconsecutive time steps subsequent , number packets sent along router Xmust 2 (k 1; k +1]. (Note possible send k +1 packets along A, k 1packets. Therefore number sent along B must 2 [W (k + 1); W (k 1)).time packet sent along cost incurred cost link average traclevel (t)=W , CA (S (t)=W ). Similarly, time link B chosen, cost incurredCB (1 (t)=W ). Since (t) 2 fk ; k + 1g, CA (:) CB (:) monotonicallyincreasing, cost sending packet link 2 (CA ((k 1)=W ); CA ((k + 1)=W ],sending link B contained [CB (1 (k +1)=W ); CB (1 (k 1)=W )).know choice must average frequency (across time)k =W (k + 1)=W . Similarly, B average frequency (1 (k + 1)=W )1 k =W . Accordingly, average cost boundedk+1kk 1k + 1CA+ 1CB 1;(5)WWWWfirst term provides maximum possible average cost using link A,second term independently provides maximum possible average cost using linkB . Note actual cost lower since two frequencies bound, oneone B , cannot values indicated. k 1 < k k since+1 , upper bound bounded1 kW1 = 1 + W2 kWk+1WCAk+1W+1+2k+1WWCB1+2k+1WW:(6)optimal k result average cost lower minimum kupper bound average cost, given Equation 6. average cost optimalk bounded minimum k upper bound. Lable argminEquation 6 k'.383fiWolpert & TumerSince values k besides kLB result behavior equivalent LB,suce simply test k' = kLB . Instead let us evaluate lower bounds similarfashion evaluated upper bounds. Using average frequencies discussed above,average cost bounded by:k 11kk+1kCA+ 1CB 1;(7)WWWWWfirst term provides minimum possible average cost using link A,second term provides minimum possible average cost using link B . Again,k 1 < k k , term Equation 7 bounded1kWCA1kW+12W1kWCB121kWparticular bound holds average cost LB algorithm:kLB 1kLB 12 kLB 12 kLBCA+ 1CB 1WWWWW(8):WW1;(9)kLB satisfies CA (kLB =W ) = CB (1 kLB =W ).appropriate choice CA (:) CB (:), ensure lower boundcost LB algorithm (Equation 9 evaluated k = kLB ) higher upperbound average cost incurred optimal algorithm (the minimum k Equation 6). is, best possible average cost achieved load balancing worseworst average cost could arise optimal routing strategy.establishes LB engage optimal routing.Example: Let CA (x) = x2 CB (x) = x. Balancing loads B | setting2CpA (S (t)=W ) = CB (1 (t)=W ) | results (S (t)=W ) = 1 (t)=W , leading kLB =W =5 1 = :618. W = 1000, associated lower bound average cost (Equation 9)2(:618)3 + (:998 :618)2 = :380. hand, CA CB given above, Eq 6k+1 2( k+1 )3 + (1 + 2) . Differentiating respect k setting resultWk0WW13W1p28+48=Wzero leads=. window size W = 1000, yieldsW +6k 0 =W = :548, different result kLB . Plugging Equation 6, upper boundcost k0 (:549)3 + (1:002 :549)2 = :371, less :380.ReferencesAhuja, R. K., Magnanti, T. L., & Orlin, J. B. (1993). Network Flows. Prentice Hall, NewJersey.Bass, T. (1992). Road ruin. Discover, 13 (5), 56{61.Bertsekas, D., & Gallager, R. (1992). Data Networks. Prentice Hall, Englewood Cliffs, NJ.Bonabeau, E., Henaux, F., Guerin, S., Snyders, D., Kuntz, P., & Theraulaz, G. (1999a).Routing telecommunications networks \smart" and-like agents. (pre-print).Bonabeau, E., Sobkowski, A., Theraulaz, G., & Deneubourg, J.-L. (1999b). Adaptive taskallocation inspired model division labor social insects. (pre-print).384fiCollective Intelligence, Data Routing Braess' ParadoxBoyan, J. A., & Littman, M. (1994). Packet routing dynamically changing networks:reinforcement learning approach. Advances Neural Information ProcessingSystems - 6, pp. 671{678. Morgan Kaufman.Choi, S. P. M., & Yeung., D. Y. (1996). Predictive Q-routing: memory based reinforcementlearning approach adaptive trac control. Touretzky, D. S., Mozer, M. C., &Hasselmo, M. E. (Eds.), Advances Neural Information Processing Systems - 8, pp.945{951. MIT Press.Claus, C., & Boutilier, C. (1998). dynamics reinforcement learning cooperativemultiagent systems. Proceedings Fifteenth National Conference ArtificialIntelligence, pp. 746{752, Madison, WI.Cohen, J. E., & Jeffries, C. (1997). Congestion resulting increased capacity singleserver queueing networks. IEEE/ACM Transactions Networking, 5 (2), 305{310.Cohen, J. E., & Kelly, F. P. (1990). paradox congestion queuing network. JournalApplied Probability, 27, 730{734.Crowe, B. L. (1969). tragedy commons revisited. Science, 166, 1103{1107.Deo, N., & Pang, C. (1984). Shortest path algorithms: Taxonomy annotation. Networks,14, 275{323.Dijkstra, E. (1959). note two problems connection graphs. Numeriche Mathematics, 1 (269-171).Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press, Cambridge, MA.Glance, N. S. (1993). Dynamics Expectations. Ph.D. thesis, Stanford University.Glance, N. S., & Hogg, T. (1995). Dilemmas computational societies. Lesser, V.(Ed.), Proc. 1st International Conference Multi-Agent Systems (ICMAS95),pp. 117{124, Menlo Park, CA. AAAI Press.Hardin, G. (1968). tragedy commons. Science, 162, 1243{1248.Heusse, M., Snyers, D., Guerin, S., & Kuntz, P. (1998). Adaptive agent-driven routingload balancing communication networks. Advances Complex Systems, 1,237{254.Hogg, T. (1995). Social dilemmas computational ecosystems. ProceedingsFourteenth International Joint Conference Artificial Intelligence, pp. 711{716, SanMateo, CA. Morgan Kaufmann.Hu, J., & Wellman, M. P. (1998a). Multiagent reinforcement learning: Theoretical framework algorithm. Proceedings Fifteenth International ConferenceMachine Learning, pp. 242{250.Hu, J., & Wellman, M. P. (1998b). Online learning agents dynamic multiagent system. Proceedings Second International Conference AutonomousAgents, pp. 239{246.Huberman, B. A., & Hogg, T. (1988). behavior computational ecologies.Ecology Computation, pp. 77{115. North-Holland.385fiWolpert & TumerHuberman, B. A., & Lukose, R. M. (1997). Social dilemmas internet congestion. Science,277 (5325), 535{537.Huberman, B. A., & Hogg, T. (1993). emergence computational ecologies. Nadel,L., & Stein, D. (Eds.), 1992 Lectures Complex Systems, Vol. V SFI StudiesSciences Complexity, pp. 185{205. Addison-Wesley, Reading, MA.Huhns, M. E. (Ed.). (1987). Distributed Artificial Intelligence. Pittman, London.Jennings, N. R., Sycara, K., & Wooldridge, M. (1998). roadmap agent researchdevelopment. Autonomous Agents Multi-Agent Systems, 1, 7{38.Kaelbing, L. P., Littman, M. L., & Moore, A. W. (1996). Reinforcement learning: survey.Journal Artificial Intelligence Research, 4, 237{285.Kelly, F. P. (1996). Modeling communication networks, present future. PhilosophicalTrends Royal Society London A, 354, 437{463.Korilis, Y. A., Lazar, A. A., & Orda, A. (1995). Architecting noncooperative networks.IEEE Journal Selected Areas Communications, 13 (8), 1241{1251.Korilis, Y. A., Lazar, A. A., & Orda, A. (1997a). Achieving network optima using Stackelberg routing strategies. IEEE/ACM Transactions Networking, 5 (1), 161{173.Korilis, Y. A., Lazar, A. A., & Orda, A. (1997b). Capacity allocation noncooperativerouting. IEEE Transactions Automatic Control, 42 (3), 309{325.Korilis, Y. A., Lazar, A. A., & Orda, A. (1999). Avoiding Braess paradox noncooperative networks. Journal Applied Probability, 36, 211{222.Kumar, S., & Miikkulainen, R. (1997). Dual reinforcement Q-routing: on-line adaptiverouting algorithm. Artificial Neural Networks Engineering, Vol. 7, pp. 231{238.ASME Press.Littman, M. L., & Boyan, J. (1993). distributed reinforcement learning scheme networkrouting. Proceedings 1993 International Workshop Applications NeuralNetworks Telecommunications, pp. 45{51.Marbach, P., Mihatsch, O., Schulte, M., & Tsisiklis, J. (1998). Reinforcement learningcall admission control routing integrated service networks. AdvancesNeural Information Processing Systems - 10, pp. 922{928. MIT Press.Orda, A., Rom, R., & Shimkin, N. (1993a). Competitive routing multiuse communicationnetworks. IEEE/ACM Transactions Networking, 1 (5), 510{521.Orda, A., Rom, R., & Sidi, M. (1993b). Minimum delay routing stochastic networks.IEEE/ACM Transactions Networking, 1 (2), 187{198.Sandholm, T., Larson, K., Anderson, M., Shehory, O., & Tohme, F. (1998). Anytime coalition structure generation worst case guarantees. Proceedings FifteenthNational Conference Artificial Intelligence, pp. 46{53.Sandholm, T., & Lesser, V. R. (1995). Issues automated negotiations electronic commerce: extending contract net protocol. Proceedings Second InternationalConference Multi-Agent Systems, pp. 328{335. AAAI Press.386fiCollective Intelligence, Data Routing Braess' ParadoxSchaerf, A., Shoham, Y., & Tennenholtz, M. (1995). Adaptive load balancing: studymulti-agent learning. Journal Artificial Intelligence Research, 162, 475{500.Shenker, S. J. (1995). Making greed work networks: game-theoretic analysis switchservice disciplines. IEEE Transactions Networking, 3 (6), 819{831.Stone, P. (2000). TPOT-RL applied network routing. Proceedings SeventeenthInternational Machine Learning Conference, pp. 935{942. Morgan Kauffman.Subramanian, D., Druschel, P., & Chen, J. (1997). Ants reinforcement learning: casestudy routing dynamic networks. Proceedings Fifteenth InternationalConference Artificial Intelligence, pp. 832{838.Sutton, R. S. (1988). Learning predict methods temporal differences. MachineLearning, 3, 9{44.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press,Cambridge, MA.Sycara, K. (1998). Multiagent systems. AI Magazine, 19 (2), 79{92.Tumer, K., Agogino, A., & Wolpert, D. (2002). Learning sequences actions collectivesautonomous agents. Proceedings First International Joint ConferenceAutonomous Agents Multi-Agent Systems, Bologna, Italy.Tumer, K., & Wolpert, D. H. (2000). Collective intelligence Braess' paradox.Proceedings Seventeenth National Conference Artificial Intelligence, pp. 104{109, Austin, TX.Watkins, C., & Dayan, P. (1992). Q-learning. Machine Learning, 8 (3/4), 279{292.Wolpert, D. H., Kirshner, S., Merz, C. J., & Tumer, K. (2000). Adaptivity agent-basedrouting data networks. Proceedings fourth International ConferenceAutonomous Agents, pp. 396{403.Wolpert, D. H., Sill, J., & Tumer, K. (2001). Reinforcement learning distributed domains:Beyond team games. Proceedings Seventeenth International Joint ConferenceArtificial Intelligence, pp. 819{824, Seattle, WA.Wolpert, D. H., & Tumer, K. (1999). Introduction Collective Intelligence. Tech.rep. NASA-ARC-IC-99-63, NASA Ames Research Center. URL:http://ic.arc.nasa.gov/ic/projects/coin pubs.html. appear Handbook Agent Technology,Ed. J. M. Bradshaw, AAAI/MIT Press.Wolpert, D. H., & Tumer, K. (2001). Optimal payoff functions members collectives.Advances Complex Systems, 4 (2/3), 265{279.Wolpert, D. H., Tumer, K., & Frank, J. (1999). Using collective intelligence route internettrac. Advances Neural Information Processing Systems - 11, pp. 952{958. MITPress.Wolpert, D. H., Wheeler, K., & Tumer, K. (2000). Collective intelligence controldistributed dynamical systems. Europhysics Letters, 49 (6).387fiJournal Artificial Intelligence Research 16 (2002) 259-292Submitted 9/01; published 4/02Efficient Reinforcement Learning UsingRecursive Least-Squares MethodsXin XuHan-genDewen HuXUXIN_MAIL@263.NETHEHANGEN@CS.HN.CNDWHU@NUDT.EDU.CNDepartment Automatic ControlNational University Defense TechnologyChangSha, Hunan, 410073, P.R.ChinaAbstractrecursive least-squares (RLS) algorithm one well-known algorithms usedadaptive filtering, system identification adaptive control. popularity mainly duefast convergence speed, considered optimal practice. paper, RLS methodsused solve reinforcement learning problems, two new reinforcement learningalgorithms using linear value function approximators proposed analyzed. twoalgorithms called RLS-TD( ) Fast-AHC (Fast Adaptive Heuristic Critic), respectively.RLS-TD( ) viewed extension RLS-TD(0) =0 general 0 1,multi-step temporal-difference (TD) learning algorithm using RLS methods. convergenceprobability one limit convergence RLS-TD( ) proved ergodic Markovchains. Compared existing LS-TD( ) algorithm, RLS-TD( ) advantagescomputation suitable online learning. effectiveness RLS-TD( )analyzed verified learning prediction experiments Markov chains wide rangeparameter settings.Fast-AHC algorithm derived applying proposed RLS-TD( ) algorithmcritic network adaptive heuristic critic method. Unlike conventional AHC algorithm,Fast-AHC makes use RLS methods improve learning-prediction efficiency critic.Learning control experiments cart-pole balancing acrobot swing-up problemsconducted compare data efficiency Fast-AHC conventional AHC.experimental results, shown data efficiency learning control also improvedusing RLS methods learning-prediction process critic. performanceFast-AHC also compared AHC method using LS-TD( ). Furthermore,demonstrated experiments different initial values variance matrix RLS-TD( )required get better performance learning prediction also learning control.experimental results analyzed based existing theoretical work transientphase forgetting factor RLS methods.1. Introductionrecent years, reinforcement learning (RL) active research area machinelearning also control engineering, operations research robotics (Kaelbling et al.,1996;Bertsekas, et al.,1996; Sutton Barto,1998; Lin,1992). computational approach2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiXU, HE, & HUunderstand automate goal-directed learning decision-making, without relyingexemplary supervision complete models environment. RL, agent placedinitial unknown environment receives evaluative feedback environment.feedback called reward reinforcement signal. ultimate goal RL learn strategyselecting actions expected sum discounted rewards maximized.Since lots problems real world sequential decision processes delayedevaluative feedback, research RL focused theory algorithms learningsolve optimal control problem Markov decision processes (MDPs) provideelegant mathematical model sequential decision-making. operations research, many resultspresented solve optimal control problem MDPs model information.However, reinforcement learning, model information assumed unknown,different methods studied operations research dynamic programming.dynamic programming, two elemental processes, policy evaluation process policy improvement process, respectively. RL, two similar processes.One called learning prediction called learning control. goal learningcontrol estimate optimal policy optimal value function MDP without knowingmodel. Learning prediction aims solve policy evaluation problem stationary-policyMDP without prior model regarded sub-problem learning control.Furthermore, RL, learning prediction different supervised learning. pointedSutton (1988), prediction problems supervised learning single-step predictionproblems reinforcement learning multi-step prediction problems. solvemulti-step prediction problems, learning system must predict outcomes depend futuresequence decisions. Therefore, theory algorithms multi-step learning predictionbecome important topic RL much research work done literature (Sutton,1988; Tsitsiklis Roy, 1997).Among proposed multi-step learning prediction methods, temporal-difference (TD)learning (Sutton, 1988) one popular methods. studied applied earlyresearch machine learning, including celebrated checkers-playing program (Minsky, 1954;Samuel, 1959). 1988, Sutton presented first formal description temporal- differencemethods TD( ) algorithm (Sutton,1988). Convergence results established tabulartemporal-difference learning algorithms cardinality tunable parametersstate space (Sutton, 1988; Watkins,et al.,1992; Dayan,et al., 1994; Jaakkola, etal.,1994). Since many real-world applications large infinite state space, value functionapproximation (VFA) methods need used cases. combined nonlinearvalue function approximators, TD( ) guarantee convergence several resultsregarding divergence reported literature (Tsitsiklis Roy,1997). TD( )linear function approximators, also called linear TD( ) algorithms, several convergenceproofs presented. Dayan (1992) showed convergence mean linear TD( )algorithms arbitrary 0 1 . Tsitsiklis Roy (1994) proved convergencespecial class TD learning algorithms, known TD(0), Tsitsiklis Roy (1997),extended early results general linear TD( ) case proved convergenceprobability one.linear TD( ) algorithms rules updating parameters similargradient-descent methods. However, gradient-learning methods, step-size schedule mustcarefully designed guarantee convergence also obtain good performance.260fiEFFICIENT REINFORCEMENT LEARNING USING RLS METHODSaddition, inefficient use data slows convergence algorithms. Basedtheory linear least-squares estimation, Brartke Barto (1996) proposed twotemporal-difference algorithms called Least-Squares TD(0) algorithm (LS-TD(0))Recursive Least- Squares TD(0) algorithm (RLS-TD(0)), respectively. LS-TD(0) RLS-TD(0)efficient statistical sense conventional linear TD( ) algorithmseliminate design step-size schedules. Furthermore, convergence LS-TD(0)RLS-TD(0) provided theory. two algorithms viewedleast-squares versions conventional linear TD(0) methods. However, shownliterature, TD learning algorithms TD( ) 0< <1 update predictions basedestimates multiple steps efficient Monte-Carlo methods well TD(0).employing mechanism eligibility traces, determined , TD( ) algorithms0< <1 extract information historical data. Recently, class lineartemporal-difference learning algorithms called LS-TD( ) proposed Boyan(1999,2002), least-squares methods employed compute value-function estimationTD( ) 0 1. Although LS-TD( ) efficient TD( ), requires muchcomputation per time-step online updates needed number state featuresbecomes large.system identification, adaptive filtering adaptive control, recursive least-squares(RLS) (Young,1984; Ljung, 1983; Ljung,1977) method, commonly used reducecomputational burden least-squares methods, suitable online estimation control.Although RLS-TD(0) makes use RLS methods, employ mechanismeligibility traces. Based work Tsitsiklis Roy (1994, 1997), Boyan (1999,2002)motivated ideas, new class temporal-difference learning methods, calledRLS-TD( ) algorithm, proposed analyzed formally paper. RLS-TD( ) superiorconventional linear TD( ) algorithms makes use RLS methods improvelearning efficiency statistical point view eliminates step-size schedules.RLS-TD( ) mechanism eligibility traces viewed extensionRLS-TD(0) =0 general 0 1. convergence probability 1 RLS-TD( )proved ergodic Markov chains limit convergence also analyzed. learningprediction experiments Markov chains, performance RLS-TD( ) TD( ) wellLS-TD( ) compared, wide range parameter settings tested. addition, influence initialization parameters RLS-TD( ) also discussed. observedrate convergence influenced initialization variance matrix,phenomenon investigated theoretically adaptive filtering (Moustakides, 1997; Haykin, 1996).analyzed following sections, two benefits extensionRLS-TD(0) RLS-TD( ). One value (0 1) still affect performanceRLS-based temporal-difference algorithms. Although RLS-TD( ), rateconvergence mainly influenced initialization variance matrix, boundapproximation error dominantly determined parameter . smallest error boundobtained =1 worst bound obtained =0. bounds suggestvalue selected appropriately obtain best approximation error. secondbenefit RLS-TD( ) suitable online learning LS-TD( ) sincecomputation per time-step reduced O(K3) O(K2), K number statefeatures.Adaptive-Heuristic-Critic (AHC) learning algorithm class reinforcement learning261fiXU, HE, & HUmethods actor-critic architecture used solve full reinforcement learninglearning control problems. applying RLS-TD( ) algorithm critic, Fast-AHCalgorithm proposed paper. Using RLS methods critic, performance learningprediction critic improved learning control problems solvedefficiently. Simulation experiments learning control cart-pole balancing problemswing-up acrobot conducted verify effectiveness Fast-AHC method.comparing conventional AHC methods use TD( ) critic, demonstratedFast-AHC obtain higher data efficiency conventional AHC methods. Experimentsperformance comparisons AHC methods using LS-TD( ) Fast-AHC alsoconducted. learning control experiments, also illustrated initializing constantvariance matrix RLS-TD( ) influences performance Fast-AHC different valuesconstant selected get better performance different problems.results analyzed based theoretical work transient phase RLS methods.paper organized follows. Section 2, introduction previous lineartemporal-difference algorithms presented. Section 3, RLS-TD( ) algorithm proposedconvergence (with probability one) proved. Section 4, simulation examplevalue-function prediction absorbing Markov chains presented illustrate effectivenessRLS-TD( ) algorithm, different parameter settings different algorithmsincluding LS-TD( ) studied. Section 5, Fast-AHC method proposedsimulation experiments learning control cart-pole balancing acrobotconducted compare Fast-AHC conventional AHC method wellLS-TD( )-based AHC method. simulation results presented analyzed detail.last section contains concluding remarks directions future work.2. Previous Work Linear Temporal-Difference Algorithmssection, brief discussion conventional linear TD( ) algorithm RLS-TD(0)well LS-TD( ) algorithm given. First all, mathematical notationspresented follows.Consider Markov chain whose states lie finite countable infinite space S. statesMarkov chain indexed {1,2,,n}, n possibly infinite. Althoughalgorithms results paper applicable Markov chains general state space,discussion paper restricted within cases countable state spacesimplify notation. extension Markov chains general state space requirestranslation matrix notation operator notation.Let trajectory generated Markov chain denoted {xt |t=0,1,2,; xt S}.Thedynamics Markov chain described transition probability matrix P whose (i,j)-thentry, denoted pij, transition probability xt+1=j given xt=i. state transitionxt xt+1, scalar reward rt defined. value function state defined follows:V (i ) = E{ rt x 0 = i}(1)=00< 1 discount factor.TD( ) algorithm, two basic mechanisms temporal difference262fiEFFICIENT REINFORCEMENT LEARNING USING RLS METHODSeligibility trace, respectively. Temporal differences defined differencestwo successive estimations following form.~~= rt + Vt ( xt +1 ) Vt ( xt )(2)~xt+1 successive state xt, V ( x) denotes estimate value function V(x) rtreward received state transition xt xt+1.Eligibility trace viewed algebraic trick improve learning efficiencywithout recording data multi-step prediction process. trick based ideausing truncated return Markov chain. temporal-difference learning eligibilitytraces, n-step truncated return defined~Rtn = rt + rt +1 + ... + n 1 rt + n 1 + nVt ( + n )(3)absorbing Markov chain whose length T, weighted average truncated returns1Rt = (1 )n1 Rtn + 1 RT(4)n =10 1 decaying factor RT= rt + rt +1 + ... + rT Monte-Carlo returnterminal state. step TD( ) algorithm, update rule value functionestimation determined weighted average truncated returns defined above.corresponding update equation~~Vt ( ) = ( Rt Vt ( ))(5)learning factor.update equation (5) used whole trajectory Markov chainobserved. realize incremental online learning, eligibility traces defined statefollows:z ( ) + 1,z +1 ( ) =z ( ),=online TD( ) update rule eligibility traces~~Vt +1 ( si ) = Vt ( si ) + z +1 ( si )(6)(7)temporal difference time step t, defined (2) z0(s)=0 s.Since state space Markov chain usually large infinite practice, functionapproximators neural networks commonly used approximate value function.TD( ) algorithms linear function approximators popular well-studied ones.Consider general linear function approximator fixed basis function vector( x ) = (1 ( x ), 2 ( x ),..., n ( x ))Testimated value function denoted~Vt ( x) = ( x)Wt263(8)fiXU, HE, & HUWt =(w1, w2,,wn)T weight vector.corresponding incremental weight update rulerWt +1 = Wt + (rt + ( xt +1 )Wt ( xt )Wt ) z +1religibility trace vector z ( ) = ( z1t ( ), z 2t ( ),..., z nt ( )) definedrrz +1 = z + ( xt )(9)(10)Tsitsiklis Roy (1997), linear TD( ) algorithm proved convergeprobability 1 certain assumptions limit convergence W* also derived,satisfies following equation.E 0 [ A( X )]W * E 0 [b( X )] = 0(11)Xt =(xt,xt+1,zt+1) (t=1,2,) form Markov process, E0[] stands expectationrespect unique invariant distribution {Xt}, A(Xt) b(Xt) definedrA( X ) = z ( ( xt ) ( xt +1 ))(12)rb( X ) = z rt(13)improve efficiency linear TD() algorithms, least-squares methods usedlinear TD(0) algorithm, LS-TD(0) RLS-TD(0) algorithms suggested (BrartkeBarto, 1996). LS-TD(0) RLS-TD(0), following quadratic objective function defined.1J = [rt ( tT tT+1 )W ] 2(14)=1Thus, aim LS-TD(0) RLS-TD(0) obtain least-squares estimation realvalue function satisfies following Bellman equation.V ( xt ) = E[rt ( xt , xt +1 ) + V ( xt +1 )](15)employing instrumental variables approach (Soderstrom Stoica, 1983),least-squares solution (14) given=1=1W LS TD ( 0) = ( ( ( +1 ) )) 1 ( rt )(16)instrumental variable chosen uncorrelated input output noises.RLS-TD(0), recursive least-squares methods used decrease computational burden LS-TD(0). update rules RLS-TD(0) follows:Wt +1 = Wt + Pt (rt ( +1 ) Wt ) /(1 + ( +1 ) Pt )(17)Pt +1 = Pt Pt ( +1 ) Pt /(1 + ( +1 ) Pt )(18)convergence (with probability one) LS-TD(0) RLS-TD(0) proved periodicabsorbing Markov chains certain assumptions (Brartke Barto,1996).264fiEFFICIENT REINFORCEMENT LEARNING USING RLS METHODSBoyan (1999,2002), LS-TD( ) proposed solving (11) directly model-basedproperty LS-TD( ) also analyzed. However, LS-TD( ), computation per time-stepO(K3), i.e., cubic order state feature number. Therefore computation requiredLS-TD() increases fast K increases, undesirable online learning.next section, propose RLS-TD( ) algorithm making use recursiveleast-squares methods computational burden LS-TD( ) reduced O(K3)O(K2). also give rigorous mathematical analysis algorithm, convergence(with probability 1) RLS-TD( ) proved.3. RLS-TD( ) AlgorithmMarkov chain discussed above, linear function approximators used,least-squares estimation problem (11) following objective function.J==1=1A( X )W b( X )2(19)A( X ) R nn , b( X ) R n defined (12) (13), respectively, Euclid normn number basis functions.LS-TD( ), least-squares estimate weight vector W computed accordingfollowing equation.=1=1W LS TD ( ) = AT1bT = ( A( X )) 1 ( b( X ))(20)r= ( A( X )) = z ( ( xt ) ( xt +1 ))(21)rbT = b( X ) = z rt(22)=0=0=0=0well known system identification, adaptive filtering control, RLS methodscommonly used solve computational memory problems least-squares algorithms.sequel, present RLS-TD( ) algorithm based idea. First, matrix inverse lemma given follows:Lemma 1(Ljung, et al.,1983). R nn , B R n1 , C R 1n invertible,( + BC ) 1 = 1 1 B ( + CA 1 B ) 1 CA 1(23)Pt = At1(24)Let265fiXU, HE, & HUP0 =(25)rK +1 = Pt +1 z(26)positive number identity matrix.weight update rules RLS-TD( ) givenrrK +1 = Pt z /( + ( ( xt ) ( xt +1 )) Pt z )Wt +1 = Wt + K +1 (rt ( ( xt ) ( xt +1 ))Wt )Pt +1 =1rr[ Pt Pt z [ + ( ( xt ) ( xt +1 )) Pt z )] 1 ( ( xt ) ( xt +1 )) Pt ](27)(28)(29)standard RLS-TD() algorithm, =1; general forgetting factor RLS-TD()case, 0<1.forgetting factor (0<1) usually used adaptive filtering improveperformance RLS methods non-stationary environments. forgetting factor RLS-TD( )algorithm 0<1 derived using similar techniques Haykin (1996). detailedderivation RLS-TD() referred Appendix A.follows, descriptions RLS-TD( ) two different kinds Markov chainsgiven. First, complete description RLS-TD( ) ergodic Markov chains presented below.Algorithm 1 RLS-TD( ) ergodic Markov chains1: Given:termination criterion algorithm.set basis functions { j (i ) } (j=1,2,,n) state i, nnumber basis functions.2: Initialize:(2.1) Let t=0.(2.2) Initialize weight vector Wt, variance matrix Pt , initial state x0.r(2.3) Set eligibility traces vector z 0 =0.3: Loop:(3.1) current state xt, observe state transition xt xt+1reward r(xt ,xt+1).(3.2) Apply equations (27)-(29) update weight vector.(3.3) t=t+1.termination criterion satisfied.RLS-TD( ) algorithm absorbing Markov chains little differentalgorithm coping state features absorbing states. Following description266fiEFFICIENT REINFORCEMENT LEARNING USING RLS METHODSRLS-TD( ) absorbing Markov chains.Algorithm 2 RLS-TD( ) absorbing Markov chains1: Given:termination criterion algorithm.set basis functions { j (i ) } (j=1,2,,n) state i, nnumber basis functions.2: Initialize:(2.1) Let t=0.(2.2) Initialize weight vector Wt, variance matrix Pt , initial state x0.r(2.3) Set eligibility traces vector z 0 =0.3: Loop:(3.1) current state xt,xt absorbing state, set (xt+1)=0, r(xt)=rT, rT terminalreward.Otherwise, observe state transition xt xt+1 rewardr(xt ,xt+1).(3.2) Apply equations (27)-(29) update weight vector.(3.3) xt absorbing state, re-initialize process setting xt+1 initialrstate set eligibility traces z zero vector.(3.4) t=t+1.termination criterion satisfied.RLS-TD( ) algorithm absorbing Markov chains, weight updatesabsorbing states treated differently process re-initialized absorbing statestransform absorbing Markov chain equivalent ergodic Markov chain.following convergence analysis, focus ergodic Markov chains.similar assumptions Tsitsiklis Roy (1997), prove proposedRLS-TD( ) algorithm converges probability one.Assumption 1. Markov chain {xt}, whose transition probability matrix P, ergodic,unique distribution satisfiesP =(30)(i)>0 finite infinite vector, depending cardinality S.Assumption 2. Transition rewards r(xt,xt+1) satisfyE 0 [r 2 ( xt , xt +1 )] <(31)E0[ ] expectation respect distribution .Assumption 3. matrix = [1 , 2 ,..., n ] R N n full column rank, is, basis267fiXU, HE, & HUfunctions (i=1,2,,n) linearly independent.Assumption 4. every (i=1,2,,n), basis function satisfies2E 0 [ ( xt )] <(32)1A( X )] non-singular T>0.=1Assumptions 14 almost linear TD() algorithms discussedTsitsiklis Roy (1997) except Assumption 1, ergodic Markov chains considered.Assumption 5 specially needed convergence RLS-TD() algorithm.Based assumptions, convergence theorem RLS-TD() givenfollows:Assumption 5. matrix [ P01 +Theorem 1. Markov chain satisfies Assumptions 15, asymptotic estimate foundRLS-TD( ) converges, probability 1, W* determined (11).proof Theorem 1, please refer Appendix B. condition specifiedAssumption 5 satisfied setting P0= appropriately.According Theorem 1, RLS-TD( ) converges solution conventional linearTD( ) algorithms do, satisfies (11). limit convergence characterizedfollowing theorem.Theorem 2 (Tsitsiklis Roy ,1997) Let W* weight vector determined (11) V*true value function Markov chain, Assumption 14, following relationholds.1W * V *(33)V * V *1X=X DX , = ( ) 1 .explanations notations Theorem 2, please refer Appendix B.discussed Tsitsiklis Roy (1997), theorem shows distancelimiting function W* true value function V* bounded smallest boundapproximation error obtained =1. every <1, bound actually deterioratesdecreases. worst bound obtained =0. Although bound, stronglysuggests higher values likely produce accurate approximations V*.Compared LS-TD(), additional parameter RLS-TD(), valueinitial variance matrix P0. pointed Haykin (1996,pp.570), exact valueinitializing constant insignificant effect data length large enough.means limit, final solutions obtained LS RLS almost same.influence transient phase, positive constant becomes large enough goesinfinity, transient behavior RLS almost LS methods (Ljung,1983). initialized relatively small value, transient phases RLS LSdifferent. practice, observed variable performance RLSfunction initialization (Moustakides, 1997). cases, RLS exhibitsignificantly faster convergence initialized relatively small positive definite matrixinitialized large one (Haykin,1996; Moustakides, 1997; Hubing Alexander,268fiEFFICIENT REINFORCEMENT LEARNING USING RLS METHODS1989). first effort toward direction statistical analysis RLS soft exactinitialization limits case number iterations less sizeestimation vector (Hubing Alexander, 1989). Moustakides (1997) provided theoreticalanalysis relation algorithmic performance RLS initialization .using settling time performance measure, Moustakides proved well-knownrule initialization relatively small matrix preferable cases high mediumsignal-to-noise ratio (SNR), whereas low SNR, relatively large matrix must selectedachieving best results. following learning prediction experiments RLS-TD(), welllearning control simulation Fast-AHC, observed value initializingconstant also plays important role convergence performance, theoreticalanalyses provide clue explain experimental results.4. Learning Prediction Experiments Markov Chainssection, illustrative example given show effectiveness proposedRLS-TD() algorithm. Furthermore, algorithmic performance influenceinitializing constant studied.example finite-state absorbing Markov chain called Hop-World problem (Boyan,1999). shown Figure 1, Hop-World problem 13-state Markov chainabsorbing state.Figure 1: Hop-World ProblemFigure 1, state 12 initial state trajectory state 0 absorbing state.non-absorbing state two possible state transitions transition probability 0.5.state transition reward 3 except transition state 1 state 0 reward 2.Thus, true value function state (0i12) 2i.apply linear temporal-difference algorithms value function prediction problem, setfour-element state features basis functions chosen, shown Figure 1. statefeatures states 12,8,4 0 are, respectively, [1,0,0,0], [0,1,0,0], [0,0,1,0], [0,0,0,1]state features states obtained linearly interpolating these.simulation, RLS-TD( ) algorithm well LS-TD() conventional linearTD( ) algorithms used solve value function prediction problem withoutknowing model Markov chain. experiments, trial defined periodinitial state 12 terminal state 0. performance algorithms evaluatedaveraged root mean squared (RMS) error value-function predictions 13 states.parameter setting, performance averaged 20 independent Monte-Carlo runs.Figure 2 shows learning curves RLS-TD() conventional linear TD() algorithmsthree different parameter settings. parameter set 0.3 algorithms269fiXU, HE, & HUstep-size parameter TD() following form.n = 0N0 +1N0 + n(34)step-size schedule also studied Boyan (1999). experiments, threedifferent settings used,(s1) 0 = 0.01 , N 0 = 10 6(s2) 0 = 0.01 , N 0 = 1000(s3) 0 = 0.1 , N 0 = 1000 .(35)Different Boyan (1999), linear TD() algorithms appliedonline forms, update weights every state transitions. parameter n (34)number state transitions. run, weights initialized zeroes. Figure 2,learning curves conventional linear TD() algorithms step-size schedules (s1), (s2)(s3) shown curves 1,2 3, respectively. curve, averaged RMS errorsvalue function predictions states 20 independent runs plotted trial.Curve 4 shows learning performance RLS-TD(). One additional parameter RLS-TD()initial value variance matrix P0. experiment, set 500,relatively large value. Figure 2, concluded making use RLS methods,RLS-TD() obtain much better performance conventional linear TD() algorithmseliminates design problem step-size schedules. experiments linear TD()RLS-TD() different parameters also conducted similar results obtainedinitial values RLS-TD() large conclusion confirmed.Figure 2: Performance comparison RLS-TD() TD()1,2,3 ---TD(0.3) step-size parameters specified (s1),(s2) (s3)4RLS-TD(0.3) initial variance matrix P0=500Idone demonstrative experiments investigate influence performanceRLS-TD() algorithm. Figure 3 shows performance comparison RLS-TD()270fiEFFICIENT REINFORCEMENT LEARNING USING RLS METHODSalgorithms using two different initial parameters variance matrix P0, P0=0.1IP0=1000I, respectively. forgetting factor =0.995. performance suggestedalgorithm measured averaged RMS errors value function prediction first200 trials 20 independent runs 13 states. experiments, 11 settingsparameter tested, 0.1n (n=0,1,,10).Figure 3, clearly shown performance RLS-TD() large initial valuemuch better RLS-TD() small initial value . experimentsdifferent parameter settings , similar results also obtained. may referphenomenon low SNR case forgetting factor RLS studied Moustakides (1997).Hop-World problem, stochastic state transitions could introduce high equationresiduals A( X )W b( X ) (19), corresponds additive noise large variance,i.e., low SNR case. discussed Section 2, forgetting factor RLS lowSNR cases, relatively large initializing constant must selected better results. fullunderstanding phenomenon yet found.Figure 3: Performance comparison RLS-TD() different initial value (=0.995)performance RLS-TD() unit forgetting factor =1 also testedexperiments. Although initial value effect RLS =1 discussed intensively(Moustakides,1997), effects observed empirically case =1<1, shown Figure 4.experiments, also found initialized small value,performance sensitive values parameter . case, convergencespeed RLS-TD() increases increases 0 1, shown Figure 3.Furthermore, fixed, performance RLS-TD() deteriorates becomes smaller,shown Figure 5 .271fiXU, HE, & HUFigure 4: Performance comparison RLS-TD() different initial value (=1)Figure 5: Learning curves LS-TD() RLS-TD() different (=1)Figure 5, learning curves RLS-TD() different initializing constantsshown compared LS-TD(). experiment, set 0.5. Figure 5,shown performance RLS-TD() approaches LS-TD() becomes large.well known, becomes large enough, performance RLS LS methodsalmost same. Figure 6 shows performance comparison LS-TD()RLS-TD() large value . initial variance matrix RLS-TD() set 500Ievery runs, identity matrix.272fiEFFICIENT REINFORCEMENT LEARNING USING RLS METHODSFigure 6: Performance comparison LS-TD() RLS-TD() =1 large initialvalueBased experimental results, concluded convergence speedRLS-TD( ) mainly influenced initial value variance matrix parameter. Detailed discussions properties RLS-TD( ) given follows:(1) relatively large, effect becomes small. large enough goesinfinity, performance RLS-TD( ) LS-TD( ) almost same,discussed above. cases, effect speed convergence insignificant,coincides discussion Boyan (1999). However, described Theorem 2,value still affects ultimate error bound value function approximation.(2) relatively small, observed convergence performanceRLS-TD() different LS-TD() influenced values .experiments Hop-World problem, results show smaller values leadslower convergence. results may explained theoretical analysis transientphase forgetting factor RLS (Moustakides,1997). According theory Moustakides(1997), larger values needed better performance cases low SNRsmaller values preferable fast convergence cases high medium SNR.different values must selected faster convergence RLS-TD( ) different cases.Especially, cases, high SNR case discussed Moustakides (1997), RLSmethods small values obtain fast speed convergence.(3) Compared conventional linear TD( ) algorithms, RLS-TD( ) algorithmobtain much better performance making use RLS methods value function predictionproblems. Furthermore, TD( ), step-size schedule needs carefully designed achievegood performance, RLS-TD( ), initial value variance matrix selectedaccording criterion large small value.(4) comparison LS-TD( ) RLS-TD( ), one preferable dependsobjective. online applications, RLS-TD( ) advantages computational efficiencycomputation per step RLS-TD( ) O(K2) LS-TD( ), O(K3),273fiXU, HE, & HUK number state features. Moreover, seen later, RLS-TD( ) obtain bettertransient convergence performance LS-TD( ) cases. hand, LS-TD( )may preferable RLS-TD( ) long-term convergence performance, seenFigure 5. system identification point view, LS-TD( ) obtain unbiasedparameter estimates face white additive noises RLS-TD( ) finite wouldpossess large parameter discrepancies.5. Fast-AHC Algorithm Two Learning Control Experimentssection, Fast-AHC algorithm proposed based results learningprediction solve learning control problems. Two learning control experiments conductedillustrate efficiency Fast-AHC.5.1 Fast-AHC Algorithmultimate goal reinforcement learning learning control, i.e., estimate optimalpolicies optimal value functions Markov decision processes (MDPs). now, severalreinforcement learning control algorithms including Q-learning (Watkins Dayan,1992),Sarsa-learning (Singh, et al.,2000) Adaptive Heuristic Critic (AHC) algorithm (Barto,Sutton Anderson,1983) proposed. Among methods, AHC methoddifferent Q-learning Sarsa-learning value-function-based methods.AHC method, value functions policies separately represented value-functionbased methods policies determined value functions directly. twocomponents AHC method, called critic actor, respectively. actorused generate control actions according policies. critic used evaluatepolicies represented actor provide actor internal rewards without waitingdelayed external rewards. Since objective critic policy evaluation learningprediction, temporal-difference learning methods chosen critics learning algorithms.learning algorithm actor determined estimation gradient policies.following discussion, detailed introduction AHC method given.Figure 7 shows architecture learning system based AHC method. learningsystem consists critic network actor network. inputs critic network includeexternal rewards state feedback environment. internal rewards providedcritic network called temporal-difference (TD) signals.reinforcement learning methods, whole system modeled MDP denotedtuple {S,A,P,R},where state set, action set, P state transition probabilityR reward function. policy MDP defined function :SPr(A),Pr(A) probability distribution action space. objective AHC methodestimate optimal policy * satisfying following equation.J = max J = max E [ rt ]*(36)=0discount factor rt reward time-step tE[ ] stands expectationrespect policy state transition probabilities J expected totalreward.274fiEFFICIENT REINFORCEMENT LEARNING USING RLS METHODSFigure 7: AHC learning systemvalue function stationary policy optimal value function optimalpolicy defined follows:V ( ) = E [ rt 0 = ](37)V * ( ) = E *[ rt s0 = ](38)=0=0According theory dynamic programming, optimal value function satisfiesfollowing Bellman equation.(39)V * ( ) = max[ R ( s, ) + EV * ( ' )]R(s,a) expected reward received taking action state s.AHC, critic uses temporal-difference learning approximate value functioncurrent policy. linear function approximators used critic, weight updateequationWt +1 = Wt + [rt + V ( +1 ) V ( )]z(40)zt eligibility trace defined (10).action selection policy actor determined current state valuefunction estimation critic. Suppose neural network weight vector u=[u1, u2,, um]used actor, output actor network= f (u , st )(41)action outputs actor determined following Gaussian probabilistic distribution.( )2p r ( ) = exp( 2 )(42)mean value given (41) variance given= k1 /(1 + exp(k 2V ( ))(43)equation, k1 k2 positive constants V(st) value function es275fiXU, HE, & HUtimation critic network.obtain learning rule actor, estimation policy gradient givenfollows:JJ=rtuuu(44)rt internal reward TD signal provided critic:rt = rt + V ( st +1 ) V ( st )(45)Since AHC method, critic used estimate value function actors policyprovide internal reinforcement using temporal-difference learning algorithms,efficiency temporal-different learning learning prediction greatly influence wholelearning systems performance. Although policy actor changing, may changerelatively slowly especially fast convergence learning prediction criticrealized. previous sections, RLS-TD( ) shown better data efficiencyconventional linear TD( ) algorithms fast convergence speed obtainedinitializing constant chosen appropriately. Thus, applying RLS-TD( ) policyevaluation critic network improve learning prediction performance criticpromising enhance whole systems learning control performance. Basedidea, new AHC method called Fast-AHC algorithm proposed paper. efficiencyFast-AHC algorithm verified empirically detailed analysis results given.Following complete description Fast-AHC algorithm.Algorithm 3: Fast-AHC algorithm1: Given: critic neural network actor neural network, linearparameters, stop criterion algorithm.2: Initialize state MDP learning parameters, set t=0.3: stop criterion satisfied,(3.1) According current state , compute output actor network ,(3.2)determine actual action actor probability distribution given(42).Take action MDP, observe state transition+1 , set reward rt = r ( st , st +1 ) .(3.3)(3.4)(3.5)Apply RLS-TD( ) algorithm described (27)-(29) update weightscritic network.Apply following equation update weights actor network,J+1 = +(46)learning factor actor.Let t=t+1, return 3.276fiEFFICIENT REINFORCEMENT LEARNING USING RLS METHODS5.2 Learning Control Experiments Cart-Pole Balancing Problembalancing control inverted pendulums typical nonlinear control problemwidely studied control theory also artificial intelligence. researchartificial intelligence, learning control inverted pendulums considered standard testproblem machine learning methods, especially RL algorithms. studiedearly work Michies BOXES system (Michie,et al.,1968) later Barto Sutton (1983),learning controllers two output values: +10(N) 10(N). Berenji, etal.(1992) Lin, et al.(1994), AHC methods continuous outputs applied cart-polebalancing problem. paper, cart-pole balancing problem continuous control valuesused illustrate effectiveness Fast-AHC method.Figure 8 shows typical cart-pole balancing control system, consists cart movinghorizontally pole one end fixed cart. Let x denote horizontal distancecenter cart center track, x negative cartleft part track. Variable denotes angle pole upright position (indegrees) F amount force (N) applied cart move towards left right.control system four state variables x, x& , ,& , x& ,& derivatives x ,respectively.Figure 8, mass cart M=1.0kg, mass pole m=0.1kg, half-polelength l=0.5m, coefficient friction cart track c=0.0005 coefficientfriction pole cart p=0.000002. boundary constraints state variablesgiven follows.12 12(47)2.4m x 2.4m(48)dynamics control system described following equations.p (m + )&(m + ) g sin cos [ F + ml& 2 sin c sgn( x& )]ml&& =42(49)( + m)l ml cos3F + ml (& 2 sin && cos ) c sgn( x& )&x& =+mg acceleration due gravity, 9.8m/s2. parametersdynamics equations studied Barto et al. (1983).Figure 8: cart-pole balancing control system277fiXU, HE, & HUlearning control experiments pole-balancing problem, dynamics (49)assumed unknown learning controller. addition four state variables,available feedback failure signal notifies controller failure occurs,means values state variables exceed boundary constraints prescribed inequalities(47) (48). typical reinforcement learning problem, failure signal servesreward. Since external reward may available long sequence actions, criticAHC learning controller used provide internal reinforcement signal accomplishlearning task. Learning control experiments pole-balancing problem conductedusing conventional AHC method uses linear TD() algorithms criticFast-AHC method proposed paper.solve continuous state space problem reinforcement learning, class linearfunction approximators, called Cerebellar Model Articulation Controller (CMAC)used. neural network model based neuro-physiological theory humancerebellarCMAC first proposed Albus (1975) widely used automaticcontrol function approximation. CMAC neural networks, dependence adjustableparameters weights respect outputs linear. detailed discussion structureCMAC neural networks, one may refer Albus (1975) Sutton & Barto (1998).AHC Fast-AHC learning controllers, two CMAC neural networks four inputsone output used function approximators critic actor,respectively. CMAC C tilings partitions every input. total physicalmemory CMAC network M4C. reduce computation memory requirements,hashing technique described following equations employed experiments. (Fordetailed discussion parameters CMAC networks, please refer Appendix C).A( ) =4[a(i) + 1 ](50)=1F(s)=A(s) mod K(51)(50) (51), represents input state vector, a(i) (0 a(i) M) activated tilei-th element s, K total number physical memory F(s) physicalmemory address corresponding state s, remainder A(s) divided K.order compare performance different learning algorithms, initial parameterslearning controller selected follows: weights critic initialized 0weights actor initialized random numbers interval [0,0.1].parameters AHC Fast-AHC algorithms = 0.95 , k1 = 0.4 k 2 = 0.5 .experiments, trial defined period initial state failure stateinitial state trial set randomly generated state near unstable equilibrium(0,0,0,0) maximum distance 0.05. Equation (49) employed simulate dynamicssystem using Euler method, time step 0.02s. trial lasts120,000 time steps, said successful learning controller assumedable balance pole. reinforcement signal problem defined1, failure occursrt =0, otherwise(52)performance Fast-AHC method tested extensively, different parametersettings including initial variance matrix P0 chosen. experiments,278fiEFFICIENT REINFORCEMENT LEARNING USING RLS METHODSforgetting factor RLS-TD() critic set value equal 1 close 1.learning control experiments using conventional AHC methods also conductedcomparison. performance comparisons two algorithms shown Figure 9, 1011.experiments, initial variance matrixes Fast-AHC algorithm setP0=0.1I. performance Fast-AHC compared AHC different . numbersphysical memories critic network actor network chosen 30 80,respectively. parameter setting two algorithms, 5 independent runs tested.performance evaluated according trial number needed successfully balance pole.learning factors actor networks set 0.5, manually optimized valuealgorithms. experiments, 11 settings tested.Figure 9: Performance comparison Fast-AHC AHC =0.01Figure 10: Performance comparison Fast-AHC AHC =0.03279fiXU, HE, & HUFigure 11: Performance comparison Fast-AHC AHC =0.05Figure 9, 10 11, learning factors critic networks AHC chosen=0.01, 0.03 0.05, respectively. found <0.01, performance AHCbecomes worse. learning factors greater 0.05, AHC algorithm maybecome unstable, even =0.03 =0.05, AHC algorithm becomes unstable=1. time-varying learning factors specified (s1)-(s3), performance worseconstant learning factors. three settings learning factor typicalnear optimal AHC algorithm.experimental results, concluded using RLS-TD()critic network, Fast-AHC algorithm obtain better performance conventional AHCalgorithms. Although Fast-AHC requires computation per step AHC,efficient AHC less trials data needed successfully balance pole.discussed previous sections, convergence performance RLS-TD()influenced initial value variance matrix. also case Fast-AHC.learning control experiments, small value =0.1 selected. experiments,set small values, performance Fast-AHC satisfactory better AHC.However, equal relatively large value, example =100 500, performanceFast-AHC deteriorates significantly. Since RLS-TD() large initializing constantsimilar performance LS-TD(), deduced AHC method using LS-TD()critic also bad performance cart-pole balancing problem. verify this,experiments conducted using Fast-AHC large initializing constant AHC usingLS-TD(). parameter setting, 5 independent runs tested. experiments,maximum trials algorithm one run 200 algorithm fails balancepole within 200 trials, performance set 200.When using LS-TD() AHC method,may computational problems matrix inversion first steps learningtwo methods tried avoid problem. One usage TD() first 60 stepsupdates. actor updated early stage learning LS-TD()280fiEFFICIENT REINFORCEMENT LEARNING USING RLS METHODSstable. However, similar results found two methods. Figure 12 shows experimentalresults clearly verify performance Fast-AHC large initializing constantsimilar AHC using LS-TD() much worse Fast-AHC small . detaileddiscussion phenomenon provided subsection 5.4.Figure 12: Performance comparison Fast-AHC different initial variancefollowing Figure 13 Figure 14, variations pole angle controlforce F plotted, successfully trained Fast-AHC learning controller used controlcart-pole system.Figure 13: Variation pole angleFigure 14: Variation control force5.3 Learning Control Experiments Acrobotsubsection, another learning control example, swing-up control acrobotminimum time, presented. learning control acrobot class adaptive optimalcontrol problem difficult pole-balancing problem. investigatedSutton (1996), CMAC-based Sarsa-learning algorithms employed solvecase discrete control actions studied. experiments, case continuous actions281fiXU, HE, & HUconsidered.acrobot moving vertical plane shown Figure 15, OA AB firstlink second link, respectively. control torque applied point A. goalswing-up control swing tip B acrobot line CD higherjoint amount length one link.Figure 15: acrobotdynamics acrobot system described following equations.&&1 = (d 2&&2 + 1 ) / d1(53)&&2 = ( + 21 / d1 2 )(54)d1 = m1l c21 + m2 (l12 + l c22 + 2l1l c 2 cos 2 ) + 1 + 2(55)2 = m2 (l c22 + l1l c 2 cos 2 ) + 2(56)1 = m2 l1l c 2&22 sin 2 2m2 l1l c 2&1&2 sin 2 + (m1l c1 + m2 l1 ) g cos( 1 / 2) + 2(57)2 = m2 l c 2 g cos( 1 + 2 / 2)(58)equations, parameters , &i , mi , li , , l ci angle, angle velocity,mass, length, moment inertia length center mass link (i=1,2),respectively.Let sT denote goal state swing-up control. Since control aim swingacrobot minimum time, reward function rt defined1, = sTrt =0, else(59)simulation experiments, control torque continuous bounded [-3N, 3N].Similar cart-pole balancing problem, CMAC neural networks applied solve282fiEFFICIENT REINFORCEMENT LEARNING USING RLS METHODSlearning control problem continuous states actions. CMAC-based actor-criticcontroller, actor network critic network C=4 tilings M=7 partitionsinput. actor network, uniform coding employed non-uniform coding usedcritic network. details coding parameters, please refer Appendix C. sizesphysical memories actor network critic network 100 80, respectively.CMAC networks, following hashing techniques used. (For definition A(s),a(i)F(s), please refer Subsection 5.2.)4A( ) = [ a(i ) 1 ](60)=1F(s)=A(s) mod K(61)simulation, parameters acrobot chosen m1=m2=1kg, I1=I2=1kgm2,lc1=lc2=0.5m, l1=l2=1m g=9.8m/s2. time step simulation 0.05s time intervallearning control 0.2s. learning parameters =0.6, =0.90, =0.2, k1=0.4, k2=0.5.trial defined period starts stable equilibrium ends goal statereached. trial, state acrobot re-initialized stable equilibrium.parameter setting, 5 independent runs tested. run consists 50 trials 50-th trial,actor network tested controlling acrobot alone, i.e., setting action variancedefined (43) zero. performance algorithms evaluated according stepsused actor networks swing acrobot.performance comparisons Fast-AHC AHC shown Figure 16,1718. experiments, algorithms tested different AHC also testeddifferent learning factors critic networks.results, also shown Fast-AHC achieve higher data efficiency AHC.However, example, relatively large used, different previouscart-pole balancing example. experiments, good performance obtained largeinitializing constant small, performance deteriorates significantly. Thusproblem may referred low SNR case Moustakides (1997), large valuespreferable best convergence rate RLS methods.Figure 16: Performance comparison Fast-AHC AHC =0.02283fiXU, HE, & HUFigure 17: Performance comparison Fast-AHC AHC =0.05Figure 18: Performance comparison Fast-AHC AHC =0.1following Figure 19 shows performance comparison Fast-AHC large(300) small (0.01) value , 6 settings parameter testedalgorithm. performance AHC using LS-TD() also shown. Figure 20, typical curveangle first link plotted, acrobot controlled actor networkFast-AHC method (=0.6) 50 trials.284fiEFFICIENT REINFORCEMENT LEARNING USING RLS METHODSFigure 19: Performance comparison Fast-AHC AHC using LS-TD()Figure 20: Variation angle link 1(Controlled Fast-AHC 50 trials)5.4Analysis Experimental ResultsBased experimental results, concluded using RLS-TD()algorithm critic network, Fast-AHC algorithm obtain better performanceconventional AHC algorithms less trials data needed converge near optimalpolicy. well known, one difficulty applications RL methods slowconvergence, especially cases learning data hard generated.Fast-AHC algorithm, although computation per step required conventional AHCmethods, serious problem number linear state features small.learning control experiments, hashing techniques used reduce state featuresCMAC networks computation Fast-AHC reduced economical amount.Nevertheless, state feature number large, conventional AHC methods maypreferable.experiments, observed performance Fast-AHC affectedinitializing constant . results consistent property RLS-TD() RLS285fiXU, HE, & HUmethod adaptive filtering, discussed Section 4. learning controlexperiments cart-pole balancing problem, better performance Fast-AHC obtainedusing small values . learning control acrobot, higher data efficiencyachieved using Fast-AHC relatively large . two different properties Fast-AHCmay referred different SNR cases RLS methods (Moustakides,1997). thoroughtheoretical analysis problem interesting topic future research.experiments, performance AHC method using LS-TD() also tested.studied Section 4, initializing constant large, performanceRLS-TD() LS-TD() differ much. performance AHC using LS-TD()similar Fast-AHC large values .studied Moustakides (1997), RLS method converge much fasteradaptive filtering methods environment stationary initializing constant selectedappropriately. cases, RLS may converge almost instantly. also verifiedlearning prediction experiments RLS-TD() algorithm. applying RLS-TD()actor-critic learning controller, although policy actor change time, stillassumed changing speed policy slow compared fastconvergence speed RLS-TD(). Thus good performance learning prediction obtainedcritic. Moreover, since learning prediction performance critic importantpolicy learning actor, improvement learning prediction efficiency contributewhole performance improvement controller.6. Conclusions Future WorkTwo new reinforcement learning algorithms using RLS methods, called RLS-TD( )Fast-AHC, respectively, proposed paper. RLS-TD( ) used solve learningprediction problems efficiently conventional linear TD( ) algorithms.convergence probability 1 proved RLS-TD( ) limit convergence alsoanalyzed. Experimental results learning prediction problems show RLS-TD( )algorithm superior conventional TD( ) algorithms data efficiency also eliminatesdesign problem step sizes linear TD( ) algorithms. RLS-TD( ) viewedextension RLS-TD(0) =0 general 0< 1. Although effectconvergence speed RLS-TD( ) may significant cases, usage >0still affect approximation error bound. Thus, needs value functionestimation high precision, large values preferable =0. Furthermore, RLSTD( ) superior LS-TD( ) computation weight vector must updatedevery observations.Since learning prediction viewed sub-problem learning control, extendresults learning prediction learning control method called AHC algorithm. UsingRLS-TD( ) critic network, Fast-AHC achieve better performance conventionalAHC method data efficiency. Simulation results learning control pole-balancingproblem acrobot system confirm analyses.experiments, found performance RLS-TD( ) well Fast-AHCinfluenced initializing constant RLS methods. Different values needed bestperformance different cases. also well-known phenomenon RLS-based adaptive286fiEFFICIENT REINFORCEMENT LEARNING USING RLS METHODSfiltering theoretical results Moustakides (1997) provide basis explanationsresults. complete investigation problem ongoing work.idea using RLS-TD( ) critic network may applied reinforcementlearning methods actor-critic architectures. Konda Tsitsiklis (1998), new actor-criticalgorithm using linear function approximators proposed convergence certainconditions proved. One condition convergence algorithm convergencerate critic much faster actor. Thus application RLS-TD( )critic may preferable order ensure convergence algorithm. theoreticalempirical work problem deserves studied future.Acknowledgementswork supported National Natural Science Foundation China Grants60075020, 60171003 China University Key Teachers Fellowship. would much likethank anonymous reviewers Associate Editor Michael L. Littman insightsconstructive criticisms, helped improve paper significantly.287fiXU, HE, & HUAppendix A. Derivation RLS-TD() Algorithmderivation RLS-TD(), two different cases, determined valueforgetting factor.(1) RLS-TD() unit forgetting factor.SincePt = At1(62)P0 =(63)rK +1 = Pt +1 z(64)According Lemma 1,Pt +1 = At+11rr= Pt Pt z [1 + ( ( xt ) ( x +1 )) Pt z )] 1 ( ( x ) ( xt +1 )) PtrK +1 = Pt +1 zrr= Pt z /(1 + ( ( xt ) ( xt +1 )) Pt z )(65)(66)Wt +1 = At+11bt +1r= Pt +1 ( z ri )(67)=0r= Pt +1 ( Pt 1Wt + z rt )ThusrrWt +1 = Pt +1 [( Pt +11 z ( ( xt ) ( x +1 )))Wt + z rt ]rr= Wt + Pt +1 ( z rt z ( ( xt ) ( x +1 ))Wt )(68)= Wt + K +1 [rt ( ( xt ) ( xt +1 ))Wt ](2) RLS-TD() forgetting factor <1derivation RLS-TD() forgetting factor <1 similar exponentially weightedRLS algorithm Haykins (1996, pp.566-569). present results:Pt +1 =1rrK +1 = Pt z /( + ( ( x ) ( x +1 )) Pt z )(69)Wt +1 = Wt + K +1 (rt ( ( x ) ( xt +1 ))Wt )(70)rr[ Pt Pt z [ + ( ( xt ) ( xt +1 )) Pt z )]1 ( ( xt ) ( xt +1 )) Pt ]288(71)fiEFFICIENT REINFORCEMENT LEARNING USING RLS METHODSAppendix B. Proof Theorem 1study steady property Markov chain defined Section 3, construct stationaryprocess follows. Let {xt} Markov chain evolves according transition matrix Palready steady state, means Pr{xt=i}= (i) t. Given sample pathMarkov chain, definerzt =( ) ( x )(72)=rX = {xt , xt +1 , z } stationary process, discussed (TsitsiklisRoy, 1997).Let denote NN diagonal matrix diagonal entries (1), (2),, (N), Ncardinality state space X. Lemma 2 derived follows.Lemma 2. (Tsitsiklis Roy, 1997) Assumption 1-4, following equations hold.1) E 0 [ ( xt ) ( xt + )] = DP , m>0r2) E 0 [ z ( xt )] =(73)( ) DP ,(74)=0r3) E 0 [ z rt ( xt , xt +1 )] =( ) DP r(75)=0r R N , whose Nth component equal E[r ( xt , xt +1 ) xt = ] .According Lemma 2, E0[A(Xt)] E0[b(Xt)] well defined finite. Furthermore, E0[A(Xt)]negative definite, invertible.equation (67),WRLS TD ( ) = [ P01 + A( X )] 1 [ P01W0 + b( X )]=1=11111= [ P01 + A( X )] 1 [ P01W0 + b( X )]=1=1(76)Since1A( X )=1(77)1b( X )=1(78)E 0 [ A( X )] = limE 0 [b( X )] = limE0[A(Xt)] invertible,1lim W RLS TD ( ) = E 0 [ A( X )]E 0 [b( X )] = W *289(79)fiXU, HE, & HUThus W RLS TD ( ) converges W* probability 1.Appendix C. details coding structures CMAC networksfollowing discussion, coding structures CMAC networks cart-pole balancingproblem acrobot control problem presented.(1) CMAC coding structures cart-pole balancing problemCMAC networks, state variables following boundaries.[12 ,12 ] ,& [50 deg/ s, 50 deg/ s]x [2.4, 2.4] ,x& [1,1]critic network, C=4 M=7. hashing technique specified equations (50) (51)employed total memory size 30.actor network, C=4 M=7. hashing technique specified equations (60) (61)employed total memory size 100.(2) CMAC coding structures acrobot swing-up problemsimulation, angles bounded [ , ] angular velocities bounded&1 [4 ,4 ] , &2 [9 ,9 ] . tiling numbers actor critic equal 4(C=4). total memory sizes critic actor 80 100, respectively. actornetwork, tiling partitions range input 7 equal intervals (M=7). criticnetwork, partitions input non-uniform, given1 : { -, -1, -0.5, 0, 0.5, 1, },&1 : {-4, -1.5, -0.5, 0, 0.5, 1.5, 4}2 : {-, -1, -0.5, 0, 0.5, 1, },&2 : {-9, -2, -0.5,0, 0.5,2, 9}290fiEFFICIENT REINFORCEMENT LEARNING USING RLS METHODSReferencesAlbus,J.S.(1975). new approach manipulator control: cerebellar model articulationcontroller (CMAC). Journal Dynamic Systems, Measurement, Control, 97(3), 220-227.Barto,A.G., Sutton R.S., & Anderson C.W. (1983). Neuronlike adaptive elements solvedifficult learning control problems. IEEE Transactions System, Man, Cybernetics,13,834-846.Bertsekas D.P. & Tsitsiklis J.N. (1996). Neurodynamic Programming. Belmont, Mass.: AthenaScientific.Berenji H.R. & Khedkar P. (1992). Learning tuning fuzzy logic controllers reinforcements, IEEE Trans.On Neural Networks, 3(5), 724-740.Boyan. J.(1999). Least-squares temporal difference learning. Bratko, I., Dzeroski, S., eds.,Machine Learning: Proceedings Sixteenth International Conference (ICML).Boyan, J.(2002). Technical update: least-squares temporal difference learning. Machine Learning,Special Issue Reinforcement Learning, appear.Brartke. S.J. & Barto A. (1996). Linear least-squares algorithms temporal difference learning.Machine Learning, 22, 33-57.Dayan P.(1992). convergence TD() general . Machine Learning, 8, 341-362.Dayan P.. & Sejnowski T.J. (1994). TD() converges probability 1. Machine Learning, 14,295-301.Eleftheriou E. & Falconer,D.D. (1986). Tracking properties steady state performance RLSadaptive filter algorithms. IEEE Transactions Acoustics, Speech, Signal Processing, 34,1097-1110.Eweda E. & Macchi, O. (1987). Convergence RLS LMS adaptive filters. IEEE Trans.Circuits Systems, 34, 799-803.Haykin S. (1996), Adaptive Filter Theory, 3rd edition, Englewood Cliffs, NJ: Prentice-Hall.Hubing N.E. & Alexander S.T. (1989). Statistical analysis soft constrained initializationRLS algorithms. Proc. IEEE International Conference Acoustics, SpeechSignal Processing.Jaakkola T., Jordan M.I., & Singh S.P. (1994). convergence stochastic iterative dynamicprogramming algorithms. Neural Computation. 6(6), 1185-1201.Kaelbling L.P., Littman M.L., & Moore A.W. (1996). Reinforcement learning: survey. JournalArtificial Intelligence Research, 4, 237-285.Konda V.R, & Tsitsiklis J.N. (2000). Actor-critic algorithms. Neural Information ProcessingSystems, 2000, MIT Press.291fiXU, HE, & HULin L.J. (1992). Self-improving reactive agents based reinforcement learning, planningteaching. Machine Learning, 8(3/4), 293-321.Lin C.T. & Lee C.S.G. (1994). Reinforcement structure/parameter learning neural-networkbased fuzzy Logic control system. IEEE Transactions Fuzzy System, 2(1), 46-63.Ljung L. & Soderstron T. (1983). Theory Practice Recursive Identification. MIT Press.Ljung L. (1977). Analysis recursive stochastic algorithm. IEEE. Transactions AutomaticControl, 22, 551.Michie D. & Chambers R.A. (1968). BOXES: experiment adaptive control. MachineIntelligence 2, Dale E. Michie D., eds., Edinburgh: Oliver Boyd, 137-152.Minsky M.L. (1954). Theory neural-analog reinforcement systems applicationbrain-model problem. Ph.D. Thesis, Princeton University.Moustakides G.V. (1997). Study transient phase forgetting factor RLS. IEEE Trans.Signal Processing, 45(10), 2468-2476.Samuel A.L. (1959). studies machine learning using game checkers. IBM JournalResearch Development, 3, 211-229.Singh, S.P., Jaakkola T., Littman M.L., & Szepesvari C. (2000). Convergence results singlestep on-policy reinforcement-learning algorithms. Machine Learning, 38, 287-308.Sutton R. & Barto A. (1998). Reinforcement Learning, Introduction. Cambridge MA, MITPress.Sutton R. (1988). Learning predict method temporal differences. Machine Learning,3(1), 9-44.Tsitsiklis J.N. (1994). Asynchronous stochastic approximation Q-learning. Machine Learning,16, 185-202.Tsitsiklis J.N. & Roy B.V. (1994). Feature-based methods large scale dynamic programming.Neural Computation. 6(6), 1185-1201.Tsitsiklis J.N. & Roy B.V. (1997). analysis temporal difference learning functionapproximation. IEEE Transactions Automatic Control. 42(5), 674-690.Watkins C.J.C.H. & Dayan P. (1992). Q-Learning. Machine Learning. 8, 279-292.Young P. (1984). Recursive Estimation Time-Series Analysis. Springer-Verlag.292fiJournal Artificial Intelligence Research 16 (2002) 1-58Submitted 7/01; published 1/02Fusions Description LogicsAbstract Description SystemsFranz BaaderCarsten Lutzbaader@cs.rwth-aachen.delutz@cs.rwth-aachen.deTeaching Research Area Theoretical Computer Science,RWTH Aachen, Ahornstrae 55, 52074 Aachen, GermanyHolger Sturmholger.sturm@uni-konstanz.deFachbereich Philosophie, Universitat Konstanz,78457 Konstanz, GermanyFrank Wolterwolter@informatik.uni-leipzig.deInstitut fur Informatik, Universitat Leipzig,Augustus-Platz 10-11, 04109 Leipzig, GermanyAbstractFusions simple way combining logics. normal modal logics, fusionsinvestigated detail. particular, known that, certain conditions, decidability transfers component logics fusion. Though description logicsclosely related modal logics, necessarily normal. addition, ABoxreasoning description logics covered results modal logics.paper, extend decidability transfer results normal modal logicslarge class description logics. cover different description logics uniform way,introduce abstract description systems, seen common generalizationdescription modal logics, show transfer results general setting.1. IntroductionKnowledge representation systems based description logics (DL) used represent knowledge application domain structured formally well-understoodway (Brachman & Schmolze, 1985; Baader & Hollunder, 1991; Brachman, McGuinness,Patel-Schneider, Alperin Resnick, & Borgida, 1991; Woods & Schmolze, 1992; Borgida,1995; Horrocks, 1998). systems, important notions domain described concept descriptions, i.e., expressions built atomic concepts (unarypredicates) atomic roles (binary predicates) using concept constructors provideddescription logic employed system. atomic concepts conceptdescriptions represent sets individuals, whereas roles represent binary relationsindividuals. example, using atomic concepts Woman Human, atomicrole child, concept women daughters (i.e., womenchildren women) represented description Woman u child.Woman,concept mothers description Woman u child.Human. example,used constructors concept conjunction (u), value restriction (R.C), existential restriction (R.C). DL literature, also various constructorsconsidered. prominent example so-called number restrictions, availablealmost DL systems. example, using number restrictions concept womenc2002AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiBaader, Lutz, Sturm, & Wolterexactly two children represented concept descriptionWoman u ( 2child) u ( 2child).knowledge base DL system consists terminological component (TBox)assertional component (ABox). simplest form, TBox consists conceptdefinitions, assign names (abbreviations) complex descriptions. general TBoxformalisms allow so-called general concept inclusion axioms (GCIs) complexdescriptions. example, concept inclusionHuman u ( 3child) v entitled.Taxbreakstates people least three children entitled tax break. ABoxformalism consists concept assertions (stating individual belongs concept)role assertions (stating two individuals related role). example,assertions Woman(MARY), child(MARY, TOM), Human(TOM) state Mary woman,child, Tom, human.DL systems provide users various inference capabilities allowdeduce implicit knowledge explicitly represented knowledge. instance, subsumption problem concerned subconcept-superconcept relationships: C subsumed(C v D) if, if, instances C also instances D, i.e., first description always interpreted subset second description. example, conceptdescription Woman obviously subsumes concept description Woman u child.Woman.concept description C satisfiable iff non-contradictory, i.e., interpretednonempty set. DLs allowing conjunction negation concepts, subsumption reduced (un)satisfiability: C v iff C u unsatisfiable. instancechecking problem consists deciding whether given individual instance givenconcept. example, w.r.t. assertions above, MARY instance conceptdescription Woman u child.Human. ABox consistent iff non-contradictory,i.e., model. DLs allowing negation concepts, instance problemreduced (in)consistency ABoxes: instance C w.r.t. ABox iff A{C(i)}inconsistent.order ensure reasonable predictable behavior DL system, reasoningDL employed system least decidable, preferably lowcomplexity. Consequently, expressive power DL question must restrictedappropriate way. imposed restrictions severe, however, importantnotions application domain longer expressed. Investigating trade-offexpressivity DLs complexity inference problems thusone important issues DL research (see, e.g., Levesque & Brachman,1987; Nebel, 1988; Schmidt-Schau, 1989; Schmidt-Schau & Smolka, 1991; Nebel, 1990;Donini, Lenzerini, Nardi, & Nutt, 1991, 1997; Donini, Hollunder, Lenzerini, Spaccamela,Nardi, & Nutt, 1992; Schaerf, 1993; Donini, Lenzerini, Nardi, & Schaerf, 1994; De Giacomo& Lenzerini, 1994a, 1994b, 1995; Calvanese, De Giacomo, & Lenzerini, 1999; Lutz, 1999;Horrocks, Sattler, & Tobies, 2000).paper investigates approach extending expressivity DLs (in manycases) guarantees reasoning remains decidable: fusion DLs. order explain2fiFusions Description Logics Abstract Description Systemsdifference usual union fusion DLs, let us consider simpleexample. Assume DL D1 ALC, i.e., provides Boolean operators u, t,additional concept constructors value restriction R.C existential restrictionR.C, DL D2 provides Boolean operators number restrictions( nR) ( nR). application requires concept constructors DLsexpressing relevant concepts, one would usually consider union D1 D2 D1D2 , allows unrestricted use constructors. example, conceptdescription C1 := (R.A) u (R.A) u ( 1R) legal D1 D2 description. Notedescription unsatisfiable, due interaction constructors D1 D2 .fusion D1 D2 D1 D2 prevents interactions imposing following restriction:one assumes set role names partitioned two sets, one usedconstructors D1 , another one used constructors D2 . Thus,description C1 legal D1 D2 description since uses role Rexistential restrictions (which D1 -constructors) number restriction(which D2 -constructor). contrast, descriptions (R1 .A) u (R1 .A) u ( 1R2 )(R1 .( 1R2 )) admissible D1 D2 since employ different roles D1 D2 -constructors. concepts must expressed requireconstructors D1 D2 , ones D1 roles onesD2 , one really need union D1 D2 ; fusion would sufficient.advantage taking fusion instead union? Basically, uniontwo DLs one must design new reasoning methods, whereas reasoning fusionreduced reasoning component DLs. Indeed, reasoning union may evenundecidable whereas reasoning fusion still decidable. example, considerDLs (i) ALCF, extends basic DL ALC functional roles (features)same-as constructor (agreement) chains functional roles (Hollunder & Nutt, 1990;Baader, Burckert, Nebel, Nutt, & Smolka, 1993); (ii) ALC +,,t , extends ALCtransitive closure, composition, union roles (Baader, 1991; Schild, 1991).DLs, subsumption concept descriptions known decidable (Hollunder & Nutt,1990; Schild, 1991; Baader, 1991). However, union ALCF +,,t undecidablesubsumption problem (Baader et al., 1993). undecidability result depends factthat, ALCF +,,t , role constructors transitive closure, composition, unionapplied functional roles also appear within same-as constructor.allowed fusion ALCF ALC +,,t . course, failure certain undecidability proofmake fusion decidable.know fusion decidable DLs decidable? Actually,general dont, main reason writing paper. notion fusion introduced investigated modal logic, basically transfer results like finiteaxiomatizability, decidability, finite model property, etc. uni-modal logics (with onepair box diamond operators) multi-modal logics (with several pairs, possibly satisfying different axioms). led rather general transfer results (see, e.g.,Wolter, 1998; Kracht & Wolter, 1991; Fine & Schurz, 1996; Spaan, 1993; Gabbay, 1999results concern decidability), sometimes restricted so-called normalmodal logics (Chellas, 1980). Since close relationship modal logicsDLs (Schild, 1991), clear transfer results also apply DLs. question is, however, DLs exactly inference problems. First, DLs3fiBaader, Lutz, Sturm, & Wolterallow constructors considered modal logics (e.g., same-as constructormentioned above). Second, DL constructors considered modal logics, qualified number restrictions ( nR.C), ( nR.C) (Hollunder & Baader, 1991),correspond graded modalities (Van der Hoek & de Rijke, 1995), easilyshown non-normal. Third, transfer results decidability concernedsatisfiability problem (with without general inclusion axioms). ABoxes relatedinference problems considered. ABoxes simulated modal logics allowingso-called nominals, i.e., names individuals, within formulae (Prior, 1967; Gargov& Goranko, 1993; Areces, Blackburn, & Marx, 2000). However, see below,general transfer results apply modal logics nominals.purpose paper clarify DLs decidability component DLstransfers fusion. purpose, introduce so-called abstract description systems(ADSs), seen common generalization description modal logics.define fusion ADSs, state four theorems say conditionsdecidability transfers component ADSs fusion. Two theoremsconcerned inference w.r.t. general concept inclusion axioms two inferencewithout TBox axioms. cases, first formulate prove resultsconsistency problem ABoxes (more precisely, corresponding problem ADSs)establish analogous results satisfiability problem concepts.DL point view, four theorems shown paper concernedfollowing four decision problems:(i) decidability consistency ABoxes w.r.t. TBox axioms (Theorem 17);(ii) decidability satisfiability concepts w.r.t. TBox axioms; (Corollary 22);(iii) decidability consistency ABoxes without TBox axioms (Theorem 29);(iv) decidability satisfiability concepts without TBox axioms (Corollary 34).theorems imply decidability consistency problem satisfiabilityproblem transfers fusion DLs considered literature. main exceptions (which satisfy prerequisites theorems)(a) DLs propositionally closed, i.e., contain Boolean connectives;(b) DLs allowing individuals (called nominals modal logic) concept descriptions;(c) DLs explicitly allowing universal role negation roles.Results modal logic problem (iv) usually require component modal logicsnormal. Theorem 29 less restrictive, thus also applies DLs allowingconstructors like qualified number restrictions.2. Description logicsdefining abstract description systems next section, introduce mainfeatures DLs must covered definition. purpose, first introduce4fiFusions Description Logics Abstract Description SystemsALC, basic DL containing Boolean connectives, relevant inference problems.Then, consider different possibilities extending ALC expressive DLs.Definition 1 (ALC Syntax). Let NC , NR , NI countable pairwise disjoint setsconcept, role, individual names, respectively. set ALC concept descriptionssmallest set1. every concept name concept description,2. C concept descriptions R role name, following expressions also concept descriptions:C (negation), C u (conjunction), C (disjunction),R.C (existential restriction), R.C (value restriction).use > abbreviation abbreviation u (wherearbitrary concept name).Let C concept descriptions. C v general concept inclusion axiom(GCI). finite set axioms called TBox.Let C concept description, R role name, i, j individual names. C(i)concept assertion R(i, j) role assertion. finite set assertions calledABox.meaning ALC-concept descriptions, TBoxes, ABoxes definedhelp set-theoretic semantics.Definition 2 (ALC Semantics). ALC-interpretation pair (I , ),nonempty set, domain interpretation, interpretation function.interpretation function mapsconcept name subset AI ,role name R subset RI ,individual name element iI different names mappeddifferent elements (unique name assumption).role name R element define RI (a) := {b | (a, b) RI }.interpretation function inductively extended complex concepts follows:(C)I := \ C(C u D)I := C DI(C D)I := C DI(R.C)I := {a | RI (a) C 6= }(R.C)I := {a | RI (a) C }interpretation model TBox iff satisfies C DI GCIs C v. model ABox iff satisfies iI C concept assertions C(i)(iI , j ) RI role assertions R(i, j) A. Finally, model ABoxrelative TBox iff model ABox TBox.5fiBaader, Lutz, Sturm, & WolterGiven semantics, formally define relevant inference problems.Definition 3 (Inferences). Let C concept descriptions, individual name,TBox, ABox. say C subsumes relative TBox (D vT C)iff DI C models . concept description C satisfiable relativeTBox iff exists model C 6= . individual instanceC ABox relative TBox iff iI C models relative .ABox consistent relative TBox iff exists model relative .three inferences also considered without reference TBox: C subsumes(C satisfiable) iff C subsumes (C satisfiable) relative empty TBox,instance C (A consistent) iff instance C (A consistent)relative empty TBox.restrict attention DLs propositionally closed (i.e., allowBoolean operators conjunction, disjunction, negation). Consequently, subsumptionreduced (un)satisfiability since C vT iff C u unsatisfiable relative .Conversely, (un)satisfiability reduced subsumption since C unsatisfiable relativeiff C vT . reason, irrelevant whether consider subsumptionsatisfiability problem results concerning transfer decidability problemscomponent DLs fusion (informally called transfer results following).Similarly, instance problem reduced (in)consistency problem viceversa: instance C relative iff {C(i)} inconsistent relative ;inconsistent relative iff instance relative ,arbitrary individual name. Consequently, irrelevant whether consider instanceproblem consistency problem transfer results.Finally, satisfiability problem reduced consistency problem: C satisfiable relative iff ABox {C(i)} consistent relative , arbitraryindividual name. However, converse need true. obviousimplies transfer result satisfiability problem yield correspondingtransfer result consistency problem: decidability consistency problemcomponent DLs deduce decidability satisfiability problemfusion. might less obvious transfer result consistency problem needimply corresponding transfer result satisfiability problem: satisfiabilityproblems component DLs decidable, transfer result consistencyproblem applied (since prerequisite transfer result, namely, decidability consistency problem component DLs, need satisfied). However,show method used show transfer result consistency problemalso applies satisfiability problem.2.1 expressive DLsseveral possibilities extending ALC order obtain expressive DL.three prominent adding additional concept constructors, adding role constructors, formulating restrictions role interpretations. addition giving examplesextensions, also introduce naming scheme obtained DLs. Additionalconcept constructors indicated appending caligraphic letters language name,role constructors symbols superscript, restrictions roles letters subscript.6fiFusions Description Logics Abstract Description Systemsstart introducing restrictions role interpretations, since need referrestrictions defining certain concept constructors.2.1.1 Restrictions role interpretationsrestrictions enforce interpretations roles satisfy certain properties,functionality, transitivity, etc. consider three prominent examples:1. Functional roles. one considers subset NF set role names NR ,whose elements called features. interpretation must map features f NFfunctional binary relations f , i.e., relations satisfying a, b, c.f (a, b)f (a, c) b = c. sometimes treat functional relations partial functions,write f (a) = b rather f (a, b). ALC extended features denotedALC f .2. Transitive roles. one considers subset NR+ NR . Role names R NR+called transitive roles. interpretation must map transitive roles R NR+transitive binary relations RI . ALC extended transitive rolesdenoted ALC R+ .3. Role hierarchies. role inclusion axiom expression form R vR, NR . finite set H role inclusion axioms called role hierarchy.interpretation must satisfy RI R v H. ALC extended rolehierarchy H denoted ALC H(H) . H clear context irrelevant,write ALCH instead ALC H(H) .restrictions also combined other. example, ALC HR+ ALCrole hierarchy transitive roles.Transitive roles DLs first investigated Sattler (1996). Features introduced DLs Hollunder Nutt (1990) (under name attributes)CLASSIC system (Brachman et al., 1991), cases conjunction feature agreements disagreements (see concept constructors below). Features without agreementsdisagreements are, e.g., used DL SHIF (Horrocks & Sattler, 1999), albeitexpressive local way, functionality asserted hold certain individuals, necessarily whole model. According naming scheme, indicatepresence features DL letter f subscript.1remark role hierarchies also order: definition, H1 H2 differentrole hierarchies, ALC H(H1 ) ALC H(H2 ) different DLs. DL literature,usually one logic ALCH defined role hierarchies treated like TBoxes, i.e.,satisfiability subsumption defined relative TBoxes role hierarchies (see, e.g.,Horrocks, 1998). purposes, however, convenient define one DL per rolehierarchy since distinct role hierarchies impose distinct restrictions interpretationroles. advantages approach become clear later frames abstractdescription systems introduced.1. Note authors (e.g., Horrocks & Sattler, 1999) use appended F denote local features.Following Hollunder Nutt (1990), use F denote DL allows feature agreements(see below).7fiBaader, Lutz, Sturm, & WolterNameUnqualifiednumber restrictionsQualifiednumber restrictionsNominalsFeature agreementdisagreementSyntaxnRnRnR.CnR.Cu1 u2u1 u2Semantics{a | |RI (a)| n}{a | |RI (a)| n}{a | |RI (a) C | n}{a | |RI (a) C | n}|I | = 1{a | b . uI1 (a) = b = uI2 (a)}{a | b1 , b2 .uI1 (a) = b1 6= b2 = uI2 (b1 )}SymbolNQFFigure 1: description logic concept constructors.2.1.2 Concept constructorsConcept constructors take concept and/or role descriptions transformcomplex concept descriptions. addition constructors available ALC, variousconcept constructors considered DL literature. small collectionconstructors found Figure 1, |S| denotes cardinality set S.symbols rightmost column indicate naming scheme resulting DL.mentioned name modifiers concept constructors written subscript,appended language name. example, ALC HR+ extended qualifiednumber restrictions called ALCQHR+ . syntax extended DLs expected, i.e.,constructors may arbitrarily combined. semantics obtained augmentingsemantics ALC appropriate conditions, found thirdcolumn Figure 1. Nominals feature (dis)agreements need explanation:Nominals. consider set (names for) nominals, pairwise disjointsets NC , NR , NI . Elements often denoted (possiblyindex). interpretation must map nominals singleton subsets .intention underlying nominals stand elements , like individualnames. However, since want use nominal (nullary) conceptconstructor, must interpret set, namely singleton set consistingindividual denotes.Feature (dis)agreements. ALCF extension ALC f feature agreementsdisagreements. Beside additional concept constructors, ALCF uses featurechains part (dis)agreement constructor. feature chain expressionform u = f1 fn . interpretation uI feature chaincomposition partial functions f1I , . . . , fnI , composition readleft right.DLs including nominals feature (dis)agreements additional concept constructorsrestrictions role interpretations defined (and named) obvious way.Number restriction available almost DL systems. DL ALCN (i.e., ALCextended number restrictions) first treated Hollunder Nutt (1990),ALCF. DL ALCQ first investigated Hollunder Baader (1991), ALCOSchaerf (1994).8fiFusions Description Logics Abstract Description SystemsNameRole compositionSyntaxR1 R2Semantics{(a, b) |c . (a, c) R1I (c, b) R2I }Role complement R{(a, b) | (a, b)/ RI }Role conjunctionR1 u R2 {(a, b) | (a, b) R1I (a, b) R2I }Role disjunctionR1 R2 {(a, b) | (a, b) R1I (a, b) R2I }Inverse rolesR1{(a, b) | (b, a) RI }Transitive closure R+{(a, b) | (a, b) (RI )+ }Universal roleUbinary relation R, R+ denotes transitive closure R.Symbolu1+UFigure 2: description logic role constructors.2.1.3 Role constructorsRole constructors allow us build complex role descriptions. collection role constructors found Figure 2. Again, rightmost column indicates naming scheme,name modifiers role constructors written superscript separatedcommas. example, ALCQ inverse roles transitive closure called ALCQ+,1 .DLs admitting role constructors, set role descriptions defined inductively, analogously set concept descriptions. semantics role constructors giventhird column Figure 2. concept descriptions, used extendinterpretation function role names role descriptions.DL role constructors, role descriptions used wherever role names mayused corresponding DLs without role constructors. example,(R1 u R3 ).C u (R2 R2 ).C,u,tALC-concept description. concept description unsatisfiable since R2 R2equivalent universal role. Note role descriptions also used within roleassertions ABox.DL ALC ,t,+ first treated Baader (1991) (under name ALC trans ); Schild(1991) shown DL notational variant propositional dynamic logic (PDL).DLs Boolean operators roles investigated Lutz Sattler (2000).inverse operator available system CRACK (Bresciani, Franconi, & Tessaris,1995), reasoning DLs inverse roles was, example, investigated Calvaneseet al. (1998) Horrocks et al. (2000). universal role expressed using DLsBoolean operators roles (see example), turn used simulategeneral concept inclusion axioms within concept descriptions.2.2 Restricting syntaxnow, constructors could combined arbitrarily. Sometimes makes sense restrictinteraction constructors since reasoning restricted DL may easierreasoning unrestricted DL. consider DLs imposing certain restrictions9fiBaader, Lutz, Sturm, & Wolter1. roles may used inside certain concept constructors,2. roles may used inside certain role constructors,3. combination role constructors,4. role constructors may used inside certain concept constructors.example first case, consider fragment ALCQR+ transitive rolesmay used existential universal restrictions, number restrictions (see,e.g., Horrocks et al., 2000).result taking fusion two DLs, obtain DLs whose set roles NRpartitioned. example, fusion ALCQ ALC 1 yields fragment ALCQ1NR partitioned two sets, say NR1 NR2 . fragment, inverse roleconstructor roles NR2 may used within qualified number restrictions,roles NR1 may used inside inverse role constructor.2 Thus, DLexample first, second, fourth case.consider DL ALCF introduced above, extend ALC ffeature (dis)agreement concept constructor, also provides role composition constructor. However, role chains built using composition comprised exclusivelyfeatures non-functional roles may appear inside feature (dis)agreement. Hence,ALCF also example first, second, fourth case.example third case, fragment ALC ,u role conjunctionmay used inside role complement constructor considered Lutz Sattler(2000).restricted DLs, introduce explicit naming scheme. Note that,paper, deal DLs combinability concept constructorsrestricted since DLs would fit framework abstractdescription systems introduced next section. example DL wouldone atomic negation concepts, i.e., negation may applied conceptnames (e.g., DL AL discussed Donini et al., 1997).3. Abstract description systemsorder define fusion DLs prove general results fusions DLs, one needsformal definition description logics. Since exists wide variety DLsdifferent characteristics, introduce general formalization,cover DLs considered literature, also includes logics would usuallysubsumed name DL.3.1 Syntax semanticssyntax abstract description system given abstract description language,determines set terms, term assertions, object assertions. setting,concept descriptions represented terms built using abstract description2. become clearer given formal definition fusion.10fiFusions Description Logics Abstract Description Systemslanguage. General inclusion axioms DLs represented term assertions ABoxassertions DLs represented object assertions.Definition 4 (Abstract description language). abstract description language (ADL)determined countably infinite set V set variables, countably infinite set Xobject variables, (possibly infinite) countable set R relation symbols arity two,3(possibly infinite) countable set F functions symbols f , equipped aritiesnf . sets pairwise disjoint.terms tj ADL built using follow syntax rules:tjx, t1 , t1 t2 , t1 t2 , f (t1 , . . . , tnf ),x V , f F, Boolean operators , , different functionsymbols F. term t, denote var(t) set set variables used t.symbol > used abbreviation x x abbreviation x x (wherex set variable).term assertions ADLt1 v t2 , terms t1 , t2 ,object assertionsR(a, b), a, b X R R;(a : t), X term.sets term object assertions together form set assertions ADL.DL point view, set variables correspond concept names, objectvariables individual names, relation symbols roles, Boolean operators wellfunction symbols correspond concept constructors. Thus, terms correspondconcept descriptions. example, let us view concept descriptions DL ALCN u ,i.e., ALC extended number restrictions conjunction roles, terms ADL.Value restrictions existential restrictions seen unary function symbols:role description R, function symbols fR fR , take term tC(corresponding concept description C) transform complex termsfR (tC ) fR (tC ) (corresponding concept descriptions R.C R.C). Similarly,number restrictions seen nullary function symbols: role description Rn N, function symbols fnR fnR . Hence, ALCN u -conceptdescription u (R1 u R2 ).(B u ( 2R1 )) corresponds term xA f(R1 uR2 ) ((xBf(2R1 ) )). analyze connection ADLs DLs formally later on.semantics abstract description systems defined based abstract descriptionmodels. models general semantic structures terms ADLinterpreted. already noted here, however, abstract descriptionsystem usually take account abstract description models availablelanguage: allows selected subclass models. subclass determinessemantics system.3. keep things simpler, restrict attention case binary predicates, i.e., roles DL.However, results easily extended n-ary predicates.11fiBaader, Lutz, Sturm, & WolterDefinition 5. Let L ADL Definition 4. abstract description model (ADM)L formEW = W, F W = {f W | f F}, RW = {RW | R R} ,ffW nonempty set, f W functions mapping every sequence X1 , . . . , Xnfsubsets W subset W , RW binary relations W .Since ADMs interpret variables, need assignment assigns subsetW set variable, evaluate terms ADM. evaluate objectassertions, need additional assignment assigns element W objectvariable.ffDefinition 6. Let L ADL W = W, F W , RW ADM L. assignmentW pair = (A1 , A2 ) A1 mapping set set variables V2W , A2 injective4 mapping set object variables X W . Let WADM = (A1 , A2 ) assignment W. L-term t, inductivelyassociate value tW,A 2W follows:xW,A := A1 (x) variables x V ,t2W,A ,, (t1 t2 )W,A := tW,AtW,A(t)W,A := W \ (t)W,A , (t1 t2 )W,A := tW,A121f (t1 , . . . , tnf )W,A := f W (tW,A, . . . , tW,Anf ).1x1 , . . . , xn set variables occurring t, often write tW (X1 , . . . , Xn )shorthand tW,A , assignment xA= Xi 1 n.truth-relation |= hW, Ai assertions defined follows:hW, Ai |= R(a, b) iff A2 (a)RW A2 (b),hW, Ai |= : iff A2 (a) tW,A ,.tW,AhW, Ai |= t1 v t2 iff tW,A21case say assertion satisfied hW, Ai. If, ADM W setassertions , exists assignment W assertion satisfiedhW, Ai, W model .two differences ADMs DL interpretations. First, DL interpretation, interpretation role names fixes interpretation functionsymbols corresponding concept constructors involve roles (like value restrictions,number restrictions, etc.). interpretation concept names corresponds assignment. Thus, DL model ADM together assignment, whereas ADMalone corresponds called frame modal logics. Second, DL roles usedconcept constructors may, course, also occur role assertions. contrast, definitionADMs per se enforce connection interpretation functionsymbols interpretation relation symbols. connections can, however,enforced restricting attention subclass possible ADMs ADL.4. corresponds unique name assumption.12fiFusions Description Logics Abstract Description SystemsDefinition 7. abstract description system (ADS) pair (L, M), L ADLclass ADMs L closed isomorphic copies.5DL point view, choice class defines semanticsconcept role constructors, allows us, e.g., incorporate restrictions roleinterpretations. sense, ADS viewed determining (description) logic.concrete, DL interpretation interpretation function symbolsdetermined interpretation role names. Thus one can, example, restrictclass models ADMs interpret certain role transitive relationcomposition two roles. Another restriction realized choicenominals (corresponding nullary function symbols) must interpretedsingleton sets.Let us define reasoning problems abstract description systems. introducesatisfiability sets assertions (with without term assertions), correspondsconsistency ABoxes (with without GCIs), satisfiability terms (with withoutterm assertions), corresponds satisfiability concept descriptions (with withoutGCIs).Definition 8. Given ADS (L, M), finite set assertions called satisfiable(L, M) iff exists ADM W assignment W hW, Aisatisfies assertions . term called satisfiable (L, M) iff {a : t} satisfiable(L, M), arbitrary object variable.satisfiability problem (L, M) concerned following question: givenfinite set object assertions L, satisfiable (L, M).relativized satisfiability problem (L, M) concerned following question: given finite set assertions L, satisfiable (L, M).term satisfiability problem (L, M) concerned following question:given term L, satisfiable (L, M).relativized term satisfiability problem (L, M) concerned followingquestion: given term set term assertions L, {a : t} satisfiable(L, M).next section, define fusion two ADSs, show (relativized)satisfiability decidable fusion (relativized) satisfiability component ADSsdecidable. transfer results hold, must restrict so-called localADSs.ffWp , RWp pairwiseDefinition 9. Given family (Wp )pPADMs Wp = Wp , Fffdisjoint domains Wp , say W = W, F W , RW disjoint union (Wp )pP iffW = pP Wp ,5. Intuitively, means that, ADM W belongs M, ADMs differ w.r.t.names elements domain W also belong M.13fiBaader, Lutz, Sturm, & Wolterf W (X1 , . . . , Xnf ) = pP f Wp (X1 Wp , . . . , Xnf Wp ) f FX1 , . . . , Xnf W ,RW = pP RWp R R.ADS = (L, M) called local iff closed disjoint unions.remainder section, first analyze connection ADSs DLsdetail, comment relationship modal logics.3.2 Correspondence description logicsshow DLs introduced Section 2 correspond ADSs. order this,first need introduce frames, notion well-known modal logic. Let L oneDLs introduced Section 2.Definition 10 (Frames). L-frame F pair (F , F ), F nonempty set,called domain F, F interpretation function, mapsnominal singleton subset F F ,role name R subset RF F F restrictions roleinterpretations L satisfied. example, ALC R+ , R NR+ mappedtransitive binary relation.interpretation function F inductively extended complex roles obviousway, i.e., interpreting role constructors L according semantics givenFigure 2.interpretation based frame F iff = F , RI = RF roles R NR ,= F nominals .frame viewed interpretation partial sense interpretation individual concept names fixed. Note (in contrast caseconcept individual names) interpretation nominals already fixed frame.reason that, interpret nominals frame,treat set variables ADS side. would, however, variablessingleton sets may assigned. Since restriction possibleframework ADSs defined above, interpret nominals frame. consequencecorrespond functions arity 0 ADS side.Now, define abstract description system = (L, M) corresponding DL L.straightforward translate syntax L abstract description language L.Definition 11 (Corresponding ADL). Let L DL concept role constructorswell restrictions role interpretations introduced Section 2. correspondingabstract description language L defined follows. every concept name L,exists set variable xA L, every individual name L exists objectvariable ai L. Let R set (possibly complex) role descriptions L. setrelation symbols L R, set function symbols L smallest set containing1. every role description R R, unary function symbols fR fR ,14fiFusions Description Logics Abstract Description Systems2. L provides unqualified number restrictions, then, every n N every roledescription R R, function symbols fnR fnR arity 0,3. L provides qualified number restrictions, then, every n N every role R R,unary function symbols fnRfnR,4. L provides nominals, then, every , function symbol fI arity 0,5. L provides feature agreement disagreement, then, every pair feature chains(u1 , u2 ), two function symbols fu1 u2 fu1 u2 arity 0.L-concept description C, let tC denote representation C L-term,defined obvious way: concept names translated set variables xA ,concept constructors , u, mapped , , , respectively,concept constructors translated corresponding function symbols. Obviously,sets function relation symbols L may infinite.example translation concept descriptions terms ADL alreadygiven above: ALCN u -concept description u (R1 u R2 ).(B u ( 2R1 )) correspondsterm xA f(R1 uR2 ) ((xB f(2R1 ) )).define set abstract description models corresponding DL L.every L-frame, contains corresponding ADM.Definition 12 (CorrespondingLetF = (F , F ) frame. correspondingADM).ffabstract description model W = W, F W , RW domain W := F . relation symbolsL role descriptions L, thus interpreted frame F.relation symbol R R hence define RW := RF .define F W , need define f W every nullary function symbol f L,Wf (X) every unary function symbol f L every X . Let arbitraryconcept name. X F , let IX interpretation based F mappingconcept name X every concept name .6 define f W , make casedistinction according type f :W (X) := (R.A)IX ,1. fRW (X) := (R.A)IX ,fRW := (nR)I , f W := (nR)I ,2. fnRnRW (X) := (nR.A)IX , f W (X) := (nR.A)IX ,3. fnRnR4. fIW := ,5. fuW1 u2 = (u1 u2 )I , fuW1 u2 = (u1 u2 )I .class ADMs thus obtained DL L obviously closed isomorphic copies since also holds set L-frames (independently DL Lconsider). Hence, tuple = (L, M) corresponding DL L indeed ADS.example, let us view DL ALCN u ADS. ADL L correspondingALCN u already discussed. Thus, concentrate class ADMs induced6. Taking empty set arbitrary.15fiBaader, Lutz, Sturm, & Wolterframes ALCN u . Assume F frame, i.e., F consistsnonemptyffdomain interpretations RF role names R. ADM W = W, F W , RW inducedF defined follows. set W identical domain F. role descriptionyields relation symbol, interpreted W frame. example,(R1 u R2 )W = R1F R2F . remains define interpretation function symbols.illustrate two examples. First, consider (unary) function symbol f(R1 uR2 ) .WGiven subset X W , function f(Rmaps X1 uR2 )Wf(R(X) := {w W | v X v (w, v) R1F R2F },1 uR2 )i.e., interpretation concept description (R1 u R2 ).A interpretations basedF interpreting X. Accordingly, value constant symbol f(2R) Wgiven interpretation ( 2R) interpretations based F.easy show interpretation concept descriptions L coincidesinterpretation corresponding terms = (L, M).ffLemma 13. Let F frame, W = W, F W , RW ADM corresponding F, =(A1 , A2 ) assignment W, C concept description, let concept namesused C among A1 , . . . , Ak . interpretations based F AIi = A1 (xAi )1 k,C = tW,A.Ceasy consequence lemma, close connection reasoningDL L reasoning corresponding ADS. Given TBox ABoxDL L, define corresponding set S(T , A) assertions corresponding ADL(L, M) obvious way, i.e., GCI C v yields term assertion tC v tD ,role assertion R(i, j) yields object assertion R(ai , aj ), concept assertionC(i) yields object assertion ai : tC .Proposition 14. ABox consistent relative TBox L iff S(T , A)satisfiable corresponding ADS.treat non-relativized consistency explicitly since special caserelativized consistency TBox empty.already mentioned above, transfer results require component ADSslocal. call DL L local iff ADS (L, M) corresponding L local. turnsDLs introduced Section 2 local.Proposition 15. Let L one DLs introduced Section 2. Then, L local iff Linclude following constructors: nominals, role complement, universalrole.Proof. start direction, interesting since showsADSs corresponding DLs nominals, role complement, universal rolelocal. make case distinction according constructors L contains.Nominals. Consider disjoint union W ADMs W1 W2 , assumeW1 W2 correspond frames DL nominals. definition16fiFusions Description Logics Abstract Description Systemsdisjoint union, know W1 W2 = . nominal,definition disjoint union implies fIW = fIW1 fIW2 . Since nominalsinterpreted singleton sets W1 W2 , since domains W1 W2disjoint, implies fIW set cardinality 2. Consequently, W cannotcorrespond ADM induced frame DL nominals, since framesinterpret nominals singleton sets.Universal role. Again, consider disjoint union W ADMs W1 W2 ,assume W1 W2 correspond frames DL universal role. Let Udenote universal role, i.e., role name interpretation restrictedbinary relation relating pair individuals domain. definitiondisjoint union, U W = U W1 U W2 = W1 W1 W2 W2 6= W W .Consequently, W cannot correspond ADM induced frame DLuniversal role, since frame would interpret U W W .Role complement. Again, consider disjoint union W ADMs W1 W2 ,assume W1 W2 correspond frames DL role negation.WWWarbitrary role name R, R = R 1 R 2 = (W1 W1 \ RW1 ) (W2W2 \ RW2 ) 6= (W1 W2 ) \ (RW1 RW2 ) = W \ RW .remains prove direction. Assume L one DLs introducedSection 2 allow nominals, role complements,universal role.Letff(Fp )pP family L-frames Fp = (Fp , Fp ) let Wp = Wp , F Wp , RWpADMs corresponding them. definition, Fp = Wp p P . Assumedomains (Wp )pP pairwise disjoint. must show disjoint union (Wp )pPalso corresponds L-frame. purpose, define frame F = (F , F )follows:F :=RF :=pPFppPRFp R NR .ffLet W = W, F W , RWADM correspondingF.WpBy Definition 12 (corWresponding ADM), W = pP Wp R = pP RR NR .induction structure complex roles, easy show also holdsR R, i.e., complex role descriptions. example, consider role descriptionWWR1 R2 . induction, know R1W = pP R1 p R2W = pP R2 p . Sincesets (Wp )pP pairwise disjoint,(R1 R2 )W = R1W R2W =[pPWpR1[WpR2pP=[pPWpR1WpR2=[(R1 R2 )Wp .pPSince RWp = RFp R R p P , obtain following fact:() p P , Fp , role descriptions R R, following holds: RF (a) =RFp (a); particular, RF (a) Fp .17fiBaader, Lutz, Sturm, & Wolterremains show that, n 0, X1 , . . . , Xn W , function symbols farity n,[f W (X1 , . . . , Xn ) =f Wp (X1 Wp , . . . , Xn Wp ).pPproved making case distinction according type f . treat twocases exemplarily.f = fu1 u2 . Since W = pP Wp sets Wp pairwise disjoint, fuW1 u2disjoint union sets fuW1 u2 Wp p P . remains show fuW1 u2 Wp =WWWpppfu1 u(p P ). definition fu1 u, know fu1 uiff Fp ,222FFFFu1 p (a) u2 p (a) defined, u1 p (a) = u2 p (a). (), case iffFp , uF1 (a) uF2 (a) defined uF1 (a) = uF2 (a), equivalentfuW1 u2 Wp .W (X)f = fnR. Since W = pP Wp sets Wp pairwise disjoint, fnRW (X) W p P . remains showdisjoint union sets fnRpWWW (X) W = f p (X W ) (p P ). definition f p , knowfnRppnRnRWpfnR(X Wp ) iff Fp |RFp (a) (X Wp )| n. (), case iffW (X) W .|RF (a) (X Wp )| n iff |RF (a) X| n, hence iff fnRpnoted arguments similar ones used proofdirection show that, presence universal role role negation, functionsymbols (e.g., fU ) may also violate locality condition.transfer results decidability developed paper apply fusionslocal ADSs. Hence, direction proposition implies resultsapplicable fusions ADSs corresponding DLs incorporate nominals, rolecomplement, universal role.3.3 Correspondence modal logicspaper concern fusions description logics modal logics. Nevertheless,useful brief look relationship ADSs modal logic. Standardmodal languages regarded ADLs without relation symbols object variables(just identify propositional formulas terms). Given ADL L, set L L-termscalled classical modal logic iff contains tautologies classical propositional logicclosed modus ponens, substitutions, regularity rulex1 y1 , . . . , xnf ynff (x1 , . . . , xnf ) f (y1 , . . . , ynf )function symbols f L. minimal classical modal logic language oneunary function symbol known logic E (see Chellas, 1980).ADS (L, M) based L determines classical modal logic L taking validterms, i.e., definingL iff tW,A = W W assignments W.18fiFusions Description Logics Abstract Description Systemslogic E determined ADS precisely one unary operator whose classADMs consists models. Chellas formulates completeness result (Theorem9.8 Chellas, 1980) so-called minimal models (alias neighborhood-frames), are,however, notational variant abstract description models one unary operator(Dosen, 1988). classical modal logic L determined ADS decidable termsatisfiability problem, L decidable since L iff unsatisfiable.classical modal logic L called normal iff additionally containsf (x1 , . . . , xj1 , xj yj , xj+1 , . . . , xnf ) f (x1 , . . . , xj1 , xj , xj+1 , . . . , xnf )f (x1 , . . . , xj1 , yj , xj+1 , . . . , xnf )f (>, , . . . , ), f (, >, , . . . , ), . . . , f (, . . . , , >),function symbols f j 1 j nf (Jonsson & Tarski, 1951; Jonsson &Tarski, 1952; Goldblatt, 1989). definition normal modal logics assumesformulas (terms) built using necessity (box) operators.7 worknecessity operators; corresponding possibility-operators definable puttingf 3 (x1 , . . . , xnf ) = f (x1 , . . . , xnf ).minimal normal modal logic language one unary operator known K(Chellas, 1980).call function F : W n W normal iff 1 j n X1 , . . . , Xn , Yj WF (X1 , . . . , Xj1 , Xj Yj , Xj+1 , . . . , Xn ) = F (X1 , . . . , Xj1 , Xj , Xj+1 , . . . , Xn )F (X1 , . . . , Xj1 , Yj , Xj+1 , . . . , Xn ))F (W, , . . . , ) = F (, W, , . . . , ) = = F (, . . . , , W ) = W.Note unary function F normal iff F (W ) = W F (X ) = F (X) F (Y ),X, W . function symbol f called normal ADS (L, M) iff functionsf W normal W M.role R DL, function symbol fR normal correspondingADS. contrary, readily checked neither fnRfnRduals33fnRfnormal.nRObviously, ADS (L, M) determines normal modal logic iff function symbolsL normal (L, M). Completeness K respect Kripke semantics (Chellas,1980) implies logic K determined ADS one unary operator whoseclass ADMs consists models interpreting operator normal function.7. Note authors define normal modal logics using possibility (diamond) operators, casedefinitions duals introduced thus first sight look quite different.19fiBaader, Lutz, Sturm, & Wolter4. Fusions abstract description systemssection, define fusion abstract description systems prove two transfer theorems decidability, one concerning satisfiability one concerningrelativized satisfiability.Definition 16. fusion S1 S2 = (L1 L2 , M1 M2 ) two abstract descriptionsystems S1 = (L1 , M1 ) S2 = (L2 , M2 )disjoint sets function symbols F L1 G L2 ,disjoint sets relation symbols R L1 Q L2 ,sets set object variablesdefined follows: L1 L2 ADL basedunion F G function symbols L1 L2 ,union R Q relation symbols L1 L2 ,M1 M2 definedEEE{ W, F W G W , RW QW | W, F W , RW M1 W, G W , QW M2 }.example, consider ADSs S1 S2 corresponding DLs ALCFALC +,,t introduced Section 2. concentrate function symbols providedfusion. following, assume set role names employed ALCFALC +,,t disjoint.ADS S1 based following function symbols: (i) unary functions symbolfR fR every role name R ALCF, (ii) nullary functions symbols corresponding same-as constructor every pair chains functional rolesALCF.ADS S2 based following function symbols: (iii) unary functions symbolfQ fQ every role description Q built role names ALC +,,t usingunion, composition, transitive closure.Since assumed set role names employed ALCF ALC +,,t disjoint,sets function symbols also disjoint. union sets provides ussymbols same-as constructor symbols value existential restrictions role descriptions involving union, composition, transitive closure.However, role descriptions contain role names ALC +,,t , thus nonefunctional roles ALCF occurs descriptions. Thus, fusion ALCFALC +,,t yields strict fragment union ALCF +,,t .4.1 Relativized satisfiabilityprove transfer result decidability relativized satisfiability problem, showalso yields corresponding transfer result relativized term satisfiability problem,investigate transfer results extended ADSs correspond DLsproviding universal role.20fiFusions Description Logics Abstract Description Systems4.1.1 transfer resultsection concerned establishing following transfer theorem:Theorem 17. Let S1 S2 local ADSs, suppose relativized satisfiabilityproblems S1 S2 decidable. relativized satisfiability problem S1 S2also decidable.idea underlying proof theorem translate given set assertionsS1 S2 set assertions 1 S1 set assertions 2 S2satisfiable S1 S2 iff 1 satisfiable S1 2 satisfiable S2 . first (naive)idea obtain set (i = 1, 2) replace alien terms (i.e., subtermsstarting function symbols belonging Si ) new set variables (the surrogatevariables introduced below). approach, satisfiability would fact implysatisfiability sets , converse would true. difficulty arisestrying combine models 1 2 one . ensure two modelsindeed combined, sets must contain additional assertions make suresurrogate variables one model corresponding alien subtermsmodel interpreted compatible way. precise, (finitely many)different ways adding assertions, one must try (if any) leadssatisfiable pair 1 2 .proof Theorem 17, fix two local ADSs Si = (Li , Mi ), {1, 2},L1 based set function symbols F relation symbols R, L2 based GQ. Let L = L1 L2 = M1 M2 .follows, use following notation: set assertions , denoteterm() obj() set terms object names , respectively.start explaining alien subterms set replaced new setvariables. L-term form h(t1 , . . . , tn ), h F G, reserve new variablext , called surrogate t. assume set surrogate variablesdisjoint original sets variables. sketched above, idea underlyingintroduction surrogate variables decision procedure S1 (S2 ) cannot dealterms containing function symbols G (F). Thus, alien function symbolsmust replaced applying procedure. precise, replace wholealien subterm starting alien function symbol surrogate. example,unary symbol f belongs F, unary symbol g belongs G, f (g(f (x)))mixed L-term. obtain term L1 , replace subterm g(f (x)) surrogate,yields f (xg(f (x)) ). Analogously, obtain term L2 , replace whole termsurrogate, yields xf (g(f (x))) . define replacement processformally.Definition 18. L-term without surrogate variables, denote sur1 (t) L1 -termresulting occurrences terms g(t1 , . . . , tn ), g G, withinscope g 0 G replaced surrogate variable xg(t1 ,...,tn ) . setterms, put sur1 () := {sur1 (t) | } define sur2 (t) well sur2 () accordingly.Denote sub() set subterms terms , sub1 () variablesoccurring well subterms alien terms (i.e., terms starting symbol21fiBaader, Lutz, Sturm, & WolterG) . formally, definesub1 () := sub{t | xt var(sur1 ())} var().Define sub2 () accordingly.example, let f F unary g G binary. = f (g(x, f (g(x, y)))),sur1 (t) = f (xg(x,f (g(x,y))) ). Note restriction within scope g 0 Gclarify top-most alien subterms replaced. termexample, sub1 ({t}) = {g(x, f (g(x, y))), f (g(x, y)), g(x, y), x, y}.Note Boolean operators occurring terms shared function symbolssense alien neither L1 L2 . Thus, sur1 (f (x)g(x, y)) = f (x)xg(x,y)sur2 (f (x) g(x, y)) = xf (x) g(x, y).course, replacing whole terms variables, information lost.example, consider (inconsistent) assertion (R1 .((1 R2 )u(2 R2 )))(i) assumeR1 role one component fusion, R2 role component. Translatedabstract description language syntax, concept description R1 .((1 R2 ) u (2 R2 ))yields term := fR1 (f(1 R2 ) f(2 R2 ) ), fR1 function symbol L1two function symbols belong L2 . Now, sur1 (t) = fR1 (x y), xsurrogate f(1 R2 ) surrogate f(2 R2 ) . decision procedurefirst ADS sees fR1 (x y), way know conjunction aliensubterms corresponding x unsatisfiable. fact, procedure xarbitrary set variables, thus x satisfiable. avoid problem, introduceso-called consistency set consisting types, type says relevant formulawhether formula negation supposed hold. sets 1 2contain additional information basically ensures models satisfytypes. allow us merge models one .Definition 19. Given finite set L-terms, define consistency set C()C() := {tc | c }, type tc determined c definedtc :=^{ | c}^{ | \ c}.Given finite set assertions L, define subi () := subi (term()). abbreviateC () := C(subi ()), {1, 2}.example above,sub1 (fR1 (f(1 R2 ) f(2 R2 ) ) = {f(1 R2 ) , f(2 R2 ) },thus C 1 ({ai : fR1 (f(1 R2 ) f(2 R2 ) )}) consists 4 termsf(1 R2 )f(1 R2 )f(1 R2 )f(1 R2 )f(2 R2 ) ,f(2 R2 ) ,f(2 R2 ) ,f(2 R2 ) .22fiFusions Description Logics Abstract Description SystemsGiven set terms , element tc consistency set C() indeed consideredtype element e domain ADM w.r.t. . element ebelongs interpretations terms , complementsinterpretations terms. Thus, c set terms e belongs,e also belongs interpretation tc belong interpretationterms C(). case say e realizes type tc .ready formulate theorem reduces relativized satisfiabilityproblem fusion two local ADSs relativized satisfiability component ADSs.proof theorem found appendix.Theorem 20. Let Si = (Li , Mi ), {1, 2}, two local ADSs L1 basedset function symbols F relation symbols R, L2 based G Q,let L = L1 L2 = M1 M2 . finite set assertions L,following equivalent:1. satisfiable (L, M).2. exist(a) set C 1 (),(b) every term object variable 6 obj(),(c) every obj() term ta D,union 1 following sets assertions L1 satisfiable(L1 , M1 ):W(d) {at : sur1 (t) | D} {> v sur1 ( D)},(e) {a : sur1 (ta ) | obj()},(f ) {R(a, b) | R(a, b) , R R},(g) {sur1 (t1 ) v sur1 (t2 ) | t1 v t2 } {a : sur1 (s) | (a : s) };union 2 following sets assertions L2 satisfiable (L2 , M2 ):W(h) {at : sur2 (t) | D} {> v sur2 ( D)},(i) {a : sur2 (ta ) | obj()},(j) {Q(a, b) | Q(a, b) , Q Q}.Intuitively, (2a) guesses set types (i.e., elements consistency set).idea exactly types realized model (to constructedshowing (2 1) given showing (1 2)). Condition (2b) introducesevery type name object realizing type, (2c) guesses every objectvariable occurring type D.W Regarding (2d) (2h), one note set assertions {at : | D}{> vD} states every type realized (i.e., object modeltype) every object one types D. sets assertions (2d)(2h) obtained set surrogation make digestible decisionprocedures component logics.23fiBaader, Lutz, Sturm, & Wolterassertions (2e) (2i) state (again surrogated versions) objectinterpreting variable type ta . ensures that, models 1 2(given showing (2 1)), objects interpreting type ta D.Otherwise, models could combined common one .sets (2f) (2j) obtained distributing relationship assertions1 2 , depending relation symbol used assertion.set (2g) contains (in surrogated version) term assertions form t1 v t2membership assertions form : .Condition 2 asymmetric two respects. First, guesses subset C 1 () rathersubset C 2 (). course arbitrary, could also chosen index 2 instead1 here. Second, set 2 neither contains assertions {sur2 (t1 ) v sur2 (t2 ) | t1 vt2 } {a : sur2 (s) | (a : s) }. added assertions, theorem wouldstill true, would unnecessarily increase amount work donecombined decision procedure. fact, since assertions 1 2 enforce tightcoordination models 1 2 , fact membership assertionsterm assertions satisfied models 1 implies also satisfiedmodels 2 (see appendix details).prove Theorem 17, must show Theorem 20 used constructdecision procedure relativized satisfiability S1 S2 decision procedurescomponent systems S1 S2 . given finite set assertions S1 S2 , setC 1 () also finite, thus finitely many sets (2a) choices typesobject variables (2c). Consequently, enumerate check whetherone choices leads satisfiable sets 1 2 . definition setsfunctions suri , assertions indeed assertions Li , thus satisfiabilityalgorithm (Li , Mi ) applied . proves Theorem 17.Regarding complexity obtained decision procedure, costly step guessingright set D. Since cardinality set sub1 () linear size ,cardinality C 1 () exponential size (and element size quadratic). Thus, doubly exponentially many different subsets chosen from. Sincecardinality chosen set may exponential size , also size 12 may exponential (because big disjunction D). this,following corollary follows.Corollary 21. Let S1 S2 local ADSs, suppose relativized satisfiabilityproblems S1 S2 decidable ExpTime (PSpace). relativized satisfiability problem S1 S2 decidable 2ExpTime (ExpSpace).p (n)Proof. Assume size n. must consider 22 1 (for polynomial p1 )p (n)different sets (2a). set size 2p1 (n) thus 22 2 choices(2c) (for polynomial p2 ). Overall, still leaves us doubly exponentiallymany choices. assume relativized satisfiability problems S1 S2decidable ExpTime. Since call procedures applied set assertionsp (n)p (n)exponential size, may take double exponential time, say 22 3 22 4 (for polynomialsp3 p4 ). Overall, thus time complexity22p1 (n)22p2 (n)(2224p3 (n)+ 22p4 (n)),fiFusions Description Logics Abstract Description Systemsp(n)clearly majorized 22appropriate polynomial p. showsmembership 2ExpTime.argument regarding space complexity similar. one must additionallytake account doubly exponentially many choices enumerated usingexponentially large counter.4.1.2 relativized term satisfiability problemstatement Theorem 17 imply transfer result relativized termsatisfiability problem. problem decidability relativized term satisfiabilityproblem S1 S2 necessarily imply decidability relativized satisfiabilityproblem ADSs, thus prerequisite theorem apply satisfied.However, consider statement Theorem 20, easy see theoremalso yields transfer result relativized term satisfiability problem.Corollary 22. Let S1 S2 local ADSs, suppose relativized term satisfiability problems S1 S2 decidable. relativized term satisfiability problemS1 S2 also decidable.Proof. Consider satisfiability criterion Theorem 20. interested relativized term satisfiability, form {a : t} 0 , 0 set termassertions. case, sets assertions 1 2 contain object assertionsinvolving relations. Now, assume form {a1 : t1 , . . . , : tn } 0i , 0iset term assertions. Since two assertions form b : s1 , b : s2 equivalentone assertion b : s1 s2 , may assume ai distinct other. Since Silocal, easy see following equivalent:1. {a1 : t1 , . . . , : tn } 0i satisfiable Si .2. {aj : tj } 0i satisfiable Si j = 1, . . . , n.Since (1 2) trivial, enough show (2 1). Given models Wj Mi {aj :tj } 0i (j = 1, . . . , n), disjoint union also belongs Mi , clearly model{a1 : t1 , . . . , : tn } 0i .second condition checked applying term satisfiability test Sin times.4.1.3 Dealing universal rolestated (Proposition 15), ADSs corresponding DLs universal rolelocal, thus Theorem 17 cannot applied directly. Nevertheless, casestheorem also used obtain decidability result fusions DLsuniversal role, provided provide universal role. (We commentusefulness approach detail Section 5.4).Definition 23. Given ADS = (L, M), denote U ADS obtained1. extending L two function symbols fUS fUS ,25fiBaader, Lutz, Sturm, & WolterffW2. extending every ADM W = W, F W , RW unary functions fUW ,fUW (X) = X = , f W (X) = W otherwise;fUUSW (X) = W X = W , f W (X) = otherwise.fUUSADSs corresponding DL L, ADS U corresponds extension Luniversal role, universal role used within value existentialrestrictions.8 close connection relativized satisfiability problemsatisfiability problem U .Proposition 24. local ADS, following conditions equivalent:1. relativized (term) satisfiability problem decidable,2. (term) satisfiability problem U decidable,3. relativized (term) satisfiability problem U decidable.Proof. restrict attention term satisfiability problem since equivalencessatisfiability problem proved similarly.implication (3 2) trivial, (2 1) easy show. fact, satisfiablerelative term assertions {s1 v t1 , . . . , sn v tn } iff tfUS .((t1 s1 ). . .(tn sn ))satisfiable U .show (1 3), assume relativized term satisfiability problemdecidable. Let = (L, M) U = (LU , MU ). following, use fUabbreviation fUS . Since replace equivalently term function symbolfUS fU , may assume without loss generality fUS occur termsLU .Suppose set = {a : s} LU given, set term assertions.want decide whether satisfiable model W MU . purpose, transform set assertions containing fU . idea underlying transformationthat, given model W MU , fU (t)W {W, }, depending whether tW = Wnot. Consequently, replace fU (t) accordingly > , evaluation termW change. However, satisfiability test model W (wetrying decide whether one exists), thus must guess right replacement.term LU called U -term iff starts fU . set U -termsoccur (possibly subterms) denoted U . Set, inductively, function8. Note necessary add universal role U set relation symbols since assertionform U (a, b) trivially true. However, use universal role within (qualified) numberrestrictions covered extension.26fiFusions Description Logics Abstract Description Systems: U {, >} subterms terms :x := x,(t1 t2 ) := t1 t2 ,(t1 t2 ) := t1 t2 ,(t) := ,(f (t1 , . . . , tn )) := f (t1 , . . . , tn ) f 6= fU arity n,(fU (t)) := (fU (t)).Thus, obtained replacing occurrences U -terms image, i.e., >. Define, function ,:= {t1 v t2 | t1 v t2 } {a : }{> v | fU (t) U (fU (t)) = >}{at : | fU (t) U (fU (t)) = },mutually distinct new object variables. Note containfunction symbol fU , thus viewed set assertions S. addition, thoughcontains one membership assertion, contain assertions involvingrelation symbols. Consequently, satisfiability checked using termsatisfiability test (see proof Corollary 22 above). Decidability relativizedterm satisfiability problem U follows following claim:Claim. satisfiable member MU iff exists mapping : U {, >}satisfiable member M.prove claim, firstff suppose satisfied assignment memberW = W, F W {fUW }, RW MU . Define setting (fU (t)) = > (fU (t))W,A =W , (fU (t))= otherwise.Obviously, implies satisfiedffWWassignment W, F , R , member M.suppose satisfiable mapping . Take member W =Conversely,ffWW0ffand assignment hW, Ai |= . Set W :=W, F W , R WWW, F {fU }, R , prove, induction, terms occur :()0tW ,A = (t )W,A .critical case one = fU (s). First, assume (fU (s)) = (fU (s)) =0>. contains > v , thus W = (s )W,A = sW ,A , second identity00holds induction. However, sW ,A = W implies (fU (s))W ,A = W = >W,A . case(fU (s)) = (fU (s)) = treated similarly. term assertion : ensures(and thus induction s) interpreted whole domain. Consequently,applying fU yields empty set.Since hW, Ai |= , identity () implies hW0 , Ai |= . completes proofclaim, thus also proposition.normal modal logics, result stated proposition already shownGoranko Passy (1992). proof technique used can, however, transfered27fiBaader, Lutz, Sturm, & Woltergeneral situation since strongly depends normality modaloperators.Using Proposition 24, obtain following corollary first transfer theorem.Corollary 25. Let S1 , S2 local ADSs assume that, {1, 2}, relativized(term) satisfiability problem Si decidable. relativized (term) satisfiabilityproblem S1U S2U decidable.Proof. know Theorem 17 (Corollary 22) relativized (term) satisfiabilityproblem S1 S2 decidable. Hence, Proposition 24 yields relativized (term)satisfiability problem (S1 S2 )U decidable. S1U S2U notational variant(S1 S2 )U : function symbols fUS1 fUS2 replaced fUS1 S2 (andanalogously fUS1 S2 ) since three identical semantics.4.2 SatisfiabilityNote Theorem 17 yield transfer result unrelativized satisfiabilityproblem. course, relativized satisfiability problems S1 S2 decidable,theorem implies satisfiability problem S1 S2 also decidable (sincespecial case relativized satisfiability problem). However, able applytheorem obtain decidability satisfiability problem fusion, componentADSs must satisfy stronger requirement relativized satisfiability problemWis decidable. Indeed, set Theorem 20 contains term assertion (namely > v suri ( D))even contain term assertions.cases relativized satisfiability problem undecidable whereassatisfiability problem still decidable. example, Theorem 17 cannot appliedfusion ALCF ALC +,,t since relativized satisfiability problem ALCFalready undecidable (Baader et al., 1993). However, satisfiability problem decidableDLs.4.2.1 Covering normal termsformulate transfer result satisfiability problem, need introduceadditional notion, generalizes notion normal modal logic.Definition 26 (Covering normal terms). Let (L, M) ADS f functionsymbol L arity n. term tf (x) (with one variable x) covering normal termf iff following holds W M:tWf (W ) = WWWX, W , tWf (X ) = tf (X) tf (Y ),X, X1 , . . . , Yn W : X Xi = X Yi 1 n impliesWWWtWf (X) f (X1 , . . . , Xn ) = tf (X) f (Y1 , . . . , Yn ).ADS (L, M) said covering normal terms iff one effectively determinecovering normal term tf every function symbol f L.28fiFusions Description Logics Abstract Description SystemsIntuitively, first two conditions state covering normal term behaves likevalue restriction (or box operator). Consider term fR (x), fR functionsymbol corresponding value restriction constructor role R. fR (x)obviously satisfies first two requirements covering normal terms. Notesecond condition implies function induced tf monotonic, i.e., X impliesWtWf (X) tf (Y ). third condition specifies connection covering normalterm function symbol covers. respect elements tWf (X), valuesWWfunctions f (X1 , . . . , Xn ) f (Y1 , . . . , Yn ) agree provided argumentsagree X. easy see fR (x) covering normal term function symbolscorresponding value, existential, (qualified) number restrictions role R(see Proposition 35 below).Given covering normal terms tf function symbols f finite set functionsymbols E, one construct term tE covering normal term elementsE.Lemma 27. Suppose ADS (L, M) covering normal terms L based setfunction symbols F . Denote tf covering normal term function symbol f ,f F . Then, every finite set E F function symbols, termtE (x) :=^tf (x)f Ecovering normal term f E.4.2.2 Correspondence normal modal logicsfollowing result shows ADS every function symbol normalcovering normal terms. Hence, notion covering normal terms generalizes notionnormality modal logics.Proposition 28. Let (L, M) ADS, assume f normal function symbol(L, M).tf (x) := f (x, , . . . , ) f (, x, . . . , ) f (, . . . , , x)covering normal term f . particular, f nullary (unary), tf (x) = >(tf (x) = f (x)) covering normal term f .Proof. first two conditions definition covering normal terms immediatelyfollow definition normal function symbols. Thus, concentrate thirdcondition. Assume, simplicity, f binary. Suppose W X, X1 , X2 , Y1 , Y2W X Xi = X Yi = 1, 2, set F := f W . F (X X1 , X X2 ) =F (X Y1 , X Y2 ). Since F normal, knowF (X X1 , X X2 ) = F (X, X) F (X, X2 ) F (X1 , X) F (X1 , X2 ),F (X Y1 , X Y2 ) = F (X, X) F (X, Y2 ) F (Y1 , X) F (Y1 , Y2 ),29fiBaader, Lutz, Sturm, & WolterthusF (X, X) F (X, X2 ) F (X1 , X) F (X1 , X2 ) =F (X, X) F (X, Y2 ) F (Y1 , X) F (Y1 , Y2 ).Since, normality F ,F (X, X) F (X, X2 ) F (X1 , X) tWf (X),F (X, X) F (X, Y2 ) F (Y1 , X) tWf (X),Wimplies tWf (X) F (X1 , X2 ) = tf (X) F (Y1 , Y2 ).4.2.3 transfer resultUsing covering normal terms, formulate second transfer theorem,concerned transfer decidability (non-relativized) satisfiability.Theorem 29. Let S1 S2 local ADSs covering normal terms, supposesatisfiability problems S1 S2 decidable. satisfiability problemS1 S2 also decidable.proof Theorem 17, fix two local ADSs Si = (Li , Mi ), {1, 2},L1 based set function symbols F relation symbols R, L2 based GQ. Let L = L1 L2 = M1 M2 .proof Theorem 29 follows general ideas proof Theorem 17.are, however, notable differences way satisfiability S1 S2 reducedsatisfiability S1 S2 . Theorem 20 guess set types,based set additional guesses, pair satisfiability problems 1 2S1 S2 , respectively, generated. proof Theorem 29, need guessD. Instead, compute right set. However, computation requires us solveadditional satisfiability problems fusion S1 S2 . Nevertheless, yields reductionsince alternation depth (i.e., number alternations function symbols S1S2 ) decreases going input set additional mixed satisfiabilityproblems.describe reduction detail, must introduce someWnewnotation. case relativized satisfiability, term assertions Wform > v suri ( D)used assert elements theW domain belong suri ( D). Now, usecovering normal terms propagate suri ( D) terms certain depth.set function symbols E, define E-depth dE (t) term inductively:dE (xi ) = 0dE (t) = dE (t)dE (t1 t2 ) = dE (t1 t2 ) = max{dE (t1 ), dE (t2 )}dE (f (t1 , . . . , tn )) = max{dE (t1 ), . . . , dE (tn )} + 1 f EdE (f (t1 , . . . , tn )) = max{dE (t1 ), . . . , dE (tn )} f 6 E30fiFusions Description Logics Abstract Description Systemsfinite set assertions,dE () := max{dE (t) | term()}.Put, term t(x) one variable x, t0 (x) := x, tm+1 (x) := t(tm (x)), t0 (x) := x,tm+1 (x) := tm+1 (x) tm (x).position formulate result reduces satisfiability fusiontwo local ADSs covering normal terms satisfiability component ADSs.Theorem 30. Let Si = (Li , Mi ), {1, 2}, two local ADSs covering normalterms L1 based set function symbols F relation symbols R,L2 based G Q, let L = L1 L2 = M1 M2 . Let finite setobject assertions L. Put := dF (), r := dG (), let c(x) (d(x)) coveringnormal term function symbols F (G).{1, 2}, denote set C () term satisfiable(L, M). following three conditions equivalent:1. satisfiable (L, M).2. existevery 1 object variable 6 obj()every obj() term ta 1union 1 following sets object assertions satisfiable(L1 , M1 ):W{at : sur1 (t cm (sur1 ( 1 )) | 1 },W{a : sur1 (ta cm (sur1 ( 1 )) | obj()},{R(a, b) | R(a, b) , R R},{a : sur1 (s) | (a : s) };union 2 following sets object assertions satisfiable (L2 , M2 ):W{at : sur2 (t dr (sur2 ( 1 )) | 1 },W{a : sur2 (ta dr (sur2 ( 1 )) | obj()},{Q(a, b) | Q(a, b) , Q Q}.3. condition (2) above, 1 replaced 2 .sets theorem similarWto ones Theorem 20.main differenceW term assertion > v suri ( D) longer there. Instead,disjunction suri ( 1 ) directly inserted terms using covering normalsterms. already mentioned above, another difference set D,guessed Theorem 20, replaced set 1 (2) 2 (3). Actually, guessingsetW longer possible case. proof Theorem 30 need know> v suri ( D) satisfiable Si (i.e., holds least one model Mi ).way check effectively since algorithm relativized satisfiability31fiBaader, Lutz, Sturm, & WolterSi . Taking set ensures property satisfied (see proof appendixdetails).definition, set C () term satisfiable (L, M).Recall term satisfiable iff {a : s} satisfiable (L, M) arbitraryobject variable a. Since elements C () still mixed terms (i.e., termsfusion), computing set actually needs recursive call decision proceduresatisfiability (L, M). recursion well-founded since alternation depth decreases.Definition 31. term L, denote a1 (s) a2 (s) 1-alternation2-alternation depth s, respectively. say, a1 (s) length longestsequence form (g1 , f2 , g3 , . . .)g1 (. . . (f2 . . . (g3 . . .)))gj G fj F appears s. 2-alternation depth a2 (s) defined exchangingroles F G. Put a(s) := a1 (s) + a2 (s), call alternation depth.finite set terms, a() maximum a(s) .Thus, a1 (s) counts maximal number changes symbols firstsecond ADS, starting first symbol S2 (i.e., first symbol S2counts change, even occur inside scope symbol S2 ).2-alternation depth defined accordingly. alternation depth sums 1-2-alternation depth.Lemma 32. a(term()) > 0, a(C 1 ()) < a(term()) a(C 2 ()) < a(term()).Proof. show that, a(term()) > 0, a(sub1 ()) < a(term())a(sub2 ()) < a(term()), which, definition C , clearly implies lemma. Firstnote that, definition subi ,ai (subj ()) ai (term()) i, j.()make case distinction follows:1. a1 (term()) a2 (term()). want show a1 (sub2 ()) < a1 (term()),since, (), implies a(sub2 ()) < a(term()). Assume contrarya1 (sub2 ()) a1 (term()). () implies a1 (sub2 ()) = a1 (term()). Hence,exists term sub2 () sequence (g1 , f2 , g3 , . . . ) function symbolsgi G, fi F length a1 (term()) g1 (. . . (f2 . . . (g3 . . .))) occurs s.definition sub2 , implies existence term term() functionsymbol f F f (. . . g1 (. . . (f2 . . . (g3 . . .)))) occurs t. Since length(g1 , f2 , g3 , . . . ) a1 (term()), obviously yields a2 (term()) > a1 (term())contradiction.2. a1 (term()) a2 (term()). Similar previous case: exchange rolesa1 a2 , F G, sub1 sub2 .32fiFusions Description Logics Abstract Description Systemsprove Theorem 29, must show Theorem 30 used construct decisionprocedure satisfiability S1 S2 decision procedures componentsystems S1 S2 . Let us first consider problem computing sets 1 2 .a((term()) = 0, consists Boolean combinations set variables.case, C () consists set variables, , = 1, 2, computed using Booleanreasoning. a(term()) > 0, Lemma 32 states {1, 2}a(C ()) < a(term()). induction thus assume effectivelycomputed. Consequently, remains check Condition (i + 1) Theorem 30 {1, 2}.Since finite, guess every object variable occurring type ta .sets 1 2 obtained way indeed sets assertions L1 L2 , respectively.Thus, satisfiability effectively checked using decision procedures S1S2 . proves Theorem 29.argument used also shows Theorem 30 sufficient stateequivalence (1) (2) (as Theorem 20). fact, induction argument usednecessarily always apply computation 1 . cases, alternationdepth may decreases 1 , 2 . noted Theorem 20 couldalso formulated symmetric way. done sincenecessary proving Theorem 17.Regarding complexity combined decision procedure, must principle alsoconsider complexity computing covering normal terms size terms.examples DL, terms value restrictions, thus sizecomplexity computing linear. Here, assume polynomial bound both.assumption, obtain complexity results case relativizedsatisfiability. fact, complexity testing Condition (2) (3) Theorem 30 agreescomplexity testing Condition (2) Theorem 20: adds one exponentialcomplexity decision procedure single ADSs. order compute , needexponentially many recursive calls procedure. Since recursion depth linearsize , end exponentially many tests Condition (2) (3).Corollary 33. Let S1 S2 local ADSs covering normal terms, assumecovering normal terms computed polynomial time. satisfiabilityproblems S1 S2 decidable ExpTime (PSpace), satisfiability problemS1 S2 decidable 2ExpTime (ExpSpace).argument case relativized satisfiability, extendtransfer result also term satisfiability.Corollary 34. Let S1 S2 local ADSs covering normal terms, supposeterm satisfiability problems S1 S2 decidable. term satisfiabilityproblem S1 S2 also decidable.5. Fusions description logicsGiven two DLs L1 L2 , fusion defined follows. translatecorresponding ADSs S1 S2 , build fusion S1 S2 . fusion L1 L2L1 L2 DL corresponds S1 S2 . Since definition fusionADSs requires sets function symbols disjoint, must ensure ADSs33fiBaader, Lutz, Sturm, & Woltercorresponding L1 L2 built disjoint sets function symbols. DLsintroduced Section 2, achieved assuming sets role names L1L2 disjoint sets nominals L1 L2 disjoint. DL L1 L2allows use concept role constructors DLs, restricted way.Role descriptions either role descriptions L1 L2 . role descriptionsinvolving constructors names DLs. Concept descriptions may contain conceptconstructors DLs; however, constructor Li may use role descriptionLi (i = 1, 2).Let us illustrate restrictions two simple examples. fusion ALC + ALC 1two DLs ALC + ALC 1 fragment ALC +,1 whose set role namespartitioned two sets NR1 NR2transitive closure operator may applied names NR1 ;inverse operator may applied names NR2 .example, concept name, R NR1 Q NR2 , R+ .A u Q1 .Aconcept description ALC + ALC 1 , R+ .A u R1 .A (Q1 )+ .A not.Note that, although two source DLs disjoint sets role names, ALC + ALC 1role names sets may used inside existential value restrictions sinceconcept constructors available DLs.fusion ALCQ ALC R+ two DLs ALCQ ALC R+ fragmentALCQR+ whose set role names NR (with transitive roles NR+ NR ) partitionedtwo sets NR1 NR2 NR+ NR2 that, inside qualifying number restrictions,role names NR1 may used. particular, means transitive rolescannot occur within qualified number restrictions.following, give examples illustrate usefulness transfer resultsproved previous section. First, give example case satisfiabilityrelativized satisfiability. Subsequently, consider complex exampleinvolving so-called concrete domains. Here, general transfer result used provedecidability result recently proved designing specialized algorithmfusion. Finally, give example demonstrates restrictionlocal ADSs really necessary.5.1 Decidability transfer satisfiabilitysubsection, give example application Theorem 29decidability result could obtained using Theorem 17.Theorem 29 requires ADSs covering normal terms. is, however, satisfiedDLs yield local ADSs.Proposition 35. Let L one DLs introduced Section 2, let correspondingADS = (L, M) local. covering normal terms, termscomputed linear time.Proof. function symbols f L, term tf form fR (x) roledescription R. semantics value restrictions implies terms form satisfy34fiFusions Description Logics Abstract Description Systemsfirst two properties Definition 26. completes proof function symbolsf arity 0 since third condition Definition 26 trivially satisfied. Thus,nullary function symbols, fR (x) arbitrary role name R job.remains show that, every unary function symbol f {fR , fR , fnR, fnR},term fR (x) also satisfies third property. immediate consequenceW (X) f W (Y ) = f W (X) f W (X )fact that, function symbols f , fRRmodels W X, W .following, consider two description logics ALCF ALC +,,t . HollunderNutt (1990) show satisfiability ALCF-concept descriptions decidable.true consistency ALCF-ABoxes (Lutz, 1999). Note, however, relativizedsatisfiability ALCF-concept descriptions thus also relativized ABox consistencyALCF undecidable (Baader et al., 1993). ALC +,,t , decidability satisfiabilityshown Baader (1991) Schild (1991).9 Decidability ABox consistency ALC +,,tshown Chapter 7 (De Giacomo, 1995).unrestricted combination ALCF +,,t two DLs undecidable. precise, satisfiability ALCF +,,t -concept descriptions (and thus also consistency ALCF +,,t ABoxes) undecidable. follows undecidability relativized satisfiabilityALCF-concept descriptions fact role operators ALCF +,,t usedinternalize TBoxes (Schild, 1991; Baader et al., 1993). contrast undecidabilityALCF +,,t , Theorem 29 immediately implies satisfiability concept descriptionsfusion ALCF ALC +,,t decidable.Theorem 36. Satisfiability concept descriptions consistency ABoxes decidableALCF ALC +,,t , whereas satisfiability ALCF +,,t -concept descriptions alreadyundecidable.Taking fusion thus yields decidable combination two DLs whose unrestrictedcombination undecidable. price one pay fusion offers less expressivity unrestricted combination. concept f1 f2 u f1+ .C exampleconcept description ALCF +,,t allowed fusion ALCF ALC +,,t .5.2 Decidability transfer relativized satisfiabilityexample application Corollary 22 (and thus Theorem 17), considerDL ALC +,,u,t. DL, satisfiability concept descriptions undecidable. However,fexpressive fragment decidable relativized satisfiability problem obtainedbuilding fusion two sublanguages ALC +,,tALC +,,t,u .fTheorem 37. Satisfiability ALC +,,u,t-concept descriptions undecidable.fUndecidability shown reduction domino problem (Berger, 1966;Knuth, 1973) (see, e.g., Baader & Sattler, 1999, undecidability proofs DLs usingreduction). main tasks solve reduction one expressgrid one access points grid. One square grid expressedN N9. Note ALC +,,t notational variant test-free propositional dynamic logic (PDL) (Fischer &Ladner, 1979).35fiBaader, Lutz, Sturm, & Wolterdescription form (xyuyx).>, x, features. fact, descriptionexpresses points belonging x x successor,two successors coincide. Accessing point grid achievedusing role description (x y)+ .Note undecidability result also closely related known undecidabilityIDPDL, i.e., deterministic propositional dynamic logic intersection (Harel, 1984).However, undecidability proof IDPDL Harel (1984) uses test construct,available ALC +,,u,t.fNext, show relativized satisfiability two rather expressive sublanguagesALC +,,u,tdecidable.fTheorem 38. Relativized satisfiability concept descriptions decidable ALC f+,,tALC +,,t,u .Proof sketch. cases, TBoxes internalized described Schild (1991)Baader et al. (1993). Thus, sufficient show decidability (unrelativized)satisfiability., follows decidability DPDL (Ben-Ari, Halpern, & Pnueli,ALC +,,tf1982), known correspondence PDL ALC +,,t (Schild, 1991), factnon-functional roles simulated functional ones presence compositiontransitive closure (Parikh, 1980).ALC +,,t,u , decidability satisfiability follows decidability IPDL, i.e., PDLintersection (Danecki, 1984).Given theorem, Corollary 22 yields following decidability result.Corollary 39. Relativized satisfiability concept descriptions decidable fusionALC f+,,t ALC +,,t,u .5.3 concrete exampleDescription logics concrete domains introduced Baader Hanschke (1991)order allow reference concrete objects like numbers, time intervals, spatialregions, etc. defining concepts. precise, Baader Hanschke (1991)define extension ALC(D) ALC, concrete domain (see below).suitable assumptions D, show satisfiability ALC(D) decidable. Onemain problems extension DLs relativized satisfiability (and satisfiability DLs TBoxes internalized) usually undecidable (Baader & Hanschke,1992) (though exceptions, see Lutz, 2001). reason, Haarslev et al. (2001)introduce restricted way extending DLs concrete domains, show corresponding extension ALCN HR+ decidable relativized satisfiability problem.10following, show result also obtained easy consequence10. precise, even show relativized ABox consistency decidable restrictedextension ALCN HR+ concrete domains. Here, restrict ourself satisfiability conceptssince ABoxes introduced Haarslev et al. (2001) also allow use concrete individualspredicate assertions individuals, covered object assertions ADSsintroduced present paper.36fiFusions Description Logics Abstract Description SystemsTheorem 17. Moreover, ALCN HR+ replaced arbitrary local DLdecidable relativized satisfiability problem.Definition 40 (Concrete Domain). concrete domain pair (D , ),nonempty set called domain, set predicate names. predicatename P associated arity n n-ary predicate P nD . concretedomain called admissible iff (1) set predicate names closed negationcontains name >D , (2) satisfiability problem finite conjunctionspredicates decidable.Given concrete domain one predicates P (of arity n), onedefine new concept constructor f1 , . . . , fn .P (predicate restriction), f1 , . . . , fnconcrete features.11 contrast abstract features considered now, concretefeatures interpreted partial functions abstract domain concretedomain . consider basic DL allows Boolean operators newconcept constructors only.Definition 41 (B(D)). Let NC set concept names NFc set namesconcrete features disjoint NC , let admissible concrete domain. Conceptsdescriptions B(D) Boolean combinations concept names predicate restrictions, i.e., expressions form f1 , . . . , fn .P P n-ary predicatef1 , . . . , fn NFc .semantics B(D) defined follows. consider interpretation I,nonempty domain , interprets concept names subsets concretefeatures partial functions . Boolean operators interpretedusual,(f1 , . . . , fn .P )I = {a | x1 , . . . , xn .fiI (a) = xi 1 n (x1 , . . . , xn ) P }.Note concept descriptions interpreted subsets .Thus, go ADS corresponding B(D), concrete domain explicitpart corresponding ADMs. used define interpretation functionsymbols corresponding predicate restrictions. predicate restriction constructortranslated function symbol ff1 ,...,fn .P arity 0, and, ADM W correspondingWframe F, ffdefined (f1 , . . . , fn .P )I , interpretation based1 ,...,fn .PF maps concept names empty set.Theorem 42. Let admissible concrete domain. Then, B(D) localrelativized satisfiability problem B(D)-concept descriptions decidable.Proof. Given family (Wi )iI ADMs Wi corresponding frames Fi pairwisedisjointdomains Fi (i I), first build union F frames: domain FFinterprets concrete features obvious way, i.e., f F (x) := f Fi (x)iI11. Note general framework introduced Baader Hanschke (1991) allows feature chainspredicate restrictions. Considering feature chains length one main restriction introducedHaarslev et al. (2001).37fiBaader, Lutz, Sturm, & Wolterx Fi . Let W ADM induced F. ToSprove W fact disjoint unionWiW(Wi )iI , remains show ff= iI ff. easy consequence1 ,...,fn .P1 ,...,fn .Psemantics predicate restriction constructor, interpretation concretefeatures F, fact domains Fi pairwise disjoint.Decidability unrelativized satisfiability problem immediate consequencedecidability results ALC(D) given Baader Hanschke (1991). Since B(D)simple DL contain concept constructors requiring generationabstract individuals, easy see B(D)-concept description C0 satisfiable relativeTBox C1 v D1 , . . . , Cn v Dn iff satisfiable one-element interpretation.TBox internalized simple way: C0 satisfiable relativeTBox C1 v D1 , . . . , Cn v Dn iff C0 u (C1 D1 ) u . . . u (Cn Dn ) satisfiable.Given theorem, Corollary 22 yields following transfer result, showsconcrete domains restricted form predicate restrictions introducedintegrated local DL decidable relativized satisfiability problem withoutlosing decidability.Corollary 43. Let admissible concrete domain L local DLrelativized satisfiability concept descriptions decidable. Then, relativized satisfiabilityconcept descriptions B(D) L also decidable.5.4 Non-local DLsProposition 15, DLs allowing nominals, universal role, role negationlocal. follows decidability transfer theorems applicable fusionsDLs. following, try clarify reasons restricted applicabilitytheorems.First, show DLs decidable satisfiability problemfusion undecidable satisfiability problem. culprit case universalrole (or role negation).Theorem 44. Satisfiability concept descriptions decidable ALC U ALCF,undecidable fusion ALC U ALCF.Proof. Decidability ALCF shown Hollunder Nutt (1990) ALC UBaader et al. (1990) Goranko Passy (1992). Undecidability ALC U ALCF(which identical ALCF U ) follows results Baader et al. (1993) factuniversal role used simulate TBoxes (see Proposition 24).Note role negation used simulate universal role: replace U.CR.C u R.C U.C R.C R.C. addition, decidability ALC knowndecidable (Lutz & Sattler, 2000). Consequently, theorem also holds replaceALC U ALC .noted example given theorem depends factone two DLs allows universal role becomes undecidableuniversal role added. fact, Corollary 25 shows decidability transferDLs already provide universal role.38fiFusions Description Logics Abstract Description SystemsConcerning nominals, counterexample transfer decidabilitypresence. However, think unlikely generaltransfer result case. fact, note DL L without nominals introducedSection 2, fusion ALCO identical L extended nominals. Since (relativized)satisfiability ALCO decidable, general transfer result case would implyextension decidable provided L decidable. Consequently, would yieldgeneral transfer result adding nominals.6. ConclusionRegarding related work, work closely related one presented(Wolter, 1998). There, analogs Theorems 20 30 proved normal modallogics within algebraic framework. present results extend ones Wolter(1998) two directions. First, added object assertions, thus also provetransfer results ABox reasoning. Second, show transfer results satisfiabilitynon-normal modal logics long covering normal terms. allows us handlenon-normal concept constructors like qualified number restrictions (graded modalities)framework.also think introduction abstract description systems (ADSs) contribution right. ADSs abstract internal structure concept constructorsthus allow us treat vast range constructors uniform way. Nevertheless, model theoretic semantics provided ADSs less abstract algebraicsemantics employed Wolter (1998). closer usual semantics DLs, thuseasier comprehend people used semantics. results paper showADSs fact yield good level abstraction proving general results description logics. Recently, notion used proving general resultsso-called E-connections representation formalisms like description logics, modal spatiallogics, temporal logics (Kutz, Wolter, & Zakharyaschev, 2001). contrast fusions,E-connection two domains merged connected means relations.Regarding complexity, transfer results yield upper bounds. Basically,show complexity algorithm fusion one exponent higherones components. believe complexity satisfiabilityfusion ADSs indeed exponentially higher complexity satisfiabilitycomponent ADSs. However, yet matching lower bounds, i.e., knowexample exponential increase complexity really happens.Note Spaans results (1993) transfer NP PSpace decidabilitycomponent modal logics fusion restricted normal modal logics,make additional assumptions algorithms used solve satisfiability problemcomponent logics. Nevertheless, many PSpace-complete description logicseasy see fusion also PSpace-complete. sense, general techniquesreasoning fusion descriptions logics developed paper give roughcomplexity estimate.39fiBaader, Lutz, Sturm, & WolterAppendix A. Proofsappendix, give detailed proofs criteria (relativized) satisfiabilityfusion local ADSs. Recall that, criteria, transfer theorems decidabilityeasily follow. deferred proofs theorems appendix sincerather technical.A.1 Proof Theorem 20prove theorem, need technical lemma. proof Theorem 20,going merge models W1 M1 W2 M2 means bijective function bdomain W1 W1 onto domain W2 W2 way surrogatessuri (t), C 1 (), respected b sense1w sur1 (t)W1 ,A b(w) sur2 (t)W2 ,A2w W1 C 1 (). existence bijection equivalent condi1122tion cardinalities |sur1 (t)W1 ,A | sur1 (t)W1 ,A |sur2 (t)W2 ,A | sur2 (t)W2 ,Acoincide C 1 (): 6= t0 t, t0 C 1 (), contains conjunct(equivalent to) negation conjunct t0 ; hence, t, t0 , suri (t)Wi ,Asuri (t0 )Wi ,A = {1, 2}, clearly yields equivalence. followinglemma used choose models way cardinality condition satisfied.(We refer reader to, e.g., Gratzer, 1979 information cardinals.)Lemma 45. Let (L, M) local ADS set assertions satisfiable (L, M).exists aff cardinal that, cardinals 0 , exists modelW = W, F W , RW |W | = 0 assignment hW, Ai |=|sW,A | {0, 0 } terms s.ffProof. assumption, exists ADM W0 = W0 , F W0 , RW0 assignment B = hB1 , B2 hW0 , Bi |= . Let = max{0 , |W0 |}.showLet 0 . Take 0 disjoint isomorphic copies hW , B1 i,isWas required.ffWW = W , F , R, < 0 , ffof hW0 , B1 i. (The first member list coincidesW0 .) Let W = W, F W , RW disjoint union W , < 0 , definehW, = hA1 , A2 ii putting A2 (a) = B2 (a), X ,[A1 (x) =B1 (x),<0x V . Note object variables interpreted W0 . followsdefinitions term semantics disjoint unions[sW,A =sW ,B ,()<0terms s. Hence |W | = 0 hW, Ai |= . remains show |sW,A | {0, 0 }every term s. Suppose |sW,A | =6 0. Then, (), 0 |sW,A | 0 = 0 , means0W,A= |s|.40fiFusions Description Logics Abstract Description Systemsnoted above, disjointness sets suri (t)Wi ,A suri (t0 )Wi ,A (for 6= t0 )required order ensure existence bijection b. precisely, ordermerge models W1 , W2 , sets suri (t)Wi ,A member relevant subset C 1 ()must form partition Wi domain satisfies certain cardinality condition.formalized following definition:Definition 46. Let cardinal. set {X1 , . . . , Xn } called -partition set Wiff1. |Xi | = , 1 n,2. Xi Xj = whenever 6= j,3. W = 1in Xi .{X1 , . . . , Xn } -partition ADM W domain W iff -partition W .proof, enforce Properties 1 3 hold appropriate constructions,Property 2 holds definition C 1 ().proving Theorem 20, repeat formulation.Theorem 20. Let Si = (Li , Mi ), {1, 2}, two local ADSs L1 basedset function symbols F relation symbols R, L2 based G Q,let L = L1 L2 = M1 M2 . finite set assertions L,following equivalent:1. satisfiable (L, M).2. exist(a) set C 1 (),(b) every term object variable 6 obj(),(c) every obj() term ta D,union 1 following sets assertions L1 satisfiable(L1 , M1 ):W(d) {at : sur1 (t) | D} {> v sur1 ( D)},(e) {a : sur1 (ta ) | obj()},(f ) {R(a, b) | R(a, b) , R R},(g) {sur1 (t1 ) v sur1 (t2 ) | t1 v t2 } {a : sur1 (s) | (a : s) };union 2 following sets assertions L2 satisfiable (L2 , M2 ):W(h) {at : sur2 (t) | D} {> v sur2 ( D)},(i) {a : sur2 (ta ) | obj()},(j) {Q(a, b) | Q(a, b) , Q Q}.41fiBaader, Lutz, Sturm, & Woltersur1 (s1 )W1 ,Ab1bW1 ,A1sur1 (s2 )sur2 (s1 )W2 ,A2sur2 (s2 )W2 ,A2......sur1 (sk )W1 ,A...b1sur2 (sk )W2 ,AW12W2Figure 3: mapping b.Proof. start direction (2) (1). Take set C 1 () satisfyingproperties listed theorem. Takecardinalsi1, 1ffff{1, 2}Lemma245 2forffff12(Li , Mi ), put = max{1 , 2 },take W1 , = A1 , A2 W2 , = A1 , A2ffWi Mi Wi , Ai |= {1, 2}. Lemma 45, {1, 2}assume |Wi | = and, |suri (s)Wi ,A | {0, } D.sets {suri (s)Wi ,A : D}-partitionsWiWfor {0, 1} since (i)ffD, (as : suri (s)) , (ii) Wi , |= > v suri ( D), (iii) s, s0 6= s0implies suri (s)Wi ,A suri (s0 )Wi ,A definition C 1 . Moreover, obj(1 ) = obj(2 )12and, obj(1 ) D, A12 (a) sur1 (s)W1 ,A iff A22 (a) sur2 (s)W2 ,A .Together fact A12 A22 injective, implies existencebijection b W1 onto W212{b(w) : w sur1 (t)W1 ,A } = sur2 (t)W2 ,A ,D,b(A12 (a)) = A22 (a),obj(1 ). Figure 3, assumed = {s1 , . . . , sk }, illustratesmapping b.ffDefine model W = W, (F G)W , (R Q)W puttingW = W1 ,f W = f W1 , f F,g G arity n Z1 , . . . , Zn W ,g W (Z1 , . . . , Zn ) = b1 (g W2 (b(Z1 ), . . . , b(Zn ))),b(Z) = {b(z) : z Z},RW = RW1 , R R,QW (x, y) iff QW2 (b(x), b(y)), Q Q.42fiFusions Description Logics Abstract Description SystemsSince M2 closed isomorphic copies, hard see W M1 M2 . Let= A1 . prove implication (2) (1) theorem remains showhW, Ai |= . end suffices prove following claim:Claim. terms sub1 (),21tW,A = sur1 (t)W1 ,A = b1 (sur2 (t)W2 ,A ).prove claim, let us show implies hW, Ai |= . First note that,claim, obtain1tW,A = sur1 (t)W1 ,A term().(1)may proved induction construction term() terms sub1 ()using booleans function symbols L1 , only. basis induction (i.e.,equality members sub1 ()) stated claim induction step straightforward.show hW, Ai |= consequence (1). Suppose R(a, b) .R(a, b) 1 thus hW, Ai |= R(a, b). Similarly, Q(a, b) implies Q(a, b) 21hW, Ai |= Q(a, b). Suppose (a : t) . (a : sur1 (t)) 1 A12 (a) sur1 (t)W1 ,Aimplies, (1), A12 (a) tW,A . Hence hW, Ai |= (a : t). t1 v t2 ,sur1 (t1 ) v sur1 (t2 ) 1 so, (1), tW,AtW,A. Hence hW, Ai |= t1 v t2 .12come proof claim. proved induction structure t.Due following equalities holding sub1 (), suffices show tW,A =1sur1 (t)W1 ,A .sur1 (t)W1 ,A11=[{sur1 (s)W1 ,A : D, conjunct s}=[{b1 (sur2 (s)W2 ,A ) : D, conjunct s}22= b1 (sur2 (t)W2 ,A )W1first equality holds since sur1 ( D)W1 ,A = W1 and, D, eitherconjunct s. second equality true definition b validitythirdWequality seen analogously validity first one considering2sur2 ( D)W2 ,A = W2 .1Hence let us show tW,A = sur1 (t)W1 ,A . induction start, let variable.1equation tW,A = sur1 (t)W1 ,A immediate consequence fact = A1 .induction step, distinguish several cases:= t1 . induction hypothesis, tW,A= sur1 (t1 )W1 ,A1 . Hence, tW,A = W \ tW,A=1111W,AW,A11W \ sur1 (t1 )= sur1 (t)(since W = W1 ).= t1 t2 . induction hypothesis, tW,A= sur1 (ti )W1 ,A1 {1, 2}. Hence,111tW,A = tW,AtW,A= sur1 (t1 )W1 ,A sur1 (t2 )W1 ,A = sur1 (t)W1 ,A .12= t1 t2 . Similar case.43fiBaader, Lutz, Sturm, & Wolter1= f (t1 , . . . , tn ). induction hypothesis, tW,A= sur1 (ti )W1 ,A 1 n. Hence,111W,AW,AtW,A = f W (t1 , . . . , tn ) = f W (sur1 (t1 )W1 ,A , . . . , sur1 (tn )W1 ,A ) = sur1 (t)W1 ,A(since f W = f W1 ).= g(t1 , . . . , tn ). case, tW,A = b1 (g W2 (b(tW,A), . . . , b(tW,A))). Since,n1221W,A1W,A12equalities, sur1 (t)= b (sur2 (t)), remains show sur2 (t)W2 ,A =222g W2 (b(tW,A), . . . , b(tW,A)). Since sur2 (t)W2 ,A = g W2 (sur2 (t1 )W2 ,A , . . . , sur2 (tn )W2 ,A ),n12amounts showing b(tW,A) = sur2 (ti )W2 ,A 1 n. This, however,follows induction hypothesis together equations.concludes proof direction (2) (1).remains prove direction (1) (2). Suppose hW, Ai |= , W= hA1 , A2 i. Put= {s C 1 () : sW,A 6= }.Note fusion local ADLs local ADL again. Hence (L, M) local mayassume, Lemma 45, sets sW,A infinite.Take new object name 6 obj() every let, obj(),^^ta = {t sub1 () : A2 (a) tW,A } {t : sub1 (), A2 (a) 6 tW,A }.prove set assertions 1 based D, ta , obj(), , D, satisfiable(L1 , M1 ).WLet F W denote restriction (F G)Wsymbols F.Rff Similarly,1ffWWW1restriction (RQ) symbols R. Set W1 = W, F , RM1 , = A1 , A12 ,A11 = A1 {xt 7 tW,A : = g(t1 , . . . , tk ) sub1 ()},A12 (a) = A2 (a), obj(), A12 (as ) sW,A , D. Note chooseinjective function A12 sW,A infinite. show inductionsur1 (t)W1 ,A1 = tW,A term().(2)Let = x variable. x surrogate, A11 (x) = A1 (x). inductionstep, distinguish several cases:inductive steps = t1 , = t1 t2 , = t1 t2 , = f (t1 , . . . , tn ), f F,identical corresponding cases proof Equation 1, occursdirection (2) implies (1) above.= g(t1 , . . . , tn ), g G. sur1 (t) = xt . Hence A11 (xt ) = tW,Aequation proved.ffffEquation 2,obtainW1 , A1 |= 1 : prove W1 , A1 |= R(a, b) wheneverffR(a, b) 1 W1 , A1 |= sur1 (t1 ) v sur1 (t2 ) whenever sur1 (t1 ) v sur1 (t2 ) 1 .remaining formulas 1 lefttheffreader. Suppose R(a, b) 1 . R(a, b)hW, Ai |= R(a, b). Hence W1 , A1 |= R(a, b). Suppose sur1 (t1 ) v sur1 (t2 ) 1 .44fiFusions Description Logics Abstract Description Systemst2W,A . Equation 2,t1 v t2 . Hence hW, Ai |= t1 v t2 means tW,A1ff11sur1 (t1 )W1 ,A sur1 (t2 )W1 ,A means W1 , A1 |= sur1 (t1 ) v sur1 (t2 ).construction model M2 satisfying 2 similar left reader.A.2 Proof Theorem 30proof Theorem 17, fix two local ADSs Si = (Li , Mi ), {1, 2},L1 based set function symbols F relation symbols R, L2 basedG Q. Let L = L1 L2 = M1 M2 . assume S1 S2 coveringnormal terms.Similarly done previous section, merge models means1bijections map points sets sur1 (t)W1 ,A points corresponding sets2sur2 (t)W2 ,A . finite set object assertions L, let () denote setC () term satisfiable (L, M) (for {1, 2}). ensuremerging models succeeds, must enforce elements 1 () 2 ()form -partitions (for appropriate ) models merged. 1 (),captured following lemma. Explicitly stating dual lemma 2 ()omitted brevity.Lemma 47. Let finite set object assertions L, cardinal satisfyingconditions Lemma 45 (L, M) , 1 = 1 (). 0 ,1. exists model W M1 assignment{sur1 (s)W,A | 1 }0 -partition W;2. exists model W M2 assignment{sur2 (s)W,A | 1 }0 -partition W.Proof. 1. definition 1 , 1 , find model Wsassignment sWs ,As 6= . Since fusion two local ADSs local,set models closed disjoint unions. Hence, exists model W1assignment A1 sW1 ,A1 6= 1 . follows set1 := D{as : | 1 } satisfiableE (L, M). Lemma 45, thus exists model0000WWW = W , (F G) , (R Q)assignment A0 W0 , A0 |= 100{sW ,A | 1 } 0 -partition W 0 . let W denote restriction W0 L1define00A1 = A01 {xt 7 tW ,A | = g(t1 , . . . , tk ) sub1 ()}.00hW, Ai required. prove note sur1 (t)W,A = tW ,A term().2. similar left reader.45fiBaader, Lutz, Sturm, & Wolterrepeat formulation theorem proved.Theorem 30. Let Si = (Li , Mi ), {1, 2}, two local ADSs covering normalterms L1 based set function symbols F relation symbols R,L2 based G Q, let L = L1 L2 = M1 M2 . Let finite setobject assertions L. Put := dF (), r := dG (), let c(x) (d(x)) coveringnormal term function symbols F (G).{1, 2}, denote set C () term satisfiable(L, M). following three conditions equivalent:1. satisfiable (L, M).2. existevery 1 object variable 6 obj()every obj() term ta 1union 1 following sets object assertions satisfiable(L1 , M1 ):W{at : sur1 (t cm (sur1 ( 1 )) | 1 },W{a : sur1 (ta cm (sur1 ( 1 )) | obj()},{R(a, b) | R(a, b) , R R},{a : sur1 (s) | (a : s) };union 2 following sets object assertions satisfiable (L2 , M2 ):W{at : sur2 (t dr (sur2 ( 1 )) | 1 },W{a : sur2 (ta dr (sur2 ( 1 )) | obj()},{Q(a, b) | Q(a, b) , Q Q}.3. condition (2) above, 1 replaced 2 .start proof direction (1) (2) (1) (3). proofsdualonlyff give proof (1) (2). Suppose hW, Ai |= ,other,WW = W, (F G) , (R Q)W . Lemma 45, assume that, every 1 ,|tW,A | infinite. Take new object name 6 obj() every 1 let,obj(),^^ta = {t sub1 () : A2 (a) tW,A } {t : sub1 (), A2 (a) 6 tW,A }.prove set 1 assertions based ta , obj(), , 1 , satisfiable(L1 , M1 ) (the proof rather similar proof direction (1) (2)proof Theorem 20). Let F W (resp. G W ) denote restriction (F G)W symbolsF (resp. G). Similarly, RWQW theffrestrictions(R Q)ffW symbolsR Q, respectively. Set W1 = W, F W , RW M1 , A1 = A11 , A12 ,A11 = A1 {xt 7 tW,A | = g(t1 , . . . , tk ) sub1 ()},46fiFusions Description Logics Abstract Description SystemsA12 (a) = A2 (a), obj(), A12 (at ) tW,A , 1 (we choose injectivefunction A12 since sets tW,A infinite).corresponding part proof Theorem 20, show inductionsur1 (t)W1 ,A1 = tW,A term().ffLet us see W1 , A1 |= 1 followsR(a, b) 1equation.ff1 |= R(a, b). hW, Ai |=R(a,b)hW,Ai|=R(a,b).HenceW,1 1ffWW( 1 ) = > (by definition).HenceW1 , |= sur1 ( 1 ) = > so,1ffWdefinition cm , W1 , A1 |= (cm (sur1 ( 1 ))) = >. remains observeA12 (a) sur1 (ta )W1 ,A1 obj(), A12 (a) sur1 (s)W1 ,A1 whenever (a : s) ,A12 (at ) sur1 (t)W1 ,A1 1 .construction model M2 satisfying 2 similar left reader.remains show implications (2) (1) (3) (1). similar,concentrate first. proof Theorem 20 possible constructrequired model merging models 1 2 . situation different here.possible Wmerge models 1W 2 one step, since know whethersatisfy sur1 ( 1 ) = > sur2 ( 1 ) = >,W respectively. knowWsatisfy approximations : sur1 (s) cm (sur1 ( 1 )) : sur2 (s) dr (sur2 ( 1 )),respectively, : . merge models type distinguish variouspieces models add new pieces well. define pieces needtechnical claim. proof Theorem 17, take cardinals , {1, 2} Lemma 45(Li , Mi ) put = max{1 , 2 }.Claim 1. Suppose (2) holds.ff(a) exist W1 = W1 , F W , RW M1 , assignment = hA1 , A2 W1 ,sequence X0 , . . . , Xm subsets W1[a1] A2 (a) Xm , obj(1 ),[a2] hW1 , Ai |= 1 ,[a3] Xn+1 Xn cW1 (Xn ), 0 n < m,[a4] set {sur1 (s)W1 ,A Xm : 1 } -partition Xm ,[a5] sets{sur1 (s)W1 ,A (Xn Xn+1 ) : 1 }-partitions Xn Xn+1 , 0 n < m.[a6] |W1 X0 | = .ff(b) exist W2 = W2 , G W , QW M2 , assignment B = hB1 , B2 i, sequenceY0 , . . . , Yr subsets W2[b1] B2 (a) Yr , obj(1 ),[b2] hW2 , Bi |= 2 ,47fiBaader, Lutz, Sturm, & WolterA1 = W1 X0A0 = X 0 X 1......Am2 = Xm2 Xm1Am1 = Xm1 XmXmW1Figure 4: sets Xi .[b3] Yn+1 Yn dW2 (Yn ), 0 n < r,[b4] set {sur2 (s)M,A Yr : 1 } -partition Yr ,[b5] sets{sur2 (s)M,A (Yn Yn+1 ) : 1 }-partitions Yn Yn+1 , 0 n < r.[b6] |W2 Y0 | = .Figure 4 illustrates relation sets Xi . (We set Ai = Xi Xi+1 0 <A1 = WW1 X0 .) Intuitively, Xm set points know pointsW1 sur1 ( 1 )W1 ,A far away. Xm1 possibly less far away,Xm2 possibly even less far, WXi , < 1. Finally, members A1even known whether sur1 ( 1 )W1 ,A not. Note object namesinterpreted Xm . come formal construction sets Xi .Proof Claim 1. prove (a). Part (b) provedandffleft reader.similarlyWassumption Lemma 45, find ADM Wa = Wa , F , RWa M1 |Wa | =assignment Aa = hAa1 , Aa2 hWa , Aa |= 1 .Let_Zn = (cn (sur1 ( 1 )))Wa ,Aa ,0n m. Lemma47 (1) take every n 1 n ADMffWn = Wn , F Wn , RWn M1 assignmentsn{sur1 (s)Wn ,A : 1 }48fiFusions Description Logics Abstract Description Systems-partitions Wn .ffTake disjoint union W (with W = W, F W , RW ) Wn , 1 n m, Wa .Define = hA1 , A2 W putting[A1 (x) = Aa1 (x)Ai1 (x),1imset variables x A2 (b) = Aa2 (b), object variables b. Let, 0 n m,[Xn = ZnWi .nimshow hW, Ai sets Xn , 0 n m, required.[a1] hWa , Aa |= 1 A2 (b) = Aa2 (b) Zm b obj(1 ). HenceA2 (b) Xm = Zm Wm b obj(1 ).[a2] definition disjoint unions hWa , Aa |= 1 .[a3] Firstly, have, definition cn since cW monotone (it distributesintersections),Zn+1 Zn cW (Zn ) Xn cW (Xn ).(3)Secondly, definition disjoint unions, first property covering normalterms, since cW monotone[[[[WiWiWi cW (Wi ) Xn cW Xn .(4)n+1imnimnimnim(3) (4) obtainXn+1 = Zn+1[Wi Xn cW Xn .(5)n+1im[a4] show three properties Definition 46 satisfied. Since{sur1 (s)Wm ,Am : 1 }-partition Wm , |sur1 (s)Wm ,Am | = 1 . impliesProperty 1 since sur1 (s)W,A Wm = sur1 (s)Wm ,Am , Wm Xm , |Xm | .Property 2 immediate consequence definition 1 . Property 3,show that, w Xm , w sW,A 1 . Fix w Xm .distinguish two cases: firstly, assume w Wm . Then, fact {sur1 (s)Wm ,Am :1 } -partition Wm , clearW exists 1 required.(sur ( )))Wa ,Aa . definition cm t,Secondly, assumewZ=(c11Ww (sur1 ( 1 ))Wa ,Aa w sur1 (s)W,A 1 .[a5] proof similar Property [a4].49fiBaader, Lutz, Sturm, & Wolter[a6] definition.finishes proof Claim 1.SupposeEEW1 = W1 , F W1 , RW1 , A, Xm , . . . , X0 W2 = W2 , G W2 , QW2 , B, Yr , . . . , Y0satisfying properties listed Claim 1. may assume(W1 Xm ) (W2 Yr ) = .Using appropriate bijection b Xm onto Yr may also assume Xm = Yr ,A2 (a) = B2 (a) object variables obj(1 ),sur1 (s)W1 ,A Xm = sur2 (s)W2 ,B Xm 1 .(6)follows fact object variables mapped A2 B2 XmYr ([a1], [b1]), respectively, injectivity mappings A2 B2 , conditions[a4] [b4] state {sur1 (s)W1 ,A Xm : 1 } {sur2 (s)W2 ,B Yr : 1 }form -partitions Xm = Yr . abbreviations useful: setAi = Xi Xi+1 , 0 < m,Bi = Yi Yi+1 , 0 < r,A1 = W1 X0 , B1 = W2 Y0 .far merged Xm -part W1 Yr -part W2 . remains take caresets Ai , 1 < m, Bi , 1 < r: sets Ai merged newmodels Wi M2 sets Bi merged new models Vi M1 . Thus,final model obtained merging disjoint union W1 Wi , 1 <disjoint union W2 Vi , 1 < r. Figure 5 illustrates merging.figure, assume 1 = {s1 , . . . , sk }.course, merging Ai , 0, new model Wi respect partition{sur1 (t)W1 ,A Ai | 1 }Ai . merging Bi , 0, new model Vi respect partition{sur1 (t)W1 ,B Bi | 1 }Bi . Note A1 B1 partitioncaretakeE of. proceedWWformal construction. find models W = Ai , G , QM2 assignmentsiffB = B1 , B2 , 1 1, that, 0 1,sur2 (s)W ,B = sur1 (s)W1 ,A Ai 1 .follows [a5], [a6], Lemma 47 (2).50(7)fiFusions Description Logics Abstract Description SystemsXm Am1...A0 A1 Vr1...V0 V1sur1 (s1 )............Wm1 . . .......sur1 (sk )YrW0 W1 Br1B0 B1sur2 (s1 )........ .sur2 (sk )Figure 5: bijection.Efind, using [b5], [b6], Lemma 47 (1), models Vi = Bi , F V , RV M1ffassignments Ai = Ai1 , Ai2 , 1 r 1, that, 0 r 1,sur1 (s)V ,A = sur2 (s)W2 ,B Bi 1 .Let(8)E00W01 = W1 (W2 Yr ), F W1 , RW1 M1disjoint union Vi , 1 < r, W1 , letE00W02 = W2 (W1 Xm ), G W2 , QW2 M2disjoint union Wi , 1 < m, W2 . assume Xm = Yrdomain ADMsW1 W2 .ffDefine model W = W, (F G)W , (R Q)W based W = W1 W2 putting0RW = RW1 ,0F W = F W1 ,0QW = QW2 ,0G W = G W2 .51fiBaader, Lutz, Sturm, & WolterDefine assignment C = hC1 , C2 W puttingC2 (a) = A2 (a)(= B2 (a)), obj(1 ).C1 (x) = A1 (x) 1i<r Ai1 (x), set variables x term().Notice C1 (x) = B1 (x) 1i<m B1i (x), set variables x term().C1 (xt ) = A1 (xt )C1 (xt ) = B1 (xt )1i<rAi1 (xt ), = g(t1 , . . . , tk ) sub1 ().1i<m B1 (xt ),= f (t1 , . . . , tk ) sub1 ().show hW, Ci |= . Firstly, however, make list relevant propertieshW, Ci:Claim 2.[c1] C2 (a) Xm = Yr , obj();[c2] hW, Ci |= 1 2 ;[c3] sur1 (t)W,C (X0 Y0 ) = sur2 (t)W,C (X0 Y0 ), 1 ;[c4] sur1 (s)W,C (X0 Y0 ) = sur2 (s)W,C (X0 Y0 ), sub1 ();[c5] Xn+1 Xn cW (Xn ), 0 n < m;[c6] Yn+1 Yn dW (Yn ), 0 n < r;[c7] g G arity l, 0 n < m, C1 , . . . , Cl W :g W (C1 , . . . , Cl ) Xn = g W (C1 Xn , . . . , Cl Xn ) Xn ;[c8] f F arity l, 0 n < r, C1 , . . . , Cl W :f W (C1 , . . . , Cl ) Yn = f W (C1 Yn , . . . , Cl Yn ) Yn .Proof Claim 2. [c1] follows [a1] [b1] construction hW, Ci. [c2] follows[a2] [b2]. [c3] follows construction hW, Ci equations (6), (7),(8). [c4] follows [c3]. [c5] [c6] follow [a3][b3], ffrespectively. remainsprove [c7] [c8]. [c7] follows fact W, GW disjoint unionstructures based Xn W Xn , 0 n < m, [c8] dual [c7]. Claim 2proved.show hW, Ci |= . end first show following:Claim 3. k1 , k2 0 k1 0 k2 r sub1 () dF (s) k1dG (s) k2 have, Z {Xk1 , Yk2 },Z sM,C = Z sur1 (s)M,C = Z sur2 (s)M,C .52fiFusions Description Logics Abstract Description SystemsProof Claim 3. [c4] suffices prove first equation. proof inductioncardinal k1 + k2 . induction base k1 = k2 = 0 follows sur1 (s) = sur2 (s)dF (s) = dG (s) = 0.Suppose claim proved Xk , Yk0 k m, k 0 r k + k 0 < k1 + k2 .prove claim Xk1 , Yk2 . proof induction construction termsdF (s) k1 dG (s) k2 . boolean cases trivial.Suppose = f (s1 , . . . , sl ) dF (s) k1 dG (s) k2 . showfollowing two statements:(i) Xk1 sW,C = Xk1 sur1 (s)M,C .(ii) Yk2 sW,C = Yk2 sur1 (s)M,C .Consider (i) first. induction hypothesis yieldsXk1 1 sW,C= Xk1 1 sur1 (si )W,C1 l.Xk1 1 cW (Xk1 1 ) sW,C = Xk1 1 cW (Xk1 1 ) f W (s1W,C , . . . , slW,C )= Xk1 1 cW (Xk1 1 ) f W (sur1 (s1 )W,C , . . . , sur1 (sl )W,C )= Xk1 1 cW (Xk1 1 ) sur1 (s)W,C .second equation immediate consequence third property covering normalterms given Definition 26. equation follows [c5], i.e. Xk1 Xk1 1cW (Xk1 1 ). (i) proved.(ii) Suppose first k2 = r. Yk2 = Xm claim provedsince Xm Xk1 and, induction hypothesis, Xk1 1 sW,C= Xk1 1 sur1 (si )W,C ,1 l.Assume k2 < r. induction hypothesis,Yk2 sW,C= Yk2 sur2 (si )W,C ,1 l. Hence, . . . , Yk2 sW,C) = f W (Yk2 sur2 (s1 )W,C , . . . , Yk2 sur2 (sl )W,C ).f W (Yk2 sW,C1lintersect sides equation Yk2 derive help [c8]:Yk2 f W (sW,C, . . . , sW,C) = Yk2 f W (sur2 (s1 )W,C , . . . , sur2 (sl )W,C ).1lmeans Yk2 sW,C = Yk2 sur2 (s)W,C , equation follows. statementsproved.case = g(s1 , . . . , sl ) dual left reader. proved claim 3.induction (c.f. proof Theorem 20 proof (1) correspondingclaim), obtain Claim 3:Xm sW,C = Xm sur1 (s)M,C term().53(9)fiBaader, Lutz, Sturm, & WolterLet us see hW, Ai |= follows (9). distinguish three cases: Suppose R(a, b). R(a, b) 1 therefore hW, Ci |= R(a, b). Similarly, Q(a, b) impliesQ(a, b) 2 hW, Ci |= Q(a, b). Suppose (a : t) . (a : sur1 (t)) 1 so,[c2], C2 (a) sur1 (t)W,C implies, (9), C2 (a) tW,C . Hence hW, Ci |= (a : t).finishes proof Theorem 30.ReferencesAreces, C., Blackburn, P., & Marx, M. (2000). computational complexity hybridtemporal logics. Logic Journal IGPL, 8 (5), 653679.Baader, F. (1991). Augmenting concept languages transitive closure roles: alternative terminological cycles. Proc. 12th Int. Joint Conf. ArtificialIntelligence (IJCAI91).Baader, F., Burckert, H.-J., Hollunder, B., Nutt, W., & Siekmann, J. H. (1990). Conceptlogics. Lloyd, J. W. (Ed.), Computational Logics, Symposium Proceedings, pp.177201. Springer-Verlag.Baader, F., Burckert, H.-J., Nebel, B., Nutt, W., & Smolka, G. (1993). expressivityfeature logics negation, functional uncertainty, sort equations. J. Logic,Language Information, 2, 118.Baader, F., & Hanschke, P. (1991). schema integrating concrete domains conceptlanguages. Proc. 12th Int. Joint Conf. Artificial Intelligence (IJCAI91),pp. 452457.Baader, F., & Hanschke, P. (1992). Extensions concept languages mechanical engineering application. Proc. 16th German Workshop Artificial Intelligence(GWAI92), Vol. 671 Lecture Notes Computer Science, pp. 132143, Bonn (Germany). Springer-Verlag.Baader, F., & Hollunder, B. (1991). terminological knowledge representation systemcomplete inference algorithm. Proc. Workshop Processing DeclarativeKnowledge (PDK91), Vol. 567 Lecture Notes Artificial Intelligence, pp. 6786.Springer-Verlag.Baader, F., & Sattler, U. (1999). Expressive number restrictions description logics. J.Logic Computation, 9 (3), 319350.Ben-Ari, M., Halpern, J. Y., & Pnueli, A. (1982). Deterministic propositional dynamic logic:Finite models, complexity, completeness. J. Computer System Sciences,25, 402417.Berger, R. (1966). undecidability dominoe problem. Mem. Amer. Math. Soc.,66, 172.Borgida, A. (1995). Description logics data management. IEEE Trans. KnowledgeData Engineering, 7 (5), 671682.Brachman, R. J., McGuinness, D. L., Patel-Schneider, P. F., Alperin Resnick, L., & Borgida,A. (1991). Living CLASSIC: use KL-ONE-like language.54fiFusions Description Logics Abstract Description SystemsSowa, J. F. (Ed.), Principles Semantic Networks, pp. 401456. Morgan Kaufmann,Los Altos.Brachman, R. J., & Schmolze, J. G. (1985). overview KL-ONE knowledge representation system. Cognitive Science, 9 (2), 171216.Bresciani, P., Franconi, E., & Tessaris, S. (1995). Implementing testing expressive description logics: Preliminary report. Proc. 1995 Description Logic Workshop(DL95), pp. 131139.Calvanese, D., De Giacomo, G., & Lenzerini, M. (1999). Reasoning expressive descriptionlogics fixpoints based automata infinite trees. Proc. 16th Int.Joint Conf. Artificial Intelligence (IJCAI99), pp. 8489.Calvanese, D., De Giacomo, G., & Rosati, R. (1998). note encoding inverse rolesfunctional restrictions ALC knowledge bases. Proc. 1998 Description LogicWorkshop (DL98), pp. 6971. CEUR Electronic Workshop Proceedings, http://ceurws.org/Vol-11/.Chellas, B. F. (1980). Modal logic. Cambridge University Press, Cambridge, UK.Danecki, R. (1984). Nondeterministic Propositional Dynamic Logic intersectiondecidable. Proc. 5th Symp. Computation Theory, Vol. 208 LectureNotes Computer Science, pp. 3453. Springer-Verlag.De Giacomo, G. (1995). Decidability Class-Based Knowledge Representation Formalisms.Ph.D. thesis, Dipartimento di Informatica e Sistemistica, Universita di Roma LaSapienza.De Giacomo, G., & Lenzerini, M. (1994a). Boosting correspondence descriptionlogics propositional dynamic logics. Proc. 12th Nat. Conf. ArtificialIntelligence (AAAI94), pp. 205212. AAAI Press/The MIT Press.De Giacomo, G., & Lenzerini, M. (1994b). Concept language number restrictionsfixpoints, relationship -calculus. Proc. 11th Eur. Conf.Artificial Intelligence (ECAI94), pp. 411415.De Giacomo, G., & Lenzerini, M. (1995). Whats aggregate: Foundations description logics tuples sets. Proc. 14th Int. Joint Conf. ArtificialIntelligence (IJCAI95), pp. 801807.Donini, F. M., Hollunder, B., Lenzerini, M., Spaccamela, A. M., Nardi, D., & Nutt, W.(1992). complexity existential quantification concept languages. ArtificialIntelligence, 23, 309327.Donini, F. M., Lenzerini, M., Nardi, D., & Nutt, W. (1991). Tractable concept languages.Proc. 12th Int. Joint Conf. Artificial Intelligence (IJCAI91), pp. 458463,Sydney (Australia).Donini, F. M., Lenzerini, M., Nardi, D., & Nutt, W. (1997). complexity conceptlanguages. Information Computation, 134, 158.Donini, F. M., Lenzerini, M., Nardi, D., & Schaerf, A. (1994). Deduction concept languages: subsumption instance checking. J. Logic Computation, 4 (4),423452.55fiBaader, Lutz, Sturm, & WolterDosen, K. (1988). Duality modal algebras neighbourhood frames. StudiaLogica, 48, 219234.Fine, K., & Schurz, G. (1996). Transfer theorems stratified modal logics. Copeland,J. (Ed.), Logic Reality: Essays Pure Applied Logic. Memory ArthurPrior, pp. 169213. Oxford University Press.Fischer, M. J., & Ladner, R. E. (1979). Propositional dynamic logic regular programs.J. Computer System Sciences, 18, 194211.Gabbay, D. M. (1999). Fibring Logics, Vol. 38 Oxford Logic Guides. Clarendon Press,Oxford.Gargov, G., & Goranko, V. (1993). Modal logic names. J. Philosophical Logic, 22,607636.Goldblatt, R. I. (1989). Varieties complex algebras. Annals Pure Applied Logic,38, 173241.Goranko, V., & Passy, S. (1992). Using universal modality: Gains questions. JournalLogic Computation, 2 (1), 530.Gratzer, G. (1979). Universal Algebra. Springer-Verlag, New York.Haarslev, V., Moller, R., & Wessel, M. (2001). description logic ALCN HR+ extendedconcrete domains: practically motivated approach. Proceedings International Joint Conference Automated Reasoning IJCAR01, Lecture NotesArtificial Intelligence. Springer-Verlag.Harel, D. (1984). Dynamic logic. Handbook Philosophical Logic, Vol. 2, pp. 497640.D. Reidel, Dordrecht (Holland).Hollunder, B., & Baader, F. (1991). Qualifying number restrictions concept languages.Tech. rep. RR-91-03, Deutsches Forschungszentrum fur Kunstliche Intelligenz (DFKI),Kaiserslautern (Germany). abridged version appeared Proc. 2nd Int.Conf. Principles Knowledge Representation Reasoning (KR91).Hollunder, B., & Nutt, W. (1990). Subsumption algorithms concept languages. Tech. rep.RR-90-04, Deutsches Forschungszentrum fur Kunstliche Intelligenz (DFKI), Kaiserslautern (Germany).Horrocks, I. (1998). Using expressive description logic: FaCT fiction?. Proc.6th Int. Conf. Principles Knowledge Representation Reasoning (KR98),pp. 636647.Horrocks, I., & Sattler, U. (1999). description logic transitive inverse rolesrole hierarchies. J. Logic Computation, 9 (3), 385410.Horrocks, I., Sattler, U., & Tobies, S. (2000). Practical reasoning expressive description logics. J. Interest Group Pure Applied Logic, 8 (3), 239264.Jonsson, B., & Tarski, A. (1951). Boolean algebras operators. I. American JournalMathematics, 73, 891939.Jonsson, B., & Tarski, A. (1952). Boolean algebras operators. II. American JournalMathematics, 74, 127162.56fiFusions Description Logics Abstract Description SystemsKnuth, D. E. (1973). Art Computer Programming, Vol. 3. Addison-Wesley, Mass.Kracht, M., & Wolter, F. (1991). Properties independently axiomatizable bimodal logics.Journal Symbolic Logic, 56 (4), 14691485.Kutz, O., Wolter, F., & Zakharyaschev, M. (2001). Connecting abstract description systems.Submitted. Available http://www.informatik.uni-leipzig.de/wolter/.Levesque, H. J., & Brachman, R. J. (1987). Expressiveness tractability knowledgerepresentation reasoning. Computational Intelligence, 3, 7893.Lutz, C. (1999). Reasoning concrete domains. Dean, T. (Ed.), Proc. 16thInt. Joint Conf. Artificial Intelligence (IJCAI99), pp. 9095, Stockholm, Sweden.Morgan Kaufmann, Los Altos.Lutz, C. (2001). Interval-based temporal reasoning general TBoxes. Proc.17th Int. Joint Conf. Artificial Intelligence (IJCAI 2001), pp. 8994.Lutz, C., & Sattler, U. (2000). Mary likes cats. Proc. 2000 DescriptionLogic Workshop (DL 2000), pp. 213226. CEUR Electronic Workshop Proceedings,http://ceur-ws.org/Vol-33/.Nebel, B. (1988). Computational complexity terminological reasoning BACK. ArtificialIntelligence, 34 (3), 371383.Nebel, B. (1990). Terminological reasoning inherently intractable. Artificial Intelligence,43, 235249.Parikh, R. (1980). Propositional logics programs: Systems, models complexity.Proc. 7th ACM SIGACT-SIGPLAN Symp. Principles Programming Languages (POPL80), pp. 186192, Las Vegas (USA).Prior, A. N. (1967). Past, Present Future. Oxford University Press.Sattler, U. (1996). concept language extended different kinds transitive roles.Gorz, G., & Holldobler, S. (Eds.), Proc. 20th German Annual Conf. ArtificialIntelligence (KI96), No. 1137 Lecture Notes Artificial Intelligence, pp. 333345.Springer-Verlag.Schaerf, A. (1993). complexity instance checking problem concept languagesexistential quantification. J. Intelligent Information Systems, 2, 265278.Schaerf, A. (1994). Reasoning individuals concept languages. Data KnowledgeEngineering, 13 (2), 141176.Schild, K. (1991). correspondence theory terminological logics: Preliminary report.Proc. 12th Int. Joint Conf. Artificial Intelligence (IJCAI91), pp. 466471.Schmidt-Schau, M. (1989). Subsumption KL-ONE undecidable. Brachman, R. J.,Levesque, H. J., & Reiter, R. (Eds.), Proc. 1st Int. Conf. PrinciplesKnowledge Representation Reasoning (KR89), pp. 421431. Morgan Kaufmann,Los Altos.Schmidt-Schau, M., & Smolka, G. (1991). Attributive concept descriptions complements. Artificial Intelligence, 48 (1), 126.57fiBaader, Lutz, Sturm, & WolterSpaan, E. (1993). Complexity Modal Logics. Ph.D. thesis, Department MathematicsComputer Science, University Amsterdam, Netherlands.Van der Hoek, W., & de Rijke, M. (1995). Counting objects. J. Logic Computation,5 (3), 325345.Wolter, F. (1998). Fusions modal logics revisited. Kracht, M., de Rijke, M., Wansing, H., & Zakharyaschev, M. (Eds.), Advances Modal Logic, pp. 361379. CSLIPublications.Woods, W. A., & Schmolze, J. G. (1992). KL-ONE family. Lehmann, F. W. (Ed.),Semantic Networks Artificial Intelligence, pp. 133178. Pergamon Press. Publishedspecial issue Computers & Mathematics Applications, Volume 23, Number29.58fiJournal Artificial Intelligence Research 16 (2002) 321357Submitted 09/01; published 06/02SMOTE: Synthetic Minority Over-sampling TechniqueNitesh V. Chawlachawla@csee.usf.eduDepartment Computer Science Engineering, ENB 118University South Florida4202 E. Fowler Ave.Tampa, FL 33620-5399, USAKevin W. Bowyerkwb@cse.nd.eduDepartment Computer Science Engineering384 Fitzpatrick HallUniversity Notre DameNotre Dame, 46556, USALawrence O. Hallhall@csee.usf.eduDepartment Computer Science Engineering, ENB 118University South Florida4202 E. Fowler Ave.Tampa, FL 33620-5399, USAW. Philip Kegelmeyerwpk@california.sandia.govSandia National LaboratoriesBiosystems Research Department, P.O. Box 969, MS 9951Livermore, CA, 94551-0969, USAAbstractapproach construction classiers imbalanced datasets described.dataset imbalanced classication categories approximately equally represented. Often real-world data sets predominately composed normal examplessmall percentage abnormal interesting examples. also casecost misclassifying abnormal (interesting) example normal exampleoften much higher cost reverse error. Under-sampling majority (normal) class proposed good means increasing sensitivity classierminority class. paper shows combination method over-samplingminority (abnormal) class under-sampling majority (normal) class achievebetter classier performance (in ROC space) under-sampling majority class.paper also shows combination method over-sampling minority classunder-sampling majority class achieve better classier performance (in ROCspace) varying loss ratios Ripper class priors Naive Bayes. methodover-sampling minority class involves creating synthetic minority class examples.Experiments performed using C4.5, Ripper Naive Bayes classier. methodevaluated using area Receiver Operating Characteristic curve (AUC)ROC convex hull strategy.1. Introductiondataset imbalanced classes approximately equally represented. Imbalanceorder 100 1 prevalent fraud detection imbalance 100,000c2002AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiChawla, Bowyer, Hall & Kegelmeyer1 reported applications (Provost & Fawcett, 2001).attempts deal imbalanced datasets domains fraudulent telephone calls(Fawcett & Provost, 1996), telecommunications management (Ezawa, Singh, & Norton,1996), text classication (Lewis & Catlett, 1994; Dumais, Platt, Heckerman, & Sahami,1998; Mladenic & Grobelnik, 1999; Lewis & Ringuette, 1994; Cohen, 1995a) detectionoil spills satellite images (Kubat, Holte, & Matwin, 1998).performance machine learning algorithms typically evaluated using predictiveaccuracy. However, appropriate data imbalanced and/or costsdierent errors vary markedly. example, consider classication pixels mammogram images possibly cancerous (Woods, Doss, Bowyer, Solka, Priebe, & Kegelmeyer,1993). typical mammography dataset might contain 98% normal pixels 2% abnormalpixels. simple default strategy guessing majority class would give predictive accuracy 98%. However, nature application requires fairly high rate correctdetection minority class allows small error rate majority classorder achieve this. Simple predictive accuracy clearly appropriate situations. Receiver Operating Characteristic (ROC) curve standard techniquesummarizing classier performance range tradeos true positive falsepositive error rates (Swets, 1988). Area Curve (AUC) accepted traditional performance metric ROC curve (Duda, Hart, & Stork, 2001; Bradley, 1997; Lee,2000). ROC convex hull also used robust method identifying potentiallyoptimal classiers (Provost & Fawcett, 2001). line passes point convexhull, line slope passing another pointlarger true positive (TP) intercept. Thus, classier point optimaldistribution assumptions tandem slope.machine learning community addressed issue class imbalance two ways.One assign distinct costs training examples (Pazzani, Merz, Murphy, Ali, Hume, &Brunk, 1994; Domingos, 1999). re-sample original dataset, either oversampling minority class and/or under-sampling majority class (Kubat & Matwin,1997; Japkowicz, 2000; Lewis & Catlett, 1994; Ling & Li, 1998). approach (Chawla,Bowyer, Hall, & Kegelmeyer, 2000) blends under-sampling majority classspecial form over-sampling minority class. Experiments various datasetsC4.5 decision tree classier (Quinlan, 1992), Ripper (Cohen, 1995b), Naive BayesClassier show approach improves previous re-sampling, modifying lossratio, class priors approaches, using either AUC ROC convex hull.Section 2 gives overview performance measures. Section 3 reviewsclosely related work dealing imbalanced datasets. Section 4 presents detailsapproach. Section 5 presents experimental results comparing approachre-sampling approaches. Section 6 discusses results suggests directions futurework.2. Performance Measuresperformance machine learning algorithms typically evaluated confusion matrixillustrated Figure 1 (for 2 class problem). columns Predicted classrows Actual class. confusion matrix, N number negative examples322fiSMOTEPredictedNegativePredictedPositiveActualNegativeTNFPActualPositiveFNTPFigure 1: Confusion Matrixcorrectly classied (True Negatives), F P number negative examples incorrectlyclassied positive (False Positives), F N number positive examples incorrectlyclassied negative (False Negatives) P number positive examples correctlyclassied (True Positives).Predictive accuracy performance measure generally associated machine learning algorithms dened Accuracy = (T P + N )/(T P + F P + N + F N ).context balanced datasets equal error costs, reasonable use error rateperformance metric. Error rate 1 Accuracy. presence imbalanced datasetsunequal error costs, appropriate use ROC curve similartechniques (Ling & Li, 1998; Drummond & Holte, 2000; Provost & Fawcett, 2001; Bradley,1997; Turney, 1996).ROC curves thought representing family best decision boundariesrelative costs TP FP. ROC curve X-axis represents %F P = F P/(T N +F P )Y-axis represents %T P = P/(T P +F N ). ideal point ROC curve would(0,100), positive examples classied correctly negative examplesmisclassied positive. One way ROC curve swept manipulatingbalance training samples class training set. Figure 2 shows illustration.line = x represents scenario randomly guessing class. Area ROCCurve (AUC) useful metric classier performance independent decisioncriterion selected prior probabilities. AUC comparison establish dominancerelationship classiers. ROC curves intersecting, total AUCaverage comparison models (Lee, 2000). However, specic cost classdistributions, classier maximum AUC may fact suboptimal. Hence,also compute ROC convex hulls, since points lying ROC convex hullpotentially optimal (Provost, Fawcett, & Kohavi, 1998; Provost & Fawcett, 2001).3. Previous Work: Imbalanced datasetsKubat Matwin (1997) selectively under-sampled majority class keepingoriginal population minority class. used geometric mean performance measure classier, related single point ROC curve.minority examples divided four categories: noise overlapping positive class decision region, borderline samples, redundant samples safe samples.borderline examples detected using Tomek links concept (Tomek, 1976). Another323fiChawla, Bowyer, Hall & KegelmeyerROC(100, 100)100Ideal pointPercentTruey=xPositiveincreased undersamplingmajority class movesoperating pointupper rightoriginal data set0Percent False Positive100Figure 2: Illustration sweeping ROC curve under-sampling. Increasedunder-sampling majority (negative) class move performancelower left point upper right.related work proposed SHRINK system classies overlapping region minority (positive) majority (negative) classes positive; searches best positiveregion (Kubat et al., 1998).Japkowicz (2000) discussed eect imbalance dataset. evaluated threestrategies: under-sampling, resampling recognition-based induction scheme. focussampling approaches. experimented articial 1D data order easilymeasure construct concept complexity. Two resampling methods considered.Random resampling consisted resampling smaller class random consistedmany samples majority class focused resampling consisted resamplingminority examples occurred boundary minoritymajority classes. Random under-sampling considered, involved under-samplingmajority class samples random numbers matched number minorityclass samples; focused under-sampling involved under-sampling majority class sampleslying away. noted sampling approaches eective, alsoobserved using sophisticated sampling techniques give clear advantagedomain considered (Japkowicz, 2000).One approach particularly relevant work Ling Li (1998).combined over-sampling minority class under-sampling majorityclass. used lift analysis instead accuracy measure classiers performance.proposed test examples ranked condence measure lift usedevaluation criteria. lift curve similar ROC curve, tailored324fiSMOTEmarketing analysis problem (Ling & Li, 1998). one experiment, under-sampledmajority class noted best lift index obtained classes equallyrepresented (Ling & Li, 1998). another experiment, over-sampled positive(minority) examples replacement match number negative (majority) examplesnumber positive examples. over-sampling under-sampling combinationprovide signicant improvement lift index. However, approach oversampling diers theirs.Solberg Solberg (1996) considered problem imbalanced data sets oil slickclassication SAR imagery. used over-sampling under-sampling techniquesimprove classication oil slicks. training data distribution 42 oilslicks 2,471 look-alikes, giving prior probability 0.98 look-alikes. imbalancewould lead learner (without appropriate loss functions methodology modifypriors) classify almost look-alikes correctly expense misclassifying manyoil slick samples (Solberg & Solberg, 1996). overcome imbalance problem,over-sampled (with replacement) 100 samples oil slick, randomly sampled100 samples non oil slick class create new dataset equal probabilities.learned classier tree balanced data set achieved 14% error rateoil slicks leave-one-out method error estimation; look alikes achievederror rate 4% (Solberg & Solberg, 1996).Another approach similar work Domingos (1999). comparesmetacost approach majority under-sampling minority over-sampling.nds metacost improves either, under-sampling preferable minority over-sampling. Error-based classiers made cost-sensitive. probabilityclass example estimated, examples relabeled optimallyrespect misclassication costs. relabeling examples expands decisionspace creates new samples classier may learn (Domingos, 1999).feed-forward neural network trained imbalanced dataset may learn discriminate enough classes (DeRouin, Brown, Fausett, & Schneider, 1991).authors proposed learning rate neural network adapted statisticsclass representation data. calculated attention factor proportionsamples presented neural network training. learning rate networkelements adjusted based attention factor. experimented articiallygenerated training set real-world training set, multiple (more two)classes. compared approach replicating minority class samplesbalance data set used training. classication accuracy minority classimproved.Lewis Catlett (1994) examined heterogeneous uncertainty sampling supervisedlearning. method useful training samples uncertain classes. trainingsamples labeled incrementally two phases uncertain instances passednext phase. modied C4.5 include loss ratio determining classvalues leaves. class values determined comparison probabilitythreshold LR/(LR + 1), LR loss ratio (Lewis & Catlett, 1994).information retrieval (IR) domain (Dumais et al., 1998; Mladenic & Grobelnik,1999; Lewis & Ringuette, 1994; Cohen, 1995a) also faces problem class imbalancedataset. document web page converted bag-of-words representation;325fiChawla, Bowyer, Hall & Kegelmeyeris, feature vector reecting occurrences words page constructed. Usually,instances interesting category text categorization. overrepresentation negative class information retrieval problems cause problemsevaluating classiers performances. Since error rate good metric skeweddatasets, classication performance algorithms information retrieval usuallymeasured precision recall:recall =TPTP + FNprecision =TPTP + FPMladenic Grobelnik (1999) proposed feature subset selection approach dealimbalanced class distribution IR domain. experimented variousfeature selection methods, found odds ratio (van Rijsbergen, Harper, & Porter,1981) combined Naive Bayes classier performs best domain. Oddsratio probabilistic measure used rank documents according relevancepositive class (minority class). Information gain word, hand,pay attention particular target class; computed per word class.imbalanced text dataset (assuming 98 99% negative class), featuresassociated negative class. Odds ratio incorporates target class informationmetric giving better results compared information gain text categorization.Provost Fawcett (1997) introduced ROC convex hull method estimateclassier performance imbalanced datasets. note problems unequalclass distribution unequal error costs related little work doneaddress either problem (Provost & Fawcett, 2001). ROC convex hull method,ROC space used separate classication performance class cost distributioninformation.summarize literature, under-sampling majority class enables better classiersbuilt over-sampling minority class. combination two doneprevious work lead classiers outperform built utilizing undersampling. However, over-sampling minority class done samplingreplacement original data. approach uses dierent method over-sampling.4. SMOTE: Synthetic Minority Over-sampling TEchnique4.1 Minority over-sampling replacementPrevious research (Ling & Li, 1998; Japkowicz, 2000) discussed over-samplingreplacement noted doesnt signicantly improve minority class recognition.interpret underlying eect terms decision regions feature space. Essentially,minority class over-sampled increasing amounts, eect identify similarspecic regions feature space decision region minority class.eect decision trees understood plots Figure 3.326fiSMOTE2attributes, 10% data original Mammography dataset2attributes, 10% data original Mammography dataset450200400350150Attribute 2Attribute 230025020010015010050500024681012140161234Attribute 15678Attribute 1(a)(b)2attributes, 10% data original Mammography dataset200Attribute 215010050012345Attribute 1678(c)Figure 3: a) Decision region three minority class samples (shown +) residebuilding decision tree. decision region indicated solid-linerectangle. b) zoomed-in view chosen minority class samplesdataset. Small solid-line rectangles show decision regions result oversampling minority class replication. c) zoomed-in view chosenminority class samples dataset. Dashed lines show decision regionover-sampling minority class synthetic generation.327fiChawla, Bowyer, Hall & Kegelmeyerdata plot Figure 3 extracted Mammography dataset1 (Woodset al., 1993). minority class samples shown + majority class samplesshown plot. Figure 3(a), region indicated solid-line rectanglemajority class decision region. Nevertheless, contains three minority class samplesshown + false negatives. replicate minority class, decision regionminority class becomes specic cause new splits decision tree.lead terminal nodes (leaves) learning algorithm tries learnspecic regions minority class; essence, overtting. Replication minorityclass cause decision boundary spread majority class region. Thus,Figure 3(b), three samples previously majority class decision regionspecic decision regions.4.2 SMOTEpropose over-sampling approach minority class over-sampled creating synthetic examples rather over-sampling replacement. approachinspired technique proved successful handwritten character recognition (Ha& Bunke, 1997). created extra training data performing certain operationsreal data. case, operations like rotation skew natural ways perturbtraining data. generate synthetic examples less application-specic manner,operating feature space rather data space. minority class over-sampledtaking minority class sample introducing synthetic examples along linesegments joining any/all k minority class nearest neighbors. Depending uponamount over-sampling required, neighbors k nearest neighbors randomlychosen. implementation currently uses nearest neighbors. instance,amount over-sampling needed 200%, two neighbors nearest neighbors chosen one sample generated direction each. Synthetic samplesgenerated following way: Take dierence feature vector (sample)consideration nearest neighbor. Multiply dierence random number0 1, add feature vector consideration. causesselection random point along line segment two specic features.approach eectively forces decision region minority class become general.Algorithm SMOTE , next page, pseudo-code SMOTE. Table 4.2 showsexample calculation random synthetic samples. amount over-samplingparameter system, series ROC curves generated dierentpopulations ROC analysis performed.synthetic examples cause classier create larger less specic decisionregions shown dashed lines Figure 3(c), rather smaller specicregions. general regions learned minority class samples rathersubsumed majority class samples around them. eect decision trees generalize better. Figures 4 5 compare minority over-samplingreplacement SMOTE. experiments conducted mammography dataset.10923 examples majority class 260 examples minority classoriginally. approximately 9831 examples majority class 233 examples1. data available USF Intelligent Systems Lab, http://morden.csee.usf.edu/chawla.328fiSMOTEminority class training set used 10-fold cross-validation. minority classover-sampled 100%, 200%, 300%, 400% 500% original size. graphsshow tree sizes minority over-sampling replacement higher degreesreplication much greater SMOTE, minority class recognitionminority over-sampling replacement technique higher degrees replication isntgood SMOTE.Algorithm SMOTE (T, N, k)Input: Number minority class samples ; Amount SMOTE N %; Number nearestneighbors kOutput: (N/100) * synthetic minority class samples1. ( N less 100%, randomize minority class samples randompercent SMOTEd. )2. N < 1003.Randomize minority class samples4.= (N/100)5.N = 1006. endif7. N = (int)(N/100) ( amount SMOTE assumed integral multiples100. )8. k = Number nearest neighbors9. numattrs = Number attributes10. Sample[ ][ ]: array original minority class samples11. newindex: keeps count number synthetic samples generated, initialized 012. Synthetic[ ][ ]: array synthetic samples( Compute k nearest neighbors minority class sample only. )13. 114.Compute k nearest neighbors i, save indices nnarray15.Populate(N , i, nnarray)16. endforPopulate(N, i, nnarray) ( Function generate synthetic samples. )17. N = 018.Choose random number 1 k, call nn. step chooses onek nearest neighbors i.19.attr 1 numattrs20.Compute: dif = Sample[nnarray[nn]][attr] Sample[i][attr]21.Compute: gap = random number 0 122.Synthetic[newindex][attr] = Sample[i][attr] + gap dif23.endfor24.newindex++25.N = N 126. endwhile27. return ( End Populate. )End Pseudo-Code.329fiChawla, Bowyer, Hall & KegelmeyerConsider sample (6,4) let (4,3) nearest neighbor.(6,4) sample k-nearest neighbors identied.(4,3) one k-nearest neighbors.Let:f1 1 = 6 f2 1 = 4 f2 1 - f1 1 = -2f1 2 = 4 f2 2 = 3 f2 2 - f1 2 = -1new samples generated(f1,f2) = (6,4) + rand(0-1) * (-2,-1)rand(0-1) generates random number 0 1.Table 1: Example generation synthetic examples (SMOTE).Pruned decision tree size vs degree minority oversampling260240Decisiion tree size (Number nodes)220200180160140Synthetic dataReplicated data1201008060050100150200250300350Degree minority oversampling400450500Figure 4: Comparison decision tree sizes replicated over-sampling SMOTEMammography dataset330fiSMOTE% Minority Correct vs Degree Minority Oversampling75%Minority Correct706560Synthetic dataReplicated data5550050100150200250300350400450500Degree Minority OversamplingFigure 5: Comparison % Minority correct replicated over-sampling SMOTEMammography dataset4.3 Under-sampling SMOTE Combinationmajority class under-sampled randomly removing samples majority classpopulation minority class becomes specied percentage majority class.forces learner experience varying degrees under-sampling higher degreesunder-sampling minority class larger presence training set. describingexperiments, terminology under-sample majority class200%, would mean modied dataset contain twice many elementsminority class majority class; is, minority class 50 samplesmajority class 200 samples under-sample majority 200%, majorityclass would end 25 samples. applying combination under-samplingover-sampling, initial bias learner towards negative (majority) class reversedfavor positive (minority) class. Classiers learned dataset perturbedSMOTING minority class under-sampling majority class.5. Experimentsused three dierent machine learning algorithms experiments. Figure 6 providesoverview experiments.1. C4.5: compared various combinations SMOTE under-sampling plainunder-sampling using C4.5 release 8 (Quinlan, 1992) base classier.331fiChawla, Bowyer, Hall & KegelmeyerSMOTEUndersampling.C4.5Loss-RatioModify costs majority minorityvaried 0.9 0.001.classes changing priors.RipperNaive BayesROCs generated SMOTE, UndersamplingLoss Ratio comparisons. Performanceevaluated AUC ROC convex hull.ROCs generated comparisonSMOTE Under-sampling using C4.5,SMOTE using C4.5 Naive bayes.Performance evaluated AUC ROC convex hull.Figure 6: Experiments Overview2. Ripper: compared various combinations SMOTE under-samplingplain under-sampling using Ripper (Cohen, 1995b) base classier. alsovaried Rippers loss ratio (Cohen & Singer, 1996; Lewis & Catlett, 1994) 0.90.001 (as means varying misclassication cost) compared eectvariation combination SMOTE under-sampling. reducing lossratio 0.9 0.001 able build set rules minority class.3. Naive Bayes Classifier: Naive Bayes Classier2 made cost-sensitivevarying priors minority class. varied priors minorityclass 1 50 times majority class compared C4.5s SMOTEunder-sampling combination.dierent learning algorithms allowed SMOTE compared methodshandle misclassication costs directly. %FP %TP averaged 10-foldcross-validation runs data combinations. minority class examplesover-sampled calculating nearest neighbors generating synthetic examples.AUC calculated using trapezoidal rule. extrapolated extra point TP= 100% FP = 100% ROC curve. also computed ROC convex hullidentify optimal classiers, points lying hull potentially optimalclassiers (Provost & Fawcett, 2001).2. source code downloaded http://fuzzy.cs.uni-magdeburg.de/borgelt/software.html.332fiSMOTE5.1 Datasetsexperimented nine dierent datasets. datasets summarized Table 5.2.datasets vary extensively size class proportions, thus oering dierentdomains SMOTE. order increasing imbalance are:1. Pima Indian Diabetes (Blake & Merz, 1998) 2 classes 768 samples.data used identify positive diabetes cases population near Phoenix,Arizona. number positive class samples 268. Good sensitivitydetection diabetes cases desirable attribute classier.2. Phoneme dataset ELENA project3 . aim datasetdistinguish nasal (class 0) oral sounds (class 1). 5 features.class distribution 3,818 samples class 0 1,586 samples class 1.3. Adult dataset (Blake & Merz, 1998) 48,842 samples 11,687 samplesbelonging minority class. dataset 6 continuous features 8 nominalfeatures. SMOTE SMOTE-NC (see Section 6.1) algorithms evaluateddataset. SMOTE, extracted continuous features generated newdataset continuous features.4. E-state data4 (Hall, Mohney, & Kier, 1991) consists electrotopological statedescriptors series compounds National Cancer Institutes Yeast AntiCancer drug screen. E-state descriptors NCI Yeast AntiCancer Drug Screengenerated Tripos, Inc. Briey, series 60,000 compoundstested series 6 yeast strains given concentration. testhigh-throughput screen one concentration results subject contamination, etc. growth inhibition yeast strain exposed givencompound (with respect growth yeast neutral solvent) measured.activity classes either active least one single yeast strain inhibited70%, inactive yeast strain inhibited 70%.dataset 53,220 samples 6,351 samples active compounds.5. Satimage dataset (Blake & Merz, 1998) 6 classes originally. chosesmallest class minority class collapsed rest classes onedone (Provost et al., 1998). gave us skewed 2-class dataset, 5809majority class samples 626 minority class samples.6. Forest Cover dataset UCI repository (Blake & Merz, 1998).dataset 7 classes 581,012 samples. dataset prediction forestcover type based cartographic variables. Since system currently works binary classes extracted data two classes dataset ignored rest.approaches work two classes (Ling & Li, 1998; Japkowicz,2000; Kubat & Matwin, 1997; Provost & Fawcett, 2001). two classes considered Ponderosa Pine 35,754 samples Cottonwood/Willow 2,7473. ftp.dice.ucl.ac.be directory pub/neural-nets/ELENA/databases.4. would like thank Steven Eschrich providing dataset description us.333fiChawla, Bowyer, Hall & KegelmeyerDatasetPimaPhonemeAdultE-stateSatimageForest CoverOilMammographyMajority Class5003818371554686958093575489610923435512Minority Class26815861168763516262747412608360Table 2: Dataset distributionsamples. Nevertheless, SMOTE technique applied multiple class problem well specifying class SMOTE for. However, paper,focused 2-classes problems, explicitly represent positive negative classes.7. Oil dataset provided Robert Holte used paper (Kubat et al.,1998). dataset 41 oil slick samples 896 non-oil slick samples.8. Mammography dataset (Woods et al., 1993) 11,183 samples 260 calcications. look predictive accuracy measure goodness classiercase, default accuracy would 97.68% every sample labeled noncalcication. But, desirable classier predict calcicationscorrectly.9. dataset generated ExodusII data using AVATAR(Chawla & Hall, 1999) version Mustafa Visualization tool5 . portioncrushed marked interesting restmarked unknown. dataset size 443,872 samples 8,360 samples markedinteresting generated.5.2 ROC CreationROC curve SMOTE produced using C4.5 Ripper create classierone series modied training datasets. given ROC curve produced rstover-sampling minority class specied degree under-sampling majorityclass increasing degrees generate successive points curve. amountunder-sampling identical plain under-sampling. So, corresponding pointROC curve dataset represents number majority class samples. DierentROC curves produced starting dierent levels minority over-sampling. ROCcurves also generated varying loss ratio Ripper 0.9 0.001varying priors minority class original distribution 50 timesmajority class Naive Bayes Classier.5. Mustafa visualization tool developed Mike Glass Sandia National Labs.334fiSMOTEPhoneme ROC100959085%TPUnderC4.5200 SMOTEC4.5Naive BayesHull80757065102030405060708090100%FPFigure 7: Phoneme. Comparison SMOTE-C4.5, Under-C4.5, Naive Bayes. SMOTEC4.5 dominates Naive Bayes Under-C4.5 ROC space. SMOTEC4.5 classiers potentially optimal classiers.Figures 9 23 show experimental ROC curves obtained nine datasetsthree classiers. ROC curve plain under-sampling majority class(Ling & Li, 1998; Japkowicz, 2000; Kubat & Matwin, 1997; Provost & Fawcett, 2001)compared approach combining synthetic minority class over-sampling (SMOTE)majority class under-sampling. plain under-sampling curve labeled Under,SMOTE under-sampling combination ROC curve labeled SMOTE. Depending size relative imbalance dataset, one SMOTE undersampling curves created. show best results SMOTE combinedunder-sampling plain under-sampling curve graphs. SMOTE ROC curveC4.5 also compared ROC curve obtained varying priors minorityclass using Naive Bayes classier labeled Naive Bayes. SMOTE, Under,Loss Ratio ROC curves, generated using Ripper also compared. given familyROC curves, ROC convex hull (Provost & Fawcett, 2001) generated. ROCconvex hull generated using Grahams algorithm (ORourke, 1998). reference,show ROC curve would obtained using minority over-sampling replicationFigure 19.point ROC curve result either classier (C4.5 Ripper) learnedparticular combination under-sampling SMOTE, classier (C4.5 Ripper)learned plain under-sampling, classier (Ripper) learned using loss ratioclassier (Naive Bayes) learned dierent prior minority class. pointrepresents average (%TP %FP) 10-fold cross-validation result. lower leftmostpoint given ROC curve raw dataset, without majority class under335fiChawla, Bowyer, Hall & KegelmeyerPhoneme ROC Ripper10095%TP9085UnderRipper200 SMOTERipperLoss RatioHull80757001020304050%FP60708090100Figure 8: Phoneme. Comparison SMOTE-Ripper, Under-Ripper, modifying LossRatio Ripper. SMOTE-Ripper dominates Under-Ripper Loss RatioROC space. SMOTE-Ripper classiers lie ROC convex hull.Pima ROC100959085%TP8075UnderC4.5100 SMOTEC4.5Naive BayesHull7065605550102030405060708090100%FPFigure 9: Pima Indians Diabetes. Comparison SMOTE-C4.5, Under-C4.5, NaiveBayes. Naive Bayes dominates SMOTE-C4.5 ROC space.336fiSMOTEPima ROC Ripper100959085%TP80UnderRipper100 SMOTERipperLoss RatioHull7570656055102030405060708090100%FPFigure 10: Pima Indians Diabetes. Comparison SMOTE-Ripper, Under-Ripper,modifying Loss Ratio Ripper. SMOTE-Ripper dominates Under-RipperLoss Ratio ROC space.sampling minority class over-sampling. minority class over-sampled 50%,100%, 200%, 300%, 400%, 500%. majority class under-sampled 10%, 15%,25%, 50%, 75%, 100%, 125%, 150%, 175%, 200%, 300%, 400%, 500%, 600%, 700%, 800%,1000%, 2000%. amount majority class under-sampling minority class oversampling depended dataset size class proportions. instance, considerROC curves Figure 17 mammography dataset. three curves oneplain majority class under-sampling range under-sampling varied5% 2000% dierent intervals, one combination SMOTE majority classunder-sampling, one Naive Bayes one ROC convex hull curve. ROCcurve shown Figure 17 minority class over-sampled 400%. pointSMOTE ROC curves represents combination (synthetic) over-sampling undersampling, amount under-sampling follows range plain under-sampling.better understanding ROC graphs, shown dierent sets ROC curvesone datasets Appendix A.dataset, SMOTE lesser degree datasetsdue structural nature dataset. dataset structuralneighborhood already established mesh geometry, SMOTE lead creatingneighbors surface (and hence interesting), since lookingfeature space physics variables structural information.ROC curves show trend increase amount under-sampling coupledover-sampling, minority classication accuracy increases, course expensemajority class errors. almost ROC curves, SMOTE approach dom337fiChawla, Bowyer, Hall & KegelmeyerSatimage ROC100959085UnderC4.5200 SMOTEC4.5Naive BayesHull%TP8075706560555001020304050%FP60708090100Figure 11: Satimage. Comparison SMOTE-C4.5, Under-C4.5, Naive Bayes.ROC curves Naive Bayes SMOTE-C4.5 show overlap; however,higher TPs points SMOTE-C4.5 lie ROC convex hull.Satimage ROC Ripper100959085%TP80UnderRipper300 SMOTERipperLoss RatioHull75706560555001020304050%FP60708090100Figure 12: Satimage. Comparison SMOTE-Ripper, Under-Ripper, modifying LossRatio Ripper. SMOTE-Ripper dominates ROC space. ROC convexhull mostly constructed points SMOTE-Ripper.338fiSMOTECovtype ROC100908070%TP60UnderC4.5300 SMOTEC4.5Naive BayesHull504030201001020304050%FP60708090100Figure 13: Forest Cover. Comparison SMOTE-C4.5, Under-C4.5, Naive Bayes.SMOTE-C4.5 Under-C4.5 ROC curves close other. However, points SMOTE-C4.5 ROC curve lie ROC convexhull, thus establishing dominance.inates. Adhering denition ROC convex hull, potentially optimalclassiers ones generated SMOTE.5.3 AUC CalculationArea ROC curve (AUC) calculated using form trapezoid rule.lower leftmost point given ROC curve classiers performance raw data.upper rightmost point always (100%, 100%). curve naturally endpoint, point added. necessary order AUCs comparedrange %FP.AUCs listed Table 5.3 show datasets combined synthetic minority over-sampling majority over-sampling able improve plain majorityunder-sampling C4.5 base classier. Thus, SMOTE approach providesimprovement correct classication data underrepresented class.conclusion holds examination ROC convex hulls. entriesmissing table, SMOTE applied amounts datasets.amount SMOTE less less skewed datasets. Also, included AUCsRipper/Naive Bayes. ROC convex hull identies SMOTE classiers potentially optimal compared plain under-sampling treatments misclassicationcosts, generally. Exceptions follows: Pima dataset, Naive Bayes dominatesSMOTE-C4.5; Oil dataset, Under-Ripper dominates SMOTE-Ripper.dataset, SMOTE-classifier (classifier = C4.5 Ripper) Under-classifier ROC339fiChawla, Bowyer, Hall & KegelmeyerCovtype ROC RIPPER1009896%TP94UnderRipper100 SMOTERipperLoss RatioHull9290888601020304050%FP60708090100Figure 14: Forest Cover. Comparison SMOTE-Ripper, Under-Ripper, modifyingLoss Ratio Ripper. SMOTE-Ripper shows domination ROC space.points SMOTE-Ripper curve lie ROC convex hull.Oil ROC100908070%TP605040UnderC4.5500 SMOTEC4.5Naive BayesHull302010001020304050%FP60708090100Figure 15: Oil. Comparison SMOTE-C4.5, Under-C4.5, Naive Bayes. Although,SMOTE-C4.5 Under-C4.5 ROC curves intersect points, pointsSMOTE-C4.5 curve lie ROC convex hull.340fiSMOTEOil ROC Ripper1009080%TP70UnderRipper300 SMOTERipperLoss RatioHull6050403001020304050%FP60708090100Figure 16: Oil. Comparison SMOTE-Ripper, Under-Ripper, modifying Loss RatioRipper. Under-Ripper SMOTE-Ripper curves intersect, pointsUnder-Ripper curve lie ROC convex hull.Mammography ROC100908070UnderC4.5400 SMOTEC4.5Naive BayesHull%TP605040302010001020304050%FP60708090100Figure 17: Mammography. Comparison SMOTE-C4.5, Under-C4.5, Naive Bayes.SMOTE-C4.5 Under-C4.5 curves intersect ROC space; however,virtue number points ROC convex hull, SMOTE-C4.5potentially optimal classiers.341fiChawla, Bowyer, Hall & KegelmeyerMammography ROC RIPPER100959085%TP80UnderRipper400 SMOTERipperLoss RatioHull757065605501020304050%FP60708090100Figure 18: Mammography. Comparison SMOTE-Ripper, Under-Ripper, modifyingLoss Ratio Ripper. SMOTE-Ripper dominates ROC space TP > 75%.Mammography ROC C4.5100959085%TP807570400 SMOTE400 ReplicateHull6560555001020304050%FP60708090100Figure 19: comparison over-sampling minority class examples SMOTE oversampling minority class examples replication Mammographydataset.342fiSMOTEEstate ROC100908070%TP605040UnderC4.5500 SMOTEC4.5Naive BayesHull302010001020304050%FP60708090100Figure 20: E-state. (a) Comparison SMOTE-C4.5, Under-C4.5, Naive Bayes.SMOTE-C4.5 Under-C4.5 curves intersect ROC space; however,SMOTE-C4.5 potentially optimal classiers, based numberpoints ROC convex hull.Estate ROC Ripper100908070%TP605040UnderRipper100 SMOTERipperLoss RatioHull302010001020304050%FP60708090100Figure 21: E-state. Comparison SMOTE-Ripper, Under-Ripper, modifying LossRatio Ripper. SMOTE-Ripper potentially optimal classiers, basednumber points ROC convex hull.343fiChawla, Bowyer, Hall & KegelmeyerROC100908070%TP605040UnderC4.5100 SMOTEC4.5Naive BayesHull302010001020304050%FP60708090100Figure 22: Can. Comparison SMOTE-C4.5, Under-C4.5, Naive Bayes. SMOTEC4.5 Under-C4.5 ROC curves overlap ROC space.ROC Ripper100908070%TP605040UnderRipper50 SMOTERipperLoss RatioHull302010001020304050%FP60708090100Figure 23: Can. Comparison SMOTE-Ripper, Under-Ripper, modifying Loss RatioRipper. SMOTE-Ripper Under-Ripper ROC curves overlapROC space.344fiSMOTEDatasetPimaPhonemeSatimageForest CoverOilMammographyE-state7242862289009807852492606811953550SMOTE9560100SMOTE73078644895798328523925067929505200SMOTE300SMOTE400SMOTE500SMOTE8661897998348368926568289505896398498161931167849494897598418339933067889472896098428537930467799470Table 3: AUCs [C4.5 base classier] best highlighted bold.curves overlap ROC space. datasets, SMOTE-classifierpotentially optimal classiers approach.5.4 Additional comparison changing decision thresholdsProvost (2000) suggested simply changing decision threshold alwaysconsidered alternative sophisticated approaches. case C4.5,would mean changing decision threshold leaves decision trees. example,leaf could classify examples minority class even 50% trainingexamples leaf represent majority class. experimented setting decisionthresholds leaves C4.5 decision tree learner 0.5, 0.45, 0.42, 0.4, 0.35, 0.32,0.3, 0.27, 0.25, 0.22, 0.2, 0.17, 0.15, 0.12, 0.1, 0.05, 0.0. experimented Phonemedataset. Figure 24 shows comparison SMOTE under-sampling combinationC4.5 learning tuning bias towards minority class. graph showsSMOTE under-sampling combination ROC curve dominating entirerange values.5.5 Additional comparison one-sided selection SHRINKoil dataset, also followed slightly dierent line experiments obtain resultscomparable (Kubat et al., 1998). alleviate problem imbalanced datasetsauthors proposed (a) one-sided selection under-sampling majority class (Kubat& Matwin, 1997) (b) SHRINK system (Kubat et al., 1998). Table 5.5 containsresults (Kubat et al., 1998). Acc+ accuracy positive (minority) examplesAcc accuracy negative (majority) examples. Figure 25 shows trendAcc+ Acc one combination SMOTE strategy varying degrees undersampling majority class. Y-axis represents accuracy X-axis representspercentage majority class under-sampled. graphs indicate bandunder-sampling 50% 125% results comparable achievedSHRINK better SHRINK cases. Table 5.5 summarizes resultsSMOTE 500% under-sampling combination. also tried combinations SMOTE100-400% varying degrees under-sampling achieved comparable results.345fiChawla, Bowyer, Hall & KegelmeyerPhoneme: ROC comparison SMOTE C4.5 variation decision thresholds10095%TP90SMOTEVarying C4.5 decision thresholdsHull858075102030405060708090100%FPFigure 24: SMOTE Under-sampling combination C4.5 learning tuningbias towards minority classSMOTE Undersampling10090Accuracy80Accuracy majority (negative class)Accuracy minority (positive class)70605040300100200300400500600Percentage undersampling majority class700800Figure 25: SMOTE (500 OU) Under-sampling combination performanceSHRINK approach SMOTE approach directly comparable, though,see dierent data points. SMOTE oers clear improvement one-sided selection.346fiSMOTEMethodSHRINKOne-sided selectionAcc+82.5%76.0%Acc60.9%86.6%Table 4: Cross-validation results (Kubat et al., 1998)Under-sampling %10%15%25%50%75%100%125%150%175%200%300%400%500%600%700%800%Acc+64.7%62.8%64.0%89.5%83.7%78.3%84.2%83.3%85.0%81.7%89.0%95.5%98.0%98.0%96.0%90.7%Acc94.2%91.3%89.1%78.9%73.0%68.7%68.1%57.8%57.8%56.7%55.0%44.2%35.5%40.0%32.8%33.3%Table 5: Cross-validation results SMOTE 500% SMOTE Oil data set.347fiChawla, Bowyer, Hall & Kegelmeyer6. Future Workseveral topics considered line research. Automated adaptiveselection number nearest neighbors would valuable. Dierent strategiescreating synthetic neighbors may able improve performance. Also, selectingnearest neighbors focus examples incorrectly classied may improveperformance. minority class sample could possibly majority class samplenearest neighbor rather minority class sample. crowding likely contributeredrawing decision surfaces favor minority class. additiontopics, following subsections discuss two possible extensions SMOTE,application SMOTE information retrieval.6.1 SMOTE-NCSMOTE approach currently handle data sets nominal features,generalized handle mixed datasets continuous nominal features. callapproach Synthetic Minority Over-sampling TEchnique-Nominal Continuous [SMOTE-NC].tested approach Adult dataset UCI repository. SMOTE-NCalgorithm described below.1. Median computation: Compute median standard deviations continuousfeatures minority class. nominal features dier samplepotential nearest neighbors, median included Euclidean distancecomputation. use median penalize dierence nominal featuresamount related typical dierence continuous feature values.2. Nearest neighbor computation: Compute Euclidean distance featurevector k-nearest neighbors identied (minority class sample)feature vectors (minority class samples) using continuous feature space.every diering nominal feature considered feature vectorpotential nearest-neighbor, include median standard deviations previouslycomputed, Euclidean distance computation. Table 2 demonstrates example.F1 = 1 2 3 B C [Let sample computing nearestneighbors]F2 = 4 6 5 EF3 = 3 5 6 B KSo, Euclidean Distance F2 F1 would be:Eucl = sqrt[(4-1)2 + (6-2)2 + (5-3)2 + Med2 + Med2 ]Med median standard deviations continuous features minority class.median term included twice feature numbers 5: BD 6: CE,dier two feature vectors: F1 F2.Table 6: Example nearest neighbor computation SMOTE-NC.348fiSMOTE3. Populate synthetic sample: continuous features new synthetic minorityclass sample created using approach SMOTE described earlier.nominal feature given value occuring majority k-nearest neighbors.SMOTE-NC experiments reported set SMOTE,except fact examine one dataset only. SMOTE-NC Adult datasetdiers typical result: performs worse plain under-sampling based AUC,shown Figures 26 27. extracted continuous features separate eectSMOTE SMOTE-NC dataset, determine whether odditydue handling nominal features. shown Figure 28, even SMOTEcontinuous features applied Adult dataset, achieve better performanceplain under-sampling. minority class continuous features highvariance, so, synthetic generation minority class samples could overlappingmajority class space, thus leading false positives plain under-sampling.hypothesis also supported decreased AUC measure SMOTE degreesgreater 50%. higher degrees SMOTE lead minority class samplesdataset, thus greater overlap majority class decision space.Adult SMOTENC100959085%TP80UnderC4.550 SMOTENCC4.5Naive BayesHull75706560555001020304050%FP60708090100Figure 26: Adult. Comparison SMOTE-C4.5, Under-C4.5, Naive Bayes. SMOTEC4.5 Under-C4.5 ROC curves overlap ROC space.6.2 SMOTE-NPotentially, SMOTE also extended nominal features SMOTE-Nnearest neighbors computed using modied version Value Dierence Metric (Stanll& Waltz, 1986) proposed Cost Salzberg (1993). Value Dierence Metric (VDM)looks overlap feature values feature vectors. matrix dening distance349fiChawla, Bowyer, Hall & KegelmeyerAdult ROC Ripper1009590%TP8580UnderRipper50 SMOTERipperLoss RatioHull7570656001020304050%FP60708090100Figure 27: Adult. Comparison SMOTE-Ripper, Under-Ripper, modifying Loss Ratio Ripper. SMOTE-Ripper Under-Ripper ROC curves overlapROC space.Adult continuous [C4.5]10090%TP807050 SMOTE60504001020304050%FP60708090100Figure 28: Adult continuous features. overlap SMOTE-C4.5 UnderC4.5 observed scenario well.350fiSMOTEcorresponding feature values feature vectors created. distancetwo corresponding feature values dened follows.(V1 , V2 ) =nC1i|i=1C1C2i k|C2(1)equation, V1 V2 two corresponding feature values. C1 totalnumber occurrences feature value V1 , C1i number occurrences featurevalue V1 class i. similar convention also applied C2i C2 . k constant,usually set 1. equation used compute matrix value dierencesnominal feature given set feature vectors. Equation 1 gives geometric distancexed, nite set values (Cost & Salzberg, 1993). Cost Salzbergs modied VDMomits weight term wfa included computation Stanll Waltz,eect making symmetric. distance two feature vectors given by:(X, ) = wx wyN(xi , yi )r(2)i=1r = 1 yields Manhattan distance, r = 2 yields Euclidean distance (Cost &Salzberg, 1993). wx wy exemplar weights modied VDM. wy = 1new example (feature vector), wx bias towards reliable examples (featurevectors) computed ratio number uses feature vector numbercorrect uses feature vector; thus, accurate feature vectors wx1. SMOTE-N ignore weights equation 2, SMOTE-N usedclassication purposes directly. However, redene weights give weightminority class feature vectors falling closer majority class feature vectors; thus,making minority class features appear away feature vectorconsideration. Since, interested forming broader accurate regionsminority class, weights might used avoid populating along neighbors fallcloser majority class. generate new minority class feature vectors, createnew set feature values taking majority vote feature vector considerationk nearest neighbors. Table 6.2 shows example creating synthetic feature vector.Let F1 = B C E feature vector considerationlet 2 nearest neighborsF2 = F C G NF3 = H B C Napplication SMOTE-N would create following feature vector:FS = B C NTable 7: Example SMOTE-N351fiChawla, Bowyer, Hall & Kegelmeyer6.3 Application SMOTE Information Retrievalinvestigating application SMOTE information retrieval (IR). IR problems come plethora features potentially many categories. SMOTE wouldapplied conjunction feature selection algorithm, transforming givendocument web page bag-of-words format.interesting comparison SMOTE would combination Naive BayesOdds ratio. Odds ratio focuses target class, ranks documents accordingrelevance target positive class. SMOTE also focuses target class creatingexamples class.7. Summaryresults show SMOTE approach improve accuracy classiersminority class. SMOTE provides new approach over-sampling. combinationSMOTE under-sampling performs better plain under-sampling. SMOTEtested variety datasets, varying degrees imbalance varying amountsdata training set, thus providing diverse testbed. combination SMOTEunder-sampling also performs better, based domination ROC space, varyingloss ratios Ripper varying class priors Naive Bayes Classier: methodscould directly handle skewed class distribution. SMOTE forces focused learningintroduces bias towards minority class. Pima least skewed datasetNaive Bayes Classier perform better SMOTE-C4.5. Also, Oildataset Under-Ripper perform better SMOTE-Ripper. dataset,SMOTE-classifier Under-classifier ROC curves overlap ROC space.rest datasets SMOTE-classifier performs better Under-classifier, Loss Ratio,Naive Bayes. total 48 experiments performed, SMOTE-classifierperform best 4 experiments.interpretation synthetic minority over-sampling improves performanceminority over-sampling replacement fairly straightforward. Considereect decision regions feature space minority over-sampling donereplication (sampling replacement) versus introduction synthetic examples.replication, decision region results classication decision minorityclass actually become smaller specic minority samples regionreplicated. opposite desired eect. method synthetic over-samplingworks cause classier build larger decision regions contain nearby minorityclass points. reasons may applicable SMOTE performs betterRippers loss ratio Naive Bayes; methods, nonetheless, still learninginformation provided dataset, albeit dierent cost information. SMOTEprovides related minority class samples learn from, thus allowing learner carvebroader decision regions, leading coverage minority class.Acknowledgmentsresearch partially supported United States Department EnergySandia National Laboratories ASCI VIEWS Data Discovery Program, contract number352fiSMOTEDE-AC04-76DO00789. thank Robert Holte providing oil spill dataset usedpaper. also thank Foster Provost clarifying method using Satimagedataset. would also like thank anonymous reviewers various insightfulcomments suggestions.353fiChawla, Bowyer, Hall & KegelmeyerAppendix A. ROC graphs Oil Datasetfollowing gures show dierent sets ROC curves oil dataset. Figure 29 (a)shows ROC curves Oil dataset, included main text; Figure 29(b) showsROC curves without ROC convex hull; Figure 29(c) shows two convex hulls,obtained without SMOTE. ROC convex hull shown dashed lines starsFigure 29(c), computed including Under-C4.5 Naive Bayes familyROC curves. ROC convex hull shown solid line small circles Figure 29(c)computed including 500 SMOTE-C4.5, Under-C4.5, Naive Bayes familyROC curves. ROC convex hull SMOTE dominates ROC convex hull withoutSMOTE, hence SMOTE-C4.5 contributes optimal classiers.Oil9090808070706060%TP10050403020UnderC4.5500 SMOTEC4.5Naive Bayes30201005040UnderC4.5500 SMOTEC4.5Naive BayesHull1001020304050%FP607080900100010203040(a)50%FP60708090(b)Oil ROC Convex Hulls10090807060%TP%TPOil ROC10050Convex Hull SMOTEConvex Hull without SMOTE40302010001020304050%FP60708090100(c)Figure 29: ROC curves Oil Dataset. (a) ROC curves SMOTE-C4.5, UnderC4.5, Naive Bayes, ROC convex hull. (b) ROC curves SMOTEC4.5, Under-C4.5, Naive Bayes. (c) ROC convex hulls withoutSMOTE.354100fiSMOTEReferencesBlake, C., & Merz, C. (1998).UCI Repository Machine Learning Databaseshttp://www.ics.uci.edu/mlearn/MLRepository.html. Department InformationComputer Sciences, University California, Irvine.Bradley, A. P. (1997). Use Area ROC Curve EvaluationMachine Learning Algorithms. Pattern Recognition, 30(6), 11451159.Chawla, N., Bowyer, K., Hall, L., & Kegelmeyer, P. (2000). SMOTE: Synthetic MinorityOver-sampling TEchnique. International Conference Knowledge Based Computer Systems, pp. 4657. National Center Software Technology, Mumbai, India,Allied Press.Chawla, N., & Hall, L. (1999). Modifying MUSTAFA capture salient data. Tech. rep.ISL-99-01, University South Florida, Computer Science Eng. Dept.Cohen, W. (1995a). Learning Classify English Text ILP Methods. Proceedings 5th International Workshop Inductive Logic Programming, pp. 324.Department Computer Science, Katholieke Universiteit Leuven.Cohen, W. W. (1995b). Fast Eective Rule Induction. Proc. 12th International Conference Machine Learning, pp. 115123 Lake Tahoe, CA. Morgan Kaufmann.Cohen, W. W., & Singer, Y. (1996). Context-sensitive Learning Methods Text Categorization. Frei, H.-P., Harman, D., Schauble, P., & Wilkinson, R. (Eds.), ProceedingsSIGIR-96, 19th ACM International Conference Research DevelopmentInformation Retrieval, pp. 307315 Zurich, CH. ACM Press, New York, US.Cost, S., & Salzberg, S. (1993). Weighted Nearest Neighbor Algorithm LearningSymbolic Features. Machine Learning, 10 (1), 5778.DeRouin, E., Brown, J., Fausett, L., & Schneider, M. (1991). Neural Network TrainingUnequally Represented Classes. Intellligent Engineering Systems ArtificialNeural Networks, pp. 135141 New York. ASME Press.Domingos, P. (1999). Metacost: General Method Making Classiers Cost-sensitive.Proceedings Fifth ACM SIGKDD International Conference KnowledgeDiscovery Data Mining, pp. 155164 San Diego, CA. ACM Press.Drummond, C., & Holte, R. (2000). Explicitly Representing Expected Cost: AlternativeROC Representation. Proceedings Sixth ACM SIGKDD InternationalConference Knowledge Discovery Data Mining, pp. 198207 Boston. ACM.Duda, R., Hart, P., & Stork, D. (2001). Pattern Classification. Wiley-Interscience.Dumais, S., Platt, J., Heckerman, D., & Sahami, M. (1998). Inductive Learning Algorithms Representations Text Categorization. Proceedings SeventhInternational Conference Information Knowledge Management., pp. 148155.355fiChawla, Bowyer, Hall & KegelmeyerEzawa, K., J., Singh, M., & Norton, S., W. (1996). Learning Goal Oriented BayesianNetworks Telecommunications Risk Management. Proceedings International Conference Machine Learning, ICML-96, pp. 139147 Bari, Italy. MorganKauman.Fawcett, T., & Provost, F. (1996). Combining Data Mining Machine Learning Effective User Prole. Proceedings 2nd International Conference KnowledgeDiscovery Data Mining, pp. 813 Portland, OR. AAAI.Ha, T. M., & Bunke, H. (1997). O-line, Handwritten Numeral Recognition PerturbationMethod. Pattern Analysis Machine Intelligence, 19/5, 535539.Hall, L., Mohney, B., & Kier, L. (1991). Electrotopological State: Structure InformationAtomic Level Molecular Graphs. Journal Chemical InformationComputer Science, 31 (76).Japkowicz, N. (2000). Class Imbalance Problem: Signicance Strategies. Proceedings 2000 International Conference Artificial Intelligence (IC-AI2000):Special Track Inductive Learning Las Vegas, Nevada.Kubat, M., Holte, R., & Matwin, S. (1998). Machine Learning Detection OilSpills Satellite Radar Images. Machine Learning, 30, 195215.Kubat, M., & Matwin, S. (1997). Addressing Curse Imbalanced Training Sets: OneSided Selection. Proceedings Fourteenth International Conference MachineLearning, pp. 179186 Nashville, Tennesse. Morgan Kaufmann.Lee, S. (2000). Noisy Replication Skewed Binary Classication. Computational StatisticsData Analysis, 34.Lewis, D., & Catlett, J. (1994). Heterogeneous Uncertainity Sampling Supervised Learning. Proceedings Eleventh International Conference Machine Learning, pp.148156 San Francisco, CA. Morgan Kaufmann.Lewis, D., & Ringuette, M. (1994). Comparison Two Learning Algorithms TextCategorization. Proceedings SDAIR-94, 3rd Annual Symposium DocumentAnalysis Information Retrieval, pp. 8193.Ling, C., & Li, C. (1998). Data Mining Direct Marketing Problems Solutions.Proceedings Fourth International Conference Knowledge Discovery DataMining (KDD-98) New York, NY. AAAI Press.Mladenic, D., & Grobelnik, M. (1999). Feature Selection Unbalanced Class DistributionNaive Bayes. Proceedings 16th International Conference MachineLearning., pp. 258267. Morgan Kaufmann.ORourke, J. (1998). Computational Geometry C. Cambridge University Press, UK.Pazzani, M., Merz, C., Murphy, P., Ali, K., Hume, T., & Brunk, C. (1994). ReducingMisclassication Costs. Proceedings Eleventh International ConferenceMachine Learning San Francisco, CA. Morgan Kaumann.356fiSMOTEProvost, F., & Fawcett, T. (2001). Robust Classication Imprecise Environments. Machine Learning, 42/3, 203231.Provost, F., Fawcett, T., & Kohavi, R. (1998). Case Accuracy EstimationComparing Induction Algorithms. Proceedings Fifteenth InternationalConference Machine Learning, pp. 445453 Madison, WI. Morgan Kaumann.Quinlan, J. (1992). C4.5: Programs Machine Learning. Morgan Kaufmann, San Mateo,CA.Solberg, A., & Solberg, R. (1996). Large-Scale Evaluation Features AutomaticDetection Oil Spills ERS SAR Images. International Geoscience RemoteSensing Symposium, pp. 14841486 Lincoln, NE.Stanll, C., & Waltz, D. (1986). Toward Memory-based Reasoning. CommunicationsACM, 29 (12), 12131228.Swets, J. (1988). Measuring Accuracy Diagnostic Systems. Science, 240, 12851293.Tomek, I. (1976). Two Modications CNN. IEEE Transactions Systems, ManCybernetics, 6, 769772.Turney, P. (1996). Cost Sensitive Bibliography. http://ai.iit.nrc.ca/bibiliographies/costsensitive.html.van Rijsbergen, C., Harper, D., & Porter, M. (1981). Selection Good Search Terms.Information Processing Management, 17, 7791.Woods, K., Doss, C., Bowyer, K., Solka, J., Priebe, C., & Kegelmeyer, P. (1993). Comparative Evaluation Pattern Recognition Techniques Detection MicrocalcicationsMammography. International Journal Pattern Recognition Artificial Intelligence, 7(6), 14171436.357fiff fi!#"$%%$&'%()**+,-. /0$1%23,/.$1%$46587:9;<9=.9>8?A@B9CEDFG?IH8JLKMCG>8CE?GJ ;<J >E7ONP97RQTSPJ#9>8UFEVRW.J ;<J >E7XYJ#C V0>89>8?[Z]\_^85`J.VR9;<J >E7:aPNP97RQT7RQ8JcbcdIe[H[>gfGh8a7:J ;i:j'klmRnRo'pqiRlm:rRstuv'w xu:yGz'{}| z'~'}~''u':~0| w`R'] _}Ylj:m:o_#lk}j:m'#u':yGz'{}| '0| wG 0IR.'}#G#.}.}}'6}Pl s:j'o' Yojp mRG 0IR.'} 8G[G#. }R :'O}6jp}l.mPjo'p#w u''{yGz{}| ' w '0| w#u'w :yE'w{w u''z0| u}'0| z'~'ERG` 0.. E# :# [ IYE I}<}E[}` }}R. 0# } E}8}. }I# [ 88 E}'. R EY } 8}8}[80} 8 E}B.`} [[ 8YEG` G }[ I8 E#} }I}8}8 0}O} R R.I0E}[ G R G#q}0# Rq:} 8 0:[ 0}.}8} #} G8 #I.}P[R .##Gff fi}ff ''ff 'fi'fiff!""#$" !%fifi&(' )*#ff *+ ,% %!"-}-[/. !""fi- ff# fi 0 0 0!1'2fifi&,'!fi!34 q 5'fi ff',--[fffi!6!273+ff} 0!/'`&8$#$`9 " ff":#7,', "'fi ;#$ ,#"fi!2''fi ,*!* #;} 3, fifi<3/ , #4 ,0 'fi 2= ">@?ffffB 3*`9 !C>$Dff*3<E<<3<FHG6} 34IJJKLM,FOGN/34IJJPB & ',fi'fi fffifi#$ [*H> ffE7BRQST$UV"QT$W@X QY@YZ) C'2 -fi"= +!fi ;#$ 0#$8'*'fi ;#$ ff[->$:E<3/[4}$37F1.\ } 3]^^^LG6} 3_<[3FH`0! <3/IJJKB &$%%$Rfi'fib/ R /caI4d: ff-. 4e,;ffi} @g/ffi'#u'Ew u''{fiffYu'wA<I +G_ [,-`_<'<& .(!*8 fi2!,I ff8 2} ,":: ) .-2E7"'"* ,"/&>-Y"W !#,T$%U $& US'4(W &#*) (W #,+ff(T -.#(W &2(T -.#0/7Q2V 1#*) 3W@Y@4Y #,(W &)(T -.#,V"U)5&/W(&.6.7 B] +Mff2!- !-!- ff22E7"'*0] %8. &A9 +Mff2!- !-!. "* ,".%9 %8. &A.: 684#$'2".q! E7"'0'fi ** ,"/&8$0"[#0GR!-)E7"'&' -!"#$- ff!*&[4 ,"[0# /} -!* !<;3 ; =;3%;&: ,N07&P %N0/ ! , ) ,["/! >_44?I` 5fi,,.2`_<'<&?' ff fi}*"!c[ )`_<'<3/.02. fffi[ )-fi'2`_<'.G+%_4)I34.6! "' (AffC "' B%A &8%30!6).% *fi'= ' RBC5 . !68" fi%!,/3!1 ,S+,#*0) } ,W(/& W@T$W@QT$W(3*ff#-fi"#$- 0}! !+<&< , fi "+ "!)'*!6'7&*8_ 3E + Z* + T# V< + }" "*!) !* "-fiF C [4" [0!-./3" ff4"fi'0#$-fi} 0-"/ ff#}ff)`E .@ !&?1 fi,"."#< }!&4G("#< EG#7!0fi'0!-'fi'+ !-* ,fifi'ff#4 "''!2 2fi';# ff?ffA"3fifi#< 34. /40#; &4'.#<0'fi !0,3< 200I 5fi ,#[#4`9 ff'*'&8 " 0<3fi" 0 'fi:-#< 0ff[fi!)0 -ff')fi <47#"!O G %>@.0I}" 00fi!3!"'*!,8 5'fi B 3E fi06.+) ff}2.)GR ff,# !*37Y"'0#-[E #$0} "3GR!fi%>@M,4FHGN/3IJJPLA'<3<A *3'IH03 J3/F ? [3<IJJKLDff*34IJJPL<G6} 37E<<3Dff*37FH?ff'3IJJKB &ffM,"* [ 0# 5'fi[=<37!+2 #;# fi- - _! 5fi 6+!)5'fi[&28. 3!"#,-)fi2 -!fi!Cfi&C8 %` _<'<34#$I5fi 3ffff" - fi} ff#] K $ fi7fi3< .4',')'.,&G."- ,,fiq!-'ff')0#$"# L+,'2fi"(> L)M,[4 B42#$ [+> ffE7B0> J'*F E</3IJJ ML:E] -$&3]^^^LG6} [-$&30IJJKLA<3 G3E<<3 F G6} 30IJJJLG6} 3/]^^^B 3.02 ,'["" /*fifi} --!?ff8fi "0+ 0)*fi -'fi ;#$!)}).)8[*>$A)FN5O*Pfi '# u'}~'w`u''uw #w 'J/3 IJJKL Dff}/30E<<3F L) 3 IJJ MB & L) * 'fi: !30 <L)M,[H ffE#$", "2[ )#$fffi"=+*fi#; fi--/ 3) !%# *. =;16 6fi #"+'<& ' 2#'+ *#;} - ffE(-'(_ 'fi )} #;!C.]!C )>@C-?ffffB 3/'ff2 [[*>@.02)8"ff fffifiB 3*'! 2 . ,>@.02 0!fi<* fi} -,!" B & ',2#,fifi} 2ff fi#$Efi)2fi-fi!+.+*"4 , fi} 3ff!"'4#<"&'EffE*fifi}" / *= `9'. }4 #;',#/ 3.00,[qG,fi&G#$ ' !3/ fi}4fifi+##ffE+- # fi}25=["fi " !) '&*G(* !)#EffE%* 73fi=fiff ff'-"+" 5!*fi"` $3fi'0 <3[5=fi!6> & /&37> ?ffF J/37IJJ ML/R' /3IJJPBB &Mff[fffi ="* ffGR ,!'fi # fi *3+.0+ 2L)M,[("'-.2!<}%.%+fifiC#,% 3ffER* C+fi"= 2 2!<fi ;#$ &ff_/ff!''fi "#fifi<3 "'0#*/,!2"!% )[- -6 %} .% 2!*&R_< " 3 C#$5fi!/ "" ', 2.- 8 -#$ff#;'-!*3$& .& } `0! 0,*"fi5 " } 0 ff-5#;, , 0'fi 'fi&'fi'fi ,fi *'C[!2#$,ffE%2fi"=- -'+#0- [,fi!6 +2"6},.+ )3 _ 5fi'=!*'[",!2#4 ,fifi} -* 85 #4 ,`_<'*!*&4?2) $34IffE%[!)"-# fififi-'fi ;#$>@$& &3 . ,[B 87#$<3 'fi![4#/ff! ''! 5fi!-"/ 3*#<L)M,["'7#4 fifi2 }GR 0}`3/* , 'fi![#4!O- fffi7"fi!)}0 22"'$&+]-''"[#-fi!_" ,-* ff"}&AI9 5fi,.#$[02'" 2fi"="R): '(+! .C R&:6'' 2 +2#6` _<'R!*30.0%P%''+.` _<'(fi"= )*%fi!#; 5'fi[!22,/ &IM" fiEfi4 G'fi ;#$ #` _<', +-fi!34+'"0 0fffifi}fi` _<'Gfi-,>@0[#$4'fi ;#$fi"=B &IM-fi 0 G* ff}!-# ,L)M,[3fi'fi ;#$ #/ -fi!"0 'fi ;#$#/ /.=;'*fi) "0& Hffff ,fi'fi#'- 3/.0)fi'fi !+fifi703 ffE!* -!*fi0 ff'fi ;#$0#4, fi},!*&fiff fi fi!#" $%& ')((#*+-,." (#/ (01) $#&/ (01)/ 1)1) $/ fi / ($# ')*$#3245&#*4" "675(989:fi:;<>=" 8+-fi13?>3896+-fi0fifi/@89ABfiB#CffN5O#Dfi'#u'Ew u''{fiffYu'wASRUserDialoguePolicyTTS_4,] ?Database6fi%#"+ fi}%)!*&(' +} 0-/ ,!* fi'* ,!7 , *, 'fi +)! >@?ffffB &<' ! ,} *- --" 5 " 'fi %>$' ' AB!*&0 cfffi00 fffiO8 6-!fifi})-!>@ .G26 =;#$+_4-]B 37 -fi' !("[ ff fi"fi30#;5=$#$O3-'0'*#$#;H"} =* - ,/ &4', 'fi ,4fi " ff"4 'fi "= >@?ffffB 3 " !<0 fiE! ff 0 4,ff 5 =;=; 'fi 2>$' ' A0B fi&'ff 7#< !1 0W@QY5U 6.# UYW@XZffff''.04 !!+>@YffE)"!3.0+QXT$W@U &)2 } B } *fi0* ff&_/<fifi 3 ff?ff"'.,'fi ;# 3!, 7.,,C fi[D2>@ YQ &.6S*Q 6#"V"*U #Y6)QV"V"Q )B2', ' 2"<ff!'fi #'fi ))"} ff'& 8 )2-!2'fi62 "3*?ff+ -2 6>@!fi!% %) =;}'')'L+"'B*R6_)[#:/'6R +-#$'7& '2 )fi*fi- ff?ff1 &Hff.G"0.0fi !'fi 4#/'#;} ""fi!6'<3 +# .0% -! %!+ ?ff#;} "&2':<,!'fi#4'37#4.0*. " , !* )` 5fi 3<ff. "+(W &/W@T$W@QT$(W 3*#" ff!2.( ff[!3.00!!-fi2fifi2-!2'fi ='+ '">@#$* # 2-,+,#*)"B0 -!" ',> + *Z + #VB &'+!'fi #-."P.! %'X U &,$) V"(W &.60''# , &4? #$0fifi2 ff?ff("3-*ff0#$4[ff#7,>#$43G.E7"'B 3! "ff''*.0ffq:< -'fiC.+ - &-? #$ff, fi%,I"_4,I3#$05fi 3` _<'"4''0.045fi!X U &,$) V(ff''/3<20A])9&` _<'*-fiY!,.) -34,.0+,[8 5fi!:< , - ff.ff*:: +4.&4G(. "fi4 0:<,'' !ff#$"#/?ff:/'34 _!2#$ .13 fi'fi ff'::"0# C.D2BC..+'!6'-'"_fi!6#$ ff 2>#$037''fi+.00'"`9 !"fi#5B 3-"4''fi -,4[#4!&N5Ofi '# u'}~'w`u''uw #w '?0ff.''%' .,3<) `_<')!*3<. "': % !2GRff#$ .02. ,. 22Y4# Q)5&).0 0 }" !O"#$ [ 5fifi&1A"!3,. 2': 1 !CGR*+R.0R. 2. R).0ffY:< ?ff='fi% ,37IffY:<*& $ G_ff* fi2'ff#0#:<*"!O'->@G6} ffFHG(} 3IJJ^L/M,FOGN/34IJJPL 0 ,FL0!3IJJK3IJJJL<A"<3IJJKL<G6} G,$&34IJJKB &0?0,-fi ` 5fi 37[!6!"" [:< #;!#36#,''!32-fi':/'ff!10''ff &', G. =''q.000"fi`3.0-fi!*.0!. 0.-"3*"fifi. !3 ,fi0#`0* ,.# fi/ &Rfi :..R 08 }8 R*<30. )''6 + } *[ !C. +fifi)%fifi!ffE 6*="fi!)'<& 82 [ 50<3/. ff.4''"2',*#!-* "[` _<'*!*&fiff8ff'<0fifi!IffE" 'ff#fi!37. !ff ' ::+ T$QT# 1Q+,#5fi*#$0&EJ!2,. "fi!6[ 2 ,4ff"0##$0 ,#; 0ff0#$ '2.0ff}* "! + }5G22,"=`!` ) ff & HI,0fi} 5=0"#$ff ,,-fi0 !O*# ["37.0).'* -)-#; 37 -,6!) ?ff"3<-"'73E:/'0 -!" ?ff"3-'fi fi!"&48 -fi}3. [ ) fi 00 ,ff"20fifi- 0!* ,ff#0#4#.0*#$!-#$0-)'&G_,.1 ,'2# 2fififi, ff fi} ,Q <YW@X QT$W@U & # #*&#*&/T 3<) #$")! '&ffN0#$ 0 # 3 0!H'--"#7 fffi}3 %fififi},2 }"_} 2 &G_' ::* W@QYU56S.# UYW@XZ,)'-fifi-#; , 0# + T$QT #,+"* , , fi} ,- 0# QXT$W@U &+&_/[, 3fi'fi "}62 } -!6'*>#$ff3) * "6 - , 37!" 0/ .0-/#$</B &_/4 4 31,X -UW@5X # + T$QT #,+34 2!6')"fi +2}+>@%#-:<B &,\} 2fifi*#;Oq5=; ff*-fi,}ff,fi!&'!fi!- !1'-8 ff'}"ff }[} [5=; & Hff.ffE = -fifi} "ff-} E!)4Y # Q )5&/(W &.6<&fiff86fi34**! 8 5fi }6*!. !*"fi"= ,ff'!-}-.*fi, *&' ff!.,'fi ;#$H0 #7fi40<&Aff -" &03 1(fi " ( $/(&#>8-? fi/ &"1)fi$#fi8fiff 0#ff 81)(!# (#- &#" ' $#fi?fiN5Ofi- fi!> '>$/ " fi0&3!>" /fi&/2@,>/ 1)(98$# / / (fi(9896=" 8:fi: Cfffi'#u'Ew u''{fiffYu'w_/0} "ff}<3fffi';#$ 0[ 3 20) #*'4Q) 3# 7& *',fi0 -[)Q)!U 30# X"W + W@U & )UX5#,+5+0>(L)M,[B4.0"'0 *}.0!*&GRfifi} <3 fffi H#fffffi!-/-8 fi, 0fi/fi!#$0}" L)M,[73 !<74 } }0ff5"= 5'fi . 7&'E fi"#< fi<fiE! 6(W 3*#*&- EL)M,['0E `9!-/*'! ""fi"""> J#0FH'3IJJ MLA*fiF J/3IJJKB &2`9 *+fi5-}34 3C . "C3. 22'L)M,[ #; fi )&(_/.%A]*$&ff>IJJJB 34. q%.2"* !2+ ` + fi} -'"C!) -! }fi*fffi $ fifi ff*fifi ffffE.*3' 50 0 A$ ` 5 3 ff!}3/+ .3/ 2 * , G 2& 8*E 5fi'[0!"7" 8=* . &4Mff, 02#;H/ %'2 6fi!- *6fi>B->@'-fi!6#0*)23+ ff -! . ff+6}B 37 ) . *#;'> B">@'* [ 5'fi 6 . )73<* )! . *R(%}B &H_/`5fi 3ff`)#"fi!-fi! G"'#7[3-/#73 4 !. ,34 /34 663'C!+ Y"',#[" ! . ,6 %>$ "G# 5" B &*'66fi*% .#;'`, 2L)M,[%"'<# , fifi0}.- ff!*&48$>$'fi #;!EB fi 0ff'# ff .0-}.ff!*&` 4"'4, 8!:/'ff""'$3fi 0! =H"* !fi,}#;H!fiff 3-fi # !-![&28 + ff.37)/ 2""' # <YU )QT$U ) Z).6 'fi ,2 `2}&8@#4. 8 !-*. 2}#;H[ff 3. G'E 5'fi 0.%0#7ff }"4 &0[ fi 0"4#$. ,. !ff#[5fi!"/ 0, } 0}".! K&G(ff0fifi}. ff.7 } ff2` _<'<300 . ,'85 fiq! #;<*'* ,}. 68}5=; 3)'ff2" ff -<'-. !2",,-* & >$Gfi*2"* ffG5fi-5=; ff.0-fififi})" !+G. )):/5 6!) "!'& EB H0 fifi}"`5fi!/ ,fi&` 537)EL)M,[3< ` 5'fi "* . C>@3QY.S #B *> B #}#;H*'8 )*"#4 =;ff#4"$# !""!%&-+./fi#ff5=3$/ &/ &fi&(#/"#ff -'$/&#fi8# fi(/// (' fi&(# 89($!#??#/ " / /'@-#/ - $?/ (?#"/fi1))fi 3/ " "(($#fi1% fi!#" fi/ (98/ 5/ (fi5!>fi/ ?#" 3/ (1)21) fi&#3" fi8#?#&-/ (' fi1.3 fi!>/ 1)(#" *@&#!98&10&#31))'@((fi ff/ $('ff*,'@((!>fi(#/ " " / 1' / (#' fi&(#3fi*fi3( 3 >fi )fi)!>(# 8 fi*/ (!/ ffN*N5O&#!#*) !&#3 fi!>/ 1)(# $fi-&*fi/ '@// (fifi" fi8-($ &1)&#(/ / (/ "fi133 fi!#" 3" "9fi fi&" "-/ 3fi3fi fi3/ (!/ 3/ " "5?>!#" / (9ff'@(9ff'@(/ " "5 fi!#??#/ " / /'@&#fi)()(/ / (fi '# u'}~'w`u''uw #w 'StateUsersUtterancesDB accessASR/DBRewardUser utteranceslog-likelihoodsemantic tagsDialogue EstimatedPolicyState_49 ?StateEstimator2!. R- L)M,[&4' 2fifiC#, fiCG[.000",' :: 2! 0 fi#'fi*>@?ffAffB7!1 " / ff>@M JB &'fi!2':: ff 3 , 5=':: ff "* 3< 2/ ,}0 . 4 "fi" 0#' ' A*0':: , "*}- &#$.*8+>@G637IJKJLA*FfiJ/3<IJJKB,)*> ! B#> ! B > ! B/ 5 )*> B!>IB+# !.0 >B4#--"' 7 > B4.* . -"' $&E 2^I--2'"#;} , "#ff "+2* - +*.6'.-4-[&G_ #$'- 4#$`_<' fffi!- -.0.4# ff #$4. [0'/3 1I3 #$< . 5fi'[fi 6&-'=;,':: C!)3\%[+'`)*.6*'C+ =;26# * / 3QY.#2W@T #*)QT$W@U &R> J#F '3IJJ MB 3.02!+fi/ 0 [,# *> B 22 8=; R#" -fi4.0" 0fi/0!ffGR 0 4'.R7& HIffff-fi 73 0fi<,fi!6>$}",6"'B,"%!)+ -}+.+ -5" =;28}* &2'7) ` 5" , `L)M,[(-6} -"'#0 *fifi<3/0fi"= )fi!2 )5"= " , . -*#; ST$.) # &G(+2fifi} %2!(fi'fi/30 *#,C fi +-} "[)"*= *#0 - fi} 3)""= )/ * fi!fi "3.0*q+#$2+ "* ++} "'$&*8@#fi -/ *. -::3'= R ""',!+ -**#; 3*% !%'C# )> & /&R?ff3 =;}* fi6?ff:/'3/, !3/ , #/'3 & B & 8. E*" ff*!)- ."'0#4# G*!6q"0 , fi} &0G(" fffifi @+ W@V"SYQT$(W &.62 + -}26]CC/ R>$:E*$&3]^^^L 84'/3 ]^^^B 3-fifi} 6*6.+!CR+ ff` #;!R'2 0 fi}*>$A0$&37IJJJB 3 G. -*_409& J!2*"fi%6fifi52 22 3 )"'#,/ +R+ Cfi7"fi!*#$ ,L)M,[%-"`2'ff !* /7&)+,1) !,,fiffN*N*Nfi'#u'Ew u''{fiffYu'w'2#40fifi'0fi!)/"fffi}[ !-#$6#$["+ 1 SW@Y4*2*! "fi"=',#;= fi-"/ &482[ $3< fifi 2fifi} -*I& ? +fififi. +[ "#$034 )fififi-fi#$") 3 %'R++fi!C -fi} % *6+ #,}&8 2 !- ,!*',!-",}<&]&J)5= )T)QW(&/W(&.6"!H # ` 5fi!"/ , ,>@,34 !)[,#;<} _5=; 03 } +# *},. -.6}*"B &7Ifi0'85fi!34! -/fi' 'ff#;'!&9&,ff- 8fiL)M,[)"' , fi}&4'#)L M,[6.7',"'- fffifi0}2 .#$ ff0!O}&:/& ? fiff fffi7"fi!)}0 IL)M,[&P&Gfi[0 ff!O- ff 2fi!&' 8 50-'ff ,ff#4ff[ !-'* ,`_<'*!*&.fffi.` _<'+2 =;[- fi}+-! "fi' ,.+#$+"2)6`E . !&)`_<'+-6* fifi*fi#$ #$ff fi}!">$E:<3[4}$34\. }3/_<=/3F `0! <37IJJJB 3/.2 fifi#$"/ #$'fi *)>@?ffffB 3 fi}ff''/3 5 ==; 'fi H>$' ' AB 3/ )} 3ffR6[&H` _<'( 2 )G6'fi += 0.2,+'')"'ff2#;c5 =fi , ,>$:E$&3<IJJJL:E2F [4}$34IJJPB 3*"' ' A-!"fi'!->$Afi0F H03IJJPB& Hffff"5 .=;-".26 *L)Mfi6%>$:E-$&3ffIJJJB &%'2` _<'/ ,,fifi )#;O". fi"`2#$2ff ,#$ =.}!"!'fi * 4" [fi3"3303" "3fi33/.3 2= &ff` _<'2'5 ,ff/ "** }!!'fi 3<3< *[ff#4/!+>@.0* [ff,"/3/#$<3B &8 #$!30 )` _<'R6"!2 ) *%!3}-[03 'fi!&` _<'":< 4 0 #$ E+>$ %fi!6 - "3''fi6+ -B &68@#0 `*6*73,` _<'( -#$- +R>$(fi!( +B<&C8@#"` _<'%0%)30` _<'C""%) 5>@ B &)G(` _<'6#;!%-23[:< *3"" 5>@ B &G(-` _<'*::)}-3)0/ ">$-ff.'-#$#} -'2B &_/!-# 0 ,3 ff!-',"fi ,/ 03.0-.',fiffN*Nfi '# u'}~'w`u''uw #w 'NffG` G[fi' !fi'Hfffi'MffMff 0}0A!O88L)5 )8_4: 4MI ::*#8,#$A!O[fi&, &' ff *#`_<'*, #; Iff2I] 0' #$,/ !&-?0 ) -`_<'+,#;!+ ->@*`_<'+ ff#$ffff".B 3 0#$-}2fi#7 0,"""fi 5** <fi '6>@M,FHGN/37IJJPLA'` 0$&3<IJJKB & (?0ffC 37ff[!2#$,)#$ [")*fi"= -=fi!+, ff4fi}0#$E} * "''fi: 78& G4 ff[" 0,8!*#$ff* 22} " [ ,})> & /&3/. "ff."!O*'- ! C/! ,D-2 "4 3<ff2 ""ff# :E$&7>$]^^^BB &7_G ff'0,fi!*3/* *!fi"= " ,`9->@G6} ff$&37IJJKB &8 )` _<'<3/. "2 "}-%IB, *!'fi -#ff2+ *.0C))#$"63]B,.0"_:< 6*227&%'*fi0}-!+!.2" 3< + , 0*}"'"2 ,&,'"}q"` _<'2 ff G. -*_4ffP"M&'ff ff!'fi #4" ff!O 0 ff':: 2*_4:/3 2-"2# ".*# "! fifi>U #*&-0W() # XT$(W 3*#>$Dff*3IJJPBB ! 32 ff!'fi ,#4` _<') /*?ffO> ) #,+ ) W@XT$(W 3*#&/U & ) #,+ ) W@XT$(W 3*# B &'5fi -6_42P) .`_<'% ) 2 -:<".)2 " !'fi ff#&-8@#` _<'+ "2'fi).)Y=3/ff,6S +,#*)"(W &/W@T$W@QT$(W 3*#> & /&37Nff 50B &<'=". !R.R%%fifi3 '+)#" ))"}-6 8 &28@#ff` _<'+% *2fifi,.6)3 !1E+ *Z + #VH(W &/W@T$W@QT$(W 3*#0> & /&3Nff AB& E !6?ffR0 00=! 0fi0[6 2fifi&+8@#,` _<'% -26.%=* 3"6V"W #52W(&/W@T$W@QT$(W 3*#37',. ff ff- } " "*!2 fifi!5#$R> & /&R3 G ?0 /,I L+B &7'=*0"'%)= 20G 5fi!2[-,fifi34. 7#$" GR,& ',0.. #4 ff:/ , . 0`_<'2. !0 0!"#$ ")3<'0 0fiff " G*!)fi', "[#4/!&ff&ff 0)&#!#!>(#/ (&&&fi81' &#(/ (" /&#" $?>3 ($# $/ ((&13?>3'5 -& fi-#ff5= #/ " fi '$##(#/ (0 / (#/ / fi/ fi 2@=" 6 = #/ 83:fi:fiB#<345&#*4" "36 75(98:fi:;fiC8#/ !>fi/ (" / fi/ (/ fi1)1)(#" !#!#" / $/ ( !>($/ " fi0&) 1) 2@,9fi/ ( "@ff 89:fi:fi:Cff;fffiff fi) / -fi&#/ " (# )fi/ (0)'@#-fi/ ?#&fiff" 0fi" / fi)$#fi?fi($&#!#!>-'@'@" " &#!fi& / (?N*N& fffi'#u'Ew u''{fiffYu'w?GNff[fiG_ [ff`_<'<&[4, ! *}5=![4 2! ;}* #$40#}ff8.(&G_ [2` _<'<E& .H!)80fi!8." [fi3"33<"3<"="30fi3 3 .+= & [4 R !HH}!B[#;H0&[4 [" -}!2!'fi 0& 84, <[-[&[4 + !% [)#" )G. %!- !* ff*<&[4 ,,[," ff#$<&[4 /[G[#< G. ff!- !* ff*<&[4 ) ,[2 )C -!-<& 84" 7[ff[&G([,#4 ff/!--!-..Mff!-. "2 ""/3,#$<3*.Nff 5G ?0 /IAG ?0 /I,L?0 ]A?0 ]G ?0 ]AG ?0 ]L?0 .9AG ?0 .9A[ fi '!fi'Nfffi'fi'_4,P 080ff`_<'<&' :< - fi': I[ #}fi)* -fififf+ " <&-'_'fi: " -fififf!'fi+ "#$ q+ fi': " !fi'"#7&4G?0 *', } -* ff [ff , ff'fi *&` _<'` *!- ,}#$# :<"} *3/ .G--_4M&8@#`_<'2 , [ 5fi!)#$!2 *3ff# <YW@XW@TX U&,$) V"QT$W@U&)>& /&3\45fi ?#;]#$ff<3R 5fi: R!+A]-+_42IB &"?0# 5fi:<"!(340! 0<4 73",#;Rfi &_/E5fi 3< fifi0`:<O "[,<CMff)!* !*!*.--,D/37.0, fi} 6!2 'fi+# "[>$"/3/#$<3B &8@#` _<'*,`!:<*fifi3ff&/U-X U &,$) V"QT$W@U &2>@ ,` ?#}B &!2#$0 -fifi ,#)ff'fiC>$fffifi +* "/3.0.-ff"[B 3` _<'!-ff fi"#<0 3*U #*)QT$W@U &+%3*# XT$U )0#4,I :,&]ff} ff.04 !H&N*Nfffi '# u'}~'w`u''uw #w '?G\45fi ? #I[ fi 'RfiMff,!0 !0!ff,ffA.A[ fi0'!fi'Nff` ?#\45fi ?#;]Mff!R !R!(. *RC(=!` ?#\45fi ?# 9=` ? #=Mff!O!B1_4? :<q*2`_<'<&*' :<I + fi': `[#0 *}fi6) *fifi"% - ] <&%' -% 'fi: * )fifi!'fi )% *#$C 'fi: * 2!fi'*#?7&',fifi#$ "`# > =:<B }*Efi!&ffRoj'kfiRpo8jfi:o'0j:m:j'klRmNff ">;NffB?->@?ffB? :/' ? :<[>? B*> ffB'>$' BNffff(> L+B^3II3 ]3 93 :^3I3 ]3 93 :!+>0B^3IG( ff!O * ,G(*,0'*.} -^3I3 ]ff#$ .,3<[*3)2?ff:/'&93 :#$#5fi!:<[73/2:<[G(0'"#$R.( !-[E0,0') }G(q=626.G(ff. ,*!*fiff^3I^3I3 ]^3I_44A 0# 0 * &ff 3 *.0*ff!1E!*fi,"<&4_/.} #9*3:2" } *.0 ff "! ff6 -ff*.00 "37 "!<G:/') ")>@#/B 3< "'0#[-! } + 2 "" *34% -!'fi -# ?ffO,"!2 2 "#$ ,&'#$4 fi} HC!6` _<')#$, *fifi "#0+"fi + *'fi" 34/*) -/ 2 fi!_- !67&'2) - fi} B-! )30= R%_4& Hfi ,#;( 'fi4,0.=;'**&4'0C Nff D#} .0! - ff 4 ff> ff^3! "IB %& C?,D, 'fi:.0*,` _<'-E!*fi""-#$!)>$}! "I3ff]3[93/,.)%:B & C ?:/'?:<[D* fi 0 8:/'` _<'6,#$0+-#$ff+&'^3I36]* fi ,N*Nfi'#u'Ew u''{fiffYu'w. 30"% (2?ffA :/'+ &' ) F9% :C) -.0? C! D)ICD6#$"q :<%<&@C ,D+ } ".0 `_<'ff06"#$*> ff^3<! "IB &2C 'D* } "'0#[,`_<'6, } + - ,, -& C Nff D- } ff !fi'#?ffA,>@ "'B,"ff!) +-22>$^=3ffB &_4!3 C5.! Dff fi .0` _<'0''"02 8,fi0#4 [6>$ ff^3/ "IB & _G ""0 ,#;4'::<3ff0` 5fi 3/.02` _<'20.- ,)->@B 3 "!0,^ff#` _<'E0}!3}! #8:/'* ff3/E').ff"* ,}!&G I00 fi_<3- ff#} fi- 0 fi} ff $3''!*fi!*fi#;7#$-ff,#; &7_/.5fi 3ff # 5fi!- }ff?ffC4/ 44#;3 4,. 0} fi#$ff.6##$4fi& E .3"[% 3 4"2'%* " fi} - "} 8_0, fifi/&'ff ff# C /I"'#7 "E! M]3fifi"# L)M,[+"'/ 44 fi .'fi 0}3"-,/ & % 'fi} .= ,3 ""$3/.} ,'" )* ,ff##G537q:<2'=0 *-?ff:/',*32!.2>@M,F GN/37IJJPLG6} 0$&3<IJJK<LE<<3/G6} 3/F1G37IJJJB &GR- , ff fi} " )}`,fi!2':: 73<.q.('UYW@XZXYQ +5+8 5fi )2E5'fi[3<':: )*'" , 0#'"-fifi0#;,2.02 ,! 0"--fi3/:/5 q&ff', }fifi% fi%` _<'-)fi]! *\8 ? >$\45fi!)#$8+? :<B4G. "_4ffK&_/0}5=; 3.0.I#}&*>$'"}q,)#;} - , "G!)': %0fi4!*%fi3 C *R6'& B) 2 E:]5=;.R]6}q} <3 ) G"'#"'6fi)C*2] K $ & 8fi*.- 8ffE6[}!-''63 <0 fi"2fi ["fifi5!,fi/fi!"4,4:# ffE*fifi-G 5fi!-&'fffi!-_4,Kff2!-.-8ff#!1.0, *! ) ), 2#$,63%!6.6Y*#:<"fffi!"0,0 E 5.0!ff#$&_/.5fi 37 .00 0 !ff ff5> C Nff D, 0,^B 3 0!H80#" 0!1#ff&//fi0&(( $#(' fi1%( $#(fi8-+fiff&!#&/ ( " &$#7fi $( $#fi" & / (#(fi)!#!#fi/ 1)fi"!>" /B#ff/ ((fi8#'@-)fi3/ (#/ / "-$/ " fi0&fi/ " " ( fifiB(B)Bfifi0(#/$/ (0#8-?#&B #ff!/ / ( fffi& fiff -&#/ ()$/ " fi0&fiffN*N5Pfifi / fi $$# #( $1)!#!#/ (031)3/ (#'@1)fi/ (989& fi-$#fi1(fi-/ ( #&(!#" fi890 B& 8>" "5fifi -?> 0/ (#(#/ (0/ B&#ff" ($# fi" !1)(# 8fi-fi'@ fi&# ff&" "B)B!>!#&#" fi $fi(#&"5$#fi?fi(fi $fi -fifi&" ":#ff -$/ & $?> fifi8>3 1.& -/ -!>fi/ (" & 3' !# fi/ &3fi/ ?#& -'@(#"?/ ( $ $&#/ (0 1/ (#"2@fiff 0#ff&"' &&#3$/ " fi0&B3B!>fi/ ?#" )/ (BBB Cfi '# u'}~'w`u''uw #w 'B4/*fiBBB0BBBBBBBBBB.BBBBBBBB.BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB..--BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB.BBBBBB.B_4"K 4\8 ?45/ffBB/ (45/ff- / 8 fffi ff58 +->4(#'8 ff4(#'8 ff4(#'8 ff4(#'8 ff!" 8 5# fi!>4(#'!" 8 5# fi!>4(#'+->/ 8 +->fi ff5 8 +->/ 8 ff$%/ 8 ff$%+-A / 8 fi ff$%&+-A / 8 fi ff$%&4(#'8 '$4(#'8 '$4(#'8 '$4(#'8 5# fi!>4(#'A4(#'8 '$4(#'8 '$!" 8 5# fi!>4(#'A4(#'8 '$!" 8 5# fi!>4(#'A4(#'8 '$!" 8 5# fi!>4(#'A!" 8 5# fi!>4(#'Afi ff$%5 8 +-Aff+-A / 8 +-Aff+-A / 8 fi ff$%&+-A / 8 fi ff$%&4(#'8 5# fi!>4(#'4(#'8 5# fi!>4(#'!" 8 5# fi!>4(#'4(#'8 '(4(#'8 '(4(#'8 5# fi!>4(#'!" 8 5# fi!>4(#'4(#'8 '(4(#'8 '(4(#'8 5# fi!>4(#'!" 8 5# fi!>4(#'4(#'8 '([! ? &4MI ::0#$ 0# ff**_4&fifiIC [4- !+ 6}!_[-ff ! ;}*#$,*"#ff}8ff.& D) ,"fifi2C5 .R!-8 fi*!,D+?00 # 5fi3':<)-ff #$ .0) C,D-# "-I&ff8 ) " 3-! _[:< *-*+#; -?ff"37"} fi"02 )" 0- 8 50&N*NfiDfi'#u'Ew u''{fiffYu'w'7I50fffifi!fi! \8 ? 3`_<'[ )Q&UV"YZ"' ..ff}4#$.0 05=; 0<3 5"=[ 5fi- -""=5=ff/ fi .08ffL)M,[)"' $&4` /0 "=#$}3 fffifi-_4P, <M" '28 0 G#fi}-&[,-0O^-I,^^^^^I"I,]*I,^^^Iff]]*I,^^*I9]*I,^^*I:-^^^^^%?G'G .Nff 5` ?#\45fi ?#;]\45fi ?# 9'RA<I^A]^=^A9^A.:_4"J NG,,*_4I&_4"J,. "fi! ff2_4"K0 ""_4-I&\} 2.Rff , ff 0`_<'20<3/ "}5 220 3fi2 ))_42I3+ . +7&*'"fi-`_<'%.:<-fi"+%+I&C` _<'5 2Nff 5 >$ff G. )+_4-K3Nff A)")fiB 342 ":<,+_42I&? #$0 - , , fi37 5, " fi , ff`_<'68.1 ) -2) }!*.)q:/'37!)2`=" &` _<'% - 2` ?#,}<3+-fi_:< )}!3.00 "fifi4"'7&4'- fi`_<'"E.%.ff"-,>@B 3 4!.):/')>@2. 0).)}!)#$ , :<,B 36 ff -*!)"7& '"[-` _<', -\45fi ?#;]2}<3q:<" ,ff.* ,2` _<')3/* ff0<&'"fi*#4[,0"0 #<3/.02 ff` _<'2 ff:: 7 3.0*fi';#$"" 2}BC R' 4 D(> fi+!+ */ 34fi, 0 , 3< 2- , -fi'" . /B &4` ff2` _<'<3/. *0. !0[^5 fi0 ff"7 3 G. -* ffE*#4_4,J&_4-I^" 0` _<'20.+* \8 ? fi!&` 4_40I0)I^00.2W #*) #*&/T,fi+ -\8 ? fi! &-_/I5fi 34 6` _<'6'+"+ ":<0*_4"K3` _<'5 ,Nff 5(*ff)Nff A-* ff &0 fifi ' 8G_ 5fi'[,#$ff )) +2ff!*&'72)34.fi[ C`_<'6) -\8 ?*fi! "''fififf5+-" "9fi5(#"5'@ fi&# 5/ (&#(#5fi/ ?#&/ (#'@1)fi/ ( 0fi$/ (0!# fi/ &3fi/ ?#& ffN*N-fififf fi8-!>fi/ ( fi(#/ (fi '# u'}~'w`u''uw #w 'A<I +G_ ["*`_<'<&ff[4" !2 2}!q[" ! ;,}*/#$0ff#,8}. &,I ff8.2} ,"ff,,2A 'fi ,0"/&> 1UST <ST %'4US4Y *Y"W !#"T$U-(T -.# U2U -"W + T$U ) W@X + W@T #,+ff(W &I+ T$Q &-U # -W"+ T$U) W@X B] +Mff2!- !-!- ff2*-"= .0] ff` /&A9 68.(0" [fi3/"33<,3" "3/fi33.3< *= &[4 , !-*}!q[0#;H0&%9 ff84.*} ,"0",&0> (UST <ST %%'4US4Y *Y"W !#,T$EU 3"W + W@-"W + T$U ) W@X + W@T #,+BA.: +Mff2!- !-!- ff2*-,*: %8. &P 6[4 ,"[," ff#$<&0P ;S +,#*)%+ Q*Z + &/U(T -(W &.66[4 0 <[04!-<& 84[-, <[[&%M 0,"&ff> UST <ST E-QT -"W + T$U ) W@X B+G([ff#4 ,/!-!..ffA 'fi &ff> &/0U UST <STBK +Mff!-. "* ,"/32 ,#$<3*.0K %L)/&J +Mff2!- !-!. "* ,".0J %8. &A<I^ 8 #$'CII-"+E` . !+ , 'fi )+ -"/&*'":<09& & & G+2!-} "" *,I^ ` /&A<II ' -!#$* ff!*&[4 ,"[ff# /} *!- !;3 ; =;3%;&,II 4J7&_4-I^ ?I 5fi,".*`_<'<&)A<:/&G_" 2 ,ff-6 `fiL)M,[3/ 2 fi 2fi/fffi!-L)M,[R>$4''**E9B &8". ''85'fi['% 6 - %2fi!&68 6 5"+. *fi#;,4 *fi!*.C 4fifi- 3fi ;#$ ,[',. G ,"fi"= &\45'fi[4 ,. "?' FffP' fi! ["+.) -` _<'+fi &'-. *P :2 ,#$ff6%]I"#$,/&)A ". -%)- -fi . ff-#$4'3#\2ff:<3`5'fi =".) fi} 2!"& $ ') 0. "#$[60 '')#[ 5'fi[ff ff`_<')"G"ff'0/* [ 5'fi[3<* 0#. = 2>@ ff?fffi'fi52?ffB &Aff/&#? fi&(#'@ff("/ ($/ fi $fi) 1!>'@1)(N*N$/ $ (fi)$#!>($/ 0(#/(#"(( 'fi'#u'Ew u''{fiffYu'w' )I& 84) +,["L).G-+-!)#$<& -`_<')::)""O"/&' 2]& 84)? fi'2L+!2 +. 0* }"[,#;,+ qq&,` _<'*"::* .0 !fi0&' E9& 842 ,)2A 'fi ,#$!-! 0ff [ 0 *"-&*'7/!)!+"#+&< -`_<'+*::6,.0ff!- ffff"/&' 2:/& 84-# 7!* 2. [,.-* ""/&?ff,!."!-! ff2E7"'*' P&4? #$-/!-#. ?' Fff'R-_4O[4/3!.*},- 5.22 , & "`_<'2"::)#0,fi"-" ._4O[4/&' EM& 84*"! ?!3< 2. - fi'2 "#$Y !,ff.0'#;$&?ffff , !*fiG!_4II 4'&M,C RR (/30(*#;5=$#$T*.`_<'2 fi , ,52fifi)*_4-II&_/ 5fi3/ , 5!) - ff+_42I. ,':2+_42II&-A "_} ) *'fi%!++) fi*. %fi #$[} 6 C>$}2#; 25'fi[.fi B 3 +` _<'-#;H`9 ,fi&? I2#4 ff /3` _<') } -#$# /} ,"#5'fi-> & /&30.:,_4,IB & 'fi" 0fi,:/ *4ff 4 !,, . <3 G. ,"_4,I]&[0 fi4#$+]- " G. <&ff'. ff- ,:<C> 6U*U+ U + U 1Q B0 fi'fi )+I3^37 = I37 'fi!&-_/03 ,6 " 2#[02-P-fiffE<} ff 2(> } /3/_/ 3/F#$73IJJ]B 3.* fi> + )U &.6YZ)*Q 6) #5# + U0V #*'-QT"*Q 6) #5# &#W@(T -.#*)**Q 6) #5# &/U )<W"+ *Q 6) #5# + U0V #*'-Q0W"+ *Q 6) #5# + )U &.6YZW"+ *Q 6) #5# B 3.02 ,fi'fi 2P" )I3 'fi!&?0,6!+Afi6]*# `ffEC[!)''%6937. ":<")Q(W &/(W &.6)6#0 *!*34+ 2\8 ? - fi} 2 %}C-fi+<3 " )Q &UV # <YU )QT$W@U &<& J!+,. -[) ,6!)#$.02. "2 'fi: 6["#!O}3/ ,-!c""!"+ 2. R}.%'#$ fi!&R_G 2fi= ) -#;}*.. '%%*. !) 8 % " !)*%![5fi!2)! . ,!6*)2+ 346'fi "ff#;Rfi*#4 !- " ff!H.')'fi ;#$*&4E`3/,fi 0Y" ffff"fi `,* "!*3/) ,!25GR! 5'fi%"fi --fi2>$ff/%!* -c5fiB 3.0" G5'fi+"3:/5 73/'"fi!&ff&N*Ofi '# u'}~'w`u''uw #w '[4,fi'>@B!# /} *E<&0>6UU*+ Uff + UMff*!` fi , ff - * ff#$*!Y ' C>Z#,+1Q"B&/U"B8-G<30. !-"::2 ,fi}, 084. 7&8-G<38 .(.008# 2 !-E} *fi0* ff&8-G<3`_<'2''2.00847&J *-,!E 5fi'".*-`_<'<3/8 2,`_<'2 !-,::2fi},".028 O. !,#;O,!` fi &_4-I] !&',fi#/ 5fi'[09II. fi0>4fi )< B 3#$.02`_<'- * ff,# * fi5 -}&4'4 "-290 *II4 3fi'!& 8-3 I"'# fi fffi' #$ ff4 [^*I,^^"^^^Nff "IPPNff 5 "IPMI,]^^"^^^?0 ]A ffJ 9?0]]I,]^^"^^*I?0 ]A 9M?0] %:K)/ -" ff - }*[+# 5fi) 62#;!%}26'fi ff &,A"!34 4 , fi} 3) "#;} ff.!+. 6]2}'fi ff 37fi%-/ - fi "fi *&*',fi ' 0 fi/fffi!-ffE-',4#;!2 &4'0:< 0*_4,K3 ff#$!-3. ,"#;!"ff>@.09IIB & HI!-K 4.#<0. ff2 0 )I^"[&'-/ ff. - -8GfiL)M,[&?0. 0ff[73[. # fi"=0!" . ff#;'" "fffi"# `[fi<R3 [lm:jpR 0oklRm437 0 }ff22I"#` _<'" "/5} !2 -ff 'fi: %+ " *'fi<34=.&2A*! [C'*+.+.06# -5+ ff * ,.fi/37". ,fi**! fi"#; ! ,.0,I,4[fi /& JI! C fiDff. ["0>$}!!'fi 3<3 "[#</!B7ff 5} 4'fi: -" ff'fi"""2. 2fi & 8 20. !'3 } 2-". 0!2'6!Iff* ff#48fi 2 /3 ffIff .&4_G 800'::*#4fi) 0 " ff)2!2 "/ 8ff*'fi:E& G 5#4ff . 2[3/ . 4 !'fi 0#[+ ff') ) . 2[3/ ff2* [ 5<&_4!34. fi + fi*fi!6+" L)M,[(=;+> #&I9B &4',}Gff )fi!) ff2#;}$,NNfi'#u'Ew u''{fiffYu'w-_4ffK&4` E8ff. 4:/5 -#$4 / ff>& /&3CI"I:^,^"^,^DB 3[ff =; ". "'#$ -<&"' 3: ).0+2 "fi!37` _<'*7[[ G 0 "!*' .*}2fi&8!3 -fi! ! 4 fi#<0,'".3/ -} " G2["5 *!1,.0*,#$-&` 3. 3 4 'fi: ff} G*["GR4.,> & /&3!(#$ffI34 !"5#$]B &7GR" 'fi 4G:<<3fifi!"ff!:< . ::/'&?0<3.3 fi.0:<6'['' !+GR"} "*> & /&:3:/'*]#$")I3[[". ,#$"]+9B 3%+''fi -# #7 0 0''E:/'*> & /&34*!B &4'0 0#7?ff:/'!fffi!," 4fi",fi4fifi}3 & /&>$`"FHD0!$&3<IJJ MLE<2FH[4 <3/]^^^B &4` _<'* *:: 5=;)- -fifi!6" 6'+Yfi+#0] K $ fi5fi!+fi&J ff":<*ff''*# ff,.ff"fi0#$` _<'<&4_4"I005fi ff,0fi<fi!&,fi.# ]fi 8_/, -+fi3`_<'6.fi[ %+* +>.H' "Bfi!&]I, 0 ff )'fi ;#$[ ) " [,52 ff +/*/3CI] :Y fi ,&-'-fi! fiff# -fifi 6[!3# 3 q 5* C:+#, 2fi[C )!fi"= )[->$!- [fiB#;H ff" fifi&8 -#;} 3[fi2 [2! [lm:jpR 0oklRm+3#; P] H-2M:H-/&'0#$.0 ff'-" ,!#43. 77 2 &RfiffRjp}lm:r_k}s:o_.ojp m:o'n:l}]kk}s:offpjlmRlm:r:l}')I= ") ")fi';#$ #0`_<'<3#$ff[ =6[q& G "+ <9II+3` _<'% C"_!fi0ff\8 ? fi`! &8 "I] :ff"3` _<'* -fffi!&-?0 ) %fi!+. fffi"= +#$0!) *"[[lm:jpR 0oklRm437!*!'fi 0#[ff"'+ 2` ""!"> & /&3/ *37!R3 `9!34!R>@M,FOGN/3IJJPL7Dff$&3<IJJKBB &7_G 0 , ff'fi ;#$0# ff 2fi!*.- 'fiff4 . *[" 2"'#4 fi. 2[. fffi"= , ff !H#$ &[ fi,,",fi "= 66 ":<,.). ff#0' +I&08 - 0:< .,3. 0= ,'fi ;#$#$ [lm:jpR 0oklRm6. -[36) fi)<&'-,#" . +[+} ff9II,ff +* " "= +*!O. 0^ ^ :K2>$ 4 "ffI0-IB 3.0ff 0ff#7[0[ff} 4 "I] :,0"6 ff! . ff^ ] :/37 2fi[ff ,,2fi =;-# ^ ^PJ+- /Nfi '# u'}~'w`u''uw #w 'jfi:j'klRmO6ojfiRpoJ! ? fiG_ ? fipjlm^ ^ :K]] :K^ IK9 9K99 :]] K^ ] :] IK9 P]9 M:]]jfi:o^ ^PJ^ ^]J^^ 9K^ :]^ JK^^ PK^ PP^ .:^ IJ^ ^^ ^I^ ^^^ IP]^ II9 9J^ ]]M?ffAG_# /}\!G( !` _<'2''G#o'k'-I '2 ff fffi';#$ "#$+[ &,' ":<Gfi 2GR -[' H>@* 5"#$,'B L 2 =2ff " ,"# "[")2 "*/ L/ ,+" - "-6+ ,/ L "#$+ ."GR '. 2 , ff"2 "2->$-fi`"'- C..D/3.0)_Y"'- C DB L :#$Cfi7: ",)- ff /* =; &.=; fi" =; 0 0 ,[ & * ', 8 fi,* )fi [0#;-P]c fi)""- ,*,-EM:c fi)""-&',).(#' -I, . 0fi';#$"fi#;--#$ff ` !% %[`PojR 0oklRm KY& PojR 0oklRmC-25ff# Efiff 74fi}*#<4.R7.'3 0,0 #7 G E"'#4& H0 .3/00.02> & /&3 ff !0C E7"',D* ff!0CL)G. .DB 30= I&'0",#$" :: *[.=#$,'". ..", / #fi "0 3.0=2 . %[, *#$6'C. "fi 3fi'fiCC) " #0-""#$"-#0 2 . 7&%'*6 2#,. fiR. )I ]R>@.02 +)ffI) 9B 3 .0+,2 ". "] IK&*' ". *-*-fi[3"[-:ff -^ ^]J $&*_G ff -fi!66!)fi"=)L)M,[R#$`! fi6>@.0*.fi [2* ff !B 3* ,fi!22!fi"=- ffEL)M,[+#$. [fi6>@.0-. Efi [/B . 0!"3/.*!- !*"GR 02}`&2#ff4( fi(#/ (" " fi89)!#* " &( ffB)#ff5=!/ 11!#fi//(/ $# $.fffi' " ( ff B 3// ($/fi#/ )/fi1!#" / (fi/ fi(/ $# $?>fi/ /" " / 0(#/'5)fi/ / "5($>ff-/ (fi/ 8>(0fi 5'@5 fi">$/ >(# " &fi/ ((#"" $# $1) fi&# #/Nfi1!#" / (/ (/ (0"&#" $1(# 81fi8>?#& fi1#/ " 3!#* " & "fi)$# / 0( $/ ( $!>'@1)(" 3 fi?> ()& $)fi5&#5 $1) fi&#fifffi'#u'Ew u''{fiffYu'w' )[ 2C 2(.,3qi2342%#[lm:jp0oklRm4&R. 3*#R" , 3qiB!&8-fi3Hfifi54 fi'}} !ff#$ / )!3. fi -!qi*I#$0} [ff *& P #$. !,.'7&' 3#7 ff,.Y0E7"'2 ""/3< 2 ,!ff ,/ ff#$!-2`E .B !** ,"/3 [lm:jp}R 0oklRm = I3PojR 0oklRm "I3qi ff]&6' 6I- . " " 2-2#0?ff%#; ] :K*/-*] ,/*)>@.0, "ff,^"E9B 3/":fffi[>^ ^ :B &"?0<37"fi [ff) ) %fi!% +#$0. Efi"= 2#$qi2&'" ['+-#;0 *.U 1 ,# XT$(W 3*#- . )[3<) "- . )"fi!6':: %"#;'+# ! 2)*34_+'fi 2!-#;H0/&4_G 8O. 5"".('fi ;#$8#;H- ff.0)- 0%# +1 ,# XT$(W 3*#ff!+[->$fi'+!2) #$.}-B'7#& G< } -, ". } fi)! ff.!)+_4)I]&-'-[`Pofiffoo'nRj}%"+#; ":<+-!(>$ 2 *ffI*CIB &C'2[Ej#3 s:j'k k j3 ff fi0mfi0mRnRo'p}k Rn(fiRo6+#; -,#$2>$ **I*PB &0A. "_fffi"= ,#$0!2# ,-[3/. "_+Q ) W@U ) W5'fi,#$fffi [,ff'/<&2'-ff:/*. ff#0' +I . ,.#;} ",::R !6!%:`6 )[6%#$ff[& . 3.*IffV"U 3*#,T$U(T -.#,V"(W Y4#I5GRff#;}-# 0Y5 [!2fi, 5 [q!ff0" !*! -) ,!*&4_4*I 93.0* . 8ff#4 ff0#$ * ff* 2 !"#$ ,,[3 .fi"=" 4!(#$fi-[3. 1,!#$ -.. !0#;1#< 00[3. 4[&(?0 C. ) q+:<A5fi%#$"2fi[<3`!1>@0"!-'0#$ P""[B. !&8 6 *3[fiff -*'"%fi["% *fi"= Rfi%[3 %)fi["6.=;fi"= 1>$ /B,&8[3 0 6.!*:#$"'#=;fi"= )"[3ff -*"0 ,"[5GR &ffo'}k0o'pklo8 %6) - =;'fi''*fi';#$ ` ,#;+2+fi!"73 *. *) =;'fi''-fi';#$ &)_/I 5fi3. 26: )}5GR 2' . (fi!( >$fi ff& ^IB-.0('fi ;#$(. `R#$ [lm:jpR 0oklRm4&G )'_6 -') 5GR -#5'fi6.C +!%fi).6* q6 )'fi ;#$fi!*` 5'fi ff#$!*. >$DffBff$&3IJJKB &" +fi!ff -&#- fi!>/ 1)(#"9$# / 0('@!>" /fiff($=fi>ff&(/ $'9'@* (" /'-/ #/ (#*0&#!/ (N233C'@fi1!#&($/ (#?> (#*0&#!/ (2>3?> (fi '# u'}~'w`u''uw #w '>$B>$B0.7TrainTest0.45TrainTest0.40.60.350.50.30.40.250.20.30.150.20.10.10>B0.0510011>@/B0.7TrainTest23450.45TrainTest0.40.60.350.50.30.40.250.20.30.150.20.10.10>B0.05123405123450.35TrainTest0.30.250.20.150.10.0501_4I*92345R}0_RG}# 0 #8 RYI '0#} [ }} .Nfi'#u'Ew u''{fiffYu'w_4I,: 8 }5GR -' . % + Rfi!&(' )[ .O 2!fi) #$ ff5- ">@- ,' !*. ,fi /B#$ ,22fi&,', fffi!)'fi ;#$,,'#$ , #$.0) -%fi!R'fi ;#$*-'"+ -:<.2 3fi'" ff 2 0fi!2!2fi"= *#$ 5'fi ff &. * CC5C .]} R 3*2fi+ - 2 fi!R*!fi"= #$0 5fi'&'7I 5fi0!fi3.' *0 fi,.C,D6>@ "I 6]Bff C 5'fi D6>@ 9*= MB0&"G_,#$'+ 0fi!2)*#;} 2- , 2:fffi[[lm:jpR 0oklRm+#$5'fi 34+ Y"',E# fi %"#; :.M /+)FMJ/)C>$fi ff& ^^IB &*8 _3< -. "q=;:' /2#$8>@MM*3 ffPP *34fi ff& 9B &+8 6fi3" G. +6_4),I :/3 * "[. * ,2[#$ ff:<0. 3/ff#$ " #$ & '"fififi,#$0-!O ff, 'fi ,L.+,' [ " 0!0fi!) )Y!" 3 ff!O"G 2'"7&RRjp}l Rmfiffk Yj:mRn`o'lrRm:o'n:l lo'?0 2 ,fi )-#;- 2fi [ #;O*-/37fi"%%2 #,fi*6 2\8 ? *! '2 2',#$ fi*" )fi!& ?1" ff /2,.)'8 =fi- ff !*'0 .=;'2:/5 )fi!& .3 ff- [*R3 0"3<0.00 ',.=;'6fi!+"ff<&CE'` 3`+ 6. ,fi"= R! fi ")!"fi!2"fi!)fi} +!25'fi &?0 *fi [)`"'# .=fi} +fi370#; *3/qfi)! =O.)'"[5=") q5'fi)>$2*#;} 35} !2 ")# 'fi 73fi [= .=; [!,. fiff, fi} B 3,! =fi'", +!)'+fi5!&ff8 )ff2. , .1N*Pfi '# u'}~'w`u''uw #w '-fi';#$ # %fi!6"' ff ) C /D-:/5 6fi3!fi" 0 . ,#$/4GfiL)M,[) E.}-,fi!&'<3/'I} -#7 ,!*"#;70#=,ff+ 2L)M,[3<+ ` 5,+. -fi " +!,# 2L)M,[} !&},-ffff )I)Q&UVc3< !-"*, 4X U&+ W"+ T#*&/T<."fffi!,4fi! fi' "'2L)? -#& J!q0. [ * 04 " cff2 "."-! &7_G E0 . 47 E,* *'q,# " -# &ff:l}'RA! ` :<A! ? :<` :<? :<L)5PffI]pj^^^ K^^ ]^ ] ]^ ^IPI*9rP^ P9:^ ^KP^ ^^^^ M:^ 9]^^ M9ff8jfi:ojfi:o^ ^M^ ^I^ ^I^ 9^^^'"] ? fi)2 /6fi&FE-. fi-ff "fi!6.+/6fi-) 2L) ? 2[ 7&*' ":<I 6fi ,GR *fiq'>@ * 5#$"'B L0 2 ] C ."'#-% 2%/ L 2]C .fi. )2,L< "#$ q. ff6-# -fi!%})*ff L)M,[37+:#$ _6 . , -:%>$fi =;B"# *fi! .'fi 0" , fi!&'*]Y fi , *fi';#$ -# ff % ,!*37+ [lm:jpR0oklRm(. %[3)P*:/5 Cfi-68 " "` "6)!"-3 -. 2C%2!%)! '&'ffA! `:< fi!2. ! !1"#:<"L ffA! ?:<fi!C. !" !):<"L `:< fi!C. !0* G:<"L7 2 ?:< fi!6. !ff " 0*:<"L< 0L)5 +fi!+ff "/2 "&ff_/0ff 2 =? :<Hfi!3 fi!' 4.-ff: 844' .R 0^ ^P0 $3/0GR ff.E ?:<1E:&ff>$` fi!3 :/5 <?:<fi!) #; +'ff2fi2,"0"ff- fi!). , 7& B+' 3+2-fi"=) 0[ ff#fi!, 0'!6" " 5=:: *!fi$3 ff#$ [-fifi} fi';#$"["'.#/2fi&N#Dfi'#u'Ew u''{fiffYu'w[s:oRn.m:o'fffiRp`Pff_4!3. # , .0 7R# . } !, 8<.0 7.fi!*'"#$ '3.0 4 L)M,[6"ff} !-'-"fi fi#4 ff,#}3/ . ,fifi' 2- G *)fi!+q! &0?00[8q'-0ff.,3<. , GR 0#fi 5'fi[ff2.02. ""!*)!6>@'"B,fi,2fi! &-_/G} )6fi!37. 6)[".fiff*'<L)? ["# 5'fi 6>$`! fiB#> 5}!2 .ff#$ ".=fi} BC 5'fi D-fi,)' "]B &'G. 4 "fi-.,,#>#$7 B7" 2L)M,[&8@#< L)M,[. ,'fi ;# ff"'7#4 , 0fififf fi0!O}3 - L)? [".*fi!2',*>!#B0# /3 G*'. -.ff.+'": ->$0## ,''fi ',* "'# fi ffL)? GB 3 , '=$:/4fi"."'fi!fiff>@'fi -I, 2fiff^B 3.0ffff!*_,".*6 6*'[6" Y"',G#",&)? "5 [3#ffL)M,[++2 * "fififi"2!}3 ) ).%'*'7346 -'". 626"ff#0,:/".%'>@'fi *%fi^B,34.+6fi!ff"')[&2'- "= 66' <9** ff. - -"_2 #$[- + - & H0, )I^^^*fi,.738)'. * -. 0fi-) ) [!fiff 0-'6. '.H -^ ^I"#:L4#; " 37:/ 'fi E`9. "I ^0"0! =;fi. ff^3fi!- ff'= _, &##### %######$##}'#}}8 *fffifi'0. ,fi )fi}4[ !-#$ fifi!2#$[0*fffi #fi"="fi!-'-- fi}-ff!"& Hff [ .=!2 } ff-!) ."'ff## 5fi!*3 )! fi fffifi 4fi/fi!.-0 fi} #7'fi fi4#7fi3#7'fi ;#$ =)--#fi ["#!+*#;# fi,fi&*_G[-Iff"#7 0` _<'fi}ff!*3-fi!C'"6fi C'fi ;#$-C` _<'%#$,fi"=<&68 %=q5'fi[0.2 * 0*` _<'<3/. ff: 2:0fi[, . 2[0#$.0* ,fi"=*. 0'fi ;#$[7&4_G " . *.:fi [4#$0 . [0>" ",fi!+. 8fffi"= 6#$0 [B 3[*fi[0#$ff* ff#=[>@'fi- *q,)0B &ff_4!37. , ., )fi!)!2'- [=;'"-\8 ? fiq! 3<+'" + ff:/5 ]-fifi %6 *& Hff '"0fifi*##$ [-.08fi!*fi"= ,ff!<,fi!2!" -,"fi} 0-'5fi *." ff[&Nfi '# u'}~'w`u''uw #w 'C^ffpjCP(I^'09 ?ff ffI^^^KMK9MJ:l lo':p}p^ 9I^ 9J^ P:o^ ^^^ ^^^ ^^jfi:oiR 0o^J P9^PKIImko'p^ ^M^ ^K^ II#L)M,[%}} !&4G_0 +I^^^ff' "fi, "!&4_/##"'*G2}*L)M,[34 %) C+ *[.6-6 *} 2fi!2. 8 fi )-fi/ &'`"',#,ff6.+fi!&2' ":<".#$,I^^^+fi30 * R. #$0fi2 -R"*P=ff37) ,.(#$fffi" ,60-I^`&)'*!C# `fiE-#ff)fi!%."'ff##,&ff'"_+fi ff [ =`9-' . 6 `fi0L)M,[&6'#$ _fi 0 ,7:# 8`9&0'")!fi4 .0 #<'"''!7&_4!34 ,.`fi , 'fi -+fi#; ,':/0' . - ,., #4&G#$ [*0'2fifi)",!"2fi0./3fifi} "GR#;1fi.ff< fi' & J'- *E<*>IJJMB0#$ [0-) -fi[ )!*3/ 2 5fi'[ff#E:q 0$&>$]^^^B<=" " "'$&G6} :$&>IJJK,B /[!ff"7-3""#$ ["."fi [-! .&G6} 04$&/>IJJK:B 5fifffifi#$7#$"fi,"fi} ff!C#$}G< fi& .< 7.! 5fifi!*I 90 43.0`! -0'5fi -." ff[">$ fi 2" :[], 5fi +B &G ff`_ff )fi!2'ff,'ff *-?ff:/''C.% ,# 3R+R+]:<6'"-:: ,+ 6fi"./L4,<34ff Cfi!6* /6fi!))!&,_/E5fi 3. ,. ,fi8 fi 52 2*} =; G6fi!).2 'fi 0".02#$&Hff0!5'fi[""'')2/ ff[,# [" fi} 2=,!"fffi 0- "fi) !*+fifi).# ffER> & /&3/2'fi84#< 65fi,." 05'fi0: ',!*Lfi* " ff fi} "0 4fffi2'}*} ,*/ *= `93/.0-7#$!"#$'=B& .3 #,-'"/ 7&_G ff`0fi'""[!-#$ /* ff ff fi} ,,0= &_< " 34., EL)M,[6"'<'fifi5 =<3. -!)'-/) -fi #'6 ",fi4!6Nfi'#u'Ew u''{fiffYu'wfi ##*fi}ff} 2 &0_/ff.)'+ "[ H%L)M,[C"' <0#$-",fififi->$Dff}` 0$&3<IJJMB &00!3[4<3<' '*>$]^^^B7 # 8! 5fi,.040[ H%L)M,[ =;! fifi},!2L)M,[ =;}'fi ff2 fi} *"!H#$ 3.0, ffff )- fi " ,ff * ff!<&? ,#; *./34. *.66'' % 2#$[C -+ 20[ 3 5fiff ,fi<GR"' . -fi"=#$# 5fi' 0 q3E#< fi} - . ,#$70!"0>@.0""4[ =!"[-"'0B 30 0 0#, * . "#;'+>@G6} .$&3IJJKB 35fi , " ff#" ff#$8=;". &fffi'* , )_< F2#$,#5G7,6fi[6`_<'<3GR\. }3/\4 0E:<3:0'*[4}$3 IL+=qff#$0 '4 fi<3' %#$* `[*R6/#$*#"2fi'fi 3ff(M,L ?03 0A<3/\4 :E2 q0'[4}7#$fi#;0&#ff fi0m`om:o'pj[s:ofi#Yo :o'p}o ff8j}ok ro'RomRnRo'p`o' p}lRklRm` _<'2, 5fi'[ 4 fi}2"!O ff. 0!**} ,/ ff#ff,-`E . !",ff fiG<&84".7'0 } I<`_<'2MffGR& 84 * !",8} "#`9!*! <&4` !.'- 'fi)2-GR ")#` _<'+/q} +fi`$34+ ,`_<'"E*!-0'.2"fiI$&8#$*` _<'*'ff#$'2 } -/&[4,**-' #$Y/& HI%-3!6!) %fifi!+'%.0*!$&'0ff 7,,!&8@#403/ -fi2 Y7 &?0/3/[E7\4?ffA\CM H1%` Hff@' 0A\%?1A[\4?ffDff\.1[ %Hff`0\ &? 0 [)# } 2 /3/!*.'} )- ! CD/3 C=;D/3/2C D+3<2'-fi',# /} -*!0fi[.2`_<'<&0[E7\4?ffA\RM HH`%Hff'@ ?ff`ffN 0[R'0\[ %Hff`0\BJ\4_ HGff\C[.%Hff8$M,8;`ffNH'08;A*_\\4M J? ? D"&/? #$!2 *fi2 "fi3<.<"'0 # .R#4#$!,,. &\4 "#`_<' -' #$ !8fi " , /3<[E7\4?ffA\C_8;`08;H' 0\REff\ 8H" 50 /& HI!+ "::%?ffE7EC# - 3< -.)'*)fifi '!)#$ff!)2fi'#; [&8@#<!" !"fi"/, E 5fi'[3 /Mff04J9*= 9M^*=K9I,:/3 4A'0J 9*= 9M*^ =IP:/&' !#$fifi**E 5fi'[*>N*Ofi '# u'}~'w`u''uw #w '#j]iR}om:jp}l:84C M) 6 !6C` 5fi'[&B84% R62 6-+[3Cfi' )' &? #$!"::q} - 2 fffi' 2!# /} /3/ fi*fi"-::* ff !"#$ /& HI,!- 0::2?ffE7E+# ff 3fifi'" !:: R[&?*ff !*' *I?*ff !*' ]?*ff !*' 29?*ff !*' 0:?*ff !*' P?*ff !*' 2M?*ff-fi'ff::R [J#3M&[&3FC'3/&`,&>IJJMB &#S.)UffffZ&/QV"W@X)U56)QV"V"W(&.6&?:&J'<3<?"&/G1&3/FHE</3<[&L%&4>IJJMB &' 8 fi2#[2 fi' =;fi}"!"&,8) UX5#5#5W(&.6ff+ U T(-.#E5&/T#*)5&/QT$W@U&/QY<ZV U+ W@SV U&FU!#*&ffW@QYU56 S.# 3/fifi<&/J fiff<I^^&ff? = ? $3*/&3F J.G<3,L%&D"&>IJJ B &'}0}5=&8 )UX5#5#5W(&.6+U T(-.#T(- &&/SQY! #5#T$W(&.6ffU T(-.#+5+ UXW@QT$W@U& U)UV <ST$QT$W@U&/QY/ W(&.6 SW" + T$W@X, + 3fifi<&/]M ]fiff] ^&4ffffff?3'"&3FfiJ/3?"&>IJJMB &8;fi0fi';#$ ,*#$[ =/&8) UX5#5#5W(&.6+ %3/fifi<&7I^I fiff<I^]9 &M,$3L%&37FONG/3\ &>IJJPB &L0#$G)ff6- fi},!*&08 )UX5#5#5W(&.6+ffU T(-.# E%%% ) W(&.6E<ZV U+ W@SV U&V <W() W@X QY#(T -*U +,(W &ff"W + X U.S )+,# 5&/T #*) ) #T$QT$W@U &)Q &#*&#*)QT$W@U &/3/fifi<& 9:ff 9J&ffL0!37A<& >IJJKB &-Afi'? fi"' "#0"5 .=;}+>$fi,IB &+,#*) )U*#YW(&.6-Q&+,#*) %Q <T#525&/T#*)QXT$W@U&/34>9*= :B &0 3A<&3FffL0!37A<& >IJJJB &-Afi'? fi"' "#0"5 .=;}+>$fi0]B &+,#*) )U*#YW(&.6-Q&+,#*) %Q <T#525&/T#*)QXT$W@U&/3 >I5=]B &0 3A<&3Fff} /3.L%&3_/ 3/& ? &3F1A#$73_ &G1&<>IJJ]B &<80- 5=fiff&8 5/& T#*)5/& QT$W@U/& QY!U& ,#*) #*&/X5#ffU&<U!#*&</7Q&.6SQ*6#")UX5#,+5+ W(&.6 fi /!3fifi<&IPffIK&ffNNfi'#u'Ew u''{fiffYu'wDff}/3E4&[&3E<<3L%&E4&3F L)3?"&G1&>IJJMB &}G#$[4?% !&U.)5&/QY7U %) T$W $XW@Q5&/T #Y@Y4W 6#*&/X5##,+,# Q)X,-33/]9 fiff]KP&ffDff*3 ? &">IJJPB & );#;} 2#$2%fifi& 8603,M&30F GRfi<30/&>$\4& B 3/UW@X5#UV"V"S.&/W@X QT$W@U& 1#T' #5#*&ffSV"Q&+ffQ& )QX,-W(&#,+ 3fifi<&:]]fiff.::]&`0? 'G,!*[ &(Dff*3 ? &3E<<3M&3FCG6} 3L%& ?"&>IJJKB &_<6G 5fi'* '5GR #/=4,0 5fi'." fi},!"&8)UX5#5#5W(&.6+U (T -.#5&/T#*)5&/QT$W@U&/QYU & ,#*) #*&/5X #ffU &I U !#*&</7Q&.6SQ*6#")UX5#,+5+ W(&.6 fi /! &ffffffE:<37\ &3/F [4}$3R"&>IJJPB & ? 3/ [ 50<&08)UX74U 2U !#*&</7Q&.6SQ*6# <Z*+ T#V +# X,-.&/UYU56Z *U)!*+5-U ffS+ T$W(& # Q+ &&E:<3ff\ &3[4}$3G"&3F \. }3G1&0>$]^^^B &C?)"' 0#, C}})#$,6+&)Q&+ QXT$W@U&+U& #5# X,-)Q& ffS.W@U)U5X #,+5+ (W &.63 37II ff] 9&E:<3\ &3[4}$3#"&37\. }37G1&37_<=/3N"&7M&3FO`0! <37A<&>IJJJB &Afi}ff_< !--fi}& 8)UX7 *U)!*+5-U %U&<ffST$UV"QT$W@X#5# ,X -2# X 5U 6&/W@T$W@U &*Q &&#*)+ T$Q&W(&.6 &E<<3<M&/&3<F [4 <3/A<&4>$]^^^B & [2 +/fi-*fi fi' )2)fi} "!*&<8)UX7/U 0T(-.#%#*3*#*&/T#5#*&/T(-"ffQT$W@U&/QYU& ,#*) #*&/X5# U&2) T$W $XW@QY5&/T #Y@Y4W 6#*&/5X # %% fiff &ffffffE<<3M&./&3[4 <3A<&3F G6} 3.L%&?"&7>IJJKB &7\4G fi,A*,G_=J 2Afi} *Mff,?0 &48)UX5#5#5W(&.6+0U -W() T$Z2<W T(-2&&/SQY #5#T$W(&.6U "T(-.#+5+ UXW@QT$W@U &2U UV <ST$QT$W@U &/Q/4(W &.6S"W + T$W@,X + 3fifi<& K^fiff K &ffffff&E<<3M&./&3G6} 3.L%&?"&3F1DG3.L%&/&7>IJJJB &<?ff'-#4fi fi'$&78)U5X #5#5W(&.6+U 0(T -.#-(W ) T$Z%#*3*#*&/T(-&&/SQY #5#T$W(&.6U ,(T -.# +5+ UXW@QT$W@U &2U UV <ST$QT$W@U &/Q/4(W &.6S"W + T$W@,X + 3fifi<& 9^Jfiff 9*I M&ffffff!`"$3 "8 &3FOD0!$&38"&>IJJMB &"?4 !) +) *!6#'fi *<&48)UX7<U ,T(-.# 5 &/T#*)5&/QT$W@U&/QY<ZV U+ W@SV U&< U!#*&ffW@QYU56S.#3fifi<&IP fiff<*I M^&ff0!3`,&3[4<3./&3Fff' '<3A<&<>$]^^^B &/Afi}[#$&/8)UX5#5#5W(&.6+ffU ,T(-.# T(-E&&/SQY #5#T$W(&.6U "T(-.#+5+ UXW@QT$W@U& U) UV <ST$QT$W@U&/QY/4W(&.6SW"+ T$W@X,+ &ffffff' <3?"&3A *3 /&34' H03\ &3 J 3E4&3F ? [34?"& >IJJKB &+\46#2/C[)#$%! ' fi'C 2?Gff8;A\Ofi &(85&/T #*)QXT$(W 3*#/UW@5X ## ,X -.&/UY5U 6Z U )#4Y # X UV"V".S &/W@X QT$W@U&+% <YW@X QT$W@U&+ ,3/fifi<&JI ffJ M&ff<3A<&3<DG3L%&<A<&37E<<3<M&/&37FHG6} 3L%&/?"&>IJJJB &#$ fi} *,!"&48)UX 7 % &NG#$[fffi '# u'}~'w`u''uw #w 'A"<3}"&G1&>IJJKB &?I8,#/7#$7!"#$!, [ff fi}8/& 5&/T #*)5&/QT$W@U &/QY U.)5&/QYU ffSV"Q & UV <ST #*)<T$.W(#,+ 33 M] fiff M: &ffffAfi3'"&3F 0H3/&>IJJPB &4?I2fifi} - 5 =;=; fi' *!'&82D0<37G1&J0&3F1[4. $ 3/D"&<D"&>$\4& B 3 #5# X,-U*W(&.6Q&2<Z&/T(-.#,+ W"+ 3fifi<&MII ffM99&\4&ffA<3'"&A<&3/FfiJ/3?"&<N"&7>IJJKB & #W(& U)X5#V0#*&/T/# Q)5&/W(&.6&L+8;'([ &'R /3N"&/&>IJJPB &ff'RfiGR-) ).=;"<&UV"V"S.&/W@X QT$W@U&+"U(T -.# )33/PKfiff MK&ffG6} 3*L%& ?"&>$]^^^B & ?I,fifi,#/#$[ff!0*, fi}-,!1#$#$& U.)5&/QY7U %) T$W $XW@QY5&/T#Y@YW46#*&/X5#%#,+,# Q)X,-3 ff39K fi.ff :/*I M&ffG6} 3L%&?"&3_<[ 3./& ? & 3FH`0! <3A<&>IJJKB &E:*fi<" 5=* ffB? !)# - fi})* 0#$G$&*8)UX5#5#5W(&.6+"U T(-.#T(&&/SQY #5#T$(W &.6U "(T -.# 5+ + UXW@QT$W@U&2U UV <ST$QT$W@U&/QY/4W(&.6SW"+ T$W@X,+ /. / 3fifi<&7*I 9:Pfiff<*I 9P]&ffffffG6} 3 L%&?"&3E<<34M&/&3Dff*3 ? &?"&3F ?ff' 3?"& > IJJKB &)\46 fi}, .*[/?G0?0M,8;A\ '.[0&UV <ST#*)% #5# X,-Q&0/7Q&.6SQ*6#3ff4> 9B &G6} 3L%&3Rff".,3H"&34Fc0$3L%&>$]^^IB &*Afi* ,?O-*fi ' &)8)U5X #5#5W(&.6+*U +(T -.#ffU) (T - ff0V #*) W@XQ &#5#T$(W &.6%U +(T -.# +5+ UXW@QT$W@U & U )UV <ST$QT$W@U &/QY/4(W &.6S"W + T$W@,X + &ffffffG6} 3L%&?"&3F G(} 3A<&>IJJ^B &L)5 *"*4?I*-, [<&48)UX7 ffT(-E&&/SQY #5#T$W(&.6U ,T(-.# /43fifi<& ^fiff J&ff84'/3A<&/&@>$]^^^B &,[EL ,6Afi})Mff-A!"&&8 -W@YU+ U -W@X QY) Q& + QXT$W@U&0+ U ,T(-.#0UZQY<UXW(# T$Z#* ) W(#,+ fi3<fifi<&7I*9 KJfiff<I,: ^]&ffffffG63 ? &/&/>IJKJB & )U*#Y + U #YQZ#5 #W(& U)X5#V0#*&/T/# Q)5&/W(&.6&[<& M&3 ? "G!<&NfiJournal Artificial Intelligence Research 16 (2002) 209-257Submitted 5/01; published 4/02Structured Knowledge Representation Image RetrievalEugenio Di SciascioFrancesco M. DoniniMarina Mongiellodisciascio@poliba.itdonini@poliba.itmongiello@poliba.itDipartimento di Elettrotecnica ed Elettronica, Politecnico di BariVia David, 200 70125 BARI ItalyAbstractpropose structured approach problem retrieval images contentpresent description logic devised semantic indexing retrievalimages containing complex objects.approaches do, start low-level features extracted image analysisdetect characterize regions image. However, contrast feature-based approaches, provide syntax describe segmented regions basic objects complexobjects compositions basic ones. introduce companion extensional semantics defining reasoning services, retrieval, classification, subsumption.services used exact approximate matching, using similarity measures.Using logical approach formal specification, implemented complete clientserver image retrieval system, allows user pose queries sketch queriesexample. set experiments carried testbed images assessretrieval capabilities system comparison expert users ranking. Resultspresented adopting well-established measure quality borrowed textual informationretrieval.1. IntroductionImage retrieval problem selecting, repository images, images fulfilling maximum extent criterion specified end user. paper,concentrate content-based image retrieval, criteria express propertiesappearance image itself, i.e., pictorial characteristics.research field till concentrated devising suitable techniquesextracting relevant cues aid image analysis algorithms. Current systems resulteffective specified properties so-called low-level characteristics, colordistribution, texture. example, systems IBMs QBIC1 easily retrieve,among others, stamps containing picture brown horse green field, askedretrieve images stamps brown central area greenish background.Nevertheless, present systems fail treating correctly high-level characteristicsimage as, retrieve stamps galloping horse. First all, systems cannoteven allow user specify queries, lack language expressing highlevel features. Usually, overcome help examples: retrieve images similarone. However, examples quite ambiguous interpret: features1. See e.g., http://wwwqbic.almaden.ibm.com/cgi-bin/stamps-democ2002AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiDi Sciascio, Donini & Mongielloexample appear retrieved images? ambiguity produces lotfalse positives, one experience.Even relevant features pointed example, system cannot tell whetherpointed color distribution, interpretation all, gallopingbrown horse produces color distribution similar running brown foxgalloping white horse. aspect, image retrieval faces problems objectrecognition, central problem robotics artificial vision. effectivesolution overcoming problem associate query significant keywords,match keywords attached way images repository. ambiguitiesimage understanding transferred text understanding, brown portraitCrazy Horse famous Indian chief could considered relevant.Resorting human experts specify expected output retrieval algorithm can,opinion, worsen ambiguities, since makes correctness approachdepend subjective perception image retrieval system do.needed formal, high-level specification image retrieval task. need motivatesresearch report here.1.1 Contributions Paperapproach problem image retrieval knowledge representation perspective,particular, refer framework already successfully applied WoodsSchmolze (1992) conceptual modeling semantic data models databases (Calvanese,Lenzerini, & Nardi, 1998). consider image retrieval knowledge representationproblem, distinguish following aspects:Interface: user given simple visual language specify (by sketch example)geometric composition basic shapes, call description. composite shapedescription intuitively stands set images (all containing given shapesrelative positions); used either query, index relevant classimages, given meaningful name.Syntax semantics: system internal syntax represent usersqueries descriptions, syntax given extensional semantics terms setsretrievable images. contrast existing image retrieval systems, semanticscompositional, sense adding details sketch may restrict setretrievable images. Syntax semantics constitute Semantic Data Model,relative position, orientation size shape component given explicit notation geometric transformation. extensional semantics allows us definehierarchy composite shape descriptions, based set containment interpretations descriptions. Coherently, recognition shape description imagedefined interpretation satisfying description.Algorithms complexity: based semantics, prove subsumptiondescriptions carried terms recognition. devise exactapproximate algorithms composite shapes recognition image, correctrespect semantics. Ideally, computational complexity problem retrievalknown, algorithms also optimal reference computationalcomplexity problems. Presently, solved problem exact retrieval,210fiStructured Knowledge Representation Image Retrievalpropose algorithm approximate retrieval which, although probably non-optimal,correct.Experiments: study complexity problem ongoing, syntax,semantics, sub-optimal algorithms obtained far already sufficient provideformal specification prototype system experimental verification approach.prototype used carry set experiments test database images,allowed us verify effectiveness proposed approach comparisonexpert users ranking.believe knowledge representation approach brings several benefits researchimage retrieval. First all, separates problem finding intuitive semanticsquery languages image retrieval problem implementing correct algorithmgiven semantics. Secondly, problem image retrieval semantically formalized, results techniques Computational Geometry exploited assessingcomputational complexity formalized retrieval problem, devising efficientalgorithms, mostly approximate image retrieval problem. muchspirit finite model theory used study complexity query answering relational databases (Chandra & Harel, 1980). Third, language borrowsobject modeling Computer Graphics hierarchical organization classes images(Foley, van Dam, Feiner, & Hughes, 1996). This, addition interpretation composite shapes one immediately visualize, opens logical approach retrievalimages 3D-objects constructed geometric language (Paquet & Rioux, 1998),still explored. Fourth, logical formalization, although simple, allows extensionsnatural logic, disjunction (OR) components. Although alternativecomponents complex shape difficult shown sketch, could usedspecify moving (i.e., non-rigid) parts composite shape. exemplifieslogical approach shed light extensions syntax suitable for, e.g., video sequenceretrieval.1.2 Outline Paperrest paper organized follows. next section, review related workimage retrieval. Section 3 describe formal language, first syntax,semantics, start proving basic properties. following section, analyzereasoning problems semantic relations among them, devise algorithmssolve them. Section 5 illustrate architecture systempropose examples pointing distinguishing aspects approach. Section 6present set experiments assess retrieval capabilities system. Last sectiondraws conclusions proposes directions future work.2. Related WorkContent-Based Image Retrieval (CBIR) recently become widely investigated researcharea. Several systems approaches proposed; briefly reportsignificant examples categorize three main research directions.211fiDi Sciascio, Donini & Mongiello2.1 Feature-based ApproachesLargest part research CBIR focused low-level features color, texture,shape, extracted using image processing algorithms used characterizeimage feature space subsequent indexing similarity retrieval.way problem retrieving images homogeneous content substitutedproblem retrieving images visually close target one (Hirata & Kato, 1992; Niblaket al., 1993; Picard & Kabir, 1993; Jacobs, Finkelstein, & Salesin, 1995; Flickner et al.,1995; Bach, Fuller, Gupta, Hampapur, Horowitz, Humphrey, Jain, & Shu, 1996; Celentano& Di Sciascio, 1998; Cox, Miller, Minka, & Papathomas, 2000; Gevers & Smeulders, 2000).Among various projects, particularly interesting QBIC system (Niblak et al.,1993; Flickner et al., 1995), often cited ancestor CBIR systems,allows queries performed shape, texture, color, example sketch usingtarget media images shots within videos. system currently embeddedtool commercial product, Ultimedia Manager. Later versions introducedautomated foreground/background segmentation scheme. indexing imagemade principal shape, aid heuristics. evident limitation:images main shape, objects often composed various parts.researchers, rather concentrating main shape, typically assumed located central part picture, proposed index regions images;focus retrieval similar images, similar regions withinimage. Examples idea VisualSeek (Smith & Chang, 1996), NETRA (Ma& Manjunath, 1997) Blobworld (Carson, Thomas, Belongie, Hellerstein, & Malik,1999). problem although systems index regions, lack higherlevel description images. Hence, able describe hence querysingle region time image.order improve retrieval performances, much attention paid recentyears relevance feedback. Relevance feedback mechanism, widely used textualinformation systems, allows improving retrieval effectiveness incorporatinguser query-retrieval loop. Depending initial query system retrieves setdocuments user mark either relevant irrelevant. system, baseduser preferences, refines initial query retrieving new set documentscloser users information need.issue particularly relevant feature-based approaches, one hand, userlacks language express powerful way information need,hand, deciding whether image relevant takes glance. Examples systemsusing relevance feedback include MARS (Rui, Huang, & Mehrotra, 1997), DrawSearch(Di Sciascio & Mongiello, 1999) PicHunter (Cox et al., 2000).2.2 Approaches Based Spatial Constraintstype approach problem image retrieval concentrates finding similarity images terms spatial relations among objects them. Usually emphasisrelative positions objects, considered symbolic images icons,identified single point 2D-space. Information content visual appearance images normally neglected.212fiStructured Knowledge Representation Image RetrievalChang, Shi, Yan (1983) present modeling type images terms2D-strings, strings accounting position icons along one twoplanar dimensions. approach retrieval images basically reverts simpler stringmatching.Gudivada Raghavan (1995) consider objects symbolic image associatedvertexes weighted graph. Edges i.e., lines connecting centroids pairobjects represent spatial relationships among objects associatedweight depending slope. symbolic image represented edge list. Givenedge lists query database image, similarity function computes degreecloseness two lists measure matching two spatial-graphs.similarity measure depends number edges comparisonorientation slope edges two spatial-graphs. algorithm robustrespect scale translation variants sense assigns highest similarityimage scale translation variant query image. extended algorithmincludes also rotational variants original images.recent papers topic include Gudivada (1998) El-KwaeKabuka (1999), basically propose extensions strings approach efficientretrieval subsets icons. Gudivada (1998) defines R-strings, logical representationimage. representation also provides geometry-based approach iconic indexingbased spatial relationships iconic objects image individuatedcentroid coordinates. Translation, rotation scale variant images variants generated arbitrary composition three geometric transformations considered.approach deal object shapes, basic image features,considers sequence names objects. concatenation objectsbased euclidean distance domain objects image starting referencepoint. similarity database query image obtained spatialsimilarity algorithm measures degree similarity query databaseimage comparing similarity R-strings. algorithm recognizes rotation, scale translation variants image also subimages, subsetsdomain objects. constraint limiting practical use approach assumptionimage contain one instance icon object.El-Kwae Kabuka (1999) propose extension spatial-graph approach,includes topological directional constraints. topological extensionobjects obviously useful determining differences imagesmight considered similar directional algorithm considers locationsobjects term centroids. similarity algorithm propose extendsgraph-matching one previously described Gudivada Raghavan (1995). similaritytwo images based three factors: number common objects, directionaltopological spatial constraint objects. similarity measure includesnumber objects, number common objects function determinestopological difference corresponding objects pairs query databaseimage. algorithm retains properties original approach, including invariancescaling, rotation translation also able recognize multiple rotation variants.213fiDi Sciascio, Donini & Mongiello2.3 Logic-based Structured Approachesreference previous work Vision Artificial Intelligence, use structuraldescriptions objects recognition images dated back Minskysframes, work Brooks (1981). idea associate parts object (andgenerally scene) regions image segmented into. hierarchicalorganization knowledge used recognition object first proposedMarr (1982). Reiter Mackworth (1989) proposed formalism reason mapssketched diagrams. approach, possible relative positions lines fixedhighly qualitative (touching, intersecting).Structured descriptions three-dimensional images already present languagesvirtual reality like VRML (Hartman & Wernecke, 1996) hierarchical object modeling. However, semantics languages operational, effort madeautomatically classify objects respect structure appearance.Meghini, Sebastiani, Straccia (2001) proposed formalism integrating DescriptionLogics image text retrieval, Haarslev, Lutz, Moeller (1998) integrateDescription Logics spatial reasoning. extensions approach describedMoeller, Neumann, Wessel (1999). proposals build clean integrationDescription Logics concrete domains Baader Hanschke (1991). However, neitherformalisms used build complex shapes nesting simple shapes.Moreover, proposal Haarslev et al. (1998) based logic spatial relationsnamed RCC8, enough specifying meaningful relations map,qualitative specify relative sizes positions regions complex shape.Also Hacid Rigotti (1999) description logics concrete domainsbasis logical framework image databases aimed reasoning query containment.Unfortunately, proposed formalism cannot consider geometric transformations neitherdetermine specific arrangements shapes.similar approach proposal Ardizzone, Chella, Gaglio (1997),parts complex shape described description logic. However, composition shapes consider positions, hence reasoning cannot take positionsaccount.Relative position parts complex shape expressed constraint relationalcalculus work Bertino Catania (1998). However, reasoning queries(containment emptiness) considered approach. Aiello (2001) proposesmulti-modal logic, provides formalism expressing topological propertiesdefining distance measure among patterns.Spatial relation parts medical tomographic images considered Tagare,Vos, Jaffe, Duncan (1995). There, medical images formed intersectionimage plane object. image plane changes, different parts objectconsidered. Besides, metric arrangements formulated expressing arrangementsterms Voronoi diagram parts. approach limited medical imagedatabases provide geometrical constraints.Compositions parts image considered work Sanfeliu Fu(1983) character recognition. However, recognizing characters, line compositionsclosed, sense one looks specified lines, more. Instead214fiStructured Knowledge Representation Image Retrievalframework, shape F composed three lines, subsumed shape something unacceptable recognizing characters. Apart different task, approachmake use extensional semantics composite shapes, hence reasoningpossible.logic-based multimedia retrieval system proposed Fuhr, Govert, Rolleke(1998); method, based object-oriented logic, supports aggregated objectsoriented towards high-level semantic indexing, neglects low-level featurescharacterize images parts them.field computation theories recognition, mention two approachesresemblance own: Biedermans structural decomposition geometric constraints proposed Ullman, described Edelmann (1999). Unfortunately, neitherappears suitable realistic image retrieval: structural decomposition approachconsider geometric constraints shapes, approach based geometric constraints consider possibility defining structural decompositionshapes, hence reasoning them.Starting reasonable assumption recognition object sceneeased previous knowledge context, work Pirri Finzi (1999),recognition task, interpretation image, takes advantage informationcognitive agent environment, representation datahigh-level formalism.3. Syntax Semanticssection present formalism dealing definition composite shape descriptions, semantics, properties distinguish approach previousones.remark formalism deals image features, like shape, color, texture,independent way features extracted actual images. interestedreader, algorithms used compute image features implementationformalism presented Appendix.3.1 Syntaxmain syntactic objects basic shapes, position shapes, composite shape descriptions, transformations. also take account features typicallydetermine visual appearance image, namely color texture.Basic shapes denoted letter B, edge contour e(B) characterizingthem. assume e(B) described single, closed 2D-curve space whose origincoincides centroid B. Examples basic shapes circle, rectangle,contours e(circle) = , e(rectangle) =, also complete, rough contoure.g., one ship basic shape. make language compositional,consider external contour region. example, region containedanother, , contour outer region external rectangle.possible transformations simple ones present drawing tool:rotation (around centroid shape), scaling translation. globally denote215fiDi Sciascio, Donini & MongielloFigure 1: graphical interface query sketch.rotation-translation-scaling transformation . Recall transformations composed sequences 1 . . . n , form mathematical group.basic building block syntax basic shape component hc, t, , Bi,represents region color c, texture t, edge contour (e(B)). (e(B))denote pointwise transformation whole contour B. example, couldspecify place contour e(B) upper left corner image, scaled 1/2rotated 45 degrees clockwise.Composite shape descriptions conjunctions basic shape components onecolor texture denotedC = hc1 , t1 , 1 , B1 u u hcn , tn , n , Bnexpect end users system actually define composite shapessyntax; internal representation composite shape. systemmaintain user draws help graphic tool complex shapedragging, rotating scaling basic shapes chosen either palette, existingimages (see Figure 1).example, composite shape lighted-candle could definedlighted-candle = hc1 , t1 , 1 , rectanglei u hc2 , t2 , 2 , circlei216fiStructured Knowledge Representation Image Retrieval1 , 2 placing circle flame top candle, textures colors definedaccordingly intuition.remark that, best knowledge, logic present first onecombining shapes explicit transformations one language.previous paper (Di Sciascio, Donini, & Mongiello, 2000) presented formalismincluding nested composite shapes, done hierarchical object modeling (Foley et al.,1996, Ch.7). However, nested composite shapes always flattened composingtransformations. Hence paper focus two levels: basic shapes compositionsbasic shapes. Also, simplify presentation semantics, followingsection present color texture features, take accountSection 4.2 on.3.2 Semanticsconsider extensional semantics, syntactic expressions interpretedsubsets domain. setting, domain interpretation set images ,shapes components interpreted subsets . Hence, also image databasedomain interpretation, complex shape C subset domainimages retrieved database C viewed query.approach quite different previous logical approaches image retrievalview image database set facts, logical assertions, e.g., one basedDescription Logics Meghini et al. (2001). setting, image retrieval amountslogical inference. However, observe usually Domain Closure Assumption (Reiter,1980) made image databases: regions ones seenimages themselves. allows one consider problem image retrieval simplemodel checking check given structure satisfies description2 .Formally, interpretation pair (I, ), set images,mapping shapes components subsets . identify imageset regions {r1 , . . . ,rn } segmented (excluding background, discussend section). region r comes edge contour e(r). imagebelongs interpretation basic shape component h, BiI containsregion whose contour matches (e(B)). formulae,h, BiI = {I | r : e(r) = (e(B))}(1)definition exact recognition shape components images, duepresence strict equality comparison contours; extendedapproximate recognition follows. Recall characteristic function f setfunction whose value either 1 0; fS (x) = 1 x S, fS (x) = 0 otherwise. considercharacteristic function set defined Formula (1). Let image;belongs h, BiI , characteristic function computed value 1, otherwisevalue 0. keep number symbols low, use expression h, BiI also2. Obviously, Domain Closure Assumption regions valid artificial vision, dealing twodimensional images three-dimensional shapes (and scenes), solid shapes surfaceshidden images. outside scope retrieval problem.217fiDi Sciascio, Donini & Mongiellodenote characteristic function (with argument (I) distinguish set).h, Bi (I) =(1 r : e(r) = (e(B))0otherwisereformulate function order make return real number range [0, 1]usual fuzzy logic (Zadeh, 1965). Let sim(, ) similarity measure pairscontours range [0, 1] real numbers (where 1 perfect matching). use sim(, )instead equality compare edge contours. Moreover, existential quantificationreplaced maximum possible regions I. Then, characteristic functionapproximate recognition image basic component, is:h, BiI (I) = max{sim(e(r), (e(B)))}rINote sim depends translations, rotation scaling, since looking regionswhose contour matches e(B), reference position size specified .interpretation basic shapes, instead, includes translation-rotation-scaling invariant recognition, commonly used single-shape Image Retrieval. defineinterpretation basic shapeB = {I | r : e(r) = (e(B))}approximate counterpart functionB (I) = max max{sim(e(r), (e(B)))}rImaximization possible transformations max effectively computedusing similarity measure simss invariant reference translation-rotationscaling (see Section 4.2). Similarity color texture added weighted sumSection 4.2. way, basic shape B used query retrieve imagesB . Therefore, approach generalizes usual approachessingle-shape retrieval, Blobworld (Carson et al., 1999).Composite shape descriptions interpreted sets images contain components composite shape. Components anywhere image, longdescribed arrangement relative other. Let C composite shapedescription h1 , B1 u u hn , Bn i. exact matching, interpretation intersectionsets interpreting component shape:C = {I | : ni=1 h( ), Bi iI }(2)Observe require shape components C transformed image regionsusing transformation . preserves arrangement shape componentsrelative given allowing C include every imagecontaining group regions right arrangement, wholly displaced .clarify formula, consider Figure 2: shape C composed two basic shapesB1 B2 , suitably arranged transformations 1 2 . Supposecontains image I. Then, C exists transformation ,218fiStructured Knowledge Representation Image RetrievalFigure 2: example application Formula (2).globally brings C I, is, 1 brings rectangle B1 rectangle recognizedI, 2 brings circle B2 circle recognized I, arranged accordingC. Note could contain also shapes, included C.formally define recognition shape image.Definition 1 (Recognition) shape description C recognized imageevery interpretation (I, ) , C . interpretation (I, ) satisfiescomposite shape description C exists image C recognizedI. composite shape description satisfiable exists interpretation satisfying it.Observe shape descriptions could unsatisfiable: two components define overlappingregions, image segmented way satisfies components. course,composite shape descriptions built using graphical tool, unsatisfiability easilyavoided, assume descriptions always satisfiable. Anyway, unsatisfiable shapedescriptions could easily detected, syntactic form, since unsatisfiabilityarise overlapping regions (see Proposition 4).Observe also set-based semantics implies intuitive interpretation conjunction u one could easily prove u commutative idempotent.approximate matching, modify definition (2), following fuzzy interpretationu minimum, existential maximum:nC (I) = max {min {h( ), Bi iI (I)}}i=1(3)Observe interpretation composite shape descriptions strictly requires presence components. fact, measure image belongs interpreta219fiDi Sciascio, Donini & Mongiellotion composite shape description C dominated least similar shape component(the one minimum similarity). Hence, basic shape component dissimilarevery region I, brings near 03 also measure C (I). strictthan, e.g., Gudivada & Raghavans (1995) El-Kwae & Kabukas (1999) approaches,non-appearing component decrease similarity value C (I),still threshold.Although requirement may seem strict one, captures way details usedrefine query: dominant shapes used first, and, retrieved set stilllarge, user adds details restrict results. refinement process,happen images match new details, pop enlarging setresults user trying restrict. formalize refinement processfollowing definition.Proposition 1 (Downward refinement) Let C composite shape description,.let refinement C, = C u h 0 , B 0 i. every interpretation I, shapesinterpreted (2), C ; shapes interpreted (3), everyimage holds (I) C (I).Proof. (2), claim follows fact considers intersectioncomponents one C , plus set h( 0 ), B 0 iI . (3), claim analogouslyfollows fact (I) computes minimum superset values considered C (I).property makes language fully compositional. Namely, let C composite shape description; consider meaning C used queryset images potentially retrieved using C. least, meaning perceived end user system. Downward refinement ensures meaningC obtained starting one component, progressively addingcomponents order. remark frameworks cited (Gudivada &Raghavan, 1995; El-Kwae & Kabuka, 1999) property hold. illustrateproblem Figure 3. Starting shape description C, may retrieve (among manyothers) two images I1 , I2 , C (I1 ) C (I2 ) threshold t,another image I3 set C (I3 ) < t. order selective, try adding details, obtain shape description D. Using D, may stillretrieve I2 , discard I1 . However, I3 partially matches new details D.Downward refinement holds, (I3 ) C (I3 ) < t, I3 cannot pop up. contrast,Downward refinement hold (as Gudivada & Raghavans approach)DI (I3 ) > > C (I3 ) matched details raise similarity sum weightedcomponents. case, meaning sketch cannot defined termscomponents.Downward refinement property linking syntax semantics. Thanks extensional semantics, extended even meaningful semantic relation, namely,3. exactly 0, since every shape matches every one low similarity measure. Similarityoften computed inverse distance. Similarity 0 would correspond infinite distance.Nevertheless, recognition algorithm force similarity 0 threshold.220fiStructured Knowledge Representation Image RetrievalFigure 3: Downward refinement: thin arrows denote non-zero similarity approximaterecognition. thick arrow denotes refinement.221fiDi Sciascio, Donini & MongielloFigure 4: example subsumption hierarchy shapes (thick arrows), imagesshapes recognized (thin arrows).subsumption. borrow definition Description Logics (Donini, Lenzerini, Nardi,& Schaerf, 1996), fuzzy extensions (Yen, 1991; Straccia, 2001).Definition 2 (Subsumption) description C subsumes description everyinterpretation I, C . (3) used, C subsumes every interpretationimage , (I) C (I).Subsumption takes account fact description might contain syntactic variantanother, without user system explicitly knowing fact. notionsubsumption extends downward refinement. enables also hierarchy shape descriptions, description another C subsumed C. Cused queries, subsumption hierarchy makes easy detect query containment.Containment used speed retrieval: images retrieved using queryimmediately retrieved also C used query, without recomputing similarities.query containment important standard databases (Ullman, 1988), becomeseven important image retrieval setting, since recognition specific featuresimage computationally demanding.Figure 4 illustrates example subsumption hierarchy basic composite shapes(thick arrows denote subsumption shapes), two images shapesrecognized (thin arrows).Although consider background, could added frameworkspecial basic component hc, t, , backgroundi property region b satisfies222fiStructured Knowledge Representation Image Retrievalbackground simply colors textures match, check edge contours.Also, one background could added; case background regionsoverlap, matching background regions considered regionsbasic shapes recognized subtracted background regions.4. Reasoning Retrievalenvisage several reasoning services carried logic image retrieval:1. shape recognition: Given image shape description D, decide recognized I.2. image retrieval: given database images shape description D, retrieveimages recognized.3. image classification: given image collection descriptions 1 , . . . , Dn , finddescriptions recognized I. practice, classified findingspecific descriptions (with reference subsumption) satisfies. Observeclassification way preprocessing recognition.4. description subsumption (and classification): given (new) description collection descriptions D1 , . . . , Dn , decide whether subsumes (or subsumed by)Di , = 1, . . . , n.services 12 standard image retrieval system, services 34 less obvious,briefly discuss below.process image retrieval quite expensive, systems usually perform off-lineprocessing data, amortizing cost several queries answered on-line.example, document retrieval systems web4 , images text, use spiderscrawl web extract relevant features (e.g., color distributions texturesimages, keywords texts), used classify documents. Then, answeringprocess uses classified, extracted features documents original data.system adapt setting composite shapes, too. system, newimage inserted database immediately segmented classified accordancebasic shapes compose it, composite descriptions satisfies (Service 3). Alsoquery undergoes classification, reference queries already answered(Service 4). basic shapes present, faster system answer newqueries based shapes.formally, given query (shape description) D, exists collection descriptions D1 , . . . , Dn images database already classified referenceD1 , . . . , Dn , may suffice classify reference D1 , . . . , Dn find (mostof) images satisfying D. usual way classification DescriptionLogics amounts semantic indexing help query answering (Nebel, 1990).example, answer query asking images containing arch, system mayclassify arch find subsumes threePortalsGate (see Figure 4). Then, system4. e.g., Altavista, QBIC, NETRA, Blobworld, also Yahoo (for textual documents).223fiDi Sciascio, Donini & Mongielloinclude answer images ancient Roman gates recognized,without recomputing whether images contain arch not.problem computing subsumption descriptions reduced recognitionnext section, algorithm exact recognition given. Then, extendalgorithm realistic approximate recognition, reconsidering color texture.4.1 Exact Reasoning Images Descriptionsstart reformulation (2), suited computational purposes.Theorem 2 (Recognition mapping) Let C = h1 , B1 u u hn , Bn compositeshape description, let image, segmented regions {r 1 , . . . ,rm }. Crecognized iff exists transformation injective mapping j : {1, . . . , n}{1, . . . , m} = 1, . . . , ne(rj(i) ) = (i (e(Bi )))Proof. (2), C recognized iff[In\h( ), Bi iI ] equivalent [i=1n^h( ), Bi iI ]i=1Expanding h( ), Bi iI definition (1) yields[n^r I.e(r) = (i (e(Bi )))]i=1since regions {r1 , . . . ,rm } equivalent[n _^e(rj ) = (i (e(Bi )))]i=1 j=1Making explicit disjunction j conjunctions i, arrange conjunctive formula matrix:(e(r1 ) = (1 (e(B1 ))) e(rm ) = (1 (e(B1 )))) ).........(e(r1 ) = (n (e(Bn ))) e(rm ) = (n (e(Bn )))) )(4)note two properties matrix equalities:1. given transformation, one region among r1 , . . . ,rm equalcomponent. means row, one disjunct true given.2. given transformation, region match one component. meanscolumn, one equality true given .224fiStructured Knowledge Representation Image Retrievalobserve properties imply regions different shapes, sinceequality contours depends translation, rotation, scaling. use equalityrepresent true overlap, equal shape.Properties 12 imply formula true iff injective functionmapping component one region matches with. ease comparisonformulae use symbol j mapping j : {1, . . . , n} {1, . . . , m}. Hence,Formula (4) rewritten claim:[j : {1..n} {1..m}n^e(rj(i) ) = (i (e(Bi )))](5)i=1Hence, even previous section semantics composite shape derivedsemantics components, computing whether image contains composite shapeone focus groups regions, one group rj(1) , . . . , rj(n) possible mapping j.Observe j injective implies n, one would expect. propositionleaves open one j must chosen first. fact, followsshow optimal choice exact recognition mix decisions j .approximate recognition considered, however, exchanging quantifiers harmless.fact, change order approximations made. returnissue next section, discuss one devise algorithms approximaterecognition.Subsumption simple logic shape descriptions relies compositioncontours basic shapes. Intuitively, actually decide subsumed C, checksketch associated seen image would retrieved using Cquery. logical perspective, existentially quantified regions semanticsshape descriptions (1) skolemized prototypical contours. Formal definitionsfollow.Definition 3 (Prototypical image) Let B basic shape. prototypical imageI(B) = {e(B)}. Let C = h1 , B1 u u hn , Bn composite shape description.prototypical image I(C) = {1 (e(B1 )), . . . , n (e(Bn ))}.practice, composite shape description one builds prototypical image applying stated transformations components (and color/texture fillings, present).Recall envisage prototypical image built directly user,help drawing tool, basic shapes colors palette items. systemkeep track transformations corresponding users actions, usebuilding (internal) shape descriptions stored previous syntax. featuremakes proposal different query-by-sketch retrieval systems, preciselysketches also logical meaning. So, properties description/sketchesproved, containment query sketches stated formal way, algorithmscontainment checking proved correct reference semantics.Prototypical images important properties. first satisfy (insense Definition 1) shape description exemplify intuition would suggest.225fiDi Sciascio, Donini & MongielloProposition 3 every composite shape description D, satisfiable interpretation hI, {I(D)}i satisfies D.Proof. Theorem 2, using identical transformation identity mappingj.shape description satisfiable overlapping regions I(D). Sinceobvious specified drawing tool, give following propositionsake completeness.Proposition 4 shape description satisfiable iff prototypical image I(D) containsoverlapping regions.turn subsumption. Observe B1 B2 basic shapes, eitherequivalent (each one subsumes other) neither two subsumes other.adopt segmented regions invariant representation, (e.g. Fourier transformscontour) deciding equivalence basic shapes, recognizing whether basic shapeappears image, call algorithm computing similarity shapes.usual image recognizers allowing tolerance matchingshapes. Therefore, framework extends retrieval shapes made singlecomponent, effective systems already available.consider composite shape descriptions, prove main property prototypical images, namely, fact subsumption shape descriptionsdecided checking subsumer recognized sketch subsumee.Theorem 5 composite shape description C subsumes description Crecognized prototypical image I(D).Proof. Let C = h1 , B1 u u hn , Bn i, let = h1 , A1 u u hm , i. RecallI(D) defined I(D) = {1 (e(A1 )), . . . , (e(Am ))}. ease reading, sketchidea proof Figure 5.If. Suppose C recognized I(D), is, I(D) C every interpretation (I, )I(D) . Then, Theorem 2 exists transformation suitableinjective function j {1, . . . , n} {1, . . . , m}e(rj(k) ) = k (e(Bk ))k = 1, . . . , nSince I(D) prototypical image D, substitute region basicshape comes from:j(k) (e(Aj(k) )) = k (e(Bk ))k = 1, . . . , n(6)suppose recognized image J = {s1 , . . . ,sp }, J . provealso C recognized J. fact, recognized J exists transformationanother injective mapping q {1, . . . , m} {1, . . . , p} selecting J regions{sq(1) , . . . , sq(m) }e(sq(h) ) = h (e(Ah ))226h = 1, . . . ,(7)fiStructured Knowledge Representation Image Retrieval(prototypical image of) Cprototypical image I(D)image JFigure 5: sketch If-proof Theorem 5composing q j is, selecting regions J satisfying componentsused recognize C one obtainse(sq(j(k)) ) = j(k) (e(Aj(k) ))k = 1, . . . , n(8)Then, substituting equals equals (6), one finally getse(sq(j(k)) ) = k (e(Bk ))k = 1, . . . , nproves C recognized J, using transformation components,q(j()) injective mapping {1, . . . , n} {1, . . . , p}. Since J generic image,follows C . Since (I, ) generic too, C subsumes D.if. reverse direction easier: suppose C subsumes D. definition,amounts C every collection images I. every contains I(D),I(D) Proposition 3. Therefore, I(D) C , is, C recognized I(D).property allows us compute subsumption recognition, concentratecomplex shape recognition, using Theorem 2. concern decide whetherexists transformation matching j properties stated Theorem 2.turns exact recognition, quadratic upper bound attainedpossible transformations try.227fiDi Sciascio, Donini & MongielloTheorem 6 Let C = h1 , B1 u u hn , Bn composite shape description, letimage, segmented regions {r1 , . . . ,rm }. Then, m(m 1) exactmatches n basic shapes regions. Moreover, possible matchverified checking matching n pairs contours.Proof. transformation matching exactly basic components regions alsoexact match centroids. Hence concentrate centroids. correspondencecentroid basic component centroid region yields two constraints. rigid motion scaling, hence four degrees freedom (twodegrees translations, one rotation, one uniform scaling). Hence, exactmatch exists centroids basic components centroidsregions, completely determined transformation two centroidsbasic shapes two centroids regions.Fixing pair basic components B1 , B2 , let p1 , p2 denote centroids. Also,let rj(1) , rj(2) regions correspond B1 , B2 , let vj(1) , vj(2) , denotecentroids. one transformation solving point equations (each one mappingpoint another)((1 (p1 )) = vj(1)(2 (p2 )) = vj(2)Hence, m(m 1) transformations. second claim,matching centroids found, one checks edge contours basic componentsregions coincide, i.e., (1 (e(B1 ))) = e(rj(1) ), (2 (e(B2 ))) = e(rj(2) ),k = 3, . . . , n (k (e(Bk )) coincides contour region e(rj(k) ).Recalling Formula (5) proof Theorem 2, means eliminateouter quantifier (5) using computed , conclude C recognized iff:j : {1..n} {1..m}n^e(rj(i) ) = (i (e(Bi )))i=1Observe that, prune search, found above, onecheck k = 3, . . . , n (k (centr(Bk ))) coincides centroid region rj ,checking contours.Based Theorem 6, devise following algorithm:Algorithm Recognize (C,I);input composite shape description C = h1 , B1 u u hn , Bn i,image I, segmented regions r1 , . . . ,rmoutput True C recognized I, False otherwisebegin(1) compute centroids v1 , . . . ,vm r1 , . . . ,rm(2) compute centroids p1 , . . . ,pn components C(3) i, h {1, . . . , m} < hcompute transformation (p1 ) = vi (p2 ) = vh ;228fiStructured Knowledge Representation Image Retrievalevery k {1, . . . , n}(k (e(Bk ))) coincides (for j) region rjreturn Trueendforreturn Falseendcorrectness Recognize (C,I) follows directly Theorems 2 6. Regardingtime complexity, step (1) requires compute centroids segmented regions. Severalmethods computing centroids well known literature (Jahne, Haubecker, &Geibler, 1999). Hence, abstract detail, assume exists functionf (Nh , Nv ) bounds complexity computing one centroid, Nh , Nvhorizontal vertical dimensions (number pixels). report Appendixcompute centroids, concentrate complexity terms n, m, f (N h , Nv ).Theorem 7 Let C = h1 , B1 u u hn , Bn composite shape description, letimage Nh Nv pixels, segmented regions {r1 , . . . ,rm }. Moreover, let f (Nh , Nv )function bounding complexity computing centroid one region. Crecognized time O(m f (Nh , Nv ) + n + m2 n Nh Nv ).Proof. assumptions, Step (1) performed time O(mf (Nh , Nv )). Instead,Step (2) accomplished extracting n translation vectors transformations 1 , . . . ,n components C. Therefore, requires O(n) time. Finally,innermost check Step (3) checking whether transformed basic shape regioncoincide performed O(Nh Nv ), using suitable marking pixelsregion belong to. Hence, obtain claim.Since subsumption two shape descriptions C reduced recognizing C I(D), upper bound holds checking subsumption compositeshape descriptions, simplification also Step (1) accomplished withoutfeature-level image processing.4.2 Approximate Recognitionalgorithm proposed previous section assumes exact recognition. Sincetarget retrieval real images, approximate recognition needed. start reconsidering proof Theorem 2, particular matrix equalities (4). Usingsemantics approximate recognition (3), expanded formula evaluating C (I)becomes following:max minmax{sim(e(r1 ), (1 (e(B1 )))),...max{sim(e(r1 ), (n (e(Bn ))),. . . , sim(e(rm ), (1 (e(B1 ))))) }.........,sim(e(rm ), (n (e(Bn ))))}Properties 12 stated exact recognition reformulated hypothesessim, follows.229fiDi Sciascio, Donini & Mongiello1. given transformation, assume one region among r 1 , . . . ,rmmaximally similar component. assumption justified supposingnegation: two regions maximally similar component,maximal value low one, lowering overall valueexternal minimization. means maximizing row, assumemaximal value given one index among 1, . . . , m.2. given transformation, assume region yield maximal similarityone component. Again, rationale assumption regionyields maximal similarity two components two different rows, valuelow one, propagates along overall minimum. meansminimizing maxima rows, consider different region row.remark also approximate case assumptions imply regionsdifferent shapes, since sim similarity measure 1 true overlap,equal shapes different pose. assumptions state simfunction near plain equality.assumptions imply focus injective mappings {1..n}{1..m} also approximate recognition, yielding formulamaxnmin{sim(e(rj(i) ), (i (e(Bi ))))}maxj:{1..n}{1..m} i=1choices j two maxima independent, hence consider groupsregions first:maxnj:{1..n}{1..m}max min{sim(e(rj(i) ), (i (e(Bi ))))}i=1(9)Differently exact recognition, choice injective mapping j directlylead transformation , since depends similarity transformed shapescomputed, is, choice depends sim.giving definition sim, reconsider image features (color, texture)skipped theoretical part ease presentation semantics. introduce weighted sums similarity measure, weights set user accordingimportance features recognition.Let sim(r, hc, t, , Bi) similarity measure takes region r (with color c(r)texture t(r)) component hc, t, , Bi range [0, 1] real numbers (where 1perfect matching). note color texture similarities depend transformations, hence introduction change Assumptions 12 above. Accordingly,Formula (9) becomesmaxj:{1..n}{1..m}nmax min{sim(rj(i) , hc, t, ( ), Bi i)}i=1(10)formula suggests groups regions image might resemblecomponents, select groups present higher similarity. artificiallyconstructed examples shapes C resemble other, may generateexponential number groups tested. However, assume realistic230fiStructured Knowledge Representation Image Retrievalimages similarity shapes selective enough yield small numberpossible groups try. recall Gudivadas approach (Gudivada, 1998)even stricter assumption made, namely, basic component C appeartwice, region matches one component C. Hence approachextends Gudivadas one, also aspect besides fact consider shape,scale, rotation, color texture component.spite assumptions made, finding algorithm computing bestFormula (10) proved us difficult task. problem continuousspectrum searched, best may unique. observedsingle points matched instead regions componentsproblem simplifies Point Pattern Matching Computational Geometry. However, evenrecent results research area complete, cannot directly appliedproblem. Cardoze Schulman (1998) solve nearly-exact point matchingefficient randomized methods, without scaling. also observe best matchdifficult problem nearly-exact match. Also Chew, Goodrich, Huttenlocher,Kedem, Kleinberg, Kravets (1997) propose method best match shapes,analyze rigid motions without scaling.Therefore, adopt heuristics evaluate formula. First all,decompose sim(r, hc, t, , Bi) sum six weighted contributions.Three contributions independent pose: color, texture shape. values color texture similarity denoted simcolor (c(r), c) simtexture (t(r), t),respectively. Similarity shapes (rotation-translation-scale invariant) denotedsimshape (e(r), e(B)). feature, pair (region, component) computesimilarity measure explained Appendix. Then, assign similaritiesfeature say, color worst similarity group. yields pessimistic estimateFormula (10); however, estimate Downward Refinement property holds (seenext Theorem 8).three contributions depend pose, try evaluate poseregion selected group similar pose specified correspondingcomponent sketch. particular, simscale (e(r), (e(B)) represents similar scaleregion transformed component, simrotation (e(r), (e(B)) denotese(r) (e(B) similarly (or not) rotated reference arrangementcomponents. Finally, simspatial (e(r), (e(B)) denotes measure coincidentcentroids region transformed component.summary, get following form overall similarity regioncomponent:sim(r, hc, t, , Bi) = simspatial (e(r), (e(B)) +simshape (e(r), e(B)) +simcolor (c(r), c) +simrotation (e(r), (e(B)) +simscale (e(r), (e(B)) +simtexture (t(r), t)231fiDi Sciascio, Donini & Mongiellocoefficients , , , , , weight relevance feature overall similaritycomputation. Obviously, impose + + + + + = 1, coefficients greaterequal 0. actual values given coefficients implemented systemreported Table 2 Section 6.difficulties computing best , compute maximumpossible s. Instead, evaluate whether rigid transformation scaling1 (e(B1 )), . . . , n (e(Bn )) rj(1) , . . . , rj(n) , similarities simspatial , simscale ,simrotation . transformation iff similarities 1. not, lowersimilarities are, less rigid transformation match componentsregions. Hence, instead Formula (10) evaluate following simpler formula:maxnmin{sim(rj(i) , hc, t, , Bi i)}j:{1..n}{1..m} i=1(11)interpreting pose similarities different way. describe detail estimatepose similarities.Let C = hc1 , t1 , 1 , B1 i) u u hcn , tn , n , Bn i), let j injective function{1..n} {1..m}, matches components regions {rj(1) , . . . , rj(n) } respectively.4.2.1 Spatial Similaritygiven component say, component 1 compute anglescomponents seen 1. Formally, let i1hc counter-clockwise-oriented anglevertex centroid component 1, formed lines linking centroidcentroids component h. n(n 1)/2 angles.Then, compute correspondent angles region rj(1) , namely, angles j(i)j(1)j(h)vertex centroid rj(1) , formed lines linking centroidcentroids regions rj(i) rj(h) respectively. pictorial representation anglesgiven Figure 6.let difference spatial (e(rj(1) ), 1 (e(B1 )) maximal absolute differencecorrespondent angles:spatial (e(rj(1) ), 1 (e(B1 )) =maxi,h=2,...,n,i6=h|}{|i1hc j(i)j(1)j(h)compute analogous measure components 2,. . . ,n, select maximumdifferences:nspatial [j] = max{spatial (e(rj(i) ), (e(Bi ))}i=1(12)argument j highlights fact measure depends mappingj. Finally, transform maximal difference perfect matching yields 0minimal similarity perfect matching yields 1 help function described Appendix. minimal similarity assigned everysimspatial (e(rj(i) ), (e(Bi )), = 1, . . . , n.Intuitively, estimate measures difference arrangement centroidscomposite shape group regions. exists transformation bringingcomponents regions exactly, every difference 0, simspatial raises 1 every232fiStructured Knowledge Representation Image Retrievalf2214f3f2213f1f1f3215f2314f1f3315f4415f4f4f5f5R2R3f5R2R3R2R3215214213315R1R4314R4R5R1R1R4R5415R5Figure 6: Representation angles used computing spatial similarity component 1region rj(1) .233fiDi Sciascio, Donini & MongielloR1f151u51h41h31h21hf2uR2h41u31uF521uR5R3f3R4f4Figure 7: Representation angles used computing rotation similarity component 1region rj(1) .component. arrangement scattered reference arrangement,higher maximum difference. reason use maximum differencessimilarity pair component-region clear prove latermeasure obeys Downward Refinement property.4.2.2 Rotation Similarityevery basic shape one imagine unit vector origin centroid orientedhorizontally right (as seen palette). shape used componentsay, component 1 also vector rotated according 1 . Let ~h denoterotated vector. = 2, . . . , n let c~ counter-clockwise-oriented angle vertexi1hcentroid component 1, formed ~h line linking centroid component1 centroid component i.region rj(1) , analogous ~u ~h constructed finding rotation phasecross-correlation attains maximum value (see Appendix). Then, = 2, . . . , nlet j(i)j(1)~u lineu angles vertex centroid rj(1) , formed ~linking centroid rj(1) centroid rj(i) . Figure 7 clarifies anglescomputing.let difference rotation (e(rj(1) ), 1 (e(B1 )) maximal absolute differencecorrespondent angles:rotation (e(rj(1) ), 1 (e(B1 )) = max {| c~ j(i)j(1)~u |}i=2,...,ni1hone orientation rj(1) cross-correlation yields maximume.g., square four orientations compute maximal differenceorientations, take best difference (the minimal one).234fiStructured Knowledge Representation Image RetrievalfimiRiMiDjdjRjfjFigure 8: Sizes distances scale similarity computation component 1 regionrj(1) .repeat process components 2 n, select maximumdifferences:nrotation [j] = max{rotation (e(rj(i) ), (e(Bi ))}i=1(13)Finally, spatial similarity, transform rotation [j] minimal similarityhelp . minimal similarity assigned every simrotation (e(rj(i) ), (e(Bi )),= 1, . . . , n.Observe also differences drop 0 perfect match, hencesimilarity raises 1. region rotated referenceregions match component, higher rotational differences. Again, factuse worst difference compute rotational similarities exploitedproof Downward Refinement.4.2.3 Scale Similarityconcentrate component 1 ease presentation. Let 1 sizecomponent 1, computed mean distance centroid points contour.Moreover, = 2, . . . , n, let d1i distance centroid component 1centroid component i. image, let Mj(1) size region rj(i) , letDj(1)j(i) distance centroids regions j(1) j(i). Figure 8 picturesquantities computing.define difference scale e(rj(1) ) 1 (e(B1 ) as:)(min{Mj(1) /Dj(1)j(i) , m1 /d1i }scale (e(rj(1) ), 1 (e(B1 )) = max 1i=2,...,nmax{Mj(1) /Dj(1)j(i) , m1 /d1i }235fiDi Sciascio, Donini & Mongiellorepeat process components 2 n, select maximum differences:nscale [j] = max{scale (e(rj(i) ), (e(Bi ))}i=1(14)Finally, similarities, transform scale [j] minimal similarityhelp . minimal similarity assigned every simscale (e(rj(i) ), (e(Bi )),= 1, . . . , n.4.2.4 Discussion Pose SimilaritiesUsing worst difference evaluating pose similarities components may appearsomewhat drastic choice. However, guided choice goal preservingDownward Refinement property, even abandon exact recognitionprevious section.Theorem 8 Let C composite shape description, let refinement C,.is, = C uhc0 , t0 , 0 , B 0 i. every image I, segmented regions r1 , . . . ,rm , C (I)DI (I) computed (11) using similarities defined above, holds (I) C (I).Proof. Every injective function j used map components C extendedfunction j 0 letting j 0 (n + 1) {1, . . . , m} suitable region index rangej. Since (I) computed extended mappings, sufficient showvalues computed Formula (11) increase reference values computedC.Let j1 mapping maximum value C (I) reached. Every extensionj10 j1 leads minimum value minn+1i=1 Formula (11) lower C (I). fact,pose differences (12), (13), (14), computed maximums strictly greater setvalues, hence pose similarities either value, lower one. Regardingcolor, texture, shape similarities, adding another component worsen valuescomponents C, since assign components worst similarity group.consider another injective mapping j2 yields non-maximum value v2 < C (I)Formula (11). Using argument pose differences (12), (13), (14), everyextension j20 leads minimum value v20 v2 . Since v2 < C (I), also every extensionevery mapping j different j1 yields value less C (I). completesproof.5. Prototype Systemorder substantiate ideas developed prototype system, written C++.system client-server application working MS-Windows environment.client side avails graphical user interface allows one carryoperations necessary query knowledge base, including canvas query sketchcomposition using basic shapes module query example using new existingimages queries. client also allows user insert new shape descriptions imagesknowledge base. client logical structure shown Figure 9. madethree main modules: sketch, communication configuration.236fiStructured Knowledge Representation Image RetrievalFigure 9: Architecture prototype system.237fiDi Sciascio, Donini & MongielloFigure 10: process reclassification images new description inserted: a)insertion description (No. 9); b) insertion.communication module manages communication server side, usingsimple application-level protocol. configuration module allows one modifyparameters relative preview images shapes transferred serverplaced cache managed FCFS policy efficient display. sketch moduleallows user trace basic shapes palette items, properly insert modifyvarying scale rotation factor. available shapes may basic onesellipse, circle, rectangle, polygons obtained composing basic shapes complexshapes defined previous sessions application inserted knowledgebase, also shapes extracted segmented images.system keeps track transformations corresponding users actions,uses building (internal) shape descriptions stored previously describedsyntax. color texture drawn shapes set according user requirements, client interface provides color palette possibility open imagesJPEG format texture content. user also load images local disktransmit server populate knowledge base. Finally, user definenew objects endowing textual description insert knowledgebase.server side, also shown Figure 9, composed concurrent threadsmanage server-side graphical interface, connections communicationsclient applications carry processing required client side. Obviously,238fiStructured Knowledge Representation Image RetrievalFigure 11: query retrieved set images.239fiDi Sciascio, Donini & Mongielloserver also carries tasks related insertion images knowledge base,including segmentation, feature extraction region indexing, allows one properlyset various parameters involved. end, server three main subcomponents:1. image features extractor contains image segmentation module regiondata extraction one;2. image classifier composed classifier module module usedimage reclassification;3. database management system.feature extractor segments processes images extract relevant featuresdetected region, characterize images knowledge base. Image segmentation carried algorithm starts extraction relevant edgescarries region growing procedure basically merges smaller regions largerones according similarity terms color texture. Detected regions obviouslycomply minimal heuristics. region associated descriptionrelevant features.classifier manages graph used represent hierarchically organizesshape descriptions: basic shapes, complex ones obtained combining elementary shapes and/or applying transformations (rotation, scaling translation).basic shapes parents, top hierarchy. Images,inserted knowledge base segmentation process, linked descriptionsstructure depending specific descriptions able satisfy.classifier module invoked new description insertedsystem new query posed. classifier carries search process hierarchyfind exact position new description (a simple complex one)inserted: position determined considering descriptions new descriptionsubsumed by. position found, image reclassifier comparesimages available database determine satisfy it; imagesverify recognition algorithm tied D. stage considers imagestied descriptions direct ancestors D, outlined Figure 10.usual Description Logics, also query process consists description insertion,query Q new description treated prototypical images: queryQ system considered new description added hierarchical datastructure; images connected either Q descriptions queryhierarchical structure returned retrieved images.database management module simply keeps track images and/or pointersimages.Using system straightforward task. logon user draw sketchcanvas combining available basic shapes, enrich query color texturecontent. query posed server obtain images ranked accordingsimilarity. Figure 11 shows query sketch two circles retrievedset. system correctly retrieves pictures cars two circles recognizedrelative positions sketch represent wheels, also snow manblack buttons.240fiStructured Knowledge Representation Image RetrievalFigure 12: Downward refinement (contd.): detailed query, picturing car,retrieved set images.241fiDi Sciascio, Donini & MongielloFigure 13: Subsumption example: increasing number objects query leadscorrect reduction retrieved set.242fiStructured Knowledge Representation Image Retrievalintroduction details restricts retrieved set: adding chassisprevious sketch makes query precise, well retrieval results, shownFigure 12. example points expect user use system. He/shestart generic query objects. number images retrieved setstill large, he/she increase number details obtaining downward refinement.Notice presence regions/objects included query obviously accepted lack region explicitly introduced query. ideaunderlying approach enormous amount available images,current stage research technology system always ensure complete recognition; yet believe focus reducing false positives, accepting withoutmuch concern higher ratio false negatives. basically means increasing precision,even cost possibly lower recall. words believe preferableuser looking image containing yellow car, e.g., using sketch Figure 12,he/she receives result query limited subset images containing almost sureyellow car, large amount images containing cars, also several imagescars all.Subsumption another distinguishing feature system. Figure 13 shows queriescomposed basic shapes obtained segmentation image picturingaircrafts, i.e., aircraft basic shape system. Here, better emphasizeexample, shape position contribute similarity value. processsubsumption clearly highlighted: query single aircraft retrieves imagesone aircraft, also one aircraft. Adding aircrafts graphicalquery correctly reduces retrieved set. example also points systemable correctly deal presence one instance object images,possible approaches Gudivada Raghavan (1995) Gudivada(1998). negative side noticed system recognizepresence third aircraft (indeed strange one, B2-Spirit) second imageFigure 13-b), segmented considered part background.ability system retrieve complex objects also images severaldifferent objects, main shapes, anyway seen Figure 14.real image directly submitted query. Notice case system carrysegmentation process fly, detect composing shapes.6. Experiments Resultsorder assess performance proposed approach system implementingit, carried extensive set experiments test dataset images.well known evaluating performances image retrieval system difficultlack ground truth measures. ease possibility comparison, adoptedapproach first proposed Gudivada Raghavan (1995). experimental frameworkhence largely based one proposed there, relies comparison systemperformances versus judgement human experts.noticed work test images iconic images,classified terms spatial relationships icons; experiments images243fiDi Sciascio, Donini & MongielloFigure 14: query example retrieved images.244fiStructured Knowledge Representation Image RetrievalFigure 15: sample images used experiments.245fiDi Sciascio, Donini & Mongielloreal classification carried image features, including color, texture,shape, scale, orientation spatial relationships.test data set consists collection 93 images; sample shownFigure 15, complete set available URL:http://www-ictserv.poliba.it/disciascio/jair images.htm.Images acquired using digital camera, combining 18 objects, either simpleobjects (i.e., single shape) composite ones, variable size color. imagessize 1080 720 pixels, 24 bits/pixel. noticed actually18 different objects, considered similar variants object, e.g., twopens different color, single test object.selected test data set 31 images used queries. query set formedtwo logical groupings.first one (namely queries 1 15 queries 27, 30 31) primaryobjective testing performance system using query single objects composedvarious shapes. is, assessing ability system detect retrieve imagescontaining object, objects similar query.query images second group (remaining images test data set) picturedtwo objects chosen assess ability system detectretrieve images according spatial relationships existing objects query.Obviously difference queries containing single objects composed severalshapes, queries containing two objects, cognitive one: systemqueries composite shapes. However, observed performances changedtwo groupings.separately asked five volunteers classify decreasing order, accordingjudgment, 93 images based similarity image selected queryset. volunteers never used system briefly instructedrank orderings based degree conformance database imagesquery images. allowed group images considered equivalent,query, discard images judged wholly dissimilar query.obtained five classifications, univocal, created final rankingmerging previous similarity rankings according minimum ranking criterion.final ranking image respect query determined minimum oneamong five available.example consider classification Query nr.1, shown Table 1.Notice images grouped together cell given relevance.Image 2 ranked third position users 1,4, 5, users 2 3 rankedfourth position, finally ranked position four. Notice image 24criterion leads withdrawal ranked images. approach limits weightimages badly classified single users final ranking.submitted set 31 queries system, whose knowledge baseloaded 93 images test set.behavior system obviously depends configuration parameters,determine relevance various features involved similarity computation.configuration parameters fed system experimentally determined test bed246fiStructured Knowledge Representation Image Retrievaluser12345final1st1111112nd44, 8844, 8844, 8844, 8844, 8844, 88ranking3rd2, 3, 68, 803, 68, 803, 68, 802, 3, 68, 802, 3, 68, 803, 68, 804th262, 262, 262624 262, 265th2424Table 1: Users rankings query nr.1ParameterFourier descriptors thresholdCircular symmetry thresholdSpatial similarity thresholdSymmetry maxima thresholdSpatial similarity weightSpatial similarity sensitivity f xspatial similarity sensitivity fshape similarity weightshape similarity sensitivity f xshape similarity sensitivity fcolor similarity weightcolor similarity sensitivity f xcolor similarity sensitivity frotation similarity weightrotation similarity sensitivity f xrotation similarity sensitivity ftexture similarity weighttexture similarity sensitivity f xtexture similarity sensitivity fscale similarity weightscale similarity sensitivity f xscale similarity sensitivity fglobal similarity thresholdValue0.980.990.300.100.3090.00.400.300.0050.200.11110.00.400.1190.00.400.07110.00.400.110.500.400.70Table 2: Configuration parameters, grouped feature type.approximately 500 images starting test phase. shown Table 2.parameters reported described Appendix. Notice that, dealing welldefined objects, gave higher relevance shape spatial features reducedrelevance scale, rotation, color texture.resulting classification gave us called system-provided ranking.adopted Rnorm quality measure retrieval effectiveness. Rnorm firstintroduced LIVE-Project (Bollmann, Jochum, Reiner, Weissmann, & Zuse, 1985)evaluation textual information retrieval systems usedexperiments referenced paper Gudivada Raghavan. make paperself-contained recall Rnorm defined.Let G finite set images user-defined preference relation completetransitive. Let usr rank ordering G induced user preference relation.Also, let sys system-provided ranking. formulation Rnorm is:Rnorm (sys ) =1S+(1 +)+2Smax+ number image pairs better image ranked systemahead worse one; number pairs worse image ranked ahead+better one Smaxmaximum possible number + . noticedcalculation + , , max based ranking image pairs sys relativeranking corresponding image pairs usr .247fiDi Sciascio, Donini & MongielloQuery nr.12345678910111213141516171819202122232425262728293031Average RnormImage nr.1234567101112131415182025262728313334353637394142507879Rnorm0.920.920.930.950.990.940.930.930.950.740.600.840.830.990.910.890.801.000.741.001.000.990.910.891.000.990.930.981.000.881.000.92Table 3: Rnorm values. (indicates single-object queries)Rnorm values range [0,1]; value 1 corresponds system-providedordering database images either identical one provided humanexperts higher degree resolution, lower values correspond proportionaldisagreement two.Table 3 shows results query final average Rnorm =0.92. Taking closerlook results, first group queries (single compound objects) average valueRnorm =0.90, Rnorm =0.94 second grouping (various compound objects).(The complete set result users ranking system ranking available onlineappendix).comparison, average Rnorm resulted 0.98 system presented GudivadaRaghavan (1995), 24 iconic images used queries databaseimages, similarity computed spatial relationships icons. remarksystem works real images computes similarity several image features,believe results prove ability system catch good extentusers information need, make refined distinctions images searchingcomposite shapes. Furthermore, algorithm able correctly deal presenceone instance object images, possible approaches(Gudivada, 1998). also noteworthy that, though parameters settingobject several experiments, cannot considered optimal yet, believeroom improvement system performance, also pointedfollowing paragraph.Obviously system fail segmentation provide accurate enoughresults. Figure 16 shows results Query 11, one worst R norm .system retrieve images users considered relevant,248fiStructured Knowledge Representation Image RetrievalFigure 16: Query results query 11, lowest Rnorm =0.60.important wrongly confused sugar-drop wrist-watch, resultedfalse positive. matter fact various images sweet-drops resulted properlysegmented. Nevertheless, highly relevant images successfully retrieved wronglyretrieved one slightly selection threshold.Another observation made human users, comparing querysingle object, much driven color feature, includingspatial positioning. appeared various queries clearly visible usingexample results Query 11. users selected highest relevance class imagescolor sugar-drop, gave lower ranking images (with sugar-drops)closer spatial relationships different colors. observation may significantrelated field object recognition.final comment. reference system behavior terms retrieval time,carry systematic testing, depends several variables: number imagesdatabase, number objects query, important depth hierarchy- search time decreases basic shapes available. Limiting analysisdatabase loaded 93 test images, system required average 12 secsanswer query, machine Celeron 400 MHz CPU 128 MB RAM runningclient server.249fiDi Sciascio, Donini & Mongiello7. Conclusionproposed Knowledge Representation approach Image Retrieval. startedobservation current sketch-based image retrieval systems lack compositionalquery language is, able handle queries made several shapes,position, orientation size shapes relative meaningful.recover this, proposed language describe composite shapes, gaveextensional semantics queries, terms sets retrieved images. coperealistic setting beginning, also generalized semantics fuzzy membershipimage description. composition shapes made possible explicituse language geometric transformations (translation-rotation-scale),borrow form hierarchical object modeling Computer Graphics. believedistinguishing feature approach, significantly extends standard invariantrecognition single shapes image retrieval. extensional semantics allows usproperly define subsumption (i.e., containment) queries.Borrowing also Structured Knowledge Representation, particular Description Logics, stored shape descriptions subsumption hierarchy. hierarchyprovides semantic index images database. logical semantics allowed usdefine reasoning services: recognition shape arrangement image,classification image reference hierarchy descriptions, subsumptiondescriptions. tasks aside, speed up, main one, ImageRetrieval.proved subsumption simple logic reduced recognition,gave polynomial-time algorithm perform exact recognition. Then, realistic application setting extended algorithm approximate recognition, weightingshape features (orientation, size, position), color texture.Using logical approach formal specification, built prototype system usingstate-of-the-art technology, set experiments assess efficacy proposal, fine tune parameters weights show approximate retrieval.results experiments, although exhaustive, show approach catchgood extent users information need make refined distinctions imagessearching composite shapes.believe proposal opens least three directions future research. First,language describing composite shapes could enriched either logicoriented connectives e.g., alternative components corresponding compositions sequences shape arrangements, cope objects internal movements video sequence retrieval. Second, techniques Computational Geometry couldused optimize algorithms approximate retrieval, study complexity recognition problem composite shapes might prove theoretical optimalityalgorithms. Finally, large-scale experiments might prove useful understandingrelative importance attributed end users various features composite shape.Acknowledgementswish thank former students G. Gallo, M. Benedetti L. Allegrettiuseful comments implementations, Marco Aiello comments earlier draft,250fiStructured Knowledge Representation Image RetrievalDino Guaragnella discussions Fourier transforms, anonymous refereeconstructive criticism helped us improving paper.research supported European Union, POP Regione Puglia sottomisura 7.4.1 (SFIDA 3), Italian Ministry Education, University Research(MIUR, ex-MURST) projects CLUSTER22 subcluster Monitoraggio ambiente e territorio, workpackage: Sistema informativo per il collocamento dei prodotti ortofrutticolipugliesi Italian National Council Research (CNR), projects LAICO, DeMAnD,Metodi di Ragionamento Automatico nella modellazione ed analisi di dominio.Appendix A.appendix briefly revise methods used extraction image features.also describe smoothing function way compute similarity imagefeatures introduced Section 4.2.A.1 Extraction Image Featuresorder deal objects image, segmentation required obtain partitionimage. Several segmentation algorithms proposed literature;approach depend particular segmentation algorithm adopted. anywayobvious better segmentation, better system work. systemused simple algorithm merges edge detection region growing.Illustration technique beyond scope paper; limitdescription image features computation, assume successful segmentation.make description self-contained start defining generic color image { (x, y) | 1x Nh , 1 Nv }, Nh , Nv horizontal vertical dimensions, respectively,(x, y) three-components tuple (R, G, B). assume imagepartitioned regions (ri ), = 1, . . . , satisfying following properties:I=(ri ), = 1, 2, . . . ,{1, 2, . . . , m}, ri nonempty connected setri rj = iff 6= jregion satisfies heuristic physical requirements.characterize region ri following attributes: shape, position, size, orientation, color texture.Shape. Given connected region point moving along boundary generates complexfunction defined as: z(t) = x(t) + jy(t), = 1, . . . , Nb , Nb number boundarysample points. Following approach proposed Rui, She, Huang (1996) defineDiscrete Fourier Transform (DFT) z(t) as:Z(k) =NbXz(t)ej 2tkNbt=1k = 1, . . . , Nb .251= (k)ej(k)fiDi Sciascio, Donini & Mongielloorder address spatial discretization problem compute Fast FourierTransform(FFT) boundary z(t); use first (2Nc + 1) FFT coefficients formdense, non-uniform set points boundary as:zdense (t) =NcXZ(k)ej 2tkNbk=Nc= 1, . . . , Ndense .interpolate samples obtain uniformly spaced samples zunif (t), =0, . . . , Nunif . compute FFT zunif (t) obtaining Fourier coefficients Zunif (k),k = Nc , . . . , Nc . shape-feature region hence characterized vector 2N c +1complex coefficients.Position Size. Position determined region centroid computed via momentinvariants (Pratt, 1991). Size computed mean distance region centroidpoints contour.Orientation. order quantify orientation region r useFourier representation, stores orientation information phase values.obviously deal also special cases shape region one symmetry, e.g., rectangle circle. Rotational similarity reference shape Bgiven region ri obtained finding maximum values via cross-correlation:C(t) =2NXc21ZB (k)Zri (k) ej 2Nc kn 0, . . . , 2Nc2Nc + 1 k=0Color. Color information region ri stored, quantization 112 valuescolor space, mean RGB value within region:Rri =XR(p)G ri =XG(p)B ri =pripriXB(p)priTexture. extract texture information region ri method basedwork Pok Liu (1999). Following approach, extract texture featuresconvolving original grey level image I(x, y) bank Gabor filters,following impulse response:h(x, y) =221x +y2 2ej2(U x+V y)e2 2(U, V ) represents filter location frequency-domain, central frequency, scale factor, orientation, defined as:=pU2 + V 2= arctan U/Vprocessing allows extract 24-components feature vector, characterizestextured region.252fiStructured Knowledge Representation Image RetrievalA.2 Functions Computing SimilaritiesSmoothing function . similarity measures, use function (x, f x, f y).role function change distance x (in 0 corresponds perfect matching)similarity measure (in value 1 corresponds perfect matching),smooth changes quantity x, depending two parameters f x, f y.(x, f x, f y) =xf +"(1 f y) cos( 2f x )fy 1arctan[(xf x)(1f y)]f xf#0 x < f xx > f xf x > 0 0 < f < 1.input data approximate recognition algorithm shape description D,containing n components hck , tk , k , Bk image segmented regions r1 , . . . ,rm .algorithm provides measure approximate recognition I.first step algorithm Section 4.2 considers regions imagesegmented n components shape description findsgroups n regions rj(k) satisfying higher shape similarity shape componentsD. purpose compute shape similarity, based Fourier representationpreviously introduced, vector complex coefficients. measure denoted sim ssinvariant respect rotation, scale translation computed cosinedistance two vectors. similarity gives measure range [0,1] assuminghigher similarity simss = 1 perfect matching.Given vectors X complex coefficients describing respectively shaperegion ri shape component Bk , X = (x1 , . . . , x2Nc ) = (y1 , . . . , y2Nc )P2Ncl=1 xl ylsimss (Bk , ri ) = qPP2Nc 22Nc 2l=1 xll=1 ylShape Similarity. quantity simshape measures similarity shapescomposite shape description regions segmented image.nsimshape = (max[1 simss (Bk , rj(k) )], f xshape , f yshape )k=1Color Similarity. quantity simcolor measures similarity terms colorappearance regions corresponding shapes composite shape description. following formula, color (k).R denotes difference red colorcomponent k-th component region rj(k) , similarlygreen blue color components.color(k) =q[color (k).R]2 + [color (k).G]2 + [color (k).B]2function takes maximum differences obtain similarity:nsimcolor = (max{color (k)}, f xcolor , f ycolor )k=1253fiDi Sciascio, Donini & MongielloTexture Similarity. Finally, simtexture measures similarity texturefeatures components corresponding regions.texture (k) denotes sum differences texture components k-thcomponent region rj(k) dividing standard deviation elements.nsimtexture = (max texture (k), f xtexture , f ytexture )k=1ReferencesAiello, M. (2001). Computing spatial similarity games. Esposito, F. (Ed.), Proceedings Eighth Conference Italian Association Artificial Intelligence(AI*IA99), No. 2175 Lecture Notes Artificial Intelligence, pp. 99110. SpringerVerlag.Ardizzone, E., Chella, A., & Gaglio, S. (1997). Hybrid computation reasoningartificial vision. Cantoni, V., Levialdi, S., & Roberto, V. (Eds.), Artificial Vision,pp. 193221. Academic Press.Baader, F., & Hanschke, P. (1991). schema integrating concrete domains conceptlanguages. Proceedings Twelfth International Joint Conference ArtificialIntelligence (IJCAI91), pp. 452457, Sydney.Bach, R., Fuller, C., Gupta, A., Hampapur, A., Horowitz, B., Humphrey, R., Jain, R.,& Shu, C. (1996). Virage image search engine: open framework imagemanagement. Storage Retrieval Image Video Databases, Vol. 2670, pp.7687. SPIE.Bertino, E., & Catania, B. (1998). constraint-based approach shape managementmultimedia databases. MultiMedia Systems, 6, 216.Bollmann, P., Jochum, F., Reiner, U., Weissmann, V., & Zuse, H. (1985). LIVEProject-Retrieval experiments based evaluation viewpoints. Proceedings8th Annual International ACM SIGIR Conference Research DevelopementInformation Retrieval (SIGIR 85), pp. 213214. ACM, New York.Brooks, R. (1981). Symbolic reasoning among 3-D models 2-D images. ArtificialIntelligence, 17, 285348.Calvanese, D., Lenzerini, M., & Nardi, D. (1998). Description logics conceptual datamodeling. Chomicki, J., & Saake, G. (Eds.), Logics Databases InformationSystems, pp. 229264. Kluwer Academic Publisher.Cardoze, D., & Schulman, L. (1998). Pattern matching spatial point sets. Proceedings Thirtyninth Annual Symposium Foundations Computer Science(FOCS98), pp. 156165, Palo Alto, CA.Carson, C., Thomas, M., Belongie, S., Hellerstein, J. M., & Malik, J. (1999). Blobworld:system region-based image indexing retrieval. Huijsmans, D., & Smeulders,A. (Eds.), Lecture Notes Computer Science, Vol. 1614, pp. 509516. Springer-Verlag.Celentano, A., & Di Sciascio, E. (1998). Features integration relevance feedback analysisimage similarity evaluation. Journal Electronic Imaging, 7 (2), 308317.254fiStructured Knowledge Representation Image RetrievalChandra, A., & Harel, D. (1980). Computable queries relational databases. JournalComputer System Sciences, 21, 156178.Chang, S., Shi, Q., & Yan, C. (1983). Iconic indexing 2D strings. IEEE TransactionsPattern Analysis Machine Intelligence, 9 (3), 413428.Chew, L., Goodrich, M., Huttenlocher, D., Kedem, K., Kleinberg, J., & Kravets, D. (1997).Geometric pattern matching euclidean motion. Computational Geometry, 7,113124.Cox, I., Miller, M., Minka, T., & Papathomas, T. (2000). bayesian image retrievalsystem, PicHunter. IEEE Transactions Image Processing, 9 (1), 2037.Di Sciascio, E., Donini, F. M., & Mongiello, M. (2000). Description logic imageretrieval. Lamma, E., & Mello, P. (Eds.), AI*IA 99: Advances Artificial Intelligence, No. 1792 Lecture Notes Artificial Intelligence, pp. 1324. Springer-Verlag.Di Sciascio, E., & Mongiello, M. (1999). Query sketch relevance feedback contentbased image retrieval web. Journal Visual Languages Computing,10 (6), 565584.Donini, F., Lenzerini, M., Nardi, D., & Schaerf, A. (1996). Reasoning description logics.Brewka, G. (Ed.), Foundations Knowledge Representation, pp. 191236. CSLIPublications.Edelmann, S. (1999). Representation Recognition Vision. MIT Press.El-Kwae, E., & Kabuka, M. (1999). Content-based retrieval spatial similarity imagedatabases. ACM Transactions Information Systems, 17, 174198.Flickner, M., Sawhney, H., Niblak, W., Ashley, J., Huang, Q., Dom, B., Gorkani, M., Hafner,J., Lee, D., Petkovic, D., Steele, D., & Yanker, P. (1995). Query image videocontent: QBIC system. IEEE Computer, 28 (9), 2331.Foley, J., van Dam, A., Feiner, S., & Hughes, J. (1996). Computer Graphics. AddisonWesley Publ. Co., Reading, Massachussetts.Fuhr, N., Govert, N., & Rolleke, T. (1998). DOLORES: system logic-based retrievalmultimedia objects. Proceedings 21st Annual International ACM SIGIRConference Research Developement Information Retrieval (SIGIR 98), pp.257265, Melbourne, Australia.Gevers, T., & Smeulders, A. (2000). Pictoseek: Combining color shape invariant featuresimage retrieval. IEEE Transactions Image Processing, 9 (1), 102119.Gudivada, V. (1998). R-string: geometry-based representation efficient effectiveretrieval images spatial similarity. IEEE Transactions Knowledge DataEngineering, 10 (3), 504512.Gudivada, V., & Raghavan, J. (1995). Design evaluation algorithms imageretrieval spatial similarity. ACM Transactions Information Systems, 13 (2),115144.Haarslev, V., Lutz, C., & Moeller, R. (1998). Foundations spatioterminological reasoning description logics. Proceedings Sixth International ConferencePrinciples Knowledge Representation Reasoning (KR98), pp. 112123.255fiDi Sciascio, Donini & MongielloHacid, M.-S., & Rigotti, C. (1999). Representing reasoning conceptual queriesimage databases. Proceedings Twelfth International Symposium Methodologies Intelligent Systems (ISMIS99), No. 1609 Lecture Notes ArtificialIntelligence, pp. 340348, Warsaw, Poland. Springer-Verlag.Hartman, J., & Wernecke, J. (1996). VRML 2.0 Handbook. Addison-Wesley.Hirata, K., & Kato, T. (1992). Query visual example. Pirotte, A., Delobel, C., &Gottlob, G. (Eds.), Advances Database Technology Proc. 3rd Int. Conf. Extending Database Technology, EDBT, Vol. 580 Lecture Notes Computer Science, pp.5671. Springer-Verlag.Jacobs, C., Finkelstein, A., & Salesin, D. (1995). Fast multiresolution image querying.Proceedings 22nd Annual Conference Computer Graphics InteractiveTechniques (SIGGRAPH 95), pp. 277286.Jahne, B., Haubecker, H., & Geibler, P. (1999). Handbook Computer Vision Applications. Academic Press.Ma, W., & Manjunath, B. (1997). NETRA: toolbox navigating large image database.Proceedings IEEE International Conference Image Processing (ICIP 97),Vol. 1, pp. 568571, Santa Barbara.Marr, D. (1982). Vision. W.H. Freeman Co., Oxford.Meghini, C., Sebastiani, F., & Straccia, U. (2001). model multimedia informationretrieval. Journal ACM, 48 (5), 909970.Moeller, R., Neumann, B., & Wessel, M. (1999). Towards computer vision descriptionlogics: recent progress. Proceedings IEEE Integration SpeechImage Understanding, pp. 101115.Nebel, B. (1990). Reasoning Revision Hybrid Representation Systems. No. 422Lecture Notes Artificial Intelligence. Springer-Verlag.Niblak, W., Barder, R., Equitz, W., Flickner, M., Glasman, E., Petkovic, D., Yanker, P.,& Faloustos, C. (1993). QBIC project: Querying images content using color,texture, shape. Storage Retrieval Still Image Video Databases,Vol. 1980, pp. 173182. SPIE.Paquet, E., & Rioux, M. (1998). content-based search engine VRML databases.Proceedings IEEE International Conference Computer Vision PatternRecognition (CVPR98), pp. 541546, Santa Barbara, CA.Picard, R., & Kabir, T. (1993). Finding similar patterns large image databases.Proceedings IEEE International Conference Acoustics Speech SignalProcessing (ICASSP 93), pp. 161164, Minneapolis, MN.Pirri, F., & Finzi, A. (1999). approach perception theory actions: part 1.Linkoping Electronic Articles Computer Information Science, No. 41. Linkoping University Electronic Press.Pok, G., & Liu, J. (1999). Texture classification two-level hybrid scheme. StorageRetrieval Image Video Databases VII, Vol. 3656, pp. 614622. SPIE.256fiStructured Knowledge Representation Image RetrievalPratt, W. (1991). Digital Image Processing. J. Wiley & Sons Inc., Englewood Cliffs, NJ.Reiter, R., & Mackworth, A. (1989). logical framework depiction image interpretation. Artificial Intelligence, 41 (2), 125155.Reiter, R. (1980). Equality domain closure first-order databases. JournalACM, 27 (2), 235249.Rui, Y., Huang, T., & Mehrotra, S. (1997). Content-based image retrieval relevancefeedback MARS. Proceedings IEEE International Conference ImageProcessing (ICIP 97), pp. 815818.Rui, Y., She, A., & Huang, T. (1996). Modified Fourier descriptors shape representation- practical approach. Proceedings 1st Workshop Image DatabasesMultimedia Search, Amsterdam.Sanfeliu, A., & Fu, K. (1983). distance measure attributed relational graphspattern recognition. IEEE Transactions Systems, Man, Cybernetics, 13 (3),353362.Smith, J., & Chang, S. (1996). VisualSEEK: fully automated content-based image querysystem. Proceedings fourth ACM International Conference Multimedia(Multimedia96), pp. 8798.Straccia, U. (2001). Reasoning within fuzzy description logics. Journal Artificial Intelligence Research, 14, 137166.Tagare, H., Vos, F., Jaffe, C., & Duncan, J. (1995). Arrangement: spatial relationparts evaluating similarity tomographic section. IEEE Transactions PatternAnalysis Machine Intelligence, 17 (9), 880893.Ullman, J. D. (1988). Principles Database Knowledge Base Systems, Vol. 1. ComputerScience Press, Potomac, Maryland.Woods, W. A., & Schmolze, J. G. (1992). KL-ONE family. Lehmann, F. W. (Ed.),Semantic Networks Artificial Intelligence, pp. 133178. Pergamon Press. Publishedspecial issue Computers & Mathematics Applications, Volume 23, Number29.Yen, J. (1991). Generalizing term subsumption languages Fuzzy logic. ProceedingsTwelfth International Joint Conference Artificial Intelligence (IJCAI91), pp.472477.Zadeh, L. (1965). Fuzzy sets. Information Control, 8, 338353.257fi fffiff ff!"$#%&ff')(*,+.-//-10321-46521*4789:; <=/*1>ff/"(?A@9&'<B/*1>ff/-CEDGFH;IKJML1NOIPJQNORTS)L8UWVPX1HZY[NOIP\]H^V_FM`PaOXcbedaOVPfPJhgFfKHiY[NjUWVkX1H]DlLffFnmoNORcpq`KX1H;JraOIKstY[NOIPJ3FudvaOL1IwFMJxzy|{%}~8z{%}$k{3uyn%uuw3wq{3yfi~8{%$ycqhM}]y|uM%Mw3w%=k6%,=u"hA_|=,nA|ff,ff6P 36 ff=fizBff ff| 6|A6^1n.fi68wM|;68n)v| ;"fi]8686AA.|h|nK ^ z)v8|6h)fifin,1fi686"))6))6.8A"6A"uz;P68j.)||A6GA6nnfi86Mw"86jlA)kAz16||z.,Gfifi8|"fi1wA|6A n8lffA| ))|q;6wnn86A%jfi1||wv|n,|)6).,fi6|833|1|fiK8n86A|ffA68A|G6. 6|||;l|j]AnAfi8]81.jA|))1fiwAfi1. "_|81|8|1_|kfi8|6,P^|"A6,8Kk68ff8"=6]A6^81.fi^h=1fi^G1|filnfi^;.ffl6)6)nG.AvffAffff^|8w686B16|A| 1G|G)8BA68 ")|Bfi|ff8 hhB8 .6|fi61G|Av),|6.A^8fi6"_K"6.6w|B6QAz1|66ff]|^|"fi!"#$%&('*),+.-0/2143 57698:3 -0;*<>=$%?@<BA;43,C+ED+,+.'F-08&(-G&9<:+,HI3(<J3>K'*&ML5N+,HO6+P8+.-08+,<+.'Q/:3 /2RN&('S3 '*HT8+M3(<&('0RU'06V &H0+.5$W V 3 /2;*+ V 3 /2RN)M3 5U5UXZY[&(10'*H0+,HZD&(/2;\&('5N&(69RN),<]3 '*HZ698:3 -0;\/2;*+,&(82XF=$^&ML_3OWa`Mb9c dAfehg_;*&(1069;\/2;*+.X;43,C+iD+,+.' V 3 RU'05UXj<2/21*HORN+,Hk3(<l3I698:3 -0;0RN)M3 5_RU'Q/+.8mY$3(),+\Yn&(8>5N&(69RN),<l&(8l3(<Z3IHORo3 698:3 VV 3 /2RN)T<2XO<2/+ V& Y5N&(69RN),<I=pYn&(8ZRU'*<2/:3 '*),+9Wq<+,+srt+.8 V +.5URU'06+.8MWu`Mb9b9vOWhY[&(8Z6+.'*+.8:3 5%?E<+,w10RUC(3 5N+.'/Z/&yx{zu|}AfWh/2;*+.RU8698:3 -0;O~$/2;*+,&(8+./2RN)uYn&(10'*H*3 /2RN&('*<];43MC+D+,+.'5N+,<:<qRU'QC+,</2RU6Q3 /+,He]y&9<2/qL&(82KO<RU'/2;0RN<_3 8+M3>3 8+5UR V RU/+,H/&TfpaNl(a:G[O99mBafWG&(8@BaN9mBaT=$^&L3OW{`Mb9c d*%;*+.RU'S1069'0RN+.8MW}`Mb9b9AfW4L;0RN):;),&(828+,<2-&('*HI/&/2;*+P-G&9<2RU/2RUC+9Wa),&('(10'*)./2RUC+l3 '*HI+fORN<2/+.'Q/2Ro3 5Y8:3 6 V +.'/u& Y!x}zu|LRU/2;*&(10/JY[10'*)./2RN&('*<Meg_;0RN< V &H0+.57;43(</2;08+,+EY[10'*H*3 V +.'Q/:3 5h);43 8:3()./+.82RN</2RN),<M`9eJ&(DO2+,)./<3 8+\D0RU-43 82/2RU/+yUQfU(2B4t='*&H0+,<>8+.-08+,<+.'/f4[[[nBT3 '*HfU9[[90iD+./L+,+.'/2;*+,<:+P+.'Q/2RU/2RN+,<BAfOe8+M3(<:&('0RU'06<3 8+@D43(<+,H&('F698:3 -0;O~$/2;*+,&(8+./2RN)&(-+.8:3 /2RN&('*<MW08+.5UXRU'06&('3lKRU'*HI& Yh698:3 -0;I;*& V & ~V &(82-0;0RN< V )M3 5U5N+,Hsa2mM2,[n(heRU/lRN<5N&(69RN)M3 5U5UXtYn&(10'*H0+,HWh8+M3(<&('0RU'06<ZDG+.RU'06y<&(10'*H3 '*Hk),& V -05N+./+sLPe 8Me /Meyx}zu|<+ V 3 '/2RN),<MW1*<143 5U5UXsDXiL_3,XI& Y{/2;*+@/28:3 '*<25o3 /2RN&(')M3 5U5N+,HyEe3 RU'j+fO/+.'*<2RN&('*<& Y/2;*+\<R V -05N+\698:3 -0;*< V &H0+.5$W{K+,+.-0RU'06698:3 -0;;*& V & V &(82-0;0RN< V D43(<:+,Ht&(-O~+.8:3 /2RN&('*<@3 '*H<:&(10'*Hy3 '*Hy),& V -05N+./+Z<+ V 3 'Q/2RN),<MW3 8+ip,ffaBlBNBF=$?@&9<2;yr1QL&('06<+9W!`Mb9b9vO^O3 5UC93 /]1069'0RN+.8MWa`Mb9b9O^O3 5UC93 /MW*`Mb9b9cA!3 '*HTGB.2E(2B4=$%;*+.RU'7W1069'0RN+.8MWQ^R V &('*+./MWa`Mb9b9cO8+.5U5N+.8MWO1069'0RN+.8MWO%;*+.RU'7W`Mb9b9cAfY[&(8_QfGf2(]_+,w10RUC93 5N+.'Q//&x}zu|]WO3 'T&(82RU69RU'43 5H0+,HO1*)./2RN&('-//-]u&&4 < 6 ff<_B!1ffzff" :ff"|9&'"&|M!'&M&N1<fi3MfiuM%<2XO<2/+ V =[@+.8HORU5N+,<MW0`Mb9b9A}),& V D0RU'*+,<]3 '43 5UX/2RN)/:3 D05N+M3 1OLRU/2;Z/2;*+_<2R V -05N+]698:3 -0;*<h-08& 2+,)./2RN&('7eq^& V +KRU'*Hj& Y(*f[2(pai;43,C+sD+,+.'j-08&(-&9<+,H/&C93 5URNH*3 /+s3IK'*&L5N+,HO6+sD43(<+i),& V -&9<+,H& Y<2R V -05N+698:3 -0;*<=[RU'*+M3 1RN<<:3(&(10R$W7`Mb9b4RUD0RN+9W0E3(+ VV +.825N9Wa|7&(RN<+M3 17W7`Mb9b9cAfert+-08+,<+.'Q/;*+.8+3uY$3 V RU5UXZ& Y7+fO/+.'*<2RN&('*<]& Y/2;*+J<R V -05N+J698:3 -0;*< V &H0+.5$ehg_;*+),& VV &('i698&(10'*HYn&(8/2;*+,<+F+f/+.'*<RN&('*<RN<Z/2;43 /&(DO2+,)./<\3 8+j(U(2jBGU(mf48+.-08+,<+.'/2RU'06I,,fWfNB&(8(*f[2(pafWq3 '*Hk&(-G+.8:3 /2RN&('*<3 8+iD43(<+,Hj10-&('k-08& m+,)./2RN&('7e?uRUC+.'3IK'*&ML5N+,HO6+sD43(<+s3 '*H3<2R V -05N+698:3 -0;=L;0RN); V 3MX>8+.-08+,<+.'/!3uw1*+.82XW3J6&3 5$W4e,e,e,W9H0+.-G+.'*HORU'06@&('Z/2;*+3 -0-05URN)M3 /2RN&('aAfW9/2;*+Q29O,[n(a2QfNf3(<2KO<{L;*+./2;*+.8)M3 'lD+_H0+,HO1*),+,HlY8& V eh),),&(8HORU'06@/&u/2;*+KRU'*H0<h& YG&(DO2+,)./<),&('*<2RNH0+.8+,HRU'WHOR+.8+.'Q/8+M3(<&('0RU'06 V &H0+.5N<3 8+&(D0/:3 RU'*+,HW),& V -&9<2RU'06/2;*+Y$3 V RU5UXe!g_;*&(1069;<2R V RU5o3 8q'*&(/2RN&('*<& Y82105N+,<3 '*H),&('*</28:3 RU'Q/<)M3 '\DG+Yn&(10'*H\RU'/2;*+%?5URU/+.8:3 /2108+9W/2;*+.RU8]),& V D0RU'43 /2RN&('RU'\8+M3(<&('0RU'06<];43(H'*+.C+.8]D+,+.'\<2/21*HORN+,He]z'*+RU'/+.8+,<2/& Y&(1083 -0-08&3():;i/2;1*<q8+,<2RNH0+,<]RU'-08&MCRNHORU'063l10'0RY[XRU'06Y[8:3 V +.L&(82KF),& V D0RU'0RU'06i82105N+,<3 '*H),&('*<2/28:3 RU'Q/<RU'IHOR+.8+.'/L_3,XO<Me'F/2;0RN<J-43 -+.8MW0L+@Y[&).1*<J&('I/2;*+EYn&(8 V 3 5H0+f*'0RU/2RN&('*<& Yh/2;*+,<:+ V &H0+.5N<MW*RU'*).5U1*HORU'06/2;*+.RU8&(-+.8:3~/2RN&('43 5<+ V 3 'Q/2RN),<3 '*Hi8+.5o3 /2RN&('*<;0RU-*<LRU/2;Fx}zu|qW*3 '*HsL+E<2/21*HOX\/2;*+EH0+,).RNH*3 D0RU5URU/XF3 '*HT),& V -05N+fORU/X& Y!/2;*+.RU8u3(<<:&).Ro3 /+,HIH0+,).RN<RN&('-08&(D05N+ V <MW4'43 V +.5UXI),&('*<2RN<2/+.'*).X3 '*HIH0+,HO1*)./2RN&('7eg_;*+,<+>8+,<2105U/<+f~/+.'*H3 '*H),& V -05N+./+I/2;*+F&('*+,<\3 5U8+M3(HOX-010D05URN<2;*+,HDX/2;*+I3 10/2;*&(8<y=[3 6+./1069'0RN+.8MW_99O`Afeg_;*&(1069;yDG&(/2;y),&('*<2RN<2/+.'*).X3 '*HH0+,HO1*)./2RN&('3 8+>10'*H0+,).RNH*3 D05N+lRU'/2;*+ V &9<2/6+.'*+.8:3 5 V &H0+.5{& Yq/2;0RN<Y$3 V RU5UXWL+\;43(Hj3 5U8+M3(HOX1*<+,H3FH0+,).RNH*3 D05N+i<10D*<+./>& Y_82105N+,<>/&I<:&(5UC+/2;*+TG.{*7.:P-08&(D05N+ V W3T/+,<2/m~$D+,Ht-08&(-&9<+,HRU'j/2;*+\K'*&ML5N+,HO6+T3(),wQ10RN<2RU/2RN&('k),& VV 10'0RU/X=[3 6+./MWh?E+.'*+,</MW}1069'0RN+.8MW`Mb9b9bAfert+I-08+,<+.'Q/\;*+.8+FY[&(8/2;*+T*8</\/2R V +3SH0+./:3 RU5N+,H3 '43 5UXO<2RN<\& Y@),& V -05N+fORU/XL;*+.'L+I8+f~<2/282RN)./_/2;*+uK'*&L5N+,HO6+@D43(<+u/&l/2;0RN<KRU'*HT& Y}82105N+,<P=[)M3 5U5N+,HS2(@Bf[fn,2T82105N+,<BAfehrt+@3 5N<&Z<2/21*HOX-43 82/2RN).105o3 8)M3(<:+,<J& Yh),&('*</28:3 RU'Q/<Me'<+,)./2RN&('D43(<RN)FH0+f*'0RU/2RN&('*<3 '*Hk8+,<2105U/<\3 DG&(10/\<R V -05N+i698:3 -0;*<i3 8+i8+,)M3 5U5N+,He^+,)./2RN&('0- 8+,<+.'/<3 'I&MC+.82CRN+.L& Yh/2;*+@_tY$3 V RU5UXe 'F-43 82/2RN).105o3 8MW*L+P+f-05o3 RU'L;QXsL+P),&('*<2RNH0+.8698:3 -0;0RN)M3 5Yn+M3 /2108+,<J& Y/2;*+@<2R V -05N+E698:3 -0;*< V &H0+.573(<+,<<+.'/2Ro3 5Y[&(8_K'*&ML5N+,HO6+ V &H0+.5URU'063 '*HT-&(RU'Q/J&(10/_/2;43 //2;*+,<+T-08&(-+.82/2RN+,<i3 8+T-08+,<+.82C+,HRU'/2;*+TY$3 V RU5UXe ''*+fO/\<+,)./2RN&('*<L+I<2/21*HOXk/2;*+IHOR+.8+.'/V + V D+.8<s& YE/2;*+IYn3 V RU5UXe105N+,<i3 8+IRU'/28&HO1*),+,HRU'<:+,)./2RN&('d*W_),&('*<2/28:3 RU'Q/<sRU'<:+,)./2RN&('vOW3 '*H<+,)./2RN&('ti<2/21*HORN+,< V &H0+.5N<E),& V D0RU'0RU'06F82105N+,<@3 '*HS),&('*<2/28:3 RU'/<Me@<u<&&('S3(<82105N+,<@3 8+lRU'QC&(5UC+,HSRU'8+M3(<&('0RU'06<MW/2;*+\3(<:<&).Ro3 /+,HSH0+,).RN<2RN&('S-08&(D05N+ V <>3 8+l'*&(/@H0+,).RNH*3 D05N+9WD010/@L+l+fO;0RUD0RU/>3i),&('*HORU/2RN&('=p*'0RU/++fO-43 '*<2RN&('<+./<BAl10'*H0+.8iL;0RN);),& V -010/:3 /2RN&('*<T3 5UL_3,XO<i</&(-7e '/2;*+I-43 82/2RN).105o3 8T)M3(<+I&2(Q2B.[Bn,2y82105N+,<Wa/2;*+Z),& V -05N+fORU/Xy& Y]/2;*+,<+-08&(D05N+ V <uYn3 5U5{RU'Q/&s/2;*+-G&(5UX'*& V Ro3 5h;0RN+.8:3 8);QXe^+,)./2RN&('sRN<!H0+.C&(/+,H/&u/2;*+,<+H0+,).RNH*3 D05N+J)M3(<:+,<Me '<+,)./2RN&('cOW98+.5o3 /2RN&('*<2;0RU-*<qLRU/2;&(/2;*+.8!L&(82KO<q3 8++,<2/:3 D05URN<2;*+,He 'I-43 82/2RN).105o3 8L+P-&(RU'Q/&(10/3 5U6&(82RU/2; V RN)>),&('0'*+,)./2RN&('*<LRU/2;),&('*<2/28:3 RU'/<:3 /2RN<mY$3()./2RN&('-08&(D05N+ V <=$%^ Ai3 '*H<2;*&L/2;43 /s/2;*+I-08&(D05N+ V & Y@):;*+,)KRU'06/2;*+),&('*<2RN<2/+.'*).X& Y>3tK'*&L5N+,HO6+D43(<+),& V -G&9<+,Hy& Yq<2R V -05N+698:3 -0;*<u3 '*Hy),&('*<2/28:3 RU'Q/<=_7~),&('*<2RN</+.'*).X0AJRN<+,w10RUC(3 5N+.'//&i/2;43 /&H0+,).RNHORU'06/2;*+@),&('*<RN<2/+.'*).XF& Y!3 V R0+,H%^ =[ u ~^!g@WIxa3 8269RN+.8MW4|3 '06*W4^);0RN+fW7`Mb9b9Afeh\z(#tz#$kqu!q4rt+8+,)M3 5U5*RU'/2;0RN<<+,)./2RN&('\D43(<2RN)_'*&(/2RN&('*<3 DG&(10/<2R V -05N+J),&('*),+.-0/2143 54698:3 -0;*<=$^&ML3OW`Mb9c d*0%;*+.RU'i1069'0RN+.8MW`Mb9b9Afe{g_;*+,<+]698:3 -0;*<}3 8+]),&('*<RNH0+.8+,H3(<7/2;*+qK+.82'*+.5Yn&(8 V &9<2/K'*&ML5N+,HO6+8+.-08+,<+.'/:3 /2RN&('Yn&(8 V 3 5URN< V <JD010RU5U/10-&('y^&ML_3O<L&(82KGe]g_;*+.XT3 8+>3 5N<:&Z/2;*+@D43(<2RN) V &H0+.5Y[&(8/2;*+PY$3 V RU5UXefi M]|9M.tM=uwuMM3Ffffi;}]}$k{%}uA{M}h3(<2RN)Z&('Q/&(5N&(69RN)M3 5qK'*&ML5N+,HO6+ZRN<E+.'*),&H0+,HSRU'S3s<2/2821*)./2108+)M3 5U5N+,H3BO9fnePxa3()./2143 5!K'*&L5N+,HO6+RN<l+.'*),&H0+,HjRU'Q/&jBGUZ(2B4QS=$^0?E<BAfWhH0+f*'*+,HLRU/2;8+,<-G+,).//&3F69RUC+.'<210-0-&(82/MeI ^0?RN<Z3D0RU-43 82/2RU/+5o3 D+.5U5N+,HZ698:3 -0;=[<2/282RN)./25UX<-G+M3 KRU'06*W9RU/hRN<q3lZ[9mBaW<2RU'*),+_/2;*+.8+)M3 'D+_<+.C+.8:3 5*+,HO6+,<D+./L+,+.'S/L&i'*&H0+,<BAfeuz'*+>).5o3(<<u& Yq'*&H0+,<8+.-08+,<+.'Q/<@+.'/2RU/2RN+,<MWa/2;*+&(/2;*+.8u).5o3(<<8+.-08+,<:+.'Q/<u8+.5o3~/2RN&('*<2;0RU-*<]DG+./L+,+.'s/2;*+,<+J+.'Q/2RU/2RN+,<e &H0+,<]3 8+5o3 D+.5U5N+,H\DX+.5N+ V +.'Q/<_& YG/2;*+<210-0-&(82/Me 5N+ V +.'Q/:3 82X8+M3(<&('0RU'06<u3 8+P),& V -010/+,HFDQXI3l698:3 -0;I;*& V & V &(82-0;0RN< V )M3 5U5N+,HsGmmM2,[n(4e"%$'&)(+*,&.-+*0/1*324657&)( (a8&.-(T 9]fi;}]} <10-0-G&(82/soT ![aUZ#O(.[n(p;:j(2Qf2 <q*[i,,>=PB$0,['?(f@:m),&('*),+.-0//X-G+,<y(a8+.5o3 /2RN&('/X-+,<A5B&.-pP0(![[[[(2S4$yB*BM.C&E-8F6F6F &H- G ms2.9[n( ::*BTmF(f :JI F6F6FLK 2B02,[M? f;:ON KQP ISRT5VU9]fNff4l2>(o.[pG,qf0f,.(a(O(2QfNW5YX(mf:Z(Z&)((a[&)-92ZQ.a92IS:Z\N^]\Q_2(*9`]olif0, ::*\mY_R 5+/pOM.JmtRU'*HORUCRNHO143 5 V 3 82K+.8A< 5Y&.(a=&.-(Gb/(PO( 9!p,s(pp,(4c 5 2p\BQap>f2(#/$8&)(d5eifa9FS :gfS0s6+.'*+.82RN) V 3 82K+.L8 =9hOfCfgi h /j5 0(f[n(h(mfZ9k/JlmTfTn90BnQfBZfNff4m/ _O9pS 9!oMpG(O(2QfN =(aofI @(29B.JfU.\.4c 55U5-43 82/2Ro3 5&(8H0+.8<\LRU5U5DG+FH0+.'*&(/+,HDX\>W3 '*HWRYu'*+,+,H0+,HWRU'*H0+f0+,HDQXk/2;*+F'43 V +I& Yu/2;*+<+./Z&('L;0RN):;/2;*+.X3 8+TH0+f*'*+,He 'k/2;0RN<l-43 -G+.8Z/2;*+iRU'Q/210RU/2RUC+ V +M3 '0RU'06t& Y1]p\q_tRN<3 5UL_3,XO<r]pZs02.n( s9[[9kmY_GeEx{RU6*e`l-43 82/2Ro3 5U5UXH0+,<).82RUD+,<@3s<210-0-G&(82/MWGL;0RN):;LRU5U5{D+1*<+,HyRU'Y[1082/2;*+.8+f*3 V -05N+,<Meuvwyx>z,{y|>}~u.w3|,x,z>|>|y,x}c>|,xyL}|| |,xzx,S>06~,>>,3|,x3|3zyx3y6}3x3|3,,~Lz0>|y,>ywyx>z,{y|>}~>|y,x,3{3z0& (&.-"Vm6&H- n/"m 7+TT3n28"mL .3a .OyTg )pnx}RU69108+`9]^10-0-G&(82/= QMq< G(? fSfM0(f>= pToq< *[fi;}]} B`yB{ <R V -05N+F698:3 -0;QCZfO(.[Sl[(2B4$"$(*-4*L*465((aB-(0aMQS,.=\2B02,[M? f;:m),&('*),+.-0/s'*&H0+,<(am8+.5o3 /2RN&(''*&H0+,<A5 pF0l[oM.l2+,HO6+,<A5pMBa.nQf4Z(f[[(aQs(2s$$(p;: (2Qf2>0Sy: (*\:f2fm(I$yOsQn92m\OaMW52Mi*.22Z\.9 :fIfU9[n(GMQ[j(ay9a:GaMEIo\Qfa2S:$M*y3*3Wi4 9anQf4[< B>*0. *fNff4_mb5!9 p( .T>,:ft M._mEB0fI[BaNB65QfIaMQ>O lif('(? fST: O\Ba5 2.9[n(aQHpPfU2ySF: /X-+=M A>=(tfNff42&)-]= (U2s[>/X-+= (aOlQn(mIZf_Zy. 0(}$iO(B[: mS/X-+=M A65U Q>{= & - G =m$M*3*dW46$MA*>*W4 En " K (GCmWS$MA*13*d64 Enb"VmI* FtFtFK n5 :(a:fi3MfiuM%aMbp>UQfN2S:F>O(y=/X-+= MAfW V 3 82K+.8= ,A2A>=d9hO.2\/X-G+= MApl(jfNff4Jm1&)(a=(U2[s/X-+ =>(a V 3 82K+.8 = MAsps(.UffaPm1/lmTfTnT=(U2t V 3 82K+.8A5Bp9>(.N'>RyoT(a(M ?M[9O(\( (f1=]Of :B0 NRTp2.$M465),&('*),+.-0/]'*&H0+_LRU/2;i3E6+.'*+.82RN) V 3 82K+.8RN<q)M3 5U5N+,H3PfGff[uGMQl=RU/!8+fY[+.8<]/&P3 '\10'*<2-+,).R4+,H+.'Q/2RU/X& Y@3S),+.82/:3 RU'/X-+Af&(/2;*+.82LRN<+FRU/RN<)M3 5U5N+,H3 'pG('?[(0(_aMj=RU/\8+fYn+.8</&t3S<2-+,).R4)RU'*HORUCRNHO143 5}H0+f*'*+,HRU'I/2;*+><210-0-&(82/BAfert+PLRU5U5h3(H0&(-0//2;*+EYn&(5U5N&MLRU'06T).5o3(<<2RN)M3 5{),&('QC+.'Q/2RN&('*<P3 D&(10/^0?E<Me '/2;*+HO8:3,LRU'06k& YP3^0?ZWq),&('*),+.-0/'*&H0+,<3 8+8+.-08+,<+.'Q/+,HDQX8+,)./:3 '0695N+,<s3 '*H8+.5o3 /2RN&(''*&H0+,<DQXs&MC93 5N<Me 's/+fO/2143 57'*&(/:3 /2RN&('7W08+,)./:3 '0695N+,<u3 8+E8+.-05o3(),+,HFDQX i3 '*HF&MC93 5N<DQX 6e]?E+.'*+.82RN)328K.+8<38+&UR2//,+He_gQ;*1><36.+*'.+28NR\),)(&*',).+0>/53G.+51$L*fE4NR@<2<R0U5X*'(&/,+HJ.Ze'RU'*HORUCRNHO143 5VVV),&('*),+.-0/5o3 D+.k5 $MS*y4lRN<'*&(/+,H ter;*+.'RU'&(108+f*3 V -05N+,<L+I1*<+FD0RU'43 82X8+.5o3 /2RN&('*<MW_L+,3X8.+05(3,)E+Q'1G.+8<(&',+H6+,<_DQXTHORU8+,)./+,HI+,HO6+,<Mq3D0RU'43 82Xs8+.5o3 /2RN&('I'*&H0+uRN<_/2;*+.'IRU'*).RNH0+.'/J/&VV+f*3()./25UX&('*+ZRU'*),& V RU'063 '*H&('*+Z&(10/26&(RU'06I+,HO6+9ex{RU6*es<2;*&MLJ<E/L&j=[),&('0'*+,)./+,H4A@<2R V -05N+l698:3 -0;*<3 '*H3(<<21 V +,HF/&ZD+PH0+f*'*+,HI&C+.8J/2;*+P<210-0-&(82/J& Y!x}RU6*e`9ebwyx>z,{y|>}~w3|,x,z| |,x| |,x>|>|y,x}c>|,x| |,x>|>|y,x}c>|,x V>|>|y,x}c>|,x| |,xwyx>z,{y|>}~wyx>z,{y|>}~00yL}|TpLc,w3|,x,z| |,xzx,S>06~,0zx,S>06~,>|y,xyL}|x{RU69108+>O]^R V -05N+>698:3 -0;*<Meg ;*+@+.5N+ V +.'/:3 82Xs8+M3(<:&('0RU'06&(-G+.8:3 /2RN&('7W*-08& m+,)./2RN&('7W0RN<J3lKRU'*HT& Y}698:3 -0;I;*& V & V &(82-0;0RN< V /2;43 /_-08+,<+.82C+,<_/2;*+-43 82/2Ro3 57&(8H0+.8H0+f*'*+,Hs&('T5o3 D+.5N<Meh|7+./_1*<*8<2/_-08+,).RN<+u/2;0RN<&(8H0+.8Yn&(8),&('*),+.-0/'*&H0+5o3 D+.5N<Mert+T;43,C+H0+f*'*+,H/2;*+sY[&(5U5N&LRU'06j-43 82/2Ro3 5&(8H0+.8i&('/2;*+ V 3 82K+.8<+.j/ /lmTfTnQJfRN<Z/2;*+698+M3 /+,<2/l+.5N+ V +.'Q/F=pY[&(83 5U+5 /W \f A@3 '*H+.5N+ V +.'Q/<Z&/3 8+-43 RU82LRN<+\'*&('k),& V -43 8:3 D05N+9eg_;*+.'T/2;*+0(f[n((2QfP(9a:G]aMQ@f ERN</2;*+-08&HO1*)./& Y7/2;*+-43 82/2Ro3 5&(8H0+.8<_&(' &)(3 '*He $M*y4\$M *y 4R\ 3 '*7H \ e 'T&(/2;*+.8L&(8H0<MW43Z),&('*),+.-0/5o3 DG+.a5 $MS*y4RN<lgmTfTnQW0R$e+9H5 $M *y 4RRN<3\<210D0/X-+P&3 '*HW4R`"fffQW*/2;*+.g' )M3 'V &(8+><-G+,).R4)@/2;43 'S3),&('*),+.-0/u5o3 DG+.+D+P3 'QX V 3 82K+.8MW*&(/2;*+.82LRN<E+ V 1*<2/D+P+,w143 5/& 7eE 9]C}M <qG2(BO(.b5 -08& 2+,)./2RN&('fi;}]} , y}J .7(G[fm( pa$ pj\BQapfm( ( $$C4$J ( $[4y(aiB2( - $$E4$J - $[4g9hQnfaB,.? f>MQBN$[hoEfO(.[9mBa(\(\(4QpBYRl(H9fG EOf4ff=](al\:$*2.n( ^ sZ:(a:_9a\fU9[n(SaMQ>UQf 65$MA*y3*3W4 r$$C4*$ $M4*y3*3$ W4y4 r$[4>Wfi M]|9M.tM=uwuMM3F5] $$E4*[$ $M])4y4d\O$M]4rt+'*&(/+Z P =$<210D*<21 V +,j< PAJRYq/2;*+.8++fORN<2/<3-08& 2+,)./2RN&('Y[8& V RU'Q/&ZegqX-0RN)M3 5U5UXW8+.-08+,<+.'/<J3Pw1*+.82XW3PYn3()./MW03 '*Hi-08& m+,)./2RN&('*<Y[8& V /&H0+f*'*+E3 '*<2L+.8<_/&e 'sx{RU6*eqOW<210-0-&9<+[JBM2(2fOf\J.:,(4WO/2;*+.'F/2;*+.8+ERN<&('*+E-08& 2+,)./2RN&('TY8& V RU'/&8Zeqg_;*+ER V 3 6+@& YqDQXT/2;0RN<-08& 2+,)./2RN&('IRN</2;*+><210D0698:3 -0; &Zey{M}hhM][g_;*+T<+ V 3 'Q/2RN),< V 3 -*<\^0?E<l/&/2;*+s+fORN<2/+.'/2Ro3 5_),&('(m10'*)./2RUC+I3 '*Hk-G&9<RU/2RUC+\Y[8:3 6 V +.'Q/\& Yx{zu|qe?uRUC+.'3I<210-0-G&(82/@uW}3F),&('*</:3 'Q/PRN<l3(<<2RU69'*+,HS/&I+M3():;jRU'*HORUCRNHO143 5 V 3 82K+.8l3 '*Hj3 ' ~3(HORN)=8+,<2-7e310'43 82X0AJ-08+,HORN)M3 /+lRN<u3(<<RU69'*+,H/&s+M3(); ~3(HORN)8+.5o3 /2RN&('=8+,<-7e),&('*),+.-0/BA/X-+9ex*&(8E<2R V -05URN).RU/XWL+u),&('*<2RNH0+.8_/2;43 /_+M3();F),&('*<2/:3 'Q/&(8-08+,HORN)M3 /+u;43(<]/2;*+u<:3 V +'43 V +E3(</2;*+E3(<<&).Ro3 /+,Hi+.5N+ V +.'/_&/2;*+u<210-0-G&(82/Me!<+./& Y7Yn&(8 V 105o3(<Jj$d4!RN<3(<<RU69'*+,H/&Z3 'QX<10-0-G&(82/W/28:3 '*<25o3 /2RU'06-43 82/2Ro3 5&(8H0+.8<&('/X-+,<Me\y&(8+<2-G+,).R4)M3 5U5UXW7Y[&(8>3 5U5HORN<2/2RU'*)./P/X-+,j< 3 '*JH <21*);j/2;43 [/ \V W}&('*+Z;43(<@/2;*+Yn&(8 V 105o73 ] FtFtF ] $M $M] * FtFtF *y] 4$M] * FtFtF *y] 4y4fW}L;*+.8+ "IYn&(8),&('*),+.-0/l/X-G+,<MWh3 '*H kRN<&(/2;*+.82LRN<+/2;*+3 82RU/X& Y/2;*+J8+.5o3 /2RN&('i/X-G+9eq?uRUC+.'T3 'QX^0? W3uYn&(8 V 105o3lj$[4!RN<qD010RU5U/3(<qY[&(5U5N&LJ<Me/+.8 V RN<3(<<RU69'*+,HT/&\+M3();y),&('*),+.-0/'*&H0+9]3ZHORN<2/2RU'*)./C93 82Ro3 D05N+EYn&(8J+M3();6+.'*+.82RN)P'*&H0+9W*3 '*HF/2;*+),&('*<2/:3 '/P),&(828+,<2-G&('*HORU'06T/&sRU/< V 3 82K+.8P&(/2;*+.82LRN<+9ePg_;*+.'t3 '3 /& V 6$ W4Z=8+,<2-7e L$ * FtFtF *3 G 42ARN<3(<<&).Ro3 /+,Hs/&+M3():;I),&('*),+.-0/'*&H0+Z=8+,<2-7e8+.5o3 /2RN&('F'*&H0H+ & Yh3 82RU/X K AfWL;*+.8H+ RN</2;*+/X-+u& Y/2;*+'*&H0+9W*3 '*7H Z=8+,<-7e $ARN<_/2;*+E/+.8 V 3(<<2RU69'*+,HT/&Z/2;0RN<_'*&H0+\=8+,<2-7e*3(<<RU69'*+,HT/&/2;*b+ /2;F'*+.RU69;QD&(108& `Afe|7+./ $[4_D+@/2;*+P),&('(m10'*)./2RN&('& Yh/2;*+,<+>3 /& V <ej$[4_RN<J/2;*+P+fORN<2/+.'Q/2Ro3 5{).5N&9<2108+P& +$E4fe; Y4RU'ix{RU6*eq@RN< ] _$Jf,2(2fO.A $M]4 2mM2, $M_4e 6*eh/2;*+Y[&(8 V 105o33(<:<2RU69'*+,H/&>/2;*+<10D0698:3 -07JBM2(2fOf $ J4 \.\:f $M]*y_4 yffW $ *y_4 9]( !9! $M]* B4y4fe8& 2+,)./2RN&('jRN<><&(10'*Ht3 '*Ht),& V -05N+./+\LPe 8Me /MeZ/2;*+<+ V 3 'Q/2RN),<ZEW10-t/&I3T'*&(8 V 3 5URU/X),&('*HORU/2RN&('Yn&(8),& V -05N+./+.'*+,<</2;*+la9B\(.(f& Y{3l^0? RN</2;*+E^0?M`$[4q&(D0/:3 RU'*+,HTDX V +.8269RU'06),&('*),+.-0/'*&H0+,<;43MCRU'06E/2;*+]<B3 V +]RU'*HORUCRNHO143 5 V 3 82K+.8Mehg_;0RN<q^0?3 5UL3,XO<h+fRN</<=n3 '*HRN<}),& V -010/:3 D05N+RU'l5URU'*+M3 8/2R V +LRU/2;T3>'43 RUC+u3 5U6&(82RU/2; V Afe]x}RU69108+ <2;*&MLJ<3P),&(10'/+.8m~+f03 V -05N+E/&-08& 2+,)./2RN&('T),& V -05N+./+.'*+,<:<L;*+.'t^0?E<3 8+'*&(/RU''*&(8 V 3 5Yn&(8 VYn&(8RU'*<2/:3 '*),+lH0&+,<'*&(/-08& m+,).//& kW4+.C+.'yRY!DG&(/2;^0?E<;43,C+/2;*+l<:3 V +P5N&(69RN)M3 5h<+ V 3 'Q/2RN),<W4D010/uRU/-08& 2+,)./</&M$ J4feJ^0?RU''*&(8 V 3 5}Y[&(8 V RN<<B3 RNHI/&D+Za(f9 efiffrt:art:a!rt:a"$#&%('*)+"$#-,.'*)0/21435#617'9835#6:;'<8=3>#6:4'98@?A#61CBD:;'<8FEG#61CBD:;'<8@HC#61CB:;'%IKJMLF,ON4IPRQTSUIVQTWYXZR[Y\]IW^`_aIJ4S`WbI^U[bXJdce^UN2f4SDSUIVQ$J4X_UV=IKW7geX_UV@hi;f;^^UN;Q>jIK_UQ([YJ4\5XVkMI_aIi4WYQ(ilj@k;_UXmQ5\n^U[bXJuut:at:au'OY3$[4+"'OYy$ J4px{RU69108+ ]g_;*+E'*+,+,HTY[&(8'*&(8 V 3 5Y[&(8 V <qsruvu wxrzy {*t Cu|u|}hy|My hyn }qhM}]y|K}$MAy.\ (a9] QM<]G2T(\fMQO(.j5kU0fF P ML$[4> >(Gi(4@:\ j$4*B[$[4 I[$$E465~2:fi3MfiuM%rt+y).5o3 R V +,HRU'/2;*+RU'Q/28&HO1*)./2RN&('/2;43 /^0?E<T3 8++,w10RUC(3 5N+.'/F/&j/2;*+-&9<2RU/2RUC+9W),&('(m10'*)./2RUC+3 '*Hj+fORN<2/+.'/2Ro3 5qY[8:3 6 V +.'Q/Z& Yx{zu|LRU/2;*&(10/Y10'*)./2RN&('*<s=5N+./>1*<H0+.'*&(/+\RU/>DXx}zu|]= _W *A2AfeFz'*++ V D+,H0HORU'06FRN<ER VV +,HORo3 /+I=pY[8& V x{zu|/&I^0?E<BAfWD010/E8+,wQ10RU8+,<E/2;*+ZH0+f*'0RU/2RN&('t& Y3<210-0-&(82/E/2;43 /H0&+,<J'*&(/3(H0H3 'X/2;0RU'06s/&/2;*+P<:+ V 3 'Q/2RN),<u& Y{/2;*+>RU'QC&(5UC+,H698:3 -0;*<Me] 9qfMQO(._RN<3<210-0-&(82/L;*&9<+/28:3 '*<25o3 /2RN&('DQXSRN<E+ V -0/XWh 5W 5uL;*+.8+Z3 5U5hHORN</2RU'*).//X-+,<@3 8+>'*&('),& V -43 8:3 D05N+9eRN</2;*+JC&)M3 D0105o3 82X=[),&('*<2/:3 '/<3 '*H\-08+,HORN)M3 /+,<BA!Y[&(8_3P<+./& YY[&(8 V 105o3(<MWL+),&('*<RNH0+.8/2;*+ a3 /<210-0-&(82/$r4"ff$'&.(+*,&)-+*0/4L;*+.8j+ &)(RN<8+,<2/282RN)./+,H/&Z/2;*+P+.5N+ V +.'Q/ j(WO/2;*+@8+.5o3 /2RN&('I/X-+,<J&& - 3 8+/2;*+@-08+,HORN)M3 /+,<& Y!3 82RU/ZX RU' \W*3 '*HI/2;*+@RU'*HORUCRNHO143 5 V 3 82K+.8<& /3 8+E/2;*+P),&('*<2/:3 '/<JRU' eU=D;5=0D; ` fiD;2MmW|7+./D+F3Sx}zu|]=U_W*APY[&(8 V 105o3&MC+.83yC&)M3 D0105o3 82Xekg_;*+^0?D;$`.4lH0+f*'*+,H&('/2;*+P<210-0-&(82/J $r4RN<D010RU5U/u3(<Yn&(5U5N&MLJ<M!/&+M3();/+.8 V & Y(yL+3(<<&).Ro3 /+P3),&('*),+.-0/'*&H0+@/X-+,H(=6+.'*+.82RN)@RYh/2;*+E/+.8 V RN<3lC93 82Ro3 D05N+9W0RU'*HORUCRNHO143 57LRU/2;3 V 3 82K+.81uRYh/2;*+@/+.8 V RN</2;*+P),&('*<2/:3 '/jMAfW3 '*Hk/&S+M3();3 /& V 6$M] * F6F6F *y]{W 4PL+I3(<<&).Ro3 /+F38+.5o3 /2RN&(''*&H0+Z/X-+,HfW]<21*);/2;43 /MW!Yn&(8I[\+\xOWO/2;*+j$/2;I'*+.RU69;DG&(D8& Y`ZRN</2;*+P),&('*),+.-0/J'*&H0+>3(<<:&).Ro3 /+,HT/&] eg_;*+ V 3 -0-0RU'06D;RN<_).5N+M3 825UXRU'(2+,)./2RUC+9W05W5hRU/ V 3 -*<HOR+.8+.'Q/_Yn&(8 V 105o3(<P='*&(/_RNH0+.'Q/2RN)M3 510-T/&I\BaZOM.yn_ }A _ UOfo\. M2,[n(y^ }$TN += R>.9BZ T? fI?M:Qf(S: $SOiM.PmG(B\(+}iQ <qG2(O 9BO9f{ $r4EfO.9M=*,((:i 9],(fZU j(a =k Ofo>Pa2mM2,[n(B2($ 4P4$$ 465C93 82Ro3 D05N+@8+.'43 V RU'06A_/&\HOR+.8+.'Q/E^0?E<>='*&(/JRNH0+.'/2RN)M3 5}10-F/&3 'FRN<:& V &(82-0;0RN< V Afe]y&(8+,&MC+.8MW4RU/JRN<3D0R 2+,)./2RN&('IRY{L+@8+,<2/282RN)./u^0?@</&Z/2;*&9<+@RU'I'*&(8 V 3 57Y[&(8 V e|7+./!1*<h'*&L),&('*<2RNH0+.8!/2;*+x}zu|= _W *A7Yn&(8 V 105o3 " ] $ $ ] 4y4_=L;*+.8+ $ ] c4}RN<q3u),&('(m10'*)./2RN&('& Y\3 /& V <FL;*&9<+C93 82Ro3 D05N+,<FD+.5N&('06/& ] Afeg_;*+ ( ~+.'082RN);*+,HY[&(8 V 105o3& RN<I/2;*+SY[&(8 V 105o3$ .4k"] $ $ ] 4$ ] 4y4PL;*+.8+ +$ ] 4@RN<>/2;*+s),&('(m10'*)./2RN&('& Y/2;*+i3 /& V < j($M]4fW{Yn&(8l+.C+.82X/+.8 V ]yRU' he_rt+>'*&L-08&C+l/2;*+P-08&(-+.82/XIDXI-G&(RU'/2RU'06s&(10/u/2;43 /MW{`A_Yn&(8 t3 '*H T/L&Tx}zu|= _W*A}Yn&(8 V 105o3(<WZR7$ .4 Z $ 4fWO3 '*HiAhY[&(83 'X\x}zu|]= _W *A}Yn&(8 V 105o3 h W $ .4"[$ $ .4y4fW3 '*HI),&('*).5U1*H0+@1*<RU'06g_;7e7`9ex*&(8E/2;*+l&(/2;*+.8@HORU8+,)./2RN&('7W/2;*+l3 -0-43 8+.'/@-08&(D05N+ V RN<u/2;43 /Y[&(8 V 105o3(<P3(<<2RU69'*+,H/&/2;*+Z<210-0-&(82/DQX3 8+P10'0RUC+.8<:3 5U5UXIwQ143 '/2R4+,H3 '*H3 8+P1*<+,HFRU'I/2;*+PH0+,HO1*)./2RN&('-08&),+,<:<Mequ&ML+.C+.8MWaL+>)M3 'H0&LRU/2;*&(10/J/2;*+ V W4DQXT+.'*),&HORU'06\/2;*+P-43 82/2Ro3 5&(8H0+.8&('I/X-+,<JHORU8+,)./25UXTRU'F/2;*+^0?E<Me] ` fi| ` |v ( |vC+ 5 ` ]5U Cz! ||v ` |v= |v0Ufi ] ` `D; `UC7f!6 UOfoMM2,[M? _Ba n9[n(yn y^ }$ }ATaI0ZM.mZa(f\(}\QM<qG(TfM0(f] $OZ,.umN += Ru,(flU fO.9M =.(S( : 9]}(aQM <q2(1=iOfSpyGmmM2,[n(B2(4$BC7$[4!C7$J465<2MmW|7+./CD+3i698:3 -0;tH0+f*'*+,Ht&('t3T<210-0-G&(82/Eue>g_;*++fO-43 '*<2RN&('& YdZW W] $E4fWRN<E/2;*+^0?H0+f*'*+,H&('j/2;*+ a3 /l<10-0-G&(82/ $Ci4 =L;*+.8+ RN<>/2;*+iC&)M3 D0105o3 82XY[&(8/2;*+\Yn&(8 V 105o3(<Z& Yuj$d42AfWD010RU5U/@3(<JYn&(5U5N&MLJ<ME`A_Y[&(8u+.C+.82X),&('*),+.-0/'*&H0+[]" H h& YZW W] $EJ4 ),&('/:3 RU'*<E3 '3(<<&).Ro3 /+,H( W0<Me /MeUWYn&(8J+M3();),&('*),+.-0/J/X-G+Y 698+M3 /+.8&(8J+,w143 5/&rf W*3l10'43 82X),&('*),+.-0/J'*&H0+b] "8+.5o3 /2RN&('j'*&H0+\& Y/X-+h5URU'0K+,Hj/&7]]3 '*HjAuY[&(8>+.C+.82X8+.5o3 /2RN&(''*&H0+ok] & YH =[& Y/X-+I3 '*H3 82RU/X K AfW4Yn&(8+.C+.82XF8+.5o3 /2RN&('y/X-G+E <Me /Me8\ W4L+Z3(H0HIRU' 6] `$[4 3\8+.5o3 /2RN&(''*&H0+P/X-+,H7LRU/2;<:3 V +'*+.RU69;QD&(8<>3(<Y}] eurt+>'*&LH0+f*'*+l/2;*+Z3 -0-05URN)M3 /2RN&('3(<P W] }W3 '*HS),&('*).5U1*H0+1*<2RU'06g_;7e`9W*'*&(/2RN).RU'06\/2;43 /uj$ $k4y4" Oe{ <<7 @ <;Afi M]|9M.tM=uwuMM3F<2RU'06\<2R V RU5o3 8/28:3 '*<mYn&(8 V 3 /2RN&('*<MWG3Z).5N&9<+E8+.5o3 /2RN&('*<2;0RU-I/&Z/2;*+@-08&(D05N+ V & Yd.*fS:s94$(*f4<2/21*HORN+,HsRU's/2;*+H*3 /:3 D43(<+4+.5NHs;43(<DG+,+.'T<2;*&L'7!);*+,)KRU'06\w1*+.82X),&('Q/:3 RU' V +.'/Y[&(8'*&('T8+,).108<2RUC+),&('(m10'*)./2RUC+FwQ1*+.82RN+,<lRN<Z+,wQ10RUC93 5N+.'Q/Z/&S);*+,):KRU'06-08& 2+,)./2RN&('DG+./L+,+.'^0?E<F=$%;*+.RU'+./3 5$eUWJ`Mb9b9cO1069'0RN+.8MW4999Afepv` qhy]fiM}]$A{M}h{q< KB`y $x*&(8/2;*+E<:3 K+E& Y}D08+.CRU/XWOL+@),&('*<2RNH0+.8_RU'FL;43 /Y[&(5U5N&LJ</2;43 /^0?E<J3 8+u69RUC+.'FRU's'*&(8 V 3 5Yn&(8 V W03 '*H-010/_RU'Q/&Z'*&(8 V 3 5Yn&(8 V RY'*+,+,H0+,HI3Y[/+.83 V &HOR4)M3 /2RN&('7e]'*HWO<2RU'*),+@3Z^0?H0&+,<_'*&(/_'*+,+,HT/&lDG+@3),&('0'*+,)./+,HI698:3 -0;7W*L+P),&(' a3 /+l3Z<+./& Y]^0?E<LRU/2;I/2;*+^0?&(D0/:3 RU'*+,HIDQXs-+.8mY[&(8 V RU'06\/2;*+>HORN<[m&(RU'/10'0RN&('& YhRU/<+.5N+ V +.'/<Me 'F/2;*+@Y[&(5U5N&LRU'06sH0+f*'0RU/2RN&('7W*Y[&(8JRU'*</:3 '*),+9W*/2;*+^0?k8+.-08+,<+.'Q/<E3<+./&^0?E<Me*| B .(a>x_{fi;}]}Q29O:@fm( J P d5@ 9]r}uQM<]G29lBO(.j5(S:% ;*+.RU'3 '*H1069'0RN+.8\=m`Mb9b9A;43MC+Z<2;*&ML'y/2;43 /-08& 2+,)./2RN&(');*+,):KRU'06TRN<Y ~),& V -05N+./+ZLRU/2;38+,HO1*)./2RN&('SY[8& V{ e wQ10RUC93 5N+.'*),+ZLRU/2;j%^ =[<:3 /2RN<ma3 D0RU5URU/Xy& Y3s),&('*<2/28:3 RU'/@'*+./L&(82K0AL_3(<3 5N<&l1*<+,Hs5o3 /+.8>=[x*+,H0+.8 ]3 8HOR$W`Mb9b *1069'0RN+.8%;*+.RU'7W`Mb9b9AfW43 '*HsRU'*H0+.-G+.'*H0+.'/25UXTRU'3>C+.82X<2R V RU5o3 8 V &H0+.5{DQXJ1*H0&(5Y=m`Mb9b9cA=[<+,+>-43 82/@c\& Yq/2;0RN<u-43 -+.8BAfeJrt+69RUC+>D+.5N&ML3 '*&(/2;*+.8E-08&& Y]&/2;0RN<u8+,<2105U/ED43(<+,Hy&('38+,HO1*)./2RN&('yY8& V ~^!g@eg_;*&(1069; V &(8+Z),& V -05URN)M3 /+,HS/2;43 'y/2;*+l-08+.CRN&(1*<&('*+,<MW0/2;0RN<J8+,HO1*)./2RN&('RN</2;*+ED43(<2RN<Y[&(8J&(/2;*+.8J8+,HO1*)./2RN&('*<-08+,<+.'/+,HI5o3 /+.8JRU'F/2;0RN<-43 -+.8Meg_;*+lYn&(5U5N&MLRU'06I/2;*+,&(8+ V K+,+.-*<@RU'Q/&I3(),),&(10'/P/2;*+),& V -05N+fRU/X& Y),&('*),+.-0/3 '*HS8+.5o3 /2RN&('t/X-+);*+,):KRU'06*W/2;*&(1069;\RU'/2;0RN<!-43 -+.8!/2;0RN<!/+,<2/q)M3 'i&(DQCRN&(1*<25UXD+_-+.8mY[&(8 V +,HZRU'-&(5UX'*& V Ro3 54/2R V +J<2RU'*),+),&('*),+.-0/3 '*HF8+.5o3 /2RN&('/X-G+,<3 8+@&('05UXs5o3 D+.5N<-43 82/2Ro3 5U5UXF&(8H0+.8+,HIRU'3l;0RN+.8:3 8):;QXephy|Myqhynsr}uvu _K*{o1!(aN.samfU.C=\qhM}]y|:B0lfO2LpTpifU( $ H5Kv { $2MmW Zx{RU8<2/@<+,+l/2;43 /@RY/X-+Z);*+,)KRU'06IRN<uRUB' WG/2;*+.'} RN<P3 5N<&sRU' 3i-08& ~2+,)./2RN&('7Wq+.'082RN);*+,HDX),+.82/2R4)M3 /+,<lYn&(83 5U5/X-+s):;*+,)KO<Z1*<+,HW!RN<3-G&(5UX'*& V Ro3 5),+.82/2R4)M3 /+9etg_;*+8+,).RU-08&)M3 57RN<J&(DQCRN&(1*<25UXT/2821*+9eqrt+E'*&L<2;*&L/2;43 /MW*+.C+.'IRYh/X-+@);*+,)KRU'06i)M3 'DG+@H0&('*+@RU' $,I4fW} jRN< ~),& V -05N+./+9e|7+./1*<'*&ML D010RU5NH3y8+,HO1*)./2RN&('Y[8& V ~^!g@e]g_;*+TRU'0-010/s& ~^!gRN<i3Y[&(8 V 105o3RU' ~),&('(m10'*)./2RUC+@'*&(8 V 3 5Yn&(8 V = ~% xqAfW0R$e+9eq3Z),&('(m10'*)./2RN&('& YhHORN<[10'*)./2RN&('*<l=[).5o3 1*<+,<BAfW0+M3():;ILRU/2;3 /V &9<2//2;08+,+@5URU/+.8:3 5N<W43 '*HT/2;*+@wQ1*+,</2RN&('IRN<_L;*+./2;*+.8J/2;*+.8+@RN<3l/28210/2;3(<:<2RU69' V +.'Q/& Yh/2;*+EC93 82Ro3 D05N+,<& <21*);T/2;43 / RN</2821*+9e u&(/2RN),+u/2;*+E).5o3(<<2RN)M3 5 ~^!g-08&(D05N+ V ),&('*<2RNH0+.8<).5o3 1*<+,<_LRU/2;F+f03()./25UX/2;08+,+@5URU/+.8:3 5N<MW*D010/Y[&(8_Y[1082/2;*+.8J-08&& Y[<_L+P-08+fYn+.8/&1*<+E/2;*+>3 D&MC+PC(3 82Ro3 '/Me|7+./ q"DG+>3 'RU'*<2/:3 '*),+>& ~^!g@e*re 5$e&0e 6*e]L+P<210-0-&9<+@/2;43 /+M3():;C93 82Ro3 D05N+F6F6FG3 -0-+M3 8<3 / V &9<2/&('*),+RU'i3E).5o3 1*<+9e!|7+./]1*<q).8+M3 /+Yn&(108]),&('*),+.-0/q/X-+,<!Yn&(8q+M3();iC(3 82Ro3 D05Nd+ ]{ GW 4WF3 '*H aert+3 5N<:&\).8+M3 /+>&('*+>8+.5o3 /2RN&('/X-+ hYn&(8+M3():;y).5o3 1*<+ Wa3 '*H38+.5o3 /2RN&('/X-G+ 0e3():;k),&('*),+.-0/l/X-G+ SRN<P698+M3 /+.8l/2;43 ' 3 '*H 4W}/2;*+,<+i3 8+/2;*+&('05UX-&9<<2RUD05N+),& V -43 82RN<:&('*<D+./L+,+.'yHORN<2/2RU'*)./J/X-+,<Mert+lD010RU5NHS/2;*+Z698:3 -0; $ 4@3(<uYn&(5U5N&MLJ<MY[&(8@+.C+.82XC(3 82Ro3 D05Nr+ ]tRU' IWL+Z;43MC+Z/2;08+,+),&('*),+.-0/'*&H0+,Z< 4W 3 '*QH lRU7' $ 43 '*Hi/L&l8+.5o3 /2RN&('s'*&H0+,</X-+,H 5URU'0KRU'06>/2;*+*8<2//&>/2;*+5o3 /2/+.8_&('*+,<u=RU'/210RU/2RUC+.5UXW0RU/ V +M3 '*</2;43 //2;*+JC93 82Ro3 D05N1+ ]F)M3 'sDG+C(3 5U143 /+,HiDQX &(8 TAfeh|7+./Kv { $@9 +U `+9`79;<<99fi3MfiuM%bvalvalvalafbtcvalbfvalvalvalctcfdt2123C1C1C1C1C1C1C11C2C2bcvalvalvalvalvaldfavbvcvdv...3C2C2C2C2C212C12313C2*|G*{$1*<<B3,XF/2;43 //2;*+>/28210/2;C93 5U1*+.9 =8+,<2-7eQA_RN<u3(<<&).Ro3 /+,HFLRU/2;ff`9y=8+,<-7eUAfe_g_;*+.'Yn&(8+.C+.82X).5o3 1*<+"$--4ERU' =L;*+.8+!&0W&T3 '*H&i3 8+5URU/+.8:3 5N<&C+.8C93 82Ro3 D05N+,<C]}W_3 '*HAfWGL+3(H0Hy/2;*+8+.5o3 /2RN&(''*&H0+,<u/X-G+,H Wa;43,CRU'063(<*8</E3 82691 V +.'/`9F&(8U 4W3(<<+,),&('*HI3 82691 V +.'/`&(8g`aWO3 '*HF3(<_/2;0RU8HI3 82691 V +.'/U9 \&(8U aW/2;43 /J),&(828+,<-G&('*Hs/&\3 '+.C93 5U143 /2RN&('& Y!/2;*+P).5o3 1*<+@/&\/2821*+i= V &(8+@-08+,).RN<+.5UXW4RY!L+@8+.-05o3(),+>RU'I/2;*+>).5o3 1*<+h+M3():;-&9<2RU/2RUC+=8+,<2-7e'*+.6Q3 /2RUC+AE5URU/+.8:3 59WaI7\\OW7DXy/2;*+\/28210/2;jC93 5U1*+=8+,<2-7e\/2;*+\'*+.6Q3 /2RN&('& Y_/2;*+/28210/2;C93 5U1*+A3(<<&).Ro3 /+,HTLRU/2;I/2;*+@ 5'*+.RU69;QD&(8& Yh/2;*+@8+.5o3 /2RN&(''*&H0+9Wv}RN<+.C(3 5U143 /+,H/&Z/2821*+Afex*&(8E).5o3 1*<+,<8+,<2/282RN)./+,H/&$ 4J&(8k$ 4fWaL+>-08&),+,+,Hy<2R V RU5o3 825UXW3(H0HORU'06 D0RU'43 82XI8+.5o3 /2RN&(''*&H0+,<u&(8E&('*+l10'43 82XI8+.5o3 /2RN&('S'*&H0+9ebu&(/+>/2;43 /E;43MCRU'06 K ~).5o3 1*<+,<MWGL;*+.8+ K RN<E3i),&('*<2/:3 '/MWRN<u&-082R V 3 82XSR V -G&(82/:3 '*),+/&F;43,C+s3T-&(5UX'*& V Ro3 5q/28:3 '*<2Y[&(8 V 3 /2RN&('7W{<2RU'*),+L+&(D0/:3 RU' GfiI8+.5o3 /2RN&(''*&H0+,<_Y[&(8J+M3():;).5o3 1*<+9e'i/2;*+698:3 -0;o$ 4fWO/L&Z),&('*),+.-0/'*&H0+,<7` 3 '*HQU9 \3 8+).8+M3 /+,HsYn&(8+M3():;FC(3 82Ro3 D05N+H]3 '*H3ZD0RU'43 82Xs8+.5o3 /2RN&(''*&H0+5 9 P5URU'0KO<g` /&U9 aeqx*&(8+M3():;).5o3 1*<+)" $-@-& 4fW*/2;*+.8+@RN<&('*+P8+.5o3 /2RN&('K7, 5URU'0K+,H/&OU9 4WHU9 T3 '*HVU9 =n3 '*H<R V RU5o3 825UXTY[&(8u).5o3 1*<+,<LRU/2;S&('*+>&(8/L&5URU/+.8:3 5N<BAfeIo$ 4@8+.-08+,<+.'Q/</2;*+w1*+,<2/2RN&(' RN<>/2;*+.8+i3FC93 5U143 /2RN&('& Y/2;*+C93 82Ro3 D05N+,<l<21*);/2;43 /l3 5U5).5o3 1*<+,<J+.C93 5U143 /+@/&d 9 9lg_;0RN<u/28:3 '*<mYn&(8 V 3 /2RN&('SY8& V /2;*+ ~^!gY[&(8 V 105o3$0`W4 $UT 4JRN<uRU5U5U1*<2/28:3 /+,HRU'tx{RU6*ed*e '/2;*+Z698:3 -0;ZW7'*&(/>3 5U5]+,HO6+,<PRN<<21*+,HyY[8& V /2;*+).5o3 1*<+,<P;43MC+DG+,+.'tHO8:3ML'7W7Yn&(8E/2;*+<:3 K+Z& Y8+M3(H*3 D0RU5URU/Xe /uRN<ER VV +,HORo3 /+/&T);*+,):KS/2;43 /MWY[&(8P3Yn&(8 V 105o3!IW/2;*+.8+ZRN<P3iC(3 5U143 /2RN&('t&RU/<_C93 82Ro3 D05N+,<J<21*);/2;43 /J+M3();I).5o3 1*<+ERN<J+.C93 5U143 /+,HT/&Z/2821*+ERYh3 '*HF&('05UXsRY!8$ 4_)M3 'FDG+u-08& 2+,)./+,HRU'Q/&Z$ 4fe7u&(/+/2;43 /l/2;*+i<10D*<21 V -0/2RN&('8+.5o3 /2RN&('RU'*HO1*),+,HkDQXj-08& m+,)./2RN&('&MC+.8^0?E<RN<l3w143(<2R~&(8H0+.8MWhD010/'*&(/l3 '&(8H0+.8MlRU/RN<l3F8+R4 +fORUC+s3 '*H/28:3 '*<2RU/2RUC+iD010/>'*&(/3 'Q/2R~<2X VV +./282RN)M3 5_8+.5o3 /2RN&('7egL&^0?E<x{RU69108+@d* * 3 V -05N+>& Yh/28:3 '*<mYn&(8 V 3 /2RN&('FY[8& V ~^!g/&%AyM}]]} ]{%}3 8+P<:3 RNHT/&\DG+y,M?(Nf4RYh/2;*+.Xs-08& m+,)./J/&+M3();&(/2;*+.8Me]^0?RN<<:3 RNHF/&ZD+Z229aQ(4RYhRU/RN<+,w10RUC(3 5N+.'//&&('*+u& Y{RU/<<2/282RN)./<210D0698:3 -0;*<>=R$e+9e]3l<210D0698:3 -0;F'*&(/+,w143 5/&oRU/<+.5YfAfWO&(/2;*+.82LRN<+ERU/RN<J<:3 RNHT/&\DG+ZB2(a94nepqsruvuhy|My hyn }qhM}]y|J(G(aL :fOS p( 1!m(aN.ia2QS!Nf85Jfyy.M?(Nfa:.(:>(Z[P* ,0ZNMt$io,(\($aQofYRlB2(a94{9mBa 5g_;*+pf2(a(4*.(f& Y}3Z^0?VRN<_3 'sRU828+,HO10'*H*3 'Q/<210D0698:3 -0;F& Y+,w10RUC93 5N+.'Q/_/&PRU/@=L;*+.'RN<RU828+,HO10'*H*3 'Q/MW4/2;0RN<_698:3 -0;sRN<RU/<+.5Y2WO&(/2;*+.82LRN<+E/2;*+.8+ V 3,XsDG+u<+.C+.8:3 5<21*):;I<210D0698:3 -0;*<MWD010//2;*+.XF3 8+>3 5U57RN<& V &(82-0;0RN)Afe;fi M]|9M.tM=uwuMM3FhD#U_ 9qu;^(#$dh#as$s O*F"g_;0RN<<+,)./2RN&('iRN<H0+.C&(/+,Hi/&l3 's&MC+.82CRN+.L& Y7/2;*+HOR+.8+.'/ V &H0+.5N<),& V -G&9<RU'06/2;*+SY$3 V RU5UXehrt+LRU5U5G*8<2/_&(10/25URU'*+E/2;*+ V 3 RU' V &(/2RUC93 /2RN&('*<Y[&(8_&(108_698:3 -0;O~$D43(<+,HI3 -0-08&3();I& Y}K'*&L5N+,HO6+E8+.-08+,<+.'O~/:3 /2RN&('7eC8) 9o}h]ynAyn}A{}[{%}hMyy|{3M}]}hu{hx08& V 3 V &H0+.5URU'06ICRN+.L-G&(RU'/MW7L+\<+,+Z/L&I+,<<+.'/2Ro3 5q-08&(-+.82/2RN+,<PRU']y }$ $y}/2;*+Z<2R V -05N+l698:3 -0; V &H0+.5$e@g_;*+FQM2,.W<2R V -05N+l698:3 -0;*<MW73 8+l+M3(<2RU5UX10'*H0+.8<2/:3 '*H*3 D05N+ZDXy3 'S+.'*H~1*<+.8=n3sK'*&ML5N+,HO6+i+.'069RU'*+,+.8>&(8P+.C+.'3 't+fO-G+.82/BAfe'*H2 .(4p(i3 8++M3(<2RU5UX10'*H0+.8</:3 '*H*3 D05N+/&&0W9Yn&(8q/L&>8+M3(<&('*<-08& 2+,)./2RN&('iRN<3E698:3 -0; V 3 /):;0RU'06l&(-+.8:3 /2RN&('7W/2;Q1*<+M3(<2RU5UXRU'Q/+.82-08+./:3 D05N+E3 '*HCRN<2143 5URN<:3 D05N+943 '*HF/2;*+@<B3 V +@5o3 '069143 6+@RN<1*<+,H3 /RU'Q/+.8mY$3(),+3 '*HI&(-+.8:3 /2RN&('43 575N+.C+.5N<Me5U/2;*&(1069;/2;*+.8+RN<3E6Q3 -\D+./L+,+.'i/2;*+/2;*+,&(8+./2RN)M3 5aY[&(10'*H*3 /2RN&('*<<2/21*HORN+,H\;*+.8+3 '*Hi3u5o3 '069143 6+1*<:3 D05N+TRU'8+M3 53 -0-05URN)M3 /2RN&('*<MWL+IL&(105NH5URUK+T/&SD082RN+ *X V +.'Q/2RN&('/L&-08& 2+,)./<RU'L;0RN):;/2;*+,<+-08&(-+.82/2RN+,<;43MC+lDG+,+.'S+f;0RUD0RU/+,HeEg_;*+*8<2/u&('*+RN<E3 'S+f-+.82R V +.'Q/ERU'SH0&).1 V +.'/@8+./282RN+.C(3 5hH0&('*+DQX\?E+.'*+,<2/=n999Afe 'Z/2;0RN<!L&(82KWQ),&('*),+.-0/2143 5a698:3 -0;*<]3 8+_1*<+,HZ/&@H0+f*'*+3u5o3 '069143 6+Y[&(8!RU'*H0+fORU'063 '*HFw1*+.82XRU'06H0&).1 V +.'Q/<Me%&('*),+.-0//X-G+,<J3 8+u/:3 K+.'TY[8& V /2;*+/2;*+,<B3 10821*<J& Y{=n3 D&(10/dQ9J99_/X-+,<BAfW(3H0&).1 V +.'Q/:3 82X@5o3 '069143 6+1*<+,H@RU' V &9<2/Y[8+.'*);-010D05URN)3 '*H@10'0RUC+.8<RU/:3 82X@5URUD08:3 82RN+,<Meg_;*+>+fO-+.82R V +.'Q/E-08&MC+,H/2;*+@Yn+M3(<2RUD0RU5URU/X& Yh/2;*+>-08&(-G&9<:+,H<2XO<2/+ V =LPe 8Me /Me),& V -010/2RU'06s/2R V +A3 '*H3 'R V -08&C+,H8+.5N+.C93 '*),+ILPe 8Me /Me/&/2;*++fRN</2RU'06j<2XO<2/+ V D43(<+,H10-&(' W V 3 RU'05UXHO1*+/&/2;*+1*<+& Y<+ V 3 '/2RN)t8+.5o3 /2RN&('*<IRU'*</+M3(H& YlK+.XL&(8H0<&('05UXe z'*+t<2RNH0++f+,)./IL3(<3 5N<&/&-08&MC+y/2;*+RU'Q/+.8+,<2/F& Y><2R V -05N+698:3 -0;*<iY8& V 3 V &H0+.5URU'06kCRN+.L-&(RU'Q/Me '*H0+,+,HW/2;*+.RU8s698:3 -0;0RN)M3 5-08&(-+.82/2RN+,<+.'43 D05N+,Hi/&@D010RU5NHi3 'iRU'*H0+fRU'06 w1*+.82XRU'06/&&(5*/2;43 /]L_3(<),&('*<RNH0+.8+,Hs3(<+M3(<2XZ/&P1*<+_Yn&(8/2;*+RU'*H0+f0+.8<Mehg_;*+1*<+.8<!L+.8+ V 3(<2/+.8];Q1 V 3 '0RU/2RN+,<_<2/21*H0+.'Q/<W'*&(/3ML3 8+Y[8& V ),&('*),+.-0/2143 5a698:3 -0;*<'*+.RU/2;*+.8Y8& V u QLRU/2;i/2;*+u<& Y[/L_3 8+E3 '*HT3 'sRU'*H0+fRU'06l6910RNH0+9WO/2;*+.XDG+,)M3 V +Ew10RN)K5UX3 D05N+/&ZD010RU5NHIRU'*H0+f*3 /2RN&('*<MW0/2;43 /L+.8+P),&('*<2RNH0+.8+,H& Y{;0RU69;Iw143 5URU/XTDXF3Z<:+.'0RN&(8J5URUD08:3 82Ro3 '7eg_;*+i<+,),&('*Hj-08& 2+,)./>/:3 K+,<-05o3(),+\RU'K'*&L5N+,HO6+T+.'069RU'*+,+.82RU'06=[_&9<MWh_&(/+.5U5o3OW} ]3 '0;*+,+.69;*+9W`Mb9b9Afe /<q-01082-&9<+JRN<]/2;*+),&('*<2/2821*)./2RN&('F& Y/&&(5N<qY[&(8 V &H0+.5URU'063 '*H<R V 105o3 /2RU'06l;Q1 V 3 'T&(826Q3 '0R 3~/2RN&('*<MW3(<E+ V +.826+.'*).X-08&),+,HO108+,<Y[&(8uRU'*<2/:3 '*),+9ePz'*+ V 3 RU'HOR ).105U/XRU'yK'*&L5N+,HO6++.'069RU'*+,+.82RU'06RN<_/&ZC93 5URNH*3 /+P3 V &H0+.5URU'06*WOR$e+9e!/&):;*+,)Ks/2;43 //2;*+@+f-+.82/8+M3(<&('0RU'06RN<),&(828+,)./25UX V &H0+.5N+,Heqg_;0RN<C93 5URNH*3 /2RN&('yRN<E1*<143 5U5UXH0&('*+lL;*+.'y/2;*+ZH0+,<2RU69'SRN<@3();0RN+.C+,HW7;*+.8+DX<2R V 105o3 /2RU'06F/2;*+),&('*</2821*)./+,HV &H0+.5URU'06>& YG/2;*+&(826Q3 '0R 3 /2RN&('7e]_/!/2;0RN<h*'43 54<2/:3 6+9W V &HOR4)M3 /2RN&('*<3 8+JC+.82Xl),&9<2/25UXehg_;*+_K+.XlRNH0+M3& Y/2;*+J-08& 2+,)./]RN<]/&>&MC+.8),& V +/2;0RN<HOR ).105U/X\DX69RUCRU'06P/2;*++f-+.82/]/2;*+u3 D0RU5URU/X/&>1*<+J<2R V 105o3 /2RN&('RU'*<2RNH0+E/2;*+PH0+,<RU69'I).X).5N+P3(<3 V +M3 '& Yh+.'082RN):;0RU'06s3 '*HTD010RU5NHORU'06\;0RN< V &H0+.5URU'06*e]g_;0RN<JR V -05URN+,</2;43 //2;*+@);*&9<:+.' V &H0+.5URU'065o3 '069143 6+P+.'43 D05N+,</2;*+@+fO-G+.82//&lYn&(5U5N&ML8+M3(<:&('0RU'06<J<2/+.-FDQXT<2/+.-7W0HORU8+,)./25UX&('I;0RN<&ML' V &H0+.5UR 3 /2RN&('7e /L3(<uH0+,).RNH0+,HI/&D010RU5NH<21*);S3Z5o3 '069143 6+P10-&('),&('*),+.-0/2143 5{698:3 -0;*<Me?E+.'*+.8:3 5q),&('*),+.-0/2143 5698:3 -0;*<P+,wQ10RUC93 5N+.'Q/>/&sx{zu|L+.8+\'*&(/P),&('*<2RNH0+.8+,Hj3(<E6&&HS)M3 '*HORNH*3 /+,<PD+f~)M3 1*<+/2;*+.X3 8+RU'*H0+,+,H\3EHORo3 698:3 VV 3 /2RN)<2X</+ V & YG5N&(69RN)/2;43 /!RN<h'*&(/]3 /{/2;*+_+fO-G+.82/!5N+.C+.5$e '*<2/+M3(HW/2;*+E5o3 '069143 6+EL3(<J698&(10'*H0+,HF10-G&('F<2R V -05N+E698:3 -0;*<3 '*Hs+fO/+.'*<2RN&('*<>=[<1*);3(<_'*+,<2/2RU'06<& Y{698:3 -0;*<BAK+,+.-0RU'06I/2;*+.RU8@8+M3(H*3 D0RU5URU/Xez-G+.8:3 /2RN&('*< V R0+,H<2R V -05N+Z698:3 -0;tH0+,HO1*)./2RN&('=R$e+9e-08& 2+,)./2RN&('aAuLRU/2;'*&('H0+,).5o3 8:3 /2RUC+>-08&),+,HO108+,<Me]x}RU8</J+f-+.82R V +.'Q/<L+.8+>),&('*).5U1*<RUC+9eRe66e6<B^A{M}h{ $y } x08& V 3S),& V -010/:3 /2RN&('43 5uCRN+.L-&(RU'Q/MWL+F/2;0RU'0K/2;43 /\698:3 -0;O~D43(<+,Hj8+M3(<&('0RU'06<MWhD+.'*+f*/2/2RU'06Y[8& V 698:3 -0;O~$/2;*+,&(8+./2RN)M3 58+,<2105U/<W{)M3 'kD082RU'063 'jRU'Q/+.8+,</2RU'06y-+.8m~<2-+,)./2RUC+s/&5N&(69RN)s-08&(698:3 VV RU'06*ekX+f*3 V -05N+9W!/2;*+F+,wQ10RUC93 5N+.'*),+sDG+./L+,+.'^0?-08& 2+,)./2RN&('3 '*H;Afi3MfiuM%UH0+,HO1*)./2RN&('TRU'ix}zu|+$ * 4)M3 'iD+<:+,+.'T3(<_3 's3 5U/+.82'43 /2RUC+uC+.8<2RN&('T& Y7/2;*+PO(\(\($aQof 02(f=$%;43 '*HO8:3k +.825URU'7W@`Mb99AfW),&('*<RNH0+.8+,H3(<Y[10'*H*3 V +.'Q/:3 5Yn&(8H*3 /:3 D43(<+w1*+.82RN+,<s&(-0/2R V R 3 /2RN&('=[D0RU/+.DG&(105$W105U5$W uRo3 'Q17W>`Mb9b9vAfez/2;*+.8s8+,<2105U/<s3 8+&(D0/:3 RU'*+,HY8& V ),&('*</28:3 RU'Q/s-08&(698:3 V ~} p 4V RU'06*eSg_;*+T<2/28&('06+,wQ10RUC93 5N+.'*),+D+./L+,+.'{ 3 '*Hk/2;*+=[<:+,+u^+,)./MeOcOWL;*+.8+/2;*+/28:3 '*<mYn&(8 V 3 /2RN&('*<1*<+,H\K+,+.-T3 5U5a<&(5U10/2RN&('*<3 '*H-08+,<+.82C+/2;*+J<2/2821*)./2108+& Y/2;*+),&('*<2/28:3 RU'/]'*+./L&(82K\RU'\/2;*+wQ1*+.82X*A!3 5U5N&MLJ</&@/28:3 '*<25o3 /+/2;*+8+,<2105U/<&(D0/:3 RU'*+,HRU'/2;0RN<h5o3 /2/+.8]),& VV 10'0RU/X=DQXZ+f*3 V -05N+9W9/28:3()./:3 D05N+J)M3(<+,<hD43(<+,HZ10-&('/2;*+<2/2821*)./2108+J& YG/2;*+_698:3 -0;7W?E&(/2/25N&(D7W|+,&('*+9W^)M3 8),+.5U5N&0W4`Mb9b9bAfW(*8<2/h/&u} } hWQ/2;*+.'Z/&EH0+,HO1*)./2RN&('RU'x}zua| $ * 4feg_;*+T698:3 -0;</2821*)./2108+F)M3 '3 5N<&yDG+T1*<:+,H/&yH0+.C+.5N&(-+ ).RN+.'Q/s3 5U6&(82RU/2; V <RU' V &(8+F6+.'*+.8:3 5V &H0+.5N<]& Y7/2;*+_yYn3 V RU5UX{RU'\/2;*+ V &H0+.54L+)M3 5U5a =[<+,+JD+.5N&MLAfW0%&(105N&('*HO8+u3 '*HT^O3 5UC(3 /E=m`Mb9b9cA1*<+l/2;*+Z698:3 -0;O~$D43(<+,H'*&(/2RN&('t& Y]a$2:/&sD010RU5NHt3 't+ ).RN+.'Q/PD43():KL_3 8H~);43 RU'0RU'063 5U6&(82RU/2; V elg}&+.'0;43 '*),+P/2;*+PY[&(82L_3 8H~);43 RU'0RU'063 5U6&(82RU/2; V 1*<+,HIRU'I/2;*+ V &(8+P6+.'*+.8:3 5 V &H0+.5N<& Yh/2;*+>Y$3 V RU5UXW3 6+./t=n99O`As+f-08+,<<:+,<sH0+.-+.'*H0+.'*).RN+,<TD+./L+,+.'82105N+,<I3 '*H),&('*</28:3 RU'Q/<TRU'/+.8 V <F& Yl3698:3 -0;;*& V & V &(82-0;0RN< V ez108!3 R V RN</2;Q1*<{/&JD010RU5NH>Y[&(8 V 3 5O+fO/+.'*<2RN&('*<}& Y4<R V -05N+),&('*),+.-0/2143 5698:3 -0;*<MW(K+,+.-0RU'06u8+M3(H*3 D0RU5URU/X& Y]&(DO2+,)./<u3(<L+.5U5!3(<8+M3(<&('0RU'06<WG3 '*H-08+fY[+.8:3 D05UXWa5N&(69RN)M3 5U5UXFYn&(10'*H0+,Heg_;*+>kY$3 V RU5UXFRN<u3*8<2/<2/+.-FRU'I/2;0RN<HORU8+,)./2RN&('7e$v$|6Kv { $0F 2D{ v ;K* { $RR; <U&z{T|7+./}1*<'*&LjRU'OYn&(8 V 3 5U5UXP-08+,<+.'Q/}/2;*+q_sYn3 V RU5UXe{g_;*+q6+.'*+.82RN)-08&(D05N+ V /&JD+q<&(5UC+,HW hW3(<2KO<MW(69RUC+.'3uK'*&ML5N+,HO6+JD43(<:+E=[@JA{3 '*H\3u<2R V -05N+J698:3 -0;iW9L;*+./2;*+.8)M3 'DG+H0+,HO1*),+,HZY[8& Ve!),),&(8HORU'06>/&>/2;*+JKRU'*H0<]& Y7&(DO2+,)./<]),& V -&9<2RU'06W&('*+&(D0/:3 RU'*</2;*+HOR+.8+.'Q/ V + V DG+.8<& Y/2;*+Y$3 V RU5UXe '\/2;*+D43(<2RN) V &H0+.5aWRN<]),& V -&9<+,Hs& Y73><+./t& Y<2R V -05N+J698:3 -0;*<8+.-08+,<+.'Q/2RU'06lY$3()./<MW3 '*H<&(5UCRU'06 3 V &(10'Q/</&S);*+,):KL;*+./2;*+.8/2;*+.8+TRN<\3-08& 2+,)./2RN&('Y[8& V RU'Q/&teJ105N+,<u3 '*HI),&('*<2/28:3 RU'/<E3 8+ V &(8+P),& V -05N+f&(DO2+,)./<D43(<+,HI10-G&('y<2R V -05N+@698:3 -0;*<MWG3 '*H&(-+.8:3 /2RN&('*<H0+M3 5URU'06\LRU/2;I/2;*+,<:+P&(DOm+,)./<3 8+@D43(<+,HF10-&('F-08& m+,)./2RN&('7eg_;08&(1069;*&(10//2;0RN<J<+,)./2RN&('7W0L+@LRU5U571*<+@+f*3 V -05N+,<JRU'*<2-0RU8+,HsY[8& V 3 V &H0+.5UR 3 /2RN&('& Yq3lK'*&L5~+,HO6+\3(),w10RN<2RU/2RN&('j)M3(<+Z<2/21*HOXW7)M3 5U5N+,H*{*77,:.RU/@H0+,<).82RUD+,<>3i8+,<&(108),+3 5U5N&)M3 /2RN&('-08&(D05N+ V WL;*+.8+/2;*+\3 R V RN<E/&I3(<<RU69't& ),+,<@/&T-G+.8<:&('*<@& Y_3s8+,<+M3 8):;t698&(10-L;0RU5N+ZY[105*5U5URU'06I<& V +),&('O~<2/28:3 RU'/<=[3 6+./+./3 5$eUW7`Mb9b9bAfe}My| $y$y* {v { $64OfficenearOfficenearOfficeadjoinOfficeadjoinOfficenearResearchermemberProjectx}RU69108+vOqJ105N+,<CBUs+fO-08+,<<+,<K'*&ML5N+,HO6+T& Y_Y[&(8 V RYfiffRN<>-08+,<+.'//2;*+.' )M3 'kDG+s3(H0H0+,H :e /PRN<y|+.'*),&H0+,HFRU'Q/&s3Z<2R V -05N+@698:3 -0;I-08&CRNH0+,HLRU/2;I/L&),&(5N&(8<MW0/2;*+@*8<2/J),&(5N&(8<210D0698:3 -0;yH0+f*'0RU'06\/2;*+;fi M]|9M.tM=uwuMM3FOffice: #1adjoinOffice: #2adjoinnearOffice: #1Office: #3adjoinnearadjoinOffice: #2Office: #4nearadjoinOffice: #3nearnearnearnearadjoinOffice: #4x{RU69108+>O!J105N+3 -0-05URN)M3 /2RN&('*<;QX-&(/2;*+,<2RN<>3 '*H/2;*+\<:+,),&('*H),&(5N&(8P/2;*+\),&('*).5U1*<2RN&('7e 'tHO8:3,LRU'06<WL+8+.-08+,<+.'Q//2;*+;QX-&(/2;*+,<2RN<DQXyL;0RU/+'*&H0+,<MW3 '*HS/2;*+),&('*).5U1*<2RN&('jDQXy698:3,X&('*+,<MeZx{RU69108+\vT<2;*&MLJ<@/2;08+,+\82105N+,<Me 3 '*H8+.-08+,<+.'/PK'*&L5N+,HO6+3 D&(10/P/2;*+TG2(s8+.5o3 /2RN&('7W<10-0-G&9<+,Hy/&TD+H0+f*'*+,HD+./L+,+.'& ),+,<P&('05UXe+ ]FRN<2(3 'T& ),Y+ _W/2;*+.Z' _+fO-08+,<<+,</2;43 /_/2;*+E8+.5o3 /2RN&('SG2(lRN<_<2X VV +./282RN)M3 5]= RY{3 'F& ),bRN<uG2(E] AfW /2;43 / RY}3 'F& ),1+ ]j2.(0@3 's& ),Y+ _/2;43 /Pm,(0u3 'F& ),+ l/2;*+.' ]FRN<G2(:eg_;*+P82105N+ <:3,XO<J/2;43 /E+.C+.82XI8+,<+M3 8):;*+.8ERN< V + V D+.8@& Y3-08& 2+,)./Z= RYq/2;*+.8+RN<E38+,<+M3 8):;*+.8]}WO/2;*+.8+PRN<3Z-08& 2+,)./J& Y{L;0RN):g; ]RN<3 V + V D+.8 Afe105N+,<>3 8+1*<+,HS/&F+.'082RN):;tY$3()./<MERY/2;*+\;QX-G&(/2;*+,<2RN<>& Y3s82105N+\)M3 'jDG+Z-08& 2+,)./+,HRU'Q/&3^0?ZW/2;*+.'F/2;*+E82105N+ERN<3 -0-05URN)M3 D05N+@/&Z/2;0RN<^0?W*3 '*HTRU/<),&('*).5U1*<2RN&(')M3 'FD+E3(H0H0+,HI/&Z/2;*+>^0?3(),),&(8HORU'06/&/2;*+-08& 2+,)./2RN&('7e &(/2RN),+s/2;43 /Z+M3();-08& m+,)./2RN&('& Y3<:3 V +i82105N+i/&S3S^0? H0+f*'*+,<\3HOR+.8+.'/L3MX& Y3 -0-05UXRU'06k/2;0RN<i82105N+S3 '*HRN<i5URUK+.5UX/&k3(H0H'*+.LRU'OYn&(8 V 3 /2RN&('/&j/2;*+S^0?Ze%&('*<2RNH0+.8Yn&(8RU'*<2/:3 '*),+@/2;*+l^0#? & Y!x{RU6*eqOW0L;0RN);yH0+,<).82RUDG+,<<2-43 /2Ro3 57RU'OYn&(8 V 3 /2RN&('3 DG&(10/& ),+,<MW43 '*HF82105N+,<J&x{RU69108+lvOe RN<E3 -0-05URN)M3 D05N+F=[<2RU'*),+sQm.9pB\G(9AfW3 '*Hy<&\RN< e|7+./E1*<u),&('*<2RNH0+.8 eg_;*+.8+3 8+s/L&SL3,XO<& YE3 -0-05UXRU'06S/2;0RN<Z82105N+9WqH0+.-+.'*HORU'06t&('kL;*+./2;*+.8RU/<l;X-&(/2;*+,<2RN<ZRN< V 3 -0-G+,H&('/&/2;*+P-43 /2V;I6!"TT# $> %"$a&# s&(8&('Q/&/2;*+-43 /2; &# $!$TT $> %$aT( ' 4e '/2;*+*8<2/)M3(<+yYn&(8FRU'*<2/:3 '*),+9W@3k8+.5o3 /2RN&(''*&H0+ tLRU/2;-08+,H0+,),+,<<&(V8I63 '*H<1*),),+,<<&(8&# kRN<s3(H0H0+,H/&t/2;*+S^0?Zae u&(/2RN),+I/2;43 /iRU'/2;0RN<s+f03 V -05N+9WJ3 -0-05UXRU'063 5U582105N+,<iRU'3 5U5-&9<<2RUD05N+@L_3,XO<u3(<5N&('06s3(<J/2;*+.X3(H0H'*+.LRU'OYn&(8 V 3 /2RN&('RN<u3Z*'0RU/+P-08&),+,<<l=5N+M3(HORU'06i/&/2;*+>698:3 -0;& Yhx{RU69108+>AD010/RU/RN<'*&(//2821*+@RU'I6+.'*+.8:3 5$er;*+.'\/2;*+J@RN<q),& V -&9<+,H\& Y73@<+./& YaY$3()./<]3 '*H3@<:+./q& Y82105N+,<&W/2;*+ -08&(DO~5N+ V 3(<2KO<L;*+./2;*+.8@/2;*+.8+lRN<@3<:+,wQ1*+.'*),+Z& Y]82105N+3 -0-05URN)M3 /2RN&('*<P+.'082RN):;0RU'06F/2;*+>Y$3()./<E<21*);S/2;43 /u/2;*+6&3 5h)M3 'D+@8+M3():;*+,HW4R$e+9e5N+M3(HORU'06s/&3698:3 -0;RU'Q/&\L;0RN):;/2;*+Z^0?)M3 'D+@-08& 2+,)./+,He e 6*e),&('*<2RNH0+.8/2;*+_Yn3()./ & Y7x{RU69108+OW3 '*H5N+./D+_/2;*+u^0%? &#( ' $) $aTTs= RN<('u'*+M3 8h3 'l& ),+ AfeqH0&+,<'*&(/{-08& m+,)./{RU'Q/&@W D010/h3 -0-05UXRU'06u/2;*+]82105N+,<MW9&('*+_3(H0H0<}/2;*+]RU'OYn&(8 V 3~/2RN&(' T( ') T$TT F=n3 5N<& TT( 'T"TT# AfW/2;Q1*<u3 '*<2L+.82RU'06Fe*445&4&4444v { $4 AGq&(0.[m9p4>)M3 'jD+-G&9<RU/2RUC+&(8>'*+.6Q3 /2RUC+9W!+fO-08+,<<2RU'06K'*&L5N+,HO6+T& YYn&(8 V RYM}h A{% }Aff ;*&(5NH0<MW<& V 1*<2/* :W&(8 RY+ff;*&(5NH0<MW, V 1*<2/s'*&(/ :e /iRN<s3 5N<:&3D0RN),&(5N&(8+,H<2R V -05N+698:3 -0;7/2;*+l*8<2/@),&(5N&(8PH0+f*'*+,<@/2;*+),&('*HORU/2RN&('t-43 82/=[&(8\[fUMQfAfW3 '*HS/2;*+<+,),&('*H),&(5N&(8@/2;*+ V 3 '*H*3 /&(82X=[&(8PYn&(82D0RNH0H0+.'aAE-43 82/MeF ^0? <:3 /2RN<24+,<3F-&9<2RU/2RUC+i),&('*<2/28:3 RU'Q/ RY2.j-08& m+,)./2RN&('Y[8& V /2;*+),&('*HORU/2RN&('F-43 82/J& RU'/o& )M3 'TDG+E+fO/+.'*H0+,Hi/&3-08& 2+,)./2RN&('I& Y}/2;*+uL;*&(5N+ eh'*7H <B3 /2RN<m4+,<3j'*+.6Q3 /2RUC+y),&('*</28:3 RU'Q/TRYa-08& 2+,)./2RN&('& YP/2;*+y),&('*HORU/2RN&('&RU'Q/& )M3 'D+y+f/+.'*H0+,H/&3-08& m+,)./2RN&('& Yu/2;*+TL;*&(5N+ etx{RU6*e<;*&MLJ<Z/L&t),&('*<2/28:3 RU'/<Meg_;*+T'*+.6Q3 /2RUC+F),&('*</28:3 RU'Q/fi05;!-fi3MfiuM%workswithPersonHeadOfGroupSecretaryPersonOfficeOfficenearOfficex{RU69108+%&('*<2/28:3 RU'/<=4 R4+fO-08+,<<+,</2;43 / /L&i-+.8<&('*<L&(82KRU'06s/&(6+./2;*+.8<2;*&(105NHF'*&(/u<2;43 8+>3 'y& ),+ :eg_;*+Z^0? & Yqx{RU6iH0&+,<u'*&(/@<:3 /2RN<mY[XF/2;0RN<E),&('*<2/28:3 RU'Q/@D+,)M3 1*<+ /2;*+.8+lRN<E38+,<+M3 8):;*+.8@L;*&iL&(82K<uLRU/2;S8+,<+M3 8):;*+.8s=-08& 2+,)./2RN&('& Y]/2;*+),&('*HORU/2RN&('-43 82/@& oIA 3 '*Hy/2;*+.X<2;43 8+Z& ),+/.s`M T=[+fO/+.'*<2RN&('& Yq/2;*+-08& 2+,)./2RN&('/&T3-08& 2+,)./2RN&('y& Yq/2;*+L;*&(5N+ IAfeJg_;*+-G&9<RU/2RUC+),&('*<2/28:3 RU'/ +f-08+,<:<+,</2;43 //2;*+& ),+P& Yq3l;*+M3(HI& Yh698&(10- V 1*<2/DG+E'*+M3 8J/2;*+>& ),+,<& Yq3 5U57<+,).8+./:3 82RN+,<Mer;*+.'/2;*+F@RN<),& V -&9<+,H& Y@3<:+./\& YY$3()./<\3 '*H3S<+./& YE),&('*<2/28:3 RU'Q/<\hW]/2;*+i8&(5N+F&),&('*<2/28:3 RU'/<IRN<F/&H0+f*'*+S/2;*+t),&('*<RN<2/+.'*).X& Yl/2;*+SD43(<+9WuR$e+9e& YZeg_;*+D43(<+SRN<F<:3 RNH/&D+),&('*<2RN<2/+.'/RY3 5U5{),&('*<2/28:3 RU'Q/<P3 8+<:3 /2RN<m4+,He 8&MCRNH0+,H/2;43 //2;*+>D43(<:+PRN<u),&('*<2RN<2/+.'Q/MWH0+,HO1*)./2RN&('yRN<H0&('*+3(<uRU'__e C+.'yRY/2;*+.Xy3 8+DG&(/2;SD0RN),&(5N&(8+,Hy698:3 -0;*<MW),&('*<2/28:3 RU'/<>3 8+>'*&(/E/&iDG+Z),&('OY[1*<+,HLRU/2;I82105N+,<Me]%&('*<RNH0+.8JYn&(8RU'*<2/:3 '*),+@/2;*+ED0RN),&(5N&(8+,HI698:3 -0; & Y!x{RU69108+PvO]3(<3l82105N+9W0RU/J<B3,XO</2;43 /+.C+.82Xt8+,<+M3 8):;*+.8ZRN<l3 V + V D+.8l& YE3F-08& 2+,)./Meg{3 K+/2;*+Yn3()./10 0T T2 ac3 '*H/2;*+w1*+.82Xi+0 0 2 a$43 !35 "$a76 8 F= RN<e V + V D+.8& Y}3@-08& 2+,)./ Afe Y{RN<3(<2K+,Hi&('"ff$n+*) "m n4fW/2;*+3 '*<2L+.8]RN< X+,< :e u&MLPW<+,+ 3(<3E-&9<2RU/2RUC+),&('*<2/28:3 RU'/ \e /<:3MX<]/2;43 /]+.C+.82XZ8+,<+M3 8);*+.8 V 1*<2/DG+J3 V + V D+.8& Y3E-08& 2+,)./Me!"ff$n+*m"m kn4!RN<!RU'*),&('*<2RN<2/+.'/MW/2;Q1*<'*&(/2;0RU'06)M3 'ID+@H0+,HO1*),+,HFY[8& V RU/MW0RU'*).5U1*HORU'06s\eqg_;*+@@;43(</&ZD+@8+.-43 RU8+,HT*8<2/Me44]; &G4q|7+./>1*<@),& V D0RU'*+\82105N+,<3 '*H),&('*<2/28:3 RU'Q/<>RU'8+M3(<&('0RU'06*e^ }h }h y| {%}}$AA{% }Art+PHORN<2/2RU'06910RN<;I'*&MLD+./L+,+.'/L&\KRU'*H0<J& Yh82105N+,<M_M,.2fG:BNBl3 '*HS? ( O[n(SBUffe'OY[+.8+.'*),+Z82105N+,<P8+.-08+,<+.'Q/PR V -05URN).RU/>K'*&L5N+,HO6+/2;43 /@RN< V 3(H0++f-05URN).RU/@DX82105N+\3 -0-05URN)M3 /2RN&('*<eg_;0RN<PRN<>/2;*+\)M3(<+ZYn&(8P82105N+,<<+,+.'3 D&MC+=[x{RU69108+svAfex43()./<Z3 '*HRU'OYn+.8+.'*),+\82105N+,<>)M3 'jDG+\<:+,+.'3(<H0+,<).82RUD0RU'063sL&(825NHW}3 '*Ht3 -0-05UXRU'063s82105N+ V &HOR4+,<P/2;*+\+f-05URN).RU/PH0+,<:).82RU-0/2RN&('j& Y/2;*+ZL&(825NH=/2;*+Y$3()./<BAfCe u&MLPWRYL+),&('*<2RNH0+.83T@),& V -G&9<+,Hj& Y_3T<+./@& Y]Y$3()./<>W3T<+./@& YRU'OY[+.8+.'*),+82105N+,<9W3 '*H3y<+./l& YE),&('*<2/28:3 RU'Q/<l!W!/2;*+s'*&(/2RN&('& Y),&('*<2RN</+.'*).Xj;43(<Z/&/:3 K+T82105N+,<RU'/&t3(),),&(10'Q/Mex*&(8RU'*<2/:3 '*),+9W03(H0Hi/&>/2;*+@^0?Ed< 3 '*H& Yx{RU69108+u>/2;*+Y[&(5U5N&LRU'06lRU'OYn&(8 V 3 /2RN&('I3 DG&(10/_& ),+E3(<<2RU69'O~;: T"< 8 "=24a> $L!"TT#7I64W 4? @7+:L!$TTV +.'Q/<o3 '*QH 4? @Aa6L!$TT 4eh|7+./ 3 '*H D+/2;*+='*&(8 V 3 5pA_^0?E<&(D0/:3 RU'*+,He%&('*<2RNH0+.8P/2;*+\L&(825NHj),& V -&9<+,Ht& Y_/2;*+i^0? b[WRU'OY[+.8+.'*),+\82105N+,< * n& Y_x{RU69108+ivOW{3 '*HS/2;*+-&9<2RU/2RUC+F),&('*<2/28:3 RU'Q/ & YEx{RU69108+eg_;*+^0? 3 5N&('*+IH0&+,<'*&(/\<:3 /2RN<2YX/2;*+F),&('*<2/28:3 RU'Q/=D+,)M3 1*<+ /2;*+T;*+M3(Hk& Yu698&(10-|qehRN<lRU'& ),+B7I9W]3 '*Hk/2;*+F<+,).8+./:3 82X ehRN<lRU'& ),+B :W!D010/RU/ZH0&+,<'*&(/Z;*&(5NHj/2;43 / %7IRN<'*+M3 8C Afe10/3Y/+.83),+.82/:3 RU'k'1 V D+.8& Y82105N+s3 -0-05URN)M3 /2RN&('*<WRU/>H0&+,<Mesg_;Q1*<P/2;*+i@RN<><:3 RNHt/&FDG+),&('*<2RN<2/+.'Q/Me 't/2;0RN<>)M3(<:+RU/PRN<>+M3(<Xy/&H0+f*'*+i3 '*Hj):;*+,)K),&('*<2RN<2/+.'*).XDG+,)M3 1*<+>/2;*+>L&(825NHSH0+,<).82RU-0/2RN&('y)M3 'yD+>),& V -05N+./+.5UX+fO-05URN).RU/+,HDQX3*'0RU/+Z^0? =/2;*+W7<:3 RNH/&FD+EfaLPe 8Me /MeCTAfW/2;Q1*<PRU/P<1 ),+,<P/&I):;*+,)K/2;43 /P/2;0RN<@698:3 -0;RN<P),&('*<2RN<2/+.'/Me698:3 -0;'6+.'*+.8:3 5J)M3(<+9W!),&('*<RN<2/+.'*).Xj8+.5URN+,<&('kL;*+./2;*+.8\+M3(); ),&('*<2/28:3 RU'/\CRN&(5o3 /2RN&(' T)M3 'D+s8+.-43 RU8+,H97944d;4 ;;.fi M]|9M.tM=uwuMM3FDQXT82105N+l3 -0-05URN)M3 /2RN&('*<MWa3(<LRU5U5D+uY[&(8 V 3 5U5UXIH0+f*'*+,H5o3 /+.8Meu<LRU/2;<R V -05N+.8JL&(825NH0<uH0+,<).82RUD+,HIDQXY$3()./<J&('05UXW*H0+,HO1*)./2RN&('RN<J'*&(/-G&9<<RUD05N+@&('IRU'*),&('*<2RN<2/+.'/K'*&ML5N+,HO6+PD43(<:+,<MePersonOfficex}RU69108+cO!82105N+C&(5U10/2RN&('j82105N+,<E8+.-08+,<+.'Q/P-&9<<2RUD05N+3()./2RN&('*<@5N+M3(HORU'06TY[8& V &('*+ZL&(825NHS/&F3 '*&(/2;*+.8>&('*+9e e 6*e),&('*<2RNH0+.8/2;*+>),&(5N&(8+,HI698:3 -0;y& Yqx}RU69108+lcOeu<3 'RU'OY[+.8+.'*),+>82105N+9W*RU/L&(105NH3 5U5N&L/&\H0+,HO1*),+>/2;43 /3 5U5-G+.8<:&('*<_3 8+uRU'I3 5U5& ),+,<Mequ<3 'T+.C&(5U10/2RN&('F82105N+9WRU/<:3MX<_/2;43 / L;*+.'T/2;*+.8+P3 8+@3>-+.8<&('F3 '*H3 'I& ),+9W43l-&9<<2RUD05N+@3()./2RN&('IRN</&\3(<:<2RU69'T/2;0RN<J& ),+@/&Z/2;43 /-+.8<&(' :e%&('*<2RNH0+.83Z@),& V -&9<+,H& Y3i<+./& YqY$3()./<EW3<+./u& Y]+.C&(5U10/2RN&('S82105N+,<D]W3 '*HS3\<+./E& Y]),&('*<2/28:3 RU'Q/<u!eux43()./<EH0+,<).82RUDG+Z3 'RU'0RU/2Ro3 5{L&(825NH+.C&(5U10/2RN&('S82105N+,<8+.-08+,<:+.'Q/E-G&9<:<2RUD05N+P/28:3 '*<2RU/2RN&('*<Y[8& V &('*+>L&(825NHy/&s&(/2;*+.8L&(825NH0<M),&('*<2/28:3 RU'/<H0+f*'*+u),&('*<2RN<2/+.'*).X\& Y+M3():;iL&(825NH03P<21*),),+,<<:&(8& Y}3P),&('*<RN<2/+.'Q/L&(825NHiRN<]&(D0/:3 RU'*+,HsDQX3 'I+.C&(5U10/2RN&('I82105N+P3 -0-05URN)M3 /2RN&('7069RUC+.'3\^0?\WO/2;*+@H0+,HO1*)./2RN&('I-08&(D05N+ V 3(<2KO<_L;*+./2;*+.8J/2;*+.8+ERN<J3-43 /2;& Y!),&('*<2RN<2/+.'/JL&(825NH0<u+.C&(5UCRU'06\Y8& V /2;*+@RU'0RU/2Ro3 5}&('*+@/&\3ZL&(825NH<:3 /2RN<mY[XRU'06i\eg_;*+ V &9<2/l6+.'*+.8:3 5 V &H0+.5& YJ/2;*+sYn3 V RU5UXj),&('*<RNH0+.8<ZDG&(/2;kKRU'*H0<Z& Y82105N+,<W_0 5W 53<+./(& Y]RU'OYn+.8+.'*),+Z82105N+,<MW3 '*H3i<:+./ED& Y+.C&(5U10/2RN&('82105N+,<e 'y/2;*+l-43 82/2RN).105o3 8P)M3(<+Z& Y]/2;*+i*{*77,:V &H0+.5UR 3 /2RN&('7WI3 '*H9H0+,<).82RUD+!/2;*+qRU'0RU/2Ro3 5RU'OYn&(8 V 3 /2RN&('Z3 D&(10/}& ),+]5N&)M3 /2RN&('*<MW -+.8<&('*<}3 '*H>/2;*+698&(10-&(826Q3 '0R 3 /2RN&('7eF3 5N<&@+.'*),&H0+,<q6+.'*+.8:3 54K'*&ML5N+,HO6+>=[<21*):;i3(<!-08&(-+.82/2RN+,<q& Y/2;*+P( i8+.5o3 /2RN&('-010/D+./L+,+.'/L&\),&('*),+.-0/J'*&H0+,<8+.-08+,<+.'Q/2RU'06iHORN<2/2RU'*)./+.'Q/2RU/2RN+,<fAfe!8+.-08+,<:+.'Q/<&(D05URU6Q3 /2RN&('*<u3 '*HRU'Q/+.8HORN)./2RN&('*<H0+f*'0RU'06L;43 /3(),),+.-0/:3 D05N+t3(<<2RU69' V +.'/<3 8+=RU'*).5U1*HORU'06)M3 8HORU'43 5URU/X),&('*<2/28:3 RU'/<<21*):;j3(< 3-+.8<&('t)M3 '0'*&(/@D+spk<+.C+.8:3 5!& ),+,< Z&(8 3s5o3 826+& ),+)M3 '0'*&(/P),&('/:3 RU' V &(8+Z/2;43 '/L&-+.8<&('*< :W!1*<2RU'06/2;*+( 8+.5o3 /2RN&('aAfeGD),&('*<2RN<2/<& YE&('*+T+.C&(5U10/2RN&('82105N+TL;*&9<+s8+,<2105U/RN<Z/&-05o3(),+>3Z-+.8<&('IRU'/&3 '& ),+s=RU/),&(105NH3 5N<&D+@),& V -&9<+,HI& Yq<+.C+.8:3 5782105N+,<),&('*<2RNH0+.82RU'06i<2-+,).R4)-08+,),&('*HORU/2RN&('*<TD+fY[&(8+/282XRU'063 '3(<<2RU69' V +.'/BAfeg_;*+6&3 58+.-08+,<+.'/<F3t<2RU/2143 /2RN&('L;*+.8++M3():;-+.8<&('& YP/2;*+698&(10-;43(<T3 '& ),+9e <&(5U10/2RN&('/&t/2;*+-08&(D05N+ V RN<T3jL&(825NH&(D0/:3 RU'*+,HY[8& V/2;*+RU'0RU/2Ro3 5]&('*+\DQXt3T<+,w1*+.'*),+\& Y_& ),+i3(<<2RU69' V +.'Q/<WL;*+.8+\+M3():;t-+.8<&('t;43(<>3 'j& ),+9WL;0RU5N+<:3 /2RN<mY[XRU'06/2;*+>3 5U5N&)M3 /2RN&('),&('*<2/28:3 RU'Q/<Me446p454 54hy _46z{4444|7+./J1*<J'*&ML<2-+,).RY[XsH0+f*'0RU/2RN&('*<u3 '*HF'*&(/:3 /2RN&('*<),&('*),+.82'0RU'06i/2;*+@jY$3 V RU5UXe}9 0f2 pfi;}]} uy ),&(5N&(8+,Hj<2R V -05N+698:3 -0;o\O( " $k)* H4oh9a/Hko\F\BQap@fm( $[4\pa$Zm%I *WIn5UOZ*f B.M,[9$IGMQ\o(U2}Ol),&(5N&(8ZmPOPaMQW5e >fa9ZS: KJ ML OEf0$(mf4mH pa9O:TL:[3!:(922sGMQBW5UOB*n(2B4 JON L Zf.9BE}$N p5 J5 OG. 02(Bum2.9[n(TaMEmJPN L ZQ.}( .fU($ JON L RT5fig ;*+E5o3 /2/+.8),&('*HORU/2RN&('k= JON L V 1*<2/_Yn&(8 V 3\^0?PARN<_'*+,),+,<<B3 82XT3(<<&&('I3(<_L+P),&('*<RNH0+.882105N+,<3(<_),&(5N&(8+,HI^0?E<Mh<2;*&(105NHT3P82105N+'*&(/_<:3 /2RN<mY[X/2;0RN<),&('*HORU/2RN&('7WORU/<3 -0-05URN)M3 /2RN&('F&('F3l^0?),&(105NHs6+.'*+.8:3 /+3l698:3 -0;I/2;43 /JRN<J'*&(/3\^0?Ze@RN<ZH0+.'*&(/+,HDX" $n+*)g*)*m4fW]L;*+.8+FRN<l3y<+./Z& Y<2R V -05N+i698:3 -0;*<Z8+.-08+,<+.'/2RU'06Y$3()./<MWWDj3 '*HsS3 8+u/2;08+,+@<+./<_& Y{),&(5N&(8+,HF<R V -05N+E698:3 -0;*<_8+,<2-G+,)./2RUC+.5UXi8+.-08+,<+.'Q/2RU'06pMMffa:fNBfWS ?( [n(BUffW3 '*H(*f[2(paI=-&9<2RU/2RUC+Z&('*+,<ERU'yRQ_WG'*+.6Q3 /2RUC+\&('*+,<ERU'yTS}Afe?uRUC+.'j3;fi3MfiuM%@3 '*Hi3E6&3 5\W/2;*+>Q(OM[[(amfU.3(<2KO<qL;*+./2;*+.8)M3 'DG+JH0+,HO1*),+,H\Y8& V =L+'*&(/+P >Afe YL+R V -G&9<:+<& V +J& Y7/2;*+<+./<&yWDS&(8!I/&PD+J+ V -0/XW&('*+&(D0/:3 RU'*<<-G+,).R4)8+M3(<&('0RU'06e u&(/+E/2;43 /RU'F/2;*+>3 D*<+.'*),+>& Yh),&('*<2/28:3 RU'/<l=p" AfW*RU'OY[+.8+.'*),+>3 '*H+.C&(5U10/2RN&('82105N+,<J;43MC+V &H0+.5N<M/2;*+P<:3 V +PDG+.;43MCRN&(8MW4/2;Q1*<fi 3 '*HUDk)M3 'IDG+@),&('OY[1*<+,Heg_;*+PjY$3 V RU5UXTRN</2;*+.'),& V -&9<+,HI& Yh/2;*+<2RsY[&(5U5N&LRU'06 V &H0+.5N<MeF/2;*+P V &H0+.5Yn&(8JW0 $n+*fig*XD* 4/2;*+P V &H0+.5Yn&(8JW0$n+* * *J.4/2;*+P\ V &H0+.5Y[&(8JY0 $na*Eg*@ *4/2;*+PD V &H0+.57Y[&(8JW0 $n+*F *fiD*_4V /2;*+P V &H0+.57Y[&(8JW0 $n+* * * 4VVVVV /2;*+PCD7 V &H0+.5Yn&(8JW0 $n+*Xg*,Da*.4^RU'*),+3EYn3()./q;43(<q/2;*+J<:3 V +J<+ V 3 '/2RN),<3(<3E82105N+LRU/2;i3 '+ V -0/XZ;QX-G&(/2;*+,<2RN<W/2;*+J<+./RN<]1*<+,HRU' V &H0+.5N<h'43 V +,<!&('05UXL;*+.'DG&(/2;Z82105N+_<+./<F3 '*H(D3 8+_+ V -0/Xe!g_;*+;0RN+.8:3 8):;QX& Ya/2;*+,<+ V &H0+.5N<NR <8+.-08+,<+.'Q/+,HyRU'x{RU6*eGbOe /;0RU69;05URU69;Q/<u/2;*+lH0+,).RNH*3 D0RU5URU/X-08&(-+.82/2RN+,<E3 '*H/2;*+),& V -05N+fRU/X& Y!/2;*+3(<<&).Ro3 /+,HsH0+,HO1*)./2RN&('s-08&(D05N+ V ea&(/2RN),+L+uHORUCRNH0+'*&('TH0+,).RNH*3 D05N+-08&(D05N+ V <_RU'/&i,fZM!Q2,[fU3 '*H[f; :GQ2.nQfN-08&(D05N+ V <Me 'T/2;*+*8<2/J)M3(<+9W03 '3 '*<2L+.8J)M3 'FD+E),& V -010/+,HFRU's*'0RU/+E/2R V +Yn&(83 5U57-G&9<RU/2RUC+@RU'*<2/:3 '*),+,<JD010/'*&(/Y[&(83 5U5'*+.6Q3 /2RUC+>&('*+,<Me 'F/2;*+P<:+,),&('*HI)M3(<+9W0/2;*+.8+@RN<J'*&Z*'0RU/+-08&),+,HO108+9W0'*+.RU/2;*+.8JYn&(83 5U57-&9<2RU/2RUC+ERU'*<2/:3 '*),+,<MW0'*&(8JY[&(83 5U5'*+.6Q3 /2RUC+&('*+,<MeZ[\%]g782105UXT10'*H0+,).RNH*3 D05N+Z[F]Z\!]^+ V R~H0+,).RNH*3 D05N+Z[_` ~),& V -05N+./+Z8^]Z8^~),& V -05N+./+x{RU69108+>bOqg_;*+@_tY$3 V RU5UX V &H0+.5N<3 '*HI),& V -05N+fRU/XF& Y{/2;*+>3(<:<&).Ro3 /+,HFH0+,HO1*)./2RN&('-08&(D05N+ VaqEcb"]$Mk]jEd!]4fiB aUi(2B4fN=$^0?82105N+A+ V D+,H0<\K'*&ML5N+,HO6+y& YEY[&(8 V RY9ff /2;*+.'e :eg_;*+FY[&(5U5N&LRU'06H0+f*'0RU/2RN&('3(<3),&(5N&(8+,H^0?RN<Z+,wQ10RUC93 5N+.'Q/Z/&/2;*+ V &(8+s/28:3(HORU/2RN&('43 5H0+f*'0RU/2RN&('& Y3I82105N+F3(<3 '&(DO2+,)./Z),& V -&9<+,H& Yu/L&j^0?@<Z8+.5o3 /+,HLRU/2;),&(8+fYn+.8+.'*),+F5URU'0KO<l1*<+,HkDQX?@&9<2;3 '*Hr1QL&('06<:+=m`Mb9b9vAfW*&(8u^O3 5UC93 /3 '*HF1069'0RN+.8=m`Mb9b9Afe;fi M]|9M.tM=uwuMM3Ffffi;}]}$k{%}uA{M}hoTt(U(2J{15 JON L pT:(pN2tT;QX~yn <2R V -05N+i698:3 -0;82105N+fi;}]}gf-&(/2;*+,<2RN<L=(a J L [),&('*).5U1*<2RN&('5E+,HO1*)./2RN&('H0+.-G+.'*H0<i&('/2;*+F'*&(/2RN&('& Y>3BNfa [[[(hRU/\RN<i3S698:3 -0;/28:3 '*<mYn&(8 V 3 /2RN&('D43(<+,HF10-&('F-08& 2+,)./2RN&('7eZ8}= (a ZifNW5 o3 -0-05UR~.fi;}]}ih ` M{M} j{)M3 D05N+S$7 \OfI)j9o.iGmmM2,[n(=u.T: =}f2( JON L NO\:BO9OfBpsm RI4$Z85gB9 ,S= OZBBmZOs3 -0-05URN)M3 /2RN&('j& &('3(),),&(8HORU'06I/&plOr} Q.$(G2SS:\ sO(o.9p4]4[(mH (aTm>sBF: J L N Ol(a. Bn(tm Rq= O.=4,(S? fS:2M7$MA*y>*364>=jh9 O.2k JPN L (a J L @= (S(2MQ!9 O.9\*fF.9 f$ W>4 9asO>:BF: md5+ oE.9[i$Fl(R VV +,HORo3 /+ ~H0+.82RUC93 /2RN&('TB2(qo5H0+.82RUC(3 /2RN&('RN<3I=-&9<<2RUD05UXi+ V -0/X0AJ<+,w1*+.'*),+@& Y{82105N+>3 -0-05URN)M3 /2RN&('*<fi;}]}gk ,yn 3{M} .l lM.2@BUf>=(arl{151el(\~H0+.82RUC93 /2RN&('fm( $ TMy.*fa:F2C{[ q" N * F6F6F *" fO.O9M=7.9rIZ\Vj\ K = p\(Gl29[9 !mQff'?[[(lfm( =h9 pPfN>pm5g}&lH0+,HO1*),+E3Z^0?\WQL+ V 1*<2/_DG+u3 D05N+/&lH0+.82RUC+@3l^0?RU'Q/&lL;0RN):;I)M3 'sD+J-08& 2+,)./+,Heqg_;0RN<'*&(/2RN&('IRN<J)M3 -0/2108+,HDQXs/2;*+EYn&(5U5N&MLRU'06iH0+f*'0RU/2RN&('7Kv { $u. " $n+*)4yonbX(atU.E :J}15 :(:fi;}]} 2iQ29O:fm( N a9$9[n(t P n$ +*)4cR \OfF)j(pfi(pg!mQff'? 9[[9sf2( $S}B0fI9! P 5MMM{{%}Mg_;*+<+ V 3 '/2RN),<RN<@+f/+.'*H0+,HS/&s/28:3 '*<25o3 /+Z82105N+,<Mu69RUC+.'j3i82105N+ W5N+./ N 3 '*H DG+l/2;*+l/L&^0?E<8+,<-G+,)./2RUC+.5UX),&(828+,<2-&('*HORU'06j/&SRU/<;QX-G&(/2;*+,<2RN<i3 '*HRU/<\),&('*).5U1*<2RN&('7W_R$e+9e N " JON L 3 '*HRN<i/2;*+S^0? &(D0/:3 RU'*+,HY[8& V J L DQX3(H0HORU'06k/2;*+'*+.RU69;DG&(8<T& YP/2;*+8+.5o3 /2RN&(''*&H0+,<i& J LL;0RN);3 8+I),&('*),+.-0/s'*&H0+,<i& JPN L eg_;*+.'[$ 4Z" ] FtFtF ] $ +$ N 4_ FtFtF _ $ 42ANNL;*+.8+ $ 4_3 '*H +$ 4_3 8+E/2;*+@),&('(m10'*)./2RN&('*<& Y!3 /& V <3(<<&).Ro3 /+,HTLRU/2; 3 '*H W ] FtFtF ]3 8+i/2;*+C93 82Ro3 D05N+,<Z& +$ N 4>3 '*H _ FtFtF _ \3 8+i/2;*+C93 82Ro3 D05N+,<Z& +$ 4@/2;43 /H0&'*&(/3 -0-G+M3 8lRU'$ N 4feFx4&(8>RU'*<2/:3 '*),+9Wh),&('*<2RNH0+.8l/2;*+\82105N+ RU'x{RU6*e}vOeTg_;*+.'[$ 4E"]`$JB,(m.OfA $M])4_)$2m,,c $M_4 ff $M]*y_4y4y4fe ^;*&(105NHL+SRU'/+.82-08+.//2;*+),&(5N&(8+,H698:3 -0;RU'x{RU6*eJ3(<3s82105N+9W7RU/<@Y[&(8 V 105o3FL&(105NHtDG+j$ 4b"ff]_$y$J.:,( $M]4 JJ.:,( $M_4 9]( MS !c9![ $M]*y_4y4$ rq: $ 4 p$M]* 4 $M_* 4y4y4fe u&(/2RN),+9W 10'05URUK+]RU'Z).5o3 1*<+,<MW C93 82Ro3 D05N+,<-08&(-+.8{/&J/2;*+),&('*).5U1*<2RN&('3 8+P+fORN<2/+.'Q/2Ro3 5U5UXFw143 'Q/2R4+,Heg_;*+EYn&(5U5N&MLRU'06s<&(10'*HO'*+,<<3 '*H),& V -05N+./+.'*+,<<J8+,<2105U/RN<J&(D0/:3 RU'*+,HRp+G=G!rC ` ff$<UCuvu w 7t Cu|uhy|MyqhM}]y|f + { 3{ kJ .!{ 3{Zo}15UOf P $na*)74> j$4*Bj$n4*Bj$t74 I[$$E465<.ffff"$n+*)74\\snYX(aiu&(/2RN),+J/2;0RN<8+,<2105U/3(<<1 V +,<]/2;43 /698:3 -0;*<3 8+69RUC+.'RU'\'*&(8 V 3 5aY[&(8 V WO3 '*HWRY'*+,+,H0+,HW-010/]RU'/&/2;*+.RU8J'*&(8 V 3 5Yn&(8 V 3Y[/+.8J+M3();82105N+P3 -0-05URN)M3 /2RN&('7e;Afi3MfiuM%` v`%&(105N&('*HO8+J3 '*H^O3 5UC(3 /=m`Mb9b9cA-08&MC+,HZ/2;43 /{K*{sRN<h<+ V R~H0+,).RNH*3 D05N+_LRU/2;38+,HO1*)./2RN&('Y[8& V /2;*+;*Q|C*v${9 <$vu(w/leig_;*+\8+,HO1*)./2RN&('69RUC+.'tDX_3 6+./T=n99O`A=pY[8& V /2;*+(xRzy@v${9 $g u> { yi| 7* AJ-&(RU'Q/<u&(10//2;43 /2 K* {RN<P3T),& V -010/:3 /2RN&(' V &H0+.5$e>rt+Z69RUC+Z;*+.8+\3 '*&(/2;*+.8@8+,HO1*)./2RN&('7W7Y8& V /2;*+~}$D*|{9AN7.h2D PW7/2;43 /@L+ZLRU5U5!1*<+\3(<E/2;*+<2/:3 82/2RU'06I-&(RU'Q/@RU'/2;*+Z-08&& Y& 8&(-7eq`MOeZg_;0RN<8+,HO1*)./2RN&('IRN<3 5N<&lRU'Q/+.8+,</2RU'06\RU'FRU/<+.5Y}<2RU'*),+ERU/_-08&C+,</2;43 /MW0+.C+.'FL;*+.'F82105N+,<J3 8+@& Y/2;*+uYn&(8 V RYO9Kk] F6F6F ] G >/2;*+.'TOUk_ F6F6F _ G: W02Kv { $t 8+ V 3 RU'*<<+ V R~H0+,).RNH*3 D05N+9e~>hy|Mh{7t Cu|u k 2Kv { $ pE,fZM!Q2,[fU52MmWFx{RU8<2/>):;*+,)Kt/2;43 /i*|RN<'*&(/>/282105UX10'*H0+,).RNH*3 D05N+S=5pW5F/2;*+.8+i+fORN<2/<l3 'k3 5~6&(82RU/2; V /2;43 /P)M3 'tH0+,).RNH0+ZRU'S*'0RU/+Z/2R V +ZRY_/2;*+\3 '*<2L+.8@/&T/2;*+Z-08&(D05N+ V RN<F X+,<5 AfuL;*+.')M3 'phy|My}qr}]y{ 3{D+uH0+,HO1*),+,HFY8& V W*3lD08+M3(HO/2;O~n*8<2/<+M3 8);I& Yh/2;*+E/28+,+@& Yh3 5U57H0+.82RUC93 /2RN&('*<_Y[8& V -08&MCRNH0+,</2;*+3 '*<2L+.8JRU'F*'0RU/+@/2R V +9ert+/2;*+.'-08&C+>/2;43 /u'*&T3 5U6&(82RU/2; V RN<u+.'*<2108+,H/&;43 5U/uL;*+.'/2;*+l3 '*<2L+.8E/&/2;*+>-08&(D05N+ V RN<'*& :e|+./1*<'*&ML<2;*&ML/2;43 /2 kRN<'*&(/H0+,).RNH*3 D05N+lDQXFD010RU5NHORU'06I3\8+,HO1*)./2RN&('Y[8& V/2;*+U}N 7 .h =[g_;Q1*+9W@`MbO`.dAfeg_;0RN<-08&(D05N+ V L_3(<\-08&C+.'<+ V R~H0+,).RNH*3 D05N+>DQX &9</=m`Mb dW08+,HO1*)./2RN&('/&Z;0RN<),&(828+,<2-&('*H0+.'*),+ 8&(D05N+ V Afeg_;*+})M3 'DG+j+f-08+,<<:+,H3(<M5N+.g/ 3 '*pH 7ED+S/L&L&(8H0<W>3 '*H "* F6F6F * nD+3@<+./]& Y82105N+,<MW+M3();i82105N+ D+.RU'06l3E-43 RU8]& YL&(8H0Y< $ ,* c4fRN<]/2;*+.8+3@H0+.82RUC93 /2RN&('GY[8& V /Z& 7 g_;*+.8+ZRN<P3 'R VV +,HORo3 /+\H0+.82RUC93 /2RN&('Y[8& V /& 7=L+Z'*&(/r+ 7NARYmWGYn&(8<& V ++ 9W %" 6 3 '*gH "p 6 eJ QffM ?9[n(Y[8& V /& =L+l'*&(/C+RN<3Z<+,w1*+.'*),j+ " N"eF6F6F4BKv { $$D *|{9 ] 2D$D *v${9&{Cff ff ff%Eu` ]*$M4ff$)4#u$Dvv$|RU'Q/&i*|g_;0RN<_-08&(D05N+ V )M3 'F+M3(<2RU5UXD+u+f-08+,<<:+,HiRU's/2;*+u V &H0+.5$ez'*+E),&('*),+.-0/_/X-G+9RN<J3(<<2RU69'*+,H/&+M3():;Z5N+./2/+.8] e}g_;*+.8+3 8+/2;08+,+&(/2;*+.8{),&('*),+.-0/h/X-G+,<M{=pYn&(8D D+.69RU' AfWZ=pY[&(8 +.'*HC A3 '*H=pYn&(83 'QX/2;0RU'06MAfeRN<!/2;*+J698+M3 /+,<2/q),&('*),+.-0/]/X-+J3 '*H3 5U5*&(/2;*+.8q/X-+,<]3 8+_-43 RU82LRN<+'*&('O~),& V -43 8:3 D05N+9eg_;*+.8+RN<P&('*+\8+.5o3 /2RN&('t/X-G+Z=pY[&(8;43(<<21*),),+,<<&(85 AfeL&(8HB " ] F6F6F ] G RN<>3(<<&).Ro3 /+,HS/2;*+698:3 -0;t$M4fW73 '*H/&F3 'XI82105N+B"$M_ F6F6F _2 *F F6F6F AW 4RN<@3(<<:&).Ro3 /+,Hy/2;*+698:3 -0;y82105N+ $.4fW73(<8+.-08+,<+.'/+,HRU'yx}RU6*e`MOeXI3<2/28:3 RU69;/mY[&(82L_3 8Hy-08&& Y=n3Z8+,).10828+.'*),+l&('/2;*+P< V 3 5U5N+,<2/H0+.82RUC93 /2RN&('5N+.'069/2;aAfW9L+&(D0/:3 RU'l/2;43 /h/&E+.C+.82X>-43 /2;lY[8& /2;*+'*&H0+/X-G+,H~ /&/2;*+'*&H0+/X-+,H~=& D+.69RU'/&+.'*HC A_RU'y3l698:3 -0;B\~H0+.82RUC+,HIY8& V $M4fWaV ),&(828+,<2-&('*H0<3ZL&(8H=n3 '*HF'*&(/3\<210DQL&(8H4AJH0+.82RUC93 D05N+Y[8& V tW43 '*HT8+,).RU-08&)M3 5U5UXe /_Yn&(5U5N&MLJ</2;43 / * $M 4 P $n$M4* $4y4fex{RU69108+\`MOqg8:3 '*<mY[&(8 V 3 /2RN&('Y8& V /2;*+9};fi M]|9M.tM=uwuMM3FhEfi#kqu2!q4| +./J1*<'*&MLRU'Q/28&HO1*),+i(*f[2(pafW0L;0RN):;S3 8+@1*<:+,HF/&C93 5URNH*3 /+@K'*&L5N+,HO6+9e_K'*&ML5N+,HO6+D43(<+7LRU5U57D+uC(3 5URNH*3 /+,HFRYhRU/J<:3 /2RN<m4+,<+.C+.82Xs),&('*<2/28:3 RU'/MWa3 '*HT'*&\H0+,HO1*)./2RN&('LRU5U57DG+@3 5U5N&L+,H10'05N+,<<_/2;*+@;43(<_D+,+.'sC(3 5URNH*3 /+,H!RU's-08+,<+.'*),+@& Y}),&('*</28:3 RU'Q/<MW0H0+,HO1*)./2RN&('FRN<_H0+f*'*+,HT&('05UXi&('F3T(0fo.f4K'*&ML5N+,HO6+PD43(<:+9e} ffK6]{Ayfi;}]}$k{%}qy|y|+ N$B$)5'*+.6Q3 /2RUC+SR),&('*<2/28:3 RU'/oF:(922{15M}h A{% }AB -&9<2RU/2RUCOJON L o(UO\/282RU696+.8imZO:(0f[2(4M = J L o(U2[&(D05URU6Q3 /2RN&('N$B$)5RU'/+.8HORN)./2RN&(' RT5#G~$CRN&(5o3 /+,<EO f[M? 8N$B$)5G$9[M? Ri(*f[2(pa oPuGmmM2,[n(mEOP[fUMQf}pa$>OB2(a94Q,(fmaN$B$.54$bHRP9h(*a{@)jfaQ2N2f$)5O9}9I:)j9.aQ2S Rl$a2m,,[[9F2 (JE9h(NW 5CRN&(5o3 /+,< [ `!c?Mn(U9B ,(_.(ha2m,,[[9a5 OfS 9!oM =`<:3 /2RN<m4+,< 85fi;}]}=rt))%rrx{RU69108+\`9`9]+,HO10'*H*3 '*).XF3 '*HI),&('*<2/28:3 RU'Q/CRN&(5o3 /2RN&('r +T;43MC+F/&S-G&(RU'/&(10//2;*+FR V -&(82/:3 '*),+I& Y/2;*+IRU828+,HO10'*H*3 '*).X),&('*HORU/2RN&('&('/2;*+T698:3 -0;/&D+IC93 5URNH*3 /+,HDQX-G&9<2RU/2RUC+),&('*<2/28:3 RU'Q/<y<;*&(105NHL+FYn&(826+./i/2;0RN<i),&('*HORU/2RN&('7WJ/2;*+.8+ V 3MXD+F/L&+,w10RUC(3 5N+.'/^0?E<W}<21*):;j/2;43 /l&('*+<:3 /2RN<m4+,<Z3F-&9<2RU/2RUC+\),&('*</28:3 RU'Q/\3 '*Ht/2;*+i&(/2;*+.8H0&+,<>'*&(/MeFx{RU6*e`9`Z<2;*&MLJ<3 'S+f*3 V -05N+& Y<1*);698:3 -0;*<Me <:3 /2RN<m4+,< \WD010/u/2;*++,w10RUC93 5N+.'Q/=8+,HO10'*H*3 'Q/BA@698:3 -0;kW}&(D0/:3 RU'*+,HDQX V 3 KRU'06/2;*+HORN<nm&(RU'/>10'0RN&('& H3 '*Ht/2;*+/282RU696+.8& W}H0&+,<>'*&(/Mesg}&y3MC&(RNHHOR+.8+.'Q/}),&('*<RN<2/+.'*).XC93 5U1*+,<Yn&(87+,w10RUC(3 5N+.'/7698:3 -0;*<MWL+!;43MC+]);*&9<:+.'P/&H0+f*'*+q-&9<2RU/2RUC+!),&('*<2/28:3 RU'/<:3 /2RN<mY$3()./2RN&('LPe 8Me /Meh/2;*+RU828+,HO10'*H*3 'Q/Yn&(8 V & Y}3l^0?ZeQg_;0RN<-08&(D05N+ V H0&+,<]'*&(/&),).108]LRU/2;s'*+.6Q3 /2RUC+),&('*<2/28:3 RU'/<Me '*H0+,+,HW5N+.E/ 3 '*H D+l/L&+,wQ10RUC93 5N+.'Q/@698:3 -0;*<>3 '*H<10-0-G&9<o+ G~$CRN&(5o3 /+,<>3'*+.6Q3 /2RUC+\),&('*<2/28:3 RU'/ <2RU'*),+Z/2;*+.8+\+fORN<2/<P3i-08& m+,)./2RN&('Y[8& V RU'Q/& W7<:3MX D.W HRN<P3-08& 2+,)./2RN&('FY8& V /& WO/2;1*Y< 3 5N<&ZCRN&(5o3 /+,< \egL&T),&('*<2/28:3 RU'Q/< 3 '*H 3 8+l<:3 RNH/&iD+Ty ,M ?(Nf4RY3 'QX698:3 -0;/2;43 /ECRN&(5o3 /+,< 3 5N<&CRN&(5o3 /+,< 3 '*HT),&('C+.8<+.5UXe]'QXi'*+.6Q3 /2RUC+P),&('*<2/28:3 RU'Q/RN<+,w10RUC93 5N+.'Q/J/&l/2;*+E'*+.6Q3 /2RUC+@),&('*<2/28:3 RU'/&(D0/:3 RU'*+,HDQX),&(5N&(82RU'06k3 5U5RU/<'*&H0+,<\DX`9ex01082/2;*+.8 V &(8+9WJ'*+.6Q3 /2RUC+y),&('*<2/28:3 RU'Q/<T3 8+IRU'*H0+,+,H3-43 82/2RN).105o3 8)M3(<:+& Y-&9<2RU/2RUC+&('*+,<M{),&('*<2RNH0+.8q/2;*+J-G&9<2RU/2RUC+),&('*<2/28:3 RU'Q/ &(D0/:3 RU'*+,HY[8& V 3E'*+.6Q3 /2RUC+),&('*<2/28:3 RU'/ DX),&(5N&(82RU'06\3 5U5G'*&H0+,<& DQXiOW/2;*+.'T3(H0HORU'06\3),&('*),+.-0/_'*&H0+u),&(5N&(8+,HsDQX`9WLRU/2;/X-+8 *W9L;*+.8+, " ERN<qRU'*),& V -43 8:3 D05N+JLRU/2;i3 5U5*&(/2;*+.8q/X-+,<]3 '*H\H0&+,<h'*&(/3 -0-+M3 8qRU'3 'QXT698:3 -0;y& Y{/2;*+@uW4+fO),+.-0/JRU'),&('*<2/28:3 RU'Q/<Meg_;*+.'y3\<2R V -05N+@698:3 -0; CRN&(5o3 /+,</2;*+P),&('*<2/28:3 RU'/RY3 '*H&('05UXRYqRU/CRN&(5o3 /+,< e &9<2RU/2RUC+),&('*<2/28:3 RU'Q/<E<2/282RN)./25UXRU'*).5U1*H0+'*+.6Q3 /2RUC+Z),&('*<2/28:3 RU'/<MWRU'/2;*+J<+.'*<:+/2;43 /q/2;*+3(<<:&).Ro3 /+,H\),&('*<RN<2/+.'*).XZ-08&(D05N+ V <3 8+'*&(/]RU'\/2;*+J<:3 V +J),& V -05N+fORU/X\).5o3(<:<=/2;*+-08&& Y}Yn&(5U5N&MLJ<JY8& V g_;7e4cAfe@4UBByn(Gf65=._ ` ! H+=aO B[[M? E(0.[m9p4E(2Pf[f[,Qffm9 ^sM9[n(2JGn['?9fi3MfiuM%^RU'*),+F'*+.6Q3 /2RUC+),&('*<2/28:3 RU'Q/<T3 8+TRU'*H0+,+,H3y-43 82/2RN).105o3 8s)M3(<+I& YE-G&9<RU/2RUC+F&('*+,<MWL+FLRU5U5J'*&LPW10'05N+,<<RU'*HORN)M3 /+,H&(/2;*+.82LRN<+9WH0+.'*&(/+FDX 3<+./& YP),&('*<2/28:3 RU'/< 3<+./& YE-G&9<RU/2RUC+I),&('*<2/28:3 RU'Q/<<& V +@& Yh/2;*+ V )M3 'ID+@+,wQ10RUC93 5N+.'Q//&Z'*+.6Q3 /2RUC+>&('*+,<Me57qX "$n+*m.4ToI),&('*<2RN<2/+.'/I Zfi;}]} M}h Ayn} Fy]fiM} } _7 nY.[oM< Bi((*f[2(paim@a5 OfS9!p,=Epl,(njRU'*),&('*<RN<2/+.'Q/A5 } (H0+,HO1*),+,Hfm( JpP(0fo.f4_(aZ :(jZQ2(0:2@B2( d5&(/+P/2;43 /3s^0?/2;43 /CRN&(5o3 /+,<3),&('*</28:3 RU'Q/E& Y! V 3,XI<2/2RU5U5DG+PH0+,HO1*),+,HIY8& Vu'*&(/ V 3 /2/+.8<RU'*),+RN<J30(f[n({8+.-08+,<+.'Q/:3 /2RN&('y& Y{K'*&ML5N+,HO6+H0+,HO1*).RUD05N+@Y[8& V ee /H0&+,<}y{M}hhM][MMME+,HO1*)./2RN&('FRU'FRN<+,<:<+.'Q/2Ro3 5U5UXi'*&(' V &('*&(/&('0RN)9e]H0HORU'06RU'OYn&(8 V 3 /2RN&('F/&Zk)M3 'T/282RU696+.83'*+.L),&('*<2/28:3 RU'/MW3 '*H/2;1*<i)M3 ').8+M3 /+3'*+.L CRN&(5o3 /2RN&('7S<2RU'*),+I'*&(/2;0RU'06k)M3 'DG+IH0+,HO1*),+,HY[8& V 3 'RU'*),&('*<2RN<2/+.'/K'*&ML5N+,HO6+D43(<+9W0-08+.CRN&(1*<H0+,HO1*)./2RN&('*<E3 8+@'*&5N&('06+.8C(3 5URNHeg_;43 /JRN<JL;XiYn&(83 '*H V &(8+Z6+.'*+.8:3 5 V &H0+.5N<\='*+fO/@<+,)./2RN&('*<BAfWRU/ERN<uR V -G&9<:<2RUD05N+l/&s&(D0/:3 RU'8+,<105U/<@& YqY[&(8 V )M3 'D+H0+,HO1*),+,HsY[8& V /2;*+uK'*&ML5N+,HO6+ED43(<+ERSj$[E4 Ij$$E4 E3(<RU/_L_3(<_/2;*+u)M3(<:+JYn&(8_3 '*Hs2eu&ML+.C+.8MWQ/2;*+'*&(/2RN&('s& Y),&('*<RN<2/+.'*).Xl)M3 'DG+_/28:3 '*<25o3 /+,HRU'Q/&Px{zu|qeQx*&(8]'*+.6Q3 /2RUC+J),&('*<2/28:3 RU'Q/<W/2;*+),&(828+,<2-&('*H0+.'*),+RN<!R VV +,HORo3 /+9W3 '*HZ8+.5URN+,<q&('-08& m+,)./2RN&('i<&(10'*HO'*+,<<]3 '*H),& V -05N+./+.'*+,<<]LPe 8Me /Me/2;*+l<+ V 3 'Q/2RN),<> =/2;*+,&(8+ V `Afe 'Q/210RU/2RUC+.5UXW}3s^0? CRN&(5o3 /+,<@3'*+.6Q3 /2RUC+Z),&('*<2/28:3 RU'Q/ ~SjRY3 '*H&('05UXRY}/2;*+RU'OYn&(8 V 3 /2RN&('F8+.-08+,<+.'/+,HFDQX RN<H0+,HO1*).RUD05N+uY[8& V /2;*+uRU'OY[&(8 V 3 /2RN&('F8+.-08+,<+.'/+,HFDQXZefipUUV M? n(U9BiGnQ9['?(F(0.[m9p4"$ *H4 j$4*Bj$E4 j$ 4>=hy|MyfV }9hOf b!pPOj}aQff;:N(Glj$ j4PoPO>U(n(.(fZUs :,M.n92T$iQob}R 5UF%&('*<2RN</+.'*).Xl8+.5o3 /2RUC+J/&@-G&9<RU/2RUC+),&('*<2/28:3 RU'Q/<)M3 '\D++f-05o3 RU'*+,HLRU/2;ix}zu|qW/28:3 '*<5o3 /2RU'06 -08& ~2+,)./2RN&(' ]RU'Q/&@3'*&(/2RN&('Z& 5N&(69RN)M3 50<210D*</2RU/210/2RN&(' E=$%;*+.RU'1069'0RN+.8MW*`Mb9b9A7DG+./L+,+.'/2;*+]Y[&(8 V 105o3(<3(<<&).Ro3 /+,H/&F698:3 -0;*<ert+\)M3 5U5_3 '!B*Bf[[[[n(kY[8& V j$[4uRU'/&yj$ J4@3F<10D*<2/2RU/210/2RN&('&/+.8 V <]& Y}j$E4{DQX/+.8 V <& Y7j$ J4!<1*);\/2;43 /),&('*<2/:3 'Q/<& Y[$[4q3 8+K+.-0/]RU'QC93 82Ro3 'Q/3 '*HWYn&(8]3 'QX3 /& V 6$ * FtFtF * G 4& Y]j$[4fW*/2;*+.8+@RNd< \_<21*):;F/2;43/ $$ 4* FtFtF *$ G 4y4RN<3 '3 /& V & Yqj$ J4feg_;*+EYn&(5U5N&MLRU'06i-08&(-G+.82/Xs;*&(5NH0<`K``? . :a2m,,[[9f2( $QM<]GBy(!B*Bf[[[O[[(B2(ynj$ J465 :fZs9o@a9B\(9,(fC=qOl9? fB,Z( .9 W5j$[4$2MmWJ|+./D+@3>-08& 2+,)./2RN&('TY[8& V /& ke!x*&(8J+M3();TC93 82Ro3 D05N+b]& Yhj$E4fWO5N+./D+/2;*+u10'0RNw1*+6+.'*+.82RN)),&('*),+.-0/i'*&H0+<21*);/2;43 /8]" [$ 64fW/2;*+.'g$M])4" j$ $ W4y4fe+,).RU-08&)M3 5U5UXW_-08&MCRNH0+,H/2;43 /RN<RU'I'*&(8 V 3 57Yn&(8 V W*/2;*+l3 -0-05URN)M3 /2RN&('Y[8& V ),&('*),+.-0/u'*&H0+,<& Ya/&),&('*),+.-0/'*&H0+,<& kW/&>/2;*+u'*&H0+ba<21*);T/2;43 /,$$ j$ W4y4a" [$ q4 RN<3>-08& 2+,)./2RN&('sY8& V/& eu&(/+V 3 -0-0RU'06\+M3();7/2;43 /MW010'05N+,<<RN<RU''*&(8 V 3 5Y[&(8 V W RN<'*&(/J10'0RNw1*+.5UXFH0+f*'*+,HFL;*+.'yj$4 RN<3Z),&('*<2/:3 '/Meq;@U(V`!c?Mn(U9BE(0.[m(4 OH!B*Bf[[[[n(Tfm9j$ JPN L 44$u {3(2B4oj$[4 B.M.n92Z9![(4a9)j9fGQ2T$s(!$f0B.[[O[n(f2( j$ C4E4$l[$[465Ufi M]|9M.tM=uwuMM3F'*&(/2;*+.8]D082RNHO6+)M3 'D+D010RU5U/]1*<2RU'06>82105N+,<Me '*H0+,+,HWO3E698:3 -0;<:3 /2RN<m4+,<3E-&9<2RU/2RUC+J),&('*<2/28:3 RU'/RY03 '*H&('05UX@RYmW),&('*<2RNH0+.82RU'063(<}3J82105N+9W 3 5U5O3 -0-05URN)M3 /2RN&('*<{& Y|&('r-08&HO1*),+3J698:3 -0;+,w10RUC(3 5N+.'//&8Zez8MW V &(8+P<2-+,).R4)M3 5U5UXG}=(*BnQffpyn} `!?M[99fFTO B[[M? I90f[2(4BG n9[n(tm (:(2(pF$Eta2M(0:B(2B4IG9y,M?(Nf4_$o5ISfN=02MmW|7+./ D+3i),&('*<2/28:3 RU'Q/P3 '*HJDG+Z3s^0?<21*):;y/2;43 /[<:3 /2RN<m4+,< e Ya N RN<E3\-08& 2+,)./2RN&('Y[8& V=[),&('*<2RNH0+.8+,HJPN L RU'Q/&8WO5N+./1*<),&('*<RNH0+.8/2;*+698:3 -0;bG&(D0/:3 RU'*+,HTDX/2;*+P3 -0-05URN)M3 /2RN&('&'*&ML3(<3\82105N+A&('J3(),),&(8HORU'06s/&8 N e|+./1*<J'*&LD010RU5NH/2;*+@Yn&(5U5N&MLRU'06s-08& 2+,)./2RN&(' Y[8& VRU'Q/&7ZYn&(8+M3():;'*&H0++GW0t$ 4d" TRY&TDG+.5N&('06<u/&Z&(/2;*+.82LRN<+9WsRN<E3\),&(-X& Y3'*&H0+&XJ L W3 '*HZRY)TRN<q&('*+J& Y/2;*+-08& 2+,)./2RN&('*<!Y[8& V RU'Q/&k/2;43 /]+fO/+.'*H0< N W9L+J;43MC+ t$ 4a"Qt$ jf4 eg_;*+.'B RN<>3i-08& m+,)./2RN&('j& RU'Q/&gZW}3 '*Ht<2RU'*),+o /282RUCRo3 5U5UX-08& 2+,)./<@RU'Q/& W/2;*+.XS3 8+Z/2;1*<+,w10RUC(3 5N+.'/Meg_;0RN<@-08&C+,<@/2;*+C -43 82/P& Y-08&(-+.82/XvOelx*&(8@/2;*+C -43 82/MWL+Z1*<:+Z/2;*+lY[&(5U5N&LRU'06F-08&(-G+.82/XW-08&MC+,HtDQXS%&(69RN<3 '*H?E10RU'43 5NH0&j=m`Mb9b9vAfe 'S/2;*+.RU8@-08&(-G+.82/X=-08&(-7eZs& Y/2;*+.RU8@-43 -+.8BA/2;*+\^0?E<),&('*<2RNH0+.8+,H3 8+>),&('0'*+,)./+,HI698:3 -0;*<MW0D010//2;*+E-08&& Yh;*&(5NH0<Yn&(8'*&('),&('0'*+,)./+,HI698:3 -0;*<eq !ruvu{}:H}(apf6 $[4(2][y .' ?9Ufayn fu] }${M],B2(a(aqf0n9mBaZN 1oEa9]2(G(4_OfyB6$[4a"YRT5UOfSOf)j(pf>iYn&(5NHORU'06fm( $FB6$[4>=J5pW5sGmmM2,[n( yB2( 4$TfL$[4>=fO.y9OZBf[fn,[[9km $aMBm@B6 $[4PoPO>nQf4[[ :gN ,(>S ? . :saMQ1]m@B6 $[4>= $M])4"]R 5$^10-0-&9<+'*&Lq G~$CRN&(5o3 /+,< e^RU'*),+),&('*<2/28:3 RU'Q/CRN&(5o3 /2RN&('tRN<>H0+f*'*+,HLRU/2;t8+,<2-+,)./@/&T/2;*+RU828+,HO10'*H*3 'Q/Yn&(8 V & Y!3698:3 -0;7W*L+>)M3 '),&('*<2RNH0+.8MW*LRU/2;*&(10/5N&9<<J& Yh6+.'*+.8:3 5URU/XWa/2;43 /YRN<RU828+,HO10'O~H*3 'Q/Me_rt+H0+.'*&(/+PDXY/2;*+P698:3 -0;S&(D0/:3 RU'*+,HIDXF/2;*+3 -0-05URN)M3 /2RN&('S&=n3 6Q3 RU'7WG),&('*<2RNH0+.8+,H'*&L3(<3P82105N+Aq&(7' 3(),),&(8HORU'06l/E& !e{rt+-08&MC+/2;43 / +,w10RUC(3 5N+.'//r& 5N+M3(H0<]/&l3P),&('Q/28:3(HORN)./2RN&('7eRN<]+,w10RUC(3 5N+.'/]/r& ZW/2;*+.'i/2;*+.8++fORN<2/<3E-08& 2+,)./2RN&('iY8& V RU'Q/& Zeh'*H\<RU'*),Y+ RN<3 'RU828+,HO10'*H*3 'Q/E<210D0698:3 -0;&WO/2;*+.8+P+fORN<2/<3u,(9p Y[8& V RU'Q/Z& =-08&(-G+.82/XFAfe%&('*<2RNH0+.8'*&ML /2;*+I-08& 2+,)./2RN&('Y[8& V/& H0+f*'*+,H3(<Yn&(5U5N&MLJ<MIY[&(8i3 'X'*&H0+ ]& JON LW $M])4C0$ $M]4y4fW&(/2;*+.82LRN<:+Z5N+.Y/ ] D+>/2;*+),&(-X&]jRUB' WGL+Z;43,C+ $M]40 $M] 4fe^RU'*),+lY[&(8@3 5U`5 ]tRU'< !ehg_;0RN<),&('/28:3(HORN)./<_/2;*+;X-&(/2;*+,<2RN< AG~$CRN&(5o3 /+,< :ehg_;1*<JON L W $ $M]4y4"Q$M])4fW 4+f/+.'*H0dRN<'*&(/+,w10RUC93 5N+.'Q/J/8& Zefi@4},9[p'<BJO f[M? E90f[2(4 r=}OfI(:(2B4\TEm kn !mQff'? 9[[9yn eh p[mHp>3.M?(Nf4_$o54F2MmW J|+./ "p N * FtFtF *H G D+@3m rn,~H0+.82RUC(3 /2RN&('I& Y`eqx08& V -08&(-G+.82/XsvOWO+M3(); mWI[\\ K WRN<J+,w10RUC(3 5N+.'/J/& WO/2;1*<JDQXs/28:3 '*<2RU/2RUCRU/XW4RN<J+,wQ10RUC93 5N+.'Q//& Ze<2RU'06S<&(10'*HO'*+,<<3 '*H),& V -05N+./+.'*+,<<& Y/2;*+i H0+,HO1*)./2RN&('7W]3 '*Hk-08&(-+.82/2RN+,<\v3 '*HW!&('*+&(D0/:3 RU'*<J/2;*+@Y[&(5U5N&LRU'06\8+.5o3 /2RN&('LRU/2;x{zu|jH0+,HO1*)./2RN&('7epFOfyj(o.}Y>B0f9hy|Myph {q ?Mn(BIO B[[M? y(0.[m(4j$d4*Bj$[4*Bj$ C4 Ij$ 4P(aG9j$4*B[$[4 I[$ 4>=9h0f2uj$ C4uoEO@[2(0f[[(Sm(*BnQf2I >BU5U;U@fi3MfiuM%g_;0RN<s/2;*+,&(8+ V )M3 'DG+8+fY[&(8 V 105o3 /+,HRU'/+.8 V <T& Yl3 DHO1*)./2RUC+yRU'OY[+.8+.'*),+=1*<2RU'06kRU'Yn3()./sRU'O~HORU8+,)./s3 DHO1*)./2RN&('7W<+,+9WYn&(8+f03 V -05N+9W_&('*&(5URU6+9WP`Mb9b9Afe '*H0+,+,HW69RUC+.'3D43()K698&(10'*H/2;*+,&(82X$d4*Bj$[43 '*H3 '&(D*<+.82C93 /2RN&('%" ]j$ E4fWaCRN&(5o3 /+,<R/2;*+.8+TRN<\3 '3 DHO1*)./2RUC+" j+fO-05o3 '43 /2RN&('IYn&(8E& Yh/2;*+uY[&(8 V \WOL;*+.8+9RN<3ZY[&(8 V 105o3ZDG+.5N&('069RU'06/&\x}zu|a$ * 4fe} q]$A{M}h{Uq B` < K$Ulg_;*+-08&(D05N+ V H0&+,<i3j69RUC+.'698:3 -0;<:3 /2RN<mY[X369RUC+.'),&('*<2/28:3 RU'Q/RN<i),& ~c ~),& V -05N+./+yRYP/2;0RN<),&('*<2/28:3 RU'/RN<'*+.6Q3 /2RUC+t=[<RU'*),+iL+ V 1*<2/);*+,):K/2;*+T3 D*<+.'*),+T& Y-08& 2+,)./2RN&('aAfW!D010/ZD+,),& V +,< _ ` ~),& V -05N+./+@Yn&(83l-&9<2RU/2RUC+P&('*+\= _ ` RN<),& ~c 2 AfepqK$72D*4tp _< K__aN.> >9p90f[2(4(Pn9[M? R 5hy|MykB`y $ [ }` !m(aN.bNmfGp]! H!:(r!2MmWSrRU/2;*&(10/i):;43 '06+& Y>),& V -05N+fORU/XWJ&('*+)M3 '),&('*<2RNH0+.8s/2;43 /\RN<i),& V -G&9<:+,H& Y>&('05UX&('*+-&9<2RU/2RUC+i),&('*</28:3 RU'Q/MWq<:3MX eIx{RU8<2/8+,)M3 5U5/2;43 /ZH0+,).RNHORU'06SL;*+./2;*+.8\3^0? <B3 /2RN<m4+,< RN<lH0&('*+&('j/2;*+RU828+,HO10'*H*3 'Q/lYn&(8 V & YHZeTrt+<;43 5U5]),&('*<2RNH0+.8l/L&L3MX<l& YJRU'Q/+.698:3 /2RU'06y/2;0RN<>Yn3()./RU't/2;*+),& V -05N+fORU/XF& Y{_ 74]e_z'*+@L3MXTRN</&\3(<<21 V +E/2;43 /J/2;*+ERU828+,HO10'*H*3 '/Yn&(8 V & YaRN<K$ 2D*),& V -010/+,HD+fY[&(8+Z/2;*+Z),&('*<2RN</+.'*).Xy):;*+,)Keg_;0RN<P)M3 'DG+3():;0RN+.C+,HLRU/2;j3s'Q1 V DG+.8>& Y_)M3 5U5N<@/&I3-08& 2+,)./2RN&('S&(8:3().5N+5URU'*+M3 8ERU'/2;*+l<2R M+l& Y=[1069'0RN+.8MW!`Mb9b9vAfeu10/MWG<RU'*),+>L+>;43MC+/2;*+.'S/&s<&(5UC+3\Y10'*)./2RN&('y-08&(D05N+ V =[),& V -010/+/2;*+lRU828+,HO10'*H*3 '/EY[&(8 V &PAJRU'*<2/+M3(H& Y_3H0+,).RN<2RN&('y-08&(D05N+ V =RN<RU828+,HO10'*H*3 'Q/ AfWL+l-08+fYn+.8E/&RU'/+.698:3 /+ZRU828+,HO10'*H*3 '*).XRU'Q/&T/2;*+l),&('*<2RN<2/+.'*).X);*+,)K/2;*+.'7W4Yn&(83-08& m+,)./2RN&(' N Y8& V /2;*+>/282RU696+.8@& RU'Q/& ZWG/2;*+-08& m+,)./2RN&('Y[8& V /7& L+>5N&&(KFYn&(8H0&+,<'*&(/'*+,),+,<:<:3 82RU5UXF+f/+.'*H0H< N W*D010/+fO/+.'*H0<J/2;*+),& V -G&9<RU/2RN&('& Y]3Z-08& 2+,)./2RN&('IY[8& V RU'/&&('*+P&RU/<J<210D0698:3 -0;*<l=-G&9<:<2RUD05UXs+,w143 5/& RU/<:+.5YfA_3 '*H N ex{RU8<2/MW>G 74 D+.5N&('06<y/& _` <2RU'*),+RU/y),&(828+,<-G&('*H0</&/2;*+5o3 '069143 6+G "mW] d_ _ $M]*_ *_ 4>nQWL;*+.8+ ]+.'*),&H0+,<3 'RU'*<2/:3 '*),+ $k* E4& Y\/2;*+k-08&(D05N+ V 3 '*H$M]*d_ *d_ 4 R_ +.'*),&H0+,<3l-08& 2+,)./2RN&(' N Y8& V XJPN L RU'Q/Z& 3 '*H _ +.'*),&H0+,<3l-08& 2+,)./2RN&('Y[8& V RU'Q/&>&('*+& YRU/<<210D0698:3 -0;*<3 '*Hs3E-08& 2+,)./2RN&(' TY[8& V RU'/k& <Me /M`e JON L "Q ) N eu&(/+E/2;43 /JRRN<RU'FRU828+,HO10'*H*3 'Q/Yn&(8 V WO/2;*+.g' RN<3 '3 10/& V &(82-0;0RN< V eu&MLPW@5N+./1*<),&('*<2RNH0+.8/2;*+-08&(D05N+ V ~ 69RUC+.'3DG&&(5N+M3 'Yn&(8 V 105o3WP3 '*H3-43 82/2RU/2RN&('*9 ni& YRU/<@C(3 82Ro3 D05N+,<W7RN<@RU/@/2821*+/2;43 /EYn&(8>3 'QXS/28210/2;3(<:<2RU69' V +.'Q/@Yn&(8@/2;*+ZC93 82Ro3 D05N+,<PRU'/2;*+.8+>+fORN<2/<u3Z/28210/2;y3(<<RU69' V +.'Q/JYn&(8J/2;*+>C(3 82Ro3 D05N+,<RU'B <Me /Me@RN<J/2821*+ Sg_;0RN<-08&(D05N+ V RN< _ ` ~),& V -05N+./+9W<RU'*),+ZRU/<@),& V -05N+ V +.'Q/:3 82X RN<P<2;*&ML'/&TD+ ` ~),& V -05N+./+DQXt^/&)K V +.X+.8i=m`Mb99Afe4]W*L+E1*<+P3l8+,<2/282RN)./2RN&('& Y{/2;0RN<'T&(8H0+.8/&ZD010RU5NHI3l-G&(5UX'*& V Ro3 58+,HO1*)./2RN&('I/&Z 7p-08&(D05N+ V /& K ~% ux*<MWOR$e+9e!),&('(m10'*)./2RN&('*<& YhHORN<[10'*)./2RN&('*<JLRU/2;3 / V &9<2/ K 5URU/+.8:3 5N<-G+.8J).5o3 1*<:+9e!|7+./1*<u)M3 5U5 ~ F1ff &E /2;*+><2-+,).Ro3 5})M3(<+>L;*+.8+~RN<E3 ~% ux_W*RU'S&(/2;*+.8L&(8H0<@3 'RU'*<2/:3 '*),+l& ~^!g@eg_;*+.' ~ F1ff &E RN<J3 5N<& _ ` ~),& V -05N+./+9e '*H0+,+,HW0RU'F/2;*+@<:3 V +E-43 -+.8=[g_;7eOd*eU`AfWa^/&)K V +.X+.8<2;*&LJ</2;43 / LRU/2;8+,<2/282RN)./+,H/&3 ~HORN<n10'*)./2RUC+i'*&(8 V 3 5]Yn&(8 V = ~buxqAE8+ V 3 RU'*< ` ~),& V -05N+./+9e^RU'*),+l/2;*+>'*+.6Q3 /2RN&('t& Y3 ~buxRN<E3 ~% ux_WaRU/Yn&(5U5N&MLJ<E/2;43 /u/2;*+l),& V -05N+ V +.'/:3 82X-08&(D05N+ V ~LRU/2;B8+,<2/282RN)./+,HI/&\3 ~% uxkRN< _` ~),& V -05N+./+9e|7+./]1*<!'*&ML8+,HO1*),+ ~ F1ff & /&@ 7p4]eqg_;*+/28:3 '*<2Y[&(8 V 3 /2RN&('i1*<+,HZRN<!C+.82X<2R V R~5o3 8q/&@/2;*+&('*+_Y8& V ~^!g/&@} k=-08&& Y7& Y/2;*+,&(8+ V AfWQRU5U5U1*<2/28:3 /+,HRU'x{RU6*e{d*eh|7+./D+3 'sRU'*<2/:3 '*),+& ~^!g@eO|7+./ $r43 '*HFo$r4!D+/2;*+E^0?E<&(D0/:3 RU'*+,HsDQX/2;*+/28:3 '*<mYn&(8 V 3 /2RN&('H0+,<).82RUD+,HZRU'/2;*+_-08&& Y& YGg_;7eOehg_;*+),&('*<2/28:3 RU'/ o$r4"ff$$o$r4*)H $t 4y4}RN<!&(D0/:3 RU'*+,HDQX3(H0HORU'063u),&(5N&(8:3 /2RN&('/&Po$k4fh3 5U5O8+.5o3 /2RN&(''*&H0+,<h&(D0/:3 RU'*+,HZY[8& V ).5o3 1*<+,<J='*&H0+,<h/X-+,H $A{3 '*HZ3 5U5O'*&H0+,<>~6K$ 2D*K AD*>~>~K AD*Kv { $d7fi M]|9M.tM=uwuMM3Fbvalvalvalafbtcvalbfvalvalvalctcfdt21C1C1C1C1C1C11C1C2C2C2bcvalvalvalvalvaldfavbvcvdv...323C2C2C2C2>~1223C11K7pAD*43C2x{RU69108+\`MO 0 3 V -05N+>& Y{/28:3 '*<mYn&(8 V 3 /2RN&('IY[8& V ~ Fff1&E /&_7@06&(D0/:3 RU'*+,HFY[8& V C93 82Ro3 D05N+,<JRU' =[),&('*),+.-0/'*&H0+,<J/X-+,H T&(8 T3 '*HF8+.5o3 /2RN&(''*&H0+,</X-G+,H QA3 8+@),&(5N&(8+,HFDXy`\=R$e+9e!D+.5N&('06\/&Z/2;*+@&(D05URU6Q3 /2RN&('aAfe_z'*),+>3 6Q3 RU'7W0;43,CRU'06).5o3 1*<+,<& Y}D&(10'*H0+,HI<2R M+5N+M3(H0<P/&3T-G&(5UX'*& V Ro3 5q/28:3 '*<mYn&(8 V 3 /2RN&('7eTg_;*+\<2R V -05N+698:3 -0; 3 '*H/2;*+\-G&9<2RU/2RUC+),&('*<2/28:3 RU'Q/-08+,<+.'/+,HRU'x{RU6*e7`Mi3 8+P&(D0/:3 RU'*+,HY8& V /2;*+ ~^!gYn&(8 V 105o3 $`W4 J$43 '*H/2;*+@-43 82/2RU/2RN&('K "Vm * n *) "VmA* nQe3():;t/28210/2;t3(<<2RU69' V +.'/>& Y]/2;*+ZC93 82Ro3 D05N+,<@& Y@ <Me /Me+RN<E/2821*+Z'43 /2108:3 5U5UX69RUC+,<>3i-08& 2+,)./2RN&('Y[8& V RU'Q/& W3 '*H8+,).RU-08&)M3 5U5UX=n3(<RU'*HORN)M3 /+,HRU'/2;*+F-08&& Yu& Y@g_;7eqAfex01082/2;*+.8 V &(8+9W3 'QX/28210/2;y3(<:<2RU69' V +.'Q/Y[&(8/2;*+>C(3 82Ro3 D05N+,<& YT '43 /2108:3 5U5UXT69RUC+,<u3Z-08& m+,)./2RN&('Y8& V XJON L RU'Q/Z& W43 '*H8+,).RU-08&)M3 5U5UXeqg_;Q1*<MW/2;*+uwQ1*+,</2RN&(' RN<RU/]/2821*+u/2;43 /Y[&(8_3 'QXi/28210/2;T3(<<RU69' V +.'Q/Y[&(8/2;*+uC(3 82Ro3 D05N+,<RU'/2;*+.8+l+fORN<2/<u3\/28210/2;S3(<:<2RU69' V +.'Q/Y[&(8u/2;*+PC93 82Ro3 D05N+,<uRU'B <Me /MeX RN</2821*+ RN<u+,wQ10RUC93 5N+.'Q/E/&/2;*+@w1*+,<2/2RN&(' RN<_RU//2821*+E/2;43 /_Y[&(8J3 'QXs-08& 2+,)./2RN&(' N Y8& V& /2;*+.8+@+fRN<2/<3l-08& 2+,)./2RN&('JPN L RU'Q/8Y[8& V RU'Q/Z& +fO/+.'*HORU'086 N :eu&(/+l/2;43 /@/2;0RN<E8+,HO1*)./2RN&('RN<E5N+,<<@<2/28:3 RU69;Q/mYn&(82L3 8Ht/2;43 '/2;*+l&('*+ZL+l-08&(-G&9<+,HSRU'=[3 6+./>1069'0RN+.8MW499O`AfW0D010/JRU/JLRU5U5D+E1*<+,H3(<3lD43(<2RN<_Yn&(8/2;*+@-08&& Y!& Y!g_;7e7`MOeKq!;u {30+ U( +TlAG1 (OM[[(_o _` ! (aN.W5h b"]ufi#ZX&QXdpEdo&' -08+,<:+.'*),+& Y),&('*<2/28:3 RU'Q/<W7/2;*+l/L&FKRU'*H0<E& Y82105N+,<MWRU'OY[+.8+.'*),+Z82105N+,<9H0+f*'*+@/L&i3 5U/+.82'43 /2RUC+ V &H0+.5N<ef fffi;}]}$k{%}3 '*HS+.C&(5U10/2RN&('t82105N+,<D]WuA{M}h' 2DhWRN<<+,+.'3(<u/2;*+>RU'0RU/2Ro3 5hL&(825NHW8&&(/E& Y3-G&(/+.'/2Ro3 5U5UXRU'O*'0RU/+l/28+,+& Y-G&9<<RUD05N+>L&(825NH0<MW3 '*HoDH0+,<).82RUD+,<E/2;*+Z-G&9<:<2RUD05N+Z+.C&(5U10/2RN&('*<@Y[8& V &('*+ZL&(825NHS/&F&(/2;*+.8<Melg_;*+H0+,HO1*)./2RN&('t-08&(D05N+ V3(<2KO<_L;*+./2;*+.8/2;*+.8+@RN<EOI2>(0fo.f4+9](BU !fm( $s89]9BU,9[ppS : leK* { $} ."#$na*)Da*m.4P+nbXd=!9alU,} >k}154 (S:Q 29O:@fm( POfo>(*D!mQff'? 9[[9FB" N * F6F6F * G B0fI9M=4,(fiIo\\ K =+$ ,*m4pP:(0Bpf.4(GZ9t:2(0:2@f2(q G 5fi;}]}'hWy-08&MCRNH0+,HLRU/2; RN<]3*'0RU/+JH0+,<).82RU-0/2RN&('s& Y3E-&(/+.'Q/2Ro3 5U5UXRU'O*'0RU/+JL&(825NHW/2;43 /q;43(</&TD+),&('*<2RN<2/+.'Q/Mei-0-05UXRU'063s82105N+/&I)M3 't).8+M3 /+\RU'*),&('*<2RN<2/+.'*).XW}D010/3iY1082/2;*+.8l3 -0-05URN)M3 /2RN&('& Y3F82105N+ V 3,Xt8+,<2/&(8+i),&('*<2RN<2/+.'*).XeF|7+./l1*<@Yn&(8 V 3 5UR M+i/2;0RN<P'*&(/2RN&('& YP:(0Bpf.aL :y2B.$(29[[94e6$-fi3MfiuM%U^10-0-&9<+Z/2;*+.8+ZRN<P3 G~$CRN&(5o3 /2RN&('t& Y3s-G&9<RU/2RUC+l),&('*</28:3 RU'Q/ RU'j/2;0RN<ECRN&(5o3 /2RN&('O$ b*34uRN<@<:3 RNH/ &TD+~g!B.$(mfUiRY/2;*+.8+\+fORN<2/P3 '\~H0+.82RUC93 /2RN&('Y8& V RU'/&3I^0?3 '*Ht3s-08& m+,)./2RN&('Y[8& VRU'Q/&FRU828$ J4@<21*):;t/2;43 />/2;*+\-08& m+,)./2RN&(' Y& Y/2;*+/282RU696+.8& RU'/&IRU828$ J4@)M3 'tD++fO/+.'*H0+,HI/&i3\-08& m+,)./2RN&('y& 3(<E3ZL;*&(5N+9eg_;*+PCRN&(5o3 /2RN&('& Y3'*+.6Q3 /2RUC+),&('*<2/28:3 RU'/u)M3 ''*+.C+.8D+Z8+,<2/&(8+,Hre &(/+Z/2;43 /P/2;*+~~$8+,<2/&(8:3 /2RN&('j)M3 'j).8+M3 /+Z'*+.LCRN&(5o3 /2RN&('*<MW7/2;43 / V 1*<2/@/2;*+ V <:+.5UC+,<D+E-08&MC+.'B~$8+,<2/&(8:3 D05N+9eK 2D*! UKv {$4 {%} \fi;}]} \<2RN<2/+.'/ >= .(I(:J}9l(Cg!mQff'? f2(? .:k`!cM? n(U9[[9Sm=+$ Y*34@p,g!2B.$(2QfNW5(*Bpff4_(aZ(jlQ29O:@fm( n$ a)* 7465Integer: Zero@Integern X" $n+*)*m.4pi),&('O~=,(S? fS:k:(0f[2(4=.(}9lQ(OB2@fm9 psuccessor<R V -05N+@698:3 -0;Integer),&(5N&(8+,Hy^0?x{RU69108+\` %&('*<2RN<2/+.'*).XTRU'FDh% &('*<2RNH0+.8ZYn&(8ZRU'*<2/:3 '*),+F3y@),&('/:3 RU'0RU'06t/2;*+I^0? RU'x}RU6*e_` Wq+fO-08+,<<2RU'06S/2;*+T+fORN<2/+.'*),+& Y@/2;*+'1 V D+.8TOWJ3j),&('*<2/28:3 RU'Q/F3 '*H3t82105N+9W_DG&(/2;8+.-08+,<+.'Q/+,HDX/2;*+),&(5N&(8+,H^0? eg_;*+),&('*<2/28:3 RU'/l3(<<+.82/<P/2;43 /J.9iS ? fS :4nf `=O.2ZQ.uT94nQ. =B0:BB.(Tm qe/2;*+u82105N+ERN<3 'I+.C&(5U10/2RN&('F82105N+9W RN<<+,+.'I3(<J3 'sRU'*),&('*<RN<2/+.'Q/RU'0RU/2Ro3 5L&(825NHt=/2;*+.8+ERN<_'*&l<1*),),+,<<&(8& YFRU' PAP3 '*Hj'*&(/2;0RU'06LRU5U5DG+iH0+,HO1*),+,HtY[8& V /2;0RN<@ue Y/2;*+82105N+\RN<Z3 'jRU'OYn+.8+.'*),+\82105N+9W{RU/<3 -0-05URN)M3 /2RN&('yR VV +,HORo3 /+.5UXF8+.-43 RU8</2;*+P),&('*</28:3 RU'Q/uCRN&(5o3 /2RN&('7W4L;0RU5N+>).8+M3 /2RU'06s3'*+.LRU'Q/+.6+.8MWa/2;43 /;43(<'*&<21*),),+,<<:&(8MW4/2;1*<u3\'*+.LCRN&(5o3 /2RN&('7eJx{RU'43 5U5UXW+.C+.82XI),&('*<2/28:3 RU'Q/ECRN&(5o3 /2RN&('),&(105NHy+.C+.'Q/2143 5U5UXD+E8+.-43 RU8+,HIDQXF3Z82105N+P3 -0-05URN)M3 /2RN&('7W3 '*HT/2;*+P@<2;*&(105NHFD+E-08&MC+.'y),&('*<2RN<2/+.'Q/Me|7+./1*<]-&(RU'Q/&(10/]/2;43 //2;*+J2 V &H0+.54RN<&(D0/:3 RU'*+,H\Y[8& V 2\&(8]2DFL;*+.'FRN<+ V -0/XW03 '*HRN<J&(D0/:3 RU'*+,HTY[8& V 2\=8+,<2-7e0D77AL;*+.'K =8+,<2-7eD{ARN<+ V -0/Xeg_;*+CD7 V &H0+.5G),& V D0RU'*+,<DG&(/2;sH0+.82RUC(3 /2RN&('T<):;*+ V +,<& Y/2;*+J2\3 '*HD V &H0+.5N<M`e &LPWH0+,<).82RUD+,<3 'RU'0RU/2Ro3 5JL&(825NHWRU'OYn+.8+.'*),+I82105N+,<& ),& V -05N+./+I/2;*+FH0+,<).82RU-0/2RN&('& Y@3 'XL&(825NHW),&('*<2/28:3 RU'/<s& Yu+.C93 5U143 /+I/2;*+),&('*<RN<2/+.'*).X& YP3L&(825NHWJ+.C&(5U10/2RN&('82105N+,<& YD/282X/& V 3 K+3),&('*<2RN<2/+.'/L&(825NH+.C&(5UC+>RU'Q/&i3\'*+.LPW4),&('*<2RN</+.'Q/&('*+9e_g_;*+PH0+,HO1*)./2RN&('y-08&(D05N+ V 3(<2K<JL;*+./2;*+.8E)M3 '+.C&(5UC+@RU'/&3),&('*<2RN</+.'Q/JL&(825NH<:3 /2RN<mY[XRU'06l/2;*+P6&3 5$e..K* {}Y{p(R VV +,HORo3 /+CD7~+.C&(5U10/2RN&('\B2(C}CD7Of@)j(pfu9(!Q.BM?9[n(@fm(ffpa$b (aZ(IR VV +,HORo3 /+Da!QffM?9[n(@B2(ff 4$5 CD~+.C&(5U10/2RN&('B2({$F8}poiMy.*fa:imE}Y"V N * F6F6F * G "VB0ft9M =}.(9J\C\ K =Y$ ,*)g*m4o(*Bpff4u(a =}.(oI7\C\ K = Pp(Z2(n9Ca!mS ?9 O[[9\B2(5\_' ?(ft~bn X" $na*)*R*m4>=_8}:(H0+,HO1*),+,HTf2(OfpP9ss!mS ? ( O[n(IB"p N * F6F6F * G B0f9h :(jZQ2(0:2@B2( $ G *)7465fi;}]}r;*+.'KD" =8+,<2-7eF" AfW0&('*+P&(D0/:3 RU'*<J/2;*+@2\ V &H0+.5=8+,<2-7ehDAfefi M]|9M.tM=uwuMM3Fqf7M}h Ay}}2\{%}Kv { $K AD*MMMg&/28:3 '*<25o3 /+G RU'5N&(69RN),<MWJ3<2/:3 82/2RU'06-&(RU'Q/T),&(105NHDG+/&j+fO/+.'*H/2;*+5N&(69RN)M3 5/28:3 '*<25o3 /2RN&('& YE 7p469RUC+.'RU'g_;7e]/&j3y/28:3 '*<25o3 /2RN&('& YEG 74]eu&ML+.C+.8MW4/2;*+EYn&(5U5N&MLRU'06/2;*+,&(8+ V -G(& RU'/<&(10/J/2;*+E5UR V RU/:3 /2RN&('*<u& Y{/2;0RN<3 -0-08&3();7epK$ 2D*u4 EnbXY5p 0f2u)j(pfj}YB0fZ9aj$d4*Bj$n4*Bj$t4*hy|My.*V"ffn$ +)* gm*j$p4[$ 4t(aa@[$4*Bj$n4*Bj$t74 j$ 4>= 9hOf[$p.4pyO[m(*BU9[[9m0(*f[2(paZm90BnQf2(fNB>= Ofo>a90Bpffac5P9S?(f>=JO\(? .:Mp],(yOQffm9h(,W52MmW irt+i*8<2/Z-08&MC+T/2;*+s-G&9<RU/2RUC+i-43 82/& Y/2;0RN<Z/2;*+,&(8+ V e YJ/2;*+.8+F+fORN<2/<Z<21*):;3698:3 -0; W/2;*+.'=[g_;7ehdA>/2;*+.8+TRN<\3$tlS.4~H0+.82RUC93 /2RN&('=[),&('*<2RNH0+.82RU'06j/2;*+F),&(5N&(8+,H698:3 -0;*<\& Y3(<82105N+,<BA" N * F6F6F * G <21*);y/2;43 j/ b-08& 2+,)./</& G eu^+,+/2;43 j/ G )M3 '0'*&(/D+lH0+,HO1*),+,HIY[8& V $n+*)74fW&(/2;*+.82LRN<7+ L&(105NHk3 5N<&DG+iH0+,HO1*).RUD05N+iY8& V $na*)74fe|7+./l1*<l),&('*<2RNH0+.8>/2;*+*8<2r/ Y8& V /2;0RN<H0+.82RUC93 /2RN&('/2;43 /sRN<s'*&(/sH0+,HO1*).RUD05N+yY[8& V $na*)74feg_;*+.p' >RN<s&(D0/:3 RU'*+,HY[8& V =n3j698:3 -0;\~H0+,HO1*).RUD05N+FY8& V !ADQX3 -0-05UXRU'06382105N+' !e^RU'*),g+ RN<Yn&(5U5N&MLRU'06k3-08& 2+,)./2RN&(H0+,HO1*).RUD05N+Y8& V $n+*)4fW/2;*+.'/2;*+.8++fORN<2/<T3698:3 -0; ~H0+.82RUC(3 D05N+Y[8& V <1*);/2;43/-08& 2+,)./<@RU'Q/& ke|+./@1*<@)M3 5U5 <21*):;j3i-08& m+,)./2RN&('7W{3 '*H),&('*<2RNH0+.8@/2;*+Z-08& m+,)./2RN&(B' " H& Y/2;*+l;X-&(/2;*+,<2RN< /282RU696+.8>& Y/2;*+Z82105N+ ),&('*<2/28:3 RU'Q/RU'Q/& ke@rt+Z'*&ML;43MC+Z/&s-08&MC+Z/2;43 /\`A~$CRN&(5o3 /+,< W43 '*HA/2;0RN<JCRN&(5o3 /2RN&('IRN<'*&(/X\~$8+,<2/&(8:3 D05N+9e^10-0-&9<+\`A&(8ARN<_Y$3 5N<+9e!g_;*+.'/2;*+.8+L&(105NH+fORN<2/q3698:3 -0; ~H0+.82RUC+,HlY8& V<1*);/2;43/ )M3 'ZDG++fO/+.'*H0+,HZ/&E3-08& 2+,)./2RN&('_ & 3(<J3>L;*&(5N+ERU's/2;*+uRU828+,HO10'*H*3 '/Y[&(8 V & g[e!g_;0RN<_RN<3 D*<2108HW0<2RU'*),+ _ RN<3-08& m+,)./2RN&('I&hRU'3Z698:3 -0;K~H0+.82RUC(3 D05N+@Y8& V eg_;*+Z),&(10'Q/+.8+f*3 V -05N+\-08+,<:+.'Q/+,HSRU'x{RU6*e{`.dTRN<E<21 ).RN+.'/@/&i-08&C+Z/2;*+Z'*+.6Q3 /2RUC+Z-43 82/@& Y]/2;*+/2;*+,&(8+ V e(F012rF182105N+1Fr-&9<2RU/2RUC+@),&('*<2/28:3 RU'/698:3 -0;x{RU69108+\`.d*!),&(10'/+.8+f03 V -05N+/&g_;7e4b/RN<uR VV +,HORo3 /+Z/&T);*+,):K/2;43 /@+.C+.82X698:3 -0;y/2;43 /@)M3 'SD+om * rn,~H0+.82RUC+,HyY8& V )M3 't3 5N<&D+[m n,~H0+.82RUC+,HsY[8& V e!&L+.C+.8MW0/2;*+-08& m+,)./2RN&('F& Y/2;*+/282RU696+.8J& RU'Q/&l/2;*+10'0RNwQ1*+u'*&H0+&H0+f*'*+,<3ZCRN&(5o3 /2RN&('& /2;43 /LRU5U57'*+.C+.8JD+E8+,<2/&(8+,He$r +@LRU5U5}<2/21*HOXTRU'I/2;*+@'*+fO/J<+,)./2RN&('k=[g_;7e7`9`AJ3Z-43 82/2RN).105o3 8)M3(<+>& Y{82105N+,<L;*+.8+@/2;*+>),&('C+.8<+& Y!g_;7e4blRN</2821*+9e)|p 8q < Dh DK*}{$Sp!,fZM!Q2,[fU5+X9JG2D*4(GP2\*|(2[f;:aQ.[QQfNW5f Y}hy|Mh{hy|My^hyAA |{Ay] fiM}$ [}fi3MfiuM%2MmW lD7RU'*).5U1*H0+,<@2 /2;Q1*<@2Da~H0+,HO1*)./2RN&('RN<E'*&(/@H0+,).RNH*3 D05N+9er;*+.'j RN<EH0+,HO1*).RUD05N+ZY[8& VW]3D08+M3(HO/2;O~n*8<2/\<+M3 8):;& Y/2;*+s/28+,+F& Yu3 5U5H0+.82RUC(3 /2RN&('*<lY[8& V Wq+M3();698:3 -0;D+.RU'06);*+,):K+,HYn&(8P),&('*<2RN<2/+.'*).XW{+.'*<2108+,<P/2;43 /k G RN<@Y[&(10'*HRU't*'0RU/+/2R V +9ex*&(8>\!W7L+<2;*&L/2;43 />):;*+,)KRU'06),&('*<2RN<2/+.'*).XsRN<_/282105UXs10'*H0+,).RNH*3 D05N+9e]|7+./JD+@3@L;*+.8+u),&('Q/:3 RU'*<3l-&9<2RU/2RUC+E),&('*<2/28:3 RU'/ 9Q3 '*Hi3P'*+.6Q3 /2RUC+),&('*</28:3 RU'Q/ WQD&(/2;LRU/2;T3 's+ V -0/X/282RU696+.8Meqx*&(8-08&MCRU'06l),&('*<2RN</+.'*).XW&('*+;43(</&i-08&MC+Z/2;43 / SP $n+*)4fW3 '*H/2;*+3 5U6&(82RU/2; V H0&+,<u'*&(/E'*+,),+,<<:3 82RU5UX<2/&(-yRU'y/2;0RN<u)M3(<:+T=pY[8& V<+ V R~H0+,).RNH*3 D0RU5URU/X& YPH0+,HO1*)./2RN&('RU'TAfeg_;*+<:3 V +I;*&(5NH0<Y[&(8/2;*+),& V -05N+ V +.'Q/:3 82X-08&(D05N+ V=-08&MCRU'06RU'*),&('*<RN<2/+.'*).X0A_/:3 KRU'06 Q RU'*</+M3(HI& W*;*+.'*),+@/2;*+@10'*H0+,).RNH*3 D0RU5URU/Xe@.!6u<s36+.'*+.8:3 5UR 3 /2RN&('& Y>2\!WJH0+,HO1*)./2RN&('RU'CD7RN<s/282105UX10'*H0+,).RNH*3 D05N+9e#u+f/s<+,)./2RN&('<2/21*HORN+,<_3@H0+,).RNH*3 D05N+Y8:3 6 V +.'/& YsDqWL;0RN):;iRU'\-43 82/2RN).105o3 8_L_3(<<21 ).RN+.'/]Yn&(8q/2;*+P*{*77,:V &H0+.5UR 3 /2RN&('7e62M0#v##isq# 2kvfi#0"vPz u28 105N+F3 -0-05URN)M3 /2RN&(' V 3MX3(H0H8+,HO10'*H*3 '/\RU'OYn&(8 V 3 /2RN&('/&t3698:3 -0;7e '6+.'*+.8:3 5$WH0+./+,)./2RU'06t8+f~HO10'*H*3 '*).XSRN<@HOR ).105U/i=8+,)M3 5U5]H0+./+.8 V RU'0RU'06L;*+./2;*+.83s698:3 -0;RN<@8+,HO10'*H*3 'Q/RN<P3 'B ~),& V -05N+./+-08&(D05N+ V AfWD010/E/2;*+.8+3 8+Z<& V +l/282RUCRo3 5!)M3(<+,<MWGL;0RN):;L+lLRU5U5h6+./u82RNHS& Y2W<2RU'*),+l/2;*+.X V 3,Xy).8+M3 /+3 82/2R4).Ro3 5U5UXRU'O*'0RU/+ZH0+.82RUC93 /2RN&('*<MeEx{RU8<2/MWa&('*),+382105N+>;43(<uD+,+.'S3 -0-05URN+,Hy/&T3\698:3 -0;3(),),&(8HORU'06F/&3F69RUC+.'k-08& 2+,)./2RN&('7W!RU/)M3 'kDG+s3 -0-05URN+,Hk3 6Q3 RU'k/&/2;*+8+,<2105U/2RU'06y698:3 -0;7Wq3(),),&(8HORU'06y/&/2;*+s<:3 V +-08& 2+,)./2RN&('7Wq3 '*Hj/2;0RN<lRU'*H0+f*'0RU/+.5UXeyg_;*+,<+\Y[1082/2;*+.83 -0-05URN)M3 /2RN&('*<&(DQCRN&(1*<25UXt-08&HO1*),+8+,HO10'*H*3 '/RU'OYn&(8 V 3 /2RN&('7eg_;*+.X3 8+l<:3 RNHI/&DG+QMfNB:.e'*&(/2;*+.8u)M3(<+& Yq/282RUCRo3 5{8+,HO10'*H*3 '*).XRU'S3698:3 -0;yRN</2;43 /q& Y} 9!8+.5o3 /2RN&(''*&H0+,<MW(R$e+9e{LRU/2;\+f03()./25UX/2;*+_<:3 V +_'*+.RU69;QD&(8<!RU'Z/2;*+<:3 V +_&(8H0+.8Meq%&('*<2RNH0+.8Yn&(8@RU'*<2/:3 '*),+\3s82105N+& YKRU'*H R$M]*j_4/2;*+.B' $M]*b_4 :eZg_;0RN<@82105N+)M3 'tD+Z3 -0-05URN+,HtRU'*H0+f*'0RU/+.5UXW+.C+.'SRY]1*<+.5N+,<<E3 -0-05URN)M3 /2RN&('*<>3 8+Z3,C&(RNH0+,HWD010/P3 5U5!3 -0-05URN)M3 /2RN&('*<P).8+M3 /+l/LRU'S8+.5o3 /2RN&('S'*&H0+,<e 'L;43 /{Y[&(5U5N&LJ<MW(L+),&('*<RNH0+.8{/2;43 /h/2;*+),&('*<2/2821*)./2RN&('\& Y4/2;*+698:3 -0;Z8+,<2105U/2RU'06uY8& V 382105N+3 -0-05URN)M3 /2RN&('-08+.C+.'Q/<J/2;*+6+.'*+.8:3 /2RN&('I& Y/LRU'T8+.5o3 /2RN&('F'*&H0+,<MW03 '*Hi/2;43 /J3>H0+.82RUC93 /2RN&('IH0&+,<'*&(/_),& V -082RN<+@3 'QX1*<+.5N+,<<J82105N+>3 -0-05URN)M3 /2RN&('7e?uRUC+.'j3T<:+./E& Y82105N+,< 3 '*Ht3 '~H0+.82RUC(3 /2RN&('5N+M3(HORU'06I/&F3I^0? kWRN<@<B3 RNHS/&iD+F.U ,2RY'*&82105N+,<& YX )M3 'DG+T3 -0-05URN+,Hk/&RU'3 '&(82RU69RU'43 5L3MXWqR$e+9e3 5U5J3 -0-05URN)M3 /2RN&('*<\& Yu3 'Xt82105N+& YX &('3 8+i1*<+.5N+,<<e&(8+iYn&(8 V 3 5U5UXWRN<Z).5N&9<+,HkLPe 8Me /Me 3 '*HkLPe 8Me /Mej3 '\~H0+.82RUC93 /2RN&('N FtFtF G G " kWL;*+.8+ !,= IE\+\ K AhRN<q/2;*+J698:3 -0;s&(D0/:3 RU'*+,HDX/2;*+3 -0-05URN)M3 /2RN&('T& Y3E82105N+& Y&('' W0RYhYn&(8+.C+.82XT82105N+ & YF W0Yn&(8+.C+.82XF-08& 2+,)./2RN&('3(),),&(8HORU'06i/&\/2;*+P-08& 2+,)./2RN&(Y8& V JON L RU'Q/& kW/2;*+.8++fRN<2/<@3i-08& 2+,)./2RN&(B' qY[8& V JON L /&,= I8\pY\ K AfW<1*);S/2;43 /g"Q e?uRUC+.'I3<+./_& Y82105N+,<@ 3 '*Hs3698:3 -0g; ZWRY}3l).5N&9<+,Hi698:3 -0;sRN<@~H0+.82RUC(3 D05N+uY[8& V W/2;*+.'TRU/RN<10'0RNw1*+9eq&(8+,&C+.8MWORY}/2;0RN<_698:3 -0;FRN<H0+.82RUC93 D05N+ELRU/2; 82105N+P3 -0-05URN)M3 /2RN&('*<W0/2;*+.' yRN<_/2;*+ V 3OR V 3 55N+.'069/2;& Y!3 'U\~H0+.82RUC93 /2RN&('7W43 '*HI3 5U57H0+.82RUC(3 /2RN&('*<& Y}5N+.'069/2; S5N+M3(HT/&ZRU/Mehr;*+.'FRU/J+fRN<2/<WL+@)M3 5U5RU//2;*+.U fl&LPe 8Me /MeWOL;0RN):;L+@'*&(/C+ [ e|7+./h1*<h3 5N<&uH0+f*'*+_3 '*&(/2;*+.8h'*&(/2RN&('7W(8+.5o3 /+,Hl/&/2;*+]Y$3()./{/2;43 /}L+_3 8+RU'Q/+.8+,</+,HRU'lRU828+,HO10'*H*3 'Q/698:3 -0;*<Me '/2;0RN<{-+.8<2-G+,)./2RUC+9W(5N+./{1*<h<:3,X>/2;43 /!3 'ZRU828+,HO10'*H*3 '/!698:3 -0;RN<afp*LPe 8Me /Meh3u<+./h& Y482105N+,<RY!+.C+.82XT698:3 -0;I/2;43 /)M3 'FD+P&(D0/:3 RU'*+,HFDXI3 -0-05UXRU'06s&('*+@& Yh/2;*&9<:+E82105N+,<&('RN<J+,w10RUC(3 5N+.'//&ke}u<<21 V RU'06@/2;43 +/ RN<q3 'RU828+,HO10'*H*3 '/]698:3 -0;3 '*HZ/2;43 /q698:3 -0;*<]&(D0/:3 RU'*+,HDQXZ3u82105N+J3 -0-05URN)M3 /2RN&('3 8+@-010/RU'/&\RU828+,HO10'*H*3 'Q/Y[&(8 V W*RY!3Y[105U5698:3 -0;)M3 'FD+@H0+.82RUC+,HFY[8& V /2;*+.'IRU/RN<J10'0RNwQ1*+9e'OY[&(8 V 3 5U5UXW/2;*+Z'*&(/2RN&('j& Y_3T).5N&9<:+,H698:3 -0;/28:3 '*<25o3 /+,<P/2;*+lY$3()./@/2;43 /@'*&(/2;0RU'06)M3 'D+\3(H0H0+,H/2;43 /u;43(<'*&(/uDG+,+.'S3 5U8+M3(HOX3(H0H0+,HWGL;*+.8+M3(<u/2;*+P'*&(/2RN&('& Y3ZY[105U5698:3 -0;S<:3,XO</2;43 /'*&(/2;0RU'06T)M3 'ev@v*+0fi M]|9M.tM=uwuMM3FD+\3(H0H0+,Ht/2;43 /P8+M3 5U5UXt3(H0H0<@'*+.LRU'OY[&(8 V 3 /2RN&('t/&I/2;*+698:3 -0;7e\r;*+.'t/2;*+\).5N&9<2108+& YJ3s698:3 -0;+fORN<2/<MWO/2;*+.'/2;*+PRU828+,HO10'*H*3 'Q/Y[&(8 V & Y!/2;0RN<J).5N&9<108+PRN<J+f*3()./25UXT/2;*+EY105U5698:3 -0;H0+.82RUC93 D05N+EY8& V Ze10/'*&(/+/2;43 /uL;*+.'/2;*+>Y105U5}698:3 -0;+fRN<2/<W*/2;*+l).5N&9<2108+H0&+,<'*&(/'*+,),+,<<B3 82RU5UX+fRN</<l=[<+,+>-08&&& 8&(-7e7`MAfeh}hAy.}9]{%}$}yA6g_;*+'*&(/2RN&('s& Y3Y[105U5*698:3 -0;\D+.RU'06 V &(8+6+.'*+.8:3 5a/2;43 '\/2;*+'*&(/2RN&('i& Y73@).5N&9<2108+9WQL+J)M3 '6+.'*+.8:3 5UR M+/2;*+H0+f*'0RU/2RN&('& Y*'0RU/++fO-43 '*<2RN&('k<+./<P1*<+,HjRU'k3I-08+.CRN&(1*<-43 -G+.8T=[3 6+./l 1069'0RN+.8MW!99O`AfW3 '*H3(H0&(-0/J/2;*+@Y[&(5U5N&LRU'06&('*+9fi;}]} }]Ayy .h{%}hM}[AyATJ M.JmlBNBE o(U2F*'0RU/+Z+fO-43 '*<2RN&('<+./>G= .(S? fS:}pC=Of)j9o.Z(K!Q.BM?9[n( F6F6F B0f9_fL$ 4p]f9+5N65oc5E5e fa9ZS: [ Qp!B4(mf4 5RN<P3i*'0RU/+Z+fO-43 '*<2RN&('t<+./\=pYme+9e<fAfWH0+,HO1*)./2RN&('tRU'S D+,),& V +,<PH0+,).RNH*3 D05N+=D010/ERU/@RN<u'*&(/3 G:B:,(S:t),&('*HORU/2RN&('jYn&(8>H0+,).RNH*3 D0RU5URU/X*Afe '*H0+,+,HWRU'k&(8H0+.8>/&IH0+./+.8 V RU'*+iL;*+./2;*+.83^0? RN<H0+,HO1*).RUD05N+sY[8& V 3y@ $n+*)4fWqRU/<21 ),+,<Z/&S),& V -010/+I [ W!/2;*+.'/&S);*+,):K/2;*+T+fORN<2/+.'*),+T& YE3-08& 2+,)./2RN&('FY8& V /&\ [ e^R V RU5o3 825UXW*),&('*<2RN</+.'*).XT):;*+,)KO<JRU'I2\t3 8+PH0&('*+P&(' [ ek<}hAycy .]{%}$} Ay|AJ . P " $na*)*m.4knbX 9hOfB pS<q*[)jB0(0Bn(y,,c5kU0fs pP:(0Bpf.4q V$m [ n *m4@p>(0fo.f4M=(Gi8}9t:ZQ2(0:2fm( $na*)7>4 (jlQ2(0:2PB2( $m [ n64 5yng_;0RN<-08&(-+.82/XI3 5U5N&LJ<J1*</&Z-08&C+@/2;43 /J/2;*+P),&('C+.8<+P& Y!g_;7e*blRN</2821*+EL;*+.'KRN<J8+,<2/282RN)./+,H/&\3l*'0RU/+P+fO-43 '*<2RN&('<:+./Mephy|My , " $n+*)g*m4IBnbX=Y9hOf~ osk<]*FjBO(0f[9,.c5UOft pa(0fo.f4l Ofj)j(pf } YB0fO9>j$4*B[$n`4*B[$t4*Bj$p4 j$Y4S(Gka9j$d4*Bj$n4*Bj$t4 [$ 4>=9hO.2j$p.4>pOZ[2(0f[[(j2O:(0f[2(4Z2J(0f[Q.22@fNB6 50=2MmWj$74;*&(5NH0<u3(<u3-43 82/2RN).105o3 8E)M3(<+P& Y]g_;7e4bOe|7+./1*<J'*&L-08&C+P/2;*+ $74_-43 82/Me^RU'*),+>RN<RU'*),&('*<2RN<2/+.'/MWQ/2;*+J-08+.CRN&(1*<]-08&(-G+.82/X3(<:<+.82/<!/2;43 /H$m [ n m* h4 RN<!RU'*),&('*<2RN</+.'Q/Me!g_;7eE+.'*<108+,<!/2;43 /j$ J4fe/2;*+.8+_+fRN</<{3698:3 -0; <21*);l/2;43 /`A}j$ d4B* jn$ [ 4B* jp$ 4 Ij$ J4fW93 '*HA}j$ d4B* jn$ [ 4^RU'*),+ij$ d4B* jn$ 4B* jt$ 4 jn$ [ Z4 =[g_;7e7dAfW7L+\&(D0/:3 RU'kj$ d4B* jn$ 4B* jt$ 4B* [p$ .4 j$ 4fe|7+./1*<E'*&ML<10-0-G&9<+/2;43 /j$ d4B* jn$ 4B* jt$ 4 jj$ J4fW73 '*HS-08&MC+Z/2;43 /ERU/ERN<P3 D*<2108He 'y/2;43 /P)M3(<+9W/2;*+.8+PL&(105NHID+>3Z698:3 -0;J \~H0+.82RUC93 D05N+@Y[8& V <21*):;I/2;43 /-08& 2+,)./<JRU'/&Z =[g_;7e4di3 6Q3 RU'aAfe[['*HF<2RU'*),+P P WOL+P<;*&(105NHF;43,C+[$ 4B* jn$ 4 I[$ 4@=[g_;7e`Afh/2;0RN<JRN<3 D*<2108He.(&(8+E6+.'*+.8:3 5U5UXW4&('*+@&(D0/:3 RU'*</2;*+@Y[&(5U5N&LRU'06H0+,).RNH*3 D0RU5URU/XF8+,<2105U/<W0H0+.-G+.'*HORU'06&('FL;*+./2;*+.8XWD]W0&(8fifflmDtRN<3*'0RU/++f-43 '*<RN&('I<+./Meuqyn<$9.fi;}hAyyh{%}hM}yAy|Ae 0f pZ@W5W5=Q2(0,[n(2 p2.nQfN=E:(0Bpf.aL:(aQ2(0,[n(p\V92ZQ.[QQfN=_Q(OM[[(2CDoE,.lM!2.nQfNW5;fi3MfiuM%e 0fDoIW5W5=lQ29O,[n(tDpT2.nQfN=ifOPf\(p*T[f;:taQ2,[fUV2CDa5V es0f*lmDo>W5pW5U>=]Q(OM[[(2CDo>Q2,[fU52MmW]^10-0-&9<+ENR <_3EY2e+9e<MehE+,).RNH*3 D0RU5URU/Xs& Y7-08&(D05N+ V <RU'i 3 '*Hi\FYn&(5U5N&MLJ<Y[8& V -08&(-+.82/XcOe 'I2CD!W*L;*+.'/2;*+3 '*<2L+.8RN<(fX+,<%(W*RU/)M3 'DG+>&(D0/:3 RU'*+,HIRU'I*'0RU/+>/2R V +9*L+P-08&),+,+,H3(<Yn&(8D7=[<:+,+E-08&& Y!& Y!/2;*+,&(8+ V `MAD010/),&('*<2RN</+.'*).XT):;*+,)KO<3 8+PH0&('*+&('F/2;*+EY[105U57698:3 -0;IRU'*<2/+M3(HI&/2;*+@698:3 -0;IRU/<:+.5Ymeu&MLPW<210-0-G&9<:+DRN<F3tYme+9e<Me \ +fORN<2/<MWJ/2;Q1*<T/2;*+yH0+.82RUC(3 /2RN&('/28+,+yRU'DRN<*'0RU/+9Wu3 '*H),&('*<2RN<2/+.'*).X);*+,):K< V 3,X&('05UX).10/I<:& V +S-43 82/<F& Yl/2;0RN<T/28+,+9eE+,HO1*)./2RN&('RU'sD8+ V 3 RU'*<10'*H0+,).RNH*3 D05N+lDG+,)M3 1*<:+>L;*+.'p" OWa&('*+l&(D0/:3 RU'*<u/2;*+>2\ V &H0+.5$WaRU'L;0RN);H0+,HO1*)./2RN&('SRN</282105UX10'*H0+,).RNH*3 D05N+9ex{RU'43 5U5UXWRYROl9DSRN<3EY2e+9e<MeUW [\ +fORN<2/<MW/2;Q1*</2;*+H0+.82RUC93 /2RN&('T/28+,+JRN<]*'0RU/+9W3 '*Hs),&('*<2RN<2/+.'*).X);*+,):K< V 3,XF&('05UXT).10/J-43 82/<& Yh/2;0RN</28+,+9eu&(/+/2;43 /_/2;*+E),&('*HORU/2RN&(' pl~DSRN<3P*'0RU/+u+fO-43 '*<2RN&('T<+./ RN<_<2/28&('06+.8_/2;43 ' DG&(/2;m3 '*HmD3 8+E*'0RU/+P+fO-43 '*<2RN&('<:+./< :e!g_;*+uY[&(5U5N&LRU'06-08&(-+.82/Xlm1*<2/2R4+,</2;0RN<),&('*HORU/2RN&('75pS29G2BB:,(B;:TQ.[QQfNW5yn!5!K*}{$pFa9(aBD (C<q*[yjBO(0f[9M.>=\O.k2CD$D vv$|] AD2MmW rt+@D010RU5NH3Z8+,HO1*)./2RN&('Y8& V }N 7 t.{ =[g_;Q1*+9W}`MbO`.dA/&lsDG hW*L;*+.8+E/2;*+u&(D0/:3 RU'*+,HT82105N+E<+./<@3 '*HmDj3 8+uDG&(/2;s*'0RU/+E+fO-43 '*<2RN&('F<+./<Meg_;0RN<E8+,HO1*)./2RN&('S8+.5URN+,<@&('S/2;*+l&('*+lD010RU5U/uYn&(8-08&CRU'06F/2;*+l<+ V R~H0+,).RNH*3 D0RU5URU/X& Y]2\~=/2;*+,&(8+ V vAfe|7+./Z1*<*8<2/Z-08+,<+.'//2;*+i/L&yKRU'*Hk& Y*'0RU/+s+fO-43 '*<2RN&('<+./<1*<+,HkRU'/2;0RN<l8+,HO1*)./2RN&('7eDRN<3*'0RU/++f-43 '*<RN&('S<:+./E<RU'*),+l&('05UX8+.5o3 /2RN&(''*&H0+,<P3 8+l-08+,<+.'/@RU'S/2;*+),&('*).5U1*<2RN&('t& Y]82105N+,<MEDRN<RU'*H0+,+,HF3P-43 82/2RN).105o3 8J)M3(<:+& Y78:3 '06+f~$8+,<2/282RN)./+,HI82105N+,<E=[<:+,+ 8&(-7e`9`AfeFRN<_3 5N<&Z3P*'0RU/+u+fO-43 '*<2RN&('<+./P<2RU'*),+9WYn&(8P+.C+.82Xy82105N+\RU'W/2;*+Z;QX-G&(/2;*+,<2RN<>RN<PHORN<),&('0'*+,)./+,HjY8& V /2;*+),&('*).5U1*<2RN&('=L+\)M3 5U5/2;*+,<+u82105N+,<@(p.(4G2,2*Afe u&(/+/2;0RN</2R V +u/2;43 /MWO/2;*&(1069;* RN</282RUCRo3 5U5UXT3@Y2e+9e<MeUW/2;*+E).5N&9<2108+E& Y{3698:3 -0;ILPe 8Me /MeH0&+,<J'*&(/J'*+,),+,<<:3 82RU5UXF+fORN<2/Me+,)M3 5U5@/2;*+}/:3 K+,<3(<TRU'0-010/F/L&L&(8H0< 3 '*H 7@3 '*H3<:+./T& Yl82105N+,<" * F6F6F * G nQWh+M3();k82105N+/ D+.RU'063F-43 RU8& YJL&(8H0Z< $ ,* c4fW!3 '*H3(<2KO<PL;*+./2;*+.8Z/2;*+.8+\RN<Z3H0+.82RUC93 /2RN&('\Y[8& V /j& 7[ehg_;*+.8+JRN<]3 'iR VV +,HORo3 /+H0+.82RUC93 /2RN&('\Y[8& V /j& 77=L+'*&(/d+7NARY2WhY[&(8Z<& V +s Q`W " W 3 '*H " 6 et Q.BM ?9[n(Y[8& V /& =L+s'*&(/+ARN<3Z<+,w1*+.'*),j+ " N" eF6F6Frt+;43MC+\<2;*&L't;*&ML/2;0RN<P-08&(D05N+ V )M3 'D++f-08+,<<:+,HRU'/2;*+ V &H0+.5$@/&I3FL&(8JH "] F6F6F ] RN<3(<<&).Ro3 /+,H/2;*+u698:3 -0;I$M4fW03 '*Hi/&Z3 'QXi82105N+E7"ff$M_ F6F6F _ *W!4NR<(3<<&).Ro3 /+,HF6F6FG/2;*+698:3 -0;82105N+ $.4fW{3(<>8+.-08+,<+.'Q/+,HRU'jx{RU6*eq`Mvt=L;*+.8+RN<P698+M3 /+.8/2;43 'k3 5U5]&(/2;*+.8l),&('*),+.-0//X-+,<BAfe!g_;*+.'Rt$M 4 P $n$M4* $`4y4>=[<:+,+E-08&& Y!& Yhg_;7eavAfe|7+./F1*<s'*&L <2-05URU/F+M3();&(D0/:3 RU'*+,H82105N+ $)4RU'/&&('*+yHORN<:),&('0'*+,)./+,HRU'OY[+.8+.'*),+S82105N+p$.43 '*H&('*+>8:3 '06+f~$8+,<2/282RN)./+,HS+.C&(5U10/2RN&('82105N+++$)4feJrt+>HORN<2/2RU'06910RN<2;RU'/2;*+>;QX-G&(/2;*+,<2RN<u& Y+$)4/L&<210D0698:3 -0;*<MZ/2;*+y(f(4W}L;0RN);),&(828+,<2-&('*H0<>/&/2;*+\;X-&(/2;*+,<2RN<l& $)4fWq3 '*Hj/2;*+yBf[a9[n(4WL;0RN);),&(828+,<-G&('*H0<F/&k/2;*+S),&('*).5U1*<2RN&('& Y($)4fe /TRN<T+M3(<2X/&k):;*+,)K/2;43 /I&('*+y-43 82/I& Y>/2;*+3 D&MC++,w10RUC(3 5N+.'*),+t</2RU5U5u;*&(5NH0<$M 4 P $n$M4*)$4Hl+$4y4feu&ML+.C+.8MW/2;*+),&('QC+.8<:+tRN<F'*&5N&('06+.8IC93 5URNH);*+,):KDQX+fO+ V -05N+t/2;43 /MWRY/ "" $ *3W4>nQW@L+;43MC+K* {$D *|{9|ffC` ]*ffff2$->* {ff2;fi M]|9M.tM=uwuMM3F$M4B$)4u%EuuOriginD*v$|RU'/&$.4D+$.4uDestinationx{RU69108+\`MvOqg8:3 '*<mY[&(8 V 3 /2RN&('*<Y[8& V /2;*+}V &H0+.5N<& Y{/2;*+E_Yn3 V RU5UX+Z=n3 -0-05UXm$)4&('*),+9WO/2;*+.'F/L&Z/2R V +,<,D+$.41*<2RU'06$ W4 P $n$ 4*)$`4)l/D$4y4/2;*&(1069;HOR+.8+.'Q/'*&H0+,<gT\D010//2;*+@<:3 V +@'*&H0+ByAOAfert+/2;Q1*<{'*+,+,H/2;*+]'*&(/2RN&('Z& Ya3M3 -0-05URN)M3 /2RN&('& Ya382105N+2D+$)4fRU/}RN<{<21*);l/2;43 /{/2;*+]-08& 2+,)./2RN&('& Y]RU/<EH0+,<2/2RU'43 /2RN&('-43 82/ERN<@3 V 3 -0-0RU'06F/&F3i<210D0698:3 -0;S/2;43 /EL3(<@&(D0/:3 RU'*+,HSDQXy3 -0-05UXRU'06F/2;*+82105N+$.4fW03 '*H/2;43 /L3(<'*+.C+.81*<+,H\/&-08& m+,).//2;*+uH0+,<2/2RU'43 /2RN&('T-43 82/& Y}3 'X\82105N+& Y{$4fWRU'*).5U1*HORU'06D+$.4_RU/<+.5Y2e]y&(8+,&MC+.8MWa/2;*+P&(82RU69RU'y3 '*HH0+,<2/2RU'43 /2RN&(' V 1*<2/D+E-08& 2+,)./+,HIRU'Q/&iHORN<[2&(RU'Q/-43 /2;*<l=R$e+9e3S'*&H0+I& YE/2;*+I&(82RU69RU')M3 '0'*&(/i;43,C+F/2;*+<:3 V +FR V 3 6+F;43(<s3S'*&H0+F& Y@/2;*+IH0+,</2RU'43 /2RN&('aAfe YuL+8+,<2/282RN)./&(108<+.5UC+,<_RU'F<& V +uL3MX/&l6&&HT3 -0-05URN)M3 /2RN&('*<J& Y}82105N+,<_& YT+$4fW/2;*+.'TL+@)M3 'TC+.82RY[X\/2;43 /$M 4 P $n$M4* $4y4R$M 4 P $n$M4*)$4l*+$4y4feg_;0RN<8+,<2/282RN)./2RN&('RN<&(D0/:3 RU'*+,HDXT1*<2RU'06i),&('*<2/28:3 RU'/<MWa/2;43 /LRU5U5{3 5U5N&L+.C+.82XF6&&H3 -0-05URN)M3 /2RN&('& Y>382105N+I& Y9$4fW3 '*HD+FCRN&(5o3 /+,HDXk/2;*+&(D0/:3 RU'*+,H698:3 -0;&(/2;*+.82LRN<+9e|7+./i1*<\'*&(/+K $`43 '*HD $`4E/2;*+'*+.L<+./<& YJRU'OY[+.8+.'*),+82105N+,<l3 '*H+.C&(5U10/2RN&('k82105N+,<eFg_;*+\'*+.L/28:3 '*<2Y[&(8 V 3 /2RN&('kRN<H0+,<).82RUD+,HRU'x{RU6*e`MOe /i3 5U5N&LJ<T/&j&(D0/:3 RU'/2;*+IYn&(5U5N&MLRU'068+,<2105U/M7$M74 P$n $M4*) $4*)D $`4*Lm Q * n4fe!g_;*+J'43 V +,<_& Y78+.5o3 /2RN&('s/X-G+,d< "ZW 3 '*H;43,C+uD+,+.'i):;*&9<+.'/&Z69RUC+>3 'IRU'/210RU/2RUC+PRNH0+M3Z& Yh/2;*+.RU8J8&(5N+@D010/J/2;*+.XF3 8+_m1*<2/_/X-G+,<3(<J&(/2;*+.8<Meq8+.5o3 /2RN&('I'*&H08+ $i 4Y[8& V 3T'*&H0+ 6/&I3F'*&H0+ ; V +M3 '*<>/2;43 /P/2;*+\5N+./2/+.8 ;43(<>DG+,+.'&(D0/:3 RU'*+,HtDQXt3 -0-05UXRU'06/2;*+@82105N+ e!8+.5o3 /2RN&('I'*&H08+ $ 4]Y[8& V G /& V +M3 '*<J/2;43 /J/2;*+E5N+./2/+.8 _ G D+.5N&('06</&Z/2;*+<210DL&(8H&('L;0RN);\/2;*+82105N+, G;43(<!DG+,+.'s3 -0-05URN+,Hae "RN<h1*<+,H/&ERU'*HORN)M3 /+/2;43 /q/L&>),&('*),+.-0/q'*&H0+,<;43,C+/&PD+-08& 2+,)./+,H&('\/2;*+<:3 V +'*&H0+>=RU'T%?/+.8 V <MWL+JL&(105NHs<+,+RU/3(<3@),& ~$8+fYn+.8+.'*),+5URU'0K*Afeg_;*+Z+.C&(5U10/2RN&('82105N+~.0$ c4fW<2/:3 82/2RU'06sY8& V 3i-43 /2;S8+.-08+,<+.'Q/2RU'06/2;*+l<10DQL&(8H 1*<+,Hy/&T3 -0-05UX_3 '*HY8& V /2;*+l8+.-08+,<+.'Q/:3 /2RN&('j& ]6+.'*+.8:3 /+,HSDXB $ c4fW-08&HO1*),+,<u/2;*+/L&T8+.5o3 /2RN&(''*&H0+,</X-+,HKP<2R V 105o3 /2RU'06/2;*+P3 -0-05URN)M3 /2RN&('& $ 4fWO/2;Q1*<, W03 '*HF/2;*+E8+.5o3 /2RN&('I'*&H0+,<_/X-G+,HL;0RN):;V 3 82KF/2;*+8+.-08+,<+.'Q/:3 /2RN&('& ]3(<1*<+,HDQX3 'S3 -0-05URN)M3 /2RN&('& YT 2eg_;*+>'*+.6Q3 /2RUC+l),&('*<2/28:3 RU'Q/-08+.C+.'Q/<_3 'i3 -0-05URN)M3 /2RN&('T& YD $ 4hRU'\L;0RN);i/L&>'*&H0+,<& Y/2;*+J&(82RU69RU'i3 '*HH0+,</2RU'43 /2RN&('-43 82/<q;43MC+/2;*+P<:3 V +PR V 3 6+=n3Z'*&H0+@'*+,),+,<<:3 82RU5UXF&(D0/:3 RU'*+,HIDXs<:& V +>3 -0-05URN)M3 /2RN&('y& Yh/2;*+@82105N+ $ c42Af0L;0RU5N+/2;*+\-&9<2RU/2RUC+s),&('*<2/28:3 RU'Q/ Q -08+.C+.'/<l<1*);3I<210D0698:3 -0;k/&ID+\1*<+,Hj/LRN),+Y[&(8Z3 -0-05UXRU'06pD $ c4LRU/2;HOR+.8+.'/@-08& m+,)./2RN&('*<@& YRU/<@&(82RU69RU'7RU/E<:3,XO<u/2;43 /ERU'y/2;0RN<@)M3(<:+9Wa/2;*+l/L&T-08& 2+,)./2RN&('*<@& Y]/2;*+&(82RU69RU'*< V 1*<2/JD+E/2;*+P<:3 V +9eU44h{%}$Myyn A'AyUff*fi`ffC0ffCy||7+./_1*<_'*&MLYn&).1*<&('T/2;*+u82105N+,<_/2;43 /L+.8+E1*<:+,Hi/&Z<&(5UC+u/2;*+G.{*7.:-08&(D05N+ V eqD0RN),&(5N&(8+,H698:3 -0;=82105N+&(8]),&('*</28:3 RU'Q/BA{RN<q<B3 RNHZ/&EDG+E2(QB.[Bn,2=8Me 8MeAPRYRU/<!<+,),&('*H-43 82/=[),&('*).5U1*<RN&('i&(8&(D05URU6Q3 /2RN&('aA_H0&+,<_'*&(/),& V -082RN<+P3 'QXs6+.'*+.82RN)@),&('*),+.-0/'*&H0+9eqrt+1*<:+/2;0RN<+fO-08+,<<2RN&('FDXs3 '43 5N&(69X7$-fi3MfiuM%$M4B$ 4==#==4=x{RU69108+\`MOJ+,HO1*)./2RN&('TY8& Vu=E=uu=u=#u#Q=uuD.0$ c4/2;*+}Dvv$|/&2CDK*}{$hW*LRU/2;*Dj3 '*HmY2e+9e<MeLRU/2;T/2;*+<:& ~)M3 5U5N+,Hi82105N+,<_RU'T@3 /:3 5N&(6*WL;*+.8+E3 5U5C93 82Ro3 D05N+,<_& Y/2;*+u;*+M3(H V 1*<2/J3 -0-G+M3 8_RU's/2;*+D&HOX=[D0RU/+.DG&(105E+./s3 5$eUW@`Mb9b9vAfe^1*);82105N+,<T3 8+y3 5N<&j)M3 5U5N+,H.2,RU'/2;*+5URU/+.8:3 /2108+9e%&('*<2RNH0+.8Yn&(8RU'*<2/:3 '*),+@/2;*+P82105N+,<J& Yhx{RU6*e4vO 3 '*H 3 8+@8:3 '06+@8+,</282RN)./+,HW0L;0RU5N+ RN<'*&(/Me5N<&S'*&(/2RN),+I/2;43 /s3S8:3 '06+F8+,<2/282RN)./+,H82105N+ )M3 'D+FH0+,),& V -G&9<:+,HRU'Q/&3 '+,wQ10RUC93 5N+.'Q/s<+./& Y]82105N+,<7$ 4LRU/2;+f*3()./25UX&('*+l'*&H0+lRU'S),&('*).5U1*<2RN&('=[+.RU/2;*+.8P3 'SRU'*HORUCRNHO143 5!),&('*),+.-0/@'*&H0+&(8P38+.5o3 /2RN&('S'*&H0+AfeEg_;*+.8+lRN<E&('*+>82105N+>Yn&(8u+M3():;y'*&H0+Z& Yq/2;*+Z),&('*).5U1*<2RN&('& _Y[&(8E+M3();SRU'*HORUCRNHO143 5'*&H0d+ W&('*+_82105N+_LRU/2;<:3 V +_;X-&(/2;*+,<2RN<]3(< 3 '*H\3E),&('*).5U1*<RN&('\8+,<2/282RN)./+,H/[& (Y[&(8q+M3():;\8+.5o3 /2RN&(''*&H08+ 0W{&('*+82105N+iL;*&9<+i;QX-G&(/2;*+,<2RN<lRN</2;*+HORN<[2&(RU'Q/Z10'0RN&('& YJ/2;*+;X-&(/2;*+,<2RN<l& 3 '*H& Yu3 5U5RU'*HORUCRNHO143 5q),&('*),+.-0/@'*&H0+,<@& Y/2;*+l),&('*).5U1*<RN&('t& W3 '*H),&('*).5U1*<2RN&('RNb< 0WGLRU/2;t<:3 V +l'*+.RU69;QD&(8<3(<@RU' eig_;*+5N&(69RN)M3 5]RU'/+.82-08+./:3 /2RN&('& Y_<21*):;t82105N+,<3 8+y=pY10'*)./2RN&('tY8+,+Au8:3 '06+8+,<2/282RN)./+,Hju&(82'82105N+,<Me Y]3^0?RN<H0+,HO1*).RUD05N+@Y[8& V 3<:+./& Y!8Me 8Me]82105N+,<XW*/2;*+.'RU/JRN<H0+,HO1*).RUD05N+PY8& V /2;*+P<+./&/2;*+.RU8H0+,),& V -&9<2RU/2RN&('*<E$t74fW43 '*HI8+,).RU-08&)M3 5U5UXeu&ML+.C+.8MWG3(<<&&('3(<),&('*<2/28:3 RU'Q/<E3 8+@RU'C&(5UC+,HW/2;0RN<J+,w10RUC(3 5N+.'*),+>H0&+,<'*&(/;*&(5NH3 'QX V &(8+9eynM.2@m(Q2ff[f[,sBUfPo>1<q*[)jfO(0f[(yM.c52MmW I^RU'*),+I3 5U5_698:3 -0;*<\3 8+T-010/ZRU'Q/&S'*&(8 V 3 5_Yn&(8 V W]3 'RU'*HORUCRNHO143 5 V 3 82K+.83 -0-+M3 8<3 / V &9<2/(& '*),+sRU'3698:3 -0;7eSg_;*+'1 V D+.8\& YRU'*HORUCRNHO143 5'*&H0+,<l).8+M3 /+,HDXj/2;*+s<+./Z& YJ82105N+,<RN<lD&(10'*H0+,HDQX " r\j- [ J L e^&I/2;*+'Q1 V D+.8& YJ8+.5o3 /2RN&(''*&H0+,<l).8+M3 /+,H='*&/LRU'8+.5o3 /2RN&(''*&H0+,<>3 8+).8+M3 /+,H4AuRN<ED&(10'*H0+,HDQXo " G$3 ( $[46eV4 WL;*+.8+ RN<E/2;*+Z'1 V D+.8& Y]8+.5o3 /2RN&('S/X-+,<LRU/2;t369RUC+.'t3 82RU/X 3 -0-+M3 82RUD'0 6sRU't382105N+Z),&('*).5U1*<2RN&('7W73 '*H K RN</2;*+l698+M3 /+,<2/3 82RU/XT& Y}<21*):;3P8+.5o3 /2RN&('/X-G+9e]^&l/2;*+E).5N&9<2108+E& Yh3698:3 -0;I)M3 'TDG+E&(D0/:3 RU'*+,HTLRU/2;I3lH0+.82RUC(3 /2RN&('I&5N+.'069/2;BO\e!rt+E/2;1*<&(D0/:3 RU'S [ RU'T*'0RU/+P/2R V +9eu&(/+]/2;43 /MW9),&('/28:3 82X/&6+.'*+.8:3 5*'0RU/+_+f-43 '*<2RN&('Z<+./<MW(+fORN<2/+.'*),+& Y4/2;*+).5N&9<108+_3 '*Hl+fORN<2/+.'*),+& Yh/2;*+uY105U5698:3 -0;3 8+>+,wQ10RUC93 5N+.'Q/J'*&(/2RN&('*<JRU'I/2;*+@)M3(<+@& Yh8:3 '06+@8+,<2/282RN)./+,HF82105N+,<Me /_Yn&(5U5N&MLJ<Y[8& V/2;*+q-08&& Y*& Y0-08&(-G+.82/X`9`q/2;43 /}/2;*+q5N+.'069/2;& Y43H0+.82RUC(3 /2RN&('>Y8& V T/& [ RN<RU'~$ G Q 4fW L;*+.8+ \RN</2;*+<2R M+&$n+*)4q3 '*H K RN<q/2;*+_698+M3 /+,<2/3 82RU/X& Y3u8+.5o3 /2RN&('/X-+J3 -0-G+M3 82RU'06PRU'3u82105N+),&('*).5U1*<2RN&('7eg_;0RN<q8&(1069;10-0-G+.8qD&(10'*H),&(105NH\D+_8+f*'*+,HD010/qRU/]RN<q<21 ).RN+.'Q//&@&(D0/:3 RU'/2;*+_Yn&(5U5N&MLRU'06>-08&(-G+.82/XWL;0RN);LRU5U5DG+1*<+,H/2;08&(1069;*&(10/l/2;*+i-08&& Y[<l& Y),& V -05N+fRU/Xj8+,<2105U/<lRU'C&(5UCRU'06y8:3 '06+s8+,<2/282RN)./+,H82105N+,<Me06$-fi M]|9M.tM=uwuMM3FynaQfOE :fG[n(T9{O\j(l 9B[ :mfU9[[9I ::*BJoZ(*f$(4M =(M? fSZm9QEB.[Bn,2,.qmufNB=!OuNf9Fmu(Cg!fBM?9[n(Pf2(pq0(@:(a9ln(@:f2T$sOEft slmE$n+*)465p'FL;43 /Yn&(5U5N&MLJ<MW0L+>3(<<21 V +P/2;43 //2;*+>3 82RU/XF& Yh8+.5o3 /2RN&('/X-+,<RN<D&(10'*H0+,HFDQXF3Z),&('*<2/:3 'Q/Meqhy|Myf[fn,2iBNB6<p1!m(aN.W5$V 2(0,[n(i2[{%}huyyn A'Ayy|esO.CD9a(2@m9QP2S!_ ` !m(aN.W5V !90BpffGL:i(asQ29O,[n(2\( EV 2(0,[n(i2D(a>sDp ` !m(aN.W52MmWkg_;*+Y[&(5U5N&LRU'06k8+,<105U/<T;*+M3,CRU5UX8+.5UX&('8&(-7eE`MO3 5U5EH0+.82RUC93 /2RN&('*<TRU'QC&(5UC+,HD+.RU'06k&-&(5UX'*& V Ro3 55N+.'069/2;7WO/2;*+.XF3(H V RU/3-G&(5UX'*& V Ro3 57),+.82/2R4)M3 /+=/2;*+@<+,w1*+.'*),+E& Y}-08& 2+,)./2RN&('*<1*<+,HT/&D010RU5NHF/2;*+PH0+.82RUC93 /2RN&('aAfeH!9GU..GB:Pmq2g! } he]g_;*+-08&(D05N+ V D+.5N&('06<q/C& e '*H0+,+,HW3@-G&(5UX'*& V Ro3 5),+.82/2R4)M3 /+RN<69RUC+.'DX3tH0+.82RUC(3 /2RN&('Y8& V /&k3S698:3 -0; WYn&(5U5N&ML+,HDQX3S-08& 2+,)./2RN&('Y[8& V/2;*+Z6&3 5h/g& Y[ePr;*+.' " OW&('*+&(D0/:3 RU'*<@~ =-08& m+,)./2RN&('t):;*+,)KRU'06AfW/2;1*<E/2;*+~),& V -05N+./+.'*+,<<Me!4(a\`! !e\+,)M3 5U5h/2;*+),&('*<2RN<2/+.'*).X_` !(aN.fB:imE2\`);*+,):KRU'QC&(5UC+,<T/2;*+RU828+,HO10'*H*3 'Q/TYn&(8 V & Ye '&(8H0+.8s/&t5URU69;/+.'/2;*+-08&(D05N+ V Y[&(8 V 105o3 /2RN&('7WL+3(<<1 V +>;*+.8+l/2;43 /P3 5U5]^0?E<@3 8+>RU828+,HO10'*H*3 '/MW7D010/ERU828+,HO10'*H*3 '*).X)M3 'SD+>RU'/+.698:3 /+,HLRU/2;*&(10/RU'*).8+M3(<2RU'06E/2;*+),&('*<2RN<2/+.'*).X>):;*+,)K),& V -05N+fORU/X{<+,+q/2;*+-08&& Y4& Y*/2;*+,&(8+ V cOe}G 74D+.5N&('06</& _ ` <2RU'*),+>RU/),&(828+,<2-&('*H0</&\/2;*+5o3 '069143 6+"#mW]_ _ $M]*1_ *1_ 4>nQWaL;*+.8+]S+.'*),&H0+,<u3 'RU'*<2/:3 '*),8+ $n2)m.4& Yh/2;*+P-08&(D05N+ V 3 '*H $M]*H_ *1_ 4 RJ_ "$ 3 N 4fW4L;*+.8+NNR\<30H.+28UR9C32/NR(&'8&/&BWNR\<308&2,+.)2/NR(&'8&2/*;+2/28UR966.+\8& Y@3S),&('*<2/28:3 RU'Q/JPN LVVRU'Q/7& W _ " $ 3 4fW RN<u3\H0+.82RUC93 /2RN&('Y[8& V /Z& 3 '*H RN<u3-08& 2+,)./2RN&('Y[8& VRU'/&!<Me /Mre D% JON L; q0 N e RN<E-&(5UX'*& V Ro3 5U5UXH0+,).RNH*3 D05N+3 '*H-&(5UX'*& V Ro3 5U5UXyD43 5o3 '*),+,H=[<2RU'*),+Z/2;*+5N+.'069/2;*<J& 3 '*H 3 8+u-G&(5UX'*& V Ro3 5RU'F/2;*+@<2R M+E& Y}/2;*+ERU'0-010/BAfeqr;*+.'U" OW0&('*+E&(D0/:3 RU'*</2;*+-08&(D05N+ V _G4]WO/2;1*<q/2;*+ _` ~),& V -05N+./+.'*+,<<Me]^RU'*),+2\ ),&('*<2RN</<qRU'<&(5UCRU'06@/L&@RU'*H0+.-G+.'*H0+.'/]-08&(D05N+ V <MWQG4= _ ` ~),& V -05N+./+Aq3 '*HZ2\~= ~),& V -05N+./+AfWG3 '*HF<RU'*),[+ RN<RU'*).5U1*H0+,HIRU' _` WO\G~ jRN<3 5N<& _` ~),& V -05N+./+9e` !:(aU,fGBBZm2DG heu<Y[&(82\=[<+,+P3 D&MC+AfW0L+>3(<<21 V +@/2;43 /u3 5U5}^0?E<3 8+RU828+,HO10'*H*3 'Q/Me]g_;*+uw1*+,<2/2RN&('iRN< 3 8+/2;*+.8+E3>H0+.82RUC(3 /2RN&('sY[8& V t/&l3l^0? 3 '*HT3P-08& 2+,)./2RN&('Y[8& V RU'/k& YnWQ<1*);\/2;43 /!Yn&(83 5U5 & Y/2;0RN<]H0+.82RUC93 /2RN&('7WQY[&(83 5U5a),&('*<2/28:3 RU'Q/ 9W9Yn&(83 5U5*-08& 2+,)./2RN&('JPN L RU'/kY[8& V& mW7/2;*+.8+\+fORN<2/<>3F-08& m+,)./2RN&(' Y[8& VRU'/& <Me /Moe JON L " :eRN<-G&(5UX'*& V Ro3 5U5UXH0+,).RNH*3 D05N+3 '*H-G&(5UX'*& V Ro3 5U5UXD43 5o3 '*),+,H=[<2RU'*),+/2;*+<R M+& Y]/2;*+lH0+.82RUC93 /2RN&('Y[8& V/& RN<-G&(5UX'*& V Ro3 5U5UXF8+.5o3 /+,H/&/2;*+<R M+>& Y!/2;*+PRU'0-010/BAfeg_;Q1*<MWaDG~ kRN<RU' ` e'T&(8H0+.8_/&l-08&MC+E/2;*+@),& V -05N+./+.'*+,<:<MWOL+uD010RU5NHI38+,HO1*)./2RN&('TY8& V 3l<2-+,).Ro3 5)M3(<+E& Y/2;*+E-08&(D05N+ VWQL;*+.8+/2;*+JYn&(8 V 105o3>RN<_3 ~% ux=R$e+9eq3 'RU'*<2/:3 '*),+u& ~^!gAf69RUC+.'T3@Y[&(8 V 105o3iWQL;0RN):;iRN<_3),&('(m10'*)./2RN&('& Yh).5o3 1*<:+,<LRU/2;3 / V &9<2/ 5URU/+.8:3 5N<W43 '*HI3l-43 82/2RU/2RN&(B' *) *) n& Y{RU/<C93 82Ro3 D05N+,<MWH0&+,<}/2;*+.8++fORN<2/!3/28210/2;3(<:<2RU69' V +.'Q/hYn&(8h/2;*+C93 82Ro3 D05N+,<hRU'~ W9<21*);Z/2;43 /hYn&(8h3 5U5O/28210/2;3(<<2RU69' V +.'/Yn&(8q/2;*+C93 82Ro3 D05N+,<]& YR W9/2;*+.8++fORN<2/<]3@/28210/2;s3(<<2RU69' V +.'/qYn&(8q/2;*+C93 82Ro3 D05N+,<]& YR <21*):;/2;43 /RN</2821*+ g_;0RN<-08&(D05N+ V RN< ` ~),& V -05N+./+=$^/&):K V +.X+.8MW`Mb9W/2;*+,&(8+ V d*eU`Afe!|7+./1*<_)M3 5U5aRU/ ~^!g e`* { $2D*>* {* |K$ 2D*{K 2D*6K* {FK 2D*>v { $62$-6* |>* {l>v { $fi3MfiuM%bafcbtbfvalvalvalctcfdt2123C1C1C1C1C1C11C1C2bcvalvalvalvalvaldfavbvcvdv...3C2C2C2C2C2C2valavbvalbvQ1>~2C12313C2valavK*}{$bvalbvx}RU69108+` 03 V -05N+& Y{/28:3 '*<2Y[&(8 V 3 /2RN&('FY[8& V ~ Fff1& /&Dg_;*+/28:3 '*<mY[&(83 /2RN&('L+1*<+RN<PRU5U5U1*</28:3 /+,HtRU'jx{RU6*eq`esg_;*+ ~^!gY[&(8 105o3F1*<+,HRN<l3 6Q3 RU'64T$UTV d=T4fWh3 '*H/2;*+\-43 82/2RU/2RN&('kRN<9 " mA*Kn *) " mAV n *) " mAnQeFg_;*+698:3 -0;&(D0/:3 RU'*+,HRN<u/2;*+l<:3 V +3(<RU'S/2;*+-08&& Y& Y]g_;7ecOWx{RU6*e{`MOWG+f0),+.-0/u/2;43 /E),&('*),+.-0/E'*&H0+,<`>),&(828+,<2-&('*HORU'06P/&@C93 82Ro3 D05N+,<!RU' 3 8+'*&(/!5URU'0K+,H/&E/2;*+_'*&H0+,< `93 '*HUP8+.-08+,<+.'/2RU'06$/2;*+.RU8J-&9<<2RUD05N+EC93 5U1*+,<Mex{RU8<2/_);*+,):Ki/2;43 /_RU's/2;0RN<RU'0RU/2Ro3 5L&(825NHWO'*&),&('*</28:3 RU'Q/RN<CRN&(5o3 /+,HWOD010//2;*+u6&3 5)M3 '0'*&(/D+<:3 /2RN<m4+,HeXF3 -0-05UXRU'06F&('*),+P/2;*+l+.C&(5U10/2RN&('S82105N+iW4L+>/282XI<& V +>C(3 5U143 /2RN&('S& Yq/2;*+C(3 82Ro3 D05N+,<uRU'3 '*HI&(D0/:3 RU'3lL&(825NH WO/2;43 /),&('Q/:3 RU'*<E3 '3 '*<2L+.8/&eq10//2;0RN<JL&(825NHF;43(<J/&<B3 /2RN<mYXi/2;*+-&9<2RU/2RUC+),&('*<2/28:3 RU'Q/ Q W9+fO-08+,<<2RU'06@/2;43 / $Yn&(8q+.C+.82X>C93 5U143 /2RN&('& YG/2;*+_C(3 82Ro3 D05N+,<!RU'~ lE W9/2;*+.8+V 1*</+fORN<2/>3TC93 5U143 /2RN&('& Y/2;*+C93 82Ro3 D05N+,<PRU' <1*);t/2;43 //2;*+ZY[&(8 V 105o3I+.C93 5U143 /+,<>/&j[B* :e<:3 /2RN<m4+,</2;0RN<),&('*<2/28:3 RU'/MW0RU/ V +M3 '*<_/2;43 /_L+E;43,C+Yn&(10'*Ht=DQXT3 -0-05UXRU'06/lA3C93 5U143 /2RN&('I& Y/2;*+C93 82Ro3 D05N+,<RU'* <1*);T/2;43 /_Y[&(8J3 5U5C93 5U143 /2RN&('*<J& Y}C93 82Ro3 D05N+,<RU'* lC =L;0RN);I)M3 'FD+E<2R V -05UR4+,HRU' $Yn&(83 5U5aC(3 5U143 /2RN&('*<& YC(3 82Ro3 D05N+,<RU'C :W<2RU'*),+J/2;*+.8+RN<]&('05UX\&('*+<1*);C93 5U143 /2RN&('iY[&(8& AfWQ/2;*+.8+RN<3FC(3 5U143 /2RN&('& Y/2;*+C(3 82Ro3 D05N+,<RU' <1*);j/2;43 //2;*+Yn&(8 V 105o3+.C(3 5U143 /+,</&j[f0,esg_;*+.'/2;*+.8+RN<3 '3 '*<L+.8 :QBs/&/2;*+ ~ F1ff & -08&(D05N+ V ej%&('QC+.8<+.5UXW]<210-0-G&9<:+s3 '3 '*<2L+.8sG/&/2;*+sD-08&(D05N+ V e / V +M3 '*<]/2;43 /]Y[&(8+.C+.82XL&(825NZH /2;43 /)M3 'iDG+J&(D0/:3 RU'*+,HiDQX\3 -0-05UXRU'06>/2;*+82105N+XWQ/2;*+),&('*<2/28:3 RU'/ Q RN<CRN&(5o3 /+,H=[&(/2;*+.82LRN<+>),&(105NHsD+-08& 2+,)./+,HTRU'Q/o& 3 '*Hs/2;*+@3 '*<2L+.8_L&(105NHTD+:QBAfeg_;1*<E/2;*+.8+>RN<'*&T3(<<2RU69' V +.'Q/@& Yq/2;*+C(3 82Ro3 D05N+,<uRU'pB<32/NR<mYXRU'06/2;*+l),&('*<2/28:3 RU'/MWh0 5W 5/2;*+3 '*<2L+.8J/&/2;*+ ~ F1ff & -08&(D05N+ V RN<@a9e! hessD <2/:3MX<>RU'/2;*+\<:3 V +).5o3(<<P&` !:(aU,fGBBsm@sD`),& V -05N+fORU/Xi3(<D } '*H0+,+,HW/2;*+w1*+,<2/2RN&('RN< 3 8+J/2;*+.8+E3 'CsD~H0+.82RUC(3 /2RN&('iY[8& V/C& Y43 '*Hs3E-08& 2+,)./2RN&('Y[8& V /&3>^0? YnWQ<21*):;/2;43 /qYn&(83 5U5 7& Y/2;0RN<H0+.82RUC(3 /2RN&('s+.RU/2;*+.8+,w143 5/&Zt&(8_&(D0/:3 RU'*+,HTDQXi3 'sR VV +,HORo3 /+D~H0+.82RUC93 /2RN&('7WQYn&(83 5U)5 & Y7/2;0RN<_H0+.82RUC(3 /2RN&('FH0+.82RUC+,HiY8& VJPN L /& W*/2;*+.8++fORN<2/<DQX3 'B\~H0+.82RUC93 /2RN&('7W*Yn&(83 5U5}),&('*</28:3 RU'Q/W0Yn&(83 5U5-08& 2+,)./2RN&(' Y8& V3 'U\~H0+.82RUC93 /2RN&('FY[8& V /&\3\^0#? 3 '*H3>-08& 2+,)./2RN&(g' aY8& V@/8& <e /Me JON L "Q3 '*HT/2;*+u5N+.'069/2;*<J& Yh3 5U57H0+.82RUC93 /2RN&('*<3 8+E-&(5UX'*& V Ro3 5RU'T/2;*+@<2R M+E& Y{/2;*+ERU'0-010/Me!r;*+.'* " OW0&('*+&(D0/:3 RU'*<J2D !W4/2;1*<J/2;*+ ` ),& V -05N+./+.'*+,<<Me|7+./_1*<-G&(RU'/&(10//2;43 /MWL;*+.8+M3(<RU'T6+.'*+.8:3 5)M3(<+9WH0+,HO1*)./2RN&('FRN< V &(8+uHOR ).105U/_RU's2\=/282105UX10'*H0+,).RNH*3 D05N+A\/2;43 'RU'D=[<+ V R~H0+,).RNH*3 D05N+AfW_/2;*+),&('QC+.8<+;*&(5NH0<ZY[&(8/2;*+F-43 82/2RN).105o3 8i)M3(<+F&8:3 '06+f~$8+,<2/282RN)./+,H82105N+,<Me$>~>~K* { $* |Gv { $* |F6e.$-,lfi M]|9M.tM=uwuMM3Fqh {3M|{3 M}h A{% }Az'*+ V 3,X),&('*<2RNH0+.8u/2;*+>)M3(<:+>L;*+.8+'*&(/u&('05UXF82105N+,<D010/@3 5N<&),&('*<2/28:3 RU'/<P3 8+>8+,</282RN)./+,He|7+./u1*<*8<2/J),&('*<2RNH0+.8/2;*+ V +M3 '0RU'06(Y105{)M3 /+.6&(82XF& Y{'*+.6Q3 /2RUC+P),&('*</28:3 RU'Q/<Mep<qhy|My$ }$ynu{ My}$ A{%fNBPsD(fig=fBi9*@:Gn9[M? Z90f[2(46}AeT[(OG9:u BBG[[99lOK$72D*4:2(B!H!:(aU,W5_K*{:2(B !m(aN.W52\:$72D** NNGK$7 2D*4 :!Ua2QfNfYRF:2(B,fZM!Q2,[fU52D*| 2f\(0@MfZ'!mQ2.nQfNW52\K*}{ $ (a>sD* | f\([B@:a2.nQfNW5V _VVVV2MmW!! 1!m(aN.fGf:m_`K{$ AvK* { $7p4@Y[8& V ~),& V -05N+./+.'*+,<<J& Y{-08& m+,)./2RN&('F):;*+,)K~RU'06=/2;7e*cAfe!:(aU,fGBBZm_ } /2;0RN<J-08&(D05N+ V )M3 'IDG+E+fO-08+,<<+,H3(< RN<JRU/J/2821*+E/2;43 /)M3 'D+F-08& m+,)./+,HRU'Q/&k3 '*H/2;43 /\'*&),&('*<2/28:3 RU'Q/T& YE)M3 'D+F-08& m+,)./+,HRU'Q/&k/2;1*<D+.5N&('06<I/& 1e u&ML 5N+./I1*<),&('*<2RNH0+.8/2;43 /I),&('Q/:3 RU'*<S&('05UX&('*+j),&('*</28:3 RU'Q/Me 8+,HO1*)./2RN&('Y[8& V ~^!g /&=[<:+,+TYme R$e/2;*+F-08&& Y@& Y@/2;7eAl-08&MCRNH0+,<s3t<2/28:3 RU69;Q/mYn&(82L3 8H8+f~HO1*)./2RN&('kY8& V ,u((Z,u /&_7 } =[<+,+\Yme R$e 3 -43(HOR V RU/282RN&(17W`Mb9b dAfWh/2;Q1*<l/2;*+~),& V -05N+./+.'*+,<<Me.lM !2.nQf [ :l2!\:7p4Jg}&E-08&MC+/2;*+_RU'*),&('*<RN<2/+.'*).X& Y3E@EW(L+ V 1*<2/*'*H<& V +CRN&(5o3 /2RN&('& Y3E),&('*<2/28:3 RU'Q//2;43 /!LRU5U5*'*+.C+.8!DG+_8+,</&(8+,He!10/!'*&ECRN&(5o3 /2RN&('& Y73u'*+.6Q3 /2RUC+),&('*<2/28:3 RU'/})M3 '>+.C+.8}DG+h8+,<2/&(8+,Hi=pY1082/2;*+.8}82105N+]3 -0-05URN)M3 /2RN&('*<})M3 '&('05UX@3(H0HPRU'OY[&(8 V 3 /2RN&('7W /2;Q1*< V &(8+-&9<<2RUD05N+J-08& 2+,)./2RN&('*<MWO3 '*Hi)M3 '0'*&(/8+ V &MC+u/2;*+).105U-082RU/&('*+Afe]^&L+u&('05UX;43,C+/&P-08&C+/2;43 /&('*+),&('*<2/28:3 RU'/u& Yhj)M3 'D+PH0+,HO1*),+,HY8& V $n+*)4fRU/RN<u3<+ V R~H0+,).RNH*3 D05N+l-08&(D05N+ V e a2.nQf [ :mSG Yn&(5U5N&MLJ<L+ V 1*<2/u-08&MC+l/2;43 /E)M3 'yDG+H0+,HO1*),+,HIY[8& V $n+*)4fWD010//2;43 /'*&\),&('*<2/28:3 RU'/& Y{)M3 '7eg_;*+j3 82691 V +.'/<-08&CRU'06<+ V R~H0+,).RNH*3 D0RU5URU/X& YH0+,HO1*)./2RN&('RU'2D3 '*H10'*H0+,).RNH*3 D0RU5URU/X&H0+,HO1*)./2RN&('RU'F2CDj3 8+E/2;*+P<B3 V +>3(</2;*+@&('*+,<J1*<:+,HTRU'F/2;*+@-08&& Y!& Y!g_;7e7`MOeg_;*+8+,<2/282RN)./2RN&('/&j'*+.6Q3 /2RUC+S),&('*<2/28:3 RU'/<TH0+,).8+M3(<+,<T),& V -05N+fRU/X& YP-08&(D05N+ V <TRU'/2;*+I&0H+.5$WD010/RU/_H0&+,<'*&(/;*+.5U- V 1*);I3(<<:&&('F3(<]82105N+,<3 8+RU'QC&(5UC+,HW0<2RU'*),+/2;*+,<+-08&(D05N+ V <_8+ V 3 RU'V10'*H0+,).RNH*3 D05N+9e%& V D0RU'0RU'06t8:3 '06+F8+,<2/282RN)./+,H82105N+,<\3 '*H'*+.6Q3 /2RUC+I),&('*<2/28:3 RU'Q/<W]L+I&(D0/:3 RU' V &(8+RU'Q/+.8+,</2RU'06i),& V -05N+fORU/XF8+,<2105U/<Mv$G*{ $TlK* { ${$ AvK* {pq <&Bf[f[M2sBNB(aiGnQ9['?(Z(0.[m(4>(a2f,f4O[G9UMQ2 MWV 2\K{$7pAv429\fZ!`1!m(aN.W5{ $ 29\f !9GU.5V 2\K*}| (a>CD7K* { ( ` !:(aU,W5V 2D*hy|My$[y|$-%-{%}}hy|M{|M}h A{% }Aps(*;:2(QS!ficonditionfrontier3MfiuM%mandatory part1122"<<23311133U2U$ C4D+$ C43211UK{$7pAv4/&3l8+,</282RN)./+,HID7GK$GK*}{$<o$ E42323x{RU69108+\`McO!g8:3 '*<mYn&(8 V 3 /2RN&('Y[8& V2MmW '*),&('*<2RN<2/+.'*).XRU't2\3(H V RU/<Z3T-G&(5UX'*& V Ro3 5),+.82/2R4)M3 /+9Wq3IH0+.82RUC(3 /2RN&('=[& Y-G&(5UX'*& V Ro3 55N+.'069/2;aAY[8& V 5N+M3(HORU'06I/&F3s698:3 -0;RU'/&TL;0RN);3s),&('*<2/28:3 RU'/>& Y])M3 'DG+l-08& 2+,)./+,HW3 '*HS/2;0RN<-08& 2+,)./2RN&('7e '*),&('*<2RN</+.'*).XRN<u/2;Q1*<ERU' W3 '*HS),& V -05N+./+.'*+,<<uY[&(5U5N&LJ<uY8& V /2;*+l-43 82/2RN).105o3 8P)M3(<+L;*+.' RN<P+ V -0/Xeix*&(8>H0+,HO1*)./2RN&('7W{L+ V 1*<2/P-08&C+\/2;43 /P'*&F),&('*<2/28:3 RU'/)M3 'tD+H0+,HO1*),+,HY[8& V$n+*)4fWQD010/!/2;43 /)M3 '7eq^&E/2;*+_-08&(D05N+ V RN<hRU' ex*&(8q),& V -05N+./+.'*+,<:<MW8+ V 3 82Kl/2;43 /!/2;*+_-08&(D05N+ VRN<J<2/2RU5U57),& V -05N+./+>L;*+.'KRN<+ V -0/Xt=[g_;7eJ` Afeg}&-08&C+E/2;43 /_D } SLRU/2;s8Me 8Me!82105N+,<3 '*Hi'*+.6Q3 /2RUC+E),&('*<2/28:3 RU'/<RN< ` ~),& V -05N+./+9WL+yLRU5U5u*8<2/F<2;*&L/2;43 /TRU/sDG+.5N&('06<T/& ` WJ/2;*+.'+fO;0RUD0RU/I3t8+,HO1*)./2RN&('Y[8& V 3 _ ` ~),& V -05N+./+-08&(D05N+ V /&ZRU/<),& ~$-08&(D05N+ V D7G G } =[<2RU'*),+P),& ~ ` 0 _` Afe2DG ),&(828+,<-G&('*H0</&I/2;*+i5o3 '069143 6+sff" mW]p _ _ $M]*y_ *y_ 4>nQW{L;*+.8+ ]+.'*),&H0+,<Z3 'RU'*<2/:3 '*),+ $$~ $n+*)*m4y4Z& YJ/2;*+-08&(D05N+ V Wq3 '*QH $M]*y_ *y_ 4 R_ +.'*),&H0+,<l3 'GD~H0+.82RUC93 /2RN&('Y[8& V /& 3 '*Hk3-08& 2+,)./2RN&('Y[8& V /J& Wq3 '*H _ +.'*),&H0+,<3 V 3 -0-0RU'06Y[8& V<& V +s),&('*<2/28:3 RU'Q/& YJ/& Y]/2;43 /lRN<'*&(/\3F-08& 2+,)./2RN&('='*&(/+i/2;43 /lRbYH0&+,<l'*&(/lCRN&(5o3 /+T3 'QX),&('*<2/28:3 RU'/MW*/2;*+.'I'*&Z698:3 -0;RU'F/2;*+PH0+.82RUC(3 /2RN&('IY8& V /& H0&+,<BAfert+k+f;0RUD0RU/S'*&L 38+,HO1*)./2RN&('Y8& V /2;*+k6+.'*+.8:3 5ZG 74 -08&(D05N+ V /&D7GG } LRU/2;8Me 8Me82105N+,<F3 '*H'*+.6Q3 /2RUC+S),&('*<2/28:3 RU'Q/<Me|7+.J/ $n+*mq" rn4D+y3 'RU'O~<2/:3 '*),+u& 7p4=LPe 5$e&0e 6*eUWOL+u8+,<2/282RN).//2;*+u-08&(D05N+ V /&),&('*<2RNH0+.8&('05UX&('*+u-&9<2RU/2RUC+),&('*<2/28:3 RU'/BAfetg_;*+s/28:3 '*<mY[&(8 V 3 /2RN&('L+s),&('*<RNH0+.8lD010RU5NH0<\3 'kRU'*<2/:3 '*),+T& Y2DG G$$o$ C4 $n+*)+$ E4*m $ C4y4y4P3(<@Yn&(5U5N&MLJ<ert+\)M3 5U5/2;*+@fm(a[nfF& Y/2;*+-&9<2RU/2RUC+\),&('*<2/28:3 RU'/ /2;*+<+./l& Y_'*&H0+,<RU'j/2;*+\/282RU696+.8F= 5pW 5I),&(5N&(8+,HjDXjAE;43MCRU'063 />5N+M3(<2/l&('*+\'*+.RU69;DG&(8ZRU'j/2;*+i&(D05URU6Q3~/2RN&('7ePg_;*+ZH0+f*'0RU/2RN&('t& Y),&(5N&(8+,HS698:3 -0;*<ER V -05URN+,<E/2;43 /EY[8&('Q/2RN+.8E'*&H0+,<P3 8+l),&('*),+.-0/@'*&H0+,<=/2;*+.RU8'*+.RU69;QD&(8<i3 8+I/2;Q1*<8+.5o3 /2RN&(''*&H0+,<BAfe|7+./1*<\H0+.'*&(/+F/2;*+,<+sY[8&('Q/2RN+.8i'*&H0+,<DX I* F6F6F * K eg_;*++.C&(5U10/2RN&('S82105N++$ E4_;43(<Yn&(8;QX-&(/2;*+,<2RN<u/2;*+>/282RU696+.8E& WG3 '*HIYn&(8),&('*).5U1*<2RN&('t3\8+.5o3 /2RN&('y'*&H0+/X-+,H 8 4WGL;*+.8r+ "FRN<@3\'*+.L K ~3 82X8+.5o3 /2RN&('/X-+RU'*),& V -43 8:3 D05N+LRU/2;t3 5U5h&(/2;*+.8E/X-+,<Meg_;*C+ 7M'*+.RU69;DG&(8@& Yq/2;0RN<'*&H0+RN</2;*+>),&('*),+.-0/E'*&H0E+ :eu%;*+,):K/2;43 /+$ E4RN<u38:3 '06+8+,<2/282RN)./+,H82105N+9eqg_;*+E'*+.6Q3 /2RUC+P),&('*</28:3 RU'Q/J $ E4RN<_/2;*+@<210D0698:3 -0;& ),& V -&9<+,HI& Y{RU/<J&(D05URU6Q3 /2RN&('= XJ L 43(H0H0+,HyLRU/2;S'*&H0+,<E& Y]/2;*+Y[8&('Q/2RN+.8P3 '*Hy/2;*+>8+.5o3 /2RN&(''*&H0+>/X-+,H "aW45URU'0K+,HS/&i/2;*+Y8&('/2RN+.8'*&H0+,<JRU'/2;*+<:3 V +@L_3,X3(<u3 DG&C+9ex}RU'43 5U5UXW4/2;*+l^0?$ C4RN< V 3(H0+& Y!&('*+>8+.5o3 /2RN&(''*&H0+P/X-+,H"i3 '*HFRU/<'*+.RU69;DG&(8<JY8&('/2RN+.8'*&H0+,<Me!g_;0RN</28:3 '*<mYn&(8 V 3 /2RN&('RN<JRU5U5U1*<2/28:3 /+,HFRU'x{RU6*e`McOeK* {K* { $K$ K* { $K$ 2D*$ K* { $K AD*UU UU7UU7$-M(7U4K$ Kv { $Ufi M]|9M.tM=uwuMM3FK AD*5$e&0e 6*eEL+l)M3 't3(<<21 V +/2;43 /@RN<uRU828+,HO10'*H*3 'Q/MRU'/2;43 /@)M3(<+9WG 7p4RN<E<2/2RU5U5_ ` ~),& V -05N+./+@=[<+,+]/2;43 /}/2;*+/28:3 '*<mYn&(8 V 3 /2RN&('Z1*<+,H>RU'/2;*+]-08&& Y4& Yag_;7e cJ-08&HO1*),+,<!3 '>RU828+,HO10'*H*3 'Q/698:3 -0;gPAfeu&ML<210-0-&9<+/2;43 /j$n+* E4]RN<_),&('*<2RN<2/+.'/MhRU/ V +M3 '*<_/2;43 /+.RU/2;*+.8_/2;*+/282RU696+.8& H0&+,<'*&(/u-08& m+,)./RU'Q/&FWG3 '*HRU'/2;43 /E)M3(<+9Wa/2;*+P82105N+D+$ E4JLRU5U5'*+.C+.8u-08&HO1*),+/2;*+'*+,+,H0+,HQ3'*&H0+9Wa&(8u+.C+.82Xj=[+fRN<2/2RU'06A-08& m+,)./2RN&('S& Yq/2;*+>),&('*HORU/2RN&('S& RU'Q/&T"$n`4J)M3 'D+>+fO/+.'*H0+,H/&>3E-08& 2+,)./2RN&('i& 3(<]3EL;*&(5N+9e]^&P+.C+.82X3 -0-05URN)M3 /2RN&('s& Yr$ E4{-08&HO1*),+,<3ECRN&(5o3 /2RN&('i& YG $ E4fe$ C4_)M3 '0'*&(/D+@H0+,HO1*),+,HFY[8& V /2;*+@K'*&ML5N+,HO6+D43(<+9e_%&('QC+.8<+.5UXWG<210-0-&9<+E/2;43 /'IDG&(/2;I)M3(<:+,<uoG~$CRN&(5o3 /+,< \W/2;*+.'k/2;*+i3 -0-05URN)M3 /2RN&('& Y,+$ C4uYn&(5U5N&MLRU'0J6 -08&HO1*),+,<l3I698:3 -0;j/2;43 /ZH0&+,<>'*&(/CRN&(5o3 /+Ela$ C4fW*3 '*HFL+P)M3 'H0+,HO1*),+o$ C4feg_;*+I3 D&MC+T/2;*+,&(8+ V <2;*&LJ<\3yH0+,).8+M3(<+TRU'),& V -05N+fRU/XL;*+.'6+.'*+.8:3 5-&9<2RU/2RUC+F),&('*<2/28:3 RU'/<3 8+S8+,<2/282RN)./+,H/&'*+.6Q3 /2RUC+&('*+,<Me 7p4Y$3 5U5N<sY8& V _` /&),& c~ 3 '*HWL;*+.'3 5N<&i),&('*<2RNH0+.82RU'06i8:3 '06+>8+,<2/282RN)./+,H82105N+,<MW*2\ 7p4Yn3 5U5N<JY8& V _ ` /&i W3 '*HID7GY$3 5U5N<Y[8& V ` /& ,` e /\L&(105NHDG+IRU'Q/+.8+,<2/2RU'06k/&j+fO;0RUD0RU/-43 82/2RN).105o3 8T)M3(<+,<&),&('*<2/28:3 RU'/<MW V &(8+Z6+.'*+.8:3 5!/2;43 ''*+.6Q3 /2RUC+&('*+,<MW7/2;43 / V 3 K+Z/2;0RN<@),& V -05N+fRU/XY$3 5U5hRU'Q/&TRU'/+.8 V +f~HORo3 82XF).5o3(<<+,<P=DXT+f*3 V -05N+P 3 '*H ` Y[&(8_7 7p4{AfeJ^& V +P<2X'Q/:3()./2RN)@8+,</282RN)./2RN&('*<L+uH0+f*'*+,HY[&(882105N+,<3 8+6&&H)M3 '*HORNH*3 /+,<Mh/2;*&(1069;F3E*'0RU/+u+fO-43 '*<2RN&('s<:+./& Y7),&('*<2/28:3 RU'Q/<_;43(<'*&<+.'*<+9W5N+./q1*<]),&('*<2RNH0+.8m(Q2ff[f[,\(0.[m9p4.eh|7+./]1*<]3 5N<:&PH0+f*'*+>(p.9*G2,(*f[2(pa3(<E),&('*<2/28:3 RU'Q/<EL;*+.8+l/2;*+l/282RU696+.8P3 '*Hy/2;*+&(D05URU6Q3 /2RN&('j3 8+'*&(/@),&('0'*+,)./+,H7<21*);),&('*<2/28:3 RU'/<@RU'O~).5U1*H0+@/2;*+ /&(-&(5N&(69RN)M3 5),&('*<2/28:3 RU'/< P1*<+,HTRU'=[RU'*+M3 1RN<<:3(&(10R$W`Mb9b9Afeg_;*+]Y[&(5U5N&LRU'06E-08&(-G+.82/XP;0RU69;05URU69;Q/<h/2;*+8+.5o3 /2RN&('*<2;0RU-*<h& Y*/2;*+,<+-43 82/2RN).105o3 8h)M3(<:+,<LRU/2;l'*+.6Q3 /2RUC+),&('*<2/28:3 RU'/<MUUUUv { $UUUK{$ AvK{$ AvK AD*5ynn9[M ? l(*f[2(pa@(O(.[[,U(> M>2P9s2(S!Bf[fn,2F(*f[2(pa(as(p.9*G2,I(0.[m9p4W52MmW Pu<E'*&(/2RN),+,HtRU't<:+,)./2RN&('jvOW}3s'*+.6Q3 /2RUC+\),&('*<2/28:3 RU'/>RN<P+,w10RUC93 5N+.'Q/P/&I3s-&9<2RU/2RUC+),&('*<2/28:3 RU'/L;*&9<+F&(D05URU6Q3 /2RN&('RN<),& V -&9<+,H& YE&('*+F),&('*),+.-0/\'*&H0+T& YE/X-G+m " 0W]L;*+.8+*8 "yRN<RU'*),& V -43 8:3 D05N+lLRU/2;S3 5U5h&(/2;*+.8u/X-G+,<E3 '*HH0&+,<'*&(/u3 -0-+M3 8RU'3 'QXy^0?+f0),+.-0/RU'=RU/RN</2;Q1*<@3HORN<),&('0'*+,)./+,Hs),&('*<2/28:3 RU'Q/BAfeqre 5$e&0e 6*eh/2;0RN<]'*&H0+)M3 'D+5o3 DG+.5N+,HDQX3 'iRU'*HORUCRNHO143 5 V 3 82K+.8u=L;0RN):;7W3(<9 *W{3 -0-+M3 8<&('05UXSRU'j7AfW}/2;Q1*<5N+M3(HORU'06/&3I),&('*<2/28:3 RU'/L;0RN):;RN<>DG&(/2;jHORN<:),&('0'*+,)./+,H3 '*HF8:3 '06+f~$8+,<2/282RN)./+,He7p} qhy|My<$(4G2,2(0.[m(4W]W|M}]}$yfiAyM}h A{% }AesOfu(4$(0(4@:9oS!K$72D*4:2(B! !m(aN.W52\K{$7pAv4k(a2\*|2.9pZaQ2.nQ.U={.GK$72D*4VV _:2(B! !m(aN.r9hO.yfUB92>2(QS!2ff[f[,5* |V 2D f\(0MfZ'!mQ2.nQfN=fOi29\f ` !m(aN.B9hOffNBt(2(S!Bf[fn,25K* { $V 2CD }2(S !Bf[fn,25f\(0aQ.[QQfN=t.(B ` !9GU.9hOffUB($-Afi$ 2D*3MfiuM%2MmW y:7*D+.5N&('06<Z/&y W!<2RU'*),+sL+ V 1*</-08&MC+T/2;43 /lY[&(8&('*+T),&('*<2/28:3 RU'//2;*+.8+yRN<F3t-08& 2+,)./2RN&('& Y>RU/<s/282RU696+.83 '*H'*&k-08& 2+,)./2RN&('& YRU/<s&(D05URU6Q3 /2RN&('7e %& V -05N+./+.'*+,<<TRN<-08&MC+,HyLRU/2;S3\8+,HO1*)./2RN&('Y8& V ^!gE^!g=n3(<RU'-08&& Y]& Y]g_;7e` Afe7p4RN</2;Q1*<),& ~ ~),& V -05N+./+9e82691 V +.'Q/<Y[&(810'*H0+,).RNH*3 D0RU5URU/XI& Y!G4]WaG k3 '*HI2CD!W73(<L+.5U5h3(<u<+ V R~H0+,).RNH*3 D0RU5URU/XS& YqD7G hW3 8+>/2;*+<B3 V +l3(<RU'/2;*+-08&& Y]&g_;7e7`MOh/2;*+P),&('*</28:3 RU'Q/<L+@1*<+,HTL+.8+3 5U8+M3(HOXFHORN<),&('0'*+,)./+,Her;*+.'82105N+,<Z3 8+\8:3 '06+f~$8+,</282RN)./+,HW!G:7p4D+.5N&('06<>/& L+ V 1*<2/-08&C+/2;43 /P/2;*+Z/282RU696+.8>& Y/2;*+\),&('*<2/28:3 RU'/>)M3 'tD+lH0+,HO1*),+,HY8& V $n+*)4fW}D010/P'*&(/@RU/<P&(D05URU6Q3 /2RN&('7W{3 '*H/2;*+,<+E-08&(D05N+ V <DG+.5N&('06\8+,<-G+,)./2RUC+.5UXs/& 3 '*HI),& c~ ea%& V -05N+./+.'*+,<<),& V +,<_Y[8& V /2;*+@-43 82/2RN)f~105o3 8)M3(<+EL;*+.8+9 RN<+ V -0/XeqG 74RN</2;1*<),& ~ ~),& V -05N+./+9e2DG DG+.5N&('06<E/& ` L;*+.'S82105N+,<uRU'QC&(5UC+,H3 8+>8:3 '06+f~$8+,<2/282RN)./+,Heg_;*&(1069;/2;0RN<-08&(-+.82/XjH0&+,<l'*&(/l3 -0-+M3 8lLRU/2;3 'kR VV +,HORo3 /+Yn&(8 V 105o3 /2RN&('& YJ/2;*+i-08&(D05N+ V W!RU/lDG+,),& V +,<l&(DO~CRN&(1*<L;*+.'/2;*+i-08&(D05N+ V RN<l</:3 /+,H3(<Yn&(5U5N&MLJ<M H0&+,<l/2;*+.8+T+fRN</Z3<+,w1*+.'*),+i& Y698:3 -0;*<"N * F6F6F *r * Q W{L;*+.8+T" N * F6F6F *r RN<l3 'D~H0+.82RUC93 /2RN&('3 '*H Q RN<>/2;*+iHORN<[m&(RU'/10'0RN&('t& 13 '*H XJ L W73s-08& m+,)./2RN&('Y[8& V /& 3 '*Ht3s-08& 2+,)./2RN&('SY8& V XJ L /&I3F^0? G W\ K \ UIT<21*);/2;43 /lY[&(8Z+.C+.82Xt698:3 -0; ,*\q K 0W N0f6RTY[&(8Z+.C+.82X V 3 -0-0RU'0B6 & XJPN LRU'Q/g& m)W kRN<u'*&(/>3i-08& m+,)./2RN&(' :[e u&(/2RN),+Z/2;43 /E'*7& D+fY[&(8o+ G RU'<21*);j3s<+,w1*+.'*),+l/282RU696+.8</2;*+Z),&('*<2/28:3 RU'Q/s= XJON L H0&+,<E'*&(/@-08& m+,)./ERU'/g& A3 '*Hy/2;43 />3 5Ua5 2W PK W<:3 /2RN<mY[XIRU/\=[<2RU'*),+ XJ L-08& 2+,)./<J/& AfW0/2;1*<u3 5U`5 q& Y!/2;*+P<+,w1*+.'*),+>3 8+>),&('*<2RN</+.'Q/Me Q +.'*<2108+,</2;43 / XJ L -08& 2+,)./<RU'Q/&\3 /_5N+M3(<2/J&('*+u698:3 -0;I& Y{/2;*+u<:+,wQ1*+.'*),+9WOL;0RN):;3 5U5N&MLJ</2;*+@3 D&MC+uYn&(8 V 105o3 /2RN&('& Y{/2;*+u-08&(D05N+ V e%& V -05N+./+.'*+,<<JY[&(5U5N&LJ<Y[8& V /2;*+E-43 82/2RN).105o3 8)M3(<+>& Y{'*+.6Q3 /2RUC+P),&('*</28:3 RU'Q/<Me8&& YY[&(8EsD RU'/2;*+)M3(<+& Y8:3 '06+8+,<2/282RN)./+,HS82105N+,<@RN<@<2R V RU5o3 8MERU'/2;*++f~-08+,<<2RN&('& YG/2;*+-08&(D05N+ V 3 D&MC+9W/2;*+H0+.82RUC(3 /2RN&('RN<{'*&ML3' $t1lfi4~H0+.82RUC93 /2RN&('7W/2;*+ ),&('*<2RNH0+.8+,H3 8+J&('05UXZ/2;*+J&('*+,<&(D0/:3 RU'*+,Hs3Y[/+.8q/2;*+3 -0-05URN)M3 /2RN&('s& Y73@82105N+_Y8& V D]W3 '*BH Nf6R $Yn&(8q+.C+.82X V 3 -0-0RU'06& JON L RU'Q/& uRN<8+.-05o3(),+,HIDX $Yn&(8+.C+.82Xs698:3 -0;I/2;43 /)M3 'ID+\~H0+.82RUC+,HIY8& V :e'OY[&(82/210'43 /+.5UXW*8:3 '06+f~$8+,<2/282RN)./+,H),&('*<2/28:3 RU'/<3 8+E/282RN):KRN+.8J/&</21*HOXG{RU'Q/210RU/2RUC+.5UXWG),&('*<2RN<2/+.'*).X);*+,):KRU'06I<;*&(105NHD+,),& V ++M3(<2RN+.8u/2;43 'LRU/2;S6+.'*+.8:3 5h),&('*</28:3 RU'Q/<MWD010/E/2;*+l8&(5N+Z& Y]RU828+,HO10'*H*3 '*).XRN<s<2/2RU5U510'*).5N+M3 8Meg_;*&(1069;RU/iRN<i+M3(<Xk/&k);*+,):K/2;43 /s LRU/2;8:3 '06+8+,<2/282RN)./+,H),&('*<2/28:3 RU'/<RN<3 /5N+M3(<2/\ ~$;43 8H=/28:3 '*<mYn&(8 V 3 /2RN&('Y[8& V ^!gE^!gA\3 '*HL+;43,C+F-08&C+.'=/2;*&(1069;RU/RN<J'*&(/JRU'*).5U1*H0+,HIRU'F/2;0RN<-43 -+.8BA/2;43 /JRU/RN<RU'B ` =R$e+9e` AfWOL+>HORNHT'*&(/ V 3 '43 6+P/&+3();0RN+.C+l3 'I+f03()./),& V -05N+fRU/XF8+,<2105U/_Y[&(8/2;0RN<-08&(D05N+ V ert+iHORNHt'*&(/+.RU/2;*+.8 V 3 '43 6+i/&3(<<2RU69'3I),& V -05N+fORU/Xj).5o3(<<PY[&(8>/2;*+\{. } 3 '*Hs: } t-08&(D05N+ V <W0/2;*&(1069;D&(/2;F-08&(D05N+ V <J/282RUCRo3 5U5UXTDG+.5N&('06\/& e%& V -05N+fORU/X8+,<2105U/<]&(D0/:3 RU'*+,H\RU'/2;0RN<!-43 -+.83 8+<21 VV 3 82R M+,HRU'\/:3 D05N+9e*`9e}rt+3 5N<&E-08+,<+.'/]RU'x{RU6*e`Mb3 ),& V -05N+fORU/X V 3 - E+ V -0;43(<2R ,RU'06\/2;*+E8+.5o3 /2RN&('*<2;0RU-*<D+./L+,+.'I-08&(D05N+ V <Me 'T/2;0RN<*69108+9WRY9 H0+.'*&(/+,<s3<:+./& Y@D0RN),&(5N&(8+,H698:3 -0;*<S=82105N+,<i&(8i),&('*<2/28:3 RU'Q/<BAfWX W W 8+,<-G+,)./2RUC+.5UXH0+.'*&(/+sRU/<>8+,</282RN)./2RN&('k/&y3F*'0RU/+s+fO-43 '*<2RN&('k<:+./MWh8:3 '06+8+,<2/282RN)./+,H+.5N+ V +.'/<MWq&(8HORN<:),&('0'*+,)./+,H+.5N+ V +.'Q/<e H0+.'*&(/+,<@3i<+./u& Yq'*+.6Q3 /2RUC+Z),&('*<2/28:3 RU'/<Meu5U5{-08&(D05N+ V <u8+.-08+,<+.'Q/+,Ht3 8+),& V -05N+./+Yn&(8P/2;*+.RU8>).5o3(<<Me HO6+,<3 8+\HORU8+,)./+,HtY8& V DG&(/2/& V /&T/&(-7e'j+,HO6+ZY[8& V 3T-08&(D05N+ V `/&3-08&(D05N+ V V +M3 '*<\/2;43 / `TRN<\3-43 82/2RN).105o3 8)M3(<+F& Oey&(8+,&MC+.8MWRU'&(8H0+.8/2;43 //2;*+ V 3 8+ V 3 RU'*<_8+M3(H*3 D05N+9W-08&(D05N+ V <_L;0RN);3 8+RU'Q/+.8 V +,HORo3 /+ED+./L+,+.'F/L&Z-08&(D05N+ V < `@3 '*H l& Y7/2;*+<:3 V +),& V -05N+fORU/X).5o3(<<MWH0&T'*&(/>3 -0-+M3 8@RU'/2;*+l*69108+9eZg_;*+),& V -05N+fRU/X& Y<21*):;-08&(D05N+ V <P)M3 'D+>&(D0/:3 RU'*+,HyDQX ).5o3(<:<2RYXRU'06 @/2;*+ V RU'/2;*+;0RN+.8:3 8);QXeEx*&(8uRU'*<2/:3 '*),+9WGD7G kRN< V &(8+6+.'*+.8:3 5G/2;43 'i } =L;0RN);sRN<&(D0/:3 RU'*+,HiRY" A3 '*H V &(8+<2-+,).R4)J/2;43 '2 D7G@|FUFl* |=* |@K* { $KK$ 2D*K* {K 2D*Kv { $Kv { $AD*K AD*66K* { $$-WK* { $Kv { $Ffi M]|9M.tM=uwuMM3FZ^Z^]Z^]Z[Z[F]Z[F]Z\!]Z[\!][ffff&|fi5 ff5 ff5 ff&:; 5<2<"2<"2&:; 5<2<"2&\>>><2<2<2>&:; 5<2>&>>>>><"<2[m&\[&r\$&>>><<<<<>>>5fffi5 ff5fiff5ff5ff]"[&r\]$>5ff5ffff5>ff5.&:; 5<2"<2&:; 5<2"<2>| 5ff5ff| 5ffff5 |5ff5ffff55 ff5ff[&r\$ ]>fffi5 5ff5ffff5fi5ff5 ff5ffg}3 D05N+\`9^1 VV 3 82XF& Y]%& V -05N+fRU/XI+,<2105U/<v{$=L;0RN);t3(H0H0</2;*+><+./ AfWG3 '*HWG<2RU'*),+>/2;*+,<+P-08&(D05N+ V<&ZRN<2D*| ! e<@3 8+PD&(/2;<:+ V R~H0+,).RNH*3 D05N+9Wh bS4M94"! $#;z'*+RU'Q/+.8+,<2/2RU'06Z8+.5o3 /2RN&('*<2;0RU-iY8& V 3 's3 5U6&(82RU/2; V RN)uCRN+.L-G&(RU'/RN<LRU/2;s/2;*+E%^ Y[8:3 V +.L&(82Ke!+f~)M3 5U5G/2;*+RU'0-010/_& Y{3),&('*<2/28:3 RU'Q/J<B3 /2RN<mYn3()./2RN&('s-08&(D05N+ V = P A!RN<3>),&('*<2/28:3 RU'/_'*+./L&(82KW0),& V -&9<+,H& Y3I<+./& Y_C93 82Ro3 D05N+,<MW{<+./<>& YJ-&9<<2RUD05N+\C(3 5U1*+,<PY[&(8P/2;*+C(3 82Ro3 D05N+,<T=[)M3 5U5N+,Ht/2;*+.RU8ZH0& V 3 RU'*<BA>3 '*H3<+./& Y]),&('*</28:3 RU'Q/<uDG+./L+,+.'y/2;*+PC93 82Ro3 D05N+,<Meg_;*+>w1*+,<2/2RN&('RN<JL;*+./2;*+.8u/2;*+.8+PRN<E3<&(5U10/2RN&('y/&/2;*+%^ W*R$e+9eq3 '3(<<RU69' V +.'Q/& YhC93 5U1*+,</&Z/2;*+@C93 82Ro3 D05N+,<J/2;43 /J<:3 /2RN<m4+,<J/2;*+P),&('*<2/28:3 RU'Q/<eg_;*+Z),&('*<2/28:3 RU'/<ERU'QC&(5UC+,HSRU'3i).5o3(<:<2RN)M3 5 > 3 8+Z<2R V -05N+.8u/2;43 '&(108<MeE)./2143 5U5UXW P ),&(8m~8+,<2-&('*H0</&/2;*+E_{ =-08& 2+,)./2RN&('aA_-08&(D05N+ V e^+.C+.8:3 5P3 10/2;*&(8<s'*&(/2RN),+,H/2;*+<2/28&('06+,w10RUC(3 5N+.'*),+yD+./L+,+.' P 3 '*H}4F *7$ =$?uRUC+.'/L&y5o3 D+.5N+,Hj698:3 -0;*o< 3 '*H kW{RN<>/2;*+.8+T3;*& V & V &(82-0;0RN< V Y8& V/&AfePu<uYn3 8@3(<EL+ZK'*&MLPW/2;*+l*8</u-43 -+.8@&('S/2;0RN<@<210DOm+,)./EL_3(<=[x*+,H0+.8> ]3 8HOR$Wq`Mb9b Afe '=[1069'0RN+.8MW_999A),&(828+,<2-G&('*H0+.'*),+,<s3 8+IH0+./:3 RU5N+,HY[8& V=$?uRUC+.'/L&k^0?EZ< 3 '*HRN<Z/2;*+.8+3y-08& m+,)./2RN&('Y8& V /&A/& P @Wh3 '*H8+,).RU-08&)M3 5U5UX=[H0+.C+.5N&(-0RU'06j/2;*+I&('*+,<-08+,<+.'/+,HTRU'S=[1069'0RN+.8J%;*+.RU'7W`Mb9b9A2Afeq|+./1*<_&(10/25URU'*+u/2;*+uRNH0+M3(<_& Y/2;*+u/28:3 '*<mY[&(8 V 3 /2RN&('TY[8& VP /&hW)M3 5U5N+,He%&('*<RNH0+.8i3S),&('*<2/28:3 RU'Q/i'*+./L&(82KeRN</28:3 '*<mYn&(8 V +,HRU'Q/&/L&y^0?E< 3 '*H3(<@Yn&(5U5N&MLJ<M e /28:3 '*<25o3 /+,</2;*+Ff[f0,[l& > +M3():;k),&('*),+.-0/l'*&H0+RN<6+.'*+.82RN)T3 '*H),&(828+,<2-&('*H0<l/&y3IC(3 82Ro3 D05N+T3 '*Hk+M3();k8+.5o3 /2RN&('k'*&H0+s),&(82 8+,<2-G&('*H0</&S3I),&('*<2/28:3 RU'/n {* |${ v$G*{ $.{{$ {{ 7{*9* T{@|G*{ $=RU/<[/2;t'*+.RU69;QD&(8>RN<>/2;*+\),&('*),+.-0/>'*&H0+\),&(828+,<2-&('*HORU'06/&F/2;*+o$/2;jC93 82Ro3 D05N+\& Y/2;*+\),&('*<2/28:3 RU'/BAfe8+.-08+,<+.'Q/</2;*+(*f[2(paQ <q*[[[(*fh/2;*+.8+PRN<&('*+@RU'*HORUCRNHO143 5{),&('*),+.-0/'*&H0+uY[&(8+M3();C93 5U1*+& Y_3sC93 82Ro3 D05N+\H0& V 3 RU'7W{3 '*H&('*+Z8+.5o3 /2RN&('t'*&H0+lYn&(8P+M3();j/210-05N+& Y_),& V -43 /2RUD05N+C93 5U1*+,<MeZ&(1069;05UX<:3 RNHWG/2;*+.8+lRN<P3<:&(5U10/2RN&('y/&RY]/2;*+.8+lRN<@3 V 3 -0-0RU'06iY[8& V C(3 82Ro3 D05N+,<\=[),&('*),+.-0/E'*&H0+,<@&PA/&C93 5U1*+,<i=[),&('*),+.-0/>'*&H0+,<>& Au/2;43 /<:3 /2RN<24+,<@/2;*+),&('*<2/28:3 RU'/<s= V 3 -*<>8+.5o3 /2RN&('j'*&H0+,<>& YH&('/&8+.5o3 /2RN&('k'*&H0+,<& AfW0 5W 5T3F-08& 2+,)./2RN&('tY[8& V /& keig_;*+i<:3 V +\8+,<105U/P;43(<>D+,+.'3():;0RN+.C+,HRU'*H0+.-+.'*H0+.'Q/25UXFRU'I/2;*+@_/2/282RUD010/+,HS?u8:3 -0;y?u8:3 VV 3 8Yn&(8 V 3 5URN< V DXFJ1*H0&(5YJ=m`Mb9b9cAfe0{$ 2D*z'*+\),&(105NH3 5N<&F<+,+ P 3(<3s-43 82/2RN).105o3 8)M3(<+& Y_ 7*>RU'*H0+,+,HW/2;*+.8+RN<>3-08& 2+,)./2RN&('Y[8& V 3s^0?RU'Q/&T3i^0?RY]3 '*H&('05UXFRY<:3 /2RN<m4+,</2;*+>-&9<2RU/2RUC+),&('*<2/28:3 RU'Q/uLRU/2;3 '+ V -0/Xs/282RU696+.8u3 '*H3(<RU/<&(D05URU6Q3 /2RN&('7e2$-fi3MfiuM%Z[\%]4 1A2*/3 014%&657 */1,8%9Z[F] C*=>A2 &Z[F] 4 1A2*/2>:(+* ;< */1,81%9Z[F] B*/>A2 &Z[EDGFH4\!]4 1A2*/ :(+*-;< *=1,81%9Z[4 1A2*/Z J [\ L DGFH ]4 1A2*=;< *=1,81%9Z[ED9FH4] C*/>A2 &$ %'&)(+*-,%.*/0,01 .2&Z[ID9FHJ4 1A2*/Z[ \ c ]4 1A2*/Z[ ]4 1A2*/Z8^]4 1A2*=Z8^] B*/>A2 &Z[ \#] 4 1A2*/Z\ c ] 4 1A2*/??Z[ \ ] 4 1A2*/2; $Z[ ] C*/CA2 &Z[ ]K4 1A2*/Z8^] C*/CA2 &2@ $Z[ ] B*/>A2 &; $Z^] 4 1A2*=Z[ 4 1A2*/Z8^4 1A2*=Z^] B*/>A2 &x{RU69108+\`MbO%& V -05N+fORU/XF+,<2105U/<q3\?E+,&(698:3 -0;QX@ $fi M]|9M.tM=uwuMM3Fu&MLPWRU'&(8H0+.8T/&H0+M3 5uLRU/2;RU'*),& V -05N+./+SK'*&L5N+,HO6+yxa3 8269RN+.8T+./F3 5$eE=m`Mb9b9AMLT+f/+.'*H/2;*+% ^ Y8:3 V +.L&(82K/& V RO+,H~%^ e '3 V R0+,H~%^ /2;*+<:+./i& YPC93 82Ro3 D05N+,<iRN<sH0+,),& V -&9<+,HRU'/&),&('Q/28&(5U5o3 D05N+T3 '*HS10'*),&('Q/28&(5U5o3 D05N+iC93 82Ro3 D05N+,<MW<:3MX 3 '*HFeZg_;*+s|NPOX>f,uRQTSGU)VTWfiX1Y[Z)\9]+\^`_ X1a _ X1S6ZbVTcedfZS9ghYPcji+XkKlJm`nKopcfi\rqU)ds\9cfi\9aGX1dta2u ^`_ cfiq _ q2ZdvVX6SGXw>U)S9YyxTWZaGXkzZ)\`w>U)WeWfiU ^ \2{|cfi\}cea~a9S9xsX_ ZayX1X1S9gz\GU)WexTa9cfiU)daGUha _ X\9xTVTdsX1a ^ U)S9]cedsk+xsqXkVtgq2ZdVXPXiKaGX1dskTXkaGUZM\GU)WexTa9cfiU)dUwa _ X^`_ U)WfiXdsX1a ^ U)S9] IrlJnKcfi\`\ _ U ^ daGUVX6lBqU)YPQTWfiX1aGX_ cfi\`SGX\9xTWea`QTSGUcfikTX\~xs\}ZdsU)a _ X1SQTSGUKUwUw` lBqU)YPQTWfiX1aGX1dsX\G\yw>U)S6|lBqU)ds\9cfi\9aGX1dsq1gdskTXXkuZdgzYPcji+XkKlJm`nKoq2ZdVXba9SZds\9WZaGXkcedtaGUZdceds\9aZdsqXzUwy'sfE\9cedTa _ X)[SGXk+xsq1a9cfiU)dkTX\Gq1S9ceVXkZVU2Xu}a _ XYPcjiTXkKlJm`nKocfi\YZQTQXkaGUnT\h[Zdskcfi\a _ X1dpQTSGUcfikTXk ^ cea _ ^ UqU)WfiU)SG\u`cecedTZQU\9cea9ceXIqU)ds\9a9SZceda<Pu ^`_ U\GX<a9S9ceX1Scfi\a _ XI\9xTVTSZQ _ qU)S9SGX\9QU)dsk+cedT}aGU~a _ X\9xTVTdsX1a ^ U)S9]cedsk+xsqXkVtgh _ XYPcji+XkKlJm`nKocfi\bqU)ds\9cfi\9aGX1dacjwrZdskU)dTWegcjw}\Za9cfi\9fX\bv7cesvceWeWexs\9a9SZaGX\a _ cfi\a9SZds\w>U)S9YZa9cfiU)dE _ X6qU)ds\9a9SZceda}dsX1a ^ U)S9]Mcfi\~qU)YPQU\GXkhUw7a _ Xa ^ZS9cZVTWfiX\GX1aG\22`Zdsk Zdska _ SGXXqU)ds\9a9SZcedaG\v u} Zdsk|" Zdsk _ ZX\ZYXkTU)YZcedt)yKy Zdskz>yZdsk _ Z2XP\ZYXbkTU)YZcedy _ XPqU)ds\9a9SZcedakTXsdTcea9cfiU)ds\ZSGXbceX1dced_ XsxTSGXIrWeWqU)dsqX1QTa}agQX\}ZSGX6\9xTQTQU\GXkhaGUbVXcedsqU)YPQfZSZVTWfiXe+bbb 2 2b 1 31 1>711C22112fiG2112<3fifi3111<2221732>23fiKG2b 1CHCcexTSGX+{SZds\w>U)S9YZa9cfiU)dvwSGU)YBIrlJnKaGUb|'sfX1ayxs\6SGX1WZaGXU)xTSkTXsdTcea9cfiU)ds\aGUvU)a _ X1SkTXsdTcea9cfiU)ds\UwqU)ds\9a9SZcedtaG\ywU)xTdskzceda _ Xm`RWeceaGX1SZla9xTSGXrxTS~qU)ds\9a9SZcedaG\yWfiX1a`xs\`q2ZWeWa _ X1YnTrlBqU)ds\9a9SZcedaG\`ZSGXZQfZS9a9cfiq1xTWZS}q2Z)\GX6Uw7a _ XYPcedTceYZWkTX\Gq1S9ceQTa9ceXqU)ds\9a9SZcedtaG\kTXsdsXkvcedceVTcfiXX1aZWCeu2{`ZbYPcedTceYZW<kTX\Gq1S9ceQTa9ceXqU)ds\9a9SZcedtaq2ZdVX~\GXX1dZ)\|Z6\GX1aEUwnTrlBqU)ds\9a9SZcedaG\ ^ cea _ _ X~\ZYX}a9S9ceX1S2tceaG\Ecedta9xTcea9ceX\GX1YZdta9cfiq\cfi\<Bcjw _ U)WfikT\\GUYyxs\9a~ U)S U)S6ee2nT\Za9cfi\fX\`ZYPcedTceYZWkTX\Gq1S9ceQTa9ceXqU)ds\9a9SZceda`cjwcea\Za9cfi\fX\~ZaWfiX2Z)\9a|U)dsXrX1WfiX1YX1daUwa _ X\GX1a2<U)aGX~a _ Za|a _ X`k+cfi\xTdsq1a9cfiU)d+rkTUKX\IdsU)a|cedsq1SGX2Z)\GXra _ XrqU)YPQTWfiXi+ceaBgUw_ XqU)ds\9cfi\9aGX1dsq1gbq _ Xq]SGX1WZa9ceXaGUnTrlBqU)ds\9a9SZcedaG\2 _ XQTSGUKUwUwa _ XU)SGX1YbqU)YPQTWfiXi+ceaBgPUwf|'sf7rq2ZdVX6xs\GXkvaGU\ _ U ^ _ ZaqU)ds\9cfi\9aGX1dsq1gUwYPcedTceYZW<kTX\Gq1S9ceQTa9ceXqU)ds\Ga9SZcedtaG\cfi\ZWfi\GUr lBqU)YPQTWfiX1aGXIceVTcfiXX1aZWC2_ Z2X}QU)cedtaGXkMU)xTaa _ ZaYPcedTceYZWkTX\Gq1S9ceQTa9ceXqU)ds\9a9SZcedaG\X1dsX1SZWece2XYU\9abqU)ds\9a9SZcedtaG\w>U)xTdskceda _ Xhm`WeceaGX1SZa9xTSGXz`q1a9xfZWeWegua _ X\XWZa9aGX1SPqU)ds\9a9SZcedaG\ZSGXyZWfi\GUbQfZS9a9cfiq1xTWZSq2Z)\GX\}UwEnTrlBqU)ds\9a9SZcedaG\'w>U)S`ceds\9aZdsqXuZ)\}ZWeSGX2Z)k+gMdsU)a9cfiqXkusa _ X6aGU)QU)WfiU)cfiq2ZWqU)ds\9a9SZcedaG\`xs\GXkVtgvcedsX2Zxvcfi\\Z)U)xTcCu2ZSGX6k+cfi\qU)dTdsXq1aGXkvnTrlBqU)ds\9a9SZcedtaG\ X1axs\`Z)kTk_ Za2u7ceda _ X\GXMm` ^ U)S9]K\u7qU)ds\Ga9SZcedtaG\PZSGXxs\GXkaGUvq _ XqG]qU)ds\9cfi\GaGX1dsq1gUwrnT\y\GU)WfiX1WegZdskdsU)afiff fffi fi !fi#"%$& fiff'(fi")!fi*'+*,-.fi/1032547698;:=<>25?@A4BUwS9cfiq _ X1S6]dsU ^ WfiXk+XbVfZ)\GX\6qU)YPQU\GXkzUwS9xTWfiX\>Z)\cedzDCZdska _ X1gZSGXbdsU)acedtaGX1SZaGXkcedaGUYU)SGXqU)YPQTWfiXihSGX2Z)\GU)dTcedT\>Z)\`cedDEzU)S`cedFCGE_ X1SGX\ _ U)xTWfikVXU)a _ X1SMqU)dTdsXq1a9cfiU)ds\ ^ cea _^ U)S9]K\hZVU)xTaX1S9cjfq2Za9cfiU)dUw6]dsU ^ WfiXk+XVfZ)\GX\qU)YPQU\GXkUw6WfiU)cfiq2ZW}S9xTWfiX\'wU)Sceds\GaZdsq=X HrU)S9dS9xTWfiX\u|dfZYX1Weg ^ cea _ _ X ^ U)S9]K\Uw X1gZdskU)xs\\GX1a27 Jusced ^`_ cfiq _ qU)ds\9a9SZcedtaG\rZSGX}6\ua _ xs\ _ ZXa _ X\ZYXrw>U)S9Ya _ ZdMU)xTSG\u+VTxTa ^ Xk+cfikhdsU)asdskk+ceSGXq1a}SGX1WZa9cfiU)ds\ _ ceQs\}VX1a ^ XX1dva _ X1ceS`wSZYX ^ U)S9]ZdskU)xTSG\\MVU)a _ YUKkTX1Wfi\ZSGXzSGUU)aGXkced\GX1YZda9cfiqdsX1a ^ U)S9]K\uqU)YPQfZS9cedTqU)dsqX1QTa9xfZWSZQ _ \ZdskkTX\Gq1S9ceQTa9cfiU)ds\bWfiU)cfiq\bcfi\PZvQTSGU)VTWfiX1Y _ Za _ Z)\PUwaGX1d VXX1dcfi\G\9xsXkLK`ZZ)kTX1S2uIU)WeceaGU)S2u<ZdskU)VTcfiX\2_ Z2XcfikTX1da9cjfXk ZwSZYX1dtaUwa _ X|pYUKkTX1Wr ^`_ X1SGX\9ceYPQTWfiXSZQ _ \ZSGXPSGX\Ga9S9cfiq1aGXkaGU_ U\GX _ ZKcedTbZa9SGXXlCWece]X\9a9S9xsq1a9xTSGXuKVTxTa|qU)d)xTdsq1a9ceX}agQX\`ZSGXrZWeWfiU ^ Xkf ^ cea _ Z6WZdTxfZXq2ZWeWfiXkE&MNDCPO {a _ cfi\RX QxTce)ZWfiX1dsqX _ Z)\WfiXkaGUZ`dsX ^ a9SZ)q1aZVTceWeceaBgySGX\GxTWeacedkTX\q1S9ceQTa9cfiU)dWfiU)cfiq\HU ^ X1X1S2ua9S9gKcedT}aGU`cfikTX1da9cjwgWZS9X1SwSZYX1daG\\XX1Y\aGU`VXEZ}kTX2Z)kKlBX1dsk{Z)\QU)cedtaGXkU)xTaVgvxTdTcfiX1S>uQTSGU9Xq1a9cfiU)d q2ZdTdsU)a _ Zdsk+WfiXdsX1tZa9cfiU)dU)dQTS9ceYPcea9ceXaBgKQX\rda _ XU)a _ X1S _ ZdskuX1X1d _ XPYU\9aXi+QTSGX\G\9ceXkTX\Gq1S9ceQTa9cfiU)dhWfiU)cfiq\`q2ZdTdsU)a`XiKQTSGX\\a _ X ^`_ U)WfiX6 FJSfiT UVEwSZYX1dtay KU)S9cfiksZ+u27dsqUKk+cedT\GU)YXhXi+cfi\9a9cedTkTX\Gq1S9ceQTa9cfiU)dWfiU)cfiq\cedtaGUYUKkTX1Wfi\Uwa _ XM|"w>ZYPceWegcfi\ZdcedtaGX1SGX\Ga9cedTQX1SG\9QXq1a9ceXuKa _ Za~qU)xTWfikhZWeWfiU ^ U)dsXaGUcfikTX1dta9cjwgdsX ^ kTXq1cfiksZVTWfiX6q1WZ)\\GX\|wU)SU)xTSYUkTX1Wfi\usZ)kTkagQXXi+QTSGX\G\9ceX1dsX\G\`aGUqU)dsqX1QTa9xfZWSZQ _ \2usZdskhYZ2gMVX6q1g+q1WfiX\`ceda _ X6kTX\Gq1S9ceQTa9cfiU)dUw< \}qU)dsqX1QTaG\2WYX[Z]\^D_3`baFcdfi\&^e X _ ZXQTSGU)QU\GXk Zw>ZYPceWegzUwYUKkTX1Wfi\6a _ Zayq2ZdVXP\GXX1dZ)\a _ XPVfZ)\9cfi\6Uw~ZX1dsX1S9cfiqPYUKkTX1WecedTwSZYX ^ U)S9]6ZcedwX2Za9xTSGX\6Uwa _ cfi\}wSZYX ^ U)S9]zZSGXa _ Xw>U)WeWfiU ^ cedTs{Zq1WfiX2ZS6k+cfi\9a9cedsq1a9cfiU)dzVX1a ^ XX1dk+)c fX1SGX1dta6]KcedskT\6UwE]dsU ^ WfiXk+Xua _ Zasa ^ X1WeW ^ cea _ ceda9xTcea9ceXq2ZaGX1U)S9cfiX\2uZxTdTcjw>U)S9YSZQ _ lCVfZ)\XkWZdTxfZXba _ Za]XX1Qs\6X\G\GX1dta9cZW<QTSGU)QX1S9a9cfiX\UwEa _ XnT YUKkTX1WCudfZYX1WegvSGX2Z)ksZVTceWeceagUwU)V+9Xq1aG\6Z)\^ X1WeWIZ)\rSGX2Z)\GU)dTcedT\2 e XxsX\G\a _ cfi\}WZa9aGX1SQU)cedtacfi\}QfZS9a9cfiq1xTWZS9WegceYPQU)S9aZdawU)Sra _ Xxs\ZVTceWeceaBgvUwZdtg]KdsU ^ WfiXk+XVfZ)\GXk \9gK\GaGX1Yd U)xTSywSZYX ^ U)S9]uZWeW]cedskT\Uw~]dsU ^ WfiXk+XZSGXSZQ _ \X2Z)\9ceWegcedtaGX1S9QTSGX1aGXkuZdskSGX2Z)\GU)dTcedT\q2ZdVXPSZQ _ cfiq2ZWeWegSGX1QTSGX\GX1daGXkced ZhdfZa9xTSZW|YZdTdsX1Sxs\GcedTa _ XSZQ _ \~a _ X1Y\X1WeX\2uTa _ xs\rXiKQTWZcedsXkaGUPa _ Xxs\GX1S}U)dhceaG\~U ^ dvYUKkTX1WeceZa9cfiU)dXq _ dTcfiq2ZWqU)dta9S9ceVTxTa9cfiU)ds\2u ^ S2 a2<QTSGX1KcfiU)xs\ ^ U)S9]+\EU)dqU)dsqX1QTa9xfZWSZQ _ \2uq2ZdVX`\GxTYPYZS9ce2XkZ)\w>U)WeWfiU ^ \2{g _ XSGX1QTSGX\GX1daZa9cfiU)dUwk+c)fX1SGX1da<]cedskT\7Uws]dsU ^ WfiXk+X~Z)\qU)WfiU)SGXknT\{w>Z)q1aG\uced+w>X1SGX1dsqX|S9xTWfiX\2uX1U)WexTa9cfiU)dS9xTWfiX\}ZdskqU)ds\9a9SZcedaG\2g _ XcedaGX1SZa9cfiU)dvUwqU)ds\9a9SZcedaG\cedtaGUZySGX2Z)\GU)dTcedTPYUkTX1WCKYU)SGXU)SWfiX\G\\9ceYPceWZSdsU)a9cfiU)ds\`Uw7ZqU)ds\Ga9SZcedta _ )Z kzZWeSGX2Z)k+gVXX1dcedta9SGUKk+xsqXkVTxTa ^ X1SGXbU)dTWegxs\GXkaGUq _ XqG]vqU)ds\9cfi\GaGX1dsq1gvUw|Z\GceYPQTWfiXSZQ _ > Z)\cedha _ X|zYUkTX1W'I _ X6qU)YPQTWfiXi+ceaBghUw<qU)ds\9cfi\9aGX1dsq1gMq _ XqG]KcedT ^ Z)\`dsU)a]KdsU ^X U)VTaZcedsXkwCZYPceWegzUwYUKkTX1Wfi\ ^ cea _Z qU)YPQTWfiXiKceagzq1WZ)\\9cjfq2Za9cfiU)dg ZM\GgK\9aGX1YZa9cfiqb\9a9xsk+gzUwa _ PUwEZ)\G\Uq1cZaGXkqU)ds\Gcfi\9aGX1dsq1g3hkTXk+xsq1a9cfiU)dQTSGU)VTWfiX1Y\2ufcedsq1Wexsk+cedTa _X \Ga9xsk+gMUwQfZS9a9cfiq1xTWZSq2Z)\GX\Uw<S9xTWfiX\rZdskhqU)ds\Ga9SZcedtaG\2u ^`_ cfiq _ QTSGUcfikTXcedtaGX1SGX\9a9cedTqU)YPQTWfiXiKceaghSGX\9xTWeaG\2e XyZWfi\UPX\9aZVTWecfi\ _ XkMWecedT]+\`VX1a ^ XX1dqU)ds\9cfi\9aGX1dsq1gMq _ X qG]KcedTZdskv kTXk+xsq1a9cfiU)dufa9SZds\9WZa9cedT_ XIqU)ds\9cfi\GaGX1dsq1g3h kTXk+xsq1a9cfiU)dQTSGU)VTWfiX1Y\cedaGX1S9Y\Uw+ kTX k+xsq1a9cfiU)d<Ba\ _ )U xTWfik6VX<dsU)a9cfiqXka _ Zaa _ XU)QX1SZa9cfiU)dfZW7\GX1YZda9cfiq\rUwYUKkTX1Wfi\}qU)YVTcedTcedTS9xTWfiX\ZdskvqU)ds\9a9SZcedaG\2ufdfZYX1WeghFCGE uTFCZdskE <u+cfi\`X2Z)\9gaGUbxTdskTX1SG\9aZdskhVTxTa ^ X ^ X1SGX6dsU)a}ZVTWfiXaGUceXZWfiU)VfZWWfiU)cfiq2ZW\GX1YZda9cfiq\2IdskTXXku,-ifijlk4Pm1n5oDprq47s5@)6utvn5wyx1<>q4rz{0>?>|}m1n5?>z~6B05@A?36z_ X1SGXcfi\IZdPxTdskTX1S9WegKcedTdsU)dPYU)dsU)aGU)dTcfiq`YXq _ ZdTcfi\GY ^`_ U\GXWfiU)cfiq2ZWscedaGX1S9QTSGX1aZa9cfiU)d\ _ )U xTWfikbSGXRQxTceSGXU)dz\9aZdsksZSGkWfiU)cfiq\2r _ XykTXsdTcea9cfiU)dUwEZWfiU)cfiq2ZW<\GX1YZda9cfiq\}w>U)S}a _ X\XYUKkTX1Wfi\}cfi\ra _x \ZdU)QX1dQTSGU)VTWfiX1Y_r^#\5`fi>D&>^cuXe XZSGXMcedskTX1VTaGXkaGUcfiq _ X1Wm _ X1cedZdskX1dsX1Kc1XvnceYU)dsX1aPwU)SPaX2ZS9WecfiX1S6X1SG\9cfiU)dUwEa _ cfi\ ^ U)S9]Zdsk _ X1WeQ+wxTWqU)YPYX1daG\2 e XbZWfi\GU ^ cfi\ _Q xTcfi\2uTZ)\ ^ X1WeWZ)\|ZdsU)dgYU)xs\SGXw>X1SGXX\2uw>U)Sa _U)xs\\GX1a|ZdskocfiX1S9SGXZS_ 1X ceSq2ZSGXwxTW`SGX2Z)k+cedTUwZdaGUa _ ZdT]ZS9cfiXlJm _ S9cfi\Ga9cedsXX1ceS|cedtaGX1SGX\9a9cedT\GxTX\9a9cfiU)ds\Zdsk\GU)YX6qU)S9SGXq1a9cfiU)ds\*>^F_>crVTceaGX1VU)xTWCuneu>H}xTWeWCu eusrcZdxub27F5{7fiu'RE`kTk+cfi\U)d+l eX\9WfiX1gK`ZZ)kTX1S2ueuU)WeceaGU)S2u euU)VTcfiX\2unI2SZ)q1aZVTWfiXZdskXq1cfiksZVTWfiXPsSZYX1dtaG\yUw~m|U)d+lqX1QTa9xfZW7SZQ _ \2Id1**{l5)usQTQ3trt7+nQTS9cedTX1S2K`ZX1a2us lBeuX1dsX\9a2ueubxTdTcfiX1S2u l 2dsU ^ WfiXk+X `qRQxTcfi\9cea9cfiU)dZoxTSGXSZQ _ lbK`Z)\GXkdsU ^ WfiXk+X X1QTSGX\GX1daZa9cfiU)d UkTX1W rQTQTWecfiq2Za9cfiU)d^ cea _aGU_ Xncfi\9gKQ _ xs\9lB mZ)\GXna9xsk+g**Z2)ZceWZVTWfiXZaZ 9g-q2Z h'ynK* h'6 e h'6 ehfZ'XG\ _ a9Y_ a9a{h7h\GX9d xsq2ZWet'K`ZX1a2u(s lBeu xTdTcfiX2u l >+y _ Xb|ZYPceWeg{<i+aGX1ds\9c)ds\w`nceYyTWfiXm1)dsqXTa9xfZWZ' _ \IBd**{5{3 r)u3s7K+2+K`ZX1a2u(s lBI>+b5R5b]r>5~75~]l>'rr3>3RluX1WeWecfiX5*RR7 Pu7LRr>>b }o _ -bsa _ X\9cfi\2u}dTceXG \GceaBg9 wE) dtaGK9cfiksZ+u27J7rda _ X{GX1WZa9ceXrXi3GX\G\9ceX1dsX\G\1wkTX\Gq9cATa9c)dW)cfiq\|Zdsk]3GXk+cfiq2ZaGXrW)cfiq\2{ 1 >b Ar55 utu>777JKK\2umeu5K)aA+u(KeuDd _ R 1 _uo7<26Kk3ecedTdskncAyx3a9cedT=Hrx3Gd}K _ Kca9x>'~' _ 2 Id1{l>{'u2u33sK+nu39cedT2cea _ m1) dsqRT_ dsk~+u(Peueceduo7 I27M{Ta9cAG'IcAy31dta~a9c)d)dqR)d)xTdsq1a9ceGQx9cRcePa9c )>'k ~a y>R2<Bd*'Dv>{(L[&[*{5uu357K+_ 1cedueu7xTdTc2 u l `2m1)dsqRTa9x>'r~' _ 2{<7xTdsk'1dta~'r)a9c)d23& >b )r5~ 1 1uu>7J7rt7J+_ 1cedufeufxTdTc2uf l euncA)d1a2uP2`{RGak~' _ 2{ ~' _ lfi>k9d jlk+ 3R1dt~a a9c )dpKk3 cea _ nGdta9cfiqR2Bd1*G9 tuY3D''7's9r9x+w GdTdm1)c2ufeuf xTced>'fik3Tu27eced'rk3RGq9cATa`wqR)dsqRTa9x>'7~' _ dsk9qwegPc'c _ c aR9a2d=1*Y*lr'uRsu3T7J7K7Kfnu39cedT2m1)x3)dskuKneu"n'ea2ut~2ocqR RexTa9c)d{l 'Gk3 '9oDq1a9ceRd[1*{ll 7>7t3u 3 )27+nu39cedT2,-fi/1032547698;:=<>25?@A4BcATculseuHyureu~ )cxurn2nGdta9cfiqv'ecfika9c)dwm1)dsqRTa9x>'~' _ IB**{l&&{R>7u33sK7+nu39cedT2>'9c2uHeu dTsufeunKq _ ciu6I27Jbvcji3kqR)d9a~cedta~a9cwfi)q1a9c)d{w~' wk q1c 9c )d933~xTdsk3~cedsqRy31ad k+Ed1*#*{{{3 uu32+3k32u<6eu<D'Gk+cCu<27z)d)a)d)d>)k+cfiqhnKodskm1)dGa~cedtana9cwfi)q1a9c)dd1~~u'*u7G<u 3J+2 J+R2uhb>b37r 7*5 5~!3& 7731off-bfiffR 2usfi e}G7u7ffuKmeu e x T~ubE27h Aqo#uw~oKqRk+x3wyfi hm1sqRfi9x>'~'fiff}o)7~'2E1D*{lr'&&{rsu3)+nu3 T2ufbeu RuTeuTnKq'GqRATus2<m1y>' =w<n9xsq9x3~'7m`nKoqRylffKk321**{3 u3>''+Gk AR2u)b2oq {fi jfq oKqRk+x3w'3x m1sqRfi9x>'s~'fiff21*uF#R&{'52 u3f+JK7+eu'P27J!+xsq eE"ffR R { jfq 'esqRK 15R 1Y5# r!5R>fiu32+m`n |oIx33 fiq 21%$uf&Peu )x2us 'Jm27J# jfq LwD( )+ KlRKl)zm1~ 'ffq% TsE1#{{3 )u37+* xu|b e euE* ~)xfi Cu }2"ff 3R~ wnGfiqm1~+sRq fi9x>'~'fiff`n$2,1**l{{'32uu3f+Tnu3 T21xT-fi 2uK ' 27~' e hnuq ' e Mw`m1sqRfi9x>'~'fiffDu7u5*.3G5fi &R F >b Ar~1Duu7'7sxT-fi 2u ' <>{( )+ 3R~ } ~fi T{>~)97~'fiffH'fifffi E,1D*{l)u3)2+nu3 T2xT-fi 2u ' eumff u27J 3R/3R6qRfi> ~sqRR~ fi2q03R7~'fiffR21& >b Ar5 Ffi uu57J+oY'> A0 )xumH2'{5fi75 7 7fi ' eR$o72ut~ 2'uq1x3 e~xfi~e'fi $w33;w"fftxDu *>G &u'u}3 )1 {II% .=uE"ffm1Aq) e Gw60 Io72uK2 A%ff>x 2u K72'su33>73'!++oA2ueuvxT-fi 2u ' euRmff uf2)- fiqyw{R)~'fiff2y{5fi75>b )u5~1Yu u>777Kx3jw9ut24 e) Tm1~}n wfi)q lq5fffifi QtxR|w6q}~'fiffoFLGqfffi TssG1*>b575 5 7~}&{Fr 7**>*73Ry~&G}Rsu3f7K7+nu3 T2n'e72u~|2"ffR 32% Tvx Tv7~'fiff~ / 8ffqRsqRfi9x>'|7~'fiffw9'G' E, 1#*3 u3577J7J+n'e72u~eu)vxT-fi 2u ' K27JTn)xfiybm1y3Y 'y K)q~ 'mff> fi~'fiff 3x R2, **{lu&{r7u33'tK7J+nu3 T2,-,fijlk4Pm1n5oDprq47s5@)6utvn5wyx1<>q4rz{0>?>|}m1n5?>z~6B05@A?36zn +u&s|I2'v75~b3 3RDR771~u959r1fi ' e R$nKq$2u uf277"ff$%0 ':'; A(fffi ~'Gqff$& {5bfi51u(uK+"fftxuT2+o3(<315=39xfiT?> fiqff3 ff*>)qffM1 17R(@u357757&&u )e T2u<27ym1sqRfi9x>'~'fiffA A9'J{3 )- fiqy,v11*lu'rRsu3577K,-3Bfifffi! #"$ %'&)( *,+.-//-102-346574!( 389:;< =)((?>/!(@BA: %&=DC1>/-EGFIHKJMLONPHKQ1R<NTS9SUWVYXZNTQ[\Q9[^]_Na`bXZJdc\S1efLONPHKQ1RhgiQ1NTSJ)]dF^ej`bXZelkmQRnHJMXpoqJ)XNsrItuJ)v)e,[wgxQNTS1J)]dF^eyrzU|{2He,L}p~$ffYn~2,M92Z#P~2#2'#u~$q22M792b~$B$M92ZZff6z7M92Z2'u2ff'2ffM92ZTKBq6Bd ?,!l?B?)qq Zf! qB9BPqZB9.BqM?ff? !P M.?M!PB??q1!?, ^I ?9\ff. fi7?B? 19#q| ff19q fn ?9#6B! qP ? !d<19.d 9!? 6B?!"7Z?9 .q! #7.)$ !B?D?%9ZB .?.&1 6?q '&().)?9??*?96? q?B?!9B 6B.,+-?%9q. q&+-?9! d? !! % 9B?!,ff q fi/1 q! . 01?M: 8< 7 =?> ff@ AB 6B!q ? !C()u87 9;12 34 .Bq951 96<+D % !B . .BqC+D !1 $qE% \.d9.B?q9Y ? 9&F ?G 9 ^ 6qH7, qK?^,ff qJ ?d5 B925% ?9uq ,9 ^? ?9&F qqqqP?^d#7?K% Lff P M?9BP % !2q !?u?9) 9&OuN B M+D % 9B?! . .Bq8+D !! )?q q Bfi% ?q% P7!B6 !5? 6 D/n\RQS q!,.u zq !1 T?% 9q.Bq9UTV 4W d?6B? | *% q?.XZY\[]^)_a`fbH^]c dfhghiffjIkmlnhopfhqr'iGsStusSvSiffwMsZdyxRfwMlzsSi)iL{J|lpiffjv-nhjmkIjmn vRr'xnhonh||LiffsRs-vSfn*ozn xRqhi~}n xlzivt$fh'lzj'fhxwMn vRlpfjesSfr'x|Liffs\nhjmksSixR}ulz|Liffs&xRfwnhjtdymfj'ihcetusSvSiffwMs&vRmn v\sRr'dmdfhxRv&sR'fhxRv\r'vSvSixnhjm|Liffs,vSfsSiffopiff|LvMndyn xRvRl|rmozn x\rmjm|LvRlpfjvRmxRfr'qnsSvRn vSiffw\iffjv6sRry|nhs;cun t|LxRiffkmlpvM|n xk5|Lfoopiff|Lvfhx6d"ixsSfjuHvSfdixsSfjmUn xi8sRnff}ulzj'qM|LfwMdynhjmlpiffs*wlzozozlpfjysGfh)k'fozozn xsadix*thiffn x ~idyopf thiffkEsStusSvSiffwMsnhjyk0xRiffsSiffn x|dmxRfhvSfhv tdiffsiL'lzsSvfhxGn dmdyozlz|n vRlzfjms-srm|\nhsdixsSfjynhoiffwnhlzounhjmk,|nhopiffjmkmn xsffhvSxnff}hiffomnhjykCxiffsSvRnhr'xnhjvlzj'fhxwMn vRlzfjZ"nhjykEdixsRfjmnhoynhjmgelzjmq5n qhqlznuKnhsSvRn qj'ixl/$nhjmlpiffozlHDffhhe-nhopghixff'xRfwMixffn xnfftnhjmnhjPffhhePceiffj'iLUrmih~DfozlpxRfjml/)n f'aPivR'ixlzjmqhvSfjZ5fukmk'iffnhr~$oznhsRsPffhhecunhjmkmixwMnhjZcuvRr'xwOk'iffj$s$af}hiffsIUxRiffw\ixsCffhheM5eru5n xRxRfoo5n xd"iffjvSixff&ffhhyL\ ! Giv$vR'ixRiCn xi&sSvRlozowMnhjtOxRiffsSiffn x||mnhozoziffj'qhiffs*|r'xRxiffjvsStesRvSiffwMsPn xi&ozlwMlpvSiffklzjvR'ilzjvSixnh|LvRlpfjOvRmit0sr'dmdfhxRv5nhjmkOmxlzvSvRopilzjOwMnhjtJxiffsSdiff|LvRsylzsdyn dix~lzj}hiffsSvRlpqn vSiffsUw\ivR'fukms)et,mlz|MsSdfhghiffjMkmlznhozfhqr'isStusSvSiffwMsa|nhj zR vSf&sRr'dmdfhxRvw\fhxRiMjyn vRr'xnho)lzjvSixnh|LvRlpfjfjvR'i\ynhsRlzs$fhUvR'ifflpxdyxRi}elzfrmsiLedixlpiffjy|LihMj'i\Un tvRmn vI|r'xRxRiffjvsSdfhghiffjkmlznhopfhqr'i&sStusSvSiffwMs$n xRi,rmlzvSiCozlzwlpvSiffklzslzjvRmifflpxsRvSxn vSiqlpiffsfhxk'ivSiff|LvRlj'qJnhjykxRidnhlpxlzj'qdmxRfhopiffwMsvRmn vIn xlzsRi,lj|Lfj}hixsn vRlpfjZ-srm|nhsIwlzsRrmjmkmixsSvRnhjmkmlj'qskmrmi&vSfEsSdiiff|xRiff|LfhqjmlzvRlpfjixRxRfhx,fhxMwMlsRlzjvSixRdmxRivRn vRlpfjndmxRfhopiffw|nhji0k'ivSiff|LvSiffkZavR'iOsStesRvSiffw|nhjifflzvR'ix,vSxnhjmsSixvR'i\|nhozo-vSfOnJermwMnhj|rmsSvSfwMixI|n xRi\n qhiffjvfhxw\fukmlptlpvRskmlznhopfhqr'i,sSvSxn vSiqhtlzjnhjn vSvSiffw\dmv$vSf-//-n %%!=6T=5D1UZ!fi;l~:! %&% q&1%2%1 =fi2Zy222 S2-7M1m72xRidynhlzxvR'iMdmxRfhopiffwO,i6|nhjvSxnhlzjsStusSvSiffwMs8vSflzw\dmxf }hi\vR'ifflpxIn lzozlpv tvSfEkmivSiff|LvIdmxRfhyoziffwMs$tiLudyopflpvRlzjmq6kmlznhozfhqr'iffs$|Lfozopiff|LvSiffklzjlzjvSixnh|LvRlpfjmslpvRermwMnhjrmsSixsmixRiCvRmi,ljmlpvRlznho-sSiqw\iffjvRsfhZvR'iffsSiPkmlznhopfhqr'iffsan xRiPrysSiffk\vSf&vSxnhlzjMnCGxRfhyoziffwMn vRlz|*$lznhopfhqrmiGxRiffkylz|LvSfhxa5vSfI /ff vRmn vndyxRfhyopiffwls8ozlpghiffoztvSfEfe||rmxff 'iMfrmvSdyr'vIfhKvR'iJ~$|nhjiJlzwMw\iffkmln vSiffoptn dydyozlpiffkvSfvR'isStusSvSiffwOsGkmiff|lzsRlpfj,fh"'ivR'ix~vSfvSxnhjmsSixGvR'i*|nhozomvSfInIrywMnhj\|rmsSvSfw\ixa|n xRin qhiffjvfhx~lzvG|LfrmozkdfhvSiffjvRlnhozopt"iMrysSiffknhs8n|r'iMvSfvRmisStusSvSiffwOs8$lznhozfhqr'inhjmn qhixCvSfw\fukmlptElpvRsiffmn }elzfhxIvSfxRidynhlzxKdmxRfhyopiffws'nhjmkOi}hiffjdixyn dysuvSfMdmxRi}hiffjv*vR'iffwjdmxRi}ulpfrmsPafhxRg"ZUi&xid"fhxvSiffkljmlpvRlznhoxRiffsRrmopvRsPfhxvSxnhlzjmlzjmq6n0~$rmsRlj'q6nJ} n xlpivtEfhakmlzixRiffjviffn vRr'xi8sSivRsC-nhj'qhgulzozk'ih'nhopghix mxlpqvfhxlzjZy-lpvRwMnhjZffhhenhopghixff-nhj'qhgulzozk'ihxlpqv$$fhxlzjZlpvRwnhjZ hh "'iffj?nhjynhoptfflj'qvR'idixRfhxwMnhjm|LifhvR'irmooptnhr'vSfwMn vRlz|,iffn vRr'xRi6sSivUi\iLunhwlzj'iffkml|mnhjmk'ozn iffozopiffkEiffn vRr'xiffsIwMnhk'iMozn xqhi\d"ixfhxwnhjm|LiMlzw,dmxRf}hiffw\iffjvRs"ryjmk'ix*vR'i&nhsRsRrmwMdmvRlpfjOvRmn vPrmvRr'xRiIUfhxRgOsR'frmokOfu|rmsfjk'i}hiffopfhdlzj'qnhr'vSfwn vRlz|iffn vRr'xRiffsvRmn vCn dmdmxRf ulzwn vSi\vR'ilzj'fhxwMn vRlzfjEdyxRf }ulzk'iffketEvRmiffsSiMmnhjmkuon "iffoopiffkiffn vRr'xRiffsff 'inhjmnhoptusRlzslzjmkylz|n vSiffkvRyn vvRmi&mnhjykuozn iffozopiffk'$D *iffn vRr'xRihZml|Eiffjm|LfekmiffsPP'ivR'ix$vR'isSdfhghiffjoznhjmqrmn qhiMrmjmk'ixsSvRnhjmkmlzjmqHff-|Lfw\dfj'iffjvI|n dmvRr'xiffkvR'iMw\iffnhjmlj'qOfhaiffnh|iL'|mnhjmqhi|LfhxRxRiff|LvRozth~'iffjvRmlsKmnhjmkuozn iffozoziffk6iffn vRr'xRiClzsKnhkmk'iffkOvSf6vR'i8nhr'vSfwn vRlz|iffn vRr'xRiffsylzvlzw\dmxf }hiffkvR'i*dixRfhxwMnhjy|Li*fhvR'i~$t\nhozwMfsSvUJ ylzsjmkylzj'q$opiffkMrms~vSf8k'i}hiffopfhdJnhjOu-dmxRiffkylz|LvSfhxnhopghixffKxlzqvKnhjmqhgelzok'ihU hhh| Mnhjmknj'i}hixsRlpfjfh$vR'iavRmn v\UixRidfhxRvafjJmixRih 'i$j'i}hixsRlpfjJfhvR'i$~$vRn ghiffs*nhs5lzjmdyr'v~nCryozopt\nhr'vSfwMn vRlz|}hixslpfjJfhvR'iu- aiffn vRr'xRihmylz|0Ui8|nhozo H u-i*vSxnhlzj\nhjmk,vSiffsSv)fhvR,vR'i H u- dmxRiffkml|LvSfhxGnhjmk,vR'i*~$fjn|LfhxRdyrmsDfh"hhkmlznhozfhqr'iffsI|Lfozopiff|LvSiffklzjnhjiLudixlzw\iffjvRnho)vSxlznhofhK sC JfiffsSdfhghiffjkmlznhopfhqr'iCsStesRvSiffwH$fhxlzjZlz||n xkyl/ xlpqvffhPiffozoznMfhxlzj-ffhhel||n xkmlfhxljZu hhu*'wMwMlz|v* PozfjmsSf'ZffhhajJvRmlzsUvSxlznhoHvR'i sStesRvSiffwUnhsKlzjysSvRnhozopiffkn v\nhj |rmsSvSfw\ix\|n xRiO|LiffjvSixff nhjmsSUixRiffk|nhozozsCxfwolp}hi6|rmsRvSfw\ix,vSxn{6|0nhjmksRrm||LiffssSryozoptnhr'vSfwMn vSiffk?nozn xRqhijermwC"ix,fh$|rmsSvSfw\ix\xiffr'iffsRvRs;jiL'nhw\dyopikmlnhopfhqr'iJvRmn v|Lfw\dyozivSiffk;srm||LiffsRsSrmozoptlzsCsR'fjljlpqr'xiE 'id'fj'i6jermwCixs)|n xk;jrmwCixsnhjmkOdlzj0jrmwCixsKlzj0vR'iCsRnhw\dyopikmlnhopfhqr'iffs*n xRiCn xRvRl|lznhoHeT44VfiVfi11"(KZ(,.q#9?ffl$q2T89B.?9q?LqD?ff%9! 2#" 1 V 4 T%$ 3'& ! 2#P" 1Nql%n.|I.BD?IB(& 1 !#!)! 2$2$22+* ,.S- @q/- !9 0LqDBlffP%<Bq1& 1 !#!)! 2$2$22()q'lpqrmxRiM Ucunhw\dopi32fi4D )567698 $lznhopfhqr'iPfhvSiCvRyn v*vR'iCsRtesSvSiffwsr'vSvSixnhjy|LiClzjEcu|LfjmsRlzsRvRsKfhGn\xRidynhlzxlzjmlpvRln vRlpfjZ'w\fhvRlp} n vSiffket0vR'isStusSvSiffwOsCn ylzozlpv tvSfkmivSiff|LvIvRmn vIvR'i6rmsSixffsIrmvSvSixnhjm|Li:);05nhs8ozlpghiffoztvSfmn }hiiiffjwMlzsrmjmk'ixSsSvSfefek miJqhfnho*fhPvR'i H u- CdmxRiffkylz|LvSfhx\lzs,vSflzw\dmxf }hiOvR'iOsStusSvSiffwOsMn lzozlpv tvSfk'ivSiff|LvJsRrm|?wMlzsRryjmk'ixsSvRnhjykmlzj'qs 'iEkmlznhopfhqr'iffsMvRmn vmn }hivR'ikmiffsRlpxRiffkfrmvR|Lfw\ih*lzjml|24-< 5ff676=8" kmlznsrm||LiffsRsSrmozopt6nhr'vSfwMn vSiffs*vRmiI|rmsSvSfw\ixffsK|nhoo/mn xRixRiixRxRiffk0vSfMnhsKvRm#4ff3ff1fi>72> 9?f7A@d.22opfhqr'iffsff$lznhozfhqr'iffs~lzjMmlz|\vR'i sStusSvSiffw kylzk\j'fhvasrm||LiffsRsSrmozopt&|Lfw\dyopivSiPvR'i|nhozozixffs)vRnhsSgn xRiIxiixRxiffk0vSfnhCBEDFGy8 4E2 6 miffsSiIn xRi8k'iffs|Lxlpiffk0lzj0rmxRvR'ix*k'ivRnhlzoiffopfIylzs5dyn dix*xRidfhxRvRsKxiffsRrmopvRs5xRfw iLudixlzw\iffjvRs5vRmn vPvSiffsSv*'ivRmixlpvlzs5dfsRslpyopi$vSfopiffn xjOvSfnhr'vSfwMn vRl|nhozoptdmxRiffkmlz|Lv$vRmn vCnkmlznhopfhqrmi&PlzozoDi&dyxRfhyopiffwMn vRl|CfjvR'iMynhsRls$fhUlzjmfhxwn vRlpfjvR'isStusSvSiffwmnhs* ~iffn xoptljvR'i$kmlznhozfhqr'ihenhjyk/UlzjxRiffnho"vRlzw\ihivSxnhlzjJnhj0nhr'vSfwMn vRlz||oznhsRslyixfhxdmxRiffkml|LvRlzj'q;dmxRfhyopiffwn vRlz|kmlznhopfhqr'iffsxRfw iffn vRr'xRiffsvRmn v|nhjinhr'vSfwn vRlz|nhozoptiLevSxnh|LvSiffkxRfw vR'i |LfhxRdyrmsffPsMkmiffsR|Lxlpiffkn f }hih5fj'ifhvR'iffsSiiffn vRr'xiffsMlzs\vR'iOfrmvSdyr'v\fh$vR'iH u$D dmxiffkmlz|LvSfhxffDvR'i H u- iffn vRr'xih)mlz|dmxRiffkml|LvRsI'ivRmixCfhx,j'fhvvR'i0|r'xRxRiffjvCrmvSvSixnhjm|LiJUnhs,|LfhxRxRiff|LvRoztrmjmk'ixsSvSffuknhopghix\iv,nho/p~ hhh| 'i6xRiffsRrmozvRs8sR'fvRmn v8lzv$ls$d"fssRlpyopi&vSfJ RR /ff dmxRfhyoziffwMn vRlz|,kmlznhopfhqrmiffsrmsRlzj'qJrmozoptnhrmvSfwMn vRlz|\iffn vRr'xRiffsPlpvRnhjnh||r'xnh|LtExnhj'qlzjmqMxfw vSf uH ;JZk'idiffjmkmlj'q\fj'ivR'ixvR'iCsRtesSvSiffwmnhssSiiffjfj'i&fhxvUf,iLu|mnhj'qhiffs~ vUlzsGdfsRsRlzyopiKvSf dmxRfhyopiffwn vRlz|*kmlznhozfhqr'iffsGlzvRnhjJnh||r'xnh|Lt6rmdvSf\hJceiff|LvRlzfjk'iffsR|Lxlpiffs nhjmkvRmikmlznhopfhqr'i|LfhxRdyrys0vRmn vOvR'iiLedixlw\iffjvRsOn xinhsSiffkfjZceiff|LvRlpfjJ;kmlsR|rmsRsSiffs8vR'iJvted"i6fhwMnh|mlzj'iJopiffn xjmlzjmqnhopqhfhxlpvRywnhk'fhdyvSiffkZ)jmnhw\iffoptKD BEBE8EDnhjmkqlz}hiffsnk'iffsR|LxlpdmvRlpfjfhvR'iiLudixlzw\iffjvRnhoKk'iffsRlpqj?ceiff|LvRlpfjqlz}hiffsnmxRiffn guk'fjfh$vR'iiffn vRr'xRiffs5rmsSiffkJlzj6vR'iffsSiiLedixlzwMiffjvRs~ceiff|LvRlzfj08dmxRiffsRiffjvRsUvR'i$w\ivR'fukfhdmxRiffkmlz|LvRlj'qIvR'iiffn vRrmxRiH u$D 5nhjmkOqlp}hiffsnh||r'xnh|Lt0xRiffsRrmozvRsaceiff|LvRlpfj&dyxRiffsSiffjvRs*w\ivR'fukms*rmsRiffk0fhxrmvRlzozlpfflzjmqB=BE8ED;vSfvSxnhlzjvRmiMnhr'vSfwMn vRlz|M~xRfhyopiffwn vRlz|,lnhopfhqr'iMGxiffkmlz|LvSfhx8nhjmkqlz}hiffsvR'i\xRiffsRryopvRs,ik'iffozn t6frmx*kmlzsR|rmssRlpfj6fh-xRiffon vSiffk0afhxRgJvSf6ceiff|LvRlpfjC'iffjJaiC|nhj|Lfw\dyn xRiIlzvUvSf\frmx*n dmdmxRfnh|Zceiff|LvRlpfjE\sRrmwMwn xlpiffs5vR'iIdn d"ix*nhjykk'iffsR|Lxlz"iffsUr'vRr'xRiUfhxRg"LYNMPORQJSUT [SWVYXlzsn6sSdfhghiffjkmlnhopfhqr'i8sStusSvSiffw ynhsSiffkfjvR'i&j'fhvRlpfjfh -S 1Z H$fhxlzjiv$nho/pDffh5eru5n xRxfozo 5n xRdiffjvSixff-ffhhjvRmi |nhozo-xRfr'vRlj'q6sStusSvSiffwOsSixR}ulz|LiffsvRmn vvR'i,rmsSix|nhjnh||LiffsRsCn xRi|oznhssRlyiffklzjvSfL|n vSiqhfhxlpiffsDdyozrysnO|n vSiqhfhxt|nhozopiffk h\u[ fhxIvRnhsRgesvRyn v8n xRij'fhv5|Lf }hixRiffktMvRminhr'vSfwn vSiffkOsStesRvSiffwnhjykJw&rmsSvUivSxnhjysSixxRiffkvSf\n&rywMnhjfhdixn vSfhxIHfhxlzjiv\nho/pffhhJ~nh||n vSiqhfhxRtk'iffsR|Lxlz"iffs&nkmlixRiffjvCvRnhsSg"asrm|nhs,dixsSfjuHvSf HdixsRfj;kylznhozlzj'q'fhx8xiff|Lifflp}elj'q|LxRiffkmlzvIfhx&nwMlsRkmlznhopiffkjermwC"ix misStusSvSiffw k'ivSixwMlzj'iffs8mlz|vRnhsSgvR'iJ|nhozopixlzs8xRiffrmiffsSvRlzj'qOfjvR'inhsRlzsfh*lpvRsCrmjmk'ixsSvRnhjmkmlzjmqJfhKvRmi|nhozopixffs8xRiffsSdfjmsSivSfvR'i6fhd"iffj'Hiffjmk'iffksStusSvSiffwqhxiivRlzj'^q ]_a`b_ca L ed0$jm|LivR'i\vRnhsSgmnhsiiffjkmivSixwMlzj'iffkvR'ilzj'fhxwMn vRlzfjj'iiffk'iffkIfhx-|LfwMdyopivRlzj'qvR'i~|nhozopix sxRiffer'iffsSvlsZfhmvRnhlzj'iffkCrmsRlzjmq5kylznhopfhqr'i~sr'yw\fukmrmopiffsvRmn vn xi8sSdiff|l|fhx*iffnh|EvRnhsSgiffozon,fhxlzjZZffhhmiCf sStusSvSiffw|LfjmslzsSvRs$fh5nhjnhr'vSfwMn vRlz|MsRd"iiff|xRiff|LfhqjmlzixffnOsSdfhghiffjoznhjmqrmn qhiMrmjuk'ixsRvRnhjmkmlzj'qMwMfekmryopihynkylznhopfhqr'i8wnhjmn qhixffnhjmkn6|Lfw\dyr'vSixvSiffopidy'fjt0dyozn vSfhxwOK$r'xlzjmqMvR'ivSxlznhoHvR'iiffmnff}ulpfhxsUfhnhooyvR'isStusSvSiffww\fukmrmopiffsaUixRinhr'vSfwMn vRlz|nhozoztMxRiff|Lfhxk'iffk0lzjJn,opfhqCopih'nhjmkozn vSix,vR'i0kmlznhopfhqrmiffsIUixRi6vSxnhjmsR|LxlpiffktermwMnhjys8nhjmk;ozn iffozopiffklpvRfjmi6fhx\w\fhxRi6fh*vR'iffvRnhsSg|n vSiqhfhxlpiffs)xRidmxiffsSiffjvRlj'qvR'i6vRnhsSgvRmn v&vR'iJ|nhozopix85nhs,nhsSgulzj'q vSfdixRfhxwO-fj;ndix8r'vSvSixnhjy|Li6ynhslzs 'iopfhqopiffs8nhosSflzjm|ormk'iffkozn iffozslzjykmlz|n vRlzj'qOP'ivR'ix8vRmiMlpffn xkmnhkvRn ghiffjf}hix8vR'iM|nhozoDfhxIvRmi,rysSixImnhkermj'qOr'd&r'x$iLedixlzwMiffjvRsrmsRi&vRmiMopfhqJopiffsvSfOiLevSxnh|Lvnhr'vSfwMn vRl|nhozopt0fhmvRnhlzjmn opiiffn vRrmxRiffsrmsRiffknhs*dmxiffkmlz|LvSfhxsnhjmkOvSf6kmiLj'ivR'i8|onhsRsSiffs*fh)kmlnhopfhqr'iffsvRmn vaaiPUnhjv~vSf&opiffn xjMvSfCdmxRiffkml|Lv 'i*|LfhxRdyrms~fhZhh8kylznhopfhqr'iffsGrysSiffklzjMfr'x~iLudixlzw\iffjvRsG5nhs|Lfozopiff|LvSiffkJlzj6sSi}hixnhoiLedixlzwMiffjvRnho'vSxlznhozsGfhCf fjJozlp}hi|rysSvSfw\ixUvSxn{6|Cg Plz||n xkml" $fhxlzjZhhu=ewMwMlz|vK PozfjmsSf'ffhhynhjmk0lzsaxRiixxRiffkvSf\nhs5&lzjg lz||n xkml"fhxlzjZ' hh4ff3"fi2Zy222 S2-7M1m72i&kmlznhopfhqrmiffs*} n xRtlzjEopiffj'qhvRZZh n xRiIy}hi&iL'|mnhj'qhiffs$fhx$opiffsRsPlpvRh;fh~nhozovRmi&kmlnhopfhqr'iffs'|LfjmsRlsSvRlzj'q,fhfjmopt6vUfiL'|mnhj'qhiffsffsIw\iffjvRlpfj'iffkn f }hihDkmlznhopfhqrmiffsljmlz|Cf sRrm||LiffsRsRrmooptnhr'vSfwMn vSiffs8vR'iM|rmsSvSfwMixffs|nhozo/5nhslozozrmsSvSxn vSiffklzjlpqr'xRi Kn xRiExRiixRxRiffkvSfnhsA24- 5)67698 vR'ix6|nhoozsUmlz|n xRidmxRfhopiffwMn vRlz| Zn xRiMkmlz}elzkmiffklzjvSf0vR'xRiiM|n vSiqhfhxlpiffsff miCxsSv$|n vSiqhfhxRth-xiixRxiffkEvSfnhs 4ijBZxRiffsRryopvRsxRfwn0|rmsSvSfw\ix sk'iff|lzsRlpfjEvSfOmnhj'q0r'dfjvR'i&sRtesSvSiffwI sRnhw\dopi 4ijBkylznhopfhqr'ilzslzjlpqrmxRi&e|nhozopix$wMn tEmnhj'qJr'd"iff|nhrysSi&ls k'i&ls*xrmsSvSxn vSiffklzvRvR'i,sStusSvSiffwOfr'xqhfnholzs5vSfJopiffn xj0xRfw vR'i8|Lfhxdyrms5ml|OsStusSvSiffw iffmn }elzfhxsKopiffkOvSfMvRmiI|nhozopixffsKxrmsRvSxn vRlpfjZeT44VfiVfi1(KZ(,.q#9, !l!q?Nq< * !q?I7 *?9/P.?'\\6on !< !Pff n!9m? 99u ?G9 q!J !K7T,G?^ffP%%C1?|<9B q)n)<p"n<.<PG?ffP% * , G=\, 1 @d, ff 0Nq)n#Tff%l q<qI.B9tRu%v +rq;lpqrmxRi8eUcunhw\dopi 4ijB $lznhopfhqrmimi5sRiff|Lfjmk,dmxRfhyoziffwMn vRlz|U|n vSiqhfhxRt\ w \x 4DyDhxRiffsRryopvRsDxRfwn$ermwMnhj,|rmsSvSfwMixG|n xRi*n qhiffjvsk'iff|lzslpfjvSfvRn ghif}hix8vR'i6|nhozo)xRfwvR'isStusSvSiffwO6aiff|nhrysSi lzsiLud"ixlzw\iffjvRnho/Ziffnh|;|nhozokmr'xlzj'q5vR'iGiffozkIvSxlnhohUnhsDw\fjmlzvSfhxRiffkIetInermwMnhjCn qhiffjvsSixR}ulzj'qnhsDn*Plpffn xkIP'f|Lfrmozk8f }hixRxlzk'ivR'isRtesSvSiffw 'ixiMaixinjermw8ixIfhKn qhiffjvRs8P'fdyn xRvRl|lpdyn vSiffknhs8lpffn xkmskyr'xlzj'q0vR'ivSxlznhofh nhjykOiffnh|Elpffn xk05nhsslzw\dyoptvSfozkOvSfvRn ghiCf }hixvR'iI|nhozolzDzs kmiIdix|Lifflp}hiffkOdmxfhyopiffwMslpvR8vR'i5sStesRvSiffwOsDd"ixfhxwnhjm|Lih mi~lpffn xkZs-kmiff|lzsRlpfj8Unhsopfhqhqhiffk&etvR'iaiLudixlzw\iffjvRnhosRivRr'dxRiffsRryopvRlzj'q&lzj0ozn iffozozlzj'q8vR'iI|nhozonhsKfj'i$vRmn vKvR'i$lzffn xkJvSffhgJf }hixffK-|LfrmxsSi$aiI|nhj0fjyoptlzj'ixmn vUwMlpqv~mn }hiw\fhvRlz}n vSiffkJvR'iPlpffn xk\vSf&vRn ghif }hix5vR'i$|nhozo/r'vGUiPnhsRsRryw\ivRmn vavR'iPlpffn xkmnhkqhffukxiffnhsSfjfhx$k'flzj'q6sSf'kmlznhozfhqr'iI'ixi8vR'iClpffn xkEk'iff|lzk'iffkvRmn vPvRmiCkmlznhozfhqr'i85nhsdmxRfhopiffwMn vRlz|$nhjmkOvSfefhg0f }hixvR'iI|nhozolsKsR'f PjlzjOlpqr'xR3;eeT44VfiVfi11"Z(K(,* -{, 1| }0.q? "+9 K%?~ z?2d*WndC.q1SF ?ffd?BZT & ff?9&qE(;(5. dCnn?z. 1 $q(()?|)Cq. 6'mD Lq D?ff%9F & !$Dqd 9Td.dffP%K & ! 2"2 "a1 V 4? "+ 9 D9? 6zq?ff% <qB.'Nas .( q-+ ulpqr'xRi3;e5cunhw\dyopi)wvSiffw* ',.-?/|?qfi,o!0gx 4Dylnhopfhqr'iiMvRmlpxkdmxRfhyopiffwn vRlz|\|n vSiqhfhxRthGvR'iP2fi4-<5p4 D8kmlznhopfhqrmiffs-n xRiJ|nhsSiffsC'ixRiMvRmi6sStus|LfwMdyopivSiffkvR'iE|nhozo/~r'vM|n xRxlpiffkfr'vMnvRnhsSgvRmn vM5nhsjmfhvMvR'iOfj'ivRyn vMvR'i|rmsRvSfw\ix4ff3 2fi>> 9?f7A@d.22725nhs8nh|LvRrmnhozoztxiffr'iffsRvRlzj'q'jiL'nhw\dyopi24-<5<4 D8kmlznhopfhqr'iMlsqlp}hiffjlzjDlzqr'xRi\'CflzjvSixRdmxRivSiffkEr'vSvSixnhjm|Lb:nhsnxRiffrmiffsSvvSfJwMn ghiCnvRmlpxkuHdn xRvt0|nhozoZih q'KvSf 5HP,[ehM[eh" vR'iffjnhsRghiffkvR'iJ|nhozopixIfhx8vR'i6lzj'fhxwMn vRlpfjlpvCj'iiffk'iffkvSf|n xRxRtfr'vIvRylzsvRnhsSg"vR'i8|nhoopix*|Lfw\dyozlziffkZ'nhjmkOvR'i8sRtesSvSiffw|Lfw\dyopivSiffkvR'iI|nhozo/eT44VfiVfi11""2Z(K(,* -{, 1| }0.q~W1? "+9 K%? z?2d* ndC.qq6G )STC%F )n?Nql DffP%)n.||.B *qm%!I?1!? ff%? #. -LqlDffP%lBB.?9 4$4 $4Nql%n.|I.BD?IB@ff=u@44 4() q'r&b'")" )&)&& $$ p"'" p&p&* fi|C,(0lpqr'xi'Ucunhw\dyozi#24-<5<4 D8J$lznhozfhqr'iYb%Q b Q] XKQ b ]$r'x0iLudixlzw\iffjvRs0n dmdyoptvRmiwMnh|mlj'iopiffn xjmlzjmqdmxRfhqhxnhw BEBE8=DHUfmiffjZ&ffhheCffhhJvSfhn r'vSfwMn vRl|nhozopt|oznhssRlptvR'ikmlznhopfhqr'iffsJnhs0dmxRfhopiffwMn vRlz|fhxsRrm||LiffsRsSrmo/D B=BE8ED lzs6n;nhsSvOnhjmkiL{6|lpiffjv*xryopiopiffn xjmlzjmq&sStusSvSiffw k'iffsR|Lxlpiffk0lzjOw\fhxiIk'ivRnhlzolzjH5f'iffjZffhhe-ffhh"Ui8k'iffsR|Lxlz"ilpv*yxlpi ytJ'ixRiIfhxP|Lfw\dopivSiffj'iffsRsB=BE8EDlzsynhsSiffkOfjvR'i R yH RR RLZ/ C~5$nhopqhfhxlzvRmwk'iffsR|Lxlz"iffklzj?mr'xj'gexnhj' lzkyw\ixff~ffhABEB=8EDlzw\dmxRf}hiffsfj/ CalpvR0nhjlj'fhxwMn vRlpfjJqnhlzjOw\ivSxl|PvSf\qrylzk'i$xrmopidmxryjmlzj'q&nhjmkOn\Eljmlzw&rmwiffsR|LxlpdmvRlpfjOiffj'qhvRfhx~$ZHynhsSiffk'iffr'xlzsRvRlz|Gfhx~k'ivSixwlzjmlzj'q'f ?wMnhjtCxrmopiffssRmfrmozk&i5oziffn xj'iffkOsSiiUfmiffjOffhheffhhEfhx,w\fhxRi0k'ivRnhlzoslpghi6fhvR'ix\opiffn xj'ixseBEBE8EDvRn ghiffs,nhs&lj'dyr'vvR'i0jmnhw\iffsCfh*nsSivCfhp avSf&i$opiffn xj'iffkvR'ijmnhwMiffsUnhjyk6xnhj'qhiffsUfh} nhozr'iffsUfhnCmuiffk6sSiv5fh Ih mnhjmkZhH sSdiff|lptulzj'qvR'i\|oznhsRs$nhjmkEiffn vRr'xi&} nhozr'iffsfhx$iffnh|iL'nhw\dyopi,lzjn6vSxnhlzjmlzj'qJsSivvRsPfrmvSdyr'vlzsUn ff ahhMff fhxUdmxRiffkmlz|LvRlj'qIvR'i$|oznhsRsUfhr'vRr'xRiiLunhw\dopiffsuiLedyxRiffsRsSiffkJnhs5nhj6fhxk'ixRiffksSiv*fhlpHvR'iffjOxryopiffsopvR'fr'qnhjtfj'i\fhUn0jrmwCix$fhaopiffn xjmixs$|Lfrmozki&n dmdozlpiffkEvSfJvRylzsdmxRfhyopiffw"Ui\mnhknjermw8ixKfhDxRiffnhsSfjms*fhx|'fefsRlzj'Nq BEBE8ED)lpxsSvmlzvU5nhslw\dfhxRvRnhjv5vSfMin yopivSf6lzjvSiqhxn vSiIvR'ixRiffsRryopvRs~fh-n dmdyoptulzj'qvR'i$opiffn xjmixaynh|g6lzjvSf8vRmi sRd"fhghiffjJkmlznhozfhqr'iPsStusSvSiffwOG~xRi}ulpfrmsaafhxRgsRr'qhqhiffsRvRs*vRmn v*vRmiIlpHvRmiffjOxrmopiffs5vRyn Cv BEB=8EDrmsSiffsKvSfMiLudmxRiffssKvR'iIopiffn xjmiffk|oznhsRsRlp|n vRlpfjOw\fuk'iffon xRi5iffnhsSt&fhx)difhdyoziavSfIrmjyk'ixsSvRnhjmk0H5n vRopivSv"ffhu '5f'iffjZmffhhuwMn gelj'qlzvDiffnhslpix)vSfIlzjvSiqhxn vSivR'iJopiffn xj'iffkxrmopiffsIljvSfvRmi sStusSvSiffwOEceiff|LfjmkeBEBE8EDsr'dmdfhxRvRs|LfjvRlzjrmfrms)sStuw8fozlz|nhjmkvSiLevRrynho~yn qsSivIiffn vRrmxRiffsOHUf'iffjZKffhhGylzopiMfhvR'ix,opiffn xjmixssRrm|;nhsM5oznhsRsl|n vRlpfjnhjmk *iqhxRiffsRslpfjMvSxRiiffsH5'*UxlziffwMnhjZmxlpiffkmwMnhju$ozs'iffjZ cevSfj'ihffhmk'fCj'fhvUsRr'dmdfhxRvvSiLuvRrmnho~n qEiffn vRr'xRiffs 'ixRin xiJsSi}hixnho~vSiLuvRrmnhoUiffn vRrmxRiffsCljvRmlzsCkmn vRnhsSiv&vRmn v&dmxRf }hi0rmsSirmolzj|oznhsRsRlztulzj'qvRmikylznhopfhqr'iffs $jmiEfhCvR'iEiffn vRr'xRiffs0vRyn vJUilzsRmiffkvSfrmsSi5nhs6vRmisRvSxlzj'qxRidmxiffsSiffjvRlj'q8vR'ixRiff|LfhqjmlzixffsKtedfhvR'iffsRlzsff ylzsalsasRrmdmdfhxRvSiffklzj BEB=8EDiff|nhrmsSivR'ixRilzsUj'fh olzwMlpvRn vRlpfj$fjCvR'iUsRlpiGfh'vR'iUsSiv 'i~rmsRirmoj'iffsRsZfhuvR'iavSiLevRrmnhoiffn vRr'xRiffsDlzsiLuiffw\dyozlpyiffklzjceiff|LvRlpfj6eH ;e~lzjmnhozopthhdyxRi}elzfrmsafhxg&lzjMmlz|,aiynhkMn dmdyozlziffkCfhvRmixaopiffn xjmixsvSf8vR'i H u-4ff3!fi2Zy222 S2-7M1m728dmxRiffkylz|LvSfhxffGr'vRlzolpfflzj'qvRmiJiffsSv,dixRfhxwMlzjmqiffn vRrmxRisSiv,lpvRvR'i0vSiLevRrynho5yn qiffn vRrmxRiffsxRiffw\f}hiffkZKsRr'qhqhiffsSvSiffk?vRmn vMUi|Lfrmokj'fhvMiLud"iff|Lv6nhjtsRlpqjyl|nhjv\d"ixfhxwnhjm|Lilzw\dmxf }hiffw\iffjvRsxRfw rmsRlj'q,fhvR'ixopiffn xjmixs8nhopghixPivPnho/py hhh|jIfhxkmixvSfvSxnhlzjIvRmi~dmxRfhopiffwMn vRlz|)kmlnhopfhqr'iGdmxiffkmlz|LvSfhxUa$UrD BEBE8=DMrmsSiffs-nsSiv-fh'iffn vRr'xiffssakmlsR|rmsRsSiffk6n f }hih'lzjmlpvRlnho'iLedixlw\iffjvRsasR'faiffkJvRmn vUvR'iPynhjmkuozn iffozopiffkJ'$D )iffn vRrmxRihml|iffjm|Lfuk'iffs-'ivR'ixDnhj8r'vSvSixnhjm|LiUynhsiiffj8wMlsRrmjmk'ixsSvSffukfhxDjmfhv lsmlpqmoztkmlsR|LxlzwMljmn vSfhxRtlzjJlzk'iffjvRlptelzjmq8dmxRfhopiffwMn vRlz|Pkmlznhopfhqr'iffsffGfai}hixffnhozoyvRmiiffn vRr'xRiffsKrysSiffkJvSf\vSxnhlzj6vR'i~$w&rmsSviavSfhvRnhooptCnhr'vSfwn vRlz|KlpmUi*n xRi5vSfIrmsSi5vR'iK~$lj&nUfhxRgulzj'qsSdfhghiffj,kmlznhopfhqr'i5sStusSvSiffwOjCfhxk'ixvSflzw\dmxRf}hivR'iJdixRfhxwMnhjm|LiMfhvR'irmozoptnhr'vSfwMn vRl|Ja$-DUiJk'i}hiffozfhd"iffknrmozoztnhr'vSfwn vRlz|n dmdmxfff'lzwMn vRlpfjfh$vR'imnhjykuozn iffozopiffkiffn vRrmxRih5mlz|ai|nhoo5vR'i H u$D &iffn vRrmxRihlzjsSidyn xn vSiiLedixlw\iffjvRs0PlpvRBEBE8=D mivSxnhlzjmlzjmqfh&vR'i H u$D Jiffn vRrmxRilzskmlzs|rmsRsSiffk0lzjEcuiff|LvRlpfje~}elzkmiffjm|LiKxfwdmxRi}ulpfrmsvSxlnhozsfhCf sRr'qhqhiffsRv~vRmn v~lzvGlzs)lzw\dfhxRvRnhjv)vSf8lzk'iffjvRlpt8dmxfhyopiffwMslpvRylzjn|Lfrmdyopi0fhPiL'|ynhj'qhiffsnhjmkhfhPvR'iOkmlnhopfhqr'iffs\lzj;vR'i|LfhxRdrms\n xRi0y}hiOiL'|mnhjmqhiffsfhxCoziffsRs ermsiffn vRr'xRiffs8fhxIvRmi\yxsSvv afiLu|mnhj'qhiffs&n xRiMiffjm|Lfuk'iffkslzjm|Li,vR'iMqhfnhoalzsvSf0 RRhnhlzozr'xRiffs&ifhxRi0vR'it;yn dmdiffjZ miJiLudixlzw\iffjvRnhoKn x|mlpvSiff|LvRr'xRiOfhvR'ialzs\lzozormsSvSxn vSiffk;lzjlpqr'xRie mlzs,sRmf s\'fB=BE8EDlzs\rmsSiffk;yxsSvCvSfdmxRiffkmlz|Lv H u$D &fhx\vRmi0yxsSvnhjmk;sSiff|LfjmkiLu|mnhj'qhiffs mlzs8iffn vRrmxRi6lzsCiffklzjvSfvR'i0~$nhopfj'qElpvRvR'i6fhvRmix&nhr'vSfwn vRlz|iffn vRr'xRiffs miPfr'vSdr'v~fhvRmi$a$k'ivSixwMlzjmiffs~mivR'ixavRmisStusSvSiffw|LfjvRlzjrmiffsufhx5lznCdyxRfhyopiffwlzsDdmxRiffkylz|LvSiffkZ vR'iK$lznhopfhqr'i*nhjmn qhix~wMn tCnhkmn dyvlzvRs)kmlznhopfhqr'i5sSvSxn vSiqht&fhx)vSxnhjmsRix)vR'iK|rmsRvSfw\ixvSfnM|rysSvSfw\ixPn qhiffjvculjm|Lih ; fhCvR'ikmlznhopfhqrmiffs6|LfjmslzsSvSiffkfhIfjmoztvUfiLu|mnhj'qhiffs$UiiLu|ozryk'iEvRmisRiff|LfjmkiL'|mnhj'qhiPiffn vRrmxRiffs)fhxGvR'fsSi*kmlnhopfhqr'iffs'ixiKvR'i*sSiff|Lfjmk\iL'|ynhj'qhiP|LfjmslzsSvRsfjmoptCfhvR'i*sStusSvSiffwdyozn telj'qn|opfsRlzj'qdyxRfw\dmvDinhozsSfiL'|ozrmkmiffk\nhjt,iffn vRr'xRiffs)vRmn valzjmkmlz|n vSiffk&vSfIvRmi|oznhsRsRlpyixvRmn vvR'i~sRiff|Lfjmk8iL'|ynhj'qhia5nhsvRmiaoznhsSviLu|mnhj'qhi5lzjvR'i~kylznhopfhqr'ih-iU|Lfw\dn xRiGxRiffsRryopvRsZfhx RRhZdmxRfhopiffwMn vRlz|5kmlznhozfhqr'iffshlpvR,xiffsRrmopvRsDfhx LyRxhfpffwnRvlU|kzlhnphfq'rffhP'ff,jRv'*|zhnRlixZmnhs*nh||LiffssvSfMiffn vRr'xRiffsxRidmxRiffsRiffjvRlzjmq&vRmiI'fopikmlnhopfhqr'ihjfhxkmix8vSfvSiffsRvCvR'i H '$D dmxRiffkml|LvSfhxCnhs8lj'dyr'vvSfEvR'i6aD-aiyxsSv8kmiLj'iffknvSxnhlzjmlzj'qnhjykvSiffsSv,sSiv8fhx&vR'i6|LfwCylzj'iffkdmxRfhyoziffwO 'iMvSiffsSv,sSiv8fhx&vR'i H u-dmxRiffkylz|LvSfhx|LfjvRnhlzjms-vR'iGiL'|mnhj'qhiffsDvRmn v-fe||rmx-lzjvRmiakmlznhozfhqr'iffsZfhuvR'iaa$vSiffsSvsSivDiasSiffoziff|LvSiffkn*xnhjmk'fwhkmlznhopfhqrmiffsnhsvRmi~vSiffsSvDsSiv-nhjmkIvR'iffjIiLuvSxnh|LvSiffk&vR'ia|LfhxxRiffsSdfjmkmlzjmqUiL'|ynhj'qhiffsK ;hhhiL'|mnhj'qhiffsculzwlzozn xoptfhx6vSxnhlzjmlzjmq'UvRmi~$vSxnhlzjmlj'qsSiv0|LfjvRnhlzjyP;hhhkmlznhopfhqrmiffsMml||LfhxRxRiffsRd"fjykms5vSfn\vSfhvRnhofh5ffh '8iLu|mnhj'qhiffsPfhxvSxnhlzjmlzjmq&vRmi H '$D 5dmxRiffkmlz|LvSfhxmiMiffn vRrmxRi H u- $lzs8dmxRiffkml|LvSiffkfhxCiffnh|r'vSvSixnhjy|Li6lzjvRmivSiffsSv&sSivvRrms8iffjun yozlj'q6vRmiMsStesRvSiffwvSfOiMrmsSiffkfjj'i kmn vRnlpvR'fr'v$vR'iMjmiiffkfhx8ynhjmkuozn iffozozlj'q'Ifai}hixvR'ixRi&n xRi&vUf6dfsRsRlzylzozlpvRlziffsafhxvR'i8fhxlzqlzjfh)vRmls*iffn vRr'xRiCljvR'iCvSxnhlzjmlzjmqsSiv miIyxsRv*dfsRsRlylzolpvtlzs$fhxvR'i,vSxnhlzjylzj'q0sSivvSfnhozsSfO|LfjmsRlsSv$fhasSfopiffoztEnhr'vSfwMn vRl|,iffn vRr'xiffs mlzsw\ivR'fukmnhsvR'i,dfhvSiffjvRlnho)nhk'}nhjvRn qhiMvRmn vvRmi\vSxnhlzj'iffk~$PlzozoD|Lfw\diffjmsRn vSihlpaj'iff|LiffsRsRn xRthfhxyn vSi}hixj'flzsRiiL'lzsSvRslzj0vR'i H u$D UdmxRiffkml|LvRlpfjmsxlpqv hh5PjOnhopvSixjmn vRlp}hiIvSfMvSxnhlzjmlzj'qvR'iIafjOvR'iInhr'vSfwn vRlz|nhozopt0k'ixlp}hiffk H u- aiffn vRr'xRiIlzs5vSfvSxnhlzjOlpvKfjOvRmiImnhjmkuozn iffozopiffkEu- aylzopi$sSvRlzozo"vSiffsSvRlzjmqlpv5fjvR'iInhrmvSfwMn vRlz|iffn vRr'xRih mlzsKsSiff|Lfjmkw\ivR'fuklzsxRiixRxRiffkOvSfJnhs6Synhjmkuozn iffozopiffk'HvSxnhlzjmlzjmqIfhx [! u$D mlzsKwMn tOdmxRf}elzkmiInw\fhxRiCnh||ruxn vSi\w\fuk'iffo-yr'vPlzvwMn tEj'fhv$|n dmvRr'xiCvR'i\|mn xnh|LvSixlzsRvRlz|s$fhGvR'i,nhr'vSfwMn vRlz|&iffn vRr'xRi\lzjEvR'i&vSiffsSvsSivaiffsRrmopvRs*fhx*vRmiffsSiIvUfw\ivRmfekmsn xRiIdmxRiffsRiffjvSiffkljceiff|LvRlpfje '4ff3p&fi>> 9?f7A@d.2272SLU FeaturesExchange 1SLU FeaturesExchange 2autoSLUsuccessFeature PredictorExchange 1autoSLUsuccessFeature PredictorExchange 2SystemContinuesYesAutomaticFeaturesExchange 1&2PDPP(Success)>TlpqrmxRi8eUcetusSvSiffwBCn x|mlpvSiff|LvRr'xi8rmsRlzjmq&iffn vRr'xRiffsxfwautoSLUsuccesspredictor training testingBCPDP Training SetAdapt DMTransferHumanCustomerAgentvR'i$yxsRv,iLu|mnhj'qhiffsBCTestTESTPDP Test setlpqr'xRi8ean vRnfhxPsSiqw\iffjvRn vRlpfjErysRlzj'q\|LxRfsRsSH}nhozlkmn vRlpfjmiCdmxfhyopiffw lpvRrmsRlzj'q H u$D fhx$vSxnhlzjmlj'qvR'i\alzsvRyn vvR'i&snhw\i\kmn vRnzl sOrmsRiffkvSfvSxnhlzjvRmi H u$D JdmxRiffkmlz|LvSfhx 'ixRifhxRih$airysSiffkn|LxRfsRsSH}nhozlkmn vRlpfjvSiff|yjmlzer'iEnhozsSfgej'fjnhs%Snh|gHgujml"j'qMifflzssC8rmozlpghfsSgul/~ffhu )'ixitvR'ivSxnhlzjmlzj'qsSivIlzs$dn xRvRlpvRlpfj'iffkljvSfOsSivRsff 'xRii,fh5vR'iffsSiMsSivRs8n xRirmsSiffkfhxvSxnhlzjylzj'qOnhjmkvR'i\fr'xRvRfhxvSiffsSvRlzjmq' 'i&xRiffsRrmozvRsPfhxvR'i,fr'xRvRsSivn xRi\j'fhvSiffknhjmkvR'i,dmxRfu|LiffsRslzsxRidiffn vSiffkZZxfhvRn vRlzj'q0vR'isSivRsPxfw vSxnhlzjmlj'q\vSfvSiffsSvRlj'q' mlzs5xRiffsRryopvRs*lzjn6|Lfw\dyopivSi&ozlzsSv5fh)dmxiffkmlz|LvSiffk H u-fhxKvR'ivSxnhlzjmlj'qCsSiv 'i$iffn vRrmxRiffsKfhxKvR'ivSiffsSv*sSivKiL'|mnhjmqhiffsn xRik'ixlz}hiffk0t6vSxnhlzjmlzjmbq BEBE8EDfjOvR'i8'fopi$vSxnhlzjylzj'q\sSiv ylzs5dmxRfu|LiffsRs*lzsKlozozrmsSvSxn vSiffkJljODlzqr'xRi8emiCfozopflzj'qsRiff|LvRlpfjqlp}hiffs$n6yxRiffn gekmf jEfhGvR'i\lzj'dr'v*iffn vRr'xRiffsIceiff|LvRlpfjJk'iffsR|Lxlz"iffsvR'ivSxnhlzjylzj'q6nhjykExiffsRrmopvRsPfhGvR'i H u$D *dyxRiffkmlz|LvSfhxnhjmkceiff|LvRlpfj6xRidfhxRvRsPvR'i\nh||r'xnh|LtxRiffsRryopvRs5fhxvR'i8~$DGYNMPORQJQ `l Q4ff3 3fi2Zy222 S2-7M1m72B\~#Pxiff|Lfhq'xRiff|Lfhq jermwCafhxkysnhsSxRkmr'xn vRlpfj kmvRw\"n q'xRq w\fukmnhozlpv thhxRq HqhxnhwMwn xffvSiffw\dfZ~#n|Lfj'k'iffjm|LiOw\iffnhsRrmxRi0fhx\iffnh|fhvRmiffdfsRslpyopi6vRnhsSgesMvRmn v,vR'irmsSix\|LfrmozkivSxtelzjmq\vSfk'fsnhozlpiffjm|LiL|Lf}hixn qhih ljm|LfjmsRlzsRvSiffjm|Lth|LfjvSiLuvsRmlpvvSfhdmHvRnhsSg 'j iLevSvSfhdmHvRnhsSgvSfhd'|Lfj'k'iffjm|Lihykyl|Lfj'k'iffjm|Lihm|Lfj'dixRvRlzw\ih'sRnhozd"ixvRlzw\ih'nhr'vSf cu*: sRry||LiffsRsJ9~2 #}p~2#~$u~2#<BY2~#sRteson "iffoHurmvSvlzkZ'dmxRfwMdmv'xRidmxRfwMdmvm|Lfjuyxwn vRlpfjZ'sRr'Zkmlznhoxrmjmjmlzjmq;vRnhoozlpiffsjermw,r'vSvRsffIjrmw\HxRidmxRfw\dyvRs$d"ix|LiffjvHxRidyxRfw\dmvRsjermw,|LfjuxwMsdix|Liffjv|LfjuyxwMsmjermw,sRr'Zkmlnhozsdix|LiffjvsRr'ZkmlnhozsP'fopiIkmlznhozfhqr'ihGkmlznhokyr'xn vRlpfjZ'#~$Y~2#P~ElvRs|LxlpdmvrywMnhjuozn iffo/ n qhihqhiffjmkmixff rmsSixSw\fukmnhozlzvth|oziffnhjuHvRsR|Lxlpdyv|opvRs|LxlpdmvjermwCafhxkmscu*: sRry||LiffsRsDlzqr'xRiC~'iffn vRrmxRiffsfhxsSdfhghiffjkylznhopfhqr'iffskmlnhopfhqr'i|LfjmslzsSvRsGfhnCsSiffer'iffjm|LifhZiL'|ynhj'qhiffsU'ixRiPiffnh|JiLu|mnhj'qhi$|LfjmsRlzsRvRsGfhZfj'iPvRr'xjetvRmisStusSvSiffwfozopfaiffktfj'iMvRrmxjetvRmirmsSixffP~nh|kmlnhopfhqr'iMnhjmkiLu|mnhj'qhi6lsiffjm|Lfuk'iffkrmsRlj'q6vRmiMsSivIfhKh ;0iffn vRrmxRiffsIlzjlpqr'xRi6anh|iffn vRr'xRi\5nhsIifflzvR'ixInhr'vSfwMn vRlz|nhooptozfhqhqhiffktfj'iMfh5vR'i6sStesRvSiffww\fukmrmoziffsmnhjmkuon "iffoopiffktermwMnhjmsfhxCk'ixlz}hiffkxfwxn iffn vRr'xRiffs 'imnhjmk'ozn iffozopiffk&iffn vRrmxRiffsan xiPrmsSiffkMvSfCdmxfekmry|Li*n 2FBy i8ZnhjMiffsRvRlzwMn vRlpfjfh'f ?aiffozonI|oznhsRslyix|Lfrmozk0k'f,vRmn v*ynhkOnh||LiffsRsKvSf\dixRiff|Lv*lzj'fhxwMn vRlpfjZ fMsSii'ivR'ix5fr'xKxiffsRrmopvRs5|nhjOqhiffj'ixnhozlpihUi&nhozsRf6iLudixlzw\iffjvlzvRrmsRlj'qnJsRr'ysSivPfhGiffn vRr'xRiffsvRmn v$n xRiCvRnhsRglzjyk'idiffjmk'iffjvPk'iffsR|Lxlpiffklzjk'ivRnhlzo"iffozf'iffn vRrmxRiffsopfhqhqhiffktvR'isStusSvSiffwn xRir'vRlozlpiffk"iff|nhrysSiOvR'itn xRi0dmxRfukmrm|Liffknhr'vSfwMn vRlz|nhoopthnhjmkvRerms0|nhj"irmsSiffkkmrmxlzj'qxrmjvRlw\iEvSfnhopvSixOvRmi|LfrmxsSifh8vR'ikmlznhozfhqr'ih 'isStusSvSiffww\fukmrmopiffsGfhxamlz|opfhqhqlzjmq8lzj'fhxwMn vRlpfjMUnhsU|Lfozopiff|LvSiffk6aixivR'inh|LfrmsSvRlz|dmxRfu|LiffsRsSfhlx knhr'vSfwn vRlz|sSdiiff|,xiff|Lfhqjmlpixg 4-< D~g Plz||n xkml'fhxlzjh hhvR'iKsSdfhghiffj,oznhj'qrmn qhiKrmjmkmixsSvRnhjmkmlj'qCH-w\fukmrmopi8H$fhxlzj6ivanho/pffhhmnhjmkMvRmiP$lznhopfhqr'iEnhjyn qhixg iffozon8 $fhxlzjZ"ffhha~nh|w\fukmrmopinhjmk0vRmiIiffn vRrmxRiffs*fhmvRnhlj'iffk0xfw lpv*n xRi8kmiffsR|LxlpiffkJiffopfAq9 ~\lff12# 'inhr'vSfwMn vRlz|OsRd"iiff|xRiff|LfhqjmlzixEg 4- DCvRn ghiffs6nhslzj'dr'vIvR'iO|nhozopix s&sRd"iiff|nhjmk;dmxRfukmrm|Liffs&nEdfhvSiffjvRlznhozoptixxRfhxRrmoGvSxnhjysR|LxlpdmvRlzfjfh*Pmn v&lzvCiLozlpi}hiffs*vR'i8|nhozopixPsRnhlzkZ '4- Diffn vRr'xRiffsfhxiffnh|EiLu|mnhj'qhiCljm|ozrmk'i$vR'i8fr'vSdyr'vKfhvR'i8sRd"iiff|xRiff|Lfhqjmlzix RR} Z PvR'iEjermwCixfhUfhxkmsJlzjvR'iExRiff|Lfhqjmlpix0fr'vSdr'vE RR Z &~h RvR'ikmr'xn vRlpfjlzjsSiff|Lfjmkysfh5vR'ilzj'dr'vPvSfvR'iMxRiff|LfhqjmlzixJ GAn n qOfhx8vSfrm|vSfj'iJlzjuVp$p$fi>72> 9?f7A@d.22dyr'v hgI <Z vR'ilzj'dyrmvaw\fukmnhozlpv tMiLud"iff|LvSiffkt6vR'i$xRiff|LfhqjmlpixC Z Mff ! 8fj'ifhGj'fj'ihsSdiiff|vSfrm|vSfj'ihsSdiiff|9$vSfrm|vSfj'ihDvSfrm|vSfj'iL|n xkZsSdiiff|vSfrm|vSfj'iL|n xk-vSfrm|vSfjmiLkmn vSihsSdiiff|9vSfrm|vSfj'iLkyn vSihfhxj'fj'iL/jynhoHdmxRfw\dyv"nhjmkvR'i,qhxnhwwMn xrmsSiffktvR'iCxiff|Lfhqjmlpix\ Z ZhSr +\h ,g Plz||n xkml$fhxlzjZ hhi\nhozsRfJ|nhoz|ryozn vSiCn6iffn vRrmxRi&|nhoopiffkkmlp}ulzkmlj'q8vR'i8}nhozrmifhvR'i Sh/ iffn vRr'xiItJvR'i RR} Z ,~ iffn vRr'xRih4-< Diffn vRr'xRiffslzs&vRmn v\nhjt;fj'i0fhPvRmiffw wMnfft;xRi yiff|Lv,xRiff|LfhqjmlzvRlpfjmi0wMfhvRlp}n vRlzfjfhx\vR'dixRfhxwMnhjm|Li6lpvRn|Lfjm|LfwMlzvRnhjv,iLiff|Lv&fjsSdfhghiffj;oznhj'qrmn qhi0rmjmkmixsSvRnhjmkmlj'q''fhx,iLunhwMdyopihfhvR'ixPafhxRgOmnhsfryjmk h/ vSfiI|LfhxRxiffozn vSiffklzvRlzjm|LfhxRxiff|Lv*xRiff|LfhqjmlpvRlzfjPlzxsR|ixRq'lzvRwMnhjZceUixRvRsffhh 'iKjmnhw\iKfh"vR'iKqhxnhwwMn xP Z ZhSr +\h ~|Lfrmozk\nhozsRfi*n$dmxiffkmlz|LvSfhxfh~ixRxRfhxssRlzjm|Li8lzv*lzsKUiffozoZguj'f jvRmn vvR'iCozn xRqhix*vR'i8qhxnhwMwMn xlzsmvR'iCw\fhxRi8ozlzghiffopt6nhj 4-ixRxRfhx-lzsjnhkmkmlzvRlpfjZffvR'i g Z Zr +M iffn vRr'xRianhozsSfKiffjm|Lfuk'iffsZiLudiff|LvRn vRlpfjmsn fr'vrysSixr'vSvSixnhjy|Liffsn v\vRmn v,dflzjv&lzj;vR'iOkmlnhopfhqr'ihGylz|;wMnfft|LfhxRxRiffon vSiOvSfkyl"ixiffjm|Liffs\lzjvR'iOiffnhsSiOlpvRml|nhjtJfjmi8xRiff|LfhqjmlzixP|Lfrmozk|LfhxRxRiff|LvRoptrmjyk'ixsSvRnhjmk0vRmi8rmsSixffsxRiffsSdfjmsSihK$j'iIw\fhvRlz}n vRlpfjfhxPvR'iiffn vRrmxRiKlzsDvRmn v)dmxRi}ulpfrms-afhxgCsRr'qhqhiffsRvRs)vRmn vGrmsSixs-vSiffjyk,vSfIsRopf k'fj,vR'ifflpx)sSdiiff|,'iffjvR'i0sStusSvSiffwmnhs,wMlzsRrmjyk'ixsSvSfefekvR'iffw i}hf 8ffhhecu'xlpixRq'Dnhk'iha Gxlz|Lih*ffhh5vRmlzssSvSxn vSiqhtMnh|LvRrynhozopt\opiffnhkms~vSf8w\fhxRiPixRxRfhxsGslzjm|Li*vR'iPsSdiiff|Mxiff|LfhqjmlpixalsGj'fhv~vSxnhlzj'iffk\fjvRmlzs)v tdifh-sRd"iiff|Z mi iffn vRr'xRiIwMn t6nhozsSfMljmkmlz|n vSi$'iffsRlpvRn vRlzfjmsudynhrmsSiffsffefhx*ljvSixRxr'dmvRlpfjmsffml||LfrmozknhozsRfopiffnhkvSf 4-< DixxRfhxs$j;vR'i0fhvR'ixMynhjmkZ)vSfrm|vSfj'ilj'dyr'v&lzj|LfwCylzjyn vRlpfj;lpvRsSdiiff|unhs5iffjy|Lfek'iffk0etMvR'i$iffn vRr'xRi hg < Z mwMlpqv5ljm|LxRiffnhsSivR'iozlpghiffozl'ffukMfhDrmjmk'ixsSvRnhjmkmlzjmqvR'isRd"iiff|ZsRljm|LiOvR'iOvSfrm|vSfj'ilzj'dr'v&lsMrmjmnhwCylpqr'frys\lpvM|nhj|LfjmsSvSxnhlzjsSdfhghiffjonhj'qrmn qhirmjmkmixsSvRnhjmkmlj'q'l2P~2#9#~$2##q~2#n'# 'iIqhfnho-fh)vR'iCsRd"fhghiffjEoznhj'qrmn qhi&rmjmk'ixsSvRnhjmkmlzjmqH-Dw\fukmrmopiKlzsvSfClzk'iffjvRlptCmlz|,fhvRmi8ff$dfsRsRlpopiavRnhsRges~vR'i*rmsSix~ls)n vSvSiffw\dmvRlzj'qCnhjmk,iLevSxnh|LvxRfwvR'iIr'vSvSixnhjy|Li8nhjt0lpvSiffwMs5fhlzj'fhxwMn vRlzfj6vRyn vn xRixRiffopi} nhjvKvSf|Lfw\dyopivRlj'q,vRmn vKvRnhsSg"mih q'n\dymfj'ijrmwCix*lzs*j'iiffkmiffkOfhxvR'iIvRnhsSg /lpvSiiffjfhUvR'i\iffn vRrmxRiffsxRfwvR'i6ffw\fukmrmopi&xRidmxiffsSiffjvvRmiMkmlzsSvSxlzyr'vRlpfjfhxIiffnh|fhUvR'iffd"fssRlpyopi,vRnhsSgus&fhKvR'i0ff?w\fekyrmopihsI|Lfju"k'iffjm|Li6ljlpvRs8"iffolpiavRyn v8vR'iJrmsSix,lzs8n vSvSiffw\dyvRlzj'qvRmn vIvRnhsRgH$fhxlzjiv8nhoHpaffhhJi6nhozsSfljm|ozrmk'i\nOiffn vRr'xRi\vSfExRidmxRiffsRiffjvylz|vRnhsSgynhsvR'imlpqmiffsSvK|Lfjuk'iffjm|LisR|Lfhxi H H ffynhjmk0ml|JvRnhsSg0mnhs5vR'isSiff|Lfjmkylpq'iffsSv5|Lfjuk'iffjy|Li$s|LfhxRi" /H H z ynhsUUiffozonhsUvR'i} nhozr'ifhvR'iylpq'iffsSvU|Lfjuk'iffjm|Li$sR|LfhxRi\ H h< nhjmk6vR'ikmlixRiffjm|LiIlj0}nhozrmiffsKivUiiffjvR'ivSfhdnhjmkj'iLuvHvSf HvSfhd|Lfj'k'iffjm|LiIsR|LfhxiffsC < ULvRmixJiffn vRr'xRiffsJxRidyxRiffsSiffjv6fhvR'ixnhsRd"iff|LvRsJfhCvR'iff dmxRfu|LiffsRsRlzjmqfhIvR'ir'vSvSixnhjy|Lih 'iL" iffn vRr'xRilzs\nhjlzjvSxnr'vSvSixnhjm|LiwMiffnhsRr'xRiOfh$sSiffwMnhjvRlz|Okmlp}hixsRlpvth5nh||Lfhxkmlj'qvSfnvRnhsSgwMfek'iffofh)vR'i,k'fwMnhlzj;iffozozn6fhxlzjZ-ffhhIcefw\i&vRnhsSg|oznhssSiffsfe||r'xvSfhqhivR'ixIermlpvSijmn vRr'xnhozoptMlzvRmlzjJnMsRlzj'qozisSvRn vSiffwMiffjvPfhxKxRiffrmiffsSvmih q'GvR'i h fiIL 3vRnhsSg0lzsK|Lfw\dyn vRlpopi$lpvRvR'i zR vRnhsSg"r'v)lzsj'fhvG|Lfw\dyn vRlpopi5lpvR&vR'#Z,RR vRnhsSg" 'i h#HL r hLS< Ziffn vRr'xRi,w\iffnhsRr'xRiffsPvR'iCdmxRfhdfhxRvRlpfjfh)vR'i&rmvSvSixnhjm|Li&mlz|lzsP|Lf }hixRiffketvR'i&sRnhozlpiffjvqhxnhwwMn xxn qw\iffjvRs mlzsCwMnfft;lzjm|ozrmkmiMvR'iJ'fopi6fhndy'fj'i6fhx,|n xk;jermwCix&lp*lzv8fu||r'xs&lpvRmljnxn qw\iffjv 'i hy} [ IL iffn vRr'xRiIlzsKnhjOljvSixSrmvSvSixnhjm|Li8w\iffnhsr'xRi$fh-vRmiiLevSiffjv*fhn&smlpvUfh|LfjvSiLev*n Un tJxRfwvR'i|r'xRxiffjvUvRnhsSgfu|rms'|nhrmsSiffkJetvR'i$n dmdiffn xnhjm|Li$fh-snhozlpiffjvadymxnhsSiffsavRmn vn xRi8ljm|Lfw\dyn vRlpopiPPlpvROlpvmnh||Lfhxkmlj'qMvSfn\vRnhsRg0wMfek'iffofhDvR'i8kmfwMnhlzjZjnhkmkylpvRlpfjZsRlzwlzozn xOvSfvR'i5nfftUi;|nho|rmozn vSiffkvRmi iffn vRr'xRihCai;j'fhxwMnhozlzivR'ih#HL r hLS< Z nhjyk H h< iffn vRr'xRiffsPtOkmlz}elzkylzj'q,vR'iffw et vSf6dmxRfukmrm|LivR'i h \ nhjyk < \ iffn vRr'xRiffs 'i nhjmk;vR'i p \ nhjmk LLfiffn vRr'xRiffsn xiIrmsSiffkOfjmozt6fhx*dmxRiffkylz|LvRlzj'q H u$DVp$Tfi2Zy222 S2-7M1m72mi5wMfhvRlp}n vRlzfj\fhx)vRmiffsSiJiffn vRr'xiffsGlzsvSf8wMn ghi*rysSiKfh"lj'fhxwMn vRlpfj&vRmn v)vR'iPffOw\fukmrmopinhs6nhsnxiffsRrmopv\fh$dmxRfu|LiffsRsRlj'qvR'ifrmvSdyr'vMfh#4-<DnhjmkvR'iE|r'xRxRiffjvkmlzs|Lfr'xsSi|LfjvSiLevmfhxiL'nhw\dyopihfhxCr'vSvSixnhjy|LiffsCvRyn vCfozopf vR'iyxsSv8rmvSvSixnhjm|Lih)vR'iO?w\fukmrmopiMguj'fsIyn v8vRnhsSglpvOiffozlpi}hiffs0vRmi|nhozopixls0vSxRtelj'qvSf|Lfw\dyozivSih 'i [ iffn vRr'xilzjm|LfhxRdfhxn vSiffsvRmlzsguj'f oziffk'qhifhKvR'iJkmlzsR|LfrmxsSiMmlzsRvSfhxRthlpvRvR'iJw\fhvRlp} n vRlpfjvRmn vClpKlpvCn dmdiffn xsIvRmn v&vR'iJ|nhozopixmnhs*|mnhj'qhiffkE'ixwMlzjykZuvR'iffjOvR'iCffw\fukmrmoziwMn tOmnff}hi&wMlzsRrmjyk'ixsSvSfefekJnhjr'vSvSixnhjm|Lih~22}p~2#~$2 'iJrmjm|LvRlpfj;fhvRmi0$lznhozfhqr'iOEnhjmn qhix6lzs&vSfvRn ghiEnhs\lzj'dyr'vCvR'ifr'vSdyrmvfhGvR'iMw\fukmrmozihk'iff|lzkmi8mn vPvRnhsSgvRmiCrmsSix$lzsPvSxRtulzj'qvSf0nh||Lfw\dyolzsRZ"k'iff|lzk'iCmn vvR'iJsStesRvSiffwlzoo)sRnfftj'iLuv)nhjmkrmdkyn vSi\vR'i6kmlsR|Lfr'xsSiMylzsSvSfhxRtP"iffoozn fhxlzjZaffhh 'i$lznhopfhqr'i,nhjmn qhixIk'iff|lzk'iffsP'ivRmixlpviffozlpi}hiffsvR'ixRi,lzsPnJsRlzjmqopiCrmjynhw8ylzqr'frms*vRnhsRgvRmn v$vR'irmsSixPlzs5vSxRtulzj'q\vSfnh||Lfw\dozlzsRZ'nhjmk'f vSfxRiffsSfop}hi8nhjtOnhw8lpqrmlpv th'iffn vRrmxRiffsKynhsSiffk0fjOlj'fhxwMn vRlpfj6vRmn vKvR'i$lznhopfhqr'inhjmn qhixopfhqhqhiffkOn fr'vKlpvRsKk'iff|lsRlpfjmsafhxiffn vRr'xRiffs*xidmxRiffsSiffjvRlzj'q\vR'iCfj'qhflzj'q6mlzsSvSfhxRt6fh)vR'i8kmlnhopfhqr'iIwMlpqv*iIrmsSirmodmxiffkmlz|LvSfhxsKfh~ffixRxRfhxs8fhx&vRnhsSgnhlzozr'xihcefw\i6fh*vR'idfhvSiffjvRlznhozoptljvSixRiffsRvRlzj'q$lznhopfhqrmiJnhjmn qhix\i}hiffjvRs&n xlzsSikmr'ivSfJopf |Lfjuk'iffjy|Li8opi}hiffozsKPmlz|opiffnhkOvR'i&lnhopfhqr'i8nhjmn qhixvSf Sr vR'i8rmsRix*fhxh< Gl lzvRsrmjmk'ixsRvRnhjmkmlzj'q'$ xidmxRfw\dmv$wMlpqv$i&nJ} n xlznhjvfhavR'i\sRnhw\i\er'iffsSvRlpfjvRmn v5nhsnhsSghiffk"ifhxRihfhxUlpvG|Lfrmozk\ljm|ozrmk'i5nhsSgulzj'qvR'iPrmsSixGvSf8|'fefsSi*ivUiiffjMv afCvRnhsSges~vRmn v~mn }hiiiffjnhsRsRlzqj'iffksRlzwMlzon x|Lfjuk'iffjy|Liffs$tvRmiMff;w\fukmrmopih$'fhxiL'nhw\dyopihZlzjEvR'i\kmlznhopfhqrmi&lzjlpqr'xRi\vR'i&sStesRvSiffw rmvSvSixnhjm|Li,lzjc ;|LfrmjvRsnhsn6xRidmxRfw\dyviff|nhrmsSi&lpvPlzsPn} n xlznhjvfh)vRmi&er'iffsSvRlpfjElzjr'vSvSixnhjy|Li&c'emi&iffn vRr'xRiffs8vRmn vUi\iLevSxnh|LvCxfwvR'iM$lznhopfhqr'iMnhjmn qhixCn xi\vR'i\vRnhsSgHvted"i6ozn iffo/p mfsSisSivfh&}nhor'iffsOlzjm|ozryk'in}nhozrmivSf?lzjmkmlz|n vSimiffjvR'isStusSvSiffw mnhklzjmsRru{J|lpiffjvlzj'fhxwMn vRlzfj0vSfk'iff|lzk'i$fjnsSdiff|l|vRnhsSgHvted"ihvR'iIr'vSvSixnhjy|Li8lzk0lpvRylzjJvR'i8kmlznhozfhqr'iM / /vR'ijmnhw\i*fhZvR'idmxRfw\dmv~dyoznffthiffkvSfCvRmirmsSix$ h ynhjmkMP'ivR'ixGvR'iPvtedifhdmxRfw\dyvGUnhsUnxRidmxfw\dmv h "n\|LfjuxwMn vRlpfj h< Gl yfhx*n\sRr'Zkmlznhopfhqrmi*dmxRfw\dyv$n\sRrmd"ixsSivafh-vR'ixRidmxfw\dmvRs)nhjmk\|LfjuxwMn vRlpfj,dmxfw\dmvRsK =h miP L iffn vRr'xRi*lzs)lzjvSiffjmk'iffk&vSf8|n dyvRr'xRivR'iJnh|Lv,vRmn v,sSfw\iJvRnhsSgus,wMnfft"iJmn xk'ixCvRmnhj;fhvR'ixs 'iE / / iffn vRr'xiJlzs&w\fhvRlp} n vSiffk;tvR'ilk'iffn0vRmn vIvR'i6opiffj'qhvRfh5vR'ikylznhopfhqr'iMwMn t"i6lzw\dfhxRvRnhjvdfsRsRlpyoztlzj|LfwCylzjmn vRlpfjlpvRfhvR'ix$iffn vRr'xRiffsozlpghi6 p 'iCkmlp"ixRiffjvdmxRfw\dmvPiffn vRrmxRiffs$fhxlzjylpvRlznhodyxRfw\dmvRs"xRidmxfw\dmvRs|LfjuyxwMn vRlpfjdmxRfwMdmvRs,nhjmksRr'Zkmlznhozfhqr'idmxfw\dmvRs\n xRiOw\fhvRlp} n vSiffketxiffsRrmopvRs,lzjmkylz|n vRlzj'qEvRmn vxRidmxfw\dmvRs~nhjyk|LfjuyxwMn vRlpfj\dmxfw\dmvRs~n xixrmsSvSxn vRlj'qfhxU|nhozopixsanhjmkMvRyn va|nhozopixs~n xRiozlpghiffopt&vSftdixn xRvRl|rmozn vSiP'iffjvRmitmnff}hivSf,xRidiffn vUvR'iffwMsSiffoz}hiffsumlz|xRiffsrmopvRsUlzj 4D DixxRfhxs$Hcu'xlpixRqivnho/p-ffhhei}hfI-ffhhenhopghixffInhwMwOy-lpvRwMnhjZy hhhnmiEkmlzs|Lfr'xsSiylzsSvSfhxRtiffn vRr'xRiffs0lzjm|ormk'iffkxrmjyjmlzj'qvRnhozolpiffsMfhx6vRmijermwC"ix6fhIxRidmxfw\dmvRsR r RDjermwCixPfh~|Lfj'yxwMn vRlpfjEdmxRfwMdmvRs\ h< Gl Rnhjmkjryw8ixfhasRr'Zkmlpnhopfhqr'iCdmxRfw\dyvRs8 E/ RvRyn vPmnhkOiiffjdyoznffthiffkifhxRi8vR'i8r'vSvSixnhjy|LiC|r'xRxiffjvRoptJifflzj'qdmxRfu|LiffsRsSiffkPnhsOUiffozo$nhs0xrmjmjylzj'qdix|LiffjvRn qhiffs Ly R Sr cM LSy < Gl c& Ly=h R 'i8rmsRiIfhxrmjmjmlj'qCvRnhoozlpiffs*nhjmkdix|LiffjvRn qhiffs$lzs*ynhsSiffkfjdmxRi}ulpfrmsKUfhxRgOsRr'qhqhiffsRvRlzj'qvRmn v~jmfhxwMnhozlpiffk&iffn vRr'xRiffsGn xiw\fhxRi*ozlzghiffoptIvSfIdmxfekmry|LiUqhiffjmixnhozlpiffk,dmxiffkmlz|LvSfhxs*-lpvRwMnhjZnhozghixffiffn xjmsDffhhiffn vRr'xRi,nff} nhlzozn opiIfhx /LZ dmxfhyopiffwMn vRlz|8kmlznhopfhqr'iffsPlzs h h/vRmn vlsKj'fhvnff} nhlzozn opifhxPlzjmlpvRlznhosSiqwMiffjvRsfh-vR'iCkmlznhopfhqr'ihY~2Y,~=l''' sw\iffjvRlpfj'iffkCn "f}hih vR'iGiffn vRr'xRiffsfhyvRnhlzj'iffkI}ulznKmnhjykuozn iffozozlzjmqan xRiUrmsSiffkvSf&dmxRf }ulzk'i*+n 2FBy i8Mn qnhlzjmsSvamlz|MvSf&|Lfw\dyn xRivR'idixRfhxwMnhjy|Li*fhZvR'irmozoztCnhr'vSfwMn vRl|iffnvRr'xRiffsff miamnhjmk'ozn iffozopiffkiffn vRr'xRiffslzjm|ormk'i~ermwMnhjCvSxnhjmsR|LxlpdmvRsfhyiffnh|\rmsSixr'vSvSixnhjy|LinsSivfh$sRiffwMnhjvRl|ozn iffozs,vRmn vn xi|opfsSiffoptxRiffon vSiffkvSfvR'isRtesSvSiffw vRnhsSgHvted"iozn iffozs [Vp$ 4fi>72> 9?f7A@d.22p "n qhi6 <Z 5nhjmk0qhiffjmkmixC ZL 5fhDvR'iIrmsRixff'vR'iInh|LvRrmnho-w\fekynhozlpvt6fh-vRmi8rmsSix*r'vSvSixnhjm|Lie Mff ! fjmifh Gj'fhvRylzj'q'usSdiiff|ZuvSfrm|vSfj'ihsSdiiff|9vSfry|vSfj'ihyj'fjusRd"iiff|mnhjmk0n|opiffnhj'iffk&vSxnhjysR|LxlpdmvlpvR&j'fjuHUfhxkCjmflzsSialj'fhxwMn vRlpfjIxiffw\f }hiffk ffp G'xRfwvR'iffsRiaiffnvRr'xRiffsffUi|nho|rmozn vSiffk6vUf,kmixlp}hiffk6iffn vRr'xiffs 'iyxsSvaUnhsUvR'ijrmwCix~fhUfhxkmsUlzjvR'i|oziffnhj'iffkvSxnhjms|Lxlpdmv8 ff! ,~ Sn qnhlzjfjvR'i&nhsRsRrmwMdmvRlpfj0vRmn vr'vSvSixnhjm|Li&opiffj'qhvRlzsPsSvSxRfj'qozt|LfhxRxRiffon vSiffklpvR4- D;nhjmk;ixRxRfhxs 'i,sSiff|Lfjmkk'ixlz}hiffkEiffn vRr'xRi,5nhs$ynhsSiffkfj|nhoz|ryozn vRlzj'q'ivRmixPvR'i [ L wMn vR|'iffs$vR'i6 L xfwvR'i,$lznhopfhqr'i,nhjmn qhix u$D Rmls5iffn vRr'xiIlzs*k'iffsR|LxlpiffkJljOk'ivRnhlzolzj0vRmiIj'iLevPsSiff|LvRlpfjZjvR'i,iLedixlw\iffjvRsff"vRmi\iffn vRr'xiffslzjDlzqr'xRiZiLu|ormkmlzj'qJvR'i\mnhjmk'ozn iffozopiffkiffn vRr'xRiffsffn xRixRiixRxRiffkCvSfnhsDvR'42F 4E2 6Ciffn vRr'xRi5sSiv 'iaiLedixlzwMiffjvRsvSiffsSv)'f ;aiffoowMlsRrmjmk'ixsSvRnhjmkmlzjmqs|nhj\i*lzk'iffjvRlyiffk,nhjmk,P'ivR'ix)dmxRfhopiffwMn vRlz|5kmlznhozfhqr'iffs)|nhjMi5dmxRiffkml|LvSiffk\rmsRlzj'qvR'42F 4E2 6iffn vRr'xRiffs)iI|Lfw\dn xRiPvRmiPdixRfhxwMnhjm|LifhvR')42F 4E2 6Jiffn vRr'xRi$sSiv5vSf,vR'irmoomiffn vRr'xRi$sSivlzjm|ormkmlzj'qCvR'iImnhjmk'ozn iffozopiffk6iffn vRr'xiffsnhjmk0vSfMvRmiIdixRfhxwMnhjm|Li$fhvR'42F 4E2 6iffn vRr'xiIsSivlpvR8nhjmkIlzvR'fr'vZvR'i H u- Ziffn vRr'xihDlpqr'xi~Kqlp}hiffsDnhjIiL'nhw\dyopi~fhevRmi~iffjm|Lfukmlzj'qKfhsSfw\ifhZvR'inhr'vSfwMn vRl|*iffn vRr'xRiffsGfhx~vRmisSiff|LfjmkiLu|mnhj'qhifhvR'w \x 4Dykmlnhopfhqr'i*lzjMlpqrmxRC;e'idyxRiLm Mk'iffsRlzqjmn vSiffs*vR'iCsSiff|LfjmkOiL'|mnhjmqhihai&kmlzsR|rmssKsSi}hixnhofhvR'i8iffn vRr'xiffs*} nhozr'iffs'ixRivSfiffjmsRrmxRiOvRmn vvRmixRiffnhk'ixJrmjmk'ixsRvRnhjmkms,vR'i5nfftljmlz|vR'iiffn vRr'xRiffs6n xRiErysSiffkZjr'vSvSixnhjy|Li,c'lzjlpqr'xRb;eyvR'i&sStesRvSiffw sRn tes8 p H 0L[e ?P[uL ujlpqrmxRiMeZvRmlzs$lzsiffjm|Lfuk'iffktsSi}hixnhoiffn vRr'xRiffs 'i&iffn vRr'xi h qlp}hiffs$vR'i\jmnhwMi&fhvRmn vPdmxRfw\dmvh=11rrZ 'iIiffn vRr'xRi Sr sSdiff|lyiffs5vRmn vc'\lzs*nxRidmxRfwMdmvynsSiff|Lfjmkn vSvSiffw\dmvIetvR'isStusSvSiffwvSfEiffozlz|lpvnkmiffsR|LxlpdmvRlzfjfhUvRmiM|nhozopixffs8dmxRfhyopiffw 'i\iffn vRrmxRi< Gl sSdiff|liffs*vRmn vIc'Mlsj'fhvn6|LfjuxwMn vRlpfjdmxRfw\dmv 'i8iffn vRr'xRi = h sSdiff|lyiffsvRmn vGc'PlzjmlpvRlzn vSiffs-n$sRr'ZkmlznhopfhqrmiGnhjmk =h iffjy|Lfek'iffs-vRmn vvRmlzsDlzsvR'i~xsSv-sr'Zkmlznhopfhqr'isSf0n xffmlopi z LSL E/ $iffjm|Lfuk'iffs$vRmn vfr'vfhUnhozoDvR'i\sStusSvSiffwr'vSvSixnhjy|LiffsIsSf0n xfhvR'iffw lzjylpvRlzn vSisRr'Zkmlznhozfhqr'iffss\w\iffjvRlpfj'iffkiffn xozlzixff)aiOn xRinhosSflzjvSixiffsSvSiffklzjqhiffj'ixnhozlpfflj'qEfrmx\dmxRfhyopiffwn vRlz|6kylznhopfhqr'idmxRiffkylz|LvSfhxMvSffhvR'ixJsStusSvSiffwMs rmsff~UivSxnhlzj'iffk BEBE8=DrysRlzj'qfjmopt;iffn vRr'xRiffsMvRyn vn xRifhvRnhr'vSfwMn vRl|nhozoptEnh|ermlpxn yopi,kmr'xlzjmqxrmjvRlzw\i,nhjmklzjyk'idiffjmk'iffjvfh~vRmiCf vRnhsSg" mi,sr'ysSivfhKiffn vRr'xRiffsCxRfwlpqr'xRiO0vRmn v8yv8vRmlsIrynhozl|n vRlpfjn xRi6ljlpqr'xRi0eOi6xRiix8vSfvR'iffwnhsvR'N42Ft24-< 5 iy8EB=2iffn vRr'xRiMsSivGunhwMdyopiffs$fh5iffn vRrmxRiffsvRmn v8n xij'fhvvRnhsSglzjmk'idiffjmkmiffjvlzjm|ormk'i S} Z Zr +M c5 L c r nhjmkOvR'iCmnhjmkuozn iffozoziffkiffn vRr'xRiffs`l ^p^ `, Q ff Q _~b?h^iJqhfnhoKfhPvR'i H '$D IdmxRiffkylz|LvSfhx\lzs&vSflzk'iffjvRlpth)fhx,iffnh|iL'|ynhj'qhihaP'ivR'ix,fhx'j'fhv$vR'iMsStusSvSiffw|LfhxRxiff|LvRoptryjmk'ixsSvSfefukvR'iMrysSixffs$r'vSvSixnhjm|Lih\sw\iffjvRlpfj'iffkn f }hihP'iffjvR'ikmlznhozfhqr'iffsKUixRi8vSxnhjysR|Lxlpiffk0et0ermwMnhjysn vSixPvR'iCkmn vRn|Lfozoziff|LvRlpfj5nhsP|LfwMdyopivSiffkZmvRmiCermwMnhjozn iffopixsKjmfhv*fjmoptJvSxnhjmsR|Lxlpiffk0vR'i8rmsSixsyr'vSvSixnhjy|Liffsyyrmv*nhozsSfozn iffozoziffk6iffnh|ErmvSvSixnhjm|Li8PlpvRnsSiffwMnhjvRlz|&|n vSiqhfhxRtxidmxRiffsSiffjvRlzj'q6vR'i8vRnhsSgvRmn vPvRmi&rmsRix5nhsnhsRgelzjmq vSfJd"ixfhxw mlzsozn iffols6|nhozoziffkvR'i [ L 'iEsRtesSvSiffwsJ$lznhozfhqr'inhjmn qhixk'iff|lk'iffsnhw\fjmqsRi}hixnhokmlixRiffjvKtedfhvR'iffsSiffsKdmxfekmry|Liffk6etJvR'iCwMfekmryopih'nhjmkOopfhqs*lpvRsKted"fhvRmiffsRlzs5n fr'vKmn v5vRnhsSgvR'irmsSixK5nhs*nhsSgulzj'q vSf\dixRfhxwOuvR'i$lznhopfhqrmiIEnhjmn qhix s*tedfhvR'iffsRlzs5lzsUguj'f PjOnhsKvR'ip iEkmlzsSvRlzjmqrmlzsRfr'xM|onhsRsSiffs\fh$sSdfhghiffjoznhj'qrmn qhiryjmk'ixsSvRnhjykmlzj'qEfr'vR|Lfw\iffsMnhsSiffkfj|Lfw\dn xlzj'q\vR'i [ \h p L vR'i, L nhjmkxRiff|LfhqjmlpvRlpfjxRiffsRrmopvRs5fhxP|n xknhjmkOvSiffopid'fj'ijermw8ixsffD67FDD8962-|LfhxRxiff|LvRoptlzk'iffjvRlyiffkvR'i&vRnhsSgEnhjmknhjtkmlpqlpvsSvSxlzjmqsUixRi,nhozsSfVp$ Vfi2Zy222 S2-7M1m72}(f\gg{P'&Z&1&==Pff N}(}(}{ H.{ %AB'&!5A !%5.'&1! }(f\gg{( le{}\(z(}{ H.{ %AB'&{. {(}{f{{ "2A;<A!5';}{g{l{.{}.<({f =5.fi5;<}(<f\}1}<ge}<g}..<({f}{ =g{1}<\}({ o<gf\} / ///}({f}}(H<g{ go\<{ / ///}({f{}}g{ g}.(fz . / ///}({f}{<{<E A95( 5A}({f}(f<{<. A;<A!}({f}{( ze(f<}9<.g (}({fz}Hzg .(f<}9<.g / C}({fz}f\}5!;}({f}{}( leg{g /}({f{}lg .g{g /}({f}/}\ \{o} %:B=}({f}}{}( l\ \{o} g (}({f}{}}zg \ \{o} g / C}({f}}{} . <.( l1{{g ((}({f}(g{\ \5pffK"5z fi}({f}}{}.lz{ ( \5!fin=! %}<{(H{(.g pf< ;!!nn?(n&=!=P+} \} (.g p ;9n<(#&9!==P+Dlzqr'xRiIea'iffn vRrmxRiIiffjm|Lfukmlzj'q\fhxceiff|Lfjyk )'|mnhjmqhiIfhw\x 4Dy( //{* *!(!(/////!(/////////(.<kmlznhopfhqrmihB\~#Pxiff|Lfhq'-xRiff|Lfhq jermwCafhxkms-nhsRxSkmr'xn vRlzfjZk'vRw\n q'xRq wMfekmnholpvtnh|LvRrmnhoGw\fukmnhozlzvtfhvRmi8rmsSixrmvSvSixnhjm|LihZ~#snhozlpiffjm|Li|Lf}hixn qhihClzjy|LfjmsRlzsSvSiffjy|Lth|LfjvSiLevsmlpvvSfhd |Lfjuk'iffjy|Lih$kyl|Lfj'k'iffjm|LihnhrmvSf cu: sRrm||LiffsRsffJ9P~#~2 #}p~2#~$rmvSvSixnhjm|Li8et0r'vSvSixnhjm|Lih~rmvSvlzkZ'xRidmxfw\dmvm|LfjuyxwMn vRlpfjZmsRrmkylznhoxrmjmjmlzjmq;vRnhoozlpiffsjermw,r'vSvRsffIjrmw\HxRidmxRfw\dyvRs$d"ix|LiffjvHxRidyxRfw\dmvRsjermw,|LfjuxwMsdix|Liffjv|LfjuyxwMsmjermw,sRr'Zkmlnhozsdix|LiffjvsRr'Zkmlnhozsukmlznhokmrmxn vRlpfjlpqr'xRi8e~r'vSfwMn vRl|vRnhsSglzjmk'idiffjmk'iffjv5iffn vRrmxRiffs*nff} nhlzozn opiIn v*xrmjvRlzw\ih|LfhxRxRiff|LvRozt;xiff|LfhqjmlpiffkZ,/DBh4D2 4fi4E26 E|LfhxRxRiff|LvRozt;xiff|Lfhqjmlpiffk?vR'ivRnhsSgyr'vvR'ixRi5nhsnhjixRxfhxMlzjxRiff|Lfhqjmlpfflj'qn|nhozozlj'q|n xkjermw8ix\fhxnd'fj'ijermw8ixffI;+D 4E26kmlkj'fhv&|LfhxRxRiff|LvRoptlk'iffjvRlztvR'i0rmsSixffs8vRnhsSg"F/D86FejGCvR'iJxRiff|Lfhqjmlzix,kylzkj'fhv&qhivnhjtElzj'dr'v*vSf0dmxRfu|LiffsRs$nhjmksSf0vR'iw\fukmrmoziCkmlzkj'fhvifflpvR'ixff mlzs|nhjn xlzsSi&ifflpvR'ix$iff|nhrmsSivR'i0rmsSix&kmlzkjmfhv&sRn tnhjtvRmlj'qfhx&iff|nhrmsSivRmi6xRiff|Lfhqjylpix,Unhs,j'fhv&ozlzsSvSiffjmlj'q'iffjvR'i0rmsSixVp$ 1fi>72> 9?f7A@d.22sSdfhghih 'i'D767FDD8962J|oznhsRsUnh||LfrmjvRs5fhx*u,;hez afhZvR'iPiL'|ynhj'qhiffsKlzjMvRmiP|LfhxRdyrys 'iDBh4D2 4fi 4E26 nh||LfrmjvRsGfhxK\uMDfhvR'i5iLu|mnhj'qhiffs 'i%D 4E26 |onhsRs)nh||LfrmjvRsfhx~mff6/ uM)fhvR'iiLu|mnhj'qhiffsUnhjmkMvR'F{D8967Fej|onhsRs~nh||LfrmjvRsafhx5hfi;6fi;ez MGfhvR'iiL'|mnhj'qhiffsffmi H u- MdmxRiffkmlz|LvSfhx0lzs6vSxnhlzj'iffkrmsRlj'qrmozoptnhr'vSfwMn vRl|Eiffn vRr'xRiffsff 'iffsSiiffn vRr'xRiffsn xRiIvR'i&P|LfrmsRvRlzp| k 4- Diffn vRr'xiffsZffiffn vRr'xRiffsnhjmk$lznhozfhqr'iCnhjmn qhix$nhjmk$lzsR|LfrmxsSilzsSvSfhxRtJiffn vRrmxRiffsmqlp}hiffjlzjOlpqr'xRiCJaPnhjmk'ozn iffozopiffk6iffn vRr'xiffs*UixRi8j'fhvrysSiffkZiMi} nhozrmn vSi\vRmi\fr'xRHUn H u- |oznhsRslyix$txRidfhxRvRlzjmqJnh||r'xnh|Lth-dmxiff|lzsRlpfjZxRiff|nhozonhjmkOvR'i8|n vSiqhfhxlpffn vRlpfj|Lfj'rmsRlpfjOwMn vSxl" mlzsK|onhsRsRlyix*lsKvSxnhlzj'iffkfjnhozoZvRmiIiffn vRrmxRiffsfhx*vR'iImfopi$vSxnhlzjmlzjmq,sRivynhjmkOvR'iffjvSiffsSvSiffkfjOvRmi8'iffozkuHfrmvKvSiffsSvsSivn yopiEsRrmwMwn xlpiffs\vR'iEf }hixnhooPnh||r'xnh|LtxRiffsRrmopvRsMfhvR'iEsStusSvSiffw vSxnhlzj'iffkfjvR'iE'fopivSxnhlzjylzj'qsSivnhjmkvSiffsRvSiffkfjvR'ivSiffsRvsSivMk'iffsR|Lxlpiffk;ljceiff|LvRlpfj ;e mi0yxsSv\ozlzjmiJfh n yopixRidmxiffsSiffjvRsCvR'i0nh||r'xnh|LtxRfwnhop5nfftusCqrmiffsRsRlzj'qEvR'i6wn fhxlzvt|oznhssJgF{D8967FjDGvRmls8lzsCvR'iG94- 8m i8n qnhlzjmsSvIPmlz|vR'ifhvR'ixCxRiffsRrmozvRsIsR'frmok"i6|Lfw\dyn xRiffkZ 'i6sSiff|Lfjmkxf Iozn iffozopiffk4 2F 4E2 6ysRmf svR'iCnh||r'xnh|LtynhsSiffkEfjrmslzj'qnhozovR'i8iffn vRr'xRiffsnff} nhlzozn yozi8xRfw vR'i&sStusSvSiffww\fukmrmopiffsff ylzs*|oznhsRslyix|nhjlzk'iffjvRlptOffixxRfhxs*ivSvSixvRynhjvR'iCynhsSiffozlj'ihUjiLudixSlzw\iffjv5nhsxrmjOvSf0sSii,lp)vR'i&|LxRfsRsH} nhozlzkmn vRlzfjw\ivR'fukk'iffsR|Lxlpiffkljceiff|LvRlpfj ;d"ixfhxws*UfhxsSivRmnhjrmsRlzj'q0vR'i'fopikyn vRnOfjvR'iJsRnhw\iMvSiffsRvCsSiv mlzs$iLudixlzw\iffjvIsR'faiffkvRmn vIvRmixRi5nhsozlpvSvRozi$ozfsRsKfhnh||r'xnh|LtO'iffjOrysRlzj'q\|LxRfsRsSH}nhozlkmn vRlpfjuM~#N BG=D4 m88 wMnSfhxlpv tO|oznhsRs42F 4E2 6Pfi#~=fie; zuz&n yopiM *iffsRrmozvRs5fhxk'ivSiff|LvRlzj'qJff~xRxRfhxsKrmslzj'qDBEB=8EDlpqr'xiJJsR'fs$sSfw\i&vSfhdd"ixfhxwlzj'q\xrmoziffsvRmn v)D B=BE8EDoziffn xjmsP'iffjEqlp}hiffjnhozovRmiCiffnvRr'xRiffsff 'iffsSi$xrmoziffsUkylpxRiff|LvRoptMxiyiff|LvKvR'iIrmsSirmozjmiffsRs~fh-vR'iCiffn vRr'xiffs~PfhvSiIvRmn vKsSfw\ifhDvR'ixrmoziffsDrysSi4D D6iffn vRr'xiffsGlzj&|Lfw8yljmn vRlpfj,lpvR\Jiffn vRr'xiffsGsRrm|&nhsK LL\M GGxRi}ulpfrmssSvRrykmlpiffsnhopghixKivKnho/pm hhh| Umn }hiInhozsSf,sR'f Pj0ffEiffn vRr'xiffs5vSfCi$rmsSirmo/Di$ynhkJnhosSf&ted"fhvRmiffsRlpiffkvRmn vKiffn vRr'xRiffsKxRfwvR'iI$lznhozfhqr'iEnhjmn qhixnhjmk0vR'ikmlzs|Lfr'xsSimlzsRvSfhxRtwMlpqv5i$rysSiryodyxRiffkmlz|vSfhxs$fhUff;ixRxRfhxsZ'f Ui}hixvR'iffsSi,iffn vRr'xRiffs$xn xRiffoztn dmdiffn xlzjvRmiCxryopiffsPlpvRvRmi&iL'|LidmvRlpfjfhp mlzslsPlzjnh||Lfhxkmnhjy|Li&PlpvRdyxRi}elzfrmsiLudixlzw\iffjvRsPmlz|EsRmf vRmn v$vR'iffsSi,iffn vRrmxRiffsk'fj'fhvMnhkyksRlpqjml"|nhjvRoptvSfvR'iOdixRfhxwMnhjm|LiOfhvR'iE Fi iffn vRr'xisSivEnhopghix6ivnho/phhh|iKnhozsSfxRidfhxRv-dmxRiff|lzsRlzfjCnhjmkCxRiff|nhozofhxDiffnh|\|n vSiqhfhxRt&fjCvRmiU'iffokuHfr'vvSiffsRvsRiv 'i~xRiffsrmopvRsn xRiIsRmf jOlzj n yopiffs*Mnhjmk ;e n yopiI,sR'fsKvRmn vKvR'iC|oznhsRsRl"|n vRlpfj0nh||r'xnh|Lt0xn vSi8lzsKn,xiffsRrmopvfhnImlzqMxn vSiPfh|LfhxxRiff|LvU|onhsRsRl|n vRlzfjMfhx~vR'CD67FDD8692JnhjmkF/D86Fej|oznhsRsen vavR'iP|LfsSvafhn0opf Uix$xn vSi,fh#x 4E26 nhjy^k DBh4D2 4 4E276 mlzsPlzsdmxRfhyn optOkmr'i&vSfJvRmiCnh|Lv$vRmn vvR'ixRiCn xRiiUixiL'nhw\dyoziffsKfh-vRmiffsSi8|n vSiqhfhxlpiffslzj0vR'i8vSxnhlzjmlzjmq,sRivjsSfw\iMsRlpvRryn vRlpfjmsfj'i\wMlpqv$j'fhvIj'iiffkvSfkmlzsSvRlj'qrmlzsR"iv aiiffjvR'i\kmlixRiffjv$wMlzsrmjmk'ixSsSvRnhjmkylzj'q|n vSiqhfhxlpiffsUieF{D8967FejaD C 4E26 nhjmk DBh4D2 4fi4E26 'ixRifhxRih*iLudixlw\iffjvRsGUixRidixRfhxw\iffkMvRmn v~|Lfozozn dsSiffkMvR'iffsR;dmxfhyopiffwMn vRlz|K|n vSiqhfhxlpiffs5lzjvSf8fj'i|n vSiqhfhxRtEgVp$"fi2Zy222 S2-7M1m72PZ-) *5k'vRwMn q xRiff|Lfhq|LfjvRnhlzjys6 xRfwMxiff|LfhqsStesSozn iffojermw8Ufhxkms # L \H[P-) K^Uk'vRw\n q nhsRxSkmr'xn vRlzfj"!'#xRiff|Lfhq HqhxnhwMwMn xsStesSozn iff5lzoozw\ivR'fukuHqhxnhw6#xRiff|Lfhq&|LfjvRnhlzjmsahw8tu$xRiff|Lfhq jermwCafhxkys% # L \H[v 'sRnhopdixRvRlzw\(u&vSfhd'|Lfju"k'iffjm|L"uhu # l & MhH [sSdfhghiffjukylpqlp&v 'sRnhopdixRvRlzw\(u&|Lfj'dixRvRlzw\)u # z , MhH [sSdfhghiffjukylpqlp&v 'vSfhd'|Lfjuk'iffjy|L"uh ;h z , MhH [sSdfhghiffjukylpqlp&vsnhopdixRvRlzw\)usStusozn iff*5P5'l &sSdfhghiffjukmlpqlpMhH [j !r'vSvl,k ! sStusozn iff.ZD)K^Ukmlp|Lfju"k'iffjm|LinhsSxSkyr'xn vRlpf+u# z, MhH [lpqr'xRiMuPsRr'sSiv~fhxrmopiffsUopiffn xj'iffk6t 'iffj6qlp}hiffjJvR'i$nhr'vSfwMn vRlz|iffn vRr'xRiffs5fhxUkmivSixSwMlzjmlzjmq H u-/~$BD6FDD8962F{D8967FejC 4E26DBh4D2 4 fi 4E26u~2'uhe#h0|1quuiff|nhozoZfhx iffsRvsSivrmslzj'q\PrmvSfwMn vRlz|iffn vRr'xRiffsn yopi8eUGxRiff|lsRlpfj0nhjmk67FDD8692Z mlzsIxRiffsRrmopvSiffklzjnxRiff|LfhqjmlpvRlpfjnh||r'xnh|Ltfhhe 0GnEhe lzw\dmxf }hiffw\iffjv8f}hixvR'i$ynhsSiffolzj'ifhh; J'Pmlz|0lzs5vRmidix|LiffjvRn qhiIfheD67FDD896O2 iL'|mnhj'qhiffsff 'i$dmxRiff|lsRlpfj0nhjmkxRiff|nhozowMn vSxl0lzsKqlp}hiffjlj n yozi'D67FDD8962F{D8967Fj4E26DBh4D2 4 fi 4E26D67FDDD8692F/D86Fej;fi;uh;4E26uhhffhDBh4D2 4n yozi3;eUUfj'rmsRlpfj0n vSxlOfhx iffsRvsSivrmslzj'q\PrmvSfwMn vRlz|iffn vRr'xRiffsVp$ 2fi>72/> 9?f7A@d.221~2'~$q67FDD869267FDD8692uh;ez0zheJ'iff|nhozoZfhx iffsRvsSivrmslzj'q\PrmvSfwMn vRlz|iffn vRr'xRiffsn yopi'UGxRiff|lsRlpfj0nhjmk1Y^t Q hb? X bH^` Q Q _~b h^iqhfnho-fhvR'i8alzsKvSf6dmxRiffkml|Lv'fjvR'iInhsRlzs5fhGlzj'fhxwMn vRlzfj0vRmn vlpvynhsKiffn xoptOlzj0vR'iCkmlzn'opfhqr'ihhP'ivR'ixDfhxjmfhvDvRmiUsStusSvSiffwlozohiUn opi~vSf|Lfw\dyozivSiUvRmiUrmsRixffsDvRnhsSg mi~fr'vSdyrmvD|oznhssSiffsn xRi&ynhsSiffkEfjvR'iCfr'x$kmlznhopfhqrmiC|n vSiqhfhxlpiffskmiffsR|Lxlpiffkn f}hih$Pf Ui}hixffnhs 4iejBw \x 4Dynhjmk 24- 5e<4D8n xRi,vSxRiffn vSiffknhs$iffermlp} nhopiffjvRoptdmxRfhopiffwMn vRlz|CtEvR'i\sStusSvSiffwOnhsIlzoozrmsSvSxn vSiffkElzjlpqr'xRieuvR'iffsS;&|n vSiqhfhxlpiffs*n xi$|Lfoozn dysSiffk0lzjvSbf B=D7FGy8 4E2 6DPfhvSivRmn v5vRmlzsU|n vSiqhfhxlpffn vRlpfjlzs*ljm'ixRiffjvRopt6jmflzsStJ"iff|nhrysSi8lpvls*lzw\dfsRsRlzyopivSfguj'f vR'iIxRiffnhoxRiffnhsSfjmst0n|nhoopixmnhj'qsPr'dfhxnlzffn xkvRn ghiffsMf}hixvR'i|nhozoH mi0|nhoopixMwMnfftmnhjmqrmd"iff|nhrysSisR'iOlzs,xrmsSvSxn vSiffklpvRvR'iJsStesRvSiffwO)fhx&s'i6wMn tsRlzw\doptkylzsRozlpghiMnhrmvSfwMn vRlpfjZ)fhx,'ixC|mlzozkwMnfftmnff}hi0sSvRn xRvSiffk|LxRtulzj'q'culzwlzozn xopthhfjmilpffn xkMwMnfft6mnff}hi$opf |Lfjukmiffjm|LiPlzjMvR'iPsStusSvSiffwOsUn ylzolpvt,vSf8xiff|Lf }hixKxRfw ixRxfhxsnhjmk,rmsSiKn$|LfjmsSix}n vRlp}hi*n dydmxRfnh|,vRyn vDxiffsRrmopvRslzjCvRn gelj'q$f }hix~wMnhjtC|nhoozs mlzozianhj'fhvR'ix)Plpffn xkwMn tEi\w\fhxRi,lzoozlzj'qMvSfozivvRmiMsStesRvSiffwvSxRtEvSfOxiff|Lf }hixff\Pi}hixRvR'iffopiffsRsffai\vRn ghivR'iffsSiMermwMnhjnh|LvRlpfjmsnhsnMermwMnhjOozn iffozolzj'q8fhvR'iffsRiI|nhozozs*nhsKdyxRfhyopiffwMn vRl| a$lp}hiffjOvRmls5ylzjmn xRtJ|oznhsRsRlp|n vRlpfjZn dmdmxfff'lzwMn vSiffopA;h;fh-vRmiI|nhozozsKlzj0vR'i|LfhxRdrms5fh-hhkmlznhopfhqrmiffsKn xRBEDFGfi8 4E2 60nhjykhn xR24-< 5ff676=8"2 4350z= 1\~9\Apn~2 #60zn qmlsKsSiff|LvRlpfjOdmxiffsSiffjvRs*xRiffsRrmopvRs5fhx*dmxiffkmlz|LvRlzj'q,dmxfhyopiffwMn vRlz|$kmlnhopfhqr'iffs n gelj'qMlzjvSfMnh||LfrmjvPvR'inh|LvCvRmn v,nEdmxRfhyopiffwn vRlz|kmlnhopfhqr'iw&rmsSv&iMdmxRiffkml|LvSiffkn v,ndflzjv8lzjvR'i0kmlznhopfhqr'i6'ixRi6vR'isStusSvSiffw |nhjkmf6sSfw\ivRylzj'q6n fr'vlpv"ai,|Lfw\dyn xRi8 RR /ff/ nh||r'xnh|LtEn vSixmn }elj'q6sSiiffjfjmoztvR'ixsSv*iL'|mnhjmqhi8fhxvR'iyxsRvKvUf6iL'|mnhjmqhiffslzvR Ly nh||r'xnh|Ltn vSix$mnff}ulzj'q6sSiiffjvR'i5'foziakmlznhozfhqr'ihDmfhx)iffnh|\fhmvRmiffsSiKsRlpvRrmn vRlpfjys aiKnhozsSf$|Lfw\dyn xiUxiffsRrmopvRsDfhxDvRm42F 4E2 6iffn vRr'xRi,sSivMnhsk'iffsR|Lxlpiffkiffn xozlpixKlpvRnhjmkElpvR'fr'vPvR'i H '$D *iffn vRr'xRi\nhjmkElpvRvR'i8ynhjmkuozn iffozopiffk6iffn vRr'xRi\u-n yopiCMsRrmwMwMn xlpiffs5vR'iIf}hixnhozonh||rmxnh|LtOxRiffsRrmozvRs 'ivRmxRii8|LfozrmwjmsKdmxRiffsRiffjv*xiffsRrmopvRs5fhx)'|ynhj'qhiJ 7)'|ynhj'qhiffs,ffInhjykf}hixvRmi8'foziCkmlznhozfhqr'ih 'i8yxsSv*xf qlp}hiffsvR'i8ynhsRiffozlzj'ixRiffsRryopvCPmlz|;xRidyxRiffsSiffjvRsCvRmiJdyxRiffkmlz|LvRlpfjnh||r'xnh|LtxRfwnhop5nfftus\qr'iffsRsRlj'qEvRmi0wn fhxlzvt|onhsRsculzjy|Liz fh5vR'ikylznhopfhqr'iffsIn xi2fiD4 )567698 &kylznhopfhqr'iffsai|nhj;nh|ylpi}hiJz nh||r'xnh|LtxRfwsRlzw\dopt0qr'iffsRsRlzjmqA24 )5 e6698 fhxiffnh|kmlznhopfhqr'ih 'i,sSiff|LfjmkxRfqlp}hiffsxRiffsRryopvRsPrysRlzj'qfjmoptMnhrmvSfwMn vRlz|iffn vRrmxRiffsuyr'valpvR'fr'vUvR'i H u$D Giffn vRr'xRih miPvRmlzxkMxRfrmsSiffsUvR'isRnhw\iMnhrmvSfwMn vRlz|\iffn vRr'xRiffs$yrmv$nhkykmslzj H u$D mlzsiffn vRrmxRiMlzsfhmvRnhlzj'iffkfhxIfhvRvR'ivSxnhlzjmlj'q8nhjmk6vR'ivSiffsSvUsRivurysRlzj'qIvRmi|LxRfssH}nholzkmn vRlpfjJw\ivR'fuk6kylzsR|rmsRsRiffkMlzjOceiff|LvRlpfjA;e 'ifr'xRvRnhjyk,yvRMxRfs~sRmf xRiffsRrmopvRs~rmsRlzj'qvRmisRr'ysRivGfhZiffn vRrmxRiffsGvRmn vUn xRifhvRrmooptCnhr'vSfwn vRlz|nhjmkOvRnhsRglzjyk'idiffjmk'iffjv5nhsk'iffsR|LxlpiffkOlzjcuiff|LvRlpfjO'Vp$!fi2Zy222 S2-7M1m72mi0nhrmvSfwMn vRlz|JxRiffsRrmozvRsCqlz}hiffjlzj;xRf n xRiOsRlpqjyl|nhjvRoptmlpq'ix,etndynhlpxiffkvHvSiffsRv\vRmnhjvR'i,ynhsSiffolzj'i&fhxInhozoDvR'xii,sRiff|LvRlpfjms$fh~vRmiMkmlznhopfhqr'iOk'7hhev8ez $u;hek'7hheDv8Ie$uh' km4 hhM8v ,< ;e 'y9$uh'f s0nhjyksR'f nh||r'xnh|Lt?lzw\dmxRf}hiffw\iffjvRsqnhlzjmiffketvR'iEnhkykmlpvRlpfjfhIynhjmkuozn iffozopiffkiffn vRr'xRiffs miffsSixRf sqlp}hin 2FBy i8n qnhljmsSvOml|vSf|Lfw\dn xRivR'ixRiffsRryopvRsOlzjxRf Pse;eGnhjmkeWiffsRrmopvRs,rmsRlj'qEnhozoUvR'iOnhr'vSfwn vRlz|Jiffn vRr'xiffs,dyozrmsCvR'iOmnhjmkuon "iffoopiffku-n xRi0qlp}hiffjlzj;xRfejvR'iffsSi0iLedixlw\iffjvRsff)vR'iOmnhjmkuozn iffozoziffku- Iiffn vRr'xilzs,rmsSiffkfhx6vSxnhljmlzj'qnhjykvSiffsSvRlj'q'5fw\dyn xlzjmqvRmlzs6xRiffsRrmozvlpvRvR'isSiff|LfjmkxRf sR'fsJvRmn v0lpfj'imnhkndixRiff|LvJdyxRiffkmlz|LvSfhx0fh H u- 6lzj?vR'ivSxnhlzjylzj'qnhjyk?vRmivSiffsRvsSivPvRmiffjvRmlzsiffn vRr'xRi\Ufrmozklzjm|LxRiffnhsRi,nh||rmxnh|Lttefhx )'|mnhj'qhixRfw uz vSfE eMtfh)x Gu|mnhj'qhiffs\ffIxRfw ez vSfhe#hMnhjmketEe fhxvRmiCmfopi&kylznhopfhqr'i0/ vSfheM miffsSialzjy|LxRiffnhsSiffsDn xRiUslpqjml|nhjvetInPdynhlpxRiffkCvHvSiffsSv*k'7 hheh8v ez h$uhh' ek'7 hhev8ez$u ;hekm4 hhey8v e#m$uh'UfwMdyn xlzj'qvRmixRiffsRryopv~lzjxRf IlzvR\vR'ixiffsRrmopv~lj\xRf ;Is'f savRmn vavR'i H u-dmxRiffkylz|LvSfhxGvRmn vGUimn }hi*vSxnhlzjmiffkM|nhjlzwMdmxRf }hiKdixRfhxwMnhjy|Lihyr'vG|Lfrmok\dfsRsRlpyoztI'iffopdw\fhxiKlpvRkmlixRiffjvvSxnhlzjmlj'qOw\ivR'fukmsMk'iffnhozopthvR'iMxRiffsRryopvlzjxRf;e-fhx8nhr'vSfwn vRlz|Miffn vRr'xRiffs8dyozrms Hu- sRmfrmozkEnhozoiv aiiffjvRmi,yqr'xRiffslzjxRfs80nhjmke-nhjmki,|ozfsSixIvSfOvR'i\xRiffsrmopvRslzj;xRfelpvRJ)'|mnhj'qhiffsffIeanhkmkylzj'q H '$D 8xRiffsrmopvRs,lzj;nhjlzjm|LxRiffnhsSi0fh& zml|lsCj'fhv,sRlpqjyl|nhjv6|Lfw\dyn xRi0xRfs,nhjmJk ;'fhx )'|mnhj'qhi6fjmopthB=BE8EDk'feiffs,j'fhvrmsSi$vR'i H u- Giffn vRr'xiIlzj6lzvRs5xrmopiffsSiv5nhjmk0k'feiffs5j'fhvKtelziffozk6nhj0lzwMdmxRf }hiffwMiffjvKf}hix*vR'isStusSvSiffw vSxnhlzj'iffkfjmoptOfjEvR'iCnhr'vSfwn vRlz|8iffn vRr'xRiffsff 'i&sStesRvSiffwvSxnhlj'iffkfjEvR'i8P'fopiCkylznhopfhqr'ilpvRnhr'vSfwMn vRlz|iffn vRr'xiffsGdyozrys H '$D )nhozsSf8k'feiffs~jmfhv~tulpiffozk\nhjlw\dmxRf}hiffw\iffjv~f }hix5vR'isStusSvSiffw vSxnhlzj'iffk0lpvRmfr'v H '$D:9;<=;<?>4D5 iy8=BE8Eiy8Ei2A@8E4E2"D8"*fsaCnhjmkJqlp}hiPvR'i*xRiffsRryopvRs~rmslzj'qvR'i'4"27Ft72fi4D 5iy8=B=26iffn vRr'xiPsSivUk'iffsR|Lxlpiffk\lzjDlzqr'xRiElpvR'frmvCnhjmk;lpvRvR'i H u$D Iiffn vRr'xRihGxiffsSdiff|LvRlp}hiffopth 'iffsSiJxRiffsRryopvRsCn xi0slpqjmlm|nhjvRoptEn f }hi\vRmi&nhsSiffozlzj'i,rmsRlj'q6n0dynhlzxRiffkvHvSiffsRvlpvR^)'|ynhj'qhiffsMffIJqlp}ulzj'qJnhjlzjm|LxRiffnhsRi&fh< ;ez k'7 hhe-8v IeeD9d $uh' IrysRlzj'q 24- 5iy8EB=2iffn vRr'xRiffsIPlpvR H u$D Oat|Lfw\dyn xlzj'qxf sPJnhjykefj'i&fhysSixR}hiffs$nhjlzjm|LxRiffnhsRi&lzjvR'+4"27Ft24- 5iy8EB=2iffn vRr'xRiffssSiv'iffjvR'iiffn vRr'xRi H u$D Glzsanhkmk'iffkJrmsRlzj'q Gu|mnhj'qhiffs$ffI8nhjmkP'fopikmlnhopfhqr'ih 'ilzjm|LxRiffnhsSi8fh'x )'|mnhj'qhiffs,ffIMsR'f PsnMvSxiffjmkk'7 hhe8v , #$uZmixRiffnhs*vR'i,lzjm|LxiffnhsSi$fhxKvR'i$mfopikmlznhopfhqr'i$lzs5sSvRn vRlzsRvRlz|nhozoptJsRlpqjml"|nhjvUtJn,dynhlpxRiffk6vHvSiffsSvCkm4 hhey8v #;eu$uh ;opvR'fr'qevRm32fi4-< 5 iy8EB92Oiffn vRr'xRiIsSivRs*n xi8n\sRr'ysRivUfhDvR'fsSiiffn vRr'xRiffsrmsSiffkOlzjJxRf ;emlpvlzsUdfsRsRlpopifhxKvR'iffwvSf\dixRfhxw"ivSvSixKiff|nhrmsRivRm32fi4-< 5 iy8EB920iffn vRrmxRiffs*n xRiw\fhxRiqhiffjmixnho/nhjmk"iff|nhrysS3B=BE8EDrmsRiffsnMqhxiiffk'tnhopqhfhxlpvRyw vSf6kmlsR|Lf }hix$lpvRs*xrmopiIsSivRs*mfh'x Gu|mnhj'qhiffs&ffIevR'iMlzjy|LxRiffnhsSi\xRfwxRf;JvSfxRf "fhvRfhUml|rmsSi H u- SlzsjmfhvIsRlpqjml"|nhjvUfw\dn xlzj'qCxRf s*&nhjmkJ'mj'ifflzvR'ix5fhml|JrmsSi H u$D efjmi$sRiiffsKn&sozlpqvUk'iqhxnhkmnvRlpfjljExiffsRrmopvRs$fhxIvR'i\mfopi\kmlznhopfhqr'iMrysRlzj'q 2fi4D 5iy8=B=2iffn vRr'xRiffsMPf Ui}hixffvR'iMlzjy|LxRiffnhsSixRfwxRf Ps~vSfCxRfw ez vSf8 uH ;fhax Gu|mnhj'qhiffsPffI$lzs)sSvRn vRlzsRvRlz|nhozopt8slpqjml|nhjv*k'7 hhev8euD$u mlzs$sR'fsvRmn v8rysRlzj'q H u$D $lzj|LfwCylzjmn vRlpfjPlpvRvR'iMsSivIfh24- 5iy8EB=2iffn vRr'xiffs*dmxRfukmrm|LiffsnMsSvRn vRlzsSvRl|nhozopt0sRlpqjml"|nhjvKlzjm|LxiffnhsSi8lzjOnh||r'xnh|LtOf }hix$nMsSivfhnhr'vSfwMn vRl|iffn vRrmxRiffs*vRmn vPk'fiffsj'fhvlzjm|ormk'ivRmlzs5iffn vRr'xRihVp$&fi>uB;72> 9?f7A@d.22~#UnhsRiffozlzj'i4"27Fj'f H u-4"27FU H u$D4"27Ft24-<5 iy8EB=2;j'f H u-4"27Ft24-< 5 iy8EB=2 H u-4"27FUu-4g 42F nhjmkuozn iffozopiffk"CD#~2#2E3zuzuzehzCDff~,3GFIHzezeeuH ;he#y#z'h;eu #n yozi8e~P||rmxnh|LtxRiffsRrmozvRs5fhxPdmxRiffkmlz|LvRlj'qCdyxRfhyopiffwMn vRl|kylznhopfhqr'iffs/~$Bfi2 4D 5)67698B=D7FGy8 4E2 6JNfi#6;h;e60zn\qu #6ffeH ;J1~2'hez&;u 60ze6he6iff|nhozoZlzvR)'|mnhj'qhiJPrmvSfwMn vRlz|I'iffn vRrmxRiffsn yozi8e~GxRiff|lsRlpfjOnhjmkmiwMnhlzj\dr'xRdfsSi5fhZvR'iffsSi*iLudixlzw\iffjvRs~ls)vSfCk'ivSixwMlzj'iKmivR'ixanIkylznhopfhqr'ilsD hyh!dmxRfhopiffwMn vRlz| vR'ixRifhxRiMrmslzj'qJvR'i,'fopi,kmlznhopfhqrmi,lsjmfhvIrmsSirmo-ljn0k'tujmnhwMl|CsStusSvSiffwO+:sRlzj'q)'|ynhj'qhiffsffIOdmxRfukmrm|Liffs$nh||r'xn vSi6xRiffsRrmopvRsnhjykafrmokiffjmn yopi\vR'iMsRtesSvSiffwvSfnhkmn dmv8ljEfhxk'ixvSf|Lfw\dopivSiIvR'i8kylznhopfhqr'ilzj0vR'iCn dmdmxRfhdmxlzn vSiwMnhjmj'ixff:9;<=;KML4iyS4G=8yfi8=y@8=4E2D8*fPlzj&vRn yopi*qlp}hiffsvR'iKxiffsRrmopvRsrmsRlj'qynhjmkuozn iffozopiffkCnhjmk,nhr'vSfwMn vRlz|5iffn vRr'xRiffs~lzjm|ozrmkylzj'q*fhvRu- Knhjyk H u- Ut|Lfw\dn xlzj'qMxf sMnhjyk"fj'i,|nhjsRiiCvRmn vPvR'ixRi,lzsj fhvI}hixtw&rm|vSfi,qnhlzj'iffketnhkmkmlzj'qJvR'iMfhvRmixCmnhjmk'ozn iffozopiffkEiffn vRr'xiffsqlp}hiffjljDlzqr'xRi6'vSfOvR'iMmnhjykuozn iffozopiffkEnhjmku$D iffn vRr'xRiMsRiv\$jyoptvR'i\lzjm|LxiffnhsSi,fhxGu|mnhj'qhi&xRfwevSfhz lzssRlzqjml|nhjvMk'4 Ihhe8v eH ;eD$umfhx8vR'i\mfopi\r'vSvSixnhjm|LiMvRmixRiMlzsnh|LvRrmnhozoztJnMkmiqhxnhkmn vRlpfjOfhxRiffsrmopvRs5xRfwhevSfJu #hJ2 HN0z1q~2#u~2''i8d"ixfhxwnhjm|Li8fh)vR'i&sStusSvSiffwvRyn vrmsRiffsnhr'vSfwMn vRl|8iffn vRr'xRiffs\lzjm|ormkmlzj'q H u-fhxIvR'i,yxsRvIr'vSvSixnhjm|Lils$qlp}hiffjlzj n yopie ylzs$sStesRvSiffw mnhsnhjf}hixnhozoanh||r'xnh|Ltfh5he0'iffsRi6xRiffsrmopvRs&sR'f vRmn vaqlp}hiffj;vR'iJyxsSvCiLu|mnhj'qhihavR'i0xrmopiffsSivCdmxRiffkml|LvRsCvRyn v0ffeH;fhPvR'ikmlznhozfhqr'iffsMlozoKidmxfhyopiffwMn vRlz| 5ylzop;h;fhIvR'iffw nh|LvRrmnhozoptPlzozoKih vRmidmxRfhopiffwMn vRlz|kmlznhozfhqr'iffs lpv-|nhj&dmxRiffkylz|Lv ;u fh'vR'iffwOG$jm|LiUlpvdyxRiffkmlz|LvRsvRmn vDnkmlznhozfhqr'iGlzoohi~dmxRfhopiffwMn vRlz|lpv*lzsK|LfhxxRiff|Lvhe fh-vRmiIvRlzw\ihx )'|ynhj'qhiffsffI&lzsUsRrmw,miPdixRfhxwMnhjm|LiPfhvR'i$sStusSvSiffwvRmn vUrysSiffs5nhr'vSfwMn vRlz|iffn vRr'xRiffsUfhwMn xlziffklzj n yopi 'iffsSi0xRiffsrmopvRs,sR'f vRmn v~qlp}hiffjvRmi0yxsSv&vUfiL'|mnhj'qhiffsffavRmlsCxrmopiffsSivdmxRiffkylz|LvRsUvRmn v* fhvR'ikmlnhopfhqr'iffsUlzozoiPdyxRfhyopiffwMn vRl| ePmlzop);h;fhvR'iffw nh|LvRrmnhooptlozomihvR'iKdmxRfhyoziffwMn vRlz|5kmlznhopfhqrmiffslpvG|nhj\dmxiffkmlz|LvDefh"vR'iffwOG$jm|Li*lpvdmxiffkmlz|LvRsvRmn v~nkylznhopfhqr'ilzooZi8dmxRfhopiffwMn vRlz| lpv$lzs|LfhxRxiff|LvI e#hfhGvR'i&vRlzw\ih mlzsP|oznhsRsRlixPmnhs$nhjlzw\dmxf }hiffw\iffjvPfhVp$ 3fi2Zy222 S2-7M1m72sRnhozlpiffjm|LiL|Lf}hixn qhiOu#h( nhsSxSkyr'xn vRlpfjP!u (i nhr'vSf cu:*sRry||LiffsRsQieF# p \:*srm||LiffsR5C 4E276 R sStusozn iffoA ZD) K^U? nhsSxRnhr'vSf cukmr'xn vRlpfSj ! ;ezff p Mhu# hSsRnhozlpiffjm|LiL|Lf}hixn qhi?u#T iHxRiff|Lfhq|LfjvRnhljmsisnhozlpiffjm|LiL|Lf}hixn qh?S'iffopdUinhsSxSkmrmxn vRlpfOj e h # z Mh/uhVnhr'vSf c':sRrm||LiffsRW4E26 (sStusozn iff%iHvSfhd'|Lfj'k'iffjm|L,5P5'# p \uh kml"|Lfjuk'iffjy|LVuuff|Lfozoziff|L)v uh ;hiHvSfhd'|Lfjuk'iffjy|LXnhsSxSkyr'xn vRlpfSj ! eH ;h&kmlznhopHfhxSwM"!u p MhD8967Fej-lpqr'xRiMh Psr'ysSiv0fh,xrmopiffs0opiffn xj'iffket BEBE8EDk'ivSixwMlzjylzj'q,dmxRfhyoziffwMn vRlz|$kmlznhopfhqrmiffs'iffjqlz}hiffjvR'inhr'vSfwn vRlz|iffn vRr'xRiffsOfhxHvSfhd'|Lfjukmiffjm|LiYuhh)i nhsSxRkmr'xn vRlpfjP!u ) nhrmvSf cu:sRrm||LiffsRsieF# p \:*srm||LiffsR"C 4E26 &HxRiff|Lfhq jermwCafhxkmsQh-i nhsRxSkmr'xn vRlzfj!nhr'vSf cueh p MhuZnhsSxSkyr'xn vRlpf[j ! u Zlzjy|LfjmsRlzsSvSiffjy|L,! uh\sRnholpiffjm|LiL|Lf }hixn qhTinhsSxSkyr'xn vRlpfAj ;eh%ljm|LfjmsRlzsRvSiffjm|L6! uzff # p \uhhSsRnhozlpiffjm|LiL|Lf}hixn qh?uhhTiHxRiff|Lfhq|LfjvRnhljmsisnhozlpiffjm|LiL|Lf}hixn qh?S'iffopdUinhsSxSkmrmxn vRlpfOj H ;h # z Mh/uh%kml"|Lfjukmiffjm|L"uuff%HxRiff|Lfhq6|LfjvRnhlzjmsMSwCtu'iHvSfhd'|Lfj'k'iffjm|LVinhsSxSkyr'xn vRlpfAj ! # z Mh/uh"inhsSxRkmr'xn vRlpf]j !uVnhsRxSkmr'xn vRlzf]j !eH ;hisRnhozlziffjm|LiL|Lf }hixn qh+# zMh/D8967Fej-lpqr'xRiMffePsRrmysSivfh~xrmoziffsoziffn xj'iffkt^D BEB=8EDP'iffjqlp}hiffjvR'iN2fi4Dk'ivSixwMlzjylzj'q,dmxRfhyoziffwMn vRlz|$kmlznhopfhqrmiffs5iy8=B=2iffn vRr'xRiffs$fhxhljExiff|nhozo)nhjmkh;eljEdyxRiff|lzsRlpfj"fhxInhjf }hixnhozoGlzw\dyxRf }hiffw\iffjvIlzjnh||r'xnh|Ltfh5ef }hix$rmsRlj'q,vR'i$yxsSvKiL'|ynhj'qhiCnhopfjmih2 _^`CD~=A#Bq'~aM#sRr'ysRiv*fhvR'i8xryopiffs5xfw vR'i8sRtesSvSiffw vRmn vrmsSiffs*nhr'vSfwn vRlz|Iiffn vRr'xRiffsPfhx')'|mnhjmqhiffsCffIn xRiqlp}hiffj6lzj\lpqr'xRiIh&xRf ;evRn yopia$j'iKfhysSix}n vRlpfjxfwvR'iffsSited"fhvRmiffsSiffs~lzsvRmi|oznhsRsRlpyixffsdmxRiixRiffjm|Li$fhx*vR'i iffn vRr'xRif }hixPvR'i$iffn vRrmxRifhxKvRmiIjrmwCix5fh-Ufhxkms5xRiff|LfhqjylpiffkRR Z &~h R$j'iKUfrmozk\iLudiff|Lv~opfj'qhixUr'vSvSixnhjm|Liffs~vSf8i*w\fhxRikyl{6|rmopvyr'v)vR'ioziffn xj'iffkxrmoziffsSivRs,lzjmkmlz|n vSi0vRmn v\kmrmxn vRlpfjlzs,nivSvSixMw\iffnhsRr'xRi0fhr'vSvSixnhjm|LiopiffjmqhvRvRmnhjvR'iOjryw8ixfhUafhxkys\Pj'fhvRmixIfhysSixR} n vRlpfjls$vR'iMrmsSirmozj'iffssPfhUvR'iJff|Lfju"k'iffjm|LiMsR|LfhxRiffs8nhjmkvR'i6ffVTz$fi>/~$Bfi2 4D 5)67698B=D7FGy8 4E2 672JNfi#6;h;e6> 9?f7A@d.220zn\qu0u01~2''6e60zez&e#iff|nhozolpvR)'|ynhj'qhiffI\r'vSfwMn vRl|I'iffn vRr'xRiffsn yopiC~~xRiff|lzsRlpfjOnhjyk *Rs nhozlziffjm|LiL|Lf }hixn qhiClzjdyxRiffkmlz|LvRlzjmqIdmxRfhyoziffwMn vRlz|kmlznhopfhqr'iffsff 'iffsSiiffn vRr'xiffsUsRiiffwvSf&dyxRf }ulzk'iPqhffukqhiffj'ixnhoDlzjmkylz|n vSfhxsKfhvR'i&sStesRvSiffwOsPsrm||LiffsRslzjOxRiff|LfhqjmlzvRlpfjnhjmkErmjmk'ixsSvRnhjmkmlzjmq' 'i8nh|LvPvRmn vvR'iUwMnhlzjIfu|rmsfh'vR'iaxrmopiffslzsk'ivSiff|LvRlj'q 4-< DMnhjmk,ixRxRfhxs-nhjmkIvRyn v-j'fj'iafh'vR'ity "iffynff}ulpfhxsn xRi8rysSiffknhsKdmxiffkmlz|LvSfhxs*nhosSfMlzjmkml|n vSiffsKvRmn vylzjnhozoZozlpghiffozl'ffukZevR'lzsKdixRfhxwMlj'q&nhsaiffoonhslpvI|nhjZ-qlp}hiffjvRmij'flzsStlzj'dyrmvvRyn v8lpvIlzsqhivSvRlj'qxRfw 4-< Dnhjmk)MjnhopvSixjmn vRlz}hiM}elzi lzsvRmn vKv afrmvSvSixnhjm|Liffsn xiIj'fhvKiffj'fr'q0vSf\dmxf }ulzk'iw\iffnhjmlzjmqhrmo"kmlznhozfhqr'i$iffn vRr'xiffs*sRrm|nhsK|LfrmjvRsnhjmkOdix|LiffjvRn qhiffs*fhxRidyxRfw\dmvRsm|Lfj'yxwMn vRlpfjysuivR| pjmi$|nhjOsRiivRyn vKvR'i$vSfhdOvUf\xrmopiffs5rmsSi H u$D 'iyxsRvaxryopiynhslz|nhozoptsRvRn vSiffs$vRmn vOlpvR'ixilzs0j'f;xRiff|LfhqjmlzvRlpfjfhx0vR'isSiff|LfjmkiL'|mnhj'qhinhs0dyxRiffkmlz|LvSiffk?tvR'i H u-S6vR'iffjvR'ikylznhopfhqr'ilzozonhlo/ 'isSiff|Lfjmkxrmopilzs0w\fhxRilzjvSixRiffsSvRlzj'qnhsOlpvOsSvRn vSiffslznwMlzsrmjmk'ixsRvRnhjmkmlzj'qEmnhs,iiffjdmxRiffkmlz|LvSiffkfhx\vR'isSiff|LfjykiLu|mnhj'qhinhjykvR'isStusSvSiffwozn iffo5lzsb(cd)e @ f)ghinhjmkvR'iMrmvSvSixnhjm|Lilzs$opfjmqJvRmiffjvR'i\sStusSvSiffwlzoonhlzo/CjfhvR'ixUfhxkmsffvR'isStusSvSiffwxRiffer'iffjvRoptwlzsRlzjvSixRdmxRivRsZozfj'q*r'vSvSixnhjm|Liffs-nhs b(c8d(e @$f)ghixRiffsRrmopvRlj'qKlzj$vRnhsSg$nhlozr'xRihlpqr'xi0ffOqlp}hiffsIn0sRr'ysRivfhUvR'i\xryopiffsSiv$fhxvRm2fi4-< 5 iy8EB92iffn vRr'xRiMsSivfhx)'|mnhjmqhiffsff Ie*$j'iI|nhjEsSii8nslzwMlzozn xlpvtMiv aiiffjvRmlzsKxryopiffsSiv*nhjmkOvRmiIfj'iIqlp}hiffjElzjlpqr'xiMh ylzsKlzskmr'iCvSf6vRmi8nh|LvPvRmn v'iffjEnhozo-vR'iCnhr'vSfwn vRlz|8iffn vRr'xRiffs$n xRi,nff} nhlzozn opih9D BEBE8EDynhsPn6vSiffjmk'iffjm|LtvSfdlz|RgJfr'vvRmi8w\fhxRiIqhiffjmixnhovRnhsSglzjmkmid"iffjyk'iffjvKfjmiffsmlpvRvR'iIiL'|LidmvRlpfjfh5 L afj'i|Lfw\dyn xiffs*vR'i&sSiff|LfjmkxrmopiIlzj0fhvROqr'xRiffs'fj'i&|nhjsSiiCvRmn Cv BEBE8EDrmsRiffs RR Z &~h $nhsnMsRrmysSvRlpvRr'vSi$fhx*vR'iIvRnhsRgsSdiff|l"|$iffn vRr'xi\ p2 kj/2ql~2'n~E}pZml|Y~2#9~ l'1q~2'#'#}p#Zs~w\iffjvRlpfj'iffk6n "f}hihenhj6nhopvSixjmn vRlz}hivSf8vSxnhlzjmlzj'q$vR'i~$fjMvR'inhrmvSfwMn vRlz|nhozopt\k'ixlp}hiffk Hu- aiffn vRr'xRi8lzs*vSfMvSxnhlzjlzvKfjOvR'i8mnhjykuozn iffozopiffku$D Umlzozi$sRvRlzozo"vSiffsSvRlzj'q6lpvKfjvR'i\nhr'vSfwMn vRl|,iffn vRr'xih mlsPsSiff|Lfjykw\ivR'fuklsPxiixRxiffkEvSfnhsOSynhjmkuozn iffozopiffk'HvSxnhlzjmlzjmqMnhjmkvR'i6xRiffsRrmopvRlj'qOiffn vRrmxRi6lzs [ u- ylzsIwMn tdmxRf }ulzk'i6nw\fhxRiJnh||r'xn vSiOw\fuk'iffo)yrmv8lpvwMn tj'fhvP|n dyvRr'xRi&vR'iC|mn xnh|LvSixlzsRvRlz|sfh)vR'iCnhr'vSfwn vRlz|&iffn vRr'xiClzjvR'i8vSiffsSv$sSiv n yozi&qlp}hiffsxRiffsRryopvRs~fhx5vR'i$vUfMw\ivR'fukms~$j'i$|nhjOsSii$xRfwvRmlzsUvRn yopivRmn v5vR'ixRilzsUn,sRozlpqveljmsRlpqjmlp|nhjvlzjm|LxiffnhsSiKlzj,nh||r'xnh|Lt,fhRx Gu|mnhj'qhiIKnhjmk,vRmiUP'fopiKkmlznhopfhqrmiUrmslzj'qvR'iKmnhjmkuozn iffozoziffkuHvSxnhlzjmlj'qw\ivR'fukZ)Pf Ui}hixffuvR'ivSfhvRnhozoztMnhr'vSfwMn vSiffkJw\ivR'fukMtulpiffozkmsGn8ivSvSix~xRiffsRryopvPH e|Lfw\dyn xRiffkvSfh M-fhx )'|mnhj'qhiffsKff8ehmlz|Cnhs)w\iffjvRlpfj'iffk,n f }hihlzsvRmiUw\fsRvlw\dfhxRvRnhjv-xRiffsRrmozvfhxDvRmiffsSiiLud"ixlzw\iffjvRs mlslzjm|LxiffnhsSiCsRmf snvSxiffjmkr'vlzsj'fhvPslpqjml|nhjv&km4 hhe8v , euh'i8jmnhoxRf fhGvR'iCvRn yopi8qlz}hiffsPvRmi8xRiffsRryopvRsrmslzj'qMvR'i,mnhjmk'ozn iffozopiffk0iffn vRr'xRiM'$D *lzjfhvROvR'ivSxnhljmlzj'q\nhjmkOvSiffsRvRlzj'qMnhjmkls5vRn ghiffjEnhsKvRmiIvSfhdyozlzjmixiffsRrmopvVTfi2Zy222 S2-~#7M1mCD#~2#2+35nhsSiffozlzj'i42F42FW [ u$D42FW H u-42FWu-zuzue72CDff~2#2+3F6Hzezhehe#z'n yopi8e||r'xnh|Lt xiffsRrmopvRsOlzjy|ozrmkmlzjmq[ u$D 0k'ixlp}hiffkrysRlzj'qvR'iynhjmkuozn iffozopiffk'vSxnhljmlzj'q\w\ivR'fuk~#5nhsSiffozlzjmi4-<$lznhopfhqr'inhjmkuozn iffozopiffk] H u$D! u$DC&Dff#~2,3zhe##eCD#~2#2E3FIHzee''#u'za#zehzhn yozi8e~P||rmxnh|LtxRiffsRrmozvRs5fhxsRr'ysSivRs5fhiffn vRr'xRiffsZ2 n#~vlzslzjvSixRiffsSvRlj'qKvSf*iL'nhwMlzj'iGPmn vZvtediffsfhuiffn vRrmxRiffsn xRi~vR'i~w\fsSvDkmlzsR|LxlzwMlzjmn vSfhxtlzjk'ivSixwlzjmlzj'q'ivRmixUnCkmlznhopfhqr'ilzsGdyxRfhyopiffwMn vRl|KfhxUjmfhvRBEBE8=DOUnhsUvSxnhlj'iffksSidn xn vSiffoptMfjJsSivRsafhiffn vRrmxRiffsynhsSiffkfjvR'iOqhxRfr'dys,qlz}hiffjlzjlpqr'xRi5jmnhw\iffopt;P|LfrysSvRlzp| k 4-< D5)a$lznhozfhqr'inhjmknhjmkuozn iffozopiffklzjy|ozrmkmlzjmqMu- miffsSixRiffsRrmozvRsKn xRiIqlp}hiffjlj n yozi8e'fhx Gu|mnhj'qhi *fjmoptvR'iiffn vRr'xRiffs*frmv6fhvR'inhr'vSfwMn vRl|iffn vRr'xRisSivRs*tulpiffozkysMnhjlzw\dyxRf }hiffw\iffjv\f }hixvR'iOynhsSiffozlj'ihjvSixRiffsRvRlzj'qopthavSxnhlzjmlzjmqEvR'iOsStusSvSiffw fjvRmi 4- D?telziffozkms&vR'iiffsSv,xRiffsRrmozv&frmv\fhPvR'inhrmvSfwMn vRlz|Oiffn vRr'xRisSivRsMfhNx Gu|mnhj'qhiffInhjykvR'iO'foziJkmlnhopfhqr'ih'iffsRisStusSvSiffwMsUfhx6iLunhwMdyopih5rmsSi Shh jermw8ix\fh$xRiff|LfhqjmlziffkUfhxkmsKnhjmkv tdifhxRiff|LfhqjmlzvRlpfjOqhxnhwMwn xnhs*iffn vRr'xRiffsPlzj0vR'ifflpxKxryopiffsSivlzjmnhoopthai\qlp}hi\xiffsRrmopvRsfhxvR'iMsStusSvSiffwvSxnhlzj'iffkfjmoztfj H u$D $nhjmk [ u-$j'i|nhjsSiiEvRyn v6vR'ixilzsJj'fhv0wCry|kmlixRiffjm|LilzjvR'ivUfsSivRs0fhIxRiffsrmopvRsmfhx)'|ynhj'qhiffs5ffIe vR'iasStusSvSiffw vSxnhlzj'iffk8fj [! u$D mnhs-nhjCnh||rmxnh|LtIml|8lssRlpqjyl|nhjvRoptmlpqmixvRmnhj?vR'iEsRtesSvSiffw vSxnhlj'iffkfj H u$D MetndnhlpxRiffkvHvSiffsRvk'7 hheP8v #;eu$u ;$jiL'nhwMlzjmlj'qvR'iExrmopiffsSiv5fj'ijmkmsMvRmn v6vRmi [ '$D MrmsSiffDBh4D2 4E426'Rx*Rvu$xrpffRGv'kfff~'jhfv'pfUxhn||'rxhnL|wn t,"i*kyr'iKvSfHvR'i,nh|LvvRyn vvRmi H u- *dmxRiffkml|LvSfhx$ynhsn0opfxRiff|nhozonhjmkEdmxRiff|lzsRlzfjfh#x DBh4D2 4E426hnffjljnz8e2 2po lmq%0z= 1\~~22sw\iffjvRlpfj'iffkljceiff|LvRlpfjevR'ixin xRiU; v tdiffsOfh,dmxfhyopiffwMn vRlz|kmlnhopfhqr'iffs24 5e<4 D8w gx 4Dynhjmk 4ijBZ&jfhxkmixvSfk'ivSixwMlzjmi&P'ivR'ixIsSfw\i\fhUvR'iffsSi\v tdiffsfhUdmxRfhopiffwMn vRlz|VT 4fi>r6rz~2g24- 5)e669824 5e<4 D8w gx 4Dy4ijBfhvRnho72> 9?f7A@d.220zn\qpfiqsn0z \qe;;u ;he#h/u' huH ;'z /heHH ;fi ;;he/he#h/hun=n opiMu~n vSxl0fhDxiff|Lfhqjmlpiffk24-<5ff676=8" Pnhjmkr#Irz~2g#2fi4-<5ff676982fi4 <5p4 D8fhvRnho0z fqpBs#u zu H ;;hee/hheffhn yopiMh Pn vSxlOfh)xRiff|Lfhqjylpiffk2fi4-<5ff67698 nhjmk^2fi4DvSiffsRvRlzj'qq$~2z /hhffeffee H r;h / hh24- 5e<4 D80|n\n9n/h/h ;/h\~f~2q~2h / uff5e<4 D8$rysRlzj'qMiffermnhovSxnhlzjmlzjmqnhjmkkmlznhozfhqr'iffsMn xRiw\fhxikml{6|ryopv,vSfdmxRiffkml|Lv&vRynhjfhvR'ixsffaUi|Lfjmkmry|LvSiffkndfsSv'fu|nhjmnhoptusRlzs,fhvR'i,dmxRfhdfhxRvRlzfjfh~dyxRiffkmlz|LvRlpfjnhlozr'xRiffsfhxiffnh|vted"i,fhGdyxRfhyopiffwMn vRl|8kmlznhozfhqr'ih8culzjm|Li&ai&UixRidmxlwMn xlzoptlzjvSixRiffsSvSiffklzjvRmi6dixRfhxwMnhjm|Li6fhKvR'i0~$rmsRlzjmqvR'irmozoanhr'vSfwMn vRlz|6iffn vRr'xRi0sSivn vSixCmn }elzjmqsSiiffWj Gu|mnhj'qhiffsJffIe-Ui|Lfjmkyrm|LvSiffkfr'xCnhjmnhoptusRlzs$fjvRylzs$}hixsRlpfjfhUvRmi~$Dn yopi06sRmf svR'i,kmlzsSvSxlpyr'vRlpfj0fh~vR'i,6v tdiffsfh~kmlznhozfhqr'iClzjEvR'i&vSiffsSvsSiv$nhjmkP'ivR'ix$vR'i)'|ynhj'qhiffsffII~$5nhs~n yoziUvSf8dmxRiffkmlz|LvG|LfhxxRiff|LvRopt&vRmn vGvR'i*kmlnhopfhqr'iKUfrmozk,2fi4-< 5ff67698fhRx BEDFGfi 8 4E2 6)$j'i5|nhjMsSii5vRmn v)vR'i5UfhxsSv)dixRfhxwMlzj'q|n vSiqhfhxRt\lz2fi4D 5e<4D8&nhjmk&vRmn vvR'i8a$dmxRiffkylz|LvRsKlzjm|LfhxRxiff|LvRopt6vRyn vPhefhvR'24-< 5<4D86kmlnhopfhqr'iffs*n xRb2fi4-< 5ff67698 h$jmiIxRiffnhsSfjEvRmn vvRylzs*wMlpqv*fu||r'x$lzsKvRmn vPvRmlzssr''|n vSiqhfhxRtOfhGkmlnhopfhqr'iffs*n xRi&wCry|w\fhxRikml{J|rmopv,vSfdmxiffkmlz|LvMsRlzjy|LilzjvRmlsM|nhsSivR'i sStusSvSiffw mnhs6j'fljmkmlz|n vRlpfjvRyn v6lpvMlzs6j'fhvsRrm||Liiffkylzj'qlzj?vR'ivRnhsSg"Pf Ui}hixffInhj'fhvR'ixOdfsRsRlzylzozlpv tlzsJvRmn vOvR'i~$ dixRfhxwMsJdffhxoptfj?vRmlzsM|n vSiqhfhxRt?iff|nhrmsSivRmixRiEn xRiEiUixJiLunhw\dopiffslzjvR'ivSxnhljmlzj'qsSivPnhopvR'fr'q?lpvk'feiffsivSvSixfjvR'i 4ijBsRr'ysRiv"Pmlz|lzs$n fr'vvR'i\sRnhw\i,dmxRfhdfhxRvRlpfjiM|nhjiffolzwMlzjmn vSiCvR'iyxsRvUdfsRslpylzozlzvt,t6iLunhwlzjmlzj'q,'fn\opiffn xj'ixKdixRfhxwMsUmiffj6vSxnhlzj'iffk0fj0iffermnhodmxRfhdfhxRvRlpfjysafh24- 5)67698nhjyk 2fi4D 5e<4D80kmlznhopfhqrmiffs)iC|Lfjmkyrm|LvSiffknhjOiLudixlzw\iffjv*rmsRlzjmq,nsRr'ysSivKfh24- 5)67698&kmlznhopfhqr'iffs8lzjvR'iJsRnhw\idyxRfhdfhxRvRlpfjnh+2fi4-< 5p4D8fhxCvR'iMvSxnhljmlzj'qnhjmkvR'ivSiffsSvsSivPnhjmkvSxnhlzj'iffknsSiff|Lfjmk~$?rysRlzj'q,vR'iIrmozozt6nhr'vSfwMn vRl3| )'|ynhj'qhi6ffIMiffn vRrmxRiffs mlzsxRiffsRryopvSiffklzjJnCvSxnhlzjmlzjmqIsSivafhDh &kylznhopfhqr'iffsUnhjmkJn8vSiffsSv5sSivUfh-uffe miylzjyn xRt\|oznhsRsRlixamnhsUnhjnh||r'xnh|Ltfh-JvRmiP|LfhxRxRiffsRd"fjykmlzj'qxRiff|LfhqjylpvRlpfjwn vSxllzs)dyxRiffsSiffjvSiffk6lzjvRn yopi8h 'i*xRiffsrmopvRssR'f vRyn vPiai#x 24- 5e<4D8In xRi8dyxRiffkmlz|LvSiffknhsPsrm||LiffsRsSrmo/"sRr'qhqhiffsSvRlzjmqvRmn #v 2fi4D 5e<4D8n xRij'fhv6ljm'ixRiffjvRoptw\fhxRikml{6|ryopv\vSfdyxRiffkmlz|LvMvRynhj?fhvRmixJ|oznhssSiffsJfhdmxRfhyopiffwn vRlz|kmlnhopfhqr'iffsUiffopf UikylzsR|rmsRsMvR'iEdfhvSiffjvRlznhoPfh8rmsRlzjmWq BEB=8EDsopfssxn vRlzfvSf;aifflpqv0kmlixRiffjv6vtediffs6fh|oznhsRsl|n vRlpfj0ixRxfhxs*lzj0r'vRr'xRiUfhxRg"VTVfi)uQ2Zy222 S2-7M1m72Q _wv ^ffx'i&xRiffsSiffn x|xRidfhxRvSiffk'ixRi,lzsPvR'i&yxsSvvRmn v$Ui&guj'f fhavSfOnhr'vSfwMn vRlz|nhozoztnhjmnhoptei\nJ|LfhxdyrmsfhopfhqsCxRfwnEsSdfhghiffjkylznhopfhqr'iJsStesRvSiffw fhx,vR'idyrmxRdfsSiMfh*opiffn xjylzj'qvSf RR /ff dmxRfhopiffwMn vRlz|sRlpvRryn vRlpfjms mlzs$UfhxRgyrylzozkmsfjv afsSvSxnhjykmsIfh5iffn xozlzixIxRiffsSiffn x|ZlpxsSvDvRmlzs8n dmdmxRfnh|5nhslzjmsRdylpxRiffk,et,afhxRg\fj6vR''Bh4D4y 8\i} nhozrmn vRlzfjMxnhw\iUfhxRg\fhxUsSdfhghiffj6kylznhopfhqr'i*sStusSvSiffwMsaml|r'vRlzolpiffs0fhvRwCrmozvRlp}n xlzn vSiozlzj'iffn xOxRiqhxiffsRsRlpfjnhjyk 5'vSfdmxRiffkml|Lv0rysSixsRn vRlzsRnh|LvRlpfjnhsnrmjm|LvRlpfjfhnjrmwCix8fh*fhvRmix,wMivSxlz|s0nhopghixff~-lpvRwMnhjZInhwMw~PiffozoznuKffhanhozghixivPnhoHp hhhn*iffsSiffn x|rysRlzj'Nq Bh4D4y < 8Omnhs*frmjmk0vRyn vvRnhsSgO|Lfw\dyozivRlpfjlzs*nhozUn tesnMwMn SfhxdmxRiffkylz|LvSfhxfhKrmsSixIsRn vRlzsRnh|LvRlpfj-nhjmkmnhsIiLunhwMlj'iffkdmxRiffkylz|LvSfhxs$fhUvRnhsSg|Lfw\dyopivRlpfj,PixRih-fr'xqhfnhozsan xRiPsRlwMlzozn x)lzj,vRmn vaaiPn vSvSiffw\dmv~vSf&rmjmk'ixsSvRnhjmk,vR'i*nh|LvSfhxsavRmn vGdmxiffkmlz|Lv)vRnhsSg\|Lfw\dyozivRlpfjZceiff|LfjmkyopthuvRmlzsaafhxRg6yrmlzokms)fj0iffn xozlzixaxRiffsRiffn x|Ofj0opiffn xjmlzj'qCvSf /y kmlznhopfhqr'iffs5lzj6ml|JvR'irmsSixiLudixlpiffjm|Liffkdfefhx$sRd"iiff|xRiff|Lfhqjmlpix8d"ixfhxwnhjm|Li0-lpvRwMnhjivInho/pGffhhMUiff|nhrmsRi\vRmn vUfhxRgOUnhsynhsSiffkEfjiffn vRr'xRiffssStujvR'iffslpiffkf}hixPvR'iCiffjvRlzxRi8kmlznhozfhqr'ihyvR'iCtedfhvR'iffsSiffs*vRyn vUixRiopiffn xjmiffk|Lfrmokj'fhv&i6rmsRiffkfhxCdyxRiffkmlz|LvRlpfjkmr'xlj'qxrmjvRlzw\ihjnhkmkmlzvRlpfjZlzj|LfjvSxnhsSv,vSfvR'i|r'xRxiffjvsSvRrmk'th"vR'i8dyxRi}elzfrms*UfhxRgnhr'vSfwn vRlz|nhozoptn dmdyxRfff'lzwMn vSiffkEvR'i,j'fhvRlpfjEfhGnqhfefekEfhx$ynhkkmlznhozfhqr'irmsRlj'qInvR'xRiffs'fozk\fj6vR'i*dix|LiffjvRn qhiPfhZxiff|LfhqjmlpvRlpfjixRxRfhxs mixRilzsGnCkmnhj'qhixafhZvRmlzsn dmdmxfnh|ifflzj'q0|lpx|rmon xPmiffjxRiff|LfhqjmlpvRlpfjdixRfhxwMnhjm|Li\n v$vR'iMr'vSvSixnhjm|LiMopi}hiffolzs$n0dmxlzwn xRtdmxRiffkylz|LvSfhxafhnCqhfefekJfhx5ynhkJkmlznhopfhqr'ihjMvRmls~UfhxRg"evRmiPj'fhvRlpfj6fhnCqhffuk 2fi4D 5)67698 Dnhjmkynhkg B=D7FGy8 4E2 6~kylznhopfhqr'i$5nhsozn iffozopiffkJetJermwMnhjysjdmxi}elpfrysafhxgKnhopghix,ivCnho/p) hh "IxRidfhxRvSiffkxiffsRrmopvRsxRfw vSxnhlzjmlzjmqndmxRfhopiffwMn vRlz|kmlznhozfhqr'iIdmxRiffkylz|LvSfhxPlzjmlz|OvR'itjmfhvSiffkvR'iCiLevSiffjvvSf6ylz|OvRmi&mnhjykuozn iffozopiffkEu-iffn vRr'xRi\lzw\dmxf }hiffs$|oznhsRsRlpyixPdixRfhxwMnhjy|LihsnxiffsRrmopvfhGvRmlzsPdmxlzfhxnhjmnhoztesRls"ljvRmlsUfhxRgUixRidfhxRvPxRiffsRrmopvRsxfw vSxnhlzjylzj'qnhj H u$D *|oznhsRslyixfhxiffnh|iLu|mnhj'qhi\nhjmkrmsRlzjmqlpvRsdmxRiffkylz|LvRlpfjmsanhsanhj0lzj'dr'v)iffn vRrmxRiPvSf&vR'i$GxRfhopiffwMn vRlz|Plnhopfhqr'iP~xRiffkmlz|LvSfhx 'ixRin xin&jryw8ixfhydyxRi}elzfrmssSvRrmkmlpiffsDfj,dmxiffkmlz|LvRlzj'qPxRiff|LfhqjmlpvRlzfj,ixRxRfhxs)nhjmk\rysSix)|LfhxRxRiff|LvRlpfjmsGmlz|Cn xRiKxiffozn vSiffk,vSfvR'i H u$D )dmxRiffkylz|LvSfhxavRyn vaUiPxid"fhxv~fj0'ixRi,PlpxsR|ixRq8ivKnho/pffhhemPlzxsR|ixRq'lzvRwMnhjZy ceUixRvRs" hhu" h'L"i}hf 8-ffhhelpvRwMnhjmPlpxsR|ixRq'y ceUixRvRsy hhuceUixRvRslzvRwMnhjZylpxsR|ixRq'y hhlpxsR|ixRq,ivnhoHpffhh*n dmdyopBEBE8=DEvSf\dyxRiffkmlz|Lv5xRiff|LfhqjmlzvRlpfj0ixRxRfhxsKljOn\|LfhxRdyrmsUfh)r'vSvSixnhjy|Liffsj|LfjvSxnhsRv6vSffr'xUfhxRg"KvR'itr'vRlzozlpiOdyxRfsSfukmlz|0iffn vRr'xRiffslj|LfwCylzjmn vRlpfjlpvRnh|LfrmsSvRl|M|Lfjuk'iffjy|LiMsR|LfhxRiffs mitxRidfhxRvnOiffsSv|oznhssRlyixnh||r'xnh|LtfhKhJPmlz|lsnLlzw\dyxRf }hiffw\iffjvGf}hixavR'ifflzxGynhsSiffozlj'i5fh0 mlzsxRiffsrmopv)|nhjMi*|Lfw\dyn xiffkMlpvR,frmx~ylzjyn xRt Hu- 5dyxRiffkmlz|LvSfhx,g D767FDD8962}es67FDD8962KkmlzsR|rmssSiffklzjceiff|LvRlpfjeGunhwMljmn vRlpfjfhmvR'i5xryopiffsopiffn xj'iffk8etIvR'ifflzxD|oznhssRlyixsRr'qhqhiffsSvRsvRyn vDkmrmxn vRlpfjmnhoiffn vRrmxRiffsn xRiKlzw\dfhxRvRnhjvmlzopiUi~k'f*j'fhvrmsRiGnhw\dyozlpvRryk'ifhxKiffn vRrmxRiffsai~kmf*mnff}hi~nhj Sh/ iffn vRrmxRiGml|lzsZopfhqhqhiffk8tvR'ixRiff|Lfhqjmlpix GlzvR'fr'v5nhjt6fhvR'i$fhvR'ix5dmxRfsSfukmlz|iffn vRrmxRiffsuvR'i H u$D Gdmxiffkmlz|LvSfhxmnhs&nhjnh||rmxnh|LtfhPhe JGnhe lzw\dmxf }hiffw\iffjv8f}hix\vR'iynhsRiffozlzj'iMfhh ;0vClzs8d"fssRlpyopivRmn v~ljm|ozrmkmlj'qdmxfsSfekylz|Uiffn vRr'xiffs~lzj,vR'i H u- DdyxRiffkmlz|LvSfhxG|Lfrmok\lzw\dmxRf}hi*vRmlzsxiffsRrmopvi}hiffjr'xRvRmixff~xRi}elzfrmssSvRrykmlpiffs*fjixRxfhx|LfhxRxiff|LvRlpfjxiff|LfhqjmlpvRlpfjn xRi,nhozsSfxiffozn vSiffkvSf6fr'x$w\ivR'fukfhawMlzsrmjmkmixsSvRnhjmkmlj'q$xRiff|LfhqjmlpvRlpfjKi}hf IZffhhan dmdyolpiffkMsRlzwlzozn x)vSiff|yjmlzer'iffsGvSf&opiffn xjMvSf,kmlzsRvRlzj'qrmlzsivUiiffjr'vSvSixnhjm|Liffsljml|EvR'i\rmsSixfhxlpqlzjmnhoopt0dmxRf }ulzk'iffkEsSfw\i\lzj'fhxwMn vRlzfjvSf0vR'i\sStusSvSiffwOnhjmk RRff/ yylz|dmxRf }ulzk'iffk6vR'i$sRnhw\ilzj'fhxwMn vRlzfjn,sSiff|LfjmkJvRlzw\ihefozopf Plzj'qCn&wMlzsrmjmk'ixSsSvRnhjmkylzj'q' mlswMn ti8w\fhxRi&xRiffozn vSiffkEvSf6frmxPxRiffsRiffn x|vRmnhjlpv*xsSvn dmdiffn xssRlzjy|LiC|LfhxRxRiff|LvRlzfjmsVT 1fi>72> 9?f7A@d.22n xRi6fhvSiffjwMlzsrmjmk'ixsRvSffukkmr'iMvSftdixSn xRvRl|rmozn vRlpfjZOi}hf Is&iLud"ixlzw\iffjvRsIvSxnhlzjnk'iff|lsRlpfjvSxRii$rmsRlzjmqiffn vRr'xiffsasRry|Jnhsakmrmxn vRlpfjZvSiffwMd"f'edylpvR|ZnhwMdyozlpvRrmkmihnhjmk6lpvRmlzj'r'vSvSixnhjm|LiKdynhrysSiffs)'nhwMlzjyn vRlpfjfh~vR'iCvSxnhlzj'iffkvSxii,ljvRmlzssSvRrmkmtnhozsSfJxRi}hiffnhozsvRmn vvR'i&kyr'xn vRlpfjmnhoiffn vRrmxRiffsn xRivR'i$w\fsSvUkmlzsR|LxlwMlzjmn vSfhxRthGculzwlzozn xoptClzjMfr'xUiLud"ixlzw\iffjvRs1BEBE8EDrmsSiffs Sh/ xRiffer'iffjvRoztlzj0vR'iCk'i}hiffopfhdiffk0xrmopisSivUi}hffhmvRnhlzjys*nhjnh||r'xnh|LtOxn vSiIfh) lpvROn\nhsSiffozlzj'i$fhG JHceUixRvRsaivUnhoHpe hhanhjmkElpxs|"ixqIivUnhoHpu h'L"GdixRfhxw sRlzwlzozn xGsSvRrmkylpiffsGfhxanhr'vSfwn vlz|nhozozt,lk'iffjvRlztulzj'qI|LfhxRxiff|LvRlpfjms5rmsRlzjmqIdmxRfsSfuk'th4- Diffn vRr'xiffsUnhjyk6kmlnhopfhqr'iP|LfjvSiLuvUUfhxRxRiff|LvRlzfjmsn xRiolpghiffopt&vSfIiwMlzsSxiff|LfhqjmlpiffkZkyr'iKvSfCtdixn xvRlz|rmozn vRlpfj 'it&fhysSix}hivRmn v~|LfhxxRiff|LvRlpfjms~vRmn vn xRiw\fhxRiPkylzsSvRnhjv~xRfw vR'iPixRxRfhxUvR'itM|LfhxRxRiff|Lv'n xRiw\fhxRiozlpghiffopt&vSfCiL'mlplpv)dmxRfsSfukmlz|Kkyl"ixiffjm|Liffs'ifflzxsStusSvSiffw nhr'vSfwn vRlz|nhozoptkmlixRiffjvRlzn vSiffs|LfhxxRiff|LvRlpfjmsxRfw j'fju|LfhxRxiff|LvRlpfjmsMPlpvRnhjixxRfhxxn vSiMfh$ffe# JM$lznhopfhqrmiM|LfjvSiLuvClzsrysSiffklzjvR'iMsSvRryk'tet;lpxsR|ixRq'-lpvRwMnhjceUixRvRsh'n5'ixRietvR'it;lzjm|LfhxRdfhxn vSi0mivR'ix,vR'iOrmsSix\lzs,nff5n xRifhnwlzsSvRn ghiOn v\vR'iO|r'xRxRiffjvr'vSvSixnhjy|LiPvSf,'iffopd6dmxRiffkmlz|LvawMlzsRrmjyk'ixsSvRnhjmkylzj'qs)nhjmk6wMlzsSxRiff|LfhqjylpvRlpfjMfhvR'idmxi}elpfrys~r'vSvSixnhjy|LiffsmlssSvRrmkmtlzssRlzwMlzon xvSfJfr'xs$lzjEvRmn v$vR'itrmsSi,nJdmxRiffkml|LvSiffkiffn vRr'xRi,n fr'vnhjr'vSvSixnhjm|LivR'inff5n xRihDiffn vRrmxRi$vSfdyxRiffkmlz|LvI|Lfjm|Lidyv8fhx8Ufhxknh||r'xnh|Lth)nhsIUirmsSi6nOdmxRiffkml|LvSiffkiffn vRrmxRi Hu- alzj0vR'iIaDmPf Ui}hixff"fr'x H u$D Uiffn vRr'xiIlzsKnhr'vSfwMn vRlz|nhooptJn }nhlozn yopin vKvR'i$vRlzw\i$vR'i$dmxiffkmlz|LvRlpfj0lzsUifflzj'q,wMnhk'ihu'ixiffnhs5vR'itJn xi$wn gelzjmq&vRmidyxRiffkmlz|LvRlpfjys~xRivSxfnh|vRlp}hiffopthj;nhkykmlpvRlpfjZDvR'itvSxnhlzjvRmifflpx&sRtesSvSiffwfj;vR'i0mnhjmkuon "iffoopiffkiffn vRr'xRiJxn vR'ix,vRmnhj;vR'idmxRiffkylz|LvSiffk0fj'iIylz|0vR'itOopiffn }hi8nhs*r'xRvRmixKafhxRg"g Ilzx|mmf D' h' adixRfhxwMs~ixxRfhxK|LfhxRxRiff|LvRlpfj0lzk'iffjvRl|n vRlzfj6rmslzj'qIvRnhsSgJlzjmk'idiffjmkmiffjv~nh|LfrysvRlz|JnhjmkkmlzsR|LfrmxsSiM} n xlzn yoziffs mlzs8ls&nEvUf5nfftkylzsSvRlzjm|LvRlzfjivUiiffjd"fslpvRlp}hi6nhjyk;jmiqn vRlp}hiixRxRfhx|LfhxRxRiff|LvRlpfj*c''i8rmsSiffsvUfJ|nhs|nhk'iffkE|onhsRsRlyixs'vR'iIxsSvlzsnk'iff|lzslpfjOvSxRiiCvSxnhlzj'iffkrysRlzj'qfhvR'ikmn vRnnhjyk}nholzkmn vRlzj'qfjJGunhwMdyopiffs&vRmn vmn }hi|Lfjukmiffjm|LisR|LfhxRiffs\iffopfnvR'xRiffs'fozkqhf0lzjvSfJnhjiL'|LidmvRlpfjEvSxnhlzjmlj'qsSivfhxnJsSiff|Lfjmk|oznhsRsRlpyixff$r'xlj'qvSiffsSvRlj'q'"lzG|Lfjumk'iffjm|Li,sR|LfhxRiffsn xiCiffopf n6vR'xRiffsRmfozkvRmiffjvR'i\r'vSvSixnhjm|Li&lsdynhssSiffkfjvSf0vR'i,sSiff|Lfjmk|oznhsRslyixffcu'iIjmkmsvRmn vPvRmiCw\fsSvkmlzsR|LxlzwMlzjmn vSfhxt6iffn vRr'xRiffsn xRi,kmlznhopfhqr'iC|LfjvSiLuvMvR'iCv tdiCfh)dmxRi}ulpfrmssStusSvSiffw rmvSvSixnhjm|Li$fozopfaiffktopiL'lz|nhoiffn vRr'xRiffsDlpvRdmxRfsSfukmlz|&iffn vRr'xRiffsIifflzjmqOvR'iopiffnhsSvCkmlzs|Lxlzwlzjmn vSfhxRth 'i6sStesRvSiffw xRiff|Lfhqjylpiffs8ixxRfhx&|LfhxxRiff|LvRlpfjmsClpvRnhj;nh||r'xnh|Ltfh |Lfw\dn xRiffkvSf6nynhsSiffozlj'i$fh~u J5jvRmlzs*sSvRryk'tg 8lpx|y'f D" h' kmiffozlpixn vSiffopt6iffsR|'iPs*vR'i&rmsSiIfh)sStusvSiffwsSdiff|l|iffn vRr'xRiffsffylzopi8lzjfr'xUfhxRg"aiCiLunhwMlj'i8vR'i,sSidyn xn vSi&|LfjvSxlpyrmvRlpfjfhGkmlp"ixRiffjviffn vRr'xRiCsRivRsP$r'xPxRiffsRrmopvRssRr'qhqhiffsSvPvRmn vPvRmiCrmsSi8fhGw\fhxRi8qhiffjmixnhoiffn vRr'xRiffsk'feiffsPj'fhvPj'iqn vRlp}hiffoptlzw\dnh|LvKd"ixfhxwnhjm|Lihg xnhmw\ixffMceUixRvRs 'iffrmjmih, iiqhiffozsEffhh nnhjmk g xnhyw\ixffMceaixvRs 'iffrmj'ih,iiqhiffozsffhhGopfefhgMn v5kmlixRiffjv~iffn vRr'xiffs~xRiffon vSiffkvSf&xRiffsSdfjmsSiffs~vSfCdyxRfhyopiffwMn vRl|*sStusSvSiffw vRrmxjms'i h < ~z Mh/ IvR'itkmlzs|rmsRs$n xRiMxRiffsRd"fjysSiffs$vSfiLudyozlz|lpvfhx8lzwMdyozlz|lpvsStusSvSiffw}hixl"|n vRlpfjer'iffsSvRlpfjmsff mitfhysSixR}hi&vRmn vkmlzs|LfjuyxwMn vRlzfjmsn xRi,opfj'qhix ynff}hi\n0wMn xRghiffkafhxkEfhxk'ixffZnhjmk|LfjvRnhlzjsSdiff|l|8oziLulz|LfjsRry|nhsOSj'fujnhkmkmlzvRlpfjZyvRmixRi\n xRi&sRd"iff|lp|IdmxfsSfekylz|8|r'iffs$sRry|nhsfrmjmkmn xtvSfj'iffsMnhjmkdynhrmsSiffscefwMiOfhPvR'iffsRiOiffn vRr'xiffsMsRrm|nhsMopiffj'qhvRa|mflz|LifhafhxkysMn xRi|n dmvRr'xiffklzj0fr'Cx BEBE8EDxryopiffsSiv*nhskylzsR|rmsRsRiffkJn f}hihsk'iffs|Lxlpiffk0lzjEceiff|LvRlpfjEeyvUf6wMivR'fekmfopfhqlpiffsKUixRi8|Lfw\dn xRiffkfhxlzjm|Lfhxd"fhxn vRlzj'q,vR'iIiffnvRr'xRiPu- lzjvSfvR'i5~$D 'iayxsSv-UnhsvSfrmsSiUvR'i5mnhjmkuon "iffoopiffkiffn vRr'xRi5lzj8vRmiUvSxnhlzjmlzj'qsSivmvRmi8sSiff|LfjmkvSfMdixRfhxw sSidyn xn vSiIiLudixlzw\iffjvRsKvSfMdyxRiffkmlz|LvKvR'iiffn vRr'xRi8fhxPvR'ivSxnhlzjmlj'q\sSivsKvR'iiffn vRr'xRiffs*lzj0vRmivSxnhlzjmlzjmq&sSiv*n xiInhr'vSfwMn vRlz|nhozozt6dmxiffkmlz|LvSiffkZ'lpv*lzsKmfhd"iffkJvRmn vvR'iIsStusSvSiffwUfrmozk,dylz|gCr'd\vRmilzkmlpfsRtejm|LxnhsRlpiffs-fh"vRmi*j'flzsSt&kmn vRnu mlzsDvSxnhljmlzj'q$w\ivR'fukMmnhs)iiffj\rmsRiffk,dmxRiL}ulpfrmsRopt6lzjxlpqv hh5mixRinhr'vSfwMn vRlz|nhozozt6lzk'iffjvRlyiffk0lzjvSfjmn vRlpfj0i}hiffjv*iffn vRr'xRiffs*n xiIrmsSiffkVT"fi2Zy222 S2-7M1m72vSfvSxnhlzjnhjnhr'vSfwMn vRlz|CsSdiiff|unh|Lv$k'ivSiff|LvSfhxff 'iffsSi&nhr'vSfwMn vRlz|nhozozt0kmixlp}hiffkiffn vRr'xRiffsPdmxRf}elk'i8nivSvSix5vSxnhlzjmlzjmq8w\fuk'iffomvRmnhjJvR'i$mnhjmk'ozn iffozopiffk,fj'iffs mlzs~ls~vSxrmiPnhozsSf,lzjvR'i|rmxRxRiffjvUsSvRryk'tMnhskmlzs|rmsRsSiffk0lzjEcuiff|LvRlpfjezyYNXb?ff'`fff bH^ ]] _`l`l Qv^zxmlsPdn d"ix$xRidfhxRvRs$xiffsRrmopvRs$fjnhr'vSfwn vRlz|nhozoptvSxnhlzjmlj'qJnO~xRfhyopiffwn vRlz|C$lznhozfhqr'iMGxRiffkylz|LvSfhxvSfdmxRiffkylz|LvPdyxRfhyopiffwMn vRl|CermwMnhju|LfwMdyr'vSixkmlznhopfhqrmiffsrysRlzj'q0n0|LfhxRdyrms$fhahh0kmlznhopfhqr'iffs|Lfoopiff|LvSiffklpvRCvR'i h L sSdfhghiffj,kmlznhopfhqr'i5sStusSvSiffwO 'i5GxRfhopiffwMn vRlz|U$lznhopfhqr'iKGxiffkmlz|LvSfhx|nhji6lzww\iffkmlzn vSiffoptn dydyozlpiffkvSfvRmi0sRtesSvSiffws&kmiff|lzsRlpfjfhmivR'ixCvSfvSxnhjysSix,vR'iO|nhozoavSfnermwMnhj|rmsSvSfw\ixO|n xRin qhiffjvPfhx0iErmsRiffk?nhs0n;|r'iEvSfvR'isStusSvSiffwOs0$lznhopfhqr'inhjmn qhixOvSfw\fukmlptlpvRsM"iffynff}ulpfhxMvSfxRidnhlpx\vR'idmxfhyopiffwMs\lzkmiffjvRliffkZ 'ixRiffsrmopvRs\sR'f vRmn v \EfsSviffn vRr'xRi,sSivRs$sRlpqjml"|nhjvRoptOlzwMdmxRf }hi&f }hixvRmiCynhsRiffozlzj'ih)/:PsRlj'q6nhr'vSfwn vRlz|8iffn vRr'xRiffsxRfw vR'i'foziJkmlnhopfhqr'ihGUi|nhjlzk'iffjvRlptdmxRfhyopiffwn vRlz|6kylznhopfhqr'iffsM ivSvSix\vRmnhjvR'iOnhsSiffozlzj'ih$ ;{ rysSvvR'iCyxsRv*iLu|mnhj'qhi,dmxRf}elk'iffsPslpqjml|nhjvRopt0ivSvSixPdyxRiffkmlz|LvRlpfj; ;M*vRmnhjvR'i8ynhsRiffozlzj'ih)'isSiff|Lfjmk6iLu|mnhj'qhi$dmxRf}elk'iffs~nhjJnhkmkmlpvRlzfjmnhomsRlpqjyl|nhjvP< ;M~lzw\dmxRf}hiffw\iffjvZ/~|oznhsRslyixynhsSiffkJfj0vRnhsSglzjmkmid"iffjyk'iffjv5nhr'vSfwMn vRl|Piffn vRr'xRiffs5dixRfhxwMs5sRolpqvRozt\"ivSvSixKvRynhj6fjmivSxnhlzj'iffkJfjvR'iIrmozonhr'vSfwn vRlz|iffn vRr'xRi8sSivmiGlzw\dmxRf}hiffkIn ylzolpvtPvSf*dmxRiffkml|Lv"dyxRfhyopiffwMn vRl|)kmlznhopfhqr'iffsZlslzw\dfhxRvRnhjvfhxZiffozkmlzj'q5vR'iCfsStusSvSiffw lpvR'frmvPvR'i,j'iiffkfhxvRmi&f}hixsRlpqvfh~n0ermwMnhj|rmsSvSfw\ixI|n xRi\n qhiffjv 'iffsRiCxRiffsrmopvRsn xRi,dmxRfwlzsRlzj'qJnhjmkai,iLudiff|LvvSfOi,n yopi,vSfOlzw\dmxf }hi\r'dfjvRmiffwOZdfsRsRlpyoztJetEljm|LfhxRdfhxn vRlzj'qdmxRfsRfek't6lzjvSf\vRmiiffn vRr'xi$sRivCPlzxsR|ixRq,iv*nho/pffhhUfhx*iLudynhjmkylzj'q&fj0vR'iCEiffn vRr'xRiIsRivRsj&nhkykmlpvRlpfjZ vR'i5xRiffsrmopvRssRr'qhqhiffsSv)vRyn vDvRmi*|r'xRxRiffjvDa$lzsozlpghiffopt8vSfqhiffj'ixnhozlpi5vSf$fhvR'ix~kylznhopfhqr'isStusSvSiffwMsj\r'vRr'xRi5UfhxRgaidyoznhj,vSf8lzjvSiqhxn vSi*vRmiopiffn xj'iffk,xrmopiffsSivRsGljvSfvR'iCf kmlznhozfhqr'i*sStusSvSiffwnhjmkEi}nhormn vSiCvRmi&lzwMdynh|LvvRmn v$vRmls*Ufrmozkmnff}hi&fjvR'i&sRtesSvSiffwsPf}hixnhozoDdixRfhxwMnhjm|Lih 'ixRin xRi,sSi}hixnho-Un tesUi&wlpqvPiCn yopiCvSfJs'f vRmlzsiffw\iffwC"ixvRmn vfj'i,rmsSi8fh)vRmiC~$lzsvSflzw\dyxRf }hi5vR'iKsStusSvSiffwOsGkmiff|lzsRlpfjCfhP'ivR'ix)nhjmk,'iffj&vSfvSxnhjysSix)n|nhozoevSfvR'iKermwMnhj\|rmsRvSfw\ix|n xRi\n qhiffjv 'i8fhvRmix$rysSiCUfrmozki&nhs$lzj'dr'v*vSfJvR'i&$lznhozfhqr'i&nhjmn qhixffskylznhopfhqr'i,sSvSxn vSiqhtsSiffopiff|LvRlzfjw\iff|mnhjmlzsRw~iffw\fjmsSvSxn vRlj'qMvR'i8rmvRlzozlpv tfhvR'i8a?fhxPkmlznhozfhqr'iIsSvSxn vSiqhtsSiffoziff|LvRlpfjxRiffermlpxRiffsDiLudixlzw\iffjvRsvRmn v)vSiffsSvGfrmvGsSi}hixnhomkmlp"ixRiffjvUn tesGvRmn v)vRmlzs)lzjmfhxwn vRlpfj,|Lfrmozk,iKrmsSiffket&vRmiP$lznhopfhqr'iEnhjyn qhixff~iffw\fjmsSvSxn vRlzj'q8vRmir'vRlzozlzvt&fhZvR'iPa;fjvR'iPk'iff|lsRlpfj\vSfCvSxnhjmsSixnJ|nhozoj'iff|LiffsRsRn xloptOlzj}hfoz}hiffsPiL'nhwMlzjylzj'qvRmiCvSxnhkmif snhw\fjmqJkmlp"ixRiffjvgelzjykms*fhGixxRfhxs mlzsPlzsiff|nhrmsSiPi}hixRt6|nhozoyvRmn vUvR'iCf sRtesSvSiffw|nhjJmnhjmkmozisRrm||LiffsRsRrmoopt\sRnff}hiffsKnC|Lfw\dynhjtMvR'i$|LfsSvfhGrmsRlj'qMnMermwMnhj|rysSvSfw\ix$|n xRiCn qhiffjvPvSfJmnhjmkmozivR'iC|nhozoH ermsyai&|nhjEnhsRsRfe|lzn vSi&vRmlzs|LfsSvlpvRvR'i6k'iff|lsRlpfjvRmn v wMn ghiffs&vSfvSxnhjmsRixCvR'i6|nhozoHJ'iffj Cf vSxnhjmsSixsIvR'iJ|nhozormjmjmiff|LiffsRsRn xlzozthUi$|nhooyvRmlsa|LfsSv5vR'i p ~ Hh \ UjvR'ifhvR'ix*mnhjykZi}hixRtJ|nhozovRmn vn vSvSiffw\dmvRs$vSfOmnhjykmopi8nhjmkEnhlzozsafrmokdfhvSiffjvRlznhozoptOnh||Lxr'i\nJkmlixRiffjvP|LfsSvjmnhwMiffoptOvR'iopfsSvCxRi}hiffjer'i6xRfw|rmsSvSfw\ixs8mfiff|Lfw\i0lpxRxlpvRn vSiffklpvRnhrmozvt|rmsSvSfwMix,sRixR}el|Li6nhjmkvRn ghivR'ifflpxrmsRlzj'iffssPiffosSi'ixRih,i|nhoovRmlzs|LfsSvIvRmi0 SJ MjvR'i\xRiffsrmopvRs$vRmn vUidmxRiffsRiffjvSiffk'ixRih"ai&xRidfhxRvPfjmoptOf }hixnhozonh||r'xnh|LtxRiffsrmopvRsnhjykvSxRiffn v p * Hh \ nhjmknhsPiffermnhozozt|LfsSvRopthfai}hix lzjnhjtdn xRvRlz|rmozn xlzjmsSvRnhoozn vRlpfjfh~vR'iCfsStusSvSiffwO"vR'ixRi&wMnffti&kmlixRiffjm|Liffs*iv aiiffjvR'iffsSi,|LfsSvRsvRmn vPafrmokj'iiffkEvSf6i&nh||LfrmjvSiffkfhxlzj\vRmi*vSxnhlzjmlj'q$fh"vRmi~$DvGUfrmozk\iKdfsRsRlpopi5vSf8rmsSCBEBE8ED0vSf&k'fvRmlzsfflp"vR'iffsSiP|LfsRvRsGUixRiguj'f j't0rmsRlzjmq,lzvRs*n ylzozlzvtvSf}n xRtJvR'i8ozfsRsKxn vRlpf'VT 2fi>72> 9?f7A@d.22j'fhvR'ixdfhvSiffjvRlznho)lzsRsRrmi8fhxr'vRrmxRiCUfhxRglzsvR'iMr'vRlzozlzvtOfhanOkylznhopfhqr'i,opi}hiffoDdmxRiffkml|LvSfhxffZih q'vR'ia$-~}es?nhjr'vSvSixnhjm|Liopi}hiffoKdmxiffkmlz|LvSfhxffaih q'?vR'i H u- &dyxRiffkmlz|LvSfhxffafhx6vR'iqhfnhofhanhrmvSfwMn vRlz|nhozoptEnhkmn dmvRlzj'q0nJsStesRvSiffwOskmlznhopfhqrmi&sSvSxn vSiqhth mlzslzs$sR'fjEvSfO"iCiL"iff|LvRlz}hilzj -lpvRwMnhj nhjZI hhC'ixRivR'itrmsSindmxRfhyopiffwn vRlz|kmlznhopfhqr'ikmivSiff|LvSfhxElzjfhxkmixvSfnhkmn dmvCvR'ikmlnhopfhqr'isSvSxn vSiqhtfhx&nvSxnhljiffjmermlpxRtsStusSvSiffwO0 v8afrmokiMdfsRsRlpyozihnhjmkfhvRmixsmn }hin xRqr'iffki}hf 8ffhheMPlzxsR|ixRqivnho/pMffhheN8lpx|y'f h' vRmn vvR'ikylznhopfhqr'iwMnhjmn qhix snhkmn dmvRn vRlzfjk'iff|lzslpfjms\|nhjiwMnhkmifjvR'iynhsRlzs,fhopfu|nhoKiffmnff}ulpfhxff5l/ ihfjvR'iynhsRlsGfhZxRiff|Lfhqjmlzfflzj'q8vRyn vavR'i|r'xRxRiffjvarmvSvSixnhjm|Li$mnhs~iiffjJwMlzsRryjmk'ixsSvSfefukZhfhxavRyn vavR'i|r'xRxRiffjvr'vSvSixnhjy|LilzsCn|LfhxRxiff|LvRlpfjZPf Ui}hixffKlpv,lzsC|oziffn x\vRmn v\vR'i0k'iff|lzsRlpfj;vSfvSxnhjmsRix,vR'iO|nhozoUvSfnermwMnhjO|rmsSvSfwMix*|n xRiIn qhiffjvP|nhjmj'fhvKiwMnhk'i$fjOvR'i$ynhsRls5fhfjmoptJopfu|nho"lj'fhxwMn vRlpfjJiff|nhrmsSivR'iJsStesRvSiffw|nhjfhvSiffjxRiff|Lf}hix&xRfwnsRlzjmqopi\ixRxRfhxff ermsDUiiLud"iff|LvCvRmn v8vRmi6n ylzolpvtvSfEin yopi,vSf0dmxRiffkylz|LvPvRmiMkmlznhopfhqr'i&fr'vR|Lfw\iMnhs$UiMk'fO'ixRi,lozo|LfjvRlzjer'i,vSfO"i,lzw\dfhxRvRnhjv$i}hiffjlzjsStusSvSiffwMsKvRyn vrmsSiIopfu|nhoZdmxiffkmlz|LvSfhxs5fhxrmjmkmixsSvRnhjmkmlj'q&nhjyk|LfhxRxRiff|LvRlpfj|Yzx] ^a}^ Q _aQy]f fj~xnhsRs$lznhjmilpvRwnhjZl|mn xkc'r'vSvSfjZ-n fflzjK PnhmlzwnhjmkElz|mn iffoRiffn xjmsmnhjmges$vSfhxkmlzsR|rysRsRlpfjmsUfjO} n xlpfrysKnhsSdiff|LvRs*fhvRmlzs5UfhxRg"uQ~/QQy] QP"iffooznuyCpfhxlzjy8)ffhhIUfjmsSvSxry|LvnhopqhimxnuKjEnhjynhoptvRl|nhow\ivR'fukEfhx$kmlznhopfhq6wMnhjun qhiffwMiffjvmj SffRZ / _ [ L\ [ ]Z/ I\ [u ] /hh^h" H "Z /5n qhqlznuDp-5nhsSvRn qj'ixl/&p $nhjmlziffozl/)ffhhClpiffozk xlznhozsPfhGvR'i, Rv nholznhjE' *Rc x nhlzjlzw\ivRn yopiCcutesSvSiffw~j fhSm / _ R [ p}Zh#I _ LzRr+ yhh ]5 !// z c_%_]Iudmdys eUxlpiffwMnhj~Gp5'xlpiffkywMnhjZ { Cp*$ozsR'iffjR IGCp5cevSfjmih5 { KffhN "ZhR / _ GnhkmsSUfhxRvRnhjykUxRffhgusyEfjvSixRitE5nhozlpfhxjmlnu5n vRopivSv{ ffhu GEiqnhlzjmkyrm|LvRlpfjZGvSiffsRvlpqvjX Z /I\[u5Zr[e\[My"hhh<ISM [ R mZ5eru5n xRxfozo/ { p'5n xRdiffjvSixff'ffhh)iff|LvSfhxSHnhsSiffkjmn vRr'xnhooznhjmqrmn qhi|nhooxfr'vRlzj'q'& h" H " 1Z h7;hu81;hUf'iffj "ffhh-ynhsSv~iLiff|LvRlp}hixrmopiljmkmrm|LvRlpfjmj SffR Z /I\[uh<ISM [ R mZ_ IL\[,y"hhUf'iffj" ~ffhh,iffn xjmlj'q6vSxiiffsInhjmkxrmopiffsPlpvRsSivH} nhozr'iffkiffn vRr'xRiffsffIjO Ly\[IffLRL",/I8\[' ] L ]$ ffffh/ /I ] aff yL#Z*PwMwlz|veCe&puopfjmsSf' ffhh8j'f oziffk'qhi|Lfozopiff|LvRlzfjMfhxajmn vRr'xnhoyoznhj'qryn qhisSdfhghiffjkylznhopfhq8sStusSvSiffwMsff"j Z /P\'[ ' Rh <ffI LRL"Ih h [ r+ m/h _ [ " hZVT!fi2Zy222 S2-7M1m72mr'xj'gxnhj'h { pmlzkmwMixff',Zffh~jm|Lxiffw\iffjvRnho"xRiffkyrm|LiffkJixRxRfhx5dmxrmjylzj'q'ZjX Z /I\ [' 5z y\[V8 " pIS, [" R mZfhxljZCph lz||n xkml/&pxlzqvh-h< ;ff{effhh'fEn tIiffozd8Gfrqm [hb m/h/lpxsR|ixRq' { mpy-lpvRwMnhjZm& { p ceUixRvRsm-ffhha~xRfsSfukmlz|$|r'iffsKvSfMxiff|LfhqjmlpvRlpfj0ixRxfhxs6j ffG/I8\[' ] HrMh [ }Zm/ h "L H " 1Z [elpxsR|ixRq' { pGlpvRwnhjZ)C { p)ceUixRvRs)*/ hhiffj'ixnhozlzfflzj'qdmxfsSfekylz|Mdmxiffkmlz|LvRlpfjfhsSdiiff|xRiff|LfhqjylpvRlpfjixRxRfhxsj Z /IO\[uT \[Lh/ h<IS/I1Z < ZZY -u K Gzff8lpxsR|ixRq' { upu-lpvRwMnhjZu& { p'cuaixRvRsffuZ/ h'nGPivSiff|LvRlj'q\wMlzsSxRiff|LfhqjylpvRlpfjmsUnhjmkJ|LfhxSxiff|LvRlpfjms)lzj&sSdfhghiffj\kmlznhopfhqrmiUsStusSvSiffwMsDxRfwnff5n xRihsRlzvSiffs'j" ff 1Z /I*\[uVh [eh ff 0 h [ } Zm ; "L H " 1ZlpxsR|ixRq' { DPpG-lpvRwMnhjZ& { pG ceUixRvRs)5/ h'Lk'iffjvRlztulzj'qrysSixC|LfhxRxiff|LvRlpfjms,nhruvSfwn vRlz|nhozoptlzjsSdfhghiffjkmlnhopfhqr'i\sStusSvSiffwO\j, SffR Z /IM\[u ffZ/I\['C L\ [ ] L [e &/ IC\ [u ]$ ffffh " H " Z /Ilpx|m'f M/ h' e|Lfw\dyn xlzsSfjfhu|oznhsRsRlp|n vRlpfjvSiff|mjmlzer'iffsZfhxvR'ianhr'vSfwMn vRlz|GkmivSiff|LvRlpfj8fhixxRfhx~|LfhxRxRiff|LvRlzfjms~lzj\ermwMnhj'|Lfw\dyr'vSixGkmlnhopfhqr'iffsjQ ff 1Z {\u[ 'C L\[ ]L] e[ ] H W$L Zff0Z /C\u[ - ]')xnhyw\ixfffip'ceUixRvRsep 'iffrmjmihpeiiqhiffos'ffhh nGxRfhopiffw sSdfhvSvRlzj'qClzj\rywMnhjuwnh|mlzjmiIlzjvSixnh|LvRlpfjZGj6 Sff H R[ ffxnhyw\ixffp$ceUixRvRs$p iffrmj'ihPpiiqhiffozs8ffhh~xRfsSfukmlz||LfhxRxRiffozn vSiffsOfhkylzsR|LfjuyxwMn vRlpfjmsj #] [e hCyLSff\ 8 p}Z 5C ffnhjmqhgelzok'ihKpPnhopghixffKCpxlpqv { pfhxljZCplpvRwnhjZ*&ffhhPr'vSfwn vRlz|dyxRiffkmlz|LvRlpfjfh*dmxRfhopiffwMn vRlz|6rmwnhju|Lfw\dyr'vSix,kmlznhozfhqr'iffsCljPf nfftIPiffopd;GfrqEjZ / I*\ ['aR [u ] Hr Mh/ h R [ } Zm/ " HZ ce]$ zi}hfI& Cuffhhy5yn xnh|LvSixlpfflzjmqnhjmkIxiff|Lfhqjmlpfflzj'qsSdfhghiffj8|LfhxRxiff|LvRlpfjmsDlzj8ermwMnhju|LfwMdyr'vSixkylznhopfhqr'ihUSj SffRZ / IC\ [u \ [ ] ff1ZO/ IC\ [u ]$ ffffh/ { r H/ hZ / 'dmdr ;h uelzvRwMnhjZm& { pPlpxsR|ixRq' { ypceaixvRsy-/ hhKGxRiffkml|LvRlzj'q\nhr'vSfwMn vRlz|CsSdiiff|Oxiff|LfhqjylpvRlpfjd"ixfhxwnhjm|Li6rmslzj'qdyxRfsSfukmlz|M|r'iffsffj SffR Z {IJ\[u Z{I0\['C L\ [ ] L [e &/ IC\ [u ]$ ffffh " H " Z /lzvRwMnhjZ& { pZ nhjZc"/ hhGxRiffkml|LvRlzj'qnhjmknhkmn dmvRlj'qvSfJdffhx$sSdiiff|ExRiff|LfhqjmlpvRlzfjElzjnsRd"fhghiffjkmlznhopfhqr'i*sRtesSvSiffwyjV Sff/IP\[u yy\[\8 " h<IS$h ] affL# Z c]]'] GzfflzvRwMnhjZuC { pnhopghix m'Cp' iffn xjmsu { Zffhh)PrmvSfwMn vRlz|$k'ivSiff|LvRlpfj0fhdfefhxUsRd"iiff|xiff|LfhqjmlpvRlpfj\n v)vR'i*kylznhopfhqr'i5opi}hiffo/'jQ SffR Z /I*\[u _ [ hLy\[ ] ff1Z{ I8\ [u ] /hh/ r Hh/ Z 'dmd=; 1;uffeVT&fi>72> 9?f7A@d.22l||n xkml/~&pGfhxlzjC*/ hh;cedfhghiffjoznhj'qrmn qhiOnhkmn dyvRn vRlpfj;f }hixMvRlzwMi6nhjmksSvRn vSilzj;njyn vRr'xnhoGsSdfhghiffjkylznhopfhqOsStusSvSiffwO R _ ff/ h] / Sff Z[; ucunhjmkmixwMnhjZGCp5cevRrmxwO { p~k'iffj$st*paUf}hiffsKGpUUxiffw\ixs~CffhhG} nhozrmn vRlzfjfhvRmikmrmvR|vSxnhlzj?vRlzw\ivRn yopilzj'fhxwMn vRlzfjsStusSvSiffw k'i}hiffopfhdiffklzjvRmi' *RcdmxRf Siff|Lv jLSff\_ [h} Z+IL _ pr + mh/ ]5 !/h/ zc _%_1]dydu8ceiffj'iLc"peZr'ihCp-folpxfjml/ { pn f'u$pivR'ixlzj'qhvSfjZ~pfukmk'iffnhrZ&poznhsRs { 'ffhh'iMdmxRiffolzwMlzjmn xtk'i}hiffopfhdywMiffjvIfh*nkmlzsSdyonfftuopiffsRsa5$c:$csStesRvSiffwO6j ] ]hZ p Z _ R [ p} Zh[ecu'xlpixRq'ep)nhk'ihapa~xlz|LihGD*ffhhrmwMnhjuwMnh|mlzj'i6dmxRfhyoziffwsSfoz}elzjmqErmsRlj'qsSdfghiffjonhj'qrmn qhi,sStesRvSiffwMs\HcuDcmmnh|LvSfhxs8n"iff|LvRlzjmqJdixRfhxwMnhjy|LiCnhjmkrmsSix$sRn vRlzsRnh|LvRlpfjjZ / I8\ [u ] ] h R [E )[u ydyd' e'ceUixRvRsKp*lpvRwMnhj5& { p*lpxsR|ixRq' { ~/ hh UfhxxRiff|LvRlpfjms6lzjsSdfhghiffjkylznhopfhqr'isRtesSvSiffwsj Z /I$\[u \[yLh/ h<IS&/I h L hZ <Ze5 GffffZS -u*nhopghixffZ8pmxRfw\ixff { Zpn xnfftnhjmnhjDc")ffhhCiffn xjmlzj'qJfhdmvRlzwMnhoDkmlznhozfhqr'i&sRvSxn vSiLqlziffs8|nhsSisSvRryk'tEfhKnsRd"fhghiffjkmlznhopfhqr'iMn qhiffjv8fhxIiffwMnhlo/\j+ SffR Z /I\[u \[] " ZO/ IC\ [u ]$ ffff ;/ r Hh/ Z c& ~ RQ ]) ffdyd< ; < ;hhenhopghixff'Cp18nhwMwOu$8p'-lpvRwMnhjZe& { / hhhn f 5n xkmsUk'i}hiffopfhdylj'qIqhiffj'ixnhow\fuk'iffozsfh"rmsRn ylozlpvtPlpvRC'c mj Ch hZ <Ze$KZh"LZ h / e )$ff/& 68 p} Znhopghixffa8p)-nhj'qhgelozk'ihpxlzqv { pG$fhxlzjZ)Cp~-lpvRwMnhjZ)&5/ hh iffn xjmlzjmqvSf~xRiffkmlz|LvUGxRfhopiffwMn vRlz|$culpvRrmn vRlpfjysGlzjn\cedfhghiffjJlnhopfhqr'i$cutesSvSiffwGedixlw\iffjvRs~lpvR6fnfftEPiffopdGfr hYj SffRhZ / I&\ ['ZC \ [ ] LZ{ I&\ [u ]$ ffff"h H " Z /nhopghixffG8pG-lpvRwMnhjZ)&pRInhwMwO~D8p~ P"iffooznuDCKffhh' Sc- qhiffjmixnhoxnhw\iUfhxRgfhxi}nhozryn vRlzj'q6sRd"fhghiffjkmlnhopfhqr'iCn qhiffjvRsjY SffRhZ /I&\[' h\[ ]ffZ/ I6\ [u ]$ ffff / r Hh/ hZ / c]) ]" GdmdDe8h unhopghixffmCpmxlpqv { py nhj'qhgulzozk'ihe/ hhh| t:sRlzj'q\jmn vRr'xnhoZoznhj'qrmn qhidmxfe|LiffsRslzj'q\nhjmkkylzsR|Lfr'xsRiMiffn vRrmxRiffs8vSflzk'iffjvRlptrmjyk'ixsSvRnhjmkylzj'q0ixRxRfhxsClzjnEsSdfhghiffjkmlnhopfhqr'isStusSvSiffwOOjZ / I8\ [u yy\ [6yLh/ < IffLRL", [" m1ZifflzsRsffIc*p8rmozlpghfsSgul/8ffhu h " _ [uh R qh h\ [eff Ih Hh / c & Cff c[ m1Z c RKcunhjn vSif'5CyEfhxRqnhj 8nhr'wnhjmjZxlpqvC$/ hh L#Z ff /; A8/ Z O<I zMh/ UIL] HrMh/ h R[RZhmh UaZ&mvR'iffsRlsE:Pjylp}hixsRlpv tfh~kylzjr'xRqZVT 3fiJournal Artificial Intelligence Research 16 (2002) 135-166Submitted 7/01; published 2/02Improving Eciency Inductive Logic ProgrammingUse Query Packshendrik.blockeel@cs.kuleuven.ac.beHendrik BlockeelKatholieke Universiteit Leuven, Department Computer ScienceCelestijnenlaan 200A, B-3001 Leuven, Belgiumluc.dehaspe@pharmadm.comLuc DehaspePharmaDM, Ambachtenlaan 54D, B-3001 Leuven, BelgiumBart DemoenGerda JanssensJan Ramonbart.demoen@cs.kuleuven.ac.begerda.janssens@cs.kuleuven.ac.bejan.ramon@cs.kuleuven.ac.beKatholieke Universiteit Leuven, Department Computer ScienceCelestijnenlaan 200A, B-3001 Leuven, Belgiumhenk.vandecasteele@pharmadm.comHenk VandecasteelePharmaDM, Ambachtenlaan 54D, B-3001 Leuven, BelgiumAbstractInductive logic programming, relational learning, powerful paradigm machinelearning data mining. However, order ILP become practically useful,eciency ILP systems must improve substantially. end, notion query packintroduced: structures sets similar queries. Furthermore, mechanism describedexecuting query packs. complexity analysis shows considerable eciencyimprovements achieved use query pack execution mechanism.claim supported empirical results obtained incorporating support querypack execution two existing learning systems.1. IntroductionMany data mining algorithms employ extent generate-and-test approach: largeamounts partial complete hypotheses generated evaluated datamining process. evaluation usually involves testing hypothesis large data set,process typically linear size data set. Examples data miningalgorithms Apriori (Agrawal et al., 1996), decision tree algorithms (Quinlan, 1993a;Breiman et al., 1984), algorithms inducing decision rules (Clark & Niblett, 1989), etc.Even though search hypothesis space seldom exhaustive practicalsituations, clever branch-and-bound greedy search strategies employed, number hypotheses generated evaluated approaches may still huge.especially true complex hypothesis space used, often case inductivelogic programming (ILP), sheer size hypothesis space importantcontribution high computational complexity ILP approaches. computational complexity reduced, however, exploiting fact manysimilarities hypotheses.c 2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & VandecasteeleILP systems build hypothesis one clause time. search single clauseconcerned rest paper, word \hypothesis"usually refer single clause. clause search space typically structuredlattice. clauses close one another lattice similar, computationsinvolved evaluating similar well. words, many computationsperformed evaluating one clause (which boils executing queryconsisting body clause) performed evaluatingnext clause. Storing certain intermediate results computation later use couldsolution (e.g., tabling XSB Prolog engine, Chen & Warren, 1996), mayinfeasible practice memory requirements. becomes feasiblesearch reorganised intermediate results always used shortlycomputed; achieved extent rearranging computations.best way removing redundancy, however, seems re-implement executionstrategy queries way much computation possible effectivelyshared.paper discuss strategy executing sets queries, organised so-calledquery packs, avoids redundant computations. strategy presented adaptation standard Prolog execution mechanism. adapted execution mechanismimplemented ilProlog, Prolog system dedicated inductive logic programming. Several inductive logic programming systems re-implemented make usededicated engine, using new implementations obtained experimentalresults showing cases speed-up order magnitude. Thus,work significantly contributes applicability inductive logic programming realworld data mining tasks. addition, believe may contribute state artquery optimisation relational databases. Indeed, latter field lotwork optimisation individual queries relatively small sets queries, muchless optimisation large groups similar queries, understandablyget much attention advent data mining. Optimisation groups queriesrelational databases seems interesting research area now, believe techniquessimilar ones proposed might relevant area.remainder paper structured follows. Section 2 precisely describeILP problem setting work set. Section 3 define notionquery pack indicate would executed standard Prolog interpretercomputational redundancy causes. describe execution mechanismquery packs makes possible avoid redundant computations would arisequeries pack run separately, show implemented makingsmall significant extensions WAM, standard Prolog execution mechanism.Section 4 describe query pack execution strategy incorporated twoexisting inductive logic programming algorithms (Tilde Warmr). Section 5present experimental results illustrate speed-up systems achieveusing query pack execution mechanism. Section 6 discuss related workSection 7 present conclusions directions future work.136fiImproving Efficiency ILP Query Packs2. Inductive Logic ProgrammingInductive logic programming (Muggleton & De Raedt, 1994) situated intersectionmachine learning data mining one hand, logic programminghand. shares former fields goal finding patterns data, patternsused build predictive models gain insight data. logic programmingshares use clausal first order logic representation language datahypotheses. remainder text use basic notions logicprogramming, literals, conjunctive queries, variable substitutions. useProlog notation throughout paper. introduction Prolog logic programmingsee Bratko (1990).Inductive logic programming used many different purposes, problemstatements found ILP papers consequently vary. article consider so-calledlearning interpretations setting (De Raedt & Dzeroski, 1994; De Raedt, 1997).argued elsewhere setting, slightly less powerful standardILP setting (it problems with, e.g., learning recursive predicates), sucientpractical purposes scales better (Blockeel et al., 1999).formulate learning task way covers number different problemstatements. specifically, consider problem detecting set conjunctivequeries instantiations certain variables query succeeds. variablescalled key variables, grounding substitution called key instantiation.intuition example learning task uniquely identified single keyinstantiation.link ILP systems learn clauses follows. search performedILP system directed regularly evaluating candidate clauses. Let us denotecandidate clause Head(X )Body (X; ) X represents vector variablesappearing head clause represents additional variables occurbody. assume head single literal list examples given,example form Head(X ) substitution grounds X . Examplesmay labelled (e.g., positive negative), essential setting.example represented fact Head(X ) learning definite Horn clauses,also consider tuple X. notations used paper.Intuitively, positive negative examples given, one wants find clausecovers many positive examples possible, covering negatives.Whether single example Head(X ) covered clause determinedrunning query ? Body(X; ). words, evaluating clause boilsrunning number queries consisting body clause. simplicity notation,often denote conjunctive query conjunction (without ? symbol).less typical ILP settings, ILP algorithm search Horn clausesrather general clauses, e.g., Claudien (De Raedt & Dehaspe, 1997) frequentpatterns expressed conjunctive queries, e.g., Warmr(Dehaspe & Toivonen,1999). settings handled approach well: needed mappinghypotheses queries allow evaluate hypotheses. mappingdefined De Raedt Dehaspe (1997) Claudien; Warmr trivial.137fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & VandecasteeleGiven set queries set examples E , main task determinequeries Q 2 cover examples e 2 E . formalise using notion resultset:Definition 1 (Result set) result set set queries deductive databasekey K example set E ,RS (S; K; D; E )= f(K; i)jQi 2 K 2 E Qi succeeds DgSimilar learning interpretations setting defined (De Raedt, 1997),problem setting stated as:Given: set conjunctive queries , deductive database D, tuple K variablesoccur query S, example set EFind: result set RS (S; K; D; E ); i.e., find query Q groundinstantiations K K 2 E Q succeeds D.Example 1 Assume ILP system learning definition grandfather/2 wants evaluate following hypotheses:grandfather(X,Y) :- parent(X,Z), parent(Z,Y), male(X).grandfather(X,Y) :- parent(X,Z), parent(Z,Y), female(X).Examples form grandfather(gf ,gc) gf gc constants; henceexample uniquely identified ground substitution tuple (X; ).problem setting set Prolog queries equals f(?- parent(X,Z), parent(Z,Y),male(X)), (?- parent(X,Z), parent(Z,Y), female(X))g key K equals (X; ).Given query Qi 2 , finding tuples (x; y) ((x; y); i) 2 R (with R resultset defined above) equivalent finding grandfather(x,y) factsexample set predicted clause grandfather(X,Y) :- Qi .generality problem setting follows fact knownqueries succeed examples, statistics heuristics typical ILP systemsuse readily obtained this. examples:discovery frequent patterns (Dehaspe & Toivonen, 1999): query Qinumber key instantiations succeeds needs counted, i.e.,f req (Qi ) = jfK j(K; i) 2 Rgj R result set.induction Horn clauses (Muggleton, 1995; Quinlan, 1993b): accuracyclause H :- Qi (defined number examples body head hold,divided number examples body holds) computedjfKj(K;i)2R^Dj=Hgj R result set.jfKj(K;i)2Rgjinduction first order classification regression trees (Kramer, 1996; Blockeel &De Raedt, 1998; Blockeel et al., 1998): class entropy variance examplescovered (or covered) query computed probability distributiontarget variable; computing distribution involves simple counts similarones above.138fiImproving Efficiency ILP Query Packstransforming grandfather/2 clausesgrandfather((X,Y)),I) :- parent(X,Z), parent(Z,Y), male(X), = 1.grandfather((X,Y)),I) :- parent(X,Z), parent(Z,Y), female(X), = 2.result set clearly computed collecting grounding 's K 2 Eanswers query ?- grandfather(K,I) . Section 3 queries literal= end another goal side-effects results collecting result set.practice, natural compute result set using double loop: one examplesone queries one choice outer loop. \examplesouter loop" \queries outer loop" used data mining systems;context decision trees, see instance Quinlan (1993a) Mehta et al. (1996).shall see redundancy removal approach propose uses \examplesouter loop" strategy. approaches however, given query key instantiation,interested whether query succeeds key instantiation. impliesparticular query succeeded example, execution stopped.words: computing result set defined boils evaluatingquery example, interested existence successevaluation. Computing one solution one query one example unnecessary.3. Query Packssimplicity, make abstraction existence keys following examples.relevant here, query interested whether succeeds not,finding answer substitutions.Given following set queriesp(X),p(X),p(X),p(X),p(X),= 1.q(X,a),q(X,b),q(X,Y),q(X,Y),= 2.= 3.t(X), = 4.t(X), r(Y,1), = 5.choose evaluate separately. Since interested one { first {success query, would evaluate Prolog queriesonce((p(X),once((p(X),once((p(X),once((p(X),once((p(X),= 1)).q(X,a), = 2)).q(X,b), = 3)).q(X,Y), t(X), = 4)).q(X,Y), t(X), r(Y,1), = 5)).wrapper once/1 pruning primitive prevents unnecessary searchsolutions. definition Prolog simplyonce(Goal) :- call(Goal), !.139fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteelealternative way evaluate queries consists merging one (nested)disjunction in:p(X), (I=1;q(X,a), I=2;q(X,b), I=3;q(X,Y), t(X), (I=4;r(Y,1), I=5)).set queries evaluated whole: success one branchdisjunctive query corresponds success corresponding individual query.Compared evaluation individual queries, disjunctive queryadvantage disadvantage:+ queries prefix p(X), evaluated individualquery, disjunctive query, goal p(X) evaluated once; dependingevaluation cost p/1, lead arbitrary performance gains.usual Prolog pruning primitives powerful enough prevent unnecessary backtracking branch disjunctive query succeeded;explained Example 2.Example 2 example literalscontribute discussion:= left out,p(X), q(X).p(X), r(X).Evaluating queries separately means evaluatingonce((p(X), q(X))).once((p(X), r(X))).equivalentlyp(X), q(X), !.p(X), r(X), !.corresponding disjunctive queryp(X), (q(X) ; r(X)).try place pruning primitive disjunctive query: !/0 endbranch resultsp(X), (q(X), ! ; r(X), !)scope first cut clearly large: goal q(X) succeeded, cutprevent entering second branch. means adding cut disjunctivequery leads wrong result.Using once/1 disjunctive query resultsp(X), (once(q(X)) ; once(r(X)))140fiImproving Efficiency ILP Query Packsresults correct query. However, branches still executed everybinding goal p(X) produces, even branches succeeded already.combination advantage disjunctive query advantageindividual query pruning (once cut) results notion query pack. Syntactically, query pack looks like disjunctive query ; control constructreplaced new control construct denoted or. query pack correspondingdisjunctive queryp(X), (I=1q(X,a), I=2q(X,b), I=3q(X,Y), t(X), (I=4r(Y,1), I=5))query pack represented tree Figure 1. query pack Qtree literals conjunctions literals nodes. path root leafnode represents conjunctive query Q member Q, denoted Q 2 Q.construct implicit branching points.p(X)I=1q(X,a),I=2q(X,b),I=3q(X,c),I=4I=5q(X,Y), t(X)r(Y,1),I=6r(Y,2),I=7Figure 1: query pack.intended procedural behaviour construct branch succeeded, effectively pruned away pack evaluation query packcurrent example. pruning must recursive, i.e., branches subtreequery pack succeeded, whole subtree must pruned. Evaluationquery pack terminates subtrees pruned remainingqueries fail example.semantics construct ecient implementation subjectrest section. however clear already caseanswers query needed, pruning cannot performed disjunctive queryalready sucient, i.e., query packs useful single success per query suces.3.1 Ecient Execution Query PacksSection 3.1.2, meta-interpreter given defines behaviour query packs.practice meta-interpreter useful, many cases meta-interpretercauses overhead use query packs compensate for. Indeed, previouslyreported results (Demoen et al., 1999; Blockeel, 1998) indicate overhead involvedhigh-level Prolog implementation destroys eciency gain obtained redundancyreduction. Moreover discussed Section 3.1.2, meta-interpreterdesired time-complexity. shows desired procedural semantics141fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteeleimplemented Prolog itself, desired performance Prolog lacksappropriate primitives.conclusion changes needed level Prolog engine itself.requires extension WAM (Warren Abstract Machine) underlyingabstract machine Prolog implementations. extended WAM providesoperator discussed above: permanently removes branches packneed investigated anymore. extended WAM become basis new Prologengine dedicated inductive logic programming, called ilProlog. section continuesintroduction basic terminology query packs explains high levelquery pack execution works. Next meta-interpreter query pack executiongiven finally changes needed WAM clarified.3.1.1 Principles Query Packs (Execution)discuss query pack execution detail, note following two points: (1)pack execution, pruning branch must survive backtracking; (2) executingpack interested variable instantiations, whether memberpack succeeds not. previous description interested bindingvariable I. Since branch bind one value { query number { collectvalues practice side effect denoted Section 3.2 report success.starting point query pack execution mechanism usual Prolog executionquery Q given Prolog program P . backtracking Prolog generatesolutions Q giving possible instantiations Q succeeds P .query pack consists conjunction literals set alternatives,alternative query pack. Note leaves query packs empty setalternatives. query pack Q, conj (Q) denotes conjunction children(Q)denotes set alternatives. set queries represented so-called root querypack. every query pack Q, path query packs starting root querypack Qroot ending query pack itself, namely < Qroot , Q1 , ..., Qn , Q >.query packs path predecessors Q. Every query pack set dependentqueries, dependent queries(Q). Let < Qroot , Qi1 , ..., Qin , Q > path Q,dependent queries(Q) = fconj (Qroot ) ^ conj (Qi1 ) ^ : : : ^ conj (Qin ) ^ conj (Q) ^ conj (Qj1 ) ^: : : ^ conj (Qjm ) ^ conj (Ql ) j < Q; Qj1 , ..., Qjm , Ql > path Q leaf Ql g. Notedependent queries(Qroot ) actually members query pack describedearlier.Qroot root tree. conj (Qroot )Qroot ) contains 4 query packs correspond treesExample 3 query pack Figure 1,p(X ). set children(rooted 4 sons root tree. Suppose query packs named (fromleft right) Q1 , Q2 , Q3 , Q4 . conj (Q2 ) equals (q(X; a); = 2), children(Q2 )equals empty set, conj (Q4 ) equals (q(X; ); t(X )), dependent queries(Q4 ) equalsf(p(X ); q(X; ); t(X ); = 4), (p(X ); q(X; ); t(X ); r(Y; 1); = 5)g.Execution root query pack Qroot aims finding queries setdependent queries(Qroot ) succeed. query pack executed ors usualdisjunctions, backtracking occurs queries already succeeded many142fiImproving Efficiency ILP Query Packs01234567891011execute qp( pack Q, substitution ) f( next solution( conj (Q))fQchild children(Q)fgg( execute qp( Qchild , ) == success)children(Q)children(Q) n fQchild g( children(Q) empty set) return(success)return(fail)gFigure 2: query pack execution algorithm.successes detected. avoid this, case soon query succeeds,corresponding part query pack longer considered backtracking. approach realises reporting success queries (and query packs)predecessors query pack. (non-root) query pack Q safely removedqueries depend (i.e., queries dependent queries(Q)) succeeded once.leaf Q (empty set children), success conj (Q) sucient remove it.non-leaf Q, wait dependent queries report success equivalentlyquery packs children(Q) report success.start evaluation root query pack, set children every querypack contains alternatives given query pack. execution, querypacks removed children sets thus values children(Q) changeaccordingly. due backtracking query pack executed again, might casefewer alternatives considered.execution query pack Q defined algorithm execute qp(Q; ) (Figure2) imposes additional control usual Prolog execution.usual Prolog execution backtracking behaviour modelled loop(line 1) generates possible solutions conjunction query pack.solutions found, fail returned backtracking occur levelcalling query pack.additional control manages children(Q). solution , necessarychildren Q executed. important notice initial set childrenquery pack changed destructively execution algorithm. Firstly,leaf reached, success returned (line 8) corresponding child removedquery pack (line 6). Secondly, query pack initially several children, finallyends empty set children (line 6), also query pack removed (line 8).fact children destructively removed, implies due backtrackingquery pack executed different , alternativesinitially there, executed more. Moreover, returning success143fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteeleqp(1)ch(1)ch(3)ch(2)b qp(2)ch(1)fq(4)g qp(3)ch(1)ch(3)ch(2)c q(1)q(2)ch(3)ch(2)e q(3)h q(5)q(6)jq(7)Figure 3: Query pack numbers qp(i), Query numbers q(i) Child numbers ch(i)example.backtracking current query pack conjunction conj (Q) stopped: branchesreported success.3.1.2 Meta-interpreter Query Packsfirst implementation query pack execution algorithm meta-interpretermeta execute qp(Q). meta-interpreter uses following labelling representationquery pack:Query pack number non-leaf query packs tree numbered, depthfirst, left right (qp(i)).Query number leaf numbered, left right. original queriesnumbered sequentially, numbers leaves correspond (q(i)).Child number non-leaf query pack N children, children numbered1 N sequentially (ch(i)).Consider query pack a, (b, (c e) f g, (h j)). Noteatoms example could general arbitrary conjunctions non-ground terms.labelling shown Figure 3.labelled query pack Q represented Prolog term follows (with Qffather Q):leafQ represented term (c; leaf (qpnbf; chnb; qnb)) c conj (Q),query pack number Qf , chnb child number Q w.r.t. Qf , qnbquery number Q.non-leaf Q represented term (c; or(cs; qpnbf; qpnb; chnb; totcs) cconj (Q), cs list children(Q), qpnbf query pack number Qf , qpnb querypack number Q, chnb child number Q w.r.t. Qf , totcs total numberchildren(Q)). query pack number father root query packassumed zero.qpnbf144fiImproving Efficiency ILP Query Packsexample Figure 3 following representation (as Prolog term):(a, or([(b,or([(c,leaf(2,1,1)),(d,leaf(2,2,2)),(e,leaf(2,3,3))],1,2,1,3)),(f,leaf(1,2,4)),(g,or([(h,leaf(3,1,5)),(i,leaf(3,2,6)),(j,leaf(3,3,7))],1,3,3,3))],0,1,1,3))execution meta-interpreter, solved/2 facts asserted. factsolved(qpnb, chnb) denotes child number chnb query pack numbersucceeded. facts asserted reaching leaf also childrenquery pack succeeded. meta-interpreter executes childrensolved/2 fact asserted.Note time-complexity meta-interpreter yet desired. Executionquery pack always dependent number original children, insteadnumber remaining (as yet unsuccessful) children.qpnbrun QueryPack(Q) :preprocess(Q, Qlabeled, 0, 1, 1, 1, , ),% code preprocessing given Appendixretractall(solved( , )),meta execute qp(Qlabeled),solved(0, ), !.meta execute qp((A,B)) :- !,call(A),meta execute qp(B).meta execute qp(or(Cs, QpNbF, QpNb, ChildNb, TotCs)) :!, % 'or' corresponds non-leaf query packhandlechildren(Cs, QpNb, 1),solved(QpNb, 0, TotCs),assert(solved(QpNbF,ChildNb)).meta execute qp(leaf(QpNbF, ChildNb , QueryNb)) :!, % 'leaf' corresponds end querywrite(succeed(QueryNb)), nl,assert(solved(QpNbF,ChildNb)).handlechildren([], , ).handlechildren([C| ], QpNb, ChildNb) :not(solved(QpNb,ChildNb)),once(meta execute qp(C)), fail.handlechildren([ |Cs], QpNb, ChildNb) :ChildNb1 ChildNb + 1,handlechildren(Cs, QpNb, ChildNb1).solved(QpNb, ChildNb, TotCs) :(ChildNb = TotCs -> true;ChildNb1 ChildNb + 1,solved(QpNb, ChildNb1),solved(QpNb, ChildNb1, TotCs)).145fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteele3.1.3 WAM Extensionsfully exploit potential query pack (shared computation avoidance unnecessary backtracking) changes made level Prolog engine itself.explanation assumes WAM-based Prolog engine (At-Kaci, 1991) short explanationexecution disjunction Prolog given first, becomes easy seenewly introduced WAM.Assume body clause executed a, (b,c ; ; e). Assume alsopredicates several clauses. moment execution reached firstclause c, choice point stack looks like Figure 4(a): choice pointsactivation a, disjunction itself, b c. choice points linked togetherbacktracking easily pop top one. choice point contains pointernext alternative tried: disjunction choice point, alternative pointershown. points beginning second branch disjunction.alternatives b c exhausted, second branch entered becomesactive: situation shown Figure 4(b). point, alternativedisjunction choice point refers last alternative branch disjunction. Finally,e entered, disjunction choice point already popped.a, (b, c ; ; e)a, (b, c ; ; e)a, (b, c ; ; e);;ebc(a) Choice pointsentering c.(b) Choice pointsentering d.(c) Choice pointsentering e.Figure 4: Illustration execution disjunction WAM.goal produces new solution, branches disjunction must triedagain. exactly want avoid query packs: branch succeeded once,never re-entered. therefore adapt disjunction choice point becomeor-choice point set point data structure contains referencesalternative disjunction. data structure named pack table. Figure5(a) shows state execution reached c: similar Figure 4(a).or-choice point contains information first branch executed.execution proceeds, two possibilities: either first branch succeeds fails.describe failing situation first branch explain happens success146fiImproving Efficiency ILP Query Packssecond branch. first branch solution, backtracking updates alternativeor-choice point, point next branch pack table. situationsecond branch entered shown 5(b) similar 4(b). Supposebranch goal succeeds: entry pack table or-alternativesadapted erasing second alternative branch, backtracking occurs, nextalternative branch or-choice point taken. shown 5(c).produces new solution or-disjunction entered again, pack tablelonger contain second alternative branch never re-entered. packtable actually arranged way entries really removed instead erasedcause overhead later.a, (b, c e)a, (b, c e)a, (b, c e)bec(a) choice pointsentering c.(b) choice pointsentering (the firstbranch succeed).(c) choice pointsentering e (d succeeded).Figure 5: Illustration execution pack disjunction WAM.Two issues must explained: first, pack table alternatives mustconstructed runtime every time query pack entered evaluation. doneemitting necessary instructions beginning code query pack.example, show code query pack a, (b,c e) Figure 6.Finally, example clear moment alternatives ordisjunction succeeded, stop producing solutions. computationstopped. general - nested query packs - means one pack table entrynext higher or-node erased recursive way. recursive removalentries pack tables, done instruction query pack prune.implemented schema ilProlog. Section 5 presents measurementsilProlog.3.2 Using Query PacksFigure 7 shows algorithm makes use pack execution mechanism computeresult set R defined problem statement. set queries typically147fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteeleconstruct pack table @1, @2, @3callquery pack try@1: call bcall cquery pack prune@2: callquery pack prune@3: call equery pack pruneFigure 6: Abstract machine code a, (b,c e) .set refinements given query, i.e., correspond whole hypothesisspace. query pack Q containing queries , derived pack Q0 constructedadding report success/2 literal leaf pack; (procedural) taskreport success(K,i) simply add (K; i) result set R. Obviously specificILP system interested result set could provide report success/2predicate thus avoid overhead explicitly building result set.11 evaluate(set examples E , pack Q, key K ) f2Q0 Q;3q1;4leaf Q0 f5add report success(K, q) right conjunction leaf6increment q7g8C(evaluate pack(K ) :- Q0 );9compile load(C);10example e E f11evaluate pack(e);12g13 gFigure 7: Using query packs compute result set.Note algorithm Figure 7 follows strategy running queriessingle example moving next example: could called \examplesouter loop" strategy, opposed \queries outer loop" strategy used ILP1. current implementation result set implemented bit-matrix indexed queriesexamples. implementation practically feasible (on typical computers time writing) evennumber queries pack multiplied number examples billion, boundholds current ILP applications.148fiImproving Efficiency ILP Query Packssystems. \examples outer loop" strategy important advantages processinglarge data sets, mainly due ability process eciently without datamain memory time (Mehta et al., 1996; Blockeel et al., 1999).3.3 Computational Complexityestimate speedup factor achieved using query pack execution twosteps: first consider one-level packs, extend results towards deeper packs.Lower upper bounds speedup factor achieved executingone-level pack instead separate queries obtained follows. pack containingn queries qi = (a; bi ), let Ti time needed compute first answer substitutionqi any, obtain failure otherwise. Let ti part Ti spent withint0i part Ti spent bi . Ts = (ti + t0i ) Tp = max(ti ) + t0i Tsrepresenting total time needed executing queries separately Tp total timeneeded executing pack. Introducing c = ti = t0i , roughly representsratio computational complexity shared part non-shared part,0c+1Tsti +ti== maxi ti(1)0Tpmaxi ti + ti+1t0PPPP PPPPdefining K ratio maximal ti average ti , i.e.rewrite Equation (1)SincePtinPmaxt =ntK=TsTp=c+1Knc(2)+1max ti Pi ti know 1 K n, leads following bounds:1TsTpc+1cn+1< min(c + 1; n)(3)Thus speedup factor bounded branching factor nratio c computational complexity shared part computational complexitynon-shared part; maximal speedup attained max ti ' ti =n (or,K ' 1), words ti queries approximately equal.multi-level packs, estimate eciency gain follows. Given query qi ,let Ti defined (the total time finding 1 answer qi obtaining failure).Instead ti t0i , define ti;l time spent level l pack solving qi ;counting root level 0 denoting depth pack Ti = dl=0 ti;l .define Ti;l time spent level l deeper: Ti;l = dj=l ti;j depthpack. (Thus Ti = Ti;0 .). assume constant branching factor b pack.Finally, define tl = ti;l =n n = bd . simplicity, formulae implicitlyassume always ranges 1 n n number queries, unless explicitlyPPP149PfiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteelespecified otherwise.Tp= max ti;0X+i;1= max ti;0X+ (maxbj =12Gji;1XT+2Gji;2)(4)j = 1 : : : b index child root Gj set indexesqueries belonging child. define K0 = maxi ti;0 =t0 define K1 smallestnumber maxi2Gj ti;1 K1 tj;1 tj;1 = i2Gj ti;1 =b. Note 1 K0 ; K1 b.followsbbmax ti;1 K1 tj;1 = K1 bt1(5)i2Gjj =1j =1PXXallows us rewrite Equation (4)TpK0t0 + K1 bt1 +XT(6)i;2equality holds maxi2Gj ti;1 equal Gj . reasoning continuedtill lowest level pack, yieldingTpK0t0 + bK1t1 + b2K2 t2 + + bdfinallyTpK0 t0 + bK1 t1 + b2 K2t2 + + bd1K1 td 11K+1 td 1Xti;d(7)+ bd td(8)Kl 1 b. simplify comparison Ts assuming8l : Kl = 1; Kl dropped inequality becomes equality (becausemaxima must equal):Tp= t0 + bt1 + b2 t2 + + bd 1 td1+ bd td(9)1+ bd td(10)Note TsTs= bd t0 + bd t1 + bd t2 + + bd tdclear, then, speedup governed bd tk terms comparebk tk terms. (In worst case, Kk = b, latter become bk+1 tk .) thereforeintroduce Rl;m follows:bm tk(11)Rl;m = km=l kk =l b tkPPR coecients always 1 (if tm dominates) bm l (if tl strongly dominates);tl equal, Rl;m approximately l.Further, similar c previous analysis, defineP =0 bc = P= +1 bllkk l150kkkk(12)fiImproving Efficiency ILP Query Packsalgebra givesTsTp=bd l cl R0;l + Rl+1;dcl + 1(13)needs hold l. interpret follows: certain level l, cl roughlyects speedup gained fact part till level l needs executedonce; R factors ect speedup obtained within parts packmechanism.inequality holds l, hence find best lower bound speedup factor maximizing right hand side. Note cl increases bd l decreasesmonotonically l. clear point cl becomes much larger 1,speedup factor roughly bd l obtained. hand, cl smaller 1,behaviour bd l cl crucial. Now,bd l cltl + 1 tl 1 + + b1l t0= 1 b:td + b td 1 + + bd 1l 1 tl+1conclusion similar one-level pack. l, cl >> 1, i.e.,upper part pack (up till level l) computations take place expensivedominate computations level l (even taking account latterperformed bd l times often), speedup bd l expected. cl << 1,usually case l except near d, speedup roughlyestimated tl =td . maximum factors determine actual speedup.4. Adapting ILP Algorithms Use Query Packssection discuss execution method included ILP algorithms, illustrate detail two existing ILP algorithms. Experimentalresults concerning actual eciency improvements yields presented next section.4.1 Refinement Single RuleMany systems inductive logic programming use algorithm consists repeatedlyrefining clauses. systems could principle rewritten make use querypack evaluation mechanism thus achieve significant eciency gain. first showconcrete algorithm decision tree induction, discuss general case.4.1.1 Induction Decision Treesfirst algorithm discuss Tilde (Blockeel & De Raedt, 1998), algorithmbuilds first-order decision trees. first-order decision tree, nodes contain literalstogether conjunction literals nodes node (i.e., pathroot node) form query run example decidesubtree sorted into. building tree, literal (or conjunctionliterals) put one node chosen follows: given query corresponding pathroot node, generate refinements query (a refinement query151fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteeleformed adding one literals query); evaluate refinementsrelevant subset data,2 computing, e.g., information gain (Quinlan, 1993a) yieldedrefinement; choose best refinement; put literals addedoriginal clause form refinement node.point clear lot computational redundancy exists refinementevaluated separately. Indeed refinements contain exactly literals exceptadded single refinement step. Organising refinements one query pack,obtain query pack essentially one level (the root immediately branchesleaves). Tilde's lookahead facility used (Blockeel & De Raedt, 1997), refinementsform lattice query pack may contain multiple (though usually few) levels.Note root packs may consist conjunction many literals, givingpack broom-like form. literals root pack, greater benefitquery pack execution expected be.Example 4 Assume node currently refined following query associatedit: ?- circle(A,C),leftof(A,C,D),above(A,D,E), i.e., node covers examplescircle left object yet another object.query pack generated refinement could instancecircle(A,C), leftof(A,C,D), above(A,D,E),triangle(A,F)circle(A,H)small(A,I)large(A,J)in(A,E,K)in(A,D,L)in(A,C,M)above(A,E,N)above(A,D,O)above(A,C,P)leftof(A,E,Q)leftof(A,D,R)leftof(A,C,S)evaluating pack, backtracking root pack (the \stick"broom) happen once, instead refinement. words:evaluating queries one one, query Prolog engine needs searchobjects C , E fulfilling constraint circle(A,C), leftof(A,C,D),above(A,D,E); executing pack search done once.4.1.2 Algorithms Based Rule Refinementmentioned, ILP algorithm consists repeatedly refining clauses could principle rewritten make use query pack evaluation mechanism thus achievesignificant eciency gain. Consider, e.g., rule induction system performing searchrefinement lattice, Progol (Muggleton, 1995). Since imposes certain order clauses considered refinement, hard reorganisecomputation level. However, taking one node list open nodesproducing refinements, evaluation refinements involves executingthem; replaced pack execution, case positive eciency gainguaranteed. principle one could also perform several levels refinement stage,2. I.e., subset original data set parent query succeeded; or, decision treecontext: examples sorted node refined.152fiImproving Efficiency ILP Query Packsadding refinements 's queue; part eciency lost,pack execution mechanism exploited larger extent. two effectsdominant depend application: first-level refinements wouldrefined anyway point search, clearly gainexecuting two-level pack; otherwise may loss eciency. instance,executing two-level pack takes x times much time one-level pack, bringeciency gain least x first level refinements would afterwards refinedthemselves.4.2 Level-wise Frequent Pattern Discoveryalternative family data mining algorithms scans refinement lattice breadthfirst manner queries whose frequency exceeds user-defined threshold. bestknown instance level-wise algorithms Apriori method finding frequentitem-sets (Agrawal et al., 1996). Warmr (Dehaspe & Toivonen, 1999) ILP variantattribute-value based Apriori.Query packs Warmr correspond hash-trees item-sets Apriori: usedstore subgraph total refinement lattice level n. paths rootlevel n 1 subgraph correspond frequent patterns. paths rootleaves depth n correspond candidates whose frequency computed.Like hash-trees Apriori, query packs Warmr exploit massive similaritycandidates make evaluation ecient. Essentially Warmr algorithm startsempty query pack iterates pack evaluation pack extension (seeFigure 8). latter achieved adding potentially frequent refinements3 leavespack, i.e., adding another level total refinement lattice.5. Experimentsgoal experimental evaluation empirically investigate actual speedupsobtained re-implementing ILP systems use pack executionmechanism. moment re-implementations exist Tilde Warmrsystems, hence used experiments. re-implementationsavailable within ACE data mining tool, available academic use upon request.4attempt quantify (a) speedup packs w.r.t. separate execution queries (thusvalidating complexity analysis), (b) total speedup yieldILP system.data sets used experiments following:Mutagenesis data set : ILP benchmark data set, introduced ILP community Srinivasan et al. (1995), consists structural descriptions 230molecules classified mutagenic not. Next standard Mutagenesis data set, also consider versions example occurs n times;3. Refinements found specialisations infrequent queries cannot frequent themselves,pruned consequently.4. See http://www.cs.kuleuven.ac.be/~dtai/ACE/.153fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteelecircle(A,B)triangle(A,B)leftof(A,B,C) above(A,B,C) leftof(A,B,C)EXPANDcircle(A,B)leftof(A,B,C)triangle(A,B)above(A,B,C)leftof(A,B,C)circle(A,C)triangle(A,C) circle(A,C)triangle(A,C) circle(A,C)triangle(A,C)EVALUATEcircle(A,B) triangle(A,B)above(A,B,C)leftof(A,B,C)triangle(A,C) circle(A,C)triangle(A,C)circle(A,B)EXPANDabove(A,B,C)triangle(A,C)triangle(A,B)leftof(A,B,C)circle(A,C)triangle(A,C)leftof(A,C,D) leftof(A,C,D) above(A,C,D) leftof(A,C,D)Figure 8: sequence 4 query packs Warmr. Refinement left querypack results 3-level pack right. Removal queries found infrequentpack evaluation results bottom left pack. Finally, another leveladded second query expansion step produce bottom right pack.iteration expansion evaluation continues pack empty.allows us easily generate data sets larger size average examplequery complexity constant equal original data set.Bongard data sets : introduced ILP De Raedt Van Laer (1995), so-called\Bongard problems" simplified version problems used Bongard (1970)research pattern recognition. number drawings shown containingnumber elementary geometrical figures; drawings classified accordingrelations hold figures them. use Bongard problem generatorcreate data sets varying size.experiments run SUN workstations: Sparc Ultra-60 360 MHzTilde, Sparc Ultra-10 333 Mhz Warmr. Tilde Warmr rundefault settings, except mentioned differently.5.1 Tildeconsider three different ways Tilde run ilProlog implementation:1. packs: normal implementation Tilde described Blockeel De Raedt(1998), queries generated one one evaluated relevantexamples. Since queries represented terms, evaluation query involvesmeta-call Prolog.154fiImproving Efficiency ILP Query Packs2. Disjoint execution packs: query pack executed queries packput beside one another; i.e., common parts shared queries.computational redundancy executing pack executingqueries one another; main difference case queriescompiled.3. Packed execution packs: compiled query pack executed queries sharemuch possible.interesting information obtained comparing (a) actual query evaluation time settings 2 3: gives view eciency gain obtainedremoval redundant computation (we abbreviate exec tables);(b) total execution time settings 1 3: provides indicationmuch gained implementing packs ILP system, taking effects account (re-implementation computation heuristics via bit matrix, use compiledqueries instead meta-calls, etc.), words: net effect wholere-implementation (indicated net tables).first experiment used Bongard problems, varying (1) size data sets;(2) complexity target hypothesis; (3) Tilde's lookahead parameter.complexity target hypothesis small, medium, none. latter caseexamples random, causes Tilde grow ever larger trees attempt findgood hypothesis; size final tree typically depends size dataset. lookahead parameter used control number levels pack contains;lookahead n, packs depth n + 1 generated.Table 1 gives overview results Bongard problems. total inductiontime reported, well (for pack-based execution mechanisms) time neededpack compilation pack execution. Note total time includes packcompilation execution, also computations directly related packs(e.g., computation heuristics bitmatrix). results interpretedfollows.First all, table shows significant speedups obtained using packmechanism; net speedups factor 5.5 obtained, execution75 times faster compared disjoint execution.observation complex target hypotheses greater speedupsobtained. explained broom-like form packs Tilde. Complextarget hypotheses correspond deep trees, refinement node lower leveltree yields pack long clause branching, accordanceprevious analysis yield speedup closer branching factor b caselookahead 0 (and generally, closer bl+1 lookahead l, although lattermuch harder achieve). Note maximum branching factor occurring packincluded table column bf .Finally, deeper packs also yield higher speedups, effect larger complextheories. understandable considering following. Let us call clauserefined c. lookahead l, conjunctions l + 1 literals added clause.cases first l + 1 literals may fail immediately, causes branchpack almost execution time, cutting away bl queries. Remember155fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & VandecasteeleLAbf012316241821012316241821012319241821012319211518012322242718012325242727012328242430012331363333012331393942original0.742.447.4929.91.825.7217.269.83.6911.434.71421.013.266.3627.23.168.3838.51246.3518.141193844.7416.3287.537312.765.1430193425.315411854256disjointpackedcomp exec total compSimple target hypothesis1007 examples0.620.140.130.490.051.640.350.451.090.144.070.81.572.150.2716.523.657.267.181.262473 examples1.430.170.341.130.073.340.341.172.240.118.450.783.954.40.2733.03.5717.513.71.134981 examples2.720.290.672.160.126.220.352.414.170.1316.00.748.148.240.2562.43.6136.524.91.09Medium complexity target hypothesis1031 examples0.930.290.180.660.112.80.980.561.660.353.470.681.221.950.2514.63.755.756.711.202520 examples2.820.890.621.910.35.881.51.863.30.4429.813.14 9.5210.32.4458.0210.328.623.93.005058 examples5.411.471.33.730.5612.983.24.157.50.9393.238.131.035.39.0927510889.110625.9target hypothesis1194 examples6.653.340.943.930.9821.2910.97 2.24 11.65 3.4113082.313.854.720.451931661.122074.92986 examples16.57.042.689.82.1683.742.910.742.4711.260639684211.382.58259216103759463326013 examples30.311.85.5318.33.5319891.233.499.922.01733107635850419769324441 1091 2006695totalspeedupexecnetexec0.071.511.860.112.244.090.163.489.810.284.1725.90.161.612.130.32.553.90.393.9210.10.695.1125.40.321.712.090.632.743.830.884.219.251.455.6925.10.071.532.570.141.9640.153.268.130.274.0621.30.241.652.580.412.544.540.63.7315.91.115.2125.70.531.702.450.912.424.561.73.3618.22.833.6231.50.201.214.700.311.407.230.571.6024.11.341.7045.60.561.304.791.141.539.392.572.0332.66.582.0457.01.271.384.353.131.5410.792.3539.814.52.1275.4Table 1: Timings Tilde runs Bongard data sets. LA = lookahead setting; bf =maximum branching factor. Reported times (in seconds) total time neededbuild tree, time spent compilation respectively execution packs.156fiImproving Efficiency ILP Query PacksLA original01231.5194.99219301227.638.02638disjointpackedtotal comp exec total compRegression, 230 examples52.9 1.96 25.5 45.5 1.02248 55.9 109 107 12.6{{{891192Classification, 230 examples27.3 1.83 4.71 25.4 1.1340.3 7.55 9.09 30.6 3.11{{{149 74.3Table 2: Timings Tilde runs Mutagenesis.ended prematurely.execspeedup rationetexec19.25 0.6916.6 1.8232.0 2.461.336.53{3.423.656.161.382.49{1.091.244.2table indicates runaccording analysis, speedup limit approximate bl complexityclause c dominates complexity rest pack; \early failing branches"pack cause actual situation approximate closer ideal case.also run experiments Mutagenesis data set (Table 2), regressionclassification setting. Here, query packs much larger Bongard data set(there higher branching factor); lookahead 2 largest packs 20000queries. large packs significant amount time spent compiling pack,even clear net speedups obtained.5 comparison execution times turnedinfeasible disjoint execution setting pack structures consumed muchmemory.5.2 Warmr5.2.1 Used ImplementationsWarmr consider following implementations:1. packs: normal implementation Warmr, queries generated,examples queries evaluated one one.2. packs: implementation first queries one level generatedput pack, pack evaluated example.5.2.2 DatasetsMutagenesis used Mutagenesis dataset 230 molecules, examplerepeated 10 times make accurate timings possible better ideaeffect larger datasets. used three different language biases. 'small' language5. one case, relatively small pack, system became slower. timings indicatedue compilation time, changes implementation relativelysimple problem compensated faster execution packs.157fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & VandecasteeleLevel123456789smallMutagenesismediumlargeQueries Frequent Queries Frequent Queries Frequent853726453160144814810712118624688114387415861323169925337216975332918153411492315{{1712{{44{{Table 3: Number queries Mutagenesis experiment Warmr.bias chosen generate limited number refinements (i.e., relativelysmall branching factor search lattice); allows us generate query packsrelatively deep narrow. 'medium' 'large' use broader shallow packs.Table 3 summarises number queries number frequent queries foundlevel different languages.Bongard use Bongard-6013 experimentsWarmr systemconstruct theory hence existence simple theory expected make muchdifference.5.2.3 ResultsTables 4, 5 6 execution times Warmr Mutagenesis given, maximalsearch depth varying 3 large language 9 levels small language. Here,'total' total execution time 'exec' time needed test queriesexamples. Table 7 execution times Warmr Bongard given.5.2.4 Discussionexecution time Warmr large component used evaluate queries.caused fact Warmr needs lot administrative work.particular, theta-subsumption tests done queries check wether queryequivalent another candidate, query specialisation infrequent one.propositional case (the Apriori algorithm), tests simple,first order case require exponential time size queries. course,using larger datasets, relative contribution administrative costs decreaseproportionally. observed deeper levels, costs less settingusing packs. One causes fact no-packs version also uses memorypacks setting (and hence causes proportionally memory management).again, important numbers speedup factors executionqueries. Speedup factors query execution always increase increasing depth158fiImproving Efficiency ILP Query PacksLevel123456789packspacks ilPrologtotalexectotalexec0.350.230.180.156.275.604.564.1236.9331.49 14.019.87117.33 84.4545.1416.27215.95 104.36 129.3720.78336.35 111.28 249.4122.39569.14 115.80 497.8624.63902.72 120.99 831.3025.981268.16 119.60 1148.2332.28speedup rationetexec1.94 1.531.38 1.362.64 3.192.60 5.191.67 5.021.35 4.971.14 4.701.09 4.661.10 3.71Table 4: Results Warmr Mutagenesis dataset using small language.Level123456packspacks ilPrologtotalexectotalexec2.582.272.162.09112.9842.3234.3513.39735.19 128.67 262.8334.704162.15 287.72 1476.0654.1017476.98 444.44 6870.1673.1165138.72 866.85 25921.73104.81speedup rationetexec1.19 1.093.29 3.162.80 3.712.82 5.322.54 6.082.51 8.27Table 5: Results Warmr Mutagenesis dataset using medium language.Level123packspacks ilPrologtotalexectotalexec2.822.422.282.11408.85102.38 102.2950.6727054.33 1417.76 3380.19370.44speedup rationetexec1.24 1.154.00 2.028.00 3.83Table 6: Results Warmr Mutagenesis dataset using large language.159fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & VandecasteeleLevel12345678910packstotalexec0.240.220.830.753.282.8211.56 9.3138.34 28.1175.51 46.97135.64 71.60186.23 84.93210.82 88.97216.61 89.38Table 7:packs ilPrologtotalexec0.240.230.770.682.341.926.084.2816.208.1536.5712.2268.9615.59102.4617.82120.7618.52125.8418.88Warmrspeedup rationetexec1.00 0.961.08 1.101.40 1.471.90 2.182.37 3.452.06 3.841.97 4.591.82 4.771.75 4.801.72 4.73results Bongard.packs, contrast Tilde larger packs yielded higher speedups. first sightfound surprising; however becomes less following observation made.refining pack new pack adding level, Warmr prunes away brancheslead infrequent queries. thus two effects adding level pack:one widening pack lowest level (at least first levels, newpack typically leaves previous one), second narrowingpack whole (because pruning). Since speedup obtained using packs largelydepends branching factor pack, speedup factors expected decreasenarrowing effect stronger widening-at-the-bottom effect.seen, e.g, small-mutagenesis experiment, deepest levels queriesbecoming less frequent. mutagenesis experiment medium size language,query execution speedup factors larger number queries increases much faster.mutagenesis experiment large language, total speedup large,language generates many queries time-consuming part becomesadministration storage memory. packs version much faster storesqueries trees, requiring significantly less memory.5.3 Comparison EnginesImplementing new special-purpose Prolog engine, different already existing ones,carries risk: given level sophistication popular Prolog engines, useful checkwhether new engine performs comparably existing engines, leasttasks consideration here. eciency gain obtained query pack executionoffset less ecient implementation engine itself.Originally Tilde Warmr systems implemented MasterProLog.attempt allow run platforms, parts systems reimplemented kind \generic" Prolog implementations specific Prolog engines (SICStus, ilProlog) easily derived (the low level standardisationProlog made necessary). Given situation, two questions answered:160fiImproving Efficiency ILP Query PacksData setLABongard-1194 0Bongard-2986 0Bongard-6013 0Bongard-1007 0Bongard-2473 0Bongard-4981 0Bongard-1007 2Bongard-2473 2Bongard-4981 2Table 8:MasterProLog ilProlog(original) ilProlog(packs)7.817.8350.772.074.17.117.7384.7412.7250.741.823.77.517.2353.939.8180.491.132.22.24.48.2compared engines (times seconds) several data setslookahead settings.ilProlog(a) move MasterProLog Prolog engines uence performancenegative way; (b) performance loss, any, reduce performance improvements due use packs?Tilde Warmr tuned fast execution MasterProLog ilProlog SICStus, makes comparison latter unfair; thereforereport former 2 engines. Table 8 shows results. confirmilProlog competitive state-of-the-art Prolog engines.5.4 Summary Experimental Resultsexperiments confirm (a) query pack execution much ecientexecuting many highly similar queries separately; (b) existing ILP systems (we use TildeWarmr examples) use mechanism advantage, achieving significantspeedups; c) although new Prolog engine needed achieve this, current statedevelopment engine respect execution speed competestate-of-the-art engines. Further, experiments consistent complexityanalysis execution time packs.6. Related Workre-implementation Tilde related work Mehta et al. (1996)first describe \examples outer loop" strategy decision tree induction.query pack execution mechanism, described Prolog execution point view,also seen first-order counterpart Apriori's mechanism counting item-sets(Agrawal et al., 1996).lines work eciency improvements ILP involves stochastic methodstrade certain amount optimality eciency by, e.g., evaluating clausessample data set instead full data set (Srinivasan, 1999), exploring clausesearch space random fashion (Srinivasan, 2000), stochastically testing whether161fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & Vandecasteelequery succeeds example (Sebag & Rouveirol, 1997). first entirelyorthogonal query pack execution easily combined it.idea optimising sets queries instead individual queries existeddatabase community. typical context considered earlier researchmulti-query optimisation (e.g., Sellis, 1988) database system needshandle disjunctions conjunctive queries, server may receive many queriesdifferent clients brief time interval. several queries expected computeintermediary relations, may ecient materialise relationsinstead recomputed query. Data mining provides sense newcontext multi-query optimisation, multi-query optimisation approachtime easier (the similarities among queries systematic, one needlook them) promising (given huge number queries maygenerated once).Tsur et al. (1998) describe algorithm ecient execution so-called query ockscontext. Like query pack execution mechanism, query ock execution mechanism inspired extent Apriori set deductive database setting.main difference query packs query ocks described Tsur et al.(1998) query packs hierarchically structured queries packstructurally less similar queries ock. (A ock represented single queryplaceholders constants, equal set queries obtainedinstantiating placeholders constants. Flocks could used applicationsconsider here.)Dekeyser Paredaens (2001) describe work multi-query optimisation contextrelational databases. also consider tree-like structures multiple queriescombined; main difference trees rooted one single tablequeries select tuples, whereas queries correspond joins multiple tables. Further,Dekeyser Paredaens define cost measure trees well operators map treesonto semantically equivalent (but less costly) trees, whereas consideredcreation packs ecient top-down execution mechanism them. Combiningapproaches seems interesting topic research.Finally, optimisation techniques ILP proposed exploit resultsprogram analysis (Santos Costa et al., 2000; Blockeel et al., 2000) propositionaldata mining technology (Blockeel et al., 1999). complementary packexecution optimisation. Especially approach Blockeel et al. (1999) easilycombined pack mechanism. techniques discussed Santos Costa et al.(2000) Blockeel et al. (2000) involve optimisations single query execution,extent upgraded pack setting. future work.7. Conclusionslot redundancy computations performed ILP systems.paper identified source redundancy proposed method avoiding it:execution query packs. discussed query pack execution incorporatedILP systems. query pack execution mechanism implemented newProlog system called ilProlog dedicated data mining tasks, two ILP systems162fiImproving Efficiency ILP Query Packsre-implemented make use mechanism. experimentally evaluatedre-implementations, results experiments confirm large speedupsmay obtained way. conjecture query pack execution mechanismincorporated ILP systems similar speedups expected.problem setting query pack execution introduced general,allows technique used kind task many queries executeddata, long queries organised hierarchy.Future work includes improvements ilProlog engine implementation techniques increase suitability engine handle large data sets.best case one might hope combine techniques known database optimisationprogram analysis pack execution mechanism improve speedILP systems.AcknowledgementsHendrik Blockeel post-doctoral fellow Fund Scientific Research (FWO)Flanders. Jan Ramon funded Flemish Institute Promotion ScientificResearch Industry (IWT). Henk Vandecasteele funded part FWO projectG.0246.99, \Query languages database mining". authors thank Luc De Raedtuence work, Ashwin Srinivasan suggesting term \query packs",anonymous reviewers useful comments, Kurt Driessens proofreadingtext. work motivated part Esprit project 28623, Aladin.Appendix A. Preparing Query Meta-interpreterNote following preprocessor assumes pack form a, (b, (ce) f g, (h j)) already transformed form , or([(b,or([c,d,e])), f, (g, or([h,i,j]))]).preprocess((A,B),(A,NewB),PrevNode,NodeNr0,LeafNr0,BranchNr,NodeNr1,LeafNr1):- !,preprocess(B,NewB,PrevNode,NodeNr0,LeafNr0,BranchNr,NodeNr1,LeafNr1).preprocess(or(Querys),or(NQuerys,PrevNode,NodeNr0,BranchNr,Length),PrevNode,NodeNr0,LeafNr0,BranchNr, NodeNr1,LeafNr1):- !,NodeNr2 NodeNr0 + 1,preprocessbranches(Querys,NQuerys,NodeNr0,NodeNr2,LeafNr0,1,NodeNr1,LeafNr1,Length).preprocess(A,(A,leaf(PrevNode,BranchNr,LeafNr0)),PrevNode,NodeNr0,LeafNr0, BranchNr,NodeNr0,LeafNr1):LeafNr1 LeafNr0 + 1.preprocessbranches([],[], ,NodeNr,LeafNr,BranchNr, NodeNr,LeafNr,BranchNr).preprocessbranches([QueryjQuerys],[NewQueryjNewQuerys],PrevNode,NodeNr0,LeafNr0,BranchNr, NodeNr1,LeafNr1,Length):preprocess(Query,NewQuery,PrevNode,NodeNr0,LeafNr0,BranchNr, NodeNr2,LeafNr2),BranchNr1 BranchNr + 1,preprocessbranches(Querys,NewQuerys, PrevNode,NodeNr2,LeafNr2,BranchNr1, NodeNr1,LeafNr1,Length).163fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & VandecasteeleReferencesAgrawal, R., Mannila, H., Srikant, R., Toivonen, H., & Verkamo, A. (1996). Fast discoveryassociation rules. Fayyad, U., Piatetsky-Shapiro, G., Smyth, P., & Uthurusamy,R. (Eds.), Advances Knowledge Discovery Data Mining, pp. 307{328. MITPress.At-Kaci, H. (1991). Warren's Abstract Machine: Tutorial Reconstruction. MITPress, Cambridge, Massachusetts.http://www.isg.sfu.ca/~hak/documents/wam.html.Blockeel, H. (1998). Top-down induction first order logical decision trees. Ph.D. thesis,Department Computer Science, Katholieke Universiteit Leuven.http://www.cs.kuleuven.ac.be/~ml/PS/blockeel98:phd.ps.gz.Blockeel, H., & De Raedt, L. (1997). Lookahead discretization ILP. ProceedingsSeventh International Workshop Inductive Logic Programming, Vol. 1297Lecture Notes Artificial Intelligence, pp. 77{85. Springer-Verlag.Blockeel, H., & De Raedt, L. (1998). Top-down induction first order logical decision trees.Artificial Intelligence, 101 (1-2), 285{297.Blockeel, H., De Raedt, L., Jacobs, N., & Demoen, B. (1999). Scaling inductive logic programming learning interpretations. Data Mining Knowledge Discovery,3 (1), 59{93.Blockeel, H., De Raedt, L., & Ramon, J. (1998). Top-down induction clustering trees.Proceedings 15th International Conference Machine Learning, pp. 55{63.http://www.cs.kuleuven.ac.be/~ml/PS/ML98-56.ps.Blockeel, H., Demoen, B., Janssens, G., Vandecasteele, H., & Van Laer, W. (2000). Twoadvanced transformations improving eciency ILP system. 10thInternational Conference Inductive Logic Programming, Work-in-Progress Reports,pp. 43{59, London, UK.Bongard, M. (1970). Pattern Recognition. Spartan Books.Bratko, I. (1990). Prolog Programming Artificial Intelligence. Addison-Wesley, Wokingham, England. 2nd Edition.Breiman, L., Friedman, J., Olshen, R., & Stone, C. (1984). Classification RegressionTrees. Wadsworth, Belmont.Chen, W., & Warren, D. S. (1996). Tabled evaluation delaying general logic programs. Journal ACM, 43 (1), 20{74. http://www.cs.sunysb.edu/~sbprolog.Clark, P., & Niblett, T. (1989). CN2 algorithm. Machine Learning, 3 (4), 261{284.De Raedt, L. (1997). Logical settings concept learning. Artificial Intelligence, 95, 187{201.De Raedt, L., & Dehaspe, L. (1997). Clausal discovery. Machine Learning, 26, 99{146.164fiImproving Efficiency ILP Query PacksDe Raedt, L., & Dzeroski, S. (1994). First order jk-clausal theories PAC-learnable.Artificial Intelligence, 70, 375{392.De Raedt, L., & Van Laer, W. (1995). Inductive constraint logic. Jantke, K. P., Shinohara, T., & Zeugmann, T. (Eds.), Proceedings Sixth International WorkshopAlgorithmic Learning Theory, Vol. 997 Lecture Notes Artificial Intelligence, pp.80{94. Springer-Verlag.Dehaspe, L., & Toivonen, H. (1999). Discovery frequent datalog patterns. Data MiningKnowledge Discovery, 3 (1), 7{36.Dekeyser, S., & Paredaens, J. (2001). Query pack trees multi query optimization. Tech.rep. 01-04, University Antwerp. ftp://wins.uia.ac.be/pub/dekeyser/qpt.ps.Demoen, B., Janssens, G., & Vandecasteele, H. (1999). Executing query flocks ILP.Etalle, S. (Ed.), Proceedings Eleventh Benelux Workshop Logic Programming,pp. 1{14, Maastricht, Netherlands. 14 pages.Kramer, S. (1996). Structural regression trees. Proceedings Thirteenth NationalConference Artificial Intelligence, pp. 812{819, Cambridge/Menlo Park. AAAIPress/MIT Press.Mehta, M., Agrawal, R., & Rissanen, J. (1996). SLIQ: fast scalable classifier datamining. Proceedings Fifth International Conference Extending DatabaseTechnology.Muggleton, S. (1995). Inverse entailment Progol. New Generation Computing, Specialissue Inductive Logic Programming, 13 (3-4), 245{286.Muggleton, S., & De Raedt, L. (1994). Inductive logic programming : Theory methods.Journal Logic Programming, 19,20, 629{679.Quinlan, J. R. (1993a). C4.5: Programs Machine Learning. Morgan Kaufmann seriesmachine learning. Morgan Kaufmann.Quinlan, J. (1993b). FOIL: midterm report. Brazdil, P. (Ed.), Proceedings 6thEuropean Conference Machine Learning, Lecture Notes Artificial Intelligence.Springer-Verlag.Santos Costa, V., Srinivasan, A., & Camacho, R. (2000). note two simple transformations improving eciency ILP system. Proceedings TenthInternational Conference Inductive Logic Programming, Vol. 1866 Lecture NotesArtificial Intelligence, pp. 225{242. Springer-Verlag.Sebag, M., & Rouveirol, C. (1997). Tractable Induction Classification First-OrderLogic via Stochastic Matching. Proceedings 15th International Joint Conference Artificial Intelligence. Morgan Kaufmann.Sellis, T. (1988). Multiple-query optimization. ACM Transactions Database Systems,13 (1), 23{52.Srinivasan, A. (1999). study two sampling methods analysing large datasetsILP. Data Mining Knowledge Discovery, 3 (1), 95{123.Srinivasan, A. (2000). study two probabilistic methods searching large spacesILP. Tech. rep. PRG-TR-16-00, Oxford University Computing Laboratory.165fiBlockeel, Dehaspe, Demoen, Janssens, Ramon, & VandecasteeleSrinivasan, A., Muggleton, S., & King, R. (1995). Comparing use background knowledge inductive logic programming systems. De Raedt, L. (Ed.), ProceedingsFifth International Workshop Inductive Logic Programming.Tsur, D., Ullman, J., Abiteboul, S., Clifton, C., Motwani, R., Nestorov, S., & Rosenthal, A.(1998). Query ocks: generalization association-rule mining. ProceedingsACM SIGMOD International Conference Management Data (SIGMOD-98),Vol. 27,2 ACM SIGMOD Record, pp. 1{12, New York. ACM Press.166fiJournal Artificial Intelligence Research 16 (2002) 59-104Submitted 5/01; published 2/02Accelerating Reinforcement Learning ComposingSolutions Automatically Identified SubtasksChris DrummondSchool Information Technology EngineeringUniversity Ottawa, Ontario, Canada, K1N 6N5cdrummon@site.uottawa.caAbstractpaper discusses system accelerates reinforcement learning using transferrelated tasks. Without transfer, even two tasks similarabstract level, extensive re-learning effort required. system achieves muchpower transferring parts previously learned solutions rather single completesolution. system exploits strong features multi-dimensional function producedreinforcement learning solving particular task. features stable easyrecognize early learning process. generate partitioning state spacethus function. partition represented graph. used indexcompose functions stored case base form close approximation solutionnew task. Experiments demonstrate function composition often producesorder magnitude increase learning rate compared basic reinforcementlearning algorithm.1. Introductionstandard reinforcement learning algorithm, applied series related tasks, could learnnew task independently. requires knowledge present state infrequentnumerical rewards learn actions necessary bring system desired goalstate. paucity knowledge results slow learning rate. paper showsexploit results prior learning speed process maintainingrobustness general learning method.system proposed achieves much power transferring parts previouslylearned solutions, rather single complete solution. solution pieces representknowledge solve certain subtasks. might call macro-actions (Precup,Sutton, & Singh, 1997), obvious allusion macro-operators commonly foundArtificial Intelligence systems. main contribution work providing wayautomatically identifying macro-actions mapping new tasks.work uses syntactic methods composition much like symbolic planning,novelty arises parts composed multi-dimensional real-valued functions.functions learned using reinforcement learning part complex functionsassociated compound tasks. ecacy approach due compositionoccurring suciently abstract level, much uncertainty removed.function acts much like funnel operator (Christiansen, 1992), although individualactions may highly uncertain, overall result largely predictable.c 2002 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiDrummondsubtasks identified basis strong features multi-dimensionalfunction arise reinforcement learning. features \in world",system's interaction world. Here, \strong" means featuresstable (i.e. relatively insensitive variations low level learning process) easyrecognize locate accurately early learning process. One important aspectfeatures largely dictate shape function. features differsmall amount, one would expect function differ small amount.features generate partitioning function. popular technique objectrecognition, snake (Kass, Witkin, & Terzopoulus, 1987; Suetens, Fua, & Hanson, 1992),used produce partition. object recognition, snake produces closed curvelies along boundary object, defined edges image. application, snake groups together sets features define region function.boundary region low order polygon, demarcating individual subtask.repeated whole function covered. polygons converted discretegraphs, vertex polygon becoming node graph. Merging graphsproduces composite graph representing whole task.composite graph used control transfer accessing case base previouslylearned functions. case base indexed graphs. relevant function determinedmatching subgraph composite graph one acting index case.associated functions transformed composed form solution new task.used reinitialize lower level learning process. necessary transferproduce exact solution new task. sucient solution close enoughfinal solution often enough produce average speed up. Reinforcement learningrefine function quickly remove error.paper demonstrates applicability transfer two different situations.first, system learns task particular goal position goal moved.Although function change significantly, partition generated initialtask used compose function new task. second situation considered, system placed different environment within domain. Here, newpartition extracted control composition process.paper unifies significantly extends previous work author (Drummond,1997, 1998). Additional work largely focussed removing limitationsinherent partitioning approach introduced Drummond (1998). One limitationoriginal approach snake could extract polygons rectangles.paper relaxes restriction, allowing applied different environmentwithin domain different task domain. Although lifting restrictionremoves desirable bias, experiments demonstrate none ecacyoriginal system lost. Further, results broadly obtained larger setrelated tasks different domain. Overall, function composition approach oftenproduces order magnitude increase learning rate comparedbasic reinforcement learning algorithm.rest paper begins Section 2 giving high level discussionapproach taken. Section 3 gives depth discussion techniques used. Sections 4 5 present analyze experimental results. Subsequent sections deallimitations related research.60fiAccelerating Reinforcement Learning2. Overviewintent section appeal intuitions reader, leaving muchdetail later sections paper. subsections follow demonstrate turn:features function produced reinforcement learning; graphsbased features used control composition function pieces;features easy detect early learning process; features existmultiple domains.2.1 Features Reinforcement Learning Functionoverview begins high level introduction reinforcement learningfunction produces. show features functionextracted converted graphical representation.One experimental test beds used paper simulated robot environmentdifferent configurations interconnected rooms. robot must learn navigate ecientlyrooms reach specified goal start location. Figure 1 shows oneexample 5 rooms goal top right corner. robot's actions smallsteps eight directions, indicated arrows. Here, location, state,simply robot's x coordinates. thin lines Figure 1 wallsrooms, thick lines boundary state space.+1GoalRobot1011111212131314-1X-1+1Figure 1: Robot Navigating Series Rooms61fiDrummondaction independent preceding actions, task becomes one learningbest action state. best overall action would one takes robotimmediately goal. possible states close goal. Supposerobot particular state number steps goalneighboring states known, indicated numbered squares surrounding robotFigure 1. one step look ahead procedure would consider step selectone reaches neighboring state shortest distance goal. Figure 1robot would move state 10 steps goal. process repeated, robottake shortest path goal. practice must, course, learn values.done using type reinforcement learning (Watkins & Dayan, 1992; Sutton, 1990)progressively improves estimates distance goal stateconverge correct values.(-1.0,1.0)(0.25,1.0)(0.25,0.9)(-1.0,0.25)(-0.9,0.25)(0.25,0.25)Figure 2: Value Function Obtained Using Reinforcement Learningfunction shown Figure 2 called value function. Subsequently, termfunction mean value function unless otherwise indicated. function resultreinforcement learning problem Figure 1, instead representingactual distance goal, represents essentially exponential decay distance goal.reasons made clear Section 3.1. shaded areas represent largegradients learned function. Comparing environment shown Figure 1,apparent correspond walls various rooms. strongfeatures discussed paper. exist extra distance robottravel around wall reach inside next room path goal.features visually readily apparent human, seems natural use visionprocessing techniques locate them.edge detection technique called snake used locate features. snakeproduces polygon, instance rectangle, locating boundary room.doorways room occur differential function, along bodysnake, local minimum. direction differential respect edges62fiAccelerating Reinforcement Learningpolygon, associated walls room, determines entranceexit. positive gradient room indicates entrance; positive gradientroom indicates exit. information, plane graph, labeled (x; y)coordinate node, constructed. Figure 2 shows one example, roomtop left corner state space, subsequent graphs show coordinates.Nodes corresponding doorways labeled \I" \O" respectively;positions function indicated dashed arrows.2.2 Composing Function Piecesoverview continues showing graphs, extracted featuresfunction learned reinforcement learning, used produce good approximationsolution new goal position. left hand side Figure 3 shows plane graphsrooms (ignore dashed lines circles now). node representinggoal labeled \G". directed edge added \I" \O" \I" \G", appropriate.Associated edge number representing distance nodes.determined value function points doorways. individualgraph merged neighbor produce graph whole problem, righthand side Figure 3. doorway nodes relabeled \D". compositegraph represents whole function. individual subgraph represents particular partfunction. information stored case base. subgraph indexcorresponding part function case.GExtractGraphsGMergeGraphsGGFigure 3: Graphical Representationsuppose goal moved top right corner top left cornerstate space. Reinforcement learning basic form would required learnnew function scratch. work goal moved, new goal position63fiDrummondknown, node representing goal relocated. new goal position showndashed circle Figure 3. edges connecting doorways goalchanged account new goal position. dashed lines representing new edgesreplace arrows subgraph. produce new function, idea regressbackwards goal along edges. edge, small subgraph containingedge extracted. extracted subgraph used index case base functions.retrieved function transformed added appropriate region state spaceform new function.RotateStretchRotateGStretchFigure 4: Function Compositionexample, existing subgraphs match new configuration. twosubgraph originally containing goal subgraph containinggoal. certainly possible exchange two, using appropriate transform.graphs case base may better match new task. best matchsubgraph containing new goal is, fact, subgraph goal originalproblem. fit new task, plane graph rotated stretched slightlynew x direction changing coordinates nodes, see Figure 4.transformation applied function. room containing original goal,case obtained solving another task better match. three rooms usefunctions original problem, since changing goal position little effectactions taken. fact, height functions must changed. simplymultiplication value representing distance goal \O" doorway (thisdiscussed detail end Section 3.3). matching subgraphsallows error asymmetric scaling may used, resulting function mayexact. experiments demonstrate, function often closereinforcement learning quickly correct error.64fiAccelerating Reinforcement Learningnew position goal must established graph modifiedfunction composition occur. system told goal moved, ratherdiscovers determining longer maximum existing function.uncertainty exact boundary original goal. robot may reachstate believes part original goal region, fail detect evengoal moved. reasonably certain goal fact moved,required occur ten times intervening occurrence goal detectedmaximum.system composes search function, assuming particular room containsgoal. Search functions also produced composing previously learned functions.However, room assumed contain goal function constant.bias search particular part room allows limited learningencourage exploration room. search function drives robot roomanywhere else state space. fails find goal fixed number steps,new search function composed another room assumed contain goal.process repeated goal located ten times, ensures good estimate\center mass" goal. \center mass" used new positiongoal node composite graph. Requiring old goal new goal positionssampled fixed number times proven effective domains discussedpaper. Nevertheless, somewhat ad hoc procedure addressed futurework, discussed Section 6.2.2.3 Detecting Features Earlyprevious section, existing task new task strongly related, wallsdoorways fixed goal position different. section,relationship assumed. robot faced brand new task must determinewhat, any, relationship exists new task previous tasks.experimental testbed simulated robot environment, timeproblem simplified inner rectangular room outer L-shaped room. Figures5 6 show two possible room configurations. Again, thin lines wallsroom, thick lines boundary state space. Suppose robot alreadylearned function \Old Task" Figure 5. would hope could adaptold solution fit closely related \New task" Figure 6.steps, example, essentially previous one.learning process started afresh, features system must waitemerge normal reinforcement learning process. proceed muchbefore. First graph inner room extracted. best matching graphcase base old task rotated stretched fit new task. Next matchinggraph outer L-shaped room rotated stretched around larger inner room.transforms applied associated functions, height adjustmentscarried functions composed form approximate solution new task.example, first step process locate goal.partition aid search, initial value function set mid-range constant value(see Figure 7). allows limited learning encourages system move65fiDrummondGoalRobotOuterRoomInnerRoomRobotInnerRoomOuterRoomGoalFigure 5: Old TaskFigure 6: New Taskaway regions explored previously, prevent completely random walkstate space. goal located, learning algorithm reinitialized functiongoal position walls (see Figure 8). function existcase base, rough approximation could used instead. \no walls" functionused exactly stored case base. difference goal reststate space reduced scaling function adding constant. reduces\bias" function, allowing learning algorithm alter relatively easily newinformation becomes available.Figure 7: Start FunctionFigure 8: Intermediate FunctionFigure 9 shows resultant function 3000 exploratory steps beginninglearning process. Again, large gradients associated walls readily66fiAccelerating Reinforcement Learningapparent. Figure 10 shows function new task allowed convergegood solution. functions roughly form, large gradientsposition, although learning latter took 200,000 steps. \nowalls" function introduced features take time clearly emerge. snaketypically filter features small well formed. Additional filteringgraphical level constrains acceptable features. total set features mustproduce consistent composite graph, doorways different subgraphs must aligngraph must overlay complete state space. must also matching casecase base every subtask. Many checks balances removediterative updating technique Section 6.2 incorporated.Figure 9: Early FunctionFigure 10: New Task Function2.4 Different Task Domainprevious sections dealt simple robot navigation problem. section demonstrates features also exist quite different domain, two degreesfreedom robot arm, shown Figure 11. shoulder joint achieve angle radians, elbow joint angle =2 radians, zero indicatedarrows. arm straight shoulder joint rotated, elbow joint describeinner dotted circle, hand outer dotted circle. eight actions, smallrotations either clockwise anti-clockwise joint separately together. aimlearn move arm eciently initial position hand reachesgoal perimeter arm's work space.state space, purposes reinforcement learning, configuration spacearm, sometimes called joint space (see Figure 12). x-axis angleshoulder joint, y-axis elbow joint. eight actions mapped actionsconfiguration space become much like actions robot navigation problem, shownshaded diamond (labeled Arm) Figure 12. map obstacle work spaceconfiguration space, one must find pairs shoulder elbow angles blockedobstacle. obstacles space become elongated form barriers much like67fiDrummond+/2ShoulderHand0Elbow AngleObstacle00111100001100111100GL1111111000000000000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111Arm0ObstacleElbow0/2Obstacle00111100001100111100Figure 11: Work Space000000011111111111111000000000000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111000000011111110000000111111100000001111111ObstacleGL0Shoulder Angle+Figure 12: Configuration Spacewalls experiments previous sections. clear, imagine straighteningarm work space rotating intersects one obstacles,middle dotted line Figure 11. arm rotated shoulder jointroughly linearly proportional rotation elbow joint, opposite direction,keep intersecting obstacle. produces \wall" configuration space.linearity holds small objects far perimeter work space.complex, larger objects, would result complex shapes configurationspace. moment feature extraction method limited simpler shapes,discussed Section 6.reinforcement learning function produced problem shown Figure 13.features shaded clarity. large gradient associated obstacleleft hand side configuration space clearly seen. similar largegradient associated obstacle right hand side configuration space.Again, features used control composition functions goalmoved different task domain.3. Details Techniques Usedsection discuss detail techniques used. include: reinforcementlearning produce initial function, snakes extract features producing graph,transformation composition subgraphs, corresponding functions, fit new task.3.1 Reinforcement LearningReinforcement learning typically works refining estimate expected future reward.goal-directed tasks, ones investigated here, equivalent progressively68fiAccelerating Reinforcement LearningFigure 13: Robot Arm Functionimproving estimate distance goal state. estimate updatedbest local action, i.e. one moving robot, arm, new statesmallest estimated distance. Early learning process, states close goallikely accurate estimates true distance. time action taken, estimatedistance new state used update estimate old state. Eventuallyprocess propagate back accurate estimates goal states.Rather directly estimating Pthe distance goal, system uses expecteddiscounted reward state E [ 1t=1 rt ]. uence rewards, rt , reducedprogressively farther future occur using less one. work,reward reaching goal. farther state goal smallervalue. use expectation allows actions stochastic, robot,arm, takes particular action particular state, next state always same.carry reinforcement learning, research uses Q-learning algorithm (Watkins& Dayan, 1992). algorithm assumes world discrete Markov process, thusstates actions discrete. action state s, Q-learning maintainsrolling average immediate reward r plus maximum value action a0next state s0 (see Equation 1). action selected state usually onehighest score. encourage exploration state space, paper uses -greedypolicy (Sutton, 1996) chooses random action fraction time.effect function composition Q-learning algorithm initial valuestate-action pair set value zero.(1)Qts;a+1 = (1 , ff)Qts;a + ff(r + maxa Qts ;a )Q-function state action usually referred action-value function.paper, action-value function transformed composed formsolution new task. value function, discussed previous sections shown06900fiDrummondfigures, maximum value Q-function. used generate partitionassociated graphs needed control process.Watkins Dayan (1992) proved Q-learning converge optimal valuecertain constraints reward learning rate ff. optimal solution produced taking action greatest value state. So, goal-directed tasks,greedy algorithm take shortest path goal, learning complete.extension continuous spaces may done using function approximation. simplestmethod, one used here, divide state dimensions intervals. resulting action-value function cells representing average Q-value taking actionsomewhere within region state space. off-line learning, actionstate executed, representation proven converge (Gordon,1995). on-line learning, current state determined environment,approach generally successful, exists proof convergence.3.2 Feature ExtractionFeature extraction uses vision processing technique fits deformable model calledsnake (Kass et al., 1987) edges image. initializing snake, processiterates external forces, due edges, balance internal forces snakepromote smooth shape. Here, external forces due steep gradients valuefunction. piecewise constant function approximator used, smoothed cubic b-splinefitted value-function used generate necessary derivatives. left handside Figure 14 gradient value function shown Figure 9 extractingfeatures early learning process. system added gradient around borderrepresent state space boundary.locate features, curve found lies along ridge hills, localmaximum differential. right hand side Figure 14, dashed linescontour lines small inner room indicated. bold lines, right hand sideFigure 14, snake different stages process. snake first positionedapproximately center room, innermost circle. expandedabuts base hills. simplify exposition, imaginesnake consists number individual hill climbers spread along line representingsnake, indicated small white circles. instead allowed climbindependently, movement relative constrained maintain smoothshape. snake reaches top ridge, constrained polygon{ instance quadrilateral { outside dark line Figure 14. point,tend oscillate around equilibrium position. limiting step size processbrought stationary state. detailed mathematical treatmentapproach given Appendix A.polygon forms \skeleton" graph, shown top left Figure 14.Nodes graph correspond vertices polygon doorways goal.Looking gradient plot, doorways regions small differentialridges. locations determined magnitude gradient alongboundary polygon. example, node added goal (labeled G)connected \in" doorway (labeled I). polygon delimits region70fiAccelerating Reinforcement LearningGraphGPolygonDoorwayFigure 14: Gradient Resultant Polygon (Left) Extracted Snake (Right)state space, therefore region action-value function. becomes casecase base, corresponding graph index. Constraining snakepolygon done two reasons. Firstly, vertices needed produce nodesplane graphs, important part matching process. Secondly, additionalconstraint results accurate fit boundaries subtask. This, turn,results accurate solution function composition.3.2.1 Three Extensions Snake Approachsection introduces three extensions basic snake approach facilitate extraction features.first extension affects direction snake moves hill climbing gradient.normal hill climbing, step taken direction steepest ascent, step sizedetermined size differential. Roughly, translates forces pointsalong body snake. force points direction steepest ascent locally,interacts forces various shape constraints. Looking gradientfunction contour lines Figure 14, steep slope leading topridge. also significant slope along ridge away doorway towardsboundary state space. Thus force single point body snake71fiDrummonddirectly towards top ridge turned towards apex, indicatedbold black arrow left hand side Figure 15.SnakeSteepestAscentTangentNormalFigure 15: Controlling Forces Snakeforce broken two components respect snake, normaltangential force. latter force acts along body snake. shapeconstrained quadrilateral, cause relevant side shrink. effectpartially counteracted force towards top ridge adjacent sidequadrilateral. net result shrinking two sides associatedridges inwards forces balanced. push corner quadrilateralnear doorway inwards, indicated thin black arrow Figure 15. extremecase, might cause snake collapse something close triangle.likely outcome degradation accuracy registration ridges.Drummond (1998) prevented degradation accuracy restricting snakesrectangular shapes. weakening constraint general polygons,effect becomes problem. problem addressed removing componentforce tangential snake. hill climbing always directionnormal. significantly restrict motion snake: removedcomponent along body snake. Thus mainly prevents stretchingshrinking snake due gradient.second extension controls way snake expanded reach basehills. Drummond (1998) used ballooning force, introduced Cohen Cohen (1993).problems arose extending system deal general shapesrectangles, outer L-shaped room Figure 6. ballooning force expandssnake directions normal body. One deleterious effect snake contactssharp external corner, inner room, force tends push snakecorner. seen Figure 16; bold continuous lines snake;bold dashed lines ridges. imagine starting circular snake72fiAccelerating Reinforcement Learningmiddle L-shaped outer room, time reaches walls inner roomsides snake roughly perpendicular ridges. Thus little restrainexpansion snake passes completely walls inner room.RidgeBallooningForceRidgeFigure 16: Using Ballooning Forceapproach adopted analogous ow mercury. imagine startingsomewhere middle L-shaped room progressively adding mercury, wouldtend fill lower regions valley first reach bases hills roughlytime. analogy mercury used high surface tension preventingowing small gaps edges associated doorways. increaseeffectiveness idea, absolute value differential gradient thresholded,values threshold set one zero. smoothedtruncated Gaussian, shown Figure 17. Smoothing thresholding commonlyused techniques machine vision (Tanimoto, 1990). typically used removenoise, aim strongly blur thresholded image. produces bowlsassociated room. example, smoothing almost completely obscuredpresence doorway, although generally case.snake initialized small circle minimum one bowls.shown circle middle Figure 18, dashed lines contourlines function. ows outwards, follow contour lines bowl;largest component ow direction arrows Figure 18.achieved varying force normal body snake according heightdifference average height snake. Thus points along snakehigher average tend get pushed inwards, lower pushed outwards. surfacetension mercury produced various smoothing constraints first seconddifferentials snake (see Appendix A).third extension limits changes shape snake expands initialposition reach base hills. smoothness constraints snake, givemercury-like properties, prevent snake owing gaps associated73fiDrummondFigure 17: Smoothed FunctionFigure 18: Mercury Flowdoorways. even proved insucient width rooms widthdoorways similar sizes. Figure 12, looking \room" left hand sideconfiguration space robot arm, \doorway" \room" topsimilar width. Increasing surface tension mercury suciently prevent owdoorways also prevents ow top room.solution limit amount snake change shape grows.achieved constraining much second differential snake changestep step. Figure 18, apparent snake takes good approximationshape room time reaches ridges. shapelocked-in reaching ridges, problem described avoided.snake initialized, constraint smoothness. snake expanded,smoothness constraint progressively weakened curvature constraint progressivelystrengthened. progressively locks shape still allowing snake makesmall local adjustments better fit features.extensions, discussed section, either modify traditional forces actsnake add new ones. also forces associated knot spacing drag.snake moves, iteration, depends vector addition forces.sum acts accelerate body snake mass velocity,therefore momentum. schematic representation forces shown Figure 19;detailed mathematical description given Appendix A. dashed line representsbody snake; arrows forces applied one point body. snakeparameterized function, given f^(s) = (x(s); y(s)) x(s) y(s) individualcubic b-splines giving x coordinates associated variable along bodysnake. circles represent points equi-distant necessarily x y.points kept roughly Euclidean distance apart x due knotspacing force. momentum, although strictly force, encourages point move74fiAccelerating Reinforcement Learningconstant direction; drag opposes motion. stiffness encourages snakemaintain smooth shape. overall stiffness reduced snake grows, keepexibility per unit length roughly constant, also controlled locally maintainshape.Steepest AscentMercuryFlowMomentumKnot SpacingDragStiffnessFigure 19: Forces Snakefollowing algorithmic summary processing snake:Initialize coecients produce circular snake middle room.Iterate forces roughly equilibrium snake oscillates aroundstationary value.Modify stiffness enforce polygonal constraintsIterate 25 steps increasing momentum drag step reduceoscillation small value.Use final position snake form polygon delimits boundaryroom.3.3 Transformationsection discusses matching process { subgraph used locate transformfunction case base. matching process first finds subgraphs case baseisomorphic extracted subgraph possible isomorphic mappingsnodes, using labeling algorithm (MacDonald, 1992). number isomorphic mappings75fiDrummondpotentially exponential number nodes. Here, graphs typicallynodes symmetries, isomorphic mappings. Associatednode subgraph (x; y) coordinate. ane transform, Equation 2, foundminimizes distances coordinates mapped nodesisomorphic subgraphs. advantage transform relative exibilitysimple form.x0 = C0 x + C1 + C2 y0 = C3 x + C4 + C5(2)Ideally transformed nodes would positioned exactly mapped nodes,usually possible. Even simple rectangular shapes, case base maycontain graph exactly doorway positions. Using graphexact match introduce error composed function new task.weighting nodes others error occurs controlled. One aimminimize introduction errors affect overall path length. However,equal importance errors introduced easily correctable normal reinforcementlearning.112 4121Figure 20: Weighting Graph Nodesleft hand side Figure 20 shows composite graph new task. righthand side shows result overlaying graph case base. fitdoorway outer L-shaped room error, robot tend miss doorwaycollide wall one side. farther doorway position, longernormal reinforcement learning take correct error. encourage good fitdoorway, weight 4 used. Nodes adjacent doorway given weight 2,nodes weight one. based intuition trajectories,different parts state space, pass region close doorway.error likely broader effect, take longer normal reinforcement76fiAccelerating Reinforcement Learninglearning correct, regions far doorway. fit around inner roomimproved sacrificing fit far doorway.exact position doorway inner room critical weightset 0.5. Whatever position doorway, shape function correctinside room goal also room. However, doorwaycorrect position, greater error edge length. produce errorcomposed function, expectation error smallreinforcement learning quickly correct it.fit good, would also prefer amount transformation small. transforms produce error particularly trueasymmetric scaling, discussed later section. Generally transform producestranslation, ection, rotation, shearing independent scaling dimension.robot navigation domain, distance points state spacenormal Euclidean distance. reinforcement learning function exponential decaydistance goal. transformation change Euclidean distance,transformed function directly applicable.Affine Similar Symmetric(3)ane transformation one family hierarchy transformations.bottom hierarchy, shown Equation 3, symmetric transformations.solid body transformations change Euclidean distance. next stephierarchy introduces scaling, equal dimension. affect Euclideandistance multiplicative factor. Thus change needed transformedfunction scale height. ane transformations allow addition asymmetricscaling shear, distort Euclidean distance. determine amountdistortion, transformation applied unit circle. symmetric, rigid body,transformations alter circle, transformations will. symmetricscaling transform changes diameter circle. asymmetric scaling sheartransformations change circle ellipse. amount distortion Euclideandistance introduced transform determined ratio lengths majorminor axes ellipse.error = sqrt(Pwi(x2 + yi2 )) (node misalignment)fi2fifi(Euclidean Distortion)+ log2 fifi rrmaj(4)minfi2jr+rjmajmin+ 0:05 log2(scaling factor)2error fit transformed subgraph combined transformationerror using lengths major minor axes, rmaj rmin respectively,ellipse. penalty Euclidean Distortion asymmetric scaling shear.log factor added directly error fit shown Equation 4. Log factorsused, penalty functions symmetric. small penalty symmetricscaling. best matching subgraph found, transformationapplied associated function. isomorphic graph found total error less1.5, constant function used default. new graph overlaysold graph, values assigned using bilinear interpolation discrete values77fiDrummondfunction. not, bilinear extrapolation used, based closest values.cases four values selected, value new point calculatedshown Equation 5. action-value function indexed action well state,process carried action turn. rotation ection transformalso applied predefined matrix actions. produces necessary mappingactions original new action-value function.v = c1 x + c2 + c2 xy + c3(5)Finally, height new action-value function must adjusted accountchange overall distance goal. height value function \out" doorwaydg dg distance goal discount factor. value randompoint within room dg+dd dd distance doorway. action-valuefunction first normalized dividing dg , height function doorwayoriginal problem. multiplied dng , dng distancenew goal; value point becomes dng+dd . Scaling also affect heightfunction. Assuming scaling symmetric new value function anywhereroom cdd c scale factor. Thus raising function power ci.e. ( dd )c account scaling. scaling symmetric result exact, assumingdistance based linear combination two dimensions. asymmetric scaling,result exact. difference two scale factors relatively small,useful approximation use maximum.following algorithmic summary whole matching process:SG = subgraph extracted new task.subgraph G acting index case base{ isomorphic mapping G SGFind minimum weighted least squares fit G SG using mappingAne transform = coecients least squares fitPenalized fit = least squares error + transform penaltyKeep graph transform lowest penalized fitRetrieve function associated best graph case base (if none use default)Apply ane transform functionApply bilinear interpolation/extrapolationAdjust function heightAdd new function existing function78fiAccelerating Reinforcement Learning3.4 Compositionsection describes function composition, transformation applied successivelyseries subgraphs extracted composite graph. Function composition usesslightly modified form Dijkstra's algorithm (Dijkstra, 1959) traverse edgesdoorway nodes. left hand side Figure 21 shows composite graph movinggoal robot navigation example Section 2.2. right hand side showsgraph traversed Dijkstra's algorithm.Gd2Gd1Gr3Gr1d3Gr2Gr5Gr4Figure 21: Using Dijkstra's Algorithmbegin process, subgraph contains goal extracted bestmatching isomorphic subgraph found. edge lengths composite graphupdated using scaled length corresponding edge matching isomorphicsubgraph, d1 d2 Figure 21. d2 less d1, next subgraph extracted,Gr2, one sharing doorway node edge length d2. best matchingisomorphic subgraph found edge length d3 updated. shortest pathdetermined. d1 less d2 + d3 subgraph, Gr3 extracted. processrepeated subgraphs updated. stage subgraph matched,corresponding transformed function retrieved added new functionappropriate region.example, single path goal room. Oftenmultiple paths. Suppose room 5 additional doorway lower left cornerroom, labeled \B" left hand side Figure 22, addition original doorwaylabeled \A". graph, shown right hand side Figure 22, would result.two possible paths goal lengths d4 d5. length across room 5, d6,greater absolute difference d4 d5, choice path roomdetermined decision boundary inside room. produced taking79fiDrummond011011111110 Room 30000001010111111100000000Room 2 11010000 10 Room 5111000 10111Room 4 10Room 1d5n2d4d6n1Gr5BBn3Figure 22: Multiple Paths Goalmaximum two functions shown Figure 23: one entering doorway \A"leaving doorway \B"; one entering doorway \B" leaving doorway \A".principle repeated two paths goal givenroom.cross-room distance, d6, smaller difference (jd4-d5j) decisionboundary would another room. general, want find roomcross-room distance larger difference incident paths.repeated every cycle path graph. cycle detected node visited twice,indicating reachable two separate paths. Let us suppose node n3graph Figure 22. Dijkstra's algorithm used, know previous nodes,either path, n1 n2 already closed. must true pathsreached n3. rooms paths nodes cannot contain decisionboundary, must either room 4 5. decide remaining room in,compare two path lengths. d4 longer d5 + d6 decision boundaryroom 4; otherwise room 5.Whichever room selected, decision boundary produced maximum twofunctions. heights two functions, adjusted path lengths, determinedecision boundary occurs within room. paths equal length, takingmaximum correctly put decision boundary doorway.functions case base, functions already include decision boundaries may used.technique produces correct decision boundary difference path lengthsentering room less difference heights function \out"doorways. left hand side Figure 24 room two doorways. path1 significantly longer path 2, decision boundary far left. shortestpath goal room via right hand doorway. functioncombined mirror image itself, produce decision boundary middle80fiAccelerating Reinforcement LearningMaximumDecisionBoundaryFigure 23: Combining Two FunctionsDecisionBoundaryPath 1Path2RoomFigure 24: Decision Functions81fiDrummondroom, shown right hand side Figure 25. could used newproblem shown left hand side Figure 25 two paths length.heights two functions changed move decision boundary.cannot moved anywhere room. decision boundary movedcloser particular doorway original function shown Figure 24DecisionBoundaryPath 1Path2RoomFigure 25: Combining Decision Functions4. Experimentssection compares learning curves function composition simple baseline algorithm. Four sets results presented; one two types related tasktwo domains. learning curves represent average distance goalfunction number actions taken learning. distance averaged64 different start positions, distributed uniformly throughout state space,different experimental runs. determine distance, normal learning stoppedfixed number actions copy function learned far stored. One 64start positions selected, learning restarted number actions needed reachgoal recorded. trial takes 2000 actions yet reached goal,stopped distance goal recorded 2000. function reinitializedstored version another start state selected. repeated 64 times.function reinitialized normal learning resumed.baseline algorithm underlying learning algorithm function composition system basic Q-learning algorithm, using discrete function approximatordiscussed Section 3.1. learning rate ff set 0.1, greedy policy uses 0.1(the best action selected 90% time), future discount 0.8 reward 1.0received reaching goal. Although state spaces different domains represent two quite different things { robot's hx; yi location angle arm's twojoints { actual representation same. state space ranges 1dimension. step 0:25 dimension either separately together, giving eightpossible actions. actions stochastic, uniformly distributed random value0:125 added dimension action. robot navigation examples82fiAccelerating Reinforcement Learningrobot hits wall, positioned small distance wall along directionlast action. implemented robot arm somewhatcomplex calculation. Instead, collision obstacle occurs arm restoredposition taking action.Learning begins randomly selected start state continues goal reached.new start state selected randomly process repeated. continuesrequisite total number actions achieved. Speed calculated dividingnumber learning steps one specific point baseline learning curve numberlearning steps equivalent point function composition system's learning curve.knee function composition system's curve used. occurs lowlevel learning algorithm initialized composed function. comparedapproximate position knee baseline curve.4.1 Robot Navigation, Goal Relocationfirst experiment investigates time taken correct learned function goalrelocated robot navigation domain. nine different room configurations,shown Figure 26, number rooms varying three five fourdifferent goal positions. room one two doorways one two pathsgoal. initialize case base, function learned configurationsgoal position shown black square. rooms generated randomly,constraints configuration rooms doorways: roomsmall narrow, doorway large. case base also includesfunctions generated experiments discussed Section 4.3. necessarygive sucient variety cases cover new tasks. Even addition,subgraphs matched. Constant valued default functions usedmatch. reduces speed significantly, eliminate altogether.123456789Figure 26: Different Suites Rooms83fiDrummondcase base loaded, basic Q-learning algorithm rerun roomconfiguration goal position shown. 400,000 steps goal moved,denoted time x-axis Figure 27. goal moved onethree remaining corners state space, task included case base. Learningcontinues 300,000 steps. fixed intervals, learning stopped averagenumber steps reach goal recorded. curves Figure 27 average27 experimental runs, three new goal positions nine room configurations.Function CompositionAverage No. Steps GoalQ-LearningQ-Learning (No Reinit)101032110t-400....t-100t-50t+50t+100t+150t+200t+250t+300+ No. Learning Steps X 1000Figure 27: Learning Curves: Robot Navigation, Goal Relocationbasic Q-learning algorithm, top curve Figure 27, performs poorly because,goal moved, existing function pushes robot towards old goal position.variant basic algorithm reinitializes function zero everywhere detectinggoal moved. reinitialized Q-learning, middle curve, performed muchbetter, still learn new task scratch.function composition system, lowest curve, performed far best.precise position knee curve dicult determine due effect usingdefault functions. examples using case base functions considered, kneepoint sharp 3000 steps. average number steps goal 3000 steps,examples, 40. non-reinitialized Q-learning fails reach value within300,000 steps giving speed 100. reinitialized Q-learning reaches value120,000 steps, giving speed 40. Function composition generallyproduces accurate solutions. Even error introduced, Q-learning quicklyrefines function towards asymptotic value 17. 150,000 steps,84fiAccelerating Reinforcement Learningnormal Q-learning reaches average value 24 steps slowly refines solutionreach average value 21 300,000 steps.4.2 Robot Arm, Goal Relocationsecond experiment essentially repeat first experiment robot armdomain. initial number steps, goal moved, reduced 300,000speed experiments. arm two degrees freedom,restrictions discussed Section 2.4, number variations small. three obstacleconfigurations used, constructed hand, two obstacles each. increasenumber experiments, allow greater statistical variation, configurationrepeated goal three possible positions, shown Figure 28.black diamonds represent obstacles, black rectangles goal. Solutionstasks loaded case base. composing function, however, systemprevented selecting case comes goal obstacle configuration.123456789Figure 28: Robot Arm Obstacle Goal Positionscurves Figure 29 average 18 experimental runs, two new goal positionsthree original goal positions three obstacle configurations shownFigure 28. two learning curves, non-reinitialized Q-Learning dropped.first experiment, function composition system, lower curve, performedmuch better Q-learning. knee function composition system occurs 2000steps, knee Q-learning 50,000 steps, giving speed 25. experiment,case base contained subgraphs matched new tasks, default functionsneeded. composed functions tend accurate little refinementnecessary.85fiDrummondFunction CompositionAverage No. Steps GoalQ-Learning101032110t-300....t-100t-50t+50t+100t+150t+200t+250t+300+ No. Learning Steps X 1000Figure 29: Learning Curves: Robot Arm, Goal Relocation4.3 Robot Navigation, New Environmentthird experiment investigates time taken learn new, related, environmentrobot navigation domain. Nine different inner rooms generated randomly,constraints. single doorway, size position roomlocation doorway varied shown Figure 30. initialize case base,function learned configurations goal inside small roomindicate dark square. Learning repeated room configurationsturn. However, composing new function system prevented selectingcase learned goal room configuration. Experimental runs Qlearning algorithm function composition system initialized functionzero 0.75 everywhere respectively, denoted zero x-axis. Learning continues100,000 steps. improve statistical variation, experiments configurationrepeated three times, time new random seed. curves Figure 31 are,therefore, average across 27 experimental runs.top curve Q-learning algorithm, bottom curve function compositionsystem. experiments, locating goal took typically 400 1200 steps,although took 2000 steps. function composition system introduces \nowalls" function typically 800 4000 steps taken usable featuresgenerated. Again, certain experimental runs took longer, discussed Section5.2. Due runs, knee function composition system's curve occurs 12,000steps. knee basic Q-learning curve occurs approximately 54,000 steps giving86fi10101032011529633040506070Q-Learning8090Function CompositionAccelerating Reinforcement Learning4820Figure 30: Single Rooms710No. Learning Steps X 100087100Figure 31: Learning Curves: Robot Navigation, New EnvironmentAverage No. Steps GoalfiDrummondspeed 4.5. previous experiments initialized function accuratelittle refinement necessary. Basic Q-learning, reaching knee, takeslong time remove residual error.4.4 Robot Arm, New Environment1010103201120302405036070Q-Learning8090Function CompositionFigure 32: Different Obstacle Positions10No. Learning Steps X 1000Figure 33: Learning Curves: Robot Arm, New Environment88100fourth experiment essentially third experiment except robotarm domain. Here, three, hand crafted, configurations single obstacle goalfixed position used, shown Figure 32. increase statistical variationconfiguration run five times different random seed. curves Figure 33therefore average across 15 experimental runs.Average No. Steps GoalfiAccelerating Reinforcement Learningtop curve Figure 31 Q-learning algorithm, bottom curve functioncomposition system. knee function composition system's curve occurs4400 steps. knee basic Q-learning algorithm 68,000 steps giving speed15.5. Analysis Resultsexperiments previous section shown function composition producessignificant speed across two different types related task across two domains.addition, composed solutions tend accurate little refinementrequired. section begins looking possible concerns experimentalmethodology might affect measurement speed up. discusses variousproperties task solved affect speed achieved using functioncomposition.5.1 Possible Concerns Experimental Methodologyspeed obtained using function composition suciently large small variationsexperimental set unlikely affect overall result. Nevertheless,number concerns might raised experimental methodology.be, least partially, addressed section; others subject future work.first concern might estimated value speed measured.value represents speed average set learning tasks, ratheraverage speed tasks. One diculties estimation,curves single tasks, average distance goal may oscillatelearning progresses, even though general trend downwards. makes judgingposition knee curves dicult, estimate speed questionable. Evenexperimental runs using configuration, different random seeds, exhibitconsiderable variation. instances, speed measured individual curves maybenefit function composition system, others, baseline algorithm. Nevertheless,probably overall effects cancel out.second concern might effect speed limit 2000 stepsmeasuring distance goal. Comparing two averages values limited waysometimes misleading (Gordon & Segre, 1996). limit primarily affectsbaseline algorithm, significant goal moved functionreinitialized. Estimation speed principally concerned comparing positionknees different curves. Here, average distance goal relatively small,limiting value likely little effect.third concern might value speed dependent configurationbaseline algorithm. Certainly, experience author wayfunction initialized, actions selected, impact speedlearning. previous work (Drummond, 1998), function initialized constantvalue 0.75, technique termed \optimistic initial values" Sutton Barto (1998).Tie breaking actions value achieved adding small amountnoise (circa 5 10,5). expected would increase exploration earlylearning process speed learning overall. However, using initial value zero89fi320150Drummond100150200250300strict tie-breaker, randomly selecting amongst actions value, turnedproduce significant speed baseline learning algorithm. configurationused preceding experiments, one experimental run caused seriousproblems baseline algorithm.101010No. Learning Steps X 1000Figure 34: Learning Curves Partially Observable Domain90upper learning curve Figure 34 baseline algorithm, one rungoal moved robot arm domain. large impact averagelearning curve, replaced lower curve, produced repeating experimentdifferent random seed. slow learning rate arises interactionpartial observability robot arm domain use initial valuezero. Individual cells function approximator straddle obstacles allowing \leakthrough" value one side obstacle other. Starting zero value,action receives value remain best action time. Continualupdate action decrease value, asymptotically approach zero.actions state updated, always selected greedyaction. occur higher initial values. may domainsdegree partial observability, small initial values better zero meansimproving exploration small values might necessary.variations parameters baseline algorithm exploredpaper. instance, constant learning rate 0.1 used. Alternatives,starting higher rate reducing learning progresses might also improveoverall speed baseline algorithm. preliminary experiments were, however,Average No. Steps GoalfiAccelerating Reinforcement Learningcarried using undiscounted reinforcement learning, discounting strictly unnecessary goal-directed tasks. Room configuration 1 Figure 26, goallower right hand corner, used experimental task. discounting, discussedSection 3.1, turned setting 1. addition, value reaching goal stateset zero cost associated every action. form learning simplifiesfunction composition, normalization procedures needed compensate value function's exponential form longer required. normalization disabled, snakesuccessfully partitioned function, critical part process. However,baseline learner took considerably longer learn function discounted case.discounting, learner reached average distance goal 72 steps80,000 learning steps. Without discounting, learner reached average 400 stepspoint time average 80 steps 300,000 learning steps.action-value function initialized zero, appears standard practiceliterature. However, experience initialization discounted case suggestsmight part problem investigated future work.baseline Q-learning algorithm used basic sophisticated onewould unquestionably reduce speed experimentally obtained. instance,form reinforcement learning using eligibility traces (Singh & Sutton, 1996) mightused. experiments goal moved, baseline Dyna-Q+ (Sutton,1990) specifically designed deal changing worlds would probablybetter reference point.speed obtained, transferring pieces action-value function, alsocompared alternatives, transferring pieces policy transferring piecesmodel. Transferring pieces policy would reduce memory requirementsrequire rescaling applied pieces action-value function. does, however,two disadvantages. Firstly, solution directly composed, positiondecision boundaries determined. learning would necessary decideappropriate policy room. Secondly, policy indicates best action.action-value function orders actions, indicating potentially useful small changespolicy might improve accuracy new task. Transferring piecesmodel, would require first learning model consisting probability distribution functionaction state. memory requirement considerably larger, unlessstates reachable action limited beforehand. Nevertheless, model would needless modification changing world, goal moved. also carriesinformation might speed learning. action-value function seems goodcompromise terms complexity versus information content, would needempirically validated subject future work.5.2 Performance Variation Task ConfigurationGenerally, function composition outperforms baseline learning algorithm amountdependent complexity learning problem. robot navigation domaingoal moved, amount speed increased rooms fewerpaths goal. speed 60, average speed 40, obtainedconfigurations five rooms single path goal. Configurations three91fiDrummondrooms least speed up, due relative simplicityproblem.1010103201506100Q-LearningFunction CompositionNo. Learning Steps X 1000692Figure 35: Failure Robot Navigation Moving Goal6150top Figure 35 shows average four learning curves three roomconfigurations. bottom Figure 35 shows one configurations producedcurves. one easiest tasks (from experimental set)baseline algorithm, also solutions case base lowest room.isomorphic subgraphs form. Rather composing solution,system introduces constant value function room. room represents almosthalf state space, much additional learning required. top Figure 35 shows,initially significant speed up. refinement reduces advantageshort baseline algorithm better. later, function composition gainsupper hand converges quickly baseline algorithm towards asymptoticvalue.Average No. Steps GoalfiAccelerating Reinforcement Learningrobot navigation domain learning new task, amount speed variedsize inner room. primarily due number actions neededfeatures emerged sucient clarity snake locate them. Functioncomposition successful inner room small. wall long, featuretakes time develop, refinement Q-learning needed make apparent.short walls also hard identify. likelihood robot collidingsmall takes many exploratory actions features emerge clearly.features may suciently clear snake form partition, yet wellenough defined precisely locate doorways. doorway may appear bit wideractually is. importantly, may appear displaced true position.Typically, error composed function small normal reinforcement learningquickly eliminates it. one experimental runs, configuration 2 Figure 30,speed reduced factor 2 due doorway incorrectly positioned.feature representing lower wall completely emerged partitiongenerated. made doorway appear almost exactly corner.algorithm, fact, positioned doorway wrong side corner. resultedsignificantly reduced speed up. unclear reinforcement learning tooklong correct seems, surface least, local error.investigated future work.6. LimitationsLimitations come , roughly, two kinds: arising overall approacharising way implemented. former case, ways address limitations may highly speculative, impossible without abandoning fundamentalideas behind approach. latter case, reasonable expectation futurework address limitations. following sections deal casesturn.6.1 Limitations Approachexplore possible limitations approach, section reviews fundamentalassumptions based.fundamental assumption features arise reinforcement learning functionqualitatively define shape. features used paper violationsmoothness assumption, neighboring states similar utility values. wall,preventing transitions neighboring states, typically causes violation.things, actions significant cost, would similar effect. Smaller,much varied costs, generate features required approach, offerslittle way speed cases. mixture large small costs,expected system capture features generated former, initializefunction normal reinforcement learning address latter.smoothness assumption less clear dimensions numeric. neighborhood relation, used here, predefined distance metric continuous space.nominal, binary mixed domains obvious metric would defined,although work metrics applications (Osborne & Bridge,93fiDrummond1997). dimensions mixed, feature location might limited continuousones. dimensions purely nominal binary, generalization snake mayappropriate. snake is, abstract level, constrained hill climber. whetheridea would usefully generalize way present somewhat speculative.fundamental assumption features clearly delimit subtasks. domains discussed paper, obstacles walls subdivide state space regionsconnected small \doorways". subtask reaching one doorway greatly affectedsubsequent subtask. domains may case. doorwaysbecome larger, context sensitivity increases. long composed solution reasonably accurate, reinforcement learning easily correct error although speedreduced. point however, due large amount context sensitivity,advantage dividing task subtasks become questionable. would possibleaccount context dependency graph matching stage, lookinglarger units subgraphs. two adjacent subgraphs match new problem, mightused pair, thereby including contextual relationship them. Evensingle subgraphs used, context appear, i.e. shape neighboringsubgraphs, could taken account. limit, graph matching whole task mightused. But, argued introduction, would considerably limit transferapplicable, thus overall effectiveness.fundamental assumption absolute position features unimportant, shape delimited region matters. increase likelihoodtransfer, solutions subtasks subjected variety transformations.domains, many, all, transformations invalid. actions cannotrotated ected, many small costs affect different regions state space,effectiveness transfer reduced. would be, extent, addressedadditional penalties different transformations, would limit opportunities transfer. transformations appropriate, whetherdetermined automatically domain, subject future research.fundamental assumption vision processing technique locatefeatures timely fashion, even high dimensional domains. Learning highdimensional domains likely slow whatever technique used. Normal reinforcementlearning take time navigate much larger space, slowing emergencefeatures. Although time taken partition function increase, frequencypartitioning applicable decrease. Thus amortized cost riseslowly. Further, high dimensional spaces generally problematical, methodsprincipal components analysis projection pursuit (Nason, 1995) used reducedimensionality. may prove practice dimensionality important,focus feature extraction, much smaller actual dimensionality space.6.2 Limitations Implementationassumptions previous section met, expected remaining limitations due present implementation. limitations likely becomeapparent system applied domains. Certainly domains may differpresented paper number ways.94fiAccelerating Reinforcement Learningdomain may differ dimensionality space higher twodimensions tasks investigated paper. implementation snakeupdated work higher dimensions. bold lines top Figure 36one simpler tasks robot navigation domain. task extendedZ-dimension. snake starts sphere expands outwards fillsroom. example, polygonal constraint used, everything elseremains same. Figure 37 shows complete partition task.Figure 36: Adding Z-DimensionFigure 37: Complete 3D Partitionmathematics behind snake limited three dimensions. also seemsnothing principle would prevent processes graph matching,planning transformation working higher dimensions. Speed main problem.problem unique approach large body research addressingissue. instance, although graph matching general NP-complete,much active research speeding matching average special cases (Gold &Rangarajan, 1996; Galil, 1986). present, snake represents principal restrictionspeed. issue great importance vision processing community. Currentresearch investigating problem, least two three dimensions. One examplehierarchical methods (Schnabel, 1997; Leroy, Herlin, & Cohen, 1996) find solutionssnake progressively finer finer resolution scales. results researchundoubtedly importance here.domain may differ value function learned might produce features locatable snake present parameter settings. values parametersempirically determined, using hand crafted examples robot navigationrobot arm domains. obvious danger parameters might tunedexamples. demonstrate case, configurations experimentsrobot navigation domain generated randomly. configurations robot armdomain tightly constrained, hand crafted examples used experiments. Nevertheless, experiments shown parameters worked successfullyrandom examples robot navigation domain. parameters also work successfully second domain, robot arm. following discussion demonstrates95fiDrummondalso reasonably effective quite different domain, \car hill".anticipated using results current research snakes automate selectionmany parameters.\car hill"domain (Moore, 1992), task, simply stated, get carsteep hill, Figure 38. car stationary part way hill, fact anywherewithin dotted line, insucient acceleration make top.car must reverse hill achieve sucient forward velocity, acceleratingside, accelerating hill. state space, purposesreinforcement learning, defined two dimensions. position velocitycar, shown Figure 39. goal reach top hill smallpositive negative velocity. domain two possible actions: accelerateforward, accelerate backwards. Unlike previous domains, clear mappingactions onto state space. state achieved applying action determinedNewton's laws motion. car insucient acceleration make hilleverywhere state space, \wall" effectively introduced, bold line Figure 39.reach top hill, car must follow trajectory around \wall", dashedline Figure 39.GoalVelocity+veGoal0citlo-ve0PositionFigure 38: Car HillPositionFigure 39: Car State SpaceFigure 40 shows reinforcement learning function. exhibits steep gradientdomains. important point note that, unlike domains,physical object causes gradient. implicit problem itself, yet featuresstill exist. Figure 41 shows partition produced applying snake \carhill" domain. main difference previous examples polygonalconstraint used. snake initially comes rest, mercury forceturned snake allowed find minimum energy state. alsonecessary reduce scaling edges, factor three quarters, achieveaccuracy fit. fit around top left corner second snake, dashed line,96fiAccelerating Reinforcement Learningalso problems: snake growing slowly downwards is, present,stopped reached maximum number iterations allowed. One dicultyexample clear delimitation upper lower regionsend feature. Future work investigate altering stopping conditioneliminate problem.Figure 40: Steep GradientFigure 41: Regions Extracteddomain may differ shape various regions partition complex dealt present snake. Fitting snake task discussedprevious paragraphs goes way towards mitigating concern. Nevertheless,randomly generated examples Section 4.1 subject certain constraints. Configurations narrower rooms tried informally, snake reliably locatefeatures. configurations Section 4 represent limit complexity partitionsnake produce present. expected using ideas large bodyalready published research snakes go long way towards addressing limitation.complex regions, locating subtleties underlying shape may unnecessary,even undesirable. aim speed low level learning. long solutionreasonably accurate, speed obtained. sensitive minor variationsshape may severely limit opportunities transfer thus reduce speed overall.domain may differ changes environment complexinvestigated paper. present, system detects goal movedcounting often reward received old goal position. ratherad hoc approach, also account possible changes, pathsbecoming blocked short-cuts becoming available. present, learning new tasksystem restarted required determine present solution longerapplicable. future work, system decide model world longercorrect. also decide what, any, relationship existing taskmight best exploited. allow complex interaction functioncomposition system reinforcement learning. instance, learning new task97fiDrummondrobot navigation domain used relatively simple situation two rooms. functioncomposition system initialized low level algorithm detecting suitable features.future, address complex tasks, many rooms, incremental approachused. new task learned, system progressively buildsolution function composition different features become apparent.approach also handle errors system might make feature extraction. experiments simple room configurations, filtering discussedSection 2.3 proved sucient prevent problems. complex tasks, likelyfalse \doorways" detected, simply system exploredregion state space. composed function including extra doorway drivesystem region. become quickly apparent doorwayexist new function composed.7. Related Workstrongly related work investigating macro actions reinforcement learning. Precup, Sutton Singh (1997, 1998) propose possible semantics macro actionswithin framework normal reinforcement learning. Singh (1992) uses policies, learnedsolve low level problems, primitives reinforcement learning higher level. Mahadevan Connell (1992) use reinforcement learning behavior based robot control.learn solution new task, systems require definition subtaskinterrelationships solving compound task. work presented givesone way macro actions extracted directly system's interactionenvironment, without hand-crafted definitions. also shows determineinterrelationships macro actions needed solve new task. Thrun's research (1994) identify macro actions, finding commonalities multiple tasks.unlike research presented here, mapping actions new tasks proposed.Hauskrecht et al. (1998) discuss various methods generating macro actions. Parr (1998)develops algorithms control caching policies used multiple tasks.cases, need given partitioning state space.automatic generation partition focus much workpresented paper. may well approach generating partitionsdetermining interrelationships partitions related tasks prove usefulwork.Another group closely connected work various forms instance based casebased learning used conjunction reinforcement learning.used address number issues: (1) economical representation statespace, (2) prioritizing states updating (3) dealing hidden state. first issueaddressed Peng (1995) Tadepalli Ok (1996) use learned instancescombined linear regression set neighboring points. Sheppard Salzberg(1997) also use learned instances, carefully selected genetic algorithm.second issue addressed Moore Atkeson (1993) keep queue \interesting"instances, predecessors states learning produces large change values.updated frequently improve learning rate. third issue addressedMcCallum (1995b) uses trees expand state representation include prior98fiAccelerating Reinforcement Learningstates, removing ambiguity due hidden states. work, McCallum (1995a) usessingle representation address hidden state problem general problemrepresenting large state space using case base state sequences associatedvarious trajectories. Unlike research, work presented caseexample value function learning. Instead, result completelearning episode, method complementary approaches.work also related case based planning (Hammond, 1990; Veloso & Carbonell,1993), firstly general connection reinforcement learning planning.analogous ways. small change world,goal moved, composite plan modified using sub-plans extractedcomposite plans.Last, least, connection object recognition vision research (Suetenset al., 1992; Chin & Dyer, 1986). work presented here, many methods {final application { come field. features reinforcement learningfunction akin edges image. located finding zero crossing pointLaplacian introduced Marr (1982). work presented here, proposedfeatures largely dictate form function. Mallat Zhong (1992)shown function accurately reconstructed record steep slopes.8. Conclusionspaper described system transfers results prior learning significantlyspeed reinforcement learning related tasks. Vision processing techniques utilizedextract features learned function. features used index casebase control function composition produce close approximation solutionnew task. experiments demonstrated function composition often producesorder magnitude increase learning rate compared basic reinforcementlearning algorithm.Acknowledgementsauthor would like thank Rob Holte many useful discussions help preparingpaper. work part supported scholarships Natural SciencesEngineering Research Council Canada Ontario Government.Appendix A. Spline Representationsappendix presents underlying mathematics associated spline representations snake. meant introduction subject. Ratheradded completeness discuss certain important aspects system addressedelsewhere paper. Knowledge aspects necessary understand basicprinciples approach discussed paper, would necessary one wantedduplicate system. detailed explanation given Drummond (1999).specific papers address ideas much greater detail are: splines (Terzopoulos,1986) snakes (Cohen & Cohen, 1993; Leymarie & Levine, 1993).99fiDrummondSplines piecewise polynomials degree polynomial determinescontinuity smoothness function approximation. Additional smoothing constraintsintroduced penalty terms reduce size various differentials. One wayview spline fitting form energy functional Equation 6.Espline(f^) =ZREfit (f^) + Esmooth (f^) ds(6)Here, energy associated goodness fit, measure closeapproximating function input function. typically least squaresdistance functions. energy associated smoothnessfunction. Two commonly used smoothness controls produce membrane thinplate splines restricting first second differentials function respectively.fit spline function, total energy must minimized. necessary conditionEuler-Lagrange differential equation Equation 7. !t controlstension spline (the resistance stretching) !s stiffness (the resistancebending). Often error function based individual data points left handside Equation 7 would include delta functions.^2^@ (! (s) @ f (s) ) + @ (! (s) @ f (s) ) = f (s) , f^(s), @s@s@s2 @s2(7)work, splines used number purposes. fittingsnake, measures first second differential needed. two dimensional quadraticspline fitted discrete representation maximum Q-values. !t 0.2 used(!s zero) limit overshoot (Drummond, 1996) prevent false edges. Valuesidentical spline except using !t 2.0 squared divided differentialvalues. normalizes differentials, size edges dependentoccur function. type spline used produce bowls associatedrooms discussed Section 3.2.1. !t 1.0 !s 0.5 giving roughlyGaussian smoothing. values used produce function weighted. Values closeone given weights 200, lower values weight 1. prevents sidesbowls collapsing smoothing.one dimensional cubic spline used locating doorways. foundsteepest descent value differential along body snake. differentialcontains many local minima associated doorways. arise eitherinherent noise process errors fit snake. aim removeones associated doorways smoothing thresholding. achievedfirst sampling gradient points along snake. values normalized liezero one. spline !t 0.15 (!s 0.0). weighted least meansquares fit used. weighting function inverse square values, preventingspline overwhelmed large values. Starting points steepest descentchanges sign coecients gradient spline. initial step sizeset slightly larger knot spacing decreased time. localminimum found value exceeds threshold (of 0.5), rejected.represent snake, model spline must changed somewhat. snakeone dimensional cubic spline. energy minimum sought100fiAccelerating Reinforcement Learningdifferential Qmax function, subject constraints. dynamicssnake defined Euler-Langrange equation shown Equation 8.2 f^!!2 f^!2 f^^ @ @@f@@@@@t2 + @t + @t @s2 !c(s) @s2 + @s2 !tp (s) @s2 = F (f^)(8)!c 512 minimizes changes snake's shape grows, penalizingdifference second differential previous time step scaled ratiolengths. !s 8.0 initial stiffness snake. reduced proportionatelysnake's length give spline degrees freedom. 96 96 controlmomentum drag snake respectively. Cohen Cohen (1993),factor added energy associated differential direction normalbody snake, shown Equation 9. instead constant,variable used produce mercury model discussed Section 3.2.1.2F (f^) = (f^),!n (s) + r(, fifirQmax(f^)fifi ),!n (s)fifi(9)energy minimization process carried iteratively interleaving steps xdirections. differential r jQmax j2 x direction given Equation 10,similar equation used direction.22 Qmax@Qmax )( @ 2 Qmax ))+(, @ jrQ@xmax j = ,2 ( @Q@xmax )( @ @x2@y@x@y"#(10)snake grows forces mercury model reaches approximatelystable position, subject small oscillations. converted polygonn = 0 : : : 3).finding corners (where normal passes (2n+1)4coecient !1 set zero everywhere. coecient !2 set zero corners15 them. produces polygon exible vertices.detect features early possible learning process, discussed Section2.4, height gradient scaled according signal noise ratio. noisearises variations low level learning process stochastic nature task.size features noise grow time somewhat normalizedscaling process. idea collect uniformly sampled values function shownEquation 10 x directions find median absolute values.median strongly affected extreme values thus largely ignores sizefeatures, measuring noise regions between.ReferencesChin, C. H., & Dyer, C. R. (1986). Model-based recognition robot vision. ComputingSurveys, 18 (1), 67{108.Christiansen, A. D. (1992). Learning predict uncertain continuous tasks. ProceedingsNinth International Workshop Machine Learning, pp. 72{81.101fiDrummondCohen, L. D., & Cohen, I. (1993). Finite element methods active contour modelsballoons 2-d 3-d images. IEEE Transactions Pattern Analysis MachineIntelligence, 15 (11), 1131{1147.Dijkstra, E. W. (1959). note two problems connexion graphs. NumerischeMathematik, 1, 269{271.Drummond, C. (1996). Preventing overshoot splines application reinforcementlearning. Computer science technical report TR-96-05, School Information Technology Engineering, University Ottawa, Ottawa, Ontario, Canada.Drummond, C. (1997). Using case-base surfaces speed-up reinforcement learning.Proceedings Second International Conference Case-Based Reasoning, Vol.1266 LNAI, pp. 435{444.Drummond, C. (1998). Composing functions speed reinforcement learning changing world. Proceedings Tenth European Conference Machine Learning,Vol. 1398 LNAI, pp. 370{381.Drummond, C. (1999). Symbol's Role Learning Low Level Control Functions. Ph.D.thesis, School Information Technology Engineering, University Ottawa, Ottawa, Ontario, Canada.Galil, Z. (1986). Ecient algorithms finding maximum matching graphs. ACMComputing Surveys, 18 (1), 23{38.Gold, S., & Rangarajan, A. (1996). graduated assignment algorithm graph matching.IEEE Transactions Pattern Analysis Machine Intelligence, 18 (4), 377{388.Gordon, G. J. (1995). Stable function approximation dynamic programming. Proceedings Twelfth International Conference Machine Learning, pp. 261{268.Gordon, G. J., & Segre, A. M. (1996). Nonparametric statistical methods experimental evaluations speedup learning. Proceedings Thirteenth InternationalConference Machine Learning, pp. 200{206.Hammond, K. J. (1990). Case-based planning: framework planning experience.Journal Cognitive Science, 14 (3), 385{443.Hauskrecht, M., Meuleau, N., Boutilier, C., Kaelbling, L. P., & Dean, T. (1998). Hierarchicalsolution Markov decision processes using macro-actions. ProceedingsFourteenth Conference Uncertainty Artificial Intelligence, pp. 220{229.Kass, M., Witkin, A., & Terzopoulus, D. (1987). Snakes: Active contour models. International Journal Computer Vision, 1, 321{331.Leroy, B., Herlin, I. L., & Cohen, L. D. (1996). Multi-resolution algorithms activecontour models. Proceedings Twelfth International Conference AnalysisOptimization Systems, pp. 58{65.102fiAccelerating Reinforcement LearningLeymarie, F., & Levine, M. D. (1993). Tracking deformable objects plane usingactive contour model. IEEE Transactions Pattern Analysis MachineIntelligence, 15 (6), 617{634.MacDonald, A. (1992). Graphs: Notes symetries, imbeddings, decompositions. Tech.rep. Electrical Engineering Department TR-92-10-AJM, Brunel University, Uxbridge,Middlesex, United Kingdom.Mahadevan, S., & Connell, J. (1992). Automatic programming behavior-based robotsusing reinforcement learning. Artificial Intelligence, 55, 311{365.Mallat, S., & Zhong, S. (1992). Characterization signals multiscale edges. IEEETransactions Pattern Analysis Machine Intelligence, 14 (7), 710{732.Marr, D. (1982). Vision: Computational Investigation Human RepresentationProcessing Visual Information. W.H. Freeman.McCallum, R. A. (1995a). Instance-based state identification reinforcement learning.Advances Neural Information Processing Systems 7, pp. 377{384.McCallum, R. A. (1995b). Instance-based utile distinctions reinforcement learninghidden state. Proceedings Twelfth International Conference MachineLearning, pp. 387{395.Moore, A. W., & Atkeson, C. G. (1993). Prioritized sweeping: Reinforcement learningless data less real time. Machine Learning, 13, 103{130.Moore, A. W. (1992). Variable resolution dynamic programming: Eciently learning actionmaps multivariate real-valued state spaces. Proceedings Ninth InternationalWorkshop Machine Learning.Nason, G. (1995). Three-dimensional projection pursuit. Tech. rep., Department Mathematics, University Bristol, Bristol, United Kingdom.Osborne, H., & Bridge, D. (1997). Similarity metrics: formal unification cardinalnon-cardinal similarity measures. Proceedings Second InternationalConference Case-Based Reasoning, Vol. 1266 LNAI, pp. 235{244.Parr, R. (1998). Flexible decomposition algorithms weakly coupled Markov decisionproblems. Proceedings Fourteenth Conference Uncertainty ArtificialIntelligence, pp. 422{430.Peng, J. (1995). Ecient memory-based dynamic programming. ProceedingsTwelfth International Conference Machine Learning, pp. 438{439.Precup, D., Sutton, R. S., & Singh, S. P. (1997). Planning closed-loop macro actions.Working notes 1997 AAAI Fall Symposium Model-directed AutonomousSystems, pp. 70{76.103fiDrummondPrecup, D., Sutton, R. S., & Singh, S. P. (1998). Theoretical results reinforcementlearning temporally abstract options. Proceedings Tenth EuropeanConference Machine Learning, Vol. 1398 LNAI, pp. 382{393.Schnabel, J. A. (1997). Multi-Scale Active Shape Description Medical Imaging. Ph.D.thesis, University London, London, United Kingdom.Sheppard, J. W., & Salzberg, S. L. (1997). teaching strategy memory-based control.Artificial Intelligence Review: Special Issue Lazy Learning, 11, 343{370.Singh, S. P., & Sutton, R. S. (1996). Reinforcement learning replacing eligibility traces.Machine Learning, 22, 123{158.Singh, S. P. (1992). Reinforcement learning hierarchy abstract models. Proceedings Tenth National Conference Artificial Intelligence, pp. 202{207.Suetens, P., Fua, P., & Hanson, A. (1992). Computational strategies object recognition.Computing Surveys, 24 (1), 5{61.Sutton, R. S. (1990). Integrated architectures learning, planning, reacting basedapproximating dynamic programming. Proceedings Seventh InternationalConference Machine Learning, pp. 216{224.Sutton, R. S. (1996). Generalization reinforcement learning: Successful examples usingsparse coarse coding. Advances Neural Information Processing Systems 8, pp.1038{1044.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press.Tadepalli, P., & Ok, D. (1996). Scaling average reward reinforcement learning approximating domain models value function. Proceedings ThirteenthInternational Conference Machine Learning, pp. 471{479.Tanimoto, S. L. (1990). Elements Artficial Intelligence. W.H. Freeman.Terzopoulos, D. (1986). Regularization inverse visual problems involving discontinuities.IEEE Transactions Pattern Analysis Machine Intelligence, 8 (4), 413{423.Thrun, S., & Schwartz, A. (1994). Finding structure reinforcement learning. AdvancesNeural Information Processing Systems 7, pp. 385{392.Veloso, M. M., & Carbonell, J. G. (1993). Derivational analogy prodigy: Automatingcase acquisition, storage utilization. Machine Learning, 10 (3), 249{278.Watkins, C. J., & Dayan, P. (1992). Technical note: Q-learning. Machine Learning, 8 (3-4),279{292.104fi