Journal Artificial Intelligence Research 24 (2005) 519-579Submitted 12/04; published 10/05Deterministic Part IPC-4: OverviewJorg Hoffmannhoffmann@mpi-sb.mpg.deMax-Planck-Institut fur Informatik,Saarbrucken, GermanyStefan Edelkampstefan.edelkamp@cs.uni-dortmund.deFachbereich Informatik,Universitat Dortmund, GermanyAbstractprovide overview organization results deterministic part4th International Planning Competition, i.e., part concerned evaluatingsystems deterministic planning. IPC-4 attracted even competing systemsalready large predecessors, competition event revised several importantrespects. giving introduction IPC, briefly explain main differencesdeterministic part IPC-4 predecessors. introduce formallylanguage used, called PDDL2.2 extends PDDL2.1 derived predicates timedinitial literals. list competing systems overview results competition.entire set data far large presented full. provide detailed summary;complete data available online appendix. explain awardedcompetition prizes.1. Introductionapplication Artificial Intelligence technology real-world, time spaceresources usually limited. led performance-oriented interpretation AImany research branches. Competition events established automatedtheorem proving, satisfiability testing, and, particular, AI Planning. competitionprovides large-scale evaluation platform. Due broadness neutrality platform, competition far better assessing state-of-the-art research branchexperiments ran individual authors: systems compared, benchmarkschosen competition organizers, rather system authors themselves.Moreover, competition serve establish common representation formalism,common core set benchmarks, marking edge current system capabilities.International Planning Competition (IPC) biennial event, hosted international conferences AI Planning Scheduling. IPC began 1998 DrewMcDermott committee created common specification language (PDDL) collection problems forming first benchmark (McDermott et al., 1998). PDDL Lisp-likeinput language description format includes planning formalisms like STRIPS (Fikes &Nilsson, 1971). Five systems participated first international planning competition,IPC-1 short, hosted AIPS 1998 Pittsburgh, Pennsylvania (McDermott, 2000).year 2000, Fahiem Bacchus continued work, IPC-2 event attracted 16competitors (Bacchus, 2001). event hosted AIPS 2000 Breckenridge, Coloradoextended include fully automatic hand-tailored planning systems.c2005AI Access Foundation. rights reserved.fiHoffmann & Edelkamphand-tailored planners allowed use additional domain-dependent informationPDDL input order improve performance, participated additional,separate, track. STRIPS ADL (Pednault, 1989) domains usedextensions made language (Bacchus, 2000).3rd International Planning Competition, IPC-3, run Derek Long MariaFox hosted AIPS 2002, Toulouse, France. competition attracted 14 competitors (Long & Fox, 2003), focussed planning temporal metric domains.purpose, Fox Long developed PDDL2.1 language (Fox & Long, 2003),first three levels used IPC-3. Level 1 STRIPS ADL planningbefore, Level 2 added numeric variables, Level 3 added durational constructs.4th International Planning Competition, IPC-4, hosted ICAPS-2004,Whistler, Canada. IPC-4 built previous efforts, particular language PDDL2.1.competition event extended revised several respects. particular, IPC-4featured, first time, competition probabilistic planners, overallcompetition split deterministic part continuation previous eventswell probabilistic part.1 latter part, co-organized Michael LittmanHakan Younes, main objective event introduce common representationlanguage probabilistic planners, establish first benchmarks results.information probabilistic part IPC-4 see work Younes Littman(2005).Herein, provide overview organization results deterministicpart IPC-4. 19 competing systems (21 counting different system versions),event even little larger already large predecessors. Several importantrevisions made event. briefly explain main differences Section 2.Afterwards, Section 3 describes input language used, named PDDL2.2: first threelevels PDDL2.1, extended derived predicates timed initial literals. Section 4 listsbriefly explains competing systems. Section 5 presents, benchmarkdomain, selection results plots, highlighting important points. entireset data points far large presented detail. full data, including plotsresults, available online appendix. Section 6 explains awardedcompetition prizes, Section 7 closes paper concluding remarks. Appendixgives BNF description PDDL2.2.2. Main Revisions made IPC-4main revisions made deterministic part IPC-4, difference predecessors, following.Competition Workshop. ran international workshop competition oneyear event (Edelkamp & Hoffmann, 2003), providing involved groupspeople (system developers, organizing committee, AI Planning researchers general)opportunity express views issues related IPC. Discussions, technicaltalks, panels covered relevant topics ranging events organizational structureinput language selection benchmarks evaluation results.1. IPC-4 running, deterministic part named classical part. re-nameddeterministic part since wording less ambiguous.520fiThe Deterministic Part IPC-4: Overviewworkshop especially useful us organizers, giving us direct feedbackevents organization.PDDL Extensions. large agreement community PDDL2.1 stillposed significant challenge, IPC-4 language featured relatively minorextensions. added language features derived predicates timed initial literals.resulting language called PDDL2.2, keeps 3-leveled structure PDDL2.1.new language features practically motivated put useIPC-4 domains. Derived predicates add form domain axioms PDDL2.1. typicaluse formulate indirect consequences planners actions. Timed initial literals addtemporal part PDDL2.1 (level 3) way defining literals become truecertain time point, independently actions taken planner. typical useformulate time windows and/or goal deadlines.Application-Oriented Benchmarks. main effort organization IPC-4devise range interesting benchmark domains, oriented (and close possibleto) real-world application domains. collaborated number people achievegoal. description application domains, PDDL2.2 adaptations,long (50+ pages). submitted JAIR special track (Edelkamp, Hoffmann,Englert, Liporace, Thiebaux, & Trug, 2005). application domains modelled were:Airport, modelling airport ground traffic control (Hatzack & Nebel, 2001; Trug, Hoffmann, & Nebel, 2004).Pipesworld, modelling oil derivative transportation pipeline networks (Milidiu, dosSantos Liporace, & de Lucena, 2003; Milidiu & dos Santos Liporace, 2004).Promela, modelling deadlock detection communication protocols formulatedPromela language (Edelkamp, 2003b, 2003a).PSR, deterministic variant Power Supply Restoration benchmark (Bertoli,Cimatti, Slaney, & Thiebaux, 2002; Bonet & Thiebaux, 2003).UMTS, modelling task scheduling concurrent application setup UMTSmobile devices (Englert, 2003, 2005).addition, re-used Satellite Settlers domains IPC-3. caseSatellite, added additional domain versions model advanced aspectsapplication (namely, sending data earth). domain described littledetail part (sub-section) Section 5 contains respective competitionresults.Domain Compilations. first time IPC, provided domain formulations problem constraints compiled complex PDDL subsetsless complex subsets. many domains natural domain formulation comes complex precondition formulas conditional effects, i.e., ADL.compiled domain formulations STRIPS. previous IPCs, example Elevator domain used IPC-2, interesting problem constraints droppedSTRIPS domain versions. using compilation approach, hope believecreated structurally much interesting range STRIPS benchmarks. ADL521fiHoffmann & EdelkampSTRIPS encodings instances posed competitors optionalway, i.e., every domain version could several domain version formulations.competitors allowed choose formulation liked best. results withindomain version evaluated together, order keep number separation linesdata acceptable level.also employed compilations encoding new PDDL2.2 language features termsartificial constructs old PDDL2.1 features. intended enablewide participation domains possible. compiled domains offeredseparate domain versions rather alternative formulations because, differenceADL/STRIPS case, figured compiled domains differentoriginal ones allow joint evaluation. importantly, compiling derived predicatestimed initial literals away, plan length increases. Details compilationmethods arrangement individual domains paper describingdomains (Edelkamp et al., 2005).Optimal vs. Satisficing Planning. define optimal planners plannersprove guarantee quality found solution. Opposed that, satisficing planners planners prove guarantee correctness solution.2Previous IPCs distinguish optimal planners satisficing planners.fair since optimal planners essentially solving different problem. theoretical hardness domain differ different kinds planners. fact,recently proved that, benchmark domains, satisficing planning easy (polynomial)optimal planning hard (NP-complete) (Helmert, 2001, 2003). practice, i.e.,commonly used benchmark domains, nowadays indeed huge performance gap optimal satisficing planners. IPC-4, separateddifferent tracks. optimal track attracted seven systems; example, planningsatisfiability approach, disappeared IPC-3, resurfaced.Competition Booklet Results Posters. previous competitions, conference time one could neither access results obtained competition, descriptionscompeting planners. clearly drawback, especially given growing complexity event. ICAPS 2004, assembled booklet containing extended abstractsdescribing core aspects competing systems (Edelkamp, Hoffmann, Littman, &Younes, 2004); booklet distributed conference participants. competitionresults, i.e., deterministic part, made available form postersshowing runtime plan quality plots.IPC Web-page. important repository large-scale competition event webpage containing relevant information benchmark problems, language descriptions,result files, etc. IPC-4, set page permanent Internet addresshttp://ipc.icaps-conference.org. long run, address intended provideentry point IPC event whole, thereby avoiding need look pagesdifferent IPC editions completely separate points web.less positive change IPCs 2 3 IPC-4, track hand-tailored plannersdisappeared. reason simply systems registered competitors.2. Satisficing planners referred sub-optimal IPC-4 running. decided replaceterm since bit misleading. guaranteeing optimal solutions, satisficing planner maywell produce solutions cases.522fiThe Deterministic Part IPC-4: Overviewcourse, coincidence. large agreement communityseveral problems hand-tailored track ran IPC-2 IPC-3.important criticism that, hand-tailored planners, performance runtimeplan quality results set benchmarks. Whats also important maybeimportant aspect much effort spent achieving results: hardtailor planner? latter obviously important question, likewiseobviously isnt easy answer. discussed matter lot people (e.g.,ICAPS03 workshop), no-one could come idea seemed adequatefeasible. basically offered hand-tailored planners opportunity participatetrack similar previous ones, maybe additional ad-hoc measurementsmany person hours spent tailoring planner domain. Apartevaluation shortcomings approach, another important reasonhand-tailored planners registered participating track huge amountwork maintaining/developing planner plus understanding domains tailoringplanner. Understanding domains would particularly hardcomplex domains used IPC-4. thus, obviously, difficult find enough timeparticipate hand-tailored IPC. future hand-tailored tracksaid Section 7.3. PDDL 2.2said, IPC-4 competition language PDDL2.2 extension first three levelsPDDL2.1 (Fox & Long, 2003). PDDL2.2 inherits separation levels.language features added top PDDL2.1 derived predicates (into levels 1,2, 3)timed initial literals (into level 3 only). discuss two featuresorder, describing syntax semantics. full BNF description PDDL2.2Appendix A.3.1 Derived PredicatesDerived predicates implemented several planning systems past,example UCPOP (Penberthy & Weld, 1992). predicates affectedactions available planner. Instead, predicates truth valuesderived set rules form (x) P (x). semantics, roughly,instance derived predicate (a derived predicate whose arguments instantiatedconstants; fact, short) TRUE derived using availablerules (more details below). name axioms, derived predicates partoriginal PDDL language defined McDermott (McDermott et al., 1998) firstplanning competition, never put use competition benchmark(we use name derived predicates instead axioms order avoid confusionsafety conditions).Derived predicates combine several key aspects made useful language extension IPC-4:practically motivated: particular, provide concise convenientmeans express updates transitive closure relation. updates occur523fiHoffmann & Edelkampdomains include structures paths flows (electricity flows, chemicalflows, etc.); particular, PSR domain includes kind structure.also theoretically justified compiling away infeasible.recently proved that, worst case, compiling derived predicates awayresults exponential blow either problem description plan length(Thiebaux, Hoffmann, & Nebel, 2003, 2005).Derived predicates cause significant implementation overhead in, least,state transition routines used forward search planners. world statetruth values non-derived, basic, predicates known, computing truthvalues derived predicates trivial.3IPC-4 benchmarks, derived predicates used non-durational context, PDDL2.2 level 1.3.1.1 SyntaxBNF definition derived predicates involves two small modifications BNFdefinition PDDL2.1:hstructure-defi ::=:derivedpredicates hderived-defidomain file specifies list structures. PDDL2.1 either actionsdurational actions. also allow derived definitions points.hderived-defi ::= (:derived hatomic formula(term)i hGDi)derived definitions rules mentioned above. simply specifypredicate P derived (with variable vector x), formula (x) instances P concluded true. Syntactically, predicate variablesgiven hatomic formula(term)i expression, formula given hGDi (a goaldescription, i.e. formula).BNF generous actually allow PDDL2.2, respectivelyIPC-4. make number restrictions ensure definitions make senseeasy treat algorithmically. call predicate P derived rulepredicate P head; otherwise call P basic. restrictions makefollowing.1. actions available planner affect derived predicates: derivedpredicate occurs effect lists domain actions.2. rule defines P (x) derived (x), variables xpairwise different (and, notation suggests, free variables (x) exactlyvariables x).3. Note, though, may much less trivial adapt heuristic function handle derived predicates;is, example, discussed Thiebaux et al. (2003, 2005).524fiThe Deterministic Part IPC-4: Overview3. rule defines P (x) derived , Negation Normal Form(NNF) (x) contain derived predicates negated form.first restriction ensures separation predicatesplanner affect (the basic predicates) (the derived predicates) whose truthvalues follow basic predicates. second restriction ensures rule righthand sides match rule left hand sides. Let us explain third restriction. NNFformula obtained pushing Wnegations Vdownwards, i.e.x :V transformingWx : (), x : x : (), (i ), (i ). Iteratingtransformation steps, one ends formula negations occur frontatomic formulas predicates variable vectors, case. formula containspredicate P negated form occurrence P negated.requiring formulas rules (that derive predicate values) containderived predicates negated form, ensure negative interactionsapplications rules (see semantics below).example derived predicate predicate Blocksworld,true blocks x whenever x transitively (possibly blocksbetween) y. Using derived predicates syntax, predicate defined follows.(:derived (above ?x ?y)(or (on ?x ?y)(exists (?z) (and (on ?x ?z)(above ?z ?y)))))Note formulating truth value terms effects normalBlocksworld actions awkward. Since set atoms affected action dependssituation, one either needs artificial actions complex conditional effects.3.1.2 Semanticsdescribe updates need made PDDL2.1 semantics definitionsgiven Fox Long (2003). introduce formal notations capture semanticsderived predicates. hook semantics PDDL2.1 languagemodifying two Fox Long (2003)s definitions.Say given truth values (instances the) basic predicates, wantcompute truth values (instances the) derived predicates that.situation every time applied action, parallel action set. durationalcontext, situation happenings current plan, every timedurative action starts finishes. Formally, want functionmaps set basic facts (instances basic predicates) set enrichedderived facts (the derivable instances derived predicates). Assume givenset R rules derived predicates, elements R form (P (x), (x))(x) P (x). D(s), set basic facts s, defined follows.\D(s) := {s0 | s0 , (P (x), (x)) R : c, |c| = |x| : (s0 |= (c) P (c) s0 )}(1)definition uses standard notations modelling relation |= states(represented sets facts case) formulas, substitution (c)525fiHoffmann & Edelkampfree variables formula (x) constant vector c. words, D(s) intersectionsupersets closed application rules R.Remember restrict rules contain derived predicates negatedform. implies order rules applied state matter(we lose derived facts deriving facts first). This, turn, impliesD(s) closed application rules R. words, D(s) leastfixed point possible applications rules R state derived factsassumed FALSE (represented contained s).constructively, D(s) computed following simple process.s0 :=select rule (P (x), (x)) vector c constants,|c| = |x|, s0 |= (c) P (c) 6 s00let := s0 {P (c)}rule constant vector existlet D(s) := s0words, apply applicable rules arbitrary order new factsderived anymore.specify executable plan PDDL2.1 derived predicates.need hook function Definition 13, Happening Execution,given Fox Long (2003). definition, Fox Long (2003) define statetransitions plan. happenings (temporal non-temporal) plan timepoints least one action effect occurs. Fox Long (2003)s definition this:Definition 13 Happening Execution (Fox & Long, 2003)Given state, (t, s, x) happening, H, activity H set grounded actionsAH = {a| name H, validP rea satisfied (t, s, x)}result executing happening, H, associated time tH , state (t, s, x)undefined |AH | =6 |H| pair actions AH mutex. Otherwise, state00(tH , , x )[[s0 = (s \Dela )Adda(2)aAHx0aAHresult applying composition functions {NPFa | AH } x.Note happenings consist grounded actions, i.e., operator parametersinstantiated constants. introduce semantics derived predicates,modify result executing happening. (We also adapt definition mutexactions, see below.) result executing happening obtained applyingactions s, subtracting derived facts this, applying function D.is, definition replace Equation 2 following:[[s0 = D(((s \Dela )Adda ) \ D)(3)aAHaAH526fiThe Deterministic Part IPC-4: Overviewdenotes set derived facts. derived predicates,empty set identity function.example, say Blocksworld instance B C, ={clear(A), on(A, B), on(B, C), ontable(C), above(A, B), above(B, C), above(A, C)},happening applies action moves table. happening executionresult computed removing on(A, B) s, adding clear(B) ontable(A)s, removing above(A, B), above(B, C), above(A, C) s, applyingthis, re-introduce (only) above(B, C). s0 s0 = {clear(A), ontable(A),clear(B), on(B, C), ontable(C), above(B, C) }.definition happening execution, Fox Long (2003) define state transitions plan. definitions executable plan is, plan achievesgoal, standard. plan executable result happeningsplan defined. means action preconditions fulfilled stateexecution, two pairs actions happening mutex. plan achievesgoal goal holds true state results execution actionsplan.extension definition happening executions, definitionsplan executability goal achievement need changed. do, however, needadapt definition pair actions mutex. important happeningscontain one action, i.e., consider parallel (Graphplan-style) concurrent (durational) planning. Fox Long (2003) give conservative definition forbidsactions interact possible way. definition following.Definition 12 Mutex Actions (Fox & Long, 2003)Two grounded actions, b non-interferingGP rea (Addb Delb ) = GP reb (Adda Dela ) = ,Adda Delb = Addb Dela = ,La Rb = Ra Lb = ,La Lb La Lb(4)two actions non-interfering mutex.Note definition talks grounded actions operator parametersinstantiated constants. La , Lb , Ra , Rb refer left right hand sidebs numeric effects. Adda /Addb Dela /Delb bs positive (add)respectively negative (delete) effects. GP rea /Gpreb denotes (ground) facts occuras/bs precondition.preconditionWcontains quantifiers grounded (xVtransforms ci , x transforms ci ci objects given instance),GP defined resulting quantifier-free (and thus variable-free) formula. Notedefinition mutex actions conservative if, example, fact F occurspositively precondition, matter F among add effectsb. conservative definition advantage makes algorithmically easyfigure b mutex.presence derived predicates, definition needs extended exclude possible interactions arise indirectly due derived facts, preconditionone action, whose truth value depends truth value (basic) facts affected527fiHoffmann & Edelkampeffects action. spirit Fox Long (2003) forbidpossibility direct interaction, forbid possibility indirect interaction.Assume ground rules (P (x), (x)) derived predicates, i.e., insertpossible vectors c constants; also ground quantifiers formulas (c), ending variable free rules. define directed graph nodes (ground)facts, edge fact F fact F 0 inserted iff grounded rule (P (c), (c))F 0 = P (c), F occurs (c). say action a, groundfacts occurring precondition are, see above, denoted GP rea . DP rea denoteground facts possibly influence truth values derived facts GP rea :DP rea := {F | path F F 0 GP rea }(5)definition mutex actions updated simply replacing Equation 4 with:(DP rea GP rea ) (Addb Delb ) =(DP reb GP reb ) (Adda Dela ) = ,Adda Delb = Addb Dela = ,La Rb = Ra Lb = ,La Lb La Lb(6)Note thing changed first line, regarding interference propositional effects preconditions. example, reconsider Blocksworldpredicate. Assume action moves block table requires additional, derived, precondition, third block. Then, principle, twoactions move two different blocks B table executed parallel.block (B) influence relations B (A) participates; however, matter B moved impliesclear, implies top different stacks anyway. observelatter statement domain semantics either requires non-trivialreasoning, access world state actions executed. order avoidneed either non-trivial reasoning domain semantics, resort forwardsearch, definition conservative one given above. definition makes actionsmoving B mutex grounds possibly influence others derivedpreconditions.definition adaptations described suffice define semantics derivedpredicates whole PDDL2.2. Fox Long (2003) reduce temporal casecase simple plans above, adapting simple-plan definitions automaticallyadapted definitions complex cases. temporal setting, PDDL2.2 level 3,derived predicates semantics values computed anew happeningplan action effect occurs. said, IPC-4 used derived predicatesnon-temporal setting. remarks limitations IPC-4 treatment derivedpredicates, future prospects, Section 7.3.2 Timed Initial LiteralsTimed initial literals syntactically simple way expressing certain restrictedform exogenous events: facts become TRUE FALSE time pointsknown planner advance, independently actions planner chooses528fiThe Deterministic Part IPC-4: Overviewexecute. Timed initial literals thus deterministic unconditional exogenous events.Syntactically, simply allow initial state specify beside usual factstrue time point 0 literals become true time points greater 0.Timed initial literals practically relevant: real world, deterministic unconditional exogenous events common, typically form time windowswithin shop opened, within humans work, within traffic slow,within daylight, within seminar room occupied, within nobody answers mail conferences, etc. timed initial literalssyntax simplest way one think communicate thingsplanner.Timed initial literals easily compiled artificial constructs (Fox, Long, &Halsey, 2004), involving linear blow-up instance representation planlength (i.e., number actions it). Still seems highly likely handing timedliterals automated planner explicitly results far better performanceone hands artificial (compiled) representation. results obtained IPC-4confirm this, see also Section 5.3.2.1 SyntaxBNF notation is:hiniti ::= (:init hinit-eli )hinit-eli ::=:timedinitialliterals (at hnumberi hliteral(name)i)requirement flag timed initial literals implies requirement flag durationalactions, i.e., said language construct available PDDL2.2 level 3. timeshnumberi timed literals occur restricted greater 0.also derived predicates domain, timed literals restricted influencethese, i.e., like action effects allowed affect truth valuesbasic (non-derived) predicates (IPC-4 use derived predicates timed initialliterals within domain).illustrative example, consider planning task goal completedshopping. single action go-shopping achieves goal, requires(single) shop open precondition. shop opens time 9 relative initialstate, closes time 20. express shop opening times two timed initialliterals:(:init(at 9 (shop-open))(at 20 (not (shop-open))))3.2.2 Semanticsdescribe updates need made PDDL2.1 semantics definitionsgiven Fox Long (2003). Adapting two definitions suffices.529fiHoffmann & Edelkampfirst definition need adapt one defines simple plan,happening sequence, is. original definition Fox Long (2003) this.Definition 11 Simple Plan (Fox & Long, 2003)simple plan, SP , planning instance, I, consists finite collection timed simpleactions pairs (t, a), rational-valued time action name.happening sequence, {ti }i=0...k SP ordered sequence times settimes appearing timed simple actions SP . ti must greater 0.possible sequence empty (an empty plan).happening time t, Et , happening sequence SP , set(simple) action names appear timed simple actions associated time SP .STRIPS case, time stamps natural numbers 1, . . . , n nactions/parallel action sets plan. happenings actions/parallel actionsets respective time steps. Fox Long (2003) reduce temporal planning casesimple plan case defined splitting durational action least twosimple actions start action, end action, possibly several actionsguard durational actions invariants points action effects occur.temporal case, happening sequence comprised time pointssomething happens, i.e., action effect occurs.introduce intended semantics timed initial literals, needdefinition introduce additional happenings temporal plan, namely timepoints timed initial literal occurs. timed initial literals interpretedsimple actions forced respective happenings (rather selectedplanner), whose precondition true, whose effect respectiveliteral. rest Fox Long (2003)s definitions carry directly (except goalachievement, involves little care, see below). PDDL2.2 definition simpleplans here.Definition 11 Simple Plansimple plan, SP , planning instance, I, consists finite collection timed simpleactions pairs (t, a), rational-valued time action name.tend denote largest time SP , 0 SP empty.Let L (finite) set timed initial literals, given pairs (t, l)rational-valued time occurrence literal l. identify timed initial literal (t, l)L uniquely named simple action associated time t, whose preconditionTRUE, whose effect l.happening sequence, {ti }i=0...k SP ordered sequence times settimes appearing timed simple actions SP L. ti must greater0. possible sequence empty (an empty plan).happening time t, Et , happening sequence SP , set(simple) action names appear timed simple actions associated time SPL.Thus happenings temporal plan points time either actioneffect, timed literal, occurs. timed literals simple actions forcedplan. construction, Fox Long (2003)s Definitions 12 (Mutex Actions) 13530fiThe Deterministic Part IPC-4: Overview(Happening Execution), described (and adapted derived predicates) Section 3.1.2,kept unchanged. state action effect allowed interfere timedinitial literal, timed initial literals true state resultsexecution happening contained in. Fox Long (2003)s Definition 14(Executability plan) also kept unchanged timed initial literals changehappenings plan, conditions happening executed.definition need reformulate makespan valid planis. Fox Long (2003)s original definition, implicit definition validplans. definition this.Definition 15 Validity Simple Plan (Fox & Long, 2003)simple plan (for planning instance, I) valid executable produces finalstate S, goal specification satisfied S.makespan valid plan accessible PDDL2.1 PDDL2.2 totaltime variable used optimization expression. Naturally, Fox Long(2003) take makespan end plan, time point plans final state.presence timed initial literals, question plans makespanbecomes little subtle. Fox Long (2003)s original definition,makespan would end happenings simple plan, include timedinitial literals (see revised Definition 11 above). plan would least take longtakes timed literals occur. plan might finished longimagine something needs done daylight; certainly planneed wait sunset. therefore define makespan earliest pointtime goal condition becomes (and remains) true. Formally readsfollows.Definition 15 Validity Makespan Simple Plansimple plan (for planning instance, I) valid executable produces finalstate S, goal specification satisfied S. plans makespansmallest tend that, happenings times t0 plans happeningsequence, goal specification satisfied execution happening.Remember tend denotes time last happening plan containseffect caused plans actions simpler terms, tend end point plan.definition says plan valid if, time point plansend, goal condition achieved remains true last timed literaloccurred. plans makespan first time point t. Note planneruse events achieve goal, nothing timed literal occursmakes goal condition true waiting time nearest timedliteral counted plans makespan. (The latter done avoid situationsplanner could prefer wait millions years rather applying single actionitself.) Remember makespan plan, defined above, denotedtotal-time optimization expression defined problem instance.derived predicates, definition adaptations suffice definesemantics timed initial literals PDDL2.2. remarks limitations languageconstruct, future prospects, Section 7.531fiHoffmann & Edelkamp4. Competitorsprovide overview table listing systems along language capabilities(subset PDDL2.2 covered), sketch competing systems. deterministicpart IPC-4 attracted 19 competitors (21 counting different system versions), 12(14) satisficing 7 optimal. competitor wrote 23 page extended abstract inclusion IPC-4 booklet ICAPS 2004 (Edelkampet al., 2004). included sketches brief outlines abstracts. readerencouraged read original work system authors.point appropriate say words system development. allowedcompetitors modify systems competition phase, i.e., data collectionrunning. reasons twofold. First, domains quiteunusual particularly, containing ADL constructs compiled STRIPS(rightly) expected planner implementations parsing etc. trouble them. Second,experience competitions knew people try enhanceplanners anyway see much point forbidding this. trustedcompetitors stupid things like hard-coding domain names etc., trusteddiverse enough range domains make tuning domain-independent task.alternative would collect executables data collection,results collected organizers. Anyone ever run experimentssomeone elses planner knows approach completely infeasible dueprototype-nature systems, due many tiny details minor languagechanges, programming environments, etc. one wants obtain meaningful results,least. One could principle apply strict failure counted unsolved rule,would likely lay way much emphasis little programming errorsnothing evaluated algorithms.competition phase was, roughly, February 2004 middle May 2004. time, released domains one-by-one, competitors workedsystems, handing results us ready. end phase,competitors submit executable, ran sampled tests seeexecutable really produce reported results, across domains. abstractsdescribing systems delivered little earlier, end April, due timingconstraints printing booklet.start overview table, sketch satisficing optimal competitors.4.1 Planner Overviewoverview participating satisficing planners, language capabilities (definedlanguage features attacked IPC-4), given Table 1.Observe planners treat small subset PDDL2.2: quickglance table, one sees far (-) entries (+) entries. Notethat, often, even (+) sign given, planner may treat subsetspecified language feature (as needed respective IPC-4 domain). example,planner might treat subset ADL, linear arithmetic numeric variables.leave details sake readability.532fiThe Deterministic Part IPC-4: OverviewCRIKEYFAPFD, FDDLPG-TDMacro-FFMarvinOptopP-MEPRoadmapperSGPlanTilsapaYAHSPBFHSPCPTHSPaOptiplanSATPLANSemSynTP4ADL++++++++-DP+++++-Numbers+++++++++Durations+++++++++TL+++++-Table 1: overview planners IPC-4, language capabilities (i.e.,language features attacked IPC-4). satisficing planners top halftable, optimal planners bottom half. table entry specifieswhether (+) (-) planner handle language feature. DP shortderived predicates, TL short timed initial literals. NumbersDurations mean numeric fluents fixed action durations (no durationinequalities), sense PDDL2.1 level 2 3, respectively. planners(and name abbreviations) explained below.LPG-TD, Optop, SGPlan planners treat full range PDDL2.2,used IPC-4. Three satisficing planners (FAP, Roadmapper, YAHSP), threeoptimal planners (BFHSP, Optiplan, SATPLAN), treat pure STRIPS. Derivedpredicates treated 4 planners, timed initial literals 5 planners, ADL 7 planners,numeric variables 8 planners, action durations 9 planners.Table 1 shows significant amount acceptance new (PDDL2.1PDDL2.2) language features, terms implemented systems participatingIPC. Table 1 also shows development systems side tendencyslower development IPC language side: even wide-spread languagefeature beyond STRIPS, action durations, dealt less half 19 planners.opinion, taken indicate language extensionsmade slowly. said Section 7.533fiHoffmann & Edelkamp4.2 Satisficing Plannerssatisficing planners planners giving guarantee quality returnedplan following. proceed alphabetical order.CRIKEY Keith Halsey, University Strathclyde, Glasgow, UK. CRIKEYheuristic search forward state space planner. includes heuristic relaxed planstemporal numeric problems applies scheduler based simple temporal networksallow posterior plan scheduling.FAP Guy Camilleri Joseph Zalaket, University Paul Sabatier / IRIT CCICSC, France. FAP handles non-temporal non-numeric domains. heuristic plannerusing relaxed planning heuristic N -best forward search, meta-actions (actionsequences) extracted relaxed planning graph perform jumps state space.Fast Downward, FD short, Fast Diagonally Downward, FDD short,Malte Helmert Silvia Richter, University Freiburg, Germany. FD FDDtreat non-temporal non-numeric domains. apply new heuristic estimate basedpolynomial relaxation automatically inferred multivariate SAS+ representationproblem space. FDD also applies traditional FF-style relaxed planning heuristic,i.e., applies heuristics hybrid search algorithm.LPG-TD Alfonso Gerevini, Alessandro Saetti, Ivan Serina, Paolo Toninelli,University Brescia, Italy. extensions randomized local plan graph searchalready included LPG IPC-3 includes functionality PDDL2.2 derivedpredicates timed initial literals, well various implementation refinements. version tailored computation speed, LPG-TD.speed, version tailored plan quality,LPG-TD.quality, participated. LPG-TD.quality differs LPG-TD.speed basicallystop first plan found continues stopping criterionmet. LPG-TD team also ran third version, called LPG-TD.bestquality,used, every instance, entire half hour CPU time available produce good planpossible. third version included official data every teamallowed enter two system versions.Macro-FF Adi Botea, Markus Enzenberger, Martin Muller, Jonathan Schaeffer,University Alberta, Canada. name suggests Macro-FF extends Hoffmanns FFplanner macro operators (and implementation refinements). Macros learnedprior search fed planner new data, separated operator fileproblem file. runtime, regular actions macro-actions used stateexpansion. Heuristic rules pruning instantiations macros added FFs originalstrategy search control.Marvin Andrew Coles Amanda Smith, University Strathclyde, Glasgow,UK. Marvin extends FF adding extra features preprocessing information,plateau-escaping macro actions, enhance search algorithm.Optop Drew McDermott, Yale University, USA. Optop extension wellknown UNPOP planner, ability handle complex input language including,amongst things, autonomous processes running parallel actions takenplanner. underlying principle forward search heuristic guidance obtainedgreedy-regression match graphs built backwards goals.534fiThe Deterministic Part IPC-4: OverviewP-MEP Javier Sanchez, Minh Tang, Amol D. Mali, University Wisconsin,USA. P-MEP short Parallel Expressive Planner. Unlike planners, P-MEPtreat numeric variables non-linear action effects. employs forward searchrelaxed plan heuristics, enhanced relevance detection pre-process, takingaccount exclusion relations relaxed planning.Roadmapper Lin Zhu Robert Givan, Purdue University, USA. Roadmapperhandles non-temporal non-numeric domains. forward heuristic search planner enhancing FF heuristic reasoning landmarks. latter propositionsmust true point every legal plan. Roadmapper finds landmarkspre-process, arranges directed road-map graph, uses graph assignweights actions FF-style relaxed plans.SGPlan Yixin Chen, Chih-Wei Hsu Benjamin W. Wah, University Illinois,USA. planner bootstraps heuristic search planners applying Lagrange optimizationcombine solution planning subproblems. split problem, orderingplanning goals derived. incremental local search strategy applied Lagrangeoptimization top individual planners relies theory extended saddle pointsmixed integer linear programming.Tilsapa Bharat Ranjan Kavuluri Senthil U., AIDB Lab, IIT Madras, India.planner extends SAPA system handles temporal numeric domains,ability handle timed initial literals.YAHSP Vincent Vidal, University Artois, France. YAHSP, acronymyet another heuristic search planner, searches forward FF-style relaxed planningheuristic. main enhancement relaxed-plan-analysis phase replaces actionsrelaxed plan based heuristic notions better suitability reality, producingmacro-actions process. macro-actions are, basically, long possible feasiblesub-sequences (modified) relaxed plan.4.3 Optimal Plannersparticipating optimal planners following, alphabetical order.BFHSP Rong Zhou Eric A. Hansen, Mississippi State University, USA. BFHSP,breadth-first heuristic search planner, optimizes number actions plan.planner implements standard max-atom max-pair heuristics (as wellmax-triple heuristic, however used IPC-4). main differencesystems search algorithm called breadth-first heuristic search; improves memoryrequirements A* search searching set nodes certain threshold valuebreadth-first instead best-first manner.CPT Vincent Vidal, University Artois, France, Hector Geffner, UniversityPompeu Fabra, Barcelona, Spain. CPT optimizes makespan. planner basedconstraint satisfaction, transforms planning problem CSP. branchingscheme solves CSP makes use several constraint propagation techniques relatedPOCL, temporal max-atom heuristic.HSPa Patrik Haslum, Linkoping University, Sweden. HSP*a derivate TP4, seebelow, expressivity, weakened version MaxTriple heuristicinstead MaxPair heuristic.535fiHoffmann & EdelkampOptiplan Menkes van der Briel Subbarao Kambhampati, Arizona State University, USA. Optiplan planner based integer programming (IP), consequent extension encoding planning graph used planning satisfiabilityapproach (see below). compiled planning problem solved using CPLEX/ILOGsystem. interesting property Optiplan that, due power underlying IPsolver, optimize great variety different plan metrics, fact every plan metricexpressed linear function. respect, planner unique.IPC-4, step-optimal plans computed typically efficient.SATPLAN04, SATPLAN short, Henry Kautz, David Roznyai, Farhad TeydayeSaheli, Shane Neph, Michael Lindmark, University Washington, USA. SATPLANtreats non-temporal non-numeric domains optimizes number parallel time steps.system participate IPC-3 IPC-1 IPC-2, real comeback.planner compiles planning problem series satisfiability tests, performancesystem relies integrated back-end SAT solver. graph-plan encoding schemeunderwent minor changes, underlying SAT solver much powerful4 years ago.SemSyn Eric Parker, Semsyn Software, Tempe, Arizona. SemSyn system optimizes number actions. Semsyn linked commercial product appliescombination forward backward chaining. searches variants originalalgorithms. Forward chaining goal-directed, backward chaining generalized, comprising partition top-level goal. product proprietary, detailed informationsystem limited.TP4-04, TP4 short, Patrik Haslum, Linkoping University, Sweden. plannerextended makespan-optimal scheduling system IDA* search routinemax-pair heuristic. deal restricted form metric planning problemsnumerical preconditions effects.5. ResultsCPU times IPC-4 measured machine located Freiburg, running 2Pentium-4 CPUs 3 GHz, 6 GB main memory. Competitors logged remotelyran planners, producing one separate ASCII result file solved instance,giving runtime taken, quality found plan, well plan itself.planner run allowed half hour (CPU, real) runtime, 1 GB memory,i.e., cutoff values solving single instance. kind performancemeasure, IPC-3 version LPG (Gerevini, Saetti, & Serina, 2003) (called LPG-3),i.e. successful automatic planner IPC-3, also run (by developers,top workload new planner version LPG-TD). remark that, sakesimplicity, save CPU time, ensure fairness, randomized planners allowedsingle run one ach instance, fixed random seed.IPC-4 featured lot domain versions instances, lot planners.way fully understand results complex event examine resultsdetail, making sense combination descriptions/PDDL encodingsdomains, techniques used respective planners. recommend so,least extent, everybody interested results (the deterministic part536fiThe Deterministic Part IPC-4: Overviewof) IPC-4. on-line appendix paper includes individual solution files.appendix also includes gnuplot graphics generated (more details below), wellGANNT chart result files; GANNT charts visualized usingVega visualization front-end (Hipke, 2000).follows, provide overview results, highlight (what thinkare) important points; explain decided IPC-4 competitionawards.precisely, Section 5.1 gives overview results, terms percentagesattacked solved instances per language subset planner. Section 5.2 describesevaluated results, particularly procedure chose decide awards.Thereafter, Sections 5.3 5.9 turn consider detail results singledomains.5.1 Results OverviewOne crude way obtain overview large data set simply countnumber instances planner attacked, i.e. tried solve, succeededsolve. case, also makes sense distinguish different PDDL2.2 subsetsused IPC-4 benchmarks. data displayed Table 2.Table 2 complicated, needs explanation. First, consider columnstable. leftmost column is, usual, table indexing. rightmost columncontains data entire set instances IPC-4. columns referspecific subset instances, way subsets disjunctexhaustive i.e., instance sets associated columns pairwise disjunct,union entire set instances. subsets instances defined PDDL2.2subsets use. abbreviations Table 2 explained caption. X+Y meansinstances use language features X Y, none features.example, N+DP (only) instances uniform durations (i.e., PDDL2.2level 1) derived predicates. Note Table 2 column possiblecombinations language features show used (a non-emptysubset of) IPC-4 benchmarks. Note also distinguish differentdomain formulations, i.e. ADL STRIPS. instance numbers Table 2counted domain versions. is, ADL STRIPS formulationversion, instance counted once.4first line Table 2, indexed Number, simply gives size instance setassociated column. lines correspond, obviously, planning systems.upper half table contains, alphabetical order, satisficing planners; lowerhalf contains optimal planners. Note list one version LPG-TD.speed quality version planner differ terms plan quality,terms number attacked/solved instances.4. said, domain featured several domain versions, differing terms application constraintsmodelled. Within domain version, could several different domain version formulations,differing terms precise PDDL subset used encode semantics. casesone formulation, exactly two formulations, using/not using ADL constructs, respectively.Competitors could choose formulation liked best results across different formulationsevaluated together.537fiHoffmann & EdelkampNumberCRIKEYFAPFDFDDLPG-3LPG-TDMacro-FFMarvinOptopP-MEPRoadmapperSGPlanTilsapaYAHSPBFHSPCPTHSPaOptiplanSATPLANSemSynTP4N38242 7733 6483 6292 6255 6267 8757 8767 6215 6128 4968 10077293333344649298787873887874864N+DP19684 10084 10075 7434 10065 100N+NV152D+TL D+NV D+TL+NV30211627213647 6698 5542 24 45 6256 5061 37 76 62 63 100 96 50 871008 438 55 24 45 24 43 13 3264 100 75 90 78 74 85 100 7410010 69626322 10010 6250 5011 3717 6252 50563383885176575281728733877292829344640311,55661 4274 1675 2875 2854 3871 71100 2175 287 343 3856 1296 9613 11100 21100 21100 4144 30100 21100 2123 1554 37Table 2: overview IPC-4 results. Used abbreviations: N durations, DPderived predicates, NV numeric variables, durations, TL timed initialliterals. Line Number gives number instances, lines give percentagevalues. entry, right number percentage instancesattacked, left number percentage solved i.e.left number success ratio. rightmost column, middle numberpercentage attacked instances relative instances lie withinlanguage range respective planner; right number percentageattacked instances all. dash indicates planner handlelanguage subset. See detailed explanation text.Let us consider table entries leftmost rightmost columns, i.e.,entries concerning planner X language/instance subset Y. numbersentries success ratio attacked ratio. Precisely, obtainedfollows. first counted number instances planner X tried solvedefinition take domain versions (inside Y) X delivered results,set total number instances domain versions. countednumber x instances planner X succeeded solve. obtainedfirst number table entry success ratio ratio (in percent) x dividedy. obtained second number entry attacked ratio ratio (inpercent) divided size Y. space reasons, rounded percentages538fiThe Deterministic Part IPC-4: Overviewvalues shown table. dash table entry means planner Xhandle language subset Y. empty table entry means plannerhandle Y, attack instance Y.cases, namely Promela domain, see discussion Section 5.5,could formulate largest instances STRIPS (fully-grounded) representations became large. So, there, numbers test instances differentADL STRIPS formulations domain version.5 Table 2 uses numberADL instances, taking account subtlety. implies slight disadvantageterms success ratio columns N All, planners attacked smallerSTRIPS test suites. planners following, correct column N successratio parentheses: CRIKEY (51), FAP (41), LPG-TD (74), SGPlan (80), YAHSP (92),BFHSP (35), CPT (39), HSPa (52), Optiplan (41), SATPLAN (55), TP4 (37).table entries rightmost column obtained similarly above. summarize situation regarding respective planners across used language subsets.left right number entry give ratio number solved instancesnumber attacked instances, number attacked instances numberinstances, respectively. number middle entry gives ratio number attacked instances number instances lie within language rangerespective planner. included number order provide measureextent planner/team attacked instances could attack.remarks order regarding latter ratio, ratio attacked instancesgeneral. First, rule telling competitors attack everythingcompetitors free choose. retrospect, feelrule, since would make data interpretation easier. way things are, knownreason planner attack instance subset (domain version): Bad results?interested? Overlooked? Second, many planners handle subsets certain languagefeatures, like, numeric variables (NV). lead low percentages Table 2,simplicity take account details. Third, one detail takeaccount 50 382 instances column N (namely, middle-compiledversion PSR domain, see Section 5.6) formulated ADL only, thusaccessible many planners. planners able handle ADL, computingmiddle number rightmost table entry, subtracted 50 instancesinstances within language range respective planner. column N, however,took usual ratio set instances particular, Macro-FF,YAHSP, BFHSP, CPT, Optiplan, SATPLAN 87% attacked-ratio Ncolumn, 100% attacked-ratio middle number rightmost column.all, planners pretty good coverage language subset couldattack; except Optop, Tilsapa, maybe Semsyn. planners/teams probablyinterested small subset instances.6 cases instances5. PSR, also impossible formulate largest instances STRIPS. But, there, splitdomain different versions regarding size formulation language instances.want introduce distinction lines Promela already 8 different domainversions.6. Drew McDermott, developer Optop, told us private conversation tried solvecomplicated domain versions.539fiHoffmann & Edelkampleft out, planners/teams typically attack domain versions derivedpredicates timed initial literals compiled away. Note lack coveragemay also due language details accounted rather crude distinctions madeTable 2.7conclude Table 2, terms planner performance? spotlightsthese:success ratios optimal planners generally lower satisficingplanners. largest overall success ratio optimal planner, SATPLAN, 46(55 taking account mentioned subtlety regarding ADL/STRIPSformulations Promela); compared 88 FDD.However, also various cases optimal planner higher successratio satisficing one.FD, FDD, YAHSP best success ratios (as mentioned, success ratioYAHSP N column 92 taking account ADL/STRIPS Promela).FD FDD also pretty good coverage N N+DP columns, i.e.within PDDL2.2 level 1 (the left instances domain versions compiledderived predicates).SGPlan extremely high coverage, attacking 96% instances. Even so,competitive success ratio. (Concretely, SGPlan solved 1,090 1,556 IPC-4instances; attacked 1,496. second place terms number instancessolved held LPG-TD, solved 843 1108 instances could attack.)LPG-3, i.e. IPC-3 version LPG, ranges somewhere middle-groundplanners, terms success ratio coverage. indicates significantperformance improvements made difference IPC-3. (Note holdsnew LPG version top performance planners.)Naturally, evaluation results, particularly evaluation formedbasis award decisions, undertook detailed examination data set.considered, much possible, scaling behavior, rather simple instance countsabove. follows, first explain evaluation process detail, considerdomains turn.5.2 Results Evaluationsaid, runtime data satisficing optimal planners considered separately.plan quality, distinguished three kinds optimization criteria: numberactions, makespan (equalling number time steps non-temporal domains),metric value. last three defined :metric specificationrespective task. compared planner according single plan qualitycriterion. is, every domain version competitors told us criterion7. private conversation, LPG-TD team told us case LPG-TD,fact attacked domain versions could time IPC-4 running.540fiThe Deterministic Part IPC-4: Overviewplanner trying optimize domain version. evaluated (and only)planners together tried optimize criterion. reasonmake sense evaluate planners based criteria dont actually consider.Altogether, every domain version created 5 gnuplot graphics: satisficingruntime, optimal runtime, number actions, makespan, metric value.plan quality data optimal planners put plots satisficingplanners, enable comparison. cases, split runtime figure(typically, satisficing planners) two separate figures many runtimecurves graphic became unreadable.Based gnuplot graphics, evaluated data terms asymptotic runtimesolution quality performance. comparisons planners madehand, i.e. looking graphs. simplistic, believe adequateway evaluating data, given goals field, demands event.agreed interested (typical) scaling behavior plannersspecific domains. excludes formal primitive comparative performancemeasures counts instances solved efficiently planner may scale worseanother planner, yet faster lot smaller instances due pre-processingimplementation details. ideal formal measure performance would approximateactual scaling functions underlying planners data points. infeasiblegenerate enough data, event like IPC, formal approximations.tried judge scaling behaviors hand, laying emphasis efficiently/iflargest instances test suite solved planner.8rest section contains one sub-section domain turn. subsection provides following material. First, give brief description domainimportant features (such domain versions formulations used IPC-4).include set gnuplot graphics containing (what think are) importantobservations regarding runtime (the total set gnuplot graphs space-consuming).discuss plan quality, data comparing relative performance pairs planners.also add intuitions regarding structural properties domains, possibleinfluence performance planners. Finally, provide information 1st2nd places, see underlying decisions awards. informationcontained text paragraph end sub-section domain.basis deciding awards, within every domain version, identifiedgroup planners scaled best roughly similar. planners counted1st place domain version. Similarly, also identified groups 2nd placeplanners. awarding prizes simply based number 1st 2ndplaces planner, see Section 6.9consider domains alphabetical order. start,remarks made. First, planners left plots order make8. Note success ratios displayed Table 2 also crude way access scaling behavior.9. course, many decisions 1st 2nd places close; numerous specialcases due to, e.g., planners participated domain versions; summing places introducesdependency results number domain versions individual domains. handawards one make decisions, decisions lot detail bound disappear. Onecannot summarize results huge event prizes.541fiHoffmann & Edelkampplots readable. Specifically, left LPG-TD.quality well LPG-3.quality (theIPC-3 version LPG preference quality); planners always slowercounterparts preference speed. also left FD, since casesshowed similar behavior FDD. chose FDD cases performancesuperior. Note distinguish runtime performance optimalplanners optimizing different criteria. Finally, make significant difference whetherplanner run ADL encoding, compilation STRIPS; distinction alsogets lost evaluation. emphasize applied simplifications orderimprove readability understandability results. wish implyplanners/distinctions omitted arent important.5.3 AirportAirport domain, planner control ground traffic airport. taskfind plan solves specific traffic situation, specifying inbound outboundplanes along current goal positions airport. planes mustendanger other, i.e. must occupy airport segment (a smallestroad unit), plane x drives behind plane x must safetydistance (depending size y). safety constraints modelled termsblocked occupied predicates, whose value updated controlled via complexADL preconditions conditional effects.four different versions domain IPC-4: non-temporal version,temporal version, temporal version time windows, temporal versioncompiled time windows. time windows latter two versions concern airplanesknown land future, thus block certain airport segments (runways)certain time windows. time windows modelled using timed initial literals,respectively compilation. every domain version, ADL formulation,well STRIPS formulation obtained compiling ADL constructs away (resultingpartially grounded encoding).Instances scale terms size underlying airport, well numberairplanes must moved. One remarkable thing Airport domaininstances generated based professional airport simulation tool. largestinstances used IPC-4 (number 36 50) correspond real airport, namely Munichairport (MUC). Instance number 50 encodes traffic situation 15 moving airplanes,typical situations encountered MUC reality. Instances number 1 20come smaller toy airports, instances number 21 35 based one half MUCairport.Figure 1 shows runtime performance non-temporal version domain.readability, set satisficing planners split two graphs. casegraphs displayed subsequent discussions, x-axis denotes instance number(obviously, higher number larger instance), y-axis gives CPU runtimeseconds logarithmic scale. CPU time total, including parsing formstatic pre-processing.observed Figure 1 FDD planner solving problem instances. LPG-TD SGPlan scale relatively well, fail largest instances.542fiThe Deterministic Part IPC-4: Overview10000100010000LPG-TDMACRO-FFSGPLANCRIKEYFDDYAHSP10001001001010110.10.10.01FAPMARVINPMEPROADMAPPERLPG-30.0151015202530354045505101520(a)253035404550(b)10000BFHSPTP4CPTOPTIPLANSATPLANSEMSYN10001001010.10.015101520253035404550(c)Figure 1: Performance non-temporal Airport, satisficing (a) (b), optimal (c).planners behave much unreliably. Observe also IPC-3 versionLPG lags far behind FDD, LPG-TD, SGPlan. optimal planners, unsurprisingly behave clearly worse satisficing planners, clear-cut observationperformance advantage SATPLAN. optimal planners behave relativelysimilarly; Semsyn BFHSP ones group solving largerinstances.plan quality, two groups planners, one trying minimize numberactions, one trying minimize makespan, i.e. number parallel action steps.former group, plan quality performance differences moderate. CRIKEY, LPGTD, SGPlan, YAHSP sometimes find sub-optimal plans. FDDs plans optimalcases optimal planner found solution. measure comparative planquality, provide, given planners B, min, mean, maximumratio quality(A) divided quality(B), instances solvedB. call data ratio vs B. CRIKEY (A) vs FDD (B), ratio 0.91(min), 1.04 (mean), 1.45 (max), [0.91(1.04)1.45] short. LPG-TD.speed vs FDD543fiHoffmann & Edelkampratio [0.91(1.08)1.80]; LPG-TD.quality vs FDD [0.91(1.06)1.80]. SGPlanvs FDD [0.91(1.07)2.08]; YAHSP vs FDD [0.91(1.07)1.43].group planners minimizing makespan, (only) Marvin tendency findlong plans. comparison Marvin vs optimal SATPLAN [1.00(2.46)4.64].maximum case, SATPLAN finds plan 53 steps, Marvins plan 246 stepslong.interesting observation concerns two scaling parameters domain:number airplanes, size airport. plots Figure 1, alsoplots Figure 2 below, one observe instances number 26 35 becomeincreasingly hard planners step instance number 36, performancesuddenly becomes better again. said above, instances 21 35 based one halfMUC airport, instances 36 50 based full MUC airport.instances 26 35, number airplanes rises 6 12; instance 36 contains2 airplanes, instances 37 38 contain 3. is, easier planners addresslarger airport fewer planes. Note domain combinatorics: numberreachable states order n , number different airport segments,n number airplanes.Figure 2 shows runtime performance temporal versions domain.first consider domain versions without time windows: parts (a) (b) figure.satisficing planners, LPG-TD SGPlan scale wellnon-temporal case; satisficing planners scale orders magnitude worse.optimal planners, CPT scales best, followed TP4. two planners minimizingnumber actions SGPlan CRIKEY; SGPlan behaves somewhat worse, ratio[0.95(1.03)1.54]. planners minimize makespan, LPG-TD scales beyondsmallest instances. ratio LPG-TD.speed vs optimal CPT [1.00(1.15)1.70],P-MEP vs CPT [1.00(1.11)1.42]. ratio LPG-TD.quality vs CPT [1.00(1.03)1.44].optimal planner competition could handle timed initial literals, explicit time windows planner participated. compiled time windows, CPTparticipated, scaling little worse temporal domain version without time windows. satisficing planners, results interesting. explicit timewindows, LPG-TD SGPlan maintain good scaling behavior simpler domain versions. planners, huge runtime performance gap.SGPlan planner minimizes number actions. makespan ratioLPG-TD.speed vs LPG-TD.quality [1.00(1.15)2.01]. compiled time windows,SGPlan CRIKEY participated. former consistently solves smaller instancescertain size, latter fails many small instances solvelarger ones. Neither planners shows reasonable runtime performance comparedexplicit encoding domain. number actions ratio CRIKEY vs SGPlan[1.00(1.14)1.36].main motivation including Airport domain IPC-4 ablemodel quite realistically, generate quite realistic test instances thingcould model real optimization criterion (which asks minimize summedtravel time airplanes). good scaling results of, least, satisficingplanners, encouraging. Note, however, reality optimization criterioncrucial importance, really reason using computer control traffic.544fiThe Deterministic Part IPC-4: Overview1000010000TP4CPTHSPS_A100010001001001010110.10.1LPG-TDSGPLANCRIKEYPMEPLPG-30.010.0151015202530354045505101520(a)253035404550(b)1000010000SGPLANCRIKEY100010001001001010110.10.1LPG-TDSGPLANOPTOPPMEPTILSAPA0.010.0151015202530354045505(c)101520253035404550(d)Figure 2: Performance temporal Airport, satisficing (a) optimal (b). temporalAirport time windows, satisficing, explicit encoding (c) compiled encoding (d).remark domain overly difficult perspective relaxed-planbased heuristic planners (using wide-spread ignore deletes relaxation). Hoffmann(2005) shows Airport instances contain unrecognized dead ends (statesgoal cant reached, relaxed plan); stateslikely occur often. dead end Airport occur two planesblock other, trying get across segment different directions. Duetopology airports (with one-way roads), happen densely populatedparking regions. case two airplanes respective paths goal positiondisjoint, length relaxed plan provides exact distance nearest goal state.sense, good runtime performance satisficing planners didnt come entirelyunexpected us, though expect behave well. Noteplanners, particularly FDD, SGPlan, LPG-TD, much than/do things545fiHoffmann & Edelkampdifferent standard heuristic search goal distances estimated relaxed planlength. Note also Hoffmann (2005)s results specific non-temporal domains.non-temporal domain version, awarded 1st places FDD (and FD)SATPLAN; awarded 2nd places LPG-TD, SGPlan, Semsyn, BFHSP.temporal version, awarded 1st places LPG-TD, SGPlan, CPT; 2nd placeawarded TP4. domain version explicit time windows, 1st places awardedLPG-TD SGPlan.5.4 PipesworldPipesworld domain PDDL adaptation application domain dealing complex problems arise transporting oil derivative products pipeline system. Note that, many planning benchmarks dealing variants transportation problems, transporting oil derivatives pipeline system different characteristic kind structure. pipelines must filled liquid times,push something pipe one end, something possibly completely differentcomes end. result, domain exhibits interesting planningspace characteristics good plans sometimes require tricky maneuvers. Additionaldifficulties dealt are, example, interface restrictions (different typesproducts interfere pipe), tankage restrictions areas (i.e., limitedstorage capacity defined product places pipe segments connect),deadlines arrival time products.form domain used IPC-4, product amounts dealt discrete sense assume smallest product unit, called batch. sixdifferent domain versions IPC-4: notankage-nontemporal, notankage-temporal, tankagenontemporal, tankage-temporal, notankage-temporal-deadlines, notankage-temporaldeadlines-compiled. versions include interface restrictions. versions tankagename include tankage restrictions, modelled number tank slotsplace network, slot hold one batch (note slots introduceadditional symmetry problem; get back below). versionstemporal name, actions take (different amounts of) time. versionsdeadlines name include deadlines arrival goal batches, modelledtimed initial literals respectively compilation standard PDDL2.1. Noneencodings uses ADL constructs, domain version one (STRIPS)formulation.IPC-4 example instances generated based five scaling network topologies. smallest network topology 3 areas connected 2 pipes; largest networktopology 5 places connected 5 pipes. network generated 10 instances,growing numbers batches, batches goal location. altogether50 instances per domain version, numbered consecutively. domain versions,instances were, much possible, transferred adding/removing constructs. E.g.,instances tankage-nontemporal (tankage-temporal) exactlynotankage-nontemporal (notankage-temporal) except tankage restrictions added.include graphs domain versions featuring deadlines. version explicit deadlines (modelled timed initial literals), LPG-TD Tilsapa546fiThe Deterministic Part IPC-4: Overview1000010000LPG-TDMACRO-FFSGPLANCRIKEYFDD1000FAPMARVINROADMAPPERPMEPYAHSPLPG-310001001001010110.10.10.010.0151015202530354045505101520(a)253035404550(b)10000BFHSPTP4CPTOPTIPLANSATPLANSEMSYN10001001010.10.015101520253035404550(c)Figure 3: Non-temporal Pipesworld, tankage constraints, satisficing (a) (b), optimal(c).participated, LPG-TD scaled middle-size instances; Tilsapa solvedsmallest instances. domain version compiled deadlines, CPTparticipated, solving small instances.Figure 3 shows results non-temporal domain version without tankage restrictions. Parts (a) (b) contain results satisficing planners respectivenon-temporal domain version. observe YAHSP SGPlan plannerssolve instances. YAHSP lot faster instances; finds excessivelylong plans: ratio YAHSP vs SGPlan [0.38(1.77)14.04], maximum caseSGPlan needs 72 actions, YAHSP 1,011. planners, plan qualityvary much, exception Marvin, whose makespan ratio vs optimal CPT[0.88(1.60)2.19]. LPG-TD FDD solve largest instances. Notethat, Airport, IPC-3 version LPG outperformed dramatically bestIPC-4 planners.547fiHoffmann & Edelkamp1000010000LPG-TDSGPLANCRIKEYPMEPLPG-31000TP4CPTHSPS_A10001001001010110.10.10.010.0151015202530354045505(a)101520253035404550(b)Figure 4: Temporal Pipesworld without tankage constraints, satisficing (a), optimal (b).Part (c) Figure 3 shows results optimal planners. runtime curvesextremely similar, nearing indistinguishable. Note Optiplan optimal plannersolves instance large size parameter. However, Pipesworld, likeAirport, due domain combinatorics, planners likely find easier solve largenetwork little traffic, small network lot traffic.10 optimalplanners may tried run planner larger instances alreadyfailed smaller ones explicitly advised people save machine workloadinsisting spending half hour runtime instances probably infeasibleplanners anyway. cases like one here, admittedly potentially misleadingguideline.parts (a) (b) Figure 4, display results temporal domain versionwithout tankage restrictions. Part (a) shows clear win SGPlan planners.find particularly remarkable that, Airport, SGPlan goodtemporal domain version nontemporal one. Again, LPG-3 outperformed far.optimal planners part (b) figure, CPT scales best; TP4 HSPa scalesimilarly. planners minimizing number actions CRIKEY SGPlan; ratio [0.35(1.24)5.67], showing quite variance slight mean advantageSGPlan. planners minimizing makespan, LPG-TD P-MEP sometimes returnlong plans; one instance (number 2), LPG-TDs plan extremely long (makespan 432).precisely, ratio LPG-TD.speed vs optimal CPT [1.00(4.55)36.00]; ratioP-MEP vs CPT [1.19(2.25)4.59]; ratio LPG-TD.quality vs CPT [0.73(1.05)1.62](i.e., particular peak instance 2 disappears LPG-TD.quality). Note that,strangely first sight, sometimes LPG-TD finds better plans optimal CPT.10. hand, note point networks Pipesworld far grow muchAirport, grow microscopic toy airports smallest instances real-world airportlargest instances. said, smallest network Pipesworld 3 areas connected 2 pipes,largest network 5 places connected 5 pipes.548fiThe Deterministic Part IPC-4: Overview1000010000LPG-TDMACRO-FFSGPLANCRIKEYFDD1000FAPMARVINROADMAPPERYAHSPLPG-310001001001010110.10.10.010.015101520253035404550510152025(a)3035404550(b)10000BFHSPCPTOPTIPLANSATPLAN10001001010.10.015101520253035404550(c)1000010000LPG-TDSGPLANCRIKEYLPG-3TP4CPTHSPS_A100010001001001010110.10.10.010.0151015202530354045505(d)101520253035404550(e)Figure 5: Pipesworld tankage constraints: non-temporal satisficing (a) (b), optimal (c), temporal satisficing (d), optimal (e).due somewhat simpler model durative actions CPT uses (Vidal &Geffner, 2004), making distinction start end time points actions.549fiHoffmann & EdelkampFigure 5, results displayed two domain versions feature tankagerestrictions. generally, see planners much troubledomain versions less constrained counterparts.non-temporal domain version tankage constraints, satisficing plannersparts (a) (b) observe that, before, YAHSP efficient, solvinginstances planners. Again, efficiency bought costoverlong plans: ratio YAHSP vs. SGPlan [0.66(1.89)6.14], maximumcase SGPlan needs 64 actions, YAHSP 393. planners, plan qualityvary much (e.g. ratio FDD vs SGPlan [0.56(0.96)1.38]. optimal plannersdisplayed part (c), non-temporal domain version, SATPLAN Optiplan scalelittle better planners, solving two three instances, respectively.SATPLAN tends faster Optiplan solved cases. Part (d) displaysresults satisficing planners respective temporal domain version. SGPlanclearly scales best, keeping performance corresponding non-temporaldomain version. LPG-TD followed relatively closely CRIKEY solveinstances. Regarding plan quality, CRIKEY SGPlan minimize plan length,ratio CRIKEY vs SGPlan [0.62(1.37)2.54]. makespan, LPG-TD peakinstance 2; ratio LPG-TD.speed vs CPT [1.00(2.55)7.27], maximum 160 vs 22units; ratio LPG-TD.quality vs CPT [0.86(0.95)1.18] (LPG-TD.qualitys makespaninstance 2 26). Note that, above, LPG-TD.quality find better plans CPTdue somewhat simpler model durative actions used CPT. optimal track,TP4 performs little better, terms runtime, similar-performing CPTHSPa ; planners solve smallest instances.remark rather surprised relatively good scaling behaviorplanners, particularly fastest satisficing planners domain versions withouttankage restrictions. Hoffmann (2005) shows that, Pipesworld, arbitrarilydeep local minima relaxed plan distances (i.e., distance local minimumbetter region state space may arbitrarily large). particularly unusualconstructs needed provoke local minima example, cycle pipe segments,also occurs network topologies underlying IPC-4 instances, suffices. lessimportantly, limited experiments testing, FF (Hoffmann & Nebel,2001) Mips (Edelkamp, 2003c) generally scaled much worse than, e.g., YAHSPSGPlan shown above.domain versions feature tankage restrictions, hardercounterparts. two important differences domain versionswith/without tankage restrictions. First, problem constrained (remember that,modulo tankage constraints, IPC-4 instances identical respective versions). Second, tank slots, model restrictions, introduce additional symmetryproblem: planner choose (free) slot insert batch.choice make difference, enlarges state space exponentially numberchoices (to basis number tank slots). considered option usecounter encoding instead, avoid symmetry: one could count product amountsareas, impose tankage restrictions based counter values. decidedsymmetry challenging aspect benchmark.550fiThe Deterministic Part IPC-4: Overviewdomain version notankage-nontemporal, awarded 1st places YAHSP SGPlan; awarded 2nd places LPG-TD FDD. version notankage-temporal,awarded 1st places SGPlan CPT; awarded 2nd places LPG-TD, TP4,HSPa . version tankage-nontemporal, awarded 1st places YAHSP FDD;awarded 2nd places SGPlan, SATPLAN, Optiplan. version tankage-temporal,awarded 1st place SGPlan; awarded 2nd places LPG-TD TP4. versionnotankage-temporal-deadlines, awarded 1st place LPG-TD.5.5 PromelaPromela input language model checker SPIN (Holzmann, 2004), usedspecifying communication protocols. Communication protocols distributed softwaresystems, many implementation bugs arise, like deadlocks, failed assertions,global invariance violations. model checking problem (Clarke, Grumberg, & Peled,2000) find errors returning counter-example, verify correctnesscomplete exploration underlying state-space. Edelkamp (2003b) developedautomatic translation problem, i.e., Promela language, (non-temporal)PDDL, making possible apply state-of-the-art planners without modification.IPC-4, two relatively simple communication protocols selected benchmarkstoy problems Model-Checking area. One well-known Dining-Philosophersprotocol, larger protocol called Optical-Telegraph. main point usingdomain, protocols, IPC-4 promote connection PlanningModel-Checking, test state-of-the-art planners scale basic problemsarea.IPC-4 instances exclusively require find deadlocks specified protocolsstates transitions possible. rules detect whethergiven state deadlock naturally modelled derived predicates, complexADL formulas rule bodies. enable broad participation, provided compilationsderived predicates additional actions, ADL STRIPS. Edelkamps originaltranslation Promela PDDL also makes use numeric variables. non-numericplanners, translation adapted use propositional variables relativelysimple Dining-Philosophers Optical-Telegraph protocols, possible.Precisely, domain versions formulations following. First, versions split modelled protocol, Dining-Philosophers Optical-Telegraph. Second, versions split used language: with/without numeric variables,with/without derived predicates.11 So, all, 8 domain versions.used ADL constructs. 4 versions without numeric variables, also providedSTRIPS formulations, obtained ADL formulations automatic compilationsoftware based FFs pre-processor (Hoffmann & Nebel, 2001), producing fully groundedencodings. Promela domain versions non-temporal.Here, show plots results obtained non-numeric domain versions.domain versions using numeric variables derived predicates, planner11. split with/without numeric variables different domain versions, rather formulations,encourage use numeric planning techniques. split with/without derived predicates differentversions since, modelling derived predicates new actions, plans become longer.551fiHoffmann & Edelkamp1000010000LPG-TDMACRO-FFSGPLANCRIKEYFAPPMEPYAHSP1000BFHSPTP4CPTHSPS_AOPTIPLANSATPLANSEMSYN10001001001010110.10.10.010.01510152025303540455101520(a)2530354045(b)10000LPG-TDSGPLANFDDMARVIN10001001010.10.0151015202530354045(c)Figure 6: Performance Promela/Dining Philosophers. Encoding without derived predicates, satisficing (a), optimal (b). Encoding derived predicates, satisficing(c).participated. numeric version Dining-Philosophers (without derived predicates),SGPlan P-MEP participated. SGPlan solved instances P-MEP solvedsmallest ones. numeric version Optical-Telegraph (withoutderived predicates), SGPlan participated, solving relatively small instances.Parts (a) (b) Figure 6 show results Dining-Philosophers, without derivedpredicates, i.e. additional actions derive deadlocks. satisficingtrack, YAHSP SGPlan clearly show best performance. planners lagseveral orders magnitude behind. optimal track, SATPLAN clearly scales best,followed Optiplan. Observe that, difference seen AirportPipesworld, optimal planners efficient satisficing ones. evidentplots. particularly, SATPLAN Optiplan solve many instances,30 philosophers (instance number x features x + 1 philosophers), like YAHSP552fiThe Deterministic Part IPC-4: OverviewSGPlan.12 SATPLAN even comparable time. competitivity optimalplanners satisficing ones seen test suite used lastthree competitions.13 efficiency SATPLAN Optiplan Dining-Philosophersprobably due fact needed number parallel time steps constantly 11 acrossinstances (see below). (standard) planning graph (Blum & Furst, 1995, 1997),goals first reached 7 steps; 4 unsuccessful iterations made planfound.Regarding plan quality, one group planners trying minimize numberactions, one group trying minimize makespan (the number parallel actionsteps). results clearly point important difference domainIPC-4 domains. Namely, single scaling parameter n numberphilosophers single instance per value n. optimal number actionslinear function n, precisely 11n: basically, one blocks philosophers sequence,taking 11 steps each. optimal makespan is, mentioned above, constantly 11:one block philosophers parallel. sub-optimal plan found plannerminimizing number actions CRIKEY n = 8, containing 104 instead88 actions. planners minimizing makespan, P-MEP finds sub-optimal plans:solves smallest four instances, n = 2, 3, 4, 5, makespan 19, 25, 30, 36,respectively.Figure 6 (c) shows results domain version uses derived predicatesdetect deadlock situations. optimal planner could handle derived predicatesresults this. satisficing planners, SGPlan clearly showsbest performance. FDD LPG-TD roughly similar note that, LPG-TDfaster FDD examples, behavior FDD largest instances indicatesadvantage scaling. sudden large increase LPG-TDs runtime,second largest instance (that solved 52 seconds) largest instance (thatsolved 1045 seconds). difference that, FDD solves largest instance almosttime second largest one, taking 111 seconds instead 110 seconds (in fact,FDDs runtime performance shows little variance pretty much linear functioninstance size). remark plans largest instances huge:400 steps long, see below. SGPlan generates plans littlesingle second CPU time.Regarding plan quality, domain version optimal number actions 9n,optimal makespan constantly 9. planners except Marvin tried minimizenumber actions. FD SGPlan always find optimal plans. FDD, LPG-TD.speed,LPG-TD.quality sometimes find slightly sub-optimal plans. Precisely, ratio FDD vsFD [1.00(1.08)1.44]; LPG-TD.speed vs FD [1.00(1.10)2.19]; LPG-TD.quality vs FD[1.00(1.03)1.24]. Marvin, makespan plans is, roughly, linear n; alwayslies 7n 9n.12. Importantly, planners handle STRIPS, compilation reasons STRIPS instances n = 30 only. planners solve respective test instances. discusslittle detail below.13. first IPC, 1998, apart fact heuristic search satisficing planners stillinfancy, Mystery Mprime used benchmarks. cant solved particularlyefficiently planner today, except, maybe, FD FDD (Helmert, 2004).553fiHoffmann & Edelkamppoint, important remark made detail regardingcompilation techniques domain versions. Observe huge gap planner performance Figure 6 (a) (b), Figure 6 (c). seen, differenceplan length (makespan) large 11n (11) compared 9n (9). Indeed, apparent performance difference due compilation detail, inherent IPC-4 instances,rather planner performance. version without derived predicates,able compile instances n = 30 philosophers ADL STRIPS.larger values n, (fully-grounded) STRIPS representations became prohibitivelylarge. version derived predicates, blow-up lot smaller, couldcompile instances, n = 49 philosophers. SGPlan, YAHSP, SATPLAN,Optiplan handle STRIPS. So, mentioned above, Figure 6 (a) (b)planners actually solve instances respective test suite; would probably scaleprovided STRIPS representations instances larger n values.1000010000LPG-TDMACRO-FFSGPLANCRIKEYFAPPMEPYAHSP1000BFHSPTP4CPTHSPS_AOPTIPLANSATPLAN10001001001010110.10.10.010.01510152025303540455101520(a)2530354045(b)10000LPG-TDSGPlanFDDMARVIN10001001010.10.0151015202530354045(c)Figure 7: Performance Promela/Optical Telegraph. Encoding without derived predicates, satisficing (a), optimal (b). Encoding derived predicates, satisficing(c).554fiThe Deterministic Part IPC-4: OverviewOptical-Telegraph protocol slightly complex Dining-Philosopherexample, i.e. involves complicated indirect interactions communicating processes, leading longer solutions. still one scaling parameter,number n telegraph station pairs, single instance per value n. telegraphstation pair pair processes goes rather complicated internal communication structure, enabling exchange data. telegraph station pair sharesoutside world i.e., telegraph station pairs two control channelsmust occupied prerequisite internal exchange data. Thus, rolecontrol channels pretty similar role (shared) forks Dining-Philosopherexample. Instance number x IPC-4 features x + 1 telegraph station pairs.Figure 7 shows parts (a) (b) performance satisficing optimalplanners, respectively, domain version using additional actions derive deadlocks.group satisficing planners, Macro-FF clearly performs best. satisficingplanners, SGPlan efficient. important note that, here, ablecompile instances n = 15 ADL STRIPS. SGPlan LPG-TDsolve respective test instances. optimal planners, SATPLAN Optiplansolve instances n = 14, i.e., failed solve largest instance STRIPStest suite attacked. SATPLAN much faster Optiplan. optimalplanners could solve smallest instance, n = 2. Figure 7 (c) shows FDD,handles ADL formulation, far successful satisficing planner domainversion encoding Optical-Telegraph derived predicates deadlock detection;planners, SGPlan scales best, solving instances STRIPS set, n = 20.Regarding plan quality, Optical-Telegraph without derived predicates optimalnumber actions 18n, optimal makespan constantly 13: optimal sequentialplans block telegraph station pairs sequence, taking 18 steps each; parallelplans, simultaneous actions possible within telegraph station pair. OpticalTelegraph derived predicates, optimal number actions 14n, optimalmakespan constantly 11. competition results, planners returned optimalplans test suites, cases single exception. plans found Marvinversion derived predicates makespan 14n solved cases.seen, results Promela are, all, quite different from, e.g.,seen Airport Pipesworld. single scaling parameter singleinstance per size, optimal makespan constant. leads rather smooth runtimeplan quality curves, well unusual competitivity optimal plannerssatisficing planners. scalability planners shows current plannersable efficiently solve basic Model-Checking benchmarks (Dining-Philosophers),efficient solving complex Model-Checking benchmarks(Optical-Telegraph). remark Hoffmann (2005) shows exist arbitrarilydeep local minima relaxed plan distances Optical-Telegraph, DiningPhilosophers, exists large upper bound (31) number actions neededescape local minimum. clear, however, much theoretical resultsplanner performance observed above. worst-cases observed Hoffmannoccur regions state space entered plans optimal number actionsfound IPC-4 participants, cases.555fiHoffmann & EdelkampDining-Philosophers without derived predicates, awarded 1st places YAHSP,SGPlan, SATPLAN; awarded 2nd place Optiplan. Dining-Philosophersderived predicates, awarded 1st place SGPlan, 2nd places FDD LPG-TD.Optical-Telegraph without derived predicates, awarded 1st places Macro-FFSATPLAN; awarded 2nd places SGPlan Optiplan. Optical-Telegraphderived predicates, awarded 1st place FDD, 2nd place SGPlan.numeric version Dining-Philosophers, awarded 1st place SGPlan.5.6 PSRPSR short Power Supply Restoration. domain PDDL adaptation application domain investigated Sylvie Thiebaux researchers (Thiebaux, Cordier,Jehl, & Krivine, 1996; Thiebaux & Cordier, 2001), deals reconfiguring faultypower distribution system resupply customers affected faults. original PSRproblem, various numerical parameters breakdown costs power margins needoptimized, subject power capacity constraints. Furthermore, locationfaults current network configuration partially observable, leadstradeoff acting resupply lines acting reduce uncertainty. contrast,version used IPC-4 set pure goal-achievement problem, numerical aspectsignored, total observability assumed. Temporality significant aspect evenoriginal application, IPC-4 domain non-temporal.used four domain versions PSR IPC-4. Primarily, versions differsize problem instances encoded. instance size determined languages able formulate domain version. domain versions named1. large, 2. middle, 3. middle-compiled, 4. small. Version 1 single formulation adl-derivedpredicates: natural formulation, domain comes derivedpredicates model flow electricity network, ADL formulasexpress necessary conditions status network connectors. Version 2formulations adl-derivedpredicates, simpleadl-derivedpredicates, strips-derivedpredicates.Version 3 single formulation adl, version 4 single formulation strips.indicated, formulation names simply give language used. version 2, ADLconstructs compiled away obtain simpler formulations. version 3, derivedpredicates compiled away introducing additional artificial actions; due increase plan length (which discuss detail below), turnedseparate domain version, rather formulation. strips domain version,enable encoding reasonably-sized instances adopted different fully-groundedencoding inspired work Bertoli et al. (2002). encoding generated description problem instance tool performing reasoning devotedplanner domain versions. Still able formulate comparativelysmall instances pure STRIPS.Starting performance smallest instances, depict performancesatisficing optimal planners PSR STRIPS domain Figure 8. result graphsdivided two completely unreadable otherwise. planners showlot variance domain, blurring performance differences (observable)individual systems. Still possible identify systems behave better others.556fiThe Deterministic Part IPC-4: Overview1000010000LPG-TDSGPLANCRIKEYFDDMARVINYAHSPLPG-3100010001001001010110.10.10.010.0151015202530354045505101520(a)253035404550(b)1000010000BFHSPTP4CPTHSPS_AOPTIPLANSATPLANSEMSYN100010001001001010110.10.10.010.0151015202530354045505(c)101520253035404550(d)Figure 8: PSR small, satisficing (a) (b), optimal (c) (d).satisficing systems, FDD solve 50 instances; consistentlyfast (the results FD almost identical). planners, LPG-TD, SGPlan,YAHSP best success ratio: solve 49, 47, 48 instances, respectively;CRIKEY solves 29 instances, Marvin 41. optimal systems, systemsolving entire test suite SATPLAN. BFHSP solved 48 instances, CPT 44, HSPa 44,Optiplan 29, Semsyn 40, TP4 38.plan quality, groups planners trying minimize planlength (number actions), makespan. former group, take performance measure plans found BFHSP, optimal sense, which,said above, 2 50 instances. ratio CRIKEY vs BFHSP[1.00(1.72)3.44]; ratio FDD vs BFHSP [1.00(1.02)1.52]; ratio LPG-TD.speed vsBFHSP [1.00(5.52)12.70]; ratio LPG-TD.quality vs BFHSP [1.00(1.82)8.32];ratio SGPlan vs BFHSP [1.00(1.01)1.24]; ratio YAHSP vs BFHSP [1.00(1.00)1.05].planner group minimizing makespan, planners except Marvin optimal.ratio Marvin vs SATPLAN [1.00(1.28)2.07].557fiHoffmann & Edelkamp1000010000LPG-TDSGPLANFDDMARVINSGPLANFDDMARVIN100010001001001010110.10.10.010.0151015202530354045505(a)101520253035404550(b)Figure 9: PSR, middle (a) large (b), satisficing planners.Apart observations made within groups satisficing respectivelyoptimal planners, something said relationshiptwo groups. Like Dining-Philosophers, rather unusual situationoptimal planners efficient satisficing ones. Indeed, solving instances,SATPLAN superior satisficing planners. remark pointHoffmann (2005) shows existence arbitrarily deep local minima PSR, i.e., regionstakes arbitrarily many step escape local minimum relaxed plan distances.example, local minima arise naturally relaxed plan able supplysupply line time, thereby make crucial distinctionfaulty non-faulty lines. Now, observations hold original domainformulation, derived predicates ADL constructs. said, IPC-4 STRIPSformulation PSR obtained combination complicated pre-processingmachines. likely make real structure domain amenablerelaxed plan distances. satisficing planners participating PSR smallmeans exclusively dependent relaxed plan distances, distancesform important part search heuristics.Figure 9 gives results PSR domain versions, middle large, largerinstances, encoded ADL constructs and/or derived predicates. optimal plannercould handle language constructs, unfortunately comparisontwo groups continued. middle sized instances, FDD, SGPlan,LPG-TD scale entire test suite. FDD indicates better scaling behaviorlargest instances. domain version large instances (available formulationusing ADL), FDD indeed shows outperforms planners (at least, SGPlan,also participates here) far. data FD almost identical FDD.Regarding plan quality, participating planner middle largetries minimize makespan Marvin, basis comparison.planners, SGPlan generally finds plans smallest number actions. Precisely, middle version plan quality ratios follows. ratio FDD vs558fiThe Deterministic Part IPC-4: OverviewSGPlan [0.67(1.23)2.33] (FD: [0.67(1.25)2.85]). ratio LPG-TD.speed vs SGPlan[0.67(1.82)7.27]; maximum case instance number 49, LPG-TD.speed takes 80steps SGPlan 11. ratio LPG-TD.quality vs SGPlan [0.60(1.08)7.27],maximum case. large version, FD FDD solve considerable numberinstances; ratio FD vs FDD [0.60(1.01)1.30].PSR domain version middle-size instances derived predicates compiledADL, i.e., domain version middle-compiled, Macro-FF SGPlan participated.Macro-FF scaled relatively well, solving 32 instances instance number 48. SGPlansolved 14 instances instance number 19. planners try minimizenumber actions, ratio SGPlan vs Macro-FF [0.51(1.28)1.91].interesting observe that, PSR, compiling derived predicates away,plan length increases much seen Section 5.5 DiningPhilosophers Optical-Telegraph. latter, derived predicates replace twoaction applications per process, detecting respective process blocked. PSR,however, said derived predicates model flow electricity network,i.e., encode transitive closure underlying graph. number additionalactions needed simulate latter grows, course, size graph.phenomenon observed IPC-4 plan length data. PSR middle-compiledinstances identical middle instances, except compilation derived predicates. Comparing plan quality Macro-FF middle-compiled SGPlanmiddle, obtain remarkably high ratio values [7.17(12.53)25.71]. maximumcase instance number 48 largest instance solved Macro-FF Macro-FFtakes 180 steps solve compiled instance, SGPlan takes 7 steps solveoriginal instance.14domain version small, awarded 1st places FDD (and FD), SATPLAN;awarded 2nd places LPG-TD, SGPlan, YAHSP, BFHSP. domain version middle,awarded 1st place FDD (and FD); awarded 2nd places LPG-TD SGPlan.domain version middle-compiled, awarded 1st place Macro-FF. domain versionlarge, awarded 1st place FDD (and FD).5.7 SatelliteSatellite domain introduced IPC-3 Long Fox (2003). motivatedNASA space application: number satellites take images numberspatial phenomena, obeying constraints data storage space fuel usage. IPC-3,domain versions Strips, Numeric, Time (action durations expressionsstatic variables), Complex (durations numerics, i.e. union NumericTime). numeric variables transport complex problem constraints, regardingdata capacity fuel usage.IPC-4, domain made little realistic additionally introducing timewindows sending image data earth, i.e. antennas visiblesatellites certain periods time. added new domain versions Time14. Macro-FF optimal planner, optimal plan lengths middle-compiled instances known, seems highly unlikely observations due overlong plansfound Macro-FF.559fiHoffmann & Edelkamptimewindows, Time-timewindows-compiled, Complex-timewindows, Complex-timewindowscompiled, introducing time windows, explicit compiled, IPC-3 TimeComplex versions, respectively.15 None domain versions uses ADL constructs,versions single (STRIPS) formulation. instances were, much possible, taken original IPC-3 instance suites. Precisely, Strips, Numeric, Time,Complex versions contained 20 instances posed IPC-3 fully-automaticplanners, plus 16 instances posed IPC-3 hand-tailored planners. Timetimewindows Time-timewindows-compiled, extended 36 instances Timetime windows. Similarly, Complex-timewindows Complex-timewindowscompiled, extended 36 instances Complex time windows. is,newly added domain versions sole difference previous instances liestime windows.Let us first consider results simpler versions Satellite domain. Figure 10shows results Strips Time versions. many satisficing planners,Strips version pose serious problem, see Figure 10 (a). Macro-FF YAHSPshow best runtime behavior, followed closely LPG-TD FDD (as well FD).optimal planners Figure 10 (b), none scales far. SATPLANefficient, solving 11 instances; CPT Semsyn solve 9 instances, Optiplan solves8, BFHSP solves 6. Time version, LPG-TD SGPlan behave similarlyinstance number 30, LPG-TD solves two more, larger, instances. Time optimalplanners, see Figure 10 (d), clearly headed CPT.Regarding efficiency satisficing planners Strips test suite, remarkinstances solved quite efficiently IPC-3 already, e.g. FF LPG-3.Further, Hoffmann (2005) shows that, domain, relaxed plan distance,non-goal state, one reach state strictly smaller heuristic value within5 steps. sense, results depicted Figure 10 (a) didnt come surprise us.Let us consider plan quality Strips Time. domain versions,addressed optimization criteria plan length, makespan. Strips, plan qualitybehavior planners trying minimize plan length rather similar. overallshortest plans found LPG-TD.quality. Precisely, ratio FDD vs LPG-TD.quality[0.96(1.19)1.48]; ratio FD vs LPG-TD.quality [0.96(1.20)1.53]; ratio LPGTD.speed vs LPG-TD.quality [1.00(1.12)1.31]; ratio Macro-FF vs LPG-TD.quality[0.95(1.03)1.17]; ratio Roadmapper vs LPG-TD.quality [1.00(1.35)1.71]; ratioSGPlan vs LPG-TD.quality [0.99(1.07)1.70]; ratio YAHSP vs LPG-TD.quality[0.97(1.22)1.93]. planners trying optimize makespan Strips version,Marvin P-MEP satisficing; Marvin planner scales largerinstances. ratio P-MEP vs SATPLAN (which solves superset instances solvedP-MEP) [1.01(2.22)3.03]. ratio Marvin vs SATPLAN [1.08(2.38)4.00].Time version, planner minimizing plan length (i.e., number actions) SGPlan, basis comparison. satisficing planners trying15. new domain versions derived Complex, also introduced utilities time windowinside image sent earth. image, utility either windows,decreases monotonically start time window, random within certain interval.image put randomly one classes, optimization requirement minimizelinear combination makespan, fuel usage, summed negated image utility.560fiThe Deterministic Part IPC-4: Overview10000100001000100010010010101BFHSPCPTOPTIPLANSATPLANSEMSYN1LPG-TDMACRO-FFSGPLANFDDMARVINPMEPROADMAPPERYAHSPLPG-30.10.10.010.01510152025303551015(a)20253035(b)1000010000TP4CPTHSPS_A100010001001001010110.10.1LPG-TDSGPLANPMEPLPG-30.010.0151015202530355(c)101520253035(d)Figure 10: Satellite; Strips satisficing (a), optimal (b), Time satisficing (c), optimal(d).minimize makespan P-MEP LPG-TD. small instances solved CPT (actually, superset solved P-MEP), ratio P-MEP vs CPT [1.10(3.71)6.49].ratio LPG-TD.speed vs CPT [1.33(3.37)5.90]; ratio LPG-TD.quality vs CPT[0.85(1.24)1.86]. Note that, like seen Pipesworld before, sometimes LPG-TDfinds better plans optimal CPT. said, due somewhat simplermodel durative actions CPT uses (Vidal & Geffner, 2004), making distinctionstart end time points actions.Figure 11 (a) shows results Satellite Numeric, together participating planners optimal planner participated Semsyn. SGPlan LPG-TDscale best; solve number instances, SGPlan solves larger onesleast order magnitude faster instances solved both. Regardingplan quality, SGPlan planner trying minimize plan length.planners tried minimize metric value plan, i.e., quality metric specifiedinstance files, fuel usage. best plans respect found LPG561fiHoffmann & Edelkamp1000010000LPG-TDSGPLANPMEPSEMSYNLPG-31000LPG-TDSGPLAN10001001001010110.10.10.010.01510152025303551015(a)20253035(b)1000010000LPG-TDSGPLANTILSAPA100010001001001010110.10.1LPG-TDSGPLANPMEPLPG-30.010.0151015202530355(c)101520253035(d)Figure 11: Satellite; Numeric (a), Time-timewindows (b), satisficing Complex (c),Complex-timewindows (d).TD.quality; unclear us Semsyn marked optimize metric value here,find optimal plans. ratio LPG-TD.speed vs LPG-TD.quality[1.00(2.26)4.69]; ratio P-MEP vs LPG-TD.quality [1.01(2.16)3.03]; ratio Semsynvs LPG-TD.quality [1.00(1.28)1.58].Time-timewindows, optimal planner could participate due timed initialliterals. satisficing planners, see Figure 11 (b), SGPlan LPG-TD participated, scaled relatively well, clear advantage SGPlan. Regardingplan length, SGPlan minimizes number actions, LPG-TD makespan. ratio LPG-TD.speed vs LPG-TD.quality [1.00(1.22)1.51]. Time-timewindows-compiled,SGPlan CPT participated. SGPlan largely maintained performanceTime-timewindows version, CPT could solve 3 smallest instances. Plan quality cant compared due different criteria (plan length makespan)minimized.562fiThe Deterministic Part IPC-4: OverviewFigure 11 (c) shows performance satisficing planners Satellite Complex.SGPlan LPG-TD scale well, particular much better competitor,P-MEP. largest three instances, SGPlan shows clear runtime advantage LPGTD. optimal track, TP4 HSPa competed here. solved foursmall instances, numbers 1, 2, 3, 5, almost runtime. SGPlanplanner minimizing number actions. planners, try minimizemakespan, LPG-TD scales large instances. ratio LPG-TD.speed vs LPGTD.quality [1.01(2.76)4.71]. ratio LPG-TD.speed vs TP4 [1.81(2.09)2.49]; ratioLPG-TD.quality vs TP4 [0.93(1.07)1.19]; ratio P-MEP vs TP4 [1.27(2.25)3.32].CPT, better plan (in one case) found LPG-TD.quality duesomewhat simpler action model used TP4 (Haslum & Geffner, 2001).Figure 11 (d) shows performance planners Complex-timewindowsabove, due timed initial literals optimal planner could compete here. SGPlanscales clearly best, followed LPG-TD; Tilsapa solves 3 smallest instances.3 participating planners, one minimizes different quality criterion: numberactions SGPlan, makespan Tilsapa, metric value aforementioned linearcombination makespan, fuel usage, summed negated image utility LPG-TD.useful comparison LPG-TD.speed LPG-TD.quality,ratio [1.00(2.33)7.05].16 Complex-timewindows-compiled, participatingplanner SGPlan. maintained good scalability Complex domain versionexplicit time windows.domain version Strips, awarded 1st places Macro-FF, YAHSP, SATPLAN;awarded 2nd places FDD (and FD), LPG-TD, CPT, Optiplan, Semsyn.domain version Time, awarded 1st places LPG-TD CPT; awarded 2nd placeSGPlan. domain versions Numeric, Time-timewindows, Complex,Complex-timewindows, awarded 1st place SGPlan 2nd place LPG-TD.5.8 SettlersSettlers domain also introduced IPC-3 (Long & Fox, 2003). featuressingle domain version, makes extensive use numeric variables. variablescarry domain semantics, building infrastructureunsettled area, involving building houses, railway tracks, sawmills, etc. IPC-3,planner able deal domain efficient way best IPC-3 plannerSettlers, Metric-FF (Hoffmann, 2003), solved smallest six instances testsuite. reasons, included domain IPC-4 challenge numericplanners. used exact domain file example instances IPC-3, exceptcompiled away universally quantified preconditions improve accessibilityplanners. quantifiers nested, ranged fixed set domain constants,could easily replaced conjunctions atoms.16. Due negated image utility, quality values negative. LPG-TD.speed LPGTD.quality here, happened 5 instances. skipped computing given ratio values,since putting positive negative values together doesnt make much sense negative quality,number larger absolute value represents better plan. would probably betterdefine, domain version, image penalty instead image utility, thus obtain strictlypositive action costs.563fiHoffmann & Edelkamp1000010001001010.1LPG-TDSGPLANSEMSYN0.012468101214161820Figure 12: Performance planners Settlers.Figure 12 shows runtime results obtained IPC-4. efficiency increase comparedIPC-3 is, obviously, dramatic: SGPlan solves every instance within less 15 seconds(instance number 8 unsolvable).17 LPG-TD solves 13 instances set, Semsynsolves 3 (numbers 1,2, 5). remark solutions tasks, returnedSGPlan, huge, 800 actions largest tasks. one hand,demonstrates SGPlans capability find extremely long plans extremelyquickly. hand, SGPlans plans Settlers might unnecessarily long,extent. largest instance solved Semsyn, number 5, Semsyn finds plan 94actions, plan found SGPlan 264 actions. largest instance solvedLPG-TD, number 17, LPG-TD.quality takes 473 actions SGPlan takes 552. LPG-TDminimizes metric value plans, linear combination invested labor,resource use, caused pollution. ratio LPG-TD.speed vs LPG-TD.quality[1.00(1.21)3.50].awarded 1st place SGPlan 2nd place LPG-TD.5.9 UMTSUMTS applications require comparatively much time started hand-held device,since communicate network several times. oneapplication called, yields true bottleneck user. Therefore,applications set-up divided several parts allow different set-up modules workconcurrently. task domain provide good schedule minimizing usedtime setting timed applications, respecting dependencies among them.IPC-4, six domain versions UMTS, UMTS-timewindows, UMTStimewindows-compiled, UMTS-flaw, UMTS-flaw-timewindows, UMTS-flaw-timewindowscompiled. domain versions temporal, make use numeric variablesmodel properties applications set up. ADL constructs used. UMTS17. remark instance 8 trivially unsolvable. One goals achieved actionsstatic precondition false initial state. detected simple reachabilityanalyses like, e.g., planning graphs, even without taking account delete lists.564fiThe Deterministic Part IPC-4: Overviewstandard model domain. UMTS-timewindows additional timewindows regarding executability set actions, encoded timed initial literals.UMTS-timewindows-compiled time windows compiled artificial constructs. remaining three domain versions result, names suggest, addingflaw construction respective counterparts. flaw construction practicallymotivated. consists extra action important sub-goal add effect,deletes another fact cant re-achieved. flaw action cant usedplan, used relaxed plans, i.e. ignoring delete effects.particular, adding important sub-goal, flawed action provides kind short-cutrelaxed plans, short-cut work reality. lead overly optimistic heuristic values. Thus flaw may confuse heuristic functions relaxed-planbased heuristic planners. used flawed domain versions IPC-4 see whetherlatter would case.IPC-4 test suites, instances, irrespective number/size, contain 10applications. main scaling parameter number applications must actuallyset up. IPC-4 instances number 1 . . . 5, single application must set up;instances number 6 . . . 10, two applications must set up, on, i.e., numberneeded applications bx/5c x index instance.Figure 13 (a) (b) shows IPC-4 performance basic domain version. Obviously, SGPlan LPG-TD difficulty domain solve everyinstance within split seconds. CRIKEY takes time, also scales nicely.optimal planners, TP4 HSPa able handle domain syntax, duecombination numeric variables action durations. Figure 13 (b) showsscaled relatively similarly, slight advantage HSPa . Note two plannersscaled better P-MEP LPG-3 satisficing track.remark point UMTS mainly intended benchmark optimalplanners minimizing makespan. domain pure scheduling problem nature.scheduling problems, trivial find plan example, one simplyschedule applications sequence.18 point domain, and, indeed, usingcomputer solve it, provide good schedules, is, schedules smallestpossible execution time, corresponding makespan plan.said, observe satisficing planners IPC-4 quite good findingnear-optimal plans UMTS. fact, see detail following,planner finding highly non-optimal plans LPG-3. Lets consider basic domainversion treated Figure 13 (a) (b). Two participating planners, CRIKEYSGPlan, try minimize number actions (i.e., wrong optimization criterion).data identical, i.e. plan lengths instances. Precisely,planners find, instance number x, plan bx/5c8 actions it. is, fact,optimal (smallest possible) number actions remember saidscaling IPC-4 test suites. participating planners trying minimize makespanLPG-3, LPG-TD, P-MEP, HSPa , TP4. P-MEP solves smallest 5 instances,finding optimal plans. ratio LPG-TD.speed vs HSPa [1.00(1.02)1.11]. ratio18. Note possible Airport domain also viewed type schedulingproblem (Hatzack & Nebel, 2001) due restricted space airport. sense, Airportdomain incorporates planning aspects UMTS.565fiHoffmann & Edelkamp1000010000LPG-TDSGPLANCRIKEYPMEPLPG-31000TP4HSPS_A10001001001010110.10.10.010.0151015202530354045505101520(a)253035404550(b)1000010000LPG-TDSGPLANCRIKEYLPG-3TP4HSPS_A100010001001001010110.10.10.010.0151015202530354045505(c)101520253035404550(d)Figure 13: UMTS, satisficing (a) optimal (b); UMTS-flaw, satisficing (c) optimal (d).LPG-TD.quality vs HSPa [1.00(1.00)1.03]. ratio LPG-3 vs HSPa [1.00(1.53)2.27];remark plan quality data used LPG-3.bestquality, takesentire available half hour time trying optimize found plan. Looking plots, onesees LPG-3 makespan curve much steeper planners.Figure 13 (c) (d), see performance IPC-4 plannersbasic domain version, flaw construct. LPG-TD remains unaffected, SGPlan CRIKEY become lot worse. Particularly, CRIKEY takes several minutessolve even smallest instances. take confirm intuition flaw(but necessarily) confuse heuristic functions relaxed-plan based heuristicplanners. Whether heuristic function becomes confused probably dependsdetails particular way relaxed plans constructed (such construction may,e.g., choose different actions based estimate harmfulalready selected actions). optimal track, introducing flaw constructdomain, performance TP4 HSPa becomes slightly worse, nearly indistinguishable. Regarding plan quality, quality difference terms numberactions needed CRIKEY SGPlan. SGPlans plans still smallest pos566fiThe Deterministic Part IPC-4: Overview1000010000LPG-TDSGPLANTILSAPALPG-TDSGPLAN100010001001001010110.10.10.010.0151015202530354045505(a)101520253035404550(b)Figure 14: UMTS-timewindows (a); UMTS-flaw-timewindows (b).sible length, bx/5c 8. CRIKEY lot variance, longer; ratioCRIKEY vs SGPlan [1.07(1.72)3.88]. group minimizing makespan, observations similar unflawed domain version above. ratio LPG-TD.speed vsHSPa [1.00(1.01)1.04], ratio LPG-TD.quality vs HSPa [1.00(1.00)1.01]. Although solves smaller half instances, ratio LPG-3.bestquality vs HSPa[1.00(1.48)2.27].Figure 14 shows results two domain versions explicitly encoded timewindows. optimal planners could participate since none could handle timedinitial literals. version without flaw, LPG-TD SGPlan needsplit seconds. competitor, Tilsapa, needs runtime also scaleswell. introducing flaw, competitors SGPlan LPG-TD. SGPlansruntime performance becomes lot worse, LPG-TD remains completely unaffected.Regarding plan quality, number actions SGPlans plans still bx/5c8 cases.LPG-TD.speed LPG-TD.quality return plans identical makespan cases.non-flawed version, UMTS-timewindows, makespan ratio Tilsapa vs LPG-TD[1.00(1.20)1.37].show runtime graphs domain versions compiled time windows.UMTS-timewindows-compiled, SGPlan CRIKEY participated. scale wellsolve instances, SGPlan needs split seconds, CRIKEY needs100 seconds per instance larger cases. planners try minimizenumber actions, need exactly bx/5c 8 + 5 actions instance numberx namely, optimal number bx/5c 8 actions before, plus 5 artificial actionsencoding time windows. UMTS-flaw-timewindows-compiled, sole participatingplanner SGPlan. solved smaller half instances, finding plans lengthbx/5c 8 + 6 i.e., using one unnecessary action instance (the action concernsapplication need set up).domain version UMTS, awarded 1st places SGPlan, LPG-TD, HSPa ;awarded 2nd places CRIKEY TP4. domain version UMTS-flaw, awarded567fiHoffmann & Edelkamp1st place LPG-TD, 2nd places SGPlan, HSPa , TP4. version UMTStimewindows, awarded 1st places SGPlan LPG-TD, 2nd place Tilsapa.UMTS-flaw-timewindows, awarded 1st place LPG-TD. UMTS-timewindowscompiled, awarded 1st place SGPlan.6. IPC-4 Awardsnumbers 1st 2nd places achieved planners shown Tables 3 4;planners never came 1st 2nd place left tables. Since manyplanners (6 satisficing planners, 4 optimal planners) dealtpurely propositional domain versions (i.e., STRIPS ADL), counted performancedomains separately.SGPlan LPG-TD FD FDD Macro-FF YAHSP CRIKEY TilsapaPropositional3/61/6 5/2 6/33/04/10/00/0Temp/Metric 13 / 27/70/10/1Total Count16 / 88 / 13 5 / 2 6 / 33/04/10/10/1Table 3: Summary results: satisficing planners, number 1st places / number 2ndplaces.CPTPropositional 0 / 1Temp/Metric 3 / 0Total Count 3 / 1TP-40/00/50/5HSPa SATPLAN Optiplan Semsyn BFHSP0/05/10/40/20/21/21/25/10/40/20/2Table 4: Summary results: optimal planners, number 1st places / number 2ndplaces.satisficing planners, based observations decided award separateprizes performance pure STRIPS ADL domains. optimal plannersseemed appropriate due to, first, small number planners competingtemporal/metric domains, and, second, smaller overall number competing systemsgiving 4 prizes 7 systems seemed much. Overall, awards made deterministicpart IPC-4 following:1st Prize, Satisficing Propositional Track Fast (Diagonally) Downward, MalteHelmert Silvia Richter2nd Prize, Satisficing Propositional Track YAHSP, Vincent Vidal2nd Prize, Satisficing Propositional Track SGPlan, Yixin Chen, Chih-Wei HsuBenjamin W. Wah1st Prize, Satisficing Metric Temporal Track SGPlan, Yixin Chen, Chih-Wei HsuBenjamin W. Wah568fiThe Deterministic Part IPC-4: Overview2nd Prize, Satisficing Metric Temporal Track LPG-TD, Alfonso Gerevini, Alessandro Saetti, Ivan Serina, Paolo Toninelli1st Prize, Optimal Track SATPLAN, Henry Kautz, David Roznyai, FarhadTeydaye-Saheli, Shane Neth, Michael Lindmark2nd Prize, Optimal Track CPT, Vincent Vidal Hector Geffnerwould like re-iterate awarding prizes is, be, sketchysummary results complex event IPC-4. bits informationsufficient summarize thousands data points. Many decisions tookawarding prizes, i.e. judgement scaling behavior, close.holds especially true runtime graphs concerning optimal planners,runtime graphs concerning satisficing propositional planners. thinkbest, encourage everybody do, closer look results plotsthemselves. said before, full plots available online appendix.7. Conclusionall, feeling organizers deterministic part IPC-4 greatsuccess, made several valuable contributions field. mention the,perspective, two prominent points: event provided community setinteresting new benchmarks, made visible yet another major step forwardscalability satisficing planning systems. latter made possible novel heuristicsdomain analysis techniques.wide variety questions addressed context future(deterministic part of) IPC. Let us discuss feel important. Regarding benchmark domains, said invested significant effort IPC-4 benchmarks,would definitely recommend re-use future IPC editions.domain versions solved relatively easily certain groups planners, manystill constitute major challenges. Examples Pipesworld tankage restrictions,Optical-Telegraph, large PSR instances, UMTS optimal planners. said,IPC-3 domains also still challenging re-used. probablyuseful community consolidate performance existing set benchmarks,rather increase benchmark database large pace. one thing, measureprogress IPC editions, re-used benchmark domains (and instances), like SatelliteSettlers case IPC-4, useful.19 generally, benchmark setalready large; large set, situation may arise authors selectrather disjoint subsets individual experiments.19. field addressing SAT problem, particularly respective competition events, progressalso often measured simply terms size (number variables clauses) formulascould tackled successfully, making distinctions origin formulas (like,randomly generated application). context IPC, one similar thingsmeasuring parameters as, e.g., number ground actions tackled successfully. However, givenlarge differences individual domains used IPC, distinctions must made.detailed investigation effect several parameters, IPC-4 domains, given Edelkampet al. (2005).569fiHoffmann & EdelkampRegarding PDDL extensions, formalisms derived predicates timed initialliterals introduced first steps respective directions. PDDL2.2derived predicates formalism restrictive allows negative interactionsderived predicates; one could easily allow negative interactions lead cyclesthus ambiguous semantics (Thiebaux et al., 2003, 2005). One could also imaginederivation rules values general data types predicates/Booleans, particularly numeric variables. timed initial literals, obviously encoderestrictive subset wide variety forms exogenous events take. Apartexogenous events numeric values, events may reality continuous processesconditioned world state, rather finitely many discrete time instants known beforehand. PDDL2.2 action model is, course, still restrictive postulationdiscrete variable value updates. Still believe IPC let gosimple PDDL subsets STRIPS, support accessibility competition. notedSection 4.1, systems still able handle language features introducedIPC-3 IPC-4. Also, believe STRIPS track, generally domainversions formulated simple language subsets, important encourage basic algorithmsresearch. new idea easier try simple language. avoid misunderstandings:language features introduced PDDL2.1 PDDL2.2 already significant basisacceptance implemented systems, definitely kept future editionsIPC.context basic research, noted satisficing track IPC-4almost entirely populated planners relaxed-plan based heuristic search type.demonstrates danger competition concentrate research much aroundsuccessful methods. Still, two remarkable planners track, FastDownward SGPlan, use significantly different heuristic new domain analysistechniques basis success, respectively.Putting optimal planners separate track serves maintain this, different,type planning algorithms. recommend keep distinction future IPCevents.hand-tailored track, say seems unclearcould brought back focus. Maybe suitable form event wouldonline (at hosting conference) programming (i.e., planner tailoring) competition.would, course, imply much smaller format event format IPCautomated planners grown already. online hand-tailored competitionwould advantage better visibility programming efforts, takingprohibitively much time system developers.context competition size, last least words saidrole responsibilities organizers. IPC grown large handled,aspects, two persons. may worth thinking distributingorganization workload among larger group people. One approach might makesense would let different people organize tracks concerning different PDDLsubsets. Another approach would let different people handle language definition,benchmark preparation, results collection, respectively. would probablygood idea establish IPC council that, unlike organizing committees past,570fiThe Deterministic Part IPC-4: Overviewwould persist across individual competitions, whose role would actively setsupport organizing teams.Acknowledgmentswould like thank IPC-4 organizing committee, namely Fahiem Bacchus, DrewMcDermott, Maria Fox, Derek Long, Jussi Rintanen, David Smith, Sylvie Thiebaux,Daniel Weld help taking decision language deterministicpart IPC-4, ironing details syntax semantics. especiallythank Maria Fox Derek Long giving us latex sources PDDL2.1 article,discussing modifications document needed introduce semanticsderived predicates timed initial literals. indebted Roman Englert, FredericoLiporace, Sylvie Thiebaux, Sebastian Trug, helped creation benchmark domains. wish say big thank participating teamsefforts. significant bravery submission planning system competition, choice design benchmark problems competitionorganizers, individuals. thank LPG team investing extra effortrunning IPC-3 LPG version IPC-4 benchmarks, thank Shahid Jabbarproofreading text. thank Subbarao Kambhampati pointing nameclassical part ambiguous, suggesting use deterministic part instead. Lastleast, thank anonymous reviewers, Maria Fox role responsible JAIReditor, comments; helped improve paper. time organizingcompetition, Jorg Hoffmann supported DFG (Deutsche Forschungsgemeinschaft), research project HEUPLAN II. Stefan Edelkamp supportedDFG research project Heuristic Search.Appendix A. BNF Description PDDL2.2appendix contains complete BNF specification PDDL2.2 language. readability, mark ( ) points BNF where, comparison PDDL2.1,new language constructs PDDL2.2 inserted.A.1 DomainsDomains defined exactly PDDL2.2, except also allow define rulesderived predicates points operators (actions) allowed.hdomainihrequire-defihrequire-keyi::= (define (domain hnamei)[hrequire-defi][htypes-defi]:typing[hconstants-defi][hpredicates-defi][hfunctions-defi]:fluentshstructure-defi )::= (:requirements hrequire-keyi+)::= See Section A.6571fiHoffmann & Edelkamphtypes-defi::= (:types htyped list (name)i)hconstants-defi::= (:constants htyped list (name)i)hpredicates-defi::= (:predicates hatomic formula skeletoni+ )hatomic formula skeletoni::= (hpredicatei htyped list (variable)i)hpredicatei::= hnameihvariablei::= ?hnameihatomic function skeletoni::= (hfunction-symboli htyped list (variable)i)hfunction-symboli::= hnameihfunctions-defi::=:fluents (:functions hfunction typed list(atomic function skeleton)i)hstructure-defi::= haction-defihstructure-defi::=:durativeactions hdurative-action-defi( ) hstructure-defi::=:derivedpredicates hderived-defihtyped list (x)i ::= xhtyped list (x)i ::=:typing x+ - htypei htyped list(x)ihprimitive-typei::= hnameihtypei::= (either hprimitive-typei+ )htypei::= hprimitive-typeihfunction typed list (x)i ::= xhfunction typed list (x)i ::=:typing x+ - hfunction typeihfunction typed list(x)ihfunction typei::= numberA.2 ActionsBNF action definition PDDL2.2.haction-defi::= (:action haction-symboli:parameters ( htyped list (variable)i )haction-def bodyi)haction-symboli ::= hnameihaction-def bodyi ::= [:precondition hGDi][:effect heffecti]hGDi::= ()hGDi::= hatomic formula(term)ihGDi::=:negativepreconditions hliteral(term)ihGDi::= (and hGDi )hGDi::=:disjunctivepreconditions (or hGDi )hGDi::=:disjunctivepreconditions (not hGDi)hGDi::=:disjunctivepreconditions (imply hGDi hGDi)hGDi::=:existentialpreconditions(exists (htyped list(variable)i ) hGDi ):universalpreconditionshGDi::=(forall (htyped list(variable)i ) hGDi ):fluentshGDi::=hf-compihf-compi::= (hbinary-compi hf-expi hf-expi)hliteral(t)i::= hatomic formula(t)ihliteral(t)i::= (not hatomic formula(t)i)572fiThe Deterministic Part IPC-4: Overviewhatomic formula(t)ihtermihtermihf-expihf-expihf-expihf-expihf-headihf-headihbinary-opihbinary-opihbinary-opihbinary-opihbinary-compihbinary-compihbinary-compihbinary-compihbinary-compihnumberiheffectiheffectiheffectihc-effectihc-effectihc-effectihp-effectihp-effectihp-effectihp-effectihcond-effectihcond-effectihassign-opihassign-opihassign-opihassign-opihassign-opi::=::=::=::=::=::=::=::=::=::=::=::=::=::=::=::=::=::=::=(hpredicatei )hnameihvariableihnumberi(hbinary-opi hf-expi hf-expi)(- hf-expi)hf-headi(hfunction-symboli htermi )hfunction-symboli+/><=>=<=numeric literal(integers floats form n.n).::= ()::= (and hc-effecti )::= hc-effecti::=:conditionaleffects (forall (hvariablei ) heffecti)::=:conditionaleffects (when hGDi hcond-effecti)::= hp-effecti::= (hassign-opi hf-headi hf-expi)::= (not hatomic formula(term)i)::= hatomic formula(term)i::=:fluents (hassign-opi hf-headi hf-expi)::= (and hp-effecti )::= hp-effecti::= assign::= scale-up::= scale-down::= increase::= decreaseA.3 Durative ActionsDurative actions PDDL2.2, except restrict level 3actions, duration given fixed value numeric expression (ratherpossible values defined set constraints). slightly simplifies BNF.hdurative-action-defi ::= (:durative-action hda-symboli:parameters ( htyped list (variable)i )hda-def bodyi)hda-symboli::= hnameihda-def bodyi::= :duration (= ?duration hf-expi):condition hda-GDi573fiHoffmann & Edelkamp:effect hda-effecti::= ()::= htimed-GDi::= (and htimed-GDi+ )::= (at htime-specifieri hGDi)::= (over hintervali hGDi)::= start::= end::=hda-GDihda-GDihda-GDihtimed-GDihtimed-GDihtime-specifierihtime-specifierihintervaliA.4 Derived predicatessaid, rules derived predicates given domain description pointsactions allowed. BNF is:( ) hderived-defi::= (:derived htyped list (variable)i hGDi)Note allow specification types derived predicate arguments.might seem redundant predicate types already declared :predicates field.Allowing specify types predicate (rule) parameters serves give languageunified look-and-feel, one might use option make parameter rangesrestrictive. (Remember specification types optional, mandatory.)Repeating said Section 3.1.1, BNF generousconsidered well-formed domain description PDDL2.2. call predicate P derivedrule predicate P head; otherwise call P basic. restrictionsapply are:1. actions available planner affect derived predicates: derivedpredicate occurs effect lists domain actions.2. rule defines P (x) derived (x), variables xpairwise different (and, notation suggests, free variables (x) exactlyvariables x).3. rule defines P (x) derived , Negation Normal Form(NNF) (x) contain derived predicates negated form.A.5 Problemschange made PDDL2.1 problem description allow specification timed initial literals.hproblemi::= (define (problem hnamei)(:domain hnamei)[hrequire-defi][hobject declarationi ]hiniti574fiThe Deterministic Part IPC-4: Overviewhgoali[hmetric-speci][hlength-speci ])hobject declarationi ::= (:objects htyped list (name)i)hiniti::= (:init hinit-eli )hinit-eli::= hliteral(name)ihinit-eli::=:fluents (= hf-headi hnumberi)( ) hinit-eli::=:timedinitialliterals (at hnumberi hliteral(name)i)hgoali::= (:goal hGDi)hmetric-speci::= (:metric hoptimizationi hground-f-expi)hoptimizationi::= minimizehoptimizationi::= maximizehground-f-expi::= (hbinary-opi hground-f-expi hground-f-expi)hground-f-expi::= (- hground-f-expi)hground-f-expi::= hnumberihground-f-expi::= (hfunction-symboli hnamei )hground-f-expi::= total-timehground-f-expi::= hfunction-symboliRepeating said Section 3.1.1, requirement flag timed initialliterals implies requirement flag durational actions (see also Section A.6), i.e.language construct available PDDL2.2 level 3. Also, BNFgenerous considered well-formed problem description PDDL2.2.times hnumberi timed literals occur restricted greater 0.also derived predicates domain, timed literals restrictedinfluence these, i.e., like action effects allowed affect truth valuesbasic (non-derived) predicates (IPC-4 use derived predicates timedinitial literals within domain).A.6 Requirementstable requirements PDDL2.2. requirements imply others;abbreviations common sets requirements. domain stipulates requirements,assumed declare requirement :strips.575fiHoffmann & EdelkampRequirement:strips:typing:negative-preconditions:disjunctive-preconditions:equality:existential-preconditions:universal-preconditions:quantified-preconditions:conditional-effects:fluents:adl:durative-actions:derived-predicates:timed-initial-literalsDescriptionBasic STRIPS-style adds deletesAllow type names declarations variablesAllow goal descriptionsAllow goal descriptionsSupport = built-in predicateAllow exists goal descriptionsAllow forall goal descriptions= :existential-preconditions+ :universal-preconditionsAllow action effectsAllow function definitions use effects usingassignment operators arithmetic preconditions.= :strips + :typing+ :negative-preconditions+ :disjunctive-preconditions+ :equality+ :quantified-preconditions+ :conditional-effectsAllows durative actions.Note imply :fluents.Allows predicates whose truth valuedefined formulaAllows initial state specify literalsbecome true specified time pointimplies durative actions (i.e. applicablePDDL2.2 level 3)ReferencesBacchus, F. (2000). Subset PDDL AIPS2000 Planning Competition. AIPS-00Planning Competition Committee.Bacchus, F. (2001). AIPS00 planning competition. AI Magazine, 22 (3), 4756.Bertoli, P., Cimatti, A., Slaney, J., & Thiebaux, S. (2002). Solving power supply restorationproblems planning via symbolic model-checking. Harmelen, F. V. (Ed.),Proceedings 15th European Conference Artificial Intelligence (ECAI-02),pp. 576580, Lyon, France. Wiley.Blum, A. L., & Furst, M. L. (1995). Fast planning planning graph analysis. Proceedings 14th International Joint Conference Artificial Intelligence (IJCAI95), pp. 16361642, Montreal, Canada. Morgan Kaufmann.Blum, A. L., & Furst, M. L. (1997). Fast planning planning graph analysis. ArtificialIntelligence, 90 (1-2), 279298.Bonet, B., & Thiebaux, S. (2003). GPT meets PSR. Proceedings 13th InternationalConference Automated Planning Scheduling (ICAPS-03), pp. 102111, Trento,Italy. Morgan Kaufmann.Cesta, A., & Borrajo, D. (Eds.). (2001). Recent Advances AI Planning. 6th EuropeanConference Planning (ECP01), Toledo, Spain. Springer-Verlag.576fiThe Deterministic Part IPC-4: OverviewClarke, E. M., Grumberg, O., & Peled, D. (2000). Model Checking. MIT Press.Edelkamp, S. (2003a). Limits possibilities PDDL model checking software..Edelkamp, & Hoffmann (Edelkamp & Hoffmann, 2003).Edelkamp, S. (2003b). Promela planning. Proceedings Model Checking Software(SPIN), pp. 197212.Edelkamp, S. (2003c). Taming numbers durations model checking integratedplanning system. Journal Artificial Intelligence Research, 20, 195238.Edelkamp, S., & Hoffmann, J. (Eds.). (2003). Proceedings Workshop Competition:Impact, Organization, Evaluation, Benchmarks, ICAPS03. AAAI Press.Edelkamp, S., Hoffmann, J., Englert, R., Liporace, F., Thiebaux, S., & Trug, S. (2005).Engineering benchmarks planning: domains used deterministic partIPC-4. Journal Artificial Intelligence Research. Submitted.Edelkamp, S., Hoffmann, J., Littman, M., & Younes, H. (Eds.). (2004). Proceedings4th International Planning Competition. JPL.Englert, R. (2003). Re-scheduling temporal operational resources mobileexecution dynamic UMTS applications. KI-Workshop AI Planning, Scheduling, Configuration Design (PUK).Englert, R. (2005). Planning optimize UMTS call set-up execution mobileagents. Journal Applied Artificial Intelligence (AAI), 19 (2), 99117.Fikes, R. E., & Nilsson, N. (1971). STRIPS: new approach application theoremproving problem solving. Artificial Intelligence, 2, 189208.Fox, M., Long, D., & Halsey, K. (2004). investigation expressive powerPDDL2.1. Saitta, L. (Ed.), Proceedings 16th European Conference Artificial Intelligence (ECAI-04), Valencia, Spain. Wiley.Fox, M., & Long, D. (2003). PDDL2.1: extension PDDL expressing temporalplanning domains. Journal Artificial Intelligence Research, 20, 61124.Gerevini, A., Saetti, A., & Serina, I. (2003). Planning stochastic local searchtemporal action graphs. Journal Artificial Intelligence Research, 20, 239290.Haslum, P., & Geffner, H. (2001). Heuristic planning time resources.. Cesta,& Borrajo (Cesta & Borrajo, 2001), pp. 121132.Hatzack, W., & Nebel, B. (2001). operational traffic control problem: Computationalcomplexity solutions.. Cesta, & Borrajo (Cesta & Borrajo, 2001), pp. 4960.Helmert, M. (2001). complexity planning transportation domains.. Cesta,& Borrajo (Cesta & Borrajo, 2001), pp. 349360.Helmert, M. (2003). Complexity results standard benchmark domains planning.Artificial Intelligence, 143, 219262.Helmert, M. (2004). planning heuristic based causal graph analysis. Koenig, S.,Zilberstein, S., & Koehler, J. (Eds.), Proceedings 14th International ConferenceAutomated Planning Scheduling (ICAPS-04), pp. 161170, Whistler, Canada.Morgan Kaufmann.577fiHoffmann & EdelkampHipke, C. A. (2000). Distributed Visualization Geometric Algorithms. Ph.D. thesis,University Freiburg.Hoffmann, J. (2003). Metric-FF planning system: Translating ignoring delete listsnumeric state variables. Journal Artificial Intelligence Research, 20, 291341.Hoffmann, J. (2005). ignoring delete lists works: Local search topology planningbenchmarks. Journal Artificial Intelligence Research. appear.Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generationheuristic search. Journal Artificial Intelligence Research, 14, 253302.Holzmann, G. J. (2004). SPIN model checker: Primer reference manual. AddisonWesley.Long, D., & Fox, M. (2003). 3rd international planning competition: Resultsanalysis. Journal Artificial Intelligence Research, 20, 159.McDermott, D. (2000). 1998 AI planning systems competition. AI Magazine,21 (2), 3555.McDermott, D., et al. (1998). PDDL Planning Domain Definition Language.AIPS-98 Planning Competition Committee.Milidiu, R. L., & dos Santos Liporace, F. (2004). Plumber, pipeline transportation planner.Proceedings International Workshop Harbour Maritime Simulation,HMS, pp. 99106, Rio de Janeiro, Brazil.Milidiu, R. L., dos Santos Liporace, F., & de Lucena, C. J. (2003). Pipesworld: Planning pipeline transportation petroleum derivatives.. Edelkamp, & Hoffmann(Edelkamp & Hoffmann, 2003).Pednault, E. P. (1989). ADL: Exploring middle ground STRIPS situation calculus. Brachman, R., Levesque, H. J., & Reiter, R. (Eds.), PrinciplesKnowledge Representation Reasoning: Proceedings 1st International Conference (KR-89), pp. 324331, Toronto, ON. Morgan Kaufmann.Penberthy, J. S., & Weld, D. S. (1992). UCPOP: sound, complete, partial order plannerADL. Nebel, B., Swartout, W., & Rich, C. (Eds.), Principles KnowledgeRepresentation Reasoning: Proceedings 3rd International Conference (KR92), pp. 103114, Cambridge, MA. Morgan Kaufmann.Thiebaux, S., & Cordier, M.-O. (2001). Supply restoration power distribution systemsbenchmark planning uncertainty.. Cesta, & Borrajo (Cesta & Borrajo,2001), pp. 8595.Thiebaux, S., Cordier, M.-O., Jehl, O., & Krivine, J.-P. (1996). Supply restoration powerdistribution systems case study integrating model-based diagnosis repairplanning. Horvitz, E., & Jensen, F. (Eds.), Proceedings 12th InternationalConference Uncertainty AI (UAI-96), pp. 525532, Portland, OR, USA. MorganKaufmann.Thiebaux, S., Hoffmann, J., & Nebel, B. (2003). defence PDDL axioms. Gottlob, G.(Ed.), Proceedings 18th International Joint Conference Artificial Intelligence(IJCAI-03), pp. 961966, Acapulco, Mexico. Morgan Kaufmann.578fiThe Deterministic Part IPC-4: OverviewThiebaux, S., Hoffmann, J., & Nebel, B. (2005). defence PDDL axioms. ArtificialIntelligence. appear.Trug, S., Hoffmann, J., & Nebel, B. (2004). Applying automatic planning systems airportground-traffic control feasibility study. Biundo, S., Fruhwirth, T., & Palm,G. (Eds.), KI-04: Advances Artificial Intelligence, pp. 183197, Ulm, Germany.Springer-Verlag.Vidal, V., & Geffner, H. (2004). Branching pruning: optimal temporal POCL planner based constraint programming. Proceedings 19th National ConferenceAmerican Association Artificial Intelligence (AAAI-04), pp. 570577, SanJose, CA. MIT Press.Younes, H., & Littman, M. (2005). Probabilistic part 4th international planningcompetition. Journal Artificial Intelligence Research. Submitted.579fiJournal Artificial Intelligence Research 24 (2005) 641-684Submitted 04/05; published 11/05Binary Encodings Non-binary Constraint SatisfactionProblems: Algorithms Experimental ResultsNikolaos Samarassamaras@uom.grDepartment Applied InformaticsUniversity Macedonia, GreeceKostas Stergioukonsterg@aegean.grDepartment Information Communication Systems EngineeringUniversity Aegean, GreeceAbstractnon-binary Constraint Satisfaction Problem (CSP) solved directly using extended versions binary techniques. Alternatively, non-binary problem translated equivalent binary one. case, generally accepted translatedproblem solved applying well-established techniques binary CSPs.paper evaluate applicability latter approach. demonstrate usestandard techniques binary CSPs encodings non-binary problems problematicresults models rarely competitive non-binary representation.overcome this, propose specialized arc consistency search algorithms binary encodings, evaluate theoretically empirically. consider threebinary representations; hidden variable encoding, dual encoding, doubleencoding. Theoretical empirical results show that, certain classes non-binaryconstraints, binary encodings competitive option, many cases, better onenon-binary representation.1. IntroductionConstraint Satisfaction Problems (CSPs) appear many real-life applicationsscheduling, resource allocation, timetabling, vehicle routing, frequency allocation, etc.CSPs naturally eciently modelled using non-binary (or n-ary) constraintsmay involve arbitrary number variables. well known non-binary CSPconverted equivalent binary one. well-known translationsdual encoding (Dechter & Pearl, 1989) hidden variable encoding (Rossi, Petrie, &Dhar, 1990). ability translate non-binary CSP binary often usedpast justication restricting attention binary CSPs. Implicitly, assumption faced non-binary CSP simply convertbinary one, apply well-known generic techniques solving binary equivalent.paper show assumption awed generic techniquesbinary CSPs suitable binary encodings non-binary problems.past years, theoretical empirical studies eciencybinary encodings comparisons binary encodings non-binary representation (Bacchus & van Beek, 1998; Stergiou & Walsh, 1999; Mamoulis & Stergiou, 2001;Smith, 2002; Bacchus, Chen, van Beek, & Walsh, 2002). Theoretical results showedc2005AI Access Foundation. rights reserved.fiSamaras & Stergiouconverting non-binary CSPs binary equivalents potentially ecient waysolve certain classes non-binary problems. However, (limited) empirical studiescases appears true, Conways game Life (Smith,2002) notable exception. various reasons this. many cases,extensive space requirements binary encodings make infeasible. Also,many non-binary problems utilize ecient specialized propagators certain constraints, algorithm developed Regin (1994) all-dierent constraint.Converting constraints binary clearly impractical. Another reason,overlooked, (if all) experimental studies use well-known generic localconsistency search algorithms encodings. way fail exploitstructure constraints encodings, ending inecient algorithms.make binary encodings realistic choice modelling solving non-binary CSPs,need algorithms utilize structural properties. Finally, important pointuse binary encoding necessarily mean convertnon-binary constraints problem binary, commonly perceived.selective constraints encode, based properties arity tightness,get ecient hybrid models.address issues, show use specialized arc consistency searchalgorithms binary encodings non-binary CSPs lead ecient models. consider three encodings; dual, hidden variable, double encoding. latter,basically conjunction two encodings, received little attentionmay well turn signicant practice. aim studytwofold. First, present ecient algorithms binary encodings analyzetheoretically experimentally. Second, importantly, investigateuse algorithms help solve non-binary problems eciently. Towardsaims, make following contributions:describe simple algorithm enforces arc consistency hidden variableencoding arbitrary non-binary CSP O(ekdk ) time complexity, enumber constraints, k maximum arity constraints,maximum domain size. gives O(d) improvement compared asymptoticcomplexity generic arc consistency algorithm. improved complexitycomplexity optimal generalized arc consistency algorithmnon-binary representation problem. also identify property arcconsistency algorithm hidden variable encoding make run faster,arc inconsistent problems, generalized arc consistency algorithm.consider search algorithms maintain local consistencies searchhidden variable encoding. show that, like maintaining arc consistency,generalizations forward checking non-binary CSPs emulatedcorresponding forward checking algorithms run hidden variable encodinginstantiate original variables (i.e. variables initial non-binaryproblem). show algorithm corresponding algorithm nonbinary constraints following relationships: 1) visit numbersearch tree nodes, 2) asymptotic cost within polynomialbound other.642fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Resultsdescribe specialized algorithm dual encoding achieves arc consistencyO(e3 dk ) worst-case time complexity. signicantly lower O(e2 d2k )complexity generic arc consistency algorithm. improvement complexitybound stems observation constraints dual encoding specicstructure; namely piecewise functional (Van Hentenryck, Deville, & Teng,1992). Apart applying arc consistency dual encoding non-binaryCSP, algorithm also used specialized ltering algorithm certainclasses non-binary constraints.adapt various search algorithms run double encoding comparetheoretically similar algorithms hidden variable encoding non-binaryrepresentation. Search algorithms operate double encoding exploitadvantages hidden variable dual encoding. example, showthat, certain conditions, asymptotic cost maintaining arc consistencyalgorithm double encoding polynomially worse asymptoticcost corresponding algorithm non-binary representation (and hiddenvariable encoding), exponentially better.Finally, make extensive empirical study various domains. considerrandom problems well structured ones, like crossword puzzle generation, conguration, frequency assignment. study consists two parts. rstpart, give experimental results demonstrate advantages specializedalgorithms binary encodings compared generic algorithms. example,specialized arc consistency algorithm dual encoding orders magnitude faster generic arc consistency algorithm. second part showuse binary encodings oer signicant benets solving certain classesnon-binary CSPs. example, solving dual encoding congurationproblems orders magnitudes ecient solving non-binaryrepresentation. Also, empirical results frequency assignment - like problemsdemonstrate binary encoding benecial even non-binary constraintsintentionally specied.paper structured follows. Section 2 give necessary denitionsbackground. Section 3 describe specialized arc consistency algorithm hiddenvariable encoding. also demonstrate extensions forward checkingnon-binary CSPs emulated binary forward checking algorithms runhidden variable encoding. Section 4 explain complexity arc consistencydual encoding improved describe specialized arc consistency algorithm.Section 5 discusses algorithms double encoding. Section 6 present experimentalresults random structured problems demonstrate usefulness proposedalgorithms. also draw conclusions regarding applicability encodings,based theoretical experimental results. Section 7 discusses related work. Finally,Section 8 conclude.643fiSamaras & Stergiou2. Backgroundsection give necessary denitions CSPs, describe hidden variable,dual, double encodings non-binary CSPs.2.1 Basic DefinitionsConstraint Satisfaction Problem (CSP), P , dened tuple (X, D, C), where:X = {x1 , . . . , xn } nite set n variables.= {Din (x1 ), . . . , Din (xn )} set initial domains. variable xi X,Din (xi ) initial nite domain possible values. CSP algorithms removevalues domains variables value assignments propagation.variable xi , denote D(xi ) current domain xi time consistsvalues removed Din (xi ). assume every xi X,total ordering <d dened Din (xi ).C = {c1 , . . . , ce } set e constraints. constraint cipair (vars(ci ), rel(ci )), 1) vars(ci ) = {xj1 , . . . , xjk }X called constraint scheme, 2) rel(ci ) subsetDin (xj1 )x . . . xDin (xjk ) species allowed combinationsables vars(ci ).C denedordered subsetCartesian productvalues vari-size vars(ci ) called arity constraint ci . Constraints arity 2 calledbinary. Constraints arity greater 2 called non-binary (or n-ary). tuplerel(ci ) ordered list values (a1 , . . . , ak ) aj Din (xj ),j = 1, . . . , k.tuple = (a1 , . . . , ak ) valid aj , j 1, . . . , k, aj D(xj ). is, tuple validvalues tuple present domains corresponding variables.process veries whether given tuple allowed constraint ci calledconsistency check. constraint either dened extensionally set allowed (ordisallowed) tuples intensionally predicate arithmetic function. binary CSPrepresented graph (called constraint graph) nodes correspond variablesedges correspond constraints. non-binary CSP represented constrainthyper-graph constraints correspond hyper-edges connecting two nodes.assignment value variable xi denoted (xi , a). tuple =(a1 , . . . , ak ) viewed set value variable assignments {(x1 , a1 ), . . . , (xk , ak )}.set variables tuple dened denoted vars( ).subset vars vars( ), [vars ] denotes sub-tuple includes assignmentsvariables vars . two tuples rel(ci ) ordered lexicographicordering <lex . ordering, <lex exists subset {x1 , . . . , xj } ci[x1 , . . . , xj ] = [x1 , . . . , xj ] [xj+1 ] <lex [xj+1 ]. assignment consistent,constraints ci , vars(ci ) vars( ), [vars(ci )] rel(ci ). solution CSP(X, D, C) consistent assignment variables X. exists solutiongiven CSP, say CSP soluble. Otherwise, insoluble.basic way solving CSPs using backtracking search. seentraversal search tree comprises possible assignments values variables.644fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Resultslevel tree corresponds variable. node search tree correspondstuple (i.e. assignment values variables). root tree correspondsempty tuple, rst level nodes correspond 1-tuples (an assignment valueone variable), second level nodes correspond 2-tuples (assignment values twovariables generated extending rst level 1-tuples) etc. stage searchtree traversal, variables already assigned called past variables.recently assigned variable called current variable. variablesassigned yet called future variables.rest paper use notation n number variablesCSP, e number constraints problem, maximum domain sizevariables, k maximum arity constraints.2.1.1 Arc Consistencyimportant concept CSPs concept local consistency. Local consistenciesproperties applied CSP, using (typically) polynomial algorithms, removeinconsistent values either prior search. Arc consistency commonlyused local consistency property existing constraint programming engines.give denition arc consistency.Definition 2.1 value D(xj ) consistent constraint ci , xj vars(ci )rel(ci ) [xj ] = valid. case say supportci . constraint ci Arc Consistent (AC) variable xj vars(ci ), D(xj ),exists support ci . CSP (X, D, C) arc consistent emptydomain constraints C arc consistent.Arc consistency enforced CSP removing unsupported valuesdomains variables. enforcing arc consistency (or local consistency propertygeneral) CSP P , mean applying algorithm yields new CSParc consistent (or property A) set solutions P .denition arc consistency applies constraints arity. distinguishbinary non-binary cases, use term arc consistency (AC) referproperty arc consistency binary constraints only. non-binary constraintsuse term Generalized Arc Consistency (GAC).usefulness AC processing recognized early, result, various ACalgorithms binary constraints proposed literature (e.g. AC-3 Mackworth, 1977, AC-4 Mohr & Henderson, 1986, AC-5 Van Hentenryck et al., 1992, AC-7Bessiere et al., 1995, AC-2001 Bessiere & Regin, 2001, AC3.1 Zhang & Yap, 2001).extended non-binary case (e.g. GAC-4 Mohr & Masini,1988, GAC-Schema Bessiere & Regin, 1996a, GAC-2001 Bessiere & Regin, 2001).AC enforced binary CSP O(ed2 ) optimal worst-case time complexity.worst-case complexity enforcing GAC non-binary CSP O(ekdk ) (Bessiere & Regin,1996a).paper use algorithms AC-2001 GAC-2001 theoretical empiricalcomparisons specialized algorithms encodings. restrictive,sense generic AC (and GAC) algorithm used instead.645fiSamaras & StergiouFollowing Debruyne & Bessiere (2001), call local consistency property strongerB problem enforcing deletes least values B, strictlystronger stronger least one problem deletes valuesB. call equivalent B delete values problems. Similarly,call search algorithm stronger search algorithm B every problem visitssearch tree nodes B, strictly stronger strongerleast one problem visits less nodes B. equivalent B visitnodes problems.Following Bacchus et al. (2002), asymptotic cost (or cost hereafter) searchalgorithm determined worst-case number nodes algorithmvisit solve CSP, worst-case time complexity algorithm node1 .paper Bacchus et al. (2002), use measure set asymptotic boundsrelative performance various algorithms. example, two algorithmsB always visit nodes enforces property node exponentiallyhigher complexity property enforced B, say algorithmexponentially greater cost algorithm B.2.1.2 Functional Piecewise Functional Constraintsspecialized AC algorithms hidden variable dual encodingdescribe Sections 3 4 exploit structural properties encodings.explain detail later, binary constraints hidden variable encoding one-wayfunctional, binary constraints dual encoding piecewise functional.dene concepts.Definition 2.2 binary constraint c, vars(c) = {xi , xj }, functional respectD(xi ) D(xj ) D(xi ) (resp. b D(xj )) exists one valueb D(xj ) (resp. D(xi )) b support c (resp. support b).example functional constraint xi = xj . binary constraint one-way functionalfunctionality property holds respect one variables involvedconstraint.Informally, piecewise functional constraint variables xi , xj constraintdomains xi xj partitioned groups group D(xi )supported one group D(xj ), vice versa. give formal denition,rst dene concept piecewise decomposition.Definition 2.3 (Van Hentenryck et al., 1992) Let c binary constraint vars(c) ={xi , xj }. partitions = {s1 , . . . , sm } D(xi ) = {s1 , . . . , sm } D(xj )piecewise decomposition D(xi ) D(xj ) respect c sl S,sl ,following property holds: either sl , b sl , (a, b) rel(c), sl , b sl ,(a, b)/ rel(c).1. paper Bacchus et al. (2002) cost applying variable ordering heuristic nodealso taken account. theoretically compare search algorithms paper assumeuse variable ordering, take cost account.646fiBinary Encodings Non-binary CSPs: Algorithms & Experimental ResultsDefinition 2.4 (Van Hentenryck et al., 1992) binary constraint c, vars(c) ={xi , xj }, piecewise functional respect D(xi ) D(xj ) exists piecewisedecomposition = {s1 , . . . , sm } D(xi ) = {s1 , . . . , sm } D(xj ) respectc sl (resp. sl ), exists one sl (resp. sl S),sl , b sl (a, b) rel(c).Example piecewise functional constraints modulo (x2 MOD x3 = a) integerdivision (x2 DIV x3 = a) constraints.2.2 Binary Encodingstwo well-known methods transforming non-binary CSP binary one;dual graph encoding hidden variable encoding. encode non-binaryconstraints variables domains valid tuples constraints. is,building binary encoding non-binary constraint store extensional representationconstraint (the set allowed tuples). third method double encodingcombines two.2.2.1 Dual Encodingdual encoding (originally called dual graph encoding) inspired work relationaldatabases. dual encoding (DE) (Dechter & Pearl, 1989) variables swappedconstraints vice versa. constraint c original non-binary CSP represented variable call dual variable denote vc . refer variablesoriginal non-binary CSP original variables. domain dual variable vcconsists set allowed tuples original constraint c. Binary constraintstwo dual variables vc vc exist vars(c) vars(c ) = . is, constraints cc share one original variables. common vars set original variablescommon c c tuple D(vc ) supported constraint vcvc exists tuple D(vc ) [common vars] = [common vars].v c1v c4(0,0,1) (0,1,0)(0,0,0) (0,1,1)(1,0,0)(1,0,1)(0,0,1) (1,0,0)(0,1,0) (1,0,0)(1,1,1)(1,1,0) (1,1,1)v c3v c2Figure 1: Dual encoding non-binary CSP.647fiSamaras & StergiouConsider following example six variables 0-1 domains, four constraints:c1 : x1 + x2 + x6 = 1, c2 : x1 x3 + x4 = 1, c3 : x4 + x5 x6 1, c4 : x2 + x5x6 = 0. DE represents problem 4 dual variables, one constraint.domains dual variables tuples satisfy respective constraint.example, dual variable vc3 associated third constraint domain{(0, 1, 0), (1, 0, 0), (1, 1, 0), (1, 1, 1)} tuples values (x4 , x5 , x6 )satisfy x4 + x5 x6 1. second example, dual variable vc4 associatedlast constraint domain {(0, 0, 0), (0, 1, 1), (1, 0, 1)}. vc3 vc4compatibility constraint ensure two original variables common, x5 x6 ,values. constraint allows pairs tuples agreesecond third elements (i.e. (1, 0, 0) vc3 (0, 0, 0) vc4 , (1, 1, 1) vc3(0, 1, 1) vc4 ). DE problem shown Figure 1.rest paper, sometimes denote cvi non-binary constraintencoded dual variable vi . original variable xj vars(cvi ), pos(xj , cvi )denote position xj cvi . instance, given constraint cvi variables x1 , x2 , x3 ,pos(x2 , cvi ) = 2.2.2.2 Hidden Variable Encodinghidden variable encoding (HVE) inspired work philosopher Peirce (1933).According Rossi et al. (1990), Peirce rst showed binary relationsexpressive power non-binary relations.HVE (Rossi et al., 1990), set variables consists original variablesnon-binary CSP plus set dual variables. dual encoding, dualvariable vc corresponds constraint c original problem. domain dualvariable consists tuples satisfy original constraint. every dual variablevc , binary constraint vc original variables xixi vars(c). tuple D(vc ) supported constraint vc xiexists value D(xi ) [xi ] = a.Consider previous example six variables 0-1 domains, four constraints:c1 : x1 + x2 + x6 = 1, c2 : x1 x3 + x4 = 1, c3 : x4 + x5 x6 1, c4 : x2 + x5 x6 = 0.HVE are, addition original six variables, four dual variables.DE, domains variables tuples satisfy respective constraint.compatibility constraints dual variable vc original variablescontained constraint c. example, constraints vc3 x4 ,vc3 x5 vc3 x6 , variables involved constraint c3 .compatibility constraint cv3 x4 relation true rst elementtuple assigned cv3 equals value x4 . HVE shown Figure 2.2.2.3 Double Encodingdouble encoding (Stergiou & Walsh, 1999) combines hidden variable dualencoding. HVE, set variables double encoding consistsvariables original non-binary CSP plus dual variables. every dual variablevc , binary constraint vc original variables xi involvedcorresponding non-binary constraint c. DE, also binary constraints648fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Resultsv c1v c4(0,0,1) (0,1,0)(0,0,0) (0,1,1)(1,0,0)(1,0,1)x1 0 1x2 0 1x3 0 1x4 0 1(0,0,1) (1,0,0)x501x601(0,1,0) (1,0,0)(1,1,1)(1,1,0) (1,1,1)v c3v c2Figure 2: Hidden variable encoding non-binary CSP.two dual variables vc vc non-binary constraints c c share oneoriginal variables.3. Algorithms Hidden Variable Encodingsection discuss specialized algorithms HVE. rst describe simpleAC algorithm HVE worst-case time complexity optimalGAC algorithm non-binary representation. Appendix A, also showarc consistent CSP proposed AC algorithm performs exactly numberconsistency checks corresponding GAC algorithm. arc inconsistent problemsshow AC algorithm HVE detect inconsistency earlier thusperform fewer consistency checks GAC algorithm.also consider search algorithms HVE maintain local consistenciessearch. show that, like maintaining arc consistency, generalizations forwardchecking non-binary CSPs emulated corresponding binary forward checkingalgorithms HVE instantiate original variables.3.1 Arc Consistencyproved AC HVE equivalent GAC non-binary problem(Stergiou & Walsh, 1999). Since HVE binary CSP, one obvious way apply ACusing generic AC algorithm. However, results redundant processingasymptotic time complexity worse O(ekdk ). precise, HVE problemkary constraints ek binary constraints dual original variables.constraint, AC enforced O(ddk ) worst-case time complexity.whole problem complexity O(ekdk+1 ).Instead, describe simple AC algorithm operates HVEachieves worst-case time complexity optimal GAC algorithm appliednon-binary representation. achieve slightly modifying GAC algorithm649fiSamaras & StergiouBessiere Regin (2001) (GAC-2001). Figure 3 sketch AC algorithmHVE, call HAC (Hidden AC).function HAC1:Q2:dual variable vj3:variable xi xi vars(cvj )4:Revise(xi , vj ) = RU E5:D(xi ) empty return INCONSISTENCY6:put Q dual variable vl xi vars(cvl )7:return P ropagationfunction P ropagation8:Q empty9:pop dual variable vj Q10:unassigned variable xi xi vars(cvj )11:Revise(xi , vj ) = RU E12:D(xi ) empty return INCONSISTENCY13:put Q dual variable vl xi vars(cvl )14: return CONSISTENCYfunction Revise(xi , vj )15: DELETION FALSE16:value D(xi )17:currentSupportxi,a,vj valid18:( D(vj )) >lex currentSupportxi,a,vj , [xi ] = valid19:currentSupportxi,a,vj20:else21:remove D(xi )22:vl xi vars(cvl )23:remove D(vl ) tuple [xi ] =24:D(vl ) empty return INCONSISTENCY25:DELETION TRUE26: return DELETIONFigure 3: HAC: AC algorithm hidden variable encoding.HAC algorithm uses stack (or queue) dual variables propagate value deletions, works follows. initialization phase iterates dual variablevj (line 2). every original variable xi constrained vj algorithm revisesconstraint vj xi . done calling function Revise (line 4).revision, value D(xi ) look tuple domain vj supportsit. AC-2001, store currentSupportxi,a,vj : recent tuple foundD(vj ) supports value variable xi 2 . tuple deleted D(vj )2. assume, without loss generality, algorithm looks supports checking tupleslexicographic order.650fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Resultsknow supported. Otherwise, look new supporting tuple startingtuple immediately currentSupportxi ,a,vj . tuple foundremoved D(xi ) (line 21). case, tuples include value removeddomains dual variables constrained xi (lines 2223).dual variables already stack added it3 . Then, dual variablesremoved stack sequentially. dual variable vj removedstack, algorithm revises constraint vj original variable xi constrained vj . algorithm terminates values domain deleted,case problem arc consistent, stack becomes empty, caseproblem arc consistent.main dierence HAC GAC-2001 GAC-2001 includelines 2224. is, even non-binary constraints given extension, GAC2001 remove tuples become invalid lists allowed tuples.result, two algorithms check validity tuple (in lines 17 18) dierentways. Later section explain detail. Apart dierence,important aects run times, two algorithms essentiallysame. move HAC GAC-2001 removing lines 2224 substitutingreferences dual variables references corresponding constraints. example,currentSupportxi,a,vj corresponds currentSupportxi,a,cvj GAC-2001, i.e. last tupleconstraint cvj supports value variable xi . Note implementationGAC-2001, propagation constraint-based. is, algorithm utilizes stackconstraints perform propagation value deletions.3.1.1 Complexitiesgive upper bound number consistency checks performed HACworst-case. Function Revise(xi , vj ) called kd times dual variablevj , every deletion value domain xi , xi one k originalvariables constrained vj . call Revise(xi , vj ) algorithm performschecks (one value D(xi )) see currentSupportxi,a,vj valid (line 17).currentSupportxi,a,vj valid, HAC tries nd new supporting tuple D(vj ).check tuple contains assignment (xi , a) supports need checkvalid. tuple valid one values removed domaincorresponding variable. means tuple also removeddomain dual variable. Therefore, checking validity tuple doneconstant time looking domain dual variable. algorithm needscheck support dk1 , maximum, tuples contain assignment (xi , a).Since HAC stores currentSupportxi,a,vj , call Revise(xi , vj ) valueD(xi ), checks tuples checked before. words,check dk1 tuples value xi . overall, worstcase, dk1 checks plus checks test validity current support.kd values upper bound checks performed HAC make one dual variable AC3. Note dual variables already stack never added it. sense, stackimplemented set.651fiSamaras & StergiouO(kd(d + dk1 ))=O(kdk ). e dual variables worst-case complexity bound O(ekdk ),complexity GAC non-binary representation.asymptotic space complexity HAC algorithm dominated O(edk )space needed store domains dual variables. algorithm also requires O(nde)space store current supports. Since space required grows exponentiallyarity constraints, reasonable assume HVE (and binaryencodings) cannot practical constraints large arity, unless constraintstight.mentioned, consistency check non-binary representation done dierentway HVE. Assume GAC-2001 looks support value ai D(xi )constraint c, vars(c) = {x1 , . . . , xk } xi vars(c). tuple = (a1 , . . . , ak )supports ai [xi ] = ai valid. check valid, GAC-2001 checkvalues a1 , . . . , ak (except ai ) still domains variables x1 , . . . , xk . Therefore,worst case, consistency check GAC-2001 involves k 1 operations. contrast,HAC checks validity tuple constant time looking domaincorresponding dual variable see tuple still there. However, meansalgorithm update (usually) large domains dual variables valuedeletion original variable. aects run times algorithms dierentproblems settings.Appendix show HAC complexity, alsoperforms exactly number consistency checks GAC-2001 arc consistentproblems. also show arc inconsistent problems dierencenumber checks favor HVE.3.2 Search AlgorithmsSearch algorithms maintain local consistencies widely used CSP solving.extended non-binary case. example, maintaining arc consistency(MAC) forward checking (FC). shown non-binary version MAC(MGAC) applied non-binary CSP equivalent MAC applied HVECSP original variables instantiated variable orderings used(Stergiou & Walsh, 1999). show that, like MGAC, non-binary extensions FCemulated equivalent algorithms run HVE.FC (Haralick & Elliot, 1980) rst generalized handle non-binary constraintsVan Hentenryck (1989). According denition Van Hentenryck (1989), forwardchecking performed k-1 variables k-ary constraint assignedremaining variable unassigned. algorithm called nFC0 paper Bessiere,Meseguer, Freuder, & Larrosa (2002) more, stronger, generalizations FCnon-binary constraints introduced. generalizations dierextent look-ahead perform variable instantiation. Algorithm nFC1 appliesone pass GAC constraint constraint projection involving current variableexactly one future variable4 . Algorithm nFC2 applies GAC set constraintsinvolving current variable least one future variable, one pass. Algorithm nFC3applies GAC set constraints involving current variable least one future4. One pass means constraint processed once.652fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Resultsvariable. Algorithm nFC4 applies GAC set constraints involving least onepast variable least one future variable, one pass. Algorithm nFC5,strongest version, applies GAC set constraints involving least one past variableleast one future variable. generalizations reduce simple FC appliedbinary constraints.show various versions nFC equivalent, terms visited nodes,binary versions FC run HVE problem. holdsassumption binary algorithms assign original variables usevariable value ordering heuristics, static dynamic, non-binary counterparts.Note algorithm nds consistent assignment original variables,assignments propagated dual variables, domains dualvariables reduced singletons. is, domain dual variable vccontain single tuple consistent assignments original variablesconstrained vc . Therefore, algorithm proceed assign dual variablesbacktrack-free manner.equivalence nFC1 version FC HVE, called FC+ (Bacchus& van Beek, 1998), proved Bessiere et al. (2002). FC+ specialized forwardchecking algorithm HVE. operates like standard binary FC exceptdomain dual variable pruned, FC+ removes adjacent original variablesvalue longer supported.Algorithms nFC2-nFC5 also equivalent algorithms operate HVE.call algorithms hFC2hFC5. example, hFC5 enforce AC set dualvariables, original variables connected them, dual variable connectedleast one past original variable least one future original variable. NotenFC0 natural equivalent algorithm HVE. emulate HVEget inecient awkward algorithm. following, hFC0 refer standardbinary FC algorithm hFC1 refer FC+.Proposition 3.1 non-binary CSP, xed variable value ordering, algorithm nFCi, i= 2, . . . 5, equivalent algorithm hFCi operates hidden variableencoding problem.Proof: prove nFC5, strongest among generalized FC algorithms.proof versions similar. need prove nodesearch tree algorithms nFC5 hFC5 delete exactly valuesdomains original variables. Assume node, instantiating currentvariable, nFC5 deletes value future variable xi . exists constraintc including xi least one past variable, value xi supporting tuple c.HVE, hFC5 tries make vc (the dual variable corresponding c) ACremove tuples assign xi . Hence, hFC5 delete domain xi .opposite case, hFC5 deletes value original variable xi meanstuples including assignment removed domains dual variablesinclude xi least one past variable. non-binary representation problem,assignment xi supporting tuples constraints involve xileast one past variable. Therefore, nFC5 delete domain xi . 2653fiSamaras & StergiouAlgorithms nFC2nFC5 equivalent node visits corresponding algorithms hFC2hFC5, also asymptotic cost. holdscondition non-binary algorithms use GAC-2001 (or optimal algorithm)enforce GAC, HVE versions use algorithm HAC.Proposition 3.2 non-binary CSP, xed variable value ordering, algorithm nFCi, i= 2, . . . 5, asymptotic cost algorithm hFCi operateshidden variable encoding problem.Proof: Section 3.1 showed enforce AC HVE non-binaryCSP worst-case complexity GAC non-binary representationproblem. Since algorithm nFCi enforces GAC part problemalgorithm hFCi enforces AC, visit nodes search tree, followstwo algorithm asymptotic cost. 2paper Bessiere et al. (2002), detailed discussion complexities algorithms nFC0nFC5 made. worst-case complexity nFC2 nFC3 one nodeO(|Cc,f |(k 1)dk1 ), |Cc,f | number constraints involving current variable least one future variable. also complexity hFC3 hFC4.worst-case complexity nFC4 nFC5 one node O(|Cp,f |(k 1)dk1 ), |Cp,f |number constraints involving least one past variable least one futurevariable. also complexity hFC4 hFC5.Assuming nodes(algi ) set search tree nodes visited search algorithmalgi following holds.Corollary 3.1 Given hidden variable encoding CSP xed variable valueordering schemes, following relations hold:1. nodes(hFC1) nodes(hFC0)2. nodes(hFC2) nodes(hFC1)3. nodes(hFC5) nodes(hFC3) nodes(hFC2)4. nodes(hFC5) nodes(hFC4) nodes(hFC2)5. nodes(MAC) nodes(hFC5)Proof: proof 1 straightforward, see paper Bacchus & van Beek (1998).Proof 2-4 straightforward consequence Proposition 3.1 Corollary 2paper Bessiere et al. (2002) hierarchy algorithms nFC0-nFC5 node visitsgiven. easy see 5 holds since hFC5 applies AC part CSP,MAC applies whole problem. Therefore, MAC prune least manyvalues hFC5 given node search tree. Since variable valueordering heuristics used, means MAC visit numbernodes hFC5. 2Note paper Bacchus & van Beek (1998) experimental results show differences FC HVE FC non-binary representation. However,654fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Resultsalgorithms compared FC+ nFC0, equivalent. Also,proved hFC0 exponentially greater cost nFC0, vice versa(Bacchus et al., 2002). However, algorithms equivalent. proved Proposition 3.2, result Bacchus et al. (2002) hold comparing equivalentalgorithms.far showed solving non-binary CSP directly many ways equivalentsolving using HVE, assuming original variables instantiated.natural question whether search techniques inapplicablenon-binary case, applied encoding. answer ability searchalgorithm operates encoding instantiate dual variables. equivalentnon-binary representation would imply instantiating values one variablessimultaneously. implement algorithm would modify standard searchalgorithms heuristics devise new ones. hand, HVE algorithminstantiates dual variables easily implemented.4. Algorithms Dual Encodingsection turn attention DE describe specialized AC algorithmsignicantly lower complexity generic algorithm.4.1 Arc Consistencyknow AC DE strictly stronger GAC non-binary representationAC HVE (Stergiou & Walsh, 1999). Since DE binary CSP, one obviousway apply AC using generic AC algorithm. domain size dual variablecorresponding kary constraint dk worst case. Therefore, applyoptimal AC algorithm enforce AC one dual constraint O(d2k ) worstcase complexity. DE CSP e constraints maximum arity ke(e 1)/2 binary constraints (when pairs dual variables share oneoriginal variables). Therefore, enforce AC DE CSP O(e2 d2k ) worstcase complexity. signicantly expensive compared O(ekdk ) complexitybound GAC non-binary representation AC HVE.high complexity bound, AC processing DE considered impractical, exceptperhaps tight constraints.However, show AC applied DE much eciently.precise enforce AC DE non-binary CSP O(e3 dk ) worst-case timecomplexity. improvement asymptotic complexity achieved exploitingstructure DE; namely, fact constraints DE piecewisefunctional.Consider binary constraint dual variables vi vj . create piecewisedecomposition tuples domain either dual variable groupstuples group supported group tuples variable.non-binary constraints corresponding two dual variables share f original variablesx1 , . . . , xf domain size d, partition tuples vi vj df groups.tuple group includes sub-tuple form (a1 , . . . , af ), a1D(x1 ), . . . , af D(xf ). tuple supported tuples group655fiSamaras & Stergiouvariable, tuple also includes sub-tuple (a1 , . . . , af ).The tuplesbelonging supports tuple since tuple containsub-tuple (a1 , . . . , af ). words, group tuples variable visupported corresponding group variable vj tuples groupsvalues original variables common two encoded non-binaryconstraints. Therefore, constraints DE piecewise functional.Example 4.1 Assume two dual variables v1 v2 . v1 encodes constraint(x1 , x2 , x3 ), v2 encodes constraint (x1 , x4 , x5 ), original variablesx1 , . . . , x5 domain {0, 1, 2}. partition tuples dual variable3 groups. rst group include tuples form (0, , ), second include tuples form (1, , ), third include tuples form (2, , ).star () means corresponding original variable take value. groupsupported corresponding group variable. Note tuplesvariable vi partitioned dierent groups according constraint involves vi .instance, another dual variable v3 encoding constraint (x6 , x7 , x3 )partition tuples D(v1 ) according constraint v1 v3 groupsform (, , 0), (, , 1), (, , 2).Van Hentenryck, Deville & Teng (1992) shown AC achievedset binary piecewise functional constraints O(ed) worst-case time complexity,improvement O(d) compared O(ed2 ) complexity arbitrary binary constraints(Van Hentenryck et al., 1992). Since showed constraints DE piecewisefunctional, result Van Hentenryck et al. (1992) means improveO(e2 d2k ) complexity AC DE.Figure 4 sketch AC-3 like AC algorithm specically designed DE,call PW-AC (PieceWise Arc Consistency). show, algorithmworst-case time complexity O(e3 dk ). complexity bound achievedAC-5 algorithm Van Hentenryck et al. (1992), specialization piecewisefunctional constraints, necessary adaptations operate DE.AC algorithms, PW-AC uses stack (or queue) propagate deletions domainsvariables. stack processes groups piecewise decompositions, instead variablesconstraints usual AC algorithms. use following notation:S(vi , vj ) = {s1 (vi , vj ), . . . , sm (vi , vj )} denotes piecewise decomposition D(vi )respect constraint vi vj . sl (vi , vj ), l = 1, . . . , m,group partition.sup(sl (vi , vj )) denotes group S(vj , vi ) support group sl (vi , vj )S(vi , vj ). discussed, group unique.counter(sl (vi , vj )) holds number valid tuples belong group sl (vi , vj )decomposition S(vi , vj ). is, time value counter(sl (vi , vj )) givescurrent cardinality group.GroupOf (S(vi , vj ), ) function returns group S(vi , vj ) tuplebelongs. implement function, constraint dual variables vi656fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Resultsfunction P W AC1:Q2:initialize group counters 03:variable vi4:variable vj constrained vi5:tuple D(vi )6:counter(GroupOf (S(vi , vj ), )) counter(GroupOf (S(vi , vj ), )) + 17:variable vi8:variable vj constrained vi9:group sl (vi , vj )10:counter(sl (vi , vj )) = 011:put sl (vi , vj ) Q12: return P ropagationfunction P ropagation13: Q empty14:pop group sl (vi , vj ) Q15:16:Revise(vi , vj , sl (vi , vj ))17:D(vj ) empty return INCONSISTENCY18:group sl (vj , vk ) put sl (vj , vk ) Q19: return CONSISTENCYfunction Revise(vi , vj , sl (vi , vj ))20: tuple D(vj ) sup(sl (vi , vj ))21:remove D(vj )22:group sl (vj , vk ) includes23:counter(sl (vj , vk )) counter(sl (vj , vk )) 124:counter(sl (vj , vk )) = 025:add sl (vj , vk )26: returnFigure 4: PW-AC. AC algorithm dual encoding.vj store original variables shared non-binary constraints cvicvj . Also, original variable xl store pos(xl , cvi ) pos(xl , cvj ).way GroupOf function takes constant time.set contains groups counter reduced 0 callfunction Revise. is, groups tuples belongingdeleted.algorithm works follows. initialization phase, group countnumber tuples contains (lines 36). Then, variable vi iterate657fiSamaras & Stergiouvariables vj constrained vi . group sl (vi , vj ) S(vi , vj ), checksl (vi , vj ) empty (line 10). empty, added stack propagation.next phase, function P ropagation called delete unsupported tuplespropagate deletions (line 12). previous phase nished, stackcontain number groups 0 cardinality. group sl (vi , vj ) mustremove tuples belonging group sup(sl (vi , vj )) since lost support.done successively removing group sl (vi , vj ) stack calling functionRevise. Since group sup(sl (vi , vj )) lost support, tuple D(xj ) belongssup(sl (vi , vj )) deleted (lines 2021). Apart sup(sl (vi , vj )), tuple may also belonggroups D(vj ) partitioned respect constraints vjvariables. Since deleted, counters groups must updated (i.e. reducedone). done lines 2223. implementation use function GroupOfaccess relevant groups. counter group becomes 0 groupadded stack propagation (lines 2425 18). process stops eitherstack domain variable becomes empty. former case, DE AC,latter not.following example illustrates advantage algorithm PW-AC genericAC algorithm employed DE, AC HVE (or GAC non-binary representation).Example 4.2 Consider three constraints c1 , c2 , c3 part CSP, vars(c1 ) ={x0 , x1 , x3 }, vars(c2 ) = {x2 , x3 , x4 }, vars(c3 ) = {x2 , x4 , x5 }. Assume pointdomains variables DE problem shown Figure 5 (disregardingoriginal variables depicted dashed lines). Assume try enforce ACx 2x 3x 4x 0x 1x 3vc10,0,00,1,00,1,31,0,11,0,2vc20,0,00,1,10,2,10,3,11,1,01,2,01,3,0x2x 2x 4x 50,11,0,00,1,0vc30,1x4Figure 5: Dual encoding non-binary CSP.DE using algorithm AC-20015 . algorithm discover rst tuple D(vc2 )support D(vc3 ) (there tuple x2 = 0 x4 = 0) delete it.deletion, rst two tuples D(vc1 ) lose support D(vc2 )AC-2001 must therefore look new supports. two tuples D(vc1 )algorithm check 6 remaining tuples D(vc2 ) discoveringsupport. result two tuples deleted. Algorithm PW-AC,hand, set counter group rst tuple D(vc2 ) belongs (accordingpartition S(vc2 , vc3 )) 0 deletes tuple. result call function5. Note construct similar examples generic AC algorithm.658fiBinary Encodings Non-binary CSPs: Algorithms & Experimental ResultsRevise automatic deletion rst two tuples D(vc1 ), saving total 2 6checks.consider HVE problem. Applying AC HVE eectvalues 0 1 x2 x4 supported D(vc2 ) D(vc3 ). Thereforepropagation variables, result two tuples D(vc1 )deleted. Similarly, propagation apply GAC non-binaryrepresentation problem.Note theoretical results regarding DE presented rest paperhold AC-5 algorithm Van Hentenryck et al. (1992) adapted used DEinstead PW-AC. two algorithms similarities (e.g. use functionaccess group decomposition certain tuple belongs to, though implementeddierently), basic operation dierent. algorithm Van Hentenryck et al.(1992), instantiation AC-5, handles queue triples (vi , vj , a) implementconstraint propagation, vi vj two variables involved constraintvalue removed D(vj ). PW-AC utilizes queue piecewisedecompositions. Also data structures used algorithms dierent. PW-ACchecks updates counters perform propagation which, explain below, requiresspace exponential number common variables non-binary constraints.algorithm Van Hentenryck et al. (1992) utilizes complicated data structurerequires space exponential arity non-binary constraints. noted,however, PW-AC specically designed DE. is, operation, datastructures, way checks consistency based fact domainsdual variables consist tuples original constraints extensionally stored.hand, algorithm Van Hentenryck et al. (1992) generic, senseadapted operate piecewise functional constraint.4.1.1 ComplexitiesPW-AC algorithm consists two phases. initialization phase set groupcounters, main phase delete unsupported tuples propagate deletions.analyze time complexity PW-AC. Note complexity analysismeasure operations, incrementing decrementing counter, since PW-ACperform consistency checks usual sense.Proposition 4.1 worst-case time complexity algorithm PW-AC O(e3 dk ).Proof: assume constraint dual encoding, non-binary constraints corresponding two dual variables vi vj share f original variablesx1 , . . . , xf domain size d. means piecewise decomposition consistsdf groups. Obviously, f equal k 1, k maximum arityconstraints. initialization phase lines 36 iterate constraints,constraint variables vi vj , iterate tuples D(vi ).done O(e2 dk ) asymptotic time complexity. Then, empty groups insertedQ (lines 711). requires e2 df operations worst case. initialization,function P ropagation called. group inserted Q (and later removed)becomes empty. means loop P ropagation executed659fiSamaras & Stergioudf times constraint, e2 df times total. also maximumnumber times function Revise called (once every iteration loop). costfunction Revise computed follows: Assuming Revise called group sl (vi , vj ),iterate (at most) dkf tuples group sup(sl (vi , vj )) (line 20). iterationremove tuple (line 21) update counters groups belongs(lines 2223). e groups (in case vj constrained dualvariables). Therefore, iteration costs O(e), result, call Revise costsO(edkf ). Since Revise called e2 df times, complexity PW-AC, includinginitialization step, O(e2 dk + e2 df + e2 df edkf )=O(e3 dk ). 2Note PW-AC easily used incrementally search. case,initialization phase executed once. asymptotic space complexity PWAC, AC algorithm binary encoding, dominated O(edk ) space needstore allowed tuples non-binary constraints. Algorithm PW-AC also requiresO(e2 df ) space store counters groups, O(e2 df ) space stack,O(f e2 ) space fast implementation function GroupOf .5. Algorithms Double Encodingdouble encoding rarely used experiments binary encodings, althoughcombines features HVE DE, therefore may exploit advantagesworlds. precise, double encoding oers following interesting potential:search algorithms deploy dynamic variable ordering heuristics assign valuesoriginal variables, constraint propagation implemented constraintsdual variables achieve higher pruning. section rst briey discussAC applied double encoding. show various search algorithmsadapted operate double encoding.5.1 Arc ConsistencyAC enforced double encoding using algorithm PW-AC additiontime value original variable xi loses supports adjacent dualvariable, deleted D(xi ). Alternatively, use generic AC algorithm,AC-2001. Note AC algorithm applied double encoding enforce variouslevels consistency depending constraints uses propagation dualvariables. is, propagation either done directly constraintsdual variables, indirectly constraints dual original variables.example, use constraints dual original variables getlevel consistency AC HVE. propagation dual variablesperformed using constraints DE get level consistency ACDE, dual variables, also prune domains original variables.between, option use dierent constraints propagation dierent partsproblem. next example shows, AC double encoding achievehigh level consistency compared non-binary representation. Sections 6.2 6.3show profound eect practice.660fiBinary Encodings Non-binary CSPs: Algorithms & Experimental ResultsExample 5.1 Consider problem Figure 6. Applying AC constrainttwo dual variables determine problem insoluble. However,problem non-binary representation GAC, also singleton (generalized)arc consistent (SGAC), high level consistency. CSP SGACapplying GAC problem induced instantiation single variable,domain wipeout (Debruyne & Bessiere, 2001; Prosser, Stergiou, & Walsh, 2000).x1x 0x 1x 2x 30x00,10x4x 1x 2x 3x 4x2vc10, 0, 0, 00, 0, 1, 10, 1, 0, 10, 1, 1, 00,10, 0, 1, 00, 1, 0, 01, 0, 0, 01, 1, 1, 0vc20,1x3Figure 6: Double encoding problem AC double encoding SGACnon-binary representation.5.2 Search AlgorithmsVarious search algorithms double encoding dened, depending variablesinstantiated constraints used propagation. restrictalgorithms instantiate original variables perform propagationusing constraints dual variables. Intuitively interesting classalgorithms combine nice features non-binary representationHVE (small domain sizes), DE (strong propagation).rst show FC versions HVE discussed Section 3.2 adaptedyield algorithms run double encoding. call algorithms dFC0dFC5.algorithm dFCi (i = 0, . . . , 5) instantiates original variables enforces ACexactly set variables double encoding corresponding algorithm hFCiHVE. example, dFC5 enforce AC set dual variables, originalvariables connected them, dual variable connected least one pastoriginal variable least one future original variable. dierence algorithmdFCi (i = 2, . . . , 5) hFCi former exploit constraints dualvariables enforce higher level consistency latter. surprisingly,results stronger algorithms.Proposition 5.1 non-binary CSP, xed variable value ordering, algorithm dFCi (i= 2, . . . , 5) strictly stronger respective algorithm hFCi.Proof: easy see value pruned hFCi HVE alsopruned dFCi double encoding. straightforward consequencefact 1) double encoding subsumes HVE, 2) algorithms dFCi hFCienforce AC set variables. Algorithm dFCi strictly stronger hFCi661fiSamaras & Stergioubecause, exploiting constraints dual variables, prune valueshFCi. Consider, instance, problem two constraints c1 c2 , vars(c1 ) ={x1 , x2 , x3 , x4 } vars(c2 ) = {x1 , x2 , x3 , x5 }. variables xi , = 1, . . . , 5, domains{0, 1}. allowed tuples constraints rel(c1 ) = {(0, 0, 1, 0), (0, 1, 0, 1), (1, 1, 0, 1)}rel(c2 ) = {(0, 0, 0, 0), (0, 1, 1, 1), (1, 0, 0, 0)}. x1 given value 0 HVEalgorithms hFC2hFC5 prune tuples (1, 1, 0, 1) (1, 0, 0, 0) domains dualvariables vc1 vc2 respectively. pruning performed. doubleencoding, variable assignment, algorithms dFC2dFC5, causedomain wipe-out two dual variables. 2Corollary 5.1 non-binary CSP, xed variable value ordering, algorithmdFCi (i= 2 . . . 5) strictly stronger respective algorithm nFCi (i=2 . . . 5).Proof: Straightforward consequence Propositions 5.1 3.1. 2easy see algorithm hFC0 (i.e. simple binary FC) equivalent dFC0.holds algorithms hFC1 dFC1. various versions FC, MACalgorithm adapted run double encoding original variablesinstantiated, propagation implemented constraints dualvariables. easy see algorithm strictly stronger correspondingalgorithm HVE (the proof similar proof Proposition 5.1). interestingly, show MAC algorithm double encoding can, most,polynomially greater cost corresponding MAC algorithm HVE, while,hand, exponentially better.Proposition 5.2 non-binary CSP, xed variable value ordering,MAC algorithm hidden variable encoding instantiates original variablesexponentially greater cost corresponding MAC algorithm doubleencoding.Proof: prove this, use Example 14 paper Bacchus et al. (2002).example CSP 4n + 2 variables, x1 , . . . , x4n+2 , domain{1, . . . , n}, 2n + 1 constraints:c1 : (x1 + x2 mod 2) = (x3 + x4 mod 2)c2 : (x3 + x4 mod 2) = (x5 + x6 mod 2)...c2n : (x4n1 + x4n mod 2) = (x4n+1 + x4n+2 mod 2)c2n+1 : (x4n+1 + x4n+2 mod 2) = (x1 + x2 mod 2)Assume variables assigned lexicographic order double encoding. x1x2 assigned values (x1 + x2 mod 2) = 0 enforcing AC prunetuples D(vc1 ) (x3 + x4 mod 2) = 0. turn prune D(vc2 )tuples (x5 + x6 mod 2) = 1. Continuing way, AC propagation pruneD(vc2n+1 ) values (x1 + x2 mod 2) = 0. deletions propagatedvc1 , D(vc1 ) become empty. similar way, enforcing AC assignments662fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Resultsx1 x2 , (x1 + x2 mod 2) = 1, leaves D(vc1 ) empty. Therefore, CSPinsoluble. MAC double encoding needs instantiate two variables discover this,visit O(n2 ) nodes. hand, explained Bacchus et al. (2002), MACHVE needs visit O(nlog(n) ) nodes conclude problem insoluble. Finally,note that, node, asymptotic costs MAC double encoding (using PWAC) MAC HVE polynomially related. Therefore, MAC HVEexponentially worse MAC double encoding. 2corollary Proposition 5.2 MAC double encoding exponentially smaller cost MGAC non-binary representation.Proposition 5.3 non-binary CSP, xed variable value ordering,MAC algorithm double encoding instantiates original variablespolynomially greater cost corresponding MAC algorithm hiddenvariable encoding.Proof: prove need show two things: 1) number node visits madeMAC double encoding polynomial factor greater numbernode visits made MAC HVE, 2) node, worst-case cost MACdouble encoding polynomial factor greater worst-case cost ACHVE. former true since MAC double encoding strictly strongerMAC HVE. latter established considering worst case complexitiesalgorithms node. MAC HVE costs O(ekdk ) node, MACdouble encoding use PW-AC enforce AC, costs O(e3 dk ). Therefore,polynomial dierence. 2similar way, prove relationship Proposition 5.3 holdsalgorithm dFCi (i= 2 . . . 5) corresponding algorithm hFCi. corollary Proposition 5.3 MAC double encoding polynomially greater costMGAC non-binary representation. important note Proposition 5.3holds algorithm PW-AC used enforce AC double encoding. usegeneric algorithm, like AC-2001, get exponential dierences favor MACHVE. Finally, regarding relationship node visits among algorithmsdouble encoding, following.Proposition 5.4 Given double encoding CSP xed variable value ordering schemes, following relations hold:1. nodes(dFC1) nodes(dFC0)2. nodes(dFC2) nodes(dFC1)3. nodes(dFC5) nodes(dFC3) nodes(dFC2)4. nodes(dFC5) nodes(dFC4) nodes(dFC2)5. nodes(dMAC) nodes(dFC5)Proof: proof simple based comparing size subsetsproblem algorithm enforces AC. 2663fiSamaras & Stergiou6. Experimental Resultssection make empirical study algorithms binary encodings. empiricalstudy organized two parts:rst part (Subsections 6.1 6.2) evaluate improvements oeredspecialized algorithms compared generic ones. time compareeciency algorithms run binary encodings non-binary counterparts. comparison give us better understanding encodingnon-binary problem binary one pays o, encoding preferable.empirical investigation use randomly generated problems, random problemsadded structure, benchmark crossword puzzle generation problems. Randomproblems allow us relate performance algorithms certain parameters,tightness, constraint graph density, domain size. Crossword puzzlesstandard benchmarks comparing binary non-binary constraint models, allow us evaluate performance algorithms problems includeconstraints high arity.second part (Subsection 6.3) , investigate usefulness binary encodingsrealistic problem settings. study use problems domainsconguration frequency assignment compare performance MACalgorithms run encodings MGAC algorithm non-binary representation.algorithms implemented C. experiments run PC 3.06GHz Pentium 4 processor 1 GB RAM. experiments, algorithms usedom/deg heuristic (Bessiere & Regin, 1996b) dynamic variable ordering lexicographic value ordering.6.0.1 Random ProblemsRandom instances generated using extended model B described Bessiereet al. (2002). summarize generation method, random non-binary CSP denedfollowing input parameters:n - number variables- uniform domain sizek - uniform arity constraintsp - density (%) percentage generated graph, i.e. ratio existing constraintsnumber possible sets k variablesq - uniform looseness (%) percentage constraints, i.e. ratio allowedtuples dk total tuples constraintconstraints allowed tuples generated following uniform distribution.made sure generated graphs connected. following, class non-binary664fiBinary Encodings Non-binary CSPs: Algorithms & Experimental ResultsCSPs denoted tuple form < n, d, k, p, q >. use star () caseone parameters varied. example, tuple < 50, 20, 3, 10, > standsclass problems 50 variables, domain size 20, arity 3, graph density 10%,varying constraint looseness.6.0.2 Crossword PuzzlesCrossword puzzle generation problems used evaluation algorithmsheuristics CSPs (Ginsberg, Frank, Halpin, & Torrance, 1990; Beacham, Chen, Sillito, &van Beek, 2001) binary encodings non-binary problems (Bacchus & van Beek, 1998;Stergiou & Walsh, 1999). crossword puzzle generation try construct puzzlesgiven number words given grid lled words. problemrepresented either non-binary binary CSP straightforward way.non-binary representation variable letter lled nonbinary constraint set k variables form word puzzle. domainvariable consists low case letters English alphabet giving domainsize 26. allowed tuples constraint words k lettersdictionary used. compared 26k possible combinations letters,means constraints tight. DE variable wordlength k puzzle possible values variable words kletters dictionary. gives variables large domains (up 4072 valuesUnix dictionary used experiments). binary constraintsvariables intersect (i.e. common letter). HVEoriginal variables well set dual variables, one non-binary constraint.6.1 Hidden Variable Encodingrst empirical study investigated performance two MAC algorithmsoperate HVE, compared MGAC-2001, counterpart nonbinary representation. two MAC algorithms HVE MHAC-2001,stands MAC HVE instantiates original variables, MHAC-2001-f ullMAC algorithm may instantiate variable (dual original) accordingheuristic choice. stated names, three algorithms use AC-2001 (GAC-2001)enforce AC. Although also run experiments various versions FC,include results since algorithms inecient hard problems (especially hardcrossword puzzles). However, qualitative comparison FC-based algorithmsHVE non-binary representation similar comparison regarding MACbased algorithms.6.1.1 Random ProblemsTable 1 shows performance, measured cpu time, algorithms classesrandomly generated CSPs. classes hard phase transition region. Classes 1,2, 3, 4 sparse, 5 dense. include results MHAC-2001-f ullexperiments showed algorithm similar behavior MHAC-2001.reason that, nature constraints, dom/deg heuristic almost665fiSamaras & Stergioualways selects original variables instantiation. rare cases heuristicselected dual variables, resulted large increase cpu time.classMGAC-2001 MHAC-20011: < 30, 6, 3, 1.847, 50 >2.081.902: < 75, 5, 3, 0.177, 41 >4.093.413: < 50, 20, 3, 0.3, 5 >64.1528.104: < 50, 10, 5, 0.001, 0.5 >74.7222.535: < 20, 10, 3, 5, 40 >5.758.15Table 1: Comparison algorithms MGAC-2001 MHAC-2001 random classesproblems. Classes 1 2 taken paper Bessiere et al. (2002). giveaverage run times (in seconds) 100 instances class. winningtime instance given bold. follow rest paper.Table 1 see MHAC-2001 performs better MGAC-2001sparse problems. general, 3-ary classes tried density less 3% 4%relative run time performance MHAC-2001 compared MGAC-2001 rangedequal around 2-3 times faster. sparse class 4, includesproblems 5-ary constraints, MHAC-2001 considerably ecient MGAC2001. due fact sparse problems relatively large domain sizeshard region located low constraint looseness (i.e. small domains dual variables)operations required revision dual variables. Another factorcontributing dominance binary algorithm class 4 larger arityconstraints. non-binary algorithm requires operations check validitytuples tuples large arity, explained Section 3.1.density graph increases (class 5), overhead revising domainsdual variables restoring failed instantiations slows MHAC-2001,result outperformed MGAC-2001. denser classes ones reported,phase transition region point half tuples allowed,cases non-binary algorithm performs even better.6.1.2 Crossword PuzzlesTable 2 demonstrates performance search algorithms various crossword puzzles.used benchmark puzzles papers Ginsberg et al. (1990) Beacham et al.(2001). Four puzzles (15.06, 15.10, 19.03, 19.04) could solved algorithmswithin 2 hours cpu time. Also, two puzzles (19.05 19.10) arc inconsistent.cases GAC discovered inconsistency slower AC HVE (around 3:1 timedierence 19.05 10:1 19.10) latter method discovered early domainwipe-out dual variable.rest puzzles observe MHAC-2001 performs better MGAC2001 hard instances. hard insoluble puzzles MHAC-2001 3 timesfaster MGAC-2001. mainly due large arity constraints666fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Resultspuzzle15.0215.04*15.0719.0219.086677*88*1010*n80767411813412141620e MGAC-2001 MHAC-2001 MHAC-2001-f ull1913.703.5819340.8438.8829.7519394.6546.3644m29634.6235.082915.45369.395.075.494914m8m12m646m2m5m10011.8111.8515.39Table 2: Comparison (in cpu time) algorithms HVE algorithmsnon-binary representation crossword puzzles. n number words enumber blanks. times seconds except followed(minutes). dash () placed wherever algorithm manage ndsolution within 2 hours cpu time. Problems marked (*) insoluble.include problems reasonably hard least one algorithmtime solvable within 2 hours least one algorithm.classes6 . Another interesting observation signicant dierencesperformance methods may instantiate dual variables instantiateoriginal ones. many cases MAC-2001-f ull managed nd (dierent) solutionMHAC-2001 MGAC-2001 earlier. hand, MAC-2001-f ull subjectthrashing instances methods terminate. fact insolublepuzzles MAC-2001-f ull better MHAC-2001 shows performancelargely dependent variable ordering scheme. many cases MAC-2001-f ull visitedless nodes MHAC-2001. However, reected similar time performancedierence dual variable instantiated MAC-2001-f ull workoriginal one instantiated. instantiate automatically originalvariable xi constrained dual variable propagate changes dualvariables containing xi .6.2 Dual Double Encodingsempirical study investigated performance algorithms DE doubleencoding. tried answer following three questions: 1) ecient specializedalgorithms compared generic algorithms? 2) use specialized algorithmmake DE eective option solving non-binary CSPs? 3) take advantagetheoretical properties double encoding practice? answer questions,run experiments random structured problems evaluate benets oeredspecialized algorithm PW-AC maintaining AC search. compared6. Puzzles 66-1010 correspond square grids blank squares.667fiSamaras & Stergiouperformance two MAC algorithms; one uses AC-2001 enforce AC (MAC2001), another uses PW-AC enforce AC (MAC-PW-AC). also comparedalgorithms algorithm maintains GAC non-binary representationusing GAC-2001 (MGAC-2001), MAC algorithms maintain AC doubleencoding using PW-AC (algorithm MAC-PW-ACd) AC-2001 (algorithm MAC-2001d).6.2.1 Random Problemsrst give indicative results comparison various algorithms usingrandom problems. Figure 7 compares time required enforce AC DEGAC non-binary representation, Figures 8-10 compare algorithmsmaintain consistencies.Figure 7 shows average cpu times (in msecs) PW-AC AC-2001 takeenforce AC DE 100 random CSPs 50 variables domain size 30, ternaryconstraints, 0.3 graph density (58 constraints). also include average time GAC2001 takes enforce GAC non-binary representation generated instances.looseness constraints varied starting point instances GACGAC AC DE delete values. signicant dierenceperformance PW-AC compared AC-2001 constantly rises loosenessconstraints becomes higher. expected, since number allowed tuplesconstraint grows, AC-2001 takes time nd supports. GAC-2001 fasterPW-AC (up one order magnitude) looseness low, dierencebecomes smaller looseness grows.Figure 8 shows cpu times relatively sparse class problems 30 variables40 ternary constraints (p = 1). Figure 9 shows cpu times node visits denser class30 variables 203 ternary constraints (p = 5). Along x-axis vary domainsize variables. data points show average cpu times (in secs) 100 instancestaken hard phase transition region.make following observations: 1) MAC-PW-AC MAC-PW-ACd signicantly faster (one order magnitude) MAC-2001 MAC-2001d, respectively,classes problems. 2) classes, non-binary representation preferable DE (MGAC-2001 two orders magnitude faster denser class).sparser class, MAC double encoding (i.e. algorithm MAC-PW-ACd) competitiveMGAC-2001 small domain sizes, considerably faster larger domain sizes.eect domain size relative performance algorithms mainly duerun time advantage PW-AC compared GAC-2001, higher consistencylevel achieved double encoding7 . run time advantage PW-AC explainedconsidering that, domain size increases, GAC-2001 check increasing numbertuples supports; operation costly counter updates PW-AC.denser class MGAC-2001 constantly faster algorithms domainsizes. surprising considering O(e3 dk ) O(ekdk ) complexities PW-ACGAC-2001 (i.e. factor e becomes signicant).Figure 10 compare algorithms MGAC-2001 MAC-PW-ACd (the faster amongalgorithms encodings) class problems 20 variables 48 4-ary7. verified looking node visits two algorithms.668fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results1000010000cpu time (secs)1000cpu time (msecs)100000AC-2001PW-ACGAC-200110010110001001010.10.100.0050.010.015q0.020.0250.03010000010152025Figure 8: < 30, , 3, 1, > CSPs.100000MAC-2001MAC-AC2001dMAC-PW-ACMAC-PW-ACdMGAC-2001MGAC-2001MAC-PW-ACd10000cpu time (secs)100005Figure 7: < 50, 30, 3, 0.3, > CSPs.cpu time (secs)MAC-2001MAC-2001dMAC-PW-ACMGAC-2001MAC-PW-ACd10001001010001001010.11051015200510152025Figure 9: < 30, , 3, 5, > CSPs.Figure 10: < 20, , 4, 1, > CSPs.constraints. algorithms encodings competitive classproblems. see MGAC-2001 ecient small domain sizes,larger domain sizes MAC-PW-ACd one order magnitude faster. However,denser classes problems results reversed.experiments random problems conjecture double encodingpreferred model sparse problems, provided ecient algorithm likePW-AC used propagation. CSPs medium high density non-binaryrepresentation preferable encodings.Random Problems Added Structure experiments ternary CSPsdetect advantage DE compared non-binary representation(and consequently HVE). MAC DE rarely better MGAC-2001 (onlycases tight constraints large domain sizes), despite use PW-ACpropagation. Also, MAC-PW-ACd competitive often faster MGAC2001 sparse random problems, result reversed density increases. basicreason results randomly generated problems (especially ones ternaryconstraints) get many pairs non-binary constraints share one originalvariable. known (see Bacchus et al., 2002 example) pairconstraints, ltering achieved AC DE ltering achievedGAC non-binary representation (and AC HVE). Therefore, AC DElooses much ltering power.669fiSamaras & Stergiouvalidate conjecture, experimented generation model structureadded purely random problems. precise, experimented problemsclique variables embedded randomly generated instance. ternary problemstwo constraints clique may share one two variables. decided random.4-ary problems two constraints clique may share one, two, three variables.Again, decided random. Table 3 compares performance various MACalgorithms < 30, 10, 3, 5, > < 20, 10, 4, 1, > problems type. secondclass include results MAC-PW-ACd, far best algorithmproblems, MGAC-2001.arity clique size MGAC-2001 MAC-2001 MAC-PW-AC MAC-2001d MAC-PW-ACd30633.5045303.769205.957549.611362.31310874.0721007.455349.553078.45421.073201121.391932.49389.22392.0865.813301598.87374.0348.22102.305.024090.11106.04410247.1861.124208348.92322.86Table 3: Average cpu times MAC algorithms DE double encodingMGAC non-binary representation random problems embeddedcliques. times seconds. number gives average 50 instancesaround phase transition region.see, comparative results algorithms vary according sizeembedded clique. clique embedded (clique size=0) MGAC-2001faster algorithms binary encodings. clique size grows, binaryencodings, especially double, become ecient. double encodingeective DE clique sizes. large clique covers variables, MACdouble encoding many orders magnitude faster MGAC-2001. hugedierence caused presence many constraints share one variablenon-binary representation. cases ltering constraints dualvariables strong. However, much advantage lost generic algorithmsused encodings. Similar results occur denser problems generationmodel used.6.2.2 Crossword PuzzlesTable 4 compares cpu times two MAC algorithms DE MGACnon-binary representation using various benchmark crossword puzzles. includeresults MAC double encoding since particular representation crosswordpuzzle generation problems impractical. reason pair dualvariables involved constraint, two variables one original variablecommon (i.e. letter two words intersect). explained previously,670fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Resultsdegrades ltering achieved constraints dual variables. constraintsdouble encoding redundant since ltering achievedconstraints dual original variables.puzzle15.0215.04*15.0715.0919.0119.0219.0821.0221.0321.0821.096677*88*99*1010*n807674821281181341301301501441214161820e MGAC-2001 MAC-2001 MAC-PW-AC1913.98164.0413.7019340.84895.29140.6519394.651870.433011.5029634.621028.1729133.017.762952.2977.5111.82295345.96273.8740.573659.963668.87369.3998.496.044914m12m646m9m81128.9210011.81474.5422.78Table 4: Comparison (in cpu time) MAC algorithms DE MGACnon-binary representation crossword puzzles. times seconds exceptfollowed (minutes). cpu limit 2 hours. Problems marked(*) insoluble. include problems reasonably hard eitherMGAC-2001 MAC-PW-AC time solvable within 2 hoursleast one algorithm.data Table 4 clearly see MAC-PW-AC signicantly fasterMAC-2001 instances. speedup oered use PW-AC makes MACDE competitive MGAC many cases using generic algorithmDE results clear advantage favor MGAC. Also, instances (e.g. puzzles21.03, 21.08, 21.09), use PW-AC makes MAC DE considerably fasterMGAC. However, still instances MGAC (and consequently MHAC)nds solution (or proves insolubility) fast, MAC DE thrashes, vice versa.Note, 4 10 hard 2121 puzzles tried solvedalgorithm within time limit two hours. MAC-PW-AC managed solve 4instances relatively fast, two algorithms solved 2 withincpu limit.671fiSamaras & Stergiou6.3 Experiments Realistic Problemsnext sections present experimental results conguration frequency assignment problems. aim experiments investigate usefulness binaryencodings realistic structured domains. focus dual double encodingspromising binary encodings strong propagation oer.6.3.1 ConfigurationConguration area CSP technology particularly eective. conguration problem viewed trying specify product dened set attributes,attribute values combined predened ways. problemsmodelled CSPs, variables correspond attributes, domains variablescorrespond possible values attributes, constraints specify predenedways values combined. many conguration problems constraintsexpressed extensionally lists allowed (or disallowed) combinations values. Alternatively, constraints expressed rules easily transformedextensional representation. Consider following example adapted paperSubbarayan, Jensen, Hadzic, Andersen, Hulgaard & Moller (2004).Example 6.1 conguration T-shirt requires specify size (small,medium, large), print (Men Black - MIB Save Whales - STW),color (black, white, red). following constraints: 1) small size chosenSTW print cannot selected. 2) MIB print chosen black colorchosen well, STW print chosen black color cannot selected.conguration problem modelled CSP three variables {x1 , x2 , x3 } representing size, print, color respectively. domains variables D(x1 ) ={small, medium, large}, D(x2 ) = {M IB, ST W }, D(x3 ) = {black, white, red}.rst constraint binary constraint variables x1 x2 following allowedtuples: {< small, IB >, < medium, IB >, < medium, ST W >, < large, IB >, <large, ST W >}. second constraint binary constraint variables x2 x3following allowed tuples: {< IB, black >, < ST W, white >, < ST W, red >}.practice, many solvers conguration problems able interact userthat, apart meeting given specications, users choices values certainattributes also satised. study use conguration instances comparenon-binary representation binary encodings structured realistic problems. Althoughwould interesting investigate applicability binary encodings interactivecongurator, work outside scope paper.run experiments problems taken CLib, library benchmark conguration problems (CLib, 2005). rst thing noticed encoding problemsbinary non-binary CSPs trivially solvable algorithms withoutbacktracking. closer look structure CLibss problems revealed reason;constraint graphs consist various unconnected components. component consistsor, cases, single variable. result, problems split independent subproblems trivially solved algorithms. order obtain dicultinstances benchmarking, made graphs connected adding randomness.672fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Resultsproblems extended adding 6 variables 8-10 constraintsgraph became connected8 . Table 5 shows total number variablesconstraints modied problems. added constraints arity 2, 3, 4 (chosenrandom) variables posted selected random, makingsure resulting graph connected. looseness added constraintalso set random, nally, allowed tuples constraint chosen randomaccording looseness.problem ne arity dommachinefxfsesvsbike2221182028302429334345656944516137MGAC-2001MAC-PW-AC MAC-PW-ACdnodes - timenodes - timenodes - time535874 - 13.83813 - 0.373367 - 1.64193372 - 4.1092 - 0.0170 - 0.01618654 - 30.4341 - 0.03193 - 0.059960160 - 332.527384 - 3.0964263 - 29.8621098334 - 501.85 16890 - 12.23 112957 - 87.77Table 5: Comparison algorithms conguration problems. arity dommaximum constraint arity maximum domain size problem. Run timesgiven seconds.Table 5 gives average run times node visits algorithms MGAC-2001non-binary representation, MAC-PW-AC DE, MAC-PW-ACd doubleencoding. benchmarks repeatedly generated instances usingmodel described above. generated instance solved three algorithmsstored instance hard least one algorithm. Otherwise, discarded.instance considered hard least one algorithm took one secondsolve it. Table 5 reports averages rst 50 hard instances generatedbenchmark. is, run 250 hard instances total. Note binary encodingsconstraints original problem (even binary ones) encoded dual variables.experimental results Table 5 show signicant advantage favorbinary encodings compared non-binary representation, node visits runtimes. DE clearly ecient model. MAC-PW-AC DEthree orders magnitude faster MGAC-2001 non-binary representation.single instance among 250 instances MGAC-2001 fasterMAC-PW-AC. double encoding also much ecient non-binaryrepresentation. main factor contributing performance encodingsstrong propagation achieved constraints dual variables,reected numbers node visits. number reasons, relatedstructure conguration problems, justify strong performanceencodings:8. Experiments showed minimum additions need made order get hardproblems without altering structure problems much.673fiSamaras & Stergiouconstraint graphs sparse. typical conguration problems since,usually, attribute product specication dependenciesattributes.constraints high arity tight. Moreover, value variableslarge domain sizes (typically one) supporting tuple constraintsvariables participate.intersecting non-binary constraints one original variablecommon. explained, demonstrated empirically Section 6.2,signicant impact propagation power AC dual double encodings.Note prole conguration problems, analyzed above, agrees conjectures made based results random problems. is, dual doubleencodings suitable sparse problems tight constraints, intersecting constraints may share one variable.6.3.2 Frequency AssignmentFrequency assignment important problem radiocommunication industry.problem radio communications network given region consistingset transmitters. transmitter position region, frequency spectrum,certain power, directional distribution. aim assign valuesproperties transmitters certain criteria satised. varioustypes frequency assignment problems. study consider version radiolink frequency assignment problem (RLFA). problem given set links{L1 , . . . , Ln }, consisting transmitter receiver. link must assignedfrequency given set F . time total interference receivers mustreduced acceptable level using frequencies possible. problemstypically optimization problems purposes study treatsatisfaction problems.RLFA problem modelled CSP transmitter correspondsvariable. domain variable consists frequencies assignedcorresponding transmitter. interferences transmitters modelledbinary constraints form |xi xj | > s, xi xj variables 0required frequency separation. constraint restricts frequencies twotransmitters simultaneously assigned, way interferenceminimized. realistic assumption closer two frequenciesgreater interference them. binary model used extensivelyrepresent RLFA problems, numerous solution methods (CSP-based other)proposed. Also, RLFA widely used benchmark test new algorithmsbinary constraints (mainly AC algorithms).argued standard binary model frequency assignment problemsfails capture important aspects real problems, multiple interferences,resulting non-optimal frequency assignments (Jeavons, Dunkin, & Bater, 1998; Watkins,Hurley, & Smith, 1998; Bater, 2000; Hodge, Hurley, & Smith, 2002). consequence,eorts introduce expressive methods utilize non-binary674fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Resultsconstraints frequency assignment (e.g. Bater, 2000; Hodge et al., 2002). manytypes non-binary constraints considered. following ones receivedattention:co-channel constraints - e.g., frequencies assigned n transmitters equal.adjacent-channel constraints - e.g., frequencies assigned n transmittersleast one frequency apart.separation constraints - e.g., frequencies assigned n transmitters leastfrequencies apart.Obviously, separation constraints generalize adjacent-channel constraints. rsttwo types constraints typically loose third tight. Separationconstraints used densely constrained areas (representing conurbations region)large number links closely situated. cases, large separationsfrequencies transmitters must imposed, resulting tight constraints.also consider richer type separation constraints: frequencies assigned set ntransmitters least frequencies apart n transmitters among least(> s) frequencies apart others. Note non-binary constraintsequivalently decomposed clique binary constraints (without introducingdual variables) resulting however weaker propagation. example adjacent-channelconstraints. Others cannot equivalently expressed set binary constraints unlessbinary encoding used. example, co-channel constraints. noted Hodge et al.(2002), non-binary constraints low arity utilized practice.shown many cases constraints sucient achieve low interferences.Constraints higher arity may oer improvements quality solutions, tendslow solution process extend solving large real problems becomesinfeasible.empirical study presented interested comparing models RLFAtype problems non-binary constraints corresponding binary encodingsdevising new ecient methods solving RLFA problems. Since available RLFAbenchmarks follow standard binary approach, test algorithms generated nonbinary problems placing variables, corresponding links, grid following typicalRLFA structure. is, problems consist several groups closely situated variablesplus constraints connect groups. example, structures depictedFigure 11. corresponds constraint graph binary RLFA problemtypically consists set cliques (or near-cliques) binary constraints small numberconstraints connecting various cliques (e.g. benchmarks Cabon, De Givry,Lobjois, Schiex, & Warners, 1999). binary encodings considereddouble since dual variables large domains, makes DE inecient.Indicative results experiments run depicted Table 6. experimentsposted low-arity (i.e. 3-ary 5-ary) separation constraints, shown Figure 11,compared performance algorithm MGAC-2001 non-binary modelproblems performance MAC-PW-ACd double encoding problems.tried two implementations MGAC-2001; one utilizes specialized propagators675fiSamaras & Stergioua) prob1b) prob2c) prob3Figure 11: Examples RLFA problems non-binary separation constraints.separation constraints (written functions), another operates extensionalrepresentation constraints. rst implementation generally faster,results MGAC-2001 presented refer intentional implementation. doubleencoding built translating separation constraints lists allowed tuplespreprocessing step.problemprob1prob1prob1prob2prob2prob2prob3prob3prob3prob4prob4prob4prob5prob5prob5(easiest)(median)(hardest)(easiest)(median)(hardest)(easiest)(median)(hardest)(easiest)(median)(hardest)(easiest)(median)(hardest)n484848444444545454686868100100100e arity252525212121242424383838585858444444555555555MGAC-2001MAC-PW-ACdnodes - timenodes - time583 - 1.5148 - 0.3618161268 - 39518.7150 - 0.3456474 - 26.46172071 - 219.06304676 - 169.01305588 - 504.0653654514 - 4220.21 68771412 - 24133.45103 - 13.450 - 6.422134 - 14.142569 - 53.184194 - 115.120 - 5.6470 - 1.2172 - 7.2490 - 8.34294 - 5.290 - 2.4296106 - 522.6499 - 2.81104 - 13.45Table 6: Comparison algorithms RLFA problems separation constraints. aritymaximum constraint arity. Run times given seconds. dash ()placed wherever algorithm nish run within 12 hours cpu time.676fiBinary Encodings Non-binary CSPs: Algorithms & Experimental ResultsTable 6 reports results total 50 instances created using dierent constraintgraph topologies. variables domains 20 25 values. number allowedtuples constraints varied around 50 tight constraints several thousands looser ones, according frequency separation imposed parametersseparation constraints. parameters set random constraint,making sure loose constraints generated. example, 4-ary basicseparation constraint variables domain size 20, least 3 (giving 7920 allowedtuples) 5 (giving 120 allowed tuples).prob1, prob2, prob3 refer problems topologies shown Figure 11.prob4 consists three groups variables, similar ones prob3, arrangedchain-like structure. Finally, instances prob5 consist randomly generated groupsvariables; one 8-10 variables 3-5 3-ary 5-ary constraints. groupsinterconnected according topological distance (i.e. constraints postedvariables nearby groups). instances prob1-prob4 xed topology.topology set instances created changing type constraints. example,two instances topology prob1 may dier type separation constraints(basic richer) include. Also, frequency separations imposedconstraint may dier. Instances prob5 may also dier constraint graph topology.report node visits run times easiest, median, hardest instancetopology, respect performance MGAC9 . hardest instancesencoding non-binary representation (except prob3), easiestmedian instances sometimes dierent.Table 6 see substantial dierences favordouble encoding. Many instances solvable double encodinglittle backtracking MGAC-2001 thrashed. mainly due large numberinterleaved constraints sharing one variable, boosts propagationdouble encoding. performance algorithms seems heavily dependenttopology problems. example, instances prob2 non-binary representationmuch ecient double encoding. seems particular classproblems heuristic choices misled propagation achieved double encoding.able come satisfactory explanation occurredparticular topology.Finally, investigate eect presence loose constraints higher arityhas, run experiments 8-ary adjacent-channel constraints postedvariables apart graph, addition separation constraints.case using double encoding model constraints problems infeasibledue spatial requirements. example, trying generate allowed tuplessingle 8-ary adjacent-channel constraint consumed memory system. Therefore,compared algorithm MGAC-2001 non-binary model MAC algorithmruns hybrid model tight separation constraints modelled usingdouble encoding loose adjacent-channel constraints kept intentional nonbinary representation. Table 7 reports results total 30 instances created using9. create instances varied type constraints values parametersnon-trivial problems generated. consider trivial problems arc inconsistent solvablebacktracking.677fiSamaras & Stergiouproblemprob1prob1prob1prob2prob2prob2prob5prob5prob5(easiest)(median)(hardest)(easiest)(median)(hardest)(easiest)(median)(hardest)n484848444444100100100e arity252525212121585858888888888MGAC-2001MAC-hybridnodes - timenodes - time106 - 20.8850 - 47.605078 - 1201.9884 - 195.43647 - 192.641019 - 308.8480245 - 17690.1276 - 45.920 - 22.1922785 - 3230.4799 - 78.4118447 - 4233.50Table 7: Comparison algorithms RLFA problems separation adjacentchannel constraints. MAC-hybrid corresponds MAC algorithm runshybrid model.graph topologies prob1, prob2 prob5 addition four 8-ary adjacent-channelconstraints instance. hybrid model ecient instances prob1prob5 strong propagation achieved binary encoding tightconstraints. non-binary model better instances prob2 seemspropagation binary encoding results bad heuristic choices.6.4 Discussionsection summarize results experimental studies draw conclusions regarding applicability encodings, based theoretical experimentalanalysis.Hidden Variable Encoding theoretical results suggested, empirical results conrmed, solving problems HVE using algorithms instantiate original variablesessentially analogous solving non-binary representation directly. commonlyused algorithms non-binary problems applied, adjustments, HVE,vice versa. algorithms used, HVE oers (moderate) computationalsavings compared non-binary representation, especially sparse problems.savings due ability AC algorithm HVE detect inconsistencies earlier corresponding GAC algorithm non-binary representation. Therefore,conjecture HVE applicable sparse non-binary problems constraintsextensionally specied. cases, HVE either less ecient run timesnon-binary representation (e.g. dense problems), building HVE adds spaceoverheads justied marginal gains search eort. Additionally,enough empirical evidence suggest essential dierence searchalgorithms HVE non-binary representation, i.e. ability formerbranch dual variables, make HVE signicantly ecient class678fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Resultsproblems. This, coupled fact benets gained instantiating dualvariables maximized double encoding used instead HVE, limitsapplicability algorithms.Dual Double Encodings DE double encoding advantagestrong ltering constraints dual variables. showedadvantage exploited low cost specialized algorithm, PW-AC, makeDE competitive often signicantly better non-binary representationseveral sparse CSPs, crossword puzzle generation conguration problems.dense CSPs, DE pay either spatial requirements make useinfeasible, case, advantages oered outweighed overheadupdating domains dual variables. holds CSPs containing constraintslarge arity unless tight (as crossword puzzles).Algorithms double encoding demonstrate especially promising performance.many non-binary constraints share one variable presentproblem MAC double encoding exploit benets variableordering heuristic, borrowed non-binary representation, stronger ltering,borrowed DE, outperform representations. demonstratedproblems structure (random also frequency assignment - like). alsocase still-life problem, explains success double encoding10 .addition, double encoding oers interesting potential hybrid models certainconstraints encoded binary others kept non-binary representationbased certain properties constraints. precise benet encodingconstraints either naturally specied extension, relatively low aritytight. demonstrated various domains. notably, frequency assignment problems double encoding (or hybrid one) payed cases,although constraints problems naturally dened intentionally.7. Related WorkAlthough, DE proposed 1989 (Dechter & Pearl, 1989) HVE 1990 (Rossiet al., 1990), rst substantial eort towards evaluating eciency carried1998 (Bacchus & van Beek, 1998). work, Bacchus van Beek compared theoretically empirically FC algorithm two encodings FC non-binaryCSPs. Also, introduced FC+, specialized algorithm HVE. algorithmscompared Bacchus van Beek simplest versions FC; hFC0 hFC1 (i.e.FC+) HVE, nFC0 non-binary representation. extend workstudying various recent advanced versions FC.Following Bacchus van Beek (1998), Stergiou Walsh made theoreticalempirical study AC encodings (Stergiou & Walsh, 1999). proved ACHVE equivalent GAC non-binary representation, AC DEstronger. small experimental study included paper Stergiou & Walsh (1999),MAC HVE, DE, double encoding compared MGAC non-binary10. Although title Smiths paper (2002) refers DE, model still-life problem usedbased double encoding.679fiSamaras & Stergiourepresentation crossword puzzles Golomb rulers problems. Results showedadvantage non-binary representation HVE, important noteMAC algorithms used generic inecient algorithms enforce AC.Smith, Stergiou & Walsh (2000) performed extensive experimental comparisonMAC HVE double encoding, MGAC non-binary modelGolomb rulers problem. However, MAC algorithms encodings used genericalgorithm enforce AC. result outperformed MGAC non-binarymodel.Beacham et al. (2001) compared performances dierent models, heuristics,algorithms CSPs using crossword puzzle generation problems benchmarks. Amongmodels compared HVE, DE non-binary representation.again, algorithms applied encodings generic algorithms.example, two implemented algorithms DE MAC uses AC-3propagation MAC uses AC-7. algorithms suer high complexity AC propagation. demonstrated, use algorithm PW-AC propagationsignicantly enhance performance MAC crossword puzzle problems.Bacchus et al. (2002) presented extensive theoretical study DE HVE.Among results, polynomial bounds placed relative performance FCMAC two encodings non-binary representation, shownpolynomial bound exists. example, shown FC HVE (i.e. hFC0terminology use) never polynomial factor worse FC DE,FC DE exponentially worse FC HVE. Also, FC non-binaryrepresentation (i.e. nFC0 terminology use) exponentially worse FCHVE, vice versa. add results analyzing performance variousadvanced algorithms HVE double encoding.Smith modelled problem nding maximum density stable pattern still-lifeConways game Life using MAC double encoding remarkable success,compared constraint programming integer programming approaches (Smith,2002). MAC algorithm implemented using Table constraint ILOG Solver.constraint implements generic AC algorithm Bessiere & Regin (1996a),expensive used DE high time complexity. believeresults presented Smith improved MAC-PW-AC used instead.8. Conclusionpaper studied three binary translations non-binary CSPs; hidden variableencoding, dual encoding, double encoding. showed common perception standard algorithms binary CSPs used encodings non-binaryCSPs suers aws. Namely, standard algorithms exploit structure encodings, end inecient. address problem, proposed specialized arcconsistency search algorithms encodings, evaluated theoreticallyempirically. showed arc consistency enforced hidden variableencoding non-binary CSP worst-case time complexity generalized arcconsistency non-binary representation. showed structure constraintsdual encoding exploited achieve much lower time complexity680fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Resultsgeneric algorithm. Empirical results demonstrated use specialized algorithmmakes dual encoding signicantly ecient. showed generalized searchalgorithms non-binary CSPs relatively easily adjusted operate hiddenvariable encoding. also showed various algorithms double encodingdesigned. algorithms exploit properties double encoding (strong ltering branching original variables) achieve good results certain problems.Empirical results random structured problems showed that, certain classesnon-binary constraints, using binary encodings competitive option, many cases,better one solving non-binary representation.Acknowledgementswould like thank Panagiotis Karagiannis, Nikos Mamoulis, Toby Walshhelp various stages work. would also like thank anonymous reviewersearlier version paper useful comments suggestions.Appendixexplained, main dierence AC algorithm HVE corresponding GAC algorithm fact AC algorithm update domainsdual variables well original ones. incurs time overhead,show, deleting values dual variables help propagation discover domain wipe-outsarc inconsistent problems faster.Proposition 8.1 Let P non-binary CSP. Assume generalized arc consistency applied P , domain wipeout resulting problem. Enforcing arcconsistency hidden variable encoding P using HAC requires numberconsistency checks enforcing generalized arc consistency P using GAC-2001, assuming two algorithms follow ordering variables values lookingsupports propagating deletions.Proof: First, consider domain wipeout variable (original dual) occurstwo algorithms add constraints (dual variables) stack removerevision exactly order. Therefore, need showvalue deleted variable revision constraint nds new supportconstraint operations require number checksrepresentations. Assume non-binary version algorithm value deleteddomain variable xi support constraint c. |T |number allowed tuples c determining lack support require |T |currentSupportxi,a,c checks, one tuples c checked yet.value deleted nds new support , > currentSupportxi,a,c ,currentSupportxi,a,c checks performed. HVE, xi processedorder non-binary version require |T | currentSupportxi,a,vccurrentSupportxi,a,vc checks depending case. Obviously, currentSupportxi ,a,ccurrentSupportxi ,a,vc since tuple c corresponds value vc ,therefore, number checks performed representations. 2681fiSamaras & StergiouProposition 8.2 Let P non-binary CSP. Assume application generalizedarc consistency P results domain wipeout. Algorithm HAC applied hiddenvariable encoding P discovers domain wipeout numberconsistency checks algorithm GAC-2001 non-binary representation, assumingtwo algorithms follow ordering variables values looking supportspropagating deletions.Proof: CSP, arc inconsistency detected domain variable wipedapplying AC. HVE non-binary CSP, arc inconsistency detecteddomain original variable wiped (crucially) domain dualvariable wiped out. second possibility make AC algorithm operatesHVE ecient corresponding GAC algorithm. prove considerarc inconsistent non-binary problem. Assume domain original variable xiwiped processing constraint c encoded dual variable vcHVE. point function Revise called xi c arguments,inconsistency according Proposition 8.1 GAC algorithmAC algorithm HVE perform number consistency checks. Assumej values left D(xi ) call Revise. function Reviseunsuccessfully look support j values. |T | number allowedtuples c then, value D(xi ), require |T | currentSupportxi,a,c checksGAC algorithm |T | currentSupportxi ,a,vc checks AC algorithm. Since|T | currentSupportxi ,a,c = |T | currentSupportxi,a,vc , two algorithms performnumber consistency checks detect domain wipeout.following example demonstrates HAC may discover inconsistency lesschecks. Consider problem variables x1 , x2 , x3 , x4 domains {0, 1}, {0, 1},{0, . . . , 9}, {0, 1}, respectively. two constraints, c1 c2 , vars(c1 ) ={x1 , x2 , x3 } vars(c2 ) = {x1 , x2 , x4 } respectively. Value 0 x2 supported c1tuples include assignment (x1 , 1). Value 0 x1 supported c2 tuplesinclude assignment (x2 , 0). Constraint c2 allows tuples include assignment(x2 , 0). Values 0, . . . , 9 x3 supported c1 tuples include (x2 , 0) tuplesinclude (x2 , 1). assume variable x1 instantiated 0, meansdeletion 1 D(x1 ) must propagated. HVE, rst deletetuples include value (x1 , 1) dual variables vc1 vc2 . Then, add dualvariables vc1 vc2 stack, remove them, revise original variables connectedthem. Assuming vc1 removed rst, value 0 x2 support vc1deleted. result, delete tuples dual variable vc2 includepair (x2 , 0). means domain vc2 wiped out. non-binaryrepresentation, proceed similar way perform number checks0 deleted x2 . deletion algorithm look supports c1value 1 x2 values x3 . involve checks avoided HVE.inconsistency discovered later process constraint c2 ndvalue 1 x2 support c2 resulting domain wipeout x2 . 2682fiBinary Encodings Non-binary CSPs: Algorithms & Experimental ResultsReferencesBacchus, F., Chen, X., van Beek, P., & Walsh, T. (2002). Binary vs. Non-binary CSPs.Artificial Intelligence, 140, 137.Bacchus, F., & van Beek, P. (1998). Conversion Non-binary BinaryConstraint Satisfaction Problems. Proceedings AAAI98, pp. 310318.Bater, J. (2000). Non-binary (Higher-Order) Modelling Solution Techniques Frequency Assignment Mobile Communications Networks. Ph.D. thesis, UniversityLondon.Beacham, A., Chen, X., Sillito, J., & van Beek, P. (2001). Constraint programming lessonslearned crossword puzzles. Proceedings 14th Canadian ConferenceAI.Bessiere, C., Freuder, E., & Regin, J. (1995). Using Inference Reduce Arc ConsistencyComputation. Proceedings IJCAI95, pp. 592599.Bessiere, C., Meseguer, P., Freuder, E., & Larrosa, J. (2002). Forward CheckingNon-binary Constraint Satisfaction. Artificial Intelligence, 141, 205224.Bessiere, C., & Regin, J. (1996a). Arc Consistency General Constraint Networks: Preliminary Results. Proceedings IJCAI97, pp. 398404.Bessiere, C., & Regin, J. (1996b). MAC Combined Heuristics: Two Reasons ForsakeFC (and CBJ?) Hard Problems. Proceedings CP96, pp. 6175.Bessiere, C., & Regin, J. (2001). Rening Basic Constraint Propagation Algorithm.Proceedings IJCAI2001, pp. 309315.Cabon, B., De Givry, S., Lobjois, L., Schiex, T., & Warners, J. (1999). Radio Link FrequencyAssignment. Constraints, 4, 7989.CLib (2005). Conguration Benchmarks Library (http://www.itu.dk/doi/VeCoS/clib/),Maintained VeCoS group, IT-University Copenhagen.Debruyne, R., & Bessiere, C. (2001). Domain Filtering Consistencies. Journal ArtificialIntelligence Research, 14, 205230.Dechter, R., & Pearl, J. (1989). Tree Clustering Constraint Networks. Artificial Intelligence, 38, 353366.Ginsberg, M., Frank, M., Halpin, M., & Torrance, M. (1990). Search Lessons LearnedCrossword Puzzles. Proceedings AAAI-90, pp. 210215.Haralick, R., & Elliot, G. (1980). Increasing Tree Search Eciency Constraint Satisfaction Problems. Artificial Intelligence, 14, 263313.Hodge, L., Hurley, S., & Smith, D. (2002). Higher-Order Constraint TechniquesFrequency Assignment Problem. Tech. rep., University Cardi.Jeavons, P., Dunkin, N., & Bater, J. (1998). Higher Order Constraints NecessaryModel Frequency Assignment Problems. ECAI98 Workshop Non-binaryconstraints.Mackworth, A. (1977). Consistency Networks Relations. Artificial Intelligence, 99118.683fiSamaras & StergiouMamoulis, N., & Stergiou, K. (2001). Solving Non-Binary CSPs using Hidden VariableEncoding. Proceedings CP-2001, pp. 168182.Mohr, R., & Henderson, T. (1986). Arc Path Consistency Revisited. Artificial Intelligence, 28, 225233.Mohr, R., & Masini, G. (1988). Good Old Discrete Relaxation. Proceedings ECAI-88,pp. 651656.Peirce, C. (1933) Collected Papers Vol. III. Cited F. Rossi, C. Petrie, V. Dhar 1989.Prosser, P., Stergiou, K., & Walsh, T. (2000). Singleton Consistencies. ProceedingsCP-2000, pp. 353368.Regin, J. (1994). Filtering Algorithm Constraints Dierence CSPs. ProceedingsAAAI-94, pp. 362367.Rossi, F., Petrie, C., & Dhar, V. (1990). Equivalence Constraint SatisfactionProblems. Proceedings ECAI-90, pp. 550556.Smith, B. (2002). Dual Graph Translation Problem Life. ProceedingsCP-02, pp. 402414.Smith, B., Stergiou, K., & Walsh, T. (2000). Using Auxiliary Variables Implied Constraints Model Non-binary Problems. Proceedings AAAI2000, pp. 182187.Stergiou, K., & Walsh, T. (1999). Encodings Non-Binary Constraint Satisfaction Problems. Proceedings AAAI99, pp. 163168.Subbarayan, S., Jensen, R., Hadzic, T., Andersen, H., Hulgaard, H., & Moller, J. (2004).Comparing two Implementations Complete Backtrack-Free Interactive Congurator. Proceedings CP-04 Workshop CSP Techniques ImmediateApplication, pp. 97111.Van Hentenryck, P. (Ed.). (1989). Constraint Satisfaction Logic Programming. MITPress.Van Hentenryck, P., Deville, Y., & Teng, C. (1992). Generic Arc Consistency AlgorithmSpecializations. Artificial Intelligence, 57, 291321.Watkins, W., Hurley, S., & Smith, D. (1998). Area Coverage Frequency Assignment: Evaluation Models Area Coverage. Tech. rep., University Glamorgan. Also presentedINFORMS-98.Zhang, Y., & Yap, R. (2001). Making AC-3 Optimal Algorithm. ProceedingsIJCAI2001, pp. 316321.684fiJournal Artificial Intelligence Research 24 (2005) 157-194Submitted 09/04; published 07/05Learning Content Selection Rules Generating ObjectDescriptions DialoguePamela W. Jordanpjordan@pitt.eduLearning Research Development Center & Intelligent Systems ProgramUniversity Pittsburgh, LRDC Rm 744Pittsburgh, PA 15260Marilyn A. WalkerM.A.Walker@sheffield.ac.ukDepartment Computer Science, University SheffieldRegent Court, 211 Portobello StreetSheffield S1 4DP, U.K.Abstractfundamental requirement task-oriented dialogue system ability generate object descriptions refer objects task domain. subproblemcontent selection object descriptions task-oriented dialogue focusmuch previous work large number models proposed. paper,use annotated coconut corpus task-oriented design dialogues develop featuresets based Dale Reiters (1995) incremental model, Brennan Clarks (1996)conceptual pact model, Jordans (2000b) intentional influences model, usefeature sets machine learning experiment automatically learn model contentselection object descriptions. Since Dale Reiters model requires representationdiscourse structure, corpus annotations used derive representation basedGrosz Sidners (1986) theory intentional structure discourse, well twosimple representations discourse structure based purely recency. applyrule-induction program ripper train test content selection componentobject description generator set 393 object descriptions corpus.knowledge, first reported experiment trainable content selection componentobject description generation dialogue. Three separate content selection modelsbased three theoretical models, independently achieve accuracies significantlymajority class baseline (17%) unseen test data, intentional influences model (42.4%) performing significantly better either incremental model(30.4%) conceptual pact model (28.9%). best performing models combinefeature sets, achieving accuracies near 60%. Surprisingly, simple recency-basedrepresentation discourse structure well one based intentional structure.knowledge, also first empirical comparison representation GroszSidners model discourse structure simpler model generation task.1. Introductionfundamental requirement task-oriented dialogue system ability generateobject descriptions refer objects task domain. example, considerexcerpt task-oriented dialogue coconut corpus Figure 1 (Di Eugenio,Jordan, Thomason, & Moore, 2000). conversants dialogue attemptingc2005AI Access Foundation. rights reserved.fiJordan & Walker(Partial solution problem already agreed upon prior dialogue: 3 green chairs 50, 1 greenchair 100 green table dining room, blue sofa living room. numbersbrackets indicate utterance breaks analysis dialogue.)G: [36] leaves us 250 dollars. [37] yellow rug 150 dollars. [38]furniture left matches 100 dollars?S: [39] No, furniture left costs $100. [40] guess buy yellow rug $150.G: [41] Okay. [42] Ill buy rug 150 dollars. [43] green chair [44] buy100 dollars [45] leave us money.S: [46] sounds good. [47] Go ahead buy yellow rug green chair.G: [48] Ill buy green 100 dollar chair. [49] Design Complete?S: [50] Sounds good, [51] want green chair dining room chairs? [52]put yellow rug living room. [53] design complete.G: [54] Sounds good. [55] Hit design completeFigure 1: Excerpt coconut dialogue illustrating variable selection attributesobject descriptions refer furniture itemscollaboratively construct solution furnishing two room house. conversant startstask separate set furniture items used solution. processnegotiating solution, generate object descriptions (shown italics) itemsfurniture.furniture type coconut task domain four associated attributes: color,price, owner quantity. first step, object description generator must decidefour attributes include utterance, subsequent surface generation stepsdecide utterance attributes expressed. example, task domainobjects discussion dialogue Figure 1 $150 yellow rug owned Garrett(G) $100 dollar green chair owned Steve (S). dialogue excerpt Figure1, yellow rug first referenced utterance 36 yellow rug 150 dollarssubsequently yellow rug 150 dollars, rug 150 dollars, yellow rug,owner attribute sometimes realized separate noun phrase withinutterance. could also described following: rug, rug,yellow rug, $150 yellow rug, $150 rug. content object descriptionsvaries depending attributes included. speaker decideattributes include?problem content selection subsequent reference focus muchprevious work large number overlapping models proposed seekexplain different aspects referring expression content selection (Clark & Wilkes-Gibbs,1986; Brennan & Clark, 1996; Dale & Reiter, 1995; Passonneau, 1995; Jordan, 2000b) interalia. factors models use include discourse structure, attributesattribute values used previous mention, recency last mention, frequencymention, task structure, inferential complexity task, ways determiningsalient objects salient attributes object. paper, use set factorsconsidered important three models, empirically compare utility158fiLearning Content Selection Rules Generating Object Descriptionsfactors predictors machine learning experiment order first establish whetherselected factors, represent them, make effective contributions larger taskcontent selection initial well subsequent reference. factor sets utilize are:contrast set factors, inspired incremental model Dale Reiter(1995);conceptual pact factors, inspired models Clark colleagues (Clark &Wilkes-Gibbs, 1986; Brennan & Clark, 1996);intentional influences factors, inspired model Jordan (2000b).develop features representing factors, use features represent examples object descriptions context occur purpose learningmodel content selection object descriptions.Dale Reiters incremental model focuses production near-minimal subsequent references allow hearer reliably distinguish task object similartask objects. Following Grosz Sidner (1986), Dale Reiters algorithm utilizes discourse structure important factor determining objects current objectmust distinguished from. model Clark, Brennan Wilkes-Gibbs basednotion conceptual pact, i.e. conversants attempt coordinate oneanother establishing conceptual pact describing object. Jordans intentionalinfluences model based assumption underlying communicativetask-related inferences important factors accounting non-minimal descriptions.describe models detail Section 3 explain expectmodels work well combination.Many aspects underlying content selection models well-definedimplementation point view, may necessary experiment different definitionsrelated parameter settings determine produce best performancemodel, done parameter setting experiments carried Jordan (2000b).1However, experiments describe paper, strive feature representationsallow machine learner take task finding optimal settingsotherwise use results reported Jordan (2000b) guidance. variationtest representation discourse structure models require it.Otherwise, explicit tests different interpretations models left future work.report set experiments designed establish predictive power factors emphasized three models using machine learning train test contentselection component object description generator set 393 object descriptionscorpus coconut dialogues. generator goes beyond modelsaccounts anaphoric expressions address general problem generatinginitial subsequent expressions. provide machine learner distinct setsfeatures motivated models, addition discourse features motivated assumed1. Determining optimal parameter settings machine learning algorithm similar issue (Daelemans& Hoste, 2002) different level. use machine learner parameter settingsexperiments although searching optimal machine learner parameter settings may valueimproving performance.159fiJordan & Walkerfamiliarity distinctions (Prince, 1981) (i.e. new vs. evoked vs. inferable discourse entities),dialogue specific features speaker object description, absolutelocation discourse, problem conversants currently tryingsolve. evaluate object description generator comparing predictionshumans said point dialogue counting correctexactly match content human generated object descriptions (Oberlander, 1998).2provides rigorous test object description generator since likelihoodobject descriptions would achieved speakers communicative goals.also quantify contribution feature set performance objectdescription generator. results indicate intentional influences features,incremental features conceptual pact features independently significantly better majority class baseline task, intentional influences model (42.4%) performing significantly better either incremental model(30.4%) conceptual pact model (28.9%). However, best performing modelscombine features models, achieving accuracies matching human performancenear 60.0%, large improvement majority class baseline 17% generator simply guesses frequent attribute combination. Surprisingly, resultsexperimenting different discourse structure parameter settings show featuresderived simple recency-based model discourse structure contribute muchparticular task one based intentional structure.coconut dataset small compared used machine learning experiments. Smaller datasets run higher risk overfitting thus specific performanceresults interpreted caution. addition coconut corpus representsone type dialogue; typed, collaborative, problem solving dialogues constraint satisfaction problems. models suggested features focus general communicativeissues, expect variations task involved communication setting impact predictive power feature sets. example, conceptual pact modeldeveloped using dialogues focus identifying novel, abstract figures.figures abstract clear start series exercises descriptionbest help dialogue partner identify target figure. Thus need negotiatedescription figures prominent tasks. Likewise expectconstraint satisfaction problems need joint agreement solution causeintentional influences model prominent coconut dialogues.fact conceptual pact features show predictive power significantlybetter baseline suggests prominence model inspired featureset may vary across tasks communication settings, expect significantcontribution make content selection model.Clearly, us whose ultimate goal general model content selectiondialogue, need carry experiments wide range dialogue types.us whose ultimate goal dialogue application, one smaller corpusrepresentative anticipated dialogues probably preferable. Despite two notes2. Note attributes discourse entity has, harder achieve exact matchhuman description, i.e. problem object description generator must correctly choose among16 possibilities represented power set four attributes.160fiLearning Content Selection Rules Generating Object Descriptionscaution expect feature representations suggest starting point largerendeavors.Previous research applied machine learning several problems natural languagegeneration, cue word selection (Di Eugenio, Moore, & Paolucci, 1997), accent placement (Hirschberg, 1993), determining form object description (Poesio, 2000),content ordering (Malouf, 2000; Mellish, Knott, Oberlander, & ODonnell, 1998; Duboue& McKeown, 2001; Ratnaparkhi, 2002), sentence planning (Walker, Rambow, & Rogati,2002), re-use textual descriptions automatic summarization (Radev, 1998), surface realization (Langkilde & Knight, 1998; Bangalore & Rambow, 2000; Varges & Mellish,2001).machine learning approaches content selection OhRudnicky (2002) Roy (2002). Oh Rudnicky report results automaticallytraining module CMU Communicator system selects attributessystem express implicitly confirming flight information ongoing dialogue.example, caller said want go Denver Sunday, implicit confirmationsystem might Flying Denver Sunday. experimentally comparedstatistical approach based bigram models strategy confirms informationsystem heard first time, found two systems performedequally well. Roy reports results spoken language generator trained generatevisual descriptions geometric objects provided features visual scenes. Roysresults show understandability automatically generated descriptions8.5% lower human-generated descriptions. Unlike approach, neither consider effects ongoing dialogue dialogue partner, effect dialoguecontext generated descriptions. work, theoretical models basedon, explicitly focus processes involved generating descriptions redescriptionsobjects interactive dialogue allow dialogue partners remain aligneddialogue progresses (Pickering & Garrod, 2004).relevant prior work Jordan (2000b). Jordan implemented DaleReiters incremental model developed implemented intentional influences model, incorporates incremental model, testedcoconut corpus. Jordan also experimented different parameter settings vagueparts models. results work directly comparable Jordantested rules subsequent reference, attempt learn rules generating initial subsequent references. However, using purely rule-based approach,best accuracy Jordan reported 69.6% using non-stringent scoring criterion(not exact match) 24.7% using stringent exact match scoring used here.paper, using features derived Jordans corpus annotations, applying ruleinduction induce rules training data, achieve exact match accuracy nearly47% comparing similar model accuracy nearly 60% comparing best overall model. results appear improvementreported Jordan (2000b), given increased accuracy ability generateinitial well subsequent references.Section 2 describes coconut corpus, definitions discourse entities objectdescriptions coconut domain, annotations corpus usederive feature sets. Section 3 presents theoretical models content selection161fiJordan & WalkerOpal 1INVENTORY10111200TABLE-HIGH YELLOW $400SOFA GREEN $350SOFA YELLOW $400RUG RED $200LAMP-FLOOR BLUE $50CHAIR BLUE $75CHAIR GREEN $100CHAIR RED $100End TurnDesign CompletePARTNERS INVENTORYTABLE-LOWTABLE-HIGHRUGSOFALAMP-TABLELAMP-FLOORCHAIRARMCHAIRDESK> change chairs,two red ones price.much like greenlooks ugly red.LIVING-ROOM> bought green sofa 350,green table 400,2 green chairs 100 each.DINING-ROOM100400350100100100400budget is: $400Figure 2: snapshot interface coconut taskobject descriptions detail describes features inspired models.Section 4 describes experimental design Section 5 presents quantitative resultstesting learned rules corpus, discusses features machinelearner identifies important, provides examples rules learned. Section6 summarizes results discusses future work.2. Coconut Corpuscoconut corpus set 24 computer-mediated dialogues consisting total1102 utterances. dialogues collected experiment two human subjectscollaborated simple design task, buying furniture two rooms house(Di Eugenio et al., 2000). collaboration carried typed dialogueworkspace action utterance automatically logged. excerptcoconut dialogue Figure 1. snapshot workspace coconutexperiments Figure 2.experimental dialogues, participants main goal negotiate purchases;items highest priority sofa living room table four chairsdining room. participants also specific secondary goals constrainproblem solving task. Participants instructed try meet manygoals possible, motivated rewards associated satisfied goals.162fiLearning Content Selection Rules Generating Object Descriptionssecondary goals are: 1) match colors within room, 2) buy much furniturecan, 3) spend money. participants told rewards associatedachieving goal.participant given separate budget (as shown mid-bottom sectionFigure 2) inventory furniture (as shown upper-left section Figure 2).Furniture types include sofas, chairs, rugs lamps, possible colors red, green,yellow blue. Neither participant knows others inventory muchmoney has. sharing information conversation, combinebudgets select furniture others inventories. Note since participantknow furniture partner available told, menu (seemid-right section Figure 2) allows participant create furniture items basedpartners description items available. participants equals purchasingdecisions joint. experiment, set participants solved one three scenariosvarying inventories budgets. problem scenarios varied task complexityranging tasks items inexpensive budget relatively large, tasksitems expensive budget relatively small.2.1 Discourse Entities Object Descriptions Corpusdiscourse model used keep track objects discussed discourse. objectdescribed, conversants relate information object utteranceappropriate mental representation object discourse model (Karttunen, 1976;Webber, 1978; Heim, 1983; Kamp & Reyle, 1993; Passonneau, 1996). model containsdiscourse entities, attributes links entities (Prince, 1981). discourse entityvariable placeholder indexes information object describedparticular linguistic description appropriate mental representation object.discourse model changes discourse progresses. object first described,discourse entity ei added discourse model. new utterances produced,additional discourse entities may added model new objects described,new attributes may get associated ei whenever redescribed. Attributesalways supplied noun phrase (NP). may arise parts utterancediscourse inference relations link discourse entities.illustrate discourse inference relations relevant coconut, (1b) green setexample new discourse entity set/subset discourse inference relationthree distinct discourse entities 2 $25 green chairs, 2 $100 green chairs 1$200 green table.(1) a. : [2 $25 green chairs] [a $200 green table].b. : [2 $100 green chairs]. Lets get [the green set].class inference relation exists referent discourse entity subsumptionrelationship previous discourse entity. example, (2) table greenone subsumption relationship.(2)Lets decide [the table] dining room. [your green one]?163fiJordan & Walkercommon noun anaphora inference relation occurs cases one anaphoranull anaphora. example, (3) marked NPs last part utterancenull anaphora relation marked NP first part. Note examplealso class inference relation well.(3)[a variety high tables] ,[green], [red] [yellow] 400, 300, 200.Discourse entities also related predicative relationships is. example, (4) entities defined cheapest table blue one $200discourse entities information one provides informationother. Note example also includes common noun anaphora class inferencerelations.(4)[My cheapest table] [a blue one $200].object description linguistic expression (usually NP) initiates creation update discourse entity furniture item, along explicit attributesexpressed within utterance. consider attributes explicitly expressedoutside NP part object description since realized eitherpart noun phrase triggers discourse entity elsewhere utterance.Attributes inferred (e.g. quantity the) help populate discourseentity considered part object description since inferred attributes maymay reflect explicit choice. inferred attribute could side-effectsurface structure selected realizing object description.32.2 Corpus Annotationscorpus collected, annotated human coders three typesfeatures: problem-solving utterance level features shown Figure 3, discourseutterance level features illustrated Figure 4 discourse entity level features illustrated Figure 5. additional features shown Figure 6.feature encodings shown dialogue excerpt Figure 1.features hand-labelled corpus human-human corpusbut, discuss end section, many features would needestablished system collaborative problem solving component functionproperly.Looking first Figure 6, explicit attributes (as described previoussection) predicted models building testing. remainingfeatures available context making predictions.problem-solving utterance level features Figure 3 capture problemsolving state terms goals actions discussed conversants,constraint changes implicitly assumed, explicitly stated conversants,size solution set current constraint equations. solution set size3. true attributes explicitly expressed (e.g. subject positionexpresses ownership attribute), attribute types interest corpus adjuncts(e.g. Lets buy chair [for $100].).164fiLearning Content Selection Rules Generating Object DescriptionsUtterance373839404243444647485152Goal/ActionLabelSelectOptionalItemLRSelectOptionalItemSelectOptionalItemSelectOptionalItemLRSelectOptionalItemLRSelectOptionalItemDRSelectOptionalItemDRSelectOptionalItemDRSelectOptionalItemDRSelectOptionalItemLRSelectOptionalItemDRSelectOptionalItemDR,SelectChairsSelectOptionalItemLRIntroducecontinueintroduceintroducecontinuecontinuecontinuecontinuecontinuecontinuecontinuecontinuecontinuecontinueintroducecontinueGoal/ActionIdentifieract4act5act5act4act4act5act5act5act4act5act5act5,act3act4ChangeConstraintsdrop color matchcolor,price limitnonenonenonenonenonenonenoneSolutionSizenonenonedeterminatedeterminatenonedeterminateindeterminateindeterminateindeterminatedeterminatedeterminateindeterminatedeterminatedeterminatedeterminateFigure 3: Problem solving utterance level annotations utterances relevant problemsolving goals actions dialogue excerpt Figure 1UtteranceInfluenceListenerInfluenceSpeaker3740424344464748495152ActionDirectiveActionDirectiveActionDirectiveOpenOptionActionDirectiveActionDirectiveActionDirectiveActionDirectiveActionDirectiveActionDirectiveActionDirectiveOfferCommitCommitnilOfferCommitCommitCommitOfferOfferCommitFigure 4: Discourse utterance level annotations utterances relevant establishing jointagreements dialogue excerpt Figure 1constraint equation characterized determinate set values closedrepresents conversants shared relevant values one another.indeterminate size means set values still open solution cannot yetdetermined. problem-solving features capture situational problemsolving influences may effect descriptions indicate task structurediscourse structure derived (Terken, 1985; Grosz & Sidner, 1986). domain165fiJordan & WalkerUtterance37383940424344474748515152ReferenceCoreferenceinitial ref-1initial ref-2initial ref-3corefers ref-1corefers ref-1initial ref-4corefers ref-4corefers ref-1corefers ref-4corefers ref-4corefers ref-4initial ref-5corefers ref-1DiscourseInferenceRelationsnilnilclass ref-20nilnilnilCNAnaphora ref-4nilnilnilnilset ref-12,ref-16AttributeValuesmy,1,yellow,rug,150your,furniture,100my,furniture,100your,1,yellow,rug,150my,1,rug,150my,1,green,chairmy,100your,1,yellow,rugyour,1,green,chairmy,1,green,chair,1001,green,chairchair1,yellow rugArgumentGoal/ActionIdentifieract4act5act5act4act4act5act5act4act5act5act5act3act4Figure 5: Discourse entity level annotations utterances referring furniture itemsFigure 1UtteranceSpeaker37383940424344474748515152GGGGGGExplicitAttributestype,color,price,ownertype,color,price,ownertype,price,ownertype,color,price,ownertype,price,ownertype,color,ownerprice,ownertype,colortype,colortype,color,price,ownertype,colortypetype,colorInferredAttributesquantityquantityquantityquantityowner,quantityowner,quantityquantityquantityquantityquantityDescriptionyellow rug 150 dollarsfurniture ... 100 dollarsfurniture ... 100 dollarsyellow rug $150rug 150 dollarsgreen chair[0] 100 dollarsyellow ruggreen chairgreen 100 dollar chairgreen chairchairsyellow rugFigure 6: Additional features dialogue excerpt Figure 1goal provides discourse segment purpose utterance relates differentdomain goal set domain goals defines new segment.discourse utterance level features Figure 4 encode influence utterance expected speaker listener defined DAMSLscheme (Allen & Core, 1997). annotations also help capture situationalinfluences may effect descriptions. possible influences listeners include openoptions, action directives information requests. possible influences speakersoffers commitments. Open options options speaker presents hearersfuture actions, whereas action directive speaker trying put hearer166fiLearning Content Selection Rules Generating Object Descriptionsobligation act. intent put hearer obligation actopen option speaker may given hearer enough informationact speaker may clearly indicated endorse action. Offerscommitments needed arrive joint commitment proposed action.offer speaker conditionally committing action whereas commitspeaker unconditionally committing. commit, hearer may alreadyconditionally committed action discussion, speaker may carehearer also committed action intends do.discourse entity level features Figure 5 define discourse entitiesdiscourse model. Discourse entities, links earlier discourse entitiesattributes expressed previously discourse entity NP-level utterance levelinputs object description generator. Part used define discourseentities discourse reference relations include initial, coreference discourse inference relations different entities links described earlier; set/subset,class, common noun anaphora predicative. addition, order link expressionappropriate problem solving actions, action entity argumentalso annotated. order test whether acceptable object description generatedmodel discourse entity context, explicit attributes used describe entityalso annotated (recall Figure 6).action entity related helps associate entities correct partsdiscourse structure helps determine problem-solving situations relevantparticular entity. discourse entity level annotations, initial representations discourse entities updates derived. example, initialrepresentation yellow rug. costs $150. would include type, quantity, colorowner following first utterance. quantity attribute inferred.second utterance entity would updated include price.encoded features good inter-coder reliability shown kappa valuesgiven Table 1 (Di Eugenio et al., 2000; Jordan, 2000b; Krippendorf, 1980). valuesstatistically significant size labelled data set, shown p-valuestable.DiscourseEntityLevelProblemSolvingUtteranceLevelDiscourseUtteranceLevelReferenceCoreference.863(z=19, p<.01)IntroduceGoal/Action.897(z=8, p<.01)InfluenceListener.72(z=19, p<.01)DiscourseInferenceRelations.819(z=14, p<.01)ContinueGoal/Action.857(z=27, p<.01)InfluenceSpeaker.72(z=13, p<.01)ArgumentGoal/Action.857(z=16, p<.01)ChangeConstraints.881(z=11, p<.01)Attributes.861(z=53, p<.01)SolutionSize.8(z=6, p<.01)Table 1: Kappa values annotation scheme167Goal/Action.74(z=12, p<.01)fiJordan & Walkeravailability annotated information dialogue systemcurrently ongoing challenge todays systems, system successfuldialogue partner collaborative problem solving dialogue, optionsknown priori, model update discourse entities, understand currentproblem solving state agreed upon, able make, accept rejectproposed solutions. Certainly, dialogue system domains communicative settingsneed information likewise information essentialdomains settings necessary engage coconut dialogue.experimental data consists 393 non-pronominal object descriptions 13 dialogues coconut corpus well features constructed annotations describedabove. next section explains detail annotations used constructfeatures used training models.3. Representing Models Content Selection Object DescriptionsFeaturesSection 1, described would use annotations coconut corpusconstruct feature sets motivated theories content selection object descriptions.describe theories detail, present, theory, featuresets inspired theory. Section 4 explain features usedautomatically learn model content selection object descriptions. order usedway, features must represented continuous (numeric), set-valued,symbolic (categorial) values.Models content selection object descriptions attempt explain motivatesspeaker use particular set attributes describe object, first mentionobject well subsequent mentions. extended discourse, speakers oftenredescribe objects introduced earlier order say somethingobject event participates. test part assumption manyfactors relevant redescriptions also relevant initial descriptions.models described previously rule-based implementationstested coconut corpus found nearly equally good explaining redescriptions corpus (Jordan, 2000b). share basic assumptionspeakers goal redescribing discourse entity already introduceddiscourse model prior conversation. speakers primary goal identification, i.e.generate linguistic expression efficiently effectively re-evoke appropriatediscourse entity hearers mind. redescription must adequate re-evokingentity unambiguously, must efficient way (Dale & Reiter, 1995). Onefactor major effect adequacy redescription fact discourseentity described must distinguished discourse entities discoursemodel currently salient. discourse entities called distractors. Characteristics discourse entities evoked dialogue recency frequencymention, relationship task goals, position relative structurediscourse hypothesized means determining entities mutually salientconversants.168fiLearning Content Selection Rules Generating Object Descriptionsmutually known: type-mk, color-mk, owner-mk, price-mk, quantity-mkreference-relation: one initial, coref, set, class, cnanaphora, predicativeFigure 7: Assumed Familiarity Feature Set.begin encoding features object description generator featuresrepresenting fundamental aspects discourse entity discourse model. dividefeatures two sets: assumed familiarity feature set inherentfeature set. assumed familiarity features Figure 7 encode informationdiscourse entity already represented discourse model pointdiscourse entity described. attributes assumedmutually known conversational participants represented five booleanfeatures: type-mk, color-mk, owner-mk, price-mk, quantity-mk. example, type-mkvalue yes, represents type attribute entity describedmutually known.Figure 7 also enumerates reference-relation feature described Section 2 encodewhether entity new (initial), evoked (coref) inferred relative discoursecontext. types inferences supported annotation set/subset, class, commonnoun anaphora (e.g. one null anaphora), predicative (Jordan, 2000b),represented values (set,class,cnanaphora,predicative). reference relations relevant initial subsequent descriptions.utterance-number, speaker-pair, speaker, problem-numberattribute values:type: one sofa, chair, table, rug, lamp, superordinatecolor: one red, blue, green, yellowowner: one self, other,price: range $50 $600quantity: range 0 4.Figure 8: Inherent Feature Set: Task, Speaker Discourse Entity Specific features.inherent features Figure 8 specific encoding particularsdiscourse situation, speaker, task, actual values entitys knownattributes (type, color, owner, price, quantity). supply values attributescase preferences associated particular values. example, maypreference include quantity, describing set chairs, price, high.inherent features allow us examine whether individual differencesselection models (speaker, speaker-pair), whether specifics attributes169fiJordan & Walkerobject, location within dialogue (utterance-number), problem difficulty(problem-number) play significant roles selecting attributes. attribute valuesentity derived annotated attribute features reference relations.dont expect rules involving feature set generalize well dialoguesituations. Instead expect lead situation specific model. Wheneverfeatures used overfitting regardless training set size. Considerparticular speaker, speaker-pair utterance number specific particular dialoguesunlikely occur another dialogue, even new coconut dialogue. featurerepresentations would abstracted value generator.3.1 Dale Reiters Incremental Modelcomputational work generating object descriptions subsequent reference (Appelt, 1985a; Kronfeld, 1986; Reiter, 1990; Dale, 1992; Heeman & Hirst, 1995; Lochbaum,1995; Passonneau, 1996; van Deemter, 2002; Gardent, 2002; Krahmer, van Erk, & Verleg,2003) concentrates produce minimally complex expression singlesdiscourse entity set distractors. set contextually salient distractorsidentified via model discourse structure mentioned above. Dale Reiters incremental model basis much current work relies discourse structuredetermine content object descriptions subsequent reference.commonly used account discourse structure task-oriented dialoguesGrosz Sidners (1986) theory attentional intentional structure discourse.theory, data structure called focus space keeps track discourse entitiessalient particular context, stack focus spaces used store focusspaces discourse whole. content focus space operationsstack focus spaces determined structure task. change task topicindicates start new discourse segment corresponding focus space.discourse entities described discourse segment classified salient dialogueparticipants corresponding focus space focus stack. Approaches usenotion discourse structure take advantage representation produce descriptorsminimally complex given current focus space, i.e. descriptionunambiguous respect global discourse.According Dale Reiters model, descriptor containing informationneeded identify referent given current focus space would minimally complexsmall number overspecifications appear relative identification goalexpected explained artifacts cognitive processing limits. Trying produceminimally complex description seen implementation two partsGrices Maxim Quantity, according utterance say muchrequired, required (Grice, 1975). Given entity describedistractor set defined entities current focus space, incremental modelincrementally builds description checking static ordering attribute typesselecting attribute include description eliminatesremaining distractors. distractors ruled out, longer influence selectionprocess.170fiLearning Content Selection Rules Generating Object DescriptionsDistractor Frequencies: type-distractors, color-distractors, owner-distractors, price-distractors, quantity-distractorsAttribute Saliency: majority-type, majority-type-freq, majority-color, majority-color-freq,majority-price, majority-price-freq, majority-owner, majority-owner-freq, majority-quantity,majority-quantity-freqFigure 9: contrast set Feature Setsset features called contrast set features used represent aspects DaleReiters model. See Figure 9. goal encoding represent whetherdistractors present focus space might motivate inclusion particularattribute. First, distractor frequencies encode many distractors attributevalue different entity described.incremental model also utilizes preferred salience ordering attributeseliminates distractors attributes added description. example, addingattribute type object chair, eliminates distractors arent chairs.feature based encoding cannot easily represent distractor set changes attributechoices made. compensate, encoding treats attributes instead objectsdistractors attribute saliency features encode attribute valuessalient attribute type, count number distractors attributevalue. example, 5 8 distractors red majority-color red majoritycolor-freq 5. Taking view attributes distractors advantagepreferred ordering attributes adjust according focus space. interpretationDale Reiters model shown statistically similar strict modelhigher mean match corpus (Jordan, 2000b). Thus goal addingadditional features try obtain best possible performance incrementalmodel.Finally, open issue deriving distractors define focus space (Walker,1996a). described above, Grosz Sidners theory discourse creates data structurecalled focus space discourse segment, discourse segments basedintentions underlying dialogue. However Grosz Sidner provide clear criterionassigning segmentation structure. order explore definition variationswork best, experiment three focus space definitions, two simple focus spacedefinitions based recency, based intentional structure describedbelow. train test three focus space definitions, create separate datasetsthree. knowledge, first empirical comparison GroszSidners model simpler model discourse-related task.intentional structure, utilize problem solving utterance features hand-labelledcoconut corpus high reliability discussed Section 2. annotatedtask goals used derive intentional structure discourse, providessegmentation discourse, described Grosz Sidner (1986). current focusspace defined annotated task goals used define segment distractors.dataset label segment. recency, one extremely simple focus space definition171fiJordan & Walkeruses discourse entities recent utterance possible distractors.dataset label one utterance. second extremely simple focus space definitionconsiders discourse entities last five utterances possible distractors.dataset label five utterance. dataset, features Figure 9computed relative distractors determined focus space definition.3.2 Jordans Intentional Influences ModelJordan (2000b) proposed model select attributes object descriptions subsequent reference called intentional influences model. model posits alongidentification goal, task-related inferences agreement process task negotiation important factors selecting attributes. Attributes necessaryidentification purposes may intentional redundancies communicative purpose(Walker, 1996b) always due cognitive processing limits finding minimallycomplex descriptions (Jordan, 2000b).goal-directed view sentence generation suggests speakers attempt satisfymultiple goals utterance (Appelt, 1985b). suggests strategy alsoapplies lower-level forms within utterance (Stone & Webber, 1998). is,form opportunistically contribute satisfaction multiple goals. many-onemapping goals linguistic forms generally referred overloading intentions(Pollack, 1991). Subsequent work shown overloading involve trade-offsacross linguistic levels. is, intention achieved complicating formone level may allow speaker simplify another level omitting important information.example, choice clausal connectives pragmatic level simplify syntacticlevel (Di Eugenio & Webber, 1996), trade-offs word choice syntaxsemantics levels (Stone & Webber, 1998).intentional influences model incorporates multiple communicative problem solving goals addition main identification goal speaker intendshearer re-evoke particular discourse entity. contribution modeloverloads multiple, general communicative problem solving goals generating description. model tested coconut corpus, inferences changesproblem solving constraints, conditional unconditional commitments proposals, closing goals shown relevant influences attributeselection (Jordan, 2000a, 2002) goals verify understanding infer informationalrelations (Jordan, 2000b).4features used approximate Jordans model Figure 10. features covergeneral communicative problem solving goals hypothesized modelexcept identification goal information relation goal. difficultymodelling information relation goal features, representation left futurework.54. different subset general goals covered model expected influentialdomains communication settings, therefore general object description generator would needtrained wide range corpora.5. Information relation goals may relate two arbitrarily distant utterances additional details beyonddistance expected important. goal previously appear relevantcoconut corpus (Jordan, 2000b), gave low priority implementation.172fiLearning Content Selection Rules Generating Object Descriptionstask situation: goal, colormatch, colormatch-constraintpresence, pricelimit, pricelimit-constraintpresence, priceevaluator, priceevaluator-constraintpresence, colorlimit, colorlimit-constraintpresence, priceupperlimit, priceupperlimit-constraintpresenceagreement state: influence-on-listener, commit-speaker, solution-size, prev-influence-on-listener, prev-commit-speaker, prev-solution-size, distance-of-last-state-in-utterances, distanceof-last-state-in-turns, ref-made-in-prev-action-state, speaker-of-last-state, prev-ref-stateprevious agreement state description: prev-state-type-expressed, prev-state-color-expressed,prev-state-owner-expressed, prev-state-price-expressed, prev-state-quantity-expressedsolution interactions: color-contrast, price-contrastFigure 10: Intentional Influences Feature Set.task situation features encode inferable changes task situation relateditem attributes, colormatch boolean feature indicates whetherchange color match constraint. pricelimit, colorlimit priceupperlimitfeatures also boolean features representing constraint changerelated setting limits values price color attributes. featuresconstraintpresence appended constraint feature name symbolic features indicatewhether constraint change implicit explicit. example, agreedupon constraint try select items color value room, speakerwants relax constraint feature colormatch would value yes.speaker communicated explicitly saying Lets forget trying match colors.constraintpresence feature would value explicit otherwise wouldvalue implicit. constraint change explicitly communicated speakerdecides include color attribute necessary identification purposes,may help hearer infer means drop constraintagreement state features Figure 10 encode critical points agreementproblem solving. Critical agreement states (Di Eugenio et al., 2000):propose: speaker offers entity conditional commitment resultsdeterminate solution size.partner decidable option: speaker offers entity conditional commitment results indeterminate solution size.unconditional commit: speaker commits entity.unendorsed option: speaker offers entity show commitmentusing solution size already determinate.example, dialogue participant unconditionally committing responseproposal, may want verify item entity description partner repeating back previous description. featuresencode critical agreement states include DAMSL features (influence-on-listener,173fiJordan & Walkercommit-speaker, prev-influence-on-listener, prev-commit-speaker), progress toward solution (solution-size, prev-solution-size, ref-made-in-prev-action-state), features inherentagreement state (speaker-of-last-state, distance-of-last-state-in-utterances, distanceof-last-state-in-turns). features make reference state derivedagreement state features extensive discourse history encoded withinfeature representation. addition, since current agreement state depends partprevious agreement state, added derived agreement state. previousagreement state description features Figure 10 booleans capture dependenciesmodel content description previous state. example,previous agreement state entity expressed type color attributeswould encoded yes prev-state-type-expressed prev-state-color-expressedrest.solution interactions features Figure 10 represent situations multiple proposals consideration may contrast one another terms solvingcolor-matching goals (color-contrast) price related goals (price-contrast).boolean feature color-contrast true, means entitys color matchespartial solution already agreed upon contrasts alternativesproposed. situation, may grounds endorsing entity relative alternatives. example, response Ss utterance [37] Figure 1,context G earlier introduced one blue rug $175, G could said Lets useblue rug. response. case blue rug would true value color-contrastdifferent color alternative, matches blue sofaalready selected.boolean feature price-contrast describes two different situations. featureprice-contrast true, either means entity best price relativealternatives, problem nearly complete, entity expensivealternatives. first case, grounds endorsement itemcheaper. second case, may item spend remaining budgetresult higher score problem solution.Note although solution interaction features depend upon agreement states,necessary recognize proposals commitments order identify alternatives track agreed upon solutions, difficult encode extensive historicalinformation directly feature representation. Therefore solution interaction featuresderived, derivation includes heuristics use agreement state featuresestimating partial solutions. sample encoding dialogue excerpt Figure 1problem solving utterance level annotations agreement states given Figures 34.3.3 Brennan Clarks Conceptual Pact ModelBrennan Clarks conceptual pact model focuses bidirectional adaptationconversational partner linguistic choices conversational participant.conceptual pact model suggests dialogue participants negotiate descriptionfind adequate describing object (Clark & Wilkes-Gibbs, 1986; Brennan& Clark, 1996). speaker generates trial descriptions hearer modifies based174fiLearning Content Selection Rules Generating Object Descriptionsobject thinks suppose identify. negotiation continuesparticipants confident hearer correctly identified intended object.Brennan Clark (1996) point lexical availability, perceptual saliencetendency people reuse terms describing objectconversation, significantly shape descriptions people generate. factorsmay override informativeness constraints imposed Grices Quantity Maxim.Lexical availability depends object best conceptualized label associatedconceptualization (e.g. referent item furniture sofa).perceptual salience, speakers may include highly salient attribute ratherattributes distinguish distractors, e.g. $50 red sofa $50sofa may informative enough. Adaptation ones conversational partner leadtendency reuse previous description.tendency reuse description derives combination recent,successfully understood description object, often descriptionused particular conversation. However, tendency moderated needadapt description changing problem-solving circumstances make repeateddescriptions even efficient precedents become established particularpairing conversational partners. Recency frequency effects reuse reflectionscoordination process conversational partners negotiatingshared way labelling conceptualizing referent. Different descriptions may triedparticipants agree conceptualization. change problem situation maycause conceptualization embellished additional attributes may instigatenegotiation new conceptualization referent.additional features suggested model include previous description sincecandidate conceptual pact, long ago description made,frequently referenced. description used back dialoguereferenced frequently, could indicate negotiation process completed.Furthermore, model suggests that, pact reached, dialogueparticipants continue use description previously negotiated unlessproblem situation changes. continued usage aspect model also similarPassonneaus lexical focus model (Passonneau, 1995).interactions discourse entities: distance-last-ref, distance-last-ref-in-turns, numberprev-mentions, speaker-of-last-ref, distance-last-relatedprevious description: color-in-last-exp, type-in-last-exp, owner-in-last-exp, price-in-last-exp,quantity-in-last-exp, type-in-last-turn, color-in-last-turn, owner-in-last-turn, price-in-lastturn, quantity-in-last-turn, initial-in-last-turnfrequency attributes: freq-type-expressed, freq-color-expressed, freq-price-expressed, freqowner-expressed, freq-quantity-expressedstability history: cp-given-last-2, cp-given-last-3Figure 11: conceptual pact Feature Set.175fiJordan & Walkerconceptual pact features Figure 11 encode current description relatesprevious descriptions entity. encode recency information: entitylast described terms number utterances turns (distance-last-ref, distancelast-in-turns), last related description (e.g. set, class) (distance-last-related),frequently described (number-prev-mentions), last described (speaker-oflast-ref), last described terms turn expression since descriptionmay broken several utterances (color-in-last-exp, type-in-last-exp, owner-inlast-exp, price-in-last-exp, quantity-in-last-exp, type-in-last-turn, color-in-last-turn, ownerin-last-turn, price-in-last-turn, quantity-in-last-turn, initial-in-last-turn). also encodefrequency information: frequency attributes expressed previousdescriptions (freq-type-expressed, freq-color-expressed, freq-price-expressed, freq-ownerexpressed, freq-quantity-expressed), history possible conceptual pacts mayformed; attribute types used describe last two last threedescriptions consistent across usages (cp-given-last-2, cp-given-last-3).4. Experimental Methodexperiments utilize rule learning program ripper (Cohen, 1996) learn contentselection component object description generator object descriptionscoconut corpus. Although categorization algorithm could applied problemgiven current formulation, ripper good match particular setupif-then rules used express learned model easily comparedtheoretical models content selection described above. One drawback ripperautomatically take context account training discourse contextmust represented via features well. Although might seem desirable use rippersprevious predictions additional context training, since considerpractice, unnecessary irrelevant so. learned model consistgeneration rules relative discourse encoded features (i.e.actually said corpus) corrections learns good improvingperformance static corpus.Like learning programs, ripper takes input names set classeslearned, names ranges values fixed set features, training data specifyingclass feature values example training set. output classificationmodel predicting class future examples. ripper, classification modellearned using greedy search guided information gain metric, expressedordered set if-then rules. default ripper corrects noisy data. experimentsreported here, unlike reported Jordan Walker (2000), corrections noisydata suppressed since reliability annotated features high.Thus apply ripper, object descriptions corpus encoded terms setclasses (the output classification), set input features used predictorsclasses. mentioned above, goal learn set content attributesincluded object description. describe class assignedobject description, summarize features extracted dialogueexpression occurs, method applied learn predict class object descriptionfeatures.176fiLearning Content Selection Rules Generating Object DescriptionsClass NameCPQCPOCPOQCPCOCCQCOQOQPOQPPQPOQNCorpus6456464241323118141312115422Explicit attributesobject descriptionColor, Price, QuantityColor, Price, OwnerColor, Price, Owner, QuantityNone (type only)Color, PriceOwnerColor, OwnerColorColor, QuantityColor, Owner, QuantityOwner, QuantityPrice, OwnerQuantityPricePrice, QuantityPrice, Owner, QuantityFigure 12: Encoding attributes included terms ML Classes, ordered frequency4.1 Class Assignmentcorpus object descriptions used construct machine learning classesfollows. learning task determine subset four attributes, color, price,owner, quantity, include object description. Thus one method representingclass object description belongs encode object descriptionmember category represented set attributes expressed objectdescription. results 16 classes representing power set four attributesshown Figure 12. frequency class also shown Figure 12. Noteclasses encodings hand annotated explicit attributes shown Figure 6exclude type attribute since attempting model pronominal selections.4.2 Feature Extractioncorpus used construct machine learning features follows. ripper, featurevalues continuous (numeric), set-valued, symbolic. encoded discourse entityfurniture item terms set 82 total features described Section 3 inspiredtheories content selection subsequent reference. features either directlyannotated humans described Section 2, derived annotated features, inherentdialogue (Di Eugenio et al., 2000; Jordan, 2000b). dialogue contextdescription occurs directly represented encodings. dialogue system,dialogue manager would access features, needed problemsolving component, would provide language generator. entire featureset summarized Figure 13.177fiJordan & WalkerAssumed Familiarity Featuresmutually known attributes: type-mk, color-mk, owner-mk, price-mk, quantity-mkreference-relation: one initial, coref, set, class, cnanaphora, predicativeInherent Featuresutterance-number, speaker-pair, speaker, problem-numberattribute values:type: one sofa, chair, table, rug, lamp, superordinatecolor: one red, blue, green, yellowowner: one self, other,price: range $50 $600quantity: range 0 4.Conceptual Pact Featuresinteractions discourse entities: distance-last-ref, distance-last-ref-in-turns, number-prev-mentions, speaker-of-last-ref, distance-last-relatedprevious description: color-in-last-exp, type-in-last-exp, owner-in-last-exp, price-in-last-exp, quantityin-last-exp, type-in-last-turn, color-in-last-turn, owner-in-last-turn, price-in-last-turn, quantity-in-lastturn, initial-in-last-turnfrequency attributes: freq-type-expressed, freq-color-expressed, freq-price-expressed, freq-ownerexpressed, freq-quantity-expressedstability history: cp-given-last-2, cp-given-last-3Contrast Set Featuresdistractor frequencies: type-distractors, color-distractors, owner-distractors, price-distractors, quantitydistractorsAttribute Saliency: majority-type, majority-type-freq, majority-color, majority-color-freq, majorityprice, majority-price-freq, majority-owner, majority-owner-freq, majority-quantity, majority-quantityfreqIntentional Influences Featurestask situation: goal, colormatch, colormatch-constraintpresence, pricelimit, pricelimit-constraintpresence, priceevaluator, priceevaluator-constraintpresence, colorlimit, colorlimit-constraintpresence, priceupperlimit, priceupperlimit-constraintpresenceagreement state: influence-on-listener, commit-speaker, solution-size, prev-influence-on-listener, prevcommit-speaker, prev-solution-size, distance-of-last-state-in-utterances, distance-of-last-state-in-turns,ref-made-in-prev-action-state, speaker-of-last-state, prev-ref-stateprevious agreement state description: prev-state-type-expressed, prev-state-color-expressed, prev-stateowner-expressed, prev-state-price-expressed, prev-state-quantity-expressedsolution interactions: color-contrast, price-contrastFigure 13: Full Feature Set Representing Basis Object Description Content SelectionTask Oriented Dialogues.4.3 Learning Experimentsfinal input learning training data, i.e., representation set discourseentities, discourse context object descriptions terms feature class178fiLearning Content Selection Rules Generating Object Descriptionsvalues. order induce rules variety feature representations, training datarepresented differently different experiments.goal experiments test contribution features suggestedthree models object description content selection described Section 3. predictionincremental intentional influences models work bestcombination predicting object descriptions initial subsequent reference.because: (1) intentional influences features capture nothing relevantreference identification goal, focus incremental model, (2)hypothesize problem solving state relevant selecting attributes initialdescriptions, incremental model features capture nothing directlyproblem solving state, focus intentional influences model. Finallyexpect conceptual pact model work best conjunction incrementalintentional influences models since overriding informativeness constraints,since, establishing pact, may need adapt description makeefficient re-negotiate pact problem-solving situation changes.Therefore, examples first represented using assumed familiarity featuresFigure 7 establish performance baseline assumed familiarity information.add individual feature sets assumed familiarity feature set examinecontribution feature set own. Thus, examples represented usingfeatures specific particular model, i.e. conceptual pact features Figure 11,contrast set features Figure 9 intentional influences features Figure 10.Remember three different versions contrast set features, derivedthree different models currently focus. One model (segment) basedintentional structure (Grosz & Sidner, 1986). two simple recency basedmodels active focus space either contains discourse entitiesrecent utterance recent five utterances (one utterance, five utterance).addition theoretically-inspired feature sets, include task dialoguespecific inherent features Figure 8. particular features unlikely producerules generalize domains, including new coconut dialogues,domain pair speakers instantiate values uniquely particular domain.Thus, features may indicate aspects individual differences, rolespecific situation models content selection object descriptions.Next, examples represented using combinations features differentmodels examine interactions feature sets.Finally, determine whether particular feature types large impact (e.g. frequency features), report results set experiments using singleton feature sets,features varied attribute alone clustered sets restcontain one feature. example, distractor frequency attributes Figure 9 formcluster singleton feature set whereas utterance-number memberfeature set. experimented singleton feature sets order determinemaking large impact performance model feature set belong.output machine learning experiment model object description generation domain task, learned training data. evaluate models,error rates learned models estimated using 25-fold cross-validation, i.e. total set examples randomly divided 25 disjoint test sets, 25 runs learning179fiJordan & Walkerprogram performed. Thus, run uses examples test set trainingremaining examples testing. estimated error rate obtained averagingerror rate test portion data 25 runs. sample sizeshundreds (the coconut corpus provides 393 examples), cross-validation often providesbetter performance estimate holding single test set (Weiss & Kulikowski, 1991).major advantage cross-validation examples eventually used testing,almost examples used given training run.5. Experimental ResultsTable 2 summarizes experimental results. feature set, combinationfeature sets, report accuracy rates standard errors resulting 25-fold crossvalidation. test differences resulting accuracies using paired t-tests. tabledivided regions grouping results using similar feature sets. Row 1 providesaccuracy majority class baseline 16.9%; standard baselinecorresponds accuracy achieved simply choosing description type occursfrequently corpus, case means object description generatorwould always use color, price quantity attributes describe domain entity. Row2 provides second baseline, namely using assumed familiarity featureset. result shows providing learner information whethervalues attributes discourse entity mutually known significantly improveperformance majority class baseline (t=2.4, p< .03). Examination resttable shows clearly accuracy learned object description generatordepends features learner available.Rows 3 8 provide accuracies object description generators trained testedusing one additional feature sets addition familiarity feature set. Overall,results show compared familiarity baseline, features intentional influences (familiarity,iinf t=10.0, p<.01), contrast set (familiarity,segt=6.1, p< .01; familiarity,1utt t=4.7, p< .01; familiarity,5utt t=4.2, p< .01),conceptual pact (familiarity,cp t=6.2, p< .01) taken independently significantly improve performance. accuracies intentional influences features (Row 7)significantly better conceptual pact (t=5.2, p<.01) three parameterizations incremental model (familiarity,seg t=6, p<.01; familiarity,1utt t=4.3,p<.01; familiarity,5utt t=4.2, p<.01), perhaps indicating importance directrepresentation problem solving state task.addition, interestingly, Rows 3, 4 5 show features incrementalmodel based three different models discourse structure perform equallywell, i.e. statistically significant differences distractors predictedmodel discourse structure based intention (seg) two recency based models(1utt, 5utt), even though raw accuracies distractors predicted intentionbased model typically higher.6 remainder table shows intentionbased model performs better recency based model combinedfeatures (Row 15 seg vs. Row 16 1utt t=2.1, p<.05).6. consistent findings reported Jordan (2000b) used smaller dataset measurediscourse structure model best explained data incremental model.180fiLearning Content Selection Rules Generating Object DescriptionsRow1234567891011121314151617181920Model Testedbaselinebaselineincrementalincrementalincrementalconceptual pactintentional influencessituation specificintentional influences,incrementalintentional influences,incrementalintentional influences,incrementaltheory features combinedtheory features combinedtheory features combinedtheories& situation specifictheories& situation specifictheories& situation specificbest singletonsmodels combinedbest singletonsmodels combinedbest singletonsmodels combinedFeature Sets Usedmajority classfamiliarityfamiliarity,segfamiliarity,1uttfamiliarity,5uttfamiliarity,cpfamiliarity,iinffamiliarity,inhAccuracy (SE)16.9% (2.1)18.1% (2.1)29.0% (2.2)29.0% (2.5)30.4% (2.6)28.9% (2.1)42.4% (2.7)54.5% (2.3)familiarity,iinf,seg46.6% (2.2)familiarity,iinf,1utt42.7% (2.2)familiarity,iinf,5uttfamiliarity,iinf,cp,segfamiliarity,iinf,cp,1uttfamiliarity,iinf,cp,5utt44.4%43.2%40.9%41.9%(2.6)(2.8)(2.6)(3.2)familiarity,iinf,inh,cp,seg59.9% (2.4)familiarity,iinf,inh,cp,1utt55.4% (2.2)familiarity,iinf,inh,cp,5uttfamiliarity,iinf,inh,cp,seg57.6% (3.0)52.9% (2.9)familiarity,iinf,inh,cp,1utt47.8% (2.4)familiarity,iinf,inh,cp,5utt50.3% (2.8)Table 2: Accuracy rates content selection component object description generator using different feature sets, SE = Standard Error. cp = conceptual pactfeatures. iinf = intentional influences features. inh = inherent features. seg = contrast-set, segment focus space features. 1utt =contrast set, one utterance focus space features, 5utt = contrastset, five utterance focus space features.Finally, situation specific model based inherent feature set (Row 8)domain, speaker task specific performs significantly better familiarity baseline (t=16.6, p< .01). also significantly better modelsutilizing theoretically motivated features. significantly better intentionalinfluences model (t=5, p<.01), conceptual pact model (t=9.9, p<.01),well three parameterizations incremental model (seg t=10, p<.01; 1uttt=10.4, p<.01; 5utt t=8.8, p<.01).181fiJordan & WalkerSay POQ priceupperlimit-constraintpresence = IMPLICIT reference-relation = classSay COQ goal = SELECTCHAIRS colormatch-constraintpresence = IMPLICIT prev-solution-size =DETERMINATE reference-relation = corefSay COQ goal = SELECTCHAIRS distance-of-last-state-in-utterances >= 3 speaker-of-last-state = SELFreference-relation = initialSay COQ goal = SELECTCHAIRS prev-ref-state = STATEMENT influence-on-listener = action-directiveprev-solution-size = DETERMINATESay C prev-commit-speaker = commit influence-on-listener = action-directive color-contrast =speaker-of-last-state = SELFSay C color-contrast = yes goal = SELECTTABLE prev-influence-on-listener = action-directive influenceon-listener = naSay C solution-size = DETERMINATE prev-influence-on-listener = na prev-state-color-expressed = yesprev-state-price-expressed = na prev-solution-size = DETERMINATESay CO colorlimit = yesSay CO price-mk = yes prev-solution-size = INDETERMINATE price-contrast = yes commit-speaker = naSay CO price-mk = yes prev-ref-state = PARTNER-DECIDABLE-OPTION distance-of-last-state-inutterances <= 1 prev-state-type-expressed = yesSay prev-influence-on-listener = open-option reference-relation = corefSay influence-on-listener = info-request distance-of-last-state-in-turns <= 0Say CP solution-size = INDETERMINATE price-contrast = yes distance-of-last-state-in-turns >= 2Say CP distance-of-last-state-in-utterances <= 1 goal = SELECTSOFA influence-on-listener = nareference-relation = classSay prev-solution-size = DETERMINATE distance-of-last-state-in-turns <= 0 prev-state-type-expressed= yes ref-made-in-prev-action-state = yesSay prev-solution-size = DETERMINATE colormatch-constraintpresence = EXPLICITSay prev-solution-size = DETERMINATE goal = SELECTSOFA prev-state-owner-expressed = nacolor-contrast =Say CPOQ goal = SELECTCHAIRS prev-solution-size = INDETERMINATE price-contrast = type-mk=Say CPOQ distance-of-last-state-in-utterances >= 5 type-mk =Say CPOQ goal = SELECTCHAIRS influence-on-listener = action-directive distance-of-last-state-inutterances >= 2Say CPO influence-on-listener = action-directive distance-of-last-state-in-utterances >= 2 commit-speaker =offerSay CPO goal = SELECTSOFA distance-of-last-state-in-utterances >= 1default Say CPQFigure 14: Sampling Rules Learned Using assumed familiarity intentionalinfluences Features. classes encode four attributes, e.g CPOQ =Color,Price,Owner Quantity, = TypeSection 4.3, hypothesized incremental intentional influencesmodels would work best combination. Rows 9, 10 11 show results combination underlying model discourse structure. combinationsprovides increase accuracy, however improvements accuracy objectdescription generator based intentional influences features alone (Row 7)statistically significant.Figure 14 shows rules object description generator learns given assumed familiarity intentional influences features. rules make usetypes assumed familiarity features four types intentional influencesfeatures. features representing mutually known attributes representingattributes expressed previous agreement state thought overlapping182fiLearning Content Selection Rules Generating Object Descriptionsconceptual pact model, features representing problem-solving structureagreement state may overlap incremental model indicating focus.One rules rule set Figure 14 is:Say prev-solution-size = DETERMINATE colormatch-constraintpresence= EXPLICIT .example dialogue excerpt matches rule shown Figure 15.rule captures particular style problem solving dialogue conversantstalk explicitly points involved matching colors (we get 650 points withoutrug bluematch living room) argue including particular item (rug).case, solution proposed, feature prev-solution-size valuedeterminate. rule describes contexts solution counterproposed, support counter-proposal presented.D: suggest buy blue sofa 300, 1 table high green 200, 2 chairs red 50, 2chairs red 50 decide rest. thinkJ: 3 chair green high table green 200 1 chair green 100. sofa blue 300 rug blue250. get 700 point. 200 sofa livingroom plus rug 10. 20 points match. 50 pointsmatch dining room plus 20 spending all. red chairs plus red table costs 600. get 650points without rug bluematch living room. add tell think.Figure 15: Example discourse excerpt matches rule intentional influences assumed familiarity rule setRows 12, 13 14 Table 2 contain results combining conceptual pactfeatures intentional influences features contrast set features.results directly compared Rows 9, 10 11. ripper uses heuristic search, additional features effect making accuraciesresulting models lower. However, none differences statistically significant. Taken together, results Rows 9-14 indicate best accuracies obtainablewithout using situation specific features (the inherent feature set), combinationintentional influences contrast set features, best overall accuracy46.6% shown Row 9.Rows 15, 16 17 contain results combining features, includinginherent feature set, underlying model discourse structure. timeone significant difference underlying discourse models intentionbased model, segment, significantly better one utterance recency model(t=2.1, p<.05) five utterance recency model. models groupsegment model significantly better models use subsetfeatures (vs. inherent t=2.4, p<.03). Figure 16 shows generation rules learnedbest performing feature set shown Row 15. Many task, entity speaker specificfeatures inherent feature set used rules. rule set performs59.9% accuracy, opposed 46.6% accuracy general feature set (shownRow 9). final rule set, conceptual pact features used removing183fiJordan & WalkerSay Q type=CHAIR price>=200 reference-relation=set quantity>=2.Say Q speaker=GARRETT color-distractors<=0 type=CHAIR.Say PO color=unk speaker-pair=GARRETT-STEVE reference-relation=initial color-contrast=no.Say PO majority-color-freq>=6 reference-relation=set.Say PO utterance-number>=39 type-distractors<=0 owner=SELF price>=100.Say OQ color=unk quantity>=2 majority-price-freq<=5.Say OQ prev-state-quantity-expressed=yes speaker=JULIE color=RED.Say COQ goal=SELECTCHAIRS price-distractors<=3 owner=SELF distance-of-last-state-inutterances>=3 majority-price<=200.Say COQ quantity>=2 price<=-1 ref-made-in-prev-action-state=no.Say COQ quantity>=2 price-distractors<=3 quantity-distractors>=4 influence-on-listener=action-directive.Say CQ speaker-pair=DAVE-GREG utterance-number>=22 utterance-number<=27 problem<=1.Say CQ problem>=2 quantity>=2 price<=-1.Say CQ color=YELLOW quantity>=3 influence-on-listener=action-directive type=CHAIR.Say C price-mk=yes majority-type=SUPERORDINATE quantity-distractors>=3.Say C price-mk=yes utterance-number<=21 utterance-number>=18 prev-state-price-expressed=namajority-price>=200 color-distractors>=2.Say CO utterance-number>=16 price<=-1 type=CHAIR.Say CO price-mk=yes speaker-pair=JILL-PENNY.Say CO majority-price<=75 distance-of-last-state-in-utterances>=4 prev-state-type-expressed=na.Say color=unk speaker-pair=GARRETT-STEVE.Say color=unk owner=OTHER price<=300.Say prev-influence-on-listener=open-option utterance-number>=22.Say CP problem>=2 quantity<=1 type=CHAIR.Say CP price>=325 reference-relation=class distance-of-last-state-in-utterances<=0.Say CP speaker-pair=JON-JULIE type-distractors<=1.Say CP reference-relation=set owner=OTHER owner-distractors<=0.Say prev-solution-size=DETERMINATE price>=250 color-distractors<=5 owner-distractors>=2utterance-number>=15.Say color=unk.Say prev-state-type-expressed=yes distance-of-last-state-in-turns<=0 owner-distractors<=4.Say CPOQ goal=SELECTCHAIRS prev-solution-size=INDETERMINATE.Say CPOQ speaker-pair=KATHY-MARK prev-solution-size=INDETERMINATE owner-distractors<=5.Say CPOQ goal=SELECTCHAIRS influence-on-listener=action-directive utterance-number<=22.Say CPO utterance-number>=11 quantity<=1 owner-distractors>=1.Say CPO influence-on-listener=action-directive price>=150.Say CPO reference-relation=class problem<=1.default Say CPQFigure 16: Sampling Best Performing Rule Set. Learned using assumed familiarity, inherent, intentional influences contrast set featuresets. classes encode four attributes, e.g., CPOQ = Color,Price,OwnerQuantity, = Type only.features training effect accuracy. types featuresassumed familiarity, inherent, contrast set used. intentionalinfluences features, mainly agreement state previous agreement state descriptionsused. possible explanations agreement state stronger influencetask situation task situation modelled well.use inherent feature set contribute much overall accuracymany inherent features used rule set Figure 16? mayinherent features objects would important domain lotdomain specific reasoning task object description content selection. However,features likely support rules overfit current data set;184fiLearning Content Selection Rules Generating Object Descriptionssaid before, rules based inherent feature set unlikely generalize newsituations. However, might general abstract versions featurescould generalize new situations. example, attribute values discourseentity may capturing aspects problem solving (e.g. near end problem,price expensive items highly relevant). Second, use utterance-numberscharacterized rules beginning, middle end dialogue mayreflect problem solving progress. Third, rules involving problem-number suggestbehavior first problem different others may reflectdialogue partners reached agreement problem solving strategy. Finally,use speaker-pair features rules included two possible speakerpairs, may reflect differences agreements reached collaborate. Onerules rule set shown below:Say CP price >= 325 reference-relation = class distance-of-last-statein-utterances <= 0.rule applies discourse entities dialogues one speaker pair. exampledialogue excerpt matches rule Figure 17. rule reflects particular styledescribing items available use problem solving, speakerfirst describes class items listed. style descriptionallows speaker efficiently list available. distance-of-last-state-inutterances feature captures style description occurs proposalsmade.M: $550, inventory consists 2 Yellow hi-tables $325 each. Sofas, yellow $400green $350.Figure 17: Example dialogue excerpt matches rule best performing rulesetdescribed above, also created singleton feature sets, addition theoretically inspired feature sets, determine singleton features are, themselves, makinglarge impact performance model belongs to. singleton features shownTable 3 resulted learned models significantly majority class baseline. last column Table 3 also shows that, except assumed familiarityincremental 5utt models, theory model particular singleton feature belongs significantly better, indicating singleton alone better predictorcombined features theoretical models. assumed familiarity incremental 5utt models perform similarly corresponding single feature models indicatingsingle features highly useful features two models.Finally, combined singleton features Table 3 learn three additionalmodels shown Rows 18, 19 20 Table 2. three models significantlydifferent one another. best performing model Row 15, combines185fiJordan & WalkerSourceModelassumed familiarityconceptualpactFeatures Settype-mk, color-mk, owner-mk,price-mk, quantity-mkfreq-type-expressed, freq-colorexpressed, freq-price-expressed,freq-owner-expressed,freqquantity-expressedcp-given-last-2type-in-last-exp, color-in-lastexp, price-in-last-exp, owner-inlast-exp, quantity-in-last-exptype-in-last-turn,color-inlast-turn,price-in-last-turn,owner-in-last-turn, quantity-inlast-turnincremental type-distractors,colorsegdistractors, price-distractors,owner-distractors,quantitydistractorsmajority-type, majority-color,majority-price, majority-owner,majority-quantityincremental type-distractors,color1uttdistractors, price-distractors,owner-distractors,quantitydistractorsincremental type-distractors,color5uttdistractors, price-distractors,owner-distractors,quantitydistractorsintentional distance-of-last-state-ininfluencesutterancesdistance-of-last-state-in-turnscolormatchprev-state-type-expressed,prev-state-color-expressed,prev-state-owner-expressed,prev-state-price-expressed,prev-state-quantity-expressedsituationtype, color, price, owner, quanspecifictityutterance-numberAccuracy(SE)18.1% (2.1)Betterbaselinet=2.4, p<.03Source ModelBetteridentical22.1% (1.8)t=3.7, p<.01t=5.7, p<.0120.9% (2.1)18.9% (1.9)t=3.9, p<.01t=2.8, p<.02t=4.3, p<.01t=5.7, p<.0118.1% (2.0)t=3.4, p<.02t=6.4, p<.0121.4% (2.5)t=3.2, p<.01t=3.6, p<.0119.9% (2.3)t=2.5, p<.02t=4.8, p<.0120.8% (2.4)t=3.2, p<.01t=3.2, p<.0125.7% (2.7)t=4.4, p<.01t=1.5, NS21.3% (2.0)t=3.7, p<.01t=11, p<.0120.0% (2.1)19.3% (2.2)19.2% (1.9)t=3.6, p<.01t=3.7, p<.01t=3.6, p<.01t=10.2, p<.01t=10.3, p<.01t=8.8, p<.0124.3% (2.5)t=4.1, p<.01t=12.5, p<.0120.5% (2.3)t=3.3, p<.01t=16.2, p<.01Table 3: Performance using singleton feature sets, SE = Standard Errorfeatures, significantly better 1utt (t=4.2, p<.01) 5utt (t=2.8, p<.01) Rows19 20, significantly different seg (t=2.0, NS) Row 18. combinedsingletons seg model (Row 18) also significantly different inherent model186fiLearning Content Selection Rules Generating Object Descriptions(Row 8). combined singletons seg model advantage requires twosituation specific features smaller set theoretical features.ClassCPQCPOCPOQCPCOCCQCOQPOOQQPOQPQrecall100.0066.67100.0050.00100.00100.0066.670.000.00100.0050.0066.670.000.000.00precision63.64100.00100.00100.00100.0060.00100.000.00100.00100.00100.0050.000.00100.00100.00fallout12.120.000.000.000.005.410.005.130.000.000.005.412.500.000.00F (1.00)0.780.801.000.671.000.750.800.000.001.000.670.570.000.000.00Table 4: Recall Precision values class; rows ordered frequentleast frequent classClassCPQCOQCCPOCOPOOQPOQCPOQQCPPQCQCPQ700101000000011030010100000000COQ002000000000000C000010010000000CPO000040000000000CO000002000000000PO000000100000000000000010000000OQ000000002100010POQ000000000000000CPOQ000000000060000Q000000001000000CP000000000000100PQ000000000000000CQ000000000000000Table 5: Confusion matrix held-out test set; row label indicates class,column indicates token classified automatically.Tables 4 5 show recall precision class sample confusion matrixone run best performing model held-out test-set consisting 40 examples.Table 4 shows overall tendency recall precision higherclasses frequent, lower less frequent classes one would expect.Table 5 shows arent significant sources confusion errors spreadacross different classes.187fiJordan & Walker6. Discussion Future Workarticle reports experimental results training generator learn attributesdiscourse entity include object description. knowledge,first reported experiment trainable content selection component object descriptiongeneration dialogue. unique feature study use theoretical workcognitive science speakers select content object description. theoriesused inspire development features machine learner based BrennanClarks (1996) model, Dale Reiters (1995) model Jordans (2000b) model.Dale Reiters model relies model discourse structure, developedfeatures represent Grosz Sidners (1986) model discourse structure, wellfeatures representing two simple recency based models discourse structure. objectdescription generators trained coconut corpus task-oriented dialogues.results show that:best performing learned object description generator achieves 60% matchhuman performance opposed 17% majority class baseline;assumed familiarity feature set improves performance baseline;Features specific task, speaker discourse entity (the inherent feature set)provide significant performance improvements;conceptual pact feature set developed approximate Brennan Clarksmodel object description generation significantly improves performancebaseline assumed familiarity;contrast set features developed approximate Dale Reiters model significantly improve performance baseline assumed familiarity;intentional influences features developed approximate Jordans modelbest performing theoretically-inspired feature set taken alone,combination intentional influences features contrast set features best performing theoretically-based models. combined modelachieves accuracy 46.6% exact match human performance holdspromise general across domains tasks includeinherent features.Tests using singleton feature sets model showed frequency featuresattributes last used impact conceptual pact model,distractor set features important incremental models, features related state biggest impact intentional influences model.none singleton features perform well feature combinationsrelated model.model consisting combination best singleton featuresmodels significantly different best learned object descriptiongenerator achieved 53% match human performance advantagefewer situation specific features.188fiLearning Content Selection Rules Generating Object DescriptionsThus choice use theoretically inspired features validated, sense everyset cognitive features improves performance baseline.previous work, presented results similar set experiments, bestmodel object description generation achieved accuracy 50% (Jordan & Walker,2000). accuracy improvements reported due number new featuresderived corpus, well modification machine learning algorithmrespect fact training data experiments noisy.hard say good best-performing accuracy 60% actuallyone first studies kind. several issues consider. First, objectdescriptions corpus may represent one way describe entity pointdialogue, using human performance standard evaluatelearned object description generators provides overly rigorous test (Oberlander, 1998;Reiter, 2002). Furthermore, know whether humans would produce identical objectdescriptions given discourse situation. previous study anaphor generationChinese showed rates match human speakers averaged 74% problem(Yeh & Mellish, 1997), results comparable that. Furthermore, resultsshow including features specific speaker attribute values improves performancesignificantly. conclusion may important quantify best performancehuman could achieve matching object descriptions corpus, givencomplete discourse context identity referent. addition, difficultyproblem depends number attributes available describing objectdomain; object description generator correctly make four different decisionsachieve exact match human performance. Since coconut corpus publiclyavailable, hope researchers improve results.Another issue must considered extent experimentstaken test theories inspired feature sets. several reasonscautious making interpretations. First, models developed explainsubsequent reference initial reference. Second, feature sets cannot claimedway complete. possible features could developed providebetter representation theories. Finally, ripper propositional learner,models object description generation may representable propositionaltheory. example, models object description generation rely representationdiscourse context form type discourse model. features utilizedrepresent discourse context capture aspects discourse history,representations rich used rule-based implementation. Howeverinteresting note whatever limitations models may have, automaticallytrained models tested perform better rule-based implementationstheoretical models, reported Jordan (2000b).Another issue extent findings might generalize across domains.always issue empirical work, one potential limitation studyJordans model explicitly developed capture features specific negotiationdialogues coconut corpus. Thus, possible featuresinspired theory better fit data. conceptual pact featuresless prominent coconut data data thus inspired new model, expectfind types dialogue inspire additional features feature representations.189fiJordan & WalkerFinally, unique contribution work experimental comparison differentrepresentations discourse structure task object description generation.tested three representations discourse structure, one represented features derivedGrosz Sidners model, two recency based representations. Onesurprising results work finding features based Grosz Sidnersmodel improve performance extremely simple models based recency.could due issues discussed Walker (1996a), namely human working memoryprocessing limitations play much larger role referring expression generationinterpretation would suggested operations Grosz Sidners focus spacemodel. However could also due much mundane reasons, namelypossible (again) feature sets adequate representations discoursestructure model differences, differences found would statistically significantcorpus much larger. However, results discourse structure modeldifferences reported confirm findings reported Jordan (2000b), i.e. alsotrue focus space model perform better simple recency modelsJordans rule-based implementations.future work, plan perform similar experiments different corpora different communications settings problem types (e.g. planning, scheduling, designing)determine whether findings specific genre dialogues examine here,whether general models applied directly new domain. Relatedquestion generality, created binary attribute inclusion model using domainindependent feature sets yet new annotated corpus upon test it.AcknowledgmentsThanks William Cohen helpful discussions use ripper problem,three anonymous reviewers provided many helpful suggestions improvingpaper.ReferencesAllen, J., & Core, M. (1997). Draft DAMSL: Dialog act markup several layers. Coding scheme developed MultiParty group, 1st Discourse Tagging Workshop,University Pennsylvania, March 1996.Appelt, D. (1985a). Planning English Sentences. Studies Natural Language Processing.Cambridge University Press.Appelt, D. E. (1985b). pragmatic issues planning definite indefinitenoun phrases. Proceedings 23rd ACL, pp. 198203.Bangalore, S., & Rambow, O. (2000). Exploiting probabilistic hierarchical modelGeneration. COLING, pp. 4248, Saarbucken, Germany.Brennan, S. E., & Clark, H. H. (1996). Lexical choice conceptual pacts conversation.Journal Experimental Psychology: Learning, Memory Cognition, 22, 14821493.190fiLearning Content Selection Rules Generating Object DescriptionsClark, H. H., & Wilkes-Gibbs, D. (1986). Referring collaborative process. Cognition,22, 139.Cohen, W. (1996). Learning trees rules set-valued features. Fourteenth Conference American Association Artificial Intelligence, pp. 709716.Daelemans, W., & Hoste, V. (2002). Evaluation machine learning methods natural language processing tasks. Proceedings LREC-2002, 3rd InternationalLanguage Resources Evaluation Conference, pp. 755760.Dale, R. (1992). Generating Referring Expressions. ACL-MIT Series Natural LanguageProcessing. MIT Press.Dale, R., & Reiter, E. (1995). Computational Interpretations Gricean MaximsGeneration Referring Expressions. Cognitive Science, 19 (2), 233263.Di Eugenio, B., Jordan, P. W., Thomason, R. H., & Moore, J. D. (2000). agreementprocess: empirical investigation human-human computer-mediated collaborativedialogues. International Journal Human-Computer Studies, 53 (6), 10171076.Di Eugenio, B., Moore, J. D., & Paolucci, M. (1997). Learning features predict cueusage. Proceedings 35th Annual Meeting Association ComputationalLinguistics, ACL/EACL 97, pp. 8087.Di Eugenio, B., & Webber, B. (1996). Pragmatic overloading natural language instructions. International Journal Expert Systems, Special Issue Knowledge Representation Reasoning Natural Language Processing, 9 (1), 5384.Duboue, P. A., & McKeown, K. R. (2001). Empirically estimating order constraintscontent planning generation. Proceedings 39rd Annual MeetingAssociation Computational Linguistics (ACL/EACL-2001).Gardent, C. (2002). Generating minimal definite descriptions. Proceedings AssociationComputational Linguistics 2002, pp. 96103.Grice, H. (1975). Logic conversation. Cole, P., & Morgan, J. (Eds.), SyntaxSemantics III - Speech Acts, pp. 4158. Academic Press, New York.Grosz, B. J., & Sidner, C. L. (1986). Attention, intentions structure discourse.Computational Linguistics, 12, 175204.Heeman, P. A., & Hirst, G. (1995). Collaborating referring expressions. ComputationalLinguistics, 21 (3), 351383.Heim, I. (1983). File change semantics familiarity theory definiteness. Bauerle,R., Schwarze, C., & von Stechow, A. (Eds.), Meaning, use, interpretationlanguage, pp. 164189. Walter de Gruyter, Berlin.Hirschberg, J. B. (1993). Pitch accent context: predicting intonational prominencetext. Artificial Intelligence Journal, 63, 305340.Jordan, P., & Walker, M. A. (2000). Learning attribute selections non-pronominalexpressions. Proceedings 38th Annual Meeting AssociationComputational Linguistics (ACL-00), Hong Kong, pp. 181190.191fiJordan & WalkerJordan, P. W. (2000a). Influences attribute selection redescriptions: corpus study.Proceedings CogSci2000, pp. 250255.Jordan, P. W. (2000b). Intentional Influences Object Redescriptions Dialogue: Evidence Empirical Study. Ph.D. thesis, Intelligent Systems Program, UniversityPittsburgh.Jordan, P. W. (2002). Contextual influences attribute selection repeated descriptions.van Deemter, K., & Kibble, R. (Eds.), Information Sharing: Reference Presupposition Language Generation Interpretation, pp. 295328. CSLI Publications.Kamp, H., & Reyle, U. (1993). Discourse Logic; Introduction ModeltheoreticSemantics Natural Language, Formal Logic Discourse Representation Theory.Kluwer Academic Publishers, Dordrecht Holland.Karttunen, L. (1976). Discourse referents. McCawley, J. (Ed.), Syntax Semantics,Vol. 7, pp. 363385. Academic Press.Krahmer, E., van Erk, S., & Verleg, A. (2003). Graph-Based generation referring expressions. Computational Linguistics, 29 (1), 5372.Krippendorf, K. (1980). Content Analysis: Introduction Methodology. Sage Publications, Beverly Hills, Ca.Kronfeld, A. (1986). Donnellans distinction computational model reference.Proceedings 24th ACL, pp. 186191.Langkilde, I., & Knight, K. (1998). Generation exploits corpus-based statistical knowledge. Proceedings COLING-ACL, pp. 704710.Lochbaum, K. (1995). use knowledge preconditions language processing.IJCAI95, pp. 12601266.Malouf, R. (2000). order prenominal adjectives natural language generation.Proceedings Meeting Association Computational Lingustics, ACL2000, pp. 8592.Mellish, C., Knott, A., Oberlander, J., & ODonnell, M. (1998). Experiments using stochastic search text planning. Proceedings International Conference NaturalLanguage Generation, pp. 97108.Oberlander, J. (1998). right thing...but expect unexpected. ComputationalLinguistics, 24 (3), 501508.Oh, A. H., & Rudnicky, A. I. (2002). Stochastic natural language generation spokendialog systems. Computer Speech Language: Special Issue Spoken LanguageGeneration, 16 (3-4), 387407.Passonneau, R. J. (1995). Integrating Gricean Attentional Constraints. ProceedingsIJCAI 95, pp. 12671273.Passonneau, R. J. (1996). Using Centering Relax Gricean Informational ConstraintsDiscourse Anaphoric Noun Phrases. Language Speech, 32 (2,3), 229264.Pickering, M., & Garrod, S. (2004). Toward mechanistic psychology dialogue. BehavioralBrain Sciences, 27 (2), 169226.192fiLearning Content Selection Rules Generating Object DescriptionsPoesio, M. (2000). Annotating corpus develop evaluate discourse entity realization algorithms: issues preliminary results. Proc. Language ResourcesEvaluation Conference, LREC-2000, pp. 211218.Pollack, M. E. (1991). Overloading intentions efficient practical reasoning. Nous, 25,513 536.Prince, E. F. (1981). Toward taxonomy given-new information. Radical Pragmatics,pp. 223255. Academic Press.Radev, D. R. (1998). Learning correlations linguistic indicators semanticconstraints: Reuse context-dependent decsriptions entities. COLING-ACL,pp. 10721078.Ratnaparkhi, A. (2002). Trainable approaches surface natural language generationapplication conversational dialog systems. Computer Speech Language:Special Issue Spoken Language Generation, 16 (3-4), 435455.Reiter, E. (1990). Generating appropriate natural language object descriptions. Tech. rep.TR-10-90, Department Computer Science, Harvard University. Dissertation.Reiter, E. (2002). corpora gold standards NLG?. Proceedings 11thInternational Workshop Natural Language Generation, pp. 97104.Roy, D. K. (2002). Learning visually grounded words syntax scene descriptiontask. Computer Speech Language: Special Issue Spoken Language Generation,16 (3-4), 353385.Stone, M., & Webber, B. (1998). Textual economy close coupling syntaxsemantics. Proceedings 1998 International Workshop Natural Language Generation, pp. 178187, Niagra-on-the-Lake, Canada.Terken, J. M. B. (1985). Use Function Accentuation: Experiments. Ph.D.thesis, Institute Perception Research, Eindhoven, Netherlands.van Deemter, K. (2002). Generating referring expressions: Boolean extensions incremental algorithm. Computational Linguistics, 28 (1), 3752.Varges, S., & Mellish, C. (2001). Instance-based natural language generation. ProceedingsNorth American Meeting Association Computational Linguistics, pp.18.Walker, M., Rambow, O., & Rogati, M. (2002). Training sentence planner spokendialogue using boosting. Computer Speech Language: Special Issue SpokenLanguage Generation, 16 (3-4), 409433.Walker, M. A. (1996a). Limited attention discourse structure. Computational Linguistics, 22-2, 255264.Walker, M. A. (1996b). Effect Resource Limits Task Complexity CollaborativePlanning Dialogue. Artificial Intelligence Journal, 85 (12), 181243.Webber, B. L. (1978). Formal Approach Discourse Anaphora. Ph.D. thesis, HarvardUniversity. New York:Garland Press.193fiJordan & WalkerWeiss, S. M., & Kulikowski, C. (1991). Computer Systems Learn: ClassificationPrediction Methods Statistics, Neural Nets, Machine Learning, Expert Systems. San Mateo, CA: Morgan Kaufmann.Yeh, C.-L., & Mellish, C. (1997). empirical study generation anaphorachinese. Computational Linguistics, 23-1, 169190.194fiJournal Articial Intelligence Research 24 (2005) 357-406Submitted 12/04; published 09/05Pure Nash Equilibria: Hard Easy GamesGeorg Gottlobgottlob@dbai.tuwien.ac.atInformation Systems Department,Technische Universitat Wien,A-1040 Wien, AustriaGianluigi Grecoggreco@mat.unical.itDipartimento di Matematica,Universita della Calabria,I-87030 Rende, ItalyFrancesco Scarcelloscarcello@deis.unical.itDEIS,Universita della Calabria,I-87030 Rende, ItalyAbstractinvestigate complexity issues related pure Nash equilibria strategic games.show that, even restrictive settings, determining whether game pure NashEquilibrium NP-hard, deciding whether game strong Nash equilibriumP2 -complete. study practically relevant restrictions lower complexity.particular, interested quantitative qualitative restrictions wayplayers payo depends moves players. say game small neighborhood utility function player depends (the actions of) logarithmicallysmall number players. dependency structure game G expressedgraph G(G) hypergraph H(G). relating Nash equilibrium problemsconstraint satisfaction problems (CSPs), show G small neighborhoodH(G) bounded hypertree width (or G(G) bounded treewidth), nding pureNash Pareto equilibria feasible polynomial time. game graphical,problems LOGCFL-complete thus class NC2 highly parallelizableproblems.1. Introduction Overview Resultstheory strategic games Nash equilibria important applications economicsdecision making (Nash, 1951; Aumann, 1985). Determining whether Nash equilibria exist, eectively computing them, relevant problems attracted muchresearch computer science (e.g. Deng, Papadimitriou, & Safra, 2002; McKelvey & McLennan, 1996; Koller, Megiddo, & von Stengel, 1996). work dedicated complexity issues related mixed equilibria games mixed strategies, playerschoices deterministic regulated probability distributions. context, existence Nash equilibrium guaranteed Nashs famous theorem (Nash,1951), currently open whether equilibrium computed polynomialtime (cf., Papadimitriou, 2001). First results computational complexity twoperson game presented Gilboa Zemel (1989), extensionsgeneral types games provided Megiddo Papadimitriou (1991),c2005AI Access Foundation. rights reserved.fiGottlob, Greco, ScarcelloPapadimitriou (1994b). recent paper Conitzer Sandholm (2003b) also provedNP-hardness determining whether Nash equilibria certain natural properties exist.present paper, dealing mixed strategies, rather investigatecomplexity deciding whether exists Nash equilibrium case pure strategies,player chooses play action deterministic, non-aleatory manner. Nashequilibria pure strategies briey referred pure Nash equilibria. Notesetting pure strategies, pure Nash equilibrium guaranteed exist (see,instance, Osborne & Rubinstein, 1994). Particular classes games pure Nashequilibria studied Rosenthal (1973), Monderer Shapley (1993),Fotakis et al. (2002). Recently, Fabrikant el. (2004) renewed interest classgames dened Rosenthal (1973), called congestion games, showing pure Nashequilibrium computed polynomial time symmetric network case,problem PLS-complete (Johnson, Papadimitriou, & Yannakakis, 1998) general.goal study fundamental questions existence pure Nash, Pareto,strong Nash equilibria, computation equilibria, nd arguably realisticrestrictions problems become tractable. Throughout paper, Paretostrong Nash equilibria considered setting pure strategies.pure strategies conceptually simpler mixed strategies, associatedcomputational problems appear harder. fact, show even severe restrictions imposed set allowed strategies, determining whether game pureNash Pareto Equilibrium NP-complete, deciding whether game strongNash equilibrium even P2 -complete. However, jointly applying suitable pairsrealistic restrictions, obtain settings practical interest complexityproblems drastically reduced. particular, determining existence pureNash equilibrium computing equilibrium feasible polynomial timeshow that, certain cases, problems even complete lowcomplexity class LOGCFL, means problems essentially easymembership problem context-free languages, thus highly parallelizable (in NC2 ).setting pure strategies, restrict attention restpaper, nite strategic game one player nite set possibleactions, chooses action all, independently actualchoices players. choices players thus thought madesimultaneously. choice action player referred players strategy.assumed player perfect knowledge possible actionspossible strategies players. global strategy, also called profile literature,consists tuple containing strategy player. player polynomial-timecomputable real valued utility function, allows assess subjective utilitypossible global strategy (global strategies higher utility better). pure Nashequilibrium (Nash, 1951) global strategy player improve utilitychanging action (while actions players remain unchanged). strongNash equilibrium (Aumann, 1959) pure Nash equilibrium change strategieswhatever coalition (i.e., group players) simultaneously increase utilityplayers coalition. pure Nash equilibrium Pareto optimal (e.g. Maskin, 1985)game admits pure Nash equilibrium player strictly higherutility. Pareto-optimal Nash equilibrium also called Pareto Nash Equilibrium.358fiPure Nash Equilibria: Hard Easy Gamesdescribing complexity results, let us discuss various parameters featureslead restricted versions strategic games. consider restrictions strategicgames impose quantitative and/or qualitative limitations payosagent (and hence decisions) may inuenced agents.set neighbors Neigh(p) player set players potentiallymatter w.r.t. ps utility function. Thus, whenever player q = p Neigh(p) psutility function directly depend actions q. assume gameequipped polynomial-time computable function Neigh property.1player neighborhood relationship, typically represented graph (or hypergraph),central notion graphical games (Koller & Milch, 2001; Kearns, Littman, & Singh,2001b), see detail next section.rst idea towards identication tractable classes games restrictcardinality Neigh(p) players p. instance, consider set companiesmarket. company usually limited number market playersbases strategic decisions. relevant players usually known constituteneighbors company setting. However, note even case gameoutcome still depends interaction players, though possibly indirect way.Indeed, choice company inuences choice competitors, hence, turn,choice competitors competitors, on. general setting,number real-world cases modeled natural way. thus denefollowing notion limited neighborhood:Bounded Neighborhood: Let k > 0 xed constant. strategic game associated neighborhood function Neigh k-bounded neighborhood if, player p,|Neigh(p)| k .setting bounded neighborhood assumption realistic, settings constant bound appears harsh imposition. much realisticappealing relax constraint consider logarithmic bound rather constant bound number neighbors.Small Neighborhood: game G denote P (G) set players, Act(p)set possible actions player p, ||G|| total size descriptiongame G (i.e., input size n). Furthermore, let maxNeigh(G) = maxpP (G) |Neigh(p)|maxAct (G) = maxpP (G) |Act(p)|.class strategic games small neighborhood if, game G class,maxNeigh(G) = (log ||G||)log maxAct (G)Note denominator log maxAct(G) bound. Intuitively, use termavoid cheating trading actions neighbors. Indeed, roughly speaking, playerinteractions may reduced signicantly adding exponential amount additionalactions. player, fresh actions may encode possible action congurations1. Note game trivially represented setting, possibly setting Neigh(p)set players, player p. cases, however, one able provide much betterneighborhood function.359fiGottlob, Greco, ScarcelloFigure 1: Dependency hypergraph dependency graph game G.neighbors, yielding equivalent game less interaction, possiblyfewer players, too. denominator takes account.terms, class games small neighborhood constant c||G||nitely many pairs (G, p) games players, |Neigh(p)| < c ( loglog|Act(p)| ).related notion i(G) intricacy game dened by:i(G) =maxNeigh(G) log maxAct (G).log ||G||clear class games small neighborhood intricacygames bounded constant.Obviously, bounded neighborhood implies small neighborhood, vice-versa.believe large number important (classes of) games economicssmall neighborhood property.addition quantitative aspect size neighborhood (and neighborhood actions), also interested qualitative aspects mutual strategic inuence.Following Kearns et al. (2001b), game G set P players, dene strategic dependency graph undirected graph G(G) P set vertices{{p, q} | q P p Neigh(q)} set edges. Moreover, dene strategic dependency hypergraph H(G), whose vertices players P whose set hyperedges{{p} Neigh(p) | p P }. instance, consider game G players A, B, C,Neigh(A) = {B, C }, Neigh(B) = {A, C }, Neigh(C ) = {A, B}, Neigh(D ) = {C }.Figure 1 shows dependency graph dependency hypergraph associated G.consider following classes structurally restricted games:Acyclic-Graph Games:Games G G(G) acyclic.Acyclic-Hypergraph Games: Games G H(G) acyclic. Noteseveral denitions hypergraph acyclicity (Fagin, 1983). refer broadest(i.e., general) one, also known -acyclicity (Fagin, 1983; Beeri, Fagin, Maier,& Yannakakis, 1983) (see Section 2).acyclic-graph game also acyclic-hypergraph game, vice-versa.extreme example, let G game player set P utility actionplayer depends players. G(G) clique size |P | H(G)trivially acyclic hypergraph hyperedge {P }.strategic games, acyclic graph acyclic hypergraph assumptionssevere restrictions, rather unlikely apply practical contexts. However,360fiPure Nash Equilibria: Hard Easy Gamesimportant generalizations appear much realistic practicalapplications. concepts bounded treewidth (Robertson & Seymour, 1986)bounded hypertree width (Gottlob, Leone, & Scarcello, 2002b) (see also Section 5),suitable measures degree cyclicity graph hypergraph, respectively.particular, acyclic graph (hypergraph) treewidth (hypertree width) 1.argued impressive number real-life graphs low treewidth (Downey& Fellows, 1995). Hypertree width turn fruitfully applied context databasequeries (Gottlob et al., 2002b) constraint satisfaction problems (Gottlob, Leone, &Scarcello, 2000). Formal denitions given Section 5. Note computingtreewidth graph hypertree width hypergraph NP-hard problems.However, (xed) constant k, checked polynomial time whethergraph treewidth k (Bodlaender, 1997) whether hypergraph hypertree widthk (Gottlob et al., 2002b). have, constant k, following restricted classesgames:Games treewidth bounded k:k.games G treewidth G(G)Games hypertree width bounded k: games G hypertreewidth H(G) k.context complexity eciency studies, important make clearinput (in case, multiplayer game) represented. say gamegeneral form sets players actions given extensional formneighborhood utility functions polynomially computable functions. Unlessotherwise stated, always assume games given general form. classesgames particular properties, alternative representations usedvarious authors. instance, game theory literature, set utility functions oftenrepresented single table (or matrix) entry combinationplayers actions containing, player p, evaluation utility functionparticular combination. representation said standard normal form (SNF)(see, instance, Osborne & Rubinstein, 1994; Owen, 1982). Note that, manyplayers, representation may space consuming, particularly playersinterested players, subset them. Moreover, case,monolithic utility table SNF obscures much structure present realworld games (Koller & Milch, 2001). fact, context games restricted playersinteractions, used representation graphical normal form (GNF). GNFgames, also known graphical games (Kearns, Littman, & Singh, 2001a; Kearns et al.,2001b; Kearns & Mansour, 2002; Vickrey, 2002), utility function player pgiven table displays ps utility function possible combined strategiesp ps neighbors, players irrelevant p. Therefore, large populationgames (modeling instance agent interactions internet), SNF practicallyunfeasible, succinct graphical normal form works well, actuallynatural representation.Main results.main results paper summarized follows:361fiGottlob, Greco, ScarcelloDetermining whether strategic game pure Nash equilibrium NP-completeremains NP-complete even following two restricted cases:Games graphical normal form (GNF) bounded neighborhood (Theorem 3.1).Acyclic-graph games, acyclic-hypergraph games (Theorem 3.2).results hold Pareto Nash equilibria pure strategies.Determining whether strategic game strong Nash equilibrium p2 -completethus second level Polynomial Hierarchy (Theorem 3.7 Theorem 3.8). proof theorem gives us fresh game-theoretic view classP2 class problems whose positive instances characterized coalitionplayers cooperate provide equilibrium, win disjoint coalition, fails trying improve utility players. E.g.,case 2 quantied Boolean formulas, former coalition consistsexistentially quantied variables, latter universally quantied ones.pure Nash, Pareto strong equilibrium existence computations problemsfeasible logarithmic space games standard normal form (Theorem 4.1).pure Nash equilibrium existence computation problems tractablegames (in whatever representation) simultaneously small neighborhoodbounded hypertree width (Theorem 5.3). Observe two joint restrictions, small neighborhood bounded hypertree width, weaker restrictions bounded neighborhood acyclicity, respectively,guarantee tractability. Thus, order obtain tractability, instead strengthening single restriction, combined two weaker restrictions. thinktwo strong restrictions unrealistic, believe many naturalgames combined weaker restrictions apply. order prove tractabilityresult, establish relationship strategic games well-known nitedomain constraint satisfaction problem (CSP), much studied AI literature (e.g. Vardi, 2000; Gottlob et al., 2000). Let us point also VickreyKoller (2002) recently exploited mapping CSP dierent problem ndingapproximate mixed equilibria graphical games. show (general,necessarily GNF) strategic game G translated CSP instancehypertree width G, whose feasible solutions exactly correspondNash equilibria game. Then, able prove G equivalentacyclic constraint satisfaction problem size ||G||O(i(G)hw(G)) , i(G) intricacy G hw(G) hypertree width strategic dependency hypergraph.Acyclic CSPs, turn, well-known solvable polynomial time.Exploiting relationship CSPs, prove Nash-equilibrium existence computation problems tractable games graphical normal form(GNF) bounded hypertree width (Theorem 5.3), regardless game intricacy, i.e., even unbounded neighborhood.362fiPure Nash Equilibria: Hard Easy Gamesshow strategic game bounded treewidth, also boundedhypertree width (Theorem 5.7). Note novel result relationshiptwo measures degree cyclicity, since earlier works similarsubjects dealt either primal dual graph given hypergraph, ratherdependency graph, present paper, focused games. Combined two previous points, entails Nash-equilibrium existencecomputation problems tractable games simultaneously smallneighborhood bounded treewidth, GNF games bounded treewidth(Corollary 5.9).cases pure Nash Equilibrium computed polynomial time,also Pareto Nash equilibrium computed polynomial time (Theorem 4.6Corollary 5.4).tractability results partially extend strong Nash equilibria. Indeed,checking problem becomes feasible polynomial time acyclic-hypergraph gamesGNF. However, even simple cases, deciding whether game strongNash equilibria NP-complete, thus still untractable (Theorem 4.8).go bit further, determining precise complexity games acyclic(or even bounded width) interactions among players: case game givenGNF, problem determining pure Nash equilibrium game boundedhypertree-width (or bounded treewidth) LOGCFL-complete thus parallel complexity class NC2 (Theorem 6.1). Membership LOGCFL followsmembership bounded hypertree-width CSPs LOGCFL (Gottlob, Leone, &Scarcello, 2001). Hardness LOGCFL shown transforming (logspace uniformfamilies of) semi-unbounded circuits logarithmic depth together inputsstrategic games, game admits Nash equilibriumcircuit outputs one given input.Figure 2 summarizes results existence pure Nash equilibria.various authors dealt complexity Nash equilibria (e.g. Gilboa &Zemel, 1989; Papadimitriou, 1994b; Koller & Megiddo, 1992, 1996; Conitzer & Sandholm,2003b), investigations dedicated mixed equilibria bestknowledge complexity results present paper novel. awarework considering quantitative structural restrictions pure games studiedhere. Note tree-structured games rst considered Kearns et al. (2001b)context mixed equilibria. turned that, games, suitable approximation(mixed) Nash equilibria computed polynomial time. future work,would like extend tractability results even setting. awarework others parallel complexity equilibria problems. believepresent work contributes understanding pure Nash equilibria proposesappealing realistic restrictions main computation problems associatedequilibria tractable.rest paper organized follows. Section 2 introduce basic notionsgames Nash equilibria studied paper, describe games363fiGottlob, Greco, ScarcelloFigure 2: Complexity deciding existence pure Nash equilibria games GNFnumbers indicate theorems corresponding results proved.may represented. Section 3 thoroughly study computational complexitydeciding existence pure Nash, Pareto strong equilibria. Section 4 identifytractable classes games, Section 5 extend tractability results largerclass games, interaction among players bounded degree cyclicity.Section 6 improve results polynomial tractability easy games, providingprecise computational complexity games acyclic (or bounded width) interactionsamong players. Finally, Section 7, draw conclusions, discuss possibleresearch related works.364fiPure Nash Equilibria: Hard Easy Games2. Games Nash Equilibriagame G tuple P, Neigh, Act, U , P non-empty set distinct playersNeigh : P 2 P function p P , Neigh(p) P {p} containsneighbors p, Act : P function returning player p set possibleactions Act(p), U associates utility function : Act(p) j Neigh(p) Act(j )player p.Note that, general, players interests symmetric. Thus, may happenthat, pair players p1 , p2 P , p1 Neigh(p2 ) p2 Neigh(p1 ).player p, pa denotes choice play action Act(p). possible pacalled strategy p, set strategies p denoted St(p).2non-empty set players P P , combined strategy P set containingexactly one strategy player P . St(P ) denotes set combined strategiesplayers P .combined strategy (also, profile) x called global players contribute it,is, P = P . global strategies possible outcomes game.set players K P often called coalition. Let x global strategy, Kcoalition, combined strategy K. Then, denote xK [y] global strategywhere, player p K, individual strategy pa x replaced individualstrategy pb y. K singleton {p}, simply write xp [y].Let x global strategy, p player, utility function p. Then,small abuse notation, (x) denote output projection xdomain , i.e., output function applied actions played pneighbors according strategy x.context complexity eciency studies important make clearinput (in case, multiplayer game) represented.General Form: game general form sets players actions givenextensional form, neighborhood utility functions given intentionally, e.g.,encodings deterministic Turing transducers. precisely, interestedclasses games computation time neighborhood utility functionsglobally bounded polynomial. Let us denote Ck class games Ggeneral form whose neighborhood utility functions computable time O(nk ),n = |G|.sake presentation, assume hereafter k 1 xed globalbound. Moreover, unless otherwise stated, speak general game G (oromit specication all) mean game G Ck .following restrictive classes (representations of) games usedmany authors.Standard Normal Form (SNF): game set P players standard normalform (SNF) utility functions explicitly represented single table matrixentry (or cell) global strategy x, displaying list containing player2. Note technical distinction actions strategies: action element form a,strategy element form pa , i.e., action chosen player. helpstechnical proofs, since strategy singles player choice.365fiGottlob, Greco, Scarcellop, ps payo (x) w.r.t. x. (Equivalently, may describe utilities |P | tables,i-th table describes payo player i.) representation utilityfunctions often assumed literature (see, instance, Osborne & Rubinstein, 1994;Owen, 1982). Observe that, general case, even utility function polynomiallycomputable, writing form table may require exponential space.Graphical Normal Form (GNF): game set P players graphical normalform (GNF) utility function player p represented separate tablecontaining cell combined strategy x St(Neigh(p) {p}) ps setneighbors Neigh(p) {p}, displaying ps payo (x) w.r.t. x. game GNF illustratedExample 2.1. GNF representation adopted several recent papersstudy games large number players, utility function player dependsdirectly strategies (possibly few) players interested (e.g. Kearnset al., 2001a, 2001b; Kearns & Mansour, 2002; Vickrey, 2002). Note GNF may leadexponentially succinct game representation SNF. Notwithstanding, SNFoften used literature, mostly because, historically, rst investigations focusedtwo-player games. Moreover, games GNF often referred graphical games.prefer use phrasing games graphical normal form, makes clearaddressing representational issues.following example, refer throughout paper, soundfamiliar everyone, generalization well known two-person game battlesexes.Example 2.1 (FRIENDS) Let us consider game FRIENDS, played grouppersons plan evening happenings. players George (short: G),Pauline (P ), Frank (F ), Robert (R), Mary (M ). decide goeither see movie (m) see opera (o). However, preferences concernparticular option (m o) chosen, usually also persons join evening(possibly, depending movie opera choice). instance, assume Frankinterested joining Pauline Robert. would like join them. However,Pauline expert movies Robert expert operas. Thus, possiblego together, prefers go cinema Pauline operaRobert. Pauline would like stay Frank, prefers movies. Robertlike Frank speaks much and, know, prefers opera. Mary,too, likes operas would like go opera Robert. Finally, Georgematchmaker group: personal preferences would like FrankPauline stay together evening, best go cinema. utility functionsassociated game shown Figure 3, denote fact player Xchooses action Xa , e.g., Fm denotes strategy Frank chooses playaction m.2Let us formally dene main concepts equilibria studiedpaper.Definition 2.2 Let G = P, Neigh, A, U game. Then,366fiPure Nash Equilibria: Hard Easy GamesFPm Rm20Pm Ro22RFm02Po Rm11Po Ro02Fo10PFm20GPm Fm22Fo01Pm Fo00Rm10Po Fm00Po Fo11Ro02Figure 3: Utility functions FRIENDS GNFglobal strategy x pure Nash Equilibrium G if, every player p P ,pa St(p) (x) < (xp [pa ]);global strategy x pure strong Nash Equilibrium G if, K P,St(K ), p K (x) (xK [y]) or, equivalently, K P ,St(K ) that, p K, (x) < (xK [y]);pure Nash equilibrium x pure Pareto Nash Equilibrium Gexist pure Nash equilibrium G that, p P, (x) < (y).3sets pure Nash, strong Nash, Pareto Nash equilibria G denotedNE(G), SNE(G), PNE(G), respectively. easy see well knownfollowing relationships hold among notions Nash equilibria: SNE(G) PNE(G)NE(G). Moreover, existence Nash equilibrium imply existencestrong Nash equilibrium. However, exists Nash equilibrium, exists alsoPareto Nash equilibrium.{Fm , Pm , Ro , Go , Mo },Example 2.3strategies{Fm , Pm , Ro , Gm , Mo },{Fo , Po , Rm , Gm , Mm } {Fo , Po , Rm , Go , Mm } Nash equilibria FRIENDSgame. instance, consider latter strategy, players get payo 1.case, since P plays opera R plays movie, F cannot improve payo changingopera movie. holds G, R, P , would get lower payo 0,change choices.Moreover, note rst two strategies above, namely {Fm , Pm , Ro , Gm , Mo }{Fm , Pm , Ro , Go , Mo }, Pareto Nash equilibria, well strong Nash equilibria. Indeed, global strategies players get maximum payo 2, thusway improve utilities.2interaction among players G generally represented hypergraphH(G) whose vertices coincide players G whose set (hyper)edges containsplayer p (hyper)edge H(p) = {p} Neigh(p), referred-to characteristic edgep. Intuitively, characteristic edges correspond utility functions.3. Note pure strategies matter definition, requirement regardpure candidate equilibria compare possible mixed equilibria.367fiGottlob, Greco, Scarcellofundamental structural property hypergraphs acyclicity. Acyclic hypergraphsdeeply investigated many equivalent characterizations (e.g. Beeri et al.,1983). recall hypergraph H acyclic join tree H,is, tree JT whose vertices edges H and, whenever playerp occurs two vertices v1 v2 , v1 v2 connected JT , p occursvertex unique path linking v1 v2 (see Figure 5 join tree H(FRIENDS)).words, set vertices p occurs induces (connected) subtree JT .refer condition Connectedness Condition join trees (also knownrunning intersection property).Another representation interaction among players (undirected)dependency graph G(G) = (P, E), whose vertices coincide players G, {p, q}E p neighbor q (or vice versa). completeness observe that, even worksgraphical games use dependency graph, another natural choice representinggame structure directed graph (also called inuence graph), takes accountfact payos player p may depend payos player q vice versa,general. Following Kearns et al. (2001b), present paper use undirected versioninterested identifying game structures possibly allow us computeeciently Nash equilibria, directed graphs help much purpose. Letus give hint case, thinking group players X = {X1 , . . . , Xn },one one neighbor C, whose payos depend player X.Player C one neighbor D, C neighbor. Figure 4 shows directedgraph representing player interactions. easy design game playersFigure 4: directed graph representation player interactions.that, combined strategy x X players, Nash equilibrium,combined strategy x players, combined strategyC union x Nash equilibrium game. Therefore,far possibility reaching Nash equilibrium concerned, choices playersX depend other, way playing C, transitively player D, too.Observe undirected dependency graph represents succinct way, i.e.,direct connections, mutual relationship among players. However, directgraph model kind inuence, looking graph seems playersX worry player game. fact, exploiting gadgetsconstructions described paper, easy see even simple games whosedirected inuence graphs quasi-acyclic (i.e., acyclic, trivial cycleslike one shown Figure 4), hard deal with. Thus, apart well known368fiPure Nash Equilibria: Hard Easy GamesGGFPRPH(FRIENDS)GFRFPG(FRIENDS)HF(F,P,R)RHP(P,F)HR(R,F)HG(G,F,P)HM(M,R)PG H(FRIENDS)Figure 5: Hypergraph, dependency graph, primal graph FRIENDS game.right, join tree H(FRIENDS).easy acyclic cases, reasonable generalization notion direct acyclicityappear useful identifying tractable classes games.Observe dependency graph G(G) dierent called primal graph PGH(G), contains edge pairs vertices jointly occur hyperedgeH(G). general, G(G) much simpler PG. instance, consider game Gplayer p depends players q1 , . . . , qn , players independent(but possibly depend p). Then, G(G) tree. However, primal graphH(G) clique n + 1 vertices.Example 2.4 hypergraph H(FRIENDS), graph G(FRIENDS) primalgraph H(FRIENDS) shown Figure 5. Note dependency graph associated FRIENDS game acyclic, even though associated hypergraphacyclic (on right, also report join tree it). Moreover, note dependencygraph diers primal graph, player P neighbor R viceversa. 23. Hard Gamessection, precisely characterize complexity deciding existencedierent kinds pure Nash equilibria (regular, Pareto, strong). way, ableidentify sources complexity problems, order single out, followingsections, natural practically relevant tractable cases.Every game considered section assumed either general graphicalnormal form. Indeed, shall discuss details Section 4, games standardnormal form, computing pure Nash equilibria tractable problem, since one easilyexplore (big) table representing utility functions players, order detectstrategy interest. Since table given input, computation triviallyfeasible polynomial time.start showing deciding existence pure Nash equilibrium dicultproblem, even restricted setting.369fiGottlob, Greco, ScarcelloFigure 6: Schema reduction proof Theorem 3.1.Theorem 3.1 Deciding whether game G pure Nash equilibrium NP-complete.Hardness holds even G GNF 3-bounded neighborhood, numberactions fixed.Proof. Membership. decide NE(G) = guessing global strategy xverifying x Nash equilibrium G. latter task done polynomialtime. Indeed, player p action Act(p), checkchoosing strategy pa lead increment , testsfeasible polynomial time.Hardness. Recall deciding whether Boolean formula conjunctive normal form= c1 . . . cm variables X1 , . . . , Xn satisable, i.e., deciding whetherexists truth assignments variables making clause cj true, well knownNP-complete problem (CNF) SAT. Hardness holds even 3SAT restrictionclause contains three distinct (possibly negated) variables, variable occursthree clauses (Garey & Johnson, 1979). W.l.o.g, assume contains least oneclause one variable.dene GNF game G that: players partitioned two sets Pv Pc ,corresponding variables clauses , respectively; player c Pc ,Neigh(c) set players corresponding variables clause c,player v Pv , Neigh(v ) set players corresponding clausesv occurs; {t, f, u} set possible actions players, finterpreted truth values true false variables clauses. Figure 6 showsgraph G(G) game G associated formula (X1 X3 X4 ) (X2 X4 )(X4 X5 X6 ).Let x global strategy, utility functions dened follows.player c Pc , utility function uc(i) uc (x) = 3 c plays t, neighbors play action {t, f } wayleast one makes corresponding clause true;(ii) uc (x) = 2 c plays u, neighbors play action {t, f } waynone makes corresponding clause true;(iii) uc (x) = 2 c plays f exists v Neigh(c) v plays u;(iv) uc (x) = 1 cases.370fiPure Nash Equilibria: Hard Easy Gamesplayer v Pv , utility function uv(v) uv (x) = 3 v plays action {t, f } neighbors play action {t, f };(vi) uv (x) = 2 v plays u exists c Neigh(v ) c plays u;(vii) uv (x) = 1 cases.claim: satisable G admits Nash equilibrium.() Assume satisable, take one satisfying truth assignments, say .Consider global strategy x G player Pv chooses action according, player Pc plays t. Note that, case, players get payo 3according rules (i) (v) above, since 3 maximum payo, x Nashequilibrium G.() Let us show Nash equilibrium x G corresponds satisfying truthassignment G. rst state following properties strategies G.P1 : strategy x player v Pv plays u cannot Nash equilibrium. Indeed,assume contradiction x Nash equilibrium. Then, c Neigh(v ) mustplay f payo 2, rule (iii); otherwise would get payo 1, rule (iv).However, case player v gets payo 1 rule (vii), thus, rule (v),easily increase payo 3 playing action {t, f }. Contradiction.P2 : strategy x player c Pc plays u cannot Nash equilibrium. Indeed,player c chooses u, rule (vi) variable playerv Neigh(c) must play u, order get maximum possible payo 2 casehand. Therefore, x cannot Nash equilibrium, property P1 above.P3 : strategy x players play action {t, f } corresponding truthassignment makes clause c false cannot Nash equilibrium. fact, case,rule (ii), c play u order get maximum possible payo 2,hence x Nash equilibrium, property P2 .P4 : strategy x players play action {t, f } exists player c Pcplays f cannot Nash equilibrium. Indeed, x Nash equilibriumplayers play action {t, f }, property P 3 truth assignment correspondingstrategy satises clause c. follows player c plays f contradictsassumption x Nash equilibrium, c could change choice t,improving payo 3.properties, follows every Nash equilibrium G strategyplayers play either f players corresponding clauses must playget payo 3, made true truth assignment neighbors.Combined -part, entails one-to-one correspondencesatisfying truth assignments variables Nash equilibria game G.Finally, observe tables (matrices) representing entries utility functions (rules (i)(vii) above) built polynomial time . Moreover,assumptions made structure , player depends 3 playersmost.2371fiGottlob, Greco, Scarcelloworthwhile noting that, though quite limited, proof interactionamong players rather complicated. particular, easy see dependencygraph game described hardness part proof cyclic. Thus, one maywonder problem easier games simple structured interactions. nextshow that, general setting, even structure player interactions simple,problem deciding whether pure Nash equilibria exist remains hard.Theorem 3.2 Deciding whether game G general form pure Nash equilibriumNP-complete, even dependency graph associated hypergraph acyclic,number actions fixed.Proof. Membership follows previous theorem. next prove problemNP-hard, via reduction SAT. Given Boolean formula variables X1 , ..., Xm ,dene game G players X1 , ..., Xm corresponding variables , twoadditional players H. player Xi , 1 m, two available actions,f , corresponding truth assignments corresponding variable . Moreover,utility function player Xi constant, say 1. Hence, choice Xi independentplayer.actions player u, read satised unsatised,actions player H g b, read good bad, respectively.role check whether actions chosen X1 , . . . , Xm encode satisfying truthassignment . Indeed, behaviors described ensure strategiesplays may Nash equilibria, interaction player H, whoserole discard bad strategies. Given combined strategy x variable playersX1 , ..., Xm , denote (x) evaluation truth values determinedstrategy x.Player depends players {X1 , . . . , Xm , H}, utility function denedfollows. combined strategy = x1 x2 X1 , . . . , Xm , H, , x1combined strategy X1 , ..., Xm x2 H:uT (y) = 1 (x1 ) true plays s, (x1 ) false x2 = {Tu , Hg },(x1 ) false x2 = {Ts , Hb };uT (y) = 0, otherwise.Player H depends and, combined strategy x H , utilityfunction following:uH (x) = 1 x either {Ts , Hg } {Tu , Hb };uH (x) = 0, otherwise.claim one-to-one correspondence Nash equilibria gamesatisfying assignments . Indeed, let satisfying assignment xcombined strategy X1 , . . . , Xm players choose actions according .Then, x {Ts , Hg } Nash equilibrium G, players get maximumpayo.372fiPure Nash Equilibria: Hard Easy Gameshand, unsatisable, combined strategy x1 X1 , . . . , Xm ,(x1 ) false. case, H opposite interests easy check that,combined strategy x2 St({H , }), x1 x2 Nash equilibrium G,either H improve payo.Finally, observe dependency graph G(G) tree, hypergraphH(G) acyclic.2shown Figure 2, NP-hardness result immediately extends generalizations acyclicity. case acyclic-hypergraph games GNF dealtSection 4.Let us draw attention Pareto equilibria. Denition 2.2, Pareto Nashequilibrium exists Nash equilibrium exists. Therefore, Theorems 3.13.2, get following corollary.Corollary 3.3 Deciding whether game G Pareto Nash equilibrium NP-complete.Hardness holds even G fixed number actions either G graphical normalform k-bounded neighborhood, fixed constant k 3, G(G)H(G) acyclic.However, checking whether global strategy x pure Nash equilibriumtractable, turns checking whether x Pareto Nash equilibrium computationally hard task. fact, next show problem dicult checkingwhether x strong Nash equilibrium. However, see deciding existencestrong Nash equilibrium much harder, fact complete second levelPolynomial Hierarchy. end, following proofs, associate quantied BooleanFormulas two quantier alternations (2QBFs) games.Quantified Boolean Formulas (QBFs) games.=1 , . . . n1 , . . . qLetquantied Boolean formula disjunctive normal form, i.e., Boolean formulaform d1 . . .dm variables 1 , . . . n , 1 , . . . q , di conjunctionliterals. Deciding validity formulas well-known P2 -complete problem (e.g.Stockmeyer & Meyer, 1973), easy see hardness result holds evendisjunct dj contains three literals variable occurs three disjunctsmost. Moreover, without loss generality, assume number disjunctspower 2, say = 2 , integer 2. Note that, 21 < < 2 ,build polynomial time new QBF 2l disjuncts, one containingfresh existentially quantied variable negation. Clearly, disjuncts cannotmade true assignment, hence equivalent . Hereafter, considerquantied Boolean formulas form, call R2QBF. formula ,truth value assignment existentially quantied variables 1 , . . . , nformula 1 , . . . q () valid called witness validity .running example section, consider following QBF r :1 2 3 1 2 3 4 5 (1 2 ) (1 3 ) (1 1 ) (1 ) (2 3 ) (1 3 )(3 4 ) (5 ).373fiGottlob, Greco, ScarcelloFigure 7: left: dependency graph game Gr . right: truth-valueassignment r corresponding strong Nash equilibrium Gr .dene GNF game G associated R2QBF follows. players Gpartitioned sets Pe , Pu , Pd , Pt , singleton {C}.Players Pe , Pu , Pd correspond existential variables 1 , . . . n , universal variables 1 , . . . l , disjuncts , respectively. variable player vPe Pu may play truth value action {T, F } (read: {true, false}), neighbors(at three) players Pd corresponding disjuncts v occurs.disjunct player p may play action {T, F, w}, neighbors (atthree) players corresponding variables, plus one player belonging setPt , described below. shown Figure 7, disjunct players leavescomplete binary tree comprising players Pt intermediate vertices, playerC root. fact, tree players Pt act logical-or gates circuit. sakesimpler presentation, tree player p, children(p) denotes set two playerschildren p tree, parent(p) denotes parent. disjunct players, set available actions players Pt {T, F, w}. Finally, player C, calledchallenger, may play actions {T, w}. shown Figure 7, neighbors Ctwo top level tree-players.Let x global strategy. utility functions players G denedfollows.Existential-variables players. Pe ,(E-i) u (x) = 1, matter players do;Universal-variables players. Pu ,(U-i) u (x) = 2, exists (disjunct) neighbor playing w;(U-ii) u (x) = 1 cases.Disjuncts players. Pd ,374fiPure Nash Equilibria: Hard Easy Games(D-i) ud (x) = 2 parent (i.e., node Pt ) play w,disjunct corresponding made false truth-value actions xvariable players, i.e., players Neigh(d) (Pe Pu );(D-ii) ud (x) = 1 plays disjunct corresponding made truetruth-value actions x variable players;(D-iii) ud (x) = 1 plays F , disjunct corresponding made falsetruth-value actions variable players, parent node (a treeplayer) play w;(D-iv) ud (x) = 0, cases.Tree players. p Pt ,(TREE-i) (x) = 2 p neighbors play w;(TREE-ii) (x) = 1 p plays , none neighbors plays w, playerchildren(p) plays ;(TREE-iii) (x) = 1 p plays F , none neighbors plays w, playerschildren(p) plays F ;(TREE-iv) (x) = 1 p plays action {T, F }, neighbors playsw, them;(TREE-v) (x) = 0 cases.Challenger. player C,(CHALL-i) uC (x) = 2 C plays w, either neighbors play F ,least one plays w;(CHALL-ii) uC (x) = 1 C plays , neighbors plays , none playsw;(CHALL-iii) uC (x) = 0 cases.Intuitively, universal-variable players corresponding variables 1 , . . . q chooseactions trying falsify formula, since maximum payo 2 obtainedsatised. strategies variable players suitably evaluatedplayers Pd Pt , eventually C.worthwhile noting G built polynomial time (actually, LOGSPACE), player G may play three actions boundednumber neighbors. precisely, sake presentation, constructionplayer four neighbors. However, show later sectionbound reduced easily three.Let x global strategy G . denote (x) truth-value assignmentdetermined actions chosen variable players (i.e., Pe Pu )strategy x. Moreover, denote e (x) u (x) restriction existentialuniversal variables, respectively.Lemma 3.4 one-to-one correspondence among satisfying truth-value assignments Nash equilibria G player plays w.375fiGottlob, Greco, ScarcelloProof. Assume satisable, let satisfying truth-value assignment it.Consider following global strategy x G : variable player Pe Pu choosestruth-value action according ; disjunct player Pd plays either F , dependinglogical evaluation disjunct associated her; tree player p Pt playseither F , acting gate input values played children(p);player C plays . Note player chooses w x .Figure 7 shows right strategy G associated truth assignment1 = 2 = 3 = 1 = 2 = 3 = 4 = 5 = F .Since satisfying assignment, least one disjunct evaluated truethus least one tree-player neighbors C plays . Therefore, easycheck that, according utility functions G , players get payo 1 respectx . particular, follows rule (D-ii) (D-iii) disjunct players, rule(TREE-ii) (TREE-iii) tree players, rule (CHALL-ii) player C.Moreover, rules may increase payo 1 2 (TREE-i),(CHALL-i) (D-i). However, single player increase payo changingaction, rules may applied neighbor playingw, case x . follows global strategy x Nash equilibriumG .next prove converse, is, show Nash equilibrium x Gplayer chooses w corresponds satisfying truth-value assignment . proofbased following properties x:P1 : least one player Neigh(C ) play F . Otherwise, C would play w orderget payo 2, rule (CHALL-i), contradicting hypothesis x.P2 : least one player Pd plays . Otherwise, since player chooses w x,possible choice disjunct players would F . However, case, bestavailable choice tree-players depending disjunct players Pd play F ,according (TREE-iii). follows induction players Pt would play Fand, particular, neighbors C. However, contradicts property P1 x.P3 : satisfied truth-assignment (x). Let p Pd disjunct player plays, whose existence guaranteed property P2 . hypothesisplayer chooses w, rule (D-i) applicable p. follows disjunctioncorresponding player p true respect (x). Otherwise, x wouldNash equilibrium, p would get payo 0 (D-iv) could improveplaying correct evaluation F , rule (D-iii).Therefore, case player chooses w, global strategies Nash equilibriacorrespond satisfying assignments .2Lemma 3.5 Nash equilibrium x G player chooses w stronge (x) witness validity .Proof. () Assume x strong Nash equilibrium G player chooses w.Then, (x) satises , previous lemma. Assume contradiction e (x)witness validity . Then, assignment u universal variables376fiPure Nash Equilibria: Hard Easy Gamessatised respect e (x) u . Let K coalition comprisingplayers G existential players Pe , let combined strategy Kuniversal players Pu choose truth-value action according u ,players K play w. choice u , disjuncts made false viatruth-value actions chosen players Pu . Then, rule (D-i), disjunct players getpayo 2 according xK [y]. Similarly, (Tree-i) (Chall-i), tree-playersplayer C get payo 2 xK [y]. However, means players coalitionimproving payo, contradicts fact x strong Nash equilibrium.() Assume valid let (x) satisfying truth-value assignmente (x) witness validity , Nash equilibrium x G . Indeed,Lemma 3.4 know equilibrium (where player plays w) exists everysatisfying assignment, player chooses w x. Moreover, easy checkplayers get payo 1, according global strategy. Assume contradiction xstrong Nash equilibrium G . Then, coalition K combined strategyK players coalition may improve payo global strategyxK [y], hence get payo 2 strategy. Note existential player maybelong K thus change action, way improvepayo. Then, rule (Tree-i), way players Pt improve payo 2change actions w, rules require that,player, neighbors play w. Thus, one belongs K,belong coalition, well player C disjunct players Pd ,neighbors change choices w order get 2, too. hand,disjunct players p Pd , improvement 2 depends also variable playersoccurring disjunct associated p (D-i). particular, besides playing w,disjunct also made false, change choices universalplayers p depends on. Note players may turn improve payo 2, p playsw. follows coalition K shows x Nash equilibrium contains numberuniversal players able let disjunct players unsatised hencechange actions w, thus getting payo 2. However, truth-values correspondingactions players Pu K determine assignment u contradicts validity.2Theorem 3.6 Given game G global strategy x, deciding whether x SNE(G)(resp., x PNE(G)) co-NP-complete. Hardness holds even given strategy xpure Nash equilibrium, G graphical normal form 3-bounded neighborhood,number actions fixed.Proof. Membership. Deciding whether x PNE(G) NP: (i) check polynomialtime whether x NE(G); (ii) case, guess global strategy checkpolynomial time whether NE(G) dominates x. Similarly, deciding whetherx SNE(G) NP: (i) check polynomial time whether x NE(G); (ii)case, guess coalition players K combined strategy players K,check polynomial time whether players K increase payo playingactions according new strategy y.377fiGottlob, Greco, ScarcelloFigure 8: Transformation disjunct containing exactly three literals.Hardness. well-known checking whether satisable formula 3DNF tautologically valid co-NP complete. reduce problem problem checkingwhether given Nash equilibrium strong (Pareto). Let satisable formula3DNF. Find satisfying truth value assignment . obviously possiblepolynomial time, given satisable DNF. Dene = 1 , . . . q .considered (degenerate) R2QBF without existentially quantied variables. Let Ggame associated . Obviously, G constructed polynomial time. Let x Nash equilibrium G determined truth-value assignmentplayer chooses w, described Lemma 3.4, note even equilibriumcomputed polynomial time . Then, Lemma 3.5, x strongvalid (i.e., vacuous assignment e witness validity). settles hardnesschecking whether given Nash Equilibrium strong. addition, hard seeconstruction x Pareto equilibrium G tautology.Indeed, note that, truth-value assignment falsies ,global strategy (universal) variable players play accordingplayers choose w, dominates Nash equilibrium x. Thus checking whethergiven Nash equilibrium Pareto co-NP complete, too.conclude proof observing that, reduction, player Pe Pu Pt{C} depends three players most, player Pd may depend fourplayers, corresponding disjunct contains exactly three literals. case,may introduce additional player whose set actions {T, F, w} whose neighborsrst two literals plus d. Moreover, utility function actsAND-gate inputs literals, preferring w two literals evaluated false,plays w. new encoding, depends third literal occurringdisjunct. basic construction previously dened, payo 2 playsw, parent plays w, third literal false, plays w. Figure 8 showstransformation. Note construction preserves properties proved far,player depends three players most.2Deciding whether game strong Nash equilibrium turns muchdicult deciding existence pure (Pareto) Nash equilibria. Indeed, problemlocated second level polynomial hierarchy.Theorem 3.7 Given game G, deciding whether G strong Nash equilibrium P2 complete. Hardness holds even G graphical normal form 3-bounded neighborhood, number actions fixed.378fiPure Nash Equilibria: Hard Easy GamesProof. Membership. decide SNE(G) = guessing global strategy xverifying x strong Nash equilibrium G. Theorem 3.6, latter taskfeasible co-NP. follows problem belongs P2 .Hardness. Let = 1 , . . . n 1 , . . . q R2QBF. Recall deciding validityformulas P2 -complete problem see denition R2QBF above,current section.dene game G associated , obtained G addition onegadget. G fresh player depending player C only. calledduplicator, gets maximum payo plays actionchallenger player C. hand, also C depends new player D, besidestree-players neighbors (recall construction shown Figure 7). Cplay actions {T, w, u}. Everything else G , utility functionsplayers C D:Challenger. player C,(CHALL-i) uC (x) = 2 C play dierent actions {w, u} eithertree-players neighbors (i.e., players Neigh(C ) {D }) play F ,least one plays w;(CHALL-ii) uC (x) = 1 C plays , one player Neigh(C ) {D } plays ,none plays w;(CHALL-iii) uC (x) = 0 cases.Duplicator. player D,(DUPL-i) uD (x) = 1 plays action C;(DUPL-ii) uD (x) = 0 cases.Recall that, order maximize payos, universal-variable players trymake false, strategies variable players suitably evaluated playersPd Pt , acting Boolean circuit. Moreover, challenger duplicatordesigned way strategies player chooses w, correspondsatisfying assignments , cannot lead Nash equilibria. Formally, Nashequilibrium G , following properties hold.P1 : least one player Neigh(C ){D } play F player Neigh(C ){D }plays w. Otherwise, C would play action {w, u} dierent one playedx, order get payo 2, rule (CHALL-i). However, strategycannot equilibrium, could improve payo choosingaction C x.P2 : player Pd Pt plays w players Pd Pt play w. Indeed, let pplayer Pd Pt playing w assume contradiction player qPd Pt play w. W.l.o.g., assume q Neigh(p)viceversa. Then, p gets payo 0, could increase payo playing action{T, F } according (D-ii) (D-iii) players Pd , (TREE-ii), (TREE-iii)(TREE-iv) players Pt . contradicts fact x Nash equilibrium.379fiGottlob, Greco, ScarcelloP3 : player Pd Pt plays w. Otherwise, P2 , players Pd Pt play w and,particular, players Neigh(C ) {D }. However, possible,property P1 .Therefore, rule (Chall-i) applicable C respect x. However,properties least one tree-players neighbors play C playturn get payo 1, rule (Chall-ii). Then, may play get payo 1,well. Thus, longer possible Nash equilibrium player choosingaction w. Therefore, Lemma 3.5 (as presence duplicator aectproof), get following fundamental result: global strategy x strong Nashequilibrium G truth-value assignment e (x) witness validity. particular, SNE(G ) = valid.Finally, observe even game G modied shown Figure 8, orderget 3-bounded neighborhood game.2next show that, game given general form, hardness result holdseven structure player interactions simple.Theorem 3.8 Deciding whether game G general form strong Nash equilibriumP2 -complete, even dependency graph associated hypergraph acyclic,number actions fixed.Proof. proof membership P2 membership proof previoustheorem. next prove problem hard P2 .Let = 1 , . . . n 1 , . . . q quantied Boolean formula disjunctivenormal form. dene game G players 1 , . . . n , 1 , . . . q correspondingexistentially universally quantied variables , two additional playersH. game based combination game techniques exploited proofsTheorem 3.2 Theorem 3.7. player associated variable two availableactions, f , represent truth assignments corresponding variable ;actions player u, read satised unsatised,actions player H g b, read good bad, respectively.Given combined strategy x, denote (x) evaluation truth valuesdetermined strategy x. Then, utility functions dened follows. player(1 n) gets always payo 1. player j (1 j q) depends getspayo 1 plays x, payo 2 plays u x. Player H dependsgets payo 1 x contains either {Ts , Hg } {Tu , Hb }, 0, otherwise. Finally, playerdepends players {1 , . . . n , 1 , . . . q , H}, utility function dened follows:uT (x) = 2, (x) false, plays u, H plays g;uT (x) = 1, (x) true plays s, (x) false, plays s, H plays b;uT (x) = 0, otherwise.First, observe dependency graph dependency hypergraph Gacyclic. Moreover, proof Theorem 3.2, easy see oneto-one correspondence Nash equilibria game satisfying assignments380fiPure Nash Equilibria: Hard Easy Games. Then, Nash equilibrium x G , denote x corresponding truth-valueassignment, ex restriction assignment existential variables .Note that, shown mentioned proof, Nash equilibrium, player playsplayers game get payo 1.next prove witness validity corresponds strong Nash equilibrium G . Let x Nash equilibrium consider coalition K playersdeviate x, leading new prole x . denition game, waycoalition get payo higher 1 changes choice u.case, (x ) false (and H plays g), get payo 2. Since true respectx, follows variable players change choices, meansbelong coalition improve payos. Therefore, variable playersK correspond universally quantied variables, players ableimprove payos 1 2. Thus, coalition K existsuniversally quantied variables make formula false, is, ex witnessvalidity . Equivalently, follows x strong Nash equilibriumvalid.2Remark 3.9 Recall assumed general game G taken class Ck .worthwhile noting that, games without restriction player interactions,hardness results hold games utility functions computable constant time,too. Namely, consider Theorems 3.1, 3.6, 3.7. constructions, playerthree neighbors fixed number actions. Therefore, utility functionplayer computable constant time.4. Easy Gamesdeal tractable games graphical normal form (GNF), let us recallcomputational problems dealt paper tractable games standardnormal form (SNF), even arbitrary interactions among players. Actually, next pointcarried logarithmic space thus low complexityclass contains highly parallelizable problems only. surprising,fact size SNF games may exponentially larger size gamesencoded GNF.Theorem 4.1 Given game standard normal form, following tasks feasiblelogarithmic space: Determining existence pure Nash equilibrium, pure Paretoequilibrium, strong Nash equilibrium, computing equilibria.Proof. Let P , usual, denote set players. assume w.l.o.g. playerleast two possible actions (in fact, player single action eliminatedgame simple logspace transformation, yielding equivalent game). sizeinput matrix thus least 2|P | .Given possible global strategies explicitly represented, correspondingtable cell (which indexed logarithmic space size input,corresponds polynomial space |P | |A|, P sets players381fiGottlob, Greco, Scarcelloset possible actions, respectively), Nash equilibria easily identied scanning(i.e., enumerating) global strategies x keeping logspace index x worktape,checking logarithmic space (in size input) whether player improveutility choosing another action. Given Nash Equilibria generatedlogarithmic space, also generated polynomial time.Pareto equilibria identied successively enumerating Nash equilibriax, additional loop x, enumerating Nash equilibria (indexedlogarithmic space above) outputting x that, p P , (y) >(x). latter condition tested means simple scan players.Strong Nash equilibria identied enumerating Nash equilibria scanning possible coalitions players (which indexed logarithmic space,number 2|P | ) order discard equilibria x exists coalitionK P combined strategy K, p K, (x) < (xK [y]).Finally, note that, xed coalition K, enumeration combined strategiesK carried means additional nested loop, requiring logarithmic spaceindexing strategy.24.1 Constraint Satisfaction Problems Games Graphical Normal FormLet us consider games GNF. rst establish interesting connectionconstraint satisfaction problems games. instance constraint satisfaction problem(CSP) (also constraint network) triple = (Var , U, C), Var nite set variables, U nite domain values, C = {C1 , C2 , . . . , Cq } nite set constraints.constraint Ci pair (Si , ri ), Si list variables length mi calledconstraint scope, ri mi -ary relation U , called constraint relation. (Thetuples ri indicate allowed combinations simultaneous values variables Si ).solution CSP instance substitution : Var U , 1 q,Si ri . problem deciding whether CSP instance solution called constraint satisfiability (CS). Since interested CSPs associated games,variables players games, use interchangeably terms variable player,whenever confusion arises.Let G = P, Neigh, A, U game p P player. Dene Nash constraintNC (p) = (Sp , rp ) follows: scope Sp consists players {p} Neigh(p),relation rp contains precisely combined strategies x {p} Neigh(p)yp St(p) (x) < (xp [yp ]). Thus note that, Nash equilibriumx G, x St(Sp ) rp .constraint satisfaction problem associated G, denoted CSP (G), triple(Var , U, C), Var = P , domain U contains possible actions players,C = {NC (p) | p P }, i.e., set Nash constraints players G.Example 4.2 constraint satisfaction problem associated FRIENDS game({F, G, R, P, }, {m, o}, C), set constraints contains exactly following Nashconstraints: NC (F ) = ({F , P , R}, rF ), NC (G) = ({G, P , F }, rG ), NC (R) = ({R, F }, rR ),NC (P ) = ({P , F }, rP ), NC (M ) = ({M , R}, rM ), constraint scopes shownFigure 9.2382fiPure Nash Equilibria: Hard Easy GamesrF :FPRrG :G0PFrR :RFrM :PrP :FRFigure 9: Constraint relations game FRIENDS Example 2.1.structure constraint satisfaction problem = (Var , U, C) representedhypergraph H(I) = (V, H), V = Var H = {var (S) | C = (S, r) C}, var (S)denotes set variables scope constraint C. Therefore, denitionCSP (G), hypergraph game G coincides hypergraph associatedconstraint satisfaction problem, thus structural properties.following theorem establishes fundamental relationship games CSPs.Theorem 4.3 strategy x pure Nash equilibrium game Gsolution CSP (G).Proof. Let x Nash equilibrium G let p player. Then, strategypa St(p), (x) (xp [pa ]). Since depends players {p} Neigh(p),combined strategy x x tuple NC (p), construction. followssubstitution assigning player p individual strategy pa x solution CSP (G).hand, consider solution CSP (G), let p player. LetP = {p} Neigh(p) x combined strategy {(q) | q P }. Then, x tupleNC (p), solution CSP (G). Thus, p, denition NC (p),individual strategy p increase utility, given strategiesplayers. follows global strategy containing (p) player p Nashequilibrium G.2following theorem states feasibility computation CSP (G).Theorem 4.4 Let G game small neighborhood graphical normal form.Then, computing CSP (G) feasible polynomial time.Proof. Let G = P, Neigh, A, U game small neighborhood. showNC (p) = (Sp , rp ) computed polynomial time. initialize rp combined strategies {p} Neigh(p). number combined strategies bounded|Neigh (p)| )2 i(G)log(||G||) = ||G||i(G) ,maxAct (G)|Neigh(p)| = 2 log(maxAct (G)intricacy (G) G givenmaxNeigh(G) log maxAct(G).log ||G||383fiGottlob, Greco, ScarcelloFunction NashEvaluation(JT : join tree H(G)): BooleanbeginBottom-Up(JT );let v = (Sv , rv ) root JT ;rv = return false;elseTop-Down(JT );Select-equilibrium(JT );output JT ;return true;end;Procedure Bottom-Up(var : tree)beginDone := set leaves ;v(i) v Done,(ii) {c | c child v} Donec = (Sc , rc ) child vrv := rv rc ;Done := Done {v};endend;Procedure Top-Down(var : tree)beginlet v = (Sv , rv ) root ;c = (Sc , rc ) child vrc := rc rv ;let Tc subtree rooted c;Top-Down(Tc );endend;Figure 10: Evaluation acyclic game.Since G small neighborhood, i(G) bounded constant, thus setcombined strategies p polynomially bounded. initialization process computesp corresponding combined strategies (via simple enumeration), thus takespolynomial time (in size G).Now, tuple x rp check whether kept rp not. Let= (x). action Act(p), compute polynomial time = (xp [pa ])delete x > m. follows CSP (G) computed polynomial time G.similar line reasoning applies G GNF. case, utility functionsexplicitly given input tabular form, thus computation Nash constraintsyet easier. fact, task feasible logspace GNF games.2Theorem 4.3, acyclic-hypergraph game G small neighborhoodgraphical normal form solved polynomial time. Indeed, G CSP (G)hypergraph and, shown Gottlob et al. (2000), solution acyclic constraintsatisfaction problem computed (a slight adaptation of) well known Yannakakiss algorithm evaluating acyclic conjunctive queries (Yannakakis, 1981),LOGCFL algorithm proposed Gottlob et al. (2000), shows problem highlyparallelizable see Section 6, information complexity class LOGCFL.sake completeness, Figure 10, report algorithm deciding existenceNash equilibrium computing Nash equilibria acyclic-hypergraph games, basedresults. assume reader familiar typical database operations likesemi-joins (for details, see, e.g., Maier, 1986).algorithm takes input join tree JT H(G). small abuse notation,vertex JT , formally hyperedge Hv associated player v, alsoused denote player well Nash constraint (Sv , rv ) associated v.384fiPure Nash Equilibria: Hard Easy GamesProcedure Select-equilibrium(var : tree)beginlet v = (Sv , rv ) root ;select combined strategy tv rv s.t. tv rv , uv (tv ) uv (tv );delete tuples rv , tv ;c = (Sc , rc ) child vrc := rc rv ;let Tc subtree rooted c;Select-equilibrium(Tc );endend;Figure 11: Selection (Pareto) Nash equilibrium acyclic game.algorithm consists two phases. rst bottom-up phase, constraint relationrv node v = (Sv , rv ) JT ltered means semijoin constraintrelation rc (denoted rv rc ) children c JT . semijoin eliminatestuples rv corresponding combined strategies players P = (Neigh(c){c}) (Neigh(v ) {v })) available (or longer available) rc .way, tuples corresponding strategies match hence cannot leadNash equilibria deleted, starting leaves. Finally, either root emptyhence G equilibria, tuples remaining root p encode strategiesp may choose Nash equilibria game. top-down phase, propertyroot propagated tree taking semi-join every vertexchildren. end, get tree tuples encode strategies belonging Nashequilibria and, vice versa, Nash equilibria made strategies relations storedJT . Then, standard techniques developed acyclic database queries CSPs,compute JT Nash equilibria G backtrack-free way, thus timepolynomial combined size input game equilibria output. Notebest do, game may exponential number equilibria.completeness, Figure 11 shows Procedure Select-equilibrium, selects JTone Nash equilibrium. similar Procedure Top-Down, selection stepsemi-joins: vertex, Select-equilibrium rst picks combined strategy tv rv ,deletes tuples rv , performs semi-joins children callsrecursively, propagate choice tv towards leaves tree. Noteselection tv may arbitrary, previous bottom-up top-down steps. However,Figure 11 select strategies giving best payos, order get Nash equilibriumcannot dominated Nash equilibrium.Theorem 4.5 Deciding existence pure Nash equilibria, well computing Nashequilibrium feasible polynomial time classes C acyclic-hypergraph gamesevery game G C small neighborhood graphical normal form.discussion, immediately follows tractability resultextended problem computing Pareto Nash equilibrium.Theorem 4.6 Deciding existence Pareto Nash equilibria, well computingPareto Nash equilibrium pure strategies feasible polynomial time classes C385fiGottlob, Greco, ScarcelloFunction InCoalitionx,J (Hp : vertex, st: combined strategy): booleanbeginlet (Sp , rp ) constraint associated player p N + = {p} Neigh(p);guess tuple st rp st matches st players common;ps strategy st dierent strategy x (xN + [st ]) (x)return false;elselet Kp set children Hp join tree JT ;Kp =return true;elsereturn H Kp InCoalitionx,J (Hp ,st );pendend.Figure 12: Algorithm deciding existence coalition improving x.acyclic-hypergraph games every game G C small neighborhoodgraphical normal form.Proof. Recall Procedure Select-equilibrium Figure 11, vertex v encounteredvisit JT , select combined strategy guarantees player corresponding v maximum payo available choices (that, point,strategies may lead Nash equilibria). particular, payo rstplayer evaluated, say root p, cannot worse payo pavailable strategy. Thus, tuples left JT procedure encode Pareto Nashequilibrium G, cannot strictly dominated Nash equilibrium.sake completeness, point that, dierently previous caseplain Nash equilibria, JT cannot compute easily Pareto Nash equilibriagame input-output polynomial time.2One may thus wonder whether result holds strong Nash equilibria, too.Unfortunately, next show computing Strong Nash equilibrium dicult problemeven case acyclic interactions among players. However, complexity reducedone level respect arbitrary interaction case, checking whether givenequilibrium strong feasible polynomial time acyclic case.Lemma 4.7 Let G acyclic-hypergraph game small neighborhoodgraphical normal form, let x global strategy. Then, deciding whether x SNE(G)feasible polynomial time.Proof. Since G small neighborhood graphical normal form, Theorem4.4 build polynomial time constraints associated player. Moreover,hypergraph H(G) acyclic thus join tree. Let JT join tree H(G).show use JT deciding polynomial time whether strategy xSNE(G), i.e., exists coalition C players getting incentive deviatetogether x. Then, result follows PTIME closed complementation.Specically, next show implementation task alternating Turing machinelogarithmic-space working tape. Therefore, problem ALOGSPACE,equal PTIME (Chandra, Kozen, & Stockmeyer, 1981).386fiPure Nash Equilibria: Hard Easy Gamesmachine deciding whether x strong Nash equilibrium works follows:guess player q;guess strategy stq q dierent choice x;root tree JT vertex corresponding characteristic edge Hq player q;check InCoalition x,JT (Hq , stq ) returns true, InCoalition x,JT Booleanfunction shown Figure 12.Intuitively, non-deterministic Turing machine rst chooses player q belongingpossible coalition C disproving x. Thus, q improve payo, generalunless x strong Nash equilibrium, getting improvement may requireneighbors Kq deviate x hence belong C. However, case, playersKq able improve payos. Again, that, involveplayers coalition, on.Whether process successful checked recursive Boolean functionInCoalition x,JT , takes input vertex Hp join tree JT combinedstrategy st. Recall vertex join tree (hyper)edge hypergraph,corresponding player G. particular, Hp characteristic edge player p.InCoalition x,JT check whether players deviating given global strategy xable improve payos. rst call function, rst parameter Hqroot JT identies rst player q chosen coalition C. secondparameter st strategy chosen q, dierent qs corresponding choicex. generic recursive call, rst parameter Hp identies player p checked,second parameter st encodes combined strategy player w associatedparent Hw Hp JT ws neighbors. Now, function checkeither p change choice respect x, changes improvespayo. end, function guesses tuple st rp , rp constraint relationassociated p. Then, st encodes combined strategy p neighbors.strategy match parameter st players common, stcontains actions already chosen algorithm parent Hw Hpevaluated. Then, ps choice st dierent ps choice x, means pnon-deterministically chosen member coalition C. Thus, p improvepayo, immediately causes fail computation branch nondeterministicTuring machine. Otherwise, is, p plays action x,belong C function check, recursively, rest join treedeviating players improve payos. done propagating current combinedstrategy st children Hp JT . Observe propagation necessary evenp belong C, connected coalitions necessarily induce connectedsubtrees JT . Indeed, may happen player z belonging coalitionneighbor p w, characteristic edge Hz occurs far Hw jointree, possibly subtree JT rooted p. (For sake completeness, notecase z neighbor players occurring path Hz Hw JT ,connectedness property join trees.)387fiGottlob, Greco, ScarcelloFigure 13: left: dependency graph game G(s ). right: coalitionwitnessing c5 c7 playing conicting way.Finally, let us consider briey low-level implementation alternating Turingmachine . Existential states correspond guesses, universal states correspondrecursive calls InCoalition x,JT , plus machinery auxiliary computations. step, encode worktape two parameters p stlocal variables, x, JT , game G pre-computed constraint relationsinput tape. Note p may encoded logspace pointer positioninput tape, well combined strategy stw may encoded logspace pointercorresponding entry constraint relation associated w. Similar considerationsapply local variables, e.g., guessed combined strategy st . Moreover,easy check computations performed function feasible logspace.Therefore logspace ATM, overall computation PTIME. (For detaileddescription logspace ATM computations, refer interested reader Gottlobet al., 2001; Gottlob, Leone, & Scarcello, 2002a).2Theorem 4.8 Let G acyclic-hypergraph game small neighborhoodgraphical normal form. Then, deciding whether G strong Nash equilibria, i.e., SNE(G) =NP-complete. Hardness holds even G graphical normal form 3-boundedneighborhood.Proof. Membership. Given game G, guess global strategy x verifypolynomial time, Lemma 4.7, x fact strong Nash equilibrium.Hardness. reduction SAT. Consider Boolean formula conjunctive normalform = c1 . . . cm variables X1 , . . . , Xn assume, w.l.o.g, = 2 ,> 0. running example, consider formula = (X1 X2 ) (X1 X3 ) (X1X4 X8 ) (X4 ) (X5 X6 ) (X1 X4 X6 ) (X6 X7 ) (X8 )., build following GNF game G(). players partitioned twosets Pc Pt . set Pc contains exactly one player clause , playersPt G(G) complete binary tree, whose leaves players Pc ,shown Figure 13 .388fiPure Nash Equilibria: Hard Easy GamesPlayers G() play actions corresponding variables plus specialactions. Intuitively, player c Pc may play literal occurring clauserepresents, players Pt check pair players ci , cj Pc playsconicting way, is, plays complementary literals. end, game rulesdesigned way players Pt may improve payos ableform coalition proving pair players playing complementary literals.worthwhile noting that, general, situation cannot detected single player,since conicting clauses may far other. instance, Figure 13, c5c7 play x6 x6 , respectively, detected coalition involving lowestcommon ancestor, say p, players Pt occurring two paths c5 c7p. show global strategy strong Nash equilibrium gamedisproving coalition. Indeed, case, conicting clausesthus formula satisable setting true literals played clauseplayers.Formally, player c Pc may play either special action B (read: bad) actionxi (resp. xi ) called literal action, provided Xi variable occurring positively (resp.negatively) corresponding clause . player Pt may play action{vi , wi , wi | Xi variable } {T }, read okay me!next describe utility functions, given global strategy x.player c Pc gets payo 1 plays literal action unique neighbor (i.e.,parent) plays , plays B neighbor play (C-i); otherwise,gets payo 0 (C-ii).player Pt , utility function ut that:(T-i) ut (x) = 2 plays wi , parent (if any) plays wi vi , none children playsB, one children plays either wi xi (depending whether leafnot);(T-ii) ut (x) = 2 plays wi , parent (if any) plays wi vi , none children playsB, one children plays either wi xi ;(T-iii) ut (x) = 2 plays vi , parent (if any) plays , children play either xixi wi wi ;(T-iv) ut (x) = 1 plays ;(T-v) ut (x) = 0 cases.Then, G() following properties.P1 : Let x global strategy G(). Then, x Nash equilibriumplayers Pt play x player Pc playing B.players Pt play players Pc play B, get payo 1 duerules (T-iv) (C-i). case, player incentive deviate, sincechanging strategy would get payo 0 due rules (T-v) (C-ii).direction proof, let x Nash equilibrium assume,contradiction, player c Pc choosing B. (C-i) (C-ii),389fiGottlob, Greco, Scarcellofollows neighbor c, say t, play . However, impossible,would get payo 0 (from T-v) could improve payo playing ,contradicting fact x Nash equilibrium. Next, assume exists playerPt play , let Pt player lowest possible leveltree satisfying assumption. follows children clause players,otherwise, choice t, play , thus would getpayo 0 (T-V) could improve 1 playing . Therefore, Neigh(t) Pc = .Then, way get payo greater 0 comes rule (T-iii),means clause children play conicting way, say xi xi . However, sinceplay , get payo 0 thus could deviate x playing Bgetting payo 1. Contradiction.P2 : Let x Nash equilibrium G(). Then, coalition players getting incentivedeviate x exists two clauses playing x conflictingway.(If part.) Since x Nash equilibrium, Property P1 , players Pt playget payo 1. two clauses, say c1 c2 , playing xi xi , respectively,may identify improving coalition follows: let rst common ancestorc1 c2 , let P1 P2 sets vertices (players) occurring pathsc1 c2 , respectively. Then, let change vi , players P1(resp. P2 ) change wi (resp. wi ) x see Figure 13. Then, game rulesabove, players coalition K = P1 P2 {t} get payo 2, improving payo1 get x.(Only-if part.) Let K coalition players improving Nash equilibrium x.property P1 , players Pt K get payo 2, get 1 x. LetK player Pt highest (close root) level tree, i.e.,parent(t), any, belong K. (T-iii), children must playeither xi xi wi wi , depending whether leavestree. former case, identied two conicting players thusproperty immediately proved. Hence, let us investigate latter one. Letchildren playing wi wi , respectively. Since play ,belong K improve payo 2. Therefore, child mustplay wi child must play wi , according (T-i) (T-ii). Therefore,players belong K, too, happen children. Eventually,leaf descendant plays xi leaf descendant plays xi , qed.NP hardness deciding existence SNE follows following claim:satisable G() admits strong Nash equilibrium.() Assume satisable take satisfying assignment . Let x globalstrategy that: player c Pc plays literal occurring clause c truerespect ; player Pt plays . P1 , x Nash equilibriumG(). Moreover, construction pair players choose conicting actions x . Hence,due P2 , exists coalition players getting incentive deviating x ,thus x strong. () Let x strong Nash equilibrium G(). Then,coalition players getting incentive deviate x. Due P1 , player Pc390fiPure Nash Equilibria: Hard Easy Gamesplays B, due P2 pair players play conicting way. Hence, x witnessessatisable. precisely, encodes implicant , extendedsatisfying assignment choosing truth value Boolean variables occurringchosen player x.25. Structurally Tractable Classes Gamesstrategic games, acyclic graph acyclic hypergraph assumptionssevere restrictions, rather unlikely apply practical contexts.section, prove even general structurally complicated classes gamesdealt ecient way. consider notions treewidth (Robertson &Seymour, 1986) hypertree width (Gottlob et al., 2002b), broadest knowngeneralizations graph hypergraph acyclicity, respectively (Gottlob et al., 2000).show tractability results acyclic games hold generalizations, too, studyrelationship two notions.5.1 Hypertree Decompositions GamesLet H = (V, E) hypergraph. Denote vert(H) edges(H) thesets V E,respectively. Moreover, set edges E edges(H), let vert(E ) = h.hypertree hypergraph H triple T, , , = (N, E) rootedtree, labeling functions associate vertex p N twosets (p) vert(H) (p) edges(H). = (N , E ) subtree , dene(T ) = vN (v). denote root root(T ). Moreover, p N , Tpdenotes subtree rooted p.Definition 5.1 (Gottlob et al., 2002b) hypertree decomposition hypergraph Hhypertree HD = T, , H, = (N, E), satises followingconditions:1. edge h edges(H), exists p N vert(h) (p) (we sayp covers h);2. vertex vert(H), set {p N | (p)} induces (connected) subtree;3. p N , (p) vert((p));4. p N , vert((p)) (Tp ) (p).edge h edges(H) strongly covered HD exists p N vert(h)(p) h (p). case, say p strongly covers h. hypertree decompositionHD hypergraph H complete decomposition H every edge H strongly coveredHD. width hypertree decomposition T, , maxpvertices(T ) |(p)|.hypertree width hw(H) H minimum width hypertree decompositions.Note constant k checking whether hypergraph hypertree-widthk feasible polynomial time (Gottlob et al., 2002b).391fiGottlob, Greco, ScarcelloG{F,L,G,M,P,R} {HF, HL}FPR{F,G,P} {HG}{F,M,P,R} {HM, HR}LL{F,P} {HP}Figure 14: H(FRIENDS) hypertree decomposition it.Let k > 0 xed constant. Then, say game G k-bounded hypertreewidth hypertree width associated hypergraph H(G) k. hypertreedecomposition width k (if any) computed polynomial time.Recall notion bounded hypertree-width generalizes notion (hypergraph) acyclicity. particular, class acyclic-hypergraph games precisely classgames G whose hypergraph H(G) hypertree width 1.Example 5.2 Consider game FRIENDS Example 2.1. Figure 5 showsleft associated hypergraph, right join tree it. fact, join treehypertree decomposition width 1 hypergraph, where, vertex p, (p)set hyperedges reported p (p) set players occurring hyperedges.involved example, consider extension FRIENDS FRIENDSnew player Laura (short: L) joins group. Laura would like go Georgecinema, Pauline Mary opera. Figure 14 shows left hypergraph H(FRIENDS). hypergraph acyclic, low degree cyclicity.Indeed, hypertree width 2, witnessed hypertree decomposition width 2shown right, Figure 14. Here, vertex p decomposition tree, twosets denote labels (p) (p), respectively.2class games C said bounded hypertree-width nite kthat, game G C, G k-bounded hypertree width. next showtractability results hold acyclic-hypergraph games holds bounded hypertreewidth games, well.Theorem 5.3 Deciding existence pure Nash equilibria, well computing Nashequilibrium feasible polynomial time classes C games bounded hypertreewidth every game G C small neighborhood graphical normalform.Proof. Let C class games game G C hypertree-widthk, k > 0, small neighborhood graphical normal form. Then,build constraint satisfaction problem CSP (G) polynomial time, Theorem 4.4.392fiPure Nash Equilibria: Hard Easy GamesMoreover, hypertree width G k, hypergraph H(G)hypergraph H associated CSP (G). results Gottlob et al. (2001), followsCSP (G) solved polynomial time, equivalent deciding existenceNash equilibria polynomial time, Theorem 4.3.Constructively, compute polynomial time hypertree decomposition H width k, exploit decomposition building equivalent acyclic problem(by putting together constraints players occurring vertex decomposition tree), nally solve problem using algorithm shown Figure 10. 2acyclic-hypergraph games, result immediately extended problemcomputing Pareto Nash equilibrium.Corollary 5.4 Deciding existence Pareto Nash equilibria, well computingPareto Nash equilibrium pure strategies feasible polynomial time classesC games bounded hypertree-width every game G C smallneighborhood graphical normal form.5.2 Treewidth Hypertree Width Gamesnext consider treewidth game structures. Recall game may represented either primal graph dual graph, shown Figure 5 gameFRIENDS. Therefore, rst question graph better far identicationtractable classes games concerned. results Gottlob et al. (2000), knownotion bounded treewidth primal graph generalized notionbounded hypertree width, is, looking hypertree width game hypergraphmay identify wider classes tractable games. Moreover, results GrecoScarcello (2003), follows looking treewidth dependency graph betterlooking treewidth primal graph.4thus know bounded treewidth primal graph sucient ensuringgame tractability. However, two questions still answered, subjectsection:1. tractability results bounded treewidth primal graph extend widerclass games bounded treewidth dependency graph?2. relationship bounded treewidth dependency graphbounded hypertree width game hypergraph?Definition 5.5 (Robertson & Seymour, 1986) tree decomposition graph G =(V, E) pair T, , = (N, F ) tree, labeling function assigningvertex p N set vertices (p) V , following conditionssatised:(1) vertex b G, exists p N b (p);4. fact, result relationship primal graph incidence graph. However, easysee that, games, treewidth incidence graph treewidth dependencygraph.393fiGottlob, Greco, ScarcelloGFP{F,L,P,R}R{L,P,R,M}L{F,G,L,P}Figure 15: G(FRIENDS) tree decomposition it.(2) edge {b, d} E, exists p N {b, d} (p);(3) vertex b G, set {p N | b (p)} induces connected subtree .Note Condition 1 subsumed Condition 2 graphs without isolated vertices.width tree decomposition T, maxpN |(p) 1|. treewidth Gminimum width tree decompositions. notion generalizes graph acyclicity,acyclic graphs precisely graphs treewidth 1. 5Example 5.6 Consider game FRIENDS introduced Example 5.2. Figure 15 shows left cyclic dependency graph G(FRIENDS), righttree decomposition width 3 graph.2Let k > 0 xed integer, let G game. say game G k-boundedtreewidth treewidth dependency graph G(G) k. Recall that, givengraph G, computing tree-decomposition width k G (if any) feasiblepolynomial (actually, linear) time (Bodlaender, 1997).next prove interesting graph-theoretic result shed light dierentpossible representations game structures: every class games bounded treewidthbounded hypertree width, too. remark previous results relationshiptreewidth hypertree width described literature (e.g. Gottlob et al.,2000) cannot used here. Indeed, deal primal graph dual graphrepresentations, interested dependency graph, eectiveprimal graph, somehow incomparable (optimal) dual graph.detailed comparison two latter notions reported Greco Scarcello (2003).Theorem 5.7 game G, hypertreewidth (H(G)) treewidth(G(G)) + 1.Proof. Let TD tree decomposition G(G) let k 1 width, is,largest label vertices TD contains k players. Then, showhypertree decomposition H(G) width k. Recall H(G) contains, player5. Observe 1 definition treewidth introduced order get correspondence acyclic graphs, 2 minimum cardinality largest label tree decomposition.394fiPure Nash Equilibria: Hard Easy Gamesp, characteristic edge H(p) = {p} Neigh(p). Let HD = T, , hypertreethat:tree form decomposition tree TD, i.e., treeisomorphism : vert(T ) vert(T D) TD;vertex v , (v) = {H(p) | p (v)}, i.e., (v) contains characteristicedge player occurring vertex tree decomposition correspondingv;(v) set vertices occurring edges (v), i.e., contains players(v) neighbors.Note width HD k, determined largest label, containsnumber elements largest label TD.claim HD hypertree decomposition H(G). Consider four conditionsDenition 5.1: Conditions 3 4 trivially satised because, vertex v,(v) = vert((v)), construction. Condition 1 guaranteed fact TD satisescorresponding Conditions 1 2. next show Condition 2, i.e., connectednesscondition, holds, too.Let v1 v2 two vertices exists p (v1 )(v2 ). Let v1 = (v1 )v2 = (v2 ) sets vertices tree decomposition TD corresponding v1v2 , respectively. Since p (v1 ) p (v2 ), two players p1 p2 (i)H(p1 ) (v1 ) p H(p1 ), (ii) H(p2 ) (v2 ) p H(p2 ). Then, construction,p1 v1 p2 v2 (see Figure 16).claim that, vertex v unique path connecting v1 v2 (denotedv1 v2 ), (v) contains player set {p1 , p2 , p}, entails p (v)hence Condition 2 satised HD. equivalent claim, treedecomposition TD, vertex v path v1 v2 contains player {p1 , p2 , p}.v1 v2 contain p, claim trivially holds verticespath v1 v2 must contain p, Condition 3 tree decompositions (the connectednesscondition).Hence, let us assume v1 contain p. Since p H(p1 ), means pneighbor p1 thus exists vertex TD, say v3 = v1 , whose labeling containsp p1 . Assume v2 contains p. Figure 16.1 shows path comprisingvertices v1 , v3 , v2 notice v1 cannot path v3 v2 , otherwisecontain p well. result follows observing that, Condition 3 treedecompositions, vertices path v1 v3 must contain p1 , verticespath v3 v2 must contain p. Similarly, assume v2 contain p. case,since p neighbor p2 (recall discussion p1 ), vertex v4 TDwhose labeling contains p2 p. Figure 16.2 shows vertices looklike tree decomposition TD. Then, result follows observing verticespath v1 v3 contains p1 , vertices path v3 v4 contains p, vertices2path v4 v2 contains p2 .next show converse hold, is, classes gamesbounded hypertree width, unbounded treewidth. is, technique based395fiGottlob, Greco, ScarcelloFigure 16: Schema reduction proof Theorem 5.7.hypertree width game hypergraph eective corresponding techniquebased treewidth dependency graph, allows us identify strictlybroader classes tractable games.Theorem 5.8 classes C games hypertree width 1 unboundedtreewidth, i.e., that, finite k > 0, game G C treewidthG bounded k.Proof. Take class games every player depends players.every game G, H(G) acyclic thus hypertree width 1, G(G) cliquecontaining players treewidth number players minus 1.2396fiPure Nash Equilibria: Hard Easy GamesTheorem 5.3, Corollary 5.4, Theorem 5.7, immediately get followingtractability results bounded treewidth games.Corollary 5.9 Deciding existence pure (Pareto) Nash equilibria, well computing pure (Pareto) Nash equilibrium feasible polynomial time classes Cgames bounded treewidth every game G C small neighborhoodgraphical normal form. Moreover, Nash equilibria games computedtime polynomial combined size input output.6. Parallel Complexity Easy Gamessection, show dealing Nash equilibria games good structuralproperties tractable also parallelizable. precisely, show decidingexistence Nash equilibria graphical games player interactions lowdegree cyclicity complete class LOGCFL. Also, show computingequilibrium belongs functional version LOGCFL.complexity class LOGCFL consists decision problems logspace reducible context-free language. order prove following theorem, exploitcharacterization LOGCFL terms circuits.recall Boolean circuit Gn n inputs nite directed acyclic graph whosenodes called gates labeled follows. Gates fan-in (indegree) zero calledcircuit input gates labeled set {false, true, z1 , z2 , . . . , zn , z1 , z2 , . . . , zn }.gates labeled either AND, OR, NOT. fan-in gates labeled mustone. unique node fan-out (outdegree) zero called output gate. evaluationGn input string w length n dened standard way. particular, inputgate g labeled zi (resp. zi ) gets value true (resp. false) ith bit w 1 (resp. 0);otherwise, g gets value false (resp. true).Boolean circuit thus given triple (N, A, label), N set nodes(gates), set arcs, label labeling nodes described.depth Boolean circuit G length longest path G circuitinput gate output gate G. size S(G) G number gates (includinginput-gates) G.family G Boolean circuits sequence (G0 , G1 , G2 , . . .), nth circuit Gnn inputs. family logspace-uniform exists logspace Turing machinewhich, input string containing n bits 1, outputs circuit Gn . Note sizenth circuit Gn logspace-uniform family G polynomial n. Intuitively,uniformity condition crucial characterizations low parallel complexity classes termscircuits, hidden inherent sequentialities circuit construction process mustavoided. fact, cicuits serve parallel devices evaluating input stringslength n, must constructed n separately, constructibleparallel themselves. assured requiring logspace uniformity, LOGSPACEhighly parallelizable complexity class contained LOGCFL.language L accepted family G circuits dened follows: L = n0 Ln ,Ln set input strings accepted nth member Gn family. inputstring w length n accepted circuit Gn Gn evaluates true input w.397fiGottlob, Greco, Scarcellofamily G Boolean circuits bounded fan-in exists constant cgate member Gn G fan-in bounded c.family G Boolean circuits semi-unbounded following two conditions met:circuits G involve non-leaves gates, gates(negation may thus occur circuit input gates);constant c gate member Gn G fan-inbounded c (the gates may unbounded fan-in).1, ACi denotes class languages recognized logspace-uniform familiesBoolean circuits depth O(logi n).1, NCi denotes class languages recognized logspace-uniform familiesBoolean circuits depth O(logi n) bounded fan-in.1, SACi denotes class languages recognized semi-unboundedlogspace-uniform families Boolean circuits depth O(logi n).Venkateswaran (1991) proved following important relationship LOGCFLsemi-unbounded circuits:LOGCFL = SAC1 .Since LOGCFL = SAC1 AC1 NC2 , problems LOGCFL highlyparallelizable. fact, problem LOGCFL solvable logarithmic timeconcurrent-read concurrent-write parallel random access machine (CRCW PRAM)polynomial number processors, log2 -time exclusive-read exclusive-writePRAM (EREW PRAM) polynomial number processors (Johnson, 1990).next show evaluation problem SAC1 circuits transformedlogspace considered Nash equilibrium existence problems.g19g19g17g18g13 g14 g15 g16g8g17g16g13g16g9 g10 g11 g12g8g9g11g12qx1 g1 x2 g2 qx2 g3 x4 g4 x5 g5 qx6 g6 x7 g7g1g3g6g6A)B)C)Figure 17: (A) normalized circuit, (B)its skeleton tree, (C) labeling correspondingproof tree.Theorem 6.1 existence problem pure Nash equilibria LOGCFL-completefollowing classes strategic games graphical normal form: acyclic-graph games, acyclichypergraph games, games bounded treewidth, games bounded hypertree-width.398fiPure Nash Equilibria: Hard Easy GamesProof. sucient show membership bounded hypertree width (the largest4 classes) hardness acyclic-graph games (the smallest one).Membership. Nash equilibrium existence problem NF games bounded hypertree width LOGCFL because, shown Section 4, problem transformedlogspace CSP bounded hypertree width, and, shown Gottlob et al. (2001),checking satisability latter LOGCFL. (Recall LOGCFL closedlogspace reductions.)Hardness. assume logspace-uniform family C = {G1 , G2 , . . .} SAC1 circuitsgiven, prove problem checking whether binary string w acceptedC translated logspace acyclic Nash equilibrium problem NF.input w, compute logspace appropriate circuit C = G|w| . shown Gottlobet al. (2001), circuit transformed logspace equivalent normalized circuitC stratied strictly alternating (see Figure 17 (A)), tree-shaped proofskeleton SKEL (see Figure 17 (B)) encompasses common structure possibleproof trees (C , w). proof tree subtree C gates value 1 witnessingC accepts w. proof tree corresponds appropriate labeling SKELgates C (for example, labeling shown Figure 17 (C)). labeling correctroot SKEL labeled output gate C , gate labeled g twochildren labeled input gates g, node SKEL labeled gone child labeled input gate g, leaf labeled input gateC whose output next higher level 1. C accepts w existsproof tree (C , w), thus exists correct labeling SKEL.Build strategic game G (C , w) SKEL follows. set players consistsvertices V SKEL plus two special players . possible actionsplayers V pairs (g, t), g gate truth value {true, false}.utilities players V given follows.1. utility leaf u SKEL depends action 1 playsinput gate g C g associated constant true, g gatecorresponds input bit 0 string w, g gate correspondsinput bit 1 w. Otherwise, utility u 0.2. non leaf vertex p V gets payo 1, plays action (g, true), eitherp vertex unique child p SKEL takes action (g , true), gchild gate g C , p vertex unique children pSKEL take actions (g , true), (g , true), respectively, g gchildren gate g C .3. non leaf vertex p V gets payo 1, plays action action (g, false),either p vertex unique child p SKEL takes action (g , false),g child g C , p vertex unique children pSKEL take actions (g , ), (g , ), respectively, g g childreng C = false.4. cases, actions non leaf vertex p V utility 1.According dened far, easy see every Nash equilibriumgame corresponds labeling SKEL assigning player V gate g399fiGottlob, Greco, Scarcellorespective action (g, t). particular, root node r forced labeledoutput gate g C , action played r (g , true) particularlabeling proof tree (g , false) otherwise.remains dene actions utilities special players .intuitive role kill equilibria correspond proof three i.e.,root vertex plays (g , false)). possible actions {ok, head, tail}, {head, tail} . strategies plays ok utility 1 rootvertex r SKEL plays (g , true)) utility 0 otherwise. Strategies plays head(resp., tail) utility 1 r plays (g , false) plays tail (resp., head),0 otherwise. Thus, case r plays (g , false), player tries play opposite player. strategies plays head (resp., tail) utility 1 player playsaction, 0 otherwise.Therefore, case C outputs 0 input w, r plays (g , false), thus tries playopposite tries mimic . classical non-equilibrium situation.summary, Nash equilibrium G corresponds proof tree (C , w). Note alsoG(G) acyclic, construction G (C , w) done logspace. 2Note that, Denition 2.2, Pareto Nash equilibrium exists Nashequilibrium exists.Corollary 6.2 existence problem pure Pareto Nash equilibria LOGCFL-completefollowing classes strategic games graphical normal form: acyclic-graph games,acyclic-hypergraph games, games bounded treewidth, games bounded hypertreewidth.Finally, far computation Nash equilibria concerned, following corollaryfollows result result Gottlob al. (2002a), statingwitnesses (i.e., proof trees) LOGCFL decision problems computed functionalLOGCFL (i.e., logspace oracle LOGCFL, or, equivalently, using SAC1circuits.Corollary 6.3 classes games mentioned Theorem 6.1, computationsingle pure Nash equilibria done functional LOGCFL, thereforeparallel complexity class N C2 .7. Conclusionpaper determined precise complexity pure Nash equilibria strategicgames. depicted Figure 2, study proceeded along three directions: representation issues, structural properties player interactions, dierent notions equilibria.Indeed, besides plain Nash equilibria, considered Pareto Strong Nash equilibria,look Nash equilibria dominated Nash equilibrium,proles possible coalition players may improve payos members,respectively.turns that, apart simple case standard normal form, decidingexistence Nash equilibria intractable problem (unless PTIME = NP),400fiPure Nash Equilibria: Hard Easy Gamesrestriction relationships among players. Interestingly, Strong Nash Equilibria,problem located second level polynomial hierarchy, gives us freshgame-theoretic view class P2 , class problems whose positive instancescharacterized coalition players cooperate provide equilibrium, windisjoint coalition, fails trying improve utilityplayers.However, paper collection bad news. Rather, central goalsingle large classes strategic games detecting Nash equilibria tractableproblem. particular, early studies game theory mainly focused gamessmall number players (e.g., traditional two-player framework), interestedlarge population games, too. cases, adopting standard normal formclearly impractical as, player, one specify payos combinationchoices players game. thus considered dierent representationgames, known literature graphical games (Kearns et al., 2001b), payosplayer p functions ps neighbors only, is, ps utility function dependsplayers p directly interested in. relationships among players mayrepresented graph or, faithfully, hypergraph. showed that, utilityfunctions represented tables (graphical normal form) game structure acycliclow degree cyclicity (i.e., bounded hypertree width), decidingexistence Nash equilibrium possibly computing feasible polynomial time.results complement obtained graphical games mixed Nash equilibriaframework (e.g. Kearns et al., 2001b; Kearns & Mansour, 2002). Moreover, casequasi-acyclic structures, also able extend tractability classes gamesutility functions given implicitly (as general form), provided playersmall number neighbors many available actions.paper sheds light sources complexity nding pure Nash equilibriastrategic games, and, particular, roles played game representationsgame structures. worthwhile noting aspects game theory receivedrenewed deal attention recently. instance, see Papadimitriou (2004) recentwork complexity pure Nash equilibria particular classes games,various contributions dierent kinds concise game representations (e.g. Koller &Milch, 2001; Vickrey, 2002; Kearns et al., 2001b; Leyton-Brown & Tennenholtz, 2003; Gal& Pfeer, 2004; Kearns & Mansour, 2002).recall preliminary version present work presented9th ACM Conference Theoretical Aspects Rationality Knowledge (TARK03).Since then, results extended along dierent directions. particular, Alvarezet al. (2005) considered version general form games, called games implicitform, also payo values given succinct way. showed that,games, complexity deciding existence pure Nash equilibria increasesrst level second level polynomial hierarchy. point generalform slightly dierent general form adopted mentioned paper,confusion may arise reading citation results presented TARK03paper (whose full version present paper). terminology, Turing-machineencoding payo functions general form games classied non-uniform,uniform time-bound. However, apart subtle technical issues,401fiGottlob, Greco, Scarcelloresults general form games non implicit actions similar ours,contributions focus games large number actions, hardness results holdeven games xed number actions payo levels. Moreover, showhardness holds even acyclic games, consider restriction playerinteractions. Observe results may immediately strengthened, givenproofs GNF games arbitrary player interactions follows NP-hardnessholds even constant-time utility functions (as discussed Remark 3.9).Another line research studies games computation Nash equilibriumsatisfactory, one rather interested equilibria satisfy additional requirements (e.g., best social welfare). Greco Scarcello (2004) proved decidingexistence pure Nash equilibria, called constrained Nash equilibria, intractableeven simple requirements. However, also able identify restrictions(for player interactions requirements) making existence computationproblems easy. Recent contributions subject (on pure mixed Nash equilibria) done Schoenebeck al. (2005) Greco Scarcello (2005).Finally, observe interesting connection among strong Nash equilibriaequilibria studied cooperative/coalitional game theory (e.g. Mas-Colell, Whinston, & Green, 1995). framework, subset K players, givenutility players K may get, cooperate together. core gameset proles x subset players may improve utilities forming coalition, deviating x (Gillies, 1953). Recently, ConitzerSandholm (2003a) proposed concise representation coalition utilities, showeddetermining whether core game nonempty NP-hard. interestingfuture work may concern detailed study complexity coalitional games, possibly exploiting suitable notions quasi-acyclic structures identifying relevant tractableclasses.AcknowledgmentsPart work published preliminary form Proceedings 9thACM Conference Theoretical Aspects Rationality Knowledge (TARK03).Georg Gottlobs work supported Austrian Science Fund (FWF)project Nr. P17222-N04 Complementary Approaches Constraint Satisfaction,GAMES Network Excellence EU.thank anonymous referees Tuomas Sandholm useful comments.ReferencesAlvarez, C., Gabarro, J., & Serna, M. (2005). Pure Nash equilibria gameslarge number actions. Electronic Colloquium Computational Complexity, Report TR05-031.Aumann, R. (1959). Accetable points general cooperative n-person games. ContributionTheory Games, IV.402fiPure Nash Equilibria: Hard Easy GamesAumann, R. (1985). game theory trying accomplish?. Frontiers Economics,2876.Beeri, C., Fagin, R., Maier, D., & Yannakakis, M. (1983). desirability acyclicdatabase schemes. Journal ACM, 30(3), 479513.Bodlaender, H. (1997). Treewidth: Algorithmic techniques results. Proc.22nd International Symposium Mathematical Foundations Computer Science(MFCS97), pp. 1936, Bratislava, Slovakia.Chandra, A., Kozen, D., & Stockmeyer, L. (1981). Alternation. Journal ACM, 28(1),114133.Conitzer, V., & Sandholm, T. (2003a). Complexity determining nonemptinesscore. Proc. 18th International Joint Conference Artificial Intelligence(IJCAI03), pp. 613618, Acapulco, Mexico.Conitzer, V., & Sandholm, T. (2003b). Complexity results nash equilibria. Proc.18th International Joint Conference Artificial Intelligence (IJCAI03), pp.765771, Acapulco, Mexico.Deng, X., Papadimitriou, C., & Safra, S. (2002). complexity equilibria. Proc.34th Annual ACM Symposium Theory Computing (STOC02), pp. 6771,Montreal, Canada.Downey, R., & Fellows, M. (1995). Fixed-parameter tractability completeness i: Basicresults. SIAM Journal Computing, 24(4), 873921.Fabrikant, A., Papadimitriou, C., & Talwar, K. (2004). complexity pure nashequilibria. Proc. 36th Annual ACM Symposium Theory Computing(STOC04), pp. 604612, Chicago, IL, USA.Fagin, R. (1983). Degrees acyclicity hypergraphs relational database schemes.Journal ACM, 30(3), 514550.Fotakis, D., Kontogiannis, S., Koutsoupias, E., Mavronicolas, M., & Spirakis, P. (2002).structure complexity nash equilibria selsh routing game. Proc.29th International Colloquium Automata, Languages Programming(ICALP02), pp. 123134, Malaga, Spain.Gal, Y., & Pfeer, A. (2004). Reasoning rationality beliefs. Proc.3rd International Joint Conference Autonomous Agents Multiagent Systems(AAMAS04), pp. 774781, New York, NY, USA.Garey, M., & Johnson, D. (1979). Computers Intractability. Guide TheoryNP-completeness. Freeman Comp., NY, USA.Gilboa, I., & Zemel, E. (1989). Nash correlated equilibria: complexity considerations. Games Economic Behaviour, 1, 8093.403fiGottlob, Greco, ScarcelloGillies, D. (1953). theorems n-person games. PhD thesis, Princeton, Dept.Mathematics.Gottlob, G., Leone, N., & Scarcello, S. (2000). comparison structural csp decompositionmethods. Artificial Intelligence, 124(2), 243282.Gottlob, G., Leone, N., & Scarcello, S. (2001). complexity acyclic conjunctive queries.Journal ACM, 48(3), 431498.Gottlob, G., Leone, N., & Scarcello, S. (2002a). Computing logc certicates. TheoreticalComputer Science, 270(1-2), 761777.Gottlob, G., Leone, N., & Scarcello, S. (2002b). Hypertree decompositions tractablequeries. Journal Computer System Sciences, 63(3), 579627.Greco, G., & Scarcello, S. (2003). Non-binary constraints optimal dual-graph representations. Proc. 18th International Joint Conference Artificial Intelligence(IJCAI03), pp. 227232, Acapulco, Mexico.Greco, G., & Scarcello, S. (2004). Constrained Pure Nash Equilibria Graphical Games.Proc. 16th Eureopean Conference Artificial Intelligence (ECAI04), pp.181185, Valencia, Spain.Greco, G., & Scarcello, S. (2005). Bounding Uncertainty Graphical Games:Complexity Simple Requirements, Pareto Strong Nash Equilibria. appearProc. 21st Conference Uncertainty Artificial Intelligence (UAI05),Edinburgh, Scotland.Johnson, D. (1990). catalog complexity classes. Handbook Theoretical ComputerScience, Volume A: Algorithms Complexity, 67161.Johnson, D., Papadimitriou, C., & Yannakakis, M. (1998). easy local search?.Journal Computer System Sciences, 37, 79100.Kearns, M., Littman, M., & Singh, S. (2001a). ecient exact algorithm singly connected graphical games. Proc. 14th International Conference Neural Information Processing Systems (NIPS01), pp. 817823, Vancouver, British Columbia,Canada.Kearns, M., Littman, M., & Singh, S. (2001b). Graphical models game theory. Proc.17th International Conference Uncertainty AI (UAI01), pp. 253260,Seattle, Washington, USA.Kearns, M., & Mansour, Y. (2002). Ecient nash computation large population gamesbounded inuence. Proc. 18th International Conference UncertaintyAI (UAI02), pp. 259266, Edmonton, Alberta, Canada.Koller, D., & Megiddo, N. (1992). complexity two-person zero-sum games extensiveform. Games Economic Behavior, 2, 528552.404fiPure Nash Equilibria: Hard Easy GamesKoller, D., & Megiddo, N. (1996). Finding mixed strategies small supports extensiveform games. International Journal Game Theory, 14, 7392.Koller, D., Megiddo, N., & von Stengel, B. (1996). Ecient computation equilibriaextensive two-person games. Games Economic Behavior, 14, 220246.Koller, D., & Milch, B. (2001). Multi-agent inuence diagrams representing solvinggames. Proc. 7th International Joint Conference Artificial Intelligence(IJCAI01), pp. 10271034, Seattle, Washington, USA.Leyton-Brown, K., & Tennenholtz, M. (2003). Local-eect games. Proc. 18thInternational Joint Conference Artificial Intelligence (IJCAI03), pp. 772780,Acapulco, Mexico.Maier, D. (1986). Theory Relational Databases, Rochville, Md, Computer SciencePress.Mas-Colell, A., Whinston, M., & Green, J. (1995). Microeconomic Theor. Oxford UniversityPress.Maskin, E. (1985). theory implementation nash equilibrium. Social GoalsOrganization: Essays memory Elisha Pazner, 173204.McKelvey, R., & McLennan, A. (1996). Computation equilibria nite games. HandbookComputational Economics, 87142.Megiddo, N., & Papadimitriou, C. (1991). total functions, existence theorems,computational complexity. Theoretical Computer Science, 81(2), 317324.Monderer, D., & Shapley, L. (1993). Potential games. Games Economic Behavior.Nash, J. (1951). Non-cooperative games. Annals Mathematics, 54(2), 286295.Osborne, M., & Rubinstein, A. (1994). Course Game Theory. MIT Press.Owen, G. (1982). Game Theory. Academic Press, New York.Papadimitriou, C. (1994a). Computational Complexity. AAddison-Wesley, Reading, Mass.Papadimitriou, C. (1994b). complexity parity argument inecientproofs existence. Journal Computer System Sciences, 48(3), 498532.Papadimitriou, C. (2001). Algorithms, games, internet. Proc. 28thInternational Colloqium Automata, Languages Programming (ICALP01), pp.13, Crete, Greece.Robertson, N., & Seymour, P. (1986). Graph minors ii. algorithmic aspects tree width.Journal Algorithms, 7, 309322.Rosenthal, R. (1973). class games possessing pure-strategy nash equilibria. International Journal Game Theory, 2, 6567.405fiGottlob, Greco, ScarcelloSchoenebeck, G.R., & Vadhan, S.P. (2005). Computational Complexity Nash Equilibria Concisely Represented Games. Electronic Colloquium Computational Complexity, Report TR05-052.Stockmeyer, L., & Meyer, A. (1973). Word problems requiring exponential time: Preliminary report. Proc. 5th Annual ACM Symposium Theory Computing(STOC73), pp. 19.Vardi, M. (2000). Constraint satisfaction database theory: tutorial. Proc.19th ACM SIGMOD-SIGACT-SIGART Symposium Principles DatabaseSystems, pp. 7685, Dallas, Texas, USA.Venkateswaran, H. (1991). Properties characterize logc. Journal ComputerSystem Sciences, 43(2), 380404.Vickrey, D. amd Koller, D. (2002). Multi-agent algortihms solving graphical games.Proc. 18th National Conference Artificial Intelligence (AAAI02), p. 345251Edmonton, Alberta, Canada.Yannakakis, M. (1981). Algorithms acyclic database schemes. Proc. 7th International Conference Large Data Bases (VLDB81), p. 8294 Cannes, France.406fiJournal Artificial Intelligence Research 24 (2005) 581-621Submitted 01/05; published 10/05Macro-FF: Improving AI Planning AutomaticallyLearned Macro-OperatorsAdi BoteaMarkus EnzenbergerMartin MullerJonathan Schaefferadib@cs.ualberta.caemarkus@cs.ualberta.cammueller@cs.ualberta.cajonathan@cs.ualberta.caDepartment Computing Science, University AlbertaEdmonton, AB Canada T6G 2E8AbstractDespite recent progress AI planning, many benchmarks remain challenging current planners. many domains, performance planner greatly improveddiscovering exploiting information domain structure explicitlyencoded initial PDDL formulation. paper present compare two automated methods learn relevant information previous experience domainuse solve new problem instances. methods share common four-step strategy.First, domain analyzed structural information extracted, macro-operatorsgenerated based previously discovered structure. filtering ranking procedure selects useful macro-operators. Finally, selected macros usedspeed future searches.successfully used approach fourth international planning competition IPC-4. system, Macro-FF, extends Hoffmanns state-of-the-art planner FF2.3 support two kinds macro-operators, engineering enhancements.demonstrate effectiveness ideas benchmarks international planning competitions. results indicate large reduction search effort complex domainsstructural information inferred.1. IntroductionAI planning recently made great advances. evolution international planningcompetition four editions (Bacchus, 2001; Hoffmann, Edelkamp, Englert, Liporace,Thiebaux, & Trug, 2004; Long & Fox, 2003; McDermott, 2000) accurately reflects this.Successive editions introduced complex realistic benchmarks, harderproblem instances domain. top performers could successfully solve largepercentage problems time. However, many hard domains, including benchmarksused IPC-4, still pose great challenges current automated planning systems.main claim paper many domains, performance plannerimproved inferring exploiting information domain structureexplicitly encoded initial PDDL formulation. implicit structural information domain encodes is, arguably, proportional complex domain is,realistically models world. example, consider driving trucktwo locations. operation composed many subtasks real world. namefew, truck fueled driver assigned. detailed planningc2005AI Access Foundation. rights reserved.fiBotea, Enzenberger, Muller, & SchaefferFigure 1: CA-ED Integrating component abstraction macro-operators standardplanning framework.formulation, would define several operators fuel, assign-driver, drive.representation already contains implicit information domain structure.quite obvious human driving truck two remote locations wouldmacro-action first fuel truck assign driver (with ordering constraintstwo actions) next apply drive operator. simpler formulation,remove operators fuel assign-driver consider that, model,truck needs neither fuel driver. driving truck modeled single action,details described removed model.article present evaluate two automated methods learn implicitdomain knowledge use simplify planning new problem instances. learninguses several training problems domain. methods share common four-steppattern:1. Analysis Extract new information domain structure.2. Generation Build macro-operators based previously acquired information.3. Filtering Select promising macro-operators.4. Planning Use selected macro-operators improve planning future problems.1.1 Component Abstraction Enhanced Domainfirst method produces small set macro-operators PDDL formulationsdomain several training problems. macro-operators added initial domainformulation, resulting enhanced domain expressed description language.definitions enhanced domain new problem instances given inputplanner, need implement additional support macro-operators (Botea,Muller, & Schaeffer, 2004b). call approach CA-ED Component AbstractionEnhanced Domain.Figure 1 shows general architecture CA-ED. box Abstraction figureincludes steps 1 3 above. Step 1 uses component abstraction, technique exploitspermanent relationships low-level features problem. Low-level features (i.e.,constant symbols) linked static facts (i.e., facts remain true planning) formcomplex unit called abstract component.582fiMacro-FF: Improving AI Planning Automatically Learned Macro-OperatorsFigure 2: general architecture SOL-EP. Enhanced Planner means plannercapabilities handle macros.step 2, local analysis abstract components builds macros speed planning. CA-ED generates macros using forward search process space macro operators. macro operator built ordered sequence operators linkedmapping operators variables. Applying macro operator semantically equivalent applying contained operators given order, respecting macros variablemapping interactions preconditions effects.step 3 (filtering), set heuristic rules used prune search space generatemacros likely useful. Macros filtered dynamically, basedperformance solving training problems, effective ones keptfuture use.best macro operators method generates added new operatorsinitial PDDL domain formulation, enhancing initial set operators. Hence, needcomplete macro-operator definitions, including precondition effect formulas. Expressing formulas starting contained operators easy STRIPS, hardlarger PDDL subsets ADL, preconditions effects containedoperators interact complex ways. See Section 3.1 detailed explanation.CA-ED work required implement step 4, since planner makes distinctionmacro operator normal operator. enhanced domain formulationavailable standard STRIPS, planner used solve problem instances.architecture CA-ED two main limitations. First, component abstractioncurrently applied domains static facts formulation. Second, addingmacros original domain definition limited STRIPS domains.1.2 Solution Enhanced Plannersecond abstraction method presented article sufferlimitations, applicable larger class problems. call approach SOL-EP,stands Solution Enhanced Planner. SOL-EP extracts macros solutionstraining problems uses planner enhanced capabilities handlemacros. general architecture approach shown Figure 2. before,module Abstraction implements steps 1 3. Instead using static facts component583fiBotea, Enzenberger, Muller, & Schaefferabstraction CA-ED, step 1 SOL-EP processes solutions training problems.extend applicability STRIPS ADL domains, different macro representationused compared CA-ED. SOL-EP macro represented sequence operatorsmapping operators variables rather compilation single operatorcomplete definition precondition effects. shown Section 3.1, ADLdomains, impractical use macros complete definition.reason, SOL-EP macros cannot added original domain formulationnew operators anymore. distinct input data planner, step 4planner enhanced code handle macro operators. Since SOL-EP general,used approach fourth planning competition IPC-4.implemented ideas presented article Macro-FF, adaptive planning system developed top FF version 2.3 (Hoffmann & Nebel, 2001). FF 2.3state-of-the-art fully automatic planner uses heuristic search approach. solvingmechanism FF two main phases: preprocessing search. preprocessing phasebuilds data structures needed search time. operators instantiated groundactions, predicates instantiated facts. action, pointers storedprecondition facts, add-effect facts, delete-effect facts. Similarly,fact f , pointers stored actions f precondition, actions fadd effect, actions f delete effect. information instantlyavailable run-time, states evaluated relaxed graphplan heuristic.Macro-FF adds ability automatically learn use macro-actions, goalimproving search. Macro-FF also includes engineering enhancements reducespace CPU time requirements performance bottlenecks testproblems. engineering enhancements affect neither number expanded nodesquality found plans.contributions article include detailed presentation Macro-FF.present compare two methods automatically create use macro-operatorsdomain-independent AI planning. Experimental evaluation focused several main directions. First, impact engineering enhancements analyzed. evaluateSOL-EP macros implemented competition system improve planning.experiments use testbeds domains used IPC-4. Finally, compare two abstraction methods test instances techniques applicable, evaluateplanning macros.rest paper structured follows: next two sections describe CA-EDSOL-EP respectively. Section 4 summarizes implementation enhancementsadded FF. present experimental results evaluate methods Section 5.Section 6 briefly review related work discuss similarities differenceswork. last section contains conclusions ideas future work.2. Enhancing Domain Macros based Component Abstractionfirst part section introduces component abstraction. topic secondpart CA-ED macro-operators.584fiMacro-FF: Improving AI Planning Automatically Learned Macro-OperatorsFigure 3: Static graph Rovers problem.2.1 Component AbstractionComponent abstraction technique groups related low-level constants planningproblem abstract entities called abstract components or, shorter, components.idea similar humans group features connected static relationshipsone abstract unit. example, robot carries hammer could consideredsingle component, mobility well maintenance skills. componentbecome permanent object representation world, provided actioninvalidate static relation robot hammer.Component abstraction two-step procedure:1. Build problems static graph, models permanent relationships constant symbols problem.2. Build abstract components clustering procedure. Formally, abstract component connected subgraph static graph.2.1.1 Building Static Graph Problemstatic graph models static relationships constant symbols problem. Nodesconstant symbols, edges correspond static facts problem definition. Followingstandard terminology, fact instantiation domain predicate, i.e., predicatewhose parameters instantiated constant symbols. fact f staticproblem p f part initial state p operator delete it.constant argument least one static fact defines node staticgraph. constants fact linked pairwise. edges graph labeledname corresponding predicate.use Rovers problem example component abstraction works.domain, rovers equipped cameras stores rock soil samplescollected analyzed. Rovers gather pictures data rock soilsamples, report base. information Rovers domain, seework Long Fox (2003). Figure 3 shows static graph sample problem.nodes include two stores (store0 store1), two rovers (rover0 rover1),585fiBotea, Enzenberger, Muller, & Schaeffertwo photo cameras (cam0 cam1), two objectives (obj0 obj1), two camera modes(colour high-res), four waypoints (point0,... point3). edges correspondstatic predicates (store-of ?s - store ?r - rover), (on-board ?c - camera ?r- rover), (supports ?c - camera ?m - mode), (calibration-target ?c - camera?o - objective), (visible-from ?o - objective ?w - waypoint).two marked clusters left examples abstract components generatedmethod. component rover equipped camera store.detailed formal explanation provided following paragraphs.identify static facts necessary build static graph, set domain operatorsused partition predicate set P two disjoint sets, P = PF PS , correspondingfluent static predicates. operator represented structure= (V (o), P (o), A(o), D(o)),V (o) variable set, P (o) precondition set, A(o) set add effects,D(o) set delete effects. predicate p fluent p part operatorseffects (either positive negative):p PF : p A(o) D(o).Otherwise, p static, denoted p PS .domain hierarchical types, instances predicate staticfluent. Consider Depots domain, combination Logistics Blocksworld,used third international planning competition (Long & Fox, 2003). domaintype hierarchy. Type locatable four atomic sub-types: pallet, hoist,truck, crate. Type place two atomic sub-types: depot distributor.Predicate (at ?l - locatable ?p - place), indicates object ?l locatedplace ?p, corresponds eight specialized predicates atomic type level. Predicate (at?p - pallet ?d - depot) static, since operator adds, deletes, movespallet. However, predicate (at ?c - crate ?d - depot) fluent. instance, liftoperator deletes fact type.address issue hierarchical types, use domain formulation typesexpressed lowest level hierarchy. expand predicate setlow-level predicates whose arguments low-level types. Similarly, low-level operatorsvariable types lowest hierarchy level. Component abstraction macrogeneration done lowest level. building macros, restore typehierarchy domain. possible, replace set two macro operatorslow-level types one equivalent macro operator hierarchical types.way, macros respect definition style (with respect hierarchical types)rest domain operators. planners pre-instantiate operators,FF, existence hierarchical types relevant. searching solution,operators instantiated ground actions whose arguments low-level types.Facts corresponding static predicates called static facts. current implementation ignore static predicates unary 1 contain two variablestype. latter kind facts often used model topological relationships,lead large components.1. fact, many current domains, unary static facts replaced types associated variables.586fiMacro-FF: Improving AI Planning Automatically Learned Macro-OperatorsStep12345CurrentPredicateUsed.Pred.component0ConstsFactscam0cam0component1ConstsFactscam1cam1(supports?c - camera?m - mode)(calibr-target?c - camera?o - objective)(on-board?c - camera?r - rover)(store-of?s - store?r - rover)cam0cam1YEScam0rover0(on-boardcam0 rover0)cam1rover1(on-boardcam1 rover1)YEScam0rover0store0(on-boardcam0 rover0)(store-ofstore0 rover0)cam1rover1store1(on-boardcam1 rover1)(store-ofstore1 rover1)Table 1: Building abstract components Rovers example.2.1.2 Building Abstract ComponentsAbstract components built connected subgraphs static graph problem.Clustering starts abstract components size 1, containing one node each,generated based domain type t, called seed type. node typestatic graph, new abstract component created. Abstract componentsiteratively extended greedy approach.Next detail clustering procedure works example, provideformal description, including pseudo-code. said before, Figure 3 shows twoabstract components built procedure. steps clustering summarizedTable 1, correspond following actions:1. Choose seed type (camera example), create one abstract componentconstant type camera: component0 contains cam0, component1contains cam1. Next, iteratively extend components created step. Oneextension step uses static predicate least one variable type alreadyencoded components.2. Choose predicate (supports ?c - camera ?m - mode), variabletype camera. avoid ending one large component containing wholegraph, merging two existing components allowed. Hence check performedwhether static facts based predicate keep existing components separated. static facts (supports cam0 colour), (supports cam0 highres), (supports cam1 colour), (supports cam1 high-res). test fails,since constants colour high-res would part components. Therefore,predicate used component extension (see third column Table 1).3. Similarly, predicate (calibration-target ?c - camera ?o - objective),would add constant obj1 components, used extension.587fiBotea, Enzenberger, Muller, & Schaeffer4. predicate (on-board ?c - camera ?r - rover) tried. merges components, used component extension. components expanded shownTable 1, Step 4.5. predicate (store-of ?s - store ?r - rover), whose type rover previously encoded components, considered. predicate extendscomponents presented Table 1, Step 5.Step 5 completed, component extension performed.static predicates using least one component types triedextension. moment quality decomposition evaluated. example satisfactory (see discussion below), process terminates. Otherwise,decomposition process restarts another domain type.quality decomposition evaluated according size built components,size defined number low-level types component. experiments,limited size values 2 4. lower limit trivial, since abstract componentcombine least two low-level types. upper limit set heuristically, preventabstraction building one large component. relatively small valuesalso consistent goal limiting size number macro operators. discussissue detail Section 2.2.Figure 4 shows pseudo-code component abstraction. Types(g) contains typesconstant symbols used nodes g. Given type t, Preds(t) set staticpredicates parameter type t. Given static predicate p, Types(p) includestypes parameters. Facts(p) facts instantiated p.iteration main loop tries build components starting seed typeTypes(g). sets Open, Closed, ried, AC initialized . graph nodetype becomes seed abstract component (method createComponent). components greedily extended adding new facts constants, constantpart two distinct components. method predConnectsComponents(p, AC) verifiesfact f Facts(p) merges two distinct abstract components AC.Method extendComponents(p, AC) extends existing components using static factsf Facts(p). simplicity, assume fact f binary constants c1 c2arguments. Given component ac, let N odes(ac) set constants (subgraph nodes)F acts(ac) set static facts (subgraph edges). general case, four possiblerelationships exist abstract components elements f , c1 , c2 :1. c1 c2 already belong abstract component ac:(ac AC) : c1 Nodes(ac) c2 Nodes(ac).case, f added ac new edge.2. Constant c1 already part abstract component ac (i.e., c1 Nodes(ac)) c2assigned component yet. ac extended c2 new node fnew edge c1 c2 .3. neither c1 c2 part previously built component, new component containing f , c1 c2 created added AC.588fiMacro-FF: Improving AI Planning Automatically Learned Macro-OperatorscomponentAbstraction(Graph g) {(each ypes(g) chosen random order) {resetAllStructures();Open t;(each ci N odes(g) type t)AC createComponent(ci );(Open 6= ) {t1 Open;Closed t1 ;(each p P reds(t1 ) \ ried)ried p;(predConnectsComponents(p, AC)) {extendComponents(p, AC);(each t2 ypes(p))(t2/ Open Closed)Open t2 ;}}(evaluateDecomposition() = OK)return AC;}return ;}Figure 4: Component abstraction pseudo-code.4. Constants c1 c2 belong two distinct abstract components:(ac1 , ac2 ) : c1 Nodes(ac1 ) c2 Nodes(ac2 ) ac1 6= ac2 .possible general, last alternative never occurs pointmethod extendComponents called. ensured previous testmethod predConnectsComponents.Consider case static graph two disconnected (i.e., edgethem) subgraphs sg1 sg2 Types(sg1 ) Types(sg2 ) = . case,algorithm shown Figure 4 finds abstract components subgraph containsseed type. perform clustering whole graph, algorithm runsubgraph separately.Following standard typed planning domains, abstract components assignedabstract types. Figure 5 shows abstract type assigned components example.shown figure, abstract type abstract component graph obtainedcomponent graph changing node labels. constant symbols used nodelabels replaced low-level types (e.g., constant cam0 replacedtype camera).589fiBotea, Enzenberger, Muller, & SchaefferFigure 5: Abstract type Rovers.Figure 6: Example macro Depots.example also shows components identical structure abstracttype. Identical structure strong form graph isomorphism, preserves edgelabels well types constants used node labels. fact f = f (c1 , ..., ck )F acts(ac) predicate whose variables instantiated constants c N odes(ac).Two abstract components ac1 ac2 identical structure if:1. |N odes(ac1 )| = |N odes(ac2 )|;2. |F acts(ac1 )| = |F acts(ac2 )|;3. bijective mapping p : N odes(ac1 ) N odes(ac2 )c N odes(ac1 ) : Type(c) = Type(p(c));f (c11 , ..., ck1 ) F acts(ac1 ) : f (p(c11 ), ..., p(ck1 )) F acts(ac2 );f (c12 , ..., ck2 ) F acts(ac2 ) : f (p1 (c12 ), ..., p1 (ck2 )) F acts(ac1 );2.2 Creating Macro-Operatorsmacro-operator CA-ED formally equivalent normal operator: setvariables V (m), set preconditions P (m), set add effects A(m), set deleteeffects D(m). Figure 6 shows example macro Depots. Figure 7 shows completeSTRIPS definitions macro operators contains.Macro operators obtained two steps, presented detail remaining part section. First, extended set macros built next macros590fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators(:action UNLOADDROP:parameters(?h - hoist ?c - crate ?t - truck ?p - place ?s - surface):precondition(and (at ?h ?p) (in ?c ?t) (available ?h)(at ?t ?p) (clear ?s) (at ?s ?p)):effect(and (not (in ?c ?t)) (not (clear ?s))(at ?c ?p) (clear ?c) (on ?c ?s)))(:action UNLOAD:parameters(?x - hoist ?y - crate ?t - truck ?p - place):precondition(and (in ?y ?t) (available ?x) (at ?t ?p) (at ?x ?p)):effect(and (not (in ?y ?t)) (not (available ?x)) (lifting ?x ?y)))(:action DROP:parameters(?x - hoist ?y - crate ?s - surface ?p - place):precondition(and (lifting ?x ?y) (clear ?s) (at ?s ?p) (at ?x ?p)):effect(and (available ?x) (not (lifting ?x ?y)) (at ?y ?p)(not (clear ?s)) (clear ?y) (on ?y ?s)))Figure 7: STRIPS definitions macro unloaddrop operators contains.filtered quick training process. Since empirical evidence indicates extra information added domain definition quite small, methods described nexttend minimize number macros size, measured number variables,preconditions effects. Static macro generation uses many constraints pruningspace macro operators, discards large macros. Finally, dynamic filtering keepstop performing macros solving future problems.2.2.1 Macro Generationabstract type at, macros generated performing forward search spacemacro operators. Macros perform local processing within component type at, accordinglocality rule detailed below.root state search represents empty macro (i.e., empty sets operators,variables, preconditions, effects). search step appends operator current591fiBotea, Enzenberger, Muller, & Schaeffervoid addOperatorToMacro(operator o, macro m, variable-mapping vm) {(each precondition p P (o)) {(p/ A(m) P (m))P (m) = P (m) {p};}(each delete effect D(o)) {(d A(m))A(m) = A(m) {d};D(m) = D(m) {d};}(each add effect A(o)) {(a D(m))D(m) = D(m) {a};A(m) = A(m) {a};}}Figure 8: Adding operators macro.macro, fixes variable mapping new operator macro. Addingnew operator macro modifies P (m), A(m), D(m) shown Figure 8.Even explicitely shown figure, variable mapping vm procedureused check identity operators predicates macros predicates (e.g.,p/ A(m) P (m)). Two predicates considered identical nameset parameters. variable mapping vm tells variables (parameters)common macro new operator.search selective: includes set rules pruning search treevalidating built macro operator. Validated macros goal states search space.search enumerates valid macro operators. following pruning rules usedstatic filtering:negated precondition rule prunes operators precondition matches onecurrent delete effects macro operator. rule avoids building incorrectmacros predicate true false.repetition rule prunes operators generate cycles. macro containing cycleeither useless, producing empty effect set, written shorter formeliminating cycle. cycle macro detected effects firstk1 operators first k2 operators, k1 < k2 . particular,k1 = 0 first k2 operators effect.chaining rule requires consecutive operators o1 o2 macro,preconditions o2 must include least one positive effect o1 . rule motivatedidea action sequence macro coherent meaning.592fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators(:action TAKE-IMAGE:parameters(?r - rover ?p - waypoint ?o - objective ?i - camera ?m - mode):precondition(and (calibrated ?i ?r) (on-board ?i ?r) (equipped-for-imaging ?r)(supports ?i ?m) (visible-from ?o ?p) (at ?r ?p)):effect(and (have-image ?r ?o ?m) (not (calibrated ?i ?r))))(:action TAKE-IMAGETAKE-IMAGE:parameters(?r0 - rover ?p - waypoint ?o - objective ?i0 - camera ?m - mode?r1 - rover ?i1 - camera):precondition(and (calibrated ?i0 ?r0) (on-board ?i0 ?r0) (equipped-for-imaging ?r0)(calibrated ?i1 ?r1) (on-board ?i1 ?r1) (equipped-for-imaging ?r1)(supports ?i0 ?m) (visible-from ?o ?p) (at ?r0 ?p)(supports ?i1 ?m) (at ?r1 ?p)):effect(and (have-image ?r0 ?o ?m) (not (calibrated ?i0 ?r0))(have-image ?r1 ?o ?m) (not (calibrated ?i1 ?r1))))Figure 9: Operator take-image macro-operator take-imagetake-imageRovers. macro rejected locality rule.limit size macro imposing maximal length maximal numberpreconditions. Similar constraints could added number variableseffects, found unnecessary. Limiting number preconditions indirectlylimits number variables effects. Large macros generally undesirable,significantly increase preprocessing costs cost per nodeplanners search.locality rule meant prune macros change two abstract components time. local static preconditions acceptable macropart abstract component. Given abstract type macro m,let local static preconditions static predicates part mspreconditions ats edges. Local static preconditions parameters msdefinition define graph structure (different variable bindings operatorscompose create different graph structures). implement idea localityrequire graph isomorphic subgraph at.example locality rule, consider Rovers abstract type Figure 5macro take-imagetake-image shown Figure 9 (this figure also shows593fiBotea, Enzenberger, Muller, & SchaefferFigure 10: Local static preconditions macro take-imagetake-image respectabstract type Figure 5. picture shows, correspond graph4 nodes 2 edges.definition take-image operator). Intuitively, involves two components, sincetwo distinct cameras two distinct rovers part macros variables. showmacro rejected locality rule. graph corresponding local staticpreconditions shown Figure 10. Obviously, subgraph atsgraph shown Figure 5, rejected.2.2.2 Macro Ranking Filteringgoal ranking filtering reduce number macros useefficient ones solving problems. overhead poor macros outweight benefit.known name utility problem (Minton, 1988). CA-ED, addingoperators domain increases preprocessing costs cost per nodeplanners search.used simple efficient practical approach dynamic macro filteringselect small set macro operators. count often macro operator instantiatedaction problem solutions found planner. often macroused past, greater chance macro useful future.ranking, macro operator assigned weight estimates efficiency.weights initialized 0. time macro present plan, weight increasednumber occurrences macro plan (occurrence points), plus 10 bonuspoints. effort spent tuning parameters bonus. common macrospart solutions training problems, bonus value v 0 produceranking among common macros. matter value v is, commonmacro receive v bonus points, number training problems. Henceoccurrence points decide relative ranking common macros.use simplest problems domain training. simple problems,use macro operators, giving macro chance participate solution planincrease weight. training phase, best macro operators selectedbecome part enhanced domain definition. experiments, 2 macros, containingtwo steps, added new operators initial sets 9 operators Rovers,5 operators Depots Satellite. domains, small amount extra594fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operatorsinformation observed good tradeoff benefits additionalpre-processing run-time costs. difficult domains, possibly larger initialsets operators, using macros would probably beneficial.3. Using Macros Solutions Enhanced Plannersection introduce SOL-EP, macro system used fourth international planning competition. start motivation Section 3.1, describemethod following two sections. SOL-EP follows four-step patternbefore, applied general classes problems. Section 3.2 describes steps1 3, Section 3.3 shows step 4. Section 3.4 concludes section discussion.3.1 MotivationSOL-EP designed goal eliminating main limitations CA-ED. Specifically, wanted extend applicability CA-ED larger classes domains. SinceCA-ED generates macros based component abstraction, applicability limiteddomains static predicates definition. SOL-EP generates macros solutionssample problems, restrictions caused nature domains predicates.Furthermore, CA-ED limited relatively simple subsets PDDL STRIPS.Since CA-ED adds macros new operators original domain, complete definitionsmacros, including precondition effect formulas, required. formulas easyobtain STRIPS, shown Figures 7 8. However, adding macros ADLdomain file becomes unfeasible practice two main reasons. First, preconditioneffect formulas macro hard infer formulas contained operators.Second, even previous issue solved macro complete definition addeddomain, costs pre-instantiating ground macro-actions large.illustrate challenging formula inference ADL, consider exampleFigure 11, shows operator move ADL Airport domain used IPC-4.preconditions effects operator quite complex formulas includequantifiers, implications conditional effects. Assume want compose macroapplies two move actions row given parameter mapping. achievecomplete definition macro move move, precondition effect formulas wouldautomatically composed analyzing preconditions effects twocontained operators interact. could find straight-forward way generate macrosformulas, decided move towards alternative solution presented latersubsection.Even issue solved macros added new domain operators, preinstantiating macro ground actions costly. Many top-level planners, includingFF, pre-instantiate domain operators possible ground actions mightapplied problem instance hand. cost instantiating one operator exponential total number parameters quantifier variables. Macros tend largernumbers parameters quantifiers therefore instantiation significantlyincrease total preprocessing costs. ADL Airport good illustration importanteffect be. shown Section 5.2, preprocessing costly compared595fiBotea, Enzenberger, Muller, & Schaeffer(:action move:parameters(?a - airplane ?t - airplanetype ?d1 - direction ?s1 ?s2 - segment ?d2 - direction):precondition(and (has-type ?a ?t) (is-moving ?a)(not (= ?s1 ?s2))(facing ?a ?d1) (can-move ?s1 ?s2 ?d1)(move-dir ?s1 ?s2 ?d2) (at-segment ?a ?s1)(not(exists (?a1 - airplane)(and (not (= ?a1 ?a)) (blocked ?s2 ?a1))))(forall (?s - segment)(imply (and (is-blocked ?s ?t ?s2 ?d2)(not (= ?s ?s1)))(not (occupied ?s))))):effect(and (occupied ?s2) (blocked ?s2 ?a)(not (occupied ?s1))(when (not (is-blocked ?s1 ?t ?s2 ?d2))(not (blocked ?s1 ?a)))(when (not (= ?d1 ?d2))(not (facing ?a ?d1)))(not (at-segment ?a ?s1))(forall (?s - segment)(when (is-blocked ?s ?t ?s2 ?d2)(blocked ?s ?a)))(forall (?s - segment)(when (and (is-blocked ?s ?t ?s1 ?d1)(not (= ?s ?s2))(not (is-blocked ?s ?t ?s2 ?d2)))(not (blocked ?s ?a))))(at-segment ?a ?s2)(when (not (= ?d1 ?d2))(facing ?a ?d2))))Figure 11: Operator move ADL Airport.596fiMacro-FF: Improving AI Planning Automatically Learned Macro-OperatorsFigure 12: solution steps problem 1 Satellite benchmark.main search dominates total cost solving problem domain.increasing preprocessing costs new operators desirable domains.solution ADL macros represent SOL-EP macro list atomic actions.Precondition effect formulas explicitly provided. Rather, determinedrun-time, macro dynamically instantiated applying action sequence.benchmarks used IPC-4 emphasize need address issues describedabove. Many competition domains provided STRIPS ADL formulations.main definition ADL and, planners could take ADL domainsinput, STRIPS compilations ADL domain provided. could runsystem ADL domains. reason STRIPS compilations ADL domains,distinct domain file generated problem instance. However, learningapproach requires several training problems domain.3.2 Generating Macrosrunning example, use solution plan problem 1 Satellite domainshown Figure 12. step, figure shows order linear plan, actionname, argument list, preconditions, effects. keep picture simple,ignore static preconditions actions. Static facts never occur action effects,therefore affect interactions preconditions effects actions.SOL-EP, macro-operators extracted solutions training problems.training problem first solved macros use. found plan represented solution graph, node represents plan step (action), edgesmodel interactions solution steps. Building solution graph step 1 (analysis)general four-step pattern. IPC-4 used first implementation solutiongraph, considers interactions two consecutive actions plan.interaction defined two actions least one common argument, least one597fiBotea, Enzenberger, Muller, & Schaefferaction arguments all. Hence implementation described article extractstwo-action sequences possible macros.macro-actions extracted solution translated macro-operatorsreplacing instantiated arguments generic variables. operation preservesrelative mapping arguments contained actions. Macro-actionsdifferent sets arguments result macro-operator. Satellite solutionFigure 12, sequence turn-to followed take-image occurs three times.replacing constant arguments generic variables, occurrences yieldmacro-operator.many pairs actions solution, decision must madeones going beneficial macro-operators search. Macros staticallyfiltered according rules Section 2.2.1 excluding limitation numberpreconditions, critical algorithm, locality rule. Also, saidbefore, use different version chaining rule. request operatorsmacro common variables, unless operator 0 parameters.Macro-operators stored global list ordered weight, smallerbetter. Weights initialized 1.0 updated dynamic ranking process usinggradient-descent method.macro-operator extracted solution training problem, resolve problem use. Let L solution length macros used, Nnumber nodes expanded solve problem macros, Nm numberexpanded nodes macro used. use difference N Nm updatewm , weight macro m. Since N Nm take arbitrarily large values, mapnew value interval (1, 1)= (N Nm)Nsigmoid function(x) =21.1 + exFunction generates curve shown Figure 13. particular definitionchosen symmetric (0, 0) (i.e., (x) = (x)) bounded withininterval (1, 1). particular, symmetry property ensures that, Nm = N ,weight update current training step 0. size boundary intervaleffect ranking procedure, scales weight updates constant multiplicativefactor. used sigmoid function bounded (1, 1) canonical representation,limits absolute value 0 1.update formula also contains factor measures difficulty traininginstance. harder problem, larger weight update be. usedifficulty factor solution length L rather N , since former smaller variancetraining problem set. formula updating wmwm = wm Lsmall constant (0.001 implementation). value affectranking macros. used keep macro weights within vicinity 1. See598fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators10-1-10-50510Figure 13: Sigmoid function.second part Section 3.4 comparison CA-EDs frequency-based rankingSOL-EPs gradient-descent ranking.CA-ED, two macros kept future use, given large extra-costs associatedtype macros. SOL-EP allow arbitrary (but still small) numbermacros used search, given smaller extra-costs involved. SOL-EP macrospreprocessing costs, cost per node search much smallercase CA-ED macros (see Table 4).decide number selected macros domain, weight threshold wim defined. threshold seen weight imaginary macro im constantperformance training instances. constant performance mean that,training instance,N Nim= c,Nc > 0 constant parameter. threshold wim updated followingprocedure regular macros: initial value wim set 1. trainingproblem, weight update imwim = wim im L = wim (c)Ltraining problems processed, macros weight smaller w imselected future use. experiments set c 0.01. Given competition tightdeadline, invested limited time studying method tuning parameters.best determine number selected macros still open problem us,clearly needs thourough study evaluation.3.3 Using Macros Run-Timepurpose learned macros speed search new problem instances. classicalsearch algorithm expands node considering low-level actions appliedcurrent state. add successor states reached applying whole sequenceactions macro. order macro successors regular successors599fiBotea, Enzenberger, Muller, & Schaefferstate. Macros affects neither completeness correctness original algorithm.completeness original search algorithm preserved since SOL-EP removesregular successors state. Correctness guaranteed following way applyingmacro state. Given state s0 sequence actions = a1 a2 ...ak (k = 2competition system), say applicable s0 ai applied si1 ,= 1, ..., k, si = (si1 , ai ) (s, a) state obtained applying s.given state expanded runtime, many instantiations macro could applicable would actually shortcuts towards goal state. instantiationsconsidered, branching factor significantly increase induced overheadlarger potential savings achieved useful instantiations. Therefore,challenge select state expansion small number good macro instantiations.determine good instantiation macro is, use heuristic method calledhelpful macro pruning. Helpful macro pruning based relaxed graphplan computation FF (Hoffmann & Nebel, 2001) performs evaluated state s. Givenstate s, FF solves relaxed problem, initial state currently evaluated state,goal conditions real problem, actions relaxed ignoring delete effects. computation produces relaxed plan RP (s). FF,relaxed plan used heuristically evaluate problem states prune low-level actionssearch space (helpful action pruning).addition, use relaxed plan prune set macro-instantiationsused node expansion. Since actions relaxed plan often useful realworld, request selected macro relaxed plan match i.e., actionmacro part relaxed plan.3.4 Discussionfirst part section summarizes properties CA-ED macros SOL-EP macros.comments macro-ranking provided, including brief comparison frequencybased ranking gradient-descent ranking.3.4.1 CA-ED Macros vs SOL-EP Macrostreated single moves, macro-actions potential influence planningprocess two important ways. First, macros change search space (the embeddingeffect), adding node successor list states would normally achieved severalsteps. Intermediate states macro sequence evaluated, reducingsearch costs considerably. effect, maximal depth search could reducedprice increasing branching factor.Second, macros improve heuristic evaluation states (the evaluation effect).shown before, FF computes heuristic solving relaxed planning problem (i.e.,delete effects actions ignored) graphplan framework. illustrate benefitsmacros relaxed graphplan, consider example Figures 6 7. Operator unloadone add effect (lifting) one delete effect (available) update statushoist available (free) lifting (busy). Similarly, operator drop updates hoiststatus two effects. However, macro unloaddrop used, statushoist change: available (free) before, available after. effects600fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operatorsnecessary express changes hoist status. Hence two delete effects (oneoperator) safely eliminated real problem relaxation performed.relaxed problem similar real problem information loss less drastic.See Section 5.4 empirical evaluation macros added domain affectheuristic state evaluation relaxed graphplan.macros added original domain formulation, evaluationeffect embedding effect present, need extend original planningengine. disadvantages alternative include limitation STRIPS domainsand, often, significant increase preprocessing costs, memory requirements, costper node search (as shown Section 5). SOL-EP macros used,two effects needs special extension planning engine. current implementationenhanced planner handles embedding effects affect computationheuristic state evaluation. Improving heuristic state evaluation macrosimportant topic future work.3.4.2 Comments Rankingfrequency-based ranking method used CA-ED simple, fast shownproduce useful macros. Part success due combination static pruningrules. particular, limiting macro length two actions simplifies problemmacro ranking filtering.However, general case, savings macro achieve dependoften occurs part solution, also several factors,interact. Examples factors include number search nodes applicationmacro would save, ratio useful instantiations macro (providing shortcutstowards goal state) versus instantiations guide search wrong direction. Seework McCluskey Porteous (1997) details factors determineperformance macro-operators AI planning.reason extended approach frequency-based ranking gradientdescent ranking integrating factors ranking method expectedproduce accurate results. Compared frequency-based ranking, gradient-descentranking measures search performance macro directly. illustrate this,consider solution plan Figure 12. Table 2 shows 5 distinct macro-operators extracted solution plan. macro, gradient-descent weightfrequency-based weight shown. latter case, bonus points ignored, sinceaffect ranking (all macros receive amount bonus pointspart solution plan). method produces different ranking. example, macro take-image turn-to ranked fourth gradient-descent methodsecond frequency-based method. reason macro turn-tocalibrate (or switch-on turn-to) saves search nodes take-image turn-to,even though appears less frequently solution.compared simple fast frequency-based method, gradient-descent ranking expensive. training problem solved several times;macros use macro. shown Table 3 Section 5, trainingtime become issue domains PSR Pipesworld Non-Temporal Tankage.601fiBotea, Enzenberger, Muller, & SchaefferMacroturn-to take-imageturn-to calibrateswitch-on turn-totake-image turn-tocalibrate turn-toWeight0.9991030.9991030.9991030.9994010.999700Occurrences31121Table 2: Macros generated Satellite example.ranking techniques ignore elements interactions several macrosused simultaneously, effects macros quality plans. See Section 5evaluation latter.Macro ranking difficult problem. training data often limited. addition,factors frequency, number search nodes macro would save, effectssolution quality, etc. combined total ordering macro set.clear best solution problem. example, select macro speedsplanning increases solution length?4. Implementation Enhancements Macro-FFsection describes implementation enhancements added FF goalimproving CPU memory requirements. FF version 2.3 highly optimized respectrelaxed graphplan generation, assumed performance bottleneckoriginal system designers. found several domains planning competitionassumption hold planner spends significant portion timeparts program. applied two implementation enhancements FF reduceCPU time requirements.Another problem memory requirements data structures builtpre-processing stage grew exponentially problem size thereforescale. replaced one data structures able solve problemsseveral domains within memory limit used planning competition.enhancements described section affect neither number expanded nodesquality plans found FF.4.1 Open QueueFF tries find solution using enhanced hill climbing method and, solutionfound, switches best-first search algorithm. Profiling runs showed Pipesworlddomains planning competition 90% CPU time spent inserting nodesopen queue. open queue implemented single linked list. changedimplementation use linked list buckets, one bucket heuristic value.buckets implemented linked lists need constant time insertion, sincelonger sorted.602fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators4.2 State Hashingoriginal FF already used state hashing help identify previously visited states,full comparison states case collision. fact planning problem assignedunique 32-bit random number, hash code problem state sumrandom numbers associated facts characterize given state. Profiling runsshowed domains 35% CPU time spent comparisonstates. particular domains large states small graphplan structuresPSR Philosophers. replaced original hash key 64-bit Zobrist hashkey implementation, standard technique game-tree search (Marsland, 1986). factassigned 64-bit random number, hash key state obtained applyingXOR operator random numbers corresponding facts true state.checking two states identical, hash codes compared.hash codes different, states guaranteed different too. twocompared states hash code, assume states identical.choice gives completeness search algorithm: two different states hashcode exist. However, unlikely occur fast state comparison based64-bit Zobrist hashing common standard high-performance game-playing programs.large size hash key better randomization makes occurrence hashcollisions much less probable random hardware errors.4.3 Memory Requirementsoptimizations FF require creation large lookup tables builtpreprocessing stage. One lookup table storing facts initial state.table sparsely populated required memory equal number constantspower arity predicate summed predicates domain.caused planner run memory large domains given 1 GB memorylimit used planning competition. replaced lookup table balanced binarytree minimal memory requirement lookup time proportional logarithmnumber facts initial state.5. Experimental Resultssection summarizes experiments analysis results. evaluate ideasseveral experiments, described next subsections. Section 5.1 evaluates impactimplementation enhancements planners performance. Section 5.2 focuseseffect macro-operators system used competition. two subsections,benchmarks competed part IPC-4 used experimental evaluation: Promela Dining Philosophers ADL (containing total 48 problems), PromelaOptical Telegraph ADL (48 problems), Satellite STRIPS (36 problems), PSR MiddleCompiled ADL (50 problems), Pipesworld Notankage Nontemporal STRIPS (50 problems), Pipesworld Tankage Nontemporal STRIPS (50 problems), Airport ADL(50 problems). Macro-FF took first place Promela Optical Telegraph, PSR,Satellite.603fiBotea, Enzenberger, Muller, & SchaefferSection 5.3 compares two abstraction techniques discussed article usingSTRIPS domains static facts. provide details later section. Section 5.4contains empirical analysis CA-ED macros affect heuristic state evaluationdepth goal states. experiments reported article run AMD Athlon 2GHz machine, limits 30 minutes 1 GB memory problem.5.1 Enhanced FFnew open queue implementation shows significant speed-up Pipesworld domains. Figure 14 shows difference CPU time two different Pipesworld domains(note logarithmic time scale). simplest problems left charts solvedquickly data bar drawn. speedup depends problem instancemaximum gains reaching factor 10. result two problems solvedPipesworld Tankage Non-Temporal domain one problem PipesworldNo-Tankage Non-Temporal domain.new 64-bit state hashing especially effective PSR Promela DiningPhilosophers domains. Figure 15 shows speed-up factor 2.5. resulted3 problems solved PSR, contributing success Macro-FF domain.reduced memory requirement important Promela Optical Telegraph. Figure 16shows memory requirement original FF initial facts lookup table.result replacement lookup table, 3 problems solved domain.Pipesworld Tankage Non-Temporal - CPU Time (seconds)1e+04FF open queueNew open queue1e+03Pipesworld No-Tankage Non-Temporal - CPU Time (seconds)1e+04FF open queueNew open queue1e+031e+021e+021e+011e+011e+001e+001e-011e-011e-02510152025301e-0235Problem5101520253035ProblemFigure 14: Comparison old new open queue implementation Pipesworld Tankage Non-Temporal (left) Pipesworld No-Tankage Non-Temporal (right). Results shown sets 50 problems domain.5.2 Evaluating Macros Competition Systemsubsection evaluate SOL-EP macros improve performance competition system. compare planner implementation enhancementsplanner implementation enhancements SOL-EP macros.604fiMacro-FF: Improving AI Planning Automatically Learned Macro-OperatorsPSR - CPU Time (seconds)1e+041e+03Philosophers - CPU Time (seconds)1e+04FF hashingNew hashing1e+021e+021e+011e+011e+001e+001e-011e-011e-0251015FF hashingNew hashing1e+0320253035401e-0245246Problem81012ProblemFigure 15: Comparison two implementations state hashing PSR (left)Promela Dining Philosophers (right). Results shown 50 problemsPSR 48 problems Promela Dining Philosophers.Optical1e+11OldNew1e+10Bytes1e+091e+081e+071e+0610000005101520253035404550ProblemFigure 16: Size data structures initial facts old implementation (lookup table) new implementation (balanced tree) Promela Optical Telegraph.seven test domains, show number expanded nodestotal CPU time, again, logarithmic scale. CPU time chart shows distinctionproblem solved quickly (within time close 0) problem couldsolved. determine case is, check corresponding node chart,absence data point always means solution.Figure 17 summarizes results Satellite, Promela Optical Telegraph, PromelaDining Philosophers. Satellite Promela Optical Telegraph, macros greatly improveperformance whole problem sets, allowing Macro-FF win domain formu605fiBotea, Enzenberger, Muller, & Schaefferlations competition. Promela Optical Telegraph macros led solving 12 additionalproblems. savings Promela Dining Philosophers limited, resulting oneproblem solved.Figure 18 shows results ADL version Airport. savings termsexpanded nodes significant, little effect total running time.domain, preprocessing costs dominate total running time.complexity preprocessing Airport also limits number solved problems21. planner solve problems STRIPS version Airport used,macros could generated domain version. STRIPS Airport contains onedomain definition problem instance, whereas learning method requires severaltraining problems domain definition.Figure 19 contains results Pipesworld Non-Temporal No-Tankage, PipesworldNon-Temporal Tankage, PSR. Pipesworld Non-Temporal No-Tankage, macros oftenlead significant speed-up. result, system solves four new problems.hand, system macros fails three previously solved problems. contributionmacros less significant Pipesworld Non-Temporal Tankage. system macrossolves two new problems fails one previously solved instance. sevenbenchmarks, PSR domain macros smallest impact. systemssolve 29 problems using similar amounts resources. competition official run,Macro-FF solved 32 problems domain formulation.Table 3 shows number training problems, total training time, selectedmacros domain. training phase uses 10 problems Airport, Satellite,Pipesworld Non-Temporal No-Tankage, PSR. reduced training set 5 problemsPromela Optical Telegraph, 6 problems Promela Dining Philosophers, 5 problemsPipesworld Non-Temporal Tankage. Promela Optical Telegraph, plannermacros solves 13 problems, using training would leave little roomevaluating learned macros. situation similar Promela Dining Philosophers;planner macros solves 12 problems. Pipesworld Non-Temporal Tankage,smaller number training problems caused long training timestructure competition problem set. first 10 problems use partdomain operators, include training set. remainingproblems, planner macros solves 11 instances. large training timesPipesworld Non-Temporal Tankage PSR caused increased difficultytraining problems.5.3 Evaluating Abstraction Techniquesevaluate performance two abstraction methods, compare four setupsMacro-FF. four setups, planner includes implementation enhancementsdescribed Section 4. Setup 1 planner macros. Setup 2 includes CA-ED,method described Section 2. Setup 3 uses SOL-EP, method described Section3. Setup 4 combination 2 3. Since methods benefits limitations,interesting analyze perform applied together. setup 4, firstrun CA-ED, obtaining enhanced domain. Next treat regular domain,606fiMacro-FF: Improving AI Planning Automatically Learned Macro-OperatorsDomainAirportTP10TT365PromelaOpticalTelegraph570PromelaDiningPhilosophersSatellite610108PipesworldNon-TemporalNo-TankagePipesworldNon-TemporalTankage1025054,206PSR101,592MacrosMOVE MOVEPUSHBACK MOVEPUSHBACK PUSHBACKMOVE TAKEOFFQUEUE-WRITE ADVANCE-EMPTY-QUEUE-TAILACTIVATE-TRANS QUEUE-WRITEACTIVATE-TRANS ACTIVATE-TRANSPERFORM-TRANS ACTIVATE-TRANSACTIVATE-TRANS QUEUE-READACTIVATE-TRANS ACTIVATE-TRANSQUEUE-READ ADVANCE-QUEUE-HEADTURN-TO SWITCH-ONSWITCH-ON TURN-TOSWITCH-ON CALIBRATETURN-TO TAKE-IMAGETURN-TO CALIBRATETAKE-IMAGE TURN-TOPOP-START POP-ENDPUSH-START PUSH-ENDPUSH-START POP-STARTPUSH-START PUSH-ENDPUSH-START POP-ENDPUSH-END POP-STARTPOP-END PUSH-STARTPUSH-END PUSH-STARTPUSH-START POP-STARTPOP-START PUSH-STARTAXIOM AXIOMCLOSE AXIOMTable 3: Summary training domain. TP number training problemsTT total training time seconds. last column shows macrosselected domain. simplicity, show variable mappingmacro.607fiBotea, Enzenberger, Muller, & SchaefferSatellite - Nodes1e+081e+07Satellite - CPU Time (seconds)1e+04FF enhancedmacros1e+031e+061e+021e+051e+041e+011e+031e+001e+021e-011e+011e+00FF enhancedmacros510152025301e-023551015ProblemOptical - Nodes1e+081e+07FF enhancedmacros1e+031e+0435FF enhancedmacros1e+011e+031e+001e+021e-011e+011e+0051015Problem201e-02255Philosophers - Nodes1015Problem2025Philosophers - CPU Time (seconds)1e+04FF enhancedmacros1e+031e+06FF enhancedmacros1e+021e+051e+041e+011e+031e+001e+021e-011e+011e+00301e+021e+051e+0725Optical - CPU Time (seconds)1e+041e+061e+0820Problem2468Problem10121e-02142468Problem101214Figure 17: Comparison enhanced version FF without macros Satellite(36 problems), Promela Optical Telegraph (48 problems) Promela DiningPhilosophers (48 problems).apply SOL-EP generate list SOL-EP macros. Finally, enhanced planner usesinput enhanced domain, list SOL-EP macros, regular problem instances.Since component abstraction currently applied STRIPS domainsstatic facts formulation, used testbeds domains satisfy constraints.608fiMacro-FF: Improving AI Planning Automatically Learned Macro-OperatorsAirport - Nodes1e+081e+07Airport - CPU Time (seconds)1e+04FF enhancedmacros1e+031e+061e+021e+051e+041e+011e+031e+001e+021e-011e+011e+00FF enhancedmacros510151e-0220Problem5101520ProblemFigure 18: Comparison enhanced version FF without macros Airport(50 problems total).ran experiment Rovers (20 problems), Depots (22 problems), Satellite (36problems). domains used third international planning competition IPC-3,Satellite re-used IPC-4 extended problem set. experiments,Rovers Depots problems sets IPC-3, Satellite problem setIPC-4.Figures 20 23 Table 4 summarize results. performance consistentlyimproves macros used. Interestingly, combining CA-ED SOL-EP often leadsbetter performance abstraction method taken separately. Rovers, threeabstraction setups produce quite similar results, slight plus combined setup.Depots, CA-ED effective SOL-EP terms expanded nodes. differencesCPU time become smaller, since adding new operators original domain significantlyincreases cost per node Depots (see discussion below). Again, overall winnerdomain combined setup. Satellite, adding macros domain reducesnumber expanded nodes, significant impact cost per node (see Table 4later section) memory requirements. Setups 2 4, add macrosoriginal domain, fail solve three problems (32, 33, 36) large memoryrequirements FFs preprocessing phase.Table 4 evaluates macros affect cost per node search. cost pernode defined total search time divided number evaluated states. valuetable cost per node corresponding setup (i.e., CA-ED SOL-EP) dividedcost per node setup macros. two methods showminimum, maximum, average value. macros added originaldomain (i.e., domain enhanced), increase cost per node significant.average rate 7.70 Satellite, 6.06 Depots. interesting notice costless 1 Rovers. effect solving problem less nodes expanded.Operations managing open list closed list costs increasesize lists rate higher linear. right part tableshows much better values cost rate macros used enhanced planner.609fiBotea, Enzenberger, Muller, & SchaefferPipesworld No-Tankage Non-Temporal - Nodes1e+081e+07Pipesworld No-Tankage Non-Temporal - CPU Time (seconds)1e+04FF enhancedmacros1e+03FF enhancedmacros1e+061e+021e+051e+041e+011e+031e+001e+021e-011e+011e+00102030401e-02501020ProblemPipesworld Tankage Non-Temporal - Nodes1e+081e+07FF enhancedmacros1e+031e+04FF enhancedmacros1e+011e+031e+001e+021e-011e+01510152025Problem30351e-0240510PSR - Nodes1e+07152025Problem3035404045PSR - CPU Time (seconds)1e+04FF enhancedmacros1e+031e+06FF enhancedmacros1e+021e+051e+041e+011e+031e+001e+021e-011e+011e+00501e+021e+051e+0840Pipesworld Tankage Non-Temporal - CPU Time (seconds)1e+041e+061e+0030Problem5101520 25 30Problem35401e-02455101520 25 30Problem35Figure 19: Comparison enhanced version FF without macrosPipesworld No-Tankage Non-Temporal, Pipesworld Tankage Non-TemporalPSR (50 problems domain).important analyze macros added new operators generate increasecost per node Satellite Depots. overhead mostly present relaxedgraphplan algorithm computes heuristic value state. complexityalgorithm depends upon total number actions instantiated610fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operatorspreprocessing given problem. Adding new operators domain increases number pre-instantiated actions. Since macros tend variables regularoperator, corresponding number instantiations significantly larger. Letaction instantiation rate number actions instantiated problem macrosused divided number actions instantiated original domain formulation.statistics show average action instantiation rate 6.03 Satellite, 3.20Depots, 1.04 Rovers.results show significant impact macro-operators solution quality.macros used, length plan slightly varies directions, average closevalue original FF system.DomainDepotsRoversSatelliteMin3.270.700.98CA-EDMax8.560.9014.38Avg6.060.837.70SOL-EPMin Max Avg0.93 1.14 1.040.85 1.14 1.000.92 1.48 1.11Table 4: Relative cost per node.5.4 Evaluating Effects CA-ED Macros Heuristic State Evaluationshown Section 3.4, macros added domain new operators affectstructure search space (the embedding effect) heuristic evaluation statesrelaxed graphplan (the evaluation effect). section presents empirical analysisthese.Figure 24 shows results Depots, Rovers Satellite. domain, chartleft shows data original domain formulation, chart rightshows data macro-enhanced domain formulation. domain formulation,data points extracted solution plans follows. state along solutionplan generates one data point. coordinates data point states heuristicevaluation vertical axis, number steps left goal state reachedhorizontal axis. number steps goal state may larger distance(i.e., length shortest path) goal state. reason states along solution plansused generate data states, heuristic evaluation,number steps goal state available solving problem.first conclusion Figure 24 macros added domain improveaccuracy heuristic state evaluation relaxed graphplan. closer data pointdiagonal, accurate heuristic evaluation corresponding state.Secondly, data clouds shorter macro-enhanced domains. direct resultembedding effect, reduces depth goal states.611fiBotea, Enzenberger, Muller, & SchaefferRovers - Nodes10000(1) Macros(2) CA-ED(3) SOL-EP(4) 2 + 310001001010246810 12 14 16 18 20 22ProblemRovers - CPU Time (seconds)10(1) Macros(2) CA-ED(3) SOL-EP(4) 2 + 310.10.010246810 12 14Problem16182022Figure 20: Evaluating abstraction techniques Rovers. show number expandednodes (top), CPU time (bottom).612fiMacro-FF: Improving AI Planning Automatically Learned Macro-OperatorsDepots - Nodes1e+06(1) Macros(2) CA-ED(3) SOL-EP(4) 2 + 310000010000100010010151015Problem20Depots - CPU Time (seconds)10001001010.10.015101520ProblemFigure 21: Evaluating abstraction techniques Depots. show number expandednodes (top), CPU time (bottom).613fi105110100100010000(1) Macros(2) CA-ED(3) SOL-EP(4) 2 + 31520ProblemSatellite - Nodes253035Botea, Enzenberger, Muller, & SchaefferFigure 22: Evaluating abstraction techniques Satellite. show number expandednodes.614fi302520Problem151050.010.11101001000(1) Macros(2) CA-ED(3) SOL-EP(4) 2 + 310000Satellite - CPU Time (seconds)35Macro-FF: Improving AI Planning Automatically Learned Macro-OperatorsFigure 23: Evaluating abstraction techniques Satellite (continued). show CPUtime.615fiBotea, Enzenberger, Muller, & SchaefferDepots + CA-ED Macros120100100Heuristic evaluationHeuristic evaluationOriginal Depots120806040200080604020020 40 60 80 100 120Number steps goal0Rovers + CA-ED Macros160160140140120120Heuristic evaluationHeuristic evaluationOriginal Rovers100806040200100806040200020 40 60 80 100 120 140 160Number steps goal0Original SatelliteSatellite + CA-ED Macros350300300Heuristic evaluationHeuristic evaluation20 40 60 80 100 120 140 160Number steps goal35025020015010050020 40 60 80 100 120Number steps goal250200150100500050 100 150 200 250 300 350Number steps goal050 100 150 200 250 300 350Number steps goalFigure 24: Effects CA-ED macros heuristic state evaluation depth goal states.616fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators6. Related Workrelated work described section falls two categories. first review approaches make use domain structure reduce complexity planning,next consider previous work macro-operators.automatic method discovers exploits domain structure exploredKnoblock (1994). work, hierarchy abstractions built starting initiallow-level problem description. new abstract level obtained dropping literalsproblem definition previous abstraction level. Planning first produces abstractsolution iteratively refines low-level representation. hierarchy builtway that, refinement abstract solution exists, backtracking acrossabstraction levels necessary refinement process. Backtracking performedabstract plan refinement. situations arbitrarily frequent,negative effects systems performance.Bacchus Yang (1994) define theoretical probabilistic framework planninghierarchical models. Abstract solutions problem different abstraction levelshierarchically represented nodes tree structure. tree edge indicatestarget node refinement start node. abstract solution refinedprevious level given probability. Hierarchical search model analyticallyevaluated. analytical model used enhace Knoblocks abstraction algorithm.enhancement refers using estimations refinement probabilities abstractsolutions.recently, implicit causal structure domain used design domainindependent heuristic state evaluation (Helmert, 2004). methods either staticallyinfer information structure domain, dynamically discover structureproblem instance. contrast, propose adaptive technique learnsprevious experience domain.Two successful approaches use hand-crafted information domain structure hierarchical task networks temporal logic control rules. Hierarchical tasknetworks (HTNs) guide restrict planning using hierarchical representation domain. Human experts design hierarchies tasks show initial problembroken level regular actions. idea introduced Sacerdoti (1975)Tate (1977), widely used real-life planning applications (Wilkins &desJardins, 2001). SHOP2 (Nau, Au, Ilghami, Kuter, Murdock, Wu, & Yaman, 2003)well-known heuristic search planner search guided HTNs.planning temporal logic control rules, formula associated stateproblem space. formula initial state provided domain description.formula state obtained based successors formula.formula associated state proven false, states subtree pruned.best known planners kind TLPlan (Bacchus & Kabanza, 2000) TALPlanner(Kvarnstrom & Doherty, 2001). efficient, approaches also rely heavily humanknowledge, might expensive impossible obtain.Early contributions macro-operators AI planning includes work FikesNilsson (1971). Macros extracted problem solved solution becameavailable. Minton (1985) advances work introducing techniques filter set617fiBotea, Enzenberger, Muller, & Schaefferlearned macro-operators. approach, two types macro-operators preferred:S-macros, occur high frequency problem solutions, T-macros,useful low priority original search algorithm. Iba (1989) introducesso-called peak-to-peak heuristic generate macro-operators run-time. macromove sequence two peaks heuristic state evaluation. macrotraverses valley search space, using later correct errors heuristicevaluation. Mooney (1988) considers whole plans macros introduces partial orderingoperators based causal interactions.Veloso Carbonell (1993) Kambhampati (1993) explore planning reusesolutions previously solved problems. Solutions annotated additional relevant information stored later use. additional information contains either explanationssuccessful failed search decisions (Veloso & Carbonell, 1993), causal structuresolution plans (Kambhampati, 1993). Several similarity metrics planning problemsintroduced. new problem fed planner, annotated solutions similarproblems used guide current planning process.McCluskey Porteous (1997) focus constructing planning domains startingnatural language description. approach combines human expertise automatictools, addresses correctness efficiency obtained formulation. Usingmacro-operators major technique authors propose efficiency improvement.work, state domain composed local states several variables calleddynamic objects. Macros model transitions local states variable.planner Marvin (Coles & Smith, 2004) generates macros online (as plateauescaping sequences) offline (from reduced version problem solved).macros cached one problem instance another.Macro-moves successfully used single-agent search problems puzzlespath-finding commercial computer games, usually domain-specific implementation.sliding-tile puzzle among first testbeds idea (Korf, 1985; Iba, 1989).Two effective concepts used Sokoban solver Rolling Stone, tunnelgoal macros, applications idea (Junghanns & Schaeffer, 2001). recent workSokoban includes approach decomposes maze set rooms connectedtunnels (Botea, Muller, & Schaeffer, 2002). Search performed higher levelabstract move sequences rearrange stones inside room stonetransferred one room another. Using macro-moves solving Rubiks Cubepuzzles proposed Hernadvolgyi (2001). method proposed Botea, Muller,Schaeffer (2004a) automatically decomposes navigation map set clusters, possiblyseveral abstraction levels. cluster, internal optimal path pre-computedtwo entrances cluster. Path-finding performed abstract level,macro-move crosses cluster one entrance another one step.Methods exploit search time relaxed graphplan associated problemstate (Hoffmann & Nebel, 2001) include helpful action pruning (Hoffmann & Nebel, 2001)look-ahead policies (Vidal, 2004). Helpful action pruning considers node expansionactions occur relaxed plan applied current state. Helpfulmacro pruning applies pruning idea macro-actions applicable state,noticeable difference helpful macro pruning give completenesssearch algorithm. lookahead policy executes parts relaxed plan real618fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operatorsworld, often provides path towards goal state search statesevaluated. actions relaxed plan iteratively applied long possibleheuristically computed order. lookahead procedure cannot continuedactions relaxed plan, plan-repair method selects new action applied.7. Conclusion Future WorkDespite great progress AI planning recently achieved, many benchmarks remainchallenging current planners. paper presented techniques automaticallylearn macro-operators previous experience domain, use speedsearch future problems. evaluated methods standard benchmarks international planning competitions, showing significant improvement domains structureinformation inferred. implemented ideas Macro-FF, extensionFF version 2.3. Macro-FF participated classical part fourth internationalplanning competition, competing seven domains taking first place three them.Exploring method deeply improving performance classesproblems major directions future work. also plan extend approachseveral directions. learning method generalized macro-operatorscomplex structures HTNs. Little research focusing learning HTNsconducted, even though problem great importance.plan explore heuristic evaluation based relaxed graphplanimproved macro-operators. shown article, macro added originaldomain formulation regular operator influences results heuristic function.convenient (no changes necessary planning engine), limitedSTRIPS domains. subsets PDDL, relaxed graphplan algorithmextended special capabilities handle macros enhanced domain definitionprovided.long-term goal component abstraction automatic reformulation planningdomains problems. real-world problem abstracted planning model,corresponding formulation expressed abstraction level human designerconsiders appropriate. However, choosing good abstraction level could hardexpensive problem humans. Hence methods automatically update formulationproblem based structure would helpful.Acknowledgmentsresearch supported Natural Sciences Engineering Research CouncilCanada (NSERC) Albertas Informatics Circle Research Excellence (iCORE).thank Jorg Hoffmann making source code FF available, kindly answeringmany technical questions related FF. also thank organizers IPC-4, reviewersarticle, Maria Fox, led reviewing process.ReferencesBacchus, F. (2001). AIPS00 Planning Competition. AI Magazine, 22 (3), 4756.619fiBotea, Enzenberger, Muller, & SchaefferBacchus, F., & Kabanza, F. (2000). Using Temporal Logics Express Search ControlKnowledge Planning. Artificial Intelligence, 16, 123191.Bacchus, F., & Yang, Q. (1994). Downward Refinement Efficiency HierarchicalProblem Solving. Artificial Intelligence, 71 (1), 43100.Botea, A., Muller, M., & Schaeffer, J. (2002). Using Abstraction Planning Sokoban.Schaeffer, J., Muller, M., & Bjornsson, Y. (Eds.), 3rd International ConferenceComputers Games (CG2002), Vol. 2883 Lecture Notes Artificial Intelligence,pp. 360375, Edmonton, Canada. Springer.Botea, A., Muller, M., & Schaeffer, J. (2004a). Near Optimal Hierarchical Path-Finding.Journal Game Development, 1 (1), 728.Botea, A., Muller, M., & Schaeffer, J. (2004b). Using Component Abstraction AutomaticGeneration Macro-Actions. Fourteenth International Conference AutomatedPlanning Scheduling ICAPS-04, pp. 181190, Whistler, Canada. AAAI Press.Coles, A., & Smith, A. (2004). Marvin: Macro Actions Reduced VersionsInstance. Booklet Fourth International Planning Competition, pp. 2426.Fikes, R. E., & Nilsson, N. (1971). STRIPS: New Approach Application TheoremProving Problem Solving. Artificial Intelligence, 5 (2), 189208.Helmert, M. (2004). Planning Heuristic Based Causal Graph Analysis. FourteenthInternational Conference Automated Planning Scheduling ICAPS-04, pp. 161170, Whistler, Canada.Hernadvolgyi, I. (2001). Searching Macro-operators Automatically GeneratedHeuristics. Fourteenth Canadian Conference Artificial Intelligence, pp. 194203.Hoffmann, J., Edelkamp, S., Englert, R., Liporace, F., Thiebaux, S., & Trug, S. (2004).Towards Realistic Benchmarks Planning: Domains Used Classical PartIPC-4. Booklet Fourth International Planning Competition, pp. 714.Hoffmann, J., & Nebel, B. (2001). FF Planning System: Fast Plan GenerationHeuristic Search. Journal Artificial Intelligence Research, 14, 253302.Iba, G. A. (1989). Heuristic Approach Discovery Macro-Operators. MachineLearning, 3 (4), 285317.Junghanns, A., & Schaeffer, J. (2001). Sokoban: Enhancing Single-Agent Search UsingDomain Knowledge. Artificial Intelligence, 129 (12), 219251.Kambhampati, S. (1993). Machine Learning Methods Planning, chap. Supporting Flexible Plan Reuse, pp. 397434. Morgan Kaufmann.Knoblock, C. A. (1994). Automatically Generating Abstractions Planning. ArtificialIntelligence, 68 (2), 243302.Korf, R. (1985). Macro-Operators: Weak Method Learning. Artificial Intelligence,26(1), 3577.Kvarnstrom, J., & Doherty, P. (2001). TALplanner: Temporal Logic Based Forward Chaining Planner. Annals Mathematics Artificial Intelligence, 30, 119169.620fiMacro-FF: Improving AI Planning Automatically Learned Macro-OperatorsLong, D., & Fox, M. (2003). 3rd International Planning Competition: ResultsAnalysis. Journal Artificial Intelligence Research, 20, 159. Special Issue3rd International Planning Competition.Marsland, T. A. (1986). Review Game-Tree Pruning. International Computer ChessAssociation Journal, 9 (1), 319.McCluskey, T. L., & Porteous, J. M. (1997). Engineering Compiling Planning DomainModels Promote Validity Efficiency. Artificial Intelligence, 95, 165.McDermott, D. (2000). 1998 AI Planning Systems Competition. AI Magazine, 21 (2),3555.Minton, S. (1985). Selectively Generalizing Plans Problem-Solving. IJCAI-85, pp.596599.Minton, S. (1988). Learning Search Control Knowledge: Explanation-Based Approach..Hingham, MA. Kluwer Academic Publishers.Mooney, R. (1988). Generalizing Order Operators Macro-Operators. FifthInternational Conference Machine Learning ICML-88, pp. 270283.Nau, D., Au, T., Ilghami, O., Kuter, U., Murdock, J., Wu, D., & Yaman, F. (2003). SHOP2:HTN Planning System. Journal Artificial Intelligence Research, 20, 379404.Sacerdoti, E. (1975). Nonlinear Nature Plans. Proceedings IJCAI-75, pp. 206214.Tate, A. (1977). Generating Project Networks. Proceedings IJCAI-77, pp. 888893.Veloso, M., & Carbonell, J. (1993). Machine Learning Methods Planning, chap. TowardScaling Machine Learning: Case Study Derivational Analogy, pp. 233272.Morgan Kaufmann.Vidal, V. (2004). Lookahead Strategy Heuristic Search Planning. FourteenthInternational Conference Automated Planning Scheduling ICAPS-04, pp. 150159, Whistler, Canada.Wilkins, D., & desJardins, M. (2001). Call Knowledge-Based Planning. AI Magazine,22 (1), 99115.621fiJournal Artificial Intelligence Research 24 (2005) 341-356Submitted 11/04; published 09/05Efficiency versus Convergence Boolean KernelsOn-Line Learning AlgorithmsRoni Khardonroni@cs.tufts.eduDepartment Computer Science, Tufts UniversityMedford, 02155Dan Rothdanr@cs.uiuc.eduDepartment Computer Science, University IllinoisUrbana, IL 61801 USARocco A. Servediorocco@cs.columbia.eduDepartment Computer Science, Columbia UniversityNew York, NY 10025Abstractpaper studies machine learning problems example described usingset Boolean features hypotheses represented linear threshold elements.One method increasing expressiveness learned hypotheses contextexpand feature set include conjunctions basic features. done explicitlypossible using kernel function. Focusing well known PerceptronWinnow algorithms, paper demonstrates tradeoff computationalefficiency algorithm run expanded feature spacegeneralization ability corresponding learning algorithm.first describe several kernel functions capture either limited forms conjunctions conjunctions. show kernels used efficiently runPerceptron algorithm feature space exponentially many conjunctions; however also show using kernels, Perceptron algorithm provably makeexponential number mistakes even learning simple functions.consider question whether kernel functions analogously usedrun multiplicative-update Winnow algorithm expanded feature spaceexponentially many conjunctions. Known upper bounds imply Winnow algorithmlearn Disjunctive Normal Form (DNF) formulae polynomial mistake boundsetting. However, prove computationally hard simulate Winnowsbehavior learning DNF feature set. implies kernel functionscorrespond running Winnow problem efficiently computable,general construction run Winnow kernels.1. Introductionproblem classifying objects one two classes positive negativeexamples concept often studied machine learning. task machine learningextract classifier given pre-classified examples - problem learningdata. example represented set n numerical features, examplec2005AI Access Foundation. rights reserved.fiKhardon, Roth, & Servedioseen point Euclidean space <n . common representation classifierscase hyperplane dimension (n 1) splits domain examplestwo areas positive negative examples. representation known linearthreshold function, many learning algorithms output hypothesis representedmanner developed, analyzed, implemented, applied practice.particular interest paper well known Perceptron (Rosenblatt, 1958; Block,1962; Novikoff, 1963) Winnow (Littlestone, 1988) algorithms intensivelystudied literature.also well known expressiveness linear threshold functions quite limited (Minsky & Papert, 1968). Despite fact, Perceptron Winnowapplied successfully recent years several large scale real world classification problems.one example, SNoW system (Roth, 1998; Carlson, Cumby, Rosen, & Roth, 1999)successfully applied variations Perceptron Winnow problems natural languageprocessing. SNoW system extracts basic Boolean features x1 , . . . , xn labeled piecestext data order represent examples, thus features numerical values restricted {0, 1}. several ways enhance set basic features x 1 , . . . , xnPerceptron Winnow. One idea expand set basic features x 1 , . . . , xn usingconjunctions (x1 x3 x4 ) use expanded higher-dimensional examples,conjunction plays role basic feature, examples PerceptronWinnow. fact approach SNoW system takes running PerceptronWinnow space restricted conjunctions basic features. idea closelyrelated use kernel methods, see e.g. book Cristianini Shawe-Taylor(2000), feature expansion done implicitly kernel function. approach clearly leads increase expressiveness thus may improve performance.However, also dramatically increases number features (from n 3 n conjunctions used), thus may adversely affect computation time convergencerate learning. paper provides theoretical study performance PerceptronWinnow run expanded feature spaces these.1.1 Background: On-Line Learning Perceptron Winnowdescribing results, recall necessary background on-line learningmodel (Littlestone, 1988) Perceptron Winnow algorithms.Given instance space X possible examples, concept mapping instancesone two (or more) classes. concept class C 2X simply set concepts. on-linelearning concept class C fixed advance adversary pick concept c C.learning modeled repeated game iteration adversarypicks example x X, learner gives guess value c(x) toldcorrect value. count one mistake iteration value predictedcorrectly. learning algorithm learns concept class C mistake boundchoice c C (arbitrarily long) sequence examples, learner guaranteedmake mistakes.paper consider case examples given Boolean features,X = {0, 1}n , two class labels denoted 1 1. Thus x {0, 1}n ,labeled example hx, 1i positive example, labeled example hx, 1i negative342fiEfficiency versus Convergence Boolean Kernelsexample. concepts consider built using logical combinations n basefeatures interested mistake bounds polynomial n.1.1.1 PerceptronThroughout execution Perceptron maintains weight vector w < N initially(0, . . . , 0). Upon receiving example x <N algorithm predicts accordinglinear threshold function w x 0. prediction 1 label 1 (false positiveprediction) vector w set w x, prediction 1 label 1(false negative) w set w + x. change made w prediction correct.Many variants basic algorithm proposed studied particular oneadd non zero threshold well learning rate controls size updatew. discussed Section 3.famous Perceptron Convergence Theorem (Rosenblatt, 1958; Block, 1962; Novikoff,1963) bounds number mistakes Perceptron algorithm make:Theorem 1 Let hx1 , y1 i, . . . , hxt , yt sequence labeled examples xi <N , kxi kR yi {1, 1} i. Let u <N , > 0 yi (u xi ) i.22mistakes example sequence.Perceptron makes R kuk21.1.2 WinnowWinnow algorithm (Littlestone, 1988) similar structure. Winnow maintainshypothesis vector w <N initially w = (1, . . . , 1). Winnow parameterizedpromotion factor > 1 threshold > 0; upon receiving example x {0, 1} NWinnow predicts according threshold function w x . prediction 1label 1 xi = 1 value wi set wi /; demotionstep. prediction 1 label 1 xi = 1 value wiset wi ; promotion step. change made w prediction correct.purposes following mistake bound, implicit Littlestones work (1988),interest:Theorem 2 Let target function k-literal monotone disjunction f (x 1 , . . . , xN ) =xi1 xik . sequence examples {0, 1}N labeled according f numberprediction mistakes made Winnow(, ) 1N + k( + 1)(1 + log ).1.2 Resultsinterested computational efficiency convergence PerceptronWinnow algorithms run expanded feature spaces conjunctions. Specifically,study use kernel functions expand feature space thus enhancelearning abilities Perceptron Winnow; refer enhanced algorithmskernel Perceptron kernel Winnow.first result (cf. also papers Sadohara, 1991; Watkins, 1999; Kowalczyket al., 2001) uses kernel functions show possible efficiently run kernelPerceptron algorithm exponential number conjunctive features.343fiKhardon, Roth, & ServedioResult 1: (see Theorem 3) algorithm simulates Perceptron 3 n dimensional feature space conjunctions n basic features. Given sequencelabeled examples {0, 1}n prediction update example take poly(n, t) timesteps. also prove variants result expanded feature space consistsmonotone conjunctions conjunctions bounded size.result closely related one main open problems learning theory:efficient learnability disjunctions conjunctions, DNF (Disjunctive Normal Form)expressions.1 Since linear threshold elements represent disjunctions (e.g. x1 x2 x3true iff x1 + x2 + x3 1), Theorem 1 Result 1 imply kernel Perceptronused learn DNF. However, framework values N R Theorem 1exponentially large (note N = 3n R = 2n/2 conjunctions used),hence mistake bound given Theorem 1 exponential rather polynomialn. question thus arises whether exponential upper bound implied Theorem1 essentially tight kernel Perceptron algorithm context DNF learning.give affirmative answer, thus showing kernel Perceptron cannot efficiently learnDNF.Result 2: monotone DNF f x1 , . . . , xn sequence examples labeledaccording f causes kernel Perceptron algorithm make 2 (n) mistakes.result holds generalized versions Perceptron algorithm fixed updatedthreshold learning rate used. also give variant result showingkernel Perceptron fails Probably Approximately Correct (PAC) learning model(Valiant, 1984) well.Turning Winnow, attractive feature Theorem 2 suitable , boundlogarithmic total number features N (e.g. = 2 = N ). Therefore,noted several researchers (Maass & Warmuth, 1998), Winnow analogue Theorem 3could obtained would imply DNF learned computationally efficientalgorithm poly(n)-mistake bound. However, give strong evidenceWinnow analogue Theorem 3 exist.Result 3: polynomial time algorithm simulates Winnow exponentially many monotone conjunctive features learning monotone DNF unless every problemcomplexity class #P solved polynomial time. result holds widerange parameter settings Winnow algorithm.observe that, contrast negative result, Maass Warmuth shownWinnow algorithm simulated efficiently exponentially many conjunctivefeatures learning simple geometric concept classes (Maass & Warmuth, 1998).results thus indicate tradeoff computational efficiency convergencekernel algorithms rich classes Boolean functions DNF formulas; kernel1. Angluin (1990) proved DNF expressions cannot learned efficiently using equivalence querieswhose hypotheses DNF expressions. Since model exact learning equivalencequeries equivalent mistake bound model consider paper, result impliesonline algorithm uses DNF formulas hypotheses efficiently learn DNF. However,result preclude efficient learnability DNF using different class hypotheses.kernel Perceptron algorithm generates hypotheses thresholds conjunctions rather DNFformulas, thus Angluins negative results apply here.344fiEfficiency versus Convergence Boolean KernelsPerceptron algorithm computationally efficient run exponentially slow convergence, whereas kernel Winnow rapid convergence seems require exponentialruntime.2. Kernel Perceptron Many Featureswell known hypothesis w Perceptron algorithm linear combinationprevious examples mistakes made (Cristianini & Shaw-Taylor, 2000).precisely, let L(v) {1, 1} denote label example v,Pw = vM L(v)v set examples algorithm made mistake.PPThus prediction Perceptron x 1 iff wx = ( vM L(v)v)x = vM L(v)(v x)0.example x {0, 1}n let (x) denote transformation enhanced featurespace space conjunctions. run Perceptron algorithmenhanced space must predict 1 iff w (x) 0 w weight vectorPenhanced space; discussion holds iff vM L(v)((v) (x)) 0.PDenoting K(v, x) = (v) (x) holds iff vM L(v)K(v, x) 0.Thus never need construct enhanced feature space explicitly; order runPerceptron need able compute kernel function K(v, x) efficiently.idea behind so-called kernel methods, applied algorithm (suchsupport vector machines) whose prediction function inner products examples.detailed discussion given book Cristianini Shawe-Taylor (2000).Thus next theorem simply obtained presenting kernel function capturingconjunctions.Theorem 3 algorithm simulates Perceptron feature spaces(1) conjunctions, (2) monotone conjunctions, (3) conjunctions size k, (4)monotone conjunctions size k. Given sequence labeled examples {0, 1} nprediction update example take poly(n, t) time steps.Proof: case (1) () includes 3n conjunctions (with positive negative literals)K(x, y) must compute number conjunctions true x y. Clearly,literal conjunction must satisfy x thus corresponding bitx, must value. Thus conjunction true x correspondssubset bits. Counting conjunctions gives K(x, y) = 2same(x,y)same(x, y) number original features value x y, i.e.number bit positions xi = yi . kernel obtained independentlySadohara (2001).express monotone monomials (2) take K(x, y) = 2|xy| |x y|number active features common x y, i.e. number bit positionsxi = yi = 1.Similarly, case (3) number conjunctions satisfy x K(x, y) =Pk same(x,y). kernel reported also Watkins (1999). case (4)l=0lPK(x, y) = kl=0 |xy|.2l345fiKhardon, Roth, & Servedio3. Kernel Perceptron Many Mistakessection describe simple monotone DNF target function sequencelabeled examples causes monotone monomials kernel Perceptron algorithmmake exponentially many mistakes.x, {0, 1}n write |x| denote number 1s x and, described above,|xy| denote number bit positions xi = yi = 1. need followingwell-known tail bound sums independent random variables found in,e.g., Section 9.3 book Kearns Vazirani (1994):Fact 4 Let X1 , . . . , Xm sequence independent 0/1-valued random variables,PE[Xi ] = p. Let X denotei=1 Xi , E[X] = pm. 0 1,Pr[X > (1 + )pm] emp2 /3Pr[X < (1 )pm] emp2 /2.also use following combinatorial property:Lemma 5 set n-bit strings = {x1 , . . . , xt } {0, 1}n = en/9600|xi | = n/20 1 |xi xj | n/80 1 < j t.Proof: use probabilistic method. = 1, . . . , let xi {0, 1}n chosenindependently setting bit 1 probability 1/10. clearE[|xi |] = n/10. Applying Fact 4, Pr[|xi | < n/20] en/80 , thusprobability xi satisfies |xi | < n/20 ten/80 . Similarly, 6= jE[|xi xj |] = n/100. Applying Fact 4 Pr[|xi xj | > n/80] en/4800 ,thus probability xi , xj6= j satisfies |xi xj | > n/80n/4800n/4800n/9600+ ten/80 less 1. Thus. = evalue 2 e2 echoice x1 , . . . , xt |xi | n/20 |xi xj | n/80. xi|xi | > n/20 set |xi | n/20 1s 0s, lemma proved.2using previous lemma construct difficult data set kernel Perceptron:Theorem 6 monotone DNF f x1 , . . . , xn sequence examples labeledaccording f causes kernel Perceptron algorithm make 2(n) mistakes.Proof: target DNF use simple: single conjunctionx1 x2 . . . xn . original Perceptron algorithm n features x1 , . . . , xn easilyseen make poly(n) mistakes target function, showmonotone kernel Perceptron algorithm runs feature space 2 n monotonemonomials make 2 + en/9600 mistakes.Recall beginning Perceptron algorithms execution 2 n coordinatesw 0. first example negative example 0n . monomial trueexample empty monomial true every example. Since w (x) = 0 Perceptron incorrectly predicts 1 example. resulting update causes coefficientw corresponding empty monomial become 1 2n 1 coordinatesw remain 0. next example positive example 1n . examplew (x) = 1 Perceptron incorrectly predicts 1. Since 2n monotone conjunctions346fiEfficiency versus Convergence Boolean Kernelssatisfied example resulting update causes w become 0 2n 1coordinates w become 1. next en/9600 examples vectors x1 , . . . , xtdescribed Lemma 5. Since example |xi | = n/20 example negative;however show Perceptron algorithm predict 1 examples.Fix value 1 en/9600 consider hypothesis vector w examplex received. Since |xi | = n/20 value w (xi ) sum 2n/20 differentcoordinates wT correspond monomials satisfied xi . preciselyPPw (xi ) = Ai wT + Bi wT Ai contains monomials satisfiedxi xj j 6= Bi contains monomials satisfied xixj j 6= i. lower bound two sums separately.Let monomial Ai . Lemma 5 Ai contains n/80 variablesPn/80monomials Ai . Using well known boundthus r=0 n/20rP` `(H()+o(1))`0 < 1/2 H(p) = p log p (1 p) log(1 p)j=0 j = 2binary entropy function, found e.g. Theorem 1.4.5 bookVan Lint (1992), 20.8113(n/20)+o(n) < 20.041n terms Ai . Moreovervalue wT must least en/9600 since wT decreases 1Pexample, hence Ai wT en/9600 20.041n > 20.042n . hand, Bifalse examples therefore wT demoted wT = 1.Lemma 5 r > n/80 every r-variable monomial satisfied xi must belong Bi ,PPn/20hence Bi wT r=n/80+1 n/20> 20.049n . Combining inequalitiesrw xi 20.042n + 20.049n > 0 hence Perceptron prediction xi 1.2Remark 7 first sight might seem result limited simple special caseperceptron algorithm. Several variations exist use: added feature fixedvalue enables algorithm update threshold indirectly (via weight w), nonzero fixed (initial) threshold , learning rate , particular threeused simultaneously. generalized algorithm predicts according hypothesisw x + w updates w w + x w w + promotions similarlydemotions. show exponential lower bounds number mistakesderived general algorithm well. First, note since kernelincludes feature empty monomial always true, first parameteralready accounted for. two parameters note degree freedomlearning rate fixed threshold since multiplying factorchange hypothesis therefore suffices consider threshold only.consider several cases value threshold. satisfies 0 2 0.047use sequence examples. first two examples algorithm makespromotion 1n (it may may update 0n important).PPexamples sequence bounds Ai wT Bi wT still validfinal inequality proof becomes w xi 20.042n + 20.049n > 20.047n truesufficiently large n. > 20.047n construct following scenario. usefunction f = x1 x2 . . . xn , sequence examples includes 2 1 repetitionsexample x first bit 1 bits 0. example x satisfiesexactly 2 monomials therefore algorithm make mistakes examplessequence. < 0 initial hypothesis misclassifies 0n . start example347fiKhardon, Roth, & Servediosequence repeating example 0n classified correctly, de times.threshold large absolute value e.g. < 20.042n done. Otherwisecontinue example 1n . Since weights except empty monomial zerostage examples 0n 1n classified way 1n misclassifiedtherefore algorithm makes promotion. argument rest sequence(except adding term empty monomial) final inequality becomesw xi 20.042n 20.042n + 20.049n > 20.042n examples misclassified. Thuscases kernel Perceptron may make exponential number mistakes.3.1 Negative Result PAC Modelproof adapted give negative result kernel Perceptron PAClearning model (Valiant, 1984). model example x independently drawnfixed probability distribution high probability learner must constructhypothesis h high accuracy relative target concept c distribution D.See Kearns-Vazirani text (1994) detailed discussion PAC learning model.Let probability distribution {0, 1}n assigns weight 1/4 ex1en/9600 examplesample 0n , weight 1/4 example 1n , weight 21 en/9600x1 , . . . , xt .Theorem 8 kernel Perceptron run using sample polynomial size p(n)probability least 1/16 error final hypothesis least 0.49.Proof: probability 1/16, first two examples received 0n1n . Thus, probability 1/16, two examples (as proof above) Perceptronalgorithm w = 0 coefficients w equal 1.Consider sequence examples following two examples. First notetrial, occurrence example 1n (i.e. occurrence either xiP0n example) decrease [n] wT 2n/20 . Since first two examplesPw (1n ) = [n] wT = 2n 1, follows least 219n/20 1 examplesmust occur 1n example incorrectly classified negative example. Sinceconsider performance algorithm p(n) < 219n/20 1 steps,may ignore subsequent occurrences 1n since change algorithmshypothesis.observe first example 1n algorithm performdemotion resulting w = 1 (possibly changing coefficients well). Sincepromotions performed rest sample, get w 1 restlearning process. follows future occurrences example 0 n correctlyclassified thus may ignore well.Considering examples xi sequence constructed above, may ignore example correctly classified since update made it. followsperceptron algorithm gone examples, hypothesis formed demotionsexamples sequence xi s. difference scenarioalgorithm may make several demotions example occurs multiple timessample. However, inspection proof shows xPPseen algorithm, bounds Ai wT Bi wT still valid348fiEfficiency versus Convergence Boolean Kernelstherefore xi misclassified. Since sample size p(n) sequencesize en/9600 probability weight examples sample 0.01 sufficientlylarge n error hypothesis least 0.49.24. Computational Hardness Kernel Winnowsection, x {0, 1}n let (x) denote (2n 1)-element vector whose coordinates nonempty monomials (monotone conjunctions) x1 , . . . , xn . saysequence labeled examples hx1 , b1 i, . . . , hxt , bt monotone consistent consistentmonotone function, i.e. xik xjk k = 1, . . . , n implies bi bj .monotone consistent labeled examples clearly monotone DNFformula consistent contains conjunctions. consider followingproblem:KERNEL WINNOW PREDICTION(, ) (KWP)Instance: Monotone consistent sequence = hx1 , b1 i, . . . , hxt , bt labeled examplesxi {0, 1}m bi {1, 1}; unlabeled example z {0, 1}m .Question: w (z) , w N = (2m 1)-dimensional hypothesis vectorgenerated running Winnow(, ) example sequence h(x1 ), b1 i, . . . h(xt ), bt i?order run Winnow 2m 1 nonempty monomials learn monotone DNF,one must able solve KWP efficiently. main result section proofKWP computationally hard wide range parameter settings yieldpolynomial mistake bound Winnow via Theorem 2.Recall #P class counting problems associated N P decision problems; well known every function #P computable polynomial timeP = N P. See book Papadimitriou (1994) paper Valiant (1979) details#P. following problem #P-hard (Valiant, 1979):MONOTONE 2-SAT (M2SAT)Instance: Monotone 2-CNF Boolean formula F = c1 c2 . . . cr ci = (yi1 yi2 )yij {y1 , . . . , yn }; integer K 1 K 2n .Question: |F 1 (1)| K, i.e. F least K satisfying assignments {0, 1}n ?Theorem 9 Fix > 0. Let N = 2m 1, let 1 + 1/m1 , let 1max( 1N , ( + 1)(1 + log )) = poly(m). polynomial time algorithmKWP(, ), every function #P computable polynomial time.Proof: N, described theorem routine calculation shows1 + 1/m1 poly(m)2m2poly(m) .poly(m)(1)proof reduction problem M2SAT. high level idea proofsimple: let (F, K) instance M2SAT F defined variables y1 , . . . , yn .Winnow algorithm maintains weight wT monomial variables x1 , . . . , xn .define 1-1 correspondence monomials truth assignments {0, 1}n349fiKhardon, Roth, & ServedioF, give sequence examples Winnow causes wT 0 F (y ) = 0wT = 1 F (y ) = 1. value w (z) thus related |F 1 (1)|. Notecould control well would sufficient since could use = Kresult follow. However parameter algorithm. therefore makeadditional updates w (z) + (|F 1 (1)| K) w (z)|F 1 (1)| K. details somewhat involved since must track resolutionapproximations different values final inner product indeed givecorrect result respect threshold.General setup construction. detail, letU = n + 1 + d(dlog 4e + 1) log e,n+1V = loge + 1,U +2W = loge + 1let defined= n + U + 6V n2 + 6U W + 3.(2)Since 1 + 1/m1 , using fact log(1 + x) x/2 0 < x < 1log 1/(2m1 ), easily follows specified polynomialn. describe polynomial time transformation maps n-variable instance (F, K)M2SAT m-variable instance (S, z) KWP(, ) = hx 1 , b1 i, . . . , hxt , btmonotone consistent, xi z belong {0, 1}m , w (z)|F 1 (1)| K.Winnow variables x1 , . . . , xm divided three sets A, B C ={x1 , . . . , xn }, B = {xn+1 , . . . , xn+U } C = {xn+U +1 , . . . , xm }. unlabeled example z1n+U 0mnU , i.e. variables B set 1 variables C set 0.PPthus w (z) = +MB +MAB = 6=T wT , MB = 6=T B wTPMAB = AB,T A6=,T B6= wT . refer monomials 6= type-A monomials,monomials 6= B type-B monomials, monomials AB, 6= , B 6=type-AB monomials.example sequence divided four stages. Stage 1 results |F 1 (1)|;described n variables correspond n variables CNF formulaF. Stage 2 results q |F 1 (1)| positive integer q specify later.Stages 3 4 together result MB + MAB q K. Thus final value w (z)approximately + q (|F 1 (1)| K), w (z) |F 1 (1)| K.Since variables C 0 z, includes variable C value wTaffect w (z). variables C slack variables (i) make Winnowperform correct promotions/demotions (ii) ensure monotone consistent.Stage 1: Setting |F 1(1)|. define following correspondencetruth assignments {0, 1}n monomials : yiT = 0 xipresent T. clause yi1 yi2 F, Stage 1 contains V negative examplesxi1 = xi2 = 0 xi = 1 xi A. show (1) Winnow makesfalse positive prediction examples (2) Stage 1 Winnow never350fiEfficiency versus Convergence Boolean Kernelspromotion example variable set 1. ConsiderF (y ) = 0. Since examples include example monomialdemoted least V times. result Stage 1 , w = 1F (y ) = 1 0 < wT V F (y ) = 0. Thus = |F 1 (1)| + 10 < 1 < 2n V < 21 .show Stage 1 examples cause Winnow make false positive predictionnegative examples xi1 = xi2 = 0 xi = 1 describedabove. negative example Stage 1 six new slack variables x+1 , . . . , x+6 Cused follows: Stage 1 dlog (/3)e repeated instances positive examplex+1 = x+2 = 1 bits 0. examples cause promotions resultwx+1 + wx+2 + wx+1 x+2 < hence wx+1 /3. Two groupssimilar examples (the first x+3 = x+4 = 1, second x+5 = x+6 = 1) causewx+3 /3 wx+5 /3. next example negative examplexi1 = xi2 = 0, xi = 1 xi A, x+1 = x+3 = x+5 = 1 bits 0.example w (x) > wx+1 + wx+3 + wx+5 Winnow makes false positiveprediction.Since F n2 clauses V negative examples per clause,construction carried using 6V n2 slack variables xn+U +1 , . . . , xn+U +6V n2 .thus (1) (2) claimed above.Stage 2: Setting q |F 1(1)|. first Stage 2 example positive examplexi = 1 xi A, xn+U +6V n2 +1 = 1 bits 0. Since 2nmonomials contain xn+U +6V n2 +1 satisfied example wT = 1,w (x) = 2n + |F 1 (1)| + 1 < 2n+1 . Since > 2m /poly(m) > 2n+1 (recallequation (2) > 6n2 ), resulting promotion w (x) =(2n + |F 1 (1)| + 1 ) < 2n+1 . Letq = dlog (/2n+1 )e 1q 2n+1 < q+1 2n+1 .(3)Stage 2 consists q repeated instances positive example described above.promotions w (x) = q (2n + |F 1 (1)| + 1 ) < q 2n+1 < . Since 1 <|F 1 (1)| + 1 < 2n alsoq < = q (|F 1 (1)| + 1 ) < q 2n < /2.(4)Equation (4) gives value throughout rest argument.Calculations Stages 3 4. start Stage 3 type-B typeAB monomial wT = 1. n variables U variables Bstart Stage 3 MB = 2U 1 MAB = (2n 1)(2U 1). Since exampleStages 3 4 satisfies xi A, end Stage 4 still q (|F 1 (1)| + 1 )MAB still (2n 1)(2U 1). Therefore end Stage 4w (z) = MB + q (|F 1 (1)| + 1 ) + (2n 1)(2U 1).351fiKhardon, Roth, & Servediosimplify notation let= (2n 1)(2U 1) q K.Ideally end Stage 4 value MB would q 1 since would implyw (z) = + q (|F 1 (1)| K) least |F 1 (1)| K. Howevernecessary MB assume exact value, since |F 1 (1)| must integer0 < 1 < 21 . long1(5)MB < + q2get1+ q (|F 1 (1)| K + 1 ) < w (z) < + q (|F 1 (1)| K + 1 + ).2|F 1 (1)| K clearly w (z) . hand |F 1 (1)| < Ksince |F 1 (1)| integer value |F 1 (1)| K 1 get w (z) < . Thereforeremains construct examples Stages 3 4 B satisfiesEquation (5).next calculate appropriate granularity D. Note K 2 n , Equation (3) q K > /2. recall Equations (2) (1) >2n + U + 6n2 > 2m /poly(m), /2 2n+U +6n /poly(m) 2n 2U . Consequentlycertainly > /4, Equation (3) > /4 > q 2n1 > 14 q .Letc = dlog 4e,1qc q < D.4(6)unique smallest positive integer p > 1 satisfies pqc < + 41 q .Stage 3 examples result MB satisfying p < MB < p + 14 . that:1qc < pqc < + q43 q4q+1 2n+1 3qc=qc(c+1 n+123).(7)(8)(9)(7) holds since K 1, thus (by definition D) + qequivalent Equation (7). Inequality (8) follows Equations (6) (3).Hence1 < p c+1 2n+1 3 2n+1+d(c+1) log e 3 = 2U 3,(10)second inequality chain follows Equation (9). usefollowing lemma:352fiEfficiency versus Convergence Boolean KernelsLemma 10 ` 1, 1 p 2` 1, monotone CNF F`,p` Boolean variables ` clauses, exactly p satisfying assignments{0, 1}` , constructed ` p poly(`) time.Proof: proof induction `. base case ` = 1 p = 1 F `,p = x1 .Assuming lemma true ` = 1, . . . , k prove ` = k + 1 :1 p 2k 1 desired CNF Fk+1,p = xk+1 Fk,p . Since Fk,p kclauses Fk+1,p k + 1 clauses. 2k + 1 p 2k+1 1 desired CNFFk+1,p = xk+1 Fk,p2k . distributing xk clause Fk,p2k write Fk+1,pCNF k clauses. p = 2k Fk,p = x1 .2Stage 3: Setting MB p. Let FU,p r-clause monotone CNF formulaU variables B p satisfying assignments. Similar Stage 1, clauseFU,p , Stage 3 W negative examples corresponding clause, Stage1 slack variables C used ensure Winnow makes false positive predictionnegative example. Thus examples Stage 3 cause MB = p + 20 < 2 < 2U W < 41 . Since six slack variables C used negative examplerW U W negative examples, slack variables xn+U +6V n2 +2 , . . . , xm2sufficient Stage 3.Stage 4: Setting MB + MAB q K. remains perform q cpromotions examples xi B set 1. cause MB equal(p + 2 )qc . inequalities established above, give us11pqc < (p + 2 )qc = MB < + q + 2 qc < + q42desired.order guarantee q c promotions use two sequences examples lengthnU nq dUlog e log e c respectively. first show positive numbers.follows directly definitions U = n + 1 + d(dlog 4e + 1) log e c = dlog 4en6n2 (by definition Equation (1)) boundedUlog c. Since > 2polynomial m, clearly log(/2n+1 ) > U n + log(). sincen+1 )U nnq = dlog (/2n+1 )e 1 implies q > log(/21 > dUlog e, q log e > 0.log()nfirst q Ulog e examples Stage 4 positive examplexi B set 1 xm1 = 1. first time example received,2w (x) = 2U + p + 2 < 2U +1 . Since > 26n , inspection U 2U +1 < ,nWinnow performs promotion. Similarly, q Ulog e occurrences example,qd U n eqd U n ew (x) = log (2U + p + 2 ) < log 2U +1 q 2n+1 <promotions indeed performed occurrence,MB =nqd Uelog(p + 2 ).nremaining examples Stage 4 Ulog e c repetitions positive example xxi B set 1 xm = 1. promotions occurred repetition353fiKhardon, Roth, & Servedioexample would w (x) =ndUeclog(2U +nqd Uelog(p + 2 )), needshow quantity less . reexpress quantityqc (p + 2 ).nec UdUlog21qc (p + 2 ) < pqc + qc43 q1+ q4161 q<2+(11)U n ec(11) follows (7) definition c. Finally, log 2U122U nc log < 22U n2 < 2< 21 q , last inequality Equation (3)2n+1previous inequality inspection values , U . Combining twobounds see indeed w (x) < .Finally, observe construction example sequence monotone consistent.Since = poly(n) contains poly(n) examples transformation M2SATKWP(, ) polynomial-time computable theorem proved.2(Theorem 9)5. ConclusionLinear threshold functions weak representation language interesting learning algorithms. Therefore, linear learning algorithms learn expressivefunctions, necessary expand feature space applied.work explores tradeoff computational efficiency convergence usingexpanded feature spaces capture conjunctions base features.shown iteration kernel Perceptron algorithmexecuted efficiently, algorithm provably require exponentially many updates evenlearning function simple f (x) = x1 x2 . . . xn . hand, kernelWinnow algorithm polynomial mistake bound learning polynomial-size monotoneDNF, results show widely accepted computational hardness assumptionimpossible efficiently simulate execution kernel Winnow. latter also impliesgeneral construction run Winnow using kernel functions.results indicate additive multiplicative update algorithms lie oppositeextremes tradeoff computational efficiency convergence; believefact could significant practical implications. demonstrating provable limitations using kernel functions correspond high-degree feature expansions,results also lend theoretical justification common practice using small degreesimilar feature expansions well-known polynomial kernel.2Since publication initial conference version work (Khardon, Roth, &Servedio, 2002), several authors explored closely related ideas. One showconstruction negative results Perceptron extend (either PAC2. Boolean kernels different standard polynomial kernels conjunctionsweighted equally, also allow negations.354fiEfficiency versus Convergence Boolean Kernelsonline setting) related algorithms Support Vector Machines work constructing maximum margin hypothesis consistent examples. paper (Khardon& Servedio, 2003) gives analysis PAC learning performance maximum marginalgorithms monotone monomials kernel, derives several negative results thusgiving negative evidence monomial kernel. paper (Cumby & Roth,2003) kernel expressions description logic (generalizing monomials kernel)developed successfully applied natural language molecular problems. Takimoto Warmuth (2003) study use multiplicative update algorithmsWinnow (such weighted majority) obtain positive results restrictingtype loss function used additive base features. Chawla et al. (2004)studied Monte Carlo estimation approaches approximately simulate Winnow algorithms performance run space exponentially many features. usekernel methods logic learning developing alternative methods feature expansionmultiplicative update algorithms remain interesting challenging problemsinvestigated.Acknowledgmentswork partly done Khardon University Edinburgh partlyServedio Harvard University. authors gratefully acknowledge financialsupport work EPSRC grant GR/N03167, NSF grant IIS-0099446 Research Semester Fellowship Award Tufts University (Khardon), NSF grants ITR-IIS00-85836, ITR-IIS-0085980 IIS-9984168 (Roth), NSF grant CCR-98-77049 NSFMathematical Sciences Postdoctoral Fellowship (Servedio).ReferencesAngluin, D. (1990). Negative results equivalence queries. Machine Learning, 2, 121150.Block, H. (1962). perceptron: model brain functioning. Reviews ModernPhysics, 34, 123135.Carlson, A., Cumby, C., Rosen, J., & Roth, D. (1999). SNoW learning architecture.Tech. rep. UIUCDCS-R-99-2101, UIUC Computer Science Department.Chawla, D., Li, L., & Scott., S. (2004). approximating weighted sums exponentiallymany terms. Journal Computer System Sciences, 69, 196234.Cristianini, N., & Shaw-Taylor, J. (2000). Introduction Support Vector Machines.Cambridge Press.Cumby, C., & Roth, D. (2003). kernel methods relational learning. Proc.International Conference Machine Learning.Kearns, M., & Vazirani, U. (1994). Introduction Computational Learning Theory.MIT Press, Cambridge, MA.355fiKhardon, Roth, & ServedioKhardon, R., Roth, D., & Servedio, R. (2002). Efficiency versus convergence Booleankernels on-line learning algorithms. Dietterich, T. G., Becker, S., & Ghahramani,Z. (Eds.), Advances Neural Information Processing Systems 14, Cambridge, MA.MIT Press.Khardon, R., & Servedio, R. (2003). Maximum margin algorithms Boolean kernels.Proceedings Sixteenth Annual Conference Computational Learning Theory,pp. 87101.Lint, J. V. (1992). Introduction Coding Theory. Springer-Verlag.Littlestone, N. (1988). Learning quickly irrelevant attributes abound: new linearthreshold algorithm. Machine Learning, 2, 285318.Maass, W., & Warmuth, M. K. (1998). Efficient learning virtual threshold gates.Information Computation, 141 (1), 378386.Minsky, M., & Papert, S. (1968). Perceptrons: introduction computational geometry.MIT Press, Cambridge, MA.Novikoff, A. (1963). convergence proofs perceptrons. Proceeding SymposiumMathematical Theory Automata, Vol. 12, pp. 615622.Papadimitriou, C. (1994). Computational Complexity. Addison-Wesley.Rosenblatt, F. (1958). Perceptron: probabilistic model information storageorganization brain. Psychological Review, 65, 386407.Roth, D. (1998). Learning resolve natural language ambiguities: unified approach.Proc. American Association Artificial Intelligence, pp. 806813.Sadohara, K. (2001). Learning Boolean functions using support vector machines. Proc.Conference Algorithmic Learning Theory, pp. 106118. Springer. LNAI 2225.Takimoto, E., & Warmuth, M. (2003). Path kernels multiplicative updates. JournalMachine Learning Research, 4, 773818.Valiant, L. G. (1979). complexity enumeration reliability problems. SIAMJournal Computing, 8, 410421.Valiant, L. G. (1984). theory learnable. Communications ACM, 27 (11),11341142.Watkins, C. (1999). Kernels matching operations. Tech. rep. CSD-TR-98-07, ComputerScience Department, Royal Holloway, University London.356fifffi! #"$ %'&)(*)+,(--.0/1((!2'34(5!264789 :)-;0<-*=?>7 %&:@-A0<-.BDC4EGFHCEGIKJHLNMPORQTSUJWVGMPQ9LXJZY[O]\GQ^Y[\GORL`_bac\dEHegfhC4ijLlknmWEGMoipC0Q9qr_sMoEGtuvORwyxdz0L{ik|C}pQN\dzYgm~vJZY[LVfwMPORtkLilmWq$YRC0mWC4EGIfMoxd\JHLNMPORQ#SRR1^??g?yyg?g?'?9N1 G?TG01P! 1)$41$1,#gyr1g'{#$,ffR1ff0$rDgG1gg1ff0$]g0@0g)y]?HG)R?)Rg?!ff fififi 4! !"#fi $fffi% ff&' ff&%(*) $ff ,+- fi$ % fffi." fi0/%1+fi3245(6/7fiy 8 fi ,$9fi:%ff;48 fi<:fi$ff=?>@? : ABBCD !/%:4/E?FfiG?H!JIK !-1sL:fiMfiWE/%?E/% ff&NfiOZM+QP?+Rfi !$:?S5fi !^$ff&fi TIU E$./% E&Bfi%/%$!5fi &%(V$?$.E%(WG/%+M!TE/= !/%U A(X 4 8 fi0fiYfi '!0 : G#4 8 ?Z 8 ff%[ ?ESO:E fi $?\/% ]F0 $,+>5^_'SfiE ff/%?K), fiE ff<SfiUS`Mfi5 a,fi (V fi:b / $ff E&:fi $ffdcWeUf%4ZgI 0/fiZ ff<CD? B ?$&fi A=1T .?h fi8CDifi 3Z P ?$ff+ >Y43 ?M fi E$ff+ICZ /%?-fiE8 /48 -4 b/% ffESy .,C ?<./%fij$fi%4 $9fi:% ffZ HE/T Eh! ?fi: ff $k fi$ % fi7 ffff&E$+lSfi ,$ 8?/bCD AN:fi $ffm/% A]F $A,+b#fi TC ?$$(VPUEfi8CDb?N 4 $ff&fi En#fiBeMf%4L ffU fiM/ ESy/ M+ $ff,$ />Yo*!3::.??IC /% ff0. " fffi E3fiSfi- ff&U"fip E ff3-!E/b/?$fi: q?Crfi%/%$3fi :E fi $?s/% ]F0 $,+7 8BSfi ?S E?/ X ?ES ff??>^bF fi8C8] ff$,$ /t $&fi Au ` K-fi%/%?$/BCDff& X /%?$ ,`+ G:$ffK , Uvfi Gff&U (#fi rC /<E/finrC $ffPp> K= E/%fin^C $Pw-fi%/%?T$ ?Sfi U#fi'E4 $ffs+ $ff$5fiZ = , ? ff$ff A,+ffR7SfiU,- ) E ?/N fi_$fi%.fi Qfi:% Z r$ E/Q (6fi:% ffZ $Kfi$ % fiEh fi_ E/%fixeUf%4E/_: fi8M !/%?`lS`%:,$fffi_#fih/% Ap.S?' l/% ]F0 $,+bfiD E/%fisEO, . E /eMf%43?>Yyk ff $ff$ff+ICZD/% ff0. [./B?-:E ff4 $ff$+'EU , 8 ,CZfifi8$M:?/% ! fiEk ?& /% ff& ?H $&fi4.? 1M fi?>"yk ff?IU EGfi%/#fiDSfiE, . ff&h ff , $J fi$ % fffi0 ffZ ff&$ff+E$ ffP?$+- fi- ff-: G: #fi ESfi?q!J>kfMSfiE/IU Fff fi $!Z/ G $ff?S /fi .H ' $#$ O:fi $ff=CD ff$ ff` $ fi E$ffb+ 1fi !/% E&T 4 l& 8 fiJzk $ E?O$,&?TS?+=$! / fi= ff&E X 4 U{/%& / 8 fiEZ T: #fiZ E>"| }7~U g,RD%Y9S%9J#w8J 0J%'1p8#w1JS8M9iS1.M.SQ,i8<%5.F%8W%YnZp%Z%pM"O#MSkJ%kv-.8k%1E .S%v 7kv%#S"3%%3p%8Y-.8xp<%#*5M%%E?<'<< 2 M<SQR%819EF6%=S7MM#M9#NM1%98%w6%iB%O7%S-%%%S9<{lFh#'%J%h%59S%9nJS%J1G%J_J%p#JT ,!5,iO5?,UuOUW-kO8 ,,",3U?%UW U(--.^ g %% !: &0%1% 0:fi$4$,ffZS9 98%.h#JE-#.bSTSMSJSJ#Rv8G8 MS9%17J1S%k9S%9 Jw89%%JN%#%%SJ vJ%S9#3YMk8UGO#.%SMO1D7p# %JSM9qMT6%KSff%%7S9J##BJS%fi. i? 'Jfi. #q%{JM 19JM%#%%JS#< MS#J%9 %9J%qv17%ZS=S%JJMl%JL<iB#<SSJJ_JS%Y<G#lS9J##0SM?"ZM9lM?%%%#SJ<MBS8MJw%G%7qSB7G v1S%-M9JS%J6%%J8MS#qJp J%##JSJG7S fi. fi%#NR88%"3%%'%JL8SESwS8JS.OS=SM1,%W,S1MS-.7176%SSM9FwMS#l%8hSF8S'17v8SS hB# spqSJ#*M% i# 8 8h# %-<S?%%vZS"K%%?' J#=MJ8BJ%q%?J8%Q1JS#J8M9F%M%J1-#Lv86%<%J1_S#J1<Z%###M?!JJ7JMS< v1S%Sq%iSM9HM %%%#SJ<=6%fi u## "%k179MMS%#_##Sh9S%%SS'9%Ov8L<%=iMNJ8%%9#7%N9J8S%J9#q% S=%%%#SJ<G%YJ*%J?JM%18$ #7S=JJJ8p#J#p8%vM?pJ%<#8JJ8SS%JJ#BBEqS'JJ%w#8KMS'k1S#%BTS% fi ZM%97JJ8#J-S09%<#8O<.OvF7pJ J_<p#lVSS8'7JS%7ESB#lv8SW%?<%J1%h#B!,JBLS9MhSqJ1SJSF%DSqMQ9%1T# &YJ1OJ%9xJ#w8J b6%SM9HM %J%S80p8%SM %%%S9<w ''88%'%# "?GJ( .S%Z<#9%EMJJ%b08%%Y#1i7p#{{0ES#WqShWMS%"S-M?bY%1BSJMiMSJ9N1%SS#M hS M18<J%7v8SW%?7Q1J%7%J%p%STSMSpSJ#wv8G8lUM?JiM?L9%1WMSJSi%J_JS%9mJb8J76%O %##M* )SM9lM?%%%#SJ 6%S+fi. 6MS", Y. -hG%{d JS8%DM%M{M% /?10=2 9J9#G8S#MS%#_8MS#%# 3G<%.lWMSJS'SJMhMSFB#Jwv#8%l_# &9JJ1JS%9d9w8J w6%p8%M?7MS%.#qV%18J0Mpq1%SS#M7hSqJS%9jJb8J%KMS{SJ?7%DSJv8D%v%JS#w%J#S#J',i#MSq8%,Y%%?pS'9%.vhS 8,p#%J8T %#S"pM%?%JwSB7%bJ#S%J1Bk8 8b%JJnp8%%JS#<b*RM6#" i8SBS" =%J68k%%%81J.h6%h#SOSJ%<SJ?l%ZSJ%S% UMM9## b#RM1-W%- %##M* )O%%%?SJL1.%8iB#W SM? JS%9 Jb8JW%7p8%iMr%J 546B 4D,p#J%8=8F%* M%%E?Z<6JJQSJM=SJ<7%J#SS%J17v8G8%J #8%K%JS<L%JS_MSF%9S#<%S#S"3BJ#?_% 78 9 :(;=<>9 :(;*K#9JQ1%SS#MBS9S%9Jb8J%v%81J.S#l6%FM#%?@/_%Sq%S%DUM?#M9###L#QM1S76MSS8=%*M% /?Nb6S879MHSJM 7A8 9 :B;C<D9 :(;%81J.SqW%q0J?%iSbUM?#M9###S1D%vp8MS#=S,%9S#<%#S9 =SJE fi Z%%JTW%{9= k8J1D#qSiS#MS%'9w8J%G FH JMS( I7%8JJFS1S%9#MK ILfi 8h8%8SS8S 7A8 9 :B;C<D9 :(;O1<7p9%78%8%OS%S1<#8K?8{S_1vJS_%179JS# 7A8 9M:(;=<>9 :(;K##<R=%J%ph_#MS%R<%#59S%9 #JS%918Y?%#S#b1p18J-S8M?J#_S8%#M9#lL7%SqS%##SS#8%#lS 8QJS%Y #9S%J18F1J"kSSJJ%#JJJ8qSJ 78 9 :(;=<>9 :(;O7pOMSN#M%_6%wJ0k8T%hJS%9 #9S%J18G%J SN7pi#%F%88JM<6%=S<7=Jb8J-JS%9 #9S%J18q'J5Yv8%J7SJ 7N8 9 :(;=<>9 :(;D7pJShJ_J#S1-JS.h#._STJp,S#<vJp%-%Z%###M?* )B%%%?SJLk78SES#<%hJJ8SS%JPORQTS 78 9 :(;=<>9 :(;5#B<JJ#b1%SSMLBSLM?R1S8=#.SpJJ1Bq%v1i7pJS9MG1%S1SiW%GShM6%S7.SlU Y8J8%5S78 9 :(;=<>9M:(;p1SK<, 'J 7p*MB9#09%TT8S%#q%J%pS# %9SJG?Jp,S#7vJp%%Z%##M* )%%%S9L"#S<MSMM9%88M% %819ES#JLW%=%80# V %GSTUMM9###RS01h%{p8MS#wv%SR%JS#<% %JRSJ,%JS#<%3#S9O_wB#=?%%0%D9S%9#JSS%J18R%Sv8 98%%pFSSM9##SlSJ=W##B#JqSJSU 3WBWBWfi91#gfiffggM-pM<7 %##M*)Z%%%S9MJvMK=vGv1S%TSS#1T=SJ9%1 8 9 :(;%7SJlSJM1ES%#9Lv%S p8%%JS#< %J\#S9lSJMRMS%8 8#VSk8$ 98%#%" <<%-iL6SbGp8%"%JS#wpBZ%##M* )F%%%?SJ 8%Hvw7pBS<MSMM9J9J# %qRMM#%.%'S#TY<1J7JS9% ?%J i% %8qS8 9 :B; SY%1%_'J<G%#1J9#S=GJ%SM9TW%?<%Y#%#QS7%JS#SR9S%9M9#S8FKS8kSJ7JS%9M9#L%GM?<p#08#8l66MS86SbDShJMS%9S#<%9S#Sb#{J%k%SJ%5V#.%89S%v%SSJ%W<uS8JSS.NJ#S%J16S SJMSN%JS<%=#S#"dp1J"SMb1p99SK77.SJ 3D{{7%SB%07%-88l66MS8{6SbZShMS0%JS<%S#iSM JS8pJQ<% 88T 66MSSJ806Sb=SbM%9S#<%5S"{R%S8%8kSF?%Jdi%l7J"%81JESh6%BMB%-% V %KSMM#MY## w#lS<%NM?R1-%1SSBT?%%F%KB#9S%J18/BBi%Jji%07pp#Z( J%#%88JM'6%D%JL%G%S &JE%J &JhS%Lfi. 8-hG8%8<%J= v8SJ1{1p#S{#TSBJ0k8D%vSMG#TSOi%k.*%.S'<U#<%vS9=J#SS%J1Fv8G8Rb#SL%9NSJMSB%9S#<%5S"=v8SJ1h#SJb<U#<%J#S%91FVJ#Q%81JEq6%G#!,pBJ= v8SJ1Sb9w8J %9S%9d#9S%J1'?Bl6SdSSFUM?J'SJ8#%SBB7%88%1Q%S7%9 G%Q7pZ%J68-NlSM9 M?%%%S9 Y%S7vG8S69 H7%b%k8?M%5BJ #=7%S<8#QS#M RSM1,%W,S1MSSMYNM?R%%%#SJ<O6%'Sfi uSJ%R %##M* )i%%%#SJLBB<%JJ G%# <1%SS1S JS9#1S=SJMq#JS#MS_Z%##M* )=%%%#SJ 6S9p J%# SMSS#SJ0B##JH#7JS%lk8W%w%J1_#'SL#JSJTMS%8l8#F<SFJMS'%JS<%5#JS"BBB%9ni%77p91%S1S7JSJ1S{SJMG%E7SM9bShMS%8SJ%bS-<#J!qJ( .J#ST%<M?wSMJMS#w#{%0#J1S%OSJOW%1S#7%vS'M?S9%1T19#%SRRZ%###M?* )B%%%?SJLv%JQ%=b1JS( .91qp#Q_8fi "!#w#9S%9 9w8J %<W%?<%#%5SJw8#<ES%JMSS7%'#M%<SM9S0#F%61p9#%S79.%9S8SNSJMT#MS%b.0#<9%10M? SSSb#S%&91pY## w%JlSFSJS#Jq#9M9## <w8MS8VJ##w1p9%SSS9%1F%K.k%?#TMSJ8 0DSJSKJSOF7%S'8S%7%J<1J18B%81J.%kSJ#K9J7lS1.1h%ZSJ fi. Z'JRS<%J8<%FS9#<9Mv8_#<%S%9 8 %_6#B8 Qk8r# 1SJ_%J /BSw1JSN%DS fi Z9 %##M* )B%%%SJN9%JNSJJS%Y #9S%J1B9R#N%J%pS#TB<Ev%SS#=9J8p#b%J%#S=#F8S%###1S$wbSJw<M 8%J 1#S$ .J_9%7SM? 9S%9 J#w8J W%wSM9uM?r%%%?SJ<T6%<S5fi# 1S 1S#JqRSSJ NW% Sl1%S_%'S_9Mv8ZBJGl8%% %JM%##JMQl%J i%r7ph%0Z%###M?* )w%%%?SJL p1S 8 1p9%SQSMJ9#8M9###_%{Sq%J G%#R7p3L7%q?J1SSJS%9# #JSS%J18F1S %1p9%S7SJRMJ9#8M9## %SN%9 i% 7JOHSMYrM?r%%%?SJ SJM_#7%SL8JS.SMS%N%SM1,%W,S1MSl%%%SJwTW%<SJ5fi. S9%u %##M* )T%%%?SJL1SJ8S%##D TJ%kSJB%JJni%77JJ#<JSJ#1S#%B8M9%8 %{-198#JqJS8JSShSJB#79#8MSJZ%v{SJSD%J<9S1SJK6%{VSSOMb#w1S( /WBW%fi$4$,ffZK} ]ff1 ~U fi11J#8LSG#!,pB SMS#MF88?<#J#SS#Pfix# hJ#%9LqJNvJSp1S_1%1Sw91-_%?L% <%J=Gff8 8B#8O%*"%%?%?%B#GSlS_%N% <%JO#_TJS1U 9Jw%J8B8S!.iJ%S"%S w%J#J #$%0#HSlSS%?8T%%&'_JSp1SS#JR%%=<%?J#' !D#%)( +* %Jw#8%#<%w%k8?MS" 4hw%v8MS"( +* qJkO9S1<%?J#!.06%7% #E8%?%G9MS&,-+*#. p0J1L#J#S#M"KJSp1SS#J8%J%7vJS1,<J%J 1J8SJ1R#9Jp#JJ%5w%J#J-=%=%#G"5*%3S7<%J=MSJJ#8M9%8 S?18s%R/012ff(3+* 8%JJ%_v8# JSp1SS 9ES#ff( + *54 2/ J%179#8H9S1S#'_SJJJ##JR%1S%L#q<#J#w 87SL<M%9%76 98;: *%ST1798S#RS#<%{ST#%-%v8MS%%.%3-M%9%p<J#< MS#N6%-SJ fi#9<>=JMNW%?. 7%J@ A. /L,=MS8% fiJJ"9 8SJ*5CBM?4-L#JS%91-%ZSD E) fi u#iJ9$ .J<U 9_wSFS8O%F G %v8MSLJJMSJ,-+*q%JH5%SJS#w%?8ffh7U 9Jq JICKML fi %%QJS%J10%8M HS%7Y##iSN,-O*#J8vJJES-%JFJ9W%?<B6S %#.8SM%P+QSRUTWVRYX.%Jb*51J91S#SD W ?%Jmv80JSMSJG%3S=#.8%8'( J1Z\[MT^]^]^]_T;RO%WHQFR$[%J`VRa[ %rVZ%##M"h%# / -<S%,iRESpO?b %F%# "? BR<% %2 fivJ9<MSbJS%J18Y#J8#J9#0<OW9JL#lS 0G'dc3#JMS ( JMF%J fihp,%JJ fi. =8%v<1J91. #7vS_SJ1SS7S8=Se,-+*M3Se%v%S"- lJM%"SM?8J%7JN1JS8SRJS%J1-BSQ91SS>v%#Si#G%.W%GM_T%JMJi1#S#q78SpJW%i%8MSqJp,%Jf,-+*-W% &J S%S?JJ#RJ%9<l6MS" iMS9J8"K J#S8%{ -hG%OM%q fi. Z. 0LMJS%? %8MS#JuJ1Sg #.%%l9MSSJ#JHS8L%\ <%JL#. OWh1.SJ8( J%#.S 8bS98S8%# OK jilk9@K O#m pn pK !?G%i1p%7Y%.h OWhY[ pS8%Y <%9##h9MSSSJ#._GNS98S-1.S%#J#_ST<%9#TqSSqqrM%JEqrMs TSSE"SSk1S#%%0SJ?lGM,9MSSS#S<%38%8SL%qJ=vJSp1S %#G<%?J#7#HS+JS09MSSHk86%SlJSp18J#JR%.H<%?J#l#1Jb9MSS#S"R BT1J%ESGMS-9#%1<bS%bSS#J%8?{BS9#7%_9MSS"TS868h fi. hBS OWh[ bS#79#_% OK jilk9@K Ofi. 8ffc5S-1<7 MSffkt#K !KQuKjm fi. 8B8 OWhv[gY*%J%#"%ZS%9Op#SiSFw%J#J'#lS%7FJS1J88<#_%J8J#GSiJSSJ1i%Y91SSi%W7wM%{SJJJ##JBJS%Y< %S8DF%F6MS80%,KM%?{S9#F#0%FS_8%w6% fi FBS?J1SSwN=% pA %JAZS%8?M%<Jw8J#_%{JS%9#x#JS%919xN%h<%SS.LSJ01-S( JSRbSJ8hp8M%_%JS#<%vSb%GTJ%=S-%JS#<%<% qS#S"xw#<9#8%TJS%v%SSJ%9OWh=Q%S8G%J8v%JJ fi -MST%8%LST%S=#9S%J18vBJ2&JBS% fi.MSqS77Jw898U#JJ16%SJ#h%98SMMS <-6S wBMM8 N%J18%71%79%i%S8787%*'%%T#.SpJJ1 8ST% 8Q%J %J G%S &9 fi.#H%%"S%9 fi B8 J#SpL%_%JS#<%##%9hJ#=Sq%JS#w%3<M%Y%J%B%#90b%BSbG%S &J fi 0MS_8JSS.SJph"Qp#w##M%3S_<q9w8J8'_8FvJ?J<MSqJS%Y<8K#SJ8%JwB79 )D#V%7J'8Ub80#JS%J1'%9L4hJ91M7%JQi.% )q%pz|{|}NJS%J18kMS0%% FM# Iw%S &Jj% &JBS%!fi. 8Y#NSJMS7S( J7ESJMF%vTJSp1S %#D<%?J#=J7%S &Jn9MSSS#v86%SJSp18J#Jqb%EL<%?J#F#lSJ1pO%S &J\9MSS#SL#OS##ESbS#Up"~98*, o;GGD , ? 3,'-,*S, MV,AM6U*! 8,OWBW^fi91#gfiffgg4-88MQ1w7p#T%p8%'M?r%%%#SJ<7MSN%J8%#H6J91SJT%-SR8<%%9%b%9S#<%5SJO_<J%9d#JSS%J1b6MSQ8h%,kM%/3p#%8B8h%*vM%%E?%JSb1q7p#=Gb8%#% 8<6JSS8F7YJ%S 8<S9#8vJJJ1%_#9MFS-179SMS9%91G%".978MS".i%J%pS#{##MS%TSS#1b08S%3' T%JDw0%9L%S &JF%JL&9BSJ% fi %l8O1.S%#JM%%7#JS%91GMY1%pBSS, +* S%<9T6S S'#.8SM%P!MT%3X,3F%SDS'8%#M9###%k{17J#8%G'%#J'08{%D8%w8'w8F?%Jfi 8%h8S'S,-+*BMSBJJ#W%wS%7Y76SSBE8SM%P!MT%3X,L 1S 8pKw19S#8S8S%=8@ 8NG%S &J %J1&9BSJ%fi. =%8?M# %u%9%%%Jww%J8u%l179M?MS%N9kSTBS SR8MSS%%JJS9%#S8v%SiSS9SGW%OMMJ8 8<#JSS%J1GWJ9L#_S0 'c3#JMS% 4-SlS78 80 '/c3J?MSw#JSS%J1OMSF<J%8B1JS#J8Sl9MSS#89#M<?J%#pS8_9%1%S9 98%.GJ%#8%kMES#R%Jl8S%=7M%##9MhSJSG%JS%#L9S#0OB8 Q8JS%Y S88 J%7% #JSS%J1_%? %'SLMW%7ES# JS%9 8S8QMM#%.0%GSN%J )T*M%%EB19%#.JS1SJJJ##JT%#%%SJ i%h9Lw17Yv%SSF%9S#<%"<M%Y%R%JlS08'%Z%JS#<%5S#SJ5TE G$[fffiK} #-J78SJSM9lM?L%%%S9<J%=v8b8%#%kb6%GSJ fi fi%#LjN88%55%%?%==%J%#S8YG71=% %%%S9 #.SpJJ1. %##MRH%"0T797.MM#%.q%- %##M* )q%%%#SJL{B9# GN%M%J %S##S8JJ91SJS1JSElB#S SJS8v%S . %##M" # JKnl SM1,%W,S1MSSM9 M?%%%#SJ\6%DSE fi. BSJG%%%?SJ<Z%N hBSp%JT0S9#Spk*M%?ZUU8##%JTN8##*M%%E? %9PiMJ=%JiJ%0k8?q%# =%8%8%#Kv8S6%<%91%2 4h#Z%{SJ%%%#SJ<ZvSSD=1%SBSM97M?<79%J#S SJM{K%8Sq#<##MZ=SJM{6JJT#9J= v8#wSh?#1-%57%-%v8M%pSh<8SbJb%8?MJS#%SJ8%JS9=%Z#M,8 <7%Sl7J%9#S<OS9N%BS#.JS 98MS#"0J-?#1T%b#hJMwMS#MG 86%STS%Sp##J_7%q17Y1k"SM1,%W,S1MS0%%MS9<8%G% JS{8%%b1S7p#K%"F#MS%TS#7Yi9DS8JESMS#%B%8S#7%vSM9M? %JS p<MS#8%%SS0Sl# &9JJ17%B7%S_1791%#%%SJ<7WMSJSl1O7p#%3S-9%S#-%%%#SJLGJ( .S%pO#79#7ESMS#w% T8p#M6SxZ%###M )%?#J%"%%%?SJd#lS8FSv1S8{KS81<9SL<M%Y%J1%1SR#JS%R%9S#wb179SMS#J%#L8w8#E-S#<MS#S?7%=1J"kTl%JQ6S( .JJ1E,Y% 77%SkZ%###Mj%"5-8%EL#JJ#8MbSJMlS vU J_%SJ?77%T#MS%#q#1wq#9S%J1{( .J##=F%8<#MS%hJ0v8hV*% \Bw###k5%8MS#J8{'J#"F#9S#M-#%#i%! q6S %9dp8%v%JS#<NVJ#T7S<1S1#kTv-K#9%7%vS'SJS#J-6S %##M* )D88?<#J#SS#i1JJ1S#<78Sp"4-FJ#S89SQ#1S #MZS8S<#L8J17SJM=S7 .v7%GS7#JS%J%'w8#Y-79%1'LSJv8LBSlhJ#"<p8M'%9S#<%5SJ8pB9#lGSM%0%BS=J<MSw%1S%0#lB%J%#S8#$%'&(h 8,?9,,UB?,,U ?,)$%*'+-, 8 8 +-.0/h+7S,AGM%1!T,*j7i32 ~54646#6798Y,U lEU ,o" KU* ,'%*,Zo;:1,U{K,MSZ,GA??,,U <:A,3ff,?>=p?A? D,+M???,,Uu+- *<: ?E,*%,3jU B,iOUM*A@Z,UK,S,A:1DO%?*jK,UKOB:1K?%,WBW'Cfi$4$,ffZ9FM%wc %M%H8T%* )l%%#,B 7%b%v8M%ZhJ#HiM9%S%1EL%v8MS#J_ 1?S#8%h9pSp_rSS?JJ#% * L#79#7ESMS#"'%J #1.%l w%Eup8%-M %%%?SJ<wW%_S1fi. BB#= p0JSJ#Sp*=%%?9%?=%O%%1.T1S#8%D%v8MS#JMSb1JS#8%JJ%ESJ=SbS#<1?S#8%9MS"G 4i%8MS% pvS7<M%9%Q%%?.v%h%{SJT8JSS.-S#'1<9R%9NSJp,SM9RJEv% ffZfiUOBSLS0S<%#SB<M%9%#'#16%=S71F#8MS"5S#=MSTJS%% %JJ<% c38wp(3+*CT ( WhJ%7ST9%%G%@%1.1S8%v%k8?MSJOSJMhMSiMJvL#<%8MW9SJ?LSJM'(+*FMJvMiv86%S( 5#SbJSp1SS#R%8%'w%J#J !.?RSbSJ9( Ej#8MSJ8! RJ8%ES0%#Mv#'%FSM9A I_%.N7%TSJM#.%8SS'Sq%v8MSR9%qp( (+*?BB#pkwMM#%.B%6S( .JJ1E,Y%7<%S%ZFR9S8%E0S1.SiMJv9%F%i1?S#8%{%v8MS#J=6Sv#_S1,SM9#S"0'7S8%#M #-B%S7SM9 S<%9Q=JJ6%<LS%<98%8S_M]A + 8?MSJ WS pp,B#S0#.8SU%GP , + X,EJTpJ%<#SM9q.JS8%R%#NG#!,pBL18#FM?NvJ%?O%Sp8#MNB#S pLSM9LS,=%8=c3M9JpY%CB%?c38 "!#$ ;pJ%OS'v{S7p8M<J?#=%ET8MS#7%vS'8SS.J%T#%{% pQ J6 98;: fi &%`6 98 : fi"!'#($ ;?DSbSMYHSMS90%) #q8M"G#%S8=G%J8 _79lS#<90%S9MS 8%K1#8"=QMS78%85SJTw#J#<%.v%#b<M%9% <Nv0%98% .Rk%SQp,SMY%JSM9p,Y%9R7%85#BJl8%F7p,SMYL7%F#i%ip'%818J5 %#v7%'# *KfiMMS=SM9"77%#%818JbW%S'8SS.{8MS#"KB%98%'SJM{#7SJ'M9J1'%kSM9<<%JS8%.S##79S%7.w%=SJ8SE_#S )<<M%9%5 H%1S_%_#79L%8uS1.JSp1J% R%S v8 98%##%G_#w8#MbSJMbS1%QM? 9#%w1pJ#9 #88v1E-8%3M59SJ?LSJM'S8#OS9 98%.G9SSS-GM?p8%v%JS#wpZM90.G8%qJ%O-<%K79%130v8S6%<%J1% G%S44035 q7Y#8%4 %5S3 S8 %##MU9J+ ,, [ fi] "-d%J. + [ M]A-HUh8S/-?[ FsffqrM10,2 .76 s<erM80,2 .76 V %##M"%" .? H%Jy MS0Sv1S%lSJ0v8B%%YB%J<%JB#RSFJ%9x#9S%J1%J < [g GK<J##<#9MS=1v87ESMS#"EGB%9S8S%wS9MS'SJS#J=.BM%#6%'h w%JR R7JS%9dS8S06Sv1S%#EP /uKT 3XK%J P WT3X6iV%#lbJS8%.B1p8##%FSMJMS# k9p%9%"v78"P , + XK( J%KAPuT MXW%=%# #%h#.%p#S_#JS%91%JS1S%79#<SwSMYS<8%8S ( N8MS#J8L%l8@ 8R#JSS%J1Gq8 P ,, + X ( J% EP "uT MX{6%%#5%#B%JM%#QS1S%7YFSqSM9.8%8S( b8MSJ9Sqv8 9M%#BM0SM%Q6S Z%###M?* )OSM?"kBJ#?N%#_%SRSM6%S7.SQJW%#%h#.%p#R8 H8l#9S%J1TV %##M"Z%" .?F %##M* )O?JMSNJS 9J7pJ JH# %#G#%#T#.%p# #MS%87JS%Y #JS%J1{%SJN%J% 8v #R1S9 fi:<;Ws1 1>= @? '=b-J#%B<%S'v1S%2fi.H7%-%v8M%GSJb% hB#v 0S9#Sp*9%%?S *%v8M%#9JJ1DM?wY%1DSJMMS K 5n IMp#TSJM{{#D%#GkS9G7%'6S%LMS9#MSbS#S_<T%9%v%9S#09LGJ( .S%'#GvSSYBw19J1'7p8%M?%%%?SJ 9%S= 0SJM3#"9S%9M9##S#8%##iM9JS#<M#-17Y8h 4B'{ -h8%# "?YJLS9MB%l%JS#<%"S#SlB#98%.SJ%##bv=p8ML%NSJw8.Sb#M%=JpS#7R 031v8#<ES%ESSJS3S%% SJM B#ff 4B15-S%9M98S56%CBZ?S,Aj-!3O5 :K%S,?,35 1 Bff,EDYG@F 5< @ 1VIH1HKJ 7WBWLfi91#gfiffggSiSM9qS%E#%TKJ W%{S1S# ,, %J +#%.% hV%#q=p8M%Q%JS#<%Z#JSRL%.N%{STJ%9 JS%J1S1?vR#1S9MSS8J#MS<SMY.JSwqJ=v<#MS%<J6%)LNS8Mvwp8%D%JS<pZ9S#LS%=SM9S8"-#hS%.W%SiM_19J11%79hB8S wB#"v170v8w%ES#MJv7#qS'M?%1%9%#q%k=Si8%p%9S#09LZ =vOJSUM9#4B JJJ8Z%J8%9M%<88TS8S#8DS %%%#SJ GJ#H#% S( Jb7pJ 98MS#J=JM9#R0%818JB%RMS9Mw7%qM'%E_%N#8MS"J%##B#JqM?N<%#GBJS%%SSiGM?b%9%5%9S#09L -h.7%# "hJ#8JShS#<#MOS( .9S7.ShLST1E1p%. 4B p8%M?r%%%?SJ<T6%w546h 4D={QJ%RJ%79SJ Ju<J$ 98MSJqv8%JLS8%{J%1S#8%.8w891F#SS3%Sp8#MqBS=v%39M%<88ZM%#1S"%%Jv8%J'#O9J8MB SJJJ1_%JJ<SiGJ#L#<9%1OS1%SSM9NM?RpJ%<88'JF79?#8%* 4B JS%v8S lJM9'9ObJMSJ%#_U 9FSJ1B( .J#Slb#%0%JS%9 #JS%J176%0$! b#%D% N%SbJ0k8=%O8?MSJF( .J#Sp8M=0#%9%#T%JS#w%kS#S"Zb%J8%*pML1S'JJ8 T#Gq%J UM?#M9BS%M9JS#<M#_1pv.S#%3J9JS"J%hTJ#S89S'# 1S -GJ( .S%GBU 9OSJBM?w1W%F%<J%9#JSS%J1'%{SJ8S'79#%7%<%<.9v8%O8MS9=S( JS R#8M_%%JS#<%#S53S<v1S%LJ%ES#SFMSwJ%7%J U QS#<Mk%S7%J LJS#JuM%% J8vJ.T#%#8RHS1pkJES#%"9MSS% SJFJJ8##JJ#?9S5E7#MS%FJ0k8i%KS%79#O#GS( .9S_%98%S%SJM9_%88MSS#<M'%Kv%SNSMSS#880JG%J%#SSlSJ-%S#b%J#S%J1fffi 2 ( {v8 8l 7#JSJ 2 %J( OhJ#uSM% %wSRG#!,pBrJ9J1S%L%M9 J#S%91H*RM6# 8b%,F%%?c58 fiK TCT U0J%bN9SJ#8M<S9M088w#Fh8S8E%>QMJvMFk86%S2%#S<9S1S#L%J8F%O<%JB%O#JS Ew'<J9J1S%T%M9HJ#S%J1fi 2 (v8G8 2 %J ( OSNU YL%6 3|4 2 3fi 2 ( v[ * W * fiK TCT 2 fiK TT (222B8=SFpvj%BS2G.#% 60 ' %k8?M%DJW%w%#%pSFJ#J91S%h%?M9J#SS%J1_#798MJSJSqS_J8%S8l%B88S%%# %98S% #HSl<%Jb9S1S#( J1h%DGL#S98 4J%SM99S%v8SL%DSqJ#SJJ1S#%=%M9R9#S%J1q#'SJM-8S%%L8FvJ9"vBJ#?#79?#8%#LS.83 SJw.9v8% H7%0S( JS7%JSW% 2 #E& ( {'J#i#G%8l#_'%J%pS#8p%'17YSMSl%ZS1p%1BJ0v8G%7%S( JLw%9W%? 2 #. ( #%D9M {MJ8D%# ?BNSJ0Sw%#J8%3S9#G9Mv8.G=J8< FJS%J1( I7%J FJ#J91S%h%?M9lJ#S%J1( ITp.<JS%K#J%%MOU 9Ji+F%9 8%p%9S#09JIh%D=S#S0SSJ#S#B6SjS'MJY##8MS%O88vS1.0#8%DM?9J8=S%k8?M%RL?%J !#^L 5n bS"4sS<!%1S%7#JShU %-_6%S9#0#JS V,%5#%Sp#L1p8##0%8#Jb8vpJ8#?#hJ#%#D%v8MSJMSwJ1SSMS#FM#SFvSS9#TSSMSS#NS7%b1J?J1'%JJx<!%1S#%0#JSJ8GJFwJSp1JS=#.SpJJ1LLRM6# %%1SQA?GBF88vS1.-JSp1JS=7YpO%JJdS1,JSMp#<LSFJJ1%D09S9( J%#_%N%#8JMS%-%JL8w#JM'910<S 0#'p8MQSJNSJM*ZfiU? 6 t8;: fiU9 6 t8;: fi ?WBWfi$4$,ffZ{} blg {,]Q fffi dR {$[,%=b%R9S%9 #JS%J1%v1JS8BSq9%1q%{6%S90#S9 r%JRSJ0SJ9%18 9 :(; r1ES%J#w%3p8%5%JS<p0bS0SSwY#%'GM p8%5%9S#<wJJJ1FSO1%SO88vS1.?M8%%EGG1pv1W( ..S%79G#S9 # 8 9 :(;J?#=M?". -B8%8Sh8%8BhJ#w#S9{# 8 9 :(;kMSB%1SJ%## fim !##n n%#JSJDp#S<. #FVJJ1S7%"v%SwSh%S<%5p8%J%9S#<FM%1%OY%S#J#SJfi. \%JSwv8 98F%OSwS%,8 <7%S79%J#SL_9MSS#89#M SSM%1%9%SJi9#LS( JS <w<%VMhGN6Sxp8%"%JS#w<#l%8hw%M?7SMJMS5R 'B1ES#%%MSR*M% /ZSTS9M SiM%1%{Y%S#J %9p8%E%9S#<#TS% fi MS'SJS#-GMTT%8%%J<8%<kiS8Mv7hSTJTJS%YM9## FS#7YQi%818JS<TS%Si%JJd( .JJ1<V*%J% #%S-%h07.S?%Z<%J#8%##G%J#J <%Q%Jn*_S1#9S#MS# %S8 S1.8x %S8RG%JhSMS% <%#v8SSSYMSJOMSqSw8.'_7%Tp8%3M?RJ'%DS0M?%1%-Y%S#L%D<#%p8%%JS#qJ #0S fi. ZUO%98S%iSJMKSOM6%S7.SqJSp1JJp#Z%T%k8?MSJ%U 99ST%5M%1%i9%S<S%S5.%pv8 YOS8MvBJ%9M9####%w5FG%9#%JJ ( J1%#%Suk'#u1.%_H7%#6%<%B%SJ<J %wJMSBJS8B#JS"p%BJ#%788i%w<SB%98SMMSJ8EB.k%SJS 8OSJMGMb# F#D v1S%TS?#1QS_9%1 8 9 :(; 8 9 :(;1.S%#Jv%S p8%%JS<R%J #JSJFS9MqMSl%8S8_p8%%JS<R#8<q%BJ9J1S%<%MYHJS%J1_%K( .J#U%.S%KSl.9v8% 7%8h3bBSJB..v%SS8JG07J#%BS ! nI !-n fi 7%D#S9OSw9#7M?R<?%%%K%JJ fi. OSM%Q6SdS 0 '/c JM%TU 9SN1Ew9#S%J1l%8%JJ#JMNS#S %7SNJ#J91S%b%?M9 J#S%91Qfi|T #v8G8EL%J p8%%9S#09 {%8Mu.M99p#S88kSS1.<JJ8qS *%v8M%N Em S%%=S1.NJ#SS%J1#lpJ%SJ SJS%0%9 S1JSMp#lJ?#l88vS1.8Tw%#1p%1?JM%18$ MS%iS1.FJ#S%J1T6%%.79MSS#8JM -%Jw#9%w17Yh1EGJ#S%J1-SMS#S8{%8OB#O%J%B%>EKJ%%QJ%9x#9S%J1%9Gq18<6%hq<##l8MSJY179JS#<SqS1.J#SS%J1w%'SJ_8SET#JSMq% 8?MS %J1%J#SwSJS#JNS#718?8#%K% FM'8<#9M7J1h%<%JS#<%JS#S7#{J1J.8Sw%JwS1SMSwWs%JJ8%J%JS#qJL{8%8%SSM8?J%B#.S9J177%SDSJMMSh1J18JSJ%##S#MN<S1.'J#S%J1%YOMSF#l1E?%'9%lRJ= v8SJ1O#l#JSJSS8{J%1%79%pM?EI lm n Q -h8Y5# "#"GU 9Jb%GS-<#J#w%J#J1S%S-#LJSSV%SS9<#<#9#< MSkiSJMqJ=v7%818JH# %8FL8MkbL8%K%9S#09 M%1%0Y%S#"p#w##M%KpJw%J0%9 JS8r*M%qU 9_M? J8JSH%qSlJ= v8SJ1bv8G8S2 9SSi%D<#JS%9lSJM'%D7%9%v%9S#09p9<<MS<SMSS#8i6%GSJ-SJS#J0S1.'J#SS%J1iMSS8v%Sl#bZM97M6%O1T9MMS#%9JSv8Gi%JJS9%#B8k%3SG7%0JS1EKJ#SS%J1%9S8S%qW%Zw###%JJ w!%1S%l#S98'Jb7% %J 7J#%HS1.7J#S%J1_SMS#S8qJJ#8MSJM 1JS#.SHS<%#JqJ# jx 7%wi 6S p8%G%JS#<p JI nT%JS%Y 8% 4h#S7M?w#Kp88%S9%#0J%q%8ST6MD6Sn#8%p%JS<pESJ?78%.SMShMSOK%1%S%k%?MwTSh S%9JMwJ8#MS#J8 79##8%p8p#J1B%%SSJM#MS%19#S%J1F8%.SMS%hJF<SJF1pJ1%Dp8%"%JS<7BSN%8SL88M%1%9%SJ8J9JBMS?MS8-%QMSSV%1B% )-S%S,8? 7<%SN79%J#SLO'JSJSWBWfi91#gfiffgg* 8 Vj$%'&(-j* 8 V UA@<:%VjU-A-! jU? ?A,oU-4-4 ff fi??~54;~ #-4-4 ff fi? H1J? 1J7J<# 46#-4-4 ff fi~ ~8 41J? H<# ~-4-4 ff fi~ ~8A? H<# HKH-4-4 ff fi~ ~8 ~j~? H~54<# 464-4-4 fi "!$#~ ~8A7J? H%7J<# HKJ-4-4 fi "!$~ ~8A;~? 1H7J;~ H&'( ' )fi*+? H%? H%~ #%~ 4' )fi? 8? #~8# 4 4&~ 4~ 4 )fi,~ ~8 ~~8 ~~A# -4#64' )fi-,~8 4 4~8 ~54~54#1H ~%JIH#64~ 4 )fi .? /J~8 4o~#1J4')fi#,? 1J~8 #%~4~ 4)fi,~ ~8 /~~8 JJ4/ 4-4 40 ~ 4 )fi,~8 54#A7J 48 ~1JZM9<@3%-S1.BJ#SS%J1=SMS#S#8i6% 0LS1O%J fiG6SmS 0 ' c3#JMS%SMSS#8M<SM%%8TS#718#=%O%SJw<## 8MSJ ''JS=6%%9x#JSJOMSF17YRJ#q<##b%JxS<!%1S%S#SJS9k%{iEv%SS#SJMGSML# 0#G#MS%7#1b0SJ-SJ9%1h%5W%9#JSJ=1.S%#J#Rk%S8%{%JS#<N%9#S#J=SJMMw%8S8QV#8<%OJ#SJJ1S%-%M9lJ#SS%J1T#8%k%JS#wpK'TV%1%iJM9-SJ#GvJ%B 3ZSJ-T9#%iM8%v%9S#<TSJMBO#JJJ1_bSJ1%S88vJS1E-M8%l% T%9LSS#MS#%GMh%M%1%=9%S#9B#RS fi ZY'JV%1%%#_JM9)_#%SSYS%ES%{JS%v%SS#J=%'S_M? S9%1%{%SJb7% S1.TJ#S%J1_JJ8)Q#J_76%1SL%KSF1E-J#S%J1=%Z%JJx<!%1S#%#S#J8'JLJ#<M9Svl%S%S,8? 77% # SMYuM?r#T9M9LS8MvL6Sp8%%JS#w<,%8O c MJJpY%CB%?BS8%#JSJMF{%{7YT%E7JM,877%<7J%9#SL#%QS-M9J1-%3%_1Y##8{J#p8%kMl?M8%b%J *SF#%b%Z%E$Dfim K i8#JJ1<S%%OSJM 7#G9%liMNv8 YM%YJpJ%# %S8J% 8 9 :B;.BJS%vOS'6#B#=..v%S#U 3 ! ! LUm SUm # h^K oLJICKML i"K n Q 8 9 :B; !%132 !m 1D"%JS%9 Jw897S9#<vB1%S#M_BS4 8 9 :(; 4 5S< 8T%S 8 9 :B;rSJ9%1%T79##8#h# SJ-%8SShSJ<%SSJ79SQSJMS=1J1S# b# 8 9 :(;#iSw8.S7S89#MOSJlS9MG%9S#<%k#S9GMJ%G#S#MS#MS#%'FS'{%kSBM?wY%1%.%JqS%9M9'S7=68 J9#79S%9M99MS.GFZJ%#%kq%98%qS9M-SJ0JJ1q%09S9%JS#<%Z#S#JBJJ1-SJS%v%SS#N% 8 9 :(; uSJM-qJ-v1p9%S5Y %8?M%%5v8W%Sqw#%9%#L%JS<%3S#TJ19E8S5 G9( .JES%L6p8J7#J% SJ65 _n N 8l% 8 9 :(; hJ# G%- 4 8 9M:(; 4 V{%iF.S9#7%Sh{J<%_M9?%1Sb9<T8MJSShShJ%SSJMOJ%9mJw8J#w#iqVJJ1S_% 4 8 9 :B; 4 %9bSJJ0v8i%9LJ##9S7% %9%##%JS#w%S#SJ BS9#S9MK9%1%v8 Y{S#wMDW% 4 8 9 :(; 4 pMSO1JS#J8Sqk##R1S#J% TSqB.WBW7fi$4DYJ b Dh[K} ^ff bT$,ffZ1$[EK E ,T ESTSO118JS7%kSM?<T99%O%JS#SJK#77%<JS%J1OJb8J_,i#MS08%*%%?J%#1#SF1i7J#D%"p8%9M?b%#%%SJ<MSB9%S<wSJ1S%Y%J%p{%S'J98p# JSSD#%9JS8Mv836%<%##% JSSD#%9JS8MvO#D%8S1,.<%?M9#wBJ#?7SB%8S#8S8JS.8%9J#JMBS#SJSB%81w#ESGS8JES% 9SS%BG%SSR%{#S98J%JLS%h8M9SSSN%S%1J1LSMSJSJ#9i#JJJ1N.L.v%_%B<%%v8M%TVM ''88%8Z%# ""S%98JM%?S8#JS%F%9% 8_SSMSJSJ#bv8G8lMMJ JSO#%JJS8MvhWMS'%JJS%Y Jw89 W% \6MSj8R%,=M%M=M% /? HJ S8%SSS# 78SpJu1J?J1LSMS#S#8%=<wSMS# %N7%Su6%JS9%#u%9W%?7Yw#%JJS8Mv6MSS8D%S_#%MSJ %'Sl.9v8q%'%JS#<%G#JSJ8Z Sb?%J6%7 1!K 2 -S( .9S Rp8Mw%9S#<%D#JSJQ) R%JH L%J fi 8 8%9S8NMS09%SSMS#MYS71#.UM%E'6MSSh%DS JSS-#%JJ8Mk%90S8W8-wSJ7p#T% !-n n N1w<8 BL%88%1 %-SSMS#L1w7pO8% v J%ES$ J %SbS8%SSS#( Z*%ZSbJS%v%SS%iSb%S%MM#MY## #HM 1q%81JE 6%Sl7J*QRT%'Sl7p#0l1JS#J8SG8S_9% S#79#w##MqS8%SS%8iJJ#SMS06MSS.SJ?7SJMS( 8MJSS<UMM9## 0J98DSB%SJ7JST%"0##MVJJ1SJ%BS#MS9SJuv8 8 #%J9S8MvNWMSJSl%J SM 18j WJ9uSJM_S%88%1l%KSMS#F1SB7p#G9%LN#,Bl#%JJ8Mk6MSS'JN%'SF.9v8%O%JS#w%{#S#Jw,i#MQ8q%*i%%?{SwY%SkJwS 8 ,p#%8d%S"DM%?%JS7%8?M%wJ#S%910v8G8 %JJ p8%Z%JS#< *MW# 8F%,K%%hi%JRM.M7p8M%{hSff( ?%#WS fi]A% fi] " 4hSJ%qS8v%S"DGl%JJS9%##.%SMQ7%S'SJ?R% 9SSJS%J1F1%SSMSH G%YF%9YnJJJ55%" .%Jb#%JJS8MvB1%S#MS_%SQ,S%J8M%vxT7%SSJMGMhqJ_7%S-1<7J#.%SM#l%v8MSJOM%JL8%#JSJMSl179S7SJ%N# 4hx_%JL%9S%#8%R#G8fi ( U%#J8-B#F6SMbb 46B 4D ,p#J%8{8%*pM%%E?'SJw79M<S9MSMS#h17pY%<wSB7%bJ#S%J1Ov8 8b%Js8%J%JS#<F%97SBM%JS#w%9#JS"B9#7G% 7A8 9M:(;=<>9 :(;*p#S#J 98%.ST7%SB%88?M%J# ( M%#% fi] "#/T%9_fi]A# 7W%' 7%JL _0%J fi. 8pSv1S%#%R 4-OSBl#_S=86GSh%KS=MSJi%1S9% W%=B?%J fi. K#Z9#8%#BSJ#q-6%1%%Z8<V*%.=7%SSJ%u8RS#7F%9R=SJ%uB ?8EF%iS<JS9#1 %#S#LW8s1p18JS#J%8%wSN%98%uJ= v8SJ17118r6%1%b%T8%p 4h9JSJ%%DSGuS9M<S78 9 :(;=<>9M:(;Y7pJ%81J.SGW%i7%vSBMM#M9#q#<SJh1S( .9S7q8M!/1 2 Kjm n L#JSJKFSSBS%7'9S%9#9S%J1{%JT9Sp#{%<19%JMS76%J= v8SJ1#TSS#MS#%FJw8J#w%G FH JMS( Fr3G%8S9JFS1S%JMK Fr3i%J fi%lSQMM#%.b%=S 78 9 :(;=<>9M:(;-7%S%8M hS 46B 4DFOp%8Q*M%%p-5CB%v8JMhS9MF#JS%J1hS #MS% 78 9 :(;=<>9M:(;KM<7%S<Jb8Jh9T F1q#9S#%Z#MS%J#SS%J1 WS SJ$P %9S#<% XF#JSJ_%LS 19S%SN%S MS # BJP %JS#w% X5#S9G%.%h719JMS_% SJ=6%1%?8 iJ#J#FNSJ#G%98SMMS"pGp8 7N8 9 :B;C<D9 :(;5%hw1J1S80<%SSF% 4 8 9 :B; 4 V9v8 Y8%#wv8%JS 78 9 :(;=<>9 :B;3S#qJS%8J%81J.S-W% 2 Kn QRSJ0S 8% 8 9M:(; %JNSJJ#?9S_%D%JS<%5#JSJOB#SJ# 8 9 :(;W%fi91#gfiffgg100001e+0710001e+06Search cost1e+08Search cost10000010010000010100001100005101520253035Mean distance nearest optimal solution404550556065707580859095Mean distance nearest optimal solutionKS<@3p8M8,9%SG% 7N8 9 :(;=<>9 :(;Y%8SJ {W%Ow_V8W J{%JQ8DN8L6. 9%J fi SJ%HJMS J'##OMSv8#<kS"R#Jwkq%SSJ7SJMh?%J #8%3%JS#<bMSS89S.SMS%%{SJh# 8 9 :(;BJL#'ESJ#S%SJS YM9-%LS#\7%M?R8JSl%Y8S%R9J8 p .SJv%S<%0_8 1J18?J# SQ%8rSQ% 4 8 9 :B; 4 -#r9S%9 Jw89%OG%98%-S9MOS%S8'SMS#1'7p#% T1JS8Sb.bMSN%JlJ#i1##M*M%MGM% /7MSbY% %JJS8Mvw6MSSL6Sl9%.vlS 8%S_J0v80%'%9S#<%#JSJ8{%7SJN%8M%QJ#S%J1Lv8 8u#8%i%JS<ESJMLJ%ES#W#S87SNS 8L%8 9 :(;u%-SJTJ0v8 ?UJ#?9Sl%%JS#<%K#JSJ8Y9%k%S5-%S8=%?J8vSJJJ8p#0<%SSOV%#v_8MJSS=% SGw%8LJ#79SJ% 4 8 9M:(; 4 W-9#i#SK19%JM%SFvG8GiJS8pJS#F#.S Jq8%8%JU Y8J8 %YSJ 7A8 9M:(;=<>9 :(;1<O6MSH8F%* M% /?<K?85S<7pK#=%SF%88M<6%=S<7F9w8JJS%Yx#JSS%J1BhSJ#LL8%5B1J"YS0<36%#Ol%81JE-6%-bpp#%KJ%k%Sr _@r /F%iS<MM#M9#Q#JS%Y Jb8JW%Tl%JJ fi. 8'J#"p7J"%88%1LV%##i<%9W8Bw7%SF?J1SSLG%S &J fi. 8fi: #1]s+=1r'!=v8SJ1w SR%88%1 %78 9 :(;=<>9 :(;B<i %JrqH%J fiw%#%#SR1J18JbS8M9#S8%M9## H #MS%8i<%SRS%#S#8%## S$8uJS%Y #JSS%J18<9#8%%EGJ%F%98S%RSJMOS<%N.9v8O%Z%JS#<%"SJO#l?%J fi.%SBOM9J7BSl#91S%O#_JS%Y 8%D L19_B#SbSJFJw8J#<% FH .9MS(I#JSS%J1DBS 8p.SJOSSJS=1{%"179S=v%S 78 9 :(;=<>9 :B;%9JS8pJS?#1FK%J%pS#5-F -%J0FOO%9 fi 8 -B8%8BSFJ88K<#1S%9S1%8GMS\M9=b%SSBSF%88%1L%ZS 7A8 9 :B;C<D9 :(;51h<vR#MS%8'%9 fi. 8179 7A8 9 :(;=<>9 :B;'W%bSQ%%-J8% 8q 8?%J fi wBS Mw###%JS#w%"#S98pSF179SMS#N#OJ9%1S#8%kW%BS=S<%#9# "7#JS%918YS<MZ***+ ,Aj ;J 2EOU,?9'+U,'K*,ff?{O,GS,i?VDOK$%'&(iU,',=ff?,Z,',*?- 2.?KO?,G,*FO 2E,D?**O,oEZ;v< :- 2.,V*,A ,AjUoB,Uff 8 9 :(; fi *U *U?KV,AhG 8*?,{-?*U* 8 8"V OAW%fi$4$,ffZ% 78 9 :(;=<>9M:(;hMS9% %% %J p8%'%JS#wp QSJ S8M8,Y%b% 7A8 9M:(;=<>9 :(;% 8S9 =W%qS_JS%9# #JS%910#Sw?EqS#w%'Z#SM' ( M%#w%'S1%SSSk9J#F8%SSSl7pY#ifi] EBJ#?wS89S.SG /#/Vm1S%Sb7pk%88%1S#MS#%-TSF\bqJ%9m88{'J#SS9GJ7JMiSJ-V%##JSB% 78 9 :(;=<>9 :(;"7pFS8%iF#M%8 fi O%9S8S%'S#<#M %9K#0%88J%106%{SMS#O1S{7J#3Y%TS'J0k8D%k%JS#w%#S98MSO9%Sv'S 8%.%J7S'7%wJ#S%J1iv8G8<?%Jp8%"%JS#wR6MS"5M% /?b-W%SJJM%JG08%9%h8SES#_%SSSB#M%8BS1S%9#M#JSS%J1'J=wS=U%SB.9v8FV*%9J'%Z9##J?D%Z%9S#<%"#JSJ8K} p3 % $[ L [b RNRM G b# dDY'U98#J8%5S 78 9 :(;=<>9 :(;v1O7pYJJ#8M-SJMGS8F 78 9 :(;=<>9 :(;v#G%O%b.SS#%88Mb7%SS7% 4 8 9 :(; 4 Z%b*-=%9 G%#Q..v%S##=#J1%S183*% 4 8 9 :B; 4#q%T1798H#JJ#8MS#%<%'JS%Y 9w8J %RLm6p8JJS0%89MS%%44BS SJ7%%D%GJ8%%9#LL7%<%88Mb<%SS7% 8 9 :(; S9% 78 9 :(;=<>9 :B;VTJ%%%JJj#8%.%JS#<p%GO#J%T1J#8ZSO8K%Y#JSJ # *I 1 M?"8W8'wSFSS9S#71B<"%h $1 "! ;@I fiML 1Sh7p*{'J F .J%!pJ%<#U7pJ J88%WS Sh6%1GSJM%#S_%%%SJ pJ%<#8{MhSM%l#.0%81J.8%1p9##8O7pv%ZJp,S7k9p%B#O%h1JJ15q8%%N .J%!pJ%<#1B<v% 7_%J%# #J7SFJ#S%91Ov8G8#JSJDp#SwJ#JSMl%JwSB1%SSSk9J#FM%JS<%9SJ8 c58 7 9 :B; fiM%wS<J#S%917k8 8HN#JS <%JS<MS%JS#<%DS"3,% 7 9M:(; fiUff[LST MB8S b%qSL8T%B%9S#<%G#S98#c58+- ; + ! _%lSl8%SJB#NbJ?#<%Q19R?JN b%R9S%9 #JS%J1%v%JQ8- . 8 9 :(;3%q<8'%K%9xp8%5%JS<p0SNU 9J 7A; + ! <D9 :(; 7A8 9 :(;=<>9M:(;Wi%'S07%J#SS%J12 7 9 :B; fiMGv8G8RS#SJ*+- ; + ! 7fi- . 8 9 :(;6G%JLSJMSO%9S#<%5S"KbNSJB798%DJ##9SJ-% 7 9 :(; fiUW%qS&- . 8 9 :(;%9 +- ; + ! T%i 8@8 %JJ fi !G%S .vq%h9#YSMSL%J8%#S<<8#_%Ju%JSS%p#%%%SJ<GB#6S( ES#%98%h%8Gb9#YSJ v%S<BSw%J7BSJ{p8,S9%p%JS#%lS%##. h8p#MS9OW Sq%JS#%L#%"MF7%S=JS8M%.'#lSFSw%#8'%JT 'OJS%Y 8S8K%#E%ZZJS%J18 7N; + ! <>9 :(;+% 7N8 9M:(;=<>9 :(;*%*% B1JS#SESp#SS'S#SJ'SJM'Q%8M%7MS8#8h_%N%JS<%5#JSLSJ%R%J<#b%8?Mp8%%9S#<pp#<#MF%98SMMSJT6%TS#S $1 n SM{S9 SJMT#S90# +- ;+ !1JSES#bvS'G8B<M%S9%J'S9%N#S#JO# - . 8 9 :(;*'JJ#%%?%<BSJB#NKSq<8S%q%B##JMS#%=1p%7Y'%KG_kh%DM?9#%1J9<.p{K8pM?l#79#%SwGMlSJSJMGM-% F%8SM%( I=J#SS%J1v8 8TSiMSSZ%9S#<%#Sq%JT#JSJ5S9MKMiwUp#w%#=J#S%.6S SbMS0%JS#<%{S#S"L1J"Z%JJ p8%{%JS#wNMS JKCnF1SSM?#QS8S.SMS%l%OS_80%'S#SJSJJ#NM?"{1.%J#1SRS_%SSJ<JSGSM79S8#JSF#wp1SJ4hSJTMb#!O#MS%0S#1T8 9 :B;ES8Sv%ES%#F1#D#MS%Ov%SS#JZ% 8 9 :(; yxFW%S%JKG'8SS.Sq=%D69#FJJJ8S%J xSJM #iJJ%<p#S8DJ%#S<%81J.'6%'SFJJ19#%S_S8JiB#YJ1SSM##p#198SMMS%lS#<MT% 4 8 9 :B; 4 Q_%Y8S%lSJMqSlSSJ#S %T1E%9#1G%JsG%#<Ev%SS#8.MS8G-S#J%S8SJM 0#k8W%w#F0%JsG%%8Tv%ES%#_S#1RS8O% 8 9 :(;ff fiW% Wfi91#gfiffgg30004500Random Local OptimaSolutions Visited SearchRandom Local OptimaSolutions Visited Search4000250035003000FrequencyFrequency2000150010002500200015001000500500000204060801001201400Distance nearest optimal solution20406080100120Distance nearest optimal solutionKS 3-h#S%%%<G%3SJ#SS%J1hTSMSSG%9S#<%k#Sb6%Gv%Sb%J p8%%JS#<%J7SJZp#ST)W%D 1p%7YF8t78%J fiO6%JSF1%SvJJiw<9J$ h9S%9d#9S%J1?Gv#8%S9M3SGU 98J8#5%JS 78 9 :(;=<>9 :B;.7pEMSGJG#F#MS%G9MS BSGV%##SD%S-JJ8##J<%SSh0%88M#w89#1ShSJ9%1h%5#S9#%#0qv'1Y%SF1E%S85S 7; + ! <>9 :(;K7%SSTU YJSQ%81J.S=W%=SJ<8%GSJ#%# vQSu p GJS( ..S%'GEv%SS 8QSJML.J%!pJ%<#17pp9%<TS 7; + ! <>9 :(;7%S'SJ#qp#7S#J 98%.D#7JS%7.S{#T%88%17%84h8#JJ1<6%SJ#Ev%SS#8 b%98S%bSJM0%#SSwSSMS# 7N8 9M:(;=<>9 :(;1q7p*+J#1S89%J8qv8G8 SNJ9JSJ=% 7 9 :B; fiMW%7?%J p8%i%JS#< %J SJp#S0.)G8SO<#J#w%E#0{v =9S%9j8S8EJ 98%. 9= k8J1Z8Si%9S8S%#Sb#M%8T@%J 8y 8QJS%9 8S xQSlS%7l#JS%91F6%0B9#S 7A8 9M:(;=<>9 :(;7pZ#h#%-%88JM%F3lVSS8##JMFSJq<M9SJ0%{S7J= v8SJ18kG0%9S8S%SJMGW%GS EF%3-8L8q%JJ fi BSHj8%p%%T%JS#w%YSJ8 7; + ! <D9 :(;Y#%8?M% /C#B V G8BS9% 78 9 :(;=<>9 :B;VG%BSJS%7JS%J189S#JSJO# +- ; + ! =N%8M%vSSB7<M%9%H( /Vd8hSJ%LS%ZSJO# - . 8 9 :(;*F .J%.S67S=%88%1b%3S 7; + ! <D9 :(; J%S9%<#'1'<YLD J w%JL8NT8%J fi 8Z%%.0#%7#JS%J1%EO1J?J1/+- ; + ! iJS#J-SJb%8wMM#MYqJ0v8h%J8vJ.'#%8G 4#%Z##JSMN6S b?%Jp8%J%JS0J %Jb8<#JMwJ1F%9%T%JS#<%Y#Sb##8M"{B'8<JMS18?w##7v7v8%JSBS8Sh1p%Y%#T%JS#<%Y#S#JD6SshJ#w07%OMSvSSYJJJ8 <7%O%v8M%B BB#J pqSJ#,p%%?O8<#JMGSi.SSJSp1S8J8#JJOSO8SS.K#%*MJ1 4 +- ; + ! 4 [78%p%%p'GSS9S#+- ; + ! MGSJ7J01<9 7N; + ! <>9 :B;6SB#M%B.9v8{%"S%7Y{#D( .J#S70%?J8%hS%JM9#q%88?MS#wM'%KSJ#OSMSS#Mp8M8S,9%SO% 7A; + ! <D9 :(;Y%8?SJ W%OSJ= <%JL L0JS%Y 8SOMS=Sv1S%#SB Sb9k8F#8W%9Jv8=#E#=%OKS/'B8%SSSH7p#=% 7N; + ! <>9 :(;(%8S9!K 2 - SG##LSv1S% U%#J'%{fi] ""l%JRfi] @B ""1%SSSk9J#TVd%JQMT V#J1%F# %88%1 SMS%7NS 7A8 9 :B;C<D9 :(;{17p*T'7%1SJ% h9#8%##8p#M6S SJSJ1 Tu<%SRSJ% V%1%l%G J%%9uGR%98%R688l%JW% %fi$4$,ffZ100001000010001000Search cost100000Search cost1000001001001010110510152025468Mean distance nearest optimal solution1012141618202224Mean distance nearest optimal solution1e+07LA19ABZ5LA18Search cost1e+06ABZ610000010000LA201000253035404550Mean distance nearest optimal solution556065KS/3 p8M8,9%SB% 7A; + ! <>9 :B;v%8?SJOM?R1 W%h RVJJv8'8W JJS?Y RVJv8=.G JS?Z%Ju8 8HV8 JSh?%J fi8 Sw%SH.9MSJ'##OMSv8#<kS"1pS7hMS%1,SS#9J%#JS%91DSJ%<J98{S 7A8 9M:(;=<>9 :(;97p56J#qSJS8'{%"%%qJMSv#.SOJ=v8O.L7%S=S9%N7V%1%B%O8p%-SS8B% EN8"H87%JJ fi. OB#S#s8%p%%_%JS#<%3#S98 5 <S8%SS7p% 7; + ! <>9M:(;-%8?SJ !K 2 - S_##Jl% ( M%#%Tfi]A% V8SG8Nv%SS %KS!/?FS 179SMS# % 7; + ! <>9M:(;-#_J9%1S#8%'6%lSQS<%#J#JSS%J18 'SS9S# ( # JB Vn%SM8OSJ%bSJM%9S8S%_W%S 7A8 9M:(;=<>9 :(;Y<9wSJ-S%<h#JSS%J18JS8'S %1SJ%ff w#w .Y#8%# B#SJ#uH6%1%L% %FSJJJ#1 <%J #8%q#OS9#S1S89%91_#M%8BSJ%Nw6%1%-%O8pqJ%T%#b%J%SMSS8M8,Y%SB_#wSJ-8iv%SSb%3K /BS_JMS0W%iS J%%5S8%8R80?%Jfi. 0JS.qS 0 '`c JMS B#S 8%fiTS%%%JS<%S#SJQ'JM}Q%JffJCBZK*,o7,,,j78 fiM?K?0,-Aj7AV,+,oT% v qVq MM,?U +UV U< 8,U{UVG- 40 q< 4B+VjUU?KU,' ',0 OOAoF,'?p*?A,oU Z;v :1- 2%+UV U 5,- 4 4'2 464 4B?,'?*?A,oU ,{? UhO?,{OU- 2_5,=GO &J ;2 8- 4'2 :1,*UD< #'2 ~1Hff?+UV UG5,O,Z,M 0- 4 4'2 464 4B?,'?*?A,oUW%5fi91#gfiffgg#JSS%J1iJ%=v8bWJ9w7vBSJ<OJw8J##bSJ#i8F fi%#l N88?%"5%%?JBJ#O1J#.'BSlS%98S%LM%#'% 7A; + ! <>9 :B;6w1J8JS" #{J#JTJJ#%#q#{#MS%hS8J%"ShM?_9%1B6%i<%EJS%Y #JS%918 4hFL19( .JJ1%Z<%SS=% 4 8 9 :(; 4 9%YSN?%J p8%%JS#w0MSF%7Tv198SMMS%=%Jl#J%88M%9Sp#J#J0q9MSS#%Y1p9#%JMS_6%OSV%##Sv%pS 78 9 :(;=<>9 :(;E<,51E%S8%S 7; + ! <>9 :(;7%SJS{JU 9JS%81J.S W% SJ#9J7"p#9#=7%B%88M7%SB% 4 8 9 :(; 4 %J<07%Sh%88JM-1S7p*-hG8%8EYSiS9 98%.3#7J%7.SK#%88?%1%S 7N8 9 :(;=<>9 :(;%J 7A; + ! <>9 :B;.hJMSGLVJJJ%7.S%ZU 98J8#U 3B%88%1QS## V%##hl8%0NMS%8JS%9 #JSS%J18"%JS=7p#JS#Jh7J1G#9S.#.0SJ-#MSJS9wv8G8lS=JJJ8p#F7%SJS%JN%#%%SJ<h?Jp,S#7=pJ%<88} G b# dDY' 7A8 9M:(;=<>9 :(;3%J 7N; + ! <>9M:(;v1Sh7p#iJp#=Sw8#JJ1=SJM<#iv1S%Lv86%<#hB%9\i%F%8DBv%.S#%#=SS#1qS98 %JS 8 9 :(; NSJ9%1%R-B8%8GFJ%=%8O7J%kS-%._Sk8$ 9hJ8S%##8%JSF8i%ZSMB#_S=7pk%OSGJ%#!SMS%B9MSS'%kSO%JSTJS%YM9##S#83''JJ%w#Gk9p%D%"%E)L -L"K ! !-p8%M?R%%%?SJL%k8MR#8%5SM pc5S91YRMS#"Ysp %9M% /B%JNS#qp#Mb%J%##J7VS9M#Y#M8p D8J*v# "#/?8%"pM%G#TJ#989%Mv'7pJSRM% ?J%#J( 3RSQ8b%6%S9#R#S#J<#wB"iS%JSS# JS%9MY##Sv8G8r#Ev%#JQSJ78% vN17Y"i%J SRMS% 9S%v8S #TJSS8S%"c5p8%vM?_%#%%SJ<G%7.lBSb77%S%p%SM9lM?"8%l%#qvh7p_%MS%?J%#JF.QvJ9#lSw1.ESq%O77% ENSJwSMbJU 9JS55SJSJMS<MS%QJS%v8S R#-JS8%"2 4h#S1p%18 S0SJS#Jb7p#h%8%##NS( JSMF%wVJ8k9J#_ S<179#1p %S<77%-%1pv.S#%K.J0v8=%GSSMx* 6 {#<S fi.Ax<%J<S88W%ShJS#Jh#S#'#JS.#.SJJ%#SMS%-JMSSh%"SM? 9%<#88BB0?J%#%T#h_J8%%QM%%8Mw7p#BRB9##MS%T.J0v8'%SM-MS=%SvNE<78SUSSM8Yp#9#T7%S=%1SM9#%JN1JS( ..SlJJ8?S%JpM9MS%NJ%#98fi:r^<7JvSF#79%1O%KS%,8x77%blS=vJ#%O% pGGJ'%J%# 8FM?LJS%%SOSJ8OiML%BG_6SdSJJMS'%JS<%v#S5ZLKS GSjbS#71S8h%DSq9#S%J10bSTMSSh%JS<%3SN6%-k%SQb%J G%JJJ8{S l7%h%v8M%i%JF_F .Y#8%38ffl8%9 fi ZEB%9S%#b#<##MSS9SDwS%79#=%v%Js' 0%Jb'q2 fi E#<%J9ST00.9v8{%"91SSJS%Yd#JS%918'J=%Jdi%l1J9SOw#J#<%vSJ%S,8xJJ#TvJ%BSM?7#JNi W %88=N%%9S#<%K#S#hSQSJ( .9%KJS%9M9#%L1E%S89GF%98S%0S7S89#MSi#lSJFvJp%O%! {B=S#718?'SB#QST.S#q%KN<JMSJM #M9qN<%#.S%# M? %%J.S6%1pJ_v8pJD%5S7%D'J#%98SMMS_%J0S-6#h#..v%S#U 3ZS-%S8 77%S<J%JS % R%1Sq19S#.S9#%0M?SJ8iM %Ti6SdSFM'%JS#w%5#S#"W%Cfi$,ffZ80807070Distance nearest optimal solutionDistance nearest optimal solution$46050403060504030200020502100215022002250Iteration #23002350240024502500200020502100215022002250Iteration #23002350240024502500KS 3h'#718?=%iSwJS%J1<SwMSS%JS#w%{#S#W%q#S#J.<0%J i%RV86,JJSD%J _6#E JSDW%i_8DN8?%J fi.Z# lRMS%u7pO% %w9%BS8JS.S#7v%SOS8h%D#S9OJ#S%J1 6SxS0MS'%9S#<%5S%J *FSJb8SEqMH%%J#E 3Nl%_SbJ78?#7M%#P MTSfiToXOBSS7pv#5%JvSv1S%#%=Qv1857MS77p#wS7#<9%1h%i%ruSJ#wEv%SS#8U9NSSM? 388ff fiUS%,8 77%SR%lS#<9S8%M%9R0vJJ#wSJ#-S8%#M=#.bS7SM7UYJS"h18vGqJ%ST<U#09xvSSYFJ#S%916S %QMS9#MSL#S#N_S0M%JS#w%ZS#S.+ FK#J%%"8hSJT19JSJ% JS%YM9## y=w ff* 4 BJ%7SJS%YM9## %-S#qJS%89S %8#QSlM?H%?%J.06S %J 7#JR6SQ#SJ#S%J1WS S_MSq%JS#<%#S# R#JSJS%J1 Q6SMSSF%JS#<%#S5<'<<% Q%iSS<JS%9MY##S-( J%{pKv8 98%##NW%q%E9%0%'SM ff* %9 LBJ8S 4 4 b%0BJS#qJS%J8J?J%%T#v%SHS%%J#E%97Sh9#S%J1O0SBMSS%JS#w%J#S#7MSh%8%#07vSS9#%U%6SSM 8 9I$fi# . 7SM 2 8 9I$fi# . D%O%?)S"$+ .SJ8Sh1#iMi7GSB6#B#J#JJpM 88S<%9SSlJ%9M9###SU 3=b 4 2 8 9I$fi# . 4 8 9I$fi# . ?=w # + 8 4 8 9$ # . ?9%Jy=b 2 +-. ;K# . 4 8 9I$fi# .=b 4 2 8 9I$fi# . 4 # + 8?=w # + 8 4 # + 8A?9%J@=b 2 +-. ;K# . 4 # + 8=b 4 2 8 9I$fi# . 4 +-. ;K# . ?J=w # + 8 4 +-. ;K# . ?9%J@=w 2 +-. ;K# . 4 +-. ;K# .'iJ%9M9###SS=w * 4 E MS'%#S1Z=SJOW##B#Jh%S%!,9S%9M9#19%#.SU 3=b 4 2 8 9I$fi# . 4 8 9I$fi# . s&=w # + 8 4 8 9$ # . s=w 2 +-. ;K# . 4 8 9I$fi# . v[=b 4 2 8 9I$fi# . 4 # + 8s=b # + 8 4 # + 8s=b 2 +-. ;K# . 4 # + 8v[=b 4 2 8 9I$fi# . 4 +-. ;K# . Gs$=w # + 8 4 +-. ;K# . s=w 2 +-. ;K# . 4 +-. ;K# . Y[W% Lfi91#gfiffgg<1798=SJRMS%L7JY%!pF1SM0TSU&J1S#T9M8OM [+ %J%<M9S%S9#SM-Mv [0v1S%07vS#-S'1J?%#ES=w - 8 9I$fi# . 4 - 8 9I$fi# . Y[%Jq=w 4 2 8 9$ # . 4 +-. ;K# . s=w # + 8 4 +B. ; # . [nMO'F1JS%#.SBp#SS8b##M SSMU 3 -# + 8ff - +B. ; # . K%J 89I$fi# . LGJ( .SSJbRM%7p1JSSO%Z1p%1S5/)0+ SM8<1J8JJ%S#_SJM=%QM%%8M%JJ i%< %6%F%E%S8p8%OM?r%%%#SJbB## JKn78M9SSLSLVJ#G8S%#O%-SNJ98p#QMuJSp1S89MSS#89#M"S79MSS#J9J1 . M%%S8MS#JPfi. \#JSJ9%SFJS%J1_S0MB%JS<%3SR'% 1fiLUm +2 RV=7.RmpJ#*5%ME?5J#SS#J1BSJMB#JES#8%"9#S%J1OwSMSS'%JS#<%"S#SLJ%0J k8S.i%JS#SlJS%9MY##S6%B7p#b88'_%JLVMSS8'6SdS0MS'%9S#<%"#JS"JJ=wk%SHOJJ> .Jv8B%J9#YSJG%{#6%SY=.k%?B%J *'J9$ .JFJ##9SJG%{#Ev%<M%Y%J80B.J"S .SSQ<MSTvS#J_#-BJ8S8=S8ST1#=Sw8#ES8JMS#LSJF%JS#SLJS%YM9##S#6%hS#SJihSJ#Lw%N9MSSNS9NS9MBB#'kS9w8S_M9JS#<MS=vJp%'%ZSFVJ#"MS%N?J%#NJ#7TSJJ1,%8B?J%#"$fiffgb ffS#<MS=MS%l7p9YM%788+ %JbS8i%S=w *ff 4 .<%79##J0SY8O%D#S9i#L J%h7%RJS%9#d#JS%J1%9F%9S%#NMh#% ,,%JM07 + !on fi5n=SJM%?JS%J1B6S SJwMS%JS#<%DS"%Juy JS%9 8SGN8 , [B8L n 7A8 9 :(;=<>9 :B;? %<SNH%J + [ # Mp{6%FSQ8@ 888Kb8 ,, [ MR%9 + [ M%pNB7M%#F%,, %J + MSF#MS%=JL7JSJS=SJM'MSS Y8#%#w#MLSMhMS%O%8?MJbQ% #9Sw8.J0k80%BS%7Y8NJJp#J9%K#%#%MS_18J JES%9% %JS#<%G#S##08M5{MqhJ#v#EqJ8 %#q#JSM"N'bJSp1SS8vMS{J.S#M#% ,, S%79#DMS'%JS%#J7W%%w9#S%J1956SSJ'MS{%9S#<%#JS"9"7N n 7A8 9M:(;=<>9 :(;W?YMhBJ#?Lv#.OS8SEB%#%%SJ<#%5#B#<7JM8<JM"'JRJv8<vJJ + #b#7v <SMS79%1<%FSJ7S9MbMSQSUS#S8%#JJ% k_p#SH. J?#%. JI *I 1 B?#%*D9TMSl8S#SJ1J.8SlB#S_Jp8##9'J%9M9###TB_1p8S#TS=#MS%=J0k8G%3?#%#SJMMSbS( .9S %?J8%_SwS%<9##l8w#JMS1?8"bJW%w%#% + %#B9=JSJSTSJMFJJRS8JS.SMS%wS#SJMS<J8#J #QS<%79788bi%9J#JM#JSJKMSOJq1JS#J8SqW%J8#JS#F8%8Sl8%F8MS#JKW%S'S<%##8DN =%J<NFJS%Y 8S8{%98%8SHM%Q8MS#JF6%0SJb#MS%8l8@ 8JS%9 88QpJ?v8#JS%7Y##hJSSKS9MDSO1#1<S%<9KMS'JJ1%S#M"SJiSk8$ 9iS%79#h#.8SM%#MS09%NS#wMh%DSJ0#%J9S8Mv1%SS#MS#R%S *RM6#Q8h%,Z%%?"*%kS1pk1_Jv8{%"8?MSJ{%"%JsG%7M68B9#<S#S 9SS{JJ1%S#M"i%J9#JMSJ MSG%81897#F%J8 %9M9kM?%J1%%*%%S 9 , J#SS#J13SJJ1J.8S M=w#%JS%J1 iMq%ip-S8S%#5k%JQMSTJ#S8M?NJ1qST.9v8%9%h%79M=J#S%91\i118J+ FJ%=%S%<9Q#SQM=J#S%91\i6SS=MSSG%9S#<%v#S#_%9_SMl%%9E G=%bS=JS%J19<%J_%%J#E6%'SSL#lSF9( .'8MS"=vU !,o fi0 17kA3 Mh fi 17 4 625 -,?Uv,G,vUS,V38,?W%fi$4$,ffZc38L Ei%JN ff* 4 %Gv1S%l%SJ=%S% J0k8O%K%9S8S%RS%<9# SM %J S%S%FJ0k8l%0%98S% %9SSJ_6S SM Hu SMff* HS#<M0%'Sb%JSS#JS%YM9##S#-M_17YH9S#NSJw%96%qJ#%8%9=w 4 2 8 9I$fi# . 4 8 9I$fi# . e[L 4 2 8 9I$fi# . 4 8 9I$fi# . ;rL 8 9I$fi# . ?uR6S( ES#%98%RM% , S%79#DW%GJ#S%91v n 78 9 :(;=<>9M:(;W?{3FSS#<M+ EG JS88<OS<#9#<%-dSJ?qSJM SJJv8Z%JS%79# MKJ#S%91 -x# SJ% , M,%USJGSw%#J#SS%J1wMFB9#%79FMw%1J#.S %98S%"bwSHU 9+ [ -<#S%'SM NhS# - J%q8#Y7#79%10H7p{%88J%1%K#J%%3G%98%'SJMJ{S#<M%vk%S<S'=w ff* 4 EK%J+ MSBMS%7#J9SS%Gv%SST#JS%3#JSR%JQST( J1T%SJhSR9#wSTUM#JB?#%#8v*%vSSMS#SS#8'MJvM'<vF#S%S%9#M'JRMW%7ES#r9S1w#wJ##N SJM_S17Yu9M?%788bSS#<MlMS9%lLS#SJi%1SJ%wp#S_ D%#%p9M%<88'S#<MB1J#_vJ8%#JJ8k9ES#q%3S=%%%SJ J98G19S#8MS#".6%i1p%<9-#q%L%J%pS#%3?%Jp8%k%JS#<p. -hG8%89 7V%1%'199S-TJS8%.'SJ?L%LMJJS%?L#_S2 fi. ZpZ#8%7SB # 1Su{%9 8%G%JS<M_ .Y#8%#%TS89S.SMS%L%hSJp#SH. QJRM?"%J G_8JSS.S %T6JQ9J8S%9S_S%q8%9%DSJ#B9<HV%SJR9S##<JMSw8p#910#J9#8MBh#BJJ0##MS%YMSB_SJ#S9S#H%=#JW%S#9L#S#J7BS9# SN6%S9#R9%1?\1J5i#w#<J98Mb_S%##S8%#lS%790ST1E.S%{S%S,8? <7%S%iJ( ES#%YGqMq8SES#6%1r J>%8M%Bp#H REiM?M#%N9S18'8JS.SMS% 8b%S%7Y8'JS8kq%0S9MhS0%W 88?<#J#SS#vJp%B% VJ#S1J.S#wS#wSh8%-%3qJSYi( .J%T%.pbJp,SM9_7%i%Jb%Jw MS<%"SJhSM9w.JS%8%NJS8%.SJS19M%18 MS%{SyI !on 62$1fin K H%{%JS#SR9S%9M9#SO6%%. ! S%7Y%-%LlkS9W%N#8%=M? %%%?SJ<_BS %8RpJ%SS#17v.8J%Y#8MNp8%5M?N%hR8S%v##BS%79#l6MSS"vM% /?rK iQS SRSS#<Mu9S%9M9#Sq%F7p#H88w V86LJq%VMSS8W 6#E JS'STMS%JS<% S#SW%=b9#8%i8)8_%J fi 'SiJS%YM9## =%Y<%ES%#9#h% 8? SMT%%9ED#K89%ufi]#?#J8vJ.3%Si8SS.KJ#S%J1SGJMSK%JS#<%#JS"5O%9S8S% J%##SMS%FS#w##M5SJS6%i%9%5JO JDb%JQ8 N8q%9 fi. 8.%SJ_%SJMiSSJ#S6%O7#JSS%J1Z%8%#kSK7%Si#=V*%E<%#!S8%#S8J#MS#?kSJ%TSSG%Y8S%T#KS '=SS9SO#JJ8M-S9M'SFJ%9M9###<%K1ES.J7w7%088B66MS86SbGSqMSh%JS#<%3#SR#O9#8%b9S%v%SSJ%{V#.%8#_9S%v%SSJ%WbS8SE<JS%J1L6S SNM<%JS#qJL 4- 118JS p88<B 8%9%%J#EO# ? B8SS=9S%9M9#7%Z1ES#J#Jq<<%8S8Ow%l%JS#<%vS%1SJ%##7#G%N pD=8SES<9%=q19%JMSbW%iSJ#9J7"%S_MJvMOwk=JJF#l9MSObSF88vS1.BY#%O1J9_'JJ%9M9###ST%07H8S8_ ?VMSS8L6S MSl%JS<%hS#S MS%#%8%*"JNp<78?#0MJJ+ rM3JQSJM=M?# #h9#%SGM?#JSJZSJM{MSO%7%8?M%hJ#SS%J1iWS SJiJMSD%JS#w%S#S"K'J ?JM%18#SS#JST%H1p9#%9MS W%7SR%9SS#%p%bJ9JSJ=% 7 9 :(; %98% W%<SJp#Su9#M?"O%'%_SBr# KJS 'R79%1<%=S%,8 <7%S #%# 8p#.8%LSJS%YM9## %qw%#ES%J# S8SELM? %%9EL#L9 %J1JSES#1p18JTfi] #%{%OSbJS%9 #JS%91Gw1%<#5ZhSS_1p189SW%fi91#gfiffgg11Probability moving closer given grad=closerProbability moving closer given grad=equalProbability moving closer given grad=fartherProbability moving farther given grad=closerProbability moving farther given grad=equalProbability moving farther given grad=farther0.60.6Probability0.8Probability0.80.40.40.20.200020406080Distance nearest optimal solution100120020406080Distance nearest optimal solution100120KS 3h'G%JSS#J%9M9###S"6%K<p#=88K<V86 9S5%D6MSSJ8Z6Sd6.JS3S'MD%JS#<%S#STJJJ8!6%9#8%"8t78%JJ fi.Z%'p88%SJ%i98OS%90G8TSJ% fi] Mq1pS<%O9#S%J1 S{*% %+ 7'J7JS%9M9#L%i#.%8SS#lS<8JSS.=%%J.F#=%#LLVJJ1S#%GS<JS%J1SNJMS<%JS<%O#S# %J SN8%8N%-?J%%%rJ%w1%79%GSLJS%YM9##%iBS?J#l%%J#ES6S 8? #=J#8=SJ% S7J%9M9###N%iBS?J#_6S8 fiU G9S#.OBS_SFSJSGJSSENMv%#R1SNZGSFJ#SS%J1DM-BJ#?H=w 4 2 8 9$ # . 4 8 9I$fi# . N[ =b 2 +-. ;K# . 4 +-. ;K# . '#hMJJSp<ML( J%3 7N; + ! <>9 :(;%J * 7N8 9 :B;C<D9 :(;5%8%l6%#'%EB8#LS0%%P+ rMuT+ X,iK#9%#%JG0%0SS09#%91Nv8G8rS%JS#S JS%YM9##S#q _MS%r7p'%JrSG#!,pB>JS6h7p W9JR#ST#8MSJSQJS%YM9## lS8%SHV8D%# ""5/CBB%?p#v%ST7p#8MSi%9jG%qpJ%<#8Z8%Tvp8G7%D-#79J= "JSJSp1SBSLw1E%3S%TW%1%9 1'RM%##JM7Sw%J G% 7p* w1<9MSwSJw%1SJ%G7%M?1S 7%9S8S%JJJ8 BS S1%SSSk9J#M%# JJ#1 .rS7p*S 1JSJ1K 2 - !K 2 - #M08%SSS 7p%BS_JS9#1 %8SJT%1SJ% b%J .J%.S67p%88%1 %=STSJS# ( G8%Jw=#-9%S ST%J i%7pZ% p"GS8680SwSJS#JN##M0S8%SSS#7p{%Tw#I S" ML l1T7p*wQS_8S#MS#JSJ v8 8 SR?%J i%u%JuJJ%w#N1_7J#8GQJRSJNGH8?<#.89%%M9_BNES$ 98MSl%K<7%SFv8 Y=1E1ph#O9J1SSM%17YwSwJSJ#1 7W%qN%JS%9# #JS%91% G<S8vMJS0JM<S1%SSSk9J#G%J G%7p%U 9J=.-S{YM%788+ SJ8"%SM .M%JShS#<M_%JS7J%9M9###Sv=w ff* 4 ?Y%?bS0JMS<%J#G#JS#M<WSmSM 6 3Jh8St [ 7 9M:(; fiU36%{#%!v8 Y{%JJj#8%p%JS0J B%J b( J%# ?% 8 fiU BSQ( .9%KJS%9M9#k"S8%#KS9M=S7JS%9MY## L%G<%ES%#9#l% 38 M?%%J#E8##9%<l179J" 1%1SrV%0%Jv#79QJS#J$n 7A8 9 :B;C<D9 :(;WW%7fi$4$,ffZ#Q%8N1.SK6%=kS90 k1SF%S7J#S9S#N%, 7 9 :(; W%=?%J p8% %9S#<pBJ9Qvb7%S_SS89#MbV*%{%JSS%Y-6%T<%#DJ%9 JS%J18{#8S#% V<-1%w#7pD%88?%1%w<SU9[ n, 7A8 9 :(;=<>9M:(;WhSSJS=LS#.w7S=JJ#1LM?R1 -%BSF7%NJ0v8O%ZS0JML8MSJ'S( .9S_w%98%SMY%S9#JqSM - 8 9I$fi# . 9SMS#S8'MSFSM%%8q8p%%b#98vJ.%#8, J51J#85SJSv%JS%#J=W% G h%J0Gi?%J fi 8Kp8M8,9%S %pSJS9#1%8?SJK%1SJ% {6%KSiGJS%9 8SDMSiSBT#FSi%Tv%SS0%9KSi' ( M%#l6%Tk%S %hSL1%SSvJ9# !K 2 - K 2 - S8%SS 7p#q#T S<MSMM9fi]A%J%'%#k9Op=%J %%3SSv1S%7M%%<\ 7%JL\_q#9S%J18pS=%1SJ% -#BS9#R_V%1%=%Gb%STJJ#1 FJ%FSTS<%#9#w#9S%J18vS7%1SJ% q8p#M6S SJ0JJ#1U%#JNb<U#qJ 6%1%=% W] _%J!/u] "Sv1S%%hQ1.%7A8 9 :(;=<>9M:(;k%J 7A; + ! <>9 :(;v1O7p#8S8S#G08p#91-% %_E%8S-1%S#MS_v8G8JS%Y Jb8J%J07JE%88%1kEp%..SJMS7pE3%Z%88MGW% "! !-nJS%Y #9S%J18"%SBRSTJv8-8WS#J%KqG 4n8S%##R1%<#JMS#%SQJp,S#JJ%O#9S%J1_#JJ#8MwSJMwSJQJ1R%=SQJS9#1S 8S%_#w%8%##S_6%1TSJM Q#Sv8 YwSY8S%-#S#JFSJM7MSl8lQ%JS#<%iSJBS JJS%v%SS9MHJ#u6S( .JJ1%'SJ?rSJMbSR9#<MS %SJ7JSrJJ8##JRMS% 7p*-*%-J79M9#%'b%SSup#M5 4-LSh k#FhJ%%%8q%98S%HSJ#=vJ#%0#S8S%'#M%8%JJ fi. 8Z%#SLS<vSS#9## NSJMqS9J7J7#O#S#M"h18vGq%S-STS8%#M9#l%{SqpJ%<#01-<3.1JS#8?#<SEb%D8yu8Q%9 fi. B#S 8%p%%%JS<%S#SJP4x8M8,9%T%BSJbJJ#1%8S9=%1SJ% qW%=SS<#JS%J1#=B #QS<#G8=k%SQ%KS< ( M%#%SJT1%SvJJ#J K 2 - !K 2 - S8%SS 7pK#-fi]ACB.0%F8W8S91%"7#J8JFSJSV#MvY06%wSJ8E 8%J fi. 7W S!0G'ac3#JMS BS 8%p%%H%9S#<%#JSJ8-'T%1SJ% #-%ipBSJ#RbV%1%=%#q%{SqJS9#1 Mv%JQS8ST#-8p#J1-% %.w1%SSMS_k8 8R%88%1b%9b9S%9mJw89%DN%F#7v%SS%.S%EG%98%<8%%9MSR#L%88J%1lS#MS%FwSFS<%##8OJS%9dS8S8J%Q%#1p9%uJ0k8w%S1JJMS 18?#6%wM%##JMS %=SJRpJ%<#1O7p*Zb9MSS8J#M.-%98S%<#9#<%J= v8SJ1v8G8lSB9SJ#1_%J_%1SJ%SMS#SS#8%FI !on 2&1Wn pK !B%vv%SRKShJ#S%J1FSBJMS{%JS<%J#JS<%JR*DSSJw%SJ8.*%ES'J0v8{%k#8MSJDS9M1JS#SESMb%%J.S{MSh<%#.S%#"4-JJS9%#%5Gb1J#809= k8J1#Sb9#YSQ%OJSJ1%8S9%1SJ%GM?1Shv #Q1SRGZJ%#%G%FS9MBSJJ%w#1h7p"#'( .J%b%88?M( .\fi]A%%81J.S#L6%S71=%#8MS#J_SJ,%JS#<%Z#JSJhNMS9MRe%Jlff<=%JJ fi. 8%G#Y%v8#%q19J1_8SG%"%8SwJ#w8Jff 0%9_ff<%JJ fi. 8 G%SNJS%Y v'MSFVJ#b8S%#L_MS *M% /F='hSSJ#S{JSSEl#wSJ#S1S_JSp#hSJ18p#J1hW%GiEv%SS#SJMM?wJ98 %1S%=UM?#%ED%"FS%.W%SiM7J1J#7JJ%p%JJ G%T%88 9M:(; SS9%1%-hG8%8{SJ<%JS#SJS%YM9##S#k8 8 SM0%OSw?%Ji%bMSFJpJJ6%L.SU &J1S#JqSJ=JSJ1%ZGwv8 9h9#%SGbSJFMR9%<#88K8SM7#Z9%GM?<#S#J3S9MKMiM9JS#<M#F( .9!J#S%.ZWS SJGM#?W^fi91#gfiffgg1000010000010000Actual search costActual search cost10001001000100101011110100100010000110Predicted search cost100100010000100000Predicted search cost1e+007ABZ5LA19Actual search cost1e+006LA18100000ABZ610000LA201000100010000100000Predicted search cost1e+0061e+007KS 3p8M8,9%Sw%hSJLJSJ#1 %8J<%1SJ%'SMu1S _W%bHrV9k8786JS?3 Q V9k8-. JS?"%J 8) 8VG8GJSB%9 fi.8"S%H JMS% J'##iMS0Sv8#7v5%JS#w%.S%90SJ SJMKMSGwUp#w%#=J#S%.ZWS SiMSZ%JS#w%.S"GJS( ..S%v#N8?<B%%J G%LSJ8%S%vS0?Jp,S#709%<#8B8%vp8G%J= "JS#J1SKhST=1E%JS%#J-6%1'GM?<#S#JZSJM{MS'%<%8M%hJS%J16S SNMSS7%JS#<%i#JS" p1J" )<SJ%S,8 7<%SH8%JS<M?1JSES#wJS%%SOS8OGM?L%Bil6SdS=M'%JS#w%kS#Sl6%O19S#7qv8pJ8vSJ?lSJJ#JwvJp%J%%v8R%9S8S%#%J G%#-%=#%S8F7<%S#S8%DSM%%%?SJ<-6%=SJfi. n6MS5ZM% /? hS97S=1.%# SM9 M5hl%J%pS#_#J9#8MwS9M8hSJ#S%%S,8 7<%Sr#_%%iplvU 98#%*M? #_JS%%SS# iM % %JS<%#S5'S S%,877%uB##B#J1S%QSQJS%9MY## HSJMlM? B##'JSp18 8% 8S8 1E%S8B M? #l7#J G 6S % %JS#w%-S#S"hS%S,8 <7%S &9M_SJS%YM9## 0S9MM?_B##1.S#Bqvhb%%ZJ%#%G%BSJMi#% 7A8 9 :(;=<>9 :B;Y%J7; + ! <>9 :(;*+ B_1J1S877%S% 4 8 9 :(; 4 k%5SS8T7%SJSh9S1S J%ES#W%YBSW^fi$4$,ffZMMSL8%S8=%G%88%1%ZS+OpIn Q%GS7M?9%171p9%S q76JSS8J#8JSiSF#UM%=v8 8RS7%SOv #R1S5"=-h.w*M%FJMS% <=S#<#MhLSS<JS.8S7%J% 87S<17%v8 9bSS89#MS%98S% #HS_Jp#%SH9#YSJ<V8p1S F%h7LM8%3SMQ%%%S9<O6%4D=8%9S9MSS#8JMB%%%S9<O#.%SM. -h.-MS77%8ZSSM7#S_1%SSvJ9#MS% J%7p#79QS8JEqS_80%#JSJ=J#SS%J1 QW S<MSSF%JS#<%'6%q7%S<MJ9S%J#M## S<8%Sw%' 4D=SMS#SWp#.#S#"ZB%JSS#wJ%9M9###SD6%'7p#qS4 8O88 OT%OVM4 SS8i6S%T%JS#w%#STMSEJT=SO4v1S%O1JS%.{U% %J [ E#J8vp.{% kR GTMMS=SOM%#D% -h.7JSMDSJM{SJ'SSJ#S#=RMS%w9%#J1J9DSJhS%7hv%"9p%S<9#YSJK%#,B<p8%9SMl%%%#SJ<D6%4D=v#J8JJ#b4D%9%# 4DF {JJ-%{SJ#-7pKMST%JJS9%#LJ%J% 8SM9MSNvJ%OS9MB#Op88%SJ%w1J9#l._S%7F%%%S9<80JFSM?H9= k8?F6S SJM0%E-B08%8%Sv1S8ZSb<%#JF%iBJ#S71p9#8=7J##_% )F%S,8 <7%S 7J%9#SL<R%Sw#7v%SS%.S%"G8#%hS<MO%3v%S_S%JSbJS%9M9#S{%9lS=.J0v8%ZSM'J#S1S76S#JSS%J11v8 9OJMSpDhS7SBM9#q%vS'SJS#=7pq8MJSSBS'vJ.%{% 7SBSk8$ 9GJS%9JS%J1%Zw1E%S8 -h.vSSD=9MS#8J#MD91SSwSJF%JS#SlJS%9MY##S mfi K 6O'"lUM#J79M%788-U%'SJ?R% 4 %JS'J0k8D%"7pSM -h.7J?M{SJMDSBSSJS-<D8MJSSOSB%%%DJ%SNJ9JSJG1p99LNp8%3M?Q%%%SJw'6%4D=k%88%1N#MS%w#9Jp#JJ%Y#JS%J1B#O%B%SSS"4-JJS#J%#%%G'6JJ<8#JJ1'SJM{SJ'%JS#S7JS%YM9##S#ZTS fi MSh#J1vJ.{%"SB8JSS.J#SS%J1'SJhMSS%JS#w%9#JS"{%bSJM-{SBSS8JESMS#HJ98p# %Jw%E %S8Tp8%M?H%#%%SJ<W%0S fii#JMS ..v88vl%J\*<.k%?7JJ87S*r%v8M%bMSR. U 9J#S -h%w<#J#SS%J1N6S SR8SEwS#S"i1JS%._%JSS# JS%9MY##SqGJ# vN.SS#J1pv1<6SsS8%S8S#8%kS%JJkEh6MSS"JM% /?K#J%##%-J%8%%vb%J%!%%JipJ%<#B1G<DW%iq.J0v8{%37<%S#Sp8%9SMl%%%#SJ<{6%GS fi9%QS 7%T%k8?M%"#J8#J9#7wYSF%9 i%kk#8M 8%ZM?""%JR8S%v##OS%7Y##N6MS"vM% /?K#J%%ES8-MS=S<##M#SKv8G8lGJ%Sw% k1S#%SMLY%1-S$ 8T 4 8 9 :(; 4%J_SF1J189O% 1 ZM?N9%1FS$ 8%. -BF%# "i%9S8S%iSJM'p8%vMR%%MS9<D1J9S1v.S#%#TJ#S97SM_1S=6BJ#?<#J8J p%GJ#8JS#bp1S_DvJ%-#w0<%J8G#.S#8%Y##JTS#<SJ9%1'%5S#SJ1pS%#Jlk%S #%9%#N%9S#<%D%J,%JS#w%ZS#SJ b-J8=SJ=#E8JS8SMS" 7%Sv1S%<p8%ZSM%#%%SJ<-MS7M9qLS?#1hSJq%S%.J0v8h%GS,%9S#<%Z#pSJJJ8{19S#8MS#".*%.S8T%v8Mh#wS<%8{pSSJ%M?_9%1%, 0%S<%v1S%qSM9%1S$ 88MJSSh<S#w##M'#.SJS5Y'#'#L1.%-%SJ9LJS1S##8?<F%OM?HS9%1w%J%pS#Z# k18KG<JS#J<%%JG8Q5SkS.-h.89B7#JJ8MJF#%##%G=GJ#L#%=wk=M9#=w#.S6wJ1SJ%vWMSJSO%KS%J%YSMNS9%1=BJ#?l8%lkSBl7vhS#ES_1%SS#MlhS_SJ%vMLS9%1gg?g$W^ Wfi91#gfiffgg8( %#"O5'(/#/? JJSS8GR79J%S$8LSLSL%SNJ0k8 JIuJ9JS%%9% %JS#<%%JS#<%G#S#JFB#SJ#S_SS9%1w%BS#SJ0JJ8q1JS#J8MS"%JLJ#S1S<SMFJp,S7-JJ%w#8=V%O%JvlwM?N1hJ##9SJZ7k1S#%M?RY%1S 8wV*%9SS+ ?B $ ) $[ffRfi #E{gNC _g GK}%JSS#J#HWS SSMS# upJ%<#Q1N7p#8hL68JLJ6 6S %%%?SJT#JJ8k9EBWMSh%S JSS#%J9S8Mvl1Y##8B<B%%#%%SJ Jp,S7v1J% GL8%8M#Jb#J1%S#_8S%#R#6%<MS"GG8SMYFw%9S%#R7J%J##79S%7.Sw 1w7pO%88%1%#S1J.S#SJNJw8J#ST%Sp8#MuB#S #pS6SQMJJS%J?#MR .vb%#6%<MS5ivSS%Q1%SS#MS v8G8 #6%<MSJ%ES# %9 1Sl<%88?%1 #_1J18JS9%#rJ9SSJ?#S# SMS# 1L7p#lMS%%%#SJT#JJ8k9Effx J8VJWMSlH18SS% 1.1pS x%J L%.S#89MlQMJv8=vJJ HSwMY#w%88J%1%OS_7J#8+0=J%S!pJ%< 7A; + ! <>9 :B;17p{#F9%SwS%<bSJw<MS SMS#S#w%SbSMS# 7A8 9M:(;=<>9 :(;1q7p*ZJS%7Yb8S7E%% # 179SMS#H%BS_SSMS#S#_MSLJ= v8S.8#S8q8%S%S_S1SJ#S#F1G7J#MS-SS9#S#JF%88M%pv8#%##0%wSh#79#80%"ShSMSS#M1.%83_179M?MS%R%8SB<#_#J1S%T#ST%7J.-%#6%<MSQMJvMvLS( JS V%wvpJ # SNJJ%w#L1w7pW %J8%R6S8<#J1S%S<#%88%1%Z8JMY07%_#.8SSRSJ%HS_1%SS#MS v8G8 #6%<MS .J%.S %J 17pD%88%1 #S<9MSST%SJ7S#MSJJQk8 8S<#6%<MS J98p#_17p#LMRJ81SS% F8%#H IpF*%v8G8\SSMS#%J J%S9%<#Q7J#8-% J%S!pJ%<#B%JbJJ%w#'7p#8{v8 98%%G-MSJhSJMGSh9M%788i%SS8#M_B#Sw9MSS8J#Mh1S-7p3S#<Mq%8N9M%<88-%DSq1S-7p MhSTSY( .JEB988%*1pvS#T%LJ1pv1JwSS<%JLS79-##7v8G8 JSJSO#%JJ8Mk91SS#lS fi. u%9LS=J,S#7=pJ%<#8i%'B8%#56S 1S>B.AwSJMhSS<MR?%JSSNJS%9M9#Si#RSpJ%<#17pMS% J%##SMS%0ES8%%1SS{SJ'%%O%vJS%Y#JS%91{%JTSJM<<%J= v8SJ1TMSN9bMM#MY## #+ SL<U#<%G%9S8S% J#S%91bSLM%JS#w%5#S#"JS8JG%9S8S%SJMBS5F88 Iw%J F6MSSJ8K I7%JSLJ%9M9##SMS'S9qS<<8#'MS9J+ rMiJ( ES#%.M?b9J8 #{J1SSM##9#%SNiM #JSJ'S9M-MSqMJJSp<MNJ#SS%J1+ rM<6S S0Mh%9S#<%#JS"{N%=JS8##%GF%S=7%LJS9#1lJ#S%J1=7SJFMSO%JS<%vM#S#7. 7 /I; + , <>9 :B;6S#qJ#MS#<1 Jw{SJM 7 /I; + , <>9M:(;+ rMpB8h%.<8MSJMS_Jw9#<MRS_%S<<8#7b#%JSS#JS%YM9## % N6%q%%J.S(J%9 ? R 7; + ! <>9 :(;9%#Sq7%SSh7%_J#SS%J1Bv8G8l#S#JDp#SbJ#lM?%J S7M=%JS#<%KS""*% 7A; + ! <>9 :B; 7 /I; + , <>9 :(;*0B.JkG7v#8%STSJ81S%S 7; + ! <>9M:(;Z7pZ#-Jq_SJqV%1SJM<BST%JSS#NJS%YM9##S#'#SwJJ%w#T107p{ML.9%#SMS%Q#.S#8%{%1SJ= v8S.=JS%9# #JS%J10%J* 7; + ! <>9M:(;#J9S1SQMJJSp#wMSb%89M%<88+ %OS_9%<#<1T7p*p# SNSMS 7; + ! <>9 :(; 7 /ff I; + , <D9 :(;+ rM#S1S89%98<# S%88%1 %pJ%<#L%9 J%S!pJ%<L1_<<MSR1pv1"'%_HSN7%SJSR#b#%8MJS=SF#79%1i%KSJS##SS8J#M?SG#_S=%JS#SlJS%9MY##S 'vG8'%ZSW^ %fi$4$,ffZ78 9 :(;=<>9M:(;J7JD#qS7JiFSJGV%1{SJM 7N8 9 :(;=<>9 :(; 7A; + ! <>9 :B;|x9JZ96%{S<%#p9S%9#JSS%J18l%qMS%8J%9 #9S%J18 78 9 :(;=<>9 :B;1JS#.S %8S,S#<M 7A; + ! <>9 :(;*K%J1J( .S+ K 6%##L J#S1J.FSSwS89F%OS_M Y%1wSJMR#JJ%H19#%S%r 1J8#JJ%SRUM#J71b<7MSNS#Mr. SN1pJSS78 9 :(;=<>9M:(; 7A; + ! <>9 :(; 7 /I; + , <>9 :B;+ rM'#MM%v8G8QS07p#h#B9_SV%1 SJMZSi7p# %#EM798BSUMSp#h8%S8Z%J%88%1% J%ES#W=S k1S#%8 4 8 9 :B; 4 %ZSSJ9%1=%D#JSJi#%b<v=Sl 7J?#TM5G bT dDYJy R E 9K}'1'7p#G8%%vL#L1S9 _xfiB7%81JEO6%iUM?#M9###<#_1E?%vJJ1_7US=%9S%9 J#w8J %3*% 7%9 <S%##% SMH10#=N%J MM#MYe6TGJS( ..S%F1<9SJ#7%#0k%SL.J%SMS%q%JLJ%.SSMS%78MJS'SVJ#I !-n 2&1Wn K H%96T2 G8%J7SJ8MST9% S79qSJ<<MNSMS#S#85--9w8J<#<M= SMSF%J+.9%S!pJ%<#-1B<GwEiv19L<%81J.'6%U6TR1.%8v7JSJ1q6nO%S#l%JS%L6SxS09%<#=17p*J%-J#S8JL#1S)B. /=9SJ#1e6 #D%8Mb#T%8179 O%J<#DSJ9( ES#0J#8M"Ou%9% 8GSOJMS%JSJGVJ#fi6rJSJ#10FSOpJ%<#1D7J.%JT88?<#B8SJ8B'%88M#_8JS.SOS%1S9%5J#?9Sb%DM?R1ShJJ8 p<6# -Bw%# "F# S868S#_NS<9#YS>6 W%Fl%JS%9 #9S%J1%0S %1 n Q !on 62$1fin K 'Uffc F?3hJM6#B83Gb19S#80Gv8 9L.SSJS#MSwlS ''c --%{?%J fi. h9J8 30h hJMhV%<##L%J#?9S9MSqS ''c -?B q%9 * 4hS0SJ0JJ#1Q%J %1SJ%R ''ffc#.S#8%##l9#YG%S1.JSJ8%Qvq%JS8S9S#wSS%JJM SMS#SS#8%Z%.pJS,%M J4h#S'UffcO6% <MS9#S1S8%GMJJ#<MFS0%1SJ%5J#S9S#J9S#71.S#.JJ%JJUM?#M98.SBMJ9S#<MSb#DS.9OShB#O?%%'%5M?b1SS%9S8S%%1SS#JJ##9J%%#%8%#B#=JK%#<#SKS#M<FS'v8 98MS#T%YSOY#TS 8#TS'SS%JJM( %pJS,%WM JDW%{JS1S8O%JJ UMM9'6%pSJ7%{S'v86%7q. -B??K9%"%GGJSSi MS%<9O=#7%%%.p<JbV09"%9S,%WM J85hJ# %SJ7-ST1pJ17%%797V#QST6% %8JqJ#MS%79SR6J91SJ%wK?W%7J#SS#J11.S#Jq%J MM#M9Q'JbJ#.k%SJS#0W%TSl0SM=S9M=S<J#?9S9'JJ8?<v%SS%79#-M<#.S#8%#NJ9J"='70{SMSS# .9%ES 9 SJiwUp#w%9#S%J1iv8G8TSiGqKD%JqSO.9#..k%SJS##S1L"S+FJ#S%J1( I0v8G8lSm#w8.S<#MS%7,p? k8B i#%%5%ME?J1JS#8SBV%<#q%5J#S9S#JZWSsBJ#?7S-#JJp#J9% 'UffcMhB"Z%###M %" D5{%F#JJ8M=SJMFSb.J0v8=%O8MSJFS( .9S #8M<%9S#<%#JSJiJS#JqJG%#%%SJd#iMJ9S#<Mb1v.S#%##wJ#?9" -B8%8Y=J#S8v%S J%##SMS%=SSJ#SiW%BwS#78 87JS%Yd#JS%91%bh#TB8B%i8e8%JJ fi. 8.GF v8SW%?mT7%F17JS9S%=%J%pS#8D%B%RJS%J1%pGF1T9-S-GMS%79#q7OSMSS#hW%GS.J9..v%SSSJMGSG ''c \#1pkJES#%J#S95' J?=S%7971J#S%GS<%1SJ%{M?1SSq%98S%%8bM%%#p8vJ.7#%8r'1Jr%79N1J#S7%<M%%p%% %JJ S%79#<B 6S%u1pv.S#%'J#S9S#B#Su7% N179uWS J?<S%79#%BJS1bS%T9#N6S SlS8%S8S#8%B#qS( .9SSJb9MS#8J#MTSMS#S8%GS%W GMSLY%SMM%GF79%R#NB%J%pS#{0SJ\SJJ#?9Sb%KSF,M%#B%Sp8#MNB#SLSW^_fi91#gfiffgg16Empirical CDF1140.90.8120.70.68F(x)Frequency100.50.46Exponential0.34Actual0.220.10000.10.20.30.40.5P Value0.60.70.80.9100.511.522.5x33.544.55KS\B 3Uc586TKJS#3L##9S%'Sl,M%#qW%TS1S#QSLJ#.k%SJS#0SJMS5''c7%78q 8%JJ fi.<MSN1pv.S#%# J##9 JJ8'B.KS# 3K'h%1SJ%9%Jw1v.S#%A 'Uffc{6%SJ8'_8#9S%J1'B#S7SS<%#SO,U%%SS9S# 0HwSSMS#S#8<HSJN8W<#l%-KJSHB. 4i fi]MGGLS1<SNJ#..v%SS6%N%_%BS8%#JSS%J18{*%SM 1<9J8 #JKn01pkJES#%J#S9#SJH8T V %S7#JSS%J18=SJq?E=S%GZ#SeB."7SJK%Dv%SNS0%1SJ% 'Uffc n%9NSq1%SSvJJ71v.S#% 'Uffc 6%BSJ0#JSS%J1FBSRSS<%q,U%%K%{( JM%ES#%DS_MS%78p#MS v8G8 Sb -K8J%7SJ##JSS%J1%%J %#%S8<#JSS%J1qBSd fi]MSl J9JSJFJ k8qJ#wM# #S786qS%##8 9MSS#8JMKL%9S8S%l6MT688<O179JS9% WJ9H# Q91pkJES#%"9#YS"0J_SJS_S#JW%1 Z%###M )w%9S8SUMS# SJMLS1''c -L9J8"MSM9JS#<M#u1v.S#%##uJ##9" Dpv.S#% 'UffcL%# MQ SJ 1.1pN%0p8%M?%%%S9<B6%%S8D<q==JMQJS%9#<8hJ%=1p%7Y%* -B<%# "55K%( "hS8v%SSJ%#SMS%#-S<##M"SJS"6%ZB%%{%J#8%.Mq%%%#SJ<6%%%. 4Dh56%Z 4%6h4D= -Bh%9JSJ%b<JMRSJMBSq8p#MSL6SxSJ1pkJES#%%F#%$ I<BVJJ1S %iJS%Y Jw89 3G''ffc=%OJM?8b6%S81-JS%9# JS%J1FMw7%SV#S?%88M# <# . % 1pv.S#%'J#S9S#"4 S<##MTS#MS#JSJ JTW%bS''cJ98 pDbZ#S "-S 0S8M8,9%G%"S-7%wM?l1 '%8SJSM%#%3S=0bS'SMS#S#-6%F8\ 8T%9 fi. 8D'=JMS7#J9#8MhS9MOSU%#J-%S<0 SMS#SS#<#=#.%8#RJS%v%SS#J%ZR#JS%91<Jw8J#%wR%Swv8 98%%"S''cOJJ8 qMFMJJSp#wM<1pkJES#%k6%'7p8M1,MJb8JO#JS%918pBJ#Sh1v.S#%9M9JS#<MS#<8%%6%%S#8#JSS%J18E%%GSBw#wSB?ES#% KJSDB.=%LSJ$ 98%EGJ= v8SJ1Gv8G8R 4%6h 4D %J_S2 fi. iSS9?%#SbkS9#L%'N<%SbJ9%8S%K9J7"lK#J%##%5_%wS9M -h.q%#RJ7pMSJM=S ''c -%G% #JS%91-M7#MJJSp#wMl#9J#ZJ#?9S5l%8% MS%GS<1pvES%DJ##9S" 4hSJ%FS8v%SJ8S%5SJ# YJJ#%#7?%JS#MB<S2 ''c'%ZS#9S%J1'SJBNLZ#S"TB#S qufi]W^Cfi$4$,ffZ0.16p=0.05p=0.010.14KS Test Statistic0.120.10.080.060.040.0201001000100001000001e+0061e+0071e+008KS" 3p8M8,9%O%Z7%LM?L1 %8SJGSM%#-%3S==7%%%S.p<#0SMSS#76%017YM#NSJw%1SJ%SM 109#YSQBSS9MF%OS1%SSvJJ=1v.S#%kJ#?9S5Sc3MS%-M%#{%3SBiSMS#SS#hJJ#8M7%SJ 98%.5J= v8SJ1 '% 8.S%E#5#J9#8M{.9#..v%SS"S1SSSSJOM qufi]0%J qufi]Search costh18Yq%J% 8FB8SJ8BS'Ucff'9SJ#1LlSpJ%<=1h7p58%%81J.6%GSJ-%1SJ%*'UcffG%98S%l6% {J%O%L%5J8\N8T%JJ fi8G1<9S' M%79-0TGSMS#SOW%SBJ#..v%S#DSJMS'JS9#1<%J<%1S9%'Ucff%JMTWS S7S%<<JJ8##J<J##9S"' JS%79T1JS#SSh%S7%1SJ%%98%R%8<M%%_J8vJ.O#%#B% h'0S1J%7919S#Sh%DSb8p%%#J9JJ%Z1S wJS#<MbSw9SJ#1 NV8Lp1S&B. /?RBwJ#1S89%J1 #G7S%79#-S$ 8GS<iW SJ-1'%8MlBSb%JS%#J#J0#J9JJ%S%7Y8KJHS8v%STSSJ#S06%<S E JS%J176%7BJ S#wMS %hSJN9%<#_1w7p9M%<887#7179JSMSJ%#%1SM9% %<%#i9JTQ%hS E #JS%J1N ( V<?G1BS0.J"Ev%SS#OS9M'SF lJ#?9S9MS0#.S#8%5M Erfi]MkWJ9N8p#J17%i%E 1%SSMS v8G8 H%J J%9 Jw89%q %SJ8F%?J83S9TSSJ81B%{SJ0pJ%<#1-< #R%819ES#Jb6% UvB%J8%#lV%##'l%81J.W%-SVJ# ''c q{88D9#wSMS#S8%# SJ Y8%EFJ k8S918 SJ<JSJ1%J%1S9%, 'UffcMSF%J8%#+.9%#SMS%_#.S#8%*{%h1p%<9%91J#8OSF9SJ#1L%JR%1SJ%ff 'Uffc6%=S7GR#JSS%J1##J#_S7S<%=%J#MS%S=,U%85%FSJB#KJS<qSLv78%%iSL 9#YSJ0MSL k1S#% #.S#8%* S1OK !-n78%%iSLGJ#S9S#JM9kMhwv2 J%#SMS%#_#JES#8%,9SJ?NSJM'SJ0%1SJ% ''ffc 8%vF8MJJ#<ML_J6S#TS=JS9#1 ''c %7S=U#8VSS8qSJv%S=%OS9#=%98UMS5ZGb<%Sb8MS8VJ##Q1J#8SJ/%#JS%J10#BJbS-9= k8J1v8 8lS%1SJ%"%JbJS9#1 'UffciMSSMS#S#8%<SJ$ 98%EGMqufi]M%%?bJS%J1%.-179hSB07SMSS#O6%SJBJ= v8SJ1'v8 8bSJS9#1 'Uffc x%JH%1pv.S#%{J#S9S# BS7%H( J%{QSw9SJ#1 NJ%%#DJ#w8J=#JSS%J183v8 Y8%#RSJ<BSNJSJ#1 ). 8fiTS%%pDw6%#KRS10SJ#9.k%SJS#SJMiS-9J8p#F9#YSJDMS=#JES#8%kM qufi]MGiJ( ES#%p#STpJ%<#F1S<38qM9#0l%88MRJSJ#1 UkSJJS9#1%9%1SJ%R 'UffcW^Lfi91#gfiffggEmpirical CDF10.90.90.80.80.70.70.60.6F(x)F(x)Empirical CDF10.50.50.40.40.30.30.20.20.10.102.533.544.5x55.5602.56.533.544.5x55.566.5KS 3Z_%=SQJS9#1r%J %1SJ% ''c-_6%b 8E 8%9 4 fi ',U%O6%'SF0_SBSMS#S=MSFSv1S%#_fi] B@/w%J5/u] e8GJ# vRSMSS#8%# #9J#S#JJ#SJMY% %lSNS<%J#%u%9r7JJ #JSS%J18GN %98S%NSMSS#8%# SJ$98%ETJ=v8SJ17M xfi]Lv8G8 SlJS9#1 %J1%SSSk9J#<1pv.S#%R''cff82-hG8%8Z%ER9=k8J1MS7##MQlS786hS%#h%v%SNJ#S9S#J8ES9LSJMBSFJS9#1 ''c -BJJ88JGSJ1%SSvJ9#q1v.S#%''c8D%%7SJB #HSl.0S#Jb%BKJS@B. %S8T%98DS ''c -qJJ#1SLpJ%<#b177J8MJSJSbSJL8MSJ0WS Sl1pvES%6% SJM7MS%98%N#LS2 'UffcO% 7L%L%JN<J#J Jb8J_#JS%918#% S-G#!,pB_Jb8JT%3%88JMwSS#<MS#0S7%_%3%_1v.S#%%<1pvES%!#%LJ#S9S#H%J *TSLV%1<SJMw%. F#J7vA 7pi% B##1SM#6%#ZR8M9SS7S7VJ#Z8S%#K%GS7<9J8p#lRM%J%"5=SJSJShT8#JJ1-bSJJv%S{%3SJ-..v%S#S9Mi%.<%9S8S%LJ= v8SJ1v8G8S{9SJ#1F%9F%1SJ% ''ffcMS%3JJ#8MS%D%%.=<%ZJ1SJ%# &9H#=SJpJ%<#1B<,|D}E C9fi# g%R p _%JMSG7%09w8J%Nfi.Q#JS%91 #3JB0h#91S%%ZSG.9v83%G%S &9 9MSSS#J.OWh5# MMF6Sm-V1%SvJJ#J'h?%J fi.?kff V1%SvJJ#&JB%Pfi??k*%v%h7%091SS0B#.SpJJ1"O%-1p%<9%kS07% O9J8%98S%uW%<Jby %JNG%S &9Fi%J &JBS% fi. 7MSR# "Mp% /#( /CB.'%J#CB.vSv1S%%G'0J= v8SJ1OS89S.B%N%J8,%wMJSJ0#J1S%0#L%8M%Jb8J %POWh<#<MMrW qrMH%JrM%# 6S qrM p#<#M<J= v8SJ1MS_%98S% 6%L8yu8%JLDG%S &J{%J &9BSJ% fi 8KBJ8SwSl7%MSSv1S%#/p( J( / W] /#8 J%JRu]A% 8 {B=%WN1S<Jw89<%K91SSfi. G#VSSJ8G##JMw.wShV%1iSJMiS7OJw89B8 R8 &9BSJ% fi S( JS%N%8M%0%{M%@L ' K 8MS9i%! 7w#8M%N%JS#<%5S#S"W^fi$4{%9R$,ffZp$8 p J1SS'h%J% &JKBS%'h%J% &JKBS%GhRJ7; + ! <>9 :(;p ""pA%p BMp BUp BMpA"p @B "p /Mp #p Jp #7A8 9M:(;=<>9 :(;p M"ZM9 B3 'J ( U%#JO%DS 7A8 9 :B;C<D9 :(;3%J 7; + ! <>9M:(;31h<O% %JS%#L6%-"%JNT%JJL% &JF9%J &JB %5fi.8N9S8#JS8k% SJM7SR%88J%1 %hS 78 9 :(;=<>9 :(;'1b7Ji6%#T%J686S ?%J fiG%S &J fi.l6MS 80%*{M%/?i%JJS#J%D1pk8?#7.Sp#S#w##MBSJShW% &JBS% fi8=ZM97_ShhSJ ( U%#Jh%S 78 9 :(;=<>9 :B;Z%J 7N; + ! <>9 :(;1w<06%b@ %JuHHQ%JJL{G%S &9Fi%J &JBS% fi8 'lSS9S7#pJ#8MwSJMFS 7N8 9 :(;=<>9 :(;{7p{=7%Sw%88?Mw?%J fi=S9%SJ8F% &J%J+&JBS%5fi p%#SL%88%1L#<JS%'B_%JS#SJ#q6S % &J J&JOS%1fi. 8-' 7A; + ! <>9 :B; 7p B7%ST%88M7S9%RS 78 9 :(;=<>9M:(;Z7p3v%Svh%91SS fi. Z -B8%899#hSM9=#7JS%7.S#MS%TS 78 9 :(;=<>9 :(;"7p*%88%1%{S 7; + ! <>9 :(; <Z1S%SBSQ#J1S%-# OWh1G 0-%8?%#*kS 7N; + ! <>9M:(; 7p%81J.SW%S##ESl%8FJ%D%DSqUM?#M9###L#N9S%9 Jw8J#l%98S% #RST7%SJb8JhSJ1SS Q+fi 80'TSJ Y8%EJ= v8SJ1T# %88%1 /MT V<h#MS%T%JJ fi B%#hSvS9###wS9MhSqpJ%<#01-< <RkqJJM9#F_1%S16%'SU Y8J8O%KS 7N; + ! <>9M:(;57J*DN9MSS#8JMp6%1%h%S8hSJ% 4 8 9 :(; 4 <Lv1.9SNQS_9w8J %hJ1S fi. 8K%T0<%qv<vSS9#7 <SvJp%O% N91SSN#9S%J1O%BwS#79#h%9di%YG9S#8OS=?%JSSl9S%9M9#SGJJ8OSFJJ%w#1B7p"6%h w%9NRG%S &9 %9!&JB% fi. 85%9S%#J#lS<S%7Y##L78Sp%% S1?vQB.A<KN8LSh=S7JS%YM9##S#'% l1.S#J#lL%9SS 88NSMSS-%9S#<%Z#S6%- N QL&JBS%#JSS%J18=%=ST#JS%91q1%SvJJ#wSJ086J%J5JS%YSF%JSN9S%9M9#SiMSJ_JS%v%SS9%"wSq8SS.J#SS%J1w6S S_JMSq%JS#<%#S5 B9#H#019S#.0hSS_SS9SF%9S8S%6%q?%J fi. 8D%%7B M87#HKJS+1.%8GW%TSL#JSS%J1_1%S1vJJ=TSh?E9%JL9S%Sh9S%9M9#q% q1.S#J#T<%=88iTSMSS%JS#w%{#S##= v1S%1JS%.0M mfi]AL'<1%79###JM7L%8v#.BS8M9#_S0vJ#%h% J1SPfi U 3BS0?%JSSJS%YM9##S#'MSS9 98%.S77%ShJ88S%%8JiSJ%_SSh%9S8S%w6%i%J fi. 8%W_8p#MS#qSMJ Y8%EST6S FJ%%9#8%$ IlV*%p<78#BMSJJ+ rM{W%? # 2 Kn Q.J%SMS%%J!J%ES#SMS%<%v1S8q#%SJ #M%TJ8#MS#J8"#JJSJ#STSJM=1F7p#9%S#<9TSJ<<MQSMSS#88Zv8 98%# 7A; + ! <D9 :(;V3V%#K%81J.6%N9S%.S#%JS%v%SS#l% SUMM9## w#lSF9w8J w%D91SS fi. 8W^fi91#gfiffgg11Probability moving closer given grad=closerProbability moving closer given grad=equalProbability moving closer given grad=fartherProbability moving closer given grad=closerProbability moving closer given grad=equalProbability moving closer given grad=farther0.60.6Probability0.8Probability0.80.40.40.20.200010203040506070Distance nearest optimal solution010203040506070Distance nearest optimal solutionKS<83h'l%JS#S JS%9M9#SW%<788<SLM7%JS#<%iSJJ8 76%BJ#SJ1'R &JBS% fi-9#J=v 8SJ1O#NS=%JS#SlJS%9MY##SS#MS#%F<S%98S%RW%'?%Jfi.8JGq%98S%qb#<9%1BRS%8%#K%88%1N%DSJ0pJ%<#=1S-7p*O%Fe%J L%S J& fi 83S ( M%#F1%SvJJ#lQ !K 2 - !K 2 - S8%SSS#%OSJS9#1Q%8SJ=%1SJ% TMSTSSk1S#%fi]ACB_%Jfi]A# T'7%J%#%%J ( 6%=v%Se%J J& BS% .fi #fi]A%%7%#9RW8m1p189SJ%JS%J18KS_%1SJ% <#%ipiBSJwq6%1%O%R0/ %3S-JSJ1 U#lT8%FGS=J=v 8SJ1B118NqV%1%% <#<##M-SS9S=MS7%JS%#J LS<%#K8=%G%JJ<N%8?Mr8 8L% J&%J 9& BSJ%5.fi OW%BBJ#?l%JSS#lJS%9M9#wS#<MSR#O179SMS#J%#bW%S#9%' JwpJ%<#<1S07p%88JM8MJSSbJp,S7<pJ%<#8=% N 2 KCn Q%JJ %J0J1SJS fiU%SJSJ%JSF9S%9M9#S"MS .9%#SMS%=J k8S.#0SiG=vK%JJS%9#L -h88S%% 7#SJG?%JSS0JS%YM9##S#5%9?J1SS fi.%JJ#SJ%#Q#JJ8MFSJM0UMM9## QSlJw8J#Q%OSbJS%J1q#9J#%v8MJST.TS#7YGJ<<MSqSMS#S88p#J#JBSJ91SJD#qS'%88?%1q%k{SMS'%JJ%S!pJ%<B1'7p#KK#9%#%=%9S8S%=SJMOO#iS##YvSSYBSJMiSF%88J%1b%S<pJ%<q1S7pK<8%%J<SJ Y8%ESJJ8VJJJ%7.S%#J= v8SE= .v=%91SS7SJ%SJw1JS8S8%3%ZBSSJR1%SS#MS#v8G8SY8S=%iS%v8MSN9MSJ9,-+*MMWl8'%*5%%i#JJ8MhSJMOJ k8S91O#wSJ9w8J 7%3%9 %Jl% &Jfi. _MSJQ 9= k8J1b SJQS$ 8%0SQSM Y%18-%l7%S .rS7%J#SS%J1Rv8G8 %J p8%'%JS<p 'JR%98% 7% <U#<%hJ#S%91+MSS7%JS#<%OS #J1S%STB 7#JQ6S %9 fi. T% &J fi. 8%J M%# 6S % &J fi. h+&JBS% fi 8vSJS-W%F L%J QbJ%9 8SMSwBH#ZM9 /NGJ( .S%3JFSSJ#SF8S%bR8#M6RM6#8q%* )F%?#J%%S8S* 3O%QSJM+ #h_<%SSq% 4 8 9 :(; 4 Vv9= k8J1hNSTJw89L%{?%J%JNSJ1SS fi OMS#7YwJ=bJ= v8SJ1'#lSJ= k1S%qS 8=%KSSM9%1%W^7fi$4{S%9#R$,ffZ?J1SSF.v%S &9 KBS%/CB."MB. "M# " "%p 8 'B%JJpM E%ACBZM9/ B3 'Jq7% <U#<%ZJ#SS%J1lSTMS%JS<% S#S+ '%98S%Q6%<%JRR7%JLpG%S &JFY%J &JBS% fi5| |"} x { g - [E b# dDYN #M #5].4-3J#8JS=#q1S / '#5BS#MS%#-?%E6%SiM797.SMS=%pSM90M?6%GSJG fi Z.b9MSS#8JM##%i6MSSOS9l%i%U%91L7%=%v8M%i%JlJM,877%u7J%9#S<bSJMlJ% v8r<JM #7JS%RSQv8S6%<%J1%=SM9M?L%%%S9<GW%OS2 fi Z#%L%_%88JM1O7pk% pS=1pi#%#8%v8#iwSwMS#8%#_%SSBSF#79%1O%ZSF%#%%SJ<h6MSS'N7p"J1SJSF%J%88%1%b-S#wM%9S%% #Bb#91S7.S%#l7%0k%SRSSM%8-%%%?SJx%JRS%Sp8#ML1O7pkiMlSSM1,%W,S1MS8k%J%O8SS.S7S89S.l.Lhh#Sp%J p0JSJ#Sp )w*M% \,h 4 n%%%S9Llb SM%L%JS#%D8 iM SJ#F%%J7JMSLSJML%8 v8S6%<%J11,9J%J8#N1<kJEffxSJ<vG8S69 H7%%v8M%9xwV%##ib#79%1OSJ8'S?J1SS=%B%88J%1L% SJpJ%<#1B<,'B8%#pWs1SL/-SJMDSJ'.k%?.p0%k=S 'J98KS *b7%'%v8M%1JSST%-%O#S9T%JS%# E%8SS SL%87%9%T%%S%1Eb%k8?MSJS%71S8%9pSk c58ZfiU_J%S#JS %JS%# . #.%8SS#S%J8N%0 %%1.1?S#8%-%v8MSJy(+*%Jd( =# E qv%S (O*%J ( FMS1.S%# ES#S BSJuH1?S#8%'YY',%BS8b%v8MS MJvML9w%l#%_#ST9pSkvS 6 98 : fi D. 6 98 : fiMq*RM6#"%%?qR%S8=G%J5<%E7%F9J8_JSMM978%JJ%p#<#w7J#MB7JS%7ESG#7SJh<M%Y%w%"S-8SS.S%JTS88W%SOSJJ#q%DvG1J#8STJ?#hSM" iJ#J#'TS9#K%98SMMS" hh#Sp%JpqSJ#%%-ESpJJ10bJ#J_S#1MM#%.B%DS * <%T%v8M%kBSS=%%3%Z%818?MS#wp8%"M?LbS9J8#TS=%S% 1'%K.k%?.pb8U%#9MS"'J3%v8M%EBJ#?0GO% 5.1E#9DS9 98%.S==Siv8SW%?<%J1G%9v%STSG#!,pBRh 4 %#%%SJ BB#Sp mpqSJ#*"%%B%JNSJ8SS.BSM1,%W,S1MS%%%#SJ 6%FS fi Z*h 4 x hB#G pqSJSp*3M% ? -B8%8ZSJ<vG8%iSr%v8M%_17<hS J1# 3LSR#J9J1 9%1RHI ! K _n IM'J S9Mw#0%q%#GqvSSYTQ7%lWS % MS9M S#SQR%9%# %JS<%S"GJS( ..S%pp8%9SMl%%%#SJn9%Sw1ST l8%wv 4Br#7SJhS8%8S#8%JS%K9SS8%D9#S8JSSvF%79?#8%T 4B vJ%K6%K9%S#GSM9TM?<%%%#SJ<9%NLS %k8?M%B#'%OvS9-W%B%J fi'Jh#%<%5S 4BrJ%k8<S9 98%.S7179##8MS8%%9<EG%31i7p#8%==#=J98M= J%.SWM1F%"( JM%.S%"JS%9# J#w8J %'J#-V%18# #MS%_9MS8{%l78#S# 9%_TSM? %%%S9L1''1.S%G<7J?M SJM=W%=?%J fi. -S %v8M%8%#9JJ1TS<%# FM9K Il%F#M#MN17v.SO%ZSM?RY%1=WSxBJ#?lS8Mv#O#7vS9T6MS""M% /?%SS9JM%KS<?M9MSw%S# 81 %J8%k78MkNNS%F%J G%W'Cfi91#gfiffgg1e+081e+071e+061e+06Actual search costMean search cost N1 operator1e+07100000100000100001000010001001001000100001000001e+061e+071e+0810001000100001000001e+061e+07KS<%@3Uc586KKJS#3Kp8M8S,9%D%9SJi%1S9%M71S J98 SJ -%8SJ!%%%SJw85S7##JH[ H#Sv8#7v5 'h.FZ#S#38M8,9%=%GSJSJ#1R%8SJh%1SJ%3SMQ1W%q8e8w%J fi. 'JS#J YS%H JMS% J'##=#Ov8#7v"Mean search cost N5 operatorPredicted search costJJJ8hST7%Sq%8%'V,%v191Y 7%7%v8M%F=%QST%98SMMSJYG#.SpJJ1Q% J,9% SM9 M? %#%%SJ W%TS fi.\SJM7#079##8%#P 4Bu%#G%-wy GHHi%J 8H 88S7%-%J fi8 'L%%%?SJL{hJ# G% pJ#i8S%##bwMSSH*M% /?, -hG8%8YBS_S1p189Sl% v%S_S=7%%v8M%w%J SJLMr81S ?S8MvR79%J#S< %J MSN#.S#8%*VSS8%98S%-SJMGM9GMSh#JWS( .STJ1J.8S 69#8%#<Mi7GJ1-8%8S %7%S=8?MSJ??%JlG=J=#.S#8%v8S#G6%'%#k9M%788?iWJ9_bv%Sl%%%#SJ<8*%> , %9 + 7GJ( .S%"<M<nM9#qN?JM%18$ 8<S7#79%1%S7%B%v8M%{7SJ' k1S#%S{%kSM9<SMwW%{SJ% fi. HJJ8D1.S#71pv8#7.S%1JJ#SJ8G9S#8=Sb7%M? 1 7J98Fv%S %Jw8@ 8N?%Jfi. 8pSF1%SvJJ#TS8M8,Y%B#OSJBL#lSJF8W'#-%ZK<%M{F%98%Jp1pk19< 1%SSMSwv8 8_JS%YsJ#w8J T9J8SJBG7%%%S9<8pJ= v8SJ1%OLV%1%0%=8RMw1<7H%JS%?HM?R6%1%0%8%#Sw%S8%%+-J<Sw#n6S( J1Q%p88SS91% N<J#<%ZJS%v%SS#%iSw%98S%9= k8J1F8%vMYl<S=M81SN%Jl8Mk07J%9#S<8D'JF#79#8MSbiSJMOSF7%%v8M%i8%b?%<MS#8%#T%8GSh1SS( J7.TSM9_M?wqp8Mh%JS<%9SJq%J fi. 8 _<%E<8%S8.SJh v1G%1SJ%##HI ^n L #n 3#<SJMSJh7%_.9v8%98?MSJZS( JS0JJ8! -8%qvGJ 98%.S=#MS%8KSJ%qSJMKS( J0J98-hG8%8{S_.J0v8%'#Ev%0JJ8FSJ %v8M%q1w7J118JqSJM09J8L%v8M%'bqV%1%'%8T%'7%%v8#%#7L#M%8G9S%9 #JSS%J18<%p#%.w8#<ES%k v1SO#wSJhM%O<%w%38%8 4-iSJ8 q1J#.S<p8M%JS#w%"#S9O#LG8B%8%# %1 n L !F%8M%qSJ%c MS%7J= v8SJ1-#NSq%98% 0JJ8 b%J>bMS71SM#L#J9#8MS%%J= v8SJ1h#LS0JJ8##Jq?Jp,S#7FJJ%w#88T 1JS8'B8SJ8BSqJ= v8SJ1MSL9 J%#SMS#%L%w78S.9%ESSMS#%%u %SJ8<%?J8i#TSL%JJ G% 7pW'Cfi$4$,ffZJS%vR#Q1S#>B7Jb%8-MJ9#8M9%%8%NSqJ=v8SJ1'vF1p9#%N#L8?<B%9%%T#7p{YM%788qSJ?%+ %9Sb%JSS#JS%9MY##SD=b ff* 4<%JG8OSJ# .JS"pGG JO179J-SS#<MO%ZS=pJ%<#-1'7pv9M%<88JSTSFS%79#T78Sp%%lS1vl#R1S#qB.A9B#SbJF1p189S* 3JJ-wSS#MS#%FM %9G0b%BM7Jhb8MJSJSFS0%Jdi%l8%.S-%8MNBSNMS8Mv% TJSS%1SMY## %=1JS8iJwSJ Eq% F8 8T?%J fi. GBSE8%p%%b%JS#<%5S#SJ'JSS9S#'?%JSSFJS%9M9#S"MSi7%SiS8J#M5SJ%0SG%98%q9J8qSOS%7iJS%Y JS%J18wSS%'SGSSJ#S %9S%#qW%D?J1SS fi. ZS1v#R1S#8p, 4-JJS#J%#%WS( .Sw%Y8S%#M%J#S189%J8i#+ JJ8%J pBJ#?"w9M8J%81JES'W%iS%98%LJ#S1S8Y%J8G# MYb-S#J0SSJS#9M%<88S<M8p-179hSB9SJ#1 B%Jb1<9MSBSJBSS9SDBSwSh%1S9%%98%bJ# p.S-1%SSvJ9#FS8M8,Y%G{SBw#<SB#E#'%5K%M' ( M%#%DSJq1%SvJJ# K 2 - K 2 - S8%SS< #-fi]A%5%JR%# 8%%1SJ%8p#MO6SJJ#1 -._<7%S=S9%LT6%1%'% 0-%8?%#*pS=SJS79M<SJM0S7%b%k8?M%0J%FJ8#9#q v1S<M9w%88%1%SJJ%w#=1h<,9%B# YMQ#S79_%1Sh%h<9#%SL%JxG%%8qS 8 9M:(; SY%1%LG9( .JES% SwpJ%<7107p{F%MJ9S%J#M7Y%S#6%l8S%%9%#B%*h 4 %=#M %%%SJw8YhJ#QJ= v8W bJ#<M?##HSLJ_%BM,8? 77%S<J%JS<qSJ %TSEJ 98MS %J 9MS S##J#JhB#ZspqSJ#,M% ?{[ ZY G _T dDY| K} ] E C9 g'Jh6MvJ?#<MSL%%KJ%v8_1p9#%RST?1q%STUMM9## L#RSJq1=%p8MS#F%9S#<%JSJD0%J fi. {JS .S-pJ%<#O1G7p9#.SpJJ1# 1S7B#MS%#%J#8%TSJ#q%1S%% -9lSJqJ81S8JG8%8GLJ%LJ###JMHSl1Y#%JM%S vG87%BSN7p*%%{S8.S 9l7p#TMSLJJ#1S%%# SJM_S8r% 8 11SJSl1J18J#J SJ1bvJp%l%J MSQ19( .JESV%#S 9MY%"1p5JDSJpJ%<#K1Z7JM'JS%v{%JF798%#'1 J? GB%11SSS8MJ#JLS7vJp%F% l%JJ fi. 8 0F%J%#S=7J?MSJMSTS###l%1=7p#h8% 19v8%JQM68,S1,V%1F1Y#%JMSJh%%%%?SJvJp%: Rfi:W# 1rGT# g# ff?^ fi$ ? #<9#8%8p#J1'%%S{S9MJpJ%##0JS#%p#JSJ l7JS%OS'v8S6%<%J1%BSMY %#%%SJ<q6%7S fi. x fiE%#" 'h%%i%%G R88%"iM%%E? {88v%SS71%1F1JJS#JJJ8BJ #7J%7.SF8% v7%J8%%J ST1v1J8%S8% 7JS%7EOMSv%<JJJ8"ZF 19#%S-TYMSS#8J#Mi%v1i%3SJJ%8#SbH19S#8SJ+S#* 3b JM<#<9%17J= v8SE7#9S#%# MS#78SpJ7J%S1-S( JSL"_#8M0%JS#<% #S9Ow%9 fi 'FJ1J#%J%pi%! TM-Y%lLS=%SS97JS_SJM'M?N#OJS#MbWdT%Jdp8%%JS#qJL -h8S%GR#JS% 1JS#8TSLvJ#%7JSJ#1 HSJN9%<#_1w7pBLSM#'#J#S#M_WS #S9i%S8BSJ%N%Jdp8%"%JS<pW'CBWfi91#gfiffggc38 |=%RSLJSJ1 7%rM?r1S<S( JS #8MR%u%JS#<%OSJ JJ8-SJwpJ%<#q17pKBJMH#=#J#S#MQWS #S9hS9MMS<J#SS%J16S SFMSSO%JS#<%"S" 4-'#N1SqB.9F%SJ7SF#J#S#%9%?%J. R(J%#? % ff8 fiU BSw( .J%YJS%YM9## % %Fv%ES%Y%p<78?<SJ#?9ST%7 9M:(; fiUh6%=%J p8%K%JS#w E"%98%7SJM=S7JS9#1 q-M9JS#<M#R( J%K-BJ8S[ n 7N8 9M:(;=<>9 :(;W?Y,% #BJS#Ml6S bp8%5%JS#qJdS9Mh#'%%8M%J#SS%J1 7N8 9M:(;=<>9 :(;36S SqMS%JS#w%3#JS"BT%JSBSJq#S%S0#<9%1h%%89MS%7#JS#%Z#JSJh STk8W%w%J1T% b%9% lS7JMSST% 6%[ K7Z#SFEG'Su9%SK%kSOJJ#171S |k%8h#i%%O% 56%v8 9ff<wV86 JSK%98L8l6. JK%JJ fi 8.SSJ#S{6% h8S u 8%pMST<Q6%9SvB%p#SJ%#$ MS"hJ%=ST w#9S%J1%"M?1#hM9#9v8G8AU[ /L%JA[ 8R%J1.S#.J=N%%J9%#J1S%<%+ <1E%S8M?1W%Sl8)H8l#JSS%J10?#hM9#J#bv8G8EN[b%J> ( b9Jh#hSJ#K !on JnVZ7pJJ#bS<%79##J_%5J1" m( "{%hE'[ /3S<pJ%<#T7pJS9#1SGSJMOML1S'#iS##kSJ$ 98%EU 3K5SJJS#%YMl%?%J.iGJ% ? M?# M9#9=%0iM7#JSJ SJMDMSOJ#S%. 6S SOMSK%JS<%.S#Sq%JT%EvU JZ%YSJGV%%?M9'#J#S#%vSS#0#D#8 O%Y8S% J%#SMS%##.S#8%vJp%D#wMS%S%7YF%KB?%J fi JMSp#<MhS6#B#T%8% %98UMS 36%B%VJMk#JS%918 SJbMJJ%HiM %%p7J%S#wU%<%M'%+ #F%?%JJ%6M9Y?0GJ( .S%"G<Ev%SS 8qSJMF_9MSS#89#M-JS#%#$ MSR78SJQB#vJ%7<#J<%Y79%1OLS=v8S6%<%91-%! 1 ! !FS=SJS#T#JSJiMSF%8S8BFSBM{%JS#w%#S5 4-JJS#J%#%MG'%98S%BSJM{S'pJ%<O17pJS9#1SS9MSJ#SS%J1hTSMSS%JS<%YS#S"%Jl%i#SLJSSJ1SMS<vU 9=%iN%#9S#%# MS#Q<8S5b'<9#S#J1S##=v8#%##R%8#fi. ZB8 JSS9#S%J1<1%S#MS#pBRv7179M?MS% MkZ%Z#1.%0%##bp%#S<% {%9 *MW#5 %%?GSJ#Ev%SS#%J% 8BSJBv8S6%<%J1'% 9S#F0UM?87%5J#S#%Jb%Jm78SpJ0%J8M=#JS#%9#S98ZJ#h# fiE%#<8O%*v*M%%E?JG-1J#8SbW##B#JR8%hJp J%# 9% Q9#9MS?9w 'h?F9#H1SJJ1SBSfi ffw8B%JL'<9* )%MEOJSp1JS=6%'%8?MS#<%1S%q#S9 3QVKi7%9Kp8S%?Q pc3% ''%#J#TG%SJ?''w%#J#.?%J*RB%?{1S#<'#<?,p%%4-JJS9%#%pq1JS#J8Bv%SR%1S%T%JNJp#N#S9,fi ff<8n'J79" %ME%8MrJS#Q%JJ , 'B8Sv1S%J%+ ; %J!; / 8 ZJ%#%DG#J8JD %##M* ){%" . 1#1%%MYJ#{1JSJ1SF<8S5UJ% Q "$#=M%JS#98SSJSp1Jq#.SpJJ1QR880%J #8T%# ?KBJQ7J%L3SJTM8#L%-SLv<1J?J1S%N?#S#8TM%##MYlW%<SJL%J fi fi% 8<%*OM%%E?'B%9x<%1S%0SJO8%%B7Y%##=%JRMS%%$fi# , 'SJ=? 2,U, A5D!,'?E' &, U % k{*,AjMB*UUZ+',U)( +* Z;v< :- 2%U*v{S,{?**OGS,AVKV* #,OK*UU+U?9?.%S,AjU< 23vDU*K,Z kG,,O"+8,,MjU8W'C%fi$,ffZ3400320000320030000030002800002800260000Predicted search costPredicted search cost$4260024002200240000220000200000200018000018001600001600140000051015202530Distance nearest optimal solution354045010203040506070Distance nearest optimal solution8090100KS< 3%SO%ZS=J#SS%J1DDv8G8R%L#J#S#%YS#Sl%JlSFJMSO%JS#w%"#pSb%9wS-JS9#1wM?l1 |56%iqff<_V8W JD%J_w8L8N6.JS-?%J fi Z3'[ Jn, 7A8 9 :(;=<>9 :B;W%0S< #JS%91FMS_%R%J# 9Sv1S%#%SS9S#76S %378SpJhMS%9W%?7R#.b#8%3%JS#<7NMJ9##JTS88kSS1.JJJ8OS*%v8M%qM%#N1JS8'JbS EL8 87%9 fi.iBS#s8%p%%b%9S#<%"#JSJ8G S1 S#MS%8_<%_%Jv E %R>uqJ%9 8LJQ SQ988%S8T%{1pv1Jw89%%%JS#%#$ MSN78Sp"k717Y 7N8 9 :(;=<>9 :(;ZW%%?JS%Y #9S%J19S# 6hSrSJR118JS % Q " #='hJ# #wJ88<#JS# %% p8%%JS#wN%8M MJ9p#L88vJS1E7M? SJb#JSJ=SJS#L6S% 78Sp"%$fi# , kGT%JS%#Qb<% 7N8 9 :(;=<>9 :(;*v%8M%%8%# Eb#JS%J1k%MJJ#<M BUfi]A%i SO7% 7A8 9M:(;=<>9 :(;W%D%?7S<%#9#hJS#%#$ MSF78SpT#ZM9 E,U%36%KSSSMS#S#8%pS9 98%J1{%9SG<%q9= k8J1# 7A8 9 :(;=<>9M:(;Ev8G8TSMMJO78SJJi%J $fi# , J17YLJS#JTT ##1LJp,9M%78?#M9%SS%79SJ % 8BMR%#HJSp#5r SuS1p189Su% i%98S%QSJ Y8%EJ= v8SJ1Z# 78 9 :(;=<>9 :B;.v8G8TSG9%##J $fi# , SJ %JqSGSSJS'6Sj%S8#J#S#%# MS <8S98 JS#%##%SSQJMS S%%SbSJMl_<uvNvS9L #7J%Sv8S6%<%J1 %JS# #J#S#%# MS 78SpJlB#S 7N8 9M:(;=<>9 :(;* -B8%8FSq7%M%#F% 7A8 9M:(;=<>9 :(;*Z%JS%#9S#lS)Q "$# %J ! 78SpJ8ZMSwS#D#MS%#M9S#<8w8_GJS( ..S% %N109#JMS#%iFG%SNEv%SS#=%9S%8?M%T9w8J w%'8 8w#9S%J106%v80SF.BS=%{KS<?vB8wB#%#SJM{8%<SBSJKMS'S#.FVM{6S S'M{%JS#w%#Sq79%1D%8?%#M?R18%%? JS%9 #JS%91%YGqJ1-179qS JJJ8B%JS#%#$ MSL78Sp"SMS#SS#8FMS<SM%%8lM%%R#98vJ.h%#% <'J7k8?1EFJ k8S91F#6%w% #9S#%# MS# <8SuS#MS%SJMb%JS%#u9J8<S $fi# , 9%#NMSS8v%S #Q F'J OK !on !#b8p#MSQ#h#S-SJ%1/V %9SJ0v#7J%7.8%JS%#JJ98%!L"#B9R BM V_FJS8"%# %98S% J#1S89%J8-8%QvqM#9S%<9##8S%#7179JSMS<% K%JwFJ= v8SJ1DG8SBSSMS#S#8%##qS#J 98%.K8%W'C^fi91#gfiffgg/ H!j4464)'&,% ! &' &',A,( :1 ,*,+ .Oj 1J' &,0/1 ,AS,3 :,2 *,+ ) ? Oj 4 4& H' &," 35476 1 /1 7,A,A :1 ,% ! &' ( &'%fffi~ #-~~ HH& &H H4 464 4 4644 4% 4 4&5#U,A?A@,j -,U% $"! # $J %H H ~/ J J% %5# -44 ~ J 4 464 4 4 44 4 44 4 44%4 41J~4 4&/ 4 <# 4 / #4 /1J4 # 4KH%AKAH*,+ -ZM9 3B'JGJ k8S91 #0v%SSJi<%q9#S%J1GhSJiJMSZ%JS#<%#S#_ 7N8 9M:(;=<>9 :(;W%JQM?1S7 '6%hMMJh#JS%# MSL78SJJBH8 H8w%J fi.8J k8S91'MS7%SlS#MS#%F<%JJx<!%1S#%#S#JF $fi# , ?7sfi]lB<JMSRJv%SSb.k%SJS#JS9#1QSJwpJ%<#71q7p 3F6%J b8J-JS%9w8"M%##M97#9S#%# MS#R78SpJ6%FSJfi. J% JKNS#J 98%.-79%1lS-v8SW%?<%J1-% D=1J8#J-w%98#J0SJMiiSJSGSl%SJ#J0MvSR1SwS( JS 6% 8M%JS#<%B#S9T%.,M7p8M #JS%J1w%SJ,%JS#<%#JSJ_ %%%qJS%Y #JS%J1 9MSS#89#MBG%98%SJM%89MS%F#JS%# MS_78SpJ'<_7JS%=k8W%w%J1=#lSSJMSJp9<S%%J9%9#J1%h% %Sp8#M_BSbSJw8J#{JS%9#n#JS%918p#<#M%%8?JMS%#J#S#%# MS78SpJT<HkJU JSM9 SM %%%?SJ<0SJMT79S1#.JS$ 98MS"SJ? %bS 8%%v . hh#Sph%9 pqSJSp* 9% %_E%S#M h8S8S#w##MFSJSq#H SJ1SS fi. 8DJ?#J89%Rv8%J_%'Sl#J1% Jw8J##179JS#Tv%S i%J 7A8 9M:(;=<>9 :(;"6%'SJS%J18: RW# 98N8= =v )^ )gR#<9#8%%Siv8S6%<%J1G%9SMYqSM<J8k9J Jp#v0SO1G%YSM9q.JS%4-SPF=S##J#J%Zv80JSq##%q v1S%O.JSiW%D%#8#%SZ%YJS%JIb,%8'dc3MJJpk%CB.p5 B%?#{%8%#TS1%9 8<SJMGS<%#JSM9<S%<M?NSMJMS#"J*%SF#9M9## T7S8MvF8%v%9S#<ppBJ##-#M%-SMYl.'8%p#TSJ$ 98%EK88#%MS7#TM?7 v1S%S8. G8%JTSJ'i%98SMMSJ8EJ%SSJ8iJ%S-J#J%J1=#l#1S#TSM9LS8J%9bSJ8SF#i7S8%S8S8%9S 98US0W% JS868S#JB%E=YMSS#8J#M3U%#J3B#SJ#=h%%%YMJ9MS.SS%JMYvSS#9##S#89<S#J1, k1'%DSJ%S,8 <7%SL#ib19S#.S_9#%'M?N#S8'iM%i_6SmS-JMSG%JS#<%k#S#"K.SJS%#%.GhGJ#b1pk1GS=<MJ#SJB%3SJ#9#%FNv<JS%v%SS9% S<SM9.JS 'K%80.JSSJJ#QW%?1bM?Q<M%W'C'Cfi$4$,ffZ7%SMY#w9S%%SSOG_6SmJS8pJ7SbS8Ji% S=MR9%1%GG9S#8GSS1JM?#TB9# F#%J#qJS%%SS#=G<WnSBJMS{%JS<%J#JS"SJ?SJMqSl8SS.q9#S%J1bQSJ_M0%9S#<%G#SH#0% . - 7; + ! <>9 :(;VQJ%%. pB wh##"8%.SJ%##E%8BSq%%J.%J<%7M?GM? S0M%JS#w%#JS" -hG8%8{S_#MS%8qSwM%#b%'KSb<%SbJS%E R#q#%Q7%<W S<MS=%9S#<%K#S# k86%S7#.%8SQp888q 8<%GFpJ%<#7pk% pSJ#GS%%S'SJMiS=<Up<%v#%w9#S%J1ff+ 7S=MSSG%9S#<%#JSN%98%R"w#OJ%k%SJ%v BTJ%0SBNS9MBJS%YxJb8J_#fi. #G#MS%706J91S7%5Sh k1S#%SM_9%18 4 8 9M:(; 4 %5BJ+ #7%SJS%GJ( .S%EGEv%SS 8hSJMG%.<#J1%h#wSBSMYwS-%JSM#.%S'SR# 4 8 9 :B; 4 "%JlL#68SJ1JS%YdJw89%F{S9#{..v%SS8%% JD1%<#OSJ+ %JS%<JSS%7Y##78Spp%%%8F_%%q%{SM9QS8<1JS8q8) 8b?%J fi. 8kSk8$ 98%#lS E#JSS%J1BhSA 8%fiTS%%l%JS#<% #S#J8O 9ST7%SM9NS #B9#1SMNS7#.8SU%tP ,, + X,G {89S%k78P ,, + X [`P "uT MX, SJ#h9MSS#8JMBM%#i%w7Y#8%##88< Z%##M p# %rv8SW%?<%J1NrS8q 8vJ9<MS #JS%J1%_l S_#79%1%Gv%SHS<%#80%J#MS%80SM9S_#p8SM%#'RSFv8S6%<%J1=% , i%L1pJS%01v87ESMS#"0%98S%SJMP uT8X'MJJSp<MSJbS<%=SbE8SM%{6%qBJ#? R#F<9#8% 4B-K*%%Jqk1w#NM9kH##S8q#8%%JS#<R%0#1HS8J0%'S_M? S9%1%0_%8M%%9S+ %9S%#lJJ8SP "uT MX3#E8U%vMS-SJ#7 V %M8OSJ%wSJ%JS%#JbJ98SP uT8X3#.8SM%*.hJ#'SJ+ %JS%#J_9J8q#MS%8=VMS9#M#7?MP!8fiT( "3Xi#.8SU%DMT SQSJ# V %SM80SJ% S7%9S8S%JJJ8-SJHP "uT MX#.8SM%*0M9Sp9J6%m%S'SRMF_J= v8SJ1'#lSJ7%LSM9R.JSJJJ8'S P uT8X{%J&P "uT MXK#.8SM%#'%8?SJ'SJ P "uT MX{%JwP!8fiT3X{#.8SM%#8 0-%8%#*SJSS9SD1 JjS'ESJ#SqSJM{#MS%8{SMYT.{%T#91S% 4 8 9 :(; 4 6E%7%S+ J%98S% J%##SMS%bES8%"J%%h# 7A; + ! <>9 :(;V_1A JxS9Mh9%%#+ p#N1%SvJJ#<?J%%#RJS%9 Jw8J#%JG179J0S0%98S% 9J8 <6%-% JS%Yx#JSS%J1%8=SS80SM9S#.8SM%#8 -B8S%h1J#8l%#08% #9S%J1l#uJ 8# 8 JS%Y 88SQ79##8#%SS97JS #_SJMNS<##MlJ%J%N#+ 6%N#JSS%J1lBS 8%p%%u%9S#<%#JSJ8-8M8,9%S%{SJSS9S# W%"P uT8X{%8J P "uT MX%9&P "uT MX{%8J P!8fiT( "3X#E8U%#GMSSv1S%#<Sh_<S86G%J_#EGS#%3KST( /'J B9J8S77JJ #E8U%9P "uT MXMS7JR# V MS%8=SJ% ST%9S8S%JJJ8hS7Sw%#8P uT8X"#E8U%*EBJ#iS i%9S%#<J98{S P!8fiT3X5#.8SM%JMS'SJJqMT V%SM8GSJ%SO%9S%#7JJJ8ZSJ P "uT MXk#.8SM%*EM%#"E'M#9OSOp9J6%j%S'S<MOJ#1S89%J8OLSJ k8S91F#N7%RSM9NS%0%9S8S%S#w##MO7%J=%SBS#qJS%YJw89F6%{F#<qS%79i%k8%w#M%8D.'#E8U%# 0-%8?%#*%SOSJSS9k%O-.k%SJS#'S9Mh#MS%8-SM9.JShJ1S%0JS%9 Jw89%9Sk8$ 98%#_.# &YMS# 4 8 9 :(; 4 6, 4hSJL%'S8v%SLJ8S%JG%JJS#J%#7%9S8S%S#w##MiSSJ#SiRS<%"S%79%{RqG%S &Jj%J &JBS%5fi0J1pk8?#7.S#J9#8M'SJMSBSM9bS 6% J#7vB?$"! !jL ' "!mfi"K ! ! 2 0BJ##hS#qJS%J8JSw%#J#JTSMNSSMJMS"{L%JJ#S_7JSp#J0SJG JS8%S8S8%#GSJS$ Jw9###JB6%'1S#7qSM9lS%SJ%Y8SMMSl79J% 8iSv%ES%#R8?#7.S%DJMSS7%iS%S,8? 77%S%T 9MSS#8JM"S7SS9S-JS.W'CLfi91#gfiffgg1e+081e+08y=x1e+071e+071e+061e+06[10,18] tabu tenure[8,14] tabu tenurey=x1000001000001000010000100010001001001000100001000001e+061e+071001001e+081000100001000001e+061e+071e+08KS<(/3 p8M8,9%S-%KSF#MS%01S =S(Jlbp8M0%R%JS#<% #SL9J8<W%-S<%#3%8SJh7p8MqSM9NSTV86%JO%J7J8M%8J#MS%FSM9N.6. J?W%8e8<%9 fi. 8[5,10] tabu tenure[8,14] tabu tenureMv%<SJ%%FSJM ASQ%7J.=%G%S,8 7<%S#Q11S=%GSJMBJ#? #S(JSqS8MvhSM%1%O9%#J{% 8%9%JS#<q##%TT8%%-S-k8W%w%J1B%_ W M,| K}7~ %0SJS-JS#JqlS9 98%.J?-S8iM8%%Y#L% JJ8SS%JJ#b%S7.J%<87JJ8##JRSM9 M?" R9%R#.SpJJ1 %9 G%#H7pi%%##M*)SM9LM?L%%%#SJmW%OS2 fi SJM89S9SiS#79#8%%81J.S'6%'Mw%Y%MM#M9#N#QS71S( .9SN8M7%9S#<%K#S#J-L%J fi. 84-JJ#SJ%#%Sq7J3%81J.S-W%-S#<#Mb9LJS%v%SS#JO%DS0UMM9## _LS01ShS( JLp8MOv%S7S,%JS<%p#S9 %J fi. D%JT%JS<%#S#JZF7%S'91SSfi. 8J0SS9S=#JJ8MqS9MFM# %##M* )-%%%#SJ 8%vT8G%FlMM#%.%Dw?%E6%SiMNJ1J#7JJ%v%JJdG%#_S9MB1J9Si b%8Lv'%D9#%( 3hH9#%<GM? S#SJ<SJM_MSJJ ( .JJ#S%.w6S SJQMw%JS<%BS%JQ#S#JOSJMMST<Up<%#lJ#S%.B6S SqJMS-%JS#<% #SR%J *Bb9#%SJM7J9T<%#.S%# 1JS#SETJS%%S7S8TGMr%<i 6S SLMSS7%JS!<% #S5GR1.%-b1S-7p#'%DJS%9 Jw8J#l9%RSMSM?S9%16MSS8DS_%JJ i%7pG#qS8%#M9_%JHJSp#qJ10#JEq#.RSlpJ%T#8-%SJTSM9S182 4h9JSJ%%9G<#.S J%J1pk19RSJl#lv8G8STJ,S#7T9%<#8-%SM9SM%J#790WMSJS%S7J98p#wSMS9%1%BJu9Sp#_% 19%JMSu6%lSJS#%'J81Sl%J JS#<M6%#SN%bM?#878 9 :(;=<>9M:(;i<G%hJS%9 J#w8J % 4hSJ LJ%N%7VJ#1p9%S SlJJ#1S%8M9M9#S%OSw%J i%7p*3GQ%vJ#%=JS9#1QSJb7p{J%v81 97SJS1pv8#7.SMSH%JJ fi. U 3SJwV%##S7%'JS#%DSJHJ 98%.S #79%1<%%%?SJ v8S6%<%J1%J SNv%.S#%# 87ES%BJMSSN%S%,8 7<%S%W'Cfi$4$,ffZ-9#wS_SJ81S0%iSw%9 i%7p*Z8%8%G#SSFS<%#HJS#%"_J%1%79%Z=#FJJ8#M=BE N#=JJ%NN1p9%7k%.S#%###MS%wS8J=% 8 9 :(;*%%B.F%9 8%.%JS#whMSO%D1SM#=8JS.SMS%i%YSJ3#J?#M5p#<#M%MF8%JS%1p9#%9MSTW%SO9#%KGM?bSJKSJM{M'SJ#(J!J#SS%E{6S %JS#<%Y#S#J{%J_#S#J{<U#<%##qJS%EWs%JS<%9SJ##%#J5%S J##<#9MSl8#JJ1qJJ#8MST9%--#79N9T_SJ<#17%S8JESMS#"9*%S9#JMS_Ev88v%Z8JMYhSJq7S7v%SS%E-1E?9S%{Sq%JJ i%R<Z#hSqWJ9JMS=Jp#=6%VSS7M5LSM1,%W,S1MSTSM9HM?%%%#SJ<=6%Sfi. <M%1pJS%R9N%=M,8 77%S hB#- pqSJSp*GM% ?B%9u<#<9J8MwSJ?<77%qh##p#79%1DSJBJ1SJSO%vSO%JnG%77p*DRp#Fv8%JTS fi. ZS8S'KS .JST%v%8%#$ MS* 3-#<##MZSS9SD#TBJ71JS#8?#-SM97M?%%%#SJ<F6%q%S8 <>=JM?J%9<8 %DS+.J%JMS#<%SJ7.0%JHv8qSMS&JOS% S9J##L9S%9< 4hSJS_7p{%JH%Sp8#MH<8SJ%%8%v%#E6%SiMJMJY# %S879S%9<Z8JS.SMSJ8{%9H8% #8%GM? %%MS9<8v--9J8M fim pK hB8S8GT8% 1pv1=Sw8.-S8J#M#ShRSTSJS#%JS<9S%9M9#SZ0p#b%88M-JSJ1SJ8K'J##Sk8%#qB6%GJS%9w{#BJLJ9b?J1SSLvJ?J<MSp'MS07%SFJ8U%.8J%k# 4D=JK#9%#%SF?%Ji%N7p3#YM%h8JSS.S%kMS%l%{J\mW"K !on # K hJ%B -#BJ98MhSJQ7pv<.Ov#8%8M%N#_%8Ob8%%N#79S%lSM9LSMN%#%%SJ<{%'1%T9%M%SJ338MZSJMZS9%"iMT#S#J"SJMKMS9#S%.5W\%JS<%ESJS9# v<<#J#w 8"5F#F6M0WS %.pJ SJ#F8%k<%?J8%"Np#w##M%5%J%S8v%ES%kM99##8MSb%3SJ-?%JmG%#b7pk#E%#%iJSJ#1SJ%9mJw8J#kSJMTSL<J%EqV%1%<# &YJ8#RJS%9 Jb8JHSJ fi MSlv1<#Qv88JJJ8" %%#JF1p08 #FQ%J% 8wBJ8S8FvSSYT%98%b%88?MS#wM'%KS2 J%.SSOB#SL<#J#w%Y%h7J8M179JSMSJ%" v%S8'J%1S%O%YKSM?TG%K F0SSW I-SivJp%Z%9SM97M?7%%%#SJ<8JS S5fi. %w v"r S9#T%%*iN9%J818" 0=7%J G% 7p8MJS5SJp,S#<KJJ%w#8"%SM9FSM0W% fi R%819ES W% S9#<MShvJp%%v#E8U 3 SJ'1{S( JSq#8MO%JS<%#S#JZFJS%9#jJS%J18D'JGv8{%Si7pE# VSS8Z###JSM=FS MY## -=%81J.ZW%D%JJ#SJ%%vJ%?%E9J7J%J 1%SS1S#uJSJ1_%-k9p%8' 8M86J-7p##J%J %J%pS#bJ%79M7SJM9OSJ{ v1S%S8.SM9wSMb%%%SJwKW%{SJ fi. MSB#TV%1JS79F#NSB%v8MS#"O'F%9xi%L7p3SJJ#L8S%T%-wJ8VJ"Y%S#O6%1p9%#J-S<##MK#SSJZ0SJ'1E1p%Yk%S7<%S'%M%J1TSM9<M?<%%%?SJ<Z6%{Sfi. u%JLSM9RM%%%S9<O6%'%S8'<>=JMR19JM%#%v%JS< MSL9S%9<q9 Fp%J9#b=L0J#S9Svq#Mv%M%SQ%v8M .p%J9#NG%Sv%MS"5@c3J8p RMS#G7Y%E%UW%3SYbh90SM h8YMSS7.5%W8S%JJJ8v1.%1RD4Bi "4ffc"#M%%p'JBG%SRi%=vJ%QR9M-RSJ 4-=%1 0w17%ip8#ES''SM"4h=%?1M8Zi<<%J"Jb4-GYJ98O%%.hJv8B E%%MU /# /#/p='J bvk-%8?J7.#K%S%? 8T=S8JSpJJ1O%JTJ9JS8J?#ESZ6%-%8?J7.S%J9kS % BSJSS%JpW'Cfi91#gfiffgg#7%._1%.iJ%SMSLS8S85'=%S%?iJ_%7SJ%LRMS8 S888'6%v#.S#Fi &9 BSb%_M#8G%8Sb%5i78Sp%%wW%GS#<MSS-%JSJS%YM9##S##lSJpJ%<#1-7J*DZJ%#%GF%M8VJ#_%Sph%SJ=1p18JS#p%#LSJEVJZ%JQ8S%#W8J9%SWS ST%.<J-S8#88YB9#JM9QJhS9 98%.Sb#<JS%=J'%#9%Y9S.SMS"E C fi$14hJ98M%qO G%YGj=%p? 4 179SMS9%hS9 %FSL%JS% S9J##9 S%9L fiK1 fi K KMLUm 1Wn K*? E_xY(%iM8 fiJ iJ%0v88.fi'%#? ##JS%uS%uJ9##QJS%9# hS SM9SM"" !#5n K !ff fiY# CB5x%#/GSkfiY v5K*M%%E? -pJ%<#=9S%9 J1S%J%pS#'%-<Y%S#'6%h19%#.9S1NS?JJ#T#SS#88 -n n ' fi 1> fiv? /pjx "pMi#8 8B# % fi hwS%%kjk " 'Z%%?h'%SJ%S?JJ#TJS%9 3YGp%.SJ%O%9 J8 S#S 9J$ 8 "1 ;Kjm W*K 1 fi'K hFm n K fi ! QEZ?Kjx /#/G.S%'7OF%JE40O JJJ5Ok=%" .? 4 8 %JMJS#% qJSSMSlJ9$ .J6%109#9M%#%"%Y%v%JS#< MS#J8Fm # n K ! ! Q)Q ^n n # ! *?Z8jxY%( /i8S<%"ff Z3F%J86%ff - %5 G%p?_ 8SwS ' SJM? JS%9w=MS%K !K hUn Q h-n Q n fin K fiWK n K 5h DK n ' fi9J5N /#/pjx /#/CB.i#MY qJ%kN fi9-.8J9R%1.S%'J 7YN 09j%#S5pF3%%?c5p8%"M?%9<SBJ0v8{%"#S989<S98B-Yp"? K !K hUn Q jK JI n #n pK fi K 5#h ##fi K fi#m ! J_n !UK h K !on n ;K ML L U955%_xY( /#/3J#J%8 D8#M-<S%,S'KN.SpKkK`b % 'FG%# "? 9J<M0W%qS%J9##lJS%Y<8"01 Kjm W*K 1 fi K;h!Fm n K fi !# UQE #" ?K( /CB5xY JM##8Yj%# "? $ n ;K5*I 1 5n K $nK +K 2 +2 ' n ffQ K I%on !NmCmC n K !VBJJ!S#Y? D*3M fi%Jl #8l%J98MS8%-% fiJJ"E qB 8SJ, 'CBM?x'1791 r%&9BSJ% %J%YS%J9##Cn Q -L n ! K;h&Fm n K ! ! QE ff' %_B5xY%fi ffw8 -9 'J79"JqWc{5%ME? 4-%%#SJ<W%'##J0JJ91SbJ9##0JS%#<8Fm # n K ! ! Q.)(K .? T"CB5x /%8OGO c3M9JpiF%CB%?2&1 Q.nF#.8+4h8%J<#P9#S8. S"%SS%?.98S8--8k,--# "#"? G.#S?JJ<W%b%JS#<%h%J%##JCn Q -L n !>K;h*Fm n K !!# QE/+K*? /p%jx /%%-h.8-0{*M%? 4s<!pSS1< 6%=S7vJp-%ificK%%%SJwh6%0 4D= K! K;h n Q " Qn n Q n K fi K 5#h ##fi eK $ -n # , Jn ' #fi -".ff'959%pjx%CB.* 44 4B {S ?U'R {S8W'C7fi$4$,ffZJnK Q !on )QSK Q 5n QuK5"I ! K5I ! tmCm n K !? " q SJS#8MwS%'b-J%8_%D3?J%%%fi%"#4.\N88%5pk9%%?*-88<#9#S#%S%<J9##3#K%8JE8.%J7VSS%"01 Kjm W*K 1 fi K;h!Fm n K fi !# UQE G+Z*?*/%M3x T/"fi%"4 'B%%i%0% - R88%"Kk*M%%E?h8 %9 I%S%8%JS%#Ev%J.pJU 34 Wp8JD<S'78Sp7% BB#SpJ%J_p0JSJ#Sp%%?)fiK 1 fi K h &1 !-n #!?.? TCB5x T"Mp=7.% fiJYsp* fiJ3%ME? pnjiMK Q !_VKOJ#SY?. q {%5h%9"F.9M?#SkkG-#M8O- D8?J*ih# "#/? 0-9S#< MS S#qJ#M %JJ%### fi 1 ff ff"UkCBjx# "Mpc5JSJ1. -0RMSS" 0q{ %D=B*M% /? 8Mrp8%iM?"Hr%8{GF?Ev8S%8kq pJ8? J+I 2 K5KiK;h 5n Q &1 !-n #!?9#EG8 4-8%<#2 9#S88MW#5N q %%?" K 1Wn pK fi Q JIn Q fi+K 2 AQuKjmY .S8U D8#MN -h#v8SMW#5 q* i8SB#SS"k-"m=%J68 -D%%?4nM?9%17%J%#S'%SJ%S%J9##TJS%YL fi !\K h!Fm n pK ! !# UQE (#U Jjx T#/hB#,3'M pqSJSp*U-.%%? 4 V%3SMvhM?q%%%SJ\W% S*%0%J%9Lfi -L Jn fi #fi 8 ffD*?GBMCB5x "p( /hB#,F'K 0S9#Sp*Z-G*M% ? ^n Q $1 !on Fm n L n pK^L"K S$ JI " K1Wn pK J39M5Z7Jh8n%F#-W% fi%Hp%Hp?JJ#kJ5D# _xYMp_#EG84-8%<2Y##S8?8ZU U8##pkksR8S##*WB *M%%E?E4 SMYRM?R78SJL9#L_J6S#Tv%SSl6%SJ%NSJ%NS9J##0JS%9#L "01 Kjm W*K 1 SK h!Fm # n K fi !# UQE +ff "3*?%CB5x /p8p''88%Z-{%# "?"c3%J9S8Mv8Y%v8M%?F%J S#qM5 fi !K h Fm n pK !! Q.)(#M @B /_x EMpp? k8N 'FYsRi%% fiJ3%ME?K 2 +2# n JI n Cn !-n #!h-K " !b /UL9SY?=E9#SJ#JqG79%.%N G"p?.JJ<%J8, 0O S8%G=*M%? c5p8%hSM 9M%18#S8w%J1798 4D9S19S8 -n # n fi 1 +ff ff'KpjxY( Mpp#J%8R fiJ'*M%%E? +QTS!-K 1Wn K ! 2 Q ;I&nK fiI ff h Cn 1 'n Q K SwK h K !onYh^K K!# Q K n QL K JICKML ! n ! +2 ' pn!on fi !? 5 0DSJS#8vb-J%8S#%J#.9S5p#J%8 fiJ9-E89p<%#* 405*M%%E? i%SkJ=WM#b%JlS=p8%kSMN1SOkMkW*K 1 fi K;h -n n ' #fi !# QE/ ffY# /#_xCBUpp#%J8% fiJ"m%S""=D*M%? i%SvF#%JS#w MS %J MJJSp<MS"Ph8v*-Kp"? ;K !K h\n Q n n Q% n # n pK fi fiK n K _#h ##fi KJn ' #fi" J95J# "x# %"R%S%F%V<%J"S%J#8 ZO*M%?Z#SSq#%JJS8Mv8L&c3%SS#KK {%#8?#%J*ff 40OpJ8?YR pK K" K 1Wn pK $ Jn n !on QTS"! #!?JJ35( "CB5xM|B.5pJ#%8S D8#M G8##"-h.8R-0O%#"?WLfi91#gfiffgg%S8'-p"Ykq9 {%88M*N'"%%?.h8 M?N9%1i6%'(J8#J0J%9<hSLMJ9#8MSl%RS%RJ9##$^L #n fi# 1 (Z8E?K E#_xY(MZ%###M5'5%# /? GJ?J<MSpi6%O9%S#S?JJ#J%9<8)"1 Kom WK*1 fiSK h!Fm #Cn pK!# QE G*?"C@B "_x# "#Z%###M5'D%" .?2 KM%# SMv.lM??JJ$ hW%S%%QSJ%QS?JJ#<J%9LfiK 1 fi K KMLUm 1Wn *? 8 "_xY%_B.{MS98 'v%# ? # I!W+K 2 AQuKjm Q *I 1 ff KMLUm n I\QK QE " qSJS#8#JJ%@bh9%8S b%K J#%%%M%gc %M%" Z 4-MSS89BO2c3JpE fiF%%? fi% S% S9J##H. S#qJ#M%9%##Fm n pK ! !# UQE "3?K%( /_xY#MS" fiJ*M% /? "9LUfim AK5I JI S"! !UK hQSK UQ ) K n Q|L !h^K 'n Q W+K 2AQuKjm fiQ *I 1 ;+K 2 -LTG 5 0vS#8 -89MS7E%OG798Fp891%"G#%%pSM\b-J%8S#%MS" fi iMS9J8"c{ J#S8%Sc{K -hG% 40G*M%? GE?%S#RSJ1SSH%J?%Jmv80JSMS&JO%LS9J##JS%9wU 3pM?L9%1%v%%_%Jl%%M?SJ v8S6%<%J1% W*K 1 fiFK KL'm 1fin i*?v# "_xY# /MS"* fi Y* fi -B% 4v JS8%Jc{ *M%?' iMQ<S1#JS%F7p"%{p8%SM1=#%JS% S9J##h HK ji ! QuKjm7K nK Q "!-n Q K pn Q|L ! nn Q ! #n #n Q% n fin K fi WK Jn K 5h K Jn ' #fi - "UMS" fi GSk fi -hG%N 49j JS#8%fic5*M% /? {S%Y Jw8J#<6%OSM9lM?N#%SJ%RSJJJ##J # n 1 K*?Z( "%_xp_B.88JJj #p8 43%# ?DJ8SS#b?JJ$ i6%iS=#SS#BS_%3S,%%NJS%YL !## ^n Nm|m n Q ^L Cn #!? (% pjxp%MWLfiJournal Artificial Intelligence Research 24 (2005) 465-518Submitted 09/04; published 10/05Reasoning Action:Argumentation-Theoretic ApproachQuoc Bao Vovqbao@cs.rmit.edu.auSchool Computer Science Information TechnologyRMIT UniversityGPO Box 2476V, Melbourne, VIC 3001, AustraliaNorman Y. Foonorman@cse.unsw.edu.auKnowledge Systems GroupArtificial Intelligence LaboratorySchool Computer Science EngineeringUniversity New South Wales, Sydney, NSW 2052, AustraliaAbstractpresent uniform non-monotonic solution problems reasoning actionbasis argumentation-theoretic approach. theory provably correct relativesensible minimisation policy introduced top temporal propositional logic.Sophisticated problem domains formalised framework. much attentionresearchers field paid traditional basic problems reasoningactions frame, qualification ramification problems, approachesproblems within formalisation lie heart expositions presentedpaper.1. Motivation Introductionneed good reasoning action formalism apparent research artificialintelligence (AI). Alongside logicist point view artificial intelligence, recently,emerges cognitivist situated action-based approaches(see Kushmerick, 1996references therein). latter approaches provide immediate practicalanswers certain issues AI. current problem domains (Soccer) Robot Cupseem area approaches promise gain fruitful results.hand, logicist approach aims long term solutions general problems AI.logicist approach, formalising dynamic domains reasoning actionrealised within logical knowledge representation. general idea intelligentagents able represent kinds knowledge uniform waygeneral problem solver fully employ find solution based knowledge.turns out, difficulties general approach AI. Consider taskformalising dynamic domains logical language. formalise dynamicsaction (or event) language n fluents 1 , one need axiomatisefluents effected action also not. Essentially,requires n axioms asserted. formalisation hardly considered good1. fluent technical term referring functions predicates whose values varied relative time.c2005AI Access Foundation. rights reserved.fiVo & Foorepresentation. Hence, need solve problem logic-based reasoningaction formalisms. well known frame problem introduced McCarthyHayes (1969). Moreover, still problem axiomatising effects action,called effect axioms. logical axiomatisation requires conditionseffects take place executing action precisely specified. However,potentially infinitely many conditions, reasoner may neverthought about. realistic formalisation would ever able exhaustively enumerateconditions. Nonetheless, start car, people worry whetherkey car. never bother checking whether something blockingtailpipe checking electric circuits make sure well connected.story long well-known within community commonsense reasoning,particular reasoning action. known qualification problemintroduced McCarthy (1977).number solutions frame problem (e.g., Shanahan, 1997;Reiter, 1991; Castilho, Gasquet, & Herzig, 1999), qualification problem largelyignored notable exception Thielschers (2001) solution within Fluent Calculus Doherty Kvarnstroms (1998) circumscription-based solution using fluentdependency constraints. people argue frame problem already challenging would good approach thoroughly solve frame problemcomplicating formalism qualification problem. argue dangerapproaching problems point view (at least) two reasons:1. may hard come uniform solution problems: manyexisting solutions frame problem monotonic (e.g., Reiter, 1991; Castilhoet al., 1999), qualification problem inherently requires non-monotonic solution.case original qualification problem stated McCarthy (1977)dynamics actions/events need finitely axiomatisableunexpected qualification action arises, agent must necessarily retractinitial expectation effects caused action would take place, makingunderlying reasoning machinery non-monotonic (see section 1.2 discussionqualification problem).2. Many solutions frame problem succeed precise assumptions.instance,Actions always succeed. action omniscience assumption. precisely, assumption dictates qualification problem skipped.case monotonic solutions frame problem. 2Fluents change reasoner knows exists actionpossibly changes value. termed domain omniscience2. argument solution frame problem works nondeterministic actionsubject assumption stand. quick fix allowing approach fortiori expressactions may fail representing failure possible effect invalid one.longer infer that, absence evidences suggest otherwise, actions would normally succeed.also worth noting Lins (1996) extension Reiters (1991) solution frame problemSituation Calculus deal nondeterministic action based circumscription.466fiReasoning Action: Argumentation-Theoretic Approachassumption. assumes reasoner complete (ontological) knowledgedomain reasoning.two reasons course closely related former arises dueunderlying assumptions latter longer holds qualification problemtaken consideration.remainder section, review several works topic introducingreader approach.1.1 Frame Problemlate 1960s, frame problem recognised major obstacle formalisingdynamic domains (see discussions exposition McCarthy & Hayes, 1969; Green,1969). Several alternative responses frame problem proposed along way.respond explosive number axioms required theorem proving-based plannersproposed Green (1969), Fikes Nilsson (1971) introduce procedures operatespecial data structures used represent dynamic domains. However, complexsophisticated problem domains, e.g. domain constraints, concurrent actions,observations different time points, etc. STRIPS quite often fails express domainknowledge. fact, expressivity STRIPS quite limited pointedLifschitz (1987). Another response attributing frame problem artefactsituation calculus proved ungrounded. attempts distinguishlogical epistemological aspect frame problem computational aspect(e.g., McDermott, 1987; Kowalski, 1992). computational inefficiency associatedrepresentation dynamic domains situation calculus attributedexplosive number global situations required situation calculus arguedKowalski Sergot (1986), logical aspect frame problem inherentlogic-based representation dynamic domains. thus essential logical approachAI knowledge representation decent solution frame problem.Later, introduction qualification problem McCarthy (1977),reckoned formalising dynamic domains solving frame problemwould require systematic studies fundamental issues knowledge representation.early 1980s, frame qualification problem considered instancescommonsense reasoning problems. particular, many believed non-monotonicreasoning framework would solve frame problem. argued principleinertia3 considered key frame problem formalised termsdefault rules default axioms default reasoning. Moreover, also arguedsolve qualification problem, following common sense law rendered:action, default, would qualify succeed bring intended effects unlessknown reason to, formalisations dynamic domains.introduction several non-monotonic reasoning formalisms, e.g. truth maintenance systems (TMSs) Doyle (1979), default logics Reiter (1980), circumscriptiveapproaches McCarthy (1980), modal non-monotonic logic McDermott Doyle3. principle inertia common sense law inertia basically states default fluentassumed persist time unless evidence believe otherwise. reader referredShanahans (1997) book details principle issues around it.467fiVo & Foo(1980), autoepistemic logic Moore (1985), etc., believed problemssolved. solutions problems illustrated examples proposed nonmonotonic reasoning frameworks. instance, McCarthy (1986) showed circumscription used solve frame problem relative blocks world domain. Unfortunately,Hanks McDermott (1987) show formalisations work correctlysimple dynamic domain known Yale Shooting Problem (YSP). reviewsuccessful attempts solve frame problem:1. Baker (1989) successfully modifies original (and incorrect) circumscription policyproposed McCarthy (1986) deal Yale Shooting Problem. traditional circumscriptive policy, predicate Abnormal minimised predicateHolds allowed vary. Baker suggests that, instead allowing Holds vary,function Result one varied. solve frameproblem full generality, initiates line research brings manyfruitful results reasoning action community. detailed discussionsolutions follow works, reader referred Shanahans(1997) book. Furthermore, Foo, Zhang, Vo, Peppas (2001) present exposition issue automata system theory point view. orderBakers (1989) solution work correctly, additional axioms need introduced,e.g. domain closure axioms, axioms existence situations, etc. emphasises that: (i) circumscriptive approach reasoning action workscareful designation considerations domain; importantly,(ii) circumscription domain dependent. is, domain dependent circumscriptive policy required correctly render common sense particular problemdomain.2. number researchers argue many cases, monotonic solution frameproblem sufficient. Pednault (1989) assumes effect actions fluentsspecified effect axioms following forms:x, ~y , s) F (~x, do(A(~y ), s)),+F (~x, ~y , s)F (~F (~x, do(A(~y ), s)),(1)(2)Here, A(~y ) F (~x, s) parameterised action fluent, respectively; +x, ~y , s)F (~(~x,~,s)firstorderformulaswhosefreevariablesamong~x,~,s.PednaultF(1989) makes following Causal Completeness Assumption:axioms (1) (2) specify causal laws relating actionfluent F .Note Causal Completeness Assumption stronger form domainomniscience assumption presented above. assumption, following frameaxioms introduced:F (~x, s)x, ~y , s) F (~x, do(A(~y ), s)).F (~468fiReasoning Action: Argumentation-Theoretic ApproachF (~x, s) +x, ~y , s) F (~x, do(A(~y ), s)).F (~Schubert (1990), elaborating proposal Haas (1987), employs so-calledExplanation Closure Axioms following forms:F (~x, s) F (~x, do(A, s)) F (~x, A, s),(3)F (~x, s) F (~x, do(A, s)) F (~x, A, s),(4)Or, equivalently, rewrite two axioms follows:F (~x, s) F (~x, A, s) F (~x, do(A, s)).F (~x, s) F (~x, A, s) F (~x, do(A, s)).Schuberts proposal correct following assumption, called Explanation Closure Assumption:F completely characterises actions cause fluentF truth value change true false; similarly F .Reiter (1991) combines merits two proposals systematicallygenerating frame axioms proposed Pednault (1989) quantifiersset actions proposed Haas (1987) Schubert (1990).researchers also propose monotonic solution frame problem includeCastilho et al. (1999), Zhang Foo (2002).3. Attempts solve frame problem using default logic (Reiter, 1980) also encounterproblematic issues. Hanks McDermott (1987) show natural formulation Yale Shooting Problem default logic suffers problemcircumscriptive approaches, viz. existence anomalous extensions. Morris(1988) proposes slight modification Hanks McDermotts original formulationYale Shooting Problem attempt avoid anomalous extensions.pointed Turner (1997), Morris formulation complete, thus eliminatesanomalous extensions Yale Shooting Problem, unsound. importantly,Morris formulation clear dynamic domains formulatedgeneral. Turner (1997) proposes way formalise dynamic domainsusing default logic (and also logic programming). solution based following observation: Yale Shooting domain similar dynamic domains,anomalous extensions arise undesired effects action derivedreasoning backward time. instance, Yale Shooting domain, making469fiVo & Foocounterintuitive supposition victim shooting somehow still aliveshooting, anomalous extension come following way. First,allows default saying victim persists alive regarding shootingaction applicable. consequence, gun must loadedshooting action. Therefore, blocks application default sayinggun persists loaded regarding waiting action. words, loadedgun would get unloaded (magically) waiting action undesirable conclusion. block lines backward reasoning, Turner appealsnon-contrapositivity inference rules replaces implications inference rules.guarantee formulation work correctly, additional techniques requiredfact formulated inference rule:falseenforcing completeness initial situation adding following rules:: Holds(f, S0 )Holds(f, S0 ): Holds(f, S0 )Holds(f, S0 )every fluent f .However, Turners (1997) formulation still fairly ad hoc different techniquesadded fix known issues. example, inference rules used placeimplications block application undesirable backward reasoning,rules completing initial situations added overcome unsoundness issueMorris (1988) formulation, etc. also shows problematic side default logicuniform formalisation various problems common sense reasoning. becomesserious issue one proceeds question qualification problem,typical problem default reasoning, solved Turners (1997) formalisationdynamic domains. case, example, instead assertingvictim dies whenever shot loaded gun reasoner maintaindefault proposition may many hidden possible conditionsvictim may die. Thus reasoner able deal surprising situationsvictim observed still alive shooting action (of loadedgun). Another, symmetric, case surprises regarding persistence fluents.instance, waiting action, supposed unload gun, gun,loaded wait action, observed unloaded. scenariofirst introduced Kautz (1986) scenario called Stolen Car Problem.cases, reasoning backward time necessary. clearrendered Turners formulation explicitly intends block backwardreasoning. scenarios analysed solution present laterpaper.1.2 Qualification Problemseveral solutions qualification problem, none addressedoriginal qualification problem introduced McCarthy (1977) later formalisedGinsberg Smith (1988).470fiReasoning Action: Argumentation-Theoretic Approach1. Lin Reiter (1994) propose formalisation action theories situation calculus (SC). formalism extension Reiters (1991) solution frameproblem (sometimes) incorporating state constraints. discoverleast two different kinds state constraints call ramification qualification constraints. go claim solution qualification (andramification) problem. basic idea behind solution qualificationproblem certain state constraints imply implicit preconditions actions.Thus action may qualified even though appears (from explicit actiondescription) be. course special case qualification problem, classical qualification problem introduced McCarthy (1977) muchbroader extent. setting, qualification problem pragmatic issuetechnical issue. Similar frame problem, impractical, sometimesimpossible, axiomatise possible preconditions action. example,addition requirement gun loaded, guarantee performingaction shoot would kill victim, many preconditions must also included as:gun malfunctioning, shooter miss victim, victimwear bullet-proof jacket, etc. among may improbableas: alien interferes bullet. reasoner simply want consider conditions assuming case unless explicitevidences stating otherwise. words, qualification problem originalform requires reasoner able tolerate mistaken conclusions possiblyjumped previous inferences correct appropriately. Henceforth,always refer qualification problem original form. similarityframe problem led John McCarthy conjecture that:frame problem may sub-case call qualificationproblem, good solution qualification problem may solveframe problem also.(McCarthy, 1977, p. 1040, italics original.)Roughly 10 years introduction qualification problem, McCarthy (1986)presented solution problem using non-monotonic formalism circumscription. However, solution suffers almost identical flaw counterpartregarding frame problem: simple minimisation abnormalities sanctions anomalous models (e.g., Thielscher, 2001).2. McCain Turner (1995) propose solution problem described LinReiter (1994), viz. problem deriving implicit preconditions stateconstraints. McCain Turners solution posed model-based representationaction theories.3. Similar McCain Turners (1995) result, Baral (1995) offers solutionproblem defined Lin Reiter using state-based representation. Baral extendslanguage disjunctive logic programs state specification actiondescription language.471fiVo & Foo4. Doherty Kvarnstrom (1998) make careful investigation qualification problem. aware shortcomings present definition qualificationproblem introduced Lin Reiter (1994). proceed one step distinguish weak strong forms qualification problem. dealcomprehensively qualification problem full extent, Doherty Kvarnstrom apply circumscription predicate plays similar role predicateP oss used Lin Reiter (1994).Even though Doherty Kvarnstroms (1998) solution closest spiritoriginal form qualification problem, still serious problemapproach. intended designation predicate P oss variants actionoriented. is, would qualify executability condition actionconsideration, towards effects action supposed cause.words, circumscribing P oss guarantee capture full extentqualification problem. example, single action shooting gun may causeseveral effects: killing victim, making loud noise, emptying cartridge, etc.conditions action executable is: gun, gunbroken, gun loadable, etc. action executable, necessaryeffects take place. may case loud noisecartridge emptied victim still alive since victim wearing bulletproof jacket. Assuming reasoner somehow aware possibility,include requirement victim wear bullet-proof jacketqualification action shoot? Perhaps would still expecthear loud noise cartridge emptied shoot action.end troubles though. presence qualificationramification constraints causes several complications. Firstly, syntactically distinguishable. Secondly, mentioned Doherty Kvarnstrom(1998), qualification constraints may cause indirect effects arise vice versa, i.e.ramification constraints may reveal implicit action preconditions.Remark: terms ramification constraints qualification constraints firstintroduced Lin Reiter (1994) careful examination state constraintstaken. discussed Doherty Kvarnstrom (1998), two kinds constraints might interact several ways. Consider example introduced DohertyKvarnstrom (1998): preconditions action board plane havingticket at-gate. However, passenger places gun pocket hometravelling airport proceeding gate, new qualificationaction board materialises. one ramification putting objectpocket stay travel location location (i.e. resultramification constraint), reasoner could easily conjecture passenger failsboard plane. hand, fact passenger possesses guntrying board plane must fail board plane result qualificationconstraint. Now, fact passenger possesses gun disqualifiesaction boarding plane also brings indirect effect actionboarding plane executed: passenger put arrest. Noteindirect effect take place, requirements must present: action472fiReasoning Action: Argumentation-Theoretic Approachboarding plane executed, qualification constraint present.words, qualification constraint might also bring indirect effects.believe problems sophisticated circumscription policy successfully address situations. Furthermore, policy wouldextremely hard understand error-prone. Recall failure non-monotonicreasoning formalisms regarding frame problem (in simplest form viz. withoutramification qualification problems). Researchers failed pointbug several years Hanks McDermott discovered awardwinning paper (1987).5. recently, Thielscher (2001) gives exposition qualification problem.Thielscher discusses problem sustained McCarthys (1986) simplistic circumscription policy, viz. anomalous models. introduces default logic basedformalisation qualification problem Fluent Calculus showsformalisation suffer problem anomalous models. NoteThielschers formalisation, circumscription still required generate initial theories default theories (in addition set default rules). Nevertheless,Thielschers solution still suffers following drawbacks: (i) Thielschers usepredicate P oss way formulated Doherty Kvarnstrom(1998). Thus, qualifications taken executability conditions actionsrather different effects actions; (ii) Thielscher showsproblem anomalous models sustained McCarthys (1986) circumscriptionpolicy overcome formalisation, entirely clear whether Thielschersformalisation based circumscription default logic sufferanomalies.1.3 Ramification Problemcontext reasoning action, ramification problem mainly relatedindirect effects. Finding solution problem may easy indirect effectsindicate exceptions frame assumptions require special treatment.several formalisms dealing ramification problem, e.g., see (Lin, 1995; McCain& Turner, 1995; Thielscher, 1997), still several issues need carefulconsideration. consider three examples motivate discussion.Example 1 Consider Thielschers (1997) circuit:example interesting gives counterexample minimalistic approaches e.g. work McCain Turner (1995). domain, intendedrelationship relay sw2 relay on, would make sw 2 jump off.Thus, sw1 sw3 closed, sw2 also closed preventedrelay. However, certainly duration (no matter short is) sw 2forced jump relay. state given Figure 1, performing actionclosing switch sw1 , two next states equally possible: one detect on,another off.4 latter sanctioned minimalistic account.4. reason nondeterminism case due insufficiency domain information: dependingsensitivity relay, light detect, light could get lit quickly detect sensitive473fiVo & Foo-sw1sw2-light-detect-relaysw3Figure 1: Thielschers circuitexample, Thielscher pointed need keeping track chains applicationsindirect effects.Thielscher (1997) proposes way remedy problem keeping track applications domain constraints re-expressed terms causal relationships.Thus, given example, formalism able arrive next statedetect on. Following chains causal relationships, dynamic system undergoesseveral intermediate states arriving next state.2paper, proceed one step Thielschers (1997) position formallyrepresenting intermediate states possible states world. 5 believeintelligent agent able reason intermediate states even thoughmay satisfy domain constraints. capability especially importantreasoner needs explain certain observations world systematic way.note given observation, may several chains causal relationshipsbring observation.6 Unless intermediate states explicitly representedreasoned about, way agent full insight system handcertain information would missing.Example 2 Consider Lins (1995) spring-loaded suitcase two latches. Lets assumelatches toggled suitcase closed. following state constraintsupposed apply domain: up(Latch 1 ) up(Latch2 ) open(Suitcase).question is: robot close suitcase back opening it? McCainTurner (1997) also consider problem answer is:detect glimpse light relay sensitive enough make switch sw2 jump quicklyenough detect on; otherwise stay off.5. Note point view also corresponds traditional definition states snapshotsworld.6. example, given detect next state, either light never brightlight may bright detect sufficiently sensitive detect momentarybrightness.474fiReasoning Action: Argumentation-Theoretic Approachgeneral, latches up, impossible perform actionclosing suitcase; one must also concurrently toggle least onelatches.(McCain & Turner, 1997, p. 464, italic original.)problem represent action holding suitcase closedwould overcome indirect effect caused loaded spring. alsosuggests another kind actions whose direct effects keep world unchanged.actions usually formalised researchers fluents, e.g. holding.main objection approach agents also need reason actionssince may also require certain preconditions agent strong enoughhold object. Moreover, certain (abnormal) circumstances, agents may also failperform actions. is, actions also subject qualification problemdiscussed previous subsection.2Example 3 Consider circuit Figure 2: 7-relay1-sw1sw2-relay2Figure 2: dynamic domain (potentially) infinite sequence indirect effectsquite obvious performing action f lip 1 whose direct effect sw1closed, following circular sequence indirect effects take place: {relay 1 , relay2 }sw2 {relay1 , relay2 } sw2 {relay1 , relay2 }. sequence course wouldpotentially carry sequence indirect effects indefinitely unless sw 1 flippedopen device stopped functioning correctly, e.g. battery charge.words, action domain requires action inserted seriesgoing indirect effects captured representation. Notealso none causation-based representations proposed Lin (1995), McCainTurner (1995) Thielscher (1997) able deal action domain.21.4 Towards Solutionaddress problems discussed previous sections, argue order finduniform solution problems one avoid cryptic formalisms whose consequences7. example instance so-called vicious cycles scenarios, e.g., see (Shanahan, 1999).475fiVo & Fooseen clearly formalisation problem domains. consequence,propose uniform non-monotonic solution main problems reasoning action. Essentially, performing commonsense reasoning, reasoner relies numberplausible assumptions, e.g., assuming instance birds flies, assumingshooting turkey loaded gun causes die, etc. traditional default reasoningformalisms circumscriptive approaches default logic, assumptions madeimplicit. example, instances predicates minimised awaycircumscription implicitly asserted justifications default rules stillconsistent extension consideration default logic. proposed representation formalism aims making assumptions explicit automated reasonerconscious (at least) assumptions relies performing reasoning.reasoner always manipulate assumptions independently other.also basic idea assumption-based frameworks heart Bondarenko,Dung, Kowalski, Tonis (1997) argumentation-theoretic approach.proceed consider ramification problems domain theories concurrent non-deterministic events. Among major results, show frameworkcaptures essence causation-based approaches regarding ramification problem.Moreover, also show expressiveness formalism two examplesindirect effects also need qualifications infinite sequence indirect effects. bestknowledge, none existing formalisms able cope scenarios.Based basic idea assumption-based frameworks, approach comprisesfollowing major aspects representation:1. introduce different types assumptions render various laws common sensedynamic domains. instance, frame assumptions introduced capturecommon sense law inertia whilst (two types of) qualification assumptionsintroduced overcome qualification problem.2. introduce special class (system-generated) dummy actions allow explanation problem, i.e. actions events occur outside reasonersknowledge, dealt uniform manner.3. based Bondarenko et al.s (1997) argumentation-theoretic framework,approach makes use inference rules represent domain knowledge.4. Lying heart approach argumentation-theoretic semantics, called plausibility semantics, argued best render common sense knowledge dynamicdomains. semantics consists particular policy resolving conflicting assumptions computing argumentation accepted.summarise, paper formalise expressive representation scheme ordercope sophisticated action domains. believe formalisation sometimesrequires certain advanced knowledge encoded precise well-engineered way.representation action theories proposed paper considered intermediate level commonsense scientific knowledge. expressivenessformalism improved several independent steps adding assumptions476fiReasoning Action: Argumentation-Theoretic Approachdomain descriptions. also shows one advantage solution: simple representation achieved simply removing involved assumptions. arguablydesirable feature reasoner option either increasing expressibilityrepresentation formalism improving simplicity and, consequence, efficiencyreasoning system.rest paper organised follows: Section 2 summarises relevant featuresabstract argumentation framework proposed Bondarenko et al. (1997), semantics concrete instances. Section 3 present syntax semantics basictemporal logic extension reasoning action. Section 4 presentformalisation reasoning action based argumentation-theoretic approachintroduced Bondarenko et al. (1997). approach reasoning action, particular uniform solution frame qualification problems, well mainresults paper presented Section 5. Section 6, show proposedformalism extended deal complex dynamic domains, includingconcurrent non-deterministic events, indirect effects. Related work futureresearch directions discussed Section 7. defer proofs resultspresented paper Appendix.paper extended version two earlier conference papers (Vo & Foo, 2001,2002). main differences version proofs included, lemmasused proofs theorems introduced help reader easily comprehendresults, presentation improved extended examplesvarious constructions.2. Defeasible Reasoning ArgumentationLet deductive system hL, Ri given, L formal language countablymany sentences R set inference rules. Given theory L sentenceL, write `hL,Ri deduction whose last element . h hL,Ri ()denotes set { L | `hL,Ri }. Since language L generally kept fixed whereasset inference rules R likely vary depending description domain,possible confusion abbreviate ` hL,Ri hhL,Ri `R hR ,respectively. Thus classical inference relation ` also written ` RC RCset inference rules classical propositional logic. Note also every set inferencerules considered paper super set R C .Given deductive system hL, Ri, assumption-based framework respect hL, Riconsists theory representing current knowledge reasoner domain,assumption base AB contrariness operator , i.e. given assumption AB,denotes contrary .Remark: notion contrary assumption intended generalise classicalnegation . Note general assumptions may constructed special operators(e.g. negation-as-failure case logic programming, modal operator Lcase autoepistemic logic, Moore, 1985), thus contrariness operator must also sufficiently general.477fiVo & Foohardest part reasoning assumption-based frameworks computing setassumptions augment given theory . argumentation-theoretic approach,realised attack relation. determine assumptions accepted,assumptions put together form arguments. assumptions behind best arguments considered acceptable. Several semantics best arguments presentedBondarenko et al. (1997) based notions attack: Given assumption-basedframework h, AB, assumption set AB:attacks assumption AB iff h( ).attacks assumption set 0 AB iff attacks assumption 0 .closed iff = AB h( ).conflict-free iff exist AB ` R , .Assumption-based frameworks assumption sets always closed referredflat. flat assumption-based framework, conflict-free property setassumptions equivalent property attack itself. majorargumentation-theoretic semantics defined Bondarenko et al. (1997) assumptionbased frameworks include:Stability semantics: assumption set AB stable iff1. closed,2. attack itself,3. attacks assumption/ .Bondarenko et al. (1997) show stability semantics correspondsstandard semantics extensions Theorist (Poole, 1988), minimal models (manycases of) circumscription (McCarthy, 1980, 1986), extensions Default Logic (Reiter,1980), stable expansions Autoepistemic Logic (Moore, 1985), stable modelslogic programming. words, complexity-theoretic perspective,approach based existing formalisms default reasoning renderedcorresponding assumption-based argumentation framework loss termscomputational complexity.Admissibility Preferability semantics: Bondarenko et al. (1997) goextend existing formalisms generalising semantics admissible preferred arguments originally proposed logic programming only.new semantics defined terms admissible preferred sets assumptions/extensions. assumption set AB admissible iff1. closed,2. attack itself,3. closed sets assumptions 0 AB 0 attacks attacks 0 .Maximal (with respect set inclusion) admissible assumption sets called preferred.478fiReasoning Action: Argumentation-Theoretic ApproachThroughout paper assumptions expressed terms usual propositions. Thus,replace notion contrariness Bondarenko et al.s (1997) systemclassical negation omit specification assumption-based frameworks.is, assumption-based framework h, ABi consists theory L,assumption base AB contains assumptions used reasoning.3. Domain Descriptionsintroduce propositional action description language based comprehensiverepresentation formalism proposed Sandewall (1994). particular, extend Drakengren Bja relands (1999) language possible describe narrativesframework.3.1 SyntaxFollowing Sandewall (1994), underlying representation time (discrete) time structure = hT, <, +, consistingtime domain whose members called time points integerspaper (except later part paper distinction made explicit);<, +, usual integers.Given time structure = hT, <, +, i, signature respect tuple= hT , F, Ai, set countably infinitely many time-point variables, F setpropositional fluent names, set action names. Since time structurefixed rest paper, taken implicitly whenever signature introduced.assume sets countable. denote F = {[]f | f F}.8 memberF fluent literal. Moreover, = A0 DA, A0 set domain dependentaction names, called basic actions, e.g. load, shoot, etc. DA = {da l | l F } setdummy actions. explained later paper, solution problemsreasoning action based basic guideline attributing changes events.Given reasoners ignorance certain events bring changes world,dummy actions used make gaps reasoners belief state.need associate dummy actions fluent literals F .fluent literal l F , introduce following two symbols: AQ l , F Al :AQl associated assumed qualifications upon preconditions actionregarding fluent literal l. Essentially, AQ l used descriptiondynamics action allows reasoner describe main preconditions(with regards fluent literal l) leaving possible (but less probable)qualifications rendered single assumption AQ l .F Al associated frame assumptions regarding l. F l , coupledparticular frame inference rule, allows reasoner infer fluent literal lcontinues hold future time points unless reason defeats F l .8. notation [] means formula following may, may not, negated.479fiVo & FoodefdefGiven set fluent literals F , denote F = {F Al | l } AQ ={AQl | l }.time-point expression one following:member T,time-point variable ,expression formed time-point expressions using + . convenience,also write + instead + 1 1, respectively.denote set time-point expressions E.Definition 3.1 Let signature = hT , F, Ai given , E, f F, A,R {=, <}, {, , , }. Define basic (domain description) languageby:0 ::= true | false | f | R | 0 | 0 0 | [ ]0 ,::= 0 | [, ] | |assumption base AB by:AB = ABAQ ABF ,ABAQ = {[, ]AQl | , E l F },ABF = {[ ]F Al | E l F }.domain description language LD (over ) defined: LD = AB.9[, ] means action duration corresponding interval [, ]. [, ]AQ lmeans fluent literal l assumed qualified hold end interval [, ].[ ]F Al means fluent literal l assumed default persist time pointnext, i.e. principle inertia. Notice difference [ ]F l1 [ ]l2fluent literals l1 , l2 F . [ ]l2 indicates fluent literal l2 holds[ ]F Al1 indicates fact fluent literal l 1 persists interval [, + ]true.example, blocks world domain, say block block B timepoint 2, write: [2]on(A, B); or, say action pickup block occurstime points t1 + 3 t2 1 relation < holds 1 + 5 t2 , write[t1 + 3, t2 1]pickup(A) (t1 + 5 < t2 ).formula contain connectives (i.e. , , , , , [.]) atomic.atomic E, formulas , [ ], , [ ], [ ] literals.Let formula. fluent f F occurs free iff occur withinscope [ ] expression . E binds f formula [ ] occurs subformula, f free . fluent occurs free , closed. containoccurrence [ ] E, propositional.9. would precise denote domain description language L . However,signature usually clear context order avoid mention every timeformalise something domain description language, choose denote LD .480fiReasoning Action: Argumentation-Theoretic Approach3.2 SemanticsDefinition 3.2 Let = hT , F, Ai signature. state function Fset {true, false} truth values. history function h setstates. valuation function E T. narrative assignment functionTAT set {true, false}. addition, define q : TAQF {true, false}f : TFAF {true, false}. interpretation tuple hh, , , q , fh history, valuation, narrative assignment q , f defined above.Example 4 Consider Hanks McDermotts (1987) Yale Shooting Problem (YSP) :three possible actions: load (the gun), wait, shoot (the victimgun). Normally, waiting cause change world, shooting leadsvictims death, provided that, course, gun loaded. Assume three actionsperformed, given order.define signature ysp tuple h{t, t1 , t2 , . . . , u, u1 , u2 , . . .}, {loaded, alive}, {load,wait, shoot}i. Yale Shooting problem formulated domain descriptionlanguage Lysp following theory: ysp,0 = {[0]alive, [0, 1]load, [1, 2]wait, [2, 3]shoot}.following two histories h1 h2 corresponding well-known modelsliterature reasoning action: h 1 intended model h2 anomalousmodel frameworks would produce.h1h2LLLL0123LLLL0123Figure 3: two histories YSP action description.oval Figure 3 represents state ysp . narrative assignment complyingaction description would map three tuples (0, load, 1), (1, wait, 2),(2, shoot, 3) true tuples false (relative assumption normally,given action time point, instance action time pointunless specified otherwise ).Definition 3.3 Let , = hh, , , q , f interpretation. Assume , E,f F, A, R {=, <}, l F , {, , , }, {true, false}. Definetruth value time point T, denoted I(, t) follows:481fiVo & FooI(, t) =I([, ]A, t) = (( ), A, ())I([ ]F Al , t) = f (( ), F Al )I(, t) = I(, t)I([ ], t) = I(, ( ))I(f, t) = h(t)(f )I([, ]AQ l , t) = q (( ), AQl , ())I( R, t) = ( )R()I( , t) = I(, t) I(, t)Two formulas equivalent iff I(, t) = I(, t) t. interpretationmodel set formulas, denoted |= , iff I(, t) = true every. formula entailed set formulas, denoted |= , ifftrue models .Definition 3.4 Let = hh, , , q , f interpretation.1. set OccI = {(t, A, u) | (t, A, u) = true} called action occurrencedenotation I.2. set F AI = {(t, F Al ) FAF | f (t, F Al ) = true} called F A-denotationI.3. set AQI = {(t, AQl , u) AQF | q (t, AQl , u) = true} called AQdenotation I.4. Representing Dynamic Domains Argumentation-TheoreticApproachproceed showing assumption-based framework representing dynamic domains. subsequently introduce uniform framework solving framequalification problems based argumentation-theoretic approach. General solutionsframe qualification problems obtained computing plausible setsassumptions guarantee extensions computed sets assumptionsconsistent given theory consistent. introduce additionalnotations: Given inference rule r R, denote prem(r) cons(r) premiseconsequence rule r, respectively.Definition4.1 deductive system hL , Ri well-defined iff subset R,set rS prem(r) consistent set CON S(S) = {cons(r) | r S} alsoconsistent.Henceforth, assume deductive systems well-defined. formalisedterms argumentation-theoretic approach, representation requires extendednotion consistency.Definition 4.2 Let hLD , Ri deductive system,(i) set sentences LD R-consistent iff 6`R false;(ii) assumption-based framework h, ABi respect hL , Ri consistent iffR-consistent.482fiReasoning Action: Argumentation-Theoretic ApproachRemark: Observe even hLD , Ri well-defined deductive system, consistencybequivalent R-consistency. instance, let R = { }, (logically) consistenttheory = {a, b} R-consistent.Example 4 (continued) Returning Yale Shooting problem, following inferencerules describe actions domain:[, ]load[]loaded [ ]F Aloaded(5)[, ]shoot, [ ]loaded[]alive [ ]F Aalive(6)[ ]loaded, [ ]F Aloaded[ + ]loaded(7)[ ]alive, [ ]F Aalive[ + ]alive(8)[ ]loaded, [ ]F Aloaded[ + ]loaded(9)[ ]alive, [ ]F Aalive[ + ]alive(10)Rules (5) (6) represent descriptions actions load shoot, respectively.Action wait cause effect world, need describe it.rules render common sense law inertia: time point, fluent literal presumablypersists next time point.argumentation-theoretic semantics, e.g. stability, admissibility, preferability, complete, well-founded semantics, etc. (Bondarenko et al., 1997) based notionattack. However, reason problem domains incomplete information, especiallyaction domains, notion alone may sufficient may always ableconstruct explicit arguments defeat unsound assumptions. example, considerYale Shooting Problem: observing turkey shot loaded gun time point1, reasoner infers plausibly turkey dead time point 2 using assumptionaction shoot qualified bring effect killing victim. However,time point 2, reasoner could observe turkey still alive. Existing solutionsframe problem, e.g. Reiters (1991), Thielschers (1997), Castilho et al.s (1999), etc.fail deal surprise since allow contradiction derived. Observereasoner explicit reason defeat qualification assumption,i.e. aware cause prevents application qualification assumption. knows acceptable case common sense. formalisephenomena, introduce notion rejected assumptions.483fiVo & FooDefinition 4.3 Given assumption-based framework h, ABi, set assumptionsAB rejects assumption AB iff(a) conflict-free,(b) {} attacks itself.instance, example 4, set assumptions 1 = {[0]F Aalive , [1]F Aalive , [1]F Aloaded }attacks assumption [2]F Aalive .10 Moreover, relative given action description,set assumptions attacks assumption [0]F loaded . hand, set assumptions 2 = {[0]F Aalive , [1]F Aalive , [2]F Aalive } rejects assumption [1]F Aloaded2 attack it.Observation 1 Given assumption-based framework h, ABi conflict-free setassumptions AB, attacks assumption/ rejects .Then, generalise contrariness notion assumptionwould general enough account rejected assumptions? reasonwant isolate set assumptions rejected attacked partsolution frame problem.Definition 4.4 Given assumption-based framework h, ABi, set assumptionsAB leniently rejects assumption AB iff(a) rejects ,(b) attack .defdenote Lr() = { AB | leniently rejected }.show solution provides intuitive account problems reasoningaction, several scenarios considered. include projection problem,basic form frame problem, whose typical example infamous YSP. Anotherscenario concerns explanation problem usually discussed StolenCar Problem (Kautz, 1986) Stanford Murder Mystery (Baker, 1989). firstprovide informal discussion approach examples.present solution, frame assumptions essence principle inertia,and role argumentation approach illustrated Yale ShootingProblem. formulation intentionally ignore qualification problem (it addressed next section) highlight frame problem solved. reconsider well-worn example YSP motivate approach frame problem.Example 4 (continued) Given theory ysp , argumentation-theoretic approachyield following preferred set assumptions (Bondarenko et al., 1997):{[t]F Al | l {loaded, alive, loaded, alive}} \ {[0]F loaded , [2]F Aalive },corresponds intended model scenario gun remains loadedtime point 2 victim alive time point 3.extension also stable extension well-founded semantics (Bondarenkoet al., 1997) given theory argumentation-theoretic approach. Note10. fact, set assumptions containing assumption [1]F Aloaded would attack [2]F Aalive .484fiReasoning Action: Argumentation-Theoretic Approachcase one would like uncertain whether gun still loaded shootingaction, one simply needs add axiom: [, ]shoot [ ]F loaded dictatepersistence fluent loaded action shooting guaranteed.case, still derive [ ]loaded = 1, 2, longer give definiteassertion [ ]loaded 3.formalisation YSP resembles using default logic, may surprising problem unintended models pointed Hanks McDermott(1987) circumscription, default logic, autoepistemic logic happen here.principal reason interaction inference rules notion attackargumentation-theoretic framework, invalidates undesired assumptions. Noticeeven [2]loaded (magically) derived, cannot lead [1]F loaded . Therefore,set assumptions corresponding case satisfy conditions preferredset assumptions, thus ruling unintended model. shows one importantfeatures assumption-based frameworks capability making explicit assumptions used reasoner course inference. Recall defaults justificationsaccepted long consistent extension credulous semanticsextensions skeptical semantics (thus name consistency-based approach.)light inertia principle, considered abnormal fluent persiststate next state. minimise abnormality, (normal) default rulesintroduced express fact consistent believe abnormalityrespect fluent f action situation assert that.would fail distinguish abnormalities brought reasonable causesunintuitively generated make consistent possible extension.latter course corresponding anomalous models. using explicit assumptions,consistency maintained (by preventing accepted assumptions attackingthemselves) rejection assumptions must also justified known factsgiven theory.Discussion:1. Turner (1997) showed alternative representation YSP default logichelp solve issue anomalous models introduced Hanks McDermotts(1987) representation. Turner formulates Yale Shooting scenario follows:Holds(Alive, S0 )False(11)TrueHolds(Loaded, Result(Load, s))(12)Holds(Loaded, s)Holds(Alive, Result(Shoot, s))(13): Holds(f, S0 )Holds(f, S0 )(14)485fiVo & Foo: Holds(f, S0 )Holds(f, S0 )(15)Holds(f, s) : Holds(f, Result(a, s))Holds(f, Result(a, s))(16)Holds(f, s) : Holds(f, Result(a, s))Holds(f, Result(a, s))(17)Notice Turner also uses inference rules block backward reasoninggenerates anomalous models Yale Shooting scenario. However, alsomeans kinds useful backward reasoning also blocked. words,Turners formulation fails deal surprising observations states latertime points. consequence, Turners formulation works domainrestricted qualification-free. soon action descriptions, e.g. oneshoot action YSP, need rely default justifications, e.g. qualificationassumptions, Turners formulation would also encounter problem undesirableextensions. approach offers solutions issues.2. Hanks McDermotts (1987) seminal paper early approachesframe problems exposed, besides new attempts solve frame problem,Sandewall (1994) accredited first tried approach problems reasoning action systematic way. part effort, alsoexamines reason behind failure early approaches frame problem.discussed Sandewall, early approaches reasoning action attemptingformulate inertia principle made common mistake making changesabnormality regarding principle failing distinguish normalchanges triggered actions anomalous changes. important insight turnsconsequence much general law reasoning dynamicdomains discovered researchers community pursuit solutions variousproblems reasoning actions: action dynamics causality-based.principle underpins solutions problems reasoning action.anomalous models arise early approaches frame problem discovered Hanks McDermott (1987) qualification problem discussedThielscher (2001) causes abnormalities present.hand, regarding ramification problem, given domain constraintinvolving number fluents, important know fluentscauses influencing fluents, i.e. causality direction involvedfluents.light analysis, Turners (1997) approach appears rather ad hoc.Note Turners solution problem anomalous models block backward reasoning use inference rules without motivation backwardreasoning bad thing. approach appears share solutions basedchronological ignorance (which discussed details Section 7)486fiReasoning Action: Argumentation-Theoretic Approachnotion directedness: minimizing chronologically blocking backward reasoning, one tends minimize causes rather effects. However, systematicapproach various problems reasoning action still much desired.Nevertheless, preferability semantics copes successfully YSP,properly account explanation problem, e.g. Stanford Murder Mystery (Baker,1989), Stolen Car Problem (Kautz, 1986). subtlety lies derivationcontrary frame assumptions. contrary frame assumption derivedoccurrence event brings change (absent StolenCar Problem) preconditions required satisfied change actually takeplace (absent Stanford Murder Mystery) explicitly derivable.notion (leniently) rejected assumptions called service.Definition 4.5 Given assumption-based framework F =h, ABi, set assumptionsAB presumable wrt F iff(a) = { AB | `R } (in terms given Bondarenko et al., 1997,closed),(b) attack itself,(c) assumption 6 , rejected .Definition 4.6 Given assumption-based framework F =h, ABi, set assumptionsAB plausible wrt F iff(a) presumable,(b) exists 0 AB 0 presumable Lr(0 ) Lr().proceed formalising action theories framework.Definition 4.7 Let = hT , F, Ai signature. Assume , E, A, ,l F . domain description (over ) tuple hL , R, AB, i, where:1. LD domain description language AB assumption base ;2. R = RC RF RA RQ ,(a) RC set inference rules (classical) propositional logic;[ ]l, [ ]F Al(b) RF set frame-based inference rules form:, i.e.[ + ]lrepresent frame axioms terms inference rules;, [, ], [, ]AQl,(c) RA set action descriptions inference rules form:[]l [ ]F Ali.e. represent conditions action bring l;(d) RQ set qualification-based inference rules form:, i.e.[, ]AQlrepresent qualifications regarding fluent literal l.3. theory .Given set assumptions , denote F = ABF AQ = ABAQ .Observation 2 Let = hLD , R, AB, domain description, set assumptions AB, either closed attacks itself.487fiVo & Foo5. Reasoning Action: Frame Qualification Problemsgeneral, adopt following guidelines seeking uniform solution problemsreasoning action:derived pieces information conflict given facts;Occurrences events minimised;inertia fluents maximised though minimality event occurrenceshigher priority.Aside trivial case occurrences actions causing frame assumptionsrejected, two aspects actions distinguished:1. action happens change supposed cause take place.call expectation failure less qualification problem;2. actions known happened caused change changetake place. call surprise usually known explanationproblem.following assumption represents underlying intuition behind reasoningaction formalisms.Assumption 1 Intuitive models contain minimal (with respect set inclusion) setssurprises.introduce model-theoretic counterpart notions assumption-basednotions presented above.Definition 5.1 Let = hT , F, Ai signature = hL , R, AB, domain description . interpretation = hh, , , q , f model iff1. model ;2. r R, |= prem(r) |= cons(r).following definition captures one several aspects (model-theoretic) solutionframe problem. aspect known action-oriented frame problem LinShohams (1995) terms. proposed minimisation policy formalises intuitionchange happen caused kind event. Thus, fluent,value changed two timepoints , (at least) occurrenceevent must end brings change.Definition 5.2 Let = hLD , R, AB, domain description model D.coherent model iff1. basic action A0 , E, |= [, ] |= [, ] ;488fiReasoning Action: Argumentation-Theoretic Approach2. l F T, |= [t]l [t+ ]l either(a) A0 r =|= prem(r)[1 /s, 2 /t+ ],11(b) |= [t, t+ ]dal, [1 , 2 ], [1 , 2 ]AQlR[2 ]l [1 ]F AlThus, coherent model: (i) satisfiable basic actions must follow giventheory, (ii) changes attributable events one kind another.Given interpretation I, want extract sets assumptions satisfiable I.Definition 5.3 Let = hT , F, Ai signature interpretation . setframe assumptions satisfiable I, denoted , defined follows:= {[t]F Al | (t, F Al ) F AI }set qualification assumptions satisfiable I, denoted IAQ , :IAQ = {[t1 , t2 ]AQl | (t1 , AQl , t2 ) AQI }also write IQF = IAQ .Conversely, given theory set assumptions , reasoner also constructmodels domain interest.Definition 5.4 Let = hLD , R, AB, domain description AB. model= hh, , , q , f -relativised iff1. AB, |= iff ;2. OccI = OAD DAS(), where:(a) OAD = {((1 ), , (2 )) A0 | |= [1 , 2 ]},(b) DAS() = {(t, dal , t+ ) DA | []FAl/ existaction, [1 , 2 ], [1 , 2 ]AQlR |=A0 r =[2 ]l [1 ]F Alprem(r)[1 /s, 2 /t+ ]}.-relativised models one central notions framework. Essentially, assumptions underpin machinery conjecture information based common sense knowledge. such, try accept many assumption possible unless goodreason to. Therefore, given set assumptions, attribute every missing frameassumption possible change domain agent reasoning causedeither known action/event unknown action, called dummy actionspaper.following observation immediate condition (1.) definition.Observation 3 Let domain description = hL , R, AB, set assumptionsAB given. model -relativised IQF = I(, t) every T.11. notation [v1 /t1 , . . . , vn /tn ] standard logic meant instantiation formulavariables v1 , . . . , vn replaced terms t1 , . . . , tn , respectively.489fiVo & Foo5.1 Frame ProblemFirst address frame problem simple setting viz. without qualificationassumptions, lift restrictions later.Definition 5.5 Let = hLD , R, AB, domain description. simple domaindescription, S-domain, iff RQ = AQ occur anywhere R .Definition 5.6 Let = hLD , R, AB, domain description. interpretation =hh, , , q , f simple model, S-model, iff1. model D;2. q (t, AQl , u) = true every (t, AQl , u) AQF T.effectively isolates frame problem qualification problem. Note alsoS-model IAQ = ABAQ . coherent S-model S-modelcoherent.Example 4 (continued.) following part one coherent models ysp :{[0, 1]load, [0]loaded, [1]loaded, [0]alive, [1]alive,[1, 2]wait, [1, 2]daloaded , [2]loaded, [2]alive,[2, 3]shoot, [3]loaded, [3]alive},corresponds one anomalous models scenario (the one pointedHanks McDermott).desirable admit occurrence event evidenceit. Thus need minimise set action occurrences given action theory.Definition 5.7 Let S-domain. coherent S-model prioritised minimalmodel (or simply PMM) iff exist coherent S-model 00OccI OccI .Note model-theoretic minimisation policy based frameassumptions. solution frame problem thus amenable well-known techniquescircumscription12 , believe argumentation-theoretic approachdirect also wider applicability. order provide connection(model-theoretic) minimisation policy (argumentation-theoretic) notionplausible sets assumptions need maximise set assumptions satisfiablePMM.Definition 5.8 Let S-domain. PMM canonical prioritised minimalmodel (or simply CPMM) iff exist PMM 00F AI F .want see account plausible sets assumptions connectsaccount minimality.12. combination introduction occurrences dummy actions.490fiReasoning Action: Argumentation-Theoretic ApproachLemma 1 Let = hLD , R, AB, S-domain. CPMMassumption AB:/ IQF iff rejected IQF .Proof. () Suppose way contradiction rejected IQF , IQF {}R-consistent, i.e. IQF {} 6`R false. Since S-domain, AB AQ IQF . Assume= [ ]F Al E l F , construct interpretation 00way 0 interprets everything except F F = F AI {(( ), F Al )}.Since PMM D, construction, 0 also PMM D.0F AI F AI . Contradiction.() Obvious.2Lemma 2 Let = hLD , R, AB, S-domain CPMM D.l F [t]F Al Lr(IQF ) |= [t, t+ ]dal .Proof. Let denote assumption [t]F l . First observe Lr(IQF ) implies6 IQF since rejected IQF IQF attack itself. turn implies|= {[t]l, [t+ ]l} denotation F required maximal sinceCPMM D. condition coherent, either (i) 0, [1 , 2 ], [1 , 2 ]AQlRr=[2 ]l [1 ]F Al|= prem(r)[1 /s, 2 /t+ ], (ii) |= [t, t+ ]dal . Condition (i) guaranteesattacked IQF thus member Lr(IQF ). Therefore, (ii) mustcase.2converse Lemma 2 hold. cases |= [t, + ]dalassumption [t]F Al attacked IQF basic action occurs changes fluentliteral l.Theorem 1 Let = hLD , R, AB, S-domain. CPMM IQFplausible.prove derive plausible set assumptions givenCPMM also construct CPMMs plausible set assumptions givenS-domain.set -relativised models S-domain denoted od (D).Observation 4 Let S-domain set assumptions D.odS (D), = IQF .Proof. construction -relativised models:odS (D), = [ ]F Al iff |= [ ]F Al iff . (More precisely,assumption [( )]F Al , valuation defined I.relative I, identical .)2Therefore, = IQF .491fiVo & FooTheorem 2 Let = hLD , R, AB, S-domain AB. plausible wrtiff odS (D) 6= odS (D), CPMM D.Theorem 3 Let = hLD , R, AB, S-domain. Furthermore, suppose CP (D)set CPMMsSof P laus(D) set plausible sets assumptions D,CP (D) = P laus(D) odS (D).5.1.1 Discussion:So, account frame problem relate existing approaches frameproblem? long line development behind monotonic approachesframe problem starting Haass (1987) Schuberts (1990) early attemptsresulting Reiters (1991) monotonic solution frame problem togethersolutions proposed others Castilho et al. (1999) Zhang Foo (2002)Thielschers (1999) Fluent Calculus-based monotonic solution frame problem,notable exception Thielschers (2001) attempt address qualification problem,tried tackle qualification within framework use address frameproblem.hand, action languages (Gelfond & Lifschitz, 1998) relatedapproaches proposed McCain Turner (1995, 1997), Giunchiglia, Kartha,Lifschitz (1997), Giunchiglia Lifschitz (1998), state transition systemsemployed underlying computation machinery essentially provides reasonerpossible complete states world. Furthermore, domain decsriptionsuniquely translated state transition systems, reasoner could safely derivesuccessor state(s) based current together transition function.5.2 Solving Qualification Problem (in Presence Frame Problem)results reported previous section established simple setting. addfollowing observation theory example 4: [3]alive, i.e. shoot action,victim still alive, like existing formalisms, account plausibilitywould come contradiction. fact, would reasonablefailure explained occurrence qualification. section, remove certainrestrictions qualifications actions order achieve general framework.subtleties way action theories represented proposedassumption-based framework. Note first potential difficulty frame assumptions qualification assumptions treated equally, illustrated versionYSP. Consider following action description:{[ ]alive, [ ]F Aalive [ ]loaded, [, ]shoot, [, ]AQalive,} R,[ + ]alive[]alive [ ]F Aalive{[0]loaded, [0]alive, [0, 1]shoot} .this, (at least) two stable sets assumptions: one contains frameassumption [0]F Aalive rejects qualification assumption [0, 1]AQ alive anothercontains [0, 1]AQalive attacks [0]F Aalive . latter intuitive caseexplicit criterion prefer one another. following assumption492fiReasoning Action: Argumentation-Theoretic Approachasserts solution frame problem presence qualification problem,action presumed bring effects unless explicit justificationdisqualification.Assumption 2 direct conflict frame assumption qualification assumption (over fluent literal), qualification assumption takes precedence.Given presence several kinds assumptions, i.e. frame qualification,adopt following convention: write Lr P () instead (Lr())P P{F A, AQ}. Since longer exclude qualification assumptions assumptionbased domain descriptions, simply refer assumption-based domain descriptionsQ-domains.Definition 5.9 Let = hLD , R, AB, Q-domain. presumable set assumptionsAB semi-Q-plausible wrt iff Lr F () minimal (with respect set inclusion).Definition 5.10 Let = hLD , R, AB, Q-domain. set assumptions ABQ-plausible wrt iff1. semi-Q-plausible wrt D,2. AQ maximal, i.e. exist 0 AB 0 semi-Qplausible (wrt D) AQ 0AQ ,3. F maximal relative two conditions, i.e. exist0 AB 0 satisfies two conditions F 0F .refer models Q-domain Q-models. coherent Q-model Qmodel coherent. minimise set action occurrences coherent Q-modelsgiven action theory.Definition 5.11 Let Q-domain. coherent Q-model prioritised minimalQ-model (or simply PMQM) iff exist coherent Q-model 00OccI OccI .Definition 5.12 Let S-domain. PMQM canonical prioritised minimalQ-model (or simply CPMQM) iff01. exist PMQM 0 AQI AQI ,02. exist PMM 0 F AI F AI .proceed obtaining main results CPMQMs regarding Q-plausiblesets assumptions similar CPMMs regarding plausible sets assumptions. following lemma, straightforward extension Lemma 1Lemma 2 proved previous section, introduced assist proof Theorem 4 .Lemma 3 Let = hLD , R, AB, Q-domain CPMM D,493fiVo & Foo1. assumption AB:/ IQF iff rejected IQF .2. = [ ]F Al Lr(IQF ) |= [, + ]dal .Theorem 4 Let Q-domain. CPMQM IQF Q-plausible wrtD.Similar previous section, prove derive plausible setassumptions given CPMQM also construct CPMQMs plausibleset assumptions given domain description. set -relativised modelsQ-domain denoted odQ(D).following observation obvious:Observation 5 Let Q-domain set assumptions D.odQ(D), = QF .Theorem 5 Let = hLD , R, AB, Q-domain AB. Q-plausible wrtQiff odQ(D) 6= od (D), CPMQM D.Theorem 6 Let Q-domain. Furthermore, suppose CP QM (D) setQCPMQMsP laus (D) Qthe set Q-plausible sets assumptions D,CP QM (D) = P lausQ (D) od (D).Q-plausible sets assumptions allow one overcome scenarios expectationfailures (or, qualification surprises) arise, e.g. shooting turkey loaded gunobserving turkey still alive. surprises arise, reasoner knowswhos blame: qualification assumptions. accordingly remove guiltyassumptions. anomalous models forming obstacle early approachesframe problem, similar anomalous models also arise solutions qualificationproblem. important issue related qualification problem thoroughlydiscussed Thielscher (2001) solution presented within frameworkFluent Calculus. give reader flavour problem within framework,invite reader consider following classical example:Example 5 Consider problem starting car whose tail pipe could possiblyblocked potato, formalised formalism follows.1. set inference rules R is:13[ ]BlockedT P,[, ]AQGetStarted[ ]HasP otato, [, ]InsertP otato, [, ]AQ BlockedT P,[]BlockedT P [ ]F ABlockedT P[ ]HasKey, [, ]T urnOnIgnition, [, ]AQ GetStarted.[]GetStarted [ ]F AGetStarted13. course also frame-based inference rules HasKey, BlockedT P , etc. omitrepresentation sake readability.494fiReasoning Action: Argumentation-Theoretic Approach2. theory is: {[0]HasP otato, [0]HasKey, [0]BlockedT P, [0]GetStarted,[0, 1]InsertP otato, [1, 2]T urnOnIgnition}.course, designed example try avoid possible troublesframe problem. consider two conflicting qualification assumptionscase [0, 1]AQBlockedT P [1, 2]AQGetStarted . Given action theory,Q-plausible set assumptions would contain exactly one them. Thus,least two extensions, one car get started since tailpipe blockedlonger consistent assume [1, 2]AQ GetStarted . extension disqualifiesaction inserting potato tailpipe thus action starting carbecomes successful. former intuitive case account Q-plausiblesets assumptions fails deliver desired solution.However, exactly way problem anomalous models arising solution frame problem tackled, problem easily addressed within framework. key insight course also underlined notion causality: [1]BlockT Pcaused (by action [0, 1]InsertP otato) turn allows [1, 2]AQ GetStartedderived. hand, cause allows [0, 1]AQ BlockT P derived.insight realised framework? answer turns rather simple: distinction leniently rejected frame assumptions non-lenientlyrejected frame assumptions allows us distinguish normal changes (i.e. actiontriggered) anomalous changes, distinction leniently rejected qualification assumptions non-leniently rejected qualification assumptions allow us distinguishnormal disqualifications (i.e. underlined cause) anomalous disqualifications. Thus, facing collection Q-plausible sets assumptions, reasoner simplyselects set assumptions contains smallest (with respect set inclusion) setleniently rejected qualification assumptions.ability introduce different argumentation-theoretic semantics assumptionbased frameworks arguably biggest advantage approach. following exampleillustrates critical point:Example 6 modify example presented Lin Shoham (1995) turnmodification Kautzs (1986) Stolen Car Problem. spy possessed microfilm topsecret evidence organisation, A, tried steal. reason, another organisation, B, wanted murder spy. microfilm safe spys hometime 0. spy home time 0. tried steal evidencetime points 0 1. spy might return home time 0 1. B triedmurder spy time 0 1. return cancels effects steal, murdercancels effects return steal cancels effects murder. threeactions steal, return, murder takes one time step. domain formalisedfollows: = {[0]EvStolen, [0]Alive, [0]AtHome}; R contains{[, ]return, [, ]AQAtHome [, ]murder, [, ]AQAlive[, ]steal, [, ]AQEvStolen,,,[]EvStolen [ ]F AEvStolen []AtHome [ ]F AAtHome []Alive [ ]F AAlive[ ]AtHome < [ ]Alive < [ ]EvStolen <,,}.[, ]AQEvStolen[, ]AQAtHome[, ]AQAlive495fiVo & FooGiven formalisation problem, traditional accounts non-monotonicreasoning (i.e. Default Logic, circumscription, Autoepistemic Logic, etc.) provideone solution since formalisms produce extension standard semantics. However, argumentation-theoretic approach gives several semantics problem including preferability semantics. Note, however, admissiblesets assumptions preferred sets assumptions domain contain noneassumptions: [0, 1]AQEvStolen , [0, 1]AQAtHome , [0, 1]AQAlive . essentially meansthat, admissibility preferability semantics, reasoner could infernone actions would succeed hand, proposed plausiblesemantics gives alternative solution problem consistent set assumptions contain one following three assumptions: [0, 1]AQ EvStolen ,[0, 1]AQAtHome , [0, 1]AQAlive . Moreover, plausible set assumptions must contain exactly one them. Among two assumptions belongplausible set assumptions, one attacked leniently rejected.believe examples underlined major advantages approach reasoner aware (defeasible) assumptions used reasoningwell able explicitly reason assumptions. flexibility allowingreasoner introduce different argumentation-theoretic semantics assumption-basedframework simply varying notion acceptability sets assumptions certainlyanother advantage favour approach.6. Complex Dynamic Domains Indirect Effectsfar havent taken consideration issues concurrent actions indirecteffects. ensure formalisation introduced expressive enough dealcomplex domains, show issues coped approach. Firstly,motivate formalisation informal discussion.6.1 Concurrent Non-Deterministic EventsGiven temporal representation, formulating concurrent events difficult issueframework. However, subtleties need carefully considered.Firstly, use assumptions. presented earlier paper, qualification assumptionsfluent oriented, i.e. qualify effects action rather action itself.Whilst manifests capability formulating actions multiple effects, thuseffect qualified independently, may fail formalise concurrent eventseffects. example, actions hit vase hammer shootloaded gun bring effect vase broken. words,essential qualification assumptions dependent actions bringeffect consideration. Thus, given n actions fluents whose valueschanged actions, potentially introduce 2 n qualificationsassumptions.14 Therefore, instead subscripting assumption symbols AQfluent literals F , extend set subscripts AQ, denoted AF, contain14. fact, see later, potentially 2 (n + 1) qualification assumptions casesince one special event corresponding (natural) events bring indirect effects.496fiReasoning Action: Argumentation-Theoretic Approachaction corresponding fluent literals. 15 example, given twoactions hit shoot additional action repair whose effect change broken vasenon-broken, viz. broken, need introduce following qualificationassumptions: AQHit-Broken , AQShoot-Broken AQRepair-Broken . Therefore, syntacticallyalso extend set AB AQ = {[, ]AQ | , E AF} semanticallyfunction q : AQAF {true, false}. definition interpretation= hh, , , q , f i, also I([, ]AQ , t) = q (( ), AQ , ()), , EAF.Though increase complexity framework, pricepay expressiveness resulting system. best knowledge, noneexisting formalisms possesses expressiveness.non-deterministic actions? solution turns quite simple:treat action non-determinism special kind action qualification. example, formulate Russian shooting scenario (Sandewall, 1994) gun non-deterministicallygets loaded spinning revolver, following action descriptions asserted:[, ]spin, [, ]AQSpin-Loaded[, ]spin, [, ]AQSpin-Loadedadr1 =adr2 =[]loaded [ ]F Aloaded[]loaded [ ]F Aloadedtogether following two qualification rules:qr1 =[]loaded[]loadedqr2 =.[, ]AQSpin-Loaded[, ]AQSpin-Loadedguarantee either []loaded []loaded follow [, ]spin (remark set qualification assumptions AQ maximised), both.consequence, two possible extensions arise given non-deterministic action.Dealing non-determinism could complicated information usedencode action description disjunctive. restrict conclusion actiondescription rule contain fluent literals, disjunctive effect straightforwardlydealt framework. However, note restriction similar imposedaction language (Gelfond & Lifschitz, 1998). extension action descriptionssimilar way action language extended action languageC done allow complex expression conclusion action description rule.However, sake presentation, choose use simpler language introduceframework reader.6.2 Formalisationanalysis introductory section regarding indirect effects, observeordering domain constraints applied plays essential role technicallysound framework. Moreover, longer guaranteed domain constraints wouldstrictly satisfied every time point. 16 help reader better understand technicalsubtlety, useful think changes attributable events. However, events15. reader referred section 3 general formalisation.16. course, necessary state world every time point observable reasoner.However, important aware states able reason them.497fiVo & Foodivided two categories: external internal. Basically, external eventscorrespond direct effects actions performed agents (including reasoner.)hand, internal events correspond indirect effects certain conditionsworld met attributed Nature. 17Like external events, internal events also happen certain order. Althoughstraightforward observe order 18 , important reasoner able reasonthem. Hence propose add one dimension set assumptionsgiven domain description. Since assumptions play essentially rolequalification assumptions, 19 subsume set qualificationassumptions AQAF . associated specific action, ignoreinitial action name subscripts AQ. example write AQ brokencase want qualify fluent broken indirect effect, i.e. independentlyaction. Moreover, avoid axiomatiser confusion determining timespan taken indirect effects, assume atomic. means indirect effectsalways take place one time point next one. meanindirect effects real-time duration, simply means relative giventime structure take place two consecutive time points. allows usavoid granularity problem irrelevant viewpoint problemstrying solve.6.2.1 Representation Issue Notations:One important remark place here. now, used integers corresponding expressions denote time points. two reasons pratice: (i)significantly simplifies presentation, (ii) Without complication ramification problem, time points reasoned also observable reasoner.However, discussed thoroughly next section, presence ramificationstime point change takes place maight observable reasonerchange could one indirect effects execution action.representation issues make integer-based time structure employed far paperinappropriate. need richer representation time structure. Following Sandewalls(1994) basic formulation, basic constant included representationtime structure denoted symbol referred origin T.standard algebraic operations + still employed obtain time expressionsbear usual meanings. relation symbol < also used compare timeexpressions. However, longer allow expressions + 1 integerslonger elements time structure.Given time expression :17. avoid use terms exogenous/endogenous events label two categoriesthroughout literature reasoning action, exogenous events used refer actionscarried agents different reasoner outside events whose occurrences beyondreasoners control.18. Unless indirect effects somehow delayed become observable reasoner, usually takeplace immediately direct effects.19. difference assumptions qualified indirect effects consideredeffects actions Nature.498fiReasoning Action: Argumentation-Theoretic Approachcontinue denote next time point + .define 1+ + and, let n > 1, n+ ( (n1)+ )+ .Furthermore, assume throughout indirect effect takes placetwo consecutive time points, also simplify presentation using following syntactical sugar: instead writing [, + ]AQl (for E l F ), write[ ]AQl . also provides simple way distinguish qualification assumptionsramificational effects caused directly action event.domain descriptions affected augmentation? changeset RA action descriptions consists rules either form, [, ], [, ]AQ- l[]l [ ]F Alform, [ ]AQl.[ ]F Al[ + ]lconvenience, refer set inference rules latter form R ,, [ ]AQlfluent literal l F }. Now, regardingi.e. RI = {r RA | r = +[ ]l [ ]F Alramification problem, basic idea state obtained updating previousstate may necessarily stable due presence indirect effects. representingindirect effects causal rules (using inference rules framework) reasoncausal rules fired (relatively) when. Moreover, since causal rulesmay take amount time fire, able reason differentpossible orders fire. achieved distinction stableunstable states.Definition 6.1 time-point expression E stable wrt given domain description= hLD , R, AB, AB iff exist fluent literal l F1., [ ]AQlRI `R , []AQl ,[ + ]l [ ]F Al2. 6`R []l.Definition 6.2 Let = hLD , R, AB, domain description. set assumptionssaid ramification-compliant iff1. exist AB AQ hR ( {}) 6= hR () {}.2. exist unstable time-point expression E [ ]F levery l F .note using unstable time points, conceptually isolated ramification problem task reasoning (explicit) actions.499fiVo & FooDefinition 6.3 Let = hLD , R, AB, domain description. set assumptionsgenerally plausible action domains, simply AD-plausible, ifframification-compliant,Q-plausible relative condition.Remarks:1. definition, seen solution ramification (insense) independent frame qualification problems regarding actionoccurrences.2. Given temporal ontology, worth noting traditional notionstate constraints may longer hold representation regarding time points.precisely, states associated stable time points subjectconstraints.6.3 Connection Causation-Based Formalismsquestion is, course, whether computational mechanism gives satisfactoryconclusions problems reasoning action. many formalismsproposed, general criterion reasoning action formalisms still seems missing.major stream research towards solution ramification problem basednotion causality (e.g., Lin, 1995; McCain & Turner, 1995; Thielscher, 1997).discussed above, none approaches deal domains (potentially)infinite sequences indirect effects present. approaches (includingthree references), however, produce successor state execution actioncapture changes taken place either direct indirect effects action.sub-section, show formalism captures notion successor statesabsence infinite sequences indirect effects.Definition 6.4 domain description = hL , R, AB, non-stratified iff existtwo sets {l1 , . . . , ln } F1. 1 n, {[ ]li } R-consistent, every E;2. 1 n, k = (i mod n) + 1, exists set k{[ ]li } `R k ,k , [ ]AQlkRI .[ + ]lk [ ]F Alkcourse, domain description stratified non-stratified. Givendefdomain description = hLD , R, AB, i, well denote ED () = hR ( ), extensionaction theory according . also write E instead ED () brevity.Definition 6.5 Let = hT , F, Ai signature.500fiReasoning Action: Argumentation-Theoretic Approach1. set F instantwise state iff every l F , either l l S.used denote set instantwise states ,defdef2. Let F E , denote = {l | l } [ ] = {[ ]l | l },3. Let = hLD , R, AB, domain description. simplistic iff = .motivation behind introduction instantwise states allow reasonerreason intermediate states may practically observable her.is, indirect effects (following occurrence action event) take place,world might transit number intermediate states becoming stabilised final state domain constraints necessarily hold. abilityexplicitly reason (unstable) intermediate states one advantages offered approach. instance, lets consider scenario Example 1originally introduced Thielscher (1997). Thielschers (1997) approach allows twopossible successor states results closing switch sw 1 initial state ={sw1 , sw2 , sw3 , relay, light, detect}. 1 = {sw1 , sw2 , sw3 , relay, light, detect}T2 = {sw1 , sw2 , sw3 , relay, light, detect}. However, outside observeridea tricky internal mechanism circuit, could quite difficultexplain T2 one possible outcomes action closing switchsw1 : starting initial state detect light off, performingaction toggle(sw1 ), light remains somehow detect becomes on. words,Thielschers (1997) framework fails render intermediate (and unstable) statelight on, albeit short instant, turned again.hand, states explicitly represented reasoned instantwise statesframework. consequence, domain constraints necessarily hold instantwisestate.following, abbreviate simplistic stratified domain descriptions SSDs.Let RI , denote:defCON SR () = {l F |[ ], [ ]AQl}.[ + ]l [ ]F AlSimilarly, let RA , denotedefCON SA () = {l F |[1 ], [1 , 2 ], [1 , 2 ]AQ-l}.[2 ]l [1 ]F Al[1 ], [1 , 2 ], [1 , 2 ]AQ-lRA applicable iff S.[2 ]l [1 ]F Aluse denote set action descriptions applicable (in S) regardingaction . possible application iff CON () consistentexist 0 0 CON SA (0 ) consistent.action descriptionDefinition 6.6 Let = hT , F, Ai signature = hL , R, AB, SSD. SupposeA. formalise direct effects action using relation Res :S, 0 IS, (S, , 0 ) ResD iff possible application that:501fiVo & Foo(i) CON SA () 0 ,(ii) exist instantwise state 00 00 satisfies (i) 00 \0 \ S.Definition 6.7 Let = hT , F, Ai signature = hL , R, AB, SSD.causation relation according D, denoted Causes , defined follows: S, 0IS, CausesD (S, 0 ) iff exists non-empty set R ramification inference rules(i)[ ], [ ]AQl,[ ]F Al[ + ]l(ii) CON SR () 0 ,(iii) exist instantwise state 00 00 satisfies (i) (ii)00 \ 0 \ S.Given domain description D, state stable regarding iffexist 0 CausesD (S, 0 ).Definition 6.8 Let = hT , F, Ai signature SSD. Suppose w A.state transition w according , denoted rans (w), transitive closure CausesD regarding state 1 satisfying (w, , 1 ) ResD . Formally,ransD (w) = {$ | exists sequence 1 , . . . , n (w, , 1 )ResD $ = n (i , i+1 ) CausesD 1 < n $ stable regarding D}.Let interpretation LD T,defuse [I]t denote instantwise state specified time point t: [I] = {lF | I(l, t) = true}. [I]t stable said stable time point I.use NI denote function maps time point next stable timepoint I: NI (t) [I]NI (t) stable every u T, < u < N (t)[I]u stable.Theorem 7 Let = hT , F, Ai signature 0 = hLD , R, AB, SSD A0 .Suppose w IS. Define domain description = hL , R, AB, i, = {[] |w}{[, + ]}. set AB assumptions AD-plausible wrt iff modelED (), [M ]NM () ransD ([M ] ), i.e. [M ]NM () belongs state transition[M ] according .re-consider motivating examples introduced Section 1.3.Example 1 (continued.) re-formulate action theory example termsformalism:502fiReasoning Action: Argumentation-Theoretic Approach[ ]sw1 , [ ]sw3 , [ ]AQrelay,[ + ]relay [ ]F Arelay[ ]swi , [ ]AQrelay(i = 1, 3),[ + ]relay [ ]F Arelay[ ]light, [ ]AQdetect,+[ ]detect [ ]F Adetect[ ]sw1 , [ ]sw2 , [ ]AQlight,[ + ]light [ ]F Alight[ ]swi , [ ]AQlight(i = 1, 2),[ + ]light [ ]F Alight[ ]relay, [ ]AQsw2,[ + ]sw2 [ ]F Asw2[ ]swi , [, ]togglei(i = 1, 2, 3),[]swi [ ]F Aswi[ ], [ ]F, F .[ + ][ ]swi , [, ]togglei(i = 1, 2, 3),[]swi [ ]F Aswitheory described follows:= {[]sw1 , []sw2 , []sw3 , []relay, []light, []detect} {[, N ()]toggle 1 }.Consider AQ = ABAQ \{[2+ ]AQdetect , [3+ ]AQdetect } F = ABF \+2+3+light , [ ]F Arelay , [ ]F Asw2 , [ ]F Alight }. AD-plausible resultingnext stable state = {sw1 , sw2 , sw3 , relay, light, detect} [4+ ].{[+ ]Faddition, set 0 AB, 0AQ = ABAQ \ {[2+ ]AQdetect } 0F =ABF \ {[+ ]F Alight , [+ ]F Arelay , [2+ ]F Asw2 , [3+ ]F Alight , [3+ ]F Adetect }, alsoAD-plausible results next stable state 0 = {sw1 , sw2 , sw3 , relay, light, detect}[4+ ].Moreover, set 00 AB, 00AQ = ABAQ 00F = ABF \{[N ()]F Alight ,[+ ]F Arelay , [2+ ]F Asw2 , [2+ ]F Adetect , [3+ ]F Alight }, also AD-plausible alsoresults next stable state 0 [4+ ]. words, model implied 0 reflectsdomain takes amount time detect switchsw2 jump off. hand, model implied 00 reflects domainamount time detect (approximately) equal amount timeswitch sw2 jump cause light well. detect impliedinsensitive even though light relay time ( 2+ ),relay causes switch sw2 jump leads light welldetect yet on.Example 2 (continued.) re-formulate action theory example termsformalism:503fiVo & Foo[ ]upL1 , [ ]upL2 , [ ]AQopen,[ + ]open [ ]F Aopen[, ]f lipi , [ ]upLi(i = 1, 2),[]upLi [ ]F AupLi[1 , 2 ]hold closed, [1 ]open, 1 2,[ ]held closed [ ]F Aheld closed[ ], [ ]F, F .[ + ][, ]f lipi , [ ]upLi(i = 1, 2),[]upLi [ ]F AupLi[, ]close, [ ]upL1 , [ ]upL2,[]open [ ]F Aopen[ ]held closed,[ ]AQopentheory described follows:= {[]upL1 , []upL2 , []open, []held closed}{[c1 , c2 ]close, [c2 , c3 ]hold closed, [c4 , c5 ]f lip1 }{ c1 < c2 c4 < c5 c3 }.Consider AB AQ = ABAQ \ {[c]AQopen | c2 c c3 } F =ABF \ ({[c1 ]F Aopen } {[c]F Aheld closed | c2 c c3 } {[c4 ]F AupL1 }). AD-plausibleresulting following:[c1 ]{upL1 , upL2 , open, held closed},[c2 ]{upL1 , upL2 , open, held closed},[c4 ]{upL1 , upL2 , open, held closed},[c5 ]{upL1 , upL2 , open, held closed},[c3 ]{upL1 , upL2 , open, held closed}.Example 3 (continued.) domain description:[ ]sw1 , [ ]sw2 , [ ]AQrelay1,[ + ]relay1 [ ]F Arelay1[ ]relay1 , [ ]AQsw2,[ + ]sw2 [ ]F Asw2[ ]swi , [, ]togglei(i = 1, 2),[]swi [ ]F Aswi[ ], [ ]F, F .[ + ][ ]sw1 , [ ]sw2 , [ ]AQrelay2,[ + ]relay2 [ ]F Arelay2[ ]relay2 , [ ]AQsw2,[ + ]sw2 [ ]F Asw2[ ]swi , [, ]togglei(i = 1, 2),[]swi [ ]F Aswistate circuit Figure 2 captured following action theory:= {[]sw1 , []sw2 , []relay1 , []relay2 }{[c1 , c2 ]toggle1 , [c3 , c4 ]toggle1 } { c1 <c2 < c 3 < c 4 }Consider AB AQ = ABAQ F = AB F \ ({[c1 ]F Asw1 }{[c3 ]F Asw1 } {[c]F Arelay1 | c2 c c3 c = (c2 )k+ k = 4i = 0, 1, 2, . . .}{[c]F Asw2 , [c]F Arelay1 | c2 c c3 c = (c2 )k+ k = 4i + 1 = 0, 1, 2, . . .}{[c]F Arelay2 | c2 c c3 c = (c2 )k+ k = 4i + 2 = 0, 1, 2, . . .}{[c]F Asw2 , [c]F Arelay2 | c2 c c3 c = (c2 )k+ k = 4i + 3 = 0, 1, 2, . . .}).AD-plausible resulting several possible models domain dependingswitch sw1 toggled off:[c1 ]{sw1 , sw2 , relay1 , relay2 },504fiReasoning Action: Argumentation-Theoretic Approach[c2 ]{sw1 , sw2 , relay1 , relay2 },[c3 ]{sw1 , sw2 , relay1 , relay2 },[c4 ]{sw1 , sw2 , relay1 , relay2 }.Remark:20Here, also important raise question whether solution ramificationproblem conflicts formulation concurrent actions. two actions 1 2concurrently performed: 1 causes indirect effect E 2 triggers non-terminatingchains effects. direct indirect effects caused 2 dont interfere 1production E reasoner reason time points execution 1E holds indirect effect 1 . time points course unstabledue non-terminating chains indirect effects caused 2 . hand,direct indirect effects caused 2 potential prevent formerproducing E, reasoning could complex. observable directeffects actions take place time concurrent occurrences twoactions viewed one single occurrence one complex actions whose direct effectscombination direct effects two actions. reasoning ramificationscarried usual. hand, reasoner unsuretemporal correlation direct effects two actions, every possibleorder changes must taken consideration leading highly nondeterministicoutcome fluent hold future time points. However, situationstill handled nicely formalisation. representation issueaddressed framework indirect effects duration. asserted above,given state world time point , assume subsequent indirecteffects take place next time point + . certainly fails deal properlyindirect effects whose durations different. simple solution problemassociate one next time point operator possible indirect effect. This, however,significantly complicate representation.7. Discussion Future Workdeveloped uniform framework reasoning action using argumentationtheoretic approach (more precisely, assumption-based approach). also presentedframework copes frame, qualification ramification problemsseveral sophisticated settings. shown framework naturally extendedbecome expressive.also explored new abstraction level believe intermediate layercommon sense knowledge scientific knowledge. Sophisticated domainknowledge well representation are, argue, required achieve adequate underlying representation reasoning process. Among merits approach, emphasisefollowing:Non-monotonicity handled assumptions argumentation-theoretic approach.20. authors would like acknowledge anonymous referee pointing subtle issue.505fiVo & Fooflexibility working different kinds information representation sincerestriction syntax system.Expressivity: temporal information explicitly represented. Thus system capable capturing many important features temporal reasoning.reviewed introductory section paper, numerous approaches reasoningaction proposed. such, much research related approachesframeworks evolved around central problems addressed paper, namelyframe, qualification ramification problems. However, non-monotonic reasoningbased formalisms reasoning actions shown flawed Hanks McDermott (1987), many existing solutions frame problem based approachesusually monotonic. Since one inherent properties argumentationtheoretic approach monotonicity, attempted solve problems reasoningactions using approach.framework reasoning actions argumentation-theoretic approachindependently proposed Kakas, Miller, Toni (1999, 2000, 2001). approach,admissibility semantics also employed resolve conflicts adversary arguments. represent common sense knowledge, e.g. common sense law inertia,order imposed set inference rules assumption-based framework. computation arguments competing performed top so-called prooftrees. Nodes proof trees arguments sets propositions. 21 Construction proof trees level hardness known frameworks argumentationtheoretic computation. framework allows persistence (inertial) fluentscaptured dealt with, clear whether formalisation extendeddeal problems reasoning actions qualificationramification problems.recently, Dimopoulos, Kakas, Michael (2004), Bracciali Kakas (2004)extended Kakas et al.s framework deal ramification qualification problems. Essentially, solution ramification problem, so-called r-propositionsfollowing form:22L whenever Cadded domain description. resulting model given domain descriptioncomputed first computing possible indirect effects fixed point repeated application r-propositions, completing model allowing unaffectedfluent literals persist time. clear representation indirect effects quite restrictive doesnt allow complex expressions conditionsindirect effects indirect effects themselves. restriction essentially dueuse Answer Set Programming (ASP) underlying computation mechanismframework. hand, solution qualification problem liesuse default rules representing effects actions. approach fairly similar21. Kakas et al.s (1999, 2000) terminologies, node set arguments equivalentnotion arguments exposition.22. L fluent literal C set fluent literals essentially equivalent conjunctionfluent literals.506fiReasoning Action: Argumentation-Theoretic ApproachThielschers (2001) solution qualification problem discussed above. approachessentially based stability semantics, clear argumentation-theoreticapproach bring benefit framework.discussed earlier paper, key insight behind solutions implementedframework exploitation causality drive inference. causalityhelped throughout solutions frame qualification problems providemechanisms eliminate anomalous models retaining intuitive modelsprocess reasoning. insight certainly general version conclusions derived Sandewall (1994) investigating reason behind productionanomalous models early approaches frame problem, namely failure distinguish normal changes triggered actions abnomalous changes.Sandewalls insight certainly originated occlusion-based solution frame problem (Sandewall, 1994; Doherty, 1994; Gustafsson & Doherty, 1996). Roughly speaking,approach action type associated subset fluents influencedaction. Also, predicate Occlude introduced allow subset fluentsspecified. reasoning dynamic domains, changes minimisedexception fluents specified Occlude. words, Occlude distinguishesnormal changes (associated action types) anomalous changes thusavoids unintended models arising.Regarding qualification problem, Thielschers (2001) solution problemanomalous models relation qualification problem shares key insight causalityapproach. However, Thielschers framework based standard semanticsDefault Logic (with initial theories generated using circumscription). Thus,approach deal problem domains standard semantics Default Logicproduce extension. Furthermore, discussed introductory sectionpaper, Thielschers framework qualifications taken executability conditionsactions instead different effects actions.parallel causality-based insight dynamic domains, mechanismssolving various problems reasoning action exist. instance, number approaches employ concept chronological ignorance (Shoham, 1987, 1988) tackleproblem anomalous models. general, causality-based frameworks approachesbased chronological ignorance share notion directedness: changes minimised chronologically, causes minimised instead effects causes likely precedeeffects. However, consequence, backward reasoning blocked prevents chronological ignorance-based approaches dealing surprises expectation failures.Furthermore, non-deterministic actions incomplete state knowledge known causedifficulty chronological minimization. detailed comparison causalitybased approaches counterparts based chronological ignorance,reader referred article Thielscher (2001). hand, approachesbased Motivated Action Theory (MAT) (Amsterdam, 1991; Stein & Morgenstern,1994) considered special case causality-based paradigm. MAT frameworks also advocate insight appropriate notion causality necessaryassuming away abnormalities. MAT frameworks, however, dont cope wellexplanation problem ramification problem pointed Jr. (1999) alsointroduce approach improve MAT overcome problems.507fiVo & FooNonetheless, several issues still remain within framework need treatment achieve optimal solution. Firstly, formalism may suitablelarge-scale problems many assumptions need taken account.address problem, localisation procedure invented guarantee adequate sub-language used capture circumstance agent reasoning about.consequence, set assumptions restricted necessaryinfer conclusions agent interested. idea development. Furthermore,uniform solution major problems reasoning action may quiteattractive especially regarding toy scenarios considered paperwell literature, solution may pragmatic. considering localityaccount reasoning, particular assumptions used default reasoning, promisingsolution achieved computational representational points view.undertaking investigation towards research direction.major limitation framework ability deal disjunctive axiomatisation action occurrences. instance, domain axiomatisation constainsdisjunction action occurrences [t 1 , t2 ]1 [t1 , t2 ]2 , plausible setsassumptions, accordingly, CPMMs (resp. CPMQMs) produced accounteffects actions. initial formalisation framework allowedcomplex expressions action occurrences premises inference rules overcame problem, formalisation appeared complex technicalresults could established. investigation, therefore, needed overcomeproblem avoiding produce overly complex formalisation.Provided formalism designed provide general framework reasoning action, following comes natural question: extent proposedapproach used formalise dynamic domains? Sandewall (1994) suggests onesystematise framework reasoning action standard criteriaprovide formal indications expressiveness capacity formalism.contrast traditional approach prevailed many yearsreasoning action one tries come examples showexisting approaches able deal scenario claims ones approachbetter others solve proposed scenario.Relative Sandewalls standard criteria, approach enjoys following properties:1. approach non-inertia allows observations later state correct systems predictions states using explanation mechanismuse assumptions.2. formalism able deal non-deterministic concurrent events.Another issue abduction problem also known literatureexplanation problem. example, Stolen car scenario, observing cardisappeared parking lot reasoner left it, expectation failure arises.formalisms would try accommodate problem introducing stealing actionpart vocabulary try bind disappearance car action.arguably intuitive good reason include actionvocabulary first place others car towed away508fiReasoning Action: Argumentation-Theoretic Approachpolice fairy turning car pumpkin, etc. pragmatic point view,reasoners may simply acquire information (perhaps police) insteadconfusing kinds explanations towards possible uncertain causes.words, effectively isolate issues deducing new conclusionsexisting knowledge base abducing possible causes observations.course closely related Shanahans approach IJCAI95 paper (Shanahan, 1989)whose title clearly indicated Prediction Deduction Explanation Abduction.also working assumption-based framework solve abduction problem.Acknowledgementswork performed first author School Computer ScienceEngineering, University New South Wales. authors wish thank membersKnowledge Systems Group, paricular Dongmo Zhang Maurice Pagnucco,anonymous reviewers earlier version paper helpful commentssuggestions significantly improve quality well readabilitypaper. first author partially supported International Postgraduate ResearchScholarship (IPRS) sponsored Australian government. first author presentlysupported DEST IAP grant (2004-2006, grant CG040014).AppendixTheorem 1 Let = hLD , R, AB, S-domain. CPMM IQFplausible.Proof: Suppose CPMM D,(i) prove IQF presumable:IQF R-consistent since model D. Observation 2, IQFclosed attack itself. Lemma 1, assumption AB,/ IQFrejected IQF .(ii) prove Lr(IQF ) minimal:Suppose way contradiction exists presumable set assumptions(wrt D) Lr() Lr(IQF ). Let -relativised model D. obviouscoherent. derive contradiction proving Occ OccI :(ii.1) OAD OccI : obvious OAD = {((1 ), , (2 )) A0 | |= [1 , 2 ]},model D.(ii.2) DAS() OccI : Let (t, dal , t+ ) DAS(), exist actionA0r=, [1 , 2 ], [1 , 2 ]AQlR[2 ]l [1 ]F Al|= prem(r)[1 /s, 2 /t+ ]}. Thus, assumption = [t]F Al Lr(). Thus,Lr(IQF ) (from hypothesis.) Lemma 2, |= [t, + ]dal . Thus (t, dal , t+ ) OccI .(ii.3) OccI 6 OccI : Let = [t]F Al Lr(IQF ) \ Lr() l F .Since CPMM D, Lemma 2, |= [t, + ]dal . Thus (t, dal , t+ ) OccI .509fiVo & FooMoreover,/ Lr() iff either (a) , (b) 0, [1 , 2 ], [1 , 2 ]AQlR `R [1 /t, 2 /t+ ], [t, t+ ], [t, t+ ]AQlr=[2 ]l [1 ]F Aliff, following construction -relativised models, 6|= [t, t+ ]dal . Thus (t, dal , t+ )/OccI . Therefore, OccI OccI .Hence, Lr(IQF ) minimal IQF plausible.2Theorem 2 Let = hLD , R, AB, S-domain AB. plausible wrtiff odS (D) 6= odS (D), CPMM D.Proof:() Suppose AB plausible wrt D. R-consistent, i.e. 6` Rfalse. construction -relativised models, od (D) 6= .= hh, , , q , f odS (D), prove CPMM D.(i) coherent S-model D: obvious definition -relativised models.(ii) OccI minimal:Assume contrary, i.e. non-empty set = {J | J coherent S-modelOccJ OccI }. Let H MI exist model JF AH F AJ .Consider set assumptions HQF :H(ii.a) QF presumable wrt D:HQF closed attack (since H model D);Let AB, = [ ]F Al 6 HQF (for E l F ) isnt rejectedHQF easily construct model J interprets everything except FH F AJ = F AH {(( ), F Al )}. Obviously, J MI F AJ F AHcontradiction. Thus rejected HQF .Therefore, HQF presumable.H(ii.b) Lr(QF ) Lr():OccH OccI since H MI .HLet Lr(HQF ). Since AB AQ QF , = [t]F Al AB Fl F . definition leniently rejected assumptions, HQF 6`R falseHQF {} `R false. then, definition coherent models, H |= [t, + ]dal(since H coherent model D). Thus, |= [t, + ]dal .construction -relativised models, [t]F l 6 . Thus, rejected(since plausible wrt D). Also construction -relativised models, 6` R. Therefore, Lr(), Lr(HQF ) Lr(). Now, Occ = OAD DAS(). OADOccH since H model D. Thus, OccI \ OccH = DAS() \ OccH . Let (t, dal , t+ )DAS() \ OccH . construction -relativised models, = [t]F l Lr().HSuppose Lr(H/ HQF ). Then,QF (as QF presumable).construct model J way J interprets everything except F H.510fiReasoning Action: Argumentation-Theoretic Approachdefinition coherent models, (t, da l , t+ )/ OccH iff either (1) H 6|= [t]l [t+ ]l;(2) A0 ,r=, [1 , 2 ], [1 , 2 ]AQlR[2 ]l [1 ]F Al|= prem(r)[1 /t, 2 /t+ ], i.e., |= [1 /t, 2 /t+ ], [t, t+ ], [t, t+ ]AQl . Since= [t]F Al Lr(), condition (2) satisfied.Thus, (t, dal , t+ )/ OccH iff H 6|= [t]l [t+ ]l. words, consistent addassumption [t]F Al set assumptions HQF . Or, model-theoretic pointview, augment denotation F H (t, F l ) still obtain coherentS-model J F AH F AJ . contradiction. Hence,/ Lr( HQF ).Hshown Lr(QF ) Lr().(ii.a) (ii.b) led conclusion Occ minimal. consequence, CPMM (from (i) (ii)).() Suppose odS (D) 6= odS (D), CPMM D.prove plausible wrt D. Take arbitrary model od (D). FollowingObservation 4, = IQF . Theorem 1 hypothesis CPMM D,conclude plausible wrt D.2Theorem 3 Let = hLD , R, AB, S-domain. Furthermore, suppose CP (D)set CPMMsSof P laus(D) set plausible sets assumptions D,CP (D) = P laus(D) odS (D).Proof:()odS (D) CP (D) (Following Theorem 2). ThereS Let P laus(D),fore, P laus(D) od (D) CP (D).() Let CP (D), IQF P laus(D) (Following Theorem 1).prove odI (D) based Definition 5.4:QF1) S-model D,2) = [ ]F Al ABF (for E l F ), IQF iff (( ), F Al )F AI (Following definition IQF - Definition 5.3)3) prove OccI = OAD DAS(IQF ):(3.)OAD = {((1 ), , (2 )) A0 | |= [1 , 2 ]} OccI (as model D),(t, dal , t+ ) DAS(IQF ).Definition 5.4,(i) = [t]F Al/ IQF ,(ii) exists action A0 that:r=, [1 , 2 ], [1 , 2 ]AQlR[2 ]l [1 ]F Al511fiVo & Foo|= [1 /t, 2 /t+ ], [t, t+ ], [t, t+ ]AQl .Lemma 1,/ IQF iff rejected IQF iff coherent modeleither (a) A0r=, [1 , 2 ], [1 , 2 ]AQlR[2 ]l [1 ]F Al|= prem(r)[1 /s, 2 /t+ ],(b) |= [t, t+ ]dal .Since (a) violates condition (ii) above, (b) must case. Thus (t, da l , t+ ) OccI .DAS(IQF ) OccI .OccI OAD DAS(IQF ).(3.) Suppose OccI 6 OAD DAS(IQF ). (3.), OccI OADDAS(IQF ). Since IQF plausible, exists model J od SI (D) JQFCPMM D. Following Definition 5.4, Occ J = OAD DAS(IQF ) propersubset OccI . Contradiction! Therefore, OccI OAD DAS(IQF ).Thus shown odSI (D),QFP laus(D) odS (D) (Since IQF P laus(D))CP (D) P laus(D) odS (D).2Therefore, CP (D) = P laus(D) odS (D).Theorem 4 Let Q-domain. CPMQM IQF Q-plausible wrtD.Proof:Suppose CPMQM D,(i) easy verify IQF semiQ-plausible wrt D: similar proof theorem1, using Lemma 3 instead Lemma 1 Lemma 2.(ii) IAQ maximal:Assume contrary, i.e. exists set assumptions semiQplausible wrt IAQ AQ . Since presumable, R-consistent. Let-relativised model D. Obviously, coherent Q-model D. easy verifyOccI minimal otherwise coherent Q-model J (of D) constructedOccJ OccI . OccI = OAD DAS() OAD OccJ since Jmodel D. Thus exists (t, da , t+ ) DAS() \ OccJ . JQF presumablewrt Lr(JQF ) Lr() contradiction. Thus, Occ minimal.model PMQM AQI AQI contradicts factCPMQM D. Therefore, IAQ maximal.(iii) maximal (relative (i) (ii)):Assume contrary, i.e. exists set assumptions semiQplausible wrt AQ maximal F . Let -relativised model512fiReasoning Action: Argumentation-Theoretic ApproachD. Similar proof part (ii), easily verify PMQM D.fact AQ maximal F contradicts given hypothesisCPMQM D, conclude maximal. Therefore, IQF Q-plausible wrt D. 2Theorem 5 Let = hLD , R, AB, Q-domain AB. Q-plausible wrtQiff odQ(D) 6= od (D), CPMQM D.Proof:() Suppose Q-plausible wrt D.presumable, R-consistent. Following construction -relativisedmodels, odQ(D) 6= .Let odQ(D):(i) easy verify coherent construction -relativised models.(ii) OccI minimal:Assume contrary, i.e. set = { | coherent Q-model OccOccI } non-empty.Let J following conditions satisfied:1. exist model Occ OccJ .2. AQJ maximal relative 1.3. F AJ maximal relative 1. 2.Consider set assumptions JQF : Obviously, JQF closed attachitself. AB,/ JQF rejected JQF , otherwise would violatemaximality JAQ JF . Thus, JQF presumable.Remark OccJ OccI . Besides, OccI = OAD DAS(). OAD OccJJ model D. Thus exists (t, da , t+ ) DAS() \ OccJ . JQFpresumable wrt Lr(JQF ) Lr() contradiction. Thus, Occ minimal.consequence, PMQM D.(iii) AQI maximal (relative (i) (ii)):Assume contrary, i.e. set = { | PMQM AQI AQ }non-empty.Let J following conditions satisfied:1. F AJ maximal;2. AQJ maximal relative 1.prove JQF semi-Q-plausible (i.e. presumable wrt Lr F (JQF )minimal):JQF presumable wrt easy verify.also easy verify LrF (JQF ) minimal J coherent OccJ minimal.would guarantee set occurrences dummy actions J minimisedconsequence set leniently rejected frame assumptions also minimised. Formally,presumable set assumptions Lr F () LrF (JQF ) relativised model coherent Q-model OccI OccJ , contradictionfact J thus J PMQM D.Thus, JQF semi-Q-plausible wrt D. But, AQ JAQ contradiction.Therefore, shown AQI maximal (relative (i) (ii)).513fiVo & Foo(iv) Now, prove F AI maximal (relative (i), (ii) (iii)):Assume contrary, i.e. exists PMQM J F F AJ .Among models satisfying condition, choose model K0exist PMQM K 0 F AK F AK . Thus, K CPMQMD.Following Theorem 4, set assumptions KQF Q-plausible FKKF since F F . Contradiction hypothesis Q-plausible.(i), (ii), (iii) (iv) led conclusion canonical prioritisedminimal Q-model D.() Suppose odQ(D) 6= canonical prioritised minimal modelQod (D), prove plausible.Take arbitrary model odQ(D). Following Observation 5, = QF .Theorem 4 hypothesis canonical prioritised minimal Q-model D,conclude Q-plausible.2Theorem 6 Let Q-domain. Furthermore, suppose CP QM (D) setQCPMQMsP laus (D) Qthe set Q-plausible sets assumptions D,CP QM (D) = P lausQ (D) od (D).Proof: Similar proof Theorem 3.2Theorem 7 Let = hT , F, Ai signature 0 = hLD , R, AB, SSD A0 .Suppose w IS. Define domain description = hL , R, AB, i, = {[] |w}{[, + ]}. set AB assumptions AD-plausible wrt iff modelED (), [M ]NM () ransD ([M ] ), i.e. [M ]NM () belongs state transition[M ] according .Proof:() Suppose AB AD-plausible wrt D, prove modelED (), [M ]NM () ransD ([M ] ).Let od(ED ()), |= , |= [] iff w. Thus w = [M ] .prove [M ]NM () ransD (w), i.e. exists sequence 1 , . . . , n(w, , 1 ) ResD [M ]NM () = n (i , i+1 ) CausesD 1 < n.w= : reasoners knowledge, applicable instantwise state wdue either non-executability w, bring effects concerned++reasoner. Thus, [M ] = w. course, (w, , [M ] ) ResD .w6= : let = {r RA | |= prem(r) |= cons(r)}, provepossible application w.0Apparently, w. maximal since otherwise construct model0 satisfies qualification assumption additional action description rule.0means 0 PMQM model AQM AQM . Thus CPMQMD. Following Theorem 5, Q-plausible wrt D. Contradiction.prove exists instantwise state CON ()+[M ] \ w \ w.514fiReasoning Action: Argumentation-Theoretic ApproachAssume contrary, i.e. exists fluent literal F (S \ w) \+([M ] \ w).6|= []F since model D.Construct model 0 way 0 interprets everything except00F A, F = F {(, F )}. Obviously, 0 PMQM AQM = AQM ,0F F . Thus CPMQM D. Following Theorem 5,+Q-plausible wrt D. Contradiction. Therefore, (w, , [M ] ) ResD .() Suppose model E (), [M ]NM () ransD ([M ] ), proveAB AD-plausible wrt obvious.2ReferencesAmsterdam, J. B. (1991). Temporal reasoning narrative conventions. Allen, J. F.,Fikes, R., & Sandewall, E. (Eds.), KR91: Principles Knowledge RepresentationReasoning, pp. 1521, Cambridge, MA. Morgan Kaufmann.Baker, A. B. (1989). simple solution Yale Shooting problem. Brachman, R. J.,Levesque, H. J., & Reiter, R. (Eds.), KR89: Principles Knowledge RepresentationReasoning, pp. 1120, San Mateo, California. Morgan Kaufmann.Baral, C. (1995). Reasoning actions: Non-deterministic effects, constraints, qualification. International Joint Conference Artificial Intelligence.Bondarenko, A., Dung, P. M., Kowalski, R. A., & Toni, F. (1997). abstract,argumentation-theoretic approach default reasoning. Artificial Intelligence Journal,93, 63101.Bracciali, A., & Kakas, A. C. (2004). Frame consistency: computing causal explanations. 10th International Workshop Non-Monotonic Reasoning (NMR 2004),pp. 7987.Castilho, M. A., Gasquet, O., & Herzig, A. (1999). Formalizing action change modallogic I: frame problem. Journal Logic Computation, 9(5), 701735.Dimopoulos, Y., Kakas, A. C., & Michael, L. (2004). Reasoning actions changeanswer set programming. International Conference Logic ProgrammingNonmonotonic Reasoning - LPNMR 04, pp. 6173.Doherty, P. (1994). Reasoning action change using occlusion. EuropeanConference Artificial Intelligence, pp. 401405.Doherty, P., & Kvarnstrom, J. (1998). Tackling qualification problem using fluent dependency constraints: Preliminary report. 5th Workshop Temporal RepresentationReasoning - TIME, pp. 97104.Doyle, J. (1979). truth maintenance system. Artificial Intelligence Journal, 12(3), 231272.Drakengren, T., & Bjareland, M. (1999). Reasoning action polynomial time.Artificial Intelligence Journal, 115, 124.Fikes, R., & Nilsson, N. J. (1971). STRIPS: new approach application theoremproving problem solving. Artificial Intelligence Journal, 2(3/4), 189208.515fiVo & FooFoo, N. Y., Zhang, D., Vo, Q. B., & Peppas, P. (2001). Circumscriptive models automata. Thielscher, M., & Williams, M.-A. (Eds.), Workshop Non-monotonicReasoning, Action Change - colocated IJCAI-01.Gelfond, M., & Lifschitz, V. (1998). Action languages. Electronic Transactions AI,3(16), 193210.Ginsberg, M. L., & Smith, D. E. (1988). Reasoning action I: possible worldsapproach. Artificial Intelligence Journal, 35(2), 165196.Giunchiglia, E., Kartha, G. N., & Lifschitz, V. (1997). Representing action: Indeterminacyramifications. Artificial Intelligence Journal, 95(2), 409438.Giunchiglia, E., & Lifschitz, V. (1998). action language based causal explanation:Preliminary report. National Conference Artificial Intelligence, pp. 623630.Green, C. (1969). Application theorem proving problem solving. International JointConference Artificial Intelligence, pp. 219240.Gustafsson, J., & Doherty, P. (1996). Embracing occlusion specifying indirect effectsactions. Principles Knowledge Representation Reasoning, pp. 8798.Haas, A. R. (1987). case domain-specific frame axioms. frame problemartificial intelligence: proc. 1987 workshop. Morgan Kaufmann.Hanks, S., & McDermott, D. (1987). Nonmonotonic logic temporal projection. ArtificialIntelligence Journal, 33(3), 379412.Jr., C. L. O. (1999). Explanatory update theory: Applications counterfactual reasoningcausation. Artificial Intelligence Journal, 108(1-2), 125178.Kakas, A. C., Miller, R., & Toni, F. (1999). argumentation framework reasoningactions change. International Conference Logic ProgrammingNonmonotonic Reasoning - LPNMR 99, pp. 7891.Kakas, A. C., Miller, R., & Toni, F. (2000). E-res - system reasoning actions, events observations. Baral, C., & Truszczynski, M. (Eds.), InternationalWorkshop Non-Monotonic Reasoning, Special Session System DescriptionsDemonstration - NMR2000.Kakas, A. C., Miller, R., & Toni, F. (2001). E-res: Reasoning actions, eventsobservations. International Conference Logic Programming NonmonotonicReasoning - LPNMR 01, pp. 254266.Kautz, H. (1986). logic persistence. National Conference Artificial Intelligence.Kowalski, R., & Sergot, M. J. (1986). logic-based calculus events. New GenerationComputing, 4, 6795.Kowalski, R. (1992). Database updates event calculus. Journal Logic Programming,12, 121146.Kushmerick, N. (1996). Cognitivism situated action: two views intelligent agency.Computers Artificial Intelligence, 15(5).Lifschitz, V. (1987). semantics STRIPS. Georgeff, & Lansky (Eds.), ReasoningActions Plans. Morgan Kauffman, Los Altos.516fiReasoning Action: Argumentation-Theoretic ApproachLin, F. (1995). Embracing causality specifying indirect effects actions. International Joint Conference Artificial Intelligence.Lin, F. (1996). Embracing causality specifying indeterminate effects actions.National Conference Artificial Intelligence, pp. 670676.Lin, F., & Reiter, R. (1994). State constraints revisited. Journal Logic Computation,4(5), 655678.Lin, F., & Shoham, Y. (1995). Provably correct theories action. Journal ACM,42(2), 293320.McCain, N., & Turner, H. (1995). causal theory ramifications qualifications.International Joint Conference Artificial Intelligence.McCain, N., & Turner, H. (1997). Causal theories action change. NationalConference Artificial Intelligence, pp. 460465.McCarthy, J. (1977). Epistemological problems artificial intelligence. InternationalJoint Conference Artificial Intelligence, pp. 555562.McCarthy, J. (1980). Circumscription - form non-monotonic reasoning. ArtificialIntelligence Journal, 13(1-2), 2739.McCarthy, J. (1986). Applications circumscription formalizing common sense knowledge. Artificial Intelligence Journal, 26(3), 89116.McCarthy, J., & Hayes, P. (1969). philosophical problems standpointartificial intelligence. Michie, D., & Meltzer, B. (Eds.), Machine Intelligence 4.Edinburgh University Press.McDermott, D. V. (1987). Weve framed: ai innocent frame problem. Pylyshyn, Z. (Ed.), Robots Dilemma: Frame Problem ArtificialIntelligence, pp. 113122. Ablex.McDermott, D. V., & Doyle, J. (1980). Non-monotonic logic I. Artificial IntelligenceJournal, 13(1-2), 4172.Moore, R. C. (1985). Semantical considerations nonmonotonic logic. Artificial Intelligence Journal, 25(1), 7594.Morris, P. H. (1988). anomalous extension problem default reasoning. ArtificialIntelligence Journal, 35(3), 383399.Pednault, E. (1989). ADL: Exploring middle ground STRIPS situation calculus. KR89: First International Conference Principles KnowledgeRepresentation Reasoning, pp. 324332. Morgan Kaufmann.Poole, D. (1988). logical framework default reasoning. Artificial Intelligence Journal,36(1), 2747.Reiter, R. (1980). logic default reasoning. Artificial Intelligence Journal, 13, 81132.Reiter, R. (1991). frame problem situation calculus: simple solution (sometimes) completeness result goal regression. Lifschitz, V. (Ed.), AIMathematical Theory Computation: Papers Honor John McCarthy, pp. 418420. Academic Press.517fiVo & FooSandewall, E. (1994). Features Fluents. Oxford University Press, Oxford.Schubert, L. (1990). Monotonic solution frame problem situation calculus;efficient method worlds fully specified actions. Kyburg, H., Loui, R., &Carlson, G. (Eds.), Knowledge Representation Defeasible Reasoning, pp. 2367.Kluwer Academic Publishers, Dordrecht.Shanahan, M. (1989). Prediction deduction explanation abduction. InternationalJoint Conference Artificial Intelligence, pp. 10551060.Shanahan, M. (1997). Solving Frame Problem: Mathematical InvestigationCommon Sense Law Inertia. MIT Press, Cambridge, Massachussets.Shanahan, M. (1999). ramification problem event calculus. InternationalJoint Conference Artificial Intelligence, pp. 140146.Shoham, Y. (1987). Reasoning Change. MIT Press, Cambridge, MA.Shoham, Y. (1988). Chronological ignorance: Experiments nonmonotonic temporal reasoning. Artificial Intelligence Journal, 36, 279331.Stein, L. A., & Morgenstern, L. (1994). Motivated action theory: formal theory causalreasoning. Artificial Intelligence Journal, 71(1), 142.Thielscher, M. (1997). Ramification causality. Artificial Intelligence Journal, 89, 317364.Thielscher, M. (1999). situation calculus fluent calculus: State update axiomssolution inferential frame problem. Artificial Intelligence Journal, 111(1-2),277299.Thielscher, M. (2001). qualification problem: solution problem anomalousmodels. Artificial Intelligence Journal, 131(1-2), 137.Turner, H. (1997). Representing actions logic programs default theories: situationcalculus approach. Journal Logic Programming, 31(1-3), 245298.Vo, Q. B., & Foo, N. Y. (2001). Solving qualification problem. Australian JointConference Artificial Intelligence, pp. 519531.Vo, Q. B., & Foo, N. Y. (2002). Solving ramification problem: Causal propagationargumentation-theoretic approach. 7th Pacific Rim International ConferenceArtificial Intelligence - PRICAI2002, pp. 4959.Zhang, D., & Foo, N. Y. (2002). Interpolation properties action logic: Lazy-formalizationframe problem. Flesca, S., Greco, S., Leone, N., & Ianni, G. (Eds.), LogicsArtificial Intelligence, European Conference, JELIA 2002, pp. 357368.518fiJournal Artificial Intelligence Research 24 (2005) 1-48Submitted 11/04; published 07/05CIXL2: Crossover Operator Evolutionary AlgorithmsBased Population FeaturesDomingo Ortiz-BoyerCesar Hervas-MartnezNicolas Garca-Pedrajasdortiz@uco.eschervas@uco.esnpedrajas@uco.esDepartment Computing Numerical AnalysisUniversity Cordoba, SpainAbstractpaper propose crossover operator evolutionary algorithms realvalues based statistical theory population distributions. operatorbased theoretical distribution values genes best individualspopulation. proposed operator takes account localization dispersionfeatures best individuals population objective featureswould inherited offspring. aim optimization balanceexploration exploitation search process.order test efficiency robustness crossover, used setfunctions optimized regard different criteria, as, multimodality, separability, regularity epistasis. set functions extract conclusionsfunction problem hand. analyze results using ANOVA multiplecomparison statistical tests.example crossover used solve artificial intelligence problems,applied proposed model problem obtaining weight networkensemble neural networks. results obtained performancestandard methods.1. IntroductionEvolutionary algorithms (EAs) general purpose searching methods. selection process crossover mutation operators establish balance explorationexploitation search space adequate wide variety problemswhose solution presents difficulties insolvable using classical methods.problems defined continuous domains, evolutionary algorithms applieduse real values, namely, evolution strategies (EPs), real-coded genetic algorithms (RCGAs),evolutionary programming (EP). paradigms precision solutiondepend coding system, binary coded genetic algorithms, precisioncomputer system algorithms run.selection process drives searching towards regions best individuals.mutation operator randomly modifies, given probability, one geneschromosome, thus increasing structural diversity population. see,clearly exploration operator, helps recover genetic diversity lostselection phase explore new solutions avoiding premature convergence. way,probability reaching given point search space never zero. operator,c2005AI Access Foundation. rights reserved.fiOrtiz-Boyer, Hervas-Martnez, & Garca-PedrajasExploration222Exploita1tionH ,12ExplorationExploitation,1121ai(a)12Exploration21bi(b)Figure 1: (a) Hypercube defined first two genes parents; (b) Representationsegment defined ith genes two chromosomes.fact, implements random search whose well-studied features useful fieldevolutionary computation.crossover operator combines genes two parents generate betteroffspring. based idea exchange information good chromosomes generate even better offspring. effect crossover operatorstudied two different points view: chromosome level gene level. effectcrossover operator chromosome level considered geometric way. Giventwo parents 1 = {11 , 21 } 2 = {12 , 22 } two genes, denote H 1 2hypercube defined genes (Figure 1a). gene level representation wouldlinear, defining case segment interval 1 , 2 pair genes (Figure 1b).crossover operators generate individuals exploitation zones, 1 , 2 H 1 2 .way, crossover operator implements depth search exploitation, leavingbreadth search exploration mutation operator.policy, intuitively natural, makes population converge values withinhypercubes defined parents, producing rapid decrease populationdiversity could end premature convergence non-optimal solution. Recentstudies BLX- crossover (Eshelman & Schaffer, 1993), crossover based fuzzyconnectives (Herrera, Herrera-Viedma, Lozano, & Verdegay, 1994), fuzzy recombination(Voigt, Muhlenbein, & Cvetkovic, 1995), confirmed good performancecrossover operators also generate individuals exploration zone. operatorsavoid loss diversity premature convergence inner points searchspace, also generation new individuals exploration zone could slowsearch process. reason, crossover operator establish adequate balanceexploration (or interpolation) exploitation (or extrapolation), generateoffspring exploration exploitation zones correct proportion.Establishing balance exploration exploitation important, alsoimportant balance self-adaptive (Kita, 2001; Beyer & Deb, 2001; Deb &Beyer, 2001), is, must guarantee dispersion offspring depends2fiCIXL2: Crossover Operator Evolutionary Algorithmsdispersion parents. So, two close parents must generate close offspring, twodistant parents must generate distant offspring. control dispersion crossoverbased fuzzy connectives based generation offspring using fuzzy connectives t-norms, t-conorms, average functions, generalized operator compensation(Mizumoto, 1989). fuzzy recombination offspring generated using two triangulardistributions whose averages derive genes two parents. BLX-probability generating offspring parents, areaclose parents whose amplitude modulated parameter.Ono Kobayashi (1997) proposed Unimodal Normally Distributed Crossover(UNDX), three parents used generate two children. childrenobtained using ellipsoidal distribution one axis segment joins twoparents extent orthogonal direction decided perpendicular distancethird parent axis. authors claim operator preservestatistics population. crossover also self-adaptive, differs BLX-fact probable generate offspring near average first twoparents.Another self-adaptive crossover Simulated Binary Crossover (SBX) (Deb & Agrawal,1995). Based search features single-point crossover used binary-coded genetic algorithms, operator respects interval schemata processing, sensecommon interval schemata parents preserved offspring. SBX crossoverputs stress generating offspring near parents. So, crossover guaranteesextent children proportional extent parents, also favorsnear parent individuals monotonically likely chosen childrenindividuals distant parents.main goal paper propose crossover operator avoids lossdiversity population individuals, and, time, favors speedconvergence algorithm. two goals are, first, conflicting; adequatebalance controlled two basic features crossover operator: i) balanceexploration exploitation and, ii) self-adaptive component. twofeatures make evolutionary algorithms avoid premature convergence favor localfine-tuning. attributes highly appreciated search algorithm.current crossover operators, features offspring depend featuresparents. crossovers take account population featureslocalization dispersion individuals. use statistical featurespopulation may help convergence population towards global optimum.crossover operator implements basically depth exploitative search, likemethods steepest gradient descent, local search simulated annealing,three search methods algorithm takes quality solutions account.So, reasonable think also convenient crossover operator considerperformance individuals involved crossover operation. idea alreadyimplemented heuristic crossovers (Wright, 1991).Nevertheless, following previous line argument, seems rather poor usetwo parents, consider promising directions towards wouldadvisable drive search. is, instead using local heuristic uses two3fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajasindividuals, involving whole population adequate subset determinationdirection search whose features would specially suitable.Motivated line argument, paper propose crossover operator,called Confidence Interval Based Crossover using L2 Norm (CIXL2). onehand, takes advantage selective component derived extractionfeatures best n individuals population indicates directionsearch, hand, makes self-adaptive sampling around featureswhose width depends number best individuals, dispersion best individuals,confidence coefficient, localization individuals participate crossover.Now, exploitation region area two parents involvedcrossover, area defined confidence interval built n bestindividuals population; exploratory region rest search domain.previous concepts exploration exploitation, merely geometrical, addedprobabilistic component depends population features best individuals.Estimation Distribution Algorithms (EDAs) Probabilistic Model-Building Evolutionary Algorithms (Muhlenbein & Paa, 1998; Muhlenbein, Mahnig, & Rodriguez, 1999)based a, seemingly, similar idea. algorithms mutation crossoveroperators. every generation population distribution selected individualsestimated new individuals obtained sampling estimated distribution. However, underlying idea behind crossover extraction population features, meanstandard deviation, order detect regions higher probabilitygetting best individuals. order perform crossover, create three virtualparents represent localization estimator mean, bounds confidenceinterval which, certain confidence degree, localization estimator takesvalues. way, children generated three parents inherit featuresbest individuals population.rest paper organized follows: Section 2 explains definition CIXL2features; Section 3 discusses problem selection test sets,justifies use test set based one proposed Eiben Back (1997a); Section4 describes experimental setup evolutionary algorithm (RCGA) used tests;Section 5 studies optimal values parameters CIXL2; Section 6 comparesperformance CIXL2 crossovers; Section 7 compares CIXL2 EDAs;Section 8 describes application RCGAs CIXL2 neural network ensembles;and, finally, Section 9 states conclusions paper future research lines.2. CIXL2 Operatorsection explain theoretical base supports defined crossoveroperator, define crossover. use example explaindynamics population subject crossover operator.2.1 Theoretical Foundationsection study distribution i-th gene constructionconfidence interval localization parameter associated distribution.4fiCIXL2: Crossover Operator Evolutionary AlgorithmsLet set N individuals p genes make populationset best n individuals. assume genes individualsbelonging independent random variables continuous distribution H(i )localization parameter , define model= + ei ,= 1, ..., p,(1)ei random variable. suppose that, gene i, best n individuals form, , ..., } distribution , model takes formrandom sample {i,1i,2i,nij= + eij ,= 1, ..., p j = 1, ..., n.(2)Using model, analyze estimator localization parameter i-thgene based minimization dispersion function induced L2 norm. L2norm definednX(eij )2 ,(3)kei k22 =j=1hence associated dispersion induced L2 norm model 2D2 (i ) =nXj=1(ij)2 ,(4)estimator localization parameter is:= arg min D2 ( ) = arg minnXj=1(ij)2 .(5)Using minimization steepest gradient descent method,S2 (i ) =obtainS2 (i ) = 2D2 (i ),nXj=1(ij),(6)(7)making (7) equal 0 yields=Pnj=1 ijn= .(8)So, estimator localization parameter i-th gene based minimization dispersion function induced L2 norm mean distribution(Kendall & Stuart, 1977), is, = .5fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajassample mean estimator linear estimator1 , properties unbiasedness2 consistency3 , follows normal distribution N (i , 2 /n)distribution genes H(i ) normal. hypothesis, construct bilateralconfidence interval localization genes best n individuals, usingstudentization method, mean localization parameter,and standard deviationSi dispersion parameter:SiSiCI(9)= tn1,/2 ; + tn1,/2nntn1,/2 value Students distribution n 1 degrees freedom,1 confidence coefficient, is, probability interval contains truevalue population mean.2.2 CIXL2 Definitiondefinition confidence interval, define three intervals create three virtual parents, formed lower limits confidence interval gene, CILL 4 ,upper limits, CIU L5 , means CIM 6 . parents statistical informationlocalization features dispersion best individuals population, is,genetic information fittest individuals share. definition is:CILL = (CILL1 , . . . , CILLi , . . . CILLp )(10)CIU L = (CIU L1 , . . . , CIU Li , . . . CIU Lp )CIM= (CIM1 , . . . , CIMi , . . . CIMp ),CILLi = tn1,/2nCIU Li = + tn1,/2nCIMi = .(11)CILL CIU L individuals divide domain gene three subintervals:Di IiL IiCI IiU , IiL [ai , CILLi ); IiCI [CILLi , CIU Li ]; IiU (CIU Li , bi ];ai bi bounds domain (see Figure 2).crossover operator creates one offspring , individual populationf , randomly selected, one individuals CILL, CIU L CIM , dependinglocalization f , follows:1. linear combination sample values.2. estimator unbiased estimator expected value estimator parameterestimate: E[] = .3. consistent estimator estimator converges probability quantity estimatedsample size grows.4. Confidence Interval Lower Limit.5. Confidence Interval Upper Limit.6. Confidence Interval Mean.6fiCIXL2: Crossover Operator Evolutionary AlgorithmsDiaiCILIiCC MiUfIiC U LibiFigure 2: example confidence interval based crossoverIiL : fitness f higher CILL, = r(if CILLi ) + , else= r(CILLi ) + CILLi .IiCI : fitness f higher CIM, = r(if CIMi ) + , else= r(CIMi ) + CIMi .IiU : fitness f higher CIUL, = r(if CIU Li ) + , else= r(CIU Li ) + CIU Li (this case seen Figure 2).r random number interval [0, 1].definition, offspring always takes values direction besttwo parents never them. virtual individual one boundsconfidence interval better parent, offspring generateddirection confidence interval likely generate better individuals.virtual individual worse parent, offspring generated nearparent opposite direction confidence interval. hand,parent selected population within confidence interval, offspringoutside interval always neighborhood fitness centerconfidence interval worse. formulation tries avoid shifting populationtowards confidence interval, unless shifting means real improvement fitnesspopulation.f distant parent, offspring probably undergo markedchange, parents close, change small. first circumstancelikely occur first stages evolutionary process, second onefinal stages.width interval CI depends confidence coefficient, 1 , numberbest individuals, n, dispersion best individuals. first stagesevolution, dispersion large, specially multimodal functions, decreasetogether convergence genetic algorithm. features allow balanceexploitation exploration adjust dynamically. crossoverexploratory beginning evolution, avoiding premature convergence,exploitative end, allowing fine tuning. parameters n 1 regulatedynamics balance favoring higher lower degree exploitation. suggestsCIXL2 establishes self-adaptive equilibrium exploration exploitation basedfeatures share, certain confidence degree 1 , best n individuals7fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas25Best individuals distributionPopulation distributionPopulation distribution crossoverCIPpopulationDCI best individualspopulation crossoverIndividualsIndividuals proyected axis x1x2Best individualsBest individuals proyected axis x1x2CIPf(x)20Individuals number40000151021.51-250.5-1.5-1-0.5x10-0.500.511.5-1-1.52x2I2LI2CII2U-20(a)-2-1CILL20x2CIM2CIUL212(b)Figure 3: Effect CIXL2 crossover population used minimizationRosenbrock function two variablespopulation. preliminary theoretical study aspect carried HervasMartnez Ortiz-Boyer (2005).2.3 Crossover DynamicsFigure 3 shows simulation behavior crossover optimization Rosenbrock function (Eiben & Back, 1997b) two variables. Figure 3a, observeindividuals within domain CIP ; best n within confidence domain CI I1CI I2CI . DCI shifted towards minimum function placed(1, 1), domain CIP new population, generated applying CIXL2,shifted optimum. displacement higher first stages evolution,decrease evolution. may modulated parameters n 1 .Figure 3a shows population, applying crossover operator, distributedregion nearer optimum whose diversity depends parameters operator.Figure 3b shows whole population n best individuals distributed.see, distribution best n individuals keeps features distributionpopulation, shifted optimum. shifting towards optimummarked value n small. tails distribution best individualslarger dispersion best individuals also large, smallerconcentrated narrow region. size tails also depends featuresproblem, stage evolution, particular gene considered. effectcrossover distribution population shift distribution towards bestn individuals stretch distribution modulately depending amplitudeconfidence interval. parameters n 1 responsible displacementstretching region new individuals generated.n small, population move promising individuals quickly.may convenient increasing convergence speed unimodal functions. Nevertheless,produce premature convergence suboptimal values multimodal functions.n large, shifting speed convergence smaller. However,8fiCIXL2: Crossover Operator Evolutionary Algorithmsevolutionary process robust, feature perfectly adequateoptimization multimodal, non-separable, highly epistatic functions.parameter n responsible selectiveness crossover, determinesregion search directed. selection regulated parameter1 . parameter bounds error margin crossover operator order obtainsearch direction feature shares best individuals population.3. Benchmark Problemsfield evolutionary computation, common compare different algorithms usinglarge test set, especially test involves function optimization (Gordon & Whitley,1993). However, effectiveness algorithm another algorithm cannotmeasured number problems solves better. free lunch theorem(Wolpert & Macready, 1995) shows that, compare two searching algorithmspossible functions, performance two algorithms , average,. result, attempting design perfect test set functions presentorder determine whether algorithm better another every function,fruitless task.reason why, algorithm evaluated, must look kindproblems performance good, order characterize type problemsalgorithm suitable. way, made previous studyfunctions optimized constructing test set fewer functions betterselection (Whitley, Mathias, Rana, & Dzubera, 1995; Salomon, 1996). allows usobtain conclusions performance algorithm depending type function.Taking account reasoning, test set designed Eiben Back (1997b)adequate. test set several well characterized functions allow usobtain generalize, far possible, results regarding kind function involved.Nevertheless, added two functions test set aim balancingnumber functions kind. two new functions function Rosenbrock(Rosenbrock, 1960) extended p dimensions function Schwefel (Schwefel, 1981);widely used evolutive optimization literature. Table 1 showsexpression function summary features: separability, multimodality,regularity.function multimodal two local optima. function p variablesseparable rewritten sum p functions one variable (Hadley, 1964).separability closely related concept epistasis interrelation amongvariables function. field evolutionary computation, epistasis measuresmuch contribution gene fitness individual depends valuesgenes.Non separable functions difficult optimize accurate search directiondepends two genes. hand, separable functions optimizedvariable turn. problem even difficult function also multimodal.search process must able avoid regions around local minima orderapproximate, far possible, global optimum. complex case appearslocal optima randomly distributed search space.9fiOrtiz-Boyer, Hervas-Martnez, & Garca-PedrajasFunctionSphereSchwefelsdouble sumRosenbrockRastriginSchwefelAckleyGriewangkFletcherPowellLangermanDefinitionPp2fSph (x) =i=1 xixi [5.12, 5.12]x = (0, 0, . . . , 0); fSph (x ) = 0P2PpfSchDS (x) =j=1 xji=1xi [65.536, 65.536]x = (0, 0, . . . , 0); fSchDS (x ) = 0Pp12 22fRos (x) =i=1 [100(xi+1 xi ) + (xi 1) ]xi [2.048, 2.048]x = (1, 1, . . . , 1); fRos (x ) = 0PpfRas (x) = 10p + i=1 (x210 cos(2xi ))xi [5.12, 5.12]x = (0, 0, . . . , 0); fRas (x ) = 0pPpfSch (x) = 418.9829 p + i=1 xi sin|xi |xi [512.03, 511.97]x = (420.9687, . . . , 420.9687);(x )=0q fSch1 Pp2fAck (x) = 20 + e 20exp 0.2 pi=1 xiPp1exp pi=1 cos(2xi )xi [30, 30]x = (0, 0, . . . , 0); fAck (x ) = 0QpPpx2xfGri (x) = 1 + i=1 4000i=1 cosxi [600, 600]x (0, 0, . . . , 0); fGri (x ) = 0Pp(A Bi )2fF le (x) =i=1Pp(aij sinj + bij cosj )Ai =j=1PpBi =j=1 (aij sinxj + bij cosxj )xi , [, ]; aij , bij [100, 100]x = ; fF le (x ) = 0P1 PpfLan (x) =c exp(x aij )2Pi=1j=1 jpcos j=1 (xj aij )2xi [0, 10]; = px = random; fLan (x ) = randomMultimodal?Separable?yesRegular?n/an/an/ayesyesn/ayesyesn/ayesyesyesyesyesyesTable 1: Definition function together featuresdimensionality search space another important factor complexityproblem. study dimensionality problem features carriedFriedman (1994). order establish degree difficulty problems,chosen search space dimensionality p = 30 functions.Sphere function used development theory evolutionary strategies(Rechenberg, 1973), evaluation genetic algorithms part test setproposed De Jong (1975). Sphere, De Jongs function F1, simple stronglyconvex function. Schwefels double sum function proposed Schwefel (1995). maindifficulty gradient oriented along axis due epistasis amongvariables; way, algorithms use gradient converge slowly. Rosenbrockfunction (Rosenbrock, 1960), De Jongs function F2, two dimensional functiondeep valley shape parabola form x21 = x2 leads globalminimum. Due non-linearity valley, many algorithms converge slowlychange direction search repeatedly. extended version functionproposed Spedicato (1975). versions proposed (Oren, 1974; Dixon,1974). considered many authors challenge optimization algorithm(Schlierkamp-Voosen, 1994). difficulty mainly due non-linear interaction amongvariables.Rastrigin function (Rastrigin, 1974) constructed Sphere adding modulatorterm cos(2xi ). contour made large number local minima whose valueincreases distance global minimum. surface Schwefel function (Schwefel, 1981) composed great number peaks valleys. function second10fiCIXL2: Crossover Operator Evolutionary Algorithmsbest minimum far global minimum many search algorithms trapped.Moreover, global minimum near bounds domain.Ackley, originally proposed Ackley (1987) generalized Back (1993),exponential term covers surface numerous local minima. complexityfunction moderated. algorithm uses gradient steepest descenttrapped local optima, search strategy analyzes wider regionable cross valley among optima achieve better results. orderobtain good results function, search strategy must combine exploratoryexploitative components efficiently. Griewangk function (Back, Fogel, & Michalewicz, 1997)product term introduces interdependence among variables. aimfailure techniques optimize variable independently. Ackley function,optima Griewangk function regularly distributed.functions Fletcher-Powell (Fletcher & Powell, 1963) Langerman (Bersini,Dorigo, Langerman, Seront, & Gambardella, 1996) highly multimodal, AckleyGriewangk, non-symmetrical local optima randomly distributed.way, objective function implicit symmetry advantages might simplifyoptimization certain algorithms. Fletcher-Powel function achieves random distribution optima choosing values matrixes b, vectorrandom. used values provided Back (1996). Langerman function,used values c referenced Eiben Back (1997b).4. Evolutionary Algorithmsuitable evolutionary algorithms solve optimization problems continuousdomains evolutionary strategies (Schwefel, 1981; Rechenberg, 1973), genetic algorithms(Holland, 1975; Goldberg, 1989a) real coding (Goldberg, 1991) evolutionary programming (Fogel, Owens, & Walsh, 1966; Fogel, 1995). evaluating CIXL2chosen real coded genetic algorithms, search algorithms general purpose crossover operator plays central role. general structure geneticalgorithm shown Figure 4.Nevertheless, CIXL2 could applied evolutionary algorithms crossoversimilar operator. hand, real codification natural onecontinuous domains, gene representing variable function. way,precision solution depends data type used store variables.objective comparison behavior proposed crossovercrossovers. comparison must made common evolutionary frameworkdefined features genetic algorithm. definition features,taken account previous studies matter. following paragraphsdescribe depth different components genetic algorithm.4.1 Structure Individual Population Sizeindividual made p = 30 genes, dimensionality functions optimize.size population one critical parameters many applications.size population small, algorithm could converge quickly towards suboptimal solutions; large, much time resources could wasted. also11fiOrtiz-Boyer, Hervas-Martnez, & Garca-PedrajasGenetic algorithmbegint0initialize (t)evaluate (t)(not stop-criterion)begintt+1select (t) (t 1)crossover (t)mutate (t)evaluate (t)endendFigure 4: Structure genetic algorithm, current generation.obvious size population, together selective pressure, influencesdiversity population.Several researches studied problems different points view. Grefenstette (1986) used meta-genetic algorithm controlling parameters another geneticalgorithm, population size selection method. Goldberg (1989b) made theoretical analysis optimum population size. study influence parameterssearch process carried Schaffer, Caruana, Eshelman Das (1989).Smith (1993) proposed algorithm adjusts size population respecterror probability selection . Another method consists changing sizepopulation (Arabas, Michalewicz, & Mulawka, 1994) dynamically.size population usually chosen interval 50 500 individuals,depending difficulty problem. general practice, function optimization,size interval [50, 100] unimodal functions, interval [100, 500]multimodal functions. However, several papers use compromise size 100functions order homogenize comparison environment. also use populationsize 100 individuals like comparative studies (Zhang & Kim, 2000; Takahashi, Kita,& Kobayashi, 1999).4.2 SelectionZhang Kim (2000) comparative study carried performance fourselection methods: proportional, ranking, tournament Genitor. contraststudies based asymptotic study less ideal conditions,paper devoted practical case, problem machine layout. paper analyzesquality solutions obtained reasonable amount time using mutationcrossover operators. study concludes methods ranking tournamentselection obtain better results methods proportional Genitor selection.12fiCIXL2: Crossover Operator Evolutionary Algorithmschosen binary tournament selection, ranking selection, usedZhang Kim (2000) two reasons:complexity tournament selection lower complexity rankingselection (Back, 1996).selective pressure higher. feature allows us measure whethercrossover able keep population diversity (Goldberg & Deb, 1991).Tournament selection runs tournament two individuals selects winner.order assure best individuals always survive next generation, useelitism, best individual population generation always includedpopulation generation + 1. proved, theoretically (Rudolph, 1994)empirically (Back, 1996; Michalewicz, 1992; Zhang & Kim, 2000), convenienceuse elitism.4.3 Population Update Modeldifferent techniques updating population, among importantgenerational model steady-state model. generational modelgeneration complete set N new offspring individuals created N parents selectedpopulation. generational models, tournament selection usedchoose two parent individuals, crossover pc probability mutation operatorcon pm probability applied parents.contrasts steady-state model, one member populationreplaced time. steady-state model selects individual mutatedmutated individual replaces another individual population. crossover twoindividuals selected one offspring replaces one individual population.number different replacement strategies: replace-worst, replace randomlychosen member, select replacement using negative fitness.model extrapolates generational steady-state saidgeneration gap G (De Jong, 1975; Jong & Sarma, 1993). Thus generational model,G = 1; steady-state model, G = 1/N . One widely used variantssteady-stated genetic algorithm Minimal Generation Gap (MGG) model (Satoh,Yamamura, & Kobayashi, 1996). model takes two parents randomly population generates children. Two individuals selected parentsoffspring: best individual, another individual chosen roulette selection.two individuals substitute parents population.generational model frequently used comparative studies useBLX, SBX, logical crossover fuzzy recombination. reasonmodel used paper. However, UNDX crossover used MGG model,UNDX MGG commonly used together generational modelnegative influence performance UNDX.parameters two models used commonly usedliterature. generational model, use probability crossover p c = 0.6 (DeJong, 1975; Herrera, Lozano, & Verdegay, 1998). MGG model used = 200,13fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajasvalue commonly used papers UNDX (Ono & Kobayashi, 1997; Ono,Kita, & Kobayashi, 1999; Ono, Kobayashi, & Yoshida, 2000). mutation probability,values interval pm [0.001, 0.1] usual (De Jong, 1975; Herrera et al., 1998;Michalewicz, 1992; Back, 1996). chosen value pm = 0.05 models.4.4 Initializationsearch algorithm, initialization method important. many casesinitialization determines success failure search process. opted,papers (Herrera et al., 1998; De Jong, 1975; Beyer & Deb, 2001; Herrera, Lozano,& Sanchez, 2003), initializing values genes means uniform randomdistribution within domain variable.4.5 Mutationmutation operator chosen non-uniform mutation parameter b = 5(Michalewicz, 1992) dynamical nature makes suitable wide varietyproblems (Herrera & Lozano, 2000).individuals generated mutation obtained follows:im=+ 4(t, bi ) si = 04(t, ai ) si = 1(12)4(t, y) = y(1 r(1 g)bmax)(13)generation, gmax maximum number generations, random value,{0, 1}, r random number interval [0, 1] b parameter determinesdegree dependence mutation regards number iterations. Equation13 gives values interval [0, y]. probability obtaining value near 0 increasesalgorithm progresses. operator performs uniform search initial stagesevolution, localized search final stages.4.6 Stop Criterionpart genetic algorithm takes time evaluationfitness function. number evaluations fitness generation dependsoperators used population update model. Different operators update modelslead different numbers evaluations per generation. reasoncommon use number evaluations stop criterion instead numbergenerations. used limit 300,000 evaluations (Eiben, van der Hauw, & vanHemert, 1998; De Jong & Kosters, 1998) stop criterion. precision solutionsbounded precision data type used implementation geneticalgorithm. used double precision data type 64 bits following specificationANSI/IEEE STD 754-1985 (IEEE Standard Binary Floating-Point Arithmetic).data type precision 15 - 17 digits.14fiCIXL2: Crossover Operator Evolutionary Algorithms5. Analysis CIXL2section perform analysis crossover, obtain every testfunction following information:1. optimal value confidence coefficient 1 confidence interval.values used 1 = {0.70, 0.90, 0.95, 0.99}.2. optimal number best individuals used crossover calculate confidence intervals mean. values used n = {5, 10, 30, 60, 90}.two factors independent, perform analysis usingpossible pairs (1 , n) Cartesian product two sets. pairperform 30 runs genetic algorithm different random seeds. Table 2 showsaverage value standard deviation 30 runs experiment.study results made means analysis variance ANOVAII (Dunn & Clark, 1974; Miller, 1981; Snedecor & Cochran, 1980), fitnessbest individuals, A, test variable. fitness obtained independently 30 runsdepending two fixed factors interaction. fixed factors are: confidencecoefficient C four levels number best individuals B five levels.linear model form:Aij = + Ci + Bj + CBij + eij(14)= 1, 2, 3, 4; j = 1, 2, 3, 4, 5where:Ci effect i-th level factor C, C1 represents confidencecoefficient 0.70, C2 0.90, C3 0.95 C4 0.99.Bj effect j-th level factor B, B1 represents valuen = 5, B2 n = 10, B3 n = 30, B4 n = 60 B5 n = 90.CBij represents effect interaction confidence coefficient Cnumber best individuals B.global mean model. variation experimental resultsexplained effects different levels factors modelinteraction.eij error variables.hypothesis tests try determine effect term fitness bestindividuals, A. carried tests every factor interaction amongfactors. subsequent tests performed confidence level 95%.coefficient R2 linear model tells us percentage variance explainedmodel.15fiOrtiz-Boyer, Hervas-Martnez, & Garca-PedrajasFunctionn 1MeanSt. Dev.1MeanMeanD. Tip.1MeanSt. Dev.SpherefSph5103060900.706.365e-165.736e-153.728e-126.082e-103.838e-092.456e-162.495e-151.623e-122.499e-102.326e-090.904.885e-162.554e-151.446e-112.867e-084.383e-08St. Dev. 11.969e-168.934e-167.062e-121.642e-083.068e-080.953.553e-162.642e-152.279e-111.557e-076.840e-081.710e-161.258e-151.256e-119.911e-085.894e-080.991.998e-161.480e-151.248e-105.494e-071.061e-076.775e-171.032e-155.914e-116.029e-078.401e-08Schwefels5double sum 10fSchDS3060900.701.995e-032.232e-028.464e-021.376e-018.048e-012.280e-032.859e-021.168e-011.202e-015.403e-010.908.403e-03 7.748e-035.407e-02 3.792e-023.190e-01 2.798e-014.059e-01 2.395e-012.257e+00 1.490e+000.957.662e-034.168e-022.644e-012.223e-017.048e-019.693e-034.383e-022.569e-011.384e-017.689e-010.991.305e-021.462e-021.223e-012.134e-012.799e-011.303e-021.422e-029.018e-021.464e-012.322e-01Rosenbrock 5fRos103060900.702.494e+012.579e+012.611e+012.576e+012.562e+011.283e+002.044e-011.471e-011.988e-012.827e-010.902.506e+012.591e+012.632e+012.593e+012.570e+013.050e-011.324e-011.745e-012.292e-012.974e-010.952.497e+012.589e+012.642e+012.600e+012.579e+014.663e-019.426e-021.377e-014.045e-012.629e-010.99RastriginfRas5103060900.702.919e+00 1.809e+006.799e+00 2.480e+009.452e+00 2.434e+001.413e+01 4.126e+001.771e+01 5.063e+000.906.036e+001.068e+011.270e+011.837e+012.438e+012.023e+003.786e+003.522e+006.070e+007.688e+000.957.893e+001.297e+011.327e+011.499e+011.987e+012.450e+003.844e+004.770e+004.434e+005.637e+000.997.164e+001.675e+011.552e+011.691e+012.249e+012.579e+006.554e+003.664e+004.123e+006.058e+00SchwefelfSch5103060900.706.410e+02 2.544e+021.793e+03 4.172e+022.675e+03 2.592e+022.700e+03 1.471e+022.738e+03 1.476e+020.901.145e+031.325e+032.264e+032.513e+032.704e+035.422e+022.340e+022.758e+021.927e+021.516e+020.951.424e+031.486e+032.061e+032.496e+032.672e+036.837e+022.607e+022.369e+022.146e+021.349e+020.992.844e+032.525e+031.986e+032.169e+032.529e+034.168e+023.069e+022.424e+022.434e+021.837e+02AckleyfAck5103060900.701.378e-082.074e-078.328e-061.019e-042.518e-045.677e-099.033e-081.403e-062.396e-057.167e-050.906.320e-099.544e-081.483e-058.292e-047.544e-042.966e-093.422e-083.956e-062.097e-042.668e-040.954.677e-099.396e-082.246e-051.897e-039.571e-021.960e-093.513e-084.957e-069.190e-043.609e-010.995.188e-095.806e-084.976e-053.204e-031.741e-012.883e-092.683e-081.298e-051.373e-035.290e-01GriewangkfGri5103060900.701.525e-021.647e-022.012e-027.884e-037.391e-031.387e-021.951e-022.372e-021.061e-027.617e-030.902.463e-022.695e-021.819e-022.808e-025.248e-032.570e-022.713e-021.664e-029.686e-026.741e-030.951.574e-022.195e-022.321e-027.410e-038.938e-031.411e-022.248e-023.842e-021.321e-021.196e-020.991.285e-023.194e-022.254e-021.582e-021.230e-021.801e-023.680e-021.877e-022.727e-022.356e-02FletcherfF le5103060900.701.523e+041.966e+042.145e+042.133e+042.432e+041.506e+041.585e+041.631e+042.110e+042.273e+040.902.293e+042.248e+042.129e+042.124e+042.898e+041.882e+042.300e+041.310e+041.213e+043.131e+040.951.286e+04 1.317e+041.633e+04 1.344e+043.049e+04 2.306e+042.935e+04 2.155e+042.918e+04 2.418e+040.991.527e+041.891e+042.492e+042.374e+043.453e+041.362e+041.612e+041.967e+041.479e+042.498e+04Langerman 5fLan103060900.70-2.064e-01-2.339e-01-2.124e-01-1.975e-01-1.599e-019.346e-021.280e-011.038e-011.405e-019.057e-020.90-2.544e-01-2.582e-01-2.191e-01-1.752e-01-1.336e-011.401e-011.574e-011.100e-017.145e-026.042e-020.95-3.545e-01-2.663e-01-1.908e-01-1.762e-01-1.656e-010.99-2.803e-01-2.830e-01-2.382e-01-1.949e-01-1.796e-011.350e-011.645e-011.572e-019.500e-028.453e-021.802e-011.247e-019.776e-028.929e-028.336e-022.463e+01 1.330e+002.579e+011.609e-012.668e+019.999e-022.617e+014.787e-012.585e+013.654e-01Table 2: Average value standard deviation 30 runs experiment16fiCIXL2: Crossover Operator Evolutionary Algorithmsdetermining whether significant differences among various levelsfactor, perform multiple comparison test average fitness obtaineddifferent levels factor. First, carry Levene test (Miller, 1996; Levene,1960) evaluating equality variances. hypothesis variancesequal accepted, perform Bonferroni test (Miller, 1996) ranking meanslevel factor. aim find level factor whose average fitnesssignificantly better average fitness rest levels factor.test Levene results rejecting equality covariance matrixes, performTamhane test (Tamhane & Dunlop, 2000) instead Bonferroni test. Tables 9, 12,13 Appendix show results obtained following methodology.Sphere function, significant levels term linear model Table 9show none factors linear model significant effect model builtexplain variance fitness A. effect due fact fSph easyoptimize fitness behaves singular random variable sample variance near0. see Table 2 best results obtained pair (0.99, 5).multiple comparison test Table 12 confirms means obtained value n = 5significatively better means obtained values. way,average fitness 1 = 0.70 significantly best one. results show that,value n, best value 1 , general, 1 = 0.70. Due simple formfSph , best parameters crossover show high exploitative component fastshifting towards region best individuals.unimodal non-separable functions fSchDS fRos , factorsinteraction significant linear model explains sample variancedetermination coefficient around 0.5. Table 2 shows best results obtainedn = 5; Tamhane test shows means obtained value nsignificatively better means obtained values. results valueconfidence coefficient less conclusive. fact, fRos significantdifferences among different values 1 , although best results obtained1 = 0.7. fSchDS average fitness 0.99 best one, without significantdifferences 0.70 . 0.70 together n = 5 one shows best results.conclude feature non-separability functions imply notablechange parameters crossover respect parameters used f Sph .fRas fSch , separable multimodal, adequate pairparameters (0.70, 5). fRas , test shows performance pair significantly better. However, fSch , best mean obtained 5 resultssignificantly better obtained values, exception 10 .significant differences among 0.70 , 0.95 90 . three factors linearmodel significant quite large determination coefficients 0.617 f Ras 0.805forfSch . means factors interaction explain high percentagevariance fitness A.fAck , best results obtained pair (0.95, 5). Tamhane test confirmsn = 5 suitable value, significant differences among 0.70 ,0.95 0.99 . fGri best results obtained pair (0.90, 90). testshows large values n suitable optimization function.significant differences among performance different values 1 .17fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajasfunctions determination coefficient linear model low, showinglinear model explain variance fitness. lack linear relationamong n, 1 fitness makes difficult determine best valueparameters crossover.case fF le fLan similar, linear model hardly gives informationeffect parameters fitness. adequate pair optimization two functions (0.95, 5). test shows best values n n = 5n = 10. hand, significant differences among performancecrossover different values 1 .overall results show selection best n = 5 individuals populationwould suffice obtaining localization estimator good enough guide search processeven multimodal functions small value n could favor convergencelocal optima. However, virtual parents worse fitness parentpopulation, offspring generated near latter, domain exploredmultiple directions. way, premature convergence suboptimal virtual parentsavoided.However, best n individuals concentrated local optimum algorithmlikely converge optimum. reason complex functionslarger value n may reasonable, adding confidence interval individuals locatednear different optima. example this, case fGri best resultsachieved n = 90 n = 60 noteworthy.confidence coefficient bounds error determination localizationparameter responsible focussing search. multiple comparison tests showvalue 1 = 0.70 best 6 problems, is, least, worsebest one problems. chosen adequate valueparameter.6. Comparative Study CrossoversDue large amount different crossovers available, unfeasible make comprehensive comparison crossovers CIXL2. chosencrossovers obtain interesting results whose features similar crossover,is, self-adaptive establish balance exploration exploitation search space. way two features balanced regulatedone parameters crossover. parameters chosen followingauthors recommendations papers devoted comparison differentoperators.crossovers used comparison are: BLX (Eshelman & Schaffer, 1993)different degrees exploration determined values = {0.2, 0.5} (Herrera et al.,2003); fuzzy recombination (Voigt et al., 1995); based fuzzy connectives logicalfamily (logical crossover) (Herrera et al., 1998) using S2 strategies = 0.5 (Herrera &Lozano, 2000), SBX (Deb & Agrawal, 1995) using values = {2, 5} (Deb & Beyer, 2001);(Kita, Ono, & Kobayashi, 1998;UNDX (Ono & Kobayashi, 1997) = 21 = 0.35pKita, 2001). CIXL2, determined previous study, use n = 51 = 0.70.18fiCIXL2: Crossover Operator Evolutionary AlgorithmsFollowing setup previous study, performed ANOVA II analysismultiple comparison test. might expected, keeping mind no-freelunch theorem diversity functions test set, tests showcrossover whose results significatively better results crossovers.mean differences could exist certain kinds functions.So, order determine kind function whether crossover betterothers, performed ANOVA analysis factor crossoveroperator multiple comparison test. Additionally, graphically study speedconvergence RCGA regard crossover operator. order enforceclearness graphics crossover, show curve best performingset parameters BLX SBX crossovers.CrossoverCIXL2BLX(0.3)BLX(0.5)SBX(2)SBX(5)Ext. F.LogicalUNDXCIXL2BLX(0.3)BLX(0.5)SBX(2)SBX(5)Ext. F.LogicalUNDXCIXL2BLX(0.3)BLX(0.5)SBX(2)SBX(5)Ext. F.LogicalUNDXMeanSt.Dev.fSph6.365e-16 2.456e-163.257e-16 1.396e-164.737e-16 4.737e-161.645e-12 8.874e-134.873e-12 3.053e-122.739e-15 1.880e-153.695e-13 1.670e-132.910e-05 1.473e-05fRas2.919e+00 1.809e+002.189e+00 1.417e+003.018e+00 1.683e+001.844e+01 4.417e+001.419e+01 3.704e+002.245e+01 4.914e+006.325e+01 1.012e+011.107e+02 1.242e+01fGri1.525e-02 1.387e-024.749e-02 4.579e-023.760e-02 2.874e-022.196e-02 1.874e-023.128e-02 2.737e-021.315e-03 3.470e-036.078e-03 6.457e-037.837e-02 4.438e-02MeanSt.Dev.fSchDS1.995e-03 2.280e-031.783e-02 1.514e-029.332e-03 1.086e-022.033e-01 1.966e-013.933e-01 2.881e-013.968e+01 1.760e+011.099e+01 7.335e+002.080e+01 7.216e+00fSch6.410e+02 2.544e+023.695e+02 1.595e+024.200e+02 1.916e+021.470e+03 3.827e+021.104e+03 3.353e+023.049e+03 2.876e+022.629e+03 9.749e+018.050e+03 3.741e+02fFle1.523e+04 1.506e+041.570e+04 1.515e+041.802e+04 1.483e+043.263e+04 3.110e+043.333e+04 2.973e+041.691e+04 1.446e+042.718e+04 1.388e+043.469e+04 2.136e+04MeanSt.Dev.fRos2.494e+01 1.283e+002.923e+01 1.723e+013.161e+01 2.094e+012.775e+01 9.178e+003.111e+01 1.971e+012.743e+01 1.394e+012.703e+01 8.358e-022.840e+01 3.606e-01fAck1.378e-08 5.677e-094.207e-08 1.713e-086.468e-08 1.928e-085.335e-06 1.453e-069.662e-06 2.377e-061.797e-07 5.823e-082.531e-06 7.129e-073.551e-02 1.224e-02fLan-2.064e-01 9.346e-02-3.003e-01 1.388e-01-3.457e-01 1.684e-01-1.939e-01 1.086e-01-1.866e-01 9.080e-02-1.064e-01 5.517e-02-7.396e-08 2.218e-07-2.130e-01 9.116e-02Table 3: Average values standard deviation 30 runs every crossover operator.Table 3 shows average values standard deviations 30 runs performedcrossover operator. Table 10 Appendix shows how, functions, exceptfRos , crossover operator significant effect linear model. table alsoshows results Levene test indicate inequality variancesresults functions, excepting fF le . So, use Bonferroni test fF le ,Tamhane test others. results multiple comparison test, rankingestablished tests significant level differences among resultscrossovers shown Tables 14, 15 16 (Appendix A). Figures 5 - 13, AppendixB, show, logarithmic scale, convergence curves function.19fiOrtiz-Boyer, Hervas-Martnez, & Garca-PedrajasfSph high value determination coefficient shows linear modelexplains much variance fitness. best values obtained BLX(0.3),BLX(0.5) CIXL2, order. operators obtain precisions around1e-16. Figure 5 shows CIXL2 fastest convergence, surpassed BLXlast generations.fSchDS fRos best results obtained CIXL2. fSchDS differenceperformance crossovers statistically significant. f Ros differencessignificant, CIXL2 compared Logical UNDX. f SchDS Figure 6shows CIXL2 achieves quasi-exponential convergence precise final result.fRos , Figure 7 see speed convergence CIXL2 highest,although profile crossovers similar fast initial convergencefollowed poor evolution due high epistasis function. differencesoverall process small. fact explains linear model influencefactor crossover significant determination coefficient small.fRas , BLX(0.3) obtains best results without significant differenceaverage values obtained CIXL2 BLX(0.5). three operators also obtainbest results fSch ; however, tests show significant differencesCIXL2 BLX(0.5), differences BLX(0.5) BLX(0.3).latter obtains best results. Figures 8 9 show BLX best termsconvergence speed followed CIXL2. large value R 2 means crossoversignificant influence evolutive process.fAck , CIXL2 obtains significantly better results. Figure 10 seealso converges faster. large value R2 means crossover significantinfluence evolutive process. fGri , Fuzzy operator obtains significantly betterresults. following ones, significant differences them, LogicalCIXL2. Figure 11 shows fast initial convergence CIXL2, end LogicalFuzzy obtain better results.fF le best results obtained CIXL2, difference significantSBX UNDX. Figure 12 shows CIXL2 fastest convergence,curve profile similar BLX Fuzzy. fLan , best operator BLX(0.5),differences significant operators exception BLX(0.3).UNDX CIXL2 together third place. Figure 13 shows behaviorcrossovers similar, except Logical crossover converges value faroperators.7. Comparison Estimation Distribution AlgorithmsEDAs evolutionary algorithms use, CIXL2, best individuals populationdirect search. comparison paradigm interesting, althoughsignificant differences EDAs RCGAs.EDAs remove operators crossover mutation. generation subsetpopulation selected distribution individuals subset estimated.individuals population next generation obtained sampling estimateddistribution. Although selection method could applied, common oneselection best individuals population.20fiCIXL2: Crossover Operator Evolutionary Algorithmsfirst EDAs developed discrete spaces. Later, adapted continuous domains. distinguish two types EDAs, whether take accountdependencies variables not. One used among EDAsconsider dependencies U DAc (Univariate Marginal Distribution Algorithm continuous domains) (Larranaga, Etxeberria, Lozano, & Pena, 2000). every generationevery variable U DAc carries statistical test order find densityfunction best fits variable. densities identified, estimationparameters performed maximum likelihood estimates. distributionsnormal, two parameters mean standard deviation. particularcase denoted U DAGc (Univariate Marginal Distribution Algorithm Gaussianmodels).Among type EDAs, consider EGN ABGe (Estimation GaussianNetwork Algorithm) (Larranaga et al., 2000) whose good results function optimizationreported Bengoetxea Miquelez (2002). generation, EGN BGe learnsGaussian network structure using Bayesian score gives valueGaussian networks reflecting conditional dependencies used. Next, calculatesestimations parameters Gaussian network structure.experiments used parameters reported Bengoetxea T. Miquelez(2002): population 2000 individuals, initialized using uniform distribution,subset best 1000 individuals selected estimate density function,elitist approach chosen (the best individual included next population 1999individuals simulated). algorithm run 30 times stop criterion300,000 evaluations fitness function.results EDAs compared results RCGA CIXL2 parametersn = 5 1 = 0.70. performed ANOVA analysis three levelsfactor different algorithms: RCGA CIXL2, U DAc EGN ABGe . alsocarried multiple comparison test.Table 4 shows average values standard deviations 30 runs algorithm.Table 11 Appendix shows how, functions excepting fAck , type algorithm significant effect linear model exist inequality variancesresults (Levene test). So, used Tamhane test functions Bonferroni test fAck . Table 17 (Appendix A) shows results multiple comparison testranking established test.fSph results similar. fitness behaves singular random variablesample variance near 0 statistical tests feasible.fSchDS results CIXL2 significantly better results U DAcEGN ABGe . situation occurs fRos , fRas , fSch fAck , exceptionfour functions significant differences two EDAs.fGri , EGN ABGe U DAc achieve best results, significantly better CIXL2.fF le , U DAc significantly better EGN ABGe CIXL2,differences two. fLan , CIXL2 obtains best results,significant differences among three algorithms.estimation distribution function best individuals populationperformed EDAs advantage fSph , unimodal separable, fGri fAckwhose optima regularly distributed. results EDAs fGri better21fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajasresults CIXL2, results fAck worse. results fSphalgorithms similar. non-separable unimodal functions, f SchDS fRos ,interdependence among variables favor performance EGN BGeU DAc CIXL2. Nevertheless, CIXL2 achieves best results two functions.multimodal separable functions, fRas fSch , difficult identify distributionbest individuals performance EDAs performance CIXL2.extremely complex functions, fF le fLan , results less conclusive.fF le best results obtained U DAc , differencesEGN ABGe CIXL2. fLan , CIXL2 achieves best results, differencesamong three algorithms statistically significant.EACIXL2U DAcEGN ABGeCIXL2U DAcEGN ABGeCIXL2U DAcEGN ABGeMeanSt.Dev.fSph6.365e-16 2.456e-161.196e-16 1.713e-171.077e-16 1.001e-17fRas2.919e+00 1.809e+001.576e+02 7.382e+001.563e+02 8.525e+00fGri1.525e-02 1.387e-029.465e-16 1.207e-168.200e-16 1.149e-16MeanSt.Dev.fSchDS1.995e-03 2.280e-032.221e+01 3.900e+002.096e-01 1.189e-01fSch6.410e+02 2.544e+021.153e+04 9.167e+011.155e+04 8.754e+01fFle1.523e+04 1.506e+045.423e+03 1.562e+039.069e+03 7.592e+03MeanSt.Dev.fRos2.494e+01 1.283e+002.787e+01 2.278e-022.785e+01 1.629e-01fAck1.378e-08 5.677e-092.478e-08 1.831e-092.297e-08 2.095e-09fLan-2.064e-01 9.346e-02-1.734e-01 4.258e-11-1.734e-01 1.864e-11Table 4: Average values standard deviation 30 runs three evolutionary algorithms: RCGA CIXL2 crossover, U DAc EGN ABGe .8. Application Artificial IntelligenceGenetic algorithms applied almost kind problem, as, object recognition artificial vision (Singh, Chatterjee, & Chaudhury, 1997; Bebis, Louis, Varol, &Yfantis, 2002), robotics path planing (Davidor, 1991; Sedighi, Ashenayi, Manikas, Wainwright, & Tai, 2004), parameter estimation (Johnson & Husbands, 1990; Ortiz-Boyer,Hervas-Martnez, & Munoz-Perez, 2003), instance selection (Cano, Herrera, & Lozano,2003; Kuncheva, 1995), reinforcement learning (Moriarty, Schultz, & Grefenstette, 1999),neural network (Miller, Todd, & Hedge, 1991; Andersen & Tsoi, 1993; Bebis, Georgiopoulos, & Kasparis, 1997) ensemble design (Zhou, Wu, & Tang, 2002).Real-coded genetic algorithms using CIXL2 applied problemsprovided defined continuous domain. chosen application RCGAsestimation weight network ensemble. interestingproblem standard methods encounter many difficulties.8.1 Estimation Weights Networks EnsembleNeural network ensembles (Perrone & Cooper, 1993) (Garca-Pedrajas, Hervas-Martnez,& Ortiz-Boyer, 2005) receiving increasing attention recent neural network research,due interesting features. powerful tool specially facing complex22fiCIXL2: Crossover Operator Evolutionary Algorithmsproblems. Network ensembles made linear combination several networkstrained using data, although actual sample used networklearn different. network within ensemble potentially different weightoutput ensemble. Several papers shown (Perrone & Cooper, 1993)network ensemble generalization error generally smaller obtainedsingle network also variance ensemble lesser variancesingle network. output ensemble, y, input pattern x presented, is:y(x) =kXyi (x),(15)i=1yi output network i, wi weight associated network.networks one output, different weight usually assigned output.ensembles neural networks advantages large networks withoutproblems long training time risk over-fitting.Moreover, combination several networks cooperate solving given taskimportant advantages, (Liu, Yao, & Higuchi, 2000; Sharkey, 1996):perform complex tasks subcomponents.make overall system easier understand modify.robust single network.Techniques using multiple models usually consist two independent phases: modelgeneration model combination (Merz, 1999b). network trainedassigned weights (model generation), are, classification environment three basicmethods combining outputs networks (model combination):1. Majority voting. pattern classified class majority networks places (Merz, 1999b). Majority voting effective, prone fail twoscenarios:(a) subset redundant less accurate models comprise majority,(b) dissenting vote recognized area specialization particular model.2. Sum outputs networks. output ensemble sumoutputs individual networks.3. Winner takes all. pattern assigned class highest outputoutputs networks. is, network largest outputs directlyclassify pattern, without taking account networks.commonly used methods combining networks majority votingsum outputs networks, weight vector measures23fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajasconfidence prediction network. problem obtaining weight vectoreasy task. Usually, values weights constrained:NX= 1,(16)i=1order help produce estimators lower prediction error (Leblanc & Tibshirani,1993), although justification constraint intuitive (Breiman, 1996).method majority voting applied, vote network weightedcounted:F (x) = arg maxyX.(17)i:fi (x)=yproblem finding optimal weight vector complex task. Basicensemble method (BEM), called Perrone Cooper (1993), consists weightingnetworks equally. So, N networks, output ensembles is:F (x) =N1 Xfi (x).N(18)i=1Perrone Cooper (1993) defined Generalized Ensemble Method, equivalent Mean Square Error - Optimal Linear Combination (MSE-OLC) withoutconstant term Hashem (Hashem, 1997). form output ensemble is:fGEM (x)NXfi (x),(19)i=1i0 real satisfy constraintby:PNi=11j Cij= P P 1 .kj CkjP= 1. values given(20)Cij symmetric correlation matrix Cij E[mi (x)mj (x)], mk (x) definesmisfit function k, deviation true solution f (x), mk (x) f (x)fk (x). previous methods commonly used. Nevertheless, many techniquesproposed last years. Among others, methods basedlinear regression (Leblanc & Tibshirani, 1993), principal components analysis leastsquare regression (Merz, 1999a), correspondence analysis (Merz, 1999b), usevalidation set (Opitz & Shavlik, 1996).application, use genetic algorithm obtaining weight component. approach similar use gradient descent procedure (Kivinen &Warmuth, 1997), avoiding problem trapped local minima. usegenetic algorithm additional advantage optimal linear combination,former affected collinearity problem (Perrone & Cooper, 1993; Hashem, 1997).24fiCIXL2: Crossover Operator Evolutionary Algorithms8.1.1 Experimental Setupset available data divided two subsets: 75% patterns usedlearning, remaining 25% testing generalization networks.two exceptions, Sonar Vowel problems, patterns two problemsprearranged two specific subsets due particular features. summarydata sets shown Table 5. validation set used experiments.Data setAnnealAutosBalanceBreast-cancerCardGermanGlassHeartHepatitisHorseIonosphereIrisLaborLiverLymphographyPimaPromotersSegmentSonarSoybeanTicTacToeVehicleVoteVowelZooCasesTrain Test67422415451469156215715181727502501615322676117382739126487113374314259861113757619280261733 5771041045131707192396352113271085284627625Classes563222622323224227219242117FeaturesC B N6 14 1815 4643664563 1196346 1313 2533 14835696857196016 1991816101 15Inputs597241551619221958344292388114196082918161016Table 5: Summary data sets. features data set C(continuous),B(binary) N(nominal). Inputs column shows number inputsnetwork depends number input variables alsotype.data sets cover wide variety problems. problems differentnumbers available patterns, 57 2310, different numbers classes, 219, different kinds inputs, nominal, binary continuous, different areas25fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajasapplication, medical diagnosis vowel recognition. Testing model widevariety problems give us clear idea performance. setsmethod applied.order test efficiency proposed crossover classical artificial intelligenceproblem, used RCGA adjust weight network within ensemble.method considers ensemble chromosome applies RCGA optimizeweight network. weight network ensemble codifiedreal number. chromosome formed way subject CIXL2 crossover nonuniform mutation. parameters CIXL2 used rest paper,n = 5 1 = 0.7. combination method used weighted sum outputsnetworks. Nevertheless, genetic algorithm could used weightingnetwork majority voting model used.exact conditions experiments run algorithmsfollowing:ensemble formed 30 networks. network trained separately usingstandard back-propagation algorithm using learning data.30 networks trained, different methods obtainingweights applied. So, methods use ensemble networksrun experiment. genetic algorithm, fitness individualpopulation classification accuracy learning set.obtaining vector weights, generalization error method evaluated using testing data.Tables 6 7 show results terms accurate classification 25 problems.tables show results using RCGA CIXL2, standard BEM GEMmethods. order compare three methods performed sign testwin/draw/loss record three algorithms (Webb, 2000). tests shown Table8.Table 8 shows comparison statistics three models (Webb, 2000).model show win/draw/loss statistic, first value number data setscol < row, second number col = row, thirdnumber col > row. second row shows p-value two-tailed sign testwin-loss record. table shows genetic algorithm using CIXL2 ableoutperform two standard algorithms BEM GEM 10% confidence.hand, significant differences BEM GEM. resultespecially interesting used comprehensive set problemsdifferent domains, different types inputs, different numbers classes.9. Conclusions Future Workpaper proposed crossover operator allows offspring inheritfeatures common best individuals population. extraction commonfeatures carried determination confidence intervals mean26fiCIXL2: Crossover Operator Evolutionary AlgorithmsProblemAnnealAutosBalanceBreastCancerCardGermanGlassHeartHepa.HorseIonos.IrisCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMMean0.99330.98790.99150.89570.86490.87400.93400.91790.91480.85750.83210.82740.97230.96780.96730.92010.90740.90490.87850.85870.86420.85090.80430.82460.92970.90890.91820.93850.91310.91790.87230.84440.84850.96350.94810.95541.00001.00001.0000LearningSt.Dev.Best0.0046 0.99850.0054 0.99550.0054 0.99850.0233 0.94160.0211 0.90910.0262 0.93510.0067 0.94460.0068 0.93180.0101 0.93180.0195 0.89300.0287 0.86980.0314 0.87910.0021 0.97710.0034 0.97330.0034 0.97330.0087 0.93630.0088 0.92470.0093 0.92080.0080 0.89730.0090 0.88270.0099 0.88270.0225 0.90060.0246 0.84470.0293 0.88200.0216 0.96530.0214 0.96040.0239 0.95540.0224 0.97440.0253 0.95730.0289 0.97440.0174 0.90840.0194 0.87180.0207 0.88640.0164 0.98860.0171 0.97730.0205 0.98860.0000 1.00000.0000 1.00000.0000 1.0000Worst0.97770.97330.97770.85060.83120.81820.92320.90190.87850.80470.73950.74880.96760.96000.95810.90540.88800.88220.86530.84400.84270.80750.75780.76400.88610.86630.86630.87180.84620.83760.83150.79490.80950.93560.91670.91671.00001.00001.0000Mean0.97780.97290.97800.72610.70520.70330.92010.91580.91580.68920.68260.68170.97990.97930.97850.85740.85210.85330.73330.73550.73770.69620.68240.68550.83580.83330.82790.87020.86580.87110.70440.70000.70040.89500.89200.89581.00001.00001.0000TestSt.Dev.Best0.0090 0.99110.0091 0.99110.0103 0.99110.0577 0.82350.0586 0.80390.0707 0.80390.0118 0.94870.0111 0.94230.0110 0.93590.0322 0.74650.0375 0.76060.0354 0.73240.0065 0.98850.0076 0.99430.0084 0.98850.0153 0.88950.0212 0.89530.0203 0.89530.0184 0.76400.0141 0.76000.0149 0.76800.0365 0.77360.0424 0.79250.0479 0.77360.0271 0.89710.0263 0.88240.0312 0.89710.0372 0.92110.0319 0.92110.0399 0.94740.0313 0.76920.0301 0.75820.0300 0.78020.0225 0.91950.0206 0.91950.0198 0.93100.0000 1.00000.0000 1.00000.0000 1.0000Worst0.94200.94640.94200.58820.56860.52940.89100.89100.89100.63380.60560.60560.96550.96550.95980.82560.79650.79650.70000.70400.71600.60380.60380.60380.77940.77940.77940.81580.81580.78950.62640.63740.64840.82760.82760.86211.00001.00001.0000Table 6: Ensemble results using real-coded genetic algorithm (CIXL2), basic ensemblemethod (BEM), generalized ensemble method (GEM). problemmarked whichever CIXL2 better (+), equal, (=), worse (-)BEM/GEM.27+++++++++++++++++++==fiOrtiz-Boyer, Hervas-Martnez, & Garca-PedrajasProblemLaborLiverLymphPimaPromot.SegmentSonarSoybeanTicTacToeVoteVowelZooCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMCIXL2BEMGEMMean0.96510.94880.95270.81260.77990.77440.94560.93180.93060.79820.77820.77520.94960.93000.92630.95020.93390.94230.90740.88590.89070.97580.96020.96910.99130.98680.98760.98320.97930.98010.91460.87330.91570.98070.96710.9750LearningSt.Dev.Best0.0257 1.00000.0283 0.97670.0270 0.97670.0175 0.84940.0176 0.81080.0198 0.81080.0208 0.97300.0242 0.96400.0254 0.97300.0073 0.81940.0079 0.79340.0089 0.78820.0304 1.00000.0357 0.98750.0319 0.98750.0030 0.95440.0042 0.94110.0044 0.95210.0236 0.95190.0266 0.94230.0277 0.95190.0114 0.99030.0130 0.98050.0157 0.98830.0027 0.99720.0020 0.99170.0024 0.99300.0055 0.99390.0060 0.99080.0062 0.99080.0148 0.94320.0179 0.90150.0129 0.93940.0175 1.00000.0215 1.00000.0203 1.0000Worst0.88370.88370.88370.77610.73360.73360.89190.87390.85590.78300.75350.74310.88750.85000.86250.94460.92560.93190.86540.82690.83650.94540.92400.93760.98470.98470.98470.97250.96640.96640.88450.83710.88450.92110.90790.9211Mean0.88570.88330.88330.69920.69500.68260.78470.77750.77840.78110.78850.77930.82440.82690.82180.92590.91830.92360.78490.78650.78530.90570.90390.90670.97940.97910.97920.92780.92840.92620.49250.49130.49730.93600.93070.9307TestSt.Dev.Best0.0550 1.00000.0663 1.00000.0689 1.00000.0276 0.74420.0253 0.74420.0337 0.74420.0538 0.86490.0539 0.86490.0504 0.83780.0209 0.81770.0199 0.81770.0222 0.82810.0726 1.00000.0612 0.92310.0711 0.96150.0057 0.93760.0054 0.93410.0061 0.93590.0286 0.84620.0286 0.83650.0266 0.84620.0165 0.93530.0182 0.93530.0187 0.93530.0024 0.98740.0000 0.97910.0008 0.98330.0110 0.95370.0068 0.94440.0107 0.94440.0293 0.56060.0331 0.55840.0342 0.55410.0290 0.96000.0392 0.96000.0347 0.9600Worst0.78570.71430.71430.65120.63950.60470.64860.64860.64860.72920.74480.72920.73080.73080.69230.91510.90810.91160.74040.72120.74040.87060.86470.87060.97490.97910.97910.88890.91670.89810.44590.42640.42210.88000.84000.8400Table 7: Ensemble results using real-coded genetic algorithm (CIXL2), basic ensemblemethod (BEM), generalized ensemble method (GEM). problemmarked whichever CIXL2 better (+), equal, (=), worse (-)BEM/GEM.28+++++++++++++++++fiCIXL2: Crossover Operator Evolutionary AlgorithmsAlgorithmCIXL2BEMBEM19/1/50.0066GEM17/1/70.06399/4/120.6636win/draw/lossp-valuewin/draw/lossp-valueTable 8: Comparison three methods. Win/draw/loss record algorithmsp-value sign test.best individuals population. confidence intervals, CIXL2 creates threevirtual parents used implement directed search towards region fittestindividuals. amplitude speed search determined number bestindividuals selected confidence coefficient.study carried order obtain best parameters CIXL2 concludesvalue n = 5 best individuals suitable obtain localization estimator guidesearch problems tested. However, difficult problems, wouldadvisable larger value n avoid premature convergence evolutionaryprocess. confident coefficient, 1 , responsible, together dispersionbest individuals, modulation wideness confidence interval centeredlocalization estimator. study results best value 1 = 0.70. pairvalues acceptable performance problems, although optimumpair values problems.comparative analysis crossover operators shows CIXL2 good alternative widely used crossovers BLX unimodal function fSph , fSchDS ,fRos . Noteworthy performance CIXL2 two non-separable functions,fSchDS fRos , crossovers disparate behavior.unimodal functions strategy extracting statistical features localizationdispersion best individuals guarantee good performance, casemultimodal functions quite different, performance algorithm assuredpriori. Nevertheless, results obtained kind functions show CIXL2always one best performing operators. instance, functions high complexityfAck multimodal, non-separable regular fF le multimodal, nonseparable irregular CIXL2 obtains best results. behavior revealsdetermination region best individuals means confidence intervalsprovides robust methodology that, applied crossover operator, shows interestingperformance even difficult functions. summary, affirm paperproves CIXL2 promising alternative bear mind, must choosecrossover use real-coded genetic algorithm.EDAs shown good performance unimodal separable functions, f Sph ,functions whose optima regularly distributed, fAck fGri . performanceEDAs decreases multimodal, fRas fSch , epistatic functions, fSchDS fRos .hand, CIXL2 less sensitive type function. main reasonbehavior may found fact CIXL2 uses distribution information obtainedbest individuals population differently. CIXL2 creates three virtual parents29fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajasdistribution, virtual parents worse fitness individualmates, offspring generated near virtual parents. way, CIXL2prevents shifting population confidence interval improvementperformance significant.applicability proposed crossover problem artificial neural networkensembles shows model used solving standard artificial intelligenceproblems. RCGAs CIXL2 also used aspects ensemble design,as, selection subset networks, sampling training set network.promising results motivate beginning new line research gearedstudy distribution best individuals taking account kind problemhand. aim propose new techniques selection individuals consideredobtaining confidence interval reliable way. multimodal, irregular,many chaotically scattered optima functions difficulty obtaining distributionsbest individuals enormous. kind functions would interestingperform cluster analysis selected best individuals obtain confidence intervalevery cluster. idea would allow implementation multi-directional crossovertowards different promising regions.hand, likely evolutive process progresses distributionbest individuals changes. case, would advisable perform, regularintervals, statistical tests determine distribution best reflects featuresbest individuals population.Alternatively, considering construction non-parametric confidence intervals.way, need robust estimators parameters localization dispersiongenes best individuals. performed preliminary studies usingmedian different measures dispersion results quite encouraging.Another research line currently open study application CIXL2 problems optimization restrictions, especially presence non-linearity,generation individuals feasible region big issue. orientationsearch based identification region best individuals implementedCIXL2 could favor generation feasible individuals. feature wouldinteresting advantage respect crossover operators.Acknowledgmentsauthors would like acknowledge R. Moya-Sanchez helping final versionpaper.work financed part project TIC2002-04036-C05-02 SpanishInter-Ministerial Commission Science Technology (CICYT) FEDER funds.30fiCIXL2: Crossover Operator Evolutionary AlgorithmsAppendix A. Results Statistical StudyFunctionfSphfSchDSfRosfRasfSchfAckfGrifF lefLanC1.0000.0000.0050.0000.0000.0950.1490.4100.040B1.0000.0000.0000.0000.0000.0000.0010.0000.000CB0.0000.0060.0000.0000.0190.024R20.6010.5260.6170.8050.0830.0400.0540.159T. Levene0.0000.0000.0000.0000.0000.0000.0000.0030.000Table 9: Significant levels, , term linear model, determination coefficientR2 , value Levene test statistical analysis CIXL2 parameters.FunctionfSphfSchDSfRosfRasfSchfAckfGrifF lefLanCrossover0.0000.0000.5730.0000.0000.0000.0000.0000.000R20.7790.7860.0240.9710.9870.8840.4210.1370.486Levene test0.0000.0000.0000.0000.0000.0000.0000.0910.000Table 10: Significance level crossover operator determination coefficient R 2linear model, value Levene test comparative study crossovers.FunctionfSchDSfRosfRasfSchfAckfGrifF lefLanEA0.0000.0000.0000.0001.0000.0000.0010.027R20.9550.7780.9920.9990.6410.4550.1500.079Levene test0.0000.0000.0000.0001.0000.0000.0000.000Table 11: Significance level evolutionary algorithms determination coefficient R 2linear model, value Levene test comparative study betwenCIXL2 EDAs.31fiOrtiz-Boyer, Hervas-Martnez, & Garca-PedrajasJ510306090105306090305106090605103090905103060Ranking510306090105306090305106090605103090905103060Ranking510306090105306090305106090605103090905103060RankingJfSph-2.683e-15-4.144e-11-1.836e-07-5.554e-082.683e-15-4.144e-11-1.836e-07-5.554e-084.144e-114.144e-11-1.835e-07-5.549e-081.836e-071.836e-071.835e-071.281e-075.554e-085.554e-085.549e-08-1.281e-0760 > 90 > 30fRas-5.79e+00-6.72e+00-1.01e+01-1.51e+015.79e+00-9.31e-01-4.30e+00-9.32e+006.72e+009.31e-01-3.37e+00-8.39e+001.01e+014.30e+003.37e+00-5.02e+001.51e+019.32e+008.39e+005.02e+0090 > 60 >30 >0.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0030.0000.0000.0000.003> 10 > 50.0000.0000.0000.0000.0000.8070.0000.0000.0000.8070.0000.0000.0000.0000.0000.0000.0000.0000.0000.00010 > 55fGri-7.207E-030.174-3.896E-030.8642.329E-031.0008.649E-030.0017.207E-030.1743.311E-030.9839.535E-030.5331.586E-020.0003.896E-030.864-3.311E-030.9836.225E-030.9301.254E-020.000-2.329E-031.000-9.535E-030.533-6.225E-030.9306.320E-030.884-8.649E-030.001-1.586E-020.000-1.254E-020.000-6.320E-030.88460 905 > 9010 > 9030 > 90JfSchDS-2.540e-020.000-1.899e-010.000-2.371e-010.000-1.004e+000.0002.540e-020.000-1.645e-010.000-2.117e-010.000-9.785e-010.0001.899e-010.0001.645e-010.000-4.720e-020.572-8.140e-010.0002.371e-010.0002.117e-010.0004.720e-020.572-7.668e-010.0001.004e+000.0009.785e-010.0008.140e-010.0007.668e-010.00090 > 30 > 10 > 560 > 5fSch-2.691e+020.082-7.338e+020.000-9.559e+020.000-1.148e+030.0002.691e+020.082-4.647e+020.000-6.868e+020.000-8.786e+020.0007.338e+020.0004.647e+020.000-2.221e+020.000-4.139e+020.0009.559e+020.0006.868e+020.0002.221e+020.000-1.918e+020.0001.148e+030.0008.786e+020.0004.139e+020.0001.918e+020.00090 > 60 > 30 > 510 5fFle-2.776e+030.885-7.968e+030.004-7.342e+030.008-1.268e+040.0002.776e+030.885-5.192e+030.234-4.566e+030.378-9.899e+030.0067.968e+030.0045.192e+030.2346.254e+021.000-4.707e+030.6787.342e+030.0084.566e+030.378-6.254e+021.000-5.333e+030.4911.268e+040.0009.899e+030.0064.707e+030.6785.333e+030.49110 530 > 560 > 590 > 5JfRos-9.433e-01-1.486e+00-1.058e+00-8.375e-019.433e-01-5.425e-01-1.142e-011.058e-011.486e+005.425e-014.283e-016.483e-011.058e+001.142e-01-4.283e-012.200e-018.375e-01-1.058e-01-6.483e-01-2.200e-0130 > 60 > 100.0000.0000.0000.0000.0000.0000.0250.0140.0000.0000.0000.0000.0000.0250.0000.0000.0000.0140.0000.000> 90 > 5fAck-1.063e-070.000-2.384e-050.000-1.508e-030.000-6.769e-020.2161.063e-070.000-2.373e-050.000-1.508e-030.000-6.769e-020.2162.384e-050.0002.373e-050.000-1.484e-030.000-6.767e-020.2161.508e-030.0001.508e-030.0001.484e-030.000-6.619e-020.2426.769e-020.2166.769e-020.2166.767e-020.2166.619e-020.24260 > 30 > 10 > 590 5fLan-1.354e-020.998-5.881e-020.009-8.794e-020.000-1.142e-010.0001.354e-020.998-4.527e-020.082-7.440e-020.000-1.007e-010.0005.881e-020.0094.527e-020.082-2.913e-020.354-5.540e-020.0008.794e-020.0007.440e-020.0002.913e-020.354-2.627e-020.2471.142e-010.0001.007e-010.0005.540e-020.0002.627e-020.24710 530 > 560 > 590 > 5Table 12: Results functions multiple comparison test rankingobtained depending number best individuals n.32fiCIXL2: Crossover Operator Evolutionary AlgorithmsJ0.700.900.950.990.900.700.950.990.950.700.900.990.990.700.900.95RankingJfSph-1.361e-08-4.394e-08-1.302e-071.361e-08-3.033e-08-1.166e-074.394e-083.033e-08-8.628e-081.302e-071.166e-078.628e-080.0000.0000.0000.0000.0000.0000.0000.0000.0190.0000.0000.0190.99 > 0.95 > 0.90 > 0.70JfSchDS-3.985e-01-3.783e-028.165e-023.985e-013.607e-014.802e-013.783e-02-3.607e-011.195e-01-8.165e-02-4.802e-01-1.195e-010.0000.9670.1140.0000.0010.0000.9670.0010.0130.1140.0000.0130.90 > 0.95 > 0.99JfRos-1.360e-01-1.693e-01-1.813e-011.360e-01-3.333e-02-4.533e-021.693e-013.333e-02-1.200e-021.813e-014.533e-021.200e-020.2810.1310.3100.2810.9950.9960.1310.9951.0000.3100.9961.0000.99 0.95 0.90 0.700.70 0.990.700.900.950.990.900.700.950.990.950.700.900.990.990.700.900.95Ranking0.700.900.950.990.900.700.950.990.950.700.900.990.990.700.900.95RankingfRas-4.23e+00-3.59e+00-5.56e+004.23e+006.40e-01-1.33e+003.59e+00-6.40e-01-1.97e+005.56e+001.33e+001.97e+000.0000.0000.0000.0000.9660.5510.0000.9660.0440.0000.5510.0440.99 > 0.95 > 0.700.90 > 0.70fGri-7.196E-03-2.027E-03-5.667E-037.196E-035.168E-031.529E-032.027E-03-5.168E-03-3.640E-035.667E-03-1.529E-033.640E-030.3950.9450.1550.3950.7911.0000.9450.7910.7470.1551.0000.7470.90 0.99 0.95 0.70fSch1.198e+028.247e+01-3.008e+02-1.198e+02-3.736e+01-4.206e+02-8.247e+013.736e+01-3.833e+023.008e+024.206e+023.833e+020.7140.9190.0010.7140.9970.0000.9190.9970.0000.0010.0000.0000.70 0.95 0.900.99 > 0.90fFle-2.986e+03-3.241e+03-3.079e+032.986e+03-2.547e+02-9.255e+013.241e+032.547e+021.622e+023.079e+039.255e+01-1.622e+020.7170.6350.6440.7171.0001.0000.6351.0001.0000.6441.0001.0000.95 0.99 0.90 0.70fAck-2.471e-04-1.944e-02-3.541e-022.471e-04-1.919e-02-3.516e-021.944e-021.919e-02-1.597e-023.541e-023.516e-021.597e-020.0000.6170.3820.0000.6310.3900.6170.6310.9850.3820.3900.9850.99 0.95 0.700.90 > 0.70fLan6.105e-032.867e-023.309e-02-6.105e-032.257e-022.698e-02-2.867e-02-2.257e-024.415e-03-3.309e-02-2.698e-02-4.415e-030.9980.2720.1330.9980.5850.3630.2720.5851.0000.1330.3631.0000.70 0.90 0.95 0.99Table 13: Results functions multiple comparison test rankingobtained depending confidence coefficient 1 .33fiOrtiz-Boyer, Hervas-Martnez, & Garca-PedrajasCrossoverJCIXL2BLX(0.3)BLX(0.5)SBX(2)SBX(5)FuzzyLogicalUNDXFunctionfSphfSchDSfRosBLX(0.3)BLX(0.5)SBX(2)SBX(5)FuzzyLogicalUNDXCIXL2BLX(0.5)SBX(2)SBX(5)FuzzyLogicalUNDXCIXL2BLX(0.3)SBX(2)SBX(5)FuzzyLogicalUNDXCIXL2BLX(0.3)BLX(0.5)SBX(5)FuzzyLogicalUNDXCIXL2BLX(0.3)BLX(0.5)SBX(2)FuzzyLogicalUNDXCIXL2BLX(0.3)BLX(0.5)SBX(2)SBX(5)LogicalUNDXCIXL2BLX(0.3)BLX(0.5)SBX(2)SBX(5)FuzzyUNDXCIXL2BLX(0.3)BLX(0.5)SBX(2)SBX(5)FuzzyLogicalfSphJ3.109e-161.628e-16-1.644e-12-4.873e-12-2.102e-15-3.689e-13-2.910e-05-3.109e-16-1.480e-16-1.644e-12-4.873e-12-2.413e-15-3.692e-13-2.910e-05-1.628e-161.480e-16-1.644e-12-4.873e-12-2.265e-15-3.690e-13-2.910e-051.644e-121.644e-121.644e-12-3.229e-121.642e-121.275e-12-2.910e-054.873e-124.873e-124.873e-123.229e-124.871e-124.504e-12-2.910e-052.102e-152.413e-152.265e-15-1.642e-12-4.871e-12-3.668e-13-2.910e-053.689e-133.692e-133.690e-13-1.275e-12-4.504e-123.668e-13-2.910e-052.910e-052.910e-052.910e-052.910e-052.910e-052.910e-052.910e-05fSchDSJfRosJ0.0000.2120.0000.0000.0000.0000.0000.0000.0740.0000.0000.0000.0000.0000.2120.0740.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.000-1.583e-020.000-4.283e+000.997-7.337e-030.028-6.667e+000.933-2.014e-010.000-2.809e+000.958-3.913e-010.000-6.165e+000.944-3.968e+010.000-2.487e+001.000-1.098e+010.000-2.092e+000.000-2.080e+010.000-3.460e+000.0001.583e-020.0004.283e+000.9978.495e-030.357-2.384e+001.000-1.855e-010.0001.473e+001.000-3.755e-010.000-1.882e+001.000-3.966e+010.0001.796e+001.000-1.097e+010.0002.191e+001.000-2.078e+010.0008.225e-011.0007.337e-030.0286.667e+000.933-8.495e-030.3572.384e+001.000-1.940e-010.0003.857e+001.000-3.840e-010.0005.019e-011.000-3.967e+010.0004.179e+001.000-1.098e+010.0004.575e+001.000-2.079e+010.0003.206e+001.0002.014e-010.0002.809e+000.9581.855e-010.000-1.473e+001.0001.940e-010.000-3.857e+001.000-1.900e-010.115-3.355e+001.000-3.948e+010.0003.222e-011.000-1.078e+010.0007.179e-011.000-2.060e+010.000-6.508e-011.0003.913e-010.0006.165e+000.9443.755e-010.0001.882e+001.0003.840e-010.000-5.019e-011.0001.900e-010.1153.355e+001.000-3.929e+010.0003.678e+001.000-1.059e+010.0004.073e+001.000-2.041e+010.0002.705e+001.0003.968e+010.0002.487e+001.0003.966e+010.000-1.796e+001.0003.967e+010.000-4.179e+001.0003.948e+010.000-3.222e-011.0003.929e+010.000-3.678e+001.0002.870e+010.0003.957e-011.0001.888e+010.000-9.730e-011.0001.098e+010.0002.092e+000.0001.097e+010.000-2.191e+001.0001.098e+010.000-4.575e+001.0001.078e+010.000-7.179e-011.0001.059e+010.000-4.073e+001.000-2.870e+010.000-3.957e-011.000-9.812e+000.000-1.369e+000.0002.080e+010.0003.460e+000.0002.078e+010.000-8.225e-011.0002.079e+010.000-3.206e+001.0002.060e+010.0006.508e-011.0002.041e+010.000-2.705e+001.000-1.888e+010.0009.730e-011.0009.812e+000.0001.369e+000.000RankingU N DX > SBX(5) > SBX(2) > Logical > Ext.F. > CIXL2 BLX(0.5) BLX(0.3)Ext.F. > U N DX > Logical > SBX(5) SBX(2) > BLX(0.3) BLX(0.5) > CIXL2BLX(0.5) SBX(5) BLX(0.3) U N DX SBX(2) Ext.F. Logical > CIXL2Table 14: Results multiple comparison tests fSph , fSchDS fRos functionsranking established test regarding crossover operator.34fiCIXL2: Crossover Operator Evolutionary AlgorithmsCrossoverJCIXL2BLX(0.3)BLX(0.5)SBX(2)SBX(5)FuzzyLogicalUNDXFunctionfRasfSchfAckBLX(0.3)BLX(0.5)SBX(2)SBX(5)FuzzyLogicalUNDXCIXL2BLX(0.5)SBX(2)SBX(5)FuzzyLogicalUNDXCIXL2BLX(0.3)SBX(2)SBX(5)FuzzyLogicalUNDXCIXL2BLX(0.3)BLX(0.5)SBX(5)FuzzyLogicalUNDXCIXL2BLX(0.3)BLX(0.5)SBX(2)FuzzyLogicalUNDXCIXL2BLX(0.3)BLX(0.5)SBX(2)SBX(5)LogicalUNDXCIXL2BLX(0.3)BLX(0.5)SBX(2)SBX(5)FuzzyUNDXCIXL2BLX(0.3)BLX(0.5)SBX(2)SBX(5)FuzzyLogicalfRasJ7.296e-01-9.950e-02-1.552e+01-1.128e+01-1.953e+01-6.033e+01-1.078e+02-7.296e-01-8.291e-01-1.625e+01-1.201e+01-2.026e+01-6.106e+01-1.085e+029.950e-028.291e-01-1.542e+01-1.118e+01-1.943e+01-6.023e+01-1.077e+021.552e+011.625e+011.542e+014.245e+00-4.013e+00-4.481e+01-9.227e+011.128e+011.201e+011.118e+01-4.245e+00-8.258e+00-4.905e+01-9.651e+011.953e+012.026e+011.943e+014.013e+008.258e+00-4.079e+01-8.826e+016.033e+016.106e+016.023e+014.481e+014.905e+014.079e+01-4.746e+011.078e+021.085e+021.077e+029.227e+019.651e+018.826e+014.746e+01fSchJfAckJ0.9231.0000.0000.0000.0000.0000.0000.9230.7130.0000.0000.0000.0000.0001.0000.7130.0000.0000.0000.0000.0000.0000.0000.0000.0050.0420.0000.0000.0000.0000.0000.0050.0000.0000.0000.0000.0000.0000.0420.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0000.0002.715e+020.000-2.830e-080.0002.210e+020.010-5.090e-080.000-8.287e+020.000-5.322e-060.000-4.631e+020.000-9.649e-060.000-2.408e+030.000-1.659e-070.000-1.988e+030.000-2.517e-060.000-7.409e+030.000-3.550e-020.000-2.715e+020.0002.830e-080.000-5.050e+011.000-2.261e-080.000-1.100e+030.000-5.293e-060.000-7.346e+020.000-9.620e-060.000-2.680e+030.000-1.376e-070.000-2.260e+030.000-2.488e-060.000-7.680e+030.000-3.550e-020.000-2.210e+020.0105.090e-080.0005.050e+011.0002.261e-080.000-1.050e+030.000-5.271e-060.000-6.841e+020.000-9.598e-060.000-2.629e+030.000-1.150e-070.000-2.209e+030.000-2.466e-060.000-7.630e+030.000-3.550e-020.0008.287e+020.0005.322e-060.0001.100e+030.0005.293e-060.0001.050e+030.0005.271e-060.0003.655e+020.006-4.327e-060.000-1.579e+030.0005.156e-060.000-1.159e+030.0002.805e-060.000-6.580e+030.000-3.550e-020.0004.631e+020.0009.649e-060.0007.346e+020.0009.620e-060.0006.841e+020.0009.598e-060.000-3.655e+020.0064.327e-060.000-1.945e+030.0009.483e-060.000-1.525e+030.0007.132e-060.000-6.946e+030.000-3.550e-020.0002.408e+030.0001.659e-070.0002.680e+030.0001.376e-070.0002.629e+030.0001.150e-070.0001.579e+030.000-5.156e-060.0001.945e+030.000-9.483e-060.0004.199e+020.000-2.351e-060.000-5.001e+030.000-3.550e-020.0001.988e+030.0002.517e-060.0002.260e+030.0002.488e-060.0002.209e+030.0002.466e-060.0001.159e+030.000-2.805e-060.0001.525e+030.000-7.132e-060.000-4.199e+020.0002.351e-060.000-5.421e+030.000-3.550e-020.0007.409e+030.0003.550e-020.0007.680e+030.0003.550e-020.0007.630e+030.0003.550e-020.0006.580e+030.0003.550e-020.0006.946e+030.0003.550e-020.0005.001e+030.0003.550e-020.0005.421e+030.0003.550e-020.000RankingU N DX > Logical > Ext.F. > SBX(2) > SBX(5) > BLX(0.5) CIXL2 BLX(0.3)U N DX > Ext.F. > Logical > SBX(2) > SBX(5) > CIXL2 > BLX(0.5) BLX(0.3)U N DX > SBX(5) > SBX(2) > Logical > Ext.F. > BLX(0.5) > BLX(0.3) > CIXL2Table 15: Results multiple comparison tests fRas , fSch fAck functionsranking established test regarding crossover operator.35fiOrtiz-Boyer, Hervas-Martnez, & Garca-PedrajasCrossoverJCIXL2BLX(0.3)BLX(0.5)SBX(2)SBX(5)FuzzyLogicalUNDXFunctionfGrifF lefLanBLX(0.3)BLX(0.5)SBX(2)SBX(5)FuzzyLogicalUNDXCIXL2BLX(0.5)SBX(2)SBX(5)FuzzyLogicalUNDXCIXL2BLX(0.3)SBX(2)SBX(5)FuzzyLogicalUNDXCIXL2BLX(0.3)BLX(0.5)SBX(5)FuzzyLogicalUNDXCIXL2BLX(0.3)BLX(0.5)SBX(2)FuzzyLogicalUNDXCIXL2BLX(0.3)BLX(0.5)SBX(2)SBX(5)LogicalUNDXCIXL2BLX(0.3)BLX(0.5)SBX(2)SBX(5)FuzzyUNDXCIXL2BLX(0.3)BLX(0.5)SBX(2)SBX(5)FuzzyLogicalfGriJ-3.224e-02-2.235e-02-6.710e-03-1.603e-021.394e-029.173e-03-6.312e-023.224e-029.893e-032.553e-021.621e-024.618e-024.142e-02-3.088e-022.235e-02-9.893e-031.564e-026.320e-033.629e-023.152e-02-4.077e-026.710e-03-2.553e-02-1.564e-02-9.320e-032.065e-021.588e-02-5.641e-021.603e-02-1.621e-02-6.320e-039.320e-032.997e-022.520e-02-4.709e-02-1.394e-02-4.618e-02-3.629e-02-2.065e-02-2.997e-02-4.763e-03-7.706e-02-9.173e-03-4.142e-02-3.152e-02-1.588e-02-2.520e-024.763e-03-7.229e-026.312e-023.088e-024.077e-025.641e-024.709e-027.706e-027.229e-02fFleJfLanJ0.0210.0120.9730.1670.0000.0570.0000.0211.0000.1880.9520.0000.0010.2520.0121.0000.3611.0000.0000.0000.0030.9730.1880.3610.9800.0000.0030.0000.1670.9521.0000.9800.0000.0010.0000.0000.0000.0000.0000.0000.0250.0000.0570.0010.0000.0030.0010.0250.0000.0000.2520.0030.0000.0000.0000.000-4.779e+021.0009.384e-020.091-2.789e+031.0001.392e-010.007-1.740e+040.034-1.253e-021.000-1.810e+040.022-1.982e-021.000-1.686e+031.000-1.000e-010.000-1.196e+040.709-2.064e-010.000-1.947e+040.0096.557e-031.0004.779e+021.000-9.384e-020.091-2.311e+031.0004.540e-021.000-1.693e+040.046-1.064e-010.046-1.763e+040.029-1.137e-010.013-1.208e+031.000-1.938e-010.000-1.148e+040.888-3.003e-010.000-1.899e+040.012-8.728e-020.1512.789e+031.000-1.392e-010.0072.311e+031.000-4.540e-021.000-1.461e+040.179-1.518e-010.004-1.531e+040.121-1.591e-010.0011.104e+031.000-2.392e-010.000-9.169e+031.000-3.457e-010.000-1.668e+040.054-1.327e-010.0121.740e+040.0341.253e-021.0001.693e+040.0461.064e-010.0461.461e+040.1791.518e-010.004-7.002e+021.000-7.285e-031.0001.572e+040.095-8.747e-020.0085.446e+031.000-1.939e-010.000-2.061e+031.0001.909e-021.0001.810e+040.0221.982e-021.0001.763e+040.0291.137e-010.0131.531e+040.1211.591e-010.0017.002e+021.0007.285e-031.0001.642e+040.063-8.018e-020.0046.146e+031.000-1.866e-010.000-1.361e+031.0002.637e-021.0001.686e+031.0001.000e-010.0001.208e+031.0001.938e-010.000-1.104e+031.0002.392e-010.000-1.572e+040.0958.747e-020.008-1.642e+040.0638.018e-020.004-1.027e+041.000-1.064e-010.000-1.778e+040.0271.066e-010.0001.196e+040.7092.064e-010.0001.148e+040.8883.003e-010.0009.169e+031.0003.457e-010.000-5.446e+031.0001.939e-010.000-6.146e+031.0001.866e-010.0001.027e+041.0001.064e-010.000-7.507e+031.0002.130e-010.0001.947e+040.009-6.557e-031.0001.899e+040.0128.728e-020.1511.668e+040.0541.327e-010.0122.061e+031.000-1.909e-021.0001.361e+031.000-2.637e-021.0001.778e+040.027-1.066e-010.0007.507e+031.000-2.130e-010.000RankingU N DX BLX(0.3) BLX(0.5) SBX(5) SBX(2) CIXL2 Logical > Ext.F.U N DX SBX(5) SBX(2) Logical BLX(0.5) Ext.F. BLX(0.3) CIXL2Logical > Ext.F. > SBX(5) SBX(2) CIXL2 U N DX BLX(0.3) BLX(0.5)Table 16: Results multiple comparison tests fGri , fF le fLan functionsranking established test regarding crossover operator.36fiCIXL2: Crossover Operator Evolutionary AlgorithmsJCIXL2U DAcEGN ABGeCIXL2EGN ABGeCIXL2U DAcU DAcEGN ABGeFunctionfSchDSfRosfRasfSchCIXL2U DAcEGN ABGeFunctionfAckfGrifF lefLanJJJfSchDSfRosfRas-2.221e+01 0.000 -2.928e+00 0.000 -1.547e+02-2.076e-01 0.000 -2.906e+00 0.000 -1.533e+022.221e+01 0.000 2.928e+00 0.000 1.547e+022.200e+01 0.000 2.207e-02 0.856 1.360e+002.076e-01 0.000 2.906e+00 0.000 1.533e+02-2.200e+01 0.000 -2.207e-02 0.856 -1.360e+00RankingU DAc > EGNBGeJfSch-1.089e+04-1.091e+041.089e+04-2.390e+011.091e+042.390e+010.0000.0000.0000.6770.0000.677fLan0.004-3.306e-020.150-3.306e-020.0043.306e-020.049 1.33781e-110.1503.306e-020.049 -1.33781e-110.1760.1760.1760.3250.1760.3250.0000.0000.0000.8880.0000.888> CIXL2U DAc EGN> CIXL2BGeU DAc EGN> CIXL2BGeEGNU DAcEGN ABGeCIXL2EGN ABGeCIXL2U DAcfAck-1.101e-08-9.194e-091.101e-081.817e-099.194e-09-1.817e-090.0000.0000.0000.1750.0000.175BGefGri1.525e-021.525e-02-1.525e-021.266e-16-1.525e-02-1.266e-16U DAc > CIXL2fFle0.000 9.803e+030.000 6.157e+030.000 -9.803e+030.000 -3.646e+030.000 -6.157e+030.000 3.646e+03RankingU DAc EGNBGe> CIXL2CIXL2 > U DAc > EGNBGeCIXL2 EGN> U DAcBGeU DAc EGNCIXL2BGeTable 17: Results functions multiple comparison test rankingobtained depending evolutionary algorithm.37fiOrtiz-Boyer, Hervas-Martnez, & Garca-PedrajasAppendix B. Convergence GraphicsAverage fitness best individual 30 runs100CIXL2(0.70,5)BLX(0.3)SBX(2)FuzzyLogicalUNDX10.010.00011e-061e-081e-101e-121e-141e-16050000100000150000200000250000300000EvaluationsFigure 5: Evolution average fitness, logarithmic scale, using different crossoveroperators function fSph .Average fitness best individual 30 runs100000CIXL2(0.70,5)BLX(0.5)SBX(2)FuzzyLogicalUNDX1000010001001010.10.010.001050000100000150000Evaluations200000250000300000Figure 6: Evolution average fitness, logarithmic scale, using different crossoveroperators function fSchDS .38fiCIXL2: Crossover Operator Evolutionary AlgorithmsAverage fitness best individual 30 runs1000CIXL2(0.70,5)BLX(0.3)SBX(2)FuzzyLogicalUNDX10010050000100000150000200000250000300000EvaluationsFigure 7: Evolution averaged fitness, logarithmic scale, using different crossoveroperators function fRos .Average fitness best individual 30 runs1000CIXL2(0.70,5)BLX(0.3)SBX(5)FuzzyLogicalUNDX100101050000100000150000Evaluations200000250000300000Figure 8: Evolution average fitness, logarithmic scale, using different crossoveroperators function fRas .39fiOrtiz-Boyer, Hervas-Martnez, & Garca-PedrajasAverage fitness best individual 30 runs100000CIXL2(0.70,5)BLX(0.3)SBX(5)FuzzyLogicalUNDX100001000100050000100000150000200000250000300000EvaluationsFigure 9: Evolution average fitness, logarithmic scale, using different crossoveroperators function fSch .Average fitness best individual 30 runs100CIXL2(0.70,5)BLX(0.3)SBX(2)FuzzyLogicalUNDX10.010.00011e-061e-08050000100000150000Evaluations200000250000300000Figure 10: Evolution average fitness, logarithmic scale, using different crossoveroperators function fAck .40fiCIXL2: Crossover Operator Evolutionary AlgorithmsAverage fitness best individual 30 runs100CIXL2(0.70,5)BLX(0.5)SBX(2)FuzzyLogicalUNDX1010.10.010.001050000100000150000200000250000300000EvaluationsFigure 11: Evolution average fitness, logarithmic scale, using different crossoveroperators function fGri .Average fitness best individual 30 runs1e+07CIXL2(0.70,5)BLX(0.3)SBX(2)FuzzyLogicalUNDX1e+0610000010000050000100000150000Evaluations200000250000300000Figure 12: Evolution average, logarithmic scale, using different crossover operatorsfunction fF le .41fiOrtiz-Boyer, Hervas-Martnez, & Garca-PedrajasAverage fitness best individual 30 runs10.010.00011e-061e-081e-10CIXL2(0.70,5)BLX(0.3)SBX(5)FuzzyLogicalUNDX1e-121e-14050000100000150000Evaluations200000250000300000Figure 13: Evolution average fitness, logarithmic scale, using different crossoveroperators function fLan .42fiCIXL2: Crossover Operator Evolutionary AlgorithmsReferencesAckley, D. (1987). empirical study bit vector function optimizacion. Genetic Algorithms Simulated Annealing, 170215.Andersen, H. C., & Tsoi, A. C. (1993). constructive algorithm trainingmultilayer pereptron based genetic algorithm. Complex Systems, 7 (4), 249268.Arabas, J., Michalewicz, Z., & Mulawka, J. (1994). Gavaps - genetic algorithmvarying population size. Michalewicz, Z., Krawczyk, J., Kazemi, M., & Janikow,C. (Eds.), First IEEE International Conference Evolutionary Computation, Vol. 1,pp. 7378, Orlando. IEEE Service Center, Piscataway, NJ.Bebis, G., Georgiopoulos, M., & Kasparis, T. (1997). Coupling weight elimination genetic algorithms reduce network size preserve generalization. Neurocomputing,17, 167194.Bebis, G., Louis, S., Varol, Y., & Yfantis, A. (2002). Genetic object recognition usingcombinations views. IEEE Transactions Evolutionary Computation, 6 (2), 132.Bengoetxea, E., & Miquelez, T. (2002). Estimation distribution algorithms: new toolevolutionary computation (D.E. Goldberg edition)., Vol. 2 Genetic algorithmsevolutionary computation, chap. Experimental result function optimizationEDAs continuous Domain. Kluwer.Bersini, H., Dorigo, M., Langerman, S., Seront, G., & Gambardella, L. M. (1996). Resultsfirst international contest evolutionary optimisation (1st iceo). ProceedingsIEEE International Conference Evolutionary Computation, IEEE-EC 96, pp.611615, Nagoya, Japan. IEEE Press.Beyer, H.-G., & Deb, K. (2001). self-adapting features real-parameter evolutionaryalgorithms. IEEE Transactions evolutionary computation, 5 (3), 250270.Breiman, L. (1996). Stacked regressions. Machine Learning, 24 (1), 4964.Back, J. H. (1996). Evolutionary Algorithms Theory Practice. Oxford UniversityPress, Oxford.Back, T., Fogel, D., & Michalewicz, Z. (1997). Handbook Evolutionary Computation.Institute Physics Publishing Ltd, Bristol Oxford University Press, New York.Back, T., & Schwefel, H. P. (1993). overview evolutionary algorithms parameteroptimization. Evolutionary Computation, 1 (1), 123.Cano, J., Herrera, F., & Lozano, M. (2003). Using evolutionary algorithms instanceselection data reduction kdd: experimental study. IEEE TransactionsEvolutionary Computation, 7 (6), 561575.Davidor, Y. (1991). Genetic Algorithms Robotics: Heuristic Strategy Optimization,Vol. 1 Robotics Automated Systems. World Scientific.De Jong, K. D. (1975). analysis behavior class genetic adaptive systems.Ph.D. thesis, Departament Computer Communication Sciences, UniversityMichigan, Ann Arbor.43fiOrtiz-Boyer, Hervas-Martnez, & Garca-PedrajasDe Jong, M. B., & Kosters, W. (1998). Solving 3-sat using adaptive sampling. Poutre,H., & van den Herik, J. (Eds.), Proceedings Tenth Dutch/Belgian ArtificialIntelligence Conference, pp. 221228.Deb, K., & Agrawal, R. B. (1995). Simulated binary crossover continuous search space.Complex Systems, 9, 115148.Deb, K., & Beyer, H. (2001). Self-adaptive genetic algorithms simulated binarycrossover. Evolutionary Computation, 9 (2), 195219.Dixon, L. C. W. (1974). Nonlinear optimization: survey state art. SoftwareNumerical Mathematics, 193216. Academic Press.Dunn, O. J., & Clark, V. (1974). Applied Statistics: Analysis Variance Regression.Wiley, New York.Eiben, A., & Back, T. (1997a). Multi-parent recombination operators continuous searchspaces. Tech. rep. TR-97-01, Leiden University.Eiben, A. E., & Back, T. (1997b). Empirical investigation multi-parent recombinationoperators evolution strategies. Evolutionary Computation, 5 (3), 347365.Eiben, A., van der Hauw, J., & van Hemert, J. (1998). Graph coloring adaptiveevolutionary algorithms. Journal Heuristics, 4 (1), 2546.Eshelman, L. J., & Schaffer, J. D. (1993). Real-coded genetic algorithms intervalschemata. Whitley, L. D. (Ed.), Foundation Genetic Algorithms 2, pp.187C3.3.7:1C3.3.7:8.202, San Mateo. Morgan Kaufmann.Fletcher, R., & Powell, M. J. D. (1963). rapidly convergent descent method minimization. Computer Journal, pp. 163168.Fogel, D. B. (1995). Evolutionary Computation: Toward New Philosophy MachineIntelligence. IEEE Press, Piscataway, New Jork.Fogel, L. J., Owens, A. J., & Walsh, M. J. (1966). Artificial Intelligence SimulatedEvolution. John Wiley & Sons.Friedman, J. H. (1994). overview predictive learning function approximation.Cherkassky, V., Friedman, J. H., & Wechsler, H. (Eds.), Statistics NeuralNetworks, Theory Pattern Recognition Applications, Vol. 136 NATO ASI SeriesF, pp. 161. Springer-Verlag.Garca-Pedrajas, N., Hervas-Martnez, C., & Ortiz-Boyer, D. (2005). Cooperative coevolution artificial neural network ensembles pattern classification. IEEE Transactions Evolutionary Computation, 9 (3), 271302.Goldberg, D. E. (1989a). Genetic Algorithms Search, Optimization, Machine Learning. Addison-Wesley, New York.Goldberg, D. E. (1989b). Sizing populations serial parallel genetic algorithms.Schaffer, J. (Ed.), 3rd International Conference Genetic Algorithms, pp. 7079,San Mateo, CA. Morgan Kaufmann.Goldberg, D. E. (1991). Real-coded genetic algorithms, virtual alphabets, blocking.Complex Systems, pp. 139167.44fiCIXL2: Crossover Operator Evolutionary AlgorithmsGoldberg, D. E., & Deb, K. (1991). comparative analysis selection schemes usedgenetic algorithms. Rawlins, G. J. E. (Ed.), Foundations Genetic Algorithms,pp. 6993, San Mateo, CA. Morgan Kaufmann.Gordon, V. S., & Whitley, D. (1993). Serial parallel genetic algorithms functionoptimizers. Forrest, S. (Ed.), Fifth International Conference Genetic Algorithms,pp. 177183. Morgan Kaufmann.Grefenstette, J. J. (1986). Optimization control parameters genetic algorithms. IEEETransactions Systems, Mans, Cybernetics, 16 (1), 122128.Hadley, G. (1964). Nonlinear Dynamics Programming. Addison Wesley.Hashem, S. (1997). Optimal linear combinations neural networks. Neural Networks,10 (4), 599614.Herrera, F., Herrera-Viedma, E., Lozano, E., & Verdegay, J. L. (1994). Fuzzy toolsimprove genetic algorithms. Second European Congress Intelligent TechniquesSoft Computing, pp. 15321539.Herrera, F., & Lozano, M. (2000). Gradual distributed real-coded genetic algorithms. IEEETransactions Evolutionary Computation, 4 (1), 4363.Herrera, F., Lozano, M., & Sanchez, A. M. (2003). taxonomy crossover operatorreal-coded genetic algorithms: experimental study. International JournalIntelligent Systems, 18, 309338.Herrera, F., Lozano, M., & Verdegay, J. L. (1998). Tackling real-coded genetic algorithms:Operators tools behavioural analysis. Artificial Inteligence Review, pp. 265319. Kluwer Academic Publisher. Printed Netherlands.Hervas-Martnez, C., & Ortiz-Boyer, D. (2005). Analizing statistical features cixl2crossover offspring. Soft Computing, 9 (4), 270279.Holland, J. H. (1975). Adaptation natural artificial systems. UniversityMichigan Press, Ann Arbor, MI.Johnson, T., & Husbands, P. (1990). System identification using genetic algorithms.Parallel Problem Solving Nature, Vol. 496 Lecture Notes Computer Science,pp. 8589, Berlin. Springer-Verlag.Jong, K. A. D., & Sarma, J. (1993). Generation gaps revisited. Whitley, L. D. (Ed.),Foundations Genetic Algorithms, Vol. 2, pp. 1928. Morgan Kaufmann, San Mateo.Kendall, M., & Stuart, S. (1977). advanced theory statistics, Vol. 1. Charles GriOEn& Company.Kita, H. (2001). comparison study self-adaptation evolution strategies real-codegenetic algorithms. Evolutionary Computation, 9 (2), 223241.Kita, H., Ono, I., & Kobayashi, S. (1998). Theoretical analysis unimodal normal distribution crossover real-coded genetic algorithms. IEEE International ConferenceEvolutionary Computation ICEC98, pp. 529534, Anchorage, Alaska, USA.Kivinen, J., & Warmuth, M. (1997). Exponential gradient descent versus gradient descentlinear predictors. Information Computation, 132 (1), 163.45fiOrtiz-Boyer, Hervas-Martnez, & Garca-PedrajasKuncheva, L. (1995). Editing k-nearest neighbors rule genetic algorithm.Pattern Recognition Letter, 16, 809814.Larranaga, P., Etxeberria, R., Lozano, J., & Pena, J. (2000). Optimization continuousdomains learning simulation gaussian networks. Wu, A. (Ed.), Proceeding2000 Genetic Evolutionary Computation Conference Workshop Program,pp. 201204.Leblanc, M., & Tibshirani, R. (1993). Combining estimates regression classification.Tech. rep., Department Statistics, University Toronto.Levene, H. (1960). Contributions Probability Statistics, chap. Essays HonorHarold Hotelling, pp. 278292. Stanford University Press.Liu, Y., Yao, X., & Higuchi, T. (2000). Evolutionary ensembles negative correlationlearning. IEEE Transactions Evolutionary Computation, 4 (4), 380387.Merz, C. J. (1999a). principal components approach combining regression estimates.Machine Learning, 36 (1), 932.Merz, C. J. (1999b). Using correspondence analysis combine classifiers. Machine Learning, 36 (1), 3358.Michalewicz, Z. (1992). Genetic Algorithms + Data Structures = Evolution Programs.Springer-Verlag, New York.Miller, G. F., Todd, P. M., & Hedge, S. U. (1991). Designing neural networks. NeuralNetworks, 4, 5360.Miller, R. G. (1981). Simultaneous Statistical Inference (2 edition). Wiley, New York.Miller, R. G. (1996). Beyond ANOVA, Basics Applied Statistics (2 edition). Chapman& Hall, London.Mizumoto, M. (1989). Pictorial representations fuzzy connectives. part i: Cases tnorms, t-conorms averaging operators. Fuzzy Sets Systems, 31, 217242.Moriarty, D., Schultz, A., & Grefenstette, J. (1999). Evolutionary algorithms reinforcement learning. Journal Artificial Intelligence Reserarch, 11.Muhlenbein, H., Mahnig, T., & Rodriguez, O. (1999). Schemata, distributions graphicalmodels evolutionary optimazation. Journal Heuristics, pp. 215247.Muhlenbein, H., & Paa, G. (1998). recombination genes estimationdistributions i. binary parameters.. Eiben, A. E., Back, T., Schoenauer, M., &Schwefel, H.-P. (Eds.), 5th Conference Parallel Problem Solving Nature,pp. 178187. Springer.Ono, I., Kita, H., & Kobayashi, S. (1999). robust real-coded genetic algorithm usingunimodal normal distribution crossover augmented uniform crossover: Effectsself-adaptation crossover probabilities. Banzhaf, W., Daida, J., Eiben, A. E.,Garzon, M. H., Honavar, V., Jakiela, M., & Smith, R. E. (Eds.), Genetic Evolutionary Computation Conf. (GECCO99), pp. 496503, San Francisco, CA. MorganKaufmann.46fiCIXL2: Crossover Operator Evolutionary AlgorithmsOno, I., & Kobayashi, S. (1997). real-coded genetic algorithm function optimizationusing unimodal normal distribution crossover. 7th International ConferenceGenetic Algorithms, pp. 246253, Michigan, USA. Michigan State University, MorganKaufman.Ono, I., Kobayashi, S., & Yoshida, K. (2000). Optimal lens design real-coded geneticalgorithms using undx. Computer methods applied mechanics engineering, pp.483497.Opitz, D. W., & Shavlik, J. W. (1996). Actively searching effective neural networkensemble. Connection Science, 8 (3), 337353.Oren, S. S. (1974). selection parameters self scaling variable metric algorithms.Mathematical Programming, pp. 351367.Ortiz-Boyer, D., Hervas-Martnez, C., & Munoz-Perez, J. (2003). Metaheuristics: ComputerDecision-Making, chap. Study genetic algorithms crossover based confidenceintervals alternative classic least squares estimation methods non-linearmodels, pp. 127151. Kluwer Academic Publishers.Perrone, M. P., & Cooper, L. N. (1993). networks disagree: Ensemble methodshybrid neural networks. Mammone, R. J. (Ed.), Neural Networks SpeechImage Processing, pp. 126142. Chapman Hall.Rastrigin, L. A. (1974). Extremal control systems. Theoretical Foundations Engineering Cybernetics Series. Moscow: Nauka, Russian.Rechenberg, I. (1973). Evolutionsstrategie-Optimierum technischer Systeme nach Prinzipien der biologischen Evolution. Ph.D. thesis, Stuttgart-Bad Cannstatt: FrommannHolzboog.Rosenbrock, H. H. (1960). automatic method finding greatest least valuefunction. Computer Journal, pp. 175184.Rudolph, G. (1994). Convergence analysis canonical genetic algorithms. IEEE Transactions Neural Networks, special issue evolutionary computation, 5 (1), 96101.Salomon, R. (1996). Reevaluating genetic algorithm performance coordinate rotationbenchmark functions. BioSystems, pp. 263278.Satoh, H., Yamamura, M., & Kobayashi, S. (1996). Minimal generation gap modelgas considering exploration exploitation.. Proceeding IIZUKA:Methodologies Conception, Design, Application Intelligent Sstems, pp.494497.Schaffer, J., Caruana, R., Eshelman, L., & Das, R. (1989). study control parameters affecting online performance genetic algorithms function optimization.Schaffer, J. (Ed.), 3rd International Conference Genetic Algorithms, pp. 5160,San Mateo, CA. Morgan Kaufmann.Schlierkamp-Voosen, D. (1994). Strategy adaptation competition. Second EuropeanCongress Intelligent Techniques Soft Computing, pp. 12701274.47fiOrtiz-Boyer, Hervas-Martnez, & Garca-PedrajasSchwefel, H. P. (1981). Numerical Optimization Computer Models. John Wiley & Sons.English translation Numerische Optimierung von Computer-Modellen mittels derEvolutionsstrategie, 1977.Schwefel, H. P. (1995). Evolution Optimum Seeking. John Wiley & Sons.Sedighi, K., Ashenayi, K., Manikas, T., Wainwright, R., & Tai, H. (2004). Autonomouslocal path planning mobile robot using genetic algorithm. IEEE CongressEvolutionary Computation.Sharkey, A. J. C. (1996). combining artificial neural nets. Connection Science, 8,299313.Singh, M., Chatterjee, A., & Chaudhury, S. (1997). Matching structural shape descriptionsusing genetic algorithms. Pattern Recognition, 30 (9), 14511462.Smith, R. E. (1993). Adaptively resizing populations: algorithm analysis. Forrest,S. (Ed.), 5th International Conference Genetic Algorithms, p. 653, San Mateo, CA.Morgan Kaufmann.Snedecor, G. W., & Cochran, W. G. (1980). Statistical Methods (7 edition). Iowa StateUniversity Press, Ames, Iowa.Spedicato, E. (1975). Computational experience quasi-newton algorithms minimization problems moderately large size. Tech. rep. CISE-N-175, Centro InformazioniStudi Esperienze, Segrate (Milano), Italy.Takahashi, O., Kita, H., & Kobayashi, S. (1999). distance dependent alternation modelreal-coded genetic algorithms. IEEE International Conference Systems, Man,Cybernetics, pp. 619624.Tamhane, A. C., & Dunlop, D. D. (2000). Statistics Data Analysis. Prentice Hall.Voigt, H. M., Muhlenbein, H., & Cvetkovic, D. (1995). Fuzzy recombination breedergenetic algorithms. Eshelman, L. (Ed.), 6th International Conference GeneticAlgorithms, pp. 104111, San Mateo, CA. Morgan Kaufmann.Webb, G. I. (2000). Multiboosting: technique combining boosting wagging.Machine Learning, 40 (2), 159196.Whitley, D., Mathias, K., Rana, S., & Dzubera, J. (1995). Building better test functions.Eshelman, L. (Ed.), Sixth International Conference Genetic Algorithms, pp.239246. Morgan Kaufmann.Wolpert, D. H., & Macready, W. G. (1995). free-lunch theorems search. Tech. rep.95-02-010, Santa Fe Institute.Wright, A. (1991). Genetic algorithms real parameter optimization. Rawlin, G.J. E. (Ed.), Foundations Genetic Algorithms 1, pp. 205218, San Mateo. MorganKaufmann.Zhang, B. T., & Kim, J. J. (2000). Comparison selection methods evolutionaryoptimization. Evolutionary Optimization, 2 (1), 5570.Zhou, Z.-H., Wu, J., & Tang, W. (2002). Ensembling neural networks: Many could betterall. Artificial Intelligence, 137 (12), 239253.48fifiJournal Artificial Intelligence Research 24 (2005) 623-639Submitted 12/04; published 11/05Hiding Satisfying Assignments: Two Better OneDimitris Achlioptasoptas@microsoft.comMicrosoft ResearchRedmond, WashingtonHaixia Jiahjia@cs.unm.eduComputer Science DepartmentUniversity New MexicoCristopher Mooremoore@cs.unm.eduComputer Science DepartmentUniversity New MexicoAbstractevaluation incomplete satisfiability solvers depends critically availabilityhard satisfiable instances. plausible source instances consists random kSAT formulas whose clauses chosen uniformly among clauses satisfyingrandomly chosen truth assignment A. Unfortunately, instances generated mannertend relatively easy solved efficiently practical heuristics. Roughlyspeaking, number different algorithms, acts stronger stronger attractorformulas density increases. Motivated recent results geometry spacesatisfying truth assignments random k-SAT NAE-k-SAT formulas, introducesimple twist basic model, appears dramatically increase hardness.Namely, addition forbidding clauses violated hidden assignment A, alsoforbid clauses violated complement, satisfying.appears symmetrization effects two attractors largely cancelout, making much harder algorithms find truth assignment. give theoreticalexperimental evidence supporting assertion.1. IntroductionRecent years witnessed rapid development application search methodsconstraint satisfaction Boolean satisfiability. important factor successalgorithms availability good sets benchmark problems evaluate fine-tunethem. two main sources problems: real world, random instancegenerators. Real-world problems arguably best benchmarks, unfortunatelyshort supply. Moreover, using real-world problems carries risk tuning algorithmstoward specific application domains good benchmarks available.sense, random instance generators good additional source, advantagecontrollable characteristics, size expected hardness.Hard random instances led development new stochastic search methodsWalkSAT (Selman, Kautz, & Cohen, 1996), breakout procedure (Morris, 1993),Survey Propagation (Mezard & Zecchina, 2002), used detailed comparisons local search methods graph coloring related problems (Johnson, Aragon,McGeoch, & Shevon, 1989). results various competitions CSP SAT algoc2005AI Access Foundation. rights reserved.fiAchlioptas, Jia, & Moorerithms show fairly direct correlation performance real-world benchmarkshard random instances (Johnson & Trick, 1996; Du, Gu, & Pardalos, 1997; Johnsonet al., 1989). Nevertheless, key limitation current problem generators concerns useevaluating incomplete satisfiability solvers based local search methods.incomplete algorithm find solution, difficult determinewhether instance fact unsatisfiable, simply algorithmfailed find satisfying assignment. standard way dealing problemuse complete search method filter unsatisfiable cases. However, greatlylimits size difficulty problem instances considered. Ideally, one woulduse problem generators generate satisfiable instances only. One relatively recent sourceproblems quasigroup completion problem (Shaw, Stergiou, & Walsh, 1998;Achlioptas, Gomes, Kautz, & Selman, 2000; Kautz, Ruan, Achlioptas, Gomes, Selman, &Stickel, 2001). However, generator random hard satisfiable instances 3-SAT, say,remained elusive.Perhaps natural candidate generating random hard satisfiable 3-SAT formulas following. Pick random truth assignment A, generate formulan variables rn random clauses, rejecting clause violated A. particular,might hope work close satisfiability threshold region r 4.25,hardest random 3-SAT problems seem (Cheeseman, Kanefsky, & Taylor, 1991; Hogg,Huberman, & Williams, 1996; Mitchell, Selman, & Levesque, 1992), would generatehard satisfiable instances. Unfortunately, generator highly biased towards formulasmany assignments clustered around A. given local search methodsWalkSAT, resulting formulas turn much easier formulas comparablesize obtained filtering satisfiable instances 3-SAT generator. sophisticatedversions hidden assignment scheme (Asahiro, Iwama, & Miyano, 1996; Van Gelder,1993) improve matters somewhat still lead easily solvable formulas.paper introduce new generator random satisfiable problems. ideasimple: pick random 3-SAT formula hidden complementary pairsatisfying assignments, A, rejecting clauses violated either A.call 2-hidden formulas. motivation comes recent work (Achlioptas &Moore, 2002b, 2005) showed moving random k-SAT random NAE-kSAT (in every clause formula must least one true least one falseliteral) tremendously reduces correlation solutions. is, whereas randomk-SAT, satisfying assignments tend form clumps, random NAE-k-SAT solutionsappear scattered throughout {0, 1} n rather uniform mist, even densitiesextremely close threshold. intuitive explanation phenomenon sincecomplement every NAE-assignment also NAE-assignment, attractionssolution pairs largely cancel out. paper exploit phenomenon imposesimilar symmetry hidden assignments A, attractions cancelout, making hard wide variety algorithms feel either one.particularly nice feature generator based extremely simpleprobabilistic procedure, sharp contrast 3-SAT generators based on, say, cryptographic ideas (Massacci, 1999). particular, generator readily amenablemathematical tools developed rigorous study random k-SATformulas. make two first steps direction. Section 2, via first mo624fiHiding Satisfying Assignments: Two Better Onement calculation study distribution number solutions functiondistance hidden assignments. Section 3, use technique differentialequations analyze performance Unit Clause (UC) heuristic formulas.Naturally, mathematical simplicity would worth much formulas producedgenerator easily solvable. Section 4, compare experimentally hardness2-hidden formulas 1-hidden 0-hidden formulas. is, compareformulas random 3-SAT formulas one hidden assignment standardrandom 3-SAT formulas hidden assignment. examine four leading algorithms:two complete solvers, zChaff Satz, two incomplete ones, WalkSAT recentlyintroduced Survey Propagation (SP).algorithms, find formulas much harder 1-hiddenformulas and, importantly, hard 0-hidden formulas, sizedensity.2. picture space solutionssection compare 1-hidden 2-hidden formulas respect expectednumber solutions given distance hidden assignment(s).2.1 1-hidden formulasLet X number satisfying truth assignments random k-SAT formula nvariables = rn clauses chosen uniformly independently among k-clausesleast one positive literal, i.e., 1-hidden formulas hide allones truth assignment. calculate expectation E[X], helpful parametrize truth assignmentsaccording overlap hidden assignment, i.e., fraction variablesagree A, case fraction variables set one.Then, linearity expectation gives (1), clause independence gives (2), selecting literalsclause uniformly independently gives (3), and, finally, writing z = n usingStirlings approximation factorial gives (4) below:XE[X] =Pr[A satisfying](1)A{0,1}nnXnPr[a truth assignment z ones satisfies random clause] (2)zz=0knX1 X kn(3)(1 z/n)j (z/n)kj1 k=jz2 1z=0j=1nXn1 (z/n)k=1z2k 1z=0r n1 k1(4)= poly(n) max1 k2 1[0,1] (1 )1== poly(n) max [fk,r ()]n[0,1]625fiAchlioptas, Jia, & Moore1fk,r () =(1 )11 k1 k2 1r.calculation see E[X] dominated contribution truth assignments maximize fk,r () (since raise fk,r nth power contributionsvanish). Now, note f product entropic factor 1/( (1 )1 )symmetric around = 1/2, correlation factor strictly increasing .result, always maximized > 1/2. means dominant contribution E[X] comes truth assignments agree hidden assignmenthalf variables. is, set solutions dominated truth assignmentsfeel hidden assignments. Moreover, r increases phenomenon becomesacute (see Figure 1 below).2.2 2-hidden formulaslet X number satisfying truth assignments random k-SAT formulan variables = rn clauses chosen uniformly among k-clauses leastone positive least one negative literal, i.e., 2-hidden formulas hideones assignment complement. compute E[X] proceed above, except(3) replacedk1nXXk1n(1 z/n)j (z/n)kj .1 kjz2 2z=0j=1Carrying ensuing changes findE[X] = poly(n) max [gk,r ()]n[0,1]1gk,r () =(1 )11 k (1 )k12k 2r.time, entropic factor correlation factor comprising g symmetricfunctions , gk,r symmetric around = 1/2 (unlike f k,r ). Indeed, one prover extremely close random k-SAT threshold r k , function gk,rglobal maximum = 1/2. words, r, dominant contributionE[X] comes truth assignments distance n/2 hidden assignments, i.e.,hidden assignments felt. precisely, exists sequence k 0gk,r unique global maximum = 1/2,r 2k ln 2ln 21 k .2(5)Contrast fact (implicit Kirousis, Kranakis, Krizanc, & Stamatiou, 1998)ln 2 1r 2k ln 2,(6)22626fiHiding Satisfying Assignments: Two Better Onerandom k-SAT formula n variables = rn clauses unsatisfiable probability 1 o(1). Moreover, convergence sequence k 0 rapid, seenconcrete values table 1. Thus gap values r given equations (5)(6) quickly converges 1/2, even threshold becomes exponentially large.kEq. (5)Eq. (6)37/24.67435/410.23520.3821.33787.2387.8810708.40708.9420726816.15726816.66Table 1: convergence (in k) asymptotic gap 1/2 rapidFigure 1 plot fk,r gk,r k = 5 r = 16, 18, 20, 22, 24 (from topbottom). see case 1-hidden formulas, i.e., f k,r , maximum alwaysoccurs right = 1/2. Moreover, observe r = 22, 24, i.e., cross5-SAT threshold (which occurs r 21) dramatic shift locationmaximum and, thus, extent bias. Specifically, since expected numbersatisfying assignments roughly f k,r ()n , since fk,r () < 1 except 1,high probability remaining satisfying assignments limit nextremely close hidden assignment.case 2-hidden formulas, hand, see r = 16, 18, 20global maximum occurs = 1/2. r = 20, threshold, alsotwo local maxima near = 0, 1, since g k,r raised nth power,exponentially suppressed. Naturally, r threshold, i.e., r = 22, 24, localmaxima become global, signifying indeed remaining truth assignmentsextremely close one two hidden ones.Intuitively, expect g flat = 1/2 random truth assignmentsconcentrated, 2-hidden formulas local search algorithms like WalkSAT essentiallyperform random walk lucky enough get close one two hiddenassignments. Thus expect WalkSAT take long 2-hidden formulas0-hidden ones. 1-hidden formulas, contrast, expect nonzero gradient f= 1/2 provide strong hint WalkSAT move towards hiddenassignment, therefore 1-hidden formulas much easier solve.see experimental results bear intuitions perfectly.3. Unit Clause heuristic DPLL algorithmsConsider following linear-time heuristic, called Unit Clause (UC), permanentlysets one variable step follows: pick random literal satisfy it, repeatedlysatisfy 1-clauses present. Chao Franco showed UC succeeds constantprobability random 3-SAT formulas r < 8/3, fails high probability, i.e.,probability 1 o(1) n , r > 8/3 (Chao & Franco, 1986). One thinkUC first branch simplest possible DPLL algorithm S: set variables randomorder, time choosing randomly branch take first. result showsthat, constant probability, solves random 3-SAT formulas r < 8/3backtracking all.627fiAchlioptas, Jia, & Moore1.31.21.110.90.80.7r=16r=18r=20r=22r=240.60.50.400.20.40.60.811-hidden formulas1.25r=16r=18r=20r=22r=241.21.151.11.0510.950.900.20.40.60.812-hidden formulasFigure 1: nth root expected number solutions f k,r gk,r 1-hidden2-hidden formulas respectively, function overlap fraction = z/nhidden assignment. k = 5 r = 16, 18, 20, 22, 24 top bottom.628fiHiding Satisfying Assignments: Two Better Oneconjectured running time goes linear exponential r = 8/3,intermediate regime. Calculations using techniques statistical physics (Cocco& Monasson, 2001a, 2001b; Monasson, 2005) show true expected runningtime. Achlioptas, Beame Molloy show running time exponential highprobability r > 3.81; moreover, show tricritical point (2 + p)-SATr = 2/5, case r > 8/3 (Achlioptas, Beame, & Molloy, 2001).section analyze performance UC 1-hidden 2-hidden formulas.Specifically, show UC fails 2-hidden formulas precisely density0-hidden ones. Based this, conjecture running time S, simpleDPLL algorithms, becomes exponential 2-hidden formulas density0-hidden ones.analyze UC random 1-hidden 2-hidden formulas actually analyze UCarbitrary initial distributions 3-clauses, i.e., 0 j 3 specify initialnumber 3-clauses j positive literals 3 j negative ones. use methoddifferential equations; see article Achlioptas(2001) review. simplify notation,assume allones assignment, 1-hidden formulas forbid clausesliterals negative, 2-hidden formulas forbid all-negative all-positive clauses.round UC consists free step, satisfy random literal,ensuing chain forced steps unit-clause propagations. 0 3 0 j i,let Si,j = si,j n number clauses length j positive literalsP j negativeones. also refer total density clauses size = j si,j . Let X = xnnumber variables set far. goal write expected changevariables given round function values beginning round. Notebeginning round 1,0 = S1,1 = 0 definition, state spaceanalysis consist variables i,j 2.convenient define two new quantities, mF , expectednumber variables set True False round. calculate below. Then,terms mT , mF ,3s3,j1x2s2,j(j + 1)s3,j+1(3 j)s3,jE[S2,j ] = (mT + mF )+ mF+ mT1x1x1xE[X] = (mT + mF ) .E[S3,j ] = (mT + mF )(7)(8)see this, note variable appears positively clause type i, j probabilityj/(n X), negatively probability (i j)/(n X). Thus, negative terms (7)(8) correspond clauses hit variables set, positive termflow 3-clauses 2-clauses.calculate mT mF , consider process unit clauses createdround. model two-type branching process, analyzearticle Achlioptas Moore(2002a). Since free step gives chosenvariable random value, think creating unit clause, positivenegative equal probability. Thus initial expected population unit clauses629fiAchlioptas, Jia, & Moorerepresented vectorp0 =1/21/2first second components count negative positive unit clauses respectively. Moreover, time X = xn, unit clause procreates according matrix1s2,1 2s2,0.M=1 x 2s2,2 s2,1words, satisfying negative unit clause creates, expectation, 1,1 = s2,1 /(1 x)negative unit clauses M2,1 = 2s2,2 /(1 x) positive unit clauses, similarlysatisfying positive unit clause.Thus, long largest eigenvalue 1 less 1, expected numbervariables set true false round givenmF= (I + + 2 + ) p0 = (I )1 p0mTidentity matrix. Moreover, long 1 < 1 throughout algorithm, i.e.,long branching process subcritical x, UC succeeds constant probability.hand, 1 ever exceeds 1, branching process becomes supercritical,high probability unit clauses proliferate, algorithm fails. Notes2,1 + 2 s2,0 s2,2.(9)1 =1xlet us rescale (7) give system differential equations i,j . WormaldsTheorem (Wormald, 1995) implies high probability random variables i,j (xn)within o(n) si,j (x) n x, si,j (x) solution following:ds3,jdxds2,jdx3s3,j1x2s2,j(j + 1)s3,j+1(3 j)s3,jmFmT=++1 x mT + F1xmT + F1x=(10)Now, suppose initial distribution 3-clauses symmetric, i.e., 3,0 (0) = s3,3 (0)s3,1 (0) = s3,2 (0). easy see (10) case, 3-clauses2-clauses symmetric times, i.e., i,j = si,ij mF = mT . cases2,1 + 2 s2,0 s2,2 = s2 , criterion subcriticality becomes1 =s2<1 .1xMoreover, since system (10) symmetric respect j, summing j givesdifferential equationsds3dxds2dx3s31x2s23s3=+1 x 2(1 x)=630fiHiding Satisfying Assignments: Two Better Oneprecisely differential equations UC 0-hidden formulas, i.e., randominstances 3-SAT.Since 2-hidden formulas correspond symmetric initial conditions, thus shownUC succeeds constant probability r < 8/3, i.e., UC failsformulas exactly density fails random 3-SAT instances.(In contrast, integrating (10) initial conditions corresponding 1-hidden formulasshows UC succeeds slightly higher density, r < 2.679.)course, UC easily improved making free step intelligent:instance, choosing variable according number occurrences formula,using majority occurrences decide truth value. best knownheuristic type (Kaporis, Kirousis, & Lalas, 2003; Hajiaghayi & Sorkin, 2003) succeedsconstant probability r < 3.52. However, believe much progressmade analyzing performance algorithms pushed2-hidden formulas. Specifically, nearly algorithms analyzed far propertygiven input symmetric initial distribution 3-clauses, e.g. random 3-SAT,residual formulas consist symmetric mixes 2- 3-clauses. result, conjecturemethods used show algorithms act 2-hidden formulasexactly 0-hidden ones, failing high probability density.generally, call DPLL algorithm myopic splitting rule consists choosingrandom clause given size, based current distribution clause sizes, decidingsatisfy based number occurrences variables clauses.given myopic algorithm A, let r density succeeds withoutbacktracking constant probability. results Achlioptas, Beame Molloy (2001)imply following statement: tricritical point random (2 + p)-SAT p c = 2/5every myopic algorithm takes exponential time r > r . Thus, UC,fact large class natural DPLL algorithms, would go linear time r < rexponential time r > rA . fact linear-time heuristics correspondingfirst branch act 2-hidden formulas 0-hidden ones suggests that,wide variety DPLL algorithms, 2-hidden formulas become exponentially harddensity 0-hidden ones. Proving this, indeed proving 2-hidden formulas takeexponential time r critical density, appears us promising directionfuture work.4. Experimental resultssection report experimental results 2-hidden formulas, compare1-hidden 0-hidden ones. use two leading complete solvers, zChaff Satz,two leading incomplete solvers, WalkSAT new Survey Propagation algorithmSP. attempt avoid numerous spurious features present too-small randominstances, i.e., non-asymptotic behavior, restricted attention experimentsn 1000. meant zChaff Satz could examined densities significantly satisfiability threshold, neither algorithm could practically solve either0-hidden 2-hidden formulas n 1000 variables close threshold. WalkSATSP, hand, easily run experiments hardest range (aroundsatisfiability threshold) n 10 4 .631fiAchlioptas, Jia, & Moore4.1 zChaff Satzorder experiments n 1000 zChaff Satz, focusedregime r relatively large, 20 < r < 60. stated above, r near satisfiabilitythreshold, 0-hidden 2-hidden random formulas n 1000 variables seem completelyreach either algorithm. formulas overconstrained regime stillchallenging, presence many forced steps allows solvers completely explorespace fairly quickly.obtained zChaff Princeton web site (Moskewicz, Madigan, Zhao, Zhang,& Malik, 2001). first part Figure 2 shows performance random formulasthree types (with n = 1000 20 r 40 n = 3000 40 n 60). seenumber decisions three types problems decreases rapidly r increases,consistent earlier findings complete solvers random 3-SAT formulas.Figure 2 shows zChaff finds 2-hidden formulas almost difficult 0-hidden ones,range r unsatisfiable overwhelming probability.hand, 1-hidden formulas much easier, number branchings 25 orders magnitude smaller. appears zChaffs smarts allow quicklyzero single hidden assignment, attractions exerted complementary pairassignments indeed cancel out, making 2-hidden formulas almost hard unsatisfiableones. is, algorithm eventually stumbles upon one two hidden assignmentssearch nearly exhaustive unsatisfiable random 3-SAT formulasdensity.obtained Satz SATLIB web site (Li & Anbulagan, 1997b). secondpart Figure 2 shows experiments random formulas three types n = 3000.seen, median number branches explored Satz three typesformulas within factor five, 0-hidden hardest 2-hiddeneasiest (note factor five corresponds setting fewer 3 variables).reason simple: Satz makes intelligent decisions variablebranch on, tries branches fixed order, attempting first set variablefalse (Li & Anbulagan, 1997a). Therefore, single hidden assignment appearuniformly random leaf Satzs search tree. 2-hidden case, since two hiddenassignments complementary, one appear random position onesymmetric position respect search tree. Naturally, trying branchesfixed order good idea goal prove formula unsatisfiable, e.g.hardware verification. However, expect Satz modified to, say, usemajority heuristic choose variables first value, performance three typesproblems would similar zChaffs.4.2 SPSP incomplete solver recently introduced Mezard Zecchina (2002) basedgeneralization belief propagation authors call survey propagation. inspiredphysical notion replica symmetry breaking observation 3.9 < r < 4.25,random 3-SAT formulas appear satisfiable, satisfying assignments appearorganized clumps.632fiHiding Satisfying Assignments: Two Better OneMedian number decisions 25 trials610510zChaff performance HIDDEN 1, 2 0 formulasHIDDEN1HIDDEN2HIDDEN0410310210110205Median number branches 25 trials1025303540r45505560Satz performance HIDDEN 1, 2 0 formulasHIDDEN1HIDDEN2HIDDEN04103102101102025303540r45505560Figure 2: median number branchings made zChaff Satz random instances0, 1, 2 hidden assignments (on log 10 scale). zChaff usen = 1000 r = 20, 30, 40 n = 3000 r = 40, 50, 60, Satzuse n = 3000 throughout. point median 25 trials. 2-hiddenformulas almost hard algorithms 0-hidden ones,1-hidden formulas much easier zChaff.633fiAchlioptas, Jia, & Moore1SP performance HIDDEN 1, 2 0 formulasfraction solved 30 trials0.90.80.70.60.5HIDDEN0HIDDEN1HIDDEN20.40.30.20.1044.55r5.56Figure 3: fraction problems successfully solved SP function density,n = 104 30 trials value r. threshold solving 2-hiddenformulas somewhat higher 0-hidden ones, 1-hidden formulashigher still.Figure 3 compare SPs performance three types problems nearsatisfiability threshold. (Because SP takes roughly time inputs,compare running times.) n = 10 4 SP solves 2-hidden formulas densitiessomewhat threshold, r 4.8, solves 1-hidden formulas stillhigher densities, r 5.6.Presumably 1-hidden formulas easier SP since messages clausesvariables, like majority heuristic, tend push algorithm towards hiddenassignment. two hidden assignments appears cancel messagesextent, causing SP fail lower density. However, argument explainSP succeed densities satisfiability threshold; explainSP solve 1-hidden formulas arbitrarily large r. Indeed, find latterresult surprising, since r increases majority clauses pointconsistently towards hidden assignment 1-hidden case.note also performed experiments n = 2 10 45000 iterations, instead default 1000, SPs convergence procedure. thresholdsFigure 3 1-hidden 2-hidden formulas appeared stablechanges, suggesting merely artifacts particular experiments.propose investigating thresholds direction work.4.3 WalkSATconclude local search algorithm, WalkSAT. Unlike complete solvers, WalkSATsolve problems n = 104 fairly close threshold. performed experimentsrandom initial state, biased initial state algorithm starts75% agreement one hidden assignments (note exponentially634fiHiding Satisfying Assignments: Two Better Oneunlikely). cases, performed trials 10 8 flips formula, without randomrestarts, step random greedy flip equal probability. Since randominitial states almost certainly roughly 50% agreement hidden assignments,expect attractions cancel WalkSAT difficulty finding eitherthem. hand, begin biased initial state, attractionnearby assignment much stronger one; situation similar1-hidden formula, expect WalkSAT find easily. Indeed data confirmsexpectations.first part Figure 4 measure WalkSATs performance three typesproblems n = 104 r ranging 3.7 7.9, compare 0-hiddenformulas r ranging 3.7 4.1, threshold becomeunsatisfiable. see that, threshold, 2-hidden formulas hard0-hidden ones WalkSAT sets initial state randomly; indeed, running timescoincide within resolution figure! become hardest r 4.2,108 flips longer suffice solve them. Unsurprisingly, 2-hidden formulas mucheasier solve start biased initial state, case running timecloser 1-hidden formulas.second part Figure 4, compare three types formulas densityclose threshold, r = 4.25, measure running times functionn. data suggests 2-hidden formulas random initial states much harder1-hidden ones, 2-hidden formulas biased initial states running timeswithin constant 1-hidden formulas. Note median running timethree types problems polynomial n, consistent earlier experiments (Barthel,Hartmann, Leone, Ricci-Tersenghi, Weigt, & Zecchina, 2002).hand, 1-hidden formulas much easier 2-hidden onessufficiently large small r, appear slightly harder 2-hidden ones 5.3 <r < 6.3. One possible explanation i) solutions 2-hiddenformula harder find due balanced distribution, ii) exponentiallysolutions 2-hidden formulas 1-hidden ones size density.seems range r, second effect overwhelms first, WalkSAT findssolution quickly 2-hidden case; explanationparticular range r. higher densities, r = 8 shown Figure 5, 2-hiddenformulas appear harder 1-hidden ones.5. Conclusionsintroduced extremely simple new generator random satisfiable 3-SAT instances amenable mathematical tools developed rigorous studyrandom 3-SAT instances. Experimentally, generator appears produce instanceshard random 3-SAT instances, sharp contrast instances single hiddenassignment. hardness appears quite robust; experiments demonstratedsatisfiability threshold, algorithms use differentstrategies, i.e., DPLL solvers (zChaff Satz), local search algorithms (WalkSAT),survey propagation (SP).635fiAchlioptas, Jia, & Moore7Median number flips 100 trials10WalkSAT performance HIDDEN 1, 2 0 formulasHIDDEN0HIDDEN1HIDDEN2 init 75% trueHIDDEN26105104103103Median number flips 100 trials10 71061051045r678WalkSAT performance function nslope 2.8HIDDEN0HIDDEN2HIDDEN1HIDDEN2 init 75% trueslope 2.7slope 1.34103102slope 1.3110100200400n8001600Figure 4: top part figure shows median number flips needed WalkSATformulas three types threshold, n = 10 4 .threshold, 2-hidden formulas hard 0-hidden ones (theycoincide within resolution figure) running time increasessteeply approach threshold. Except range 5.3 < r < 6.3, 2hidden formulas much harder 1-hidden ones unless algorithm starts(exponentially lucky) biased initial state. bottom part figureshows median number flips needed WalkSAT solve three typesformulas r = 4.25 function n. n ranges 100 2000.median running time three polynomial, 2-hidden problemsmuch harder 1-hidden ones unless start biased initial state.Again, running time 2-hidden problems scales similarly 0-hidden ones,i.e., random 3-SAT without hidden assignment.636fiHiding Satisfying Assignments: Two Better OneWalkSAT performance HIDDEN 1 2 formulas r=86Median number flips 100 trials10HIDDEN1HIDDEN2510410310210110 2103104N10Figure 5: median number flips needed WalkSAT solve two types formulasr = 8, range 1-hidden formulas harder. densities,2-hidden formulas harder 1-hidden ones, although mucheasier densities closer threshold.believe random 2-hidden instances could make excellent satisfiable benchmarks,especially around satisfiability threshold, say r = 4.25 appearhardest WalkSAT (although beating SP requires somewhat higher densities).Several aspects experiments suggest exciting directions work, including:1. Proving expected running time natural Davis-Putnam algorithms 2hidden formulas exponential n r critical density.2. Explaining different threshold behaviors SP 1-hidden 2-hidden formulas.3. Understanding long WalkSAT takes midpoint two hidden assignments, becomes sufficiently unbalanced converge one them.4. Studying random 2-hidden formulas dense case number clausesgrows linearly n.ReferencesAchlioptas, D. (2001). Lower bounds random 3-SAT via differential equations. Theor.Comp. Sci., 265, 159185.Achlioptas, D., Beame, P., & Molloy, M. (2001). sharp threshold proof complexity.Proc. STOC, pp. 337346.Achlioptas, D., Gomes, C., Kautz, H., & Selman, B. (2000). Generating satisfiable probleminstances. Proc. AAAI, pp. 256261.637fiAchlioptas, Jia, & MooreAchlioptas, D., & Moore, C. (2002a). Almost graphs average degree 4 3colorable. Proc. STOC, pp. 199208.Achlioptas, D., & Moore, C. (2002b). asymptotic order random k-SAT threshold.Proc. FOCS, pp. 779788.Achlioptas, D., & Moore, C. (2005). Two moments suffice cross sharp threshold.SIAM J. Comput. appear.Asahiro, Y., Iwama, K., & Miyano, E. (1996). Random generation test instancescontrolled attributes. DIMACS Series Disc. Math. Theor. Comp. Sci., 26,377393.Barthel, W., Hartmann, A., Leone, M., Ricci-Tersenghi, F., Weigt, M., & Zecchina, R.(2002). Hiding solutions random satisfiability problems: statistical mechanicsapproach. Phys. Rev. Lett., 88 (188701).Chao, M., & Franco, J. (1986). Probabilistic analysis two heuristics 3-satisfiabilityproblem. SIAM J. Comput., 15 (4), 11061118.Cheeseman, P., Kanefsky, R., & Taylor, W. (1991). really hard problems are.Proc. IJCAI, pp. 163169.Cocco, S., & Monasson, R. (2001a). Statistical physics analysis computational complexity solving random satisfiability problems using backtrack algorithms. Eur.Phys. J. B, 22, 505531.Cocco, S., & Monasson, R. (2001b). Trajectories phase diagrams, growth processescomputational complexity: search algorithms solve 3-satisfiability problem.Phys. Rev. Lett, 86, 16541657.Du, D., Gu, J., & Pardalos, P. (1997). Dimacs workshop satisfiability problem, 1996.DIMACS Discrete Math. Theor. Comp. Sci., Vol. 35. AMS.Hajiaghayi, M., & Sorkin, G. (2003). satisfiability threshold random 3-SATleast 3.52..Hogg, T., Huberman, B., & Williams, C. (1996). Phase transitions complexity. ArtificialIntelligence, 81. Special issue.Johnson, D., & Trick, M. (1996). Second dimacs implementation challenge, 1993. DIMACS Series Disc. Math. Theor. Comp. Sci., Vol. 26. AMS.Johnson, D., Aragon, C., McGeoch, L., & Shevon, C. (1989). Optimization simulatedannealing: experimental evaluation. Operations Research, 37 (6), 865892.Kaporis, A., Kirousis, L., & Lalas, E. (2003). Selecting complementary pairs literals.Proc. LICS Workshop Typical Case Complexity Phase Transitions.Kautz, H., Ruan, Y., Achlioptas, D., Gomes, C., Selman, B., & Stickel, . (2001). Balancefiltering structured satisfiable problems. Proc. IJCAI, pp. 351358.Kirousis, L., Kranakis, E., Krizanc, D., & Stamatiou, Y. (1998). Approximating unsatisfiability threshold random formulas. Random Structures Algorithms, 12 (3),253269.638fiHiding Satisfying Assignments: Two Better OneLi, C., & Anbulagan (1997a). Heuristics based unit propagation satisfiability problems. Proc. IJCAI, pp. 366371.Li, C., & Anbulagan (1997b). Look-ahead versus look-back satisfiability problems.Proc. 3rd Intl. Conf. Principles Practice Constraint Programming, pp. 341355.Massacci, F. (1999). Using walk-SAT rel-SAT cyptographic key search. Proc.IJCAI, pp. 290295.Mezard, M., & Zecchina, R. (2002).Random k-satisfiability: analyticsolution new efficient algorithm.Phys. Rev. E, 66.Available at:http://www.ictp.trieste.it/zecchina/SP/.Mitchell, D., Selman, B., & Levesque, H. (1992). Hard easy distributions SATproblems. Proc. AAAI, pp. 459465.Monasson, R. (2005). Average case analysis DPLL random decision problems.Proc. RANDOM.Morris, P. (1993). breakout method escaping local minima. Proc. AAAI,pp. 4045.Moskewicz, M., Madigan, C., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: engineeringefficient SAT solver. Proc. 38th Design Automation Conference, pp. 530535.Selman, B., Kautz, H., & Cohen, B. (1996). Local search strategies satisfiability testing.Proc. 2nd DIMACS Challange Cliques, Coloring, Satisfiability.Shaw, P., Stergiou, K., & Walsh, T. (1998). Arc consistency quasigroup completion.Proc. ECAI, workshop binary constraints.Van Gelder, A. (1993). Problem generator mkcnf.c. Proc. DIMACS. Challenge archive.Wormald, N. (1995). Differential equations random processes random graphs. Ann.Appl. Probab., 5 (4), 12171235.639fiJournal Artificial Intelligence Research 24 (2005) 919-931Submitted 01/05; published 12/05Engineering NoteOptiplan: Unifying IP-based Graph-based PlanningMenkes H.L. van den Brielmenkes@asu.eduDepartment Industrial EngineeringArizona State University, Tempe, AZ 85281 USASubbarao Kambhampatirao@asu.eduDepartment Computer Science EngineeringArizona State University, Tempe, AZ 85281 USAAbstractOptiplan planning system first integer programming-based plannersuccessfully participated international planning competition. engineering notedescribes architecture Optiplan provides integer programming formulationenabled perform reasonably well competition. also touch uponrecent developments make integer programming encodings significantly competitive.1. IntroductionOptiplan planning system uses integer linear programming (IP) solve STRIPSplanning problems. first system take part international planningcompetition (IPC) judged second best performer four competition domainsoptimal track propositional domains. Optiplans underlying integer programmingformulation extends state change model Vossen colleagues (1999). architecture similar Blackbox (Kautz & Selman, 1999) GP-CSP (Do &Kambhampati, 2001), instead unifying satisfiability (SAT) constraint satisfaction(CSP) graph based planning, Optiplan uses integer programming. Like BlackboxGP-CSP, Optiplan works two phases. first phase planning graph builttransformed IP formulation, second phase IP formulation solvedusing commercial solver ILOG CPLEX (ILOG Inc., 2002).practical difference original state change model Optiplanformer takes input ground actions fluents initialized plan steps,latter takes input actions fluents instantiated Graphplan(Blum & Furst, 1995). well known use planning graphs significanteffect size final encoding matter combinatorial transformation method(IP, SAT, CSP) used. instance, Kautz Selman (1999) well Kambhampati(1997) pointed Blackboxs success Satplan (Kautz & Selman, 1992) mainlyexplained Graphplans ability produce better, refined, propositional structuresSatplan. addition, Optiplan allows propositions deleted without requiredpreconditions. state changes modeled original state change model,therefore Optiplan considered general encoding. One more, althoughc2005AI Access Foundation. rights reserved.fiVan den Briel, & Kambhampatiminor, implementation detail Optiplan state change model Optiplanreads PDDL files.engineering note organized follows. Section 2 provides brief backgroundinteger programming Section 3 discusses previous IP approaches planning. Section4 describes Optiplan planning system underlying IP formulation. Section 5give experimental results look Optiplans performance internationalplanning competition 2004 (IPC4). Conclusions brief discussion recentdevelopments given Section 6.2. Backgroundlinear program represented linear objective function set inequalities,min{cx : Ax b, x 0} x n-dimensional column vector variables,n matrix, c n-dimensional row vector, b m-dimensional column vector.variables constrained integers integer (linear) program,variables restricted 0-1 values binary integer program.widely used method solving general integer programs using branchbound linear programming relaxation. Branch bound general searchmethod subproblems created restrict range integer variables,linear programming relaxation linear program obtained original integerprogram omitting integrality constraints. ideal formulation integer programone solution linear programming relaxation integral. Even thoughevery integer program ideal formulation (Wolsey, 1998), practice hardcharacterize ideal formulation may require exponential number inequalities.problems ideal formulation cannot determined, often desirable findstrong formulation integer program. Suppose P1 = min{cx : A1 x b1 , x 0}P2 = min{cx : A2 x b2 , x 0} linear programming relaxations two IPformulations problem, say formulation P1 stronger formulation P2P1 P2 . is, set solutions P1 subsumed set solutions P2 .3. Integer Programming Approaches PlanningDespite vast amount research conducted field AI planning,use linear programming (LP) integer linear programming exploredmarginal level. quite surprising since (mixed) integer linear programming providefeasible environments using numeric constraints arbitrary linear objective functions,two important aspects real-world planning problems.handful works explored use LP IP techniques AI planning.Bylander (1997) developed IP formulation classical planning used LP relaxation heuristic partial order planning. results, however, seem scalewell compared planning graph satisfiability based planners.difficulty developing strong IP formulations performance often depends way IP formulation constructed. Vossen et al. (1999) compared twoformulations classical planning. First, consider straightforward IP formulationbased converting propositional representation given Satplan (Kautz & Selman,920fiOptiplan: Unifying IP-based Graph-based Planning1992) IP formulation variables take value 1 certain propositiontrue, 0 otherwise. formulation, assertions expressed IP constraintsdirectly correspond logical conditions propositional representation. Second,consider IP formulation original propositional variables replacedstate change variables. State change variables take value 1 certain propositionadded, deleted, persisted, 0 otherwise. Vossen et al. show formulation basedstate change variables outperforms straightforward formulation based convertingpropositional representation.Dimopoulos (2001) improves IP formulation based state change variables identifying valid inequalities tighten formulation. Yet, even stronger IP formulationsgiven Bockmayr Dimopoulos (1998, 1999), IP formulations containdomain dependent knowledge are, therefore, limited solving problems specificproblem domains only.LP IP techniques also explored non-classical planning. DimopoulosGerevini (2002) describe mixed integer programming formulation temporal planning Wolfman Weld (1999) use LP formulation combination SATformulation solve resource planning problems. Kautz Walser (1999) also use IPformulations resource planning problems but, addition, incorporate action costscomplex objectives.far, none IP approaches AI planning ever participated IPC, makingharder assess relative effectiveness line work. Optiplan, planner basedstate change formulation, first IP-based planner so.4. OptiplanOptiplan planning graph based planner works follows. First buildplanning graph level goal fluents appear non-mutex. compileplanning graph integer program solve it. plan found, planninggraph extended one level new graph compiled integer programsolved again. process repeated plan found.remainder section give IP formulation used Optiplan.order present IP formulation use following notation. F set fluentsset actions (operators). fluents true initial statefluents must true goal given G respectively. Furthermore,use sets:pref A, f F, set actions fluent f precondition;addf A, f F, set actions fluent f add effect;delf A, f F, set actions fluent f delete effect;Variables defined layer 1 planning graph.variables actions variables possible state changes fluentmake, variables reachable relevant planning graph analysisinstantiated. A, 1, ..., action variables921fiVan den Briel, & Kambhampatiya,t =1 action executed period t,0 otherwise.no-op actions included ya,t variables represented separatelystate change variable xmaintain.f,tOptiplan based state change formulation (Vossen et al., 1999). formulation fluents represented explicitly, instead state change variables used modeltransitions world state. is, fluent true added statepreaddxadd, persisted previous state xmaintain. Optiplan extendsf,t xf,tf,tstate change formulation (Vossen et al., 1999) introducing extra state changevariable, xdelf,t , allows actions delete fluents without requiring preconditions.original state change formulation allow actions, therefore addednew state change variables keep track state changes altered modeltake new variables account. IPC4 domains Airport PSRmany actions delete fluents without requiring preconditions, therefore makingoriginal state change formulation ineffective. Also, Optiplan instantiatesvariables constraints reachable relevant planning graph analysis,therefore creates smaller encoding original one. f F, 1, ...,following state change variables:1 fluent f propagated period t,maintain=xf,t0 otherwise.1 action executed period pref/ delf ,preaddxf,t=0 otherwise.1 action executed period pref delf ,predelxf,t=0 otherwise.1 action executed period/ pref addf ,=xaddf,t0 otherwise.1 action executed period tsuch/ pref delf ,xdel=f,t0 otherwise.summary: xmaintain= 1 truth value fluent propagated; xpreadd= 1f,tf,taction executed requires fluent delete it; xpredel= 1 actionf,taddexecuted requires fluent deletes it; xf,t = 1 action executedrequire fluent adds it; xdelf,t = 1 action executed requirefluent deletes it. complete IP formulation Optiplan given followingobjective function constraints.4.1 Objectiveclassical AI planning problems, minimization maximization required, insteadwant find feasible solution. search solution, however, may guided922fiOptiplan: Unifying IP-based Graph-based Planningobjective function minimization number actions, currentlyimplemented Optiplan. objective function given by:minXXya,t(1)aASince constraints guarantee feasibility could used linear objective function. example, could easily set objective deal cost-sensitive plans(in context non-uniform action cost), utility-sensitive plans (in context oversubscription goal utilities), metric transformed linearexpression. Indeed flexibility handle linear objective function one advantages IP formulations.4.2 Constraintsrequirements initial goal transition given by:xaddf,0 = 1maintain preaddxadd, xf,0f,0 , xf,0maintainxadd+ xpreaddf,T + xf,Tf,Tf(2)=0f/I(3)1f G(4)constraints (2), (3) add initial fluents step 0 usedactions appear first layer (step 1) planning graph. Constraints(4) represent goal state requirements, is, fluents appear goal mustadded propagated step .state change variables linked actions following effect implicationconstraints. f F 1 have:Xya,t xadd(5)f,taaddf \prefya,t xaddf,tXya,taddf \ prefxdelf,t(6)(7)adelf \prefya,t xdelf,tXdelf \ prefya,t xpreaddf,t(8)(9)apref \delfya,t xpreaddf,tXya,t = xpredelf,tpref \ delf(10)(11)apref delfconstraints (5) (11) represent logical relations actionstate change variables. equality sign (11) actions f923fiVan den Briel, & Kambhampatiprecondition delete effect mutually exclusive. also meanssubstitute xpredelvariables, done implementationf,tOptiplan. will, however, use variables clarity. Mutexes also appeardifferent state change variables expressed constraints follows:predelmaintain1+ xdelxaddf,t + xf,tf,t + xf,t(12)predelxpreadd+ xmaintain+ xdel1f,tf,t + xf,tf,t(13)constraints (12) (13) restrict certain state changes occurring parallel.delexample, xmaintain(propagating fluent f step t) mutually exclusive xaddf,tf,t , xf,t ,xpredel(adding deleting f t).f,tFinally, backward chaining requirements binary constraints represented by:addmaintainxpreadd+ xmaintain+ xpredelxpreaddf,tf,tf,tf,t1 + xf,t1 + xf,t1f F, 1, ...,(14)del maintainxpreadd, xpredel, xadd{0, 1}f,t , xf,t , xf,tf,tf,t(15)ya,t {0, 1}(16)constraints (14) describe backward chaining requirements, is, fluentf added maintained step t1 state f changed action stepxpreadd, xpredel, propagated xmaintain. Constraints (15)f,tf,tf,t(16) binary constraints state change action variables respectively.Loc1Truck1Loc2Truck2Figure 1: simple logistics example4.3 Exampleexample, show constraints initialized commentinteraction state change variables action variables.Consider simple logistics example two locations, two trucks,one package. package transported one location another onetrucks. built formulation three plan steps. initial state package924fiOptiplan: Unifying IP-based Graph-based Planningtrucks location 1 given Figure 1. initial state constraints are:xaddpack1loc1,0xaddtruck1loc1,0addxtruck2 loc1,0add maintain preaddxf,0 , xf,0, xf,0=1=1=1=0f 6=goal get package location 2 three plan steps, expressedfollows:xaddpack1loc2,3+ xmaintainpack1loc2,3+ xpreaddpack1loc2,31write effect implication constraints, commentthem. xaddf,t = 1 certain fluent f , execute least one actionf add effect precondition. example:yunloadtruck1 loc2,t+ yunloadtruck2 loc2,txaddpack1loc2,tpreaddstate changes xdelsimilar requirement, changef,t xf,tstate del preadd must execute least one action corresponding effects. hand, execute action must changefluent states according effects a. example:yunloadtruck1 loc2,txaddpack1yunloadtruck1 loc2,tyunloadtruck1 loc2,t=loc2,tpreaddxtruck loc2,txpredelpack1 truck1,tone-to-one correspondence (note equality sign) executionactions xpredelstate change variables. because, actionsf,tpredel effect must mutex. Mutexes also present state changes. example,fluent f maintained (propagated) cannot added deleted. two statechanges mutex add preadd. add statechange behaves like preadd state change corresponding fluent already presentstate world. introduce two separate mutex constraints, oneincludes add state change one includes preadd. exampleconstraints mutex state changes follows:xaddpack1truck1,txpreaddpack1truck1,t+ xmaintainpack1truck1,t+ xdelpack1truck1,t+ xpredelpack1truck1,t1+ xmaintainpack1truck1,t+ xdelpack1truck1,t+ xpredelpack1truck1,t1state fluent change another state correct state changesoccurred previously. Hence, fluent deleted, propagated, used preconditionsstep added propagated step 1. example:xpreaddpack1predelmaintaintruck1,t + xpack1 truck1,t + xpack1 truck1,taddmaintainxpreaddpack1 truck1,t1 + xpack1 truck1,t1 + xpack1 truck1,t1925fiVan den Briel, & Kambhampatit=0xaddpack1xaddtruck1xaddtruck2loc1,0t=1yload truck1 loc1,1xaddpack1 truck1,1xpredelpack1 loc1,1xpreaddtruck1 loc1,1loc1,0xmaintaintruck2loc1,0t=2ydrive truck1 loc1 loc2,2xmaintainpack1 truck1,2xaddtruck1xpredeltruck1loc2,2t=3yunload truck1 loc2,3xaddpack1 loc2,3xpredelpack1 truck1,3xpreaddtruck1 loc2,3loc1,2loc1,1Table 1: Solution simple logistics example. displayed variables value 1variables value 0.simple problem total 107 variables (41 action 66 state change)91 constraints. However, planning graph analysis fixes 53 variables (28 action 25 statechange) zero. substituting values applying presolve techniquesbuilt ILOG CPLEX solver, problem 13 variables 17 constraints.solution example given Table 1. Note that, actionsactively delete f , nothing ensures xmaintaintrue whenever ff,ttrue preceding state (for example, see fluent truck2 loc1). Since negativepreconditions allowed, option letting xmaintainfalsef,ttrue cannot cause actions become executable be.miss solutions constraints (4) ensure goal fluents satisfied,therefore forcing xmaintaintrue whenever helps us generate plan.f,t5. Experimental ResultsFirst compare Optiplan original state change model, checkOptiplan performed IPC 2004.Optiplan original state change formulation implemented two differentlanguages. Optiplan implemented C++ using Concert Technology, setlibraries allow embed ILOG CPLEX optimizers (ILOG Inc., 2002),original state change model implemented AMPL (Fourer, Gay, & Kernighan, 1993),modeling language mathematical programming. order compareformulations produced two implementations, written outputfile using MPS format. MPS standard data format often used transferringlinear integer linear programming problems different applications.MPS file, contains IP formulation planning problem, written, readsolved ILOG CPLEX 8.1 Pentium 2.67 GHz 1.00 GB RAM.Table 3 shows encoding size two implementations, encoding sizecharacterized number variables number constraints formulation.encoding size applying ILOG CPLEX presolve given. Presolveproblem reduction technique (Brearley, Mitra, & Williams, 1975) helps linearprogramming problems simplifying, reducing eliminating redundancies. short,926fiOptiplan: Unifying IP-based Graph-based PlanningProblembw-sussmanbw-12stepbw-large-aatt-log0log-easylog-aState change modelpresolvepresolve#Var. #Cons. #Var. #Cons.486878196347390073721663310560841162826455022193231752535249214145713482168502598532436546168Optiplanpresolvepresolve#Var. #Cons. #Var. #Cons.407593105143353449988681025563986901800209611714900253430294375925746748014792313Table 2: Encoding size original state change formulation OptiplanILOG CPLEX presolve. #Var. #Cons. give number variablesconstraints respectively.Problembw-sussmanbw-12stepbw-large-abw-large-batt-log0att-log1att-log2att-log3att-log4att-logarocket-arocket-blog-easylog-alog-blog-c#Var.19616632645633125114249215121472915153216101348365442555457State change model#Cons. #Nodes3470310519502221205314350164037110368615367612496897526535172787191216843616860069893259111970Time0.014.288.45581.920.010.030.070.640.71173.5632.449.900.96145.3196.47771.36#Var.105868180047800298118136014799911071437147917182413Optiplan#Cons. #Nodes143010253720960545410003509902280507023121916447817882459202313192620187378437Time0.011.650.7272.580.010.010.010.030.042.715.483.120.042.6614.0616.07Table 3: Performance encoding size original state change formulation Optiplan. #Var. #Cons. give number variables constraintsILOG CPLEX presolve, #Nodes give number nodes exploredbranch-and-bound finding first feasible solution.927fiVan den Briel, & Kambhampatipresolve tries remove redundant constraints fixed variables formulation,aggregate (substitute out) variables possible.encoding size presolve, actual encoding size problem,see significant use planning graphs is. Optiplan, instantiatesfluents actions reachable relevant planning graphanalysis, produces encodings cases one order magnitude smallerencodings produced original state change model, instantiates groundfluents actions. Although difference encoding size reduces substantiallyapplying presolve, planning graph analysis still finds redundancies presolve failsdetect. Consequently, encodings produced Optiplan still smallerencodings produced original state change model.performance (and encoding size presolve) Optiplan originalstate change model given Table 3. Performance measured time findfirst feasible solution. results show overall effectiveness using planning graphanalysis. problems Optiplan generates smaller encodings also performsbetter encodings generated state change model.5.1 IPC ResultsOptiplan participated propositional domains optimal track IPC 2004.track, planners could either minimize number actions, like BFHSP Semsyn;minimize makespan, like CPT, HSP*a, Optiplan, Satplan04, TP-4; minimizemetric.IPC results makespan optimal planners given Figure 2. resultsevaluated competition organizers looking runtime plan quality graphs.Also, planners compared estimating asymptotic runtimeanalyzing solution quality performance. seven competition domains,Optiplan judged second best four them. quite remarkable integerprogramming hitherto considered competitive planning.Optiplan reached second place Optical Telegraph Philosopher domains.domains Optiplan one order magnitude slower Satplan04,clearly outperforms participating planners. Pipesworld Tankage domain,Optiplan awarded second place together Satplan04, Satellite domainOptiplan, CPT, Semsyn tied second place. domains Optiplanperform well. Airport domain, Optiplan solves first 17 problemsproblem 19, takes time so. Pipesworld NotankagePSR domains, Optiplan slowest also solves fewest number problemsamong participating planners.looking domains problems Optiplan difficulty scaling, noticeproblems lead large IP encodings. Since size encodingfunction plan length, Optiplan often fails solve problems long solution plans.One way resolve issue de-link encoding size solution length,done recent work (van den Briel, Vossen, & Kambhampati,2005). fact, year following IPC4 developed novel IP encodings (1)928fiOptiplan: Unifying IP-based Graph-based Planningmodel transitions individual fluents separate loosely coupled network flowproblems, (2) control encoding length generalizing notion parallelism.6. ConclusionsOptiplan planning system performs significantly better original state changemodel Vossen colleagues (1999). performed respectably IPC4, stilllags behind SAT- CSP-based planners, like Blackbox(Chaff), Satplan04(Siege),GP-CSP. believe, however, performance gap IP techniquesinferior SAT CSP, rather reflection types IP formulationstried far. Specifically, encodings triedtailored strengths IP solvers (Chandru & Hooker, 1999).experience Optiplan encouraged us continue working improved IPformulations AI planning. recent work (van den Briel, Vossen, & Kambhampati,2005) model fluents loosely coupled network flow problems control encodinglength generalizing notion parallelism. resulting IP encodings solvedwithin branch-and-cut algorithm yield impressive results. Also, new approachshown highly competitive state-of-the-art SAT-based planners.ReferencesBlum, A., & Furst, M. (1995). Fast planning planning graph analysis. Proceedings14th International Joint Conference Artificial Intelligence (IJCAI-95), pp.16361642.Bockmayr, A., & Dimopoulos, Y. (1998). Mixed integer programming models planning problems. Working notes CP-98 Constraint Problem ReformulationWorkshop.Bockmayr, A., & Dimopoulos, Y. (1999). Integer programs valid inequalities planning problems. Proceedings European Conference Planning (ECP-99),pp. 239251. Springer-Verlag.Brearley, A., Mitra, G., & Williams, H. (1975). Analysis mathematical programmingproblems prior applying simplex algorithm. Mathematical Programming, 8,5483.Bylander, T. (1997). linear programming heuristic optimal planning. AAAI97/IAAI-97 Proceedings, pp. 694699.Chandru, V., & Hooker, J. (1999). Optimization Methods Logical Inference. John Wiley& Sons, New York.Dimopoulos, Y. (2001). Improved integer programming models heuristic searchAI planning. Proceedings European Conference Planning (ECP-01), pp.301313. Springer-Verlag.929fiVan den Briel, & Kambhampati100001000010001000100Time sec.Time sec.10010Optiplan1101OptiplanSatplan040.10.1CPT0.010.01051015202530354045Satplan04CPTTP4050510100001000010001000100100Time sec.Time sec.1520253035Satellite problem nr.Airport problem nr.10Optiplan1101Satplan040.1Optiplan0.1CPTSatplan04TP4CPT0.010.010510152025303540455005102025301000100010010010Time sec.10000OptiplanSatplan041HSPS-A3456789101112 130145Satplan04CPTTP4101520Philosophers problem nr.Optical telegraph problem nr.10000Optiplan1000Satplan04HSPS-A100TP4CPT1010.10.01050OptiplanHSPS-A0.010.0124510.1TP414010CPT0.1035Pipesworld tankge problem nr.10000Time sec.Time sec.Pipesworld notankage problem nr.155101520253035404550PSR problem nr.Figure 2: IPC 2004 results makespan optimal planners.93025fiOptiplan: Unifying IP-based Graph-based PlanningDimopoulos, Y., & Gerevini, A. (2002). Temporal planning mixed integer programming. Proceeding AIPS Workshop Planning Temporal Domains,pp. 28.Do, M., & Kambhampati, S. (2001). Planning constraint satisfaction: Solving planning graph compiling CSP. Artificial Intelligence, 132 (2), 151182.Fourer, R., Gay, D., & Kernighan, B. (1993). AMPL: Modeling Language Mathematical Programming. Duxbury Press, Belmont, CA.ILOG Inc., Mountain View, CA (2002). ILOG CPLEX 8.0 users manual.Kambhampati, S. (1997). Challenges bridging plan synthesis paradigms. Proceedings16th International Joint Conference Artificial Intelligence (IJCAI-97), pp.4449.Kautz, H., & Selman, B. (1992). Planning satisfiability. Proceedings EuropeanConference Artificial Intelligence (ECAI).Kautz, H., & Selman, B. (1999). Blackbox: Unifying sat-based graph-based planning.Proceedings 18th International Joint Conference Artificial Intelligence(IJCAI-99), pp. 318325.Kautz, H., & Walser, J. (1999). State-space planning integer optimization. AAAI99/IAAI-99 Proceedings, pp. 526533.van den Briel, M., Vossen, T., & Kambhampati, S. (2005). Reviving integer programming approaches AI planning: branch-and-cut framework. ProceedingsInternational Conference Automated Planning Scheduling (ICAPS-05), pp.310319.Vossen, T., Ball, M., Lotem, A., & Nau, D. (1999). use integer programmingmodels AI planning. Proceedings 18th International Joint ConferenceArtificial Intelligence (IJCAI-99), pp. 304309.Wolfman, S., & Weld, D. (1999). LPSAT engine application resource planning. Proceedings 18th International Joint Conference Artificial Intelligence (IJCAI-99), pp. 310317.Wolsey, L. (1998). Integer Programming. Wiley-Interscience Series Discrete MathematicsOptimization. John Wiley & Sons, New York.931fiJournal Artificial Intelligence Research 24 (2005) 799-849Submitted 08/04; published 12/05Probabilistic Hybrid Action ModelsPredicting Concurrent Percept-driven Robot BehaviorMichael BeetzBEETZ @ . TUM . DEDepartment Computer Science IX, Technische Universitat Munchen,Boltzmannstr. 3, D-81667 Garching, Germany,Henrik GrosskreutzGROSSKREUTZ @ CS . RWTH - AACHEN . DEDepartment Computer Science, Aachen University TechnologyD-52056 Aachen, GermanyAbstractarticle develops Probabilistic Hybrid Action Models ( PHAMs), realistic causal modelpredicting behavior generated modern percept-driven robot plans. PHAMs representaspects robot behavior cannot represented action models used AI planning:temporal structure continuous control processes, non-deterministic effects, several modesinterferences, achievement triggering conditions closed-loop robot plans.main contributions article are: (1) PHAMs, model concurrent percept-drivenbehavior, formalization, proofs model generates probably, qualitatively accuratepredictions; (2) resource-efficient inference method PHAMs based sampling projectionsprobabilistic action models state descriptions. show PHAMs appliedplanning course action autonomous robot office courier based analyticalexperimental results.1. Introductionautonomous robots equipped restricted, unreliable, inaccurate sensors effectors operate complex dynamic environments. successful approach dealresulting uncertainty use controllers prescribe robots behavior terms concurrent reactive plans (CRPs) plans specify robots react sensory inputorder accomplish jobs reliably (e.g., McDermott, 1992a; Beetz, 1999). Reactive planssuccessfully used produce situation specific behavior, detect problems recoverautomatically, recognize exploit opportunities (Beetz et al., 2001). kindsbehaviors particularly important autonomous robots uncertain informationworld, act dynamically changing environments, accomplish complex tasksefficiently.Besides reliability flexibility, foresight another important capability competent autonomous robots (McDermott, 1992a). Temporal projection, computational process predicting happen robot executes plan, essential robots plan intendedcourses action successfully. able project plans, robots must causal modelsrepresent effects actions. robot action planners use representations include discrete action models plans define partial orders actions. Therefore, cannotautomatically generate, reason about, revise modern reactive plans. two importantdrawbacks. First, planners cannot accurately predict diagnose behavior generatedplans abstract away important aspects reactive plans. Second, planc2005AI Access Foundation. rights reserved.fiB EETZ & G ROSSKREUTZners cannot exploit control structures provided reactive plan languages make plansflexible reliable.article develop PHAMs (Probabilistic Hybrid Action Models), action modelsexpressiveness accurate prediction behavior generated concurrent reactiveplans. best knowledge, PHAMs action representation used actionplanning provides programmers means describing interference simultaneous,concurrent effects, probabilistic state action models, well exogenous events. PHAMssuccessfully applied autonomous robot office courier museum tour-guide robotmake predictions full-size robot plans execution plans (Beetz, 2001).article makes several important contributions area decision-theoretic robot actionplanning. First, describe PHAMs, formal action models allow predictionqualitative behavior generated concurrent reactive plans. Second, show PHAMsimplemented resource efficient way predictions based PHAMs performedrobots executing plans. Third, apply plan projection method probabilisticprediction-based schedule debugging analyze context robot office courier (Beetz,2001).starting technical part article would like make several remarks.article restrict navigation actions model exactly implemented one successful autonomous robot navigation systems (Burgard et al., 2000).reason want close gap action models used AI planning systemscontrol programs used autonomous robots behavior produce. controlprograms model proven achieve reliable, high performance navigationbehavior. Minerva experiment, controlled navigation crowded museum93 hours. execution, navigation plans revised planning module3200 times without causing deadlocks interacting, concurrent control processes(Beetz, 2002a; Beetz et al., 2001). robot office courier experiments, applied plan revisionmethods enabled robot plan ahead 15-25 minutes. consider timescale sufficient improving robots performance planning. However, performancegains principle achieved navigation planning often small comparedachieved planning manipulation tasks.Although use navigation example, modeling techniques applymechanisms autonomous robots, vision (Beetz et al., 1998), communication (Beetz &Peters, 1998), manipulation (Beetz, 2000) equally well. reasons coverkinds actions article require additional reasoning capabilitiesmoment models validated respect robot simulations. additional robotcapabilities would modeled include symbol grounding/object recognition (Beetz,2000), changing states objects, thorough models belief states robots (Schmittet al., 2002). Addressing issues well beyond scope article.remainder article introduce basic conceptualization underlying PHAMsdescribe two realizations them: one studying formal properties another one targeted efficient implementation. also show PHAMs employed contexttransformational robot planning.article organized follows. Section 2 describes everyday activity primary classapplication problems. introduce concurrent reactive plans (CRPs) means producingcharacteristic patterns everyday activity identify technical problems prediction800fiP ROBABILISTIC H YBRID ACTION ODELSphysical robot behavior CRPs generate. Section 3 explains execution CRPsphysical computational effects plan execution modeled using PHAMs. PHAMsdescribe behavior robot sequence control modes mode continuousbehavior specified control law. Mode transitions triggered controlled systemsatisfying specified mode transition conditions. introduce set predicates userepresent conceptualization formally. Section 4 5 describe two different approachespredicting behavior produced concurrent reactive plans context PHAMs.first one behavior approximated discretizing time sequence clock ticksmade arbitrarily dense. model used derive formal properties projectionconcurrent reactive plans. second approach, described Section 5, describes muchefficient approach projection CRPs. approach time ticks explicitlyconsidered represented discrete events may occur. time instances systemstate inferred interpolation using control laws respective modes.projection mechanism used execution time board robots. showimplementation PHAMs employed prediction-based tour scheduling autonomousrobot office courier. conclude evaluation discussion related work.2. Structured Reactive Controllers Projection Delivery Tour PlansPlan-based robot control successfully applied tasks control space probes(Muscettola et al., 1998b), disaster management surveillance (Doherty et al., 2000),control mobile robots office delivery (Simmons et al., 1997; Beetz et al., 2001) tourguidescenarios (Alami et al., 2000; Thrun et al., 2000). class tasks received little attentionplan-based robot control everyday activity human living working environments, taskspeople usually good at.get better intuition activity patterns produced everyday activity, let us consider chores hypothetical household robot. Household chores entail complex routine jobscooking dinner, cleaning kitchen, loading dish washer, etc. routine jobstypically performed parallel. household robot might clean living roomsoup cooking stove. cleaning up, phone might ring robot interrupt cleaning order go answer phone. completed telephone callrobot continue cleaning right stopped. Thus, robots activity must concurrent,percept-driven, interruptible, flexible, robust, requires foresight.fact people manage execute daily tasks effectively suggests, view,nature everyday activity permit agents make assumptions simplifycomputational tasks required competent activity. Horswill (1996) puts it, everyday life mustprovide us loopholes, structures constraints make activity tractable.believe many applications robotic agents perform everyday activities,following assumptions valid allow us simplify computational problems controllingrobot competently:1. Robotic agents familiar activities satisfying individual tasks situationstypically occur performing them. carry everyday activitiesconfronted kinds situations many times. consequence,conducting individual everyday activities learned experience simplesense require lot plan generation first principles.801fiB EETZ & G ROSSKREUTZ2. Appropriate plans satisfying multiple, possibly interfering, tasks determinedgreedy manner. robot first determine default plan performing individual tasksconcurrently additional ordering constraints simple fast heuristic plancombination methods. robot avoid remaining interferences subactivities predicting forestalling them.3. Robotic agents monitor execution activities thereby detect situationsintended course action might fail produce desired effects. situations detected, robots adapt intended course action specific situationsencounter, necessary based foresight.previous research proposed Structured Reactive Controllers (SRCs) computational model plan-based control everyday activity. SRCs collections concurrentreactive control routines adapt changing circumstances executionmeans planning. SRCs based upon following computational principles:1.SRC equipped library plan schemata routine tasks common situations.plan schemata provided programmers designed highexpected utility cost deal conceivable problems. knowAI courses plans check tailpipes every time starting cartypically lower expected utility ones check them, even thoughbananas stuck tailpipe necessary precondition starting car successfully.robustness, flexibility, reactivity plan schemata achieved implementingconcurrent percept-driven plans even highest level abstraction. plans employ control structures including conditionals, loops, program variables, processes, subroutines. also make use high-level constructs (interrupts, monitors) synchronizeparallel actions make plans reactive robust incorporating sensing monitoring actions reactions triggered observed events. Goals sub-plans representedexplicitly annotations planning algorithms infer purpose sub-plansautomatically.2.SRC fast heuristic methods putting plans together routine activities.able predict problems likely occur revise course action avoidthem. Predictive plan debugging requires SRC reason through, predict effectsof, highly conditional flexible plans subject article.3.SRC perform execution time plan management. run processes monitor beliefsrobot triggered certain belief changes. processes revise plansexecuted.Structured reactive controllers work follows. given set requests, structured reactive controllers retrieve routine plans individual requests execute plans concurrently.routine plans general flexible work standard situations executed concurrently routine plans. Routine plans cope well partly unknownchanging environments, run concurrently, handle interrupts, control robots without assistanceextended periods. standard situations, execution routine plans causes robot802fiP ROBABILISTIC H YBRID ACTION ODELSexhibit appropriate behavior achieving purpose. execute routine plans,robot controllers also try determine whether routines might interferewatch exceptional situations. encounter exceptional situations tryanticipate forestall behavior flaws predicting routine plans might work kindsituation. necessary, revise routines make robust respective kindssituations. Finally, integrate proposed revisions smoothly ongoing courseactions.2.1 Plan-based Control Robot Office Courierdescribe approach predicting concurrent percept-driven robot behavior firstgive comprehensive example plan-based robot office courier performing delivery tourexhibiting aspects everyday activity. description example includes presentationkey plan schemata used robot, sketch heuristic plan combination method, prediction behavior flaws, revision delivery plans. example run performedmobile robot RHINO acting robot office courier (Beetz, 2001; Beetz, Bennewitz, &Grosskreutz, 1999).2.1.1 P LANSP LAN CHEMATAROBOT C OURIERrobot courier equipped library plan schemata standard tasks including delivering items, picking items, navigating one place another. presentationplans plan schemata proceeds bottom up. start low-level plans navigationend comprehensive object delivery plans.low-level navigation plan specifies robot navigate one location environment, typically current position, another one, destination. Figure 1 depictslow-level navigation plan going location room A-117 location 5 room A-111.plan consists two components: sequence intermediate target points (the locations indexed numbers 1 5 Figure 1) sequentially visited robot specificationrobot adapt travel modes follows navigation path. manyenvironments advantageous adapt travel mode surroundings: drive carefully (andtherefore slowly) within offices offices cluttered, switch sonars drivingdoorways (to avoid sonar crosstalk), drive quickly hallways. second partplan depicted regions different textures different travel modes office,hallway, doorway. Whenever robot crosses boundaries regions adaptsparameterization navigation system. Thus, low-level navigation plans start terminate navigation processes change parameterization navigation system control modeswitches (SET- NAVIGATION - MODE) adding deleting intermediate target points (MOVE - TO).specify reactive plans RPL (McDermott, 1991; Beetz & McDermott, 1992), plan language provides high-level control structures specifying concurrent, event-driven robot behavior. pseudo code Figure 2 sketches initial part plan depicted Figure 1.plan leaving office consists two concurrent sub-plans: one following (initial partthe) prescribed path one adapting travel mode. second sub-plan adapts navigation mode robot dynamically. Initially, navigation mode set office. Upon enteringleaving doorway navigation mode adapted. plan uses fluents, conditions803fiB EETZ & G ROSSKREUTZ5A-111A-113A-110432A-1211A-120A-117DietersDeskLegenddoorway travelmodeoffice travelmodehallway travelmodeNavigation Planwaypoint waypoint coordinates1h2300, 800i2h2300, 900i3h1200, 1100i4h1200, 1200i5h1250, 1400iFigure 1: Graphical representation navigation plan. Topological navigation plan navigatingroom A-117 A-111 regions indicating different travel modes small blackcircles indicating additional navigation path constraints.updated asynchronously based new sensor readings. Fluents trigger (whenever )terminate (wait ) plan steps.execute concurrentlyexecute-in-order(1); wait (go-to-completed?);(2); wait (go-to-completed?);local fluents distance-to-doorwayfluent-network (| hx, yi hxdw , ydw |)entering-dw?-fl distance-to-doorway < 1mentering-hw?-fl distance-to-doorway > 1mMOVE -MOVE -execute-in-orderSET- NAVIGATION - MODE (office); wait (entering-dw?-fl);SET- NAVIGATION - MODE (doorway); wait (entering-hw?-fl);SET- NAVIGATION - MODE (hallway)Figure 2: plan sketches specification navigation process leaving office. twocomponents following prescribed path adapting travel mode implementedconcurrent sub-plans. second component uses fluent measure distancecenter doorway two dependent fluents signal robots enteringleaving doorway. Initially, travel mode set office. Upon enteringleaving doorway travel mode adapted.low-level navigation plan instances used higher-level navigation plans makenavigation processes flexible, robust, embeddable concurrent task contexts. higherlevel plans generate low-level plans based robots map environment (GENERATE NAV- PLAN ). slightly simplified version high-level plan listed below.804fiP ROBABILISTIC H YBRID ACTION ODELShighlevel-plan ACHIEVE(loc(rhino, hx, yi))1 cleanup routine ABORT- NAVIGATION - PROCESS2 valve wheels3loop4try parallel5wait navigation-interrupted?6local vars NAV- PLAN GENERATE - NAV- PLAN(c,d)7swap-plan (NAV- PLAN,NAV- STEP)8named subplan NAV- STEP9DUMMY10- CLOSE ?(hx, yi)explain plan going inner parts, generate robot behavior, outerones, modify behavior. Lines 6 8 make navigation plan independent startingposition thereby general: given destination d, plan piece computes low-levelnavigation plan robots current location c using map environmentexecutes (Beetz & McDermott, 1996).order run navigation plans less constrained task contexts must preventconcurrent routines directing robot different locations navigation planexecuted. accomplish using semaphores valves, requestedreleased. plan asking robot move stand still must request valve wheels, performactions received wheels, release wheels done. accomplishedstatement valve line 2.many cases processes higher priorities must move robot urgently. case,blocked valves simply pre-empted. make plan interruptible, robust interrupts, plan two things. First, detect gets interrupted second,handle interrupts appropriately. done loop generates executesnavigation plans navigation task robot destination. make routinecognizant interrupts using fluent navigation-interrupted?. Interrupts handled terminating current iteration loop starting next iteration, new navigationplan starting robots new position generated executed. Thus, lines 3-5 makeplan interruptible.make navigation plan transparent name routine plan ACHIEVE(loc(rhino,hx,yi))thereby enable planning system infer purpose sub-plan syntactically. Interruptible embeddable plans used task contexts higher priority concurrent sub-plans.instance, monitoring plan used controller estimates opening angles doors whenever robot passes one. Another monitoring plan localizes robot actively whenever losttrack position.facilitate online rescheduling modularized plans respect locationssub-plans executed using location plan schema. location hx,yi p planschema specifies plan p performed location hx,yi. simplified versionplan schema location .805fiB EETZ & G ROSSKREUTZnamed subplan Nilocation hx, yipbyvalve wheelslocal vars DONE ? FALSElooptry parallelwait Task-Interrupted?(Ni )sequentiallyNAVIGATE -T Ohx, yipDONE ?TRUEDONE ? = TRUEplan schema accomplishes performance plan p location hx,yi navigatinglocation hx,yi, performing sub-plan p, signalling p completed (the inner sequence).valve statement obtains semaphore wheels must owned process changinglocation robot. loop makes execution p hx,yi robust interruptshigher priority processes. Finally, named sub-plan statement gives sub-plan symbolic nameused addressing sub-plan scheduling purposes plan revisions. Usinglocation plan schema, plan delivering object location p locationroughly specified plan carries pickup(o) location p put-down(o) locationadditional constraint pickup(o) carried putdown(o). every sub-plan pperformed particular location l form location hx,yi p, schedulertraverse plan recursively collect location sub-plans install additional orderingconstraints sub-plans maximize plans expected utility.allow smooth integration revisions ongoing scheduled activities, designedplans sub-plan keeps record execution state and, started anew, skipsparts plan longer executed (Beetz & McDermott, 1996). made planssingle deliveries restartable equipping plan p variable storing execution statep used guard determine whether sub-plan executed. variablethree possible values: to-be-acquired denoting object must still acquired; loadeddenoting object loaded; delivered denoting delivery completed. planschema delivery single object consists two fairly independent plan steps: pick-upput-down step.EXECUTION - STATE(p, to-be-acquired)AT-L OCATIONLPICK - UP(o)EXECUTION - STATE(p, loaded)AT-L OCATIONPUT- (o)2.1.2 G ENERATING EFAULT ELIVERY P LANSheuristic plan generator delivery tours simple: inserts pick-up put-down subplans delivery requests overall plan determines appropriate orderlocation sub-plans. ordering determined heuristic performs simple topological806fiP ROBABILISTIC H YBRID ACTION ODELSsort sub-plans based locations sub-plans executed. heuristic considers additional constraints executing pick-up steps always respectiveput-down plan-steps.2.1.3 P REDICTION - BASED P LAN EBUGGINGROBOT FFICE C OURIERLet us contemplate specific scenario robot office courier RHINO performs office delivery requires prediction forestalling plan failures execution time. Considerfollowing situation environment pictured Figure 3. robot office courier deliverletter yellow envelope room A-111 A-117 (cmd-1) another letterenvelopes color unknown A-113 A-120 (cmd-2). robot already tried accomplish cmd-2 recognized room A-113 closed (using range sensors) revisesintended course action achieving cmd-2 opportunistically. is, later detectsA-113 open interrupt current activity reconsider intended course actionpremise steps accomplishing cmd-2 executable.perform tasks quickly robot schedules pick-up delivery actions minimizeexecution time assure letters picked delivered. ensureschedules work, robot take account state world changescarries scheduled activities. Aspects states robot consider schedulingactivities locations letters. Constraints state variables schedulessatisfy ask robot pick letters currently robots locationrobot carry two letters envelopes color.(58) (DONE GOTO (1000.0 1600.0))(58) (DO LOAD-LETTER y-letter)(62) (ACTIVATE GOTO (2300.0 600.0))(2) (ACTIVATE GOTO (1000.0 1600.0))A-111(136) (DONE GOTO (2300.0 600.0))(136) (DO UNLOAD-LETTER y-letter)A-117Figure 3: possible projected execution scenario initial plan. opportunity loadingletter unknown color ignored.Suppose robot standing front room A-117. belief state robot containsprobabilities colors letters desk A-113. robot also received evidence A-113 opened meantime. Therefore belief state assigns probability pvalue true random variable open-A113.807fiB EETZ & G ROSSKREUTZupdate belief state requires robot reevaluate options accomplishingjobs respect changed belief state. Executing current plan without modificationsmight yield mix ups robot might carry two letters envelopes color.different options are: (1) skip opportunity, (2) ask immediately letterA-113 put envelope yellow (to exclude mix ups taking opportunitylater); (3) constrain later parts schedule two yellow letters carried evenletter A-113 turns yellow; (4) keep picking letter A-113opportunistic sub-plan. option robot take depends belief state respectstates doors locations letters. find schedules probably work,particular, ones might result mixing letters, robot must apply model worlddynamics state variables.respect belief state, different scenarios possible. first one, A-113closed, pictured Figure 3. Points trajectories represent predicted events. eventswithout labels actions robot changes heading (on approximated trajectory)events representing sensor updates generated passive sensing processes. example, passivesensor update event generated robot passes door. scenario interventionprediction-based debugging necessary flaw projected.A-111A-113A-111(95) (DONE GOTO (1000.0 1600.0))(95) (DO LOAD-LETTER Y-LETTER)(95) (FAILURE SAME-COLOR LETTER)(33) (DONE GOTO (1850.0 1350.0))(33) (DO LOAD-LETTER OPP)(34) (ACTIVATE GOTO (1000.0 1600.0))A-113(102) GOTO (1000.0 1600.0))(102) LOAD-LETTER Y-LETTER)(103) GOTO (1100.0 400.0))400.0)) ff(174) (DONE GOTO (1100.0(174) UNLOAD-LETTER OPP)(175) GOTO (2300.0 600.0))(12) (RECOGNIZE LOAD-LETTER OPP)(13) (ACTIVATE GOTO (1850.0 1350.0))(2) (ACTIVATE GOTO (1000.0 1600.0))(30) GOTO (1850.0 1350.0))(30) LOAD-LETTER OPP)(31) GOTO (1000.0 1600.0))fffi(11) (RECOGNIZE LOAD-LETTER OPP)(12) (ACTIVATE GOTO (1850.0 1350.0))(2)(ACTIVATE GOTO (1000.0 1600.0))A-120(248) (DONE GOTO (2300.0 600.0))(248) (DO UNLOAD-LETTER Y-LETTER)A-117A-120(a)A-117(b)Figure 4: Two possible predicted scenarios opportunity taken. scenario (a) letterturns color one loaded afterwards. Therefore,second loading fails. scenario (b) letter turns different colorone loaded afterwards. Therefore, second loading succeeds.scenarios office A-113 open controller projected recognize opportunity reschedule enabled plan steps described above. 1 resulting schedule asksrobot enter A-113 first, pickup letter cmd-2, enter A-111 pick lettercmd-1, deliver letter cmd-2 A-120, last one A-117. categoryscenarios divided two categories. first sub-category shown Figure 4(a)letter picked yellow. Performing pickup thus would result robot carrying1. Another category scenarios characterized A-113 becoming open robot left A-111. may alsoresult execution failure letter loaded A-113 yellow, discussed further.808fiP ROBABILISTIC H YBRID ACTION ODELSA-111A-113(39) (DONE GOTO (1850.0 1450.0))(39) (DO LOAD-LETTER NIL)(70) (ACTIVATE GOTO (1100.0 400.0))(200) (DONE GOTO (1000.0 1600.0))(202) (DO LOAD-LETTER Y-LETTER)(211) (ACTIVATE GOTO (2300.0 600.0))(2) (ACTIVATE GOTO(1850.0 1450.0))(19) (USE OPPORTUNITY)(263) (DONE GOTO (2300.0 600.0))(147) (DONE GOTO (1100.0 400.0))(263) (DO UNLOAD-LETTER Y)(162) (DO UNLOAD-LETTER OPP)(178) (ACTIVATE GOTO (1000.0 1600.0))A-120A-117Figure 5: Projected scenario plan suggested plan debugger. letter unknowncolor picked also delivered first. plan little less efficient avoidsrisk able load second letter.two yellow letters therefore execution failure signalled. second sub-category shownFigure 4(b) letter different color therefore robot projected succeed taking course action scenarios. Note possible flaw introducedreactive rescheduling rescheduler consider state robotchange course action, particular state may caused robot carrytwo letters color.case, plan-based controller probably detect flaw likely respectrobots belief state. enables debugger forestall flaw, instance, introducingadditional ordering constraint, sending email increases probability letterput particular envelope. revision rules introduced last section.Figure 5 shows projection plan revised adding ordering constraintletter A-120 delivered entering A-111.Figure 6(a) shows event trace generated initial plan executed RHINOcontrol system (Thrun et al., 1998) critical scenario without prediction based schedule debugging; Figure 6(b) shows one debugger adding additional ordering constraint.scenario shows reasoning future execution plans enables robot improvebehavior.article, describe probabilistic models reactive robot behavior necessary predict scenarios one described purpose prediction-based plandebugging.2.2 Projection Low-level Navigation Plansknow robot plans look like turn question predicteffects executing delivery plan. input data plan projection probabilistic beliefs809fiB EETZ & G ROSSKREUTZA-111%%<< %% 2? fi#. +2136@+,fi25"A5..+,BCfi4( .#+2#+,=255.fi-,fi(%% << fi2#.+.3= 25.5.>!fi-,#fifi.( #8 %& %& %( (21:12:31 ARRIVED (1000.0 1600.0)21:13:06 LOADING BLUE LETTER21:13:06 GOING (2300.0 600.0)A-11321:10:13 ARRIVED (1850.0 1450.0)21:10:37 LOADING BLUE LETTER21:10:37 GOING (1100.0 400.0)P OP PPOOPG G G G G FG F F FNN QOQPG F GHQNNN NQQQEH HEFE HDH DS SSSNRJJ MI MRIM R RI R R R IIIIII R R R IR R R RS HI H H HS HS HS DD DDD ST DD TTMJM JUTULM KKJKL KK21:09:38 GOING (1850.0 1450.0)%% )*)*++ .,fi-..#+ !+-/fifi "!01"2#fi#.fi+#83. 4 259%5:%.& fi;-, 6:%#+& %7-( 7( (21:09:50 INSTALL NEW SCHEDULEAVOIDCARRYING COLORfi fi"!#fifi#$ % & ' % & %( (21:11:24 ARRIVED (1100.0 400.0)21:11:59 UNLOADING BLUE LETTER21:11:59 GOING (1000.0 1600.0)21:14:26 ARRIVED (2300.0 600.0)21:14:58 UNLOADING BLUE LETTERA-120(a)A-117(b)Figure 6: trajectory without prediction-based plan revision (Sub-figure (a)) failscourier foresee possible complications loading second letter. Subfigure (b) shows trajectory possible flaw forestalled planning mechanism.robot respect current state world, probabilistic models exogenous eventsassumed Poisson distributed, probabilistic models low-level plans, probabilisticrules guessing missing pieces information. output projection process sequencedated events along estimated state time event.Plan projection identical plan execution two exceptions. First, whenever planprojector interprets wait whenever records corresponding fluents active triggeringconditions. way, plan projection mechanism automatically generate percepts continuous control processes exogenous events make triggering conditions true. example,navigation plan waiting robot enter hallway plan projector probabilistically guesses robot motion causes respective triggering condition become true.time instant, plan projector generates sensor input event corresponding sensorreading.Plan projection also differs plan interpretation whenever robot interactsreal world, projected robot must interact symbolic representations world.places happens low-level plans. Thus instead executing low-level planprojector guesses results executing plans asserts effects formpropositions timeline. three kinds effects generated interpretationlow-level plans: (1) physical changes, robot changing position, (2) low-levelplan changing dynamical state robot, direction robot heading to,(3) computational effects, changing values program variables signalling successfailure control routines. Thus model low-level plan used plan projectionprobability distribution sequence events generates delayssubsequent events.Thinking procedurally, plan projector works follows. iteratively infers occurrencenext event given plan completely interpreted. next event either next810fiP ROBABILISTIC H YBRID ACTION ODELSevent low-level plan generates computational state controller change,sensor input event active triggering condition predicted become true, exogenousevent one predicted occur. next predicted event earliest events.consider particular instance low-level plans: low-level navigation plansused example previous section. Navigation key action autonomous mobilerobots. predicting path robot take necessary predict robotbe, prerequisite predicting robot able perceive. example,whether robot perceive door open depends robot taking path passesdoor, executing door angle estimation routine passing door doorwithin sensor range. Passing door perceived based robots position estimateenvironment map. Consequently, robot executes plan step door open,end execution plan step depends actual path robot take. impliesaction planning process must capable predicting trajectory accurately enough predictglobal course action correctly.Navigation actions representative large subset physical robot actions: movements controlled motors. Physical movements number typical characteristics. First,often inaccurate unreliable. Second, cause continuous (and sometimes discontinuous) change respective part robots state. Third, interference concurrentmovements often described superposition individual movements.discuss issues raised projection concurrent reactive plans, sketch deliverytour plan specifies robot deliver mail rooms A-113, A-111, A-120Figure 1 (Beetz, 2001). mail room A-120 delivered 10:30 (a strict deadline).Initially, planner asks robot perform deliveries order A-113, A-111, A120. room A-113 closed corresponding delivery cannot completed. Therefore,planning system revises overall plan robot accomplish delivery A-113opportunity. words, robot interrupt current delivery deliver mailA-113 (see Figure 7) delivery completed.policy long in-hallway?whenever passing-a-door?ESTIMATE - DOOR - ANGLE ()policy seq wait open?(A-113)DELIVER - MAIL - (D IETER )1.2.GO - (A-111)GO - (A-120)10:30Figure 7: Delivery tour plan concurrent monitoring process triggered continuous effects navigation plan (passing door) opportunistic step. concurrentreactive plans serve example discussing requirements causal modelsmust satisfy.plan contains constraining sub-plans whenever robot passes door estimatesopening angle door using laser range finders opportunities complete811fiB EETZ & G ROSSKREUTZdelivery room A-113 soon learn office open. sub-plans triggeredcompleted continuous effects navigation plans. example, event passingdoor occurs robot traverses rectangular region front door. call eventsendogenous events.A-111A-113end(low-level-nav-plan(...))leavingdoorwayenteringdoorwayleavinghallwayVWVWVW VWleavingdoorwayVW VWVWenteringhallwayenteringdoorwaybegin(low-level-nav-plan(...))A-120A-117Figure 8: Visualization projected execution scenario. following types events depicted specific symbols: change travel mode event rhombuses, start/stop passingdoorway small circles, start/stop low-level navigation plan double circles, entering doorway/hallway boxes.Figure 8 shows projected execution scenario low-level navigation plan embeddedplan depicted Figure 7. behavior generated low-level navigation plans modeledsequence events either cause qualitative behavior changes (e.g. adaptations travelmode) trigger conditions plan reacting (e.g. entering hallway passing door).events depicted rhomboids denote events CRP changes direction targetvelocity robot. squares denote events entering leaving offices. small circlesdenote events starting finishing passing door, predicted concurrentmonitoring process estimates opening angles doors robot passing them.projected execution scenarios used prediction-based debugging deliverytours autonomous robot office courier. Beetz et al. (1999) shown controller employing predictive plan scheduling using causal models described article performbetter possibly could without predictive capabilities (see also Section 6.1).812fiP ROBABILISTIC H YBRID ACTION ODELS2.3 Peculiarities Projecting Concurrent Reactive Plansseveral peculiarities projection concurrent reactive plans want pointhere.Continuous Change. Concurrent reactive plans activate deactivate control processesthereby cause continuous change states robots position. Continuous change mustrepresented explicitly CRPs employ sensing processes continually measure relevantstates (for example, robots position) promptly react conditions caused continuouseffects (for example, entering office).Reactive Control Processes. reactive nature robot plans, eventspredicted continuous navigation process depend process alsomonitoring processes simultaneously active wait conditions continuouseffects navigation process might cause. Suppose robot controller running monitoringprocess stops robot soon passes open door. case planner must predictrobot passes door events door robot passes continuous navigation action.events trigger sensing action estimates door angle, predicted percept open door detected navigation process deactivated. discrete eventsmight predicted based continuous effects navigation include enteringleaving room, come within one meter destination, etc.Interference continuous effects. control processes set voltages robotsmotors, possible modes interference control processes limited. generatesignals motors combined effects determined so-called task arbitrationscheme (Arkin, 1998). common task arbitration schemes (1) behavior blending (wheremotor signal weighted sum current input signals) (Konolige, Myers, Ruspini, &Saffiotti, 1997); (2) prioritized control signals (where motor signal signal processhighest priority) (Brooks, 1986); (3) exclusion concurrent control signalsuse semaphores. plans, exclude multiple control signals motorseasily incorporated prediction mechanism. Thus remaining typeinterference superposition movements turning camera moving.Uncertainty. various kinds uncertainty non-determinism robots actionscausal model represent. often necessary specify probability distributionaverage speed displacements points paths enable models predict rangespatio-temporal behavior navigation plan generate. Another important issue modelprobability distributions occurrence exogenous events. dynamic environmentsexogenous events opening closing doors might occur time.3. Modeling Reactive Control Processes Continuous ChangeLet us conceptualize behavior generated modern robot plans interactionbehavior interpretation reactive plans. base conceptualization vocabularyhybrid systems. Hybrid systems developed design, implement, verify embeddedsystems, collections computer programs interact analog environment(Alur, Henzinger, & Wong-Toi, 1997; Alur, Henzinger, & Ho, 1996).advantage hybrid system based conceptualization state-based ones hybridsystems designed represent concurrent processes interfering continuous effects.also allow discrete changes process parameterization, need model activation,813fiB EETZ & G ROSSKREUTZdeactivation, reparameterization control processes reactive plans. addition, hybrid system based conceptualizations model procedural meaning wait wheneverstatements.pictured Figure 9, consider robot operating environment two interacting processes: environment including robot hardware, also called controlledprocess, concurrent reactive plan, controlling process. state environment represented state variables including variables x y, robots real positiondoor-anglei representing opening angle door i. robot controller uses fluents storerobots measurements state variables (robot-x, robot-y, door-a120, etc.). fluentscontinually updated self-localization process model-based estimator estimatingopening angles doors. control inputs plan environment process vectorincludes travel mode, parameterization navigation processes current targetpoint reached robot.EnvironmentState Variables:XDOORANGLEiControl InputsExogenous Events- Travel Mode- Target Pointgoing-for-lunch(person)Sensing Process- self localization- door angle estimationConcurrent Reactive PlanDelivery PlanFigure 1robot-xrobot-ydoor-iFigure 9: figure shows conceptualization execution navigation plans. relevantstate variables x coordinates robots position opening anglesdoors. fluents estimate state variables robot-x, robot-y, door-a120.3.1 Hybrid System Model Reactive Robot Behaviormodel controlled process hybrid system (Alur et al., 1997, 1996). Hybridsystems continuous variable, continuous time systems phased operation. Withinphase, called control mode, system evolves continuously according dynamical lawmode, called continuous flow. Thus state hybrid system thoughtpair control mode continuous state. control mode identifies flow,814fiP ROBABILISTIC H YBRID ACTION ODELScontinuous flow identifies position it. Also associated control mode so-calledjump conditions, specifying conditions discrete state continuous state togethermust satisfy enable transition another control mode. transitions cause abrupt changesdiscrete well continuous state. jump relation specifies valid settingssystem variables might occur jump. Then, next transition, continuous stateevolves according flow identified new control mode.considering interpretation concurrent reactive plans hybrid system controlmode determined set active control processes parameterization. continuousstate characterized system variables x, y, represent robots positionorientation. continuous flow describes state variables change result activecontrol processes. change represented component velocities x, y, o. Thuscontrol mode robots velocity constant. Linear flow conditions sufficientrobots paths approximated accurately enough using polylines (Beetz & Grosskreutz,1998). also computationally much easier faster handle. jump conditionsconditions monitored constraining control processes activate deactivatecontrol processes.Thus interpretation navigation plan according hybrid systems model worksfollows. hybrid system starts initial state hcm0 , x0 i. state trajectory evolvescontrol mode remaining constant continuous state x evolving according flowcondition cm. (estimated) continuous state satisfies transition condition edgemode cm mode cm0 jump must made mode cm0 , mode might chosenprobabilistically. jump continuous state may get initialized new value x 0 .new state pair hcm0 , x0 i. continuous state x0 evolves according flow conditioncm0 .construction hybrid system given concurrent plan straightforward. startcurrent plan execution state. every concurrent active statement form wait condwhenever cond add cond jump condition current control mode. additionone additional jump condition completion plan step.Figure 10 depicts interpretation first part navigation plan shown Figure 2.interpretation represented tree nodes represent control modes corresponding hybrid system node labels continuous flow. edges control modetransitions labeled jump conditions. robot starts executing plan room A-117.initial control mode hybrid system root state tree depicted Figure 10.initial state represents state computation first control processes two parallelbranches active, processes going intermediate target point 1 maintaining office mode robots travel mode. flow specifies robotinitial control mode absolute value derivative robots position functionrobots navigation mode (office, doorway, hallway) next intermediate target point.hybrid system makes transition one subsequent states either first target pointreached distance doorway becomes less one meter. transition conditionupper edge robot come sufficiently close doorway, lower edgereached first target point. lower edge, hybrid system goes staterobot goes target point 2 still keeping office mode current travelmode. transition robot changes travel mode doorway keeps approachingfirst target point. variables changed control mode transitions815fiB EETZ & G ROSSKREUTZcontrol mode: cm3x = f1 (hallway, h2300, 800i)= f2 (hallway, h2300, 800i)e3 : dist(hx, yi, hxdw , ydw i) > 100control mode: cm1x = f1 (doorway, h2300, 800i)= f2 (doorway, h2300, 800i)e4 : x = 2300 = 800control mode: cm4x = f1 (doorway, h2300, 900i)= f2 (doorway, h2300, 900i)e1 : dist(hx, yi, hxdw , ydw i) < 100control mode: cm0x0 =2400, y0 =600x = f1 (office, h2300, 800i)= f2 (office, h2300, 800i)control mode: cm5x = f1 (office, h1200, 1100i)= f2 (office, h1200, 1100i)e2 : x = 2300 = 800e5 : x = 2300 = 900control mode: cm2x = f1 (office, h2300, 900i)= f2 (office, h2300, 900i)e6 : dist(hx, yi, hxdw , ydw i) < 100control mode: cm6x = f1 (doorway, h2300, 900i)= f2 (doorway, h2300, 900i)Figure 10: figure shows hybrid automaton interpretation navigation planFigure 2. possible control modes continuous flow equations depictednodes mode transitions edges. edges labeled jump conditions:entering doorway (e1 , e6 ), leaving doorway (e3 ), reaching first waypoint (e2 , e4 ),reaching second waypoint (e5 ).velocity robot orientation. settings implied flow conditionrespective successor states.one issue yet addressed conceptualization: uncertainty.model uncertainty respect continuous effects achievement jump conditionsusing multiple alternative successor modes varying flows jump conditions. associateprobability occurrence mode transition. way can, example, representrotational inaccuracies navigation actions typical mobile robots.816fiP ROBABILISTIC H YBRID ACTION ODELS3.2 Representation Hybrid System ModelLet us formalize hybrid system conceptualization using logical notation. so,going use following predicates describe evolution system states: jump~ f lows),~Condition(cm,e,c), jumpSuccessor(e,cm,probRange), jumpRelation(cm, vals,probRange(e,max). jumpCondition(cm,e,c) represents mode cm left along edge e conditionc becomes true. jumpSuccessor(e,cm,probRange) defines non-deterministic successor statescm probability ProbRange entered system makes transition~ f lows)~along e. jumpRelation(cm, vals,defines initial values state variables flowconditions upon entering state cm. jump e causes automaton transit probabilisticallysuccessor mode.possible successor define probability range probRange. reasons explained represent probability ranges non-overlapping, relativesizes proportional probability represent (the sum ranges 1)boundaries form 2in , n integers. predicate probRange(e,2 n ) definessum ranges. possible transition probability range [ 2in , 2jn ] represented jumpSuc~ f lows)~cessor(e,cm,[i,j]). predicate jumpRelation(cm, vals,means upon entering control~ f lows.~mode cm system variables flows initialized specified valsUsing predicates introduced above, state probabilistic hybrid automaton (Figure 10)interpretation navigation plan using following facts.jumpRelation(cm0 ,h2400,600i, hf1 (office, h2300, 800i), f2 (office, h2300, 800i)i)jumpCondition(cm0 ,e1 ,dist(hx, yi, hxdw , ydw i) < 100)jumpCondition(cm0 ,e2 ,x = 2300 = 800)jumpSuccessor(e1 ,cm1 ,[1,1])probRange(e1 ,1)jumpRelation(cm1 ,h i,hf1 (doorway, h2300, 800i), f2 (doorway, h2300, 800i)i)jumpRelation(cm2 ,h i,hf1 (office, h2300, 900i), f2 (office, h2300, 900i)i)...robot starts position h2400, 600i control mode cm 0 robot leaveslower office right. control mode robot moves hf 1 (office, h2300, 800i),f2 (office, h2300, 800i)i. navigation system leaves control mode cm 0 coming closedoor (dist(hx, yi, hxdw , ydw i) < 100) performing transition e1 . system performstransition e1 control flow changes low-level navigation plan switchesnavigation mode doorway. example, transition deterministic.account uncertainty control make transitions probabilistically. Thussubstitute control mode cm1 multiple control modes, say cm01 cm001 controlflows modes sampled probability distribution. state example40probability 75% ( 1216 ) system transits control mode cm1 25% ( 16 )mode cm001 defining effects transition e1 follows:jumpCondition(cm0 ,e1 ,dist(hx, yi, hxdw , ydw i) < 100)jumpSuccessor(e1 ,cm01 ,[1,12])jumpSuccessor(e1 ,cm001 ,),[13,16])probRange(e1 ,16)817fiB EETZ & G ROSSKREUTZrepresent state hybrid automaton use predicates mode(cm) startTime(cm,t)~represent current control mode cm cm started time t. use flow( flow)~valuesAt(ti ,vali ) assert flows values system variables given time points. Further,values system variables inferred arbitrary time points interpolation~ ). done using predicatebasis current flow last instances valuesAt(ti ,valstateVarsVals:~ valuesAt(t0 ,vals~ 0 ) now(t)stateVarVals(vals)~ = vals~ 0 + (t t0 )flow~ vals~f low(flow)now(t) specifies current time. Note, conceptualization represent discrete state changes explicitly states within mode using modes initial state flow.particular state within mode derived demand using predicate stateVarVals. Interferences different movements robot issued different control threads modeledmodes flow.Figure 11 depicts execution scenario, possible evolution hybrid system representingexecution robot controller might go. execution scenario consistent set jumpsvalues hybrid model time. extract event historiesused simulate plan execution look flaws.execution scenario consists timeline, linear sequence events results. Timelines represent effects plan execution terms time instants, occasions, co-occurringevents. implies several events occur time instant one them,primary one, changes state world. Time instants points time worldchanges due action robot exogenous event. time instant dateholds time global clock time instant occurred. occasion stretchtime world state P holds specified proposition, describes P,time interval proposition true.deal kinds uncertainty representing model using McDermotts rulelanguage probabilistic, totally-ordered temporal projection (McDermott, 1994). Using language represent Poisson distributed exogenous events, probability distributionscurrent world state, probabilistic sensor action models way consistentmodel presented far.3.3 Discussion ModelLet us discuss hybrid system model addresses issues raised Section 2.3.two inference tasks concerning issue continuous change caused concurrent reactiveplans supported model. first one inferring state particular time instant.example, projection mechanism predicts occurrence exogenous event,object falling robots gripper, projection mechanism infer robottime instant assert position object falling down. done usinginitial state flow condition active control mode. second important inferencetask prediction control mode jumps caused continuous effects low-level plans,robot entering hallway. inferred using jump conditions activecontrol mode addition initial state flow condition.818fiP ROBABILISTIC H YBRID ACTION ODELSmode(cm0)mode(cm1)initialValues(cm0,<2400,600>)initialValues(cm1,startTime(cm1,5)startTime(cm0,0)flow(<f1(off...flow(<f1(office,<2300,900>),f2(office,<2300,900>)>)valuesAt(t3,<2360,850>)t1clock-tick(t1)t2t3t4t5t6clock-tick(t2)clock-tick(t3)clock-tick(t4)clock-tick(t5)clock-tick(t6)jump(e1)Figure 11: Part timeline represents projected execution scenario low-level navigation plan. Time instants depicted circles, events rectangles, occasionsrectangles round corners.second issue raised Section 2.3 prediction robots reactionsinstantaneous events, dropping object. Typically, reactive plan carrying objectcontains sub-plans ask robot stop pick object soon sensed forcegripper drops. kinds reactions handled checking active jump conditionsimmediately instantaneous event occurred.third issue projecting concurrent reactive plans interference simultaneouscontinuous effects. model, interference modelled describing effects control modejumps flow condition subsequent control mode. programmer must specify rulesdescribing physics domain specifying flow condition next mode. Thus,sub-plan moving robots arm started robot moving, rule describingeffects corresponding control mode jump asserts flow condition specifyingworld coordinates gripper determined gripper position mode jumptransposition two motions successor mode.last issue uncertainty. One aspect uncertainty model supportsinaccuracies physical behavior robot. modelled specifying probability distributions successor modes control mode jump occurs. aspects uncertaintyincluding probabilistic sensor models, uncertainty instantaneous physical effects, uncertaintystate world, Poisson distributed exogenous events handled rule language describe next section. particular, give examples exogenous eventspassive sensors Section 5.3 detailed probabilistic model complex sensing actionSection 5.4.819fiB EETZ & G ROSSKREUTZapproach explicitly reason belief state. assume belief statecomputed probabilistic state estimators (Thrun et al., 2000). state estimators returnlikely state also infer additional properties belief state ambiguityexpected accuracy global maximum. plan-based controller interrupts delivery tourssoon position estimate ambiguous inaccurate. Details mechanism wellmotivations found work Beetz, Burgard, Fox, Cremers (1998).4. Probabilistic, Totally-Ordered Temporal Projectionlast section seen hybrid systems execution scenarios represented.section, see predict execution scenarios specification hybrid system. purpose use McDermotts rule language probabilistic, totally-orderedtemporal projection (McDermott, 1994). rule language expressiveness neededpurpose: specify probabilities event effects depending respective situation,Poisson distributed events, probability distributions delays subsequent plangenerated events. Uncertainty current state world specified formprobabilistic effect rules distinct start event.rule language excellent basis formalizing model introduced last section.set rules satisfies certain conditions implies unique distribution dated event sequencessatisfies probabilistic conditions individual rules (see Definition 2 Section 4.1).Thus give probabilistic formalizations behavior within control modes mode jumpsMcDermotts rule language define unique probability distribution state trajectories hybrid automaton satisfies probabilistic constraints. Moreover, McDermottdeveloped provably correct projection algorithm samples dated event sequencesunique distribution.remainder section proceed follows. start presenting McDermottsrule language probabilistic, totally-ordered temporal projection summarize main properties language. represent hybrid system model using rule language.Based representation can, loosely speaking, show applying McDermotts projection algorithm representation hybrid system, algorithm returns dated event sequences drawn unique distribution implied rules arbitrarily high probability.Note, obtain results use discretized model time clock tick eventsspaced arbitrarily close together resulting higher accuracy projection algorithm.makes use representation infeasible practice. Therefore, eliminate needclock tick events Section 5 making use McDermotts persist effects.4.1 McDermotts Rule Language Probabilistic, Totally-ordered Temporal Projectiondifferent kinds rules provided language projection rules, effect rules, exogenous event rules. Projection rules specify sequence dated events caused low-level plans,effect rules specify causal models sensing processes actions, exogenous event rulesused specify occurrence events control robot. describekinds rules below.Projection rules used specify sequence events caused interpretationlow-level plan. Projection rules form820fiP ROBABILISTIC H YBRID ACTION ODELSproject rule name(args)conddelay 1 occurs ev1...delay n occurs evnspecify low-level plan name(args) executed condition cond holdslow-level plan generates events ev1 , ..., evn relative delays 1 , ..., n , respectively.Thus, projection rules generate sequence dated events.Uncertain models represented sampling probability distributiondurations specifying conditions satisfied certain probability.Effect rules used specify conditional probabilistic effects events. formep rule namecondprobability event ev causes effsspecify whenever event ev occurs cond holds, probability createclip states specified effs. effects ep rule rules form A, causingoccasion hold, clip A, causing cease hold, persist A, causing holdtime units.Exogenous event rules used specify conditional occurrence exogenous events.rulepe rule namecond avg spacing occurs evspecifies interval cond true, exogenous events ev generatedPoisson-distributed average spacing time units.proving properties model must first introduce McDermotts semantics possible worlds. so, define key notions underlying conceptualization Definition 1.evolution world described sequence dated instantaneous events occurrence e@t specifies event e occurs time instant t. addition, function mappingtime instants world states. precisely notions defined follows (see McDermott,1994).Definition 1 world state function propositions {T,F,} extended booleanformulas usual way. occurrence e@t pair c = (e, t), e eventtime (t <+ ). occurrence sequence finite sequence occurrences, ordered date.duration date last occurrence. world duration L, L < + , completehistory duration L, is, pair (C, H), C occurrence sequence durationL, H function [0, L] world states. H(0) propositions mapped F,t1 < t2 H(t1) 6= H(t2) must occurrence e@t t1tt2.821fiB EETZ & G ROSSKREUTZuse following abbreviations: (A t)(W ), execution scenario W, mean> 0 t0 : < t0 < + H(t0 )(A) = . (A t)(W ),W similarly defined, upper bound t0 includes t.described represent change world, state conditionsworlds duration consistent given set event effects exogenous eventrules. so, state constraints rules, local probabilistic models, imposestate evolution. definition take plan generated events typically specifiedproject rules, given.Definition 2 set rules defined above, Exog occurrence sequence 2 , P setpropositions, L real number duration(Exog), L-Model Exogpair (U, ), U set worlds duration L (C, H) U : Exog C,probability measure U obeys following restrictions: (At), (At) e@tconsidered random variables. annihilation conjunction A, conjunctionnegations conjuncts A.1. Initial blank state: P : (A 0) = 0.2. Event-effect rules: contains rule instanceep rule name probability r event e causes B,every date t, require that, nonempty conjunctions C literals B:(Ct|e@t Bt) = r.3. Event-effect rules events dont occur: Suppose B atomic formula, letR = {Ri } set instances ep rules whose consequents contain B B.ep rule Ri = Ai probability pi event Ei causes Ci , let Di = Ai Ci ,(Bt|Bt N ) = 1 (Bt|Bt N ) = 0 N = (E1 @t D1 )(E2 @t D2 ) ....4. Event-occurrence rules: every time point occurrence dateExog every event E, exactly one instancepe rule name avg spacing occurs E(at) > 0 requirelimdt0(occ. class E t+dt|At)= 1/ddtlimdt0(occ. class E t+dt|At)=0dt2. Exog occurrence sequence, represents events generated interpretation robots planmodeled using projection rules.822fiP ROBABILISTIC H YBRID ACTION ODELSexists rule, requirelimdt0(occ. class E t+dt)=0dt5. Conditional independence: one previous clauses defines conditional probability(|), mentions times t, conditionally independent, given ,random variables mentioning times t. is, arbitrary mentioning timest, (|) = (| ).McDermott (1994) shows definition yields unique probability distribution . alsogives proof projection algorithm draws random execution scenarios sampledunique probability distribution implied given probabilistic models.4.2 Probabilistic Temporal Rules PHAMsorder predict evolution hybrid system, specify rules McDermotts rule languagethat, given state system time t, predict successor state t. predictsuccessor state, must distinguish three cases: first, control mode transition occurs; second,exogenous event occurs; third, system changes according flow current mode.start rules predicting control mode jumps. ensure mode transitionsgenerated specified probability distributions successor modes, usepredicate randomlySampledSuccessorMode(e,cm) realize random number generator usingMcDermotts rule language.randomlySampledSuccessorMode(e,cm)probRange(e, max) randomN umber(n, max)jumpSuccessor(e, cm, range) n rangeorder sample values probability distributions axiomatize random numbergenerator asserts instances predicate randomNumber(n,max) used (see Beetz &Grosskreutz, 2000). formalizing randomize event. McDermott (1994) discussesusefulness of, difficulties in, realizing nondeterministic exclusive outcomes. Thereforeimplementation escapes Lisp uses function returns random element.Lemma 1 time point randomNumber exactly one extension randomNumber(r,max)r unbiased random 0 max.Proof: Let max largest probRange extension randomBit(i,value) i-th random bit.start event causes initial state timeline causes randomBit(i,0) 0 log max .Thereafter, randomize event used sample value:ep rule RANDOMIZErandomBit(i,val) negation(val,neg)probability 0.5event randomizecauses randomBit(i,neg) clip randomBit(i,val)823fiB EETZ & G ROSSKREUTZRule ODE -J UMP causes control mode transition soon jump condition cond becomestrue. rule says interval cm current control modejump condition cond leaving cm following edge edge jump along edge occuraverage delay time units.pe rule ODE -J UMPmode(cm) jumpCondition(cm,cond,edge)~ satisfies(vals,cond)stateVarsVal(vals)average spacing time unitsoccurs jump(edge)Rule J UMP -E FFECTS specifies effects jump event control mode, system variables, flow. cm control mode randomly sampled probability distributionsuccessor nodes jumps along edge jump along edge following effects.values state variables flow condition previous control mode cm old retractedones new control mode cm asserted.ep rule J UMP -E FFECTSrandomlySampledSuccessorMode(edge,cm)~ flowCond(cm,flow)~ now(t)initialValues(cm,val)mode(cmold ) flow(flowold ) valuesAt(told ,valold )probability 1.0event jump(edge)~~ valuesAt(transTime,val)causes mode(cm) flow(flow)clip mode(cmold ) clip flow(flowold ) clip valuesAt(told ,valold )Time advanced using clock-tick events. every C LOCK -T ICK (?t ) event predicateupdated clipping previous time asserting new one. Note, time differsdtclock time units actual time.ep rule C LOCK -RULEnow(to )probability 1.0event clock-tick(t)causes now(t) clip now(to )Exogenous events modeled using rules following structure. navigation~ state variables satisfy conditionprocess control mode cm values valsoccurrence exogenous event ev, event ev occurs average spacing timeunits.pe rule C AUSE -E XO -E VENTmode(cm) exoEventCond(cm,cond,ev)~ satisfies(vals,cond)stateVarsVal(vals)average spacing time unitsoccurs exoEvent(ev)824fiP ROBABILISTIC H YBRID ACTION ODELSeffects exogenous event rules specified rules following form. exoge~nous event exoEvent(ev) effect specification exoEffect(ev, val))causes values state~~variables change valo val.ep rule E XO -E VENT-E FFECT~ valuesAt(to ,valo ) now(t)exoEffect(ev,val))probability 1.0event exoEvent(ev)~ clip valuesAt(to ,val~ o)causes valuesAt(t,val)4.3 Properties PHAMsseen last section PHAM consists rules set factsconstitute hybrid automata representation given CRP. section investigate whetherPHAM make right predictions.essentially three properties predicted execution scenarios want ensure.First, predicted control mode sequences consistent specified hybrid system. Second,mode jumps predicted according specified probability distribution successor modes.Third, two successive events, behavior predicted according flow respective control mode.McDermotts formalism allow modeling instantaneous state transitionsshow control mode sequences execution scenarios probably approximately accurate.view, low price expressiveness gain availability Poissondistributed exogenous events.subsequent lemma 2 states control mode jumps predicted arbitrary accuracyarbitrarily high probability decreasing time successive clock ticks.Lemma 2 probability delay , exists (average delay occurrenceevent triggering condition become true) dt clock (time two subsequentclock ticks) whenever jump condition becomes satisfied, probability 1jump event occur within time units.Proof: Let time jump condition fulfilled. /(2 log(1/)) dt clock/2 /2 time units antecedent rule ODE -J UMP fulfilled. probability event class jump(cm0 ) occurs t+/2 t+ e/(2 ) = elog(1/) = ,probability 1 event occur time units t.implies always non-zero chance control mode sequences predictedincorrectly. happens two jump conditions become true jump triggeredlater condition occurred one. However, probability incorrect predictionsmade arbitrarily small choice dtclock .basic framework hybrid systems take possibility exogenous eventsaccount thereby allows proving strong system properties reachability goalstates arbitrary initial conditions safety conditions system behavior (Alur et al.,825fiB EETZ & G ROSSKREUTZ1997, 1996). prediction robot behavior dynamic environments assumptions,however, unrealistic. Therefore, weaker property, namely correspondencepredicted behavior flows specified hybrid system immediatesubsequent events.Lemma 3 Let W execution scenario, e1 @t1 e2 @t2 two immediate subsequent eventstype jump exoEvent, cm control mode 1 W . Then, every occurrence~ )) unique. Further, vals~ = vals~ 1 + (t - t1 ) *e@t t1 < t2 W(t)(stateVarVals(vals~flow(cm), vals1 values state variables t1 .Proof: two classes rules affect value valuesAt flow: rule JUMP E FFECTS, rule E XO -E VENT-E FFECT. rules always clip set exactly one extensionpredicates, thus together fact initial event asserts exactly one predicate,determined value unique.interval t1 t2 extension stateVarVals evolves according flowcondition mode cm due fact flow changed rule E XO -E VENT-E FFECT. Thusremains initially set rule JUMP -E FFECTS, asserts exactly flow correspondingcm. proposition follows assumption correct axiomatization additionscalar-vector multiplication.Another important property representation jumps predicted accordingprobability distributions specified hybrid automaton.Lemma 4 Whenever jump along edge e occurs, successor state chosen accordingprobability distribution implied probRange jumpSuccessor.Proof: follows properties randomize event Rule Jump-Effects.Using lemmata state show central properties PHAMs: (1) predictedcontrol mode transitions correspond specified hybrid automaton; (2)holds continuous predicted behavior exogenous events; (3) Exogenous eventsgenerated according probabilities continuous domain (this shown McDermott,1994).Theorem 1 Every sequence mode(cm) occasions follows branch (cm ), ..., (cmj ) hybrid automaton.Proof: occasion mode(cm) must asserted rule J UMP -E FFECTS. Therefore mustjump(e) event. Consequently, must jumpCondition previouscontrol mode cm.826fiP ROBABILISTIC H YBRID ACTION ODELSjump events modeled Poisson distributed events always chancepredicting control mode sequences valid respect original hybrid system.next bound probability predicting mode sequences choosing parameterization jump event clock tick event rules appropriately.Theorem 2 every probability exists average delay mode jump eventdelay dtclock satisfaction jump conditions realized probability~ stateVarVals occasions two immediate subsequent exogenous events1 valsfollow state trajectory hybrid automaton.Proof: proof based property jumps occur correct order arbitrarilyhigh probability. particular, choose function minimal delay jumpconditions becoming true. Then, jumps successor modes occur arbitrarily high probability (Lemma 2). Finally, according Lemma 3 trajectory stateVarVals transitionsaccurate.5. Implementation PHAMsshown PHAMs define probability distributions possible execution scenariosrespect given belief state. problem using PHAMs obvious. Nontrivial CRPscontrolling robots reliably require hundreds lines code. typically several controlprocesses active, many dormant, waiting conditions trigger execution.hybrid automata CRPs huge, branching factors mode transitions immense.Let alone distribution execution scenarios might generate. accurate computationprobability distribution prohibitively expensive terms computational resources.second source inefficiency realization PHAMs. PHAMs usedclock tick rules, Poisson distributed events, generate clock ticks average spacingtime units. done so, order formalize operation CRPs single conciseframework. problem approach order predict control mode jumps accuratelymust choose small. This, however, increases number clock tick eventsdrastically makes approach infeasible simple scenarios.order draw sample execution scenarios distribution implied causal modelinitial state description use extension XFRM projector (McDermott, 1992b)employs RPL interpreter (McDermott, 1991) together McDermotts algorithm probabilistic temporal projection (McDermott, 1994). projector takes input CRP, rulesgenerating exogenous events, set probabilistic rules describing effects events actions,(probabilistic) initial state description. predict effects low-level plans projector samples effects probabilistic causal models low-level plans assertspropositions timeline. Similarly, plan activates sensor, projector makes usemodel sensor state world described timeline predict sensorreading.section investigate make effective informative predictions basisPHAMs performed speed sufficient prediction-based online plan revision.achieve effectiveness use two means. First, realize weaker inference mechanisms827fiB EETZ & G ROSSKREUTZbased sampling execution scenarios distribution implied causal modelsinitial state description. Second, replace clock tick event mechanism differentmechanism infers occurrence control mode jumps uses persist effect generaterespective delay. detail two mechanisms remainder section.5.1 Projection Adaptive Causal ModelsLet us first turn issue eliminating inefficiencies caused clock tick mechanism.replacing clock tick rules mechanism tailoring causal models flyusing persist effects probabilistic rule language.efficiency reasons process projecting continuous process p divided twophases. first phase estimates schedule endogenous events caused p considering possible effects p processes effects processes p.schedule transformed context-specific causal model tailored planprojected. second phase projects plan p using model endogenous events constructedfirst phase. phase takes account interferences concurrent events revises causal model situations arise assumptions precomputed scheduleviolated.projection module uses model dynamic system specifies continuouscontrol process state variables changes state variable fluents measurestate variable. example, consider low-level navigation plans steadily change robotsposition (that variables x y). estimated position robot stored fluentsrobot-x robot-y:changes(low-level-navigation-plan, x)changes(low-level-navigation-plan, y)measures(robot-x, x)measures(robot-y, y)Extracting relevant conditions. projector starts projecting low-level navigation plancomputes set pending conditions depend robot-x robot-y, fluentsmeasure state variables dynamic system changed low-level navigationplan. conditions implemented fluent networks.Fluent networks digital circuits components circuit fluents. Figure 12shows fluent network output fluent true, robot room A-120.inputs circuit fluents robot-x robot-y circuit updated whenever robot-xrobot-y change.reactive plans set fluent networks compute conditionsplan waiting determined automatically using (P ROLOG-like) relational queries:setof ?fl-net ( fluent(?fl) status(?fl,pending)changes(low-level-nav-plan, ?state-var)measures(?state-var-fl, ?state-var)depends-on(?fl, ?state-var-fl)fluent-network(?fl, ?fl-net) )?pending-fl-nets828fiP ROBABILISTIC H YBRID ACTION ODELS1265.0robot-x<>860.0817.0robot-yIN-A-120?<Figure 12: Fluent network room A-120. robot believes room A-120estimated x-coordinate 860 1265 y-coordinate smaller817, hallway begins.query determines ?pending-fl-nets, set fluent networks ?fl-net ?fl-net network output fluent ?fl. ?fl causes plan thread pend depends fluent measuringstate variable ?state-var changed low-level navigation plan. extraction conditions done automatically. automatic extraction requires conditions particularform effects low-level plans state variables sensing state variablesrepresented explicitly.predict fluent IN-A-120? become true false, compute regionstate space corresponds fluent compute intersections robots statetrajectories region.Endogenous event schedules. class continuous processes provide endogenous event scheduler takes initial conditions parameterization process,fluent networks might triggered computes endogenous event schedule.endogenous event scheduler low-level navigation plans described next section. Givenkind process (e.g., low-level navigation plan), process parameters (e.g., destinationrobot), pending fluent networks, scheduler returns sequence composite endogenous events. Composite events represented triples form (t, hsv 1 , ..., svn i, {ev1 , ...,evm }). delay ith i+1st event schedule, hsv 1 , ..., svn valuesstate variables, {ev1 , ..., evm } atomic events take place.state plan waiting, becomes true time instance t, passivesensor-update event triggered. passive-sensor-update event model takes set fluentsparameters, retrieves values state variables measured fluents, appliessensor model values, sets fluents accordingly.causal model low-level navigation plans. Projecting initiation executionnavigation plan causes two events: start event hypothetical completion eventinfinite number time units. shown following projection rule.829fiB EETZ & G ROSSKREUTZproject rule LOW- LEVEL - NAVIGATION - PLANtruedelay 0occurs begin(low-level-nav-plan(?dest-descr, ?id, ?fluent)delayoccurs end(low-level-nav-plan(?dest-descr, ?id, ?fluent)effect rule start event low-level navigation plan computes endogenous eventschedule asserts next endogenous navigation event timeline.ep rule ENDOGENOUS - EVENTSendogenous-event-schedule(low-level-nav-plan(?dest-descr, ?schedule))probability 1.0event begin(low-level-nav-plan(?dest-descr, ?id, ?fluent))causes predicted-events(?id, ?schedule)running(robot-goto(?descr, ?id))next-nav-event(?id))occasion next-nav-event(?id) triggers next endogenous event begin(follow-path(?hereh?x,?yi) ?dt ?id)). remaining two conditions determine parameters follow-path event:next scheduled event robots position.pe rule C AUSE -E XO -E VENTnext-nav-event(?id)predicted-events(?id, ((?dt h?x,?yi ?evs) !?remaining-evs)robot-loc(?here)average spacing 0.0001occurs begin(follow-path(?here, h?x,?yi, ?dt, ?id))effect rule begin(follow-path (...)) event specifies among things nextendogenous event occur ?dt time units (persist ?dt sleeping(?id)).ep rule FOLLOW- PATHrobot-loc(?coords)probability 1.0event begin(follow-path(?from, ?to, ?dt, ?id))causes running(follow-path(?from, ?to, ?dt, ?id))clip robot-loc(?coords)clip next-nav-event(?id)persist ?dt sleeping(?id)running follow path event finished sleeping end (follow-path (...)) event occurs.pe rule ERMINATE -F OLLOW-PATHsleeping(?id)running(follow-path(?from, ?to, ?time, ?id))average spacing 0.0001occurs end(follow-path(?from, ?to, ?time, ?id))830fiP ROBABILISTIC H YBRID ACTION ODELSmodel low-level navigation plan presented far suffices long nothing importanthappens carrying plan. However, suppose exogenous event causesobject slip robots hand projected time instant robot motion.predict new location object projector predicts location l robot timeusing control flow asserts timeline.Qualitative changes behavior robot caused adaptations travel modedescribed ep -rules. following ep -rule describes effects eventnav-event(set-travel-mode(?n)), represents low-level navigation plan resetting travelmode:ep rule SET- DOORWAY- MODEtravel-mode(?m)probability 1.0event nav-event(set-travel-mode(doorway))causes clip travel-mode(?m)clip obstacle-avoidance-with(sonar)travel-mode(doorway)rule specifies time instant event nav-event(set-travel-mode(?n))occurs state travel-mode(?m) holds ?m, states travel-mode(?m) obstacleavoidance-with(sonar) (with probability 1.0) persist event occurred, i.e.,clipped event. event causes state travel-mode(doorway) holdadapted next time.rules listed hand-coded plan-specific. investigation whether planscoded rule specification automated agenda future research.5.2 Endogenous Event Schedulershown events projected given endogenous event schedule,shown schedule constructed. Thus, section describes endogenous eventscheduler low-level navigation plans. scheduler predicts effects low-level navigation plan state variables x y. endogenous event scheduler assumes robotfollowing straight path locations 1 5. pointed earlier, twokinds events need predicted: ones causing qualitative physical change onescausing trigger conditions plan waiting for.qualitative events caused low-level navigation plan pictured Figure 13ones occur robot arrives locations 1, 2, 3, 4, 5 robot eitherchanges travel mode arrives destination. time instants occurrenceset-travel-mode-event predicted.scheduler triggering events works two phases: (1) transforms fluent networkcondition able predict (2) applies algorithm computingevents occur. conditions caused low-level navigation plan representedregions environment condition true robot withinregion. elementary conditions numeric constraints robots position distancerobot given target point. scheduler assumes robot-x robot-y fluents831fiB EETZ & G ROSSKREUTZnetworks change value execution plan. complex networksconstructed conjunctions disjunctions elementary conditions.6A111X ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX 5ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZXZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZXZXYZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZXZXYZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX 4ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZXZXYZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX 3ZYX ZYX ZXZXYZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX ZYX 2 ZYX ZYX ZYX ZXZXYZY1A117Figure 13: Initially predicted endogenous events.next step endogenous event scheduler overlays straight line path intermediate goal points topological navigation path (see Figure 7) regions computedprevious step. computes schedule endogenous events following navigation path collecting intersections regions (see Figure 13). resultscheduling step sequence triples form (ti , hxi , yi i, {ev1 , ..., evn }).Rescheduling endogenous events. One problem temporal projector dealwait step might executed low-level navigation plan projected. example,robot enters hallway, policy looks opening angles doors passingtriggered. Therefore, causal model computed endogenous event schedulerlonger sufficient. fails predict passing door events.problems handled modifying endogenous event schedule: whenever robotstarts waiting condition function robots position, interrupts projectionlow-level navigation plan, adapts causal model low-level navigation plan, continues projection. case entering hallway, new endogenous event schedulecontains endogenous events passing doorways computed. updated schedule endogenous events pictured Figure 14.5.3 Projecting Exogenous Events, Passive Sensors Obstacle AvoidanceOne type exogenous event event additional information timeoccurrence, event Dieter back lunch around 12:25. kindsevents represented pe rule together ep rule. ep rule specifies832fiP ROBABILISTIC H YBRID ACTION ODELSc dYc dcdYc dcdcYdYc dcdcYdYc dcdcYdYc dcdcYdY[Y\Y[ \Y[ \Y[ \Y[ \Y[ \[[Y\Y[ \Y[ \Y[ \Y[ \Y[ \[[Y\Y[ \Y[ \Y[ \Y[ \Y[ \[[Y\Y[ \Y[ \Y[ \Y[ \Y[ \[[Y\Y[ \Y[ \Y[ \Y[ \Y[ \[[Y\Y[ \Y[ \Y[ 8 \Y[ \Y[ \[[Y\Y[ \Y[ \Y[ \Y[ \Y[ \[[Y\Y[A111[ \Y[ \Y[ \Y[ \[\Y[Y[Y\ [Y\ [Y\ [Y\ [Y\ [\[Y\Y[ \Y[ 7\Y[ \Y[ \Y[ \[[Y\Y[ \Y[[[ ba \Y[ \[\Y\Y6ba5bYba 4baba_ `Y_ `Y_ `_`Y_ `Y_ `_`_Y`Y_ `Y_ `_`_Y`Y_ `Y_ `_`_Y`Y_ `Y_ `_`_Y`Y] ^Y] ^Y] ^]^Y] ^Y] ^]^]Y^Y] ^Y] ^]^]Y^Y3 ^Y] ^Y] ^Y] ^]] ^Y] ^Y] ^]^Ye fYe fYe fefYe fYe fefeYfYe fYe fe2 feYfYe fYe fYe 1fefYe fYe fYe fefY1A117Figure 14: Modified endogenous event schedule.start event causes state before-dieters-door-opens() hold persist ?time time units.event dieters-door-opens() triggered soon before-the-door-opens() longer holds.ep rule BACK - -L UNCHabout(?time, 12:25) difference(?time, *now*, ?wait-for))probability 1.0event startcauses persist ?wait-for before-the-door-openspe rule OOR -O PENSthnot before-the-door-opensaverage spacing 0.0001occurs dieters-door-is-openedorder predict occurrence exogenous events, plan projector following.first computes time robot cause next event e next . Let us assumeevent occurs time units last event elast c strongest condition holdselast enext .3 following algorithm predicts occurrence next exogenousevent accurately. First, every pe rule ri whose enabling condition satisfied c randomlydecide whether ei occur elast enext based average temporal spacingei events situations c holds. ei predicted occur, select occurrence timerandomly selecting time instant time interval e last enext (the exogenous events3. cases enabling conditions exogenous events caused continuous effects e lastenext handled analogously achievement triggering conditions.833fiB EETZ & G ROSSKREUTZPoisson distributed). Select exogenous event predicted occur earliest, asserttimeline, continue projection occurrence event.last two components need describe passive sensors, steadily updatedchange configuration robot behavior collision avoidance routines.Readings passive sensors need projected measured state variables changesignificantly state variables traverse values satisfy conditions robotwaiting. situations update-passive-sensors event.Collision avoidance modeled except situations robot told objectsmoved around. case endogenous event scheduler adds region correspondingobject. region blocks way destination robot cannot move aroundregion possible-bump-event generated. effect rule possible bump eventspecifies that, robot activated sensors detect object, low-level navigationplan fails failure description path blocked. Otherwise bump event generated.example, since sonar sensors sensors placed table height, collision avoidancemodule avoid collision table sonar sensors active. Thus, predictbump, projector determine long sonar sensors switchedpossible bump event occurs.5.4 Models Complex Sensing Actionsunderstand types uncertainty modeled causal models interactplan interpretation let us look complex sensing action realized low-levelplan look-for. sub-plan called visual description (?pl) objects supposed lookfor.Typically, order model low-level plan need set projection rules probabilistically describe possible event sequences outcomes activating behavior module.situation exactly one projection rule applied (although decision one mightprobabilistic).One projection rules look-for listed below. model consists three parts.first part (line 1 7) specifies condition rule predicts behaviorlook-for correctly. second part (lines 8 11) lists events look-for causerule applicable. Finally, last line specifies low-level plan signals completioninterpretation. case, low-level plan succeeds returns list object descriptions(?desigs) value.condition projection rule determines robot (1), probabilistically decideswhether look-for normal based camera used specifics location (2),infers objects located (3). inference performed based robots probabilistic belief state world predicted exogenous events. conditionuses sensor model camera order decide probabilistically robot perceivesobject. object perceived matching perceptual description ?pl localdesignator ?desig created collected variable desigs. last condition (7) estimatestime ?dt look-for behavior completes. Upon completion look-for behaviorprojected interpretation process sends success signal return value ?desigs argument. projected behavior consists three events: two change world begin(look-for(?pl,?cam)) end(look-for(?pl, ?cam)), occurs ?dt later. third event changes compu834fiP ROBABILISTIC H YBRID ACTION ODELS(1)(2)(3)(4)(5)(6)(7)(8)(9)(10)(11)(12)project rule look-for(?pl, ?cam)( loc(robot, h?x,?yi)normal-look-for-behavior(?cam, ?loc)setof ?ob loc(?ob, h?x,?yi) ?obs-heresensor-model(?cam, ?sensor-model)features(?pl,?features)setof ?desig( member(?ob,?obs-here)obj-seen(?ob, ?sensor-model)perceived-properties(?ob, ?features, ?sensor-model, ?pl)local-desig(?desig,?ob,?pl,?x,?y))?desigslook-time(h?x,?yi, ?features, ?dt))delay 0 occurs mode transition begin(look-for(?pl, ?cam))delay ?dt occurs mode transition end(look-for(?pl, ?cam))delay 0 occurs trigger fluent visual-inputs-fluent(?cam)delay 0 occurs set fluent obs-pos-fluent ?seen)delay 0 occurs succeed ?desigsFigure 15: projection rule describing behavior module look-for.tational state structured reactive controller passing ?dt time units. event pulsesfluent visual-inputs-fluent(?cam) sets fluent obs-pos-fluent(?cam).Besides asserting events take place execution plan specifyevents change world. done using effect rules. One shownFigure! 16. rule specifies time instant event end(look-for(?pl, ?cam))occurs state visual-track(?desig, ?ob) holds ?desig ?ob, states visualtrack(?desig, ?ob) (with probability 1.0) persist event occurred, i.e.,clipped event.ep rule VISUAL - TRACKINGvisual-track(?desig, ?ob)probability 0.9event end(look-for(?pl, ?cam))causes clip visual-track(?desig, ?ob))Figure 16: ep rule describing effects event end(look-for(?pl, ?cam)).5.5 Probabilistic Sampling-based Projectionfar looked issue efficiently predicting individual execution scenario.investigate issue drawing inferences useful planning based sampledexecution scenarios.835fiB EETZ & G ROSSKREUTZRecently, probabilistic sampling-based inference methods proposed infer information complex distributions quickly bounded risk (Fox, Burgard, Dellaert, & Thrun,1999; Thrun, 2000). discuss use sampling-based projection anticipating likely flaws high probability.Advantages applying probabilistic sampling-based projection prediction effectsCRPs works independently branching factor modes hybrid automatonconstructs small part complete PHAM.kinds prediction-based inferences drawn samples projected execution scenarios? inference found valuable online revisions robot plansis: projected execution scenarios drawn distribution satisfy given property pprobability greater ? robot action planner use type inference decide whetherrevise plan eliminate particular kind flaw: revise planbelieves flaws likelihood exceeds threshold ignore otherwise. course,inferences drawn based samples certain risk wrong. Suppose wantplanner classify flaw probability greater eliminated ignoreflaw less likely . assume flaws probability large impactrobots performance. many execution scenarios plan revision module projectorder classify flaws correctly probability greater 95%?main factor determines performance sample-based predictive flaw detectionflaw detector. flaw detector classifies flaw eliminated probability flawrespect robots belief state greater given threshold probability . flaw detectorclassifies flaw hallucinated probability flaw respect robots belief statesmaller given threshold . far consider severity flaws,obvious extension. Typically, choose starting 50% smaller 5%.Specific flaw detectors realized differ respect (1) time resourcesrequire; (2) reliability detect flaws eliminated; (3) probability hallucinate flaws. is, signal flaw unlikely eliminatingflaw would decrease expected utility.precise consider flaw f occurs distribution execution scenariosgiven scheduled plan respect agents belief state probability p. Further, let X (f)represent event behavior flaw f occurs ith execution scenario: X (f ) = 1, f occursith projection 0 otherwise.Prandom variable Y(f,n) = ni=1 Xi (f) represents number occurrences flaw fn execution scenarios. Define probable schedule flaw detector ET ET(f,n,k) = trueiff Y(f,n) k, means detector classifies flaw f eliminated foccurs least k n randomly sampled execution scenarios. Thus ET(f,n,k) works follows.first projects n execution scenarios. counts number occurrences flaw fn execution scenarios. greater equal k ET(f,n,k) returns true, false otherwise.defined schedule flaw detector, characterize it. Since occurrence schedule flaws randomly sampled execution scenarios independent other,value Y(f) described binomial distribution b(n,p). Using b(n,p) computelikelihood overlooking probable schedule flaw f probability p n execution scenarios:j1Xnpk (1 p)nkP (Y (f ) < j) =kk=0836fiP ROBABILISTIC H YBRID ACTION ODELSET(f,3,2)ET(f,4,2)ET(f,5,2)50%50.068.881.2Prob. Flaw60% 70% 80%64.8 78.4 89.681.2 91.6 97.391.3 96.9 99.390%97.299.699.9Figure 17: table shows probability flaw detectors ET(f,i,2) detecting flawsprobability = 50%, 60%, 70%, 80%, 90%.Figure 17 shows probability flaw detector ET(f,n,2) n = 3,...,5 detectschedule flaw probability . probability detectors classify flaws less likelyeliminated smaller 2.3% (for n5).using prediction-based scheduling component controller robot officecourier typically use ET(f,3,2), ET(f,4,2), ET(f,5,2) different experiments,means detected flaw classified probable occurs least twice three, four, fivedetection readings.Figure 18 shows number necessary projections achieve = 95% accuracy.detailed discussion see work Beetz et al. (1999).=.1%=1%=5%1%133110%10012139220%44497840%17172260%88980%333Figure 18: table lists number randomly sampled projections needed differentiate failures occurrence probability lower probabilityhigher accuracy 95%.probabilistic sampling-based projection mechanism becomes extremely useful improving robot plans execution execution scenarios sampled fast enough.moment projection takes couple seconds. overhead mainly caused recordinginterpretation RPL plans manner far detailed purposes.simplification models expect immediate speed one order magnitude.seems projection frequency 100 Hz one could start tackling number realisticproblems occur execution time continually.6. Evaluationvalidated causal model low-level navigation plans role office delivery plans respect computational resources qualitative prediction results seriesexperiments.837fiB EETZ & G ROSSKREUTZ6.1 GeneralityPHAM capable predicting behavior generated flexible plans written plan executionlanguages RAP (Firby, 1987) PRS (Myers, 1996). so, code controlstructures provided languages RPL macros. best knowledge PHAMsfirst realistic symbolic models sequencing layer 3T architectures, commonlyused software architectures controlling intelligent autonomous robots (Bonasso et al., 1997).architectures run planning execution different software layers different time scalessequencing layer synchronizes layers. layer uses different formplan behavior specification language. planning layer typically uses problem space plan,execution layer employs feedback control routines activated deactivated.intermediate layer typically uses reactive plan language. use PHAMs enables 3T planningsystems make realistic predictions robot behavior generated abstractplans. PHAMs also capable modeling different arbitration schemes superpositionseffects concurrent control processes.causal models proposed complement introduced Beetz (2000). describessophisticated models object recognition manipulation allow prediction planfailures including caused robot overlooking confusing objects, objects changing location appearance, faulty operation effectors. models, however,given simulated robot acting grid world. article, restrictedprediction behavior generated modern autonomous robot controllers. Unfortunately, objectrecognition manipulation skills current autonomous service robots advanced enoughaction planning. hand, clear action planning capabilities pay muchbetter robots manipulate environments risk manipulating wrong objects.6.2 Assumptions Restrictionscontrol problem autonomous robots generate effective goal-directed control signals robots perceptual effector apparatus within feedback loop. Plan-based robotcontrol specialization control problem, robot generates control signalsmaintaining executing plan effective high expected utility respectrobots dynamically changing belief state. problem general cannot hopesolve form.Computer Science common characterize computational problems programsolve language input program specified. example, distinguish compilers regular context-free programming languages. true planbased control agents. Typically, planning problems described terms initial statedescription, description actions available agents, applicability conditionseffects, description goal state.three components planning problems typically expressed formal language.problem solving power planning systems characterized expressivenesslanguages three inputs. classes planning problems entirely formulated propositional logic others formulated first order logic. classify planningproblems respect expressiveness action representations use; whetherallow disjunctive preconditions, conditional effects, quantified effects, model resource838fiP ROBABILISTIC H YBRID ACTION ODELSconsumption. planning systems even solve planning problems involve different kindsuncertainty.contrast, SRCs use methods make strong assumptions plans simplify computational problems. consequence, SRCs apply reliable fast algorithms construction installment sub-plans, diagnosis plan failures, editing sub-plansexecution. Making assumptions plans attractive planning algorithms construct revise plans thereby enforce assumptions hold.nutshell, set plans SRC generates reflexive, transitive closureroutine plans respect application plan revision rules. Thus, enforce plansproperty Q sufficient routine plans satisfy Q revision rules preserve Q.properties make particularly easy reason plans plans still specifyrange concurrent percept-driven behavior RPL can. properties plans playimportant role article generality, flexibility, reliability. propertiesachieved careful design hand-coding. consequence plan generation revisionperformed programmed heuristic rules. believe, however, plans ruleslearned experience.make two important assumptions. First, assume tasks environmentbenign therefore behavior flaws result disasters. important, robotsmust make errors order learn competent performance tasks experience.planner allowed occasionally propose worse plans apply fast planning methodsbased Monte Carlo methods improve average performance robot.Another design decision explicitly represent belief state robot,probability distributions values state variables. This, however, needimply cannot reason inaccuracies uncertainties robots estimate worldstate. Beetz et al. (1998) describe couple plan-based high-level control probabilisticstate estimation. article state estimator automatically computes signals propertiesbelief state ambiguity inaccuracy state estimates plan-based controller.plan-based controller, hand, uses signals order decide interruptmissions re-localize robot.6.3 Scalingcausal models described Section 5 used execution time planningrobot office courier. plans projected original plans application typically several hundreds code lines long. projected execution scenarios containedhundreds events. projection single execution scenarios cost second,robots must revise plans based samples. Thus, robot detect probable flawshigh reliability.computational resources mainly consumed bookkeeping mechanisms recordcomputational state robot time instant represented execution scenariomechanisms proposed article. recorded computational state usedplanning mechanisms order diagnose behavior flaws caused discrepanciescomputational state robot state environment. ability reconstructregularly updated fluent values computationally costly. intend provide programming839fiB EETZ & G ROSSKREUTZconstructs let programmers declare parts computational state irrelevantplanning need recorded.Even severe limitation able show preliminary implementation robot outperform controllers lack predictive capabilities. main sourceinefficiency bookkeeping needed reconstruct entire computational state planpredicted time instant, issue addressed article. Usingparsimonious representation computational state expect drastic performance gains.6.4 Qualitatively Accurate PredictionsProjecting plan listed Figure 7 generates timeline 300 events long. Manyevents generated rescheduling endogenous events (21 times). Figure 19 showspredicted endogenous events (denoted numbered circles) behavior generatednavigation plan 50 runs using robot simulator (we assume execution interruptedroom A-111 robot realizes deadline achieved). qualitativepredictions behavior relevant plan debugging perfect. projector predicts correctlyrobot exploit opportunity go location 5 going location 1 9.A11198763421A1175A118Figure 19: figure shows trajectories multiple executions navigation planevents predicted symbolic plan projector.6.5 Prediction-based Plan DebuggingBeetz (2002a 2000) describes experiments showing prediction-based plan debuggingimprove performance robot controllers substantially.840fiP ROBABILISTIC H YBRID ACTION ODELS7. Related WorkPHAM represent external events, probabilistic action models, action models rich temporalstructure, concurrent interacting actions, sensing actions domain autonomous mobilerobot control. many research efforts formalize analyze extended action representations develop prediction planning techniques them. know, however,approaches address subsets aspects addressed representation. Related work comprises research reasoning action change, probabilistic planning, numerical simulation,qualitative reasoning.Reasoning action change. Allen Ferguson (1994) give excellent detaileddiscussion important issues representation temporally complex concurrent actionsevents. One important point make actions interfering effects then,worst case, causal models possible combinations actions must provided. paper,restricted one kind interference actions: transposition movements dominant kind interference physical robot behavior. articleaddress issues reasoning uncertainty efficiency respect computationalresources.substantial amount work done extend situation calculus (McCarthy, 1963)deal time continuous change (Pinto, 1994; Grosskreutz & Lakemeyer, 2000a), exogenous (natural) actions (Reiter, 1996), complex robot actions (plans) (Levesque et al., 1997; Giacomo et al., 1997) using sensing determine action execute next (Levesque, 1996; Lakemeyer, 1999) well probabilistic state descriptions probabilistic action outcomes (Bacchus,Halpern, & Levesque, 1999; Grosskreutz & Lakemeyer, 2000b). main difference workrepresentation limited respect kinds events interactionsconcurrent actions allow. particular, know effort integrate aspects.advanced approaches area formalizations various variantshigh-level robot control language G OLOG, particular C G OLOG (Giacomo et al., 1997).Boutilier, Reiter, Soutchanski, Thrun (2000) applied decision theoretic means optimally completing partially specified G OLOG program. key difference G OLOGapproach formalization includes operation plan language whereas approachprocedural semantics realized high-level projector used.Hanks, Madigan, Gavrin (1995) present interesting expressive framework representing probabilistic information, exogenous endogenous events medical predictionproblems. application domain address issues sophisticatedpercept-driven behavior done article.Extensions Classical Action Planning Systems. Planning algorithms, SNLP (McAllester& Rosenblitt, 1991), extended various ways handle expressive action models different kinds uncertainty (about initial state occurrence outcomeevents) (Kushmerick, Hanks, & Weld, 1995; Draper, Hanks, & Weld, 1994; Hanks, 1990).planning algorithms compute bounds probabilities plan outcomes computationally expensive. addition, decision-theoretic action planning systems (see Blythe, 1999,comprehensive overview) proposed order determine plans highest,least, sufficiently high expected utility (Haddawy & Rendell, 1990; Haddawy & Hanks, 1992;841fiB EETZ & G ROSSKREUTZWilliamson & Hanks, 1994). approaches abstract away rich temporal structureevents assuming discrete atomic actions ignore various kinds uncertainty.Planning action models rich temporal structure also investigated intensively (Allen, Kautz, Pelavin, & Tenenberg, 1990; Dean, Firby, & Miller, 1988). IxTeT (Ghallab& Laruelle, 1994) planning system applied robot control reasonstemporal structure plans identify interferences plan steps resource conflicts.planner/scheduler Remote Agent (Muscettola et al., 1998b) plans space maneuversexperiments based rich temporal causal models (Muscettola et al., 1998a; Pell et al., 1997).good overview integration action planning scheduling technology foundoverview article Smith, Frank, Jonsson (2000). far considered uncertaintyrespect durations actions.Kabanza, Barbeau, St-Denis (1997) model actions behaviors state transition systemssynthesize control rules reactive robots descriptions. approach usedgenerate plans satisfy complex time, safety, liveness constraints. approacheslimited respect temporal structure (primitive) actions modeledkinds interferences concurrent actions considered.MDP-based planning approaches. recent years MDP (Markov decision process) planningbecome active research field (Boutilier, Dean, & Hanks, 1998; Kaelbling, Cassandra, &Kurien, 1996). MDP approach robot behavior modeled finite state automatondiscrete actions cause stochastic state transitions. robot rewarded reaching goalsquickly reliably. solution problems policy, mapping discretized robotstates into, often fine-grained, actions.MDP form attractive framework action planning use uniform mechanismaction selection parsimonious problem encoding. action policies computed MDPsaim robustness optimizing average performance. number researchers successfully considered navigation instance Markov decision problems (MDPs) (Burgard et al.,2000; Kaelbling et al., 1996).One main problems application MDP planning techniques keep problemencoding small enough MDPs still solvable. number techniques complexityreduction found article written Boutilier et al. (1998). Yet, still difficultsolve big planning problems MDP framework unless state action spaces wellstructured.Besides reducing complexity specifying models for, solving MDP problems, extending expressiveness MDP formalisms active research area. Semi Markov decisionproblems (Bradtke & Duff, 1995; Sutton, Precup, & Singh, 1999) add notion continuous timediscrete model change used MDPs: transitions one state another one longeroccur immediately, according probability distribution. Others investigate mechanismshierarchically structuring MDPs (Parr & Russell, 1998), decomposing MDPs loosely coupledsub-problems (Parr, 1998), making programmable (Andre & Russell, 2001). Rohanimanesh Mahadevan (2001) propose approach extending MDP-based planning concurrent temporally extended actions. efforts steps towards kind functionalityprovided PHAM framework. Another relationship research reportedMDP research navigation routines modeled PHAM implemented top842fiP ROBABILISTIC H YBRID ACTION ODELSMDP navigation planning. Belker, Beetz, Cremers (2002) useaction models improved execution navigation plans.MDPframework learnapplication MDP based planning reasoning concurrent reactive plans complicated fact that, general, activation termination concurrent sub-plan mightrequire respective modification state action space MDP.Weaver (Blythe, 1995, 1996) another probabilistic plan debugger capable reasoningexogenous events. Weaver uses Markov decision processes underlying model planning.Weaver provides much expressiveness PHAMs. Unlike Weaver, PHAMs designedreasoning physical behavior autonomous mobile robots. Therefore, PHAMs addWeavers expressiveness extensively support reasoning concurrent reactive plans.example, PHAMs predict continuous effects actions trigger concurrentmonitoring process. PHAMs built-in capabilities infer combined effects two continuous motions robot.Qualitative reasoning physical processes. Work qualitative reasoning researchedissues quantization continuous processes focussed among things quantizationsrelevant kind reasoning performed. Hendrix (1973) points limitationsdiscrete event representations introduces limited notion continuous processrepresentation change. consider influence multiple processes state variables.Hayes (1985) represents events histories, spatially bounded, temporally extended, piecestime space, proposes histories intersect interact. Forbus QualitativeProcess Theory (Forbus, 1984) technique called limit analysis applied predict qualitative statetransitions caused continuous events. Also, work simulation often addresses adequacycausal models given range prediction queries, issue neglected modelsused AI planning. Planners predict qualitative state transitions caused continuous eventsinclude EXCALIBUR (Drabble, 1993).Planning model checking. Planning model checking (Bertoli, Cimatti, & Roveri, 2001;Cimatti & Roveri, 2000) represents domains finite-state systems. Planning problems solvedsearching state space, checking existence plan satisfies goals.Goals formalized logical requirements desired behavior plans. Unlike planningmodel checking consider continuous control processes, plan interpretation wellphysical effects actions, concurrency. extended representational power comescost probably finding behavior flaws rather proving absence.Design verification embedded systems based hybrid automata. formalizationembedded software systems (Alur et al., 1997, 1996) using hybrid automata aims provingcritical aspects software rather physical effects running software.approach used ideas research field basis conceptualizationadded additional mechanisms model effects actions sensing mechanisms. Again,additional complexity model compensated solving restrictive inference problems:detection probable behavior flaws high probability rather safety systemreachability goals.843fiB EETZ & G ROSSKREUTZ8. Conclusionsuccessful application AI planning autonomous mobile robot control requires planning systems realistic models operation modern robot control systemsphysical effects caused execution. article presented probabilistic hybridaction models (PHAMs), capable representing temporal structure continuousfeedback control processes, non-deterministic effects, several modes interferences,exogenous events. shown PHAMs allow predictions are, high probability, qualitatively correct. also shown powerful prediction-based inferencesdeciding whether plan likely cause flaw probability exceeding given thresholddrawn fast bounded risk.believe equipping autonomous robot controllers concurrent reactive plansprediction-based online plan revision based PHAMs promising way improve performance autonomous service robots AI planning significantly substantially.rules used projecting navigation behavior hand-coded planpossibly even environment specific. research agenda development transformationalmechanisms learning high performance task specific plans. learned plansrobot learn projection rules applying data mining techniques planexecution traces. enable approach must invent novel representational mechanismsplans allow automatic extraction rules. Initial steps directionfound work Belker et al. (2002), Beetz Belker (2000), Beetz (2002b).ReferencesAlami, R., Chatila, R., Fleury, S., Ingrand, M. H. F., Khatib, M., Morisset, B., Moutarlier, P., &Simeon, T. (2000). Around lab 40 days .... Proceedings IEEE InternationalConference Robotics Automation (ICRA 2000), pp. 8894.Allen, J., & Ferguson, G. (1994). Actions events interval temporal logic. Journal LogicComputation, 4(5), 531579.Allen, J., Kautz, H., Pelavin, R., & Tenenberg, J. (Eds.). (1990). Reasoning Plans. MorganKaufmann.Alur, R., Henzinger, T., & Ho, P. (1996). Automatic symbolic verification embedded systems.IEEE Transactions Software Engineering, 22(3), 181201.Alur, R., Henzinger, T., & Wong-Toi, H. (1997). Symbolic analysis hybrid systems. Proceedings Thirtyssixth IEEE Conference Decision Control (CDC), pp. 702707.IEEE Press.Andre, D., & Russell, S. (2001). Programmable reinforcement learning agents. Advances Neural Information Processing Systems 13, Papers Neural Information Processing Systems(NIPS) 2000, pp. 10191025. MIT Press.Arkin, R. (1998). Behavior based Robotics. MIT Press.Bacchus, F., Halpern, J., & Levesque, H. (1999). Reasoning noisy sensors effectorssituation calculus. Artificial Intelligence 111(1-2).844fiP ROBABILISTIC H YBRID ACTION ODELSBeetz, M. (1999). Structured Reactive Controllers computational model everyday activity. Etzioni, O., Muller, J., & Bradshaw, J. (Eds.), Proceedings Third InternationalConference Autonomous Agents, pp. 228235.Beetz, M. (2000). Concurrent Reactive Plans: Anticipating forestalling execution failures, Vol.LNAI 1772 Lecture Notes Artificial Intelligence. Springer Publishers.Beetz, M. (2001). Structured Reactive Controllers. Journal Autonomous Agents Multi-AgentSystems. Special Issue: Best Papers International Conference Autonomous Agents99, 4, 2555.Beetz, M. (2002a). Plan-based Control Robotic Agents, Vol. LNAI 2554 Lecture NotesArtificial Intelligence. Springer Publishers.Beetz, M. (2002b). Plan representation robotic agents. Proceedings Sixth InternationalConference AI Planning Scheduling, pp. 223232.Beetz, M., Arbuckle, T., Bennewitz, M., Burgard, W., Cremers, A., Fox, D., Grosskreutz, H.,Hahnel, D., & Schulz, D. (2001). Integrated plan-based control autonomous service robotshuman environments. IEEE Intelligent Systems, 16(5), 5665.Beetz, M., Arbuckle, T., Cremers, A., & Mann, M. (1998). Transparent, flexible, resourceadaptive image processing autonomous service robots. Prade, H. (Ed.), ProceedingsThirteenth European Conference Artificial Intelligence (ECAI-98), pp. 632636.Beetz, M., & Belker, T. (2000). Environment task adaptation robotic agents. Horn, W.(Ed.), Proceedings Fourteenth European Conference Artificial Intelligence (ECAI2000), pp. 648652.Beetz, M., Bennewitz, M., & Grosskreutz, H. (1999). Probabilistic, prediction-based schedule debugging autonomous robot office couriers. Proceedings Twentythird GermanConference Artificial Intelligence (KI 99), Bonn, Germany, pp. 243254. Springer Publishers.Beetz, M., Burgard, W., Fox, D., & Cremers, A. (1998). Integrating active localization highlevel control systems. Robotics Autonomous Systems, 23, 205220.Beetz, M., & Grosskreutz, H. (1998). Causal models mobile service robot behavior. Simmons,R., Veloso, M., & Smith, S. (Eds.), Proceedings Fourth International Conference AIPlanning Systems, pp. 163170, Morgan Kaufmann.Beetz, M., & Grosskreutz, H. (2000). Probabilistic hybrid action models predicting concurrentpercept-driven robot behavior. Proceedings Sixth International Conference AIPlanning Systems, Toulouse, France. AAAI Press.Beetz, M., & McDermott, D. (1992). Declarative goals reactive plans. Hendler, J. (Ed.),Proceedings First International Conference AI Planning Systems, pp. 312, MorganKaufmann.Beetz, M., & McDermott, D. (1996). Local planning ongoing activities. Drabble, B. (Ed.), Proceedings Third International Conference AI Planning Systems, pp. 1926, MorganKaufmann.Beetz, M., & Peters, H. (1998). Structured reactive communication plans integrating conversational actions high-level robot control systems. Proceedings Twentysecond845fiB EETZ & G ROSSKREUTZGerman Conference Artificial Intelligence (KI 98), Bremen, Germany. Springer Publishers.Belker, T., Beetz, M., & Cremers, A. (2002). Learning action models improved executionnavigation plans. Robotics Autonomous Systems, 38(3-4), 137148.Bertoli, P., Cimatti, A., & Roveri, M. (2001). Planning nondeterministic domains partialobservability via symbolic model checking. Proceedings Seventeenth InternationalJoint Conference Artificial Intelligence (IJCAI-01). AAAI Press.Blythe, J. (1995). AI planning dynamic, uncertain domains. Extending Theories Action:Formal Theory & Practical Applications: Papers 1995 AAAI Spring Symposium, pp.2832. AAAI Press, Menlo Park, CA.Blythe, J. (1996). Decompositions Markov chains reasoning external change planners. Drabble, B. (Ed.), Proceedings 3rd International Conference ArtificialIntelligence Planning Systems (AIPS-96), pp. 2734. AAAI Press.Blythe, J. (1999). Decision-theoretic planning. AI Magazine, 20(2), 3754.Bonasso, P., Firby, J., Gat, E., Kortenkamp, D., Miller, D., & Slack, M. (1997). Experiencesarchitecture intelligent, reactive agents. Journal Experimental Theoretical ArtificialIntelligence, 9(1).Boutilier, C., Dean, T., & Hanks, S. (1998). Decision theoretic planning: Structural assumptionscomputational leverage. Journal Artificial Intelligence Research, 11, 194.Boutilier, C., Reiter, R., Soutchanski, M., & Thrun, S. (2000). Decision-theoretic, high-level robotprogramming situation calculus. Proceedings Seventeenth AAAI NationalConference Artificial Intelligence, pp. 355362, Austin, TX.Bradtke, S., & Duff, M. (1995). Reinforcement learning methods continuous-time Markovdecision problems. Tesauro, G., Touretzky, D., & Leen, T. (Eds.), Advances NeuralInformation Processing Systems, Vol. 7, pp. 393400. MIT Press.Brooks, R. (1986). robust layered control system mobile robot. IEEE Journal RoboticsAutomation, 2(1), 1423.Burgard, W., Cremers, A., Fox, D., Hahnel, D., Lakemeyer, G., Schulz, D., Steiner, W., & Thrun,S. (2000). Experiences interactive museum tour-guide robot. Artificial Intelligence,114(1-2), 355.Cimatti, A., & Roveri, M. (2000). Conformant planning via symbolic model checking. JournalArtificial Intelligence Research (JAIR), 13, 305338.Dean, T., Firby, J., & Miller, D. (1988). Hierarchical planning involving deadlines, travel timeresources. Computational Intelligence, 4(4), 381398.Doherty, P., Granlund, G., Krzysztof, G., Sandewall, E., Nordberg, K., Skarman, E., & Wiklund,J. (2000). WITAS unmanned aerial vehicle project. Proceedings FourteenthEuropean Conference Artificial Intelligence (ECAI-00), pp. 747755, Berlin, Germany.Drabble, B. (1993). Excalibur: program planning reasoning processes. ArtificialIntelligence, 62, 140.846fiP ROBABILISTIC H YBRID ACTION ODELSDraper, D., Hanks, S., & Weld, D. (1994). Probabilistic planning information gatheringcontingent execution. Proceedings Second International Conference AI PlanningSystems, p. 31.Firby, J. (1987). investigation reactive planning complex domains. ProceedingsSixth National Conference Artificial Intelligence, pp. 202206, Seattle, WA.Forbus, K. (1984). Qualitative process theory. Artificial Intelligence, 24, 85168.Fox, D., Burgard, W., Dellaert, F., & Thrun, S. (1999). Monte Carlo localization: Efficient position estimation mobile robots. Proceedings Sixteenth National ConferenceArtificial Intelligence, Orlando, FL.Ghallab, M., & Laruelle, H. (1994). Representation control IxTeT, temporal planner.Hammond, K. (Ed.), Proceedings Second International Conference AI PlanningSystems, pp. 6167, Morgan Kaufmann.Giacomo, G. D., Lesperance, Y., & Levesque, H. (1997). Reasoning concurrent execution,prioritized interrupts, exogene ous actions situation calculus. ProceedingsFifteenth International Joint Conference Artificial Intelligence, Nagoya, Japan.Grosskreutz, H., & Lakemeyer, G. (2000a). cc-Golog: Towards realistic logic-based robotcontrollers. Proceedings Seventeenth National Conference Artificial Intelligence.Grosskreutz, H., & Lakemeyer, G. (2000b). Turning high-level plans robot programs uncertain domains. Proceedings Fourteenth European Conference Artificial Intelligence (ECAI-00), pp. 548552.Haddawy, P., & Hanks, S. (1992). Representations decision-theoretic planning: Utility functionsdeadline goals. Nebel, B., Rich, C., & Swartout, W. (Eds.), Proceedings ThirdInternational Conference Principles Knowledge Representation Reasoning, pp. 7182, Cambridge, MA. Morgan Kaufmann.Haddawy, P., & Rendell, L. (1990). Planning decision theory. Knowledge EngineeringReview, 5, 1533.Hanks, S. (1990). Practical temporal projection. Proceedings Eighth National ConferenceArtificial Intelligence (AAAI-90), pp. 158163.Hanks, S., Madigan, D., & Gavrin, J. (1995). Probabilistic temporal reasoning endogenouschange. Proceedings Eleventh Conference Uncertainty Artificial Intelligence,pp. 245254. Morgan Kaufmann.Hayes, P. (1985). second naive physics manifesto. Hobbs, J. R., & Moore, R. C. (Eds.),Formal Theories Commonsense World, pp. 136. Ablex, Norwood, NJ.Hendrix, G. (1973). Modeling simultaneous actions continuous processes. Artificial Intelligence, 4, 145180.Horswill, I. (1996). Integrated systems naturalistic tasks. In: Strategic Directions ComputingResearch, AI Working Group.Kabanza, F., Barbeau, M., & St-Denis, R. (1997). Planning control rules reactive agents. Artificial Intelligence, 95, 67113.847fiB EETZ & G ROSSKREUTZKaelbling, L., Cassandra, A., & Kurien, J. (1996). Acting uncertainty: Discrete Bayesianmodels mobile-robot navigation. Proceedings IEEE/RSJ International Conference Intelligent Robots Systems.Konolige, K., Myers, K., Ruspini, E., & Saffiotti, A. (1997). Saphira architecture: designautonomy. Journal Experimental Theoretical Artificial Intelligence, 9(2).Kushmerick, N., Hanks, S., & Weld, D. (1995). algorithm probabilistic planning. ArtificialIntelligence, 76, 239286.Lakemeyer, G. (1999). sensing off-line interpreting golog. Levesque, H., & Pirri, F.(Eds.), Logical Foundations Cognitive Agents. Springer Publishers.Levesque, H., Reiter, R., Lesperance, Y., Lin, F., & Scherl, R. (1997). Golog: logic programminglanguage dynamic domains. Journal Logic Programming, 31, 5984.Levesque, H. J. (1996). planning presence sensing. Proceedings ThirteenthNational Conference Artificial Intelligence, pp. 11391146, Portland, OR.McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. ProceedingsNinth National Conference Artificial Intelligence, pp. 634639, Anaheim, CA.McCarthy, J. (1963). Situations, actions causal laws. Tech. rep., Stanford University. Reprinted1968 Semantic Information Processing (M. Minsky ed.).McDermott, D. (1991). Reactive Plan Language. Research Report YALEU/DCS/RR-864, YaleUniversity.McDermott, D. (1992a). Robot planning. AI Magazine, 13(2), 5579.McDermott, D. (1992b). Transformational planning reactive behavior.YALEU/DCS/RR-941, Yale University.Research ReportMcDermott, D. (1994). algorithm probabilistic, totally-ordered temporal projection. Research Report YALEU/DCS/RR-941, Yale University.Muscettola, N., Morris, P., Pell, B., & Smith, B. (1998a). Issues temporal reasoning autonomous control systems. Sycara, K., & Wooldridge, M. (Eds.), ProceedingsSecond International Conference Autonomous Agents (AGENTS-98), pp. 362368. ACMPress.Muscettola, N., Nayak, P., Pell, B., & Williams, B. (1998b). Remote Agent: boldly goAI system gone before. Artificial Intelligence, 103(12), 547.Myers, K. (1996). procedural knowledge approach task-level control. Drabble, B. (Ed.),Proceedings Third International Conference AI Planning Systems, pp. 158165,Edinburgh, GB. AAAI Press.Parr, R. (1998). Flexible decomposition algorithms weakly coupled Markov decision problems.Cooper, G. F., & Moral, S. (Eds.), Proceedings Fourteenth Conference Uncertainty Artificial Intelligence (UAI-98), pp. 422430, San Francisco. Morgan Kaufmann.Parr, R., & Russell, S. (1998). Reinforcement learning hierarchies machines. Jordan,M. I., Kearns, M. J., & Solla, S. A. (Eds.), Advances Neural Information Processing Systems, Vol. 10. MIT Press.848fiP ROBABILISTIC H YBRID ACTION ODELSPell, B., Gat, E., Keesing, R., Muscettola, N., & Smith, B. (1997). Robust periodic planning execution autonomous spacecraft. Proceedings 15th International Joint ConferenceArtificial Intelligence (IJCAI-97), pp. 12341239, San Francisco. Morgan Kaufmann.Pinto, J. (1994). Temporal Reasoning Situation Calculus. Ph.D. thesis, Department Computer Science, University Toronto, Toronto, Ontario, Canada.Reiter, R. (1996). Natural actions, concurrency continuous time situation calculus.Proceedings Fifth International Conference Principles Knowledge RepresentationReasoning (KR-96), pp. 213.Rohanimanesh, K., & Mahadevan, S. (2001). Decision-theoretic planning concurrent temporally extended actions. Proceedings Seventeenth Conference UncertaintyArtificial Intelligence (UAI), pp. 472479.Schmitt, T., Hanek, R., Beetz, M., Buck, S., & Radig, B. (2002). Cooperative probabilistic stateestimation vision-based autonomous mobile robots. IEEE Transactions RoboticsAutomation, 18(5), 670684.Simmons, R., Goodwin, R., Haigh, K., Koenig, S., & OSullivan, J. (1997). modular architecture office delivery robots. Proceedings First International ConferenceAutonomous Agents, pp. 245252.Smith, D., Frank, J., & Jonsson, A. (2000). Bridging gap planning scheduling.Knowledge Engineering Review, 15(1), 4783.Sutton, R., Precup, D., & Singh, S. (1999). MDPs semi-MDPs: frameworktemporal abstraction reinforcement learning. Artificial Intelligence 112(1-2), 181211.Thrun, S. (2000). Monte Carlo POMDPs. Advances Neural Information Processing Systems12, pp. 10641070. MIT Press.Thrun, S., Beetz, M., Bennewitz, M., Cremers, A., Dellaert, F., Fox, D., Hahnel, D., Rosenberg, C.,Roy, N., Schulte, J., & Schulz, D. (2000). Probabilistic algorithms interactive museumtour-guide robot Minerva. International Journal Robotics Research, 19(11), 972999.Thrun, S., Bucken, A., Burgard, W., Fox, D., Frohlinghaus, T., Hennig, D., Hofmann, T., Krell, M.,& Schmidt, T. (1998). Map learning high-speed navigation RHINO. Kortenkamp,D., Bonasso, R., & Murphy, R. (Eds.), AI-based Mobile Robots: Case studies successfulrobot systems, pp. 21 52. MIT Press.Williamson, M., & Hanks, S. (1994). Utility-directed planning. Proceedings TwelfthNational Conference Artificial Intelligence, p. 1498, Seattle, WA.849fiJournal Artificial Intelligence Research 24 (2005) 685-758Submitted 03/05; published 11/05Ignoring Delete Lists Works:Local Search Topology Planning BenchmarksJorg Hoffmannhoffmann@mpi-sb.mpg.deMax Planck Institute Computer Science,Stuhlsatzenhausweg 85,66123 SaarbruckenGermanyAbstract1998 2004, planning community seen vast progress termssizes benchmark examples domain-independent planners tackle successfully.key technique behind progress use heuristic functions based relaxingplanning task hand, relaxation assume delete lists empty.unprecedented success methods, many commonly used benchmark examples,calls understanding classes domains methods well suited for.investigation hand, derive formal background understanding. perform case study covering range 30 commonly used STRIPS ADLbenchmark domains, including examples used first four international planningcompetitions. prove connections domain structure local search topologyheuristic cost surface properties idealized version heuristic functionsused modern planners. idealized heuristic function called h+ , differspractically used functions returns length optimal relaxed plan,NP-hard compute. identify several key characteristics topology h+ , concerning existence/non-existence unrecognized dead ends, wellexistence/non-existence constant upper bounds difficulty escaping local minimabenches. distinctions divide (set all) planning domains taxonomyclasses varying h+ topology. turns out, many 30 investigated domains lieclasses relatively easy topology. particularly, 12 domains lie classesFFs search algorithm, provided h+ , polynomial solving mechanism.also present results relating h+ approximation implemented FF.behavior regarding dead ends provably same. summarize results empirical investigation showing that, many domains, topological qualities h+largely inherited approximation. overall investigation gives rare examplesuccessful analysis connections typical-case problem structure, searchperformance. theoretical investigation also gives hints topological phenomena might automatically recognizable domain analysis techniques. outlinepreliminary steps made direction.1. Introduction1998 2004, one strongest trends planning communitytowards heuristic planners, specifically towards use heuristic distance (incases, goal distance) estimation functions. best runtime results, progressing far beyondsizes benchmark examples previous domain-independent planners could tacklesuccessfully, achieved based upon technique phrased ignoring delete lists.c2005AI Access Foundation. rights reserved.fiHoffmannThere, heuristic function derived considering relaxation planning taskhand, relaxation assume delete lists (i.e. negative effectsavailable planning operators) empty. search, may forward backward,state space plan space, heuristic value search state framework (anestimate of) difficulty extending state solution using relaxed operators,difficulty defined number (relaxed) actions needed.number real actions needed extend search state solution leasthigh number relaxed actions needed. optimal (shortest) relaxed solutionscan, principle, used derive admissible heuristic functions. However, firstproved Bylander (1994), deciding bounded plan existence, i.e., existence plangiven number actions, NP-hard even delete lists.1Thus much hope find optimal relaxed plans (i.e., optimal relaxed solutionextensions search states) fast. Instead, one approximate length optimalrelaxed plan search state. Techniques kind first, independently, proposedMcDermott (1996) Bonet, Loerincs, Geffner (1997), developed plannersUnpop (McDermott, 1996, 1999), HSP1 (Bonet et al., 1997). plannersperform forward state space search guided approximation relaxed goal distance.Unpop approximates distance backchaining goals, HSP1 approximatesdistance forward value iteration technique.1st international planning competition, IPC-1 (McDermott, 2000), hostedAIPS-1998, HSP1 compared well four competitors. inspired development HSP-r HSP2 (Bonet & Geffner, 1999, 2001b, 2001a), GRT (Refanidis &Vlahavas, 1999, 2001), AltAlt (Nguyen & Kambhampati, 2000; Srivastava, Nguyen, Kambhampati, Do, Nambiar, Nie, Nigenda, & Zimmermann, 2001), well FF (Hoffmann,2000; Hoffmann & Nebel, 2001a; Hoffmann, 2001a). HSP-r avoids heuristic re-computationschanging search direction. HSP2 implements various HSP versions configurable hybrid system. GRT avoids heuristic re-computations changing heuristicdirection (the direction relaxed plans computed). AltAlt uses planninggraph extract heuristic values. FF uses modified technique approximating optimalrelaxed plan length (namely, computing necessarily optimal relaxed plan,done polynomial time), well new pruning search techniques. FF inspired integration heuristic search engines Mips (Edelkamp & Helmert, 2001)STAN4 (Fox & Long, 2001), using elaborated variations FFs relaxed plan lengthestimation technique.2nd international planning competition, IPC-2 (Bacchus, 2001), hosted AIPS2000, heuristic planners dramatically outperformed approaches runtime-wise,scaling benchmark examples far beyond reach previous, e.g., Graphplan-based(Blum & Furst, 1995, 1997), systems. caused trend towards heuristic plannersstill increase. Various researchers extended relaxed plan distance estimation techniquestemporal numeric settings (Do & Kambhampati, 2001; Hoffmann, 2002, 2003a;Edelkamp, 2003b). Others adapted use partial order plan-space search (Nguyen1. parallel planning, bound number parallel time steps needed, deciding boundedplan existence easy without delete lists. However, heuristic functions based observationgenerally found provide useful search guidance practice (see, example, Haslum &Geffner, 2000; Bonet & Geffner, 2001b).686fiWhere Ignoring Delete Lists Works& Kambhampati, 2001; Younes & Simmons, 2002), developed variations providenew means heuristic guidance (Onaindia, Sapena, Sebastia, & Marzal, 2001; Sebastia,Onaindia, & Marzal, 2001), modified take exclusion relations planning graphaccount (Gerevini & Serina, 2002; Gerevini, Serina, Saetti, & Spinoni, 2003).3rd international planning competition, IPC-3 (Long & Fox, 2003), hostedAIPS-2002, 11 domain-independent competing systems, 7 using relaxed plandistance estimations one form. 1st prize winner LPG (Gerevini & Serina,2002; Gerevini, Saetti, & Serina, 2003) uses, amongst heuristics, relaxed planningtechnique estimate difficulty sub-goal achievement planning graph.4th international planning competition, IPC-4 (Hoffmann & Edelkamp, 2005; Edelkamp,Hoffmann, Englert, Liporace, Thiebaux, & Trug, 2005), hosted ICAPS-2004, 13competing sub-optimal systems, 12 using relaxed plan based heuristics.two 1st prize winners category: Fast-Downward (Helmert, 2004; Helmert & Richter,2004) SGPlan (Chen & Wah, 2003; Chen, Hsu, & Wah, 2004). latter usesnumeric version FF sub-process. One version former combines FFs heuristicestimates new heuristic function based causal graph analysis (Helmert, 2004).investigation hand, derive formal background classes domains methods kind described well suited for. make two simplifyingassumptions. First, consider forward state space search only, used by, example,Unpop, HSP, Mips, FF, Fast-Downward. forward state space search, one startsinitial state explores space reachable states goal state found.state transitions follow sequential planning framework, single actionapplied time.2 Assuming forward search makes investigation easier sincesearch natural simple framework. second simplifying assumptionidealize matters consider heuristic value given optimal relaxed planlength (the length shortest sequential relaxed plan) search state s; denotevalue h+ (s). assumption, see many provableconnections domain structure heuristic quality. course, simplifying assumptions restrict relevance results practical planners. saidsection, Section 7. Another, benign, restriction makeconsider solvable tasks only. common restriction AI Planning, particularlycompetitions, main focus good planners finding plans.specifically, main focus investigation hand characterize kindsdomains (relaxed-plan based) heuristic planners find plans fast.common knowledge behavior heuristic search methods (mayglobal local, i.e., without backtracking mechanisms) depends cruciallyquality underlying heuristic function. has, example, studiedSAT community, example Frank, Cheeseman, Stutz (1997). work,authors empirically investigate properties local search topology, i.e., topologicalproperties like sizes local minima etc., SAT instances standard heuristicfunction. adapt Frank et al.s definitions AI planning. difference Frank etal., take analytical approach prove properties valid across2. principle, parallel forward search possible, too. best authors knowledge,published work implementation this, time writing. main difficulty is,presumably, high branching factor.687fiHoffmanncertain ranges, namely domains, example problem instances. investigate range30 commonly used STRIPS ADL benchmark domains including examples usedfirst four international planning competitions. identify several key characteristicstopology respective search spaces h+ . characteristics following.1. 24 benchmark domains, unrecognized dead ends, i.e., statesgoal unreachable relaxed plan.2. 17 24 benchmark domains, maximal exit distance localminima constantly bounded, i.e., one always escape local minima (regionsneighbors higher heuristic value) within number stepsconstant across instances domain, regardless size (in fact, 13domains local minima all).3. 12 17 benchmark domains, maximal exit distance benchesconstantly bounded, i.e., one always escape benches (regions statesheuristic value) within number steps constant acrossinstances domain, regardless size (in 6 domains bound 1, onedomain even 0).Beside positive results proving characteristic qualities h+ function,investigation also provides (parameterized) counter-examples negative cases.results divide investigated domains (more generally, possible planning domains)meaningful taxonomy classes differ terms topological behaviorrespect h+ . Many 30 investigated domains lie relatively easy classes, i.e., classesh+ provably high-quality heuristic. particularly, 12 domainsproperties lie classes FFs search algorithm polynomial solvingmechanism, idealizing assumption FFs approximative heuristic functionidentifies real h+ distances. FFs search algorithm, called enforced hill-climbing, triesescape local minima benches means breadth-first search. Breadth-first searchexponential search depth. local minima benches alwaysescaped within constant number steps case 12 domainseffort spent search polynomially bounded. way, results providenon-trivial insights typical-case problem structure (in benchmarks), possibleeffects search performance. Examples successful theoretical investigations kindextremely rare AI literature.give reader feeling looking at, Figure 1 shows two visualizedstate spaces. shown tasks instances two domains easiest classestaxonomy, Gripper Logistics. graph nodes states, edges statetransitions (action applications), height given h+ value.3 pictures,initial state somewhere left top part. goal states are, course, statesminimal zero h+ value. Gripper picture speaks itself. Logistics topologyless extreme, still state space forms one big valley bottomgoal states.3. h+ values here, empirical investigation (Hoffmann, 2001b, 2003b) preceding theoreticalanalysis, computed iterative deepening forward search space relaxed action sequences.688fiWhere Ignoring Delete Lists Works(a)(b)Figure 1: Visualized state space h+ (a) Gripper (b) Logistics instance.course, FFs approximation h+ , refer hF F , always identifyreal h+ values, priori evident relevance theoretical resultsh+ FFs efficiency practice. Additionally, forward searching plannersuse enforced hill-climbing, topological results strikingimpact. Finally, importantly, several competitive planners evenperform forward search, use additional/new techniques heuristic functionexplicitly aimed identifying better information relaxed plans. Prominent systemsformer kind HSP-r LPG, prominent systems latter kind LPGFast-Downward.relevance results performance FF, practical performanceFF coincides quite well them. concretely, behavior h+ respect deadends provably hF F . Moreover, large-scale empirical investigation(contained Hoffmann, 2003b) shown that, many domains, topology h+largely preserved hF F . include section containing brief summary results.relevance topological results forward search algorithms enforcedhill-climbing, performance planners using search paradigms enhancedheuristics, discussed Section 7.remark topological investigation specifically intended identifyproperties relevant enforced hill-climbing. theoretical investigation precededempirical investigation (Hoffmann, 2001b, 2003b) measured kindstopological parameters, including, example, size diameter local minima, benches,structures so-called valley regions. turned topologyparameters showed interesting behavior across significant number domainsmaximal exit distance parameters considered investigation hand. This, fact,came surprise us invented enforced hill-climbing FF became clear689fiHoffmannmany planning benchmarks share topological properties favoring preciselyparticular search algorithm.Observe proved results worst-case nature, i.e., heuristic search using+h show good behavior example suite domain even domain liesdifficult class taxonomy given particular example instances testsuite emphasize worst cases possible domain. relevant,discuss issue regards example suites used competitions.employed proof methods give hints topological phenomena mightautomatically detectable using general domain analysis techniques. extra section,report first (not yet successful) attempt made that.proofs individual planning domains are, cases, overly difficult,full details domains extremely space consuming. details (except5 IPC-4 domains), i.e., PDDL-like definitions domains well fully detailedproofs, looked long (138 pages) technical report (Hoffmann, 2003c) alsoforms online appendix article.4 article provides proof sketches,much better suited get overall understanding investigation results.Since even proof sketches sometimes hard read, moved appendix;another appendix provides brief descriptions domains. main body textgives results outline main proof arguments used obtain them.paper organized follows. Section 2 provides necessary background, i.e.straightforward formal framework STRIPS ADL domains, overviewinvestigated domains, definitions local search topology. Section 3 presentscore lemmas underlying many proofs single domains, illustrates lemmasapplication small example. Section 4 gives results brief proof outline,shows resulting planning domain taxonomy. Section 5 presents results relatingh+ hF F , Section 6 reports first attempt design domain analysis techniquesautomatically detecting h+ topological phenomena. Section 7 concludes articlebrief discussion contributions future work. Appendix containsproof sketches individual domains, Appendix B contains domain descriptions.2. BackgroundBackground necessary planning framework, investigated domains, localsearch topology.2.1 Planning Frameworkenable theoretical proofs properties planning domains rather single tasks,defined formal framework STRIPS ADL domains, formalizing straightforward manner way domains usually dealt community. outlinerather lengthy definitions, refer reader TR (Hoffmann, 2003c) details.follows, sets mean finite sets unless explicitly said otherwise.4. remark TR longer version paper hand. TRs overall structurepresentation angle different, intended source details needed.690fiWhere Ignoring Delete Lists Worksplanning domain defined terms set predicates, set operators,possibly infinite set instances. logical constructs domain basedset predicates. fact predicate applied tuple objects. operators(k-ary, k number operator parameters) functions (infinite) setobjects (infinite) set STRIPS ADL actions. STRIPS actiontriple (pre(a), add(a), del(a)): precondition, conjunction facts; add list,fact set; delete list, also fact set. ADL action pair (pre(a), E(a))precondition pre(a) first order logical formula without free variables, E(a)set effects e form (con(e), add(e), del(e)) con(e), effect condition,formula without free variables, add(e) (the effects add list) well del(e) (theeffects delete list) fact sets. add list action/effect contains fact p, alsosay action/effect achieves p.instance domain defined terms set objects, initial state, goalcondition. initial state set facts, goal condition formula without freevariables (in STRIPS case, conjunction facts). facts containedinitial state assumed true, facts contained assumed false,i.e., usual apply closed-world assumption. instance domain constitutes,together domains operators, planning task (A, I, G) action setresult applying operators instances objects (i.e., object tuplesappropriate lengths), initial state goal condition G instance.identify instances respective planning tasks.state set facts. logical formula holds state state modelformula according standard definition first order logic (where logical atom,fact, holds iff contained state). result Result(s, hai) applying actionsequence consisting single STRIPS ADL action state defined follows.actions precondition hold s, Result(s, hai) undefined. Otherwise,Result(s, hai) obtained including add effects, (thereafter) removingdelete effects ADL action, add effects add(e) included(delete effects del(e) removed) respective effect condition con(e) holdss. result applying sequence ha1 , . . . , consisting one actionstate defined iterative application single actions obvious manner:apply a1 s, apply a2 Result(s, ha1 i), on.plan, solution, task (A, I, G) sequence actions P that,successively applied I, yields goal state, i.e., state G holds. (We usestandard notation , set, denote set sequences elements.) many proofs need notion optimality. plan P task (A, I, G)optimal plan (A, I, G) contains fewer actions P .Note that, announced introduction, definition, particular definitionplan optimality, stays within forward state space search framework planssimple sequences actions. Note also ignoring delete lists simplifies taskformulas negation free. fixed domain, tasks polynomially normalizedproperty: compute negation normal form formulas (negationsfront facts), introduce negated fact B new fact not-B make suretrue state iff B false (Gazen & Knoblock, 1997). pre-process done in,691fiHoffmannexample, FF. investigation hand, considered normalized versionsdomains.5also consider domains, IPC-4 collection, feature derived predicates. predicates affected effects operators, truth valueinstead derived values other, basic, predicates, via set derivationrules. derivation rule form (x) P (x) P derived predicate(a formula) rules antecedent, using free variables x. obvious ideathat, (x) holds, P (x) concluded. little detail, semanticsdefined follows. initial state, whenever action applied, firstderived predicate instances (derived facts) assumed false, derivation rulesapplied fixpoint occurs. derived facts could concludedsaid false (this called negation failure). Derived predicates usedlike predicate operator preconditions, effect conditions,goal condition. However, ensure unique fixpoint rule application,use derived predicates derivation rule antecedents restricted (in contextIPC-4) positive use sense predicates appear negatednegation normal form rule antecedent (Hoffmann & Edelkamp, 2005).make ignoring delete lists simplification, one also needs derived factsused positively operator preconditions, effect conditions, goal condition(otherwise derived predicates can, example, used model negated preconditions etc.). Due negation failure semantics derived predicates, isntsimple compilation negations pure ADL case. approach take here,implemented in, example, version FF treats derived predicates(Thiebaux, Hoffmann, & Nebel, 2003, 2005), simply ignore (replace true) negatedderived predicates (the negation normal form of) operators goal (see also below,Section 2.3).2.2 Domains Overviewsaid before, case study covers total 30 commonly used STRIPS ADL benchmark domains. include examples first four international competitions,plus 7 domains used literature. Brief descriptions domains lookedAppendix B, full formal definitions domains (except 5 IPC-4 domains)TR (Hoffmann, 2003c). Note that, defining domain, one must amongstthings decide exactly instances are. Naturally, abstractedknown example suites. cases abstraction obvious, less obviouscases respective subsection Appendix B includes explanatory remarks.Here, provide brief overview 30 analyzed domains. domains categorized three groups according semantics, high level abstraction.categorization not, way, related topological characterization derivelater. use give overview structure.5. Ignoring delete lists normalized domains comes relaxation that, basically, allows (thetranslated) facts take truth values time.692fiWhere Ignoring Delete Lists Works1. Transportation domains. domains locations, objectsmust transported, vehicles means transportation.6 Operators mostly either move vehicle, load (unload) object onto (from) vehicle. domains differ terms various constraints. important one that,many domains, vehicles move instantaneously two locations,domains movable links locations form arbitrary road maps.13 transportation domains collection look at. Logistics classical transportation domain, trucks/airplanes transport objects within/betweencities. Gripper robot two gripper hands transports number balls (onetime hand) one room another. Ferry single ferry transportscars one time. Driverlog trucks need drivers board order move,location links form bi-directional road maps (which different trucksdrivers). Briefcaseworld briefcase moves, conditional effects, objects alonginside it. Grid robot transports keys grid-like road mappositions locked must opened keys matching shapes. MiconicSTRIPS elevator transports passengers, using explicit actions board/deboardpassengers. Miconic-SIMPLE like Miconic-STRIPS, passengers board/deboardconditional effects action stops elevator floor.Miconic-ADL like Miconic-SIMPLE, various constraints must obeyed (forexample, VIPs first). Zenotravel airplanes use fuel items replenishedone one using refuel operator. Mprime arbitrary road map, trucks usenon-replenishable fuel items, fuel transferred locations. Mysterylike Mprime, without possibility transfer fuel. Airport inboundoutbound planes must moved safely across road map airport.2. Construction domains. generally closely related transportation domains above. construction domains common, roughly,complex object must built individual parts. 6domains collection look at. Blocksworld-arm classical constructiondomain, blocks picked up/put stacked onto/unstackedmeans robot arm. Blocksworld-no-arm like above, blocksmoved around directly block block / table block /block table. Depots combination Blocksworld-arm Logistics,objects must transported locations stacked ontoother. Freecell encoding solitaire card game comes MicrosoftWindows (the complex object constructed final position cards).Hanoi encoding classical Towers Hanoi problem. Assembly complexobject must assembled together parts, might needassembled beforehand.3. domains. 11 domains collection whose semanticsquite fit either groups. Simple-Tsp trivial STRIPS version6. term transportation domains suggested, example, Long Fox (2000) Helmert(2003). transportation benchmarks generally closely related groupsdomains overviewed below, sometimes discuss transportation domains rather genericlevel.693fiHoffmannTSP problem, move operator applied two locations.Movie order watch movie, one must buy snacks, set counter videozero, rewind tape. Tireworld number flat tires must replaced,involves various working steps (like removing flat tire putting newone). Fridge number fridges, broken compressors must replaced,involves various working steps (like loosening/fastening screws holdcompressor). Schedule objects must processed (painted, example)number machines. Satellite satellites must take images (of phenomena space),using appropriate instruments. Rovers rovers must navigate along road map, takesoil/rock samples well images, communicate resulting data lander.Pipesworld oil derivatives must propagated pipeline network. PSRlines must re-supplied faulty electricity network. Dining-Philosophersdeadlock situation Dining-Philosophers problem, translated ADLautomata-based Promela language (Edelkamp, 2003a), must found. OpticalTelegraph similar Dining-Philosophers, considering encoding telegraphcommunication system.2.3 Local Search TopologyRemember consider solvable tasks, since main focus investigationcharacterize kinds domains heuristic planners find plans fast.discussion unsolvable tasks Section 7.Given planning task (A, I, G). state space (S, ) graph statesreachable initial state, set state transitions, i.e., setpairs (s, s0 ) states action leads s0 executeds. goal distance gd(s) state length shortest path (S, )goal state, gd(s) = path. latter case, dead end;discuss states directly below. heuristic function h : 7 N {}.7 heuristicreturn indicate state hand might dead end.Given STRIPS action = (pre(a), add(a), del(a)), relaxation a+(pre(a), add(a), ). Given ADL action = (pre(a), E(a)), relaxation a+(pre(a), E(a)+ ) E(a)+ E(a) except delete lists empty.set actions, relaxation A+ A+ := {a+ | A}. action sequence++ha1 , . . . , relaxed plan (A, I, G) ha+1 , . . . , plan (A , I, G). that,+state s, h (s) = min{n | P = ha1 , . . . , , P relaxed plan (A, s, G)},minimum empty set .presence derived predicates, said additionally relax planningtask ignoring (replacing true) negated derived predicates negation normalforms preconditions, effect conditions, goal condition. Note that,additional simplification, happen h+ (s) 0 although goal state,simplification might relax goal condition itself. Indeed, happensPSR domain. domains consider here, derived predicates either usedused positively, h+ (s) = 0 iff goal state.7. article focuses mainly h+ heuristic, keep topology definitionsdepend specific heuristic used somewhat general.694fiWhere Ignoring Delete Lists WorksOne phenomenon clearly relevant performance heuristic state spacesearch dead end states s, gd(s) = . heuristic function h return h(s) = .Taking indication dead end, obvious idea removesearch space (this done in, example, HSP FF). technique adequateh completeness preserving sense h(s) = gd(s) = S.completeness-preserving heuristic, dead end state called recognized h(s) =unrecognized otherwise. Note h+ completeness preserving. task solvedeven ignoring delete lists, task unsolvable. assumeheuristic look completeness preserving. respect dead ends,planning state space falls one following four classes. state space called:1. Undirected, if, (s, s0 ) , (s0 , s) .2. Harmless, exists (s, s0 ) (s0 , s) 6 , and, S, gd(s) < .3. Recognized, exists gd(s) = , and, S, gd(s) =h(s) = .4. Unrecognized, exists gd(s) = h(s) < .first class, dead ends everything undone.second class, things undone, single-directed state transitionsharm, sense dead end states. third class,dead end states, recognized heuristic function.critical case heuristic search class four, search algorithm run deadend without noticing it. particularly relevant if, potentially, large regionsstate space consist unrecognized dead end states. capture this, define depthunrecognized dead end number states s0 s0 unrecognized deadend, s0 reachable path moves unrecognized dead ends.investigation determines, 30 benchmark domains looked at, exactlyfour dead end classes instances domain belong. domainsturns unrecognized dead ends, construct parameterizedexamples showing unrecognized dead ends arbitrarily deep. severaldomains, individual instances fall different classes. case associateoverall domain worst-case class, i.e., class highest index above.example, Miconic-ADL, additional constraints obeyedtransportation passengers state space harmless Miconic-SIMPLE.constraints on, example, possible direction travel access floorsgiven, unrecognized dead ends arise. avoid clumsy language, henceforth,say state space harmless/recognized/unrecognized, mean fallsrespective class, class it.get definitions general topological phenomena, i.e., relevant properties search space surface. adapt definitions given SAT Frank et al.(1997). difference SAT framework there, planning formalism here,lies possibly single-directed state transitions planning. search spaces considered Frank et al., state transitions traversed directions. Single-directed695fiHoffmannstate transitions important impact search space topology, enabling,example, existence dead ends.8base entity state space topology Frank et al. name plateaus.regions equivalent reachability aspects, look pointview heuristic function. l N {}, plateau P level l maximal subsetinduced subgraph (S, ) strongly connected, h(s) = lP .9 Plateaus differ terms possibilities leaving heuristic level, i.e.,reaching exit. plateau P level l, exit state reachable P ,h(s) = l exists state s0 , (s, s0 ) , h(s0 ) < h(s). Based behaviorrespect exits, distinguish five classes plateaus. need notionflat paths. paths (S, ) value h remains constant.1. recognized dead end plateau P level l = .2. local minimum plateau P level 0 < l < exit reachableflat path.3. bench plateau P level 0 < l < , least one exit reachableP flat path, least one state P exit.4. contour plateau P level 0 < l < consists entirely exits.5. global minimum plateau P level 0.plateau belongs exactly one classes. Intuitively, roles differentkinds plateaus play heuristic search following. Recognized dead endsignored completeness-preserving heuristic function. Local minima difficultneighbors look worse, clear direction move next. Benchespotentially easier, one step without temporarily worseningheuristic value. contours, one step immediately.10main difficulty heuristic search deal local minimabenches. cases, search algorithm must (eventually) find path exitorder get closer goal (as far heuristic function informedcloser goal not). difficult find exit assessedvariety different parameters. size (number states) diameter (maximum distancetwo states) local minimum/the bench, number nearby exitstates, name important ones. benchmarks considered, mentionedintroduction, empirically found (or few) interesting observationsmade parameters (Hoffmann, 2001b, 2003b).8. One can, course, introduce backtracking mechanisms search space, always givingplanner possibility retract last step. affect relevant topological differencessearch spaces instead domains with/without dead ends, one gets domains backtrackingnecessary/not necessary.9. difference undirected case require states plateau strongly connectedundirected state transitions trivially fulfilled set connected states.10. differences undirected case lie plateaus level , allow exitslie plateaus themselves. latter minor technical device obtain compactterminology.696fiWhere Ignoring Delete Lists Worksone frequently observe interesting properties distance nearestexit state. distance dist(s, s0 ) two states s, s0 usual graphdistance, i.e., length shortest path s0 (S, ),path. exit distance ed(s) search state distance nearest exit, i.e.:ed(s) = min{d | length path (S, ) state s0 s.t. h(s0 ) = h(s),exists state s00 s.t. (s0 , s00 ) , h(s00 ) < h(s0 ) },where, before, minimum empty set . Note requirepath definition flat, i.e., may that, order reach s0 , temporarilyincrease h+ value. want definition capture possibleescape routes state state space, including states lie local minima.maximal local minimum exit distance, mlmed(S, ), state space (S, )maximum exit distances states local minima, 0states. maximal bench exit distance, mbed(S, ), state space (S, ) maximumexit distances states benches, 0 states. findthat, many considered domains, constant upper bounds mlmed(S, )and/or mbed(S, ) h+ , i.e., bounds valid irrespectively (size the)instance chosen.following implication relevant subsequent investigation.Proposition 1 Given solvable task (A, I, G), state space (S, ) completenesspreserving heuristic h, h(s) = 0 gd(s) = 0 S. exists unrecognizeddead end S, mlmed(S, ) = .Proof: Let unrecognized dead end, let s0 state reachableh value s0 minimal. s0 unrecognized dead end, (in particular,considered reachable itself), since h(s0 ) = 0 gd(s0 ) = 0 h(s0 ) > 0.have, since h value s0 minimal among states reachable s,h(s00 ) h(s0 ) states s00 reachable s0 . Thus plateau s0 lies localminimum exits reachable, particular flat paths. also shows s0infinite exit distance.2Proposition 1 says that, every region unrecognized dead ends, localminimum, given h(s) = 0 gd(s) = 0.11 definitions, unrecognizeddead end state yields infinite local minimum exit distance. makes sense definethings way (arbitrarily deep) unrecognized dead end worse localminimum: escaped all.11. Remember latter untrue h+ domain features derived predicatesappear negated negation normal form goal condition. even then, argumentproposition, every region unrecognized dead ends would contain global minimum consistingnon-solution states. could defined fake-global minima local minima, decidedorder overly complicate topological definitions, since detailseem important. said before, one 30 domains h+ (s) = 0 gd(s) = 0anyway.697fiHoffmann3. Core Lemmasmany investigated domains, intuitively similar patterns problem structure causecharacteristic qualities h+ . common structure generalizedcaptured concise definitions lemmas. lemmas formulate sufficient criteria implying (the state space of) planning task certain topological properties. Proofsdomains proceed, possible, applying lemmas arbitrary instances.several domains lemmas applied immediately (due syntactic detailsdomain definitions), similar proof arguments suffice show desired topologicalproperties.restrict STRIPS tasks lemmas. Appropriate extensions ADLand/or derived predicates probably possible least certain cases,investigated detail extensions likely rather complicated notationally,simpler STRIPS case suffices transport ideas.initial state:at(V, L1 ), at(O1 , L1 ), at(O2 , L2 )goal:at(O1 , L2 ), at(O2 , L1 )actions:namepreconditionmove(l, l0 )at(V, l)load(o, l)at(V, l), at(o, l)unload(o, l) at(V, l), in(o, V )add listat(V, l0 )in(o, V )at(o, l)delete listat(V, l)at(o, l)in(o, V )Figure 2: simple STRIPS transportation task.Throughout section, assume given STRIPS task (A, I, G). illustrative example definitions lemmas, use simple transportation taskdefined Figure 2. follows, three separate sections, concerned deadends, local minima, benches, respectively.definitions lemmas following syntactical, sensemake use informations computed efficiently (for example, inconsistenciesfacts). discuss this, focus exclusively role definitionslemmas tools proving h+ topology. role definitions lemmastools automatically detecting h+ topology discussed Section 6.3.1 Dead Endsfirst focus criteria sufficient non-existence dead ends. starting pointreformulated version simple result mentioned by, example, Koehler Hoffmann(2000). need notion inconsistency. Two facts inconsistentreachable state contains them. set facts F inconsistent another set698fiWhere Ignoring Delete Lists Worksfacts F 0 fact F inconsistent least one fact F 0 .12 actioninvertible if:(1) add(a) inconsistent pre(a);(2) del(a) pre(a);(3) action(a) pre(a) (pre(a) add(a)) \ del(a),(b) add(a) = del(a),(c) del(a) = add(a).intentions behind requirements following. (1) (2) ensureeffects occur, (3a) ensures applicable, (3b) (3c) ensureundoes effects. example, actions illustrative task Figure 2invertible. example, = move(l, l0 ) action inverted = move(l0 , l). see that,simply insert definitions: add(a) = {at(V, l0 )} inconsistent pre(a) = {at(V, l)};del(a) = {at(V, l)} = pre(a); pre(a) = {at(V, l0 )} = add(a); add(a) = {at(V, l)} = del(a);del(a) = {at(V, l0 )} = add(a). Similarly easily, one sees load(o, l) unload(o, l)invert other. Examples benchmark domains invertible actions Blocksworld(in variants), Logistics, Gripper.Lemma 1 [Koehler & Hoffmann, 2000] Given STRIPS planning task (A, I, G).actions invertible, state space task undirected.Proof: state applicable action a, applicable Result(s, hai) duecondition (3a) invertibility. Conditions (1) (2) make sure effects factappear (condition (1) requires fact add list inconsistent least onefact precondition), conditions (3b) (3c) make sure undoes exactlyeffects.2remark that, contrast one may think first sight, taskundirected state space even actions invertible sense. Imagine,example, action del(a) = {p} pre(a) = {p0 }, and, due domainsemantics, p0 true p also true. means delete effect always appears;however, detected simple syntax check, del(a) pre(a), useddefinition above.next provide new criterion weaker broadly applicableLemma 1, implies non-existence dead ends. criterion basedweaker version invertibility, two alternative properties whose combinationmake action safe.make action lead dead end, already sufficient inverse actionre-achieves least deleted, delete facts true12. may seem natural define inconsistency fact sets symmetrical fashion, demandingevery fact F inconsistent every fact F 0 . context here, definition wouldstronger need.699fiHoffmannbefore. is, given state applicable, applying Result(s, hai) leadsus back state s0 satisfies s0 s. Formally, action least invertibleaction that:(1) pre(a) (pre(a) add(a)) \ del(a),(2) add(a) del(a),(3) del(a) inconsistent pre(a).Condition (1) ensures, before, applicable Result(s, hai). Condition(2) ensures re-achieves every fact deleted a. Condition (3) ensuresfacts deleted true anyway. Note invertible actionalso least invertible. Conditions (1) (2) obviously given. condition (3),del(a) = add(a) (condition (3c) invertibility), add(a) inconsistent pre(a)(condition (1) invertibility), del(a) inconsistent pre(a). invertiblestronger least invertible; chose name least latter illustratethat, definition invertibility, potentially re-achieves factsoriginal state s.example, consider happens modify move(l, l0 ) action Figure 2include visited(l0 ) fact add list. resulting action longer invertiblemove(l0 , l) delete visited(l0 ). apply, state s, move(l, l0 ) move(l0 , l)sequence, gets us state s0 identical except alsoincludes visited(l) visited(l0 ), may true before. Move actionskind form Simple-Tsp domain. least invertible sense:pre(move(l0 , l)) = {at(V, l0 )} = add(move(l, l0 )); add(move(l0 , l)) = {at(V, l), visited(l)}{at(V, l)} = del(move(l, l0 )); del(move(l, l0 )) = {at(V, l0 )} inconsistent {at(V, l)} =pre(move(l, l0 )).Another property implying action lead dead ends this.action must applied (because add effects remain true), deletesnothing preconditions, action needs inverted. Formally,action static add effects if:[add(a)del(a0 ) = .a0action relevant delete effects, if:del(a) (G[pre(a0 )) 6= .a6=a0del(a) (G a6=a0 pre(a0 )) = , say relevant delete effects,property actually interested in. illustrative task Figure 2,imagine disallow unloading object initial location, loading objectgoal location. remaining unload actions (unload(O1 , L2 ) unload(O2 , L1 ))static add effects action delete goal position object relevantdelete effects action needs object vehicle respectiveunload goal location. Actions characteristics are, example,700fiWhere Ignoring Delete Lists Worksactions make passengers get lift Miconic-STRIPS (a passenger getlift his/her origin floor, get lift his/her destinationfloor). Another example contained Tireworld domain, actioninflates flat wheel: de-flating action add effects static;action goal needs wheel flat relevant delete effects.Lemma 2 Given solvable STRIPS planning task (A, I, G). holds actionseither1. least invertible,2. static add effects relevant delete effects,state space task harmless.Proof: short, reachable state = Result(I, ha1 , . . . , i) plan constructedinverting ha1 , . . . , (applying respective inverse actions inverse order),executing arbitrary plan (A, I, G) thereafter. processes, actions(at least) invertible skipped prerequisite static add effectsrelevant delete effects.detail, proof argument proceeds follows. reachable state =Result(I, ha1 , . . . , i) S, identify solution P (A, s, G). Let hp1 , . . . , pmsolution (A, I, G) (which exists (A, I, G) solvable prerequisite). constructP algorithm shown Figure 3.:=:= n . . . 1ai least invertible aiai 6 apply ai endifelse := {ai }endifendfor:= 1 . . .pi 6 apply pi endifendforFigure 3: Constructing plans tasks actions either least invertible,static add effects relevant delete effects.algorithm, serves kind memory set actions couldinverted. need prove preconditions applied actions fulfilledstate applied, goals true upon termination. Let us startfirst loop. denote si := result(I, ha1 , . . . , ai i) state executing701fiHoffmannith action path s, s0i state first loop starts value i.prove:[[s0i (si (Gadd(a)pre(a)))aMiaA\MiMi denotes current state set. proceed backward induction i.= n, got s0i = si Mi = , equation trivially true. assumeequation true 1. prove equation holds 1. ai leastinvertible, action applied, s0i1 = s0i , Mi1 = Mi {ai }. Concerningleft hand side expression right hand side equation, observe aiprerequisite delete fact G aA\Mi1 pre(a) (Mi1 contains ai ),relevant facts si1 already true s0i . Concerning right hand sideexpression right, observe facts add(ai ) never deletedprerequisite, aMi1 add(a) contained s0i . assume ai least invertibleai . got Mi1 = Mi . Assume ai applied, i.e., ai 6 Mi . applicablepreconditions contained si , element Mi . resulting states0i1 , facts ai deleted si1 added, facts deletedtrue si1 anyway; also, none add effects actions Mi deleted,equation fulfilled. Finally, ai applied, ai Mi , ai static add effectsapplied before, add effects contained s0i , ai delete effects empty.Inserting = 0 equation proved, gets0 (I (G[pre(a)))aA\M0[add(a)aM0second loop starts s0 . start solution plan, excluding actionsset M0 , state including initial facts contained goalprecondition action M0 . state additionally contains add effectsactions M0 , add effects deleted action, clearsimply skip actions M0 achieve goal.2example illustrate proof, consider reachable state Tireworld domain.Every action invertible, except action inflates wheel. Say, proof,state reached action sequence ha1 , . . . , i. algorithm Figure 3is, undo everything done, applying respective ai actions, exceptinflating actions ai . latter stored set . gets us stateidentical initial state, except already inflated flatwheels (those corresponding actions ). state, algorithm executesarbitrary solution, skipping previously applied inflating actions (in ).3.2 Local Minimadefine important kind relationship role action real taskrole relaxed task. Combining definition notions leastinvertible actions, (no) relevant delete effects, yields criterion sufficientnon-existence local minima h+ (or, equivalently, 0 upper boundmaximal local minimum exit distance). criterion directly applied 7702fiWhere Ignoring Delete Lists Works30 investigated domains, applied slight modifications 2 domains.Many individual proofs make use similar, albeit somewhat complicated,proof arguments.key property behind lack local minima h+ is, time,every action good solving real task also good solving relaxed task.Formally, action respected relaxation if:reachable state starts optimal plan (A, s, G),optimal relaxed plan (A, s, G) contains a.Note one assume relaxed plan start a, since relaxationbetter apply action earlier.actions illustrative task Figure 2 respected relaxation. Consider move(l, l0 ) actions, example. If, state s, optimal plan startsmove(l, l0 ), must good reason this. Either a) l0 objectyet transported, b) object truck must transported l0 .cases, relaxed plan must also transport object, chancewithout moving l0 point. Similarly, optimal plan starts load(o, l)action, means must transported somewhere else, relaxed planget around loading it. Finally, optimal plan starts unload(o, l) action,means l goal location o, relaxed plan includeaction.Similar arguments applied many transportation domains.argument regarding move actions becomes little complicated non-trivialroad maps, unlike illustrative example two locationsreachable single step other. Say road map (any) directed graph,modify move action Figure 2 add precondition factdemanding existence edge l l0 . move actions still respectedrelaxation, ignoring delete lists affect shape road map.optimal real path location l location l0 coincides optimal relaxed pathmovements l l0 (even though result executing path different).there, claim follows argument above, namely, optimalplans moves l l0 object provides reason so.transportation domain features additional constraints on, side effects of, moveactions, may respected relaxation. give example below,formulating main lemma regarding local minima h+ .Note exist local minima even actions respected relaxation.Consider following transportation task, featuring single-directional edges roadmap graph. argued above, actions respected relaxation. vehicletwo objects o1 , o2 initially l; o1 must go l1 o2 must go l2 ; edge ll1 single-directed edge l l2 single-directed; l1 l2 ,path n bi-directional (undirected) edges. optimal relaxed plan statewhere, initial state, o1 o2 loaded, length 4: move l l1 l2 ,unload o1 o2 l1 l2 , respectively. However, one moved, s, either l1l2 , optimal relaxed plan length goes n + 2, since entire path l1703fiHoffmannl2 must traversed. lies local minimum, given n > 2; note that, settingn arbitrarily high values, get local minimum arbitrarily large exit distance.turns preventing example, precisely, making use notionsinvertibility relevant delete effects, introduced above, suffices get rid localminima h+ .Lemma 3 Given solvable STRIPS task (A, I, G), state space (S, )contain unrecognized dead ends. action1. respected relaxation,2. least invertible relevant delete effects,local minima (S, ) evaluation h+ .Proof: states gd(s) = local minima prerequisite, h+ (s) = .prove that, every reachable state 0 < gd(s) 6= , action startsoptimal plan (A, s, G), h+ (Result(s, hai)) h+ (s). proves lemma:iterating argument, obtain path goal state s0 , value h+increase path. means exit reachable flat pathh(s0 ) = 0 < h(s) point path h+ value becomes lower h(s), thuslie local minimum.Let reachable state 0 < gd(s) 6= . Let action startsoptimal plan (A, s, G). denote s0 := Result(s, hai). action respectedrelaxation, optimal relaxed plan P + (s) (A, s, G) starts a.Case (A), removing P + (s) yields relaxed plan (A, s0 , G). h+ (s0 ) <+h (s) follows, finished. case, particular, relevant deleteeffects: facts deletes needed action goal, P + (s)without achieves goal starting s0 (where already applied).Case (B), assume removing P + (s) yield relaxed plan s0 . Then,said before, relevant delete effects, must thus leastinvertible. is, action pre(a) (pre(a) add(a)) \ del(a)add(a) del(a). action guaranteed applicable s0 , re-achievesdelete effects. Denote P + (s0 ) action sequence results replacing, P + (s),a. P + (s0 ) relaxed plan (A, s0 , G). seen follows. Observethat, definition, P + (s) without relaxed plan Result(s, ha+ i) (we abbreviatenotation somewhat improve readability). desired property followsResult(s0 , ha+ i) superset Result(s, ha+ i): Result(s, ha+ i) = add(a),s0 = (s add(a)) \ del(a), add(a) del(a). P + (s0 ) relaxed plan (A, s0 , G),yielding h+ (s0 ) h+ (s).2proof Lemma 3 demonstrates along lines, typically, proof argumentsinvestigation proceed. Given state s, consider action starts optimalplan s, consider optimal relaxed plan P + (that contains a, ideally). Then,determine P + modified obtain relaxed plan state resultsexecution. technique forms basis literally proofs except concerneddead ends. Note second prerequisite Lemma 3 fulfilled planning704fiWhere Ignoring Delete Lists Workstasks qualifying undirectedness harmlessness criteria given Lemmas 1 2.Note also that, said above, proved state spaceillustrative example Figure 2 undirected, contain local minimah+ .Domains actions respected relaxation are, example, STRIPStransportation domains Logistics, Gripper, Ferry, Miconic-STRIPS. cases,respective proof arguments similar said above. instructivelook examples action respected relaxation.transportation domain, can, example, happen due fuel usage side effectmoving. Concretely, Mystery domain, applying move action deletes fuel unitstart location (the location move starts). fuel running lowlocations, (real) plan may move along fuel-rich deviations road map.relaxed plan need always move along shortest connectionsmap because, there, actions delete fuel units.Formulated somewhat generally, relaxed plans take short-cuts dontwork reality. short-cuts disjoint (in starting actions) real solutionpaths, local minima may arise even actions (at least) invertible.discussed transportation case, short-cuts correspond intuitive mannerone tends think short-cuts (on road map, namely). casegeneral, i.e., kinds domains. Consider Blocksworld-arm state depictedFigure 4.CBCBFigure 4: local minimum state Blocksworld-arm. goal B table,C B.depicted state, denoted s, B table, arm holds C.goal B table, C B.13 optimal plan put Ctable, unstack B put table, pickup C stackonto B. optimal relaxed plan s, however, stack C onto B immediately,unstack B A, put B table. short-cutrelaxed plan put C table, stacking C onto Bdelete fact declares Bs surface unoccupied. result, lies local13. Usually, Blocksworld goals demanding block table. example,done sake simplicity: one could introduce one block demand Bgoal.705fiHoffmannminimum h+ .14 reason, intuitively, h+ yield local minimamany domains, vicious short-cuts like example dont happen.3.3 Benchescould find nice general sufficient criterion implying upper bounds maximalexit distance local minima except special case localminima thus 0 upper bound maximal local minimum exit distance.did, however, find simple proof argument determining upper bound maximalexit distance benches, tasks qualify application Lemma 3. proofargument works, sometimes slight modifications, 7 domains Lemma 3directly applied domains, maximal bench exit distance bounded1 (bounded 0, one case).proof argument based observing that, many domains, actionsdelete effects irrelevant (for relaxed plan, least) actionapplied optimal solution path. Formally, action relaxed-plan relevantdelete effects if:reachable state starts optimal plan (A, s, G),optimal relaxed plan ha, a1 , . . . , (A, s, G) del(a) (G ni=1 pre(ai )) = .If, reachable state starts optimal plan (A, s, G),optimal relaxed plan ha, a1 , . . . , (A, s, G) del(a) (G ni=1 pre(ai )) = ,say relaxed-plan relevant delete effects, propertyactually interested in. notation, relaxed-plan relevant delete effects,starts optimal plan s, relaxed plan Result(s, hai) constructedsequence ha1 , . . . , i, i.e., skipping relaxed plan s. Thus h+value decreases Result(s, hai). Note n set 0 results goalstate s. Note also that, definition, action relaxed-plan relevant deleteeffects respected relaxation; action respected relaxation,claim anything h+ anyway. Note finally that, assuming actionrespected relaxation, relevant delete effects, i.e., deletegoal precondition another action, also relaxed-plan relevant deleteeffects sense definition.Consider illustrative example Figure 2. Say stateload(o, l) starts optimal plan. means yet transported, locationl0 6= l. particular, means at(o, l) goal, follows actionwhose delete effect at(o, l) relevant delete effects (no actionat(o, l) precondition). Further, say unload(o, l) starts optimal plan s.means l goal location o. applying action, goalachieved, action need refer again, particular action requireinside vehicle, delete effect unload(o, l). action neither14. h+ (s) = 3. h+ value after, s, putting C table 4 (any relaxed planapply two actions two goals). h+ value stacking, s, C onto B still 3 (therelaxed plan unstack C B, unstack B A, put B), successor stateunstack C B again, going back s.706fiWhere Ignoring Delete Lists Worksrelaxed-plan relevant delete effects. contrast, consider move(l, l0 ) action,deletes at(V, l). Say state O1 loaded V initialstate task. move(L1 , L2 ) starts optimal plan s, relaxed planResult(s, hmove(L1 , L2 )i) include action move(L2 , L1 ), moving back L2L1 order able transport O2 . delete effect move(L1 , L2 ), namelyat(V, L1 ), relaxed-plan relevant.If, task satisfying prerequisites Lemma 3, optimal starting actionrelaxed-plan relevant delete effects, one apply case (A) proof Lemma 3,obtain smaller h+ value. bound maximal exit distance benches,need identify maximum number steps happen.Lemma 4 Given solvable STRIPS task (A, I, G) satisfies prerequisitesLemma 3. Let constant that, every non dead-end state S,optimal plan ha1 , . . . , d-th action, ad , relaxed-plan relevant delete effects. mbed(S, ) 1.Proof: Let reachable state 0 < gd(s) 6= . Let ha1 , . . . , optimal plan(A, s, G), ad relaxed-plan relevant delete effects. Denote, 0 n,si := Result(s, ha1 , . . . , ai i). argumentation Lemma 3, h+ (si ) h+ (s)i. Consider state sd1 . prerequisite, optimal relaxed plan0(A, sd1 , G) form , a01 , . . . , a0m i, del(ad ) (Gi=1 pre(ai )) = .00++then, obviously, ha1 , . . . , relaxed plan sd , h (sd ) h (sd1 ) 1.distance sd1 1, lemma follows.2Lemma 4 directly applied 5 7 domains qualify Lemma 3.proof argument can, somewhat general version, applied 2 domainswell namely, Ferry Gripper, loading object deletes space vehicleone domain namely, Miconic-SIMPLE, uses simple ADL constructs.domains proved upper bound maximal exit distancebenches (and/or upper bound maximal exit distance local minima),proof arguments (a lot, sometimes) complicated. Reconsidering illustrativeexample, stated load unload actions relaxed-plan relevant deleteeffects, move actions do. Now, obviously, since two locations accessiblesingle move, optimal plan applies one move actionrow, i.e., optimal plan first second action load/unload.Lemma 4 tells us maximal exit distance benches bounded 1.similar argument applied transportation domains every pairlocations connected via single move (as in, example, Logistics). generally,(the standard encoding of) transportation domain constraints (regarding,example, fuel), undirected road map graph, exit distance boundeddiameter road map graph, i.e., maximum distance two locations(nodes) graph. worst thing solution plan might traverseentire road map loading/unloading object.1515. directed road map graphs, explained above, local minima arise. technically, Lemma 3applied, Lemma 4 applied either.707fiHoffmann4. Planning Domain Taxonomylist proved results, brief explanations obtained results.summarize results form planning domain taxonomy.group positive results prove non-existence topologicalphenomena problematic heuristic search together single theorems.negative results shown separately sketching counter examples. consider deadends, local minima, benches order. Remember that, respect dead ends,problematic case heuristic search unrecognized dead ends, c.f.Section 2.3.Theorem 1 state space solvable instance1. Blocksworld-arm, Blocksworld-no-arm, Briefcaseworld, Depots, Driverlog, Ferry,Fridge, Gripper, Hanoi, Logistics undirected,2. Grid, Miconic-SIMPLE, Miconic-STRIPS, Movie, Pipesworld, PSR, Satellite,Simple-Tsp, Tireworld, Zenotravel harmless,3. Dining-Philosophers, Optical-Telegraph, Rovers, Schedule recognized evaluation h+ .Blocksworld-arm, Blocksworld-no-arm, Driverlog, Ferry, Gripper, Hanoi, Logistics, Lemma 1 directly applied. Briefcaseworld, Depots, Fridge, duesubtleties actions invertible syntactical sense, easy showevery action inverse counterpart. Movie, Miconic-STRIPS, Simple-Tsp,Tireworld, Lemma 2 directly applied, Grid Miconic-SIMPLE similar proofarguments used Lemma 2 suffice. Pipesworld, PSR, Satellite, Zenotravel,easy-to-see individual domain properties prove absence dead ends. domains dead ends recognized h+ , individual domain properties exploitedproofs somewhat involved. example, Rovers plan stateif, soil/rock samples images need taken, roverjob, communicate gathered data lander.chance run dead end take soil/rock sample rover reachlander (the soil/rock sample available once). then, relaxed planstate either.6 domains mentioned Theorem 1 (Airport, Assembly, Freecell, MiconicADL, Mprime, Mystery), easy construct arbitrarily deep unrecognized dead ends(arbitrarily long paths unrecognized dead ends). example, Mystery Mprimerelaxed plan still achieve goal situations much fuel consumedalready; Airport, two planes block others paths may move acrossrelaxed plan.positive results regarding local minima these.Theorem 2 h+ , maximal local minimum exit distance state spacesolvable instance708fiWhere Ignoring Delete Lists Works1. Blocksworld-no-arm, Briefcaseworld, Ferry, Fridge, Grid, Gripper, Hanoi, Logistics,Miconic-SIMPLE, Miconic-STRIPS, Movie, Simple-Tsp, Tireworld 0,2. Zenotravel 2, Satellite 4, Schedule 5, DiningPhilosophers 31.Ferry, Gripper, Logistics, Miconic-STRIPS, Movie, Simple-Tsp, Tireworld,Lemma 3 applied. Fridge Miconic-SIMPLE, actions adhere syntactically definitions invertibility (no) relevant delete effects, similarsemantics. Lemma 3 directly applied, similar arguments suffice: easysee actions respected relaxation, proof Lemma 3 individually adapted take account particular properties regarding invertibilityrelevant delete effects. (For example, passenger gets lift Miconic-SIMPLE,delete effect passenger longer inside lift, mattersince passenger reached destination.) Blocksworld-no-arm, Briefcaseworld,Grid, rather individual (and sometimes quite involved) arguments prove absencelocal minima h+ . proof method is, cases, consider stateidentify flat path state better h+ value. example, Grid donemoving along path locations contained relaxed plan s, keypicked up/put down, lock opened (this simplified description,actual procedure quite complicated). Hanoi, one prove optimal relaxedsolution length state equal number discs yet finalgoal position. suffices optimal plan moves disc away final position. Note that, thus, Hanoi state spaces h+ sequence benches decreasingexponentially diameter size.Zenotravel, Satellite, Schedule, proofs proceed identifying constantnumber steps suffices execute one action optimal relaxed plan states, and, without deleting relevant add effects, re-achieve relevant factsdeleted a. Dining-Philosophers (as well Optical-Telegraph), due subtletiesPDDL encoding was, said, obtained automatic compilationautomata-based Promela language (Edelkamp, 2003a) h+ loosely connectedgoal distance: relaxation, automaton (for example, philosopher) alwaysblock 3 actions. bound Dining-Philosophers followsrather constant restrictive domain structure, constant number processtransitions, namely 6, always suffices block one philosopher. proved boundderived this, considering 4 planning actions needed processtransition, certain additional actions may needed due subtletiesPDDL encoding (where process two internal states). remarkbound valid even trivial heuristic function returning number yetun-blocked philosophers. fact, proof h+ viewed corollary proofheuristic function; get back end section. finally remarkhighest exit distance h+ could actually construct Dining-Philosophers15. conjecture (tight) upper bound.Satellite, Schedule, Zenotravel, proved upper bounds tight.Dining-Philosophers, Satellite, Schedule, Zenotravel, bounds valid nondead end state s. So, beside bound local minimum exit distance, results709fiHoffmannalso provide bound bench exit distance, re-usedsection.Airport, Assembly, Freecell, Miconic-ADL, Mprime, Mystery, statedunrecognized dead ends, Proposition 1 local minimum exit distancedomains unbounded. domains mentioned Theorem 2, i.e.,Blocksworld-arm, Depots, Driverlog, Optical-Telegraph, Pipesworld, PSR, Rovers, oneconstruct local minima arbitrarily large exit distances. complicatedexample Optical-Telegraph, where, difference Dining-Philosophers, one constructsituations number process state transitions needed block one processarbitrarily high. Optical-Telegraph basically version Dining-Philosopherscomplicated philosophers, freedom next. freedom enablessituations whole row philosophers table must perform two transitionsorder block one philosopher. Details Appendix A.2. simpler exampleBlocksworld-arm (as well Depots, Blocksworld-arm situations embedded).Consider following situation. n blocks b1 , . . . , bn initially form stackbi bi+1 bn table. goal build stack topanother block bn+1 , i.e., goal stack b1 , . . . , bn , bn+1 . Reaching, initial state,state better h+ value involves disassembling entire stack b1 , . . . , bn .disassembling process, h+ increases. Note basically extended versionillustrative example Figure 4.interesting side remark, note proved topological differenceBlocksworld-arm Blocksworld-no-arm: latter, local minimah+ , former, exit distance arbitrarily large.intriguing, quite clear general message learn it. One mightinterpret telling us, formal way, encoding details significant impacttopology, search performance. FF, example, much efficientBlocksworld-no-arm Blocksworld-arm. noted, however, twodomains differ also semantically, namely plans Blocksworld-no-arm halflong plans Blocksworld-arm. practical point view, would interestingexplore Blocksworld observation generalized encoding methods tryingmodel domain way making best suited h+ . saidSection 7.positive results regarding benches these.Theorem 3 h+ , maximal bench exit distance state space solvableinstance Simple-Tsp 0, Ferry 1, Gripper 1, Logistics1, Miconic-SIMPLE 1, Miconic-STRIPS 1, Movie 1,Zenotravel 2, Satellite 4, Schedule 5, Tireworld6, Dining-Philosophers 31.Simple-Tsp, Ferry, Gripper, Logistics, Miconic-STRIPS, Movie, Tireworld,Lemma 4 directly applied. Determining actions (no) relaxed-plan relevant delete effects easy domains; Tireworld somewhat complicatedsee when, latest, action applied optimal plan. MiconicSIMPLE, similar arguments Lemma 4 suffice. Zenotravel, Satellite, Schedule,Dining-Philosophers, respective bounds shown already.710fiWhere Ignoring Delete Lists WorksNote that, Simple-Tsp, proved local minima exitdistance 0. implies h+ is, fact, identical real goal distance: entirestate space consists contours global minima.topological distinctions divide planning domains taxonomy classesdiffer terms behavior state spaces respect h+ . visualizationtaxonomy, results 30 investigated domains, given Figure 5.BlocksworldarmDepotsDriverlogPipesworldPSRRoversOpticalTelegraphMysteryMprimeMiconicADLFreecellAssemblyAirportmbed <= cmlmed <= cHanoi [0]Blocksworldnoarm [0]Fridge [0]Grid [0]Briefcaseworld [0]Logistics [0,1]Ferry [0,1]Gripper [0,1]undirectedTireworld [0,6]Satellite [4,4]Zenotravel [2,2]MiconicSIMPLE [0,1]MiconicSTRIPS [0,1]Movie [0,1]SimpleTsp [0,0]harmlessDiningPhil. [31,31]Schedule [5,5]recognizedunrecognizedFigure 5: planning domain taxonomy, overviewing results.taxonomy, shown Figure 5, two dimensions. x-axis correspondsfour dead end classes. y-axis corresponds existence non-existence constantupper bounds local minimum exit distance, bench exit distance. Notevisualization makes simplifying assumption domains boundedbench exit distance subset ones bounded local minimum exit distance.assumption justified general, holds true specific collection domains.Also, question whether bound difficulty escaping benchesseem relevant when, anyway, arbitrarily difficult escape local minima.16specific bounds proved individual domains given parentheses, local minimumexit distance bound preceding bench exit distance bound cases both.bottom right corner taxonomy crossed domain belongrespective classes.1716. Similarly, benches arbitrarily large relevant local minimasmall non-existent. sense respective results Briefcaseworld, Fridge, Grid, Blocksworldno-arm, Hanoi moderately important. Still constitute interesting propertiesdomains.17. Proposition 1, existence unrecognized dead ends implies non-existence constant upperbounds local minimum exit distance, given states gd(s) 6= 0 h+ (s) = 0.states exist, domain features derived predicates appear negated negation711fiHoffmannFigure 5 suggests h+ -approximating heuristic planners fastmany common benchmark domains lie easy regions taxonomy.concretely, described introduction, provided h+ function, FFssearch algorithm enforced hill-climbing polynomial domains located lowermost classes taxonomy (i.e., domains constant bounds maximalexit distances). empirical perspective, distinction lines taxonomycoincide quite well practical performance FF. FF excels 11 12 domainsbelong lowermost classes taxonomy (the difficult domain DiningPhilosophers, whose upper bound exceptionally high). 5 middle domains (nolocal minima potentially large benches) FF performs well, scalecomfortably easier domains. complex domains: Blocksworld-arm,Depots, Driverlog, Optical-Telegraph, Pipesworld, PSR amongst challenging domains FF. Mprime Mystery, FF performs badplanners. Freecell Miconic-ADL, FF among top performing planners, oftenruns unrecognized dead ends larger instances (for example, larger Freecellinstances used AIPS-2000). Airport, Assembly Rovers, FF performs pretty wellrespective competition example suites; however, domains competition suiteshardly explore worst-cases domain topology (details Appendix A).discuss detail relation taxonomy empirical performance heuristic planners make use h+ approximation oneway. One observation definitely made plannerstrouble solving instances domains extreme h+ properties.Simple-Tsp, Ferry, Gripper, Logistics, Miconic-SIMPLE, Miconic-STRIPS, Movie,extent also Zenotravel, planners scale comfortably. particular,scale much comfortably domains typicallydomains, least without additional (for example, goal ordering) techniques.next section, treat connection taxonomy FFs performanceanalytical way, relating properties h+ properties FFs approximationh+ , called hF F . so, remarks relation taxonomycomplexity theory order. question whether provable relation, i.e.,relation distinction lines taxonomy, complexity decidingplan existence respective domains. able construct NP-hard domain(a domain deciding plan existence NP-hard) h+ yield localminima; maximal bench exit distance domain is, however, unbounded. tried,able come NP-hard domain constant boundsmaximal exit distances. remains open question whether domain existsnot. answer yes, lowermost classes taxonomy form groupdomains worst-case hard, typically easy solve (at least farnormal form goal condition. even then, presence unrecognized dead endswould fake-global minima, i.e., global minima consisting non-solution states, fact consistingunrecognized dead ends.712fiWhere Ignoring Delete Lists Worksreflected hitherto benchmarks). answer no, identifiedlarge polynomial sub-class planning.18Talking polynomial sub-classes, intriguing observation madetrivial heuristic function returning, state s, number goals trues. Lets call function hG . little thinking, one realizes that, fact,12 domains proved constant bounds maximal exit distances h+ alsoconstant bounds hG . hand, remaining 18 30domains (except Miconic-ADL) easy see constant bounds hG .Logistics, example, clearly maximum number steps needed achieve onegoal 12: 4 steps (move, load, move, unload) within packages origin city,origin city destination city, within destination city. DiningPhilosophers, example, upper bound h+ was, said, proved corollaryupper bound hG . Blocksworld, example, clearly take arbitrarily manysteps achieve one goal, namely block must moved buried beneath nblocks need moved.observation appears rather significant first sight, probablyimportant, neither theory practice. one thing, coincidence that,here, set domains constant bounds h+ setdomains constant bounds hG . simple counter example generalcase graph-search domain, task find path two nodesdirected graph, using obvious at-predicate connected-predicate based encoding.There, h+ equal real goal distance (since one never needs move back),hG can, clearly, arbitrarily bad. another thing, domains like Logisticsconstant exit distance bounds hG , bounds large practically useful.example, h+ , FF needs look 2 steps forward breadth-firstsearch iteration enforced hill-climbing, Logistics instance. hG , breadth-firstsearches depth 12 would needed. So, most, observation regarding hGnoteworthy statement current planning benchmarks. remains open questionwhether (coincidental) correspondence bounds h+ , hG ,investigated 30 domains, exploited for, e.g., detecting bounds automatically.5. Relating h+ hF Fdiscussion relating h+ hF F structured two separate sections. first onebriefly discusses provable relations h+ hF F . second section summarizesresults large-scale empirical investigation aimed identifying extenttopological properties h+ , benchmarks, get preserved hF F .5.1 Provable Relations h+ hF FOne thing easy observe behavior h+ hF F provablyrespect dead ends, i.e., heuristics return cases.simply heuristics return state iff relaxed plan s.18. Presumably, prove latter, one would need characterize class purely syntactic mannerlevel PDDL definitions, since h+ derived directly PDDL syntax. authors wildguess going work, answer yes.713fiHoffmannh+ follows definition. hF F follows completeness, relativerelaxation, algorithm computes relaxed plans (Hoffmann & Nebel, 2001a).algorithm relaxed version Graphplan (Blum & Furst, 1995, 1997). state s,FF runs Graphplan task initial state, delete lists actionsempty. Without delete lists, Graphplan guaranteed terminate polynomial time.Graphplan terminates unsuccessfully, hF F (s) set . Otherwise, numberactions returned plan taken heuristic value hF F (s) state.19 Graphplancomplete algorithm terminates successfully planhF F set iff relaxed plan s. follows dead end classesbenchmarks h+ hF F .relaxed plans found Graphplan (just general STRIPS) propertyoptimal terms number parallel time steps, termsnumber actions. So, general, hF F h+ (even P NP).FF uses following heuristic techniques action choice relaxed Graphplan, aimingminimizing number selected actions (Hoffmann & Nebel, 2001a). First, factachieved NOOP (a dummy action propagating fact time step timestep + 1 Graphplans planning graph), NOOP selected. guaranteesevery non-NOOP action selected (of course, selected NOOP actionscounted relaxed plan). Second, NOOP available actionminimal precondition weight chosen, weight defined summedup indices first layers appearance (in planning graph) preconditionfacts. Third, actions selected parallel time step assumed linearizedorder selection; action selected a0 assumed achieve factp add(a) pre(a0 ) even a0 selected parallel time step.two restrictive sub-classes STRIPS hF F provablyh+ . first demands every fact one achiever.Proposition 2 Let (A, I, G) STRIPS planning task that, facts p,one action p add(a). Then, states task, h+ (s) = hF F (s).Proof: proposition follows observation that, running relaxed Graphplan, choice points action selection; choice points alwaysempty unary case. implies actions selected Graphplancontained relaxed plan. detail, latter proved inductionregression steps relaxed Graphplan. Let state relaxedplan. top level regression, actions selected support goalscontained s. goals need supported relaxed plan,actions so. holds true preconditions selectedactions: p pre(a) s, supporter must present relaxed plan,supporter selected relaxed Graphplan. Iterating argument, getdesired property. claim follows because, proved Hoffmann Nebel(2001a), relaxed Graphplan selects every action once.219. Note estimate sequential relaxed plan length. length planning graph builtGraphplan corresponds optimal length parallel relaxed plan, admissible heuristic estimate.However, indicated before, heuristic functions generally found provide usefulsearch guidance practice (see, example, Haslum & Geffner, 2000; Bonet & Geffner, 2001b).714fiWhere Ignoring Delete Lists Workssecond sub-class STRIPS demands one goal,one precondition per action.Proposition 3 Let (A, I, G) STRIPS planning task |G| 1 and, A,|pre(a)| 1. Then, states task, h+ (s) = hF F (s).Proof: given restrictions, relaxed planning comes finding pathsgraph nodes facts, edge p p0 iff actionpre(a) = p add(a) = p0 (empty preconditions modelled special factnode assumed always true). state relaxed plan iff makes fact nodetrue path goal node. Relaxed Graphplan identifies shortestpath.2prerequisites Propositions 2 3 maximally generous, i.e., relaxing onerequirements, one loses h+ (s) = hF F (s) property. obtain sub-optimal relaxedplans Graphplan, i.e., construct cases h+ (s) 6= hF F (s), suffices onefact two achievers, either two goal facts one action two preconditions.following example. facts g1 , g2 , p, p0 . goal {g1 , g2 },current state empty. actions shown Figure 6.nameopg1opg2 -popg2 -p0oppopp0=====(pre,add,del)({p},({p},({p0 },(,(,{g1 },{g2 },{g2 },{p},{p0 },)))))Figure 6: Actions example task hF F 6= h+ .optimal relaxed plan hopp, opg1 , opg2 -pi. However, Graphplan might chooseachieve g2 opg2 -p0 , ending (parallel) relaxed plan h{opp, opp0 }, {opg1 ,opg2 -p0 }i. Note action single precondition, single factone achiever, two goals. similar example constructedcase one goal one action two preconditions.Obviously, syntax allowed either Propositions 2 3 far restrictiveadequate formulating practical domains.20 investigate whetherinteresting situations h+ hF F same; intuitioncase.different question whether provable relations h+ hF F (someof) 30 benchmark domains considered h+ investigation. investigatequestion detail note investigation would involve constructing detailed20. remark syntax identified Proposition 3 sub-class tractable class STRIPSplanning identified Bylander (1994). Bylanders class, constant number g goal facts allowed,g greater 1; preconditions may positive negative.715fiHoffmannarguments individual domains, clearly beyond scope paper.None domains captured either Propositions 2 3. resultseasy obtain following. Simple-TSP, Movie, Miconic-STRIPS, h+ hF Fsame. follows extremely simple structure domains,finding step-optimal relaxed plans Graphplan always results relaxed plansoptimal number actions. However, even slightly complicated domainsFerry, Gripper, Logistics, Miconic-SIMPLE, Zenotravel, one easily construct statesGraphplans relaxed plans may unnecessarily long. Miconic-STRIPShappen single vehicle (the lift), capacity restrictions(on number loaded objects, i.e., passengers). several vehicles transportableobjects, occur Logistics Zenotravel (as well Driverlog, Depots, Mprime,Mystery, Rovers), difference h+ hF F become arbitrarily large.imagine n objects must transported l l0 , n vehicles availablel. parallel relaxed planning, makes difference single vehicle transportsobjects, one different vehicle selected per individual object. particular, evenFFs action choice heuristics relaxed Graphplan, hF F may 2n + 1 well 3n.21Ferry Gripper, single vehicle (with capacity restrictions),may upper bound difference h+ hF F ;check detail.spite above, authors personal experience developing FF that,least relatively simply structured domains many different operators/differentways achieve facts, relaxed plans found relaxed Graphplan typically prettyclose optimal. are, presumably, following two reasons this. First,employed action choice heuristics. example, Grid domain, relaxed plan maychoose pick key k sole purpose dropping pickinganother key k0 pickup-and-lose action (c.f. Appendix B.12). happenselecting actions minimal precondition weight (the pickup-and-lose actionhigher weight pickup action unless one already holds k considered state).Second, many published benchmark instance suites quite restricted. Logistics,example, situation outlined above, n objects n vehicles waiting location l,happen trucks single truck city. airplanes,published benchmark instances usually these, nsmall.5.2 Empirical Relations h+ hF Flarge-scale empirical investigation (Hoffmann, 2003b), turned hF F typicallypreserves quality h+ . investigation aimed verifying, domainsh+ positive topological property (for example, yielding local minima),extent property inherited hF F . considered 20 benchmark domains,namely domains paper hand, except 10 IPC-3 IPC-4 domains.21. One could circumvent particular phenomenon by, selecting action relaxed Graphplan,employing minimization summed weight preconditions actions selected far.topic future work explore effect FFs performance.716fiWhere Ignoring Delete Lists WorksNote that, latter 10 domains, three, namely Dining-Philosophers, Satellite,Zenotravel, positive topological properties.experimental approach take samples state spaces (a technique adaptedwork Frank et al., 1997). precisely, method following.domain, random generator used produce large set example instances.instances grouped together according values domain parameters, i.e.,input parameters generator (for example, number floors number passengersMiconic-SIMPLE). Then, single instance, 100 states sampled, i.e., 100random sequences actions executed initial state, sequence lengthchosen randomly interval 0 2 times FFs plan length.22resulting state s, exit distance ed(s) computed breadth-first search, anothersearch determined whether located valley, i.e., whether pathgoal state hF F value decreased monotonically.23 maximal exitdistance instance approximated maximum exit distancessample states. every group instances, mean number states valleys,mean maximal exit distance, computed. results visualized plottingvalues scaling domain parameters. give examples directly below,summarizing overall results.results experiment strongly suggested hF F typically preserves qualityh+ , considered benchmark domains. 13 domains h+ provably yieldslocal minima, almost sample states located valleys except 2 domains,namely Grid Hanoi. precisely, 11 domains experiment consideredtotal 230 groups random instances; one groups, 5.0% sample stateslay valleys, another group 2.2%, another eight groups 1.0%,remaining 220 groups single valley state found. maximalexit distance benches, tested instances domains boundh+ , single sample state exit distance larger bound, namelyexit distance 2 instead 1 Logistics domain.24Blocksworld-no-armGripperHanoiTireworld0.00.00.00.00.00.00.00.00.00.096.00.00.10.0100.00.00.00.0100.00.0Figure 7: Percentage sample states valleys. Mean values linear increaserespective domain parameter.Figure 7 provides results regarding sample states valleys, considereddomains local minima (and thus valleys) h+ , in22. tried sampling strategies found make much difference termsobtained results.23. Intuitively, local minimum lies bottom valley. used valleys experiment sincemay hard find local minimum state sampling.24. authors guess results similar empirical investigation Dining-Philosophers, Satellite,Zenotravel would similar, i.e., sampled maximal exit distances would hardly increaseupper bounds proved h+ .717fiHoffmannstances characterized single domain parameter (Movie Simple-Tsp leftsince hF F provably h+ ). Blocksworld-no-arm, parameternumber blocks (plus randomization initial goal states); Grippernumber balls transported; Hanoi number discs; Tireworldnumber flat tires. domain, left right table entries correspondlinear increase domain parameter (2 . . . 11 blocks, 1 . . . 100 balls, 3 . . . 10 discs,1 . . . 5 tires, respectively). Obviously, domain behave Hanoih+ isnt useful heuristic anyway, yielding large benches, c.f. Section 4.Blocksworld-no-armGripperHanoiTireworld0.31.06.06.01.81.023.06.02.81.012.06.03.81.02.06.03.71.02.02.0Figure 8: Sampled maximal exit distance. Mean values linear increase respectivedomain parameter.Figure 8 shows results regarding sampled maximal exit distance domainscharacterized single domain parameter. Gripper Tireworld, sampled valuesrespect bound valid h+ (in largest Tireworld example, samplingfind maximum state rather large state space). comparison, sampled valuesBlocksworld-no-arm, bound h+ , show clear increase. Again,behavior Hanoi odd.Figure 9 shows (part of) results domain characterized onedomain parameter, namely Logistics. domains least two domain parameters,experimental method run one experiment pair them. experiment,parameters except respective pair set fixed value. data couldvisualized 3-dimensional plots like ones Figure 9. figure, parametersscaled number cities number objects (packages) transported;parameter range 1 . . . 9 cases. City size number airplanesfixed 3. parameter value combination, 10 random instances generated (and100 states sampled per instance). valley states found, except 3 cities9 objects, 2 1000 sample states located valley. 5 cities3 objects, single instance one sample state exit distance 2, rather bound1 valid h+ single bound violation found entire experiment.25indicated before, Grid domain was, Hanoi, domainexperiment suggested major difference topologies h+ hF F . Largefractions sample states, 62.4%, located valleys. cleartendency increase percentage, increasing grid size increasingnumber keys transported.all, experiment confirmed that, Blocksworld-no-arm, Briefcaseworld, Ferry, Fridge, Gripper, Logistics, Miconic-SIMPLE, Tireworld domains, hF F25. decrease mean sampled maximal exit distance large parameter values suggestsbecomes harder, sampling, find maximum states rather large state spaces.718fiWhere Ignoring Delete Lists WorksZZ120.510099717153X535537X9 1(a)379 1(b)Figure 9: Mean sampled valley percentage (a) maximal exit distance (b) Logistics,scaling cities (x-axis) objects (y-axis).largely preserves quality h+ (no local minima and/or constant bound maximal exit distance benches). Remember Miconic-STRIPS, Movie, Simple-Tspthree domains this, provably, applies.6. Towards Automatically Detecting h+ Phenomenalemmas presented Section 3 provide natural starting point investigationsdomain analysis techniques trying detect topological phenomena automatically.domain analysis techniques would useful configuring hybrid systems, i.e.,automatic selection heuristic functions likely well-suited solving givenplanning task. Further, techniques would useful avoiding need re-doh+ investigation every single new planning domain. Finally, basisanalysis techniques one may able compute good lower bounds h+ ,informative admissible heuristic function. discussion points containedSection 7.question addressed if, extent, how, applicationlemmas Section 3 automated, i.e., one automatically checkwhether prerequisites satisfied given STRIPS task. section hand,present preliminary attempt made that. attemptsuccessful, believe investigation value showing one achievesimple analysis techniques, weak points would needed improvedupon order obtain better results.Invertible (or least invertible) actions, actions irrelevant delete/static addeffects, syntactically defined Section 3 thus easy detect. difficultyfind inconsistencies facts. hard planning itself,several approximation techniques literature (for example, Blum & Furst, 1995, 1997;Fox & Long, 1998; Gerevini & Schubert, 2000, 2001; Rintanen, 2000), tend workwell, least current benchmarks. challenge find syntacticalcharacterizations actions respected relaxation, actions719fiHoffmannrelaxed-plan relevant delete effects. Now, many domains phenomenaoccur, example Ferry, Gripper, Logistics, Miconic-STRIPS, Movie, Simple-Tsp,Tireworld, intuitively one looks domains causes phenomenaseem similar. getting actual syntax domain descriptions,individual details different becomes difficult get holdcommon ground. seem simple syntactical definition capturesbehavior actions domains; least find syntacticaldefinition. Instead, tried reason additive structure domains,possible interactions delete effects. (The intuition that, domainssimple h+ topology, interactions arent harmful.) capturedadditive structure domain/of instance data structure called fact generationtrees. next subsection describes data structure basic properties,subsection gives results extreme case h+ topology, subsection outlinessomewhat advanced analysis technique developed.6.1 Fact Generation Treesfact generation tree, short FGT, planning instance basically AND/OR treeresults regression search starting goals, ignoring delete effectsactions. Tree nodes labelled facts actions alternatingly. Fact nodesnodes represent choice achieving actions action nodes nodespreconditions represent sets facts must achieved together. assume goalachievement action, known from, example, description UCPOP (Penberthy &Weld, 1992). action root (AND) node FGT, top level goals formsons. Obviously, sons fact node actions achieve fact,sons action node precondition facts action. (For sakesimplicity, stayed pure STRIPS framework investigation.) Tree structureskind were, example, described used Nebel, Dimopoulos, Koehler (1997)work automatically detecting irrelevant facts operators. Note FGTtake account interactions may arise trying achieve factsnode together. effect ignoring delete lists, FGT treatsfacts completely separately.terminate FGT applying following two rules.1. Say inserted action node N (a) labeled action a. factp pre(a) fact node labeled p occurs path root nodeN (a), N (a) pruned.2. Say inserted, son action node N (a), fact node N (p) labeledfact p. action a0 p pre(a0 ), action node labeleda0 occurs path root node N (a), N (p) pruned.Intuitively, rules disallow generation branches FGT would redundant relaxed plan. Formally, call relaxed plan non-redundant strict subsequence still relaxed plan (i.e., action omitted). Every non-redundantrelaxed plan, every (not necessarily reachable) state, embedded connected,rooted, non-redundant sub-tree FGT built way described above.720fiWhere Ignoring Delete Lists Worksprecise introducing illustrative example Figure 10, usethroughout section.EE== 1 EURmv E+= 1 EURBC1 EURmv Bmv CBCmv Cmv BFigure 10: Sketch FGT illustrative example.example, task reach location E. available actions moves along(bi-directional) graph edges obvious encoding using predicate, exceptmove E, requires additional precondition possession1 EUR. acquire 1 EUR add effect action movesC. main part Figure 10 shows FGT example, picture top leftcorner illustrates example showing road map graph indication role1 EUR constructs. root node, i.e., artificial goal-achievement action,included figure, simplicity. Due termination rule 1, (for example) movingE included son fact node labeled (the precondition Eroot node). Due termination rule 2, son action node labeledmv C (at already occurs precondition mv E above).Every action non-redundant relaxed plan (to arbitrary state) achievesunique needed fact achieved preceding action, neededgoal precondition subsequent action.26 overly difficult proveone thus embed relaxed plan FGT processing relaxed planback front, associating action corresponding node neededfact added action, starting goal facts. resulting sub-tree connectedrooted sense actions associated consecutive nodes, startingroot node. sub-tree non-redundant sense that, every node,26. observation made by, example, Hoffmann Nebel (2001b), used detectactions participate non-redundant relaxed plan, thus needconsidered heuristic computations done planners FF HSP.721fiHoffmannone son gets associated action. Termination rule 1 valid since fact neededend relaxed plan also needed start. Termination rule 2 validsince every needed fact least one representative node corresponding subtree. illustration, consider different locations graph underlying exampleFigure 10. one located, example, 1 EUR,entire FGT except mv C node corresponds sub-tree non-redundantrelaxed plan. sub-tree obtained follows. relaxed plan mv B, mv BD, mv C, mv E. needed facts added actions B, D, 1EUR, E, respectively. Starting goal fact E, first mv E getsassociated respective action node. fact nodes 1 EURpreconditions action dealt become open, mv B wellmv C get associated respective node respective needed fact.consequence mv B action, fact node B becomes open, mv B getsassociated action node it. process stops. If, current state,one is, example, located C 1 EUR, process selects sub-treeconsists mv C mv E nodes only.Every non-redundant relaxed plan instance, particular every optimal relaxedplan instance, corresponds sub-tree FGT. FGT summarypossible relaxed plans sense, idea examine FGT harmful interactionsconflicts potential appear relaxed plan. hope able drawconclusions non-existence/restricted form conflicts topological propertiesh+ . next outline extreme case analysis kind, namely one postulatesabsence conflicts FGT. Note that, difference situationillustrative example, general FGT contain action/fact labels multiple nodes.worst-case size FGT exponential size instance description. So,design practically usable domain analysis techniques, one would need approximateFGT, instead building completely. aspect treated follows,objective (only) find implications FGT structure h+ topologyfirst place.6.2 Interaction-free Planning TasksThink conflict situation one part (non-redundant) relaxed planhinder execution/success another part relaxed plan.conflicts, every (non-redundant) relaxed plan executable reality, implyingh+ equal real goal distance (which course implies local minimaetc). investigated 30 benchmark domains, case (only) Simple-Tsp,use motivating example.define three kinds conflicts FGT. call two action nodes, labeledactions a0 , allied participate together non-redundant sub-tree, i.e.,occur together embedding relaxed plan, descendantsother. (This case iff paths root node a0 separatenode.) first kind conflicts given pair allied action nodes labeled a0 ,deletes precondition a0 . Second kind conflicts, pair action nodes labeleda0 , descendant a0 , deletes precondition a0 added722fiWhere Ignoring Delete Lists Worksaction path a0 . Third kind, action node labeled a,deletes goal fact added action path respective rootnode.conflicts FGT, call task interaction-free. relativelyeasy see that, without conflicts, every non-redundant relaxed plan (for every nonredundant sub-tree FGT) execution order works reality. h+equals goal distance interaction-free tasks.illustrative example Figure 10, conflict FGTnodes mv C mv E nodes allied, mv C deletesprecondition mv E. Note conflict indeed capture reasonh+ equal goal distance example. order able moveE, one first move C get 1 EUR. latter deletesprecondition former. relaxation, move C, onelocated C time, relaxed plan needs one step lessachieve goal (from states move C yet done).example domain interaction-free tasks graph-search domain mentioned earlier, tasks demand find path two nodes directedgraph, using obvious at-predicate connected-predicate based encoding. (Ourillustrative example becomes instance domain one removes 1 EURconstructs.) even come purely syntactic criterion capturesexample domain.Proposition 4 Let (A, I, G) STRIPS planning task1. |G| 1,2. A: |pre(a)| 1,3. A: del(a) pre(a).(A, I, G) interaction-free.Proof: Due prerequisites 1 2, nodes FGT one son.implies allied action nodes. Together prerequisite 3termination rule 1, implies action node delete goal fact, preconditionfact ancestor node.2Instances graph-search domain fulfill prerequisites Proposition 4static connected facts removed prior planning. Note syntax identifiedProposition 4 subset syntax identified Proposition 3, thus taskshF F identical h+ , and, since h+ identical real goal distance, plan existencedecided polynomial time. Intuitively, captured syntaxexpress graph-search domain: plans task qualifying Proposition 4correspond exactly paths graph nodes facts, edges gopreconditions add effects. true relaxed plans.instances Simple-Tsp domain interaction-free. conflictsFGT pairs actions achieving different visited goals. example, say723fiHoffmannthree locations visit, l1 , l2 , l3 . action nodes mv l1 l2 mv l1l3 allied since achieve goals visited l2 visited l3 participateroot node. actions mutually delete precondition, l1 ,constitute conflict FGT. appear together relaxed plan,relaxed plan executable reality (unless relaxed plan happens move backl1 between). Observe, however, execution of, example, mv l1 l2 , onereplace mv l1 l3 mv l2 l3 repair conflict relaxed plan.conflicts Simple-Tsp FGTs behave way.general, say conflict allied action nodes a0 repairedaction a00 pre(a00 ) (pre(a) add(a)) \ del(a) (thus a00 executeda), add(a00 ) add(a0 ) (thus a00 achieves a0 achieved). Similarrepairable cases identified two kinds conflicts. conflictsFGT repaired, non-redundant relaxed plan relaxed planlength executable reality, h+ equals goal distance.case Simple-Tsp domain.made preliminary implementation FGT analysis techniques.implementation correctly detects Simple-Tsp instances (as well graph-searchinstances), h+ equals goal distance. Simple-Tsp, less 18 locations analysistakes split seconds; 18 locations, runtime taken explodes fairlyquickly.6.3 Advanced Analysisresults encouraging, techniques applicability h+ topologydetect clearly far severely restricted. turns extremely difficult findless restrictive implications FGT structure h+ topology, i.e., sufficient criteriaweaker topological properties. best could come criterion impliesnon-existence local minima h+ , holds true Movie domainextremely simple Logistics instances.idea behind criterion following. imply non-existence localminima h+ , suffices know that, every state s, starting actionoptimal solution h+ (Result(s, hai)) h+ (s). Say considering planningtask actions (at least) invertible. Let state starting actionoptimal solution s. optimal relaxed plan contains a,done argument used Lemma 3. Else, let P + optimal relaxed plancontain a. P + embedded sub-tree FGT.delete leaf nodes sub-tree facts P + assumes true stateexecution P + relaxed plan Result(s, hai) done, too. case leftopen delete leaf node sub-tree occupied P + . Observematter (or repairable) conflicts sub-tree.Then, P + executable reality, P + optimal plan s, starting actionP + falls first case done again. get following sufficientcriterion:724fiWhere Ignoring Delete Lists Workslocal minima h+ actions holds leastinvertible, non-redundant sub-trees FGT contain a, eitherdelete leaf sub-tree, sub-tree contain conflicts.test criterion, one needs consider (redundant) sub-tree FGTbranches left start nodes labeled a. sub-treecontains conflict, deletes fact occurring sub-tree, criterionapply. Otherwise, test succeeds actions, proved localminima h+ .Reconsider illustrative example Figure 10, said conflictFGT nodes mv C mv E. sub-treecontain one nodes conflict-free. mv C mv E violatecriterion. Neither mv B D, mv C D, mv B violate criterion, sincenone actions deletes fact occurring anywhere else precondition.However, mv B mv B sub-tree looked entire FGT includingconflict, actions delete fact occurs FGT. criterionapply illustrative example. Note mv B mv B never startoptimal plan really could left considerations; uncleardetect automatically, general way.remark side order here. action appear FGT, then,difference one may think first sight, imply appearoptimal plan. FGT termination rules, adequate relaxed planning,restrictive real planning. following example. facts g1 , g2 ,p. goal {g1 , g2 }, current state {g1 }. actions shown Figure 11.nameoppopg2opg1===(pre,add,del)({g1 },(,({p},{p},{g2 },{g1 },){g1 }))Figure 11: Actions example task FGT contain action (opp,namely) needed reality.optimal plan hopp, opg2 , opg1 i: order able re-achieve g1applying opg2 , must achieve p first. However, opp appear FGT.location FGT node N labeled opp could insertedson precondition node p opg1 , inserted son g1 . N prunedtermination rule 1, opp g1 precondition, g1 appears pathroot node N . Note that, indeed, opp never part relaxed planachieving p good re-achieving g1 deleted actions necessaryreach goals.implementation criterion given easily within split seconds provesnon-existence local minima Movie instances, regardless size instance.725fiHoffmanntechnique not, however, work domain tried, except Logisticsinstances single city, two locations it, single truck,single package transported. Note even simpler smallillustrative example used Section 3, two objects need transported.open question better results achieved, i.e., state spacesrecognized feature local minima h+ . feeling backwardchaining approach domain analysis promising. But, successful, analysistechnique probably invest much effort analyzing waygoals achieved, many steps, rather crudeFGT approximation. information available goals achieved,maybe would possible discover non-trivial cases actions respectedrelaxation.27 detecting actions relaxed-plan relevant delete effects,yet completely unclear us could accomplished.7. Discussionderived formal background understanding classes domains relaxed plan-based heuristic methods, wide-spread methods modern planninglandscape time writing, well suited for. formal approach takenidentify characteristics local search topology heuristic cost surfaceidealized heuristic function h+ , forward searching framework. 30 commonly usedbenchmark domains including competition examples, i.e., basically STRIPSADL benchmark domains used field time writing, provedrelevant topological properties are. results coincide well runtime behaviorFF. Indeed, empirical results suggest quality h+ often preserved FFsapproximation it.results interesting give rare example successful theoreticalanalysis connections typical-case problem structure, search performance.practical point view, results provide clear picture strengthsweaknesses h+ lie, form good basis embarking improving heuristicweak cases. Approaches kind already appeared literature (Fox &Long, 2001; Gerevini et al., 2003). particularly, Fast-Downwards heuristic function(Helmert, 2004) motivated observations regarding unrecognized dead ends h+Mystery domain, large benches transportation domains non-trivial roadmaps.Regarding relevance topological results forward search algorithmsenforced hill-climbing, note things like non-existence unrecognized deadends non-existence local minima certainly useful heuristic searchalgorithm, albeit form provable polynomiality result.28 generally,relevance topological results performance planners using search27. remark easy find even trivial syntactical restrictions actions are,general, respected relaxation. example, even every fact added single action,one construct cases non-respected actions. One case example Figure 11,opp respected relaxation.28. Except case heuristic function identifies precise goal distances, caseh+ 1 30 domains, namely, Simple-Tsp domain.726fiWhere Ignoring Delete Lists Worksparadigms, enhanced heuristics, like LPG Fast-Downward, matter needing investigation. One thing certainly clear that, easiest classestaxonomy, particularly domains state space local minima h+ , benches escaped single step, planner using approximationh+ likely work quite well. Indeed thats one observes practice. intuitionauthor topology h+ plays large role efficiency plannersgenerally, i.e., also domains. Proving disproving beyond scopepaper. case, investigation provides nice theoretical backgroundproved results idealized setting, results used starting pointinvestigations tailored individual systems FF.investigation considers solvable planning tasks only, well justifiedfocus set international planning competitions. Turning focus unsolvable tasks,one realizes much techniques results become useless. search spacesolution, difference heuristic function make lies statesinfinite heuristic value, i.e., states recognized dead ends. meansinteresting question remaining kinds dead end statesrelaxed plan. results herein tell us this? domainsidentified unrecognized dead ends, results tell us relaxed plans generousapproximation.29 domains, things look hopeful. Still, resultsrelative solvable instances. Whether h+ detect many dead end statesunsolvable tasks depend reasons states. deadends unsolvable tasks may caused reasons solvable tasks,since assumptions making tasks solvable given. Note manybenchmarks (for example, Blocksworld Logistics) unsolvable instancesstandard definition. extent, makes existence non-existenceunrecognized dead ends choice domain designer extending domain definition.Exploring issues detail topic future work.Talking future work, biggest drawback research current form is,obviously, needs re-done every single new planning domain. woulddesirable, turns hard, come generic ideally, automaticmethods determine topological properties domain. outlinedattempt made develop automatic methods, based analyzing properties factgeneration trees. presented first promising results, regarding applicabilitydomains complexity one would like able handle, methods yet farweak. left future research answer question approachestopic work better practice. said, intuition betterapproaches, based intelligent backchaining-style reasoning goalsachieved domain. But, time writing, pure speculation.Beside easening burden proofs hand, benefits automatic domain analysis techniques would twofold. First, ambitious long-term vision domainindependent planning arsenal complementary heuristics, combinehybrid system automatically configured best suit given arbitraryplanning task. contribution made towards vision results hand29. Unsurprisingly, seeing deciding plan existence NP-hard in, example, Mystery, Mprime, MiconicADL, Freecell (Helmert, 2003).727fiHoffmannclear picture strengths h+ lie; able automatically configure hybrid system, one would need multiple heuristics different strengths weaknesses(i.e., heuristics high quality different classes domains), well abilitydetermine automatically heuristic likely work best. (At least approach could cost-effective, beside much insightful, tryingpossible combinations techniques.)Another benefit enhanced domain analysis techniques might lie abilitygenerate high-quality admissible heuristic function sequential planning. many domains, optimal relaxed plans mostly consist actions easy humansee (or one set similar actions) must contained optimalrelaxed plan (for example, loading unloading actions cant avoidedtransportation task). number actions state could provide good lowerbound value h+ . Note phenomenon actions must containedevery relaxed plan stronger version notion actions respectedrelaxation. promising approach seems try detect former sufficientapproximation latter.Since observed arbitrarily deep local minima h+ Blocksworldarm, none Blocksworld-no-arm, one might try come encoding methodstrying model domain way making best suited h+ . Since Blocksworld-no-armbasically version Blocksworld-arm possible pairs consecutive actions(pickup-stack, unstack-stack, unstack-putdown) replaced macro-actions, good(but somewhat obvious) heuristic modeling probably choose domain granularityhigh level abstraction possible. insightful heuristics may obtainedconsidering h+ topology planning benchmarks enriched automaticallydetected macro actions (Botea, Muller, & Schaeffer, 2004, 2005).Apart above, important future direction adaption formalframework, theoretical analysis methods, temporal numeric settingsdealt modern planning benchmarks modern planning systems. neededadaptations straightforward numeric framework used Metric-FF (Hoffmann,2003a). temporal planning, objective function estimated heuristicnumber actions needed complete partial plan, adaptation frameworkprobably straightforward well. If, however, makespan estimated heuristic,said article apply. most, settinganalysis techniques could relevant search uses estimation remaining actionsteps secondary heuristic.Acknowledgmentswould like thank Drew McDermott, Fahiem Bacchus, Maria Fox, Derek Longresponses various questions concerning definitions of/intentions behindcompetition domains. also thank anonymous reviewers, whose comments helpedimprove paper.728fiWhere Ignoring Delete Lists WorksAppendix A. Proof Sketcheslist proof sketches sections concerning dead ends, local minima, benches,order.A.1 Dead EndsTheorem 1 state space solvable instance1. Blocksworld-arm, Blocksworld-no-arm, Briefcaseworld, Depots, Driverlog, Ferry,Fridge, Gripper, Hanoi, Logistics undirected,2. Grid, Miconic-SIMPLE, Miconic-STRIPS, Movie, Pipesworld, PSR, Satellite,Simple-Tsp, Tireworld, Zenotravel harmless,3. Dining-Philosophers, Optical-Telegraph, Rovers, Schedule recognized evaluation h+ .proofs simple applications Lemma 1 2. said, descriptionsdomains looked Appendix B.Proof Sketch: [Theorem 1]actions Blocksworld-arm, Blocksworld-no-arm, Driverlog, Ferry, Gripper, Hanoi,Logistics instances invertible, apply Lemma 1 finished.inverse actions obvious ones cases, like stacking/unstacking block onto/fromblock, loading/unloading object onto/from vehicle, moving ll0 /moving l0 l (in case Driverlog, latter always doneunderlying road map bi-directional, c.f. Appendix B.8). Briefcaseworld, Depots,Fridge domains, actions strictly obey definition invertible(neither least invertible), still invert obvious way,i.e., every state applicable action action Result(s, ha, ai) = s.Movie, actions getting snacks irrelevant delete effects static add effects,rewinding movie resetting counter least invertible. Simple-Tsp actionmoving l l0 least invertible moving back. Tireworld, working stepsinverse one, except inflating wheel. irrelevant delete effectsstatic add effects. Miconic-STRIPS, moving lift invertible, boarding passengerleast invertible, departing passenger irrelevant delete effects static addeffects. four domains, Lemma 2 thus applied. Miconic-SIMPLEGrid domains, actions strictly adhere relevant definitions, similararguments like Lemma 2 prove non-existence dead ends. Miconic-SIMPLE, movinglift invertible. Letting passengers lift inverted,actions need applied (similar static add effects),interfere anything else (similar irrelevant deletes). Grid, actionsinverse action, except opening lock. latter action excludes actions openinglock (similar irrelevant deletes), lock needs opened once,locks closed (static add effects). Zenotravel Satellite, factsre-achieved sometimes one apply several actions so. Zenotravel,729fiHoffmannflying airplane l l0 , get back l0 one might refuel airplanetop flying back. Satellite, switching instrument on, one might recalibrate it, always done involve several actions (turning satelliteright direction applying actual calibration action). Pipesworld,push action inverted respective pop action, vice versa. state spaceundirected since pushs/pops non-unitary pipeline segments split two parts.PSR, dead end states since one always reach goal state waiting,necessary, opening breakers, bringing (non-breaker) devices goalposition, closing needed breakers.Dining-Philosophers, dead ends arise process (a philosopher) initiated impossible reading writing command (from/to empty/a full queue)queue contents updated, actions applicable. (The derivedpredicate rules determine process blocked apply case, sincerequire read/write command initiated yet.) Obviously, applicableactions relaxed plan either. states, goal reachedtraversing individual process state transitions philosophers one fork, trytake other.Optical-Telegraph, dead ends arise two kinds situations. First, processinitiated impossible reading writing command, similarly Dining-Philosophers,applicable actions thus relaxed plan. second possibilitytwo processes pair may take different decisions go next communication sequence: one may decide stop data exchange, may decidesend receive data. situation, least one processes statetwo transitions available, already activated one transitions,might already initiated respective write/read command. write/read commandimpossible (since process took different decision), actionsapplicable process. derived predicate blocking rules applyprocess, never apply process states one available transition.neither real relaxed plan exist state. reachable states,goal reached traversing individual process state transitions pairscommunicating processes occupy one control channel, try write other.Rovers, plan state if, soil/rock samples imagesneed taken, rover job, communicategathered data lander. chance run dead end take soil/rocksample rover reach lander (the soil/rock sample available once).then, relaxed plan state either.Schedule, state gd(s) < solved applying, objectturn, certain sequence working steps. sequence applied objectfollows preconditions needed action fulfilled, mustcase cold (a do-roll action applied previously,making hot). operator make cold again, i.e., operator adds respectivefact. Thus relaxed plan either.2Note worst cases Theorem 1 occur, i.e., domains whose instancesharmless, directed state transitions, domains whose instances730fiWhere Ignoring Delete Lists Worksrecognized, dead ends. remark dead ends Dining-PhilosophersOptical-Telegraph due seem bugs encoding queues(whose contents arent always updated correctly) blocked situations (whose rulesdetection seem incomplete). Modifying operators straightforward wayfix (apparent) bugs, one gets dead-end free (harmless) state spaces.domains mentioned Theorem 1 Airport, Assembly, Freecell, MiconicADL, Mprime, Mystery. domains, one construct arbitrarily deepunrecognized dead ends. Airport, unrecognized dead ends arise two planes movetowards line segments, possibility changing direction.deadlock situations arent recognized relaxed planning since, relaxation,free space left two planes remains free, used navigate planesacross other. dead end becomes arbitrarily deep when, independentlydeadlock situation, planes still moved. remark that, realityIPC-4 example instances deadlock situations like rarely occur. Airplanesmovable along standard paths serve avoid deadlocks main connectingroutes airport. places airport deadlocks occur,reality IPC-4 example instances, near parking areas, spacedense, airplanes need move directions airport segment.deadlocks occur all, i.e., planes move target positions onewithout hindering other, h+ delivers exact goal distance.presumably reason heuristic planners performed well IPC-4 Airporttest suites. performance would probably become worse one use (unrealistic)instances excessively many potential deadlock situations.Assembly, unrecognized dead ends arise several objects stuck duecomplex ordering constraints, imply solution plan would need gocyclic assembly pattern. details rather complicated, interested readerreferred TR (Hoffmann, 2003c). proved that, unless ordering constraintsAssembly instance potential yield cyclic situation, deadends all. one IPC-1 competition instances, ordering constraintspotential. helps explain FF efficient test suite(it solves even largest task within half second search time, finding plan 112steps).Freecell, unrecognized dead ends arise, example, one cautiousenough moving cards free cells. relaxed plan still achieve goalsingle free cell, using cell intermediate store cards. reality,however, moving card free cell occupies space (by deleting availabilityfree cell), thus exclude possibilities reaching goal. Thus moving cardfree cell lead unrecognized dead end state. unrecognized dead endarbitrarily deep cards still moved around independently deadlocksituation.Miconic-ADL, unrecognized dead ends arise problem constraint violated,violation goes unrecognized relaxed plan. example two passengersp1 p2 lift, p1 transported downwards, p2 accessp1 destination floor, p2 destination floor p1 s. state dead endone let p1 get first p2 access respective floor731fiHoffmannneither one let p2 get first afterwards, lift would need drive upwards,cant p1 board. relaxation, one stop destination floorssimultaneously at-facts deleted. unrecognized dead end becomesarbitrarily deep several passengers moved around reaching p1destination floor.Mystery, unrecognized dead ends arise fuel scarce, vehicle makes suboptimal moves. relaxed plan achieve goal long relevant locationsstill accessible least once. may suffice reality. dead end becomes arbitrarily deep additional objects transported independently problematicsituation. Mprime behaves similarly. difference Mystery example that,avoid possibility transferring fuel items problematic locations, one must makesure enough fuel enable transportation additional objects.A.2 Local MinimaTheorem 2 h+ , maximal local minimum exit distance state spacesolvable instance1. Blocksworld-no-arm, Briefcaseworld, Ferry, Fridge, Grid, Gripper, Hanoi, Logistics,Miconic-SIMPLE, Miconic-STRIPS, Movie, Simple-Tsp, Tireworld 0,2. Zenotravel 2, Satellite 4, Schedule 5, DiningPhilosophers 31.present proof sketch Theorem 2 terms three groups domainssimilar proofs. Note domains maximal local minimum exit distance 0domains local minima all. first focus domainsLemma 3, slight extensions it, applied.Proof Sketch: [Theorem 2, Ferry, Fridge, Gripper, Logistics, Miconic-SIMPLE, MiconicSTRIPS, Movie, Simple-Tsp, Tireworld]Theorem 1, none listed domains contains dead ends. said proofsketch theorem, actions Ferry, Gripper, Logistics, Miconic-STRIPS, Movie,Simple-Tsp, Tireworld domains either least invertible, irrelevant deleteeffects. Lemma 3 suffices show actions respected relaxation.cases, except driving/flying actions Logistics, easy seeoptimal starting action something avoided relaxed plan. (Forexample, relaxed plan avoid load/unload objects onto/from vehicles,avoid missing working steps Tireworld.) optimal starting actionLogistics drives truck/flies airplane location l, object must eitherloaded unloaded l, relaxed plan choice apply actionmoves transportation vehicle (of kind) there. vehicles equally good, exceptclever choice, i.e., vehicle already carries objects unloadedl. then, move one vehicles like optimal relaxed plan will,vehicles equally good relaxation. (In Ferry, Gripper, Miconic-STRIPS,732fiWhere Ignoring Delete Lists Workssingle vehicle, makes moving actions domains easierreason about.)Fridge Miconic-SIMPLE domains, actions adhere strictlydefinitions invertibility irrelevant delete effects. proof Theorem 1shown similar semantics, i.e., either inverted, deletefacts longer needed applied. Furthermore, actionsdomains respected relaxation. Fridge, missing working steps must alsodone relaxed plan. Miconic-SIMPLE, lift moves trivially respected, liftstops respected since clever choices reality coincide clever choices relaxedplan.2next four domains, local minima either, proofssophisticated make use rather individual properties respective domains.cases proved path goal h+ increase.Proof Sketch: [Theorem 2, Blocksworld-no-arm, Briefcaseworld, Grid, Hanoi]Theorem 1, none domains contains dead ends. Blocksworld-no-arm,optimal starting action stacks block goal position, also startsoptimal relaxed plan (because better thing achieve goalimmediately); relaxed plan, replaced inverse counterpart formrelaxed plan successor state. action state s, oneoptimal plan starts putting block b must moved order access blockblock c onto table, yielding state s0 . relaxed plans0 constructed relaxed plan P + by, taking account various casedistinctions, replacing move actions regarding b P + numbermove actions. case distinctions kind action P + uses move baway c one action a0 must contained P + . a0 moves b tablereplace a0 P + action moves b back onto c, finished. Else,must distinguish cases b required c goal,block. cases, make successful use fact b movedposition position within single action, enabling us exchange actionsP + quite flexibly.Briefcaseworld, actions inverted. Actions put objects briefcasetrivially respected relaxation. state optimal plan startstake-out action, optimal relaxed plan also used successor state, sincetaking object delete important facts. state optimal planstarts move action l l0 , P + relaxed plan s, relaxed plansuccessor state constructed replacing moves l l00 , l00 6= l0 , P + ,moves l0 l00 .Grid, rather complex procedure applied identify flat path statebetter h+ value. state s, let P + optimal relaxed plan s, letfirst unlock action P + , putdown unlock action. Identifying flatpath state s0 applied suffices, unlocking deletes factsirrelevant lock open, deletes putting key irrelevantlocks must opened. selected action uses key k733fiHoffmannposition p. P + contains sequence actions moving p. Moving along path definedactions increase h+ since actions contained relaxed plan,inverted. k already held s, apply a. handempty s, key held, one use P + identify flat path stateone hold appropriate key k. hand empty, P + must containsequence actions moving location k picked up. keyheld, P + must contain sequences actions moving locations serieskeys picked put down, key series ends picking k.Hanoi, proved optimal relaxed solution length state equalnumber discs yet final goal position proceedingsmallest largest disc, respective goal achieved single action.optimal plan moves disc away final position, h+ increase optimalsolution paths.2finally consider four domains local minima, one alwaysescape within constant number steps. cases, prove upper bounddistance non-dead end state state s0 h+ (s0 ) < h+ (s). immediatelyimplies 1 upper bound maximal local minimum exit distance (it alsoimplies 1 upper bound maximal bench exit distance; resultsre-used Appendix A.3).Dining-Philosophers, h+ loosely connected goal distance, bound,holds even trivial heuristic function returning number yet un-blockedphilosophers, follows rather constant restrictive domain structure.three domains, proofs proceed follows. reachable state s, identify constantnumber steps suffices execute one action optimal relaxed plan s, and,without deleting relevant add effects, re-achieve relevant facts deleteda. Then, state s0 h+ (s0 ) < h+ (s) reached.Proof Sketch: [Theorem 2, Dining-Philosophers, Satellite, Schedule, Zenotravel]Theorem 1, dead ends Dining-Philosophers recognized. nondead end state s, shortest relaxed plan blocks processes (philosophers)yet blocked. individual process, 3 steps needed relaxation,block process always suffices activate state transition, initiate read/writecommand, queue update. update, queue empty full,read/write impossible sense blocking rules apply. (With this,process block relaxation, h+ value fairly loosely correlatedtrue goal distance.) Thus, reach state lower h+ value, obviously alwayssuffices block one process. prove upper bound determining constantbound number steps needed that. bound exists because, besidefact philosopher processes constant interfere respectivetwo neighbors table, philosophers fixed order try pickforks: always first try pick fork right, fork left.restricts possible combinations internal states neighbored philosophers.detail, philosopher blocked iff tries pick forktable. philosopher p, refer pL ps neighbor philosopher left side.734fiWhere Ignoring Delete Lists Worksdescription 5 different states philosopher process Appendix B.7. Letnon dead end state. Let p philosopher blocked (if p exists,goal state nothing prove). prove desired upper boundexhaustive case distinction states p pL. state {1, . . . , 5}p, consider state iL {1, . . . , 5} pL. combination iLpossible, nothing. Else, determine number k process state transitionsleads state either: p blocked pL still blocked blockeds; pL blocked blocked s. cases, alsomake distinctions internal state pLs left neighbor pLL. worst case, k = 6,occurs = 3, i.e., p holds adjacent forks. Then, pL eitherstate iL = 1 iL = 4 (which means, pL cant hold fork pL p sinceheld p). iL = 4, pL blocked s; pL put left fork, gettingstate 1 pL blocked since waits pick right fork, held p. iL = 1distinguish two cases state pLL. = 3 (p holdsadjacent forks), iL = 1 (pL waits pick fork p pL); pLblocked. Case A, state pLL 0, 2, 3, pLL holds fork pLLpL. go p 3 4, 4 1, 1 2, go pL 1 2.Then, p pL blocked since wait pick fork left. Case B,state pLL 1 4, fork pLL pL table, pLLblocked. go pLL 4 1 (if 4), 1 2. that, pLL holdsfork pLL pL; case apply sequence, getting usstate pLL possibly blocked, p pL definitely blocked.always need 6 process state transitions block one philosopher.process state transitions take 4 planning actions each, makes 24 planningsteps. planning steps needed due subtleties PDDL encoding.Subtlety A, process may already decided go state, yet arrivedi.e., respective transition activated read/write command initiated,communication channel/queue occupied transition yet complete.2 steps needed reach next internal state (update queue wraptransition). Subtlety B, blocked state process must activate outgoingtransition. worst case described above, p, pL, pLL may require 2steps induced subtlety A; p pL require step induced subtlety B.get (at most) 32 planning actions. effect last action, one processbecomes blocked, upper bound exit distance 31.Theorem 1, dead ends Satellite. Let reachable state.determine upper bound distance state s0 h+ (s0 ) < h+ (s),one look optimal relaxed plan P + s, distinguish four cases regardingexistence applicable actions different types P + . action type, constantnumber steps suffices re-achieve deleted facts application action.worst case, = 5, arises switch-on action applied. Switching instrumentdeletes instruments calibration. re-achieve this, one must turn satellitecalibrate it. another turn taking image, state lower h+ value reached.Theorem 1, dead ends Schedule recognized. Let non-deadend state. determine upper bound distance state s0h+ (s0 ) < h+ (s), one look optimal relaxed plan P + distinguish seven735fiHoffmanncases regarding kinds applicable actions P + contains. worst case, = 6,arises do-roll action available (and applicable) P + . One needsapply time-step, do-lathe action achieve desired effects do-roll, another timestep, do-polish do-grind action re-achieve previous surface condition, anothertime step, do-immersion-paint action re-achieve previous color.Theorem 1, dead ends Zenotravel. reachable state s, determinedesired constant d, distinguishing two cases job. relaxed plan P +contains applicable boarding, departing, refueling action, applying actionleads state lower h+ value. Else, P + starts flying action, betterstate reached executing flight, refueling once, boarding departingperson. get = 3.2Note proved bound Dining-Philosophers holds even take heuristicfunction trivial one returns number yet un-blocked philosophers.extremely cumbersome figure exactly worst-case exit distance DiningPhilosophers h+ so, one consider combinations possible statesneighbored processes, possible developments lot action steps, ratherun-intuitive PDDL encoding made automated translation machinery. highestexit distance could actually construct Dining-Philosophers 15. conjecture(tight) upper bound.Satellite, Schedule, Zenotravel, proved upper bounds tight.Dining-Philosophers, Satellite, Schedule, Zenotravel, bounds valid nondead end state s. So, beside bound local minimum exit distance, results alsoprovide bound bench exit distance; re-use Appendix A.3.Blocksworld-arm, Depots, Driverlog, Optical-Telegraph, Pipesworld, PSR, Rovers,one construct local minima arbitrarily large exit distances. Blocksworld-arm,example situation n blocks b1 , . . . , bn initially form stack bibi+1 bn table, goal build stack topanother block bn+1 , i.e., goal stack b1 , . . . , bn , bn+1 . Reaching, initial state,state better h+ value, involves disassembling entire stack b1 , . . . , bn .disassembling process, h+ increases. example used Depots.Driverlog, local minima arise due different road maps trucks drivers,example, takes one step drive location l another location l0 , nsteps walk. relaxed plan, driver drive truck goalstaying is, reality, driver walk way back.Optical-Telegraph, treated easily reconsidering DiningPhilosophers domain, proved constant upper bound above. reasonOptical-Telegraph basically permissive version Dining-Philosophers,philosophers choose fork pick first, and, hold forks,fork want put first. Consider configuration depicted Figure 12.configuration reachable given automata underlying Dining-Philosophers,reachable given automata underlying Optical-Telegraph.Figure 12, Nietzsche holds adjacent forks, Kant holds none triesget access fork right. Nietzsche Kant, arbitrarilymany philosophers hold one fork each, trying access other.736fiWhere Ignoring Delete Lists WorksKantNietzscheFigure 12: unreachable situation Dining-Philosophers, unbounded localminimum h+ would arise. Arrows indicate pickup-requests.non-blocked philosopher Nietzsche, put forks again.PDDL encoding this, world state Nietzsche activated transitionputting right (or left) fork, h+ value 2: relaxation, sufficesinitiate write command, update queue contents. write commandinitiated, however, h+ goes 3 transition become non-activated;relaxed plan update queue contents, wrap transition, activate(same) transition again. Reaching state h+ value 1 involves propagatingforks entire sequence philosophers Nietzsche Kant, eitherright hand side, left hand side. example, say Nietzsche puts forkspicks right fork. philosopher left Nietzsche pickrequested fork (or Nietzsche pick gets us back started).resulting state, situation before, except philosopherNietzsche-role sits one position left. iterating procedurearound left side table, Kant pick requested fork, request getother, giving us goal state philosophers blocked. state h+ value 1one Kant yet activated transition request fork.configuration Figure 12 reachable Dining-Philosophers domainused IPC-4, because, there, philosopher pick fork left handside first done Figure 12 philosophers Nietzsche KantNietzsches left hand side. said, Optical-Telegraph philosophersfreedom choice, situation reachable. detail, describedAppendix B.22, Optical-Telegraph n pairs communicating processes.pairs arranged cycle, pair control channel. Internally,two processes within pair go fairly long, heavily interactive, sequenceoperations, implementing possibility exchange data two stations.737fiHoffmannoperations begin, processes occupy (write into) onecontrol channel. is, one processes occupies channel, waits signalprocess, indicating second control channel occupied well.data exchange terminated, control channels get released (read)arbitrary order. overall system blocked iff process pairs stateoccupied one control channel, waiting occupy other. Thus,process pairs correspond exactly philosophers choose fork pick (putdown) first, Figure 12 provides example arbitrarily high exit distancelocal minimum state. Precisely, local minimum state one Nietzscheprocess pair occupied channels, process blocked secondchannel activated transition sending occupied-the-other-one signal:state, h+ value 2 (all processes except active one blocked).Pipesworld, consider situation several areas form circle unitaryconnections. local minimum state s, single goal batch g go area a;g currently segment adjacent a, contains batch b, areas empty.shortest plan push b segment (not s) adjacent a, propagatebatches around circle g pushed a. shortest relaxed planis, however, push b push g side i.e., g usedpush goal area. Reaching nearest state h+ value 1 requires n 1steps n areas circle, path h+ value increases. Noteexample uses neither tankage restrictions, interface restrictions, non-unitarypipeline segments.PSR, deep local minimum given n breakers feed individual goal line,way breaker feed breakers goal line without breakeralso closed, breakers connected faulty line. onebreakers closed. h+ value state 1 (close single open breaker) sinceunsatisfied goal condition (beside supplying line fed open breaker)one postulating breaker affected; condition negated derived predicate,thus ignored relaxation. applicable action state wait.that, breakers open, shortest relaxed plan close all, yieldingh+ value n. Obviously, nearest state h+ value 0 least n steps away.30Rovers, local minima arise taking image deletes calibrationcamera. example this. n waypoints w1 , . . . , wn connected line(i.e., wi1 connected wi ), lander w1 , one rover camera c must usedtake two images w1 , c calibrated (only) wn . rover w1 ,c calibrated, relaxed plan take two images communicate twodata pieces. taking one image, one navigate way wn , calibratec, get back. Note example makes use road map arbitrarily largediameter, diameter Rovers instance longest way rover must travelorder get one waypoint another. general, distance state betterh+ value bounded 3d + 2 diameter instance (see detailsTR). road map diameter IPC-3 Rovers instances varies around 1 6.30. remark counter-example remains valid IPC-4 SIMPLE-ADL STRIPS formulationsPSR, use different encoding derived predicates, using negation formulategoal breaker affected.738fiWhere Ignoring Delete Lists WorksAirport, Assembly, Freecell, Miconic-ADL, Mprime, Mystery domains,seen Appendix A.1 contain unrecognized dead ends, so, Proposition 1,local minimum exit distance domains unbounded. Assembly,TR describes detail, initial state instance path goalh+ decreases monotonically, unless complex interactions orderingconstraints present instance. None IPC-1 instances features complexinteractions. Assuming FFs search algorithm sticks monotonically decreasingpaths, gives another indication system efficient examplesuite.A.3 BenchesTheorem 3 h+ , maximal bench exit distance state space solvableinstance Simple-Tsp 0, Ferry 1, Gripper 1, Logistics1, Miconic-SIMPLE 1, Miconic-STRIPS 1, Movie 1,Zenotravel 2, Satellite 4, Schedule 5, Tireworld6, Dining-Philosophers 31.before, subdivide proof sketch Theorem 3 groups domainssimilar proofs. first consider transportation-type domains. them, Lemma 4,similar proof arguments, applied.Proof Sketch: [Theorem 3, Ferry, Gripper, Logistics, Miconic-SIMPLE, Miconic-STRIPS]proofs Theorems 1 2 shown that, domains, actionsrespected relaxation, and, domains except Miconic-SIMPLE,actions either invertible, relevant delete effects. determine upper boundexit distance benches, thus apply Lemma 4. requires us showthat, state s, optimal plan + 1th action relaxedplan relevant delete effects. Miconic-SIMPLE, seen actions,adhering syntactic conditions invertibility (no) relevant delete effects,similar semantics; proof technique applied there.(transportation-type) domains consideration, argument is, roughly,load-type unload-type actions relaxed-plan relevant delete effects,move-type actions need applied row locationsimmediately accessible other. implies upper bound 1 maximalexit distance. Concretely, say reachable state Logistics instance, startsoptimal plan s, P + optimal relaxed plan starts a, applyingyields state s0 . loading (unloading) action, delete at(in-) fact transported object; object loaded respective location(unloaded respective vehicle) optimal relaxed plan P + ,relaxed-plan relevant delete effects, exit. Otherwise, drives flies vehiclev l l0 , s0 exit optimal plan s0 starts loading (unloading)package (from) v. Miconic-STRIPS Miconic-SIMPLE, argumentsapply. Ferry, arguments also remain valid except that, optimal start actionstate boards car, action also deletes available free space739fiHoffmannferry. then, relaxed plan P + also contains actions move ferrylocation l, debark car l (otherwise would point boardingcar). Placing actions front P + , removing a, yields relaxed planstate results applying s. similar argument applied proveclaim Gripper, gripper hands hold one ball time. (Noteargument Ferry Gripper uses somewhat weaker notion relaxed-plan relevantdelete effects, effects, undone actions containedrelaxed plan.)2Next come non-transportation domains also Lemma 4 applied.Proof Sketch: [Theorem 3, Movie, Simple-Tsp, Tireworld]proofs Theorems 1 2 shown domains actionsrespected relaxation, either least invertible, irrelevant delete effects.apply Lemma 4 cases.Movie, actions no, therefore relaxed-plan relevant, delete effects,single exception rewinding movie (which deletes counter zero).Obviously, optimal plan rewinds movie twice row. Thus, = 1 desiredupper bound.Simple-Tsp, = 0 suffices. Say reachable state one locationl. optimal plan starts action visiting yet unvisited location l0 . optimalrelaxed plan start a, visit remaining unvisited location l00move l0 l00 . latter actions require preconditions deleted a,every action relaxed-plan relevant delete effects.Tireworld, lowest constant upper bound = 6. non-final working steps(like jacking hub flat wheel on) need undone later on, i.e.,relaxed-plan relevant delete effects. final working steps (like jacking hub)need undone, i.e., relaxed-plan relevant delete effects. longestsequence non-final working steps optimal plan row following6-step one: open boot (it must closed again), fetch wrench jack (theymust put away again), loose nuts hub thats got flat wheel (the nuts musttightened again), jack respective hub (it must jacked again), undonuts (they must done again). resulting state, one remove flatwheel, needs undone.2remaining domains Theorem 3 claims constant upper boundmaximal bench exit distance, seen Appendix A.2 upper boundsdistance reachable state state s0 h+ (s0 ) < h+ (s). upperbounds trivially also imply upper bounds maximal bench exit distance.Proof Sketch: [Theorem 3, Dining-Philosophers, Satellite, Schedule, Zenotravel]Follows directly proof Theorem 2.2domains, except last four, one easily construct examplesbench exit distance equal proved upper bound. Satellite, Schedule,740fiWhere Ignoring Delete Lists WorksZenotravel, open question whether tighter bounds bench exitdistance local minimum exit distance; seem particularly relevant,though. (For Dining-Philosophers, said may even boundlocal minimum exit distance tight.)Blocksworld-no-arm, Briefcaseworld, Fridge, Grid, Hanoi domains, Theorem 2 proves local minima. important know whetherarbitrarily difficult escape benches. answer yes cases. Blocksworldno-arm, example one already used Blocksworld-arm Depots(to show bounds local minimum exit distances). n blocksb1 , . . . , bn initially form stack bi bi+1 bn table, goalbuild stack top another block bn+1 , i.e., goal stack b1 , . . . , bn , bn+1 .shortest relaxed plan initial state n steps long (remove stack topbn , move bn onto bn+1 ). nearest state h+ value n 1 one bnalready stacked onto bn+1 . state n steps away initial state.Briefcaseworld, bench exit distance becomes large many objects musttaken briefcase relaxation, point taking objects out, sincemoving briefcase delete at-facts. Consider state n objectso1 , . . . , inside briefcase location l, goal o1 , . . . , lbriefcase another location l0 . h+ (s) = 1: moving briefcase l0 sufficesrelaxation. nearest goal state, h+ = 0, n + 1 steps away: one must takeobjects moving l0 .Fridge, single fridge compressor held n screws, exit distanceinitial state n + 1. reach better state, one must: stop fridge (which mustturned back relaxed plan); unfasten n screws (which must fastenedrelaxed plan); remove broken compressor (which needs undonedeletes fact broken compressor attached fridge).31Grid, consider instances robot located n1 grid (a line) withoutlocked locations, robot starts leftmost location, shall transport keyrightmost location left end. initial value h+ n + 2 (walkkey, pick up, put at-facts deleted), value getbetter robot actually picked key.Hanoi, seen h+ always equal number discs yetgoal position. Thus maximal bench exit distance grows exponentiallynumber discs. initial state instance n discs, takes 2n1 stepsmove first (i.e., largest) disc goal position.9 domains local minimum exit distance arbitrarily large,relevant whether bench exit distance bounded not. Escaping benchmight planner better ending huge local minimum. remark that,example, Driverlog, Rovers, Mprime, Mystery, one easily construct exampleslarge bench exit distances, defining road maps large diameters i.e., usingbasically example used Grid domain.31. fact, one easily prove n + 1 also upper bound bench exit distance, Fridgeinstances compressors held n screws (details TR).741fiHoffmannAppendix B. Domain Descriptionsfollowing list brief descriptions 30 investigated domains. explainoverall idea behind domain, available operators, initial statesgoals are. cases set instances obvious; restrictions, any, explained.remark that, points, domain semantics seem bit odd (for example,Zenotravel, difference flying zooming plane zooming consumesfuel). odd points are, presumably, domain bugs overlookedrespective domain designers. corrected bugs as, all, investigationmeant determine properties benchmarks used community.domains listed alphabetical order.B.1 AirportAirport domain, planner safely navigate ingoing outgoing traffic,given point time, across airport. main problem constraint planesmust endanger other, come close others runningengines. constraint modeled letting plane block segmentsengines currently endanger. Planes enter blocked areas. five operators.plane moved one airport segment another, plane facing rightdirection, planes get endangered action. Similarly, plane pushedback cause trouble. One start engines plane, let planetake off, let plane settle parking position. initial state specifies currentpositions orientations planes, goal specifies planes outbound (havetake off), inbound parking positions.B.2 AssemblyAssembly domain, complex object must constructed assembling partstogether, obeying certain ordering constraints. parts might needassembled way beforehand. parts transient, meansmust integrated temporarily. collection machines, resources,might needed working steps. four operators. available resourcecommitted object, deleting resources availability. Releasing resourceobject inverse action. available object x assembled object y,x either part transient part y, resources requires committedy, objects assemble order x already incorporatedy. effect, x incorporated longer available, becomes availableparts except x already incorporated, transient part incorporated.incorporated object x removed y, resources requires committedy, and, given x transient part (a part y), objects remove order(an assemble order) x incorporated (not incorporated). effect, x availablelonger incorporated, becomes available parts incorporated,transient parts except x incorporated. instances, part-of relationforms tree goal make root object tree available. Also,742fiWhere Ignoring Delete Lists Worksassemble remove order constraints consistent (cycle-free). restrictions holdtrue AIPS-1998 competition examples.B.3 BriefcaseworldBriefcaseworld, number portables must transported, transportationdone via conditional effects move actions. three operators. Puttingportable location done portable briefcase respectivelocation, portable yet inside. Taking portable done inside.move applied two locations, achieves, beside is-at-factbriefcase, respective at-facts portables inside (i.e., portables insidemoved along conditional effects). goal briefcase, subsetportables, goal locations.B.4 Blocksworld-no-armBlocksworld-no-arm variant widely known Blocksworld domain. threeoperators. One move block table onto another block. One move blockanother block table. One move block another block onto thirdblock. initial state instance specifies initial positions blocks, goalstate specifies (consistent, i.e., cycle-free) set facts.B.5 Blocksworld-arminstances Blocksworld-arm Blocksworld-no-arm. difference blocks moved via single robot arm hold one block time.four operators. One pickup block table. One put block,arm holding, onto table. One unstack blockblock. Finally, one stack block, arm holding, onto block.B.6 DepotsDepots domain kind mixture Logistics Blocksworld-arm.set locations, set trucks, set pallets, set hoists, set crates.trucks transport crates locations, hoists used stack crates ontocrates, onto pallets. six operators, move truck (different)locations, load crate held hoist onto truck location, unloadcrate hoist truck location, lift crate hoist surface (apallet crate) location, drop crate held hoist onto surfacelocation. hoist hold one crate time. crates initially arrangedarbitrary stacks, bottom crate stack standing pallet. goalarrange crates arbitrary stacks (possibly) pallets,involve transporting crates locations (as pallets moved).743fiHoffmannB.7 Dining-PhilosophersDining-Philosophers encoding well-known Dining-Philosophers problem,task planner find deadlock situation arises every philosophertaken single fork. PDDL domain created automatic translationautomata-based Promela language. automata also referred processes.Promela, philosopher finite automaton/process works follows.start state, state 0, transition puts right fork onto table (this initializationstep), getting state 1. loop four states. state 1 state2, philosopher takes right fork. 2 3, takes left fork, 3 4puts right fork, state 4 puts left fork gets back state1. process communicates neighbors communicationchannel, queue, either contains fork, empty (if one adjacent philosopherscurrently holding fork).PDDL encoding, process state transition broken four actions.first action activates chosen transition. second action initiates write readcommand needed queue, deleting activation transition setting flagsqueue update. third action updates, possible, queue contents. updatepossible write command shall done full queue (a queue already containsfork), read command shall done empty queue. fourth action wrapsprocess state transition up, re-setting flags.Derived predicates used model conditions process blocked.rules require outgoing transitions current state process blocked.transition blocked activated, would need perform impossible queuewrite/read operation sense impossible write/read operation yetinitiated.32 applying planning action initiating impossible write/readcommand, blocking rules dont apply anymore resulting state dead endplanning tasks state space (but blocking situation process network,according derived predicate rules modeling blocking).remark that, IPC-4, also version Dining-Philosophers modeledprocess blocking via additional planning operators, derived predicates. choseconsider other, above, domain version since constitutes natural conciseformulation, since planners IPC-4 scaled version withoutderived predicates.B.8 DriverlogDriverlog variation Logistics, drivers needed trucks,drivers trucks move along arbitrary (bi-directional) road maps. road mapsdrivers trucks different. operators load/unload object onto/fromtruck location, board/disembark driver onto/from truck location, walk32. one outgoing transition activated time, process never become blockedstate one outgoing state transition. appears bug translationPromela PDDL intuitive requirement would activated transition needsblocked, outgoing transition need activated order blocked. Notethat, Dining-Philosophers, every automaton state one outgoing transition.744fiWhere Ignoring Delete Lists Worksdriver location another one, drive truck driver locationanother one. preconditions effects loading/unloading objects obviousones. driver board truck truck empty; effect, truck longerempty (as well driven driver). Disembarking driver inverse action.order walk driver l l0 , must path l l0 . order drivetruck l l0 , link l l0 (and must drivertruck). Paths links form arbitrary (in particular, potentially different) graphslocations, restriction undirected, i.e., truck drivermove l l0 also move back. restriction imposed Driverloginstances generated IPC-3 generator.B.9 FerryFerry, single ferry used transport cars locations, one time.three operators. One sail ferry two locations. One board car ontoferry location, deletes empty-ferry fact (plus adding carferry deleting car location). One debark car ferrylocation, achieves empty-ferry (plus adding car locationdeleting car ferry). goal subset cars goallocations.B.10 FreecellFreecell domain STRIPS formulation widely known solitaire card gamecomes Microsoft Windows. number cards different suits initiallyarranged random stacks number columns. cards must put home.suit cards, separate home column, cards suit muststacked increasing order card value. number free cells. cardsmoved around according certain rules. card clear card topit. clear card put free cell (if already there), free cell holdsone card time. clear card moved onto empty column. clear cardc put home last card put home suit one preceding c. cc0 clear cards differently colored suits, one stack c top c0 c0free cell, cs card value one less card value c0 (so stacksbuilt columns, decreasing order card value, alternating colors). goalreached topmost cards suits put home.B.11 FridgeFridge, one must replace broken compressor fridge. this, one must removecompressor; involves unfastening screws hold compressor,turn involves first switching fridge off. goal new compressor attachedfridge, screws fastened, fridge switched back on. origin domainSTRIPS formulation. consider adaptation allows arbitrary numberfridges screws, compressor fastened (arbitrary, least one)number screws. adaptation involves ADL precondition: compressor745fiHoffmannremoved screws unfastened. six operators. One stop/start fridge.One unfasten/fasten screw from/to compressor attached fridge; so,fridge needs turned off, compressor needs attached, screw must fitcompressor. Finally, one remove/attach compressor from/to fridge. Removingcompressor requires fridge turned off, none screws fitcompressor fastened. effect, compressor longer attached fridge,fridge compressor free. Attaching compressor requires fridgeturned off, compressor fits fridge. effect, compressor attached,compressor fridge longer free.B.12 GridGrid, robot must move along positions arranged grid-like reachabilityrelation. positions locked, keys different shapes open them.goal keys goal positions. five operators. Onemove position p position p0 , requires (apart obvious preconditions)p p0 connected, p0 open (not locked). One pick keyposition, requires arm empty (one hold one key time),effects one holds key, arm longer empty, keylonger position. Putting key position inverse action. Oneabbreviate two previous actions pickup-and-lose keys k k0position; this, one must hold k, directly exchanged k0 , i.e., effectsone holds k k0 position. Finally, one unlock position p0 oneposition p connected p0 , holds key shape lockedposition p0 ; add effect p0 open, delete effect position longerlocked. instances specify initial locations keys, locked positions,robot, well shapes keys locked positions. goal specifiespositions subset keys. robot always starts open position.make significant difference: robot allowed start locked position,local minima h+ .33 Otherwise none, c.f. Theorem 2. Intuitively, makessense let robot located open positions only; restriction also holds truepublished benchmark examples.B.13 GripperGripper, task transport number balls one location another.three operators. One move locations. One pick ball locationhand; apart obvious preconditions requires hand empty;effects obvious ones (the ball hand longer room) plushand longer empty. One drop ball location hand, invertseffects picking action. always exactly two locations, two gripperhands. Instances thus differ terms number balls. severe restrictionshold true AIPS-1998 instances. remark adding locations and/or hands33. Moving away locked initial position lead need applying several steps re-openposition. relaxed plan initial state realize this, since ignores deleteinitial at-fact.746fiWhere Ignoring Delete Lists Worksaffect topological properties h+ , fact proof arguments givenTheorems 1, 2, 3 remain valid case.B.14 HanoiHanoi domain STRIPS encoding classical Towers Hanoi problem.n discs d1 , . . . , dn , three pegs p1 , p2 , p3 . single operator movesobject x object onto object z (the operator parameters groundeddiscs well pegs). preconditions move x y, x clear, zclear, x smaller z. effects x z clear, xlonger z longer clear. semantics Towers Hanoi encoded viasmaller relation. relation holds obvious way discs, discssmaller pegs (the pegs smaller anything moved).instances differ terms number n discs must transferred p1p3 .B.15 LogisticsLogistics classical transportation domain, objects must transported withincities using trucks, different cities using airplanes. six operators,drive truck two locations within city, fly airplane two airports,load (unload) object onto (from) truck location, load (unload) objectonto (from) airplane airport. operators obvious preconditionseffects (the complicated operator moving truck, whose preconditionrequires locations within city). always least one city,city non-zero number locations one airport. arbitrarynumber objects, airplanes (which located airports). goalsubset objects goal locations.B.16 Miconic-ADLMiconic-ADL ADL formulation complex elevator control problem occurringreal-world application planning (Koehler & Schuster, 2000). number passengerswaiting number floors transported lift, obeying variety constraints.always least one floor, arbitrary number passengers,given origin destination floor. three operators. lift movefloor f floor f f (transitively) f, vice versa moving downwards.lift also stop floor. floor f, conditional effectsstopping action passengers waiting f boarded, passengers wanting getf depart. goal serve passengers, i.e., bring destinationfloor. constraints must obeyed following.cases, passenger p access floor f; lift stop fp boarded.passengers VIPs; long served, lift stopfloors VIP getting off.747fiHoffmannpassengers must transported non-stop, i.e., boarded, liftmake intermediate stops stopping destination floor.passengers travel alone, others attend them; one formerkind boarded, must least one latter kind.groups B passengers allowed peoplegroups boarded simultaneously.passengers transported direction travel, i.e.,need go (down), then, boarded, lift movedownwards (upwards).constraints formulated means complex first order preconditionsoperators.B.17 Miconic-SIMPLEMiconic-SIMPLE domain Miconic-ADL described above, exceptconstraints all.B.18 Miconic-STRIPSMiconic-STRIPS domain almost Miconic-SIMPLE domain, see above.difference boarding departing passengers done conditionaleffects stopping operator, explicitly separate STRIPS operators. One boardpassenger floor. precondition (current) floor passengers origin,effect passenger boarded. One let passenger departfloor. preconditions (current) floor passengers destinationpassenger boarded, effects passenger served longerboarded.B.19 MovieMovie, task prepare watching movie. seven different operators.One rewind tape, adds tape rewound, deletes counterzero. One reset counter, effect counter zero. Oneget five different kinds snacks, (add) effect one respectivesnack. Instances differ terms number items sortsnacks. goal always one snack sort, tape rewound,counter zero.B.20 MprimeMprime transportation kind domain, objects must transportedlocations means vehicles, vehicles use non-replenishable fuel. instance,set L locations, set objects, set V vehicles. alsosets F fuel numbers space numbers. location initially certain fuel748fiWhere Ignoring Delete Lists Worksnumber number fuel items available location vehicle certainspace number number objects vehicle carry time. operatorsmove vehicles locations, load (unload) objects onto (from) vehicles,transfer fuel units locations. move location l location l0made l l0 connected (where connection relation arbitrary graph),least one fuel unit available l (l fuel number lower neighbor).effect move, respective vehicle located l0 , amount fuel ldecreased one unit, i.e., l assigned next lower fuel number. similar fashion,object loaded onto vehicle space that, effect availablespace decreases. Unloading object frees space again. transfer operatortransfer one fuel unit location l location l0 , l l0 connected, lleast two fuel units left. result applying operator, ls fuel number decreasesone, l0 fuel number increases one. Note way re-gain fuel items(one transfer around one obtain new ones). goal transportsubset objects goal locations.B.21 MysteryMystery exactly Mprime domain described above, exceptoperator transfer fuel items.B.22 Optical-TelegraphLike Dining-Philosophers domain described Appendix B.7, Optical-TelegraphPDDL compilation problem originally formulated automata-based Promelalanguage. mechanics PDDL compilation Dining-Philosophers,using derived predicates detect blocked situations. problem involves n pairs communicating processes, pair featuring process. pair gofairly long, heavily interactive, sequence operations, implementing possibility exchange data two stations. data exchanged, various initializingsteps must taken, ensure processes working synchronously. importantly,process writes token control channel (queue) beginningsequence, reads token end. causes deadlock situationn control channels, accessed two processes.precisely, process pairs arranged cycle, pair control channel. overall system blocked iff process pairs stateoccupied (written into) one control channel, waiting occupy other.sense, Optical-Telegraph viewed version Dining-Philosophersinternal states philosophers complicated. particular, philosophers(process pairs) choose order pick forks (occupy controlchannels). turns out, see Appendix A.2, latter important impacttopology h+ .remark that, IPC-4, also version Optical-Telegraph modeledprocess blocking via additional planning operators, derived predicates. choseconsider other, above, domain version since constitutes natural concise749fiHoffmannformulation, since planners IPC-4 scaled version withoutderived predicates.B.23 PipesworldPipesworld, units oil derivatives, called batches, must propagatedpipeline network. network consists areas connected pipe segments differentlength. pipes completely filled batches times, one pushes batchone end pipe, last batch currently pipe comes end.interface restrictions concerning types oil derivatives allowedadjacent inside pipe, tankage restrictions concerningnumber batches (of derivative type) stored point timeindividual areas.available planning operator push batch pipe. IPC4 encoding domain, look here, non-unitary pipe segments (pipescontaining one batch) operator split two parts, start finishaction (in order reduce number operator parameters needed correctly updatepipe contents). Also, pipe segments encoded directed fashion, making necessarydistinguish (symmetrical) push pop actions. initial state specifiescurrent batch positions etc., goal specifies batches broughtareas.B.24 PSRPSR domain, used IPC-4, task re-supply given set lines faultyelectricity network. nodes network breakers, feed electricitynetwork, devices, switches used change networkconfiguration. edges network lines, connecting two three nodes.breakers devices open closed. open, disconnectlines adjacent them. breakers closed, feed electricity adjacentlines. lines faulty. goal ensure none breakersaffected, i.e., feeds electricity faulty line, transitive connectionsnetwork. Also, goal requires given set lines (transitively) fedelectricity breaker.transitive network semantics, determining breaker feeds electricityline, breaker affected, modeled means various derived predicates (withrecursive rule antecedents enable computation transitive closure). threeplanning operators. One open device breaker currently closed, oneinverse closing action. actions require precondition breakercurrently affected. latter untrue, i.e., breaker currently affected,available action wait. effect open breakers affected.remark that, IPC-4, also different version PSR, formulatedpure STRIPS without derived predicates. version constitutes, however, relativelysuperficial pre-compiled form domain (Hoffmann & Edelkamp, 2005; Edelkamp et al.,2005). included IPC-4 order provide pure STRIPS planners750fiWhere Ignoring Delete Lists Worksdomain formulation could tackle (the pre-compilation necessary order enableformulation pure STRIPS).B.25 RoversRovers, number rovers must navigate road map waypoints, take rocksoil samples well images, communicate data number landers.nine available operators following. One navigate rover one waypointanother this, waypoints must connected rover. One samplesoil/rock rover waypoint using store so, rover must(empty) store equipped soil/rock analysis, must soil/rock samplewaypoint; effect one soil/rock analysis, store full, soil/rocksample longer waypoint. One empty full store dropping store. Onecalibrate camera waypoint using objective, one take imageobjective mode camera waypoint. operators, object mustvisible waypoint, camera must board rover equippedimaging. calibrate camera, object must calibration target it;effect operator calibration camera. take image, camera mustcalibrated, support required mode. effects one image data,camera longer calibrated. Finally, three operatorsrover communicate soil/rock/image data lander. so, landers waypointmust visible rover; effect data communicated.instances restricted visibility connectivity waypointsbi-directional waypoint w visible waypoint w0 holds true viceversa; rover move w w0 also move back. Another restrictioncamera initially calibrated (this serves make sure that, reachable state,calibrated camera least one calibration target). restrictions imposedRovers instances generated IPC-3 generator.B.26 SatelliteSatellite, satellites need take images different directions, certain modes, usingappropriate instruments. number satellites, number directions, numberinstruments, number modes. following five operators. Oneturn satellite direction another one; preconditions effects obviousones, action applied pair directions (no connectivity constraints).One switch instrument board satellite, satellite power available;effect, instrument power longer calibrated, satellitepower available. One switch instrument board satellite, instrumentpower; effect, satellite power available, instrument anymore.One calibrate instrument board satellite direction, satellite pointsdirection, instrument power, direction calibration targetinstrument. effect calibration camera. Finally, one takeimage instrument board satellite direction mode. so,satellite must point direction, camera must support mode, power,calibrated; effect one image direction mode.751fiHoffmanngoal images number direction/mode pairs; also, satellitesgoal requirement point specified direction. initial statessatellite (but instrument) power available, instrument calibrated.former restriction makes sure satellite power run one instrumenttime; latter restriction makes sure that, reachable state, calibrated instrumentleast one calibration target. restrictions imposed Satellite instancesgenerated IPC-3 generator.B.27 ScheduleSchedule, collection objects must processed number machines, applyingworking steps change objects shape, surface condition, color; one also drillholes varying widths varying orientations. nine operators. Eightdescribe working steps object machine. Amongst things, operatorspreconditions require scheduled elsewhere machine busy,operators effect scheduled, machine busy. ninthoperator time step, whose effect object scheduled, machinebusy, longer. One apply do-roll action object o, makes cylindricalhot (no longer cold, see also below), deleting surface conditions, colors,holes might have. One apply do-lathe o, making cylindrical roughsurface, deleting colors might painted before. One applydo-polish cold, giving polished surface. One apply do-grind o,giving smooth surface colors. One apply do-punch o, width worientation o, cold, resulting hole w o, rough surface. Onealso apply do-drill-press o, cold, making hole width w orientation(changing none os properties except making hole). cold, onealso apply do-spray-paint color c, deleting surface conditions might have.Finally, one apply do-immersion-paint o, changing none os properties exceptcolor. Note operator change os temperature, except do-rollmakes hot; that, made cold (this reason deadends arise, c.f. Theorem 1). Initially, objects cold, shapesurface condition specified. objects also painted initially, objectnone several holes. goal condition, objects requiredcylindrical shape (the shape produced machines),need surface condition, must painted, object requiredarbitrary number holes.B.28 Simple-TspSimple-Tsp trivial version TSP problem. single operator movelocations. applied two (different) locations, effect(besides obvious ones) destination location visited. instances specifynumber locations must visited, starting one them.752fiWhere Ignoring Delete Lists WorksB.29 TireworldTireworld, one must replace number flat tires. involves collection objectsmust used appropriate working steps. Briefly summarized, situationfollows. thirteen operators. boot either opened closed;initially closed shall end. pump, wrench, jackfetched put away (from/into boot); initially bootshall put back end. spare wheels initially inflated, inflatedusing pump (the add effect wheel inflated, delete effectlonger not-inflated). hub fastened nuts; loosened tightened,using wrench, respective hub ground. jack used eitherjack jack hub. hub jacked up, one undo (loose) nuts,up; nuts undone, one remove respective wheel, put one.optimal solution plan this: open boot; fetch tools; inflate spare wheels; loosennuts; turn jack hub, undo nuts, remove flat wheel, put sparewheel, nuts, jack hub again; tighten nuts; put away tools;close boot.B.30 ZenotravelZenotravel transportation domain variant vehicles (called aircrafts) use fuelunits replenished using refueling operator. number cities,number aircrafts, number persons, number different possible fuel levels.fuel levels encode natural numbers next predicate next(f,f0 ) true iff f0next higher fuel level f. task transport subset personsinitial locations goal locations. following five operators. Oneboard/debark person onto/from aircraft city; obvious preconditions effects. One fly aircraft city different city, decreasingaircrafts fuel level f f0 ; f must aircrafts current fuel level, f0 mustnext lower level. One also zoom aircraft; exactly flying it, exceptzooming uses fuel aircrafts fuel level decreased two units. Finally,one refuel aircraft city fuel level f fuel level f0 . conditionsf aircrafts current fuel level, f0 next higher level. Thus aircraftsrefueled city, steps one unit.ReferencesBacchus, F. (2001). AIPS00 planning competition. AI Magazine, 22 (3), 4756.Biundo, S., & Fox, M. (Eds.). (1999). Recent Advances AI Planning. 5th EuropeanConference Planning (ECP99), Lecture Notes Artificial Intelligence, Durham,UK. Springer-Verlag.Blum, A. L., & Furst, M. L. (1995). Fast planning planning graph analysis.Mellish, S. (Ed.), Proceedings 14th International Joint Conference ArtificialIntelligence (IJCAI-95), pp. 16361642, Montreal, Canada. Morgan Kaufmann.753fiHoffmannBlum, A. L., & Furst, M. L. (1997). Fast planning planning graph analysis. ArtificialIntelligence, 90 (1-2), 279298.Bonet, B., & Geffner, H. (1999). Planning heuristic search: New results.. Biundo, &Fox (Biundo & Fox, 1999), pp. 6072.Bonet, B., & Geffner, H. (2001a). Heuristic search planner 2.0. AI Magazine, 22 (3),7780.Bonet, B., & Geffner, H. (2001b). Planning heuristic search. Artificial Intelligence,129 (12), 533.Bonet, B., Loerincs, G., & Geffner, H. (1997). robust fast action selection mechanismplanning. Kuipers, B. J., & Webber, B. (Eds.), Proceedings 14th NationalConference American Association Artificial Intelligence (AAAI-97), pp.714719, Portland, OR. MIT Press.Botea, A., Muller, M., & Schaeffer, J. (2004). Using component abstraction automaticgeneration macro-actions.. Koenig et al. (Koenig, Zilberstein, & Koehler, 2004),pp. 181190.Botea, A., Muller, M., & Schaeffer, J. (2005). Learning partial-order macros solutions.Biundo, S., Myers, K., & Rajan, K. (Eds.), Proceedings 15th InternationalConference Automated Planning Scheduling (ICAPS-05), pp. 231240, Monterey, CA, USA. Morgan Kaufmann.Brazdil, P., & Jorge, A. (Eds.)., EPIA-01 (2001). Proceedings 10th Portuguese Conference Artificial Intelligence (EPIA-01), Porto, Portugal. Springer-Verlag.Bylander, T. (1994). computational complexity propositional STRIPS planning.Artificial Intelligence, 69 (12), 165204.Cesta, A., & Borrajo, D. (Eds.). (2001). Recent Advances AI Planning. 6th EuropeanConference Planning (ECP01), Lecture Notes Artificial Intelligence, Toledo,Spain. Springer-Verlag.Chen, Y., Hsu, C., & Wah, B. (2004). SGPlan: Subgoal partitioning resolutionplanning.. Edelkamp et al. (Edelkamp, Hoffmann, Littman, & Younes, 2004).Chen, Y., & Wah, B. (2003). Automated planning scheduling using calculus variationsdiscrete space.. Giunchiglia et al. (Giunchiglia, Muscettola, & Nau, 2003), pp.211.Chien, S., Kambhampati, R., & Knoblock, C. (Eds.)., AIPS-00 (2000). Proceedings5th International Conference Artificial Intelligence Planning Systems (AIPS-00),Breckenridge, CO. AAAI Press, Menlo Park.Do, M. B., & Kambhampati, S. (2001). Sapa: domain-independent heuristic metrictemporal planner.. Cesta, & Borrajo (Cesta & Borrajo, 2001), pp. 109120.Edelkamp, S. (2003a). Promela planning. Ball, T., & Rajamani, S. (Eds.), Proceedings10th International SPIN Workshop Model Checking Software (SPIN-03),pp. 197212, Portland, OR. Springer-Verlag.Edelkamp, S. (2003b). Taming numbers durations model checking integratedplanning system. Journal Artificial Intelligence Research, 20, 195238.754fiWhere Ignoring Delete Lists WorksEdelkamp, S., & Helmert, M. (2001). MIPS: model checking integrated planning system.AI Magazine, 22 (3), 6771.Edelkamp, S., Hoffmann, J., Englert, R., Liporace, F., Thiebaux, S., & Trug, S. (2005).Engineering benchmarks planning: domains used deterministic partIPC-4. Journal Artificial Intelligence Research. Submitted.Edelkamp, S., Hoffmann, J., Littman, M., & Younes, H. (Eds.)., IPC-04 (2004). Proceedings4th International Planning Competition, Whistler, BC, Canada. JPL.Fox, M., & Long, D. (1998). automatic inference state invariants TIM. JournalArtificial Intelligence Research, 9, 367421.Fox, M., & Long, D. (2001). STAN4: hybrid planning strategy based subproblemabstraction. AI Magazine, 22 (3), 8184.Frank, J., Cheeseman, P., & Stutz, J. (1997). gravity fails: Local search topology.Journal Artificial Intelligence Research, 7, 249281.Gazen, B. C., & Knoblock, C. (1997). Combining expressiveness UCPOPefficiency Graphplan.. Steel, & Alami (Steel & Alami, 1997), pp. 221233.Gerevini, A., & Schubert, L. (2000). Inferring state constraints DISCOPLAN: newresults.. Kautz, & Porter (Kautz & Porter, 2000), pp. 761767.Gerevini, A., & Schubert, L. (2001). DISCOPLAN: efficient on-line system computingplanning domain invariants.. Cesta, & Borrajo (Cesta & Borrajo, 2001), pp. 433436.Gerevini, A., Saetti, A., & Serina, I. (2003). Planning stochastic local searchtemporal action graphs. Journal Artificial Intelligence Research, 20, 239290.Gerevini, A., & Serina, I. (2002). LPG: planner based local search planning graphsaction costs.. Ghallab et al. (Ghallab, Hertzberg, & Traverso, 2002), pp.1322.Gerevini, A., Serina, I., Saetti, A., & Spinoni, S. (2003). Local search techniques temporalplanning LPG.. Giunchiglia et al. (Giunchiglia et al., 2003). Acceptedpublication.Ghallab, M., Hertzberg, J., & Traverso, P. (Eds.)., AIPS-02 (2002). Proceedings 6thInternational Conference Artificial Intelligence Planning Scheduling (AIPS02), Toulouse, France. Morgan Kaufmann.Giunchiglia, E., Muscettola, N., & Nau, D. (Eds.)., ICAPS-03 (2003). Proceedings13th International Conference Automated Planning Scheduling (ICAPS-03),Trento, Italy. Morgan Kaufmann.Haslum, P., & Geffner, H. (2000). Admissible heuristics optimal planning.. Chienet al. (Chien, Kambhampati, & Knoblock, 2000), pp. 140149.Helmert, M. (2003). Complexity results standard benchmark domains planning.Artificial Intelligence, 143, 219262.Helmert, M. (2004). planning heuristic based causal graph analysis.. Koenig et al.(Koenig et al., 2004), pp. 161170.755fiHoffmannHelmert, M., & Richter, S. (2004). Fast downward making use causal dependenciesproblem representation.. Edelkamp et al. (Edelkamp et al., 2004).Hoffmann, J. (2000). heuristic domain independent planning use enforcedhill-climbing algorithm. Ras, Z. W., & Ohsuga, S. (Eds.), Proceedings 12thInternational Symposium Methodologies Intelligent Systems (ISMIS-00), pp.216227, Charlotte, NC. Springer-Verlag.Hoffmann, J. (2001a). FF: fast-forward planning system. AI Magazine, 22 (3),5762.Hoffmann, J. (2001b). Local search topology planning benchmarks: empirical analysis.. Nebel (Nebel, 2001), pp. 453458.Hoffmann, J. (2002). Extending FF numerical state variables. Harmelen, F. V. (Ed.),Proceedings 15th European Conference Artificial Intelligence (ECAI-02), pp.571575, Lyon, France. Wiley.Hoffmann, J. (2003a). Metric-FF planning system: Translating ignoring delete listsnumeric state variables. Journal Artificial Intelligence Research, 20, 291341.Hoffmann, J. (2003b). Utilizing Problem Structure Planning: Local Search Approach,Vol. 2854 Lecture Notes Artificial Intelligence. Springer-Verlag.Hoffmann, J. (2003c).ignoring delete lists works: Local search topology planning benchmarks.Tech. rep. 185, Albert-Ludwigs-Universitat,Institut fur Informatik, Freiburg, Germany.Available http://www.mpiinf.mpg.de/hoffmann/papers/jair05report.ps.gz.Hoffmann, J., & Edelkamp, S. (2005). deterministic part IPC-4: overview. JournalArtificial Intelligence Research. appear.Hoffmann, J., & Nebel, B. (2001a). FF planning system: Fast plan generationheuristic search. Journal Artificial Intelligence Research, 14, 253302.Hoffmann, J., & Nebel, B. (2001b). RIFO revisited: Detecting relaxed irrelevance.. Cesta,& Borrajo (Cesta & Borrajo, 2001), pp. 325336.Kautz, H. A., & Porter, B. (Eds.)., AAAI-00 (2000). Proceedings 17th NationalConference American Association Artificial Intelligence (AAAI-00), Austin,TX. MIT Press.Koehler, J., & Hoffmann, J. (2000). reasonable forced goal orderings useagenda-driven planning algorithm. Journal Artificial Intelligence Research,12, 338386.Koehler, J., & Schuster, K. (2000). Elevator control planning problem.. Chien et al.(Chien et al., 2000), pp. 331338.Koenig, S., Zilberstein, S., & Koehler, J. (Eds.)., ICAPS-04 (2004). Proceedings14th International Conference Automated Planning Scheduling (ICAPS-04),Whistler, Canada. Morgan Kaufmann.Long, D., & Fox, M. (2000). Automatic synthesis use generic types planning..Chien et al. (Chien et al., 2000), pp. 196205.756fiWhere Ignoring Delete Lists WorksLong, D., & Fox, M. (2003). 3rd international planning competition: Resultsanalysis. Journal Artificial Intelligence Research, 20, 159.McDermott, D. (1996). heuristic estimator means-ends analysis planning. Drabble, B. (Ed.), Proceedings 3rd International Conference Artificial IntelligencePlanning Systems (AIPS-96), pp. 142149. AAAI Press, Menlo Park.McDermott, D. (2000). 1998 AI planning systems competition. AI Magazine,21 (2), 3555.McDermott, D. V. (1999). Using regression-match graphs control search planning.Artificial Intelligence, 109 (1-2), 111159.Nebel, B. (Ed.)., IJCAI-01 (2001). Proceedings 17th International Joint ConferenceArtificial Intelligence (IJCAI-01), Seattle, Washington, USA. Morgan Kaufmann.Nebel, B., Dimopoulos, Y., & Koehler, J. (1997). Ignoring irrelevant facts operatorsplan generation.. Steel, & Alami (Steel & Alami, 1997), pp. 338350.Nguyen, X., & Kambhampati, S. (2000). Extracting effective admissible heuristicsplanning graph.. Kautz, & Porter (Kautz & Porter, 2000), pp. 798805.Nguyen, X., & Kambhampati, S. (2001). Reviving partial order planning.. Nebel (Nebel,2001), pp. 459464.Onaindia, E., Sapena, O., Sebastia, L., & Marzal, E. (2001). Simplanner: executionmonitoring system replanning dynamic worlds.. Brazdil, & Jorge (Brazdil &Jorge, 2001), pp. 393400.Penberthy, J. S., & Weld, D. S. (1992). UCPOP: sound, complete, partial order plannerADL. Nebel, B., Swartout, W., & Rich, C. (Eds.), Principles KnowledgeRepresentation Reasoning: Proceedings 3rd International Conference (KR92), pp. 103114, Cambridge, MA. Morgan Kaufmann.Refanidis, I., & Vlahavas, I. (1999). GRT: domain independent heuristic STRIPSworlds based greedy regression tables.. Biundo, & Fox (Biundo & Fox, 1999),pp. 4759.Refanidis, I., & Vlahavas, I. (2001). GRT planning system: Backward heuristic construction forward state-space planning. Journal Artificial Intelligence Research,15, 115161.Rintanen, J. (2000). iterative algorithm synthesizing invariants.. Kautz, & Porter(Kautz & Porter, 2000), pp. 806811.Sebastia, L., Onaindia, E., & Marzal, E. (2001). Stella: optimal sequential parallelplanner.. Brazdil, & Jorge (Brazdil & Jorge, 2001), pp. 409416.Srivastava, B., Nguyen, X., Kambhampati, S., Do, M. B., Nambiar, U., Nie, Z., Nigenda, R.,& Zimmermann, T. (2001). Altalt: Combining graphplan heuristic state search.AI Magazine, 22 (3), 8890.Steel, S., & Alami, R. (Eds.). (1997). Recent Advances AI Planning. 4th European Conference Planning (ECP97), Vol. 1348 Lecture Notes Artificial Intelligence,Toulouse, France. Springer-Verlag.757fiHoffmannThiebaux, S., Hoffmann, J., & Nebel, B. (2003). defence PDDL axioms. Gottlob, G.(Ed.), Proceedings 18th International Joint Conference Artificial Intelligence(IJCAI-03), pp. 961966, Acapulco, Mexico. Morgan Kaufmann.Thiebaux, S., Hoffmann, J., & Nebel, B. (2005). defence PDDL axioms. ArtificialIntelligence. appear.Younes, H., & Simmons, R. (2002). role ground actions refinement planning..Ghallab et al. (Ghallab et al., 2002), pp. 5461.758fiJournal Artificial Intelligence Research 24 (2005) 889-917Submitted 11/04; published 12/05Ignorability Statistical Probabilistic InferenceManfred Jaegerjaeger@cs.aau.dkInstitut Datalogi, Aalborg UniversitetFredrik Bajers Vej 7 E, DK-9220 AalborgAbstractdealing incomplete data statistical learning, incomplete observationsprobabilistic inference, one needs distinguish fact certain event observedfact observed event happened. Since modeling computationalcomplexities entailed maintaining proper distinction often prohibitive, one asksconditions safely ignored. conditions given missingrandom (mar) coarsened random (car) assumptions. paper providein-depth analysis several questions relating mar/car assumptions. Main purposestudy provide criteria one may evaluate whether car assumptionreasonable particular data collecting observational process. questioncomplicated fact several distinct versions mar/car assumptions exist.therefore first provide overview different versions, highlightdistinction distributional coarsening variable induced versions. showdistributional versions less restrictive sufficient applications.address two different perspectives question mar/car assumptionwarranted. First provide static analysis characterizes admissibilitycar assumption terms support structure joint probability distributioncomplete data incomplete observations. obtain equivalence characterizationimproves extends recent result Grunwald Halpern. turnprocedural analysis characterizes admissibility car assumption termsprocedural models actual data (or observation) generating process. mainresult analysis stronger coarsened completely random (ccar) conditionarguably reasonable assumption, alone corresponds data coarseningprocedures satisfy natural robustness property.1. IntroductionProbabilistic models become preeminent tool reasoning uncertaintyAI. probabilistic model consists state space W , probability distributionstates x W . given probabilistic model used probabilistic inference basedobservations. observation determines subset U W true state knownbelong to. Probabilities updated conditioning U .required probabilistic models often learned empirical data using statisticalparameter estimation techniques. data consist sampled exact states W ,often consists incomplete observations, establish exactdata point x belongs subset U W . learning probabilistic model,using probabilistic inference, one should, principle, distinguish eventcertain observation U made (U observed) event truestate W member U (U occurred). Ignoring distinction probabilisticc2005AI Access Foundation. rights reserved.fiJaegerinference lead flawed probability assignments conditioning. Illustrationsgiven well-known probability puzzles like Monty-Hall problem three prisoners paradox. Ignoring distinction statistical learning lead constructionmodels fit true distribution W . spite known difficulties,one usually tries avoid extra complexity incurred making proper distinctionU observed U occurred. statistics exists sizable literatureignorability conditions permit learning procedures ignore distinction.AI literature dealing probabilistic inference topic received rather scant attention, though realized early (Shafer, 1985; Pearl, 1988). Recently, however,Grunwald Halpern (2003) provided in-depth analysis ignorabilityprobabilistic inference point view.ignorability conditions required learning inference basicallymathematical form, expressed missing random (mar ) coarsenedrandom (car ) conditions. paper investigate several questions relatingformal conditions. central theme investigation provide deeper insightmakes observational process satisfy, violate, coarsened random condition.question studied two different angles: first (Section 3) identify qualitative properties joint distribution true states observations make carassumption feasible all. qualitative properties consider constraintsstates observations nonzero probabilities. directly extends workGrunwald Halpern (2003) (henceforth also referred GH ). fact, main resultSection 3 extension improvement one main results GH. Secondly(Section 4), investigate general types observational procedures lead carobservations. This, again, directly extends material GH, well earlierwork Gill, van der Laan & Robins (1997) (henceforth also referred GvLR).develop formal framework allows us analyze previous new types proceduralmodels unified systematic way. particular, framework allows us specifyprecise conditions makes certain types observational processes natural reasonable. somewhat surprising result analysis arguably naturalclasses observational processes correspond exactly processes resultobservations coarsened completely random (ccar ) strengthened versioncar often considered unrealistically strong assumption.2. Fundamentals Coarse Data Ignorabilityexist numerous definitions literature means data missingcoarsened random (Rubin, 1976; Dawid & Dickey, 1977; Heitjan & Rubin, 1991; Heitjan,1994, 1997; Gill et al., 1997; Grunwald & Halpern, 2003). capturebasic principle, various definitions subtly different way substantially affectimplications. Section 2.1 give fairly comprehensive overview variantdefinitions, analyze relationships. survey aim providing uniformframework terminology different mar /car variants. Definitions attributedearlier sources basic content first appeared, even though definitionsterminology differ details original versions (cf. also remarksend Section 2.1).890fiIgnorability Statistical Probabilistic InferenceSpecial emphasis placed distinction distributional coarseningvariable induced versions car . paper main focus distributionalversions. Section 2.2 summarize results showing distributional car sufficientestablish ignorability probabilistic inference.2.1 Defining Carbegin concepts introduced Rubin (1976) special case datamissing values. Assume concerned multivariate random variable X =(X1 , . . . , Xk ), Xi takes values finite state space V . Observations Xincomplete, i.e. observe values = (y 1 , . . . , yk ), yi either valuexi Vi Xi , special missingness symbol . One view realizationrandom variable function X missingness indicator, ,random variable values {0, 1} k := f (X, ),(1)(2)= f (x, m) definedyi =xi mi = 0.mi = 1Rubins (1976) original definition missing random condition conditionaldistribution : data missing random iff m:P (M = | X) constant {x | P (X = x) > 0, f (x, m) = y}.(3)refer condition -mar condition, indicate fact expressedterms missingness indicator .Example 2.1 Let X = (X1 , X2 ) V1 = V2 = {p, n}. interpret X1 , X2 twomedical tests possible outcomes positive negative. Suppose test X 1 alwaysperformed first patient, test X 2 performed X1 comespositive. Possible observations made(n, ) = f ((n, n), (0, 1)) = f ((n, p), (0, 1)),(p, n) = f ((p, n), (0, 0)),(p, p) = f ((p, p), (0, 0)).= (n, ) = (0, 1) obtainP (M = | X = (n, n)) = P (M = | X = (n, p)) = 1,(3) satisfied. values condition (3) trivially holds,sets x-values (3) singletons (or empty).also eliminate random vector definition mar , formulatedefinition directly terms joint distribution X. this, observeobserved identified setU (y) := {x | : yi 6= xi = yi }.891(4)fiJaegerset U (y) contains complete data values consistent observed y.rephrase -marP (Y = | X) constant {x | P (X = x) > 0, x U (y)}.(5)call distributional mar condition, abbreviated d-mar , termsjoint distribution complete data X, observed data .Example 2.2 (continued Example 2.1)U ((n, )) = {(n, n), (n, p)}, U ((p, n)) = {(p, n)}, U ((p, p)) = {(p, p)}.computeP (Y = (n, ) | X = (n, n))) = P (Y = (n, ) | X = (n, p))) = 1.Together (again trivial) conditions two possible -values, shows(5).-mar d-mar equivalent, given X one-to-one correspondence, i.e. exists function h x, x U (y):= f (x, m) = h(y)(6)(h simply translates {0, 1}-vector replacing occurrences 1,values 0). Using (6) one easily derive one-to-one correspondenceconditions (3) (5), hence obtain equivalence -mar d-mar .One advantage -mar easily leads strengthened condition missingcompletely random (Rubin, 1976):P (M = | X) constant {x | P (X = x) > 0}.(7)refer -mcar condition.Example 2.3 (continued Example 2.2) obtainP (M = (0, 1) | X = (n, p)) = 1 6= 0 = P (M = (0, 1) | X = (p, p)).Thus, observations -mcar.distributional version mcar slightly complex, defer statementgeneral case coarse data, turn to.Missing attribute values one special way observations incomplete. possibilities include imperfectly observed values (e.g. X knowneither x Vi x0 Vi ), partly attributed values (e.g. x V = Vj knownXi = x Xj = x), etc. cases, incomplete observation X defines setpossible instantiations X consistent observation. leadsgeneral concept coarse data (Heitjan & Rubin, 1991), generalizes conceptmissing data observations arbitrary subsets state space. general setting892fiIgnorability Statistical Probabilistic Inferenceconvenient abstract particular structure state space productki=1 Vi induced multivariate X, instead assume univariate random variableX taking values set W = {x1 , . . . , xn } (of course, preclude possibilityfact W = ki=1 Vi ). Abstracting missingness indicator , one imaginecoarse data produced X coarsening variable G. Again, one also takecoarsening variable G picture, model coarse data directly jointdistribution X random variable (the observed data) values 2 W .view mostly adopt, therefore motivation following definition.Definition 2.4 Let W = {x1 , . . . , xn }. coarse data space W(W ) := {(x, U ) | x W, U W : x U }.coarse data distribution probability distribution P (W ).coarse data distribution seen joint distribution P (X, ) randomvariable X values W , random variable values 2 W \ . jointdistribution X constrained condition X . Note that, thus, coarsedata spaces coarse data distributions actually represent true complete datacoarsened observation. remainder paper, P without argumentsalways denote coarse data distribution sense Definition 2.4,used interchangeably P (X, ). need refer (joint) distributionsrandom variables, listed explicitly arguments P . E.g.: P (X, G)joint distribution X G.Coarsening variables introduced following definition means specifyingconditional distribution given X.Definition 2.5 Let G random variable values finite state space ,f : W 2W \ ,(8)x P (X = x) > 0: x f (x, g);x, x0 P (X = x) > 0, P (X = x0 ) > 0, U 2W \ , g :f (x, g) = U, x0 U f (x0 , g) = U.(9)call pair (G, f ) coarsening variable X. Often also refer G alonecoarsening variable, case function f assumed implicitly given.coarse data distribution P induced X (G, f ) P joint distributionX f (X, G).condition (9) always made explicit introduction coarseningvariables. However, noted Heitjan (1997), usually implied conceptcoarsening variable. GvLR (pp. 283-285) consider somewhat general setupf (x, g) take values 2 W directly, = f (x, g) observable893fiJaegerU = (y) W obtained via mapping . introductionintermediate observable necessary, example, dealing real-valuedrandom variables X. Since statistically tractable modelsgeneral distributions 2R , parameterization small subset 2 R needed.example, could take values R R, (y 1 , y2 ) might defined interval[min{y1 , y2 }, max{y1 , y2 }]. GvLR require (9) general; instead call f Cartesian(9) satisfied.following definition generalizes property (6) missingness indicators arbitrarycoarsening variables.Definition 2.6 coarsening variable (G, f ) called invertible exists functionh : 2W \ ,(10)x, U x U , g :U = f (x, g) g = h(U ).(11)alternative reading (11) G observable: coarse observation Uvalue g reconstructed, G treated fully observable randomvariable.generalize definition missing (completely) random coarsedata setting. begin generalization -mar .Definition 2.7 (Heitjan, 1997) Let G coarsening variable X. joint distributionP (X, G) G-car U W , g :P (G = g | X) constant {x | P (X = x) > 0, f (x, g) = U }.(12)marginalizing coarsening variable G (or assuming variable Gfirst place), obtain following distributional version car .Definition 2.8 (Heitjan & Rubin, 1991) Let P coarse data distribution. P d-carU WP (Y = U | X) constant {x | P (X = x) > 0, x U }.(13)X multivariate, incompleteness observations consists missing values,d-car coincides d-mar , -car -mar .Condition (12) refers joint distribution X G, condition (13) jointdistribution X . Since function X G, one always determinejoint distribution X G whether d-car holds induced coarse datadistribution. Conversely, coarse data distribution P (X, ) coarseningvariable G inducing P (X, ) given, general possible determine whetherP (X, G) G-car , joint distribution P (X, G) cannot reconstructedgiven information. However, suitable assumptions G possible inferP (X, G) G-car induced P (X, ) d-car . followingtwo theorems clarify relationships G-car d-car . theoremsessentially restatements conceptual framework results already given GvLR (pp.284-285).894fiIgnorability Statistical Probabilistic InferenceTheorem 2.9 coarse data distribution P (X, ) d-car iff exists coarseningvariable G inducing P (X, ), P (X, G) G-car.Proof: First assume P (X, ) d-car . construct canonical coarsening variableG inducing P (X, ) follows: let = 2 W \ f (x, U ) := U x W U .Define -valued coarsening variable G P (G = U | X = x) := P (Y = U | X = x).Clearly, coarse data distribution induced G original P (X, ), P (X, G)G-car .Conversely, assume P (X, G) G-car G inducing P (X, ). Let U W ,x U .P (Y = U | X = x) = P (G {g | f (x, g) = U } | X = x)X=P (G = g | X = x).g:f (x,g)=U(9) summation values g x U .G-car , conditional probabilities P (G = g | X = x) constant x U . ThusP (Y = U | X = x) constant x U , i.e. d-car holds.following example shows d-car general imply G-car ,fixed coarse data distribution P (X, ) induced coarsening variableG-car holds, another coarsening variable G-car hold.Example 2.10 (continued Example 2.3) already seen coarse datadistribution d-mar -mar, hence d-car -car.coarsening variable inducing P (X, ). fact, evensimplest: let G1 trivial random variable assume one state, i.e. 1 = {g}.Define f1f1 ((n, n), g) = f1 ((n, p), g) = {(n, n), (n, p)},f1 ((p, n), g) = {(p, n)},f1 ((p, p), g) = {(p, p)}.G1 induces P (X, ), P (X, G1 ) also trivially G-car.Finally, let G2 defined 2 = {g1 , g2 } f2 (x, gi ) = f1 (x, g) x W= 1, 2. Thus, G2 like G1 , trivial state space G1 split twoelements identical meaning. Let conditional distribution G 2 given XP (G2 = g1 | X = (n, n)) = P (G2 = g2 | X = (n, p)) = 2/3,P (G2 = g2 | X = (n, n)) = P (G2 = g1 | X = (n, p)) = 1/3,P (G2 = g1 | X = (p, n)) = P (G2 = g1 | X = (p, p)) = 1.Again, G2 induces P (X, ). However, P (X, G2 ) G-car,f2 ((n, n), g1 ) = f2 ((n, p), g1 ) = {(n, n), (n, p)},P (G2 = g1 | X = (n, n)) 6= P (G2 = g1 | X = (n, p))violates G-car condition. G2 invertible sense Definition 2.6: when,example, U = {(n, n), (n, p)} observed, possible determine whether valueG2 g1 g2 .895fiJaegerfollowing theorem shows non-invertibility G 2 preceding examplereason cannot deduce G-car P (X, G 2 ) d-car propertyinduced P (X, ). theorem completes picture G-car / d-car relationship.Theorem 2.11 Let P (X, ) coarse data distribution, G invertible coarsening variable inducing P (X, ). P (X, ) d-car, P (X, G) G-car.Proof: Let U W , g , x U , P (X = x) > 0 f (x, g) = U . Since Ginvertible, f (x, g 0 ) 6= U g 0 6= g, henceP (G = g | X = x) = P (Y = U | X = x).assumption P d-car follows right-hand probability constantx U , hence holds left-hand side, i.e. G-car holds.turn coarsening completely random (ccar ). straightforward generalize definition -mcar general coarsening variables:Definition 2.12 (Heitjan, 1994) Let G coarsening variable X. joint distribution P (X, G) G-ccar gP (G = g | X) constant {x | P (X = x) > 0}.(14)distributional version ccar seem formalized previouslyliterature. GvLR refer coarsening completely random, provide formaldefinition. However, implicit discussion mind slightlyrestricted version following definition (the restriction limitation casek = 1 Theorem 2.14 below).first observe one cannot give definition d-ccar variant Definition 2.12way Definition 2.8 varies Definition 2.7, would lead uscondition P (Y = U | X) constant {x | P (X = x) > 0}. would inconsistentexistence x W \ U P (X = x) > 0. However, real semantic cored-car , arguably, much captured Definition 2.8, characterization givenTheorem 2.9. d-ccar , therefore, make analogous characterization basisdefinition:Definition 2.13 coarse data distribution P (X, ) d-ccar iff exists coarseningvariable G inducing P (X, ), P (X, G) G-ccar.following theorem provides constructive characterization d-ccar .Theorem 2.14 coarse data distribution P (X, ) d-ccar iff exists family {W 1 ,. . . , Wk } partitions W , probability distribution ( 1 , . . . , k ) (W1 , . . . , Wk ),x W P (X = x) > 0:XP (Y = U | X = x) =.(15)i1,...,kxU Wi896fiIgnorability Statistical Probabilistic InferenceMissing valuesd-mar -marCoarse observations(c)-mcarG-car(a)(b)==(c)G-ccard-car(a)==d-ccarFigure 1: Versions car . (a): exists G implication holds; (b):invertible G implication holds; (c): equivalence holds G = .Proof: Assume P d-ccar . Let G coarsening variable inducing P (X, ),P (X, G) G-ccar . (9), value g induces partition Wi ={Ui,1 , . . . , Ui,k(i) }, f (x, gi ) = Ui,j x Ui,j . partitions Wi together:= P (G = gi | X) provide representation P (X, ) form (15).Conversely, P (X, ) given (15) via partitions W 1 , . . . , Wk parameters ,one defines coarsening variable G = {1, . . . , k}, P (G = g | X = x) = xP (X = x) > 0, f (x, i) U W containing x. P (X, G) G-ccarinduces P (X, ), hence P (X, ) d-ccar .before, G-ccar property P (X, G) cannot determinedinduced coarse data distribution:Example 2.15 (continuation Example 2.10) P (X, ) d-ccar inducedthree coarsening variables , G 1 , G2 . However, P (X, G1 ) G-ccar, P (X, )P (X, G2 ) not.previous example also shows analog Theorem 2.11 holds ccar :invertible, d-ccar induced P (X, ) cannot infer G-ccarP (X, ).Figure 1 summarizes different versions mar /car considered. distributional versions d-car d-ccar weaker - G- counterparts,therefore less restrictive assumptions. time, sufficient establishignorability statistical learning probabilistic inference tasks. caseprobabilistic inference detailed Theorem 2.18 following section.statistical inference problems, too, required ignorability results obtaineddistributional car versions, unless specific coarsening variable explicitly partinference problem. Whenever coarsening variable G introduced artificialconstruct modeling connection incomplete observations complete data,one must aware G-car G-ccar conditions unnecessarily restrictive,may lead us reject ignorability when, fact, ignorability holds (cf. Examples 2.32.15).897fiJaegerconclude section three additional important remarks definitions car ,needed complete picture different approaches car literature:Remark 1: definitions given weak versions mar /car . Corresponding strong versions obtained dropping restriction P (X = x) > 0(3),(5),(7),(12),(13),(14), respectively (15). Differences weak strong versionscar studied previous work (Jaeger, 2005). results obtained indicatecontext probability updating weak versions suitable. reasongo details strong versions here.Remark 2: definitions car differ originally given Rubin Heitjan definitions global definitions view mar /car propertyjoint distribution complete coarse data. original definitions, hand,conditional single observation = U , impose constraints jointdistribution X values . local mar /car assumptionsrequired justify application certain probabilistic statistical inferencetechniques single observation = U . global mar /car conditions stated justify inference techniques general strategies would applied possibleobservation. Local versions car natural Bayesian statistical philosophy,whereas global versions required frequentist interpretation. Global versionscar also used works (e.g., Jacobsen & Keiding, 1995; Gill et al., 1997;Nielsen, 1997; Cator, 2004).Remark 3: definitions results stated strictly limited casefinite W . already indicated discussion following Definition 2.5, extensions cargeneral state spaces C typically require setup observations modeledrandom variable taking values manageable state space 2 C . Severalformalizations car continuous state spaces investigated (e.g., Jacobsen &Keiding, 1995; Gill et al., 1997; Nielsen, 2000; Cator, 2004).2.2 IgnorabilityCar mar assumptions needed ignoring distinction U observedU occurred statistical inference probability updating. statistical inference, example, d-car required justify likelihood maximizing techniques likeEM algorithm (Dempster, Laird, & Rubin, 1977) learning incomplete data.paper emphasis probability updating. therefore briefly review significancecar context. use well-known Monty Hall problem.Example 2.16 contestant game show asked choose one three closed doorsA, B, C, behind one hidden valuable prize, others hiding goat.contestant chooses door A, say. host opens door B, revealing goat. pointcontestant allowed change choice C. Would advantageous?savvy probabilistic reasoner, contestant knows analyzesituation using coarse data space ({A, B, C}), compute probabilitiesP (X = | = {A, C}), P (X = C | = {A, C}).898fiIgnorability Statistical Probabilistic Inferencemakes following assumptions: 1. A-priori doors equally likely hideprize. 2. Independent contestants choice, host always open one door. 3.host never open door chosen contestant. 4. host never opendoor hiding prize. 5. one possible door remain host,determine fair coin flip one open. this, contestant first obtainsP (Y = {A, C} | X = A) = 1/2, P (Y = {A, C} | X = C) = 1,(16)P (X = | = {A, C}) = 1/3, P (X = C | = {A, C}) = 2/3.conclusion, thus, advantageous switch door C. differentconclusion obtained simply conditioning state space W {A, C} occurred:P (X = | X {A, C}) = 1/2, P (X = C | X {A, C}) = 1/2.Example 2.17 Consider similar situation previous example, assumecontestant decided would pick door A,communicating choice host, host says let make things little easieryou, opens door B, reveals goat. Would changing C advantageous?contestant performs similar analysis before, based followingassumptions: 1. A-priori doors equally likely hide prize. 2. hosts decisionopen door independent location prize. 3. Given decision opendoor, host chose fair coin flip one two doors hiding prize.P (Y = {A, C} | X = A) = P (Y = {A, C} | X = C),(17)henceP (X = | = {A, C}) = 1/2, P (X = C | = {A, C}) = 1/2.particularP (X = | = {A, C}) = P (X = | X {A, C})P (X = C | = {A, C}) = P (X = C | X {A, C}),i.e. difference {A, C} observed {A, C} occurred ignoredprobability updating.coarse data distribution Example 2.16 d-car (as evidenced (16)), whereascoarse data distribution Example 2.17 d-car (as shown, part, (17)).connection ignorability probability updating d-car assumptionshown GvLR GH. following theorem restates connection terminology.Theorem 2.18 Let P coarse data distribution. following equivalent:(i) P d-car.(ii) x W , U W x U P (Y = U ) > 0:P (X = x | = U ) = P (X = x | X U ).899fiJaeger(iii) x W , U W x U P (X = x) > 0:P (Y = U | X = x) =P (Y = U ).P (X U )equivalence (i)(ii) shown GH, based GvLR. equivalence (iii)see (Jaeger, 2005).3. Criteria Car CcarGiven coarse data distribution P is, principle, easy determine whether P d-car(d-ccar ) based Definition 2.8, respectively Theorem 2.14 (though case d-ccartest might require search possible families partitions). However, typically Pcompletely known. Instead, usually partial information P .case statistical inference problems information consists sample U 1 , . . . , UNcoarse data variable . case conditional probabilistic inference, knowmarginal P W . cases would like decide whether partial knowledgeP possess, conjunction certain assumptions structureP want make, consistent d-car , respectively d-ccar , i.e. whetherexists distribution P d-car (d-ccar ), satisfies partial knowledgeadditional assumptions.statistical problems, additional assumptions P usually come formparametric representation distribution X. X = (X 1 , . . . , Xk ) multivariate,parametric representation consist, example, factorization jointdistribution Xi , induced certain conditional independence assumptions.probabilistic inference problems analysis evidence gathering process leadassumptions likelihoods possible observations. cases, onedetermine whether constraints imposed P partial knowledge assumptionsconsistent constraints imposed d-car assumption. general,lead computationally difficult optimization constraint satisfaction problems.Like GH, focus section rather idealized special problem withinwider area, consider case constraints P establish valuesvariables X assume nonzero probability, i.e. constraints P consistprescribed sets support X . interpret special case reducedform specific statistical setting, assuming observed sample U 1 , . . . , UNused infer observations possible, parametric modelX, too, used determine x W nonzero probabilities. Similarly,probabilistic inference setting, special case occurs knowledgedistribution X used identify x P (X = x) > 0, assumptionsevidence generation pertain set possible observations.GH represent specific support structure P form 0, 1-matrix,call CARacterizing matrix. following definition provide equivalent,different, encoding support structures P .Definition 3.1 support hypergraph (for given coarse data space (W )) hypergraphform (N , W 0 ),900fiIgnorability Statistical Probabilistic InferenceN 2W \ set nodes,W 0 W set edges, edge x W 0 contains nodes{U N | x U }.(N , W 0 ) called support hypergraph distribution P (W ) iff N = {U2W \ | P (Y = U ) > 0}, W 0 = {x W | P (X = x) > 0}. support hypergraphcar-compatible iff support hypergraph d-car distribution P .PSfrag replacements{A, C}{A, B}B{A, B}{A, C}C B{B, C}C(b)(a)Figure 2: Support hypergraphs Examples 2.16 2.17Example 3.2 Figure 2 (a) shows support hypergraph coarse data distributionExample 2.16; (b) Example 2.17.definition support hypergraph may appear strange, much natural definition would take states x W P (X = x) > 0 nodes, observationsU W edges. support hypergraph Definition 3.1 dualnatural support hypergraph. turns duals useful purposeanalysis.support hypergraph contain multiple edges containing nodes.corresponds multiple states distinguished possible observations.Similarly, support hypergraph contain multiple nodes belong exactlyedges. corresponds different observations U, U 0 U {x | P (X = x) > 0} =U 0 {x | P (X = x) > 0}. hand, support hypergraph cannot containnode contained least one edge (this would correspond observation UP (Y = U ) > 0 P (X U ) = 0). Similarly, cannot contain empty edges.restrictions support hypergraphs:Theorem 3.3 hypergraph (N , E) finite N E support hypergraphdistribution P , iff node N contained least one edge E, edgesnonempty.Proof: Let W = E define P (X = x) = 1/ | E | x W . node n N letU (n) {x W | n x} (nonempty!), define P (Y = U (n) | X = x) = 1/ | x |.(N , E) support hypergraph P .901fiJaeger(almost) every hypergraph, thus, support hypergraph distribution, rather special hypergraphs support hypergraphs d-car distribution.goal, now, characterize car -compatible support hypergraphs. followingproposition gives first characterization. similar lemma 4.3 GH.Proposition 3.4 support hypergraph (N , W 0 ) car-compatible iff exists function : N (0, 1], x W 0X(U ) = 1(18)U N :U xProof: First note proposition looking x U edges nodes,respectively, support hypergraph, writing U x makes sense, meansx U x U seen states, respectively sets states, coarsedata space.Suppose (N , W 0 ) support hypergraph d-car distribution P . followsLemma 2.18 (U ) := P (Y = U )/P (X U ) defines function requiredproperty. Conversely, assume given. Let P (X) distribution Wsupport W 0 . Setting P (Y = U | X = x) := (U ) U N , x W 0 U extends Pd-car distribution whose support hypergraph (N , W 0 ).Corollary 3.5 support hypergraph contains (properly) nested edges,car-compatible.Example 3.6 support hypergraph Example 2.16 contains nested edges. Withoutnumerical computations, thus follows alone qualitative analysisobservations could made, coarse data distribution d-car, henceconditioning valid update strategy.proof Proposition 3.4 shows (as already observed GH ) supporthypergraph car -compatible, car -compatible given distribution P (X)support W 0 , i.e. support assumptions encoded hypergraph, togetherd-car assumption (if jointly consistent), impose constraints distributionX (other prescribed set support). truemarginal : car -compatible support hypergraph (N , W 0 ) usually alsoexist distributions P (Y ) N P (Y ) cannot extended d-car distributionsupport structure specified hypergraph (N , W 0 ).Proposition 3.4 already provides complete characterization car -compatible supporthypergraphs, used basis decision procedure car -compatibilityusing methods linear constraint satisfaction. However, Proposition 3.4 providemuch real insight makes evidence hypergraph car -compatible. Muchintuitive insight provided Corollary 3.5. criterion provided Corollary 3.5complete: following example shows, exist support hypergraphs withoutnested edges car -compatible.902fiPSfrag replacementsIgnorability Statistical Probabilistic Inferencex1x2U1U4U2U5U3U6x3x4x5Figure 3: car -incompatible support hypergraph without nested edgesExample 3.7 Let (N , W 0 ) shown Figure 3. assuming existence suitablefunction , summing(18) x 1 x2 , x3 , x4 , x5 , obtainPcontradiction 2 = 6i=1 (Ui ) = 3. Thus, (N , W 0 ) car-compatible.proceed extend partial characterization car -compatibility providedCorollary 3.5 complete characterization. following result improves theorem 4.4GH giving necessary sufficient condition car -compatibility, ratherseveral necessary ones, and, arguably, providing criterion intuitiveeasier apply. characterization based following definition.Definition 3.8 Let (N , W 0 ) support hypergraph. Let x = x1 , . . . , xk finite sequence edges W 0 , possibly containing repetitions edge. Denotelength k sequence | x |. x W denote 1 x indicator function Ninduced x, i.e.1 U x1x (U ) :=(U N ).0 elsePfunction 1x (U ) := xx 1x (U ) counts number edges x contain U .two sequences x, x0 write 1x 1x0 iff 1x (U ) 1x0 (U ) U .Example 3.9 evidence hypergraph Figure 3 1 (x1 ,x2 ) = 1(x3 ,x4 ,x5 )function N constant 1.x = (x1 , x3 , x4 , x5 ) one obtains 1x (U ) = 2 U = U1 , U2 , U3 , 1x (U ) = 1U = U4 , U5 , U6 . function also defined x = (x 1 , x1 , x2 ).evidence hypergraph, one two single edges x, x 0 : 1x < 1x0 iff xproper subset x0 .obtain following characterization (which partly inspired known conditions existence finitely additive measures, see Bhaskara Rao & Bhaskara Rao,1983):Theorem 3.10 support hypergraph (N , W 0 ) car-compatible iff every two sequences x, x0 edges W 01x = 1 x 0| x |=| x0 |,(19)01x 1x0 , 1x 6= 1x0 | x |<| x | .903(20)fiJaegerProof: Denote k :=| W 0 |, l :=| N |. Let = (ai,j ) incidence matrix (N , W 0 ), i.e.k l matrix ai,j = 1 Uj xi , ai,j = 0 Uj 6 xi (using indexingsi, j W 0 N ).Condition (3.4) reads:exists (0, 1]l = 1(21)(here 1 vector k ones). edge indicator function 1 x represented rowvector z Nk , zi number times xi occurs x. 1x writtenrow vector zA, conditions Theorem 3.10 become: z, z 0 Nk :zA = z 0 z 1 = z 0 1,0(22)00zA z A, zA 6= z z 1 < z 1.(23)Subtracting right sides, equivalent to: z Z k :zA = 0 z 1 = 0,(24)zA 0, zA 6= 0 z 1 < 0.(25)Using Farkass lemma (see e.g. Schrijver, 1986, Section 7.3), one obtains conditions (24) (25) necessary sufficient (21). application Farkasslemma particular setting one observe since 1 rational,sufficient (24) (25) rational z (cf. Schrijver, 1986[p.85]). This, turn,equivalent (24) (25) integer z. strict positivity solutionderived conditions (24) (25) analogous arguments Corollary 7.1k(Schrijver, 1986).Example 3.11 Example 3.9 immediately obtain nested edges x, x 0 violate(20), hence obtain Corollary 3.5. Also sequences (x 1 , x2 ) (x3 , x4 , x5 )support hypergraph Figure 3 violate (19), obtain car-incompatibility hypergraph.PSfrag replacements(a)(b-i)(b-ii)(c)(d)Figure 4: Car -compatible support hypergraphs three nodesExample 3.12 GH (Example 4.6) derive complete characterization car-compatibilitycase exactly three different observations made positive probability.framework amounts finding support hypergraphs three nodes satisfyconditions Theorem 3.10. possible solutions shown Figure 4 (omittingequivalent solutions obtained duplicating edges). labeling (a)-(d) solutions904fiIgnorability Statistical Probabilistic Inferencecorresponds case enumeration GH. easy verify shown supporthypergraphs satisfy (19) (20). hypergraphs followsfacts adding new edge shown hypergraphs either leads hypergraphalready list (only possible pair (b-i) (b-ii)), introduces pair nestededges. Similarly, deleting edge either leads hypergraph already shown,invalid hypergraph nodes covered.4. Procedural Modelsfar emphasized distributional perspective car . tried identify car joint distribution complete coarse data. point viewcoarsening variables artificial construct introduced describe joint distribution. cases, however, coarsening variable also model actual physical,stochastic process leads data coarsening. cases, analysisobviously take concrete model underlying coarsening process account.section study d-car distributions terms procedural models datagenerating mechanism. results section extend previous investigations carmechanisms GvLR GH.first goal section determine canonical procedural models coarsening mechanisms leading d-car data. canonical models used practiceevaluating whether d-car assumption warranted particular data set investigation matching (partially known hypothesized) coarsening mechanismdata canonical models. investigation focus propertiesone may expect reasonable natural procedural models possess. propertiescaptured two formal conditions honesty robustness. analysisconditions provide new strong support d-ccar assumption.following definition procedural model essentially generalization coarseningvariables, obtained omitting condition (9), replacing single variable G(potentially infinite) sequence G.Definition 4.1 Let P coarse data distribution (W ). procedural model Pgivenrandom variable X distributed according marginal P W .finite infinite sequence G = G1 , G2 , . . . , random variables, G takesvalues finite set (i 1).function f : W 2W \ , (X, f (X, G)) distributed accordingP .also call procedural model (X, G, f ) car model (ccar model), coarse datadistribution P defines d-car (d-ccar ). following denote .natural coarsening processes modeled real-valued coarsening variables(e.g. censoring times, Heitjan & Rubin, 1991). accommodate real-valued variablesZ framework identifying Z sequence binary random variables Z (i 1)defining binary representation. sequence G containing continuous Z = G905fiJaegerreplaced sequence G0 original variables Gj (j 6= i) interleavedbinary Zi .following, discuss measurability issues detail (only Appendixsmall amount measure theory needed). mentioned, however,always assumed W equipped -algebra equal powerset,W generated product -algebra, f 1 (U ) measurableU W .f2.16h{A, C}{A, B}B{A, B}{A, B}C{A, C}{A, C}f2.17h{A, C}{A, B}B{B, C}{A, B}C{B, C}{A, C}Table 1: Procedural models Examples 2.16 2.17Example 4.2 Natural procedural models coarse data distributions Examples 2.162.17 constructed letting G = F represent coin flip determines dooropened. Suppose examples host following rule matchingresult coin flip potential doors opening: coin comes heads,host opens door first alphabetical order among doors (two,most) rules permit open. coin comes tails, opens door lastalphabetical order. formally represented procedural model X{A, B, C}-valued, uniformly distributed random variable, G consists single {h, t}valued, uniformly distributed random variable F , X F independent.Table 1 completes specification procedural models defining functionsf2.16 f2.17 respective examples. Note neither (F, f 2.16 ) (F, f2.17 )coarsening variables sense Definition 2.5, e.g. f 2.16 (B, h) 6= f2.16 (A, h),violation (9).two procedures described preceding example appear quite similar, yet oneproduces d-car distribution not. interested identifyingclasses procedural models guaranteed induce d-car (d-ccar ) distributions.Conversely, given d-car distribution P , would like identify procedural modelsmight induced P . begin class procedural models standstrivial one-to-one correspondence d-car distributions.Example 4.3 ( Direct car model) Let X W -valued random variable, G = G 11 = 2W \ . Let joint distribution X G 1 P (G1 = U | X = x) = 0x 6 U ,P (G1 = U | X = x) constant {x | P (X = x) > 0, x U }.(26)Define f (x, U ) = U . Procedural models form coarsening variable representations d-car distributions already encountered Theorem 2.9. Hence,coarse data distribution P d-car iff induced direct car model.906fiIgnorability Statistical Probabilistic Inferencedirect car models much restatement d-car definition.help us much endeavor identify canonical observational datagenerating processes lead d-car distributions, condition (26)correspond easily interpretable condition experimental setup.d-ccar situation quite different: direct encoding d-ccar conditionleads rather natural class procedural models. class models described nextcould called, analogy Example 4.3, direct ccar models. Since modelsdescribed permit natural interpretation, give different name, however.Example 4.4 ( Multiple grouped data model, MGD) Let X W -valued random variable. Let (W1 , . . . , Wk ) family partitions W (cf. Theorem 2.14). Let G = G 1 ,G1 takes values {1, . . . , k} independent X. Define f (x, i) U Wcontains x. (X, G1 , f ) ccar. Conversely, every d-ccar coarse data modelinduced multiple grouped data model.multiple grouped data model corresponds exactly CARgen procedure GH.allows intuitive interpretations representing procedures one randomly selects onek different available sensors tests, reveal true value Xaccuracy represented set U W containing x. special case k = 1corresponds grouped censored data (Heitjan & Rubin, 1991). GH introduced CARgenprocedure guaranteed produce d-car distributions. consider dccar , therefore establish exact correspondence CARgen d-ccar .similar vein, GvLR introduced general procedure generating d-car distributions.following example rephrases construction GvLR terminology.Example 4.5 ( Randomized monotone coarsening, RMC) Let X W -valued randomvariable. Let G = H1 , S1 , H2 , S2 , . . . , Sn1 , Hn , Hi take values 2W , Si{0, 1}-valued. DefineHiX HiHi :=W \ Hi X 6 Hi .Let conditional distribution H given X H1 , . . . , Hi1 concentrated subsetsi1j=1 Hj .model represents procedure one successively refines current coarse dataset Ai := i1h=1 Hh selecting random subset H Ai checking whether X Hinot, thus computing Hi Ai+1 . process continued first time = 1(i.e. Si represent stopping conditions). result procedure, representedfollowing function f :min{k|Sk =1}f (X, (H1 , S1 , . . . , Sn1 , Hn )) = i=1Hi .Finally, impose conditional independence condition distributionHi , Si depend X H1 , . . . , Hi1 , i.e.P (Hi | X, H1 , . . . , Hi1 ) = P (Hi | H1 , . . . , Hi1 )P (Si | X, H1 , . . . , Hi1 ) = P (Si | H1 , . . . , Hi1 ).907fiJaegershown GvLR, RMC model always generates d-car distribution, everyd-car distribution obtained way. GH state RMC models special caseCARgen models. see below, CARgen RMC actually equivalent,thus, correspond exactly d-ccar distributions. distribution Example 2.17standard example (already used slightly different form GvLR) d-cardistribution cannot generated RMC CARgen. question considerableinterest, then, whether exist natural procedural models correspond exactlyd-car distributions. GvLR state cannot conceive general mechanismrandomized monotone coarsening scheme constructing car mechanismsone would expect meet practice,. . . (p.267). GH, hand, generalizeCARgen models class models termed CARgen , show exactlycomprise models inducing d-car distributions.However, exact extent CARgen natural reasonabletrivial direct car models formally characterized. discuss issuebelow. First present another class procedural models. rather intuitive classcontains models equivalent CARgen/RMC model.Example 4.6 ( Uniform noise model) Let X W -valued random variable. Let G =N1 , H1 , N2 , H2 , . . ., Ni {0, 1}-valued, Hi W -valuedP (Hi = x) = 1/ | W |(x W ).(27)Let X, N1 , H1 , . . . independent. Define hi W, ni {0, 1}:f (x, (n1 , h1 , . . .)) = {x} {hi | : ni = 1}.(28)model describes procedure several steps (perhaps infinitely many) uniformlyselected states W added noise observation. random variables Nrepresent events cause additional noise added. distributions generatedprocedure d-car, x, U x U :P (Y = U | X = x) = P ({hi | : ni = 1} = U ) + P ({hi | : ni = 1} = U \ {x}).uniformity condition (27), independence family {X, N 1 , H1 , . . .},last probability term equation constant x U .uniform noise model generate exactly d-car distribution Example 2.17.However, generate variant distribution originally given GvLR.uniform noise model rather specialized, far able induce everypossible d-car distribution. mentioned above, GH proposed procedure calledCARgen generating exactly d-car distributions. procedure described GHform randomized algorithm, easily recast form proceduralmodel sense Definition 4.1. shall pursue detail, however, insteadpresent procedure essential properties CARgen (especiallyregard formal reasonableness conditions shall introduce below), somewhatsimpler perhaps slightly intuitive.908fiIgnorability Statistical Probabilistic InferenceExample 4.7 (Propose test model, P&T)) Let X W -valued random variable. LetG = G1 , G2 , . . . infinite sequence random variables taking values 2 W \ . LetX, G1 , G2 , . . . independent, Gi identically distributed,XP (Gi = U ) constant {x W | P (X = x) > 0}.(29)U :xUDefinef (x, (U1 , U2 , . . .) :=UiW= min{j 1 | x Uj }.{j 1 | x Uj } =P&T model describes procedure randomly propose set U W , testwhether x U , return U result positive (else continue). condition (29)understood unbiasedness condition, ensures every x W (withP (X = x) > 0) equally likely draw positive test x. following theoremanalogous Theorem 4.9 GH ; proof much simpler, however.Theorem 4.8 coarse data distribution P d-car iff induced P&T model.Proof: every distribution induced P&T model d-car follows immediatelyXP (Y = U | X = x) = P (Gi = U )/P (Gi = U 0 ).(30)U 0 :xU 0(29) constant {x U | P (X = x) > 0} (note, too, (29) ensuressum denominator (30) nonzero x, definition f case{j 1 | x Uj } = occurs probability zero).PConversely, let P d-car distribution (W ). Define c := U 2W P (Y = U | XU ),P (Gi = U ) = P (Y = U | X U )/c.SinceP (Y = U | X U ) = P (Y = U | X = x) x U P (X = x) > 0,PU :xU P (Y = U | X U ) = 1 x W P (X = x) > 0. follows (29)satisfied 1/c constant. resulting P &T model induces original P :P (f (X, G) = U | X = x) = (P (Y = U | X U )/c)/(XP (Y = U 0 | X U 0 )/c)U 0 :xU 0= P (Y = U | X U ) = P (Y = U | X = x).P&T model looks like reasonable natural procedure. However, violates desideratum GvLR put forward natural coarsening procedure:(D) coarsening procedure, information true valueX used finally revealed coarse data variable (Gillet al., 1997, p.266, paraphrased).909fiJaegerP&T model violates desideratum (D), first unsuccessfully test U 1 , . . . ,Uk , require information x 6 ki=1 Ui , included final data= Uk+1 . observation generating process Example 2.17, too, appears violate(D), host requires precise value X following strategy. Finally,uniform noise model violates (D), computation (28) final coarse dataoutput exact value X required. examples suggest (D) conditionone must necessarily expect every natural coarsening procedure possess. (D)appropriate coarse data generated experimental process aimeddetermining true value X, may unable precisely. scenario,(D) corresponds assumption information value X collectedexperimental process also reported final result. Apart experimentalprocedures, also accidental processes corrupting complete data generate d-car data (asrepresented, e.g., uniform noise model). procedures (D) immediatelyseen necessary feature. However, Theorem 4.17 lend additional support(D) also cases.GH argue class CARgen procedures contains reasonable processes,step algorithm depend information available experimenter, information encoded observations made experimentercourse running algorithm(GH, p. 260). saidP&T procedure. direct car model would reasonable sense,simulation variable G one would need pick distribution dependenttrue value X, assumed available. However, hard make rigorousdistinction direct car models one hand, CARgen /P&Thand, latter procedures permit tests value X (through checkingX U test sets U using singleton sets U one even query exact value X),continuation simulation dependent outcome tests.establish solid foundation discussing reasonable vs. unreasonable coarsening procedures introducing two different rigorous conditions naturalreasonable car procedures. One formalization desideratum (D),expresses invariance car property numerical parameter changes.show conditions satisfied generated distributiond-ccar . purpose analysis helpful restrict attention special typeprocedural models.Definition 4.9 procedural model (X, G, f ) Bernoulli-model family X, G 1 ,G2 , . . . independent.name Bernoulli model quite appropriate here, variables X, Gnecessarily binary. However, clear one could also replace multinomialX Gi suitable sets (independent) binary random variables. essence, then,Bernoulli model sense Definition 4.9 seen infinite sequenceindependent coin tosses (with coins varying bias). Focusing Bernoulli modelsreal limitation:Theorem 4.10 Let (X, G, f ) procedural model. exists Bernoulli model(X, G , f ) inducing coarse data distribution.910fiIgnorability Statistical Probabilistic Inferencereader may notice statement Theorem 4.10 really quite trivial:coarse data distribution induced (X, G, f ) distribution finite coarsedata space (W ), many simple, direct constructions Bernoulli modelsgiven distribution. significance Theorem 4.10, therefore, lies essentiallyfollowing proof, construct Bernoulli model (X, G , f ) preservesessential procedural characteristics original model (X, G, f ). fact, model(X, G , f ) understood implementation procedure (X, G, f ) usinggenerator independent random numbers.understand intuition construction, consider randomized algorithmsimulating procedural model (X, G, f ). algorithm successively samples valuesX, G1 , G2 , . . ., finally computes f (for natural procedural models value falready determined finitely many initial G -values, infinitely many Gneed sampled, algorithm actually terminates; considerations, however,algorithms taking infinite time pose conceptual difficulties). distribution usedsampling Gi may depend values previously sampled G 1 , . . . , Gi1 , which,computer implementation algorithm encoded current program state.set possible runs algorithm represented tree, branching nodes correspond sampling steps G . single execution algorithmgenerates one branch tree. One construct equivalent algorithm that,instead, generates whole tree breadth-first, labels branching noderandom value Gi associated node, sampled according distributiondetermined program state corresponding node. algorithm, samplingrandom values independent. labeling branching nodes identifies uniquebranch tree, branch, probability identified labelingequal probability branch representing execution original algorithm(a similar transformation pre-computing random choices might become relevantdescribed Gill & J.M.Robins, 2001[Section 7]). following proof formalizespreceding informal description.Proof Theorem 4.10: random variable G introduce sequence randomvariables Gi,1 , . . . , Gi,K(i) , K(i) =| W i1j=1 j | size joint state spaceX, G1 , . . . , Gi1 . state space Gi,h (with regard informal explanation,Gi,h corresponds node full computation tree represent sampling Gprevious execution resulted hth K(i) possible program states).construct joint distribution X G i,h setting P (Gi,h = v) = P (Gi = v |i1j ), taking(X, G1 , . . . , Gi1 ) = sh ) (sh hth state enumeration W j=1X Gi,h independent.straightforward define mappingK(i)h : W i1(X, h (X, G )) distributed (X, G) (the mapping h corresponds extraction active branch full labeled computation tree). Defining f (x, g ) :=f (x, h (x, g )) completes construction Bernoulli model.911fiJaegerDefinition 4.11 Bernoulli model (X, G , f ) obtained via construction proofTheorem 4.10 called Bernoulli transform (X, G, f ).Example 4.12 direct car model (X, G, f ) obtain Bernoulli transform (X, (G 1 ,. . . , Gn ), f ),P (Gi = U ) = P (G = U | X = xi ),h (xi , U1 , . . . , Un ) = (xi , Ui ),f (xi , U1 , . . . , Un ) = Ui .coarsening procedure Bernoulli model, information Xused sampling variables G. part procedure X influencesoutcome final computation = f (X, G). condition computationmuch knowledge X required finally revealed basicallycondition (9) coarsening variables. state space G (potentially)uncountable, however appropriate replace universal quantificationg (9) almost g probabilistic sense. thus define:Definition 4.13 Bernoulli model honest, x, x 0 P (X = x) > 0, P (X =x0 ) > 0, U 2W \ :P (G {g | f (x, g) = U, x0 U f (x0 , g) = U }) = 1.(31)Example 4.14 Bernoulli model Example 4.12 honest, oneU1 , . . . , Un P (G = (U1 , . . . , Un )) > 0: Uj 6= Ui , xi , xj Ui ,f (xi , U1 , . . . , Un ) = Ui 6= Uj = f (xj , U1 , . . . , Un ).Honest Bernoulli models certainly satisfy (D). hand, nonBernoulli models also seem satisfy (D) (notably RMC models,developed (D) mind). However, non-Bernoulli models appears hard makeprecise condition sampling G depend X beyond factX 1 . following theorem indicates formalization (D) terms Bernoullimodels narrow.Theorem 4.15 Bernoulli transforms MGD, CARgen RMC models honest.proof three types models elementary, though partly tedious. omitdetails here.turn second condition reasonable procedures. observeMGD/CARgen/RMC models essentially defined terms mechanical procedure generating coarse data, whereas direct car , uniform noise,P&T models (and similar way CARgen ) rely numerical conditions (26),(27),respectively (29), distributional parameters. procedures, therefore, fragilesense slight perturbations parameters destroy d-car propertyinduced distribution. would like distinguish robust car procedures1. intuitive condition G must independent X given turns inadequate.912fiIgnorability Statistical Probabilistic Inferenced-car property guaranteed mechanics process alone (as determinedstate spaces Gi , definition f ), depend parameterconstraints Gi (which, less subtle way, used mimic bruteforce condition (26)). Thus, essentially consider car procedure robust,stays car changes parameter settings G . two points consider state formal definition idea. First, observe conceptrobustness based Bernoulli models, since non-Bernoulli models evenarbitrarily small parameter changes create destroy independence relationsvariables X, G, independence relations, arguably, reflect qualitative rathermerely quantitative aspects coarsening mechanism.Secondly, want limit permissible parameter changes leaddrastic quantitative changes outcomes previously nonzero probability becomezero-probability events, vice versa. line perspective Section 3,set support distribution finite state space viewed basicqualitative property. current context dealing distributions uncountablestate spaces, need replace notion identical support notionabsolute continuity: recall two distributions P, P state space called mutuallyabsolutely continuous, written P P , P (S) = 0 P (S) = 0 measurable .distribution P (G) , G independent family, obtain P (G)P P , example, changing finitely many parameter values P (G = g) = r > 0new values P (Gi = g) = r > 0. hand, e.g. = {0, 1}, P (Gi = 0) = 1/2,P (Gi = 0) = 1/2 + > 0, P () 6 P (). distributionP (X) X alone one P (X) P (X) iff P P support.Definition 4.16 Bernoulli model (X, G, f ) robust car ( robust ccar), car (ccar),remains car (ccar) distributions P (X) P (G ) (i 1) replaceddistributions P (X) P (Gi ), P (X) P (X) P (G) P (G).Bernoulli transforms MGD/CARgen robust ccar . class RMCknow, far, car . Bernoulli transform RMC seen robust car .Bernoulli transforms CARgen /P&T, hand, robust (and neitheruniform noise model, already Bernoulli). come main resultsection, basically identifies existence reasonable procedural modelsd-ccar .Theorem 4.17 following equivalent distribution P (W ):(i) P induced robust car Bernoulli model.(ii) P induced robust ccar Bernoulli model.(iii) P induced honest Bernoulli model.(iv) P d-ccar.proof given Appendix A. Theorem 4.17 essentially identifies existencenatural procedural model d-car distribution property d-ccar , rather913fiJaegermerely d-car . somewhat surprising result first sight, given -mcarusually considered unrealistically strong assumption compared -mar .real contradiction here, however, seen d-ccar weaker-mcar . Theorem 4.17 indicates practice one may find many cases d-ccarholds, -mcar fulfilled.5. Conclusionreviewed several versions car conditions. differ respectformulation, terms coarsening variable, terms purely distributional constraint. different versions mostly non-equivalent. care, therefore,required determining particular statistical probabilistic inference problemappropriate car condition sufficient justify intended form inference,assumption warranted observational process hand. arguedistributional forms car relevant ones: observationsfully described subsets W , coarse data distribution requiredanalysis, introduction artificial coarsening variable G skewanalysis.main goal provide characterizations coarse data distributions satisfyd-car . considered two types characterizations: first type staticdescription d-car distributions terms sets support. derivedquite intuitive, complete characterization means support hypergraph coarsedata distribution.second type characterizations terms procedural models observational process generates coarse data. considered several modelsobservational processes, found arguably natural ones exactlygenerate observations d-ccar , rather d-car . somewhatsurprising first, -ccar typically unrealistically strong assumption (cf.Example 2.3). distributional form, d-ccar , contrary, turns perhapsnatural assumption. strongest support support d-ccar assumption provided equivalence (i) (iv) Theorem 4.17: assuming d-car , d-ccar , meansmust dealing fragile coarsening mechanism produces d-car datavirtue specific parameter settings. Since usually know muchcoarsening mechanism, assumption special parameter-equilibrium(as exemplified (29)) typically unwarranted.Acknowledgmentsauthor would like thank Ian Pratt providing initial motivation investigating basis probabilistic inference conditioning. Richard Gill, Peter Grunwald,James Robins provided valuable comments earlier versions paper.particularly indebted Peter Grunwald suggestions organization materialSection 2.1, led great improvement presentation. Richard Gill mustcredited short proof Theorem 3.10, replaced previous muchlaborious one.914fiIgnorability Statistical Probabilistic InferenceAppendix A. Proof Theorem 4.17Theorem 4.17 following equivalent distribution P (W ):(i) P induced robust car Bernoulli model.(ii) P induced robust ccar Bernoulli model.(iii) P induced honest Bernoulli model.(iv) P d-ccar .begin measure theoretic preliminaries. Let product -algebragenerated powersets 2i . joint distribution P (X, G) definedproduct 2W A. -algebra generated cylinder sets (g 1 , g2 , . . . , gk )j>k j (k 0, gh h h = 1, . . . , k). cylinder sets also basis topology. space (, O) compact (this seen directly, applicationTikhonovs theorem). follows every probability distribution P regular,especially A:P (A) = inf{P (O) | O}(see e.g. Cohn, 1993, Prop. 7.2.3). following use interchangeablynotation P (A) P (G A). former notation sufficient reasoningprobability distributions A, latter emphasizes fact always dealingdistributions induced family G random variables.Lemma A.1 Let P (G) joint distribution independent family G. LetA1 , A2 A1 A2 = P (G A1 ) = P (G A2 ) > 0. exists jointdistribution P (G) P (G) P (G) P (G A1 ) 6= P (G A2 ).Proof: Let p := P (A1 ). Let = p/2 A1 P (O) < p + . Usingdisjointness A1 A2 one obtains P (A1 | O) > P (A2 | O). Since cylinder setsbasis O, = i0 Zi countable family cylinders Z . follows alsocylinder set Z = (g1 , g2 , . . . , gk ) j>k j P (Z) > 0: P (A1 | Z) > P (A2 | Z).let > 0 define h = 1, . . . , k:XP (Gh = gh ) := 1 ; P (Gh = g) := (P (Gh = g)/P (Gh = g 0 )) (g 6= gh )g 0 :g 0 6=ghh k + 1: P (Gh ) := P (Gh ). P (G) P (G), P (A1 | Z) = P (A1 | Z), P (A2 |Z) = P (A2 | Z), therefore:P (A1 ) (1 )k P (A1 | Z),P (A2 ) (1 )k P (A2 | Z) + 1 (1 )k .sufficiently small gives P (A1 ) > P (A2 ).Proof Theorem 4.17: simplification may assume P (x) > 0 x W .justified observation none conditions (i)-(iv) affected addingdeleting states zero probability W .915fiJaegerimplication (iv)(ii) follows Example 4.4 observation MGD modelsrobust d-ccar Bernoulli models. (ii)(i) trivial. show (i)(iii) (iii)(iv).First assume (i), let (X, G, f ) robust car Bernoulli model inducing P .x W U W denoteA(x, U ) := {g | f (x, g) = U }.d-car property P equivalentP (G A(x, U )) = P (G A(x0 , U )).(32)x, x0 U .Condition (31) equivalent condition P (G A(x, U ) \ A(x 0 , U )) = 0x, x0 U . Assume otherwise. A1 := A(x, U ) \ A(x0 , U ), A2 := A(x0 , U ) \ A(x, U ):0 < P (G A1 ) = P (G A2 ). Applying Lemma A.1 obtain Bernoulli modelP (X, G) = P (X)P (G) P (X, G) P (X, G) P (G A1 ) 6= P (G A2 ). alsoP (G A(x, U )) 6= P (G A(x0 , U )), P (X, G) d-car, contradicting (i).(iii)(iv): Let\:={g | f (x, g) = U, x0 U f (x0 , g) = U }.x,x0 W,U W :x,x0 USince intersection finitely many x, x 0 , U , obtain (iii) P (G) = 1. U W define A(U ) := A(x, U ) , x U arbitrary.definition definition A(U ) independent particular choice x. Defineequivalence relation viag g0U W : g A(U ) g 0 A(U ).(33)equivalence relation partitions finitely many equivalence classes 1 , . . . , k .show g systemWi := {U | x W : f (x, g) = U }(34)partition W , definition W depend choice g.latter claim immediate fact gf (x, g) = Ug A(U ) x U.(35)first claim assume f (x, g) = U, f (x 0 , g) = U 0 U 6= U 0 . particular,g A(U ) A(U 0 ). Assume exists x00 U U 0 . (35) would obtainf (x00 , g) = U f (x00 , g) = U 0 , contradiction. Hence, sets U Wpairwise disjoint. also cover W , every x W exists Ux U = f (x, g).thus obtain given Bernoulli model equivalent multiple groupeddata model defined partitions W parameters := P (G ).916fiIgnorability Statistical Probabilistic InferenceReferencesBhaskara Rao, K. P. S., & Bhaskara Rao, M. (1983). Theory Charges: Study FinitelyAdditive Measures. Academic Press.Cator, E. (2004). testability CAR assumption. Annals Statistics,32 (5), 19571980.Cohn, D. (1993). Measure Theory. Birkhauser.Dawid, A. P., & Dickey, J. M. (1977). Likelihood bayesian inference selectivelyreported data. Journal American Statistical Association, 72 (360), 845850.Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood incompletedata via EM algorithm. Journal Royal Statistical Society, Ser. B, 39, 138.Gill, R., & J.M.Robins (2001). Causal inference complex longitudinal data: continuous case. Annals Statistics, 29 (6), 17851811.Gill, R. D., van der Laan, M. J., & Robins, J. M. (1997). Coarsening random: Characterizations, conjectures, counter-examples. Lin, D. Y., & Fleming, T. R. (Eds.),Proceedings First Seattle Symposium Biostatistics: Survival Analysis, LectureNotes Statistics, pp. 255294. Springer-Verlag.Grunwald, P. D., & Halpern, J. Y. (2003). Updating probabilities. Journal ArtificialIntelligence Research, 19, 243278.Heitjan, D. F. (1994). Ignorability general incomplete-data models. Biometrika, 81 (4),701708.Heitjan, D. F. (1997). Ignorability, sufficiency ancillarity. Journal Royal StatisticalSociety, B, 59 (2), 375381.Heitjan, D. F., & Rubin, D. B. (1991). Ignorability coarse data. Annals Statistics,19 (4), 22442253.Jacobsen, M., & Keiding, N. (1995). Coarsening random general sample spacesrandom censoring continuous time. Annals Statistics, 23 (3), 774786.Jaeger, M. (2005). Ignorability categorical data. Annals Statistics, 33 (4), 19641981.Nielsen, S. F. (1997). Inference missing data: Asymptotic results. Scandinavian JournalStatistics, 24, 261274.Nielsen, S. F. (2000). Relative coarsening random. Statistica Neerlandica, 54 (1), 7999.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems : Networks PlausibleInference (rev. 2nd pr. edition). Morgan Kaufmann series representationreasoning. Morgan Kaufmann, San Mateo, CA.Rubin, D. (1976). Inference missing data. Biometrika, 63 (3), 581592.Schrijver, A. (1986). Theory Linear Integer Programming. John Wiley & Sons.Shafer, G. (1985). Conditional probability. International Statistical Review, 53 (3), 261277.917fiJournal Artificial Intelligence Research 24 (2005) 851-887Submitted 08/05; published 12/05First Probabilistic TrackInternational Planning CompetitionHakan L. S. Youneslorens@cs.cmu.eduComputer Science DepartmentCarnegie Mellon UniversityPittsburgh, PA 15213 USAMichael L. LittmanDavid WeissmanJohn Asmuthmlittman@cs.rutgers.edudweisman@cs.rutgers.edujasmuth@cs.rutgers.eduDepartment Computer ScienceRutgers UniversityPiscataway, NJ 08854 USAAbstract2004 International Planning Competition, IPC-4, included probabilistic planningtrack first time. describe new domain specification language createdtrack, evaluation methodology, competition domains developed,results participating teams.1. BackgroundFourth International Planning Competition (IPC-4) held part International Conference Planning Scheduling (ICAPS04) Vancouver, British ColumbiaJune 2004. request ICAPS04 organizers, Sven Koenig Shlomo Zilberstein,asked create first probabilistic planning track part IPC-4.overriding goal first probabilistic planning track bring together twocommunities converging similar set research issues aid creating comparable tools evaluation metrics. One community consists Markov decision process(MDP) researchers interested developing algorithms apply powerfully expressiverepresentations environments. consists planning researchers incorporatingprobabilistic decision theoretic concepts planning algorithms. Cross fertilization begun, intent probabilistic planning track create setshared benchmarks metrics could crystallize efforts area study.created new domain description language called PPDDL1.0, described Section 2. PPDDL stands Probabilistic Planning Domain Definition Language, analogy PDDL (McDermott, 2000), introduced IPC-1. PPDDL modeledPDDL2.1 (Fox & Long, 2003), domain-description language deterministic domainsused IPC-3. Syntactically, language STRIPS/ADL-like flavor, includesprobabilistic constructs. focus energy participants issues dealing uncertainty, chose include constructs durative actions PPDDL1.0.basing domain-description language PDDL, sought remain spiritexisting planning competition, hope bring communitiesc2005AI Access Foundation. rights reserved.fiYounes, Littman, Weissman & Asmuthtogether. PPDDL representation relational. Although representationsexplicit objects traditional feature MDP-based domain-description languages,algorithms exploit features begun appear. expected participantspropositionalize domains running planning algorithms and,part, so.fully functional parser PPDDL provided participants C++ formplan validator simple planner. basic tools convert PPDDL decisiondiagram representation also provided. many ways, handling rich constructsPPDDL main hurdle many participants tried provide muchassistance could dimension.Although PPDDL supports numerical fluents, feature used fullestextent competition. Numerical quantities used representing rewardvalues, reward effects required additive.Since classical track well established point, helpful contrastprobabilistic track differs. defining difference, course, actionsuncertain effects. is, pickup action Blocksworld might behave differentlydifferent occasions, even state. single difference numbersignificant consequences. First, optimal action choices reaching goal mayfunction probabilistic outcomes along waya single sequence actions maysufficient. result, difficult output plan. reason,decided separate plan synthesis execution two phases, instead evaluatedplanners online. Second, unpredictability effects, even optimal planreaching goal may get unlucky fail probability. reason,evaluated planner multiple times problem include separateoptimal planner track. addition, since planners may fail reach goal stateexecutions, needed way trading goal attainment actioncost. decided score execution goal reward minus action cost chose goalreward problem. Section 3 describes evaluation methodology detail.total, designed eight domains competition (Section 4). domainssimply noisy versions classical planning domains, domains designedspecifically thwart greedy replanning approaches ignore uncertainty.Ten planners seven different groups entered competition. resultscompetition presented Section 5. deterministic replanner performed best overall,primarily due disproportionate number noisy classical planning problemsevaluation suite. domains proved challenging participating planners.latter domains could serve basis future probabilistic planning competitions.2. Probabilistic PDDLsection describes input language, PPDDL1.0, used probabilistictrack. PPDDL1.0 essentially syntactic extension Levels 1 2 PDDL2.1 (Fox& Long, 2003). complete syntax PPDDL1.0 given Appendix A. assumereader familiar PDDL2.1, focus new language features,include probabilistic effects rewards. detailed account PPDDL1.0 provided852fiThe First Probabilistic Track IPCNamebomb-in-package package1bomb-in-package package2toilet-cloggedbomb-defusedTypebooleanbooleanbooleanbooleanInit 1truefalsefalsefalseInit 2falsetruefalsefalseTable 1: State variables initial values Bomb Toilet problem.Younes Littman (2004). semantics PPDDL1.0 planning problem giventerms discrete-time Markov decision process (Howard, 1960, 1971; Puterman, 1994).2.1 Probabilistic Effectsdefine probabilistic decision theoretic planning problems, need add supportprobabilistic effects. syntax probabilistic effects(probabilistic p1 e1 . . . pk ek )meaningPk effect ei occurs probability pi . require constraints pi 0i=1 pi = 1 fulfilled: probabilistic effect declares exhaustive set probabilityweighted outcomes. do, however, allow probability-effect pair lefteffect empty. words,(probabilistic p1 e1 . . . pl el )Pli=1 pi< 1 syntactic sugar(probabilistic p1 e1 . . . pl el q (and))Plq = 1 i=1 pi (and) representing empty effect (that is, state changes).example, effect (probabilistic 0.9 (clogged)) means probability 0.9state variable clogged becomes true next state, probability 0.1state remains unchanged.Figure 1 shows encoding PPDDL Bomb Toilet example describedKushmerick, Hanks, Weld (1995). requirements flag :probabilistic-effectssignals probabilistic effects used domain definition. problem,two packages, one contains bomb. bomb defused dunkingpackage containing bomb toilet. 0.05 probability toilet becomingclogged package placed it, thus rendering goal state unreachable.problem definition Figure 1 also shows initial conditions PPDDLprobabilistic. particular example, define two possible initial states equalprobability (0.5) true initial state given execution. Table 1 listsstate variables Bomb Toilet problem values two possible initialstates. Intuitively, think initial conditions PPDDL planning problemeffects action forced scheduled right time 0. Also, notegoal problem involves negation, problem definition declares:negative-preconditions requirements flag.853fiYounes, Littman, Weissman & Asmuth(define (domain bomb-and-toilet)(:requirements :conditional-effects :probabilistic-effects)(:predicates (bomb-in-package ?pkg) (toilet-clogged)(bomb-defused))(:action dunk-package:parameters (?pkg):effect (and (when (bomb-in-package ?pkg)(bomb-defused))(probabilistic 0.05 (toilet-clogged)))))(define (problem bomb-and-toilet)(:domain bomb-and-toilet)(:requirements :negative-preconditions)(:objects package1 package2)(:init (probabilistic 0.5 (bomb-in-package package1)0.5 (bomb-in-package package2)))(:goal (and (bomb-defused) (not (toilet-clogged)))))Figure 1: PPDDL encoding Bomb Toilet example.PPDDL allows arbitrary nesting conditional probabilistic effects (see exampleFigure 2). feature contrast popular encodings, probabilistic STRIPSoperators (PSOs; Kushmerick et al., 1995) factored PSOs (Dearden & Boutilier, 1997),allow conditional effects nested inside probabilistic effects. arbitrarynesting add expressiveness language, allow exponentiallycompact representations certain effects given set state variablesactions (Rintanen, 2003). PPDDL action can, however, translated set PSOspolynomial increase size representation. Consequently, followsresults Littman (1997) PPDDL, grounding (that is, full instantiationaction schemata), representationally equivalent dynamic Bayesian networks (Dean& Kanazawa, 1989), another popular representation MDP planning problems.Still, worth noting single PPDDL action schema represent large numberactions single predicate represent large number state variables, meaningPPDDL often represent planning problems succinctly representations. example, number actions represented using objects naction schemata arity c nc , bounded polynomial sizeoriginal representation (m + n). Grounding means prerequisite PPDDLplanning, planners could conceivably take advantage compact representationworking directly action schemata.2.2 RewardsMarkovian rewards, associated state transitions, encoded using fluents (numericstate variables). PPDDL reserves fluent reward , accessed (reward) reward,represent total accumulated reward since start execution. Rewards associated854fiThe First Probabilistic Track IPC(define (domain coffee-delivery)(:requirements :negative-preconditions:disjunctive-preconditions:conditional-effects :mdp)(:predicates (in-office) (raining) (has-umbrella) (is-wet)(has-coffee) (user-has-coffee))(:action deliver-coffee:effect (and (when (and (in-office) (has-coffee))(probabilistic0.8 (and (user-has-coffee)(not (has-coffee))(increase (reward) 0.8))0.2 (and (probabilistic 0.5 (not (has-coffee)))(when (user-has-coffee)(increase (reward) 0.8)))))(when (and (not (in-office)) (has-coffee))(and (probabilistic 0.8 (not (has-coffee)))(when (user-has-coffee)(increase (reward) 0.8))))(when (and (not (has-coffee)) (user-has-coffee))(increase (reward) 0.8))(when (not (is-wet))(increase (reward) 0.2))))... )Figure 2: Part PPDDL encoding Coffee Delivery domain.state transitions update rules action effects. use reward fluentrestricted action effects form (hadditive-opi hreward fluenti hf-expi),hadditive-opi either increase decrease, hf-expi numeric expression involving reward . Action preconditions effect conditions allowed referreward fluent, means accumulated reward consideredpart state space. initial value reward zero. restrictions usereward fluent allow planner handle domains rewards withoutimplement full support fluents.new requirements flag, :rewards, introduced signal support rewardsrequired. Domains require probabilistic effects rewards declare :mdprequirements flag, implies :probabilistic-effects :rewards.Figure 2 shows part PPDDL encoding coffee delivery domain describedDearden Boutilier (1997). reward 0.8 awarded user coffeedeliver-coffee action executed, reward 0.2 awarded is-wet falseexecution deliver-coffee. Note total reward 1.0 awardedresult executing deliver-coffee action execution action leads stateuser -has-coffee is-wet hold.855fiYounes, Littman, Weissman & Asmuth2.3 Plan ObjectivesRegular PDDL goals used express goal-type performance objectives. goal statement(:goal ) probabilistic planning problem encodes objective probabilityachieving maximized, unless explicit optimization metric specifiedplanning problem. planning problems instantiated domain declaring:rewards requirement, default plan objective maximize expected reward.goal statement specification reward oriented planning problem identifies setabsorbing states. addition transition rewards specified action effects, possibleassociate one-time reward entering goal state. done using (:goal-rewardf ) construct, f numeric expression.general, statement (:metric maximize f ) problem definition meansexpected value f maximized. Reward-oriented problems, example problem instance coffee-delivery domain Figure 2, would declare (:metric maximize(reward)) optimization criterion (this declaration default :rewardsrequirement specified). PPDDL defines goal-achieved special optimizationmetric, used explicitly specify plan objective maximize (orminimize) probability goal achievement. value goal-achieved fluent 1execution ends goal state. expected value goal-achieved therefore equalprobability goal achievement. declaration (:metric maximize (goal-achieved))takes precedence reward specifications domain problem definition,default :rewards requirement specified (for example, BombToilet problem Figure 1).2.4 PPDDL Semanticscompleteness, present formal semantics PPDDL planning problems termsmapping probabilistic transition system rewards. planning problem definesset state variables V , possibly containing Boolean numeric state variables,although consider planning problems without numeric state variablessection. assignment values state variables defines state, state spaceplanning problem set states representing possible assignments valuesvariables. additionV , planning problem defines initial-state distributionPp0 : [0, 1] sS p0 (s) = 1 (that is, p0 probability distribution states),formula G V characterizing set goal states G = {s | |= G }, one-time rewardrG associated entering goal state, set actions instantiated PPDDLaction schemata. goal-directed planning problems, without explicit rewards, userG = 1.2.4.1 Probability Reward Structureaction consists precondition effect ea . Action applicablestate |= G . error apply state6|= G . Goal states absorbing, action may applied state satisfyingG . requirement must hold order applicable consistentsemantics PDDL2.1 (Fox & Long, 2003) permits modeling forced chainsactions. Effects recursively defined follows (see also, Rintanen, 2003):856fiThe First Probabilistic Track IPC1. > null-effect, represented PPDDL (and).2. b b effects b V Boolean state variable.3. r v, v R, effect.4. c e effect c formula V e effect.5. e1 en effect e1 , . . . , en effects.6. p1 e1 | . . . |pn en effect e1 , . . . , en effects, pi 0 {1, . . . , n},Pni=1 pi = 1.effect b sets Boolean state variable b true next state, b sets b falsenext state. Effects form r v used associate rewards transitionsdescribed below.action = ha , ea defines transition probability matrix Pa state rewardvector Ra , Pa (i, j) probability transitioning state j applyingstate i, Ra (i) expected reward executing action state i.readily compute entries reward vector action effect formula ea . Let ccharacteristic function Boolean formula c, is, c (s) 1 |= c 0otherwise. expected reward effect e applied state s, denoted R(e; s),computed using following inductive definition:.R(>; s) = 0.R(b; s) = 0.R(b; s) = 0.R(r v; s) = v.R(c e; s) = c (s) R(e; s)n. XR(e1 en ; s) =R(ei ; s)i=1n. XR(p1 e1 | . . . |pn en ; s) =pi R(ei ; s).i=1factored representation probability matrix Pa obtained generatingdynamic Bayesian network (DBN) representation action effect formula ea .use Bayesian inference DBN obtain monolithic representation Pa ,structure factored representation exploited algorithms decisiontheoretic planning (see, example, work Boutilier, Dearden, & Goldszmidt, 1995;Hoey, St-Aubin, Hu, & Boutilier, 1999; Boutilier, Dean, & Hanks, 1999; Guestrin, Koller,Parr, & Venkataraman, 2003).Bayesian network directed graph. node graph represents statevariable, directed edge one node another represents causal dependence.node associated conditional probability table (CPT). CPT state variableXs node represents probability distribution possible values X conditionedvalues state variables whose nodes parents Xs node. Bayesian network857fiYounes, Littman, Weissman & Asmuthfactored representation joint probability distribution variables representednetwork.DBN Bayesian network specific structure aimed capturing temporaldependence. state variable X, create duplicate state variable X 0 , Xrepresenting situation present time X 0 representing situation one timestep future. directed edge present-time state variable X future-timestate variable 0 encodes temporal dependence. edges two presenttime state variables, future-time present-time state variable (the presentdepend future). can, however, edge two future-time statevariables. edges, called synchronic edges, used represent correlated effects.DBN factored representation joint probability distribution present-timefuture-time state variables, also transition probability matrix discrete-timeMarkov process.show generate DBN representing transition probability matrixPPDDL action. avoid representational blowup, introduce multi-valued auxiliaryvariable probabilistic effect action effect. auxiliary variables introduced indicate possible outcomes probabilistic effect occurs, allowingrepresentation correlate effects specific outcome. auxiliary variableassociated probabilistic effect n outcomes take n different values.PPDDL effect e size |e| consist O(|e|) distinct probabilistic effects. Hence,number auxiliary variables required encode transition probability matrixaction effect e O(|e|). future-time versions auxiliaryvariables necessary. PPDDL problem Boolean state variables, needorder 2m + maxaA |ea | nodes DBNs representing transition probabilitymatrices actions.provide compositional approach generating DBN represents transition probability matrix PPDDL action precondition effect ea . assumeeffect consistent, is, b b occur outcomeoverlapping conditions. DBN empty effect > simply consists 2m nodes,present-time node X connected future-time counterpart X 0 . CPT X 0non-zero entries Pr[X 0 = > | X = >] = 1 Pr[X 0 = | X = ] = 1.holds reward effect r v, change value state variables.Next, consider simple effects b b. Let Xb state variable associatedPPDDL atom b. effects, eliminate edge Xb Xb0 . CPTXb0 entry Pr[Xb0 = >] = 1 effect b Pr[Xb0 = ] = 1 effect b.conditional effects, c e, take DBN e add edges presenttime state variables mentioned formula c future-time state variablesDBN e.1 Entries CPT state variable X 0 correspond settingspresent-time state variables satisfy c remain unchanged. entries set1 X true 0 otherwise (the value X change effect conditionsatisfied).DBN effect conjunction e1 en constructed DBNsn effect conjuncts. value Pr[X 0 = > | X] DBN conjunction set1. transformation increase size DBNs exponentially unless context-specific DBNsused (Boutilier, Friedman, Goldszmidt, & Koller, 1996).858fiThe First Probabilistic Track IPCRRR:HU:IW :UHC:HC:IO:raininghas-umbrellais-wetuser-has-coffeehas-coffeein-officeHUHUIWIWUHCUHCAux1HCHCAux2IOIOAux3Aux 011111111122222222IO>>>>>>>>HC>>>>>>>>UHC>>>>>>>>UHC 0>10101001100110011001100110011001Figure 3: DBN structure (left) deliver-coffee action Coffee Delivery domain, CPT UHC 0 (the future-time version state variableuser -has-coffee) shown right.maximum Pr[X 0 = > | X] DBNs conjuncts. maximum usedstate variable set true (false) conjunctive effect set true(false) one effect conjuncts (effects assumed consistent, resulttaking maximum separate probability tables still probability table).Finally, construct DBN probabilistic effect p1 e1 | . . . |pn en , introduceauxiliary variable 0 used indicate one n outcomes occurred.node 0 parents, entries CPT Pr[Y 0 = i] = pi .Given DBN ei , add synchronic edge 0 state variables X.value Pr[X 0 = > | X, 0 = j] set Pr[X 0 = > | X] j = 0 otherwise.transformation repeated n outcomes, results n DBNs. DBNstrivially combined single DBN probabilistic effectmutually exclusive preconditions (the value Y).example, Figure 3 shows DBN encoding transition probability matrixdeliver-coffee action, whose PPDDL encoding given Figure 2.three auxiliary variables action effect contains three probabilistic effects.node labeled UHC 0 (the future-time version state variable user -has-coffee) fourparents, including one auxiliary variable. Consequently, CPT node24 = 16 rows (shown right Figure 3).2.4.2 Optimality Criteriashown construct MDP PPDDL encoding planning problem.plan objective maximize expected reward MDP. objectiveinterpreted different ways, example expected discounted reward expected total859fiYounes, Littman, Weissman & Asmuthreward. suitable interpretation depends problem. process-oriented planning problems (for example, Coffee Delivery problem), discounted reward typicallydesirable, total reward often interpretation chosen goal-oriented problems(for example, Bomb Toilet problem). PPDDL include facilityenforcing given interpretation specifying discount factor.competition, used expected total reward optimality criterion. Withoutdiscounting, care required design planning problems ensureexpected total reward bounded optimal policy. following restrictionsmade problems used planning competition:1. problem goal statement, identifying set absorbing goal states.2. positive reward associated transitioning goal state.3. negative reward (cost) associated action.4. done action available states, could used end accumulation reward.conditions ensure MDP model planning problem positive boundedmodel (Puterman, 1994). positive reward transitioning goal state.Since goal states absorbing (that is, outgoing transitions), maximumvalue state bounded goal reward. Furthermore, done action ensuresaction available state guarantees non-negative future reward.3. Evaluation Methodologyclassical planning, plan series operators. successful plan one that,applied initial state, achieves goal. probabilistic planning, manyproposals plan representations (straight-line plans, plan trees, policy graphs, triangletables, example), none considered widely accepted standard. addition, evensimple plans challenging evaluate exactly non-deterministic environment,possible outcomes need checked results combined (Littman, Goldsmith, &Mundhenk, 1998).reasons, chose evaluate planners simulation. is, plan validator server, individual planning algorithms acted clients. Planners connectedvalidator, received initial state, returned operator/action. dialogcontinued terminating condition reached point validator evaluatedperformance planner trajectory initial state terminating condition. entire process repeated several times results averaged multipleruns.evaluation scheme blurs distinction planner executor,means computation longer one-time preprocessing cost, something integrated action selection itself. Planner quality, therefore, needs combinationexpected utility running time. simplicity, set time threshold allowedreward gathered time ran out. time threshold known competitors,whose planners could take consideration deciding balance computation860fiThe First Probabilistic Track IPCaction. Since know whether participants would reuse results one trajectory speed planning next, set overall time limit applied totalrepetitions evaluator given domain.Concretely, evaluations, participants presented twenty previously unseen problems PPDDL format. evaluate problem, participants connected oneevaluation servers (at CMU Rutgers). server provided plannerinitial state planner selected returned action. dialogue iteratedgoal reached, time ran out, planner sent done action. valueobtained problem goal reward, goal reached, minus sumaction costs (if any). problem, procedure repeated 30 times maximum15 minutes results averaged.two types problems evaluation set: reward problems goalproblems. goal problems, success percentage determined participants scoreproblem (no action costs). reward problems, every action fixed cost. timescompletion recorded, explicitly used ranking. Planners completedless 30 runs 15 minutes given score 0 unfinished runs.design server, believed time needed computationplanner would far outweigh possible communication delay. However, preliminaryevaluations, participantsespecially halfway across worldexperienced disruptive levels latency evaluating planners connecting remotely server.formal evaluation, offered participants local accounts CMU nearlyavailed option.3.1 Communication Client Servercommunication participants client program server took placeXML. made decision two reasons: first parsing messageseasily managed format trivial parties involvedmany solid XML parsers existpublic domain. second bandwidth great concernas mentionedprevious section, participants ran clients machine hostedserver. true excessively large messages take valuable processingtime, specific case large messages corresponded large state spaces,took somewhat longer process altogether, XML parsing limitingfactor.client connected server, would request certain problem run.server would lead client running problem 30 times, sending stateproblem, receiving clients action, creating new state oldstate action, sending back again. Figure 4 gives schematic illustrationconversation client server. specific format XML elementdescribed Appendix B.Prior competition, example client written C++ distributedparticipants minimize difficulties dealing nuts bolts protocol,allowing instead focus design algorithms.861fiYounes, Littman, Weissman & Asmuthclient: hsession-requestiserver: hsession-initiloop 30 roundsclient: hround-requestiserver: hround-initiloop termination conditionsserver: hstateiclient: hacti | hnoopi | hdoneiserver: hend-roundserver: hend-sessioniFigure 4: interaction client (planners) server (environment) evaluation system.3.2 Generator-Based DomainsSeveral example domains provided participants advance serve testbedsparser planner development. addition, parameterized problem generatorsprovided two domain classesBlocksworld Boxworld, described detailSection 4. availability domains served allow participants learn, either manually automatically, domains create domain-specific solutions.approaches evaluated independently separate category.4. Competition Domainssection describes domains used competition. Machine readable versionsdomains found online competition Web site:http://www.cs.rutgers.edu/mlittman/topics/ipc04-pt/4.1 Blocksworld (Traditional)traditional Blocksworld domain stray far original Blocksworld domain. domain consists two types objects, blocks tables. domainexactly one table problem instance number blocks (the numberblocks problem specific). actions domain pick-up-block-from putdown-block-on. problem instance, initial configuration goal configurationblocks given. goal problem move blocks initial configuration goal configuration. domain comes two flavors: goal versionreward version. Within reward version, cost one unit every time actionpick-up-block-from executed, reward 500 reaching goal configuration.domains used competition, Blocksworld domainincorporates probabilistic effects adding slip probability. is,time block picked put down, block slip fall onto table862fiThe First Probabilistic Track IPCprobability 0.25. (Of course, intended action put block onto table,effect always achieved.) Blocksworld domain extremely simpledomain, yet offers lot insight planning process. Two important featuresdomain are:1. basic policy solve domain is:(a) initial configuration, place blocks onto table blocktop another block.(b) Starting bottom up, place block place final configuration.Note without noise, n blocks, policy takes 4n steps (2 stepsblock Part 1a, 2 steps block Part 1b) hence costs 2nunits. So, basic, inexpensive way solve domain.2. state space domain increases exponentially number blocks.Thus, domain aims testing planners could find easy (maybe slightlyexpensive) policy state space large find good policy. farcomplexity domain concerned, one easier domains planhope many planners would quite well domain.generation program random traditional Blocksworld domains providedparticipants competition problems generated program.availability generator allowed participants test planners many problemsliked advance evaluation.4.2 Blocksworld (Color)colored Blocksworld domain variant traditional Blocksworld presented above.traditional Blocksworld, colored Blocksworld consists two types objects,tables blocks. Again, domain exactly one table problem instancenumber blocks. actions domain still pick-up-block-fromput-down-block-on, domain also comes two flavors: goal reward.major difference traditional Blocksworld domain block coloredBlocksworld domain assigned color, goal configuration specified termsblock colors rather specific blocks. Thus, general, many different valid goalconfigurations. Goal conditions expressed existential quantification. example,PPDDL fragment(:goal (and (exists (?b1) (is-green ?b1))(exists (?b2) (and (is-blue ?b2) (on-top-of ?b1 ?b2)))))states goal green block top blue block.noise colored Blocksworld domain traditional Blocksworld domain. is, colored Blocksworld domain incorporates probabilistic effectsadding slip probability. time block picked put down, blockslip fall onto table probability 0.25.863fiYounes, Littman, Weissman & AsmuthNotice although goal configuration existentially quantified hence precisely specified, basic policy used solve traditional Blocksworldused solve colored Blocksworld. solve colored Blocksworld problem,unstack blocks then, bottom fashion, choose block satisfiescolor constraint place appropriate position.colored Blocksworld domain aims add complexity traditional Blocksworld domain incorporating existential quantification goal configuration.indeterminacy goal colored Blocksworld domain make planning problemconsiderably harder traditional counterpart. Thus, colored Blocksworld problemmay impossible given planner solve reasonable amount time, whereasplanner would problem traditional Blocksworld problemsize.2generation program random colored Blocksworld domains provided participants competition problems generated program.4.3 BoxworldBoxworld domain modeled traditional logistics domain. domain consistsfour types objects: cities, boxes, trucks planes. problem, graphsuperimposed cities two different types edges, one denoting abilitydrive one city another denoting ability fly one cityother. actions domain load-box-on-truck-in-city, unload-boxfrom-truck-in-city, load-box-on-plane-in-city, unload-box-from-plane-in-city, drivetruck fly-plane. goal reward versions domain includedevaluation. Within reward version, cost 1 unit every time eitherload-box-on-truck-in-city load-box-on-plane-in-city executed, cost 5 unitsevery time drive-truck executed cost 25 units every time fly-planeexecuted. problem instance, initial configuration determines graphsuperimposed cities, identifies locations boxes, trucks planesdetermines final destination box arrive. goal configurationspecifies destination every box. goal problem move initialconfiguration state box destined location.Noise enters domain action drive-truck. action executed,desired effect achieved probability 0.8 (that is, probability 0.8 truckend expected destination). However, probability 0.2, truck get lostend wrong destination. city, three cities truckmay get lost trying execute drive-truck action. truck actually getslost end cities equal probability (that is, probability1/3).Blocksworld domains, generation program random Boxworld domainsprovided participants competition problems generatedprogram.2. important note existentially quantified goal formula colored Blocksworld,grounded, excessively long. fact serious bottleneck larger instances domain.Planners avoid grounding benefit here, competitionplan validator grounded goal formula.864fiThe First Probabilistic Track IPC4.4 Exploding Blocksworldexploding Blocksworld domain dead-end version traditional Blocksworlddomain described earlier. traditional Blocksworld domain, two typesobjects (tables blocks) two actions (pick-up-block-from put-down-blockon). initial configuration goal configuration blocks given goaldomain move blocks initial configuration goal configuration.key difference domain traditional Blocksworld domainevery block exploding Blocksworld domain initially set detonate. Every timeput-down-block action executed, block put yetdetonated detonate probability 0.3; noise domain.block detonates executing put-down-block action, object beneath block(whether table another block) destroyed longer accessible withindomain. block detonates, safe longer detonate.exploding Blocksworld domain aims testing planners ability think ahead.formally, actions executed possible reach state goalcannot reached. Consider, example, executing standard Blocksworld approachblocks unstacked table goal configuration constructed.seven blocks unstacked, 92% (1 (1 0.3)7 ) probabilitytable destroyed, rendering problem unsolvable.One strategy solving exploding Blocksworld problem never place unsafeblock top something valuable (the table block needed final stack). Instead,block first disarmed, placing top block neededfinal configuration, block exists.illustrate strategy problem instance used planning competition, shown Figure 5. Four blocks needed goal configuration: 4, 8, 9,10. start repeatedly picking Block 0 placing Block 9 Block 0detonates. Next, detonate Block 1 way using Block 10. Block 0Block 1 safe, place Block 1 table Block 0 top Block 1. completes left-most tower. stage, safe moves Blocks 4 8clear. pick Block 6 put Block 2. last action leads failureprobability 0.3. successful, right-most tower completed. Block 8 clearuse detonate Block 3. Block 3 safely placed top Block 5. Finally,center tower completed placing Block 7 top Block 3, result failureprobability 0.3. total, success probability given plan (1 0.3)2 = 0.49,which, fact, optimal given problem (there action costs).Along several test domains, exploding Blocksworld specifically designedreplanning strategy performs suboptimally (gets stuck high probability).replanning strategy would ignore 0.3 probability detonation try replansomething unexpected happens. However, high probability approachrender goal state unreachable.4.5 FileworldFileworld fairly basic domain. consists k files n folders filesfiled into. actions domain get-type (reports folder given file865fiYounes, Littman, Weissman & Asmuthinitial state0137245689goal100173562Figure 5: Exploding Blocksworld problem used planning competition. Notegoal condition require Block 2 table.belongs in), get-folder-Fi (one {0, . . . , n 1}, retrieves Folder filingcabinet), file-Fi (one {0, . . . , n 1}, inserts given file Folder i)return-Fi (one 0, . . . , n 1}, returns Folder filing cabinet).domain comes reward version. cost 100 executing actionget-folder-Fi cost 1 executing action file-Fi. actionsexplicit costs since must used conjunction get-folder-Fi file-Fi.initial configuration problem specifies many folders (the competitionproblem used 30 files 5 folders) goal configuration specifies filesmust filed. Note initial configuration specify folder file gointo, files cannot filed folder; constraint noise comesdomain.file filed, destination folder must determined. destinationfolder file obtained executing action get-type file questionparameter. action executed, file passed parameter assigned folder,folder files destination equal probability (that is, probability 1/n).file destination folder, filed (and this) folder.Fileworld domain tests planners ability consider strategies chooseone minimizes cost. particular, straightforward plan achieve goalcarry following series actions file turn:1. Get type get-type2. Get destination folder executing get-folder-Fi3. Place file appropriate folder executing file-Fi action4. Return folder executing return-Fi actionAlthough plan works, costly. cost would 101k k numberfiles, get-folder-Fi (expensive) file-Fi (cheap) executed every file.less costly (in fact, optimal) plan described. first executes get-type everyfile. Then, folder {0, . . . , n 1} least one file destination,runs get-folder-Fi. Next, files every file belongs folder using file-Fi.uses return-Fi preparation getting next folder.866fiThe First Probabilistic Track IPCexpected reward optimal plan 600 (100n + k), n numberfolders k number files (this analysis gives 70 optimal expected rewardcompetition problem). domain designed reward planners ablereason initial destination uncertainty files recognize secondplan much less costly preferred straightforward brute-force plan.4.6 TireworldTireworld another domain tests planners ability plan ahead uncertainty.domain consists one type object, namely locations. domain comes twoflavors, goal version reward version. actions common versionsmove-car, load-tire change-tire. reward version, additionalaction call-AAA.Within reward version, cost 1 every time one actions move-car,load-tire change-tire executed cost 100 every time action callAAA executed. initial configuration problem defines set locations,superimposed graph locations (roads), subset locations representinglocations spare tires, starting location graph. goal configurationdefines destination location graph. goal problem movestarting location goal location.noise Tireworld comes action move-car. time actionexecuted, car drives one city another get flat tire probability0.15. car flat tire, cannot execute action move-cartire fixed. car ability store one spare tire, pickexecuting action load-tire location spare tire. carholding spare tire, change-tire action invoked fix flat. However,car currently spare action disabled. goal version,flat tire may result dead end car gets flat carries spare tire.reward version, planner choice executing one actions change-tire (ifcar spare) call-AAA (at high cost) repair flat. Thus, rewardversion, dead ends goal always reachable. Notice since costcall-AAA large compared costs change-tire load-tire, fixing flatalways less expensive car spare tire.Figure 6 illustrates Tireworld problem used competition. next compareprobability reaching goal state two different plans problem illustrateideal plan looks like domain.optimal plan would look ahead attempt keep spare tires accessiblepossible avoid dead ends. start state, car must make three steps withoutflat tire reach first spare cc, occur probability 0.853 0.61. Now,car needs go four steps without getting two flats make next spare d5.gets zero flats probability 0.854 0.52 one flat probability 4 0.853 0.150.37, four-step segment traversed probability 0.52 + 0.37 = 0.89 onespare tire. three four-step segments must traversed successfully reachck. Finally, spare, last two steps traveled certainty. Thus, totalsuccess probability event sequence 0.61 0.893 0.43. Note estimate867fiYounes, Littman, Weissman & Asmuthspare tire(all boxed locations)startgoald6d5cac1cncdccc0cmcbc2cecfcgchcic6c3c4cjckc7 c8c5clc9d4d0d1d2d3Figure 6: Tireworld domain used competition.lower bound success probability optimal strategy, factorprobability getting flat tire upon arrival state spare tire. Furthermore,car location cf ch spare flat, unnecessary traverseloop pick spare tire location d5 cm. accounting factors getsuccess probability 0.57.contrast, greedy replanning algorithm would gather spares, since utilitycomes realization something might go wrong. planner, bestplan go directly c0 c9 shortest (9-step) route. success probability0.859 0.23, 40 percent best success probability computed above.reward version planning problem, optimal success probability onecall-AAA action always available. However, cost action equalsreward reaching goal, always better end execution doneaction repair flat tire call-AAA action. Hence, best strategygoal version optimal reward version well gives reward45. greedy strategy outlined would result expected reward 22.call-AAA action used fix flat tires, expected reward drops 29.4.7 Towers Hanoisename suggests, domain noisy version famous Towers Hanoiproblem. domain two types objects, disks pegs. problemused competition five disks three pegs. actions domainsingle-move-big-not-moved, single-move-big-moved, double-move-big-not-moveddouble-move-big-moved. action names suggest, one move either one two868fiThe First Probabilistic Track IPCdisks time (single-move/double-move) outcome move dependentwhether biggest disk moved yet (big-not-moved/big-moved). objective domain maximize probability reaching goal configuration (norewards).initial configuration defines starting positions disks (as TowersHanoi, five disks stacked first peg bottom top, largest smallestorder). goal configuration defines destination positions disks (again,destination positions Towers Hanoi, namely five disksstacked order initial configuration last peg). goalproblem move disks starting configuration goal configuration.actions Towers Hanoise noisy outcomes. particular, executing actionpossible drop disk lost forever, thus bringing execution deadend. success probabilities are:Actionsingle-move-big-not-movedsingle-move-big-moveddouble-move-big-not-moveddouble-move-big-movedSuccess Probability0.990.950.800.90Notice probability succeeding move dependent number disksmoved whether big disk moved yet.Every sequence actions success probability less one problem,possible reach goal certainty. maximize probability reachinggoal, careful comparison must made. move big disk first lastpeg, necessary move four smaller disks middle peg. subgoalachieved executing single-move-big-not-moved fifteen times smaller disks,resulting success probability 0.9915 0.86. also accomplished movingfour smaller disks two units two using double-move-big-not-moved three times,resulting low success probability approximately 0.51.Next, big disk moved first last peg success probability0.99 (single-move-big-not-moved). Then, four smaller disks need moved,time middle peg last peg. big disk moved,success probabilities change two strategies yield success probabilities 0.46single-move-big-moved 0.73 double-move-big-moved.planner chooses optimally step would switch single moves doublemoves big disk place resulting total success probability 0.99150.99 0.93 0.62. One ignores probabilities always uses single moves lowersuccess probability 0.9915 0.99 0.9515 0.39. planner ignores probabilitiesminimizes number steps always using double moves lower success probabilitystill 0.83 0.990.93 0.37. Thus, optimum performance, planner must realizepolicy consider success probabilities actions influencedstatus big disk.869fiYounes, Littman, Weissman & Asmuth4.8 Zeno Travellast domain Zeno Travel, based domain used IPC-3. Problem instancesdomain involve using airplanes move people cities. airplane requires fuel fly. flown two different speedsthe higher speed requiringfuel. problem instance used one aircraft, two people, three cities sevenfuel levels. actions domain start-boarding, complete-boarding, startdebarking, complete-debarking, start-refueling, complete-refueling, start-flying,complete-flying, start-zooming, complete-zooming. initial configurationspecifies location plane, initial fuel level plane locationpeople (as well initializations allow arithmetic type operationsfuel-level objects). goal configuration specifies destination plane destinations people. noise domain comes family complete-Xactions. time complete-X action executed desired effectprobability 1/k positive integer k (note k function action executed, specifically k = 20 complete-boarding k = 30 complete-debarking).desired effect achieved effect, occurs probability1 (1/k). structure meant represent actions random duration. durative action X represented two primitive actions start-X complete-X, givingX duration geometrically distributed.Ultimately, problem presented real challenge neglected includeaction costs. Since actions either standard desired effect none all, plannersimple continue execute action effect achieved, without incurring cost.5. Competition ResultsBased initial announcement competition, put together mailing list87 researchers expressing interest. development PPDDL, server, evaluationcriteria, practice domains progressed, kept community informed releasingseries FAQs (May 2003, FAQ 0.1; September 2003, FAQ 0.5; November 2003 FAQ 1.01).early 2004, core group participants became evident competition logisticsfinalized. Leading June 2004, participants ran planners previouslyunseen test problems. tabulated scores set evaluation categoriespresented ICAPS04 Vancouver, Canada.following subsections describe competitions participants, evaluation tracks,results.5.1 ParticipantsAlthough twenty teams registered competition initially, seven teams four continents ultimately competed. produced ten different planners, evaluatedvarious subsets problem domains. groups planners were:Group C. UMassParticipants: Zhengzhu Feng (University Massachusetts) Eric Hansen (Mississippi State University).870fiThe First Probabilistic Track IPCDescription: Symbolic heuristic search.Group E. Dresden (FluCaP, formerly FCPlanner)Participants: Eldar Karabaev Olga Skvortsova (both Dresden UniversityTechnology).Description: First-order heuristic search.Group G. ANU (NMRDPP)Participants: Charles Gretton, David Price Sylvie Thiebaux (all AustralianNational University).Descriptions: G1: Planner primarily designed domains non-Markovian rewards, G2: NMRDPP augmented control knowledge.Group J. PurdueParticipants: SungWook Yoon, Alan Fern Robert Givan (all Purdue University).Descriptions: J1: Human-written policy Classys policy language (Purdue-Humans), J2: Offline policy iteration reduction classification, automatically acquiring domain-specific policy (Classy), J3: Deterministic replanner usingFF (FF-rePlan).Group P. Simon Bolvar (mGPT)Participants: Blai Bonet (Universidad Simon Bolvar) Hector Geffner (UniversitatPompeu Fabra).Description: Labeled RTDP lower bounds extracted problem description.Group Q. Michigan Tech (Probapop)Participants: Nilufer Onder, Garrett C. Whelan Li Li (all Michigan Technological University).Description: POP-style planner (no sensing).Group R. CERTParticipants: Florent Teichteil-Konigsbuch Patrick Fabiani (both CERT).Description: Probabilistic reachability heuristic DBNs.5.2 Evaluation Tracksclear discussions leading competition different groupsprioritizing efforts differently. wanted ensure diverse set powerfulapproaches recognized decided tabulate results several different waysacknowledge value different approaches. six tracks were:871fiYounes, Littman, Weissman & AsmuthOverall. track used reward-based evaluation criterion domains (goalachievement counted 500 goal-based domains). Domains: Blocksworld (7 problems), Colored Blocksworld (2), Boxworld (5), Exploding Blocksworld (1), Fileworld(1), Tireworld (2), Towers Hanoise (1), Zeno Travel (1).Goal-based. track, ignored action costs counted goal achievementunit reward (thus emphasizing approaches maximized probabilityreaching goal state). domains problems usedOverall track: Blocksworld (7), Colored Blocksworld (2), Boxworld (5), ExplodingBlocksworld (1), Fileworld (1), Tireworld (2), Towers Hanoise (1), Zeno Travel (1).Overall, Non-Blocks/Box. Blocksworld Boxworld dominated full setwanted see subtler problems handled. Domains: ExplodingBlocksworld (1), Fileworld (1), Tireworld (2), Towers Hanoise (1), Zeno Travel (1).Domain-specific. Domain-specific allowed human-tuned rules; Domain-specific,Tuning (only automatically generated rules specific domainallowed). evaluated using generated domains: Blocksworld (8), ColoredBlocksworld (6), Boxworld (5).Conformant. Planners category produce straight-line plans, blindintermediate states encountered. prepared unobservable versions domainsevaluate planners category. Domains: Blocksworld (7), Colored Blocksworld(2), Boxworld (5), Exploding Blocksworld (1), Fileworld (1), Tireworld (2), TowersHanoise (1), Zeno Travel (1).5.3 Resultsdisplay results evaluation track, plotted cumulative reward achievedparticipant set evaluation problems (reward accumulated left right).reward-based tracks, goal achievement counted 500 problems withoutexplicitly specified goal reward. plots highlight one planner advantageanother (greater slope) well total difference score (height differencelines).Figure 7 displays results Overall category. Two planners, J3 P, producedsignificantly positive results others, replanning algorithm J3 clearlydominating others. J3 crowned Overall winner, P runner up. figurealso displays results Conformant category, consisted solely Q,uncontested winner category.Similar results visible Goal-based track, displayed Figure 8, J3comes ahead P achieving runner-up status. Comparing Figures 7 8reveals margin victory J3 P, R G1 diminished Goalbased category. suggests J3 sensitive rewards themselveschoosingcheaper paths among multiple paths available goal. set problems usedcompetition, distinction significant graphs look similar.However, different set test problems might revealed fundamental tradeoff872fi873Zeno TravelTower HanoiseTireworld (reward)Tireworld (goal)FileworldExploding BlocksworldBoxworld (10, 10; goal)Boxworld (5, 10; goal)Boxworld (15, 10)Boxworld (10, 10)Boxworld (5, 10)Colored Blocksworld (8; goal)Colored Blocksworld (8)Blocksworld (8; goal)Blocksworld (21)Blocksworld (18)Blocksworld (15)5000Blocksworld (11)Blocksworld (8)Blocksworld (5)cumulative rewardFirst Probabilistic Track IPCJ3PCG1RQ40003000200010000Figure 7: Competition results Overall category. result Conformant category line marked Q. numbers parentheses indicate problem size:number blocks Blocksworld domains; number cities boxes, respectively, Boxworld domains.fiYounes, Littman, Weissman & AsmuthJ3PCG1RQ14cumulative goal probability12108642Zeno TravelTower HanoiseTireworld (reward)Tireworld (goal)FileworldExploding BlocksworldBoxworld (10, 10; goal)Boxworld (5, 10; goal)Boxworld (15, 10)Boxworld (10, 10)Boxworld (5, 10)Colored Blocksworld (8; goal)Colored Blocksworld (8)Blocksworld (8; goal)Blocksworld (21)Blocksworld (18)Blocksworld (15)Blocksworld (11)Blocksworld (8)Blocksworld (5)0Figure 8: Competition results Goal-based category.seeking maximize reward seeking reach goal high probability.Future competitions could attempt highlight important issue.interesting note J3s outstanding performance stems primarilyearly problems, Blocksworld Boxworld problems amenablereplanning. later problems set handled well J3planners.Figure 9 displays results Non-Block/Box category. Indeed, J3 performedmuch poorly problems category, Planner C taking top spot.runner-up spot closely contested planners R G1, G1 pulled aheadlast problem claim honors. Planner P also performed nearly wellset.Figure 10 gives detailed view results Non-Blocks/Box category.optimal score problem indicated graphs.3 Note Planner Csperformance Tireworld domain well optimal, result now-fixed bugcompetition server allowed disabled actions executed. Planner P displayedoutstanding performance Fileworld goal-based Tireworld problems,attempt solve Tower Hanoise therefore fell behind G1 R overall. Planner Rused time per round Planner G1 Zeno Travel domain, ultimatelycost R second place could complete 27 30 runs domain.Note planners received negative score reward-oriented problems.3. optimal scores necessarily apply Planner Q, conformant planner.874fiThe First Probabilistic Track IPCCG1RPJ3Q1000cumulative reward800600400200Zeno TravelTower HanoiseTireworld (reward)Tireworld (goal)FileworldExploding Blocksworld0Figure 9: Summary competition results Overall, Non-Blocks/Box category.counted negative scores individual problems zero overall evaluationgive advantage planners even attempt solve problems. Planner Qentrant (except, possibly, C) receive positive score reward-basedTireworld problem. planners negative score problem used expensivecall-AAA action ensure goal always reached.results domain-specific planners shown Figure 11. highest scoringplanners J1 G2, difference primarily due two largestBlocksworld problems, J1 solved effectively G2. performancefive domain-specific planners colored Blocksworld problems virtually indistinguishable. mentioned earlier, grounding goal condition validator prevented ususing larger problem instances, might otherwise separated plannersdomain.two planners domain specific category ineligibletuning subcategory hand-tuned domains. Thus, J3 J2took top spots subcategory. interesting note J3 spitegeneral-purpose plannerit not, fact, created domain specific. overtookJ2 due two small Boxworld problems J3 solved J2 missed.Figure 12 summarizes competition results six evaluation categories.6. Conclusionhappy outcomes first probabilistic track International PlanningCompetition. addition bringing attention important set planning challenges,875fiYounes, Littman, Weissman & AsmuthExploding BlocksworldTireworld (goal)11**max prob.0.8goal probability0.60.40.200.80.60.40.2*CG1*PJ3*Q*R0C1100***0-100prob.max prob.rewardmax rewardG1J3QRPQprob.max prob.rewardmax reward0.8200CP**300goal probability10.80.60.40.20J3Tireworld (reward)rewardgoal probabilityFileworldG10.680600.4400.2200-200rewardgoal probabilitymax prob.0-300-20-400RCG1Tower HanoiseJ3PQRZeno Travelmax prob.110.8goal probabilitygoal probabilitymax prob.0.60.40.200.80.60.40.2*CG1J3*P*Q0RCG1J3PQRFigure 10: Competition results Non-Blocks/Box problems (* indicates plannerattempt solve problem; ** indicates anomalous results due bugserver allowed execution disabled actions). Note twographs center reward scales right.876fiThe First Probabilistic Track IPCJ1*G2*J3J2E*80007000cumulative reward600050004000300020001000Boxworld (10, 10; goal)Boxworld (5, 10; goal)Boxworld (15, 10)Boxworld (10, 10)Boxworld (5, 10)Colored Blocksworld (11; goal)Colored Blocksworld (8; goal)Colored Blocksworld (5; goal)Colored Blocksworld (11)Colored Blocksworld (8)Colored Blocksworld (5)Blocksworld (8; goal)Blocksworld (21)Blocksworld (18)Blocksworld (15)Blocksworld (11)Blocksworld (8)Blocksworld (5)0Figure 11: Competition results Domain-specific categories. Tuningcategory results, ignore J1, G2, E lines graph (markedasterisks).CategoryOverallGoal-based DomainsOverall, Non-Blocks/BoxDomain-specific, TuningDomain-specificConformant1stJ3J3CJ3J1Q2ndPPG1J2G2Figure 12: Summary competition results category.877fiYounes, Littman, Weissman & Asmuthappears helped spur community use uniform comparison problemsproviding domain language set benchmarks (Yoon, Fern, & Givan, 2005).spite success, feel changes could made future competitions would increase value community. First, competition logisticsside, server logged outcomes interactions planners domains,keep exhaustive record actions taken timing information. retrospect,information would helpful identifying planners addresseddomains whether took suboptimal actions got unlucky. addition,server provisions security. simple password and/or reservation system wouldhelped evaluations go much smoothly would prevented inadvertentaccess server one group another assigned evaluation slot.domain side, hope future competitions able focus interestingdomains. found simply adding noisy action failures deterministic domainenough produce interesting probabilistic problemsfor domains, straightforward replanning effective. non-Blocksworld domains createdmastered planners hope retained form futureevaluations.Like progression competitions classical track, hope future competitionsprobabilistic track move toward domains grounded real-life data real-worldproblems including handling partially observability time. second competitionslated held conjunction IPC 2006 urge interested membersplanning community participate help keep competition moving productivedirection benefit field.Acknowledgmentsappreciate support National Science Foundation Royal SwedishAcademy Engineering Sciences, well feedback Sven Koenig, Shlomo Zilberstein, Paul Batchis, Bob Givan, Hector Geffner participants contributeddesign competition. JAIR editor David Smith anonymous reviewers provided invaluable insights document tried reflect final manuscript.material based upon work supported National Science FoundationGrant No. 0315909 Royal Swedish Academy Engineering Sciences (IVA)grants Hans Werthen fund. opinions, findings, conclusions recommendations expressed material author(s) necessarily reflectviews National Science Foundation IVA.878fiThe First Probabilistic Track IPCAppendix A. BNF Grammar PPDDL1.0provide full syntax PPDDL1.0 using extended BNF notation following conventions:rule form hnon-terminal ::= expansion.Alternative expansions separated vertical bar (|).syntactic element surrounded square brackets ([ ]) optional.Expansions optional syntactic elements superscripted requirements flagavailable requirements flag specified domain problem currentlydefined. example, [htypes-def i]:typing syntax domain definitionsmeans htypes-def may occur domain definitions include :typingflag requirements declaration.asterisk (*) following syntactic element x means zero occurrencesx ; plus (+ ) following x means least one occurrence x.Parameterized non-terminals, example htyped list (x )i, represent separate rulesinstantiation parameter.Terminals written using typewriter font.syntax Lisp-like. particular, case significant (for example, ?x ?Xequivalent), parenthesis essential part syntax semanticmeaning extended BNF notation, number whitespace characters(space, newline, tab, etc.) may occur tokens.A.1 Domainssyntax domain definitions PDDL2.1, except durative actionsallowed. Declarations constants, predicates, functions allowedorder respect one another, must come type declarationsprecede action declarations.hdomainihrequire-defhrequire-keyihtypes-defhconstants-defhpredicates-def::= ( define ( domain hnamei )[hrequire-def i][htypes-def i]:typing[hconstants-def i][hpredicates-def i][hfunctions-def i]:fluentshstructure-def i* )::= ( :requirements hrequire-keyi* )::= See Section A.4::= ( :types htyped list (name)i )::= ( :constants htyped list (name)i )::= ( :predicates hatomic formula skeletoni* )879fiYounes, Littman, Weissman & Asmuthhatomic formula skeletonihpredicateihfunctions-defhfunction skeletonihfunction symbolhstructure-defhaction-defhtyped list (x )ihtypeihprimitive typeihfunction typed list (x )ihfunction typei::= ( hpredicatei htyped list (variable)i )::= hnamei::= ( :functions hfunction typed list (function skeleton)i )::= ( hfunction symbol htyped list (variable)i )::= hnamei::= haction-def::= See Section A.2::= hx i* |:typing hx i+ - htypei htyped list (x )i::= ( either hprimitive typei+ ) | hprimitive typei::= hnamei::= hx i*|:typing hx i+ - hfunction typei hfunction typed list (x )i::= numberhnamei string characters starting alphabetic character followedpossibly empty sequence alphanumeric characters, hyphens (-), underscore characters ( ). hvariablei hnamei immediately preceded question mark (?).example, in-office ball 2 names, ?gripper variable.A.2 ActionsAction definitions goal descriptions syntax PDDL2.1.haction-def::= ( :action haction symbol[:parameters ( htyped list (variable)i )]haction-def bodyi )haction symbol::= hnameihaction-def bodyi::= [:precondition hGDi][:effect heffecti]hGDi::= hatomic formula (term)i | ( hGDi* )|:equality ( = htermi htermi )|:equality ( ( = htermi htermi ) )|:negative-preconditions ( hatomic formula (term)i )|:disjunctive-preconditions ( hGDi )|:disjunctive-preconditions ( hGDi* )|:disjunctive-preconditions ( imply hGDi hGDi )|:existential-preconditions ( exists ( htyped list (variable)i )hGDi )|:universal-preconditions ( forall ( htyped list (variable)i )hGDi )|:fluents hf-compihatomic formula (x )i ::= ( hpredicatei hx i* ) | hpredicateihtermi::= hnamei | hvariableihf-compi::= ( hbinary-compi hf-expi hf-expi )hbinary-compi::= < | <= | = | >= | >hf-expi::= hnumber | hf-head (term)i880fiThe First Probabilistic Track IPChf-head (x )ihbinary-opi| ( hbinary-opi hf-expi hf-expi ) | ( - hf-expi )::= ( hfunction symbol hx i* ) | hfunction symbol::= + | - | * | /hnumber sequence numeric characters, possibly single decimal point (.)position sequence. Negative numbers written (- hnumber i).syntax effects extended allow probabilistic effects,arbitrarily interleaved conditional effects universal quantification.heffecti::= hp-effecti | ( heffecti* )|:conditional-effects ( forall ( htyped list (variable)i ) heffecti )|:conditional-effects ( hGDi heffecti )|:probabilistic-effects ( probabilistic hprob-effecti+ )hp-effecti::= hatomic formula (term)i | ( hatomic formula (term)i )|:fluents ( hassign-opi hf-head (term)i hf-expi )|:rewards ( hadditive-opi hreward fluenti hf-expi )hprob-effecti::= hprobabilityi heffectihassign-opi::= assign | scale-up | scale-down | hadditive-opihadditive-opi ::= increase | decreasehreward fluenti ::= ( reward ) | rewardhprobabilityi hnumber value interval [0, 1].A.3 Problemssyntax problem definitions extended allow specificationprobability distribution initial states, also permit association one-timereward entering goal state. otherwise identical syntax PDDL2.1problem definitions.hproblemihobjects-defhinitihinit-elhp-init-elhprob-init-elha-init-elhgoalhgoal-specihmetric-speci::= ( define ( problem hnamei )( :domain hnamei )[hrequire-def i][hobjects-def i][hiniti]hgoal )::= ( :objects htyped list (name)i )::= ( :init hinit-el i* )::= hp-init-el|:probabilistic-effects ( probabilistic hprob-init-el i* )::= hatomic formula (name)i |:fluents ( = hf-head (name)i hnumber )::= hprobabilityi ha-init-el::= hp-init-el | ( hp-init-el i* )::= hgoal-speci [hmetric-speci] | hmetric-speci::= ( :goal hGDi ) [( :goal-reward hground-f-expi )]:rewards::= ( :metric hoptimizationi hground-f-expi )881fiYounes, Littman, Weissman & Asmuthhoptimizationi ::= minimize | maximizehground-f-expi ::= hnumber | hf-head (name)i| ( hbinary-opi hground-f-expi hground-f-expi )| ( - hground-f-expi )| ( total-time ) | total-time| ( goal-achieved ) | goal-achieved|:rewards hreward fluentiA.4 Requirementstable requirements PPDDL1.0. requirements imply others;abbreviations common sets requirements. domain stipulates requirements,assumed declare requirement :strips.Requirement:strips:typing:equality:negative-preconditions:disjunctive-preconditions:existential-preconditions:universal-preconditions:quantified-preconditions:conditional-effects:probabilistic-effects:rewards:fluents:adl:mdpDescriptionBasic STRIPS-style adds deletesAllow type names declarations variablesSupport = built-in predicateAllow negated atoms goal descriptionsAllow disjunctive goal descriptionsAllow exists goal descriptionsAllow forall goal descriptions= :existential-preconditions+ :universal-preconditionsAllow forall action effectsAllow probabilistic action effectsAllow reward fluent action effectsoptimization metricAllow numeric state variables= :strips + :typing + :equality+ :negative-preconditions+ :disjunctive-preconditions+ :quantified-preconditions+ :conditional-effects= :probabilistic-effects + :rewards882fiThe First Probabilistic Track IPCCLIENTSERVER/ session-request \\// session-init \\// round-request \\// round-init \\// state \\// action\spec \/.../ state \\// action\spec \// end-round \\/repeat/ end-session \\/Figure 13: Successful communication session.Appendix B. Communication Protocoladopt XML-like syntax client/server communication protocol. useextended BNF notation Appendix describe syntax protocol messages.hnamei hnumber terminals defined exactly way PPDDL.hinteger nonempty string numeric characters. hmessagei arbitrary characterstring, possibly empty.Figure 13 shows expected sequence messages. session starts clientsending hsession-requesti message server. server replies hsession-initimessage, tells client number evaluation rounds run. startevaluation round, client sends hround-requesti message, server replieshround-initi message. point evaluation round starts. server sendshturn-responsei message client, hstatei message hend-roundmessage. every hstatei message client receives, sends haction speci messagereturn. client receives hend-round message, ends current evaluationround. client starts new evaluation round hround-requesti messageserver, waits hend-sessioni message server case roundsalready run. server sends herror message client error occurs,example server receives unexpected message client.883fiYounes, Littman, Weissman & AsmuthB.1 Client MessagesClient messages following form:hsession-requesti ::= <session-request><name> hnamei </name><problem> hnamei </problem></session-request>hround-requesti::= <round-request/>haction specihactionihtermi::= <act> hactioni </act> | <done/>::= <action> <name> hnamei </name> htermi* </action>::= <term> hnamei </term>B.2 Server MessagesServer messages following form:hsession-initi::= <session-init><sessionID> hinteger </sessionID><setting><rounds> hinteger </rounds><allowed-time> hinteger </allowed-time><allowed-turns> hinteger </allowed-turns></setting></session-init>hround-initi::= <round-init><round> hinteger </round><sessionID> hinteger </sessionID><time-left> hinteger </time-left><rounds-left> hinteger </rounds-left></round-init>hturn-responsei ::= hstatei | hend-roundhend-round::= <end-round>hstatei [<goal-reached/>]<time-spent> hinteger </time-spent><turns-used> hinteger </turns-used></end-round>hstatei::= <state> [<is-goal/>] hatomi* hfluenti* </state>hatomi::= <atom> hpredicatei htermi* </atom>hfluenti::= <fluent> hfunctioni htermi* hvaluei </fluent>hpredicatei::= <predicate> hnamei </predicate>hfunctioni::= <function> hnamei </function>htermi::= <term> hnamei </term>884fiThe First Probabilistic Track IPChvaluei::= <value> hnumber </value>hend-sessioni::= <end-session><sessionID> hinteger </sessionID><problem> hnamei </problem><rounds> hinteger </rounds><goals><failed> hinteger </failed><reached><successes> hinteger </successes>[<time-average> hnumber </time-average>]</reached></goals>[<metric-average> hnumber </metric-average>]</end-session>herror::= <error> hmessagei </error>885fiYounes, Littman, Weissman & AsmuthReferencesBoutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research,11, 194.Boutilier, C., Dearden, R., & Goldszmidt, M. (1995). Exploiting structure policy construction. Mellish, C. S. (Ed.), Proceedings Fourteenth International JointConference Artificial Intelligence, pp. 11041111, Montreal, Canada. Morgan Kaufmann Publishers.Boutilier, C., Friedman, N., Goldszmidt, M., & Koller, D. (1996). Context-specific independence Bayesian networks. Proceedings Twelfth Annual ConferenceUncertainty Artificial Intelligence (UAI 96), pp. 115123, Portland, OR.Dean, T., & Kanazawa, K. (1989). model reasoning persistence causation.Computational Intelligence, 5 (3), 142150.Dearden, R., & Boutilier, C. (1997). Abstraction approximate decision-theoretic planning. Artificial Intelligence, 89 (12), 219283.Fox, M., & Long, D. (2003). PDDL2.1: extension PDDL expressing temporalplanning domains. Journal Artificial Intelligence Research, 20, 61124.Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003). Efficient solution algorithmsfactored MDPs. Journal Artificial Intelligence Research, 19, 399468.Hoey, J., St-Aubin, R., Hu, A., & Boutilier, C. (1999). SPUDD: Stochastic planning usingdecision diagrams. Laskey, K. B., & Prade, H. (Eds.), Proceedings FifteenthConference Uncertainty Artificial Intelligence, pp. 279288, Stockholm, Sweden.Morgan Kaufmann Publishers.Howard, R. A. (1960). Dynamic Programming Markov Processes. John Wiley & Sons,New York, NY.Howard, R. A. (1971). Dynamic Probabilistic Systems, Vol. I: Markov Models. John Wiley& Sons, New York, NY.Kushmerick, N., Hanks, S., & Weld, D. S. (1995). algorithm probabilistic planning.Artificial Intelligence, 76 (12), 239286.Littman, M. L. (1997). Probabilistic propositional planning: Representations complexity. Proceedings Fourteenth National Conference Artificial Intelligence,pp. 748754, Providence, RI. American Association Artificial Intelligence, AAAIPress.Littman, M. L., Goldsmith, J., & Mundhenk, M. (1998). computational complexityprobabilistic planning. Journal Artificial Intelligence Research, 9, 136.McDermott, D. (2000). 1998 AI planning systems competition. AI Magazine, 21 (2),3555.Puterman, M. L. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming. John Wiley & Sons, New York, NY.886fiThe First Probabilistic Track IPCRintanen, J. (2003). Expressive equivalence formalisms planning sensing.Giunchiglia, E., Muscettola, N., & Nau, D. S. (Eds.), Proceedings Thirteenth International Conference Automated Planning Scheduling, pp. 185194, Trento,Italy. AAAI Press.Yoon, S., Fern, A., & Givan, R. (2005). Learning measures progress planning domains.Proceedings Twentieth National Conference Artificial Intelligence, pp.12171222.Younes, H. L. S., & Littman, M. L. (2004). PPDDL1.0: extension PDDL expressingplanning domains probabilistic effects. Tech. rep. CMU-CS-04-167, CarnegieMellon University, Pittsburgh, PA.887fiJournal Artificial Intelligence Research 24 (2005) 305339Submitted 11/04; published 8/05Learning Concept Hierarchies Text Corporausing Formal Concept AnalysisCIMIANO @ AIFB . UNI - KARLSRUHE . DEPhilipp CimianoInstitute AIFB, University KarlsruheEnglerstr. 11, 76131 Karlsruhe, GermanyHOTHO @ CS . UNI - KASSEL . DEAndreas HothoKnowledge Data Engineering Group, University KasselWilhelmshoher Allee 73, 34121 Kassel, GermanySTAAB @ UNI - KOBLENZ . DESteffen StaabInstitute Computer Science, University Koblenz-LandauUniversitatsstr. 1, 56016 Koblenz, GermanyAbstractpresent novel approach automatic acquisition taxonomies concept hierarchiestext corpus. approach based Formal Concept Analysis (FCA), method mainlyused analysis data, i.e. investigating processing explicitly given information.follow Harris distributional hypothesis model context certain term vector representing syntactic dependencies automatically acquired text corpus linguistic parser. basis context information, FCA produces lattice convertspecial kind partial order constituting concept hierarchy. approach evaluated comparing resulting concept hierarchies hand-crafted taxonomies two domains: tourismfinance. also directly compare approach hierarchical agglomerative clusteringwell Bi-Section-KMeans instance divisive clustering algorithm. Furthermore,investigate impact using different measures weighting contribution attributewell applying particular smoothing technique cope data sparseness.1. IntroductionTaxonomies concept hierarchies crucial knowledge-based system, i.e. systemequipped declarative knowledge domain deals capable reasoningbasis knowledge. Concept hierarchies fact important allow structureinformation categories, thus fostering search reuse. Further, allow formulaterules well relations abstract concise way, facilitating development, refinementreuse knowledge-base. Further, fact allow generalize words shownprovide benefits number applications Information Retrieval (Voorhees, 1994)well text clustering (Hotho, Staab, & Stumme, 2003) classification (Bloehdorn & Hotho,2004). addition, also important applications within Natural Language Processing (e.g.Cimiano, 2003).However, also well known knowledge-based system suffers so-calledknowledge acquisition bottleneck, i.e. difficulty actually model domain question.c 2005 AI Access Foundation. rights reserved.fiC IMIANO , H OTHO , & TAABorder partially overcome problem present novel approach automatically learningconcept hierarchy text corpus.Making knowledge implicitly contained texts explicit great challenge. example,Brewster, Ciravegna, Wilks (2003) argued text writing reading fact processbackground knowledge maintenance sense basic domain knowledge assumed,relevant part knowledge issue text article mentionedless explicit way. Actually, knowledge found texts different levels explicitnessdepending sort text considered. Handbooks, textbooks dictionaries example containexplicit knowledge form definitions tiger mammal mammalstigers, lions elephants. fact, researchers exploited regular patterns discovertaxonomic part-of relations texts (Hearst, 1992; Charniak & Berland, 1999; Iwanska, Mata, &Kruger, 2000; Ahmad, Tariq, Vrusias, & Handy, 2003). However, seems technicalspecialized texts get, less basic knowledge find stated explicitly. Thus, interestingalternative derive knowledge texts analyzing certain terms used ratherlook explicit definition. lines distributional hypothesis (Harris, 1968) assumesterms similar extent share similar linguistic contexts.fact, different methods proposed literature address problem (semi-)automatically deriving concept hierarchy text based distributional hypothesis. Basically, methods grouped two classes: similarity-based methods one handset-theoretical hand. methods adopt vector-space model representword term vector containing features attributes derived certain corpus.certainly great divergence attributes used purpose, typically sortsyntactic features used, conjunctions, appositions (Caraballo, 1999) verb-argumentdependencies (Hindle, 1990; Pereira, Tishby, & Lee, 1993; Grefenstette, 1994; Faure & Nedellec,1998).first type methods characterized use similarity distance measureorder compute pairwise similarity distance vectors corresponding two wordsterms order decide clustered not. prominent examples typemethod developed Hindle (1990), Pereira et al. (1993), Grefenstette (1994), FaureNedellec (1998), Caraballo (1999) well Bisson, Nedellec, Canamero (2000). Settheoretical approaches partially order objects according inclusion relationsattribute sets (Petersen, 2002; Sporleder, 2002).paper, present approach based Formal Concept Analysis, method basedorder theory mainly used analysis data, particular discovering inherent relationships objects described set attributes one hand, attributes(Ganter & Wille, 1999). order derive attributes certain corpus,parse extract verb/prepositional phrase (PP)-complement, verb/object verb/subjectdependencies. noun appearing head argument positions use corresponding verbs attributes building formal context calculating formal conceptlattice basis.Though different methods explored literature, actually lack comparative work concerning task automatically learning concept hierarchies clustering techniques. However, argued Cimiano, Hotho, Staab (2004c), ontology engineers need guidelines effectiveness, efficiency trade-offs different methods order decidetechniques apply settings. Thus, present comparison along lines306fiL EARNING C ONCEPT H IERARCHIESEXT C ORPORAUSINGF ORMAL C ONCEPT NALYSISFCA-based approach, hierarchical bottom-up (agglomerative) clustering Bi-Section-KMeansinstance divisive algorithm. particular, compare learned concept hierarchiesterms similarity handcrafted reference taxonomies two domains: tourism finance.addition, examine impact using different information measures weight significancegiven object/attribute pair. Furthermore, also investigate use smoothing techniquecope data sparseness.remainder paper organized follows: Section 2 describes overall processSection 3 briefly introduces Formal Concept Analysis describes nature concepthierarchies automatically acquire. Section 4 describes text processing methods applyautomatically derive context attributes. Section 5 discuss detail evaluation methodologypresent actual results Section 6. particular, present comparison differentapproaches well evaluation impact different information measures wellsmoothing technique. concluding, discuss related work Section 7.2. Overall Processoverall process automatically deriving concept hierarchies text depicted Figure 1.First, corpus part-of-speech (POS) tagged 1 using TreeTagger (Schmid, 1994) parsed usingLoPar2 (Schmid, 2000), thus yielding parse tree sentence. Then, verb/subject, verb/objectverb/prepositional phrase dependencies extracted parse trees. particular, pairsextracted consisting verb head subject, object prepositional phrasesubcategorize. Then, verb heads lemmatized, i.e. assigned base form.order address data sparseness, collection pairs smoothed, i.e. frequency pairsappear corpus estimated basis frequency pairs.pairs weighted according statistical measure pairs certainthreshold transformed formal context Formal Concept Analysis applied.lattice resulting this, ( , ), transformed partial order ( , ) closerconcept hierarchy traditional sense. FCA typically leads proliferation concepts,partial order compacted pruning step, removing abstract concepts leading compactedpartial order ( , ) resulting concept hierarchy. process described detailSection 3. process described formally Algorithm 1.3. Formal Concept AnalysisFormal Concept Analysis (FCA) method mainly used analysis data, i.e. derivingimplicit relationships objects described set attributes one handattributes other. data structured units formal abstractionsconcepts human thought, allowing meaningful comprehensible interpretation (Ganter & Wille,1999). Thus, FCA seen conceptual clustering technique also provides intensionaldescriptions abstract concepts data units produces. Central FCA notionformal context:1. Part-of-speech tagging consists assigning word syntactic category, i.e. noun, verb, adjective etc.2. http://www.ims.uni-stuttgart.de/projekte/gramotron/SOFTWARE/LoPar-en.html307fiC IMIANO , H OTHO , & TAABAlgorithm 1 ConstructConceptHierarchy(D,T)/* construct hierarchy terms basis documents1: Parses = parse(POS-tag( ));2: SynDeps = tgrep(Parses);3: lemmatize(SynDeps);4: smooth(SynDeps);5: weight(SynDeps);6: SynDeps = applyThreshold(SynDeps);7:= getFormalContext( ,SynDeps);8:computeLattice;9:transform;compact;10:11: return;fi*/ffParsertgrepLatticeCompactionLemmatizerSmoothingPruningFCAWeightingFigure 1: Overall ProcessDefinition 1 (Formal Context)triple ( , , ) called formal contextsetsrelation . elements called objects,incidence context.binaryattributes!"# $&%(')"* '+,#-".0/dually 123 : 1 ( 4'5".6$7%(8"*1 '+,#-"59/Intuitively speaking, set attributes common objects , 1set objects attributes 1 . Furthermore, define formal concept is:, define:Definition 2 (Formal Concept)pair ( , ) formal concept ( ,1, ) :;1<3=> +?1@A1 .words, ( , 1 ) formal concept set attributes shared objectsidentical 1 hand also set objects attributes 1 .called extent 1 intent formal concept ( ,1 ). formal concepts308fiL EARNING C ONCEPT H IERARCHIESEXT C ORPORAUSINGF ORMAL C ONCEPT NALYSISgiven context naturally ordered subconcept-superconcept relation defined by:! 1 =1 > 1;31Thus, formal concepts partially ordered regard inclusion extents (whichequivalent) inverse inclusion intent.give examples illustrate definitions. context tourism domainone knows example things like hotel, apartment, car, bike, trip excursionbooked. Furthermore, know rent car, bike apartment. Moreover,drive car bike, ride bike 3 . addition, know join excursiontrip. represent formal context corresponding knowledge formal context(see Table 1). lattice produced FCA depicted Figure 2 (left) 4 . transformedspecial type concept hierarchy shown Figure 2 (right) removing bottom element,introducing ontological concept formal concept (named intent) introducingsubconcept element extent formal concept question.partial order,order formally define transformation latticeassume lattice represented using reduced labeling. Reduced labeling defined(Ganter & Wille, 1999) means objects extension specific conceptattributes conversely intension general one. reduced labeling achievedintroducing functionsff . particular, name object attached lower halfcorresponding object concept, i.e., name attributelocated upper half attribute concept, i.e. ff. given latticeformal concepts formal context, transform partial orderfollows:'' 4'9/ 4'9/fi# 2 ! / ! /@fi)Definition 3 (TransformationFirstcontains objects well intents (sets attributes):@ fi# 1 $1 " #/Further:7'( 1 $'1 /fi.71 1 $1 =1 /Finally, FCA typically produces high number concepts, compress resulting hierarchy ontological concepts removing inner node whose extension terms leave nodesfollows:subsumed one child, i.e. create partial orderDefinition 4 (Compacted Concept Hierarchy)Assuming set leave nodes dominated according!:! " $ %"#>" ! # %$&'( ) +* '( # /Further:3. According Longman Dictionary, American English also possible ride vehicles general. However,purposes example gloss fact.4. Concept Explorer software used produce lattice (see http://sourceforge.net/projects/conexp).309fiC IMIANO , H OTHO , & TAABbookablejoinableexcursionrentablehoteldriveabletripapartmentrideablecarbikeFigure 2: lattice formal concepts (left) corresponding hierarchy ontological concepts (right) tourism examplei.e.relation$restricted pairs elements.particular hierarchy figure 2 (right) would remove rideable concept.hotelapartmentcarbikeexcursiontripbookablexxxxxxrentabledriveablerideablexxxxxxjoinablexxTable 1: Tourism domain knowledge formal contextfirst glance, seems hierarchy shown Figure 2 (right) somehow odd duefact labels abstract concepts verbs rather nouns typically assumed.However, formal point view, concept identifiers meaning couldnamed concepts arbitrary symbols. reason handyintroduce meaningful concept identifiers purpose easier human readability. fact,adopt extensional interpretation hierarchy, problems assertingextension concept denoted bike subset extension concept rideableobjects world. view totally compatible interpreting concept hierarchy310fiL EARNING C ONCEPT H IERARCHIESEXT C ORPORAUSINGF ORMAL C ONCEPT NALYSIS% 7& ,terms formal subsumption given logical formula:$ .thus conclude extensional point view verb-like concept identifiersstatus concept label based noun. intensional point view, mayeven exist hypernym adequate intension label certain abstract concept,using verb-like identifier may even appropriate choice. example, could easilyreplace identifiers joinable, rideable driveable activity, two-wheeled vehicle vehicle,respectively. However, certainly difficult substitute rentable meaningful termdenoting extension, i.e. things rented.also important mention learned concept hierarchies represent conceptualizationdomain respect given corpus sense represent relationsterms used text. However, corpora represent limited view worldcertain domain due fact something mentioned, meanrelevant, simply issue text question. also leads factcertain similarities terms respect corpus actually accidental, sensemap corresponding semantic relation, due fact textsrepresent arbitrary snapshot domain. Thus, learned concept hierarchies merelyregarded approximations conceptualization certain domain.task focusing is: given certain number terms referring conceptsrelevant domain question, derive concept hierarchy them? termsFCA, objects thus given need find corresponding attributes order buildincidence matrix, lattice transform corresponding concept hierarchy.following section, describe acquire attributes automatically underlyingtext collection.4. Text Processingalready mentioned introduction, order derive context attributes describing termsinterested in, make use syntactic dependencies verbs appearing textcollection heads subject, object PP-complements subcategorize. fact,previous experiments (Cimiano, Hotho, & Staab, 2004b) found using dependenciesgeneral leads better results subsets them. order extract dependenciesautomatically, parse text LoPar, trainable, statistical left-corner parser (Schmid, 2000).parse trees extract syntactic dependencies verb subject, object PP-complement using tgrep 5 . Finally, also lemmatize verbs well headsubject, object PP-complement looking lemma lexicon provided LoPar.Lemmatization maps word base form context used sort normalizationtext. Lets take instance following two sentences:museum houses impressive collection medieval modern art. building combines geometric abstraction classical references allude Roman influenceregion.parsing sentences, would extract following syntactic dependencies:5. see http://mccawley.cogsci.uiuc.edu/corpora/treebank3.html311fiC IMIANO , H OTHO , & TAABhouses subj(museum)houses obj(collection)combines subj(building)combines obj(abstraction)combine with(references)allude to(influence)lemmatization step, references mapped base form reference combineshouses combine house, respectively, yield result:house subj(museum)house obj(collection)combine subj(building)combine obj(abstraction)combine with(reference)allude to(influence)addition, three important issues consider:1. output parser erroneous, i.e. derived verb/argument dependenciescorrect,2. derived dependencies interesting sense help discriminate different objects,3. assumption completeness information never fulfilled, i.e. text collectionnever big enough find possible occurrences (compare Zipf, 1932).deal first two problems, weight object/attribute pairs regard certaininformation measure process verb/argument relations measurethreshold . particular, explore following three information measures (seeCimiano, S.Staab, & Tane, 2003; Cimiano et al., 2004b):ff$fffi(fi ' $#fifi $!$ ' .#ffFurthermore, " total number occurrences term argument argffverb ,number occurrences verb argumentrelative frequency term compared terms. first information measure simplyconditional probability term given argument ' verb . second measure ( called pointwise mutual information used Hindle (1990)312fiL EARNING C ONCEPT H IERARCHIESEXT C ORPORAUSINGF ORMAL C ONCEPT NALYSISdiscovering groups similar terms. third measure inspired work Resnik (1997)introduces additional factorfi takes account terms appearingargument position verb question. particular, factor measures relativeentropy prior posterior (considering verb appears with) distributions thusselectional strength verb given argument position. important mentionapproach values measures normalized interval [0,1].third problem requires smoothing input data. fact, working text corpora,data sparseness always issue (Zipf, 1932). typical method overcome data sparsenesssmoothing (Manning & Schuetze, 1999) essence consists assigning non-zero probabilities unseen events. purpose apply technique proposed Cimiano, Staab,Tane (2003) mutually similar terms clustered result occurrenceattribute one term also counted occurrence attribute term.similarity measures examine Cosine, Jaccard, L1 norm, Jensen-Shannon divergenceSkew Divergence measures analyzed described Lee (1999):'$ $$$fi$ $$( $fi $ $fi ff $ $fi fiffff / / $ $( $ $ $ 4$) (fifi($ $ ' ( , : $ $ ' ( ,( $ $ @ ! " :,!# : $ $ #:,' %'&$ ! ' ()(*$!,+)(,&!particular, implemented measures using variants relying elementscommon described Lee (1999). Strictly speaking, Jensen-Shannon wellSkew divergences dissimilarity functions measure average information lossusing one distribution instead other. fact transform similarity measuresffff, constant dissimilarity function question. clusterterms mutually similar regard similarity measure question, countingattribute/object pairs actually found text thus obtaining also non-zero frequenciesattribute/object pairs appear literally corpus. overall result thussmoothing relative frequency landscape assigning non-zero relative frequenciescombinations verbs objects actually found corpus. followsformal definition mutual similarity:Definition 5 (Mutual Similarity)Two terms mutually similar iff( .'7313'7 (fiC IMIANO , H OTHO , & TAABFigure 3: Examples lattices automatically derived tourism-related texts without smoothing(left) smoothing (right)According definition, two terms mutually similar similarterm regard similarity measure question way round. Actually,definition equivalent reciprocal similarity Hindle (1990).Figure 3 (left) shows example lattice automatically derived set textsacquired http://www.lonelyplanet.com well http://www.all-in-all.de, web page containing information history, accommodation facilities well activities MecklenburgVorpommern, region northeast Germany. extracted verb/object pairs termsTable 1 used conditional probability weight significance pairs. excursion,dependencies extracted therefore considered computing lattice.. Assumingcorpus size million words threshold usedcar bike mutually similar, would clustered, i.e. car would get attribute startablebike attribute needable. result thus lattice Figure 3 (right), carbike extension one concept.5. Evaluationorder evaluate approach need assess good automatically learned ontologiesreflect given domain. One possibility would compute many superconcept relationsautomatically learned ontology correct. example done Hearst (1992)Caraballo (1999). However, due fact approach, well many others (compareHindle, 1990; Pereira et al., 1993; Grefenstette, 1994), produce appropriate namesabstract concepts generated, seems difficult assess validity given superconceptrelation. Another possibility compute similar automatically learned concept hierarchyrespect given hierarchy domain question. crucial questiondefine similarity concept hierarchies. Though great amount workAI community compute similarity trees (Zhang, Statman, & Shasha, 1992;Goddard & Swart, 1996), concept lattices (Belohlavek, 2000), conceptual graphs (Maher, 1993;Myaeng & Lopez-Lopez, 1992) (plain) graphs (Chartrand, Kubicki, & Schultz, 1998; Zhang,Wang, & Shasha, 1996), clear similarity measures also translate concept314fiL EARNING C ONCEPT H IERARCHIESEXT C ORPORAUSINGF ORMAL C ONCEPT NALYSIShierarchies. interesting work lines one presented Maedche Staab (2002)ontologies compared along different levels: semiotic, syntactic pragmatic.particular, authors present measures compare lexical taxonomic overlap twoontologies. Furthermore, also present interesting study different subjectsasked model tourism ontology. resulting ontologies compared terms definedsimilarity measures thus yielding agreement different subjects task modelingontology.order formally define evaluation measures, introduce core ontology model lineontological model presented Stumme et al. (2003):Definition 6 (Core Ontology)consisting (i) set concept identifiers, (ii)core ontology structure#designated root element representing top element (iii) partial order fi, called concept hierarchy taxonomy.";% "/sake notational simplicity adopt following convention: given ontology, corresponding set concepts denoted partial order representingconcept hierarchy .important mention approach presented here, terms directly identifiedconcepts, i.e. neglect fact terms polysemous. 6 Now, Lexical Recall (LR)measured follows:7two ontologies$ $ $ $Take example concept hierarchiesdepicted Figure 4. example,(fiffLexical Recallfi( ff.order compare taxonomy two ontologies, use Semantic Cotopy (SC) presented Maedche Staab (2002). Semantic Cotopy concept defined setsuper- subconcepts:" $/follows illustrate definitions basis several example concepthierarchies. Take instance concept hierarchies Figure 5. assume left concepthierarchy automatically learned FCA approach concept hierarchyright handcrafted one. Further, important point left ontology is,terms arrangement leave nodes abstracting labels inner nodes,perfectly learned concept hierarchy. thus reflected maximum similarityontologies. Semantic Cotopy concept vehicle right ontology Figure 5example car, bike, two-wheeled vehicle, vehicle, object-to-rent Semantic Cotopydriveable left ontology bike, car, rideable, driveable, rentable, bookable .becomes thus already clear comparing cotopies concepts yield desiredresults, i.e. maximum similarity concepts. Thus use modified version SC//6. principle, FCA able account polysemy terms. However, paper neglect aspect.7. terms ordered hierarchically given need measure lexical precision.315fiC IMIANO , H OTHO , & TAABrootactivityobject_to_renthotelrootexcursionrunableapartmentofferablestartableneedableattemptable, ...bikecartripvehicletriptwowheeledvehiclecarbikehotelFigure 4: Example automatically acquired concept hierarchyreference concept hierarchy (right)joinableactivityrentablehoteldriveabletrip(fiff(left) comparedrootbookableexcursionapartmentrideableexcursionapartmentobject_to_renthotelvehicletriptwowheeledvehiclecarapartmentcarbikebikeFigure 5: Example perfectly learned concept hierarchyence concept hierarchy (right)((left) compared refer-Semantic Cotopy consider concepts common concept hierarchiesSemantic Cotopy(compare Cimiano et al., 2004b, 2004c), i.e." $ $ $ /using Common Semantic Cotopy thus exclude comparison conceptsrunable, offerable, needable, activity, vehicle etc. one ontology. So,concepts vehicle driveable identical ontologiesCommon Semantic CotopyFigure 5, i.e. bike, car thus representing perfect overlap concepts,certainly corresponds intuitions similarity concepts. However, letsconsider concept hierarchy Figure 6. common cotopy concept bike bike/316/fiL EARNING C ONCEPT H IERARCHIESEXT C ORPORAF ORMAL C ONCEPT NALYSISUSINGrootactivityexcursionvehicletriptwowheeledvehiclerootexcursiontriphotelobject_to_renthotelapartmentcarapartmentcarbikebikeFigure 6: Example trivial concept hierarchyhierarchy (right)((left) compared reference conceptconcept hierarchies. fact, every leave concept left concept hierarchy maximumoverlap corresponding concept right ontology. certainly undesirablefact leads high baselines comparing trivial concept hierarchies referencestandard (compare earlier results Cimiano et al., 2004b, 2004c). Thus, introducemodification Semantic Cotopy excluding concept Common SemanticCotopy, i.e:" $ $ $ /maintains perfect overlap vehicle driveable concept hierarchiesFigure 5, yielding empty common cotopies leave concepts left ontologyFigure 6.Now, according Maedche et al. Taxonomic Overlap () two ontologiescomputed follows:$$ $defined follows:$$fi$& $317fi"" * %4$4 $fi 4 $4$fiC IMIANO , H OTHO , & TAABSo,gives similarity concepts ontologies comparinggives similarity conceptrespective semantic cotopies. contrast,concept maximizes overlap respective semantic cotopies, i.e. makesoptimistic estimation assuming overlap happen show immediatelexical surface (compare Maedche & Staab, 2002). Taxonomic Overlaptwo ontologies calculated averaging taxonomic overlaps concepts. case doesnt make sense calculate Semantic Cotopy conceptsontologies represent leave nodes thus common semantic cotopiesempty. Thus, calculate Taxonomic Overlap two ontologies follows:& ffff ( fi$ &Finally, want compute Taxonomic Overlap one direction, introduce precision, recall F-Measure calculating harmonic mean both:"$$$ $!4 $4$importance balancing recall precision clear discussion examples below. Lets consider example concept hierarchy(Figure 5. five concepts bookable, joinable, rentable, driveable rideable findcorresponding concept maximum Taxonomic Overlapwayround concepts activity, object-to-rent, vehicle two-wheeled-vehicle ,(((.concept hierarchy fiff shown Figure 7 precision still 100% reasons above, due fact rideable concept removed corresponding concept two-wheeled-vehicle. concept maximizing taxonomic similaritytwo-wheeled-vehicle driveable++ + Taxonomic Overlap 0.5. recall$thus ffff& F-Measure decreasesff.55concept hierarchy fiff Figure 8, additional+ + + + concept planable introduced,$reduces precision fiffrecall stays obvi& ,thus F-Measure fiff .ously ff))becomes thus clear important measure precision recall automatically learned concept hierarchies balance harmonic meanF-Measure. automaticallylearned concept hierarchyFigure+++++!" + " 4+ precision(fiff& $$ $$&fi( ff, recall$#& &&fi(ffthus F-Measure# .fi( ff318fiL EARNING C ONCEPT H IERARCHIESEXT C ORPORAUSINGF ORMAL C ONCEPT NALYSISrootactivitybookablejoinableexcursionexcursionrentablehoteldriveabletripvehicletriptwowheeledvehicleapartmentbikeobject_to_renthotelapartmentcarbikecarFigure 7: Example concept hierarchy lower recall ( ff ) compared reference concept hierarchyrootbookablejoinableplanabledriveabletripactivityrentablehotelexcursionapartmentvehicletripexcursionrideableobject_to_renthoteltwowheeledvehiclecarapartmentcarbikebikeFigure 8: Example concept hierarchy lower precision ( ff ) compared reference concept hierarchyFigure 6 getcomparison, trivial concept hierarchy! + ++(& & $ ((per definition),.((important mention though toy examples difference respectmeasures automatically learned concept hierarchy trivial concept hierfi( ffarchy big, considering real-world concept hierarchies much higher(number concepts clear F-Measures trivial concept hierarchies low(see results Section 6).Finally, also calculate harmonic mean lexical recall F-Measure follows:!319fiC IMIANO , H OTHO , & TAABNo. ConceptsNo. LeavesAvg. DepthMax. DepthMax. ChildrenAvg. ChildrenTourism2932363.996215.26Finance12238614.5713333.5Table 2: Ontology statisticsautomatically learned concept hierarchy, get example:fi( ff###!6. Resultsalready mentioned above, evaluate approach two domains: tourism finance.ontology tourism domain reference ontology comparison study presentedMaedche Staab (2002), modeled experienced ontology engineer. financeontology basically one developed within GETESS project (Staab et al., 1999);designed purpose analyzing German texts Web, also English labels availablemany concepts. Moreover, manually added English labels concepts whoseGerman label English counterpart result concepts ( 95%) finallyyielded also English label.8 tourism domain ontology consists 293 concepts,finance domain ontology bigger total 1223 concepts 9 . Table 2 summarizes factsconcept hierarchies ontologies, total number concepts, totalnumber leave concepts, average maximal length paths leave root nodewell average maximal number children concept (without considering leaveconcepts).domain-specific text collection tourism domain use texts acquiredmentioned web sites, i.e. http://www.lonelyplanet.com well http://www.all-in-all.de.Furthermore, also used general corpus, British National Corpus 10 . Altogether, corpussize 118 Million tokens. finance domain considered Reuters news 1987185 Million tokens11 .6.1 Comparisonbest F-Measure tourism datasetcorresponding precision(fiff(fiff(at thresholdrecallfi( ff'),#.8. concepts direct counterpart language.9. ontologies downloaded http://www.aifb.uni-karlsruhe.de/WBS/pci/TourismGoldStandard.isahttp://www.aifb.uni-karlsruhe.de/WBS/pci/FinanceGoldStandard.isa, respectively10. http://www.natcorp.ox.ac.uk/11. http://www.daviddlewis.com/resources/testcollections/reuters21578/320fiL EARNING C ONCEPT H IERARCHIESEXT C ORPORAUSINGF ORMAL C ONCEPT NALYSIS,finance dataset, corresponding values.Lexical Recall obviously also decreases increasing threshold overallF-Measurealso decreases inverse proportionally . Overall, best results terms Ffinance# tourism datasetfi( ff reason results finance dataset slightly lower probably duedataset.technical nature domain (compared tourism domain) also factconcept hierarchy learned bigger.order evaluate FCA-based approach, compare hierarchical agglomerativeclustering Bi-Section-KMeans. Hierarchical agglomerative clustering (compare Duda, Hart, &Stork, 2001) similarity-based bottom-up clustering technique beginning everyterm forms cluster own. algorithm iterates step merges twosimilar clusters still available, one arrives universal cluster contains terms.experiments, use three different strategies calculate similarity clusters:complete, average single-linkage. three strategies may based similaritymeasure terms, i.e. cosine measure experiments, measure similaritytwo non-trivial clusters different ways.,Single linkage defines similarity two clustersconsidering closest pair two clusters. Complete linkage considers twodissimilar terms, i.e.. Finally, average-linkage computes average simi. reader notelarity terms two clusters, i.e.rather order fictive universalprohibit merging clusters similarity0cluster root. corresponds exactly way FCA creates orders objects attributescommon. time complexity naive implementation agglomerative clustering ,complete linkageefficient implementations worst-time complexityaverage linkas requires sorting similarity matrix (Day & Edelsbrunner, 1984),age vectors length-normalized similarity measure cosine (see Manning &Schuetze, 1999) O( ) single linkage (compare Sibson, 1973). 12Bi-Section-KMeans defined outer loop around standard KMeans (Steinbach, Karypis,& Kumar, 2000). order generate clusters, Bi-Section-KMeans repeatedly applies KMeans.Bi-Section-KMeans initiated universal cluster containing terms. loops:selects cluster largest variance 13 calls KMeans order split clusterexactly two subclusters. loop repeated " times non-overlapping subclustersgenerated. similarity measure also use cosine measure. complexity Bi-SectionKMeans . want generate complete cluster tree clusters complexitythus O( ). Furthermore, Bi-Section-KMeans randomized algorithm, produce ten runsaverage obtained results.compare different approaches along lines measures described Section 5.Figure 9 shows results terms F-Measure Lexical Recall domainsclustering approaches. particular, shows 8 data points corresponding thresholds0.005, 0.01, 0.05, 0.1, 0.3, 0.5, 0.7 0.9. First seems important discuss baselinesapproach. baselines approach trivial concept hierarchiesgenerated objects attributes common. trivial concept hierarchies generatedfifffifffiff'412. See also http://www-csli.stanford.edu/ schuetze/completelink.html topic.13. Though dont make use experiments, also possible select largest cluster splitting.321fiC IMIANO , H OTHO , & TAABTourismFCAComplete LinkageAverage LinkageSingle LinkageBiSection KMeans0.5FMeasure0.40.30.20.100.360.380.40.420.44Lexical Recall0.460.480.5FinanceFCAComplete LinkageAverage LinkageSingle LinkageBiSection KMeans0.5FMeasure0.40.30.20.100.380.40.420.44Lexical Recall0.460.480.5Figure 9: Results FCA-based approach: F-Measure Lexical Recall tourismfinance domainsthreshold 0.7 datasets definition precision 100% recall close0. baselines FCA agglomerative clustering algorithm same, BiSection-KMeans producing hierarchy random binary splits results higher F values.trivial hierarchies represent absolute baseline sense algorithm could performworse. also seen Figure 9 FCA-based approach performs better322fiL EARNING C ONCEPT H IERARCHIESEXT C ORPORAUSINGF ORMAL C ONCEPT NALYSISTourism0.7FCAComplete LinkageAverage LinkageSingle LinkageBiSection KMeans0.6Recall0.50.40.30.20.100.20.30.40.50.6Precision0.70.80.91Finance0.7FCAComplete LinkageAverage LinkageSingle LinkageBiSection KMeans0.6Recall0.50.40.30.20.100.20.30.40.50.6Precision0.70.80.91Figure 10: Results FCA-based approach: Recall precision tourism financedomainsapproaches domains. observed Figure 10, showing recall precision,main reason FCA-based approach yields higher recallapproaches, maintaining precision reasonable levels.tourism domain, second best result achieved agglomerative algorithmsingle-linkage strategy, followed ones average-linkage complete-linkage (in323fiC IMIANO , H OTHO , & TAABFCAComplete LinkAverage LinkSingle LinkBi-Sec. KMeansP29.33%34.67%35.21%34.78%32.85%TourismRF65.49% 40.52%31.98% 33.27%31.45% 33.23%28.71% 31.46%28.71% 30.64%F44.69%36.85%36.55%38.57%36.42%P29.93%24.56%29.51%25.23%34.41%FinanceRF37.05% 33.11%25.65% 25.09%24.65% 26.86%22.44% 23..75%21.77% 26.67%F38.85%33.35%32.92%32.15%32.77%Table 3: Results comparison different clustering approachesorder), worst results obtained using Bi-Section-KMeans (compare Table 3).finance domain, second best results achieved agglomerative algorithmcomplete-linkage strategy followed one average-linkage strategy, Bi-SectionKMeans one single-linkage strategy (in order). Overall, valid claimFCA outperforms clustering algorithms datasets. closer look Table 3,reason becomes clear, i.e. FCA much higher recall approaches,precision less comparable. due fact FCA generates higher numberconcepts clustering algorithms thus increasing recall. Interestingly,time precision concepts remains reasonably high thus also yielding higher F-Measures.interesting question thus big produced concept hierarchies are. Figure 11 showssize concept hierarchies terms number concepts threshold parameterdifferent approaches domains. important explain number conceptsdifferent different agglomerative algorithms well Bi-Section-KMeans principlesize always , number objects clustered. However,objects similarity objects added directly fictive root element, sizeconcept hierarchies varies depending way similarities calculated. general,sizes agglomerative divisive approaches similar, lower thresholds FCA yieldsconcept hierarchies much higher number concepts. threshold on, sizeshierarchies produced different approaches quite similar. Table 4 shows resultsapproaches using thresholds 0.3 0.5. particular conclude FCA alsooutperforms approaches domains producing similar number concepts.general, determined statistical significance results presented paper FCA, contrast Bi-Section-K-Means, deterministic algorithm dependrandom seeding. implementation agglomerative clustering algorithm also deterministic given certain order terms clustered. Thus, possibility calculatesignificance results would produce different runs randomly leaving partscorpus calculating statistical significance different runs. pursueddirection fact FCA performs better setting clear results Table3.324fiL EARNING C ONCEPT H IERARCHIESThresholdFCAComplete LinkSingle LinkAverage LinkBi-Sec. KMeansEXT C ORPORATourism0.30.537.53% 37.74%36.85% 36.78%29.84% 35.79%35.36% 36.55%31.50% 35.02%USINGF ORMAL C ONCEPT NALYSISFinance0.30.537.59% 34.92%33.05% 30.37%29.34% 27.79%32.92% 31.30%32.77% 31.38%Table 4: Comparison results thresholds 0.3 0.5 terms FTourismFinanceTourismFinanceTourismFinanceTourismFinanceTourismFinanceConditionalPMIFCA44.69%44.51%38.85%38.96%Complete Linkage36.85%27.56%33.35%22.29%Average Linkage36.55%26.90%32.92%23.78%Single Linkage38.57%30.73%32.15%25.47%Bi-Section-KMeans36.42%27.32%32.77%26.52%Resnik43.31%38.87 %23.52%22.96%23.93%23.26%28.63%23.46%29.33%24.00%Table 5: Comparison results different information measures terms F6.2 Information Measuresalready anticipated Section 4, different information measures also subject analysis. Table 5 presents best results different clustering approaches information measures. concluded results using PMI Resnik measures produces worseresults tourism dataset, yielding slightly better results finance datasetFCA-based approach. also interesting observe compared FCA-based approach,clustering approaches much sensitive information measure used. Overall,use Conditional information measure seems reasonable choice.6.3 Smoothingapplied smoothing method described section 4 datasets order findfar clustering terms improves results FCA-based approach. informationmeasure use experiment conditional probability performs reasonably well325fiC IMIANO , H OTHO , & TAABTourism2200FCAComplete LinkageAverage LinkageSingle LinkageBiSectionKMeans200018001600140012001000800600400200000.10.20.30.40.50.6threshold0.70.80.910.91Finance7000FCAComplete LinkageAverage LinkageSingle LinkageBiSectionKMeans600050004000300020001000000.10.20.30.40.50.6threshold0.70.8Figure 11: Sizes concept hierarchies different approaches tourism financedomains: number concepts thresholdshown Section 6.2. particular used following similarity measures: cosine measure, Jaccard coefficient, L1 norm well Jensen-Shannon Skew divergences(compare Lee, 1999). Table 6 shows impact smoothing technique terms numberobject/attribute terms added dataset. Skew Divergence excluded326fiL EARNING C ONCEPT H IERARCHIESBaseline525912577607TourismFinanceJaccard531041 (+ 5129)599691 (+ 22084)EXT C ORPORAUSINGCosine534709 (+ 8797)634954 (+ 57347)F ORMAL C ONCEPT NALYSISL1530695 (+ 4783)584821 (+ 7214)JS528892 (+ 2980)583526 (+ 5919)Table 6: Impact Smoothing Technique terms new object/attribute pairsTourismFinanceBaseline44.69%38.85%Jaccard39.54%38.63%Cosine41.81%36.69%L141.59%38.48%JS42.35%38.66%Table 7: Results Smoothing terms F-Measure Fyield mutually similar terms. observed smoothing mutual similarity basedcosine measure produces previously unseen object/attribute pairs, followedJaccard, L1 Jensen-Shannon divergence (in order). Table 7 shows results different similarity measures. tables appendix list mutually similar terms differentdomains similarity measures. results show smoothing technique actually yieldsworse results domains similarity measures used.6.4 Discussionshown FCA-based approach reasonable alternative similarity-based clustermeasure defineding approaches, even yielding better results datasets regardSection 5. main reason concept hierarchies produced FCA yieldhigher recall due higher number concepts, maintaining precision relatively hightime. Furthermore, shown conditional probability performs reasonablywell information measure compared elaborate measures PMI oneused Resnik (1997). Unfortunately, applying smoothing method based clustering mutuallysimilar terms improve quality automatically learned concept hierarchies. Table8 highlights fact every approach benefits drawbacks. main benefitusing FCA one hand datasets performed better algorithms thusproducing better concept hierarchies hand, generate clusters - formalconcepts specific - also provides intensional description clusters thuscontributing better understanding ontology engineer (compare Figure 2 (left)). contrast,similarity-based methods provide level traceability due factnumerical value similarity two high-dimensional vectors drives clusteringprocess thus remains opaque engineer. agglomerative divisive approachdifferent respect agglomerative paradigm, initial merges small-size clusterscorrespond high degrees similarity thus understandable, divisiveparadigm splitting clusters aims minimizing overall cluster variance thus hardertrace.clear disadvantage FCA size lattice get exponential sizecontext worst case thus resulting exponential time complexity comparedagglomerative clustering Bi-Section-KMeans, respectively.327fiC IMIANO , H OTHO , & TAABFCAAgglomerative Clustering:Complete LinkageAverage LinkageSingle LinkageBi-Section-KMeansEffectiveness (F)Tourism Finance44.69% 38.85%36.85%36.55%38.57%36.42%33.35%32.92%32.15%32.77%Worst CaseTime ComplexityTraceabilityGoodSizeHierarchiesLargeFairSmallWeakSmallTable 8: Trade-offs different taxonomy construction methodsimplementation FCA used concepts tool Christian Lindig 14 , basicallyimplements Ganters Next Closure algorithm (Ganter & Reuter, 1991; Ganter & Wille, 1999)extension Aloui computing covering relation described (Godin, Missaoui, &Alaoui, 1995). Figure 12 shows number seconds number attribute/object pairstook FCA compute lattice formal concepts compared time needed naiveimplementation agglomerative algorithm complete linkage. seenFCA performs quite efficiently compared agglomerative clustering algorithm. duefact object/attribute matrix sparsely populated. observations alreadymade before. Godin et al. (1995) example suspect lattice size linearly increasesnumber attributes per object. Lindig (2000) presents empirical results analyzing contextsfill ratio 0.1 comes conclusion lattice size grows quadratically respectsize incidence relation . Similar findings also reported Carpineto Romano(1996).Figure 13 shows number attributes terms rank, rank naturalnumber indicating position word list ordered decreasing term frequencies.appreciated amount (non-zero) attributes distributed Zipfian way (compareZipf, 1932), i.e. small number objects lot attributes, large numberfew. particular, tourism domain, term attributes person3077 attributes, average term approx. 178 attributes. total number attributesconsidered 9738, conclude object/attribute matrix contains almost 98% zerovalues. finance domain term highest rank percent 2870 attributes,average ca. 202 attributes. total number attributes 21542, statecase 99% matrix populated zero-values thus much sparserones considered Lindig (2000). figures explain FCA performs efficientlyexperiments. Concluding, though worst-time complexity exponential, FCA muchefficient agglomerative clustering algorithm setting.!7. Related Worksection, discuss work related automatic acquisition taxonomies. mainparadigms learning taxonomic relations exploited literature one hand clustering14. http://www.st.cs.uni-sb.de/ lindig/src/concepts.html328fiL EARNING C ONCEPT H IERARCHIESEXT C ORPORAUSINGF ORMAL C ONCEPT NALYSISTourism200FCAComplete Linkage180160time (sec.)1401201008060402000200040006000800010000 12000object/attribute pairs140001600018000Finance6000FCAComplete Linkage5000time (sec.)40003000200010000010000200003000040000 50000 60000object/attribute pairs700008000090000Figure 12: Comparison time complexities FCA agglomerative clusteringtourism finance domainsapproaches based distributional hypothesis (Harris, 1968) hand approachesbased matching lexico-syntactic patterns corpus convey certain relation.One first works clustering terms one Hindle (1990), nounsgrouped classes according extent appear similar verb frames. particular, uses verbs nouns appear subjects objects contextual attributes. Further,also introduces notion reciprocal similarity, equivalent mutual similarity.Pereira et al. (1993) also present top-down clustering approach build unlabeled hierarchynouns. present entropy-based evaluation approach, also show results329fiC IMIANO , H OTHO , & TAAB3500tourismfinance3000no. features250020001500100050000100200300400500600700rankFigure 13: Distribution Features: number (non-zero) features word ranklinguistic decision task: i.e. two verbs likely take given nounobject. Grefenstette also addressed automatic construction thesauri (Grefenstette, 1994).presents results different various domains. Further, also compares window-basedsyntactic approaches, finding results depend frequency words question.particular, shows frequent words, syntactic-based approaches better,rare words window-based approaches preferable (Grefenstette, 1992). work FaureNedellec (1998) also based distributional hypothesis; present iterative bottomup clustering approach nouns appearing similar contexts. step, cluster twosimilar extents argument position two verbs. Interestingly, wayyield concept hierarchy, also ontologically generalized subcategorization frames verbs.method semi-automatic involves users validation clusters createdstep. authors present results system terms cluster accuracy dependencypercentage corpus used. Caraballo (1999) also uses clustering methods derive unlabeled hierarchy nouns using data conjunctions nouns appositions collectedWall Street Journal corpus. Interestingly, second step also labels abstract conceptshierarchy considering Hearst patterns (see below) children conceptquestion appear hyponyms. frequent hypernym chosen order labelconcept. step also compresses produced ontological tree eliminating internalnodes without label. final ontological tree evaluated presenting random choiceclusters corresponding hypernym three human judges validation. Bisson et al.(2000) present interesting framework corresponding workbench - MoK - allowing usersdesign conceptual clustering methods assist ontology building task. particularuse bottom-up clustering compare different similarity measures well different pruningparameters.earlier work used collocation statistics learn relations terms using modification association rules extraction algorithm (Maedche & Staab, 2000). However,relations inherently taxonomic work described paper di330fiL EARNING C ONCEPT H IERARCHIESEXT C ORPORAUSINGF ORMAL C ONCEPT NALYSISrectly compared it. Maedche, Pekar, Staab (2002) examined different supervised techniquesbased collocations find appropriate hypernym unknown term, reaching accuracyaround 15% using combination tree ascending algorithm -Nearest-Neighbors wellSkew Divergence similarity measure. results neither comparable taskhand. Recently, Reinberger Spyns (2005) presented application clustering techniques biomedical domain. evaluate clusters directly comparing UMLSthesaurus. results low (3-17% precision depending corpus clustering technique) comparable results obtained comparing clusters directlygold standards reported paper though.Furthermore, quite lot work related use linguistic patterns discovercertain ontological relations text. Hearsts seminal approach aimed discovering taxonomicrelations electronic dictionaries (Hearst, 1992). precision isa-relations learned%## (57.55%) measured WordNet gold standard. Hearsts ideareapplied different researchers either slight variations patterns used (Iwanska et al.,2000), specific domains (Ahmad et al., 2003), acquire knowledge anaphora resolution(Poesio, Ishikawa, im Walde, & Viera, 2002), discover kinds semantic relationspart-of relations (Charniak & Berland, 1999) causation relations (Girju & Moldovan, 2002).approaches Hearst others characterized (relatively) high precisionsense quality learned relations high. However, approaches sufferlow recall due fact patterns rare. possible solutionproblem, approach Cimiano, Pivk, Schmidt-Thieme, Staab (2004, 2005) Hearstpatterns matched corpus Web well explicit information derivedresources heuristics combined yielding better results compared considering onesource evidence task learning superconcept relations. general, overcome datasparseness problems, researchers resorting WWW example Markert,Modjeska, Nissim (2003). approach, Hearst patterns searched WWWusing Google API order acquire background knowledge anaphora resolution. Agirre,Ansa, Hovy, Martinez (2000), download related texts Web enrich given ontology.Cimiano, Handschuh, Staab (2004a) well Cimiano, Ladwig, Staab (2005) usedGoogle API match Hearst-like patterns Web order (i) find best conceptunknown instance well (ii) appropriate superconcept certain concept givenontology (Cimiano & Staab, 2004).Velardi, Fabriani, Missikoff (2001) present OntoLearn system discovers i)domain concepts relevant certain domain, i.e. relevant terminology, ii) named entities, iii)vertical (is-a taxonomic) relations well iv) certain relations concepts basedspecific syntactic relations. approach vertical relation established termterm , i.e. is-a() , ), gained ) stripping latters prenominalmodifiers adjectives modifying nouns. Thus, vertical relation example established term international credit card term credit card, i.e. is-a(internationalcredit card,credit card). paper (Velardi, Navigli, Cuchiarelli, & Neri, 2005), mainfocus task word sense disambiguation, i.e. finding correct sense wordrespect general ontology lexical database. particular, present novel algorithm calledSSI relying structure general ontology purpose. Furthermore, includeexplanation component users consisting gloss generation component generatesdefinitions terms found relevant certain domain.331fiC IMIANO , H OTHO , & TAABSanderson Croft (1999) describe interesting approach automatically derive hierarchyconsidering document certain term appears context. particular, presentdocument-based definition subsumption according certain term specialterm also appears documents appears.Formal Concept Analysis applied many tasks within Natural Language Processing.Priss (2004) example, mentions several possible applications FCA analyzing linguisticstructures, lexical semantics lexical tuning. Sporleder (2002) Petersen (2002) apply FCAyield concise lexical inheritance hierarchies regard morphological featuresnumerus, gender etc. Basili, Pazienza, Vindigni (1997) apply FCA task learningsubcategorization frames corpora. However, knowledge appliedacquisition domain concept hierarchies approach presented paper.8. Conclusionpresented novel approach automatically acquire concept hierarchies domainspecific texts. addition, compared approach hierarchical agglomerative clustering algorithm well Bi-Section-KMeans found approach produces betterresults two datasets considered. examined different information measuresweight significance attribute/object pair concluded conditional probabilityworks well compared elaborate information measures. also analyzedimpact smoothing technique order cope data sparseness found doesntimprove results FCA-based approach. Further, highlighted advantages disadvantages three approaches.Though approach fully automatic, important mention believefully automatic ontology construction without user involvement. sense, futureexplore users involved process presenting him/her ontological relationsvalidation way necessary user feedback kept minimum.hand, involving users semi-automatic way necessary clarify good certainapproach works per se. research presented paper aim. Furthermore,also proposed systematic way evaluating ontologies comparing certain humanmodeled ontology. sense aim also establish baseline research.Acknowledgmentswould like thank colleagues feedback comments, particular Gerd Stummeclarifying FCA-related questions. would also like thank Johanna Volker comments first version well proof-reading final version paper. errorscourse own. would also like acknowledge reviewers Journal ArtificialIntelligence Research well ones earlier workshops (ATEM04, FGML04) conferences (LREC04, ECAI04) work presented valuable comments. PhilippCimiano currently supported Dot.Kom project (http://www.dot-kom.org), sponsoredEC part framework V, (grant IST-2001-34038) well SmartWeb project(http://smartweb.dfki.de), funded German Ministry Education Research.332fiL EARNING C ONCEPT H IERARCHIESEXT C ORPORAUSINGF ORMAL C ONCEPT NALYSISAppendix A. Mutually Similar TermsJaccard(art exhibition,thing)(autumn,spring)(balcony,menu)(ballroom,theatre)(banquet,ship)(bar,pub)(basilica,hair dryer)(beach,swimming pool)(billiard,sauna)(bus,car)(caravan,tree)(casino,date)(cinema,fitness studio)(city,town)(conference,seminar)(conference room,volleyball field)(cure,washing machine)(day tour,place)(distance,radio)(exhibition,price list)(ferry,telephone)(gallery,shop)(golf course,promenade)(holiday,service)(journey,terrace)(kiosk,time interval)(law,presentation)(lounge,park)(motel,port)(nature reserve,parking lot)(night,tourist)(region,situation)Cosine(agreement,contract)(animal,plant)(art exhibition,washing machine)(basilica,hair dryer)(boat,ship)(cabaret,email)(cheque,pension)(city,town)(conference room,volleyball field)(golf course,promenade)(group,party)(inn,yacht)(journey,meal)(kiosk,tennis court)(law,view)(library,museum)(money,thing)(motel,port)(pilgrimage,whirlpool)(sauna,swimming)L1 norm(day,time)(golf course,promenade)(group,person)Jensen-Shannon divergence(group,person)Table 9: Mutually Similar Terms tourism domain333fiC IMIANO , H OTHO , & TAABJaccard(action,average)(activity,downturn)(addition,liquidity)(afternoon,key)(agency,purchase)(agreement,push)(alliance,project team)(allocation,success)(analysis,negotiation)(animal,basis)(anomaly,regression)(archives,futures)(area,profitability)(argument,dismantling)(arrangement,capital market)(arranger,update)(assembly,price decline)(assurance,telephone number)(automobile,oil)(backer,trade partner)(balance sheet,person)(balancing,countenance)(behaviour,business partnership)(bike,moment)(billing,grade)(board,spectrum)(board chairman,statement)(bonus,nationality)(bonus share,cassette)(branch office,size)(broker,competition)(budget,regulation)(builder,devices)(building,vehicle)(business volume,outlook)(business year,quota)(capital,material costs)(capital increase,stock split)(capital stock,profit distribution)(caravan,seminar)(cent,point)(chance,hope)(change,subsidiary)(charge,suspicion)(chip,woman)(circle,direction)(clock,ratio)(code,insurance company)(comment,foundation)(commission,expansion)(communication,radio)(community,radius)(company profile,intangible)(compensation,participation)(complaint,petition)(computer,cooperation)(conference,height)(confidentiality,dollar)(consultant,survey)(contact,hint)(contract,copyright)(control,data center)(conversation,output)(copper,replacement)(corporation,liabilities)(cost,equity capital)(course,step)(court,district court)(credit,disbursement)(credit agreement,overview)(currency,faith)(curve,graph)(decision,maximum)(deficit,negative)(diagram,support)(difference,elimination)Cosine(access,advantage)(acquisition,merger)(action,measure)(administration costs,treasury stock)(advice,assurance)(allocation,length)(amount,total)(analysis,component)(area,region)(arrangement,regime)(assembly,chamber)(assessment,receipt)(backer,gamble)(balancing,matrix)(bank,company)(barometer,market price)(bid,offer)(bond,stock)(bonus share,cassette)(boom,turnaround)(bull market,tool)(business deal,graph)(buy,stop)(capital stock,profit distribution)(caravan,software company)(cent,point)(change,increase)(commission,committee)(company profile,intangible)(complaint,request)(controller,designer)(copper,share index)(copy,push)(credit,loan)(credit agreement,credit line)(currency,dollar)(decision,plan)(detail,test)(diagram,support)(dimension,surcharge)(discussion,negotiation)(diversification,milestone)(do,email)(document,letter)(effect,impact)(equity fund,origin)(evaluation,examination)(example,hint)(first,meter)(forecast,stock market activity)(function,profile)(gesture,input)(guarantee,solution)(half,quarter)(increment,rearrangement)(information,trading company)(insurance,percentage)(interest rate,tariff)(man,woman)(maximum,supervision)(meeting,talk)(merchant,perspective)(month,week)(press conference,seminar)(price,rate)(productivity,traffic)(profit,volume)(share price,stock market)(stock broker,theory)L1 norm(archives,futures)(assurance,telephone number)(balancing,countenance)(cent,point)(creation,experience)(government,person)(loss,profit)(month,year)Jensen-Shannon divergence(cent,point)(government,person)(month,year)Table 10: Mutually Similar Terms finance domain334fiL EARNING C ONCEPT H IERARCHIESJaccard(disability insurance,pension)(discrimination,union)(diversification,request)(do,email)(effect,help)(employer,insurance)(energy,test)(equity fund,origin)(evening,purpose)(event,manager)(examination,registration)(example,source)(exchange,volume)(exchange risk,interest rate)(experience,questionnaire)(expertise,period)(faculty,sales contract)(fair,product)(flop,type)(forecast,stock market activity)(fusion,profit zone)(gamble,thing)(good,service)(government bond,life insurance)(happiness,question)(hold,shareholder)(hour,pay)(house,model)(idea,solution)(impact,matter)(improvement,situation)(index,wholesale)(information,trading company)(initiation,middle)(input,traffic)(institute,organization)(investment,productivity)(knowledge,tradition)(label,title)(letter,reception)(level,video)(license,reward)(loan,project)(location,process)(loss,profit)(man,trainee)(margin,software company)(market,warranty)(market access,name)(matrix,newspaper)(meeting,oscillation)(meter,share)(method,technology)(milestone,state)(month,year)(mouse,option)(multiplication,transfer)(noon,press conference)(occasion,talk)(opinion,rivalry)(personnel,resource)(picture,surcharge)(plane,tool)(police,punishment)(profession,writer)(property,qualification)(provision,revenue)(requirement,rule)(risk,trust)(sales revenue,validity)(savings bank,time)(segment,series)(show,team)(speech,winter)(stock broker,theory)(supplier,train)(tariff,treasury stock)(weekend,wisdom)EXT C ORPORACosineL1 normUSINGF ORMAL C ONCEPT NALYSISJensen-Shannon divergenceTable 11: Mutually Similar Terms finance domain (Contd)335fiC IMIANO , H OTHO , & TAABReferencesAgirre, E., Ansa, O., Hovy, E., & Martinez, D. (2000). Enriching large ontologies usingWWW. Proceedings ECAI Ontology Learning Workshop.Ahmad, K., Tariq, M., Vrusias, B., & Handy, C. (2003). Corpus-based thesaurus constructionimage retrieval specialist domains. Proceedings 25th European ConferenceAdvances Information Retrieval (ECIR), pp. 502510.Basili, R., Pazienza, M., & Vindigni, M. (1997). Corpus-driven unsupervised learning verbsubcategorization frames. Proceedings 5th Congress Italian AssociationArtificial Intelligence (AI*IA97).Belohlavek, R. (2000). Similarity relations concept lattices. Journal Logic Computation,10(6), 823845.Bisson, G., Nedellec, C., & Canamero, L. (2000). Designing clustering methods ontology building - MoK workbench. Proceedings ECAI Ontology Learning Workshop, pp.1319.Bloehdorn, S., & Hotho, A. (2004). Text classification boosting weak learners based termsconcepts. Proceedings 4th IEEE International Conference Data Mining(ICDM), pp. 331334.Brewster, C., Ciravegna, F., & Wilks, Y. (2003). Background foreground knowledge dynamicontology construction. Proceedings SIGIR Semantic Web Workshop.Caraballo, S. (1999). Automatic construction hypernym-labeled noun hierarchy text.Proceedings 37th Annual Meeting Association Computational Linguistics(ACL), pp. 120126.Carpineto, C., & Romano, G. (1996). lattice conceptual clustering system applicationbrowsing retrieval. Machine Learning, 24, 95122.Charniak, E., & Berland, M. (1999). Finding parts large corpora. Proceedings 37thAnnual Meeting Association Computational Linguistics (ACL), pp. 5764.Chartrand, G., Kubicki, G., & Schultz, M. (1998). Graph similarity distance graphs. Aequationes Mathematicae, 55(1-2), 129145.Cimiano, P. (2003). Ontology-driven discourse analysis GenIE. Proceedings 8th International Conference Applications Natural Language Information Systems, pp. 7790.Cimiano, P., Handschuh, S., & Staab, S. (2004a). Towards self-annotating web. Proceedings13th World Wide Web Conference, pp. 462471.Cimiano, P., Hotho, A., & Staab, S. (2004b). Clustering ontologies text. Proceedings4th International Conference Language Resources Evaluation (LREC), pp. 17211724.Cimiano, P., Hotho, A., & Staab, S. (2004c). Comparing conceptual, divisive agglomerativeclustering learning taxonomies text. Proceedings European ConferenceArtificial Intelligence (ECAI), pp. 435439.Cimiano, P., Ladwig, G., & Staab, S. (2005). Gimme context: Context-driven automatic semantic annotation C-PANKOW. Proceedings 14th World Wide Web Conference.336fiL EARNING C ONCEPT H IERARCHIESEXT C ORPORAUSINGF ORMAL C ONCEPT NALYSISCimiano, P., Pivk, A., Schmidt-Thieme, L., & Staab, S. (2004). Learning taxonomic relationsheterogeneous sources. Proceedings ECAI 2004 Ontology Learning PopulationWorkshop.Cimiano, P., Pivk, A., Schmidt-Thieme, L., & Staab, S. (2005). Learning taxonomic relationsheterogeneous evidence. Buitelaar, P., Cimiano, P., & Magnini, B. (Eds.), Ontology Learning Text: Methods, Applications Evaluation. IOS Press. appear.Cimiano, P., S.Staab, & Tane, J. (2003). Automatic acquisition taxonomies text: FCAmeets NLP. Proceedings PKDD/ECML03 International Workshop AdaptiveText Extraction Mining (ATEM), pp. 1017.Cimiano, P., & Staab, S. (2004). Learning googling. SIGKDD Explorations, 6(2), 2434.Cimiano, P., Staab, S., & Tane, J. (2003). Deriving concept hierarchies text smooth formalconcept analysis. Proceedings GI Workshop Lehren Lernen - Wissen - Adaptivit(LLWA), pp. 7279.Day, W., & Edelsbrunner, H. (1984). Efficient algorithms agglomerative hierarchical clusteringmethods. Journal Classification, 1, 724.Duda, R. O., Hart, P. E., & Stork, D. G. (2001). Pattern Classification. John Wiley & Sons, Inc.Faure, D., & Nedellec, C. (1998). corpus-based conceptual clustering method verb framesontology. Velardi, P. (Ed.), Proceedings LREC Workshop Adapting lexicalcorpus resources sublanguages applications, pp. 512.Ganter, B., & Reuter, K. (1991). Finding closed sets: general approach. Order, 8, 283290.Ganter, B., & Wille, R. (1999). Formal Concept Analysis Mathematical Foundations. SpringerVerlag.Girju, R., & Moldovan, M. (2002). Text mining causal relations. Proceedings FLAIRSConference, pp. 360364.Goddard, W., & Swart, H. (1996). Distance graphs edge operations. Discrete Mathematics, 161, 121132.Godin, R., Missaoui, R., & Alaoui, H. (1995). Incremental concept formation algorithms basedgalois (concept) lattices. Computational Intelligence, 11(2), 246267.Grefenstette, G. (1994). Explorations Automatic Thesaurus Construction. Kluwer.Grefenstette, G. (1992). Evaluation techniques automatic semantic extraction: Comparing syntactic window-based approaches. Proceedings Workshop Acquisition Lexical Knowledge Text.Harris, Z. (1968). Mathematical Structures Language. Wiley.Hearst, M. (1992). Automatic acquisition hyponyms large text corpora. Proceedings14th International Conference Computational Linguistics (COLING), pp. 539545.Hindle, D. (1990). Noun classification predicate-argument structures. ProceedingsAnnual Meeting Association Computational Linguistics (ACL), pp. 268275.Hotho, A., Staab, S., & Stumme, G. (2003). Ontologies improve text document clustering.Prodeedings IEEE International Conference Data Mining (ICDM), pp. 541544.337fiC IMIANO , H OTHO , & TAABIwanska, L., Mata, N., & Kruger, K. (2000). Fully automatic acquisition taxonomic knowledgelarge corpora texts. Iwanksa, L., & Shapiro, S. (Eds.), Natural Language Processing Knowledge Processing, pp. 335345. MIT/AAAI Press.Lee, L. (1999). Measures distributional similarity. 37th Annual Meeting AssociationComputational Linguistics (ACL), pp. 2532.Lindig, C. (2000). Fast concept analysis. Stumme, G. (Ed.), Proceedings InternationalConference Conceptual Structures (ICCS). Shaker Verlag, Aachen, Germany.Maedche, A., Pekar, V., & Staab, S. (2002). Ontology learning part one - discovering taxonomicrelations web. Proceedings Web Intelligence conference, pp. 301322.Springer Verlag.Maedche, A., & Staab, S. (2002). Measuring similarity ontologies. ProceedingsEuropean Conference Knowledge Engineering Knowledge Management (EKAW), pp.251263. Springer Verlag.Maedche, A., & Staab, S. (2000). Discovering conceptual relations text. Horn, W. (Ed.),Proceedings 14th European Conference Artificial Intelligence (ECAI).Maher, P. (1993). similarity measure conceptual graphs. Intelligent Systems, 8, 819837.Manning, C., & Schuetze, H. (1999). Foundations Statistical Language Processing. MIT Press.Markert, K., Modjeska, N., & Nissim, M. (2003). Using web nominal anaphora resolution.EACL Workshop Computational Treatment Anaphora.Myaeng, S., & Lopez-Lopez, A. (1992). Conceptual graph matching: flexible algorithmexperiments. Experimental Theoretical Artificial Intelligence, 4, 107126.Pereira, F., Tishby, N., & Lee, L. (1993). Distributional clustering english words. Proceedings31st Annual Meeting Association Computational Linguistics (ACL), pp. 183190.Petersen, W. (2002). set-theoretical approach induction inheritance hierarchies. Electronic Notes Theoretical Computer Science, 51.Poesio, M., Ishikawa, T., im Walde, S. S., & Viera, R. (2002). Acquiring lexical knowledgeanaphora resolution. Proceedings 3rd Conference Language Resources Evaluation (LREC).Priss, U. (2004). Linguistic applications formal concept analysis. Stumme, G., & Wille, R.(Eds.), Formal Concept Analysis - State Art. Springer.Reinberger, M.-L., & Spyns, P. (2005). Unsupervised text mining learning dogma-inspiredontologies. Buitelaar, P., Cimiano, P., & Magnini, B. (Eds.), Ontology Learning Text:Methods, Evaluation Applications. IOS Press. appear.Resnik, P. (1997). Selectional preference sense disambiguation. Proceedings ACLSIGLEX Workshop Tagging Text Lexical Semantics: Why, What, How?Sanderson, M., & Croft, B. (1999). Deriving concept hierarchies text. Research Development Information Retrieval, pp. 206213.Schmid, H. (1994). Probabilistic part-of-speech tagging using decision trees. ProceedingsInternational Conference New Methods Language Processing.338fiL EARNING C ONCEPT H IERARCHIESEXT C ORPORAUSINGF ORMAL C ONCEPT NALYSISSchmid, H. (2000). Lopar: Design implementation. Arbeitspapiere des Sonderforschungsbereiches 340, No. 149.Sibson, R. (1973). SLINK: optimally efficient algorithm single-link cluster method.Computer Journal, 16(1), 3034.Sporleder, C. (2002). galois lattice based approach lexical inheritance hierarchy learning.Proceedings ECAI Workshop Machine Learning Natural Language ProcessingOntology Engineering (OLT 2002).Staab, S., Braun, C., Bruder, I., Dusterhoft, A., Heuer, A., Klettke, M., Neumann, G., Prager, B.,Pretzel, J., Schnurr, H.-P., Studer, R., Uszkoreit, H., & Wrenger, B. (1999). Getess - searching web exploiting german texts. Proceedings 3rd Workshop CooperativeInformation Agents, pp. 113124. Springer Verlag.Steinbach, M., Karypis, G., & Kumar, V. (2000). comparison document clustering techniques.KDD Workshop Text Mining.Stumme, G., Ehrig, M., Handschuh, S., Hotho, A., Maedche, A., Motik, B., Oberle, D., Schmitz, C.,Staab, S., Stojanovic, L., Stojanovic, N., Studer, R., Sure, Y., Volz, R., & Zacharias, V. (2003).karlsruhe view ontologies. Tech. rep., University Karlsruhe, Institute AIFB.Velardi, P., Fabriani, P., & Missikoff, M. (2001). Using text processing techniques automatically enrich domain ontology. Proceedings International Conference FormalOntology Information Systems (FOIS), pp. 270284.Velardi, P., Navigli, R., Cuchiarelli, A., & Neri, F. (2005). Evaluation ontolearn, methodologyautomatic population domain ontologies. Buitelaar, P., Cimiano, P., & Magnini, B.(Eds.), Ontology Learning Text: Methods, Evaluation Applications. IOS Press.appear.Voorhees, E. (1994). Query expansion using lexical-semantic relations. Proceedings 17thAnnual International ACM SIGIR Conference Research Development InformationRetrieval, pp. 6169.Zhang, K., Statman, R., & Shasha, D. (1992). editing distance unordered labeledtrees. Information Processing Letters, 42(3), 133139.Zhang, K., Wang, J., & Shasha, D. (1996). editing distance undirected acyclicgraphs. International Journal Foundations Computer Science, 7(1), 4357.Zipf, G. (1932). Selective Studies Principle Relative Frequency Language. Cambridge.339fiJournal Artificial Intelligence Research 24 (2005) 81-108Submitted 12/04; published 07/05Risk-Sensitive Reinforcement Learning Applied ControlConstraintsPeter Geibelpgeibel@uos.deInstitute Cognitive Science, AI GroupUniversity Osnabruck, GermanyFritz Wysotzkiwysotzki@cs.tu-berlin.deFaculty Electrical Engineering Computer Science, AI GroupTU Berlin, GermanyAbstractpaper, consider Markov Decision Processes (MDPs) error states. Errorstates states entering undesirable dangerous. define riskrespect policy probability entering state policypursued. consider problem finding good policies whose risk smalleruser-specified threshold, formalize constrained MDP two criteria.first criterion corresponds value function originally given. showrisk formulated second criterion function based cumulative return,whose definition independent original value function. present model free,heuristic reinforcement learning algorithm aims finding good deterministic policies.based weighting original value function risk. weight parameteradapted order find feasible solution constrained problem goodperformance respect value function. algorithm successfully appliedcontrol feed tank stochastic inflows lies upstream distillationcolumn. control task originally formulated optimal control problemchance constraints, solved certain assumptions model obtainoptimal solution. power learning algorithm used evenrestrictive assumptions relaxed.1. IntroductionReinforcement Learning, research area, provides range techniques applicable difficult nonlinear stochastic control problems (see e.g. Sutton & Barto, 1998;Bertsekas & Tsitsiklis, 1996). reinforcement learning (RL) agent consideredlearns control process. agent able perceive state process,acts order maximize cumulative return based real valued rewardsignal. Often, experiences process used improve agents policy insteadpreviously given analytical model.notion risk RL related fact, even optimal policy may performpoorly cases due stochastic nature problem. risk-sensitive RLapproaches concerned variance return, worst outcomes,(e.g. Coraluppi & Marcus, 1999; Heger, 1994; Neuneier & Mihatsch, 1999), see alsodiscussion section 3. take alternative view risk defined Geibel (2001)concerned variability return, occurrence errorsc2005AI Access Foundation. rights reserved.fiGeibel & Wysotzkiundesirable states underlying Markov Decision Process (MDP). meansaddress different class problems compared approaches referring variabilityreturn.paper, consider constrained MDPs two criteria usual value function risk second value function. value optimized riskmust remain specified threshold. describe heuristic algorithm basedweighted formulation finds feasible policy original constrained problem.order offer insight behavior algorithm, investigate application algorithm simple grid world problem discounted criterion function.apply algorithm stochastic optimal control problem continuous states,set feasible solutions restricted constraint required holdcertain probability, thus demonstrating practical applicability approach.consider control feed tank lies upstream distillation column respecttwo objectives: (1) outflow tank required stay close specified valueorder ensure optimal operation distillation column, (2) tank levelsubstance concentrations required remain within specified intervals, certainadmissible chance constraint violation.Li, Wendt, Arellano-Garcia, Wozny (2002) formulate problem quadraticprogram chance constraints1 (e.g. Kall & Wallace, 1994), relaxed nonlinearprogram case Gaussian distributions random input variables systemswhose dynamics given linear equations. nonlinear program solvedsequential quadratic programming.Note approach Li et al. involves simulation based estimationgradients chance constraints (Li et al., 2002, p. 1201). Like Q-learning (Watkins,1989; Watkins & Dayan, 1992; Sutton & Barto, 1998), learning algorithm basedsimulating episodes estimating value risk states, tank control taskcorrespond measure deviation optimal outflow probabilityconstraint violation, respectively.contrast approach Li et al. (2002), RL algorithm applicable systemscontinuous state spaces, whose system dynamics governed nonlinear equationsinvolve randomization noise arbitrary distributions random variables,makes prior assumptions either aspect. special propertylearning algorithm, also holds true e.g. Q-learning RL algorithms.convergence Q-learning combined function approximation techniques necessarycontinuous state spaces cannot guaranteed general (e.g. Sutton & Barto, 1998).holds true algorithm. Nevertheless, RL algorithms successfully appliedmany difficult problems continuous state spaces nonlinear dynamics (see e.g.Sutton & Barto, 1998; Crites & Barto, 1998; Smart & Kaelbling, 2002; Stephan, Debes,Gross, Wintrich, & Wintrich, 2001).1. constraint seen relation domains variables restricting possible values.variables constraint C = C(x1 , . . . , xn ) random, constraint hold certainprobability. Chance constrained programming particular approach stochastic programmingconsiders constrained optimization problems containing random variables so-called chanceconstraints form P(C) p p [0, 1] formulated.82fiRisk-Sensitive Reinforcement Learningarticle organized follows. section 2, RL framework described. Section 3 reviews related work risk-sensitive approaches. Section 4 describes approachrisk-sensitive RL. section 5, elucidate heuristic learning algorithm solvingconstrained problem using weighted formulation. section 6, describe applicationgrid world problem. tank control task described section 7. section 8,experiments feed tank control described. Section 9 concludes shortsummary outlook.2. RL FrameworkRL one considers agent interacts process controlled.discrete time-step, agent observes state x takes action u generaldepends x. action agent causes environment change state xaccording probability px,u (x ). section 7, consider set states, X,finite set.action set agent assumed finite, allowed dependcurrent state. state x, agent uses action set U (x) possible actions.taking action u U (x), agent receives real valued reinforcement signal rx,u (x )depends action taken successor state x . case random rewardsignal, rx,u (x ) corresponds expected value. Markov property MDP requiresprobability distribution successor states one rewards dependcurrent state action only. distributions change additionalinformation past states, actions rewards considered, i.e. independentpath leading current state.aim agent find policy selecting actions maximizescumulative reward, called return. return definedR=Xrt ,(1)t=0random variable rt denotes reward occurring t-th time stepagent uses policy . Let x0 , x1 , x2 , . . . denote corresponding probabilistic sequencestates, ui sequence actions chosen according policy .constant [0, 1] discount factor allows control influence futurerewards. expectation return,hV (x) = E R | x0 = x ,(2)defined value x respect . well-known exist stationarydeterministic policies V (x) optimal (maximal) every state x. stationary deterministic policy function maps states actions particularly definedindependent time Markovian (independent history). work,use term maximum-value policies instead optimal policies distinguishminimum-risk policies also optimal sense, see section 4.1.usual, define state/action value functionfifihQ (x, u) = E r0 + V (x1 ) fi x0 = x, u0 = u .83(3)fiGeibel & WysotzkiQ (x, u) expected return agent first chooses action u, acts accordingsubsequent time steps. optimal Q-function Q , optimal policiesunique optimal values V derived (x) argmaxu Q (x, u) V (x) = Q (x, (x)).Q computed using Watkins Q-learning algorithm.RL one general distinguishes episodic continuing tasks treatedframework (see e.g. Sutton & Barto, 1998). episodic tasks, agent mayreach terminal absorbing state time . reaching absorbing state,agent stays executes dummy action. reward defined rt = 0. learning agent restarted according distributioninitial states reached absorbing state.3. Related WorkPrandom variable R =t=0 rt (return) used define value state possessescertain variance. risk-averse approaches dynamic programming (DP) reinforcement learning concerned variance R, worst outcomes.example approach worst case control (e.g. Coraluppi & Marcus, 1999; Heger,1994), worst possible outcome R optimized. risk-sensitive control based use exponential utility functions (e.g. Liu, Goodwin, & Koenig, 2003a;Koenig & Simmons, 1994; Liu, Goodwin, & Koenig, 2003b; Borkar, 2002), return Rtransformed reflect subjective measure utility. Instead maximizingexpected value R, objective maximize e.g. U = 1 log E(eR ),parameter R usual return. shown depending parameter, policies high variance V(R) penalized ( < 0) enforced ( > 0). value-criterion introduced Heger (1994) seen extension worst case controlbad outcomes policy occur probability less neglected.Neuneier Mihatsch (1999) give model- free RL algorithm basedparameterized transformation temporal difference errors occurring (see also Mihatsch& Neuneier, 2002). parameter transformation allows switch riskaverse risk-seeking policies. influence parameter value function cannotexpressed explicitly.view risk concerned variance return worst possibleoutcomes, instead fact processes generally possess dangerous undesirable states. Think chemical plant temperature pressure exceedingthreshold may cause plant explode. controlling plant, return corresponds plants yield. seems inappropriate let return also reflectcost explosion, e.g. human lives affected.work, consider processes undesirable terminal states. seemingly straightforward way handle error states system provide highnegative rewards systems enters error state. optimal policy avoiderror states general. drawback approach fact unknownlarge risk (probability) entering error state is. Moreover, may want providethreshold probability entering error state must exceededagents policy. general, impossible completely avoid error states, riskcontrollable extend. precisely, agent placed state84fiRisk-Sensitive Reinforcement Learningx, follow policy whose risk constrained . parameter [0, 1]reflects agents risk-averseness. is, goal minimization risk,maximization V risk kept threshold .Markowitz (1952) considers combination different criteria equal discountfactors context portfolio selection. risk selected portfolio relatedvariance combined (weighted) criteria. Markowitz introduces notion(E, V )-space. notion risk related variance V , dependsoccurrence error states MDP. Therefore risk conceptually independent V ,see e.g. tank control problem described section 7.idea weighting return risk (Markowitz, 1959; Freund, 1956; Heger, 1994) leadsexpected-value-minus-variance-criterion, E(R) kV(R), k parameter.use idea computing feasible policy problem finding good policyconstrained risk (in regard probability entering error state): valuerisk weighted using weight value weight 1 risk. valueincreased, giving value weight compared risk, risk statebecomes larger user-specified threshold .considering ordering relation tuples values, learning algorithmfixed value also related ARTDP approach Gabor, Kalmar, Szepesvari(1998). article, Gabor et al. additionally propose recursive formulationMDP constraints may produce suboptimal solutions. applicablecase approach requires nonnegative reward function.noted aforementioned approaches based variabilityreturn suited problems like grid world problem discussed section 6,tank control task section 7 risk related parameters (variables) statedescription. example, grid world problem, policies worst caseoutcome. regard approaches based variance, found policy leadingerror states fast possible higher variance one reachesgoal states fast possible. policy small variance therefore large risk(with respect probability entering error state), means addressdifferent class control problems. underpin claim section 8.1.3.Fulkerson, Littman, Keim (1998) sketch approach framework probabilistic planning similar although based complementary notionsafety. Fulkerson et al. define safety probability reaching goal state (see alsoBURIDAN system Kushmerick, Hanks, & Weld, 1994). Fulkerson et al. discussproblem finding plan minimum cost subject constraint safety (seealso Blythe, 1999). episodic MDP goal states, safety 1 minus risk.continuing tasks absorbing states neither goal error states,safety may correspond smaller value. Fulkerson et al. (1998) manipulate (scale)(uniform) step reward undiscounted cost model order enforce agent reachgoal quickly (see also Koenig & Simmons, 1994). contrast, also considerdiscounted MDPs, neither require existence goal states. Althoughchange original reward function, algorithm section 5 seen systematicapproach dealing idea Fulkerson et al. consists modificationrelative importance original objective (reaching goal) safety. contrastaforementioned approaches belonging field probabilistic planning,85fiGeibel & Wysotzkioperate previously known finite MDP, designed online learning algorithmuses simulated actual experiences process. use neural networktechniques algorithm also applied continuous-state processes.Dolgov Durfee (2004) describe approach computes policiesconstrained probability violating given resource constraints. notion risksimilar described Geibel (2001). algorithm given Dolgov Durfee(2004) computes suboptimal policies using linear programming techniques requirepreviously known model and, contrast approach, cannot easily extendedcontinuous state spaces. Dolgov Durfee included discussion DP approachesconstrained MDPs (e.g. Altman, 1999) also generalize continuous statespaces (as tank control task) require known model. algorithm describedFeinberg Shwartz (1999) constrained problems two criteria applicablecase, requires discount factors strictly smaller 1,limited finite MDPs.Downside risk common notion finance refers likelihood securityinvestment declining price, amount loss could resultpotential decline. scientific literature downside risk (e.g. Bawas, 1975; Fishburn,1977; Markowitz, 1959; Roy, 1952) investigates risk-measures particularly considercase return lower mean value, target value encountered.contrast, notion risk coupled return R, fact statex error state, example, parameters describing state lie outsidepermissible ranges, state lies inside obstacle may occurrobotics applications.4. Riskdefine notion risk precisely, consider setX(4)error states. Error states terminal states. means control agentends reaches state . allow additional set non-error terminal states= .Now, define risk x respect probability state sequence(xi )i0 x0 = x, generated executing policy , terminates error statex .Definition 4.1 (Risk) Let policy, let x state. risk defined(x) = P xi | x0 = x .(5)definition, (x) = 1 holds x . x , (x) = 0 = .states 6 , risk depends action choices policy .following subsection, consider computation minimum-risk policiesanalogous computation maximum-value policies.86fiRisk-Sensitive Reinforcement Learning4.1 Risk Minimizationrisk considered value function defined cost signal r. see this,augment state space MDP additional absorbing stateagent transfered reaching state . state introduced technicalreasons.agent reaches state , reward signals r r become zero.set r = 0 r = 1, agent reaches error state. stateslonger absorbing states. new cost function r definedrx,u (x ) =(1 x x =0 else.(6)construction cost function r, episode states, actions costsstarting initial state x contains exactly cost r = 1 error stateoccurs it. process enter error state, sequence r-costs containszeros only. Therefore, probability defining risk expressed expectationcumulative return.Proposition 4.1 holds(x) = E"Xi=0discount factor = 1.#fifiri fi x0 = x(7)Proof: r0 , r1 , . . . probabilistic sequence costs related risk. statedPabove, holds R =defi=0 ri = 1 trajectory leads error state; otherwisePi=0 ri = 0. means return R Bernoulli random variable,probability q R = 1 corresponds risk x respect . Bernoulli randomvariable holds ER = q (see e.g. Ross, 2000). Notice introduction togetherfact r = 1 occurs transition error stateiwhenfihP ,fientering respective error state, ensures correct value Ei=0 ri fi x0 = x alsoerror states x. q.e.d.Similar Q-function define state/action riskhQ (x, u) = E r0 + (x1 ) | x0 = x, u0 = u=Xpx,u (x ) rx,u (x ) + (x ) .x(8)(9)Minimum-risk policies obtained variant Q-learning algorithm (Geibel,2001).4.2 Maximized Value, Constrained Riskgeneral, one interested policies minimum risk. Instead, want provideparameter specifies risk willing accept. Let X X setstates interested in, e.g. X = X ( {}) X = {x0 } distinguished87fiGeibel & Wysotzkistarting state x0 . state x X , let px probability selecting startingstate. valueXV =defpx V (x)(10)xXcorresponds performance states X . consider constrained problemmax V(11)x X : (x) .(12)subjectpolicy fulfills (12) called feasible. Depending , set feasible policiesmay empty. Optimal policies generally depend starting state, nonstationary randomized (Feinberg & Shwartz, 1999; Gabor et al., 1998; Geibel, 2001).restrict considered policy class stationary deterministic policies, constrainedproblem generally well defined X singleton, needstationary deterministic policy optimal states X . Feinberg Shwartz(1999) shown case two unequal discount factors smaller 1exist optimal policies randomized Markovian time step n (i.e.depend history, may non-stationary randomized), stationarydeterministic (particularly Markovian) time step n onwards. Feinberg Shwartz(1999) give DP algorithm case (cp. Feinberg & Shwartz, 1994). cannotapplied case = 1, also generalize continuous statespaces. case equal discount factors, shown Feinberg Shwartz (1996)(for fixed starting state) also exist optimal stationary randomized policiescase one constraint consider one action stationary deterministicpolicy, i.e. one state policy chooses randomly twoactions.5. Learning Algorithmreasons efficiency predictability agents behaviorsaid end last section, restrict consideration stationary deterministic policies. following present heuristic algorithm aimscomputing good policy. assume reader familiar Watkins Q-learningalgorithm (Watkins, 1989; Watkins & Dayan, 1992; Sutton & Barto, 1998).5.1 Weighting Risk Valuedefine new (third) value function V state/action value function Qweighted sum risk valueV (x) = V (x) (x)Q (x, u)= Q (x, u) Q (x, u) .(13)(14)parameter 0 determines influence V -values (Q -values) compared-values (Q -values). = 0, V corresponds negative . means88fiRisk-Sensitive Reinforcement Learningmaximization V0 lead minimization . , maximizationV leads lexicographically optimal policy unconstrained, unweighted 2-criteriaproblem. one compares performance two policies lexicographically, criteriaordered. large values , original value function multiplied dominatesweighted criterion.weight successively adapted starting = 0, see section 5.3. adaptation, discuss learning fixed proceeds.5.2 Learning fixedfixed value , learning algorithm computes optimal policy usingalgorithm resembles Q-Learning also based ARTDP approach Gaboret al. (1998).learning, agent estimates Qt , Qt time 0, thus estimateQt performance current greedy policy, policy selects bestaction respect current estimate Qt . values updated using examplestate transitions: let x current state, u chosen action, x observedsuccessor state. reward risk signal example state transition givenr r respectively. x , greedy action defined following manner: actionu preferable u Qt (x , u) > Qt (x , u ) holds. equality holds, actionhigher Qt -value preferred. write u u , u preferable u .Let u greedy action x respect ordering . agentsestimates updated accordingQt+1 (x, u) = (1 )Qt (x, u) + (r + Qt (x , u ))(15)Qt+1 (x, u) = (1 )Qt (x, u) + (r + Qt (x , u ))(16)t+1Qt+1(x, u) Qt+1 (x, u)(x, u) = Q(17)Every time new chosen, learning rate set 1. Afterwards decreasestime (cp. Sutton & Barto, 1998).fixed , algorithm aims computing good stationary deterministic policyweighted formulation feasible original constrained problem. Existenceoptimal stationary deterministic policy weighted problem convergencelearning algorithm guaranteed criteria discount factor, i.e.= , even < 1. case = , Q forms standard criterion functionrewards r r. consider risk second criterion function, = implies= = 1. ensure convergence case also required either (a)exists least one proper policy (defined policy reaches absorbing stateprobability one), improper policies yield infinite costs (see Tsitsiklis, 1994), (b),policies proper. case application example. conjecturecase < convergence possibly suboptimal policy guaranteed MDP formsdirected acyclic graph (DAG). cases oscillations non-convergence may occur,optimal policies weighted problem generally found consideredpolicy class stationary deterministic policies (as constrained problem).89fiGeibel & Wysotzki5.3 Adaptationlearning starts, agent chooses = 0 performs learning steps lead,time, approximated minimum-risk policy 0 . policy allows agentdetermine constrained problem feasible.Afterwards value increased step step risk state X becomeslarger . Increasing increases influence Q-values comparedQ-values. may cause agent select actions result higher value,perhaps also higher risk. increasing , agent performs learningsteps greedy policy sufficiently stable. aimed producing optimaldeterministic policy . computed Q- Q-values old (i.e. estimates.Q Q ) used initialization computing +aim increasing give value function V maximum influence possible.means value maximized, needs chosen user.adaptation provides means searching space feasible policies.5.4 Using Discounted Riskorder prevent oscillations algorithm section 5.2 case < , mayadvisable set = corresponding using discounted risk defined(x)=E"Xi=0#fifiri fi x0 = x .(18)values ri positive, holds (x) (x) states x. discounted risk (x) gives weight error states occurring near future, dependingvalue .finite MDP fixed , convergence algorithm optimal stationarypolicy weighted formulation guaranteed Q (using (x)) formsstandard criterion function rewards r r. terminating adaptationcase risk state X becomes larger , one might still use original(undiscounted) risk (x) learning done discounted version (x), i.e.learning algorithm maintain two risk estimates every state, majorproblem. Notice case = , effect considering weighted criterionV corresponds modifying unscaled original reward function r addingnegative reward 1 agent enters error state: set optimal stationarydeterministic policies equal cases (where added absorbing statesingle dummy action neglected).section 6, experiments case < 1 = , X = X ( {}), finitestate space found. sections 7 8 consider application exampleinfinite state space, X = {x0 }, = = 1.6. Grid World Experimentfollowing study behaviour learning algorithm finite MDPdiscounted criterion. contrast continuous-state case discussed next90fiRisk-Sensitive Reinforcement LearningEEEa)EE GE EEEEc)EE GE EE GEEb)EE GE E E E E EE GEEd)EE GE E E E E EGEEEEE EGE EFigure 1: a) example grid world, x : horizontal, : vertical. explanation seetext. b) Minimum risk policy ( = 0) 11 unsafe states. c) Maximum valuepolicy ( = 4.0) 13 unsafe states. d) Result algorithm: policy = 0.6411 unsafe states.section, function approximation neural networks needed valuefunction risk stored table. grid world, chosen <1 = , X = X , state graph DAG. impliesstationary policy optimal every state X . Although oscillations thereforeexpected, found algorithm stabilizes feasible policylearning rate tends zero. also investigated use discounted riskprevents oscillatory behaviour.consider 6 6 grid world depicted Figure 1(a). empty field denotesstate, Es denote error states, two Gs denote two goal states. describestates pairs (x, y) x, {1, 2, 3, 4, 5, 6}. I.e. = {(2, 2), (6, 6)}, = {(1, 1), (1,2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)}. additional absorbingstate depicted.chosen error states lower, i.e. extremal values xdangerous. One goal states placed next error states, saferpart state space.agent actions U = {, , , }. action u U takes agentdenoted direction possible. probability 0.21, agent transporteddesired direction one three remaining directions.agent receives reward 1 enters goal state. agent receives reward0 every case. noted explicit punishment enteringerror state, implicit one: agent enters error state, currentepisode ends. means agent never receive positive rewardreached error state. Therefore, try reach one goal states,< 1, try fast possible.91fiGeibel & Wysotzkichosen X = X ( {}), = 0.9, equal probabilities px states.Although convergence algorithm cannot guaranteed case, experimental results show algorithm yields feasible policy.selected = 0.13. order illustrate behaviour algorithmalso computed minimum-risk maximum-value policy. Figure 1(b) showsminimum risk policy. Though reward function r defined plays roleminimum risk policy, agent tries reach one two goal states.goal state probability reaching error state 0. Clearly, respectvalue function V , policy Figure 1(b) optimal: e.g. state (3, 3) agenttries reach distant goal, causes higher discounting goal reward.minimum risk policy Figure 1(b) 25 safe states, defined statesrisk . minimum risk policy estimated mean value V = 0.442.Figure 1(c) maximum-value policy shown. maximum-value policyoptimizes value without considering risk estimated value V = 0.46.Thus, performs better minimum-risk policy Figure 1(b), risk (5, 2)(2, 5) become greater . algorithm starts = 0 computesminimum-risk policy Figure 1(b). increased step step risk statechanges value lower value > . algorithm stops = 0.64.policy computed shown Figure 1(d). Obviously, lies minimum riskpolicy Figure 1(b) maximum-value policy Figure 1(c).also applied algorithm discounted version risk, , gridworld problem. discounted risk used learning, whereas original risk, ,used selecting best weight . parameters described above, modifiedalgorithm also produced policy depicted figure 1(d). Seemingly, grid worldexample, oscillations present major problem.tank control task described next section, holds == .7. Stochastic Optimal Control Chance Constraintssection, consider solution stochastic optimal control problem chanceconstraints (Li et al., 2002) applying risk-sensitive learning method.7.1 Description Control Problemfollowing, consider plant depicted Figure 2. task controloutflow tank lies upstream distillation column order fulfill severalobjectives described below. purpose distillation column separationtwo substances 1 2. consider finite number time steps 0, . . . , N . outflowtank, i.e. feedstream distillation column, characterized flowrateF (t) controlled agent, substance concentrations c1 (t) c2 (t) (for0 N ).purpose control designed keep outflow rate F (t) near specifiedoptimal flow rate Fspec order guarantee optimal operation distillation column.92fiRisk-Sensitive Reinforcement LearningF1c11c12distillation columnF2c21c22ymaxy, h, c1, c2yminFtankFspecc1min, c1maxc2min, c2maxFigure 2: plant. See text description.Using quadratic objective function, goal specifiedminF (0),...,F (N 1)N1X(F (t) Fspec )2 ,(19)t=0values obey0 N 1 : Fmin F (t) Fmax .(20)tank characterized tank level y(t) holdup h(t), = A1 hconstant footprint tank. tank level y(t) concentrationsc1 (t) c2 (t) depend two stochastic inflow streams characterized flowratesF1 (t) F2 (t), inflow concentrations c1,j (t) c2,j (t) substances j {1, 2}.linear dynamics tank level giveny(t + 1) = y(t) + A1XFj (t) F (t) .(21)A1 XFj (t)(cj,i (t) ci (t))(y(t) j=1,2(22)j=1,2dynamics concentrations given= 1, 2 : ci (t + 1) = ci (t) +initial state system characterizedy(0) = y0 , c1 (0) = c01 , c2 (0) = c02 .(23)tank level required fulfill constraint ymin y(t) ymax . concentrations inside tank correspond concentrations outflow. substanceconcentrations c1 (t) c2 (t) required remain intervals [c1,min , c1,max ]93fiGeibel & Wysotzki[c2,min , c2,max ], respectively. assume inflows Fi (t) inflow concentrationsci,j (t) random, governed probability distribution. Li et al. (2002)assume multivariate Gaussian distribution. randomness variables,tank level feedstream concentrations may violate given constraints.therefore formulate stochastic constraintP ymin y(t) ymax , ci,min ci (t) ci,max , 1 N, = 1, 2 p(24)expression (24) called (joint) chance constraint, 1 p correspondspermissible probability constraint violation. value p given user.stochastic optimization problem SOP-YC defined quadratic objective function (19) describing sum quadratic differences outflow rates Fspec ,linear dynamics tank level (21), nonlinear dynamics concentrations(22), initial state given (23), chance constraint (24).Li et al. describe simpler problem SOP-Y concentrations considered;see Figure 3. SOP-Y use cumulative inflow F = F1 + F2 descriptiontank level dynamics, see (27). SOP-Y describes dynamics linear system.Li et al. solve SOP-Y relaxing nonlinear program solved sequentialquadratic programming. relaxation possible SOP-Y linear system,multivariate Gaussian distribution assumed. Solving nonlinear systems like SOP-YCnon-Gaussian distributions difficult (e.g. Wendt, Li, & Wozny, 2002),achieved RL approach.minF (0),...,F (N 1)subject0 N 1 :y(t + 1)N1X(F (t) Fspec )2(25)t=0Fmin F (t) Fmax= y(t) + A1 F (t) F (t)y(0) = y0P ymin y(t) ymax , 1 N p(26)(27)(28)(29)Figure 3: problem SOP-Y.Note control F (t) optimization problems depends time stept. means solutions SOP-YC SOP-Y yield open loop controls.dependence initial condition (23), moving horizon approach takendesign closed loop control. discuss issue, goes beyond scopepaper.94fiRisk-Sensitive Reinforcement Learning7.2 Formulation Reinforcement Learning ProblemUsing RL instead analytical approach advantage probability distribution doesnt Gaussian unknown. state equations also needknown, nonlinear. learning agent must access simulatedempirical data, i.e. samples least random variables.Independent chosen state representation, immediate reward definedrx,u (x ) = (u Fspec )2 ,(30)u chosen action minus required RL value functionmaximized. reward signal depends action chosen, currentsuccessor state.work consider finite (discretized) action sets, although approachalso extended continuous action sets, e.g. using actor-critic method (Sutton &Barto, 1998). following, assume interval [Fmin , Fmax ] discretizedappropriate manner.process reaches error state one constraints (24) (or (29), respectively) violated. process artificially terminated transferring agentadditional absorbing state giving risk signal r = 1. V -value error statesset zero, controller could choose action Fspec first constraintviolation, subsequent constraint violations make things worse respectchance constraints (24) (29), respectively.7.3 Definition State Spacefollowing consider design appropriate state spaces result eitheropen loop control (OLC) closed loop control (CLC).7.3.1 Open Loop Controlnote SOP-YC SOP-Y time-dependent finite horizon problemscontrol F (xt ) = F (t) depends only. means state feedbackresulting controller open-looped. respect state definition xt = (t),Markov property defined section 2 clearly holds probabilities rewards definingV . Markov property hold rewards defining . Using xt = (t)implies agent information state process. includinginformation history form past action, agent gets ideacurrent state process. Therefore, inclusion history information changesprobability r = 1, Markov property violated. Including past actionsstate description ensures Markov property r. Markov property thereforerecovered considering augmented state definitionxt = (t, ut1 , . . . , u0 ) ,(31)past actions (ut1 , . . . , u0 ). first action u0 depends fixed initial tank level y0fixed initial concentrations only. second action depends first action, i.e.also initial tank level initial concentrations on. Therefore, learning95fiGeibel & Wysotzkistates (31) results open loop control, original problems SOP-YCSOP-Y.noted MDP, risk depend past actions,future actions only. choice xt = (t), hidden state information,MDP Markov property violated. Therefore probabilityentering error state conditioned time step, i.e. P (r0 = 1|t), changesadditionally conditioned past actions yielding value P (r0 = 1|t, ut1 , . . . , u0 )(corresponding agent remembers past actions). example, agentremembers past time steps current learning episode always usedaction F = 0 corresponding zero outflow, conclude increasedprobability tank level exceeds ymax , i.e. knowledge increased risk.If, hand, remember past actions, cannot know increasedrisk knows index current time step, carries less informationcurrent state.well-known Markov property generally recovered includingcomplete state history state description. xt = (t), state history containspast time indices, actions r-costs. tank control task, action historyrelevant part state history previous r-costs necessarily zero,indices past time steps already given actual time knownagent. Therefore, past rewards indices past time steps needincluded expanded state. Although still complete state informationknown agent, knowledge past actions suffices recover Markov property.respect state choice (31) reward signal (30), expectationdefinition value function needed, cp. eq. (2). meanshV (x) = E R | x0 = x =N1X(F (t) Fspec )2t=0holds, i.e. direct correspondence value function objectivefunction SOP-YC SOP-Y.7.3.2 Closed Loop Controldefine alternative state space, expectation needed.decided use state definitionxt = (t, y(t), c1 (t), c2 (t))(32)xt = (t, y(t))(33)problem SOP-YCsimpler problem SOP-Y. result learning state time-dependent closedloop controller, achieve better regulation behavior open loop controller,reacts actual tank level concentrations, whereas open loop controlnot. agent access inflow rates concentrations,included state vector, yielding improved performance controller.96fiRisk-Sensitive Reinforcement LearningParameterNy0[ymin , ymax ]A1Fspec[Fmin , Fmax ]RL-YC-CLC:c01c02[c1,min , c1,max ][c2,min , c2,max ]Table 1: Parameter settingsValueExplanation16number time steps0.4initial tank level[0.25, 0.75] admissible interval tank level0.1constant, see (22)0.8optimal action value[0.55, 1.05] interval actions, 21 discrete values0.20.8[0.1, 0.4][0.6, 0.9]initial concentration subst. 1initial concentration subst. 2interval concentration 1interval concentration 27.4 RL Problemsdefinitions, optimization problem defined via (11) (12)= 1p (see (24) (29)). set X (see (10) (12)) defined contain uniquestarting state, i.e X = {x0 }. experiments consider following instantiationsRL problem:RL-Y-CLC Reduced problem SOP-Y using states xt = (t, y(t)), x0 = (0, y0 ) resulting closed loop controller (CLC).RL-Y-OLC Open loop controller (OLC) reduced problem SOP-Y. state spacedefined action history time, see eq. (31). starting state x0 = (0).RL-YC-CLC Closed loop controller full problem SOP-YC using states xt =(t, y(t), c1 (t), c2 (t)) x0 = (0, y0 , c01 , c01 ).Solving problem RL-Y-OLC yields action vector. problems RL-YC-CLCRL-Y-CLC result state dependent controllers. present results fourthnatural problem RL-YC-OLC, offer additional insights.interpolation states used 2 16 multilayer perceptrons (MLPs, e.g.Bishop, 1995) case RL-Y-OLC extremely large state space (15 dimensions = N 1). used radial basis function (RBF) networks caseRL-YC-CLC RL-Y-CLC, produced faster, stable robust resultscompared MLPs.training respective networks, used direct method correspondsperforming one gradient descent step current state-action pair newestimate target value (see e.g. Baird, 1995). new estimate Q givenr + Qt (x , u ), Q r + Qt (x , u ) (compare right sides updateequations (15)-(17)).97fiGeibel & Wysotzki(a)21.81.61.41.210.80.60.40.20outflow rateInflow(b)024610.950.90.850.80.750.70.658 10 12 14 16time(c)omega=0.010.802468 10 12 14 16timeomega=0.050.8outflow rateoutflow rate(d)10.950.90.850.80.750.70.6502468 10 12 14 16time10.950.90.850.80.750.70.65omega=0.10.802468 10 12 14 16timeFigure 4: RL-Y-CLC: (a) inflow rates F (t) 10 runs. (b), (c), (d) Example runspolicies = 0.01, 0.05, 0.10 (i.e. p = 0.99, 0.95, 0.90). holds Fspec = 0.8.8. Experimentssection, examine experimental results obtained tank control task( = = 1). section 8.1 discuss linear case compare results Liet al. (2002). linear case, consider closed loop controller obtained solvingRL-Y-CLC (sect. 8.1.1) open loop controller related RL problem RL-Y-OLC(sect. 8.1.2). closed loop controller, discuss problem non-zero covariancesvariables different time steps. nonlinear case discussed section 8.2.8.1 Problems RL-Y-CLC RL-Y-OLCstart simplified problems, RL-Y-CLC RL-Y-OLC, derived SOP-Ydiscussed Li et al. (2002). SOP-Y concentrations considered,one inflow rate F (t) = F1 (t) + F2 (t). parameter settings Table 1 (first fivelines) taken Li et al. (2002). minimum maximum values actionsdetermined preliminary experiments.Li et al. define inflows (F (0), . . . , F (15))T Gaussian distributionmean vector(1.8, 1.8, 1.5, 1.5, 0.7, 0.7, 0.5, 0.3, 0.2, 0.2, 0.2, 0.2, 0.2, 0.6, 1.2, 1.2)T .98(34)fiRisk-Sensitive Reinforcement Learning0.30.20.1risk0-0.1value-0.2weighted-0.3-0.4-0.505101520xiFigure 5: RL-Y-CLC: Estimates risk (x0 ), value V (x0 ), V (x0 ) =V (x0 ) (x0 ) different values .covariance matrix givenC=0 1 r01020 1 r01...0 N 1 r0(N 1)0 N 1 r0(N 1)......2N1(35)= 0.05. correlation inflows time j definedrij = rji = 1 0.05(j i)(36)0 N 1, < j N 1 (from Li et al., 2002). inflow rates ten exampleruns depicted Figure 4(a).8.1.1 Problem RL-Y-CLC (Constraints Tank Level)start presentation results problem RL-Y-CLC, control(i.e. outflow F ) depends time tank level. X = {x0 }overall performance policy defined (10) corresponds performance x0 ,V = V (x0 ) .holds x0 = (0, y0 ). V (x0 ) value respect policy learnedweighted criterion function V , see also (13). respective risk(x0 ) .Figure 5 estimated2 risk (x0 ) estimated value V (x0 ) depicteddifferent values . estimate risk (x0 ) value V (x0 )2. values policies presented following estimated learning algorithm. Noteorder enhance readability, also denoted learned policy .99fiGeibel & Wysotzki0.50.40.30.20.10-0.10 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20xiFigure 6: RL-Y-CLC: Difference weighted criteria. explanation see text.increase . Given fixed value p admissible probability constraint violation,appropriate = (p) obtained value risk (x0 ) lower= 1p maximum V (x0 ). Due variation performance (seeFig. 5) found works better selecting maximum . estimateweighted criterion V (x0 ) = V (x0 ) (x0 ) also shown Figure 5.outflow rate F (control variable) different values found Figure 4(bc). Note rates certain variance since depend probabilistic tanklevel. randomly picked one example run value . found controlvalues F (t) tend approach Fspec increasing values (i.e. decreasing values p).Correlations definition covariance matrix (35) (36) reveals highcorrelation inflow rates neighboring time steps. order better account this,possible include information past time steps state description time t.level changes according inflow rate F , investigated inclusionpast values y. inflow rates measured, could includedstate vector. Former rewards need included depend past tanklevels, i.e. represent redundant information.compared performance algorithm augmented state spacedefined xt = (t, y(t), y(t 1), y(t 2)) (depth 2 history) normal state spacext = (t, y(t)) (no history). Fig. 6 showsV (0, y0 , 0, 0) V (0, y0 ) ,|{zx0}| {z }x0i.e. difference weighted criteria starting state respect learnedpolicies (history) (no history). Note starting state x0 , past valuesdefined 0. curve Figure 6 runs mainly 0. means usingaugmented state space results better performance many values . Note100fiRisk-Sensitive Reinforcement Learning(a)(b)0.31Risk0.20.950.1outflow rate0.90-0.1Value-0.20.850.80.75-0.30.7-0.40.65024681012140xi2468time101214Figure 7: RL-Y-OLC: (a) Estimates risk (x0 ) value V (x0 ) increasingvalues . (b) Learned policy (x0 ) 0.098 V (x0 ) 0.055larger values original value function overweights risk casespolicy always chooses outflow Fspec approximated. meansdifference performance tends zero.similar, quite pronounced effect observed using historylength 1 only. principle, assume possible achieve even better performanceincluding full history tank levels state description, tradeoff objective difficulty network training caused numberadditional dimensions.8.1.2 RL-Y-OLC (History Control Actions)RL problem RL-Y-OLC comprises state descriptions consisting action historytogether time, see eq. (31). starting state empty history, i.e. x0 = (0).result learning time-dependent policy implicit dependence y0 .learned policy therefore fixed vector actions F (0), . . . , F (15) forms feasible,general suboptimal solution problem SOP-Y Figure 3.progression risk estimate, i.e. (x0 ), value, V (x0 ),different values found Figure 7. results good onesRL-Y-CLC Figure 5: estimated minimum risk 0.021, risk (x0 ) growsmuch faster RL-Y-CLC-risk Figure 5.policy risk (x0 ) 0.098 depicted Figure 7(b). contrastpolicies RL-Y-CLC (see Figure 4(b-c)), control values change different runs.8.1.3 ComparisonTable 2, compared performance approach Li et al. RL-Y-CLCRL-Y-OLC p = 0.8 p = 0.9. RL-Y-CLC RL-Y-OLC performed 10learning runs. respective learned policy , risk (x0 ) value V (x0 )estimated 1000 test runs. RL-Y-CLC RL-Y-OLC, table shows meanperformance averaged 10 runs together standard deviation parentheses.101fiGeibel & WysotzkiTable 2: Comparison est. squared deviation Fspec (i.e. V (x0 )) results Li etal. results RL-Y-CLC RL-Y-OLC p = 0.8 ( = 0.2) p = 0.9( = 0.1). Smaller values better.approachLi et al. (2002)RL-Y-CLCRL-Y-OLCp = 0.80.01230.00758 (0.00190)0.0104 (0.000302)p = 0.90.04840.02 (0.00484)0.0622 (0.0047)found that, average, policy determined RL-Y-CLC performs betterobtained approach Li et al. (2002) (with respect estimated squareddeviation desired outflow Fspec , i.e. respect V (x0 ).) policy obtainedRL-Y-OLC performs better p = 0.8 worse p = 0.9. maximal achievableprobability holding constraints 1.0 (sd 0.0) RL-Y-CLC, 0.99 (sd 0.0073)RL-Y-OLC. Li et al. report p = 0.999 approach.approach Neuneier Mihatsch (1999) considers worst-case outcomespolicy, i.e. risk related variability return. Neuneier Mihatsch showlearning algorithm interpolates risk-neutral worst-case criterionlimiting behavior exponential utility approach.0.6riskvalue0.50.40.3risk0.2value0.10-0.1-1-0.500.51kappaFigure 8: Risk value several valueslearning algorithm Neuneier Mihatsch parameter (1.0, 1.0)allows switch risk-averse behavior ( 1), risk-neutral behavior ( = 0),risk-seeking behavior ( 1). agent risk-seeking, prefers policiesgood best-case outcome. Figure 8 shows risk (probability constraint violation) valuestarting state regard policy computed algorithm NeuneierMihatsch. Obviously, algorithm able find maximum-value policy yielding zerodeviation Fspec , corresponding choosing F = Fspec = 0.8 states, learningresult sensitive risk parameter . reason worst-casebest-case returns policy always chooses outflow 0.8 also correspond102fiRisk-Sensitive Reinforcement Learning(a)Inflow(b)110.80.8ymaxmu(t)+0.040.60.60.40.4mu(t)-0.04c1maxc1ymin0.20.2c1min00024681012140Time246810121416TimeFigure 9: RL-YC-CLC: (a) (t) + 0.04 (t) 0.04 (profiles two mode means).(b) tank level y(t) concentration c1 (t) 10 example runs usingminimum risk policy.0, best return possible (implying zero variance return). approachNeuneier Mihatsch variance-based approaches therefore unsuitedproblem hand.8.2 Problem RL-YC-CLC (Constraints Tank Level Concentrations)following consider full problem RL-YC-CLC. two inflows F1 F2assumed equal Gaussian distributions distribution cumulativeinflow F (t) = F1 (t) + F2 (t) described covariance matrix (35) meanvector (34); see also Figure 4(a).order demonstrate applicability approach non-Gaussian distributions,chosen bimodal distributions inflow concentrations c1 c2 . underlyingassumption upstream plants either increased output,lower output, e.g. due different hours weekdays.distribution inflow concentration ci,1 (t) characterized two Gaussiandistributions means(t) + (1)k 0.04 ,k = 1, 2 2 = 0.0025. value k {0, 1} chosen beginningrun equal probability outcome. means overall mean valueci,1 (t) given (t). profiles mean values modes foundFigure 9(a). ci,2 given ci,2 (t) = 1.0 ci,1 (t). minimum maximum valuesconcentrations ci (t) found Table 1, also Figure 9(b). Noteconcentrations controlled indirectly choosing appropriate outflow F .developing risk value starting state shown Figure 10.resulting curves behave similar problem RL-Y-CLC depicted Figure 5:value risk increase . seen algorithm covers relativelybroad range policies different value-risk combinations.103fiGeibel & Wysotzki0.40.30.2risk0.10-0.1-0.2value-0.3-0.405101520253035404550xiFigure 10: RL-YC-CLC: Estimated risk (x0 ), value V (x0 ), V (x0 ) = V (x0 )(x0 ) different values .minimum risk policy, curves tank level concentrationc1 found Figure 9(b). bimodal characteristics substance 1 inflowconcentrations reflected c1 (t) (it holds c2 (t) = 1 c1 (t)). attainable minimumrisk 0.062. Increasing weight leads curves similar shown Figures 57. assume minimum achievable risk decreased inclusionadditional variables, e.g. inflow rates concentrations, and/or inclusion pastvalues discussed section 8.1.1. treatment version action historyanalogous section 8.1.2. therefore conclude presentation experimentspoint.9. Conclusionpaper, presented approach learning optimal policies constrained riskMDPs error states. contrast RL DP approaches consider riskmatter variance return worst outcomes, defined riskprobability entering error state.presented heuristic algorithm aims learning good stationary policiesbased weighted formulation problem. weight original value functionincreased order maximize return risk required staygiven threshold. fixed weight finite state space, algorithm convergesoptimal policy case undiscounted value function. case statespace finite, contains cycles, < 1 holds, conjecture convergencelearning algorithm policy, assume suboptimal weightedformulation. optimal stationary policy exists weighted formulation,feasible, generally suboptimal solution constrained problem.104fiRisk-Sensitive Reinforcement Learningweighted approach combined adaptation heuristic searching space feasible stationary policies original constrained problem,us seems relatively intuitive. conjecture better policies could found allowingstate-dependent weights (x) modified adaptation strategy, extendingconsidered policy class.successfully applied algorithm control outflow feed tanklies upstream distillation column. started formulation stochasticoptimal control problem chance constraints, mapped risk-sensitive learningproblem error states (that correspond constraint violation). latter problemsolved using weighted RL algorithm.crucial point reformulation RL problem design state space.found algorithm consistently performed better state informationprovided learner. Using time action history resulted large statespaces, poorer learning performance. RBF networks together sufficient stateinformation facilitated excellent results.must mentioned use RL together MLP RBF network basedfunction approximation suffers usual flaws: non-optimality learned network,potential divergence learning process, long learning times. contrastexact method, priori performance guarantee given, course posterioriestimate performance learned policy made. main advantageRL method lies broad applicability. tank control task, achieved goodresults compared obtained (mostly) analytical approach.cases |X| > 1 < 1 theoretical investigations convergenceexperiments required. Preliminary experiments shown oscillations mayoccur algorithm, behavior tends oscillate sensible policies withoutgetting bad in-between although convergence usefulness policies remainsopen issue.Oscillations prevented using discounted risk leads underestimationactual risk. existence optimal policy convergence learningalgorithm fixed guaranteed case finite MDP. probabilisticinterpretation discounted risk given considering 1 probabilityexiting control MDP (Bertsekas, 1995). investigation discountedrisk may worthwhile right. example, task long episodes,continuing, i.e. non-episodic, natural give larger weight errorstates occurring closer current state.designed learning algorithm online algorithm. means learning accomplished using empirical data obtained interaction simulatedreal process. use neural networks allows apply algorithm processescontinuous state spaces. contrast, algorithm described Dolgov Durfee (2004)applied case known finite MDP. model obtainedcase continuous-state process finding appropriate discretization estimating state transition probabilities together reward function. Althoughdiscretization prevents application Dolgov Durfees algorithm RL-Y-OLC,15-dimensional state space encountered, probably applied caseRL-Y-OLC. plan investigate point future experiments.105fiGeibel & Wysotzkiquestion arises whether approach also applied stochastic optimalcontrol problems types chance constraints. Consider conjunction chanceconstraintsP(C0 ) p1 , . . . , P(CN 1 ) pN 1 ,(37)Ct constraint system containing variables time t, ptrespective probability threshold. (37) requires alternative RL formulation riskstate depends next reward, time-step .solution modified version RL algorithm difficult.Ct (37) allowed constraint system state variables depending t, things get involved several risk functions neededstate. plan investigating cases future.Acknowledgments thank Dr. Pu Li providing application examplehelpful comments. thank Onder Gencaslan conducting first experimentsmasters thesis.ReferencesAltman, E. (1999). Constrained Markov Decision Processes. Chapman Hall/CRC.Baird, L. (1995). Residual algorithms: reinforcement learning function approximation. Proc. 12th International Conference Machine Learning, pp. 3037. MorganKaufmann.Bawas, V. S. (1975). Optimal rules ordering uncertain prospects. Journal Finance,2 (1), 1975.Bertsekas, D. P. (1995). Dynamic Programming Optimal Control. Athena Scientific,Belmont, Massachusetts. Volumes 1 2.Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific,Belmont, MA.Bishop, C. M. (1995). Neural Networks Pattern Recognition. Oxford University Press,Oxford.Blythe, J. (1999). Decision-theoretic planning. AI Magazine, 20 (2), 3754.Borkar, V. (2002). Q-learning risk-sensitive control. Mathematics Operations Research,27 (2), 294311.Coraluppi, S., & Marcus, S. (1999). Risk-sensitive minimax control discrete-time,finite-state Markov decision processes. Automatica, 35, 301309.Crites, R. H., & Barto, A. G. (1998). Elevator group control using multiple reinforcementlearning agents. Machine Learning, 33 (2/3), 235262.Dolgov, D., & Durfee, E. (2004). Approximating optimal policies agents limitedexecution resources. Proceedings Eighteenth International Joint ConferenceArtificial Intelligence, pp. 11071112. AAAI Press.106fiRisk-Sensitive Reinforcement LearningFeinberg, E., & Shwartz, A. (1994). Markov decision models weighted discountedcriteria. Math. Operations Research, 19, 152168.Feinberg, E., & Shwartz, A. (1996). Constrained discounted dynamic programming. Math.Operations Research, 21, 922945.Feinberg, E., & Shwartz, A. (1999). Constrained dynamic programming two discountfactors: Applications algorithm. IEEE Transactions Automatic Control,44, 628630.Fishburn, P. C. (1977). Mean-risk analysis risk associated below-target returns.American Economics Review, 67 (2), 116126.Freund, R. (1956). introduction risk programming model. Econometrica, 21,253263.Fulkerson, M. S., Littman, M. L., & Keim, G. A. (1998). Speeding safely: Multi-criteriaoptimization probabilistic planning. Proceedings Fourteenth NationalConference Artificial Intelligence, p. 831. AAAI Press/MIT Press.Gabor, Z., Kalmar, Z., & Szepesvari, C. (1998). Multi-criteria reinforcement learning.Proc. 15th International Conf. Machine Learning, pp. 197205. Morgan Kaufmann,San Francisco, CA.Geibel, P. (2001). Reinforcement learning bounded risk. Brodley, E., & Danyluk,A. P. (Eds.), Machine Learning - Proceedings Eighteenth International Conference (ICML01), pp. 162169. Morgan Kaufmann Publishers.Heger, M. (1994). Consideration risk reinforcement learning. Proc. 11th International Conference Machine Learning, pp. 105111. Morgan Kaufmann.Kall, P., & Wallace, S. W. (1994). Stochastic Programming. Wiley, New York.Koenig, S., & Simmons, R. G. (1994). Risk-sensitive planning probabilistic decisiongraphs. Doyle, J., Sandewall, E., & Torasso, P. (Eds.), KR94: Principles Knowledge Representation Reasoning, pp. 363373, San Francisco, California. MorganKaufmann.Kushmerick, N., Hanks, S., & Weld, D. S. (1994). algorithm probabilistic leastcommitment planning.. AAAI, pp. 10731078.Li, P., Wendt, M., Arellano-Garcia, & Wozny, G. (2002). Optimal operation distillationprocesses uncertain inflows accumulated feed tank. AIChe Journal, 48,11981211.Liu, Y., Goodwin, R., & Koenig, S. (2003a). Risk-averse auction agents. Rosenschein, J.,Sandholm, T., & Wooldridge, M. Yokoo, M. (Eds.), Proceedings Second International Joint Conference Autonomous Agents MultiAgent Systems (AAMAS03), pp. 353360. ACM Press.Liu, Y., Goodwin, R., & Koenig, S. (2003b). Risk-averse auction agents.. AAMAS, pp.353360.Markowitz, H. M. (1952). Portfolio selection. Journal Finance, 7 (1), 7791.Markowitz, H. M. (1959). Portfolio Selection. John Wiley Sons, New York.107fiGeibel & WysotzkiMihatsch, O., & Neuneier, R. (2002). Risk-sensitive reinforcement learning. Machine Learning, 49 (2-3), 267290.Neuneier, R., & Mihatsch, O. (1999). Risk-sensitive reinforcement learning. MichaelS. Kearns, Sara A. Solla, D. A. C. (Ed.), Advances Neural Information ProcessingSystems, Vol. 11. MIT Press.Ross, S. M. (2000). Introduction Probability Models. Academic Press, New York.Roy, A. D. (1952). Safety first holding assets. Econometrica, 20 (3), 431449.Smart, W. D., & Kaelbling, L. P. (2002). Effective reinforcement learning mobile robots. Proceedings 2002 IEEE International Conference RoboticsAutomation (ICRA 2002).Stephan, V., Debes, K., Gross, H.-M., Wintrich, F., & Wintrich, H. (2001). new controlscheme combustion processes using reinforcement learning based neural networks. International Journal Computational Intelligence Applications, 1 (2),121136.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning Introduction. MITPress.Tsitsiklis, J. N. (1994). Asynchronous stochastic approximation Q-learning. MachineLearning, 16 (3), 185202.Watkins, C. J. C. H. (1989). Learning Delayed Rewards. Ph.D. thesis, Kings College,Oxford.Watkins, C. J. C. H., & Dayan, P. (1992). Q-learning. Machine Learning, 8 (3/4). SpecialIssue Reinforcement Learning.Wendt, M., Li, P., & Wozny, G. (2002). Non-linear chance constrained process optimizationuncertainty. Ind. Eng. Chem. Res., 21, 36213629.108fiJournal Artificial Intelligence Research 24 (2005) 933944Submitted 12/04; published 12/05Engineering NotemGPT: Probabilistic Planner Based Heuristic SearchBlai Bonetbonet@ldc.usb.veDepartamento de ComputacionUniversidad Simon Bolvar, VenezuelaHector Geffnerhector.geffner@upf.eduICREA & Universitat Pompeu FabraPaseo de Circunvalacion 8, Barcelona 08003, SpainAbstractdescribe version GPT planner used probabilistic track 4thInternational Planning Competition (ipc-4). version, called mGPT, solves MarkovDecision Processes specified ppddl language extracting using different classeslower bounds along various heuristic-search algorithms. lower boundsextracted deterministic relaxations alternative probabilistic effectsaction mapped different, independent, deterministic actions. heuristic-searchalgorithms use lower bounds focusing updates delivering consistentvalue function states reachable initial state greedy policy.1. IntroductionmGPT planner based heuristic search solving Markov Decision Processes (MDPs)specified high-level planning language ppddl. mGPT captures fragmentfunctionality GPT system handles non-determinism incomplete information,qualitative probabilistic forms, including pomdps Conformant planning(Bonet & Geffner, 2000).mGPT supports several algorithms admissible heuristic functions (lower bounds)combined generate wide range solvers. main algorithms lrtdphdp. heuristic-search algorithms solving MDPs make use lower boundscomputing consistent value function V : function Bellman residuals boundeduser-provided parameter states reachable given initial state s0greedy policy based V (Bonet & Geffner, 2003b, 2003a).lower bounds derived solving relaxations input problem. Since algorithms solving relaxations also based heuristic search, implementedstackable software components created sequence computing complex heuristic functions simpler ones.2. Algorithmsdivide algorithms two groups: deliver consistent value functionsrespect user-provided parameter , select actions real time. firstc2005AI Access Foundation. rights reserved.fiBonet & Geffnerclass algorithms compute -consistent value function V states reachableinitial state s0 , greedy policy V based V .following subsection, give definitions admissible consistent value functions, greedy, partial proper policies. Then, present algorithms implementedmGPT.2.1 Consistent Value Functions, Greedy, Partial Proper Policiesvalue function V admissible non-overestimating; i.e. value V (s)state lower bound optimal expected cost starting s. V -consistentstate Bellman residual s,fifiXfifidef00 fifiR(s) = fiV (s) min c(s, a) +P r(s |s, a)V (s ) fi ,(1)aA(s)s0less equal . Here, A(s) denotes actions applicable s, c(s, a)cost applying action s, P r() probabilistic transition function. V0-consistent s, say V consistent s.state reachable initial state s0 policy exists trajectorys0 , s1 , . . . , sn sn = P (sk+1 |sk , (sk )) > 0 0 k < n. words,state reached positive probability s0 zero steps usingpolicy .known greedy policy V based value function V , definedXdef00V (s) = argmin c(s, a) +P r(s |s, a)V (s ) ,(2)aA(s)s0optimal V -consistent states sufficiently small . Yet, since goalfind optimal policy respect initial state s0 states reachableit, sufficient V admissible -consistent states reachables0 V .partial policy policy doesnt need defined states. closedrespect state defined states reachable ,proper respect goal state reached every state reachable, finally proper proper respect states.2.2 Algorithms Compute -Consistent Value Functionsfirst group algorithms, mGPT implements Value Iteration (vi), Labeled RealTime Dynamic Programming (lrtdp), Heuristic Dynamic Programming (hdp).Value Iteration (Bertsekas, 1995) applied states reachedgiven initial state available operators, yields -consistent value functionthem.1 mGPTs vi serves bottom-line reference comparisonalgorithms.1. undiscounted problems like probabilistic planning, conditions neeeded orderVI finish -consistent value function (Bertsekas, 1995).934fimGPT: Probabilistic Planner Based Heuristic SearchLabeled Real-Time Dynamic Programming (Bonet & Geffner, 2003b) heuristicsearch algorithm implements labeling scheme top rtdp algorithm (Barto,Bradtke, & Singh, 1995) improve convergence. Lrtdp works performing simulatedtrials start initial state end solved states, selecting actions accordinggreedy policy V successor states according corresponding transitionprobabilities. Initially, V input heuristic function, solved statesgoal states. Then, time action picked state s, value updatedmaking consistent value successors. end trial, labelingprocedure called checks whether new states labeled solved: state solvedvalue value descendents -consistent. algorithm endsinitial state labeled solved. point states reachable initial states0 greedy policy V -consistent. labeling mechanism also guaranteesV proper partial policy respect s0 .Heuristic Dynamic Programming (Bonet & Geffner, 2003a) second heuristic-searchalgorithm supported mGPT solving MDPs. Hdp performs systematic depth-firstsearches set states reachable initial state s0 greedy policyV looking -inconsistent states updating values. top search,labeling scheme based Tarjans strongly-connected components procedure (Tarjan,1972), identifies states solved need revisited. initialvalue function given heuristic function, algorithm ends initial statesolved. lrtdp, labeling mechanism guarantees V proper respects0 .2.3 Algorithms Real-Time Action Selectionsecond class algorithms attempt solve given MDP; rather selectactions real-time limited amount processing without offering guaranteesquality resulting policies. Algorithms group include extensionAction Selection Planning algorithm (asp) (Bonet, Loerincs, & Geffner, 1997)probabilistic domains, basically rtdp algorithm lookahead. Asp, like rtdp,performs value function updates states cannot get trapped loop. Thus,although policy delivered asp suboptimal, proper policy; i.e. policyguaranteed reach goal state.3. Heuristicsalgorithms assume initial value function given heuristic functionprovides good cost estimates, particular, lrtdp hdp expect heuristicadmissible. described Pearl (1983), informative admissible heuristicsobtained solving suitable relaxations input problem. Two relaxationssupported mGPT: min-min relaxation, Strips relaxation. first defines(deterministic) shortest-path problem original state space; second used define(deterministic) shortest-path problems atom space.2 Thus, first solved2. Atoms refer propositional symbols used representation language, ppddl case,define problem. number atoms polynomial size input, sizestate space is, general, exponential number atoms.935fiBonet & Geffnertime polynomial number states, shortest-path problems defined secondsolved time polynomial number atoms. methods yield lower boundsexpected cost goal given state, yet bounds produced min-minrelaxation stronger produced Strips relaxation.3.1 Min-Min State Relaxationidea behind min-min relaxation transform input probabilistic problem,described Bellman equationsXdef00V (s) = min c(s, a) +P r(s |s, a)V (s ) ,(3)aA(s)s0deterministic shortest-path problem Bellman equations form,Vmin(s) =defmin c(s, a) + min {Vmin(s0 ) : P (s0 |s, a) > 0} .(4)aA(s)level representation language, min-min relaxation built transforming probabilistic operator form:= h , [ p1 : 1 , . . . , pn : n ] ,(5)precondition ith probabilistic effect (with probabilitypi ), set independent deterministic operators form:oi = h , ,1 n.(6)Thus, min-min relaxation one actually choose convenient non-deterministic effect operator, hence, cost relaxation lower boundexpected cost original probabilistic problem.min-min relaxation deterministic problem solved meansstandard path-finding algorithms. example, solved Dijkstras algorithm,a*, ida*, deterministic version lrtdp (i.e. labeled lrta algorithm (Korf, 1990)).mGPT provides two methods computing min-min heuristic relaxation:min-min-ida*, uses ida*, min-min-lrtdp, uses lrtdp. versionslazy sense heuristic values states computed neededplanner requires them.3.2 Strips RelaxationStrips relaxation turn converts deterministic problem obtained min-minrelaxation Strips problem, obtains lower bounds original MDPcomputing lower bounds resulting Strips problem using methods developedclassical planning (e.g., Bonet & Geffner, 2001; Haslum & Geffner, 2000; Hoffmann & Nebel,2001; Edelkamp, 2001; Nguyen & Kambhampati, 2000). methods run polynomialtime number atoms yet, unlike min-min relaxation, require casting minmin relaxation Strips format, conversion that, like conversion ADL Strips(Gazen & Knoblock, 1997), may require exponential time space (see below).936fimGPT: Probabilistic Planner Based Heuristic SearchmGPT, Strips relaxation obtained directly original problem, firsttransforming probabilistic operator form:= h prec, [ p1 : (add1 , del1 ), . . . , pn : (addn , deln ) ] ,(7)prec, addi , deli conjunctions literals represents precondition, ithadd list, ith delete list operator respectively, pi probabilities sum1. order take operators form (7), disjunctive preconditions, conditionaleffects, quantifiers removed described Gazen Knoblock (1997).operators form (7), Strips relaxation generated splittingoperators n independent Strips operators form:oi = h prec, addi , deli ,1 n.(8)following heuristics implemented mGPT upon Strips relaxation.first two lower bounds optimal cost Strips relaxation henceoptimal (expected) cost original MDP, third one necessarily lower boundeither cost.hm heuristics (h-m) (Haslum & Geffner, 2000) heuristics recursivelyapproximate cost achieving set atoms C initial state costachieving costly subset size C. computed shortestpath algorithm graph nodes standing sets atoms,result values hm (s) estimate cost reaching goal state s. useoption h-m-k mGPT refer hm heuristic = k.Pattern database heuristics (patterndb) (Edelkamp, 2001) compute optimal costsrelaxations Strips problem defined multi-valued variablesimplicit problem (e.g. location block blocksworld domainimplicit multi-valued variable whose possible values either table topblock). heuristic also precomputed once, beginning,provides lower bound cost arbitrary state goal. patterndatabase computed projecting Strips problem respect set atoms(those define multi-valued variables) solving resulting problemoptimally Dijkstras algorithm. Multiple pattern databases combinedeither taking max sum. latter case, pattern database referredadditive.3 use additive pattern databases defined Haslum, Bonet,Geffner (2005) constraints original problem preservedprojection; something often results stronger heuristics. Patterndb-k referspattern database heuristic defined k multi-valued variables.FF (ff) heuristic implements heuristic function used FF planner (Hoffmann & Nebel, 2001). computed building so-called relaxed planning graphfinding plan it. heuristic number operators plan.3. conditions required adding two pattern databases result remains admissible.sufficient condition B = sets B used build projectionsrespectively.937fiBonet & Geffnerrelaxed planning graph version graph constructed Graphplan(Blum & Furst, 1997) delete lists ignored. shown computingff heuristic done polynomial time size input problem(Hoffmann & Nebel, 2001). heuristic however informative non-admissible.shown below, heuristics plugged directly planning algorithmused compute informative heuristics. example, patterndbheuristic used within ida* solve min-min relaxation, gives strongerheuristic patterndb heuristic. Thus, mGPT implements algorithms heuristicsstackable software components element stack used solve elementsit.4. Implementationsection gives details implementation mGPT together examplesuse. mGPT system implemented C++ upon preliminary parser offeredorganizers ipc-4.4.1 Hash TablesPerhaps important component modern search-based planners internalrepresentation states hash tables. Since mGPT uses different search algorithmshash tables solve given instance (e.g. informative heuristics computedless informative ones), good internal representations hash table implementationcritical good performance.grounding atoms operators, state represented ordered listatoms hold true state. state appear associated differentdata multiple hash tables simultaneously. Thus, instead multiples copiess, mGPT implements system-wide state-hash-table stores representationstates referenced hash tables entries tables simply contain referencestate-hash-table. way, planner saves time space.Another issue large impact performance average number collisionshash table. Two points relevant keeping number collisions low:hashing function size hash table. former, seencryptographic hashing functions like md4 behave well even though slowertraditional choices. latter, mGPT uses hash tables whose size equallarge prime number (Cormen, Leiserson, & Rivest, 1990).4.2 Algorithms Heuristicsalgorithm mGPT implemented subclass abstract algorithm classwhose members reference problem and, cases, reference hash tableparameter . Similarly, heuristic mGPT implemented subclassabstract heuristic class whose members reference problem functionmaps states non-negative values. Simple heuristics like constant-zero functionstraightforward, others like min-min-lrtdp implemented class whose members are,addition above, references hash table lrtdp algorithm.938fimGPT: Probabilistic Planner Based Heuristic Search4.3 Examplesmain parameters call mGPT -a <algorithm> specifies algorithmuse, -h <heuristic> specifies heuristic function, -e <epsilon>specifies threshold consistency check. typical call looks like:mGPT -a lrtdp -h h-m-1 -e .001 <domain> <problem>instructs mGPT use lrtdp algorithm h-m-1 heuristic = 0.001domain problem files specified.h-m-1 heuristic admissible weak. following example showscompute min-min-lrtdp heuristic using h-m-1 base heuristic:mGPT -a lrtdp -h "h-m-1|min-min-lrtdp" -e .001 <domain> <problem>pipe symbol used instruct planner heuristics computed usingheuristics.Another possibility use mGPT reactive planner decisions takenon-line respect heuristic function improved time. example,mGPT -a asp -h ff <domain> <problem>uses asp algorithm ff heuristic,mGPT -a asp -h "zero|min-min-ida*" <domain> <problem>uses asp algorithm min-min-ida* heuristic computed constant-zeroheuristic. combinations algorithms heuristics possible. mGPT also acceptsparameters control initial hash size, weight heuristic function, values dead-endstates, verbosity level, lookahead settings asp, etc.5. Competitioncompetition suite consisted 7 probabilistic domains named blocksworld, explodingblocksworld, boxworld, fileworld, tireworld, towers-of-hanoise, zeno. Blocksworldexploding-blocksworld variations standard blocksworld domain classical planning. Boxworld logistics-like transportation domain. Fileworld file/folder domainuncertainty present initial situation destinationfile set. Tireworld towers-of-hanoise variations classical tireworld domaintowers-of-hanoi. Zeno traveling domain fuel resource.domains come two variations: goal-oriented version goalachieved certainty minimizing expected costs, reward-oriented versioninvolves rewards. mGPT planner handles first type tasks only.competition used lrtdp algorithm patterndb-1 heuristic,parameter = 0.001, weight W = 5 heuristic function. cases,patterndb-1 heuristic poor, planner switched automatically aspalgorithm ff heuristic.939fiBonet & Geffnerproblem nameblocksworld-5blocksworld-8blocksworld-11blocksworld-15blocksworld-18blocksworld-21exploding-bwboxworld-c5-b10boxworld-c10-b10boxworld-c15-b10fileworld-30-5towers-of-hanoisetireworld-gtireworld-rzenoruns303030303030303030failed0000001400successful303030303030163030time43601307,7066,3702,2204839162reward494.1487.7465.7397.2183.657.6266.60500Table 1: Results mGPT planner competition problems. table showsproblem name, number runs, number failed successful runs (see text),time reward averages. dash means mGPT able solveproblem. Times milliseconds.5.1 Resultscompetition held client/server model. planner evaluatedproblem number runs supervision server. planner initiatedsession connecting server interacted exchanging messages.run consisted actions sent planner whose effects transmitted backserver planner. Thus, current state problem maintainedplanner server.Table 1 shows results mGPT competition problems. problem,30 runs executed. table shows number runs, number failed runs(i.e. finished without reaching goal state), number successful runs (i.e.finished goal states), time reward averages per run.4blocksworld, problem blocksworld-xx means problem xx blocks, boxworld,problem boxworld-cxx-byy means problem xx cities yy boxes.seen table, mGPT solve exploding-bw, larger instancesblocksworld boxworld, also failed approximately half instancestireworld-g. difficulties encountered mGPT solving problems oftenmuch probabilities involved, domains, particular,encodings. basic algorithms used mGPT try solve problems4. competition format reward-based presentation cost-based. straightforwardgo one format other.940fimGPT: Probabilistic Planner Based Heuristic Searchcomputing value function -residuals relevant states (those reachableinitial state optimal policy). this, mGPT computes admissible heuristicfunction solving either min-min relaxation, Strips relaxation, both. problemfaced approach many instances neither relaxations couldsolved. Here, give detailed explanation problems encountered mGPTdifferent domains. worth noting many difficulties would surfaceStrips planner well, even probabilities ignored.Blocksworld exploding blocksworld: operator encodings preconditionscontaining universally-quantified negative literals, result using clearpredicate. example,(:action pick-up-block-from:parameters (?top - block ?bottom):precondition (and (not (= ?top ?bottom))(forall (?b - block) (not (holding ?b)))(on-top-of ?top ?bottom)(forall (?b - block) (not (on-top-of ?b ?top)))):effect (and (decrease (reward) 1)(probabilistic0.75 (and (holding ?top) (not (on-top-of ?top ?bottom)))0.25 (when (not (= ?bottom table))(and (not (on-top-of ?top ?bottom))(on-top-of ?top table))))))complex encoding standard planning makes atom-based heuristics almost useless. mGPT could solve instances 5, 8, 11 15 blocks18 21 blocks. exploding blocksworld, mGPT unablesolve parser incomplete parse complex constructs.Boxworld: encoding contains drive-truck operator moves truckintended destination probability 0.8 one three wrong destinationsprobability 0.2/3 each. encoding specifies unintended effects meansnested conditional effects form(:action drive-truck:parameters (?t - truck ?src - city ?dst - city):precondition (and (truck-at-city ?t ?src) (can-drive ?src ?dst)):effect (and (not (truck-at-city ?t ?src))(probabilistic0.2 (forall (?c1 - city)(when (wrong-drive1 ?src ?c1)(forall (?c2 - city)(when (wrong-drive2 ?src ?c2)(forall (?c3 - city)(when (wrong-drive3 ?src ?c3)(probabilistic1/3 (truck-at-city ?t ?c1)1/3 (truck-at-city ?t ?c2)1/3 (truck-at-city ?t ?c3))))))))0.8 (truck-at-city ?t ?dst))))941fiBonet & GeffnerStrips relaxation, like planner converts ADL-style operators Strips,suffers exponential blow domain: 10 cities,thousand operators grounded ADL-operator. set included problems5, 10 15 cities.Fileworld: domain, 30 files need filed one 5 differentfolders: exact destination determined probabilistically. optimal policyproblem, proper policy, must prescribe action 530 states,relevant. consequence problem millions relevant statesneed stored hash table task compute proper policy.patterndb-1 heuristic problem informative, revealed analysisvalues stored pattern database, thus mGPT switched automaticallyasp algorithm ff heuristic.Towers-of-hanoise: blocksworld domain, encoding complex operators disjunctions universally-quantified negative literals preconditions, complex conditional effects. Yet problem prevented mGPTsolving problem domain bug code implements conditionaleffects surface domains.Tireworld: two versions: goal-based version called tireworld-greward-based version called tireworld-r. domain contains multiple dead endslocations car gets flat tire spare tire available.dead ends unavoidable; i.e. proper policy problem. trialsreward-based version end successfully since requirement reach goalposition, rather objective maximize accumulated reward. mGPT treatedversions goal-based problems deal directly reward-basedproblems.6. ConclusionsmGPT planner entered probabilistic planning competition combines heuristicsearch algorithms methods obtaining lower bounds deterministic relaxations.results obtained competition mixed difficultiesselection domains encodings match capabilities mGPT:mGPT tries compute proper solutions using heuristics derived Strips relaxations.described, domains could solved due number relevantstates, others due complexity Strips relaxations themselves.definition good benchmarks MDP solvers, crucial defineconstitutes solution bottom line assessing performance. classicalplanning, example, solutions plans bottom line given blind-searchalgorithms; progress field measured distance bottom line.probabilistic setting, difficult always clear meanssolve problem. This, however, needs defined way, otherwise performancecomparisons meaningful. Indeed, classical setting, one longer comparesoptimal non-optimal planners since types planners different: oneprovides guarantees apply solutions, provides guarantees942fimGPT: Probabilistic Planner Based Heuristic Searchapply one solution only. probabilistic setting even subtledifferent types guarantees. example, restrict class MDPsconstitute simplest generalization classical setting task reachinggoal certainty minimizing expected number steps given initialstate s0 methods yield solutions (policies) ensure goalreached certainty finite number steps (not necessarily optimal), methodsguarantees. types methods necessary practice, yet crucialmake distinction among identify useful benchmarks class.methods yield optimal policies, least policies finite expected costs, standarddynamic programming methods like value iteration provide useful bottom-line referenceassessing performance. case, believe useful benchmarks need definedtaking account types tasks various algorithms aim solve,types guarantees, any, provide solutions.GPT mGPT available download http://www.ldc.usb.ve/bonet.AcknowledgementsmGPT built upon parser developed John Asmuth Rutgers UniversityHakan Younes Carnegie Mellon University. also thank David E. Smith comments helped us improve note.ReferencesBarto, A., Bradtke, S., & Singh, S. (1995). Learning act using real-time dynamic programming. Artificial Intelligence, 72, 81138.Bertsekas, D. (1995). Dynamic Programming Optimal Control, (2 Vols). Athena Scientific.Blum, A., & Furst, M. (1997). Fast planning planning graph analysis. ArtificialIntelligence, 90, 281300.Bonet, B., & Geffner, H. (2000). Planning incomplete information heuristic searchbelief space. Chien, S., Kambhampati, S., & Knoblock, C. (Eds.), Proc. 6thInternational Conf. Artificial Intelligence Planning Scheduling, pp. 5261,Breckenridge, CO. AAAI Press.Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129 (12), 533.Bonet, B., & Geffner, H. (2003a). Faster heuristic search algorithms planninguncertainty full feedback. Gottlob, G. (Ed.), Proc. 18th International JointConf. Artificial Intelligence, pp. 12331238, Acapulco, Mexico. Morgan Kaufmann.Bonet, B., & Geffner, H. (2003b). Labeled RTDP: Improving convergence real-timedynamic programming. Giunchiglia, E., Muscettola, N., & Nau, D. (Eds.), Proc.13th International Conf. Automated Planning Scheduling, pp. 1221, Trento,Italy. AAAI Press.943fiBonet & GeffnerBonet, B., Loerincs, G., & Geffner, H. (1997). robust fast action selection mechanismplanning. Kuipers, B., & Webber, B. (Eds.), Proc. 14th National Conf.Artificial Intelligence, pp. 714719, Providence, RI. AAAI Press / MIT Press.Cormen, T., Leiserson, C., & Rivest, R. (1990). Introduction Algorithms. MIT Press.Edelkamp, S. (2001). Planning pattern databases. Cesta, A. (Ed.), Proc. 6thEuropean Conf. Planning, pp. 1324, Toledo, Spain. Springer: LNCS.Gazen, B., & Knoblock, C. (1997). Combining expressiveness UCPOPefficiency Graphplan. Steel, S., & Alami, R. (Eds.), Proc. 4th European Conf.Planning, pp. 221233, Toulouse, France. Springer: LNCS.Haslum, P., Bonet, B., & Geffner, H. (2005). New admissible heuristics domainindependent planning. Veloso, M., & Kambhampati, S. (Eds.), Proc. 20 NationalConf. Artificial Intelligence, pp. 11631168, Pittsburgh, PA. AAAI Press / MITPress.Haslum, P., & Geffner, H. (2000). Admissible heuristic optimal planning. Chien, S.,Kambhampati, S., & Knoblock, C. (Eds.), Proc. 6th International Conf. ArtificialIntelligence Planning Scheduling, pp. 140149, Breckenridge, CO. AAAI Press.Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generationheuristic search. Journal Artificial Intelligence Research, 14, 253302.Korf, R. (1990). Real-time heuristic search. Artificial Intelligence, 42 (23), 189211.Nguyen, X., & Kambhampati, S. (2000). Extracting effective admissible state-spaceheuristics planning graph. Kautz, H., & Porter, B. (Eds.), Proc. 17thNational Conf. Artificial Intelligence, pp. 798805, Austin, TX. AAAI Press /MIT Press.Pearl, J. (1983). Heuristics. Morgan Kaufmann.Tarjan, R. E. (1972). Depth first search linear graph algorithms. SIAM JournalComputing, 1 (2), 146160.944fiJournal Artificial Intelligence Research 24 (2005) 195-220Submitted 11/04; published 08/05Perseus: Randomized Point-basedValue Iteration POMDPsMatthijs T. J. SpaanNikos Vlassismtjspaan@science.uva.nlvlassis@science.uva.nlInformatics Institute, University AmsterdamKruislaan 403, 1098 SJ Amsterdam, NetherlandsAbstractPartially observable Markov decision processes (POMDPs) form attractive principled framework agent planning uncertainty. Point-based approximate techniques POMDPs compute policy based finite set points collected advanceagents belief space. present randomized point-based value iteration algorithm called Perseus. algorithm performs approximate value backup stages, ensuringbackup stage value point belief set improved; keyobservation single backup may improve value many belief points. Contrarypoint-based methods, Perseus backs (randomly selected) subsetpoints belief set, sufficient improving value belief point set.show idea extended dealing continuous action spaces.Experimental results show potential Perseus large scale POMDP problems.1. Introductionmajor goal Artificial Intelligence build intelligent agents (Russell & Norvig, 2003).intelligent agent, whether physical simulated, able autonomously performgiven task, often characterized sensethinkact loop: uses sensors observeenvironment, considers information decide do, executes chosenaction. agent influences environment acting detect effect actionssensing: environment closes loop. work interested computingplan maps sensory input optimal action execute given task. considertypes domains agent uncertain exact consequence actions.Furthermore, cannot determine full certainty state environmentsingle sensor reading, i.e., environment partially observable agent.Planning kinds uncertainty challenging problem requires reasoning possible futures given possible histories. Partially observable Markov decisionprocesses (POMDPs) provide rich mathematical framework acting optimallypartially observable stochastic environments (Dynkin, 1965; Astrom, 1965; Aoki, 1965;Sondik, 1971; Lovejoy, 1991; Kaelbling, Littman, & Cassandra, 1998). POMDP defines sensor model specifying probability observing particular sensor readingspecific state stochastic transition model captures uncertain outcomeexecuting action. agents task defined reward receives time stepgoal maximize discounted cumulative reward. Assuming discrete models,POMDP framework allows capturing uncertainty introduced transitionobservation model defining operating belief state agent. beliefc2005AI Access Foundation. rights reserved.fiSpaan & Vlassisstate probability distribution states summarizes information regardingpast.use belief states allows one transform original discrete state POMDPcontinuous state Markov decision process (MDP), turn solvedcorresponding MDP techniques (Bertsekas & Tsitsiklis, 1996). However, optimal valuefunction POMDP exhibits particular structure (it piecewise linear convex)one exploit order facilitate solving. Value iteration, instance, methodsolving POMDPs builds sequence value function estimates convergeoptimal value function current task (Sondik, 1971). value functionparameterized finite number hyperplanes, vectors, belief space,partition belief space finite amount regions. vector maximizes valuefunction certain region action associated it, optimal actiontake beliefs region. Computing next value function estimatelooking onestep deeper futurerequires taking account possible actions agenttake subsequent observations may receive. Unfortunately, leadsexponential growth vectors planning horizon. Many computed vectorsuseless sense maximizing region empty, identifyingsubsequently pruning expensive operation.Exact value iteration algorithms (Sondik, 1971; Cheng, 1988; Kaelbling et al., 1998)search value iteration step complete belief simplex minimal set beliefpoints generate necessary set vectors next horizon value function.typically requires linear programming therefore costly high dimensions. ZhangZhang (2001) argued value iteration still converges optimal value functionexact value iteration steps interleaved approximate value iteration stepsnew value function upper bound previously computed value function.results speedup total algorithm, however, linear programming neededorder ensure new value function upper bound previous onecomplete belief simplex. general, computing exact solutions POMDPsintractable problem (Papadimitriou & Tsitsiklis, 1987; Madani, Hanks, & Condon, 1999),calling approximate solution techniques (Lovejoy, 1991; Hauskrecht, 2000).practical tasks one would like compute solutions parts beliefsimplex reachable, i.e., actually encountered interactingenvironment. recently motivated use approximate solution techniquesfocus use sampled set belief points planning performed (Hauskrecht,2000; Poon, 2001; Roy & Gordon, 2003; Pineau, Gordon, & Thrun, 2003; Spaan & Vlassis,2004), possibility already mentioned Lovejoy (1991). idea insteadplanning complete belief space agent (which intractable large statespaces), planning carried limited set prototype beliefssampled letting agent interact (randomly) environment. PBVI (Pineauet al., 2003), instance, builds successive estimates value function updatingvalue gradient points (dynamically growing) belief set.work describe Perseus, randomized point-based value iteration algorithmPOMDPs (Vlassis & Spaan, 2004; Spaan & Vlassis, 2004). Perseus operates largeset beliefs gathered simulating random interactions agentPOMDP environment. belief set number value backup stages performed.196fiPerseus: Randomized Point-based Value Iteration POMDPsalgorithm ensures backup stage value point belief setimproved (or least decrease). Contrary point-based methods, Perseusbacks random subset belief points; key observation single backupmay improve value many points set. allows us compute value functionsconsist small number vectors (relative belief set size), leadingsignificant speedups. evaluate performance Perseus benchmark problemsliterature, show competitive methods terms solutionquality computation time.Furthermore, extend Perseus compute plans agents continuous(or large discrete) set actions disposal (Spaan & Vlassis, 2005). Examplesinclude navigating arbitrary location, rotating pan-and-tilt camera desiredangle. work POMDP solution techniques targets discrete action spaces; exceptionsinclude application particle filter continuous state action space (Thrun,2000) certain policy search methods (Ng & Jordan, 2000; Baxter & Bartlett, 2001).report experiments domain agent equipped proximity sensorsmove continuous heading distance, present experimental resultsnavigation task involving mobile robot omnidirectional vision perceptuallyaliased office environment.remainder paper structured follows: Section 2 review POMDPframework AI perspective, discuss exact methods solving POMDPstractability problems. Next, outline class approximate value iterationalgorithms, so-called point-based techniques. Section 3 describe discussPerseus algorithm, well extension continuous action spaces. Related workapproximate techniques POMDP planning discussed Section 4. presentexperimental results several problem domains Section 5. Finally, wrapconclusions Section 6.2. Partially Observable Markov Decision Processespartially observable Markov decision process (POMDP) models repeated interactionagent stochastic environment, parts hidden agents view.agents goal perform task choosing actions fulfill task best. Statedotherwise, agent compute plan optimizes given performance measure.assume time discretized time steps equal length, startstep agent execute action. time step agent also receives scalarreward environment, performance measure directs agent maximizecumulative reward gather. reward signal allows one define taskagent, e.g., one give agent large positive reward accomplishes certaingoal small negative reward action leading it. way agentsteered toward finding plan let accomplish goal fast possible.POMDP framework models stochastic environments agent uncertainexact effect executing certain action. uncertainty captured probabilistic transition model case fully observable Markov decision process (MDP)(Sutton & Barto, 1998; Bertsekas & Tsitsiklis, 1996). MDP defines transition modelspecifies probabilistic effect action changes state. Extending197fiSpaan & VlassisMDP setting, POMDP also deals uncertainty resulting agents imperfect sensors. allows planning environments partially observableagent, i.e., environments agent cannot determine full certaintytrue state environment. general partial observability stems two sources:(1) multiple states give sensor reading, case agent sense limitedpart environment, (2) sensor readings noisy: observing stateresult different sensor readings. partial observability lead perceptual aliasing: different parts environment appear similar agents sensor system,require different actions. POMDP captures partial observability probabilisticobservation model, relates possible observations states.formally, POMDP assumes time step environment stateS, agent takes action receives reward r(s, a) environmentresult action, environment switches new state s0 accordingknown stochastic transition model p(s0 |s, a). Markov property entails s0depends previous state action a. agent perceives observationO, may conditional action, provides information state s0known stochastic observation model p(o|s, a). sets S, O, assumeddiscrete finite (but generalize continuous Section 3.3).order agent choose actions successfully partially observable environments form memory needed, observations agent receives provideunique identification s. Given transition observation model POMDPtransformed belief-state MDP: agent summarizes information pastusing belief vector b(s). belief b probability distribution S, formsMarkovian signal planning task. beliefs contained (|S| 1)-dimensionalsimplex , means represent belief using |S| 1 numbers. POMDPproblem assumes initial belief b0 , instance set uniform distributionstates (representing complete ignorance regarding initial state environment). Every time agent takes action observes o, belief updatedBayes rule:p(o|s0 , a) Xp(s0 |s, a)b(s),(1)boa (s0 ) =p(o|a, b)sSPPp(o|a, b) = s0 p(o|s0 , a) sS p(s0 |s, a)b(s) normalizing constant.discussed above, goal agent choose actions fulfill taskwell possible, i.e., compute optimal plan. plan called policy (b)maps beliefs actions. Note that, contrary MDPs, policy (b) functioncontinuous set probability distributions S. policy characterizedvalue function V : R defined expected future discounted rewardV (b) agent gather following starting belief b:V (b) = EhXt=0fifir(bt , (bt ))fib0 = b ,(2)Pr(bt , (bt )) = sS r(s, (bt ))bt (s), discount rate, 0 < 1. discountrate ensures finite sum usually chosen close 1. policy maximizes Vcalled optimal policy ; specifies b optimal action execute198fiPerseus: Randomized Point-based Value Iteration POMDPscurrent step, assuming agent also act optimally future time steps. valueoptimal policy defined optimal value function V , satisfies Bellmanoptimality equation V = HV :V (b) = maxaAhXr(s, a)b(s) +sSXp(o|a, b)V(boa ),(3)oOboa given (1), H Bellman backup operator (Bellman, 1957). (3)holds every b ensured solution optimal.V approximated iterating number stages, see nextsection, stage considering step future. problems finiteplanning horizon V piecewise linear convex (PWLC) (Smallwood & Sondik,1973), infinite horizon tasks V approximated arbitrary well PWLCvalue function. parameterize value function Vn stage n finite set vectors(hyperplanes) {ni }, = 1, . . . , |Vn |. Additionally, vector action a(ni )associated, optimal one take current step. vector definesregion belief space vector maximizing element Vn .regions form partition belief space, induced piecewise linearity valuefunction. Examples value function two state POMDP shown Fig. 1(a)|Vn |stage n, value belief b given1(d). Given set vectors {ni }i=1Vn (b) = max b ni ,{in }i(4)() denotes inner product. gradient value function b givenvector nb = arg max{in }i b ni , policy b given (b) = a(nb ).2.1 Exact Value IterationComputing optimal plan agent means solving POMDP, classical methodvalue iteration (Puterman, 1994). POMDP framework, value iteration involvesapproximating V applying exact dynamic programming operator H above,approximate operator H, initially piecewise linear convex value function V0 .H, many commonly used H, produced intermediate estimates V1 , V2 , . . .also piecewise linear convex. main idea behind many value iteration algorithmsPOMDPs given value function Vn particular belief point bbeasily compute vector n+1HVnb,n+1= arg max b n+1(5){in+1 }i|HV |{n+1}i=1 n (unknown) set vectors HVn . denote operationbn+1 = backup(b). computes optimal vector given belief b back-projectingvectors current horizon value function one step future returningvector maximizes value b. particular, defining ra (s) = r(s, a) using (1),199fiSpaan & Vlassis(3), (4) have:hXVn+1 (b) = max b ra +p(o|a, b)Vn (boa )(6)hXXboa (s0 )ni (s0 )p(o|a, b) max= max b ra +(7)hXXX= max b ra +maxp(o|s0 , a)p(s0 |s, a)b(s)ni (s0 )(8)hX= max b ra +max b ga,o,(9){in }i{in }is0s0}{ga,oga,o(s) =Xp(o|s0 , a)p(s0 |s, a)ni (s0 ).(10)s0Applying identity maxj b j = b arg maxj b j (9) twice, compute vectorbackup(b) follows:backup(b) = arg max b gab ,(11){gab }aAgab = ra +X.arg max b ga,o(12)}{ga,oAlthough computing vector backup(b) given b straightforward, locating(minimal) set points b required compute vectors b backup(b) HVn costly.b region belief space nb maximal, family algorithmstries identify regions (Sondik, 1971; Cheng, 1988; Kaelbling et al., 1998).corresponding b region called witness point, testifies existenceregion. Another set exact POMDP value iteration algorithms focussearching belief space, instead consider enumerating possible vectors HVnpruning useless vectors (Monahan, 1982; Cassandra, Littman, & Zhang, 1997).example exact value iteration let us consider straightforward waycomputing HVn due Monahan (1982). involves calculating possible ways HVncould constructed, exploiting known structure value function. operateindependent particular b (12) longer applied. Insteado:include ways selecting ga,oHVn =[Ga , Ga =Mn 1ra + ga,o,|O|(13)Ldenotes cross-sum operator.1 Unfortunately, stage number vectorsexponential |O| generated: |A||Vn ||O| . regions many generated vectorsempty vectors useless such, identifying subsequently pruningrequires linear programming introduces considerable additional cost (e.g.,state space large).1. Cross-sum sets defined as:LkRk = R1 R2 . . . Rk , P Q = { p + q | p P, q Q }.200fiPerseus: Randomized Point-based Value Iteration POMDPsZhang Zhang (2001) proposed alternative approach exact value iteration,designed speed exact value iteration step. turns value iteration stillconverges optimal value function exact value update steps interleavedapproximate update steps new value function Vn+1 computed VnVn (b) Vn+1 (b) HVn (b),b .(14)additionally requires value function appropriately initialized, choosing1mins,a r(s, a). vectorV0 single vector components equal 1represents minimum cumulative discounted reward obtainable POMDP,guaranteed V . Zhang Zhang (2001) compute Vn+1 backing witnesspoints Vn number steps. saw above, backing set belief pointsrelatively cheap operation. Thus, given Vn , number vectors HVn createdapplying backup witness points Vn , set linear programs solvedensure Vn+1 (b) Vn (b), b . repeated number steps,exact value update step takes place. authors demonstrate experimentallycombination approximate exact backup steps speed exact value iteration.general, however, computing optimal planning solutions POMDPs intractableproblem reasonably sized task (Papadimitriou & Tsitsiklis, 1987; Madani et al.,1999). calls approximate solution techniques. describe next recent lineresearch approximate POMDP algorithms focus planning fixed setbelief points.2.2 Approximate Value Iterationmajor cause intractability exact POMDP solution methods aim computing optimal action every possible belief point . instance, use (13)end series value functions whose size grows exponentially planninghorizon. natural way sidestep intractability settle computing approximate solution considering finite set belief points. backup stage reducesapplying (11) fixed number times, resulting small number vectors (boundedsize belief set). motivation using approximate methods abilitycompute successful policies much larger problems, compensates lossoptimality.approximate POMDP value iteration methods operating fixed set pointsexplored Lovejoy (1991) subsequent works (Hauskrecht, 2000; Poon, 2001; Pineauet al., 2003; Spaan & Vlassis, 2004). Pineau et al. (2003) instance, use approximatebackup operator HPBVI instead H, computes value backup stage set[HPBVI Vn =backup(b)(15)bBusing fixed set belief points B. general assumption underlying so-calledpoint-based methods updating value also gradient (thevector) b B, resulting policy generalize well effective beliefsoutside set B. Whether assumption realistic depends POMDPsstructure contents B, intuition many problems set201fiSpaan & Vlassisreachable beliefs (reachable following arbitrary policy starting b0 ) forms lowdimensional manifold belief simplex, thus covered densely enoughrelatively small number belief points.Crucial control quality computed approximate solution makeup B.number schemes build B proposed. instance, one could use regulargrid belief simplex, computed, e.g., Freudenthal triangulation (Lovejoy, 1991).options include taking extreme points belief simplex use random grid(Hauskrecht, 2000; Poon, 2001). alternative scheme include belief pointsencountered simulating POMDP: generate trajectoriesbelief space sampling random actions observations time step (Lovejoy, 1991;Hauskrecht, 2000; Poon, 2001; Pineau et al., 2003; Spaan & Vlassis, 2004). samplingscheme focuses contents B beliefs actually encounteredexperiencing POMDP model.PBVI algorithm (Pineau et al., 2003) instance point-based POMDPalgorithm. PBVI starts selecting small set beliefs B0 , performs number backupstages (15) B0 , expands B0 B1 sampling beliefs, performs seriesbackups, repeats process satisfactory solution found (orallowed computation time expires). set Bt+1 grows simulating actions everyb Bt , maintaining new belief points furthest away pointsalready Bt+1 . scheme heuristic let Bt cover wide area belief space,comes cost requires computing distances b Bt . backingb Bt PBVI algorithm generates stage approximately |Bt | vectors,lead slow performance domains requiring large Bt .next section present point-based POMDP value iteration methodrequire backing b B. compute backups subset B only,seeing computed solution effective complete set B. resultlimit growth number vectors successive value function estimates,leading significant speedups.3. Randomized Point-based Backup Stagesintroduced POMDP framework models agents inhabiting stochasticenvironments partially observable them, discussed exact approximatemethods computing successful plans agents. describe Perseus,approximate solution method capable computing competitive solutions large POMDPdomains.3.1 PerseusPerseus approximate point-based value iteration algorithm POMDPs (Vlassis &Spaan, 2004; Spaan & Vlassis, 2004). value update scheme Perseus implementsrandomized approximate backup operator HPerseus increases (or leastdecrease) value belief points B. operator efficientlyimplemented POMDPs given shape value function. key ideavalue backup stage improve value points belief setupdating value gradient (randomly selected) subset points.202fiPerseus: Randomized Point-based Value Iteration POMDPsbackup stage, given value function Vn , compute value function Vn+1 improvesvalue b B, i.e., build value function Vn+1 = HPerseus Vn upper boundsVn B (but necessarily would require linear programming):Vn (b) Vn+1 (b),b B.(16)first let agent randomly explore environment collect set B reachablebelief points, remains fixed throughout complete algorithm. initialize value1mins,a r(s, a) (Zhang &function V0 single vector components equal 1Zhang, 2001). Starting V0 , Perseus performs number backup stagesconvergence criterion met. backup stage defined follows (where B auxiliaryset containing non-improved points):Perseus backup stage: Vn+1 = HPerseus Vn1. Set Vn+1 = . Initialize B B.2. Sample belief point b uniformly random B compute = backup(b).3. b Vn (b) add Vn+1 , otherwise add 0 = arg max{in }i b ni Vn+1 .4. Compute B = {b B : Vn+1 (b) < Vn (b)}.5. B = stop, else go 2.Often, small number vectors sufficient improve Vn (b) b B, especiallyfirst steps value iteration. idea compute vectors randomizedgreedy manner sampling B, increasingly smaller subset B. keep trackset non-improved points B consisting b B whose new value Vn+1 (b)still lower Vn (b). start backup stage, Vn+1 set means Binitialized B, indicating b B still need improved backup stage.long B empty, sample point b B compute = backup(b).improves value b (i.e., b Vn (b) step 3), add Vn+1 updateVn+1 (b) b B computing inner product new . hopeimproves value many points B, points removed B.long B empty sample belief points add vectors.ensure termination backup stage enforce B shrinksadding vectors, i.e., actually improves least value b generatedit. (i.e., b < Vn (b) step 3), ignore insert copy maximizingvector b Vn Vn+1 . Point b considered improved removed Bstep 4, together belief points vector maximizingone Vn . procedure ensures B shrinks backup stage terminate.pictorial example backup stage presented Fig. 1.Perseus performs backup stages convergence criterion met. pointbased methods several convergence criteria considered, one could instance bounddifference successive value function estimates maxbB (Vn+1 (b) Vn (b)). Another option would track number policy changes: number b Bdifferent optimal action Vn compared Vn+1 (Lovejoy, 1991).203fiSpaan & VlassisreplacemenVn(1, 0)Vn+1b1 b2 b3 b4 b5b6 b7 (0, 1)(1, 0)(0, 1)b6(b)(a)Vn+1Vn+1(1, 0)(1, 0)(0, 1)(0, 1)b3(c)(d)Figure 1: Example Perseus backup stage two state POMDP. belief spacedepicted x-axis y-axis represents V (b). Solid lines ni vectorscurrent stage n dashed lines n1vectors previousstage. operate B 7 beliefs, indicated tick marks. backupstage computing Vn+1 Vn proceeds follows: (a) value function stage n;(b) start computing Vn+1 sampling b6 , add = backup(b6 ) Vn+1improves value b6 b7 ; (c) sample b3 {b1 , . . . , b5 }, add backup(b3 )Vn+1 improves b1 b5 ; (d) value b B improved,backup stage finished.3.2 Discussionkey observation underlying Perseus algorithm belief b backedup, resulting vector improves V (b) often also value manybelief points B. results value functions relatively small number vectors(as compared to, e.g., Poon, 2001; Pineau et al., 2003). Experiments show indeednumber vectors grows modestly number backup stages (|Vn | |B|).practice means afford use much larger B point-basedmethods, positive effect approximation accuracy dictatedbounds Pineau et al. (2003). Furthermore, compared methods buildset B based various heuristics (Pineau et al., 2003; Smith & Simmons, 2004),build-up B cheap requires sampling random trajectories starting b0 .Moreover, duplicate entries B affect probability particular bsampled value update stages, size Vn .204fiPerseus: Randomized Point-based Value Iteration POMDPsalternative using single fixed set B collected following fixed policybeginning algorithm, would resample new Bt every t-th backupstage (or fixed intervals) following recent policy. approach couldjustified fact agent executing optimal policy probably visit(small) subset beliefs B. tested scheme wouldaffect solution quality Perseus trade-offs achieve additionalcomputational cost sampling multiple sets B. note similar off-policy learningusing fixed set sampled states also adopted recent algorithms likeLSPI (Lagoudakis & Parr, 2003) PSDP (Bagnell, Kakade, Ng, & Schneider, 2004).backups Perseus fixed set B viewed particular instanceasynchronous dynamic programming (Bertsekas & Tsitsiklis, 1989). asynchronous dynamic programming algorithms full sweeps state space made, orderstates backed arbitrary. allows algorithm focus backupsmay high potential impact, instance prioritized sweeping algorithm solving fully observable MDPs (Moore & Atkeson, 1993; Andre, Friedman, &Parr, 1998). drawback notion exact planning horizon somewhat lost:general, performing n backup stages computed plan considering nsteps future, less. backing non-improved belief points asynchronouslyPerseus focuses interesting regions (reachable) belief space, samplingrandom ensures eventually b B taken account. ensurevalue particular belief point never decreases, guaranteed Perseus converge: proof requires observing every added vector always V (Poon,2001; Vlassis & Spaan, 2004). Moreover, explained above, Perseus handle largebelief sets B, thus obviating use dynamic belief point selection strategies likeproposed Hauskrecht (2000), Poon (2001), Pineau et al. (2003). Noteparameter set user size B; however, complexity resultingpolicy seems mildly dependent size B.interesting issue many new vectors generated backup stagePerseus, may affect speed convergence algorithm. general,smaller size |Vn | value function, faster backups (since backup operatorlinear dependence |Vn |). hand, two consecutive value functions maydiffer arbitrarily sizeand observed cases new value functionfewer vectors old value functionwhich makes hard derive boundsspeed convergence Perseus complicates analysis involved trade-offs.mainly identified two cases small number new vectors addedvalue function. first case initial backup stages, V0initialized low (e.g., large large negative immediate reward).case single vector may improve points, number backup stages, valuefunction reached sufficient level. second case near convergence,value function almost converged certain regions belief space. Sampling beliefpoint region result (near) copy old vector. Whereas formercase provides evidence value function initialized low (and addingsingle vector efficient way correct this), latter case may viewed providingevidence convergence Perseus.205fiSpaan & Vlassis3.3 Extension Large Continuous Action Spacesattractive feature Perseus naturally extended largecontinuous action spaces, due improveonly principle backup stage. Notebackup operator (11) involves maximization actions A.action space finite small, one cache advance transition, observation,reward models A, therefore achieve optimized implementationbackup operator. large continuous action spaces, full maximizationactions (11) clearly infeasible, one resort sampling-based techniques.idea replace full maximization actions sampled max operatorperforms maximization random subset (Szepesvari & Littman, 1996).also means one compute models fly sampled action,requires algorithm (a parameterized model family) generate neededmodels action given input. generated models cached lateruse case action considered future iterations (see experimentalsection using so-called old actions).use sampled max operator well suited backup schemePerseus require values belief points decrease twoconsecutive backup stages. particular, replace backup operator (11)new backup operator = backup0 defined follows (Spaan & Vlassis, 2005):backup0 (b) = arg max b gab ,(17){gab }aA0bA0b random set actions drawn A, gab defined (12).sampled action A0b generate POMDP models fly mentioned above,models compute required vectors gab used backup0 .backup0 operator simply replace backup operator step 2 Section 3.1. full maximization case, need check step 3 whethervectors generated actions A0b improves value particular belief point.not, keep old vector associated action selected previousbackup stage. Concerning sample complexity backup0 operator, derivesimple bounds involve number actions drawn probability find goodaction (good terms value improvement b). easily showprobability least 1 , best action among n = |A0b | actions selected uniformlyrandom among best fraction actions A, n dlog / log(1 )e.practice various sampling schemes possible, vary way A0b constructed. identified number proposal distributions sampleactions: (1) uniform A, (2) Gaussian distribution centered best known actionparticular b, i.e., a(nb ), (3) Dirac distribution a(nb ). latter two takeaccount policy computed far focusing current action associatedinput belief b (as recorded Vn ), sampling uniformly random usesknowledge. Actions sampled uniformly random viewed exploring actions,two distributions exploiting current knowledge. select makeupA0b , choose combination distributions mentioned above, allowing usexplore exploit time. experiments (see Section 5.2) implementbackup0 operator using number different combinations analyze effects.206fiPerseus: Randomized Point-based Value Iteration POMDPs4. Related WorkSection 2.2 reported class approximate solution techniques POMDPsfocus computing value function approximation based fixed set prototype beliefpoints. broaden picture approximate POMDP solution methods.related overview provided Hauskrecht (2000).heuristic control strategies proposed rely solutionunderlying MDP. popular technique QMDP (Littman, Cassandra, & Kaelbling, 1995),simple approximation technique treats POMDP fully observablesolves MDP, e.g., using value iteration.resulting Q(s, a) values usedPdefine control policy (b) = arg maxa b(s)Q(s, a). QMDP effectivedomains, policies computes take informative actions, QMDPsolution assumes uncertainty regarding state disappear taking oneaction. such, QMDP policies fail domains repeated information gatheringnecessary.One way sidestep intractability exact POMDP value iteration gridbelief simplex, using either fixed grid (Lovejoy, 1991; Bonet, 2002) variable grid(Brafman, 1997; Zhou & Hansen, 2001). Value backups performed every grid point,value grid point preserved gradient ignored. valuenon-grid points defined interpolation rule. grid based methods differ mainlygrid points selected shape interpolation function takes. general,regular grids scale well problems high dimensionality non-regular gridssuffer expensive interpolation routines.alternative computing (approximate) value function policy search:methods search good policy within restricted class controllers. instance, policy iteration (Hansen, 1998b) bounded policy iteration (BPI) (Poupart & Boutilier,2004) search space (bounded-size) stochastic finite state controllers performing policy iteration steps. options searching policy space include gradientascent (Meuleau, Kim, Kaelbling, & Cassandra, 1999; Kearns, Mansour, & Ng, 2000; Ng& Jordan, 2000; Baxter & Bartlett, 2001; Aberdeen & Baxter, 2002) heuristic methods like stochastic local search (Braziunas & Boutilier, 2004). particular, Pegasusmethod (Ng & Jordan, 2000) estimates value policy simulating (bounded)number trajectories POMDP using fixed random seed, takes stepspolicy space order maximize value. Policy search methods demonstratedsuccess several cases, searching policy space often difficult pronelocal optima.Another approach solving POMDPs based heuristic search (Satia & Lave, 1973;Hansen, 1998a; Smith & Simmons, 2004). Defining initial belief b0 root node,methods build tree branches (a, o) pairs, recursively induces newbelief node. methods bear similarity Perseus since also focus reachablebeliefs b0 . However, differ way belief points selected back up;methods branch bound techniques used maintain upper lower boundsexpected return fringe nodes search tree. Hansen (1998a) proposes policyiteration method represents policy finite state controller, usesbelief tree focus search areas belief space controller207fiSpaan & VlassisName|S||O||A|Tiger-gridHallwayHallway2TagContinuous navigationcTRC3357898702002001721173016105555Table 1: Characteristics problem domains.likely improved. However, applicability large problems limited use fulldynamic programming updates. HSVI (Smith & Simmons, 2004) approximate valueiteration technique performs heuristic search belief space beliefsupdate bounds, similar work Satia Lave (1973). alternativerecent approach maintaining uncertainty estimates approximate value functionbased Gaussian Processes (Tuttle & Ghahramani, 2004).Compression techniques applied large POMDPs reduce dimensionalitybelief space, facilitating computation approximate solution. Roy, Gordon,Thrun (2005) apply Exponential family PCA sample set beliefs find lowdimensional representation, based approximate solution sought.non-linear compression effective, requires learning reward transitionmodel reduced space. model learned, one compute approximatesolution original POMDP using, e.g., MDP value iteration. Alternatively linearcompression techniques used preserve shape value function (Poupart& Boutilier, 2003). property desirable allows one exploit existingPOMDP machinery. instance, linear compression applied preprocessingstep BPI (Poupart & Boutilier, 2005) well Perseus (Poupart, 2005).literature POMDPs continuous actions still relatively sparse (Thrun,2000; Ng & Jordan, 2000; Baxter & Bartlett, 2001). Thrun (2000) applies real-time dynamicprogramming POMDP continuous state action space. work beliefsrepresented sets samples drawn state space, Q(b, a) valuesapproximated nearest-neighbor interpolation (growing) set prototype valuesupdated on-line exploration use sampling-based Bellman backups.Pegasus also handle continuous action spaces, cost sample complexitypolynomial size state space (Theorem 3, Ng & Jordan, 2000).5. Experimentsshow experimental results applying Perseus benchmark problemsPOMDP literature, present two POMDP domains testing Perseus problemscontinuous action spaces. Table 5 summarizes domains terms sizeS, A. belief set gathered simulating trajectories interactionsagent POMDP environment starting random state sampled b0 ,208fiPerseus: Randomized Point-based Value Iteration POMDPstime step agent picked action uniformly random. domains discountfactor set 0.95.5.1 Discrete Action SpacesHallway, Hallway2 Tiger-grid problems (introduced Littman et al., 1995)maze domains commonly used test scalable POMDP solution techniques(Littman et al., 1995; Brafman, 1997; Zhou & Hansen, 2001; Pineau et al., 2003; Smith &Simmons, 2004; Spaan & Vlassis, 2004; Poupart, 2005). Tag domain (Pineau et al.,2003) order magnitude larger first three problems, recent benchmark problem (Pineau et al., 2003; Smith & Simmons, 2004; Braziunas & Boutilier, 2004;Poupart & Boutilier, 2004; Spaan & Vlassis, 2004; Poupart, 2005).5.1.1 Benchmark MazesLittman et al. (1995) introduced three benchmark maze domains: Tiger-grid, Hallway,Hallway2. navigation tasks: objective agent reachdesignated goal state quickly possible. agent observes possible combinationpresence wall four directions plus unique observation indicating goalstate; Hallway problem three landmarks also available. stepagent take one five actions: {stay place, move forward, turn right, turnleft, turn around}. transition observation model noisy. Table 2(a)(c) compares performance Perseus algorithms. problemsampled set B 1,000 beliefs, executed Perseus 10 times problem usingdifferent random seeds. average expected discounted reward R computed 1,000trajectories starting random states (drawn according b0 ) 10 Perseusruns, following computed policy. reported reward R average10,000 trajectories. Perseus reaches competitive control quality using small numbervectors resulting considerable speedup.25.1.2 Taggoal Tag domain, described Pineau et al. (2003), robot searchmoving opponent robot tag it. chasing robot cannot observe opponentoccupy position, time execute tag action orderwin game, receive reward 10. opponent presentlocation, reward 10, robot penalized 1 rewardmotion action takes. opponent tries escape tagged moving awaychasing robot, however, 0.2 probability remaining location.chasing opponent robot start random location. chasing robot perfectinformation regarding position movement actions {north, east, south, west}deterministic. state space represented cross-product statestwo robots. robots located one 29 positions depicted Fig. 2(a),opponent also tagged state, resulting total 870 states. Tag rather2. Perseus QMDP results (in Section 5.1) computed Matlab Intel Pentium IV 2.4 GHz;results obtained different platforms, time comparisons rough.209fiSpaan & VlassisVreward#C100(a) State space.10110210time (s)3468101214161820100(b) Value.101102time (s)103(c) Reward.280006000101# vectors100001040002000100100101210time (s)100310(d) Nr. vectors.0101102time (s)103(e) Policy changes.Figure 2: Tag: (a) state space chasing opponent robot; (b)(e) performancePerseus.large benchmark problem compared POMDP problems studied literature,exhibits sparse structure. applied Perseus belief set B 10,000 points.Fig. 2(b)(e) show performance Perseus averaged 10 runs,error bars indicate standard deviation within runs. evaluate computed policiestested 10 trajectories (of 100 steps) times 100 starting positions(sampledstarting belief b0 ). Fig. 2(b) displays value estimated B,PV(b);(c) expected discounted reward averaged 1,000 trajectories; (d)bBnumber vectors value function estimate, |{ni }|; (e) number policychanges: number b B different optimal action Vn1 compared Vn .latter regarded measure convergence point-based solution methods(Lovejoy, 1991). see almost experiments Perseus reaches solutionsvirtually equal quality size.Table 2(d) compares performance Perseus state-of-the-art methods.results show Tag problem Perseus displays better control qualitymethod computes solution order magnitude fastermethods. Specifically, solution computed |B| = 10,000 beliefs consists 280vectors, much less PBVI maintains vector 1334 b B.indicates randomized backup stage Perseus justified: takes advantagelarge B size value function grows moderately planning horizon,leading significant speedups. interesting compare two variations BPI,bias (w/b) (Poupart, 2005) without (n/b) (Poupart & Boutilier, 2004). bias focuses210fiPerseus: Randomized Point-based Value Iteration POMDPsR||2.352.342.302.252.220.940.234860134660470120174n.a.103411041211634481000n.a.2.76Tiger-gridHSVIPerseusPBUAPBVIBPI w/bGridQMDPHallwayR||PBVIPBUAHSVIPerseusBPI w/bQMDP0.530.530.520.510.510.278630013415543n.a.28845010836351851.34(b) Results Hallway.(a) Results Tiger-grid.Hallway2R||PerseusHSVIPBUAPBVIBPI w/bQMDP0.350.350.350.340.320.0956157118409560n.a.1010010278983607902.23TagPerseusHSVIBPI w/bBBSLSBPI n/bPBVIQMDP(c) Results Hallway2.R||6.176.376.658.39.189.1816.9280165717309401334n.a.1670101132501055977218088016.1(d) Results Tag.Table 2: Experimental comparisons Perseus algorithms. Perseus resultsaveraged 10 runs. table lists method, average expecteddiscounted reward R, size solution || (value function controllersize), time (in seconds) used compute solution. Sources: PBVI(Pineau et al., 2003), BPI bias (Poupart & Boutilier, 2004), BPI bias(Poupart, 2005), HSVI (Smith & Simmons, 2004), Grid (Brafman, 1997), PBUA(Poon, 2001), BBSLS (Braziunas & Boutilier, 2004) (approximate, readfigure).reachable belief space incorporating initial belief dramatically increasesperformance solution size computation time, reach controlquality Perseus.5.2 Continuous Action Spacesapplied Perseus two domains continuous action spaces: agent equippedproximity sensors moving continuous heading distance, navigationtask involving mobile robot omnidirectional vision perceptually aliased officeenvironment.211fiSpaan & Vlassis(a) Continuous Navigation: state space.(b) cTRC: example image.(c) cTRC: environment.Figure 3: Continuous action space domains: points indicate states, F depictsgoal state. (a) Environment Continuous Navigation problem: blacksquare represents agent, four beams indicate range proximitysensors. (b) cTRC Problem: panoramic image corresponding prototypefeature vector ok O, (c) induced p(s|ok ). darker dot, higherprobability.5.2.1 Continuous Navigationfirst tested approach navigation task simulated environment,agent move continuous heading distance. Continuous Navigation environment represents 2010m hallway highly perceptually aliased (see Fig. 3(a)).agent inhabiting hallway equipped four proximity sensors, observing onecompass direction. assume proximity sensor detect whetherwall within range 2m not, resulting total number 16 possible sensor readings.agents sensor system noisy: 0.9 probability correct wall configurationobserved, otherwise one 15 observations returned equal probability.task reach goal location located open area walls near enoughagent detect. agent initialized random state environment,learn movement actions take order reach goal fast possible.Perseus assumes finite discrete state space (the set possible locationsagent) need discretize space; performed simple k-means clusteringrandom subset possible locations, resulting grid 200 locations depictedFig. 3(a). agents actions defined two parameters: headingagent turns distance intends move direction. Executingaction transports according Gaussian distribution centered expected resultingposition, defined current (x, y) position translated meter direction. standard deviation Gaussian transition model 0.25d I, meansagent wants travel, uncertainty regarding resulting212fiPerseus: Randomized Point-based Value Iteration POMDPsposition. distance parameter limited interval [0, 2]m headingranges [0, 2]. movement penalized reward 0.1 per stepreward obtainable goal location 10.test feasibility Perseus continuous action spaces, i.e., whethercompute successful policies sampling actions random, experimented numberdifferent sampling schemes backup0 operator. scheme definedoldmakeup A0b = {AU ,b , Ab }, composed samples three distributions:UN: uniformly random; Ab : Gaussian distribution centered best known actiona(nb ) b far, standard deviation = 5 = 0.1 d; Aoldb : Dirac0distribution best known action. describe Ab number samplesolddistribution {|AU |, |ANb |, |Ab |}. tested following schemes: sampling singleaction uniformly random {1, 0, 0}, Gaussian distribution a(nb ) {0, 1, 0};adding a(nb ) schemes resulting {1, 0, 1} {0, 1, 1}; {k, k, 1}, sampling kactions uniform Gaussian distributions including old action. latterscheme explores option sampling one action particular distribution,tested k = {1, 3, 10}. option try best known (old) actionparticular b relatively cheap cache transition, observation, rewardmodel first time chosen (at previous backup stage).problem used set B 10,000 belief points. evaluate control qualitycomputed value functions collected rewards sampling 10 trajectories 100random starting locations particular time intervals, following policy computedfar. trajectory stopped maximum 100 steps (if agentreached goal then), collected reward properly discounted. resultsaveraged 10 runs Perseus different random seed computedMatlab Intel Xeon 3.4GHz.Fig. 4 shows results sampling schemes mentioned above. top rowdisplays control quality indicated average discounted reward. Fig. 4(a)see sampling single action uniformly random {1, 0, 0} already gives goodperformance, extending A0b include best known action {1, 0, 1} improves controlquality. Gaussian sampling schemes {0, 1, 0} {0, 1, 1} learn slower takesmall steps action space. additional disadvantage Gaussian samplingneed user specify standard deviation. Fig. 4(b) depicts control qualityschemes sample three distributions {k, k, 1}, different valuesk. figure shows tested variations reach similar control quality, tryingactions particular b slow learning. However, looking sizevalue function (Fig. 4(c)(d)), see k = 10 resulting value function smallerscheme tested. appears experiment sampling actionsincreases chance finding high quality action generalizes well (so fewer vectorseventually needed reach control quality), higher computationalcost per backup stage. Note tested schemes number vectors valuefunction remains two orders magnitude lower size B (10,000 belief points),confirming efficient behavior Perseus randomized backup scheme.obtain insight effect sampling different distributions A0b ,computed relative frequency occurrence maximizing action AU ,b ,0 check whether vector computed using returnedAold.executingbackupb213fi77665544rewardrewardSpaan & Vlassis332211UniformUniform/OldGaussGauss/Old01 11023101 110410Uniform/Gauss/OldUniform*3/Gauss*3/OldUniform*10/Gauss*10/Old0102350350300300250250# vectors# vectors400200150100503200150500 110410Uniform/Gauss/OldUniform*3/Gauss*3/OldUniform*10/Gauss*10/Old100UniformUniform/OldGaussGauss/Old210210(d) Number vectors.110.80.8Origin best actionOrigin best action410time (s)(c) Number vectors.Improved: UniformImproved: Oldimproved0.4310time (s)0.610(b) Reward.40010410time (s)(a) Reward.0 110310time (s)0.20.6Improved: UniformImproved: GaussImproved: Oldimproved0.40.20 010110210time (s)3100 010410(e) Origin maximizing action.110210time (s)310410(f) Origin maximizing action.Figure 4: Perseus results Continuous Navigation problem, averaged 10 runs.oldleft column shows performance {|AU |, |ANb |, |Ab |} = {{1, 0, 0},{1, 0, 1}, {0, 1, 0}, {0, 1, 1}}, right column displays {k, k, 1} k ={1, 3, 10}. top row figures display average discounted reward obtainedvs. computation time, figures middle row show size valuefunction, bottom row details origin maximizing vector (seemain text).214fiPerseus: Randomized Point-based Value Iteration POMDPsV321.5Discrete 4Discrete 8Discrete 16Uniform*3/Old1210310time (s)(a) Reward.410Origin best actionDiscrete 4Discrete 8Discrete 16Uniform*3/Old2000# vectorsreward2.50.5 11012500150010005000 110210310time (s)(b) Number vectors.4100.80.6Improved: UniformImproved: Oldimproved0.40.20 110210310time (s)410(c) Origin best action.Figure 5: Performance Perseus cTRC domain, averaged 10 runs.action actually improves V (b), so, record whether action originated AU ,oldb , Ab . every backup stage normalize counts respect totalnumber backups backup stage (including improve V (b)).resulting frequencies plotted bottom row Fig. 4 two sampling schemes:sampling uniform old {1, 0, 1} (Fig. 4(e)) sampling one action three distributions {1, 1, 1} (Fig. 4(f)). see time relative frequency bestknown action grows (Improved: Old), number instances nonesampled actions improves V (b) drops almost zero (Not improved). frequenciesactions sampled uniform Gaussian distribution (Improved: Uniform resp.Improved: Gauss) resulting best action A0b (and improving V (b)) also drop.observations confirm intuition sampling actions random Perseuseffectively explore action space (which advantageous beginning algorithm), time progresses algorithm seems able exploit actionsturn useful.5.2.2 Arbitrary Heading Navigationevaluate Perseus continuous actions realistic problem comparediscretized action spaces also include cTRC domain. problem (adaptedSpaan & Vlassis, 2005) mobile robot omnidirectional vision navigatehighly perceptually aliased office environment (see Fig. 3(b) (c)). use MEMORABLE3 robot database contains set approximately 8000 panoramic imagescollected manually driving robot around 17 17 meters office environment.robot decide move 5m arbitrary direction, i.e., actions parameterized heading ranging [0, 2]. applied technique ContinuousNavigation domain grid state space 200 states (Fig. 3(c)) assume Gaussianerror resulting position. observation model compressed imagesPCA applied k-means clustering create 10 three-dimensional prototype feature vectors {o1 , . . . , o10 }. Fig. 3(c) shows inverse observation model p(s|o) one observation,Fig. 3(b) displays image database closest particular prototype obser3. MEMORABLE database provided Tsukuba Research Center Japan, RealWorld Computing project.215fiSpaan & Vlassisvation. task reach certain goal state reward 10 obtained;action yields reward 0.1. belief set B contained 10,000 belief points.compared continuous action extension Perseus three discretized versionsproblem, applied regular Perseus fixed discrete action set 4,8 16 headings equal separation (offset random angle prevent bias).oldFig. 5 displays results Perseus {|AU |, |ANb |, |Ab |} = {3, 0, 1} (other schemesturned give similar results), three discrete action spaces. Fig. 5(a) showssampling continuous results control quality discrete 16version, needs time reach (as backup0 requires generate transition,observation reward models fly). discrete cases benefit optimizedimplementation (we cache transition, observation reward models) continuousaction scheme needs computation time match performance outperform them.However, employing continuous scheme, Perseus exploits ability movearbitrary heading find better policy discrete 4 8 cases. seeproviding robot fine-grained action space leads better control quality,problem discretization 16 headings appears fine-grained enoughgood control performance. Fig. 5(b) plots number vectors value functionscheme, see reaching control quality continuousdiscrete 16 version need similar amount vectors. Fig. 5(c) shows relative frequencyoccurrence maximizing action AU Aoldb , detailed Section 5.2.1.Fig. 4(e)(f) see time best known action exploited, frequencyinstances sampled action improves value b diminished near zero.6. Conclusionspartially observable Markov decision process (POMDP) framework provides attractive principled model sequential decision making uncertainty. modelsinteraction agent stochastic environment inhabits. POMDP assumes agent imperfect information: parts environment hiddenagents sensors. goal compute plan allows agent act optimallygiven uncertainty sensory input uncertain effect executing action. Unfortunately, expressiveness POMDPs counterbalanced intractability computingexact solutions, calls efficient approximate solution techniques. workconsidered recent line research approximate point-based POMDP algorithmsplan sampled set belief points.presented Perseus, randomized point-based value iteration algorithm planning POMDPs. Perseus operates large belief set sampled simulating randomtrajectories belief space. Approximate value iteration performed belief setapplying number backup stages, ensuring backup stage valuepoint belief set improved; key observation single backup may improvevalue many belief points. Contrary point-based methods, Perseus backs(randomly selected) subset points belief set, sufficient improvingvalue belief point set. Experiments confirm allows us computevalue functions consist small number vectors (relative belief setsize), leading significant speedups. performed experiments benchmark problems216fiPerseus: Randomized Point-based Value Iteration POMDPsliterature, Perseus turns competitive methods termssolution quality computation time. extended Perseus compute plans agentslarge continuous set actions disposal, sampling actionsaction space. demonstrated viability Perseus two POMDP problems continuous action spaces: continuous navigation task robotic probleminvolving mobile robot omnidirectional vision. analyzed number differentaction sampling schemes compared discretized action spaces.Perseus recently extended deal structured state spaces (Poupart, 2005;Boger, Poupart, Hoey, Boutilier, Fernie, & Mihailidis, 2005), continuous observation spaces(Hoey & Poupart, 2005), continuous state spaces (Porta, Spaan, & Vlassis, 2005).future work would like explore alternative compact representations (Guestrin, Koller,& Parr, 2001; Theocharous, Murphy, & Kaelbling, 2004), well applying Perseuscooperative multiagent domains, extending recent approaches (Emery-Montemerlo, Gordon,Schneider, & Thrun, 2004; Becker, Zilberstein, Lesser, & Goldman, 2004; Paquet, Tobin, &Chaib-draa, 2005).Acknowledgmentswould like thank Bruno Scherrer, Geoff Gordon, Pascal Poupart, anonymousreviewers comments. research supported PROGRESS, embeddedsystems research program Dutch organization Scientific Research NWO, DutchMinistry Economic Affairs Technology Foundation STW, project AES 5414.ReferencesAberdeen, D., & Baxter, J. (2002). Scaling internal-state policy-gradient methodsPOMDPs. International Conference Machine Learning, Sydney, Australia.Andre, D., Friedman, N., & Parr, R. (1998). Generalized prioritized sweeping. AdvancesNeural Information Processing Systems 10. MIT Press.Aoki, M. (1965). Optimal control partially observable Markovian systems. JournalFranklin Institute, 280 (5), 367386.Astrom, K. J. (1965). Optimal control Markov processes incomplete state information. Journal Mathematical Analysis Applications, 10, 174205.Bagnell, J. A., Kakade, S., Ng, A. Y., & Schneider, J. (2004). Policy search dynamicprogramming. Advances Neural Information Processing Systems 16. MIT Press.Baxter, J., & Bartlett, P. (2001). Infinite-horizon policy-gradient estimation. JournalArtificial Intelligence Research, 15, 319350.Becker, R., Zilberstein, S., Lesser, V., & Goldman, C. (2004). Solving transition independentdecentralized Markov decision processes. Journal Artificial Intelligence Research,22, 423455.Bellman, R. (1957). Dynamic programming. Princeton University Press.Bertsekas, D. P., & Tsitsiklis, J. N. (1989). Parallel Distributed Computation: NumericalMethods. Prentice-Hall.217fiSpaan & VlassisBertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific,Belmont, MA.Boger, J., Poupart, P., Hoey, J., Boutilier, C., Fernie, G., & Mihailidis, A. (2005). decisiontheoretic approach task assistance persons dementia. Proc. Int. JointConf. Artificial Intelligence.Bonet, B. (2002). epsilon-optimal grid-based algorithm partially observable Markovdecision processes. International Conference Machine Learning, pp. 5158,Sydney, Australia. Morgan Kaufmann.Brafman, R. I. (1997). heuristic variable grid solution method POMDPs. Proc.National Conference Artificial Intelligence.Braziunas, D., & Boutilier, C. (2004). Stochastic local search POMDP controllers.Proc. National Conference Artificial Intelligence, San Jose, CA.Cassandra, A. R., Littman, M. L., & Zhang, N. L. (1997). Incremental pruning: simple,fast, exact method partially observable Markov decision processes. Proc.Uncertainty Artificial Intelligence, Providence, Rhode Island.Cheng, H. T. (1988). Algorithms partially observable Markov decision processes. Ph.D.thesis, University British Columbia.Dynkin, E. B. (1965). Controlled random sequences. Theory probability applications, 10 (1), 114.Emery-Montemerlo, R., Gordon, G., Schneider, J., & Thrun, S. (2004). Approximate solutions partially observable stochastic games common payoffs. Proc. Int.Joint Conference Autonomous Agents Multi Agent Systems.Guestrin, C., Koller, D., & Parr, R. (2001). Solving factored POMDPs linear valuefunctions. IJCAI-01 workshop Planning Uncertainty IncompleteInformation.Hansen, E. A. (1998a). Finite-memory control partially observable systems. Ph.D. thesis,University Massachusetts, Amherst.Hansen, E. A. (1998b). Solving POMDPs searching policy space. Proc. Uncertainty Artificial Intelligence, pp. 211219.Hauskrecht, M. (2000). Value function approximations partially observable Markovdecision processes. Journal Artificial Intelligence Research, 13, 3395.Hoey, J., & Poupart, P. (2005). Solving POMDPs continuous large discrete observation spaces. Proc. Int. Joint Conf. Artificial Intelligence.Kaelbling, L. P., Littman, M. L., & Cassandra, A. R. (1998). Planning actingpartially observable stochastic domains. Artificial Intelligence, 101, 99134.Kearns, M., Mansour, Y., & Ng, A. Y. (2000). Approximate planning large POMDPsvia reusable trajectories. Advances Neural Information Processing Systems 12.MIT Press.Lagoudakis, M. G., & Parr, R. (2003). Least-squares policy iteration. Journal MachineLearning Research, 4, 11071149.218fiPerseus: Randomized Point-based Value Iteration POMDPsLittman, M. L., Cassandra, A. R., & Kaelbling, L. P. (1995). Learning policies partially observable environments: Scaling up. International Conference MachineLearning, San Francisco, CA.Lovejoy, W. S. (1991). Computationally feasible bounds partially observed Markovdecision processes. Operations Research, 39 (1), 162175.Madani, O., Hanks, S., & Condon, A. (1999). undecidability probabilistic planninginfinite-horizon partially observable Markov decision problems. Proc.National Conference Artificial Intelligence, Orlando, Florida.Meuleau, N., Kim, K.-E., Kaelbling, L. P., & Cassandra, A. R. (1999). Solving POMDPssearching space finite policies. Proc. Uncertainty Artificial Intelligence.Monahan, G. E. (1982). survey partially observable Markov decision processes: theory,models algorithms. Management Science, 28 (1).Moore, A. W., & Atkeson, C. G. (1993). Prioritized sweeping: Reinforcement learningless data less time. Machine Learning, 13, 103130.Ng, A. Y., & Jordan, M. (2000). PEGASUS: policy search method large MDPsPOMDPs. Proc. Uncertainty Artificial Intelligence.Papadimitriou, C. H., & Tsitsiklis, J. N. (1987). complexity Markov decision processes. Mathematics operations research, 12 (3), 441450.Paquet, S., Tobin, L., & Chaib-draa, B. (2005). online POMDP algorithm complexmultiagent environments. Proc. Int. Joint Conference Autonomous AgentsMulti Agent Systems.Pineau, J., Gordon, G., & Thrun, S. (2003). Point-based value iteration: anytimealgorithm POMDPs. Proc. Int. Joint Conf. Artificial Intelligence, Acapulco,Mexico.Poon, K.-M. (2001). fast heuristic algorithm decision-theoretic planning. Mastersthesis, Hong-Kong University Science Technology.Porta, J. M., Spaan, M. T. J., & Vlassis, N. (2005). Robot planning partially observablecontinuous domains. Robotics: Science Systems, MIT, Cambridge, MA.Poupart, P., & Boutilier, C. (2003). Value-directed compression POMDPs. AdvancesNeural Information Processing Systems 15. MIT Press.Poupart, P., & Boutilier, C. (2004). Bounded finite state controllers. Advances NeuralInformation Processing Systems 16. MIT Press.Poupart, P. (2005). Exploiting Structure Efficiently Solve Large Scale Partially ObservableMarkov Decision Processes. Ph.D. thesis, University Toronto.Poupart, P., & Boutilier, C. (2005). VDCBPI: approximate scalable algorithm largescale POMDPs. Advances Neural Information Processing Systems 17. MITPress.Puterman, M. L. (1994). Markov Decision ProcessesDiscrete Stochastic Dynamic Programming. John Wiley & Sons, Inc., New York, NY.219fiSpaan & VlassisRoy, N., & Gordon, G. (2003). Exponential family PCA belief compression POMDPs.Advances Neural Information Processing Systems 15. MIT Press.Roy, N., Gordon, G., & Thrun, S. (2005). Finding approximate POMDP solutionsbelief compression. Journal Artificial Intelligence Research, 23, 140.Russell, S. J., & Norvig, P. (2003). Artificial Intelligence: modern approach (2nd edition).Prentice Hall.Satia, J. K., & Lave, R. E. (1973). Markovian decision processes probabilistic observation states. Management Science, 20 (1).Smallwood, R. D., & Sondik, E. J. (1973). optimal control partially observableMarkov decision processes finite horizon. Operations Research, 21, 10711088.Smith, T., & Simmons, R. (2004). Heuristic search value iteration POMDPs. Proc.Uncertainty Artificial Intelligence.Sondik, E. J. (1971). optimal control partially observable Markov decision processes.Ph.D. thesis, Stanford University.Spaan, M. T. J., & Vlassis, N. (2004). point-based POMDP algorithm robot planning.Proceedings IEEE International Conference Robotics Automation, pp.23992404, New Orleans, Louisiana.Spaan, M. T. J., & Vlassis, N. (2005). Planning continuous actions partially observable environments. Proceedings IEEE International Conference RoboticsAutomation, pp. 34693474, Barcelona, Spain.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press.Szepesvari, C., & Littman, M. L. (1996). Generalized Markov decision processes: Dynamicprogramming reinforcement-learning algorithms. Tech. rep. CS-96-11, BrownUniversity, Department Computer Science.Theocharous, G., Murphy, K., & Kaelbling, L. P. (2004). Representing hierarchicalPOMDPs DBNs multi-scale robot localization. Proceedings IEEEInternational Conference Robotics Automation.Thrun, S. (2000). Monte Carlo POMDPs. Advances Neural Information ProcessingSystems 12. MIT Press.Tuttle, E., & Ghahramani, Z. (2004). Propagating uncertainty POMDP value iterationGaussian processes. Tech. rep., Gatsby Computational Neuroscience Unit.Vlassis, N., & Spaan, M. T. J. (2004). fast point-based algorithm POMDPs.Benelearn 2004: Proceedings Annual Machine Learning Conference BelgiumNetherlands, pp. 170176, Brussels, Belgium. (Also presented NIPS 16workshop Planning Real-World, Whistler, Canada, Dec 2003).Zhang, N. L., & Zhang, W. (2001). Speeding convergence value iteration partially observable Markov decision processes. Journal Artificial Intelligence Research,14, 2951.Zhou, R., & Hansen, E. A. (2001). improved grid-based approximation algorithmPOMDPs. Proc. Int. Joint Conf. Artificial Intelligence, Seattle, WA.220fifffifi fi!" #$!fffifififffiff fifffififffifffifffiffff fifffffffi ffffffffff ffff ff fffi ffff ff ffff ffff ff fffffffiff fi fi ff fffffiffff ff ff fffi fi fffffffffi ffff fiff ffffff fffffiffff ffffff ff ff ffffff ff fffffi fffiffffffffffff ffffff fffifffiff! fi ffff fffifi ffffff"fffifffffifi! fffi fffifi fffiff#ff fiff ffffff fi fffffi fffiffff$fffffiffffffff ffffffff ff %&ff'ff()*+&,ff ff ffffffff ff fffiffff ffffffff fffi -./ffff0 fiff1.../ffffff0 ffff ff .23 fiff fffffi fffffifffffffffifififffifffi fffifffiffff ff fi fi fifififf!fi!$ff fffi fififififffffififffiff ff ff fifi ffff !" #fiff #fifi !$ % ff &' &fifi' ff & fi ff fi'fi fi'fifi( (ff& ) * * fi ff" +, -.." fifi + % fi !$fi fifi %&' &fi ffff fifififfffff "#$ fffffi% fffffififffifififi fififififfff ff&fffffififffi'fi ff!ff (fi fi ) *+,,-. (fi ) +,,-+ ff/fffi fffffffi fi fi fffi ff! fifi! fi! ffff0fififfffff0fi fi fifffi fifffffifi fffiff fi fffffifffiff fffffiffff fffiff&1fiff ffff fi fi 0fifi fi !2fiffff fi fiffffff'fifi0fffffi ) 3 4556 78fifi fi 9 1) :! +,,;. ! ( ) 1455<. +,,+ fiffffff+fi78 fiff!ffff=ff>? !!'fiff=$fi 78fffiff fiff&& fiffffffffffff !fffffi @:!) ( 455+78fi fifffi! fi ff ff$@fi!&&ff ff ff/ fifffififffifi fi!3fififffffiff fffffiffffffff& !4.5fifi fifffiff ff fifi fiff ffff&fffffififffifffffi# "!! fiff fffiff!ff 0 fffffififf fi!ffff ! $fffi'fi fififfffffff= fiff/=# "ffffff ff2 ff;fi# "fffffiff ffff# "ff= fifffffifffifffifi fifififffi (fi *) fi +,,A# "fffiff fifffffi 00!fffffi/! 4566.fiff +,,- ffff 'fifffi# "00= 00fffi fifffi 2fiff fifi ffff fffffiff fiff00ff8 ) " +,,-. B455C. Bfi8 )+,,4 fifffffffffiEff!ff+ ff3fifffifffffifffiff&ffffffFfi != fffffi! fifi # " fiff2ffffffff fiff fi 00 &fifffi fifffifi fifffi fi/ fffi ff 0 1 ff & ff 'fifi fi fifi &2! / 3fifi 4 0 1 ff ff ff & ff 4ff & ff &ff fi2 # ff fifi &fifi 5ff6--7" 5 8 --9" 8 : ; --.$ ff & fi'fi ff 6fffifi '6ff ff ff ff & ) )ff<8 2$4.6fi ffff fifififffi!"fffffififi # "fiffCfiffff!ff fi ! fiG 3 8ffE@ fi3 ) 8ff 455- ff #F'fi7ff 8#F 78 ) H 4555 fffifffi ff!! fi" ) (4556. #!) +,,+. +,,,fffififf+,,, /ff ff! ff=# " fifffffffi=ffff# "9fffififf& !! fffifffi # "fi fifffffifi fi C,Ifi! ff 4,,,I.fifffi fffffiffffff,+A fi # " ff ff!fffi. fi= 5AI =fifffffifiG: fi fifffifffffi ff: fffffiff= fi J! ffJfffi:fiff# "ff fiff fifffffiff00ff: ff &# " fifffifffififf fiffff+fifffifi= fiff'fifffffi-fffifffffi7 # fifi ff & ff fi fi ff &ffff fififf fi fi &ff' ff ff ff ff &' &ff ff' fifi 6ff fifi:' fffi fififi 3 'ffff & ' &ff &fi 6fifi fi ff & ff fi <%=) ><( &ffff ff fififi& ff ff fiff fi 3% &'fi fffi ff fi41.fifi fifffiff ff fifi fifi!fffifffi fi fffffi; 'fififfff fifffffiff# "fffffi ffffffff!ff @ fi#F 78fffififf fiff fi'fifffiC<ff fffififffi ff fi fffi26 fiff!= fi fifi !fi ff=ffKff!fi ffff fiffffffff+4++fi78=4 78 ff!ff!fiff! = fififf!ff! fi= fi fi fffffiff ff=fififf2+-fifi!fffffiff= fi& fffififi fiff fifffifi ffKfififffffffififi2 %"fiff fffifi89ff 4566 fifffi fifififi fififi/ff fifffifffifi fffffi/fififf&fifffffifi 2 %"fi fffffiff ff= ! 'fiff4 0 2 %"fi >?L fififi'fi>?fiFfi != fffffiff411fi ffff fifififffi fifffffffffi Kfi= fiff2 %"fffffifi Jfffiffff ff Jff " ) 1 4555fi fifi! fi ffff!fffifi'fiff4 ff=fffffffi fiffffff !>fi? )ff45A6fi fi ! = fififffffiff Eff! fififffffi 'fififi=ff ffff ff#1#(fi ) 8 4554fi fiffffffffK!0#1# fffifffiff! ffffffff ff#1#E JEfffififf ff!fffi/ff'fiff4fffifffffi9#1# !9fffffiff! (! 455A 455A ffff!ff$fiG fffffififi fffi.fi ff. ff!%! ffffffff fi fi1#1#fifffffi (! ) 8 455A (!ffffff $! #1#1#1#fififfGfffffffifi&fi412fifi fifffiff ff fifi fiff fffififffffffffi 1#1#fiff=4/ #1# 1#1# ffffffff fi'fififffffffffffififf Efi fiffff ffff 'fifi=fi!# ff ffff!fifi9 ff 455< *455A. 7)455<fiK" ) 8'fi 4554 Kffffff *455-ff>K?*#1 ffKffffff fffffifi9*#1G>'fi? fi fififfffff fi>=ff?ffffffffff >'fi? 2fi 9ff >? ff 1L ) Mfi 455C fi ff ff ffffffff fifi 9ff!fiff!Kfffiff! ff ! fifffffi'fififf! fiff fi9fi fi'fiffKffffff ff ff ffff= fffi fffffiff fffi'fi=fffifffffi!fi 'fifffffffffffi Ffiff! fifi0ff !fi ff'fifffiff"#$ %fi&78fffi ffff! 3 8ff 3 ) 8ff 455- ! !fiffff fffffifi C Cff fffffi!417fi ffff fififi&fi !'fififf$fffi 'fififffffiffff ! fi fi@fffffffififf fifffifffififf& fffi !fffi! fi fi ff!fiff!fffi !!&!ffff@ fiff fififf ffff! 3 8ff fiff fffffi! fi ! fi0 fffffififffffffi fi!ff fififffi fifififfff fifffififffififffffi! ffffff fifffiffff3 8ff 455-! fi@fffffi 0fffi(,fi 4566>?ff fi# " fffifi fi # "ff3 8ff 455-@ fiff fiff! fffiff # "'($)"ff#'fi "ffff #F 78+,,, Kff!!fifffffffifffi fi fffiffff "fiff 455C.*!! ) * 455A fiL! / #F 78& ff fifffffffi &=fi fi ff &ff ! fififi414fifi fifffiff ff fifi fifififffffi!fifffffifi ! fi#F 78&fffffififffiff) H 4555fi fi #F 78fffffi ! fifffiEK! ffff!fi2fifffffifi=fffi#F 78fi fffffififffffffiff #F 78 fiff ff fffi!ff @ fifiJfffi! fiff& 0ff! 2fi fffffiffEfffffi fiffff 'fififififf!'fiffff =ff fififi ff ff! +,,,fiff Eff fififfff=++4ff fifi ! fffffifi!ff 2#F 78fffi fi+,,, fffffiff/ff fifffffi # "fiffffff!fffi fffffffiff &#F 78 ff! fffi# "' fffi *fi78fi fffi) fi +,,,78fffffi fi=fiffffffff fi fiffffff2 ff! fiff ff! fi! fifffffi fiffffff fi ! fiffff !fifffi!413fi ffff fifififfff!fiffff Jffff ! fi Efi Kfifffffi fiffJ fffffffifi!ffff fi /fffiff!ff fffffiff=fffffffffifffffi !fi ! ff fifffiffff4 fifffffi fi:ff 455+ 3 3 4555#!+,,+ ff ! ffffff fiffff!ff fiff /!:ff 455+ 3 3 4555fffiff'fififffifffifffffififfffff!! #!+,,+ fifififffffifi! fififffffifffffi'fifi ! fffffififffififi ! & fifi% +ff#Bfi 8+,,4 fffffiEfi fi! (# (# 2) L +,,4fffffifi/ fffffifffifffffiE (# fifffffifi / fi fffffffi'fifi fiff Effff!fffi(# 3fi4555 fiffff= fiff fifffffi9 fi fifi ff ff & ' fifi ff % ff' ff & fi ff & ff fi41-fifi fifffiff ff fifi fiff fi fffifffi (#fffiff fffffiff! Bfi +,,4fi /fffffiEfffffi: 'fiffff=ff# " ffFfi !& ff Bfi +,,42! fifffi 'fi fffffi: ffff fifi fifffi fffffi. fiffffffFff=fffffi2fffffififi ffffff fi fi !fifffi !!fffiff ! ff- /fi !fi ff! fiff.!fiff fi, +ffff# "fffffi8 :) /& 45C, fi fiff fffiff!fi/&fiG8 = fiff fi>?fifffiff# "! fifififf8fffffifffffiff # "ff= fiff !8fiff Ffi ff # "ff=fffifffffiff# "ff fi!'fiffff455< fifififf ff@fffifi!fifffi2fifffffififf!418fi ffff fififi!'fi ! fifififi&fffiffffff 'fiffffffff 7'fififi ff !fi ff!&$ %fi& !%! 'fi0!ff ff !fiff ff! &ff! fffffiFfi# "fffifffi @:!) ( 455+fffififfffff!fffi !fi fi fffiff ffKfi!*) (+,,+ /fiff! fi fifi fiff fiE fffffififf>?! fi fi" ) (45564556!fifi fifffi 3fifffifffffffffiff Nfi 8) 3! 4555.7" 7ff /! ) 3fi! +,,, /fi'fifffffiff # "ff fifffffi 2fifffifffffiff! ff&ff=2! 7+,,,!ff'fifi&'fififf 3@fffffifi fffi= ffffff ff ! ff fi 1 !fffi ff fi=fi3fiff& fi !& ff 'fi! fi'fififi4566. #fi! 3! ) "!+,,4ff fffifffifi415fifi fifffiff ff fifi fi& fifffifi ff= ff fffffifi *) 3fiff +,,-fi !'fi2 fffiff'fiffff'fifffi # "'fiff/'fiffff# ". # "fiff'fi!; ff0!fi ! H) H 455< fi(!) :! +,,; fffffiMff ) 4555 ff fi&&fi'fi!/fi= fifi!'fifffiff fifffffifi 'fi!fffifi fi 2fififi ff'fifififffi fffi fi !ff !=! 0ffff fffffifi# "fi ff0fffi fififfff fffi ff fi fifffiG fffifi&ff!fffffififi! fiff fifffi fifi'fififf fifi fi0 fififffffiff fi9 fifffifffffiff fifffffifi 9 fffffifffffiffJ >fi? " =fiff"fffifififf Kfifi fififffffiffffff7fifffffifififf fifi fiffEff!ff fi / !ff'fi fifffififi !fi ff fi: fi!fi!&ff416fi ffff fififi# " 00fffifififiC# "fiff0 ff2fiffffffff!@ fi#F 78ffffff ff !ffff &ffff!fffffifiG"ff!(fi)fffffi/ fffffffffffiff!fffiffffff fififi)fififfffffff 0ff fiff1# "&fiff*fiffff fi fffffffiffff!fifi ff! fifffifi ff!fffffi'fi ! ffff!fffffi!fffi! ffff fi &fiff !fifffffififfffff fiff'fiff=fiffffff 'fi# "00ff # "=# "ffffff Ffiffff# "0 fffi;+Kfi fi2fi fi ff# "'fifffi fi fiff0!fifiKffff E fffi 7fi ff ! fi !fifi ff fi/fi ! 'fiff fi ff42.fifi fifffiff ff fifi fiff # " fififffi !fi fffi 'fi'fififffifi fffffi# "fifififfff= fi@fi'fi# "ffff0fffi@ fi#F 78ffffff+ ,ff@ffff! fifi fifffifi'fiffffff78! fifffi !fi! ff78 'fiff fiG==Gfi!Gfifi fi!078Gff1fififffifi'fi ( ff 4 fi4(), fi4fi ffffff0 fifi fi=fififf !E >?fiff=fiff='fiGff+ffGffPfffi ff-fi fiff9-ff'fiff fi fi0ff ! fi fi/fffffi ! fi! fi fifi @ffff fi fi!421fifi ffff fififififiGPfffffi ff;fffififfffffff fi fifffiffCfffi=fifiPfffffffi ffff<:fi !fifi fi<ff fififi fi :!(ff fi Qfi fi :!) ( 455+GQ ($ 4 Q P R P ff Q6ffffffff/fi P4, fi fi 4fi Qfffifi !fi3 Kfifi fifi Qffff fi fi :!) ( 455+fi fifi 6 fiffff+fi-fifififi!%!fifffi fi(fiff0fi4!fffifi-E @ff= fi @fifiL @fifi 0 @ fifi ff ff!"#$fiff 0@ fififi&fffffiff3: ff fiff'fifi fi&ffffffffffffffffff422fifi fifffiff ff fifi fifi @ fi= >&fi?ff.fififffifi fifi@ fifffffiff0ff@ fififi fififi@3 ) 8ff 455-fifi3:fifi ff fffffifi fffi fi 3LffE:!4565 fffiff$E 'fifi2fi 4 3'fi'fi $ fi2fi 4fifififi 2fi 4 fiffff! fi fififf fi9fifffiff fi2fi 4fiff fffi fi/ ! fiff ffff!ff 'fi 'fi# "=4=0 ff/fiffffff fi2fi 4fifffi fifffffiffff'fifffffiff fififf2fi ! 'fi 'fifffffifffi'fi fififf fi fi fififififfC+'fi! ff fi=# "ffffffffff!ffffffffffffffffffffff? / ff ' & & ff fi 'ff fffffifi ff fi ff ff' ' fffi ff fiff 'fifi fi ff ff fi& fififi @fifi427fi ffff fififiNetwork2a2saestequra1a1(a)Call sourceCall destinationnode / agenta2 forwards requesta2preallocatea3(b)a1Final routea3a2senAllocatea1dsconnectmessage(c)drop calla3a2bandwidth a3(d)deallocatea12fi 4GffCfffifi ffffff' ## ff !)"fi ff $ fi$# "fffffi0 E3: fi3:fffffffiff fifffffiff$ fi$ fiff E3: fi$fffi@ fi fi 'fi6G $ 4 $ Pff>?@ fi@ff fi'fi $ fffffiff 4 fifffffififffffiffff fffffififffffffifi fiC- fifi*fffiff4 fiffff $fifififffi fifi$fffi fffifi fiffffff ff fiffffff ffffffffffffffffffffffffffffff. ffff A5fi &fffffi ffff &fi424fifi fifffiff ff fifi fiC-EEfffffifffiffff fi /ff0!fi! &fifi'fi 'fi F fffffi fifffiff fi/& fffffffififf # "# "0 ffff fffffifffffffifiG0ff!fi'fi ffff.fffffifffffi .ffff'fi fffififi /& fffiff# " fffffifffffffi# "fifffffffi 3fififf fiffff# "=fiffff ! ! fffiffff fi=0fiff fffi fi=ff!ff'fi fififffffiff>? @fiffffff'fi@fffiff &Efi"#@ fiff00fi++4@ fi@7fi($E fiff 3:P +fifi ($ffQ ($ ff($ ff($fffffi ( ($0fffffifffffffffiff fiff($ fffffffiff>? ($ff fi'fiP 4 G P 4fiff fiff4 P 4 P Q ($!fiEfffi fi2fi 4ff2fi 4ff fi@7fffi fi fi# ";+4&ffffffffffffffffff423fi ffff fififiG@7fffffffi# "fiffff fifffi'fi'#$#F 78fffffi 0 ff+,,,fi #F 78 +,,, ffffffGfifi fiff4,, fi!fiA, J fffffiff=<++,,,.ff fi fi4,,C+ffff fiff fi :fi#F 78 fffi'fififf fi9 fffifi!fi @ fifffi! fi ffff! fi3Lff@ff 7fifi#F 78ff fi fiff= fifififffiffffff fi fifffifffiff!fi fi fi@ fiff$fifi'fi ($ fifi@ fi 0 fiffff fi'fiff# ";+4ffffffffffff" fiff ##fffiffff00 := # "fifffffffi fffi= fi fifffififffffifffi ff fiff.fffi ! fifi-!'fi'fififi fffififi $$! fi! fifffi!G $fiffff!$ fi!ffffffffffffff42-fifi fifffiff ff fifi fi!fffi$!ff;+0 0ff ! 'fi! fffifi fififf fi fi'fififffffifffifi fffffifi # " 00 fi fififf=fffffi& fiE !'fifi fi2fi!fifi-ff =fffi! fi fiff!fffffffifi'fiAC fi ffff ff fi'fi Kfi!>fi'fi? ff >?= : fi'fi= ($$;+fifi2 ff!'fififi;+fifffffifffffi'fiffE ! Eff!ffGO45fi fiG44,0ffffff 2 fffffffiff fififf fi ! fi& ff fi fifi fi'fi ff!fi & fiff!ff fifi fffi'fi! ff0 fffi'fiff fffffffi& fiff fifi fffffifffiff Ffifffi7fififfffff!fi ffEfi/fiffffffffffffffffffffffffffff428fi ffff fifififi fifffi Efiffff fifffffi ff &Efiffff& fffffi. "fi -fifi(fifffififffffi00 2fi $ E ! fi$ffff $ !fi 4 /! 4 +& fffi fffi 'fi 4 0fffffffifi fffffifi;++fififfff@7 00 !!ff 44 'fifi'fi ($ E !ff 2'fiffff ($ +T fiff'fi($ ($ ff ! fiP +T 0 fffffifffffffi7fi;+++($ff($/($ E !ffff (fi 'fi(fi 'fi ($ ( fifi !PP P +T+Tff( ($ff(fffi 'fi ( 'fi ( (P +T +P +T + P +T+ +T 9fi fi'fiffP+Tfffi'fifffi 4 +T P 0fi fiP 4T 4 P +Tfifffiff P 4T 4 P +Tfiffff4fiffff ff fiffffffff ff=4ffff fifffffffi'fififi $ fiff'fi E !ff $ffff P+T 4 fiff +4 / ! fi fi'fi$ 'fi ffff fiffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff- : ff 2 & BC &fffffi ff ff @/ ff fi &ff ffff fffi3fi ff' ff4 &fi425fifi fifffiff ff fifi fi4Gfffffiff$P +Tff$P +TP P +TffffP +T +P P +T +P +T P +T += ff /ff P +Tff$$Gff$(,ff4 P +T Pff+T P +T + +440fifi fi'fi44fi4ff fifffffi'fifffffi .fi 2P +T44fi$4 P+T + +fiff4+44-fi 4+ ! $fffififf ff=!fffiG4;4 Pfffifi00ff ff# "ffffff.$ "fi -fifi(fi"fffififffffi# "ffA+ fiff!ff $!'fi ff# "fffffffi!ff!fffifffiff! fffifffffffifffffiffffffff426fffit + (n2)2 tc2 tc+ (n2)tc+ (n2)tc1Agent23Timeffff fififin2 communicating 1n communicating n1Information transmission2fi +Gffff # "ffff$ff! ffff fi P P+ 1$ ffffff P P PPT P+ff$ ff9ff!$ P +T P +T P P +T P+2fi += fifffffffi fiff$fffi'fifffffifi $fffifi'fi fiffffffff G$ 4T 44Afiff4-& fffifi 4Aff$fffififf ff=fffffiG4Cfi fffi fffi4C 4;# " ff 00ffffffffffffffffffffffffffffffffffff.+ fi"fi -fifi(fi" !A- fi# "ff!fffffi 4Cfi 00Eff4 Pfffi 4; "fffifififi%&& fiff47.fifi fifffiff ff fifi fifi4+T4 P4<fi! fifffifffffifffffi$/ fi # "fi fffi 00/# "fiffffffff00 fi# " ff fiff.. -fi! 'fi ffffff"fffffffi# "ffff 'fiff# " 00 !fiffff ff fi!fiffff /fffi fffi$$4ff:ffffff 1fffffi fififf fiff fiff :fffi fiffffffffffff00# "A;fiff# "=G*fi 'fi4! $fiff fffffifi/ fififf ff( ! fi $fffi ff$fi&ffGfiffP 4 ffff46fi($fiff fiL P 4&ff ff fffiffP4& ff; 3fi ff& & ff ff fffi fi& ' fifi ff &ff ff fi &ff fififf$ fi ff ff 'fifi & ff / ff & ff'fi ff ff:' fffi$ E471fi ffff fififi$0fiff ff fffffffi ffE >=?ff fi=ffff ff / fiff 46ff ff fi'fi fffi fifi&fifi ffffA; # "00 fififififi % &&fiffff !fffiffff ff ff fi.0 fifi!ff "& 'fiA+ A- fiff! fffffffi 4;4Cfiff!fiff fi! fffffi fffififfff00 fffi 4; fi fiffff ff 00fifi"A+ fffifffi 4;$+T45ffff)$$ ffff$fffffiA;4Cff45 fiG+ +T+,)$fifffffififi $ )fi% && ff fiff/ Eff ff 3'fi ' 6ff @fi fifi /ff &fi ff ' ff &ffff ff fi472$fifi fifffiff ff fifi fifi ff+, ff 4+T+4#-ff4fifi fifffi!fffififffffifffffffififfff# "00ffAA fi! fiff! fi # " fi00fififi + )fi %&&ff fififffffi'fifffi # "fffi fiff :fi# "!ff00fiff ff fffi# "fififffffi!fffiff$ffff%fiff&'ff= fiff fifffffifffifi fffi&ff fi'fififffffiff fifi!fiffff# " @7 #F 78;+fffi2fi# "ff;+40 fifi: fifffifffi0ff ! ) 3fi+,,;fffffffifffffiff0ff0 ff-fffffifffifffffffffifffffffi"%fffi fifffi=fifififi fi !477fi ffff fififiEffGfffi fi fffffifffffiF fififififi fi fifififi!9ff 9fffi=fffffiff: =fffifi fffffiff fiff fi90 fifi!%! fifffi fi fi;+fi'fifi/ fffifffffffffi;+&fiffff G'fi'fi'fi'fifi= =fifiG! $.fi . @ fi@ fiEffG R, 4Sfi . G fi. G . G !fffifffififf . !ff ff.fffiff fifffffiff #F78&@ff fffi#F 78 fifi fififfff&fffifi!fifiEfififi E @ffG>?fifffiffff>?;+-= fi fi fffiffffffGfifififfffffffffffffffffffffffffffffffffffffffffff474fifi fifffiff ff fifi fiff! fi fifffi fififffffifi ($fifi$ fifi / fi fi:2fi -$4!fifffffiff fiffff+ffff;fi $--fi-; fffi-C fi-= = !fi!fi< ff6 fffi 4, 5($4,fi ff=fffi44 fi4+fffffi4- $ffA, fifi@ff.fi#F 78 fiA+ A;fifi'fiAAfffififfA<2fffiA6fififffifi/$!!fi4;fi4C fffi fi+4fi;+ff;5 fi.fffi/fi #F 78+4ff+,. fiff#F 78fffi# "C-4 C-+ff$ 946 ;<fi# " fifffiffffffffffffffffffffff!ffffffffffffff! / 3& ff' ' ff ff ff fifi ff = fi% 'fi & fi fifififf2 ff A5fi ' fifi % &' 36fi fifi fi 3fifi $ : ff ff A5ff fi ff ' # ff' fffifi fi & ff' ' ff ff (# fifi@fi ff fi fifi473fi ffff fifififffi fi fifififffffffifffffiff ! !ff " !fffffiff ! # !" "# " $ !ffff !fffffiff ! !!ff !" %&'&( %&'&)fi#ff ! $!%&' *&)&'ff"#ff " !! +, " !#!$ff %ff&,ff ! $!%&'fi# %ffff" !ff (& *&)&)!" #fffi' ) %fi%(%(ff -fffffi&,ff "ffff ../fffffiff ! $!%&' fi# ! /-/,))ff fi fffffi%ff (%ff ()!ff !" %&'&( %&'&)! 0))ff fi fffffi% (% ()fi#ff "ffff -./1fffffiff ! $!%&'%ff (%ff (% (% (ff" "&,ffff ! $!%&' 2 $ /-/,ff* #! " ffff * %++#fffiff !ff ! 02fi -Gfi ff47-fifi fifffiff ff fifi fiffffff fffififffffifi;AC-4 C-+ = fifififi fi@ff;C fi fi@;4 fififffffffiFfififf'fi+;=fiE @fffififiGffffffff')ff++0 'fi++ffff # " @7fi#F 78fi @ fi'fi++ />fffi? ff G R,4S fffi&fi @ff fi &ff !fi3Lff:!4565fi'fifi+A+6 @7fifffi-4'fi ffK ff@- ff .;++ 'fifi,ff fiff-+ #F 78@ff+<'fiff'fi#F 780fiffff#F 78fi2ff! fifiC,fffifffi fiff fi fiffC4fffffiEfi= ff fi ff-6fiff fffi2fi - 9ff fi fiC-fiC;fffffiff $fffififffi'fi-5ff# " fi@ fi;,fifffifffi fffi#F78 @ffffffA< fi :fi ffff #F 78C-+ffff""ffffffffffffffffffffffffffffffff478fi ffff fififififfff-=ff=fiff&fffifi fi!@ff ff fi fiff!ffff!fffffifffiff fi# " fi =fififffi# $ff0$ "1fffiC+fi# "fffffiffff >ff?fffi : fffiff fiff# "L fiff ff # " !ff ff # "$- ' !) .fi /'# 02fi - fifi# " fifffifi fi fi ff G+-ffff% fffffifi fffi2fi -ffff fi'fifi fi@ff fiff fifffi fifi >ff?% ffffffff# $ff-' !) +fi /'#+0ff# " G fifi 2 ff fi# " fifffiG+;ffP 4ffffff fififffifififf#F 78fiffff7 % ff fi ff ff fi fi 7 ff ff''fi ff &' fffifi3 fi fi 'fi 3fi & ff'fi ff 6fi3 ff fiff & &@ ff ffff ff & )D 4 fi6 ffff fi ff 5 + C'$475fifi fifffiff ff fifi fi( )*) ff3fiC fifffffi &# " ff ff! @7 #F78fifffffiffff fi'fi fiffff fffi2 fifffffi fi fffffffiff01 &2 ) )ffffffK!fffffiff fifi fifififffi fi fififf fifi fffififfff fi fi ff fifffiff fifi fifi fifffifi fifffffiff !fffififf fifi fi ! ! fifffi! fi !fifififffififffiff : fffi >-fi 3 ? D(! =fiffff D(ff fi=% $ ff fifffiff 4 fi +fifffi fi$fffi fi fifi ff D(+ffD( fi fi+=fffifiD(ff fffffiff D(! fi! =&'!'!!9 ff /F)ff ff fi fi ff fi' '? : /F)fi fifififi ff fffi ff fi fffi fifi/F)476fi ffff fififi1)ff $ ) %))fi ff<44 fffi fififfff ff fffi fiff fffifi fffffiffff ff /&fi fffifffi 'fifififf"fi fifi ff fifffffffififffi fifififffffififf fffi'fifi fffi fiff fifififi= fffffiff fififffi ! !fi fffifi fifffifififf fifffififffi2& fi& fi fi fi ff& fffffi&'!&!1 $!)+fi ff fi& ff fffffiC+ fiff/ ffff ffff!fffi fifffiff !fffi'fiff fffi @7 fffffffi'fi;++ffff# " ff ff fffiffffffC-4 C-+0fffifi fifffiff $* fiffff&'fiff F. # ff' fi &ff A5 ff fi fifi fi ff' fi ff fi ff ff fififi & ff ff BCA>6C+ % &' fifi & & ff fifi ff ff A5ff fi fifi & ff fi ff ff A5fi ) fi 7$44.fifi fifffiff ff fifi fi2fi ;G -Cfififfff#F 78fffffi'fifffi fi @ fi<+ff &# " / ff #F 78fffi fifffiff fi ff fi fffifffffiJ fiff fffifffi ff ff fffi fi fi= fiffffffE !fffifffifffififf ffff fifffifi fiffff& fffffifffi fffifi$ 7ff$ff2fi AG 7ff !2 !ff @7 # " # " #F 78 fffffi<4441fi ffff fififi9ff fi fiff& !fi fiff 2fi ;-CfiffJ A,ff 2fi 4,, ff 2fi -Cfififi78!fi++fififf!fffi fiffff = fi fi ff&L$+= fi fiffE0 fffi!fffffifffffi ffff fi fiff fiG,,- 3Lfffffi ,4fiff -C A, 4,,ff= fi ;: fiffL ! fi+,ff fiff fi>?!ff!fi && ! ff "ffff :fifffiffff fi fifffififffffifififffifi : fi& fifffifffifi&fi fififf # " @7 #F 78ff'fifffififffifi A,,,,,ff2fi ; 4,,,,,,ff2fi +,,,,,,ff2fi 7fi 4,fffifi = fi= 5AI = fffffiff4, fifi fi fifi fffffifi<+4 &fififi<++ fi fffffiff<+-"1 ')3ffff $:fiff fifffiff/fififf D( fifi ff=ff ff- G fffi & & ff ' 'fffi ff fi & ' % ff &fffifi442fifi fifffiff ff fifi fifi fi! :fffiGfifffi fi ff D( fifi fiff fifi D( fi fffi fifffifi 4,fffififi2fi fifffififf ! fifffiff+G " fiJ 2fi ;&ff.1.2.4.-93.64724116661458(...45...74...15...12:;<(82--.-63378345893.6572-42.2813.8(...8...78...21...11:;<( 9 ( :;<( 9 (8211fffi...32 8.23 2384 ...22-.3- fi ...76 355- 1664 ...13327 fi ...2 3286 1452 ....63744 fffi ...14 3.- 1132 ...12:;<(663868-35644532-G " fiJ 2fi&ff.1.2.4.-93871781122651818(...42...2...12...1:;<(5183-683-14435593513787227731848(...32...25...12....6:;<( 9 ( :;<( 9 (51-8fi ...32 5.6 1215 ...28-587 fi...2- -577 1.21 ...11-2- fiff ...17 -.47 84- ....8-126 fffi ....5 3837 -11 ....4:;<(6666665665665;G " fiJ 2fi&ff.1.2.49738624181355(...72...18...11:;<(--32384134.197352431-1-(...74...2....8:;<( 9 ( :;<( 9-335 fi ...7 -2-3 5373615 fi ...14 3428 -123337 fffiff ....5 3.82 486(...71...17....-:;<(66556657666ff+ fi&D( fi& !: :fi&ff & ff 'fifi ff & ff& fififi 3 fifi $ ff B6'fi ff & ff 'fifi& ff 'fifi ff ff B6'fi % &' ff fifi 'fifi&ffff ff &ff fififi447fi ffff fififi2fi ; - ; fffffiff2fififi fi fiff > ?# " fffi& !2 ff+,4 # "fi A46AI # "A,56I @7 A,5;I #F 78 +A<;I# " ffff fiff! fi fi# " !fffi fi!fifi=fi# "fifffffifffifffifi-15PTC-A / QRPTC-M / QR% improvement deviation IZDS (relative TPORL)% improvement deviation IZDS (relative QR)0-2-4-6-8-10-12-140.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6Call origination probability$ A5 BCPTC-A / TPOT-RLPTC-M / TPOT-RL-20-25-30-35-40-45-50-55-60-650.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6Call origination probability$ A5 A>6C+2fi CG ffff fiff D(@7 #F 78J 2fi ;: fffifffffi fiff# "ff@7 #F 78 =fiff D(fffi ++<44 fi'fi%) ,, -,, -,)*)* ,fi ff ! G%)2fi Cffff fiff D(fi# " @7 2fi C #F 782fi C2fi ;fi 0= fi fififi )*+ fi ,- .-/ff %2ff=ffff# "@7 #F 78 fi& fi !=5AI = 2 ff>8? ,4+,4fi ff D(+C+I $* # " +55I +444fifi fifffiff ff fifi fi1-20PTC-A / QRPTC-M / QR% improvement deviation IZDS (relative TPORL)% improvement deviation IZDS (relative QR)0-1-2-3-4-5-6-7-80.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6PTC-A / TPOT-RLPTC-M / TPOT-RL-25-30-35-40-45-50-55-60-65-700.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6Call origination probabilityCall origination probability$ A5 BC$ A5 A>6C+2fi <G ffff fiff D(@7 #F 78J 2fi2-25PTC-A / QRPTC-M / QR% improvement deviation IZDS (relative TPORL)% improvement deviation IZDS (relative QR)0-2-4-6-8-10-12-140.10.150.20.250.30.350.4Call origination probabilityPTC-A / TPOT-RLPTC-M / TPOT-RL-30-35-40-45-50-55-600.10.150.20.250.30.350.4Call origination probability$ A5 BC$ A5 A>6C+2fi 6G ffff fiff D(@7 #F 78J 2fi443fi ffff fififi+ D(@7 fi fi # "4+-<I +++@7 fiff D( # " ff@7ffff# "#F 78 ff # "+C+Iff D(= fi #F 78<;4AI$++++ fi fi # "C;CCI$D(#F 78 ff # " ff# "fi ff @7 #F 78 fififffffifffifffi fi'fiff # " ff D( @7ffff # " @7 #F 78 fifi2fi Cffff # " @74+-<I,4-<I,Cff2fi C # "C;CCI#F 78 ,4 fi 466+I ,C 0fffiff fi!ff'fiff fifi!fiffff& # ":ff # "ff!2fi < fi2fi2fi 62fifffi! fi fffifffi !fifififf fi fffiff2fi 5fffi # " @7 #F 78ff ,4 ,Cfffifi fi2fi ;$ ff # "# " . # "fiff fiff# " @7 #F78 fi ff,4ff A,,Cff A, fifi&fffifi+ : fifffffifififffifi 2fi 5fi =& fiG ,4 ,+ ,; ,C ,6# "fi fi# " @7 #F 78 0fi fi&fifiG,4 ,C fffifi ff fifi=fi#fi!ffff&ff# ff' 3& ff fifi ff fffi fifi ff fi ff' ff fi fi fifi ff % & fffififi ff44-fifi fifffiff ff fifi fifififf fffffi fi# " fiffff! fifffi0.45PTC-MQRTPOTRL0.450.40.40.350.350.3Call success rateCall success rate0.50.30.250.250.20.20.150.150.10.10102030405060Time708090PTC-MQRTPOTRL0.05100$ # ff0102030405060Time708090100$ # ff 7% Difference call success rates QR PTC-M2fi 5Gfffi @7 # " #F 78!fifiJ 2fi ;-2-4-6-8-10-12-14-16minavgmax-18-20123456Degree dynamism2fi 4,G fifffffi& @7 # "! fifiJ 2fi ;0ff fiffff& ff!fiff=fifffffifi > ffff? 2 ff 2fi 5ffff + 2fi 5 ffffffff fffi& fi @7448fi ffff fififi, ", ", -, )*, "#F 78 fi# "G %) , "fffi 0& fffifffiffffffff fi fi# " = fffffiffff fffffiff&fffifffifffffffffi'fi fffffffiff ff fffffiff&fifffififfff&fffffi2 ff2fi 5 fffffiff fffffffiff& fffi,4,C fi'fi ff&fffi 2fi 4, fffffiffff fififf @7ff # "#F 78fi # "@7 fi fiffff ff#F 78# "L2fi 4,fffffifffffi&= fiffff +ff ,4 ,+. -,4 ,+,;. ;,4 ,+ ,; ,C.,4 ,+ ,; ,C ,6fifi&fi = fifffffiff fffffiff& fififfffff 2ff 6Iffff+fi ;AI fffffififffffififfff / fifi+ 0fi& # "=fiffff 2 fffi 4,+I+ ffff 5AIfffffi fifffifffiff(ff02 fffi ff D(fi 4+-<I# " @7 fi CAI# " #F 78 2fiff# "4,Ifffffi @7=&fffifi1')3 $)ffff ) %))fi fi<+4ff # "@7 #F 78fffi &fffiff fifffi<4+=fffifi7fi ffff:fffiffff<+4 fiff # " ff! fi!445fifi fifffiff ff fifi fiAG " fifiJ 2fi ;&ff.1.2.4.-(ff'+)=9)=$)*+&'+)=9)=$)*+&'+)=9)=$)*+&'+)=9)=$)*+&1fi.5-7.538.-77fi.887.8-5.354fi.-83.--8.46-fi.-1.36.415$7438fi .-7 .31 .42 .78 .733.845 .-72 .31- .42- .784 .733.837 fi fifi fi ff fi.372 .73- .215 .1-4 .145 .12fi.44 .71 .222 .185 .135.357 .44 .713 .271 .151 .1-4.357 fi fi fi fiff fiff.4-2 .2-- .176 .1.1 ..65 ..5fiff .2-- .1-1 .1.7 ..84 ..-4.418 .282 .18 .111 ..51 ..-5.41- fi fiff fiffff fi ff fi.783 .165 ..5- ..36 ..-7 ..34fi .153 .1.7 ..-2 ..43 ..78.727 .16 .111 ..-5 ..48 ..4.722 fiff fiffff fi fi fi.7.1 .145 ..-3 ..47 ..4- ..782561..747 .744 .74.743 .745 .734fififi..64 ..81 ..36.148 .148 .176.133 .131 .131fifffiffff fiff..-- ..3- ..45..3-7 ..37 ..3..- ..33 ..35fiff fifi..4 ..78 ..26..7 ..26 ..28..73 ..72 ..7fifi fi..27 ..13 ..17CG " fifiJ 2fi&ff.1.2.4.-(ff'+)=9)=$)*+&'+)=9)=$)*+&'+)=9)=$)*+&'+)=9)=$)*+&1fi.58.587.158fi.88.8-.214fi.-45.-4.2.2fi.3-.338.188$7438fiff .- .3.4 .425 .786 .737.84- .35- .463 .42- .751 .7-3.837 fiff fiffff fi fi fi.126 .11 .1.2 .1.4 .176 .2.7fi.781 .2-5 .168 .1-1 .141.3-1 .7-6 .2-3 .2 .1-7 .143.3-4 fifi fi fiff fiff.128 ..53 ..-3 ..33 ..- ..-1.757 .2.7 .12 .852 .35 .462fi.2.5 .12- .525 .-71 .37.754 fiff fiff fi fi fi.1.6 ..34 ..23 ..21 ..24 ..45.25- .177 .812 .425 .7.3 .246fi .14 .851 .451 .748 .258.258 fiff fi fififf fi..63 ..4- ..18 ..11 ...8. ...3.2fi # "ff<+4fi fi&fi ff446fi ffff fififi<G " fifiJ 2fi&ff.1.2.4.-(ff'+)=9)=$)*+&'+)=9)=$)*+&'+)=9)=$)*+&'+)=9)=$)*+&127fi fififf.56 .846 .356.55 .825 .365.22 .182 .14fi fi fi.578 .-25 .43.527 .-22 .445.2.2 .135 .11fi fififf$385fi.724 .248 .2.5 .183.472 .718 .248 .22 .168.447 fi fi fi fi.1.4 ..86 ..38 ..31 ..43fi .156 .127 ..65 ..86.258 .185 .124 .1 ..58.262 fiff fiff fiff fi..82 ..48 ..72 ..26 ..23.18 ..64 ..38 ..41 ..71.1-1 ..6 ..38 ..42 ..744.8-- .454 .265.84- .48- .7.7 fiff.156 .141 ..6 ..3fiff fi fi.112.8.- .767 .21- .1.6.-55 .75- .221 fiffff.181 .128 ..86 ..4861.1112.146 .12 ..58 ..52.1-6 .141 .111 .1fiffff fiff fiff fiff..78 ..26 ..25 ..26..-1 ..48 ..7- ..26..81 ..3- ..4- ..76fi fi fifi..1- ..12 ...5 .....22 ..18 ..11 ..12..2- ..21 ..143 ..13fi fiff fi fi fiff fi fiff fiff..74 ..2 ..1-8 ..11 ...- ...7 ...2 1. 4..- ..7 ..24 ..15 ..12 ...6 ...- ...3..38 ..71 ..23 ..168 ..14 ..118 ...5 ...83fiff fi fi fi fiff fiff fi fi..28 ..13 ..1 ...- ...7 1. 4 1. 4 1. 4ffC < fi& fi >fffi? fi& != fi ;2fi- @7fi # " /fi# "fiff@7# " ff #F 78fi# "@7 #F 78ffff,fi# ". , -, )*, . %)@7 #F 78, -, )*%)fifffffifffi2fi 44fi# " @7 2fi 44# " @7 2fi 44 # " #F 78 2fi 44 # "#F 78 2fi 44fi fffffiff fi fifi2fi ; 9= fi& fi2fi 4+4-fffi fi2fi2fi= fi 44 44fi>fffffifffi?fi 4 + @7 ff# "# "ff2 ff ,C @7fi AIffff # "4 2fi 44 /fi!!()!ff 3 'fi ff ffffff&43.fifi fifffiff ff fifi fi>fffffiff fi?- fififffi# "@7fi2ff2fi 44 fi ,C # "ff 4AIffff @76ff fifffffi # "ffff &fi= fi 4444 # " # " ff #F 78fifi20loadloadloadload200.10.20.40.610501050-5-100.10.20.40.615% improvement success rates% improvement success rates15loadloadloadload1234567Minimum hop count89-510123$ A56 BCloadloadloadload5004567Minimum hop count89108910$ A56 BC5000.10.20.40.6loadloadloadload4500.10.20.40.6400% improvement success rates% improvement success rates40030020035030025020015010010050012345678910Minimum hop count01234567Minimum hop count$ A56 A>6C+$ A56 A>6C+2fi 44G " fifiJ 2fi ;# " fififffifififffffffifi fififi431fi ffff fififi25loadloadloadload160.10.20.40.6200.10.20.40.612% improvement success rates% improvement success ratesloadloadloadload141510510864200-2-512345Minimum hop count6-4712$ A56 BC1000loadloadloadload10000.10.20.40.67loadloadloadload0.10.20.40.6800% improvement success rates% improvement success rates6$ A56 BC8006004002000345Minimum hop count60040020012345Minimum hop count607$ A56 A>6C+12345Minimum hop count$ A56 A>6C+2fi 4+G " fifiJ 2fi43267fifi fifffiff ff fifi fi60loadloadloadload40302010302010123456789Minimum hop count1011-1012123$ A56 BC1000loadloadloadload10000.10.20.40.6101112loadloadloadload1011120.10.20.40.6% improvement success rates8006004002000456789Minimum hop count$ A56 BC800% improvement success rates0.10.20.40.600-10loadloadloadload40% improvement success rates% improvement success rates50500.10.20.40.6600400200123456789Minimum hop count101112$ A56 A>6C+0123456789Minimum hop count$ A56 A>6C+2fi 4-G " fifiJ 2fi437fi ffff fififififf! fiff!fi fffi :ff fiff# "!fifffi@7fi# "@7 fififi fiff fffififf 1fffi2fi 44# "ff&@7 #F 78 fi# "ff &# " fi @7#F 78# " @72fi 44 # " @7 2fi 44# " #F 78 2fi 44 # " #F 78 2fi 44ffff 2fi 44= fi 4+ 4-= fifiKfifi<+4fi fifffifffffffi0fffffiff fifffiff @7 #F 78 ff # "fiff@7 #F 78# "# "/fi # "ff!2 ff2fi 44 6fi +AI,4 ff 4AI,Cfiffff!!!!ffffff( fi fiffffff A,Ififi# " @74+4,, ff!,C2fi 4- 2 ff ff fi # "ffff #F 78 ff 4,,,I 2fi 4-1 ')3 !)+$fiff ff<4-=ff!fffifffffififf fi fffifffffi fffiff7fi ffff =ff fffi fi! 6 fffi2fi ; 5 4, ff2fi 2fifi434fifi fifffiff ff fifi fiff fi fiff > ?=# "@7 #F 78 2 ff6,+A# " ,+C# " ,-5 @7 ,A+- #F 78,4fiff fiffff >I? fifi, # ." ffff fi%), ., -, )*fi fffi%), -, )*fffffffi2 ff6 ,4# " fi -ACI $++ ff @7 fi A+I$ #F 78 /fffi 6,-I *$$@7 fi <+6I *$$#F 78,Cfi!fiff ff@7 #F 78fffi# "6 ffff ,-54;A@7 J +<+Iff ,A+- 4,A#F 78 J 4,4Iff ,+A4 ,+6A# " J 4-AIJff ,4,C()6G ffffJ 2fi ;.1.2.4.-'+9 (.76 ...45.-- ...8611 ..1143 ..123!)=9)=$)*+& !"%. !"%/ !"%.9 ( 9 ( 9 ( (&(&! $!%&'.2- ...16 fiff ...16 .327 ...27 7777 73-4 3.25.251 ...2 fi...22 .-57 ...26 3842 3577 3553.256 ...15 fi ...1- .561 ...7- 8787 8415 -83.2564 ...18 fi...13 1.3 ...88 5..4 5.74 8247!"%/! $!%&'32..3687-51282535G ffffJ 2fi.1.2.4.-'+9 (.77 ...27.33 ...45.6 ...4612 ...34!)=9)=$)*+& !"%. !"%/ !"%.9 ( 9 ( 9 ( (&(&! $!%&'.27 ...12 fi ...14 .836 ...34 7.7. 7.7. -6-6.2- ...17 fi...12 142 ...84 3287 3433 51-6.28 ...1 fi ....6 21-7 ...61 8.. 8111 5831.282 ....8 fi ...12 28. ..1.- 8877 8883 5662!"%/! $!%&'-6-6527658686.110@7 fffffffifffifififf ff fi ff fffi #F 78fffifififi#F 78ff fi fiffffff fififi ff433fi ffff fififi4,G ffffJ 2fi'+9 (.35 ..118.57 ..11212- ...651-7 ...63.1.2.4.-!)=9)=$)*+& !"%. !"%/ !"%.9 ( 9 ( 9 ( (&(&! $!%&'.214 ....6 fiff ...14 142 ..15 -71. -786 5462.273 ...1 fi ...1 216 ...61 81-6 8241 5628.246 ...1 fiff ....5 265 ...-1 5.24 5.58 61-4.237 ....8 fi....5 778 ...86 5445 5468 6246!"%/! $!%&'5321563461616282fiff fiff fifi fiff fi ff# "=fffffffiffff fffififfffffff fi3@7 #F 78 fifi ff=# "ff ff ff@7 #F 78fi fi 3fifi# " fffffiff fffffffi!fffi fffiff<+4ffffff! fifi fffffifi1.61.8PTC-MQRTPOTRLPTC-MQRTPOTRL1.61.41.41.21.2Message rateMessage rate10.810.80.60.60.40.40.200.20102030405060708090100Time00102030405060708090100Time$ # ff$ # ff 72fi 4;Gffff @7 # " #F 78!fifiJ 2fi ;43-fi% Difference message rates QR PTC-M500maxavgmin450400350300250200150100501234Degree dynamism56$ BCA56% Difference message rates TPOTRL PTC-Mfi fifffiff ff fifi fi500maxavgmin4504003503002502001501001234Degree dynamism56$ A>6C+A562fi 4AG fiffffff& @7 #F 78 # "! fifiJ 2fi ;2fi 4; ff# " @7 #F 78ff ,4 ,Cfffifi fi2fi ;2fi 4; ff,4 ,+ ,; ,C ,6 'fifffifffifi 3 = fi # "= ff @7 #F 78 fi fifi2fi !ff@7 #F 78fiff# "=@7 #F 78fffffifi fi fifi#F 78ff fi fiff / ff! fiff fiff#F 78 ff@7 :#F 78@7fifi @7<+4#F 78@7ff#F 78 fiff fffifififf#F 78fi fffififf fffi @7fffi fififififfff&ff @7 # " #F 78 # "= fi 4A 4A= fiffffLfffi@7 #F 78# "fi fi 2fi 4,2fi 4A 4Afffffiff fffffiff& ff fiff 22fi 4Afi 4;,I+ ffC,Iff 0 ff&ff # " @7 # " #F 78438fi ffff fifififfff 2 ff ff&ff 4A4I-+4I2fi 4Aff +,,I +6;I2fi 4A# "ff fffffiff ff ff@7 #F 782fffifi ! 123$( fi! 122$ ff fffi 4ff2 ff # "6,Iff ff @7 <+Iff #F 78fi! 2fiff=!# " fi -+,Iff @7 fi +6;I #F 78fi # "fi fiffff+ fffffi , fffififf ! 'fifffififi ff'fi!ff !ff0fifffififf fifiKff ff ffff fiKfifi/fififffi1ff&ffffff fi "fifffffi @fi fifffi=fififffiJ ! ffffJffff fffffiEfffifffiffff fiff fifffffiff2fiffff fffffifi# "fifffififf fi! : fifffifffiff!ffff& !! ff7fiff fiff ff! fifi fi C,I fiff ff 4,,,Ififi fiff fiffff= ff fi -,,Iff!: ff# "fffffffffiff= fiffff /= fffffififi435fifi fifffiff ff fifi fi# " # "fiffffff fifi! fffi;fiff# " fifffi fi!fffi= fifffffi fififfffff =ff ! fffffi'fifffi fffffififf&ffff!ffff 'fiff!fiff7fi ) 0+,,+fifffffi! (#(9" (# 3!8 ) 1ff +,,-. 31ffffff)+,,+!fffffi fffffifi==fi(9" (# ffff3fififffffifi ff fiff 'fififf'fiFfi!fffi fffffiff fi: ! Bfi 8fi 1fi(ff 3ffff fi29#7" fiK .5 ) %&!F/" 0 17%7-+C5<%,4!( 0 3fiff # 3 * (fi 9 /M! "fi0 ) ff " : +,,+ "ffG fi) ) 31 - +CU-A3 * ) 3 # 8 4555 (ffG 1ffff 7 ff9fi0$3! 78 H ) 1ff " H +,,-L ff!)6 %! 2778$;4U;6 fi " # 0 V!3( 17 ffffff 0 )+,,+ ffL ff!. -21 ; 645U6;,436fi ffff fififi3fi" 4555 'fifffffiff) 6 % 4 )!)6%)99$;<6U;6A !ff3 * ) 8ff 8 455- #! fiff!Gff" * ( fi 1 ) * 9fi & ) H C C<4UC<6" ) 1 8 4555 "fffi:1 9:+ff4 ) +55U--, # "ff" 1 ( ) (4556 0G (fifffffffi! 6 4 ) - 9 -4<U-CA" 1 ( ) (4556ff & fiff !)+ ) %+ff%A;4UA;C 9(% "#"3 455A fifi %% 8; 44 ;5UA-"!fi ( ) *0 7 455C Gfi=fffiFE/ 1 # ) *0 7 9 <+ff4 ) -45U-;; :" # 7 ) 8'fi / * 4554 ff! & 8= ; ;6<UA4+fi"="ff / 8" 9 77 8 )" +,,4 )++;Gfi # #(! 455A 9G ff!ffffff FE/ 1 ) *0 9 <+ff4 ) 4C :(! 455A fi#($fi ff fi(! ) 8 H 7 455A (ffff< ) % <-U6,2(! 3) :! # +,,; 5H +<;;%+,,; / & % fififi4,, U 4,5H /(fi 9 / ) 8 H 4554 #Gff!fiff)%ff23 44C<U446-(fi # (ff 1fi 7 *0 7 ) fi 8 +,,; "fffffi7/fi "46U+-4-.fifi fifffiff ff fifi fi(fi # *0 7 ) fi 8 +,,Aff'!ff!fi< ) 6 %! $(fi # fi 8 ) *0 7 +,,- 2fi# )6%)2778%fi) ;CUAA(fi # ) +,,- 2ff%fi -- +44U++49 ( 1) :! 8 +,,; # ffG 7ffff! ) 39 4 ;+<U ;-A29 ) L +,,4 5ff fi + :Mfi ff#fi1L 3 ) Mfi 455C "ff fi4) ;> + +C5U-A</! " 4566 - ) !-<% 37=;$ 0! :!1fi9 2 fffi*) (" +,,+ #G fffifffifi !$ #4;U+A*0 7 455- "ffffffG fifffiff ?-fi ; - ++-U+A,*0 7 455A "fffifffiff fiK4 ) 1= + 45AU+;,*0 7 ) 3fiff +,,- ff ) %@ 28 - C4U<;*0 7 0ff * ) 2# 4556 Gfiff ff % )'.+ 21 ; -+U-5) 3fi+,,; # & FE7:(ff fifi fffifi fififi8) 3! 4555 fi) )&<.%.!3$ +-AU+;A8 H 7 ) 9ff 8 ( 4566 (fiG ffff3 / ) 1 8 9 -+ff4 )4+,U4-5 Mfiff "! 0 ( ) 1455<fffffififififfff< ) / % +,+U+4,Mfiff7 8 H ) /3 +,,- "fffi fi) 6 %4-1fi ffff fififi! 2778$A<CUA6-fi " #* 4566-ff% )-%; A+AUA-,* 1 )ff / 45A6 .@ * :)"fiff 7 455C /ff=)%ff" "+C ;C; U ;<-0 Mff / ) # 4555 "ffff!fi< %H 30 - A;, CAA<6 C455< / 4-G 7ff 81 /#fi! / H ( 3! ( ) "! * +,,4fiG 2fffffifi'fiff ff)%; 4 ;AUA6#!8 ) H +,,+ 7fffi) 6 % & & !)6%&&$7H " 77 ff /! 3 ) 3fi! 7 +,,,fiff)% % )7" )" 8 455< "F88 190G :< ) % ! A91$+6;U+547fi * ) 0# +,,+ 4 ) :+4<G !"ff (#/* 8 H ) " 0 +,,-ffLfffffifi3! fiL (#)6 %! 2778$C<6UC6A " ## *!! ) * 455A 7fffi 1 fiL! ( ) 8 9fi &) H < -C4U-C6 ## +,,, #F 78! fi)%/ 27775-AU5;+# ) H 4555 ff'fiff% +,CU+4+fi 7 () fi V +,,, #fffffifffi & )32 4,A<U4,C-fi 7 4566 8ff ff&/ 8 5U;;4-2fifi fifffiff ff fifi fifi 7 ) 3 1 4556- /: )!fi%/$#!9 ) ! V +,,- fi&ffff2 + -+-U--6ff 455<ff! 6 4 ) - 16-U4+;fiff +,,- % & ;AG 0! 8#/ # 7/ +,,+ 7fffffifi 'fifffiff! / 9 + 444U4-5H7 ) H # 455< (fifffiG #fiff) H 6A 4 A;UC-: : 9 ) :ff # +,,- (L fiffG ff!ff'fififf6 4 ) -39 A4-UAC<:!" * " / 4565 /#(# (ff $"ff:!" * " / ) ( # 455+G @/ ;+<5U+5+:3 ) /& 9 45C,fi#%.& %fi-)B 5CU4,;:ff 7 * 455+ffffff/ ; - ++5U+ACBV 455Cff!fffififfLfffffi4 ) ;1 4 + +5AU-;+Bfi # 8 H )+,,4 "fffffifffiG ffff< ) %!73$ C4CUC+-4-7fiJournal Artificial Intelligence Research 24 (2005) 263-303Submitted 06/04; published 08/05Integrating Learning Examples SearchDiagnostic PoliciesValentina Bayer-ZubekThomas G. DietterichSchool Electrical Engineering Computer Science,Dearborn Hall 102, Oregon State University,Corvallis, 97331-3102 USAbayer@cs.orst.edutgd@cs.orst.eduAbstractpaper studies problem learning diagnostic policies training examples.diagnostic policy complete description decision-making actions diagnostician(i.e., tests followed diagnostic decision) possible combinations test results.optimal diagnostic policy one minimizes expected total cost,sum measurement costs misdiagnosis costs. diagnostic settings,tradeoff two kinds costs.paper formalizes diagnostic decision making Markov Decision Process (MDP).paper introduces new family systematic search algorithms based AO algorithm solve MDP. make AO ecient, paper describes admissible heuristicenables AO prune large parts search space. paper also introduces severalgreedy algorithms including improvements previously-published methods.paper addresses question learning diagnostic policies examples.probabilities diseases test results computed training data, greatdanger overfitting. reduce overfitting, regularizers integrated search algorithms. Finally, paper compares proposed methods five benchmark diagnosticdata sets. studies show cases systematic search methods producebetter diagnostic policies greedy methods. addition, studies showtraining sets realistic size, systematic search algorithms practical today'sdesktop computers.1. Introductionpatient arrives doctor's oce complaining symptoms fatigue, frequenturination, frequent thirst. doctor performs sequence measurements.measurements simple questions (e.g., asking patient's age, medical history,family history medical conditions), others simple tests (e.g., measure body mass index,blood pressure), others expensive tests (e.g., blood tests). measurement,doctor analyzes known far decides whether enough informationmake diagnosis whether tests needed. making diagnosis, doctormust take account likelihood possible disease costs misdiagnoses.example, diagnosing diabetic patient healthy incurs cost aggravatingpatient's medical condition delaying treatment; diagnosing healthy patientdiabetes incurs costs unnecessary treatments. informationgathered suciently conclusive, doctor makes diagnosis.c 2005AI Access Foundation. rights reserved.fiBayer-Zubek & Dietterichformalize diagnostic task follows. Given patient, doctor executeset N possible measurements x1 ; : : : ; xN . measurement xn executed, resultobserved value vn . example, x1 \patient's age", v1 could 36 (years).measurement xn associated cost C (xn ). doctor also choose one Kdiagnosis actions. Diagnosis action fk diagnoses patient suffering disease k.denote correct diagnosis patient y. misdiagnosis cost predictingdisease k correct diagnosis denoted MC (fk ; y).process diagnosis consists sequence decisions. starting state,measurements diagnoses made. denote empty set fg. Supposestarting \knowledge state", doctor chooses measurement x1 receivesresult x1 = 36 cost $0.50. modeled transition knowledgestate fx1 = 36g cost C (x1 ) = 0:5. suppose doctor chooses x3 ,measures body mass index, receives result x3 = small cost $1. changesknowledge state fx1 = 36; x3 = smallg cost C (x3 ) = 1. Finally, doctor makesdiagnosis \healthy". Suppose correct diagnosis = diabetes. illustrativepurposes,1 suppose cost misdiagnosis MC (healthy; diabetes) = $100.diagnosis action terminates process, total cost :5 + 1 + 100 = 101:5.summarize decision-making process doctor terms diagnosticpolicy, . diagnostic policy specifies possible knowledge state s, action(s) take, action one N measurement actions one Kdiagnosis actions. Every diagnostic policy expected total cost, dependsjoint probability distribution P (x1 ; : : : ; xN ; y) test results true diseasepatients costs C (xn ) MC (fk ; y). optimal diagnostic policyminimizes expected total cost choosing best tradeoff point costperforming measurements cost misdiagnosis. Every measurement gathersinformation, reduces risk costly misdiagnosis. every measurement incursmeasurement cost.Diagnostic decision making challenging costs measurementmisdiagnosis similar magnitudes. measurement costs small comparedmisdiagnosis costs, optimal diagnostic policy measure everythingmake diagnostic decision. Conversely, misdiagnosis costs small comparedmeasurement costs, best policy measure nothing diagnose basedmisdiagnosis costs prior probabilities diseases.Learning cost-sensitive diagnostic policies important many domains, medicineautomotive troubleshooting network fault detection repair (Littman et al., 2004).note formulation optimal diagnosis assumes costs expressed single numerical scale, that, although need correspond economic cost,must support principle choosing actions minimizing expected total cost. medical diagnosis, large body work methods eliciting patient's preferencessummarizing utility cost function (e.g., Lenert & Soetikno, 1997).paper studies problem learning diagnostic policies training examples.assume given representative set complete training examples drawnP (x1 ; : : : ; xN ; y) told measurement costs misdiagnosis costs.1. true cost misdiagnosing diabetes would depend age patient degreeprogression disease, case, would probably much higher $100.264fiLearning Diagnostic Policies Exampleskind training data could collected, example, clinical trialmeasurements performed patients. costs involved collectingdata, assume training data sets relatively small (hundredsthousands patients; millions). goal paper develop learningalgorithms finding good diagnostic policies modest-sized training data sets.Unlike work test selection diagnosis (Heckerman, Horvitz, & Middleton, 1993;van der Gaag & Wessels, 1993; Madigan & Almond, 1996; Dittmer & Jensen, 1997),assume Bayesian network uence diagram provided; instead directlylearn diagnostic policy data.framework diagnosis ignores several issues hope address futureresearch. First, assumes measurement action effect patient.measurement action pure observation action. real medical equipmentdiagnosis situations, actions may also attempted therapies attempted repairs.repairs may help cure patient fix equipment, addition gatheringinformation. approach handle attempted repair actions.Second, framework assumes measurement actions chosen executed oneat-a-time cost action depend order actionsexecuted. always true medical diagnosis. example, orderingblood tests, physician choose order several different tests group, costsmuch less tests ordered individually.Third, framework assumes result measurement action available diagnostician must choose next action. medicine, often (stochastic)delay time test ordered time results available. Fragmentaryresults may arrive time, may lead physician order testspreviously-ordered results available.Fourth, framework assumes measurement actions noise-free. is, repeating measurement action obtain exactly result. Therefore measurementaction executed, never needs repeated.Fifth, framework assumes results measurements discrete values.enforce via pre-processing discretization step.assumptions allow us represent doctor's knowledge state setpartial measurement results: fx1 = v1 ; x3 = v3 ; : : :g represent entire diagnosticprocess Markov Decision Process (MDP). optimal solution MDP providesoptimal diagnostic policy.Given formalization, conceptually two problems must addressedorder learn good diagnostic policies. First, must learn joint probability distributionP (x1 ; : : : ; xN ; y). Second, must solve resulting MDP optimal policy.paper, begin addressing second problem. show applyAO algorithm solve MDP optimal policy. define admissible heuristicAO allows prune large parts state space, search becomesecient. addresses second conceptual problem.However, instead solving first conceptual problem (learning joint distributionP (x1 ; : : : ; xN ; y)) directly, argue best approach integrate learningprocess AO search. three reasons pursue integration. First,integrating learning search, ensure probabilities computed265fiBayer-Zubek & Dietterichlearning probabilities relevant task. instead separately learnedmodel joint distribution P (x1 ; : : : ; xN ; y), probabilities wouldlearned task-independent way, long experience machine learning shownbetter exploit task guiding learning process (e.g., Friedman & Goldszmidt,1996; Friedman, Geiger, & Goldszmidt, 1997).Second, integrating learning search, introduce regularization methodsreduce risk overfitting. thoroughly learning algorithm searchesspace possible policies, greater risk overfitting training data, resultspoor performance new cases. main contribution paper (in addition showingmodel diagnosis MDP) development careful experimental evaluationseveral methods regularizing combined learning AO search process.Third, integration learning AO provides additional opportunities pruneAO search thereby improve computational eciency learning process.introduce pruning technique, called \statistical pruning", simultaneously reducesAO search space also regularizes learning procedure.addition applying AO algorithm perform systematic search spacediagnostic policies, also consider greedy algorithms constructing diagnostic policies.algorithms much ecient AO , show experimentallygive worse performance several cases. experiments also show AO feasiblefive diagnostic benchmark problems studied.remainder paper organized follows. First, discuss relationshipproblem learning minimum cost diagnostic policies previous workcost-sensitive learning diagnosis. Section 3, formulate diagnostic learningproblem Markov Decision Problem. Section 4 presents systematic greedy searchalgorithms finding good diagnostic policies. Section 5, take questionlearning good diagnostic policies describe various regularization methods. Section 6presents series experiments measure effectiveness eciency variousmethods real-world data sets. Section 7 summarizes contributions paperdiscusses future research directions.2. Relationship Previous Researchproblem learning diagnostic policies related several areas previous researchincluding cost-sensitive learning, test sequencing, troubleshooting. discussturn.2.1 Cost-Sensitive Learningterm \cost-sensitive learning" denotes learning algorithm sensitive onecosts. Turney (2000) provides excellent overview. Cost-sensitive learning employsclassification terminology class possible outcome classification process.corresponds case diagnosis. forms cost-sensitive learningrelevant work concern methods sensitive misclassification costs, methods sensitivemeasurement costs, methods sensitive kinds costs.Learning algorithms sensitive misclassification costs received significant attention. setting, learning algorithm given (at cost) results possible266fiLearning Diagnostic Policies Examplesmeasurements, (v1 ; : : : ; vN ). must make prediction y^ class example,pays cost MC (^y; y) correct class y. Important work settingincludes papers Breiman et al. (1984), Pazzani et al. (1994), Fawcett Provost(1997), Bradford et al. (1998), Domingos (Domingos, 1999), Zadrozny Elkan (2001),Provost Fawcett (2001).researchers machine learning studied application problemscost measuring attribute (Norton, 1989; Nunez, 1991; Tan, 1993).setting, goal minimize number misclassification errors biasinglearning algorithm favor less-expensive attributes. formal point view,problem ill-defined, explicit definition objective functiontrades cost measuring attributes number misclassification errors.Nonetheless, several interesting heuristics implemented tested papers.recently, researchers begun consider measurement misclassification costs (Turney, 1995; Greiner, Grove, & Roth, 2002). objective identicalone studied paper: minimize expected total cost measurementsmisclassifications. algorithms learn data well.Turney developed ICET, algorithm employs genetic search tune parameterscontrol classification-tree learning algorithm. classification tree built usingcriterion selects attributes greedily, based information gain estimatedcosts. measurement costs adjusted order build different classification trees;trees evaluated internal holdout set using real measurement misclassification costs. best set measurement costs found genetic search employedbuild final classification tree entire training data set.Greiner et al.'s paper provides PAC-learning analysis problem learningoptimal diagnostic policy|provided policy makes L measurements,L fixed constant. Recall N total number measurements. proveexists algorithm runs time polynomial N , consumes numbertraining examples polynomial N , finds diagnostic policy that, high probability,close optimal. Unfortunately, running time required number examplesexponential L. effect, algorithm works estimating, high confidence,transition probabilities class probabilities states L valuesx1 = v1, . . . , xN = vN observed. value iteration dynamic programmingalgorithm applied compute best diagnostic policy L measurements.theory, works well, dicult convert algorithm work practice.theoretical algorithm chooses space possible policiescomputes number training examples needed guarantee good performance, whereasreal setting, number available training examples fixed, spacepossible policies must adapted avoid overfitting.2.2 Test Sequencingfield electronic systems testing formalized studied problem calledtest sequencing problem (Pattipati & Alexandridis, 1990). electronic system viewedone K possible states. states include one fault-free state K , 1faulty states. relationship tests (measurements) system states specified267fiBayer-Zubek & Dietterichbinary diagnostic matrix tells whether test xn detects fault fi not.probabilities different system states specified known distribution P (y).test sequencing policy performs series measurements identify statesystem. test sequencing, assumed measurements sucient determinesystem state probability 1. objective find test sequencing policyachieves minimizing expected number tests. Hence, misdiagnosis costsirrelevant, test sequencing policy must guarantee zero misdiagnoses. Severalheuristics AO applied compute optimal test sequencing policy (Pattipati & Alexandridis, 1990).test sequencing problem involve learning examples. requiredprobabilities provided diagnostic matrix fault distribution P (y).2.3 TroubleshootingAnother task related work task troubleshooting (Heckerman, Breese, &Rommelse, 1994). Troubleshooting begins system known functioningincorrectly ends system restored correctly-functioning state.troubleshooter two kinds actions: pure observation actions (identical measurement actions) repair actions (e.g., removing replacing component, replacingbatteries, filling gas tank, rebooting computer, etc.). action cost,goal find troubleshooting policy minimizes expected cost restoringsystem correctly-functioning state.Heckerman et al. (1994, 1995) show case actions purerepair actions one broken component, ecient greedyalgorithm computes optimal troubleshooting policy. incorporate pure observation actions via one-step value information (VOI) heuristic. Accordingheuristic, compare expected cost repair-only policy expected costpolicy makes exactly one observation action executes repair-only policy.observe-once-and-then-repair-only policy better, execute chosen observationaction, obtain result, compare best repair-only policy bestobserve-once-and-then-repair-only policy. Below, define variant VOI heuristiccompare greedy systematic search algorithms developedpaper.Heckerman et al. consider case joint distribution P (x1 ; : : : ; xN ; y)provided known Bayesian network. convert approach learning approach,could first learn Bayesian network compute troubleshooting policy.suspect approach integrates learning probabilitiessearch good policies|along lines described paper|would give better results.Exploring question important direction future research.3. Formalizing Diagnosis Markov Decision Problemprocess diagnosis sequential decision making process. every decision,diagnostician must decide next (perform another measurement, terminatemaking diagnosis). modeled Markov Decision Problem (MDP).268fiLearning Diagnostic Policies ExamplesMDP mathematical model describing interaction agentenvironment. MDP defined set states (including start state), action setA, transition probabilities Ptr (s0 js; a) moving state state s0 executingaction a, (expected immediate) costs C (s; a; s0 ) associated transitions.state representation contains relevant information future decisions,said exhibit Markov property.policy maps states actions. value state policy , V (s),expected sum future costs incurred starting state following afterwards(Sutton & Barto, 1999, chapter 3). value function V policy satisfies followingrecursive relationship, known Bellman equation V :V (s) =X2S0Ptr (s0 js; (s)) C (s; (s); s0) + V (s0 ) ; 8; 8s:(1)viewed one-step lookahead state next states s0 reachedexecuting action (s). Given policy , value state computedvalue successor states s0 , adding expected costs transitions,weighting transition probabilities.Solving MDP means finding policy smallest value. policy calledoptimal policy , value optimal value function V . Value iterationalgorithm solves MDPs iteratively computing V (Puterman, 1994).problem learning diagnostic policies represented MDP. firstdefine actions MDP, states, finally transition probabilitiescosts. costs positive.discussed above, assume N measurement actions (tests) Kdiagnosis actions. Measurement action n (denoted xn ) returns value attribute xn ,assume discrete variable Vn possible values. Diagnosis action k (denotedfk ) act predicting correct diagnosis example k. action(measurement diagnosis) denoted a.diagnostic setting, case completely described results N measurement actions correct diagnosis y: (v1 ; : : : ; vN ; y). framework, casedrawn independently according (unknown) joint distribution P (x1 ; : : : ; xN ; y).case drawn, values defining stay constant. Test xn reveals diagnosticagent value xn = vn case. consequence, case drawn,order tests performed change values observed.is, joint distribution P (xi = vi ; xj = vj ) independent order testsxi xj .follows define state MDP set attribute-value pairsobserved thus far. state representation Markov property containsrelevant past information. unique start state, s0 = fg, attributesmeasured. set states contains one state possible combinationmeasured attributes, found training data. training example provides evidencereachability 2N states. set A(s) actions executable state consistsattributes yet measured plus diagnosis actions.also define special terminal state sf . Every diagnosis action makes transitionsf probability 1 (i.e., diagnosis made, task terminates). definition,269fiBayer-Zubek & Dietterichactions executable terminal state, value function zero. Noteterminal state always reached, finitely-many measurement actionsdiagnosis action must executed.define transition probabilities immediate costs MDP.measurement action xn executed state s, result state s0 = [ fxn = vn g,vn observed value xn . expected cost transition denoted C (xn),since assume depends measurement action xn executed,state executed resulting value vn observed. probabilitytransition Ptr (s0 js; xn ) = P (xn = vn js).misdiagnosis cost diagnosis action fk depends correct diagnosisexample. Let MC (fk ; y) misdiagnosis cost guessing diagnosis k correctdiagnosis y. correct diagnosis example part staterepresentation, cost diagnosis action (which depends y) performed statemust viewed random variable whose value MC (fk ; y) probability P (yjs),probability correct diagnosis given current state s. Hence,MDP stochastic cost function diagnosis actions. leaddiculties, required compute optimal policy MDPexpected cost action. case, expected cost diagnosis action fk stateXC (s; fk ) = P (yjs) MC (fk ; y);(2)independent y.uniformity notation, write expected immediate cost actionstate C (s; a), either measurement action diagnosis action.given start state s0 , diagnostic policy decision tree (Raiffa, 1968).Figure 1 illustrates simple example diagnostic policy. root starting states0 = fg. node labeled state corresponding action (s). actionmeasurement action, xn , possible results different possible observed valuesvn, leading children nodes. action diagnosis action, fk , possible resultsdiagnoses y. (s) measurement action, node called internal node,(s) diagnosis action, node called leaf node. branch tree labeledprobability followed (conditioned reaching parent node). nodelabeled V (s), expected total cost executing diagnostic policy startingnode s. Notice value leaf expected cost diagnosis, C (s; fk ).fact diagnostic policy decision tree potentially confusing,similar data structure, classification tree (often also called decision tree),focus much work machine learning literature (e.g., Quinlan, 1993).important remember whereas evaluation criterion classification treemisclassification error rate, evaluation criterion decision tree diagnosticpolicy expected total cost diagnosis. One way clarifying differencenote given classification tree transformed many equivalent classificationtrees changing order tests performed (see Utgoff's work treemanipulation operators, Utgoff, 1989). equivalent classifiers implementclassification function = f (x1 ; : : : ; xN ). consider \equivalent" treesdiagnostic policies, different expected total diagnosis costs, tests270fiLearning Diagnostic Policies Exampleslow{ BMI = large, Insulin = low}.8large45.98.5{}28.99{ BMI = large }.324.2BMI1.5{ BMI = small }.7Insulin22.78highsmallDiabetesHealthy10.9.1= Healthy= Diabetes{ BMI = large, Insulin = high }Healthy.8.220= Diabetes= Healthy= Healthy= Diabetes08001000100Figure 1: example diagnostic policy diabetes. Body Mass Index (BMI) testedfirst. small, Healthy diagnosis made. BMI large, Insulin testedmaking diagnosis. costs measurements (BMI Insulin)written name variable. costs misdiagnoses writtennext solid squares. Probabilities written branches. valuesstates written state. value start state, V (s0 ) =28:99, computed single sweep, starting leaves, follows. Firstexpected costs diagnosis actions computed (e.g., upper-mostDiabetes diagnosis action expected cost 0:7 0 + 0:3 80 = 24).value Insulin subtree computed cost measuring Insulin(22.78) + 0:8 24 + 0:2 20 = 45:98. Finally, value whole treecomputed cost measuring BMI (1) + 0:5 45:98 + 0:5 10 = 28:99.largelow.57.7{ Insulin = low } BMI121.4.3smallInsulin{}22.7840.138.43high{ Insulin = high }12Healthy .88.12{ BMI = large, Insulin = low}24{ BMI = small, Insulin = low }12= Healthy= DiabetesDiabetes.7.3Healthy .88.12= Diabetes= Healthy= Healthy= Diabetes08001000100Figure 2: Another diagnostic policy 2 , making classification decisionsFigure 1, changed order tests, therefore different policyvalue.closer root tree executed often, measurement costsmake larger contribution total diagnosis cost. example, policy Figure 1first performs cheap test, BMI. policy value 28:99. tree 2 Figure 2makes classification decisions (with error rate 19%), first tests Insulin,expensive, increases policy value 40:138.271fiBayer-Zubek & Dietterich4. Searching Good Diagnostic Policiesconsider systematic greedy search algorithms computing diagnostic policies.section, assume necessary probabilities known. deferquestion learning probabilities Section 5. note exactlyprevious uses AO done. always assumed required probabilitiescosts known.Given MDP formulation diagnostic process, could proceed constructingentire state space applying dynamic programming algorithms (e.g., valueiteration policy iteration) find optimal policy. However, size state spaceexponential: given N measurement actions, V possible outcomes, (V +1)N + 1 states MDP (counting special terminal state sf , taking accountmeasurement may performed yet). seek search algorithmsconsider small fraction huge space. section, study two generalapproaches dealing combinatorial explosion states: systematic search usingAO algorithm various greedy search algorithms.4.1 Systematic SearchMDP unique start state (directed) cycles, space policiesrepresented AND/OR graph (Qi, 1994; Washington, 1997; Hansen, 1998).AND/OR graph directed acyclic graph alternates two kinds nodes:nodes nodes. node represents state MDP state space.child node node represents one possible action executedstate s. child node node represents state s0 resultsexecuting action state s. Figure 3 shows example AND/OR graphdiabetes diagnosis problem three tests (BMI, Glucose, Insulin) two diagnosisactions (Diabetes Healthy).diagnostic setting, root node corresponds starting state s0 = fg.node one child (s; xn ) measurement action (test) xnexecuted s. node could also one child possible diagnosis actionfk could performed s, save time memory, include onediagnosis action fk minimum expected cost. denote fbest .time node created, child fbest created immediately. leafnode stores action-value function Q(s; fbest ) = C (s; fbest ). Note multiple pathsroot may lead node, changing order tests.implementation, node stores representation state s, currentpolicy (s) specifies test diagnosis action, current value function V (s).node (s; xn ) stores probability distribution outcomes xn,action-value function Q (s; xn ), expected cost measuring xn continuingpolicy .Every possible policy corresponds subtree full AND/OR graph.node subtree (starting root) contains one child (s; a)corresponding action = (s) chosen policy .AO algorithm (Nilsson, 1980) computes optimal policy AND/OR graph.AO guided heuristic function. describe heuristic function terms state272fiLearning Diagnostic Policies Examples{}nodeHealthyInsulinDiabetesGlucoseBMInodenodenodesmalllargeHGHGlowhighHHGGlowhighHlowHhighHHFigure 3: example AND/OR graph. root node corresponds states0 = fg. child node test actions (BMI, GlucoseInsulin), also diagnosis actions (Healthy Diabetes).choice BMI test root node leads node (s0 ; BMI ),specifies expectation outcomes test BMI (small large).BMI small, child node (s0 ; BMI ) node statefBMI = smallg; node, choice among actions Healthy,Diabetes, Glucose Insulin.action pairs, h(s; a), instead terms states. heuristic function admissibleh(s; a) Q(s; a) states actions a. means h underestimatestotal cost executing action state following optimal policy afterwards.admissible heuristic allows AO algorithm safely ignore action a0 anotheraction known Q (s; a) < h(s; a0 ). conditions, (s; a0 ) cannotpart optimal policy.AO search begins AND/OR graph containing root node.repeats following steps: current best policy, selects node expand;expands (expanding node creates children nodes); recomputes(bottom-up) optimal value function policy revised graph. algorithmterminates best policy unexpanded nodes (in words, leaf273fiBayer-Zubek & Dietterichvxuse hoptevaluateFigure 4: Qopt (s; x) unexpanded node (s; x) computed using one-step lookaheadhopt evaluate resulting states s0 . x attribute yet measuredstate s, v one values.nodes policy specify diagnosis actions, policy complete diagnosticpolicy).AO search, maintain two policies, whose actions value functionsstored nodes AND/OR graph. call first policy optimistic policy,opt . show below, value function V opt lower bound optimal valuefunction V . policy appears Nilsson's original description AO ,provides enough information compute optimal policy (Martelli & Montanari,1973). search, optimistic policy opt incomplete policy,includes unexpanded nodes; opt becomes complete policy, factoptimal policy.second policy maintain called realistic policy, real . showvalue function, V real , upper bound optimal value function V .realistic policy always complete policy, executable iteration AO .maintaining realistic policy, AO becomes anytime algorithm.define two policies detail introduce admissible heuristic.4.1.1 Admissible Heuristicadmissible heuristic provides optimistic estimate, Qopt (s; x), expected costunexpanded node (s; x). based incomplete two-step lookahead search(seeFigure 4). first step lookahead search computes Qopt (s; x) = C (s; x) +P0opt 00Ptr (s js; x) h (s ). iterates states resulting measuring test x.second step lookahead defined function hopt (s0 ) = mina 2A(s ) C (s0 ; a0 );minimum cost diagnosis action fbest costremaining tests x0 s0. is, rather considering states s00 would resultmeasuring x0 , consider cost measuring x0 itself. ItPfollows immediatelyhopt (s0) V (s0 ); 8s0, C (s0; x0 ) Q (s0 ; x0 ) = C (s0; x0 ) + Ptr (s00 js0; x0 ) V (s00 ).key thing notice cost single measurement x0 less equalcost policy begins measuring x0 , policy must pay costleast one action (diagnosis measurement) entering terminal statesf . Consequently, Qopt(s; x) Q (s; x), Qopt admissible heuristic stateaction x.00002740fiLearning Diagnostic Policies Examples4.1.2 Optimistic Values Optimistic Policydefinition optimistic action-value value Qopt extended nodesAND/OR graph following recursion:8>< C (s; a), = fk (a diagnosis action)optQ (s; a) = > C (s; a) + PPtr (s0js; a) hopt (s0 ), (s; a) unexpanded(3)Ps:0opt0C (s; a) + Ptr (s js; a) V (s ), (s; a) expanded,00V opt (s) def= mina2A(s) Qopt (s; a). Recall A(s) consists attributes yetmeasured diagnosis actions.optimistic policy opt (s) = argmina2A(s) Qopt (s; a): Every node storesoptimistic value V opt (s) policy opt (s), every node (s; a) stores Qopt (s; a).Theorem 4.1 proves Qopt V opt form admissible heuristic. proofstheorems paper appear thesis Bayer-Zubek (2003).Theorem 4.1 states actions 2 A(s), Qopt(s; a) Q (s; a); V opt (s)V (s):4.1.3 Realistic Values Realistic Policycurrent graph constructed AO , suppose delete unexpandednodes (s; a). call resulting graph realistic graph, every leaf nodeselect diagnosis action. optimal policy computed graph called realisticpolicy, real . complete policy leaves specify diagnosis actions minimum expectedmisdiagnosis cost.Every node stores realistic value V real (s) policy real (s), everynode (s; a) stores realistic action-value value, Qreal (s; a). 2 A(s), define8>= fk (a diagnosis action)< C (s; a), ifPrealQ (s; a) = > C (s; a) + Ptr (s0 js; a) V real (s0 ), (s; a) expanded(4):ignore, (s; a) unexpanded0V real (s) = mina2A (s) Qreal (s; a); set A0 (s) A(s) without unexpanded actions. realistic policy real (s) = argmina2A (s) Qreal (s; a):00Theorem 4.2 realistic value function V real upper bound optimal valuefunction: V (s) V real (s); 8s:4.1.4 Selecting Node Expansioncurrent optimistic policy opt , choose expand unexpanded node(s; opt (s)) largest impact root node. definedargmax [V real (s) , V opt (s)] Preach (sjopt );optPreach(sj ) probability reaching state start state followingpolicy opt . difference V real (s) , V opt (s) upper bound much valuestate could change opt (s) expanded.275fiBayer-Zubek & Dietterichrationale selection based observation AO terminatesV opt(s0 ) = V real (s0 ). Therefore, want expand node makes biggest steptoward goal.4.1.5 Implementation AO (High Level)implementation AO following:repeatselect node (s; a) expand (using opt; V opt; V real ).expand (s; a).bottom-up updates Qopt; V opt; opt Qreal; V real; real.unexpanded nodes reachable opt .updates value functions based one-step lookaheads (Equations 3 4), using value functions children. iteration, start newly expandednode (s; a), compute Qopt (s; a) Qreal (s; a), compute V opt (s); opt (s),V real (s); real (s) parent node, propagate changesAND/OR graph way root. Full details implementation AO appearthesis Bayer-Zubek (2003).nodes expanded, optimistic values V opt increase, becoming tighter lowerbounds optimal values V , realistic values V real decrease, becoming tighterupper bounds. V opt V real converge value optimal policy: V opt (s) =V real (s) = V (s), states reached .admissible heuristic avoids exploring expensive parts AND/OR graph; indeed,V real (s) < Qopt (s; a), action need expanded (this heuristiccutoff). Initially, V real (s) = C (s; fbest ), explains measurement costslarge relative misdiagnosis costs produce many cutoffs.4.2 Greedy Searchconsidered AO algorithm systematic search, turn attentionseveral greedy search algorithms finding good diagnostic policies. Greedy searchalgorithms grow decision tree starting root, state s0 = fg. nodetree corresponds state MDP, stores corresponding action = (s)chosen greedy algorithm. children node correspond states resultexecuting action state s. diagnosis action fk chosen state s,node children decision tree (it leaf node).greedy algorithms considered paper share general template,shown pseudo-code Table 1. state s, greedy algorithm performslimited lookahead search commits choice action executes, thereby defines (s) = a. generates child nodes correspondingstates could result executing action state s. algorithm invokedrecursively child nodes.greedy algorithm committed xn = (s), choice final. Note however,regularization methods may prune policy replacing measurementaction (and descendents) diagnosis action. general, greedy policiesoptimal, perform complete analysis expected total cost276fiLearning Diagnostic Policies ExamplesTable 1: Greedy search algorithm. Initially, function Greedy() calledstart state s0 .function Greedy(state s) returns policy (in form decision tree).(1) (stopping conditions met)(2) select measurement action xn executeset (s) := xnresulting value vn test xn add subtreeGreedy(state [ fxn = vn g)else(3) select diagnosis action fbest , set (s) := fbest :executing xn committing action. Nevertheless, ecientgreediness.following discussion, describe several different greedy algorithms. defineone describing refines numbered lines template Table 1.4.2.1 InfoGainCost MethodsInfoGainCost methods inspired C4.5 algorithm constructing classificationtrees (Quinlan, 1993). C4.5 chooses attribute xn highest conditional mutualinformation class labels training examples. diagnostic setting,analogous criterion choose measurement action predictive correctdiagnosis. Specifically, let xn proposed measurement action, define P (xn ; yjs)joint distribution xn correct diagnosis conditioned informationalready collected state s. conditional mutual information xny, (xn ; yjs), defined(xn; yjs) = H (yjs) , H(yjs; xn )X= H (yjs) , P (xn = vn js) H (yjs [ fxn = vn g)vnH (y) = ,P (y) log P (y) Shannon entropy random variable y.mutual information also called information gain, quantifiesaverage amount information gain measuring xn .InfoGainCost methods penalize information gain dividing costtest. Specifically, choose action xn maximizes (xn ; yjs)=C (xn ). criterionintroduced Norton (1989). researchers considered various monotonictransformations information gain prior dividing measurement cost (Tan,1993; Nunez, 1991). defines step (2) algorithm template.InfoGainCost methods employ stopping conditions defined C4.5.first stopping condition applies P (yjs) 1 value = k. case,diagnosis action chosen fbest = k. second stopping condition appliesP277fiBayer-Zubek & Dietterichmeasurement actions available (i.e., tests performed). case,diagnosis action set likely diagnosis: fbest := argmaxy P (yjs).Notice InfoGainCost methods make use misdiagnosis costsMC (fk ; y).4.2.2 Modified InfoGainCost Methods (MC+InfoGainCost)propose extending InfoGainCost methods consider misdiagnosis costsstopping conditions. Specifically, step (3), MC+InfoGainCost methods setfbest diagnosis action minimum expected cost:(s) := fbest = argminXfkP (yjs) MC (fk ; y):4.2.3 One-step Value Information (VOI)previous greedy methods either ignore misdiagnosis costs considerchoosing final diagnosis actions, VOI approach considers misdiagnosiscosts (and measurement costs) step.Traditionally, value information measurement defined differenceexpected value best action performing measurementexpected value best action performing measurement. Since objectivecost minimization, need reverse sign definition. However, still keepnotation VOI instead cost information. Instead taking account futuredecisions, make greedy approximation VOI, called one-step VOI,consider cost best diagnosis action performing measurementxn state s:X1-step-VOI(s; xn ) = minP (yjs) MC (fk ; y)fk",XvnP (xn = vn js) minfkX#P (yjs [ fxn = vn g) MC (fk ; y) :test xn performed value exceeds cost, 1-step-VOI(s; xn ) > C (xn ).Intuitively, one-step VOI method repeatedly asks following question: worthexecuting one measurement making diagnosis, better makediagnosis now?state s, one-step VOI method first computes cost stopping choosingaction fbest minimizes expected misdiagnosis costs:C (s; fbest ) = minfkXP (yjs) MC (fk ; y):Then, possible measurement action xn , method computes expected costmeasuring xn choosing minimum cost diagnosis actions resulting278fiLearning Diagnostic Policies Examplesstates:1-step-LA(s; xn ) = C (xn) +Xvn"P (xn = vnjs) minfkX#P (yjs [ fxn = vn g) MC (fk ; y) :(5)Define xbest = argminxn 1-step-LA(s; xn ).definitions, describe one-step VOI method terms template Table 1 follows. stopping condition (1) C (s; fbest ) 1-step-LA(s; xbest );method also stops tests performed. choice measurement action (2) xbest . choice final diagnosis action step (3) fbest .5. Learning, Overfitting, Regularizationprevious section, considered search algorithms finding good diagnostic policies.algorithms require various probabilities, particularly P (xn = vn js) P (yjs)every state-action pair (s; xn ) (s; fk ) generated search.One way obtain probabilities fit probabilistic model P (x1 ; : : : ; xN ; y)training data apply probabilistic inference model computedesired probabilities. example, algorithm K2 (Cooper & Herskovits, 1992)could applied learn Bayesian network training data. advantageapproach would cleanly separate process learning probabilitiesprocess searching good policy.chief disadvantage approach prevents us exploitingproblem solving task determine probabilities learned accuratelyprobabilities ignored (or learned less accurately). Consequently,adopted different approach learning fully integrated search process.important, enables us control overfitting also providesadditional opportunities speeding search.basic way integrate learning search process simple. timesearch algorithm needs estimate probability, algorithm examines trainingdata computes required probability estimate. example, algorithm needsestimate P (x1 = v1 jfx3 = v3 ; x5 = v5 g), make pass training datacount number training examples x3 = v3 x5 = v5 . Denote#(x3 = v3 ; x5 = v5 ). make second pass data count #(x1 = v1 ; x3 =v3 ; x5 = v5). two quantities, compute maximum likelihood estimate:P^ (x1 = v1 j fx3 = v3 ; x5 = v5g) = #(x1#(=xv1 ;=xv3 ;=xv3 ;=xv5 )= v5 ) :3general,3fxn = vng) :P^ (xn = vnjs) = #(s [ #(s)55Similarly, P (yjs) estimated fraction training examples matching statediagnosis y:s; y) :P^ (yjs) = #(#(s)279fiBayer-Zubek & Dietterichprocess obviously made ecient allowing training data\ ow" AND/OR graph (for AO algorithm) classification tree (for greedyalgorithms) constructed. Hence, starting state (the root) stores listtraining examples. node state stores list trainingexamples match s. example matches state agrees measurementresults define state. node measures xn state viewedpartitioning training examples stored node disjoint subsets accordingobserved values test xn . method employed classification treealgorithms many years (Breiman et al., 1984; Quinlan, 1993).Unfortunately, straightforward approach, combined systematicgreedy search algorithms, often results overfitting|that is, finding policies givegood performance training data give quite poor performance newcases.Figure 5 illustrates AO . figure shows anytime graphvalue V real (s0 ) current realistic policy, real , plotted node expansion (oriteration algorithm). V real evaluated training data disjointtest data set. training data, quality learned policy improves monotonicallynumber iterations|indeed, guaranteed AO algorithm.test data, performance realistic policies gets worse 350 iterations. Uponconvergence, AO learned optimal policy respect training data,policy performs badly test data.Machine learning research developed many strategies reducing overfitting.remainder section describes regularizers developed systematic greedy search algorithms. First, discuss regularizers AO . discussregularizers greedy search.5.1 Regularizers AO SearchOverfitting tends occur learning algorithm extracts much detailed information training data. happen, example, learning algorithmconsiders many alternative policies given amount training data. alsooccur algorithm estimates probabilities small numbers training examples. problems arise AO . AO considers many different policieslarge AND/OR graph. AND/OR graph grows deeper, probabilitiesdeeper nodes estimated fewer fewer training examples.pursued three main strategies regularization: (a) regularizing probabilityestimates computed search, (b) reducing amount search pruningearly stopping, (c) simplifying learned policy post-pruning eliminate partsmay overfit training data.5.1.1 Laplace Correction (denoted `L')regularize probability estimates, standard technique employ Laplace corrections. Suppose measurement xn Vn possible outcomes. discussed above,280fiLearning Diagnostic Policies Examples45AO* training dataAO* test dataValue realistic policy403530252015110100iteration100010000Figure 5: Illustration AO overfitting. anytime graph shows best realisticpolicy, according test data, discovered 350 iterations,AO overfits.maximum likelihood estimate P (xn = vn js)fxn = vng) :P^ (xn = vnjs) = #(s [ #(s)Laplace-corrected estimate obtained adding 1 numerator Vndenominator:fxn = vng) + 1 :P^L (xn = vn j s) = #(s [#(s) + VnSimilarly, Laplace-corrected estimate diagnosis obtained adding 1numerator K (the number possible diagnoses) denominator:s; y) + 1 :P^L (yjs) = #(#(s) + KOne advantage Laplace correction probability value ever estimated 0 1. probability values extreme, hence, extremely dangerous.281fiBayer-Zubek & Dietterich45AO* training dataAO* test dataAO*-L training dataAO*-L test dataValue realistic policy403530252015110100iteration100010000Figure 6: Anytime graphs AO AO Laplace correction. Laplace regularizerhelps AO , anytime graph value last policy learned.example, AO believes P (xn = vn js) = 0, expand branchtree. Even serious, AO believes P (y = cjs) = 0,consider potential misdiagnosis cost MC (fk ; = c) computing expected costsdiagnosis actions fk state s.Figure 6 shows AO Laplace regularizer gives worse performancetraining data better performance test data AO . Despite improvement,AO Laplace still overfits: better policy learned early discarded laterworse one.5.1.2 Statistical Pruning (SP)second regularization technique reduces size AO search space pruningsubtrees unlikely improve current realistic policy.statistical motivation following: given small training data sample,many pairs diagnostic policies statistically indistinguishable. Ideally, wouldlike prune policies AND/OR graph statistically indistinguishableoptimal policies. Since possible without first expanding graph, needheuristic approximately implements following indifference principle:282fiLearning Diagnostic Policies Examplesstateunexpandedoptimistic policyoptVrealisticpolicyVrealFigure 7: Statistical pruning (SP) checks whether V opt (s) falls inside confidence intervalaround V real (s). does, SP prunes opt (s) (the unexpanded optimisticpolicy).Indifference Principle. Given two diagnostic policies whose values statisticallyindistinguishable based training data set, learning algorithm choose arbitrarilythem.heuristic called statistical pruning (abbreviated SP), appliednode whose optimistic policy selected expansion. two diagnostic policiesconsideration currently unexpanded optimistic policy opt (s) currentrealistic policy real (s). action specified opt (s) pruned graphstatistical test cannot reject null hypothesis V opt (s) = V real (s). words,incomplete policy opt complete policy real , prefer latter.statistical test computed follows. training examples tematches state s, apply real compute total cost diagnosis (startingstate s). information, compute 95% confidence interval V real (s) (e.g.,using standard normal distribution assumption). V opt (s) falls inside confidenceinterval, cannot reject null hypothesis V opt (s) = V real (s). Therefore,indifference principle, choose real (s) prune opt (s). illustratedFigure 7.V opt (s) lower bound V (s) (see Theorem 4.1) V real (s) upperbound V (s) (see Theorem 4.2), relate statistical pruning indifferenceprinciple slightly stronger way. V opt (s) falls inside confidence interval V real (s),V (s) must also fall inside confidence interval, V opt (s) V (s) V real (s).Hence, least 95% confidence, cannot reject null hypothesis V real (s) =V (s). Hence, indifference principle authorizes us choose real , since statisticallyindistinguishable optimal policy. However, argument remains truelong real remains unchanged. Subsequent expansions AO may change realinvalidate statistical decision.SP heuristic applied AND/OR graph grown. node (s; a)selected expansion, SP first checks see node pruned instead.pruned, action ignored computations (SP deletes283fiBayer-Zubek & Dietterichset available actions A(s)). AO updates Qopt ; V opt ; opt graph.updates real V real needed, pruning change realistic graph.previous work (Bayer-Zubek & Dietterich, 2002), described version SPheuristic employed paired-difference statistical test instead simple confidenceinterval test described here. synthetic problems, two statistical tests gave nearlyidentical results. prefer confidence interval test, allows us relateV real (s) V (s).care must taken combining statistical pruning Laplace corrections.Laplace corrections, mean observed total cost training examplesmatching state processed real V real (s), lattercomputed using Laplace-corrected probabilities. fix problem, compute widthconfidence interval applying real training example matching stateuse V real (s) center confidence interval.5.1.3 Early Stopping (ES)Another way limit size search space considered AO halt searchearly. method long applied regularize neural networks (e.g., Lang, Waibel,& Hinton, 1990). Early stopping employs internal validation set decide haltAO . training data split half. One half called \subtraining data",half called \holdout data". AO trained subtraining data,every iteration, real evaluated holdout data. real gives lowest totalcost holdout data remembered, AO eventually terminates, bestrealistic policy returned learned policy.Early stopping combined Laplace correction simply running AOLaplace corrections subtraining set. need Laplace-correctevaluation real holdout set.5.1.4 Pessimistic Post-Pruning (PPP) Based Misdiagnosis Costsfinal AO regularizer pessimistic post-pruning. based well-known methodinvented Quinlan pruning classification trees C4.5 (Quinlan, 1993). PPP takescomplete policy training data set produces \pruned" policy 0 hope0 exhibits less overfitting. PPP applied final realistic policy computedAO .central idea PPP replace expected total cost V (s) statestatistical upper bound UB (s) takes account uncertainty due amountvariability training data. internal node s, upper bound showsselecting best diagnosis action would preferred selecting measurement action (s),node converted leaf node (and UB estimates ancestors policyupdated). PPP performed single traversal decision tree .Computation begins leaves policy (i.e., states (s) choosesdiagnosis action fk ). Let UB (s) upper limit 95% normal confidence intervalC (s; fk ) (i.e., expected misdiagnosis cost choosing action fk state s).computed taking training example matches state s, assigning diagnosis284fiLearning Diagnostic Policies Examplesfk , computing misdiagnosis cost MC (fk ; y), correct diagnosistraining example.upper bound internal node computed according recursionXUB (s) = C (s; (s)) + Ptr (s0 js; (s)) UB (s0):0Bellman equation state value function replaced UBfunction. (s) pruned, replaced diagnosis action fbest minimumexpected cost, upper bound C (s; fbest ) less UB (s) internal node,computed above. case, UB (s) set upper bound C (s; fbest ).PPP combined Laplace regularization follows. First, computing UB (s)leaf node, K \virtual" training examples added state s, one virtual example diagnosis. words, normal confidence interval computedusing misdiagnosis costs training examples match plus one MC ((s); y)possible diagnosis y. Note probabilities P (yjs) Ptr (s0 js; (s)) alreadyLaplace-corrected running AO Laplace corrections.5.1.5 Summary AO Regularizersdescribed following regularizers: Laplace corrections (L), statistical pruning(SP), early stopping (ES), pessimistic post-pruning (PPP). also showncombine Laplace regularization others.5.2 Regularizers Greedy Searchdescribe four regularizers employed greedy search.5.2.1 Minimum Support PruningInfoGainCost InfoGainCost+MC methods, adopt minimum supportstopping condition C4.5 (Quinlan, 1993). order measurement action xnchosen, least two possible outcomes vn must lead states least 2training examples matching them. not, xn eligible selection step (2)Table 1.5.2.2 Pessimistic Post-Pruning (PPP) Based Misdiagnosis RatesInfoGainCost method, applied C4.5's standard pessimistic post-pruning.InfoGainCost grown decision tree, tree traversed post-order. leafnode s, pessimistic error estimate computed23UB (s) = n 4p + zc p(1 n, p) + 21n 5 ;n number training examples reaching leaf node, p error ratecommitted diagnosis action training examples leaf, zc = 1:1575% critical value normal distribution. UB (s) upper limit 75%confidence interval binomial distribution (n; p) plus continuity correction.285fiBayer-Zubek & Dietterichinternal node s, pessimistic error estimate simply sum pessimisticerror estimates children. internal node converted leaf node sumchildren's pessimistic errors greater equal pessimistic error wouldconverted leaf node.Laplace regularization combined PPP replacing observed error ratep Laplace-corrected version (this computed adding one \virtual" examplediagnosis).5.2.3 Post-Pruning Based Expected Total CostsMC+InfoGainCost method, apply post-pruning procedure basedpessimistic estimate rather estimated total cost diagnosis. RecallMC+InfoGainCost grows decision tree way InfoGainCost, assigns diagnosis actions leaf nodes choosing action smallest expectedmisdiagnosis cost training data.regularized traversing resulting decision tree convertinginternal node (s) = xn leaf node (where (s) = fbest ) expected costchoosing diagnosis action fbest less expected total cost choosing measurementaction xn . implemented computing C (s; fbest ) Q (s; xn ) comparingthem. C (s; fbest) Q (s; xn ), node converted leaf node. computationcarried single post-order traversal decision tree corresponding .Laplace corrections combined pruning procedure applying Laplacecorrections probabilities employed computing Q (s; xn ) C (s; fbest).Bradford et al. (1998) present similar method pruning decision trees basedmisclassification costs (and zero attribute costs), combined Laplace correction classprobability estimates (there Laplace correction transition probabilities).interesting note post-pruning based total costs necessaryVOI, pruning already built-in. Indeed, internal node VOI policy, (s) = xn, Q (s; xn ) V OI (s; xn ) < C (s; fbest ) (the proof theoremappears thesis Bayer-Zubek (2003)).5.2.4 Laplace CorrectionAO , could apply Laplace corrections probabilities computedgreedy search.InfoGainCost method, Laplace correction diagnosis probabilities P (yjs)change likely diagnosis. MC+InfoGainCost method, Laplace correctiondiagnosis probabilities may change diagnosis action minimum expected cost.Laplace correction applied computation information gain (xn ; yjs).InfoGainCost method, Laplace correction applied pruning phase,error rate p. MC+InfoGainCost method, Laplace correction applied, policygrown, P (yjs) computing C (s; fk ), also applied post-pruningbased expected total costs, P (xn = vn js) P (yjs).VOI method, Laplace correction applied probabilities employedEquation 5 computation C (s; fbest).286fiLearning Diagnostic Policies Examples6. Experimental Studiespresent experimental study measure compare effectiveness efficiency various search regularization methods described above. goalidentify one practical algorithms learn good diagnostic policies real problems modest-sized training data sets. main questions are: algorithmbest among algorithms proposed? overall winner,robust algorithm?6.1 Experimental Setupperformed experiments five medical diagnosis problems based real data sets foundUniversity California Irvine (UCI) repository (Blake & Merz, 1998).five problems listed along short name parentheses userefer them: Liver disorders (bupa), Pima Indians Diabetes (pima), Cleveland HeartDisease (heart), original Wisconsin Breast Cancer (breast-cancer), SPECT heartdatabase (spect). data sets describe patient vector attribute valuesclass label. define measurement action attribute; executed, actionreturns measured value attribute. define one diagnosis action classlabel.domains chosen two reasons. First, real medical diagnosisdomains. Second, measurement costs provided three (bupa, pima,heart) Peter Turney (Turney, 1995); two domains, set measurementcosts 1. Table 2 brie describes medical domains; information availablethesis Bayer-Zubek (2003).pre-processing steps applied domains. First, training examplescontained missing attribute values removed data sets. Second, dataset contained two classes, selected classes merged two classes(healthy sick) remained. Third, existing division data trainingtest sets ignored, data simply merged single set. real-valuedattribute xn discretized 3 levels (as defined two thresholds, 1 2 )discretized variable takes value 0 xn 1 , value 1 1 < xn 2value 2 otherwise. values thresholds chosen maximize informationgain discretized variable class. information gain computedusing entire data set.domain, transformed data (2 classes, discretized attributes missingvalues) used generate 20 random splits training sets (two thirds data)test sets (one third data), sampling stratified class. split (training data,test data) called replica. repeated experiments replicasobtain rough idea amount variability expected one replicaanother. However, important note replicas independent (i.e.,share data points), must use caution combining results different replicasdrawing conclusions superiority one algorithm compared another.287fiBayer-Zubek & DietterichTable 2: Medical domains. domain, list number examples, numbertests, minimum maximum cost test.domain# examples # tests min test cost max test costbupa34557.279.86pima7688122.78heart297131102.9breast-cancer683911spect26722116.1.1 Setting Misdiagnosis Costs (MC)None five UCI domains specifies misdiagnosis costs, performed experimentsusing five different levels misdiagnosis costs domain. cost levelsdesigned initial state s0 diagnosis decisions f0 f1 equalexpected cost diagnostic policies non-trivial (i.e., perform leastone measurement, perform possible measurements). call five MClevels MC1, MC2, MC3, MC4, MC5, progressively make misdiagnosisexpensive. Full details methodology given thesis Bayer-Zubek (2003).6.1.2 Memory Limitlarge domains (with many measurements), AND/OR graph constructed AOgrows large, especially following cases: measurements informative; measurement costs low relative misdiagnosis costs, admissibleheuristic produce many cutoffs; optimal policy deep;many policies tied optimal one AO needs expand provebetter alternative.make systematic search feasible, need prevent AND/OR graph growinglarge. imposing limit total amount memory AND/ORgraph occupy. measure memory usage based amount memory wouldrequired optimized AND/OR graph data structure. \theoretical" memorylimit set 100 MB. actual implementation optimized, translateslimit 500 MB. memory limit reached, current realistic policyreturned result search. algorithms (greedy systematic)converge within memory limit five domains, one exception: AO largemisdiagnosis costs reaches memory limit spect data set.interesting note even domain many measurements, systematicsearch algorithms may converge reaching memory limit. consequencefact modest-sized training data sets, number reachable states MDP(i.e., states reached non-zero probability policy) fairly small,288fiLearning Diagnostic Policies Examplespossible combinations attribute values appear modest-sized dataset.6.1.3 Notations Learning Algorithmsremainder paper, employ following abbreviations identifyvarious search algorithms regularizers. cases, sux \L" indicatesLaplace corrections applied algorithm described Section 5.Nor, Nor-L denote InfoGainCost Norton's criterion selecting actions pessimistic post-pruning based misdiagnosis rates.MC-N, MC-N-L denote MC+InfoGainCost Norton's criterion selecting measurement actions. Diagnosis actions selected minimize expected misdiagnosiscosts. Post-pruning based expected total costs.VOI, VOI-L denote one-step Value Information greedy method.AO , AO -L denote AO .SP, SP-L denote AO Statistical Pruning.ES, ES-L denote AO Early Stopping. early stopping, half trainingdata held choose stopping point, half used AOcompute transition probabilities.PPP, PPP-L denote AO Pessimistic Post-Pruning.6.1.4 Evaluation Methodsevaluate algorithm, train training set construct policy.compute value policy test set, denote Vtest . computeVtest , sum measurement costs misdiagnosis cost test example,processed policy, divide total cost examples numbertest examples.Note framework, Vtest always computed using measurement costsmisdiagnosis costs, even policy constructed learning algorithm (e.g.,InfoGainCost) ignores misdiagnosis costs.order compare learning algorithms, need way comparing Vtestvalues see statistically significant difference among them. Even two learningalgorithms equally good, Vtest values may different random variationchoice training test data sets. Ideally, would employ statistical proceduresimilar analysis variance determine whether observed differences Vtestexplained differences learning algorithm (rather random variationdata sets). Unfortunately, procedure exists suitable comparing diagnosticpolicies. Hence, adopted following procedure.discussed above, generated 20 replicas data sets. addition,built five misdiagnosis cost matrices data set. apply learningalgorithm replica using five MC matrices, requires total 500289fiBayer-Zubek & Dietterichruns learning algorithm domains. replica cost matrixpair learning algorithms (call alg1 alg2), apply BDeltaCost bootstrapstatistical test (Margineantu & Dietterich, 2000) decide whether policy constructedalg1 better than, worse than, indistinguishable policy constructed alg2(based 95% confidence level). Depending BDeltaCost results, sayalg1 wins, loses, ties alg2.BDeltaCost test applied replica data set. BDeltaCostresults combined produce overall score algorithm accordingfollowing chess metric. given pair algorithms, alg1 alg2, domain D, let(wins; ties; losses) cumulative BDeltaCost results alg1 alg2, across fivemisdiagnosis cost matrices 20 replicas. chess metric computed countingwin one point, tie half point, loss zero points:Score(alg1; alg2; D) def= wins + 0:5 ties:also compute overall chess score algorithm summing chess scoresalgorithms:XScore(alg1; D) =Score(alg1; alg2; D):alg26=alg1Note total number \games" played algorithm Total = wins +ties + losses, games turned ties, chess score would 0:5 Total,call Tie-Score. algorithm's chess score greater Tie-Score,algorithm wins losses.pairwise BDeltaCost tests account variation Vtest resulting random choice test sets. purpose 20 replicas account also randomchoice training sets. Ideally, 20 training sets would disjoint, would allow us compute unbiased estimate variability Vtest due training sets.Unfortunately, amount training data limited, cannot make training sets independent, result, overall chess scores probably underestimatesource variability.6.2 Resultspresent results experiments.6.2.1 Laplace Correction Improves Algorithmsfirst studied effect Laplace regularizer algorithm.seven algorithms Laplace correction, computed chess score respectnon-Laplace version, domain. total number \games" algorithmplays non-Laplace version 100 (there 5 misdiagnosis costs 20 replicas);therefore, Tie-Score = 50.Figure 8 shows domain, Laplace-corrected algorithm scores winslosses versus non-Laplace-corrected algorithm (because score greaterTie-Score). supports conclusion Laplace correction improves performance algorithm. algorithms, AO , helpedothers Laplace.290fiLearning Diagnostic Policies ExamplesChess score Laplace-corrected alg. vs. non-Laplace alg.100bupa90pimaheart80b-can70spect60Tie-Score50403020100Nor-LMC-N-LgreedyVOI-LAO*-LSP-LES-LPPP-LsystematicFigure 8: score Laplace-corrected algorithm versus non-Laplace version,domain, greater Tie-Score. Therefore Laplace versionwins losses.Since Laplace regularizer improved algorithm, decided compareLaplace-corrected versions algorithms subsequent experiments.6.2.2 Robust Algorithmdetermine algorithm robust across five domains, computedoverall chess score Laplace-corrected algorithm Laplacecorrected algorithms, domain. total number \games" 600 (there5 misdiagnosis costs matrices, 20 replicas, 6 \opponent" algorithms); therefore,Tie-Score 300.Figure 9 shows best algorithm varies depending domain: ES-L bestbupa, VOI-L best pima spect, SP-L best heart, MC-N-L bestbreast-cancer. Therefore single algorithm best everywhere. Nor-L consistently baddomain; score always Tie-Score. expected, sinceNor-L use misdiagnosis costs learning policy. MC-N-L, usemisdiagnosis costs, always scores better Nor-L.291fiBayer-Zubek & Dietterich400bupa380pimaheart360b-canOverall chess score340spect320Tie-Score300280260240220200Nor-LMC-N-LgreedyVOI-LAO*-LSP-LES-LsystematicPPP-LFigure 9: overall chess score Laplace-corrected algorithm, versusLaplace-corrected algorithms. robust algorithm SP-L;one whose score greater Tie-Score (and therefore winslosses) every domain.fact VOI-L best two domains interesting, ecientgreedy algorithm. Unfortunately, VOI-L obtains worst score two domains: heartbreast-cancer.algorithm wins losses every domain SP-L, combines AO search, Laplace corrections, statistical pruning. SP-L always scored amongtop three algorithms. Consequently, recommend robust algorithm.However, applications SP-L (or systematic search algorithms)expensive run, VOI-L recommended, since best greedy methods.addition looking overall chess scores, also studied actual Vtest values.visualize differences Vtest values, plotted graph call \pair graph".Figure 10 shows pair graphs comparing VOI-L SP-L five domains. horizontalaxis graph corresponds 20 replicas, vertical axis Vtest valuestwo algorithms (VOI-L SP-L) replica. 20 replicas sorted according292fiLearning Diagnostic Policies ExamplesVtest VOI-L. two algorithms tied replica (according BDeltaCost),Vtest values connected vertical dotted line.bupa heart, Vtest SP-L mostly smaller (better) Vtest VOI-L,BDeltaCost finds tied. pima spect, situation reversed (VOI-Lalmost always better SP-L), several replicas difference statistically significant. breast-cancer, SP-L better VOI-L, difference sometimessignificant. general, pair graphs confirm chess score results support mainconclusion SP-L robust learning algorithm.6.2.3 Impact Heuristics Regularizers Memory Consumptionconsider effect admissible heuristic Laplace Statistical Pruning regularizers amount memory required AO search. this, measuredamount memory consumed five different algorithm configurations: AO withoutadmissible heuristic, AO admissible heuristic, AO admissible heuristic Laplace correction, AO admissible heuristic statistical pruning,and, finally, AO admissible heuristic, Laplace correction, statistical pruning.AO without admissible heuristic, set action-value every unexpandednode (s; xn ) zero, i.e., Qopt (s; xn ) = 0. results plotted Figure 11.memory amounts plotted computed taking actual memory consumedimplementation converting memory would consumed optimizedimplementation.several important conclusions draw figures. First, note AOwithout admissible heuristic requires much memory AO admissibleheuristic. Hence, admissible heuristic pruning large parts search space.particularly evident low settings misdiagnosis costs (MC1 MC2). lowsettings, AO able find many cutoffs expected cost diagnosis lesscost making additional measurements (as estimated admissible heuristic).savings much smaller MC levels 4 5.second important conclusion Laplace correction increases sizesearch space amount memory consumed. reason without Laplacecorrection, many test outcomes zero probability, pruned AO .Laplace correction, outcomes must expanded evaluated. effectminor low MC levels, AND/OR graph much smaller, consequentlyenough training data prevent zero-probability outcomes. high MC levels,Laplace correction cause increases factor 10 amount memoryconsumed.third important conclusion statistical pruning significantly decreases sizeAND/OR graph almost cases. exception heart MC4 MC5,statistical pruning increases amount memory needed AO . seems paradoxical statistical pruning could lead overall increase size AND/ORgraph explored. explanation interaction statistical pruning one point AND/OR graph additional search elsewhere.branch pruned would given significantly smaller value V , pre293fiBayer-Zubek & Dietterich1302400VOI-LSP-LVOI-LSP-L230012522001202100V_test[replica]V_test[replica]11511010520001900180017001001600951500901400replicareplica(a) bupa(b) pima5509VOI-LSP-LVOI-LSP-L8500450V_test[replica]V_test[replica]740065435033002replicareplica(c) heart(d) breast-cancer45VOI-LSP-LV_test[replica]4035302520replica(e) spectFigure 10: Pair graphs VOI-L SP-L every domain replica, largestmisdiagnosis costs MC5. replicas sorted increasing order VtestVOI-L. Vertical lines connect Vtest values tied according BDeltaCost.294fiLearning Diagnostic Policies ExamplesBUPAPima300001e+07AO*+LAO*+L20000AO* heurAO*AO*+SPMemory Consumed (bytes)Memory Consumed (bytes)AO*+SP+LAO*+SP+LAO* heurAO*1e+06AO*+SP10000010000MC1MC2MC3MC4MC5MC1MC2Misdiagnosis Cost LevelMC3MC4MC5Misdiagnosis Cost Level(a) bupa(b) pimaHeartBreast-cancer1e+091e+07AO*+LAO*+L1e+081e+06AO* heurAO*+SPAO*1e+06100000Memory Consumed (bytes)Memory Consumed (bytes)AO*+SP+L1e+07AO*+SP+LAO* heurAO*100000AO*+SP100001000010001000100100MC1MC2MC3MC4MC5MC1Misdiagnosis Cost LevelMC2MC3MC4MC5Misdiagnosis Cost Level(c) heart(d) breast-cancerSpectMemory Consumed (bytes)2e+081e+08AO* heurAO*AO*+LAO*+SPAO*+SP+L5e+072e+07MC1MC2MC3MC4MC5Misdiagnosis Cost Level(e) spectFigure 11: Memory consumed domain five combinations AO without admissible heuristic, Laplace corrections, statistical pruningfive levels misdiagnosis costs.295fiBayer-Zubek & Dietterichvent heuristic cutoffs elsewhere graph. cases, pruning increase overallmemory consumption.final conclusion statistical pruning dramatically reduces amount memory required AO Laplace correction. Even cases, heart, statistical pruning causes AO (without Laplace) consume space, SP reduces amountspace needed Laplace correction nearly order magnitude. Nonetheless,statistical pruning able completely compensate extra memory consumptionLaplace corrections, final algorithm (AO + SP + L) requires memoryAO without admissible heuristic high MC levels, AO + SP + L requiresmuch memory AO admissible heuristic.Despite large amount memory required, one domain (spectMC4 MC5) AO hit memory limit. Hence, see termsmemory, systematic search AO feasible today's desktop workstations.6.2.4 CPU Timeaddition measuring memory consumption, also measured CPU time requiredalgorithms. results plotted Figure 12. expected, systematicsearch algorithms require several orders magnitude CPU time greedymethods. However, even expensive algorithm configurations require less1000 seconds execute. Note misdiagnosis cost level increases, amountCPU time increases. direct ection corresponding increase sizeAND/OR graph explored algorithms.7. Conclusionsproblem addressed paper learn diagnostic policy data set labeledexamples, given measurement costs misdiagnosis costs. tradeofftwo types costs important issue machine learning research begunstudy.formulated process diagnosis Markov Decision Problem. showedapply AO algorithm solve MDP find optimal diagnostic policy.also showed convert AO algorithm anytime algorithm computingrealistic policy point search (the realistic policy best complete policyfound far). defined admissible heuristic AO able prune large partssearch space problems. also presented three greedy algorithms findingdiagnostic policies.paper discussed interaction learning training data searching good diagnostic policy. Experiments demonstrated overfitting seriousproblem AO . central contribution paper development methodsregularizing AO search reduce overfitting and, cases, also reducesize search space. Four regularization techniques (Laplace corrections, statisticalpruning, early stopping, pessimistic post-pruning) presented. paper also introduced regularizers greedy search algorithms extending existing methodsclassification tree learning.296fiLearning Diagnostic Policies Examples11000MC1MC3MC5MC1MC3MC5average_replica CPU Time (in seconds)average_replica CPU Time (in seconds)1000.10.011010.10.0010.01Nor-L MC-NMC-N-L VOI VOI-L AO* AO*-LESES-LSPSP-LPPP PPP-L(a) bupaNor-L MC-N MC-N-L VOIVOI-L AO* AO*-LESES-LSPSP-LPPP PPP-LESES-LSPSP-LPPP PPP-L(b) pima1000100MC1MC3MC5MC1MC3MC5100average_replica CPU Time (in seconds)average_replica CPU Time (in seconds)101010.110.10.010.010.0010.001Nor-L MC-NMC-N-L VOI VOI-L AO* AO*-LESES-LSPSP-LPPP PPP-L(c) heartNor-L MC-NMC-N-L VOI VOI-L AO* AO*-L(d) breast-cancer1000MC1MC3MC5average_replica CPU Time (in seconds)1001010.10.01Nor-L MC-N MC-N-L VOIVOI-L AO* AO*-LESES-LSPSP-LPPP PPP-L(e) spectFigure 12: CPU time 14 algorithm configurations five domains (in caseaveraged 20 replicas). three curves plot CPU time misdiagnosiscost levels MC1, MC3, MC5.297fiBayer-Zubek & Dietterichvarious search regularization algorithms tested experimentally fiveclassification problems drawn UCI repository. methodology assigning misdiagnosis costs developed problems could converted cost-sensitivediagnosis problems. paper also introduced methodology combining resultsmultiple training/test replicas overall \chess score" evaluating learningalgorithms.experiments showed search algorithms improved includingLaplace corrections estimating probabilities training data. experimentsalso showed systematic search algorithms generally robustgreedy search algorithms across five domains. best greedy algorithm VOI-L,although obtained best score two domains, produced worst score twodomains. robust learning algorithm SP-L. combines systematic AOsearch Laplace corrections statistical pruning.Systematic search diagnostic policies studied previously machinelearning researchers, probably generally regarded computationallyinfeasible. surprising conclusion paper AO computationally feasibleapplied problem learning diagnostic policies training examples.conclusion based experimental evidence|AO required less 500 MBmemory virtually benchmark scenarios|and theoretical analysis.theoretical perspective, five factors help make AO feasiblesetting: modest amount training data, modest number possible tests,small number outcomes test, admissible heuristic, statistical pruningregularizer. discuss factors turn:Modest amount training data. learning diagnosis, cost measuring attribute training example. Consequently, training exampleexpensive collect, puts practical limit size training dataset. turn limits space reachable states MDP. result,AND/OR graph searched AO grow large. amount trainingdata grows, graph gradually grow larger point, becomelarge available memory. Good results may still obtained imposingmemory limit, spect experiments.Modest number possible tests. experiments considered domains 22fewer tests. number tests determines branching factor nodesgraph, size graph scales exponentially quantity. However,tests pruned admissible heuristic statistical pruning,exponential explosion avoided. Whether possible particularproblem depends relative costs informativeness different tests.Small number outcomes test. discretized continuous measurement3 outcomes. number outcomes determines branching factornodes graph, graph size scales exponentially quantitywell. quantity controlled discretization (see below).admissible heuristic. problem learning diagnosis non-trivialcosts making measurements comparable costs misdiagnosis.298fiLearning Diagnostic Policies Examplestrue, admissible heuristic able prune large parts searchspace.Statistical pruning. Finally, statistical pruning regularizer able prune partssearch space unlikely produce improved policies.Notice size AND/OR graph increase number possiblediagnoses increases. Hence, AO* search approach scales well number possiblediagnostic outcomes.cases AND/OR graph becomes infeasibly large, recommend VOI-L, sinceexperiments showed best greedy method.MDP framework diagnosis general enough handle several extensionslearning algorithms studied paper. example, experiments, considereddiagnosis problems involve two classes, \healthy" \sick." could easilygeneralized consider arbitrary number classes. implementations assumedcost measurement depends attribute measured, C (xn ).easily generalized cost measurement depends testsalready executed results produced, also dependresult measurement. words, cost function measurementgeneralized C (s; xn ; s0 ), current state MDP, xn measurement,s0 resulting state s0 = [ fxn = vn g. implementations also assumedmisdiagnosis costs fixed patients, could extended allowcosts vary one patient another. changes diagnosis problem (multipleclasses complex costs) modify size complexity MDP.important extensions diagnostic setting require extensions MDPframework well. example, handle treatment actions side effects, noisyactions may need repeated, actions delayed results, definitionstate MDP needs extended. initial examination extensionssuggest cause MDP state space grow significantly,may make infeasible search space diagnostic policies systematically. Hence,extensions probably require new ideas solution.Another important direction future work extend approach handle testslarge number possible outcomes, including particularly tests continuousmeasured values. applied standard information-gain methods discretizing continuous attributes, interesting direction future work develop cost-sensitivediscretization methods.final challenge future research learn good diagnostic policies incomplete training data. algorithms presented paper assume attributetraining example measured. data hard obtain. every day,thousands patients seen physicians, medical tests performed, diagnosticdecisions made. data incomplete, physician followingdiagnostic policy certainly perform possible medical tests.resulting training examples many missing values, values \missingrandom", standard methods handling missing values cannot applied. Methodslearning diagnostic policies data would valuable many applications.299fiBayer-Zubek & Dietterichproblem learning diagnostic policy data collected executingdiagnostic policy identical problem \off-policy" reinforcement learning(Sutton & Barto, 1999). reinforcement learning, diagnostic policy generatingdata called exploration policy. Much known creating exploration policiesenable learning optimal policies. example, exploration policy non-zeroprobability executing every action every state, optimal policy stilllearned. exploration policy controlled learning system, muchselective exploration produce optimal policy (Kearns & Singh, 1998). extendingideas, may possible learn diagnostic policies data collected routinelyhospitals clinics.problem learning diagnostic policies fundamental many application domainsincluding medicine, equipment diagnosis, autonomic computing. diagnostic policymust balance cost gathering information performing measurements costmaking incorrect diagnoses. paper shown AO -based systematic search,combined regularization methods preventing overfitting, feasible methodlearning good diagnostic policies labeled examples.Acknowledgmentsauthors gratefully acknowledge support National Science Foundationgrants IRI-9626584, EIA-9818414, IIS-0083292, EIA-0224012, ITR-5710001197.authors also gratefully acknowledge support Air Force Oce Scientific Researchgrant number F49620-98-1-0375.paper extends conference paper Bayer-Zubek (2004).authors thank anonymous reviewers comments.ReferencesBayer-Zubek, V. (2003). Learning Cost-sensitive Diagnostic Policies Data. Ph.D.thesis, Department Computer Science, Oregon State University, Corvallis,http://eecs.oregonstate.edu/library/?call=2003-13.Bayer-Zubek, V. (2004). Learning diagnostic policies examples systematic search.Proceedings Twentieth Conference Uncertainty Artificial Intelligence,pp. 27{35, Banff, Canada.Bayer-Zubek, V., & Dietterich, T. (2002). Pruning improves heuristic search costsensitive learning. Proceedings Nineteenth International Conference Machine Learning, pp. 27{35, Sydney, Australia. Morgan Kaufmann.Blake, C., & Merz, C. (1998). UCI repository machine learning databases.http://www.ics.uci.edu/mlearn/MLRepository.html.Bradford, J. P., Kunz, C., Kohavi, R., Brunk, C., & Brodley, C. E. (1998). Pruning decision trees misclassification costs. European Conference Machine Learning,pp. 131{136. Longer version http://robotics.stanford.edu/users/ronnyk/ronnykbib.html, ECE TR 98-3, Purdue University.300fiLearning Diagnostic Policies ExamplesBreiman, L., Friedman, J., Olshen, R. A., & Stone, C. (1984). Classification RegressionTrees. Wadsworth, Monterey, California.Cooper, G. F., & Herskovits, E. (1992). Bayesian method induction probabilisticnetworks data. Machine Learning, 9, 309{347.Dittmer, S., & Jensen, F. (1997). Myopic value information uence diagrams.Proceedings Thirteenth Conference Uncertainty Artificial Intelligence, pp.142{149, San Francisco.Domingos, P. (1999). MetaCost: general method making classifiers cost-sensitive.Knowledge Discovery Data Mining, pp. 155{164.Fawcett, T., & Provost, F. (1997). Adaptive fraud detection. Data Mining KnowledgeDiscovery, 1(3), 1{28.Friedman, N., Geiger, D., & Goldszmidt, M. (1997). Bayesian network classifiers. MachineLearning, 29, 131{163.Friedman, N., & Goldszmidt, M. (1996). Building classifiers using Bayesian networks.Proceedings Thirteenth National Conference Artificial Intelligence, pp. 1277{1284, Cambridge, MA. AAAI Press/MIT Press.Greiner, R., Grove, A. J., & Roth, D. (2002). Learning cost-sensitive active classifiers.Artificial Intelligence, 139:2, 137{174.Hansen, E. (1998). Solving POMDPs searching policy space. ProceedingsFourteenth International Conference Uncertainty Artificial Intelligence, pp.211{219, San Francisco. Morgan Kaufmann.Heckerman, D., Breese, J., & Rommelse, K. (1994). Troubleshooting uncertainty.Tech. rep., MSR-TR-94-07, Microsoft Research.Heckerman, D., Horvitz, E., & Middleton, B. (1993). approximate nonmyopic computation value information. IEEE Transactions Pattern Analysis MachineIntelligence, 15, 292{298.Heckerman, D., Breese, J., & Rommelse, K. (1995). Decision-theoretic troubleshooting.Communications ACM, 38, 49{57.Kearns, M., & Singh, S. (1998). Near-optimal reinforcement learning polynomial time.Proceedings Fifteenth International Conference Machine Learning, pp.260{268. Morgan Kaufmann, San Francisco, CA.Lang, K. J., Waibel, A. H., & Hinton, G. E. (1990). time-delay neural network architectureisolated word recognition. Neural Networks, 3, 33{43.Lenert, L. A., & Soetikno, R. M. (1997). Automated computer interviews elicit utilities:potential applications treatment deep venous thrombosis. JournalAmerican Medical Informatics Association, 4 (1), 49{56.Littman, M. L., Ravi, N., Fenson, E., & Howard, R. (2004). instance-based state representation network repair. Proceedings Nineteenth National ConferenceArtificial Intelligence (in press), San Jose, California.301fiBayer-Zubek & DietterichMadigan, D., & Almond, R. (1996). test selection strategies belief networks.Fisher, D., & Lenz, H. (Eds.), Learning Data: AI Statistics, pp. 89{98.Morgan Kaufmann.Margineantu, D. D., & Dietterich, T. (2000). Bootstrap methods cost-sensitiveevaluation classifiers. Proceedings Seventeenth International ConferenceMachine Learning, pp. 583{590, San Francisco, CA. Morgan Kaufmann.Martelli, A., & Montanari, U. (1973). Additive AND/OR graphs. ProceedingsThird International Joint Conference Artificial Intelligence, pp. 1{11.Nilsson, N. (1980). Principles Artificial Intelligence. Tioga Publishing Co., Palo Alto,CA.Norton, S. W. (1989). Generating better decision trees. Proceedings EleventhInternational Joint Conference Artificial Intelligence, pp. 800{805, San Francisco.Morgan Kaufmann.Nunez, M. (1991). use background knowledge decision tree induction. MachineLearning, 6(3), 231{250.Pattipati, K. R., & Alexandridis, M. G. (1990). Application heuristic search information theory sequential fault diagnosis. IEEE Transactions Systems, ManCybernetics, 20(4), 872{887.Pazzani, M., Merz, C., Murphy, P., Ali, K., Hume, T., & Brunk, C. (1994). Reducingmisclassification costs. Proceedings Eleventh International ConferenceMachine Learning, pp. 217{225, New Brunswick, New Jersey. Morgan Kaufmann.Provost, F. J., & Fawcett, T. (2001). Robust classification imprecise environments.Machine Learning, 42 (3), 203{231.Puterman, M. L. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming. John Wiley & Sons, New York.Qi, R. (1994). Decision Graphs: Algorithms Applications uence Diagram Evaluation High-Level Path Planning Uncertainty. Ph.D. thesis, UniversityBritish Columbia.Quinlan, J. R. (1993). C4.5: Programs Machine Learning. Morgan Kaufmann, SanMateo, California.Raiffa, H. (1968). Decision Analysis. Adison-Wesley, Reading, MA.Sutton, R. S., & Barto, A. (1999). Reinforcement Learning: Introduction. MIT Press,Cambrdige, Massachusetts.Tan, M. (1993). Cost-sensitive learning classification knowledge applicationsrobotics. Machine Learning, 13(1), 1{33.Turney, P. (2000). Types cost inductive concept learning. Workshop CostSensitive Learning ICML2000, pp. 15{21, Stanford University, California.Turney, P. D. (1995). Cost-sensitive classification: Empirical evaluation hybrid geneticdecision tree induction algorithm. Journal Artificial Intelligence Research, 2, 369{409.302fiLearning Diagnostic Policies ExamplesUtgoff, P. E. (1989). Incremental induction decision trees. Machine Learning, 4, 161{186.van der Gaag, L., & Wessels, M. (1993). Selective evidence gathering diagnostic beliefnetworks. AISB Quarterly, 86, 23{34.Washington, R. (1997). BI-POMDP: Bounded, incremental partially-observable Markovmodel planning. Proceedings Fourth European Conference Planning.Zadrozny, B., & Elkan, C. (2001). Learning making decisions costs probabilities unknown. Proceedings Seventh International ConferenceKnowledge Discovery Data Mining, pp. 204{213. ACM Press.303fiJournal Artificial Intelligence Research 24 (2005) 109156Submitted 10/04; published 7/05Solving Set Constraint Satisfaction Problems using ROBDDsPeter HawkinsVitaly Lagoonhawkinsp@cs.mu.oz.aulagoon@cs.mu.oz.auDepartment Computer Science Software EngineeringUniversity Melbourne, VIC 3010, AustraliaPeter J. Stuckeypjs@cs.mu.oz.auNICTA Victoria Laboratory, Department Computer Science Software EngineeringUniversity Melbourne, VIC 3010, AustraliaAbstractpaper present new approach modeling finite set domain constraint problems using Reduced Ordered Binary Decision Diagrams (ROBDDs). showpossible construct efficient set domain propagator compactly represents manyset domains set constraints using ROBDDs. demonstrate ROBDD-basedapproach provides unprecedented flexibility modeling constraint satisfaction problems,leading performance improvements. also show ROBDD-based modelingapproach extended modeling integer multiset constraint problemsstraightforward manner. Since domain propagation always practical, also showincorporate less strict consistency notions ROBDD framework, setbounds, cardinality bounds lexicographic bounds consistency. Finally, present experimental results demonstrate ROBDD-based solver performs better variousconventional constraint solvers several standard set constraint problems.1. Introductionoften natural express constraint satisfaction problem (CSP) using finite domainvariables relations variables, values variable drawnfinite universe possible values. One common methods solving finitedomain CSPs maintaining updating domain variable usingcombination backtracking search incomplete local propagation algorithm.local propagation algorithm attempts enforce consistency values variabledomains removing values cannot form part solution system constraints.Various levels consistency defined, associated costs benefits.consistency algorithms incompletethat is, incapable solving problemthemselves, must combined backtracking search procedure producecomplete constraint solver.attempting apply general scheme task solving constraint satisfaction problems finite set variables quickly run practical problems. Sinceuniverse possible values set variable usually large, nave representationdomain set variable set sets unwieldy solve realistic problems.example, set variable take value subset set {1, . . . , N },domain contains 2N elements, quickly becomes infeasible represent N increasesc2005AI Access Foundation. rights reserved.fiHawkins, Lagoon, & Stuckeymagnitude. Accordingly, set constraint solvers date used approximationtrue domain set variable order avoid combinatorial explosion.common approximation true domain set variable vmaintain upper bound U lower bound L domain subset partialordering relation perform set bounds propagation bounds. is, Lcontains elements must set v, U complement set elementsmust v. Conventionally, fixed set inference rules specific constraintused enforce consistency upper lower bounds. basic schemeproposed Puget (1992), implemented set solvers Conjunto(Gervet, 1997), fd sets ic sets libraries ECLi PSe (IC-PARC, 2003), Mozart(Muller, 2001), ILOG Solver (ILOG, 2004).Set bounds crude approximation set domain best, thus various refinements bounds propagation scheme proposed effectivelycapture nature set domain. Azevedo (2002) demonstrated maintainingperforming inferences upon upper lower bounds cardinality set domainleads significant performance improvement variety problems. earlierset solvers Conjunto also maintained cardinality bounds, partial usagemade information. recently, Sadler Gervet (2004) showed incorporating upper lower bounds lexicographic ordering leads significantly strongerpropagation, albeit cost marked increase propagation time, leadingmarginal performance improvement overall. approaches provideeffective propagation simple set bounds scheme, approach effectiveness true set domain propagator, ensures every value domainset variable extended complete assignment every variable givenconstraint.Consequently, would like devise representation set domains constraintsdomains tractable enough permit domain propagation. principalobservation permits implementation set domain propagator finiteinteger set v represented characteristic function v :v : Z {0, 1} v (i) = 1 iff vAccordingly use set Boolean variables vi represent set v, correspondpropositions vi v. describe set domains set constraints termsBoolean variables. Interestingly, set bounds propagation describedequivalent performing domain propagation nave way Boolean representation.paper investigate Boolean modeling approach modeling finite domainconstraints, particular set constraints. show possible representdomains set variables using Reduced Ordered Binary Decision Diagrams (ROBDDs),data structure representing manipulating Boolean formul. representationsusually fairly compact, even correspond large domains. addition,possible represent constraints ROBDDs, permitting us produceefficient set domain constraint propagators solely using ROBDD operations.ROBDD-based representation allows us easily conjoin constraints existentially quantify variables, thus permitting us remove intermediate variables mergeconstraints stronger propagation. construction global constraints becomes110fiSolving Set Constraint Satisfaction Problems using ROBDDsalmost trivial exercise, without requirement write laboriously new propagatorsevery new constraint would like use.also demonstrate minor changes needed operation setdomain propagator order implement other, less strict notions consistency. particular, show construct set bounds, cardinality bounds lexicographic boundspropagators, utilize notions produce split domain solver combinesbounds domain reasoning.key theme paper flexibility ROBDD-based modeling approach.limited modeling set variablesfor example ROBDDs usedmodel integer variables integer constraints. ROBDD-based approachmodeling finite domain integer variables general efficient many existingfinite domain integer solvers, ability model integer constraints using ROBDDsessential building block allows us construct set constraints cardinalityweighted sum, well allowing us represent multisets multiset constraints.Finally, present experiments using variety standard set problems demonstrateadvantages modeling approach.Many ideas paper previously published two previous works(Lagoon & Stuckey, 2004; Hawkins, Lagoon, & Stuckey, 2004). paper containscomplete exposition ideas, well important extensions workpreviously presented. include substantial improvements complexitypropagation algorithm, well cardinality lexicographic bounds solvers implementedusing ROBDDs. addition, show model integer expressions, allowing usimplement weighted-sum constraint, model multisets multiset constraints.Using this, present new experimental results Hamming Code BalancedAcademic Curriculum problems. Finally, present results comparing ROBDD-basedsolver solver good cardinality reasoning (Mozart).remainder paper structured follows. Section 2 contains essential conceptsdefinitions necessary discussing finite domain solvers ROBDDs. Section 3shows model set domains set constraints using ROBDDs, presents basicoutline ROBDD-based set constraint solver. Section 4 demonstrates improveperformance ROBDD-based set solver construction global constraints, removal intermediate variables, symmetry-breaking approaches.Section 5 demonstrates model integer multiset expressions, wellimplement weighted-sum constraint set multiset variables. Section 6 showsconstruct efficient domain propagator, well set bounds, set cardinality,lexicographic bounds propagators. Finally, Section 7 present experimental resultscomparing ROBDD-based solver conventional set solvers varietystandard problems.2. Preliminariessection define concepts notation necessary discussing propagationbased constraint solvers. definitions largely identical presented LagoonStuckey (2004) others. simplicity shall present definitionscase finite set variables; extensions multiset integer variables trivial.111fiHawkins, Lagoon, & Stuckey2.1 Lattices, Domains, ValuationsLet L powerset lattice hP(U), i, P(x) denotes powerset xuniverse U finite subset Z. say subset L convex a, crelation b c implies b b L. interval [a, b] set = {xL | x b}. Intervals obviously convex. Given subset K L, define convexclosure K:"#\[conv (K) =x,xxKxKconvex closure operation satisfies properties extension (x conv (x)), idempotence (conv (x) = conv (conv (x))), monotonicity (if x conv (x) (y)) (Gervet,1997).Example 2.1. set X = {{1}, {1, 3}, {1, 4}, {1, 3, 4}} convex equivalent interval [{1}, {1, 3, 4}]. Conversely, set = {{1}, {1, 3}, {1, 3, 4}} convex. However,convex closure precisely interval X, i.e. conv (Y ) = X.Let V denote fixed finite collection set variables. variable domain,finite collection possible values L (which sets).generally, define domain complete mapping set V finite collectionsfinite sets integers. speak domain variable v, mean D(v).domain D1 said stronger domain D2 , written D1 v D2 , D1 (v) D2 (v)v V. Two domains said equal, written D1 = D2 , D1 (v) = D2 (v)v V. call domain range domain D(v) interval v V.extend concept convex closure domains defining ran(D) unique(range) domain ran(D)(v) = conv (D(v)) v V.valuation function V L, write using mapping notation{v1 7 d1 , v2 7 d2 , . . . , vn 7 dn }, vi V di L N. Clearly valuationextended constraints involving variables obvious way. define varsfunction returns set variables involved constraint, expressionvaluation. abuse notation, valuation said element domainD, written D, (v) D(v) v vars().say domain singleton valuation domain |D(v)| = 1 v V.case corresponds single valuation D(v) = {(v)} v V.2.2 Constraints, Propagators, Propagation Solversconstraint restriction placed upon allowable values collection variables.interested following primitive set constraints, k integer,ground set value, u, v w set variables: k v (membership), k/ v (nonmembership), u = v (equality), u = (constant equality), u v (non-strict subset),u = v w (union), u = v w (intersection), u = v \ w (set difference), u = v (complement),u 6= v (disequality), |u| = k (cardinality), |u| k (lower cardinality bound), |u| k(upper cardinality bound). Later shall introduce non-primitive set constraintsformed composing primitive set constraints.define solutions constraint c set valuations makeconstraint true, i.e. solns(c) = { | vars() = vars(c) (c)}.112fiSolving Set Constraint Satisfaction Problems using ROBDDsExample 2.2. Suppose v w set variables, domain D(v) ={{1}, {1, 3}, {2, 3}}, D(w) = {{2}, {1, 2}, {1, 3}}. Let c constraint v w.solutions c domain valuations {v 7 {1}, w 7 {1, 2}},{v 7 {1}, w 7 {1, 3}}, {v 7 {1, 3}, w 7 {1, 3}}.every constraint associate propagator f , monotonic decreasingfunction domains domains, D1 v D2 f (D1 ) v f (D2 ) f (D1 ) v D1 .propagator f said correct constraint c if:{ | D} solns(c) = { | f (D)} solns(c)Correctness strong restriction, since identity propagator correct constraints c. usually assume propagators correct checking, is,singleton domain formed propagation associated valuation makes(c) true.use propagators form basis constraint solver. propagation solversolv (F, D) takes set propagators F current domain D, repeatedly appliespropagators F current domain fixpoint reached. wordssolv (F, D) weakest domain 0 v fixpoint (i.e. f (D 0 ) = D0 )f F . fixpoint unique (Apt, 1999).2.3 Local Consistencynotion local consistency importance considering solution constraintsatisfaction problems. define various levels consistency different strengthslevels difficulty enforce. describe two here.domain said domain consistent constraint c strongestdomain contains solutions c; words existdomain 0 v solns(c) implies 0 . set propagatorsmaintains domain consistency solv (F, D) domain consistent constraints c.Definition 1. domain propagator constraint c function dom(c) mapping domains domains satisfies following identity:({(v) | solns(c)} v vars(c)dom(c)(D)(v) =D(v)otherwiseLemma 2.1. domain propagator dom(c) constraint c correct, checking, monotonic, idempotent.Proof. Straightforward definitions.Example 2.3. Consider constraint v w domain Example 2.2. domainpropagation 0 = dom(c)(D) returns domain 0 0 (v) = {{1}, {1, 3}} 0 (w) ={{1, 2}, {1, 3}}. missing values take part solution.Domain consistency may difficult achieve set constraints, instead oftenneed weaker notion consistency. notion set bounds consistency commonly113fiHawkins, Lagoon, & Stuckeyused. domain bounds consistent constraint c every variable v vars(c)upper bound D(v) union values v solutions c D,lower bound D(v) intersection values v solutions c D.above, set propagators F said maintain set bounds consistency constraint csolv (F, D) bounds consistent domains D.Definition 2. set bounds propagator constraint c function sb(c) mappingdomains domains satisfying following identity:(conv (dom(c)(ran(D))(v)) v vars(c)sb(c)(D)(v) =D(v)otherwiseLemma 2.2. set bounds propagator sb(c) constraint c correct, checking,idempotent. propagator sb(c) also monotonic range domains.Proof. follow trivially properties dom(c) extensionidempotence properties conv ran.Clearly constraint c v vars(c) dom(c)(D)(v) sb(c)(D)(v)domain propagators dom(c) set bounds propagators sb(c).2.4 Boolean Formul Binary Decision Diagramsuse Boolean formul extensively model sets set relations. particular, makeuse following Boolean operations: (conjunction), (disjunction), (negation),(implication), (bi-directional implication), (exclusive OR), (existential quantification). use shorthand V F x1 xn F V = {x1 , . . . , xn }, useV F mean V 0 F V 0 = vars(F ) \ V .Binary Decision Trees (BDTs) well-known method modeling Boolean functionsBoolean variables. Binary Decision Tree complete binary tree,internal node n(v, t, f ) labelled Boolean variable v leaf node labelledtruth value 0 (false) 1 (true). internal node corresponds if-then-elsetest labelled variable, two outgoing arcsthe false arc (to BDT f )true arc (to BDT t). order evaluate function represented binary tree,tree traversed root leaf. reaching internal node, valueBoolean variable whose label appears node examined, correspondingarc followed. traversal stops upon reaching leaf node, whereupon valuefunction taken label node.Binary Decision Diagram (BDD) variant Binary Decision Tree, formedrelaxing tree structure requirement, instead representing functions directed acyclicgraphs. Binary Decision Diagram, node permitted multiple parents,opposed tree structure requires node one parent.effectively permits common portions tree shared multiple branches,allowing compact representation many functions.primary disadvantage Binary Decision Trees Binary Decision Diagramsrepresentation given function canonical (i.e. one function maymany representations). Two additional canonicity properties allow many operations114fiSolving Set Constraint Satisfaction Problems using ROBDDs012376540123765401237654v Ev RRRv RRREERRRRRR)lul"01230123765401237654l(0123v FFv FF0123765476547654v Evv Ev|"|"EEE"E"01237654012376540123765401237654|||vvvv FFFFFFFF0123765401237654012376540123765401237654vvvvv"0123"""EEE2E765401237654012376540123765422E" y|vvvv' E" y|y|22012376540123765401237654||||vvvDD01237654012376540123765401237654/( EEE2vvvvz"< 5 DDDD z z/||||01237654v0123765401237654012376540123765456h0vvvvRFFFFFFFF:b eiDDzz DD"""""! }z# rt|z01237654012376540123765401237654vvvv FFFFF011F"F"F""012376547654012376547654v FF 0123vv FF 0123v"0123|"|765401237654v RRRvRRl lw3124518228838234699767345563455667877889(b)89R((a)41vl(c)Figure 1: ROBDDs (a) LU = v3 v4 v5 v6 v7 (b) R = (v1 v9 ) (v2 v8 )(c) LU R (omitting node 0 arcs it). Solid arcs arcs,dashed arcs else arcs.BDDs performed efficiently (Bryant, 1986, 1992). BDD said reducedcontains identical nodes (that is, nodes label identicalelse arcs), redundant tests (there nodeselse arcs node). BDD said ordered total ordervariables, arc node labelled v1 node labelled v2v1 v2 . Reduced Ordered BDD (ROBDD) canonical function representationreordering, permits efficient implementation many Boolean function operations.details reader referred work Bryant (1992), introductionAndersen (1998).define size |R| number non-leaf nodes ROBDD R, welldefining VAR(R) set ROBDD variables appear labels internalnodes R. shall interested stick ROBDDs, every internal node n(v, t, f )exactly one f constant 0 node.Example 2.4. Figure 1(a) gives example stick ROBDD LU representing formulav3 v4 v5 v6 v7 . |LU | = 5 V AR(LU ) = {v3 , v4 , v5 , v6 , v7 }. Figure 1(b) givesexample complex ROBDD representing formula (v1 v9 ) (v2 v8 ).|R| = 9 V AR(R) = {v1 , v2 , v8 , v9 }. One verify valuation {v1 7 1, v2 70, v8 7 1, v9 7 0} makes formula true following path right, left, right, leftroot.2.5 ROBDD Operationsefficient algorithms many Boolean operations applied ROBDDs.complexity basic operations constructing new ROBDDs O(|R 1 ||R2 |) R1 R2 ,115fiHawkins, Lagoon, & Stuckeynode(v, t, f ) (t = f ) return else return n(v, t, f )and(R1 , R2 )(R1 = 0 R2 = 0) return 0(R1 = 1) return R2(R2 = 1) return R1n(v1 , t1 , f1 ) := R1n(v2 , t2 , f2 ) := R2(v1 v2 ) return node(v1 ,and(t1 , R2 ),and(f1 , R2 ))else (v2 v1 ) return node(v2 ,and(t2 , R1 ),and(f2 , R1 ))else return node(v1 ,and(t1 , t2 ),and(f1 , f2 ))exists(v, R)(R = 0) return 0(R = 1) return 1n(vr , t, f ) := R(vr v) return node(vr ,exists(v, t),exists(v, f ))else (v vr ) return Relse return or(t, f )Figure 2: Example ROBDD operationsR1 R2 R1 R2 , O(|R|) R, O(|R|2 ) v R. Note however testwhether two ROBDDs identical, whether R1 R2 equivalent true (1), O(1).give code conjunction R1 R2 = and(R1 , R2 ) existential quantification (ofone variable) v R = exists(v, R). code disjunction R1 R2 = or(R1 , R2 ) dualsimilar structure. code make use auxiliary function nodebuilds new ROBDD node. node function returns = f , practicememoed call node arguments previous call returns referencepreviously created ROBDD node.Modern BDD packages provide many operations, including specialized implementations operations improved speed. important operations purposesexistential quantification multiple variables V formula R V R, combination conjunction existential quantification V R1 R2 .Although theory number nodes ROBDDs exponentialnumber variables represented Boolean function, practice ROBDDs oftencompact computationally efficient. due fact ROBDDs exploithigh-degree symmetry models Boolean formula.3. Modeling Set CSPs Using ROBDDssection discuss solve set constraint satisfaction problems using ROBDDs.three parts thisthe modeling set domains ROBDDs, modelingset constraints ROBDDs, use produce set solver.116fiSolving Set Constraint Satisfaction Problems using ROBDDsz}01237654vDD01237654v PPPPzz101237654PPPP'v2DD!v3 @"~ @@@+17 <H @U -2012376540(a)01237654x EEE10123765401237654{ 1 CCCC{C!}{s2 CC{{ 2 CCCCCC{{CC!! }{}{s3 Cs3 C{ CCC{ CCC{ 3{{{CC! }{}{! }{s4 Cs4s4 CCC{{CCCCCC{{! }{! }{s5 CCC{ 5C! }{(171LW U^ \` /0 pqt001237654EE"xz 2z|zx3 E( EEEE"1xz 4AAA:zL . q|z010123765401237654(b)012376540123765401237654012376540123765401237654012376540123765401237654(c)Figure 3: ROBDDs (a) {{1}, {1, 3}, {2, 3}}, (b) [{1, 3, 4, 5}, {1, 3, 4, 5, 6, . . . N }] (c){s {1, 2, 3, 4, 5} | |s| = 2}.3.1 Modeling Set Domains using ROBDDsSuppose universe U = {1, . . . , N }. assume set values subsets U.Let x set variable, let domain V. Given size universe bounded, associate Boolean variable xi potential element{1, . . . , N } x. Hence set variable x represented vector Boolean variables V (x) = hx1 , . . . , xN i.Take set D(x). represent valuation variableshx1 , . . . , xN defined = {x1 7 (1 A), . . . , xn 7 (n A)}. representvaluation consequently set Boolean formula B(A)valuation unique solution:(^xiB(A) =yi yi =xi otherwiseiUGiven represent element D(x) valuation, representD(x) Boolean formula B(D(x)) whose solutions correspond elementsD(x). is, B(D(x)) disjunction B(A) possible sets D(x):_B(D(x)) =B(A) B(A) definedAD(x)solution (x) D(x) corresponds satisfying assignment Booleanformula B(D(x)). overload notion domain equivalentlyreturn set possible sets D(x) variable x, equivalent Boolean representationB(D(x)).Example 3.1. Let U = {1, 2, 3}. Suppose v set variable D(v) = {{1}, {1, 3}, {2, 3}}.associate Boolean variables {v1 , v2 , v3 } v. represent D(v)117fiHawkins, Lagoon, & StuckeyBoolean formula (v1 v2 v3 ) (v1 v2 v3 ) (v1 v2 v3 ). three solutionsformula correspond elements D(v). corresponding ROBDD B(D(v))shown Figure 3(a).representation useful since Boolean formul directly representedreasonably compact ROBDDs. Given Boolean formula representing domain,clearly construct corresponding ROBDD bottom-up fashion, practiceever construct ROBDD domain implicitly constraint propagation.show, ROBDDs permit surprisingly compact representation (many) subsetsP(U).Since ROBDDs ordered, must specify variable ordering Boolean variablesuse. arbitrarily order ROBDD variables single set variable xfollows: x1 x2 . . . xn . Assuming special relationshipelements universe, choice ordering ROBDD variables representparticular set variable unimportant. However, relative ordering ROBDD variablescomprising different set variables drastic effect size ROBDDs representingconstraints, discussed Section 3.2.Example 3.2. ROBDD representing 2N 5 sets interval [{1, 3, 4, 5}, {1, 3, 4, 5, 6, . . . N }]shown Figure 3(b).ROBDD representation flexible enough able represent compactly widevariety domains, even might first seem difficult represent. example,set subsets {1, 2, 3, 4, 5} cardinality 2 represented ROBDDshown Figure 3(c).convenience, set initial variable domains Dinit (x) = P(U),corresponds constant 1 ROBDD. Restrictions initial bounds domaininstead expressed unary constraints.3.2 Modeling Primitive Set Constraints Using ROBDDsmajor benefit using ROBDDs model set constraint problems ROBDDsused model constraints themselves, set domains. set constraintc converted Boolean formula B(c) Boolean variables comprising setvariables vars(c), B(c) satisfied corresponding set variablevaluations satisfy c. usual, represent B(c) ROBDD.Example 3.3. Let v w set variables universe U = {1, 2, 3}, let cdenote constraint v w. Assume Boolean variables associated vw hv1 , v2 , v3 hw1 , w2 , w3 respectively. c represented Booleanformula (v1 w1 ) (v2 w2 ) (v3 w3 ). formula turn representedeither ROBDDs shown Figure 4 (depending variable order).Example 3.4 demonstrates order variables within ROBDDsgreat effect size formula representations.Example 3.4. Consider constraint v w described Example 3.3. Figure 4shows effect two different variable orderings size resulting BDD.118fiSolving Set Constraint Satisfaction Problems using ROBDDs01237654vzzz} 0123012376547654vv2301237654v1 FFFFF"y|3#$);/7?G101237654v FFF"0123765401237654vv FxFxF"|x01237654012376540123765401237654wwww1-01237654v EEE%+2331110123765401237654ww}+ 01237654wx!2'xx% |xs x123(a) Order: v1 v2 v3 w1 w2 w301237654EEEE"5101237654EEQ Z ` E0 " v2 EE% EEE"+!w2 E5EEE'EQ Z ` E0 " v3 EEEEE"4w32 l n;b f h j R - }0p1012376540123765401237654(b) Order: v1 w1 v2 w2 v3 w3(Arcs 0 shown clarity)Figure 4: Two ROBDDs v wcase, variable ordering v1 w1 v2 w2 gives much compact representationconstraint ordering v1 v2 w1 w2 . seen figure,latter ordering size exponential n, whereas former size linear n.variable set V = {v1 , . . . , vm } corresponding Boolean variables hv1,1 , v1,2 , . . . , v1,N i,hv2,1 , v2,2 , . . . , v2,N i, . . . , hvm,1 , vm,2 , . . . , vm,N i, choose order Boolean variablesv1,1 vm,1 v1,2 vm,2 v1,N vm,N . ordering guarantees linear representation primitive set constraints except cardinality.reason primitive set constraints except cardinality defined elementwise,element v never constrains whether j w j/ w 6= j. reasoninteractions bits vi wj , 6= j. Placing bitselement adjacent order means interactions bits vi wi capturedsmall ROBDD, effectively separate ROBDD describing interactionsnext elements bits. Table 1 contains list primitive set constraints,corresponding Boolean formul sizes ROBDDs representing formulpoint-wise ordering.Cardinality constraints represented quadratic number ROBDD nodesusing simple recursive definition. define card (hvi1 , . . . , vin , l, u) Booleanformula restricts number true bits vector hvi1 , . . . , vin l119fiHawkins, Lagoon, & StuckeycBoolean expression B(c)kvvkk 6 vvVVku 1iN,i6d uiu=dVidu=v(u vi )V1iNuv(u vi )V1iNu=vw(u (vi wi ))V1iN(u (vi wi ))u=vwV1iN(u (vi wi ))u=vwV1iN(ui vi )u=vW1iNu 6= v1iN (ui vi )|u| = kcard (V (u), k, k))|u| kcard (V (u), k, N )card (V (u), 0, k)|u| ksize ROBDDO(1)O(1)O(N )O(N )O(N )O(N )O(N )O(N )O(N )O(N )O(k(N k))O(k(N k))O(k(N k))Table 1: Boolean representation set constraints size correspondingROBDD.u inclusive.10card (hvi1 , . . . , vin , l, u) =(vi1 card (hvi2 , . . . , vin , l, u))(v card (hv , . . . , v , l 1, u 1)i1i2l 0 n un < l u < 0otherwiseclear structure card (hvi1 , . . . , vin , l, u) resulting ROBDD O(n2 )size. general method characterising cardinality constraints presentedSection 5.5.3.3 Basic Set Constraint Solvershow construct simple set domain propagator dom(c) constraint c.vars(c) = {v1 , . . . , vn }, define function dom(c) mapping domains domainsfollows:(VV (vi ) B(c) ni=1 D(vi ) vi vars(c)dom(c)(D)(vi ) =D(vi )otherwisewords, perform propagation take conjunction Boolean representations current domains variables vars(c) Boolean representationconstraint B(c) project result onto Boolean variables V (v ) representingvariable vi . Since B(c) D(vi ) ROBDDs, formula implementeddirectly using ROBDD operations.120fiSolving Set Constraint Satisfaction Problems using ROBDDs01237654wx 1FFFFxF"|xw2 WWWWWwxWWWxWW 2FFFF|x WWWWWF+ "%ww3 FFFx 31FxF" |x= HHL 1G"W - p012376540123765401237654001237654v FFF10123765401237654EEFF"1|y01237654EE01237654 01237654101237654- D!v2B{ @@@@}{U Z .1001237654EE"v2201237654v' DD01237654EE"v301237654w FFF1~01237654FF"w2 FFFFxF"|x xw3 Fw$x 3| FFF2xF" |x~|0c10123765401237654|yw3 w36vvvv III 6II 6vvvvII 6I${vvvpn01(a)(b)(c)(d)Figure 5: ROBDDs used domain propagation c v w (a) D(w), (b) B(c)D(v) D(w), (c) 0 (v), (d) 0 (w)Example 3.5. Consider domain propagation constraint v w initial domainD(v) = {{1}, {1, 3}, {2, 3}}, D(w) = {{2}, {1, 2}, {1, 3}} Examples 2.2 2.3.conjoin ROBDD B(c) shown Figure 4(b) domain ROBDD D(v) shownFigure 3(a) ROBDD D(w) shown Figure 5(a). result ROBDDrepresenting solutions formula v w v D(v) w D(w) shown Figure 5(b).project resulting onto V (v) V (w), individually obtaining ROBDDs 0 (v) ={{1}, {1, 3}} 0 (w) = {{1, 2}, {1, 3}} shown Figure 5(c) (d) respectively.need verify correctness propagator:Lemma 3.1. Let V collection set variables, let c set constraintvars(c) = {v1 , . . . , vk } V. dom(c) domain propagator c.Proof. need verify dom(c) satisfies identity Definition 1. Suppose domainV. need Vcheck foreach v vars(c) {char ((v)) | solns(c)} =u | u V (vi ) B(c) ni=1 D(vi ) , char (X) denotes characteristic vector X.clearly true, since values solns(c) definition satisfying assignmentsB(c), values definition satisfying assignments ni=1 D(vi ).Hence equality holds, implying dom(c) domain propagator.F set domain propagators, define complete propagation algorithm solv (F, D): simplicity use set constraints C rathercorresponding propagators.solv(C, D)121fiHawkins, Lagoon, & StuckeyQ := C( c Q)D0 := dom(c)(D)(| vars(c)| = 1) C := C {c}V := {v V | D(v) 6= 0 (v)}Q := (Q {c0 C | vars(c0 ) V 6= }) {c}:= D0returnmaintain queue Q constraints (re-)propagated, initially C. selectconstraint c queue propagate, calculating new domain 0 . constraintunary remove C, never considered again, since information captureddomain. determine variables V changed domain, addqueue constraints c0 C involving variables, exception currentconstraint c.combining algorithm modeling techniques described earlier,shown construct simple ROBDD-based set domain propagator. Various improvements basic scheme discussed Section 4 Section 6.reader may wonder whether section done anything map setconstraints Boolean constraints apply Boolean ROBDD solver them.case. Crucially domain propagation original set variables,Boolean variables make up. fact set bounds consistency approach (Puget,1992; Gervet, 1997) considered simply mapping set constraints Booleanconstraints.4. Effective Modeling Set Constraints Using ROBDDssection demonstrate ROBDD-based modeling approach flexible,allowing us produce highly efficient implementations many complex constraints.4.1 Combining Constraints Removing Intermediate Variablesrarely possible express constraints real set problem directly primitiveset constraints variables original problem. Instead, would usually likeexpress complicated set constraints, decomposed multiple primitiveset constraints, often requiring introduction intermediate variables.Example 4.1. Let c constraint |v w| k, requires v wk elements common. constraint used modeling problem findingSteiner systems (see Section 7.1). Since primitive set constraint, existingset solvers would usually implicitly decompose two primitive set constraintsintroduce intermediate variable u. representation constraint becomesu u = v w |u| k.case Example 4.1 decomposition affect strength resultingpropagator. prove fact, use two results presented Choi, Lee, Stuckey122fiSolving Set Constraint Satisfaction Problems using ROBDDs(2003). Choi, Lee, Stuckey prove results case finite integer domainsolver, although proofs set domain case identical. 1Lemma 4.1 (Choi et al., 2003). Let c1 c2 set constraints. solv ({dom(c1c2 )}, D) v solv ({dom(c1 ), dom(c2 )}, D) domains D.Lemma 4.2 (Choi et al., 2003). Let c1 c2 two set constraints sharingone variable x V. solv ({dom(c1 ), dom(c2 )}, D) = solv ({dom(c1 c2 )}, D)domains D.Even strength propagator unaffected decomposition, splittingpropagator introduces new variable, thus slowing propagation process. casestwo set constraints share one variable Lemma 4.2 apply,case also loss propagation strength.ROBDD representation constraints allows us utilise complex constraints directly, thus avoiding problems associated splitting constraint.directly construct ROBDD complex constraints forming conjunctioncorresponding primitive constraints existentially quantifying away intermediatevariables.Example 4.2. Consider constraint c |v w| k discussed Example 4.1.build domain propagator dom(c) directly c constructing ROBDDV (u) u = v w |u| k. case size resulting ROBDD O(kN ).ROBDD |v w| 2, V (u) B(u = v w) B(|u| 2), U ={1, 2, 3, 4, 5} shown Figure 6(a). ROBDD |u| 2 shown Figure 6(b)comparison. Note ui node Figure 6(b) replaced vi wi (the formulaui ) Figure 6(a).4.2 Modeling Global Constraintsprevious section demonstrates, possible join ROBDDs representing primitive set constraints single ROBDD representing conjunction constraints.use join large numbers primitive constraints form global constraints,many cases improve performance due stronger propagation.one strengths ROBDD-based modeling approach trivialconstruct global constraints simply using ROBDD operations primitive set constraints,without laboriously writing code perform propagation global constraint.approach powerful, feasible combinations primitive constraints.shall see, global constraints might desire construct lead ROBDDsexponentially large.useful global constraint constraint partition(v1 , . . . , vn ), requiressets v1 , v2 , . . . , vn form partition universe U = {1, . . . , N }. easily1. observation Choi et al. Lemma 4.2 apply shared variable set variabletrue performing set bounds propagation, set domain propagation.123fiHawkins, Lagoon, & Stuckey01237654v1 EEEEE"w1 EhEEEh h h hE"y| sh hv2 EEv2 EEEEEEE"E"h w2EEh w2EEhhEEEEEEh hh hy| sh h h"" y| sh h hv3, EEv3 EEv3 EEEEEEEEE, EE"""w, w'3Eh w3h 3EEhhEEEhhE,hhEE" y| sh h h, ' E" v y| sh h hv'44EEEE,EEEE", 'EE"w4 E, 'h w4EEEE, 'h h h h" y| sh h, 'v5 EE,'EEE,'"w',h h 5DDD,' h h h hDD"|ysh h012376540123765401237654012376540123765401237654012376540123765401237654012376540123765401237654012376540123765401237654u1 EEEEE"y|u2 Eu2 EEEEEEEE"Ey|" y|u3, Euu3 EEEE3EEEE" y|, E" y|u, u 4 EE4, EEE" y|,u5, z z DDDD|z"01237654012376540123765401237654012376540123765401237654012376541012376540012376540123765410(a)(b)Figure 6: ROBDDs (a) |v w| 2 v, w {1, 2, 3, 4, 5}, (b) |s| 2{1, 2, 3, 4, 5}.construct constraint primitive set constraints follows:partition(v1 , . . . , vn ) =n1^n^uij (uij = vi vj uij = )i=1 j=i+1w0 wn (w0 = (n^wi = wi1 vi ) wn = U)i=1propagator dom(partition( )) stronger domain propagatordecomposition. example, consider constraint c partition(x, y, z) depictedFigure 7, domain D(x) = D(y) = {{1}, {2}} D(z) = {{2}, {3}}.Domain propagation using decomposition constraint alter D, domainpropagation using global constraint give dom(c)(D)(z) = {{3}}. Hence strongerpropagation gained global propagation using constraint.Unfortunately global constraints modelled efficiently using approach.particular, risk ROBDD representation global constraint couldextremely large, making infeasible construct use propagation.example, consider constraint atmost(hv1 , . . . , vn , k) proposed SadlerGervet (2001), requires sets v1 , . . . , vn cardinality kintersection pair sets 1 element size. constraint models124fiSolving Set Constraint Satisfaction Problems using ROBDDs01237654xz 1 DDDDzD!z}y1y1 QQQQQQwQG&QQ(z1 DDzz 1DDDz" |zx2DDzDDzz}!y2 QQQy2wQQQQQQG&(zz2 DD2zDDDz" |zx3DDDzzD!z}y3y1 QQQQQQwQQQG&(zz3 DD3zDDD! }z z012376540123765401237654012376540123765401237654012376540123765401237654xz 1 DDDDzD!z}y1y1DDzz 9 3z! z} zx2(DDDzzz}!!y2y2z.DDzz! z} z)x3$z -z} z-y3 HH-HH --H -H#,10v01237654 G01237654 x w012376540123765401237654 G01237654 x w0123765401237654 G01237654 x w012376540123765401237654012376541partition(x, y, z)lexlt(x, y)(Arcs 0 omitted clarity)Figure 7: ROBDDs constraints partition(x, y, z) lexlt(x, y), x, zset variables taking values universe U = {1, 2, 3}.Steiner triple systems Section 7.1. Bessiere, Hebrard, Hnich, Walsh (2004) provedenforcing bounds consistency constraint NP-hard, follows enforcingdomain consistency constraint least NP-hard well. Theoretically stillconstruct ROBDD representing constraint primitive constraints follows:n^i=1|vi | = nn1^n^uij (uij = vi vj |uij | 1)i=1 j=i+1Unfortunately, resulting ROBDD turns exponential size, making impractical use global propagator. surprising light NP-hardnessproblem generalin fact would surprising resulting ROBDDexponential size!4.3 Avoiding Symmetry Ordering Constraintsimportant modeling constraint satisfaction problem minimize symmetriesmodel problem. model contains symmetrical solutions often greatlyenlarged search space, leading large amounts time spent searching sectionssearch tree identical symmetric rearrangement. therefore highlydesirable remove whatever symmetries exist problem.125fiHawkins, Lagoon, & StuckeyOne approach symmetry-breaking introduction additional ordering constraints variables problem. convenient ordering use setslexicographic order characteristic bit vectors sets. words, v wset variables, v < w lexicographic ordering list bits V (v)lexicographically smaller V (w). model lexicographic ordering constraintlexlt(v, w, 1), defined recursively following manner:(0n > Nlexlt(v, w, n) =(vn wn ) ((vn wn ) lexlt(v, w, n + 1) otherwiseexample ROBDD depicted Figure 7.shall make use lexicographic ordering constraint extensively experimentsSection 7.5. Modeling Integers, Multisets, Weighted Sum Constraintssection show model integer variables integer constraints using ROBDDs. general representations large, limits usefulnessROBDDs basis general purpose finite-domain constraint solver. Despite this,ability represent integers extremely useful component set solver.propose two major uses integer representation.Firstly, use integer representation model values weighted sumelements set. Constraints weighted sum elements setshown useful practical applications (Mailharro, 1998).Secondly, model finite multisets using ROBDDs replacing individualROBDD variables set representation bundles ROBDD variables, bundle corresponding binary integer. Multiset operations constructedcomposing integer operations variable bundles.addition, integer representation described could used interface ROBDD-based set solver conventional integer finite-domainsolver. interface could easily implemented using channeling constraintsROBDD integer finite-domain versions variable.5.1 Representing Integer Values using ROBDDsorder model integers integer operations must choose appropriate representation terms Boolean formul. general free use encoding integerbinary sequence, unary, unsigned binary twos-complement encodings,simplicity choose represent integers unsigned binary form.represent arbitrary integer expression e list Boolean formul.formula list corresponds single bit unsigned binary value expression.denote list hen1 , en2 , . . . , e1 , e0 i, ei Boolean formula,order significant bit least significant bit. interpret formula1 bit formula logically true, 0 bit otherwise; simplicitycall formul bits expression. also use expression elist constituent bits interchangeably. usual, represent Boolean formul126fiSolving Set Constraint Satisfaction Problems using ROBDDsROBDDs. shall see, notation flexible enough represent arbitrary integerexpressions.Example 5.1. Consider integer constant k = 25, 11001 unsigned binary.represent k list h1, 1, 0, 0, 1i.order represent integer variable x, associate x fixed set Booleanvariables {xk1 , . . . , x0 }. value x taken value unsigned binaryinteger hxk1 , . . . , x0 i. varying value xi variables, value x range0 2k 1 inclusive. always ordering Boolean variables significanteffect sizes ROBDD representations formul. x = hx k1 , . . . , x0 i, =hyk1 , . . . , y0 i, z = hzk1 , . . . , z0 i, choose order corresponding ROBDDvariables interleaved most-significant-bit-first order, i.e. xk1 yk1 zk1 xk2x 0 y0 z0 .Since permit arbitrary Boolean formul bits expression, alsomodel arbitrary integer expressions. example, suppose x integer variablesbits hx2 , x1 , x0 hy2 , y1 , y0 respectively. Then, example, represent expression xy (where denotes bitwise operator) list hx 2 y2 , x1 y1 , x0 y0 i.limited logical operations, shall see next section.5.2 Representing Integer Operations using ROBDDsalso use ROBDDs model arithmetic operations addition, analogydesign corresponding logic circuits. purpose set multisetsolvers, require implementations operations addition, left shift, minimum,maximum, multiplication constant, multiplication single variable bit.require general implementation multiplication using ROBDDs.convenient assume integer expressions number bits.may assume without loss generality since freely pad left shorterpair expressions 0 bits.model addition, simulate operation full binary adder. Suppose xinteger expressions, bit representations hxl1 , . . . , x0 hyl1 , . . . , y0 i.use ROBDDs compute output bits plus(x, y) operation x + follows (hereci denotes carry bit si denotes sum bit):c1 = 0si = xi yi ci10i<lci = (ci1 xi yi ) (ci1 (xi yi ))0i<lplus(x, y) = hcl1 , sl1 , . . . , s1 , s0Note avoid overflow extending size result one bit.Example 5.2. Suppose x integer variable, bits hx1 , x0 i. representexpression x+3 bits h(x0 x1 ) x0 ), x1 1 x0 , x0 1i = hx0 x1 , x0 x1 , x0 i.left shift operation trivial implement. x integer expression representedhxl1 , . . . , x0 k non-negative integer, represent left shift x127fiHawkins, Lagoon, & Stuckeye301237654x76540123x}1001(x0 x1 )01237654x1e2e101237654x G& zzz|zz001ww01237654x101237654x RRRRwG'00(x0 x1 )ze001237654l x0 GRlRlRlllRR( w wlv}01237654x0011(x0 x1 )(x0 )Figure 8: ROBDDs representing bits he3 , e2 , e1 , e0 expression e =mul (hx1 , x0 , 3), together simplified Boolean expressions ei .k bits shl (x, k) following formula:shl (hxl1 , . . . , x0 , k) = hxl1 , . . . , x0 , 0, . . . , 0i| {z }k bitsimplement operation multiplication constant using plus shloperators. x integer expression bits hxl1 , . . . , x0 k non-negativeinteger, x k corresponds mul (x, k) following formula:k = 0hik(1)mul (x, k) = mul (shl (x, 1), 2 )k even k > 0kplus(x, mul (shl (x, 1), b 2 c)) k odd k > 0Example 5.3. Let x = hx1 , x0 i, consider expression e = mul (x, 3). applyingEquation (1), obtain e = hx1 (x1 x0 ), x1 (x0 x1 ), x0 x1 , x0 simplified hx0 x1 , x0 x1 , x0 x1 , x0 i. corresponding ROBDD representationsshown Figure 8.5.3 Integer Constraints using ROBDDsalso express constraints integer expressions using ROBDDs. particular,show implement equality inequality constraints. usual, assume twoexpressions x equal lengths l bits; not, pad shorter expression0 bits right.Equality two integer expressions x easy represent ROBDDthecorresponding bits x must equal. Hence represent equality constraintx = ROBDD B(x = y):B(x = y) =l1^i=0128xifiSolving Set Constraint Satisfaction Problems using ROBDDsNote identical implementation equality two set expressionsaddition zero-padding.turns already implementation inequality constraints, albeitdifferent guise. Inequalities binary integers correspond inequalitieslexicographic ordering bit representations, implement, example,strict less-than constraint x < two integer variables x using lexlt operationSection 4.3.B(x < y) = lexlt(x, y)use construct reverse inequality swapping orderoperands, non-strict inequality negating formula (reversed necessary).implementation inequalities also leads us implementation minimummaximum expressions. Consider problem finding smaller two integerexpressions x y. x bit vectors hxl1 , . . . , x0 hyl1 , . . . , y0 respectively,recursively define min(x, y) follows:= R l = 0Li = Li+1 (Li+1 Ri+1 xi yi )1i<lRi = Ri+1 (Li+1 Ri+1 xi yi )1i<lmi = (Li+1 xi ) (Ri+1 yi ) (Li+1 Ri+1 xi yi )0i<lmin(x, y) = hml1 , . . . , m0equation above, Li Ri values flag bits state whether higherorder bits already allowed us conclude one two values minimum.maximum operation defined similarly.5.4 Modeling Multisets Multiset ConstraintsVarious authors suggested multisets valuable addition modelingabilities set constraint solver (Kiziltan & Walsh, 2002). section briefly showmultisets multiset constraints modelled using ROBDDs making useinteger building blocks described above.multiset unordered list elements {{m0 , . . . , mn }} drawn universe U,(unlike set) repetition elements permitted. set operations paralleloperations multisets, although multiset operations strict generalisationsset operations. Let occ(i, m) denote number occurrences elementmultiset m. Suppose n multisets, k integer constant. definefollowing multiset relations operations actions number occurrenceselement universe:Equality: = n iff occ(i, m) = occ(i, n) U.Subset: n iff occ(i, m) occ(i, n) U.Union: occ(i, n) = occ(i, m) + occ(i, n) U.Intersection: occ(i, n) = min{occ(i, m), occ(i, n)} U.129fiHawkins, Lagoon, & StuckeyDifference: occ(i, \ n) = max{0, occ(i, m) occ(i, n)} U.Cardinality: |m| =PiUocc(i, m) U.represent set variable x associated vector Boolean variables hx 1 , . . . , xnbits characteristic vector valuation x. case multiset,characteristic vector multiset vector integers, need associateinteger value mi potential element multiset m. modelinteger value using approach described above.multiset variable, associate bundle ROBDD variables everyU, contents comprise bits corresponding integer expression .order represent multisets finite number bits, assume numberoccurrences element multiset variable bounded reasonably small, allowing us use k = dlog2 e Boolean variables per bundle. writelist bundles hm1 , . . . , mn i, mi turn list bits hmi,k1 , . . . , mi,0 i.Given representation multiset variables, turn attention implementation multiset expressions constraints. Multiset expressions implementedobvious way sequences integer expressions. example, suppose x multiset variables associated bundles hx1 , . . . , xN hy1 , . . . , yN respectively.bundles corresponding expression xy hplus(x1 , y1 ), plus(x2 , y2 ), . . . , plus(xN , yN )i.Similarly, bundles corresponding expression xy hmin(x1 , y1 ), . . . , min(xN , yN )i,expressions. show implement cardinality weighted sumconstraints Section 5.5.Multiset constraints also trivial implementfor example, two multisets xequal constituent bundles equal, multiset equalitymodelled conjunction integer equalities. Relations subset correspondconjunction integer inequalities constituent bundles, implementationdescribed Section 5.3.point left ordering ROBDD variables makemultiset variable unspecified. Unfortunately, unlike set case, single optimalvariable ordering guaranteed produce compact descriptions primitivemultiset constraints. example, subset constraint compactly representedbundle-major bit ordering bit-major ordering (see Figure 9), since subsetconstraint consists series integer inequalities corresponding bundlestwo multiset variables, bundle-major ordering gives interleaving variablesabove. However, opposite true cardinality constraint, consists sumvalues bundles within variable, variables interleavedbit-major ordering bundle-major ordering. two orderings mutuallyexclusive, hence conclude general need optimal variableordering modeling multiset constraints.5.5 Weighted Sum Cardinality Constraintsmany practical applications interested placing constraints weighted sumelements set variable. example, Balanced Academic Curriculum problem(problem prob030 CSPLib), every course associated weight corresponding130fiSolving Set Constraint Satisfaction Problems using ROBDDsBundle 1Bundle 2Bundle 3Bundle 1Variable 1Bit 1Bit 2Bit 3Bit 1Bit 2Bit 3Bit 1Bit 2Bit 3Variable 2Bit 1Bit 2Bit 3Bit 1Bit 2Bit 3Bit 1Bit 2Bit 3Bit majorBundle 2Bundle 3Variable 1Bit 1Bit 2Bit 3Bit 1Bit 2Bit 3Bit 1Bit 2Bit 3Variable 2Bit 1Bit 2Bit 3Bit 1Bit 2Bit 3Bit 1Bit 2Bit 3Bundle majorFigure 9: Bit bundle major orderings two multiset variablesacademic load, limit total academic load undertakengiven time period. set model problem proposed Hnich, Kiziltan,Walsh (2002), limits academic load period made useweighted sum constraint. addition cardinality constraint alreadydescribed special case weighted sum constraint weights set1. therefore seems essential implement constraint ROBDD framework.Suppose x set multiset expression bit bundles hx1 , . . . , xn i. (If x setexpression, bit bundle size 1). use integer operations describedearlier produce integer expression wsum(x, w) corresponding weighted sumPni=1 xi wi , w vector integers hw1 , . . . , wn i:0 = hi= plus(i1 , mul (xi , wi ))wsum(x, w) = nExpressions involving cardinality set multiset variables expressedspecial case weighted sum expression wi = 1 1 n.already seen one method constructing ROBDDs constraints |x| = k, |x| k|x| k set variable case; method general, since permits us directlymodel constraints |x| + 5 |y| + |z|. great practical valuefor exampleneeded implement Hamming Code experiment Section 7.3. cases alreadydiscussed Section 3.2 ROBDDs produced two methods identical sinceROBDDs canonical representation.6. Efficient Constraint Propagation Using ROBDDssection discuss improvements variants basic domain propagationscheme presented Section 3.3.implementation domain propagator dom(c) substantial effectperformance solver. definition dom(c) given purest mathematicalform simplicity. Section 6.1 discusses several implementation details leadgreatly improved efficiency performing domain propagation.general, inferences obtained using domain propagator maycostly practical, circumstances may desirable enforce131fiHawkins, Lagoon, & Stuckeyweaker form consistency. Weaker consistency may substantially cheaper enforce,permitting time spent searching solution space.always compromise propagation time search time,certain problems may productive spend time searching performingaccurate propagation, problems converse may true. ROBDDbased representation allows taken extremesin theory possible formsingle ROBDD representing solutions constraint satisfaction problem formingROBDD conjunction constraints. solution could trivially readROBDD satisfying assignment. Usually ROBDD would prohibitivelyexpensive construct time space, forcing us maintain less strict consistencylevels.Accordingly, show implement weaker levels consistency using ROBDDrepresentation combining domain propagator approximation operation.approximation operation simplifies ROBDD representing domain bounds closuresuitable definition bounds. ROBDD representing bounds domainalmost always smaller domain itself, leading better performance futureoperations domain. shall see, lead substantial performanceimprovements overall solver.6.1 Domain PropagationLet c constraint, vars(c) = {v1 , . . . , vn }. Section 3.3 gave following definitiondomain propagator:dom(c)(D)(vi ) = V (vi ) (B(c)n^D(vj ))(2)j=1Since B(c) D(vj ) ROBDDs, directly implement Equation (2) usingROBDD operations. practice efficient perform existential quantificationearly possible limit size intermediate ROBDDs. make useefficient combined conjunction existential quantification operation, well calland-abstraction, provided ROBDD packages.leads following implementation:0i = B(c)(V (vj ) (D(vj ) j1)ji =i11 i, j n, 6= j (and-abstraction)i=j(3)dom(c)(D)(vi ) = D(vi ) niQworst case complexity still O(|B(c)| nj=1 |D(vj )|) vj . Clearlycomputation shared propagation c different variables since ji = ji0j < j < i0 . Even improvement algorithm Equation (3) usesO(n2 ) and-abstraction operations (which experimentally shown occupymajority execution time set solver).domain propagator implementation Equation (3) significantly improvedobserving case n-variable constraint (n 3) many similar sub-formul132fiSolving Set Constraint Satisfaction Problems using ROBDDsdom divide conquer(D, , V ):(|V | = 0) returnelse (V = {vi })D(vi ) := D(vi )returnelse{v1 , . . . , vk } := Vh := b k2 cR := V (v1 ) D(v1 ) V (v2 ) D(v2 ) V (vh ) D(vh )L := V (vh+1 ) D(vh+1 ) V (vh+2 ) D(vh+2 ) V (vk ) D(vk )D1 := dom divide conquer(D, L, {v1 , . . . , vh })D2 := dom divide conquer(D1 , R, {vh+1 , . . . , vk })return D2Figure 10: divide conquer algorithm domain propagationcomputed. Due need perform existential quantification operations earlypossible, complete freedom rearrange order evaluation seefit. However, simple divide-and-conquer strategy calculating dom(c)(D)(v ) allows usperform domain propagation using O(n log n) and-abstraction operations. definedom(c)(D) = dom divide conquer(D, B(c), vars(c)), dom divide conquer definedFigure 10.6.2 Set Bounds Propagationdomain propagation may prohibitively expensive enforce problems,useful investigate less strict notions consistency. cases, speed propagation simplifying domains approximation. Since set boundssubset partial ordering relation one commonly used approximations setdomain, seems natural implement set bounds propagator ROBDD framework.relatively minor changes needed domain propagator turn setbounds propagator.Given ROBDD representation set domain, easily identify corresponding set bounds. ROBDD-based set domain representation, set boundsdomain correspond fixed variables ROBDD representing domain. sayROBDD variable v fixed either nodes n(v, t, e) constant 0 node,nodes n(v, t, e) e constant 0 node, node appears every pathroot diagram 1 node.nodes identified single pass domain ROBDD, time proportional size. ROBDD, write JK denote ROBDD representingconjunction fixed variables . represents set sets S, JK representsconv (S). ROBDD = JK stick ROBDD definition.133fiHawkins, Lagoon, & StuckeyExample 6.1. Let ROBDD depicted Figure 1(c). JK ROBDDFigure 1(a).Using operation convert domain propagator set bounds propagatordiscarding non-fixed variables domain ROBDDs propagationstep. Suppose D(v) stick ROBDD v V. c constraint,vars(c) = {v1 , . . . , vn }, define set bounds propagator sb(c) thus:nzr^D(vj ))sb(c)(D)(vi ) = V (vi )(B(c)(4)j=1Despite relatively minor differences set bounds propagatordomain propagator, set bounds propagator usually significantly faster domain propagator two reasons. Firstly, domains D(v) sticks,ROBDD operations cheap, compared operations possibly large ROBDDsrepresenting arbitrary domains. entire propagator implemented O(|B(c)|)complexity, since ROBDDs sticks. Secondly, use updated setbounds simplify propagator ROBDD B(c). Since domains monotonic decreasingsize, fixed variables remain fixed backtracking, projectB(c), thus reducing size propagator ROBDD future propagation steps.leads us following implementation propagator:0 = B(c)j = V AR(D(vj )) D(vj ) j1 1 j nV (v ) Jn Ksb(c)(D)(vi ) = D(vi )1in(5)propagation step replace representation constraint B(c) nsince fixed variables longer new impact.Example 6.2. Consider bounds propagation constraint c v w N = 3.ROBDD representation B(c) given Figure 4. Assume domains v wrespectively [{1}, {1, 2, 3}], represented formula v1 , [, {1, 2}], representedformula w3 . ROBDD n v1 w3 B(c) v1 w3 shown Figure 11(a).Jn K = w1 v3 . project fixed variables v1 , w1 , v3 , w3 B(c)get new simplified form constraint v2 w2 shown Figure 11(b).set bounds solver retains modeling advantages domain solver,including ability easily conjoin existentially quantify constraints, remove intermediate variables form global constraints. cases permits substantialperformance improvement traditional set bounds solvers.Experimentally appears direct implementation Equation (4), writtenuse divide conquer approach calculate and-abstractions, fasterimplementation Equation (5), even divide conquer approach used calculatingexistential quantification. former approach calculates fewer intermediate results,leads faster propagator overall. Experimental results bounds propagatorgiven Section 7.134fiSolving Set Constraint Satisfaction Problems using ROBDDs01237654) EE10123765401237654v EE( E2E+ E". v2 EE1 % EEE"5 +9 5 w(2EEEEDE Q Z. E"`L Pl Cl0 v3 @@l V @@XU [Z -.vl l100123765401237654(a)01237654EE"wz 2BBBC|z z U [B.01.(b)Figure 11: Set bounds propagation constraint v w showing (a) resulting ROBDDconjunction domains, (b) simplified constraint ROBDDremoving fixed variables.6.3 Split Domain Propagationcombine set bounds propagator domain propagator producespace efficient split domain propagator. separating domain representation fixedunfixed parts, reduce total size representation, also hopefully speedingpropagation.One unfortunate characteristics ROBDDs size ROBDDrepresenting domain highly dependent variable ordering. Consider ROBDDrepresenting set domain contains several fixed variables. variablesappear beginning variable ordering, ROBDD representingdomain effect contain several copies sticks representing fixed variables.example, Figure 1(c) contains several copies stick Figure 1(a). Since manyROBDD operations take time proportional product number ROBDDnodes arguments, overly large representation performance cost.solve problem two wayseither reordering ROBDD variables splittingdomain representation.Variable reordering capable eliminating redundancy representationindividual domain, general cannot eliminate redundancy across set domains.reordering ROBDD variables, reduce size domain placing fixedvariables beginning variable order, thus removing unnecessary duplicationdomain. Unfortunately, variable order global property ROBDDsexistence, whereas fixed variables domain local property specific particulardomain, may variable ordering optimal domainsproblem.context applying ROBDDs groundness analysis logic programs, Bagnara (1996) demonstrated performance ROBDD-based program analyzercould improved splitting ROBDDs fixed non-fixed parts.apply technique here.135fiHawkins, Lagoon, & Stuckeysplit ROBDD representing domain D(v) pair ROBDDs (LU , R). LUstick ROBDD representing lower upper set bounds D(v), R remainderROBDD representing information unfixed part domain. Logically =LU R. write LU (D(v)) R(D(v)) denote LU R parts D(v)respectively.following results provide upper bound size split domain representation:Lemma 6.1. Let G ROBDD, let v fixed variable G. |v G| < |G|.Proof. Since v fixed variable, either every node n(v, t, f ) G constant 0node, every node f constant 0 node. Since node n(v, t, f ) correspondsproposition (v t) (v f ), clear v n(v, t, f ) corresponds simply f ,moreover since v fixed node one f zero. Hence existential quantificationfixed variable v simply removes nodes labelled v D. Since least onenode, result follows.Lemma 6.2. Let G ROBDD, LU = JGK, R = VAR(LU ) G. G LU R|LU | + |R| |G|.Proof. result G LU R straightforward, prove result sizes.Suppose VAR(LU ) = {v1 , . . . , vn } set fixed variables G. Then, since|v1 G| < |G|, 1 + |v1 G| |G|. repeating operation vi , obtain n +|VAR(LU ) G| |G|. LU stick, trivially |LU | = n, R = VAR(LU ) Gdefinition required inequality.Note |D| O(|LU | |R|). example, considering ROBDDs Figure 1LU shown (a), R (b), = LU R (c), |LU | = 5|R| = 9 |D| = 9 + 4 5 = 29.show construct propagator split domains. Firstly, eliminatefixed variables (as bounds propagator) apply domain propagationremainder domains R. propagator produces new pair (LU , R) consisting newfixed variables new remainder. process shown below:0 = B(c)j = VAR(LU (D(vj ))) (LU (D(vj )) j1 )= V (vi ) (nn^R(D(vj )))(6)j=1= LU (D(vi )) Ji Kdom(c)(D)(vi ) = (i , VAR(i ) )efficiency components calculated using divide-and-conquer approach described domain propagator.split domain representation three main advantages. Proposition 6.2 tells ussplit domain representation larger original domain representation. However, often split representation substantially smaller, lead improvements136fiSolving Set Constraint Satisfaction Problems using ROBDDs{1,2,3,4}Upper bound{1,2,3} {1,2,4} {1,3,4} {2,3,4}{1,2}{1,3}{1,4}{2,3}{2,4}{3,4}Lower bound{1}{2}{3}{4}{}Figure 12: set interval [, {1, 2, 3, 4}] upper lower cardinality bounds u = 3l = 2 respectivelypropagation performance. split solver also use propagator simplificationtechnique bounds solver abstracting fixed variables propagator ROBDDs. Finally using split solver mix usage domain boundspropagators problem.Experimental results split domain propagator given Section 7.6.4 Cardinality Bounds PropagationGiven able model set bounds propagator using ROBDDs, also appropriate consider might model levels consistency set constraint problems.One level consistency commonly used (Azevedo, 2002; Muller, 2001)combined set bounds cardinality consistency, upper lower boundscardinality domain maintained addition bounds subset partial ordering. hybrid approach allows accurate representation domains,particularly constrained cardinality, common set problems.Example 6.3. Figure 12 depicts set interval [, {1, 2, 3, 4}], together lowerupper cardinality bounds 2 3 respectively. general interval consists largenumber sets, making crude approximation set domain. Cardinality boundspermit fine grained representation effectively allowing us select subsetrows lattice diagram.able implement set bounds propagator using domain propagator together function extracts set bounds domain,create combined set bounds set cardinality propagator. extend splitdomain solver simplifying remainder component split domain ROBDDrepresenting cardinality bounds.137fiHawkins, Lagoon, & Stuckeybdd count cardinality(D, V ):(D = 0) return h,else (D = 1)(|V | = 0) return h0, 0ielsehv1 , v2 , . . . , vn := Vreturn h0, nielse(|V | = 0) errorn(v, t, e) :=hv1 , v2 , . . . , vn := V(v1 v) errorelse (v = v1 )hlt , ut := bdd count cardinality(t, hv2 , . . . , vn i)hle , ue := bdd count cardinality(e, hv2 , . . . , vn i)return hmin(lt + 1, le ), max(ut + 1, ue )ielsehl, ui := bdd count cardinality(D, hv2 , . . . , vn i)return hl, u + 1ibdd card bounds(D, V ):hl, ui := bdd count cardinality(D, V )(l = u = ) return 0return card (V, l, u)Figure 13: algorithm determine cardinality bounds domain set variablerepresented ROBDD D, V vector bits Booleanrepresentation set variablebefore, need method extracting ROBDD representing cardinalitybounds arbitrary domain ROBDD. perform operation two stages. Firstlydefine function bdd count cardinality takes ROBDD representing set domainreturns upper lower bounds cardinality. represent boundsROBDD form constructing new cardinality constraint ROBDD describedSection 3.2.implementation bdd count cardinality shown Figure 13. functionimplemented run O(|D||V |) time dynamic programming/caching used saveresults intermediate recursive calls. practice since V highly interrelated, O(|D|). implementation utilise global cache mechanismROBDD library, also permits caching partial results multiple callsbdd count cardinality.138fiSolving Set Constraint Satisfaction Problems using ROBDDs01237654x EEE1%01237654x EEEEE",2h0, 2i1h0, 2i01237654EE"4x3> z z AAAG % z|ztJJJJ$h0, 1ih0, 1izt0h0, 0i(a)JJJJ$zth0, 0i NNNNN&h,(b)Figure 14: Cardinality propagation example showing (a) resulting ROBDD projected ontox, (b) calculation cardinality boundsuse function construct function bdd card bounds takesROBDD list Boolean variables V returns new ROBDD representingbounds cardinality solutions D. implementation bdd card boundsshown Figure 13.algorithm split set bounds set cardinality propagator constraint cgiven sbc(c) following equation:0 = B(c)j = VAR(LU (D(vj ))) (LU (D(vj )) j1 )= V (vi ) (nn^R(D(vj )))(7)j=1= LU (D(vi )) Ji Ksbc(c)(D)(vi ) = (i , bdd card bounds(VAR(i ) , V (vi ) \ VAR(i )))Note keep cardinality bounds remaining non-fixed Booleanvariables set variable v rather original variables V (v), sinceneed consider fixed variables again, leads slightly smaller cardinalityROBDD. usual Equation 7 implemented using divide-and-conquer approachefficiency. Experimental results propagator shown Section 7.Example 6.4. illustrate set bounds cardinality propagation constraintc lexlt(x, y) whose ROBDD B(c) shown Figure 7(b). Assume original domainsx universal, D(x) = D(y) = [, {1, 2, 3}], represented ROBDD 1.V (x) B(c) shown Figure 14(a), x = Jx K = 1. treeROBDD x =calculations bdd card bounds(x , hx1 , x2 , x3 i) shown Figure 14(b). Overallcardinality x determined range [0, 2].139fiHawkins, Lagoon, & Stuckey6.5 Lexicographic Bounds Propagationalternative form set consistency proposed Sadler Gervet (2004) maintainbounds lexicographic ordering addition set bounds. lexicographic orderingtotal ordering sets embeds subset partial ordering. Boundslexicographic ordering alone sufficient express effects many constraints (inparticular inclusion single element), Sadler Gervet constructed hybrid solvercombines lexicographic bounds traditional set bounds. demonstratedset solver based upon lexicographic bounds consistency techniques produced strongerpropagation traditional set bounds solver, although came substantial costpropagation performance. However, given use ROBDD representationleads performance improvement case set bounds propagation, worthinvestigating performance ROBDD-based lexicographic bounds propagator.lexicographic bounds domain compactly represented ROBDD.Like set bounds, ROBDD representing upper lower lexicographic boundsdomain ROBDD size O(N ), combination. ROBDDscompact hopefully leads fast propagation. Moreover, given ROBDD domain,easy extract lexicographic bounds domain single pass. processanalogous construction bounds cardinality propagator, use splitdomain propagator combined function determines lexicographic boundsdomain construct highly efficient lexicographic bounds solver.define two functions bdd lex lower bound bdd lex upper bound. functions,given ROBDD representing domain variable V together list Booleanvariables B corresponding bits V , return lower upper lexicographic bounds(respectively) D. bdd lex lower bound implemented shown Figure 15 (the implementation bdd lex upper bound similar).define:bdd lex bounds(D, B) = bdd lex lower bound(D, B) bdd lex upper bound(D, B)split set lexicographic bounds propagator implemented exactlyEquation (7), using bdd lex bounds place bdd card bounds.Example 6.5. Consider lexicographic bounds propagation constraint c |s| = 2{1, 2, 3, 4, 5}. ROBDD B(c) shown Figure 3(b) initial domainD(s) = [, {1, 2, 3, 4, 5}]. = B(c) = 1 call bdd lex bounds calculates lower bounds lexicographic ROBDD shown Figure 16(a), upper boundslexicographic ROBDD shown Figure 16(b), final answer conjunction shownFigure 16(c). Note lost information relative original cardinalityROBDD.observed Section 5.3, lexicographic ordering set variables actually corresponds numeric ordering integer variables, pure lexicographic bounds propagatorwould also coincidentally integer bounds propagator.Experimental results lexicographic bounds propagator given Section 7.140fiSolving Set Constraint Satisfaction Problems using ROBDDsbdd lex lower bound(D, B):(|B| = 0 = 1) return 1(D = 0) errorn(v, t, e) :=hb1 , . . . , bn := B(b1 v) errorelse (b1 = v e = 0)return b1 bdd lex lower bound(t, hb2 , . . . , bn i)else(b1 = v) r := bdd lex lower bound(e, hb2 , . . . , bn i)else r := bdd lex lower bound(D, hb2 , . . . , bn i)return b1 (b1 r)Figure 15: algorithm extract lower lexicographic bounds domain setvariable represented ROBDD D, B vector (non-fixed) bitsBoolean representation set variable01237654}{ {01237654{{ 2{}{{ 3++++}{ {s4 C++++CCCC!s5 C +++CC +C! |(171LW U^ \` /00012376540123765401237654(a)01237654CCC1101237654012376540123765401237654{ 1 CCCCC!s2s2 C{CCCC{!}{{ 3{ 3++{{+}{}{++s4 Cs4++C{C{CC+!}{s5 C +++ s5CC +{C! }{(171LW U^ \` /0 qtp0CC!s2 CCCCC!s3{{}{s4{{!}{$ ~5~~012376540123765410 p qt(b)012376540123765401237654}{ {01237654012376540123765401237654(c)Figure 16: Calculating lexicographic (a) lower (b) upper bounds (c) conjunction.7. Experimentsimplemented set solver using ideas described paper. implementation written primarily Mercury (Somogyi, Henderson, & Conway, 1996), usinginterface C language ROBDD library CUDD platform ROBDD manipulations (Somenzi, 2004). ROBDD library effectively treated black box.141fiHawkins, Lagoon, & Stuckeyused solver implement series standard constraint benchmarks describedbelow. Many problems CSPLib library constraint satisfaction problems(Gent, Walsh, & Selman, 2004). purposes comparison, also implementedbenchmarks using ic sets library ECLi PSe v5.62 finite sets libraryMozart v1.3.0. conducted experiments cluster 8 identical 2.8GHzPentium 4 machines, 1 Gb RAM running Debian GNU/Linux 3.1.three solvers limited 1 Gb memory minimise swapping. experimentsrepeated three times, lowest time three runs taken result.7.1 Steiner Systemscommonly used benchmark set constraint solvers calculation small Steinersystems. Steiner system S(t, k, N ) set X cardinality N collection Csubsets X cardinality k (called blocks), elements X exactlyone block. Steiner systems extensively studied combinatorial mathematics.= 2 k = 3, so-called Steiner triple systems, often usedbenchmarks (Gervet,1997; Azevedo, 2002; Muller, 2001). Steiner system mustexactly = Nt / kt blocks (Theorem 19.2 van Lint & Wilson, 2001).natural model Steiner system using set variables s1 , . . . , sm , setvariable corresponds single block, subject following constraints:^(|si | = k)(8)(uij uij = si sj |uij | (t 1)) (si < sj )(9)i=1m1^^i=1 j=i+1lexicographic ordering constraint si < sj added remove symmetriesproblem formed permuting blocks.ki/ tinecessary condition existence Steiner system Ntiinteger {0, 1, . . . , 1} (van Lint & Wilson, 2001); say set parameters(t, k, N ) admissible satisfies condition. order choose test cases, ransolver every admissible set (t, k, N ) values N < 32. Results shownevery test case least one solver able solve within time limit 10 minutes.denotes abnormal termination due exceeding arbitrary limit maximumnumber ROBDD variables imposed CUDD package, denotes failurecomplete testcase within time limit.cases use sequential variable-ordering heuristic, value-ordering heuristicchooses largest unfixed value within variables domain. variableunfixed value chosen labeling, either value member setrepresented variable not. order try two alternativessignificant effect performance solver. case elect chooseelement-not-in-set option first.2. recently new sets library Cardinal added ECLi PSe supports better cardinalityreasoning. Unfortunately cannot directly compare benchmarks since142fiSolving Set Constraint Satisfaction Problems using ROBDDsTable 2: Results Steiner systems, split constraints intermediate variables.Testcase ECLi PSe Mozart BoundsDomainLU+RLU+Lex LU+CardTime Fails Time Fails Time Fails Time Fails Time Fails Time Fails Time Fails/s/sS(2,3,7)0.310S(3,4,8)0.521S(2,3,9)7.7 1394S(2,4,13) 1.8 313S(2,3,15) 3.665S(3,4,16) 67.5 289S(2,5,21) 3.2 421S(3,6,22) 49.7 1619/s/s/s/s/s0.1 21 <0.1 10 0.10 0.10 0.14 <0.120.1 52 0.1 21 0.40 0.40 0.44 0.141.0 5102 1.6 1394 1.0 100 1.3 100 3.3 421 2.4 10720.4 1685 0.6 313 1.7 32 1.5 32 2.1 127 0.7 1570.5 354 2.2 65 20.20 19.60 20.4 127 3.3 410.4 668 2.3 421 110.20 59.80 21.5 139 2.6 124Table 3: Results Steiner systems, merged constraints intermediate variables.TestcaseBoundsDomainLU+RLU+LexLU+CardTime Fails Time Fails Time Fails Time Fails Time Fails/s/s/sS(2,3,7) <0.18 <0.10S(3,4,8)0.1180.10S(2,3,9)0.23250.19S(2,3,13)109.2 24723S(2,4,13) 0.11570.10S(2,3,15) 0.4561.30S(2,4,16) 421.4 5227060.615S(2,6,16)80.7 15205S(3,4,16) 9.7274 548.70S(2,5,21) 0.54131.40S(3,6,22) 8.3 1608S(2,3,31) 23.3280/s<0.100.100.19144.6 247230.101.400.61582.7 15205485.301.40/s<0.100.100.111518.1 303380.4112.902.516428.9032.90<0.100.100.21130.1270.732577.0 20979918.41620.611612.738148.6224Table 4: All-solutions results Steiner systems. denotes failure complete testcase within one hourECLi PSeBoundsProblem Solns. time fails time fails/sS(2,3,7)S(3,4,8)S(2,3,9)S(2,6,16)/sDomainLU+Rtime fails time fails/s/sLU+LexLU+Cardtime fails time fails/s/s30 16.3 3,015 0.2537 0.147 0.147 0.276 0.326730726.5 610271 1.4 492 2.1 492 22.4 3248 951.2 431801840398.1 391691 23.4 16794 37.8 16794 110.4 29133 593.3 224131080.9 15205 83.0 15205143fiHawkins, Lagoon, & Stuckeyorder compare raw performance various solvers, irrespectivemodeling advantages ROBDD-based solver, performed experiments using modelproblem contains primitive constraints makes use intermediatevariables. split model contains unary constraints corresponding Equation (8)3m(m1)/2 binary constraints corresponding Equation (9) (containing intermediatevariables uij ). model used ECLi PSe , Mozart ROBDD-basedsolvers, permitting direct comparison propagation performance. Results modelshown Table 2. particular, observe model ECLi PSe ROBDDbased bounds solver produce number failures, demonstrating searchspaces explored two solvers identical.One main strengths ROBDD-based modeling approach gives usfreedom merge arbitrary constraints existentially quantify away intermediatevariables, allowing us model set constraint problems efficiently. caseSteiner systems, allows us model problem unary constraints correspondingEquation (8), m(m 1)/2 binary constraints ij form ij = (|si sj |(t 1)) (si < sj ). binary constraints contain intermediate variablesuij required since existentially quantified ROBDDrepresentation. Experimental results revised model shown Table 3.cases revised model propagates much strongly original model,leading substantial decrease solution time. addition, decrease numberset variables required permits solution larger test cases. Clearly beneficialremove intermediate variables merge constraints.Despite weaker propagation ROBDD bounds solver often fastest methodfinding single solution Steiner System. order determine whether dueefficiency solver, whether solver lucky finding solutionquickly, also ran experiments find solutions Steiner systems reorderingblocks. results test cases least one solvers able solvewithin time limit one hour shown Table 4. cases reductiontime number fails demonstrate superiority propagation approaches baseddomain consistency.7.2 Social GolfersAnother problem often used set benchmark Social Golfers problem (problemprob010 CSPLib). aim problem arrange N = g golfers g groupsplayers w weeks, two players play together once.model problem set constraint problem using w g matrix set variablesvij , 1 w week index 1 j g group index.support lexicographic ordering constraints. Testing without lexicographic orderings showed23 times slower LU + Card.144fiSolving Set Constraint Satisfaction Problems using ROBDDsuse following model problem:w^(partition< (vi1 , . . . , vig ))^|vij | =i=1 j=1i=1gw ^^^|vik vjl | 1w1^w^(10)vi1 vj1i=1 j=i+1i,j{1,...,w} k,l{1,...,g}i6=jpartition< global constraint combined partitioning lexicographical ordering constraint, formed merging partition constraint Section 4.2 constraintsimposing lexicographic order variables. constraint trivial construct usingROBDDs, available either ECLi PSe Mozart.3Results solvers shown Table 5 Table 6. former table,sequential smallest-element-in-set labeling strategy used enable fair comparisonpropagation performance, whereas latter table first-fail labeling strategyused order give measure peak performance solver. every test casetables, single exception (5-8-3), least one ROBDD-based solversperforms equal better ECLi PSe Mozart. also observedusing first-fail labeling strategy, domain split domain solverssolvers able solve every test case.several features results worth noting. caseSteiner systems, ROBDD-based set bounds solver often fastest, despite weakpropagation. Amongst solvers stronger propagation, split domain solveralmost always faster original domain solver due smaller domain sizes. is,however, slower original domain solver presence backtracking (duerequirement trail valuesin particular propagator ROBDDs). lexicographic bounds solver almost effective domain solvers restricting searchspace, although usually outperformed domain bounds solvers.7.3 Weighted Hamming Codesproblem finding maximal Hamming Codes modelled set constraintproblem.define l-bit codeword bit-string (or vector Boolean values) length l.Given two l-bit codewords B, define Hamming distance d(A, B)B number positions two bit-strings differ. (l, d)-HammingCode set l-bit codewords Hamming distance two codewordsset least d.Given codeword length l minimum Hamming distance d, problemconstruct Hamming code largest possible number codewords. variantproblem, used benchmark Sadler Gervet (2004), additional requirementcodeword fixed weight w, weight codeword defined3. would, course, possible implement constraint ECLi PSe Mozart,implementation would fairly laborious process. strength ROBDD-based modelingapproach construct global constraints extra code.145fiHawkins, Lagoon, & StuckeyTable 5: First-solution performance results Social Golfers problem, using sequentialsmallest-element-in-set labeling strategy. Time number failures givensolvers. denotes failure complete test case within 10 minutes.cases 5-4-3, 6-4-3, 7-5-5 solutionsProblemw-g-s2-5-42-6-42-7-42-8-53-5-43-6-43-7-44-5-44-6-54-7-44-9-45-4-35-5-45-7-45-8-36-4-36-5-36-6-37-5-5ECLi PSetime fails/sMozarttime fails/s7.6 1046849.2 6430895.1 11481812.5 1409276.3 83815146.8 14641914.1 14369169.3 14976727.3 19065350.6 1996325.0 2229458.9 2402963.3 14621.0 76386.4 4234610.9 666372.5 1031114.0 5113427.3 883943.9 1071546.4 907127.8 12489217.7 4168890.9 1820287.4 4714851.0 1462BoundsDomain LU+R LU+Lex LU+Cardtime fails time fails time time fails time fails/s/s0.130 0.100.6 2036 0.201.7 4447 0.402.000.130 0.301.6 2039 1.604.6 4492 8.900.230 0.8021.9 12747 118.608.7 44982.671113.9 63642 28.6 51657.0 2686 3.8 4114.6 45831.114 9.20158.2 61770 20.3 21324.1 1455 1.8 820.55 1.800.50/s0.10.10.41.60.31.48.40.680.7481.632.12.37.823.01.51.40.4/s0.130.7 1942.3 6920.432.2 1947.6 6950.7319.3 49914.1 69622.2888.9 1021012 31323.7 7003.2360.8 45064.1 2021.202.40/s0.150.4 3261.6 16080.251.9 3285.1 16290.4532.0 212210.5 16328.933202.7 5054220.8 158417.5 16832.14293.5 499668.3 10780.711.322number 1 bits codeword contains. denote instance problemH(l, d, w).proposed Muller Muller (1997), model problem n codewordsusing n set variables Si , 1 n . codeword Ci corresponds characteristicfunction set Si , i.e. bit j set codeword Ci j Si . Hammingdistance d(Ci , Cj ) two codewords Ci Cj calculated associatedsets Si Sj thus:d(Ci , Cj ) = l |Si Sj | |{1, . . . , l} \ (Si Sj )|remove symmetries created permuting codewords introducing lexicographic ordering constraints Si < Sj , 1 < j n. complete model146fiSolving Set Constraint Satisfaction Problems using ROBDDsTable 6: First-solution performance results Social Golfers problem, using first-failsmallest-element-in-set labeling strategy. Time number failures givensolvers. cases 5-4-3, 6-4-3, 7-5-5 solutionsProblemw-g-s2-5-42-6-42-7-42-8-53-5-43-6-43-7-44-5-44-6-54-7-44-9-45-4-35-5-45-7-45-8-36-4-36-5-36-6-37-5-37-5-5ECLi PSetime failsMozarttime fails/s/s7.9 1046851.3 6430899.9 11481814.5 1409291.8 83815183.0 14641918.0 14369243.9 14976740.9 19065394.9 1996325.4 2229501.0 2402963.6 1462Boundstime fails/s1.1 76386.5 4234611.1 666372.6 1031115.1 5113428.7 883944.1 1071549.6 907128.3 12489224.5 4168890.9 1820294.2 4714851.0 1462Domain LU+R LU+Lex LU+Cardtime fails time time fails time fails/s0.1300.6 20361.7 44470.1441.9 23615.2 51400.34738.5 193769.9 51492.7143187.5 1039724.5 238817.6 54941.119234.2 904281.6495/s0.100.200.401.900.301.101.900.8062.506.50152.0023.2 38122.5 1818.204.5014.6 15041.2 341.6716.9 5280.500.10.10.41.60.30.91.70.640.15.1107.426.01.712.83.915.21.01.313.10.4/s0.130.7 1862.0 3900.452.4 2096.2 5120.7724.6 60710.6 40522.61391.4 1042223.4 77616.9 4473.4254.0 401358.2 37875.1 292288.8 98292.40/s0.4 4473.8 38204.6 64241.3 48113.7 372215.6 60672.6 49429.5 571712.5 516309.1 7266941.4 473047.1 54732.783349.9 59805473.6 686731.081.322problem is:n^|Si | = w(11)i=1n1^n^(|Si Sj | + |(Si Sj )| l d) (Si < Sj )(12)i=1 j=i+1constraints described Equation (12) implemented using single ROBDDpair j values. possible since model integer additioncomparison operations ROBDDs described Section 5, using representationcardinality set variable integer expression described Section 5.5.order find optimal solution, initially set n 1, repeatedly solve instancesproblem, progressively incrementing n find larger larger codes. proveoptimality solution n = k failing solve problem n = k + 1;know optimal value n k.147fiHawkins, Lagoon, & StuckeyTable 7: Statistics 51 Weighted Hamming Code testcases solvedsolvers.Boundstimefails/sDomainLU+Rtime fails time fails/sMean17.7 110034Total903.3Minimum0.03025th Percentile 0.0319Median0.0519675th Percentile 0.675604Maximum415.55 3021057LU+LexLU+Cardtime fails time fails/s0.2 210.711.40.0300.0300.0420.06254.16 3740/s0.3 210.714.20.0300.0300.0420.06254.69 3740/s4.4 1886222.60.0300.0330.04200.18 143.5113.9 456673.6 6604184.60.0300.0300.0420.0911292.09 211677Table 8: Weighted Hamming Code testcases solved least onesolversBoundsDomainLU+Rtime fails time fails time fails/sH(8,4,4)H(9,4,3)H(9,4,6)H(10,6,5)/s/sLU+Lextime fails/sLU+Cardtime fails/s1.6 224 1.9 224 8.598611.3 5615 20.6 561525.4 16554 45.7 16554 321.9 5659926.7 16635 29.6 16635 528.8 169457 428.3 762775order assist timing comparisons, use set problem instancesSadler Gervet (2004). consider sets values H(l, d, w) l {6, 7, 8, 9, 10},{4, 6, 8, 10, 12}, w {3, 4, 5, 6, 7, 8}, < l w l (triviallyone solution l none w > l). 62 testcases; almostidenticalin particular testcases H(l, d, w) H(l, d, l w) solutions differcomplementation bits. ROBDD-based solver solve seven testcases (namely H(9, 4, 4), H(9, 4, 5), H(10, 4, 3), H(10, 4, 4), H(10, 4, 5), H(10, 4, 6), H(10, 4, 7)),reality contains three pairs mirror image testcases.Since many results list testcase individually, performance statisticstestcases solvers able solve shown Table 7. casessolved least one ROBDD-based solvers shownTable 8.Sadler Gervet (2004) report results problem using set bounds lexicographic bounds solvers implemented ECLi PSe . solvers able solve 50testcases time limit 240 seconds testcase. individual testcases tookupwards 100 seconds. contrast, ROBDD-based domain solver capable solving 55 testcases 76.4 seconds total. Clearly case enforcing domain consistencybrings considerable reduction search space, leading highly efficient solver.148fiSolving Set Constraint Satisfaction Problems using ROBDDsMoreover, set bounds lexicographic bounds solvers implemented usingROBDD platform appear perform considerably better Sadler Gervet.Due graphical nature presentation difficult quantify performance difference; exact figures presented two testcasesnamely H(9, 4, 7)H(10, 6, 7). testcase H(9, 4, 7) ROBDD set bounds lexicographic boundssolvers found proved optimal solution 0.6 0.3 seconds respectively,compared > 240 167.1 seconds respectively quoted bounds lexicographic solvers Sadler Gervet. Similarly H(10, 6, 7) ROBDD set boundslexicographic bounds solvers found proved optimal solution 1.9 1.1 secondsrespectively, compared > 240 98.5 seconds. Given dramatic performancedifference, appears additional modeling flexibility ROBDD-based solver provides substantial performance gain.noted performance results reported Sadler Gervet runslightly slower machine (a 2 Ghz Pentium 4 machine). Nonetheless, contributionperformance difference due machine speed dwarfed performance gaptwo solvers.7.4 Balanced Academic CurriculaBalanced Academic Curriculum problem (problem prob030 CSPLib) involves planning academic curriculum sequence academic periods order providebalanced load period.curriculum consists courses (1 m) n academic periods. courseset prerequisites associated academic load ti . Every course must assignedexactly one period. given period total number courses must leastminimum number c maximum number d. addition, within givenperiod total academic load courses must least minimum loadmaximum load b. Let R set prequisite pairs hi, ji, jcourses. Prerequisite relationships must observed, pair courses hi, ji R,course scheduled period p, course j must scheduled period strictlyprior p.model problem using set variables set constraints proposed Hnichet al. (2002), although experimental results presented model.primal model, use one set variable Si per academic period. Si representsset courses assigned academic period i, k Si course k assignedperiod i. model problem using following constraints:(S1) Every course taken exactly once: partition(S1 , . . . , Sn )(S2) number courses period c d:ni=1 ((c |Si |) (|Si | d))(S3) total academic load period b:ni=1 ((a wsum(Si , ht1 , . . . , tm i)) (wsum(Si , ht1 , . . . , tm i) b))(S4) Prerequisitesrespected:V/ Sj ))ni=1 ij=1 ( hc,piR (p Si ) (c149fiHawkins, Lagoon, & Stuckeygeneral partition wsum constraints primal set modellarge, making domain propagation impractical.addition presenting results primal model, Choi et al. (2003) demonstratedsubstantial performance improvement obtained problemuse redundant models together channelling constraints.obtain better results dual set model, additional set variablesintroduced model course. define set variables Xi (1 m) representingcourse, k Xi course assigned period k. definefollowing constraints:n(CX) Channelling constraints:i=1 j=1 (i Sj ) (j Xi )(X1) course may assigned one period:i=1 |Xi | = 1(X2) Prerequisites respected: hi, ji R lexlt(Xj , Xi )define dual model consist constraints {S2, S3, CX, X1, X2}. ConstraintsS1 S4 longer required, since propagation redundant.Unfortunately, dual model performs better primal set model, stillincapable proving optimality solutions problems. obtainstronger propagation introducing redundant global constraints total academicload number courses academic periods, suggested Choi et al. (2003).academic period j define two integer variables lj , representing academicload period j qj , representing number courses period j. definefollowing constraints new integer variables:(CI1) Channeling constraints li : ni=1 wsum(Si , ht1 , . . . , tm i) = li(CI2) Channeling constraints qi : ni=1 |Si | = qi(I1) Range constraints li : ni=1 (a li ) (li b)(I2) Range constraints qi : ni=1 (c qi ) (qi d)PnPn(I3) loads undertaken:i=1 tii=1 lj =Pn(I4) courses must taken:i=1 qj =define hybrid dual model consisting constraints {CX, X1, X2,CI1, CI2, I1, I2, I3, I4}. Note none original constraints S1S4 remain.completeness also possible define hybrid primal model consisting constraints{S1, S4, CI1, CI2, I1, I2, I3, I4}, although large ROBDD sizes make domainpropagation impractical.Experimental results Balanced Academic Curriculum problem shown Table 9. timing results Hybrid Dual model comparable best resultsobtained Hnich et al. (2002) Choi et al. (2003). number failures requiredsolve problem orders magnitude smaller best results presented eitherpaper, emphasising value domain propagation case. examples also showcase LU+Lex solver competitive clearly robust solverdifferent models.150fiSolving Set Constraint Satisfaction Problems using ROBDDsTable 9: Performance results Balanced Academic Curriculum Problem 8, 1012 period problems. first column contains number periods,second column contains model type (HD=hybrid dual, D=dual, P=primal,HP=hybrid primal), third column contains maximum load per periodb. cases sequential smallest-element-in-set labeling method usedProblemBoundsDomain LU+R LU+Lextime fails time fails time time fails/sHD8PHPHD10PHPHD12PHP/s160.3178.1 5586 1.718 35.7 30430 1.716177.7 5348 1.118 32.8 29781 1.216176.0 535318 16.3 2978116176.8 558618 19.3 30431130.314 17.2 11439 1.3152.1 630 1.41314 26.8 21103 1.0152.1 711 1.01314 14.7 21105153.5 7111314 11.8 11440153.6 630161.1176.0186.1 235 8.11617186.3 220 6.8161718 101.7 225161718 100.9 236/s03535021210944151/s0.30.302.71.033.01.051.20.631.30.7513.9 204653.1 264310.3012.8 151069.8 261450.30.301.50.921.70.911.60.621.60.6153.3 162759.65930.4025.6 467210.6 5161.10.909.33.099.23.449.03.04153.8 2243.40216.8 526166.0 224LU+Cardtime fails/s2.332.351.731.6532.7 475761.2 2962840.5 541070.5 301412.622.612.422.1152.1 1177231.5 51546.9 577331.753315.7413.14fiHawkins, Lagoon, & StuckeySteiner system S(2, 3, 15)500DomainBoundsLex BoundsCard Bounds1500Total BDD sizelog(Total Domain Size)400300200DomainSplitBoundsLex BoundsCard Bounds1000500100001002003000100Labelling step200300Labelling stepSocial Golfers problem 4-5-41000Total BDD sizelog(Total Domain Size)DomainSplitBoundsLex BoundsCard BoundsDomainBoundsLex BoundsCard Bounds3002005001000020406080100Labelling step020406080100Labelling stepFigure 17: Comparison total domain total ROBDD sizes labeling step setbounds, set domain, split set domain, set lexicographic bounds, setcardinality bounds solvers Steiner System S(2, 3, 15) Social Golfersproblem 4-5-4. Note axes total domain size graphslogarithmic scale (base 2).7.5 Comparing Propagation Performance Solversinstructive compare propagation performance various ROBDD-basedsolvers graphically. pick two small examples, namely Steiner System S(2, 3, 15)Social Golfers problem 4-5-4, using default labeling problem, graphBDD domain sizes number labeling steps time.152fiSolving Set Constraint Satisfaction Problems using ROBDDs500log(Total Domain Size)400300200DomainSplitBoundsLex BoundsCard Bounds300log(Total Domain Size)DomainSplitBoundsLex BoundsCard Bounds20010010000120.2Time/s0.40.60.8Time/sSteiner system S(2, 3, 15)Social Golfers problem 4-5-4Figure 18: Comparison total domain size time set bounds, set domain, split setdomain, set lexicographic bounds, set cardinality bounds solversSteiner System S(2, 3, 15) Social Golfers problem 4-5-4. Noteaxes logarithmic scale (base 2).Figure 17 depicts total domain sizes total ROBDD sizes (total numberinternal nodes) vary labeling step solvers Steiner SystemS(2, 3, 15) Social Golfers problem 4-5-4. particular, observe domainsplit-domain propagators effective reducing domain size thusrestricting search space, although maintaining domain consistency costly duesize ROBDDs required representing arbitrary domains. seenROBDD size labeling step graph, notably case Social Golfersproblem 4-5-4. lexicographic bounds solver next effective domain sizereduction, requires smaller number ROBDD nodes store boundsdomain cardinality bounds solvers. bounds solver clearly weakest termsdomain size reduction, opposed solvers starts zero size domainrepresentation builds slowly ROBDDs representing answer.concerned strength propagator abstract, sinceefficiency solver whole dependent propagation labelingprocesses. Figure 18 depicts graphs domain size time propagators discussed paper. see effective propagatornecessarily lead efficient set solver. Despite comparatively weak propagation,set cardinality bounds solvers lead fastest reduction domain size per unittime. Nonetheless, experimental timing results given demonstrate hardercases additional cost maintaining domain consistency lexicographic boundsjustified consequent reduction search space.153fiHawkins, Lagoon, & StuckeyInterestingly see graphs Figure 18 initial domain reductionlabeling, gap time 0 line starts, significantpart computation. particular, one weaknesses lexicographic boundssolver large time required reach initial fixpoint lexicographic boundspropagation. practical applications might preferable implement hybrid solverutilises one propagators generate initial domains, useslexicographic bounds propagator labeling.8. Conclusiondemonstrated ROBDDs form highly flexible platform constructing setconstraint solvers. ROBDDs allow compact representation many set domainsset constraints, making effective basis efficient set solver. Since ROBDDsrepresent arbitrary Boolean formul easily conjoin existentially quantifythem, permitting removal intermediate variables making constructionglobal constraints trivial. demonstrated efficiently enforce various levelsconsistency, including set domain, set bounds, cardinality bounds lexicographic boundsconsistency. Finally, presented experimental results demonstrateROBDD-based solver outperforms common set solvers wide variety standardset constraint satisfaction problems.single set solver uniformly better others. many examples simplebounds propagation best approach, cases, particularly asksolutions, domain consistency preferable. also examples lexicographic bounds cardinality bounds best approach. split-domain approachsomewhat disappointing, since appears many cases overheadcomplicated calculation (Equation 6) rewarded terms smaller ROBDD sizes.future plan explore robust general set constraint solver dynamicallychooses level consistency maintain examining big domain ROBDDsbecoming search progresses.ReferencesAndersen, H. R. (1998). introduction Binary Decision Diagrams. [Online, accessed30 July 2004]. http://www.itu.dk/people/hra/notes-index.html.Apt, K. R. (1999). essence constraint propagation. Theoretical Computer Science,221 (12), 179210.Azevedo, F. (2002). Constraint Solving Multi-valued Logics. Ph.D. thesis, Faculdadede Ciencias e Tecnologia, Universidade Nova de Lisboa.Bagnara, R. (1996). reactive implementation Pos using ROBDDs. Procs. PLILP,Vol. 1140 LNCS, pp. 107121. Springer.Bessiere, C., Hebrard, E., Hnich, B., & Walsh, T. (2004). Disjoint, partition intersectionconstraints set multiset variables. Wallace, M. (Ed.), Proceedings154fiSolving Set Constraint Satisfaction Problems using ROBDDs10th International Conference Principles Practice Constraint Programming,Vol. 3258 LNCS, pp. 138152. Springer-Verlag.Bryant, R. E. (1986). Graph-based algorithms Boolean function manipulation. IEEETrans. Comput., 35 (8), 677691.Bryant, R. E. (1992). Symbolic Boolean manipulation ordered binary-decision diagrams. ACM Comput. Surv., 24 (3), 293318.Choi, C., Lee, J., & Stuckey, P. J. (2003). Propagation redundancy redundant modelling.Rossi, F. (Ed.), Proceedings 9th International Conference PrinciplesPractices Constraint Programming, Vol. 2833 LNCS, pp. 229243. SpringerVerlag.Gent, I. P., Walsh, T., & Selman, B. (2004). CSPLib: problem library constraints.[Online, accessed 24 Jul 2004]. http://www.csplib.org/.Gervet, C. (1997). Interval propagation reason sets: Definition implementationpractical language. Constraints, 1 (3), 191246.Hawkins, P., Lagoon, V., & Stuckey, P. (2004). Set bounds (split) set domain propagation using ROBDDs. Webb, G., & Yu, X. (Eds.), AI 2004: Advances ArtificialIntelligence, 17th Australian Joint Conference Artificial Intelligence, Vol. 3339LNCS, pp. 706717. Springer-Verlag.Hnich, B., Kiziltan, Z., & Walsh, T. (2002). Modelling balanced academic curriculumproblem. Proceedings Fourth International Workshop Integration AITechniques Constraint Programming Combinatorial Optimization Problems, pp. 121131.IC-PARC (2003). ECLiPSe constraint logic programming system. [Online, accessed 31May 2004]. http://www.icparc.ic.ac.uk/eclipse/.ILOG (2004). ILOG Solver. [Online, accessed 30 Aug 2004]. http://www.ilog.com/.Kiziltan, Z., & Walsh, T. (2002). Constraint programming multisets. Proceedings2nd International Workshop Symmetry Constraint Satisfaction Problems(SymCon-02).Lagoon, V., & Stuckey, P. (2004). Set domain propagation using ROBDDs. Wallace, M.(Ed.), Proceedings 10th International Conference Principles PracticeConstraint Programming, Vol. 3258 LNCS, pp. 347361. Springer-Verlag.van Lint, J. H., & Wilson, R. M. (2001). Course Combinatorics (2nd edition). Cambridge University Press.Mailharro, D. (1998). classification constraint-based framework configuration.Artificial Intelligence Engineering Design, Analysis Manufacturing, 12, 383397.Muller, T. (2001). Constraint Propagation Mozart. Doctoral dissertation, Universitat desSaarlandes, Naturwissenschaftlich-Technische Fakultat I, Fachrichtung Informatik,Saarbrucken, Germany.155fiHawkins, Lagoon, & StuckeyMuller, T., & Muller, M. (1997). Finite set constraints Oz. Bry, F., Freitag, B., &Seipel, D. (Eds.), Workshop Logische Programmierung, Vol. 13. Technische UniversitatMunchen.Puget, J.-F. (1992). PECOS: high level constraint programming language. ProceedingsSPICIS92, Singapore.Sadler, A., & Gervet, C. (2001). Global reasoning sets. FORMUL01 workshopmodelling problem formulation, conjunction CP01.Sadler, A., & Gervet, C. (2004). Hybrid set domains strengthen constraint propagationreduce symmetries. Wallace, M. (Ed.), Proceedings 10th InternationalConference Principles Practice Constraint Programming, Vol. 3258 LNCS,pp. 604618. Springer-Verlag.Somenzi, F. (2004). CUDD: Colorado University Decision Diagram package. [Online, accessed 31 May 2004]. http://vlsi.colorado.edu/~fabio/CUDD/.Somogyi, Z., Henderson, F., & Conway, T. (1996). execution algorithm Mercury,efficient purely declarative logic programming language. Journal Logic Programming, 29 (13), 1764.156fiJournal Artificial Intelligence Research 24 (2005) 49-79Submitted 09/04; published 07/05Framework Sequential Planning Multi-Agent SettingsPiotr J. GmytrasiewiczPrashant DoshiPIOTR @ CS . UIC . EDUPDOSHI @ CS . UIC . EDUDepartment Computer ScienceUniversity Illinois Chicago851 S. Morgan StChicago, IL 60607Abstractpaper extends framework partially observable Markov decision processes (POMDPs)multi-agent settings incorporating notion agent models state space. Agentsmaintain beliefs physical states environment models agents,use Bayesian updates maintain beliefs time. solutions map belief states actions.Models agents may include belief states related agent types consideredgames incomplete information. express agents autonomy postulating models directly manipulable observable agents. show important propertiesPOMDPs, convergence value iteration, rate convergence, piece-wise linearity convexity value functions carry framework. approach complementstraditional approach interactive settings uses Nash equilibria solution paradigm.seek avoid drawbacks equilibria may non-unique captureoff-equilibrium behaviors. cost represent, process continuouslyrevise models agents. Since agents beliefs may arbitrarily nested, optimal solutions decision making problems asymptotically computable. However, approximatebelief updates approximately optimal plans computable. illustrate framework usingsimple application domain, show examples belief updates value functions.1. Introductiondevelop framework sequential rationality autonomous agents interactingagents within common, possibly uncertain, environment. use normative paradigmdecision-theoretic planning uncertainty formalized partially observable Markov decisionprocesses (POMDPs) (Boutilier, Dean, & Hanks, 1999; Kaelbling, Littman, & Cassandra, 1998;Russell & Norvig, 2003) point departure. Solutions POMDPs mappingsagents beliefs actions. drawback POMDPs comes environments populatedagents agents actions represented implicitly environmental noisewithin the, usually static, transition model. Thus, agents beliefs another agent partsolutions POMDPs.main idea behind formalism, called interactive POMDPs (I-POMDPs), allowagents use sophisticated constructs model predict behavior agents. Thus,replace flat beliefs state space used POMDPs beliefs physicalenvironment agent(s), possibly terms preferences, capabilities,beliefs. beliefs could include others beliefs others, thus nested arbitrarylevels. called interactive beliefs. space interactive beliefs richupdating beliefs complex updating flat counterparts, use valuec2005AI Access Foundation. rights reserved.fiG MYTRASIEWICZ & OSHIfunction plots show solutions I-POMDPs least good as, usual cases superiorto, comparable solutions POMDPs. reason intuitive maintaining sophisticated modelsagents allows refined analysis behavior better predictions actions.I-POMDPs applicable autonomous self-interested agents locally compute actions execute optimize preferences given believe interactingothers possibly conflicting objectives. approach using decision-theoretic framework solution concept complements equilibrium approach analyzing interactions usedclassical game theory (Fudenberg & Tirole, 1991). drawback equilibria couldmany (non-uniqueness), describe agents optimal actions if, when,equilibrium reached (incompleteness). approach, instead, centered optimalitybest response anticipated action agent(s), rather stability (Binmore, 1990;Kadane & Larkey, 1982). question whether, circumstances, kindequilibria could arise solutions I-POMDPs currently open.approach avoids difficulties non-uniqueness incompleteness traditional equilibrium approach, offers solutions likely better solutions traditionalPOMDPs applied multi-agent settings. advantages come cost processingmaintaining possibly infinitely nested interactive beliefs. Consequently, approximate beliefupdates approximately optimal solutions planning problems computable general.define class finitely nested I-POMDPs form basis computable approximations infinitely nested ones. show number properties facilitate solutions POMDPs carryfinitely nested I-POMDPs. particular, interactive beliefs sufficient statisticshistories agents observations, belief update generalization update POMDPs,value function piece-wise linear convex, value iteration algorithm convergesrate.remainder paper structured follows. start brief review relatedwork Section 2, followed overview partially observable Markov decision processesSection 3. There, include simple example tiger game. introduce conceptagent types Section 4. Section 5 introduces interactive POMDPs defines solutions.finitely nested I-POMDPs, properties introduced Section 6. continueexample application finitely nested I-POMDPs multi-agent version tiger gameSection 7. There, show examples belief updates value functions. concludebrief summary current research issues Section 8. Details proofsAppendix.2. Related Workwork draws prior research partially observable Markov decision processes,recently gained lot attention within AI community (Smallwood & Sondik, 1973; Monahan,1982; Lovejoy, 1991; Hausktecht, 1997; Kaelbling et al., 1998; Boutilier et al., 1999; Hauskrecht,2000).formalism Markov decision processes extended multiple agents giving risestochastic games Markov games (Fudenberg & Tirole, 1991). Traditionally, solution conceptused stochastic games Nash equilibria. recent work AI follows tradition(Littman, 1994; Hu & Wellman, 1998; Boutilier, 1999; Koller & Milch, 2001). However,mentioned before, pointed game theorists (Binmore, 1990; Kadane &50fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGSLarkey, 1982), Nash equilibria useful describing multi-agent system when, if,reached stable state, solution concept sufficient general control paradigm.main reasons may multiple equilibria clear way choose among(non-uniqueness), fact equilibria specify actions cases agents believeagents may act according equilibrium strategies (incompleteness).extensions POMDPs multiple agents appeared AI literature recently (Bernstein,Givan, Immerman, & Zilberstein, 2002; Nair, Pynadath, Yokoo, Tambe, & Marsella, 2003).called decentralized POMDPs (DEC-POMDPs), related decentralized controlproblems (Ooi & Wornell, 1996). DEC-POMDP framework assumes agents fully cooperative, i.e., common reward function form team. Furthermore, assumedoptimal joint solution computed centrally distributed among agents execution.game-theoretic side, motivated subjective approach probabilitygames (Kadane & Larkey, 1982), Bayesian games incomplete information (see Fudenberg &Tirole, 1991; Harsanyi, 1967, references therein), work interactive belief systems (Harsanyi,1967; Mertens & Zamir, 1985; Brandenburger & Dekel, 1993; Fagin, Halpern, Moses, & Vardi,1995; Aumann, 1999; Fagin, Geanakoplos, Halpern, & Vardi, 1999), insights researchlearning game theory (Fudenberg & Levine, 1998). approach, closely related decisiontheoretic (Myerson, 1991), epistemic (Ambruster & Boge, 1979; Battigalli & Siniscalchi, 1999;Brandenburger, 2002) approach game theory, consists predicting actions agents givenavailable information, choosing agents action (Kadane & Larkey, 1982).Thus, descriptive aspect decision theory used predict others actions, prescriptiveaspect used select agents optimal action.work presented also extends previous work Recursive Modeling Method (RMM)(Gmytrasiewicz & Durfee, 2000), adds elements belief update sequential planning.3. Background: Partially Observable Markov Decision Processespartially observable Markov decision process (POMDP) (Monahan, 1982; Hausktecht, 1997;Kaelbling et al., 1998; Boutilier et al., 1999; Hauskrecht, 2000) agent definedPOMDPi = hS, Ai , Ti , , Oi , Ri(1)where: set possible states environment. Ai set actions agent execute. Titransition function Ti : Ai [0, 1] describes results agent actions.set observations agent make. Oi agents observation function Oi : Ai[0, 1] specifies probabilities observations given agents actions resulting states. Finally,Ri reward function representing agent preferences R : Ai <.POMDPs, agents belief state represented probability distribution S.Initially, observations actions take place, agent (prior) belief, b 0i .time steps, t, assume agent + 1 observations performed actions 1 .assembled agent observation history: h ti = {o0i , o1i , .., ot1, oi } time t. LetHi denote set observation histories agent i. agents current belief, b ti S,continuously revised based new observations expected results performed actions. turns1. assume action taken every time step; without loss generality since actions maybeNo-op.51fiG MYTRASIEWICZ & OSHIagents belief state sufficient summarize past observation historyinitial belief; hence called sufficient statistic.2t1belief update takes account changes initial belief, b t1, due action, ai , executedtime 1, new observation, oi . new belief, bi , current state st , is:bti (st ) = Oi (oti , st , at1)Xbit1 (st1 )Ti (st , ati , st1 )(2)st1normalizing constant.convenient summarize update performed statesbti = SE(bit1 , at1, oi ) (Kaelbling et al., 1998).3.1 Optimality Criteria Solutionsagents optimality criterion, OCi , needed specify rewards acquired timehandled. Commonly used criteria include:finite horizon criterion,Pagent maximizes expected value sumfollowing rewards: E( Tt=0 rt ). Here, rt reward obtained time lengthhorizon. denote criterion fhT .AnPinfinite horizon criterion discounting, according agent maximizesE(t=0 rt ), 0 < < 1 discount factor. denote criterion ih .infinite horizon criterion averaging, according agent maximizesaverage reward per time step. denote ihAV .follows, concentrate infinite horizon criterion discounting, approach easily adapted criteria.utility associated belief state, bi composed best immediate rewardsobtained bi , together discounted expected sum utilities associatedbelief states following bi :U (bi ) = maxai AiXbi (s)Ri (s, ai ) +XP r(oi |ai , bi )U (SEi (bi , ai , oi ))oisS(3)Value iteration uses Equation 3 iteratively obtain values belief states longer timehorizons. step value iteration error current value estimate reducedfactor least (see example Russell & Norvig, 2003, Section 17.2.) optimal action, ,element set optimal actions, OP (bi ), belief state, defined as:OP (bi ) = argmaxai AiXbi (s)Ri (s, ai ) +XoisS2. See (Smallwood & Sondik, 1973) proof.52P r(oi |ai , bi )U (SE(bi , ai , oi ))(4)fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGSLOL10Value Function(U)8642000.20.40.60.81pp_i(TL)(TL)POMDP noisePOMDPFigure 1: value function single agent tiger game time horizon length 1, OC = fh1 .Actions are: open right door - OR, open left door - OL, listen - L. valuetime horizon value function POMDP noise factor identical singleagent POMDP.3.2 Example: Tiger Gamebriefly review POMDP solutions tiger game (Kaelbling et al., 1998). purposebuild insights POMDP solutions provide simple case illustrate solutionsinteractive versions game later.traditional tiger game resembles game-show situation decision makerchoose open one two doors behind lies either valuable prize dangerous tiger.Apart actions open doors, subject option listening tigers growlcoming left, right, door. However, subjects hearing imperfect, givenpercentages (say, 15%) false positive false negative occurrences. Following (Kaelbling et al.,1998), assume value prize 10, pain associated encounteringtiger quantified -100, cost listening -1.value function, Figure 1, shows values various belief states agents timehorizon equal 1. Values beliefs based best action available belief state,specified Eq. 3. state certainty valuable agent knows locationtiger open opposite door claim prize certainly awaits. Thus,probability tiger location 0 1, value 10. agent sufficiently uncertain,best option play safe listen; value -1. agent indifferent openingdoors listening assigns probabilities 0.9 0.1 location tiger.Note that, time horizon equal 1, listening provide useful informationsince game continue allow use information. longer time horizonsbenefits results listening results policies better ranges initial belief.Since value function composed values corresponding actions, linear prob53fiG MYTRASIEWICZ & OSHIL\();L\(GL),OL\(GR)L\();L\(*)L\();OR\(GL),L\(GR)L\();OR\(*)OR\();L\(*)L\();OL\(*)OL\();L\(*)8Value Function(U)6420-200.20.40.60.81pp_i(TL)(TL)POMDP noisePOMDPFigure 2: value function single agent tiger game compared agent facing noise factor, horizon length 2. Policies corresponding value lines conditional plans.Actions, L, OL, conditioned observational sequences parenthesis.example L\();L\(GL),OL\(GR) denotes plan perform listening action, L,beginning (list observations empty), another L observation growlleft (GL), open left door, OL, observation GR. wildcardusual interpretation.ability tiger location, value function property piece-wise linear convex(PWLC) horizons. simplifies computations substantially.Figure 2 present comparison value functions horizon length 2 singleagent, agent facing noisy environment. presence noise coulddue another agent opening doors listening probabilities. 3 Since POMDPsinclude explicit models agents, noise actions included transitionmodel, .Consequences folding noise two-fold. First, effectiveness agents optimalpolicies declines since value hearing growls diminishes many time steps. Figure 3 depictscomparison value functions horizon length 3. Here, example, two consecutive growlsnoisy environment valuable agent knows acting alone since noisemay perturbed state system growls. time horizon length 1noise matter value vectors overlap, Figure 1.Second, since presence another agent implicit static transition model, agentcannot update model agents actions repeated interactions. effect becomes important time horizon increases. approach addresses issue allowingexplicit modeling agent(s). results policies superior quality, showSection 7. Figure 4 shows policy agent facing noisy environment time horizon 3.compare corresponding I-POMDP policy Section 7. Note slightly different3. assumed that, due noise, either door opens probabilities 0.1 turn, nothing happensprobability 0.8. explain origin assumption Section 7.54fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGSL\();L\(*);OL\(GR;GR),L\(?)L\();L\(GL),OL\(GR);OL\(GL;GR),L\(?)L\();L\(*);OR\(GL;GL),L\(?)L\();OR\(GL),L\(GR);OR\(GR;GL),L\(?)L\();L\(*);OR\(GL;GL),OL\(GR;GR),L\(?)OR\();L\(*);L\(*)L\();L\(*);OR\(*)OL\();L\(*);L\(*)L\();L\(*);OL\(*)8Value Function(U)765432100.20.40.60.81p (TL)p_i(TL)POMDP noisePOMDPFigure 3: value function single agent tiger game compared agent facing noise factor,horizon length 3. ? description policy standsperceptual sequences yet listed description policy.[00.045)OL*[0.0450.135) [0.1350.175) [0.1750.825)LLGRGLGRLGRGL*OLLGRLGLGRGL*GLLGL[0.8650.955) [0.9551]LGROL[0.8250.865)L*LGRGL*Figure 4: policy graph corresponding value function POMDP noise depictedFig. 3.55fiG MYTRASIEWICZ & OSHIpolicy without noise example Kaelbling, Littman Cassandra (1998) duedifferences value functions.4. Agent Types FramesPOMDP definition includes parameters permit us compute agents optimal behavior, 4conditioned beliefs. Let us collect implementation independent factors constructcall agent type.Definition 1 (Type). type agent is, = hbi , Ai , , Ti , Oi , Ri , OCi i, bi agentstate belief (an element (S)), OCi optimality criterion, rest elementsdefined before. Let set agent types.Given type, , assumption agent Bayesian-rational, set agents optimalactions denoted OP (i ). next section, generalize notion type situations include interactions agents; coincides notion type usedBayesian games (Fudenberg & Tirole, 1991; Harsanyi, 1967).convenient define notion frame, bi , agent i:b setDefinition 2 (Frame). frame agent is, bi = hAi , , Ti , Oi , Ri , OCi i. Letagent frames.brevity one write type consisting agents belief together frame: =hbi , bi i.context tiger game described previous section, agent type describesagents actions results, quality agents hearing, payoffs, belieftiger location.Realistically, apart implementation-independent factors grouped type, agents behavior may also depend implementation-specific parameters, like processor speed, memoryavailable, etc. included (implementation dependent, complete) type, increasing accuracy predicted behavior, cost additional complexity. Definition usecomplete types topic ongoing work.5. Interactive POMDPsmentioned, intention generalize POMDPs handle presence agents.including descriptions agents (their types example) state space.simplicity presentation, consider agent i, interacting one agent, j.formalism easily generalizes larger number agents.Definition 3 (I-POMDP). interactive POMDP agent i, I-POMDPi , is:I-POMDPi = hISi , A, Ti , , Oi , Ri(5)4. issue computability solutions POMDPs subject much research (Papadimitriou & Tsitsiklis,1987; Madani, Hanks, & Condon, 2003). obvious importance one uses POMDPs model agents;return issue later.56fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGSwhere:ISi set interactive states defined ISi = Mj ,5 interacting agent i,set states physical environment, Mj set possible models agentj. model, mj Mj , defined triple mj = hhj , fj , Oj i, fj : Hj (Aj )agent js function, assumed computable, maps possible histories js observationsdistributions actions. hj element Hj , Oj function specifying wayenvironment supplying agent input. Sometimes write model j mj = hhj ,b j i,b j consists fj Oj . convenient subdivide set models two classes.subintentional models, SMj , relatively simple, intentional models, IMj , usenotion rationality model agent. Thus, Mj = IMj SMj .Simple examples subintentional models include no-information model fictitious playmodel, history independent. no-information model (Gmytrasiewicz & Durfee,2000) assumes agents actions executed equal probability. Fictitiousplay (Fudenberg & Levine, 1998) assumes agent chooses actions according fixedunknown distribution, original agents prior belief distribution takes formDirichlet distribution.6 example powerful subintentional model finite statecontroller.intentional models sophisticated ascribe agent beliefs,preferences rationality action selection.7 Intentional models thus js types, j = hbj , bj i,assumption agent j Bayesian-rational.8 Agent js belief probability distributionstates environment models agent i; b j (S Mi ). notion typeuse coincides notion type game theory, defined consistingagent private information relevant decision making (Harsanyi, 1967; Fudenberg& Tirole, 1991). particular, agents beliefs private information, types involvepossibly infinitely nested beliefs others types beliefs others (Mertens & Zamir,1985; Brandenburger & Dekel, 1993; Aumann, 1999; Aumann & Heifetz, 2002). 9 relatedrecursive model structures prior work (Gmytrasiewicz & Durfee, 2000). definitioninteractive state space consistent notion completely specified state space put forwardAumann (1999). Similar state spaces proposed others (Mertens & Zamir, 1985;Brandenburger & Dekel, 1993).= Ai Aj set joint moves agents.Ti transition model. usual way define transition probabilities POMDPsassume agents actions change aspect state description. case IPOMDPs, would mean actions modifying aspect interactive states, includingagents observation histories functions, or, modeled intentionally, beliefsreward functions. Allowing agents directly manipulate agents ways, however,violates notion agents autonomy. Thus, make following simplifying assumption:15. agents, say N > 2, ISi = Nj=1 Mj6. Technically, according notation, fictitious play actually ensemble models.7. Dennet (1986) advocates ascribing rationality agent(s), calls assuming intentional stance towardsthem.8. Note space types far richer computable models. particular, since set computablemodels countable set types uncountable, many types computable models.9. Implicit definition interactive beliefs assumption coherency (Brandenburger & Dekel, 1993).57fiG MYTRASIEWICZ & OSHIModel Non-manipulability Assumption (MNM): Agents actions changeagents models directly.Given simplification, transition model defined : [0, 1]Autonomy, formalized MNM assumption, precludes, example, direct mind control,implies agents belief states changed indirectly, typically changingenvironment way observable them. words, agents beliefs change, like POMDPs,result belief update observation, direct result agentsactions.10defined POMDP model.Oi observation function. defining function make following assumption:Model Non-observability (MNO): Agents cannot observe others models directly.Given assumption observation function defined : [0, 1].MNO assumption formalizes another aspect autonomy agents autonomousobservations functions, beliefs properties, say preferences, intentionalmodels, private agents cannot observe directly. 11Ri defined Ri : ISi <. allow agent preferences physicalstates models agents, usually physical state matter.mentioned, see interactive POMDPs subjective counterpart objective external view stochastic games (Fudenberg & Tirole, 1991), also followed workAI (Boutilier, 1999) (Koller & Milch, 2001) decentralized POMDPs (Bernstein et al.,2002; Nair et al., 2003). Interactive POMDPs represent individual agents point viewenvironment agents, facilitate planning problem solving agentsindividual level.5.1 Belief Update I-POMDPsshow that, POMDPs, agents beliefs interactive states sufficientstatistics, i.e., fully summarize agents observation histories. Further, need showbeliefs updated agents action observation, solutions defined.t1new belief state, bti , function previous belief state, bt1, last action, ai ,new observation, oi , POMDPs. two differences complicate beliefupdate compared POMDPs. First, since state physical environment dependsactions performed agents prediction physical state changesmade based probabilities various actions agent. probabilities othersactions obtained based models. Thus, unlike Bayesian stochastic games,assume actions fully observable agents. Rather, agents attempt inferactions agents performed sensing results environment. Second, changesmodels agents included update. reflect others observationsand, modeled intentionally, update agents beliefs. case, agentupdate beliefs agent based anticipates agent observes10. possibility agents influence observational capabilities agents accommodatedincluding factors change sensing capabilities set S.11. Again, possibility agents observe factors may influence observational capabilities agentsallowed including factors S.58fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGSupdates. could expected, update possibly infinitely nested beliefothers types is, general, asymptotically computable.Proposition 1. (Sufficiency) interactive POMDP agent i, current belief, i.e., probability distribution set Mj , sufficient statistic past history observations.t1next proposition defines agent belief update function, b ti (ist ) = P r(ist |oti , at1, bi ),ist ISi interactive state. use belief state estimation function, SE , abt1breviation belief updates individual states bti = SEi (bt1, ai , oi ).t1 t1t1t1(bi , ai , oi , bi ) stand P r(bti |bi , ai , oti ). also define settype-dependent optimal actions agent, OP (i ).Proposition 2. (Belief Update) MNM MNO assumptions, belief update functioninteractive POMDP hISi , A, Ti , , Oi , Ri i, mj ist intentional, is:bti (ist ) =TiPt1 )bt1(isist1 :mb t1=bjtjPt1t1(s , , st )otjPt1t1 , ot )P r(at1j |j )Oi (s ,at1jt1 t1t1 , ot )(bj j , aj , oj , bj )Oj (s ,j(6)=mb tj ,mj ist subintentional first summation extends ist1 :b t1jt1t1t1t1 t1P r(at1j |j ) replaced P r(aj |mj ), jt (bj , aj , oj , bj ) replacedKronecker delta function K (APPEND(ht1j , oj ), hj ).Above, bt1btj belief elements jt1 jt , respectively, normalizing constant,jt1t1P r(at1Bayesian rational agent described typej |j ) probability ajt1t11j . probability equal |OP (j )| aj OP (j ), equal zero otherwise.define OP Section 5.2.12 case js subintentional model, = (s, mj ), ht1jrespectively, observationhtj observation histories part mt1,jjjt1t1t1function mtj , P r(at1|m)probabilityassignedjjjj . APPEND returnsstring second argument appended first. proofs propositionsAppendix.Proposition 2 Eq. 6 lot common belief update POMDPs,expected. depend agent observation transition functions. However, since agentobservations also depend agent js actions, probabilities various actions jincluded (in first line Eq. 6.) Further, since update agent js model dependsj observes, probabilities various observations j included (in second lineEq. 6.) update js beliefs represented j term. belief update easilygeneralized setting one agents co-exist agent i.P12. agents prior belief ISi given probability density functionist1 replaced:, otj , btj ) takes form Dirac delta function argument bt1, at1integral. case jt (bt1jjj, otj ) btj )., at1(SEjt (bt1jj59fiG MYTRASIEWICZ & OSHI5.2 Value Function Solutions I-POMDPsAnalogously POMDPs, belief state I-POMDP associated value reflecting maximum payoff agent expect belief state:PPbERi (is, ai )bi (is) +U (i ) = maxP r(oi |ai , bi )U (hSEi (bi , ai , oi ), i)(7)ai AioiPwhere, ERi (is, ai ) =aj Ri (is, ai , aj )P r(aj |mj ). Eq. 7 basis value iteration IPOMDPs.Agent optimal action, ai , case infinite horizon criterion discounting,element set optimal actions belief state, OP (i ), defined as:PPOP (i ) = argmaxERi (is, ai )bi (is) +P r(oi |ai , bi )U (hSEi (bi , ai , oi ), bi i)ai Aioi(8)case belief update, due possibly infinitely nested beliefs, step value iterationoptimal actions asymptotically computable.6. Finitely Nested I-POMDPsPossible infinite nesting agents beliefs intentional models presents obvious obstaclecomputing belief updates optimal solutions. Since models agents infinitelynested beliefs correspond agent functions computable natural considerfinite nestings. follow approaches game theory (Aumann, 1999; Brandenburger & Dekel,1993; Fagin et al., 1999), extend previous work (Gmytrasiewicz & Durfee, 2000), constructfinitely nested I-POMDPs bottom-up. Assume set physical states world S, twoagents j. Agent 0-th level beliefs, bi,0 , probability distributions S. 0-th leveltypes, i,0 , contain 0-th level beliefs, frames, analogously agent j. 0-level typesare, therefore, POMDPs.13 0-level models include 0-level types (i.e., intentional models)subintentional models, elements SM . agents first level beliefs probability distributionsphysical states 0-level models agent. agents first level types consistfirst level beliefs frames. first level models consist types upto level 1subintentional models. Second level beliefs defined terms first level models on.Formally, define spaces:ISi,0 = S,j,0 = {hbj,0 , bj : bj,0 (ISj,0 )}, Mj,0 = j,0 SMjISi,1 = Mj,0 ,j,1 = {hbj,1 , bj : bj,1 (ISj,1 )}, Mj,1 = j,1 Mj,0......ISi,l = Mj,l1 , j,l = {hbj,l , bj : bj,l (ISj,l )}, Mj,l = j,l Mj,l1Definition 4. (Finitely Nested I-POMDP) finitely nested I-POMDP agent i, I-POMDP i,l , is:I-POMDPi,l = hISi,l , A, Ti , , Oi , Ri13. 0-level types agents actions folded , R functions noise.60(9)fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGSparameter l called strategy level finitely nested I-POMDP. belief update,value function, optimal actions finitely nested I-POMDPs computed using Equation 6Equation 8, recursion guaranteed terminate 0-th level subintentional models.Agents strategic capable modeling others deeper levels (i.e., levelsstrategy level l), always boundedly optimal. such, agentscould fail predict strategy sophisticated opponent. fact computabilityagent function implies agent may suboptimal interactions pointedBinmore (1990), proved recently Nachbar Zame (1996). Intuitively,difficulty agents unbounded optimality would include capability modelagents modeling original agent. leads impossibility result due self-reference,similar Godels incompleteness theorem halting problem (Brandenburger,2002). positive note, convergence results (Kalai & Lehrer, 1993) strongly suggestapproximate optimality achievable, although applicability work remains open.mentioned, 0-th level types POMDPs. provide probability distributionsactions agent modeled level models strategy level 1. Given probabilitydistributions agents actions level-1 models solved POMDPs,provide probability distributions yet higher level models. Assume number modelsconsidered level bound number, . Solving I-POMDP i,l equivalentsolving O(M l ) POMDPs. Hence, complexity solving I-POMDPi,l PSPACE-hardfinite time horizons,14 undecidable infinite horizons, like POMDPs.6.1 Properties I-POMDPssection establish two important properties, namely convergence value iterationpiece-wise linearity convexity value function, finitely nested I-POMDPs.6.1.1 C ONVERGENCEVALUE TERATIONagent I-POMDPi,l , show sequence value functions, {U n },n horizon, obtained value iteration defined Eq. 7, converges unique fixed-point, U .Let us define backup operator H : B B U n = HU n1 , B setbounded value functions. order prove convergence result, first establishproperties H.Lemma 1 (Isotonicity). finitely nested I-POMDP value functions V U , V U ,HV HU .proof lemma analogous one due Hauskrecht (1997), POMDPs.also sketched Appendix. Another important property exhibited backup operatorproperty contraction.Lemma 2 (Contraction). finitely nested I-POMDP value functions V , U discountfactor (0, 1), ||HV HU || ||V U ||.proof lemma similar corresponding one POMDPs (Hausktecht,1997). proof makes use Lemma 1. || || supremum norm.14. Usually PSPACE-complete since number states I-POMDPs likely larger time horizon(Papadimitriou & Tsitsiklis, 1987).61fiG MYTRASIEWICZ & OSHIcontraction property H, noting space value functions alongsupremum norm forms complete normed space (Banach space), apply ContractionMapping Theorem (Stokey & Lucas, 1989) show value iteration I-POMDPs convergesunique fixed point (optimal solution). following theorem captures result.Theorem 1 (Convergence). finitely nested I-POMDP, value iteration algorithm starting arbitrary well-defined value function converges unique fixed-point.detailed proof theorem included Appendix.case POMDPs (Russell & Norvig, 2003), error iterative estimates, U n ,finitely nested I-POMDPs, i.e., ||U n U ||, reduced factor least iteration.Hence, number iterations, N , needed reach error is:N = dlog(Rmax /(1 ))/ log(1/)e(10)Rmax upper bound reward function.6.1.2 P IECEWISE L INEARITYC ONVEXITYAnother property carries POMDPs finitely nested I-POMDPs piecewiselinearity convexity (PWLC) value function. Establishing property allows us decompose I-POMDP value function set alpha vectors, represents policytree. PWLC property enables us work sets alpha vectors rather perform valueiteration continuum agents beliefs. Theorem 2 states PWLC propertyI-POMDP value function.Theorem 2 (PWLC). finitely nested I-POMDP, U piecewise linear convex.complete proof Theorem 2 included Appendix. proof similar onedue Smallwood Sondik (1973) POMDPs proceeds induction. basis caseestablished considering horizon 1 value function. Showing PWLC inductive steprequires substituting belief update (Eq. 6) Eq. 7, followed factoring beliefterms equation.7. Example: Multi-agent Tiger Gameillustrate optimal sequential behavior agents multi-agent settings apply I-POMDPframework multi-agent tiger game, traditional version described before.7.1 DefinitionLet us denote actions opening doors listening OR, OL L, before. TLTR denote states corresponding tiger located behind left right door, respectively.transition, reward observation functions depend actions agents. Again,assume tiger location chosen randomly next time step agents openeddoors current step. also assume agent hears tigers growls, GR GL,accuracy 85%. make interaction interesting added observationdoor creaks, depend action executed agent. Creak right, CR, likely due62fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGSagent opened right door, similarly creak left, CL. Silence, S, goodindication agent open doors listened instead. assume accuracycreaks 90%. also assume agents payoffs analogous single agent versionsdescribed Section 3.2 make cases comparable. Note result assumptionagents actions impact original agents payoffs directly, rather indirectlyresulting states matter original agent. Table 1 quantifies factors.hai , ajhOL,hOR,h, OLih, ORihL, LihL, LiState****TLTRTL0.50.50.50.51.00TR0.50.50.50.501.0hai , ajhOR, ORihOL, OLihOR, OLihOL, ORihL, LihL, ORihOR, LihL, OLihOL, LiTransition function: Ti = TjTL10-10010-100-1-110-1-100TR-10010-10010-1-1-100-110hai , ajhOR, ORihOL, OLihOR, OLihOL, ORihL, LihL, ORihOR, LihL, OLihOL, LiTL10-100-10010-110-1-100-1TR-1001010-100-1-100-110-1Reward functions agents jhai , ajhL, LihL, LihL, OLihL, OLihL, ORihL, ORihOL,hOR,StateTLTRTLTRTLTRh GL, CL0.85*0.050.15*0.050.85*0.90.15*0.90.85*0.050.15*0.051/61/6h GL, CR0.85*0.050.15*0.050.85*0.050.15*0.050.85*0.90.15*0.91/61/6h GL,0.85*0.90.15*0.90.85*0.050.15*0.050.85*0.050.15*0.051/61/6h GR, CL0.15*0.050.85*0.050.15*0.90.85*0.90.15*0.050.85*0.051/61/6h GR, CR0.15*0.050.85*0.050.15*0.050.85*0.050.15*0.90.85*0.91/61/6h GR,0.15*0.90.85*0.90.15*0.050.85*0.050.15*0.050.85*0.051/61/6hai , ajhL, LihL, LihOL, LihOL, LihOR, LihOR, Lih, OLih, ORiStateTLTRTLTRTLTRh GL, CL0.85*0.050.15*0.050.85*0.90.15*0.90.85*0.050.15*0.051/61/6h GL, CR0.85*0.050.15*0.050.85*0.050.15*0.050.85*0.90.15*0.91/61/6h GL,0.85*0.90.15*0.90.85*0.050.15*0.050.85*0.050.15*0.051/61/6h GR, CL0.15*0.050.85*0.050.15*0.90.85*0.90.15*0.050.85*0.051/61/6h GR, CR0.15*0.050.85*0.050.15*0.050.85*0.050.15*0.90.85*0.91/61/6h GR,0.15*0.90.85*0.90.15*0.050.85*0.050.15*0.050.85*0.051/61/6Observation functions agents j.Table 1: Transition, reward, observation functions multi-agent Tiger game.agent makes choice multi-agent tiger game, considers believeslocation tiger, well whether agent listen open door,turn depends agents beliefs, reward function, optimality criterion, etc. 15 particular,agent open doors tiger location next time step wouldchosen randomly. Thus, information obtained hearing previous growls woulddiscarded. simplify situation considering I-POMDP single level nesting,assuming agent js properties, except beliefs, known i, js timehorizon equal is. words, uncertainty pertains js beliefsframe. Agent interactive state space is, ISi,1 = j,0 , physical state, S={TL,15. assume intentional model agent here.63fiG MYTRASIEWICZ & OSHITR}, j,0 set intentional models agent js, differs js beliefslocation tiger.7.2 Examples Belief UpdateSection 5, presented belief update equation I-POMDPs (Eq. 6). considerexamples beliefs, bi,1 , agent i, probability distributions j,0 . 0-thlevel type agent j, j,0 j,0 , contains flat belief location tiger,represented single probability assignment bj,0 = pj (T L).0.5060.5040.504Pr(TL,pPr(TL,b_j) )jPr(TL,pPr(TL,b_j)j)0.5060.5020.50.4980.5020.50.4980.4960.4960.49400.20.40.60.810.49400.20.40.60.810.81pb_jj (TL)0.5060.5060.5040.504j)0.502Pr(TR,pPr(TR,b_j)Pr(TR,pPr(TR,b_j)j)pjb_j(TL)j(TL)0.50.4980.5020.50.4980.4960.4940.49600.20.4 0.6 0.8ppb_j(TL)(TR)(TL)10.494jj00.20.40.6p j (TL)b_j(i)(ii)Figure 5: Two examples singly nested belief states agent i. case informationtigers location. (i) agent knows j know locationtiger; single point (star) denotes Dirac delta function integrates heightpoint, 0.5 . (ii) agent uninformed js beliefs tigers location.Fig. 5 show examples level 1 beliefs agent i. case knowlocation tiger marginals top bottom sections figure sum0.5 probabilities TL TR each. Fig. 5(i), knows j assigns 0.5 probability tigerbehind left door. represented using Dirac delta function. Fig. 5(ii), agentuninformed js beliefs. represented uniform probability density valuesprobability j could assign state TL.make presentation belief update transparent decompose formulaEq. 6 two steps:64fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGSt1Prediction: agent performs action at1, given agent j performs aj ,predicted belief state is:bbt (ist ) = P r(ist |at1 , at1 , bt1 ) = P t1 bt1 bt bt1 (ist1 )P r(at1 |t1 )jjj|j =jP(st1 , at1 , st ) Oj (st , at1 , otj )(11)otjt1jt (bt1j , j , j , bj )Correction: agent perceives observation, ti , predicted belief states,t1 t1P r(|at1, aj , bi ), combined according to:bti (ist ) = P r(ist |oti , ait1 , bt1)=Xt1 t1Oi (st , at1 , oti )P r(ist |at1, j , bi )(12)at1jnormalizing constant.t10.4960.49400.20.4 0.6 0.8pb_j(TL)1j0.4960.4940.4 0.6 0.8pb_j(TL)10.810.70.60.50.40.3L,<GL,S>0.20.1L,<GL,S> 000.81L,<GL,S>00.20.40.6pjb_j(TL)<GL,S><GL,S>0.20.40.60.8L,<GL,S>0.1L,<GL,S>0.060.810.4 0.6 0.8pb_j(TL)10.020.010.0050.04L,<GL,S>0.20.4pjb_j(TL)0.6pjb_j(TL)(b)0.6pjb_j(TL)0.0150.08010.40.0250.120.0200.2L,<GL,S>0.140.450.40.350.30.250.20.150.10.05j(a)0.6pjb_j(TL)0.80.70.60.50.40.30.20.1j)j)0.4Pr(TR,pj )0.498Pr(TR,b_j)j)Pr(TR,pPr(TR,b_j)L,(L,GL)0.50.20.2L,(L,GR)0.5040<GL,S>00.5060.502L,<GL,S>0.450.40.350.30.250.20.150.10.05Pr(TL,pPr(TL,b_j)L,(L,GR)0.50.498biPr(TR,b_j)Pr(TR,p)j0.502t+1bi<GL,S>Pr(TL,pPr(TL,b_j)0.504Pr(TL,pPr(TL,b_j) )jPr(TL,pPr(TL,b_j)j)0.506biL,(L,GL)Pr(TR,pPr(TR,b_j) )jbi(c)0.81000.2j(d)Figure 6: trace belief update agent i. (a) depicts prior. (b) result predictiongiven listening action, L, pair denoting js action observation. knowsj listen could hear tigers growl right left, probabilitiesj would assign TL 0.15 0.85, respectively. (c) result correctionobserves tigers growl left creaks, hGL,Si. probability assignsTL greater TR. (d) depicts results another update (both predictioncorrection) another listen action observation, hGL,Si.discrete point denotes, again, Dirac delta function integrates heightpoint.Fig. 6, display example trace update singly nested belief. firstcolumn Fig. 6, labeled (a), example agent prior belief introduced before, according65fiG MYTRASIEWICZ & OSHIknows j uninformed location tiger. 16 Let us assume listenshears growl left creaks. second column Fig. 6, (b), displays predictedbelief performs listen action (Eq. 11). part prediction step, agent must solvejs model obtain js optimal action belief 0.5 (term P r(a t1j |j ) Eq. 11). Givenvalue function Fig. 3, evaluates probability 1 listen action, zero openingdoors. also updates js belief given j listens hears tiger growling eithert1left, GL, right, GR, (term jt (bt1j , aj , oj , bj ) Eq. 11). Agent js updated probabilitiestiger left 0.85 0.15, js hearing GL GR, respectively. tigerleft (top Fig. 6 (b)) js observation GL likely, consequently js assigningprobability 0.85 state TL likely (i assigns probability 0.425 state.)tiger right j likely hear GR assigns lower probability, 0.075,js assigning probability 0.85 tiger left. third column, (c), Fig. 6 showsposterior belief correction step. belief column (b) updated accounthearing growl left creaks, hGL,Si. resulting marginalised probabilitytiger left higher (0.85) tiger right. assumenext time step listens hears tiger growling left creaks, beliefstate depicted fourth column Fig. 6 results.Fig. 7 show belief update starting prior Fig. 5 (ii), accordingagent initially information j believes tigers location.traces belief updates Fig. 6 Fig. 7 illustrate changing state information agentagents beliefs. benefit representing updates explicitly that,stage, optimal behavior depends estimate probabilities js actions.informative estimates value agent expect interaction. Below,show increase value function I-POMDPs compared POMDPs noise factor.7.3 Examples Value Functionssection compares value functions obtained solving POMDP static noise factor,accounting presence another agent,17 value functions level-1 I-POMDP. advantage refined modeling update I-POMDPs due two factors. First abilitykeep track agents state beliefs better predict future actions. secondability adjust agents time horizon number steps go interactiondecreases. Neither possible within classical POMDP formalism.continue simple example I-POMDPi,1 agent i. Fig. 8 displayvalue function time horizon 1, assuming initial belief value j assignsTL, pj (T L), depicted Fig. 5 (ii), i.e. information j believestigers location. value function identical value function obtained agent usingtraditional POMDP framework noise, well single agent POMDP describedSection 3.2. value functions overlap since agents update beliefsadvantage refined modeling agent j I-POMDP become apparent. Putanother way, agent models j using intentional model, concludes agent j opendoor probability 0.1 listen probability 0.8. coincides noise factordescribed Section 3.2.16. points Fig. 7 denote Dirac delta functions integrate value equal points height.17. POMDP noise level-0 I-POMDP.66fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGSt1bibiL(L,GR)L(L,GL)0.50.5L(L,GL)0.40.4L(L,GR)0.20.50.30.20.4980.10.1L(L,GR)0.4960.49400.20.40.60.80L(OL/OR,*)1pjb_j(TL)00.5040.5020.49400.20.40.60.810.8010Pr(TL,b_j)L(L,GR)pjb_j(TL)0.40.60.81pjb_j(TL)0.022750.02270.022650.02260.02260.022550.02250.022450.022550.02250.022450.02240.02240.022350.022350.0223L(OL/OR,*)0.20.02265Pr(TL, pj )L(OL/OR,*)0.4960.60.0227L(OL/OR,*)0.4980.40.02275L(L,GL)0.50.2pjb_j(TL)L(L,GL)0.506Pr(TR,pj )Pr(TR,b_j)0.3Pr(TR,b_j)Pr(TR,pj)Pr(TL,p)Pr(TL,b_j)j0.502Pr(TR,b_j)Pr(TR,pj)0.504Pr(TL,b_j)Pr(TL,pj )0.5060.02230.022250.0222500.20.40.60.810pjb_j(TL)(a)0.20.40.60.81pjb_j(TL)(b)<GL,S>bi0.31.81.60.25Pr(TR,pj )1.2Pr(TR,b_j)Pr(TL,p)Pr(TL,b_j)j1.410.80.20.150.10.60.40.050.20000.20.40.6pjb_j(TL)0.8010.20.40.60.81pj b_j(TL)(c)Figure 7: trace belief update agent i. (a) depicts prior accordinguninformed js beliefs. (b) result prediction step listeningaction (L). top half (b) shows belief listened given j alsolistened. two observations j make, GL GR, probability dependenttigers location, give rise flat portions representing knows js beliefcase. increased probability assigns js belief 0.472 0.528due js updates hears GL hears GR resulting valuesinterval. bottom half (b) shows belief listened j openedleft right door (plots identical action one shown).knows j information tigers location case. (c) resultcorrection observes tigers growl left creaks hGL,Si. plots (c)obtained performing weighted summation plots (b). probabilityassigns TL greater TR, information js beliefs allows refineprediction js action next time step.67fiG MYTRASIEWICZ & OSHILOL10Value Function (U)8642000.20.40.60.81pp_i(TL)(TL)Level 1 I-POMDPPOMDP noiseFigure 8: time horizon 1 value functions obtained solving singly nested I-POMDPPOMDP noise factor overlap.L\();OL\(<GR,S>),L\(?)L\();OR\(<GL,S>),L\(?)L\();L\(<GL,*>),OL\(<GR,*>)OL\();L\(*)L\();L\(*)L\();OR\(<GL,*>),L\(<GR,*>)L\();L\(GL),OL\(GR)L\();OR\(GL),L\(GR)OR\();L\(*)8Value Function (U)6420-200.20.40.60.81pp_i(TL)(TL)Level 1 I-POMDPPOMDP noiseFigure 9: Comparison value functions obtained solving I-POMDP POMDPnoise time horizon 2. I-POMDP value function dominates due agent adjustingbehavior agent j remaining steps go interaction.68fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGS8Value Function (U)765432100.20.40.60.81p (TL)p_i(TL)Level 1 I-POMDPPOMDP noiseFigure 10: Comparison value functions obtained solving I-POMDP POMDPnoise time horizon 3. I-POMDP value function dominates due agent adjusting js remaining steps go, due modeling js belief update. factorsallow better predictions js actions interaction. descriptions individual policies omitted clarity; read Fig. 11.Fig. 9 display value functions time horizon 2. value functionI-POMDPi,1 higher value function POMDP noise factor. reasonrelated advantages modeling agent js beliefs effect becomes apparent timehorizon 3 longer. Rather, I-POMDP solution dominates due agent modeling js timehorizon interaction: knows last time step j behave according optimalpolicy time horizon 1, two steps go j optimize according 2 steps gopolicy. mentioned, effect cannot modeled using POMDP static noise factorincluded transition function.Fig. 10 shows comparison I-POMDP noisy POMDP value functionshorizon 3. advantage refined agent modeling within I-POMDP frameworkincreased.18 factors, adjusting js steps go modeling js belief updateinteraction responsible superiority values achieved using I-POMDP. particular,recall second time step information js beliefs tigers locationdepicted Fig. 7 (c). enables make high quality prediction that, two steps leftgo, j perform actions OL, L, probabilities 0.009076, 0.96591 0.02501,respectively (recall POMDP noise probabilities remained unchanged 0.1, 0,8,0.1, respectively.)Fig. 11 shows agent policy graph time horizon 3. usual, prescribes optimalfirst action depending initial belief tigers location. subsequent actions dependobservations received. observations include creaks indicative agents18. Note I-POMDP solution good solution POMDP agent operating alone environment shown Fig. 3.69fiG MYTRASIEWICZ & OSHI[0 0.029)OL[0.029 0.089)[0.089 0.211)L*L<GR,S><GL,CL/CR><GR,*>[0.211 0.789)[0.789 0.911)L*OL*<GR,S><GL,CL\CR>LL<GR,*>[0.971 1]L<GR,CL\CR><GR,CL\CR><GL,CL\CR><GL,S><GR,*> <GL,*><GL,*><GR,S><GL,S><GL,S><GR,CL\CR>OL[0.911 0.971)L<GL,*>L*<GR,*><GL,*>*LFigure 11: policy graph corresponding I-POMDP value function Fig. 10.opened door. creaks contain valuable information allow agent makerefined choices, compared ones noisy POMDP Fig. 4. Consider case agentstarts fairly strong belief tigers location, decides listen (according fouroff-center top row L nodes Fig. 11) hears door creak. agent positionopen either left right door, even counter initial belief. reasoncreak indication tigers position likely reset agent j jopen doors following two time steps. Now, two growls comingdoor lead enough confidence open door. agent hearingtigers growls indicative tigers position state following agents actions,Note value functions policy depict special case agentinformation probability j assigns tigers location (Fig. 5 (ii)). Accountingvisualizing possible beliefs js beliefs difficult due complexityspace interactive beliefs. ongoing work indicates, drastic reduction complexitypossible without loss information, consequently representation solutions manageablenumber dimensions indeed possible. report results separately.8. Conclusionsproposed framework optimal sequential decision-making suitable controlling autonomousagents interacting agents within uncertain environment. used normativeparadigm decision-theoretic planning uncertainty formalized partially observable Markovdecision processes (POMDPs) point departure. extended POMDPs cases agentsinteracting agents allowing beliefs physical environment, also agents. could include beliefs others abilities, sensingcapabilities, beliefs, preferences, intended actions. framework shares numerous propertiesPOMDPs, analogously defined solutions, reduces POMDPs agents aloneenvironment.contrast recent work DEC-POMDPs (Bernstein et al., 2002; Nair et al., 2003),work motivated game-theoretic equilibria (Boutilier, 1999; Hu & Wellman, 1998; Koller70fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGS& Milch, 2001; Littman, 1994), approach subjective amenable agents independentlycomputing optimal solutions.line work presented opens area future research integrating frameworkssequential planning elements game theory Bayesian learning interactive settings.particular, one avenues future research centers proving formal propertiesI-POMDPs, establishing clearer relations solutions I-POMDPs various flavorsequilibria. Another concentrates developing efficient approximation techniques solvingI-POMDPs. POMDPs, development approximate approaches I-POMDPs crucialmoving beyond toy problems. One promising approximation technique working particlefiltering. also devising methods representing I-POMDP solutions without assumptionswhats believed agents beliefs. mentioned, spite complexityinteractive state space, seem intuitive representations belief partitions correspondingoptimal policies, analogous POMDPs. research issues include suitablechoice priors models,19 ways fulfill absolute continuity condition neededconvergence probabilities assigned alternative models interactions (Kalai & Lehrer,1993).Acknowledgmentsresearch supported National Science Foundation CAREER award IRI-9702132,NSF award IRI-0119270.Appendix A. ProofsProof Propositions 1 2. start Proposition 2, applying Bayes Theorem:t1bti (ist ) = P r(ist |oti , at1, bi ) =),bt1P r(ist ,oti |at1t1 t1P r(oi |ai ,bi )Pt1 )= ist1 bit1 (ist1 )P r(ist , oti |at1,PPt1t1 )P r(at1 |at1 , ist1 )= ist1 bit1 (ist1 ) at1 P r(ist , oti |at1, aj ,jjPP(13)t1t1 )P r(at1 |ist1 ),,= ist1 bit1 (ist1 ) at1 P r(ist , oti |at1jjjPPt1t1 , ist1 )P r(ist |at1 , ist1 )= ist1 bit1 (ist1 ) at1 P r(at1j |mj )P r(ot |is ,jPPt1t1 )P r(ist |at1 , ist1 )= ist1 bit1 (ist1 ) at1 P r(at1j |mj )P r(ot |is ,jPPt1t1 , ot )P r(ist |at1 , ist1 )= ist1 bit1 (ist1 ) at1 P r(at1j |mj )Oi (s ,j19. looking Kolmogorov complexity (Li & Vitanyi, 1997) possible way assign priors.71fiG MYTRASIEWICZ & OSHIsimplify term P r(ist |at1 , ist1 ) let us substitute interactive state ist components. mj interactive states intentional: ist = (st , jt ) = (st , btj , bjt ).P r(ist |at1 , ist1 ) = P r(st , btj , bjt |at1 , ist1 )= P r(btj |st , bjt , at1 , ist1 )P r(st , bjt |at1 , ist1 )= P r(btj |st , bjt , at1 , ist1 )P r(bjt |st , at1 , ist1 )P r(st |at1 , ist1 )= P r(btj |st , bjt , at1 , ist1 )I(bjt1 , bjt )Ti (st1 , at1 , st )(14)b tj ).mj subintentional: ist = (st , mtj ) = (st , htj ,P r(ist |at1 , ist1 ) = P r(st , htj ,b tj |at1 , ist1 )b tj |at1 , ist1 )b tj , at1 , ist1 )P r(st ,= P r(htj |st ,b tj , at1 , ist1 )P r(bjt |st , at1 , ist1 )P r(st |at1 , ist1 )= P r(htj |st ,= P r(hj |s ,b tj , at1 , ist1 )I(mb tj )Ti (st1 , at1 , st )b t1(14)j ,mjoint action pair, at1 , may change physical state. third term right-handside Eqs. 14 140 captures transition. utilized MNM assumption replacesecond terms equations boolean identity functions, I( bjt1 , bjt ) I(mb t1b tj )j ,mrespectively, equal 1 two frames identical, 0 otherwise. Let us turn attentionfirst terms. mj ist ist1 intentional:PP r(btj |st , bjt , at1 , ist1 ) = ot P r(btj |st , bjt , at1 , ist1 , otj )P r(otj |st , bjt , at1 , ist1 )Pj= ot P r(btj |st , bjt , at1 , ist1 , otj )P r(otj |st , bjt , at1 )Pjt1t1 , ot )= ot jt (bt1jj , aj , oj , bj )Oj (st ,(15)jElse subintentional:P r(htj |st ,b tj , at1 , ist1 ) ===PPo jPo jotjb tj , at1 , ist1 )b tj , at1 , ist1 , otj )P r(otj |st ,P r(htj |st ,b tj , at1 )b tj , at1 , ist1 , otj )P r(otj |st ,P r(htj |st ,t1 , ot )K (APPEND(ht1jj , oj ), hj )Oj (st ,(15)t1Eq. 15, first term right-hand side 1 agent js belief update, SE j (bt1j , j , oj )generates belief state equal btj . Similarly, Eq. 150 , first term 1 appending otjht1results htj . K Kronecker delta function. second terms right-handjside equations, MNO assumption makes possible replace P r(o |st , bt , at1 )jjOj (st , at1 , otj ), P r(otj |st ,b tj , at1 ) Oj (st , at1 , otj ) respectively.Let us substitute Eq. 15 Eq. 14.Pt1t1 , ot )I(bt1 , bt )Ti (st1 , at1 , st )P r(ist |at1 , ist1 ) = ot jt (bt1jjj , aj , oj , bj )Oj (s ,jj(16)00Substituting Eq. 15 Eq. 14 get,Pt1 , ot )I(mP r(ist |at1 , ist1 ) = ot K (APPEND(ht1b t1b tj )jj , oj ), hj )Oj (s ,j ,mjTi (st1 , at1 , st )(16)72fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGSReplacing Eq. 16 Eq. 13 get:PPt1t1t1 )P r(at1|jt1 )Oi (st , at1 , oti ) ot jt (bt1ist1 bi (isj , j , j , bj )jat1jjOj (st , at1 , otj )I(bjt1 , bjt )Ti (st1 , at1 , st )bti (ist ) =P(17)Similarly, replacing Eq. 160 Eq. 13 get:PPt1t1 , ot )t1 )P r(at1bti (ist ) = ist1 bt1j |mj )Oi (s ,(isat1jPt1t1t1bj ,mb tj )Ti (st1 , at1 , st )ot K (APPEND(hj , oj ), hj )Oj (s , , oj )I(mjarrive final expressions belief update removing termsI(mb t1b tj ) changing scope first summations.j ,mmj interactive states intentional:I( bjt1 , bjt )PPt1t1 , ot )bt1 (ist1 ) at1 P r(at1bti (ist ) = ist1 :mj |j )Oi (s ,b t1=bjtjjPt1 t1t1t1t1ot jt (bj , aj , oj , bj )Oj (s , , oj )Ti (s , , )(170 )(18)jElse, subintentional:PPt1t1t1 , ot )(ist1 ) at1 P r(at1bti (ist ) = ist1 :mbij |mj )Oi (s ,=bb t1jjjP), ht )O (st , at1 , ot )T (st1 , at1 , st ),ot K (APPEND(ht1jjjjj(19)jSince proposition 2 expresses belief bti (ist ) terms parameters previous time steponly, Proposition 1 holds well.present proof Theorem 1 note Equation 7, defines valueiteration I-POMDPs, rewritten following form, U n = HU n1 . Here, H : B Bbackup operator, defined as,HU n1 (i ) = max h(i , ai , U n1 )ai Aih : Ai B R is,h(i , ai , U ) =Pbi (is)ERi (is, ai ) +PoiP r(oi |ai , bi )U (hSEi (bi , ai , oi ), i)B set bounded value functions U . Lemmas 1 2 establish importantproperties backup operator. Proof Lemma 1 given below, proof Lemma 2 followsthereafter.Proof Lemma 1. Select arbitrary value functions V U V ( i,l ) U (i,l ) i,li,l . Let i,l arbitrary type agent i.73fiG MYTRASIEWICZ & OSHIPPHV (i,l ) = maxoi P r(oi |ai , bi )V (hSEi,l (bi , ai , oi ), i)bi (is)ERi (is, ai ) +ai AiPP= bi (is)ERi (is, ai ) + oi P r(oi |ai , bi )V (hSEi,l (bi , ai , oi ), i)PPb(is)ERi (is, ai ) +oi P r(oi |ai , bi )U (hSEi,l (bi , ai , oi ), i)PPmaxoi P r(oi |ai , bi )U (hSEi,l (bi , ai , oi ), i)bi (is)ERi (is, ai ) +ai Ai= HU (i,l )Since i,l arbitrary, HV HU .Proof Lemma 2. Assume two arbitrary well defined value functions V U V U .Lemma 1 follows HV HU . Let i,l arbitrary type agent i. Also, let aiaction optimizes HU (i,l ).0 HU (i,l ) HV (i,l )P= max sumis bi (is)ERi (is, ai ) + oi P r(oi |ai , bi )U (SEi,l (bi , ai , oi ), hi i)ai AiPPmaxbi (is)ERi (is, ai ) +oi P r(oi |ai , bi )V (SEi,l (bi , ai , oi ), hi i)ai AiPPbi (is)ERi (is, ai ) + oi P r(oi |ai , bi )U (SEi,l (bi , ai , oi ), hi i)PPoi P r(oi |ai , bi )V (SEi,l (bi , ai , oi ), hi i)bi (is)ERi (is, ai )P= oi P r(oi |ai , bi )U (SEi,l (bi , ai , oi ), hi i)Poi P r(oi |ai , bi )V (SEi,l (bi , ai , oi ), hi i)P= oi P r(oi |ai , bi ) U (SEi,l (bi , ai , oi ), hi i) V (SEi,l (bi , ai , oi ), hi i)Poi P r(oi |ai , bi )||U V ||= ||U V ||supremum norm symmetrical, similar result derived HV ( i,l ) HU (i,l ).Since i,l arbitrary, Contraction property follows, i.e. ||HV HU || ||V U ||.Lemmas 1 2 provide stepping stones proving Theorem 1. Proof Theorem 1 followsstraightforward application Contraction Mapping Theorem. state ContractionMapping Theorem (Stokey & Lucas, 1989) below:Theorem 3 (Contraction Mapping Theorem). (S, ) complete metric space :contraction mapping modulus ,1. exactly one fixed point U S,2. sequence {U n } converges U .Proof Theorem 1 follows.74fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGSProof Theorem 1. normed space (B, || ||) complete w.r.t metric induced supremum norm. Lemma 2 establishes contraction property backup operator, H. Using Theorem 3, substituting H, convergence value iteration I-POMDPs unique fixedpoint established.go piecewise linearity convexity (PWLC) property value function.follow outlines analogous proof POMDPs (Hausktecht, 1997; Smallwood &Sondik, 1973).Let : R real-valued bounded function. Let space real-valuedbounded functions B(IS). define inner product.Definition 5 (Inner product). Define inner product, h, : B(IS) (IS) R,Xh, bi =bi (is)(is)next lemma establishes bilinearity inner product defined above.Lemma 3 (Bilinearity). s, R, f, g B(IS), b, (IS) following equalitieshold:hsf + tg, bi = shf, bi + thg, bihf, sb + ti = shf, bi + thf,ready give proof Theorem 2. Theorem 4 restates Theorem 2 mathematically, proof follows thereafter.Theorem 4 (PWLC). value function, U n , finitely nested I-POMDP piece-wise linearconvex (PWLC). Mathematically,U n (i,l ) = maxnXbi (is)n (is)n = 1, 2, ...Proof Theorem 4. Basis Step: n = 1Bellmans Dynamic Programming equation,U 1 (i ) = maxaiXbi (is)ER(is, ai )(20)PERi (is, ai ) = aj R(is, ai , aj )P r(aj |mj ). Here, ERi () represents expectationR w.r.t. agent js actions. Eq. 20 represents inner product using Lemma 3, inner productlinear bi . selecting maximum set linear vectors (hyperplanes), obtain PWLChorizon 1 value function.Inductive Hypothesis: Suppose U n1 (i,l ) PWLC. Formally have,U n1 (i,l ) = maxn1=Pmaxn1 ,bi (is)n1Pn1 (is)is:mj IMj bi(is)n1 (is)75+Pis:mj SMj bi(is)n1 (is)(21)fiG MYTRASIEWICZ & OSHIInductive Proof: show U n (i,l ) PWLC.U n (i,l ) = maxat1(Xt1bt1)ERi (ist1 , at1(is)+Xt1n1P r(oti |at1(i,l ), bi )Uotiist1inductive hypothesis:(Pt1t1 )ER (ist1 , at1 )U n (i,l ) = maxist1 bi (isat1+Potit1P r(oti |at1, bi )maxn1 n1Pn1 (ist )ist bi (is )))t1t1 t1Let l(bt1, ai , oi ) index alpha vector maximizes value b = SE(bi , ai , oi ).Then,(Pt1t1 )ER (ist1 , at1 )U n (i,l ) = maxist1 bi (ist1ai)PPt1n1+ ot P r(oti |at1ist bi (is )l(bt1 ,at1 ,ot ), bi )second equation inductive hypothesis:(PPt1t1 )ER (ist1 , at1 ) +nt1 t1U (i,l ) = maxot P r(oi |ai , bi )ist1 bi (isat1Pn1ist :mtj IMj bi (is )l(bt1 ,at1 ,ot )+Pn1ist :mtj SMj bi (is )l(bt1 ,at1 ,ot )Substituting bti appropriate belief updates Eqs. 17 17 0 get:(PPt1t1 t1t1 )ER (ist1 , at1 ) +U n (i,l ) = maxoti P r(oi |ai , bi )ist1 bi (ist1ai"PPPt1t1 t1t1)P r(aj |j ) Oi (st , at1 , oti )ist :mtj IMjist1 bi (isat1jPt1 t1t1t1t1t1ot Oj (s , , oj ) jt (bj , aj , oj , bj )I(bj , bj )Ti (s , , ))jn1l(bt1 t1 (is ),ai ,oi )PPPt1t1t1t1+ ist :mt SMj ist1 bi (is )P r(aj |mj ) Oi (st , at1 , oti )at1jjPt1t1t1t1t1ot Oj (s , , oj ) K (APPEND(hj , oj ) hj )I(mbj ,mb j )Ti (s , , )j#)n1l(bt1 t1 (is ),a,o )76fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGSU n (i,l ) = maxat1PP(Pt1t1 )ER (ist1 , at1 )ist1 bi (ist1t1 )ist1 bi (ist1 , ot )jotj Oj (s ,Pat1j+Poti"Pist :mtj IMjt1P r(at1|)Oi (st , at1 , oti )jjt1t1 , at1 , st )bt1 btjt (bt1j , aj , oj , bj )I(j , j )Ti (sn1l(bt1 t1 (is ),ai ,oi )PPPt1t1t1t1P r(aj |mj ) Oi (st , at1 , oti )+ ist :mt SMj ist1 bi (is )at1jjPt1) ht )I(m)T (st1 , at1 , st )ot Ojt (st , at1 , otj ) K (APPEND(ht1,b,bjjjjjj#)n1l(bt1 t1 (is ),a,o )Rearranging terms equation:U n ((PP Pt1t1 ) ER (ist1 , at1 ) +)=maxb(ist1t1 :mi,lotiist :mtj IMjIMjjat1PPt1 t1P r(aj |j ) Oi (st , at1 , oti ) ot Ojt (st , at1 , otj )at1jjn1t1 t1t1t1t1jt (bj , aj , oj , bj )I(bj , bj )Ti (s , , )l(bt1 ,at1 ,ot ) (is )PPPP+ ist1 :mt1 SMj bit1 (ist1 ) ERi (ist1 , at1otiist :mtj SMjoti)+jPPP r(ajt1 |mt1) Oi (st , at1 , oti ) ot Ojt (st , at1 , otj )jat1jj)n1l(bb t1b tj )Ti (st1 , at1 , st )K (APPEND(ht1t1 t1 (is )j ,mj , oj ) hj )I(m,ai ,oi )Pt1t1 )n (ist1 )= maxaiIMj bi (isist1 :mt1jat1Pt1t1t1n+ ist1 :mt1 SMj bi (is )ai (is )jTherefore,U n (i,l )= maxnn,+=PPt1t1 )n (ist1 )ist1 :mt1IMj bi (isjt1t1 )n (ist1 )SMj bi (isist1 :mt1jPt1t1 )n (ist1 ) = maxhbt1 , nmaxist1 bi (isnn77(22)fiG MYTRASIEWICZ & OSHIwhere, mjt1 ist1 intentional n = n :n (ist1 )ERi (ist1 , at1)P PPt1P r(at1j |j )Oi (ist , at1 , oti )+ ot ist :mt IMjat1jjPt1 t1t1t1t1t1ot Oj (isj , , oj ) jt (bj , aj , oj , bj )I(bj , bj )Ti (s , , )=jn1l(bt1 t1 (is ),o ),aand, mjt1 subintentional n = n :n (ist1 )ERi (ist1 , at1)P PPt1P r(at1j |j )Oi (ist , at1 , oti )+ ot ist :mt SMjat1jjPt1t1t1t1t1bj ,mb j )Ti (s , , )ot Oj (isj , , oj ) K (APPEND(hj , oj ) hj )I(m=jn1l(bt1 t1 (is ),ai ,oi )Eq. 22 inner product using Lemma 3, value function linear b t1. Furthermore,maximizing set linear vectors (hyperplanes) produces piecewise linear convex valuefunction.ReferencesAmbruster, W., & Boge, W. (1979). Bayesian game theory. Moeschlin, O., & Pallaschke, D. (Eds.), GameTheory Related Topics. North Holland.Aumann, R. J. (1999). Interactive epistemology i: Knowledge. International Journal Game Theory, pp.263300.Aumann, R. J., & Heifetz, A. (2002). Incomplete information. Aumann, R., & Hart, S. (Eds.), HandbookGame Theory Economic Applications, Volume III, Chapter 43. Elsevier.Battigalli, P., & Siniscalchi, M. (1999). Hierarchies conditional beliefs interactive epistemologydynamic games. Journal Economic Theory, pp. 188230.Bernstein, D. S., Givan, R., Immerman, N., & Zilberstein, S. (2002). complexity decentralized controlmarkov decision processes. Mathematics Operations Research, 27(4), 819840.Binmore, K. (1990). Essays Foundations Game Theory. Blackwell.Boutilier, C. (1999). Sequential optimality coordination multiagent systems. ProceedingsSixteenth International Joint Conference Artificial Intelligence, pp. 478485.Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial intelligence Research, 11, 194.Brandenburger, A. (2002). power paradox: recent developments interactive epistemology.Tech. rep., Stern School Business, New York University, http://pages.stern.nyu.edu/ abranden/.Brandenburger, A., & Dekel, E. (1993). Hierarchies beliefs common knowledge. Journal EconomicTheory, 59, 189198.Dennett, D. (1986). Intentional systems. Dennett, D. (Ed.), Brainstorms. MIT Press.Fagin, R. R., Geanakoplos, J., Halpern, J. Y., & Vardi, M. Y. (1999). hierarchical approach modelingknowledge common knowledge. International Journal Game Theory, pp. 331365.Fagin, R. R., Halpern, J. Y., Moses, Y., & Vardi, M. Y. (1995). Reasoning Knowledge. MIT Press.Fudenberg, D., & Levine, D. K. (1998). Theory Learning Games. MIT Press.78fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGSFudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press.Gmytrasiewicz, P. J., & Durfee, E. H. (2000). Rational coordination multi-agent environments. Autonomous Agents Multiagent Systems Journal, 3(4), 319350.Harsanyi, J. C. (1967). Games incomplete information played Bayesian players. ManagementScience, 14(3), 159182.Hauskrecht, M. (2000). Value-function approximations partially observable markov decision processes.Journal Artificial Intelligence Research, pp. 3394.Hausktecht, M. (1997). Planning control stochastic domains imperfect information. Ph.D. thesis,MIT.Hu, J., & Wellman, M. P. (1998). Multiagent reinforcement learning: Theoretical framework algorithm. Fifteenth International Conference Machine Learning, pp. 242250.Kadane, J. B., & Larkey, P. D. (1982). Subjective probability theory games. Management Science,28(2), 113120.Kaelbling, L. P., Littman, M. L., & Cassandra, A. R. (1998). Planning acting partially observablestochastic domains. Artificial Intelligence, 101(2), 99134.Kalai, E., & Lehrer, E. (1993). Rational learning leads nash equilibrium. Econometrica, pp. 12311240.Koller, D., & Milch, B. (2001). Multi-agent influence diagrams representing solving games. Seventeenth International Joint Conference Artificial Intelligence, pp. 10271034, Seattle, Washington.Li, M., & Vitanyi, P. (1997). Introduction Kolmogorov Complexity Applications. Springer.Littman, M. L. (1994). Markov games framework multi-agent reinforcement learning. ProceedingsInternational Conference Machine Learning.Lovejoy, W. S. (1991). survey algorithmic methods partially observed markov decision processes.Annals Operations Research, 28(1-4), 4766.Madani, O., Hanks, S., & Condon, A. (2003). undecidability probabilistic planning relatedstochastic optimization problems. Artificial Intelligence, 147, 534.Mertens, J.-F., & Zamir, S. (1985). Formulation Bayesian analysis games incomplete information.International Journal Game Theory, 14, 129.Monahan, G. E. (1982). survey partially observable markov decision processes: Theory, models,algorithms. Management Science, 116.Myerson, R. B. (1991). Game Theory: Analysis Conflict. Harvard University Press.Nachbar, J. H., & Zame, W. R. (1996). Non-computable strategies discounted repeated games. EconomicTheory, 8, 103122.Nair, R., Pynadath, D., Yokoo, M., Tambe, M., & Marsella, S. (2003). Taming decentralized pomdps: Towardsefficient policy computation multiagent settings. Proceedings Eighteenth InternationalJoint Conference Artificial Intelligence (IJCAI-03).Ooi, J. M., & Wornell, G. W. (1996). Decentralized control multiple access broadcast channel.Proceedings 35th Conference Decision Control.Papadimitriou, C. H., & Tsitsiklis, J. N. (1987). complexity markov decision processes. MathematicsOperations Research, 12(3), 441450.Russell, S., & Norvig, P. (2003). Artificial Intelligence: Modern Approach (Second Edition). Prentice Hall.Smallwood, R. D., & Sondik, E. J. (1973). optimal control partially observable markov decisionprocesses finite horizon. Operations Research, pp. 10711088.Stokey, N. L., & Lucas, R. E. (1989). Recursive Methods Economic Dynamics. Harvard Univ. Press.79fi