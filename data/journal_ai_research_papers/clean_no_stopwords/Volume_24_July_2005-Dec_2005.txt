Journal Artificial Intelligence Research 24 (2005) 519-579

Submitted 12/04; published 10/05

Deterministic Part IPC-4: Overview
Jorg Hoffmann

hoffmann@mpi-sb.mpg.de

Max-Planck-Institut fur Informatik,
Saarbrucken, Germany

Stefan Edelkamp

stefan.edelkamp@cs.uni-dortmund.de

Fachbereich Informatik,
Universitat Dortmund, Germany

Abstract
provide overview organization results deterministic part
4th International Planning Competition, i.e., part concerned evaluating
systems deterministic planning. IPC-4 attracted even competing systems
already large predecessors, competition event revised several important
respects. giving introduction IPC, briefly explain main differences
deterministic part IPC-4 predecessors. introduce formally
language used, called PDDL2.2 extends PDDL2.1 derived predicates timed
initial literals. list competing systems overview results competition.
entire set data far large presented full. provide detailed summary;
complete data available online appendix. explain awarded
competition prizes.

1. Introduction
application Artificial Intelligence technology real-world, time space
resources usually limited. led performance-oriented interpretation AI
many research branches. Competition events established automated
theorem proving, satisfiability testing, and, particular, AI Planning. competition
provides large-scale evaluation platform. Due broadness neutrality platform, competition far better assessing state-of-the-art research branch
experiments ran individual authors: systems compared, benchmarks
chosen competition organizers, rather system authors themselves.
Moreover, competition serve establish common representation formalism,
common core set benchmarks, marking edge current system capabilities.
International Planning Competition (IPC) biennial event, hosted international conferences AI Planning Scheduling. IPC began 1998 Drew
McDermott committee created common specification language (PDDL) collection problems forming first benchmark (McDermott et al., 1998). PDDL Lisp-like
input language description format includes planning formalisms like STRIPS (Fikes &
Nilsson, 1971). Five systems participated first international planning competition,
IPC-1 short, hosted AIPS 1998 Pittsburgh, Pennsylvania (McDermott, 2000).
year 2000, Fahiem Bacchus continued work, IPC-2 event attracted 16
competitors (Bacchus, 2001). event hosted AIPS 2000 Breckenridge, Colorado
extended include fully automatic hand-tailored planning systems.
c
2005
AI Access Foundation. rights reserved.

fiHoffmann & Edelkamp

hand-tailored planners allowed use additional domain-dependent information
PDDL input order improve performance, participated additional,
separate, track. STRIPS ADL (Pednault, 1989) domains used
extensions made language (Bacchus, 2000).
3rd International Planning Competition, IPC-3, run Derek Long Maria
Fox hosted AIPS 2002, Toulouse, France. competition attracted 14 competitors (Long & Fox, 2003), focussed planning temporal metric domains.
purpose, Fox Long developed PDDL2.1 language (Fox & Long, 2003),
first three levels used IPC-3. Level 1 STRIPS ADL planning
before, Level 2 added numeric variables, Level 3 added durational constructs.
4th International Planning Competition, IPC-4, hosted ICAPS-2004,
Whistler, Canada. IPC-4 built previous efforts, particular language PDDL2.1.
competition event extended revised several respects. particular, IPC-4
featured, first time, competition probabilistic planners, overall
competition split deterministic part continuation previous events
well probabilistic part.1 latter part, co-organized Michael Littman
Hakan Younes, main objective event introduce common representation
language probabilistic planners, establish first benchmarks results.
information probabilistic part IPC-4 see work Younes Littman
(2005).
Herein, provide overview organization results deterministic
part IPC-4. 19 competing systems (21 counting different system versions),
event even little larger already large predecessors. Several important
revisions made event. briefly explain main differences Section 2.
Afterwards, Section 3 describes input language used, named PDDL2.2: first three
levels PDDL2.1, extended derived predicates timed initial literals. Section 4 lists
briefly explains competing systems. Section 5 presents, benchmark
domain, selection results plots, highlighting important points. entire
set data points far large presented detail. full data, including plots
results, available online appendix. Section 6 explains awarded
competition prizes, Section 7 closes paper concluding remarks. Appendix
gives BNF description PDDL2.2.

2. Main Revisions made IPC-4
main revisions made deterministic part IPC-4, difference predecessors, following.
Competition Workshop. ran international workshop competition one
year event (Edelkamp & Hoffmann, 2003), providing involved groups
people (system developers, organizing committee, AI Planning researchers general)
opportunity express views issues related IPC. Discussions, technical
talks, panels covered relevant topics ranging events organizational structure
input language selection benchmarks evaluation results.
1. IPC-4 running, deterministic part named classical part. re-named
deterministic part since wording less ambiguous.

520

fiThe Deterministic Part IPC-4: Overview

workshop especially useful us organizers, giving us direct feedback
events organization.
PDDL Extensions. large agreement community PDDL2.1 still
posed significant challenge, IPC-4 language featured relatively minor
extensions. added language features derived predicates timed initial literals.
resulting language called PDDL2.2, keeps 3-leveled structure PDDL2.1.
new language features practically motivated put use
IPC-4 domains. Derived predicates add form domain axioms PDDL2.1. typical
use formulate indirect consequences planners actions. Timed initial literals add
temporal part PDDL2.1 (level 3) way defining literals become true
certain time point, independently actions taken planner. typical use
formulate time windows and/or goal deadlines.
Application-Oriented Benchmarks. main effort organization IPC-4
devise range interesting benchmark domains, oriented (and close possible
to) real-world application domains. collaborated number people achieve
goal. description application domains, PDDL2.2 adaptations,
long (50+ pages). submitted JAIR special track (Edelkamp, Hoffmann,
Englert, Liporace, Thiebaux, & Trug, 2005). application domains modelled were:
Airport, modelling airport ground traffic control (Hatzack & Nebel, 2001; Trug, Hoffmann, & Nebel, 2004).
Pipesworld, modelling oil derivative transportation pipeline networks (Milidiu, dos
Santos Liporace, & de Lucena, 2003; Milidiu & dos Santos Liporace, 2004).
Promela, modelling deadlock detection communication protocols formulated
Promela language (Edelkamp, 2003b, 2003a).
PSR, deterministic variant Power Supply Restoration benchmark (Bertoli,
Cimatti, Slaney, & Thiebaux, 2002; Bonet & Thiebaux, 2003).
UMTS, modelling task scheduling concurrent application setup UMTS
mobile devices (Englert, 2003, 2005).
addition, re-used Satellite Settlers domains IPC-3. case
Satellite, added additional domain versions model advanced aspects
application (namely, sending data earth). domain described little
detail part (sub-section) Section 5 contains respective competition
results.
Domain Compilations. first time IPC, provided domain formulations problem constraints compiled complex PDDL subsets
less complex subsets. many domains natural domain formulation comes complex precondition formulas conditional effects, i.e., ADL.
compiled domain formulations STRIPS. previous IPCs, example Elevator domain used IPC-2, interesting problem constraints dropped
STRIPS domain versions. using compilation approach, hope believe
created structurally much interesting range STRIPS benchmarks. ADL
521

fiHoffmann & Edelkamp

STRIPS encodings instances posed competitors optional
way, i.e., every domain version could several domain version formulations.
competitors allowed choose formulation liked best. results within
domain version evaluated together, order keep number separation lines
data acceptable level.
also employed compilations encoding new PDDL2.2 language features terms
artificial constructs old PDDL2.1 features. intended enable
wide participation domains possible. compiled domains offered
separate domain versions rather alternative formulations because, difference
ADL/STRIPS case, figured compiled domains different
original ones allow joint evaluation. importantly, compiling derived predicates
timed initial literals away, plan length increases. Details compilation
methods arrangement individual domains paper describing
domains (Edelkamp et al., 2005).
Optimal vs. Satisficing Planning. define optimal planners planners
prove guarantee quality found solution. Opposed that, satisficing planners planners prove guarantee correctness solution.2
Previous IPCs distinguish optimal planners satisficing planners.
fair since optimal planners essentially solving different problem. theoretical hardness domain differ different kinds planners. fact,
recently proved that, benchmark domains, satisficing planning easy (polynomial)
optimal planning hard (NP-complete) (Helmert, 2001, 2003). practice, i.e.,
commonly used benchmark domains, nowadays indeed huge performance gap optimal satisficing planners. IPC-4, separated
different tracks. optimal track attracted seven systems; example, planning
satisfiability approach, disappeared IPC-3, resurfaced.
Competition Booklet Results Posters. previous competitions, conference time one could neither access results obtained competition, descriptions
competing planners. clearly drawback, especially given growing complexity event. ICAPS 2004, assembled booklet containing extended abstracts
describing core aspects competing systems (Edelkamp, Hoffmann, Littman, &
Younes, 2004); booklet distributed conference participants. competition
results, i.e., deterministic part, made available form posters
showing runtime plan quality plots.
IPC Web-page. important repository large-scale competition event web
page containing relevant information benchmark problems, language descriptions,
result files, etc. IPC-4, set page permanent Internet address
http://ipc.icaps-conference.org. long run, address intended provide
entry point IPC event whole, thereby avoiding need look pages
different IPC editions completely separate points web.
less positive change IPCs 2 3 IPC-4, track hand-tailored planners
disappeared. reason simply systems registered competitors.
2. Satisficing planners referred sub-optimal IPC-4 running. decided replace
term since bit misleading. guaranteeing optimal solutions, satisficing planner may
well produce solutions cases.

522

fiThe Deterministic Part IPC-4: Overview

course, coincidence. large agreement community
several problems hand-tailored track ran IPC-2 IPC-3.
important criticism that, hand-tailored planners, performance runtime
plan quality results set benchmarks. Whats also important maybe
important aspect much effort spent achieving results: hard
tailor planner? latter obviously important question, likewise
obviously isnt easy answer. discussed matter lot people (e.g.,
ICAPS03 workshop), no-one could come idea seemed adequate
feasible. basically offered hand-tailored planners opportunity participate
track similar previous ones, maybe additional ad-hoc measurements
many person hours spent tailoring planner domain. Apart
evaluation shortcomings approach, another important reason
hand-tailored planners registered participating track huge amount
work maintaining/developing planner plus understanding domains tailoring
planner. Understanding domains would particularly hard
complex domains used IPC-4. thus, obviously, difficult find enough time
participate hand-tailored IPC. future hand-tailored track
said Section 7.

3. PDDL 2.2
said, IPC-4 competition language PDDL2.2 extension first three levels
PDDL2.1 (Fox & Long, 2003). PDDL2.2 inherits separation levels.
language features added top PDDL2.1 derived predicates (into levels 1,2, 3)
timed initial literals (into level 3 only). discuss two features
order, describing syntax semantics. full BNF description PDDL2.2
Appendix A.
3.1 Derived Predicates
Derived predicates implemented several planning systems past,
example UCPOP (Penberthy & Weld, 1992). predicates affected
actions available planner. Instead, predicates truth values
derived set rules form (x) P (x). semantics, roughly,
instance derived predicate (a derived predicate whose arguments instantiated
constants; fact, short) TRUE derived using available
rules (more details below). name axioms, derived predicates part
original PDDL language defined McDermott (McDermott et al., 1998) first
planning competition, never put use competition benchmark
(we use name derived predicates instead axioms order avoid confusion
safety conditions).
Derived predicates combine several key aspects made useful language extension IPC-4:
practically motivated: particular, provide concise convenient
means express updates transitive closure relation. updates occur
523

fiHoffmann & Edelkamp

domains include structures paths flows (electricity flows, chemical
flows, etc.); particular, PSR domain includes kind structure.
also theoretically justified compiling away infeasible.
recently proved that, worst case, compiling derived predicates away
results exponential blow either problem description plan length
(Thiebaux, Hoffmann, & Nebel, 2003, 2005).
Derived predicates cause significant implementation overhead in, least,
state transition routines used forward search planners. world state
truth values non-derived, basic, predicates known, computing truth
values derived predicates trivial.3
IPC-4 benchmarks, derived predicates used non-durational context, PDDL2.2 level 1.
3.1.1 Syntax
BNF definition derived predicates involves two small modifications BNF
definition PDDL2.1:
hstructure-defi ::=:derivedpredicates hderived-defi

domain file specifies list structures. PDDL2.1 either actions
durational actions. also allow derived definitions points.
hderived-defi ::= (:derived hatomic formula(term)i hGDi)

derived definitions rules mentioned above. simply specify
predicate P derived (with variable vector x), formula (x) instances P concluded true. Syntactically, predicate variables
given hatomic formula(term)i expression, formula given hGDi (a goal
description, i.e. formula).
BNF generous actually allow PDDL2.2, respectively
IPC-4. make number restrictions ensure definitions make sense
easy treat algorithmically. call predicate P derived rule
predicate P head; otherwise call P basic. restrictions make
following.
1. actions available planner affect derived predicates: derived
predicate occurs effect lists domain actions.
2. rule defines P (x) derived (x), variables x
pairwise different (and, notation suggests, free variables (x) exactly
variables x).
3. Note, though, may much less trivial adapt heuristic function handle derived predicates;
is, example, discussed Thiebaux et al. (2003, 2005).

524

fiThe Deterministic Part IPC-4: Overview

3. rule defines P (x) derived , Negation Normal Form
(NNF) (x) contain derived predicates negated form.
first restriction ensures separation predicates
planner affect (the basic predicates) (the derived predicates) whose truth
values follow basic predicates. second restriction ensures rule right
hand sides match rule left hand sides. Let us explain third restriction. NNF
formula obtained pushing W
negations V
downwards, i.e.
x :
V transforming
W
x : (), x : x : (), (i ), (i ). Iterating
transformation steps, one ends formula negations occur front
atomic formulas predicates variable vectors, case. formula contains
predicate P negated form occurrence P negated.
requiring formulas rules (that derive predicate values) contain
derived predicates negated form, ensure negative interactions
applications rules (see semantics below).
example derived predicate predicate Blocksworld,
true blocks x whenever x transitively (possibly blocks
between) y. Using derived predicates syntax, predicate defined follows.
(:derived (above ?x ?y)
(or (on ?x ?y)
(exists (?z) (and (on ?x ?z)
(above ?z ?y)))))

Note formulating truth value terms effects normal
Blocksworld actions awkward. Since set atoms affected action depends
situation, one either needs artificial actions complex conditional effects.
3.1.2 Semantics
describe updates need made PDDL2.1 semantics definitions
given Fox Long (2003). introduce formal notations capture semantics
derived predicates. hook semantics PDDL2.1 language
modifying two Fox Long (2003)s definitions.
Say given truth values (instances the) basic predicates, want
compute truth values (instances the) derived predicates that.
situation every time applied action, parallel action set. durational
context, situation happenings current plan, every time
durative action starts finishes. Formally, want function
maps set basic facts (instances basic predicates) set enriched
derived facts (the derivable instances derived predicates). Assume given
set R rules derived predicates, elements R form (P (x), (x))
(x) P (x). D(s), set basic facts s, defined follows.
\
D(s) := {s0 | s0 , (P (x), (x)) R : c, |c| = |x| : (s0 |= (c) P (c) s0 )}
(1)
definition uses standard notations modelling relation |= states
(represented sets facts case) formulas, substitution (c)
525

fiHoffmann & Edelkamp

free variables formula (x) constant vector c. words, D(s) intersection
supersets closed application rules R.
Remember restrict rules contain derived predicates negated
form. implies order rules applied state matter
(we lose derived facts deriving facts first). This, turn, implies
D(s) closed application rules R. words, D(s) least
fixed point possible applications rules R state derived facts
assumed FALSE (represented contained s).
constructively, D(s) computed following simple process.
s0 :=

select rule (P (x), (x)) vector c constants,
|c| = |x|, s0 |= (c) P (c) 6 s0
0
let := s0 {P (c)}
rule constant vector exist
let D(s) := s0
words, apply applicable rules arbitrary order new facts
derived anymore.
specify executable plan PDDL2.1 derived predicates.
need hook function Definition 13, Happening Execution,
given Fox Long (2003). definition, Fox Long (2003) define state
transitions plan. happenings (temporal non-temporal) plan time
points least one action effect occurs. Fox Long (2003)s definition this:
Definition 13 Happening Execution (Fox & Long, 2003)
Given state, (t, s, x) happening, H, activity H set grounded actions
AH = {a| name H, valid
P rea satisfied (t, s, x)}
result executing happening, H, associated time tH , state (t, s, x)
undefined |AH | =
6 |H| pair actions AH mutex. Otherwise, state
0
0
(tH , , x )
[
[
s0 = (s \
Dela )
Adda
(2)
aAH



x0

aAH

result applying composition functions {NPFa | AH } x.

Note happenings consist grounded actions, i.e., operator parameters
instantiated constants. introduce semantics derived predicates,
modify result executing happening. (We also adapt definition mutex
actions, see below.) result executing happening obtained applying
actions s, subtracting derived facts this, applying function D.
is, definition replace Equation 2 following:
[
[
s0 = D(((s \
Dela )
Adda ) \ D)
(3)
aAH

aAH

526

fiThe Deterministic Part IPC-4: Overview

denotes set derived facts. derived predicates,
empty set identity function.
example, say Blocksworld instance B C, =
{clear(A), on(A, B), on(B, C), ontable(C), above(A, B), above(B, C), above(A, C)},
happening applies action moves table. happening execution
result computed removing on(A, B) s, adding clear(B) ontable(A)
s, removing above(A, B), above(B, C), above(A, C) s, applying
this, re-introduce (only) above(B, C). s0 s0 = {clear(A), ontable(A),
clear(B), on(B, C), ontable(C), above(B, C) }.
definition happening execution, Fox Long (2003) define state transitions plan. definitions executable plan is, plan achieves
goal, standard. plan executable result happenings
plan defined. means action preconditions fulfilled state
execution, two pairs actions happening mutex. plan achieves
goal goal holds true state results execution actions
plan.
extension definition happening executions, definitions
plan executability goal achievement need changed. do, however, need
adapt definition pair actions mutex. important happenings
contain one action, i.e., consider parallel (Graphplan-style) concurrent (durational) planning. Fox Long (2003) give conservative definition forbids
actions interact possible way. definition following.
Definition 12 Mutex Actions (Fox & Long, 2003)
Two grounded actions, b non-interfering
GP rea (Addb Delb ) = GP reb (Adda Dela ) = ,
Adda Delb = Addb Dela = ,
La Rb = Ra Lb = ,
La Lb La Lb

(4)

two actions non-interfering mutex.
Note definition talks grounded actions operator parameters
instantiated constants. La , Lb , Ra , Rb refer left right hand side
bs numeric effects. Adda /Addb Dela /Delb bs positive (add)
respectively negative (delete) effects. GP rea /Gpreb denotes (ground) facts occur
as/bs precondition.
preconditionWcontains quantifiers grounded (x
V
transforms ci , x transforms ci ci objects given instance),
GP defined resulting quantifier-free (and thus variable-free) formula. Note
definition mutex actions conservative if, example, fact F occurs
positively precondition, matter F among add effects
b. conservative definition advantage makes algorithmically easy
figure b mutex.
presence derived predicates, definition needs extended exclude possible interactions arise indirectly due derived facts, precondition
one action, whose truth value depends truth value (basic) facts affected
527

fiHoffmann & Edelkamp

effects action. spirit Fox Long (2003) forbid
possibility direct interaction, forbid possibility indirect interaction.
Assume ground rules (P (x), (x)) derived predicates, i.e., insert
possible vectors c constants; also ground quantifiers formulas (c), ending variable free rules. define directed graph nodes (ground)
facts, edge fact F fact F 0 inserted iff grounded rule (P (c), (c))
F 0 = P (c), F occurs (c). say action a, ground
facts occurring precondition are, see above, denoted GP rea . DP rea denote
ground facts possibly influence truth values derived facts GP rea :
DP rea := {F | path F F 0 GP rea }

(5)

definition mutex actions updated simply replacing Equation 4 with:
(DP rea GP rea ) (Addb Delb ) =
(DP reb GP reb ) (Adda Dela ) = ,
Adda Delb = Addb Dela = ,
La Rb = Ra Lb = ,
La Lb La Lb

(6)

Note thing changed first line, regarding interference propositional effects preconditions. example, reconsider Blocksworld
predicate. Assume action moves block table requires additional, derived, precondition, third block. Then, principle, two
actions move two different blocks B table executed parallel.
block (B) influence relations B (A) participates; however, matter B moved implies
clear, implies top different stacks anyway. observe
latter statement domain semantics either requires non-trivial
reasoning, access world state actions executed. order avoid
need either non-trivial reasoning domain semantics, resort forward
search, definition conservative one given above. definition makes actions
moving B mutex grounds possibly influence others derived
preconditions.
definition adaptations described suffice define semantics derived
predicates whole PDDL2.2. Fox Long (2003) reduce temporal case
case simple plans above, adapting simple-plan definitions automatically
adapted definitions complex cases. temporal setting, PDDL2.2 level 3,
derived predicates semantics values computed anew happening
plan action effect occurs. said, IPC-4 used derived predicates
non-temporal setting. remarks limitations IPC-4 treatment derived
predicates, future prospects, Section 7.
3.2 Timed Initial Literals
Timed initial literals syntactically simple way expressing certain restricted
form exogenous events: facts become TRUE FALSE time points
known planner advance, independently actions planner chooses
528

fiThe Deterministic Part IPC-4: Overview

execute. Timed initial literals thus deterministic unconditional exogenous events.
Syntactically, simply allow initial state specify beside usual facts
true time point 0 literals become true time points greater 0.
Timed initial literals practically relevant: real world, deterministic unconditional exogenous events common, typically form time windows
within shop opened, within humans work, within traffic slow,
within daylight, within seminar room occupied, within nobody answers mail conferences, etc. timed initial literals
syntax simplest way one think communicate things
planner.
Timed initial literals easily compiled artificial constructs (Fox, Long, &
Halsey, 2004), involving linear blow-up instance representation plan
length (i.e., number actions it). Still seems highly likely handing timed
literals automated planner explicitly results far better performance
one hands artificial (compiled) representation. results obtained IPC-4
confirm this, see also Section 5.
3.2.1 Syntax
BNF notation is:
hiniti ::= (:init hinit-eli )
hinit-eli ::=:timedinitialliterals (at hnumberi hliteral(name)i)

requirement flag timed initial literals implies requirement flag durational
actions, i.e., said language construct available PDDL2.2 level 3. times
hnumberi timed literals occur restricted greater 0.
also derived predicates domain, timed literals restricted influence
these, i.e., like action effects allowed affect truth values
basic (non-derived) predicates (IPC-4 use derived predicates timed initial
literals within domain).
illustrative example, consider planning task goal completed
shopping. single action go-shopping achieves goal, requires
(single) shop open precondition. shop opens time 9 relative initial
state, closes time 20. express shop opening times two timed initial
literals:
(:init
(at 9 (shop-open))
(at 20 (not (shop-open)))
)

3.2.2 Semantics
describe updates need made PDDL2.1 semantics definitions
given Fox Long (2003). Adapting two definitions suffices.
529

fiHoffmann & Edelkamp

first definition need adapt one defines simple plan,
happening sequence, is. original definition Fox Long (2003) this.
Definition 11 Simple Plan (Fox & Long, 2003)
simple plan, SP , planning instance, I, consists finite collection timed simple
actions pairs (t, a), rational-valued time action name.
happening sequence, {ti }i=0...k SP ordered sequence times set
times appearing timed simple actions SP . ti must greater 0.
possible sequence empty (an empty plan).
happening time t, Et , happening sequence SP , set
(simple) action names appear timed simple actions associated time SP .
STRIPS case, time stamps natural numbers 1, . . . , n n
actions/parallel action sets plan. happenings actions/parallel action
sets respective time steps. Fox Long (2003) reduce temporal planning case
simple plan case defined splitting durational action least two
simple actions start action, end action, possibly several actions
guard durational actions invariants points action effects occur.
temporal case, happening sequence comprised time points
something happens, i.e., action effect occurs.
introduce intended semantics timed initial literals, need
definition introduce additional happenings temporal plan, namely time
points timed initial literal occurs. timed initial literals interpreted
simple actions forced respective happenings (rather selected
planner), whose precondition true, whose effect respective
literal. rest Fox Long (2003)s definitions carry directly (except goal
achievement, involves little care, see below). PDDL2.2 definition simple
plans here.
Definition 11 Simple Plan
simple plan, SP , planning instance, I, consists finite collection timed simple
actions pairs (t, a), rational-valued time action name.
tend denote largest time SP , 0 SP empty.
Let L (finite) set timed initial literals, given pairs (t, l)
rational-valued time occurrence literal l. identify timed initial literal (t, l)
L uniquely named simple action associated time t, whose precondition
TRUE, whose effect l.
happening sequence, {ti }i=0...k SP ordered sequence times set
times appearing timed simple actions SP L. ti must greater
0. possible sequence empty (an empty plan).
happening time t, Et , happening sequence SP , set
(simple) action names appear timed simple actions associated time SP
L.
Thus happenings temporal plan points time either action
effect, timed literal, occurs. timed literals simple actions forced
plan. construction, Fox Long (2003)s Definitions 12 (Mutex Actions) 13
530

fiThe Deterministic Part IPC-4: Overview

(Happening Execution), described (and adapted derived predicates) Section 3.1.2,
kept unchanged. state action effect allowed interfere timed
initial literal, timed initial literals true state results
execution happening contained in. Fox Long (2003)s Definition 14
(Executability plan) also kept unchanged timed initial literals change
happenings plan, conditions happening executed.
definition need reformulate makespan valid plan
is. Fox Long (2003)s original definition, implicit definition valid
plans. definition this.
Definition 15 Validity Simple Plan (Fox & Long, 2003)
simple plan (for planning instance, I) valid executable produces final
state S, goal specification satisfied S.
makespan valid plan accessible PDDL2.1 PDDL2.2 totaltime variable used optimization expression. Naturally, Fox Long
(2003) take makespan end plan, time point plans final state.
presence timed initial literals, question plans makespan
becomes little subtle. Fox Long (2003)s original definition,
makespan would end happenings simple plan, include timed
initial literals (see revised Definition 11 above). plan would least take long
takes timed literals occur. plan might finished long
imagine something needs done daylight; certainly plan
need wait sunset. therefore define makespan earliest point
time goal condition becomes (and remains) true. Formally reads
follows.
Definition 15 Validity Makespan Simple Plan
simple plan (for planning instance, I) valid executable produces final
state S, goal specification satisfied S. plans makespan
smallest tend that, happenings times t0 plans happening
sequence, goal specification satisfied execution happening.
Remember tend denotes time last happening plan contains
effect caused plans actions simpler terms, tend end point plan.
definition says plan valid if, time point plans
end, goal condition achieved remains true last timed literal
occurred. plans makespan first time point t. Note planner
use events achieve goal, nothing timed literal occurs
makes goal condition true waiting time nearest timed
literal counted plans makespan. (The latter done avoid situations
planner could prefer wait millions years rather applying single action
itself.) Remember makespan plan, defined above, denoted
total-time optimization expression defined problem instance.
derived predicates, definition adaptations suffice define
semantics timed initial literals PDDL2.2. remarks limitations language
construct, future prospects, Section 7.
531

fiHoffmann & Edelkamp

4. Competitors
provide overview table listing systems along language capabilities
(subset PDDL2.2 covered), sketch competing systems. deterministic
part IPC-4 attracted 19 competitors (21 counting different system versions), 12
(14) satisficing 7 optimal. competitor wrote 23 page extended abstract inclusion IPC-4 booklet ICAPS 2004 (Edelkamp
et al., 2004). included sketches brief outlines abstracts. reader
encouraged read original work system authors.
point appropriate say words system development. allowed
competitors modify systems competition phase, i.e., data collection
running. reasons twofold. First, domains quite
unusual particularly, containing ADL constructs compiled STRIPS
(rightly) expected planner implementations parsing etc. trouble them. Second,
experience competitions knew people try enhance
planners anyway see much point forbidding this. trusted
competitors stupid things like hard-coding domain names etc., trusted
diverse enough range domains make tuning domain-independent task.
alternative would collect executables data collection,
results collected organizers. Anyone ever run experiments
someone elses planner knows approach completely infeasible due
prototype-nature systems, due many tiny details minor language
changes, programming environments, etc. one wants obtain meaningful results,
least. One could principle apply strict failure counted unsolved rule,
would likely lay way much emphasis little programming errors
nothing evaluated algorithms.
competition phase was, roughly, February 2004 middle May 2004. time, released domains one-by-one, competitors worked
systems, handing results us ready. end phase,
competitors submit executable, ran sampled tests see
executable really produce reported results, across domains. abstracts
describing systems delivered little earlier, end April, due timing
constraints printing booklet.
start overview table, sketch satisficing optimal competitors.
4.1 Planner Overview
overview participating satisficing planners, language capabilities (defined
language features attacked IPC-4), given Table 1.
Observe planners treat small subset PDDL2.2: quick
glance table, one sees far (-) entries (+) entries. Note
that, often, even (+) sign given, planner may treat subset
specified language feature (as needed respective IPC-4 domain). example,
planner might treat subset ADL, linear arithmetic numeric variables.
leave details sake readability.
532

fiThe Deterministic Part IPC-4: Overview

CRIKEY
FAP
FD, FDD
LPG-TD
Macro-FF
Marvin
Optop
P-MEP
Roadmapper
SGPlan
Tilsapa
YAHSP
BFHSP
CPT
HSPa
Optiplan
SATPLAN
SemSyn
TP4

ADL
+
+
+
+
+
+
+
+
-

DP
+
+
+
+
+
-

Numbers
+
+
+
+
+
+
+
+
+

Durations
+
+
+
+
+
+
+
+
+

TL
+
+
+
+
+
-

Table 1: overview planners IPC-4, language capabilities (i.e.,
language features attacked IPC-4). satisficing planners top half
table, optimal planners bottom half. table entry specifies
whether (+) (-) planner handle language feature. DP short
derived predicates, TL short timed initial literals. Numbers
Durations mean numeric fluents fixed action durations (no duration
inequalities), sense PDDL2.1 level 2 3, respectively. planners
(and name abbreviations) explained below.

LPG-TD, Optop, SGPlan planners treat full range PDDL2.2,
used IPC-4. Three satisficing planners (FAP, Roadmapper, YAHSP), three
optimal planners (BFHSP, Optiplan, SATPLAN), treat pure STRIPS. Derived
predicates treated 4 planners, timed initial literals 5 planners, ADL 7 planners,
numeric variables 8 planners, action durations 9 planners.
Table 1 shows significant amount acceptance new (PDDL2.1
PDDL2.2) language features, terms implemented systems participating
IPC. Table 1 also shows development systems side tendency
slower development IPC language side: even wide-spread language
feature beyond STRIPS, action durations, dealt less half 19 planners.
opinion, taken indicate language extensions
made slowly. said Section 7.
533

fiHoffmann & Edelkamp

4.2 Satisficing Planners
satisficing planners planners giving guarantee quality returned
plan following. proceed alphabetical order.
CRIKEY Keith Halsey, University Strathclyde, Glasgow, UK. CRIKEY
heuristic search forward state space planner. includes heuristic relaxed plans
temporal numeric problems applies scheduler based simple temporal networks
allow posterior plan scheduling.
FAP Guy Camilleri Joseph Zalaket, University Paul Sabatier / IRIT CCICSC, France. FAP handles non-temporal non-numeric domains. heuristic planner
using relaxed planning heuristic N -best forward search, meta-actions (action
sequences) extracted relaxed planning graph perform jumps state space.
Fast Downward, FD short, Fast Diagonally Downward, FDD short,
Malte Helmert Silvia Richter, University Freiburg, Germany. FD FDD
treat non-temporal non-numeric domains. apply new heuristic estimate based
polynomial relaxation automatically inferred multivariate SAS+ representation
problem space. FDD also applies traditional FF-style relaxed planning heuristic,
i.e., applies heuristics hybrid search algorithm.
LPG-TD Alfonso Gerevini, Alessandro Saetti, Ivan Serina, Paolo Toninelli,
University Brescia, Italy. extensions randomized local plan graph search
already included LPG IPC-3 includes functionality PDDL2.2 derived
predicates timed initial literals, well various implementation refinements. version tailored computation speed, LPG-TD.speed, version tailored plan quality,
LPG-TD.quality, participated. LPG-TD.quality differs LPG-TD.speed basically
stop first plan found continues stopping criterion
met. LPG-TD team also ran third version, called LPG-TD.bestquality,
used, every instance, entire half hour CPU time available produce good plan
possible. third version included official data every team
allowed enter two system versions.
Macro-FF Adi Botea, Markus Enzenberger, Martin Muller, Jonathan Schaeffer,
University Alberta, Canada. name suggests Macro-FF extends Hoffmanns FF
planner macro operators (and implementation refinements). Macros learned
prior search fed planner new data, separated operator file
problem file. runtime, regular actions macro-actions used state
expansion. Heuristic rules pruning instantiations macros added FFs original
strategy search control.
Marvin Andrew Coles Amanda Smith, University Strathclyde, Glasgow,
UK. Marvin extends FF adding extra features preprocessing information,
plateau-escaping macro actions, enhance search algorithm.
Optop Drew McDermott, Yale University, USA. Optop extension wellknown UNPOP planner, ability handle complex input language including,
amongst things, autonomous processes running parallel actions taken
planner. underlying principle forward search heuristic guidance obtained
greedy-regression match graphs built backwards goals.
534

fiThe Deterministic Part IPC-4: Overview

P-MEP Javier Sanchez, Minh Tang, Amol D. Mali, University Wisconsin,
USA. P-MEP short Parallel Expressive Planner. Unlike planners, P-MEP
treat numeric variables non-linear action effects. employs forward search
relaxed plan heuristics, enhanced relevance detection pre-process, taking
account exclusion relations relaxed planning.
Roadmapper Lin Zhu Robert Givan, Purdue University, USA. Roadmapper
handles non-temporal non-numeric domains. forward heuristic search planner enhancing FF heuristic reasoning landmarks. latter propositions
must true point every legal plan. Roadmapper finds landmarks
pre-process, arranges directed road-map graph, uses graph assign
weights actions FF-style relaxed plans.
SGPlan Yixin Chen, Chih-Wei Hsu Benjamin W. Wah, University Illinois,
USA. planner bootstraps heuristic search planners applying Lagrange optimization
combine solution planning subproblems. split problem, ordering
planning goals derived. incremental local search strategy applied Lagrange
optimization top individual planners relies theory extended saddle points
mixed integer linear programming.
Tilsapa Bharat Ranjan Kavuluri Senthil U., AIDB Lab, IIT Madras, India.
planner extends SAPA system handles temporal numeric domains,
ability handle timed initial literals.
YAHSP Vincent Vidal, University Artois, France. YAHSP, acronym
yet another heuristic search planner, searches forward FF-style relaxed planning
heuristic. main enhancement relaxed-plan-analysis phase replaces actions
relaxed plan based heuristic notions better suitability reality, producing
macro-actions process. macro-actions are, basically, long possible feasible
sub-sequences (modified) relaxed plan.
4.3 Optimal Planners
participating optimal planners following, alphabetical order.
BFHSP Rong Zhou Eric A. Hansen, Mississippi State University, USA. BFHSP,
breadth-first heuristic search planner, optimizes number actions plan.
planner implements standard max-atom max-pair heuristics (as well
max-triple heuristic, however used IPC-4). main difference
systems search algorithm called breadth-first heuristic search; improves memory
requirements A* search searching set nodes certain threshold value
breadth-first instead best-first manner.
CPT Vincent Vidal, University Artois, France, Hector Geffner, University
Pompeu Fabra, Barcelona, Spain. CPT optimizes makespan. planner based
constraint satisfaction, transforms planning problem CSP. branching
scheme solves CSP makes use several constraint propagation techniques related
POCL, temporal max-atom heuristic.
HSPa Patrik Haslum, Linkoping University, Sweden. HSP*a derivate TP4, see
below, expressivity, weakened version MaxTriple heuristic
instead MaxPair heuristic.
535

fiHoffmann & Edelkamp

Optiplan Menkes van der Briel Subbarao Kambhampati, Arizona State University, USA. Optiplan planner based integer programming (IP), consequent extension encoding planning graph used planning satisfiability
approach (see below). compiled planning problem solved using CPLEX/ILOG
system. interesting property Optiplan that, due power underlying IP
solver, optimize great variety different plan metrics, fact every plan metric
expressed linear function. respect, planner unique.
IPC-4, step-optimal plans computed typically efficient.
SATPLAN04, SATPLAN short, Henry Kautz, David Roznyai, Farhad TeydayeSaheli, Shane Neph, Michael Lindmark, University Washington, USA. SATPLAN
treats non-temporal non-numeric domains optimizes number parallel time steps.
system participate IPC-3 IPC-1 IPC-2, real comeback.
planner compiles planning problem series satisfiability tests, performance
system relies integrated back-end SAT solver. graph-plan encoding scheme
underwent minor changes, underlying SAT solver much powerful
4 years ago.
SemSyn Eric Parker, Semsyn Software, Tempe, Arizona. SemSyn system optimizes number actions. Semsyn linked commercial product applies
combination forward backward chaining. searches variants original
algorithms. Forward chaining goal-directed, backward chaining generalized, comprising partition top-level goal. product proprietary, detailed information
system limited.
TP4-04, TP4 short, Patrik Haslum, Linkoping University, Sweden. planner
extended makespan-optimal scheduling system IDA* search routine
max-pair heuristic. deal restricted form metric planning problems
numerical preconditions effects.

5. Results
CPU times IPC-4 measured machine located Freiburg, running 2
Pentium-4 CPUs 3 GHz, 6 GB main memory. Competitors logged remotely
ran planners, producing one separate ASCII result file solved instance,
giving runtime taken, quality found plan, well plan itself.
planner run allowed half hour (CPU, real) runtime, 1 GB memory,
i.e., cutoff values solving single instance. kind performance
measure, IPC-3 version LPG (Gerevini, Saetti, & Serina, 2003) (called LPG-3),
i.e. successful automatic planner IPC-3, also run (by developers,
top workload new planner version LPG-TD). remark that, sake
simplicity, save CPU time, ensure fairness, randomized planners allowed
single run one ach instance, fixed random seed.
IPC-4 featured lot domain versions instances, lot planners.
way fully understand results complex event examine results
detail, making sense combination descriptions/PDDL encodings
domains, techniques used respective planners. recommend so,
least extent, everybody interested results (the deterministic part
536

fiThe Deterministic Part IPC-4: Overview

of) IPC-4. on-line appendix paper includes individual solution files.
appendix also includes gnuplot graphics generated (more details below), well
GANNT chart result files; GANNT charts visualized using
Vega visualization front-end (Hipke, 2000).
follows, provide overview results, highlight (what think
are) important points; explain decided IPC-4 competition
awards.
precisely, Section 5.1 gives overview results, terms percentages
attacked solved instances per language subset planner. Section 5.2 describes
evaluated results, particularly procedure chose decide awards.
Thereafter, Sections 5.3 5.9 turn consider detail results single
domains.
5.1 Results Overview
One crude way obtain overview large data set simply count
number instances planner attacked, i.e. tried solve, succeeded
solve. case, also makes sense distinguish different PDDL2.2 subsets
used IPC-4 benchmarks. data displayed Table 2.
Table 2 complicated, needs explanation. First, consider columns
table. leftmost column is, usual, table indexing. rightmost column
contains data entire set instances IPC-4. columns refer
specific subset instances, way subsets disjunct
exhaustive i.e., instance sets associated columns pairwise disjunct,
union entire set instances. subsets instances defined PDDL2.2
subsets use. abbreviations Table 2 explained caption. X+Y means
instances use language features X Y, none features.
example, N+DP (only) instances uniform durations (i.e., PDDL2.2
level 1) derived predicates. Note Table 2 column possible
combinations language features show used (a non-empty
subset of) IPC-4 benchmarks. Note also distinguish different
domain formulations, i.e. ADL STRIPS. instance numbers Table 2
counted domain versions. is, ADL STRIPS formulation
version, instance counted once.4
first line Table 2, indexed Number, simply gives size instance set
associated column. lines correspond, obviously, planning systems.
upper half table contains, alphabetical order, satisficing planners; lower
half contains optimal planners. Note list one version LPG-TD.
speed quality version planner differ terms plan quality,
terms number attacked/solved instances.
4. said, domain featured several domain versions, differing terms application constraints
modelled. Within domain version, could several different domain version formulations,
differing terms precise PDDL subset used encode semantics. cases
one formulation, exactly two formulations, using/not using ADL constructs, respectively.
Competitors could choose formulation liked best results across different formulations
evaluated together.

537

fiHoffmann & Edelkamp

Number
CRIKEY
FAP
FD
FDD
LPG-3
LPG-TD
Macro-FF
Marvin
Optop
P-MEP
Roadmapper
SGPlan
Tilsapa
YAHSP
BFHSP
CPT
HSPa
Optiplan
SATPLAN
SemSyn
TP4

N
382
42 77
33 64
83 62
92 62
55 62
67 87
57 87
67 62
15 61
28 49
68 100
77
29
33
33
34
46
49
29

87
87
87
38
87
87
48
64

N+DP
196


84 100
84 100

75 74

34 100



65 100










N+NV
152


D+TL D+NV D+TL+NV
302
116
272
136
47 66

98 55
















42 24 45 62

56 50

61 37 76 62 63 100 96 50 87
100











8 43


8 55 24 45 24 43 13 32





64 100 75 90 78 74 85 100 74
100
10 69
62
63











22 100



10 62

50 50











11 37




17 62

52 50


56
33
83
88
51
76
57
52
8
17
28
73
38
77
29
28
29
34
46
40
31


1,556
61 42
74 16
75 28
75 28
54 38
71 71
100 21
75 28
7 3
43 38
56 12
96 96
13 11
100 21
100 21
100 41
44 30
100 21
100 21
23 15
54 37

Table 2: overview IPC-4 results. Used abbreviations: N durations, DP
derived predicates, NV numeric variables, durations, TL timed initial
literals. Line Number gives number instances, lines give percentage
values. entry, right number percentage instances
attacked, left number percentage solved i.e.
left number success ratio. rightmost column, middle number
percentage attacked instances relative instances lie within
language range respective planner; right number percentage
attacked instances all. dash indicates planner handle
language subset. See detailed explanation text.

Let us consider table entries leftmost rightmost columns, i.e.,
entries concerning planner X language/instance subset Y. numbers
entries success ratio attacked ratio. Precisely, obtained
follows. first counted number instances planner X tried solve
definition take domain versions (inside Y) X delivered results,
set total number instances domain versions. counted
number x instances planner X succeeded solve. obtained
first number table entry success ratio ratio (in percent) x divided
y. obtained second number entry attacked ratio ratio (in
percent) divided size Y. space reasons, rounded percentages
538

fiThe Deterministic Part IPC-4: Overview

values shown table. dash table entry means planner X
handle language subset Y. empty table entry means planner
handle Y, attack instance Y.
cases, namely Promela domain, see discussion Section 5.5,
could formulate largest instances STRIPS (fully-grounded) representations became large. So, there, numbers test instances different
ADL STRIPS formulations domain version.5 Table 2 uses number
ADL instances, taking account subtlety. implies slight disadvantage
terms success ratio columns N All, planners attacked smaller
STRIPS test suites. planners following, correct column N success
ratio parentheses: CRIKEY (51), FAP (41), LPG-TD (74), SGPlan (80), YAHSP (92),
BFHSP (35), CPT (39), HSPa (52), Optiplan (41), SATPLAN (55), TP4 (37).
table entries rightmost column obtained similarly above. summarize situation regarding respective planners across used language subsets.
left right number entry give ratio number solved instances
number attacked instances, number attacked instances number
instances, respectively. number middle entry gives ratio number attacked instances number instances lie within language range
respective planner. included number order provide measure
extent planner/team attacked instances could attack.
remarks order regarding latter ratio, ratio attacked instances
general. First, rule telling competitors attack everything
competitors free choose. retrospect, feel
rule, since would make data interpretation easier. way things are, known
reason planner attack instance subset (domain version): Bad results?
interested? Overlooked? Second, many planners handle subsets certain language
features, like, numeric variables (NV). lead low percentages Table 2,
simplicity take account details. Third, one detail take
account 50 382 instances column N (namely, middle-compiled
version PSR domain, see Section 5.6) formulated ADL only, thus
accessible many planners. planners able handle ADL, computing
middle number rightmost table entry, subtracted 50 instances
instances within language range respective planner. column N, however,
took usual ratio set instances particular, Macro-FF,
YAHSP, BFHSP, CPT, Optiplan, SATPLAN 87% attacked-ratio N
column, 100% attacked-ratio middle number rightmost column.
all, planners pretty good coverage language subset could
attack; except Optop, Tilsapa, maybe Semsyn. planners/teams probably
interested small subset instances.6 cases instances
5. PSR, also impossible formulate largest instances STRIPS. But, there, split
domain different versions regarding size formulation language instances.
want introduce distinction lines Promela already 8 different domain
versions.
6. Drew McDermott, developer Optop, told us private conversation tried solve
complicated domain versions.

539

fiHoffmann & Edelkamp

left out, planners/teams typically attack domain versions derived
predicates timed initial literals compiled away. Note lack coverage
may also due language details accounted rather crude distinctions made
Table 2.7
conclude Table 2, terms planner performance? spotlights
these:
success ratios optimal planners generally lower satisficing
planners. largest overall success ratio optimal planner, SATPLAN, 46
(55 taking account mentioned subtlety regarding ADL/STRIPS
formulations Promela); compared 88 FDD.
However, also various cases optimal planner higher success
ratio satisficing one.
FD, FDD, YAHSP best success ratios (as mentioned, success ratio
YAHSP N column 92 taking account ADL/STRIPS Promela).
FD FDD also pretty good coverage N N+DP columns, i.e.
within PDDL2.2 level 1 (the left instances domain versions compiled
derived predicates).
SGPlan extremely high coverage, attacking 96% instances. Even so,
competitive success ratio. (Concretely, SGPlan solved 1,090 1,556 IPC-4
instances; attacked 1,496. second place terms number instances
solved held LPG-TD, solved 843 1108 instances could attack.)
LPG-3, i.e. IPC-3 version LPG, ranges somewhere middle-ground
planners, terms success ratio coverage. indicates significant
performance improvements made difference IPC-3. (Note holds
new LPG version top performance planners.)
Naturally, evaluation results, particularly evaluation formed
basis award decisions, undertook detailed examination data set.
considered, much possible, scaling behavior, rather simple instance counts
above. follows, first explain evaluation process detail, consider
domains turn.
5.2 Results Evaluation
said, runtime data satisficing optimal planners considered separately.
plan quality, distinguished three kinds optimization criteria: number
actions, makespan (equalling number time steps non-temporal domains),
metric value. last three defined :metric specification
respective task. compared planner according single plan quality
criterion. is, every domain version competitors told us criterion
7. private conversation, LPG-TD team told us case LPG-TD,
fact attacked domain versions could time IPC-4 running.

540

fiThe Deterministic Part IPC-4: Overview

planner trying optimize domain version. evaluated (and only)
planners together tried optimize criterion. reason
make sense evaluate planners based criteria dont actually consider.
Altogether, every domain version created 5 gnuplot graphics: satisficing
runtime, optimal runtime, number actions, makespan, metric value.
plan quality data optimal planners put plots satisficing
planners, enable comparison. cases, split runtime figure
(typically, satisficing planners) two separate figures many runtime
curves graphic became unreadable.
Based gnuplot graphics, evaluated data terms asymptotic runtime
solution quality performance. comparisons planners made
hand, i.e. looking graphs. simplistic, believe adequate
way evaluating data, given goals field, demands event.
agreed interested (typical) scaling behavior planners
specific domains. excludes formal primitive comparative performance
measures counts instances solved efficiently planner may scale worse
another planner, yet faster lot smaller instances due pre-processing
implementation details. ideal formal measure performance would approximate
actual scaling functions underlying planners data points. infeasible
generate enough data, event like IPC, formal approximations.
tried judge scaling behaviors hand, laying emphasis efficiently/if
largest instances test suite solved planner.8
rest section contains one sub-section domain turn. subsection provides following material. First, give brief description domain
important features (such domain versions formulations used IPC-4).
include set gnuplot graphics containing (what think are) important
observations regarding runtime (the total set gnuplot graphs space-consuming).
discuss plan quality, data comparing relative performance pairs planners.
also add intuitions regarding structural properties domains, possible
influence performance planners. Finally, provide information 1st
2nd places, see underlying decisions awards. information
contained text paragraph end sub-section domain.
basis deciding awards, within every domain version, identified
group planners scaled best roughly similar. planners counted
1st place domain version. Similarly, also identified groups 2nd place
planners. awarding prizes simply based number 1st 2nd
places planner, see Section 6.9
consider domains alphabetical order. start,
remarks made. First, planners left plots order make
8. Note success ratios displayed Table 2 also crude way access scaling behavior.
9. course, many decisions 1st 2nd places close; numerous special
cases due to, e.g., planners participated domain versions; summing places introduces
dependency results number domain versions individual domains. hand
awards one make decisions, decisions lot detail bound disappear. One
cannot summarize results huge event prizes.

541

fiHoffmann & Edelkamp

plots readable. Specifically, left LPG-TD.quality well LPG-3.quality (the
IPC-3 version LPG preference quality); planners always slower
counterparts preference speed. also left FD, since cases
showed similar behavior FDD. chose FDD cases performance
superior. Note distinguish runtime performance optimal
planners optimizing different criteria. Finally, make significant difference whether
planner run ADL encoding, compilation STRIPS; distinction also
gets lost evaluation. emphasize applied simplifications order
improve readability understandability results. wish imply
planners/distinctions omitted arent important.
5.3 Airport
Airport domain, planner control ground traffic airport. task
find plan solves specific traffic situation, specifying inbound outbound
planes along current goal positions airport. planes must
endanger other, i.e. must occupy airport segment (a smallest
road unit), plane x drives behind plane x must safety
distance (depending size y). safety constraints modelled terms
blocked occupied predicates, whose value updated controlled via complex
ADL preconditions conditional effects.
four different versions domain IPC-4: non-temporal version,
temporal version, temporal version time windows, temporal version
compiled time windows. time windows latter two versions concern airplanes
known land future, thus block certain airport segments (runways)
certain time windows. time windows modelled using timed initial literals,
respectively compilation. every domain version, ADL formulation,
well STRIPS formulation obtained compiling ADL constructs away (resulting
partially grounded encoding).
Instances scale terms size underlying airport, well number
airplanes must moved. One remarkable thing Airport domain
instances generated based professional airport simulation tool. largest
instances used IPC-4 (number 36 50) correspond real airport, namely Munich
airport (MUC). Instance number 50 encodes traffic situation 15 moving airplanes,
typical situations encountered MUC reality. Instances number 1 20
come smaller toy airports, instances number 21 35 based one half MUC
airport.
Figure 1 shows runtime performance non-temporal version domain.
readability, set satisficing planners split two graphs. case
graphs displayed subsequent discussions, x-axis denotes instance number
(obviously, higher number larger instance), y-axis gives CPU runtime
seconds logarithmic scale. CPU time total, including parsing form
static pre-processing.
observed Figure 1 FDD planner solving problem instances. LPG-TD SGPlan scale relatively well, fail largest instances.
542

fiThe Deterministic Part IPC-4: Overview

10000

1000

10000
LPG-TD
MACRO-FF
SGPLAN
CRIKEY
FDD
YAHSP

1000

100

100

10

10

1

1

0.1

0.1

0.01

FAP
MARVIN
PMEP
ROADMAPPER
LPG-3

0.01
5

10

15

20

25

30

35

40

45

50

5

10

15

20

(a)

25

30

35

40

45

50

(b)
10000
BFHSP
TP4
CPT
OPTIPLAN
SATPLAN
SEMSYN

1000

100

10

1

0.1

0.01
5

10

15

20

25

30

35

40

45

50

(c)
Figure 1: Performance non-temporal Airport, satisficing (a) (b), optimal (c).

planners behave much unreliably. Observe also IPC-3 version
LPG lags far behind FDD, LPG-TD, SGPlan. optimal planners, unsurprisingly behave clearly worse satisficing planners, clear-cut observation
performance advantage SATPLAN. optimal planners behave relatively
similarly; Semsyn BFHSP ones group solving larger
instances.
plan quality, two groups planners, one trying minimize number
actions, one trying minimize makespan, i.e. number parallel action steps.
former group, plan quality performance differences moderate. CRIKEY, LPGTD, SGPlan, YAHSP sometimes find sub-optimal plans. FDDs plans optimal
cases optimal planner found solution. measure comparative plan
quality, provide, given planners B, min, mean, maximum
ratio quality(A) divided quality(B), instances solved
B. call data ratio vs B. CRIKEY (A) vs FDD (B), ratio 0.91
(min), 1.04 (mean), 1.45 (max), [0.91(1.04)1.45] short. LPG-TD.speed vs FDD
543

fiHoffmann & Edelkamp

ratio [0.91(1.08)1.80]; LPG-TD.quality vs FDD [0.91(1.06)1.80]. SGPlan
vs FDD [0.91(1.07)2.08]; YAHSP vs FDD [0.91(1.07)1.43].
group planners minimizing makespan, (only) Marvin tendency find
long plans. comparison Marvin vs optimal SATPLAN [1.00(2.46)4.64].
maximum case, SATPLAN finds plan 53 steps, Marvins plan 246 steps
long.
interesting observation concerns two scaling parameters domain:
number airplanes, size airport. plots Figure 1, also
plots Figure 2 below, one observe instances number 26 35 become
increasingly hard planners step instance number 36, performance
suddenly becomes better again. said above, instances 21 35 based one half
MUC airport, instances 36 50 based full MUC airport.
instances 26 35, number airplanes rises 6 12; instance 36 contains
2 airplanes, instances 37 38 contain 3. is, easier planners address
larger airport fewer planes. Note domain combinatorics: number
reachable states order n , number different airport segments,
n number airplanes.
Figure 2 shows runtime performance temporal versions domain.
first consider domain versions without time windows: parts (a) (b) figure.
satisficing planners, LPG-TD SGPlan scale well
non-temporal case; satisficing planners scale orders magnitude worse.
optimal planners, CPT scales best, followed TP4. two planners minimizing
number actions SGPlan CRIKEY; SGPlan behaves somewhat worse, ratio
[0.95(1.03)1.54]. planners minimize makespan, LPG-TD scales beyond
smallest instances. ratio LPG-TD.speed vs optimal CPT [1.00(1.15)1.70],
P-MEP vs CPT [1.00(1.11)1.42]. ratio LPG-TD.quality vs CPT [1.00(1.03)1.44].
optimal planner competition could handle timed initial literals, explicit time windows planner participated. compiled time windows, CPT
participated, scaling little worse temporal domain version without time windows. satisficing planners, results interesting. explicit time
windows, LPG-TD SGPlan maintain good scaling behavior simpler domain versions. planners, huge runtime performance gap.
SGPlan planner minimizes number actions. makespan ratio
LPG-TD.speed vs LPG-TD.quality [1.00(1.15)2.01]. compiled time windows,
SGPlan CRIKEY participated. former consistently solves smaller instances
certain size, latter fails many small instances solve
larger ones. Neither planners shows reasonable runtime performance compared
explicit encoding domain. number actions ratio CRIKEY vs SGPlan
[1.00(1.14)1.36].
main motivation including Airport domain IPC-4 able
model quite realistically, generate quite realistic test instances thing
could model real optimization criterion (which asks minimize summed
travel time airplanes). good scaling results of, least, satisficing
planners, encouraging. Note, however, reality optimization criterion
crucial importance, really reason using computer control traffic.
544

fiThe Deterministic Part IPC-4: Overview

10000

10000
TP4
CPT
HSPS_A

1000

1000

100

100

10

10

1

1

0.1

0.1

LPG-TD
SGPLAN
CRIKEY
PMEP
LPG-3

0.01

0.01
5

10

15

20

25

30

35

40

45

50

5

10

15

20

(a)

25

30

35

40

45

50

(b)

10000

10000
SGPLAN
CRIKEY

1000

1000

100

100

10

10

1

1

0.1

0.1

LPG-TD
SGPLAN
OPTOP
PMEP
TILSAPA

0.01

0.01
5

10

15

20

25

30

35

40

45

50

5

(c)

10

15

20

25

30

35

40

45

50

(d)

Figure 2: Performance temporal Airport, satisficing (a) optimal (b). temporal
Airport time windows, satisficing, explicit encoding (c) compiled encoding (d).

remark domain overly difficult perspective relaxed-plan
based heuristic planners (using wide-spread ignore deletes relaxation). Hoffmann
(2005) shows Airport instances contain unrecognized dead ends (states
goal cant reached, relaxed plan); states
likely occur often. dead end Airport occur two planes
block other, trying get across segment different directions. Due
topology airports (with one-way roads), happen densely populated
parking regions. case two airplanes respective paths goal position
disjoint, length relaxed plan provides exact distance nearest goal state.
sense, good runtime performance satisficing planners didnt come entirely
unexpected us, though expect behave well. Note
planners, particularly FDD, SGPlan, LPG-TD, much than/do things
545

fiHoffmann & Edelkamp

different standard heuristic search goal distances estimated relaxed plan
length. Note also Hoffmann (2005)s results specific non-temporal domains.
non-temporal domain version, awarded 1st places FDD (and FD)
SATPLAN; awarded 2nd places LPG-TD, SGPlan, Semsyn, BFHSP.
temporal version, awarded 1st places LPG-TD, SGPlan, CPT; 2nd place
awarded TP4. domain version explicit time windows, 1st places awarded
LPG-TD SGPlan.
5.4 Pipesworld
Pipesworld domain PDDL adaptation application domain dealing complex problems arise transporting oil derivative products pipeline system. Note that, many planning benchmarks dealing variants transportation problems, transporting oil derivatives pipeline system different characteristic kind structure. pipelines must filled liquid times,
push something pipe one end, something possibly completely different
comes end. result, domain exhibits interesting planning
space characteristics good plans sometimes require tricky maneuvers. Additional
difficulties dealt are, example, interface restrictions (different types
products interfere pipe), tankage restrictions areas (i.e., limited
storage capacity defined product places pipe segments connect),
deadlines arrival time products.
form domain used IPC-4, product amounts dealt discrete sense assume smallest product unit, called batch. six
different domain versions IPC-4: notankage-nontemporal, notankage-temporal, tankagenontemporal, tankage-temporal, notankage-temporal-deadlines, notankage-temporaldeadlines-compiled. versions include interface restrictions. versions tankage
name include tankage restrictions, modelled number tank slots
place network, slot hold one batch (note slots introduce
additional symmetry problem; get back below). versions
temporal name, actions take (different amounts of) time. versions
deadlines name include deadlines arrival goal batches, modelled
timed initial literals respectively compilation standard PDDL2.1. None
encodings uses ADL constructs, domain version one (STRIPS)
formulation.
IPC-4 example instances generated based five scaling network topologies. smallest network topology 3 areas connected 2 pipes; largest network
topology 5 places connected 5 pipes. network generated 10 instances,
growing numbers batches, batches goal location. altogether
50 instances per domain version, numbered consecutively. domain versions,
instances were, much possible, transferred adding/removing constructs. E.g.,
instances tankage-nontemporal (tankage-temporal) exactly
notankage-nontemporal (notankage-temporal) except tankage restrictions added.
include graphs domain versions featuring deadlines. version explicit deadlines (modelled timed initial literals), LPG-TD Tilsapa
546

fiThe Deterministic Part IPC-4: Overview

10000

10000
LPG-TD
MACRO-FF
SGPLAN
CRIKEY
FDD

1000

FAP
MARVIN
ROADMAPPER
PMEP
YAHSP
LPG-3

1000

100

100

10

10

1

1

0.1

0.1

0.01

0.01
5

10

15

20

25

30

35

40

45

50

5

10

15

20

(a)

25

30

35

40

45

50

(b)
10000
BFHSP
TP4
CPT
OPTIPLAN
SATPLAN
SEMSYN

1000

100

10

1

0.1

0.01
5

10

15

20

25

30

35

40

45

50

(c)
Figure 3: Non-temporal Pipesworld, tankage constraints, satisficing (a) (b), optimal
(c).

participated, LPG-TD scaled middle-size instances; Tilsapa solved
smallest instances. domain version compiled deadlines, CPT
participated, solving small instances.
Figure 3 shows results non-temporal domain version without tankage restrictions. Parts (a) (b) contain results satisficing planners respective
non-temporal domain version. observe YAHSP SGPlan planners
solve instances. YAHSP lot faster instances; finds excessively
long plans: ratio YAHSP vs SGPlan [0.38(1.77)14.04], maximum case
SGPlan needs 72 actions, YAHSP 1,011. planners, plan quality
vary much, exception Marvin, whose makespan ratio vs optimal CPT
[0.88(1.60)2.19]. LPG-TD FDD solve largest instances. Note
that, Airport, IPC-3 version LPG outperformed dramatically best
IPC-4 planners.
547

fiHoffmann & Edelkamp

10000

10000
LPG-TD
SGPLAN
CRIKEY
PMEP
LPG-3

1000

TP4
CPT
HSPS_A
1000

100

100

10

10

1

1

0.1

0.1

0.01

0.01
5

10

15

20

25

30

35

40

45

50

5

(a)

10

15

20

25

30

35

40

45

50

(b)

Figure 4: Temporal Pipesworld without tankage constraints, satisficing (a), optimal (b).

Part (c) Figure 3 shows results optimal planners. runtime curves
extremely similar, nearing indistinguishable. Note Optiplan optimal planner
solves instance large size parameter. However, Pipesworld, like
Airport, due domain combinatorics, planners likely find easier solve large
network little traffic, small network lot traffic.10 optimal
planners may tried run planner larger instances already
failed smaller ones explicitly advised people save machine workload
insisting spending half hour runtime instances probably infeasible
planners anyway. cases like one here, admittedly potentially misleading
guideline.
parts (a) (b) Figure 4, display results temporal domain version
without tankage restrictions. Part (a) shows clear win SGPlan planners.
find particularly remarkable that, Airport, SGPlan good
temporal domain version nontemporal one. Again, LPG-3 outperformed far.
optimal planners part (b) figure, CPT scales best; TP4 HSPa scale
similarly. planners minimizing number actions CRIKEY SGPlan; ratio [0.35(1.24)5.67], showing quite variance slight mean advantage
SGPlan. planners minimizing makespan, LPG-TD P-MEP sometimes return
long plans; one instance (number 2), LPG-TDs plan extremely long (makespan 432).
precisely, ratio LPG-TD.speed vs optimal CPT [1.00(4.55)36.00]; ratio
P-MEP vs CPT [1.19(2.25)4.59]; ratio LPG-TD.quality vs CPT [0.73(1.05)1.62]
(i.e., particular peak instance 2 disappears LPG-TD.quality). Note that,
strangely first sight, sometimes LPG-TD finds better plans optimal CPT.
10. hand, note point networks Pipesworld far grow much
Airport, grow microscopic toy airports smallest instances real-world airport
largest instances. said, smallest network Pipesworld 3 areas connected 2 pipes,
largest network 5 places connected 5 pipes.

548

fiThe Deterministic Part IPC-4: Overview

10000

10000
LPG-TD
MACRO-FF
SGPLAN
CRIKEY
FDD

1000

FAP
MARVIN
ROADMAPPER
YAHSP
LPG-3

1000

100

100

10

10

1

1

0.1

0.1

0.01

0.01
5

10

15

20

25

30

35

40

45

50

5

10

15

20

25

(a)

30

35

40

45

50

(b)
10000
BFHSP
CPT
OPTIPLAN
SATPLAN
1000

100

10

1

0.1

0.01
5

10

15

20

25

30

35

40

45

50

(c)
10000

10000
LPG-TD
SGPLAN
CRIKEY
LPG-3

TP4
CPT
HSPS_A

1000

1000

100

100

10

10

1

1

0.1

0.1

0.01

0.01
5

10

15

20

25

30

35

40

45

50

5

(d)

10

15

20

25

30

35

40

45

50

(e)

Figure 5: Pipesworld tankage constraints: non-temporal satisficing (a) (b), optimal (c), temporal satisficing (d), optimal (e).

due somewhat simpler model durative actions CPT uses (Vidal &
Geffner, 2004), making distinction start end time points actions.
549

fiHoffmann & Edelkamp

Figure 5, results displayed two domain versions feature tankage
restrictions. generally, see planners much trouble
domain versions less constrained counterparts.
non-temporal domain version tankage constraints, satisficing planners
parts (a) (b) observe that, before, YAHSP efficient, solving
instances planners. Again, efficiency bought cost
overlong plans: ratio YAHSP vs. SGPlan [0.66(1.89)6.14], maximum
case SGPlan needs 64 actions, YAHSP 393. planners, plan quality
vary much (e.g. ratio FDD vs SGPlan [0.56(0.96)1.38]. optimal planners
displayed part (c), non-temporal domain version, SATPLAN Optiplan scale
little better planners, solving two three instances, respectively.
SATPLAN tends faster Optiplan solved cases. Part (d) displays
results satisficing planners respective temporal domain version. SGPlan
clearly scales best, keeping performance corresponding non-temporal
domain version. LPG-TD followed relatively closely CRIKEY solve
instances. Regarding plan quality, CRIKEY SGPlan minimize plan length,
ratio CRIKEY vs SGPlan [0.62(1.37)2.54]. makespan, LPG-TD peak
instance 2; ratio LPG-TD.speed vs CPT [1.00(2.55)7.27], maximum 160 vs 22
units; ratio LPG-TD.quality vs CPT [0.86(0.95)1.18] (LPG-TD.qualitys makespan
instance 2 26). Note that, above, LPG-TD.quality find better plans CPT
due somewhat simpler model durative actions used CPT. optimal track,
TP4 performs little better, terms runtime, similar-performing CPT
HSPa ; planners solve smallest instances.
remark rather surprised relatively good scaling behavior
planners, particularly fastest satisficing planners domain versions without
tankage restrictions. Hoffmann (2005) shows that, Pipesworld, arbitrarily
deep local minima relaxed plan distances (i.e., distance local minimum
better region state space may arbitrarily large). particularly unusual
constructs needed provoke local minima example, cycle pipe segments,
also occurs network topologies underlying IPC-4 instances, suffices. less
importantly, limited experiments testing, FF (Hoffmann & Nebel,
2001) Mips (Edelkamp, 2003c) generally scaled much worse than, e.g., YAHSP
SGPlan shown above.
domain versions feature tankage restrictions, harder
counterparts. two important differences domain versions
with/without tankage restrictions. First, problem constrained (remember that,
modulo tankage constraints, IPC-4 instances identical respective versions). Second, tank slots, model restrictions, introduce additional symmetry
problem: planner choose (free) slot insert batch.
choice make difference, enlarges state space exponentially number
choices (to basis number tank slots). considered option use
counter encoding instead, avoid symmetry: one could count product amounts
areas, impose tankage restrictions based counter values. decided
symmetry challenging aspect benchmark.
550

fiThe Deterministic Part IPC-4: Overview

domain version notankage-nontemporal, awarded 1st places YAHSP SGPlan; awarded 2nd places LPG-TD FDD. version notankage-temporal,
awarded 1st places SGPlan CPT; awarded 2nd places LPG-TD, TP4,
HSPa . version tankage-nontemporal, awarded 1st places YAHSP FDD;
awarded 2nd places SGPlan, SATPLAN, Optiplan. version tankage-temporal,
awarded 1st place SGPlan; awarded 2nd places LPG-TD TP4. version
notankage-temporal-deadlines, awarded 1st place LPG-TD.
5.5 Promela
Promela input language model checker SPIN (Holzmann, 2004), used
specifying communication protocols. Communication protocols distributed software
systems, many implementation bugs arise, like deadlocks, failed assertions,
global invariance violations. model checking problem (Clarke, Grumberg, & Peled,
2000) find errors returning counter-example, verify correctness
complete exploration underlying state-space. Edelkamp (2003b) developed
automatic translation problem, i.e., Promela language, (non-temporal)
PDDL, making possible apply state-of-the-art planners without modification.
IPC-4, two relatively simple communication protocols selected benchmarks
toy problems Model-Checking area. One well-known Dining-Philosophers
protocol, larger protocol called Optical-Telegraph. main point using
domain, protocols, IPC-4 promote connection Planning
Model-Checking, test state-of-the-art planners scale basic problems
area.
IPC-4 instances exclusively require find deadlocks specified protocols
states transitions possible. rules detect whether
given state deadlock naturally modelled derived predicates, complex
ADL formulas rule bodies. enable broad participation, provided compilations
derived predicates additional actions, ADL STRIPS. Edelkamps original
translation Promela PDDL also makes use numeric variables. non-numeric
planners, translation adapted use propositional variables relatively
simple Dining-Philosophers Optical-Telegraph protocols, possible.
Precisely, domain versions formulations following. First, versions split modelled protocol, Dining-Philosophers Optical-Telegraph. Second, versions split used language: with/without numeric variables,
with/without derived predicates.11 So, all, 8 domain versions.
used ADL constructs. 4 versions without numeric variables, also provided
STRIPS formulations, obtained ADL formulations automatic compilation
software based FFs pre-processor (Hoffmann & Nebel, 2001), producing fully grounded
encodings. Promela domain versions non-temporal.
Here, show plots results obtained non-numeric domain versions.
domain versions using numeric variables derived predicates, planner
11. split with/without numeric variables different domain versions, rather formulations,
encourage use numeric planning techniques. split with/without derived predicates different
versions since, modelling derived predicates new actions, plans become longer.

551

fiHoffmann & Edelkamp

10000

10000
LPG-TD
MACRO-FF
SGPLAN
CRIKEY
FAP
PMEP
YAHSP

1000

BFHSP
TP4
CPT
HSPS_A
OPTIPLAN
SATPLAN
SEMSYN

1000

100

100

10

10

1

1

0.1

0.1

0.01

0.01
5

10

15

20

25

30

35

40

45

5

10

15

20

(a)

25

30

35

40

45

(b)
10000
LPG-TD
SGPLAN
FDD
MARVIN
1000

100

10

1

0.1

0.01
5

10

15

20

25

30

35

40

45

(c)
Figure 6: Performance Promela/Dining Philosophers. Encoding without derived predicates, satisficing (a), optimal (b). Encoding derived predicates, satisficing
(c).

participated. numeric version Dining-Philosophers (without derived predicates),
SGPlan P-MEP participated. SGPlan solved instances P-MEP solved
smallest ones. numeric version Optical-Telegraph (without
derived predicates), SGPlan participated, solving relatively small instances.
Parts (a) (b) Figure 6 show results Dining-Philosophers, without derived
predicates, i.e. additional actions derive deadlocks. satisficing
track, YAHSP SGPlan clearly show best performance. planners lag
several orders magnitude behind. optimal track, SATPLAN clearly scales best,
followed Optiplan. Observe that, difference seen Airport
Pipesworld, optimal planners efficient satisficing ones. evident
plots. particularly, SATPLAN Optiplan solve many instances,
30 philosophers (instance number x features x + 1 philosophers), like YAHSP
552

fiThe Deterministic Part IPC-4: Overview

SGPlan.12 SATPLAN even comparable time. competitivity optimal
planners satisficing ones seen test suite used last
three competitions.13 efficiency SATPLAN Optiplan Dining-Philosophers
probably due fact needed number parallel time steps constantly 11 across
instances (see below). (standard) planning graph (Blum & Furst, 1995, 1997),
goals first reached 7 steps; 4 unsuccessful iterations made plan
found.
Regarding plan quality, one group planners trying minimize number
actions, one group trying minimize makespan (the number parallel action
steps). results clearly point important difference domain
IPC-4 domains. Namely, single scaling parameter n number
philosophers single instance per value n. optimal number actions
linear function n, precisely 11n: basically, one blocks philosophers sequence,
taking 11 steps each. optimal makespan is, mentioned above, constantly 11:
one block philosophers parallel. sub-optimal plan found planner
minimizing number actions CRIKEY n = 8, containing 104 instead
88 actions. planners minimizing makespan, P-MEP finds sub-optimal plans:
solves smallest four instances, n = 2, 3, 4, 5, makespan 19, 25, 30, 36,
respectively.
Figure 6 (c) shows results domain version uses derived predicates
detect deadlock situations. optimal planner could handle derived predicates
results this. satisficing planners, SGPlan clearly shows
best performance. FDD LPG-TD roughly similar note that, LPG-TD
faster FDD examples, behavior FDD largest instances indicates
advantage scaling. sudden large increase LPG-TDs runtime,
second largest instance (that solved 52 seconds) largest instance (that
solved 1045 seconds). difference that, FDD solves largest instance almost
time second largest one, taking 111 seconds instead 110 seconds (in fact,
FDDs runtime performance shows little variance pretty much linear function
instance size). remark plans largest instances huge:
400 steps long, see below. SGPlan generates plans little
single second CPU time.
Regarding plan quality, domain version optimal number actions 9n,
optimal makespan constantly 9. planners except Marvin tried minimize
number actions. FD SGPlan always find optimal plans. FDD, LPG-TD.speed,
LPG-TD.quality sometimes find slightly sub-optimal plans. Precisely, ratio FDD vs
FD [1.00(1.08)1.44]; LPG-TD.speed vs FD [1.00(1.10)2.19]; LPG-TD.quality vs FD
[1.00(1.03)1.24]. Marvin, makespan plans is, roughly, linear n; always
lies 7n 9n.
12. Importantly, planners handle STRIPS, compilation reasons STRIPS instances n = 30 only. planners solve respective test instances. discuss
little detail below.
13. first IPC, 1998, apart fact heuristic search satisficing planners still
infancy, Mystery Mprime used benchmarks. cant solved particularly
efficiently planner today, except, maybe, FD FDD (Helmert, 2004).

553

fiHoffmann & Edelkamp

point, important remark made detail regarding
compilation techniques domain versions. Observe huge gap planner performance Figure 6 (a) (b), Figure 6 (c). seen, difference
plan length (makespan) large 11n (11) compared 9n (9). Indeed, apparent performance difference due compilation detail, inherent IPC-4 instances,
rather planner performance. version without derived predicates,
able compile instances n = 30 philosophers ADL STRIPS.
larger values n, (fully-grounded) STRIPS representations became prohibitively
large. version derived predicates, blow-up lot smaller, could
compile instances, n = 49 philosophers. SGPlan, YAHSP, SATPLAN,
Optiplan handle STRIPS. So, mentioned above, Figure 6 (a) (b)
planners actually solve instances respective test suite; would probably scale
provided STRIPS representations instances larger n values.

10000

10000
LPG-TD
MACRO-FF
SGPLAN
CRIKEY
FAP
PMEP
YAHSP

1000

BFHSP
TP4
CPT
HSPS_A
OPTIPLAN
SATPLAN

1000

100

100

10

10

1

1

0.1

0.1

0.01

0.01
5

10

15

20

25

30

35

40

45

5

10

15

20

(a)

25

30

35

40

45

(b)
10000
LPG-TD
SGPlan
FDD
MARVIN
1000

100

10

1

0.1

0.01
5

10

15

20

25

30

35

40

45

(c)
Figure 7: Performance Promela/Optical Telegraph. Encoding without derived predicates, satisficing (a), optimal (b). Encoding derived predicates, satisficing
(c).

554

fiThe Deterministic Part IPC-4: Overview

Optical-Telegraph protocol slightly complex Dining-Philosopher
example, i.e. involves complicated indirect interactions communicating processes, leading longer solutions. still one scaling parameter,
number n telegraph station pairs, single instance per value n. telegraph
station pair pair processes goes rather complicated internal communication structure, enabling exchange data. telegraph station pair shares
outside world i.e., telegraph station pairs two control channels
must occupied prerequisite internal exchange data. Thus, role
control channels pretty similar role (shared) forks Dining-Philosopher
example. Instance number x IPC-4 features x + 1 telegraph station pairs.
Figure 7 shows parts (a) (b) performance satisficing optimal
planners, respectively, domain version using additional actions derive deadlocks.
group satisficing planners, Macro-FF clearly performs best. satisficing
planners, SGPlan efficient. important note that, here, able
compile instances n = 15 ADL STRIPS. SGPlan LPG-TD
solve respective test instances. optimal planners, SATPLAN Optiplan
solve instances n = 14, i.e., failed solve largest instance STRIPS
test suite attacked. SATPLAN much faster Optiplan. optimal
planners could solve smallest instance, n = 2. Figure 7 (c) shows FDD,
handles ADL formulation, far successful satisficing planner domain
version encoding Optical-Telegraph derived predicates deadlock detection;
planners, SGPlan scales best, solving instances STRIPS set, n = 20.
Regarding plan quality, Optical-Telegraph without derived predicates optimal
number actions 18n, optimal makespan constantly 13: optimal sequential
plans block telegraph station pairs sequence, taking 18 steps each; parallel
plans, simultaneous actions possible within telegraph station pair. OpticalTelegraph derived predicates, optimal number actions 14n, optimal
makespan constantly 11. competition results, planners returned optimal
plans test suites, cases single exception. plans found Marvin
version derived predicates makespan 14n solved cases.
seen, results Promela are, all, quite different from, e.g.,
seen Airport Pipesworld. single scaling parameter single
instance per size, optimal makespan constant. leads rather smooth runtime
plan quality curves, well unusual competitivity optimal planners
satisficing planners. scalability planners shows current planners
able efficiently solve basic Model-Checking benchmarks (Dining-Philosophers),
efficient solving complex Model-Checking benchmarks
(Optical-Telegraph). remark Hoffmann (2005) shows exist arbitrarily
deep local minima relaxed plan distances Optical-Telegraph, DiningPhilosophers, exists large upper bound (31) number actions needed
escape local minimum. clear, however, much theoretical results
planner performance observed above. worst-cases observed Hoffmann
occur regions state space entered plans optimal number actions
found IPC-4 participants, cases.
555

fiHoffmann & Edelkamp

Dining-Philosophers without derived predicates, awarded 1st places YAHSP,
SGPlan, SATPLAN; awarded 2nd place Optiplan. Dining-Philosophers
derived predicates, awarded 1st place SGPlan, 2nd places FDD LPG-TD.
Optical-Telegraph without derived predicates, awarded 1st places Macro-FF
SATPLAN; awarded 2nd places SGPlan Optiplan. Optical-Telegraph
derived predicates, awarded 1st place FDD, 2nd place SGPlan.
numeric version Dining-Philosophers, awarded 1st place SGPlan.
5.6 PSR
PSR short Power Supply Restoration. domain PDDL adaptation application domain investigated Sylvie Thiebaux researchers (Thiebaux, Cordier,
Jehl, & Krivine, 1996; Thiebaux & Cordier, 2001), deals reconfiguring faulty
power distribution system resupply customers affected faults. original PSR
problem, various numerical parameters breakdown costs power margins need
optimized, subject power capacity constraints. Furthermore, location
faults current network configuration partially observable, leads
tradeoff acting resupply lines acting reduce uncertainty. contrast,
version used IPC-4 set pure goal-achievement problem, numerical aspects
ignored, total observability assumed. Temporality significant aspect even
original application, IPC-4 domain non-temporal.
used four domain versions PSR IPC-4. Primarily, versions differ
size problem instances encoded. instance size determined languages able formulate domain version. domain versions named
1. large, 2. middle, 3. middle-compiled, 4. small. Version 1 single formulation adl-derivedpredicates: natural formulation, domain comes derived
predicates model flow electricity network, ADL formulas
express necessary conditions status network connectors. Version 2
formulations adl-derivedpredicates, simpleadl-derivedpredicates, strips-derivedpredicates.
Version 3 single formulation adl, version 4 single formulation strips.
indicated, formulation names simply give language used. version 2, ADL
constructs compiled away obtain simpler formulations. version 3, derived
predicates compiled away introducing additional artificial actions; due increase plan length (which discuss detail below), turned
separate domain version, rather formulation. strips domain version,
enable encoding reasonably-sized instances adopted different fully-grounded
encoding inspired work Bertoli et al. (2002). encoding generated description problem instance tool performing reasoning devoted
planner domain versions. Still able formulate comparatively
small instances pure STRIPS.
Starting performance smallest instances, depict performance
satisficing optimal planners PSR STRIPS domain Figure 8. result graphs
divided two completely unreadable otherwise. planners show
lot variance domain, blurring performance differences (observable)
individual systems. Still possible identify systems behave better others.
556

fiThe Deterministic Part IPC-4: Overview

10000

10000
LPG-TD
SGPLAN
CRIKEY

FDD
MARVIN
YAHSP
LPG-3

1000

1000

100

100

10

10

1

1

0.1

0.1

0.01

0.01
5

10

15

20

25

30

35

40

45

50

5

10

15

20

(a)

25

30

35

40

45

50

(b)

10000

10000
BFHSP
TP4
CPT
HSPS_A

OPTIPLAN
SATPLAN
SEMSYN

1000

1000

100

100

10

10

1

1

0.1

0.1

0.01

0.01
5

10

15

20

25

30

35

40

45

50

5

(c)

10

15

20

25

30

35

40

45

50

(d)

Figure 8: PSR small, satisficing (a) (b), optimal (c) (d).

satisficing systems, FDD solve 50 instances; consistently
fast (the results FD almost identical). planners, LPG-TD, SGPlan,
YAHSP best success ratio: solve 49, 47, 48 instances, respectively;
CRIKEY solves 29 instances, Marvin 41. optimal systems, system
solving entire test suite SATPLAN. BFHSP solved 48 instances, CPT 44, HSPa 44,
Optiplan 29, Semsyn 40, TP4 38.
plan quality, groups planners trying minimize plan
length (number actions), makespan. former group, take performance measure plans found BFHSP, optimal sense, which,
said above, 2 50 instances. ratio CRIKEY vs BFHSP
[1.00(1.72)3.44]; ratio FDD vs BFHSP [1.00(1.02)1.52]; ratio LPG-TD.speed vs
BFHSP [1.00(5.52)12.70]; ratio LPG-TD.quality vs BFHSP [1.00(1.82)8.32];
ratio SGPlan vs BFHSP [1.00(1.01)1.24]; ratio YAHSP vs BFHSP [1.00(1.00)1.05].
planner group minimizing makespan, planners except Marvin optimal.
ratio Marvin vs SATPLAN [1.00(1.28)2.07].
557

fiHoffmann & Edelkamp

10000

10000
LPG-TD
SGPLAN
FDD
MARVIN

SGPLAN
FDD
MARVIN

1000

1000

100

100

10

10

1

1

0.1

0.1

0.01

0.01
5

10

15

20

25

30

35

40

45

50

5

(a)

10

15

20

25

30

35

40

45

50

(b)

Figure 9: PSR, middle (a) large (b), satisficing planners.

Apart observations made within groups satisficing respectively
optimal planners, something said relationship
two groups. Like Dining-Philosophers, rather unusual situation
optimal planners efficient satisficing ones. Indeed, solving instances,
SATPLAN superior satisficing planners. remark point
Hoffmann (2005) shows existence arbitrarily deep local minima PSR, i.e., regions
takes arbitrarily many step escape local minimum relaxed plan distances.
example, local minima arise naturally relaxed plan able supply
supply line time, thereby make crucial distinction
faulty non-faulty lines. Now, observations hold original domain
formulation, derived predicates ADL constructs. said, IPC-4 STRIPS
formulation PSR obtained combination complicated pre-processing
machines. likely make real structure domain amenable
relaxed plan distances. satisficing planners participating PSR small
means exclusively dependent relaxed plan distances, distances
form important part search heuristics.
Figure 9 gives results PSR domain versions, middle large, larger
instances, encoded ADL constructs and/or derived predicates. optimal planner
could handle language constructs, unfortunately comparison
two groups continued. middle sized instances, FDD, SGPlan,
LPG-TD scale entire test suite. FDD indicates better scaling behavior
largest instances. domain version large instances (available formulation
using ADL), FDD indeed shows outperforms planners (at least, SGPlan,
also participates here) far. data FD almost identical FDD.
Regarding plan quality, participating planner middle large
tries minimize makespan Marvin, basis comparison.
planners, SGPlan generally finds plans smallest number actions. Precisely, middle version plan quality ratios follows. ratio FDD vs
558

fiThe Deterministic Part IPC-4: Overview

SGPlan [0.67(1.23)2.33] (FD: [0.67(1.25)2.85]). ratio LPG-TD.speed vs SGPlan
[0.67(1.82)7.27]; maximum case instance number 49, LPG-TD.speed takes 80
steps SGPlan 11. ratio LPG-TD.quality vs SGPlan [0.60(1.08)7.27],
maximum case. large version, FD FDD solve considerable number
instances; ratio FD vs FDD [0.60(1.01)1.30].
PSR domain version middle-size instances derived predicates compiled
ADL, i.e., domain version middle-compiled, Macro-FF SGPlan participated.
Macro-FF scaled relatively well, solving 32 instances instance number 48. SGPlan
solved 14 instances instance number 19. planners try minimize
number actions, ratio SGPlan vs Macro-FF [0.51(1.28)1.91].
interesting observe that, PSR, compiling derived predicates away,
plan length increases much seen Section 5.5 DiningPhilosophers Optical-Telegraph. latter, derived predicates replace two
action applications per process, detecting respective process blocked. PSR,
however, said derived predicates model flow electricity network,
i.e., encode transitive closure underlying graph. number additional
actions needed simulate latter grows, course, size graph.
phenomenon observed IPC-4 plan length data. PSR middle-compiled
instances identical middle instances, except compilation derived predicates. Comparing plan quality Macro-FF middle-compiled SGPlan
middle, obtain remarkably high ratio values [7.17(12.53)25.71]. maximum
case instance number 48 largest instance solved Macro-FF Macro-FF
takes 180 steps solve compiled instance, SGPlan takes 7 steps solve
original instance.14
domain version small, awarded 1st places FDD (and FD), SATPLAN;
awarded 2nd places LPG-TD, SGPlan, YAHSP, BFHSP. domain version middle,
awarded 1st place FDD (and FD); awarded 2nd places LPG-TD SGPlan.
domain version middle-compiled, awarded 1st place Macro-FF. domain version
large, awarded 1st place FDD (and FD).
5.7 Satellite
Satellite domain introduced IPC-3 Long Fox (2003). motivated
NASA space application: number satellites take images number
spatial phenomena, obeying constraints data storage space fuel usage. IPC-3,
domain versions Strips, Numeric, Time (action durations expressions
static variables), Complex (durations numerics, i.e. union Numeric
Time). numeric variables transport complex problem constraints, regarding
data capacity fuel usage.
IPC-4, domain made little realistic additionally introducing time
windows sending image data earth, i.e. antennas visible
satellites certain periods time. added new domain versions Time14. Macro-FF optimal planner, optimal plan lengths middle-compiled instances known, seems highly unlikely observations due overlong plans
found Macro-FF.

559

fiHoffmann & Edelkamp

timewindows, Time-timewindows-compiled, Complex-timewindows, Complex-timewindowscompiled, introducing time windows, explicit compiled, IPC-3 Time
Complex versions, respectively.15 None domain versions uses ADL constructs,
versions single (STRIPS) formulation. instances were, much possible, taken original IPC-3 instance suites. Precisely, Strips, Numeric, Time,
Complex versions contained 20 instances posed IPC-3 fully-automatic
planners, plus 16 instances posed IPC-3 hand-tailored planners. Timetimewindows Time-timewindows-compiled, extended 36 instances Time
time windows. Similarly, Complex-timewindows Complex-timewindowscompiled, extended 36 instances Complex time windows. is,
newly added domain versions sole difference previous instances lies
time windows.
Let us first consider results simpler versions Satellite domain. Figure 10
shows results Strips Time versions. many satisficing planners,
Strips version pose serious problem, see Figure 10 (a). Macro-FF YAHSP
show best runtime behavior, followed closely LPG-TD FDD (as well FD).
optimal planners Figure 10 (b), none scales far. SATPLAN
efficient, solving 11 instances; CPT Semsyn solve 9 instances, Optiplan solves
8, BFHSP solves 6. Time version, LPG-TD SGPlan behave similarly
instance number 30, LPG-TD solves two more, larger, instances. Time optimal
planners, see Figure 10 (d), clearly headed CPT.
Regarding efficiency satisficing planners Strips test suite, remark
instances solved quite efficiently IPC-3 already, e.g. FF LPG-3.
Further, Hoffmann (2005) shows that, domain, relaxed plan distance,
non-goal state, one reach state strictly smaller heuristic value within
5 steps. sense, results depicted Figure 10 (a) didnt come surprise us.
Let us consider plan quality Strips Time. domain versions,
addressed optimization criteria plan length, makespan. Strips, plan quality
behavior planners trying minimize plan length rather similar. overall
shortest plans found LPG-TD.quality. Precisely, ratio FDD vs LPG-TD.quality
[0.96(1.19)1.48]; ratio FD vs LPG-TD.quality [0.96(1.20)1.53]; ratio LPGTD.speed vs LPG-TD.quality [1.00(1.12)1.31]; ratio Macro-FF vs LPG-TD.quality
[0.95(1.03)1.17]; ratio Roadmapper vs LPG-TD.quality [1.00(1.35)1.71]; ratio
SGPlan vs LPG-TD.quality [0.99(1.07)1.70]; ratio YAHSP vs LPG-TD.quality
[0.97(1.22)1.93]. planners trying optimize makespan Strips version,
Marvin P-MEP satisficing; Marvin planner scales larger
instances. ratio P-MEP vs SATPLAN (which solves superset instances solved
P-MEP) [1.01(2.22)3.03]. ratio Marvin vs SATPLAN [1.08(2.38)4.00].
Time version, planner minimizing plan length (i.e., number actions) SGPlan, basis comparison. satisficing planners trying
15. new domain versions derived Complex, also introduced utilities time window
inside image sent earth. image, utility either windows,
decreases monotonically start time window, random within certain interval.
image put randomly one classes, optimization requirement minimize
linear combination makespan, fuel usage, summed negated image utility.

560

fiThe Deterministic Part IPC-4: Overview

10000

10000

1000

1000

100

100

10

10

1

BFHSP
CPT
OPTIPLAN
SATPLAN
SEMSYN

1
LPG-TD
MACRO-FF
SGPLAN
FDD
MARVIN
PMEP
ROADMAPPER
YAHSP
LPG-3

0.1

0.1

0.01

0.01
5

10

15

20

25

30

35

5

10

15

(a)

20

25

30

35

(b)

10000

10000
TP4
CPT
HSPS_A

1000

1000

100

100

10

10

1

1

0.1

0.1
LPG-TD
SGPLAN
PMEP
LPG-3

0.01

0.01
5

10

15

20

25

30

35

5

(c)

10

15

20

25

30

35

(d)

Figure 10: Satellite; Strips satisficing (a), optimal (b), Time satisficing (c), optimal
(d).

minimize makespan P-MEP LPG-TD. small instances solved CPT (actually, superset solved P-MEP), ratio P-MEP vs CPT [1.10(3.71)6.49].
ratio LPG-TD.speed vs CPT [1.33(3.37)5.90]; ratio LPG-TD.quality vs CPT
[0.85(1.24)1.86]. Note that, like seen Pipesworld before, sometimes LPG-TD
finds better plans optimal CPT. said, due somewhat simpler
model durative actions CPT uses (Vidal & Geffner, 2004), making distinction
start end time points actions.
Figure 11 (a) shows results Satellite Numeric, together participating planners optimal planner participated Semsyn. SGPlan LPG-TD
scale best; solve number instances, SGPlan solves larger ones
least order magnitude faster instances solved both. Regarding
plan quality, SGPlan planner trying minimize plan length.
planners tried minimize metric value plan, i.e., quality metric specified
instance files, fuel usage. best plans respect found LPG561

fiHoffmann & Edelkamp

10000

10000
LPG-TD
SGPLAN
PMEP
SEMSYN
LPG-3

1000

LPG-TD
SGPLAN

1000

100

100

10

10

1

1

0.1

0.1

0.01

0.01
5

10

15

20

25

30

35

5

10

15

(a)

20

25

30

35

(b)

10000

10000
LPG-TD
SGPLAN
TILSAPA

1000

1000

100

100

10

10

1

1

0.1

0.1
LPG-TD
SGPLAN
PMEP
LPG-3

0.01

0.01
5

10

15

20

25

30

35

5

(c)

10

15

20

25

30

35

(d)

Figure 11: Satellite; Numeric (a), Time-timewindows (b), satisficing Complex (c),
Complex-timewindows (d).

TD.quality; unclear us Semsyn marked optimize metric value here,
find optimal plans. ratio LPG-TD.speed vs LPG-TD.quality
[1.00(2.26)4.69]; ratio P-MEP vs LPG-TD.quality [1.01(2.16)3.03]; ratio Semsyn
vs LPG-TD.quality [1.00(1.28)1.58].
Time-timewindows, optimal planner could participate due timed initial
literals. satisficing planners, see Figure 11 (b), SGPlan LPG-TD participated, scaled relatively well, clear advantage SGPlan. Regarding
plan length, SGPlan minimizes number actions, LPG-TD makespan. ratio LPG-TD.speed vs LPG-TD.quality [1.00(1.22)1.51]. Time-timewindows-compiled,
SGPlan CPT participated. SGPlan largely maintained performance
Time-timewindows version, CPT could solve 3 smallest instances. Plan quality cant compared due different criteria (plan length makespan)
minimized.
562

fiThe Deterministic Part IPC-4: Overview

Figure 11 (c) shows performance satisficing planners Satellite Complex.
SGPlan LPG-TD scale well, particular much better competitor,
P-MEP. largest three instances, SGPlan shows clear runtime advantage LPGTD. optimal track, TP4 HSPa competed here. solved four
small instances, numbers 1, 2, 3, 5, almost runtime. SGPlan
planner minimizing number actions. planners, try minimize
makespan, LPG-TD scales large instances. ratio LPG-TD.speed vs LPGTD.quality [1.01(2.76)4.71]. ratio LPG-TD.speed vs TP4 [1.81(2.09)2.49]; ratio
LPG-TD.quality vs TP4 [0.93(1.07)1.19]; ratio P-MEP vs TP4 [1.27(2.25)3.32].
CPT, better plan (in one case) found LPG-TD.quality due
somewhat simpler action model used TP4 (Haslum & Geffner, 2001).
Figure 11 (d) shows performance planners Complex-timewindows
above, due timed initial literals optimal planner could compete here. SGPlan
scales clearly best, followed LPG-TD; Tilsapa solves 3 smallest instances.
3 participating planners, one minimizes different quality criterion: number
actions SGPlan, makespan Tilsapa, metric value aforementioned linear
combination makespan, fuel usage, summed negated image utility LPG-TD.
useful comparison LPG-TD.speed LPG-TD.quality,
ratio [1.00(2.33)7.05].16 Complex-timewindows-compiled, participating
planner SGPlan. maintained good scalability Complex domain version
explicit time windows.
domain version Strips, awarded 1st places Macro-FF, YAHSP, SATPLAN;
awarded 2nd places FDD (and FD), LPG-TD, CPT, Optiplan, Semsyn.
domain version Time, awarded 1st places LPG-TD CPT; awarded 2nd place
SGPlan. domain versions Numeric, Time-timewindows, Complex,
Complex-timewindows, awarded 1st place SGPlan 2nd place LPG-TD.
5.8 Settlers
Settlers domain also introduced IPC-3 (Long & Fox, 2003). features
single domain version, makes extensive use numeric variables. variables
carry domain semantics, building infrastructure
unsettled area, involving building houses, railway tracks, sawmills, etc. IPC-3,
planner able deal domain efficient way best IPC-3 planner
Settlers, Metric-FF (Hoffmann, 2003), solved smallest six instances test
suite. reasons, included domain IPC-4 challenge numeric
planners. used exact domain file example instances IPC-3, except
compiled away universally quantified preconditions improve accessibility
planners. quantifiers nested, ranged fixed set domain constants,
could easily replaced conjunctions atoms.
16. Due negated image utility, quality values negative. LPG-TD.speed LPGTD.quality here, happened 5 instances. skipped computing given ratio values,
since putting positive negative values together doesnt make much sense negative quality,
number larger absolute value represents better plan. would probably better
define, domain version, image penalty instead image utility, thus obtain strictly
positive action costs.

563

fiHoffmann & Edelkamp

10000

1000

100

10

1

0.1
LPG-TD
SGPLAN
SEMSYN
0.01
2

4

6

8

10

12

14

16

18

20

Figure 12: Performance planners Settlers.
Figure 12 shows runtime results obtained IPC-4. efficiency increase compared
IPC-3 is, obviously, dramatic: SGPlan solves every instance within less 15 seconds
(instance number 8 unsolvable).17 LPG-TD solves 13 instances set, Semsyn
solves 3 (numbers 1,2, 5). remark solutions tasks, returned
SGPlan, huge, 800 actions largest tasks. one hand,
demonstrates SGPlans capability find extremely long plans extremely
quickly. hand, SGPlans plans Settlers might unnecessarily long,
extent. largest instance solved Semsyn, number 5, Semsyn finds plan 94
actions, plan found SGPlan 264 actions. largest instance solved
LPG-TD, number 17, LPG-TD.quality takes 473 actions SGPlan takes 552. LPG-TD
minimizes metric value plans, linear combination invested labor,
resource use, caused pollution. ratio LPG-TD.speed vs LPG-TD.quality
[1.00(1.21)3.50].
awarded 1st place SGPlan 2nd place LPG-TD.
5.9 UMTS
UMTS applications require comparatively much time started hand-held device,
since communicate network several times. one
application called, yields true bottleneck user. Therefore,
applications set-up divided several parts allow different set-up modules work
concurrently. task domain provide good schedule minimizing used
time setting timed applications, respecting dependencies among them.
IPC-4, six domain versions UMTS, UMTS-timewindows, UMTStimewindows-compiled, UMTS-flaw, UMTS-flaw-timewindows, UMTS-flaw-timewindowscompiled. domain versions temporal, make use numeric variables
model properties applications set up. ADL constructs used. UMTS
17. remark instance 8 trivially unsolvable. One goals achieved actions
static precondition false initial state. detected simple reachability
analyses like, e.g., planning graphs, even without taking account delete lists.

564

fiThe Deterministic Part IPC-4: Overview

standard model domain. UMTS-timewindows additional time
windows regarding executability set actions, encoded timed initial literals.
UMTS-timewindows-compiled time windows compiled artificial constructs. remaining three domain versions result, names suggest, adding
flaw construction respective counterparts. flaw construction practically
motivated. consists extra action important sub-goal add effect,
deletes another fact cant re-achieved. flaw action cant used
plan, used relaxed plans, i.e. ignoring delete effects.
particular, adding important sub-goal, flawed action provides kind short-cut
relaxed plans, short-cut work reality. lead overly optimistic heuristic values. Thus flaw may confuse heuristic functions relaxed-plan
based heuristic planners. used flawed domain versions IPC-4 see whether
latter would case.
IPC-4 test suites, instances, irrespective number/size, contain 10
applications. main scaling parameter number applications must actually
set up. IPC-4 instances number 1 . . . 5, single application must set up;
instances number 6 . . . 10, two applications must set up, on, i.e., number
needed applications bx/5c x index instance.
Figure 13 (a) (b) shows IPC-4 performance basic domain version. Obviously, SGPlan LPG-TD difficulty domain solve every
instance within split seconds. CRIKEY takes time, also scales nicely.
optimal planners, TP4 HSPa able handle domain syntax, due
combination numeric variables action durations. Figure 13 (b) shows
scaled relatively similarly, slight advantage HSPa . Note two planners
scaled better P-MEP LPG-3 satisficing track.
remark point UMTS mainly intended benchmark optimal
planners minimizing makespan. domain pure scheduling problem nature.
scheduling problems, trivial find plan example, one simply
schedule applications sequence.18 point domain, and, indeed, using
computer solve it, provide good schedules, is, schedules smallest
possible execution time, corresponding makespan plan.
said, observe satisficing planners IPC-4 quite good finding
near-optimal plans UMTS. fact, see detail following,
planner finding highly non-optimal plans LPG-3. Lets consider basic domain
version treated Figure 13 (a) (b). Two participating planners, CRIKEY
SGPlan, try minimize number actions (i.e., wrong optimization criterion).
data identical, i.e. plan lengths instances. Precisely,
planners find, instance number x, plan bx/5c8 actions it. is, fact,
optimal (smallest possible) number actions remember said
scaling IPC-4 test suites. participating planners trying minimize makespan
LPG-3, LPG-TD, P-MEP, HSPa , TP4. P-MEP solves smallest 5 instances,
finding optimal plans. ratio LPG-TD.speed vs HSPa [1.00(1.02)1.11]. ratio
18. Note possible Airport domain also viewed type scheduling
problem (Hatzack & Nebel, 2001) due restricted space airport. sense, Airport
domain incorporates planning aspects UMTS.

565

fiHoffmann & Edelkamp

10000

10000
LPG-TD
SGPLAN
CRIKEY
PMEP
LPG-3

1000

TP4
HSPS_A

1000

100

100

10

10

1

1

0.1

0.1

0.01

0.01
5

10

15

20

25

30

35

40

45

50

5

10

15

20

(a)

25

30

35

40

45

50

(b)

10000

10000
LPG-TD
SGPLAN
CRIKEY
LPG-3

TP4
HSPS_A

1000

1000

100

100

10

10

1

1

0.1

0.1

0.01

0.01
5

10

15

20

25

30

35

40

45

50

5

(c)

10

15

20

25

30

35

40

45

50

(d)

Figure 13: UMTS, satisficing (a) optimal (b); UMTS-flaw, satisficing (c) optimal (d).
LPG-TD.quality vs HSPa [1.00(1.00)1.03]. ratio LPG-3 vs HSPa [1.00(1.53)2.27];
remark plan quality data used LPG-3.bestquality, takes
entire available half hour time trying optimize found plan. Looking plots, one
sees LPG-3 makespan curve much steeper planners.
Figure 13 (c) (d), see performance IPC-4 planners
basic domain version, flaw construct. LPG-TD remains unaffected, SGPlan CRIKEY become lot worse. Particularly, CRIKEY takes several minutes
solve even smallest instances. take confirm intuition flaw
(but necessarily) confuse heuristic functions relaxed-plan based heuristic
planners. Whether heuristic function becomes confused probably depends
details particular way relaxed plans constructed (such construction may,
e.g., choose different actions based estimate harmful
already selected actions). optimal track, introducing flaw construct
domain, performance TP4 HSPa becomes slightly worse, nearly indistinguishable. Regarding plan quality, quality difference terms number
actions needed CRIKEY SGPlan. SGPlans plans still smallest pos566

fiThe Deterministic Part IPC-4: Overview

10000

10000
LPG-TD
SGPLAN
TILSAPA

LPG-TD
SGPLAN

1000

1000

100

100

10

10

1

1

0.1

0.1

0.01

0.01
5

10

15

20

25

30

35

40

45

50

5

(a)

10

15

20

25

30

35

40

45

50

(b)

Figure 14: UMTS-timewindows (a); UMTS-flaw-timewindows (b).
sible length, bx/5c 8. CRIKEY lot variance, longer; ratio
CRIKEY vs SGPlan [1.07(1.72)3.88]. group minimizing makespan, observations similar unflawed domain version above. ratio LPG-TD.speed vs
HSPa [1.00(1.01)1.04], ratio LPG-TD.quality vs HSPa [1.00(1.00)1.01]. Although solves smaller half instances, ratio LPG-3.bestquality vs HSPa
[1.00(1.48)2.27].
Figure 14 shows results two domain versions explicitly encoded time
windows. optimal planners could participate since none could handle timed
initial literals. version without flaw, LPG-TD SGPlan need
split seconds. competitor, Tilsapa, needs runtime also scales
well. introducing flaw, competitors SGPlan LPG-TD. SGPlans
runtime performance becomes lot worse, LPG-TD remains completely unaffected.
Regarding plan quality, number actions SGPlans plans still bx/5c8 cases.
LPG-TD.speed LPG-TD.quality return plans identical makespan cases.
non-flawed version, UMTS-timewindows, makespan ratio Tilsapa vs LPG-TD
[1.00(1.20)1.37].
show runtime graphs domain versions compiled time windows.
UMTS-timewindows-compiled, SGPlan CRIKEY participated. scale well
solve instances, SGPlan needs split seconds, CRIKEY needs
100 seconds per instance larger cases. planners try minimize
number actions, need exactly bx/5c 8 + 5 actions instance number
x namely, optimal number bx/5c 8 actions before, plus 5 artificial actions
encoding time windows. UMTS-flaw-timewindows-compiled, sole participating
planner SGPlan. solved smaller half instances, finding plans length
bx/5c 8 + 6 i.e., using one unnecessary action instance (the action concerns
application need set up).
domain version UMTS, awarded 1st places SGPlan, LPG-TD, HSPa ;
awarded 2nd places CRIKEY TP4. domain version UMTS-flaw, awarded
567

fiHoffmann & Edelkamp

1st place LPG-TD, 2nd places SGPlan, HSPa , TP4. version UMTStimewindows, awarded 1st places SGPlan LPG-TD, 2nd place Tilsapa.
UMTS-flaw-timewindows, awarded 1st place LPG-TD. UMTS-timewindowscompiled, awarded 1st place SGPlan.

6. IPC-4 Awards
numbers 1st 2nd places achieved planners shown Tables 3 4;
planners never came 1st 2nd place left tables. Since many
planners (6 satisficing planners, 4 optimal planners) dealt
purely propositional domain versions (i.e., STRIPS ADL), counted performance
domains separately.
SGPlan LPG-TD FD FDD Macro-FF YAHSP CRIKEY Tilsapa
Propositional
3/6
1/6 5/2 6/3
3/0
4/1
0/0
0/0
Temp/Metric 13 / 2
7/7
0/1
0/1
Total Count
16 / 8
8 / 13 5 / 2 6 / 3
3/0
4/1
0/1
0/1
Table 3: Summary results: satisficing planners, number 1st places / number 2nd
places.

CPT
Propositional 0 / 1
Temp/Metric 3 / 0
Total Count 3 / 1

TP-4
0/0
0/5
0/5

HSPa SATPLAN Optiplan Semsyn BFHSP
0/0
5/1
0/4
0/2
0/2
1/2
1/2
5/1
0/4
0/2
0/2

Table 4: Summary results: optimal planners, number 1st places / number 2nd
places.
satisficing planners, based observations decided award separate
prizes performance pure STRIPS ADL domains. optimal planners
seemed appropriate due to, first, small number planners competing
temporal/metric domains, and, second, smaller overall number competing systems
giving 4 prizes 7 systems seemed much. Overall, awards made deterministic
part IPC-4 following:
1st Prize, Satisficing Propositional Track Fast (Diagonally) Downward, Malte
Helmert Silvia Richter
2nd Prize, Satisficing Propositional Track YAHSP, Vincent Vidal
2nd Prize, Satisficing Propositional Track SGPlan, Yixin Chen, Chih-Wei Hsu
Benjamin W. Wah
1st Prize, Satisficing Metric Temporal Track SGPlan, Yixin Chen, Chih-Wei Hsu
Benjamin W. Wah
568

fiThe Deterministic Part IPC-4: Overview

2nd Prize, Satisficing Metric Temporal Track LPG-TD, Alfonso Gerevini, Alessandro Saetti, Ivan Serina, Paolo Toninelli
1st Prize, Optimal Track SATPLAN, Henry Kautz, David Roznyai, Farhad
Teydaye-Saheli, Shane Neth, Michael Lindmark
2nd Prize, Optimal Track CPT, Vincent Vidal Hector Geffner
would like re-iterate awarding prizes is, be, sketchy
summary results complex event IPC-4. bits information
sufficient summarize thousands data points. Many decisions took
awarding prizes, i.e. judgement scaling behavior, close.
holds especially true runtime graphs concerning optimal planners,
runtime graphs concerning satisficing propositional planners. think
best, encourage everybody do, closer look results plots
themselves. said before, full plots available online appendix.

7. Conclusion
all, feeling organizers deterministic part IPC-4 great
success, made several valuable contributions field. mention the,
perspective, two prominent points: event provided community set
interesting new benchmarks, made visible yet another major step forward
scalability satisficing planning systems. latter made possible novel heuristics
domain analysis techniques.
wide variety questions addressed context future
(deterministic part of) IPC. Let us discuss feel important. Regarding benchmark domains, said invested significant effort IPC-4 benchmarks,
would definitely recommend re-use future IPC editions.
domain versions solved relatively easily certain groups planners, many
still constitute major challenges. Examples Pipesworld tankage restrictions,
Optical-Telegraph, large PSR instances, UMTS optimal planners. said,
IPC-3 domains also still challenging re-used. probably
useful community consolidate performance existing set benchmarks,
rather increase benchmark database large pace. one thing, measure
progress IPC editions, re-used benchmark domains (and instances), like Satellite
Settlers case IPC-4, useful.19 generally, benchmark set
already large; large set, situation may arise authors select
rather disjoint subsets individual experiments.
19. field addressing SAT problem, particularly respective competition events, progress
also often measured simply terms size (number variables clauses) formulas
could tackled successfully, making distinctions origin formulas (like,
randomly generated application). context IPC, one similar things
measuring parameters as, e.g., number ground actions tackled successfully. However, given
large differences individual domains used IPC, distinctions must made.
detailed investigation effect several parameters, IPC-4 domains, given Edelkamp
et al. (2005).

569

fiHoffmann & Edelkamp

Regarding PDDL extensions, formalisms derived predicates timed initial
literals introduced first steps respective directions. PDDL2.2
derived predicates formalism restrictive allows negative interactions
derived predicates; one could easily allow negative interactions lead cycles
thus ambiguous semantics (Thiebaux et al., 2003, 2005). One could also imagine
derivation rules values general data types predicates/Booleans, particularly numeric variables. timed initial literals, obviously encode
restrictive subset wide variety forms exogenous events take. Apart
exogenous events numeric values, events may reality continuous processes
conditioned world state, rather finitely many discrete time instants known beforehand. PDDL2.2 action model is, course, still restrictive postulation
discrete variable value updates. Still believe IPC let go
simple PDDL subsets STRIPS, support accessibility competition. noted
Section 4.1, systems still able handle language features introduced
IPC-3 IPC-4. Also, believe STRIPS track, generally domain
versions formulated simple language subsets, important encourage basic algorithms
research. new idea easier try simple language. avoid misunderstandings:
language features introduced PDDL2.1 PDDL2.2 already significant basis
acceptance implemented systems, definitely kept future editions
IPC.
context basic research, noted satisficing track IPC-4
almost entirely populated planners relaxed-plan based heuristic search type.
demonstrates danger competition concentrate research much around
successful methods. Still, two remarkable planners track, FastDownward SGPlan, use significantly different heuristic new domain analysis
techniques basis success, respectively.
Putting optimal planners separate track serves maintain this, different,
type planning algorithms. recommend keep distinction future IPC
events.
hand-tailored track, say seems unclear
could brought back focus. Maybe suitable form event would
online (at hosting conference) programming (i.e., planner tailoring) competition.
would, course, imply much smaller format event format IPC
automated planners grown already. online hand-tailored competition
would advantage better visibility programming efforts, taking
prohibitively much time system developers.
context competition size, last least words said
role responsibilities organizers. IPC grown large handled,
aspects, two persons. may worth thinking distributing
organization workload among larger group people. One approach might make
sense would let different people organize tracks concerning different PDDL
subsets. Another approach would let different people handle language definition,
benchmark preparation, results collection, respectively. would probably
good idea establish IPC council that, unlike organizing committees past,
570

fiThe Deterministic Part IPC-4: Overview

would persist across individual competitions, whose role would actively set
support organizing teams.

Acknowledgments
would like thank IPC-4 organizing committee, namely Fahiem Bacchus, Drew
McDermott, Maria Fox, Derek Long, Jussi Rintanen, David Smith, Sylvie Thiebaux,
Daniel Weld help taking decision language deterministic
part IPC-4, ironing details syntax semantics. especially
thank Maria Fox Derek Long giving us latex sources PDDL2.1 article,
discussing modifications document needed introduce semantics
derived predicates timed initial literals. indebted Roman Englert, Frederico
Liporace, Sylvie Thiebaux, Sebastian Trug, helped creation benchmark domains. wish say big thank participating teams
efforts. significant bravery submission planning system competition, choice design benchmark problems competition
organizers, individuals. thank LPG team investing extra effort
running IPC-3 LPG version IPC-4 benchmarks, thank Shahid Jabbar
proofreading text. thank Subbarao Kambhampati pointing name
classical part ambiguous, suggesting use deterministic part instead. Last
least, thank anonymous reviewers, Maria Fox role responsible JAIR
editor, comments; helped improve paper. time organizing
competition, Jorg Hoffmann supported DFG (Deutsche Forschungsgemeinschaft), research project HEUPLAN II. Stefan Edelkamp supported
DFG research project Heuristic Search.

Appendix A. BNF Description PDDL2.2
appendix contains complete BNF specification PDDL2.2 language. readability, mark ( ) points BNF where, comparison PDDL2.1,
new language constructs PDDL2.2 inserted.
A.1 Domains
Domains defined exactly PDDL2.2, except also allow define rules
derived predicates points operators (actions) allowed.
hdomaini

hrequire-defi
hrequire-keyi

::= (define (domain hnamei)
[hrequire-defi]
[htypes-defi]:typing
[hconstants-defi]
[hpredicates-defi]
[hfunctions-defi]:fluents
hstructure-defi )
::= (:requirements hrequire-keyi+)
::= See Section A.6
571

fiHoffmann & Edelkamp

htypes-defi
::= (:types htyped list (name)i)
hconstants-defi
::= (:constants htyped list (name)i)
hpredicates-defi
::= (:predicates hatomic formula skeletoni+ )
hatomic formula skeletoni
::= (hpredicatei htyped list (variable)i)
hpredicatei
::= hnamei
hvariablei
::= ?hnamei
hatomic function skeletoni
::= (hfunction-symboli htyped list (variable)i)
hfunction-symboli
::= hnamei
hfunctions-defi
::=:fluents (:functions hfunction typed list
(atomic function skeleton)i)
hstructure-defi
::= haction-defi
hstructure-defi
::=:durativeactions hdurative-action-defi
( ) hstructure-defi
::=:derivedpredicates hderived-defi

htyped list (x)i ::= x
htyped list (x)i ::=:typing x+ - htypei htyped list(x)i
hprimitive-typei::= hnamei
htypei
::= (either hprimitive-typei+ )
htypei
::= hprimitive-typei
hfunction typed list (x)i ::= x
hfunction typed list (x)i ::=:typing x+ - hfunction typei
hfunction typed list(x)i
hfunction typei
::= number

A.2 Actions
BNF action definition PDDL2.2.
haction-defi

::= (:action haction-symboli
:parameters ( htyped list (variable)i )
haction-def bodyi)
haction-symboli ::= hnamei
haction-def bodyi ::= [:precondition hGDi]
[:effect heffecti]
hGDi
::= ()
hGDi
::= hatomic formula(term)i
hGDi
::=:negativepreconditions hliteral(term)i
hGDi
::= (and hGDi )
hGDi
::=:disjunctivepreconditions (or hGDi )
hGDi
::=:disjunctivepreconditions (not hGDi)
hGDi
::=:disjunctivepreconditions (imply hGDi hGDi)
hGDi
::=:existentialpreconditions
(exists (htyped list(variable)i ) hGDi )
:universalpreconditions
hGDi
::=
(forall (htyped list(variable)i ) hGDi )
:fluents
hGDi
::=
hf-compi
hf-compi
::= (hbinary-compi hf-expi hf-expi)
hliteral(t)i
::= hatomic formula(t)i
hliteral(t)i
::= (not hatomic formula(t)i)
572

fiThe Deterministic Part IPC-4: Overview

hatomic formula(t)i
htermi
htermi
hf-expi
hf-expi
hf-expi
hf-expi
hf-headi
hf-headi
hbinary-opi
hbinary-opi
hbinary-opi
hbinary-opi
hbinary-compi
hbinary-compi
hbinary-compi
hbinary-compi
hbinary-compi
hnumberi
heffecti
heffecti
heffecti
hc-effecti
hc-effecti
hc-effecti
hp-effecti
hp-effecti
hp-effecti
hp-effecti
hcond-effecti
hcond-effecti
hassign-opi
hassign-opi
hassign-opi
hassign-opi
hassign-opi

::=
::=
::=
::=
::=
::=
::=
::=
::=
::=
::=
::=
::=
::=
::=
::=
::=
::=
::=

(hpredicatei )
hnamei
hvariablei
hnumberi
(hbinary-opi hf-expi hf-expi)
(- hf-expi)
hf-headi
(hfunction-symboli htermi )
hfunction-symboli
+


/
>
<
=
>=
<=
numeric literal
(integers floats form n.n).

::= ()
::= (and hc-effecti )
::= hc-effecti
::=:conditionaleffects (forall (hvariablei ) heffecti)
::=:conditionaleffects (when hGDi hcond-effecti)
::= hp-effecti
::= (hassign-opi hf-headi hf-expi)
::= (not hatomic formula(term)i)
::= hatomic formula(term)i
::=:fluents (hassign-opi hf-headi hf-expi)
::= (and hp-effecti )
::= hp-effecti
::= assign
::= scale-up
::= scale-down
::= increase
::= decrease

A.3 Durative Actions
Durative actions PDDL2.2, except restrict level 3
actions, duration given fixed value numeric expression (rather
possible values defined set constraints). slightly simplifies BNF.
hdurative-action-defi ::= (:durative-action hda-symboli
:parameters ( htyped list (variable)i )
hda-def bodyi)
hda-symboli
::= hnamei
hda-def bodyi
::= :duration (= ?duration hf-expi)
:condition hda-GDi
573

fiHoffmann & Edelkamp

:effect hda-effecti
::= ()
::= htimed-GDi
::= (and htimed-GDi+ )
::= (at htime-specifieri hGDi)
::= (over hintervali hGDi)
::= start
::= end
::=

hda-GDi
hda-GDi
hda-GDi
htimed-GDi
htimed-GDi
htime-specifieri
htime-specifieri
hintervali

A.4 Derived predicates
said, rules derived predicates given domain description points
actions allowed. BNF is:
( ) hderived-defi

::= (:derived htyped list (variable)i hGDi)

Note allow specification types derived predicate arguments.
might seem redundant predicate types already declared :predicates field.
Allowing specify types predicate (rule) parameters serves give language
unified look-and-feel, one might use option make parameter ranges
restrictive. (Remember specification types optional, mandatory.)
Repeating said Section 3.1.1, BNF generous
considered well-formed domain description PDDL2.2. call predicate P derived
rule predicate P head; otherwise call P basic. restrictions
apply are:
1. actions available planner affect derived predicates: derived
predicate occurs effect lists domain actions.
2. rule defines P (x) derived (x), variables x
pairwise different (and, notation suggests, free variables (x) exactly
variables x).
3. rule defines P (x) derived , Negation Normal Form
(NNF) (x) contain derived predicates negated form.
A.5 Problems
change made PDDL2.1 problem description allow specification timed initial literals.
hproblemi

::= (define (problem hnamei)
(:domain hnamei)
[hrequire-defi]
[hobject declarationi ]
hiniti
574

fiThe Deterministic Part IPC-4: Overview

hgoali
[hmetric-speci]
[hlength-speci ])
hobject declarationi ::= (:objects htyped list (name)i)
hiniti
::= (:init hinit-eli )
hinit-eli
::= hliteral(name)i
hinit-eli
::=:fluents (= hf-headi hnumberi)
( ) hinit-eli
::=:timedinitialliterals (at hnumberi hliteral(name)i)
hgoali
::= (:goal hGDi)
hmetric-speci
::= (:metric hoptimizationi hground-f-expi)
hoptimizationi
::= minimize
hoptimizationi
::= maximize
hground-f-expi
::= (hbinary-opi hground-f-expi hground-f-expi)
hground-f-expi
::= (- hground-f-expi)
hground-f-expi
::= hnumberi
hground-f-expi
::= (hfunction-symboli hnamei )
hground-f-expi
::= total-time
hground-f-expi
::= hfunction-symboli

Repeating said Section 3.1.1, requirement flag timed initial
literals implies requirement flag durational actions (see also Section A.6), i.e.
language construct available PDDL2.2 level 3. Also, BNF
generous considered well-formed problem description PDDL2.2.
times hnumberi timed literals occur restricted greater 0.
also derived predicates domain, timed literals restricted
influence these, i.e., like action effects allowed affect truth values
basic (non-derived) predicates (IPC-4 use derived predicates timed
initial literals within domain).

A.6 Requirements

table requirements PDDL2.2. requirements imply others;
abbreviations common sets requirements. domain stipulates requirements,
assumed declare requirement :strips.
575

fiHoffmann & Edelkamp

Requirement
:strips
:typing
:negative-preconditions
:disjunctive-preconditions
:equality
:existential-preconditions
:universal-preconditions
:quantified-preconditions
:conditional-effects
:fluents
:adl

:durative-actions
:derived-predicates
:timed-initial-literals

Description
Basic STRIPS-style adds deletes
Allow type names declarations variables
Allow goal descriptions
Allow goal descriptions
Support = built-in predicate
Allow exists goal descriptions
Allow forall goal descriptions
= :existential-preconditions
+ :universal-preconditions
Allow action effects
Allow function definitions use effects using
assignment operators arithmetic preconditions.
= :strips + :typing
+ :negative-preconditions
+ :disjunctive-preconditions
+ :equality
+ :quantified-preconditions
+ :conditional-effects
Allows durative actions.
Note imply :fluents.
Allows predicates whose truth value
defined formula
Allows initial state specify literals
become true specified time point
implies durative actions (i.e. applicable
PDDL2.2 level 3)

References
Bacchus, F. (2000). Subset PDDL AIPS2000 Planning Competition. AIPS-00
Planning Competition Committee.
Bacchus, F. (2001). AIPS00 planning competition. AI Magazine, 22 (3), 4756.
Bertoli, P., Cimatti, A., Slaney, J., & Thiebaux, S. (2002). Solving power supply restoration
problems planning via symbolic model-checking. Harmelen, F. V. (Ed.),
Proceedings 15th European Conference Artificial Intelligence (ECAI-02),
pp. 576580, Lyon, France. Wiley.
Blum, A. L., & Furst, M. L. (1995). Fast planning planning graph analysis. Proceedings 14th International Joint Conference Artificial Intelligence (IJCAI95), pp. 16361642, Montreal, Canada. Morgan Kaufmann.
Blum, A. L., & Furst, M. L. (1997). Fast planning planning graph analysis. Artificial
Intelligence, 90 (1-2), 279298.
Bonet, B., & Thiebaux, S. (2003). GPT meets PSR. Proceedings 13th International
Conference Automated Planning Scheduling (ICAPS-03), pp. 102111, Trento,
Italy. Morgan Kaufmann.
Cesta, A., & Borrajo, D. (Eds.). (2001). Recent Advances AI Planning. 6th European
Conference Planning (ECP01), Toledo, Spain. Springer-Verlag.
576

fiThe Deterministic Part IPC-4: Overview

Clarke, E. M., Grumberg, O., & Peled, D. (2000). Model Checking. MIT Press.
Edelkamp, S. (2003a). Limits possibilities PDDL model checking software..
Edelkamp, & Hoffmann (Edelkamp & Hoffmann, 2003).
Edelkamp, S. (2003b). Promela planning. Proceedings Model Checking Software
(SPIN), pp. 197212.
Edelkamp, S. (2003c). Taming numbers durations model checking integrated
planning system. Journal Artificial Intelligence Research, 20, 195238.
Edelkamp, S., & Hoffmann, J. (Eds.). (2003). Proceedings Workshop Competition:
Impact, Organization, Evaluation, Benchmarks, ICAPS03. AAAI Press.
Edelkamp, S., Hoffmann, J., Englert, R., Liporace, F., Thiebaux, S., & Trug, S. (2005).
Engineering benchmarks planning: domains used deterministic part
IPC-4. Journal Artificial Intelligence Research. Submitted.
Edelkamp, S., Hoffmann, J., Littman, M., & Younes, H. (Eds.). (2004). Proceedings
4th International Planning Competition. JPL.
Englert, R. (2003). Re-scheduling temporal operational resources mobile
execution dynamic UMTS applications. KI-Workshop AI Planning, Scheduling, Configuration Design (PUK).
Englert, R. (2005). Planning optimize UMTS call set-up execution mobile
agents. Journal Applied Artificial Intelligence (AAI), 19 (2), 99117.
Fikes, R. E., & Nilsson, N. (1971). STRIPS: new approach application theorem
proving problem solving. Artificial Intelligence, 2, 189208.
Fox, M., Long, D., & Halsey, K. (2004). investigation expressive power
PDDL2.1. Saitta, L. (Ed.), Proceedings 16th European Conference Artificial Intelligence (ECAI-04), Valencia, Spain. Wiley.
Fox, M., & Long, D. (2003). PDDL2.1: extension PDDL expressing temporal
planning domains. Journal Artificial Intelligence Research, 20, 61124.
Gerevini, A., Saetti, A., & Serina, I. (2003). Planning stochastic local search
temporal action graphs. Journal Artificial Intelligence Research, 20, 239290.
Haslum, P., & Geffner, H. (2001). Heuristic planning time resources.. Cesta,
& Borrajo (Cesta & Borrajo, 2001), pp. 121132.
Hatzack, W., & Nebel, B. (2001). operational traffic control problem: Computational
complexity solutions.. Cesta, & Borrajo (Cesta & Borrajo, 2001), pp. 4960.
Helmert, M. (2001). complexity planning transportation domains.. Cesta,
& Borrajo (Cesta & Borrajo, 2001), pp. 349360.
Helmert, M. (2003). Complexity results standard benchmark domains planning.
Artificial Intelligence, 143, 219262.
Helmert, M. (2004). planning heuristic based causal graph analysis. Koenig, S.,
Zilberstein, S., & Koehler, J. (Eds.), Proceedings 14th International Conference
Automated Planning Scheduling (ICAPS-04), pp. 161170, Whistler, Canada.
Morgan Kaufmann.
577

fiHoffmann & Edelkamp

Hipke, C. A. (2000). Distributed Visualization Geometric Algorithms. Ph.D. thesis,
University Freiburg.
Hoffmann, J. (2003). Metric-FF planning system: Translating ignoring delete lists
numeric state variables. Journal Artificial Intelligence Research, 20, 291341.
Hoffmann, J. (2005). ignoring delete lists works: Local search topology planning
benchmarks. Journal Artificial Intelligence Research. appear.
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation
heuristic search. Journal Artificial Intelligence Research, 14, 253302.
Holzmann, G. J. (2004). SPIN model checker: Primer reference manual. Addison
Wesley.
Long, D., & Fox, M. (2003). 3rd international planning competition: Results
analysis. Journal Artificial Intelligence Research, 20, 159.
McDermott, D. (2000). 1998 AI planning systems competition. AI Magazine,
21 (2), 3555.
McDermott, D., et al. (1998). PDDL Planning Domain Definition Language.
AIPS-98 Planning Competition Committee.
Milidiu, R. L., & dos Santos Liporace, F. (2004). Plumber, pipeline transportation planner.
Proceedings International Workshop Harbour Maritime Simulation,
HMS, pp. 99106, Rio de Janeiro, Brazil.
Milidiu, R. L., dos Santos Liporace, F., & de Lucena, C. J. (2003). Pipesworld: Planning pipeline transportation petroleum derivatives.. Edelkamp, & Hoffmann
(Edelkamp & Hoffmann, 2003).
Pednault, E. P. (1989). ADL: Exploring middle ground STRIPS situation calculus. Brachman, R., Levesque, H. J., & Reiter, R. (Eds.), Principles
Knowledge Representation Reasoning: Proceedings 1st International Conference (KR-89), pp. 324331, Toronto, ON. Morgan Kaufmann.
Penberthy, J. S., & Weld, D. S. (1992). UCPOP: sound, complete, partial order planner
ADL. Nebel, B., Swartout, W., & Rich, C. (Eds.), Principles Knowledge
Representation Reasoning: Proceedings 3rd International Conference (KR92), pp. 103114, Cambridge, MA. Morgan Kaufmann.
Thiebaux, S., & Cordier, M.-O. (2001). Supply restoration power distribution systems
benchmark planning uncertainty.. Cesta, & Borrajo (Cesta & Borrajo,
2001), pp. 8595.
Thiebaux, S., Cordier, M.-O., Jehl, O., & Krivine, J.-P. (1996). Supply restoration power
distribution systems case study integrating model-based diagnosis repair
planning. Horvitz, E., & Jensen, F. (Eds.), Proceedings 12th International
Conference Uncertainty AI (UAI-96), pp. 525532, Portland, OR, USA. Morgan
Kaufmann.
Thiebaux, S., Hoffmann, J., & Nebel, B. (2003). defence PDDL axioms. Gottlob, G.
(Ed.), Proceedings 18th International Joint Conference Artificial Intelligence
(IJCAI-03), pp. 961966, Acapulco, Mexico. Morgan Kaufmann.
578

fiThe Deterministic Part IPC-4: Overview

Thiebaux, S., Hoffmann, J., & Nebel, B. (2005). defence PDDL axioms. Artificial
Intelligence. appear.
Trug, S., Hoffmann, J., & Nebel, B. (2004). Applying automatic planning systems airport
ground-traffic control feasibility study. Biundo, S., Fruhwirth, T., & Palm,
G. (Eds.), KI-04: Advances Artificial Intelligence, pp. 183197, Ulm, Germany.
Springer-Verlag.
Vidal, V., & Geffner, H. (2004). Branching pruning: optimal temporal POCL planner based constraint programming. Proceedings 19th National Conference
American Association Artificial Intelligence (AAAI-04), pp. 570577, San
Jose, CA. MIT Press.
Younes, H., & Littman, M. (2005). Probabilistic part 4th international planning
competition. Journal Artificial Intelligence Research. Submitted.

579

fiJournal Artificial Intelligence Research 24 (2005) 641-684

Submitted 04/05; published 11/05

Binary Encodings Non-binary Constraint Satisfaction
Problems: Algorithms Experimental Results
Nikolaos Samaras

samaras@uom.gr

Department Applied Informatics
University Macedonia, Greece

Kostas Stergiou

konsterg@aegean.gr

Department Information Communication Systems Engineering
University Aegean, Greece

Abstract
non-binary Constraint Satisfaction Problem (CSP) solved directly using extended versions binary techniques. Alternatively, non-binary problem translated equivalent binary one. case, generally accepted translated
problem solved applying well-established techniques binary CSPs.
paper evaluate applicability latter approach. demonstrate use
standard techniques binary CSPs encodings non-binary problems problematic
results models rarely competitive non-binary representation.
overcome this, propose specialized arc consistency search algorithms binary encodings, evaluate theoretically empirically. consider three
binary representations; hidden variable encoding, dual encoding, double
encoding. Theoretical empirical results show that, certain classes non-binary
constraints, binary encodings competitive option, many cases, better one
non-binary representation.

1. Introduction
Constraint Satisfaction Problems (CSPs) appear many real-life applications
scheduling, resource allocation, timetabling, vehicle routing, frequency allocation, etc.
CSPs naturally eciently modelled using non-binary (or n-ary) constraints
may involve arbitrary number variables. well known non-binary CSP
converted equivalent binary one. well-known translations
dual encoding (Dechter & Pearl, 1989) hidden variable encoding (Rossi, Petrie, &
Dhar, 1990). ability translate non-binary CSP binary often used
past justication restricting attention binary CSPs. Implicitly, assumption faced non-binary CSP simply convert
binary one, apply well-known generic techniques solving binary equivalent.
paper show assumption awed generic techniques
binary CSPs suitable binary encodings non-binary problems.
past years, theoretical empirical studies eciency
binary encodings comparisons binary encodings non-binary representation (Bacchus & van Beek, 1998; Stergiou & Walsh, 1999; Mamoulis & Stergiou, 2001;
Smith, 2002; Bacchus, Chen, van Beek, & Walsh, 2002). Theoretical results showed
c
2005
AI Access Foundation. rights reserved.

fiSamaras & Stergiou

converting non-binary CSPs binary equivalents potentially ecient way
solve certain classes non-binary problems. However, (limited) empirical studies
cases appears true, Conways game Life (Smith,
2002) notable exception. various reasons this. many cases,
extensive space requirements binary encodings make infeasible. Also,
many non-binary problems utilize ecient specialized propagators certain constraints, algorithm developed Regin (1994) all-dierent constraint.
Converting constraints binary clearly impractical. Another reason,
overlooked, (if all) experimental studies use well-known generic local
consistency search algorithms encodings. way fail exploit
structure constraints encodings, ending inecient algorithms.
make binary encodings realistic choice modelling solving non-binary CSPs,
need algorithms utilize structural properties. Finally, important point
use binary encoding necessarily mean convert
non-binary constraints problem binary, commonly perceived.
selective constraints encode, based properties arity tightness,
get ecient hybrid models.
address issues, show use specialized arc consistency search
algorithms binary encodings non-binary CSPs lead ecient models. consider three encodings; dual, hidden variable, double encoding. latter,
basically conjunction two encodings, received little attention
may well turn signicant practice. aim study
twofold. First, present ecient algorithms binary encodings analyze
theoretically experimentally. Second, importantly, investigate
use algorithms help solve non-binary problems eciently. Towards
aims, make following contributions:
describe simple algorithm enforces arc consistency hidden variable
encoding arbitrary non-binary CSP O(ekdk ) time complexity, e
number constraints, k maximum arity constraints,
maximum domain size. gives O(d) improvement compared asymptotic
complexity generic arc consistency algorithm. improved complexity
complexity optimal generalized arc consistency algorithm
non-binary representation problem. also identify property arc
consistency algorithm hidden variable encoding make run faster,
arc inconsistent problems, generalized arc consistency algorithm.
consider search algorithms maintain local consistencies search
hidden variable encoding. show that, like maintaining arc consistency,
generalizations forward checking non-binary CSPs emulated
corresponding forward checking algorithms run hidden variable encoding
instantiate original variables (i.e. variables initial non-binary
problem). show algorithm corresponding algorithm nonbinary constraints following relationships: 1) visit number
search tree nodes, 2) asymptotic cost within polynomial
bound other.
642

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

describe specialized algorithm dual encoding achieves arc consistency
O(e3 dk ) worst-case time complexity. signicantly lower O(e2 d2k )
complexity generic arc consistency algorithm. improvement complexity
bound stems observation constraints dual encoding specic
structure; namely piecewise functional (Van Hentenryck, Deville, & Teng,
1992). Apart applying arc consistency dual encoding non-binary
CSP, algorithm also used specialized ltering algorithm certain
classes non-binary constraints.
adapt various search algorithms run double encoding compare
theoretically similar algorithms hidden variable encoding non-binary
representation. Search algorithms operate double encoding exploit
advantages hidden variable dual encoding. example, show
that, certain conditions, asymptotic cost maintaining arc consistency
algorithm double encoding polynomially worse asymptotic
cost corresponding algorithm non-binary representation (and hidden
variable encoding), exponentially better.
Finally, make extensive empirical study various domains. consider
random problems well structured ones, like crossword puzzle generation, conguration, frequency assignment. study consists two parts. rst
part, give experimental results demonstrate advantages specialized
algorithms binary encodings compared generic algorithms. example,
specialized arc consistency algorithm dual encoding orders magnitude faster generic arc consistency algorithm. second part show
use binary encodings oer signicant benets solving certain classes
non-binary CSPs. example, solving dual encoding conguration
problems orders magnitudes ecient solving non-binary
representation. Also, empirical results frequency assignment - like problems
demonstrate binary encoding benecial even non-binary constraints
intentionally specied.

paper structured follows. Section 2 give necessary denitions
background. Section 3 describe specialized arc consistency algorithm hidden
variable encoding. also demonstrate extensions forward checking
non-binary CSPs emulated binary forward checking algorithms run
hidden variable encoding. Section 4 explain complexity arc consistency
dual encoding improved describe specialized arc consistency algorithm.
Section 5 discusses algorithms double encoding. Section 6 present experimental
results random structured problems demonstrate usefulness proposed
algorithms. also draw conclusions regarding applicability encodings,
based theoretical experimental results. Section 7 discusses related work. Finally,
Section 8 conclude.
643

fiSamaras & Stergiou

2. Background
section give necessary denitions CSPs, describe hidden variable,
dual, double encodings non-binary CSPs.
2.1 Basic Definitions
Constraint Satisfaction Problem (CSP), P , dened tuple (X, D, C), where:
X = {x1 , . . . , xn } nite set n variables.
= {Din (x1 ), . . . , Din (xn )} set initial domains. variable xi X,
Din (xi ) initial nite domain possible values. CSP algorithms remove
values domains variables value assignments propagation.
variable xi , denote D(xi ) current domain xi time consists
values removed Din (xi ). assume every xi X,
total ordering <d dened Din (xi ).
C = {c1 , . . . , ce } set e constraints. constraint ci
pair (vars(ci ), rel(ci )), 1) vars(ci ) = {xj1 , . . . , xjk }
X called constraint scheme, 2) rel(ci ) subset
Din (xj1 )x . . . xDin (xjk ) species allowed combinations
ables vars(ci ).

C dened
ordered subset
Cartesian product
values vari-

size vars(ci ) called arity constraint ci . Constraints arity 2 called
binary. Constraints arity greater 2 called non-binary (or n-ary). tuple
rel(ci ) ordered list values (a1 , . . . , ak ) aj Din (xj ),j = 1, . . . , k.
tuple = (a1 , . . . , ak ) valid aj , j 1, . . . , k, aj D(xj ). is, tuple valid
values tuple present domains corresponding variables.
process veries whether given tuple allowed constraint ci called
consistency check. constraint either dened extensionally set allowed (or
disallowed) tuples intensionally predicate arithmetic function. binary CSP
represented graph (called constraint graph) nodes correspond variables
edges correspond constraints. non-binary CSP represented constraint
hyper-graph constraints correspond hyper-edges connecting two nodes.
assignment value variable xi denoted (xi , a). tuple =
(a1 , . . . , ak ) viewed set value variable assignments {(x1 , a1 ), . . . , (xk , ak )}.
set variables tuple dened denoted vars( ).
subset vars vars( ), [vars ] denotes sub-tuple includes assignments
variables vars . two tuples rel(ci ) ordered lexicographic
ordering <lex . ordering, <lex exists subset {x1 , . . . , xj } ci
[x1 , . . . , xj ] = [x1 , . . . , xj ] [xj+1 ] <lex [xj+1 ]. assignment consistent,
constraints ci , vars(ci ) vars( ), [vars(ci )] rel(ci ). solution CSP
(X, D, C) consistent assignment variables X. exists solution
given CSP, say CSP soluble. Otherwise, insoluble.
basic way solving CSPs using backtracking search. seen
traversal search tree comprises possible assignments values variables.
644

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

level tree corresponds variable. node search tree corresponds
tuple (i.e. assignment values variables). root tree corresponds
empty tuple, rst level nodes correspond 1-tuples (an assignment value
one variable), second level nodes correspond 2-tuples (assignment values two
variables generated extending rst level 1-tuples) etc. stage search
tree traversal, variables already assigned called past variables.
recently assigned variable called current variable. variables
assigned yet called future variables.
rest paper use notation n number variables
CSP, e number constraints problem, maximum domain size
variables, k maximum arity constraints.
2.1.1 Arc Consistency
important concept CSPs concept local consistency. Local consistencies
properties applied CSP, using (typically) polynomial algorithms, remove
inconsistent values either prior search. Arc consistency commonly
used local consistency property existing constraint programming engines.
give denition arc consistency.
Definition 2.1 value D(xj ) consistent constraint ci , xj vars(ci )
rel(ci ) [xj ] = valid. case say support
ci . constraint ci Arc Consistent (AC) variable xj vars(ci ), D(xj ),
exists support ci . CSP (X, D, C) arc consistent empty
domain constraints C arc consistent.
Arc consistency enforced CSP removing unsupported values
domains variables. enforcing arc consistency (or local consistency property
general) CSP P , mean applying algorithm yields new CSP
arc consistent (or property A) set solutions P .
denition arc consistency applies constraints arity. distinguish
binary non-binary cases, use term arc consistency (AC) refer
property arc consistency binary constraints only. non-binary constraints
use term Generalized Arc Consistency (GAC).
usefulness AC processing recognized early, result, various AC
algorithms binary constraints proposed literature (e.g. AC-3 Mackworth, 1977, AC-4 Mohr & Henderson, 1986, AC-5 Van Hentenryck et al., 1992, AC-7
Bessiere et al., 1995, AC-2001 Bessiere & Regin, 2001, AC3.1 Zhang & Yap, 2001).
extended non-binary case (e.g. GAC-4 Mohr & Masini,
1988, GAC-Schema Bessiere & Regin, 1996a, GAC-2001 Bessiere & Regin, 2001).
AC enforced binary CSP O(ed2 ) optimal worst-case time complexity.
worst-case complexity enforcing GAC non-binary CSP O(ekdk ) (Bessiere & Regin,
1996a).
paper use algorithms AC-2001 GAC-2001 theoretical empirical
comparisons specialized algorithms encodings. restrictive,
sense generic AC (and GAC) algorithm used instead.
645

fiSamaras & Stergiou

Following Debruyne & Bessiere (2001), call local consistency property stronger
B problem enforcing deletes least values B, strictly
stronger stronger least one problem deletes values
B. call equivalent B delete values problems. Similarly,
call search algorithm stronger search algorithm B every problem visits
search tree nodes B, strictly stronger stronger
least one problem visits less nodes B. equivalent B visit
nodes problems.
Following Bacchus et al. (2002), asymptotic cost (or cost hereafter) search
algorithm determined worst-case number nodes algorithm
visit solve CSP, worst-case time complexity algorithm node1 .
paper Bacchus et al. (2002), use measure set asymptotic bounds
relative performance various algorithms. example, two algorithms
B always visit nodes enforces property node exponentially
higher complexity property enforced B, say algorithm
exponentially greater cost algorithm B.
2.1.2 Functional Piecewise Functional Constraints
specialized AC algorithms hidden variable dual encoding
describe Sections 3 4 exploit structural properties encodings.
explain detail later, binary constraints hidden variable encoding one-way
functional, binary constraints dual encoding piecewise functional.
dene concepts.
Definition 2.2 binary constraint c, vars(c) = {xi , xj }, functional respect
D(xi ) D(xj ) D(xi ) (resp. b D(xj )) exists one value
b D(xj ) (resp. D(xi )) b support c (resp. support b).
example functional constraint xi = xj . binary constraint one-way functional
functionality property holds respect one variables involved
constraint.
Informally, piecewise functional constraint variables xi , xj constraint
domains xi xj partitioned groups group D(xi )
supported one group D(xj ), vice versa. give formal denition,
rst dene concept piecewise decomposition.
Definition 2.3 (Van Hentenryck et al., 1992) Let c binary constraint vars(c) =
{xi , xj }. partitions = {s1 , . . . , sm } D(xi ) = {s1 , . . . , sm } D(xj )
piecewise decomposition D(xi ) D(xj ) respect c sl S,sl ,
following property holds: either sl , b sl , (a, b) rel(c), sl , b sl ,
(a, b)
/ rel(c).
1. paper Bacchus et al. (2002) cost applying variable ordering heuristic node
also taken account. theoretically compare search algorithms paper assume
use variable ordering, take cost account.

646

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

Definition 2.4 (Van Hentenryck et al., 1992) binary constraint c, vars(c) =
{xi , xj }, piecewise functional respect D(xi ) D(xj ) exists piecewise
decomposition = {s1 , . . . , sm } D(xi ) = {s1 , . . . , sm } D(xj ) respect
c sl (resp. sl ), exists one sl (resp. sl S),
sl , b sl (a, b) rel(c).
Example piecewise functional constraints modulo (x2 MOD x3 = a) integer
division (x2 DIV x3 = a) constraints.
2.2 Binary Encodings
two well-known methods transforming non-binary CSP binary one;
dual graph encoding hidden variable encoding. encode non-binary
constraints variables domains valid tuples constraints. is,
building binary encoding non-binary constraint store extensional representation
constraint (the set allowed tuples). third method double encoding
combines two.
2.2.1 Dual Encoding
dual encoding (originally called dual graph encoding) inspired work relational
databases. dual encoding (DE) (Dechter & Pearl, 1989) variables swapped
constraints vice versa. constraint c original non-binary CSP represented variable call dual variable denote vc . refer variables
original non-binary CSP original variables. domain dual variable vc
consists set allowed tuples original constraint c. Binary constraints
two dual variables vc vc exist vars(c) vars(c ) = . is, constraints c
c share one original variables. common vars set original variables
common c c tuple D(vc ) supported constraint vc
vc exists tuple D(vc ) [common vars] = [common vars].

v c1

v c4

(0,0,1) (0,1,0)

(0,0,0) (0,1,1)

(1,0,0)

(1,0,1)

(0,0,1) (1,0,0)

(0,1,0) (1,0,0)

(1,1,1)

(1,1,0) (1,1,1)
v c3

v c2

Figure 1: Dual encoding non-binary CSP.
647

fiSamaras & Stergiou

Consider following example six variables 0-1 domains, four constraints:
c1 : x1 + x2 + x6 = 1, c2 : x1 x3 + x4 = 1, c3 : x4 + x5 x6 1, c4 : x2 + x5
x6 = 0. DE represents problem 4 dual variables, one constraint.
domains dual variables tuples satisfy respective constraint.
example, dual variable vc3 associated third constraint domain
{(0, 1, 0), (1, 0, 0), (1, 1, 0), (1, 1, 1)} tuples values (x4 , x5 , x6 )
satisfy x4 + x5 x6 1. second example, dual variable vc4 associated
last constraint domain {(0, 0, 0), (0, 1, 1), (1, 0, 1)}. vc3 vc4
compatibility constraint ensure two original variables common, x5 x6 ,
values. constraint allows pairs tuples agree
second third elements (i.e. (1, 0, 0) vc3 (0, 0, 0) vc4 , (1, 1, 1) vc3
(0, 1, 1) vc4 ). DE problem shown Figure 1.
rest paper, sometimes denote cvi non-binary constraint
encoded dual variable vi . original variable xj vars(cvi ), pos(xj , cvi )
denote position xj cvi . instance, given constraint cvi variables x1 , x2 , x3 ,
pos(x2 , cvi ) = 2.
2.2.2 Hidden Variable Encoding
hidden variable encoding (HVE) inspired work philosopher Peirce (1933).
According Rossi et al. (1990), Peirce rst showed binary relations
expressive power non-binary relations.
HVE (Rossi et al., 1990), set variables consists original variables
non-binary CSP plus set dual variables. dual encoding, dual
variable vc corresponds constraint c original problem. domain dual
variable consists tuples satisfy original constraint. every dual variable
vc , binary constraint vc original variables xi
xi vars(c). tuple D(vc ) supported constraint vc xi
exists value D(xi ) [xi ] = a.
Consider previous example six variables 0-1 domains, four constraints:
c1 : x1 + x2 + x6 = 1, c2 : x1 x3 + x4 = 1, c3 : x4 + x5 x6 1, c4 : x2 + x5 x6 = 0.
HVE are, addition original six variables, four dual variables.
DE, domains variables tuples satisfy respective constraint.
compatibility constraints dual variable vc original variables
contained constraint c. example, constraints vc3 x4 ,
vc3 x5 vc3 x6 , variables involved constraint c3 .
compatibility constraint cv3 x4 relation true rst element
tuple assigned cv3 equals value x4 . HVE shown Figure 2.
2.2.3 Double Encoding
double encoding (Stergiou & Walsh, 1999) combines hidden variable dual
encoding. HVE, set variables double encoding consists
variables original non-binary CSP plus dual variables. every dual variable
vc , binary constraint vc original variables xi involved
corresponding non-binary constraint c. DE, also binary constraints
648

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

v c1

v c4

(0,0,1) (0,1,0)

(0,0,0) (0,1,1)

(1,0,0)

(1,0,1)

x1 0 1

x2 0 1

x3 0 1

x4 0 1

(0,0,1) (1,0,0)

x5

01

x6

01

(0,1,0) (1,0,0)

(1,1,1)

(1,1,0) (1,1,1)
v c3

v c2

Figure 2: Hidden variable encoding non-binary CSP.
two dual variables vc vc non-binary constraints c c share one
original variables.

3. Algorithms Hidden Variable Encoding
section discuss specialized algorithms HVE. rst describe simple
AC algorithm HVE worst-case time complexity optimal
GAC algorithm non-binary representation. Appendix A, also show
arc consistent CSP proposed AC algorithm performs exactly number
consistency checks corresponding GAC algorithm. arc inconsistent problems
show AC algorithm HVE detect inconsistency earlier thus
perform fewer consistency checks GAC algorithm.
also consider search algorithms HVE maintain local consistencies
search. show that, like maintaining arc consistency, generalizations forward
checking non-binary CSPs emulated corresponding binary forward checking
algorithms HVE instantiate original variables.
3.1 Arc Consistency
proved AC HVE equivalent GAC non-binary problem
(Stergiou & Walsh, 1999). Since HVE binary CSP, one obvious way apply AC
using generic AC algorithm. However, results redundant processing
asymptotic time complexity worse O(ekdk ). precise, HVE problem
kary constraints ek binary constraints dual original variables.
constraint, AC enforced O(ddk ) worst-case time complexity.
whole problem complexity O(ekdk+1 ).
Instead, describe simple AC algorithm operates HVE
achieves worst-case time complexity optimal GAC algorithm applied
non-binary representation. achieve slightly modifying GAC algorithm
649

fiSamaras & Stergiou

Bessiere Regin (2001) (GAC-2001). Figure 3 sketch AC algorithm
HVE, call HAC (Hidden AC).
function HAC
1:
Q
2:
dual variable vj
3:
variable xi xi vars(cvj )
4:
Revise(xi , vj ) = RU E
5:
D(xi ) empty return INCONSISTENCY
6:
put Q dual variable vl xi vars(cvl )
7:
return P ropagation
function P ropagation
8:
Q empty
9:
pop dual variable vj Q
10:
unassigned variable xi xi vars(cvj )
11:
Revise(xi , vj ) = RU E
12:
D(xi ) empty return INCONSISTENCY
13:
put Q dual variable vl xi vars(cvl )
14: return CONSISTENCY
function Revise(xi , vj )
15: DELETION FALSE
16:
value D(xi )
17:
currentSupportxi,a,vj valid
18:
( D(vj )) >lex currentSupportxi,a,vj , [xi ] = valid
19:
currentSupportxi,a,vj
20:
else
21:
remove D(xi )
22:
vl xi vars(cvl )
23:
remove D(vl ) tuple [xi ] =
24:
D(vl ) empty return INCONSISTENCY
25:
DELETION TRUE
26: return DELETION
Figure 3: HAC: AC algorithm hidden variable encoding.
HAC algorithm uses stack (or queue) dual variables propagate value deletions, works follows. initialization phase iterates dual variable
vj (line 2). every original variable xi constrained vj algorithm revises
constraint vj xi . done calling function Revise (line 4).
revision, value D(xi ) look tuple domain vj supports
it. AC-2001, store currentSupportxi,a,vj : recent tuple found
D(vj ) supports value variable xi 2 . tuple deleted D(vj )
2. assume, without loss generality, algorithm looks supports checking tuples
lexicographic order.

650

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

know supported. Otherwise, look new supporting tuple starting
tuple immediately currentSupportxi ,a,vj . tuple found
removed D(xi ) (line 21). case, tuples include value removed
domains dual variables constrained xi (lines 2223).
dual variables already stack added it3 . Then, dual variables
removed stack sequentially. dual variable vj removed
stack, algorithm revises constraint vj original variable xi constrained vj . algorithm terminates values domain deleted,
case problem arc consistent, stack becomes empty, case
problem arc consistent.
main dierence HAC GAC-2001 GAC-2001 include
lines 2224. is, even non-binary constraints given extension, GAC2001 remove tuples become invalid lists allowed tuples.
result, two algorithms check validity tuple (in lines 17 18) dierent
ways. Later section explain detail. Apart dierence,
important aects run times, two algorithms essentially
same. move HAC GAC-2001 removing lines 2224 substituting
references dual variables references corresponding constraints. example,
currentSupportxi,a,vj corresponds currentSupportxi,a,cvj GAC-2001, i.e. last tuple
constraint cvj supports value variable xi . Note implementation
GAC-2001, propagation constraint-based. is, algorithm utilizes stack
constraints perform propagation value deletions.
3.1.1 Complexities
give upper bound number consistency checks performed HAC
worst-case. Function Revise(xi , vj ) called kd times dual variable
vj , every deletion value domain xi , xi one k original
variables constrained vj . call Revise(xi , vj ) algorithm performs
checks (one value D(xi )) see currentSupportxi,a,vj valid (line 17).
currentSupportxi,a,vj valid, HAC tries nd new supporting tuple D(vj ).
check tuple contains assignment (xi , a) supports need check
valid. tuple valid one values removed domain
corresponding variable. means tuple also removed
domain dual variable. Therefore, checking validity tuple done
constant time looking domain dual variable. algorithm needs
check support dk1 , maximum, tuples contain assignment (xi , a).
Since HAC stores currentSupportxi,a,vj , call Revise(xi , vj ) value
D(xi ), checks tuples checked before. words,
check dk1 tuples value xi . overall, worst
case, dk1 checks plus checks test validity current support.
kd values upper bound checks performed HAC make one dual variable AC
3. Note dual variables already stack never added it. sense, stack
implemented set.

651

fiSamaras & Stergiou

O(kd(d + dk1 ))=O(kdk ). e dual variables worst-case complexity bound O(ekdk ),
complexity GAC non-binary representation.
asymptotic space complexity HAC algorithm dominated O(edk )
space needed store domains dual variables. algorithm also requires O(nde)
space store current supports. Since space required grows exponentially
arity constraints, reasonable assume HVE (and binary
encodings) cannot practical constraints large arity, unless constraints
tight.
mentioned, consistency check non-binary representation done dierent
way HVE. Assume GAC-2001 looks support value ai D(xi )
constraint c, vars(c) = {x1 , . . . , xk } xi vars(c). tuple = (a1 , . . . , ak )
supports ai [xi ] = ai valid. check valid, GAC-2001 check
values a1 , . . . , ak (except ai ) still domains variables x1 , . . . , xk . Therefore,
worst case, consistency check GAC-2001 involves k 1 operations. contrast,
HAC checks validity tuple constant time looking domain
corresponding dual variable see tuple still there. However, means
algorithm update (usually) large domains dual variables value
deletion original variable. aects run times algorithms dierent
problems settings.
Appendix show HAC complexity, also
performs exactly number consistency checks GAC-2001 arc consistent
problems. also show arc inconsistent problems dierence
number checks favor HVE.
3.2 Search Algorithms
Search algorithms maintain local consistencies widely used CSP solving.
extended non-binary case. example, maintaining arc consistency
(MAC) forward checking (FC). shown non-binary version MAC
(MGAC) applied non-binary CSP equivalent MAC applied HVE
CSP original variables instantiated variable orderings used
(Stergiou & Walsh, 1999). show that, like MGAC, non-binary extensions FC
emulated equivalent algorithms run HVE.
FC (Haralick & Elliot, 1980) rst generalized handle non-binary constraints
Van Hentenryck (1989). According denition Van Hentenryck (1989), forward
checking performed k-1 variables k-ary constraint assigned
remaining variable unassigned. algorithm called nFC0 paper Bessiere,
Meseguer, Freuder, & Larrosa (2002) more, stronger, generalizations FC
non-binary constraints introduced. generalizations dier
extent look-ahead perform variable instantiation. Algorithm nFC1 applies
one pass GAC constraint constraint projection involving current variable
exactly one future variable4 . Algorithm nFC2 applies GAC set constraints
involving current variable least one future variable, one pass. Algorithm nFC3
applies GAC set constraints involving current variable least one future
4. One pass means constraint processed once.

652

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

variable. Algorithm nFC4 applies GAC set constraints involving least one
past variable least one future variable, one pass. Algorithm nFC5,
strongest version, applies GAC set constraints involving least one past variable
least one future variable. generalizations reduce simple FC applied
binary constraints.
show various versions nFC equivalent, terms visited nodes,
binary versions FC run HVE problem. holds
assumption binary algorithms assign original variables use
variable value ordering heuristics, static dynamic, non-binary counterparts.
Note algorithm nds consistent assignment original variables,
assignments propagated dual variables, domains dual
variables reduced singletons. is, domain dual variable vc
contain single tuple consistent assignments original variables
constrained vc . Therefore, algorithm proceed assign dual variables
backtrack-free manner.
equivalence nFC1 version FC HVE, called FC+ (Bacchus
& van Beek, 1998), proved Bessiere et al. (2002). FC+ specialized forward
checking algorithm HVE. operates like standard binary FC except
domain dual variable pruned, FC+ removes adjacent original variables
value longer supported.
Algorithms nFC2-nFC5 also equivalent algorithms operate HVE.
call algorithms hFC2hFC5. example, hFC5 enforce AC set dual
variables, original variables connected them, dual variable connected
least one past original variable least one future original variable. Note
nFC0 natural equivalent algorithm HVE. emulate HVE
get inecient awkward algorithm. following, hFC0 refer standard
binary FC algorithm hFC1 refer FC+.

Proposition 3.1 non-binary CSP, xed variable value ordering, algorithm nFCi, i= 2, . . . 5, equivalent algorithm hFCi operates hidden variable
encoding problem.
Proof: prove nFC5, strongest among generalized FC algorithms.
proof versions similar. need prove node
search tree algorithms nFC5 hFC5 delete exactly values
domains original variables. Assume node, instantiating current
variable, nFC5 deletes value future variable xi . exists constraint
c including xi least one past variable, value xi supporting tuple c.
HVE, hFC5 tries make vc (the dual variable corresponding c) AC
remove tuples assign xi . Hence, hFC5 delete domain xi .
opposite case, hFC5 deletes value original variable xi means
tuples including assignment removed domains dual variables
include xi least one past variable. non-binary representation problem,
assignment xi supporting tuples constraints involve xi
least one past variable. Therefore, nFC5 delete domain xi . 2
653

fiSamaras & Stergiou

Algorithms nFC2nFC5 equivalent node visits corresponding algorithms hFC2hFC5, also asymptotic cost. holds
condition non-binary algorithms use GAC-2001 (or optimal algorithm)
enforce GAC, HVE versions use algorithm HAC.
Proposition 3.2 non-binary CSP, xed variable value ordering, algorithm nFCi, i= 2, . . . 5, asymptotic cost algorithm hFCi operates
hidden variable encoding problem.
Proof: Section 3.1 showed enforce AC HVE non-binary
CSP worst-case complexity GAC non-binary representation
problem. Since algorithm nFCi enforces GAC part problem
algorithm hFCi enforces AC, visit nodes search tree, follows
two algorithm asymptotic cost. 2
paper Bessiere et al. (2002), detailed discussion complexities algorithms nFC0nFC5 made. worst-case complexity nFC2 nFC3 one node
O(|Cc,f |(k 1)dk1 ), |Cc,f | number constraints involving current variable least one future variable. also complexity hFC3 hFC4.
worst-case complexity nFC4 nFC5 one node O(|Cp,f |(k 1)dk1 ), |Cp,f |
number constraints involving least one past variable least one future
variable. also complexity hFC4 hFC5.
Assuming nodes(algi ) set search tree nodes visited search algorithm
algi following holds.
Corollary 3.1 Given hidden variable encoding CSP xed variable value
ordering schemes, following relations hold:
1. nodes(hFC1) nodes(hFC0)
2. nodes(hFC2) nodes(hFC1)
3. nodes(hFC5) nodes(hFC3) nodes(hFC2)
4. nodes(hFC5) nodes(hFC4) nodes(hFC2)
5. nodes(MAC) nodes(hFC5)
Proof: proof 1 straightforward, see paper Bacchus & van Beek (1998).
Proof 2-4 straightforward consequence Proposition 3.1 Corollary 2
paper Bessiere et al. (2002) hierarchy algorithms nFC0-nFC5 node visits
given. easy see 5 holds since hFC5 applies AC part CSP,
MAC applies whole problem. Therefore, MAC prune least many
values hFC5 given node search tree. Since variable value
ordering heuristics used, means MAC visit number
nodes hFC5. 2
Note paper Bacchus & van Beek (1998) experimental results show differences FC HVE FC non-binary representation. However,
654

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

algorithms compared FC+ nFC0, equivalent. Also,
proved hFC0 exponentially greater cost nFC0, vice versa
(Bacchus et al., 2002). However, algorithms equivalent. proved Proposition 3.2, result Bacchus et al. (2002) hold comparing equivalent
algorithms.
far showed solving non-binary CSP directly many ways equivalent
solving using HVE, assuming original variables instantiated.
natural question whether search techniques inapplicable
non-binary case, applied encoding. answer ability search
algorithm operates encoding instantiate dual variables. equivalent
non-binary representation would imply instantiating values one variables
simultaneously. implement algorithm would modify standard search
algorithms heuristics devise new ones. hand, HVE algorithm
instantiates dual variables easily implemented.

4. Algorithms Dual Encoding
section turn attention DE describe specialized AC algorithm
signicantly lower complexity generic algorithm.
4.1 Arc Consistency
know AC DE strictly stronger GAC non-binary representation
AC HVE (Stergiou & Walsh, 1999). Since DE binary CSP, one obvious
way apply AC using generic AC algorithm. domain size dual variable
corresponding kary constraint dk worst case. Therefore, apply
optimal AC algorithm enforce AC one dual constraint O(d2k ) worstcase complexity. DE CSP e constraints maximum arity k
e(e 1)/2 binary constraints (when pairs dual variables share one
original variables). Therefore, enforce AC DE CSP O(e2 d2k ) worstcase complexity. signicantly expensive compared O(ekdk ) complexity
bound GAC non-binary representation AC HVE.
high complexity bound, AC processing DE considered impractical, except
perhaps tight constraints.
However, show AC applied DE much eciently.
precise enforce AC DE non-binary CSP O(e3 dk ) worst-case time
complexity. improvement asymptotic complexity achieved exploiting
structure DE; namely, fact constraints DE piecewise
functional.
Consider binary constraint dual variables vi vj . create piecewise
decomposition tuples domain either dual variable groups
tuples group supported group tuples variable.
non-binary constraints corresponding two dual variables share f original variables
x1 , . . . , xf domain size d, partition tuples vi vj df groups.
tuple group includes sub-tuple form (a1 , . . . , af ), a1
D(x1 ), . . . , af D(xf ). tuple supported tuples group
655

fiSamaras & Stergiou

variable, tuple also includes sub-tuple (a1 , . . . , af ).The tuples
belonging supports tuple since tuple contain
sub-tuple (a1 , . . . , af ). words, group tuples variable vi
supported corresponding group variable vj tuples groups
values original variables common two encoded non-binary
constraints. Therefore, constraints DE piecewise functional.
Example 4.1 Assume two dual variables v1 v2 . v1 encodes constraint
(x1 , x2 , x3 ), v2 encodes constraint (x1 , x4 , x5 ), original variables
x1 , . . . , x5 domain {0, 1, 2}. partition tuples dual variable
3 groups. rst group include tuples form (0, , ), second include tuples form (1, , ), third include tuples form (2, , ).
star () means corresponding original variable take value. group
supported corresponding group variable. Note tuples
variable vi partitioned dierent groups according constraint involves vi .
instance, another dual variable v3 encoding constraint (x6 , x7 , x3 )
partition tuples D(v1 ) according constraint v1 v3 groups
form (, , 0), (, , 1), (, , 2).
Van Hentenryck, Deville & Teng (1992) shown AC achieved
set binary piecewise functional constraints O(ed) worst-case time complexity,
improvement O(d) compared O(ed2 ) complexity arbitrary binary constraints
(Van Hentenryck et al., 1992). Since showed constraints DE piecewise
functional, result Van Hentenryck et al. (1992) means improve
O(e2 d2k ) complexity AC DE.
Figure 4 sketch AC-3 like AC algorithm specically designed DE,
call PW-AC (PieceWise Arc Consistency). show, algorithm
worst-case time complexity O(e3 dk ). complexity bound achieved
AC-5 algorithm Van Hentenryck et al. (1992), specialization piecewise
functional constraints, necessary adaptations operate DE.
AC algorithms, PW-AC uses stack (or queue) propagate deletions domains
variables. stack processes groups piecewise decompositions, instead variables
constraints usual AC algorithms. use following notation:
S(vi , vj ) = {s1 (vi , vj ), . . . , sm (vi , vj )} denotes piecewise decomposition D(vi )
respect constraint vi vj . sl (vi , vj ), l = 1, . . . , m,
group partition.
sup(sl (vi , vj )) denotes group S(vj , vi ) support group sl (vi , vj )
S(vi , vj ). discussed, group unique.
counter(sl (vi , vj )) holds number valid tuples belong group sl (vi , vj )
decomposition S(vi , vj ). is, time value counter(sl (vi , vj )) gives
current cardinality group.
GroupOf (S(vi , vj ), ) function returns group S(vi , vj ) tuple
belongs. implement function, constraint dual variables vi
656

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

function P W AC
1:
Q
2:
initialize group counters 0
3:
variable vi
4:
variable vj constrained vi
5:
tuple D(vi )
6:
counter(GroupOf (S(vi , vj ), )) counter(GroupOf (S(vi , vj ), )) + 1
7:
variable vi
8:
variable vj constrained vi
9:
group sl (vi , vj )
10:
counter(sl (vi , vj )) = 0
11:
put sl (vi , vj ) Q
12: return P ropagation
function P ropagation
13: Q empty
14:
pop group sl (vi , vj ) Q
15:

16:
Revise(vi , vj , sl (vi , vj ))
17:
D(vj ) empty return INCONSISTENCY
18:
group sl (vj , vk ) put sl (vj , vk ) Q
19: return CONSISTENCY
function Revise(vi , vj , sl (vi , vj ))
20: tuple D(vj ) sup(sl (vi , vj ))
21:
remove D(vj )
22:
group sl (vj , vk ) includes
23:
counter(sl (vj , vk )) counter(sl (vj , vk )) 1
24:
counter(sl (vj , vk )) = 0
25:
add sl (vj , vk )
26: return
Figure 4: PW-AC. AC algorithm dual encoding.

vj store original variables shared non-binary constraints cvi
cvj . Also, original variable xl store pos(xl , cvi ) pos(xl , cvj ).
way GroupOf function takes constant time.
set contains groups counter reduced 0 call
function Revise. is, groups tuples belonging
deleted.
algorithm works follows. initialization phase, group count
number tuples contains (lines 36). Then, variable vi iterate
657

fiSamaras & Stergiou

variables vj constrained vi . group sl (vi , vj ) S(vi , vj ), check
sl (vi , vj ) empty (line 10). empty, added stack propagation.
next phase, function P ropagation called delete unsupported tuples
propagate deletions (line 12). previous phase nished, stack
contain number groups 0 cardinality. group sl (vi , vj ) must
remove tuples belonging group sup(sl (vi , vj )) since lost support.
done successively removing group sl (vi , vj ) stack calling function
Revise. Since group sup(sl (vi , vj )) lost support, tuple D(xj ) belongs
sup(sl (vi , vj )) deleted (lines 2021). Apart sup(sl (vi , vj )), tuple may also belong
groups D(vj ) partitioned respect constraints vj
variables. Since deleted, counters groups must updated (i.e. reduced
one). done lines 2223. implementation use function GroupOf
access relevant groups. counter group becomes 0 group
added stack propagation (lines 2425 18). process stops either
stack domain variable becomes empty. former case, DE AC,
latter not.
following example illustrates advantage algorithm PW-AC generic
AC algorithm employed DE, AC HVE (or GAC non-binary representation).
Example 4.2 Consider three constraints c1 , c2 , c3 part CSP, vars(c1 ) =
{x0 , x1 , x3 }, vars(c2 ) = {x2 , x3 , x4 }, vars(c3 ) = {x2 , x4 , x5 }. Assume point
domains variables DE problem shown Figure 5 (disregarding
original variables depicted dashed lines). Assume try enforce AC

x 2x 3x 4

x 0x 1x 3

vc1

0,0,0
0,1,0
0,1,3
1,0,1
1,0,2

vc2

0,0,0
0,1,1
0,2,1
0,3,1
1,1,0
1,2,0
1,3,0

x2

x 2x 4x 5

0,1
1,0,0
0,1,0

vc3

0,1
x4

Figure 5: Dual encoding non-binary CSP.
DE using algorithm AC-20015 . algorithm discover rst tuple D(vc2 )
support D(vc3 ) (there tuple x2 = 0 x4 = 0) delete it.
deletion, rst two tuples D(vc1 ) lose support D(vc2 )
AC-2001 must therefore look new supports. two tuples D(vc1 )
algorithm check 6 remaining tuples D(vc2 ) discovering
support. result two tuples deleted. Algorithm PW-AC,
hand, set counter group rst tuple D(vc2 ) belongs (according
partition S(vc2 , vc3 )) 0 deletes tuple. result call function
5. Note construct similar examples generic AC algorithm.

658

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

Revise automatic deletion rst two tuples D(vc1 ), saving total 2 6
checks.
consider HVE problem. Applying AC HVE eect
values 0 1 x2 x4 supported D(vc2 ) D(vc3 ). Therefore
propagation variables, result two tuples D(vc1 )
deleted. Similarly, propagation apply GAC non-binary
representation problem.
Note theoretical results regarding DE presented rest paper
hold AC-5 algorithm Van Hentenryck et al. (1992) adapted used DE
instead PW-AC. two algorithms similarities (e.g. use function
access group decomposition certain tuple belongs to, though implemented
dierently), basic operation dierent. algorithm Van Hentenryck et al.
(1992), instantiation AC-5, handles queue triples (vi , vj , a) implement
constraint propagation, vi vj two variables involved constraint
value removed D(vj ). PW-AC utilizes queue piecewise
decompositions. Also data structures used algorithms dierent. PW-AC
checks updates counters perform propagation which, explain below, requires
space exponential number common variables non-binary constraints.
algorithm Van Hentenryck et al. (1992) utilizes complicated data structure
requires space exponential arity non-binary constraints. noted,
however, PW-AC specically designed DE. is, operation, data
structures, way checks consistency based fact domains
dual variables consist tuples original constraints extensionally stored.
hand, algorithm Van Hentenryck et al. (1992) generic, sense
adapted operate piecewise functional constraint.
4.1.1 Complexities
PW-AC algorithm consists two phases. initialization phase set group
counters, main phase delete unsupported tuples propagate deletions.
analyze time complexity PW-AC. Note complexity analysis
measure operations, incrementing decrementing counter, since PW-AC
perform consistency checks usual sense.
Proposition 4.1 worst-case time complexity algorithm PW-AC O(e3 dk ).
Proof: assume constraint dual encoding, non-binary constraints corresponding two dual variables vi vj share f original variables
x1 , . . . , xf domain size d. means piecewise decomposition consists
df groups. Obviously, f equal k 1, k maximum arity
constraints. initialization phase lines 36 iterate constraints,
constraint variables vi vj , iterate tuples D(vi ).
done O(e2 dk ) asymptotic time complexity. Then, empty groups inserted
Q (lines 711). requires e2 df operations worst case. initialization,
function P ropagation called. group inserted Q (and later removed)
becomes empty. means loop P ropagation executed
659

fiSamaras & Stergiou

df times constraint, e2 df times total. also maximum
number times function Revise called (once every iteration loop). cost
function Revise computed follows: Assuming Revise called group sl (vi , vj ),
iterate (at most) dkf tuples group sup(sl (vi , vj )) (line 20). iteration
remove tuple (line 21) update counters groups belongs
(lines 2223). e groups (in case vj constrained dual
variables). Therefore, iteration costs O(e), result, call Revise costs
O(edkf ). Since Revise called e2 df times, complexity PW-AC, including
initialization step, O(e2 dk + e2 df + e2 df edkf )=O(e3 dk ). 2
Note PW-AC easily used incrementally search. case,
initialization phase executed once. asymptotic space complexity PWAC, AC algorithm binary encoding, dominated O(edk ) space need
store allowed tuples non-binary constraints. Algorithm PW-AC also requires
O(e2 df ) space store counters groups, O(e2 df ) space stack,
O(f e2 ) space fast implementation function GroupOf .

5. Algorithms Double Encoding
double encoding rarely used experiments binary encodings, although
combines features HVE DE, therefore may exploit advantages
worlds. precise, double encoding oers following interesting potential:
search algorithms deploy dynamic variable ordering heuristics assign values
original variables, constraint propagation implemented constraints
dual variables achieve higher pruning. section rst briey discuss
AC applied double encoding. show various search algorithms
adapted operate double encoding.
5.1 Arc Consistency
AC enforced double encoding using algorithm PW-AC addition
time value original variable xi loses supports adjacent dual
variable, deleted D(xi ). Alternatively, use generic AC algorithm,
AC-2001. Note AC algorithm applied double encoding enforce various
levels consistency depending constraints uses propagation dual
variables. is, propagation either done directly constraints
dual variables, indirectly constraints dual original variables.
example, use constraints dual original variables get
level consistency AC HVE. propagation dual variables
performed using constraints DE get level consistency AC
DE, dual variables, also prune domains original variables.
between, option use dierent constraints propagation dierent parts
problem. next example shows, AC double encoding achieve
high level consistency compared non-binary representation. Sections 6.2 6.3
show profound eect practice.
660

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

Example 5.1 Consider problem Figure 6. Applying AC constraint
two dual variables determine problem insoluble. However,
problem non-binary representation GAC, also singleton (generalized)
arc consistent (SGAC), high level consistency. CSP SGAC
applying GAC problem induced instantiation single variable,
domain wipeout (Debruyne & Bessiere, 2001; Prosser, Stergiou, & Walsh, 2000).

x1
x 0x 1x 2x 3

0
x0

0,1

0
x4

x 1x 2x 3x 4

x2
vc1

0, 0, 0, 0
0, 0, 1, 1
0, 1, 0, 1
0, 1, 1, 0

0,1

0, 0, 1, 0
0, 1, 0, 0
1, 0, 0, 0
1, 1, 1, 0

vc2

0,1
x3

Figure 6: Double encoding problem AC double encoding SGAC
non-binary representation.

5.2 Search Algorithms
Various search algorithms double encoding dened, depending variables
instantiated constraints used propagation. restrict
algorithms instantiate original variables perform propagation
using constraints dual variables. Intuitively interesting class
algorithms combine nice features non-binary representation
HVE (small domain sizes), DE (strong propagation).
rst show FC versions HVE discussed Section 3.2 adapted
yield algorithms run double encoding. call algorithms dFC0dFC5.
algorithm dFCi (i = 0, . . . , 5) instantiates original variables enforces AC
exactly set variables double encoding corresponding algorithm hFCi
HVE. example, dFC5 enforce AC set dual variables, original
variables connected them, dual variable connected least one past
original variable least one future original variable. dierence algorithm
dFCi (i = 2, . . . , 5) hFCi former exploit constraints dual
variables enforce higher level consistency latter. surprisingly,
results stronger algorithms.
Proposition 5.1 non-binary CSP, xed variable value ordering, algorithm dFCi (i= 2, . . . , 5) strictly stronger respective algorithm hFCi.
Proof: easy see value pruned hFCi HVE also
pruned dFCi double encoding. straightforward consequence
fact 1) double encoding subsumes HVE, 2) algorithms dFCi hFCi
enforce AC set variables. Algorithm dFCi strictly stronger hFCi
661

fiSamaras & Stergiou

because, exploiting constraints dual variables, prune values
hFCi. Consider, instance, problem two constraints c1 c2 , vars(c1 ) =
{x1 , x2 , x3 , x4 } vars(c2 ) = {x1 , x2 , x3 , x5 }. variables xi , = 1, . . . , 5, domains
{0, 1}. allowed tuples constraints rel(c1 ) = {(0, 0, 1, 0), (0, 1, 0, 1), (1, 1, 0, 1)}
rel(c2 ) = {(0, 0, 0, 0), (0, 1, 1, 1), (1, 0, 0, 0)}. x1 given value 0 HVE
algorithms hFC2hFC5 prune tuples (1, 1, 0, 1) (1, 0, 0, 0) domains dual
variables vc1 vc2 respectively. pruning performed. double
encoding, variable assignment, algorithms dFC2dFC5, cause
domain wipe-out two dual variables. 2
Corollary 5.1 non-binary CSP, xed variable value ordering, algorithm
dFCi (i= 2 . . . 5) strictly stronger respective algorithm nFCi (i=2 . . . 5).
Proof: Straightforward consequence Propositions 5.1 3.1. 2
easy see algorithm hFC0 (i.e. simple binary FC) equivalent dFC0.
holds algorithms hFC1 dFC1. various versions FC, MAC
algorithm adapted run double encoding original variables
instantiated, propagation implemented constraints dual
variables. easy see algorithm strictly stronger corresponding
algorithm HVE (the proof similar proof Proposition 5.1). interestingly, show MAC algorithm double encoding can, most,
polynomially greater cost corresponding MAC algorithm HVE, while,
hand, exponentially better.
Proposition 5.2 non-binary CSP, xed variable value ordering,
MAC algorithm hidden variable encoding instantiates original variables
exponentially greater cost corresponding MAC algorithm double
encoding.
Proof: prove this, use Example 14 paper Bacchus et al. (2002).
example CSP 4n + 2 variables, x1 , . . . , x4n+2 , domain
{1, . . . , n}, 2n + 1 constraints:
c1 : (x1 + x2 mod 2) = (x3 + x4 mod 2)
c2 : (x3 + x4 mod 2) = (x5 + x6 mod 2)
...
c2n : (x4n1 + x4n mod 2) = (x4n+1 + x4n+2 mod 2)
c2n+1 : (x4n+1 + x4n+2 mod 2) = (x1 + x2 mod 2)
Assume variables assigned lexicographic order double encoding. x1
x2 assigned values (x1 + x2 mod 2) = 0 enforcing AC prune
tuples D(vc1 ) (x3 + x4 mod 2) = 0. turn prune D(vc2 )
tuples (x5 + x6 mod 2) = 1. Continuing way, AC propagation prune
D(vc2n+1 ) values (x1 + x2 mod 2) = 0. deletions propagated
vc1 , D(vc1 ) become empty. similar way, enforcing AC assignments
662

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

x1 x2 , (x1 + x2 mod 2) = 1, leaves D(vc1 ) empty. Therefore, CSP
insoluble. MAC double encoding needs instantiate two variables discover this,
visit O(n2 ) nodes. hand, explained Bacchus et al. (2002), MAC
HVE needs visit O(nlog(n) ) nodes conclude problem insoluble. Finally,
note that, node, asymptotic costs MAC double encoding (using PWAC) MAC HVE polynomially related. Therefore, MAC HVE
exponentially worse MAC double encoding. 2
corollary Proposition 5.2 MAC double encoding exponentially smaller cost MGAC non-binary representation.
Proposition 5.3 non-binary CSP, xed variable value ordering,
MAC algorithm double encoding instantiates original variables
polynomially greater cost corresponding MAC algorithm hidden
variable encoding.
Proof: prove need show two things: 1) number node visits made
MAC double encoding polynomial factor greater number
node visits made MAC HVE, 2) node, worst-case cost MAC
double encoding polynomial factor greater worst-case cost AC
HVE. former true since MAC double encoding strictly stronger
MAC HVE. latter established considering worst case complexities
algorithms node. MAC HVE costs O(ekdk ) node, MAC
double encoding use PW-AC enforce AC, costs O(e3 dk ). Therefore,
polynomial dierence. 2
similar way, prove relationship Proposition 5.3 holds
algorithm dFCi (i= 2 . . . 5) corresponding algorithm hFCi. corollary Proposition 5.3 MAC double encoding polynomially greater cost
MGAC non-binary representation. important note Proposition 5.3
holds algorithm PW-AC used enforce AC double encoding. use
generic algorithm, like AC-2001, get exponential dierences favor MAC
HVE. Finally, regarding relationship node visits among algorithms
double encoding, following.
Proposition 5.4 Given double encoding CSP xed variable value ordering schemes, following relations hold:
1. nodes(dFC1) nodes(dFC0)
2. nodes(dFC2) nodes(dFC1)
3. nodes(dFC5) nodes(dFC3) nodes(dFC2)
4. nodes(dFC5) nodes(dFC4) nodes(dFC2)
5. nodes(dMAC) nodes(dFC5)
Proof: proof simple based comparing size subsets
problem algorithm enforces AC. 2
663

fiSamaras & Stergiou

6. Experimental Results
section make empirical study algorithms binary encodings. empirical
study organized two parts:
rst part (Subsections 6.1 6.2) evaluate improvements oered
specialized algorithms compared generic ones. time compare
eciency algorithms run binary encodings non-binary counterparts. comparison give us better understanding encoding
non-binary problem binary one pays o, encoding preferable.
empirical investigation use randomly generated problems, random problems
added structure, benchmark crossword puzzle generation problems. Random
problems allow us relate performance algorithms certain parameters,
tightness, constraint graph density, domain size. Crossword puzzles
standard benchmarks comparing binary non-binary constraint models, allow us evaluate performance algorithms problems include
constraints high arity.
second part (Subsection 6.3) , investigate usefulness binary encodings
realistic problem settings. study use problems domains
conguration frequency assignment compare performance MAC
algorithms run encodings MGAC algorithm non-binary representation.
algorithms implemented C. experiments run PC 3.06
GHz Pentium 4 processor 1 GB RAM. experiments, algorithms use
dom/deg heuristic (Bessiere & Regin, 1996b) dynamic variable ordering lexicographic value ordering.
6.0.1 Random Problems
Random instances generated using extended model B described Bessiere
et al. (2002). summarize generation method, random non-binary CSP dened
following input parameters:
n - number variables
- uniform domain size
k - uniform arity constraints
p - density (%) percentage generated graph, i.e. ratio existing constraints
number possible sets k variables
q - uniform looseness (%) percentage constraints, i.e. ratio allowed
tuples dk total tuples constraint
constraints allowed tuples generated following uniform distribution.
made sure generated graphs connected. following, class non-binary
664

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

CSPs denoted tuple form < n, d, k, p, q >. use star () case
one parameters varied. example, tuple < 50, 20, 3, 10, > stands
class problems 50 variables, domain size 20, arity 3, graph density 10%,
varying constraint looseness.
6.0.2 Crossword Puzzles
Crossword puzzle generation problems used evaluation algorithms
heuristics CSPs (Ginsberg, Frank, Halpin, & Torrance, 1990; Beacham, Chen, Sillito, &
van Beek, 2001) binary encodings non-binary problems (Bacchus & van Beek, 1998;
Stergiou & Walsh, 1999). crossword puzzle generation try construct puzzles
given number words given grid lled words. problem
represented either non-binary binary CSP straightforward way.
non-binary representation variable letter lled nonbinary constraint set k variables form word puzzle. domain
variable consists low case letters English alphabet giving domain
size 26. allowed tuples constraint words k letters
dictionary used. compared 26k possible combinations letters,
means constraints tight. DE variable word
length k puzzle possible values variable words k
letters dictionary. gives variables large domains (up 4072 values
Unix dictionary used experiments). binary constraints
variables intersect (i.e. common letter). HVE
original variables well set dual variables, one non-binary constraint.
6.1 Hidden Variable Encoding
rst empirical study investigated performance two MAC algorithms
operate HVE, compared MGAC-2001, counterpart nonbinary representation. two MAC algorithms HVE MHAC-2001,
stands MAC HVE instantiates original variables, MHAC-2001-f ull
MAC algorithm may instantiate variable (dual original) according
heuristic choice. stated names, three algorithms use AC-2001 (GAC-2001)
enforce AC. Although also run experiments various versions FC,
include results since algorithms inecient hard problems (especially hard
crossword puzzles). However, qualitative comparison FC-based algorithms
HVE non-binary representation similar comparison regarding MACbased algorithms.
6.1.1 Random Problems
Table 1 shows performance, measured cpu time, algorithms classes
randomly generated CSPs. classes hard phase transition region. Classes 1,
2, 3, 4 sparse, 5 dense. include results MHAC-2001-f ull
experiments showed algorithm similar behavior MHAC-2001.
reason that, nature constraints, dom/deg heuristic almost
665

fiSamaras & Stergiou

always selects original variables instantiation. rare cases heuristic
selected dual variables, resulted large increase cpu time.
class
MGAC-2001 MHAC-2001
1: < 30, 6, 3, 1.847, 50 >
2.08
1.90
2: < 75, 5, 3, 0.177, 41 >
4.09
3.41
3: < 50, 20, 3, 0.3, 5 >
64.15
28.10
4: < 50, 10, 5, 0.001, 0.5 >
74.72
22.53
5: < 20, 10, 3, 5, 40 >
5.75
8.15
Table 1: Comparison algorithms MGAC-2001 MHAC-2001 random classes
problems. Classes 1 2 taken paper Bessiere et al. (2002). give
average run times (in seconds) 100 instances class. winning
time instance given bold. follow rest paper.

Table 1 see MHAC-2001 performs better MGAC-2001
sparse problems. general, 3-ary classes tried density less 3% 4%
relative run time performance MHAC-2001 compared MGAC-2001 ranged
equal around 2-3 times faster. sparse class 4, includes
problems 5-ary constraints, MHAC-2001 considerably ecient MGAC2001. due fact sparse problems relatively large domain sizes
hard region located low constraint looseness (i.e. small domains dual variables)
operations required revision dual variables. Another factor
contributing dominance binary algorithm class 4 larger arity
constraints. non-binary algorithm requires operations check validity
tuples tuples large arity, explained Section 3.1.
density graph increases (class 5), overhead revising domains
dual variables restoring failed instantiations slows MHAC-2001,
result outperformed MGAC-2001. denser classes ones reported,
phase transition region point half tuples allowed,
cases non-binary algorithm performs even better.
6.1.2 Crossword Puzzles
Table 2 demonstrates performance search algorithms various crossword puzzles.
used benchmark puzzles papers Ginsberg et al. (1990) Beacham et al.
(2001). Four puzzles (15.06, 15.10, 19.03, 19.04) could solved algorithms
within 2 hours cpu time. Also, two puzzles (19.05 19.10) arc inconsistent.
cases GAC discovered inconsistency slower AC HVE (around 3:1 time
dierence 19.05 10:1 19.10) latter method discovered early domain
wipe-out dual variable.
rest puzzles observe MHAC-2001 performs better MGAC2001 hard instances. hard insoluble puzzles MHAC-2001 3 times
faster MGAC-2001. mainly due large arity constraints
666

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

puzzle
15.02
15.04*
15.07
19.02
19.08
66
77*
88*
1010*

n
80
76
74
118
134
12
14
16
20

e MGAC-2001 MHAC-2001 MHAC-2001-f ull
191
3.70
3.58

193
40.84
38.88
29.75
193
94.65
46.36
44m
296
34.62
35.08

291


5.45
36
9.39
5.07
5.49
49
14m
8m
12m
64
6m
2m
5m
100
11.81
11.85
15.39

Table 2: Comparison (in cpu time) algorithms HVE algorithms
non-binary representation crossword puzzles. n number words e
number blanks. times seconds except followed
(minutes). dash () placed wherever algorithm manage nd
solution within 2 hours cpu time. Problems marked (*) insoluble.
include problems reasonably hard least one algorithm
time solvable within 2 hours least one algorithm.

classes6 . Another interesting observation signicant dierences
performance methods may instantiate dual variables instantiate
original ones. many cases MAC-2001-f ull managed nd (dierent) solution
MHAC-2001 MGAC-2001 earlier. hand, MAC-2001-f ull subject
thrashing instances methods terminate. fact insoluble
puzzles MAC-2001-f ull better MHAC-2001 shows performance
largely dependent variable ordering scheme. many cases MAC-2001-f ull visited
less nodes MHAC-2001. However, reected similar time performance
dierence dual variable instantiated MAC-2001-f ull work
original one instantiated. instantiate automatically original
variable xi constrained dual variable propagate changes dual
variables containing xi .
6.2 Dual Double Encodings
empirical study investigated performance algorithms DE double
encoding. tried answer following three questions: 1) ecient specialized
algorithms compared generic algorithms? 2) use specialized algorithm
make DE eective option solving non-binary CSPs? 3) take advantage
theoretical properties double encoding practice? answer questions,
run experiments random structured problems evaluate benets oered
specialized algorithm PW-AC maintaining AC search. compared
6. Puzzles 66-1010 correspond square grids blank squares.

667

fiSamaras & Stergiou

performance two MAC algorithms; one uses AC-2001 enforce AC (MAC2001), another uses PW-AC enforce AC (MAC-PW-AC). also compared
algorithms algorithm maintains GAC non-binary representation
using GAC-2001 (MGAC-2001), MAC algorithms maintain AC double
encoding using PW-AC (algorithm MAC-PW-ACd) AC-2001 (algorithm MAC-2001d).
6.2.1 Random Problems
rst give indicative results comparison various algorithms using
random problems. Figure 7 compares time required enforce AC DE
GAC non-binary representation, Figures 8-10 compare algorithms
maintain consistencies.
Figure 7 shows average cpu times (in msecs) PW-AC AC-2001 take
enforce AC DE 100 random CSPs 50 variables domain size 30, ternary
constraints, 0.3 graph density (58 constraints). also include average time GAC2001 takes enforce GAC non-binary representation generated instances.
looseness constraints varied starting point instances GAC
GAC AC DE delete values. signicant dierence
performance PW-AC compared AC-2001 constantly rises looseness
constraints becomes higher. expected, since number allowed tuples
constraint grows, AC-2001 takes time nd supports. GAC-2001 faster
PW-AC (up one order magnitude) looseness low, dierence
becomes smaller looseness grows.
Figure 8 shows cpu times relatively sparse class problems 30 variables
40 ternary constraints (p = 1). Figure 9 shows cpu times node visits denser class
30 variables 203 ternary constraints (p = 5). Along x-axis vary domain
size variables. data points show average cpu times (in secs) 100 instances
taken hard phase transition region.
make following observations: 1) MAC-PW-AC MAC-PW-ACd signicantly faster (one order magnitude) MAC-2001 MAC-2001d, respectively,
classes problems. 2) classes, non-binary representation preferable DE (MGAC-2001 two orders magnitude faster denser class).
sparser class, MAC double encoding (i.e. algorithm MAC-PW-ACd) competitive
MGAC-2001 small domain sizes, considerably faster larger domain sizes.
eect domain size relative performance algorithms mainly due
run time advantage PW-AC compared GAC-2001, higher consistency
level achieved double encoding7 . run time advantage PW-AC explained
considering that, domain size increases, GAC-2001 check increasing number
tuples supports; operation costly counter updates PW-AC.
denser class MGAC-2001 constantly faster algorithms domain
sizes. surprising considering O(e3 dk ) O(ekdk ) complexities PW-AC
GAC-2001 (i.e. factor e becomes signicant).
Figure 10 compare algorithms MGAC-2001 MAC-PW-ACd (the faster among
algorithms encodings) class problems 20 variables 48 4-ary
7. verified looking node visits two algorithms.

668

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

10000

10000
cpu time (secs)

1000
cpu time (msecs)

100000

AC-2001
PW-AC
GAC-2001

100

10

1

1000
100
10
1

0.1

0.1
0

0.005

0.01

0.015
q

0.02

0.025

0.03

0

100000

10

15

20

25

Figure 8: < 30, , 3, 1, > CSPs.
100000

MAC-2001
MAC-AC2001d
MAC-PW-AC
MAC-PW-ACd
MGAC-2001

MGAC-2001
MAC-PW-ACd

10000
cpu time (secs)

10000

5



Figure 7: < 50, 30, 3, 0.3, > CSPs.

cpu time (secs)

MAC-2001
MAC-2001d
MAC-PW-AC
MGAC-2001
MAC-PW-ACd

1000
100
10

1000

100

10

1
0.1

1
0

5

10


15

20

0

5

10

15

20

25



Figure 9: < 30, , 3, 5, > CSPs.

Figure 10: < 20, , 4, 1, > CSPs.

constraints. algorithms encodings competitive class
problems. see MGAC-2001 ecient small domain sizes,
larger domain sizes MAC-PW-ACd one order magnitude faster. However,
denser classes problems results reversed.
experiments random problems conjecture double encoding
preferred model sparse problems, provided ecient algorithm like
PW-AC used propagation. CSPs medium high density non-binary
representation preferable encodings.
Random Problems Added Structure experiments ternary CSPs
detect advantage DE compared non-binary representation
(and consequently HVE). MAC DE rarely better MGAC-2001 (only
cases tight constraints large domain sizes), despite use PW-AC
propagation. Also, MAC-PW-ACd competitive often faster MGAC2001 sparse random problems, result reversed density increases. basic
reason results randomly generated problems (especially ones ternary
constraints) get many pairs non-binary constraints share one original
variable. known (see Bacchus et al., 2002 example) pair
constraints, ltering achieved AC DE ltering achieved
GAC non-binary representation (and AC HVE). Therefore, AC DE
looses much ltering power.
669

fiSamaras & Stergiou

validate conjecture, experimented generation model structure
added purely random problems. precise, experimented problems
clique variables embedded randomly generated instance. ternary problems
two constraints clique may share one two variables. decided random.
4-ary problems two constraints clique may share one, two, three variables.
Again, decided random. Table 3 compares performance various MAC
algorithms < 30, 10, 3, 5, > < 20, 10, 4, 1, > problems type. second
class include results MAC-PW-ACd, far best algorithm
problems, MGAC-2001.
arity clique size MGAC-2001 MAC-2001 MAC-PW-AC MAC-2001d MAC-PW-ACd
3
0
633.50
45303.76
9205.95
7549.61
1362.31
3
10
874.07
21007.45
5349.55
3078.45
421.07
3
20
1121.39
1932.49
389.22
392.08
65.81
3
30
1598.87
374.03
48.22
102.30
5.02
4
0
90.11
106.04
4
10
247.18
61.12
4
20
8348.92
322.86
Table 3: Average cpu times MAC algorithms DE double encoding
MGAC non-binary representation random problems embedded
cliques. times seconds. number gives average 50 instances
around phase transition region.
see, comparative results algorithms vary according size
embedded clique. clique embedded (clique size=0) MGAC-2001
faster algorithms binary encodings. clique size grows, binary
encodings, especially double, become ecient. double encoding
eective DE clique sizes. large clique covers variables, MAC
double encoding many orders magnitude faster MGAC-2001. huge
dierence caused presence many constraints share one variable
non-binary representation. cases ltering constraints dual
variables strong. However, much advantage lost generic algorithms
used encodings. Similar results occur denser problems generation
model used.
6.2.2 Crossword Puzzles
Table 4 compares cpu times two MAC algorithms DE MGAC
non-binary representation using various benchmark crossword puzzles. include
results MAC double encoding since particular representation crossword
puzzle generation problems impractical. reason pair dual
variables involved constraint, two variables one original variable
common (i.e. letter two words intersect). explained previously,
670

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

degrades ltering achieved constraints dual variables. constraints
double encoding redundant since ltering achieved
constraints dual original variables.

puzzle
15.02
15.04*
15.07
15.09
19.01
19.02
19.08
21.02
21.03
21.08
21.09
66
77*
88*
99*
1010*

n
80
76
74
82
128
118
134
130
130
150
144
12
14
16
18
20

e MGAC-2001 MAC-2001 MAC-PW-AC
191
3.98
164.04
13.70
193
40.84
895.29
140.65
193
94.65


187
0.43


301
1.50


296
34.62

1028.17
291

33.01
7.76
295
2.29
77.51
11.82
295
345.96
273.87
40.57
365


9.96
366


8.87
36
9.39
98.49
6.04
49
14m

12m
64
6m

9m
81


128.92
100
11.81
474.54
22.78

Table 4: Comparison (in cpu time) MAC algorithms DE MGAC
non-binary representation crossword puzzles. times seconds except
followed (minutes). cpu limit 2 hours. Problems marked
(*) insoluble. include problems reasonably hard either
MGAC-2001 MAC-PW-AC time solvable within 2 hours
least one algorithm.

data Table 4 clearly see MAC-PW-AC signicantly faster
MAC-2001 instances. speedup oered use PW-AC makes MAC
DE competitive MGAC many cases using generic algorithm
DE results clear advantage favor MGAC. Also, instances (e.g. puzzles
21.03, 21.08, 21.09), use PW-AC makes MAC DE considerably faster
MGAC. However, still instances MGAC (and consequently MHAC)
nds solution (or proves insolubility) fast, MAC DE thrashes, vice versa.
Note, 4 10 hard 2121 puzzles tried solved
algorithm within time limit two hours. MAC-PW-AC managed solve 4
instances relatively fast, two algorithms solved 2 within
cpu limit.
671

fiSamaras & Stergiou

6.3 Experiments Realistic Problems
next sections present experimental results conguration frequency assignment problems. aim experiments investigate usefulness binary
encodings realistic structured domains. focus dual double encodings
promising binary encodings strong propagation oer.
6.3.1 Configuration
Conguration area CSP technology particularly eective. conguration problem viewed trying specify product dened set attributes,
attribute values combined predened ways. problems
modelled CSPs, variables correspond attributes, domains variables
correspond possible values attributes, constraints specify predened
ways values combined. many conguration problems constraints
expressed extensionally lists allowed (or disallowed) combinations values. Alternatively, constraints expressed rules easily transformed
extensional representation. Consider following example adapted paper
Subbarayan, Jensen, Hadzic, Andersen, Hulgaard & Moller (2004).
Example 6.1 conguration T-shirt requires specify size (small,
medium, large), print (Men Black - MIB Save Whales - STW),
color (black, white, red). following constraints: 1) small size chosen
STW print cannot selected. 2) MIB print chosen black color
chosen well, STW print chosen black color cannot selected.
conguration problem modelled CSP three variables {x1 , x2 , x3 } representing size, print, color respectively. domains variables D(x1 ) =
{small, medium, large}, D(x2 ) = {M IB, ST W }, D(x3 ) = {black, white, red}.
rst constraint binary constraint variables x1 x2 following allowed
tuples: {< small, IB >, < medium, IB >, < medium, ST W >, < large, IB >, <
large, ST W >}. second constraint binary constraint variables x2 x3
following allowed tuples: {< IB, black >, < ST W, white >, < ST W, red >}.
practice, many solvers conguration problems able interact user
that, apart meeting given specications, users choices values certain
attributes also satised. study use conguration instances compare
non-binary representation binary encodings structured realistic problems. Although
would interesting investigate applicability binary encodings interactive
congurator, work outside scope paper.
run experiments problems taken CLib, library benchmark conguration problems (CLib, 2005). rst thing noticed encoding problems
binary non-binary CSPs trivially solvable algorithms without
backtracking. closer look structure CLibss problems revealed reason;
constraint graphs consist various unconnected components. component consists
or, cases, single variable. result, problems split independent subproblems trivially solved algorithms. order obtain dicult
instances benchmarking, made graphs connected adding randomness.
672

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

problems extended adding 6 variables 8-10 constraints
graph became connected8 . Table 5 shows total number variables
constraints modied problems. added constraints arity 2, 3, 4 (chosen
random) variables posted selected random, making
sure resulting graph connected. looseness added constraint
also set random, nally, allowed tuples constraint chosen random
according looseness.

problem n

e arity dom

machine
fx
fs
esvs
bike

22
21
18
20
28

30
24
29
33
43

4
5
6
5
6

9
44
51
61
37

MGAC-2001
MAC-PW-AC MAC-PW-ACd
nodes - time
nodes - time
nodes - time
535874 - 13.83
813 - 0.37
3367 - 1.64
193372 - 4.10
92 - 0.01
70 - 0.01
618654 - 30.43
41 - 0.03
193 - 0.05
9960160 - 332.52
7384 - 3.09
64263 - 29.86
21098334 - 501.85 16890 - 12.23 112957 - 87.77

Table 5: Comparison algorithms conguration problems. arity dom
maximum constraint arity maximum domain size problem. Run times
given seconds.

Table 5 gives average run times node visits algorithms MGAC-2001
non-binary representation, MAC-PW-AC DE, MAC-PW-ACd double
encoding. benchmarks repeatedly generated instances using
model described above. generated instance solved three algorithms
stored instance hard least one algorithm. Otherwise, discarded.
instance considered hard least one algorithm took one second
solve it. Table 5 reports averages rst 50 hard instances generated
benchmark. is, run 250 hard instances total. Note binary encodings
constraints original problem (even binary ones) encoded dual variables.
experimental results Table 5 show signicant advantage favor
binary encodings compared non-binary representation, node visits run
times. DE clearly ecient model. MAC-PW-AC DE
three orders magnitude faster MGAC-2001 non-binary representation.
single instance among 250 instances MGAC-2001 faster
MAC-PW-AC. double encoding also much ecient non-binary
representation. main factor contributing performance encodings
strong propagation achieved constraints dual variables,
reected numbers node visits. number reasons, related
structure conguration problems, justify strong performance
encodings:
8. Experiments showed minimum additions need made order get hard
problems without altering structure problems much.

673

fiSamaras & Stergiou

constraint graphs sparse. typical conguration problems since,
usually, attribute product specication dependencies
attributes.
constraints high arity tight. Moreover, value variables
large domain sizes (typically one) supporting tuple constraints
variables participate.
intersecting non-binary constraints one original variable
common. explained, demonstrated empirically Section 6.2,
signicant impact propagation power AC dual double encodings.
Note prole conguration problems, analyzed above, agrees conjectures made based results random problems. is, dual double
encodings suitable sparse problems tight constraints, intersecting constraints may share one variable.
6.3.2 Frequency Assignment
Frequency assignment important problem radiocommunication industry.
problem radio communications network given region consisting
set transmitters. transmitter position region, frequency spectrum,
certain power, directional distribution. aim assign values
properties transmitters certain criteria satised. various
types frequency assignment problems. study consider version radio
link frequency assignment problem (RLFA). problem given set links
{L1 , . . . , Ln }, consisting transmitter receiver. link must assigned
frequency given set F . time total interference receivers must
reduced acceptable level using frequencies possible. problems
typically optimization problems purposes study treat
satisfaction problems.
RLFA problem modelled CSP transmitter corresponds
variable. domain variable consists frequencies assigned
corresponding transmitter. interferences transmitters modelled
binary constraints form |xi xj | > s, xi xj variables 0
required frequency separation. constraint restricts frequencies two
transmitters simultaneously assigned, way interference
minimized. realistic assumption closer two frequencies
greater interference them. binary model used extensively
represent RLFA problems, numerous solution methods (CSP-based other)
proposed. Also, RLFA widely used benchmark test new algorithms
binary constraints (mainly AC algorithms).
argued standard binary model frequency assignment problems
fails capture important aspects real problems, multiple interferences,
resulting non-optimal frequency assignments (Jeavons, Dunkin, & Bater, 1998; Watkins,
Hurley, & Smith, 1998; Bater, 2000; Hodge, Hurley, & Smith, 2002). consequence,
eorts introduce expressive methods utilize non-binary
674

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

constraints frequency assignment (e.g. Bater, 2000; Hodge et al., 2002). many
types non-binary constraints considered. following ones received
attention:
co-channel constraints - e.g., frequencies assigned n transmitters equal.
adjacent-channel constraints - e.g., frequencies assigned n transmitters
least one frequency apart.
separation constraints - e.g., frequencies assigned n transmitters least
frequencies apart.
Obviously, separation constraints generalize adjacent-channel constraints. rst
two types constraints typically loose third tight. Separation
constraints used densely constrained areas (representing conurbations region)
large number links closely situated. cases, large separations
frequencies transmitters must imposed, resulting tight constraints.
also consider richer type separation constraints: frequencies assigned set n
transmitters least frequencies apart n transmitters among least
(> s) frequencies apart others. Note non-binary constraints
equivalently decomposed clique binary constraints (without introducing
dual variables) resulting however weaker propagation. example adjacent-channel
constraints. Others cannot equivalently expressed set binary constraints unless
binary encoding used. example, co-channel constraints. noted Hodge et al.
(2002), non-binary constraints low arity utilized practice.
shown many cases constraints sucient achieve low interferences.
Constraints higher arity may oer improvements quality solutions, tend
slow solution process extend solving large real problems becomes
infeasible.
empirical study presented interested comparing models RLFAtype problems non-binary constraints corresponding binary encodings
devising new ecient methods solving RLFA problems. Since available RLFA
benchmarks follow standard binary approach, test algorithms generated nonbinary problems placing variables, corresponding links, grid following typical
RLFA structure. is, problems consist several groups closely situated variables
plus constraints connect groups. example, structures depicted
Figure 11. corresponds constraint graph binary RLFA problem
typically consists set cliques (or near-cliques) binary constraints small number
constraints connecting various cliques (e.g. benchmarks Cabon, De Givry,
Lobjois, Schiex, & Warners, 1999). binary encodings considered
double since dual variables large domains, makes DE inecient.
Indicative results experiments run depicted Table 6. experiments
posted low-arity (i.e. 3-ary 5-ary) separation constraints, shown Figure 11,
compared performance algorithm MGAC-2001 non-binary model
problems performance MAC-PW-ACd double encoding problems.
tried two implementations MGAC-2001; one utilizes specialized propagators
675

fiSamaras & Stergiou

a) prob1

b) prob2

c) prob3

Figure 11: Examples RLFA problems non-binary separation constraints.

separation constraints (written functions), another operates extensional
representation constraints. rst implementation generally faster,
results MGAC-2001 presented refer intentional implementation. double
encoding built translating separation constraints lists allowed tuples
preprocessing step.

problem
prob1
prob1
prob1
prob2
prob2
prob2
prob3
prob3
prob3
prob4
prob4
prob4
prob5
prob5
prob5

(easiest)
(median)
(hardest)
(easiest)
(median)
(hardest)
(easiest)
(median)
(hardest)
(easiest)
(median)
(hardest)
(easiest)
(median)
(hardest)

n
48
48
48
44
44
44
54
54
54
68
68
68
100
100
100

e arity
25
25
25
21
21
21
24
24
24
38
38
38
58
58
58

4
4
4
4
4
4
5
5
5
5
5
5
5
5
5

MGAC-2001
MAC-PW-ACd
nodes - time
nodes - time
583 - 1.51
48 - 0.36
18161268 - 39518.71
50 - 0.34


56474 - 26.46
172071 - 219.06
304676 - 169.01
305588 - 504.06
53654514 - 4220.21 68771412 - 24133.45
103 - 13.45
0 - 6.42
2134 - 14.14
2569 - 53.18
4194 - 115.12
0 - 5.64
70 - 1.21
72 - 7.24

90 - 8.34


294 - 5.29
0 - 2.42
96106 - 522.64
99 - 2.81

104 - 13.45

Table 6: Comparison algorithms RLFA problems separation constraints. arity
maximum constraint arity. Run times given seconds. dash ()
placed wherever algorithm nish run within 12 hours cpu time.

676

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

Table 6 reports results total 50 instances created using dierent constraint
graph topologies. variables domains 20 25 values. number allowed
tuples constraints varied around 50 tight constraints several thousands looser ones, according frequency separation imposed parameters
separation constraints. parameters set random constraint,
making sure loose constraints generated. example, 4-ary basic
separation constraint variables domain size 20, least 3 (giving 7920 allowed
tuples) 5 (giving 120 allowed tuples).
prob1, prob2, prob3 refer problems topologies shown Figure 11.
prob4 consists three groups variables, similar ones prob3, arranged
chain-like structure. Finally, instances prob5 consist randomly generated groups
variables; one 8-10 variables 3-5 3-ary 5-ary constraints. groups
interconnected according topological distance (i.e. constraints posted
variables nearby groups). instances prob1-prob4 xed topology.
topology set instances created changing type constraints. example,
two instances topology prob1 may dier type separation constraints
(basic richer) include. Also, frequency separations imposed
constraint may dier. Instances prob5 may also dier constraint graph topology.
report node visits run times easiest, median, hardest instance
topology, respect performance MGAC9 . hardest instances
encoding non-binary representation (except prob3), easiest
median instances sometimes dierent.
Table 6 see substantial dierences favor
double encoding. Many instances solvable double encoding
little backtracking MGAC-2001 thrashed. mainly due large number
interleaved constraints sharing one variable, boosts propagation
double encoding. performance algorithms seems heavily dependent
topology problems. example, instances prob2 non-binary representation
much ecient double encoding. seems particular class
problems heuristic choices misled propagation achieved double encoding.
able come satisfactory explanation occurred
particular topology.
Finally, investigate eect presence loose constraints higher arity
has, run experiments 8-ary adjacent-channel constraints posted
variables apart graph, addition separation constraints.
case using double encoding model constraints problems infeasible
due spatial requirements. example, trying generate allowed tuples
single 8-ary adjacent-channel constraint consumed memory system. Therefore,
compared algorithm MGAC-2001 non-binary model MAC algorithm
runs hybrid model tight separation constraints modelled using
double encoding loose adjacent-channel constraints kept intentional nonbinary representation. Table 7 reports results total 30 instances created using
9. create instances varied type constraints values parameters
non-trivial problems generated. consider trivial problems arc inconsistent solvable
backtracking.

677

fiSamaras & Stergiou

problem
prob1
prob1
prob1
prob2
prob2
prob2
prob5
prob5
prob5

(easiest)
(median)
(hardest)
(easiest)
(median)
(hardest)
(easiest)
(median)
(hardest)

n
48
48
48
44
44
44
100
100
100

e arity
25
25
25
21
21
21
58
58
58

8
8
8
8
8
8
8
8
8

MGAC-2001
MAC-hybrid
nodes - time
nodes - time
106 - 20.88
50 - 47.60
5078 - 1201.98
84 - 195.43


647 - 192.64
1019 - 308.84
80245 - 17690.12



76 - 45.92
0 - 22.19
22785 - 3230.47
99 - 78.41

18447 - 4233.50

Table 7: Comparison algorithms RLFA problems separation adjacentchannel constraints. MAC-hybrid corresponds MAC algorithm runs
hybrid model.

graph topologies prob1, prob2 prob5 addition four 8-ary adjacent-channel
constraints instance. hybrid model ecient instances prob1
prob5 strong propagation achieved binary encoding tight
constraints. non-binary model better instances prob2 seems
propagation binary encoding results bad heuristic choices.
6.4 Discussion
section summarize results experimental studies draw conclusions regarding applicability encodings, based theoretical experimental
analysis.
Hidden Variable Encoding theoretical results suggested, empirical results conrmed, solving problems HVE using algorithms instantiate original variables
essentially analogous solving non-binary representation directly. commonly
used algorithms non-binary problems applied, adjustments, HVE,
vice versa. algorithms used, HVE oers (moderate) computational
savings compared non-binary representation, especially sparse problems.
savings due ability AC algorithm HVE detect inconsistencies earlier corresponding GAC algorithm non-binary representation. Therefore,
conjecture HVE applicable sparse non-binary problems constraints
extensionally specied. cases, HVE either less ecient run times
non-binary representation (e.g. dense problems), building HVE adds space
overheads justied marginal gains search eort. Additionally,
enough empirical evidence suggest essential dierence search
algorithms HVE non-binary representation, i.e. ability former
branch dual variables, make HVE signicantly ecient class
678

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

problems. This, coupled fact benets gained instantiating dual
variables maximized double encoding used instead HVE, limits
applicability algorithms.
Dual Double Encodings DE double encoding advantage
strong ltering constraints dual variables. showed
advantage exploited low cost specialized algorithm, PW-AC, make
DE competitive often signicantly better non-binary representation
several sparse CSPs, crossword puzzle generation conguration problems.
dense CSPs, DE pay either spatial requirements make use
infeasible, case, advantages oered outweighed overhead
updating domains dual variables. holds CSPs containing constraints
large arity unless tight (as crossword puzzles).
Algorithms double encoding demonstrate especially promising performance.
many non-binary constraints share one variable present
problem MAC double encoding exploit benets variable
ordering heuristic, borrowed non-binary representation, stronger ltering,
borrowed DE, outperform representations. demonstrated
problems structure (random also frequency assignment - like). also
case still-life problem, explains success double encoding10 .
addition, double encoding oers interesting potential hybrid models certain
constraints encoded binary others kept non-binary representation
based certain properties constraints. precise benet encoding
constraints either naturally specied extension, relatively low arity
tight. demonstrated various domains. notably, frequency assignment problems double encoding (or hybrid one) payed cases,
although constraints problems naturally dened intentionally.

7. Related Work
Although, DE proposed 1989 (Dechter & Pearl, 1989) HVE 1990 (Rossi
et al., 1990), rst substantial eort towards evaluating eciency carried
1998 (Bacchus & van Beek, 1998). work, Bacchus van Beek compared theoretically empirically FC algorithm two encodings FC non-binary
CSPs. Also, introduced FC+, specialized algorithm HVE. algorithms
compared Bacchus van Beek simplest versions FC; hFC0 hFC1 (i.e.
FC+) HVE, nFC0 non-binary representation. extend work
studying various recent advanced versions FC.
Following Bacchus van Beek (1998), Stergiou Walsh made theoretical
empirical study AC encodings (Stergiou & Walsh, 1999). proved AC
HVE equivalent GAC non-binary representation, AC DE
stronger. small experimental study included paper Stergiou & Walsh (1999),
MAC HVE, DE, double encoding compared MGAC non-binary
10. Although title Smiths paper (2002) refers DE, model still-life problem used
based double encoding.

679

fiSamaras & Stergiou

representation crossword puzzles Golomb rulers problems. Results showed
advantage non-binary representation HVE, important note
MAC algorithms used generic inecient algorithms enforce AC.
Smith, Stergiou & Walsh (2000) performed extensive experimental comparison
MAC HVE double encoding, MGAC non-binary model
Golomb rulers problem. However, MAC algorithms encodings used generic
algorithm enforce AC. result outperformed MGAC non-binary
model.
Beacham et al. (2001) compared performances dierent models, heuristics,
algorithms CSPs using crossword puzzle generation problems benchmarks. Among
models compared HVE, DE non-binary representation.
again, algorithms applied encodings generic algorithms.
example, two implemented algorithms DE MAC uses AC-3
propagation MAC uses AC-7. algorithms suer high complexity AC propagation. demonstrated, use algorithm PW-AC propagation
signicantly enhance performance MAC crossword puzzle problems.
Bacchus et al. (2002) presented extensive theoretical study DE HVE.
Among results, polynomial bounds placed relative performance FC
MAC two encodings non-binary representation, shown
polynomial bound exists. example, shown FC HVE (i.e. hFC0
terminology use) never polynomial factor worse FC DE,
FC DE exponentially worse FC HVE. Also, FC non-binary
representation (i.e. nFC0 terminology use) exponentially worse FC
HVE, vice versa. add results analyzing performance various
advanced algorithms HVE double encoding.
Smith modelled problem nding maximum density stable pattern still-life
Conways game Life using MAC double encoding remarkable success,
compared constraint programming integer programming approaches (Smith,
2002). MAC algorithm implemented using Table constraint ILOG Solver.
constraint implements generic AC algorithm Bessiere & Regin (1996a),
expensive used DE high time complexity. believe
results presented Smith improved MAC-PW-AC used instead.

8. Conclusion
paper studied three binary translations non-binary CSPs; hidden variable
encoding, dual encoding, double encoding. showed common perception standard algorithms binary CSPs used encodings non-binary
CSPs suers aws. Namely, standard algorithms exploit structure encodings, end inecient. address problem, proposed specialized arc
consistency search algorithms encodings, evaluated theoretically
empirically. showed arc consistency enforced hidden variable
encoding non-binary CSP worst-case time complexity generalized arc
consistency non-binary representation. showed structure constraints
dual encoding exploited achieve much lower time complexity
680

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

generic algorithm. Empirical results demonstrated use specialized algorithm
makes dual encoding signicantly ecient. showed generalized search
algorithms non-binary CSPs relatively easily adjusted operate hidden
variable encoding. also showed various algorithms double encoding
designed. algorithms exploit properties double encoding (strong ltering branching original variables) achieve good results certain problems.
Empirical results random structured problems showed that, certain classes
non-binary constraints, using binary encodings competitive option, many cases,
better one solving non-binary representation.

Acknowledgements
would like thank Panagiotis Karagiannis, Nikos Mamoulis, Toby Walsh
help various stages work. would also like thank anonymous reviewers
earlier version paper useful comments suggestions.

Appendix
explained, main dierence AC algorithm HVE corresponding GAC algorithm fact AC algorithm update domains
dual variables well original ones. incurs time overhead,
show, deleting values dual variables help propagation discover domain wipe-outs
arc inconsistent problems faster.
Proposition 8.1 Let P non-binary CSP. Assume generalized arc consistency applied P , domain wipeout resulting problem. Enforcing arc
consistency hidden variable encoding P using HAC requires number
consistency checks enforcing generalized arc consistency P using GAC-2001, assuming two algorithms follow ordering variables values looking
supports propagating deletions.
Proof: First, consider domain wipeout variable (original dual) occurs
two algorithms add constraints (dual variables) stack remove
revision exactly order. Therefore, need show
value deleted variable revision constraint nds new support
constraint operations require number checks
representations. Assume non-binary version algorithm value deleted
domain variable xi support constraint c. |T |
number allowed tuples c determining lack support require |T |
currentSupportxi,a,c checks, one tuples c checked yet.
value deleted nds new support , > currentSupportxi,a,c ,
currentSupportxi,a,c checks performed. HVE, xi processed
order non-binary version require |T | currentSupportxi,a,vc
currentSupportxi,a,vc checks depending case. Obviously, currentSupportxi ,a,c
currentSupportxi ,a,vc since tuple c corresponds value vc ,
therefore, number checks performed representations. 2
681

fiSamaras & Stergiou

Proposition 8.2 Let P non-binary CSP. Assume application generalized
arc consistency P results domain wipeout. Algorithm HAC applied hidden
variable encoding P discovers domain wipeout number
consistency checks algorithm GAC-2001 non-binary representation, assuming
two algorithms follow ordering variables values looking supports
propagating deletions.
Proof: CSP, arc inconsistency detected domain variable wiped
applying AC. HVE non-binary CSP, arc inconsistency detected
domain original variable wiped (crucially) domain dual
variable wiped out. second possibility make AC algorithm operates
HVE ecient corresponding GAC algorithm. prove consider
arc inconsistent non-binary problem. Assume domain original variable xi
wiped processing constraint c encoded dual variable vc
HVE. point function Revise called xi c arguments,
inconsistency according Proposition 8.1 GAC algorithm
AC algorithm HVE perform number consistency checks. Assume
j values left D(xi ) call Revise. function Revise
unsuccessfully look support j values. |T | number allowed
tuples c then, value D(xi ), require |T | currentSupportxi,a,c checks
GAC algorithm |T | currentSupportxi ,a,vc checks AC algorithm. Since
|T | currentSupportxi ,a,c = |T | currentSupportxi,a,vc , two algorithms perform
number consistency checks detect domain wipeout.
following example demonstrates HAC may discover inconsistency less
checks. Consider problem variables x1 , x2 , x3 , x4 domains {0, 1}, {0, 1},
{0, . . . , 9}, {0, 1}, respectively. two constraints, c1 c2 , vars(c1 ) =
{x1 , x2 , x3 } vars(c2 ) = {x1 , x2 , x4 } respectively. Value 0 x2 supported c1
tuples include assignment (x1 , 1). Value 0 x1 supported c2 tuples
include assignment (x2 , 0). Constraint c2 allows tuples include assignment
(x2 , 0). Values 0, . . . , 9 x3 supported c1 tuples include (x2 , 0) tuples
include (x2 , 1). assume variable x1 instantiated 0, means
deletion 1 D(x1 ) must propagated. HVE, rst delete
tuples include value (x1 , 1) dual variables vc1 vc2 . Then, add dual
variables vc1 vc2 stack, remove them, revise original variables connected
them. Assuming vc1 removed rst, value 0 x2 support vc1
deleted. result, delete tuples dual variable vc2 include
pair (x2 , 0). means domain vc2 wiped out. non-binary
representation, proceed similar way perform number checks
0 deleted x2 . deletion algorithm look supports c1
value 1 x2 values x3 . involve checks avoided HVE.
inconsistency discovered later process constraint c2 nd
value 1 x2 support c2 resulting domain wipeout x2 . 2

682

fiBinary Encodings Non-binary CSPs: Algorithms & Experimental Results

References
Bacchus, F., Chen, X., van Beek, P., & Walsh, T. (2002). Binary vs. Non-binary CSPs.
Artificial Intelligence, 140, 137.
Bacchus, F., & van Beek, P. (1998). Conversion Non-binary Binary
Constraint Satisfaction Problems. Proceedings AAAI98, pp. 310318.
Bater, J. (2000). Non-binary (Higher-Order) Modelling Solution Techniques Frequency Assignment Mobile Communications Networks. Ph.D. thesis, University
London.
Beacham, A., Chen, X., Sillito, J., & van Beek, P. (2001). Constraint programming lessons
learned crossword puzzles. Proceedings 14th Canadian Conference
AI.
Bessiere, C., Freuder, E., & Regin, J. (1995). Using Inference Reduce Arc Consistency
Computation. Proceedings IJCAI95, pp. 592599.
Bessiere, C., Meseguer, P., Freuder, E., & Larrosa, J. (2002). Forward Checking
Non-binary Constraint Satisfaction. Artificial Intelligence, 141, 205224.
Bessiere, C., & Regin, J. (1996a). Arc Consistency General Constraint Networks: Preliminary Results. Proceedings IJCAI97, pp. 398404.
Bessiere, C., & Regin, J. (1996b). MAC Combined Heuristics: Two Reasons Forsake
FC (and CBJ?) Hard Problems. Proceedings CP96, pp. 6175.
Bessiere, C., & Regin, J. (2001). Rening Basic Constraint Propagation Algorithm.
Proceedings IJCAI2001, pp. 309315.
Cabon, B., De Givry, S., Lobjois, L., Schiex, T., & Warners, J. (1999). Radio Link Frequency
Assignment. Constraints, 4, 7989.
CLib (2005). Conguration Benchmarks Library (http://www.itu.dk/doi/VeCoS/clib/),
Maintained VeCoS group, IT-University Copenhagen.
Debruyne, R., & Bessiere, C. (2001). Domain Filtering Consistencies. Journal Artificial
Intelligence Research, 14, 205230.
Dechter, R., & Pearl, J. (1989). Tree Clustering Constraint Networks. Artificial Intelligence, 38, 353366.
Ginsberg, M., Frank, M., Halpin, M., & Torrance, M. (1990). Search Lessons Learned
Crossword Puzzles. Proceedings AAAI-90, pp. 210215.
Haralick, R., & Elliot, G. (1980). Increasing Tree Search Eciency Constraint Satisfaction Problems. Artificial Intelligence, 14, 263313.
Hodge, L., Hurley, S., & Smith, D. (2002). Higher-Order Constraint Techniques
Frequency Assignment Problem. Tech. rep., University Cardi.
Jeavons, P., Dunkin, N., & Bater, J. (1998). Higher Order Constraints Necessary
Model Frequency Assignment Problems. ECAI98 Workshop Non-binary
constraints.
Mackworth, A. (1977). Consistency Networks Relations. Artificial Intelligence, 99118.
683

fiSamaras & Stergiou

Mamoulis, N., & Stergiou, K. (2001). Solving Non-Binary CSPs using Hidden Variable
Encoding. Proceedings CP-2001, pp. 168182.
Mohr, R., & Henderson, T. (1986). Arc Path Consistency Revisited. Artificial Intelligence, 28, 225233.
Mohr, R., & Masini, G. (1988). Good Old Discrete Relaxation. Proceedings ECAI-88,
pp. 651656.
Peirce, C. (1933) Collected Papers Vol. III. Cited F. Rossi, C. Petrie, V. Dhar 1989.
Prosser, P., Stergiou, K., & Walsh, T. (2000). Singleton Consistencies. Proceedings
CP-2000, pp. 353368.
Regin, J. (1994). Filtering Algorithm Constraints Dierence CSPs. Proceedings
AAAI-94, pp. 362367.
Rossi, F., Petrie, C., & Dhar, V. (1990). Equivalence Constraint Satisfaction
Problems. Proceedings ECAI-90, pp. 550556.
Smith, B. (2002). Dual Graph Translation Problem Life. Proceedings
CP-02, pp. 402414.
Smith, B., Stergiou, K., & Walsh, T. (2000). Using Auxiliary Variables Implied Constraints Model Non-binary Problems. Proceedings AAAI2000, pp. 182187.
Stergiou, K., & Walsh, T. (1999). Encodings Non-Binary Constraint Satisfaction Problems. Proceedings AAAI99, pp. 163168.
Subbarayan, S., Jensen, R., Hadzic, T., Andersen, H., Hulgaard, H., & Moller, J. (2004).
Comparing two Implementations Complete Backtrack-Free Interactive Congurator. Proceedings CP-04 Workshop CSP Techniques Immediate
Application, pp. 97111.
Van Hentenryck, P. (Ed.). (1989). Constraint Satisfaction Logic Programming. MIT
Press.
Van Hentenryck, P., Deville, Y., & Teng, C. (1992). Generic Arc Consistency Algorithm
Specializations. Artificial Intelligence, 57, 291321.
Watkins, W., Hurley, S., & Smith, D. (1998). Area Coverage Frequency Assignment: Evaluation Models Area Coverage. Tech. rep., University Glamorgan. Also presented
INFORMS-98.
Zhang, Y., & Yap, R. (2001). Making AC-3 Optimal Algorithm. Proceedings
IJCAI2001, pp. 316321.

684

fiJournal Artificial Intelligence Research 24 (2005) 157-194

Submitted 09/04; published 07/05

Learning Content Selection Rules Generating Object
Descriptions Dialogue
Pamela W. Jordan

pjordan@pitt.edu

Learning Research Development Center & Intelligent Systems Program
University Pittsburgh, LRDC Rm 744
Pittsburgh, PA 15260

Marilyn A. Walker

M.A.Walker@sheffield.ac.uk

Department Computer Science, University Sheffield
Regent Court, 211 Portobello Street
Sheffield S1 4DP, U.K.

Abstract
fundamental requirement task-oriented dialogue system ability generate object descriptions refer objects task domain. subproblem
content selection object descriptions task-oriented dialogue focus
much previous work large number models proposed. paper,
use annotated coconut corpus task-oriented design dialogues develop feature
sets based Dale Reiters (1995) incremental model, Brennan Clarks (1996)
conceptual pact model, Jordans (2000b) intentional influences model, use
feature sets machine learning experiment automatically learn model content
selection object descriptions. Since Dale Reiters model requires representation
discourse structure, corpus annotations used derive representation based
Grosz Sidners (1986) theory intentional structure discourse, well two
simple representations discourse structure based purely recency. apply
rule-induction program ripper train test content selection component
object description generator set 393 object descriptions corpus.
knowledge, first reported experiment trainable content selection component
object description generation dialogue. Three separate content selection models
based three theoretical models, independently achieve accuracies significantly
majority class baseline (17%) unseen test data, intentional influences model (42.4%) performing significantly better either incremental model
(30.4%) conceptual pact model (28.9%). best performing models combine
feature sets, achieving accuracies near 60%. Surprisingly, simple recency-based
representation discourse structure well one based intentional structure.
knowledge, also first empirical comparison representation Grosz
Sidners model discourse structure simpler model generation task.

1. Introduction
fundamental requirement task-oriented dialogue system ability generate
object descriptions refer objects task domain. example, consider
excerpt task-oriented dialogue coconut corpus Figure 1 (Di Eugenio,
Jordan, Thomason, & Moore, 2000). conversants dialogue attempting
c
2005
AI Access Foundation. rights reserved.

fiJordan & Walker

(Partial solution problem already agreed upon prior dialogue: 3 green chairs 50, 1 green
chair 100 green table dining room, blue sofa living room. numbers
brackets indicate utterance breaks analysis dialogue.)
G: [36] leaves us 250 dollars. [37] yellow rug 150 dollars. [38]
furniture left matches 100 dollars?
S: [39] No, furniture left costs $100. [40] guess buy yellow rug $150.
G: [41] Okay. [42] Ill buy rug 150 dollars. [43] green chair [44] buy
100 dollars [45] leave us money.
S: [46] sounds good. [47] Go ahead buy yellow rug green chair.
G: [48] Ill buy green 100 dollar chair. [49] Design Complete?
S: [50] Sounds good, [51] want green chair dining room chairs? [52]
put yellow rug living room. [53] design complete.
G: [54] Sounds good. [55] Hit design complete

Figure 1: Excerpt coconut dialogue illustrating variable selection attributes
object descriptions refer furniture items

collaboratively construct solution furnishing two room house. conversant starts
task separate set furniture items used solution. process
negotiating solution, generate object descriptions (shown italics) items
furniture.
furniture type coconut task domain four associated attributes: color,
price, owner quantity. first step, object description generator must decide
four attributes include utterance, subsequent surface generation steps
decide utterance attributes expressed. example, task domain
objects discussion dialogue Figure 1 $150 yellow rug owned Garrett
(G) $100 dollar green chair owned Steve (S). dialogue excerpt Figure
1, yellow rug first referenced utterance 36 yellow rug 150 dollars
subsequently yellow rug 150 dollars, rug 150 dollars, yellow rug,
owner attribute sometimes realized separate noun phrase within
utterance. could also described following: rug, rug,
yellow rug, $150 yellow rug, $150 rug. content object descriptions
varies depending attributes included. speaker decide
attributes include?
problem content selection subsequent reference focus much
previous work large number overlapping models proposed seek
explain different aspects referring expression content selection (Clark & Wilkes-Gibbs,
1986; Brennan & Clark, 1996; Dale & Reiter, 1995; Passonneau, 1995; Jordan, 2000b) inter
alia. factors models use include discourse structure, attributes
attribute values used previous mention, recency last mention, frequency
mention, task structure, inferential complexity task, ways determining
salient objects salient attributes object. paper, use set factors
considered important three models, empirically compare utility
158

fiLearning Content Selection Rules Generating Object Descriptions

factors predictors machine learning experiment order first establish whether
selected factors, represent them, make effective contributions larger task
content selection initial well subsequent reference. factor sets utilize are:
contrast set factors, inspired incremental model Dale Reiter
(1995);
conceptual pact factors, inspired models Clark colleagues (Clark &
Wilkes-Gibbs, 1986; Brennan & Clark, 1996);
intentional influences factors, inspired model Jordan (2000b).
develop features representing factors, use features represent examples object descriptions context occur purpose learning
model content selection object descriptions.
Dale Reiters incremental model focuses production near-minimal subsequent references allow hearer reliably distinguish task object similar
task objects. Following Grosz Sidner (1986), Dale Reiters algorithm utilizes discourse structure important factor determining objects current object
must distinguished from. model Clark, Brennan Wilkes-Gibbs based
notion conceptual pact, i.e. conversants attempt coordinate one
another establishing conceptual pact describing object. Jordans intentional
influences model based assumption underlying communicative
task-related inferences important factors accounting non-minimal descriptions.
describe models detail Section 3 explain expect
models work well combination.
Many aspects underlying content selection models well-defined
implementation point view, may necessary experiment different definitions
related parameter settings determine produce best performance
model, done parameter setting experiments carried Jordan (2000b).1
However, experiments describe paper, strive feature representations
allow machine learner take task finding optimal settings
otherwise use results reported Jordan (2000b) guidance. variation
test representation discourse structure models require it.
Otherwise, explicit tests different interpretations models left future work.
report set experiments designed establish predictive power factors emphasized three models using machine learning train test content
selection component object description generator set 393 object descriptions
corpus coconut dialogues. generator goes beyond models
accounts anaphoric expressions address general problem generating
initial subsequent expressions. provide machine learner distinct sets
features motivated models, addition discourse features motivated assumed
1. Determining optimal parameter settings machine learning algorithm similar issue (Daelemans
& Hoste, 2002) different level. use machine learner parameter settings
experiments although searching optimal machine learner parameter settings may value
improving performance.

159

fiJordan & Walker

familiarity distinctions (Prince, 1981) (i.e. new vs. evoked vs. inferable discourse entities),
dialogue specific features speaker object description, absolute
location discourse, problem conversants currently trying
solve. evaluate object description generator comparing predictions
humans said point dialogue counting correct
exactly match content human generated object descriptions (Oberlander, 1998).2
provides rigorous test object description generator since likelihood
object descriptions would achieved speakers communicative goals.
also quantify contribution feature set performance object
description generator. results indicate intentional influences features,
incremental features conceptual pact features independently significantly better majority class baseline task, intentional influences model (42.4%) performing significantly better either incremental model
(30.4%) conceptual pact model (28.9%). However, best performing models
combine features models, achieving accuracies matching human performance
near 60.0%, large improvement majority class baseline 17% generator simply guesses frequent attribute combination. Surprisingly, results
experimenting different discourse structure parameter settings show features
derived simple recency-based model discourse structure contribute much
particular task one based intentional structure.
coconut dataset small compared used machine learning experiments. Smaller datasets run higher risk overfitting thus specific performance
results interpreted caution. addition coconut corpus represents
one type dialogue; typed, collaborative, problem solving dialogues constraint satisfaction problems. models suggested features focus general communicative
issues, expect variations task involved communication setting impact predictive power feature sets. example, conceptual pact model
developed using dialogues focus identifying novel, abstract figures.
figures abstract clear start series exercises description
best help dialogue partner identify target figure. Thus need negotiate
description figures prominent tasks. Likewise expect
constraint satisfaction problems need joint agreement solution cause
intentional influences model prominent coconut dialogues.
fact conceptual pact features show predictive power significantly
better baseline suggests prominence model inspired feature
set may vary across tasks communication settings, expect significant
contribution make content selection model.
Clearly, us whose ultimate goal general model content selection
dialogue, need carry experiments wide range dialogue types.
us whose ultimate goal dialogue application, one smaller corpus
representative anticipated dialogues probably preferable. Despite two notes
2. Note attributes discourse entity has, harder achieve exact match
human description, i.e. problem object description generator must correctly choose among
16 possibilities represented power set four attributes.

160

fiLearning Content Selection Rules Generating Object Descriptions

caution expect feature representations suggest starting point larger
endeavors.
Previous research applied machine learning several problems natural language
generation, cue word selection (Di Eugenio, Moore, & Paolucci, 1997), accent placement (Hirschberg, 1993), determining form object description (Poesio, 2000),
content ordering (Malouf, 2000; Mellish, Knott, Oberlander, & ODonnell, 1998; Duboue
& McKeown, 2001; Ratnaparkhi, 2002), sentence planning (Walker, Rambow, & Rogati,
2002), re-use textual descriptions automatic summarization (Radev, 1998), surface realization (Langkilde & Knight, 1998; Bangalore & Rambow, 2000; Varges & Mellish,
2001).
machine learning approaches content selection Oh
Rudnicky (2002) Roy (2002). Oh Rudnicky report results automatically
training module CMU Communicator system selects attributes
system express implicitly confirming flight information ongoing dialogue.
example, caller said want go Denver Sunday, implicit confirmation
system might Flying Denver Sunday. experimentally compared
statistical approach based bigram models strategy confirms information
system heard first time, found two systems performed
equally well. Roy reports results spoken language generator trained generate
visual descriptions geometric objects provided features visual scenes. Roys
results show understandability automatically generated descriptions
8.5% lower human-generated descriptions. Unlike approach, neither consider effects ongoing dialogue dialogue partner, effect dialogue
context generated descriptions. work, theoretical models based
on, explicitly focus processes involved generating descriptions redescriptions
objects interactive dialogue allow dialogue partners remain aligned
dialogue progresses (Pickering & Garrod, 2004).
relevant prior work Jordan (2000b). Jordan implemented Dale
Reiters incremental model developed implemented intentional influences model, incorporates incremental model, tested
coconut corpus. Jordan also experimented different parameter settings vague
parts models. results work directly comparable Jordan
tested rules subsequent reference, attempt learn rules generating initial subsequent references. However, using purely rule-based approach,
best accuracy Jordan reported 69.6% using non-stringent scoring criterion
(not exact match) 24.7% using stringent exact match scoring used here.
paper, using features derived Jordans corpus annotations, applying rule
induction induce rules training data, achieve exact match accuracy nearly
47% comparing similar model accuracy nearly 60% comparing best overall model. results appear improvement
reported Jordan (2000b), given increased accuracy ability generate
initial well subsequent references.
Section 2 describes coconut corpus, definitions discourse entities object
descriptions coconut domain, annotations corpus use
derive feature sets. Section 3 presents theoretical models content selection
161

fiJordan & Walker

Opal 1

INVENTORY
1
0
1
1
1
2
0
0

TABLE-HIGH YELLOW $400
SOFA GREEN $350
SOFA YELLOW $400
RUG RED $200
LAMP-FLOOR BLUE $50
CHAIR BLUE $75
CHAIR GREEN $100
CHAIR RED $100

End Turn

Design Complete

PARTNERS INVENTORY
TABLE-LOW
TABLE-HIGH
RUG
SOFA
LAMP-TABLE
LAMP-FLOOR
CHAIR
ARMCHAIR
DESK

> change chairs,
two red ones price.
much like green
looks ugly red.

LIVING-ROOM
> bought green sofa 350,
green table 400,
2 green chairs 100 each.

DINING-ROOM

100
400
350

100

100

100

400

budget is: $400

Figure 2: snapshot interface coconut task
object descriptions detail describes features inspired models.
Section 4 describes experimental design Section 5 presents quantitative results
testing learned rules corpus, discusses features machine
learner identifies important, provides examples rules learned. Section
6 summarizes results discusses future work.

2. Coconut Corpus
coconut corpus set 24 computer-mediated dialogues consisting total
1102 utterances. dialogues collected experiment two human subjects
collaborated simple design task, buying furniture two rooms house
(Di Eugenio et al., 2000). collaboration carried typed dialogue
workspace action utterance automatically logged. excerpt
coconut dialogue Figure 1. snapshot workspace coconut
experiments Figure 2.
experimental dialogues, participants main goal negotiate purchases;
items highest priority sofa living room table four chairs
dining room. participants also specific secondary goals constrain
problem solving task. Participants instructed try meet many
goals possible, motivated rewards associated satisfied goals.
162

fiLearning Content Selection Rules Generating Object Descriptions

secondary goals are: 1) match colors within room, 2) buy much furniture
can, 3) spend money. participants told rewards associated
achieving goal.
participant given separate budget (as shown mid-bottom section
Figure 2) inventory furniture (as shown upper-left section Figure 2).
Furniture types include sofas, chairs, rugs lamps, possible colors red, green,
yellow blue. Neither participant knows others inventory much
money has. sharing information conversation, combine
budgets select furniture others inventories. Note since participant
know furniture partner available told, menu (see
mid-right section Figure 2) allows participant create furniture items based
partners description items available. participants equals purchasing
decisions joint. experiment, set participants solved one three scenarios
varying inventories budgets. problem scenarios varied task complexity
ranging tasks items inexpensive budget relatively large, tasks
items expensive budget relatively small.
2.1 Discourse Entities Object Descriptions Corpus
discourse model used keep track objects discussed discourse. object
described, conversants relate information object utterance
appropriate mental representation object discourse model (Karttunen, 1976;
Webber, 1978; Heim, 1983; Kamp & Reyle, 1993; Passonneau, 1996). model contains
discourse entities, attributes links entities (Prince, 1981). discourse entity
variable placeholder indexes information object described
particular linguistic description appropriate mental representation object.
discourse model changes discourse progresses. object first described,
discourse entity ei added discourse model. new utterances produced,
additional discourse entities may added model new objects described,
new attributes may get associated ei whenever redescribed. Attributes
always supplied noun phrase (NP). may arise parts utterance
discourse inference relations link discourse entities.
illustrate discourse inference relations relevant coconut, (1b) green set
example new discourse entity set/subset discourse inference relation
three distinct discourse entities 2 $25 green chairs, 2 $100 green chairs 1
$200 green table.
(1) a. : [2 $25 green chairs] [a $200 green table].
b. : [2 $100 green chairs]. Lets get [the green set].
class inference relation exists referent discourse entity subsumption
relationship previous discourse entity. example, (2) table green
one subsumption relationship.
(2)

Lets decide [the table] dining room. [your green one]?
163

fiJordan & Walker

common noun anaphora inference relation occurs cases one anaphora
null anaphora. example, (3) marked NPs last part utterance
null anaphora relation marked NP first part. Note example
also class inference relation well.
(3)

[a variety high tables] ,[green], [red] [yellow] 400, 300, 200.

Discourse entities also related predicative relationships is. example, (4) entities defined cheapest table blue one $200
discourse entities information one provides information
other. Note example also includes common noun anaphora class inference
relations.
(4)

[My cheapest table] [a blue one $200].

object description linguistic expression (usually NP) initiates creation update discourse entity furniture item, along explicit attributes
expressed within utterance. consider attributes explicitly expressed
outside NP part object description since realized either
part noun phrase triggers discourse entity elsewhere utterance.
Attributes inferred (e.g. quantity the) help populate discourse
entity considered part object description since inferred attributes may
may reflect explicit choice. inferred attribute could side-effect
surface structure selected realizing object description.3
2.2 Corpus Annotations
corpus collected, annotated human coders three types
features: problem-solving utterance level features shown Figure 3, discourse
utterance level features illustrated Figure 4 discourse entity level features illustrated Figure 5. additional features shown Figure 6.
feature encodings shown dialogue excerpt Figure 1.
features hand-labelled corpus human-human corpus
but, discuss end section, many features would need
established system collaborative problem solving component function
properly.
Looking first Figure 6, explicit attributes (as described previous
section) predicted models building testing. remaining
features available context making predictions.
problem-solving utterance level features Figure 3 capture problem
solving state terms goals actions discussed conversants,
constraint changes implicitly assumed, explicitly stated conversants,
size solution set current constraint equations. solution set size
3. true attributes explicitly expressed (e.g. subject position
expresses ownership attribute), attribute types interest corpus adjuncts
(e.g. Lets buy chair [for $100].).

164

fiLearning Content Selection Rules Generating Object Descriptions

Utterance

37
38
39
40
42
43
44
46
47
48
51
52

Goal/
Action
Label
SelectOptionalItemLR
SelectOptionalItem
SelectOptionalItem
SelectOptionalItemLR
SelectOptionalItemLR
SelectOptionalItemDR
SelectOptionalItemDR
SelectOptionalItemDR
SelectOptionalItemDR
SelectOptionalItemLR
SelectOptionalItemDR
SelectOptionalItemDR,
SelectChairs
SelectOptionalItemLR

Introduce

continue
introduce
introduce
continue
continue
continue
continue
continue
continue
continue
continue
continue
continue
introduce
continue

Goal/
Action
Identifier
act4
act5
act5
act4
act4
act5
act5
act5
act4
act5
act5
act5,
act3
act4

Change

Constraints
drop color match
color,price limit
none
none
none
none
none
none
none

Solution
Size

none
none

determinate
determinate

none

determinate

indeterminate
indeterminate
indeterminate
determinate
determinate
indeterminate
determinate
determinate
determinate

Figure 3: Problem solving utterance level annotations utterances relevant problem
solving goals actions dialogue excerpt Figure 1

Utterance

Influence
Listener

Influence
Speaker

37
40
42
43
44
46
47
48
49
51
52

ActionDirective
ActionDirective
ActionDirective
OpenOption
ActionDirective
ActionDirective
ActionDirective
ActionDirective
ActionDirective
ActionDirective
ActionDirective

Offer
Commit
Commit
nil
Offer
Commit
Commit
Commit
Offer
Offer
Commit

Figure 4: Discourse utterance level annotations utterances relevant establishing joint
agreements dialogue excerpt Figure 1

constraint equation characterized determinate set values closed
represents conversants shared relevant values one another.
indeterminate size means set values still open solution cannot yet
determined. problem-solving features capture situational problemsolving influences may effect descriptions indicate task structure
discourse structure derived (Terken, 1985; Grosz & Sidner, 1986). domain
165

fiJordan & Walker

Utterance

37
38
39
40
42
43
44
47
47
48
51
51
52

Reference

Coreference
initial ref-1
initial ref-2
initial ref-3
corefers ref-1
corefers ref-1
initial ref-4
corefers ref-4
corefers ref-1
corefers ref-4
corefers ref-4
corefers ref-4
initial ref-5
corefers ref-1

Discourse
Inference
Relations
nil
nil
class ref-20
nil
nil
nil
CNAnaphora ref-4
nil
nil
nil
nil
set ref-12,ref-16

Attribute
Values
my,1,yellow,rug,150
your,furniture,100
my,furniture,100
your,1,yellow,rug,150
my,1,rug,150
my,1,green,chair
my,100
your,1,yellow,rug
your,1,green,chair
my,1,green,chair,100
1,green,chair
chair
1,yellow rug

Argument
Goal/Action
Identifier
act4
act5
act5
act4
act4
act5
act5
act4
act5
act5
act5
act3
act4

Figure 5: Discourse entity level annotations utterances referring furniture items
Figure 1

Utterance

Speaker

37
38
39
40
42
43
44
47
47
48
51
51
52

G
G


G
G
G


G




Explicit
Attributes
type,color,price,owner
type,color,price,owner
type,price,owner
type,color,price,owner
type,price,owner
type,color,owner
price,owner
type,color
type,color
type,color,price,owner
type,color
type
type,color

Inferred
Attributes
quantity

quantity
quantity
quantity
owner,quantity
owner,quantity
quantity
quantity
quantity
quantity

Description
yellow rug 150 dollars
furniture ... 100 dollars
furniture ... 100 dollars
yellow rug $150
rug 150 dollars
green chair
[0] 100 dollars
yellow rug
green chair
green 100 dollar chair
green chair
chairs
yellow rug

Figure 6: Additional features dialogue excerpt Figure 1

goal provides discourse segment purpose utterance relates different
domain goal set domain goals defines new segment.
discourse utterance level features Figure 4 encode influence utterance expected speaker listener defined DAMSL
scheme (Allen & Core, 1997). annotations also help capture situational
influences may effect descriptions. possible influences listeners include open
options, action directives information requests. possible influences speakers
offers commitments. Open options options speaker presents hearers
future actions, whereas action directive speaker trying put hearer
166

fiLearning Content Selection Rules Generating Object Descriptions

obligation act. intent put hearer obligation act
open option speaker may given hearer enough information
act speaker may clearly indicated endorse action. Offers
commitments needed arrive joint commitment proposed action.
offer speaker conditionally committing action whereas commit
speaker unconditionally committing. commit, hearer may already
conditionally committed action discussion, speaker may care
hearer also committed action intends do.
discourse entity level features Figure 5 define discourse entities
discourse model. Discourse entities, links earlier discourse entities
attributes expressed previously discourse entity NP-level utterance level
inputs object description generator. Part used define discourse
entities discourse reference relations include initial, coreference discourse inference relations different entities links described earlier; set/subset,
class, common noun anaphora predicative. addition, order link expression
appropriate problem solving actions, action entity argument
also annotated. order test whether acceptable object description generated
model discourse entity context, explicit attributes used describe entity
also annotated (recall Figure 6).
action entity related helps associate entities correct parts
discourse structure helps determine problem-solving situations relevant
particular entity. discourse entity level annotations, initial representations discourse entities updates derived. example, initial
representation yellow rug. costs $150. would include type, quantity, color
owner following first utterance. quantity attribute inferred.
second utterance entity would updated include price.
encoded features good inter-coder reliability shown kappa values
given Table 1 (Di Eugenio et al., 2000; Jordan, 2000b; Krippendorf, 1980). values
statistically significant size labelled data set, shown p-values
table.
Discourse
Entity
Level

Problem
Solving
Utterance
Level
Discourse
Utterance
Level

Reference

Coreference
.863
(z=19, p<.01)
Introduce
Goal/Action
.897
(z=8, p<.01)
Influence
Listener
.72
(z=19, p<.01)

Discourse
Inference
Relations
.819
(z=14, p<.01)
Continue
Goal/Action
.857
(z=27, p<.01)
Influence
Speaker
.72
(z=13, p<.01)

Argument
Goal/
Action
.857
(z=16, p<.01)
Change
Constraints
.881
(z=11, p<.01)

Attributes

.861
(z=53, p<.01)
Solution
Size
.8
(z=6, p<.01)

Table 1: Kappa values annotation scheme
167

Goal/Action
.74
(z=12, p<.01)

fiJordan & Walker

availability annotated information dialogue system
currently ongoing challenge todays systems, system successful
dialogue partner collaborative problem solving dialogue, options
known priori, model update discourse entities, understand current
problem solving state agreed upon, able make, accept reject
proposed solutions. Certainly, dialogue system domains communicative settings
need information likewise information essential
domains settings necessary engage coconut dialogue.
experimental data consists 393 non-pronominal object descriptions 13 dialogues coconut corpus well features constructed annotations described
above. next section explains detail annotations used construct
features used training models.

3. Representing Models Content Selection Object Descriptions
Features
Section 1, described would use annotations coconut corpus
construct feature sets motivated theories content selection object descriptions.
describe theories detail, present, theory, feature
sets inspired theory. Section 4 explain features used
automatically learn model content selection object descriptions. order used
way, features must represented continuous (numeric), set-valued,
symbolic (categorial) values.
Models content selection object descriptions attempt explain motivates
speaker use particular set attributes describe object, first mention
object well subsequent mentions. extended discourse, speakers often
redescribe objects introduced earlier order say something
object event participates. test part assumption many
factors relevant redescriptions also relevant initial descriptions.
models described previously rule-based implementations
tested coconut corpus found nearly equally good explaining redescriptions corpus (Jordan, 2000b). share basic assumption
speakers goal redescribing discourse entity already introduced
discourse model prior conversation. speakers primary goal identification, i.e.
generate linguistic expression efficiently effectively re-evoke appropriate
discourse entity hearers mind. redescription must adequate re-evoking
entity unambiguously, must efficient way (Dale & Reiter, 1995). One
factor major effect adequacy redescription fact discourse
entity described must distinguished discourse entities discourse
model currently salient. discourse entities called distractors. Characteristics discourse entities evoked dialogue recency frequency
mention, relationship task goals, position relative structure
discourse hypothesized means determining entities mutually salient
conversants.
168

fiLearning Content Selection Rules Generating Object Descriptions

mutually known: type-mk, color-mk, owner-mk, price-mk, quantity-mk
reference-relation: one initial, coref, set, class, cnanaphora, predicative

Figure 7: Assumed Familiarity Feature Set.

begin encoding features object description generator features
representing fundamental aspects discourse entity discourse model. divide
features two sets: assumed familiarity feature set inherent
feature set. assumed familiarity features Figure 7 encode information
discourse entity already represented discourse model point
discourse entity described. attributes assumed
mutually known conversational participants represented five boolean
features: type-mk, color-mk, owner-mk, price-mk, quantity-mk. example, type-mk
value yes, represents type attribute entity described
mutually known.
Figure 7 also enumerates reference-relation feature described Section 2 encode
whether entity new (initial), evoked (coref) inferred relative discourse
context. types inferences supported annotation set/subset, class, common
noun anaphora (e.g. one null anaphora), predicative (Jordan, 2000b),
represented values (set,class,cnanaphora,predicative). reference relations relevant initial subsequent descriptions.
utterance-number, speaker-pair, speaker, problem-number
attribute values:
type: one sofa, chair, table, rug, lamp, superordinate
color: one red, blue, green, yellow
owner: one self, other,
price: range $50 $600
quantity: range 0 4.

Figure 8: Inherent Feature Set: Task, Speaker Discourse Entity Specific features.

inherent features Figure 8 specific encoding particulars
discourse situation, speaker, task, actual values entitys known
attributes (type, color, owner, price, quantity). supply values attributes
case preferences associated particular values. example, may
preference include quantity, describing set chairs, price, high.
inherent features allow us examine whether individual differences
selection models (speaker, speaker-pair), whether specifics attributes
169

fiJordan & Walker

object, location within dialogue (utterance-number), problem difficulty
(problem-number) play significant roles selecting attributes. attribute values
entity derived annotated attribute features reference relations.
dont expect rules involving feature set generalize well dialogue
situations. Instead expect lead situation specific model. Whenever
features used overfitting regardless training set size. Consider
particular speaker, speaker-pair utterance number specific particular dialogues
unlikely occur another dialogue, even new coconut dialogue. feature
representations would abstracted value generator.
3.1 Dale Reiters Incremental Model
computational work generating object descriptions subsequent reference (Appelt, 1985a; Kronfeld, 1986; Reiter, 1990; Dale, 1992; Heeman & Hirst, 1995; Lochbaum,
1995; Passonneau, 1996; van Deemter, 2002; Gardent, 2002; Krahmer, van Erk, & Verleg,
2003) concentrates produce minimally complex expression singles
discourse entity set distractors. set contextually salient distractors
identified via model discourse structure mentioned above. Dale Reiters incremental model basis much current work relies discourse structure
determine content object descriptions subsequent reference.
commonly used account discourse structure task-oriented dialogues
Grosz Sidners (1986) theory attentional intentional structure discourse.
theory, data structure called focus space keeps track discourse entities
salient particular context, stack focus spaces used store focus
spaces discourse whole. content focus space operations
stack focus spaces determined structure task. change task topic
indicates start new discourse segment corresponding focus space.
discourse entities described discourse segment classified salient dialogue
participants corresponding focus space focus stack. Approaches use
notion discourse structure take advantage representation produce descriptors
minimally complex given current focus space, i.e. description
unambiguous respect global discourse.
According Dale Reiters model, descriptor containing information
needed identify referent given current focus space would minimally complex
small number overspecifications appear relative identification goal
expected explained artifacts cognitive processing limits. Trying produce
minimally complex description seen implementation two parts
Grices Maxim Quantity, according utterance say much
required, required (Grice, 1975). Given entity describe
distractor set defined entities current focus space, incremental model
incrementally builds description checking static ordering attribute types
selecting attribute include description eliminates
remaining distractors. distractors ruled out, longer influence selection
process.
170

fiLearning Content Selection Rules Generating Object Descriptions

Distractor Frequencies: type-distractors, color-distractors, owner-distractors, price-distractors, quantity-distractors
Attribute Saliency: majority-type, majority-type-freq, majority-color, majority-color-freq,
majority-price, majority-price-freq, majority-owner, majority-owner-freq, majority-quantity,
majority-quantity-freq

Figure 9: contrast set Feature Sets

set features called contrast set features used represent aspects Dale
Reiters model. See Figure 9. goal encoding represent whether
distractors present focus space might motivate inclusion particular
attribute. First, distractor frequencies encode many distractors attribute
value different entity described.
incremental model also utilizes preferred salience ordering attributes
eliminates distractors attributes added description. example, adding
attribute type object chair, eliminates distractors arent chairs.
feature based encoding cannot easily represent distractor set changes attribute
choices made. compensate, encoding treats attributes instead objects
distractors attribute saliency features encode attribute values
salient attribute type, count number distractors attribute
value. example, 5 8 distractors red majority-color red majoritycolor-freq 5. Taking view attributes distractors advantage
preferred ordering attributes adjust according focus space. interpretation
Dale Reiters model shown statistically similar strict model
higher mean match corpus (Jordan, 2000b). Thus goal adding
additional features try obtain best possible performance incremental
model.
Finally, open issue deriving distractors define focus space (Walker,
1996a). described above, Grosz Sidners theory discourse creates data structure
called focus space discourse segment, discourse segments based
intentions underlying dialogue. However Grosz Sidner provide clear criterion
assigning segmentation structure. order explore definition variations
work best, experiment three focus space definitions, two simple focus space
definitions based recency, based intentional structure described
below. train test three focus space definitions, create separate datasets
three. knowledge, first empirical comparison Grosz
Sidners model simpler model discourse-related task.
intentional structure, utilize problem solving utterance features hand-labelled
coconut corpus high reliability discussed Section 2. annotated
task goals used derive intentional structure discourse, provides
segmentation discourse, described Grosz Sidner (1986). current focus
space defined annotated task goals used define segment distractors.
dataset label segment. recency, one extremely simple focus space definition
171

fiJordan & Walker

uses discourse entities recent utterance possible distractors.
dataset label one utterance. second extremely simple focus space definition
considers discourse entities last five utterances possible distractors.
dataset label five utterance. dataset, features Figure 9
computed relative distractors determined focus space definition.
3.2 Jordans Intentional Influences Model
Jordan (2000b) proposed model select attributes object descriptions subsequent reference called intentional influences model. model posits along
identification goal, task-related inferences agreement process task negotiation important factors selecting attributes. Attributes necessary
identification purposes may intentional redundancies communicative purpose
(Walker, 1996b) always due cognitive processing limits finding minimally
complex descriptions (Jordan, 2000b).
goal-directed view sentence generation suggests speakers attempt satisfy
multiple goals utterance (Appelt, 1985b). suggests strategy also
applies lower-level forms within utterance (Stone & Webber, 1998). is,
form opportunistically contribute satisfaction multiple goals. many-one
mapping goals linguistic forms generally referred overloading intentions
(Pollack, 1991). Subsequent work shown overloading involve trade-offs
across linguistic levels. is, intention achieved complicating form
one level may allow speaker simplify another level omitting important information.
example, choice clausal connectives pragmatic level simplify syntactic
level (Di Eugenio & Webber, 1996), trade-offs word choice syntax
semantics levels (Stone & Webber, 1998).
intentional influences model incorporates multiple communicative problem solving goals addition main identification goal speaker intends
hearer re-evoke particular discourse entity. contribution model
overloads multiple, general communicative problem solving goals generating description. model tested coconut corpus, inferences changes
problem solving constraints, conditional unconditional commitments proposals, closing goals shown relevant influences attribute
selection (Jordan, 2000a, 2002) goals verify understanding infer informational
relations (Jordan, 2000b).4
features used approximate Jordans model Figure 10. features cover
general communicative problem solving goals hypothesized model
except identification goal information relation goal. difficulty
modelling information relation goal features, representation left future
work.5
4. different subset general goals covered model expected influential
domains communication settings, therefore general object description generator would need
trained wide range corpora.
5. Information relation goals may relate two arbitrarily distant utterances additional details beyond
distance expected important. goal previously appear relevant
coconut corpus (Jordan, 2000b), gave low priority implementation.

172

fiLearning Content Selection Rules Generating Object Descriptions

task situation: goal, colormatch, colormatch-constraintpresence, pricelimit, pricelimit-constraintpresence, priceevaluator, priceevaluator-constraintpresence, colorlimit, colorlimit-constraintpresence, priceupperlimit, priceupperlimit-constraintpresence
agreement state: influence-on-listener, commit-speaker, solution-size, prev-influence-on-listener, prev-commit-speaker, prev-solution-size, distance-of-last-state-in-utterances, distanceof-last-state-in-turns, ref-made-in-prev-action-state, speaker-of-last-state, prev-ref-state
previous agreement state description: prev-state-type-expressed, prev-state-color-expressed,
prev-state-owner-expressed, prev-state-price-expressed, prev-state-quantity-expressed
solution interactions: color-contrast, price-contrast

Figure 10: Intentional Influences Feature Set.

task situation features encode inferable changes task situation related
item attributes, colormatch boolean feature indicates whether
change color match constraint. pricelimit, colorlimit priceupperlimit
features also boolean features representing constraint change
related setting limits values price color attributes. features
constraintpresence appended constraint feature name symbolic features indicate
whether constraint change implicit explicit. example, agreed
upon constraint try select items color value room, speaker
wants relax constraint feature colormatch would value yes.
speaker communicated explicitly saying Lets forget trying match colors.
constraintpresence feature would value explicit otherwise would
value implicit. constraint change explicitly communicated speaker
decides include color attribute necessary identification purposes,
may help hearer infer means drop constraint
agreement state features Figure 10 encode critical points agreement
problem solving. Critical agreement states (Di Eugenio et al., 2000):
propose: speaker offers entity conditional commitment results
determinate solution size.
partner decidable option: speaker offers entity conditional commitment results indeterminate solution size.
unconditional commit: speaker commits entity.
unendorsed option: speaker offers entity show commitment
using solution size already determinate.
example, dialogue participant unconditionally committing response
proposal, may want verify item entity description partner repeating back previous description. features
encode critical agreement states include DAMSL features (influence-on-listener,
173

fiJordan & Walker

commit-speaker, prev-influence-on-listener, prev-commit-speaker), progress toward solution (solution-size, prev-solution-size, ref-made-in-prev-action-state), features inherent
agreement state (speaker-of-last-state, distance-of-last-state-in-utterances, distanceof-last-state-in-turns). features make reference state derived
agreement state features extensive discourse history encoded within
feature representation. addition, since current agreement state depends part
previous agreement state, added derived agreement state. previous
agreement state description features Figure 10 booleans capture dependencies
model content description previous state. example,
previous agreement state entity expressed type color attributes
would encoded yes prev-state-type-expressed prev-state-color-expressed
rest.
solution interactions features Figure 10 represent situations multiple proposals consideration may contrast one another terms solving
color-matching goals (color-contrast) price related goals (price-contrast).
boolean feature color-contrast true, means entitys color matches
partial solution already agreed upon contrasts alternatives
proposed. situation, may grounds endorsing entity relative alternatives. example, response Ss utterance [37] Figure 1,
context G earlier introduced one blue rug $175, G could said Lets use
blue rug. response. case blue rug would true value color-contrast
different color alternative, matches blue sofa
already selected.
boolean feature price-contrast describes two different situations. feature
price-contrast true, either means entity best price relative
alternatives, problem nearly complete, entity expensive
alternatives. first case, grounds endorsement item
cheaper. second case, may item spend remaining budget
result higher score problem solution.
Note although solution interaction features depend upon agreement states,
necessary recognize proposals commitments order identify alternatives track agreed upon solutions, difficult encode extensive historical
information directly feature representation. Therefore solution interaction features
derived, derivation includes heuristics use agreement state features
estimating partial solutions. sample encoding dialogue excerpt Figure 1
problem solving utterance level annotations agreement states given Figures 3
4.
3.3 Brennan Clarks Conceptual Pact Model
Brennan Clarks conceptual pact model focuses bidirectional adaptation
conversational partner linguistic choices conversational participant.
conceptual pact model suggests dialogue participants negotiate description
find adequate describing object (Clark & Wilkes-Gibbs, 1986; Brennan
& Clark, 1996). speaker generates trial descriptions hearer modifies based
174

fiLearning Content Selection Rules Generating Object Descriptions

object thinks suppose identify. negotiation continues
participants confident hearer correctly identified intended object.
Brennan Clark (1996) point lexical availability, perceptual salience
tendency people reuse terms describing object
conversation, significantly shape descriptions people generate. factors
may override informativeness constraints imposed Grices Quantity Maxim.
Lexical availability depends object best conceptualized label associated
conceptualization (e.g. referent item furniture sofa).
perceptual salience, speakers may include highly salient attribute rather
attributes distinguish distractors, e.g. $50 red sofa $50
sofa may informative enough. Adaptation ones conversational partner lead
tendency reuse previous description.
tendency reuse description derives combination recent,
successfully understood description object, often description
used particular conversation. However, tendency moderated need
adapt description changing problem-solving circumstances make repeated
descriptions even efficient precedents become established particular
pairing conversational partners. Recency frequency effects reuse reflections
coordination process conversational partners negotiating
shared way labelling conceptualizing referent. Different descriptions may tried
participants agree conceptualization. change problem situation may
cause conceptualization embellished additional attributes may instigate
negotiation new conceptualization referent.
additional features suggested model include previous description since
candidate conceptual pact, long ago description made,
frequently referenced. description used back dialogue
referenced frequently, could indicate negotiation process completed.
Furthermore, model suggests that, pact reached, dialogue
participants continue use description previously negotiated unless
problem situation changes. continued usage aspect model also similar
Passonneaus lexical focus model (Passonneau, 1995).
interactions discourse entities: distance-last-ref, distance-last-ref-in-turns, numberprev-mentions, speaker-of-last-ref, distance-last-related
previous description: color-in-last-exp, type-in-last-exp, owner-in-last-exp, price-in-last-exp,
quantity-in-last-exp, type-in-last-turn, color-in-last-turn, owner-in-last-turn, price-in-lastturn, quantity-in-last-turn, initial-in-last-turn
frequency attributes: freq-type-expressed, freq-color-expressed, freq-price-expressed, freqowner-expressed, freq-quantity-expressed
stability history: cp-given-last-2, cp-given-last-3

Figure 11: conceptual pact Feature Set.

175

fiJordan & Walker

conceptual pact features Figure 11 encode current description relates
previous descriptions entity. encode recency information: entity
last described terms number utterances turns (distance-last-ref, distancelast-in-turns), last related description (e.g. set, class) (distance-last-related),
frequently described (number-prev-mentions), last described (speaker-oflast-ref), last described terms turn expression since description
may broken several utterances (color-in-last-exp, type-in-last-exp, owner-inlast-exp, price-in-last-exp, quantity-in-last-exp, type-in-last-turn, color-in-last-turn, ownerin-last-turn, price-in-last-turn, quantity-in-last-turn, initial-in-last-turn). also encode
frequency information: frequency attributes expressed previous
descriptions (freq-type-expressed, freq-color-expressed, freq-price-expressed, freq-ownerexpressed, freq-quantity-expressed), history possible conceptual pacts may
formed; attribute types used describe last two last three
descriptions consistent across usages (cp-given-last-2, cp-given-last-3).

4. Experimental Method
experiments utilize rule learning program ripper (Cohen, 1996) learn content
selection component object description generator object descriptions
coconut corpus. Although categorization algorithm could applied problem
given current formulation, ripper good match particular setup
if-then rules used express learned model easily compared
theoretical models content selection described above. One drawback ripper
automatically take context account training discourse context
must represented via features well. Although might seem desirable use rippers
previous predictions additional context training, since consider
practice, unnecessary irrelevant so. learned model consist
generation rules relative discourse encoded features (i.e.
actually said corpus) corrections learns good improving
performance static corpus.
Like learning programs, ripper takes input names set classes
learned, names ranges values fixed set features, training data specifying
class feature values example training set. output classification
model predicting class future examples. ripper, classification model
learned using greedy search guided information gain metric, expressed
ordered set if-then rules. default ripper corrects noisy data. experiments
reported here, unlike reported Jordan Walker (2000), corrections noisy
data suppressed since reliability annotated features high.
Thus apply ripper, object descriptions corpus encoded terms set
classes (the output classification), set input features used predictors
classes. mentioned above, goal learn set content attributes
included object description. describe class assigned
object description, summarize features extracted dialogue
expression occurs, method applied learn predict class object description
features.
176

fiLearning Content Selection Rules Generating Object Descriptions

Class Name
CPQ
CPO
CPOQ

CP

CO
C
CQ
COQ
OQ
PO
Q
P
PQ
POQ

N
Corpus
64
56
46
42
41
32
31
18
14
13
12
11
5
4
2
2

Explicit attributes
object description
Color, Price, Quantity
Color, Price, Owner
Color, Price, Owner, Quantity
None (type only)
Color, Price
Owner
Color, Owner
Color
Color, Quantity
Color, Owner, Quantity
Owner, Quantity
Price, Owner
Quantity
Price
Price, Quantity
Price, Owner, Quantity

Figure 12: Encoding attributes included terms ML Classes, ordered frequency

4.1 Class Assignment
corpus object descriptions used construct machine learning classes
follows. learning task determine subset four attributes, color, price,
owner, quantity, include object description. Thus one method representing
class object description belongs encode object description
member category represented set attributes expressed object
description. results 16 classes representing power set four attributes
shown Figure 12. frequency class also shown Figure 12. Note
classes encodings hand annotated explicit attributes shown Figure 6
exclude type attribute since attempting model pronominal selections.
4.2 Feature Extraction
corpus used construct machine learning features follows. ripper, feature
values continuous (numeric), set-valued, symbolic. encoded discourse entity
furniture item terms set 82 total features described Section 3 inspired
theories content selection subsequent reference. features either directly
annotated humans described Section 2, derived annotated features, inherent
dialogue (Di Eugenio et al., 2000; Jordan, 2000b). dialogue context
description occurs directly represented encodings. dialogue system,
dialogue manager would access features, needed problem
solving component, would provide language generator. entire feature
set summarized Figure 13.
177

fiJordan & Walker

Assumed Familiarity Features
mutually known attributes: type-mk, color-mk, owner-mk, price-mk, quantity-mk
reference-relation: one initial, coref, set, class, cnanaphora, predicative
Inherent Features
utterance-number, speaker-pair, speaker, problem-number
attribute values:






type: one sofa, chair, table, rug, lamp, superordinate
color: one red, blue, green, yellow
owner: one self, other,
price: range $50 $600
quantity: range 0 4.

Conceptual Pact Features
interactions discourse entities: distance-last-ref, distance-last-ref-in-turns, number-prev-mentions, speaker-of-last-ref, distance-last-related
previous description: color-in-last-exp, type-in-last-exp, owner-in-last-exp, price-in-last-exp, quantityin-last-exp, type-in-last-turn, color-in-last-turn, owner-in-last-turn, price-in-last-turn, quantity-in-lastturn, initial-in-last-turn
frequency attributes: freq-type-expressed, freq-color-expressed, freq-price-expressed, freq-ownerexpressed, freq-quantity-expressed
stability history: cp-given-last-2, cp-given-last-3
Contrast Set Features
distractor frequencies: type-distractors, color-distractors, owner-distractors, price-distractors, quantitydistractors
Attribute Saliency: majority-type, majority-type-freq, majority-color, majority-color-freq, majorityprice, majority-price-freq, majority-owner, majority-owner-freq, majority-quantity, majority-quantityfreq
Intentional Influences Features
task situation: goal, colormatch, colormatch-constraintpresence, pricelimit, pricelimit-constraintpresence, priceevaluator, priceevaluator-constraintpresence, colorlimit, colorlimit-constraintpresence, priceupperlimit, priceupperlimit-constraintpresence
agreement state: influence-on-listener, commit-speaker, solution-size, prev-influence-on-listener, prevcommit-speaker, prev-solution-size, distance-of-last-state-in-utterances, distance-of-last-state-in-turns,
ref-made-in-prev-action-state, speaker-of-last-state, prev-ref-state
previous agreement state description: prev-state-type-expressed, prev-state-color-expressed, prev-stateowner-expressed, prev-state-price-expressed, prev-state-quantity-expressed
solution interactions: color-contrast, price-contrast

Figure 13: Full Feature Set Representing Basis Object Description Content Selection
Task Oriented Dialogues.

4.3 Learning Experiments
final input learning training data, i.e., representation set discourse
entities, discourse context object descriptions terms feature class
178

fiLearning Content Selection Rules Generating Object Descriptions

values. order induce rules variety feature representations, training data
represented differently different experiments.
goal experiments test contribution features suggested
three models object description content selection described Section 3. prediction
incremental intentional influences models work best
combination predicting object descriptions initial subsequent reference.
because: (1) intentional influences features capture nothing relevant
reference identification goal, focus incremental model, (2)
hypothesize problem solving state relevant selecting attributes initial
descriptions, incremental model features capture nothing directly
problem solving state, focus intentional influences model. Finally
expect conceptual pact model work best conjunction incremental
intentional influences models since overriding informativeness constraints,
since, establishing pact, may need adapt description make
efficient re-negotiate pact problem-solving situation changes.
Therefore, examples first represented using assumed familiarity features
Figure 7 establish performance baseline assumed familiarity information.
add individual feature sets assumed familiarity feature set examine
contribution feature set own. Thus, examples represented using
features specific particular model, i.e. conceptual pact features Figure 11,
contrast set features Figure 9 intentional influences features Figure 10.
Remember three different versions contrast set features, derived
three different models currently focus. One model (segment) based
intentional structure (Grosz & Sidner, 1986). two simple recency based
models active focus space either contains discourse entities
recent utterance recent five utterances (one utterance, five utterance).
addition theoretically-inspired feature sets, include task dialogue
specific inherent features Figure 8. particular features unlikely produce
rules generalize domains, including new coconut dialogues,
domain pair speakers instantiate values uniquely particular domain.
Thus, features may indicate aspects individual differences, role
specific situation models content selection object descriptions.
Next, examples represented using combinations features different
models examine interactions feature sets.
Finally, determine whether particular feature types large impact (e.g. frequency features), report results set experiments using singleton feature sets,
features varied attribute alone clustered sets rest
contain one feature. example, distractor frequency attributes Figure 9 form
cluster singleton feature set whereas utterance-number member
feature set. experimented singleton feature sets order determine
making large impact performance model feature set belong.
output machine learning experiment model object description generation domain task, learned training data. evaluate models,
error rates learned models estimated using 25-fold cross-validation, i.e. total set examples randomly divided 25 disjoint test sets, 25 runs learning
179

fiJordan & Walker

program performed. Thus, run uses examples test set training
remaining examples testing. estimated error rate obtained averaging
error rate test portion data 25 runs. sample sizes
hundreds (the coconut corpus provides 393 examples), cross-validation often provides
better performance estimate holding single test set (Weiss & Kulikowski, 1991).
major advantage cross-validation examples eventually used testing,
almost examples used given training run.

5. Experimental Results
Table 2 summarizes experimental results. feature set, combination
feature sets, report accuracy rates standard errors resulting 25-fold crossvalidation. test differences resulting accuracies using paired t-tests. table
divided regions grouping results using similar feature sets. Row 1 provides
accuracy majority class baseline 16.9%; standard baseline
corresponds accuracy achieved simply choosing description type occurs
frequently corpus, case means object description generator
would always use color, price quantity attributes describe domain entity. Row
2 provides second baseline, namely using assumed familiarity feature
set. result shows providing learner information whether
values attributes discourse entity mutually known significantly improve
performance majority class baseline (t=2.4, p< .03). Examination rest
table shows clearly accuracy learned object description generator
depends features learner available.
Rows 3 8 provide accuracies object description generators trained tested
using one additional feature sets addition familiarity feature set. Overall,
results show compared familiarity baseline, features intentional influences (familiarity,iinf t=10.0, p<.01), contrast set (familiarity,seg
t=6.1, p< .01; familiarity,1utt t=4.7, p< .01; familiarity,5utt t=4.2, p< .01),
conceptual pact (familiarity,cp t=6.2, p< .01) taken independently significantly improve performance. accuracies intentional influences features (Row 7)
significantly better conceptual pact (t=5.2, p<.01) three parameterizations incremental model (familiarity,seg t=6, p<.01; familiarity,1utt t=4.3,
p<.01; familiarity,5utt t=4.2, p<.01), perhaps indicating importance direct
representation problem solving state task.
addition, interestingly, Rows 3, 4 5 show features incremental
model based three different models discourse structure perform equally
well, i.e. statistically significant differences distractors predicted
model discourse structure based intention (seg) two recency based models
(1utt, 5utt), even though raw accuracies distractors predicted intentionbased model typically higher.6 remainder table shows intention
based model performs better recency based model combined
features (Row 15 seg vs. Row 16 1utt t=2.1, p<.05).
6. consistent findings reported Jordan (2000b) used smaller dataset measure
discourse structure model best explained data incremental model.

180

fiLearning Content Selection Rules Generating Object Descriptions

Row
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20

Model Tested
baseline
baseline
incremental
incremental
incremental
conceptual pact
intentional influences
situation specific
intentional influences,
incremental
intentional influences,
incremental
intentional influences,
incremental
theory features combined
theory features combined
theory features combined
theories
& situation specific
theories
& situation specific
theories
& situation specific
best singletons
models combined
best singletons
models combined
best singletons
models combined

Feature Sets Used
majority class
familiarity
familiarity,seg
familiarity,1utt
familiarity,5utt
familiarity,cp
familiarity,iinf
familiarity,inh

Accuracy (SE)
16.9% (2.1)
18.1% (2.1)
29.0% (2.2)
29.0% (2.5)
30.4% (2.6)
28.9% (2.1)
42.4% (2.7)
54.5% (2.3)

familiarity,iinf,seg

46.6% (2.2)

familiarity,iinf,1utt

42.7% (2.2)

familiarity,iinf,5utt
familiarity,iinf,cp,seg
familiarity,iinf,cp,1utt
familiarity,iinf,cp,5utt

44.4%
43.2%
40.9%
41.9%

(2.6)
(2.8)
(2.6)
(3.2)

familiarity,iinf,inh,cp,seg

59.9% (2.4)

familiarity,iinf,inh,cp,1utt

55.4% (2.2)

familiarity,iinf,inh,cp,5utt
familiarity,iinf,inh,cp,seg

57.6% (3.0)
52.9% (2.9)

familiarity,iinf,inh,cp,1utt

47.8% (2.4)

familiarity,iinf,inh,cp,5utt

50.3% (2.8)

Table 2: Accuracy rates content selection component object description generator using different feature sets, SE = Standard Error. cp = conceptual pact
features. iinf = intentional influences features. inh = inherent features. seg = contrast-set, segment focus space features. 1utt =
contrast set, one utterance focus space features, 5utt = contrast
set, five utterance focus space features.

Finally, situation specific model based inherent feature set (Row 8)
domain, speaker task specific performs significantly better familiarity baseline (t=16.6, p< .01). also significantly better models
utilizing theoretically motivated features. significantly better intentional
influences model (t=5, p<.01), conceptual pact model (t=9.9, p<.01),
well three parameterizations incremental model (seg t=10, p<.01; 1utt
t=10.4, p<.01; 5utt t=8.8, p<.01).
181

fiJordan & Walker

Say POQ priceupperlimit-constraintpresence = IMPLICIT reference-relation = class
Say COQ goal = SELECTCHAIRS colormatch-constraintpresence = IMPLICIT prev-solution-size =
DETERMINATE reference-relation = coref
Say COQ goal = SELECTCHAIRS distance-of-last-state-in-utterances >= 3 speaker-of-last-state = SELF
reference-relation = initial
Say COQ goal = SELECTCHAIRS prev-ref-state = STATEMENT influence-on-listener = action-directive
prev-solution-size = DETERMINATE
Say C prev-commit-speaker = commit influence-on-listener = action-directive color-contrast =
speaker-of-last-state = SELF
Say C color-contrast = yes goal = SELECTTABLE prev-influence-on-listener = action-directive influenceon-listener = na
Say C solution-size = DETERMINATE prev-influence-on-listener = na prev-state-color-expressed = yes
prev-state-price-expressed = na prev-solution-size = DETERMINATE
Say CO colorlimit = yes
Say CO price-mk = yes prev-solution-size = INDETERMINATE price-contrast = yes commit-speaker = na
Say CO price-mk = yes prev-ref-state = PARTNER-DECIDABLE-OPTION distance-of-last-state-inutterances <= 1 prev-state-type-expressed = yes
Say prev-influence-on-listener = open-option reference-relation = coref
Say influence-on-listener = info-request distance-of-last-state-in-turns <= 0
Say CP solution-size = INDETERMINATE price-contrast = yes distance-of-last-state-in-turns >= 2
Say CP distance-of-last-state-in-utterances <= 1 goal = SELECTSOFA influence-on-listener = na
reference-relation = class
Say prev-solution-size = DETERMINATE distance-of-last-state-in-turns <= 0 prev-state-type-expressed
= yes ref-made-in-prev-action-state = yes
Say prev-solution-size = DETERMINATE colormatch-constraintpresence = EXPLICIT
Say prev-solution-size = DETERMINATE goal = SELECTSOFA prev-state-owner-expressed = na
color-contrast =
Say CPOQ goal = SELECTCHAIRS prev-solution-size = INDETERMINATE price-contrast = type-mk
=
Say CPOQ distance-of-last-state-in-utterances >= 5 type-mk =
Say CPOQ goal = SELECTCHAIRS influence-on-listener = action-directive distance-of-last-state-inutterances >= 2
Say CPO influence-on-listener = action-directive distance-of-last-state-in-utterances >= 2 commit-speaker =
offer
Say CPO goal = SELECTSOFA distance-of-last-state-in-utterances >= 1
default Say CPQ

Figure 14: Sampling Rules Learned Using assumed familiarity intentional
influences Features. classes encode four attributes, e.g CPOQ =
Color,Price,Owner Quantity, = Type

Section 4.3, hypothesized incremental intentional influences
models would work best combination. Rows 9, 10 11 show results combination underlying model discourse structure. combinations
provides increase accuracy, however improvements accuracy object
description generator based intentional influences features alone (Row 7)
statistically significant.
Figure 14 shows rules object description generator learns given assumed familiarity intentional influences features. rules make use
types assumed familiarity features four types intentional influences
features. features representing mutually known attributes representing
attributes expressed previous agreement state thought overlapping
182

fiLearning Content Selection Rules Generating Object Descriptions

conceptual pact model, features representing problem-solving structure
agreement state may overlap incremental model indicating focus.
One rules rule set Figure 14 is:
Say prev-solution-size = DETERMINATE colormatch-constraintpresence
= EXPLICIT .
example dialogue excerpt matches rule shown Figure 15.
rule captures particular style problem solving dialogue conversants
talk explicitly points involved matching colors (we get 650 points without
rug bluematch living room) argue including particular item (rug).
case, solution proposed, feature prev-solution-size value
determinate. rule describes contexts solution counterproposed, support counter-proposal presented.
D: suggest buy blue sofa 300, 1 table high green 200, 2 chairs red 50, 2
chairs red 50 decide rest. think
J: 3 chair green high table green 200 1 chair green 100. sofa blue 300 rug blue
250. get 700 point. 200 sofa livingroom plus rug 10. 20 points match. 50 points
match dining room plus 20 spending all. red chairs plus red table costs 600. get 650
points without rug bluematch living room. add tell think.

Figure 15: Example discourse excerpt matches rule intentional influences assumed familiarity rule set

Rows 12, 13 14 Table 2 contain results combining conceptual pact
features intentional influences features contrast set features.
results directly compared Rows 9, 10 11. ripper uses heuristic search, additional features effect making accuracies
resulting models lower. However, none differences statistically significant. Taken together, results Rows 9-14 indicate best accuracies obtainable
without using situation specific features (the inherent feature set), combination
intentional influences contrast set features, best overall accuracy
46.6% shown Row 9.
Rows 15, 16 17 contain results combining features, including
inherent feature set, underlying model discourse structure. time
one significant difference underlying discourse models intentionbased model, segment, significantly better one utterance recency model
(t=2.1, p<.05) five utterance recency model. models group
segment model significantly better models use subset
features (vs. inherent t=2.4, p<.03). Figure 16 shows generation rules learned
best performing feature set shown Row 15. Many task, entity speaker specific
features inherent feature set used rules. rule set performs
59.9% accuracy, opposed 46.6% accuracy general feature set (shown
Row 9). final rule set, conceptual pact features used removing
183

fiJordan & Walker

Say Q type=CHAIR price>=200 reference-relation=set quantity>=2.
Say Q speaker=GARRETT color-distractors<=0 type=CHAIR.
Say PO color=unk speaker-pair=GARRETT-STEVE reference-relation=initial color-contrast=no.
Say PO majority-color-freq>=6 reference-relation=set.
Say PO utterance-number>=39 type-distractors<=0 owner=SELF price>=100.
Say OQ color=unk quantity>=2 majority-price-freq<=5.
Say OQ prev-state-quantity-expressed=yes speaker=JULIE color=RED.
Say COQ goal=SELECTCHAIRS price-distractors<=3 owner=SELF distance-of-last-state-inutterances>=3 majority-price<=200.
Say COQ quantity>=2 price<=-1 ref-made-in-prev-action-state=no.
Say COQ quantity>=2 price-distractors<=3 quantity-distractors>=4 influence-on-listener=action-directive.
Say CQ speaker-pair=DAVE-GREG utterance-number>=22 utterance-number<=27 problem<=1.
Say CQ problem>=2 quantity>=2 price<=-1.
Say CQ color=YELLOW quantity>=3 influence-on-listener=action-directive type=CHAIR.
Say C price-mk=yes majority-type=SUPERORDINATE quantity-distractors>=3.
Say C price-mk=yes utterance-number<=21 utterance-number>=18 prev-state-price-expressed=na
majority-price>=200 color-distractors>=2.
Say CO utterance-number>=16 price<=-1 type=CHAIR.
Say CO price-mk=yes speaker-pair=JILL-PENNY.
Say CO majority-price<=75 distance-of-last-state-in-utterances>=4 prev-state-type-expressed=na.
Say color=unk speaker-pair=GARRETT-STEVE.
Say color=unk owner=OTHER price<=300.
Say prev-influence-on-listener=open-option utterance-number>=22.
Say CP problem>=2 quantity<=1 type=CHAIR.
Say CP price>=325 reference-relation=class distance-of-last-state-in-utterances<=0.
Say CP speaker-pair=JON-JULIE type-distractors<=1.
Say CP reference-relation=set owner=OTHER owner-distractors<=0.
Say prev-solution-size=DETERMINATE price>=250 color-distractors<=5 owner-distractors>=2
utterance-number>=15.
Say color=unk.
Say prev-state-type-expressed=yes distance-of-last-state-in-turns<=0 owner-distractors<=4.
Say CPOQ goal=SELECTCHAIRS prev-solution-size=INDETERMINATE.
Say CPOQ speaker-pair=KATHY-MARK prev-solution-size=INDETERMINATE owner-distractors<=5.
Say CPOQ goal=SELECTCHAIRS influence-on-listener=action-directive utterance-number<=22.
Say CPO utterance-number>=11 quantity<=1 owner-distractors>=1.
Say CPO influence-on-listener=action-directive price>=150.
Say CPO reference-relation=class problem<=1.
default Say CPQ

Figure 16: Sampling Best Performing Rule Set. Learned using assumed familiarity, inherent, intentional influences contrast set feature
sets. classes encode four attributes, e.g., CPOQ = Color,Price,Owner
Quantity, = Type only.

features training effect accuracy. types features
assumed familiarity, inherent, contrast set used. intentional
influences features, mainly agreement state previous agreement state descriptions
used. possible explanations agreement state stronger influence
task situation task situation modelled well.
use inherent feature set contribute much overall accuracy
many inherent features used rule set Figure 16? may
inherent features objects would important domain lot
domain specific reasoning task object description content selection. However,
features likely support rules overfit current data set;
184

fiLearning Content Selection Rules Generating Object Descriptions

said before, rules based inherent feature set unlikely generalize new
situations. However, might general abstract versions features
could generalize new situations. example, attribute values discourse
entity may capturing aspects problem solving (e.g. near end problem,
price expensive items highly relevant). Second, use utterance-numbers
characterized rules beginning, middle end dialogue may
reflect problem solving progress. Third, rules involving problem-number suggest
behavior first problem different others may reflect
dialogue partners reached agreement problem solving strategy. Finally,
use speaker-pair features rules included two possible speakerpairs, may reflect differences agreements reached collaborate. One
rules rule set shown below:
Say CP price >= 325 reference-relation = class distance-of-last-statein-utterances <= 0.
rule applies discourse entities dialogues one speaker pair. example
dialogue excerpt matches rule Figure 17. rule reflects particular style
describing items available use problem solving, speaker
first describes class items listed. style description
allows speaker efficiently list available. distance-of-last-state-inutterances feature captures style description occurs proposals
made.
M: $550, inventory consists 2 Yellow hi-tables $325 each. Sofas, yellow $400
green $350.

Figure 17: Example dialogue excerpt matches rule best performing rule
set

described above, also created singleton feature sets, addition theoretically inspired feature sets, determine singleton features are, themselves, making
large impact performance model belongs to. singleton features shown
Table 3 resulted learned models significantly majority class baseline. last column Table 3 also shows that, except assumed familiarity
incremental 5utt models, theory model particular singleton feature belongs significantly better, indicating singleton alone better predictor
combined features theoretical models. assumed familiarity incremental 5utt models perform similarly corresponding single feature models indicating
single features highly useful features two models.
Finally, combined singleton features Table 3 learn three additional
models shown Rows 18, 19 20 Table 2. three models significantly
different one another. best performing model Row 15, combines
185

fiJordan & Walker

Source
Model
assumed familiarity
conceptual
pact

Features Set

type-mk, color-mk, owner-mk,
price-mk, quantity-mk
freq-type-expressed, freq-colorexpressed, freq-price-expressed,
freq-owner-expressed,
freqquantity-expressed
cp-given-last-2
type-in-last-exp, color-in-lastexp, price-in-last-exp, owner-inlast-exp, quantity-in-last-exp
type-in-last-turn,
color-inlast-turn,
price-in-last-turn,
owner-in-last-turn, quantity-inlast-turn
incremental type-distractors,
colorseg
distractors, price-distractors,
owner-distractors,
quantitydistractors
majority-type, majority-color,
majority-price, majority-owner,
majority-quantity
incremental type-distractors,
color1utt
distractors, price-distractors,
owner-distractors,
quantitydistractors
incremental type-distractors,
color5utt
distractors, price-distractors,
owner-distractors,
quantitydistractors
intentional distance-of-last-state-ininfluences
utterances
distance-of-last-state-in-turns
colormatch
prev-state-type-expressed,
prev-state-color-expressed,
prev-state-owner-expressed,
prev-state-price-expressed,
prev-state-quantity-expressed
situation
type, color, price, owner, quanspecific
tity
utterance-number

Accuracy
(SE)
18.1% (2.1)

Better
baseline
t=2.4, p<.03

Source Model
Better
identical

22.1% (1.8)

t=3.7, p<.01

t=5.7, p<.01

20.9% (2.1)
18.9% (1.9)

t=3.9, p<.01
t=2.8, p<.02

t=4.3, p<.01
t=5.7, p<.01

18.1% (2.0)

t=3.4, p<.02

t=6.4, p<.01

21.4% (2.5)

t=3.2, p<.01

t=3.6, p<.01

19.9% (2.3)

t=2.5, p<.02

t=4.8, p<.01

20.8% (2.4)

t=3.2, p<.01

t=3.2, p<.01

25.7% (2.7)

t=4.4, p<.01

t=1.5, NS

21.3% (2.0)

t=3.7, p<.01

t=11, p<.01

20.0% (2.1)
19.3% (2.2)
19.2% (1.9)

t=3.6, p<.01
t=3.7, p<.01
t=3.6, p<.01

t=10.2, p<.01
t=10.3, p<.01
t=8.8, p<.01

24.3% (2.5)

t=4.1, p<.01

t=12.5, p<.01

20.5% (2.3)

t=3.3, p<.01

t=16.2, p<.01

Table 3: Performance using singleton feature sets, SE = Standard Error

features, significantly better 1utt (t=4.2, p<.01) 5utt (t=2.8, p<.01) Rows
19 20, significantly different seg (t=2.0, NS) Row 18. combined
singletons seg model (Row 18) also significantly different inherent model
186

fiLearning Content Selection Rules Generating Object Descriptions

(Row 8). combined singletons seg model advantage requires two
situation specific features smaller set theoretical features.
Class
CPQ
CPO
CPOQ

CP

CO
C
CQ
COQ
PO
OQ
Q
POQ
PQ

recall
100.00
66.67
100.00
50.00
100.00
100.00
66.67
0.00
0.00
100.00
50.00
66.67
0.00
0.00
0.00

precision
63.64
100.00
100.00
100.00
100.00
60.00
100.00
0.00
100.00
100.00
100.00
50.00
0.00
100.00
100.00

fallout
12.12
0.00
0.00
0.00
0.00
5.41
0.00
5.13
0.00
0.00
0.00
5.41
2.50
0.00
0.00

F (1.00)
0.78
0.80
1.00
0.67
1.00
0.75
0.80
0.00
0.00
1.00
0.67
0.57
0.00
0.00
0.00

Table 4: Recall Precision values class; rows ordered frequent
least frequent class

Class
CPQ

COQ
C
CPO
CO
PO

OQ
POQ
CPOQ
Q
CP
PQ
CQ

CPQ
7
0
0
1
0
1
0
0
0
0
0
0
0
1
1


0
3
0
0
1
0
1
0
0
0
0
0
0
0
0

COQ
0
0
2
0
0
0
0
0
0
0
0
0
0
0
0

C
0
0
0
0
1
0
0
1
0
0
0
0
0
0
0

CPO
0
0
0
0
4
0
0
0
0
0
0
0
0
0
0

CO
0
0
0
0
0
2
0
0
0
0
0
0
0
0
0

PO
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0


0
0
0
0
0
0
0
1
0
0
0
0
0
0
0

OQ
0
0
0
0
0
0
0
0
2
1
0
0
0
1
0

POQ
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0

CPOQ
0
0
0
0
0
0
0
0
0
0
6
0
0
0
0

Q
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0

CP
0
0
0
0
0
0
0
0
0
0
0
0
1
0
0

PQ
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0

CQ
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0

Table 5: Confusion matrix held-out test set; row label indicates class,
column indicates token classified automatically.

Tables 4 5 show recall precision class sample confusion matrix
one run best performing model held-out test-set consisting 40 examples.
Table 4 shows overall tendency recall precision higher
classes frequent, lower less frequent classes one would expect.
Table 5 shows arent significant sources confusion errors spread
across different classes.
187

fiJordan & Walker

6. Discussion Future Work
article reports experimental results training generator learn attributes
discourse entity include object description. knowledge,
first reported experiment trainable content selection component object description
generation dialogue. unique feature study use theoretical work
cognitive science speakers select content object description. theories
used inspire development features machine learner based Brennan
Clarks (1996) model, Dale Reiters (1995) model Jordans (2000b) model.
Dale Reiters model relies model discourse structure, developed
features represent Grosz Sidners (1986) model discourse structure, well
features representing two simple recency based models discourse structure. object
description generators trained coconut corpus task-oriented dialogues.
results show that:
best performing learned object description generator achieves 60% match
human performance opposed 17% majority class baseline;
assumed familiarity feature set improves performance baseline;
Features specific task, speaker discourse entity (the inherent feature set)
provide significant performance improvements;
conceptual pact feature set developed approximate Brennan Clarks
model object description generation significantly improves performance
baseline assumed familiarity;
contrast set features developed approximate Dale Reiters model significantly improve performance baseline assumed familiarity;
intentional influences features developed approximate Jordans model
best performing theoretically-inspired feature set taken alone,
combination intentional influences features contrast set features best performing theoretically-based models. combined model
achieves accuracy 46.6% exact match human performance holds
promise general across domains tasks include
inherent features.
Tests using singleton feature sets model showed frequency features
attributes last used impact conceptual pact model,
distractor set features important incremental models, features related state biggest impact intentional influences model.
none singleton features perform well feature combinations
related model.
model consisting combination best singleton features
models significantly different best learned object description
generator achieved 53% match human performance advantage
fewer situation specific features.
188

fiLearning Content Selection Rules Generating Object Descriptions

Thus choice use theoretically inspired features validated, sense every
set cognitive features improves performance baseline.
previous work, presented results similar set experiments, best
model object description generation achieved accuracy 50% (Jordan & Walker,
2000). accuracy improvements reported due number new features
derived corpus, well modification machine learning algorithm
respect fact training data experiments noisy.
hard say good best-performing accuracy 60% actually
one first studies kind. several issues consider. First, object
descriptions corpus may represent one way describe entity point
dialogue, using human performance standard evaluate
learned object description generators provides overly rigorous test (Oberlander, 1998;
Reiter, 2002). Furthermore, know whether humans would produce identical object
descriptions given discourse situation. previous study anaphor generation
Chinese showed rates match human speakers averaged 74% problem
(Yeh & Mellish, 1997), results comparable that. Furthermore, results
show including features specific speaker attribute values improves performance
significantly. conclusion may important quantify best performance
human could achieve matching object descriptions corpus, given
complete discourse context identity referent. addition, difficulty
problem depends number attributes available describing object
domain; object description generator correctly make four different decisions
achieve exact match human performance. Since coconut corpus publicly
available, hope researchers improve results.
Another issue must considered extent experiments
taken test theories inspired feature sets. several reasons
cautious making interpretations. First, models developed explain
subsequent reference initial reference. Second, feature sets cannot claimed
way complete. possible features could developed provide
better representation theories. Finally, ripper propositional learner,
models object description generation may representable propositional
theory. example, models object description generation rely representation
discourse context form type discourse model. features utilized
represent discourse context capture aspects discourse history,
representations rich used rule-based implementation. However
interesting note whatever limitations models may have, automatically
trained models tested perform better rule-based implementations
theoretical models, reported Jordan (2000b).
Another issue extent findings might generalize across domains.
always issue empirical work, one potential limitation study
Jordans model explicitly developed capture features specific negotiation
dialogues coconut corpus. Thus, possible features
inspired theory better fit data. conceptual pact features
less prominent coconut data data thus inspired new model, expect
find types dialogue inspire additional features feature representations.
189

fiJordan & Walker

Finally, unique contribution work experimental comparison different
representations discourse structure task object description generation.
tested three representations discourse structure, one represented features derived
Grosz Sidners model, two recency based representations. One
surprising results work finding features based Grosz Sidners
model improve performance extremely simple models based recency.
could due issues discussed Walker (1996a), namely human working memory
processing limitations play much larger role referring expression generation
interpretation would suggested operations Grosz Sidners focus space
model. However could also due much mundane reasons, namely
possible (again) feature sets adequate representations discourse
structure model differences, differences found would statistically significant
corpus much larger. However, results discourse structure model
differences reported confirm findings reported Jordan (2000b), i.e. also
true focus space model perform better simple recency models
Jordans rule-based implementations.
future work, plan perform similar experiments different corpora different communications settings problem types (e.g. planning, scheduling, designing)
determine whether findings specific genre dialogues examine here,
whether general models applied directly new domain. Related
question generality, created binary attribute inclusion model using domain
independent feature sets yet new annotated corpus upon test it.

Acknowledgments
Thanks William Cohen helpful discussions use ripper problem,
three anonymous reviewers provided many helpful suggestions improving
paper.

References
Allen, J., & Core, M. (1997). Draft DAMSL: Dialog act markup several layers. Coding scheme developed MultiParty group, 1st Discourse Tagging Workshop,
University Pennsylvania, March 1996.
Appelt, D. (1985a). Planning English Sentences. Studies Natural Language Processing.
Cambridge University Press.
Appelt, D. E. (1985b). pragmatic issues planning definite indefinite
noun phrases. Proceedings 23rd ACL, pp. 198203.
Bangalore, S., & Rambow, O. (2000). Exploiting probabilistic hierarchical model
Generation. COLING, pp. 4248, Saarbucken, Germany.
Brennan, S. E., & Clark, H. H. (1996). Lexical choice conceptual pacts conversation.
Journal Experimental Psychology: Learning, Memory Cognition, 22, 1482
1493.
190

fiLearning Content Selection Rules Generating Object Descriptions

Clark, H. H., & Wilkes-Gibbs, D. (1986). Referring collaborative process. Cognition,
22, 139.
Cohen, W. (1996). Learning trees rules set-valued features. Fourteenth Conference American Association Artificial Intelligence, pp. 709716.
Daelemans, W., & Hoste, V. (2002). Evaluation machine learning methods natural language processing tasks. Proceedings LREC-2002, 3rd International
Language Resources Evaluation Conference, pp. 755760.
Dale, R. (1992). Generating Referring Expressions. ACL-MIT Series Natural Language
Processing. MIT Press.
Dale, R., & Reiter, E. (1995). Computational Interpretations Gricean Maxims
Generation Referring Expressions. Cognitive Science, 19 (2), 233263.
Di Eugenio, B., Jordan, P. W., Thomason, R. H., & Moore, J. D. (2000). agreement
process: empirical investigation human-human computer-mediated collaborative
dialogues. International Journal Human-Computer Studies, 53 (6), 10171076.
Di Eugenio, B., Moore, J. D., & Paolucci, M. (1997). Learning features predict cue
usage. Proceedings 35th Annual Meeting Association Computational
Linguistics, ACL/EACL 97, pp. 8087.
Di Eugenio, B., & Webber, B. (1996). Pragmatic overloading natural language instructions. International Journal Expert Systems, Special Issue Knowledge Representation Reasoning Natural Language Processing, 9 (1), 5384.
Duboue, P. A., & McKeown, K. R. (2001). Empirically estimating order constraints
content planning generation. Proceedings 39rd Annual Meeting
Association Computational Linguistics (ACL/EACL-2001).
Gardent, C. (2002). Generating minimal definite descriptions. Proceedings Association
Computational Linguistics 2002, pp. 96103.
Grice, H. (1975). Logic conversation. Cole, P., & Morgan, J. (Eds.), Syntax
Semantics III - Speech Acts, pp. 4158. Academic Press, New York.
Grosz, B. J., & Sidner, C. L. (1986). Attention, intentions structure discourse.
Computational Linguistics, 12, 175204.
Heeman, P. A., & Hirst, G. (1995). Collaborating referring expressions. Computational
Linguistics, 21 (3), 351383.
Heim, I. (1983). File change semantics familiarity theory definiteness. Bauerle,
R., Schwarze, C., & von Stechow, A. (Eds.), Meaning, use, interpretation
language, pp. 164189. Walter de Gruyter, Berlin.
Hirschberg, J. B. (1993). Pitch accent context: predicting intonational prominence
text. Artificial Intelligence Journal, 63, 305340.
Jordan, P., & Walker, M. A. (2000). Learning attribute selections non-pronominal
expressions. Proceedings 38th Annual Meeting Association
Computational Linguistics (ACL-00), Hong Kong, pp. 181190.
191

fiJordan & Walker

Jordan, P. W. (2000a). Influences attribute selection redescriptions: corpus study.
Proceedings CogSci2000, pp. 250255.
Jordan, P. W. (2000b). Intentional Influences Object Redescriptions Dialogue: Evidence Empirical Study. Ph.D. thesis, Intelligent Systems Program, University
Pittsburgh.
Jordan, P. W. (2002). Contextual influences attribute selection repeated descriptions.
van Deemter, K., & Kibble, R. (Eds.), Information Sharing: Reference Presupposition Language Generation Interpretation, pp. 295328. CSLI Publications.
Kamp, H., & Reyle, U. (1993). Discourse Logic; Introduction Modeltheoretic
Semantics Natural Language, Formal Logic Discourse Representation Theory.
Kluwer Academic Publishers, Dordrecht Holland.
Karttunen, L. (1976). Discourse referents. McCawley, J. (Ed.), Syntax Semantics,
Vol. 7, pp. 363385. Academic Press.
Krahmer, E., van Erk, S., & Verleg, A. (2003). Graph-Based generation referring expressions. Computational Linguistics, 29 (1), 5372.
Krippendorf, K. (1980). Content Analysis: Introduction Methodology. Sage Publications, Beverly Hills, Ca.
Kronfeld, A. (1986). Donnellans distinction computational model reference.
Proceedings 24th ACL, pp. 186191.
Langkilde, I., & Knight, K. (1998). Generation exploits corpus-based statistical knowledge. Proceedings COLING-ACL, pp. 704710.
Lochbaum, K. (1995). use knowledge preconditions language processing.
IJCAI95, pp. 12601266.
Malouf, R. (2000). order prenominal adjectives natural language generation.
Proceedings Meeting Association Computational Lingustics, ACL
2000, pp. 8592.
Mellish, C., Knott, A., Oberlander, J., & ODonnell, M. (1998). Experiments using stochastic search text planning. Proceedings International Conference Natural
Language Generation, pp. 97108.
Oberlander, J. (1998). right thing...but expect unexpected. Computational
Linguistics, 24 (3), 501508.
Oh, A. H., & Rudnicky, A. I. (2002). Stochastic natural language generation spoken
dialog systems. Computer Speech Language: Special Issue Spoken Language
Generation, 16 (3-4), 387407.
Passonneau, R. J. (1995). Integrating Gricean Attentional Constraints. Proceedings
IJCAI 95, pp. 12671273.
Passonneau, R. J. (1996). Using Centering Relax Gricean Informational Constraints
Discourse Anaphoric Noun Phrases. Language Speech, 32 (2,3), 229264.
Pickering, M., & Garrod, S. (2004). Toward mechanistic psychology dialogue. Behavioral
Brain Sciences, 27 (2), 169226.
192

fiLearning Content Selection Rules Generating Object Descriptions

Poesio, M. (2000). Annotating corpus develop evaluate discourse entity realization algorithms: issues preliminary results. Proc. Language Resources
Evaluation Conference, LREC-2000, pp. 211218.
Pollack, M. E. (1991). Overloading intentions efficient practical reasoning. Nous, 25,
513 536.
Prince, E. F. (1981). Toward taxonomy given-new information. Radical Pragmatics,
pp. 223255. Academic Press.
Radev, D. R. (1998). Learning correlations linguistic indicators semantic
constraints: Reuse context-dependent decsriptions entities. COLING-ACL,
pp. 10721078.
Ratnaparkhi, A. (2002). Trainable approaches surface natural language generation
application conversational dialog systems. Computer Speech Language:
Special Issue Spoken Language Generation, 16 (3-4), 435455.
Reiter, E. (1990). Generating appropriate natural language object descriptions. Tech. rep.
TR-10-90, Department Computer Science, Harvard University. Dissertation.
Reiter, E. (2002). corpora gold standards NLG?. Proceedings 11th
International Workshop Natural Language Generation, pp. 97104.
Roy, D. K. (2002). Learning visually grounded words syntax scene description
task. Computer Speech Language: Special Issue Spoken Language Generation,
16 (3-4), 353385.
Stone, M., & Webber, B. (1998). Textual economy close coupling syntax
semantics. Proceedings 1998 International Workshop Natural Language Generation, pp. 178187, Niagra-on-the-Lake, Canada.
Terken, J. M. B. (1985). Use Function Accentuation: Experiments. Ph.D.
thesis, Institute Perception Research, Eindhoven, Netherlands.
van Deemter, K. (2002). Generating referring expressions: Boolean extensions incremental algorithm. Computational Linguistics, 28 (1), 3752.
Varges, S., & Mellish, C. (2001). Instance-based natural language generation. Proceedings
North American Meeting Association Computational Linguistics, pp.
18.
Walker, M., Rambow, O., & Rogati, M. (2002). Training sentence planner spoken
dialogue using boosting. Computer Speech Language: Special Issue Spoken
Language Generation, 16 (3-4), 409433.
Walker, M. A. (1996a). Limited attention discourse structure. Computational Linguistics, 22-2, 255264.
Walker, M. A. (1996b). Effect Resource Limits Task Complexity Collaborative
Planning Dialogue. Artificial Intelligence Journal, 85 (12), 181243.
Webber, B. L. (1978). Formal Approach Discourse Anaphora. Ph.D. thesis, Harvard
University. New York:Garland Press.
193

fiJordan & Walker

Weiss, S. M., & Kulikowski, C. (1991). Computer Systems Learn: Classification
Prediction Methods Statistics, Neural Nets, Machine Learning, Expert Systems. San Mateo, CA: Morgan Kaufmann.
Yeh, C.-L., & Mellish, C. (1997). empirical study generation anaphora
chinese. Computational Linguistics, 23-1, 169190.

194

fiJournal Articial Intelligence Research 24 (2005) 357-406

Submitted 12/04; published 09/05

Pure Nash Equilibria: Hard Easy Games
Georg Gottlob

gottlob@dbai.tuwien.ac.at

Information Systems Department,
Technische Universitat Wien,
A-1040 Wien, Austria

Gianluigi Greco

ggreco@mat.unical.it

Dipartimento di Matematica,
Universita della Calabria,
I-87030 Rende, Italy

Francesco Scarcello

scarcello@deis.unical.it

DEIS,
Universita della Calabria,
I-87030 Rende, Italy

Abstract
investigate complexity issues related pure Nash equilibria strategic games.
show that, even restrictive settings, determining whether game pure Nash
Equilibrium NP-hard, deciding whether game strong Nash equilibrium
P
2 -complete. study practically relevant restrictions lower complexity.
particular, interested quantitative qualitative restrictions way
players payo depends moves players. say game small neighborhood utility function player depends (the actions of) logarithmically
small number players. dependency structure game G expressed
graph G(G) hypergraph H(G). relating Nash equilibrium problems
constraint satisfaction problems (CSPs), show G small neighborhood
H(G) bounded hypertree width (or G(G) bounded treewidth), nding pure
Nash Pareto equilibria feasible polynomial time. game graphical,
problems LOGCFL-complete thus class NC2 highly parallelizable
problems.

1. Introduction Overview Results
theory strategic games Nash equilibria important applications economics
decision making (Nash, 1951; Aumann, 1985). Determining whether Nash equilibria exist, eectively computing them, relevant problems attracted much
research computer science (e.g. Deng, Papadimitriou, & Safra, 2002; McKelvey & McLennan, 1996; Koller, Megiddo, & von Stengel, 1996). work dedicated complexity issues related mixed equilibria games mixed strategies, players
choices deterministic regulated probability distributions. context, existence Nash equilibrium guaranteed Nashs famous theorem (Nash,
1951), currently open whether equilibrium computed polynomial
time (cf., Papadimitriou, 2001). First results computational complexity twoperson game presented Gilboa Zemel (1989), extensions
general types games provided Megiddo Papadimitriou (1991),
c
2005
AI Access Foundation. rights reserved.

fiGottlob, Greco, Scarcello

Papadimitriou (1994b). recent paper Conitzer Sandholm (2003b) also proved
NP-hardness determining whether Nash equilibria certain natural properties exist.
present paper, dealing mixed strategies, rather investigate
complexity deciding whether exists Nash equilibrium case pure strategies,
player chooses play action deterministic, non-aleatory manner. Nash
equilibria pure strategies briey referred pure Nash equilibria. Note
setting pure strategies, pure Nash equilibrium guaranteed exist (see,
instance, Osborne & Rubinstein, 1994). Particular classes games pure Nash
equilibria studied Rosenthal (1973), Monderer Shapley (1993),
Fotakis et al. (2002). Recently, Fabrikant el. (2004) renewed interest class
games dened Rosenthal (1973), called congestion games, showing pure Nash
equilibrium computed polynomial time symmetric network case,
problem PLS-complete (Johnson, Papadimitriou, & Yannakakis, 1998) general.
goal study fundamental questions existence pure Nash, Pareto,
strong Nash equilibria, computation equilibria, nd arguably realistic
restrictions problems become tractable. Throughout paper, Pareto
strong Nash equilibria considered setting pure strategies.
pure strategies conceptually simpler mixed strategies, associated
computational problems appear harder. fact, show even severe restrictions imposed set allowed strategies, determining whether game pure
Nash Pareto Equilibrium NP-complete, deciding whether game strong
Nash equilibrium even P2 -complete. However, jointly applying suitable pairs
realistic restrictions, obtain settings practical interest complexity
problems drastically reduced. particular, determining existence pure
Nash equilibrium computing equilibrium feasible polynomial time
show that, certain cases, problems even complete low
complexity class LOGCFL, means problems essentially easy
membership problem context-free languages, thus highly parallelizable (in NC2 ).
setting pure strategies, restrict attention rest
paper, nite strategic game one player nite set possible
actions, chooses action all, independently actual
choices players. choices players thus thought made
simultaneously. choice action player referred players strategy.
assumed player perfect knowledge possible actions
possible strategies players. global strategy, also called profile literature,
consists tuple containing strategy player. player polynomial-time
computable real valued utility function, allows assess subjective utility
possible global strategy (global strategies higher utility better). pure Nash
equilibrium (Nash, 1951) global strategy player improve utility
changing action (while actions players remain unchanged). strong
Nash equilibrium (Aumann, 1959) pure Nash equilibrium change strategies
whatever coalition (i.e., group players) simultaneously increase utility
players coalition. pure Nash equilibrium Pareto optimal (e.g. Maskin, 1985)
game admits pure Nash equilibrium player strictly higher
utility. Pareto-optimal Nash equilibrium also called Pareto Nash Equilibrium.
358

fiPure Nash Equilibria: Hard Easy Games

describing complexity results, let us discuss various parameters features
lead restricted versions strategic games. consider restrictions strategic
games impose quantitative and/or qualitative limitations payos
agent (and hence decisions) may inuenced agents.
set neighbors Neigh(p) player set players potentially
matter w.r.t. ps utility function. Thus, whenever player q = p Neigh(p) ps
utility function directly depend actions q. assume game
equipped polynomial-time computable function Neigh property.1
player neighborhood relationship, typically represented graph (or hypergraph),
central notion graphical games (Koller & Milch, 2001; Kearns, Littman, & Singh,
2001b), see detail next section.
rst idea towards identication tractable classes games restrict
cardinality Neigh(p) players p. instance, consider set companies
market. company usually limited number market players
bases strategic decisions. relevant players usually known constitute
neighbors company setting. However, note even case game
outcome still depends interaction players, though possibly indirect way.
Indeed, choice company inuences choice competitors, hence, turn,
choice competitors competitors, on. general setting,
number real-world cases modeled natural way. thus dene
following notion limited neighborhood:
Bounded Neighborhood: Let k > 0 xed constant. strategic game associated neighborhood function Neigh k-bounded neighborhood if, player p,
|Neigh(p)| k .
setting bounded neighborhood assumption realistic, settings constant bound appears harsh imposition. much realistic
appealing relax constraint consider logarithmic bound rather constant bound number neighbors.
Small Neighborhood: game G denote P (G) set players, Act(p)
set possible actions player p, ||G|| total size description
game G (i.e., input size n). Furthermore, let maxNeigh(G) = maxpP (G) |Neigh(p)|
maxAct (G) = maxpP (G) |Act(p)|.
class strategic games small neighborhood if, game G class,
maxNeigh(G) = (

log ||G||
)
log maxAct (G)

Note denominator log maxAct(G) bound. Intuitively, use term
avoid cheating trading actions neighbors. Indeed, roughly speaking, player
interactions may reduced signicantly adding exponential amount additional
actions. player, fresh actions may encode possible action congurations
1. Note game trivially represented setting, possibly setting Neigh(p)
set players, player p. cases, however, one able provide much better
neighborhood function.

359

fiGottlob, Greco, Scarcello

Figure 1: Dependency hypergraph dependency graph game G.
neighbors, yielding equivalent game less interaction, possibly
fewer players, too. denominator takes account.
terms, class games small neighborhood constant c
||G||
nitely many pairs (G, p) games players, |Neigh(p)| < c ( loglog
|Act(p)| ).
related notion i(G) intricacy game dened by:
i(G) =

maxNeigh(G) log maxAct (G)
.
log ||G||

clear class games small neighborhood intricacy
games bounded constant.
Obviously, bounded neighborhood implies small neighborhood, vice-versa.
believe large number important (classes of) games economics
small neighborhood property.
addition quantitative aspect size neighborhood (and neighborhood actions), also interested qualitative aspects mutual strategic inuence.
Following Kearns et al. (2001b), game G set P players, dene strategic dependency graph undirected graph G(G) P set vertices
{{p, q} | q P p Neigh(q)} set edges. Moreover, dene strategic dependency hypergraph H(G), whose vertices players P whose set hyperedges
{{p} Neigh(p) | p P }. instance, consider game G players A, B, C,
Neigh(A) = {B, C }, Neigh(B) = {A, C }, Neigh(C ) = {A, B}, Neigh(D ) = {C }.
Figure 1 shows dependency graph dependency hypergraph associated G.
consider following classes structurally restricted games:
Acyclic-Graph Games:

Games G G(G) acyclic.

Acyclic-Hypergraph Games: Games G H(G) acyclic. Note
several denitions hypergraph acyclicity (Fagin, 1983). refer broadest
(i.e., general) one, also known -acyclicity (Fagin, 1983; Beeri, Fagin, Maier,
& Yannakakis, 1983) (see Section 2).
acyclic-graph game also acyclic-hypergraph game, vice-versa.
extreme example, let G game player set P utility action
player depends players. G(G) clique size |P | H(G)
trivially acyclic hypergraph hyperedge {P }.
strategic games, acyclic graph acyclic hypergraph assumptions
severe restrictions, rather unlikely apply practical contexts. However,
360

fiPure Nash Equilibria: Hard Easy Games

important generalizations appear much realistic practical
applications. concepts bounded treewidth (Robertson & Seymour, 1986)
bounded hypertree width (Gottlob, Leone, & Scarcello, 2002b) (see also Section 5),
suitable measures degree cyclicity graph hypergraph, respectively.
particular, acyclic graph (hypergraph) treewidth (hypertree width) 1.
argued impressive number real-life graphs low treewidth (Downey
& Fellows, 1995). Hypertree width turn fruitfully applied context database
queries (Gottlob et al., 2002b) constraint satisfaction problems (Gottlob, Leone, &
Scarcello, 2000). Formal denitions given Section 5. Note computing
treewidth graph hypertree width hypergraph NP-hard problems.
However, (xed) constant k, checked polynomial time whether
graph treewidth k (Bodlaender, 1997) whether hypergraph hypertree width
k (Gottlob et al., 2002b). have, constant k, following restricted classes
games:
Games treewidth bounded k:
k.

games G treewidth G(G)

Games hypertree width bounded k: games G hypertree
width H(G) k.
context complexity eciency studies, important make clear
input (in case, multiplayer game) represented. say game
general form sets players actions given extensional form
neighborhood utility functions polynomially computable functions. Unless
otherwise stated, always assume games given general form. classes
games particular properties, alternative representations used
various authors. instance, game theory literature, set utility functions often
represented single table (or matrix) entry combination
players actions containing, player p, evaluation utility function
particular combination. representation said standard normal form (SNF)
(see, instance, Osborne & Rubinstein, 1994; Owen, 1982). Note that, many
players, representation may space consuming, particularly players
interested players, subset them. Moreover, case,
monolithic utility table SNF obscures much structure present realworld games (Koller & Milch, 2001). fact, context games restricted players
interactions, used representation graphical normal form (GNF). GNF
games, also known graphical games (Kearns, Littman, & Singh, 2001a; Kearns et al.,
2001b; Kearns & Mansour, 2002; Vickrey, 2002), utility function player p
given table displays ps utility function possible combined strategies
p ps neighbors, players irrelevant p. Therefore, large population
games (modeling instance agent interactions internet), SNF practically
unfeasible, succinct graphical normal form works well, actually
natural representation.
Main results.

main results paper summarized follows:
361

fiGottlob, Greco, Scarcello

Determining whether strategic game pure Nash equilibrium NP-complete
remains NP-complete even following two restricted cases:
Games graphical normal form (GNF) bounded neighborhood (Theorem 3.1).
Acyclic-graph games, acyclic-hypergraph games (Theorem 3.2).
results hold Pareto Nash equilibria pure strategies.
Determining whether strategic game strong Nash equilibrium p2 -complete
thus second level Polynomial Hierarchy (Theorem 3.7 Theorem 3.8). proof theorem gives us fresh game-theoretic view class
P2 class problems whose positive instances characterized coalition
players cooperate provide equilibrium, win disjoint coalition, fails trying improve utility players. E.g.,
case 2 quantied Boolean formulas, former coalition consists
existentially quantied variables, latter universally quantied ones.
pure Nash, Pareto strong equilibrium existence computations problems
feasible logarithmic space games standard normal form (Theorem 4.1).
pure Nash equilibrium existence computation problems tractable
games (in whatever representation) simultaneously small neighborhood
bounded hypertree width (Theorem 5.3). Observe two joint restrictions, small neighborhood bounded hypertree width, weaker restrictions bounded neighborhood acyclicity, respectively,
guarantee tractability. Thus, order obtain tractability, instead strengthening single restriction, combined two weaker restrictions. think
two strong restrictions unrealistic, believe many natural
games combined weaker restrictions apply. order prove tractability
result, establish relationship strategic games well-known nite
domain constraint satisfaction problem (CSP), much studied AI literature (e.g. Vardi, 2000; Gottlob et al., 2000). Let us point also Vickrey
Koller (2002) recently exploited mapping CSP dierent problem nding
approximate mixed equilibria graphical games. show (general,
necessarily GNF) strategic game G translated CSP instance
hypertree width G, whose feasible solutions exactly correspond
Nash equilibria game. Then, able prove G equivalent
acyclic constraint satisfaction problem size ||G||O(i(G)hw(G)) , i(G) intricacy G hw(G) hypertree width strategic dependency hypergraph.
Acyclic CSPs, turn, well-known solvable polynomial time.
Exploiting relationship CSPs, prove Nash-equilibrium existence computation problems tractable games graphical normal form
(GNF) bounded hypertree width (Theorem 5.3), regardless game intricacy, i.e., even unbounded neighborhood.
362

fiPure Nash Equilibria: Hard Easy Games

show strategic game bounded treewidth, also bounded
hypertree width (Theorem 5.7). Note novel result relationship
two measures degree cyclicity, since earlier works similar
subjects dealt either primal dual graph given hypergraph, rather
dependency graph, present paper, focused games. Combined two previous points, entails Nash-equilibrium existence
computation problems tractable games simultaneously small
neighborhood bounded treewidth, GNF games bounded treewidth
(Corollary 5.9).
cases pure Nash Equilibrium computed polynomial time,
also Pareto Nash equilibrium computed polynomial time (Theorem 4.6
Corollary 5.4).
tractability results partially extend strong Nash equilibria. Indeed,
checking problem becomes feasible polynomial time acyclic-hypergraph games
GNF. However, even simple cases, deciding whether game strong
Nash equilibria NP-complete, thus still untractable (Theorem 4.8).
go bit further, determining precise complexity games acyclic
(or even bounded width) interactions among players: case game given
GNF, problem determining pure Nash equilibrium game bounded
hypertree-width (or bounded treewidth) LOGCFL-complete thus parallel complexity class NC2 (Theorem 6.1). Membership LOGCFL follows
membership bounded hypertree-width CSPs LOGCFL (Gottlob, Leone, &
Scarcello, 2001). Hardness LOGCFL shown transforming (logspace uniform
families of) semi-unbounded circuits logarithmic depth together inputs
strategic games, game admits Nash equilibrium
circuit outputs one given input.
Figure 2 summarizes results existence pure Nash equilibria.
various authors dealt complexity Nash equilibria (e.g. Gilboa &
Zemel, 1989; Papadimitriou, 1994b; Koller & Megiddo, 1992, 1996; Conitzer & Sandholm,
2003b), investigations dedicated mixed equilibria best
knowledge complexity results present paper novel. aware
work considering quantitative structural restrictions pure games studied
here. Note tree-structured games rst considered Kearns et al. (2001b)
context mixed equilibria. turned that, games, suitable approximation
(mixed) Nash equilibria computed polynomial time. future work,
would like extend tractability results even setting. aware
work others parallel complexity equilibria problems. believe
present work contributes understanding pure Nash equilibria proposes
appealing realistic restrictions main computation problems associated
equilibria tractable.
rest paper organized follows. Section 2 introduce basic notions
games Nash equilibria studied paper, describe games
363

fiGottlob, Greco, Scarcello

Figure 2: Complexity deciding existence pure Nash equilibria games GNF
numbers indicate theorems corresponding results proved.

may represented. Section 3 thoroughly study computational complexity
deciding existence pure Nash, Pareto strong equilibria. Section 4 identify
tractable classes games, Section 5 extend tractability results larger
class games, interaction among players bounded degree cyclicity.
Section 6 improve results polynomial tractability easy games, providing
precise computational complexity games acyclic (or bounded width) interactions
among players. Finally, Section 7, draw conclusions, discuss possible
research related works.
364

fiPure Nash Equilibria: Hard Easy Games

2. Games Nash Equilibria
game G tuple P, Neigh, Act, U , P non-empty set distinct players
Neigh : P 2 P function p P , Neigh(p) P {p} contains
neighbors p, Act : P function returning player p set possible
actions Act(p), U associates utility function : Act(p) j Neigh(p) Act(j )

player p.
Note that, general, players interests symmetric. Thus, may happen
that, pair players p1 , p2 P , p1 Neigh(p2 ) p2 Neigh(p1 ).
player p, pa denotes choice play action Act(p). possible pa
called strategy p, set strategies p denoted St(p).2
non-empty set players P P , combined strategy P set containing
exactly one strategy player P . St(P ) denotes set combined strategies
players P .
combined strategy (also, profile) x called global players contribute it,
is, P = P . global strategies possible outcomes game.
set players K P often called coalition. Let x global strategy, K
coalition, combined strategy K. Then, denote xK [y] global strategy
where, player p K, individual strategy pa x replaced individual
strategy pb y. K singleton {p}, simply write xp [y].
Let x global strategy, p player, utility function p. Then,
small abuse notation, (x) denote output projection x
domain , i.e., output function applied actions played p
neighbors according strategy x.
context complexity eciency studies important make clear
input (in case, multiplayer game) represented.
General Form: game general form sets players actions given
extensional form, neighborhood utility functions given intentionally, e.g.,
encodings deterministic Turing transducers. precisely, interested
classes games computation time neighborhood utility functions
globally bounded polynomial. Let us denote Ck class games G
general form whose neighborhood utility functions computable time O(nk ),
n = |G|.
sake presentation, assume hereafter k 1 xed global
bound. Moreover, unless otherwise stated, speak general game G (or
omit specication all) mean game G Ck .
following restrictive classes (representations of) games used
many authors.
Standard Normal Form (SNF): game set P players standard normal
form (SNF) utility functions explicitly represented single table matrix
entry (or cell) global strategy x, displaying list containing player
2. Note technical distinction actions strategies: action element form a,
strategy element form pa , i.e., action chosen player. helps
technical proofs, since strategy singles player choice.

365

fiGottlob, Greco, Scarcello

p, ps payo (x) w.r.t. x. (Equivalently, may describe utilities |P | tables,
i-th table describes payo player i.) representation utility
functions often assumed literature (see, instance, Osborne & Rubinstein, 1994;
Owen, 1982). Observe that, general case, even utility function polynomially
computable, writing form table may require exponential space.
Graphical Normal Form (GNF): game set P players graphical normal
form (GNF) utility function player p represented separate table
containing cell combined strategy x St(Neigh(p) {p}) ps set
neighbors Neigh(p) {p}, displaying ps payo (x) w.r.t. x. game GNF illustrated
Example 2.1. GNF representation adopted several recent papers
study games large number players, utility function player depends
directly strategies (possibly few) players interested (e.g. Kearns
et al., 2001a, 2001b; Kearns & Mansour, 2002; Vickrey, 2002). Note GNF may lead
exponentially succinct game representation SNF. Notwithstanding, SNF
often used literature, mostly because, historically, rst investigations focused
two-player games. Moreover, games GNF often referred graphical games.
prefer use phrasing games graphical normal form, makes clear
addressing representational issues.
following example, refer throughout paper, sound
familiar everyone, generalization well known two-person game battle
sexes.
Example 2.1 (FRIENDS) Let us consider game FRIENDS, played group
persons plan evening happenings. players George (short: G),
Pauline (P ), Frank (F ), Robert (R), Mary (M ). decide go
either see movie (m) see opera (o). However, preferences concern
particular option (m o) chosen, usually also persons join evening
(possibly, depending movie opera choice). instance, assume Frank
interested joining Pauline Robert. would like join them. However,
Pauline expert movies Robert expert operas. Thus, possible
go together, prefers go cinema Pauline opera
Robert. Pauline would like stay Frank, prefers movies. Robert
like Frank speaks much and, know, prefers opera. Mary,
too, likes operas would like go opera Robert. Finally, George
matchmaker group: personal preferences would like Frank
Pauline stay together evening, best go cinema. utility functions
associated game shown Figure 3, denote fact player X
chooses action Xa , e.g., Fm denotes strategy Frank chooses play
action m.
2

Let us formally dene main concepts equilibria studied
paper.
Definition 2.2 Let G = P, Neigh, A, U game. Then,
366

fiPure Nash Equilibria: Hard Easy Games

F



Pm Rm
2
0

Pm Ro
2
2
R



Fm
0
2

Po Rm
1
1

Po Ro
0
2

Fo
1
0

P



Fm
2
0

G



Pm Fm
2
2

Fo
0
1





Pm Fo
0
0
Rm
1
0

Po Fm
0
0

Po Fo
1
1

Ro
0
2

Figure 3: Utility functions FRIENDS GNF
global strategy x pure Nash Equilibrium G if, every player p P ,
pa St(p) (x) < (xp [pa ]);
global strategy x pure strong Nash Equilibrium G if, K P,
St(K ), p K (x) (xK [y]) or, equivalently, K P ,
St(K ) that, p K, (x) < (xK [y]);
pure Nash equilibrium x pure Pareto Nash Equilibrium G
exist pure Nash equilibrium G that, p P, (x) < (y).3
sets pure Nash, strong Nash, Pareto Nash equilibria G denoted
NE(G), SNE(G), PNE(G), respectively. easy see well known
following relationships hold among notions Nash equilibria: SNE(G) PNE(G)
NE(G). Moreover, existence Nash equilibrium imply existence
strong Nash equilibrium. However, exists Nash equilibrium, exists also
Pareto Nash equilibrium.
{Fm , Pm , Ro , Go , Mo },
Example 2.3
strategies
{Fm , Pm , Ro , Gm , Mo },
{Fo , Po , Rm , Gm , Mm } {Fo , Po , Rm , Go , Mm } Nash equilibria FRIENDS
game. instance, consider latter strategy, players get payo 1.
case, since P plays opera R plays movie, F cannot improve payo changing
opera movie. holds G, R, P , would get lower payo 0,
change choices.
Moreover, note rst two strategies above, namely {Fm , Pm , Ro , Gm , Mo }
{Fm , Pm , Ro , Go , Mo }, Pareto Nash equilibria, well strong Nash equilibria. Indeed, global strategies players get maximum payo 2, thus
way improve utilities.
2

interaction among players G generally represented hypergraph
H(G) whose vertices coincide players G whose set (hyper)edges contains
player p (hyper)edge H(p) = {p} Neigh(p), referred-to characteristic edge
p. Intuitively, characteristic edges correspond utility functions.
3. Note pure strategies matter definition, requirement regard
pure candidate equilibria compare possible mixed equilibria.

367

fiGottlob, Greco, Scarcello

fundamental structural property hypergraphs acyclicity. Acyclic hypergraphs
deeply investigated many equivalent characterizations (e.g. Beeri et al.,
1983). recall hypergraph H acyclic join tree H,
is, tree JT whose vertices edges H and, whenever player
p occurs two vertices v1 v2 , v1 v2 connected JT , p occurs
vertex unique path linking v1 v2 (see Figure 5 join tree H(FRIENDS)).
words, set vertices p occurs induces (connected) subtree JT .
refer condition Connectedness Condition join trees (also known
running intersection property).
Another representation interaction among players (undirected)
dependency graph G(G) = (P, E), whose vertices coincide players G, {p, q}
E p neighbor q (or vice versa). completeness observe that, even works
graphical games use dependency graph, another natural choice representing
game structure directed graph (also called inuence graph), takes account
fact payos player p may depend payos player q vice versa,
general. Following Kearns et al. (2001b), present paper use undirected version
interested identifying game structures possibly allow us compute
eciently Nash equilibria, directed graphs help much purpose. Let
us give hint case, thinking group players X = {X1 , . . . , Xn },
one one neighbor C, whose payos depend player X.
Player C one neighbor D, C neighbor. Figure 4 shows directed
graph representing player interactions. easy design game players

Figure 4: directed graph representation player interactions.
that, combined strategy x X players, Nash equilibrium,
combined strategy x players, combined strategy
C union x Nash equilibrium game. Therefore,
far possibility reaching Nash equilibrium concerned, choices players
X depend other, way playing C, transitively player D, too.
Observe undirected dependency graph represents succinct way, i.e.,
direct connections, mutual relationship among players. However, direct
graph model kind inuence, looking graph seems players
X worry player game. fact, exploiting gadgets
constructions described paper, easy see even simple games whose
directed inuence graphs quasi-acyclic (i.e., acyclic, trivial cycles
like one shown Figure 4), hard deal with. Thus, apart well known
368

fiPure Nash Equilibria: Hard Easy Games

G

G

F
P

R

P


H(FRIENDS)

G

F
R

F
P


G(FRIENDS)

HF(F,P,R)

R
HP(P,F)

HR(R,F)

HG(G,F,P)

HM(M,R)


PG H(FRIENDS)

Figure 5: Hypergraph, dependency graph, primal graph FRIENDS game.
right, join tree H(FRIENDS).

easy acyclic cases, reasonable generalization notion direct acyclicity
appear useful identifying tractable classes games.
Observe dependency graph G(G) dierent called primal graph PG
H(G), contains edge pairs vertices jointly occur hyperedge
H(G). general, G(G) much simpler PG. instance, consider game G
player p depends players q1 , . . . , qn , players independent
(but possibly depend p). Then, G(G) tree. However, primal graph
H(G) clique n + 1 vertices.
Example 2.4 hypergraph H(FRIENDS), graph G(FRIENDS) primal
graph H(FRIENDS) shown Figure 5. Note dependency graph associated FRIENDS game acyclic, even though associated hypergraph
acyclic (on right, also report join tree it). Moreover, note dependency
graph diers primal graph, player P neighbor R viceversa. 2

3. Hard Games
section, precisely characterize complexity deciding existence
dierent kinds pure Nash equilibria (regular, Pareto, strong). way, able
identify sources complexity problems, order single out, following
sections, natural practically relevant tractable cases.
Every game considered section assumed either general graphical
normal form. Indeed, shall discuss details Section 4, games standard
normal form, computing pure Nash equilibria tractable problem, since one easily
explore (big) table representing utility functions players, order detect
strategy interest. Since table given input, computation trivially
feasible polynomial time.
start showing deciding existence pure Nash equilibrium dicult
problem, even restricted setting.

369

fiGottlob, Greco, Scarcello

Figure 6: Schema reduction proof Theorem 3.1.
Theorem 3.1 Deciding whether game G pure Nash equilibrium NP-complete.
Hardness holds even G GNF 3-bounded neighborhood, number
actions fixed.
Proof. Membership. decide NE(G) = guessing global strategy x
verifying x Nash equilibrium G. latter task done polynomial
time. Indeed, player p action Act(p), check
choosing strategy pa lead increment , tests
feasible polynomial time.
Hardness. Recall deciding whether Boolean formula conjunctive normal form
= c1 . . . cm variables X1 , . . . , Xn satisable, i.e., deciding whether
exists truth assignments variables making clause cj true, well known
NP-complete problem (CNF) SAT. Hardness holds even 3SAT restriction
clause contains three distinct (possibly negated) variables, variable occurs
three clauses (Garey & Johnson, 1979). W.l.o.g, assume contains least one
clause one variable.
dene GNF game G that: players partitioned two sets Pv Pc ,
corresponding variables clauses , respectively; player c Pc ,
Neigh(c) set players corresponding variables clause c,
player v Pv , Neigh(v ) set players corresponding clauses
v occurs; {t, f, u} set possible actions players, f
interpreted truth values true false variables clauses. Figure 6 shows
graph G(G) game G associated formula (X1 X3 X4 ) (X2 X4 )
(X4 X5 X6 ).
Let x global strategy, utility functions dened follows.
player c Pc , utility function uc
(i) uc (x) = 3 c plays t, neighbors play action {t, f } way
least one makes corresponding clause true;
(ii) uc (x) = 2 c plays u, neighbors play action {t, f } way
none makes corresponding clause true;
(iii) uc (x) = 2 c plays f exists v Neigh(c) v plays u;
(iv) uc (x) = 1 cases.
370

fiPure Nash Equilibria: Hard Easy Games

player v Pv , utility function uv
(v) uv (x) = 3 v plays action {t, f } neighbors play action {t, f };
(vi) uv (x) = 2 v plays u exists c Neigh(v ) c plays u;
(vii) uv (x) = 1 cases.
claim: satisable G admits Nash equilibrium.
() Assume satisable, take one satisfying truth assignments, say .
Consider global strategy x G player Pv chooses action according
, player Pc plays t. Note that, case, players get payo 3
according rules (i) (v) above, since 3 maximum payo, x Nash
equilibrium G.
() Let us show Nash equilibrium x G corresponds satisfying truth
assignment G. rst state following properties strategies G.
P1 : strategy x player v Pv plays u cannot Nash equilibrium. Indeed,
assume contradiction x Nash equilibrium. Then, c Neigh(v ) must
play f payo 2, rule (iii); otherwise would get payo 1, rule (iv).
However, case player v gets payo 1 rule (vii), thus, rule (v),
easily increase payo 3 playing action {t, f }. Contradiction.
P2 : strategy x player c Pc plays u cannot Nash equilibrium. Indeed,
player c chooses u, rule (vi) variable player
v Neigh(c) must play u, order get maximum possible payo 2 case
hand. Therefore, x cannot Nash equilibrium, property P1 above.
P3 : strategy x players play action {t, f } corresponding truth
assignment makes clause c false cannot Nash equilibrium. fact, case,
rule (ii), c play u order get maximum possible payo 2,
hence x Nash equilibrium, property P2 .
P4 : strategy x players play action {t, f } exists player c Pc
plays f cannot Nash equilibrium. Indeed, x Nash equilibrium
players play action {t, f }, property P 3 truth assignment corresponding
strategy satises clause c. follows player c plays f contradicts
assumption x Nash equilibrium, c could change choice t,
improving payo 3.
properties, follows every Nash equilibrium G strategy
players play either f players corresponding clauses must play
get payo 3, made true truth assignment neighbors.
Combined -part, entails one-to-one correspondence
satisfying truth assignments variables Nash equilibria game G.
Finally, observe tables (matrices) representing entries utility functions (rules (i)(vii) above) built polynomial time . Moreover,
assumptions made structure , player depends 3 players
most.
2

371

fiGottlob, Greco, Scarcello

worthwhile noting that, though quite limited, proof interaction
among players rather complicated. particular, easy see dependency
graph game described hardness part proof cyclic. Thus, one may
wonder problem easier games simple structured interactions. next
show that, general setting, even structure player interactions simple,
problem deciding whether pure Nash equilibria exist remains hard.
Theorem 3.2 Deciding whether game G general form pure Nash equilibrium
NP-complete, even dependency graph associated hypergraph acyclic,
number actions fixed.
Proof. Membership follows previous theorem. next prove problem
NP-hard, via reduction SAT. Given Boolean formula variables X1 , ..., Xm ,
dene game G players X1 , ..., Xm corresponding variables , two
additional players H. player Xi , 1 m, two available actions,
f , corresponding truth assignments corresponding variable . Moreover,
utility function player Xi constant, say 1. Hence, choice Xi independent
player.
actions player u, read satised unsatised,
actions player H g b, read good bad, respectively.
role check whether actions chosen X1 , . . . , Xm encode satisfying truth
assignment . Indeed, behaviors described ensure strategies
plays may Nash equilibria, interaction player H, whose
role discard bad strategies. Given combined strategy x variable players
X1 , ..., Xm , denote (x) evaluation truth values determined
strategy x.
Player depends players {X1 , . . . , Xm , H}, utility function dened
follows. combined strategy = x1 x2 X1 , . . . , Xm , H, , x1
combined strategy X1 , ..., Xm x2 H:
uT (y) = 1 (x1 ) true plays s, (x1 ) false x2 = {Tu , Hg },
(x1 ) false x2 = {Ts , Hb };
uT (y) = 0, otherwise.
Player H depends and, combined strategy x H , utility
function following:
uH (x) = 1 x either {Ts , Hg } {Tu , Hb };
uH (x) = 0, otherwise.
claim one-to-one correspondence Nash equilibria game
satisfying assignments . Indeed, let satisfying assignment x
combined strategy X1 , . . . , Xm players choose actions according .
Then, x {Ts , Hg } Nash equilibrium G, players get maximum
payo.
372

fiPure Nash Equilibria: Hard Easy Games

hand, unsatisable, combined strategy x1 X1 , . . . , Xm ,
(x1 ) false. case, H opposite interests easy check that,
combined strategy x2 St({H , }), x1 x2 Nash equilibrium G,
either H improve payo.
Finally, observe dependency graph G(G) tree, hypergraph
H(G) acyclic.
2
shown Figure 2, NP-hardness result immediately extends generalizations acyclicity. case acyclic-hypergraph games GNF dealt
Section 4.
Let us draw attention Pareto equilibria. Denition 2.2, Pareto Nash
equilibrium exists Nash equilibrium exists. Therefore, Theorems 3.1
3.2, get following corollary.
Corollary 3.3 Deciding whether game G Pareto Nash equilibrium NP-complete.
Hardness holds even G fixed number actions either G graphical normal
form k-bounded neighborhood, fixed constant k 3, G(G)
H(G) acyclic.
However, checking whether global strategy x pure Nash equilibrium
tractable, turns checking whether x Pareto Nash equilibrium computationally hard task. fact, next show problem dicult checking
whether x strong Nash equilibrium. However, see deciding existence
strong Nash equilibrium much harder, fact complete second level
Polynomial Hierarchy. end, following proofs, associate quantied Boolean
Formulas two quantier alternations (2QBFs) games.
Quantified Boolean Formulas (QBFs) games.


=

1 , . . . n

1 , . . . q

Let


quantied Boolean formula disjunctive normal form, i.e., Boolean formula
form d1 . . .dm variables 1 , . . . n , 1 , . . . q , di conjunction
literals. Deciding validity formulas well-known P2 -complete problem (e.g.
Stockmeyer & Meyer, 1973), easy see hardness result holds even
disjunct dj contains three literals variable occurs three disjuncts
most. Moreover, without loss generality, assume number disjuncts
power 2, say = 2 , integer 2. Note that, 21 < < 2 ,
build polynomial time new QBF 2l disjuncts, one containing
fresh existentially quantied variable negation. Clearly, disjuncts cannot
made true assignment, hence equivalent . Hereafter, consider
quantied Boolean formulas form, call R2QBF. formula ,
truth value assignment existentially quantied variables 1 , . . . , n
formula 1 , . . . q () valid called witness validity .
running example section, consider following QBF r :
1 2 3 1 2 3 4 5 (1 2 ) (1 3 ) (1 1 ) (1 ) (2 3 ) (1 3 )
(3 4 ) (5 ).
373

fiGottlob, Greco, Scarcello

Figure 7: left: dependency graph game Gr . right: truth-value
assignment r corresponding strong Nash equilibrium Gr .

dene GNF game G associated R2QBF follows. players G
partitioned sets Pe , Pu , Pd , Pt , singleton {C}.
Players Pe , Pu , Pd correspond existential variables 1 , . . . n , universal variables 1 , . . . l , disjuncts , respectively. variable player v
Pe Pu may play truth value action {T, F } (read: {true, false}), neighbors
(at three) players Pd corresponding disjuncts v occurs.
disjunct player p may play action {T, F, w}, neighbors (at
three) players corresponding variables, plus one player belonging set
Pt , described below. shown Figure 7, disjunct players leaves
complete binary tree comprising players Pt intermediate vertices, player
C root. fact, tree players Pt act logical-or gates circuit. sake
simpler presentation, tree player p, children(p) denotes set two players
children p tree, parent(p) denotes parent. disjunct players, set available actions players Pt {T, F, w}. Finally, player C, called
challenger, may play actions {T, w}. shown Figure 7, neighbors C
two top level tree-players.
Let x global strategy. utility functions players G dened
follows.
Existential-variables players. Pe ,
(E-i) u (x) = 1, matter players do;
Universal-variables players. Pu ,
(U-i) u (x) = 2, exists (disjunct) neighbor playing w;
(U-ii) u (x) = 1 cases.
Disjuncts players. Pd ,
374

fiPure Nash Equilibria: Hard Easy Games

(D-i) ud (x) = 2 parent (i.e., node Pt ) play w,
disjunct corresponding made false truth-value actions x
variable players, i.e., players Neigh(d) (Pe Pu );
(D-ii) ud (x) = 1 plays disjunct corresponding made true
truth-value actions x variable players;
(D-iii) ud (x) = 1 plays F , disjunct corresponding made false
truth-value actions variable players, parent node (a tree
player) play w;
(D-iv) ud (x) = 0, cases.
Tree players. p Pt ,
(TREE-i) (x) = 2 p neighbors play w;
(TREE-ii) (x) = 1 p plays , none neighbors plays w, player
children(p) plays ;
(TREE-iii) (x) = 1 p plays F , none neighbors plays w, players
children(p) plays F ;
(TREE-iv) (x) = 1 p plays action {T, F }, neighbors plays
w, them;
(TREE-v) (x) = 0 cases.
Challenger. player C,
(CHALL-i) uC (x) = 2 C plays w, either neighbors play F ,
least one plays w;
(CHALL-ii) uC (x) = 1 C plays , neighbors plays , none plays
w;
(CHALL-iii) uC (x) = 0 cases.
Intuitively, universal-variable players corresponding variables 1 , . . . q choose
actions trying falsify formula, since maximum payo 2 obtained
satised. strategies variable players suitably evaluated
players Pd Pt , eventually C.
worthwhile noting G built polynomial time (actually, LOGSPACE)
, player G may play three actions bounded
number neighbors. precisely, sake presentation, construction
player four neighbors. However, show later section
bound reduced easily three.
Let x global strategy G . denote (x) truth-value assignment
determined actions chosen variable players (i.e., Pe Pu )
strategy x. Moreover, denote e (x) u (x) restriction existential
universal variables, respectively.
Lemma 3.4 one-to-one correspondence among satisfying truth-value assignments Nash equilibria G player plays w.
375

fiGottlob, Greco, Scarcello

Proof. Assume satisable, let satisfying truth-value assignment it.
Consider following global strategy x G : variable player Pe Pu chooses
truth-value action according ; disjunct player Pd plays either F , depending
logical evaluation disjunct associated her; tree player p Pt plays
either F , acting gate input values played children(p);
player C plays . Note player chooses w x .
Figure 7 shows right strategy G associated truth assignment
1 = 2 = 3 = 1 = 2 = 3 = 4 = 5 = F .
Since satisfying assignment, least one disjunct evaluated true
thus least one tree-player neighbors C plays . Therefore, easy
check that, according utility functions G , players get payo 1 respect
x . particular, follows rule (D-ii) (D-iii) disjunct players, rule
(TREE-ii) (TREE-iii) tree players, rule (CHALL-ii) player C.
Moreover, rules may increase payo 1 2 (TREE-i),
(CHALL-i) (D-i). However, single player increase payo changing
action, rules may applied neighbor playing
w, case x . follows global strategy x Nash equilibrium
G .
next prove converse, is, show Nash equilibrium x G
player chooses w corresponds satisfying truth-value assignment . proof
based following properties x:
P1 : least one player Neigh(C ) play F . Otherwise, C would play w order
get payo 2, rule (CHALL-i), contradicting hypothesis x.
P2 : least one player Pd plays . Otherwise, since player chooses w x,
possible choice disjunct players would F . However, case, best
available choice tree-players depending disjunct players Pd play F ,
according (TREE-iii). follows induction players Pt would play F
and, particular, neighbors C. However, contradicts property P1 x.
P3 : satisfied truth-assignment (x). Let p Pd disjunct player plays
, whose existence guaranteed property P2 . hypothesis
player chooses w, rule (D-i) applicable p. follows disjunction
corresponding player p true respect (x). Otherwise, x would
Nash equilibrium, p would get payo 0 (D-iv) could improve
playing correct evaluation F , rule (D-iii).
Therefore, case player chooses w, global strategies Nash equilibria
correspond satisfying assignments .
2
Lemma 3.5 Nash equilibrium x G player chooses w strong
e (x) witness validity .
Proof. () Assume x strong Nash equilibrium G player chooses w.
Then, (x) satises , previous lemma. Assume contradiction e (x)
witness validity . Then, assignment u universal variables
376

fiPure Nash Equilibria: Hard Easy Games

satised respect e (x) u . Let K coalition comprising
players G existential players Pe , let combined strategy K
universal players Pu choose truth-value action according u ,
players K play w. choice u , disjuncts made false via
truth-value actions chosen players Pu . Then, rule (D-i), disjunct players get
payo 2 according xK [y]. Similarly, (Tree-i) (Chall-i), tree-players
player C get payo 2 xK [y]. However, means players coalition
improving payo, contradicts fact x strong Nash equilibrium.
() Assume valid let (x) satisfying truth-value assignment
e (x) witness validity , Nash equilibrium x G . Indeed,
Lemma 3.4 know equilibrium (where player plays w) exists every
satisfying assignment, player chooses w x. Moreover, easy check
players get payo 1, according global strategy. Assume contradiction x
strong Nash equilibrium G . Then, coalition K combined strategy
K players coalition may improve payo global strategy
xK [y], hence get payo 2 strategy. Note existential player may
belong K thus change action, way improve
payo. Then, rule (Tree-i), way players Pt improve payo 2
change actions w, rules require that,
player, neighbors play w. Thus, one belongs K,
belong coalition, well player C disjunct players Pd ,
neighbors change choices w order get 2, too. hand,
disjunct players p Pd , improvement 2 depends also variable players
occurring disjunct associated p (D-i). particular, besides playing w,
disjunct also made false, change choices universal
players p depends on. Note players may turn improve payo 2, p plays
w. follows coalition K shows x Nash equilibrium contains number
universal players able let disjunct players unsatised hence
change actions w, thus getting payo 2. However, truth-values corresponding
actions players Pu K determine assignment u contradicts validity
.
2

Theorem 3.6 Given game G global strategy x, deciding whether x SNE(G)
(resp., x PNE(G)) co-NP-complete. Hardness holds even given strategy x
pure Nash equilibrium, G graphical normal form 3-bounded neighborhood,
number actions fixed.
Proof. Membership. Deciding whether x PNE(G) NP: (i) check polynomial
time whether x NE(G); (ii) case, guess global strategy check
polynomial time whether NE(G) dominates x. Similarly, deciding whether
x SNE(G) NP: (i) check polynomial time whether x NE(G); (ii)
case, guess coalition players K combined strategy players K,
check polynomial time whether players K increase payo playing
actions according new strategy y.
377

fiGottlob, Greco, Scarcello

Figure 8: Transformation disjunct containing exactly three literals.
Hardness. well-known checking whether satisable formula 3DNF tautologically valid co-NP complete. reduce problem problem checking
whether given Nash equilibrium strong (Pareto). Let satisable formula
3DNF. Find satisfying truth value assignment . obviously possible
polynomial time, given satisable DNF. Dene = 1 , . . . q .
considered (degenerate) R2QBF without existentially quantied variables. Let G
game associated . Obviously, G constructed polynomial time
. Let x Nash equilibrium G determined truth-value assignment
player chooses w, described Lemma 3.4, note even equilibrium
computed polynomial time . Then, Lemma 3.5, x strong
valid (i.e., vacuous assignment e witness validity). settles hardness
checking whether given Nash Equilibrium strong. addition, hard see
construction x Pareto equilibrium G tautology.
Indeed, note that, truth-value assignment falsies ,
global strategy (universal) variable players play according
players choose w, dominates Nash equilibrium x. Thus checking whether
given Nash equilibrium Pareto co-NP complete, too.
conclude proof observing that, reduction, player Pe Pu Pt
{C} depends three players most, player Pd may depend four
players, corresponding disjunct contains exactly three literals. case,
may introduce additional player whose set actions {T, F, w} whose neighbors
rst two literals plus d. Moreover, utility function acts
AND-gate inputs literals, preferring w two literals evaluated false,
plays w. new encoding, depends third literal occurring
disjunct. basic construction previously dened, payo 2 plays
w, parent plays w, third literal false, plays w. Figure 8 shows
transformation. Note construction preserves properties proved far,
player depends three players most.
2
Deciding whether game strong Nash equilibrium turns much
dicult deciding existence pure (Pareto) Nash equilibria. Indeed, problem
located second level polynomial hierarchy.
Theorem 3.7 Given game G, deciding whether G strong Nash equilibrium P2 complete. Hardness holds even G graphical normal form 3-bounded neighborhood, number actions fixed.
378

fiPure Nash Equilibria: Hard Easy Games

Proof. Membership. decide SNE(G) = guessing global strategy x
verifying x strong Nash equilibrium G. Theorem 3.6, latter task
feasible co-NP. follows problem belongs P2 .
Hardness. Let = 1 , . . . n 1 , . . . q R2QBF. Recall deciding validity
formulas P2 -complete problem see denition R2QBF above,
current section.
dene game G associated , obtained G addition one
gadget. G fresh player depending player C only. called
duplicator, gets maximum payo plays action
challenger player C. hand, also C depends new player D, besides
tree-players neighbors (recall construction shown Figure 7). C
play actions {T, w, u}. Everything else G , utility functions
players C D:
Challenger. player C,
(CHALL-i) uC (x) = 2 C play dierent actions {w, u} either
tree-players neighbors (i.e., players Neigh(C ) {D }) play F ,
least one plays w;
(CHALL-ii) uC (x) = 1 C plays , one player Neigh(C ) {D } plays ,
none plays w;
(CHALL-iii) uC (x) = 0 cases.
Duplicator. player D,
(DUPL-i) uD (x) = 1 plays action C;
(DUPL-ii) uD (x) = 0 cases.
Recall that, order maximize payos, universal-variable players try
make false, strategies variable players suitably evaluated players
Pd Pt , acting Boolean circuit. Moreover, challenger duplicator
designed way strategies player chooses w, correspond
satisfying assignments , cannot lead Nash equilibria. Formally, Nash
equilibrium G , following properties hold.
P1 : least one player Neigh(C ){D } play F player Neigh(C ){D }
plays w. Otherwise, C would play action {w, u} dierent one played
x, order get payo 2, rule (CHALL-i). However, strategy
cannot equilibrium, could improve payo choosing
action C x.
P2 : player Pd Pt plays w players Pd Pt play w. Indeed, let p
player Pd Pt playing w assume contradiction player q
Pd Pt play w. W.l.o.g., assume q Neigh(p)
viceversa. Then, p gets payo 0, could increase payo playing action
{T, F } according (D-ii) (D-iii) players Pd , (TREE-ii), (TREE-iii)
(TREE-iv) players Pt . contradicts fact x Nash equilibrium.
379

fiGottlob, Greco, Scarcello

P3 : player Pd Pt plays w. Otherwise, P2 , players Pd Pt play w and,
particular, players Neigh(C ) {D }. However, possible,
property P1 .
Therefore, rule (Chall-i) applicable C respect x. However,
properties least one tree-players neighbors play C play
turn get payo 1, rule (Chall-ii). Then, may play get payo 1,
well. Thus, longer possible Nash equilibrium player choosing
action w. Therefore, Lemma 3.5 (as presence duplicator aect
proof), get following fundamental result: global strategy x strong Nash
equilibrium G truth-value assignment e (x) witness validity
. particular, SNE(G ) = valid.
Finally, observe even game G modied shown Figure 8, order
get 3-bounded neighborhood game.
2
next show that, game given general form, hardness result holds
even structure player interactions simple.
Theorem 3.8 Deciding whether game G general form strong Nash equilibrium
P2 -complete, even dependency graph associated hypergraph acyclic,
number actions fixed.
Proof. proof membership P2 membership proof previous
theorem. next prove problem hard P2 .
Let = 1 , . . . n 1 , . . . q quantied Boolean formula disjunctive
normal form. dene game G players 1 , . . . n , 1 , . . . q corresponding
existentially universally quantied variables , two additional players
H. game based combination game techniques exploited proofs
Theorem 3.2 Theorem 3.7. player associated variable two available
actions, f , represent truth assignments corresponding variable ;
actions player u, read satised unsatised,
actions player H g b, read good bad, respectively.
Given combined strategy x, denote (x) evaluation truth values
determined strategy x. Then, utility functions dened follows. player
(1 n) gets always payo 1. player j (1 j q) depends gets
payo 1 plays x, payo 2 plays u x. Player H depends
gets payo 1 x contains either {Ts , Hg } {Tu , Hb }, 0, otherwise. Finally, player
depends players {1 , . . . n , 1 , . . . q , H}, utility function dened follows:
uT (x) = 2, (x) false, plays u, H plays g;
uT (x) = 1, (x) true plays s, (x) false, plays s, H plays b;
uT (x) = 0, otherwise.
First, observe dependency graph dependency hypergraph G
acyclic. Moreover, proof Theorem 3.2, easy see oneto-one correspondence Nash equilibria game satisfying assignments
380

fiPure Nash Equilibria: Hard Easy Games

. Then, Nash equilibrium x G , denote x corresponding truth-value
assignment, ex restriction assignment existential variables .
Note that, shown mentioned proof, Nash equilibrium, player plays
players game get payo 1.
next prove witness validity corresponds strong Nash equilibrium G . Let x Nash equilibrium consider coalition K players
deviate x, leading new prole x . denition game, way
coalition get payo higher 1 changes choice u.
case, (x ) false (and H plays g), get payo 2. Since true respect
x, follows variable players change choices, means
belong coalition improve payos. Therefore, variable players
K correspond universally quantied variables, players able
improve payos 1 2. Thus, coalition K exists
universally quantied variables make formula false, is, ex witness
validity . Equivalently, follows x strong Nash equilibrium
valid.
2
Remark 3.9 Recall assumed general game G taken class Ck .
worthwhile noting that, games without restriction player interactions,
hardness results hold games utility functions computable constant time,
too. Namely, consider Theorems 3.1, 3.6, 3.7. constructions, player
three neighbors fixed number actions. Therefore, utility function
player computable constant time.

4. Easy Games
deal tractable games graphical normal form (GNF), let us recall
computational problems dealt paper tractable games standard
normal form (SNF), even arbitrary interactions among players. Actually, next point
carried logarithmic space thus low complexity
class contains highly parallelizable problems only. surprising,
fact size SNF games may exponentially larger size games
encoded GNF.
Theorem 4.1 Given game standard normal form, following tasks feasible
logarithmic space: Determining existence pure Nash equilibrium, pure Pareto
equilibrium, strong Nash equilibrium, computing equilibria.
Proof. Let P , usual, denote set players. assume w.l.o.g. player
least two possible actions (in fact, player single action eliminated
game simple logspace transformation, yielding equivalent game). size
input matrix thus least 2|P | .
Given possible global strategies explicitly represented, corresponding
table cell (which indexed logarithmic space size input,
corresponds polynomial space |P | |A|, P sets players
381

fiGottlob, Greco, Scarcello

set possible actions, respectively), Nash equilibria easily identied scanning
(i.e., enumerating) global strategies x keeping logspace index x worktape,
checking logarithmic space (in size input) whether player improve
utility choosing another action. Given Nash Equilibria generated
logarithmic space, also generated polynomial time.
Pareto equilibria identied successively enumerating Nash equilibria
x, additional loop x, enumerating Nash equilibria (indexed
logarithmic space above) outputting x that, p P , (y) >
(x). latter condition tested means simple scan players.
Strong Nash equilibria identied enumerating Nash equilibria scanning possible coalitions players (which indexed logarithmic space,
number 2|P | ) order discard equilibria x exists coalition
K P combined strategy K, p K, (x) < (xK [y]).
Finally, note that, xed coalition K, enumeration combined strategies
K carried means additional nested loop, requiring logarithmic space
indexing strategy.
2
4.1 Constraint Satisfaction Problems Games Graphical Normal Form
Let us consider games GNF. rst establish interesting connection
constraint satisfaction problems games. instance constraint satisfaction problem
(CSP) (also constraint network) triple = (Var , U, C), Var nite set variables, U nite domain values, C = {C1 , C2 , . . . , Cq } nite set constraints.
constraint Ci pair (Si , ri ), Si list variables length mi called
constraint scope, ri mi -ary relation U , called constraint relation. (The
tuples ri indicate allowed combinations simultaneous values variables Si ).
solution CSP instance substitution : Var U , 1 q,
Si ri . problem deciding whether CSP instance solution called constraint satisfiability (CS). Since interested CSPs associated games,
variables players games, use interchangeably terms variable player,
whenever confusion arises.
Let G = P, Neigh, A, U game p P player. Dene Nash constraint
NC (p) = (Sp , rp ) follows: scope Sp consists players {p} Neigh(p),
relation rp contains precisely combined strategies x {p} Neigh(p)
yp St(p) (x) < (xp [yp ]). Thus note that, Nash equilibrium
x G, x St(Sp ) rp .
constraint satisfaction problem associated G, denoted CSP (G), triple
(Var , U, C), Var = P , domain U contains possible actions players,
C = {NC (p) | p P }, i.e., set Nash constraints players G.
Example 4.2 constraint satisfaction problem associated FRIENDS game
({F, G, R, P, }, {m, o}, C), set constraints contains exactly following Nash
constraints: NC (F ) = ({F , P , R}, rF ), NC (G) = ({G, P , F }, rG ), NC (R) = ({R, F }, rR ),
NC (P ) = ({P , F }, rP ), NC (M ) = ({M , R}, rM ), constraint scopes shown
Figure 9.
2

382

fiPure Nash Equilibria: Hard Easy Games

rF :

F







P







R







rG :

G







0

P









F









rR :

R



F



rM :

P



rP :





F



R



Figure 9: Constraint relations game FRIENDS Example 2.1.
structure constraint satisfaction problem = (Var , U, C) represented
hypergraph H(I) = (V, H), V = Var H = {var (S) | C = (S, r) C}, var (S)
denotes set variables scope constraint C. Therefore, denition
CSP (G), hypergraph game G coincides hypergraph associated
constraint satisfaction problem, thus structural properties.
following theorem establishes fundamental relationship games CSPs.
Theorem 4.3 strategy x pure Nash equilibrium game G
solution CSP (G).
Proof. Let x Nash equilibrium G let p player. Then, strategy
pa St(p), (x) (xp [pa ]). Since depends players {p} Neigh(p),
combined strategy x x tuple NC (p), construction. follows
substitution assigning player p individual strategy pa x solution CSP (G).
hand, consider solution CSP (G), let p player. Let

P = {p} Neigh(p) x combined strategy {(q) | q P }. Then, x tuple
NC (p), solution CSP (G). Thus, p, denition NC (p),
individual strategy p increase utility, given strategies
players. follows global strategy containing (p) player p Nash
equilibrium G.
2
following theorem states feasibility computation CSP (G).
Theorem 4.4 Let G game small neighborhood graphical normal form.
Then, computing CSP (G) feasible polynomial time.
Proof. Let G = P, Neigh, A, U game small neighborhood. show
NC (p) = (Sp , rp ) computed polynomial time. initialize rp combined strategies {p} Neigh(p). number combined strategies bounded

|Neigh (p)| )
2 i(G)log(||G||) = ||G||i(G) ,
maxAct (G)|Neigh(p)| = 2 log(maxAct (G)
intricacy (G) G given
maxNeigh(G) log maxAct(G)
.
log ||G||
383

fiGottlob, Greco, Scarcello

Function NashEvaluation(JT : join tree H(G)): Boolean
begin
Bottom-Up(JT );
let v = (Sv , rv ) root JT ;
rv = return false;
else
Top-Down(JT );
Select-equilibrium(JT );
output JT ;
return true;
end;
Procedure Bottom-Up(var : tree)
begin
Done := set leaves ;
v
(i) v Done,
(ii) {c | c child v} Done
c = (Sc , rc ) child v
rv := rv rc ;
Done := Done {v};
end
end;

Procedure Top-Down(var : tree)
begin
let v = (Sv , rv ) root ;
c = (Sc , rc ) child v
rc := rc rv ;
let Tc subtree rooted c;
Top-Down(Tc );
end
end;

Figure 10: Evaluation acyclic game.
Since G small neighborhood, i(G) bounded constant, thus set
combined strategies p polynomially bounded. initialization process computes
p corresponding combined strategies (via simple enumeration), thus takes
polynomial time (in size G).
Now, tuple x rp check whether kept rp not. Let
= (x). action Act(p), compute polynomial time = (xp [pa ])
delete x > m. follows CSP (G) computed polynomial time G.
similar line reasoning applies G GNF. case, utility functions
explicitly given input tabular form, thus computation Nash constraints
yet easier. fact, task feasible logspace GNF games.
2
Theorem 4.3, acyclic-hypergraph game G small neighborhood
graphical normal form solved polynomial time. Indeed, G CSP (G)
hypergraph and, shown Gottlob et al. (2000), solution acyclic constraint
satisfaction problem computed (a slight adaptation of) well known Yannakakiss algorithm evaluating acyclic conjunctive queries (Yannakakis, 1981),
LOGCFL algorithm proposed Gottlob et al. (2000), shows problem highly
parallelizable see Section 6, information complexity class LOGCFL.
sake completeness, Figure 10, report algorithm deciding existence
Nash equilibrium computing Nash equilibria acyclic-hypergraph games, based
results. assume reader familiar typical database operations like
semi-joins (for details, see, e.g., Maier, 1986).
algorithm takes input join tree JT H(G). small abuse notation,
vertex JT , formally hyperedge Hv associated player v, also
used denote player well Nash constraint (Sv , rv ) associated v.
384

fiPure Nash Equilibria: Hard Easy Games

Procedure Select-equilibrium(var : tree)
begin
let v = (Sv , rv ) root ;
select combined strategy tv rv s.t. tv rv , uv (tv ) uv (tv );
delete tuples rv , tv ;
c = (Sc , rc ) child v
rc := rc rv ;
let Tc subtree rooted c;
Select-equilibrium(Tc );
end
end;

Figure 11: Selection (Pareto) Nash equilibrium acyclic game.
algorithm consists two phases. rst bottom-up phase, constraint relation
rv node v = (Sv , rv ) JT ltered means semijoin constraint
relation rc (denoted rv rc ) children c JT . semijoin eliminates
tuples rv corresponding combined strategies players P = (Neigh(c)
{c}) (Neigh(v ) {v })) available (or longer available) rc .
way, tuples corresponding strategies match hence cannot lead
Nash equilibria deleted, starting leaves. Finally, either root empty
hence G equilibria, tuples remaining root p encode strategies
p may choose Nash equilibria game. top-down phase, property
root propagated tree taking semi-join every vertex
children. end, get tree tuples encode strategies belonging Nash
equilibria and, vice versa, Nash equilibria made strategies relations stored
JT . Then, standard techniques developed acyclic database queries CSPs,
compute JT Nash equilibria G backtrack-free way, thus time
polynomial combined size input game equilibria output. Note
best do, game may exponential number equilibria.
completeness, Figure 11 shows Procedure Select-equilibrium, selects JT
one Nash equilibrium. similar Procedure Top-Down, selection step
semi-joins: vertex, Select-equilibrium rst picks combined strategy tv rv ,
deletes tuples rv , performs semi-joins children calls
recursively, propagate choice tv towards leaves tree. Note
selection tv may arbitrary, previous bottom-up top-down steps. However,
Figure 11 select strategies giving best payos, order get Nash equilibrium
cannot dominated Nash equilibrium.
Theorem 4.5 Deciding existence pure Nash equilibria, well computing Nash
equilibrium feasible polynomial time classes C acyclic-hypergraph games
every game G C small neighborhood graphical normal form.
discussion, immediately follows tractability result
extended problem computing Pareto Nash equilibrium.
Theorem 4.6 Deciding existence Pareto Nash equilibria, well computing
Pareto Nash equilibrium pure strategies feasible polynomial time classes C
385

fiGottlob, Greco, Scarcello

Function InCoalitionx,J (Hp : vertex, st: combined strategy): boolean
begin
let (Sp , rp ) constraint associated player p N + = {p} Neigh(p);
guess tuple st rp st matches st players common;
ps strategy st dierent strategy x (xN + [st ]) (x)
return false;
else
let Kp set children Hp join tree JT ;
Kp =
return true;
else

return H Kp InCoalitionx,J (Hp ,st );
p

end
end.

Figure 12: Algorithm deciding existence coalition improving x.
acyclic-hypergraph games every game G C small neighborhood
graphical normal form.
Proof. Recall Procedure Select-equilibrium Figure 11, vertex v encountered
visit JT , select combined strategy guarantees player corresponding v maximum payo available choices (that, point,
strategies may lead Nash equilibria). particular, payo rst
player evaluated, say root p, cannot worse payo p
available strategy. Thus, tuples left JT procedure encode Pareto Nash
equilibrium G, cannot strictly dominated Nash equilibrium.
sake completeness, point that, dierently previous case
plain Nash equilibria, JT cannot compute easily Pareto Nash equilibria
game input-output polynomial time.
2
One may thus wonder whether result holds strong Nash equilibria, too.
Unfortunately, next show computing Strong Nash equilibrium dicult problem
even case acyclic interactions among players. However, complexity reduced
one level respect arbitrary interaction case, checking whether given
equilibrium strong feasible polynomial time acyclic case.
Lemma 4.7 Let G acyclic-hypergraph game small neighborhood
graphical normal form, let x global strategy. Then, deciding whether x SNE(G)
feasible polynomial time.
Proof. Since G small neighborhood graphical normal form, Theorem
4.4 build polynomial time constraints associated player. Moreover,
hypergraph H(G) acyclic thus join tree. Let JT join tree H(G).
show use JT deciding polynomial time whether strategy x
SNE(G), i.e., exists coalition C players getting incentive deviate
together x. Then, result follows PTIME closed complementation.
Specically, next show implementation task alternating Turing machine
logarithmic-space working tape. Therefore, problem ALOGSPACE,
equal PTIME (Chandra, Kozen, & Stockmeyer, 1981).
386

fiPure Nash Equilibria: Hard Easy Games

machine deciding whether x strong Nash equilibrium works follows:
guess player q;
guess strategy stq q dierent choice x;
root tree JT vertex corresponding characteristic edge Hq player q;
check InCoalition x,JT (Hq , stq ) returns true, InCoalition x,JT Boolean
function shown Figure 12.
Intuitively, non-deterministic Turing machine rst chooses player q belonging
possible coalition C disproving x. Thus, q improve payo, general
unless x strong Nash equilibrium, getting improvement may require
neighbors Kq deviate x hence belong C. However, case, players
Kq able improve payos. Again, that, involve
players coalition, on.
Whether process successful checked recursive Boolean function
InCoalition x,JT , takes input vertex Hp join tree JT combined
strategy st. Recall vertex join tree (hyper)edge hypergraph,
corresponding player G. particular, Hp characteristic edge player p.
InCoalition x,JT check whether players deviating given global strategy x
able improve payos. rst call function, rst parameter Hq
root JT identies rst player q chosen coalition C. second
parameter st strategy chosen q, dierent qs corresponding choice
x. generic recursive call, rst parameter Hp identies player p checked,
second parameter st encodes combined strategy player w associated
parent Hw Hp JT ws neighbors. Now, function check
either p change choice respect x, changes improves
payo. end, function guesses tuple st rp , rp constraint relation
associated p. Then, st encodes combined strategy p neighbors.
strategy match parameter st players common, st
contains actions already chosen algorithm parent Hw Hp
evaluated. Then, ps choice st dierent ps choice x, means p
non-deterministically chosen member coalition C. Thus, p improve
payo, immediately causes fail computation branch nondeterministic
Turing machine. Otherwise, is, p plays action x,
belong C function check, recursively, rest join tree
deviating players improve payos. done propagating current combined
strategy st children Hp JT . Observe propagation necessary even
p belong C, connected coalitions necessarily induce connected
subtrees JT . Indeed, may happen player z belonging coalition
neighbor p w, characteristic edge Hz occurs far Hw join
tree, possibly subtree JT rooted p. (For sake completeness, note
case z neighbor players occurring path Hz Hw JT ,
connectedness property join trees.)
387

fiGottlob, Greco, Scarcello

Figure 13: left: dependency graph game G(s ). right: coalition
witnessing c5 c7 playing conicting way.

Finally, let us consider briey low-level implementation alternating Turing
machine . Existential states correspond guesses, universal states correspond
recursive calls InCoalition x,JT , plus machinery auxiliary computations. step, encode worktape two parameters p st
local variables, x, JT , game G pre-computed constraint relations
input tape. Note p may encoded logspace pointer position
input tape, well combined strategy stw may encoded logspace pointer
corresponding entry constraint relation associated w. Similar considerations
apply local variables, e.g., guessed combined strategy st . Moreover,
easy check computations performed function feasible logspace.
Therefore logspace ATM, overall computation PTIME. (For detailed
description logspace ATM computations, refer interested reader Gottlob
et al., 2001; Gottlob, Leone, & Scarcello, 2002a).
2

Theorem 4.8 Let G acyclic-hypergraph game small neighborhood
graphical normal form. Then, deciding whether G strong Nash equilibria, i.e., SNE(G) =
NP-complete. Hardness holds even G graphical normal form 3-bounded
neighborhood.
Proof. Membership. Given game G, guess global strategy x verify
polynomial time, Lemma 4.7, x fact strong Nash equilibrium.
Hardness. reduction SAT. Consider Boolean formula conjunctive normal
form = c1 . . . cm variables X1 , . . . , Xn assume, w.l.o.g, = 2 ,
> 0. running example, consider formula = (X1 X2 ) (X1 X3 ) (X1
X4 X8 ) (X4 ) (X5 X6 ) (X1 X4 X6 ) (X6 X7 ) (X8 ).
, build following GNF game G(). players partitioned two
sets Pc Pt . set Pc contains exactly one player clause , players
Pt G(G) complete binary tree, whose leaves players Pc ,
shown Figure 13 .
388

fiPure Nash Equilibria: Hard Easy Games

Players G() play actions corresponding variables plus special
actions. Intuitively, player c Pc may play literal occurring clause
represents, players Pt check pair players ci , cj Pc plays
conicting way, is, plays complementary literals. end, game rules
designed way players Pt may improve payos able
form coalition proving pair players playing complementary literals.
worthwhile noting that, general, situation cannot detected single player,
since conicting clauses may far other. instance, Figure 13, c5
c7 play x6 x6 , respectively, detected coalition involving lowest
common ancestor, say p, players Pt occurring two paths c5 c7
p. show global strategy strong Nash equilibrium game
disproving coalition. Indeed, case, conicting clauses
thus formula satisable setting true literals played clause
players.
Formally, player c Pc may play either special action B (read: bad) action
xi (resp. xi ) called literal action, provided Xi variable occurring positively (resp.
negatively) corresponding clause . player Pt may play action
{vi , wi , wi | Xi variable } {T }, read okay me!
next describe utility functions, given global strategy x.
player c Pc gets payo 1 plays literal action unique neighbor (i.e.,
parent) plays , plays B neighbor play (C-i); otherwise,
gets payo 0 (C-ii).
player Pt , utility function ut that:
(T-i) ut (x) = 2 plays wi , parent (if any) plays wi vi , none children plays
B, one children plays either wi xi (depending whether leaf
not);
(T-ii) ut (x) = 2 plays wi , parent (if any) plays wi vi , none children plays
B, one children plays either wi xi ;
(T-iii) ut (x) = 2 plays vi , parent (if any) plays , children play either xi
xi wi wi ;
(T-iv) ut (x) = 1 plays ;
(T-v) ut (x) = 0 cases.
Then, G() following properties.
P1 : Let x global strategy G(). Then, x Nash equilibrium
players Pt play x player Pc playing B.
players Pt play players Pc play B, get payo 1 due
rules (T-iv) (C-i). case, player incentive deviate, since
changing strategy would get payo 0 due rules (T-v) (C-ii).
direction proof, let x Nash equilibrium assume,
contradiction, player c Pc choosing B. (C-i) (C-ii),
389

fiGottlob, Greco, Scarcello

follows neighbor c, say t, play . However, impossible,
would get payo 0 (from T-v) could improve payo playing ,
contradicting fact x Nash equilibrium. Next, assume exists player
Pt play , let Pt player lowest possible level
tree satisfying assumption. follows children clause players,
otherwise, choice t, play , thus would get
payo 0 (T-V) could improve 1 playing . Therefore, Neigh(t) Pc = .
Then, way get payo greater 0 comes rule (T-iii),
means clause children play conicting way, say xi xi . However, since
play , get payo 0 thus could deviate x playing B
getting payo 1. Contradiction.
P2 : Let x Nash equilibrium G(). Then, coalition players getting incentive
deviate x exists two clauses playing x conflicting
way.
(If part.) Since x Nash equilibrium, Property P1 , players Pt play
get payo 1. two clauses, say c1 c2 , playing xi xi , respectively,
may identify improving coalition follows: let rst common ancestor
c1 c2 , let P1 P2 sets vertices (players) occurring paths
c1 c2 , respectively. Then, let change vi , players P1
(resp. P2 ) change wi (resp. wi ) x see Figure 13. Then, game rules
above, players coalition K = P1 P2 {t} get payo 2, improving payo
1 get x.
(Only-if part.) Let K coalition players improving Nash equilibrium x.
property P1 , players Pt K get payo 2, get 1 x. Let
K player Pt highest (close root) level tree, i.e.,
parent(t), any, belong K. (T-iii), children must play
either xi xi wi wi , depending whether leaves
tree. former case, identied two conicting players thus
property immediately proved. Hence, let us investigate latter one. Let
children playing wi wi , respectively. Since play ,
belong K improve payo 2. Therefore, child must
play wi child must play wi , according (T-i) (T-ii). Therefore,
players belong K, too, happen children. Eventually,
leaf descendant plays xi leaf descendant plays xi , qed.
NP hardness deciding existence SNE follows following claim:
satisable G() admits strong Nash equilibrium.
() Assume satisable take satisfying assignment . Let x global
strategy that: player c Pc plays literal occurring clause c true
respect ; player Pt plays . P1 , x Nash equilibrium
G(). Moreover, construction pair players choose conicting actions x . Hence,
due P2 , exists coalition players getting incentive deviating x ,
thus x strong. () Let x strong Nash equilibrium G(). Then,
coalition players getting incentive deviate x. Due P1 , player Pc
390

fiPure Nash Equilibria: Hard Easy Games

plays B, due P2 pair players play conicting way. Hence, x witnesses
satisable. precisely, encodes implicant , extended
satisfying assignment choosing truth value Boolean variables occurring
chosen player x.
2

5. Structurally Tractable Classes Games
strategic games, acyclic graph acyclic hypergraph assumptions
severe restrictions, rather unlikely apply practical contexts.
section, prove even general structurally complicated classes games
dealt ecient way. consider notions treewidth (Robertson &
Seymour, 1986) hypertree width (Gottlob et al., 2002b), broadest known
generalizations graph hypergraph acyclicity, respectively (Gottlob et al., 2000).
show tractability results acyclic games hold generalizations, too, study
relationship two notions.
5.1 Hypertree Decompositions Games
Let H = (V, E) hypergraph. Denote vert(H) edges(H) thesets V E,
respectively. Moreover, set edges E edges(H), let vert(E ) = h.
hypertree hypergraph H triple T, , , = (N, E) rooted
tree, labeling functions associate vertex p N two
sets (p) vert(H) (p) edges(H). = (N , E ) subtree , dene
(T ) = vN (v). denote root root(T ). Moreover, p N , Tp
denotes subtree rooted p.
Definition 5.1 (Gottlob et al., 2002b) hypertree decomposition hypergraph H
hypertree HD = T, , H, = (N, E), satises following
conditions:
1. edge h edges(H), exists p N vert(h) (p) (we say
p covers h);
2. vertex vert(H), set {p N | (p)} induces (connected) subtree
;
3. p N , (p) vert((p));
4. p N , vert((p)) (Tp ) (p).
edge h edges(H) strongly covered HD exists p N vert(h)
(p) h (p). case, say p strongly covers h. hypertree decomposition
HD hypergraph H complete decomposition H every edge H strongly covered
HD. width hypertree decomposition T, , maxpvertices(T ) |(p)|.
hypertree width hw(H) H minimum width hypertree decompositions.
Note constant k checking whether hypergraph hypertree-width
k feasible polynomial time (Gottlob et al., 2002b).
391

fiGottlob, Greco, Scarcello

G

{F,L,G,M,P,R} {HF, HL}

F
P

R

{F,G,P} {HG}

{F,M,P,R} {HM, HR}

L

L



{F,P} {HP}

Figure 14: H(FRIENDS) hypertree decomposition it.
Let k > 0 xed constant. Then, say game G k-bounded hypertree
width hypertree width associated hypergraph H(G) k. hypertree
decomposition width k (if any) computed polynomial time.
Recall notion bounded hypertree-width generalizes notion (hypergraph) acyclicity. particular, class acyclic-hypergraph games precisely class
games G whose hypergraph H(G) hypertree width 1.
Example 5.2 Consider game FRIENDS Example 2.1. Figure 5 shows
left associated hypergraph, right join tree it. fact, join tree
hypertree decomposition width 1 hypergraph, where, vertex p, (p)
set hyperedges reported p (p) set players occurring hyperedges.
involved example, consider extension FRIENDS FRIENDS
new player Laura (short: L) joins group. Laura would like go George
cinema, Pauline Mary opera. Figure 14 shows left hypergraph H(FRIENDS). hypergraph acyclic, low degree cyclicity.
Indeed, hypertree width 2, witnessed hypertree decomposition width 2
shown right, Figure 14. Here, vertex p decomposition tree, two
sets denote labels (p) (p), respectively.
2
class games C said bounded hypertree-width nite k
that, game G C, G k-bounded hypertree width. next show
tractability results hold acyclic-hypergraph games holds bounded hypertreewidth games, well.
Theorem 5.3 Deciding existence pure Nash equilibria, well computing Nash
equilibrium feasible polynomial time classes C games bounded hypertreewidth every game G C small neighborhood graphical normal
form.
Proof. Let C class games game G C hypertree-width
k, k > 0, small neighborhood graphical normal form. Then,
build constraint satisfaction problem CSP (G) polynomial time, Theorem 4.4.
392

fiPure Nash Equilibria: Hard Easy Games

Moreover, hypertree width G k, hypergraph H(G)
hypergraph H associated CSP (G). results Gottlob et al. (2001), follows
CSP (G) solved polynomial time, equivalent deciding existence
Nash equilibria polynomial time, Theorem 4.3.
Constructively, compute polynomial time hypertree decomposition H width k, exploit decomposition building equivalent acyclic problem
(by putting together constraints players occurring vertex decomposition tree), nally solve problem using algorithm shown Figure 10. 2
acyclic-hypergraph games, result immediately extended problem
computing Pareto Nash equilibrium.
Corollary 5.4 Deciding existence Pareto Nash equilibria, well computing
Pareto Nash equilibrium pure strategies feasible polynomial time classes
C games bounded hypertree-width every game G C small
neighborhood graphical normal form.
5.2 Treewidth Hypertree Width Games
next consider treewidth game structures. Recall game may represented either primal graph dual graph, shown Figure 5 game
FRIENDS. Therefore, rst question graph better far identication
tractable classes games concerned. results Gottlob et al. (2000), know
notion bounded treewidth primal graph generalized notion
bounded hypertree width, is, looking hypertree width game hypergraph
may identify wider classes tractable games. Moreover, results Greco
Scarcello (2003), follows looking treewidth dependency graph better
looking treewidth primal graph.4
thus know bounded treewidth primal graph sucient ensuring
game tractability. However, two questions still answered, subject
section:
1. tractability results bounded treewidth primal graph extend wider
class games bounded treewidth dependency graph?
2. relationship bounded treewidth dependency graph
bounded hypertree width game hypergraph?
Definition 5.5 (Robertson & Seymour, 1986) tree decomposition graph G =
(V, E) pair T, , = (N, F ) tree, labeling function assigning
vertex p N set vertices (p) V , following conditions
satised:
(1) vertex b G, exists p N b (p);
4. fact, result relationship primal graph incidence graph. However, easy
see that, games, treewidth incidence graph treewidth dependency
graph.

393

fiGottlob, Greco, Scarcello

G

F
P

{F,L,P,R}

R
{L,P,R,M}

L

{F,G,L,P}



Figure 15: G(FRIENDS) tree decomposition it.
(2) edge {b, d} E, exists p N {b, d} (p);
(3) vertex b G, set {p N | b (p)} induces connected subtree .
Note Condition 1 subsumed Condition 2 graphs without isolated vertices.
width tree decomposition T, maxpN |(p) 1|. treewidth G
minimum width tree decompositions. notion generalizes graph acyclicity,
acyclic graphs precisely graphs treewidth 1. 5
Example 5.6 Consider game FRIENDS introduced Example 5.2. Figure 15 shows left cyclic dependency graph G(FRIENDS), right
tree decomposition width 3 graph.
2
Let k > 0 xed integer, let G game. say game G k-bounded
treewidth treewidth dependency graph G(G) k. Recall that, given
graph G, computing tree-decomposition width k G (if any) feasible
polynomial (actually, linear) time (Bodlaender, 1997).
next prove interesting graph-theoretic result shed light dierent
possible representations game structures: every class games bounded treewidth
bounded hypertree width, too. remark previous results relationship
treewidth hypertree width described literature (e.g. Gottlob et al.,
2000) cannot used here. Indeed, deal primal graph dual graph
representations, interested dependency graph, eective
primal graph, somehow incomparable (optimal) dual graph.
detailed comparison two latter notions reported Greco Scarcello (2003).
Theorem 5.7 game G, hypertreewidth (H(G)) treewidth(G(G)) + 1.
Proof. Let TD tree decomposition G(G) let k 1 width, is,
largest label vertices TD contains k players. Then, show
hypertree decomposition H(G) width k. Recall H(G) contains, player
5. Observe 1 definition treewidth introduced order get correspondence acyclic graphs, 2 minimum cardinality largest label tree decomposition.

394

fiPure Nash Equilibria: Hard Easy Games

p, characteristic edge H(p) = {p} Neigh(p). Let HD = T, , hypertree
that:
tree form decomposition tree TD, i.e., tree
isomorphism : vert(T ) vert(T D) TD;
vertex v , (v) = {H(p) | p (v)}, i.e., (v) contains characteristic
edge player occurring vertex tree decomposition corresponding
v;
(v) set vertices occurring edges (v), i.e., contains players
(v) neighbors.
Note width HD k, determined largest label, contains
number elements largest label TD.
claim HD hypertree decomposition H(G). Consider four conditions
Denition 5.1: Conditions 3 4 trivially satised because, vertex v,
(v) = vert((v)), construction. Condition 1 guaranteed fact TD satises
corresponding Conditions 1 2. next show Condition 2, i.e., connectedness
condition, holds, too.
Let v1 v2 two vertices exists p (v1 )(v2 ). Let v1 = (v1 )
v2 = (v2 ) sets vertices tree decomposition TD corresponding v1
v2 , respectively. Since p (v1 ) p (v2 ), two players p1 p2 (i)
H(p1 ) (v1 ) p H(p1 ), (ii) H(p2 ) (v2 ) p H(p2 ). Then, construction,
p1 v1 p2 v2 (see Figure 16).
claim that, vertex v unique path connecting v1 v2 (denoted
v1 v2 ), (v) contains player set {p1 , p2 , p}, entails p (v)
hence Condition 2 satised HD. equivalent claim, tree
decomposition TD, vertex v path v1 v2 contains player {p1 , p2 , p}.
v1 v2 contain p, claim trivially holds vertices
path v1 v2 must contain p, Condition 3 tree decompositions (the connectedness
condition).
Hence, let us assume v1 contain p. Since p H(p1 ), means p
neighbor p1 thus exists vertex TD, say v3 = v1 , whose labeling contains
p p1 . Assume v2 contains p. Figure 16.1 shows path comprising
vertices v1 , v3 , v2 notice v1 cannot path v3 v2 , otherwise
contain p well. result follows observing that, Condition 3 tree
decompositions, vertices path v1 v3 must contain p1 , vertices
path v3 v2 must contain p. Similarly, assume v2 contain p. case,
since p neighbor p2 (recall discussion p1 ), vertex v4 TD
whose labeling contains p2 p. Figure 16.2 shows vertices look
like tree decomposition TD. Then, result follows observing vertices
path v1 v3 contains p1 , vertices path v3 v4 contains p, vertices
2
path v4 v2 contains p2 .
next show converse hold, is, classes games
bounded hypertree width, unbounded treewidth. is, technique based
395

fiGottlob, Greco, Scarcello

Figure 16: Schema reduction proof Theorem 5.7.
hypertree width game hypergraph eective corresponding technique
based treewidth dependency graph, allows us identify strictly
broader classes tractable games.
Theorem 5.8 classes C games hypertree width 1 unbounded
treewidth, i.e., that, finite k > 0, game G C treewidth
G bounded k.
Proof. Take class games every player depends players.
every game G, H(G) acyclic thus hypertree width 1, G(G) clique
containing players treewidth number players minus 1.
2

396

fiPure Nash Equilibria: Hard Easy Games

Theorem 5.3, Corollary 5.4, Theorem 5.7, immediately get following
tractability results bounded treewidth games.
Corollary 5.9 Deciding existence pure (Pareto) Nash equilibria, well computing pure (Pareto) Nash equilibrium feasible polynomial time classes C
games bounded treewidth every game G C small neighborhood
graphical normal form. Moreover, Nash equilibria games computed
time polynomial combined size input output.

6. Parallel Complexity Easy Games
section, show dealing Nash equilibria games good structural
properties tractable also parallelizable. precisely, show deciding
existence Nash equilibria graphical games player interactions low
degree cyclicity complete class LOGCFL. Also, show computing
equilibrium belongs functional version LOGCFL.
complexity class LOGCFL consists decision problems logspace reducible context-free language. order prove following theorem, exploit
characterization LOGCFL terms circuits.
recall Boolean circuit Gn n inputs nite directed acyclic graph whose
nodes called gates labeled follows. Gates fan-in (indegree) zero called
circuit input gates labeled set {false, true, z1 , z2 , . . . , zn , z1 , z2 , . . . , zn }.
gates labeled either AND, OR, NOT. fan-in gates labeled must
one. unique node fan-out (outdegree) zero called output gate. evaluation
Gn input string w length n dened standard way. particular, input
gate g labeled zi (resp. zi ) gets value true (resp. false) ith bit w 1 (resp. 0);
otherwise, g gets value false (resp. true).
Boolean circuit thus given triple (N, A, label), N set nodes
(gates), set arcs, label labeling nodes described.
depth Boolean circuit G length longest path G circuit
input gate output gate G. size S(G) G number gates (including
input-gates) G.
family G Boolean circuits sequence (G0 , G1 , G2 , . . .), nth circuit Gn
n inputs. family logspace-uniform exists logspace Turing machine
which, input string containing n bits 1, outputs circuit Gn . Note size
nth circuit Gn logspace-uniform family G polynomial n. Intuitively,
uniformity condition crucial characterizations low parallel complexity classes terms
circuits, hidden inherent sequentialities circuit construction process must
avoided. fact, cicuits serve parallel devices evaluating input strings
length n, must constructed n separately, constructible
parallel themselves. assured requiring logspace uniformity, LOGSPACE
highly parallelizable complexity class contained LOGCFL.

language L accepted family G circuits dened follows: L = n0 Ln ,
Ln set input strings accepted nth member Gn family. input
string w length n accepted circuit Gn Gn evaluates true input w.
397

fiGottlob, Greco, Scarcello

family G Boolean circuits bounded fan-in exists constant c
gate member Gn G fan-in bounded c.
family G Boolean circuits semi-unbounded following two conditions met:
circuits G involve non-leaves gates, gates
(negation may thus occur circuit input gates);
constant c gate member Gn G fan-in
bounded c (the gates may unbounded fan-in).
1, ACi denotes class languages recognized logspace-uniform families
Boolean circuits depth O(logi n).
1, NCi denotes class languages recognized logspace-uniform families
Boolean circuits depth O(logi n) bounded fan-in.
1, SACi denotes class languages recognized semi-unbounded
logspace-uniform families Boolean circuits depth O(logi n).
Venkateswaran (1991) proved following important relationship LOGCFL
semi-unbounded circuits:
LOGCFL = SAC1 .
Since LOGCFL = SAC1 AC1 NC2 , problems LOGCFL highly
parallelizable. fact, problem LOGCFL solvable logarithmic time
concurrent-read concurrent-write parallel random access machine (CRCW PRAM)
polynomial number processors, log2 -time exclusive-read exclusive-write
PRAM (EREW PRAM) polynomial number processors (Johnson, 1990).
next show evaluation problem SAC1 circuits transformed
logspace considered Nash equilibrium existence problems.
g19

g19
g17

g18

g13 g14 g15 g16
g8

g17

g16

g13

g16

g9 g10 g11 g12

g8

g9

g11

g12

qx1 g1 x2 g2 qx2 g3 x4 g4 x5 g5 qx6 g6 x7 g7

g1

g3

g6

g6

A)

B)

C)

Figure 17: (A) normalized circuit, (B)its skeleton tree, (C) labeling corresponding
proof tree.

Theorem 6.1 existence problem pure Nash equilibria LOGCFL-complete
following classes strategic games graphical normal form: acyclic-graph games, acyclichypergraph games, games bounded treewidth, games bounded hypertree-width.
398

fiPure Nash Equilibria: Hard Easy Games

Proof. sucient show membership bounded hypertree width (the largest
4 classes) hardness acyclic-graph games (the smallest one).
Membership. Nash equilibrium existence problem NF games bounded hypertree width LOGCFL because, shown Section 4, problem transformed
logspace CSP bounded hypertree width, and, shown Gottlob et al. (2001),
checking satisability latter LOGCFL. (Recall LOGCFL closed
logspace reductions.)
Hardness. assume logspace-uniform family C = {G1 , G2 , . . .} SAC1 circuits
given, prove problem checking whether binary string w accepted
C translated logspace acyclic Nash equilibrium problem NF.
input w, compute logspace appropriate circuit C = G|w| . shown Gottlob
et al. (2001), circuit transformed logspace equivalent normalized circuit
C stratied strictly alternating (see Figure 17 (A)), tree-shaped proof
skeleton SKEL (see Figure 17 (B)) encompasses common structure possible
proof trees (C , w). proof tree subtree C gates value 1 witnessing
C accepts w. proof tree corresponds appropriate labeling SKEL
gates C (for example, labeling shown Figure 17 (C)). labeling correct
root SKEL labeled output gate C , gate labeled g two
children labeled input gates g, node SKEL labeled g
one child labeled input gate g, leaf labeled input gate
C whose output next higher level 1. C accepts w exists
proof tree (C , w), thus exists correct labeling SKEL.
Build strategic game G (C , w) SKEL follows. set players consists
vertices V SKEL plus two special players . possible actions
players V pairs (g, t), g gate truth value {true, false}.
utilities players V given follows.
1. utility leaf u SKEL depends action 1 plays
input gate g C g associated constant true, g gate
corresponds input bit 0 string w, g gate corresponds
input bit 1 w. Otherwise, utility u 0.
2. non leaf vertex p V gets payo 1, plays action (g, true), either
p vertex unique child p SKEL takes action (g , true), g
child gate g C , p vertex unique children p
SKEL take actions (g , true), (g , true), respectively, g g
children gate g C .
3. non leaf vertex p V gets payo 1, plays action action (g, false),
either p vertex unique child p SKEL takes action (g , false),
g child g C , p vertex unique children p
SKEL take actions (g , ), (g , ), respectively, g g children
g C = false.
4. cases, actions non leaf vertex p V utility 1.
According dened far, easy see every Nash equilibrium
game corresponds labeling SKEL assigning player V gate g
399

fiGottlob, Greco, Scarcello

respective action (g, t). particular, root node r forced labeled
output gate g C , action played r (g , true) particular
labeling proof tree (g , false) otherwise.
remains dene actions utilities special players .
intuitive role kill equilibria correspond proof three i.e.,
root vertex plays (g , false)). possible actions {ok, head, tail}
, {head, tail} . strategies plays ok utility 1 root
vertex r SKEL plays (g , true)) utility 0 otherwise. Strategies plays head
(resp., tail) utility 1 r plays (g , false) plays tail (resp., head),
0 otherwise. Thus, case r plays (g , false), player tries play opposite player
. strategies plays head (resp., tail) utility 1 player plays
action, 0 otherwise.
Therefore, case C outputs 0 input w, r plays (g , false), thus tries play
opposite tries mimic . classical non-equilibrium situation.
summary, Nash equilibrium G corresponds proof tree (C , w). Note also
G(G) acyclic, construction G (C , w) done logspace. 2
Note that, Denition 2.2, Pareto Nash equilibrium exists Nash
equilibrium exists.
Corollary 6.2 existence problem pure Pareto Nash equilibria LOGCFL-complete
following classes strategic games graphical normal form: acyclic-graph games,
acyclic-hypergraph games, games bounded treewidth, games bounded hypertreewidth.
Finally, far computation Nash equilibria concerned, following corollary
follows result result Gottlob al. (2002a), stating
witnesses (i.e., proof trees) LOGCFL decision problems computed functional
LOGCFL (i.e., logspace oracle LOGCFL, or, equivalently, using SAC1
circuits.
Corollary 6.3 classes games mentioned Theorem 6.1, computation
single pure Nash equilibria done functional LOGCFL, therefore
parallel complexity class N C2 .

7. Conclusion
paper determined precise complexity pure Nash equilibria strategic
games. depicted Figure 2, study proceeded along three directions: representation issues, structural properties player interactions, dierent notions equilibria.
Indeed, besides plain Nash equilibria, considered Pareto Strong Nash equilibria,
look Nash equilibria dominated Nash equilibrium,
proles possible coalition players may improve payos members,
respectively.
turns that, apart simple case standard normal form, deciding
existence Nash equilibria intractable problem (unless PTIME = NP),
400

fiPure Nash Equilibria: Hard Easy Games

restriction relationships among players. Interestingly, Strong Nash Equilibria,
problem located second level polynomial hierarchy, gives us fresh
game-theoretic view class P2 , class problems whose positive instances
characterized coalition players cooperate provide equilibrium, win
disjoint coalition, fails trying improve utility
players.
However, paper collection bad news. Rather, central goal
single large classes strategic games detecting Nash equilibria tractable
problem. particular, early studies game theory mainly focused games
small number players (e.g., traditional two-player framework), interested
large population games, too. cases, adopting standard normal form
clearly impractical as, player, one specify payos combination
choices players game. thus considered dierent representation
games, known literature graphical games (Kearns et al., 2001b), payos
player p functions ps neighbors only, is, ps utility function depends
players p directly interested in. relationships among players may
represented graph or, faithfully, hypergraph. showed that, utility
functions represented tables (graphical normal form) game structure acyclic
low degree cyclicity (i.e., bounded hypertree width), deciding
existence Nash equilibrium possibly computing feasible polynomial time.
results complement obtained graphical games mixed Nash equilibria
framework (e.g. Kearns et al., 2001b; Kearns & Mansour, 2002). Moreover, case
quasi-acyclic structures, also able extend tractability classes games
utility functions given implicitly (as general form), provided player
small number neighbors many available actions.
paper sheds light sources complexity nding pure Nash equilibria
strategic games, and, particular, roles played game representations
game structures. worthwhile noting aspects game theory received
renewed deal attention recently. instance, see Papadimitriou (2004) recent
work complexity pure Nash equilibria particular classes games,
various contributions dierent kinds concise game representations (e.g. Koller &
Milch, 2001; Vickrey, 2002; Kearns et al., 2001b; Leyton-Brown & Tennenholtz, 2003; Gal
& Pfeer, 2004; Kearns & Mansour, 2002).
recall preliminary version present work presented
9th ACM Conference Theoretical Aspects Rationality Knowledge (TARK03).
Since then, results extended along dierent directions. particular, Alvarez
et al. (2005) considered version general form games, called games implicit
form, also payo values given succinct way. showed that,
games, complexity deciding existence pure Nash equilibria increases
rst level second level polynomial hierarchy. point general
form slightly dierent general form adopted mentioned paper,
confusion may arise reading citation results presented TARK03
paper (whose full version present paper). terminology, Turing-machine
encoding payo functions general form games classied non-uniform,
uniform time-bound. However, apart subtle technical issues,
401

fiGottlob, Greco, Scarcello

results general form games non implicit actions similar ours,
contributions focus games large number actions, hardness results hold
even games xed number actions payo levels. Moreover, show
hardness holds even acyclic games, consider restriction player
interactions. Observe results may immediately strengthened, given
proofs GNF games arbitrary player interactions follows NP-hardness
holds even constant-time utility functions (as discussed Remark 3.9).
Another line research studies games computation Nash equilibrium
satisfactory, one rather interested equilibria satisfy additional requirements (e.g., best social welfare). Greco Scarcello (2004) proved deciding
existence pure Nash equilibria, called constrained Nash equilibria, intractable
even simple requirements. However, also able identify restrictions
(for player interactions requirements) making existence computation
problems easy. Recent contributions subject (on pure mixed Nash equilibria) done Schoenebeck al. (2005) Greco Scarcello (2005).
Finally, observe interesting connection among strong Nash equilibria
equilibria studied cooperative/coalitional game theory (e.g. Mas-Colell, Whinston, & Green, 1995). framework, subset K players, given
utility players K may get, cooperate together. core game
set proles x subset players may improve utilities forming coalition, deviating x (Gillies, 1953). Recently, Conitzer
Sandholm (2003a) proposed concise representation coalition utilities, showed
determining whether core game nonempty NP-hard. interesting
future work may concern detailed study complexity coalitional games, possibly exploiting suitable notions quasi-acyclic structures identifying relevant tractable
classes.

Acknowledgments
Part work published preliminary form Proceedings 9th
ACM Conference Theoretical Aspects Rationality Knowledge (TARK03).
Georg Gottlobs work supported Austrian Science Fund (FWF)
project Nr. P17222-N04 Complementary Approaches Constraint Satisfaction,
GAMES Network Excellence EU.
thank anonymous referees Tuomas Sandholm useful comments.

References
Alvarez, C., Gabarro, J., & Serna, M. (2005). Pure Nash equilibria games
large number actions. Electronic Colloquium Computational Complexity, Report TR05-031.
Aumann, R. (1959). Accetable points general cooperative n-person games. Contribution
Theory Games, IV.
402

fiPure Nash Equilibria: Hard Easy Games

Aumann, R. (1985). game theory trying accomplish?. Frontiers Economics,
2876.
Beeri, C., Fagin, R., Maier, D., & Yannakakis, M. (1983). desirability acyclic
database schemes. Journal ACM, 30(3), 479513.
Bodlaender, H. (1997). Treewidth: Algorithmic techniques results. Proc.
22nd International Symposium Mathematical Foundations Computer Science
(MFCS97), pp. 1936, Bratislava, Slovakia.
Chandra, A., Kozen, D., & Stockmeyer, L. (1981). Alternation. Journal ACM, 28(1),
114133.
Conitzer, V., & Sandholm, T. (2003a). Complexity determining nonemptiness
core. Proc. 18th International Joint Conference Artificial Intelligence
(IJCAI03), pp. 613618, Acapulco, Mexico.
Conitzer, V., & Sandholm, T. (2003b). Complexity results nash equilibria. Proc.
18th International Joint Conference Artificial Intelligence (IJCAI03), pp.
765771, Acapulco, Mexico.
Deng, X., Papadimitriou, C., & Safra, S. (2002). complexity equilibria. Proc.
34th Annual ACM Symposium Theory Computing (STOC02), pp. 6771,
Montreal, Canada.
Downey, R., & Fellows, M. (1995). Fixed-parameter tractability completeness i: Basic
results. SIAM Journal Computing, 24(4), 873921.
Fabrikant, A., Papadimitriou, C., & Talwar, K. (2004). complexity pure nash
equilibria. Proc. 36th Annual ACM Symposium Theory Computing
(STOC04), pp. 604612, Chicago, IL, USA.
Fagin, R. (1983). Degrees acyclicity hypergraphs relational database schemes.
Journal ACM, 30(3), 514550.
Fotakis, D., Kontogiannis, S., Koutsoupias, E., Mavronicolas, M., & Spirakis, P. (2002).
structure complexity nash equilibria selsh routing game. Proc.
29th International Colloquium Automata, Languages Programming
(ICALP02), pp. 123134, Malaga, Spain.
Gal, Y., & Pfeer, A. (2004). Reasoning rationality beliefs. Proc.
3rd International Joint Conference Autonomous Agents Multiagent Systems
(AAMAS04), pp. 774781, New York, NY, USA.
Garey, M., & Johnson, D. (1979). Computers Intractability. Guide Theory
NP-completeness. Freeman Comp., NY, USA.
Gilboa, I., & Zemel, E. (1989). Nash correlated equilibria: complexity considerations. Games Economic Behaviour, 1, 8093.
403

fiGottlob, Greco, Scarcello

Gillies, D. (1953). theorems n-person games. PhD thesis, Princeton, Dept.
Mathematics.
Gottlob, G., Leone, N., & Scarcello, S. (2000). comparison structural csp decomposition
methods. Artificial Intelligence, 124(2), 243282.
Gottlob, G., Leone, N., & Scarcello, S. (2001). complexity acyclic conjunctive queries.
Journal ACM, 48(3), 431498.
Gottlob, G., Leone, N., & Scarcello, S. (2002a). Computing logc certicates. Theoretical
Computer Science, 270(1-2), 761777.
Gottlob, G., Leone, N., & Scarcello, S. (2002b). Hypertree decompositions tractable
queries. Journal Computer System Sciences, 63(3), 579627.
Greco, G., & Scarcello, S. (2003). Non-binary constraints optimal dual-graph representations. Proc. 18th International Joint Conference Artificial Intelligence
(IJCAI03), pp. 227232, Acapulco, Mexico.
Greco, G., & Scarcello, S. (2004). Constrained Pure Nash Equilibria Graphical Games.
Proc. 16th Eureopean Conference Artificial Intelligence (ECAI04), pp.
181185, Valencia, Spain.
Greco, G., & Scarcello, S. (2005). Bounding Uncertainty Graphical Games:
Complexity Simple Requirements, Pareto Strong Nash Equilibria. appear
Proc. 21st Conference Uncertainty Artificial Intelligence (UAI05),
Edinburgh, Scotland.
Johnson, D. (1990). catalog complexity classes. Handbook Theoretical Computer
Science, Volume A: Algorithms Complexity, 67161.
Johnson, D., Papadimitriou, C., & Yannakakis, M. (1998). easy local search?.
Journal Computer System Sciences, 37, 79100.
Kearns, M., Littman, M., & Singh, S. (2001a). ecient exact algorithm singly connected graphical games. Proc. 14th International Conference Neural Information Processing Systems (NIPS01), pp. 817823, Vancouver, British Columbia,
Canada.
Kearns, M., Littman, M., & Singh, S. (2001b). Graphical models game theory. Proc.
17th International Conference Uncertainty AI (UAI01), pp. 253260,
Seattle, Washington, USA.
Kearns, M., & Mansour, Y. (2002). Ecient nash computation large population games
bounded inuence. Proc. 18th International Conference Uncertainty
AI (UAI02), pp. 259266, Edmonton, Alberta, Canada.
Koller, D., & Megiddo, N. (1992). complexity two-person zero-sum games extensive
form. Games Economic Behavior, 2, 528552.
404

fiPure Nash Equilibria: Hard Easy Games

Koller, D., & Megiddo, N. (1996). Finding mixed strategies small supports extensive
form games. International Journal Game Theory, 14, 7392.
Koller, D., Megiddo, N., & von Stengel, B. (1996). Ecient computation equilibria
extensive two-person games. Games Economic Behavior, 14, 220246.
Koller, D., & Milch, B. (2001). Multi-agent inuence diagrams representing solving
games. Proc. 7th International Joint Conference Artificial Intelligence
(IJCAI01), pp. 10271034, Seattle, Washington, USA.
Leyton-Brown, K., & Tennenholtz, M. (2003). Local-eect games. Proc. 18th
International Joint Conference Artificial Intelligence (IJCAI03), pp. 772780,
Acapulco, Mexico.
Maier, D. (1986). Theory Relational Databases, Rochville, Md, Computer Science
Press.
Mas-Colell, A., Whinston, M., & Green, J. (1995). Microeconomic Theor. Oxford University
Press.
Maskin, E. (1985). theory implementation nash equilibrium. Social Goals
Organization: Essays memory Elisha Pazner, 173204.
McKelvey, R., & McLennan, A. (1996). Computation equilibria nite games. Handbook
Computational Economics, 87142.
Megiddo, N., & Papadimitriou, C. (1991). total functions, existence theorems,
computational complexity. Theoretical Computer Science, 81(2), 317324.
Monderer, D., & Shapley, L. (1993). Potential games. Games Economic Behavior.
Nash, J. (1951). Non-cooperative games. Annals Mathematics, 54(2), 286295.
Osborne, M., & Rubinstein, A. (1994). Course Game Theory. MIT Press.
Owen, G. (1982). Game Theory. Academic Press, New York.
Papadimitriou, C. (1994a). Computational Complexity. AAddison-Wesley, Reading, Mass.
Papadimitriou, C. (1994b). complexity parity argument inecient
proofs existence. Journal Computer System Sciences, 48(3), 498532.
Papadimitriou, C. (2001). Algorithms, games, internet. Proc. 28th
International Colloqium Automata, Languages Programming (ICALP01), pp.
13, Crete, Greece.
Robertson, N., & Seymour, P. (1986). Graph minors ii. algorithmic aspects tree width.
Journal Algorithms, 7, 309322.
Rosenthal, R. (1973). class games possessing pure-strategy nash equilibria. International Journal Game Theory, 2, 6567.
405

fiGottlob, Greco, Scarcello

Schoenebeck, G.R., & Vadhan, S.P. (2005). Computational Complexity Nash Equilibria Concisely Represented Games. Electronic Colloquium Computational Complexity, Report TR05-052.
Stockmeyer, L., & Meyer, A. (1973). Word problems requiring exponential time: Preliminary report. Proc. 5th Annual ACM Symposium Theory Computing
(STOC73), pp. 19.
Vardi, M. (2000). Constraint satisfaction database theory: tutorial. Proc.
19th ACM SIGMOD-SIGACT-SIGART Symposium Principles Database
Systems, pp. 7685, Dallas, Texas, USA.
Venkateswaran, H. (1991). Properties characterize logc. Journal Computer
System Sciences, 43(2), 380404.
Vickrey, D. amd Koller, D. (2002). Multi-agent algortihms solving graphical games.
Proc. 18th National Conference Artificial Intelligence (AAAI02), p. 345251
Edmonton, Alberta, Canada.
Yannakakis, M. (1981). Algorithms acyclic database schemes. Proc. 7th International Conference Large Data Bases (VLDB81), p. 8294 Cannes, France.

406

fiJournal Artificial Intelligence Research 24 (2005) 581-621

Submitted 01/05; published 10/05

Macro-FF: Improving AI Planning Automatically
Learned Macro-Operators
Adi Botea
Markus Enzenberger
Martin Muller
Jonathan Schaeffer

adib@cs.ualberta.ca
emarkus@cs.ualberta.ca
mmueller@cs.ualberta.ca
jonathan@cs.ualberta.ca

Department Computing Science, University Alberta
Edmonton, AB Canada T6G 2E8

Abstract
Despite recent progress AI planning, many benchmarks remain challenging current planners. many domains, performance planner greatly improved
discovering exploiting information domain structure explicitly
encoded initial PDDL formulation. paper present compare two automated methods learn relevant information previous experience domain
use solve new problem instances. methods share common four-step strategy.
First, domain analyzed structural information extracted, macro-operators
generated based previously discovered structure. filtering ranking procedure selects useful macro-operators. Finally, selected macros used
speed future searches.
successfully used approach fourth international planning competition IPC-4. system, Macro-FF, extends Hoffmanns state-of-the-art planner FF
2.3 support two kinds macro-operators, engineering enhancements.
demonstrate effectiveness ideas benchmarks international planning competitions. results indicate large reduction search effort complex domains
structural information inferred.

1. Introduction
AI planning recently made great advances. evolution international planning
competition four editions (Bacchus, 2001; Hoffmann, Edelkamp, Englert, Liporace,
Thiebaux, & Trug, 2004; Long & Fox, 2003; McDermott, 2000) accurately reflects this.
Successive editions introduced complex realistic benchmarks, harder
problem instances domain. top performers could successfully solve large
percentage problems time. However, many hard domains, including benchmarks
used IPC-4, still pose great challenges current automated planning systems.
main claim paper many domains, performance planner
improved inferring exploiting information domain structure
explicitly encoded initial PDDL formulation. implicit structural information domain encodes is, arguably, proportional complex domain is,
realistically models world. example, consider driving truck
two locations. operation composed many subtasks real world. name
few, truck fueled driver assigned. detailed planning
c
2005
AI Access Foundation. rights reserved.

fiBotea, Enzenberger, Muller, & Schaeffer

Figure 1: CA-ED Integrating component abstraction macro-operators standard
planning framework.

formulation, would define several operators fuel, assign-driver, drive.
representation already contains implicit information domain structure.
quite obvious human driving truck two remote locations would
macro-action first fuel truck assign driver (with ordering constraints
two actions) next apply drive operator. simpler formulation,
remove operators fuel assign-driver consider that, model,
truck needs neither fuel driver. driving truck modeled single action,
details described removed model.
article present evaluate two automated methods learn implicit
domain knowledge use simplify planning new problem instances. learning
uses several training problems domain. methods share common four-step
pattern:
1. Analysis Extract new information domain structure.
2. Generation Build macro-operators based previously acquired information.
3. Filtering Select promising macro-operators.
4. Planning Use selected macro-operators improve planning future problems.
1.1 Component Abstraction Enhanced Domain
first method produces small set macro-operators PDDL formulations
domain several training problems. macro-operators added initial domain
formulation, resulting enhanced domain expressed description language.
definitions enhanced domain new problem instances given input
planner, need implement additional support macro-operators (Botea,
Muller, & Schaeffer, 2004b). call approach CA-ED Component Abstraction
Enhanced Domain.
Figure 1 shows general architecture CA-ED. box Abstraction figure
includes steps 1 3 above. Step 1 uses component abstraction, technique exploits
permanent relationships low-level features problem. Low-level features (i.e.,
constant symbols) linked static facts (i.e., facts remain true planning) form
complex unit called abstract component.
582

fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators

Figure 2: general architecture SOL-EP. Enhanced Planner means planner
capabilities handle macros.

step 2, local analysis abstract components builds macros speed planning. CA-ED generates macros using forward search process space macro operators. macro operator built ordered sequence operators linked
mapping operators variables. Applying macro operator semantically equivalent applying contained operators given order, respecting macros variable
mapping interactions preconditions effects.
step 3 (filtering), set heuristic rules used prune search space generate
macros likely useful. Macros filtered dynamically, based
performance solving training problems, effective ones kept
future use.
best macro operators method generates added new operators
initial PDDL domain formulation, enhancing initial set operators. Hence, need
complete macro-operator definitions, including precondition effect formulas. Expressing formulas starting contained operators easy STRIPS, hard
larger PDDL subsets ADL, preconditions effects contained
operators interact complex ways. See Section 3.1 detailed explanation.
CA-ED work required implement step 4, since planner makes distinction
macro operator normal operator. enhanced domain formulation
available standard STRIPS, planner used solve problem instances.
architecture CA-ED two main limitations. First, component abstraction
currently applied domains static facts formulation. Second, adding
macros original domain definition limited STRIPS domains.
1.2 Solution Enhanced Planner
second abstraction method presented article suffer
limitations, applicable larger class problems. call approach SOL-EP,
stands Solution Enhanced Planner. SOL-EP extracts macros solutions
training problems uses planner enhanced capabilities handle
macros. general architecture approach shown Figure 2. before,
module Abstraction implements steps 1 3. Instead using static facts component
583

fiBotea, Enzenberger, Muller, & Schaeffer

abstraction CA-ED, step 1 SOL-EP processes solutions training problems.
extend applicability STRIPS ADL domains, different macro representation
used compared CA-ED. SOL-EP macro represented sequence operators
mapping operators variables rather compilation single operator
complete definition precondition effects. shown Section 3.1, ADL
domains, impractical use macros complete definition.
reason, SOL-EP macros cannot added original domain formulation
new operators anymore. distinct input data planner, step 4
planner enhanced code handle macro operators. Since SOL-EP general,
used approach fourth planning competition IPC-4.
implemented ideas presented article Macro-FF, adaptive planning system developed top FF version 2.3 (Hoffmann & Nebel, 2001). FF 2.3
state-of-the-art fully automatic planner uses heuristic search approach. solving
mechanism FF two main phases: preprocessing search. preprocessing phase
builds data structures needed search time. operators instantiated ground
actions, predicates instantiated facts. action, pointers stored
precondition facts, add-effect facts, delete-effect facts. Similarly,
fact f , pointers stored actions f precondition, actions f
add effect, actions f delete effect. information instantly
available run-time, states evaluated relaxed graphplan heuristic.
Macro-FF adds ability automatically learn use macro-actions, goal
improving search. Macro-FF also includes engineering enhancements reduce
space CPU time requirements performance bottlenecks test
problems. engineering enhancements affect neither number expanded nodes
quality found plans.
contributions article include detailed presentation Macro-FF.
present compare two methods automatically create use macro-operators
domain-independent AI planning. Experimental evaluation focused several main directions. First, impact engineering enhancements analyzed. evaluate
SOL-EP macros implemented competition system improve planning.
experiments use testbeds domains used IPC-4. Finally, compare two abstraction methods test instances techniques applicable, evaluate
planning macros.
rest paper structured follows: next two sections describe CA-ED
SOL-EP respectively. Section 4 summarizes implementation enhancements
added FF. present experimental results evaluate methods Section 5.
Section 6 briefly review related work discuss similarities differences
work. last section contains conclusions ideas future work.

2. Enhancing Domain Macros based Component Abstraction
first part section introduces component abstraction. topic second
part CA-ED macro-operators.
584

fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators

Figure 3: Static graph Rovers problem.

2.1 Component Abstraction
Component abstraction technique groups related low-level constants planning
problem abstract entities called abstract components or, shorter, components.
idea similar humans group features connected static relationships
one abstract unit. example, robot carries hammer could considered
single component, mobility well maintenance skills. component
become permanent object representation world, provided action
invalidate static relation robot hammer.
Component abstraction two-step procedure:
1. Build problems static graph, models permanent relationships constant symbols problem.
2. Build abstract components clustering procedure. Formally, abstract component connected subgraph static graph.
2.1.1 Building Static Graph Problem
static graph models static relationships constant symbols problem. Nodes
constant symbols, edges correspond static facts problem definition. Following
standard terminology, fact instantiation domain predicate, i.e., predicate
whose parameters instantiated constant symbols. fact f static
problem p f part initial state p operator delete it.
constant argument least one static fact defines node static
graph. constants fact linked pairwise. edges graph labeled
name corresponding predicate.
use Rovers problem example component abstraction works.
domain, rovers equipped cameras stores rock soil samples
collected analyzed. Rovers gather pictures data rock soil
samples, report base. information Rovers domain, see
work Long Fox (2003). Figure 3 shows static graph sample problem.
nodes include two stores (store0 store1), two rovers (rover0 rover1),
585

fiBotea, Enzenberger, Muller, & Schaeffer

two photo cameras (cam0 cam1), two objectives (obj0 obj1), two camera modes
(colour high-res), four waypoints (point0,... point3). edges correspond
static predicates (store-of ?s - store ?r - rover), (on-board ?c - camera ?r
- rover), (supports ?c - camera ?m - mode), (calibration-target ?c - camera
?o - objective), (visible-from ?o - objective ?w - waypoint).
two marked clusters left examples abstract components generated
method. component rover equipped camera store.
detailed formal explanation provided following paragraphs.
identify static facts necessary build static graph, set domain operators
used partition predicate set P two disjoint sets, P = PF PS , corresponding
fluent static predicates. operator represented structure
= (V (o), P (o), A(o), D(o)),
V (o) variable set, P (o) precondition set, A(o) set add effects,
D(o) set delete effects. predicate p fluent p part operators
effects (either positive negative):
p PF : p A(o) D(o).
Otherwise, p static, denoted p PS .
domain hierarchical types, instances predicate static
fluent. Consider Depots domain, combination Logistics Blocksworld,
used third international planning competition (Long & Fox, 2003). domain
type hierarchy. Type locatable four atomic sub-types: pallet, hoist,
truck, crate. Type place two atomic sub-types: depot distributor.
Predicate (at ?l - locatable ?p - place), indicates object ?l located
place ?p, corresponds eight specialized predicates atomic type level. Predicate (at
?p - pallet ?d - depot) static, since operator adds, deletes, moves
pallet. However, predicate (at ?c - crate ?d - depot) fluent. instance, lift
operator deletes fact type.
address issue hierarchical types, use domain formulation types
expressed lowest level hierarchy. expand predicate set
low-level predicates whose arguments low-level types. Similarly, low-level operators
variable types lowest hierarchy level. Component abstraction macro
generation done lowest level. building macros, restore type
hierarchy domain. possible, replace set two macro operators
low-level types one equivalent macro operator hierarchical types.
way, macros respect definition style (with respect hierarchical types)
rest domain operators. planners pre-instantiate operators,
FF, existence hierarchical types relevant. searching solution,
operators instantiated ground actions whose arguments low-level types.
Facts corresponding static predicates called static facts. current implementation ignore static predicates unary 1 contain two variables
type. latter kind facts often used model topological relationships,
lead large components.
1. fact, many current domains, unary static facts replaced types associated variables.

586

fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators

Step
1
2

3

4

5

Current
Predicate

Used.
Pred.


component0
Consts
Facts
cam0
cam0

component1
Consts
Facts
cam1
cam1

(supports
?c - camera
?m - mode)
(calibr-target
?c - camera
?o - objective)
(on-board
?c - camera
?r - rover)
(store-of
?s - store
?r - rover)



cam0

cam1

YES

cam0
rover0

(on-board
cam0 rover0)

cam1
rover1

(on-board
cam1 rover1)

YES

cam0
rover0
store0

(on-board
cam0 rover0)
(store-of
store0 rover0)

cam1
rover1
store1

(on-board
cam1 rover1)
(store-of
store1 rover1)

Table 1: Building abstract components Rovers example.
2.1.2 Building Abstract Components
Abstract components built connected subgraphs static graph problem.
Clustering starts abstract components size 1, containing one node each,
generated based domain type t, called seed type. node type
static graph, new abstract component created. Abstract components
iteratively extended greedy approach.
Next detail clustering procedure works example, provide
formal description, including pseudo-code. said before, Figure 3 shows two
abstract components built procedure. steps clustering summarized
Table 1, correspond following actions:
1. Choose seed type (camera example), create one abstract component
constant type camera: component0 contains cam0, component1
contains cam1. Next, iteratively extend components created step. One
extension step uses static predicate least one variable type already
encoded components.
2. Choose predicate (supports ?c - camera ?m - mode), variable
type camera. avoid ending one large component containing whole
graph, merging two existing components allowed. Hence check performed
whether static facts based predicate keep existing components separated. static facts (supports cam0 colour), (supports cam0 highres), (supports cam1 colour), (supports cam1 high-res). test fails,
since constants colour high-res would part components. Therefore,
predicate used component extension (see third column Table 1).
3. Similarly, predicate (calibration-target ?c - camera ?o - objective),
would add constant obj1 components, used extension.
587

fiBotea, Enzenberger, Muller, & Schaeffer

4. predicate (on-board ?c - camera ?r - rover) tried. merges components, used component extension. components expanded shown
Table 1, Step 4.
5. predicate (store-of ?s - store ?r - rover), whose type rover previously encoded components, considered. predicate extends
components presented Table 1, Step 5.
Step 5 completed, component extension performed.
static predicates using least one component types tried
extension. moment quality decomposition evaluated. example satisfactory (see discussion below), process terminates. Otherwise,
decomposition process restarts another domain type.
quality decomposition evaluated according size built components,
size defined number low-level types component. experiments,
limited size values 2 4. lower limit trivial, since abstract component
combine least two low-level types. upper limit set heuristically, prevent
abstraction building one large component. relatively small values
also consistent goal limiting size number macro operators. discuss
issue detail Section 2.2.
Figure 4 shows pseudo-code component abstraction. Types(g) contains types
constant symbols used nodes g. Given type t, Preds(t) set static
predicates parameter type t. Given static predicate p, Types(p) includes
types parameters. Facts(p) facts instantiated p.
iteration main loop tries build components starting seed type
Types(g). sets Open, Closed, ried, AC initialized . graph node
type becomes seed abstract component (method createComponent). components greedily extended adding new facts constants, constant
part two distinct components. method predConnectsComponents(p, AC) verifies
fact f Facts(p) merges two distinct abstract components AC.
Method extendComponents(p, AC) extends existing components using static facts
f Facts(p). simplicity, assume fact f binary constants c1 c2
arguments. Given component ac, let N odes(ac) set constants (subgraph nodes)
F acts(ac) set static facts (subgraph edges). general case, four possible
relationships exist abstract components elements f , c1 , c2 :
1. c1 c2 already belong abstract component ac:
(ac AC) : c1 Nodes(ac) c2 Nodes(ac).
case, f added ac new edge.
2. Constant c1 already part abstract component ac (i.e., c1 Nodes(ac)) c2
assigned component yet. ac extended c2 new node f
new edge c1 c2 .
3. neither c1 c2 part previously built component, new component containing f , c1 c2 created added AC.
588

fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators

componentAbstraction(Graph g) {
(each ypes(g) chosen random order) {
resetAllStructures();
Open t;
(each ci N odes(g) type t)
AC createComponent(ci );
(Open 6= ) {
t1 Open;
Closed t1 ;
(each p P reds(t1 ) \ ried)
ried p;
(predConnectsComponents(p, AC)) {
extendComponents(p, AC);
(each t2 ypes(p))
(t2
/ Open Closed)
Open t2 ;
}
}
(evaluateDecomposition() = OK)
return AC;
}
return ;
}
Figure 4: Component abstraction pseudo-code.

4. Constants c1 c2 belong two distinct abstract components:
(ac1 , ac2 ) : c1 Nodes(ac1 ) c2 Nodes(ac2 ) ac1 6= ac2 .
possible general, last alternative never occurs point
method extendComponents called. ensured previous test
method predConnectsComponents.
Consider case static graph two disconnected (i.e., edge
them) subgraphs sg1 sg2 Types(sg1 ) Types(sg2 ) = . case,
algorithm shown Figure 4 finds abstract components subgraph contains
seed type. perform clustering whole graph, algorithm run
subgraph separately.
Following standard typed planning domains, abstract components assigned
abstract types. Figure 5 shows abstract type assigned components example.
shown figure, abstract type abstract component graph obtained
component graph changing node labels. constant symbols used node
labels replaced low-level types (e.g., constant cam0 replaced
type camera).
589

fiBotea, Enzenberger, Muller, & Schaeffer

Figure 5: Abstract type Rovers.

Figure 6: Example macro Depots.

example also shows components identical structure abstract
type. Identical structure strong form graph isomorphism, preserves edge
labels well types constants used node labels. fact f = f (c1 , ..., ck )
F acts(ac) predicate whose variables instantiated constants c N odes(ac).
Two abstract components ac1 ac2 identical structure if:
1. |N odes(ac1 )| = |N odes(ac2 )|;
2. |F acts(ac1 )| = |F acts(ac2 )|;
3. bijective mapping p : N odes(ac1 ) N odes(ac2 )
c N odes(ac1 ) : Type(c) = Type(p(c));
f (c11 , ..., ck1 ) F acts(ac1 ) : f (p(c11 ), ..., p(ck1 )) F acts(ac2 );
f (c12 , ..., ck2 ) F acts(ac2 ) : f (p1 (c12 ), ..., p1 (ck2 )) F acts(ac1 );
2.2 Creating Macro-Operators
macro-operator CA-ED formally equivalent normal operator: set
variables V (m), set preconditions P (m), set add effects A(m), set delete
effects D(m). Figure 6 shows example macro Depots. Figure 7 shows complete
STRIPS definitions macro operators contains.
Macro operators obtained two steps, presented detail remaining part section. First, extended set macros built next macros
590

fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators

(:action UNLOADDROP
:parameters
(?h - hoist ?c - crate ?t - truck ?p - place ?s - surface)
:precondition
(and (at ?h ?p) (in ?c ?t) (available ?h)
(at ?t ?p) (clear ?s) (at ?s ?p))
:effect
(and (not (in ?c ?t)) (not (clear ?s))
(at ?c ?p) (clear ?c) (on ?c ?s))
)
(:action UNLOAD
:parameters
(?x - hoist ?y - crate ?t - truck ?p - place)
:precondition
(and (in ?y ?t) (available ?x) (at ?t ?p) (at ?x ?p))
:effect
(and (not (in ?y ?t)) (not (available ?x)) (lifting ?x ?y))
)
(:action DROP
:parameters
(?x - hoist ?y - crate ?s - surface ?p - place)
:precondition
(and (lifting ?x ?y) (clear ?s) (at ?s ?p) (at ?x ?p))
:effect
(and (available ?x) (not (lifting ?x ?y)) (at ?y ?p)
(not (clear ?s)) (clear ?y) (on ?y ?s))
)
Figure 7: STRIPS definitions macro unloaddrop operators contains.

filtered quick training process. Since empirical evidence indicates extra information added domain definition quite small, methods described next
tend minimize number macros size, measured number variables,
preconditions effects. Static macro generation uses many constraints pruning
space macro operators, discards large macros. Finally, dynamic filtering keeps
top performing macros solving future problems.
2.2.1 Macro Generation
abstract type at, macros generated performing forward search space
macro operators. Macros perform local processing within component type at, according
locality rule detailed below.
root state search represents empty macro (i.e., empty sets operators,
variables, preconditions, effects). search step appends operator current
591

fiBotea, Enzenberger, Muller, & Schaeffer

void addOperatorToMacro(operator o, macro m, variable-mapping vm) {
(each precondition p P (o)) {
(p
/ A(m) P (m))
P (m) = P (m) {p};
}
(each delete effect D(o)) {
(d A(m))
A(m) = A(m) {d};
D(m) = D(m) {d};
}
(each add effect A(o)) {
(a D(m))
D(m) = D(m) {a};
A(m) = A(m) {a};
}
}
Figure 8: Adding operators macro.

macro, fixes variable mapping new operator macro. Adding
new operator macro modifies P (m), A(m), D(m) shown Figure 8.
Even explicitely shown figure, variable mapping vm procedure
used check identity operators predicates macros predicates (e.g.,
p
/ A(m) P (m)). Two predicates considered identical name
set parameters. variable mapping vm tells variables (parameters)
common macro new operator.
search selective: includes set rules pruning search tree
validating built macro operator. Validated macros goal states search space.
search enumerates valid macro operators. following pruning rules used
static filtering:
negated precondition rule prunes operators precondition matches one
current delete effects macro operator. rule avoids building incorrect
macros predicate true false.
repetition rule prunes operators generate cycles. macro containing cycle
either useless, producing empty effect set, written shorter form
eliminating cycle. cycle macro detected effects first
k1 operators first k2 operators, k1 < k2 . particular,
k1 = 0 first k2 operators effect.
chaining rule requires consecutive operators o1 o2 macro,
preconditions o2 must include least one positive effect o1 . rule motivated
idea action sequence macro coherent meaning.
592

fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators

(:action TAKE-IMAGE
:parameters
(?r - rover ?p - waypoint ?o - objective ?i - camera ?m - mode)
:precondition
(and (calibrated ?i ?r) (on-board ?i ?r) (equipped-for-imaging ?r)
(supports ?i ?m) (visible-from ?o ?p) (at ?r ?p))
:effect
(and (have-image ?r ?o ?m) (not (calibrated ?i ?r)))
)
(:action TAKE-IMAGETAKE-IMAGE
:parameters
(?r0 - rover ?p - waypoint ?o - objective ?i0 - camera ?m - mode
?r1 - rover ?i1 - camera)
:precondition
(and (calibrated ?i0 ?r0) (on-board ?i0 ?r0) (equipped-for-imaging ?r0)
(calibrated ?i1 ?r1) (on-board ?i1 ?r1) (equipped-for-imaging ?r1)
(supports ?i0 ?m) (visible-from ?o ?p) (at ?r0 ?p)
(supports ?i1 ?m) (at ?r1 ?p))
:effect
(and (have-image ?r0 ?o ?m) (not (calibrated ?i0 ?r0))
(have-image ?r1 ?o ?m) (not (calibrated ?i1 ?r1)))
)
Figure 9: Operator take-image macro-operator take-imagetake-image
Rovers. macro rejected locality rule.

limit size macro imposing maximal length maximal number
preconditions. Similar constraints could added number variables
effects, found unnecessary. Limiting number preconditions indirectly
limits number variables effects. Large macros generally undesirable,
significantly increase preprocessing costs cost per node
planners search.
locality rule meant prune macros change two abstract components time. local static preconditions acceptable macro
part abstract component. Given abstract type macro m,
let local static preconditions static predicates part ms
preconditions ats edges. Local static preconditions parameters ms
definition define graph structure (different variable bindings operators
compose create different graph structures). implement idea locality
require graph isomorphic subgraph at.
example locality rule, consider Rovers abstract type Figure 5
macro take-imagetake-image shown Figure 9 (this figure also shows
593

fiBotea, Enzenberger, Muller, & Schaeffer

Figure 10: Local static preconditions macro take-imagetake-image respect
abstract type Figure 5. picture shows, correspond graph
4 nodes 2 edges.

definition take-image operator). Intuitively, involves two components, since
two distinct cameras two distinct rovers part macros variables. show
macro rejected locality rule. graph corresponding local static
preconditions shown Figure 10. Obviously, subgraph ats
graph shown Figure 5, rejected.
2.2.2 Macro Ranking Filtering
goal ranking filtering reduce number macros use
efficient ones solving problems. overhead poor macros outweight benefit.
known name utility problem (Minton, 1988). CA-ED, adding
operators domain increases preprocessing costs cost per node
planners search.
used simple efficient practical approach dynamic macro filtering
select small set macro operators. count often macro operator instantiated
action problem solutions found planner. often macro
used past, greater chance macro useful future.
ranking, macro operator assigned weight estimates efficiency.
weights initialized 0. time macro present plan, weight increased
number occurrences macro plan (occurrence points), plus 10 bonus
points. effort spent tuning parameters bonus. common macros
part solutions training problems, bonus value v 0 produce
ranking among common macros. matter value v is, common
macro receive v bonus points, number training problems. Hence
occurrence points decide relative ranking common macros.
use simplest problems domain training. simple problems,
use macro operators, giving macro chance participate solution plan
increase weight. training phase, best macro operators selected
become part enhanced domain definition. experiments, 2 macros, containing
two steps, added new operators initial sets 9 operators Rovers,
5 operators Depots Satellite. domains, small amount extra594

fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators

information observed good tradeoff benefits additional
pre-processing run-time costs. difficult domains, possibly larger initial
sets operators, using macros would probably beneficial.

3. Using Macros Solutions Enhanced Planner
section introduce SOL-EP, macro system used fourth international planning competition. start motivation Section 3.1, describe
method following two sections. SOL-EP follows four-step pattern
before, applied general classes problems. Section 3.2 describes steps
1 3, Section 3.3 shows step 4. Section 3.4 concludes section discussion.
3.1 Motivation
SOL-EP designed goal eliminating main limitations CA-ED. Specifically, wanted extend applicability CA-ED larger classes domains. Since
CA-ED generates macros based component abstraction, applicability limited
domains static predicates definition. SOL-EP generates macros solutions
sample problems, restrictions caused nature domains predicates.
Furthermore, CA-ED limited relatively simple subsets PDDL STRIPS.
Since CA-ED adds macros new operators original domain, complete definitions
macros, including precondition effect formulas, required. formulas easy
obtain STRIPS, shown Figures 7 8. However, adding macros ADL
domain file becomes unfeasible practice two main reasons. First, precondition
effect formulas macro hard infer formulas contained operators.
Second, even previous issue solved macro complete definition added
domain, costs pre-instantiating ground macro-actions large.
illustrate challenging formula inference ADL, consider example
Figure 11, shows operator move ADL Airport domain used IPC-4.
preconditions effects operator quite complex formulas include
quantifiers, implications conditional effects. Assume want compose macro
applies two move actions row given parameter mapping. achieve
complete definition macro move move, precondition effect formulas would
automatically composed analyzing preconditions effects two
contained operators interact. could find straight-forward way generate macros
formulas, decided move towards alternative solution presented later
subsection.
Even issue solved macros added new domain operators, preinstantiating macro ground actions costly. Many top-level planners, including
FF, pre-instantiate domain operators possible ground actions might
applied problem instance hand. cost instantiating one operator exponential total number parameters quantifier variables. Macros tend larger
numbers parameters quantifiers therefore instantiation significantly
increase total preprocessing costs. ADL Airport good illustration important
effect be. shown Section 5.2, preprocessing costly compared
595

fiBotea, Enzenberger, Muller, & Schaeffer

(:action move
:parameters
(?a - airplane ?t - airplanetype ?d1 - direction ?s1 ?s2 - segment ?d2 - direction)
:precondition
(and (has-type ?a ?t) (is-moving ?a)
(not (= ?s1 ?s2))
(facing ?a ?d1) (can-move ?s1 ?s2 ?d1)
(move-dir ?s1 ?s2 ?d2) (at-segment ?a ?s1)
(not
(exists (?a1 - airplane)
(and (not (= ?a1 ?a)) (blocked ?s2 ?a1))))
(forall (?s - segment)
(imply (and (is-blocked ?s ?t ?s2 ?d2)
(not (= ?s ?s1)))
(not (occupied ?s))))
)
:effect
(and (occupied ?s2) (blocked ?s2 ?a)
(not (occupied ?s1))
(when (not (is-blocked ?s1 ?t ?s2 ?d2))
(not (blocked ?s1 ?a)))
(when (not (= ?d1 ?d2))
(not (facing ?a ?d1)))
(not (at-segment ?a ?s1))
(forall (?s - segment)
(when (is-blocked ?s ?t ?s2 ?d2)
(blocked ?s ?a)))
(forall (?s - segment)
(when (and (is-blocked ?s ?t ?s1 ?d1)
(not (= ?s ?s2))
(not (is-blocked ?s ?t ?s2 ?d2)))
(not (blocked ?s ?a))))
(at-segment ?a ?s2)
(when (not (= ?d1 ?d2))
(facing ?a ?d2))
)
)
Figure 11: Operator move ADL Airport.

596

fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators

Figure 12: solution steps problem 1 Satellite benchmark.

main search dominates total cost solving problem domain.
increasing preprocessing costs new operators desirable domains.
solution ADL macros represent SOL-EP macro list atomic actions.
Precondition effect formulas explicitly provided. Rather, determined
run-time, macro dynamically instantiated applying action sequence.
benchmarks used IPC-4 emphasize need address issues described
above. Many competition domains provided STRIPS ADL formulations.
main definition ADL and, planners could take ADL domains
input, STRIPS compilations ADL domain provided. could run
system ADL domains. reason STRIPS compilations ADL domains,
distinct domain file generated problem instance. However, learning
approach requires several training problems domain.
3.2 Generating Macros
running example, use solution plan problem 1 Satellite domain
shown Figure 12. step, figure shows order linear plan, action
name, argument list, preconditions, effects. keep picture simple,
ignore static preconditions actions. Static facts never occur action effects,
therefore affect interactions preconditions effects actions.
SOL-EP, macro-operators extracted solutions training problems.
training problem first solved macros use. found plan represented solution graph, node represents plan step (action), edges
model interactions solution steps. Building solution graph step 1 (analysis)
general four-step pattern. IPC-4 used first implementation solution
graph, considers interactions two consecutive actions plan.
interaction defined two actions least one common argument, least one
597

fiBotea, Enzenberger, Muller, & Schaeffer

action arguments all. Hence implementation described article extracts
two-action sequences possible macros.
macro-actions extracted solution translated macro-operators
replacing instantiated arguments generic variables. operation preserves
relative mapping arguments contained actions. Macro-actions
different sets arguments result macro-operator. Satellite solution
Figure 12, sequence turn-to followed take-image occurs three times.
replacing constant arguments generic variables, occurrences yield
macro-operator.
many pairs actions solution, decision must made
ones going beneficial macro-operators search. Macros statically
filtered according rules Section 2.2.1 excluding limitation number
preconditions, critical algorithm, locality rule. Also, said
before, use different version chaining rule. request operators
macro common variables, unless operator 0 parameters.
Macro-operators stored global list ordered weight, smaller
better. Weights initialized 1.0 updated dynamic ranking process using
gradient-descent method.
macro-operator extracted solution training problem, resolve problem use. Let L solution length macros used, N
number nodes expanded solve problem macros, Nm number
expanded nodes macro used. use difference N Nm update
wm , weight macro m. Since N Nm take arbitrarily large values, map
new value interval (1, 1)
= (

N Nm
)
N

sigmoid function
(x) =

2
1.
1 + ex

Function generates curve shown Figure 13. particular definition
chosen symmetric (0, 0) (i.e., (x) = (x)) bounded within
interval (1, 1). particular, symmetry property ensures that, Nm = N ,
weight update current training step 0. size boundary interval
effect ranking procedure, scales weight updates constant multiplicative
factor. used sigmoid function bounded (1, 1) canonical representation,
limits absolute value 0 1.
update formula also contains factor measures difficulty training
instance. harder problem, larger weight update be. use
difficulty factor solution length L rather N , since former smaller variance
training problem set. formula updating wm
wm = wm L
small constant (0.001 implementation). value affect
ranking macros. used keep macro weights within vicinity 1. See
598

fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators

1

0

-1
-10

-5

0

5

10

Figure 13: Sigmoid function.

second part Section 3.4 comparison CA-EDs frequency-based ranking
SOL-EPs gradient-descent ranking.
CA-ED, two macros kept future use, given large extra-costs associated
type macros. SOL-EP allow arbitrary (but still small) number
macros used search, given smaller extra-costs involved. SOL-EP macros
preprocessing costs, cost per node search much smaller
case CA-ED macros (see Table 4).
decide number selected macros domain, weight threshold wim defined. threshold seen weight imaginary macro im constant
performance training instances. constant performance mean that,
training instance,
N Nim
= c,
N
c > 0 constant parameter. threshold wim updated following
procedure regular macros: initial value wim set 1. training
problem, weight update im
wim = wim im L = wim (c)L
training problems processed, macros weight smaller w im
selected future use. experiments set c 0.01. Given competition tight
deadline, invested limited time studying method tuning parameters.
best determine number selected macros still open problem us,
clearly needs thourough study evaluation.
3.3 Using Macros Run-Time
purpose learned macros speed search new problem instances. classical
search algorithm expands node considering low-level actions applied
current state. add successor states reached applying whole sequence
actions macro. order macro successors regular successors
599

fiBotea, Enzenberger, Muller, & Schaeffer

state. Macros affects neither completeness correctness original algorithm.
completeness original search algorithm preserved since SOL-EP removes
regular successors state. Correctness guaranteed following way applying
macro state. Given state s0 sequence actions = a1 a2 ...ak (k = 2
competition system), say applicable s0 ai applied si1 ,
= 1, ..., k, si = (si1 , ai ) (s, a) state obtained applying s.
given state expanded runtime, many instantiations macro could applicable would actually shortcuts towards goal state. instantiations
considered, branching factor significantly increase induced overhead
larger potential savings achieved useful instantiations. Therefore,
challenge select state expansion small number good macro instantiations.
determine good instantiation macro is, use heuristic method called
helpful macro pruning. Helpful macro pruning based relaxed graphplan computation FF (Hoffmann & Nebel, 2001) performs evaluated state s. Given
state s, FF solves relaxed problem, initial state currently evaluated state,
goal conditions real problem, actions relaxed ignoring delete effects. computation produces relaxed plan RP (s). FF,
relaxed plan used heuristically evaluate problem states prune low-level actions
search space (helpful action pruning).
addition, use relaxed plan prune set macro-instantiations
used node expansion. Since actions relaxed plan often useful real
world, request selected macro relaxed plan match i.e., action
macro part relaxed plan.
3.4 Discussion
first part section summarizes properties CA-ED macros SOL-EP macros.
comments macro-ranking provided, including brief comparison frequencybased ranking gradient-descent ranking.
3.4.1 CA-ED Macros vs SOL-EP Macros
treated single moves, macro-actions potential influence planning
process two important ways. First, macros change search space (the embedding
effect), adding node successor list states would normally achieved several
steps. Intermediate states macro sequence evaluated, reducing
search costs considerably. effect, maximal depth search could reduced
price increasing branching factor.
Second, macros improve heuristic evaluation states (the evaluation effect).
shown before, FF computes heuristic solving relaxed planning problem (i.e.,
delete effects actions ignored) graphplan framework. illustrate benefits
macros relaxed graphplan, consider example Figures 6 7. Operator unload
one add effect (lifting) one delete effect (available) update status
hoist available (free) lifting (busy). Similarly, operator drop updates hoist
status two effects. However, macro unloaddrop used, status
hoist change: available (free) before, available after. effects
600

fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators

necessary express changes hoist status. Hence two delete effects (one
operator) safely eliminated real problem relaxation performed.
relaxed problem similar real problem information loss less drastic.
See Section 5.4 empirical evaluation macros added domain affect
heuristic state evaluation relaxed graphplan.
macros added original domain formulation, evaluation
effect embedding effect present, need extend original planning
engine. disadvantages alternative include limitation STRIPS domains
and, often, significant increase preprocessing costs, memory requirements, cost
per node search (as shown Section 5). SOL-EP macros used,
two effects needs special extension planning engine. current implementation
enhanced planner handles embedding effects affect computation
heuristic state evaluation. Improving heuristic state evaluation macros
important topic future work.
3.4.2 Comments Ranking
frequency-based ranking method used CA-ED simple, fast shown
produce useful macros. Part success due combination static pruning
rules. particular, limiting macro length two actions simplifies problem
macro ranking filtering.
However, general case, savings macro achieve depend
often occurs part solution, also several factors,
interact. Examples factors include number search nodes application
macro would save, ratio useful instantiations macro (providing shortcuts
towards goal state) versus instantiations guide search wrong direction. See
work McCluskey Porteous (1997) details factors determine
performance macro-operators AI planning.
reason extended approach frequency-based ranking gradientdescent ranking integrating factors ranking method expected
produce accurate results. Compared frequency-based ranking, gradient-descent
ranking measures search performance macro directly. illustrate this,
consider solution plan Figure 12. Table 2 shows 5 distinct macro-operators extracted solution plan. macro, gradient-descent weight
frequency-based weight shown. latter case, bonus points ignored, since
affect ranking (all macros receive amount bonus points
part solution plan). method produces different ranking. example, macro take-image turn-to ranked fourth gradient-descent method
second frequency-based method. reason macro turn-to
calibrate (or switch-on turn-to) saves search nodes take-image turn-to,
even though appears less frequently solution.
compared simple fast frequency-based method, gradient-descent ranking expensive. training problem solved several times;
macros use macro. shown Table 3 Section 5, training
time become issue domains PSR Pipesworld Non-Temporal Tankage.
601

fiBotea, Enzenberger, Muller, & Schaeffer

Macro
turn-to take-image
turn-to calibrate
switch-on turn-to
take-image turn-to
calibrate turn-to

Weight
0.999103
0.999103
0.999103
0.999401
0.999700

Occurrences
3
1
1
2
1

Table 2: Macros generated Satellite example.

ranking techniques ignore elements interactions several macros
used simultaneously, effects macros quality plans. See Section 5
evaluation latter.
Macro ranking difficult problem. training data often limited. addition,
factors frequency, number search nodes macro would save, effects
solution quality, etc. combined total ordering macro set.
clear best solution problem. example, select macro speeds
planning increases solution length?

4. Implementation Enhancements Macro-FF
section describes implementation enhancements added FF goal
improving CPU memory requirements. FF version 2.3 highly optimized respect
relaxed graphplan generation, assumed performance bottleneck
original system designers. found several domains planning competition
assumption hold planner spends significant portion time
parts program. applied two implementation enhancements FF reduce
CPU time requirements.
Another problem memory requirements data structures built
pre-processing stage grew exponentially problem size therefore
scale. replaced one data structures able solve problems
several domains within memory limit used planning competition.
enhancements described section affect neither number expanded nodes
quality plans found FF.
4.1 Open Queue
FF tries find solution using enhanced hill climbing method and, solution
found, switches best-first search algorithm. Profiling runs showed Pipesworld
domains planning competition 90% CPU time spent inserting nodes
open queue. open queue implemented single linked list. changed
implementation use linked list buckets, one bucket heuristic value.
buckets implemented linked lists need constant time insertion, since
longer sorted.
602

fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators

4.2 State Hashing
original FF already used state hashing help identify previously visited states,
full comparison states case collision. fact planning problem assigned
unique 32-bit random number, hash code problem state sum
random numbers associated facts characterize given state. Profiling runs
showed domains 35% CPU time spent comparison
states. particular domains large states small graphplan structures
PSR Philosophers. replaced original hash key 64-bit Zobrist hash
key implementation, standard technique game-tree search (Marsland, 1986). fact
assigned 64-bit random number, hash key state obtained applying
XOR operator random numbers corresponding facts true state.
checking two states identical, hash codes compared.
hash codes different, states guaranteed different too. two
compared states hash code, assume states identical.
choice gives completeness search algorithm: two different states hash
code exist. However, unlikely occur fast state comparison based
64-bit Zobrist hashing common standard high-performance game-playing programs.
large size hash key better randomization makes occurrence hash
collisions much less probable random hardware errors.
4.3 Memory Requirements
optimizations FF require creation large lookup tables built
preprocessing stage. One lookup table storing facts initial state.
table sparsely populated required memory equal number constants
power arity predicate summed predicates domain.
caused planner run memory large domains given 1 GB memory
limit used planning competition. replaced lookup table balanced binary
tree minimal memory requirement lookup time proportional logarithm
number facts initial state.

5. Experimental Results
section summarizes experiments analysis results. evaluate ideas
several experiments, described next subsections. Section 5.1 evaluates impact
implementation enhancements planners performance. Section 5.2 focuses
effect macro-operators system used competition. two subsections,
benchmarks competed part IPC-4 used experimental evaluation: Promela Dining Philosophers ADL (containing total 48 problems), Promela
Optical Telegraph ADL (48 problems), Satellite STRIPS (36 problems), PSR Middle
Compiled ADL (50 problems), Pipesworld Notankage Nontemporal STRIPS (50 problems), Pipesworld Tankage Nontemporal STRIPS (50 problems), Airport ADL
(50 problems). Macro-FF took first place Promela Optical Telegraph, PSR,
Satellite.
603

fiBotea, Enzenberger, Muller, & Schaeffer

Section 5.3 compares two abstraction techniques discussed article using
STRIPS domains static facts. provide details later section. Section 5.4
contains empirical analysis CA-ED macros affect heuristic state evaluation
depth goal states. experiments reported article run AMD Athlon 2
GHz machine, limits 30 minutes 1 GB memory problem.
5.1 Enhanced FF
new open queue implementation shows significant speed-up Pipesworld domains. Figure 14 shows difference CPU time two different Pipesworld domains
(note logarithmic time scale). simplest problems left charts solved
quickly data bar drawn. speedup depends problem instance
maximum gains reaching factor 10. result two problems solved
Pipesworld Tankage Non-Temporal domain one problem Pipesworld
No-Tankage Non-Temporal domain.
new 64-bit state hashing especially effective PSR Promela Dining
Philosophers domains. Figure 15 shows speed-up factor 2.5. resulted
3 problems solved PSR, contributing success Macro-FF domain.
reduced memory requirement important Promela Optical Telegraph. Figure 16
shows memory requirement original FF initial facts lookup table.
result replacement lookup table, 3 problems solved domain.
Pipesworld Tankage Non-Temporal - CPU Time (seconds)
1e+04
FF open queue
New open queue
1e+03

Pipesworld No-Tankage Non-Temporal - CPU Time (seconds)
1e+04
FF open queue
New open queue
1e+03

1e+02

1e+02

1e+01

1e+01

1e+00

1e+00

1e-01

1e-01

1e-02

5

10

15

20

25

30

1e-02

35

Problem

5

10

15

20

25

30

35

Problem

Figure 14: Comparison old new open queue implementation Pipesworld Tankage Non-Temporal (left) Pipesworld No-Tankage Non-Temporal (right). Results shown sets 50 problems domain.

5.2 Evaluating Macros Competition System
subsection evaluate SOL-EP macros improve performance competition system. compare planner implementation enhancements
planner implementation enhancements SOL-EP macros.
604

fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators

PSR - CPU Time (seconds)
1e+04
1e+03

Philosophers - CPU Time (seconds)
1e+04

FF hashing
New hashing

1e+02

1e+02

1e+01

1e+01

1e+00

1e+00

1e-01

1e-01

1e-02

5

10

15

FF hashing
New hashing

1e+03

20

25

30

35

40

1e-02

45

2

4

6

Problem

8

10

12

Problem

Figure 15: Comparison two implementations state hashing PSR (left)
Promela Dining Philosophers (right). Results shown 50 problems
PSR 48 problems Promela Dining Philosophers.

Optical
1e+11

Old
New

1e+10

Bytes

1e+09
1e+08
1e+07
1e+06
100000

0

5

10

15

20

25

30

35

40

45

50

Problem

Figure 16: Size data structures initial facts old implementation (lookup table) new implementation (balanced tree) Promela Optical Telegraph.

seven test domains, show number expanded nodes
total CPU time, again, logarithmic scale. CPU time chart shows distinction
problem solved quickly (within time close 0) problem could
solved. determine case is, check corresponding node chart,
absence data point always means solution.
Figure 17 summarizes results Satellite, Promela Optical Telegraph, Promela
Dining Philosophers. Satellite Promela Optical Telegraph, macros greatly improve
performance whole problem sets, allowing Macro-FF win domain formu605

fiBotea, Enzenberger, Muller, & Schaeffer

lations competition. Promela Optical Telegraph macros led solving 12 additional
problems. savings Promela Dining Philosophers limited, resulting one
problem solved.
Figure 18 shows results ADL version Airport. savings terms
expanded nodes significant, little effect total running time.
domain, preprocessing costs dominate total running time.
complexity preprocessing Airport also limits number solved problems
21. planner solve problems STRIPS version Airport used,
macros could generated domain version. STRIPS Airport contains one
domain definition problem instance, whereas learning method requires several
training problems domain definition.
Figure 19 contains results Pipesworld Non-Temporal No-Tankage, Pipesworld
Non-Temporal Tankage, PSR. Pipesworld Non-Temporal No-Tankage, macros often
lead significant speed-up. result, system solves four new problems.
hand, system macros fails three previously solved problems. contribution
macros less significant Pipesworld Non-Temporal Tankage. system macros
solves two new problems fails one previously solved instance. seven
benchmarks, PSR domain macros smallest impact. systems
solve 29 problems using similar amounts resources. competition official run,
Macro-FF solved 32 problems domain formulation.
Table 3 shows number training problems, total training time, selected
macros domain. training phase uses 10 problems Airport, Satellite,
Pipesworld Non-Temporal No-Tankage, PSR. reduced training set 5 problems
Promela Optical Telegraph, 6 problems Promela Dining Philosophers, 5 problems
Pipesworld Non-Temporal Tankage. Promela Optical Telegraph, planner
macros solves 13 problems, using training would leave little room
evaluating learned macros. situation similar Promela Dining Philosophers;
planner macros solves 12 problems. Pipesworld Non-Temporal Tankage,
smaller number training problems caused long training time
structure competition problem set. first 10 problems use part
domain operators, include training set. remaining
problems, planner macros solves 11 instances. large training times
Pipesworld Non-Temporal Tankage PSR caused increased difficulty
training problems.
5.3 Evaluating Abstraction Techniques
evaluate performance two abstraction methods, compare four setups
Macro-FF. four setups, planner includes implementation enhancements
described Section 4. Setup 1 planner macros. Setup 2 includes CA-ED,
method described Section 2. Setup 3 uses SOL-EP, method described Section
3. Setup 4 combination 2 3. Since methods benefits limitations,
interesting analyze perform applied together. setup 4, first
run CA-ED, obtaining enhanced domain. Next treat regular domain,
606

fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators

Domain
Airport

TP
10

TT
365

Promela
Optical
Telegraph

5

70

Promela
Dining
Philosophers
Satellite

6

10

10

8

Pipesworld
Non-Temporal
No-Tankage
Pipesworld
Non-Temporal
Tankage

10

250

5

4,206

PSR

10

1,592

Macros
MOVE MOVE
PUSHBACK MOVE
PUSHBACK PUSHBACK
MOVE TAKEOFF
QUEUE-WRITE ADVANCE-EMPTY-QUEUE-TAIL
ACTIVATE-TRANS QUEUE-WRITE
ACTIVATE-TRANS ACTIVATE-TRANS
PERFORM-TRANS ACTIVATE-TRANS
ACTIVATE-TRANS QUEUE-READ
ACTIVATE-TRANS ACTIVATE-TRANS
QUEUE-READ ADVANCE-QUEUE-HEAD
TURN-TO SWITCH-ON
SWITCH-ON TURN-TO
SWITCH-ON CALIBRATE
TURN-TO TAKE-IMAGE
TURN-TO CALIBRATE
TAKE-IMAGE TURN-TO
POP-START POP-END
PUSH-START PUSH-END
PUSH-START POP-START
PUSH-START PUSH-END
PUSH-START POP-END
PUSH-END POP-START
POP-END PUSH-START
PUSH-END PUSH-START
PUSH-START POP-START
POP-START PUSH-START
AXIOM AXIOM
CLOSE AXIOM

Table 3: Summary training domain. TP number training problems
TT total training time seconds. last column shows macros
selected domain. simplicity, show variable mapping
macro.

607

fiBotea, Enzenberger, Muller, & Schaeffer

Satellite - Nodes
1e+08
1e+07

Satellite - CPU Time (seconds)
1e+04

FF enhanced
macros

1e+03

1e+06

1e+02

1e+05
1e+04

1e+01

1e+03

1e+00

1e+02

1e-01

1e+01
1e+00

FF enhanced
macros

5

10

15

20

25

30

1e-02

35

5

10

15

Problem
Optical - Nodes
1e+08
1e+07

FF enhanced
macros

1e+03

1e+04

35

FF enhanced
macros

1e+01

1e+03

1e+00

1e+02

1e-01

1e+01
1e+00

5

10

15
Problem

20

1e-02

25

5

Philosophers - Nodes

10

15
Problem

20

25

Philosophers - CPU Time (seconds)
1e+04

FF enhanced
macros

1e+03

1e+06

FF enhanced
macros

1e+02

1e+05
1e+04

1e+01

1e+03

1e+00

1e+02

1e-01

1e+01
1e+00

30

1e+02

1e+05

1e+07

25

Optical - CPU Time (seconds)
1e+04

1e+06

1e+08

20
Problem

2

4

6

8
Problem

10

12

1e-02

14

2

4

6

8
Problem

10

12

14

Figure 17: Comparison enhanced version FF without macros Satellite
(36 problems), Promela Optical Telegraph (48 problems) Promela Dining
Philosophers (48 problems).

apply SOL-EP generate list SOL-EP macros. Finally, enhanced planner uses
input enhanced domain, list SOL-EP macros, regular problem instances.
Since component abstraction currently applied STRIPS domains
static facts formulation, used testbeds domains satisfy constraints.
608

fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators

Airport - Nodes
1e+08
1e+07

Airport - CPU Time (seconds)
1e+04

FF enhanced
macros

1e+03

1e+06

1e+02

1e+05
1e+04

1e+01

1e+03

1e+00

1e+02

1e-01

1e+01
1e+00

FF enhanced
macros

5

10

15

1e-02

20

Problem

5

10

15

20

Problem

Figure 18: Comparison enhanced version FF without macros Airport
(50 problems total).

ran experiment Rovers (20 problems), Depots (22 problems), Satellite (36
problems). domains used third international planning competition IPC-3,
Satellite re-used IPC-4 extended problem set. experiments,
Rovers Depots problems sets IPC-3, Satellite problem set
IPC-4.
Figures 20 23 Table 4 summarize results. performance consistently
improves macros used. Interestingly, combining CA-ED SOL-EP often leads
better performance abstraction method taken separately. Rovers, three
abstraction setups produce quite similar results, slight plus combined setup.
Depots, CA-ED effective SOL-EP terms expanded nodes. differences
CPU time become smaller, since adding new operators original domain significantly
increases cost per node Depots (see discussion below). Again, overall winner
domain combined setup. Satellite, adding macros domain reduces
number expanded nodes, significant impact cost per node (see Table 4
later section) memory requirements. Setups 2 4, add macros
original domain, fail solve three problems (32, 33, 36) large memory
requirements FFs preprocessing phase.
Table 4 evaluates macros affect cost per node search. cost per
node defined total search time divided number evaluated states. value
table cost per node corresponding setup (i.e., CA-ED SOL-EP) divided
cost per node setup macros. two methods show
minimum, maximum, average value. macros added original
domain (i.e., domain enhanced), increase cost per node significant.
average rate 7.70 Satellite, 6.06 Depots. interesting notice cost
less 1 Rovers. effect solving problem less nodes expanded.
Operations managing open list closed list costs increase
size lists rate higher linear. right part table
shows much better values cost rate macros used enhanced planner.
609

fiBotea, Enzenberger, Muller, & Schaeffer

Pipesworld No-Tankage Non-Temporal - Nodes
1e+08
1e+07

Pipesworld No-Tankage Non-Temporal - CPU Time (seconds)
1e+04
FF enhanced
macros
1e+03

FF enhanced
macros

1e+06

1e+02

1e+05
1e+04

1e+01

1e+03

1e+00

1e+02

1e-01

1e+01
1e+00

10

20

30

40

1e-02

50

10

20

Problem
Pipesworld Tankage Non-Temporal - Nodes
1e+08
1e+07

FF enhanced
macros

1e+03

1e+04

FF enhanced
macros

1e+01

1e+03

1e+00

1e+02

1e-01

1e+01
5

10

15

20
25
Problem

30

35

1e-02

40

5

10

PSR - Nodes
1e+07

15

20
25
Problem

30

35

40

40

45

PSR - CPU Time (seconds)
1e+04

FF enhanced
macros

1e+03

1e+06

FF enhanced
macros

1e+02

1e+05
1e+04

1e+01

1e+03

1e+00

1e+02

1e-01

1e+01
1e+00

50

1e+02

1e+05

1e+08

40

Pipesworld Tankage Non-Temporal - CPU Time (seconds)
1e+04

1e+06

1e+00

30
Problem

5

10

15

20 25 30
Problem

35

40

1e-02

45

5

10

15

20 25 30
Problem

35

Figure 19: Comparison enhanced version FF without macros
Pipesworld No-Tankage Non-Temporal, Pipesworld Tankage Non-Temporal
PSR (50 problems domain).

important analyze macros added new operators generate increase
cost per node Satellite Depots. overhead mostly present relaxed
graphplan algorithm computes heuristic value state. complexity
algorithm depends upon total number actions instantiated
610

fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators

preprocessing given problem. Adding new operators domain increases number pre-instantiated actions. Since macros tend variables regular
operator, corresponding number instantiations significantly larger. Let
action instantiation rate number actions instantiated problem macros
used divided number actions instantiated original domain formulation.
statistics show average action instantiation rate 6.03 Satellite, 3.20
Depots, 1.04 Rovers.
results show significant impact macro-operators solution quality.
macros used, length plan slightly varies directions, average close
value original FF system.
Domain
Depots
Rovers
Satellite

Min
3.27
0.70
0.98

CA-ED
Max
8.56
0.90
14.38

Avg
6.06
0.83
7.70

SOL-EP
Min Max Avg
0.93 1.14 1.04
0.85 1.14 1.00
0.92 1.48 1.11

Table 4: Relative cost per node.

5.4 Evaluating Effects CA-ED Macros Heuristic State Evaluation
shown Section 3.4, macros added domain new operators affect
structure search space (the embedding effect) heuristic evaluation states
relaxed graphplan (the evaluation effect). section presents empirical analysis
these.
Figure 24 shows results Depots, Rovers Satellite. domain, chart
left shows data original domain formulation, chart right
shows data macro-enhanced domain formulation. domain formulation,
data points extracted solution plans follows. state along solution
plan generates one data point. coordinates data point states heuristic
evaluation vertical axis, number steps left goal state reached
horizontal axis. number steps goal state may larger distance
(i.e., length shortest path) goal state. reason states along solution plans
used generate data states, heuristic evaluation,
number steps goal state available solving problem.
first conclusion Figure 24 macros added domain improve
accuracy heuristic state evaluation relaxed graphplan. closer data point
diagonal, accurate heuristic evaluation corresponding state.
Secondly, data clouds shorter macro-enhanced domains. direct result
embedding effect, reduces depth goal states.
611

fiBotea, Enzenberger, Muller, & Schaeffer

Rovers - Nodes
10000

(1) Macros
(2) CA-ED
(3) SOL-EP
(4) 2 + 3

1000
100
10
1

0

2

4

6

8

10 12 14 16 18 20 22
Problem

Rovers - CPU Time (seconds)
10

(1) Macros
(2) CA-ED
(3) SOL-EP
(4) 2 + 3

1

0.1

0.01

0

2

4

6

8

10 12 14
Problem

16

18

20

22

Figure 20: Evaluating abstraction techniques Rovers. show number expanded
nodes (top), CPU time (bottom).
612

fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators

Depots - Nodes
1e+06

(1) Macros
(2) CA-ED
(3) SOL-EP
(4) 2 + 3

100000
10000
1000
100
10
1

5

10
15
Problem

20

Depots - CPU Time (seconds)
1000
100
10
1
0.1
0.01

5

10

15

20

Problem
Figure 21: Evaluating abstraction techniques Depots. show number expanded
nodes (top), CPU time (bottom).
613

fi10
5
1

10

100

1000

10000

(1) Macros
(2) CA-ED
(3) SOL-EP
(4) 2 + 3

15

20
Problem

Satellite - Nodes

25

30

35

Botea, Enzenberger, Muller, & Schaeffer

Figure 22: Evaluating abstraction techniques Satellite. show number expanded
nodes.
614

fi30
25
20
Problem
15
10
5
0.01

0.1

1

10

100

1000

(1) Macros
(2) CA-ED
(3) SOL-EP
(4) 2 + 3
10000

Satellite - CPU Time (seconds)

35

Macro-FF: Improving AI Planning Automatically Learned Macro-Operators

Figure 23: Evaluating abstraction techniques Satellite (continued). show CPU
time.
615

fiBotea, Enzenberger, Muller, & Schaeffer

Depots + CA-ED Macros
120

100

100
Heuristic evaluation

Heuristic evaluation

Original Depots
120

80
60
40
20
0

0

80
60
40
20
0

20 40 60 80 100 120
Number steps goal

0

Rovers + CA-ED Macros

160

160

140

140

120

120

Heuristic evaluation

Heuristic evaluation

Original Rovers

100
80
60
40
20
0

100
80
60
40
20

0

0

20 40 60 80 100 120 140 160
Number steps goal

0

Original Satellite

Satellite + CA-ED Macros
350

300

300
Heuristic evaluation

Heuristic evaluation

20 40 60 80 100 120 140 160
Number steps goal

350

250
200
150
100
50
0

20 40 60 80 100 120
Number steps goal

250
200
150
100
50

0

0

50 100 150 200 250 300 350
Number steps goal

0

50 100 150 200 250 300 350
Number steps goal

Figure 24: Effects CA-ED macros heuristic state evaluation depth goal states.
616

fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators

6. Related Work
related work described section falls two categories. first review approaches make use domain structure reduce complexity planning,
next consider previous work macro-operators.
automatic method discovers exploits domain structure explored
Knoblock (1994). work, hierarchy abstractions built starting initial
low-level problem description. new abstract level obtained dropping literals
problem definition previous abstraction level. Planning first produces abstract
solution iteratively refines low-level representation. hierarchy built
way that, refinement abstract solution exists, backtracking across
abstraction levels necessary refinement process. Backtracking performed
abstract plan refinement. situations arbitrarily frequent,
negative effects systems performance.
Bacchus Yang (1994) define theoretical probabilistic framework planning
hierarchical models. Abstract solutions problem different abstraction levels
hierarchically represented nodes tree structure. tree edge indicates
target node refinement start node. abstract solution refined
previous level given probability. Hierarchical search model analytically
evaluated. analytical model used enhace Knoblocks abstraction algorithm.
enhancement refers using estimations refinement probabilities abstract
solutions.
recently, implicit causal structure domain used design domainindependent heuristic state evaluation (Helmert, 2004). methods either statically
infer information structure domain, dynamically discover structure
problem instance. contrast, propose adaptive technique learns
previous experience domain.
Two successful approaches use hand-crafted information domain structure hierarchical task networks temporal logic control rules. Hierarchical task
networks (HTNs) guide restrict planning using hierarchical representation domain. Human experts design hierarchies tasks show initial problem
broken level regular actions. idea introduced Sacerdoti (1975)
Tate (1977), widely used real-life planning applications (Wilkins &
desJardins, 2001). SHOP2 (Nau, Au, Ilghami, Kuter, Murdock, Wu, & Yaman, 2003)
well-known heuristic search planner search guided HTNs.
planning temporal logic control rules, formula associated state
problem space. formula initial state provided domain description.
formula state obtained based successors formula.
formula associated state proven false, states subtree pruned.
best known planners kind TLPlan (Bacchus & Kabanza, 2000) TALPlanner
(Kvarnstrom & Doherty, 2001). efficient, approaches also rely heavily human
knowledge, might expensive impossible obtain.
Early contributions macro-operators AI planning includes work Fikes
Nilsson (1971). Macros extracted problem solved solution became
available. Minton (1985) advances work introducing techniques filter set
617

fiBotea, Enzenberger, Muller, & Schaeffer

learned macro-operators. approach, two types macro-operators preferred:
S-macros, occur high frequency problem solutions, T-macros,
useful low priority original search algorithm. Iba (1989) introduces
so-called peak-to-peak heuristic generate macro-operators run-time. macro
move sequence two peaks heuristic state evaluation. macro
traverses valley search space, using later correct errors heuristic
evaluation. Mooney (1988) considers whole plans macros introduces partial ordering
operators based causal interactions.
Veloso Carbonell (1993) Kambhampati (1993) explore planning reuse
solutions previously solved problems. Solutions annotated additional relevant information stored later use. additional information contains either explanations
successful failed search decisions (Veloso & Carbonell, 1993), causal structure
solution plans (Kambhampati, 1993). Several similarity metrics planning problems
introduced. new problem fed planner, annotated solutions similar
problems used guide current planning process.
McCluskey Porteous (1997) focus constructing planning domains starting
natural language description. approach combines human expertise automatic
tools, addresses correctness efficiency obtained formulation. Using
macro-operators major technique authors propose efficiency improvement.
work, state domain composed local states several variables called
dynamic objects. Macros model transitions local states variable.
planner Marvin (Coles & Smith, 2004) generates macros online (as plateauescaping sequences) offline (from reduced version problem solved).
macros cached one problem instance another.
Macro-moves successfully used single-agent search problems puzzles
path-finding commercial computer games, usually domain-specific implementation.
sliding-tile puzzle among first testbeds idea (Korf, 1985; Iba, 1989).
Two effective concepts used Sokoban solver Rolling Stone, tunnel
goal macros, applications idea (Junghanns & Schaeffer, 2001). recent work
Sokoban includes approach decomposes maze set rooms connected
tunnels (Botea, Muller, & Schaeffer, 2002). Search performed higher level
abstract move sequences rearrange stones inside room stone
transferred one room another. Using macro-moves solving Rubiks Cube
puzzles proposed Hernadvolgyi (2001). method proposed Botea, Muller,
Schaeffer (2004a) automatically decomposes navigation map set clusters, possibly
several abstraction levels. cluster, internal optimal path pre-computed
two entrances cluster. Path-finding performed abstract level,
macro-move crosses cluster one entrance another one step.
Methods exploit search time relaxed graphplan associated problem
state (Hoffmann & Nebel, 2001) include helpful action pruning (Hoffmann & Nebel, 2001)
look-ahead policies (Vidal, 2004). Helpful action pruning considers node expansion
actions occur relaxed plan applied current state. Helpful
macro pruning applies pruning idea macro-actions applicable state,
noticeable difference helpful macro pruning give completeness
search algorithm. lookahead policy executes parts relaxed plan real
618

fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators

world, often provides path towards goal state search states
evaluated. actions relaxed plan iteratively applied long possible
heuristically computed order. lookahead procedure cannot continued
actions relaxed plan, plan-repair method selects new action applied.

7. Conclusion Future Work
Despite great progress AI planning recently achieved, many benchmarks remain
challenging current planners. paper presented techniques automatically
learn macro-operators previous experience domain, use speed
search future problems. evaluated methods standard benchmarks international planning competitions, showing significant improvement domains structure
information inferred. implemented ideas Macro-FF, extension
FF version 2.3. Macro-FF participated classical part fourth international
planning competition, competing seven domains taking first place three them.
Exploring method deeply improving performance classes
problems major directions future work. also plan extend approach
several directions. learning method generalized macro-operators
complex structures HTNs. Little research focusing learning HTNs
conducted, even though problem great importance.
plan explore heuristic evaluation based relaxed graphplan
improved macro-operators. shown article, macro added original
domain formulation regular operator influences results heuristic function.
convenient (no changes necessary planning engine), limited
STRIPS domains. subsets PDDL, relaxed graphplan algorithm
extended special capabilities handle macros enhanced domain definition
provided.
long-term goal component abstraction automatic reformulation planning
domains problems. real-world problem abstracted planning model,
corresponding formulation expressed abstraction level human designer
considers appropriate. However, choosing good abstraction level could hard
expensive problem humans. Hence methods automatically update formulation
problem based structure would helpful.

Acknowledgments
research supported Natural Sciences Engineering Research Council
Canada (NSERC) Albertas Informatics Circle Research Excellence (iCORE).
thank Jorg Hoffmann making source code FF available, kindly answering
many technical questions related FF. also thank organizers IPC-4, reviewers
article, Maria Fox, led reviewing process.

References
Bacchus, F. (2001). AIPS00 Planning Competition. AI Magazine, 22 (3), 4756.
619

fiBotea, Enzenberger, Muller, & Schaeffer

Bacchus, F., & Kabanza, F. (2000). Using Temporal Logics Express Search Control
Knowledge Planning. Artificial Intelligence, 16, 123191.
Bacchus, F., & Yang, Q. (1994). Downward Refinement Efficiency Hierarchical
Problem Solving. Artificial Intelligence, 71 (1), 43100.
Botea, A., Muller, M., & Schaeffer, J. (2002). Using Abstraction Planning Sokoban.
Schaeffer, J., Muller, M., & Bjornsson, Y. (Eds.), 3rd International Conference
Computers Games (CG2002), Vol. 2883 Lecture Notes Artificial Intelligence,
pp. 360375, Edmonton, Canada. Springer.
Botea, A., Muller, M., & Schaeffer, J. (2004a). Near Optimal Hierarchical Path-Finding.
Journal Game Development, 1 (1), 728.
Botea, A., Muller, M., & Schaeffer, J. (2004b). Using Component Abstraction Automatic
Generation Macro-Actions. Fourteenth International Conference Automated
Planning Scheduling ICAPS-04, pp. 181190, Whistler, Canada. AAAI Press.
Coles, A., & Smith, A. (2004). Marvin: Macro Actions Reduced Versions
Instance. Booklet Fourth International Planning Competition, pp. 2426.
Fikes, R. E., & Nilsson, N. (1971). STRIPS: New Approach Application Theorem
Proving Problem Solving. Artificial Intelligence, 5 (2), 189208.
Helmert, M. (2004). Planning Heuristic Based Causal Graph Analysis. Fourteenth
International Conference Automated Planning Scheduling ICAPS-04, pp. 161
170, Whistler, Canada.
Hernadvolgyi, I. (2001). Searching Macro-operators Automatically Generated
Heuristics. Fourteenth Canadian Conference Artificial Intelligence, pp. 194
203.
Hoffmann, J., Edelkamp, S., Englert, R., Liporace, F., Thiebaux, S., & Trug, S. (2004).
Towards Realistic Benchmarks Planning: Domains Used Classical Part
IPC-4. Booklet Fourth International Planning Competition, pp. 714.
Hoffmann, J., & Nebel, B. (2001). FF Planning System: Fast Plan Generation
Heuristic Search. Journal Artificial Intelligence Research, 14, 253302.
Iba, G. A. (1989). Heuristic Approach Discovery Macro-Operators. Machine
Learning, 3 (4), 285317.
Junghanns, A., & Schaeffer, J. (2001). Sokoban: Enhancing Single-Agent Search Using
Domain Knowledge. Artificial Intelligence, 129 (12), 219251.
Kambhampati, S. (1993). Machine Learning Methods Planning, chap. Supporting Flexible Plan Reuse, pp. 397434. Morgan Kaufmann.
Knoblock, C. A. (1994). Automatically Generating Abstractions Planning. Artificial
Intelligence, 68 (2), 243302.
Korf, R. (1985). Macro-Operators: Weak Method Learning. Artificial Intelligence,
26(1), 3577.
Kvarnstrom, J., & Doherty, P. (2001). TALplanner: Temporal Logic Based Forward Chaining Planner. Annals Mathematics Artificial Intelligence, 30, 119169.
620

fiMacro-FF: Improving AI Planning Automatically Learned Macro-Operators

Long, D., & Fox, M. (2003). 3rd International Planning Competition: Results
Analysis. Journal Artificial Intelligence Research, 20, 159. Special Issue
3rd International Planning Competition.
Marsland, T. A. (1986). Review Game-Tree Pruning. International Computer Chess
Association Journal, 9 (1), 319.
McCluskey, T. L., & Porteous, J. M. (1997). Engineering Compiling Planning Domain
Models Promote Validity Efficiency. Artificial Intelligence, 95, 165.
McDermott, D. (2000). 1998 AI Planning Systems Competition. AI Magazine, 21 (2),
3555.
Minton, S. (1985). Selectively Generalizing Plans Problem-Solving. IJCAI-85, pp.
596599.
Minton, S. (1988). Learning Search Control Knowledge: Explanation-Based Approach..
Hingham, MA. Kluwer Academic Publishers.
Mooney, R. (1988). Generalizing Order Operators Macro-Operators. Fifth
International Conference Machine Learning ICML-88, pp. 270283.
Nau, D., Au, T., Ilghami, O., Kuter, U., Murdock, J., Wu, D., & Yaman, F. (2003). SHOP2:
HTN Planning System. Journal Artificial Intelligence Research, 20, 379404.
Sacerdoti, E. (1975). Nonlinear Nature Plans. Proceedings IJCAI-75, pp. 206214.
Tate, A. (1977). Generating Project Networks. Proceedings IJCAI-77, pp. 888893.
Veloso, M., & Carbonell, J. (1993). Machine Learning Methods Planning, chap. Toward
Scaling Machine Learning: Case Study Derivational Analogy, pp. 233272.
Morgan Kaufmann.
Vidal, V. (2004). Lookahead Strategy Heuristic Search Planning. Fourteenth
International Conference Automated Planning Scheduling ICAPS-04, pp. 150
159, Whistler, Canada.
Wilkins, D., & desJardins, M. (2001). Call Knowledge-Based Planning. AI Magazine,
22 (1), 99115.

621

fiJournal Artificial Intelligence Research 24 (2005) 341-356

Submitted 11/04; published 09/05

Efficiency versus Convergence Boolean Kernels
On-Line Learning Algorithms
Roni Khardon

roni@cs.tufts.edu

Department Computer Science, Tufts University
Medford, 02155

Dan Roth

danr@cs.uiuc.edu

Department Computer Science, University Illinois
Urbana, IL 61801 USA

Rocco A. Servedio

rocco@cs.columbia.edu

Department Computer Science, Columbia University
New York, NY 10025

Abstract
paper studies machine learning problems example described using
set Boolean features hypotheses represented linear threshold elements.
One method increasing expressiveness learned hypotheses context
expand feature set include conjunctions basic features. done explicitly
possible using kernel function. Focusing well known Perceptron
Winnow algorithms, paper demonstrates tradeoff computational
efficiency algorithm run expanded feature space
generalization ability corresponding learning algorithm.
first describe several kernel functions capture either limited forms conjunctions conjunctions. show kernels used efficiently run
Perceptron algorithm feature space exponentially many conjunctions; however also show using kernels, Perceptron algorithm provably make
exponential number mistakes even learning simple functions.
consider question whether kernel functions analogously used
run multiplicative-update Winnow algorithm expanded feature space
exponentially many conjunctions. Known upper bounds imply Winnow algorithm
learn Disjunctive Normal Form (DNF) formulae polynomial mistake bound
setting. However, prove computationally hard simulate Winnows
behavior learning DNF feature set. implies kernel functions
correspond running Winnow problem efficiently computable,
general construction run Winnow kernels.

1. Introduction
problem classifying objects one two classes positive negative
examples concept often studied machine learning. task machine learning
extract classifier given pre-classified examples - problem learning
data. example represented set n numerical features, example
c
2005
AI Access Foundation. rights reserved.

fiKhardon, Roth, & Servedio

seen point Euclidean space <n . common representation classifiers
case hyperplane dimension (n 1) splits domain examples
two areas positive negative examples. representation known linear
threshold function, many learning algorithms output hypothesis represented
manner developed, analyzed, implemented, applied practice.
particular interest paper well known Perceptron (Rosenblatt, 1958; Block,
1962; Novikoff, 1963) Winnow (Littlestone, 1988) algorithms intensively
studied literature.
also well known expressiveness linear threshold functions quite limited (Minsky & Papert, 1968). Despite fact, Perceptron Winnow
applied successfully recent years several large scale real world classification problems.
one example, SNoW system (Roth, 1998; Carlson, Cumby, Rosen, & Roth, 1999)
successfully applied variations Perceptron Winnow problems natural language
processing. SNoW system extracts basic Boolean features x1 , . . . , xn labeled pieces
text data order represent examples, thus features numerical values restricted {0, 1}. several ways enhance set basic features x 1 , . . . , xn
Perceptron Winnow. One idea expand set basic features x 1 , . . . , xn using
conjunctions (x1 x3 x4 ) use expanded higher-dimensional examples,
conjunction plays role basic feature, examples Perceptron
Winnow. fact approach SNoW system takes running Perceptron
Winnow space restricted conjunctions basic features. idea closely
related use kernel methods, see e.g. book Cristianini Shawe-Taylor
(2000), feature expansion done implicitly kernel function. approach clearly leads increase expressiveness thus may improve performance.
However, also dramatically increases number features (from n 3 n conjunctions used), thus may adversely affect computation time convergence
rate learning. paper provides theoretical study performance Perceptron
Winnow run expanded feature spaces these.
1.1 Background: On-Line Learning Perceptron Winnow
describing results, recall necessary background on-line learning
model (Littlestone, 1988) Perceptron Winnow algorithms.
Given instance space X possible examples, concept mapping instances
one two (or more) classes. concept class C 2X simply set concepts. on-line
learning concept class C fixed advance adversary pick concept c C.
learning modeled repeated game iteration adversary
picks example x X, learner gives guess value c(x) told
correct value. count one mistake iteration value predicted
correctly. learning algorithm learns concept class C mistake bound
choice c C (arbitrarily long) sequence examples, learner guaranteed
make mistakes.
paper consider case examples given Boolean features,
X = {0, 1}n , two class labels denoted 1 1. Thus x {0, 1}n ,
labeled example hx, 1i positive example, labeled example hx, 1i negative
342

fiEfficiency versus Convergence Boolean Kernels

example. concepts consider built using logical combinations n base
features interested mistake bounds polynomial n.
1.1.1 Perceptron
Throughout execution Perceptron maintains weight vector w < N initially
(0, . . . , 0). Upon receiving example x <N algorithm predicts according
linear threshold function w x 0. prediction 1 label 1 (false positive
prediction) vector w set w x, prediction 1 label 1
(false negative) w set w + x. change made w prediction correct.
Many variants basic algorithm proposed studied particular one
add non zero threshold well learning rate controls size update
w. discussed Section 3.
famous Perceptron Convergence Theorem (Rosenblatt, 1958; Block, 1962; Novikoff,
1963) bounds number mistakes Perceptron algorithm make:
Theorem 1 Let hx1 , y1 i, . . . , hxt , yt sequence labeled examples xi <N , kxi k
R yi {1, 1} i. Let u <N , > 0 yi (u xi ) i.
2
2
mistakes example sequence.
Perceptron makes R kuk
2
1.1.2 Winnow
Winnow algorithm (Littlestone, 1988) similar structure. Winnow maintains
hypothesis vector w <N initially w = (1, . . . , 1). Winnow parameterized
promotion factor > 1 threshold > 0; upon receiving example x {0, 1} N
Winnow predicts according threshold function w x . prediction 1
label 1 xi = 1 value wi set wi /; demotion
step. prediction 1 label 1 xi = 1 value wi
set wi ; promotion step. change made w prediction correct.
purposes following mistake bound, implicit Littlestones work (1988),
interest:
Theorem 2 Let target function k-literal monotone disjunction f (x 1 , . . . , xN ) =
xi1 xik . sequence examples {0, 1}N labeled according f number

prediction mistakes made Winnow(, ) 1
N + k( + 1)(1 + log ).
1.2 Results
interested computational efficiency convergence Perceptron
Winnow algorithms run expanded feature spaces conjunctions. Specifically,
study use kernel functions expand feature space thus enhance
learning abilities Perceptron Winnow; refer enhanced algorithms
kernel Perceptron kernel Winnow.
first result (cf. also papers Sadohara, 1991; Watkins, 1999; Kowalczyk
et al., 2001) uses kernel functions show possible efficiently run kernel
Perceptron algorithm exponential number conjunctive features.
343

fiKhardon, Roth, & Servedio

Result 1: (see Theorem 3) algorithm simulates Perceptron 3 n dimensional feature space conjunctions n basic features. Given sequence
labeled examples {0, 1}n prediction update example take poly(n, t) time
steps. also prove variants result expanded feature space consists
monotone conjunctions conjunctions bounded size.
result closely related one main open problems learning theory:
efficient learnability disjunctions conjunctions, DNF (Disjunctive Normal Form)
expressions.1 Since linear threshold elements represent disjunctions (e.g. x1 x2 x3
true iff x1 + x2 + x3 1), Theorem 1 Result 1 imply kernel Perceptron
used learn DNF. However, framework values N R Theorem 1
exponentially large (note N = 3n R = 2n/2 conjunctions used),
hence mistake bound given Theorem 1 exponential rather polynomial
n. question thus arises whether exponential upper bound implied Theorem
1 essentially tight kernel Perceptron algorithm context DNF learning.
give affirmative answer, thus showing kernel Perceptron cannot efficiently learn
DNF.
Result 2: monotone DNF f x1 , . . . , xn sequence examples labeled
according f causes kernel Perceptron algorithm make 2 (n) mistakes.
result holds generalized versions Perceptron algorithm fixed updated
threshold learning rate used. also give variant result showing
kernel Perceptron fails Probably Approximately Correct (PAC) learning model
(Valiant, 1984) well.
Turning Winnow, attractive feature Theorem 2 suitable , bound
logarithmic total number features N (e.g. = 2 = N ). Therefore,
noted several researchers (Maass & Warmuth, 1998), Winnow analogue Theorem 3
could obtained would imply DNF learned computationally efficient
algorithm poly(n)-mistake bound. However, give strong evidence
Winnow analogue Theorem 3 exist.
Result 3: polynomial time algorithm simulates Winnow exponentially many monotone conjunctive features learning monotone DNF unless every problem
complexity class #P solved polynomial time. result holds wide
range parameter settings Winnow algorithm.
observe that, contrast negative result, Maass Warmuth shown
Winnow algorithm simulated efficiently exponentially many conjunctive
features learning simple geometric concept classes (Maass & Warmuth, 1998).
results thus indicate tradeoff computational efficiency convergence
kernel algorithms rich classes Boolean functions DNF formulas; kernel
1. Angluin (1990) proved DNF expressions cannot learned efficiently using equivalence queries
whose hypotheses DNF expressions. Since model exact learning equivalence
queries equivalent mistake bound model consider paper, result implies
online algorithm uses DNF formulas hypotheses efficiently learn DNF. However,
result preclude efficient learnability DNF using different class hypotheses.
kernel Perceptron algorithm generates hypotheses thresholds conjunctions rather DNF
formulas, thus Angluins negative results apply here.

344

fiEfficiency versus Convergence Boolean Kernels

Perceptron algorithm computationally efficient run exponentially slow convergence, whereas kernel Winnow rapid convergence seems require exponential
runtime.

2. Kernel Perceptron Many Features
well known hypothesis w Perceptron algorithm linear combination
previous examples mistakes made (Cristianini & Shaw-Taylor, 2000).
precisely, let L(v) {1, 1} denote label example v,
P
w = vM L(v)v set examples algorithm made mistake.
P
P
Thus prediction Perceptron x 1 iff wx = ( vM L(v)v)x = vM L(v)(v x)
0.
example x {0, 1}n let (x) denote transformation enhanced feature
space space conjunctions. run Perceptron algorithm
enhanced space must predict 1 iff w (x) 0 w weight vector
P
enhanced space; discussion holds iff vM L(v)((v) (x)) 0.
P
Denoting K(v, x) = (v) (x) holds iff vM L(v)K(v, x) 0.
Thus never need construct enhanced feature space explicitly; order run
Perceptron need able compute kernel function K(v, x) efficiently.
idea behind so-called kernel methods, applied algorithm (such
support vector machines) whose prediction function inner products examples.
detailed discussion given book Cristianini Shawe-Taylor (2000).
Thus next theorem simply obtained presenting kernel function capturing
conjunctions.
Theorem 3 algorithm simulates Perceptron feature spaces
(1) conjunctions, (2) monotone conjunctions, (3) conjunctions size k, (4)
monotone conjunctions size k. Given sequence labeled examples {0, 1} n
prediction update example take poly(n, t) time steps.
Proof: case (1) () includes 3n conjunctions (with positive negative literals)
K(x, y) must compute number conjunctions true x y. Clearly,
literal conjunction must satisfy x thus corresponding bit
x, must value. Thus conjunction true x corresponds
subset bits. Counting conjunctions gives K(x, y) = 2same(x,y)
same(x, y) number original features value x y, i.e.
number bit positions xi = yi . kernel obtained independently
Sadohara (2001).
express monotone monomials (2) take K(x, y) = 2|xy| |x y|
number active features common x y, i.e. number bit positions
xi = yi = 1.
Similarly, case (3) number conjunctions satisfy x K(x, y) =
Pk same(x,y)
. kernel reported also Watkins (1999). case (4)
l=0
l


P
K(x, y) = kl=0 |xy|
.
2
l
345

fiKhardon, Roth, & Servedio

3. Kernel Perceptron Many Mistakes
section describe simple monotone DNF target function sequence
labeled examples causes monotone monomials kernel Perceptron algorithm
make exponentially many mistakes.
x, {0, 1}n write |x| denote number 1s x and, described above,
|xy| denote number bit positions xi = yi = 1. need following
well-known tail bound sums independent random variables found in,
e.g., Section 9.3 book Kearns Vazirani (1994):
Fact 4 Let X1 , . . . , Xm sequence independent 0/1-valued random variables,
P
E[Xi ] = p. Let X denote
i=1 Xi , E[X] = pm. 0 1,

Pr[X > (1 + )pm] emp

2 /3



Pr[X < (1 )pm] emp

2 /2

.

also use following combinatorial property:
Lemma 5 set n-bit strings = {x1 , . . . , xt } {0, 1}n = en/9600
|xi | = n/20 1 |xi xj | n/80 1 < j t.
Proof: use probabilistic method. = 1, . . . , let xi {0, 1}n chosen
independently setting bit 1 probability 1/10. clear
E[|xi |] = n/10. Applying Fact 4, Pr[|xi | < n/20] en/80 , thus
probability xi satisfies |xi | < n/20 ten/80 . Similarly, 6= j
E[|xi xj |] = n/100. Applying Fact 4 Pr[|xi xj | > n/80] en/4800 ,
thus probability xi , xj
6= j satisfies |xi xj | > n/80
n/4800
n/4800
n/9600
+ ten/80 less 1. Thus
. = e
value 2 e
2 e
choice x1 , . . . , xt |xi | n/20 |xi xj | n/80. xi
|xi | > n/20 set |xi | n/20 1s 0s, lemma proved.
2
using previous lemma construct difficult data set kernel Perceptron:
Theorem 6 monotone DNF f x1 , . . . , xn sequence examples labeled
according f causes kernel Perceptron algorithm make 2(n) mistakes.
Proof: target DNF use simple: single conjunction
x1 x2 . . . xn . original Perceptron algorithm n features x1 , . . . , xn easily
seen make poly(n) mistakes target function, show
monotone kernel Perceptron algorithm runs feature space 2 n monotone
monomials make 2 + en/9600 mistakes.
Recall beginning Perceptron algorithms execution 2 n coordinates
w 0. first example negative example 0n . monomial true
example empty monomial true every example. Since w (x) = 0 Perceptron incorrectly predicts 1 example. resulting update causes coefficient
w corresponding empty monomial become 1 2n 1 coordinates
w remain 0. next example positive example 1n . example
w (x) = 1 Perceptron incorrectly predicts 1. Since 2n monotone conjunctions
346

fiEfficiency versus Convergence Boolean Kernels

satisfied example resulting update causes w become 0 2n 1
coordinates w become 1. next en/9600 examples vectors x1 , . . . , xt
described Lemma 5. Since example |xi | = n/20 example negative;
however show Perceptron algorithm predict 1 examples.
Fix value 1 en/9600 consider hypothesis vector w example

x received. Since |xi | = n/20 value w (xi ) sum 2n/20 different
coordinates wT correspond monomials satisfied xi . precisely
P
P
w (xi ) = Ai wT + Bi wT Ai contains monomials satisfied
xi xj j 6= Bi contains monomials satisfied xi
xj j 6= i. lower bound two sums separately.
Let monomial Ai . Lemma 5 Ai contains n/80 variables

Pn/80
monomials Ai . Using well known bound
thus r=0 n/20
r


P` `
(H()+o(1))`
0 < 1/2 H(p) = p log p (1 p) log(1 p)
j=0 j = 2
binary entropy function, found e.g. Theorem 1.4.5 book
Van Lint (1992), 20.8113(n/20)+o(n) < 20.041n terms Ai . Moreover
value wT must least en/9600 since wT decreases 1
P
example, hence Ai wT en/9600 20.041n > 20.042n . hand, Bi
false examples therefore wT demoted wT = 1.
Lemma 5 r > n/80 every r-variable monomial satisfied xi must belong Bi ,


P
Pn/20
hence Bi wT r=n/80+1 n/20
> 20.049n . Combining inequalities
r
w xi 20.042n + 20.049n > 0 hence Perceptron prediction xi 1.
2
Remark 7 first sight might seem result limited simple special case
perceptron algorithm. Several variations exist use: added feature fixed
value enables algorithm update threshold indirectly (via weight w), non
zero fixed (initial) threshold , learning rate , particular three
used simultaneously. generalized algorithm predicts according hypothesis
w x + w updates w w + x w w + promotions similarly
demotions. show exponential lower bounds number mistakes
derived general algorithm well. First, note since kernel
includes feature empty monomial always true, first parameter
already accounted for. two parameters note degree freedom
learning rate fixed threshold since multiplying factor
change hypothesis therefore suffices consider threshold only.
consider several cases value threshold. satisfies 0 2 0.047
use sequence examples. first two examples algorithm makes
promotion 1n (it may may update 0n important).
P
P
examples sequence bounds Ai wT Bi wT still valid
final inequality proof becomes w xi 20.042n + 20.049n > 20.047n true
sufficiently large n. > 20.047n construct following scenario. use
function f = x1 x2 . . . xn , sequence examples includes 2 1 repetitions
example x first bit 1 bits 0. example x satisfies
exactly 2 monomials therefore algorithm make mistakes examples
sequence. < 0 initial hypothesis misclassifies 0n . start example
347

fiKhardon, Roth, & Servedio

sequence repeating example 0n classified correctly, de times.
threshold large absolute value e.g. < 20.042n done. Otherwise
continue example 1n . Since weights except empty monomial zero
stage examples 0n 1n classified way 1n misclassified
therefore algorithm makes promotion. argument rest sequence
(except adding term empty monomial) final inequality becomes
w xi 20.042n 20.042n + 20.049n > 20.042n examples misclassified. Thus
cases kernel Perceptron may make exponential number mistakes.
3.1 Negative Result PAC Model
proof adapted give negative result kernel Perceptron PAC
learning model (Valiant, 1984). model example x independently drawn
fixed probability distribution high probability learner must construct
hypothesis h high accuracy relative target concept c distribution D.
See Kearns-Vazirani text (1994) detailed discussion PAC learning model.
Let probability distribution {0, 1}n assigns weight 1/4 ex1
en/9600 examples
ample 0n , weight 1/4 example 1n , weight 21 en/9600
x1 , . . . , xt .
Theorem 8 kernel Perceptron run using sample polynomial size p(n)
probability least 1/16 error final hypothesis least 0.49.
Proof: probability 1/16, first two examples received 0n
1n . Thus, probability 1/16, two examples (as proof above) Perceptron
algorithm w = 0 coefficients w equal 1.
Consider sequence examples following two examples. First note
trial, occurrence example 1n (i.e. occurrence either xi
P
0n example) decrease [n] wT 2n/20 . Since first two examples
P
w (1n ) = [n] wT = 2n 1, follows least 219n/20 1 examples
must occur 1n example incorrectly classified negative example. Since
consider performance algorithm p(n) < 219n/20 1 steps,
may ignore subsequent occurrences 1n since change algorithms
hypothesis.
observe first example 1n algorithm perform
demotion resulting w = 1 (possibly changing coefficients well). Since
promotions performed rest sample, get w 1 rest
learning process. follows future occurrences example 0 n correctly
classified thus may ignore well.
Considering examples xi sequence constructed above, may ignore example correctly classified since update made it. follows
perceptron algorithm gone examples, hypothesis formed demotions
examples sequence xi s. difference scenario
algorithm may make several demotions example occurs multiple times
sample. However, inspection proof shows x
P
P
seen algorithm, bounds Ai wT Bi wT still valid
348

fiEfficiency versus Convergence Boolean Kernels

therefore xi misclassified. Since sample size p(n) sequence
size en/9600 probability weight examples sample 0.01 sufficiently
large n error hypothesis least 0.49.
2

4. Computational Hardness Kernel Winnow
section, x {0, 1}n let (x) denote (2n 1)-element vector whose coordinates nonempty monomials (monotone conjunctions) x1 , . . . , xn . say
sequence labeled examples hx1 , b1 i, . . . , hxt , bt monotone consistent consistent
monotone function, i.e. xik xjk k = 1, . . . , n implies bi bj .
monotone consistent labeled examples clearly monotone DNF
formula consistent contains conjunctions. consider following
problem:
KERNEL WINNOW PREDICTION(, ) (KWP)
Instance: Monotone consistent sequence = hx1 , b1 i, . . . , hxt , bt labeled examples
xi {0, 1}m bi {1, 1}; unlabeled example z {0, 1}m .
Question: w (z) , w N = (2m 1)-dimensional hypothesis vector
generated running Winnow(, ) example sequence h(x1 ), b1 i, . . . h(xt ), bt i?
order run Winnow 2m 1 nonempty monomials learn monotone DNF,
one must able solve KWP efficiently. main result section proof
KWP computationally hard wide range parameter settings yield
polynomial mistake bound Winnow via Theorem 2.
Recall #P class counting problems associated N P decision problems; well known every function #P computable polynomial time
P = N P. See book Papadimitriou (1994) paper Valiant (1979) details
#P. following problem #P-hard (Valiant, 1979):
MONOTONE 2-SAT (M2SAT)
Instance: Monotone 2-CNF Boolean formula F = c1 c2 . . . cr ci = (yi1 yi2 )
yij {y1 , . . . , yn }; integer K 1 K 2n .
Question: |F 1 (1)| K, i.e. F least K satisfying assignments {0, 1}n ?
Theorem 9 Fix > 0. Let N = 2m 1, let 1 + 1/m1 , let 1

max( 1
N , ( + 1)(1 + log )) = poly(m). polynomial time algorithm
KWP(, ), every function #P computable polynomial time.
Proof: N, described theorem routine calculation shows
1 + 1/m1 poly(m)



2m
2poly(m) .
poly(m)

(1)

proof reduction problem M2SAT. high level idea proof
simple: let (F, K) instance M2SAT F defined variables y1 , . . . , yn .
Winnow algorithm maintains weight wT monomial variables x1 , . . . , xn .
define 1-1 correspondence monomials truth assignments {0, 1}n
349

fiKhardon, Roth, & Servedio

F, give sequence examples Winnow causes wT 0 F (y ) = 0
wT = 1 F (y ) = 1. value w (z) thus related |F 1 (1)|. Note
could control well would sufficient since could use = K
result follow. However parameter algorithm. therefore make
additional updates w (z) + (|F 1 (1)| K) w (z)
|F 1 (1)| K. details somewhat involved since must track resolution
approximations different values final inner product indeed give
correct result respect threshold.
General setup construction. detail, let
U = n + 1 + d(dlog 4e + 1) log e,
n+1
V = log
e + 1,
U +2
W = log
e + 1

let defined
= n + U + 6V n2 + 6U W + 3.

(2)

Since 1 + 1/m1 , using fact log(1 + x) x/2 0 < x < 1
log 1/(2m1 ), easily follows specified polynomial
n. describe polynomial time transformation maps n-variable instance (F, K)
M2SAT m-variable instance (S, z) KWP(, ) = hx 1 , b1 i, . . . , hxt , bt
monotone consistent, xi z belong {0, 1}m , w (z)
|F 1 (1)| K.
Winnow variables x1 , . . . , xm divided three sets A, B C =
{x1 , . . . , xn }, B = {xn+1 , . . . , xn+U } C = {xn+U +1 , . . . , xm }. unlabeled example z
1n+U 0mnU , i.e. variables B set 1 variables C set 0.
P
P
thus w (z) = +MB +MAB = 6=T wT , MB = 6=T B wT
P
MAB = AB,T A6=,T B6= wT . refer monomials 6= type-A monomials,
monomials 6= B type-B monomials, monomials AB, 6= , B 6=
type-AB monomials.
example sequence divided four stages. Stage 1 results |F 1 (1)|;
described n variables correspond n variables CNF formula
F. Stage 2 results q |F 1 (1)| positive integer q specify later.
Stages 3 4 together result MB + MAB q K. Thus final value w (z)
approximately + q (|F 1 (1)| K), w (z) |F 1 (1)| K.
Since variables C 0 z, includes variable C value wT
affect w (z). variables C slack variables (i) make Winnow
perform correct promotions/demotions (ii) ensure monotone consistent.
Stage 1: Setting |F 1(1)|. define following correspondence
truth assignments {0, 1}n monomials : yiT = 0 xi
present T. clause yi1 yi2 F, Stage 1 contains V negative examples
xi1 = xi2 = 0 xi = 1 xi A. show (1) Winnow makes
false positive prediction examples (2) Stage 1 Winnow never
350

fiEfficiency versus Convergence Boolean Kernels

promotion example variable set 1. Consider
F (y ) = 0. Since examples include example monomial
demoted least V times. result Stage 1 , w = 1
F (y ) = 1 0 < wT V F (y ) = 0. Thus = |F 1 (1)| + 1
0 < 1 < 2n V < 21 .
show Stage 1 examples cause Winnow make false positive prediction
negative examples xi1 = xi2 = 0 xi = 1 described
above. negative example Stage 1 six new slack variables x+1 , . . . , x+6 C
used follows: Stage 1 dlog (/3)e repeated instances positive example
x+1 = x+2 = 1 bits 0. examples cause promotions result
wx+1 + wx+2 + wx+1 x+2 < hence wx+1 /3. Two groups
similar examples (the first x+3 = x+4 = 1, second x+5 = x+6 = 1) cause
wx+3 /3 wx+5 /3. next example negative example
xi1 = xi2 = 0, xi = 1 xi A, x+1 = x+3 = x+5 = 1 bits 0.
example w (x) > wx+1 + wx+3 + wx+5 Winnow makes false positive
prediction.
Since F n2 clauses V negative examples per clause,
construction carried using 6V n2 slack variables xn+U +1 , . . . , xn+U +6V n2 .
thus (1) (2) claimed above.
Stage 2: Setting q |F 1(1)|. first Stage 2 example positive example
xi = 1 xi A, xn+U +6V n2 +1 = 1 bits 0. Since 2n
monomials contain xn+U +6V n2 +1 satisfied example wT = 1,
w (x) = 2n + |F 1 (1)| + 1 < 2n+1 . Since > 2m /poly(m) > 2n+1 (recall
equation (2) > 6n2 ), resulting promotion w (x) =
(2n + |F 1 (1)| + 1 ) < 2n+1 . Let
q = dlog (/2n+1 )e 1

q 2n+1 < q+1 2n+1 .

(3)

Stage 2 consists q repeated instances positive example described above.
promotions w (x) = q (2n + |F 1 (1)| + 1 ) < q 2n+1 < . Since 1 <
|F 1 (1)| + 1 < 2n also
q < = q (|F 1 (1)| + 1 ) < q 2n < /2.

(4)

Equation (4) gives value throughout rest argument.
Calculations Stages 3 4. start Stage 3 type-B typeAB monomial wT = 1. n variables U variables B
start Stage 3 MB = 2U 1 MAB = (2n 1)(2U 1). Since example
Stages 3 4 satisfies xi A, end Stage 4 still q (|F 1 (1)| + 1 )
MAB still (2n 1)(2U 1). Therefore end Stage 4
w (z) = MB + q (|F 1 (1)| + 1 ) + (2n 1)(2U 1).
351

fiKhardon, Roth, & Servedio

simplify notation let
= (2n 1)(2U 1) q K.
Ideally end Stage 4 value MB would q 1 since would imply
w (z) = + q (|F 1 (1)| K) least |F 1 (1)| K. However
necessary MB assume exact value, since |F 1 (1)| must integer
0 < 1 < 21 . long
1
(5)
MB < + q
2
get
1
+ q (|F 1 (1)| K + 1 ) < w (z) < + q (|F 1 (1)| K + 1 + ).
2
|F 1 (1)| K clearly w (z) . hand |F 1 (1)| < K
since |F 1 (1)| integer value |F 1 (1)| K 1 get w (z) < . Therefore
remains construct examples Stages 3 4 B satisfies
Equation (5).
next calculate appropriate granularity D. Note K 2 n , Equation (3) q K > /2. recall Equations (2) (1) >
2
n + U + 6n2 > 2m /poly(m), /2 2n+U +6n /poly(m) 2n 2U . Consequently
certainly > /4, Equation (3) > /4 > q 2n1 > 14 q .
Let
c = dlog 4e,

1
qc q < D.
4

(6)

unique smallest positive integer p > 1 satisfies pqc < + 41 q .
Stage 3 examples result MB satisfying p < MB < p + 14 . that:
1
qc < pqc < + q
4
3 q

4
q+1 2n+1 3qc
=

qc

(

c+1 n+1

2

3).

(7)
(8)
(9)

(7) holds since K 1, thus (by definition D) + q
equivalent Equation (7). Inequality (8) follows Equations (6) (3).
Hence
1 < p c+1 2n+1 3 2n+1+d(c+1) log e 3 = 2U 3,

(10)

second inequality chain follows Equation (9). use
following lemma:
352

fiEfficiency versus Convergence Boolean Kernels

Lemma 10 ` 1, 1 p 2` 1, monotone CNF F`,p
` Boolean variables ` clauses, exactly p satisfying assignments
{0, 1}` , constructed ` p poly(`) time.
Proof: proof induction `. base case ` = 1 p = 1 F `,p = x1 .
Assuming lemma true ` = 1, . . . , k prove ` = k + 1 :
1 p 2k 1 desired CNF Fk+1,p = xk+1 Fk,p . Since Fk,p k
clauses Fk+1,p k + 1 clauses. 2k + 1 p 2k+1 1 desired CNF
Fk+1,p = xk+1 Fk,p2k . distributing xk clause Fk,p2k write Fk+1,p
CNF k clauses. p = 2k Fk,p = x1 .
2
Stage 3: Setting MB p. Let FU,p r-clause monotone CNF formula
U variables B p satisfying assignments. Similar Stage 1, clause
FU,p , Stage 3 W negative examples corresponding clause, Stage
1 slack variables C used ensure Winnow makes false positive prediction
negative example. Thus examples Stage 3 cause MB = p + 2
0 < 2 < 2U W < 41 . Since six slack variables C used negative example
rW U W negative examples, slack variables xn+U +6V n2 +2 , . . . , xm2
sufficient Stage 3.
Stage 4: Setting MB + MAB q K. remains perform q c
promotions examples xi B set 1. cause MB equal
(p + 2 )qc . inequalities established above, give us
1
1
pqc < (p + 2 )qc = MB < + q + 2 qc < + q
4
2
desired.
order guarantee q c promotions use two sequences examples length
n
U n
q dU
log e log e c respectively. first show positive numbers.
follows directly definitions U = n + 1 + d(dlog 4e + 1) log e c = dlog 4e
n
6n2 (by definition Equation (1)) bounded
U
log c. Since > 2
polynomial m, clearly log(/2n+1 ) > U n + log(). since
n+1 )
U n
n
q = dlog (/2n+1 )e 1 implies q > log(/2
1 > dU
log e, q log e > 0.
log()
n
first q U
log e examples Stage 4 positive example
xi B set 1 xm1 = 1. first time example received,
2
w (x) = 2U + p + 2 < 2U +1 . Since > 26n , inspection U 2U +1 < ,
n
Winnow performs promotion. Similarly, q U
log e occurrences example,

qd U n e
qd U n e
w (x) = log (2U + p + 2 ) < log 2U +1 q 2n+1 <

promotions indeed performed occurrence,
MB =

n
qd U
e
log

(p + 2 ).

n
remaining examples Stage 4 U
log e c repetitions positive example x
xi B set 1 xm = 1. promotions occurred repetition

353

fiKhardon, Roth, & Servedio

example would w (x) =

n
dU
ec
log

(2U +

n
qd U
e
log

(p + 2 )), need

show quantity less . reexpress quantity
qc (p + 2 ).

n
ec U
dU
log
2

1
qc (p + 2 ) < pqc + qc
4
3 q
1
+ q
4
16
1 q
<
2

+

(11)

U n ec

(11) follows (7) definition c. Finally, log 2U
1

22U nc log < 22U n2 < 2
< 21 q , last inequality Equation (3)
2n+1
previous inequality inspection values , U . Combining two
bounds see indeed w (x) < .
Finally, observe construction example sequence monotone consistent.
Since = poly(n) contains poly(n) examples transformation M2SAT
KWP(, ) polynomial-time computable theorem proved.
2(Theorem 9)

5. Conclusion
Linear threshold functions weak representation language interesting learning algorithms. Therefore, linear learning algorithms learn expressive
functions, necessary expand feature space applied.
work explores tradeoff computational efficiency convergence using
expanded feature spaces capture conjunctions base features.
shown iteration kernel Perceptron algorithm
executed efficiently, algorithm provably require exponentially many updates even
learning function simple f (x) = x1 x2 . . . xn . hand, kernel
Winnow algorithm polynomial mistake bound learning polynomial-size monotone
DNF, results show widely accepted computational hardness assumption
impossible efficiently simulate execution kernel Winnow. latter also implies
general construction run Winnow using kernel functions.
results indicate additive multiplicative update algorithms lie opposite
extremes tradeoff computational efficiency convergence; believe
fact could significant practical implications. demonstrating provable limitations using kernel functions correspond high-degree feature expansions,
results also lend theoretical justification common practice using small degree
similar feature expansions well-known polynomial kernel.2
Since publication initial conference version work (Khardon, Roth, &
Servedio, 2002), several authors explored closely related ideas. One show
construction negative results Perceptron extend (either PAC
2. Boolean kernels different standard polynomial kernels conjunctions
weighted equally, also allow negations.

354

fiEfficiency versus Convergence Boolean Kernels

online setting) related algorithms Support Vector Machines work constructing maximum margin hypothesis consistent examples. paper (Khardon
& Servedio, 2003) gives analysis PAC learning performance maximum margin
algorithms monotone monomials kernel, derives several negative results thus
giving negative evidence monomial kernel. paper (Cumby & Roth,
2003) kernel expressions description logic (generalizing monomials kernel)
developed successfully applied natural language molecular problems. Takimoto Warmuth (2003) study use multiplicative update algorithms
Winnow (such weighted majority) obtain positive results restricting
type loss function used additive base features. Chawla et al. (2004)
studied Monte Carlo estimation approaches approximately simulate Winnow algorithms performance run space exponentially many features. use
kernel methods logic learning developing alternative methods feature expansion
multiplicative update algorithms remain interesting challenging problems
investigated.

Acknowledgments
work partly done Khardon University Edinburgh partly
Servedio Harvard University. authors gratefully acknowledge financial
support work EPSRC grant GR/N03167, NSF grant IIS-0099446 Research Semester Fellowship Award Tufts University (Khardon), NSF grants ITR-IIS00-85836, ITR-IIS-0085980 IIS-9984168 (Roth), NSF grant CCR-98-77049 NSF
Mathematical Sciences Postdoctoral Fellowship (Servedio).

References
Angluin, D. (1990). Negative results equivalence queries. Machine Learning, 2, 121150.
Block, H. (1962). perceptron: model brain functioning. Reviews Modern
Physics, 34, 123135.
Carlson, A., Cumby, C., Rosen, J., & Roth, D. (1999). SNoW learning architecture.
Tech. rep. UIUCDCS-R-99-2101, UIUC Computer Science Department.
Chawla, D., Li, L., & Scott., S. (2004). approximating weighted sums exponentially
many terms. Journal Computer System Sciences, 69, 196234.
Cristianini, N., & Shaw-Taylor, J. (2000). Introduction Support Vector Machines.
Cambridge Press.
Cumby, C., & Roth, D. (2003). kernel methods relational learning. Proc.
International Conference Machine Learning.
Kearns, M., & Vazirani, U. (1994). Introduction Computational Learning Theory.
MIT Press, Cambridge, MA.
355

fiKhardon, Roth, & Servedio

Khardon, R., Roth, D., & Servedio, R. (2002). Efficiency versus convergence Boolean
kernels on-line learning algorithms. Dietterich, T. G., Becker, S., & Ghahramani,
Z. (Eds.), Advances Neural Information Processing Systems 14, Cambridge, MA.
MIT Press.
Khardon, R., & Servedio, R. (2003). Maximum margin algorithms Boolean kernels.
Proceedings Sixteenth Annual Conference Computational Learning Theory,
pp. 87101.
Lint, J. V. (1992). Introduction Coding Theory. Springer-Verlag.
Littlestone, N. (1988). Learning quickly irrelevant attributes abound: new linearthreshold algorithm. Machine Learning, 2, 285318.
Maass, W., & Warmuth, M. K. (1998). Efficient learning virtual threshold gates.
Information Computation, 141 (1), 378386.
Minsky, M., & Papert, S. (1968). Perceptrons: introduction computational geometry.
MIT Press, Cambridge, MA.
Novikoff, A. (1963). convergence proofs perceptrons. Proceeding Symposium
Mathematical Theory Automata, Vol. 12, pp. 615622.
Papadimitriou, C. (1994). Computational Complexity. Addison-Wesley.
Rosenblatt, F. (1958). Perceptron: probabilistic model information storage
organization brain. Psychological Review, 65, 386407.
Roth, D. (1998). Learning resolve natural language ambiguities: unified approach.
Proc. American Association Artificial Intelligence, pp. 806813.
Sadohara, K. (2001). Learning Boolean functions using support vector machines. Proc.
Conference Algorithmic Learning Theory, pp. 106118. Springer. LNAI 2225.
Takimoto, E., & Warmuth, M. (2003). Path kernels multiplicative updates. Journal
Machine Learning Research, 4, 773818.
Valiant, L. G. (1979). complexity enumeration reliability problems. SIAM
Journal Computing, 8, 410421.
Valiant, L. G. (1984). theory learnable. Communications ACM, 27 (11),
11341142.
Watkins, C. (1999). Kernels matching operations. Tech. rep. CSD-TR-98-07, Computer
Science Department, Royal Holloway, University London.

356

fi
ff
fi
! #"$ %
'&)(
*)+,(--.0/1((!2'34(5!2

64789 :)-;0<
-
*=?>7 %&:@-A0<
-.

BDC4EGFHCEGIKJHLNMPORQTSUJWVGMPQ9LXJZY[O]\GQ^Y[\GORL`_bac\dEHegfhC4ijLlknmWEGMoipC0Q9qr_sMoEGt
uvORwyxdz0L{i

k|C}pQN\dzYgm~v

JZY[LVfwMPORtkLilmWq$YRC0mWC4EGIfMoxd\
JHLNMPORQ#S

RR1^?
?g?yyg?g
?'?
9N1 G?TG
01P! 1

)$41$1,#g

yr1g'{#

$,ffR1ff0$

rDgG

1gg1ff0$

]g0@0g
)y
]?HG

)R?




)Rg
?!
ff fifi
fi 4
! !"#fi $fffi% ff&' ff&%(*) $ff ,+- fi$ % fffi." fi
0/%
1+fi3245(6/7fiy 8 fi ,$9fi:%
ff;48 fi<:fi$ff=?>@? : ABBCD !/%:4/
E?FfiG
?H!JIK !-1sL:fiMfiWE/%?E/% ff&NfiOZM+QP?+Rfi !$
:?S5fi !^$ff&fi TIU E$./% E&B
fi%/%$!5fi &%(V$?$.E%(W
G/%+M
!TE/= !/%U A(
X 4 8 fi0fiYfi '!0 : G#4 8 ?Z 8 ff%[ ?ESO:E fi $?\/% ]F0 $,+>5^_'SfiE ff/%?K
), fiE ff<
SfiUS`Mfi5 a,fi (V fi:b / $ff E&:fi $ffdcWeUf%4ZgI 0/fiZ ff<CD? B ?
$&fi A=1T .?h fi8CDifi 3Z P ?$ff+ >Y43 ?M fi E$ff+ICZ /%?-fiE
8 /
4
8 -
4 b/% ffESy .,C ?<
./%fij$fi%4 $9fi:% ffZ HE/T Eh! ?fi: ff $k fi$ % fi7 ff
ff&E$+lSfi ,$ 8?/bCD AN:fi $ffm/% A]F $A,+b#fi TC ?$$(VPUEfi8CDb
?N 4 $ff&fi En#fiB
eMf%4L ffU fiM/ ESy/ M+ $ff,$ />Yo*
!3::.??IC /% ff0. " fffi E3fiSfi- ff&U"fip E ff3-!
E/b/?$fi
: q?Cr
fi%/%$3fi :E fi $?s/% ]F0 $,+7 8BSfi ?S E?
/ X ?ES ff??>
^bF fi8C
8] ff$,$ /t $&fi Au ` K-fi%/%?$/BCD
ff& X /%?$ ,`+ G
:$ffK , Uvfi G
ff&U (
#fi rC /<
E/finrC $ffPp> K= E/%fin^C $Pw-fi%/%?T$ ?Sfi U#fi'E4 $ffs
+ $ff$5fiZ = , ? ff$ff A,+
ffR7SfiU,- ) E ?/N fi_$fi%
.fi Qfi:% Z r$ E/Q (6fi:% ffZ $Kfi$ % fiEh fi_ E/%fixeUf%4
E/_: fi8M !/%?`lS`%:,$
fffi_#fih/% Ap.S?' l/% ]F0 $,+bfiD E/%fisEO, . E /
eMf%43?>Yyk ff $ff$ff+ICZD/% ff0. [./B?-:E ff4 $ff$+'EU , 8 ,CZfifi8$M:?/% ! fiEk ?& /% ff& ?
H $&fi
4
.? 1M fi?>"yk ff?IU EG
fi%/#fiDSfiE, . ff&h ff , $J fi$ % fffi0 ffZ ff&$ff+
E$ ffP?$+- fi- ff-
: G: #fi ESfi
?q!J>kfMSfiE/IU Fff fi $!Z/ G $ff?S /

fi .H ' $#$ O:fi $ff=CD ff$ ff` $ fi E$ffb
+ 1fi !/% E&T 4 l& 8 fiJzk $ E?O$,&?
TS?+=$! / fi= ff&E X 4 U{/%& / 8 fiEZ T: #fiZ E>


"| }7~U g,
RD%Y9S%9J#w8J 0J%'1p8#w1JS8M9iS1.M.SQ,i8<%5.F%8W
%YnZp%Z%pM"O#MSkJ%kv-.8k%1E .S%v 7kv%#S"3%%3p%8Y-.8
xp<%#*5M%%E?<'<< 2 M<SQR%819EF6%=S7MM#M9#NM1
%98%w6%iB%O7%S-%%%S9<{lFh#'%J%h%59S%9nJS%J1G%J_J%
p#
JT ,!5,iO5?,UuOUW-kO8 ,,",3U?%




U

W U

(--.^ g %% !: &0%1% 0:

fi$4

$,ffZ

S9 98%.h#JE-#.bSTSMSJSJ#Rv8G8 MS9%17J1S%k9S%9 Jw89%
%JN%#%%SJ vJ%
S9#3YMk8UGO#.%SMO1D7p# %JSM9qMT6%KSff
%%7S9J##BJS%
fi. i? 'J
fi. #q%
{JM 19JM%#%%JS#< MS#J%9 %9J%qv17

%ZS=S%JJMl%JL<iB#<SSJJ_JS%Y<G#lS9J##0SM?"ZM9lM?
%%%#SJ<MBS8MJw%G%7qSB7G v1S%-M9JS%J6%%J8MS#qJp J%#
#JSJG7S fi. fi%#NR88%"3%%'%JL8SESwS8JS.OS=SM1,%W,S1MS-.
7176%SSM9FwMS#l%8hSF8S'17v8SS hB# spqSJ#*M% i# 8 8h# %
-<S?%%v
ZS"K%%?' J#=MJ8BJ%q%?J8%Q1JS#J8M9F%M%J1-#Lv8
6%<%J1_S#J1<Z%###M?!
JJ7JMS< v1S%Sq%iSM9HM %%%#SJ<=6%
fi u## "%k179MMS%#_##Sh9S%%SS'9%Ov8L<%=iMNJ8%%9#7%N9J8
S%J9#q% S=%%%#SJ<G%YJ*%J?JM%18$ #7S=JJJ8p#J#p8%vM?
pJ%<#8JJ8SS%JJ#BBEqS'JJ%w#8KMS'
k1S#%BTS% fi ZM%97JJ8#J-
S09%<#8O<.OvF7pJ J_<p#lVSS8'7JS%7ESB#lv8SW%?<%J1%
h#B!,JBLS9MhSqJ1SJSF%DSqMQ9%1T# &YJ1OJ%9xJ#w8J b6%
SM9HM %J%S80p8%SM %%%S9<w ''88%'%# "?GJ( .S%Z<#9%E
MJJ%b08%%Y#1i7p#{{0ES#WqShWMS%"S-M?bY%1BSJMiMS
J9N1%SS#M hS M18<J%7v8SW%?7Q1J%7%J%p
%STSMSp
SJ#wv8G8lUM?JiM?L9%1
WMSJSi%J_JS%9mJb8J76%O %##M* )SM9lM?
%%%#SJ 6%S+
fi. 6MS", Y. -hG%{d JS8%DM%M{M% /?1
0=2 9J9#
G8S
#MS%#_8MS#%# 3G<%.lWMSJS'SJMhMSFB#Jwv#8%l_# &9JJ1
JS%9d9w8J w6%
p8%M?7MS%.#qV%18J0Mpq1%SS#M7hSqJS%9jJb8J%KMS{SJ?7%DS
Jv8D%v%JS#w%J#S#J',i#MSq8%,Y%%?pS'9%.vhS 8,p#%J8T %#S"pM%?
%JwSB7%bJ#S%J1Bk8 8b%JJnp8%%JS#<b*RM6#" i8SBS" =%J68k%%
%81J.h6%h#SOSJ%<SJ?l%ZSJ%S% UMM9## b#RM1-W%- %##M* )O%%%?SJL
1.%8iB#W SM? JS%9 Jb8JW%7p8%iMr%J 5
46B 4D
,p#J%8=8F%* M%%E?Z<6JJQSJM=SJ<7%J#SS%J17v8G8%J #8%K%JS<L%J
S_MSF%9S#<%S#S"3BJ#?_% 78 9 :(;=<>9 :(;*K#9JQ1%SS#MBS9S%9
Jb8J%v%81J.S#l6%FM
#%
?@/_%Sq%S%DUM?#M9###L#QM1S76MSS8=%*
M% /?Nb6S879MHSJM 7A8 9 :B;C<D9 :(;%81J.SqW%q0J?%iSbUM?#M9###S
1D%vp8MS#=S,%9S#<%#S9 =SJE fi Z%%JTW%{9= k8J1D#qSiS#MS%'9w8J
%G FH JMS( I7%8JJ
FS1S%9#MK ILfi 8
h8%8SS8S 7A8 9 :B;C<D9 :(;O1<7p9%78%8%OS%S1<#8K?8{S_1vJS_%
179JS# 7A8 9M:(;=<>9 :(;K##<R=%J%ph_#MS%R<%#59S%9 #JS%918Y?%#S#b1p
18J-S8M?J#_S8%#M9#lL7%SqS%##SS#8%#lS 8QJS%Y #9S%J18F1J"kSSJJ%#
JJJ8qSJ 78 9 :(;=<>9 :(;O7pOMSN#M%_6%wJ0k8T%hJS%9 #9S%J18G%J SN7pi#
%F%88JM<6%=S<7=Jb8J-JS%9 #9S%J18q'J5Yv8%J7SJ 7N8 9 :(;=<>9 :(;D7p
JShJ_J#S1-JS.h#._STJp,S#<vJp%-%Z%###M?* )B%%%?SJLk78SES#
<%hJJ8SS%JP
ORQTS 78 9 :(;=<>9 :(;5#B<JJ#b1%SSMLBSLM?R1S8
=#.SpJJ1Bq%v1i7pJS9MG1%S1SiW%GShM6%S7.SlU Y8J8%5S
78 9 :(;=<>9M:(;p1SK<, 'J 7p*MB9#09%TT
8S%#q%J%pS# %9SJG?Jp,S#7vJp%
%Z%##M* )
%%%S9L"#
S<MSMM9%88M% %819ES#JLW%=%80# V %GSTUMM9##
#RS01h%{p8MS#wv%SR%JS#<% %JRSJ,%JS#<%3#S9O_wB#=?%%0%D9S%9
#JSS%J18R%Sv8 98%%pFSSM9##SlSJ=W##B#JqSJSU 3
WBWBW

fi91#
gfiffgg

M-pM<7 %##M*)Z%%%S9MJvMK=vGv1S%TSS#1T=SJ9%1 8 9 :(;
%7SJlSJM1ES%#9Lv%S p8%
%JS#< %J\#S9lSJMRMS%8 8#
VSk8$ 98%#%" <<%-iL6SbGp8%"%JS#wp
BZ%##M* )F%%%?SJ 8%Hvw7pBS<MSMM9J
9J# %qRMM#%.%'S#T
Y<1J7JS9% ?%J i% %8qS
8 9 :B; SY%1%_'J<G%#1J9#S=G
J%SM9TW%?<
%Y#%
#QS7%JS#SR9S%9M9#S8FKS8kSJ7JS%9M9#L%GM?
<p#08#8l66MS86SbDShJMS%9S#<%9S#Sb#{J%k%SJ%5V#.%8
9S%v%SSJ%W<uS8JSS.NJ#S%J16S SJMSN%JS<%=#S#"dp1J"
SMb1p99SK77.SJ 3D{{7%SB%07%-88l66MS8{6SbZShM
S0%JS<%S#iSM JS8pJQ<% 88T 66MSSJ806Sb=SbM
%9S#<%5S"{R%S8%8kSF?%Jdi%l7J"%81JESh6%BMB%-% V %KS
MM#MY## w#lS<%NM?R1-%1SSBT?%%F%KB#9S%J18
/BBi%Jji%07pp#Z( J%#%88JM'6%D%JL%G%S &JE%J &JhS%L
fi. 8
-hG8%8<
%J= v8SJ1{1p#S{#TSBJ0k8D%vSMG#TSOi%k.*%.S'<U#<%
vS9=J#SS%J1Fv8G8Rb#SL%9NSJMSB%9S#<%5S"
=v8SJ1h#
SJb<U#<%J#S%91FVJ#Q%81JEq6%G#!,pBJ= v8SJ1Sb9w8J %
9S%9d#9S%J1'?Bl6SdSSFUM?J'SJ8#%S
BB7%88%1Q%S7%9 G%Q7pZ%J68-NlSM9 M?%%%S9 Y%
S7vG8S69 H7%b%k8?M%5BJ #=7%S<8#QS#M RSM1,%W,S1MS
SMYNM?R%%%#SJ<O6%'S
fi uSJ%R %##M* )i%%%#SJL
BB<%JJ G%# <1%SS1S JS9#1S=SJMq#JS#MS_Z%##M* )=%%%#SJ 6S
9p J%# SMSS#SJ0B##JH#7JS%lk8W%w%J1_#'SL#JSJTMS
%8l8#F<SFJMS'%JS<%5#JS"
BBB%9ni%77p91%S1S7JSJ1S{SJMG%E7SM9bShMS%8SJ%bS-<#J!
qJ( .J#ST%<M?wSMJMS#w#{%0#J1S%OSJOW%1S#7%vS'M?
S9%1T19#%SRRZ%###M?* )B%%%?SJLv%JQ%=b1JS( .91qp#Q_8
fi "!#w#
9S%9 9w8J %<W%?<%#%5SJw8#<ES%JMSS7%'#M%<SM9S0#F%6
1p9#%S79.%9S8SNSJMT#MS%b.0#<9%10M? SSSb#S%
&91pY## w%JlSFSJS#Jq#9M9## <w8MS8VJ##w1p9%S
SS9%1F%K.k%?#TM
SJ8 0
DSJSKJSOF7%S'8S%7%J<1J18B%81J.%kSJ#K9J7
lS1.1h%ZSJ fi. Z
'JRS<%J8<%FS9#<9Mv8_#<%S%9 8 %_6#B8 Qk8r# 1SJ_%J /
BSw1JSN%DS fi Z9 %##M* )B%%%SJN9%JNSJJS%Y #9S%J1B9R#N
%J%pS#TB<Ev%SS#=9J8p#b%J%#S=#F8S%###1S$
wbSJw<M 8
%J 1#S$ .J_9%7SM? 9S%9 J#w8J W%wSM9uM?r%%%?SJ<T6%<S5
fi
# 1S 1S#JqRSSJ NW% Sl1%S_%'S_9Mv8ZBJGl8%% %J
M%##JMQl%J i%r7ph%0Z%###M?* )w%%%?SJL p1S 8 1p9%SQS
MJ9#8M9###_%{Sq%J G%#R7p3L7%q?J1SSJS%9# #JSS%J18F1S %
1p9%S7SJRMJ9#8M9## %
SN%9 i% 7JOHSMYrM?r%%%?SJ SJM_#
7%SL8JS.SMS%N%
SM1,%W,S1MSl%%%SJwTW%<SJ5
fi. S9%u %##M* )T%%%?SJL
1SJ8S%##D TJ%kSJB%JJni%77JJ#<JSJ#1S#%B8M9%8 %{-198#J
qJS8JSShSJB#79#8MSJZ%v{SJSD%J<9S1SJK6%{VSSOMb#w1S( /
WBW%

fi$4

$,ffZ

K} ]
ff1 ~U fi1
1J#8LSG#!,pB SMS#MF88?<#J#SS#Pfix# hJ#
%9LqJNv
JSp1S_1%1Sw91-_%?L% <%J=Gff8 8B#
8O%*"%%?%?
%B
#GSlS_%N% <%JO#_TJS1U 9Jw%J8B8S!.iJ%
S"%S w%J#J #
$%0#HSlSS%?8T%
%&'_JSp1SS#JR%
%=
<%?J#' !D#%)( +* %Jw#8%#<%w%k8?MS" 4hw%v8MS"( +* qJkO9S1
<%?J#!.06%7% #E8%?%G9MS&,-+*#. p
0
J1L#J#S#M"KJSp1SS#J8%J%7v
JS1,<J%J 1J8SJ1R#9Jp#JJ%5w%J#J-=%=%#G"5*%3S7<%J=MS
JJ#8M9%8 S?18s%R/012ff(3+* 8%JJ%_v8# JSp1SS 9ES#ff( + *54 2/ J%
179#8H9S1S#'_SJJJ##JR%
1S%L#q<#J#w 87SL<M%9%76 98;: *%
ST1798S#RS#<%{ST#%-%v8MS%%.
%3-M%9%p<J#< MS#N6%-SJ fi
#9<>=
JMNW%?. 7%J@ A. /L,=MS8% fiJJ"9 8SJ*5CBM?
4-L#JS%91-%ZSD E) fi u#iJ9$ .J<U 9_wSFS8O%F G %v8MSLJJMSJ
,-+*q%JH5

%SJS#w%?8ffh7U 9Jq JICKML fi %
%QJS%J10%8M H
S%7Y##iSN,-O*#J8vJJES-%JFJ9W%?<B6S %#.8SM%P+QSRUTWVRYX.%Jb*51J91S#
SD W ?%Jmv80JSMSJG%3S=#.8%8'( J1Z\[MT^]^]^]_T;RO%WHQFR$[
%J`VRa[ %rVZ%##M"h%# / -<S%,iRESpO?b %F%# "? BR<
% %2 fi
vJ9<MSbJS%J18Y#J8#J9#0<OW9JL#lS 0G'dc3#JMS ( JMF%J fi
hp,%JJ fi. =8%v<1J91. #7vS_SJ1SS7S8=Se,-+*M3Se
%
v%S"- lJM%"SM?8
J%7JN1JS8SRJS%J1-BSQ91SS>v%#S
i#G%.W%GM_T%JMJi1#S#q78SpJW%i%8MSqJp,%Jf,-+*-W% &J S%
S?JJ#RJ%9<l6MS" iMS9J8"K J#S8%{ -hG%OM%q fi. Z. 0
LM
JS%? %8MS#JuJ1Sg #.%%l9MSSJ#JHS8L%\ <%JL#. OWh
1.SJ8( J%#.S 8bS98S8%# OK jilk9@K O#m pn pK !?G%i1p%7Y%.h OWhY[ pS
8
%Y <%9#
#h9MSSSJ#._GNS98S-1.S%#J#_ST<%9#TqSSqqrM
%JEqrMs TSSE"SSk1S#%%0SJ?lGM,9MSSS#S<%38%8SL

%qJ=v
JSp1S %#G<%?J#7#HS+
JS09MSSHk86%SlJSp18J#JR%.H<%?J#l#
1Jb9MSS#S"R BT1J%ESGMS-9#%1<bS
%bSS#J%8?{BS9#7%_9MSS"
TS868h fi. hBS OWh[ bS#79#_% OK jilk9@K Ofi. 8ffc5S-1<7 MSffkt#K !KQuKjm fi. 8
B8 OWhv[gY*%J%#"%ZS
%9Op#SiSFw%J#J'#lS%7FJS1J88<#_%J8
J#GSiJSSJ1i%Y91SSi%W7wM%{SJJJ##JBJS%Y< %S8DF%F6MS
80%,KM%?{S9#F#0%FS_8%w6% fi FBS?J1SSwN=% pA %JAZS
%8?M%<Jw8J#_%{JS%9#x#JS%919xN%h<%SS.LSJ01-S( JSRbSJ8hp8M
%_%JS#<%vSb%GTJ%=S-%JS#<%<% qS#S"xw#<9#8%TJS%v%SSJ%9
OWh=Q%S8
G%J8v%JJ fi -MST%8%LST%S=#9S%J18vBJ2
&JBS% fi.
MSqS77
Jw898U#JJ16%
SJ#h%98SMMS <-6S wBMM8 N%J18
%71%79%i%S8787%*'%%T#.SpJJ1 8ST% 8Q%J %J G%S &9 fi.
#H%%"S%9 fi B8 J#SpL%_%JS#<%##%9hJ#=Sq%JS#w%3<M%Y%J
%B%#90b%BSbG%S &J fi 0MS_8JSS.SJph"Qp#w##M%3S_<q9w8J
8'_8FvJ?J<MSqJS%Y<8K#SJ8%JwB79 )D#V%7J'8Ub80#JS%J1'%9L
4hJ91
M7%JQi.% )q%pz|{|}NJS%J18kMS0%% FM# Iw%S &Jj% &JBS%!
fi. 8Y#NSJM
S7S( J7E
SJMF
%vTJSp1S %#D<%?J#=J7%S &Jn9MSSS#v86%S
JSp18J#Jqb%EL<%?J#F#lSJ1pO%S &J\9MSS#SL#OS##ESbS#Up"
~98*, o;GGD , ? 3,'-,*S, MV,AM6U*! 8,O
WBW^

fi91#
gfiffgg

4-88MQ1w7p#T%
p8%'M?r%%%#SJ<7MSN%J8%#H6J91SJT%-SR8<%
%9%b%9S#<%5SJO_<J%9d#JSS%J1b6MSQ8h%,kM%/3p#%8B8h%*vM%%E?
%JSb1q7p#=Gb8%#% 8<6JSS8F7YJ%S 8<S9#8vJJJ1%

_#9MF
S-179SMS9%91G%".978MS".i%J%pS#{##MS%TSS#1b08S%3' T%J
Dw0%9L%S &JF%JL
&9BSJ% fi %l8O1.S%#J
M%%7#JS%91GMY1%pBS
S, +* S%<9T6S S'#.8SM%P!MT%3X,3F%SDS'8%#M9###%k{17J#8%G'%#
J'08{%D8%w8'w8F?%J
fi 8%h8S'S,-+*BMSBJJ#W%wS%7Y76SSBE8SM%
P!MT%3X,L 1S 8pKw19S#8S8S%=8@ 8NG%S &J %J1
&9BSJ%
fi. =%8?M
# %u%9%%%Jww%J8u%l179M?MS%N9kSTBS SR8MSS%%JJS9%#
S8v%SiSS9SGW%OMMJ
8 8<#JSS%J1GWJ9L#_S
0 'c3#JMS% 4-SlS78 8
0 '/c3J?MSw#JSS%J1OMSF<J%8B1JS#J8Sl9MSS#89#M<?J%#pS8_9%1%
S9 98%.GJ%#8%kMES#R%Jl8S%=7M%##9MhSJSG%JS%#L9S#0OB8 Q8
JS%Y S88 J%7% #JSS%J1_%? %'SLMW%7ES# JS%9 8S8QMM#%.0%
GSN%J )T*M%%EB19%#.JS1SJJJ##JT%#%%SJ i%h9Lw17Yv%S
SF%9S#<%"<M%Y%R%JlS08'%Z%JS#<%5S#SJ
5TE G
$[ff
fi
K} #

-J78SJSM9lM?L%%%S9<J%=v8b8%#%kb6%GSJ fi fi%#LjN88%55%%?

%==%J%#S8YG71=% %%%S9 #.SpJJ1. %##MRH%"0T797.
MM#%.q%- %##M* )q%%%#SJL{B9# GN%M%J %S##S8JJ91SJS
1JSElB#S SJS8v%S . %##M" # JKnl SM1,%W,S1MSSM9 M?
%%%#SJ\6%DSE fi. BSJG%%%?SJ<Z%N hBSp%JT0S9#Spk*M%?ZUU8##
%JTN8##
*M%%E? %9P
iMJ=%JiJ%0k8?q%# =%8
%8%#Kv8S6%<%91%2 4h#Z%{SJ
%%%#SJ<ZvSSD=1%SBSM97M?<79%J#S SJM{K%8Sq#<##MZ=SJM{6JJT#

9J= v8#wSh?#1-%57%-%v8M%pSh<8SbJb%8?M
JS#%SJ8%J
S9=%Z#M,8 <7%Sl7J%9#S<OS9N%BS#.JS 98MS#"
0
J-?#1T%
b#hJMwMS#MG 86%STS%Sp##J_7%q17Y1k"SM1,%W,S1MS0%%M
S9<8%G% JS{8%%b1S7p#K%"F#MS%TS#7Yi9DS8JESMS#%B%8S#7%vSM9
M? %JS p<MS#8%%SS0Sl# &9JJ17%B7%S_1791%#%%SJ<7WMSJS
l1O7p#%3S-9%S#-%%%#SJLGJ( .S%pO#79#7ESMS#w% T8p#M
6SxZ%###M )%?#J%"%%%?SJd#lS8FSv1S8{KS81<9SL<M%Y%J
1%1SR#JS%R%9S#wb179SMS#J%#L8w8#E-S#<MS#S?7%=1J"kTl%
JQ6S( .JJ1E,Y% 77%SkZ%###Mj%"
5-8%EL#JJ#8MbSJMlS vU J_%SJ?
77%T#MS%#q#1wq#9S%J1{( .J##=F%8<#MS%hJ0v8hV*% \Bw###k5%
8MS#J8{'J#"F#9S#M-#%#i%! q6S %9dp8%v%JS#<NVJ#T7S<1
S1#kTv-K#9%7%vS'SJS#J-6S %##M* )D88?<#J#SS#i1JJ1S#<78Sp"
4-FJ#S89SQ#1S #MZS8S<#
L8J17SJM=S7 .v7%GS7#JS%
J%'w8#Y-79%1'LSJv8LBSlhJ#"
<p8M'%9S#<%5SJ8pB9#lG
SM%0%BS=J<MSw%
1S%0#lB%J%#S8

#$%'&(h 8,?9,
,UB?,,U ?,)$%*'+-, 8 8 +-.0/h+7S,AGM%1!T,*j7i32 ~54646#6798Y,
U lEU ,o" KU* ,'%*,Zo;:1
,U{K,MSZ,GA??,,U <:A,3ff,?>=p?A? D,+M
???,,Uu+- *<: ?E,*%,3jU B,iOUM*A@Z,UK,S,A:1DO%?*jK,UKOB:1K?%,
WBW'C

fi$4

$,ffZ

9FM%wc %M%H8T%* )l%%#,B 7%b%v8M%ZhJ#HiM9
%
S%1EL%v8MS#J_ 1?S#8%h9pSp_rSS?JJ#% * L#79#7ESMS#"'%J #
1.%l w%Eup8%-M %%%?SJ<wW%_S1fi. BB#= p0JSJ#Sp*=%%?
9%?=%O%
%1.T1S#8%D%v8MS#JMSb1JS#8%JJ%E
SJ=SbS#<1?S#8%
9MS"G 4i
%8MS% pvS7<M%9%Q%%?.v%h%{SJT8JSS.-S
#'1<9R%9NSJp,SM9RJEv% ff
ZfiUOBSLS0S<%#SB<M%9%#'#1
6%=S71F#8MS"5S#=MSTJS%% %JJ<% c38wp(3+*CT ( WhJ%7ST9%
%G%@
%1.
1S8%v%k8?MSJOSJMhMSiMJvL#<%8MW9SJ?LSJM'(+*FMJvMiv86%S( 5#
SbJSp1SS#R%8%'w%J#J !.?RSbSJ9( Ej#8MSJ8! RJ8%ES0%
#Mv#'%
FSM9A I_%.N7%TSJM
#.%8SS'Sq%v8MSR9%qp( (+*?BB#pkwMM#%.B%
6S( .JJ1E,Y%7<%S%ZFR9S8%E0S1.SiMJv9%F%i1?S#8%{%v8MS#J=6S
v#_S1,SM9#S"0'7S8%#M #-B%
S7SM9 S<%9Q=JJ6%<LS%<9
8%8S_M]A + 8?MSJ WS pp,B#S0#.8SU%GP , + X,EJTpJ%<#SM9q.JS
8%R%#NG#!,pBL18#FM?NvJ%?O%Sp8#MNB#S pLSM9LS,=%8=
c3M9JpY%CB%?c38 "!#$ ;pJ%OS'v{S7p8M<J?#=%ET8MS#7%vS'8SS.
J%T#%{% pQ J6 98;: fi &%`6 98 : fi"!'#($ ;?DSbSMYHSMS90%) #q8M"G#
%S8=G%J8 _79
lS#<90%S9MS 8%K1#8"=QMS78%85SJTw#J#<%
.v%#b<M%9% <Nv0%98% .Rk%SQp,SMY%JSM9p,Y%9R7%85#
BJl8%F7p,SMYL7%F#i%ip'%818J5 %#v7%'# *KfiMMS=SM9"77%#
%818JbW%S'8SS.{8MS#"KB%98%'SJM{#7SJ'M9J1'%kSM9<<%JS8%.S#
#79S%7.w%=SJ8SE_#S )<<M%9%5 H%1S_%_#79L%8uS1.
JSp1J% R%S v8 98%##%G_#w8#MbSJMbS1%QM? 9#%w1pJ#9 #
88v1E-8%3M59SJ?LSJM'S8#OS9 98%.G9SSS-GM?p8%v%JS#wp
ZM90.G8%qJ%O-<
%K79%130v8S6%<%J1% G%S44035 q7Y#8%4 %5S3 S8 %##M
U9J+ ,, [ fi] "-d%J. + [ M]A-HUh8S/-?[ FsffqrM10,2 .76 s<erM80,2 .76 V %##M"
%" .? H%Jy MS0Sv1S%lSJ0v8B%
%YB%J<%JB#RSFJ%9x#9S%J1
%J < [g GK<J##<#9MS=1v87ESMS#"EGB%9S8S%wS9MS'SJS#J=.BM%#
6%'h w%JR R7JS%9dS8S06Sv1S%#EP /uKT 3XK%J P WT3X6iV%#lbJS8%.B1p8##
%FSMJMS# k9p%
9%"v78"P , + XK( J%KAPuT MXW%=%# #%h#.%p#
S_#JS%91%JS1S%79#<SwSMYS<8%8S ( N8MS#J8L%l8@ 8R#JSS%J1
Gq8 P ,, + X ( J% EP "uT MX{6%
%#5%#B%JM%#QS1S%7YFSqSM9.8%8S
( b8MSJ9Sqv8 9
M%#BM0SM%Q6S Z%###M?* )OSM?"kBJ#?N%#_%SRS
M6%S7.SQJW%
#%h#.%p#R8 H8l#9S%J1TV %##M"Z%" .?F %##M* )O?J
MSNJS 9J7pJ JH# %#G#%#T#.%p# #MS%87JS%Y #JS%J1{%SJN%J% 8
v #R1S
9 fi:<;Ws1 1>= @? '=
b-J#%B<%S'v1S%2fi.H7%-%v8M%GSJb% hB#v 0S9#Sp*9%%?S *
%v8M%#9JJ1DM?wY%1DSJMMS K 5n IMp#TSJM{{#D%#GkS9G7%'6S
%LMS9#MSbS#S_<T%9%v%9S#09LGJ( .S%'#GvSSYBw19J1'7p8%
M?%%%?SJ 9%S= 0SJM3#"9S%9M9##S#8%##iM9JS#<M#-17Y8h 4B'{ -h8
%# "?YJLS9MB%l%JS#<%"S#SlB#98%.SJ%##bv=p8ML%NSJw8.Sb#M%=Jp
S#7R 0
31v8#<ES%ESSJS3S%% SJM B#ff 4B

15-S%9M98S56%
CBZ?S,Aj-!3O5 :K%S,?,35 1 Bff,EDYG@F 5< @ 1VIH1HKJ 7
WBWL

fi91#
gfiffgg

SiSM9qS%E#%TKJ W%{S1S# ,, %J +
#%.% hV%#q=p8M
%Q%JS#<%Z#JSRL%.N%{STJ%9 JS%J1
S1?vR#1S
9MSS8J#M
S<SMY.JSwqJ=v<#MS%<J6%)
LNS8Mvwp8%D%JS<pZ9S#LS%=SM9
S8"-#hS%.W%SiM_19J1
1%79hB8S wB#"v170v8w%ES#
MJv7#qS'M?%1%9%#q%k=Si8%p%9S#09LZ =vOJSUM9#
4B JJJ8Z%J8%
9M%<88TS8S#8DS %%%#SJ GJ#H#% S( Jb7pJ 98MS#J=JM9#R0
%818JB%RMS9Mw7%qM'%E_%N#8MS"J%##B#JqM?N<%#GBJS%%SSiGM?
b%9%5%9S#09L -h.7%# "hJ#8JShS#<#MOS( .9S7.ShLST1E1p
%. 4B p8%
M?r%%%?SJ<T6%w5
46h 4D={QJ%RJ%79SJ Ju<J$ 98MSJqv8%JLS8
%{J%1S#8%.8w891F#SS3%Sp8#MqBS=v%39M%<88ZM%#1S"%%Jv8%J
'#O9J8MB SJJJ1_%JJ<SiGJ#L#<9%1OS1%SSM9NM?RpJ%<88
'JF79?#8%* 4B JS%v8S lJM9'9ObJMSJ%#_U 9FSJ1B( .J#Slb#%0
%JS%9 #JS%J176%0$
! b#%D% N%SbJ0k8=%O8?MSJF( .J#S
p8M=0#%9%#T%JS#w%kS#S"Zb%J8%*pML1S'JJ8 T#Gq%J UM?#M9
BS%M9JS#<M#_1pv.S#%3J9JS"J%hTJ#S89S'# 1S -GJ( .S%
GBU 9OSJBM?w1W%F%<J%9#JSS%J1'%{SJ8S'79#%7%<%<.9v8
%O8MS9=S( JS R#8M_%%JS#<%#S53S<v1S%L
J%ES#SFMSwJ%

7%J U QS#<Mk%S
7%J LJS#JuM%% J8vJ.T#%#8
RHS
1pkJES#%"9MSS
% SJFJJ8##JJ#?9S5E7#MS%FJ0k8i%KS%79#O#GS( .9S_
%98%S%SJM9_%88MSS#<M'%Kv%SNSMSS#88
0
JG%J%#SSlSJ-%S#b%
J#S%J1ff

fi 2 ( {v8 8l 7#JSJ 2 %J
( OhJ#uSM% %wSRG#!,pBrJ
9J1S%L%M9 J#S%91H*RM6# 8b%,F%%?
c58 fiK TCT U0J%bN9SJ#8M<S9M088w#Fh8S8E
%>QMJvMFk86%S2
%
#
S<9S1S#L%J8F%O<%JB%O#JS Ew'<J
9J1S%T%M9HJ#S%J1

fi 2 (
v8G8 2 %J ( OSNU YL%
6 3|4 2 3

fi 2 ( v[ * W * fiK TCT 2 fiK TT (
2
2
2
B8=SFpvj%BS2G.#% 60 ' %k8?M%DJW%w%#%pSFJ#
J91S%h%?M9
J#SS%J1_#798MJSJSqS_J8%S8l%B88S%%# %98S% #HSl<%Jb9S1S#
( J1h%DGL#S98 4J%SM99S%v8SL%DSqJ#
SJJ1S#%=%M9R9#S%J1q#'SJM-
8S%%L8FvJ9"vBJ#?#
79?#8%#LS.83 SJw.9v8
% H7%0S( JS
7%JSW% 2 #E& ( {'J#i#G%8l#_'%J%pS#8p%'17YSMSl%ZS
1p%1BJ0v8G%
7%
S( JLw%9W%? 2 #. ( #%
D9M {MJ8D%# ?BNSJ0Sw%#J8
%3S9#G9Mv8.G=J

8< FJS%J1( I7%J FJ#
J91S%h%?M9lJ#S%J1( ITp.<JS%
K#J%%MOU 9Ji+
F%9 8%p%9S#09J
Ih%D=S#S0SSJ#S#B6SjS'MJY##8MS
%O88vS1.0#8%DM?9J8=S
%k8?M%RL?%J !#^L 5n bS"
4sS<!%1S%7#JShU %-_6%S9#0#JS V,%5#%Sp#L1p8##0%8#Jb8vp
J8#?
#hJ#%#D%v8MSJMSwJ1SSMS#FM#SFvSS9#TSSMSS#NS7%b
1J?J1'%JJx<!%1S#%0#JSJ8GJFwJSp1JS=#.SpJJ1LLRM6# %%
1SQA?GBF88vS1.-JSp1JS=7YpO%JJdS1,JSMp#<LSFJJ1
%D09S9
( J%#_%N%#8JMS%-%JL8w#JM'910<S 0#'p8MQSJNSJM

*ZfiU? 6 t8;: fiU9 6 t8;: fi ?
WBW



fi$4

$,ffZ

{} blg {,]Q ff
fi dR {$[,
%=b%R9S%9 #JS%J1%v1JS8BSq9%1q%{6%S90#S9 r%JRSJ0SJ9%1
8 9 :(; r1ES%J#w%3p8%5%JS<p
0bS0SSwY#%'GM p8%5%9S#<wJJJ1
FSO1%SO88vS1.?M8%%EGG1pv1
W( ..S%79G#S9 # 8 9 :(;
J?#=M?". -B8%8Sh8%8BhJ#w#S9{# 8 9 :(;kMSB%1SJ%## fim !##n n
%
#JSJDp#S<. #FVJJ1S7%"v%SwSh%S<%5p8%J%9S#<FM%1%OY%S#J
#SJ
fi. \%JSwv8 98F%OSwS%,8 <7%S79%J#SL_9MSS#89#M SS
M%1%
9%SJi9#LS( JS <w<%VMhGN6Sxp8%"%JS#w<#l%8hw%
M?7SMJMS5R 'B1ES#%%MSR*M% /ZSTS9M SiM%1%{Y%S#J %9p8%E%9S#<
#TS% fi MS'SJS#-GMTT%8%%J<8%<kiS8Mv7hSTJTJS%YM9## FS#7Y
Qi%818JS<TS%Si%JJd( .JJ1<V*%J% #%S-%h07.S?%Z<%J#8%##
G%J#J <%Q%Jn*_S1#9S#MS# %S8 S1.8x %S8RG%JhSMS% <%#
v8SSSYMSJOMSqSw8.'_7%Tp8%3M?RJ'%DS0M?%1%-Y%S#L%D<#%p8%
%JS#qJ #0S fi. ZUO%98S%iSJMKSOM6%S7.SqJSp1JJp#Z%T%k8?MSJ%
U 99ST%5M%1%i9%S<S%S5.%pv8 YOS8MvBJ%9M9####%w5
FG%9#
%JJ ( J1%
#%Suk'#u1.%_H7%#6%<%B%SJ<J %wJMSBJS8
B#JS"p%BJ#%788
i%w<SB%98SMMSJ8EB.k%SJS 8OSJMGMb# F#D v1S%TS?#1
QS_9%1 8 9 :(; 8 9 :(;1.S%#Jv%S p8%%JS<R%J #JSJFS9MqMSl%8S
8_p8%%JS<R#8<q%BJ
9J1S%<%MYHJS%J1_%K( .J#U%.S%KSl.9v8
% 7%8h3bBSJB..v%SS8JG07J#%BS ! nI !-n fi 7%D#S9OS
w9#7M?R<?%%%K%JJ fi. OSM%Q6SdS 0 '/c JM%TU 9
SN1Ew9#S%J1l%
8%JJ#JMNS#S %7SNJ#
J91S%b%?M9 J#S%91
Qfi|T #
v8G8EL%J p8%%9S#09 {%8Mu.M99p#S88kSS1.<JJ8qS *
%v8M%N Em S%%=S1.NJ#SS%J1#lpJ%SJ SJS%0%9 S1
JSMp#lJ?#l88vS1.8Tw%#1p%1?JM%18$ MS%iS1.FJ#S%J1T6%
%.79MSS#8JM -%Jw#9%w17Yh1EGJ#S%J1-SMS#S8{%8OB#O%J%B%>EKJ%
%QJ%9x#9S%J1%9Gq18
<6%hq<##l8MSJY179JS#<SqS1.
J#SS%J1w%'SJ_8SET#JSMq% 8?MS %J1%J#SwSJS#JNS#718?8
#%K% FM'8<#9M7J1h%<%JS#<%JS#S7#{J1J.8Sw%JwS1SMSwWs
%JJ8%J%JS#qJL{8%8%SSM8?J%B#.S9J177%SDSJMMSh1J18JSJ%##
S#MN<S1.'J#S%J1%YOMSF#l1E?%'9%lRJ= v8SJ1O#l#JS
JSS8{J%
1%79%pM?EI lm n Q -h
8Y5# "#"GU 9Jb%GS-<#J#w%J#J1S%S-#L
JSS
V%SS9<#
<#9#< MSkiSJMqJ=v7%818JH# %8FL8MkbL8%K%9S#09 M%1%0Y%S#"
p#w##M%KpJw%J0%9 JS8r*M%qU 9_M? J8JSH%qSlJ= v8SJ1bv8G8
S2 9SSi%D<#JS%9lSJM'%D7%9%v%9S#09
p9<<MS<SMSS#8i6%GSJ-SJS#J0S1.'J#SS%J1iMS
S8v%Sl#bZM97M6%O1T
9MMS#%9JSv8Gi%JJS9%#B8k%3SG7%0JS1EKJ#SS%J1%9S8S%qW%Zw###
%JJ w!%1S%l#S98'Jb7% %J 7J#%HS1.7J#S%J1_SMS#S8qJJ#8M
SJM 1JS#.SHS<%#JqJ# jx 7%wi 6S p8%G%JS#<p JI nT%
JS%Y 8% 4h#S7M?w#Kp88%S9%#0J%q%8ST6MD6Sn#8%p%JS<pESJ?78%.S
MShMSOK%1%S%k%?MwTSh S%9JMwJ8#MS#J8 79##8%p8p#J1B%%SSJM
#MS%19#S%J1F8%.S
MS%hJF<SJF1pJ1%Dp8%"%JS<7BSN%8SL88M%1%
9%SJ8J9JBMS?MS8-%QMSSV%1B% )-S%S,8? 7<%SN79%J#SLO'JSJS
WBW

fi91#
gfiffgg

* 8 Vj
$%'&(
-j
* 8 V U
A@
<:%
VjU
-A
-


! jU? ?A,oU
-4
-4 ff fi
?
?
~54
;~ #
-4
-4 ff fi
? H1J
? 1J
7J
<# 46#
-4
-4 ff fi
~ ~8 41J
? H

<# ~
-4
-4 ff fi
~ ~8A
? H

<# HKH
-4
-4 ff fi
~ ~8 ~j~
? H
~54
<# 464
-4
-4 fi "!$#
~ ~8A7J
? H%
7J
<# HKJ
-4
-4 fi "!$
~ ~8A;~
? 1H
7J
;~ H&
'( ' )fi*+
? H%
? H%

~ #%
~ 4
' )fi
? 8
? #
~8
# 4 4&
~ 4
~ 4 )fi,
~ ~8 ~
~8 ~
~A
# -4
#64
' )fi-,
~8 4 4
~8 ~54
~54
#1H ~%
JIH
#64
~ 4 )fi .
? /J
~8 4o~
#1J

4
'
)fi#,
? 1J
~8 #%
~
4
~ 4
)fi,
~ ~8 /~
~8 J
J4
/ 4
-4 40 ~ 4 )fi,
~8 54
#A7J 4
8 ~1J
ZM9<@3%-S1.BJ#SS%J1=SMS#S#8i6% 0LS1O%J fiG6SmS 0 ' c3#JMS%
SMSS#8M<SM%%8TS#718#=%O%SJw<## 8MSJ ''JS=6%
%9x#JSJOMSF17YRJ#q<##b%JxS<!%1S%S#SJ
S9k%{iEv%SS#SJMGSML# 0#G#MS%7#1b0SJ-SJ9%1h%5W%9
#JSJ=1.S%#J#Rk%S8%{%JS#<N%9#S#J=SJMMw%8S8QV#8<%OJ#

SJJ1S%-%M9lJ#SS%J1T#8%k%JS#wpK'TV%1%iJM9-SJ#GvJ%B 3ZSJ-T9#%
iM8%v%9S#<TSJMBO#JJJ1_bSJ1%S88vJS1E-M8%l% T%9LS
S#MS#%GMh%M%1%=9%S#9B#RS fi ZY'JV%1%
%#_JM9)
_#%S
SYS%ES%{JS%v%SS#J=%'S_M? S9%1%{%SJb7% S1.TJ#S%J1_JJ8)
Q#
J_76%1SL%KSF1E-J#S%J1=%Z%JJx<!%1S#%#S#J8
'JLJ#<M9Svl%
S%S,8? 77% # SMYuM?r#T9M9LS8MvL6S
p8%%JS#w<,
%8O c MJJpY%CB%?BS8%#JSJM
F{%{7YT%E7JM,8
77%<7J%9#SL
#%QS-M9J1-%3%_1Y##8{J#p8%kMl?M8%b%J *
SF#%b%Z%E$
Dfim K i8#JJ1
<S%%OSJM 7#G9%liMNv8 YM%YJp
J%# %S8J% 8 9 :B;.BJS%vOS'6#B#=..v%S#U 3 ! ! LUm SUm # h^K oL
JICKML i"K n Q 8 9 :B; !%132 !m 1D"%JS%9 Jw897S9#<vB1%S#M_BS
4 8 9 :(; 4 5S< 8T%S 8 9 :B;rSJ9%1%T79##8#h# SJ-%8SShSJ<%SSJ79SQSJM
S=1J1S# b# 8 9 :(;#iSw8.S7S89#MOSJlS9MG%9S#<%k#S9GM
J%G#S#M
S#MS#%'FS'{%kSBM?wY%1%.%JqS%9M9'S7=68 J9#79S%9M9
9MS.GFZJ%#%kq%98%qS9M-SJ0JJ1q%09S9%JS#<%Z#S#JBJJ1-S
JS%v%SS#N% 8 9 :(; uSJM-qJ-v1p9%S5Y %8?M%%5v8W%Sqw#%9%#L%JS<%3S
#TJ19E8S5 G9( .JES%L6p8J7#J% SJ

65 _n N 8l% 8 9 :(; hJ# G
%- 4 8 9M:(; 4 V{%iF.S9#7%Sh{J<%_M9?%1Sb9<T8MJSShShJ%S
SJMOJ%9mJw8J#w#iqVJJ1S_% 4 8 9 :B; 4 %9bSJ
J0v8i%9LJ##9S7% %9%##
%JS#w%S#SJ BS9#S9MK9%1%v8 Y{S#wMDW% 4 8 9 :(; 4 pMSO1JS#J8Sqk#
#R1S#J% TSqB.
WBW7

fi$4

DYJ b Dh[
K} ^ff bT

$,ffZ



1$[
EK E ,T E

STSO118JS7%kSM?<T99%O%JS#SJK#77%<JS%J1OJb8J_,i#MS08%*
%%?J%#1#SF1i7J#D%"p8%9M?b%#%%SJ<MSB9%S<wSJ1S%Y%J%p{%
S'J98p# JSSD#%9JS8Mv836%<%##% JSSD#%9JS8MvO#D
%8S1,.<%?M9
#wBJ#?7SB%8S#8S8JS.8%9J#JMBS#SJSB%81w#ESGS8JES% 9SS
%BG%SSR%{#S98J%JLS%h8M9SSSN%
S%1J1LSMSJSJ#9i#JJJ1N.L
.v%_%B<%%v8M%TVM ''88%8Z%# ""S%98JM%?
S8#JS%F%9% 8_S
SMSJSJ#bv8G8lMMJ JSO#%JJS8MvhWMS'%J
JS%Y Jw89 W% \6MSj8R%,=M%M=M% /? HJ S8%SSS# 78SpJ
u1J?J1LSMS#S#8%=<wSMS# %N7%Su6%JS9%#u%9W%?7Yw#%JJS8Mv
6MSS8D%S_#%MSJ %'Sl.9v8q%'%JS#<%G#JSJ8Z Sb?%J6%7 1
!K 2 -
S( .9S Rp8Mw%9S#<%D#JSJ
Q) R%JH L%J fi 8 8%9
S8NMS09%SSMS#MYS71#.UM%E'6MSSh%DS JSS-#%JJ8Mk%90S8W8-wSJ
7p#T% !-n n N1w<8 BL%88%1 %-SSMS#L1w7pO8% v J%ES$ J %
SbS8%SSS#
( Z*%ZSbJS%v%SS%iSb%S%MM#MY## #HM 1q%81JE 6%
Sl7J*QRT%'Sl7p#0l1JS#J8SG8S_9% S#79#w##MqS8%SS
%8iJJ#SMS06MSS.SJ?7SJMS
( 8MJSS<UMM9## 0J98DSB%SJ7JST%"0##M
VJJ1SJ%BS#MS9SJuv8 8 #%J9S8MvNWMSJSl%J SM 18j WJ9uSJM_S
%88%1l%KSMS#F1SB7p#G9%LN#,Bl#%JJ8Mk
6MSS'JN%'SF.9v8
%O%JS#w%{#S#Jw,i#MQ8q%*i%%?{SwY%SkJwS 8 ,p#%8d%S"DM%?%J
S7%8?M%wJ#S%910v8G8 %JJ p8%Z%JS#< *MW# 8F%,K%%hi%
JRM.
M7p8M%{hSff
( ?%#WS fi]A% fi] " 4hSJ%qS8v%S"DGl%JJS9%#
#.%SMQ7%S'SJ?R% 9SSJS%J1F1%SSMSH G%YF%9YnJJJ55%" .
%Jb#%JJS8MvB1%S#MS_%SQ,S%J8M%vxT7%SSJMGMhqJ_7%S-1<7J
#.%SM#l%v8MSJOM%JL8%#JSJMSl179S7SJ%N# 4hx_%JL%9S%#
8%R#G8fi ( U%#J8
-B#F6SMbb 46B 4D ,p#J%8{8%*pM%%E?'SJw79M<S9M
SMS#h17pY%<wSB7%bJ#S%J1Ov8 8b%Js8%J%JS#<F%97SBM
%JS#w%9#JS"B9#7G
% 7A8 9M:(;=<>9 :(;*p#S#J 98%.ST7%SB%88?M%J# ( M%#
% fi] "#/T%9_fi]A# 7W%' 7%JL _0%J fi. 8pSv1S%#%R 4-OSBl#_S=86GSh%
KS=MSJi%1S9% W%=B?%J fi. K#Z9#8%#BSJ#q-6%1%%Z8<V*%.=7%S
SJ%u8RS#7F%9R=SJ%uB ?8EF%iS<JS9#1 %#S#LW8s1p18JS#J%
8%wSN%98%uJ= v8SJ17118r6%1%b%T8%p 4h9JSJ%%DSGuS9M<S
78 9 :(;=<>9M:(;Y7pJ%81J.SGW%i7%vSBMM#M9#q#<SJh1S( .9S7q8M
!/1 2 Kjm n L
#JSJKFSSBS%7'9S%9#9S%J1{%JT9Sp#{%<19%JMS76%J= v8SJ1#TS
S#MS#%FJw8J#w%G FH JMS( Fr3
G%8S9J
FS1S%JMK Fr3
i%J fi
%lSQMM#%.b%=S 78 9 :(;=<>9M:(;-7%S%8M hS 46B 4DFOp%8Q*M%%p-5
CB%
v8JMhS9MF#JS%J1
hS #MS% 78 9 :(;=<>9M:(;KM<7%S<Jb8Jh9T F1q#9S#%Z#MS%
J#SS%J1 WS SJ$P %9S#<% XF#JSJ_%LS 19S%SN%S MS # BJ
P %JS#w% X5#S9G%.%h719JMS_% SJ=6%1%?8 iJ#J#FNSJ#G%98SMMS"pG
p8 7N8 9 :B;C<D9 :(;5%hw1J1S80<%SSF% 4 8 9 :B; 4 V9v8 Y8%#wv8%JS 78 9 :(;=<>9 :B;3S#qJS%8J
%81J.S-W% 2 Kn QRSJ0S 8% 8 9M:(; %JNSJJ#?9S_%D%JS<%5#JSJOB#SJ# 8 9 :(;
W%

fi91#
gfiffgg

10000

1e+07

1000

1e+06
Search cost

1e+08

Search cost

100000

100

100000

10

10000

1

1000
0

5

10

15

20

25

30

35

Mean distance nearest optimal solution

40

45

50

55

60

65

70

75

80

85

90

95

Mean distance nearest optimal solution

KS<@3
p8M8,9%SG% 7N8 9 :(;=<>9 :(;Y%8SJ {W%Ow_V8W J{%JQ8DN8L6. 9
%J fi SJ%HJMS J'##OMSv8#<kS"
R#Jwkq%SSJ7SJMh?%J #8%3%JS#<bMSS89S.SMS%%{SJh# 8 9 :(;
BJL#'ESJ#S%
SJS YM9-%LS#\7%M?R8JSl%Y8S%R9J8 p .
SJv%S<%0_8 1J18?J# SQ%8rSQ% 4 8 9 :B; 4 -#r9S%9 Jw89%OG
%98%-S9MOS
%S8'SMS#
1'7p#% T1JS8Sb.bMSN%JlJ#i1##M
*M%MGM% /7MSbY% %JJS8Mvw6MSSL6Sl9%.vlS 8%S_J0v80%'%9S#<%
#JSJ8{%7SJN%8M%QJ#S%J1Lv8 8u#8%i%JS<ESJML
J%ES#W#S87SNS 8L%
8 9 :(;u%-SJTJ0v8 ?UJ#?9Sl%%JS#<%K#JSJ8Y9
%
k%S5-%S8=%?J8vS
JJJ8p#0<%SSOV%#v_8MJSS=% SGw%8LJ#79SJ% 4 8 9M:(; 4 W
-9#i#SK19%JM%SFvG8GiJS8pJS#F#.S Jq8%8%JU Y8J8 %YSJ 7A8 9M:(;=<>9 :(;
1<O6MSH8F%* M% /?<K?85S<7pK#=%SF%88M<6%=S<7F9w8J
JS%Yx#JSS%J1BhSJ#LL
8%5B1J"YS0<36%#Ol%81JE-6%-bp
p#%KJ%k%Sr _@r /F%iS<MM#M9#Q#JS%Y Jb8JW%Tl%JJ fi. 8
'J#"p7J"%88%1LV%##i<%9W8Bw7%SF?J1SSLG%S &J fi. 8

fi: #1]s+=1r'!

=v8SJ1w SR%88%1 %
78 9 :(;=<>9 :(;B<i %JrqH%J fiw%#
%#SR1J18JbS8M9#S8%M9## H #MS%8i<%SRS%#S#8%## S$8uJS%Y #JSS%J18
<9#8%%EGJ%F%98S%RSJMOS<%N.9v8O%Z%JS#<%"SJO#l?%J fi.
%SBOM9J7BSl#91S%O#_JS%Y 8%D L19_B#SbSJFJw8J#<% FH .9MS(I
#JSS%J1DBS 8p.SJOSSJS=1{%"179S=v%S 78 9 :(;=<>9 :B;%9
JS8pJ
S?#1FK%J%pS#5-F -%J0FOO%9 fi 8 -B8%8BSFJ88K<#1S%9S1%8
GMS\M9=b%SSBSF%88%1L%ZS 7A8 9 :B;C<D9 :(;51h<vR#MS%8'%9 fi. 8
179 7A8 9 :(;=<>9 :B;'W%bSQ%%-J8% 8q 8?%J fi wBS Mw###
%JS#w%"#S98pSF179SMS#N#OJ9%1S#8%kW%BS=S<%#9# "7#JS%918YS<M

Z***+ ,Aj ;J 2EOU,?9'+U,'K*,ff?{O,GS,i?VDOK
$%'&(iU,',=ff?,Z,',*?- 2.?KO?,G,*FO 2E,D?**O,oE
Z;v< :- 2.,V*,A ,AjU
oB,U
ff 8 9 :(; fi *U *U?KV,AhG 8*?,{-?*U* 8 8"V OA




W%

fi$4

$,ffZ

% 78 9 :(;=<>9M:(;hMS9% %% %J p8%'%JS#wp QSJ S8M8,Y%b% 7A8 9M:(;=<>9 :(;
% 8S9 =W%qS_JS%9# #JS%910#Sw?EqS#w%'Z#SM' ( M%#w%'S
1%SSSk9J#F8%SSSl7pY#ifi] EBJ#?wS89S.SG /#/Vm1S%S
b7pk%88%1
S#MS#%-TSF\bqJ%9m88{'J#SS9GJ7JMiSJ-V%##JSB% 78 9 :(;=<>9 :(;"7p
FS8%iF#M%8 fi O%9S8S%'S#<#M %9K#0%88J%106%{SMS#O1S{7J#3Y%T
S'J0k8D%k%JS#w%#S98MSO9%Sv'S 8%.%J7S'7%wJ#S%J1iv8G8<?%J
p8%"%JS#wR6MS"5M% /?b-W%SJJM%JG08%9%h8SES#_%SSSB#M%8BS1S%9#M
#JSS%J1'J=wS=U%SB.9v8FV*%9J'%Z9##J?D%Z%9S#<%"#JSJ8





K} p3 % $[ L [b RNRM G b# dDY
'
U98#J8%5S 78 9 :(;=<>9 :(;v1O7pYJJ#8M-SJMGS8F 78 9 :(;=<>9 :(;v#G%O%b.SS#
%88Mb7%SS7% 4 8 9 :(; 4 Z%b*-=%9 G%#Q..v%S#
#=#J1%S183*% 4 8 9 :B; 4
#q%T1798H#JJ#8MS#%<%'JS%Y 9w8J %RLm6p8J
JS0%89MS%%
4
4
BS SJ7%%D%GJ8%%9#LL7%<%88Mb<%SS7% 8 9 :(; S9% 78 9 :(;=<>9 :B;VTJ%%
%JJj#8%.%JS#<p%GO#J%T1J#8ZSO8K%Y#JSJ # *I 1 M?"
8W8'wSFSS9S#71B<"%h $1 "! ;@I fiML 1Sh7p*{'J F .J%!pJ%<#U
7pJ J88%WS Sh6%1GSJM%#S_%%%SJ pJ%<#8{MhSM%l#.0%81J.8%
1p9##8O7pv%ZJp,S7
k9p%B#O%h1JJ15
q8%%N .J%!pJ%<#
1B<v% 7_%J%# #J7SFJ#S%91Ov8G8
#JSJDp#SwJ#J
SMl%JwSB1%SSSk9J#FM%JS<%9SJ8 c58 7 9 :B; fiM
%wS<J#S%917k8 8HN#JS <%JS<MS%JS#<%DS"3,% 7 9M:(; fiUff[
L
ST MB8S b%qSL8T%B%9S#<%G#S98#c58+
- ; + ! _%lSl8
%SJB#N
bJ?#<%Q19R?JN b%R9S%9 #JS%J1%v%JQ8
- . 8 9 :(;3%q<8'%K%9xp8%5%JS<p0SNU 9J 7A; + ! <D9 :(; 7A8 9 :(;=<>9M:(;Wi%'S07%
J#SS%J12 7 9 :B; fiMGv8G8RS#SJ*
+
- ; + ! 7fi
- . 8 9 :(;6G%JLSJMSO%9S#<%5S"
KbNSJB798%DJ##9SJ-% 7 9 :(; fiU
W%qS&- . 8 9 :(;%9 +
- ; + ! T%i 8@
8 %JJ fi !
G%S .vq%h9#YSMSL%J8%#S<<8#_%Ju
%JSS%p#%%
%SJ<GB#6S( ES#%98%h%8Gb9#YSJ v%S<BSw%J7BSJ{p8,S9%p

%JS#%lS%##. h8p#MS9OW Sq
%JS#%L#%"MF7%S=JS8M%.'#lSFSw%#8'
%JT 'OJS%Y 8S8K%#E%ZZJS%J18 7N; + ! <>9 :(;+% 7N8 9M:(;=<>9 :(;*%*% B1JS#SES
p#SS'S#SJ'SJM'Q%8M%7MS8#8h_%N%JS<%5#JSLSJ%R%J<#b%8?M
p8%%9S#<pp#<#MF%98SMMSJT6%TS#S $1 n SM{S9 SJMT#S90# +
- ;+ !
1JSES#bvS'G8B<M%S9%J'S9%N#S#JO# - . 8 9 :(;*
'JJ#%%?%<BSJB#NKSq<8S%q%B##JMS#%=1p%7Y'%KG_kh%DM?
9#%1J9<.
p{K8pM?l#79#%SwGMlSJSJMGM-% F%8S
M%( I=J#SS%J1v8 8TSiMSSZ%9S#<%#Sq%JT#JSJ5S9MKMiwUp#w%#=J#S%.
6S SbMS0%JS#<%{S#S"L1J"Z%JJ p8%{%JS#wNMS JKCnF1SSM?#QS8
S.SMS%l%OS_80%'S#SJSJJ#NM?"{1.%J#1SRS_%SSJ<JSG
SM79S8#JSF#wp1SJ
4hSJTMb#
!O#MS%0S#1T
8 9 :B;ES8S
v%ES%#F1#D#MS%Ov%SS#JZ% 8 9 :(; yxFW%S%JKG'8SS.Sq=%D69#FJJJ8S%J x
SJM #iJJ%<p#S8DJ%#S
<%81J.'6%'SFJJ19#%S_S8JiB#YJ1SSM##
p#198SMMS%lS#<MT% 4 8 9 :B; 4 Q_%Y8S%lSJMqSlSSJ#S %T1E%9#1
G%JsG%#<Ev%SS#8.MS8G-S#J%S8SJM 0#k8W%w#F0%JsG%
%8
Tv%ES%#_S#1RS8O% 8 9 :(;





ff fi








W% W







fi91#
gfiffgg

3000

4500
Random Local Optima
Solutions Visited Search

Random Local Optima
Solutions Visited Search
4000

2500
3500

3000
Frequency

Frequency

2000

1500

1000

2500

2000

1500

1000
500
500

0

0
0

20

40

60

80

100

120

140

0

Distance nearest optimal solution

20

40

60

80

100

120

Distance nearest optimal solution

KS 3-h#S%%%<G%3S
J#SS%J1hTS
MSSG%9S#<%k#Sb6%Gv%Sb%J p8%
%JS#<
%J7SJZp#ST)
W%D 1p%7YF8t78
%J fiO6%
JSF1%SvJJiw<9J$ h9S%9d#9S%J1?
Gv#8%S9M3SGU 98J8#5%JS 78 9 :(;=<>9 :B;.7pEMSGJG#F#MS%G9MS BSGV%##SD%
S-JJ8##J
<%SSh0%88M#w89#1ShSJ9%1h%5#S9#%#0qv'1Y%S
F1E%S85S 7; + ! <>9 :(;K7%SSTU YJSQ%81J.S=W%=SJ<8
%GSJ
#%# vQSu p GJS( ..S%'GEv%SS 8QSJML
.J%!pJ%<#1
7pp9%<TS 7; + ! <>9 :(;7%S'SJ#qp#7S#J 98%.D#7JS%7.S{#T%88%17%8
4h8#JJ1<6%SJ#Ev%SS#8 b%98S%bSJM0%#S
SwSSMS# 7N8 9M:(;=<>9 :(;1q7p*+
J#1S89%J8qv8G8 SNJ9JSJ=% 7 9 :B; fiMW%7?%J p8%i%JS#< %J SJ
p#S0.)
G8SO<#J#w%E#0{v =9S%9j8S8EJ 98%. 9= k8J1Z8Si%9S8S%
#Sb#M%8T@%J 8y 8QJS%9 8S xQSlS%7l#JS%91F6%0B9#S 7A8 9M:(;=<>9 :(;
7pZ#h#%-%88JM%F3lVSS8
##JMFSJq<M9SJ0%{S7J= v8SJ18kG0%9S8S%
SJMGW%GS EF%3-8L8q%JJ fi BSHj8%p%%T%JS#w%YSJ8 7; + ! <D9 :(;Y#
%8?M% /C#B V G8BS9% 78 9 :(;=<>9 :B;VG%BSJS%7JS%J189S#JSJO# +
- ; + ! =N%8M%
vSSB7<M%9%H( /Vd8hSJ%LS%ZSJO# - . 8 9 :(;*
F .J%.S67S=%88%1b%3S 7; + ! <D9 :(; J%S9%<#'1'<YLD J w
%JL8NT8
%J fi 8Z%%.0#%7#JS%J1%EO1J?J1/+
- ; + ! iJS#J-SJ
b%8wMM#MYqJ0v8h%J8vJ.'#%8G 4#%Z#
#JSMN6S b?%J
p8%J%JS0J %Jb8<#JMwJ1
F%9%T%JS#<%Y#Sb##8M"{B'8<JMS
18?w##7v7v8%JSBS8Sh1p%Y%#T%JS#<%Y#S#JD6SshJ#w07%OMS
vSSYJJJ8 <7%O%v8M%B BB#J pqSJ#,p%%?O8<#JMGSi.SS
JSp1S8J8#JJOSO8SS.K#%*MJ1 4 +
- ; + ! 4 [78%p%%p'GSS9S#+
- ; + ! MGSJ7J
01<9 7N; + ! <>9 :B;6SB#M%B.9v8{%"S%7Y{#D( .J#S70%?J8%hS%JM9#q%88?M
S#wM'%KSJ#OSMSS#M
p8M8S,9%SO% 7A; + ! <D9 :(;Y%8?SJ W%OSJ= <%JL L0JS%Y 8SOMS=Sv1S%#
SB Sb9k8F#8W%9Jv8=#E#=%OKS
/
'B8%SSSH7p#=% 7N; + ! <>9 :(;
(
%8S9!K 2 - SG##LSv1S% U%#J'%{fi] ""l%JRfi] @B ""1%SSSk9J#T
Vd%JQMT V
#J1%F# %88%1 SMS%7NS 7A8 9 :B;C<D9 :(;{17p*T'7%1SJ% h9#8%##8p#M
6S SJSJ1 Tu<%SRSJ% V%1%l%G J%%9uGR%98%R688l%J





















W% %

fi$4

$,ffZ

10000

10000

1000

1000
Search cost

100000

Search cost

100000

100

100

10

10

1

1
0

5

10

15

20

25

4

6

8

Mean distance nearest optimal solution

10

12

14

16

18

20

22

24

Mean distance nearest optimal solution

1e+07

LA19
ABZ5
LA18

Search cost

1e+06

ABZ6

100000

10000

LA20

1000
25



30

35

40
45
50
Mean distance nearest optimal solution

55

60

65

KS/
3 p8M8,9%SB% 7A; + ! <>9 :B;v%8?SJOM?R1 W%h RVJJv8'8W JJS?Y R
VJv8=.G JS?Z%Ju8 8HV8 JSh?%J fi8 Sw%SH.9MS
J'##OMSv8#<kS"
1pS7hMS%1,SS#9J%#JS%91DSJ%<J98{S 7A8 9M:(;=<>9 :(;97p56J#qSJS8'{%"%%qJMS
v#.SOJ=v8O.L7%S=S9%N7V%1%B%O8p
%-SS8B% EN8"H87%JJ fi. OB#S#s8%p%%_%JS#<%3#S98 5 <S8%SS
7p
% 7; + ! <>9M:(;-%8?SJ !K 2 - S_##Jl% ( M%#%Tfi]A% V8SG8Nv%SS %
KS!
/?FS 179SMS# % 7; + ! <>9M:(;-#_J9%1S#8%'6%lSQS<%#J#JSS%J18 '
SS9S# ( # JB Vn%SM8OSJ%bSJM%9S8S%_W%S 7A8 9M:(;=<>9 :(;Y<9wSJ-S%<h#JSS%J18
JS8'S %1SJ%ff w#w .Y#8%# B#SJ#uH6%1%L% %FSJJJ#1 <%J #
8%q#OS9#S1S89%91_#M%8BSJ%Nw6%1%-%O8pqJ%T%#b%J%SMSS8M8,Y%
SB_#wSJ-8iv%SSb%3K /BS_JMS0W%iS J%
%5S
8%8R80?%J
fi. 0JS.qS 0 '`c JMS B#S 8%fiTS%%%JS<%S#SJQ'J
M}Q%J
ff

JCBZK*,o7,,,j78 fiM?K?0,
-Aj7AV,+,oT% v qVq MM,?U +UV U< 8
,U{UVG- 40 q< 4B+VjUU?KU,' ',0 OOAoF,'?p*?A,oU Z;v :1- 2%+UV U 5,
- 4 4'2 464 4B?,'?*?A,oU ,{? UhO?,{OU- 2_5,=GO &J ;2 8- 4'2 :1,*UD< #'2 ~1Hff?
+UV UG5,
O,Z,M 0- 4 4'2 464 4B?,'?*?A,oU





W%5

fi91#
gfiffgg

#JSS%J1iJ%=v8bWJ9w7vBSJ
<OJw8J##bSJ#i8F fi%#l N88?%"5%%?JBJ
#O1J#.'BSlS%98S%LM%#'% 7A; + ! <>9 :B;6
w1J8JS" #{J#JTJJ#%#q#{#MS%hS8J%"ShM?_9%1B6%i<%E
JS%Y #JS%918 4hFL19( .JJ1%Z<%SS=% 4 8 9 :(; 4 9%YSN?%J p8%
%JS#w0MSF%7Tv
198SMMS%=%Jl#J%88M%9Sp#J#J0q9MSS#%Y1p9#%JMS_6%OS
V%##Sv%pS 78 9 :(;=<>9 :(;E<,51E%S8%S 7; + ! <>9 :(;7%SJS{
JU 9JS
%81J.S W% SJ#
9J7"p#9#=7%B%88M
7%SB% 4 8 9 :(; 4 %J<07%Sh%88JM-1S7p*
-hG8%8EYSiS9 98%.3#7J%7.SK#%88?%1%S 7N8 9 :(;=<>9 :(;%J 7A; + ! <>9 :B;.hJMS
GLVJJJ%7.S%ZU 98J8#U 3B%88%1QS## V%##hl8%0NMS%8
JS%9 #JSS%J18"%J
S=7p#JS#Jh7J1G#9S.#.0SJ-#MSJS9wv8G8lS=JJJ8p#F7%SJS
%JN%#%%SJ<h?Jp,S#7=pJ%<88









} G b# dDY
' 7A8 9M:(;=<>9 :(;3%J 7N; + ! <>9M:(;v1Sh7p#iJp#=Sw8#JJ1=SJM<#iv1S%Lv8
6%<#hB%9\i%F%8DBv%.S#%#=SS#1qS98 %JS 8 9 :(; NSJ9%1%R-B8%8
GFJ%=%8O7J%kS-%._Sk8$ 9hJ8S%##8%JSF8i%ZSMB#_S=7pk%OSGJ%#!
SMS%B9MSS'%kSO%JSTJS%YM9##S#83''JJ%w#Gk9p%D%"%E)L -L"K ! !-p8%
M?R%%%?SJL%k8MR#8%5SM pc5S91YRMS#"Ysp %9M% /B%JNS#qp
#Mb%J%##J7VS9M#Y
#M8p D8J*v# "#/?8%"pM%G#TJ#989%Mv'7p
JSRM% ?J%#J( 3RSQ8b%
6%S9#R#S#J<#wB"iS%JSS# JS%9MY##S
v8G8r#Ev%#JQSJ78% vN17Y"i%J SRMS% 9S%v8S #TJSS8S%"
c5p8%vM?_%#%%SJ<G%7.lBSb77%S%p%SM9lM?"8%l%#qvh7p_%
MS%?J%#JF.QvJ9#lSw1.ESq%O77% ENSJwSMbJU 9JS55SJSJM
S<MS%QJS%v8S R#-JS8%"2 4h#S1p%18 S0SJS#Jb7p#h%8%##NS( JS
MF%wVJ8k9J#_ S<179#1p %S<77%-%1pv.S#%K.J0v8=%GSSMx
* 6 {#<S fi.Ax<%J<S88W%ShJS#Jh#S#'#JS.#.SJJ%#SMS%-JMSSh%"S
M? 9%<#88BB0?J%#%T#h_J8%%QM%%8Mw7p#BRB9##MS%T.J0v8'%
SM-MS=%SvNE<78SUSSM8Yp#9#T7%S=%1SM9#%JN1JS( ..SlJJ8?S%Jp
M9MS%NJ%#98



fi:
r^
<7JvSF#79%1O%KS%,8x77%blS=vJ#%O% pGGJ'%J%# 8F
M?LJS%%SOSJ8OiML%BG_6SdSJ
JMS'%JS<%v#S5ZLKS G
SjbS#71S8h%DSq9#S%J10bSTMSSh%JS<%3SN6%-k%SQb%J G%
JJJ8{S l7%h%v8M%i%J
F_F .Y#8%38ffl8%9 fi ZEB%9S%#b#<##M
SS9SDwS%79#=%v%Js' 0%Jb'q2 fi E#<%J9ST00.9v8{%"91SS
JS%Yd#JS%918'J=%Jdi%l1J9SOw#J#<%vSJ%S,8xJJ#TvJ%BS
M?7#JNi W %88=N%%9S#<%K#S#hSQSJ( .9%KJS%9M9#%
L1E%S89GF%98S%0S7S89#MSi#lSJFvJp%O%! {B=S#718?'SB
#QST.
S#q%K
N<JM
SJM #
M9qN<%#.S%# M? %%J.S
6%1pJ_v8pJD%5S7%D'J#%98SMMS_%J0S-6#h#..v%S#U 3ZS-%S
8 77%S<J%JS % R%1Sq19S#.S9#%0M?SJ8iM %Ti
6SdSFM'%JS#w%5#S#"


W%

C

fi$,ffZ

80

80

70

70
Distance nearest optimal solution

Distance nearest optimal solution

$4

60

50

40

30

60

50

40

30

2000

2050

2100

2150

2200

2250
Iteration #

2300

2350

2400

2450

2500

2000

2050

2100

2150

2200

2250
Iteration #

2300

2350

2400

2450

2500

KS 3h'#718?=%iSwJS%J1<SwMSS%JS#w%{#S#W%q#S#J

.<0%J i%RV86,JJSD%J _6#E JSDW%i_8DN8?%J fi.Z



# lRMS%u7pO% %w
9%BS8JS.S#7v%SOS8h%D#S9OJ#S%J1 6SxS0MS'%9S#<%5S
%J *FSJb8SEqMH%%J#E 3Nl%_SbJ78?#7M%#
P MTSfiToXOBS
S7pv#

5%J
vSv1S%#%=Qv1857MS77p#wS7#<9%1h%
i%ruSJ#wEv%SS#8U9NSSM





? 38
8ff fiU
S%,8 77%SR%
lS#<9S8%M
%9R0vJJ#wSJ#-S8%#M=#.bS7SM7UYJS"
h18vGqJ%ST<U#09xvSSYFJ#S%916S %QMS9#MSL#S#N_S0M
%JS#w%ZS#S.
+ FK#J%%"8hSJT19JSJ% JS%YM9## y=w ff* 4 BJ%7S
JS%YM9## %-S#qJS%89S %8#QSlM?H%?%J.06S %J 7#JR6S
Q#SJ#S%J1
WS S_MSq%JS#<%#S# R#JSJS%J1 Q6S
MSSF%JS#<%#S5<'<<
% Q%iSS<JS%9MY##S-( J%{pKv8 98%##NW%q%E
9%0%'SM ff* %9 LBJ8S 4 4 b%0BJS#qJS%J8J?J%%T#v%SHS
%%J#E%97Sh9#S%J1O0SBMSS%JS#w%J#S#7MSh%8%#07vSS9#%U%6S
SM 8 9I$fi# . 7SM 2 8 9I$fi# . D%O%?)S"$
+ .SJ8Sh1#iMi7GSB6#B#
J#J
JpM 88S<%9SSlJ%9M9###SU 3
=b 4 2 8 9I$fi# . 4 8 9I$fi# . ?=w # + 8 4 8 9$ # . ?9%Jy=b 2 +-. ;K# . 4 8 9I$fi# .
=b 4 2 8 9I$fi# . 4 # + 8?=w # + 8 4 # + 8A?9%J@=b 2 +-. ;K# . 4 # + 8
=b 4 2 8 9I$fi# . 4 +-. ;K# . ?J=w # + 8 4 +-. ;K# . ?9%J@=w 2 +-. ;K# . 4 +-. ;K# .
'iJ%9M9###SS=w * 4 E MS'%#S

1Z=SJOW##B#Jh%S%!,9S%9M9#19%#.SU 3
=b 4 2 8 9I$fi# . 4 8 9I$fi# . s&=w # + 8 4 8 9$ # . s=w 2 +-. ;K# . 4 8 9I$fi# . v[
=b 4 2 8 9I$fi# . 4 # + 8s=b # + 8 4 # + 8s=b 2 +-. ;K# . 4 # + 8v[
=b 4 2 8 9I$fi# . 4 +-. ;K# . Gs$=w # + 8 4 +-. ;K# . s=w 2 +-. ;K# . 4 +-. ;K# . Y[


































W% L

fi91#
gfiffgg

<1798=SJRMS%L7JY%!pF1SM0TSU&J1S#T9M8OM [
+ %J
%<M9S%S9#
SM-Mv [
0v1S%07vS#-S'1J?%#ES=w - 8 9I$fi# . 4 - 8 9I$fi# . Y[
%Jq=w 4 2 8 9$ # . 4 +-. ;K# . s=w # + 8 4 +B. ; # . [nMO'F1JS%#.SBp#
SS8b##M SSMU 3 -# + 8ff - +B. ; # . K%J 89I$fi# . LGJ( .SSJbRM%7p
1JSSO%Z1p%1S5
/)0
+ SM8
<1J8JJ%S#_SJM=%QM%%8M%JJ i%< %
6%F%E%S8
p8%OM?r%%%#SJbB## JKn78M9SSLSLVJ#G8S%#O%-SNJ98p#QMuJSp1S8
9MSS#89#M"S79MSS#J9J1 . M%%S8MS#JP
fi. \#JSJ
9%SFJS%J1
_S0MB%JS<%3SR'% 1fiLUm +2 RV=7.RmpJ#*5%ME?5J#SS#J1BSJ
MB#JES#8%"9#S%J1OwSMSS'%JS#<%"S#SLJ%0J k8S.i%JS#SlJS%9MY##S
6%B7p#b88'_%JLVMSS8'6SdS0MS'%9S#<%"#JS"JJ=wk%SHOJJ> .
Jv8B%J9#YSJG%{#6%SY=.k%?B%J *'J9$ .JFJ##9SJG%{#Ev%
<M%Y%J80B.J"S .SSQ<MSTvS#J_#-BJ8S8=S8ST1#=Sw8#E
S8JMS
#LSJF%JS#SLJS%YM9##S#6%hS#SJihSJ#Lw%N9MSSNS9NS9MBB#'kS9
w8S_M9JS#<MS=vJp%'%ZSFVJ#"MS%N?J%#NJ#7TSJJ1,%8B?J%#"






$fiff

gb ff






S#<M
S=MS%l7p9YM%788
+ %JbS
8i%S=w *ff 4 .<%79##J0
SY8O%D#S9i#L J%h7%RJS%9#d#JS%J1%9F%9S%#NMh#% ,,
%JM07 + !on fi5n=SJ
M%?JS%J1B6S SJwMS%JS#<%DS"
%Juy JS%9 8SGN8 , [
B8L n 7A8 9 :(;=<>9 :B;? %<SNH

%J + [ # Mp{6%FSQ8@ 888Kb8 ,, [ MR%9 + [ M%pNB7M%#F%
,, %J + MSF#MS%=JL7JSJS=SJM'MSS Y8#%#w#MLSMhMS%O%8?M
JbQ% #9Sw8.J0k80%BS%7Y8NJJp#J9%K#%#%
MS_18J JES
%9% %JS#<%G#S##08M5{MqhJ#v#EqJ8 %#q#JSM"N'bJSp1S
S8vMS{J.S#M#% ,, S%79#DMS'%JS%#J7W%%w9#S%J1956SSJ'MS{%9S#<%
#JS"9"7N n 7A8 9M:(;=<>9 :(;W?YMhBJ#?Lv#.OS8SEB%#%%SJ<
#%5#B#<7JM
8<JM"
'JRJv8<vJJ + #b#7v <SMS79%1<%FSJ7S9MbMSQSU
S#S8%#JJ% k_p#SH. J?#%. JI *I 1 B?#%*D9TMSl8S#S
J1J.8SlB#S_Jp8##9'J%9M9###TB_1p8S#TS=#MS%=J0k8G%3?#%#SJM
MSbS( .9S %?J8%_SwS%<9##l8w#JMS1?8"bJW%w%#% + %#B9=
JSJSTSJMFJJRS8JS.SMS%wS#SJ
MS<J8#J #QS<%79788bi%9J#JM
#JSJKMSOJq1JS#J8SqW%J8#JS#F8%8Sl8%F8MS#JKW%S'S<%##8DN =%J<NF
JS%Y 8S8{%98%8SHM%Q8MS#JF6%0SJb#MS%8l8@ 8JS%9 88QpJ?v8#J
S%7Y##hJSSKS9MDSO1#1<S%<9KMS'JJ1%S#M"SJiSk8$ 9iS%79#h#.8SM%#
MS09%NS#wMh%DSJ0#%J9S8Mv1%SS#MS#R%S *RM6#Q8h%,Z%%?"*%kS
1pk1_Jv8{%"8?MSJ{%"%JsG%7M68B9#<S#S 9SS{JJ1%S#M"
i%J9#JMSJ MSG%81897#F%J8 %9M9kM?%J1%%*%%S 9 , J#SS#J13SJ
J1J.8S M=w#%JS%J1 iMq%ip-S8S%#5k%JQMSTJ#S8M?NJ1qST.9v8
%9%h%79
M=J#S%91\i118J
+ FJ%=%S%<9Q#SQM=J#S%91\i6S
S=MSSG%9S#<%v#S#_%9_SMl%%9E G=%bS=JS%J19<%J_%%J#E
6%'SSL#lSF9( .'8MS"
=vU !,o fi0 17kA3 Mh fi 17 4 625 -,?Uv,G,vUS,V38,?



W%





fi$4



$,ffZ



c38L Ei%JN ff* 4 %Gv1S%l%SJ=%S% J0k8O%K%9S8S%RS%<9
# SM %J S%S%FJ0k8l%0%98S% %9SSJ_6S SM Hu SM
ff* HS#<M0%'Sb%JSS#JS%YM9##S#-M_17YH9S#NSJw%96%qJ#%8
%9=w 4 2 8 9I$fi# . 4 8 9I$fi# . e[L 4 2 8 9I$fi# . 4 8 9I$fi# . ;rL 8 9I$fi# . ?uR6S( ES#%98%RM
% , S%79#DW%GJ#S%91v n 78 9 :(;=<>9M:(;W?{3FSS#<M
+ EG JS88<OS
<#9#<%-dSJ?qSJM SJJv8Z%JS%79# MKJ#S%91 -x# SJ% , M,%USJGSw%#
J#SS%J1wMFB9#%79FMw%1J#.S %98S%"bwSHU 9

+ [ -
<#S%'SM NhS# - J%q8#Y7#79%10H7p{%88J%1%K#J%%3G
%98%'SJMJ{S#<M%vk%S<S'=w ff* 4 EK%J
+ MSBMS%7#J9SS%Gv%S
ST#JS%3#JSR%JQST( J1T%SJhSR9#wSTUM#JB?#%#8v*%vS
SMS#SS#8'MJvM'<vF#S%S%9#M
'JRMW%7ES#r9S1w#wJ##N SJM_S17Yu9M?%788bSS#<MlMS
9%lLS#SJi%1SJ%wp#S_ D%#%p9M%<88'S#<MB1J#_v
J8%
#JJ8k9ES#q%3S=%%%SJ J98G19S#8MS#".6%i1p%<9-#q%L%J%pS#%3?%J
p8%k%JS#<p. -hG8%89 7V%1%'199S-TJS8%.'SJ?L%LMJJS%?L#_S2 fi. ZpZ#8
%7SB # 1Su{%9 8%G%JS<M_ .Y#8%#%TS89S.SMS%L%hSJ
p#SH. QJRM?"%J G_8JSS.S %T6JQ9J8S%9S_S%q8%9
%DSJ#B9<HV%SJR9S##<JMSw8p#910#J9#8MBh#BJJ0##MS%YMSB_S
J#S9S#H%=#JW%S#9L#S#J7BS9# SN6%S9#R9%1?\1J5i#w#<J98Mb
_S%##S8%#lS%790ST1E.S
%{S%S,8? <7%S%
iJ( ES#%YGqMq8SES#
6%1r J>
%8M%Bp#H REiM?M#%N9S18'8JS.SMS% 8b%
S%7Y8'JS8kq%0S9MhS0%W 88?<#J#SS#
vJp%B% VJ#S1J.S#wS
#wSh8%-%3qJSYi( .J%T%.pbJp,SM9_7%i%Jb%Jw MS<%"SJhSM9w.JS
%8%NJS8%.S
JS1
9M%18 MS%{SyI !on 62$1fin K H%{%JS#SR9S%9M9#SO6%
%. ! S%7Y%-%LlkS9W%N#8%=M? %%%?SJ<_BS %8RpJ%SS#
17v.8J%Y#8MNp8%5M?N%hR8S%v##BS%79#l6MSS"vM% /?
rK iQS SRSS#<Mu9S%9M9#Sq%F7p#H88w V86L
Jq%
VMSS8
W 6#E JS'STMS
%JS<% S#SW%=b9#8%i8)8_%J fi '
SiJS%YM9## =%Y<%ES%#9#h% 8? SMT%%9ED#K89
%ufi]#?#J8vJ.3%
Si8SS.KJ#S%J1
SGJMSK%JS#<%#JS"5O%9S8S% J%##SMS%FS#w##M5SJS
6%i%9%5JO JDb%JQ8 N8q%9 fi. 8.%SJ_
%
SJMiSSJ#S6%O7
#JSS%J1Z%8%#kSK7%Si#=V*%E<%#!S8%#S8J#MS#?kSJ%TSSG%Y8S%T#
KS '=SS9SO#JJ8M-S9M'SFJ%9M9###<%K1ES.J7w7%088B66MS8
6SbGSqMSh%JS#<%3#SR#O9#8%b9S%v%SSJ%{V#.%8#_9S%v%SSJ%WbS
8SE<JS%J1L6S SNM<%JS#qJL 4- 118JS p88<B 8%9
%%J#EO# ? B8S
S=9S%9M9#7%Z1ES#J#Jq<<%8S8Ow%l%JS#<%vS
%1SJ%##7#G%N pD=8SES<9%=q19%JMSbW%iSJ#9J7"%S_
MJvMOwk=JJF#l9MSObSF88vS1.BY#%O1J9_
'JJ%9M9###ST%07H8S8_ ?VMSS8L6S MSl%JS<%hS#S MS%
#%8%*"JNp<78?#0MJJ
+ rM3JQSJM=M?# #h9#%SGM?
#JSJZSJM{MSO%7%8?M%hJ#SS%J1iWS SJiJMSD%JS#w%S#S"K'J ?JM%18#SS#
JST%H1p9#%9MS W%7SR
%9SS#%p%bJ9JSJ=% 7 9 :(; %98% W%<SJ
p#Su9#M?"O%'%_SBr# KJS 'R79%1<%=S%,8 <7%S #
%# 8p#.8
%LSJS%YM9## %qw%#ES%J# S8SELM? %%9EL#L9 %J
1JSES#1p18JTfi] #%{%OSbJS%9 #JS%91Gw1%<#5ZhSS_1p189S









W%



fi91#
gfiffgg

1

1
Probability moving closer given grad=closer
Probability moving closer given grad=equal
Probability moving closer given grad=farther

Probability moving farther given grad=closer
Probability moving farther given grad=equal
Probability moving farther given grad=farther

0.6

0.6
Probability

0.8

Probability

0.8

0.4

0.4

0.2

0.2

0

0
0

20

40
60
80
Distance nearest optimal solution

100

120

0

20

40
60
80
Distance nearest optimal solution

100

120

KS 3h'G%JSS#J%9M9###S"6%K<p#=88K<V86 9S5%D6MSSJ8Z6Sd6.
JS3S'MD%JS#<%S#STJJJ8!
6%
9#8%"8t78
%JJ fi.Z
%'p88%SJ%i98OS%90G8TSJ% fi] Mq1pS<%O9#S%J1 S{*% %

+ 7'J7JS%9M9#L%i#.%8SS#lS<8JSS.=%%J.F#=%#LLVJJ1S#%GS<JS%J1
SNJMS<%JS<%O#S# %J SN8%8N%-?J%%%rJ%w1%79%GSLJS%YM9##
%iBS?J#l%%J#ES
6S 8? #=J#8=SJ% S7J%9M9###N%iBS?J#_6S
8 fiU G9S#.OBS_SFSJSGJSSENMv%#R1SNZGSFJ#SS%J1D
M-BJ#?H=w 4 2 8 9$ # . 4 8 9I$fi# . N[ =b 2 +-. ;K# . 4 +-. ;K# . '#hMJJSp<ML( J%3 7N; + ! <>9 :(;
%J * 7N8 9 :B;C<D9 :(;5%8%l6%#'%EB8#LS0%%P
+ rMuT
+ X,iK#9%#%JG0%0S
S09#%91Nv8G8rS%JS#S JS%YM9##S#q _MS%r7p'%JrS
G#!,pB>JS6h7p W9JR#ST#8MSJSQJS%YM9## lS8%SHV8D%# ""5
/CBB%?p#v%ST7p#8MSi%9jG%qpJ%<#8Z8%Tvp8G7%D-#79J= "JSJSp1S
BSLw1E%3S%TW%1%



9 1'

RM%##JM7Sw%J G% 7p* w1<9MSwSJw%1SJ%G7%M?1S 7%9S8S%
JJJ8 BS S1%SSSk9J#M%# JJ#1 .rS7p*S 1JSJ1
K 2 - !K 2 - #M08%SSS 7p%BS_JS9#1 %8SJT%1SJ% b%J .J%.S67p
%88%1 %=STSJS# ( G8%Jw=#-9%S ST%J i%7pZ% p"G
S8680SwSJS#JN##M0S8%SSS#7p{%Tw#I S" ML l1T7p*
wQS_8
S#MS#JSJ v8 8 SR?%J i%u%JuJJ%w#N1_7J#8GQJRSJNGH8?<
#.89%%M9_BNES$ 98MSl%K<7%SFv8 Y=1E1ph#O9J1SSM%
17YwSwJSJ#1 7W%qN%JS%9# #JS%91% G<S8vMJS0JM<S
1%SSSk9J#G%J G%
7p%U 9J=.-S{YM%788
+ SJ8"%SM .M%J
ShS#<M_%JS7J%9M9###Sv=w ff* 4 ?Y%?bS0JMS<%J#G#JS#M<WSm
SM 6 3Jh8St [ 7 9M:(; fiU36%{
#%!v8 Y{%JJj#8%p%JS0J B%J b( J%# ?
% 8 fiU BSQ( .9%KJS%9M9#k"S8%#KS9M=S7JS%9MY## L%G<%ES%#9#l% 38 M?
%%J#E8##9%<l179J" 1%1SrV%0%Jv#79QJS#J$
n 7A8 9 :B;C<D9 :(;W



W%7



fi$4

$,ffZ

#Q%8
N1.SK6%=kS90 k1SF%S7J#S9S#N%, 7 9 :(; W%=?%J p8% %9S#<p
BJ9Qvb7%S_SS89#MbV*%{
%JSS%Y-6%T<%#DJ%9 JS%J18{#8S#
% V<-1%w#7pD%88?%1%w<SU9
[ n, 7A8 9 :(;=<>9M:(;WhSSJS=LS#.w7
S=JJ#1LM?R1 -%BSF7%NJ0v8O%ZS0JML8MSJ'S( .9S_w%98%
SMY%S9#JqSM - 8 9I$fi# . 9SMS#S8'MSFSM%%8q8p%%b#98vJ.%#8
, J51J#85SJSv%JS%#J=W% G h%J0Gi?%J fi 8Kp8M8,9%S %pS
JS9#1%8?SJK%1SJ% {6%KSiG
JS%9 8SDMSiSBT#FSi%Tv%SS0%9KSi
' ( M%#l6%Tk%S %hSL1%SSvJ9# !K 2 - K 2 - S8%SS 7p#q#T S<MSMM9
fi]A%J%'%#k9Op=%J %
%3S
Sv1S%7M%%<\ 7%JL\_q#9S%J18pS=%1SJ% -#
BS9#R_V%1%=%Gb%STJJ#1 FJ%FSTS<%#9#w#9S%J18vS7%1SJ% q8p#M
6S SJ0JJ#1U%#JNb<U#qJ 6%1%=% W] _%J!
/u] "Sv1S%%hQ1.%

7A8 9 :(;=<>9M:(;k%J 7A; + ! <>9 :(;v1O7p#8S8S
#G08p#91-% %_E%8S-1%S#MS_v8G8
JS%Y Jb8J
%J07JE%88%1kEp%..SJMS7pE3%Z%88MGW% "! !-n
JS%Y #9S%J18"%
SBRSTJv8-8W
S#J%KqG 4n8S%##R1%<#JMS#%
SQJp,S#JJ%O#9S%J1_#JJ#8MwSJMwSJQJ1R%=SQJS9#1S 8S%_#w%8%##
S_6%1TSJM Q#Sv8 YwSY8S%-#S#JFSJM7MSl8lQ%JS#<%iSJ
BS JJS%v%SS9MHJ#u6S( .JJ1%'SJ?rSJMbSR9#<MS %SJ7JSrJJ8##J
RMS% 7p*-*%-J79M9#%'b%SSup#M5 4-LSh k#FhJ%%
%8q%98S%HSJ#=vJ#%0#S8S%'#M%8%JJ fi. 8Z%#SLS<vSS#9## NSJMqS
9J7J7#O#S#M"
h18vGq%S-STS8%#M9#l%{SqpJ%<#01-<3.1JS#8?#<S
Eb%D
8yu8Q%9 fi. B#S 8%p%%%JS<%S#SJP
4x8M8,9%T%BSJbJJ#1
%8S9=%1SJ% qW%=SS<#JS%J1
#=B #QS<#G8=k%SQ%KS< ( M%#
%SJT1%SvJJ#J K 2 - !K 2 - S8%SS 7pK#-fi]ACB.0%F8W8S91%"7#J8JFSJS
V#MvY06%wSJ8E 8%J fi. 7W S!
0G'ac3#JMS BS 8%p%%H%9S#<%
#JSJ8-'T%1SJ% #-%ip
BSJ#RbV%1%=%#q%{SqJS9#1 Mv%JQS8ST#-
8p#J1-% %.w1%SSMS_k8 8R%88%1b%9b9S%9mJw89%DN%F#7v%SS%.S%EG
%98%<8%%9MSR#L%88J%1lS#MS%FwSFS<%##8OJS%9dS8S8
J%Q%#1p9%uJ0k8w%
S1JJMS 18?#6%wM%##JMS %=SJRpJ%<#
1O7p*Zb9MSS8J#M.-%98S%
<#9#<%J= v8SJ1v8G8lSB9SJ#1_%J_%1SJ%
SMS#SS#8%FI !on 2&1Wn pK !B%vv%SRKShJ#S%J1FSBJMS{%JS<%J#JS<%JR*DS
SJw%SJ8.*%ES'J0v8{%k#8MSJDS9M1JS#SESMb%%J.S{MSh<%#.S%#"
4-JJS9%#%5Gb1J#809= k8J1#Sb9#YSQ%OJSJ1%8S9%1SJ%GM?
1Shv #Q1SRGZJ%#%G%FS9MBSJJ%w#
1h7p"#'( .J%b%88?M
( .\fi]A%
%81J.S#L6%
S71=%#8MS#J_SJ,%JS#<%Z#JSJhNMS9MRe
%Jlff<=%JJ fi. 8%G#Y%v8#%q19J1_8SG%"%8SwJ#w8Jff 0%9_ff<
%JJ fi. 8 G%SNJS%Y v'MSFVJ#b8S%#L_MS *M% /F



=
'hSSJ#S{JSSEl#wSJ#S1S_JSp#hSJ18p#J1hW%GiEv%SS#SJM
M?wJ98 %1S%=UM?#%ED%"FS%.W%SiM7J1J#7JJ%p%JJ G%T%8
8 9M:(; SS9%1%
-hG8%8{SJ<%JS#SJS%YM9##S#
k8 8 SM0%OSw?%J
i%bMSFJpJJ6%L.SU &J1S#JqSJ=JSJ1
%ZGwv8 9h9#%SGbSJFMR9%<#88
K8SM7#Z9%GM?<#S#J3S9MKMiM9JS#<M#F( .9!J#S%.ZWS SJGM


#?

W^



fi91#
gfiffgg

10000

100000

10000

Actual search cost

Actual search cost

1000

100

1000

100

10
10

1

1
1

10

100

1000

10000

1

10

Predicted search cost

100

1000

10000

100000

Predicted search cost

1e+007

ABZ5
LA19

Actual search cost

1e+006

LA18

100000

ABZ6

10000

LA20

1000
1000

10000

100000
Predicted search cost

1e+006

1e+007

KS 3
p8M8,9%Sw%hSJLJSJ#1 %8J<%1SJ%'SMu1S _W%bH
rV9k8786
JS?3 Q V9k8-. JS?"%J 8) 8VG8GJSB%9 fi.8"S
%H JMS% J'##iMS0Sv8#7v5
%JS#w%.S%90SJ SJMKMSGwUp#w%#=J#S%.ZWS SiMSZ%JS#w%.S"
GJS( ..S%v#N8?<B%%J G%LSJ8%S%vS0?Jp,S#709%<#8B8%vp8G%

J= "JS#J1SKhST=1E%JS%#J-6%1'GM?<#S#JZSJM{MS'%<%8M%hJS%J1
6S SNMSS7%JS#<%i#JS" p1J" )<SJ%S,8 7<%SH8%JS<M?
1JSES#wJS%%SOS8OGM?L%Bil6SdS=M'%JS#w%kS#Sl6%O19
S#7qv8pJ8vSJ?lSJJ#JwvJp%
J%
%
v8R%9S8S%#%J G%#-%=#
%S8F7<%S#S
8%DSM%%%?SJ<-6%=SJ
fi. n6MS5ZM% /? hS97S=1.%
# SM9 M5hl%J%pS#_#J9#8MwS9M8hSJ#S%%S,8 7<%Sr#_%
%iplvU 98#%*M? #_JS%%SS# iM % %JS<%
#S5'S S%,8
77%uB##B#J1S%QSQJS%9MY## HSJMlM? B##'JSp18 8% 8S8 1E%S8
B M? #l7#J G 6S % %JS#w%-S#S"hS%S,8 <7%S &9M_S
JS%YM9## 0S9MM?_B##1.S#Bqvhb%%ZJ%#%G
%BSJMi#% 7A8 9 :(;=<>9 :B;Y%J
7; + ! <>9 :(;*
+ B_1J1S877%S% 4 8 9 :(; 4 k%5SS8T7%SJSh9S1S J%ES#W%YBS



W^

fi$4

$,ffZ

MMSL8%S8=%G%88%1%ZS+OpIn Q%GS7M?9%171p9%S q76JSS8
J#8JSiSF#UM%=v8 8RS7%SOv #R1S5
"



=
-h.w*M%FJMS% <=S#<#MhLSS<JS.8S7%J% 87S<17%
v8 9bSS89#MS%98S% #HS_Jp#%SH9#YSJ<V8p1S F%h7LM
8%3SMQ%%%S9<O6%
4D=8%9S9MSS#8JMB%%%S9<O#.%SM. -h.-MS
77%8ZSSM7#S_1%SSvJ9#MS% J%7p#79QS8JEqS_80%
#JSJ=J#SS%J1 QW S<MSSF%JS#<%'6%q7%S<MJ9S%J#M## S<8%Sw%' 4D=
SMS#SWp#.#S#"ZB
%JSS#wJ%9M9###SD6%'7p#qS4 8O88 OT%OVM4 SS8i6S
%T%JS#w%#STMSEJT=SO4v1S%O1JS%.{U% %J [ E#J8vp
.{% kR GTMMS=SOM%#D% -h.7JSMDSJM{SJ'SSJ#S#=RMS%w9%#J
1J9DSJhS%7hv%"9p%S<9#YSJK%#,B<p8%9SMl%%%#SJ<D6%
4D=v#J8JJ#b
4D%9%# 4DF {JJ-%{SJ#-7pKMST%JJS9%#LJ
%J% 8SM9MSNvJ%OS9MB#Op88%SJ%w1J9#l._S%7F%%%S9<8
0
JFSM?H9= k8?F6S SJM0%E
-B08%8%Sv1S8ZSb<%#JF%iBJ
#
S71p9#8=7J##_% )F%S,8 <7%S 7J%9#SL<R%Sw#7v%SS%.S%"G
8#%hS<MO%3v%S_S
%JSbJS%9M9#S{%9lS=.J0v8%ZSM'J#S1S76S
#JSS%J11v8 9OJMSpDhS7SBM9#q%vS'SJS#=7pq8MJSSBS'vJ.
%{% 7SBSk8$ 9GJS%9JS%J1%Zw1E%S8 -h.vSSD=9MS#8J#MD91SS
wSJF%JS#SlJS%9MY##S mfi K 6O'"lUM#J79M%788-U%'SJ?R% 4 %J
S'J0k8D%"7pSM -h.7J?M{SJMDSBSSJS-<D8MJSSOSB%%
%DJ%SNJ9JSJG1p99LNp8%3M?Q%%%SJw'6%
4D=k%88%1N#MS%
w#9Jp#JJ%Y#JS%J1B#O%B%SSS"
4-JJS#J%#%%G'6JJ<8#JJ1'SJM{SJ'%JS#S7JS%YM9##S#ZTS fi MSh#J1
vJ.{%"SB8JSS.J#SS%J1'SJhMSS%JS#w%9#JS"{
%bSJM-{SBS
S8JESMS#HJ98p# %Jw%E %S8Tp8%M?H%#%%SJ<W%0S fi
i#JMS ..v88vl%J\*<.k%?7JJ87S
*r%v8M%bMSR. U 9J#S -h%w<#
J#SS%J1N6S SR8SEwS#S"i1JS%._%JSS# JS%9MY##SqGJ# vN.SS#
J1pv1<6SsS8%S8S#8%kS%JJkEh6MSS"JM% /?K#J%##%-J%
8%%vb%J%!
%%JipJ%<#B1G<DW%iq.J0v8{%37<%S#Sp8%9SMl%%%#SJ<{6%GS fi
9%QS 7%T%k8?M%"#J8#J9#7wYSF%9 i%kk#8M 8%ZM?""%J
R8S%v##OS%7Y##N6MS"vM% /?
K#J%%ES8-MS=S<##M#SKv8G8lGJ%Sw% k1S#%
SMLY%1-S$ 8T 4 8 9 :(; 4
%J_SF1J189O% 1 ZM?N9%1FS$ 8%. -BF%# "i%9S8S%iSJM'p8%vMR%%M
S9<D1J9S
1v.S#%#TJ#S97SM_1S=6BJ#?<#J8J p%GJ#8JS
#bp1S_DvJ%-#w0<%J8G#.S#8%Y##JTS#<SJ9%1'%5S#SJ1p
S%#Jlk%S #%9%#N%9S#<%D%J,%JS#w%ZS#SJ b-J8=SJ=#E8JS8SMS" 7%S
v1S%<p8%ZSM%#%%SJ<-MS7M9qLS?#1hSJq%S%.J0v8h%GS,%9S#<%Z#p
SJJJ8{19S#8MS#".*%.S8T%v8Mh#wS<%8{pSSJ%M?_9%1%, 0
%S<%
v1S%qSM9%1S$ 88MJSSh<S#w##M'#.SJS5Y'#'#L1.%-%SJ9LJS1S#
#8?<F%OM?HS9%1w%J%pS#Z# k18KG<JS#J<%%JG8Q5
SkS.
-h.89B7#JJ8MJ
F#%##%G=GJ#L#%=wk=M9#=w#.S6wJ1SJ%vWMSJSO%KS
%J%YSMNS9%1=BJ#?l8%lk
SBl7vhS#ES_1%SS#MlhS_SJ%vMLS9%1


g

g?g$

W^ W

fi91#
gfiffgg

8( %#"O5'(/#/? JJSS8GR79J%S$8LSLSL%
SNJ0k8 JIuJ9JS%
%9% %JS#<%%JS#<%G#S#JFB#SJ#S_SS9%1w%BS#SJ0JJ8q1JS#J8MS"
%JLJ#S1S<SMFJp,S7-JJ%w#8=V%O%JvlwM?N1hJ##9SJZ7k1S#%
M?RY%1S 8wV*%9SS
+ ?




B $ ) $[ff
Rfi #E{gNC _g G
K}
%JSS#J#HWS SSMS# upJ%<#Q1N7p#8hL68JLJ6 6S %%%?SJT
#JJ8k9EBWMSh%S JSS
#%J9S8Mvl1Y##8B<B%%#%%SJ Jp,S7v1
J% GL8%8M#Jb#J1%S#_8S%#R#6%<MS"GG8SMYFw%9S%#R7J%J#
#79S%7.Sw 1w7pO%88%1%
#S1J.S#SJNJw8J#ST%Sp8#MuB#S #p
S6SQMJJS%J?#MR .vb%#6%<MS5ivSS%Q1%SS#MS v8G8 #6%<MS
J%ES# %9 1Sl<
%88?%1 #_1J18JS9%#rJ9SSJ?#S# SMS# 1L7p#lMS
%%%#SJT#JJ8k9Effx J8VJWMSlH18SS% 1.1pS x%J L%.S#89MlQM
Jv8=vJJ HSwMY#w%88J%1%OS_7J#8+
0=
J%S!pJ%< 7A; + ! <>9 :B;1
7p{#F9%SwS%<bSJw<MS SMS#S#w%SbSMS# 7A8 9M:(;=<>9 :(;1q7p*ZJ
S%7Yb8S7E%% # 179SMS#H%BS_SSMS#S#_MSLJ= v8S.8#S8q8%S%S_S1
SJ#S#F1G7J#MS-SS9#S#JF%88M%pv8#%##0%wSh#79#80%"ShSMSS#M
1.%83_179M?MS%R%8SB<#_#J1S%T#ST%7J.-%#6%<MSQMJvM
vLS( JS V%wvpJ # SNJJ%w#L1w7pW %J8%R6S8<#J1S%S<#
%88%1%
Z8JMY07%_#.8SSRSJ%HS_1%SS#MS v8G8 #6%<MS .J%.S %J 1
7pD%88%1 #
S<9MSST%SJ7S#MSJJQk8 8S<#6%<MS J98p#_1
7p#LMRJ81SS% F8%#H IpF*%
v8G8\SSMS#%J J%S9%<#Q7J#8-% J%S!
pJ%<#B%JbJJ%w#'7p#8{v8 98%%G-MSJhSJMGSh9M%788i%SS8#M_B#Sw
9MSS8J#Mh1S-7p3S#<Mq%8N9M%<88-%DSq1S-7p MhSTSY( .JEB98
8%*1pvS#T%LJ1pv1JwSS<%JLS79-##7v8G8 JSJSO#%JJ8Mk
91SS
#lS fi. u%9LS=J,S#7=pJ%<#8i%
'B8%#56S 1S>B.AwSJMhSS<MR?%JSSNJS%9M9#Si#RSpJ%<#1
7pMS% J%##SMS%0ES8%%1SS{SJ'%%O%vJS%Y#JS%91{%JTSJM<<
%
J= v8SJ1TMSN9bMM#MY## #

+ SL<U#<%G%9S8S% J#S%91bSLM
%JS#w%5#S#"JS8JG%9S8S%SJMBS5
F88 Iw%J F6MSSJ8K I7%JSLJ%9M9##
SMS'S9qS<<8#'MS9J

+ rMiJ( ES#%.M?b9J8 #{J1SSM##
9#%SNiM #JSJ'S9M-MSqMJJSp<MNJ#SS%J1
+ rM<6S S0Mh%9S#<%
#JS"{N%=JS8##%GF%S=7%LJS9#1lJ#S%J1=7SJFMSO%JS<%vM
#S#7. 7 /
I; + , <>9 :B;6S#qJ#MS#<1 Jw{SJM 7 /
I; + , <>9M:(;
+ rMpB8h%.<8MSJ
MS_Jw9#<MRS_%S<<8#7b#%JSS#JS%YM9## % N6%q%%J.S
(J%9 ? R 7; + ! <>9 :(;9%#Sq7%SSh7%_J#SS%J1Bv8G8l#S#JDp#SbJ
#lM?%J S7M=%JS#<%KS""*% 7A; + ! <>9 :B; 7 /
I; + , <>9 :(;*0B.JkG7v#8%
STSJ81S
%S 7; + ! <>9M:(;Z7pZ#-Jq_SJqV%1
SJM<BST%JSS#NJS%YM9##S#'#
SwJJ%w#T107p{ML
.9%#SMS%Q#.S#8%{%1SJ= v8S.=JS%9# #JS%J10%J
* 7; + ! <>9M:(;#J9S1SQMJJSp#wMSb%89M%<88
+ %OS_9%<#<1T7p*
p# SNSMS 7; + ! <>9 :(; 7 /ff I; + , <D9 :(;
+ rM
#S1S89%98<# S%88%1 %

pJ%<#L%9 J%S!pJ%<L1_<<MSR1pv1"'%_HSN7%SJSR#b#%
8MJS=SF#79%1i%KSJS#
#SS8J#M?SG#_S=%JS#SlJS%9MY##S '
vG8'%ZS













W^ %

fi$4

$,ffZ



78 9 :(;=<>9M:(;J7JD#qS7JiFSJGV%1{SJM 7N8 9 :(;=<>9 :(; 7A; + ! <>9 :B;|x9JZ96%{S<%#p9S%9
#JSS%J18l%qMS%8J%9 #9S%J18 78 9 :(;=<>9 :B;1JS#.S %8S,S#<M 7A; + ! <>9 :(;*K%J
1J( .S
+ K 6%##L J#S1J.FSSwS89F%OS_M Y%1wSJMR#



JJ%H19#%S%r 1J8#JJ%SRUM#J71b<7MSNS#Mr. SN1pJSS
78 9 :(;=<>9M:(; 7A; + ! <>9 :(; 7 /
I; + , <>9 :B;
+ rM
'#MM%v8G8QS07p#h#B9_S
V%1 SJMZSi7p# %#EM798BSUMSp#h8%S8Z%J%88%1% J%ES#W=S k1S#%
8 4 8 9 :B; 4 %ZSSJ9%1=%D#JSJi#%b<v=Sl 7J?#TM5







G bT dDYJy R E 9
K}
'
1'7p#G8%%vL#L1S9 _xfiB7%81JEO6%iUM?#M9###<#_1E?%vJJ1_7U
S=%9S%9 J#w8J %3*% 7%9 <S%##% SMH10#=N%J MM#MYe6T
GJS( ..S%F1<9SJ#7%#0k%SL
.J%SMS%q%JL
J%.SSMS%78MJS'S
VJ#I !-n 2&1Wn K H%96T2 G8%J7SJ8MST9% S79qSJ<<MNSMS#S#85--9w8J
<#<M= SMSF%J+
.9%S!pJ%<#-1B<GwEiv
19L<%81J.'6%U6T
R1.%8v7JSJ1q6nO%S#l%JS%L6SxS09%<#=1
7p*J%-J#S8JL#
1S)B. /=9SJ#1e6 #D%8Mb#T%8179 O%J<#DSJ9( ES#0J#8M"
Ou%9% 8GSOJMS%JSJGVJ#fi6rJSJ#10FSOpJ%<#1D7J.%JT88?<#
B8SJ8B'%88M#_8JS.SOS%1S9%5J#?9Sb%DM?R1ShJJ8 p
<6# -Bw%# "F# S868S#_NS<9#YS>6 W%Fl%JS%9 #9S%J1
%0S %1 n Q !on 62$1fin K 'Uffc F?3hJM6#B83Gb19S#80Gv8 9L
.SSJ
S#MSwlS ''c --%{?%J fi. h9J8 30h hJMhV%<##L%J#?9S9
MSqS ''c -
?B q%9 * 4hS0SJ0JJ#1Q%J %1SJ%R ''ffc

#.S#8%##l9#Y
G%S1
.JSJ
8%Qvq%JS8S9S#wSS%JJM SMS#SS#8%Z%.pJS,%M J

4h#S
'Uffc
O6% <MS9#S1S8%GMJJ#<MFS0%1SJ%5J#S9S#J9S#71.S#.JJ
%JJUM?#M98.SBMJ9S#<MSb#DS.9OShB#O?%%'%5M?b1SS%9S8S%
%1SS#JJ##9J%%#%8%#B#=JK%#<#SKS#M<FS'v8 98MS#T%YSOY#TS 8
#TS'SS%JJM
( %pJS,%WM JDW%{JS1S8O%JJ UMM9'6%pSJ7%{S'v8
6%7q. -B??K9%"%GGJSSi MS%<9O=#7%%%.p<JbV09"%9S,%WM J
85hJ# %SJ7-ST1pJ17%%797V#QST6% %8JqJ#MS%79SR6J91SJ
%w
K?W%7J#SS#J11.S#Jq%J MM#M9Q'JbJ#.k%SJS#0W%TSl0
SM=S9M=S<J#?9S9'JJ8?<v%SS%79#-M<#.S#8%#NJ9J"='70
{SMSS# .9%ES 9 SJiwUp#w%9#S%J1iv8G8TSiGq
KD%JqSO.9#..k%SJS#
#S
1L"S+
FJ#S%J1( I0v8G8lSm#w8.S<#MS%7,p? k8B i#%%5%ME?
J1JS#8SBV%<#q%5J#S9S#JZWSsBJ#?7S-#JJp#J9% 'Uffc
MhB"
Z%###M %" D5{%F#JJ8M=SJMFSb.J0v8=%O8MSJFS( .9S #8M<%9S#<%
#JSJiJS#JqJG%#%%SJd#iMJ9S#<Mb1v.S#%##wJ#?9" -B8%8Y=J#
S8v%S J%##SMS%=SSJ#SiW%BwS#78 87JS%Yd#JS%91%bh#TB8B%i8e8
%JJ fi. 8.GF v8SW%?mT7%F17JS9S%=%J%pS#8D%B%RJS%J1%pGF1T
9-S-GMS%79#
q7OSMSS#hW%GS
.J9..v%SSSJMGSG ''c \#1pkJES#%
J#S95' J?=S%7971J#S
%GS<%1SJ%{M?1SS
q%98S%%8bM%%#p
8vJ.7#%8r'1Jr%79N1J#S7%<M%%p%% %JJ S%79#<B 6S
%u1pv.S#%'J#S9S#B#Su7% N179uWS J?<S%79#%BJS1bS%T
9#N6S SlS8%S8S#8%B
#qS( .9SSJb9MS#8J#MTSMS#S8%GS%W GMSLY%SMM%
GF79%R#NB%J%pS#{0SJ\SJJ#?9Sb%KSF,M%#B%Sp8#MNB#SLS
W^_

fi91#
gfiffgg

16

Empirical CDF
1

14

0.9

0.8

12

0.7

0.6

8

F(x)

Frequency

10

0.5

0.4

6

Exponential
0.3

4

Actual
0.2

2
0.1

0

0

0

0.1

0.2

0.3

0.4

0.5
P Value

0.6

0.7

0.8

0.9

1

0

0.5

1

1.5

2

2.5
x

3

3.5

4

4.5

5

KS\B 3Uc586TKJS#3L
##9S%'Sl,M%#qW%TS
1S#QSLJ#.k%SJS#0SJM
S5''c
7%78q 8%JJ fi.<MSN1pv.S#%# J##9 JJ8
'B.KS# 3K'h%1SJ%9%Jw1v.S#%A 'Uff
c
{6%SJ8'_8#9S%J1'B#S7S
S<%#SO,U%%
SS9S# 0HwSSMS#S#8<HSJN8W<#l%-KJSHB. 4i fi]MGGLS
1<SNJ#
..v%SS6%N%_%BS8%#JSS%J18{*%SM 1<9J8 #JKn01pkJES#%
J#S9#SJH8T V %S7#JSS%J18=SJq?E=S%GZ#SeB."7SJ
K
%Dv%SNS0%1SJ% 'Uffc n%9NSq1%SSvJJ71v.S#% 'Uffc 6%BSJ0#JSS%J1FBSRS
S<%q,U%%K%{( JM%ES#%DS_MS%78p#MS v8G8 Sb -K8J%7SJ#
#JSS%J1%%J %#%S8<#JSS%J1qBSd fi]MSl J9JSJFJ k8qJ#wM# #
S786qS%##8 9MSS#8JMKL%9S8S%l6MT688<O179JS9% WJ9H# Q9
1pkJES#%"9#YS"
0
J_SJS_S#JW%1 Z%###M )w%9S8SUMS# SJMLS1
''c -L9J8"
MSM9JS
#<M#u1v.S#%##uJ##9" Dpv.S#% 'Uffc
L%# MQ SJ 1.1pN%0p8%
M?%%%S9<B6%
%S8D<q==JMQJS%9#<8hJ%=1p%7Y%* -B<%# "55K%( "hS8v%SS
J%#SMS%#-S<##M"SJS"6%ZB%%{%J#8%.Mq%%%#SJ<6%%%. 4Dh56%Z 4%6h
4D= -Bh%9JSJ%b<JMRSJMBSq8p#MSL6SxSJ1pkJES#%%
F#%$ I<B
VJJ1S %iJS%Y Jw89 3G''ffc
=%OJM?8b6%S81-JS%9# JS%J1FMw7%SV#S?
%88M# <# . % 1pv.S#%'J#S9S#"
4 S<##MTS#MS#JSJ JTW%bS
''
c
J98 pDbZ#S "-S 0S8M8,9%G%"S-7%wM?l1 '%8SJS
M%#
%3S=0bS'SMS#S#-6%F8\ 8T%9 fi. 8D'=JMS7#J9#8MhS9MOS
U%#J-%
S<0 SMS#SS#<#=#.%8#RJS%v%SS#J%ZR#JS%91<Jw8J#%wR%Swv8 98%%"S
''
c
OJJ8 qMFMJJSp#wM<1pkJES#%k6%'7p8M1,MJb8JO#JS%918pBJ#
Sh1v.S#%9M9JS#<MS#<8%%6%%S#8#JSS%J18E%%GSBw#wSB?ES#
% KJSDB.=%LSJ$ 98%EGJ= v8SJ1Gv8G8R 4%6h 4D %J_S2 fi. iSS9?%#
SbkS9#L%'N<%SbJ9%8S%K9J7"lK#J%##%5_%wS9M -h.q%#RJ7p
MSJM=S ''c -
%G% #JS%91-M7#MJJSp#wMl#9J#ZJ#?9S5
l%8% MS%GS<1pvES%DJ##9S" 4hSJ%FS8v%SJ8S%5SJ# YJJ#
%#7?%JS#MB<S2 ''c
'%ZS#9S%J1'SJBNLZ#S
"TB#S qufi]
W^

C

fi$4

$,ffZ

0.16
p=0.05
p=0.01
0.14

KS Test Statistic

0.12

0.1

0.08

0.06

0.04

0.02

0
100

1000

10000

100000

1e+006

1e+007

1e+008

KS" 3
p8M8,9%O%Z7%LM?L1 %8SJGS
M%#-%3S==7%%%S.p<#
0SMSS#76%017YM#NSJw%1SJ%SM 109#YSQBSS9MF%OS
1%SSvJJ=1v.S#%kJ#?9S5Sc3MS%-M%#{%3SBiSMS#SS#hJJ#8M
7%SJ 98%.5J= v8SJ1 '% 8.S%E#5#J9#8M{.9#..v%SS"S
1S
SSSJOM qufi]0%J qufi]
Search cost

h18Yq%J% 8FB8SJ8BS'Ucff
'9SJ#1LlSpJ%<=1h7p58%%81J.
6%GSJ-%1SJ%*'Ucff
G%98S%l6% {J%O%L%5J
8\N8T%JJ fi8G
1<9
S' M%79-0TGSMS#SOW%SBJ#..v%S#DSJMS'JS9#1<%J<%1S9%'Ucff

%JMTWS S7S%<<JJ8##J<J##9S"
' JS
%79T1JS#SSh%S7%1SJ%
%98%R%8<M%%_J8vJ.O#%#B% h'0S1J%7919S#Sh%DSb8p%%
#J9JJ%Z1S wJS#<MbSw9SJ#1 NV8Lp1S&B. /?RBwJ#1S89%J1 #

G7S%79#-S$ 8GS<iW SJ-1'%8MlBSb%JS%#J#J0#J9JJ%S%7Y8K
JHS8v%STSSJ#S06%<S E JS%J176%7BJ S#wMS %hSJN9%<#_1w7p
9M%<887#7179JSMSJ%#%1SM9% %<%#i9JTQ%hS E #JS%J1N ( V<?G

1BS0.J"Ev%SS#OS9M'SF lJ#?9S9MS0#.S#8%5M Erfi]MkWJ9N
8p#J17%i%E 1%SSMS v8G8 H%J J%9 Jw89%q %SJ8F%?J83S9TS
SJ81B%{SJ0pJ%<#1-< #R%819ES#Jb6% UvB%J8%#lV%##'l%81J.
W%-S
VJ# ''c q{88D9#wSMS#S8%# SJ Y8%EFJ k8S918 SJ<JSJ1%J%1S9%, 'Uffc

MSF%J8%#+
.9%#SMS%_#.S#8%*{%h1p%<9%91J#8OSF9SJ#1L%JR%1SJ%ff 'Uffc

6%=S7GR#JSS%J1
##J#_S7S<%=%J#MS%S=,U%85%FSJB#KJS<q
SLv78%%iSL 9#YSJ0MSL k1S#% #.S#8%* S1
OK !-n78%%iSLG
J#S9S#JM9kMhwv2 J%#SMS%#_#JES#8%,9SJ?NSJM'SJ0%1SJ% ''ffc 8%vF8
MJJ#<ML_J6S#TS=JS9#1 ''c %7S=U#8
VSS8qSJv%S=%OS9#=%98UMS5ZGb<%Sb8MS8VJ##Q1J#8SJ
/%#JS%J10#
BJbS-9= k8J1v8 8lS
%1SJ%"%JbJS9#1 'Uffc
iMS
SMS#S#8%<SJ$ 98%EGM
qufi]M%%?bJS%J1%.-179hSB07SMSS#O6%SJBJ= v8SJ1'v8 8bS
JS9#1 'Uffc x%JH%1pv.S#%{J#S9S# BS7%H( J%{QSw9SJ#1 NJ%
%#DJ#w8J=#JSS%J183v8 Y8%#RSJ<BSNJSJ#1 ). 8fiTS%%pDw6%#KRS
10S
J#9.k%SJS#SJMiS-9J8p#F9#YSJDMS=#JES#8%kM qufi]MGiJ( ES#%p#
STpJ%<#F1S
<38qM9#0l%88MRJSJ#1 UkSJJS9#1%9%1SJ%R 'Uffc

W^

L

fi91#
gfiffgg

Empirical CDF
1

0.9

0.9

0.8

0.8

0.7

0.7

0.6

0.6

F(x)

F(x)

Empirical CDF
1

0.5

0.5

0.4

0.4

0.3

0.3

0.2

0.2

0.1

0.1

0
2.5

3

3.5

4

4.5
x

5

5.5

6

0
2.5

6.5

3

3.5

4

4.5
x

5

5.5

6

6.5

KS 3

Z_%=SQJS9#1r%J %1SJ% ''c-_6%b 8E 8%9 4 fi '
,U%O6%'SF0_SBSMS#S=MSFSv1S%#_fi] B@/w%J5/u] e8
GJ# vRSMSS#8%# #9J#S#JJ#SJMY% %lSNS<%J#%u%9r7JJ #JSS%J18
GN %98S%NSMSS#8%# SJ$98%ETJ=v8SJ17M xfi]Lv8G8 SlJS9#1 %J
1%SSSk9J#<1pv.S#%R''cff
82-hG8%8Z%ER9=k8J1
MS7##MQlS786hS%#h%
v%SNJ#S9S#J8ES9LSJMBSFJS9#1 ''c -BJJ88JGSJ1%SSvJ9#q1v.S#%
''
c
8D%%7SJB #HSl.0S#Jb%BKJS@B. %S8T%98DS ''c -qJJ#1
SLpJ%<#b177J8MJSJSbSJL8MSJ0WS Sl1pvES%6% SJM7MS
%98%N#LS2 'Uffc
O% 7L%L%JN<J#J Jb8J_#JS%918

#% S-G#!,pB_Jb8JT%3%88JMwSS#<MS#0S
7%_%3%_1v.S#%
%<1pvES%!#%LJ#S9S#H%J *TSLV%1<SJMw%. F#J7vA 7pi% B##
1SM#6%#ZR8M9SS7S7VJ#Z8S%#K%GS7<9J8p#lRM%J%"5=SJS
JShT8#JJ1-bSJJv%S{%3SJ-..v%S#S9Mi%.<%9S8S%LJ= v8SJ1v8G8
S{9SJ#1F%9F%1SJ% ''ffc
MS%3JJ#8MS%D%%.=<
%ZJ1SJ%# &9H#=SJpJ%<#
1B<,
|D}

E C9fi






# g



%R p _%JMSG7%09w8J
%Nfi.Q#JS%91 #3JB0h#91S%%ZSG.9v83%
G%S &9 9MSSS#J.OWh5# MMF6Sm-V1%SvJJ#J'h?%J fi.?kff V1%SvJJ#

&JB%Pfi??k*%v%h7%091SS0B#.SpJJ1"O%-1p%<9%kS07% O9J8
%98S%uW%<Jby %JNG%S &9Fi%J &JBS% fi. 7MSR# "Mp% /#( /CB.'%J
#CB.vSv1S%%G'0J= v8SJ1OS89S.B%N%J8,%wMJSJ0#J1S%0#L%8M%
Jb8J %P
OWh<#<MMrW qrMH%JrM%# 6S qrM p#<#M<J= v8SJ1
MS_%98S% 6%L8yu8%JLDG%S &J{%J &9BSJ% fi 8KBJ8SwSl7%
MS

Sv1S%#
/p( J( / W] /#8 J%JRu]A% 8 {B=%WN1S<Jw89<%K91SS
fi. G#VSSJ8G##JMw.wShV%1iSJMiS
7OJw89B8 R8 &9BSJ% fi S( JS
%N%8M%0%{M%@L ' K 8MS9i%! 7w#8M%N%JS#<%5S#S"
W^



fi$4

{%9





R

$,ffZ

p$8 p J1SS
'h%J
% &J
KBS%
'h%J
% &J
KBS%



GhRJ
7; + ! <>9 :(;
p ""
pA%
p BM
p BU
p BM
pA"
p @B "
p /M
p #
p J
p #
7A8 9M:(;=<>9 :(;
p M"



ZM9 B3 'J ( U%#JO%DS 7A8 9 :B;C<D9 :(;3%J 7; + ! <>9M:(;31h<O% %JS%#L6%-"
%JNT%JJL% &JF9%J &JB %5fi.8


N9S8#JS8k% SJM7SR%88J%1 %hS 78 9 :(;=<>9 :(;'1b7Ji6%#T%J68
6S ?%J fiG%S &J fi.l6MS 80%*{M%/?i%JJS#J%D1pk8?#7.Sp#
S#w##MBSJShW% &JBS% fi8=ZM97_ShhSJ ( U%#Jh%S 78 9 :(;=<>9 :B;Z%J 7N; + ! <>9 :(;
1w<06%b@ %JuHHQ%JJL{G%S &9Fi%J &JBS% fi8 'lSS9S7#p
J#8MwSJMFS 7N8 9 :(;=<>9 :(;{7p{=7%Sw%88?Mw?%J fi=S9%SJ8F% &J
%J+
&JBS%5
fi p%#SL%88%1L#<JS%'B_%JS#SJ#q6S % &J J
&JO
S%1
fi. 8-' 7A; + ! <>9 :B; 7p B7%ST%88M7S9%RS 78 9 :(;=<>9M:(;Z7p3v%Svh%
91SS fi. Z -B8%899#hS
M9=#7JS%7.S#MS%
TS 78 9 :(;=<>9 :(;"7p*
%88%1%{S 7; + ! <>9 :(; <Z1S%S
BSQ#J1S%-# OWh1G 0-%8?%#*kS 7N; + ! <>9M:(; 7p
%81J.S
W%
S##ESl%8FJ%D%DSqUM?#M9###L#N9S%9 Jw8J#l%98S% #RST7%S
Jb8JhSJ1SS Q+
fi 80'TSJ Y8%E
J= v8SJ1T# %88%1 /MT V<h#MS%T
%JJ fi B%#hSvS9###wS9MhSqpJ%<#01-< <RkqJJM9#F_1%S1
6%'SU Y8J8O%KS 7N; + ! <>9M:(;57J*DN9MSS#8JMp6%1%h%S8hSJ% 4 8 9 :(; 4 <Lv
1.9SNQS_9w8J %hJ1S fi. 8K%T0<%qv<vSS9#7 <S
vJp%O% N91SSN#9S%J1O%BwS#79#h%9di%Y
G9S#8OS=?%JSSl9S%9M9#SGJJ8OSFJJ%w#
1B7p"6%h w%9NR
G%S &9 %9!
&JB% fi. 85%9S%#J#lS<S%7Y##L78Sp%% S1?vQ
B.A<KN8LSh=S7JS%YM9##S#'% l1.S#J#lL%9SS 88NS
MSS-%9S#<%Z#S6%- N QL
&JBS%#JSS%J18=%=ST#JS%91q1%SvJJ#
wSJ086J%J5
JS%YSF%JSN9S%9M9#SiMSJ_JS%v%SS9%"wSq8SS.
J#SS%J1w6S S_JMSq%JS#<%#S5 B9#H#019S#.0hSS_SS9SF%9S8S%
6%q?%J fi. 8D%%7B M87#HKJS+
1.%8GW%TSL#JSS%J1_1%S1
vJJ=TSh?E9%JL
9S%Sh9S%9M9#q% q1.S#J#T<%=88iTS
MSS%JS#w%{#S##= v1S%1JS%.0M mfi]AL'<1%79###JM7L%8
v#.BS8M9#_S0vJ#%h% J1SP
fi U 3BS0?%JSSJS%YM9##S#'MS
S9 98%.S77%ShJ88S%%8JiSJ%_SSh%9S8S%w6%i%J fi. 8%W_8p#MS#qSM
J Y8%EST6S FJ%%9#8%$ IlV*%p<78#BMSJJ
+ rM{W%? # 2 Kn Q.J%SMS%
%J!
J%ES#SMS%<%v1S8q
#%SJ #M%TJ8#MS#J8"
#
JJSJ#STSJM=1F7p#
9%S#<9TSJ<<MQSMSS#88Zv8 98%# 7A; + ! <D9 :(;V3V%#K%81J.6%N9S%.S#%
JS%v%SS#l% SUMM9## w#lSF9w8J w%D91SS fi. 8












W^

fi91#
gfiffgg

1

1
Probability moving closer given grad=closer
Probability moving closer given grad=equal
Probability moving closer given grad=farther

Probability moving closer given grad=closer
Probability moving closer given grad=equal
Probability moving closer given grad=farther

0.6

0.6
Probability

0.8

Probability

0.8

0.4

0.4

0.2

0.2

0

0
0

10

20

30

40

50

60

70

Distance nearest optimal solution

0

10

20

30

40

50

60

70

Distance nearest optimal solution

KS<83h'l%JS#S JS%9M9#SW%<788<SLM7%JS#<%iS
JJ8 76%BJ#SJ1'R &JBS% fi

-9#J=v 8SJ1O#NS=%JS#SlJS%9MY##SS#MS#%F<S%98S%RW%'?%J
fi.8JGq%98S%qb#<9%1BRS%8%#K%88%1N%DSJ0pJ%<#=1S-7p*O%Fe
%J L%S J& fi 83S ( M%#F1%SvJJ#lQ !K 2 - !K 2 - S8%SSS#%OS
JS9#1Q%8SJ=%1SJ% TMSTSSk1S#%fi]ACB_%Jfi]A# T'7%J%#%%J ( 6%=v%Se
%J J& BS% .fi #fi]A%%7%#9RW8m1p189SJ%JS%J18KS_%1SJ% <#
%ipiBSJwq6%1%O%R0
/ %3S-JSJ1 U#lT8%FGS=J=v 8SJ1B118NqV%1%
% <#<##M-SS9S=MS7%JS%#J LS<%#K8=%G%JJ<N%8?Mr8 8L% J&
%J 9& BSJ%5.fi OW%BBJ#?l%JSS#lJS%9M9#wS#<MSR#O179SMS#J%#bW%S#9%
' JwpJ%<#<1S07p%88JM8MJSSbJp,S7<pJ%<#8=% N 2 KCn Q
%JJ %J0J1SJS fiU%SJSJ%JSF9S%9M9#S"MS .9%#SMS%=J k8S.
#0SiG=vK%JJS%9#L -h88S%% 7#SJG?%JSS0JS%YM9##S#5%9?J1SS fi.
%JJ#SJ%#Q#JJ8MFSJM0UMM9## QSlJw8J#Q%OSbJS%J1q#9J#%v
8MJST.TS#7YGJ<<MSqSMS#S88p#J#JBSJ91SJD#qS'%88?%1q%k{SMS'%J
J%S!pJ%<B1'7p#KK#9%#%=%9S8S%=SJMOO#iS##YvSSYBSJMiSF%88J%1b%
S<pJ%<q1S7pK<8%%J<SJ Y8%ESJJ8
VJJJ%7.S%#J= v8SE= .v=%
91SS7SJ%SJw1JS8S8%3%ZBSSJR1%SS#MS#v8G8SY8S=%iS
%v8MSN9MSJ9,-+*M
MWl8'%*5%%i#JJ8MhSJMOJ k8S91O#wSJ
9w8J 7%3%9 %Jl% &J
fi. _MSJQ 9= k8J1b SJQS$ 8%0SQSM Y%18-%l7%S .rS7%
J#SS%J1Rv8G8 %J p8%'%JS<p 'JR%98% 7% <U#<%hJ#S%91
+
MSS7%JS#<%OS #J1S%STB 7#JQ6S %9 fi. T% &J fi. 8
%J M%# 6S % &J fi. h+
&JBS% fi 8vSJS-W%F L%J QbJ%9 8S
MSwBH#ZM9 /NGJ( .S%3JFSSJ#SF8S%bR8#M6RM6#8q%* )F%?#J%
%S8S* 3O%QSJM
+ #h_<%SSq% 4 8 9 :(; 4 Vv9= k8J1hNSTJw89L%{?%J
%JNSJ1SS fi OMS#7YwJ=bJ= v8SJ1'#lSJ= k1S%qS 8=%KSSM9%1%
W^7

fi$4

{S%9#





R

$,ffZ

?J1SSF.v
%S &9 KBS%
/CB.
"M
B. "M
# " "%

p 8 'B%JJ
pM E
%ACB

ZM9/ B3 'Jq7% <U#<%ZJ#SS%J1lSTMS
%JS<% S#S
+ '%98S%Q6%
<%JRR7%JLpG%S &JFY%J &JBS% fi
5| |"} x { g - [E b# dDYN #M #5].
4-3J#8JS=#q1S / '#5BS#MS%#-?%E6%SiM797.SMS=%pSM90M?
6%GSJG fi Z.b9MSS#8JM##%i6MSSOS9l%i%U%91L7%=%v8M%i%JlJM,8
77%u7J%9#S<bSJMlJ% v8r<JM #7JS%RSQv8S6%<%J1%=SM9
M?L%%%S9<GW%OS2 fi Z
#%L%_%88JM1O7pk% pS=1pi#%#8%v8
#iwSwMS#8%#_%SSBSF#79%1O%ZSF%#%%SJ<h6MSS'N7p"J1SJSF%J
%88%1%b-S#wM%9S%% #Bb#91S7.S%#l7%0k%SRSSM%8-%%%?SJx%JRS
%Sp8#ML1O7pkiMlS
SM1,%W,S1MS8k%J%O8SS.S7S89S.l.L
hh#Sp
%J p0JSJ#Sp )w*M% \,h 4 n%%%S9Llb SM%L%JS#%D8 iM SJ#F%%
J7JMSLSJML%8 v8S6%<%J11,9J%J8#N1<kJEffxSJ<vG8S69 H7%
%v8M%9xwV%##ib#79%1OSJ8'S?J1SS=%B%88J%1L% SJpJ%<#
1B<,
'B8%#pWs1SL
/-SJMDSJ'.k%?.p0%k=S 'J98KS *b7%'%v8M%
1JSST%-%O#S9T%JS%# E%8SS SL%87%
9%T%
%
S%1Eb%k8?MSJ
S%71S8%
9pSk c58
ZfiU_J%S#JS %JS%# . #.%8SS#
S%J8N%0 %
%1.1?S#8%-%v8MSJy(+*%Jd( =# E qv%S (O*%J ( FMS
1.S%# ES#S BSJuH1?S#8%'YY',%BS8b%v8MS MJvML
9w%l#%_#
ST9pSkvS 6 98 : fi D. 6 98 : fiMq*RM6#"%%?qR%S8=G%J5<%E7%F9J8
_JSMM978%JJ%p#<#w7J#MB7JS%7ESG#7SJh<M%Y%w%"S-8SS.S
%JTS88W%SOSJJ#q%DvG1J#8STJ?#hSM" iJ#J#'TS9#K%98SMMS" hh#Sp
%JpqSJ#%%-ESpJJ10bJ#J_S#1MM#%.B%DS * <%T%v8M%kBS
S=%%3%Z%818?MS#wp8%"M?LbS9J8#TS=%S% 1'%K.k%?.pb8U%#9MS"
'J3%v8M%EBJ#?0GO% 5.1E#9DS9 98%.S==Siv8SW%?<%J1G%9v%STS
G#!,pBRh 4 %#%%SJ BB#Sp mpqSJ#*"%%B%JNSJ8SS.BSM1,%W,S1MS
%%%#SJ 6%FS fi Z*h 4 x hB#G pqSJSp*3M% ? -B8%8ZSJ<vG8%iS
r%v8M%_17<hS J1# 3LSR#J9J1 9%1RHI ! K _n IM'J S9Mw
#0%q%#GqvSSYTQ7%lWS % MS9M S#SQR%9%# %JS<%S"
GJS( ..S%pp8%9SMl%%%#SJn9%Sw1ST l8%wv 4Br#7SJhS8%8S#8%
JS%K9SS8%D9#S8JSSvF%79?#8%T 4B vJ%K6%K9%S#GSM9TM?<%%%#SJ<
9%NLS %k8?M%B#'%OvS9-W%B%J fi
'Jh#%<%5S 4BrJ%k8<S9 98%.S7179##8MS
8%%9<EG%31i7p#8
%==#=J98M= J%.SWM1F%"( JM%.S%"JS%9# J#w8J %'J#-V%18
# #MS%_9MS8{%l78#S# 9%_TSM? %%%S9L1
''1.S%
G<7J?M SJM=W%=?%J fi. -S %v8M%8%#9JJ1TS<%# FM9K Il%F#M
#MN17v.SO%ZSM?RY%1=WSxBJ#?lS8Mv#O#7vS9T6MS""M% /?
%SS9JM%KS<?M9MSw%S# 81 %J8%k78MkNNS%F%J G%
W'C



fi91#
gfiffgg

1e+08

1e+07

1e+06
1e+06
Actual search cost

Mean search cost N1 operator

1e+07

100000

100000

10000
10000
1000

100
100

1000

10000

100000

1e+06

1e+07

1e+08

1000
1000

10000

100000

1e+06

1e+07

KS<%@3Uc586KKJS#3Kp8M8S,9%D%9SJi%1S9%M71S J98 SJ -%8SJ!
%%%SJw85S7##J
H[ H#
Sv8#7v5 'h.FZ#S#3
8M8,9%=%GS
JSJ#1R%8SJh%1SJ%3SMQ1
W%q8e8w%J fi. 'JS#J YS
%H JMS% J'##=#Ov8#7v"
Mean search cost N5 operator

Predicted search cost



JJJ8hST7%Sq%8%'V,%v191Y 7%7%v8M%F=%QST%98SMMSJYG
#.SpJJ1Q% J,9% SM9 M? %#%%SJ W%TS fi.\SJM7#079##8%#P 4B
u%#G%-wy GHHi%J 8H 88S7%-%J fi8 'L%%%?SJL{hJ# G
% pJ#i8S%##bwMSSH*M% /?, -hG8%8YBS_S
1p189Sl% v%S_S=7%
%v8M%w%J SJLMr81S ?S8MvR79%J#S< %J MSN#.S#8%*
VSS8%98S%-SJMGM9GMSh#JWS( .STJ1J.8S 69#8%#<Mi7GJ1-8%8S %
7%S=8?MSJ??%JlG=J=#.S#8%v8S#G6%'%#k9M%788?iWJ9_bv%Sl%%%#SJ<8
*%> , %9 + 7GJ( .S%"<M<nM9#qN?JM%18$ 8<S7#79%1
%S
7%B%v8M%{7SJ' k1S#%S{%kSM9<SMwW%{SJ% fi. HJJ8D1.S#71pv8#7.S%
1JJ#SJ8
G9S#8=Sb7%M? 1 7J98Fv%S %J
w8@ 8N?%J
fi. 8pSF1%SvJJ#TS8M8,Y%B#OSJBL#lSJF8W'#-%ZK<%M{F%98%Jp
1pk19< 1%SSMSwv8 8_JS%YsJ#w8J T9J8SJBG7%%%S9<8pJ= v8SJ1
%OLV%1%0%=8RMw1<7H%JS%?HM?R6%1%0%
8%#Sw%S8%%+
-J<
Sw#n6S( J1Q%p88SS91% N<J#<%ZJS%v%SS#%iSw%98S%9= k8J1F8%v
MYl<S=M81SN%Jl8Mk07J%9#S<8D'JF#79#8MSbiSJMOSF7%
%v8M%i8%b?%<MS#8%#T%8GSh1SS( J7.TSM9_M?wqp8Mh%JS<%9SJ
q%J fi. 8 _<%E<8%S8.SJh v1G%1SJ%##HI ^n L #n 3#<SJMSJh7%_.9v8
%98?MSJZS( JS0JJ8! -8%qvGJ 98%.S=#MS%8KSJ%qSJMKS( J0J98
-hG8%8{S_.J0v8%'#Ev%0JJ8FSJ %v8M%q1w7J118JqSJM09J8
L%v8M%'bqV%1%'%8T%'7%%v8#%#7L#M%8G9S%9 #JSS%J18<%p#
%.w8#<ES%k v1SO#wSJhM%O<
%w%38%8 4-iSJ8 q1J#.S<p8M
%JS#w%"#S9O#LG8B%8%# %1 n L !F%8M%qSJ%

c MS%7J= v8SJ1-#NSq%98% 0JJ8 b%J>
bMS71SM#L#J9#8MS%%
J= v8SJ1h#LS0JJ8##Jq?Jp,S#7FJJ%w#88T 1JS8'B8SJ8BSqJ= v8SJ1
MSL9 J%#SMS#%L%w78S
.9%ESSMS#%%u %SJ8<%?J8i#TSL%JJ G% 7p
W'C

fi$4

$,ffZ

JS%vR#Q1S#>B7Jb%8-MJ9#8M9%%
8%NSqJ=v8SJ1'vF1p9#%N#L8?<B%
9%%T#7p{YM%788qSJ?%
+ %9Sb%JSS#JS%9MY##SD=b ff* 4
<%JG8OSJ# .JS"pGG JO179J-SS#<MO%ZS=pJ%<#-1'7pv9M%<88
JSTSFS%79#T78Sp%%lS1vl#R1S#qB.A9B#SbJF1p189S* 3JJ-wS
S#MS#%FM %9G0b%BM7Jhb8MJSJSFS0%Jdi%l8%.S-%8MNBSNM
S8Mv% TJSS
%1SMY## %=1JS8iJwSJ Eq% F8 8T?%J fi. GBSE
8%p%%b%JS#<%5S#SJ
'JSS9S#'?%JSSFJS%9M9#S"MSi7%SiS8J#M5SJ%0SG%98%q9J8
qSOS%7iJS%Y JS%J18wSS%'SGSSJ#S %9S%#qW%D?J1SS fi. ZS1v
#R1S#8p, 4-JJS#J%#%WS( .Sw%Y8S%#M%J#S189%J8i#
+ JJ8
%J pBJ#?"w9M8J%81JES'W%iS
%98%LJ#S1S8Y%J8G# MYb-S#J0S
SJS#
9M%<88S<M8p-179hSB9SJ#1 B%Jb1<9MSBSJBSS9SDBSwSh%1S9%
%98%bJ# p.S-1%SSvJ9#FS8M8,Y%G{SBw#<SB#E#'%5K%M
' ( M%#%DSJq1%SvJJ# K 2 - K 2 - S8%SS< #-fi]A%5%JR%# 8%

%1SJ%
8p#MO6S
JJ#1 -._<7%S=S9%LT6%1%'% 0-%8?%#*pS=SJS
79M<SJM0S
7%b%k8?M%0J%FJ8#9#q v1S<M9w%88%1%
SJJ%w#=1h<,9%B# YMQ#
S79_%1Sh%h<9#%SL%JxG%
%8qS 8 9M:(; SY%1%LG9( .JES% SwpJ%<7107p{F%MJ9S%J#M7Y%S#
6%
l8S%%9%#B%*h 4 %=#M %%%SJw8YhJ#QJ= v8
W bJ#<M?#
#HSLJ_%BM,8? 77%S<J%JS<qSJ %TSEJ 98MS %J 9MS S##J#J
hB#ZspqSJ#,M% ?





{[ ZY G _T dDY
| K} ] E C9 g
'Jh6Mv
J?#<MSL%%KJ%
v8_1p9#%RST?1q%STUMM9## L#RSJq1=%
p8MS#F%9S#<%JSJD0%J fi. {JS .S-pJ%<#O1G7p9#.SpJJ1
# 1S7B#MS%#%J#8%TSJ#q%
1S%% -9lSJqJ81S8JG8%8GLJ%LJ#
##JMHSl1Y#%JM%S vG87%BSN7p*%%{S8.S 9l7p#TMSLJJ#1S%%
# SJM_S8r% 8 1
1SJSl1J18J#J SJ
1bvJp%l%J MSQ19( .JES
V%#S 9MY%"1p5JDSJpJ%<#K1Z7JM'JS%v{%JF798%#'1 J? GB%
1
1SSS8MJ#JLS7vJp%F% l%JJ fi. 8 0
F%J%#S=7J?M
SJM
STS###l%1=7p#h8% 19v8%JQM68,S1,V%1F1Y#%JMSJh%%%%?SJ
vJp%
: Rfi:W# 1rGT
# g# ff
?^ fi$ ? #
<9#8%8p#J1'%%S{S9MJpJ%##0JS#%p#JSJ l7JS%OS'v8S6%<%J1
%BSMY %#%%SJ<q6%7S fi. x fiE%#" 'h%%i%%G R88%"iM%%E? {88v%S
S71%1F1JJS#J
JJ8
BJ #7J%7.SF8% v7%J8%%J ST1v1J8%S8
% 7JS%7EOMS
v%<JJJ8"ZF 19#%S-TYMSS#8J#Mi%v1i%3SJJ%8
#SbH19S#8SJ+
S#* 3b JM<#<9%17J= v8SE7#9S#%# MS#78SpJ7J%
S1-S( JSL"
_#8M0%JS#<% #S9Ow%9 fi 'FJ1J#
%J%pi%! TM-Y%lLS=%SS97JS_SJM'M?N#OJS#MbWdT%Jdp8%
%JS#qJL -h8S%GR#JS% 1JS#8TSLvJ#%7JSJ#1 HSJN9%<#_1w7p
BLSM#'#J#S#M_WS #S9i%S8BSJ%N%Jdp8%"%JS<p
W'CBW

fi91#
gfiffgg

c38 |=%RSLJSJ1 7%rM?r1S<S( JS #8MR%u%JS#<%OS
J JJ8-SJwpJ%<#q17pKBJMH#=#J#S#MQWS #S9hS9MMS<J#SS%J1
6S SFMSSO%JS#<%"S" 4-'#N1SqB.9F%SJ7
SF#J#S#%9%?%J. R(J%#
? % ff8 fiU BSw( .J%YJS%YM9## % %Fv%ES%Y%p<78?<S
J#?9ST%
7 9M:(; fiUh6%=%J p8%K%JS#w E"%98%7SJM=S7JS9#1 q-M9JS#<M#R( J%K
-BJ8S
[ n 7N8 9M:(;=<>9 :(;W?Y,% #BJS#Ml6S bp8%5%JS#qJdS9Mh#'%%8M%
J#SS%J1 7N8 9M:(;=<>9 :(;36S SqMS
%JS#w%3#JS"BT%JSBSJq#S%S0#<9%1h%
%89MS%7#JS#%Z#JSJh STk8W%w%J1T% b%9% lS7JMSST% 6%

[ K7Z#SFEG'Su9%SK%kSOJJ#171S |k%8
h#i%%O% 56%v8 9
ff<wV86 JSK%98L8l6. JK%JJ fi 8.SSJ#S{6% h8S u 8%p
MST<Q6%
9SvB%p#SJ%#$ MS"hJ%=ST w#9S%J1%"M?1
#hM9#9
v8G8AU[ /L%JA[ 8R%J1.S#.J=N%%J9%#J1S%<%
+ <1E%S8
M?1
W%
Sl8)H8l#JSS%J10?#hM9#J#bv8G8EN[b%J> ( b9Jh#hSJ#
K !on JnVZ7pJJ#bS<%79##J_%5J1" m( "{%hE'[ /3S<pJ%<#T7p
JS9#1SGSJMOML1S'#iS##kSJ$ 98%EU 3K5SJ
JS#%YMl%?%J.iGJ% ? M?
# M9#9=%0iM7#JSJ SJMDMSOJ#S%. 6S SOMSK%JS<%.S#Sq%JT%E
vU JZ%YSJGV%%?M9'#J#S#%vSS#0#D#8 O%Y8S% J%#SMS%##.S#8%vJp%D#
wMS%S%7YF%KB?%J fi JMSp#<MhS6#B#T%8% %98UMS 36%B%
VJMk
#JS%918 SJbMJJ%HiM %%p7J%S#wU%<%
M'%
+ #F%?%JJ%
6M9Y?0GJ( .S%"G<Ev%SS 8qSJMF_9MSS#89#M-JS#%#$ MSR78SJQB#
v
J%7<#J<%Y79%1OLS=v8S6%<%91-%! 1 ! !FS=SJS#T#JSJiMSF%8S
8BFSBM{%JS#w%#S5 4-JJS#J%#%MG'%98S%BSJM{S'pJ%<O17p
JS9#1SS9MS
J#SS%J1hTS
MSS%JS<%YS#S"%Jl%i#SL
JSSJ1SM
S<vU 9=%iN%#9S#%# MS#Q<8S5b'<9#S#J1S##=v8#%##R%8#
fi. Z
B8 JSS9#S%J1<1%S#MS#
pBRv7179M?MS% MkZ%Z#1.%0
%##bp%#S<% {%9 *MW#5 %%?
GSJ#Ev%SS#
%J% 8BSJBv8S6%<%J1'% 9S#F0UM?87%5J#S#
%Jb%Jm78SpJ0%J8M=#JS#%9#S98ZJ#h# fiE%#<8O%*v*M%%E?JG-1J#8
SbW##B#JR8%hJp J%# 9% Q9#9MS?9w 'h?F9#H1
SJJ1SBS

fi ffw8B%JL'<9* )%MEOJSp1JS=6%'%8?MS#<%1S%q#S9 3
QVKi7%9Kp8S%?
Q pc3% ''%#J#TG%SJ?

''w%#J#.?%J
*RB%?
{1S#<'#<?
,p%%
4-JJS9%#%pq1JS#J8Bv%SR%1S%T%JNJp#N#S9,
fi ff<8
n'J79" %ME
%8MrJS#Q%JJ , 'B8Sv1S%J%
+ ; %J!
; / 8 ZJ%#%DG
#J8JD %##M* ){%" . 1#1%%MYJ#{1JSJ1SF<8S5UJ% Q "$#=M%JS#98SS
JSp1Jq#.SpJJ1QR880%J #8T%# ?KBJQ7J%
L3SJTM8#
L%-SLv<1J?J1S%N?#S#8TM%##MYlW%<SJL%J fi fi% 8<%*OM%%E?
'B%9x<%1S%0SJO8%%B7Y%##=%JRMS%%
$fi# , 'SJ
=? 2,U, A5D!,'?E' &, U % k
{*,Aj
MB*UUZ+',U)
( +* Z;v< :- 2%U*
v{S,{?**OGS,AVKV* #,OK*UU+U?9?.%S,AjU< 23vDU*K,Z kG,,O"+8,,MjU8



W'C%

fi$,ffZ

3400

320000

3200

300000

3000

280000

2800

260000
Predicted search cost

Predicted search cost

$4

2600

2400

2200

240000

220000

200000

2000

180000

1800

160000

1600

140000
0

5

10

15
20
25
30
Distance nearest optimal solution

35

40

45

0

10

20

30

40
50
60
70
Distance nearest optimal solution

80

90

100

KS< 3%SO%ZS=J#SS%J1DDv8G8R%L#J#S#%YS#Sl%JlSFJMSO%JS#w%"#p
Sb%9wS-JS9#1wM?l1 |56%iqff<_V8W JD%J_w8L8N6.
JS-?%J fi Z3'
[ Jn, 7A8 9 :(;=<>9 :B;
W%0S< #JS%91FMS_%R%J
# 9Sv1S%#%
SS9S#76S %378SpJhMS%9W%?7R#.b#8%3%JS#<7NMJ9##JTS88kSS1.
JJJ8OS
*%v8M%
qM%#N1JS8'JbS EL8 87%9 fi.iBS#s8%p%%b%9S#<%"#JSJ8
G S1 S#MS%8_<%_%Jv E %R>uqJ%9 8LJQ SQ98
8%S8T%{1pv1Jw89%
%
%JS#%#$ MSN78Sp"k717Y 7N8 9 :(;=<>9 :(;ZW%
%?
JS%Y #9S%J19S# 6hSrSJR118JS % Q " #='hJ# #wJ88<#JS# %% p8%
%JS#wN%8M MJ9p#L88vJS1E7M? SJb#JSJ=SJS#L6S
% 78Sp"
%
$fi# , kGT%JS%#Qb<% 7N8 9 :(;=<>9 :(;*v%8M%%8%# Eb#JS%J1k%
MJJ#<M BUfi]A%i SO7% 7A8 9M:(;=<>9 :(;W%D%?7S<%#9#hJS#%#$ MSF78SpT#
ZM9 E,U%36%KSSSMS#S#8%pS9 98%J1{%9SG<%q9= k8J1# 7A8 9 :(;=<>9M:(;Ev8G8TS
MMJO78SJJi%J $fi# , J17YLJS#JTT ##1LJp,9M%78?#M9%SS%79
SJ % 8BMR%#HJSp#5r SuS1p189Su% i%98S%QSJ Y8%E
J= v8SJ1Z# 78 9 :(;=<>9 :B;.v8G8TSG9%##J $fi# , SJ %JqSGSSJS'6Sj%S8
#J#S#%# MS <8S98 JS#%##%SSQJMS S%%SbSJMl_<uvNvS9L #7J%
Sv8S6%<%J1 %
JS# #J#S#%# MS 78SpJlB#S 7N8 9M:(;=<>9 :(;* -B8%8FS
q7%M%#F% 7A8 9M:(;=<>9 :(;*Z%JS%#9S#lS)Q "$# %J ! 78SpJ8ZMSwS#D#MS%
#M9S#<8w8_GJS( ..S% %N109#JMS#%iFG%SNEv%SS#=%9S
%8?M%T9w8J w%'8 8w#9S%J106%v80SF.BS=%{KS<?vB8wB#%#
SJM{8%<SBSJKMS'S#.FVM{6S S'M{%JS#w%#Sq79%1D%8?%#
M?R18
%
%? JS%9 #JS%91%YGqJ1-179qS JJJ8B%JS#%#$ MSL78Sp"
SMS#SS#8FMS<SM%%8lM%%R#98vJ.h%#
% <'J7k8?1EFJ k8S91F#
6%w% #9S#%# MS# <8SuS#MS%SJMb%JS%#u9J8<S $fi# , 9%#NMS
S8v%S #Q F'J OK !on !#b8p#MSQ#h#S-SJ%1
/V %9SJ0v
#7J%7.8
%JS%#JJ98%
!L"#B9R BM V_FJS8"%# %98S% J#1S89%J8-8%QvqM#9
S%<9##
8S%#7179JSMS<% K%JwFJ= v8SJ1DG8SBSSMS#S#8%##qS#J 98%.K8%
W'C^

fi91#
gfiffgg



/ H

!








j


4
464
)
'&,
% ! &' &'
,A,( :1 ,
*,+ .
Oj 1J
' &,
0/1 ,AS,3 :
,2 *,+ ) ? Oj 4 4& H
' &,
" 35476 1 /1 7
,A,A :1 ,

% ! &' ( &'

%



ff
fi

~ #-~

~ H

H& &H H
4 464 4 464

4 4% 4 4&5#



U,A?A@,j -,U
% $


"! # $
J %H H ~/ J J% %
5# -4
4 ~ J 4 464 4 4 4
4 4 4
4 4 4
4%

4 41J

~

4 4&/ 4 <# 4 / #

4 /1J

4 # 4KH

%

AKA

H

*,+ -

ZM9 3B'JGJ k8S91 #0v%SSJi<%q9#S%J1GhSJiJMSZ%JS#<%#S#_ 7N8 9M:(;=<>9 :(;W
%JQM?1S7 '6%hMMJh#JS%# MSL78SJJBH8 H8w%J fi.8
J k8S91'MS7%SlS#MS#%F<%JJx<!%1S#%#S#JF $fi# , ?
7sfi]lB<JMSRJv%S
Sb.k%SJS#
JS9#1QSJwpJ%<#71q7p 3F6%
J b8J-JS%9w8"M%##M97#9S#%# MS#R78SpJ
6%FSJfi. J% JKNS#J 98%.-79%1
lS-v8SW%?<%J1-% D=1J8#J-w%98#J0SJMiiSJSGSl%SJ#J0Mv
SR1SwS( JS 6% 8M%JS#<%B#S9T%.,M7p8M #JS%J1w%
SJ,%JS#<%
#JSJ_ %%%qJS%Y #JS%J1 9MSS#89#MBG%98%SJM
%89MS%F#JS%# MS_78SpJ'<_7JS%=k8W%w%J1=#lSSJMSJp9
<S
%%J9%9#J1%h% %Sp8#M_BSbSJw8J#{JS%9#n#JS%918p#<#M%%8?JMS%
#J#S#%# MS78SpJT<HkJU JSM9 SM %%%?SJ<0SJMT79S1#.JS$ 98MS"
SJ? %bS 8%%v . hh#Sph%9 pqSJSp* 9% %_E%S#M h8S8
S#w##MFSJSq#H SJ1SS fi. 8DJ?#J89%Rv8%J_%'Sl#J1% Jw8J##
179JS#Tv%S i%J 7A8 9M:(;=<>9 :(;"6%'SJS%J18

: R
W# 98N8= =v )^ )gR#
<9#8%%Siv8S6%<%J1G%9SMYqSM<J8k9J Jp#v0SO1G%YSM9q.JS%
4-SP
F=S##J#J%Zv80JSq
##%q v1S%O.JSiW%D%#8#%SZ%YJS%
J
Ib,
%8'dc3MJJpk%CB.p5 B%?#{%8%#TS1%9 8<SJMGS<%#JSM9<S%
<M?NSMJMS#"J*%SF#9M9## T7S8MvF8%v%9S#<ppBJ##-#M%-SMYl.'8%
p#TSJ$ 98%EK88#%MS7#TM?7 v1S%S8. G8%JTSJ'i%98SMMSJ8EJ%
SSJ8iJ%S-J#J%J1=#l#1S#TSM9LS8J%9bSJ8SF#i7S8%S8S8%
9S 98U
S0W% JS868S#JB%E=YMSS#8J#M3U%#J3B#SJ#=h%%%YMJ9MS.S
S%JMYvSS#9##S#8

9<S#J1, k1'%DSJ%S,8 <7%SL#ib19S#.S_9#%'M?N#S8'iM%
i_6SmS-JMSG%JS#<%k#S#"K.SJS%#%.GhGJ#b1pk1GS=<MJ#SJB%3SJ#
9#%FNv<JS%v%SS9% S<SM9.JS 'K%80.JSSJJ#QW%?1bM?Q<M%
W'C'C

fi$4

$,ffZ

7%S
MY#w9S%%SSOG_6SmJS8pJ7SbS8Ji% S=MR9%1%GG9S#8GS
S1JM?#TB9# F#%J#qJS%%SS#=G<WnSBJMS{%JS<%J#JS"SJ?
SJMqSl8SS.q9#S%J1bQSJ_M0%9S#<%G#SH#0% . - 7; + ! <>9 :(;VQJ%
%. pB wh##"8%.SJ%##E%8BSq%%J.
%J<%7M?GM? S0M
%JS#w%#JS" -hG8%8{S_#MS%8qSwM%#b%'KSb<%SbJS%E R#q#%Q
7%<W S<MS=%9S#<%K#S# k86%S7#.%8SQp888q 8<
%GFpJ%<#
7pk% pSJ#GS%%S'SJMiS=<Up<%v#%w9#S%J1ff
+ 7S=MSSG%9S#<%
#JSN%98%R"
w#OJ%k%SJ%v BTJ%0SBNS9MBJS%YxJb8J_#
fi. #G#MS%706J91S7%5Sh k1S#%
SM_9%1
8 4 8 9M:(; 4 %5BJ

+ #
7%SJS%GJ( .S%EG
Ev%SS 8hSJMG%.<#J1%h#wSBSMYwS-%JSM#.
%S'SR# 4 8 9 :B; 4 "%JlL#68SJ1
JS%YdJw89%
F{S9#{..v%SS8%% JD1%<#OSJ
+ %JS%<JS
S%7Y##
78Spp
%%%8F_%%q%{SM9QS8
<1JS8q8) 8b?%J fi. 8kSk8$ 98%#lS E
#JSS%J1BhSA 8%fiTS%%l%JS#<% #S#J8O 9ST7%SM9NS #B9#1SM
NS7#.8SU%tP ,, + X,G {89S%k78P ,, + X [`P "uT MX, SJ#h9MSS#8JMBM%#
i%w7Y#8%##88< Z%##M p# %rv8SW%?<%J1NrS
8q 8
vJ9<MS #JS%J1%_l S_#79%1%Gv%SHS<%#80%J#MS%80SM9S_#p
8SM%#'RSFv8S6%<%J1=% , i%L1pJS%01v87ESMS#"0%98S%SJM
P uT8X'MJJSp<MSJbS<%=SbE8SM%{6%qBJ#? R#F<9#8% 4B-K*%
%Jqk1w#NM9kH##S8q#8%%JS#<R%0#1HS8J0%'S_M? S9%1%
0
_%8M%%9S
+ %9S%#lJJ8SP "uT MX3#E8U%vMS-SJ#7 V %M8OSJ%wSJ
%JS%#JbJ98SP uT8X3#.8SM%*.hJ#'SJ
+ %JS%#J_9J8q#MS%8=VMS9#M#7?M
P!8fiT( "3Xi#.8SU%DMT SQSJ# V %SM80SJ% S7%9S8S%JJJ8-SJHP "uT MX
#.8SM%*0M9Sp9J6%m%S'SRMF_J= v8SJ1'#lSJ7%LSM9R.JS
JJJ8'S P uT8X{%J&P "uT MXK#.8SM%#'%8?SJ'SJ P "uT MX{%JwP!8fiT3X{#.8SM%#8 0-%8%#*SJ
SS9SD1 JjS'ESJ#SqSJM{#MS%8{SMYT.{%T#91S% 4 8 9 :(; 4 6E%7%S

+ J%98S% J%##SMS%bES8%"J%%h# 7A; + ! <>9 :(;V
_1A JxS9Mh9%%
#
+ p#N1%SvJJ#<?J%%
#RJS%9 Jw8J#%JG
179J0S0%98S% 9J8 <6%-% JS%Yx#JSS%J1%8=SS80SM9S
#.8SM%#8 -B8S%h1J#8l%#08% #9S%J1l#uJ 8# 8 JS%Y 88SQ79##8#
%SS97JS #_SJMNS<##MlJ%J%N#
+ 6%N#JSS%J1lBS 8%p%%u%9S#<%
#JSJ8-8M8,9%S
%{SJSS9S# W%"P uT8X{%8J P "uT MX%9&P "uT MX{%8J P!8fiT( "3X

#E8U%#GMS
Sv1S%#<Sh_<S
86G%J_#EGS#%3KST( /'J B9J8
S77JJ #E8U%9P "uT MXMS7JR# V MS%8=SJ% ST%9S8S%JJJ8hS7Sw%#8
P uT8X"#E8U%*EBJ#iS i%9S%#<J98{S P!8fiT3X5#.8SM%JMS'SJJqMT V%SM8GSJ%
SO%9S%#7JJJ8ZSJ P "uT MXk#.8SM%*EM%#"E'M#9OSOp9J6%j%S'S<MO
J#1S89%J8OLSJ k8S91F#N7%RSM9NS%0%9S8S%S#w##MO7%J=%SBS
#qJS%YJw89F6%{F#<qS%79i%k8%w#M%8D.'#E8U%# 0-%8?%#*%SOSJS
S9k%O-.k%SJS#'S9Mh#MS%8-SM9.JShJ1S%0JS%9 Jw89%9Sk8$ 98%#_.
# &YMS# 4 8 9 :(; 4 6, 4hSJL%'S8v%SLJ8S%JG%JJS#J%#7%9S8S%S#w##MiSSJ#SiR
S<%"S%79
%{RqG%S &Jj%J &JBS%5
fi
0
J1pk8?#7.S#J9#8M'SJMSBSM9bS 6% J#7vB?$
"! !jL ' "!
mfi"K ! ! 2 0BJ##hS#qJS%J8JSw%#J#JTSMNSSMJMS"{L%JJ#S_7JSp#J0SJG J
S8%S8S8%#G
SJS$ Jw9###JB6%'1S#7qSM9lS%SJ%Y8SMMSl79J% 8iS
v%ES%#R8?#7.S%DJMSS7%iS%S,8? 77%S%T 9MSS#8JM"S7SS9S-JS.





W'CL

fi91#
gfiffgg

1e+08

1e+08
y=x

1e+07

1e+07

1e+06

1e+06
[10,18] tabu tenure

[8,14] tabu tenure

y=x

100000

100000

10000

10000

1000

1000

100
100

1000

10000

100000

1e+06

1e+07

100
100

1e+08

1000

10000

100000

1e+06

1e+07

1e+08

KS<(/
3 p8M8,9%S-%KSF#MS%01S =S(Jlbp8M0%R%JS#<% #SL9J8
<W%-S<%#3%8SJh7p8MqSM9NSTV86%JO%J7J8M%8J
#MS%FSM9N.6. J?W%8e8<%9 fi. 8
[5,10] tabu tenure

[8,14] tabu tenure

Mv%<SJ%%FSJM ASQ%7J.=%G%S,8 7<%S#Q11S=%GSJM
BJ#? #
S(JS
qS8MvhS
M%1%O9%#J{% 8%9%JS#<q##%TT8%%-S-k8W%w%J1B%
_ W M,
| K}7~ %
0

SJS-JS#JqlS9 98%.J?-S8iM8%%Y#L% JJ8SS%JJ#b%S7.
J%<87JJ8##JRSM9 M?" R9%R#.SpJJ1 %9 G%#H7pi%
%##M*)
SM9LM?L%%%#SJmW%OS2 fi SJM89S9
SiS#79#8%%81J.S'6%'Mw%Y%
MM#M9#N#QS71S( .9SN8M7%9S#<%K#S#J-L%J fi. 8
4-JJ#SJ%#%
Sq7J3%81J.S-W%-S#<#Mb9LJS%v%SS#JO%DS0UMM9## _LS01ShS( JL
p8MOv%S7S,%JS<%p#S9 %J fi. D%JT%JS<%#S#JZF7%S'91SS
fi. 8J
0

SS9S=#JJ8MqS9MFM# %##M* )-%%%#SJ 8%vT8G%FlMM#%.
%Dw?%E6%SiMNJ1J#7JJ%v%JJdG%#_S9MB1J9Si b%8Lv'%D9#%( 3h
H9#%<GM? S#SJ<SJM_MSJJ ( .JJ#S%.w6S SJQMw%JS<%BS
%JQ#S#JOSJM
MST<Up<%#lJ#S%.B6S SqJMS-%JS#<% #SR%J *Bb9#%
SJM7J9T<%#.S%# 1JS#SETJS%%S7S8TGMr%<i 6S SLMSS7%JS!
<% #S5GR1.%-b1S-7p#'%DJS%9 Jw8J#l9%RSMSM?S9%1
6MSS8DS_%JJ i%7pG#qS8%#M9_%JHJSp#qJ10#JEq#.RSlpJ%T
#8-%SJTSM9S182 4h9JSJ%%9G<#.S J%J1pk19RSJl#lv8G8
STJ,S#7T9%<#8-%SM9SM%J#790WMSJS
%S7J98p#wSMS9%1%
BJu9Sp#_% 19%JMSu6%lSJS#%'J81Sl%J JS#<M6%#SN%bM?#8
78 9 :(;=<>9M:(;i<G%hJS%9 J#w8J % 4hSJ LJ%N%7VJ#1p9%S SlJJ#1S%
8M9M9#S
%OSw%J i%7p*3GQ%vJ#%=JS9#1QSJb7p{J%
v81 97SJS1pv8#7.SMSH%JJ fi. U 3SJwV%##S7%'JS#%DSJ
HJ 98%.S #79%1<%%%?SJ v8S6%<%J1%J SNv%.S#%# 87ES%BJMSSN%
S%,8 7<%S%
W'C



fi$4

$,ffZ

-9#wS_SJ81S0%iSw%9 i%7p*Z8%8%G#SSFS<%#HJS#%"_J%
1%79%Z=#FJJ8#M=BE N#=JJ%NN1p9%7k%.S#%###MS%wS8J=% 8 9 :(;
*%%B.F%9 8%.%JS#whMSO%D1SM#=8JS.SMS%i%YSJ3#
J?#
M5p#<#M%MF8%JS%1p9#%9MSTW%SO9#%KGM?bSJKSJM{M'SJ#
(J!J#SS%E{6S %JS#<%Y#S#J{%J_#S#J{<U#<%##qJS%EWs%JS<%9SJ
#
#%#J5%S J##<#9MSl8#JJ1qJJ#8M
ST9%--#79N9T_SJ<#17%
S8JESMS#"9*%S9#JMS_Ev88v%
Z8JMYhSJq7S
7v%SS%E-1E?9S%{Sq%JJ i%R<Z#hSqWJ9JMS
=Jp#=6%VSS7M5LSM1,%W,S1MSTSM9HM?%%%#SJ<=6%S
fi. <M%
1pJS%R9N%=M,8 77%S hB#- pqSJSp*GM% ?B%9u<#<9J8Mw
SJ?<77%qh##p#79%1DSJBJ1SJSO%vSO%JnG%77p*DRp#Fv8%JTS fi. Z
S8S'KS .JST%v%8%#$ MS* 3-#<##MZSS9SD#TBJ71JS#8?#-SM97M?
%%%#SJ<F6%q%S8 <>=
JM?J%9<8 %DS+
.J%JMS#<%SJ7.0%JHv8qSMS
&JOS% S9J##L9S%9< 4hSJS_7p{%JH%Sp8#MH<8SJ%%8%v
%#E6%SiMJMJY# %S879S%9<Z8JS.SMSJ8{%9H8% #8%GM? %%M
S9<8v--9J8M fim pK hB8S8
GT8% 1pv1=Sw8.-S8J#M#ShRSTSJS#
%JS<9S%9M9#SZ0p#b%88M-JSJ1SJ8K'J##Sk8%#qB6%GJS%9w{#
BJLJ9b?J1SSLvJ?J<MSp'MS07%SFJ8U%.8J%k# 4D=JK#9%#%SF?%J
i%N7p3#YM
%h8JSS.S%kMS%l%{J

\mW"K !on # K hJ%B -#BJ98MhSJQ
7pv<.Ov
#8%8M%N#_%8Ob8%%N#79S%lSM9LSMN%#%%SJ<{%'1%T
9%M%SJ338MZSJMZS9%"iMT#S#J"SJMKMS9#S%.5W\%JS<%ESJ
S9# v<<#J#w 8"5F#F6M0WS %.pJ SJ#F8%k<%?J8%"Np#w##M%5%J%S8
v%ES%kM99##8MSb%3SJ-?%JmG%#b7pk#E%#%iJSJ#1SJ%9mJw8J#k
SJMTSL<J%EqV%1%<# &YJ8#RJS%9 Jb8JHSJ fi MSlv1<#Qv88
JJJ8" %%#JF1p08 #FQ%J% 8wBJ8S8FvSSYT%98%b%88?M
S#wM'%KS2 J%.SSOB#SL<#J#w%Y%h7J8M179JSMSJ%" v%S8
'J%
1S%O%YKSM?TG%K F0SSW I-SivJp%Z%9SM97M?7%%%#SJ<8
JS S5
fi. %w v"r S9#T%%*iN9%J818" 0=7%J G% 7p
8MJS5SJp,S#<KJJ%w#8"%SM9FSM0W% fi R%819ES W% S9#<MShvJp%
%v#E8U 3 SJ'1{S( JSq#8MO%JS<%#S#JZFJS%9#jJS%J18D'JGv8{%
Si7pE# VSS8Z###JSM=FS MY## -=%81J.ZW%D%JJ#SJ%%vJ%?%E9J7J
%J 1%SS1S#uJSJ1_%-k9p%8' 8M86J-7p##J%J %J%pS#bJ%
79M7SJM9OSJ{ v1S%S8.SM9wSMb%%%SJwKW%{SJ fi. MSB#TV%1
JS79F#NSB%v8MS#"O'F%9xi%L7p3SJJ#L8S%T%-wJ8VJ"Y%S#O6%
1p9%#J-S<##MK#SSJZ0SJ'1E1p%Yk%S7<%S'%M%J1TSM9<M?<%%%?SJ<Z6%{S
fi. u%JLSM9RM%%%S9<O6%'%S8'<>=
JMR19JM%#%v%JS< MSL9S%9<




q9 F



p%J9#b=L0J#S9Svq#Mv%M%SQ%v8M .p%J9#NG%Sv%MS"5@c3J8p RMS#
G7Y%E%UW%3SYbh90SM h8YMSS7.5%W8S%
JJJ8v1.%1RD4Bi "4ffc"#M%%p
'JBG%SRi%=vJ%QR9M-RSJ 4-=%1 0
w17%ip8#ES
''SM"4h=%?1
M8Zi<<%J"Jb
4-GYJ98O%%.hJv8B E%%MU /# /#/p='J bvk-%8?J7.
#K%S%? 8T=S8JSpJJ1O%JTJ9JS8J?#ESZ6%-%8?J7.S%J9kS % BSJSS%Jp
W'C

fi91#
gfiffgg

#7%._1%.iJ%SMSLS8S85'=%S%?iJ_%
7SJ%LRMS8 S888'6%
v#.S#Fi &9 BSb%_M#8G%8Sb%5i78Sp%%wW%GS#<MSS-%JS
JS%YM9##S##lSJpJ%<#
1-7J*DZJ%#%GF%M8VJ#_%Sph%SJ=1p18JS#p
%#LSJEVJZ%JQ8S%#W8J9%SWS ST%.<J-S8#88YB9#JM9QJh
S9 98%.Sb#<JS%=J'%#9%Y9S.SMS"

E C fi
$

1

4hJ98M%

qO G%YGj=%p? 4 179SMS9%hS9 %FSL
%JS% S9J##
9 S%9L fiK1 fi K KMLUm 1Wn K*? E_xY(%
iM8 fiJ iJ%0v88.fi'%#? ##JS
%uS%uJ9##QJS%9# hS SM9
SM"
" !#5n K !ff fiY# CB5x%#/
GSk
fiY v5K*M%%E? -pJ%<#=9S%9 J1S%J%pS#'%-<Y%S#'6%h19%#.
9S1NS?JJ#T#SS#88 -n n ' fi 1> fiv? /pjx "pM
i#
8 8B# % fi hwS%%kjk " 'Z%%?h'
%SJ%S?JJ#TJS%9 3YGp
%.SJ%O%9 J8 S#S 9J$ 8 "
1 ;Kjm W*K 1 fi'K hFm n K fi ! QE
Z?Kjx /#/
G.S%'7OF%JE
40O JJJ5Ok=%" .? 4 8 %JMJS#% qJSSMSlJ9$ .J6%
109#9M%#%"%Y%v%JS#< MS#J8Fm # n K ! ! Q)Q ^n n # ! *?Z8jxY%( /
i8S<%"ff Z3F%J86%ff - %5 G%p?_ 8SwS ' SJM? JS%9w=MS%
K !K hUn Q h-n Q n fin K fiWK n K 5h DK n ' fi
9J5N /#/pjx /#/CB.
i#MY qJ%kN fi9-.8J9R%1.S%'J 7YN 09j%#S5pF3%%?c5p8%"M?
%9<SBJ0v8{%"#S989<S98B-Yp"? K !K hUn Q jK JI n #
n pK fi K 5#h ##fi K fi#m ! J
_n !UK h K !on n ;K ML L U
955%_xY( /#/3J#J%8 D8#M
-<S%,S'KN.SpKkK`b % 'FG%# "? 9J<M0W%qS%J9##lJS%Y<8
"01 Kjm W*K 1 fi K;h!Fm n K fi !# UQE #" ?K( /CB5xY JM
##8Yj%# "? $ n ;K5*I 1 5n K $n
K +K 2 +2 ' n ffQ K I%on !NmCmC n K !VBJJ!
S#Y? D*3M fi%Jl #8l%J98

MS8%-% fiJJ"E qB 8SJ, 'CBM?x'1791 r%
&9BSJ% %J
%YS%
J9##
Cn Q -L n ! K;h&Fm n K ! ! QE ff' %_B5xY%

fi ffw8 -9 'J79"JqWc{5%ME? 4-%%#SJ<W%'##J0JJ91SbJ9##0JS%
#<8Fm # n K ! ! Q.)(K .? T"CB5x /

%8OGO c3M9JpiF%CB%?
2&1 Q.nF#.8+
4h8%J<#P
9#S8. S"
%SS%?.98S8
--
8k,
--# "#"? G.#S?JJ<W%b%JS#<%h%J%##J
Cn Q -L n !>K;h*Fm n K !
!# QE/+K*? /p%jx /%%
-h.8
-0{*M%? 4s<!pSS1< 6%=S7vJp-%ificK%%%SJwh6%0 4D= K
! K;h n Q " Qn n Q n K fi K 5#h ##fi eK $ -n # , Jn ' #fi -
".ff'
959%pjx%CB.* 44 4B {S ?U'R {S8
W'C7

fi$4

$,ffZ

JnK Q !on )QSK Q 5n QuK5"I ! K5I ! tmCm n K !? " q SJS#8

MwS%'b-J%8_%D3?J%%%
fi%"#4.\N88%5pk9%%?*-88<#9#S#
%S%<J9##3#K%8JE8.%J7VSS%
"01 Kjm W*K 1 fi K;h!Fm n K fi !# UQE G+Z*?*
/%M3x T/"
fi%"
4 'B%%i%0% - R88%"Kk*M%%E?
h8 %9 I%S%8
%JS%#Ev%
J.pJU 34 Wp8JD<S'78Sp7% BB#SpJ%J_p0JSJ#Sp%%?)fiK 1 fi K h &1 !-n #!?
.? TCB5x T"Mp
=7.% fiJYsp* fiJ3%ME? pn
jiMK Q !_VKOJ#SY?. q {%5
h%9"
F.9M?#SkkG-#M8O- D8?J*ih# "#/? 0-9S#< MS S#qJ#M %JJ%##
# fi 1 ff ff"UkCBjx# "Mp
c5JSJ1. -0RMSS" 0q{ %D=B*M% /? 8Mrp8%iM?"Hr
%8{G
F?Ev8S%8kq pJ8? J+I 2 K5KiK;h 5n Q &1 !-n #!?9#EG8 4-8%<#2 9#S88
MW#5N q %%?
" K 1Wn pK fi Q JIn Q fi+K 2 AQuKjmY .S8U D8#MN -h#v8S
MW#5 q* i8SB#SS"k-"m=%J68 -D%%?
4nM?9%17%J%#S'%SJ
%S%
J9##TJS%YL fi !\K h!Fm n pK ! !# UQE (#U Jjx T#/
hB#,3'M pqSJSp*U-.%%? 4 V%3SMvhM?q%%%SJ\W% S*
%0%J%9L
fi -L J
n fi #fi 8 ffD*?GBMCB5x "p( /
hB#,F'K 0S9#Sp*Z-G*M% ? ^n Q $1 !on Fm n L n pK
^L"K S$ JI " K
1Wn pK J39M5Z7J
h8n%F#-W% fi%Hp%Hp?JJ#kJ5D# _xYMp_#EG8
4-8%<2
Y##S8?8
ZU U8##pkksR8S##*WB *M%%E?E
4 SMYRM?R78SJL9#L_J6S#Tv%SSl6%
SJ
%NSJ%NS9J##0JS%9#L "01 Kjm W*K 1 SK h!Fm # n K fi !# UQE +ff "3*?
%CB5x /p8p
''88%Z-{%# "?"c3%J9S8Mv8Y%v8M%?F%J S#qM5 fi !K h Fm n pK !
! Q.)(#M @B /_x EMp
p? k8N 'FYsRi%% fiJ3%ME?
K 2 +2# n JI n Cn !-n #!h-K " !b /UL9SY?
=E
9#SJ#JqG79%.%N G"
p?.JJ<%J8, 0O S8%G=*M%? c5p8%hSM 9M%18#S8w%J1798 4D
9S19S8 -n # n fi 1 +ff ff'KpjxY( Mp
p#J%8R fiJ'*M%%E? +QTS!-K 1Wn K ! 2 Q ;I&nK fiI ff h Cn 1 'n Q K SwK h K !onYh^K K
!# Q K n QL K JICKML ! n ! +2 ' pn
!on fi !? 5 0DSJS#8vb-J%8S#%
J#.9S5
p#J%8 fiJ9-E89p<%#* 405*M%%E? i%SkJ=WM#b%JlS=p8%kSMN1SOkMk
W*K 1 fi K;h -n n ' #fi !# QE/ ffY# /#_xCBUp
p#%J8% fiJ"m%S""=D*M%? i%SvF#%JS#w MS %J MJJSp<MS"
P
h8v*
-Kp"? ;K !K h\n Q n n Q% n # n pK fi fiK n K _#h ##fi K
Jn ' #fi
" J95J# "x# %"R%S%F%V<%J"
S%J#8 ZO*M%?Z#SSq#%JJS8Mv8L&c3%SS#KK {%#8?#%J*ff 40OpJ8?YR pK K
" K 1Wn pK $ J
n n !on QTS"! #!?JJ35( "CB5xM|B.5pJ#%8S D8#M G8##"
-h.8R-0O%#"?

WL

fi91#
gfiffgg

%S8'-p"Ykq9 {%88M*N'"%%?.h8 M?N9%1i6%'(J8#J0J%9<
hSLMJ9#8MSl
%RS%RJ9##$
^L #n fi# 1 (Z8E?K E#_xY(M
Z%###M5'5%# /? GJ?J<MSpi6%O9%S#
S?JJ#J%9<8)"
1 Kom WK*1 fiSK h!Fm #
Cn pK
!# QE G*?"C@B "_x# "#
Z%###M5'D%" .?2 KM%# SMv.lM??JJ$ hW%
S%
%QSJ%QS?JJ#<J%9L
fiK 1 fi K KMLUm 1Wn *? 8 "_xY%_B.
{MS98 'v%# ? # I!W+K 2 AQuKjm Q *I 1 ff KMLUm n I\QK QE " q
SJS#8#JJ%@bh9%8S b%K J#%%%
M%gc %M%" Z 4-MSS89BO2c3JpE fiF%%? fi% S% S9J##H. S#qJ#M
%9%##Fm n pK ! !# UQE "3?K%( /_xY#
MS" fiJ*M% /? "9LUfim AK5I JI S"! !UK hQSK UQ ) K n Q|L !h^K 'n Q W+K 2
AQuKjm fiQ *I 1 ;+K 2 -LTG 5 0vS#8 -89MS7E
%OG798Fp891%"G#%%
pSM\b-J%8S#%
MS" fi iMS9J8"c{ J#S8%Sc{K -hG% 40G*M%? GE?%S#RSJ1SSH%J
?%Jmv80JSMS
&JO%LS9J##JS%9wU 3pM?L9%1
%v%%_%Jl%%M
?SJ v8S6%<%J1% W*K 1 fiFK KL'm 1fin i*?v# "_xY# /
MS"* fi Y* fi -B% 4v JS8%Jc{ *M%?' iMQ<S1#JS%F7p"%{p8%
SM1=#
%JS% S9J##h HK ji ! QuKjm7K nK Q "!-n Q K pn Q|L ! n
n Q ! #n #n Q% n fin K fi WK Jn K 5h K Jn ' #fi - "U
MS" fi GSk fi -hG%N 49j JS#8%fic5*M% /? {S%Y Jw8J#<6%OSM9lM?N#

%SJ%RSJJJ##J # n 1 K*?Z( "%_xp_B.
88JJj #p8 43%# ?DJ8SS#b?JJ$ i6%iS=#SS#BS_%3S,
%
%NJS%YL !## ^n Nm|m n Q ^L Cn #!? (% pjxp%M

WL

fiJournal Artificial Intelligence Research 24 (2005) 465-518

Submitted 09/04; published 10/05

Reasoning Action:
Argumentation-Theoretic Approach
Quoc Bao Vo

vqbao@cs.rmit.edu.au

School Computer Science Information Technology
RMIT University
GPO Box 2476V, Melbourne, VIC 3001, Australia

Norman Y. Foo

norman@cse.unsw.edu.au

Knowledge Systems Group
Artificial Intelligence Laboratory
School Computer Science Engineering
University New South Wales, Sydney, NSW 2052, Australia

Abstract
present uniform non-monotonic solution problems reasoning action
basis argumentation-theoretic approach. theory provably correct relative
sensible minimisation policy introduced top temporal propositional logic.
Sophisticated problem domains formalised framework. much attention
researchers field paid traditional basic problems reasoning
actions frame, qualification ramification problems, approaches
problems within formalisation lie heart expositions presented
paper.

1. Motivation Introduction
need good reasoning action formalism apparent research artificial
intelligence (AI). Alongside logicist point view artificial intelligence, recently,
emerges cognitivist situated action-based approaches(see Kushmerick, 1996
references therein). latter approaches provide immediate practical
answers certain issues AI. current problem domains (Soccer) Robot Cup
seem area approaches promise gain fruitful results.
hand, logicist approach aims long term solutions general problems AI.
logicist approach, formalising dynamic domains reasoning action
realised within logical knowledge representation. general idea intelligent
agents able represent kinds knowledge uniform way
general problem solver fully employ find solution based knowledge.
turns out, difficulties general approach AI. Consider task
formalising dynamic domains logical language. formalise dynamics
action (or event) language n fluents 1 , one need axiomatise
fluents effected action also not. Essentially,
requires n axioms asserted. formalisation hardly considered good
1. fluent technical term referring functions predicates whose values varied relative time.
c
2005
AI Access Foundation. rights reserved.

fiVo & Foo

representation. Hence, need solve problem logic-based reasoning
action formalisms. well known frame problem introduced McCarthy
Hayes (1969). Moreover, still problem axiomatising effects action,
called effect axioms. logical axiomatisation requires conditions
effects take place executing action precisely specified. However,
potentially infinitely many conditions, reasoner may never
thought about. realistic formalisation would ever able exhaustively enumerate
conditions. Nonetheless, start car, people worry whether
key car. never bother checking whether something blocking
tailpipe checking electric circuits make sure well connected.
story long well-known within community commonsense reasoning,
particular reasoning action. known qualification problem
introduced McCarthy (1977).
number solutions frame problem (e.g., Shanahan, 1997;
Reiter, 1991; Castilho, Gasquet, & Herzig, 1999), qualification problem largely
ignored notable exception Thielschers (2001) solution within Fluent Calculus Doherty Kvarnstroms (1998) circumscription-based solution using fluent
dependency constraints. people argue frame problem already challenging would good approach thoroughly solve frame problem
complicating formalism qualification problem. argue danger
approaching problems point view (at least) two reasons:
1. may hard come uniform solution problems: many
existing solutions frame problem monotonic (e.g., Reiter, 1991; Castilho
et al., 1999), qualification problem inherently requires non-monotonic solution.
case original qualification problem stated McCarthy (1977)
dynamics actions/events need finitely axiomatisable
unexpected qualification action arises, agent must necessarily retract
initial expectation effects caused action would take place, making
underlying reasoning machinery non-monotonic (see section 1.2 discussion
qualification problem).
2. Many solutions frame problem succeed precise assumptions.
instance,
Actions always succeed. action omniscience assumption. precisely, assumption dictates qualification problem skipped.
case monotonic solutions frame problem. 2
Fluents change reasoner knows exists action
possibly changes value. termed domain omniscience
2. argument solution frame problem works nondeterministic action
subject assumption stand. quick fix allowing approach fortiori express
actions may fail representing failure possible effect invalid one.
longer infer that, absence evidences suggest otherwise, actions would normally succeed.
also worth noting Lins (1996) extension Reiters (1991) solution frame problem
Situation Calculus deal nondeterministic action based circumscription.

466

fiReasoning Action: Argumentation-Theoretic Approach

assumption. assumes reasoner complete (ontological) knowledge
domain reasoning.
two reasons course closely related former arises due
underlying assumptions latter longer holds qualification problem
taken consideration.
remainder section, review several works topic introducing
reader approach.
1.1 Frame Problem
late 1960s, frame problem recognised major obstacle formalising
dynamic domains (see discussions exposition McCarthy & Hayes, 1969; Green,
1969). Several alternative responses frame problem proposed along way.
respond explosive number axioms required theorem proving-based planners
proposed Green (1969), Fikes Nilsson (1971) introduce procedures operate
special data structures used represent dynamic domains. However, complex
sophisticated problem domains, e.g. domain constraints, concurrent actions,
observations different time points, etc. STRIPS quite often fails express domain
knowledge. fact, expressivity STRIPS quite limited pointed
Lifschitz (1987). Another response attributing frame problem artefact
situation calculus proved ungrounded. attempts distinguish
logical epistemological aspect frame problem computational aspect
(e.g., McDermott, 1987; Kowalski, 1992). computational inefficiency associated
representation dynamic domains situation calculus attributed
explosive number global situations required situation calculus argued
Kowalski Sergot (1986), logical aspect frame problem inherent
logic-based representation dynamic domains. thus essential logical approach
AI knowledge representation decent solution frame problem.
Later, introduction qualification problem McCarthy (1977),
reckoned formalising dynamic domains solving frame problem
would require systematic studies fundamental issues knowledge representation.
early 1980s, frame qualification problem considered instances
commonsense reasoning problems. particular, many believed non-monotonic
reasoning framework would solve frame problem. argued principle
inertia3 considered key frame problem formalised terms
default rules default axioms default reasoning. Moreover, also argued
solve qualification problem, following common sense law rendered:
action, default, would qualify succeed bring intended effects unless
known reason to, formalisations dynamic domains.
introduction several non-monotonic reasoning formalisms, e.g. truth maintenance systems (TMSs) Doyle (1979), default logics Reiter (1980), circumscriptive
approaches McCarthy (1980), modal non-monotonic logic McDermott Doyle
3. principle inertia common sense law inertia basically states default fluent
assumed persist time unless evidence believe otherwise. reader referred
Shanahans (1997) book details principle issues around it.

467

fiVo & Foo

(1980), autoepistemic logic Moore (1985), etc., believed problems
solved. solutions problems illustrated examples proposed nonmonotonic reasoning frameworks. instance, McCarthy (1986) showed circumscription used solve frame problem relative blocks world domain. Unfortunately,
Hanks McDermott (1987) show formalisations work correctly
simple dynamic domain known Yale Shooting Problem (YSP). review
successful attempts solve frame problem:
1. Baker (1989) successfully modifies original (and incorrect) circumscription policy
proposed McCarthy (1986) deal Yale Shooting Problem. traditional circumscriptive policy, predicate Abnormal minimised predicate
Holds allowed vary. Baker suggests that, instead allowing Holds vary,
function Result one varied. solve frame
problem full generality, initiates line research brings many
fruitful results reasoning action community. detailed discussion
solutions follow works, reader referred Shanahans
(1997) book. Furthermore, Foo, Zhang, Vo, Peppas (2001) present exposition issue automata system theory point view. order
Bakers (1989) solution work correctly, additional axioms need introduced,
e.g. domain closure axioms, axioms existence situations, etc. emphasises that: (i) circumscriptive approach reasoning action works
careful designation considerations domain; importantly,
(ii) circumscription domain dependent. is, domain dependent circumscriptive policy required correctly render common sense particular problem
domain.
2. number researchers argue many cases, monotonic solution frame
problem sufficient. Pednault (1989) assumes effect actions fluents
specified effect axioms following forms:
x, ~y , s) F (~x, do(A(~y ), s)),
+
F (~
x, ~y , s)

F (~

F (~x, do(A(~y ), s)),

(1)
(2)

Here, A(~y ) F (~x, s) parameterised action fluent, respectively; +
x, ~y , s)
F (~

(~
x
,
~

,
s)

first
order
formulas
whose
free
variables

among
~
x
,
~

,
s.
Pednault
F
(1989) makes following Causal Completeness Assumption:
axioms (1) (2) specify causal laws relating action
fluent F .
Note Causal Completeness Assumption stronger form domain
omniscience assumption presented above. assumption, following frame
axioms introduced:
F (~x, s)
x, ~y , s) F (~x, do(A(~y ), s)).
F (~
468

fiReasoning Action: Argumentation-Theoretic Approach


F (~x, s) +
x, ~y , s) F (~x, do(A(~y ), s)).
F (~
Schubert (1990), elaborating proposal Haas (1987), employs so-called
Explanation Closure Axioms following forms:

F (~x, s) F (~x, do(A, s)) F (~x, A, s),

(3)

F (~x, s) F (~x, do(A, s)) F (~x, A, s),

(4)

Or, equivalently, rewrite two axioms follows:

F (~x, s) F (~x, A, s) F (~x, do(A, s)).

F (~x, s) F (~x, A, s) F (~x, do(A, s)).
Schuberts proposal correct following assumption, called Explanation Closure Assumption:
F completely characterises actions cause fluent
F truth value change true false; similarly F .
Reiter (1991) combines merits two proposals systematically
generating frame axioms proposed Pednault (1989) quantifiers
set actions proposed Haas (1987) Schubert (1990).
researchers also propose monotonic solution frame problem include
Castilho et al. (1999), Zhang Foo (2002).
3. Attempts solve frame problem using default logic (Reiter, 1980) also encounter
problematic issues. Hanks McDermott (1987) show natural formulation Yale Shooting Problem default logic suffers problem
circumscriptive approaches, viz. existence anomalous extensions. Morris
(1988) proposes slight modification Hanks McDermotts original formulation
Yale Shooting Problem attempt avoid anomalous extensions.
pointed Turner (1997), Morris formulation complete, thus eliminates
anomalous extensions Yale Shooting Problem, unsound. importantly,
Morris formulation clear dynamic domains formulated
general. Turner (1997) proposes way formalise dynamic domains
using default logic (and also logic programming). solution based following observation: Yale Shooting domain similar dynamic domains,
anomalous extensions arise undesired effects action derived
reasoning backward time. instance, Yale Shooting domain, making
469

fiVo & Foo

counterintuitive supposition victim shooting somehow still alive
shooting, anomalous extension come following way. First,
allows default saying victim persists alive regarding shooting
action applicable. consequence, gun must loaded
shooting action. Therefore, blocks application default saying
gun persists loaded regarding waiting action. words, loaded
gun would get unloaded (magically) waiting action undesirable conclusion. block lines backward reasoning, Turner appeals
non-contrapositivity inference rules replaces implications inference rules.
guarantee formulation work correctly, additional techniques required
fact formulated inference rule:

false
enforcing completeness initial situation adding following rules:
: Holds(f, S0 )
Holds(f, S0 )

: Holds(f, S0 )
Holds(f, S0 )

every fluent f .
However, Turners (1997) formulation still fairly ad hoc different techniques
added fix known issues. example, inference rules used place
implications block application undesirable backward reasoning,
rules completing initial situations added overcome unsoundness issue
Morris (1988) formulation, etc. also shows problematic side default logic
uniform formalisation various problems common sense reasoning. becomes
serious issue one proceeds question qualification problem,
typical problem default reasoning, solved Turners (1997) formalisation
dynamic domains. case, example, instead asserting
victim dies whenever shot loaded gun reasoner maintain
default proposition may many hidden possible conditions
victim may die. Thus reasoner able deal surprising situations
victim observed still alive shooting action (of loaded
gun). Another, symmetric, case surprises regarding persistence fluents.
instance, waiting action, supposed unload gun, gun,
loaded wait action, observed unloaded. scenario
first introduced Kautz (1986) scenario called Stolen Car Problem.
cases, reasoning backward time necessary. clear
rendered Turners formulation explicitly intends block backward
reasoning. scenarios analysed solution present later
paper.
1.2 Qualification Problem
several solutions qualification problem, none addressed
original qualification problem introduced McCarthy (1977) later formalised
Ginsberg Smith (1988).
470

fiReasoning Action: Argumentation-Theoretic Approach

1. Lin Reiter (1994) propose formalisation action theories situation calculus (SC). formalism extension Reiters (1991) solution frame
problem (sometimes) incorporating state constraints. discover
least two different kinds state constraints call ramification qualification constraints. go claim solution qualification (and
ramification) problem. basic idea behind solution qualification
problem certain state constraints imply implicit preconditions actions.
Thus action may qualified even though appears (from explicit action
description) be. course special case qualification problem, classical qualification problem introduced McCarthy (1977) much
broader extent. setting, qualification problem pragmatic issue
technical issue. Similar frame problem, impractical, sometimes
impossible, axiomatise possible preconditions action. example,
addition requirement gun loaded, guarantee performing
action shoot would kill victim, many preconditions must also included as:
gun malfunctioning, shooter miss victim, victim
wear bullet-proof jacket, etc. among may improbable
as: alien interferes bullet. reasoner simply want consider conditions assuming case unless explicit
evidences stating otherwise. words, qualification problem original
form requires reasoner able tolerate mistaken conclusions possibly
jumped previous inferences correct appropriately. Henceforth,
always refer qualification problem original form. similarity
frame problem led John McCarthy conjecture that:
frame problem may sub-case call qualification
problem, good solution qualification problem may solve
frame problem also.
(McCarthy, 1977, p. 1040, italics original.)
Roughly 10 years introduction qualification problem, McCarthy (1986)
presented solution problem using non-monotonic formalism circumscription. However, solution suffers almost identical flaw counterpart
regarding frame problem: simple minimisation abnormalities sanctions anomalous models (e.g., Thielscher, 2001).
2. McCain Turner (1995) propose solution problem described Lin
Reiter (1994), viz. problem deriving implicit preconditions state
constraints. McCain Turners solution posed model-based representation
action theories.
3. Similar McCain Turners (1995) result, Baral (1995) offers solution
problem defined Lin Reiter using state-based representation. Baral extends
language disjunctive logic programs state specification action
description language.
471

fiVo & Foo

4. Doherty Kvarnstrom (1998) make careful investigation qualification problem. aware shortcomings present definition qualification
problem introduced Lin Reiter (1994). proceed one step distinguish weak strong forms qualification problem. deal
comprehensively qualification problem full extent, Doherty Kvarnstrom apply circumscription predicate plays similar role predicate
P oss used Lin Reiter (1994).
Even though Doherty Kvarnstroms (1998) solution closest spirit
original form qualification problem, still serious problem
approach. intended designation predicate P oss variants actionoriented. is, would qualify executability condition action
consideration, towards effects action supposed cause.
words, circumscribing P oss guarantee capture full extent
qualification problem. example, single action shooting gun may cause
several effects: killing victim, making loud noise, emptying cartridge, etc.
conditions action executable is: gun, gun
broken, gun loadable, etc. action executable, necessary
effects take place. may case loud noise
cartridge emptied victim still alive since victim wearing bulletproof jacket. Assuming reasoner somehow aware possibility,
include requirement victim wear bullet-proof jacket
qualification action shoot? Perhaps would still expect
hear loud noise cartridge emptied shoot action.
end troubles though. presence qualification
ramification constraints causes several complications. Firstly, syntactically distinguishable. Secondly, mentioned Doherty Kvarnstrom
(1998), qualification constraints may cause indirect effects arise vice versa, i.e.
ramification constraints may reveal implicit action preconditions.
Remark: terms ramification constraints qualification constraints first
introduced Lin Reiter (1994) careful examination state constraints
taken. discussed Doherty Kvarnstrom (1998), two kinds constraints might interact several ways. Consider example introduced Doherty
Kvarnstrom (1998): preconditions action board plane havingticket at-gate. However, passenger places gun pocket home
travelling airport proceeding gate, new qualification
action board materialises. one ramification putting object
pocket stay travel location location (i.e. result
ramification constraint), reasoner could easily conjecture passenger fails
board plane. hand, fact passenger possesses gun
trying board plane must fail board plane result qualification
constraint. Now, fact passenger possesses gun disqualifies
action boarding plane also brings indirect effect action
boarding plane executed: passenger put arrest. Note
indirect effect take place, requirements must present: action
472

fiReasoning Action: Argumentation-Theoretic Approach

boarding plane executed, qualification constraint present.
words, qualification constraint might also bring indirect effects.
believe problems sophisticated circumscription policy successfully address situations. Furthermore, policy would
extremely hard understand error-prone. Recall failure non-monotonic
reasoning formalisms regarding frame problem (in simplest form viz. without
ramification qualification problems). Researchers failed point
bug several years Hanks McDermott discovered award
winning paper (1987).
5. recently, Thielscher (2001) gives exposition qualification problem.
Thielscher discusses problem sustained McCarthys (1986) simplistic circumscription policy, viz. anomalous models. introduces default logic based
formalisation qualification problem Fluent Calculus shows
formalisation suffer problem anomalous models. Note
Thielschers formalisation, circumscription still required generate initial theories default theories (in addition set default rules). Nevertheless,
Thielschers solution still suffers following drawbacks: (i) Thielschers use
predicate P oss way formulated Doherty Kvarnstrom
(1998). Thus, qualifications taken executability conditions actions
rather different effects actions; (ii) Thielscher shows
problem anomalous models sustained McCarthys (1986) circumscription
policy overcome formalisation, entirely clear whether Thielschers
formalisation based circumscription default logic suffer
anomalies.
1.3 Ramification Problem
context reasoning action, ramification problem mainly related
indirect effects. Finding solution problem may easy indirect effects
indicate exceptions frame assumptions require special treatment.
several formalisms dealing ramification problem, e.g., see (Lin, 1995; McCain
& Turner, 1995; Thielscher, 1997), still several issues need careful
consideration. consider three examples motivate discussion.
Example 1 Consider Thielschers (1997) circuit:
example interesting gives counterexample minimalistic approaches e.g. work McCain Turner (1995). domain, intended
relationship relay sw2 relay on, would make sw 2 jump off.
Thus, sw1 sw3 closed, sw2 also closed prevented
relay. However, certainly duration (no matter short is) sw 2
forced jump relay. state given Figure 1, performing action
closing switch sw1 , two next states equally possible: one detect on,
another off.4 latter sanctioned minimalistic account.
4. reason nondeterminism case due insufficiency domain information: depending
sensitivity relay, light detect, light could get lit quickly detect sensitive

473

fiVo & Foo

-sw1

sw2
-light

-detect

-relay
sw3

Figure 1: Thielschers circuit
example, Thielscher pointed need keeping track chains applications
indirect effects.
Thielscher (1997) proposes way remedy problem keeping track applications domain constraints re-expressed terms causal relationships.
Thus, given example, formalism able arrive next state
detect on. Following chains causal relationships, dynamic system undergoes
several intermediate states arriving next state.
2
paper, proceed one step Thielschers (1997) position formally
representing intermediate states possible states world. 5 believe
intelligent agent able reason intermediate states even though
may satisfy domain constraints. capability especially important
reasoner needs explain certain observations world systematic way.
note given observation, may several chains causal relationships
bring observation.6 Unless intermediate states explicitly represented
reasoned about, way agent full insight system hand
certain information would missing.
Example 2 Consider Lins (1995) spring-loaded suitcase two latches. Lets assume
latches toggled suitcase closed. following state constraint
supposed apply domain: up(Latch 1 ) up(Latch2 ) open(Suitcase).
question is: robot close suitcase back opening it? McCain
Turner (1997) also consider problem answer is:
detect glimpse light relay sensitive enough make switch sw2 jump quickly
enough detect on; otherwise stay off.
5. Note point view also corresponds traditional definition states snapshots
world.
6. example, given detect next state, either light never bright
light may bright detect sufficiently sensitive detect momentary
brightness.

474

fiReasoning Action: Argumentation-Theoretic Approach

general, latches up, impossible perform action
closing suitcase; one must also concurrently toggle least one
latches.
(McCain & Turner, 1997, p. 464, italic original.)
problem represent action holding suitcase closed
would overcome indirect effect caused loaded spring. also
suggests another kind actions whose direct effects keep world unchanged.
actions usually formalised researchers fluents, e.g. holding.
main objection approach agents also need reason actions
since may also require certain preconditions agent strong enough
hold object. Moreover, certain (abnormal) circumstances, agents may also fail
perform actions. is, actions also subject qualification problem
discussed previous subsection.
2
Example 3 Consider circuit Figure 2: 7

-relay1

-sw1
sw2

-relay2
Figure 2: dynamic domain (potentially) infinite sequence indirect effects
quite obvious performing action f lip 1 whose direct effect sw1
closed, following circular sequence indirect effects take place: {relay 1 , relay2 }
sw2 {relay1 , relay2 } sw2 {relay1 , relay2 }. sequence course would
potentially carry sequence indirect effects indefinitely unless sw 1 flipped
open device stopped functioning correctly, e.g. battery charge.
words, action domain requires action inserted series
going indirect effects captured representation. Note
also none causation-based representations proposed Lin (1995), McCain
Turner (1995) Thielscher (1997) able deal action domain.
2
1.4 Towards Solution
address problems discussed previous sections, argue order find
uniform solution problems one avoid cryptic formalisms whose consequences
7. example instance so-called vicious cycles scenarios, e.g., see (Shanahan, 1999).

475

fiVo & Foo

seen clearly formalisation problem domains. consequence,
propose uniform non-monotonic solution main problems reasoning action. Essentially, performing commonsense reasoning, reasoner relies number
plausible assumptions, e.g., assuming instance birds flies, assuming
shooting turkey loaded gun causes die, etc. traditional default reasoning
formalisms circumscriptive approaches default logic, assumptions made
implicit. example, instances predicates minimised away
circumscription implicitly asserted justifications default rules still
consistent extension consideration default logic. proposed representation formalism aims making assumptions explicit automated reasoner
conscious (at least) assumptions relies performing reasoning.
reasoner always manipulate assumptions independently other.
also basic idea assumption-based frameworks heart Bondarenko,
Dung, Kowalski, Tonis (1997) argumentation-theoretic approach.
proceed consider ramification problems domain theories concurrent non-deterministic events. Among major results, show framework
captures essence causation-based approaches regarding ramification problem.
Moreover, also show expressiveness formalism two examples
indirect effects also need qualifications infinite sequence indirect effects. best
knowledge, none existing formalisms able cope scenarios.
Based basic idea assumption-based frameworks, approach comprises
following major aspects representation:
1. introduce different types assumptions render various laws common sense
dynamic domains. instance, frame assumptions introduced capture
common sense law inertia whilst (two types of) qualification assumptions
introduced overcome qualification problem.
2. introduce special class (system-generated) dummy actions allow explanation problem, i.e. actions events occur outside reasoners
knowledge, dealt uniform manner.
3. based Bondarenko et al.s (1997) argumentation-theoretic framework,
approach makes use inference rules represent domain knowledge.
4. Lying heart approach argumentation-theoretic semantics, called plausibility semantics, argued best render common sense knowledge dynamic
domains. semantics consists particular policy resolving conflicting assumptions computing argumentation accepted.
summarise, paper formalise expressive representation scheme order
cope sophisticated action domains. believe formalisation sometimes
requires certain advanced knowledge encoded precise well-engineered way.
representation action theories proposed paper considered intermediate level commonsense scientific knowledge. expressiveness
formalism improved several independent steps adding assumptions
476

fiReasoning Action: Argumentation-Theoretic Approach

domain descriptions. also shows one advantage solution: simple representation achieved simply removing involved assumptions. arguably
desirable feature reasoner option either increasing expressibility
representation formalism improving simplicity and, consequence, efficiency
reasoning system.
rest paper organised follows: Section 2 summarises relevant features
abstract argumentation framework proposed Bondarenko et al. (1997), semantics concrete instances. Section 3 present syntax semantics basic
temporal logic extension reasoning action. Section 4 present
formalisation reasoning action based argumentation-theoretic approach
introduced Bondarenko et al. (1997). approach reasoning action, particular uniform solution frame qualification problems, well main
results paper presented Section 5. Section 6, show proposed
formalism extended deal complex dynamic domains, including
concurrent non-deterministic events, indirect effects. Related work future
research directions discussed Section 7. defer proofs results
presented paper Appendix.
paper extended version two earlier conference papers (Vo & Foo, 2001,
2002). main differences version proofs included, lemmas
used proofs theorems introduced help reader easily comprehend
results, presentation improved extended examples
various constructions.

2. Defeasible Reasoning Argumentation
Let deductive system hL, Ri given, L formal language countably
many sentences R set inference rules. Given theory L sentence
L, write `hL,Ri deduction whose last element . h hL,Ri ()
denotes set { L | `hL,Ri }. Since language L generally kept fixed whereas
set inference rules R likely vary depending description domain,
possible confusion abbreviate ` hL,Ri hhL,Ri `R hR ,
respectively. Thus classical inference relation ` also written ` RC RC
set inference rules classical propositional logic. Note also every set inference
rules considered paper super set R C .
Given deductive system hL, Ri, assumption-based framework respect hL, Ri
consists theory representing current knowledge reasoner domain,
assumption base AB contrariness operator , i.e. given assumption AB,
denotes contrary .
Remark: notion contrary assumption intended generalise classical
negation . Note general assumptions may constructed special operators
(e.g. negation-as-failure case logic programming, modal operator L
case autoepistemic logic, Moore, 1985), thus contrariness operator must also sufficiently general.

477

fiVo & Foo

hardest part reasoning assumption-based frameworks computing set
assumptions augment given theory . argumentation-theoretic approach,
realised attack relation. determine assumptions accepted,
assumptions put together form arguments. assumptions behind best arguments considered acceptable. Several semantics best arguments presented
Bondarenko et al. (1997) based notions attack: Given assumption-based
framework h, AB, assumption set AB:
attacks assumption AB iff h( ).
attacks assumption set 0 AB iff attacks assumption 0 .
closed iff = AB h( ).
conflict-free iff exist AB ` R , .
Assumption-based frameworks assumption sets always closed referred
flat. flat assumption-based framework, conflict-free property set
assumptions equivalent property attack itself. major
argumentation-theoretic semantics defined Bondarenko et al. (1997) assumptionbased frameworks include:
Stability semantics: assumption set AB stable iff
1. closed,
2. attack itself,
3. attacks assumption
/ .
Bondarenko et al. (1997) show stability semantics corresponds
standard semantics extensions Theorist (Poole, 1988), minimal models (many
cases of) circumscription (McCarthy, 1980, 1986), extensions Default Logic (Reiter,
1980), stable expansions Autoepistemic Logic (Moore, 1985), stable models
logic programming. words, complexity-theoretic perspective,
approach based existing formalisms default reasoning rendered
corresponding assumption-based argumentation framework loss terms
computational complexity.
Admissibility Preferability semantics: Bondarenko et al. (1997) go
extend existing formalisms generalising semantics admissible preferred arguments originally proposed logic programming only.
new semantics defined terms admissible preferred sets assumptions/extensions. assumption set AB admissible iff
1. closed,
2. attack itself,
3. closed sets assumptions 0 AB 0 attacks attacks 0 .
Maximal (with respect set inclusion) admissible assumption sets called preferred.
478

fiReasoning Action: Argumentation-Theoretic Approach

Throughout paper assumptions expressed terms usual propositions. Thus,
replace notion contrariness Bondarenko et al.s (1997) system
classical negation omit specification assumption-based frameworks.
is, assumption-based framework h, ABi consists theory L,
assumption base AB contains assumptions used reasoning.

3. Domain Descriptions
introduce propositional action description language based comprehensive
representation formalism proposed Sandewall (1994). particular, extend Drakengren Bja relands (1999) language possible describe narratives
framework.
3.1 Syntax
Following Sandewall (1994), underlying representation time (discrete) time structure = hT, <, +, consisting
time domain whose members called time points integers
paper (except later part paper distinction made explicit);
<, +, usual integers.
Given time structure = hT, <, +, i, signature respect tuple
= hT , F, Ai, set countably infinitely many time-point variables, F set
propositional fluent names, set action names. Since time structure
fixed rest paper, taken implicitly whenever signature introduced.
assume sets countable. denote F = {[]f | f F}.8 member
F fluent literal. Moreover, = A0 DA, A0 set domain dependent
action names, called basic actions, e.g. load, shoot, etc. DA = {da l | l F } set
dummy actions. explained later paper, solution problems
reasoning action based basic guideline attributing changes events.
Given reasoners ignorance certain events bring changes world,
dummy actions used make gaps reasoners belief state.
need associate dummy actions fluent literals F .
fluent literal l F , introduce following two symbols: AQ l , F Al :
AQl associated assumed qualifications upon preconditions action
regarding fluent literal l. Essentially, AQ l used description
dynamics action allows reasoner describe main preconditions
(with regards fluent literal l) leaving possible (but less probable)
qualifications rendered single assumption AQ l .
F Al associated frame assumptions regarding l. F l , coupled
particular frame inference rule, allows reasoner infer fluent literal l
continues hold future time points unless reason defeats F l .
8. notation [] means formula following may, may not, negated.

479

fiVo & Foo

def

def

Given set fluent literals F , denote F = {F Al | l } AQ =
{AQl | l }.
time-point expression one following:
member T,
time-point variable ,

expression formed time-point expressions using + . convenience,
also write + instead + 1 1, respectively.
denote set time-point expressions E.
Definition 3.1 Let signature = hT , F, Ai given , E, f F, A,
R {=, <}, {, , , }. Define basic (domain description) language
by:
0 ::= true | false | f | R | 0 | 0 0 | [ ]0 ,
::= 0 | [, ] | |
assumption base AB by:
AB = ABAQ ABF ,
ABAQ = {[, ]AQl | , E l F },
ABF = {[ ]F Al | E l F }.
domain description language LD (over ) defined: LD = AB.9
[, ] means action duration corresponding interval [, ]. [, ]AQ l
means fluent literal l assumed qualified hold end interval [, ].
[ ]F Al means fluent literal l assumed default persist time point
next, i.e. principle inertia. Notice difference [ ]F l1 [ ]l2
fluent literals l1 , l2 F . [ ]l2 indicates fluent literal l2 holds
[ ]F Al1 indicates fact fluent literal l 1 persists interval [, + ]
true.
example, blocks world domain, say block block B time
point 2, write: [2]on(A, B); or, say action pickup block occurs
time points t1 + 3 t2 1 relation < holds 1 + 5 t2 , write
[t1 + 3, t2 1]pickup(A) (t1 + 5 < t2 ).
formula contain connectives (i.e. , , , , , [.]) atomic.
atomic E, formulas , [ ], , [ ], [ ] literals.
Let formula. fluent f F occurs free iff occur within
scope [ ] expression . E binds f formula [ ] occurs subformula
, f free . fluent occurs free , closed. contain
occurrence [ ] E, propositional.
9. would precise denote domain description language L . However,
signature usually clear context order avoid mention every time
formalise something domain description language, choose denote LD .

480

fiReasoning Action: Argumentation-Theoretic Approach

3.2 Semantics
Definition 3.2 Let = hT , F, Ai signature. state function F
set {true, false} truth values. history function h set
states. valuation function E T. narrative assignment function
TAT set {true, false}. addition, define q : TAQF {true, false}
f : TFAF {true, false}. interpretation tuple hh, , , q , f
h history, valuation, narrative assignment q , f defined above.
Example 4 Consider Hanks McDermotts (1987) Yale Shooting Problem (YSP) :
three possible actions: load (the gun), wait, shoot (the victim
gun). Normally, waiting cause change world, shooting leads
victims death, provided that, course, gun loaded. Assume three actions
performed, given order.
define signature ysp tuple h{t, t1 , t2 , . . . , u, u1 , u2 , . . .}, {loaded, alive}, {load,
wait, shoot}i. Yale Shooting problem formulated domain description
language Lysp following theory: ysp,0 = {[0]alive, [0, 1]load, [1, 2]wait, [2, 3]shoot}.
following two histories h1 h2 corresponding well-known models
literature reasoning action: h 1 intended model h2 anomalous
model frameworks would produce.

h1

h2









L

L

L

L

0

1

2

3









L

L

L

L

0

1

2

3

Figure 3: two histories YSP action description.
oval Figure 3 represents state ysp . narrative assignment complying
action description would map three tuples (0, load, 1), (1, wait, 2),
(2, shoot, 3) true tuples false (relative assumption normally,
given action time point, instance action time point
unless specified otherwise ).
Definition 3.3 Let , = hh, , , q , f interpretation. Assume , E,
f F, A, R {=, <}, l F , {, , , }, {true, false}. Define
truth value time point T, denoted I(, t) follows:

481

fiVo & Foo

I(, t) =
I([, ]A, t) = (( ), A, ())
I([ ]F Al , t) = f (( ), F Al )
I(, t) = I(, t)
I([ ], t) = I(, ( ))

I(f, t) = h(t)(f )
I([, ]AQ l , t) = q (( ), AQl , ())
I( R, t) = ( )R()
I( , t) = I(, t) I(, t)

Two formulas equivalent iff I(, t) = I(, t) t. interpretation
model set formulas, denoted |= , iff I(, t) = true every
. formula entailed set formulas, denoted |= , iff
true models .
Definition 3.4 Let = hh, , , q , f interpretation.
1. set OccI = {(t, A, u) | (t, A, u) = true} called action occurrence
denotation I.
2. set F AI = {(t, F Al ) FAF | f (t, F Al ) = true} called F A-denotation
I.
3. set AQI = {(t, AQl , u) AQF | q (t, AQl , u) = true} called AQdenotation I.

4. Representing Dynamic Domains Argumentation-Theoretic
Approach
proceed showing assumption-based framework representing dynamic domains. subsequently introduce uniform framework solving frame
qualification problems based argumentation-theoretic approach. General solutions
frame qualification problems obtained computing plausible sets
assumptions guarantee extensions computed sets assumptions
consistent given theory consistent. introduce additional
notations: Given inference rule r R, denote prem(r) cons(r) premise
consequence rule r, respectively.
Definition
4.1 deductive system hL , Ri well-defined iff subset R,
set rS prem(r) consistent set CON S(S) = {cons(r) | r S} also
consistent.
Henceforth, assume deductive systems well-defined. formalised
terms argumentation-theoretic approach, representation requires extended
notion consistency.
Definition 4.2 Let hLD , Ri deductive system,
(i) set sentences LD R-consistent iff 6`R false;
(ii) assumption-based framework h, ABi respect hL , Ri consistent iff
R-consistent.
482

fiReasoning Action: Argumentation-Theoretic Approach

Remark: Observe even hLD , Ri well-defined deductive system, consistency
b
equivalent R-consistency. instance, let R = { }, (logically) consistent

theory = {a, b} R-consistent.
Example 4 (continued) Returning Yale Shooting problem, following inference
rules describe actions domain:
[, ]load
[]loaded [ ]F Aloaded

(5)

[, ]shoot, [ ]loaded
[]alive [ ]F Aalive

(6)

[ ]loaded, [ ]F Aloaded
[ + ]loaded

(7)

[ ]alive, [ ]F Aalive
[ + ]alive

(8)

[ ]loaded, [ ]F Aloaded
[ + ]loaded

(9)

[ ]alive, [ ]F Aalive
[ + ]alive

(10)

Rules (5) (6) represent descriptions actions load shoot, respectively.
Action wait cause effect world, need describe it.
rules render common sense law inertia: time point, fluent literal presumably
persists next time point.
argumentation-theoretic semantics, e.g. stability, admissibility, preferability, complete, well-founded semantics, etc. (Bondarenko et al., 1997) based notion
attack. However, reason problem domains incomplete information, especially
action domains, notion alone may sufficient may always able
construct explicit arguments defeat unsound assumptions. example, consider
Yale Shooting Problem: observing turkey shot loaded gun time point
1, reasoner infers plausibly turkey dead time point 2 using assumption
action shoot qualified bring effect killing victim. However,
time point 2, reasoner could observe turkey still alive. Existing solutions
frame problem, e.g. Reiters (1991), Thielschers (1997), Castilho et al.s (1999), etc.
fail deal surprise since allow contradiction derived. Observe
reasoner explicit reason defeat qualification assumption,
i.e. aware cause prevents application qualification assumption. knows acceptable case common sense. formalise
phenomena, introduce notion rejected assumptions.
483

fiVo & Foo

Definition 4.3 Given assumption-based framework h, ABi, set assumptions
AB rejects assumption AB iff
(a) conflict-free,
(b) {} attacks itself.
instance, example 4, set assumptions 1 = {[0]F Aalive , [1]F Aalive , [1]F Aloaded }
attacks assumption [2]F Aalive .10 Moreover, relative given action description,
set assumptions attacks assumption [0]F loaded . hand, set assumptions 2 = {[0]F Aalive , [1]F Aalive , [2]F Aalive } rejects assumption [1]F Aloaded
2 attack it.
Observation 1 Given assumption-based framework h, ABi conflict-free set
assumptions AB, attacks assumption
/ rejects .
Then, generalise contrariness notion assumption
would general enough account rejected assumptions? reason
want isolate set assumptions rejected attacked part
solution frame problem.
Definition 4.4 Given assumption-based framework h, ABi, set assumptions
AB leniently rejects assumption AB iff
(a) rejects ,
(b) attack .
def

denote Lr() = { AB | leniently rejected }.
show solution provides intuitive account problems reasoning
action, several scenarios considered. include projection problem,
basic form frame problem, whose typical example infamous YSP. Another
scenario concerns explanation problem usually discussed Stolen
Car Problem (Kautz, 1986) Stanford Murder Mystery (Baker, 1989). first
provide informal discussion approach examples.
present solution, frame assumptions essence principle inertia,and role argumentation approach illustrated Yale Shooting
Problem. formulation intentionally ignore qualification problem (it addressed next section) highlight frame problem solved. reconsider well-worn example YSP motivate approach frame problem.
Example 4 (continued) Given theory ysp , argumentation-theoretic approach
yield following preferred set assumptions (Bondarenko et al., 1997):
{[t]F Al | l {loaded, alive, loaded, alive}} \ {[0]F loaded , [2]F Aalive },
corresponds intended model scenario gun remains loaded
time point 2 victim alive time point 3.
extension also stable extension well-founded semantics (Bondarenko
et al., 1997) given theory argumentation-theoretic approach. Note
10. fact, set assumptions containing assumption [1]F Aloaded would attack [2]F Aalive .

484

fiReasoning Action: Argumentation-Theoretic Approach

case one would like uncertain whether gun still loaded shooting
action, one simply needs add axiom: [, ]shoot [ ]F loaded dictate
persistence fluent loaded action shooting guaranteed.
case, still derive [ ]loaded = 1, 2, longer give definite
assertion [ ]loaded 3.
formalisation YSP resembles using default logic, may surprising problem unintended models pointed Hanks McDermott
(1987) circumscription, default logic, autoepistemic logic happen here.
principal reason interaction inference rules notion attack
argumentation-theoretic framework, invalidates undesired assumptions. Notice
even [2]loaded (magically) derived, cannot lead [1]F loaded . Therefore,
set assumptions corresponding case satisfy conditions preferred
set assumptions, thus ruling unintended model. shows one important
features assumption-based frameworks capability making explicit assumptions used reasoner course inference. Recall defaults justifications
accepted long consistent extension credulous semantics
extensions skeptical semantics (thus name consistency-based approach.)
light inertia principle, considered abnormal fluent persist
state next state. minimise abnormality, (normal) default rules
introduced express fact consistent believe abnormality
respect fluent f action situation assert that.
would fail distinguish abnormalities brought reasonable causes
unintuitively generated make consistent possible extension.
latter course corresponding anomalous models. using explicit assumptions,
consistency maintained (by preventing accepted assumptions attacking
themselves) rejection assumptions must also justified known facts
given theory.
Discussion:
1. Turner (1997) showed alternative representation YSP default logic
help solve issue anomalous models introduced Hanks McDermotts
(1987) representation. Turner formulates Yale Shooting scenario follows:
Holds(Alive, S0 )
False

(11)

True
Holds(Loaded, Result(Load, s))

(12)

Holds(Loaded, s)
Holds(Alive, Result(Shoot, s))

(13)

: Holds(f, S0 )
Holds(f, S0 )

(14)

485

fiVo & Foo

: Holds(f, S0 )
Holds(f, S0 )

(15)

Holds(f, s) : Holds(f, Result(a, s))
Holds(f, Result(a, s))

(16)

Holds(f, s) : Holds(f, Result(a, s))
Holds(f, Result(a, s))

(17)

Notice Turner also uses inference rules block backward reasoning
generates anomalous models Yale Shooting scenario. However, also
means kinds useful backward reasoning also blocked. words,
Turners formulation fails deal surprising observations states later
time points. consequence, Turners formulation works domain
restricted qualification-free. soon action descriptions, e.g. one
shoot action YSP, need rely default justifications, e.g. qualification
assumptions, Turners formulation would also encounter problem undesirable
extensions. approach offers solutions issues.
2. Hanks McDermotts (1987) seminal paper early approaches
frame problems exposed, besides new attempts solve frame problem,
Sandewall (1994) accredited first tried approach problems reasoning action systematic way. part effort, also
examines reason behind failure early approaches frame problem.
discussed Sandewall, early approaches reasoning action attempting
formulate inertia principle made common mistake making changes
abnormality regarding principle failing distinguish normal
changes triggered actions anomalous changes. important insight turns
consequence much general law reasoning dynamic
domains discovered researchers community pursuit solutions various
problems reasoning actions: action dynamics causality-based.
principle underpins solutions problems reasoning action.
anomalous models arise early approaches frame problem discovered Hanks McDermott (1987) qualification problem discussed
Thielscher (2001) causes abnormalities present.
hand, regarding ramification problem, given domain constraint
involving number fluents, important know fluents
causes influencing fluents, i.e. causality direction involved
fluents.
light analysis, Turners (1997) approach appears rather ad hoc.
Note Turners solution problem anomalous models block backward reasoning use inference rules without motivation backward
reasoning bad thing. approach appears share solutions based
chronological ignorance (which discussed details Section 7)
486

fiReasoning Action: Argumentation-Theoretic Approach

notion directedness: minimizing chronologically blocking backward reasoning, one tends minimize causes rather effects. However, systematic
approach various problems reasoning action still much desired.
Nevertheless, preferability semantics copes successfully YSP,
properly account explanation problem, e.g. Stanford Murder Mystery (Baker,
1989), Stolen Car Problem (Kautz, 1986). subtlety lies derivation
contrary frame assumptions. contrary frame assumption derived
occurrence event brings change (absent Stolen
Car Problem) preconditions required satisfied change actually take
place (absent Stanford Murder Mystery) explicitly derivable.
notion (leniently) rejected assumptions called service.
Definition 4.5 Given assumption-based framework F =h, ABi, set assumptions
AB presumable wrt F iff
(a) = { AB | `R } (in terms given Bondarenko et al., 1997,
closed),
(b) attack itself,
(c) assumption 6 , rejected .
Definition 4.6 Given assumption-based framework F =h, ABi, set assumptions
AB plausible wrt F iff
(a) presumable,
(b) exists 0 AB 0 presumable Lr(0 ) Lr().
proceed formalising action theories framework.
Definition 4.7 Let = hT , F, Ai signature. Assume , E, A, ,
l F . domain description (over ) tuple hL , R, AB, i, where:
1. LD domain description language AB assumption base ;
2. R = RC RF RA RQ ,
(a) RC set inference rules (classical) propositional logic;
[ ]l, [ ]F Al
(b) RF set frame-based inference rules form:
, i.e.
[ + ]l
represent frame axioms terms inference rules;
, [, ], [, ]AQl
,
(c) RA set action descriptions inference rules form:
[]l [ ]F Al
i.e. represent conditions action bring l;

(d) RQ set qualification-based inference rules form:
, i.e.
[, ]AQl
represent qualifications regarding fluent literal l.
3. theory .
Given set assumptions , denote F = ABF AQ = ABAQ .
Observation 2 Let = hLD , R, AB, domain description, set assumptions AB, either closed attacks itself.
487

fiVo & Foo

5. Reasoning Action: Frame Qualification Problems
general, adopt following guidelines seeking uniform solution problems
reasoning action:
derived pieces information conflict given facts;
Occurrences events minimised;
inertia fluents maximised though minimality event occurrences
higher priority.
Aside trivial case occurrences actions causing frame assumptions
rejected, two aspects actions distinguished:
1. action happens change supposed cause take place.
call expectation failure less qualification problem;
2. actions known happened caused change change
take place. call surprise usually known explanation
problem.
following assumption represents underlying intuition behind reasoning
action formalisms.
Assumption 1 Intuitive models contain minimal (with respect set inclusion) sets
surprises.
introduce model-theoretic counterpart notions assumption-based
notions presented above.
Definition 5.1 Let = hT , F, Ai signature = hL , R, AB, domain description . interpretation = hh, , , q , f model iff
1. model ;
2. r R, |= prem(r) |= cons(r).
following definition captures one several aspects (model-theoretic) solution
frame problem. aspect known action-oriented frame problem Lin
Shohams (1995) terms. proposed minimisation policy formalises intuition
change happen caused kind event. Thus, fluent,
value changed two timepoints , (at least) occurrence
event must end brings change.
Definition 5.2 Let = hLD , R, AB, domain description model D.
coherent model iff
1. basic action A0 , E, |= [, ] |= [, ] ;
488

fiReasoning Action: Argumentation-Theoretic Approach

2. l F T, |= [t]l [t+ ]l either
(a) A0 r =
|= prem(r)[1 /s, 2 /t+ ],11
(b) |= [t, t+ ]dal

, [1 , 2 ], [1 , 2 ]AQl
R
[2 ]l [1 ]F Al

Thus, coherent model: (i) satisfiable basic actions must follow given
theory, (ii) changes attributable events one kind another.
Given interpretation I, want extract sets assumptions satisfiable I.
Definition 5.3 Let = hT , F, Ai signature interpretation . set
frame assumptions satisfiable I, denoted , defined follows:
= {[t]F Al | (t, F Al ) F AI }
set qualification assumptions satisfiable I, denoted IAQ , :
IAQ = {[t1 , t2 ]AQl | (t1 , AQl , t2 ) AQI }
also write IQF = IAQ .
Conversely, given theory set assumptions , reasoner also construct
models domain interest.
Definition 5.4 Let = hLD , R, AB, domain description AB. model
= hh, , , q , f -relativised iff
1. AB, |= iff ;
2. OccI = OAD DAS(), where:
(a) OAD = {((1 ), , (2 )) A0 | |= [1 , 2 ]},
(b) DAS() = {(t, dal , t+ ) DA | []FAl
/ exist
action
, [1 , 2 ], [1 , 2 ]AQl
R |=
A0 r =
[2 ]l [1 ]F Al
prem(r)[1 /s, 2 /t+ ]}.
-relativised models one central notions framework. Essentially, assumptions underpin machinery conjecture information based common sense knowledge. such, try accept many assumption possible unless good
reason to. Therefore, given set assumptions, attribute every missing frame
assumption possible change domain agent reasoning caused
either known action/event unknown action, called dummy actions
paper.
following observation immediate condition (1.) definition.
Observation 3 Let domain description = hL , R, AB, set assumptions
AB given. model -relativised IQF = I(, t) every T.
11. notation [v1 /t1 , . . . , vn /tn ] standard logic meant instantiation formula
variables v1 , . . . , vn replaced terms t1 , . . . , tn , respectively.

489

fiVo & Foo

5.1 Frame Problem
First address frame problem simple setting viz. without qualification
assumptions, lift restrictions later.
Definition 5.5 Let = hLD , R, AB, domain description. simple domain
description, S-domain, iff RQ = AQ occur anywhere R .
Definition 5.6 Let = hLD , R, AB, domain description. interpretation =
hh, , , q , f simple model, S-model, iff
1. model D;
2. q (t, AQl , u) = true every (t, AQl , u) AQF T.
effectively isolates frame problem qualification problem. Note also
S-model IAQ = ABAQ . coherent S-model S-model
coherent.
Example 4 (continued.) following part one coherent models ysp :
{[0, 1]load, [0]loaded, [1]loaded, [0]alive, [1]alive,
[1, 2]wait, [1, 2]daloaded , [2]loaded, [2]alive,
[2, 3]shoot, [3]loaded, [3]alive},
corresponds one anomalous models scenario (the one pointed
Hanks McDermott).
desirable admit occurrence event evidence
it. Thus need minimise set action occurrences given action theory.
Definition 5.7 Let S-domain. coherent S-model prioritised minimal
model (or simply PMM) iff exist coherent S-model 0
0
OccI OccI .
Note model-theoretic minimisation policy based frame
assumptions. solution frame problem thus amenable well-known techniques
circumscription12 , believe argumentation-theoretic approach
direct also wider applicability. order provide connection
(model-theoretic) minimisation policy (argumentation-theoretic) notion
plausible sets assumptions need maximise set assumptions satisfiable
PMM.
Definition 5.8 Let S-domain. PMM canonical prioritised minimal
model (or simply CPMM) iff exist PMM 0
0
F AI F .
want see account plausible sets assumptions connects
account minimality.
12. combination introduction occurrences dummy actions.

490

fiReasoning Action: Argumentation-Theoretic Approach

Lemma 1 Let = hLD , R, AB, S-domain. CPMM
assumption AB:
/ IQF iff rejected IQF .
Proof. () Suppose way contradiction rejected IQF , IQF {}
R-consistent, i.e. IQF {} 6`R false. Since S-domain, AB AQ IQF . Assume
= [ ]F Al E l F , construct interpretation 0
0
way 0 interprets everything except F F = F AI {(( ), F Al )}.
Since PMM D, construction, 0 also PMM D.
0
F AI F AI . Contradiction.
() Obvious.

2

Lemma 2 Let = hLD , R, AB, S-domain CPMM D.
l F [t]F Al Lr(IQF ) |= [t, t+ ]dal .
Proof. Let denote assumption [t]F l . First observe Lr(IQF ) implies
6 IQF since rejected IQF IQF attack itself. turn implies
|= {[t]l, [t+ ]l} denotation F required maximal since
CPMM D. condition coherent, either (i) 0

, [1 , 2 ], [1 , 2 ]AQl
R
r=
[2 ]l [1 ]F Al
|= prem(r)[1 /s, 2 /t+ ], (ii) |= [t, t+ ]dal . Condition (i) guarantees
attacked IQF thus member Lr(IQF ). Therefore, (ii) must
case.
2
converse Lemma 2 hold. cases |= [t, + ]dal
assumption [t]F Al attacked IQF basic action occurs changes fluent
literal l.
Theorem 1 Let = hLD , R, AB, S-domain. CPMM IQF
plausible.
prove derive plausible set assumptions given
CPMM also construct CPMMs plausible set assumptions given
S-domain.
set -relativised models S-domain denoted od (D).
Observation 4 Let S-domain set assumptions D.
odS (D), = IQF .
Proof. construction -relativised models:
odS (D), = [ ]F Al iff |= [ ]F Al iff . (More precisely,
assumption [( )]F Al , valuation defined I.
relative I, identical .)
2
Therefore, = IQF .
491

fiVo & Foo

Theorem 2 Let = hLD , R, AB, S-domain AB. plausible wrt
iff odS (D) 6= odS (D), CPMM D.
Theorem 3 Let = hLD , R, AB, S-domain. Furthermore, suppose CP (D)
set CPMMsSof P laus(D) set plausible sets assumptions D,
CP (D) = P laus(D) odS (D).
5.1.1 Discussion:
So, account frame problem relate existing approaches frame
problem? long line development behind monotonic approaches
frame problem starting Haass (1987) Schuberts (1990) early attempts
resulting Reiters (1991) monotonic solution frame problem together
solutions proposed others Castilho et al. (1999) Zhang Foo (2002)
Thielschers (1999) Fluent Calculus-based monotonic solution frame problem,
notable exception Thielschers (2001) attempt address qualification problem,
tried tackle qualification within framework use address frame
problem.
hand, action languages (Gelfond & Lifschitz, 1998) related
approaches proposed McCain Turner (1995, 1997), Giunchiglia, Kartha,
Lifschitz (1997), Giunchiglia Lifschitz (1998), state transition systems
employed underlying computation machinery essentially provides reasoner
possible complete states world. Furthermore, domain decsriptions
uniquely translated state transition systems, reasoner could safely derive
successor state(s) based current together transition function.
5.2 Solving Qualification Problem (in Presence Frame Problem)
results reported previous section established simple setting. add
following observation theory example 4: [3]alive, i.e. shoot action,
victim still alive, like existing formalisms, account plausibility
would come contradiction. fact, would reasonable
failure explained occurrence qualification. section, remove certain
restrictions qualifications actions order achieve general framework.
subtleties way action theories represented proposed
assumption-based framework. Note first potential difficulty frame assumptions qualification assumptions treated equally, illustrated version
YSP. Consider following action description:
{

[ ]alive, [ ]F Aalive [ ]loaded, [, ]shoot, [, ]AQalive
,
} R,
[ + ]alive
[]alive [ ]F Aalive

{[0]loaded, [0]alive, [0, 1]shoot} .
this, (at least) two stable sets assumptions: one contains frame
assumption [0]F Aalive rejects qualification assumption [0, 1]AQ alive another
contains [0, 1]AQalive attacks [0]F Aalive . latter intuitive case
explicit criterion prefer one another. following assumption
492

fiReasoning Action: Argumentation-Theoretic Approach

asserts solution frame problem presence qualification problem,
action presumed bring effects unless explicit justification
disqualification.
Assumption 2 direct conflict frame assumption qualification assumption (over fluent literal), qualification assumption takes precedence.
Given presence several kinds assumptions, i.e. frame qualification,
adopt following convention: write Lr P () instead (Lr())P P
{F A, AQ}. Since longer exclude qualification assumptions assumptionbased domain descriptions, simply refer assumption-based domain descriptions
Q-domains.
Definition 5.9 Let = hLD , R, AB, Q-domain. presumable set assumptions
AB semi-Q-plausible wrt iff Lr F () minimal (with respect set inclusion).
Definition 5.10 Let = hLD , R, AB, Q-domain. set assumptions AB
Q-plausible wrt iff
1. semi-Q-plausible wrt D,
2. AQ maximal, i.e. exist 0 AB 0 semi-Qplausible (wrt D) AQ 0AQ ,
3. F maximal relative two conditions, i.e. exist
0 AB 0 satisfies two conditions F 0F .
refer models Q-domain Q-models. coherent Q-model Qmodel coherent. minimise set action occurrences coherent Q-models
given action theory.
Definition 5.11 Let Q-domain. coherent Q-model prioritised minimal
Q-model (or simply PMQM) iff exist coherent Q-model 0
0
OccI OccI .
Definition 5.12 Let S-domain. PMQM canonical prioritised minimal
Q-model (or simply CPMQM) iff
0

1. exist PMQM 0 AQI AQI ,
0

2. exist PMM 0 F AI F AI .
proceed obtaining main results CPMQMs regarding Q-plausible
sets assumptions similar CPMMs regarding plausible sets assumptions. following lemma, straightforward extension Lemma 1
Lemma 2 proved previous section, introduced assist proof Theorem 4 .
Lemma 3 Let = hLD , R, AB, Q-domain CPMM D,
493

fiVo & Foo

1. assumption AB:
/ IQF iff rejected IQF .
2. = [ ]F Al Lr(IQF ) |= [, + ]dal .
Theorem 4 Let Q-domain. CPMQM IQF Q-plausible wrt
D.
Similar previous section, prove derive plausible set
assumptions given CPMQM also construct CPMQMs plausible
set assumptions given domain description. set -relativised models
Q-domain denoted odQ
(D).
following observation obvious:
Observation 5 Let Q-domain set assumptions D.

odQ
(D), = QF .
Theorem 5 Let = hLD , R, AB, Q-domain AB. Q-plausible wrt
Q
iff odQ
(D) 6= od (D), CPMQM D.
Theorem 6 Let Q-domain. Furthermore, suppose CP QM (D) set
Q
CPMQMs
P laus (D) Qthe set Q-plausible sets assumptions D,
CP QM (D) = P lausQ (D) od (D).
Q-plausible sets assumptions allow one overcome scenarios expectation
failures (or, qualification surprises) arise, e.g. shooting turkey loaded gun
observing turkey still alive. surprises arise, reasoner knows
whos blame: qualification assumptions. accordingly remove guilty
assumptions. anomalous models forming obstacle early approaches
frame problem, similar anomalous models also arise solutions qualification
problem. important issue related qualification problem thoroughly
discussed Thielscher (2001) solution presented within framework
Fluent Calculus. give reader flavour problem within framework,
invite reader consider following classical example:
Example 5 Consider problem starting car whose tail pipe could possibly
blocked potato, formalised formalism follows.
1. set inference rules R is:13
[ ]BlockedT P
,
[, ]AQGetStarted
[ ]HasP otato, [, ]InsertP otato, [, ]AQ BlockedT P
,
[]BlockedT P [ ]F ABlockedT P
[ ]HasKey, [, ]T urnOnIgnition, [, ]AQ GetStarted
.
[]GetStarted [ ]F AGetStarted
13. course also frame-based inference rules HasKey, BlockedT P , etc. omit
representation sake readability.

494

fiReasoning Action: Argumentation-Theoretic Approach

2. theory is: {[0]HasP otato, [0]HasKey, [0]BlockedT P, [0]GetStarted,
[0, 1]InsertP otato, [1, 2]T urnOnIgnition}.
course, designed example try avoid possible troubles
frame problem. consider two conflicting qualification assumptions
case [0, 1]AQBlockedT P [1, 2]AQGetStarted . Given action theory,
Q-plausible set assumptions would contain exactly one them. Thus,
least two extensions, one car get started since tailpipe blocked
longer consistent assume [1, 2]AQ GetStarted . extension disqualifies
action inserting potato tailpipe thus action starting car
becomes successful. former intuitive case account Q-plausible
sets assumptions fails deliver desired solution.
However, exactly way problem anomalous models arising solution frame problem tackled, problem easily addressed within framework. key insight course also underlined notion causality: [1]BlockT P
caused (by action [0, 1]InsertP otato) turn allows [1, 2]AQ GetStarted
derived. hand, cause allows [0, 1]AQ BlockT P derived.
insight realised framework? answer turns rather simple: distinction leniently rejected frame assumptions non-leniently
rejected frame assumptions allows us distinguish normal changes (i.e. actiontriggered) anomalous changes, distinction leniently rejected qualification assumptions non-leniently rejected qualification assumptions allow us distinguish
normal disqualifications (i.e. underlined cause) anomalous disqualifications. Thus, facing collection Q-plausible sets assumptions, reasoner simply
selects set assumptions contains smallest (with respect set inclusion) set
leniently rejected qualification assumptions.
ability introduce different argumentation-theoretic semantics assumptionbased frameworks arguably biggest advantage approach. following example
illustrates critical point:
Example 6 modify example presented Lin Shoham (1995) turn
modification Kautzs (1986) Stolen Car Problem. spy possessed microfilm top
secret evidence organisation, A, tried steal. reason, another organisation, B, wanted murder spy. microfilm safe spys home
time 0. spy home time 0. tried steal evidence
time points 0 1. spy might return home time 0 1. B tried
murder spy time 0 1. return cancels effects steal, murder
cancels effects return steal cancels effects murder. three
actions steal, return, murder takes one time step. domain formalised
follows: = {[0]EvStolen, [0]Alive, [0]AtHome}; R contains
{

[, ]return, [, ]AQAtHome [, ]murder, [, ]AQAlive
[, ]steal, [, ]AQEvStolen
,
,
,
[]EvStolen [ ]F AEvStolen []AtHome [ ]F AAtHome []Alive [ ]F AAlive

[ ]AtHome < [ ]Alive < [ ]EvStolen <
,
,
}.
[, ]AQEvStolen
[, ]AQAtHome
[, ]AQAlive
495

fiVo & Foo

Given formalisation problem, traditional accounts non-monotonic
reasoning (i.e. Default Logic, circumscription, Autoepistemic Logic, etc.) provide
one solution since formalisms produce extension standard semantics. However, argumentation-theoretic approach gives several semantics problem including preferability semantics. Note, however, admissible
sets assumptions preferred sets assumptions domain contain none
assumptions: [0, 1]AQEvStolen , [0, 1]AQAtHome , [0, 1]AQAlive . essentially means
that, admissibility preferability semantics, reasoner could infer
none actions would succeed hand, proposed plausible
semantics gives alternative solution problem consistent set assumptions contain one following three assumptions: [0, 1]AQ EvStolen ,
[0, 1]AQAtHome , [0, 1]AQAlive . Moreover, plausible set assumptions must contain exactly one them. Among two assumptions belong
plausible set assumptions, one attacked leniently rejected.
believe examples underlined major advantages approach reasoner aware (defeasible) assumptions used reasoning
well able explicitly reason assumptions. flexibility allowing
reasoner introduce different argumentation-theoretic semantics assumption-based
framework simply varying notion acceptability sets assumptions certainly
another advantage favour approach.

6. Complex Dynamic Domains Indirect Effects
far havent taken consideration issues concurrent actions indirect
effects. ensure formalisation introduced expressive enough deal
complex domains, show issues coped approach. Firstly,
motivate formalisation informal discussion.
6.1 Concurrent Non-Deterministic Events
Given temporal representation, formulating concurrent events difficult issue
framework. However, subtleties need carefully considered.
Firstly, use assumptions. presented earlier paper, qualification assumptions
fluent oriented, i.e. qualify effects action rather action itself.
Whilst manifests capability formulating actions multiple effects, thus
effect qualified independently, may fail formalise concurrent events
effects. example, actions hit vase hammer shoot
loaded gun bring effect vase broken. words,
essential qualification assumptions dependent actions bring
effect consideration. Thus, given n actions fluents whose values
changed actions, potentially introduce 2 n qualifications
assumptions.14 Therefore, instead subscripting assumption symbols AQ
fluent literals F , extend set subscripts AQ, denoted AF, contain
14. fact, see later, potentially 2 (n + 1) qualification assumptions case
since one special event corresponding (natural) events bring indirect effects.

496

fiReasoning Action: Argumentation-Theoretic Approach

action corresponding fluent literals. 15 example, given two
actions hit shoot additional action repair whose effect change broken vase
non-broken, viz. broken, need introduce following qualification
assumptions: AQHit-Broken , AQShoot-Broken AQRepair-Broken . Therefore, syntactically
also extend set AB AQ = {[, ]AQ | , E AF} semantically
function q : AQAF {true, false}. definition interpretation
= hh, , , q , f i, also I([, ]AQ , t) = q (( ), AQ , ()), , E
AF.
Though increase complexity framework, price
pay expressiveness resulting system. best knowledge, none
existing formalisms possesses expressiveness.
non-deterministic actions? solution turns quite simple:
treat action non-determinism special kind action qualification. example, formulate Russian shooting scenario (Sandewall, 1994) gun non-deterministically
gets loaded spinning revolver, following action descriptions asserted:
[, ]spin, [, ]AQSpin-Loaded
[, ]spin, [, ]AQSpin-Loaded
adr1 =
adr2 =
[]loaded [ ]F Aloaded
[]loaded [ ]F Aloaded
together following two qualification rules:
qr1 =

[]loaded
[]loaded
qr2 =
.
[, ]AQSpin-Loaded
[, ]AQSpin-Loaded

guarantee either []loaded []loaded follow [, ]spin (remark set qualification assumptions AQ maximised), both.
consequence, two possible extensions arise given non-deterministic action.
Dealing non-determinism could complicated information used
encode action description disjunctive. restrict conclusion action
description rule contain fluent literals, disjunctive effect straightforwardly
dealt framework. However, note restriction similar imposed
action language (Gelfond & Lifschitz, 1998). extension action descriptions
similar way action language extended action language
C done allow complex expression conclusion action description rule.
However, sake presentation, choose use simpler language introduce
framework reader.
6.2 Formalisation
analysis introductory section regarding indirect effects, observe
ordering domain constraints applied plays essential role technically
sound framework. Moreover, longer guaranteed domain constraints would
strictly satisfied every time point. 16 help reader better understand technical
subtlety, useful think changes attributable events. However, events
15. reader referred section 3 general formalisation.
16. course, necessary state world every time point observable reasoner.
However, important aware states able reason them.

497

fiVo & Foo

divided two categories: external internal. Basically, external events
correspond direct effects actions performed agents (including reasoner.)
hand, internal events correspond indirect effects certain conditions
world met attributed Nature. 17
Like external events, internal events also happen certain order. Although
straightforward observe order 18 , important reasoner able reason
them. Hence propose add one dimension set assumptions
given domain description. Since assumptions play essentially role
qualification assumptions, 19 subsume set qualification
assumptions AQAF . associated specific action, ignore
initial action name subscripts AQ. example write AQ broken
case want qualify fluent broken indirect effect, i.e. independently
action. Moreover, avoid axiomatiser confusion determining time
span taken indirect effects, assume atomic. means indirect effects
always take place one time point next one. mean
indirect effects real-time duration, simply means relative given
time structure take place two consecutive time points. allows us
avoid granularity problem irrelevant viewpoint problems
trying solve.
6.2.1 Representation Issue Notations:
One important remark place here. now, used integers corresponding expressions denote time points. two reasons pratice: (i)
significantly simplifies presentation, (ii) Without complication ramification problem, time points reasoned also observable reasoner.
However, discussed thoroughly next section, presence ramifications
time point change takes place maight observable reasoner
change could one indirect effects execution action.
representation issues make integer-based time structure employed far paper
inappropriate. need richer representation time structure. Following Sandewalls
(1994) basic formulation, basic constant included representation
time structure denoted symbol referred origin T.
standard algebraic operations + still employed obtain time expressions
bear usual meanings. relation symbol < also used compare time
expressions. However, longer allow expressions + 1 integers
longer elements time structure.
Given time expression :
17. avoid use terms exogenous/endogenous events label two categories
throughout literature reasoning action, exogenous events used refer actions
carried agents different reasoner outside events whose occurrences beyond
reasoners control.
18. Unless indirect effects somehow delayed become observable reasoner, usually take
place immediately direct effects.
19. difference assumptions qualified indirect effects considered
effects actions Nature.

498

fiReasoning Action: Argumentation-Theoretic Approach

continue denote next time point + .
define 1+ + and, let n > 1, n+ ( (n1)+ )+ .
Furthermore, assume throughout indirect effect takes place
two consecutive time points, also simplify presentation using following syntactical sugar: instead writing [, + ]AQl (for E l F ), write
[ ]AQl . also provides simple way distinguish qualification assumptions
ramificational effects caused directly action event.
domain descriptions affected augmentation? change
set RA action descriptions consists rules either form
, [, ], [, ]AQ- l
[]l [ ]F Al
form

, [ ]AQl
.
[ ]F Al

[ + ]l

convenience, refer set inference rules latter form R ,
, [ ]AQl
fluent literal l F }. Now, regarding
i.e. RI = {r RA | r = +
[ ]l [ ]F Al
ramification problem, basic idea state obtained updating previous
state may necessarily stable due presence indirect effects. representing
indirect effects causal rules (using inference rules framework) reason
causal rules fired (relatively) when. Moreover, since causal rules
may take amount time fire, able reason different
possible orders fire. achieved distinction stable
unstable states.
Definition 6.1 time-point expression E stable wrt given domain description
= hLD , R, AB, AB iff exist fluent literal l F
1.

, [ ]AQl
RI `R , []AQl ,
[ + ]l [ ]F Al

2. 6`R []l.
Definition 6.2 Let = hLD , R, AB, domain description. set assumptions
said ramification-compliant iff
1. exist AB AQ hR ( {}) 6= hR () {}.
2. exist unstable time-point expression E [ ]F l
every l F .
note using unstable time points, conceptually isolated ramification problem task reasoning (explicit) actions.
499

fiVo & Foo

Definition 6.3 Let = hLD , R, AB, domain description. set assumptions
generally plausible action domains, simply AD-plausible, iff
ramification-compliant,
Q-plausible relative condition.
Remarks:
1. definition, seen solution ramification (in
sense) independent frame qualification problems regarding action
occurrences.
2. Given temporal ontology, worth noting traditional notion
state constraints may longer hold representation regarding time points.
precisely, states associated stable time points subject
constraints.
6.3 Connection Causation-Based Formalisms
question is, course, whether computational mechanism gives satisfactory
conclusions problems reasoning action. many formalisms
proposed, general criterion reasoning action formalisms still seems missing.
major stream research towards solution ramification problem based
notion causality (e.g., Lin, 1995; McCain & Turner, 1995; Thielscher, 1997).
discussed above, none approaches deal domains (potentially)
infinite sequences indirect effects present. approaches (including
three references), however, produce successor state execution action
capture changes taken place either direct indirect effects action.
sub-section, show formalism captures notion successor states
absence infinite sequences indirect effects.
Definition 6.4 domain description = hL , R, AB, non-stratified iff exist
two sets {l1 , . . . , ln } F
1. 1 n, {[ ]li } R-consistent, every E;
2. 1 n, k = (i mod n) + 1, exists set k
{[ ]li } `R k ,
k , [ ]AQlk
RI .
[ + ]lk [ ]F Alk
course, domain description stratified non-stratified. Given
def

domain description = hLD , R, AB, i, well denote ED () = hR ( ), extension
action theory according . also write E instead ED () brevity.
Definition 6.5 Let = hT , F, Ai signature.
500

fiReasoning Action: Argumentation-Theoretic Approach

1. set F instantwise state iff every l F , either l l S.
used denote set instantwise states ,
def

def

2. Let F E , denote = {l | l } [ ] = {[ ]l | l },
3. Let = hLD , R, AB, domain description. simplistic iff = .
motivation behind introduction instantwise states allow reasoner
reason intermediate states may practically observable her.
is, indirect effects (following occurrence action event) take place,
world might transit number intermediate states becoming stabilised final state domain constraints necessarily hold. ability
explicitly reason (unstable) intermediate states one advantages offered approach. instance, lets consider scenario Example 1
originally introduced Thielscher (1997). Thielschers (1997) approach allows two
possible successor states results closing switch sw 1 initial state =
{sw1 , sw2 , sw3 , relay, light, detect}. 1 = {sw1 , sw2 , sw3 , relay, light, detect}
T2 = {sw1 , sw2 , sw3 , relay, light, detect}. However, outside observer
idea tricky internal mechanism circuit, could quite difficult
explain T2 one possible outcomes action closing switch
sw1 : starting initial state detect light off, performing
action toggle(sw1 ), light remains somehow detect becomes on. words,
Thielschers (1997) framework fails render intermediate (and unstable) state
light on, albeit short instant, turned again.
hand, states explicitly represented reasoned instantwise states
framework. consequence, domain constraints necessarily hold instantwise
state.
following, abbreviate simplistic stratified domain descriptions SSDs.
Let RI , denote:
def

CON SR () = {l F |

[ ], [ ]AQl
}.
[ + ]l [ ]F Al

Similarly, let RA , denote
def

CON SA () = {l F |

[1 ], [1 , 2 ], [1 , 2 ]AQ-l
}.
[2 ]l [1 ]F Al

[1 ], [1 , 2 ], [1 , 2 ]AQ-l
RA applicable iff S.
[2 ]l [1 ]F Al
use denote set action descriptions applicable (in S) regarding
action . possible application iff CON () consistent
exist 0 0 CON SA (0 ) consistent.
action description

Definition 6.6 Let = hT , F, Ai signature = hL , R, AB, SSD. Suppose
A. formalise direct effects action using relation Res :
S, 0 IS, (S, , 0 ) ResD iff possible application that:
501

fiVo & Foo

(i) CON SA () 0 ,
(ii) exist instantwise state 00 00 satisfies (i) 00 \
0 \ S.
Definition 6.7 Let = hT , F, Ai signature = hL , R, AB, SSD.
causation relation according D, denoted Causes , defined follows: S, 0
IS, CausesD (S, 0 ) iff exists non-empty set R ramification inference rules

(i)

[ ], [ ]AQl
,
[ ]F Al

[ + ]l

(ii) CON SR () 0 ,
(iii) exist instantwise state 00 00 satisfies (i) (ii)
00 \ 0 \ S.
Given domain description D, state stable regarding iff
exist 0 CausesD (S, 0 ).
Definition 6.8 Let = hT , F, Ai signature SSD. Suppose w A.
state transition w according , denoted rans (w), transitive closure CausesD regarding state 1 satisfying (w, , 1 ) ResD . Formally,
ransD (w) = {$ | exists sequence 1 , . . . , n (w, , 1 )
ResD $ = n (i , i+1 ) CausesD 1 < n $ stable regarding D}.
Let interpretation LD T,
def

use [I]t denote instantwise state specified time point t: [I] = {l
F | I(l, t) = true}. [I]t stable said stable time point I.
use NI denote function maps time point next stable time
point I: NI (t) [I]NI (t) stable every u T, < u < N (t)
[I]u stable.
Theorem 7 Let = hT , F, Ai signature 0 = hLD , R, AB, SSD A0 .
Suppose w IS. Define domain description = hL , R, AB, i, = {[] |
w}{[, + ]}. set AB assumptions AD-plausible wrt iff model
ED (), [M ]NM () ransD ([M ] ), i.e. [M ]NM () belongs state transition
[M ] according .
re-consider motivating examples introduced Section 1.3.
Example 1 (continued.) re-formulate action theory example terms
formalism:

502

fiReasoning Action: Argumentation-Theoretic Approach

[ ]sw1 , [ ]sw3 , [ ]AQrelay
,
[ + ]relay [ ]F Arelay
[ ]swi , [ ]AQrelay
(i = 1, 3),
[ + ]relay [ ]F Arelay
[ ]light, [ ]AQdetect
,
+
[ ]detect [ ]F Adetect

[ ]sw1 , [ ]sw2 , [ ]AQlight
,
[ + ]light [ ]F Alight
[ ]swi , [ ]AQlight
(i = 1, 2),
[ + ]light [ ]F Alight
[ ]relay, [ ]AQsw2
,
[ + ]sw2 [ ]F Asw2
[ ]swi , [, ]togglei
(i = 1, 2, 3),
[]swi [ ]F Aswi
[ ], [ ]F
, F .
[ + ]

[ ]swi , [, ]togglei
(i = 1, 2, 3),
[]swi [ ]F Aswi

theory described follows:
= {[]sw1 , []sw2 , []sw3 , []relay, []light, []detect} {[, N ()]toggle 1 }.
Consider AQ = ABAQ \{[2+ ]AQdetect , [3+ ]AQdetect } F = ABF \
+
2+
3+
light , [ ]F Arelay , [ ]F Asw2 , [ ]F Alight }. AD-plausible resulting
next stable state = {sw1 , sw2 , sw3 , relay, light, detect} [4+ ].

{[+ ]F

addition, set 0 AB, 0AQ = ABAQ \ {[2+ ]AQdetect } 0F =
ABF \ {[+ ]F Alight , [+ ]F Arelay , [2+ ]F Asw2 , [3+ ]F Alight , [3+ ]F Adetect }, also
AD-plausible results next stable state 0 = {sw1 , sw2 , sw3 , relay, light, detect}
[4+ ].
Moreover, set 00 AB, 00AQ = ABAQ 00F = ABF \{[N ()]F Alight ,
[+ ]F Arelay , [2+ ]F Asw2 , [2+ ]F Adetect , [3+ ]F Alight }, also AD-plausible also
results next stable state 0 [4+ ]. words, model implied 0 reflects
domain takes amount time detect switch
sw2 jump off. hand, model implied 00 reflects domain
amount time detect (approximately) equal amount time
switch sw2 jump cause light well. detect implied
insensitive even though light relay time ( 2+ ),
relay causes switch sw2 jump leads light well
detect yet on.

Example 2 (continued.) re-formulate action theory example terms
formalism:

503

fiVo & Foo

[ ]upL1 , [ ]upL2 , [ ]AQopen
,
[ + ]open [ ]F Aopen
[, ]f lipi , [ ]upLi
(i = 1, 2),
[]upLi [ ]F AupLi
[1 , 2 ]hold closed, [1 ]open, 1 2
,
[ ]held closed [ ]F Aheld closed
[ ], [ ]F
, F .
[ + ]

[, ]f lipi , [ ]upLi
(i = 1, 2),
[]upLi [ ]F AupLi
[, ]close, [ ]upL1 , [ ]upL2
,
[]open [ ]F Aopen
[ ]held closed
,
[ ]AQopen

theory described follows:
= {[]upL1 , []upL2 , []open, []held closed}{[c1 , c2 ]close, [c2 , c3 ]hold closed, [c4 , c5 ]f lip1 }
{ c1 < c2 c4 < c5 c3 }.
Consider AB AQ = ABAQ \ {[c]AQopen | c2 c c3 } F =
ABF \ ({[c1 ]F Aopen } {[c]F Aheld closed | c2 c c3 } {[c4 ]F AupL1 }). AD-plausible
resulting following:
[c1 ]{upL1 , upL2 , open, held closed},
[c2 ]{upL1 , upL2 , open, held closed},
[c4 ]{upL1 , upL2 , open, held closed},
[c5 ]{upL1 , upL2 , open, held closed},
[c3 ]{upL1 , upL2 , open, held closed}.
Example 3 (continued.) domain description:
[ ]sw1 , [ ]sw2 , [ ]AQrelay1
,
[ + ]relay1 [ ]F Arelay1
[ ]relay1 , [ ]AQsw2
,
[ + ]sw2 [ ]F Asw2
[ ]swi , [, ]togglei
(i = 1, 2),
[]swi [ ]F Aswi
[ ], [ ]F
, F .
[ + ]

[ ]sw1 , [ ]sw2 , [ ]AQrelay2
,
[ + ]relay2 [ ]F Arelay2
[ ]relay2 , [ ]AQsw2
,
[ + ]sw2 [ ]F Asw2
[ ]swi , [, ]togglei
(i = 1, 2),
[]swi [ ]F Aswi

state circuit Figure 2 captured following action theory:
= {[]sw1 , []sw2 , []relay1 , []relay2 }{[c1 , c2 ]toggle1 , [c3 , c4 ]toggle1 } { c1 <
c2 < c 3 < c 4 }
Consider AB AQ = ABAQ F = AB F \ ({[c1 ]F Asw1 }
{[c3 ]F Asw1 } {[c]F Arelay1 | c2 c c3 c = (c2 )k+ k = 4i = 0, 1, 2, . . .}
{[c]F Asw2 , [c]F Arelay1 | c2 c c3 c = (c2 )k+ k = 4i + 1 = 0, 1, 2, . . .}
{[c]F Arelay2 | c2 c c3 c = (c2 )k+ k = 4i + 2 = 0, 1, 2, . . .}
{[c]F Asw2 , [c]F Arelay2 | c2 c c3 c = (c2 )k+ k = 4i + 3 = 0, 1, 2, . . .}).
AD-plausible resulting several possible models domain depending
switch sw1 toggled off:
[c1 ]{sw1 , sw2 , relay1 , relay2 },
504

fiReasoning Action: Argumentation-Theoretic Approach

[c2 ]{sw1 , sw2 , relay1 , relay2 },
[c3 ]{sw1 , sw2 , relay1 , relay2 },
[c4 ]{sw1 , sw2 , relay1 , relay2 }.
Remark:20
Here, also important raise question whether solution ramification
problem conflicts formulation concurrent actions. two actions 1 2
concurrently performed: 1 causes indirect effect E 2 triggers non-terminating
chains effects. direct indirect effects caused 2 dont interfere 1
production E reasoner reason time points execution 1
E holds indirect effect 1 . time points course unstable
due non-terminating chains indirect effects caused 2 . hand,
direct indirect effects caused 2 potential prevent former
producing E, reasoning could complex. observable direct
effects actions take place time concurrent occurrences two
actions viewed one single occurrence one complex actions whose direct effects
combination direct effects two actions. reasoning ramifications
carried usual. hand, reasoner unsure
temporal correlation direct effects two actions, every possible
order changes must taken consideration leading highly nondeterministic
outcome fluent hold future time points. However, situation
still handled nicely formalisation. representation issue
addressed framework indirect effects duration. asserted above,
given state world time point , assume subsequent indirect
effects take place next time point + . certainly fails deal properly
indirect effects whose durations different. simple solution problem
associate one next time point operator possible indirect effect. This, however,
significantly complicate representation.

7. Discussion Future Work
developed uniform framework reasoning action using argumentationtheoretic approach (more precisely, assumption-based approach). also presented
framework copes frame, qualification ramification problems
several sophisticated settings. shown framework naturally extended
become expressive.
also explored new abstraction level believe intermediate layer
common sense knowledge scientific knowledge. Sophisticated domain
knowledge well representation are, argue, required achieve adequate underlying representation reasoning process. Among merits approach, emphasise
following:
Non-monotonicity handled assumptions argumentation-theoretic approach.
20. authors would like acknowledge anonymous referee pointing subtle issue.

505

fiVo & Foo

flexibility working different kinds information representation since
restriction syntax system.
Expressivity: temporal information explicitly represented. Thus system capable capturing many important features temporal reasoning.
reviewed introductory section paper, numerous approaches reasoning
action proposed. such, much research related approaches
frameworks evolved around central problems addressed paper, namely
frame, qualification ramification problems. However, non-monotonic reasoningbased formalisms reasoning actions shown flawed Hanks McDermott (1987), many existing solutions frame problem based approaches
usually monotonic. Since one inherent properties argumentationtheoretic approach monotonicity, attempted solve problems reasoning
actions using approach.
framework reasoning actions argumentation-theoretic approach
independently proposed Kakas, Miller, Toni (1999, 2000, 2001). approach,
admissibility semantics also employed resolve conflicts adversary arguments. represent common sense knowledge, e.g. common sense law inertia,
order imposed set inference rules assumption-based framework. computation arguments competing performed top so-called proof
trees. Nodes proof trees arguments sets propositions. 21 Construction proof trees level hardness known frameworks argumentationtheoretic computation. framework allows persistence (inertial) fluents
captured dealt with, clear whether formalisation extended
deal problems reasoning actions qualification
ramification problems.
recently, Dimopoulos, Kakas, Michael (2004), Bracciali Kakas (2004)
extended Kakas et al.s framework deal ramification qualification problems. Essentially, solution ramification problem, so-called r-propositions
following form:22
L whenever C
added domain description. resulting model given domain description
computed first computing possible indirect effects fixed point repeated application r-propositions, completing model allowing unaffected
fluent literals persist time. clear representation indirect effects quite restrictive doesnt allow complex expressions conditions
indirect effects indirect effects themselves. restriction essentially due
use Answer Set Programming (ASP) underlying computation mechanism
framework. hand, solution qualification problem lies
use default rules representing effects actions. approach fairly similar
21. Kakas et al.s (1999, 2000) terminologies, node set arguments equivalent
notion arguments exposition.
22. L fluent literal C set fluent literals essentially equivalent conjunction
fluent literals.

506

fiReasoning Action: Argumentation-Theoretic Approach

Thielschers (2001) solution qualification problem discussed above. approach
essentially based stability semantics, clear argumentation-theoretic
approach bring benefit framework.
discussed earlier paper, key insight behind solutions implemented
framework exploitation causality drive inference. causality
helped throughout solutions frame qualification problems provide
mechanisms eliminate anomalous models retaining intuitive models
process reasoning. insight certainly general version conclusions derived Sandewall (1994) investigating reason behind production
anomalous models early approaches frame problem, namely failure distinguish normal changes triggered actions abnomalous changes.
Sandewalls insight certainly originated occlusion-based solution frame problem (Sandewall, 1994; Doherty, 1994; Gustafsson & Doherty, 1996). Roughly speaking,
approach action type associated subset fluents influenced
action. Also, predicate Occlude introduced allow subset fluents
specified. reasoning dynamic domains, changes minimised
exception fluents specified Occlude. words, Occlude distinguishes
normal changes (associated action types) anomalous changes thus
avoids unintended models arising.
Regarding qualification problem, Thielschers (2001) solution problem
anomalous models relation qualification problem shares key insight causality
approach. However, Thielschers framework based standard semantics
Default Logic (with initial theories generated using circumscription). Thus,
approach deal problem domains standard semantics Default Logic
produce extension. Furthermore, discussed introductory section
paper, Thielschers framework qualifications taken executability conditions
actions instead different effects actions.
parallel causality-based insight dynamic domains, mechanisms
solving various problems reasoning action exist. instance, number approaches employ concept chronological ignorance (Shoham, 1987, 1988) tackle
problem anomalous models. general, causality-based frameworks approaches
based chronological ignorance share notion directedness: changes minimised chronologically, causes minimised instead effects causes likely precede
effects. However, consequence, backward reasoning blocked prevents chronological ignorance-based approaches dealing surprises expectation failures.
Furthermore, non-deterministic actions incomplete state knowledge known cause
difficulty chronological minimization. detailed comparison causalitybased approaches counterparts based chronological ignorance,
reader referred article Thielscher (2001). hand, approaches
based Motivated Action Theory (MAT) (Amsterdam, 1991; Stein & Morgenstern,
1994) considered special case causality-based paradigm. MAT frameworks also advocate insight appropriate notion causality necessary
assuming away abnormalities. MAT frameworks, however, dont cope well
explanation problem ramification problem pointed Jr. (1999) also
introduce approach improve MAT overcome problems.
507

fiVo & Foo

Nonetheless, several issues still remain within framework need treatment achieve optimal solution. Firstly, formalism may suitable
large-scale problems many assumptions need taken account.
address problem, localisation procedure invented guarantee adequate sub-language used capture circumstance agent reasoning about.
consequence, set assumptions restricted necessary
infer conclusions agent interested. idea development. Furthermore,
uniform solution major problems reasoning action may quite
attractive especially regarding toy scenarios considered paper
well literature, solution may pragmatic. considering locality
account reasoning, particular assumptions used default reasoning, promising
solution achieved computational representational points view.
undertaking investigation towards research direction.
major limitation framework ability deal disjunctive axiomatisation action occurrences. instance, domain axiomatisation constains
disjunction action occurrences [t 1 , t2 ]1 [t1 , t2 ]2 , plausible sets
assumptions, accordingly, CPMMs (resp. CPMQMs) produced account
effects actions. initial formalisation framework allowed
complex expressions action occurrences premises inference rules overcame problem, formalisation appeared complex technical
results could established. investigation, therefore, needed overcome
problem avoiding produce overly complex formalisation.
Provided formalism designed provide general framework reasoning action, following comes natural question: extent proposed
approach used formalise dynamic domains? Sandewall (1994) suggests one
systematise framework reasoning action standard criteria
provide formal indications expressiveness capacity formalism.
contrast traditional approach prevailed many years
reasoning action one tries come examples show
existing approaches able deal scenario claims ones approach
better others solve proposed scenario.
Relative Sandewalls standard criteria, approach enjoys following properties:
1. approach non-inertia allows observations later state correct systems predictions states using explanation mechanism
use assumptions.
2. formalism able deal non-deterministic concurrent events.
Another issue abduction problem also known literature
explanation problem. example, Stolen car scenario, observing car
disappeared parking lot reasoner left it, expectation failure arises.
formalisms would try accommodate problem introducing stealing action
part vocabulary try bind disappearance car action.
arguably intuitive good reason include action
vocabulary first place others car towed away
508

fiReasoning Action: Argumentation-Theoretic Approach

police fairy turning car pumpkin, etc. pragmatic point view,
reasoners may simply acquire information (perhaps police) instead
confusing kinds explanations towards possible uncertain causes.
words, effectively isolate issues deducing new conclusions
existing knowledge base abducing possible causes observations.
course closely related Shanahans approach IJCAI95 paper (Shanahan, 1989)
whose title clearly indicated Prediction Deduction Explanation Abduction.
also working assumption-based framework solve abduction problem.
Acknowledgements
work performed first author School Computer Science
Engineering, University New South Wales. authors wish thank members
Knowledge Systems Group, paricular Dongmo Zhang Maurice Pagnucco,
anonymous reviewers earlier version paper helpful comments
suggestions significantly improve quality well readability
paper. first author partially supported International Postgraduate Research
Scholarship (IPRS) sponsored Australian government. first author presently
supported DEST IAP grant (2004-2006, grant CG040014).

Appendix
Theorem 1 Let = hLD , R, AB, S-domain. CPMM IQF
plausible.
Proof: Suppose CPMM D,
(i) prove IQF presumable:
IQF R-consistent since model D. Observation 2, IQF
closed attack itself. Lemma 1, assumption AB,
/ IQF
rejected IQF .
(ii) prove Lr(IQF ) minimal:
Suppose way contradiction exists presumable set assumptions
(wrt D) Lr() Lr(IQF ). Let -relativised model D. obvious
coherent. derive contradiction proving Occ OccI :
(ii.1) OAD OccI : obvious OAD = {((1 ), , (2 )) A0 | |= [1 , 2 ]},
model D.
(ii.2) DAS() OccI : Let (t, dal , t+ ) DAS(), exist action
A0
r=

, [1 , 2 ], [1 , 2 ]AQl
R
[2 ]l [1 ]F Al

|= prem(r)[1 /s, 2 /t+ ]}. Thus, assumption = [t]F Al Lr(). Thus,
Lr(IQF ) (from hypothesis.) Lemma 2, |= [t, + ]dal . Thus (t, dal , t+ ) OccI .
(ii.3) OccI 6 OccI : Let = [t]F Al Lr(IQF ) \ Lr() l F .
Since CPMM D, Lemma 2, |= [t, + ]dal . Thus (t, dal , t+ ) OccI .
509

fiVo & Foo

Moreover,
/ Lr() iff either (a) , (b) 0
, [1 , 2 ], [1 , 2 ]AQl
R `R [1 /t, 2 /t+ ], [t, t+ ], [t, t+ ]AQl
r=
[2 ]l [1 ]F Al
iff, following construction -relativised models, 6|= [t, t+ ]dal . Thus (t, dal , t+ )
/
OccI . Therefore, OccI OccI .
Hence, Lr(IQF ) minimal IQF plausible.
2
Theorem 2 Let = hLD , R, AB, S-domain AB. plausible wrt
iff odS (D) 6= odS (D), CPMM D.
Proof:
() Suppose AB plausible wrt D. R-consistent, i.e. 6` R
false. construction -relativised models, od (D) 6= .
= hh, , , q , f odS (D), prove CPMM D.
(i) coherent S-model D: obvious definition -relativised models.
(ii) OccI minimal:
Assume contrary, i.e. non-empty set = {J | J coherent S-model
OccJ OccI }. Let H MI exist model J
F AH F AJ .
Consider set assumptions H
QF :
H
(ii.a) QF presumable wrt D:
H
QF closed attack (since H model D);

Let AB, = [ ]F Al 6 H
QF (for E l F ) isnt rejected
H
QF easily construct model J interprets everything except F
H F AJ = F AH {(( ), F Al )}. Obviously, J MI F AJ F AH
contradiction. Thus rejected H
QF .

Therefore, H
QF presumable.
H
(ii.b) Lr(QF ) Lr():
OccH OccI since H MI .
H
Let Lr(H
QF ). Since AB AQ QF , = [t]F Al AB F

l F . definition leniently rejected assumptions, H
QF 6`R false
H
QF {} `R false. then, definition coherent models, H |= [t, + ]dal
(since H coherent model D). Thus, |= [t, + ]dal .
construction -relativised models, [t]F l 6 . Thus, rejected
(since plausible wrt D). Also construction -relativised models, 6` R

. Therefore, Lr(), Lr(H
QF ) Lr(). Now, Occ = OAD DAS(). OAD
OccH since H model D. Thus, OccI \ OccH = DAS() \ OccH . Let (t, dal , t+ )
DAS() \ OccH . construction -relativised models, = [t]F l Lr().
H
Suppose Lr(H
/ H
QF ). Then,
QF (as QF presumable).
construct model J way J interprets everything except F H.
510

fiReasoning Action: Argumentation-Theoretic Approach

definition coherent models, (t, da l , t+ )
/ OccH iff either (1) H 6|= [t]l [t+ ]l;
(2) A0 ,
r=

, [1 , 2 ], [1 , 2 ]AQl
R
[2 ]l [1 ]F Al

|= prem(r)[1 /t, 2 /t+ ], i.e., |= [1 /t, 2 /t+ ], [t, t+ ], [t, t+ ]AQl . Since
= [t]F Al Lr(), condition (2) satisfied.
Thus, (t, dal , t+ )
/ OccH iff H 6|= [t]l [t+ ]l. words, consistent add
assumption [t]F Al set assumptions H
QF . Or, model-theoretic point
view, augment denotation F H (t, F l ) still obtain coherent
S-model J F AH F AJ . contradiction. Hence,
/ Lr( H
QF ).
H
shown Lr(QF ) Lr().
(ii.a) (ii.b) led conclusion Occ minimal. consequence, CPMM (from (i) (ii)).
() Suppose odS (D) 6= odS (D), CPMM D.
prove plausible wrt D. Take arbitrary model od (D). Following
Observation 4, = IQF . Theorem 1 hypothesis CPMM D,
conclude plausible wrt D.
2
Theorem 3 Let = hLD , R, AB, S-domain. Furthermore, suppose CP (D)
set CPMMsSof P laus(D) set plausible sets assumptions D,
CP (D) = P laus(D) odS (D).
Proof:
()
odS (D) CP (D) (Following Theorem 2). ThereS Let P laus(D),

fore, P laus(D) od (D) CP (D).
() Let CP (D), IQF P laus(D) (Following Theorem 1).
prove odI (D) based Definition 5.4:
QF

1) S-model D,
2) = [ ]F Al ABF (for E l F ), IQF iff (( ), F Al )
F AI (Following definition IQF - Definition 5.3)
3) prove OccI = OAD DAS(IQF ):
(3.)
OAD = {((1 ), , (2 )) A0 | |= [1 , 2 ]} OccI (as model D),
(t, dal , t+ ) DAS(IQF ).
Definition 5.4,
(i) = [t]F Al
/ IQF ,
(ii) exists action A0 that:
r=

, [1 , 2 ], [1 , 2 ]AQl
R
[2 ]l [1 ]F Al
511

fiVo & Foo

|= [1 /t, 2 /t+ ], [t, t+ ], [t, t+ ]AQl .
Lemma 1,
/ IQF iff rejected IQF iff coherent model
either (a) A0
r=

, [1 , 2 ], [1 , 2 ]AQl
R
[2 ]l [1 ]F Al

|= prem(r)[1 /s, 2 /t+ ],
(b) |= [t, t+ ]dal .
Since (a) violates condition (ii) above, (b) must case. Thus (t, da l , t+ ) OccI .
DAS(IQF ) OccI .
OccI OAD DAS(IQF ).
(3.) Suppose OccI 6 OAD DAS(IQF ). (3.), OccI OAD
DAS(IQF ). Since IQF plausible, exists model J od SI (D) J
QF

CPMM D. Following Definition 5.4, Occ J = OAD DAS(IQF ) proper
subset OccI . Contradiction! Therefore, OccI OAD DAS(IQF ).
Thus shown odSI (D),
QF

P laus(D) odS (D) (Since IQF P laus(D))

CP (D) P laus(D) odS (D).

2
Therefore, CP (D) = P laus(D) odS (D).
Theorem 4 Let Q-domain. CPMQM IQF Q-plausible wrt
D.
Proof:
Suppose CPMQM D,
(i) easy verify IQF semiQ-plausible wrt D: similar proof theorem
1, using Lemma 3 instead Lemma 1 Lemma 2.
(ii) IAQ maximal:
Assume contrary, i.e. exists set assumptions semiQplausible wrt IAQ AQ . Since presumable, R-consistent. Let
-relativised model D. Obviously, coherent Q-model D. easy verify
OccI minimal otherwise coherent Q-model J (of D) constructed
OccJ OccI . OccI = OAD DAS() OAD OccJ since J
model D. Thus exists (t, da , t+ ) DAS() \ OccJ . JQF presumable
wrt Lr(JQF ) Lr() contradiction. Thus, Occ minimal.
model PMQM AQI AQI contradicts fact
CPMQM D. Therefore, IAQ maximal.
(iii) maximal (relative (i) (ii)):
Assume contrary, i.e. exists set assumptions semiQplausible wrt AQ maximal F . Let -relativised model
512

fiReasoning Action: Argumentation-Theoretic Approach

D. Similar proof part (ii), easily verify PMQM D.
fact AQ maximal F contradicts given hypothesis
CPMQM D, conclude maximal. Therefore, IQF Q-plausible wrt D. 2
Theorem 5 Let = hLD , R, AB, Q-domain AB. Q-plausible wrt
Q
iff odQ
(D) 6= od (D), CPMQM D.
Proof:
() Suppose Q-plausible wrt D.
presumable, R-consistent. Following construction -relativised
models, odQ
(D) 6= .
Let odQ
(D):
(i) easy verify coherent construction -relativised models.
(ii) OccI minimal:
Assume contrary, i.e. set = { | coherent Q-model Occ
OccI } non-empty.
Let J following conditions satisfied:
1. exist model Occ OccJ .
2. AQJ maximal relative 1.
3. F AJ maximal relative 1. 2.
Consider set assumptions JQF : Obviously, JQF closed attach
itself. AB,
/ JQF rejected JQF , otherwise would violate
maximality JAQ JF . Thus, JQF presumable.
Remark OccJ OccI . Besides, OccI = OAD DAS(). OAD OccJ
J model D. Thus exists (t, da , t+ ) DAS() \ OccJ . JQF
presumable wrt Lr(JQF ) Lr() contradiction. Thus, Occ minimal.
consequence, PMQM D.
(iii) AQI maximal (relative (i) (ii)):
Assume contrary, i.e. set = { | PMQM AQI AQ }
non-empty.
Let J following conditions satisfied:
1. F AJ maximal;
2. AQJ maximal relative 1.
prove JQF semi-Q-plausible (i.e. presumable wrt Lr F (JQF )
minimal):
JQF presumable wrt easy verify.
also easy verify LrF (JQF ) minimal J coherent OccJ minimal.
would guarantee set occurrences dummy actions J minimised
consequence set leniently rejected frame assumptions also minimised. Formally,
presumable set assumptions Lr F () LrF (JQF ) relativised model coherent Q-model OccI OccJ , contradiction
fact J thus J PMQM D.
Thus, JQF semi-Q-plausible wrt D. But, AQ JAQ contradiction.
Therefore, shown AQI maximal (relative (i) (ii)).
513

fiVo & Foo

(iv) Now, prove F AI maximal (relative (i), (ii) (iii)):
Assume contrary, i.e. exists PMQM J F F AJ .
Among models satisfying condition, choose model K
0
exist PMQM K 0 F AK F AK . Thus, K CPMQM
D.
Following Theorem 4, set assumptions K
QF Q-plausible F

K
K
F since F F . Contradiction hypothesis Q-plausible.
(i), (ii), (iii) (iv) led conclusion canonical prioritised
minimal Q-model D.
() Suppose odQ
(D) 6= canonical prioritised minimal model
Q
od (D), prove plausible.

Take arbitrary model odQ
(D). Following Observation 5, = QF .
Theorem 4 hypothesis canonical prioritised minimal Q-model D,
conclude Q-plausible.
2
Theorem 6 Let Q-domain. Furthermore, suppose CP QM (D) set
Q
CPMQMs
P laus (D) Qthe set Q-plausible sets assumptions D,
CP QM (D) = P lausQ (D) od (D).
Proof: Similar proof Theorem 3.

2

Theorem 7 Let = hT , F, Ai signature 0 = hLD , R, AB, SSD A0 .
Suppose w IS. Define domain description = hL , R, AB, i, = {[] |
w}{[, + ]}. set AB assumptions AD-plausible wrt iff model
ED (), [M ]NM () ransD ([M ] ), i.e. [M ]NM () belongs state transition
[M ] according .
Proof:
() Suppose AB AD-plausible wrt D, prove model
ED (), [M ]NM () ransD ([M ] ).
Let od(ED ()), |= , |= [] iff w. Thus w = [M ] .
prove [M ]NM () ransD (w), i.e. exists sequence 1 , . . . , n
(w, , 1 ) ResD [M ]NM () = n (i , i+1 ) CausesD 1 < n.
w
= : reasoners knowledge, applicable instantwise state w
due either non-executability w, bring effects concerned
+
+
reasoner. Thus, [M ] = w. course, (w, , [M ] ) ResD .
w
6= : let = {r RA | |= prem(r) |= cons(r)}, prove
possible application w.
0
Apparently, w
. maximal since otherwise construct model
0 satisfies qualification assumption additional action description rule.
0
means 0 PMQM model AQM AQM . Thus CPMQM
D. Following Theorem 5, Q-plausible wrt D. Contradiction.
prove exists instantwise state CON ()
+
[M ] \ w \ w.
514

fiReasoning Action: Argumentation-Theoretic Approach

Assume contrary, i.e. exists fluent literal F (S \ w) \
+
([M ] \ w).
6|= []F since model D.
Construct model 0 way 0 interprets everything except
0
0
F A, F = F {(, F )}. Obviously, 0 PMQM AQM = AQM ,
0
F F . Thus CPMQM D. Following Theorem 5,
+
Q-plausible wrt D. Contradiction. Therefore, (w, , [M ] ) ResD .
() Suppose model E (), [M ]NM () ransD ([M ] ), prove
AB AD-plausible wrt obvious.
2

References
Amsterdam, J. B. (1991). Temporal reasoning narrative conventions. Allen, J. F.,
Fikes, R., & Sandewall, E. (Eds.), KR91: Principles Knowledge Representation
Reasoning, pp. 1521, Cambridge, MA. Morgan Kaufmann.
Baker, A. B. (1989). simple solution Yale Shooting problem. Brachman, R. J.,
Levesque, H. J., & Reiter, R. (Eds.), KR89: Principles Knowledge Representation
Reasoning, pp. 1120, San Mateo, California. Morgan Kaufmann.
Baral, C. (1995). Reasoning actions: Non-deterministic effects, constraints, qualification. International Joint Conference Artificial Intelligence.
Bondarenko, A., Dung, P. M., Kowalski, R. A., & Toni, F. (1997). abstract,
argumentation-theoretic approach default reasoning. Artificial Intelligence Journal,
93, 63101.
Bracciali, A., & Kakas, A. C. (2004). Frame consistency: computing causal explanations. 10th International Workshop Non-Monotonic Reasoning (NMR 2004),
pp. 7987.
Castilho, M. A., Gasquet, O., & Herzig, A. (1999). Formalizing action change modal
logic I: frame problem. Journal Logic Computation, 9(5), 701735.
Dimopoulos, Y., Kakas, A. C., & Michael, L. (2004). Reasoning actions change
answer set programming. International Conference Logic Programming
Nonmonotonic Reasoning - LPNMR 04, pp. 6173.
Doherty, P. (1994). Reasoning action change using occlusion. European
Conference Artificial Intelligence, pp. 401405.
Doherty, P., & Kvarnstrom, J. (1998). Tackling qualification problem using fluent dependency constraints: Preliminary report. 5th Workshop Temporal Representation
Reasoning - TIME, pp. 97104.
Doyle, J. (1979). truth maintenance system. Artificial Intelligence Journal, 12(3), 231
272.
Drakengren, T., & Bjareland, M. (1999). Reasoning action polynomial time.
Artificial Intelligence Journal, 115, 124.
Fikes, R., & Nilsson, N. J. (1971). STRIPS: new approach application theorem
proving problem solving. Artificial Intelligence Journal, 2(3/4), 189208.
515

fiVo & Foo

Foo, N. Y., Zhang, D., Vo, Q. B., & Peppas, P. (2001). Circumscriptive models automata. Thielscher, M., & Williams, M.-A. (Eds.), Workshop Non-monotonic
Reasoning, Action Change - colocated IJCAI-01.
Gelfond, M., & Lifschitz, V. (1998). Action languages. Electronic Transactions AI,
3(16), 193210.
Ginsberg, M. L., & Smith, D. E. (1988). Reasoning action I: possible worlds
approach. Artificial Intelligence Journal, 35(2), 165196.
Giunchiglia, E., Kartha, G. N., & Lifschitz, V. (1997). Representing action: Indeterminacy
ramifications. Artificial Intelligence Journal, 95(2), 409438.
Giunchiglia, E., & Lifschitz, V. (1998). action language based causal explanation:
Preliminary report. National Conference Artificial Intelligence, pp. 623630.
Green, C. (1969). Application theorem proving problem solving. International Joint
Conference Artificial Intelligence, pp. 219240.
Gustafsson, J., & Doherty, P. (1996). Embracing occlusion specifying indirect effects
actions. Principles Knowledge Representation Reasoning, pp. 8798.
Haas, A. R. (1987). case domain-specific frame axioms. frame problem
artificial intelligence: proc. 1987 workshop. Morgan Kaufmann.
Hanks, S., & McDermott, D. (1987). Nonmonotonic logic temporal projection. Artificial
Intelligence Journal, 33(3), 379412.
Jr., C. L. O. (1999). Explanatory update theory: Applications counterfactual reasoning
causation. Artificial Intelligence Journal, 108(1-2), 125178.
Kakas, A. C., Miller, R., & Toni, F. (1999). argumentation framework reasoning
actions change. International Conference Logic Programming
Nonmonotonic Reasoning - LPNMR 99, pp. 7891.
Kakas, A. C., Miller, R., & Toni, F. (2000). E-res - system reasoning actions, events observations. Baral, C., & Truszczynski, M. (Eds.), International
Workshop Non-Monotonic Reasoning, Special Session System Descriptions
Demonstration - NMR2000.
Kakas, A. C., Miller, R., & Toni, F. (2001). E-res: Reasoning actions, events
observations. International Conference Logic Programming Nonmonotonic
Reasoning - LPNMR 01, pp. 254266.
Kautz, H. (1986). logic persistence. National Conference Artificial Intelligence.
Kowalski, R., & Sergot, M. J. (1986). logic-based calculus events. New Generation
Computing, 4, 6795.
Kowalski, R. (1992). Database updates event calculus. Journal Logic Programming,
12, 121146.
Kushmerick, N. (1996). Cognitivism situated action: two views intelligent agency.
Computers Artificial Intelligence, 15(5).
Lifschitz, V. (1987). semantics STRIPS. Georgeff, & Lansky (Eds.), Reasoning
Actions Plans. Morgan Kauffman, Los Altos.
516

fiReasoning Action: Argumentation-Theoretic Approach

Lin, F. (1995). Embracing causality specifying indirect effects actions. International Joint Conference Artificial Intelligence.
Lin, F. (1996). Embracing causality specifying indeterminate effects actions.
National Conference Artificial Intelligence, pp. 670676.
Lin, F., & Reiter, R. (1994). State constraints revisited. Journal Logic Computation,
4(5), 655678.
Lin, F., & Shoham, Y. (1995). Provably correct theories action. Journal ACM,
42(2), 293320.
McCain, N., & Turner, H. (1995). causal theory ramifications qualifications.
International Joint Conference Artificial Intelligence.
McCain, N., & Turner, H. (1997). Causal theories action change. National
Conference Artificial Intelligence, pp. 460465.
McCarthy, J. (1977). Epistemological problems artificial intelligence. International
Joint Conference Artificial Intelligence, pp. 555562.
McCarthy, J. (1980). Circumscription - form non-monotonic reasoning. Artificial
Intelligence Journal, 13(1-2), 2739.
McCarthy, J. (1986). Applications circumscription formalizing common sense knowledge. Artificial Intelligence Journal, 26(3), 89116.
McCarthy, J., & Hayes, P. (1969). philosophical problems standpoint
artificial intelligence. Michie, D., & Meltzer, B. (Eds.), Machine Intelligence 4.
Edinburgh University Press.
McDermott, D. V. (1987). Weve framed: ai innocent frame problem. Pylyshyn, Z. (Ed.), Robots Dilemma: Frame Problem Artificial
Intelligence, pp. 113122. Ablex.
McDermott, D. V., & Doyle, J. (1980). Non-monotonic logic I. Artificial Intelligence
Journal, 13(1-2), 4172.
Moore, R. C. (1985). Semantical considerations nonmonotonic logic. Artificial Intelligence Journal, 25(1), 7594.
Morris, P. H. (1988). anomalous extension problem default reasoning. Artificial
Intelligence Journal, 35(3), 383399.
Pednault, E. (1989). ADL: Exploring middle ground STRIPS situation calculus. KR89: First International Conference Principles Knowledge
Representation Reasoning, pp. 324332. Morgan Kaufmann.
Poole, D. (1988). logical framework default reasoning. Artificial Intelligence Journal,
36(1), 2747.
Reiter, R. (1980). logic default reasoning. Artificial Intelligence Journal, 13, 81132.
Reiter, R. (1991). frame problem situation calculus: simple solution (sometimes) completeness result goal regression. Lifschitz, V. (Ed.), AI
Mathematical Theory Computation: Papers Honor John McCarthy, pp. 418
420. Academic Press.
517

fiVo & Foo

Sandewall, E. (1994). Features Fluents. Oxford University Press, Oxford.
Schubert, L. (1990). Monotonic solution frame problem situation calculus;
efficient method worlds fully specified actions. Kyburg, H., Loui, R., &
Carlson, G. (Eds.), Knowledge Representation Defeasible Reasoning, pp. 2367.
Kluwer Academic Publishers, Dordrecht.
Shanahan, M. (1989). Prediction deduction explanation abduction. International
Joint Conference Artificial Intelligence, pp. 10551060.
Shanahan, M. (1997). Solving Frame Problem: Mathematical Investigation
Common Sense Law Inertia. MIT Press, Cambridge, Massachussets.
Shanahan, M. (1999). ramification problem event calculus. International
Joint Conference Artificial Intelligence, pp. 140146.
Shoham, Y. (1987). Reasoning Change. MIT Press, Cambridge, MA.
Shoham, Y. (1988). Chronological ignorance: Experiments nonmonotonic temporal reasoning. Artificial Intelligence Journal, 36, 279331.
Stein, L. A., & Morgenstern, L. (1994). Motivated action theory: formal theory causal
reasoning. Artificial Intelligence Journal, 71(1), 142.
Thielscher, M. (1997). Ramification causality. Artificial Intelligence Journal, 89, 317
364.
Thielscher, M. (1999). situation calculus fluent calculus: State update axioms
solution inferential frame problem. Artificial Intelligence Journal, 111(1-2),
277299.
Thielscher, M. (2001). qualification problem: solution problem anomalous
models. Artificial Intelligence Journal, 131(1-2), 137.
Turner, H. (1997). Representing actions logic programs default theories: situation
calculus approach. Journal Logic Programming, 31(1-3), 245298.
Vo, Q. B., & Foo, N. Y. (2001). Solving qualification problem. Australian Joint
Conference Artificial Intelligence, pp. 519531.
Vo, Q. B., & Foo, N. Y. (2002). Solving ramification problem: Causal propagation
argumentation-theoretic approach. 7th Pacific Rim International Conference
Artificial Intelligence - PRICAI2002, pp. 4959.
Zhang, D., & Foo, N. Y. (2002). Interpolation properties action logic: Lazy-formalization
frame problem. Flesca, S., Greco, S., Leone, N., & Ianni, G. (Eds.), Logics
Artificial Intelligence, European Conference, JELIA 2002, pp. 357368.

518

fiJournal Artificial Intelligence Research 24 (2005) 1-48

Submitted 11/04; published 07/05

CIXL2: Crossover Operator Evolutionary Algorithms
Based Population Features
Domingo Ortiz-Boyer
Cesar Hervas-Martnez
Nicolas Garca-Pedrajas

dortiz@uco.es
chervas@uco.es
npedrajas@uco.es

Department Computing Numerical Analysis
University Cordoba, Spain

Abstract
paper propose crossover operator evolutionary algorithms real
values based statistical theory population distributions. operator
based theoretical distribution values genes best individuals
population. proposed operator takes account localization dispersion
features best individuals population objective features
would inherited offspring. aim optimization balance
exploration exploitation search process.
order test efficiency robustness crossover, used set
functions optimized regard different criteria, as, multimodality, separability, regularity epistasis. set functions extract conclusions
function problem hand. analyze results using ANOVA multiple
comparison statistical tests.
example crossover used solve artificial intelligence problems,
applied proposed model problem obtaining weight network
ensemble neural networks. results obtained performance
standard methods.

1. Introduction
Evolutionary algorithms (EAs) general purpose searching methods. selection process crossover mutation operators establish balance exploration
exploitation search space adequate wide variety problems
whose solution presents difficulties insolvable using classical methods.
problems defined continuous domains, evolutionary algorithms applied
use real values, namely, evolution strategies (EPs), real-coded genetic algorithms (RCGAs),
evolutionary programming (EP). paradigms precision solution
depend coding system, binary coded genetic algorithms, precision
computer system algorithms run.
selection process drives searching towards regions best individuals.
mutation operator randomly modifies, given probability, one genes
chromosome, thus increasing structural diversity population. see,
clearly exploration operator, helps recover genetic diversity lost
selection phase explore new solutions avoiding premature convergence. way,
probability reaching given point search space never zero. operator,
c
2005
AI Access Foundation. rights reserved.

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

Exploration
2

2

2

Ex

pl
oi
ta

1

tio
n

H ,

12

Exploration

Exploitation
,

1
1



2
1



ai

(a)

1

2





Exploration

2

1






bi

(b)

Figure 1: (a) Hypercube defined first two genes parents; (b) Representation
segment defined ith genes two chromosomes.

fact, implements random search whose well-studied features useful field
evolutionary computation.
crossover operator combines genes two parents generate better
offspring. based idea exchange information good chromosomes generate even better offspring. effect crossover operator
studied two different points view: chromosome level gene level. effect
crossover operator chromosome level considered geometric way. Given
two parents 1 = {11 , 21 } 2 = {12 , 22 } two genes, denote H 1 2
hypercube defined genes (Figure 1a). gene level representation would
linear, defining case segment interval 1 , 2 pair genes (Figure 1b).


crossover operators generate individuals exploitation zones, 1 , 2 H 1 2 .


way, crossover operator implements depth search exploitation, leaving
breadth search exploration mutation operator.
policy, intuitively natural, makes population converge values within
hypercubes defined parents, producing rapid decrease population
diversity could end premature convergence non-optimal solution. Recent
studies BLX- crossover (Eshelman & Schaffer, 1993), crossover based fuzzy
connectives (Herrera, Herrera-Viedma, Lozano, & Verdegay, 1994), fuzzy recombination
(Voigt, Muhlenbein, & Cvetkovic, 1995), confirmed good performance
crossover operators also generate individuals exploration zone. operators
avoid loss diversity premature convergence inner points search
space, also generation new individuals exploration zone could slow
search process. reason, crossover operator establish adequate balance
exploration (or interpolation) exploitation (or extrapolation), generate
offspring exploration exploitation zones correct proportion.
Establishing balance exploration exploitation important, also
important balance self-adaptive (Kita, 2001; Beyer & Deb, 2001; Deb &
Beyer, 2001), is, must guarantee dispersion offspring depends
2

fiCIXL2: Crossover Operator Evolutionary Algorithms

dispersion parents. So, two close parents must generate close offspring, two
distant parents must generate distant offspring. control dispersion crossover
based fuzzy connectives based generation offspring using fuzzy connectives t-norms, t-conorms, average functions, generalized operator compensation
(Mizumoto, 1989). fuzzy recombination offspring generated using two triangular
distributions whose averages derive genes two parents. BLX-
probability generating offspring parents, area
close parents whose amplitude modulated parameter.
Ono Kobayashi (1997) proposed Unimodal Normally Distributed Crossover
(UNDX), three parents used generate two children. children
obtained using ellipsoidal distribution one axis segment joins two
parents extent orthogonal direction decided perpendicular distance
third parent axis. authors claim operator preserve
statistics population. crossover also self-adaptive, differs BLX-
fact probable generate offspring near average first two
parents.
Another self-adaptive crossover Simulated Binary Crossover (SBX) (Deb & Agrawal,
1995). Based search features single-point crossover used binary-coded genetic algorithms, operator respects interval schemata processing, sense
common interval schemata parents preserved offspring. SBX crossover
puts stress generating offspring near parents. So, crossover guarantees
extent children proportional extent parents, also favors
near parent individuals monotonically likely chosen children
individuals distant parents.
main goal paper propose crossover operator avoids loss
diversity population individuals, and, time, favors speed
convergence algorithm. two goals are, first, conflicting; adequate
balance controlled two basic features crossover operator: i) balance
exploration exploitation and, ii) self-adaptive component. two
features make evolutionary algorithms avoid premature convergence favor local
fine-tuning. attributes highly appreciated search algorithm.
current crossover operators, features offspring depend features
parents. crossovers take account population features
localization dispersion individuals. use statistical features
population may help convergence population towards global optimum.
crossover operator implements basically depth exploitative search, like
methods steepest gradient descent, local search simulated annealing,
three search methods algorithm takes quality solutions account.
So, reasonable think also convenient crossover operator consider
performance individuals involved crossover operation. idea already
implemented heuristic crossovers (Wright, 1991).
Nevertheless, following previous line argument, seems rather poor use
two parents, consider promising directions towards would
advisable drive search. is, instead using local heuristic uses two
3

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

individuals, involving whole population adequate subset determination
direction search whose features would specially suitable.
Motivated line argument, paper propose crossover operator,
called Confidence Interval Based Crossover using L2 Norm (CIXL2). one
hand, takes advantage selective component derived extraction
features best n individuals population indicates direction
search, hand, makes self-adaptive sampling around features
whose width depends number best individuals, dispersion best individuals,
confidence coefficient, localization individuals participate crossover.
Now, exploitation region area two parents involved
crossover, area defined confidence interval built n best
individuals population; exploratory region rest search domain.
previous concepts exploration exploitation, merely geometrical, added
probabilistic component depends population features best individuals.
Estimation Distribution Algorithms (EDAs) Probabilistic Model-Building Evolutionary Algorithms (Muhlenbein & Paa, 1998; Muhlenbein, Mahnig, & Rodriguez, 1999)
based a, seemingly, similar idea. algorithms mutation crossover
operators. every generation population distribution selected individuals
estimated new individuals obtained sampling estimated distribution. However, underlying idea behind crossover extraction population features, mean
standard deviation, order detect regions higher probability
getting best individuals. order perform crossover, create three virtual
parents represent localization estimator mean, bounds confidence
interval which, certain confidence degree, localization estimator takes
values. way, children generated three parents inherit features
best individuals population.
rest paper organized follows: Section 2 explains definition CIXL2
features; Section 3 discusses problem selection test sets,
justifies use test set based one proposed Eiben Back (1997a); Section
4 describes experimental setup evolutionary algorithm (RCGA) used tests;
Section 5 studies optimal values parameters CIXL2; Section 6 compares
performance CIXL2 crossovers; Section 7 compares CIXL2 EDAs;
Section 8 describes application RCGAs CIXL2 neural network ensembles;
and, finally, Section 9 states conclusions paper future research lines.

2. CIXL2 Operator
section explain theoretical base supports defined crossover
operator, define crossover. use example explain
dynamics population subject crossover operator.
2.1 Theoretical Foundation
section study distribution i-th gene construction
confidence interval localization parameter associated distribution.
4

fiCIXL2: Crossover Operator Evolutionary Algorithms

Let set N individuals p genes make population
set best n individuals. assume genes individuals
belonging independent random variables continuous distribution H(i )
localization parameter , define model
= + ei ,

= 1, ..., p,

(1)

ei random variable. suppose that, gene i, best n individuals form
, , ..., } distribution , model takes form
random sample {i,1
i,2
i,n


ij
= + eij ,

= 1, ..., p j = 1, ..., n.

(2)

Using model, analyze estimator localization parameter i-th
gene based minimization dispersion function induced L2 norm. L2
norm defined
n
X
(eij )2 ,
(3)
kei k22 =
j=1

hence associated dispersion induced L2 norm model 2
D2 (i ) =

n
X
j=1


(ij
)2 ,

(4)

estimator localization parameter is:




= arg min D2 ( ) = arg min


n
X
j=1


(ij
)2 .

(5)

Using minimization steepest gradient descent method,
S2 (i ) =
obtain
S2 (i ) = 2

D2 (i )
,


n
X
j=1


(ij
),

(6)

(7)

making (7) equal 0 yields
=

Pn


j=1 ij

n

= .

(8)

So, estimator localization parameter i-th gene based minimization dispersion function induced L2 norm mean distribution
(Kendall & Stuart, 1977), is, = .
5

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

sample mean estimator linear estimator1 , properties unbiasedness2 consistency3 , follows normal distribution N (i , 2 /n)

distribution genes H(i ) normal. hypothesis, construct bilateral
confidence interval localization genes best n individuals, using
studentization method, mean localization parameter,and standard deviation
Si dispersion parameter:


Si
Si
CI

(9)
= tn1,/2 ; + tn1,/2
n
n
tn1,/2 value Students distribution n 1 degrees freedom,
1 confidence coefficient, is, probability interval contains true
value population mean.
2.2 CIXL2 Definition
definition confidence interval, define three intervals create three virtual parents, formed lower limits confidence interval gene, CILL 4 ,
upper limits, CIU L5 , means CIM 6 . parents statistical information
localization features dispersion best individuals population, is,
genetic information fittest individuals share. definition is:
CILL = (CILL1 , . . . , CILLi , . . . CILLp )

(10)

CIU L = (CIU L1 , . . . , CIU Li , . . . CIU Lp )
CIM

= (CIM1 , . . . , CIMi , . . . CIMp ),



CILLi = tn1,/2
n


CIU Li = + tn1,/2
n
CIMi = .

(11)

CILL CIU L individuals divide domain gene three subintervals:
Di IiL IiCI IiU , IiL [ai , CILLi ); IiCI [CILLi , CIU Li ]; IiU (CIU Li , bi ];
ai bi bounds domain (see Figure 2).
crossover operator creates one offspring , individual population
f , randomly selected, one individuals CILL, CIU L CIM , depending
localization f , follows:
1. linear combination sample values.
2. estimator unbiased estimator expected value estimator parameter
estimate: E[] = .
3. consistent estimator estimator converges probability quantity estimated
sample size grows.
4. Confidence Interval Lower Limit.
5. Confidence Interval Upper Limit.
6. Confidence Interval Mean.

6

fiCIXL2: Crossover Operator Evolutionary Algorithms

Di


ai

CI

L


Ii
C

C Mi

U






f

Ii


C U Li

bi

Figure 2: example confidence interval based crossover
IiL : fitness f higher CILL, = r(if CILLi ) + , else
= r(CILLi ) + CILLi .
IiCI : fitness f higher CIM, = r(if CIMi ) + , else
= r(CIMi ) + CIMi .
IiU : fitness f higher CIUL, = r(if CIU Li ) + , else
= r(CIU Li ) + CIU Li (this case seen Figure 2).
r random number interval [0, 1].
definition, offspring always takes values direction best
two parents never them. virtual individual one bounds
confidence interval better parent, offspring generated
direction confidence interval likely generate better individuals.
virtual individual worse parent, offspring generated near
parent opposite direction confidence interval. hand,
parent selected population within confidence interval, offspring
outside interval always neighborhood fitness center
confidence interval worse. formulation tries avoid shifting population
towards confidence interval, unless shifting means real improvement fitness
population.
f distant parent, offspring probably undergo marked
change, parents close, change small. first circumstance
likely occur first stages evolutionary process, second one
final stages.
width interval CI depends confidence coefficient, 1 , number
best individuals, n, dispersion best individuals. first stages
evolution, dispersion large, specially multimodal functions, decrease
together convergence genetic algorithm. features allow balance
exploitation exploration adjust dynamically. crossover
exploratory beginning evolution, avoiding premature convergence,
exploitative end, allowing fine tuning. parameters n 1 regulate
dynamics balance favoring higher lower degree exploitation. suggests
CIXL2 establishes self-adaptive equilibrium exploration exploitation based
features share, certain confidence degree 1 , best n individuals
7

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

25

Best individuals distribution
Population distribution
Population distribution crossover

CIP


population
DCI best individuals
population crossover
Individuals
Individuals proyected axis x1x2
Best individuals
Best individuals proyected axis x1x2
CIP



f(x)

20

Individuals number

4000

0

15

10

2
1.5
1
-2

5

0.5
-1.5

-1

-0.5
x1

0
-0.5
0

0.5

1

1.5

-1
-1.5
2

x2

I2L

I2CI

I2U

-2
0

(a)

-2

-1

CILL2

0
x2

CIM2

CIUL2

1

2

(b)

Figure 3: Effect CIXL2 crossover population used minimization
Rosenbrock function two variables

population. preliminary theoretical study aspect carried HervasMartnez Ortiz-Boyer (2005).
2.3 Crossover Dynamics
Figure 3 shows simulation behavior crossover optimization Rosenbrock function (Eiben & Back, 1997b) two variables. Figure 3a, observe
individuals within domain CIP ; best n within confidence domain CI I1CI I2CI . DCI shifted towards minimum function placed
(1, 1), domain CIP new population, generated applying CIXL2,
shifted optimum. displacement higher first stages evolution,
decrease evolution. may modulated parameters n 1 .
Figure 3a shows population, applying crossover operator, distributed
region nearer optimum whose diversity depends parameters operator.
Figure 3b shows whole population n best individuals distributed.
see, distribution best n individuals keeps features distribution
population, shifted optimum. shifting towards optimum
marked value n small. tails distribution best individuals
larger dispersion best individuals also large, smaller
concentrated narrow region. size tails also depends features
problem, stage evolution, particular gene considered. effect
crossover distribution population shift distribution towards best
n individuals stretch distribution modulately depending amplitude
confidence interval. parameters n 1 responsible displacement
stretching region new individuals generated.
n small, population move promising individuals quickly.
may convenient increasing convergence speed unimodal functions. Nevertheless,
produce premature convergence suboptimal values multimodal functions.
n large, shifting speed convergence smaller. However,
8

fiCIXL2: Crossover Operator Evolutionary Algorithms

evolutionary process robust, feature perfectly adequate
optimization multimodal, non-separable, highly epistatic functions.
parameter n responsible selectiveness crossover, determines
region search directed. selection regulated parameter
1 . parameter bounds error margin crossover operator order obtain
search direction feature shares best individuals population.

3. Benchmark Problems
field evolutionary computation, common compare different algorithms using
large test set, especially test involves function optimization (Gordon & Whitley,
1993). However, effectiveness algorithm another algorithm cannot
measured number problems solves better. free lunch theorem
(Wolpert & Macready, 1995) shows that, compare two searching algorithms
possible functions, performance two algorithms , average,
. result, attempting design perfect test set functions present
order determine whether algorithm better another every function,
fruitless task.
reason why, algorithm evaluated, must look kind
problems performance good, order characterize type problems
algorithm suitable. way, made previous study
functions optimized constructing test set fewer functions better
selection (Whitley, Mathias, Rana, & Dzubera, 1995; Salomon, 1996). allows us
obtain conclusions performance algorithm depending type function.
Taking account reasoning, test set designed Eiben Back (1997b)
adequate. test set several well characterized functions allow us
obtain generalize, far possible, results regarding kind function involved.
Nevertheless, added two functions test set aim balancing
number functions kind. two new functions function Rosenbrock
(Rosenbrock, 1960) extended p dimensions function Schwefel (Schwefel, 1981);
widely used evolutive optimization literature. Table 1 shows
expression function summary features: separability, multimodality,
regularity.
function multimodal two local optima. function p variables
separable rewritten sum p functions one variable (Hadley, 1964).
separability closely related concept epistasis interrelation among
variables function. field evolutionary computation, epistasis measures
much contribution gene fitness individual depends values
genes.
Non separable functions difficult optimize accurate search direction
depends two genes. hand, separable functions optimized
variable turn. problem even difficult function also multimodal.
search process must able avoid regions around local minima order
approximate, far possible, global optimum. complex case appears
local optima randomly distributed search space.
9

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

Function
Sphere

Schwefels
double sum
Rosenbrock

Rastrigin

Schwefel

Ackley

Griewangk

Fletcher
Powell

Langerman

Definition
Pp
2
fSph (x) =
i=1 xi
xi [5.12, 5.12]
x = (0, 0, . . . , 0); fSph (x ) = 0
P
2
Pp

fSchDS (x) =
j=1 xj
i=1
xi [65.536, 65.536]
x = (0, 0, . . . , 0); fSchDS (x ) = 0
Pp1
2 2
2
fRos (x) =
i=1 [100(xi+1 xi ) + (xi 1) ]
xi [2.048, 2.048]
x = (1, 1, . . . , 1); fRos (x ) = 0
Pp
fRas (x) = 10p + i=1 (x2
10 cos(2xi ))
xi [5.12, 5.12]

x = (0, 0, . . . , 0); fRas (x ) = 0
p

Pp
fSch (x) = 418.9829 p + i=1 xi sin
|xi |
xi [512.03, 511.97]
x = (420.9687, . . . , 420.9687);
(x )
=0

q fSch
1 Pp
2
fAck (x) = 20 + e 20exp 0.2 p
i=1 xi
P

p
1
exp p
i=1 cos(2xi )
xi [30, 30]

x = (0, 0, . . . , 0); fAck (x ) = 0


Qp
Pp
x2
x


fGri (x) = 1 + i=1 4000
i=1 cos


xi [600, 600]
x (0, 0, . . . , 0); fGri (x ) = 0
Pp
(A Bi )2
fF le (x) =
i=1
Pp
(aij sinj + bij cosj )
Ai =
j=1
Pp
Bi =
j=1 (aij sinxj + bij cosxj )
xi , [, ]; aij , bij [100, 100]
x = ; fF le (x ) = 0


P
1 Pp
fLan (x) =
c exp
(x aij )2
Pi=1
j=1 j
p
cos j=1 (xj aij )2
xi [0, 10]; = p
x = random; fLan (x ) = random

Multimodal?


Separable?
yes

Regular?
n/a





n/a





n/a

yes

yes

n/a

yes

yes

n/a

yes



yes

yes



yes

yes





yes





Table 1: Definition function together features

dimensionality search space another important factor complexity
problem. study dimensionality problem features carried
Friedman (1994). order establish degree difficulty problems,
chosen search space dimensionality p = 30 functions.
Sphere function used development theory evolutionary strategies
(Rechenberg, 1973), evaluation genetic algorithms part test set
proposed De Jong (1975). Sphere, De Jongs function F1, simple strongly
convex function. Schwefels double sum function proposed Schwefel (1995). main
difficulty gradient oriented along axis due epistasis among
variables; way, algorithms use gradient converge slowly. Rosenbrock
function (Rosenbrock, 1960), De Jongs function F2, two dimensional function
deep valley shape parabola form x21 = x2 leads global
minimum. Due non-linearity valley, many algorithms converge slowly
change direction search repeatedly. extended version function
proposed Spedicato (1975). versions proposed (Oren, 1974; Dixon,
1974). considered many authors challenge optimization algorithm
(Schlierkamp-Voosen, 1994). difficulty mainly due non-linear interaction among
variables.
Rastrigin function (Rastrigin, 1974) constructed Sphere adding modulator
term cos(2xi ). contour made large number local minima whose value
increases distance global minimum. surface Schwefel function (Schwefel, 1981) composed great number peaks valleys. function second
10

fiCIXL2: Crossover Operator Evolutionary Algorithms

best minimum far global minimum many search algorithms trapped.
Moreover, global minimum near bounds domain.
Ackley, originally proposed Ackley (1987) generalized Back (1993),
exponential term covers surface numerous local minima. complexity
function moderated. algorithm uses gradient steepest descent
trapped local optima, search strategy analyzes wider region
able cross valley among optima achieve better results. order
obtain good results function, search strategy must combine exploratory
exploitative components efficiently. Griewangk function (Back, Fogel, & Michalewicz, 1997)
product term introduces interdependence among variables. aim
failure techniques optimize variable independently. Ackley function,
optima Griewangk function regularly distributed.
functions Fletcher-Powell (Fletcher & Powell, 1963) Langerman (Bersini,
Dorigo, Langerman, Seront, & Gambardella, 1996) highly multimodal, Ackley
Griewangk, non-symmetrical local optima randomly distributed.
way, objective function implicit symmetry advantages might simplify
optimization certain algorithms. Fletcher-Powel function achieves random distribution optima choosing values matrixes b, vector
random. used values provided Back (1996). Langerman function,
used values c referenced Eiben Back (1997b).

4. Evolutionary Algorithm
suitable evolutionary algorithms solve optimization problems continuous
domains evolutionary strategies (Schwefel, 1981; Rechenberg, 1973), genetic algorithms
(Holland, 1975; Goldberg, 1989a) real coding (Goldberg, 1991) evolutionary programming (Fogel, Owens, & Walsh, 1966; Fogel, 1995). evaluating CIXL2
chosen real coded genetic algorithms, search algorithms general purpose crossover operator plays central role. general structure genetic
algorithm shown Figure 4.
Nevertheless, CIXL2 could applied evolutionary algorithms crossover
similar operator. hand, real codification natural one
continuous domains, gene representing variable function. way,
precision solution depends data type used store variables.
objective comparison behavior proposed crossover
crossovers. comparison must made common evolutionary framework
defined features genetic algorithm. definition features,
taken account previous studies matter. following paragraphs
describe depth different components genetic algorithm.
4.1 Structure Individual Population Size
individual made p = 30 genes, dimensionality functions optimize.
size population one critical parameters many applications.
size population small, algorithm could converge quickly towards suboptimal solutions; large, much time resources could wasted. also
11

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

Genetic algorithm
begin
t0
initialize (t)
evaluate (t)
(not stop-criterion)
begin
tt+1
select (t) (t 1)
crossover (t)
mutate (t)
evaluate (t)
end
end
Figure 4: Structure genetic algorithm, current generation.
obvious size population, together selective pressure, influences
diversity population.
Several researches studied problems different points view. Grefenstette (1986) used meta-genetic algorithm controlling parameters another genetic
algorithm, population size selection method. Goldberg (1989b) made theoretical analysis optimum population size. study influence parameters
search process carried Schaffer, Caruana, Eshelman Das (1989).
Smith (1993) proposed algorithm adjusts size population respect
error probability selection . Another method consists changing size
population (Arabas, Michalewicz, & Mulawka, 1994) dynamically.
size population usually chosen interval 50 500 individuals,
depending difficulty problem. general practice, function optimization,
size interval [50, 100] unimodal functions, interval [100, 500]
multimodal functions. However, several papers use compromise size 100
functions order homogenize comparison environment. also use population
size 100 individuals like comparative studies (Zhang & Kim, 2000; Takahashi, Kita,
& Kobayashi, 1999).
4.2 Selection
Zhang Kim (2000) comparative study carried performance four
selection methods: proportional, ranking, tournament Genitor. contrast
studies based asymptotic study less ideal conditions,
paper devoted practical case, problem machine layout. paper analyzes
quality solutions obtained reasonable amount time using mutation
crossover operators. study concludes methods ranking tournament
selection obtain better results methods proportional Genitor selection.
12

fiCIXL2: Crossover Operator Evolutionary Algorithms

chosen binary tournament selection, ranking selection, used
Zhang Kim (2000) two reasons:
complexity tournament selection lower complexity ranking
selection (Back, 1996).
selective pressure higher. feature allows us measure whether
crossover able keep population diversity (Goldberg & Deb, 1991).
Tournament selection runs tournament two individuals selects winner.
order assure best individuals always survive next generation, use
elitism, best individual population generation always included
population generation + 1. proved, theoretically (Rudolph, 1994)
empirically (Back, 1996; Michalewicz, 1992; Zhang & Kim, 2000), convenience
use elitism.
4.3 Population Update Model
different techniques updating population, among important
generational model steady-state model. generational model
generation complete set N new offspring individuals created N parents selected
population. generational models, tournament selection used
choose two parent individuals, crossover pc probability mutation operator
con pm probability applied parents.
contrasts steady-state model, one member population
replaced time. steady-state model selects individual mutated
mutated individual replaces another individual population. crossover two
individuals selected one offspring replaces one individual population.
number different replacement strategies: replace-worst, replace randomly
chosen member, select replacement using negative fitness.
model extrapolates generational steady-state said
generation gap G (De Jong, 1975; Jong & Sarma, 1993). Thus generational model,
G = 1; steady-state model, G = 1/N . One widely used variants
steady-stated genetic algorithm Minimal Generation Gap (MGG) model (Satoh,
Yamamura, & Kobayashi, 1996). model takes two parents randomly population generates children. Two individuals selected parents
offspring: best individual, another individual chosen roulette selection.
two individuals substitute parents population.
generational model frequently used comparative studies use
BLX, SBX, logical crossover fuzzy recombination. reason
model used paper. However, UNDX crossover used MGG model,
UNDX MGG commonly used together generational model
negative influence performance UNDX.
parameters two models used commonly used
literature. generational model, use probability crossover p c = 0.6 (De
Jong, 1975; Herrera, Lozano, & Verdegay, 1998). MGG model used = 200,
13

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

value commonly used papers UNDX (Ono & Kobayashi, 1997; Ono,
Kita, & Kobayashi, 1999; Ono, Kobayashi, & Yoshida, 2000). mutation probability,
values interval pm [0.001, 0.1] usual (De Jong, 1975; Herrera et al., 1998;
Michalewicz, 1992; Back, 1996). chosen value pm = 0.05 models.
4.4 Initialization
search algorithm, initialization method important. many cases
initialization determines success failure search process. opted,
papers (Herrera et al., 1998; De Jong, 1975; Beyer & Deb, 2001; Herrera, Lozano,
& Sanchez, 2003), initializing values genes means uniform random
distribution within domain variable.
4.5 Mutation
mutation operator chosen non-uniform mutation parameter b = 5
(Michalewicz, 1992) dynamical nature makes suitable wide variety
problems (Herrera & Lozano, 2000).
individuals generated mutation obtained follows:
im

=



+ 4(t, bi ) si = 0
4(t, ai ) si = 1

(12)


4(t, y) = y(1 r

(1 g


)b
max

)

(13)

generation, gmax maximum number generations, random value,
{0, 1}, r random number interval [0, 1] b parameter determines
degree dependence mutation regards number iterations. Equation
13 gives values interval [0, y]. probability obtaining value near 0 increases
algorithm progresses. operator performs uniform search initial stages
evolution, localized search final stages.
4.6 Stop Criterion
part genetic algorithm takes time evaluation
fitness function. number evaluations fitness generation depends
operators used population update model. Different operators update models
lead different numbers evaluations per generation. reason
common use number evaluations stop criterion instead number
generations. used limit 300,000 evaluations (Eiben, van der Hauw, & van
Hemert, 1998; De Jong & Kosters, 1998) stop criterion. precision solutions
bounded precision data type used implementation genetic
algorithm. used double precision data type 64 bits following specification
ANSI/IEEE STD 754-1985 (IEEE Standard Binary Floating-Point Arithmetic).
data type precision 15 - 17 digits.
14

fiCIXL2: Crossover Operator Evolutionary Algorithms

5. Analysis CIXL2
section perform analysis crossover, obtain every test
function following information:
1. optimal value confidence coefficient 1 confidence interval.
values used 1 = {0.70, 0.90, 0.95, 0.99}.
2. optimal number best individuals used crossover calculate confidence intervals mean. values used n = {5, 10, 30, 60, 90}.
two factors independent, perform analysis using
possible pairs (1 , n) Cartesian product two sets. pair
perform 30 runs genetic algorithm different random seeds. Table 2 shows
average value standard deviation 30 runs experiment.
study results made means analysis variance ANOVA
II (Dunn & Clark, 1974; Miller, 1981; Snedecor & Cochran, 1980), fitness
best individuals, A, test variable. fitness obtained independently 30 runs
depending two fixed factors interaction. fixed factors are: confidence
coefficient C four levels number best individuals B five levels.
linear model form:

Aij = + Ci + Bj + CBij + eij

(14)

= 1, 2, 3, 4; j = 1, 2, 3, 4, 5
where:
Ci effect i-th level factor C, C1 represents confidence
coefficient 0.70, C2 0.90, C3 0.95 C4 0.99.
Bj effect j-th level factor B, B1 represents value
n = 5, B2 n = 10, B3 n = 30, B4 n = 60 B5 n = 90.
CBij represents effect interaction confidence coefficient C
number best individuals B.
global mean model. variation experimental results
explained effects different levels factors model
interaction.
eij error variables.
hypothesis tests try determine effect term fitness best
individuals, A. carried tests every factor interaction among
factors. subsequent tests performed confidence level 95%.
coefficient R2 linear model tells us percentage variance explained
model.
15

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

Function

n 1

Mean

St. Dev.

1

Mean

Mean

D. Tip.

1

Mean

St. Dev.

Sphere
fSph

5
10
30
60
90

0.70

6.365e-16
5.736e-15
3.728e-12
6.082e-10
3.838e-09

2.456e-16
2.495e-15
1.623e-12
2.499e-10
2.326e-09

0.90

4.885e-16
2.554e-15
1.446e-11
2.867e-08
4.383e-08

St. Dev. 1
1.969e-16
8.934e-16
7.062e-12
1.642e-08
3.068e-08

0.95

3.553e-16
2.642e-15
2.279e-11
1.557e-07
6.840e-08

1.710e-16
1.258e-15
1.256e-11
9.911e-08
5.894e-08

0.99

1.998e-16
1.480e-15
1.248e-10
5.494e-07
1.061e-07

6.775e-17
1.032e-15
5.914e-11
6.029e-07
8.401e-08

Schwefels
5
double sum 10
fSchDS
30
60
90

0.70

1.995e-03
2.232e-02
8.464e-02
1.376e-01
8.048e-01

2.280e-03
2.859e-02
1.168e-01
1.202e-01
5.403e-01

0.90

8.403e-03 7.748e-03
5.407e-02 3.792e-02
3.190e-01 2.798e-01
4.059e-01 2.395e-01
2.257e+00 1.490e+00

0.95

7.662e-03
4.168e-02
2.644e-01
2.223e-01
7.048e-01

9.693e-03
4.383e-02
2.569e-01
1.384e-01
7.689e-01

0.99

1.305e-02
1.462e-02
1.223e-01
2.134e-01
2.799e-01

1.303e-02
1.422e-02
9.018e-02
1.464e-01
2.322e-01

Rosenbrock 5
fRos
10
30
60
90

0.70

2.494e+01
2.579e+01
2.611e+01
2.576e+01
2.562e+01

1.283e+00
2.044e-01
1.471e-01
1.988e-01
2.827e-01

0.90

2.506e+01
2.591e+01
2.632e+01
2.593e+01
2.570e+01

3.050e-01
1.324e-01
1.745e-01
2.292e-01
2.974e-01

0.95

2.497e+01
2.589e+01
2.642e+01
2.600e+01
2.579e+01

4.663e-01
9.426e-02
1.377e-01
4.045e-01
2.629e-01

0.99

Rastrigin
fRas

5
10
30
60
90

0.70

2.919e+00 1.809e+00
6.799e+00 2.480e+00
9.452e+00 2.434e+00
1.413e+01 4.126e+00
1.771e+01 5.063e+00

0.90

6.036e+00
1.068e+01
1.270e+01
1.837e+01
2.438e+01

2.023e+00
3.786e+00
3.522e+00
6.070e+00
7.688e+00

0.95

7.893e+00
1.297e+01
1.327e+01
1.499e+01
1.987e+01

2.450e+00
3.844e+00
4.770e+00
4.434e+00
5.637e+00

0.99

7.164e+00
1.675e+01
1.552e+01
1.691e+01
2.249e+01

2.579e+00
6.554e+00
3.664e+00
4.123e+00
6.058e+00

Schwefel
fSch

5
10
30
60
90

0.70

6.410e+02 2.544e+02
1.793e+03 4.172e+02
2.675e+03 2.592e+02
2.700e+03 1.471e+02
2.738e+03 1.476e+02

0.90

1.145e+03
1.325e+03
2.264e+03
2.513e+03
2.704e+03

5.422e+02
2.340e+02
2.758e+02
1.927e+02
1.516e+02

0.95

1.424e+03
1.486e+03
2.061e+03
2.496e+03
2.672e+03

6.837e+02
2.607e+02
2.369e+02
2.146e+02
1.349e+02

0.99

2.844e+03
2.525e+03
1.986e+03
2.169e+03
2.529e+03

4.168e+02
3.069e+02
2.424e+02
2.434e+02
1.837e+02

Ackley
fAck

5
10
30
60
90

0.70

1.378e-08
2.074e-07
8.328e-06
1.019e-04
2.518e-04

5.677e-09
9.033e-08
1.403e-06
2.396e-05
7.167e-05

0.90

6.320e-09
9.544e-08
1.483e-05
8.292e-04
7.544e-04

2.966e-09
3.422e-08
3.956e-06
2.097e-04
2.668e-04

0.95

4.677e-09
9.396e-08
2.246e-05
1.897e-03
9.571e-02

1.960e-09
3.513e-08
4.957e-06
9.190e-04
3.609e-01

0.99

5.188e-09
5.806e-08
4.976e-05
3.204e-03
1.741e-01

2.883e-09
2.683e-08
1.298e-05
1.373e-03
5.290e-01

Griewangk
fGri

5
10
30
60
90

0.70

1.525e-02
1.647e-02
2.012e-02
7.884e-03
7.391e-03

1.387e-02
1.951e-02
2.372e-02
1.061e-02
7.617e-03

0.90

2.463e-02
2.695e-02
1.819e-02
2.808e-02
5.248e-03

2.570e-02
2.713e-02
1.664e-02
9.686e-02
6.741e-03

0.95

1.574e-02
2.195e-02
2.321e-02
7.410e-03
8.938e-03

1.411e-02
2.248e-02
3.842e-02
1.321e-02
1.196e-02

0.99

1.285e-02
3.194e-02
2.254e-02
1.582e-02
1.230e-02

1.801e-02
3.680e-02
1.877e-02
2.727e-02
2.356e-02

Fletcher
fF le

5
10
30
60
90

0.70

1.523e+04
1.966e+04
2.145e+04
2.133e+04
2.432e+04

1.506e+04
1.585e+04
1.631e+04
2.110e+04
2.273e+04

0.90

2.293e+04
2.248e+04
2.129e+04
2.124e+04
2.898e+04

1.882e+04
2.300e+04
1.310e+04
1.213e+04
3.131e+04

0.95

1.286e+04 1.317e+04
1.633e+04 1.344e+04
3.049e+04 2.306e+04
2.935e+04 2.155e+04
2.918e+04 2.418e+04

0.99

1.527e+04
1.891e+04
2.492e+04
2.374e+04
3.453e+04

1.362e+04
1.612e+04
1.967e+04
1.479e+04
2.498e+04

Langerman 5
fLan
10
30
60
90

0.70

-2.064e-01
-2.339e-01
-2.124e-01
-1.975e-01
-1.599e-01

9.346e-02
1.280e-01
1.038e-01
1.405e-01
9.057e-02

0.90

-2.544e-01
-2.582e-01
-2.191e-01
-1.752e-01
-1.336e-01

1.401e-01
1.574e-01
1.100e-01
7.145e-02
6.042e-02

0.95

-3.545e-01
-2.663e-01
-1.908e-01
-1.762e-01
-1.656e-01

0.99

-2.803e-01
-2.830e-01
-2.382e-01
-1.949e-01
-1.796e-01

1.350e-01
1.645e-01
1.572e-01
9.500e-02
8.453e-02

1.802e-01
1.247e-01
9.776e-02
8.929e-02
8.336e-02

2.463e+01 1.330e+00
2.579e+01
1.609e-01
2.668e+01
9.999e-02
2.617e+01
4.787e-01
2.585e+01
3.654e-01

Table 2: Average value standard deviation 30 runs experiment

16

fiCIXL2: Crossover Operator Evolutionary Algorithms

determining whether significant differences among various levels
factor, perform multiple comparison test average fitness obtained
different levels factor. First, carry Levene test (Miller, 1996; Levene,
1960) evaluating equality variances. hypothesis variances
equal accepted, perform Bonferroni test (Miller, 1996) ranking means
level factor. aim find level factor whose average fitness
significantly better average fitness rest levels factor.
test Levene results rejecting equality covariance matrixes, perform
Tamhane test (Tamhane & Dunlop, 2000) instead Bonferroni test. Tables 9, 12,
13 Appendix show results obtained following methodology.
Sphere function, significant levels term linear model Table 9
show none factors linear model significant effect model built
explain variance fitness A. effect due fact fSph easy
optimize fitness behaves singular random variable sample variance near
0. see Table 2 best results obtained pair (0.99, 5).
multiple comparison test Table 12 confirms means obtained value n = 5
significatively better means obtained values. way,
average fitness 1 = 0.70 significantly best one. results show that,
value n, best value 1 , general, 1 = 0.70. Due simple form
fSph , best parameters crossover show high exploitative component fast
shifting towards region best individuals.
unimodal non-separable functions fSchDS fRos , factors
interaction significant linear model explains sample variance
determination coefficient around 0.5. Table 2 shows best results obtained
n = 5; Tamhane test shows means obtained value n
significatively better means obtained values. results value
confidence coefficient less conclusive. fact, fRos significant
differences among different values 1 , although best results obtained
1 = 0.7. fSchDS average fitness 0.99 best one, without significant
differences 0.70 . 0.70 together n = 5 one shows best results.
conclude feature non-separability functions imply notable
change parameters crossover respect parameters used f Sph .
fRas fSch , separable multimodal, adequate pair
parameters (0.70, 5). fRas , test shows performance pair significantly better. However, fSch , best mean obtained 5 results
significantly better obtained values, exception 10 .
significant differences among 0.70 , 0.95 90 . three factors linear
model significant quite large determination coefficients 0.617 f Ras 0.805
forfSch . means factors interaction explain high percentage
variance fitness A.
fAck , best results obtained pair (0.95, 5). Tamhane test confirms
n = 5 suitable value, significant differences among 0.70 ,
0.95 0.99 . fGri best results obtained pair (0.90, 90). test
shows large values n suitable optimization function.
significant differences among performance different values 1 .
17

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

functions determination coefficient linear model low, showing
linear model explain variance fitness. lack linear relation
among n, 1 fitness makes difficult determine best value
parameters crossover.
case fF le fLan similar, linear model hardly gives information
effect parameters fitness. adequate pair optimization two functions (0.95, 5). test shows best values n n = 5
n = 10. hand, significant differences among performance
crossover different values 1 .
overall results show selection best n = 5 individuals population
would suffice obtaining localization estimator good enough guide search process
even multimodal functions small value n could favor convergence
local optima. However, virtual parents worse fitness parent
population, offspring generated near latter, domain explored
multiple directions. way, premature convergence suboptimal virtual parents
avoided.
However, best n individuals concentrated local optimum algorithm
likely converge optimum. reason complex functions
larger value n may reasonable, adding confidence interval individuals located
near different optima. example this, case fGri best results
achieved n = 90 n = 60 noteworthy.
confidence coefficient bounds error determination localization
parameter responsible focussing search. multiple comparison tests show
value 1 = 0.70 best 6 problems, is, least, worse
best one problems. chosen adequate value
parameter.

6. Comparative Study Crossovers
Due large amount different crossovers available, unfeasible make comprehensive comparison crossovers CIXL2. chosen
crossovers obtain interesting results whose features similar crossover,
is, self-adaptive establish balance exploration exploitation search space. way two features balanced regulated
one parameters crossover. parameters chosen following
authors recommendations papers devoted comparison different
operators.
crossovers used comparison are: BLX (Eshelman & Schaffer, 1993)
different degrees exploration determined values = {0.2, 0.5} (Herrera et al.,
2003); fuzzy recombination (Voigt et al., 1995); based fuzzy connectives logical
family (logical crossover) (Herrera et al., 1998) using S2 strategies = 0.5 (Herrera &
Lozano, 2000), SBX (Deb & Agrawal, 1995) using values = {2, 5} (Deb & Beyer, 2001);
(Kita, Ono, & Kobayashi, 1998;
UNDX (Ono & Kobayashi, 1997) = 21 = 0.35
p
Kita, 2001). CIXL2, determined previous study, use n = 5
1 = 0.70.
18

fiCIXL2: Crossover Operator Evolutionary Algorithms

Following setup previous study, performed ANOVA II analysis
multiple comparison test. might expected, keeping mind no-free
lunch theorem diversity functions test set, tests show
crossover whose results significatively better results crossovers.
mean differences could exist certain kinds functions.
So, order determine kind function whether crossover better
others, performed ANOVA analysis factor crossover
operator multiple comparison test. Additionally, graphically study speed
convergence RCGA regard crossover operator. order enforce
clearness graphics crossover, show curve best performing
set parameters BLX SBX crossovers.
Crossover
CIXL2
BLX(0.3)
BLX(0.5)
SBX(2)
SBX(5)
Ext. F.
Logical
UNDX
CIXL2
BLX(0.3)
BLX(0.5)
SBX(2)
SBX(5)
Ext. F.
Logical
UNDX
CIXL2
BLX(0.3)
BLX(0.5)
SBX(2)
SBX(5)
Ext. F.
Logical
UNDX

Mean

St.Dev.
fSph
6.365e-16 2.456e-16
3.257e-16 1.396e-16
4.737e-16 4.737e-16
1.645e-12 8.874e-13
4.873e-12 3.053e-12
2.739e-15 1.880e-15
3.695e-13 1.670e-13
2.910e-05 1.473e-05
fRas
2.919e+00 1.809e+00
2.189e+00 1.417e+00
3.018e+00 1.683e+00
1.844e+01 4.417e+00
1.419e+01 3.704e+00
2.245e+01 4.914e+00
6.325e+01 1.012e+01
1.107e+02 1.242e+01
fGri
1.525e-02 1.387e-02
4.749e-02 4.579e-02
3.760e-02 2.874e-02
2.196e-02 1.874e-02
3.128e-02 2.737e-02
1.315e-03 3.470e-03
6.078e-03 6.457e-03
7.837e-02 4.438e-02

Mean
St.Dev.
fSchDS
1.995e-03 2.280e-03
1.783e-02 1.514e-02
9.332e-03 1.086e-02
2.033e-01 1.966e-01
3.933e-01 2.881e-01
3.968e+01 1.760e+01
1.099e+01 7.335e+00
2.080e+01 7.216e+00
fSch
6.410e+02 2.544e+02
3.695e+02 1.595e+02
4.200e+02 1.916e+02
1.470e+03 3.827e+02
1.104e+03 3.353e+02
3.049e+03 2.876e+02
2.629e+03 9.749e+01
8.050e+03 3.741e+02
fFle
1.523e+04 1.506e+04
1.570e+04 1.515e+04
1.802e+04 1.483e+04
3.263e+04 3.110e+04
3.333e+04 2.973e+04
1.691e+04 1.446e+04
2.718e+04 1.388e+04
3.469e+04 2.136e+04

Mean

St.Dev.
fRos
2.494e+01 1.283e+00
2.923e+01 1.723e+01
3.161e+01 2.094e+01
2.775e+01 9.178e+00
3.111e+01 1.971e+01
2.743e+01 1.394e+01
2.703e+01 8.358e-02
2.840e+01 3.606e-01
fAck
1.378e-08 5.677e-09
4.207e-08 1.713e-08
6.468e-08 1.928e-08
5.335e-06 1.453e-06
9.662e-06 2.377e-06
1.797e-07 5.823e-08
2.531e-06 7.129e-07
3.551e-02 1.224e-02
fLan
-2.064e-01 9.346e-02
-3.003e-01 1.388e-01
-3.457e-01 1.684e-01
-1.939e-01 1.086e-01
-1.866e-01 9.080e-02
-1.064e-01 5.517e-02
-7.396e-08 2.218e-07
-2.130e-01 9.116e-02

Table 3: Average values standard deviation 30 runs every crossover operator.

Table 3 shows average values standard deviations 30 runs performed
crossover operator. Table 10 Appendix shows how, functions, except
fRos , crossover operator significant effect linear model. table also
shows results Levene test indicate inequality variances
results functions, excepting fF le . So, use Bonferroni test fF le ,
Tamhane test others. results multiple comparison test, ranking
established tests significant level differences among results
crossovers shown Tables 14, 15 16 (Appendix A). Figures 5 - 13, Appendix
B, show, logarithmic scale, convergence curves function.
19

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

fSph high value determination coefficient shows linear model
explains much variance fitness. best values obtained BLX(0.3),
BLX(0.5) CIXL2, order. operators obtain precisions around
1e-16. Figure 5 shows CIXL2 fastest convergence, surpassed BLX
last generations.
fSchDS fRos best results obtained CIXL2. fSchDS difference
performance crossovers statistically significant. f Ros differences
significant, CIXL2 compared Logical UNDX. f SchDS Figure 6
shows CIXL2 achieves quasi-exponential convergence precise final result.
fRos , Figure 7 see speed convergence CIXL2 highest,
although profile crossovers similar fast initial convergence
followed poor evolution due high epistasis function. differences
overall process small. fact explains linear model influence
factor crossover significant determination coefficient small.
fRas , BLX(0.3) obtains best results without significant difference
average values obtained CIXL2 BLX(0.5). three operators also obtain
best results fSch ; however, tests show significant differences
CIXL2 BLX(0.5), differences BLX(0.5) BLX(0.3).
latter obtains best results. Figures 8 9 show BLX best terms
convergence speed followed CIXL2. large value R 2 means crossover
significant influence evolutive process.
fAck , CIXL2 obtains significantly better results. Figure 10 see
also converges faster. large value R2 means crossover significant
influence evolutive process. fGri , Fuzzy operator obtains significantly better
results. following ones, significant differences them, Logical
CIXL2. Figure 11 shows fast initial convergence CIXL2, end Logical
Fuzzy obtain better results.
fF le best results obtained CIXL2, difference significant
SBX UNDX. Figure 12 shows CIXL2 fastest convergence,
curve profile similar BLX Fuzzy. fLan , best operator BLX(0.5),
differences significant operators exception BLX(0.3).
UNDX CIXL2 together third place. Figure 13 shows behavior
crossovers similar, except Logical crossover converges value far
operators.

7. Comparison Estimation Distribution Algorithms
EDAs evolutionary algorithms use, CIXL2, best individuals population
direct search. comparison paradigm interesting, although
significant differences EDAs RCGAs.
EDAs remove operators crossover mutation. generation subset
population selected distribution individuals subset estimated.
individuals population next generation obtained sampling estimated
distribution. Although selection method could applied, common one
selection best individuals population.
20

fiCIXL2: Crossover Operator Evolutionary Algorithms

first EDAs developed discrete spaces. Later, adapted continuous domains. distinguish two types EDAs, whether take account
dependencies variables not. One used among EDAs
consider dependencies U DAc (Univariate Marginal Distribution Algorithm continuous domains) (Larranaga, Etxeberria, Lozano, & Pena, 2000). every generation
every variable U DAc carries statistical test order find density
function best fits variable. densities identified, estimation
parameters performed maximum likelihood estimates. distributions
normal, two parameters mean standard deviation. particular
case denoted U DAG
c (Univariate Marginal Distribution Algorithm Gaussian
models).
Among type EDAs, consider EGN ABGe (Estimation Gaussian
Network Algorithm) (Larranaga et al., 2000) whose good results function optimization
reported Bengoetxea Miquelez (2002). generation, EGN BGe learns
Gaussian network structure using Bayesian score gives value
Gaussian networks reflecting conditional dependencies used. Next, calculates
estimations parameters Gaussian network structure.
experiments used parameters reported Bengoetxea T. Miquelez
(2002): population 2000 individuals, initialized using uniform distribution,
subset best 1000 individuals selected estimate density function,
elitist approach chosen (the best individual included next population 1999
individuals simulated). algorithm run 30 times stop criterion
300,000 evaluations fitness function.
results EDAs compared results RCGA CIXL2 parameters
n = 5 1 = 0.70. performed ANOVA analysis three levels
factor different algorithms: RCGA CIXL2, U DAc EGN ABGe . also
carried multiple comparison test.
Table 4 shows average values standard deviations 30 runs algorithm.
Table 11 Appendix shows how, functions excepting fAck , type algorithm significant effect linear model exist inequality variances
results (Levene test). So, used Tamhane test functions Bonferroni test fAck . Table 17 (Appendix A) shows results multiple comparison test
ranking established test.
fSph results similar. fitness behaves singular random variable
sample variance near 0 statistical tests feasible.
fSchDS results CIXL2 significantly better results U DAc
EGN ABGe . situation occurs fRos , fRas , fSch fAck , exception
four functions significant differences two EDAs.
fGri , EGN ABGe U DAc achieve best results, significantly better CIXL2.
fF le , U DAc significantly better EGN ABGe CIXL2,
differences two. fLan , CIXL2 obtains best results,
significant differences among three algorithms.
estimation distribution function best individuals population
performed EDAs advantage fSph , unimodal separable, fGri fAck
whose optima regularly distributed. results EDAs fGri better
21

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

results CIXL2, results fAck worse. results fSph
algorithms similar. non-separable unimodal functions, f SchDS fRos ,
interdependence among variables favor performance EGN BGe
U DAc CIXL2. Nevertheless, CIXL2 achieves best results two functions.
multimodal separable functions, fRas fSch , difficult identify distribution
best individuals performance EDAs performance CIXL2.
extremely complex functions, fF le fLan , results less conclusive.
fF le best results obtained U DAc , differences
EGN ABGe CIXL2. fLan , CIXL2 achieves best results, differences
among three algorithms statistically significant.
EA
CIXL2
U DAc
EGN ABGe
CIXL2
U DAc
EGN ABGe
CIXL2
U DAc
EGN ABGe

Mean

St.Dev.
fSph
6.365e-16 2.456e-16
1.196e-16 1.713e-17
1.077e-16 1.001e-17
fRas
2.919e+00 1.809e+00
1.576e+02 7.382e+00
1.563e+02 8.525e+00
fGri
1.525e-02 1.387e-02
9.465e-16 1.207e-16
8.200e-16 1.149e-16

Mean
St.Dev.
fSchDS
1.995e-03 2.280e-03
2.221e+01 3.900e+00
2.096e-01 1.189e-01
fSch
6.410e+02 2.544e+02
1.153e+04 9.167e+01
1.155e+04 8.754e+01
fFle
1.523e+04 1.506e+04
5.423e+03 1.562e+03
9.069e+03 7.592e+03

Mean

St.Dev.
fRos
2.494e+01 1.283e+00
2.787e+01 2.278e-02
2.785e+01 1.629e-01
fAck
1.378e-08 5.677e-09
2.478e-08 1.831e-09
2.297e-08 2.095e-09
fLan
-2.064e-01 9.346e-02
-1.734e-01 4.258e-11
-1.734e-01 1.864e-11

Table 4: Average values standard deviation 30 runs three evolutionary algorithms: RCGA CIXL2 crossover, U DAc EGN ABGe .

8. Application Artificial Intelligence
Genetic algorithms applied almost kind problem, as, object recognition artificial vision (Singh, Chatterjee, & Chaudhury, 1997; Bebis, Louis, Varol, &
Yfantis, 2002), robotics path planing (Davidor, 1991; Sedighi, Ashenayi, Manikas, Wainwright, & Tai, 2004), parameter estimation (Johnson & Husbands, 1990; Ortiz-Boyer,
Hervas-Martnez, & Munoz-Perez, 2003), instance selection (Cano, Herrera, & Lozano,
2003; Kuncheva, 1995), reinforcement learning (Moriarty, Schultz, & Grefenstette, 1999),
neural network (Miller, Todd, & Hedge, 1991; Andersen & Tsoi, 1993; Bebis, Georgiopoulos, & Kasparis, 1997) ensemble design (Zhou, Wu, & Tang, 2002).
Real-coded genetic algorithms using CIXL2 applied problems
provided defined continuous domain. chosen application RCGAs
estimation weight network ensemble. interesting
problem standard methods encounter many difficulties.
8.1 Estimation Weights Networks Ensemble
Neural network ensembles (Perrone & Cooper, 1993) (Garca-Pedrajas, Hervas-Martnez,
& Ortiz-Boyer, 2005) receiving increasing attention recent neural network research,
due interesting features. powerful tool specially facing complex
22

fiCIXL2: Crossover Operator Evolutionary Algorithms

problems. Network ensembles made linear combination several networks
trained using data, although actual sample used network
learn different. network within ensemble potentially different weight
output ensemble. Several papers shown (Perrone & Cooper, 1993)
network ensemble generalization error generally smaller obtained
single network also variance ensemble lesser variance
single network. output ensemble, y, input pattern x presented, is:
y(x) =

k
X

yi (x),

(15)

i=1

yi output network i, wi weight associated network.
networks one output, different weight usually assigned output.
ensembles neural networks advantages large networks without
problems long training time risk over-fitting.
Moreover, combination several networks cooperate solving given task
important advantages, (Liu, Yao, & Higuchi, 2000; Sharkey, 1996):
perform complex tasks subcomponents.
make overall system easier understand modify.
robust single network.
Techniques using multiple models usually consist two independent phases: model
generation model combination (Merz, 1999b). network trained
assigned weights (model generation), are, classification environment three basic
methods combining outputs networks (model combination):
1. Majority voting. pattern classified class majority networks places (Merz, 1999b). Majority voting effective, prone fail two
scenarios:
(a) subset redundant less accurate models comprise majority,
(b) dissenting vote recognized area specialization particular model.
2. Sum outputs networks. output ensemble sum
outputs individual networks.
3. Winner takes all. pattern assigned class highest output
outputs networks. is, network largest outputs directly
classify pattern, without taking account networks.
commonly used methods combining networks majority voting
sum outputs networks, weight vector measures
23

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

confidence prediction network. problem obtaining weight vector
easy task. Usually, values weights constrained:
N
X

= 1,

(16)

i=1

order help produce estimators lower prediction error (Leblanc & Tibshirani,
1993), although justification constraint intuitive (Breiman, 1996).
method majority voting applied, vote network weighted
counted:
F (x) = arg maxy

X

.

(17)

i:fi (x)=y

problem finding optimal weight vector complex task. Basic
ensemble method (BEM), called Perrone Cooper (1993), consists weighting
networks equally. So, N networks, output ensembles is:
F (x) =

N
1 X
fi (x).
N

(18)

i=1

Perrone Cooper (1993) defined Generalized Ensemble Method, equivalent Mean Square Error - Optimal Linear Combination (MSE-OLC) without
constant term Hashem (Hashem, 1997). form output ensemble is:
fGEM (x)

N
X

fi (x),

(19)

i=1

i0 real satisfy constraint
by:

PN

i=1

1
j Cij
= P P 1 .
k
j Ckj

P

= 1. values given

(20)

Cij symmetric correlation matrix Cij E[mi (x)mj (x)], mk (x) defines
misfit function k, deviation true solution f (x), mk (x) f (x)
fk (x). previous methods commonly used. Nevertheless, many techniques
proposed last years. Among others, methods based
linear regression (Leblanc & Tibshirani, 1993), principal components analysis leastsquare regression (Merz, 1999a), correspondence analysis (Merz, 1999b), use
validation set (Opitz & Shavlik, 1996).
application, use genetic algorithm obtaining weight component. approach similar use gradient descent procedure (Kivinen &
Warmuth, 1997), avoiding problem trapped local minima. use
genetic algorithm additional advantage optimal linear combination,
former affected collinearity problem (Perrone & Cooper, 1993; Hashem, 1997).
24

fiCIXL2: Crossover Operator Evolutionary Algorithms

8.1.1 Experimental Setup
set available data divided two subsets: 75% patterns used
learning, remaining 25% testing generalization networks.
two exceptions, Sonar Vowel problems, patterns two problems
prearranged two specific subsets due particular features. summary
data sets shown Table 5. validation set used experiments.
Data set
Anneal
Autos
Balance
Breast-cancer
Card
German
Glass
Heart
Hepatitis
Horse
Ionosphere
Iris
Labor
Liver
Lymphography
Pima
Promoters
Segment
Sonar
Soybean
TicTacToe
Vehicle
Vote
Vowel
Zoo

Cases
Train Test
674
224
154
51
469
156
215
71
518
172
750
250
161
53
226
76
117
38
273
91
264
87
113
37
43
14
259
86
111
37
576
192
80
26
1733 577
104
104
513
170
719
239
635
211
327
108
528
462
76
25

Classes
5
6
3
2
2
2
6
2
2
3
2
3
2
2
4
2
2
7
2
19
2
4
2
11
7

Features
C B N
6 14 18
15 4
6
4



3
6
6
4
5
6
3 11
9


6
3
4
6 13
13 2
5
33 1

4


8
3
5
6



9
6
8

57
19

60

16 19


9
18

16
10

1 15

Inputs
59
72
4
15
51
61
9
22
19
58
34
4
29
2
38
8
114
19
60
82
9
18
16
10
16

Table 5: Summary data sets. features data set C(continuous),
B(binary) N(nominal). Inputs column shows number inputs
network depends number input variables also
type.

data sets cover wide variety problems. problems different
numbers available patterns, 57 2310, different numbers classes, 2
19, different kinds inputs, nominal, binary continuous, different areas
25

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

application, medical diagnosis vowel recognition. Testing model wide
variety problems give us clear idea performance. sets
method applied.
order test efficiency proposed crossover classical artificial intelligence
problem, used RCGA adjust weight network within ensemble.
method considers ensemble chromosome applies RCGA optimize
weight network. weight network ensemble codified
real number. chromosome formed way subject CIXL2 crossover nonuniform mutation. parameters CIXL2 used rest paper,
n = 5 1 = 0.7. combination method used weighted sum outputs
networks. Nevertheless, genetic algorithm could used weighting
network majority voting model used.
exact conditions experiments run algorithms
following:
ensemble formed 30 networks. network trained separately using
standard back-propagation algorithm using learning data.
30 networks trained, different methods obtaining
weights applied. So, methods use ensemble networks
run experiment. genetic algorithm, fitness individual
population classification accuracy learning set.
obtaining vector weights, generalization error method evaluated using testing data.
Tables 6 7 show results terms accurate classification 25 problems.
tables show results using RCGA CIXL2, standard BEM GEM
methods. order compare three methods performed sign test
win/draw/loss record three algorithms (Webb, 2000). tests shown Table
8.
Table 8 shows comparison statistics three models (Webb, 2000).
model show win/draw/loss statistic, first value number data sets
col < row, second number col = row, third
number col > row. second row shows p-value two-tailed sign test
win-loss record. table shows genetic algorithm using CIXL2 able
outperform two standard algorithms BEM GEM 10% confidence.
hand, significant differences BEM GEM. result
especially interesting used comprehensive set problems
different domains, different types inputs, different numbers classes.

9. Conclusions Future Work
paper proposed crossover operator allows offspring inherit
features common best individuals population. extraction common
features carried determination confidence intervals mean
26

fiCIXL2: Crossover Operator Evolutionary Algorithms

Problem
Anneal

Autos

Balance

Breast

Cancer

Card

German

Glass

Heart

Hepa.

Horse

Ionos.

Iris

CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM

Mean
0.9933
0.9879
0.9915
0.8957
0.8649
0.8740
0.9340
0.9179
0.9148
0.8575
0.8321
0.8274
0.9723
0.9678
0.9673
0.9201
0.9074
0.9049
0.8785
0.8587
0.8642
0.8509
0.8043
0.8246
0.9297
0.9089
0.9182
0.9385
0.9131
0.9179
0.8723
0.8444
0.8485
0.9635
0.9481
0.9554
1.0000
1.0000
1.0000

Learning
St.Dev.
Best
0.0046 0.9985
0.0054 0.9955
0.0054 0.9985
0.0233 0.9416
0.0211 0.9091
0.0262 0.9351
0.0067 0.9446
0.0068 0.9318
0.0101 0.9318
0.0195 0.8930
0.0287 0.8698
0.0314 0.8791
0.0021 0.9771
0.0034 0.9733
0.0034 0.9733
0.0087 0.9363
0.0088 0.9247
0.0093 0.9208
0.0080 0.8973
0.0090 0.8827
0.0099 0.8827
0.0225 0.9006
0.0246 0.8447
0.0293 0.8820
0.0216 0.9653
0.0214 0.9604
0.0239 0.9554
0.0224 0.9744
0.0253 0.9573
0.0289 0.9744
0.0174 0.9084
0.0194 0.8718
0.0207 0.8864
0.0164 0.9886
0.0171 0.9773
0.0205 0.9886
0.0000 1.0000
0.0000 1.0000
0.0000 1.0000

Worst
0.9777
0.9733
0.9777
0.8506
0.8312
0.8182
0.9232
0.9019
0.8785
0.8047
0.7395
0.7488
0.9676
0.9600
0.9581
0.9054
0.8880
0.8822
0.8653
0.8440
0.8427
0.8075
0.7578
0.7640
0.8861
0.8663
0.8663
0.8718
0.8462
0.8376
0.8315
0.7949
0.8095
0.9356
0.9167
0.9167
1.0000
1.0000
1.0000

Mean
0.9778
0.9729
0.9780
0.7261
0.7052
0.7033
0.9201
0.9158
0.9158
0.6892
0.6826
0.6817
0.9799
0.9793
0.9785
0.8574
0.8521
0.8533
0.7333
0.7355
0.7377
0.6962
0.6824
0.6855
0.8358
0.8333
0.8279
0.8702
0.8658
0.8711
0.7044
0.7000
0.7004
0.8950
0.8920
0.8958
1.0000
1.0000
1.0000

Test
St.Dev.
Best
0.0090 0.9911
0.0091 0.9911
0.0103 0.9911
0.0577 0.8235
0.0586 0.8039
0.0707 0.8039
0.0118 0.9487
0.0111 0.9423
0.0110 0.9359
0.0322 0.7465
0.0375 0.7606
0.0354 0.7324
0.0065 0.9885
0.0076 0.9943
0.0084 0.9885
0.0153 0.8895
0.0212 0.8953
0.0203 0.8953
0.0184 0.7640
0.0141 0.7600
0.0149 0.7680
0.0365 0.7736
0.0424 0.7925
0.0479 0.7736
0.0271 0.8971
0.0263 0.8824
0.0312 0.8971
0.0372 0.9211
0.0319 0.9211
0.0399 0.9474
0.0313 0.7692
0.0301 0.7582
0.0300 0.7802
0.0225 0.9195
0.0206 0.9195
0.0198 0.9310
0.0000 1.0000
0.0000 1.0000
0.0000 1.0000

Worst
0.9420
0.9464
0.9420
0.5882
0.5686
0.5294
0.8910
0.8910
0.8910
0.6338
0.6056
0.6056
0.9655
0.9655
0.9598
0.8256
0.7965
0.7965
0.7000
0.7040
0.7160
0.6038
0.6038
0.6038
0.7794
0.7794
0.7794
0.8158
0.8158
0.7895
0.6264
0.6374
0.6484
0.8276
0.8276
0.8621
1.0000
1.0000
1.0000

Table 6: Ensemble results using real-coded genetic algorithm (CIXL2), basic ensemble
method (BEM), generalized ensemble method (GEM). problem
marked whichever CIXL2 better (+), equal, (=), worse (-)
BEM/GEM.
27

+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
=
=

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

Problem
Labor

Liver

Lymph

Pima

Promot.

Segment

Sonar

Soybean

TicTacToe

Vote

Vowel

Zoo

CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM
CIXL2
BEM
GEM

Mean
0.9651
0.9488
0.9527
0.8126
0.7799
0.7744
0.9456
0.9318
0.9306
0.7982
0.7782
0.7752
0.9496
0.9300
0.9263
0.9502
0.9339
0.9423
0.9074
0.8859
0.8907
0.9758
0.9602
0.9691
0.9913
0.9868
0.9876
0.9832
0.9793
0.9801
0.9146
0.8733
0.9157
0.9807
0.9671
0.9750

Learning
St.Dev.
Best
0.0257 1.0000
0.0283 0.9767
0.0270 0.9767
0.0175 0.8494
0.0176 0.8108
0.0198 0.8108
0.0208 0.9730
0.0242 0.9640
0.0254 0.9730
0.0073 0.8194
0.0079 0.7934
0.0089 0.7882
0.0304 1.0000
0.0357 0.9875
0.0319 0.9875
0.0030 0.9544
0.0042 0.9411
0.0044 0.9521
0.0236 0.9519
0.0266 0.9423
0.0277 0.9519
0.0114 0.9903
0.0130 0.9805
0.0157 0.9883
0.0027 0.9972
0.0020 0.9917
0.0024 0.9930
0.0055 0.9939
0.0060 0.9908
0.0062 0.9908
0.0148 0.9432
0.0179 0.9015
0.0129 0.9394
0.0175 1.0000
0.0215 1.0000
0.0203 1.0000

Worst
0.8837
0.8837
0.8837
0.7761
0.7336
0.7336
0.8919
0.8739
0.8559
0.7830
0.7535
0.7431
0.8875
0.8500
0.8625
0.9446
0.9256
0.9319
0.8654
0.8269
0.8365
0.9454
0.9240
0.9376
0.9847
0.9847
0.9847
0.9725
0.9664
0.9664
0.8845
0.8371
0.8845
0.9211
0.9079
0.9211

Mean
0.8857
0.8833
0.8833
0.6992
0.6950
0.6826
0.7847
0.7775
0.7784
0.7811
0.7885
0.7793
0.8244
0.8269
0.8218
0.9259
0.9183
0.9236
0.7849
0.7865
0.7853
0.9057
0.9039
0.9067
0.9794
0.9791
0.9792
0.9278
0.9284
0.9262
0.4925
0.4913
0.4973
0.9360
0.9307
0.9307

Test
St.Dev.
Best
0.0550 1.0000
0.0663 1.0000
0.0689 1.0000
0.0276 0.7442
0.0253 0.7442
0.0337 0.7442
0.0538 0.8649
0.0539 0.8649
0.0504 0.8378
0.0209 0.8177
0.0199 0.8177
0.0222 0.8281
0.0726 1.0000
0.0612 0.9231
0.0711 0.9615
0.0057 0.9376
0.0054 0.9341
0.0061 0.9359
0.0286 0.8462
0.0286 0.8365
0.0266 0.8462
0.0165 0.9353
0.0182 0.9353
0.0187 0.9353
0.0024 0.9874
0.0000 0.9791
0.0008 0.9833
0.0110 0.9537
0.0068 0.9444
0.0107 0.9444
0.0293 0.5606
0.0331 0.5584
0.0342 0.5541
0.0290 0.9600
0.0392 0.9600
0.0347 0.9600

Worst
0.7857
0.7143
0.7143
0.6512
0.6395
0.6047
0.6486
0.6486
0.6486
0.7292
0.7448
0.7292
0.7308
0.7308
0.6923
0.9151
0.9081
0.9116
0.7404
0.7212
0.7404
0.8706
0.8647
0.8706
0.9749
0.9791
0.9791
0.8889
0.9167
0.8981
0.4459
0.4264
0.4221
0.8800
0.8400
0.8400

Table 7: Ensemble results using real-coded genetic algorithm (CIXL2), basic ensemble
method (BEM), generalized ensemble method (GEM). problem
marked whichever CIXL2 better (+), equal, (=), worse (-)
BEM/GEM.

28

+
+
+
+
+
+

+

+
+
+


+

+
+

+
+

+
+

fiCIXL2: Crossover Operator Evolutionary Algorithms

Algorithm
CIXL2
BEM

BEM
19/1/5
0.0066

GEM
17/1/7
0.0639
9/4/12
0.6636

win/draw/loss
p-value
win/draw/loss
p-value

Table 8: Comparison three methods. Win/draw/loss record algorithms
p-value sign test.

best individuals population. confidence intervals, CIXL2 creates three
virtual parents used implement directed search towards region fittest
individuals. amplitude speed search determined number best
individuals selected confidence coefficient.
study carried order obtain best parameters CIXL2 concludes
value n = 5 best individuals suitable obtain localization estimator guide
search problems tested. However, difficult problems, would
advisable larger value n avoid premature convergence evolutionary
process. confident coefficient, 1 , responsible, together dispersion
best individuals, modulation wideness confidence interval centered
localization estimator. study results best value 1 = 0.70. pair
values acceptable performance problems, although optimum
pair values problems.
comparative analysis crossover operators shows CIXL2 good alternative widely used crossovers BLX unimodal function fSph , fSchDS ,
fRos . Noteworthy performance CIXL2 two non-separable functions,
fSchDS fRos , crossovers disparate behavior.
unimodal functions strategy extracting statistical features localization
dispersion best individuals guarantee good performance, case
multimodal functions quite different, performance algorithm assured
priori. Nevertheless, results obtained kind functions show CIXL2
always one best performing operators. instance, functions high complexity
fAck multimodal, non-separable regular fF le multimodal, nonseparable irregular CIXL2 obtains best results. behavior reveals
determination region best individuals means confidence intervals
provides robust methodology that, applied crossover operator, shows interesting
performance even difficult functions. summary, affirm paper
proves CIXL2 promising alternative bear mind, must choose
crossover use real-coded genetic algorithm.
EDAs shown good performance unimodal separable functions, f Sph ,
functions whose optima regularly distributed, fAck fGri . performance
EDAs decreases multimodal, fRas fSch , epistatic functions, fSchDS fRos .
hand, CIXL2 less sensitive type function. main reason
behavior may found fact CIXL2 uses distribution information obtained
best individuals population differently. CIXL2 creates three virtual parents
29

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

distribution, virtual parents worse fitness individual
mates, offspring generated near virtual parents. way, CIXL2
prevents shifting population confidence interval improvement
performance significant.
applicability proposed crossover problem artificial neural network
ensembles shows model used solving standard artificial intelligence
problems. RCGAs CIXL2 also used aspects ensemble design,
as, selection subset networks, sampling training set network.
promising results motivate beginning new line research geared
study distribution best individuals taking account kind problem
hand. aim propose new techniques selection individuals considered
obtaining confidence interval reliable way. multimodal, irregular,
many chaotically scattered optima functions difficulty obtaining distributions
best individuals enormous. kind functions would interesting
perform cluster analysis selected best individuals obtain confidence interval
every cluster. idea would allow implementation multi-directional crossover
towards different promising regions.
hand, likely evolutive process progresses distribution
best individuals changes. case, would advisable perform, regular
intervals, statistical tests determine distribution best reflects features
best individuals population.
Alternatively, considering construction non-parametric confidence intervals.
way, need robust estimators parameters localization dispersion
genes best individuals. performed preliminary studies using
median different measures dispersion results quite encouraging.
Another research line currently open study application CIXL2 problems optimization restrictions, especially presence non-linearity,
generation individuals feasible region big issue. orientation
search based identification region best individuals implemented
CIXL2 could favor generation feasible individuals. feature would
interesting advantage respect crossover operators.

Acknowledgments
authors would like acknowledge R. Moya-Sanchez helping final version
paper.
work financed part project TIC2002-04036-C05-02 Spanish
Inter-Ministerial Commission Science Technology (CICYT) FEDER funds.

30

fiCIXL2: Crossover Operator Evolutionary Algorithms

Appendix A. Results Statistical Study
Function
fSph
fSchDS
fRos
fRas
fSch
fAck
fGri
fF le
fLan

C
1.000
0.000
0.005
0.000
0.000
0.095
0.149
0.410
0.040

B
1.000
0.000
0.000
0.000
0.000
0.000
0.001
0.000
0.000

CB

0.000
0.006
0.000
0.000
0.019


0.024

R2

0.601
0.526
0.617
0.805
0.083
0.040
0.054
0.159

T. Levene
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.003
0.000

Table 9: Significant levels, , term linear model, determination coefficient
R2 , value Levene test statistical analysis CIXL2 parameters.

Function
fSph
fSchDS
fRos
fRas
fSch
fAck
fGri
fF le
fLan

Crossover
0.000
0.000
0.573
0.000
0.000
0.000
0.000
0.000
0.000

R2
0.779
0.786
0.024
0.971
0.987
0.884
0.421
0.137
0.486

Levene test
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.091
0.000

Table 10: Significance level crossover operator determination coefficient R 2
linear model, value Levene test comparative study crossovers.

Function
fSchDS
fRos
fRas
fSch
fAck
fGri
fF le
fLan

EA
0.000
0.000
0.000
0.000
1.000
0.000
0.001
0.027

R2
0.955
0.778
0.992
0.999
0.641
0.455
0.150
0.079

Levene test
0.000
0.000
0.000
0.000
1.000
0.000
0.000
0.000

Table 11: Significance level evolutionary algorithms determination coefficient R 2
linear model, value Levene test comparative study betwen
CIXL2 EDAs.

31

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas



J

5

10
30
60
90
10
5
30
60
90
30
5
10
60
90
60
5
10
30
90
90
5
10
30
60
Ranking

5

10
30
60
90
10
5
30
60
90
30
5
10
60
90
60
5
10
30
90
90
5
10
30
60
Ranking

5

10
30
60
90
10
5
30
60
90
30
5
10
60
90
60
5
10
30
90
90
5
10
30
60
Ranking



J
fSph
-2.683e-15
-4.144e-11
-1.836e-07
-5.554e-08
2.683e-15
-4.144e-11
-1.836e-07
-5.554e-08
4.144e-11
4.144e-11
-1.835e-07
-5.549e-08
1.836e-07
1.836e-07
1.835e-07
1.281e-07
5.554e-08
5.554e-08
5.549e-08
-1.281e-07
60 > 90 > 30
fRas
-5.79e+00
-6.72e+00
-1.01e+01
-1.51e+01
5.79e+00
-9.31e-01
-4.30e+00
-9.32e+00
6.72e+00
9.31e-01
-3.37e+00
-8.39e+00
1.01e+01
4.30e+00
3.37e+00
-5.02e+00
1.51e+01
9.32e+00
8.39e+00
5.02e+00
90 > 60 >
30 >

0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.003
0.000
0.000
0.000
0.003
> 10 > 5

0.000
0.000
0.000
0.000
0.000
0.807
0.000
0.000
0.000
0.807
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
10 > 5
5

fGri
-7.207E-03
0.174
-3.896E-03
0.864
2.329E-03
1.000
8.649E-03
0.001
7.207E-03
0.174
3.311E-03
0.983
9.535E-03
0.533
1.586E-02
0.000
3.896E-03
0.864
-3.311E-03
0.983
6.225E-03
0.930
1.254E-02
0.000
-2.329E-03
1.000
-9.535E-03
0.533
-6.225E-03
0.930
6.320E-03
0.884
-8.649E-03
0.001
-1.586E-02
0.000
-1.254E-02
0.000
-6.320E-03
0.884
60 90
5 > 90
10 > 90
30 > 90

J



fSchDS
-2.540e-02
0.000
-1.899e-01
0.000
-2.371e-01
0.000
-1.004e+00
0.000
2.540e-02
0.000
-1.645e-01
0.000
-2.117e-01
0.000
-9.785e-01
0.000
1.899e-01
0.000
1.645e-01
0.000
-4.720e-02
0.572
-8.140e-01
0.000
2.371e-01
0.000
2.117e-01
0.000
4.720e-02
0.572
-7.668e-01
0.000
1.004e+00
0.000
9.785e-01
0.000
8.140e-01
0.000
7.668e-01
0.000
90 > 30 > 10 > 5
60 > 5
fSch
-2.691e+02
0.082
-7.338e+02
0.000
-9.559e+02
0.000
-1.148e+03
0.000
2.691e+02
0.082
-4.647e+02
0.000
-6.868e+02
0.000
-8.786e+02
0.000
7.338e+02
0.000
4.647e+02
0.000
-2.221e+02
0.000
-4.139e+02
0.000
9.559e+02
0.000
6.868e+02
0.000
2.221e+02
0.000
-1.918e+02
0.000
1.148e+03
0.000
8.786e+02
0.000
4.139e+02
0.000
1.918e+02
0.000
90 > 60 > 30 > 5
10 5
fFle
-2.776e+03
0.885
-7.968e+03
0.004
-7.342e+03
0.008
-1.268e+04
0.000
2.776e+03
0.885
-5.192e+03
0.234
-4.566e+03
0.378
-9.899e+03
0.006
7.968e+03
0.004
5.192e+03
0.234
6.254e+02
1.000
-4.707e+03
0.678
7.342e+03
0.008
4.566e+03
0.378
-6.254e+02
1.000
-5.333e+03
0.491
1.268e+04
0.000
9.899e+03
0.006
4.707e+03
0.678
5.333e+03
0.491
10 5
30 > 5
60 > 5
90 > 5

J
fRos
-9.433e-01
-1.486e+00
-1.058e+00
-8.375e-01
9.433e-01
-5.425e-01
-1.142e-01
1.058e-01
1.486e+00
5.425e-01
4.283e-01
6.483e-01
1.058e+00
1.142e-01
-4.283e-01
2.200e-01
8.375e-01
-1.058e-01
-6.483e-01
-2.200e-01
30 > 60 > 10


0.000
0.000
0.000
0.000
0.000
0.000
0.025
0.014
0.000
0.000
0.000
0.000
0.000
0.025
0.000
0.000
0.000
0.014
0.000
0.000
> 90 > 5

fAck
-1.063e-07
0.000
-2.384e-05
0.000
-1.508e-03
0.000
-6.769e-02
0.216
1.063e-07
0.000
-2.373e-05
0.000
-1.508e-03
0.000
-6.769e-02
0.216
2.384e-05
0.000
2.373e-05
0.000
-1.484e-03
0.000
-6.767e-02
0.216
1.508e-03
0.000
1.508e-03
0.000
1.484e-03
0.000
-6.619e-02
0.242
6.769e-02
0.216
6.769e-02
0.216
6.767e-02
0.216
6.619e-02
0.242
60 > 30 > 10 > 5
90 5
fLan
-1.354e-02
0.998
-5.881e-02
0.009
-8.794e-02
0.000
-1.142e-01
0.000
1.354e-02
0.998
-4.527e-02
0.082
-7.440e-02
0.000
-1.007e-01
0.000
5.881e-02
0.009
4.527e-02
0.082
-2.913e-02
0.354
-5.540e-02
0.000
8.794e-02
0.000
7.440e-02
0.000
2.913e-02
0.354
-2.627e-02
0.247
1.142e-01
0.000
1.007e-01
0.000
5.540e-02
0.000
2.627e-02
0.247
10 5
30 > 5
60 > 5
90 > 5

Table 12: Results functions multiple comparison test ranking
obtained depending number best individuals n.

32

fiCIXL2: Crossover Operator Evolutionary Algorithms



J

0.70

0.90
0.95
0.99
0.90
0.70
0.95
0.99
0.95
0.70
0.90
0.99
0.99
0.70
0.90
0.95
Ranking

J
fSph
-1.361e-08
-4.394e-08
-1.302e-07
1.361e-08
-3.033e-08
-1.166e-07
4.394e-08
3.033e-08
-8.628e-08
1.302e-07
1.166e-07
8.628e-08


0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.019
0.000
0.000
0.019

0.99 > 0.95 > 0.90 > 0.70

J
fSchDS
-3.985e-01
-3.783e-02
8.165e-02
3.985e-01
3.607e-01
4.802e-01
3.783e-02
-3.607e-01
1.195e-01
-8.165e-02
-4.802e-01
-1.195e-01


0.000
0.967
0.114
0.000
0.001
0.000
0.967
0.001
0.013
0.114
0.000
0.013

0.90 > 0.95 > 0.99

J
fRos
-1.360e-01
-1.693e-01
-1.813e-01
1.360e-01
-3.333e-02
-4.533e-02
1.693e-01
3.333e-02
-1.200e-02
1.813e-01
4.533e-02
1.200e-02


0.281
0.131
0.310
0.281
0.995
0.996
0.131
0.995
1.000
0.310
0.996
1.000

0.99 0.95 0.90 0.70

0.70 0.99

0.70

0.90
0.95
0.99
0.90
0.70
0.95
0.99
0.95
0.70
0.90
0.99
0.99
0.70
0.90
0.95
Ranking

0.70

0.90
0.95
0.99
0.90
0.70
0.95
0.99
0.95
0.70
0.90
0.99
0.99
0.70
0.90
0.95
Ranking

fRas
-4.23e+00
-3.59e+00
-5.56e+00
4.23e+00
6.40e-01
-1.33e+00
3.59e+00
-6.40e-01
-1.97e+00
5.56e+00
1.33e+00
1.97e+00

0.000
0.000
0.000
0.000
0.966
0.551
0.000
0.966
0.044
0.000
0.551
0.044

0.99 > 0.95 > 0.70
0.90 > 0.70

fGri
-7.196E-03
-2.027E-03
-5.667E-03
7.196E-03
5.168E-03
1.529E-03
2.027E-03
-5.168E-03
-3.640E-03
5.667E-03
-1.529E-03
3.640E-03

0.395
0.945
0.155
0.395
0.791
1.000
0.945
0.791
0.747
0.155
1.000
0.747

0.90 0.99 0.95 0.70

fSch
1.198e+02
8.247e+01
-3.008e+02
-1.198e+02
-3.736e+01
-4.206e+02
-8.247e+01
3.736e+01
-3.833e+02
3.008e+02
4.206e+02
3.833e+02

0.714
0.919
0.001
0.714
0.997
0.000
0.919
0.997
0.000
0.001
0.000
0.000

0.70 0.95 0.90
0.99 > 0.90

fFle
-2.986e+03
-3.241e+03
-3.079e+03
2.986e+03
-2.547e+02
-9.255e+01
3.241e+03
2.547e+02
1.622e+02
3.079e+03
9.255e+01
-1.622e+02

0.717
0.635
0.644
0.717
1.000
1.000
0.635
1.000
1.000
0.644
1.000
1.000

0.95 0.99 0.90 0.70

fAck
-2.471e-04
-1.944e-02
-3.541e-02
2.471e-04
-1.919e-02
-3.516e-02
1.944e-02
1.919e-02
-1.597e-02
3.541e-02
3.516e-02
1.597e-02

0.000
0.617
0.382
0.000
0.631
0.390
0.617
0.631
0.985
0.382
0.390
0.985

0.99 0.95 0.70
0.90 > 0.70

fLan
6.105e-03
2.867e-02
3.309e-02
-6.105e-03
2.257e-02
2.698e-02
-2.867e-02
-2.257e-02
4.415e-03
-3.309e-02
-2.698e-02
-4.415e-03

0.998
0.272
0.133
0.998
0.585
0.363
0.272
0.585
1.000
0.133
0.363
1.000

0.70 0.90 0.95 0.99

Table 13: Results functions multiple comparison test ranking
obtained depending confidence coefficient 1 .

33

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas



Crossover
J

CIXL2

BLX(0.3)

BLX(0.5)

SBX(2)

SBX(5)

Fuzzy

Logical

UNDX

Function
fSph
fSchDS
fRos

BLX(0.3)
BLX(0.5)
SBX(2)
SBX(5)
Fuzzy
Logical
UNDX
CIXL2
BLX(0.5)
SBX(2)
SBX(5)
Fuzzy
Logical
UNDX
CIXL2
BLX(0.3)
SBX(2)
SBX(5)
Fuzzy
Logical
UNDX
CIXL2
BLX(0.3)
BLX(0.5)
SBX(5)
Fuzzy
Logical
UNDX
CIXL2
BLX(0.3)
BLX(0.5)
SBX(2)
Fuzzy
Logical
UNDX
CIXL2
BLX(0.3)
BLX(0.5)
SBX(2)
SBX(5)
Logical
UNDX
CIXL2
BLX(0.3)
BLX(0.5)
SBX(2)
SBX(5)
Fuzzy
UNDX
CIXL2
BLX(0.3)
BLX(0.5)
SBX(2)
SBX(5)
Fuzzy
Logical

fSph
J
3.109e-16
1.628e-16
-1.644e-12
-4.873e-12
-2.102e-15
-3.689e-13
-2.910e-05
-3.109e-16
-1.480e-16
-1.644e-12
-4.873e-12
-2.413e-15
-3.692e-13
-2.910e-05
-1.628e-16
1.480e-16
-1.644e-12
-4.873e-12
-2.265e-15
-3.690e-13
-2.910e-05
1.644e-12
1.644e-12
1.644e-12
-3.229e-12
1.642e-12
1.275e-12
-2.910e-05
4.873e-12
4.873e-12
4.873e-12
3.229e-12
4.871e-12
4.504e-12
-2.910e-05
2.102e-15
2.413e-15
2.265e-15
-1.642e-12
-4.871e-12
-3.668e-13
-2.910e-05
3.689e-13
3.692e-13
3.690e-13
-1.275e-12
-4.504e-12
3.668e-13
-2.910e-05
2.910e-05
2.910e-05
2.910e-05
2.910e-05
2.910e-05
2.910e-05
2.910e-05

fSchDS
J





fRos
J



0.000
0.212
0.000
0.000
0.000
0.000
0.000
0.000
0.074
0.000
0.000
0.000
0.000
0.000
0.212
0.074
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000

-1.583e-02
0.000
-4.283e+00
0.997
-7.337e-03
0.028
-6.667e+00
0.933
-2.014e-01
0.000
-2.809e+00
0.958
-3.913e-01
0.000
-6.165e+00
0.944
-3.968e+01
0.000
-2.487e+00
1.000
-1.098e+01
0.000
-2.092e+00
0.000
-2.080e+01
0.000
-3.460e+00
0.000
1.583e-02
0.000
4.283e+00
0.997
8.495e-03
0.357
-2.384e+00
1.000
-1.855e-01
0.000
1.473e+00
1.000
-3.755e-01
0.000
-1.882e+00
1.000
-3.966e+01
0.000
1.796e+00
1.000
-1.097e+01
0.000
2.191e+00
1.000
-2.078e+01
0.000
8.225e-01
1.000
7.337e-03
0.028
6.667e+00
0.933
-8.495e-03
0.357
2.384e+00
1.000
-1.940e-01
0.000
3.857e+00
1.000
-3.840e-01
0.000
5.019e-01
1.000
-3.967e+01
0.000
4.179e+00
1.000
-1.098e+01
0.000
4.575e+00
1.000
-2.079e+01
0.000
3.206e+00
1.000
2.014e-01
0.000
2.809e+00
0.958
1.855e-01
0.000
-1.473e+00
1.000
1.940e-01
0.000
-3.857e+00
1.000
-1.900e-01
0.115
-3.355e+00
1.000
-3.948e+01
0.000
3.222e-01
1.000
-1.078e+01
0.000
7.179e-01
1.000
-2.060e+01
0.000
-6.508e-01
1.000
3.913e-01
0.000
6.165e+00
0.944
3.755e-01
0.000
1.882e+00
1.000
3.840e-01
0.000
-5.019e-01
1.000
1.900e-01
0.115
3.355e+00
1.000
-3.929e+01
0.000
3.678e+00
1.000
-1.059e+01
0.000
4.073e+00
1.000
-2.041e+01
0.000
2.705e+00
1.000
3.968e+01
0.000
2.487e+00
1.000
3.966e+01
0.000
-1.796e+00
1.000
3.967e+01
0.000
-4.179e+00
1.000
3.948e+01
0.000
-3.222e-01
1.000
3.929e+01
0.000
-3.678e+00
1.000
2.870e+01
0.000
3.957e-01
1.000
1.888e+01
0.000
-9.730e-01
1.000
1.098e+01
0.000
2.092e+00
0.000
1.097e+01
0.000
-2.191e+00
1.000
1.098e+01
0.000
-4.575e+00
1.000
1.078e+01
0.000
-7.179e-01
1.000
1.059e+01
0.000
-4.073e+00
1.000
-2.870e+01
0.000
-3.957e-01
1.000
-9.812e+00
0.000
-1.369e+00
0.000
2.080e+01
0.000
3.460e+00
0.000
2.078e+01
0.000
-8.225e-01
1.000
2.079e+01
0.000
-3.206e+00
1.000
2.060e+01
0.000
6.508e-01
1.000
2.041e+01
0.000
-2.705e+00
1.000
-1.888e+01
0.000
9.730e-01
1.000
9.812e+00
0.000
1.369e+00
0.000
Ranking
U N DX > SBX(5) > SBX(2) > Logical > Ext.F. > CIXL2 BLX(0.5) BLX(0.3)
Ext.F. > U N DX > Logical > SBX(5) SBX(2) > BLX(0.3) BLX(0.5) > CIXL2
BLX(0.5) SBX(5) BLX(0.3) U N DX SBX(2) Ext.F. Logical > CIXL2

Table 14: Results multiple comparison tests fSph , fSchDS fRos functions
ranking established test regarding crossover operator.

34

fiCIXL2: Crossover Operator Evolutionary Algorithms



Crossover
J

CIXL2

BLX(0.3)

BLX(0.5)

SBX(2)

SBX(5)

Fuzzy

Logical

UNDX

Function
fRas
fSch
fAck

BLX(0.3)
BLX(0.5)
SBX(2)
SBX(5)
Fuzzy
Logical
UNDX
CIXL2
BLX(0.5)
SBX(2)
SBX(5)
Fuzzy
Logical
UNDX
CIXL2
BLX(0.3)
SBX(2)
SBX(5)
Fuzzy
Logical
UNDX
CIXL2
BLX(0.3)
BLX(0.5)
SBX(5)
Fuzzy
Logical
UNDX
CIXL2
BLX(0.3)
BLX(0.5)
SBX(2)
Fuzzy
Logical
UNDX
CIXL2
BLX(0.3)
BLX(0.5)
SBX(2)
SBX(5)
Logical
UNDX
CIXL2
BLX(0.3)
BLX(0.5)
SBX(2)
SBX(5)
Fuzzy
UNDX
CIXL2
BLX(0.3)
BLX(0.5)
SBX(2)
SBX(5)
Fuzzy
Logical

fRas
J
7.296e-01
-9.950e-02
-1.552e+01
-1.128e+01
-1.953e+01
-6.033e+01
-1.078e+02
-7.296e-01
-8.291e-01
-1.625e+01
-1.201e+01
-2.026e+01
-6.106e+01
-1.085e+02
9.950e-02
8.291e-01
-1.542e+01
-1.118e+01
-1.943e+01
-6.023e+01
-1.077e+02
1.552e+01
1.625e+01
1.542e+01
4.245e+00
-4.013e+00
-4.481e+01
-9.227e+01
1.128e+01
1.201e+01
1.118e+01
-4.245e+00
-8.258e+00
-4.905e+01
-9.651e+01
1.953e+01
2.026e+01
1.943e+01
4.013e+00
8.258e+00
-4.079e+01
-8.826e+01
6.033e+01
6.106e+01
6.023e+01
4.481e+01
4.905e+01
4.079e+01
-4.746e+01
1.078e+02
1.085e+02
1.077e+02
9.227e+01
9.651e+01
8.826e+01
4.746e+01

fSch
J





fAck
J



0.923
1.000
0.000
0.000
0.000
0.000
0.000
0.923
0.713
0.000
0.000
0.000
0.000
0.000
1.000
0.713
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.005
0.042
0.000
0.000
0.000
0.000
0.000
0.005
0.000
0.000
0.000
0.000
0.000
0.000
0.042
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000

2.715e+02
0.000
-2.830e-08
0.000
2.210e+02
0.010
-5.090e-08
0.000
-8.287e+02
0.000
-5.322e-06
0.000
-4.631e+02
0.000
-9.649e-06
0.000
-2.408e+03
0.000
-1.659e-07
0.000
-1.988e+03
0.000
-2.517e-06
0.000
-7.409e+03
0.000
-3.550e-02
0.000
-2.715e+02
0.000
2.830e-08
0.000
-5.050e+01
1.000
-2.261e-08
0.000
-1.100e+03
0.000
-5.293e-06
0.000
-7.346e+02
0.000
-9.620e-06
0.000
-2.680e+03
0.000
-1.376e-07
0.000
-2.260e+03
0.000
-2.488e-06
0.000
-7.680e+03
0.000
-3.550e-02
0.000
-2.210e+02
0.010
5.090e-08
0.000
5.050e+01
1.000
2.261e-08
0.000
-1.050e+03
0.000
-5.271e-06
0.000
-6.841e+02
0.000
-9.598e-06
0.000
-2.629e+03
0.000
-1.150e-07
0.000
-2.209e+03
0.000
-2.466e-06
0.000
-7.630e+03
0.000
-3.550e-02
0.000
8.287e+02
0.000
5.322e-06
0.000
1.100e+03
0.000
5.293e-06
0.000
1.050e+03
0.000
5.271e-06
0.000
3.655e+02
0.006
-4.327e-06
0.000
-1.579e+03
0.000
5.156e-06
0.000
-1.159e+03
0.000
2.805e-06
0.000
-6.580e+03
0.000
-3.550e-02
0.000
4.631e+02
0.000
9.649e-06
0.000
7.346e+02
0.000
9.620e-06
0.000
6.841e+02
0.000
9.598e-06
0.000
-3.655e+02
0.006
4.327e-06
0.000
-1.945e+03
0.000
9.483e-06
0.000
-1.525e+03
0.000
7.132e-06
0.000
-6.946e+03
0.000
-3.550e-02
0.000
2.408e+03
0.000
1.659e-07
0.000
2.680e+03
0.000
1.376e-07
0.000
2.629e+03
0.000
1.150e-07
0.000
1.579e+03
0.000
-5.156e-06
0.000
1.945e+03
0.000
-9.483e-06
0.000
4.199e+02
0.000
-2.351e-06
0.000
-5.001e+03
0.000
-3.550e-02
0.000
1.988e+03
0.000
2.517e-06
0.000
2.260e+03
0.000
2.488e-06
0.000
2.209e+03
0.000
2.466e-06
0.000
1.159e+03
0.000
-2.805e-06
0.000
1.525e+03
0.000
-7.132e-06
0.000
-4.199e+02
0.000
2.351e-06
0.000
-5.421e+03
0.000
-3.550e-02
0.000
7.409e+03
0.000
3.550e-02
0.000
7.680e+03
0.000
3.550e-02
0.000
7.630e+03
0.000
3.550e-02
0.000
6.580e+03
0.000
3.550e-02
0.000
6.946e+03
0.000
3.550e-02
0.000
5.001e+03
0.000
3.550e-02
0.000
5.421e+03
0.000
3.550e-02
0.000
Ranking
U N DX > Logical > Ext.F. > SBX(2) > SBX(5) > BLX(0.5) CIXL2 BLX(0.3)
U N DX > Ext.F. > Logical > SBX(2) > SBX(5) > CIXL2 > BLX(0.5) BLX(0.3)
U N DX > SBX(5) > SBX(2) > Logical > Ext.F. > BLX(0.5) > BLX(0.3) > CIXL2

Table 15: Results multiple comparison tests fRas , fSch fAck functions
ranking established test regarding crossover operator.

35

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas



Crossover
J

CIXL2

BLX(0.3)

BLX(0.5)

SBX(2)

SBX(5)

Fuzzy

Logical

UNDX

Function
fGri
fF le
fLan

BLX(0.3)
BLX(0.5)
SBX(2)
SBX(5)
Fuzzy
Logical
UNDX
CIXL2
BLX(0.5)
SBX(2)
SBX(5)
Fuzzy
Logical
UNDX
CIXL2
BLX(0.3)
SBX(2)
SBX(5)
Fuzzy
Logical
UNDX
CIXL2
BLX(0.3)
BLX(0.5)
SBX(5)
Fuzzy
Logical
UNDX
CIXL2
BLX(0.3)
BLX(0.5)
SBX(2)
Fuzzy
Logical
UNDX
CIXL2
BLX(0.3)
BLX(0.5)
SBX(2)
SBX(5)
Logical
UNDX
CIXL2
BLX(0.3)
BLX(0.5)
SBX(2)
SBX(5)
Fuzzy
UNDX
CIXL2
BLX(0.3)
BLX(0.5)
SBX(2)
SBX(5)
Fuzzy
Logical

fGri
J
-3.224e-02
-2.235e-02
-6.710e-03
-1.603e-02
1.394e-02
9.173e-03
-6.312e-02
3.224e-02
9.893e-03
2.553e-02
1.621e-02
4.618e-02
4.142e-02
-3.088e-02
2.235e-02
-9.893e-03
1.564e-02
6.320e-03
3.629e-02
3.152e-02
-4.077e-02
6.710e-03
-2.553e-02
-1.564e-02
-9.320e-03
2.065e-02
1.588e-02
-5.641e-02
1.603e-02
-1.621e-02
-6.320e-03
9.320e-03
2.997e-02
2.520e-02
-4.709e-02
-1.394e-02
-4.618e-02
-3.629e-02
-2.065e-02
-2.997e-02
-4.763e-03
-7.706e-02
-9.173e-03
-4.142e-02
-3.152e-02
-1.588e-02
-2.520e-02
4.763e-03
-7.229e-02
6.312e-02
3.088e-02
4.077e-02
5.641e-02
4.709e-02
7.706e-02
7.229e-02

fFle
J





fLan
J



0.021
0.012
0.973
0.167
0.000
0.057
0.000
0.021
1.000
0.188
0.952
0.000
0.001
0.252
0.012
1.000
0.361
1.000
0.000
0.000
0.003
0.973
0.188
0.361
0.980
0.000
0.003
0.000
0.167
0.952
1.000
0.980
0.000
0.001
0.000
0.000
0.000
0.000
0.000
0.000
0.025
0.000
0.057
0.001
0.000
0.003
0.001
0.025
0.000
0.000
0.252
0.003
0.000
0.000
0.000
0.000

-4.779e+02
1.000
9.384e-02
0.091
-2.789e+03
1.000
1.392e-01
0.007
-1.740e+04
0.034
-1.253e-02
1.000
-1.810e+04
0.022
-1.982e-02
1.000
-1.686e+03
1.000
-1.000e-01
0.000
-1.196e+04
0.709
-2.064e-01
0.000
-1.947e+04
0.009
6.557e-03
1.000
4.779e+02
1.000
-9.384e-02
0.091
-2.311e+03
1.000
4.540e-02
1.000
-1.693e+04
0.046
-1.064e-01
0.046
-1.763e+04
0.029
-1.137e-01
0.013
-1.208e+03
1.000
-1.938e-01
0.000
-1.148e+04
0.888
-3.003e-01
0.000
-1.899e+04
0.012
-8.728e-02
0.151
2.789e+03
1.000
-1.392e-01
0.007
2.311e+03
1.000
-4.540e-02
1.000
-1.461e+04
0.179
-1.518e-01
0.004
-1.531e+04
0.121
-1.591e-01
0.001
1.104e+03
1.000
-2.392e-01
0.000
-9.169e+03
1.000
-3.457e-01
0.000
-1.668e+04
0.054
-1.327e-01
0.012
1.740e+04
0.034
1.253e-02
1.000
1.693e+04
0.046
1.064e-01
0.046
1.461e+04
0.179
1.518e-01
0.004
-7.002e+02
1.000
-7.285e-03
1.000
1.572e+04
0.095
-8.747e-02
0.008
5.446e+03
1.000
-1.939e-01
0.000
-2.061e+03
1.000
1.909e-02
1.000
1.810e+04
0.022
1.982e-02
1.000
1.763e+04
0.029
1.137e-01
0.013
1.531e+04
0.121
1.591e-01
0.001
7.002e+02
1.000
7.285e-03
1.000
1.642e+04
0.063
-8.018e-02
0.004
6.146e+03
1.000
-1.866e-01
0.000
-1.361e+03
1.000
2.637e-02
1.000
1.686e+03
1.000
1.000e-01
0.000
1.208e+03
1.000
1.938e-01
0.000
-1.104e+03
1.000
2.392e-01
0.000
-1.572e+04
0.095
8.747e-02
0.008
-1.642e+04
0.063
8.018e-02
0.004
-1.027e+04
1.000
-1.064e-01
0.000
-1.778e+04
0.027
1.066e-01
0.000
1.196e+04
0.709
2.064e-01
0.000
1.148e+04
0.888
3.003e-01
0.000
9.169e+03
1.000
3.457e-01
0.000
-5.446e+03
1.000
1.939e-01
0.000
-6.146e+03
1.000
1.866e-01
0.000
1.027e+04
1.000
1.064e-01
0.000
-7.507e+03
1.000
2.130e-01
0.000
1.947e+04
0.009
-6.557e-03
1.000
1.899e+04
0.012
8.728e-02
0.151
1.668e+04
0.054
1.327e-01
0.012
2.061e+03
1.000
-1.909e-02
1.000
1.361e+03
1.000
-2.637e-02
1.000
1.778e+04
0.027
-1.066e-01
0.000
7.507e+03
1.000
-2.130e-01
0.000
Ranking
U N DX BLX(0.3) BLX(0.5) SBX(5) SBX(2) CIXL2 Logical > Ext.F.
U N DX SBX(5) SBX(2) Logical BLX(0.5) Ext.F. BLX(0.3) CIXL2
Logical > Ext.F. > SBX(5) SBX(2) CIXL2 U N DX BLX(0.3) BLX(0.5)

Table 16: Results multiple comparison tests fGri , fF le fLan functions
ranking established test regarding crossover operator.

36

fiCIXL2: Crossover Operator Evolutionary Algorithms



J

CIXL2

U DAc
EGN ABGe
CIXL2
EGN ABGe
CIXL2
U DAc

U DAc
EGN ABGe
Function
fSchDS
fRos
fRas
fSch
CIXL2
U DAc
EGN ABGe
Function
fAck
fGri
fF le
fLan

J

J

J
fSchDS
fRos
fRas
-2.221e+01 0.000 -2.928e+00 0.000 -1.547e+02
-2.076e-01 0.000 -2.906e+00 0.000 -1.533e+02
2.221e+01 0.000 2.928e+00 0.000 1.547e+02
2.200e+01 0.000 2.207e-02 0.856 1.360e+00
2.076e-01 0.000 2.906e+00 0.000 1.533e+02
-2.200e+01 0.000 -2.207e-02 0.856 -1.360e+00
Ranking
U DAc > EGN

BGe





J
fSch
-1.089e+04
-1.091e+04
1.089e+04
-2.390e+01
1.091e+04
2.390e+01

0.000
0.000
0.000
0.677
0.000
0.677

fLan
0.004
-3.306e-02
0.150
-3.306e-02
0.004
3.306e-02
0.049 1.33781e-11
0.150
3.306e-02
0.049 -1.33781e-11

0.176
0.176
0.176
0.325
0.176
0.325

0.000
0.000
0.000
0.888
0.000
0.888

> CIXL2

U DAc EGN
> CIXL2
BGe
U DAc EGN
> CIXL2
BGe

EGN

U DAc
EGN ABGe
CIXL2
EGN ABGe
CIXL2
U DAc

fAck
-1.101e-08
-9.194e-09
1.101e-08
1.817e-09
9.194e-09
-1.817e-09

0.000
0.000
0.000
0.175
0.000
0.175

BGe

fGri
1.525e-02
1.525e-02
-1.525e-02
1.266e-16
-1.525e-02
-1.266e-16

U DAc > CIXL2

fFle
0.000 9.803e+03
0.000 6.157e+03
0.000 -9.803e+03
0.000 -3.646e+03
0.000 -6.157e+03
0.000 3.646e+03
Ranking

U DAc EGN

BGe

> CIXL2

CIXL2 > U DAc > EGN

BGe

CIXL2 EGN
> U DAc
BGe
U DAc EGN
CIXL2
BGe

Table 17: Results functions multiple comparison test ranking
obtained depending evolutionary algorithm.

37

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

Appendix B. Convergence Graphics

Average fitness best individual 30 runs

100

CIXL2(0.70,5)
BLX(0.3)
SBX(2)
Fuzzy
Logical
UNDX

1
0.01
0.0001
1e-06
1e-08
1e-10
1e-12
1e-14
1e-16

0

50000

100000

150000

200000

250000

300000

Evaluations

Figure 5: Evolution average fitness, logarithmic scale, using different crossover
operators function fSph .

Average fitness best individual 30 runs

100000

CIXL2(0.70,5)
BLX(0.5)
SBX(2)
Fuzzy
Logical
UNDX

10000

1000

100

10

1

0.1

0.01

0.001

0

50000

100000

150000
Evaluations

200000

250000

300000

Figure 6: Evolution average fitness, logarithmic scale, using different crossover
operators function fSchDS .

38

fiCIXL2: Crossover Operator Evolutionary Algorithms

Average fitness best individual 30 runs

1000

CIXL2(0.70,5)
BLX(0.3)
SBX(2)
Fuzzy
Logical
UNDX

100

10

0

50000

100000

150000

200000

250000

300000

Evaluations

Figure 7: Evolution averaged fitness, logarithmic scale, using different crossover
operators function fRos .

Average fitness best individual 30 runs

1000

CIXL2(0.70,5)
BLX(0.3)
SBX(5)
Fuzzy
Logical
UNDX

100

10

1

0

50000

100000

150000
Evaluations

200000

250000

300000

Figure 8: Evolution average fitness, logarithmic scale, using different crossover
operators function fRas .

39

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

Average fitness best individual 30 runs

100000

CIXL2(0.70,5)
BLX(0.3)
SBX(5)
Fuzzy
Logical
UNDX

10000

1000

100

0

50000

100000

150000

200000

250000

300000

Evaluations

Figure 9: Evolution average fitness, logarithmic scale, using different crossover
operators function fSch .

Average fitness best individual 30 runs

100

CIXL2(0.70,5)
BLX(0.3)
SBX(2)
Fuzzy
Logical
UNDX

1

0.01

0.0001

1e-06

1e-08

0

50000

100000

150000
Evaluations

200000

250000

300000

Figure 10: Evolution average fitness, logarithmic scale, using different crossover
operators function fAck .

40

fiCIXL2: Crossover Operator Evolutionary Algorithms

Average fitness best individual 30 runs

100

CIXL2(0.70,5)
BLX(0.5)
SBX(2)
Fuzzy
Logical
UNDX

10

1

0.1

0.01

0.001

0

50000

100000

150000

200000

250000

300000

Evaluations

Figure 11: Evolution average fitness, logarithmic scale, using different crossover
operators function fGri .

Average fitness best individual 30 runs

1e+07

CIXL2(0.70,5)
BLX(0.3)
SBX(2)
Fuzzy
Logical
UNDX

1e+06

100000

10000

0

50000

100000

150000
Evaluations

200000

250000

300000

Figure 12: Evolution average, logarithmic scale, using different crossover operators
function fF le .

41

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

Average fitness best individual 30 runs

1

0.01

0.0001

1e-06

1e-08

1e-10
CIXL2(0.70,5)
BLX(0.3)
SBX(5)
Fuzzy
Logical
UNDX

1e-12

1e-14

0

50000

100000

150000
Evaluations

200000

250000

300000

Figure 13: Evolution average fitness, logarithmic scale, using different crossover
operators function fLan .

42

fiCIXL2: Crossover Operator Evolutionary Algorithms

References
Ackley, D. (1987). empirical study bit vector function optimizacion. Genetic Algorithms Simulated Annealing, 170215.
Andersen, H. C., & Tsoi, A. C. (1993). constructive algorithm training
multilayer pereptron based genetic algorithm. Complex Systems, 7 (4), 249
268.
Arabas, J., Michalewicz, Z., & Mulawka, J. (1994). Gavaps - genetic algorithm
varying population size. Michalewicz, Z., Krawczyk, J., Kazemi, M., & Janikow,
C. (Eds.), First IEEE International Conference Evolutionary Computation, Vol. 1,
pp. 7378, Orlando. IEEE Service Center, Piscataway, NJ.
Bebis, G., Georgiopoulos, M., & Kasparis, T. (1997). Coupling weight elimination genetic algorithms reduce network size preserve generalization. Neurocomputing,
17, 167194.
Bebis, G., Louis, S., Varol, Y., & Yfantis, A. (2002). Genetic object recognition using
combinations views. IEEE Transactions Evolutionary Computation, 6 (2), 132.
Bengoetxea, E., & Miquelez, T. (2002). Estimation distribution algorithms: new tool
evolutionary computation (D.E. Goldberg edition)., Vol. 2 Genetic algorithms
evolutionary computation, chap. Experimental result function optimization
EDAs continuous Domain. Kluwer.
Bersini, H., Dorigo, M., Langerman, S., Seront, G., & Gambardella, L. M. (1996). Results
first international contest evolutionary optimisation (1st iceo). Proceedings
IEEE International Conference Evolutionary Computation, IEEE-EC 96, pp.
611615, Nagoya, Japan. IEEE Press.
Beyer, H.-G., & Deb, K. (2001). self-adapting features real-parameter evolutionary
algorithms. IEEE Transactions evolutionary computation, 5 (3), 250270.
Breiman, L. (1996). Stacked regressions. Machine Learning, 24 (1), 4964.
Back, J. H. (1996). Evolutionary Algorithms Theory Practice. Oxford University
Press, Oxford.
Back, T., Fogel, D., & Michalewicz, Z. (1997). Handbook Evolutionary Computation.
Institute Physics Publishing Ltd, Bristol Oxford University Press, New York.
Back, T., & Schwefel, H. P. (1993). overview evolutionary algorithms parameter
optimization. Evolutionary Computation, 1 (1), 123.
Cano, J., Herrera, F., & Lozano, M. (2003). Using evolutionary algorithms instance
selection data reduction kdd: experimental study. IEEE Transactions
Evolutionary Computation, 7 (6), 561575.
Davidor, Y. (1991). Genetic Algorithms Robotics: Heuristic Strategy Optimization,
Vol. 1 Robotics Automated Systems. World Scientific.
De Jong, K. D. (1975). analysis behavior class genetic adaptive systems.
Ph.D. thesis, Departament Computer Communication Sciences, University
Michigan, Ann Arbor.
43

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

De Jong, M. B., & Kosters, W. (1998). Solving 3-sat using adaptive sampling. Poutre,
H., & van den Herik, J. (Eds.), Proceedings Tenth Dutch/Belgian Artificial
Intelligence Conference, pp. 221228.
Deb, K., & Agrawal, R. B. (1995). Simulated binary crossover continuous search space.
Complex Systems, 9, 115148.
Deb, K., & Beyer, H. (2001). Self-adaptive genetic algorithms simulated binary
crossover. Evolutionary Computation, 9 (2), 195219.
Dixon, L. C. W. (1974). Nonlinear optimization: survey state art. Software
Numerical Mathematics, 193216. Academic Press.
Dunn, O. J., & Clark, V. (1974). Applied Statistics: Analysis Variance Regression.
Wiley, New York.
Eiben, A., & Back, T. (1997a). Multi-parent recombination operators continuous search
spaces. Tech. rep. TR-97-01, Leiden University.
Eiben, A. E., & Back, T. (1997b). Empirical investigation multi-parent recombination
operators evolution strategies. Evolutionary Computation, 5 (3), 347365.
Eiben, A., van der Hauw, J., & van Hemert, J. (1998). Graph coloring adaptive
evolutionary algorithms. Journal Heuristics, 4 (1), 2546.
Eshelman, L. J., & Schaffer, J. D. (1993). Real-coded genetic algorithms intervalschemata. Whitley, L. D. (Ed.), Foundation Genetic Algorithms 2, pp.
187C3.3.7:1C3.3.7:8.202, San Mateo. Morgan Kaufmann.
Fletcher, R., & Powell, M. J. D. (1963). rapidly convergent descent method minimization. Computer Journal, pp. 163168.
Fogel, D. B. (1995). Evolutionary Computation: Toward New Philosophy Machine
Intelligence. IEEE Press, Piscataway, New Jork.
Fogel, L. J., Owens, A. J., & Walsh, M. J. (1966). Artificial Intelligence Simulated
Evolution. John Wiley & Sons.
Friedman, J. H. (1994). overview predictive learning function approximation.
Cherkassky, V., Friedman, J. H., & Wechsler, H. (Eds.), Statistics Neural
Networks, Theory Pattern Recognition Applications, Vol. 136 NATO ASI Series
F, pp. 161. Springer-Verlag.
Garca-Pedrajas, N., Hervas-Martnez, C., & Ortiz-Boyer, D. (2005). Cooperative coevolution artificial neural network ensembles pattern classification. IEEE Transactions Evolutionary Computation, 9 (3), 271302.
Goldberg, D. E. (1989a). Genetic Algorithms Search, Optimization, Machine Learning. Addison-Wesley, New York.
Goldberg, D. E. (1989b). Sizing populations serial parallel genetic algorithms.
Schaffer, J. (Ed.), 3rd International Conference Genetic Algorithms, pp. 7079,
San Mateo, CA. Morgan Kaufmann.
Goldberg, D. E. (1991). Real-coded genetic algorithms, virtual alphabets, blocking.
Complex Systems, pp. 139167.
44

fiCIXL2: Crossover Operator Evolutionary Algorithms

Goldberg, D. E., & Deb, K. (1991). comparative analysis selection schemes used
genetic algorithms. Rawlins, G. J. E. (Ed.), Foundations Genetic Algorithms,
pp. 6993, San Mateo, CA. Morgan Kaufmann.
Gordon, V. S., & Whitley, D. (1993). Serial parallel genetic algorithms function
optimizers. Forrest, S. (Ed.), Fifth International Conference Genetic Algorithms,
pp. 177183. Morgan Kaufmann.
Grefenstette, J. J. (1986). Optimization control parameters genetic algorithms. IEEE
Transactions Systems, Mans, Cybernetics, 16 (1), 122128.
Hadley, G. (1964). Nonlinear Dynamics Programming. Addison Wesley.
Hashem, S. (1997). Optimal linear combinations neural networks. Neural Networks,
10 (4), 599614.
Herrera, F., Herrera-Viedma, E., Lozano, E., & Verdegay, J. L. (1994). Fuzzy tools
improve genetic algorithms. Second European Congress Intelligent Techniques
Soft Computing, pp. 15321539.
Herrera, F., & Lozano, M. (2000). Gradual distributed real-coded genetic algorithms. IEEE
Transactions Evolutionary Computation, 4 (1), 4363.
Herrera, F., Lozano, M., & Sanchez, A. M. (2003). taxonomy crossover operator
real-coded genetic algorithms: experimental study. International Journal
Intelligent Systems, 18, 309338.
Herrera, F., Lozano, M., & Verdegay, J. L. (1998). Tackling real-coded genetic algorithms:
Operators tools behavioural analysis. Artificial Inteligence Review, pp. 265
319. Kluwer Academic Publisher. Printed Netherlands.
Hervas-Martnez, C., & Ortiz-Boyer, D. (2005). Analizing statistical features cixl2
crossover offspring. Soft Computing, 9 (4), 270279.
Holland, J. H. (1975). Adaptation natural artificial systems. University
Michigan Press, Ann Arbor, MI.
Johnson, T., & Husbands, P. (1990). System identification using genetic algorithms.
Parallel Problem Solving Nature, Vol. 496 Lecture Notes Computer Science,
pp. 8589, Berlin. Springer-Verlag.
Jong, K. A. D., & Sarma, J. (1993). Generation gaps revisited. Whitley, L. D. (Ed.),
Foundations Genetic Algorithms, Vol. 2, pp. 1928. Morgan Kaufmann, San Mateo.
Kendall, M., & Stuart, S. (1977). advanced theory statistics, Vol. 1. Charles GriOEn
& Company.
Kita, H. (2001). comparison study self-adaptation evolution strategies real-code
genetic algorithms. Evolutionary Computation, 9 (2), 223241.
Kita, H., Ono, I., & Kobayashi, S. (1998). Theoretical analysis unimodal normal distribution crossover real-coded genetic algorithms. IEEE International Conference
Evolutionary Computation ICEC98, pp. 529534, Anchorage, Alaska, USA.
Kivinen, J., & Warmuth, M. (1997). Exponential gradient descent versus gradient descent
linear predictors. Information Computation, 132 (1), 163.
45

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

Kuncheva, L. (1995). Editing k-nearest neighbors rule genetic algorithm.
Pattern Recognition Letter, 16, 809814.
Larranaga, P., Etxeberria, R., Lozano, J., & Pena, J. (2000). Optimization continuous
domains learning simulation gaussian networks. Wu, A. (Ed.), Proceeding
2000 Genetic Evolutionary Computation Conference Workshop Program,
pp. 201204.
Leblanc, M., & Tibshirani, R. (1993). Combining estimates regression classification.
Tech. rep., Department Statistics, University Toronto.
Levene, H. (1960). Contributions Probability Statistics, chap. Essays Honor
Harold Hotelling, pp. 278292. Stanford University Press.
Liu, Y., Yao, X., & Higuchi, T. (2000). Evolutionary ensembles negative correlation
learning. IEEE Transactions Evolutionary Computation, 4 (4), 380387.
Merz, C. J. (1999a). principal components approach combining regression estimates.
Machine Learning, 36 (1), 932.
Merz, C. J. (1999b). Using correspondence analysis combine classifiers. Machine Learning, 36 (1), 3358.
Michalewicz, Z. (1992). Genetic Algorithms + Data Structures = Evolution Programs.
Springer-Verlag, New York.
Miller, G. F., Todd, P. M., & Hedge, S. U. (1991). Designing neural networks. Neural
Networks, 4, 5360.
Miller, R. G. (1981). Simultaneous Statistical Inference (2 edition). Wiley, New York.
Miller, R. G. (1996). Beyond ANOVA, Basics Applied Statistics (2 edition). Chapman
& Hall, London.
Mizumoto, M. (1989). Pictorial representations fuzzy connectives. part i: Cases tnorms, t-conorms averaging operators. Fuzzy Sets Systems, 31, 217242.
Moriarty, D., Schultz, A., & Grefenstette, J. (1999). Evolutionary algorithms reinforcement learning. Journal Artificial Intelligence Reserarch, 11.
Muhlenbein, H., Mahnig, T., & Rodriguez, O. (1999). Schemata, distributions graphical
models evolutionary optimazation. Journal Heuristics, pp. 215247.
Muhlenbein, H., & Paa, G. (1998). recombination genes estimation
distributions i. binary parameters.. Eiben, A. E., Back, T., Schoenauer, M., &
Schwefel, H.-P. (Eds.), 5th Conference Parallel Problem Solving Nature,
pp. 178187. Springer.
Ono, I., Kita, H., & Kobayashi, S. (1999). robust real-coded genetic algorithm using
unimodal normal distribution crossover augmented uniform crossover: Effects
self-adaptation crossover probabilities. Banzhaf, W., Daida, J., Eiben, A. E.,
Garzon, M. H., Honavar, V., Jakiela, M., & Smith, R. E. (Eds.), Genetic Evolutionary Computation Conf. (GECCO99), pp. 496503, San Francisco, CA. Morgan
Kaufmann.
46

fiCIXL2: Crossover Operator Evolutionary Algorithms

Ono, I., & Kobayashi, S. (1997). real-coded genetic algorithm function optimization
using unimodal normal distribution crossover. 7th International Conference
Genetic Algorithms, pp. 246253, Michigan, USA. Michigan State University, Morgan
Kaufman.
Ono, I., Kobayashi, S., & Yoshida, K. (2000). Optimal lens design real-coded genetic
algorithms using undx. Computer methods applied mechanics engineering, pp.
483497.
Opitz, D. W., & Shavlik, J. W. (1996). Actively searching effective neural network
ensemble. Connection Science, 8 (3), 337353.
Oren, S. S. (1974). selection parameters self scaling variable metric algorithms.
Mathematical Programming, pp. 351367.
Ortiz-Boyer, D., Hervas-Martnez, C., & Munoz-Perez, J. (2003). Metaheuristics: Computer
Decision-Making, chap. Study genetic algorithms crossover based confidence
intervals alternative classic least squares estimation methods non-linear
models, pp. 127151. Kluwer Academic Publishers.
Perrone, M. P., & Cooper, L. N. (1993). networks disagree: Ensemble methods
hybrid neural networks. Mammone, R. J. (Ed.), Neural Networks Speech
Image Processing, pp. 126142. Chapman Hall.
Rastrigin, L. A. (1974). Extremal control systems. Theoretical Foundations Engineering Cybernetics Series. Moscow: Nauka, Russian.
Rechenberg, I. (1973). Evolutionsstrategie-Optimierum technischer Systeme nach Prinzipien der biologischen Evolution. Ph.D. thesis, Stuttgart-Bad Cannstatt: FrommannHolzboog.
Rosenbrock, H. H. (1960). automatic method finding greatest least value
function. Computer Journal, pp. 175184.
Rudolph, G. (1994). Convergence analysis canonical genetic algorithms. IEEE Transactions Neural Networks, special issue evolutionary computation, 5 (1), 96101.
Salomon, R. (1996). Reevaluating genetic algorithm performance coordinate rotation
benchmark functions. BioSystems, pp. 263278.
Satoh, H., Yamamura, M., & Kobayashi, S. (1996). Minimal generation gap model
gas considering exploration exploitation.. Proceeding IIZUKA:
Methodologies Conception, Design, Application Intelligent Sstems, pp.
494497.
Schaffer, J., Caruana, R., Eshelman, L., & Das, R. (1989). study control parameters affecting online performance genetic algorithms function optimization.
Schaffer, J. (Ed.), 3rd International Conference Genetic Algorithms, pp. 5160,
San Mateo, CA. Morgan Kaufmann.
Schlierkamp-Voosen, D. (1994). Strategy adaptation competition. Second European
Congress Intelligent Techniques Soft Computing, pp. 12701274.
47

fiOrtiz-Boyer, Hervas-Martnez, & Garca-Pedrajas

Schwefel, H. P. (1981). Numerical Optimization Computer Models. John Wiley & Sons.
English translation Numerische Optimierung von Computer-Modellen mittels der
Evolutionsstrategie, 1977.
Schwefel, H. P. (1995). Evolution Optimum Seeking. John Wiley & Sons.
Sedighi, K., Ashenayi, K., Manikas, T., Wainwright, R., & Tai, H. (2004). Autonomous
local path planning mobile robot using genetic algorithm. IEEE Congress
Evolutionary Computation.
Sharkey, A. J. C. (1996). combining artificial neural nets. Connection Science, 8,
299313.
Singh, M., Chatterjee, A., & Chaudhury, S. (1997). Matching structural shape descriptions
using genetic algorithms. Pattern Recognition, 30 (9), 14511462.
Smith, R. E. (1993). Adaptively resizing populations: algorithm analysis. Forrest,
S. (Ed.), 5th International Conference Genetic Algorithms, p. 653, San Mateo, CA.
Morgan Kaufmann.
Snedecor, G. W., & Cochran, W. G. (1980). Statistical Methods (7 edition). Iowa State
University Press, Ames, Iowa.
Spedicato, E. (1975). Computational experience quasi-newton algorithms minimization problems moderately large size. Tech. rep. CISE-N-175, Centro Informazioni
Studi Esperienze, Segrate (Milano), Italy.
Takahashi, O., Kita, H., & Kobayashi, S. (1999). distance dependent alternation model
real-coded genetic algorithms. IEEE International Conference Systems, Man,
Cybernetics, pp. 619624.
Tamhane, A. C., & Dunlop, D. D. (2000). Statistics Data Analysis. Prentice Hall.
Voigt, H. M., Muhlenbein, H., & Cvetkovic, D. (1995). Fuzzy recombination breeder
genetic algorithms. Eshelman, L. (Ed.), 6th International Conference Genetic
Algorithms, pp. 104111, San Mateo, CA. Morgan Kaufmann.
Webb, G. I. (2000). Multiboosting: technique combining boosting wagging.
Machine Learning, 40 (2), 159196.
Whitley, D., Mathias, K., Rana, S., & Dzubera, J. (1995). Building better test functions.
Eshelman, L. (Ed.), Sixth International Conference Genetic Algorithms, pp.
239246. Morgan Kaufmann.
Wolpert, D. H., & Macready, W. G. (1995). free-lunch theorems search. Tech. rep.
95-02-010, Santa Fe Institute.
Wright, A. (1991). Genetic algorithms real parameter optimization. Rawlin, G.
J. E. (Ed.), Foundations Genetic Algorithms 1, pp. 205218, San Mateo. Morgan
Kaufmann.
Zhang, B. T., & Kim, J. J. (2000). Comparison selection methods evolutionary
optimization. Evolutionary Optimization, 2 (1), 5570.
Zhou, Z.-H., Wu, J., & Tang, W. (2002). Ensembling neural networks: Many could better
all. Artificial Intelligence, 137 (12), 239253.

48

fifiJournal Artificial Intelligence Research 24 (2005) 623-639

Submitted 12/04; published 11/05

Hiding Satisfying Assignments: Two Better One
Dimitris Achlioptas

optas@microsoft.com

Microsoft Research
Redmond, Washington

Haixia Jia

hjia@cs.unm.edu

Computer Science Department
University New Mexico

Cristopher Moore

moore@cs.unm.edu

Computer Science Department
University New Mexico

Abstract
evaluation incomplete satisfiability solvers depends critically availability
hard satisfiable instances. plausible source instances consists random kSAT formulas whose clauses chosen uniformly among clauses satisfying
randomly chosen truth assignment A. Unfortunately, instances generated manner
tend relatively easy solved efficiently practical heuristics. Roughly
speaking, number different algorithms, acts stronger stronger attractor
formulas density increases. Motivated recent results geometry space
satisfying truth assignments random k-SAT NAE-k-SAT formulas, introduce
simple twist basic model, appears dramatically increase hardness.
Namely, addition forbidding clauses violated hidden assignment A, also
forbid clauses violated complement, satisfying.
appears symmetrization effects two attractors largely cancel
out, making much harder algorithms find truth assignment. give theoretical
experimental evidence supporting assertion.

1. Introduction
Recent years witnessed rapid development application search methods
constraint satisfaction Boolean satisfiability. important factor success
algorithms availability good sets benchmark problems evaluate fine-tune
them. two main sources problems: real world, random instance
generators. Real-world problems arguably best benchmarks, unfortunately
short supply. Moreover, using real-world problems carries risk tuning algorithms
toward specific application domains good benchmarks available.
sense, random instance generators good additional source, advantage
controllable characteristics, size expected hardness.
Hard random instances led development new stochastic search methods
WalkSAT (Selman, Kautz, & Cohen, 1996), breakout procedure (Morris, 1993),
Survey Propagation (Mezard & Zecchina, 2002), used detailed comparisons local search methods graph coloring related problems (Johnson, Aragon,
McGeoch, & Shevon, 1989). results various competitions CSP SAT algoc
2005
AI Access Foundation. rights reserved.

fiAchlioptas, Jia, & Moore

rithms show fairly direct correlation performance real-world benchmarks
hard random instances (Johnson & Trick, 1996; Du, Gu, & Pardalos, 1997; Johnson
et al., 1989). Nevertheless, key limitation current problem generators concerns use
evaluating incomplete satisfiability solvers based local search methods.
incomplete algorithm find solution, difficult determine
whether instance fact unsatisfiable, simply algorithm
failed find satisfying assignment. standard way dealing problem
use complete search method filter unsatisfiable cases. However, greatly
limits size difficulty problem instances considered. Ideally, one would
use problem generators generate satisfiable instances only. One relatively recent source
problems quasigroup completion problem (Shaw, Stergiou, & Walsh, 1998;
Achlioptas, Gomes, Kautz, & Selman, 2000; Kautz, Ruan, Achlioptas, Gomes, Selman, &
Stickel, 2001). However, generator random hard satisfiable instances 3-SAT, say,
remained elusive.
Perhaps natural candidate generating random hard satisfiable 3-SAT formulas following. Pick random truth assignment A, generate formula
n variables rn random clauses, rejecting clause violated A. particular,
might hope work close satisfiability threshold region r 4.25,
hardest random 3-SAT problems seem (Cheeseman, Kanefsky, & Taylor, 1991; Hogg,
Huberman, & Williams, 1996; Mitchell, Selman, & Levesque, 1992), would generate
hard satisfiable instances. Unfortunately, generator highly biased towards formulas
many assignments clustered around A. given local search methods
WalkSAT, resulting formulas turn much easier formulas comparable
size obtained filtering satisfiable instances 3-SAT generator. sophisticated
versions hidden assignment scheme (Asahiro, Iwama, & Miyano, 1996; Van Gelder,
1993) improve matters somewhat still lead easily solvable formulas.
paper introduce new generator random satisfiable problems. idea
simple: pick random 3-SAT formula hidden complementary pair
satisfying assignments, A, rejecting clauses violated either A.
call 2-hidden formulas. motivation comes recent work (Achlioptas &
Moore, 2002b, 2005) showed moving random k-SAT random NAE-kSAT (in every clause formula must least one true least one false
literal) tremendously reduces correlation solutions. is, whereas random
k-SAT, satisfying assignments tend form clumps, random NAE-k-SAT solutions
appear scattered throughout {0, 1} n rather uniform mist, even densities
extremely close threshold. intuitive explanation phenomenon since
complement every NAE-assignment also NAE-assignment, attractions
solution pairs largely cancel out. paper exploit phenomenon impose
similar symmetry hidden assignments A, attractions cancel
out, making hard wide variety algorithms feel either one.
particularly nice feature generator based extremely simple
probabilistic procedure, sharp contrast 3-SAT generators based on, say, cryptographic ideas (Massacci, 1999). particular, generator readily amenable
mathematical tools developed rigorous study random k-SAT
formulas. make two first steps direction. Section 2, via first mo624

fiHiding Satisfying Assignments: Two Better One

ment calculation study distribution number solutions function
distance hidden assignments. Section 3, use technique differential
equations analyze performance Unit Clause (UC) heuristic formulas.
Naturally, mathematical simplicity would worth much formulas produced
generator easily solvable. Section 4, compare experimentally hardness
2-hidden formulas 1-hidden 0-hidden formulas. is, compare
formulas random 3-SAT formulas one hidden assignment standard
random 3-SAT formulas hidden assignment. examine four leading algorithms:
two complete solvers, zChaff Satz, two incomplete ones, WalkSAT recently
introduced Survey Propagation (SP).
algorithms, find formulas much harder 1-hidden
formulas and, importantly, hard 0-hidden formulas, size
density.

2. picture space solutions
section compare 1-hidden 2-hidden formulas respect expected
number solutions given distance hidden assignment(s).
2.1 1-hidden formulas
Let X number satisfying truth assignments random k-SAT formula n
variables = rn clauses chosen uniformly independently among k-clauses
least one positive literal, i.e., 1-hidden formulas hide allones truth assignment. calculate expectation E[X], helpful parametrize truth assignments
according overlap hidden assignment, i.e., fraction variables
agree A, case fraction variables set one.
Then, linearity expectation gives (1), clause independence gives (2), selecting literals
clause uniformly independently gives (3), and, finally, writing z = n using
Stirlings approximation factorial gives (4) below:
X
E[X] =
Pr[A satisfying]
(1)
A{0,1}n
n
X

n
Pr[a truth assignment z ones satisfies random clause] (2)
z
z=0


k
n
X
1 X k
n
(3)
(1 z/n)j (z/n)kj
1 k
=
j
z
2 1
z=0
j=1

n
X
n
1 (z/n)k
=
1
z
2k 1
z=0


r n
1 k
1
(4)
= poly(n) max
1 k
2 1
[0,1] (1 )1
=

= poly(n) max [fk,r ()]n
[0,1]

625

fiAchlioptas, Jia, & Moore


1
fk,r () =
(1 )1



1 k
1 k
2 1

r

.

calculation see E[X] dominated contribution truth assignments maximize fk,r () (since raise fk,r nth power contributions
vanish). Now, note f product entropic factor 1/( (1 )1 )
symmetric around = 1/2, correlation factor strictly increasing .
result, always maximized > 1/2. means dominant contribution E[X] comes truth assignments agree hidden assignment
half variables. is, set solutions dominated truth assignments
feel hidden assignments. Moreover, r increases phenomenon becomes
acute (see Figure 1 below).
2.2 2-hidden formulas
let X number satisfying truth assignments random k-SAT formula
n variables = rn clauses chosen uniformly among k-clauses least
one positive least one negative literal, i.e., 2-hidden formulas hide
ones assignment complement. compute E[X] proceed above, except
(3) replaced


k1
n
X
X
k
1
n
(1 z/n)j (z/n)kj .
1 k
j
z
2 2
z=0

j=1

Carrying ensuing changes find
E[X] = poly(n) max [gk,r ()]n
[0,1]


1
gk,r () =
(1 )1



1 k (1 )k
1
2k 2

r

.

time, entropic factor correlation factor comprising g symmetric
functions , gk,r symmetric around = 1/2 (unlike f k,r ). Indeed, one prove
r extremely close random k-SAT threshold r k , function gk,r
global maximum = 1/2. words, r, dominant contribution
E[X] comes truth assignments distance n/2 hidden assignments, i.e.,
hidden assignments felt. precisely, exists sequence k 0
gk,r unique global maximum = 1/2,
r 2k ln 2

ln 2
1 k .
2

(5)

Contrast fact (implicit Kirousis, Kranakis, Krizanc, & Stamatiou, 1998)

ln 2 1
r 2k ln 2
,
(6)
2
2
626

fiHiding Satisfying Assignments: Two Better One

random k-SAT formula n variables = rn clauses unsatisfiable probability 1 o(1). Moreover, convergence sequence k 0 rapid, seen
concrete values table 1. Thus gap values r given equations (5)
(6) quickly converges 1/2, even threshold becomes exponentially large.
k
Eq. (5)
Eq. (6)

3
7/2
4.67

4
35/4
10.23

5
20.38
21.33

7
87.23
87.88

10
708.40
708.94

20
726816.15
726816.66

Table 1: convergence (in k) asymptotic gap 1/2 rapid
Figure 1 plot fk,r gk,r k = 5 r = 16, 18, 20, 22, 24 (from top
bottom). see case 1-hidden formulas, i.e., f k,r , maximum always
occurs right = 1/2. Moreover, observe r = 22, 24, i.e., cross
5-SAT threshold (which occurs r 21) dramatic shift location
maximum and, thus, extent bias. Specifically, since expected number
satisfying assignments roughly f k,r ()n , since fk,r () < 1 except 1,
high probability remaining satisfying assignments limit n
extremely close hidden assignment.
case 2-hidden formulas, hand, see r = 16, 18, 20
global maximum occurs = 1/2. r = 20, threshold, also
two local maxima near = 0, 1, since g k,r raised nth power,
exponentially suppressed. Naturally, r threshold, i.e., r = 22, 24, local
maxima become global, signifying indeed remaining truth assignments
extremely close one two hidden ones.
Intuitively, expect g flat = 1/2 random truth assignments
concentrated, 2-hidden formulas local search algorithms like WalkSAT essentially
perform random walk lucky enough get close one two hidden
assignments. Thus expect WalkSAT take long 2-hidden formulas
0-hidden ones. 1-hidden formulas, contrast, expect nonzero gradient f
= 1/2 provide strong hint WalkSAT move towards hidden
assignment, therefore 1-hidden formulas much easier solve.
see experimental results bear intuitions perfectly.

3. Unit Clause heuristic DPLL algorithms
Consider following linear-time heuristic, called Unit Clause (UC), permanently
sets one variable step follows: pick random literal satisfy it, repeatedly
satisfy 1-clauses present. Chao Franco showed UC succeeds constant
probability random 3-SAT formulas r < 8/3, fails high probability, i.e.,
probability 1 o(1) n , r > 8/3 (Chao & Franco, 1986). One think
UC first branch simplest possible DPLL algorithm S: set variables random
order, time choosing randomly branch take first. result shows
that, constant probability, solves random 3-SAT formulas r < 8/3
backtracking all.
627

fiAchlioptas, Jia, & Moore

1.3
1.2
1.1
1
0.9
0.8
0.7
r=16
r=18
r=20
r=22
r=24

0.6
0.5
0.4
0

0.2

0.4



0.6

0.8

1

1-hidden formulas
1.25

r=16
r=18
r=20
r=22
r=24

1.2
1.15
1.1
1.05
1
0.95
0.9
0

0.2

0.4



0.6

0.8

1

2-hidden formulas
Figure 1: nth root expected number solutions f k,r gk,r 1-hidden
2-hidden formulas respectively, function overlap fraction = z/n
hidden assignment. k = 5 r = 16, 18, 20, 22, 24 top bottom.

628

fiHiding Satisfying Assignments: Two Better One

conjectured running time goes linear exponential r = 8/3,
intermediate regime. Calculations using techniques statistical physics (Cocco
& Monasson, 2001a, 2001b; Monasson, 2005) show true expected running
time. Achlioptas, Beame Molloy show running time exponential high
probability r > 3.81; moreover, show tricritical point (2 + p)-SAT
r = 2/5, case r > 8/3 (Achlioptas, Beame, & Molloy, 2001).
section analyze performance UC 1-hidden 2-hidden formulas.
Specifically, show UC fails 2-hidden formulas precisely density
0-hidden ones. Based this, conjecture running time S, simple
DPLL algorithms, becomes exponential 2-hidden formulas density
0-hidden ones.
analyze UC random 1-hidden 2-hidden formulas actually analyze UC
arbitrary initial distributions 3-clauses, i.e., 0 j 3 specify initial
number 3-clauses j positive literals 3 j negative ones. use method
differential equations; see article Achlioptas(2001) review. simplify notation,
assume allones assignment, 1-hidden formulas forbid clauses
literals negative, 2-hidden formulas forbid all-negative all-positive clauses.
round UC consists free step, satisfy random literal,
ensuing chain forced steps unit-clause propagations. 0 3 0 j i,
let Si,j = si,j n number clauses length j positive literals
P j negative
ones. also refer total density clauses size = j si,j . Let X = xn
number variables set far. goal write expected change
variables given round function values beginning round. Note
beginning round 1,0 = S1,1 = 0 definition, state space
analysis consist variables i,j 2.
convenient define two new quantities, mF , expected
number variables set True False round. calculate below. Then,
terms mT , mF ,
3s3,j
1x
2s2,j
(j + 1)s3,j+1
(3 j)s3,j
E[S2,j ] = (mT + mF )
+ mF
+ mT
1x
1x
1x
E[X] = (mT + mF ) .

E[S3,j ] = (mT + mF )

(7)
(8)

see this, note variable appears positively clause type i, j probability
j/(n X), negatively probability (i j)/(n X). Thus, negative terms (7)
(8) correspond clauses hit variables set, positive term
flow 3-clauses 2-clauses.
calculate mT mF , consider process unit clauses created
round. model two-type branching process, analyze
article Achlioptas Moore(2002a). Since free step gives chosen
variable random value, think creating unit clause, positive
negative equal probability. Thus initial expected population unit clauses
629

fiAchlioptas, Jia, & Moore

represented vector
p0 =



1/2
1/2



first second components count negative positive unit clauses respectively. Moreover, time X = xn, unit clause procreates according matrix


1
s2,1 2s2,0
.
M=
1 x 2s2,2 s2,1
words, satisfying negative unit clause creates, expectation, 1,1 = s2,1 /(1 x)
negative unit clauses M2,1 = 2s2,2 /(1 x) positive unit clauses, similarly
satisfying positive unit clause.
Thus, long largest eigenvalue 1 less 1, expected number
variables set true false round given


mF
= (I + + 2 + ) p0 = (I )1 p0
mT
identity matrix. Moreover, long 1 < 1 throughout algorithm, i.e.,
long branching process subcritical x, UC succeeds constant probability.
hand, 1 ever exceeds 1, branching process becomes supercritical,
high probability unit clauses proliferate, algorithm fails. Note

s2,1 + 2 s2,0 s2,2
.
(9)
1 =
1x
let us rescale (7) give system differential equations i,j . Wormalds
Theorem (Wormald, 1995) implies high probability random variables i,j (xn)
within o(n) si,j (x) n x, si,j (x) solution following:
ds3,j
dx
ds2,j
dx

3s3,j
1x
2s2,j
(j + 1)s3,j+1
(3 j)s3,j
mF
mT
=
+
+
1 x mT + F
1x
mT + F
1x
=

(10)

Now, suppose initial distribution 3-clauses symmetric, i.e., 3,0 (0) = s3,3 (0)
s3,1 (0) = s3,2 (0). easy see (10) case, 3-clauses
2-clauses symmetric times, i.e., i,j = si,ij mF = mT . case

s2,1 + 2 s2,0 s2,2 = s2 , criterion subcriticality becomes
1 =

s2
<1 .
1x

Moreover, since system (10) symmetric respect j, summing j gives
differential equations
ds3
dx
ds2
dx

3s3
1x
2s2
3s3
=
+
1 x 2(1 x)
=

630

fiHiding Satisfying Assignments: Two Better One

precisely differential equations UC 0-hidden formulas, i.e., random
instances 3-SAT.
Since 2-hidden formulas correspond symmetric initial conditions, thus shown
UC succeeds constant probability r < 8/3, i.e., UC fails
formulas exactly density fails random 3-SAT instances.
(In contrast, integrating (10) initial conditions corresponding 1-hidden formulas
shows UC succeeds slightly higher density, r < 2.679.)
course, UC easily improved making free step intelligent:
instance, choosing variable according number occurrences formula,
using majority occurrences decide truth value. best known
heuristic type (Kaporis, Kirousis, & Lalas, 2003; Hajiaghayi & Sorkin, 2003) succeeds
constant probability r < 3.52. However, believe much progress
made analyzing performance algorithms pushed
2-hidden formulas. Specifically, nearly algorithms analyzed far property
given input symmetric initial distribution 3-clauses, e.g. random 3-SAT,
residual formulas consist symmetric mixes 2- 3-clauses. result, conjecture
methods used show algorithms act 2-hidden formulas
exactly 0-hidden ones, failing high probability density.
generally, call DPLL algorithm myopic splitting rule consists choosing
random clause given size, based current distribution clause sizes, deciding
satisfy based number occurrences variables clauses.
given myopic algorithm A, let r density succeeds without
backtracking constant probability. results Achlioptas, Beame Molloy (2001)
imply following statement: tricritical point random (2 + p)-SAT p c = 2/5
every myopic algorithm takes exponential time r > r . Thus, UC,
fact large class natural DPLL algorithms, would go linear time r < r
exponential time r > rA . fact linear-time heuristics corresponding
first branch act 2-hidden formulas 0-hidden ones suggests that,
wide variety DPLL algorithms, 2-hidden formulas become exponentially hard
density 0-hidden ones. Proving this, indeed proving 2-hidden formulas take
exponential time r critical density, appears us promising direction
future work.

4. Experimental results
section report experimental results 2-hidden formulas, compare
1-hidden 0-hidden ones. use two leading complete solvers, zChaff Satz,
two leading incomplete solvers, WalkSAT new Survey Propagation algorithm
SP. attempt avoid numerous spurious features present too-small random
instances, i.e., non-asymptotic behavior, restricted attention experiments
n 1000. meant zChaff Satz could examined densities significantly satisfiability threshold, neither algorithm could practically solve either
0-hidden 2-hidden formulas n 1000 variables close threshold. WalkSAT
SP, hand, easily run experiments hardest range (around
satisfiability threshold) n 10 4 .
631

fiAchlioptas, Jia, & Moore

4.1 zChaff Satz
order experiments n 1000 zChaff Satz, focused
regime r relatively large, 20 < r < 60. stated above, r near satisfiability
threshold, 0-hidden 2-hidden random formulas n 1000 variables seem completely
reach either algorithm. formulas overconstrained regime still
challenging, presence many forced steps allows solvers completely explore
space fairly quickly.
obtained zChaff Princeton web site (Moskewicz, Madigan, Zhao, Zhang,
& Malik, 2001). first part Figure 2 shows performance random formulas
three types (with n = 1000 20 r 40 n = 3000 40 n 60). see
number decisions three types problems decreases rapidly r increases,
consistent earlier findings complete solvers random 3-SAT formulas.
Figure 2 shows zChaff finds 2-hidden formulas almost difficult 0-hidden ones,
range r unsatisfiable overwhelming probability.
hand, 1-hidden formulas much easier, number branchings 2
5 orders magnitude smaller. appears zChaffs smarts allow quickly
zero single hidden assignment, attractions exerted complementary pair
assignments indeed cancel out, making 2-hidden formulas almost hard unsatisfiable
ones. is, algorithm eventually stumbles upon one two hidden assignments
search nearly exhaustive unsatisfiable random 3-SAT formulas
density.
obtained Satz SATLIB web site (Li & Anbulagan, 1997b). second
part Figure 2 shows experiments random formulas three types n = 3000.
seen, median number branches explored Satz three types
formulas within factor five, 0-hidden hardest 2-hidden
easiest (note factor five corresponds setting fewer 3 variables).
reason simple: Satz makes intelligent decisions variable
branch on, tries branches fixed order, attempting first set variable
false (Li & Anbulagan, 1997a). Therefore, single hidden assignment appear
uniformly random leaf Satzs search tree. 2-hidden case, since two hidden
assignments complementary, one appear random position one
symmetric position respect search tree. Naturally, trying branches
fixed order good idea goal prove formula unsatisfiable, e.g.
hardware verification. However, expect Satz modified to, say, use
majority heuristic choose variables first value, performance three types
problems would similar zChaffs.
4.2 SP
SP incomplete solver recently introduced Mezard Zecchina (2002) based
generalization belief propagation authors call survey propagation. inspired
physical notion replica symmetry breaking observation 3.9 < r < 4.25,
random 3-SAT formulas appear satisfiable, satisfying assignments appear
organized clumps.
632

fiHiding Satisfying Assignments: Two Better One

Median number decisions 25 trials

6

10

5

10

zChaff performance HIDDEN 1, 2 0 formulas
HIDDEN1
HIDDEN2
HIDDEN0

4

10

3

10

2

10

1

10
20

5

Median number branches 25 trials

10

25

30

35

40
r

45

50

55

60

Satz performance HIDDEN 1, 2 0 formulas
HIDDEN1
HIDDEN2
HIDDEN0

4

10

3

10

2

10

1

10
20

25

30

35

40
r

45

50

55

60

Figure 2: median number branchings made zChaff Satz random instances
0, 1, 2 hidden assignments (on log 10 scale). zChaff use
n = 1000 r = 20, 30, 40 n = 3000 r = 40, 50, 60, Satz
use n = 3000 throughout. point median 25 trials. 2-hidden
formulas almost hard algorithms 0-hidden ones,
1-hidden formulas much easier zChaff.

633

fiAchlioptas, Jia, & Moore

1

SP performance HIDDEN 1, 2 0 formulas

fraction solved 30 trials

0.9
0.8
0.7
0.6
0.5
HIDDEN0
HIDDEN1
HIDDEN2

0.4
0.3
0.2
0.1
0
4

4.5

5
r

5.5

6

Figure 3: fraction problems successfully solved SP function density,
n = 104 30 trials value r. threshold solving 2-hidden
formulas somewhat higher 0-hidden ones, 1-hidden formulas
higher still.

Figure 3 compare SPs performance three types problems near
satisfiability threshold. (Because SP takes roughly time inputs,
compare running times.) n = 10 4 SP solves 2-hidden formulas densities
somewhat threshold, r 4.8, solves 1-hidden formulas still
higher densities, r 5.6.
Presumably 1-hidden formulas easier SP since messages clauses
variables, like majority heuristic, tend push algorithm towards hidden
assignment. two hidden assignments appears cancel messages
extent, causing SP fail lower density. However, argument explain
SP succeed densities satisfiability threshold; explain
SP solve 1-hidden formulas arbitrarily large r. Indeed, find latter
result surprising, since r increases majority clauses point
consistently towards hidden assignment 1-hidden case.
note also performed experiments n = 2 10 4
5000 iterations, instead default 1000, SPs convergence procedure. thresholds
Figure 3 1-hidden 2-hidden formulas appeared stable
changes, suggesting merely artifacts particular experiments.
propose investigating thresholds direction work.
4.3 WalkSAT
conclude local search algorithm, WalkSAT. Unlike complete solvers, WalkSAT
solve problems n = 104 fairly close threshold. performed experiments
random initial state, biased initial state algorithm starts
75% agreement one hidden assignments (note exponentially
634

fiHiding Satisfying Assignments: Two Better One

unlikely). cases, performed trials 10 8 flips formula, without random
restarts, step random greedy flip equal probability. Since random
initial states almost certainly roughly 50% agreement hidden assignments,
expect attractions cancel WalkSAT difficulty finding either
them. hand, begin biased initial state, attraction
nearby assignment much stronger one; situation similar
1-hidden formula, expect WalkSAT find easily. Indeed data confirms
expectations.
first part Figure 4 measure WalkSATs performance three types
problems n = 104 r ranging 3.7 7.9, compare 0-hidden
formulas r ranging 3.7 4.1, threshold become
unsatisfiable. see that, threshold, 2-hidden formulas hard
0-hidden ones WalkSAT sets initial state randomly; indeed, running times
coincide within resolution figure! become hardest r 4.2,
108 flips longer suffice solve them. Unsurprisingly, 2-hidden formulas much
easier solve start biased initial state, case running time
closer 1-hidden formulas.
second part Figure 4, compare three types formulas density
close threshold, r = 4.25, measure running times function
n. data suggests 2-hidden formulas random initial states much harder
1-hidden ones, 2-hidden formulas biased initial states running times
within constant 1-hidden formulas. Note median running time
three types problems polynomial n, consistent earlier experiments (Barthel,
Hartmann, Leone, Ricci-Tersenghi, Weigt, & Zecchina, 2002).
hand, 1-hidden formulas much easier 2-hidden ones
sufficiently large small r, appear slightly harder 2-hidden ones 5.3 <
r < 6.3. One possible explanation i) solutions 2-hidden
formula harder find due balanced distribution, ii) exponentially
solutions 2-hidden formulas 1-hidden ones size density.
seems range r, second effect overwhelms first, WalkSAT finds
solution quickly 2-hidden case; explanation
particular range r. higher densities, r = 8 shown Figure 5, 2-hidden
formulas appear harder 1-hidden ones.

5. Conclusions
introduced extremely simple new generator random satisfiable 3-SAT instances amenable mathematical tools developed rigorous study
random 3-SAT instances. Experimentally, generator appears produce instances
hard random 3-SAT instances, sharp contrast instances single hidden
assignment. hardness appears quite robust; experiments demonstrated
satisfiability threshold, algorithms use different
strategies, i.e., DPLL solvers (zChaff Satz), local search algorithms (WalkSAT),
survey propagation (SP).
635

fiAchlioptas, Jia, & Moore

7

Median number flips 100 trials

10

WalkSAT performance HIDDEN 1, 2 0 formulas
HIDDEN0
HIDDEN1
HIDDEN2 init 75% true
HIDDEN2

6

10

5

10

4

10

3

10

3

Median number flips 100 trials

10 7
10

6

10

5

10

4

5

r

6

7

8

WalkSAT performance function n
slope 2.8

HIDDEN0
HIDDEN2
HIDDEN1
HIDDEN2 init 75% true

slope 2.7
slope 1.3

4

10

3

10

2

slope 1.3

1

10
100

200

400
n

800

1600

Figure 4: top part figure shows median number flips needed WalkSAT
formulas three types threshold, n = 10 4 .
threshold, 2-hidden formulas hard 0-hidden ones (they
coincide within resolution figure) running time increases
steeply approach threshold. Except range 5.3 < r < 6.3, 2hidden formulas much harder 1-hidden ones unless algorithm starts
(exponentially lucky) biased initial state. bottom part figure
shows median number flips needed WalkSAT solve three types
formulas r = 4.25 function n. n ranges 100 2000.
median running time three polynomial, 2-hidden problems
much harder 1-hidden ones unless start biased initial state.
Again, running time 2-hidden problems scales similarly 0-hidden ones,
i.e., random 3-SAT without hidden assignment.

636

fiHiding Satisfying Assignments: Two Better One

WalkSAT performance HIDDEN 1 2 formulas r=8

6

Median number flips 100 trials

10

HIDDEN1
HIDDEN2

5

10

4

10

3

10

2

10

1

10 2
10

3

10

4

N

10

Figure 5: median number flips needed WalkSAT solve two types formulas
r = 8, range 1-hidden formulas harder. densities,
2-hidden formulas harder 1-hidden ones, although much
easier densities closer threshold.

believe random 2-hidden instances could make excellent satisfiable benchmarks,
especially around satisfiability threshold, say r = 4.25 appear
hardest WalkSAT (although beating SP requires somewhat higher densities).
Several aspects experiments suggest exciting directions work, including:
1. Proving expected running time natural Davis-Putnam algorithms 2hidden formulas exponential n r critical density.
2. Explaining different threshold behaviors SP 1-hidden 2-hidden formulas.
3. Understanding long WalkSAT takes midpoint two hidden assignments, becomes sufficiently unbalanced converge one them.
4. Studying random 2-hidden formulas dense case number clauses
grows linearly n.

References
Achlioptas, D. (2001). Lower bounds random 3-SAT via differential equations. Theor.
Comp. Sci., 265, 159185.
Achlioptas, D., Beame, P., & Molloy, M. (2001). sharp threshold proof complexity.
Proc. STOC, pp. 337346.
Achlioptas, D., Gomes, C., Kautz, H., & Selman, B. (2000). Generating satisfiable problem
instances. Proc. AAAI, pp. 256261.
637

fiAchlioptas, Jia, & Moore

Achlioptas, D., & Moore, C. (2002a). Almost graphs average degree 4 3colorable. Proc. STOC, pp. 199208.
Achlioptas, D., & Moore, C. (2002b). asymptotic order random k-SAT threshold.
Proc. FOCS, pp. 779788.
Achlioptas, D., & Moore, C. (2005). Two moments suffice cross sharp threshold.
SIAM J. Comput. appear.
Asahiro, Y., Iwama, K., & Miyano, E. (1996). Random generation test instances
controlled attributes. DIMACS Series Disc. Math. Theor. Comp. Sci., 26,
377393.
Barthel, W., Hartmann, A., Leone, M., Ricci-Tersenghi, F., Weigt, M., & Zecchina, R.
(2002). Hiding solutions random satisfiability problems: statistical mechanics
approach. Phys. Rev. Lett., 88 (188701).
Chao, M., & Franco, J. (1986). Probabilistic analysis two heuristics 3-satisfiability
problem. SIAM J. Comput., 15 (4), 11061118.
Cheeseman, P., Kanefsky, R., & Taylor, W. (1991). really hard problems are.
Proc. IJCAI, pp. 163169.
Cocco, S., & Monasson, R. (2001a). Statistical physics analysis computational complexity solving random satisfiability problems using backtrack algorithms. Eur.
Phys. J. B, 22, 505531.
Cocco, S., & Monasson, R. (2001b). Trajectories phase diagrams, growth processes
computational complexity: search algorithms solve 3-satisfiability problem.
Phys. Rev. Lett, 86, 16541657.
Du, D., Gu, J., & Pardalos, P. (1997). Dimacs workshop satisfiability problem, 1996.
DIMACS Discrete Math. Theor. Comp. Sci., Vol. 35. AMS.
Hajiaghayi, M., & Sorkin, G. (2003). satisfiability threshold random 3-SAT
least 3.52..
Hogg, T., Huberman, B., & Williams, C. (1996). Phase transitions complexity. Artificial
Intelligence, 81. Special issue.
Johnson, D., & Trick, M. (1996). Second dimacs implementation challenge, 1993. DIMACS Series Disc. Math. Theor. Comp. Sci., Vol. 26. AMS.
Johnson, D., Aragon, C., McGeoch, L., & Shevon, C. (1989). Optimization simulated
annealing: experimental evaluation. Operations Research, 37 (6), 865892.
Kaporis, A., Kirousis, L., & Lalas, E. (2003). Selecting complementary pairs literals.
Proc. LICS Workshop Typical Case Complexity Phase Transitions.
Kautz, H., Ruan, Y., Achlioptas, D., Gomes, C., Selman, B., & Stickel, . (2001). Balance
filtering structured satisfiable problems. Proc. IJCAI, pp. 351358.
Kirousis, L., Kranakis, E., Krizanc, D., & Stamatiou, Y. (1998). Approximating unsatisfiability threshold random formulas. Random Structures Algorithms, 12 (3),
253269.
638

fiHiding Satisfying Assignments: Two Better One

Li, C., & Anbulagan (1997a). Heuristics based unit propagation satisfiability problems. Proc. IJCAI, pp. 366371.
Li, C., & Anbulagan (1997b). Look-ahead versus look-back satisfiability problems.
Proc. 3rd Intl. Conf. Principles Practice Constraint Programming, pp. 341
355.
Massacci, F. (1999). Using walk-SAT rel-SAT cyptographic key search. Proc.
IJCAI, pp. 290295.
Mezard, M., & Zecchina, R. (2002).
Random k-satisfiability: analytic
solution new efficient algorithm.
Phys. Rev. E, 66.
Available at:
http://www.ictp.trieste.it/zecchina/SP/.
Mitchell, D., Selman, B., & Levesque, H. (1992). Hard easy distributions SAT
problems. Proc. AAAI, pp. 459465.
Monasson, R. (2005). Average case analysis DPLL random decision problems.
Proc. RANDOM.
Morris, P. (1993). breakout method escaping local minima. Proc. AAAI,
pp. 4045.
Moskewicz, M., Madigan, C., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: engineering
efficient SAT solver. Proc. 38th Design Automation Conference, pp. 530535.
Selman, B., Kautz, H., & Cohen, B. (1996). Local search strategies satisfiability testing.
Proc. 2nd DIMACS Challange Cliques, Coloring, Satisfiability.
Shaw, P., Stergiou, K., & Walsh, T. (1998). Arc consistency quasigroup completion.
Proc. ECAI, workshop binary constraints.
Van Gelder, A. (1993). Problem generator mkcnf.c. Proc. DIMACS. Challenge archive.
Wormald, N. (1995). Differential equations random processes random graphs. Ann.
Appl. Probab., 5 (4), 12171235.

639

fiJournal Artificial Intelligence Research 24 (2005) 919-931

Submitted 01/05; published 12/05

Engineering Note
Optiplan: Unifying IP-based Graph-based Planning
Menkes H.L. van den Briel

menkes@asu.edu

Department Industrial Engineering
Arizona State University, Tempe, AZ 85281 USA

Subbarao Kambhampati

rao@asu.edu

Department Computer Science Engineering
Arizona State University, Tempe, AZ 85281 USA

Abstract
Optiplan planning system first integer programming-based planner
successfully participated international planning competition. engineering note
describes architecture Optiplan provides integer programming formulation
enabled perform reasonably well competition. also touch upon
recent developments make integer programming encodings significantly competitive.

1. Introduction
Optiplan planning system uses integer linear programming (IP) solve STRIPS
planning problems. first system take part international planning
competition (IPC) judged second best performer four competition domains
optimal track propositional domains. Optiplans underlying integer programming
formulation extends state change model Vossen colleagues (1999). architecture similar Blackbox (Kautz & Selman, 1999) GP-CSP (Do &
Kambhampati, 2001), instead unifying satisfiability (SAT) constraint satisfaction
(CSP) graph based planning, Optiplan uses integer programming. Like Blackbox
GP-CSP, Optiplan works two phases. first phase planning graph built
transformed IP formulation, second phase IP formulation solved
using commercial solver ILOG CPLEX (ILOG Inc., 2002).
practical difference original state change model Optiplan
former takes input ground actions fluents initialized plan steps,
latter takes input actions fluents instantiated Graphplan
(Blum & Furst, 1995). well known use planning graphs significant
effect size final encoding matter combinatorial transformation method
(IP, SAT, CSP) used. instance, Kautz Selman (1999) well Kambhampati
(1997) pointed Blackboxs success Satplan (Kautz & Selman, 1992) mainly
explained Graphplans ability produce better, refined, propositional structures
Satplan. addition, Optiplan allows propositions deleted without required
preconditions. state changes modeled original state change model,
therefore Optiplan considered general encoding. One more, although
c
2005
AI Access Foundation. rights reserved.

fiVan den Briel, & Kambhampati

minor, implementation detail Optiplan state change model Optiplan
reads PDDL files.
engineering note organized follows. Section 2 provides brief background
integer programming Section 3 discusses previous IP approaches planning. Section
4 describes Optiplan planning system underlying IP formulation. Section 5
give experimental results look Optiplans performance international
planning competition 2004 (IPC4). Conclusions brief discussion recent
developments given Section 6.

2. Background
linear program represented linear objective function set inequalities,
min{cx : Ax b, x 0} x n-dimensional column vector variables,
n matrix, c n-dimensional row vector, b m-dimensional column vector.
variables constrained integers integer (linear) program,
variables restricted 0-1 values binary integer program.
widely used method solving general integer programs using branch
bound linear programming relaxation. Branch bound general search
method subproblems created restrict range integer variables,
linear programming relaxation linear program obtained original integer
program omitting integrality constraints. ideal formulation integer program
one solution linear programming relaxation integral. Even though
every integer program ideal formulation (Wolsey, 1998), practice hard
characterize ideal formulation may require exponential number inequalities.
problems ideal formulation cannot determined, often desirable find
strong formulation integer program. Suppose P1 = min{cx : A1 x b1 , x 0}
P2 = min{cx : A2 x b2 , x 0} linear programming relaxations two IP
formulations problem, say formulation P1 stronger formulation P2
P1 P2 . is, set solutions P1 subsumed set solutions P2 .

3. Integer Programming Approaches Planning
Despite vast amount research conducted field AI planning,
use linear programming (LP) integer linear programming explored
marginal level. quite surprising since (mixed) integer linear programming provide
feasible environments using numeric constraints arbitrary linear objective functions,
two important aspects real-world planning problems.
handful works explored use LP IP techniques AI planning.
Bylander (1997) developed IP formulation classical planning used LP relaxation heuristic partial order planning. results, however, seem scale
well compared planning graph satisfiability based planners.
difficulty developing strong IP formulations performance often depends way IP formulation constructed. Vossen et al. (1999) compared two
formulations classical planning. First, consider straightforward IP formulation
based converting propositional representation given Satplan (Kautz & Selman,
920

fiOptiplan: Unifying IP-based Graph-based Planning

1992) IP formulation variables take value 1 certain proposition
true, 0 otherwise. formulation, assertions expressed IP constraints
directly correspond logical conditions propositional representation. Second,
consider IP formulation original propositional variables replaced
state change variables. State change variables take value 1 certain proposition
added, deleted, persisted, 0 otherwise. Vossen et al. show formulation based
state change variables outperforms straightforward formulation based converting
propositional representation.
Dimopoulos (2001) improves IP formulation based state change variables identifying valid inequalities tighten formulation. Yet, even stronger IP formulations
given Bockmayr Dimopoulos (1998, 1999), IP formulations contain
domain dependent knowledge are, therefore, limited solving problems specific
problem domains only.
LP IP techniques also explored non-classical planning. Dimopoulos
Gerevini (2002) describe mixed integer programming formulation temporal planning Wolfman Weld (1999) use LP formulation combination SAT
formulation solve resource planning problems. Kautz Walser (1999) also use IP
formulations resource planning problems but, addition, incorporate action costs
complex objectives.
far, none IP approaches AI planning ever participated IPC, making
harder assess relative effectiveness line work. Optiplan, planner based
state change formulation, first IP-based planner so.

4. Optiplan
Optiplan planning graph based planner works follows. First build
planning graph level goal fluents appear non-mutex. compile
planning graph integer program solve it. plan found, planning
graph extended one level new graph compiled integer program
solved again. process repeated plan found.
remainder section give IP formulation used Optiplan.
order present IP formulation use following notation. F set fluents
set actions (operators). fluents true initial state
fluents must true goal given G respectively. Furthermore,
use sets:
pref A, f F, set actions fluent f precondition;
addf A, f F, set actions fluent f add effect;
delf A, f F, set actions fluent f delete effect;
Variables defined layer 1 planning graph.
variables actions variables possible state changes fluent
make, variables reachable relevant planning graph analysis
instantiated. A, 1, ..., action variables
921

fiVan den Briel, & Kambhampati

ya,t =



1 action executed period t,
0 otherwise.

no-op actions included ya,t variables represented separately
state change variable xmaintain
.
f,t
Optiplan based state change formulation (Vossen et al., 1999). formulation fluents represented explicitly, instead state change variables used model
transitions world state. is, fluent true added state
preadd
xadd
, persisted previous state xmaintain
. Optiplan extends
f,t xf,t
f,t
state change formulation (Vossen et al., 1999) introducing extra state change
variable, xdel
f,t , allows actions delete fluents without requiring preconditions.
original state change formulation allow actions, therefore added
new state change variables keep track state changes altered model
take new variables account. IPC4 domains Airport PSR
many actions delete fluents without requiring preconditions, therefore making
original state change formulation ineffective. Also, Optiplan instantiates
variables constraints reachable relevant planning graph analysis,
therefore creates smaller encoding original one. f F, 1, ...,
following state change variables:

1 fluent f propagated period t,
maintain
=
xf,t
0 otherwise.

1 action executed period pref
/ delf ,
preadd
xf,t
=
0 otherwise.

1 action executed period pref delf ,
predel
xf,t
=
0 otherwise.

1 action executed period
/ pref addf ,
=
xadd
f,t
0 otherwise.

1 action executed period tsuch
/ pref delf ,
xdel
=
f,t
0 otherwise.
summary: xmaintain
= 1 truth value fluent propagated; xpreadd
= 1
f,t
f,t
action executed requires fluent delete it; xpredel
= 1 action
f,t
add
executed requires fluent deletes it; xf,t = 1 action executed
require fluent adds it; xdel
f,t = 1 action executed require
fluent deletes it. complete IP formulation Optiplan given following
objective function constraints.

4.1 Objective
classical AI planning problems, minimization maximization required, instead
want find feasible solution. search solution, however, may guided
922

fiOptiplan: Unifying IP-based Graph-based Planning

objective function minimization number actions, currently
implemented Optiplan. objective function given by:
min

XX

ya,t

(1)

aA

Since constraints guarantee feasibility could used linear objective function. example, could easily set objective deal cost-sensitive plans
(in context non-uniform action cost), utility-sensitive plans (in context oversubscription goal utilities), metric transformed linear
expression. Indeed flexibility handle linear objective function one advantages IP formulations.

4.2 Constraints
requirements initial goal transition given by:
xadd
f,0 = 1
maintain preadd
xadd
, xf,0
f,0 , xf,0
maintain
xadd
+ xpreadd
f,T + xf,T
f,T

f

(2)

=0

f
/I

(3)

1

f G

(4)

constraints (2), (3) add initial fluents step 0 used
actions appear first layer (step 1) planning graph. Constraints
(4) represent goal state requirements, is, fluents appear goal must
added propagated step .
state change variables linked actions following effect implication
constraints. f F 1 have:
X
ya,t xadd
(5)
f,t
aaddf \pref

ya,t xadd
f,t
X

ya,t

addf \ pref

xdel
f,t

(6)
(7)

adelf \pref

ya,t xdel
f,t
X

delf \ pref

ya,t xpreadd
f,t

(8)
(9)

apref \delf

ya,t xpreadd
f,t
X

ya,t = xpredel
f,t

pref \ delf

(10)
(11)

apref delf

constraints (5) (11) represent logical relations action
state change variables. equality sign (11) actions f
923

fiVan den Briel, & Kambhampati

precondition delete effect mutually exclusive. also means
substitute xpredel
variables, done implementation
f,t
Optiplan. will, however, use variables clarity. Mutexes also appear
different state change variables expressed constraints follows:

predel
maintain
1
+ xdel
xadd
f,t + xf,t
f,t + xf,t

(12)

predel
xpreadd
+ xmaintain
+ xdel
1
f,t
f,t + xf,t
f,t

(13)

constraints (12) (13) restrict certain state changes occurring parallel.
del
example, xmaintain
(propagating fluent f step t) mutually exclusive xadd
f,t
f,t , xf,t ,
xpredel
(adding deleting f t).
f,t
Finally, backward chaining requirements binary constraints represented by:

add
maintain
xpreadd
+ xmaintain
+ xpredel
xpreadd
f,t
f,t
f,t
f,t1 + xf,t1 + xf,t1

f F, 1, ...,

(14)

del maintain
xpreadd
, xpredel
, xadd
{0, 1}
f,t , xf,t , xf,t
f,t
f,t

(15)

ya,t {0, 1}

(16)

constraints (14) describe backward chaining requirements, is, fluent
f added maintained step t1 state f changed action step
xpreadd
, xpredel
, propagated xmaintain
. Constraints (15)
f,t
f,t
f,t
(16) binary constraints state change action variables respectively.

Loc1

Truck1

Loc2

Truck2

Figure 1: simple logistics example

4.3 Example
example, show constraints initialized comment
interaction state change variables action variables.
Consider simple logistics example two locations, two trucks,
one package. package transported one location another one
trucks. built formulation three plan steps. initial state package
924

fiOptiplan: Unifying IP-based Graph-based Planning

trucks location 1 given Figure 1. initial state constraints are:
xadd
pack1

loc1,0

xadd
truck1

loc1,0
add
xtruck2 loc1,0
add maintain preadd
xf,0 , xf,0
, xf,0

=1
=1
=1
=0

f 6=

goal get package location 2 three plan steps, expressed
follows:
xadd
pack1

loc2,3

+ xmaintain
pack1

loc2,3

+ xpreadd
pack1

loc2,3

1

write effect implication constraints, comment
them. xadd
f,t = 1 certain fluent f , execute least one action
f add effect precondition. example:
yunload

truck1 loc2,t

+ yunload

truck2 loc2,t

xadd
pack1

loc2,t

preadd
state changes xdel
similar requirement, change
f,t xf,t
state del preadd must execute least one action corresponding effects. hand, execute action must change
fluent states according effects a. example:

yunload

truck1 loc2,t

xadd
pack1

yunload

truck1 loc2,t



yunload

truck1 loc2,t

=

loc2,t
preadd
xtruck loc2,t
xpredel
pack1 truck1,t

one-to-one correspondence (note equality sign) execution
actions xpredel
state change variables. because, actions
f,t
predel effect must mutex. Mutexes also present state changes. example,
fluent f maintained (propagated) cannot added deleted. two state
changes mutex add preadd. add state
change behaves like preadd state change corresponding fluent already present
state world. introduce two separate mutex constraints, one
includes add state change one includes preadd. example
constraints mutex state changes follows:
xadd
pack1

truck1,t

xpreadd
pack1

truck1,t

+ xmaintain
pack1

truck1,t

+ xdel
pack1

truck1,t

+ xpredel
pack1

truck1,t

1

+ xmaintain
pack1

truck1,t

+ xdel
pack1

truck1,t

+ xpredel
pack1

truck1,t

1

state fluent change another state correct state changes
occurred previously. Hence, fluent deleted, propagated, used preconditions
step added propagated step 1. example:
xpreadd
pack1

predel
maintain
truck1,t + xpack1 truck1,t + xpack1 truck1,t
add
maintain
xpreadd
pack1 truck1,t1 + xpack1 truck1,t1 + xpack1 truck1,t1

925



fiVan den Briel, & Kambhampati

t=0
xadd
pack1
xadd
truck1
xadd
truck2

loc1,0

t=1
yload truck1 loc1,1
xadd
pack1 truck1,1
xpredel
pack1 loc1,1
xpreadd
truck1 loc1,1

loc1,0

xmaintain
truck2

loc1,0

t=2
ydrive truck1 loc1 loc2,2
xmaintain
pack1 truck1,2
xadd
truck1
xpredel
truck1

loc2,2

t=3
yunload truck1 loc2,3
xadd
pack1 loc2,3
xpredel
pack1 truck1,3
xpreadd
truck1 loc2,3

loc1,2

loc1,1

Table 1: Solution simple logistics example. displayed variables value 1
variables value 0.

simple problem total 107 variables (41 action 66 state change)
91 constraints. However, planning graph analysis fixes 53 variables (28 action 25 state
change) zero. substituting values applying presolve techniques
built ILOG CPLEX solver, problem 13 variables 17 constraints.
solution example given Table 1. Note that, actions
actively delete f , nothing ensures xmaintain
true whenever f
f,t
true preceding state (for example, see fluent truck2 loc1). Since negative
preconditions allowed, option letting xmaintain
false
f,t
true cannot cause actions become executable be.
miss solutions constraints (4) ensure goal fluents satisfied,
therefore forcing xmaintain
true whenever helps us generate plan.
f,t

5. Experimental Results
First compare Optiplan original state change model, check
Optiplan performed IPC 2004.
Optiplan original state change formulation implemented two different
languages. Optiplan implemented C++ using Concert Technology, set
libraries allow embed ILOG CPLEX optimizers (ILOG Inc., 2002),
original state change model implemented AMPL (Fourer, Gay, & Kernighan, 1993),
modeling language mathematical programming. order compare
formulations produced two implementations, written output
file using MPS format. MPS standard data format often used transferring
linear integer linear programming problems different applications.
MPS file, contains IP formulation planning problem, written, read
solved ILOG CPLEX 8.1 Pentium 2.67 GHz 1.00 GB RAM.
Table 3 shows encoding size two implementations, encoding size
characterized number variables number constraints formulation.
encoding size applying ILOG CPLEX presolve given. Presolve
problem reduction technique (Brearley, Mitra, & Williams, 1975) helps linear
programming problems simplifying, reducing eliminating redundancies. short,
926

fiOptiplan: Unifying IP-based Graph-based Planning

Problem
bw-sussman
bw-12step
bw-large-a
att-log0
log-easy
log-a

State change model
presolve
presolve
#Var. #Cons. #Var. #Cons.
486
878
196
347
3900
7372
1663
3105
6084
11628
2645
5022
1932
3175
25
35
24921
41457
1348
2168
50259
85324
3654
6168

Optiplan
presolve
presolve
#Var. #Cons. #Var. #Cons.
407
593
105
143
3534
4998
868
1025
5639
8690
1800
2096
117
149
0
0
2534
3029
437
592
5746
7480
1479
2313

Table 2: Encoding size original state change formulation Optiplan
ILOG CPLEX presolve. #Var. #Cons. give number variables
constraints respectively.

Problem
bw-sussman
bw-12step
bw-large-a
bw-large-b
att-log0
att-log1
att-log2
att-log3
att-log4
att-loga
rocket-a
rocket-b
log-easy
log-a
log-b
log-c

#Var.
196
1663
2645
6331
25
114
249
2151
2147
2915
1532
1610
1348
3654
4255
5457

State change model
#Cons. #Nodes
347
0
3105
19
5022
2
12053
14
35
0
164
0
371
10
3686
15
3676
12
4968
975
2653
517
2787
191
2168
43
6168
600
6989
325
9111
970

Time
0.01
4.28
8.45
581.92
0.01
0.03
0.07
0.64
0.71
173.56
32.44
9.90
0.96
145.31
96.47
771.36

#Var.
105
868
1800
4780
0
29
81
181
360
1479
991
1071
437
1479
1718
2413

Optiplan
#Cons. #Nodes
143
0
1025
37
2096
0
5454
10
0
0
35
0
99
0
228
0
507
0
2312
19
1644
78
1788
24
592
0
2313
19
2620
187
3784
37

Time
0.01
1.65
0.72
72.58
0.01
0.01
0.01
0.03
0.04
2.71
5.48
3.12
0.04
2.66
14.06
16.07

Table 3: Performance encoding size original state change formulation Optiplan. #Var. #Cons. give number variables constraints
ILOG CPLEX presolve, #Nodes give number nodes explored
branch-and-bound finding first feasible solution.

927

fiVan den Briel, & Kambhampati

presolve tries remove redundant constraints fixed variables formulation,
aggregate (substitute out) variables possible.
encoding size presolve, actual encoding size problem,
see significant use planning graphs is. Optiplan, instantiates
fluents actions reachable relevant planning graph
analysis, produces encodings cases one order magnitude smaller
encodings produced original state change model, instantiates ground
fluents actions. Although difference encoding size reduces substantially
applying presolve, planning graph analysis still finds redundancies presolve fails
detect. Consequently, encodings produced Optiplan still smaller
encodings produced original state change model.
performance (and encoding size presolve) Optiplan original
state change model given Table 3. Performance measured time find
first feasible solution. results show overall effectiveness using planning graph
analysis. problems Optiplan generates smaller encodings also performs
better encodings generated state change model.
5.1 IPC Results
Optiplan participated propositional domains optimal track IPC 2004.
track, planners could either minimize number actions, like BFHSP Semsyn;
minimize makespan, like CPT, HSP*a, Optiplan, Satplan04, TP-4; minimize
metric.
IPC results makespan optimal planners given Figure 2. results
evaluated competition organizers looking runtime plan quality graphs.
Also, planners compared estimating asymptotic runtime
analyzing solution quality performance. seven competition domains,
Optiplan judged second best four them. quite remarkable integer
programming hitherto considered competitive planning.
Optiplan reached second place Optical Telegraph Philosopher domains.
domains Optiplan one order magnitude slower Satplan04,
clearly outperforms participating planners. Pipesworld Tankage domain,
Optiplan awarded second place together Satplan04, Satellite domain
Optiplan, CPT, Semsyn tied second place. domains Optiplan
perform well. Airport domain, Optiplan solves first 17 problems
problem 19, takes time so. Pipesworld Notankage
PSR domains, Optiplan slowest also solves fewest number problems
among participating planners.
looking domains problems Optiplan difficulty scaling, notice
problems lead large IP encodings. Since size encoding
function plan length, Optiplan often fails solve problems long solution plans.
One way resolve issue de-link encoding size solution length,
done recent work (van den Briel, Vossen, & Kambhampati,
2005). fact, year following IPC4 developed novel IP encodings (1)
928

fiOptiplan: Unifying IP-based Graph-based Planning

model transitions individual fluents separate loosely coupled network flow
problems, (2) control encoding length generalizing notion parallelism.

6. Conclusions
Optiplan planning system performs significantly better original state change
model Vossen colleagues (1999). performed respectably IPC4, still
lags behind SAT- CSP-based planners, like Blackbox(Chaff), Satplan04(Siege),
GP-CSP. believe, however, performance gap IP techniques
inferior SAT CSP, rather reflection types IP formulations
tried far. Specifically, encodings tried
tailored strengths IP solvers (Chandru & Hooker, 1999).
experience Optiplan encouraged us continue working improved IP
formulations AI planning. recent work (van den Briel, Vossen, & Kambhampati,
2005) model fluents loosely coupled network flow problems control encoding
length generalizing notion parallelism. resulting IP encodings solved
within branch-and-cut algorithm yield impressive results. Also, new approach
shown highly competitive state-of-the-art SAT-based planners.

References
Blum, A., & Furst, M. (1995). Fast planning planning graph analysis. Proceedings
14th International Joint Conference Artificial Intelligence (IJCAI-95), pp.
16361642.
Bockmayr, A., & Dimopoulos, Y. (1998). Mixed integer programming models planning problems. Working notes CP-98 Constraint Problem Reformulation
Workshop.
Bockmayr, A., & Dimopoulos, Y. (1999). Integer programs valid inequalities planning problems. Proceedings European Conference Planning (ECP-99),
pp. 239251. Springer-Verlag.
Brearley, A., Mitra, G., & Williams, H. (1975). Analysis mathematical programming
problems prior applying simplex algorithm. Mathematical Programming, 8,
5483.
Bylander, T. (1997). linear programming heuristic optimal planning. AAAI97/IAAI-97 Proceedings, pp. 694699.
Chandru, V., & Hooker, J. (1999). Optimization Methods Logical Inference. John Wiley
& Sons, New York.
Dimopoulos, Y. (2001). Improved integer programming models heuristic search
AI planning. Proceedings European Conference Planning (ECP-01), pp.
301313. Springer-Verlag.
929

fiVan den Briel, & Kambhampati

10000

10000

1000

1000

100
Time sec.

Time sec.

100
10
Optiplan

1

10
1
Optiplan

Satplan04
0.1

0.1

CPT

0.01

0.01
0

5

10

15

20

25

30

35

40

45

Satplan04
CPT

TP4

0

50

5

10

10000

10000

1000

1000

100

100

Time sec.

Time sec.

15

20

25

30

35

Satellite problem nr.

Airport problem nr.

10
Optiplan

1

10
1

Satplan04
0.1

Optiplan
0.1

CPT

Satplan04

TP4

CPT

0.01

0.01
0

5

10

15

20

25

30

35

40

45

50

0

5

10

20

25

30

1000

1000

100

100

10

Time sec.

10000

Optiplan
Satplan04

1

HSPS-A
3

4

5

6

7

8

9

10

11

12 13

0

14

5

Satplan04

CPT

TP4

10

15

20

Philosophers problem nr.

Optical telegraph problem nr.

10000
Optiplan

1000

Satplan04
HSPS-A

100

TP4
CPT

10
1
0.1
0.01
0

50

Optiplan
HSPS-A

0.01

0.01
2

45

1
0.1

TP4

1

40

10

CPT
0.1

0

35

Pipesworld tankge problem nr.

10000

Time sec.

Time sec.

Pipesworld notankage problem nr.

15

5

10

15

20

25

30

35

40

45

50

PSR problem nr.

Figure 2: IPC 2004 results makespan optimal planners.

930

25

fiOptiplan: Unifying IP-based Graph-based Planning

Dimopoulos, Y., & Gerevini, A. (2002). Temporal planning mixed integer programming. Proceeding AIPS Workshop Planning Temporal Domains,
pp. 28.
Do, M., & Kambhampati, S. (2001). Planning constraint satisfaction: Solving planning graph compiling CSP. Artificial Intelligence, 132 (2), 151182.
Fourer, R., Gay, D., & Kernighan, B. (1993). AMPL: Modeling Language Mathematical Programming. Duxbury Press, Belmont, CA.
ILOG Inc., Mountain View, CA (2002). ILOG CPLEX 8.0 users manual.
Kambhampati, S. (1997). Challenges bridging plan synthesis paradigms. Proceedings
16th International Joint Conference Artificial Intelligence (IJCAI-97), pp.
4449.
Kautz, H., & Selman, B. (1992). Planning satisfiability. Proceedings European
Conference Artificial Intelligence (ECAI).
Kautz, H., & Selman, B. (1999). Blackbox: Unifying sat-based graph-based planning.
Proceedings 18th International Joint Conference Artificial Intelligence
(IJCAI-99), pp. 318325.
Kautz, H., & Walser, J. (1999). State-space planning integer optimization. AAAI99/IAAI-99 Proceedings, pp. 526533.
van den Briel, M., Vossen, T., & Kambhampati, S. (2005). Reviving integer programming approaches AI planning: branch-and-cut framework. Proceedings
International Conference Automated Planning Scheduling (ICAPS-05), pp.
310319.
Vossen, T., Ball, M., Lotem, A., & Nau, D. (1999). use integer programming
models AI planning. Proceedings 18th International Joint Conference
Artificial Intelligence (IJCAI-99), pp. 304309.
Wolfman, S., & Weld, D. (1999). LPSAT engine application resource planning. Proceedings 18th International Joint Conference Artificial Intelligence (IJCAI-99), pp. 310317.
Wolsey, L. (1998). Integer Programming. Wiley-Interscience Series Discrete Mathematics
Optimization. John Wiley & Sons, New York.

931

fiJournal Artificial Intelligence Research 24 (2005) 799-849

Submitted 08/04; published 12/05

Probabilistic Hybrid Action Models
Predicting Concurrent Percept-driven Robot Behavior
Michael Beetz

BEETZ @ . TUM . DE

Department Computer Science IX, Technische Universitat Munchen,
Boltzmannstr. 3, D-81667 Garching, Germany,

Henrik Grosskreutz

GROSSKREUTZ @ CS . RWTH - AACHEN . DE

Department Computer Science, Aachen University Technology
D-52056 Aachen, Germany

Abstract
article develops Probabilistic Hybrid Action Models ( PHAMs), realistic causal model
predicting behavior generated modern percept-driven robot plans. PHAMs represent
aspects robot behavior cannot represented action models used AI planning:
temporal structure continuous control processes, non-deterministic effects, several modes
interferences, achievement triggering conditions closed-loop robot plans.
main contributions article are: (1) PHAMs, model concurrent percept-driven
behavior, formalization, proofs model generates probably, qualitatively accurate
predictions; (2) resource-efficient inference method PHAMs based sampling projections
probabilistic action models state descriptions. show PHAMs applied
planning course action autonomous robot office courier based analytical
experimental results.

1. Introduction
autonomous robots equipped restricted, unreliable, inaccurate sensors effectors operate complex dynamic environments. successful approach deal
resulting uncertainty use controllers prescribe robots behavior terms concurrent reactive plans (CRPs) plans specify robots react sensory input
order accomplish jobs reliably (e.g., McDermott, 1992a; Beetz, 1999). Reactive plans
successfully used produce situation specific behavior, detect problems recover
automatically, recognize exploit opportunities (Beetz et al., 2001). kinds
behaviors particularly important autonomous robots uncertain information
world, act dynamically changing environments, accomplish complex tasks
efficiently.
Besides reliability flexibility, foresight another important capability competent autonomous robots (McDermott, 1992a). Temporal projection, computational process predicting happen robot executes plan, essential robots plan intended
courses action successfully. able project plans, robots must causal models
represent effects actions. robot action planners use representations include discrete action models plans define partial orders actions. Therefore, cannot
automatically generate, reason about, revise modern reactive plans. two important
drawbacks. First, planners cannot accurately predict diagnose behavior generated
plans abstract away important aspects reactive plans. Second, planc
2005
AI Access Foundation. rights reserved.

fiB EETZ & G ROSSKREUTZ

ners cannot exploit control structures provided reactive plan languages make plans
flexible reliable.
article develop PHAMs (Probabilistic Hybrid Action Models), action models
expressiveness accurate prediction behavior generated concurrent reactive
plans. best knowledge, PHAMs action representation used action
planning provides programmers means describing interference simultaneous,
concurrent effects, probabilistic state action models, well exogenous events. PHAMs
successfully applied autonomous robot office courier museum tour-guide robot
make predictions full-size robot plans execution plans (Beetz, 2001).
article makes several important contributions area decision-theoretic robot action
planning. First, describe PHAMs, formal action models allow prediction
qualitative behavior generated concurrent reactive plans. Second, show PHAMs
implemented resource efficient way predictions based PHAMs performed
robots executing plans. Third, apply plan projection method probabilistic
prediction-based schedule debugging analyze context robot office courier (Beetz,
2001).
starting technical part article would like make several remarks.
article restrict navigation actions model exactly implemented one successful autonomous robot navigation systems (Burgard et al., 2000).
reason want close gap action models used AI planning systems
control programs used autonomous robots behavior produce. control
programs model proven achieve reliable, high performance navigation
behavior. Minerva experiment, controlled navigation crowded museum
93 hours. execution, navigation plans revised planning module
3200 times without causing deadlocks interacting, concurrent control processes
(Beetz, 2002a; Beetz et al., 2001). robot office courier experiments, applied plan revision
methods enabled robot plan ahead 15-25 minutes. consider time
scale sufficient improving robots performance planning. However, performance
gains principle achieved navigation planning often small compared
achieved planning manipulation tasks.
Although use navigation example, modeling techniques apply
mechanisms autonomous robots, vision (Beetz et al., 1998), communication (Beetz &
Peters, 1998), manipulation (Beetz, 2000) equally well. reasons cover
kinds actions article require additional reasoning capabilities
moment models validated respect robot simulations. additional robot
capabilities would modeled include symbol grounding/object recognition (Beetz,
2000), changing states objects, thorough models belief states robots (Schmitt
et al., 2002). Addressing issues well beyond scope article.
remainder article introduce basic conceptualization underlying PHAMs
describe two realizations them: one studying formal properties another one targeted efficient implementation. also show PHAMs employed context
transformational robot planning.
article organized follows. Section 2 describes everyday activity primary class
application problems. introduce concurrent reactive plans (CRPs) means producing
characteristic patterns everyday activity identify technical problems prediction
800

fiP ROBABILISTIC H YBRID ACTION ODELS

physical robot behavior CRPs generate. Section 3 explains execution CRPs
physical computational effects plan execution modeled using PHAMs. PHAMs
describe behavior robot sequence control modes mode continuous
behavior specified control law. Mode transitions triggered controlled system
satisfying specified mode transition conditions. introduce set predicates use
represent conceptualization formally. Section 4 5 describe two different approaches
predicting behavior produced concurrent reactive plans context PHAMs.
first one behavior approximated discretizing time sequence clock ticks
made arbitrarily dense. model used derive formal properties projection
concurrent reactive plans. second approach, described Section 5, describes much
efficient approach projection CRPs. approach time ticks explicitly
considered represented discrete events may occur. time instances system
state inferred interpolation using control laws respective modes.
projection mechanism used execution time board robots. show
implementation PHAMs employed prediction-based tour scheduling autonomous
robot office courier. conclude evaluation discussion related work.

2. Structured Reactive Controllers Projection Delivery Tour Plans
Plan-based robot control successfully applied tasks control space probes
(Muscettola et al., 1998b), disaster management surveillance (Doherty et al., 2000),
control mobile robots office delivery (Simmons et al., 1997; Beetz et al., 2001) tourguide
scenarios (Alami et al., 2000; Thrun et al., 2000). class tasks received little attention
plan-based robot control everyday activity human living working environments, tasks
people usually good at.
get better intuition activity patterns produced everyday activity, let us consider chores hypothetical household robot. Household chores entail complex routine jobs
cooking dinner, cleaning kitchen, loading dish washer, etc. routine jobs
typically performed parallel. household robot might clean living room
soup cooking stove. cleaning up, phone might ring robot interrupt cleaning order go answer phone. completed telephone call
robot continue cleaning right stopped. Thus, robots activity must concurrent,
percept-driven, interruptible, flexible, robust, requires foresight.
fact people manage execute daily tasks effectively suggests, view,
nature everyday activity permit agents make assumptions simplify
computational tasks required competent activity. Horswill (1996) puts it, everyday life must
provide us loopholes, structures constraints make activity tractable.
believe many applications robotic agents perform everyday activities,
following assumptions valid allow us simplify computational problems controlling
robot competently:
1. Robotic agents familiar activities satisfying individual tasks situations
typically occur performing them. carry everyday activities
confronted kinds situations many times. consequence,
conducting individual everyday activities learned experience simple
sense require lot plan generation first principles.
801

fiB EETZ & G ROSSKREUTZ

2. Appropriate plans satisfying multiple, possibly interfering, tasks determined
greedy manner. robot first determine default plan performing individual tasks
concurrently additional ordering constraints simple fast heuristic plan
combination methods. robot avoid remaining interferences subactivities predicting forestalling them.
3. Robotic agents monitor execution activities thereby detect situations
intended course action might fail produce desired effects. situations detected, robots adapt intended course action specific situations
encounter, necessary based foresight.
previous research proposed Structured Reactive Controllers (SRCs) computational model plan-based control everyday activity. SRCs collections concurrent
reactive control routines adapt changing circumstances execution
means planning. SRCs based upon following computational principles:
1.

SRC equipped library plan schemata routine tasks common situations.
plan schemata provided programmers designed high
expected utility cost deal conceivable problems. know
AI courses plans check tailpipes every time starting car
typically lower expected utility ones check them, even though
bananas stuck tailpipe necessary precondition starting car successfully.

robustness, flexibility, reactivity plan schemata achieved implementing
concurrent percept-driven plans even highest level abstraction. plans employ control structures including conditionals, loops, program variables, processes, subroutines. also make use high-level constructs (interrupts, monitors) synchronize
parallel actions make plans reactive robust incorporating sensing monitoring actions reactions triggered observed events. Goals sub-plans represented
explicitly annotations planning algorithms infer purpose sub-plans
automatically.
2.

SRC fast heuristic methods putting plans together routine activities.
able predict problems likely occur revise course action avoid
them. Predictive plan debugging requires SRC reason through, predict effects
of, highly conditional flexible plans subject article.

3.

SRC perform execution time plan management. run processes monitor beliefs
robot triggered certain belief changes. processes revise plans
executed.

Structured reactive controllers work follows. given set requests, structured reactive controllers retrieve routine plans individual requests execute plans concurrently.
routine plans general flexible work standard situations executed concurrently routine plans. Routine plans cope well partly unknown
changing environments, run concurrently, handle interrupts, control robots without assistance
extended periods. standard situations, execution routine plans causes robot
802

fiP ROBABILISTIC H YBRID ACTION ODELS

exhibit appropriate behavior achieving purpose. execute routine plans,
robot controllers also try determine whether routines might interfere
watch exceptional situations. encounter exceptional situations try
anticipate forestall behavior flaws predicting routine plans might work kind
situation. necessary, revise routines make robust respective kinds
situations. Finally, integrate proposed revisions smoothly ongoing course
actions.
2.1 Plan-based Control Robot Office Courier
describe approach predicting concurrent percept-driven robot behavior first
give comprehensive example plan-based robot office courier performing delivery tour
exhibiting aspects everyday activity. description example includes presentation
key plan schemata used robot, sketch heuristic plan combination method, prediction behavior flaws, revision delivery plans. example run performed
mobile robot RHINO acting robot office courier (Beetz, 2001; Beetz, Bennewitz, &
Grosskreutz, 1999).
2.1.1 P LANS



P LAN CHEMATA



ROBOT C OURIER

robot courier equipped library plan schemata standard tasks including delivering items, picking items, navigating one place another. presentation
plans plan schemata proceeds bottom up. start low-level plans navigation
end comprehensive object delivery plans.
low-level navigation plan specifies robot navigate one location environment, typically current position, another one, destination. Figure 1 depicts
low-level navigation plan going location room A-117 location 5 room A-111.
plan consists two components: sequence intermediate target points (the locations indexed numbers 1 5 Figure 1) sequentially visited robot specification
robot adapt travel modes follows navigation path. many
environments advantageous adapt travel mode surroundings: drive carefully (and
therefore slowly) within offices offices cluttered, switch sonars driving
doorways (to avoid sonar crosstalk), drive quickly hallways. second part
plan depicted regions different textures different travel modes office,
hallway, doorway. Whenever robot crosses boundaries regions adapts
parameterization navigation system. Thus, low-level navigation plans start terminate navigation processes change parameterization navigation system control mode
switches (SET- NAVIGATION - MODE) adding deleting intermediate target points (MOVE - TO).
specify reactive plans RPL (McDermott, 1991; Beetz & McDermott, 1992), plan language provides high-level control structures specifying concurrent, event-driven robot behavior. pseudo code Figure 2 sketches initial part plan depicted Figure 1.
plan leaving office consists two concurrent sub-plans: one following (initial part
the) prescribed path one adapting travel mode. second sub-plan adapts navigation mode robot dynamically. Initially, navigation mode set office. Upon entering
leaving doorway navigation mode adapted. plan uses fluents, conditions
803

fiB EETZ & G ROSSKREUTZ



















































































5

















































A-111















































A-113
A-110
4


























3
















2
































































A-121













1












A-120






A-117





































Dieters


















Desk



























































Legend
doorway travelmode
office travelmode
hallway travelmode
Navigation Plan
waypoint waypoint coordinates
1
h2300, 800i
2
h2300, 900i
3
h1200, 1100i
4
h1200, 1200i
5
h1250, 1400i

Figure 1: Graphical representation navigation plan. Topological navigation plan navigating
room A-117 A-111 regions indicating different travel modes small black
circles indicating additional navigation path constraints.
updated asynchronously based new sensor readings. Fluents trigger (whenever )
terminate (wait ) plan steps.
execute concurrently
execute-in-order

(1); wait (go-to-completed?);
(2); wait (go-to-completed?);
local fluents distance-to-doorway
fluent-network (| hx, yi hxdw , ydw |)
entering-dw?-fl distance-to-doorway < 1m
entering-hw?-fl distance-to-doorway > 1m
MOVE -
MOVE -

execute-in-order

SET- NAVIGATION - MODE (office); wait (entering-dw?-fl);
SET- NAVIGATION - MODE (doorway); wait (entering-hw?-fl);
SET- NAVIGATION - MODE (hallway)

Figure 2: plan sketches specification navigation process leaving office. two
components following prescribed path adapting travel mode implemented
concurrent sub-plans. second component uses fluent measure distance
center doorway two dependent fluents signal robots entering
leaving doorway. Initially, travel mode set office. Upon entering
leaving doorway travel mode adapted.

low-level navigation plan instances used higher-level navigation plans make
navigation processes flexible, robust, embeddable concurrent task contexts. higherlevel plans generate low-level plans based robots map environment (GENERATE NAV- PLAN ). slightly simplified version high-level plan listed below.
804

fiP ROBABILISTIC H YBRID ACTION ODELS

highlevel-plan ACHIEVE(loc(rhino, hx, yi))
1 cleanup routine ABORT- NAVIGATION - PROCESS
2 valve wheels
3
loop
4
try parallel
5
wait navigation-interrupted?
6
local vars NAV- PLAN GENERATE - NAV- PLAN(c,d)
7
swap-plan (NAV- PLAN,NAV- STEP)
8
named subplan NAV- STEP
9
DUMMY
10
- CLOSE ?(hx, yi)

explain plan going inner parts, generate robot behavior, outer
ones, modify behavior. Lines 6 8 make navigation plan independent starting
position thereby general: given destination d, plan piece computes low-level
navigation plan robots current location c using map environment
executes (Beetz & McDermott, 1996).
order run navigation plans less constrained task contexts must prevent
concurrent routines directing robot different locations navigation plan
executed. accomplish using semaphores valves, requested
released. plan asking robot move stand still must request valve wheels, perform
actions received wheels, release wheels done. accomplished
statement valve line 2.
many cases processes higher priorities must move robot urgently. case,
blocked valves simply pre-empted. make plan interruptible, robust interrupts, plan two things. First, detect gets interrupted second,
handle interrupts appropriately. done loop generates executes
navigation plans navigation task robot destination. make routine
cognizant interrupts using fluent navigation-interrupted?. Interrupts handled terminating current iteration loop starting next iteration, new navigation
plan starting robots new position generated executed. Thus, lines 3-5 make
plan interruptible.
make navigation plan transparent name routine plan ACHIEVE(loc(rhino,hx,yi))
thereby enable planning system infer purpose sub-plan syntactically. Interruptible embeddable plans used task contexts higher priority concurrent sub-plans.
instance, monitoring plan used controller estimates opening angles doors whenever robot passes one. Another monitoring plan localizes robot actively whenever lost
track position.
facilitate online rescheduling modularized plans respect locations
sub-plans executed using location plan schema. location hx,yi p plan
schema specifies plan p performed location hx,yi. simplified version
plan schema location .
805

fiB EETZ & G ROSSKREUTZ

named subplan Ni
location hx, yipby
valve wheels
local vars DONE ? FALSE
loop
try parallel
wait Task-Interrupted?(Ni )
sequentially
NAVIGATE -T Ohx, yi

p
DONE ?



TRUE

DONE ? = TRUE

plan schema accomplishes performance plan p location hx,yi navigating
location hx,yi, performing sub-plan p, signalling p completed (the inner sequence).
valve statement obtains semaphore wheels must owned process changing
location robot. loop makes execution p hx,yi robust interrupts
higher priority processes. Finally, named sub-plan statement gives sub-plan symbolic name
used addressing sub-plan scheduling purposes plan revisions. Using
location plan schema, plan delivering object location p location
roughly specified plan carries pickup(o) location p put-down(o) location
additional constraint pickup(o) carried putdown(o). every sub-plan p
performed particular location l form location hx,yi p, scheduler
traverse plan recursively collect location sub-plans install additional ordering
constraints sub-plans maximize plans expected utility.
allow smooth integration revisions ongoing scheduled activities, designed
plans sub-plan keeps record execution state and, started anew, skips
parts plan longer executed (Beetz & McDermott, 1996). made plans
single deliveries restartable equipping plan p variable storing execution state
p used guard determine whether sub-plan executed. variable
three possible values: to-be-acquired denoting object must still acquired; loaded
denoting object loaded; delivered denoting delivery completed. plan
schema delivery single object consists two fairly independent plan steps: pick-up
put-down step.
EXECUTION - STATE(p, to-be-acquired)
AT-L OCATION
L
PICK - UP(o)
EXECUTION - STATE(p, loaded)
AT-L OCATION

PUT- (o)

2.1.2 G ENERATING EFAULT ELIVERY P LANS
heuristic plan generator delivery tours simple: inserts pick-up put-down subplans delivery requests overall plan determines appropriate order
location sub-plans. ordering determined heuristic performs simple topological
806

fiP ROBABILISTIC H YBRID ACTION ODELS

sort sub-plans based locations sub-plans executed. heuristic considers additional constraints executing pick-up steps always respective
put-down plan-steps.
2.1.3 P REDICTION - BASED P LAN EBUGGING



ROBOT FFICE C OURIER

Let us contemplate specific scenario robot office courier RHINO performs office delivery requires prediction forestalling plan failures execution time. Consider
following situation environment pictured Figure 3. robot office courier deliver
letter yellow envelope room A-111 A-117 (cmd-1) another letter
envelopes color unknown A-113 A-120 (cmd-2). robot already tried accomplish cmd-2 recognized room A-113 closed (using range sensors) revises
intended course action achieving cmd-2 opportunistically. is, later detects
A-113 open interrupt current activity reconsider intended course action
premise steps accomplishing cmd-2 executable.
perform tasks quickly robot schedules pick-up delivery actions minimize
execution time assure letters picked delivered. ensure
schedules work, robot take account state world changes
carries scheduled activities. Aspects states robot consider scheduling
activities locations letters. Constraints state variables schedules
satisfy ask robot pick letters currently robots location
robot carry two letters envelopes color.
(58) (DONE GOTO (1000.0 1600.0))
(58) (DO LOAD-LETTER y-letter)
(62) (ACTIVATE GOTO (2300.0 600.0))






(2) (ACTIVATE GOTO (1000.0 1600.0))

A-111







(136) (DONE GOTO (2300.0 600.0))
(136) (DO UNLOAD-LETTER y-letter)





A-117

Figure 3: possible projected execution scenario initial plan. opportunity loading
letter unknown color ignored.
Suppose robot standing front room A-117. belief state robot contains
probabilities colors letters desk A-113. robot also received evidence A-113 opened meantime. Therefore belief state assigns probability p
value true random variable open-A113.
807

fiB EETZ & G ROSSKREUTZ

update belief state requires robot reevaluate options accomplishing
jobs respect changed belief state. Executing current plan without modifications
might yield mix ups robot might carry two letters envelopes color.
different options are: (1) skip opportunity, (2) ask immediately letter
A-113 put envelope yellow (to exclude mix ups taking opportunity
later); (3) constrain later parts schedule two yellow letters carried even
letter A-113 turns yellow; (4) keep picking letter A-113
opportunistic sub-plan. option robot take depends belief state respect
states doors locations letters. find schedules probably work,
particular, ones might result mixing letters, robot must apply model world
dynamics state variables.
respect belief state, different scenarios possible. first one, A-113
closed, pictured Figure 3. Points trajectories represent predicted events. events
without labels actions robot changes heading (on approximated trajectory)
events representing sensor updates generated passive sensing processes. example, passive
sensor update event generated robot passes door. scenario intervention
prediction-based debugging necessary flaw projected.
A-111

A-113

A-111

(95) (DONE GOTO (1000.0 1600.0))
(95) (DO LOAD-LETTER Y-LETTER)
(95) (FAILURE SAME-COLOR LETTER)
(33) (DONE GOTO (1850.0 1350.0))
(33) (DO LOAD-LETTER OPP)
(34) (ACTIVATE GOTO (1000.0 1600.0))
















A-113

(102) GOTO (1000.0 1600.0))
(102) LOAD-LETTER Y-LETTER)
(103) GOTO (1100.0 400.0))




400.0)) ff
(174) (DONE GOTO (1100.0
(174) UNLOAD-LETTER OPP)

(175) GOTO (2300.0 600.0))

(12) (RECOGNIZE LOAD-LETTER OPP)
(13) (ACTIVATE GOTO (1850.0 1350.0))



(2) (ACTIVATE GOTO (1000.0 1600.0))





(30) GOTO (1850.0 1350.0))
(30) LOAD-LETTER OPP)
(31) GOTO (1000.0 1600.0))




ff

fi




(11) (RECOGNIZE LOAD-LETTER OPP)
(12) (ACTIVATE GOTO (1850.0 1350.0))
(2)
(ACTIVATE GOTO (1000.0 1600.0))

A-120

(248) (DONE GOTO (2300.0 600.0))
(248) (DO UNLOAD-LETTER Y-LETTER)

A-117

A-120

(a)

A-117

(b)

Figure 4: Two possible predicted scenarios opportunity taken. scenario (a) letter
turns color one loaded afterwards. Therefore,
second loading fails. scenario (b) letter turns different color
one loaded afterwards. Therefore, second loading succeeds.
scenarios office A-113 open controller projected recognize opportunity reschedule enabled plan steps described above. 1 resulting schedule asks
robot enter A-113 first, pickup letter cmd-2, enter A-111 pick letter
cmd-1, deliver letter cmd-2 A-120, last one A-117. category
scenarios divided two categories. first sub-category shown Figure 4(a)
letter picked yellow. Performing pickup thus would result robot carrying
1. Another category scenarios characterized A-113 becoming open robot left A-111. may also
result execution failure letter loaded A-113 yellow, discussed further.

808

fiP ROBABILISTIC H YBRID ACTION ODELS

A-111

A-113

(39) (DONE GOTO (1850.0 1450.0))
(39) (DO LOAD-LETTER NIL)
(70) (ACTIVATE GOTO (1100.0 400.0))



(200) (DONE GOTO (1000.0 1600.0))
(202) (DO LOAD-LETTER Y-LETTER)
(211) (ACTIVATE GOTO (2300.0 600.0))














(2) (ACTIVATE GOTO
(1850.0 1450.0))







(19) (USE OPPORTUNITY)









(263) (DONE GOTO (2300.0 600.0))
(147) (DONE GOTO (1100.0 400.0))(263) (DO UNLOAD-LETTER Y)
(162) (DO UNLOAD-LETTER OPP)
(178) (ACTIVATE GOTO (1000.0 1600.0))

A-120

A-117

Figure 5: Projected scenario plan suggested plan debugger. letter unknown
color picked also delivered first. plan little less efficient avoids
risk able load second letter.

two yellow letters therefore execution failure signalled. second sub-category shown
Figure 4(b) letter different color therefore robot projected succeed taking course action scenarios. Note possible flaw introduced
reactive rescheduling rescheduler consider state robot
change course action, particular state may caused robot carry
two letters color.
case, plan-based controller probably detect flaw likely respect
robots belief state. enables debugger forestall flaw, instance, introducing
additional ordering constraint, sending email increases probability letter
put particular envelope. revision rules introduced last section.
Figure 5 shows projection plan revised adding ordering constraint
letter A-120 delivered entering A-111.
Figure 6(a) shows event trace generated initial plan executed RHINO
control system (Thrun et al., 1998) critical scenario without prediction based schedule debugging; Figure 6(b) shows one debugger adding additional ordering constraint.
scenario shows reasoning future execution plans enables robot improve
behavior.
article, describe probabilistic models reactive robot behavior necessary predict scenarios one described purpose prediction-based plan
debugging.
2.2 Projection Low-level Navigation Plans
know robot plans look like turn question predict
effects executing delivery plan. input data plan projection probabilistic beliefs
809

fiB EETZ & G ROSSKREUTZ

A-111

%%<< %% 2? fi#. +2136@+,fi25"A5..+,BCfi4( .#+2#+,=255.fi-,fi(
%% << fi2#.+.3= 25.5.>!fi
-,#fifi.( #8 %& %& %( (

21:12:31 ARRIVED (1000.0 1600.0)
21:13:06 LOADING BLUE LETTER
21:13:06 GOING (2300.0 600.0)

A-113
21:10:13 ARRIVED (1850.0 1450.0)
21:10:37 LOADING BLUE LETTER
21:10:37 GOING (1100.0 400.0)

P OP P
POOP
G G G G G FG F F F
NN QOQP
G F GH
QN
NN NQQQ
EH HEFE HD
H DS SSS
NR
JJ MI MRIM R RI R R R IIIIII R R R IR R R RS HI H H HS HS HS DD DDD ST DD TT
MJM J
UTU
LM KKJ
KL KK

21:09:38 GOING (1850.0 1450.0)

%% )*)*++ .,fi-..#+ !+-/fifi "!01"2
#fi#.fi+#83. 4 259%5:%.& fi;-, 6:%#+& %7-( 7( (

21:09:50 INSTALL NEW SCHEDULE
AVOID
CARRYING COLOR

fi fi"!
#fifi#$ % & ' % & %( (

21:11:24 ARRIVED (1100.0 400.0)
21:11:59 UNLOADING BLUE LETTER
21:11:59 GOING (1000.0 1600.0)

21:14:26 ARRIVED (2300.0 600.0)
21:14:58 UNLOADING BLUE LETTER

A-120

(a)

A-117

(b)

Figure 6: trajectory without prediction-based plan revision (Sub-figure (a)) fails
courier foresee possible complications loading second letter. Subfigure (b) shows trajectory possible flaw forestalled planning mechanism.

robot respect current state world, probabilistic models exogenous events
assumed Poisson distributed, probabilistic models low-level plans, probabilistic
rules guessing missing pieces information. output projection process sequence
dated events along estimated state time event.
Plan projection identical plan execution two exceptions. First, whenever plan
projector interprets wait whenever records corresponding fluents active triggering
conditions. way, plan projection mechanism automatically generate percepts continuous control processes exogenous events make triggering conditions true. example,
navigation plan waiting robot enter hallway plan projector probabilistically guesses robot motion causes respective triggering condition become true.
time instant, plan projector generates sensor input event corresponding sensor
reading.
Plan projection also differs plan interpretation whenever robot interacts
real world, projected robot must interact symbolic representations world.
places happens low-level plans. Thus instead executing low-level plan
projector guesses results executing plans asserts effects form
propositions timeline. three kinds effects generated interpretation
low-level plans: (1) physical changes, robot changing position, (2) low-level
plan changing dynamical state robot, direction robot heading to,
(3) computational effects, changing values program variables signalling success
failure control routines. Thus model low-level plan used plan projection
probability distribution sequence events generates delays
subsequent events.
Thinking procedurally, plan projector works follows. iteratively infers occurrence
next event given plan completely interpreted. next event either next
810

fiP ROBABILISTIC H YBRID ACTION ODELS

event low-level plan generates computational state controller change,
sensor input event active triggering condition predicted become true, exogenous
event one predicted occur. next predicted event earliest events.
consider particular instance low-level plans: low-level navigation plans
used example previous section. Navigation key action autonomous mobile
robots. predicting path robot take necessary predict robot
be, prerequisite predicting robot able perceive. example,
whether robot perceive door open depends robot taking path passes
door, executing door angle estimation routine passing door door
within sensor range. Passing door perceived based robots position estimate
environment map. Consequently, robot executes plan step door open,
end execution plan step depends actual path robot take. implies
action planning process must capable predicting trajectory accurately enough predict
global course action correctly.
Navigation actions representative large subset physical robot actions: movements controlled motors. Physical movements number typical characteristics. First,
often inaccurate unreliable. Second, cause continuous (and sometimes discontinuous) change respective part robots state. Third, interference concurrent
movements often described superposition individual movements.
discuss issues raised projection concurrent reactive plans, sketch delivery
tour plan specifies robot deliver mail rooms A-113, A-111, A-120
Figure 1 (Beetz, 2001). mail room A-120 delivered 10:30 (a strict deadline).
Initially, planner asks robot perform deliveries order A-113, A-111, A120. room A-113 closed corresponding delivery cannot completed. Therefore,
planning system revises overall plan robot accomplish delivery A-113
opportunity. words, robot interrupt current delivery deliver mail
A-113 (see Figure 7) delivery completed.
policy long in-hallway?
whenever passing-a-door?

ESTIMATE - DOOR - ANGLE ()

policy seq wait open?(A-113)

DELIVER - MAIL - (D IETER )

1.
2.

GO - (A-111)
GO - (A-120)

10:30

Figure 7: Delivery tour plan concurrent monitoring process triggered continuous effects navigation plan (passing door) opportunistic step. concurrent
reactive plans serve example discussing requirements causal models
must satisfy.
plan contains constraining sub-plans whenever robot passes door estimates
opening angle door using laser range finders opportunities complete
811

fiB EETZ & G ROSSKREUTZ

delivery room A-113 soon learn office open. sub-plans triggered
completed continuous effects navigation plans. example, event passing
door occurs robot traverses rectangular region front door. call events
endogenous events.

A-111

A-113

end(low-level-nav-plan(...))
leaving
doorway
entering
doorway

leaving
hallway

VW
VW

VW VW

leaving
doorway

VW VW
VW

entering
hallway
entering
doorway
begin(low-level-nav-plan(...))
A-120

A-117

Figure 8: Visualization projected execution scenario. following types events depicted specific symbols: change travel mode event rhombuses, start/stop passing
doorway small circles, start/stop low-level navigation plan double circles, entering doorway/hallway boxes.

Figure 8 shows projected execution scenario low-level navigation plan embedded
plan depicted Figure 7. behavior generated low-level navigation plans modeled
sequence events either cause qualitative behavior changes (e.g. adaptations travel
mode) trigger conditions plan reacting (e.g. entering hallway passing door).
events depicted rhomboids denote events CRP changes direction target
velocity robot. squares denote events entering leaving offices. small circles
denote events starting finishing passing door, predicted concurrent
monitoring process estimates opening angles doors robot passing them.
projected execution scenarios used prediction-based debugging delivery
tours autonomous robot office courier. Beetz et al. (1999) shown controller employing predictive plan scheduling using causal models described article perform
better possibly could without predictive capabilities (see also Section 6.1).
812

fiP ROBABILISTIC H YBRID ACTION ODELS

2.3 Peculiarities Projecting Concurrent Reactive Plans
several peculiarities projection concurrent reactive plans want point
here.
Continuous Change. Concurrent reactive plans activate deactivate control processes
thereby cause continuous change states robots position. Continuous change must
represented explicitly CRPs employ sensing processes continually measure relevant
states (for example, robots position) promptly react conditions caused continuous
effects (for example, entering office).
Reactive Control Processes. reactive nature robot plans, events
predicted continuous navigation process depend process also
monitoring processes simultaneously active wait conditions continuous
effects navigation process might cause. Suppose robot controller running monitoring
process stops robot soon passes open door. case planner must predict
robot passes door events door robot passes continuous navigation action.
events trigger sensing action estimates door angle, predicted percept open door detected navigation process deactivated. discrete events
might predicted based continuous effects navigation include entering
leaving room, come within one meter destination, etc.
Interference continuous effects. control processes set voltages robots
motors, possible modes interference control processes limited. generate
signals motors combined effects determined so-called task arbitration
scheme (Arkin, 1998). common task arbitration schemes (1) behavior blending (where
motor signal weighted sum current input signals) (Konolige, Myers, Ruspini, &
Saffiotti, 1997); (2) prioritized control signals (where motor signal signal process
highest priority) (Brooks, 1986); (3) exclusion concurrent control signals
use semaphores. plans, exclude multiple control signals motors
easily incorporated prediction mechanism. Thus remaining type
interference superposition movements turning camera moving.
Uncertainty. various kinds uncertainty non-determinism robots actions
causal model represent. often necessary specify probability distribution
average speed displacements points paths enable models predict range
spatio-temporal behavior navigation plan generate. Another important issue model
probability distributions occurrence exogenous events. dynamic environments
exogenous events opening closing doors might occur time.

3. Modeling Reactive Control Processes Continuous Change
Let us conceptualize behavior generated modern robot plans interaction
behavior interpretation reactive plans. base conceptualization vocabulary
hybrid systems. Hybrid systems developed design, implement, verify embedded
systems, collections computer programs interact analog environment
(Alur, Henzinger, & Wong-Toi, 1997; Alur, Henzinger, & Ho, 1996).
advantage hybrid system based conceptualization state-based ones hybrid
systems designed represent concurrent processes interfering continuous effects.
also allow discrete changes process parameterization, need model activation,
813

fiB EETZ & G ROSSKREUTZ

deactivation, reparameterization control processes reactive plans. addition, hybrid system based conceptualizations model procedural meaning wait whenever
statements.
pictured Figure 9, consider robot operating environment two interacting processes: environment including robot hardware, also called controlled
process, concurrent reactive plan, controlling process. state environment represented state variables including variables x y, robots real position
door-anglei representing opening angle door i. robot controller uses fluents store
robots measurements state variables (robot-x, robot-y, door-a120, etc.). fluents
continually updated self-localization process model-based estimator estimating
opening angles doors. control inputs plan environment process vector
includes travel mode, parameterization navigation processes current target
point reached robot.
Environment
State Variables:
X



DOORANGLEi

Control Inputs

Exogenous Events

- Travel Mode
- Target Point

going-for-lunch(person)

Sensing Process
- self localization
- door angle estimation

Concurrent Reactive Plan
Delivery Plan
Figure 1

robot-x
robot-y
door-i

Figure 9: figure shows conceptualization execution navigation plans. relevant
state variables x coordinates robots position opening angles
doors. fluents estimate state variables robot-x, robot-y, door-a120.

3.1 Hybrid System Model Reactive Robot Behavior
model controlled process hybrid system (Alur et al., 1997, 1996). Hybrid
systems continuous variable, continuous time systems phased operation. Within
phase, called control mode, system evolves continuously according dynamical law
mode, called continuous flow. Thus state hybrid system thought
pair control mode continuous state. control mode identifies flow,
814

fiP ROBABILISTIC H YBRID ACTION ODELS

continuous flow identifies position it. Also associated control mode so-called
jump conditions, specifying conditions discrete state continuous state together
must satisfy enable transition another control mode. transitions cause abrupt changes
discrete well continuous state. jump relation specifies valid settings
system variables might occur jump. Then, next transition, continuous state
evolves according flow identified new control mode.
considering interpretation concurrent reactive plans hybrid system control
mode determined set active control processes parameterization. continuous
state characterized system variables x, y, represent robots position
orientation. continuous flow describes state variables change result active
control processes. change represented component velocities x, y, o. Thus
control mode robots velocity constant. Linear flow conditions sufficient
robots paths approximated accurately enough using polylines (Beetz & Grosskreutz,
1998). also computationally much easier faster handle. jump conditions
conditions monitored constraining control processes activate deactivate
control processes.
Thus interpretation navigation plan according hybrid systems model works
follows. hybrid system starts initial state hcm0 , x0 i. state trajectory evolves
control mode remaining constant continuous state x evolving according flow
condition cm. (estimated) continuous state satisfies transition condition edge
mode cm mode cm0 jump must made mode cm0 , mode might chosen
probabilistically. jump continuous state may get initialized new value x 0 .
new state pair hcm0 , x0 i. continuous state x0 evolves according flow condition
cm0 .
construction hybrid system given concurrent plan straightforward. start
current plan execution state. every concurrent active statement form wait cond
whenever cond add cond jump condition current control mode. addition
one additional jump condition completion plan step.
Figure 10 depicts interpretation first part navigation plan shown Figure 2.
interpretation represented tree nodes represent control modes corresponding hybrid system node labels continuous flow. edges control mode
transitions labeled jump conditions. robot starts executing plan room A-117.
initial control mode hybrid system root state tree depicted Figure 10.
initial state represents state computation first control processes two parallel
branches active, processes going intermediate target point 1 maintaining office mode robots travel mode. flow specifies robot
initial control mode absolute value derivative robots position function
robots navigation mode (office, doorway, hallway) next intermediate target point.
hybrid system makes transition one subsequent states either first target point
reached distance doorway becomes less one meter. transition condition
upper edge robot come sufficiently close doorway, lower edge
reached first target point. lower edge, hybrid system goes state
robot goes target point 2 still keeping office mode current travel
mode. transition robot changes travel mode doorway keeps approaching
first target point. variables changed control mode transitions
815

fiB EETZ & G ROSSKREUTZ

control mode: cm3
x = f1 (hallway, h2300, 800i)
= f2 (hallway, h2300, 800i)
e3 : dist(hx, yi, hxdw , ydw i) > 100
control mode: cm1
x = f1 (doorway, h2300, 800i)
= f2 (doorway, h2300, 800i)
e4 : x = 2300 = 800
control mode: cm4
x = f1 (doorway, h2300, 900i)
= f2 (doorway, h2300, 900i)

e1 : dist(hx, yi, hxdw , ydw i) < 100

control mode: cm0
x0 =2400, y0 =600
x = f1 (office, h2300, 800i)
= f2 (office, h2300, 800i)
control mode: cm5
x = f1 (office, h1200, 1100i)
= f2 (office, h1200, 1100i)

e2 : x = 2300 = 800

e5 : x = 2300 = 900
control mode: cm2
x = f1 (office, h2300, 900i)
= f2 (office, h2300, 900i)
e6 : dist(hx, yi, hxdw , ydw i) < 100
control mode: cm6
x = f1 (doorway, h2300, 900i)
= f2 (doorway, h2300, 900i)

Figure 10: figure shows hybrid automaton interpretation navigation plan
Figure 2. possible control modes continuous flow equations depicted
nodes mode transitions edges. edges labeled jump conditions:
entering doorway (e1 , e6 ), leaving doorway (e3 ), reaching first waypoint (e2 , e4 ),
reaching second waypoint (e5 ).

velocity robot orientation. settings implied flow condition
respective successor states.
one issue yet addressed conceptualization: uncertainty.
model uncertainty respect continuous effects achievement jump conditions
using multiple alternative successor modes varying flows jump conditions. associate
probability occurrence mode transition. way can, example, represent
rotational inaccuracies navigation actions typical mobile robots.
816

fiP ROBABILISTIC H YBRID ACTION ODELS

3.2 Representation Hybrid System Model
Let us formalize hybrid system conceptualization using logical notation. so,
going use following predicates describe evolution system states: jump~ f lows),
~
Condition(cm,e,c), jumpSuccessor(e,cm,probRange), jumpRelation(cm, vals,
probRange(e,max). jumpCondition(cm,e,c) represents mode cm left along edge e condition
c becomes true. jumpSuccessor(e,cm,probRange) defines non-deterministic successor states
cm probability ProbRange entered system makes transition
~ f lows)
~
along e. jumpRelation(cm, vals,
defines initial values state variables flow
conditions upon entering state cm. jump e causes automaton transit probabilistically
successor mode.
possible successor define probability range probRange. reasons explained represent probability ranges non-overlapping, relative
sizes proportional probability represent (the sum ranges 1)
boundaries form 2in , n integers. predicate probRange(e,2 n ) defines
sum ranges. possible transition probability range [ 2in , 2jn ] represented jumpSuc~ f lows)
~
cessor(e,cm,[i,j]). predicate jumpRelation(cm, vals,
means upon entering control
~ f lows.
~
mode cm system variables flows initialized specified vals
Using predicates introduced above, state probabilistic hybrid automaton (Figure 10)
interpretation navigation plan using following facts.
jumpRelation(cm0 ,h2400,600i, hf1 (office, h2300, 800i), f2 (office, h2300, 800i)i)
jumpCondition(cm0 ,e1 ,dist(hx, yi, hxdw , ydw i) < 100)
jumpCondition(cm0 ,e2 ,x = 2300 = 800)
jumpSuccessor(e1 ,cm1 ,[1,1])
probRange(e1 ,1)
jumpRelation(cm1 ,h i,hf1 (doorway, h2300, 800i), f2 (doorway, h2300, 800i)i)
jumpRelation(cm2 ,h i,hf1 (office, h2300, 900i), f2 (office, h2300, 900i)i)
...
robot starts position h2400, 600i control mode cm 0 robot leaves
lower office right. control mode robot moves hf 1 (office, h2300, 800i),
f2 (office, h2300, 800i)i. navigation system leaves control mode cm 0 coming close
door (dist(hx, yi, hxdw , ydw i) < 100) performing transition e1 . system performs
transition e1 control flow changes low-level navigation plan switches
navigation mode doorway. example, transition deterministic.
account uncertainty control make transitions probabilistically. Thus
substitute control mode cm1 multiple control modes, say cm01 cm001 control
flows modes sampled probability distribution. state example
4
0
probability 75% ( 12
16 ) system transits control mode cm1 25% ( 16 )
mode cm001 defining effects transition e1 follows:
jumpCondition(cm0 ,e1 ,dist(hx, yi, hxdw , ydw i) < 100)
jumpSuccessor(e1 ,cm01 ,[1,12])
jumpSuccessor(e1 ,cm001 ,),[13,16])
probRange(e1 ,16)
817

fiB EETZ & G ROSSKREUTZ

represent state hybrid automaton use predicates mode(cm) startTime(cm,t)
~
represent current control mode cm cm started time t. use flow( flow)
~
valuesAt(ti ,vali ) assert flows values system variables given time points. Further,
values system variables inferred arbitrary time points interpolation
~ ). done using predicate
basis current flow last instances valuesAt(ti ,val
stateVarsVals:
~ valuesAt(t0 ,vals
~ 0 ) now(t)
stateVarVals(vals)
~ = vals
~ 0 + (t t0 )flow
~ vals
~
f low(flow)
now(t) specifies current time. Note, conceptualization represent discrete state changes explicitly states within mode using modes initial state flow.
particular state within mode derived demand using predicate stateVarVals. Interferences different movements robot issued different control threads modeled
modes flow.
Figure 11 depicts execution scenario, possible evolution hybrid system representing
execution robot controller might go. execution scenario consistent set jumps
values hybrid model time. extract event histories
used simulate plan execution look flaws.
execution scenario consists timeline, linear sequence events results. Timelines represent effects plan execution terms time instants, occasions, co-occurring
events. implies several events occur time instant one them,
primary one, changes state world. Time instants points time world
changes due action robot exogenous event. time instant date
holds time global clock time instant occurred. occasion stretch
time world state P holds specified proposition, describes P,
time interval proposition true.
deal kinds uncertainty representing model using McDermotts rule
language probabilistic, totally-ordered temporal projection (McDermott, 1994). Using language represent Poisson distributed exogenous events, probability distributions
current world state, probabilistic sensor action models way consistent
model presented far.
3.3 Discussion Model
Let us discuss hybrid system model addresses issues raised Section 2.3.
two inference tasks concerning issue continuous change caused concurrent reactive
plans supported model. first one inferring state particular time instant.
example, projection mechanism predicts occurrence exogenous event,
object falling robots gripper, projection mechanism infer robot
time instant assert position object falling down. done using
initial state flow condition active control mode. second important inference
task prediction control mode jumps caused continuous effects low-level plans,
robot entering hallway. inferred using jump conditions active
control mode addition initial state flow condition.
818

fiP ROBABILISTIC H YBRID ACTION ODELS

mode(cm0)

mode(cm1)

initialValues(cm0,<2400,600>)

initialValues(cm1,
startTime(cm1,5)

startTime(cm0,0)

flow(<f1(off...

flow(<f1(office,<2300,900>),f2(office,<2300,900>)>)
valuesAt(t3,<2360,850>)

t1

clock-tick(t1)

t2

t3

t4

t5

t6

clock-tick(t2)

clock-tick(t3)

clock-tick(t4)

clock-tick(t5)

clock-tick(t6)

jump(e1)

Figure 11: Part timeline represents projected execution scenario low-level navigation plan. Time instants depicted circles, events rectangles, occasions
rectangles round corners.

second issue raised Section 2.3 prediction robots reactions
instantaneous events, dropping object. Typically, reactive plan carrying object
contains sub-plans ask robot stop pick object soon sensed force
gripper drops. kinds reactions handled checking active jump conditions
immediately instantaneous event occurred.
third issue projecting concurrent reactive plans interference simultaneous
continuous effects. model, interference modelled describing effects control mode
jumps flow condition subsequent control mode. programmer must specify rules
describing physics domain specifying flow condition next mode. Thus,
sub-plan moving robots arm started robot moving, rule describing
effects corresponding control mode jump asserts flow condition specifying
world coordinates gripper determined gripper position mode jump
transposition two motions successor mode.
last issue uncertainty. One aspect uncertainty model supports
inaccuracies physical behavior robot. modelled specifying probability distributions successor modes control mode jump occurs. aspects uncertainty
including probabilistic sensor models, uncertainty instantaneous physical effects, uncertainty
state world, Poisson distributed exogenous events handled rule language describe next section. particular, give examples exogenous events
passive sensors Section 5.3 detailed probabilistic model complex sensing action
Section 5.4.
819

fiB EETZ & G ROSSKREUTZ

approach explicitly reason belief state. assume belief state
computed probabilistic state estimators (Thrun et al., 2000). state estimators return
likely state also infer additional properties belief state ambiguity
expected accuracy global maximum. plan-based controller interrupts delivery tours
soon position estimate ambiguous inaccurate. Details mechanism well
motivations found work Beetz, Burgard, Fox, Cremers (1998).

4. Probabilistic, Totally-Ordered Temporal Projection
last section seen hybrid systems execution scenarios represented.
section, see predict execution scenarios specification hybrid system. purpose use McDermotts rule language probabilistic, totally-ordered
temporal projection (McDermott, 1994). rule language expressiveness needed
purpose: specify probabilities event effects depending respective situation,
Poisson distributed events, probability distributions delays subsequent plan
generated events. Uncertainty current state world specified form
probabilistic effect rules distinct start event.
rule language excellent basis formalizing model introduced last section.
set rules satisfies certain conditions implies unique distribution dated event sequences
satisfies probabilistic conditions individual rules (see Definition 2 Section 4.1).
Thus give probabilistic formalizations behavior within control modes mode jumps
McDermotts rule language define unique probability distribution state trajectories hybrid automaton satisfies probabilistic constraints. Moreover, McDermott
developed provably correct projection algorithm samples dated event sequences
unique distribution.
remainder section proceed follows. start presenting McDermotts
rule language probabilistic, totally-ordered temporal projection summarize main properties language. represent hybrid system model using rule language.
Based representation can, loosely speaking, show applying McDermotts projection algorithm representation hybrid system, algorithm returns dated event sequences drawn unique distribution implied rules arbitrarily high probability.
Note, obtain results use discretized model time clock tick events
spaced arbitrarily close together resulting higher accuracy projection algorithm.
makes use representation infeasible practice. Therefore, eliminate need
clock tick events Section 5 making use McDermotts persist effects.
4.1 McDermotts Rule Language Probabilistic, Totally-ordered Temporal Projection
different kinds rules provided language projection rules, effect rules, exogenous event rules. Projection rules specify sequence dated events caused low-level plans,
effect rules specify causal models sensing processes actions, exogenous event rules
used specify occurrence events control robot. describe
kinds rules below.
Projection rules used specify sequence events caused interpretation
low-level plan. Projection rules form
820

fiP ROBABILISTIC H YBRID ACTION ODELS

project rule name(args)
cond
delay 1 occurs ev1

...
delay n occurs evn

specify low-level plan name(args) executed condition cond holds
low-level plan generates events ev1 , ..., evn relative delays 1 , ..., n , respectively.
Thus, projection rules generate sequence dated events.
Uncertain models represented sampling probability distribution
durations specifying conditions satisfied certain probability.
Effect rules used specify conditional probabilistic effects events. form
ep rule name
cond
probability event ev causes effs

specify whenever event ev occurs cond holds, probability create
clip states specified effs. effects ep rule rules form A, causing
occasion hold, clip A, causing cease hold, persist A, causing hold
time units.
Exogenous event rules used specify conditional occurrence exogenous events.
rule
pe rule name
cond avg spacing occurs ev

specifies interval cond true, exogenous events ev generated
Poisson-distributed average spacing time units.
proving properties model must first introduce McDermotts semantics possible worlds. so, define key notions underlying conceptualization Definition 1.
evolution world described sequence dated instantaneous events occurrence e@t specifies event e occurs time instant t. addition, function mapping
time instants world states. precisely notions defined follows (see McDermott,
1994).
Definition 1 world state function propositions {T,F,} extended boolean
formulas usual way. occurrence e@t pair c = (e, t), e event
time (t <+ ). occurrence sequence finite sequence occurrences, ordered date.
duration date last occurrence. world duration L, L < + , complete
history duration L, is, pair (C, H), C occurrence sequence duration
L, H function [0, L] world states. H(0) propositions mapped F,
t1 < t2 H(t1) 6= H(t2) must occurrence e@t t1tt2.
821

fiB EETZ & G ROSSKREUTZ

use following abbreviations: (A t)(W ), execution scenario W, mean
> 0 t0 : < t0 < + H(t0 )(A) = . (A t)(W ),
W similarly defined, upper bound t0 includes t.
described represent change world, state conditions
worlds duration consistent given set event effects exogenous event
rules. so, state constraints rules, local probabilistic models, impose
state evolution. definition take plan generated events typically specified
project rules, given.
Definition 2 set rules defined above, Exog occurrence sequence 2 , P set
propositions, L real number duration(Exog), L-Model Exog
pair (U, ), U set worlds duration L (C, H) U : Exog C,
probability measure U obeys following restrictions: (At), (At) e@t
considered random variables. annihilation conjunction A, conjunction
negations conjuncts A.
1. Initial blank state: P : (A 0) = 0.
2. Event-effect rules: contains rule instance
ep rule name probability r event e causes B,

every date t, require that, nonempty conjunctions C literals B:
(Ct|e@t Bt) = r.
3. Event-effect rules events dont occur: Suppose B atomic formula, let
R = {Ri } set instances ep rules whose consequents contain B B.
ep rule Ri = Ai probability pi event Ei causes Ci , let Di = Ai Ci ,
(Bt|Bt N ) = 1 (Bt|Bt N ) = 0 N = (E1 @t D1 )
(E2 @t D2 ) ....
4. Event-occurrence rules: every time point occurrence date
Exog every event E, exactly one instance
pe rule name avg spacing occurs E

(at) > 0 require
limdt0

(occ. class E t+dt|At)
= 1/d
dt

limdt0

(occ. class E t+dt|At)
=0
dt

2. Exog occurrence sequence, represents events generated interpretation robots plan
modeled using projection rules.

822

fiP ROBABILISTIC H YBRID ACTION ODELS

exists rule, require
limdt0

(occ. class E t+dt)
=0
dt

5. Conditional independence: one previous clauses defines conditional probability
(|), mentions times t, conditionally independent, given ,
random variables mentioning times t. is, arbitrary mentioning times
t, (|) = (| ).
McDermott (1994) shows definition yields unique probability distribution . also
gives proof projection algorithm draws random execution scenarios sampled
unique probability distribution implied given probabilistic models.
4.2 Probabilistic Temporal Rules PHAMs
order predict evolution hybrid system, specify rules McDermotts rule language
that, given state system time t, predict successor state t. predict
successor state, must distinguish three cases: first, control mode transition occurs; second,
exogenous event occurs; third, system changes according flow current mode.
start rules predicting control mode jumps. ensure mode transitions
generated specified probability distributions successor modes, use
predicate randomlySampledSuccessorMode(e,cm) realize random number generator using
McDermotts rule language.
randomlySampledSuccessorMode(e,cm)
probRange(e, max) randomN umber(n, max)
jumpSuccessor(e, cm, range) n range
order sample values probability distributions axiomatize random number
generator asserts instances predicate randomNumber(n,max) used (see Beetz &
Grosskreutz, 2000). formalizing randomize event. McDermott (1994) discusses
usefulness of, difficulties in, realizing nondeterministic exclusive outcomes. Therefore
implementation escapes Lisp uses function returns random element.
Lemma 1 time point randomNumber exactly one extension randomNumber(r,max)
r unbiased random 0 max.
Proof: Let max largest probRange extension randomBit(i,value) i-th random bit.
start event causes initial state timeline causes randomBit(i,0) 0 log max .
Thereafter, randomize event used sample value:
ep rule RANDOMIZE
randomBit(i,val) negation(val,neg)
probability 0.5
event randomize
causes randomBit(i,neg) clip randomBit(i,val)

823

fiB EETZ & G ROSSKREUTZ

Rule ODE -J UMP causes control mode transition soon jump condition cond becomes
true. rule says interval cm current control mode
jump condition cond leaving cm following edge edge jump along edge occur
average delay time units.
pe rule ODE -J UMP
mode(cm) jumpCondition(cm,cond,edge)

~ satisfies(vals,cond)
stateVarsVal(vals)
average spacing time units
occurs jump(edge)
Rule J UMP -E FFECTS specifies effects jump event control mode, system variables, flow. cm control mode randomly sampled probability distribution
successor nodes jumps along edge jump along edge following effects.
values state variables flow condition previous control mode cm old retracted
ones new control mode cm asserted.
ep rule J UMP -E FFECTS
randomlySampledSuccessorMode(edge,cm)

~ flowCond(cm,flow)
~ now(t)
initialValues(cm,val)
mode(cmold ) flow(flowold ) valuesAt(told ,valold )
probability 1.0
event jump(edge)
~
~ valuesAt(transTime,val)
causes mode(cm) flow(flow)
clip mode(cmold ) clip flow(flowold ) clip valuesAt(told ,valold )
Time advanced using clock-tick events. every C LOCK -T ICK (?t ) event predicate
updated clipping previous time asserting new one. Note, time differs
dtclock time units actual time.
ep rule C LOCK -RULE
now(to )
probability 1.0
event clock-tick(t)
causes now(t) clip now(to )

Exogenous events modeled using rules following structure. navigation
~ state variables satisfy condition
process control mode cm values vals
occurrence exogenous event ev, event ev occurs average spacing time
units.
pe rule C AUSE -E XO -E VENT
mode(cm) exoEventCond(cm,cond,ev)

~ satisfies(vals,cond)
stateVarsVal(vals)
average spacing time units
occurs exoEvent(ev)
824

fiP ROBABILISTIC H YBRID ACTION ODELS

effects exogenous event rules specified rules following form. exoge~
nous event exoEvent(ev) effect specification exoEffect(ev, val))
causes values state
~
~
variables change valo val.
ep rule E XO -E VENT-E FFECT

~ valuesAt(to ,valo ) now(t)
exoEffect(ev,val))
probability 1.0
event exoEvent(ev)
~ clip valuesAt(to ,val
~ o)
causes valuesAt(t,val)
4.3 Properties PHAMs
seen last section PHAM consists rules set facts
constitute hybrid automata representation given CRP. section investigate whether
PHAM make right predictions.
essentially three properties predicted execution scenarios want ensure.
First, predicted control mode sequences consistent specified hybrid system. Second,
mode jumps predicted according specified probability distribution successor modes.
Third, two successive events, behavior predicted according flow respective control mode.
McDermotts formalism allow modeling instantaneous state transitions
show control mode sequences execution scenarios probably approximately accurate.
view, low price expressiveness gain availability Poisson
distributed exogenous events.
subsequent lemma 2 states control mode jumps predicted arbitrary accuracy
arbitrarily high probability decreasing time successive clock ticks.
Lemma 2 probability delay , exists (average delay occurrence
event triggering condition become true) dt clock (time two subsequent
clock ticks) whenever jump condition becomes satisfied, probability 1
jump event occur within time units.

Proof: Let time jump condition fulfilled. /(2 log(1/)) dt clock
/2 /2 time units antecedent rule ODE -J UMP fulfilled. probability event class jump(cm0 ) occurs t+/2 t+ e/(2 ) = elog(1/) = ,
probability 1 event occur time units t.

implies always non-zero chance control mode sequences predicted
incorrectly. happens two jump conditions become true jump triggered
later condition occurred one. However, probability incorrect predictions
made arbitrarily small choice dtclock .
basic framework hybrid systems take possibility exogenous events
account thereby allows proving strong system properties reachability goal
states arbitrary initial conditions safety conditions system behavior (Alur et al.,
825

fiB EETZ & G ROSSKREUTZ

1997, 1996). prediction robot behavior dynamic environments assumptions,
however, unrealistic. Therefore, weaker property, namely correspondence
predicted behavior flows specified hybrid system immediate
subsequent events.
Lemma 3 Let W execution scenario, e1 @t1 e2 @t2 two immediate subsequent events
type jump exoEvent, cm control mode 1 W . Then, every occurrence
~ )) unique. Further, vals
~ = vals
~ 1 + (t - t1 ) *
e@t t1 < t2 W(t)(stateVarVals(vals
~
flow(cm), vals1 values state variables t1 .

Proof: two classes rules affect value valuesAt flow: rule JUMP E FFECTS, rule E XO -E VENT-E FFECT. rules always clip set exactly one extension
predicates, thus together fact initial event asserts exactly one predicate,
determined value unique.
interval t1 t2 extension stateVarVals evolves according flow
condition mode cm due fact flow changed rule E XO -E VENT-E FFECT. Thus
remains initially set rule JUMP -E FFECTS, asserts exactly flow corresponding
cm. proposition follows assumption correct axiomatization addition
scalar-vector multiplication.

Another important property representation jumps predicted according
probability distributions specified hybrid automaton.
Lemma 4 Whenever jump along edge e occurs, successor state chosen according
probability distribution implied probRange jumpSuccessor.

Proof: follows properties randomize event Rule Jump-Effects.

Using lemmata state show central properties PHAMs: (1) predicted
control mode transitions correspond specified hybrid automaton; (2)
holds continuous predicted behavior exogenous events; (3) Exogenous events
generated according probabilities continuous domain (this shown McDermott,
1994).
Theorem 1 Every sequence mode(cm) occasions follows branch (cm ), ..., (cmj ) hybrid automaton.

Proof: occasion mode(cm) must asserted rule J UMP -E FFECTS. Therefore must
jump(e) event. Consequently, must jumpCondition previous
control mode cm.

826

fiP ROBABILISTIC H YBRID ACTION ODELS

jump events modeled Poisson distributed events always chance
predicting control mode sequences valid respect original hybrid system.
next bound probability predicting mode sequences choosing parameterization jump event clock tick event rules appropriately.
Theorem 2 every probability exists average delay mode jump event
delay dtclock satisfaction jump conditions realized probability
~ stateVarVals occasions two immediate subsequent exogenous events
1 vals
follow state trajectory hybrid automaton.

Proof: proof based property jumps occur correct order arbitrarily
high probability. particular, choose function minimal delay jump
conditions becoming true. Then, jumps successor modes occur arbitrarily high probability (Lemma 2). Finally, according Lemma 3 trajectory stateVarVals transitions
accurate.


5. Implementation PHAMs
shown PHAMs define probability distributions possible execution scenarios
respect given belief state. problem using PHAMs obvious. Nontrivial CRPs
controlling robots reliably require hundreds lines code. typically several control
processes active, many dormant, waiting conditions trigger execution.
hybrid automata CRPs huge, branching factors mode transitions immense.
Let alone distribution execution scenarios might generate. accurate computation
probability distribution prohibitively expensive terms computational resources.
second source inefficiency realization PHAMs. PHAMs used
clock tick rules, Poisson distributed events, generate clock ticks average spacing
time units. done so, order formalize operation CRPs single concise
framework. problem approach order predict control mode jumps accurately
must choose small. This, however, increases number clock tick events
drastically makes approach infeasible simple scenarios.
order draw sample execution scenarios distribution implied causal model
initial state description use extension XFRM projector (McDermott, 1992b)
employs RPL interpreter (McDermott, 1991) together McDermotts algorithm probabilistic temporal projection (McDermott, 1994). projector takes input CRP, rules
generating exogenous events, set probabilistic rules describing effects events actions,
(probabilistic) initial state description. predict effects low-level plans projector samples effects probabilistic causal models low-level plans asserts
propositions timeline. Similarly, plan activates sensor, projector makes use
model sensor state world described timeline predict sensor
reading.
section investigate make effective informative predictions basis
PHAMs performed speed sufficient prediction-based online plan revision.
achieve effectiveness use two means. First, realize weaker inference mechanisms
827

fiB EETZ & G ROSSKREUTZ

based sampling execution scenarios distribution implied causal models
initial state description. Second, replace clock tick event mechanism different
mechanism infers occurrence control mode jumps uses persist effect generate
respective delay. detail two mechanisms remainder section.
5.1 Projection Adaptive Causal Models
Let us first turn issue eliminating inefficiencies caused clock tick mechanism.
replacing clock tick rules mechanism tailoring causal models fly
using persist effects probabilistic rule language.
efficiency reasons process projecting continuous process p divided two
phases. first phase estimates schedule endogenous events caused p considering possible effects p processes effects processes p.
schedule transformed context-specific causal model tailored plan
projected. second phase projects plan p using model endogenous events constructed
first phase. phase takes account interferences concurrent events revises causal model situations arise assumptions precomputed schedule
violated.
projection module uses model dynamic system specifies continuous
control process state variables changes state variable fluents measure
state variable. example, consider low-level navigation plans steadily change robots
position (that variables x y). estimated position robot stored fluents
robot-x robot-y:
changes(low-level-navigation-plan, x)
changes(low-level-navigation-plan, y)
measures(robot-x, x)
measures(robot-y, y)
Extracting relevant conditions. projector starts projecting low-level navigation plan
computes set pending conditions depend robot-x robot-y, fluents
measure state variables dynamic system changed low-level navigation
plan. conditions implemented fluent networks.
Fluent networks digital circuits components circuit fluents. Figure 12
shows fluent network output fluent true, robot room A-120.
inputs circuit fluents robot-x robot-y circuit updated whenever robot-x
robot-y change.
reactive plans set fluent networks compute conditions
plan waiting determined automatically using (P ROLOG-like) relational queries:
setof ?fl-net ( fluent(?fl) status(?fl,pending)

changes(low-level-nav-plan, ?state-var)
measures(?state-var-fl, ?state-var)
depends-on(?fl, ?state-var-fl)
fluent-network(?fl, ?fl-net) )
?pending-fl-nets
828

fiP ROBABILISTIC H YBRID ACTION ODELS

1265.0
robot-x

<
>


860.0
817.0
robot-y

IN-A-120?

<

Figure 12: Fluent network room A-120. robot believes room A-120
estimated x-coordinate 860 1265 y-coordinate smaller
817, hallway begins.

query determines ?pending-fl-nets, set fluent networks ?fl-net ?fl-net network output fluent ?fl. ?fl causes plan thread pend depends fluent measuring
state variable ?state-var changed low-level navigation plan. extraction conditions done automatically. automatic extraction requires conditions particular
form effects low-level plans state variables sensing state variables
represented explicitly.
predict fluent IN-A-120? become true false, compute region
state space corresponds fluent compute intersections robots state
trajectories region.
Endogenous event schedules. class continuous processes provide endogenous event scheduler takes initial conditions parameterization process,
fluent networks might triggered computes endogenous event schedule.
endogenous event scheduler low-level navigation plans described next section. Given
kind process (e.g., low-level navigation plan), process parameters (e.g., destination
robot), pending fluent networks, scheduler returns sequence composite endogenous events. Composite events represented triples form (t, hsv 1 , ..., svn i, {ev1 , ...,
evm }). delay ith i+1st event schedule, hsv 1 , ..., svn values
state variables, {ev1 , ..., evm } atomic events take place.
state plan waiting, becomes true time instance t, passivesensor-update event triggered. passive-sensor-update event model takes set fluents
parameters, retrieves values state variables measured fluents, applies
sensor model values, sets fluents accordingly.
causal model low-level navigation plans. Projecting initiation execution
navigation plan causes two events: start event hypothetical completion event
infinite number time units. shown following projection rule.
829

fiB EETZ & G ROSSKREUTZ

project rule LOW- LEVEL - NAVIGATION - PLAN
true
delay 0
occurs begin(low-level-nav-plan(?dest-descr, ?id, ?fluent)
delay
occurs end(low-level-nav-plan(?dest-descr, ?id, ?fluent)

effect rule start event low-level navigation plan computes endogenous event
schedule asserts next endogenous navigation event timeline.
ep rule ENDOGENOUS - EVENTS
endogenous-event-schedule(low-level-nav-plan(?dest-descr, ?schedule))
probability 1.0
event begin(low-level-nav-plan(?dest-descr, ?id, ?fluent))
causes predicted-events(?id, ?schedule)

running(robot-goto(?descr, ?id))
next-nav-event(?id))
occasion next-nav-event(?id) triggers next endogenous event begin(follow-path(?here
h?x,?yi) ?dt ?id)). remaining two conditions determine parameters follow-path event:
next scheduled event robots position.
pe rule C AUSE -E XO -E VENT
next-nav-event(?id)

predicted-events(?id, ((?dt h?x,?yi ?evs) !?remaining-evs)
robot-loc(?here)
average spacing 0.0001
occurs begin(follow-path(?here, h?x,?yi, ?dt, ?id))
effect rule begin(follow-path (...)) event specifies among things next
endogenous event occur ?dt time units (persist ?dt sleeping(?id)).
ep rule FOLLOW- PATH
robot-loc(?coords)
probability 1.0
event begin(follow-path(?from, ?to, ?dt, ?id))
causes running(follow-path(?from, ?to, ?dt, ?id))
clip robot-loc(?coords)
clip next-nav-event(?id)
persist ?dt sleeping(?id)

running follow path event finished sleeping end (follow-path (...)) event occurs.
pe rule ERMINATE -F OLLOW-PATH
sleeping(?id)

running(follow-path(?from, ?to, ?time, ?id))
average spacing 0.0001
occurs end(follow-path(?from, ?to, ?time, ?id))
830

fiP ROBABILISTIC H YBRID ACTION ODELS

model low-level navigation plan presented far suffices long nothing important
happens carrying plan. However, suppose exogenous event causes
object slip robots hand projected time instant robot motion.
predict new location object projector predicts location l robot time
using control flow asserts timeline.
Qualitative changes behavior robot caused adaptations travel mode
described ep -rules. following ep -rule describes effects event
nav-event(set-travel-mode(?n)), represents low-level navigation plan resetting travel
mode:
ep rule SET- DOORWAY- MODE
travel-mode(?m)
probability 1.0
event nav-event(set-travel-mode(doorway))
causes clip travel-mode(?m)
clip obstacle-avoidance-with(sonar)

travel-mode(doorway)
rule specifies time instant event nav-event(set-travel-mode(?n))
occurs state travel-mode(?m) holds ?m, states travel-mode(?m) obstacleavoidance-with(sonar) (with probability 1.0) persist event occurred, i.e.,
clipped event. event causes state travel-mode(doorway) hold
adapted next time.
rules listed hand-coded plan-specific. investigation whether plans
coded rule specification automated agenda future research.
5.2 Endogenous Event Scheduler
shown events projected given endogenous event schedule,
shown schedule constructed. Thus, section describes endogenous event
scheduler low-level navigation plans. scheduler predicts effects low-level navigation plan state variables x y. endogenous event scheduler assumes robot
following straight path locations 1 5. pointed earlier, two
kinds events need predicted: ones causing qualitative physical change ones
causing trigger conditions plan waiting for.
qualitative events caused low-level navigation plan pictured Figure 13
ones occur robot arrives locations 1, 2, 3, 4, 5 robot either
changes travel mode arrives destination. time instants occurrence
set-travel-mode-event predicted.
scheduler triggering events works two phases: (1) transforms fluent network
condition able predict (2) applies algorithm computing
events occur. conditions caused low-level navigation plan represented
regions environment condition true robot within
region. elementary conditions numeric constraints robots position distance
robot given target point. scheduler assumes robot-x robot-y fluents
831

fiB EETZ & G ROSSKREUTZ

networks change value execution plan. complex networks
constructed conjunctions disjunctions elementary conditions.

6
A111

X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X 5ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZX
ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZX
ZXYZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZX
ZXYZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X 4ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZX
ZXYZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X 3ZY
X ZY
X ZX
ZXYZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X ZY
X 2 ZY
X ZY
X ZY
X ZX
ZXYZY
1

A117

Figure 13: Initially predicted endogenous events.
next step endogenous event scheduler overlays straight line path intermediate goal points topological navigation path (see Figure 7) regions computed
previous step. computes schedule endogenous events following navigation path collecting intersections regions (see Figure 13). result
scheduling step sequence triples form (ti , hxi , yi i, {ev1 , ..., evn }).
Rescheduling endogenous events. One problem temporal projector deal
wait step might executed low-level navigation plan projected. example,
robot enters hallway, policy looks opening angles doors passing
triggered. Therefore, causal model computed endogenous event scheduler
longer sufficient. fails predict passing door events.
problems handled modifying endogenous event schedule: whenever robot
starts waiting condition function robots position, interrupts projection
low-level navigation plan, adapts causal model low-level navigation plan, continues projection. case entering hallway, new endogenous event schedule
contains endogenous events passing doorways computed. updated schedule endogenous events pictured Figure 14.
5.3 Projecting Exogenous Events, Passive Sensors Obstacle Avoidance
One type exogenous event event additional information time
occurrence, event Dieter back lunch around 12:25. kinds
events represented pe rule together ep rule. ep rule specifies
832

fiP ROBABILISTIC H YBRID ACTION ODELS

c dY
c dc
dY
c dc
dcYdY
c dc
dcYdY
c dc
dcYdY
c dc
dcYdY

[Y\Y
[ \Y
[ \Y
[ \Y
[ \Y
[ \[
[Y\Y
[ \Y
[ \Y
[ \Y
[ \Y
[ \[
[Y\Y
[ \Y
[ \Y
[ \Y
[ \Y
[ \[
[Y\Y
[ \Y
[ \Y
[ \Y
[ \Y
[ \[
[Y\Y
[ \Y
[ \Y
[ \Y
[ \Y
[ \[
[Y\Y
[ \Y
[ \Y
[ 8 \Y
[ \Y
[ \[
[Y\Y
[ \Y
[ \Y
[ \Y
[ \Y
[ \[
[Y\Y
[A111
[ \Y
[ \Y
[ \Y
[ \[
\Y
[Y[Y
\ [Y
\ [Y
\ [Y
\ [Y
\ [\
[Y\Y
[ \Y
[ 7\Y
[ \Y
[ \Y
[ \[
[Y\Y
[ \Y
[
[
[ ba \Y
[ \[
\Y
\Y
6

ba

5bY
ba 4


ba


ba


_ `Y
_ `Y
_ `_
`Y
_ `Y
_ `_
`_Y`Y
_ `Y
_ `_
`_Y`Y
_ `Y
_ `_
`_Y`Y
_ `Y
_ `_
`_Y`Y

] ^Y
] ^Y
] ^]
^Y
] ^Y
] ^]
^]Y^Y
] ^Y
] ^]
^]Y^Y
3 ^Y
] ^Y
] ^Y
] ^]
] ^Y
] ^Y
] ^]
^Y

e fY
e fY
e fe
fY
e fY
e fe
feYfY
e fY
e fe
2 feYfY
e fY
e fY
e 1fe
fY
e fY
e fY
e fe
fY
1

A117

Figure 14: Modified endogenous event schedule.

start event causes state before-dieters-door-opens() hold persist ?time time units.
event dieters-door-opens() triggered soon before-the-door-opens() longer holds.
ep rule BACK - -L UNCH
about(?time, 12:25) difference(?time, *now*, ?wait-for))
probability 1.0
event start
causes persist ?wait-for before-the-door-opens
pe rule OOR -O PENS
thnot before-the-door-opens
average spacing 0.0001
occurs dieters-door-is-opened

order predict occurrence exogenous events, plan projector following.
first computes time robot cause next event e next . Let us assume
event occurs time units last event elast c strongest condition holds
elast enext .3 following algorithm predicts occurrence next exogenous
event accurately. First, every pe rule ri whose enabling condition satisfied c randomly
decide whether ei occur elast enext based average temporal spacing
ei events situations c holds. ei predicted occur, select occurrence time
randomly selecting time instant time interval e last enext (the exogenous events
3. cases enabling conditions exogenous events caused continuous effects e last
enext handled analogously achievement triggering conditions.

833

fiB EETZ & G ROSSKREUTZ

Poisson distributed). Select exogenous event predicted occur earliest, assert
timeline, continue projection occurrence event.
last two components need describe passive sensors, steadily updated
change configuration robot behavior collision avoidance routines.
Readings passive sensors need projected measured state variables change
significantly state variables traverse values satisfy conditions robot
waiting. situations update-passive-sensors event.
Collision avoidance modeled except situations robot told objects
moved around. case endogenous event scheduler adds region corresponding
object. region blocks way destination robot cannot move around
region possible-bump-event generated. effect rule possible bump event
specifies that, robot activated sensors detect object, low-level navigation
plan fails failure description path blocked. Otherwise bump event generated.
example, since sonar sensors sensors placed table height, collision avoidance
module avoid collision table sonar sensors active. Thus, predict
bump, projector determine long sonar sensors switched
possible bump event occurs.
5.4 Models Complex Sensing Actions
understand types uncertainty modeled causal models interact
plan interpretation let us look complex sensing action realized low-level
plan look-for. sub-plan called visual description (?pl) objects supposed look
for.
Typically, order model low-level plan need set projection rules probabilistically describe possible event sequences outcomes activating behavior module.
situation exactly one projection rule applied (although decision one might
probabilistic).
One projection rules look-for listed below. model consists three parts.
first part (line 1 7) specifies condition rule predicts behavior
look-for correctly. second part (lines 8 11) lists events look-for cause
rule applicable. Finally, last line specifies low-level plan signals completion
interpretation. case, low-level plan succeeds returns list object descriptions
(?desigs) value.
condition projection rule determines robot (1), probabilistically decides
whether look-for normal based camera used specifics location (2),
infers objects located (3). inference performed based robots probabilistic belief state world predicted exogenous events. condition
uses sensor model camera order decide probabilistically robot perceives
object. object perceived matching perceptual description ?pl local
designator ?desig created collected variable desigs. last condition (7) estimates
time ?dt look-for behavior completes. Upon completion look-for behavior
projected interpretation process sends success signal return value ?desigs argument. projected behavior consists three events: two change world begin(look-for(?pl,
?cam)) end(look-for(?pl, ?cam)), occurs ?dt later. third event changes compu834

fiP ROBABILISTIC H YBRID ACTION ODELS

(1)
(2)
(3)
(4)
(5)
(6)

(7)
(8)
(9)
(10)
(11)
(12)

project rule look-for(?pl, ?cam)
( loc(robot, h?x,?yi)

normal-look-for-behavior(?cam, ?loc)
setof ?ob loc(?ob, h?x,?yi) ?obs-here
sensor-model(?cam, ?sensor-model)
features(?pl,?features)
setof ?desig
( member(?ob,?obs-here)
obj-seen(?ob, ?sensor-model)
perceived-properties(?ob, ?features, ?sensor-model, ?pl)
local-desig(?desig,?ob,?pl,?x,?y))
?desigs
look-time(h?x,?yi, ?features, ?dt))
delay 0 occurs mode transition begin(look-for(?pl, ?cam))
delay ?dt occurs mode transition end(look-for(?pl, ?cam))
delay 0 occurs trigger fluent visual-inputs-fluent(?cam)
delay 0 occurs set fluent obs-pos-fluent ?seen)
delay 0 occurs succeed ?desigs
Figure 15: projection rule describing behavior module look-for.

tational state structured reactive controller passing ?dt time units. event pulses
fluent visual-inputs-fluent(?cam) sets fluent obs-pos-fluent(?cam).
Besides asserting events take place execution plan specify
events change world. done using effect rules. One shown
Figure! 16. rule specifies time instant event end(look-for(?pl, ?cam))
occurs state visual-track(?desig, ?ob) holds ?desig ?ob, states visualtrack(?desig, ?ob) (with probability 1.0) persist event occurred, i.e.,
clipped event.
ep rule VISUAL - TRACKING
visual-track(?desig, ?ob)
probability 0.9
event end(look-for(?pl, ?cam))
causes clip visual-track(?desig, ?ob))

Figure 16: ep rule describing effects event end(look-for(?pl, ?cam)).

5.5 Probabilistic Sampling-based Projection
far looked issue efficiently predicting individual execution scenario.
investigate issue drawing inferences useful planning based sampled
execution scenarios.
835

fiB EETZ & G ROSSKREUTZ

Recently, probabilistic sampling-based inference methods proposed infer information complex distributions quickly bounded risk (Fox, Burgard, Dellaert, & Thrun,
1999; Thrun, 2000). discuss use sampling-based projection anticipating likely flaws high probability.
Advantages applying probabilistic sampling-based projection prediction effects
CRPs works independently branching factor modes hybrid automaton
constructs small part complete PHAM.
kinds prediction-based inferences drawn samples projected execution scenarios? inference found valuable online revisions robot plans
is: projected execution scenarios drawn distribution satisfy given property p
probability greater ? robot action planner use type inference decide whether
revise plan eliminate particular kind flaw: revise plan
believes flaws likelihood exceeds threshold ignore otherwise. course,
inferences drawn based samples certain risk wrong. Suppose want
planner classify flaw probability greater eliminated ignore
flaw less likely . assume flaws probability large impact
robots performance. many execution scenarios plan revision module project
order classify flaws correctly probability greater 95%?
main factor determines performance sample-based predictive flaw detection
flaw detector. flaw detector classifies flaw eliminated probability flaw
respect robots belief state greater given threshold probability . flaw detector
classifies flaw hallucinated probability flaw respect robots belief state
smaller given threshold . far consider severity flaws,
obvious extension. Typically, choose starting 50% smaller 5%.
Specific flaw detectors realized differ respect (1) time resources
require; (2) reliability detect flaws eliminated; (3) probability hallucinate flaws. is, signal flaw unlikely eliminating
flaw would decrease expected utility.
precise consider flaw f occurs distribution execution scenarios
given scheduled plan respect agents belief state probability p. Further, let X (f)
represent event behavior flaw f occurs ith execution scenario: X (f ) = 1, f occurs
ith projection 0 otherwise.
P
random variable Y(f,n) = ni=1 Xi (f) represents number occurrences flaw f
n execution scenarios. Define probable schedule flaw detector ET ET(f,n,k) = true
iff Y(f,n) k, means detector classifies flaw f eliminated f
occurs least k n randomly sampled execution scenarios. Thus ET(f,n,k) works follows.
first projects n execution scenarios. counts number occurrences flaw f
n execution scenarios. greater equal k ET(f,n,k) returns true, false otherwise.
defined schedule flaw detector, characterize it. Since occurrence schedule flaws randomly sampled execution scenarios independent other,
value Y(f) described binomial distribution b(n,p). Using b(n,p) compute
likelihood overlooking probable schedule flaw f probability p n execution scenarios:

j1
X
n
pk (1 p)nk
P (Y (f ) < j) =
k
k=0

836

fiP ROBABILISTIC H YBRID ACTION ODELS

ET(f,3,2)
ET(f,4,2)
ET(f,5,2)

50%
50.0
68.8
81.2

Prob. Flaw
60% 70% 80%
64.8 78.4 89.6
81.2 91.6 97.3
91.3 96.9 99.3

90%
97.2
99.6
99.9

Figure 17: table shows probability flaw detectors ET(f,i,2) detecting flaws
probability = 50%, 60%, 70%, 80%, 90%.

Figure 17 shows probability flaw detector ET(f,n,2) n = 3,...,5 detect
schedule flaw probability . probability detectors classify flaws less likely
eliminated smaller 2.3% (for n5).
using prediction-based scheduling component controller robot office
courier typically use ET(f,3,2), ET(f,4,2), ET(f,5,2) different experiments,
means detected flaw classified probable occurs least twice three, four, five
detection readings.
Figure 18 shows number necessary projections achieve = 95% accuracy.
detailed discussion see work Beetz et al. (1999).

=.1%
=1%
=5%

1%
1331



10%
100
121
392

20%
44
49
78

40%
17
17
22

60%
8
8
9

80%
3
3
3

Figure 18: table lists number randomly sampled projections needed differentiate failures occurrence probability lower probability
higher accuracy 95%.
probabilistic sampling-based projection mechanism becomes extremely useful improving robot plans execution execution scenarios sampled fast enough.
moment projection takes couple seconds. overhead mainly caused recording
interpretation RPL plans manner far detailed purposes.
simplification models expect immediate speed one order magnitude.
seems projection frequency 100 Hz one could start tackling number realistic
problems occur execution time continually.

6. Evaluation
validated causal model low-level navigation plans role office delivery plans respect computational resources qualitative prediction results series
experiments.
837

fiB EETZ & G ROSSKREUTZ

6.1 Generality
PHAM capable predicting behavior generated flexible plans written plan execution
languages RAP (Firby, 1987) PRS (Myers, 1996). so, code control
structures provided languages RPL macros. best knowledge PHAMs
first realistic symbolic models sequencing layer 3T architectures, commonly
used software architectures controlling intelligent autonomous robots (Bonasso et al., 1997).
architectures run planning execution different software layers different time scales
sequencing layer synchronizes layers. layer uses different form
plan behavior specification language. planning layer typically uses problem space plan,
execution layer employs feedback control routines activated deactivated.
intermediate layer typically uses reactive plan language. use PHAMs enables 3T planning
systems make realistic predictions robot behavior generated abstract
plans. PHAMs also capable modeling different arbitration schemes superpositions
effects concurrent control processes.

causal models proposed complement introduced Beetz (2000). describes
sophisticated models object recognition manipulation allow prediction plan
failures including caused robot overlooking confusing objects, objects changing location appearance, faulty operation effectors. models, however,
given simulated robot acting grid world. article, restricted
prediction behavior generated modern autonomous robot controllers. Unfortunately, object
recognition manipulation skills current autonomous service robots advanced enough
action planning. hand, clear action planning capabilities pay much
better robots manipulate environments risk manipulating wrong objects.
6.2 Assumptions Restrictions
control problem autonomous robots generate effective goal-directed control signals robots perceptual effector apparatus within feedback loop. Plan-based robot
control specialization control problem, robot generates control signals
maintaining executing plan effective high expected utility respect
robots dynamically changing belief state. problem general cannot hope
solve form.
Computer Science common characterize computational problems program
solve language input program specified. example, distinguish compilers regular context-free programming languages. true planbased control agents. Typically, planning problems described terms initial state
description, description actions available agents, applicability conditions
effects, description goal state.
three components planning problems typically expressed formal language.
problem solving power planning systems characterized expressiveness
languages three inputs. classes planning problems entirely formulated propositional logic others formulated first order logic. classify planning
problems respect expressiveness action representations use; whether
allow disjunctive preconditions, conditional effects, quantified effects, model resource
838

fiP ROBABILISTIC H YBRID ACTION ODELS

consumption. planning systems even solve planning problems involve different kinds
uncertainty.
contrast, SRCs use methods make strong assumptions plans simplify computational problems. consequence, SRCs apply reliable fast algorithms construction installment sub-plans, diagnosis plan failures, editing sub-plans
execution. Making assumptions plans attractive planning algorithms construct revise plans thereby enforce assumptions hold.
nutshell, set plans SRC generates reflexive, transitive closure
routine plans respect application plan revision rules. Thus, enforce plans
property Q sufficient routine plans satisfy Q revision rules preserve Q.
properties make particularly easy reason plans plans still specify
range concurrent percept-driven behavior RPL can. properties plans play
important role article generality, flexibility, reliability. properties
achieved careful design hand-coding. consequence plan generation revision
performed programmed heuristic rules. believe, however, plans rules
learned experience.
make two important assumptions. First, assume tasks environment
benign therefore behavior flaws result disasters. important, robots
must make errors order learn competent performance tasks experience.
planner allowed occasionally propose worse plans apply fast planning methods
based Monte Carlo methods improve average performance robot.
Another design decision explicitly represent belief state robot,
probability distributions values state variables. This, however, need
imply cannot reason inaccuracies uncertainties robots estimate world
state. Beetz et al. (1998) describe couple plan-based high-level control probabilistic
state estimation. article state estimator automatically computes signals properties
belief state ambiguity inaccuracy state estimates plan-based controller.
plan-based controller, hand, uses signals order decide interrupt
missions re-localize robot.
6.3 Scaling
causal models described Section 5 used execution time planning
robot office courier. plans projected original plans application typically several hundreds code lines long. projected execution scenarios contained
hundreds events. projection single execution scenarios cost second,
robots must revise plans based samples. Thus, robot detect probable flaws
high reliability.
computational resources mainly consumed bookkeeping mechanisms record
computational state robot time instant represented execution scenario
mechanisms proposed article. recorded computational state used
planning mechanisms order diagnose behavior flaws caused discrepancies
computational state robot state environment. ability reconstruct
regularly updated fluent values computationally costly. intend provide programming
839

fiB EETZ & G ROSSKREUTZ

constructs let programmers declare parts computational state irrelevant
planning need recorded.
Even severe limitation able show preliminary implementation robot outperform controllers lack predictive capabilities. main source
inefficiency bookkeeping needed reconstruct entire computational state plan
predicted time instant, issue addressed article. Using
parsimonious representation computational state expect drastic performance gains.
6.4 Qualitatively Accurate Predictions
Projecting plan listed Figure 7 generates timeline 300 events long. Many
events generated rescheduling endogenous events (21 times). Figure 19 shows
predicted endogenous events (denoted numbered circles) behavior generated
navigation plan 50 runs using robot simulator (we assume execution interrupted
room A-111 robot realizes deadline achieved). qualitative
predictions behavior relevant plan debugging perfect. projector predicts correctly
robot exploit opportunity go location 5 going location 1 9.

A111
9

8
7
6

3
4

2
1

A117
5

A118

Figure 19: figure shows trajectories multiple executions navigation plan
events predicted symbolic plan projector.

6.5 Prediction-based Plan Debugging
Beetz (2002a 2000) describes experiments showing prediction-based plan debugging
improve performance robot controllers substantially.
840

fiP ROBABILISTIC H YBRID ACTION ODELS

7. Related Work
PHAM represent external events, probabilistic action models, action models rich temporal
structure, concurrent interacting actions, sensing actions domain autonomous mobile
robot control. many research efforts formalize analyze extended action representations develop prediction planning techniques them. know, however,
approaches address subsets aspects addressed representation. Related work comprises research reasoning action change, probabilistic planning, numerical simulation,
qualitative reasoning.

Reasoning action change. Allen Ferguson (1994) give excellent detailed
discussion important issues representation temporally complex concurrent actions
events. One important point make actions interfering effects then,
worst case, causal models possible combinations actions must provided. paper,
restricted one kind interference actions: transposition movements dominant kind interference physical robot behavior. article
address issues reasoning uncertainty efficiency respect computational
resources.
substantial amount work done extend situation calculus (McCarthy, 1963)
deal time continuous change (Pinto, 1994; Grosskreutz & Lakemeyer, 2000a), exogenous (natural) actions (Reiter, 1996), complex robot actions (plans) (Levesque et al., 1997; Giacomo et al., 1997) using sensing determine action execute next (Levesque, 1996; Lakemeyer, 1999) well probabilistic state descriptions probabilistic action outcomes (Bacchus,
Halpern, & Levesque, 1999; Grosskreutz & Lakemeyer, 2000b). main difference work
representation limited respect kinds events interactions
concurrent actions allow. particular, know effort integrate aspects.
advanced approaches area formalizations various variants
high-level robot control language G OLOG, particular C G OLOG (Giacomo et al., 1997).
Boutilier, Reiter, Soutchanski, Thrun (2000) applied decision theoretic means optimally completing partially specified G OLOG program. key difference G OLOG
approach formalization includes operation plan language whereas approach
procedural semantics realized high-level projector used.
Hanks, Madigan, Gavrin (1995) present interesting expressive framework representing probabilistic information, exogenous endogenous events medical prediction
problems. application domain address issues sophisticated
percept-driven behavior done article.
Extensions Classical Action Planning Systems. Planning algorithms, SNLP (McAllester
& Rosenblitt, 1991), extended various ways handle expressive action models different kinds uncertainty (about initial state occurrence outcome
events) (Kushmerick, Hanks, & Weld, 1995; Draper, Hanks, & Weld, 1994; Hanks, 1990).
planning algorithms compute bounds probabilities plan outcomes computationally expensive. addition, decision-theoretic action planning systems (see Blythe, 1999,
comprehensive overview) proposed order determine plans highest,
least, sufficiently high expected utility (Haddawy & Rendell, 1990; Haddawy & Hanks, 1992;
841

fiB EETZ & G ROSSKREUTZ

Williamson & Hanks, 1994). approaches abstract away rich temporal structure
events assuming discrete atomic actions ignore various kinds uncertainty.
Planning action models rich temporal structure also investigated intensively (Allen, Kautz, Pelavin, & Tenenberg, 1990; Dean, Firby, & Miller, 1988). IxTeT (Ghallab
& Laruelle, 1994) planning system applied robot control reasons
temporal structure plans identify interferences plan steps resource conflicts.
planner/scheduler Remote Agent (Muscettola et al., 1998b) plans space maneuvers
experiments based rich temporal causal models (Muscettola et al., 1998a; Pell et al., 1997).
good overview integration action planning scheduling technology found
overview article Smith, Frank, Jonsson (2000). far considered uncertainty
respect durations actions.
Kabanza, Barbeau, St-Denis (1997) model actions behaviors state transition systems
synthesize control rules reactive robots descriptions. approach used
generate plans satisfy complex time, safety, liveness constraints. approaches
limited respect temporal structure (primitive) actions modeled
kinds interferences concurrent actions considered.
MDP-based planning approaches. recent years MDP (Markov decision process) planning
become active research field (Boutilier, Dean, & Hanks, 1998; Kaelbling, Cassandra, &
Kurien, 1996). MDP approach robot behavior modeled finite state automaton
discrete actions cause stochastic state transitions. robot rewarded reaching goals
quickly reliably. solution problems policy, mapping discretized robot
states into, often fine-grained, actions.
MDP form attractive framework action planning use uniform mechanism
action selection parsimonious problem encoding. action policies computed MDPs
aim robustness optimizing average performance. number researchers successfully considered navigation instance Markov decision problems (MDPs) (Burgard et al.,
2000; Kaelbling et al., 1996).

One main problems application MDP planning techniques keep problem
encoding small enough MDPs still solvable. number techniques complexity
reduction found article written Boutilier et al. (1998). Yet, still difficult
solve big planning problems MDP framework unless state action spaces well
structured.
Besides reducing complexity specifying models for, solving MDP problems, extending expressiveness MDP formalisms active research area. Semi Markov decision
problems (Bradtke & Duff, 1995; Sutton, Precup, & Singh, 1999) add notion continuous time
discrete model change used MDPs: transitions one state another one longer
occur immediately, according probability distribution. Others investigate mechanisms
hierarchically structuring MDPs (Parr & Russell, 1998), decomposing MDPs loosely coupled
sub-problems (Parr, 1998), making programmable (Andre & Russell, 2001). Rohanimanesh Mahadevan (2001) propose approach extending MDP-based planning concurrent temporally extended actions. efforts steps towards kind functionality
provided PHAM framework. Another relationship research reported
MDP research navigation routines modeled PHAM implemented top
842

fiP ROBABILISTIC H YBRID ACTION ODELS

MDP navigation planning. Belker, Beetz, Cremers (2002) use
action models improved execution navigation plans.

MDP

framework learn

application MDP based planning reasoning concurrent reactive plans complicated fact that, general, activation termination concurrent sub-plan might
require respective modification state action space MDP.
Weaver (Blythe, 1995, 1996) another probabilistic plan debugger capable reasoning
exogenous events. Weaver uses Markov decision processes underlying model planning.
Weaver provides much expressiveness PHAMs. Unlike Weaver, PHAMs designed
reasoning physical behavior autonomous mobile robots. Therefore, PHAMs add
Weavers expressiveness extensively support reasoning concurrent reactive plans.
example, PHAMs predict continuous effects actions trigger concurrent
monitoring process. PHAMs built-in capabilities infer combined effects two continuous motions robot.
Qualitative reasoning physical processes. Work qualitative reasoning researched
issues quantization continuous processes focussed among things quantizations
relevant kind reasoning performed. Hendrix (1973) points limitations
discrete event representations introduces limited notion continuous process
representation change. consider influence multiple processes state variables.
Hayes (1985) represents events histories, spatially bounded, temporally extended, pieces
time space, proposes histories intersect interact. Forbus Qualitative
Process Theory (Forbus, 1984) technique called limit analysis applied predict qualitative state
transitions caused continuous events. Also, work simulation often addresses adequacy
causal models given range prediction queries, issue neglected models
used AI planning. Planners predict qualitative state transitions caused continuous events
include EXCALIBUR (Drabble, 1993).
Planning model checking. Planning model checking (Bertoli, Cimatti, & Roveri, 2001;
Cimatti & Roveri, 2000) represents domains finite-state systems. Planning problems solved
searching state space, checking existence plan satisfies goals.
Goals formalized logical requirements desired behavior plans. Unlike planning
model checking consider continuous control processes, plan interpretation well
physical effects actions, concurrency. extended representational power comes
cost probably finding behavior flaws rather proving absence.
Design verification embedded systems based hybrid automata. formalization
embedded software systems (Alur et al., 1997, 1996) using hybrid automata aims proving
critical aspects software rather physical effects running software.
approach used ideas research field basis conceptualization
added additional mechanisms model effects actions sensing mechanisms. Again,
additional complexity model compensated solving restrictive inference problems:
detection probable behavior flaws high probability rather safety system
reachability goals.
843

fiB EETZ & G ROSSKREUTZ

8. Conclusion
successful application AI planning autonomous mobile robot control requires planning systems realistic models operation modern robot control systems
physical effects caused execution. article presented probabilistic hybrid
action models (PHAMs), capable representing temporal structure continuous
feedback control processes, non-deterministic effects, several modes interferences,
exogenous events. shown PHAMs allow predictions are, high probability, qualitatively correct. also shown powerful prediction-based inferences
deciding whether plan likely cause flaw probability exceeding given threshold
drawn fast bounded risk.
believe equipping autonomous robot controllers concurrent reactive plans
prediction-based online plan revision based PHAMs promising way improve performance autonomous service robots AI planning significantly substantially.
rules used projecting navigation behavior hand-coded plan
possibly even environment specific. research agenda development transformational
mechanisms learning high performance task specific plans. learned plans
robot learn projection rules applying data mining techniques plan
execution traces. enable approach must invent novel representational mechanisms
plans allow automatic extraction rules. Initial steps direction
found work Belker et al. (2002), Beetz Belker (2000), Beetz (2002b).

References
Alami, R., Chatila, R., Fleury, S., Ingrand, M. H. F., Khatib, M., Morisset, B., Moutarlier, P., &
Simeon, T. (2000). Around lab 40 days .... Proceedings IEEE International
Conference Robotics Automation (ICRA 2000), pp. 8894.
Allen, J., & Ferguson, G. (1994). Actions events interval temporal logic. Journal Logic
Computation, 4(5), 531579.
Allen, J., Kautz, H., Pelavin, R., & Tenenberg, J. (Eds.). (1990). Reasoning Plans. Morgan
Kaufmann.
Alur, R., Henzinger, T., & Ho, P. (1996). Automatic symbolic verification embedded systems.
IEEE Transactions Software Engineering, 22(3), 181201.
Alur, R., Henzinger, T., & Wong-Toi, H. (1997). Symbolic analysis hybrid systems. Proceedings Thirtyssixth IEEE Conference Decision Control (CDC), pp. 702707.
IEEE Press.
Andre, D., & Russell, S. (2001). Programmable reinforcement learning agents. Advances Neural Information Processing Systems 13, Papers Neural Information Processing Systems
(NIPS) 2000, pp. 10191025. MIT Press.
Arkin, R. (1998). Behavior based Robotics. MIT Press.
Bacchus, F., Halpern, J., & Levesque, H. (1999). Reasoning noisy sensors effectors
situation calculus. Artificial Intelligence 111(1-2).
844

fiP ROBABILISTIC H YBRID ACTION ODELS

Beetz, M. (1999). Structured Reactive Controllers computational model everyday activity. Etzioni, O., Muller, J., & Bradshaw, J. (Eds.), Proceedings Third International
Conference Autonomous Agents, pp. 228235.
Beetz, M. (2000). Concurrent Reactive Plans: Anticipating forestalling execution failures, Vol.
LNAI 1772 Lecture Notes Artificial Intelligence. Springer Publishers.
Beetz, M. (2001). Structured Reactive Controllers. Journal Autonomous Agents Multi-Agent
Systems. Special Issue: Best Papers International Conference Autonomous Agents
99, 4, 2555.
Beetz, M. (2002a). Plan-based Control Robotic Agents, Vol. LNAI 2554 Lecture Notes
Artificial Intelligence. Springer Publishers.
Beetz, M. (2002b). Plan representation robotic agents. Proceedings Sixth International
Conference AI Planning Scheduling, pp. 223232.
Beetz, M., Arbuckle, T., Bennewitz, M., Burgard, W., Cremers, A., Fox, D., Grosskreutz, H.,
Hahnel, D., & Schulz, D. (2001). Integrated plan-based control autonomous service robots
human environments. IEEE Intelligent Systems, 16(5), 5665.
Beetz, M., Arbuckle, T., Cremers, A., & Mann, M. (1998). Transparent, flexible, resourceadaptive image processing autonomous service robots. Prade, H. (Ed.), Proceedings
Thirteenth European Conference Artificial Intelligence (ECAI-98), pp. 632636.
Beetz, M., & Belker, T. (2000). Environment task adaptation robotic agents. Horn, W.
(Ed.), Proceedings Fourteenth European Conference Artificial Intelligence (ECAI2000), pp. 648652.
Beetz, M., Bennewitz, M., & Grosskreutz, H. (1999). Probabilistic, prediction-based schedule debugging autonomous robot office couriers. Proceedings Twentythird German
Conference Artificial Intelligence (KI 99), Bonn, Germany, pp. 243254. Springer Publishers.
Beetz, M., Burgard, W., Fox, D., & Cremers, A. (1998). Integrating active localization highlevel control systems. Robotics Autonomous Systems, 23, 205220.
Beetz, M., & Grosskreutz, H. (1998). Causal models mobile service robot behavior. Simmons,
R., Veloso, M., & Smith, S. (Eds.), Proceedings Fourth International Conference AI
Planning Systems, pp. 163170, Morgan Kaufmann.
Beetz, M., & Grosskreutz, H. (2000). Probabilistic hybrid action models predicting concurrent
percept-driven robot behavior. Proceedings Sixth International Conference AI
Planning Systems, Toulouse, France. AAAI Press.
Beetz, M., & McDermott, D. (1992). Declarative goals reactive plans. Hendler, J. (Ed.),
Proceedings First International Conference AI Planning Systems, pp. 312, Morgan
Kaufmann.
Beetz, M., & McDermott, D. (1996). Local planning ongoing activities. Drabble, B. (Ed.), Proceedings Third International Conference AI Planning Systems, pp. 1926, Morgan
Kaufmann.
Beetz, M., & Peters, H. (1998). Structured reactive communication plans integrating conversational actions high-level robot control systems. Proceedings Twentysecond
845

fiB EETZ & G ROSSKREUTZ

German Conference Artificial Intelligence (KI 98), Bremen, Germany. Springer Publishers.
Belker, T., Beetz, M., & Cremers, A. (2002). Learning action models improved execution
navigation plans. Robotics Autonomous Systems, 38(3-4), 137148.
Bertoli, P., Cimatti, A., & Roveri, M. (2001). Planning nondeterministic domains partial
observability via symbolic model checking. Proceedings Seventeenth International
Joint Conference Artificial Intelligence (IJCAI-01). AAAI Press.
Blythe, J. (1995). AI planning dynamic, uncertain domains. Extending Theories Action:
Formal Theory & Practical Applications: Papers 1995 AAAI Spring Symposium, pp.
2832. AAAI Press, Menlo Park, CA.
Blythe, J. (1996). Decompositions Markov chains reasoning external change planners. Drabble, B. (Ed.), Proceedings 3rd International Conference Artificial
Intelligence Planning Systems (AIPS-96), pp. 2734. AAAI Press.
Blythe, J. (1999). Decision-theoretic planning. AI Magazine, 20(2), 3754.
Bonasso, P., Firby, J., Gat, E., Kortenkamp, D., Miller, D., & Slack, M. (1997). Experiences
architecture intelligent, reactive agents. Journal Experimental Theoretical Artificial
Intelligence, 9(1).
Boutilier, C., Dean, T., & Hanks, S. (1998). Decision theoretic planning: Structural assumptions
computational leverage. Journal Artificial Intelligence Research, 11, 194.
Boutilier, C., Reiter, R., Soutchanski, M., & Thrun, S. (2000). Decision-theoretic, high-level robot
programming situation calculus. Proceedings Seventeenth AAAI National
Conference Artificial Intelligence, pp. 355362, Austin, TX.
Bradtke, S., & Duff, M. (1995). Reinforcement learning methods continuous-time Markov
decision problems. Tesauro, G., Touretzky, D., & Leen, T. (Eds.), Advances Neural
Information Processing Systems, Vol. 7, pp. 393400. MIT Press.
Brooks, R. (1986). robust layered control system mobile robot. IEEE Journal Robotics
Automation, 2(1), 1423.
Burgard, W., Cremers, A., Fox, D., Hahnel, D., Lakemeyer, G., Schulz, D., Steiner, W., & Thrun,
S. (2000). Experiences interactive museum tour-guide robot. Artificial Intelligence,
114(1-2), 355.
Cimatti, A., & Roveri, M. (2000). Conformant planning via symbolic model checking. Journal
Artificial Intelligence Research (JAIR), 13, 305338.
Dean, T., Firby, J., & Miller, D. (1988). Hierarchical planning involving deadlines, travel time
resources. Computational Intelligence, 4(4), 381398.
Doherty, P., Granlund, G., Krzysztof, G., Sandewall, E., Nordberg, K., Skarman, E., & Wiklund,
J. (2000). WITAS unmanned aerial vehicle project. Proceedings Fourteenth
European Conference Artificial Intelligence (ECAI-00), pp. 747755, Berlin, Germany.
Drabble, B. (1993). Excalibur: program planning reasoning processes. Artificial
Intelligence, 62, 140.
846

fiP ROBABILISTIC H YBRID ACTION ODELS

Draper, D., Hanks, S., & Weld, D. (1994). Probabilistic planning information gathering
contingent execution. Proceedings Second International Conference AI Planning
Systems, p. 31.
Firby, J. (1987). investigation reactive planning complex domains. Proceedings
Sixth National Conference Artificial Intelligence, pp. 202206, Seattle, WA.
Forbus, K. (1984). Qualitative process theory. Artificial Intelligence, 24, 85168.
Fox, D., Burgard, W., Dellaert, F., & Thrun, S. (1999). Monte Carlo localization: Efficient position estimation mobile robots. Proceedings Sixteenth National Conference
Artificial Intelligence, Orlando, FL.
Ghallab, M., & Laruelle, H. (1994). Representation control IxTeT, temporal planner.
Hammond, K. (Ed.), Proceedings Second International Conference AI Planning
Systems, pp. 6167, Morgan Kaufmann.
Giacomo, G. D., Lesperance, Y., & Levesque, H. (1997). Reasoning concurrent execution,
prioritized interrupts, exogene ous actions situation calculus. Proceedings
Fifteenth International Joint Conference Artificial Intelligence, Nagoya, Japan.
Grosskreutz, H., & Lakemeyer, G. (2000a). cc-Golog: Towards realistic logic-based robot
controllers. Proceedings Seventeenth National Conference Artificial Intelligence.
Grosskreutz, H., & Lakemeyer, G. (2000b). Turning high-level plans robot programs uncertain domains. Proceedings Fourteenth European Conference Artificial Intelligence (ECAI-00), pp. 548552.
Haddawy, P., & Hanks, S. (1992). Representations decision-theoretic planning: Utility functions
deadline goals. Nebel, B., Rich, C., & Swartout, W. (Eds.), Proceedings Third
International Conference Principles Knowledge Representation Reasoning, pp. 71
82, Cambridge, MA. Morgan Kaufmann.
Haddawy, P., & Rendell, L. (1990). Planning decision theory. Knowledge Engineering
Review, 5, 1533.
Hanks, S. (1990). Practical temporal projection. Proceedings Eighth National Conference
Artificial Intelligence (AAAI-90), pp. 158163.
Hanks, S., Madigan, D., & Gavrin, J. (1995). Probabilistic temporal reasoning endogenous
change. Proceedings Eleventh Conference Uncertainty Artificial Intelligence,
pp. 245254. Morgan Kaufmann.
Hayes, P. (1985). second naive physics manifesto. Hobbs, J. R., & Moore, R. C. (Eds.),
Formal Theories Commonsense World, pp. 136. Ablex, Norwood, NJ.
Hendrix, G. (1973). Modeling simultaneous actions continuous processes. Artificial Intelligence, 4, 145180.
Horswill, I. (1996). Integrated systems naturalistic tasks. In: Strategic Directions Computing
Research, AI Working Group.
Kabanza, F., Barbeau, M., & St-Denis, R. (1997). Planning control rules reactive agents. Artificial Intelligence, 95, 67113.
847

fiB EETZ & G ROSSKREUTZ

Kaelbling, L., Cassandra, A., & Kurien, J. (1996). Acting uncertainty: Discrete Bayesian
models mobile-robot navigation. Proceedings IEEE/RSJ International Conference Intelligent Robots Systems.
Konolige, K., Myers, K., Ruspini, E., & Saffiotti, A. (1997). Saphira architecture: design
autonomy. Journal Experimental Theoretical Artificial Intelligence, 9(2).
Kushmerick, N., Hanks, S., & Weld, D. (1995). algorithm probabilistic planning. Artificial
Intelligence, 76, 239286.
Lakemeyer, G. (1999). sensing off-line interpreting golog. Levesque, H., & Pirri, F.
(Eds.), Logical Foundations Cognitive Agents. Springer Publishers.
Levesque, H., Reiter, R., Lesperance, Y., Lin, F., & Scherl, R. (1997). Golog: logic programming
language dynamic domains. Journal Logic Programming, 31, 5984.
Levesque, H. J. (1996). planning presence sensing. Proceedings Thirteenth
National Conference Artificial Intelligence, pp. 11391146, Portland, OR.
McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. Proceedings
Ninth National Conference Artificial Intelligence, pp. 634639, Anaheim, CA.
McCarthy, J. (1963). Situations, actions causal laws. Tech. rep., Stanford University. Reprinted
1968 Semantic Information Processing (M. Minsky ed.).
McDermott, D. (1991). Reactive Plan Language. Research Report YALEU/DCS/RR-864, Yale
University.
McDermott, D. (1992a). Robot planning. AI Magazine, 13(2), 5579.
McDermott, D. (1992b). Transformational planning reactive behavior.
YALEU/DCS/RR-941, Yale University.

Research Report

McDermott, D. (1994). algorithm probabilistic, totally-ordered temporal projection. Research Report YALEU/DCS/RR-941, Yale University.
Muscettola, N., Morris, P., Pell, B., & Smith, B. (1998a). Issues temporal reasoning autonomous control systems. Sycara, K., & Wooldridge, M. (Eds.), Proceedings
Second International Conference Autonomous Agents (AGENTS-98), pp. 362368. ACM
Press.
Muscettola, N., Nayak, P., Pell, B., & Williams, B. (1998b). Remote Agent: boldly go
AI system gone before. Artificial Intelligence, 103(12), 547.
Myers, K. (1996). procedural knowledge approach task-level control. Drabble, B. (Ed.),
Proceedings Third International Conference AI Planning Systems, pp. 158165,
Edinburgh, GB. AAAI Press.
Parr, R. (1998). Flexible decomposition algorithms weakly coupled Markov decision problems.
Cooper, G. F., & Moral, S. (Eds.), Proceedings Fourteenth Conference Uncertainty Artificial Intelligence (UAI-98), pp. 422430, San Francisco. Morgan Kaufmann.
Parr, R., & Russell, S. (1998). Reinforcement learning hierarchies machines. Jordan,
M. I., Kearns, M. J., & Solla, S. A. (Eds.), Advances Neural Information Processing Systems, Vol. 10. MIT Press.
848

fiP ROBABILISTIC H YBRID ACTION ODELS

Pell, B., Gat, E., Keesing, R., Muscettola, N., & Smith, B. (1997). Robust periodic planning execution autonomous spacecraft. Proceedings 15th International Joint Conference
Artificial Intelligence (IJCAI-97), pp. 12341239, San Francisco. Morgan Kaufmann.
Pinto, J. (1994). Temporal Reasoning Situation Calculus. Ph.D. thesis, Department Computer Science, University Toronto, Toronto, Ontario, Canada.
Reiter, R. (1996). Natural actions, concurrency continuous time situation calculus.
Proceedings Fifth International Conference Principles Knowledge Representation
Reasoning (KR-96), pp. 213.
Rohanimanesh, K., & Mahadevan, S. (2001). Decision-theoretic planning concurrent temporally extended actions. Proceedings Seventeenth Conference Uncertainty
Artificial Intelligence (UAI), pp. 472479.
Schmitt, T., Hanek, R., Beetz, M., Buck, S., & Radig, B. (2002). Cooperative probabilistic state
estimation vision-based autonomous mobile robots. IEEE Transactions Robotics
Automation, 18(5), 670684.
Simmons, R., Goodwin, R., Haigh, K., Koenig, S., & OSullivan, J. (1997). modular architecture office delivery robots. Proceedings First International Conference
Autonomous Agents, pp. 245252.
Smith, D., Frank, J., & Jonsson, A. (2000). Bridging gap planning scheduling.
Knowledge Engineering Review, 15(1), 4783.
Sutton, R., Precup, D., & Singh, S. (1999). MDPs semi-MDPs: framework
temporal abstraction reinforcement learning. Artificial Intelligence 112(1-2), 181211.
Thrun, S. (2000). Monte Carlo POMDPs. Advances Neural Information Processing Systems
12, pp. 10641070. MIT Press.
Thrun, S., Beetz, M., Bennewitz, M., Cremers, A., Dellaert, F., Fox, D., Hahnel, D., Rosenberg, C.,
Roy, N., Schulte, J., & Schulz, D. (2000). Probabilistic algorithms interactive museum
tour-guide robot Minerva. International Journal Robotics Research, 19(11), 972999.
Thrun, S., Bucken, A., Burgard, W., Fox, D., Frohlinghaus, T., Hennig, D., Hofmann, T., Krell, M.,
& Schmidt, T. (1998). Map learning high-speed navigation RHINO. Kortenkamp,
D., Bonasso, R., & Murphy, R. (Eds.), AI-based Mobile Robots: Case studies successful
robot systems, pp. 21 52. MIT Press.
Williamson, M., & Hanks, S. (1994). Utility-directed planning. Proceedings Twelfth
National Conference Artificial Intelligence, p. 1498, Seattle, WA.

849

fiJournal Artificial Intelligence Research 24 (2005) 685-758

Submitted 03/05; published 11/05

Ignoring Delete Lists Works:
Local Search Topology Planning Benchmarks
Jorg Hoffmann

hoffmann@mpi-sb.mpg.de

Max Planck Institute Computer Science,
Stuhlsatzenhausweg 85,
66123 Saarbrucken
Germany

Abstract
1998 2004, planning community seen vast progress terms
sizes benchmark examples domain-independent planners tackle successfully.
key technique behind progress use heuristic functions based relaxing
planning task hand, relaxation assume delete lists empty.
unprecedented success methods, many commonly used benchmark examples,
calls understanding classes domains methods well suited for.
investigation hand, derive formal background understanding. perform case study covering range 30 commonly used STRIPS ADL
benchmark domains, including examples used first four international planning
competitions. prove connections domain structure local search topology
heuristic cost surface properties idealized version heuristic functions
used modern planners. idealized heuristic function called h+ , differs
practically used functions returns length optimal relaxed plan,
NP-hard compute. identify several key characteristics topology h+ , concerning existence/non-existence unrecognized dead ends, well
existence/non-existence constant upper bounds difficulty escaping local minima
benches. distinctions divide (set all) planning domains taxonomy
classes varying h+ topology. turns out, many 30 investigated domains lie
classes relatively easy topology. particularly, 12 domains lie classes
FFs search algorithm, provided h+ , polynomial solving mechanism.
also present results relating h+ approximation implemented FF.
behavior regarding dead ends provably same. summarize results empirical investigation showing that, many domains, topological qualities h+
largely inherited approximation. overall investigation gives rare example
successful analysis connections typical-case problem structure, search
performance. theoretical investigation also gives hints topological phenomena might automatically recognizable domain analysis techniques. outline
preliminary steps made direction.

1. Introduction
1998 2004, one strongest trends planning community
towards heuristic planners, specifically towards use heuristic distance (in
cases, goal distance) estimation functions. best runtime results, progressing far beyond
sizes benchmark examples previous domain-independent planners could tackle
successfully, achieved based upon technique phrased ignoring delete lists.
c
2005
AI Access Foundation. rights reserved.

fiHoffmann

There, heuristic function derived considering relaxation planning task
hand, relaxation assume delete lists (i.e. negative effects
available planning operators) empty. search, may forward backward,
state space plan space, heuristic value search state framework (an
estimate of) difficulty extending state solution using relaxed operators,
difficulty defined number (relaxed) actions needed.
number real actions needed extend search state solution least
high number relaxed actions needed. optimal (shortest) relaxed solutions
can, principle, used derive admissible heuristic functions. However, first
proved Bylander (1994), deciding bounded plan existence, i.e., existence plan
given number actions, NP-hard even delete lists.1
Thus much hope find optimal relaxed plans (i.e., optimal relaxed solutionextensions search states) fast. Instead, one approximate length optimal
relaxed plan search state. Techniques kind first, independently, proposed
McDermott (1996) Bonet, Loerincs, Geffner (1997), developed planners
Unpop (McDermott, 1996, 1999), HSP1 (Bonet et al., 1997). planners
perform forward state space search guided approximation relaxed goal distance.
Unpop approximates distance backchaining goals, HSP1 approximates
distance forward value iteration technique.
1st international planning competition, IPC-1 (McDermott, 2000), hosted
AIPS-1998, HSP1 compared well four competitors. inspired development HSP-r HSP2 (Bonet & Geffner, 1999, 2001b, 2001a), GRT (Refanidis &
Vlahavas, 1999, 2001), AltAlt (Nguyen & Kambhampati, 2000; Srivastava, Nguyen, Kambhampati, Do, Nambiar, Nie, Nigenda, & Zimmermann, 2001), well FF (Hoffmann,
2000; Hoffmann & Nebel, 2001a; Hoffmann, 2001a). HSP-r avoids heuristic re-computations
changing search direction. HSP2 implements various HSP versions configurable hybrid system. GRT avoids heuristic re-computations changing heuristic
direction (the direction relaxed plans computed). AltAlt uses planning
graph extract heuristic values. FF uses modified technique approximating optimal
relaxed plan length (namely, computing necessarily optimal relaxed plan,
done polynomial time), well new pruning search techniques. FF inspired integration heuristic search engines Mips (Edelkamp & Helmert, 2001)
STAN4 (Fox & Long, 2001), using elaborated variations FFs relaxed plan length
estimation technique.
2nd international planning competition, IPC-2 (Bacchus, 2001), hosted AIPS2000, heuristic planners dramatically outperformed approaches runtime-wise,
scaling benchmark examples far beyond reach previous, e.g., Graphplan-based
(Blum & Furst, 1995, 1997), systems. caused trend towards heuristic planners
still increase. Various researchers extended relaxed plan distance estimation techniques
temporal numeric settings (Do & Kambhampati, 2001; Hoffmann, 2002, 2003a;
Edelkamp, 2003b). Others adapted use partial order plan-space search (Nguyen
1. parallel planning, bound number parallel time steps needed, deciding bounded
plan existence easy without delete lists. However, heuristic functions based observation
generally found provide useful search guidance practice (see, example, Haslum &
Geffner, 2000; Bonet & Geffner, 2001b).

686

fiWhere Ignoring Delete Lists Works

& Kambhampati, 2001; Younes & Simmons, 2002), developed variations provide
new means heuristic guidance (Onaindia, Sapena, Sebastia, & Marzal, 2001; Sebastia,
Onaindia, & Marzal, 2001), modified take exclusion relations planning graph
account (Gerevini & Serina, 2002; Gerevini, Serina, Saetti, & Spinoni, 2003).
3rd international planning competition, IPC-3 (Long & Fox, 2003), hosted
AIPS-2002, 11 domain-independent competing systems, 7 using relaxed plan
distance estimations one form. 1st prize winner LPG (Gerevini & Serina,
2002; Gerevini, Saetti, & Serina, 2003) uses, amongst heuristics, relaxed planning
technique estimate difficulty sub-goal achievement planning graph.
4th international planning competition, IPC-4 (Hoffmann & Edelkamp, 2005; Edelkamp,
Hoffmann, Englert, Liporace, Thiebaux, & Trug, 2005), hosted ICAPS-2004, 13
competing sub-optimal systems, 12 using relaxed plan based heuristics.
two 1st prize winners category: Fast-Downward (Helmert, 2004; Helmert & Richter,
2004) SGPlan (Chen & Wah, 2003; Chen, Hsu, & Wah, 2004). latter uses
numeric version FF sub-process. One version former combines FFs heuristic
estimates new heuristic function based causal graph analysis (Helmert, 2004).
investigation hand, derive formal background classes domains methods kind described well suited for. make two simplifying
assumptions. First, consider forward state space search only, used by, example,
Unpop, HSP, Mips, FF, Fast-Downward. forward state space search, one starts
initial state explores space reachable states goal state found.
state transitions follow sequential planning framework, single action
applied time.2 Assuming forward search makes investigation easier since
search natural simple framework. second simplifying assumption
idealize matters consider heuristic value given optimal relaxed plan
length (the length shortest sequential relaxed plan) search state s; denote
value h+ (s). assumption, see many provable
connections domain structure heuristic quality. course, simplifying assumptions restrict relevance results practical planners. said
section, Section 7. Another, benign, restriction make
consider solvable tasks only. common restriction AI Planning, particularly
competitions, main focus good planners finding plans.
specifically, main focus investigation hand characterize kinds
domains (relaxed-plan based) heuristic planners find plans fast.
common knowledge behavior heuristic search methods (may
global local, i.e., without backtracking mechanisms) depends crucially
quality underlying heuristic function. has, example, studied
SAT community, example Frank, Cheeseman, Stutz (1997). work,
authors empirically investigate properties local search topology, i.e., topological
properties like sizes local minima etc., SAT instances standard heuristic
function. adapt Frank et al.s definitions AI planning. difference Frank et
al., take analytical approach prove properties valid across
2. principle, parallel forward search possible, too. best authors knowledge,
published work implementation this, time writing. main difficulty is,
presumably, high branching factor.

687

fiHoffmann

certain ranges, namely domains, example problem instances. investigate range
30 commonly used STRIPS ADL benchmark domains including examples used
first four international planning competitions. identify several key characteristics
topology respective search spaces h+ . characteristics following.
1. 24 benchmark domains, unrecognized dead ends, i.e., states
goal unreachable relaxed plan.
2. 17 24 benchmark domains, maximal exit distance local
minima constantly bounded, i.e., one always escape local minima (regions
neighbors higher heuristic value) within number steps
constant across instances domain, regardless size (in fact, 13
domains local minima all).
3. 12 17 benchmark domains, maximal exit distance benches
constantly bounded, i.e., one always escape benches (regions states
heuristic value) within number steps constant across
instances domain, regardless size (in 6 domains bound 1, one
domain even 0).
Beside positive results proving characteristic qualities h+ function,
investigation also provides (parameterized) counter-examples negative cases.
results divide investigated domains (more generally, possible planning domains)
meaningful taxonomy classes differ terms topological behavior
respect h+ . Many 30 investigated domains lie relatively easy classes, i.e., classes
h+ provably high-quality heuristic. particularly, 12 domains
properties lie classes FFs search algorithm polynomial solving
mechanism, idealizing assumption FFs approximative heuristic function
identifies real h+ distances. FFs search algorithm, called enforced hill-climbing, tries
escape local minima benches means breadth-first search. Breadth-first search
exponential search depth. local minima benches always
escaped within constant number steps case 12 domains
effort spent search polynomially bounded. way, results provide
non-trivial insights typical-case problem structure (in benchmarks), possible
effects search performance. Examples successful theoretical investigations kind
extremely rare AI literature.
give reader feeling looking at, Figure 1 shows two visualized
state spaces. shown tasks instances two domains easiest classes
taxonomy, Gripper Logistics. graph nodes states, edges state
transitions (action applications), height given h+ value.3 pictures,
initial state somewhere left top part. goal states are, course, states
minimal zero h+ value. Gripper picture speaks itself. Logistics topology
less extreme, still state space forms one big valley bottom
goal states.
3. h+ values here, empirical investigation (Hoffmann, 2001b, 2003b) preceding theoretical
analysis, computed iterative deepening forward search space relaxed action sequences.

688

fiWhere Ignoring Delete Lists Works

(a)

(b)

Figure 1: Visualized state space h+ (a) Gripper (b) Logistics instance.

course, FFs approximation h+ , refer hF F , always identify
real h+ values, priori evident relevance theoretical results
h+ FFs efficiency practice. Additionally, forward searching planners
use enforced hill-climbing, topological results striking
impact. Finally, importantly, several competitive planners even
perform forward search, use additional/new techniques heuristic function
explicitly aimed identifying better information relaxed plans. Prominent systems
former kind HSP-r LPG, prominent systems latter kind LPG
Fast-Downward.
relevance results performance FF, practical performance
FF coincides quite well them. concretely, behavior h+ respect dead
ends provably hF F . Moreover, large-scale empirical investigation
(contained Hoffmann, 2003b) shown that, many domains, topology h+
largely preserved hF F . include section containing brief summary results.
relevance topological results forward search algorithms enforced
hill-climbing, performance planners using search paradigms enhanced
heuristics, discussed Section 7.
remark topological investigation specifically intended identify
properties relevant enforced hill-climbing. theoretical investigation preceded
empirical investigation (Hoffmann, 2001b, 2003b) measured kinds
topological parameters, including, example, size diameter local minima, benches,
structures so-called valley regions. turned topology
parameters showed interesting behavior across significant number domains
maximal exit distance parameters considered investigation hand. This, fact,
came surprise us invented enforced hill-climbing FF became clear
689

fiHoffmann

many planning benchmarks share topological properties favoring precisely
particular search algorithm.
Observe proved results worst-case nature, i.e., heuristic search using
+
h show good behavior example suite domain even domain lies
difficult class taxonomy given particular example instances test
suite emphasize worst cases possible domain. relevant,
discuss issue regards example suites used competitions.
employed proof methods give hints topological phenomena might
automatically detectable using general domain analysis techniques. extra section,
report first (not yet successful) attempt made that.
proofs individual planning domains are, cases, overly difficult,
full details domains extremely space consuming. details (except
5 IPC-4 domains), i.e., PDDL-like definitions domains well fully detailed
proofs, looked long (138 pages) technical report (Hoffmann, 2003c) also
forms online appendix article.4 article provides proof sketches,
much better suited get overall understanding investigation results.
Since even proof sketches sometimes hard read, moved appendix;
another appendix provides brief descriptions domains. main body text
gives results outline main proof arguments used obtain them.
paper organized follows. Section 2 provides necessary background, i.e.
straightforward formal framework STRIPS ADL domains, overview
investigated domains, definitions local search topology. Section 3 presents
core lemmas underlying many proofs single domains, illustrates lemmas
application small example. Section 4 gives results brief proof outline,
shows resulting planning domain taxonomy. Section 5 presents results relating
h+ hF F , Section 6 reports first attempt design domain analysis techniques
automatically detecting h+ topological phenomena. Section 7 concludes article
brief discussion contributions future work. Appendix contains
proof sketches individual domains, Appendix B contains domain descriptions.

2. Background
Background necessary planning framework, investigated domains, local
search topology.
2.1 Planning Framework
enable theoretical proofs properties planning domains rather single tasks,
defined formal framework STRIPS ADL domains, formalizing straightforward manner way domains usually dealt community. outline
rather lengthy definitions, refer reader TR (Hoffmann, 2003c) details.
follows, sets mean finite sets unless explicitly said otherwise.
4. remark TR longer version paper hand. TRs overall structure
presentation angle different, intended source details needed.

690

fiWhere Ignoring Delete Lists Works

planning domain defined terms set predicates, set operators,
possibly infinite set instances. logical constructs domain based
set predicates. fact predicate applied tuple objects. operators
(k-ary, k number operator parameters) functions (infinite) set
objects (infinite) set STRIPS ADL actions. STRIPS action
triple (pre(a), add(a), del(a)): precondition, conjunction facts; add list,
fact set; delete list, also fact set. ADL action pair (pre(a), E(a))
precondition pre(a) first order logical formula without free variables, E(a)
set effects e form (con(e), add(e), del(e)) con(e), effect condition,
formula without free variables, add(e) (the effects add list) well del(e) (the
effects delete list) fact sets. add list action/effect contains fact p, also
say action/effect achieves p.
instance domain defined terms set objects, initial state, goal
condition. initial state set facts, goal condition formula without free
variables (in STRIPS case, conjunction facts). facts contained
initial state assumed true, facts contained assumed false,
i.e., usual apply closed-world assumption. instance domain constitutes,
together domains operators, planning task (A, I, G) action set
result applying operators instances objects (i.e., object tuples
appropriate lengths), initial state goal condition G instance.
identify instances respective planning tasks.
state set facts. logical formula holds state state model
formula according standard definition first order logic (where logical atom,
fact, holds iff contained state). result Result(s, hai) applying action
sequence consisting single STRIPS ADL action state defined follows.
actions precondition hold s, Result(s, hai) undefined. Otherwise,
Result(s, hai) obtained including add effects, (thereafter) removing
delete effects ADL action, add effects add(e) included
(delete effects del(e) removed) respective effect condition con(e) holds
s. result applying sequence ha1 , . . . , consisting one action
state defined iterative application single actions obvious manner:
apply a1 s, apply a2 Result(s, ha1 i), on.
plan, solution, task (A, I, G) sequence actions P that,
successively applied I, yields goal state, i.e., state G holds. (We use
standard notation , set, denote set sequences elements
.) many proofs need notion optimality. plan P task (A, I, G)
optimal plan (A, I, G) contains fewer actions P .
Note that, announced introduction, definition, particular definition
plan optimality, stays within forward state space search framework plans
simple sequences actions. Note also ignoring delete lists simplifies task
formulas negation free. fixed domain, tasks polynomially normalized
property: compute negation normal form formulas (negations
front facts), introduce negated fact B new fact not-B make sure
true state iff B false (Gazen & Knoblock, 1997). pre-process done in,
691

fiHoffmann

example, FF. investigation hand, considered normalized versions
domains.5
also consider domains, IPC-4 collection, feature derived predicates. predicates affected effects operators, truth value
instead derived values other, basic, predicates, via set derivation
rules. derivation rule form (x) P (x) P derived predicate
(a formula) rules antecedent, using free variables x. obvious idea
that, (x) holds, P (x) concluded. little detail, semantics
defined follows. initial state, whenever action applied, first
derived predicate instances (derived facts) assumed false, derivation rules
applied fixpoint occurs. derived facts could concluded
said false (this called negation failure). Derived predicates used
like predicate operator preconditions, effect conditions,
goal condition. However, ensure unique fixpoint rule application,
use derived predicates derivation rule antecedents restricted (in context
IPC-4) positive use sense predicates appear negated
negation normal form rule antecedent (Hoffmann & Edelkamp, 2005).
make ignoring delete lists simplification, one also needs derived facts
used positively operator preconditions, effect conditions, goal condition
(otherwise derived predicates can, example, used model negated preconditions etc.). Due negation failure semantics derived predicates, isnt
simple compilation negations pure ADL case. approach take here,
implemented in, example, version FF treats derived predicates
(Thiebaux, Hoffmann, & Nebel, 2003, 2005), simply ignore (replace true) negated
derived predicates (the negation normal form of) operators goal (see also below,
Section 2.3).
2.2 Domains Overview
said before, case study covers total 30 commonly used STRIPS ADL benchmark domains. include examples first four international competitions,
plus 7 domains used literature. Brief descriptions domains looked
Appendix B, full formal definitions domains (except 5 IPC-4 domains)
TR (Hoffmann, 2003c). Note that, defining domain, one must amongst
things decide exactly instances are. Naturally, abstracted
known example suites. cases abstraction obvious, less obvious
cases respective subsection Appendix B includes explanatory remarks.
Here, provide brief overview 30 analyzed domains. domains categorized three groups according semantics, high level abstraction.
categorization not, way, related topological characterization derive
later. use give overview structure.
5. Ignoring delete lists normalized domains comes relaxation that, basically, allows (the
translated) facts take truth values time.

692

fiWhere Ignoring Delete Lists Works

1. Transportation domains. domains locations, objects
must transported, vehicles means transportation.6 Operators mostly either move vehicle, load (unload) object onto (from) vehicle. domains differ terms various constraints. important one that,
many domains, vehicles move instantaneously two locations,
domains movable links locations form arbitrary road maps.
13 transportation domains collection look at. Logistics classical transportation domain, trucks/airplanes transport objects within/between
cities. Gripper robot two gripper hands transports number balls (one
time hand) one room another. Ferry single ferry transports
cars one time. Driverlog trucks need drivers board order move,
location links form bi-directional road maps (which different trucks
drivers). Briefcaseworld briefcase moves, conditional effects, objects along
inside it. Grid robot transports keys grid-like road map
positions locked must opened keys matching shapes. MiconicSTRIPS elevator transports passengers, using explicit actions board/deboard
passengers. Miconic-SIMPLE like Miconic-STRIPS, passengers board/deboard
conditional effects action stops elevator floor.
Miconic-ADL like Miconic-SIMPLE, various constraints must obeyed (for
example, VIPs first). Zenotravel airplanes use fuel items replenished
one one using refuel operator. Mprime arbitrary road map, trucks use
non-replenishable fuel items, fuel transferred locations. Mystery
like Mprime, without possibility transfer fuel. Airport inbound
outbound planes must moved safely across road map airport.
2. Construction domains. generally closely related transportation domains above. construction domains common, roughly,
complex object must built individual parts. 6
domains collection look at. Blocksworld-arm classical construction
domain, blocks picked up/put stacked onto/unstacked
means robot arm. Blocksworld-no-arm like above, blocks
moved around directly block block / table block /
block table. Depots combination Blocksworld-arm Logistics,
objects must transported locations stacked onto
other. Freecell encoding solitaire card game comes Microsoft
Windows (the complex object constructed final position cards).
Hanoi encoding classical Towers Hanoi problem. Assembly complex
object must assembled together parts, might need
assembled beforehand.
3. domains. 11 domains collection whose semantics
quite fit either groups. Simple-Tsp trivial STRIPS version
6. term transportation domains suggested, example, Long Fox (2000) Helmert
(2003). transportation benchmarks generally closely related groups
domains overviewed below, sometimes discuss transportation domains rather generic
level.

693

fiHoffmann

TSP problem, move operator applied two locations.
Movie order watch movie, one must buy snacks, set counter video
zero, rewind tape. Tireworld number flat tires must replaced,
involves various working steps (like removing flat tire putting new
one). Fridge number fridges, broken compressors must replaced,
involves various working steps (like loosening/fastening screws hold
compressor). Schedule objects must processed (painted, example)
number machines. Satellite satellites must take images (of phenomena space),
using appropriate instruments. Rovers rovers must navigate along road map, take
soil/rock samples well images, communicate resulting data lander.
Pipesworld oil derivatives must propagated pipeline network. PSR
lines must re-supplied faulty electricity network. Dining-Philosophers
deadlock situation Dining-Philosophers problem, translated ADL
automata-based Promela language (Edelkamp, 2003a), must found. OpticalTelegraph similar Dining-Philosophers, considering encoding telegraph
communication system.
2.3 Local Search Topology
Remember consider solvable tasks, since main focus investigation
characterize kinds domains heuristic planners find plans fast.
discussion unsolvable tasks Section 7.
Given planning task (A, I, G). state space (S, ) graph states
reachable initial state, set state transitions, i.e., set
pairs (s, s0 ) states action leads s0 executed
s. goal distance gd(s) state length shortest path (S, )
goal state, gd(s) = path. latter case, dead end;
discuss states directly below. heuristic function h : 7 N {}.7 heuristic
return indicate state hand might dead end.
Given STRIPS action = (pre(a), add(a), del(a)), relaxation a+
(pre(a), add(a), ). Given ADL action = (pre(a), E(a)), relaxation a+
(pre(a), E(a)+ ) E(a)+ E(a) except delete lists empty.
set actions, relaxation A+ A+ := {a+ | A}. action sequence
+
+
ha1 , . . . , relaxed plan (A, I, G) ha+
1 , . . . , plan (A , I, G). that,
+

state s, h (s) = min{n | P = ha1 , . . . , , P relaxed plan (A, s, G)},
minimum empty set .
presence derived predicates, said additionally relax planning
task ignoring (replacing true) negated derived predicates negation normal
forms preconditions, effect conditions, goal condition. Note that,
additional simplification, happen h+ (s) 0 although goal state,
simplification might relax goal condition itself. Indeed, happens
PSR domain. domains consider here, derived predicates either used
used positively, h+ (s) = 0 iff goal state.
7. article focuses mainly h+ heuristic, keep topology definitions
depend specific heuristic used somewhat general.

694

fiWhere Ignoring Delete Lists Works

One phenomenon clearly relevant performance heuristic state space
search dead end states s, gd(s) = . heuristic function h return h(s) = .
Taking indication dead end, obvious idea remove
search space (this done in, example, HSP FF). technique adequate
h completeness preserving sense h(s) = gd(s) = S.
completeness-preserving heuristic, dead end state called recognized h(s) =
unrecognized otherwise. Note h+ completeness preserving. task solved
even ignoring delete lists, task unsolvable. assume
heuristic look completeness preserving. respect dead ends,
planning state space falls one following four classes. state space called:
1. Undirected, if, (s, s0 ) , (s0 , s) .
2. Harmless, exists (s, s0 ) (s0 , s) 6 , and, S, gd(s) < .
3. Recognized, exists gd(s) = , and, S, gd(s) =
h(s) = .
4. Unrecognized, exists gd(s) = h(s) < .
first class, dead ends everything undone.
second class, things undone, single-directed state transitions
harm, sense dead end states. third class,
dead end states, recognized heuristic function.
critical case heuristic search class four, search algorithm run dead
end without noticing it. particularly relevant if, potentially, large regions
state space consist unrecognized dead end states. capture this, define depth
unrecognized dead end number states s0 s0 unrecognized dead
end, s0 reachable path moves unrecognized dead ends.
investigation determines, 30 benchmark domains looked at, exactly
four dead end classes instances domain belong. domains
turns unrecognized dead ends, construct parameterized
examples showing unrecognized dead ends arbitrarily deep. several
domains, individual instances fall different classes. case associate
overall domain worst-case class, i.e., class highest index above.
example, Miconic-ADL, additional constraints obeyed
transportation passengers state space harmless Miconic-SIMPLE.
constraints on, example, possible direction travel access floors
given, unrecognized dead ends arise. avoid clumsy language, henceforth,
say state space harmless/recognized/unrecognized, mean falls
respective class, class it.
get definitions general topological phenomena, i.e., relevant properties search space surface. adapt definitions given SAT Frank et al.
(1997). difference SAT framework there, planning formalism here,
lies possibly single-directed state transitions planning. search spaces considered Frank et al., state transitions traversed directions. Single-directed
695

fiHoffmann

state transitions important impact search space topology, enabling,
example, existence dead ends.8
base entity state space topology Frank et al. name plateaus.
regions equivalent reachability aspects, look point
view heuristic function. l N {}, plateau P level l maximal subset
induced subgraph (S, ) strongly connected, h(s) = l
P .9 Plateaus differ terms possibilities leaving heuristic level, i.e.,
reaching exit. plateau P level l, exit state reachable P ,
h(s) = l exists state s0 , (s, s0 ) , h(s0 ) < h(s). Based behavior
respect exits, distinguish five classes plateaus. need notion
flat paths. paths (S, ) value h remains constant.
1. recognized dead end plateau P level l = .
2. local minimum plateau P level 0 < l < exit reachable
flat path.
3. bench plateau P level 0 < l < , least one exit reachable
P flat path, least one state P exit.
4. contour plateau P level 0 < l < consists entirely exits.
5. global minimum plateau P level 0.
plateau belongs exactly one classes. Intuitively, roles different
kinds plateaus play heuristic search following. Recognized dead ends
ignored completeness-preserving heuristic function. Local minima difficult
neighbors look worse, clear direction move next. Benches
potentially easier, one step without temporarily worsening
heuristic value. contours, one step immediately.10
main difficulty heuristic search deal local minima
benches. cases, search algorithm must (eventually) find path exit
order get closer goal (as far heuristic function informed
closer goal not). difficult find exit assessed
variety different parameters. size (number states) diameter (maximum distance
two states) local minimum/the bench, number nearby exit
states, name important ones. benchmarks considered, mentioned
introduction, empirically found (or few) interesting observations
made parameters (Hoffmann, 2001b, 2003b).
8. One can, course, introduce backtracking mechanisms search space, always giving
planner possibility retract last step. affect relevant topological differences
search spaces instead domains with/without dead ends, one gets domains backtracking
necessary/not necessary.
9. difference undirected case require states plateau strongly connected
undirected state transitions trivially fulfilled set connected states.
10. differences undirected case lie plateaus level , allow exits
lie plateaus themselves. latter minor technical device obtain compact
terminology.

696

fiWhere Ignoring Delete Lists Works

one frequently observe interesting properties distance nearest
exit state. distance dist(s, s0 ) two states s, s0 usual graph
distance, i.e., length shortest path s0 (S, ),
path. exit distance ed(s) search state distance nearest exit, i.e.:
ed(s) = min{d | length path (S, ) state s0 s.t. h(s0 ) = h(s),
exists state s00 s.t. (s0 , s00 ) , h(s00 ) < h(s0 ) },
where, before, minimum empty set . Note require
path definition flat, i.e., may that, order reach s0 , temporarily
increase h+ value. want definition capture possible
escape routes state state space, including states lie local minima.
maximal local minimum exit distance, mlmed(S, ), state space (S, )
maximum exit distances states local minima, 0
states. maximal bench exit distance, mbed(S, ), state space (S, ) maximum
exit distances states benches, 0 states. find
that, many considered domains, constant upper bounds mlmed(S, )
and/or mbed(S, ) h+ , i.e., bounds valid irrespectively (size the)
instance chosen.
following implication relevant subsequent investigation.
Proposition 1 Given solvable task (A, I, G), state space (S, ) completenesspreserving heuristic h, h(s) = 0 gd(s) = 0 S. exists unrecognized
dead end S, mlmed(S, ) = .
Proof: Let unrecognized dead end, let s0 state reachable
h value s0 minimal. s0 unrecognized dead end, (in particular,
considered reachable itself), since h(s0 ) = 0 gd(s0 ) = 0 h(s0 ) > 0.
have, since h value s0 minimal among states reachable s,
h(s00 ) h(s0 ) states s00 reachable s0 . Thus plateau s0 lies local
minimum exits reachable, particular flat paths. also shows s0
infinite exit distance.
2
Proposition 1 says that, every region unrecognized dead ends, local
minimum, given h(s) = 0 gd(s) = 0.11 definitions, unrecognized
dead end state yields infinite local minimum exit distance. makes sense define
things way (arbitrarily deep) unrecognized dead end worse local
minimum: escaped all.
11. Remember latter untrue h+ domain features derived predicates
appear negated negation normal form goal condition. even then, argument
proposition, every region unrecognized dead ends would contain global minimum consisting
non-solution states. could defined fake-global minima local minima, decided
order overly complicate topological definitions, since detail
seem important. said before, one 30 domains h+ (s) = 0 gd(s) = 0
anyway.

697

fiHoffmann

3. Core Lemmas
many investigated domains, intuitively similar patterns problem structure cause
characteristic qualities h+ . common structure generalized
captured concise definitions lemmas. lemmas formulate sufficient criteria implying (the state space of) planning task certain topological properties. Proofs
domains proceed, possible, applying lemmas arbitrary instances.
several domains lemmas applied immediately (due syntactic details
domain definitions), similar proof arguments suffice show desired topological
properties.
restrict STRIPS tasks lemmas. Appropriate extensions ADL
and/or derived predicates probably possible least certain cases,
investigated detail extensions likely rather complicated notationally,
simpler STRIPS case suffices transport ideas.

initial state:
at(V, L1 ), at(O1 , L1 ), at(O2 , L2 )
goal:
at(O1 , L2 ), at(O2 , L1 )
actions:
name
precondition
move(l, l0 )
at(V, l)
load(o, l)
at(V, l), at(o, l)
unload(o, l) at(V, l), in(o, V )

add list
at(V, l0 )
in(o, V )
at(o, l)

delete list
at(V, l)
at(o, l)
in(o, V )

Figure 2: simple STRIPS transportation task.
Throughout section, assume given STRIPS task (A, I, G). illustrative example definitions lemmas, use simple transportation task
defined Figure 2. follows, three separate sections, concerned dead
ends, local minima, benches, respectively.
definitions lemmas following syntactical, sense
make use informations computed efficiently (for example, inconsistencies
facts). discuss this, focus exclusively role definitions
lemmas tools proving h+ topology. role definitions lemmas
tools automatically detecting h+ topology discussed Section 6.
3.1 Dead Ends
first focus criteria sufficient non-existence dead ends. starting point
reformulated version simple result mentioned by, example, Koehler Hoffmann
(2000). need notion inconsistency. Two facts inconsistent
reachable state contains them. set facts F inconsistent another set
698

fiWhere Ignoring Delete Lists Works

facts F 0 fact F inconsistent least one fact F 0 .12 action
invertible if:
(1) add(a) inconsistent pre(a);
(2) del(a) pre(a);
(3) action
(a) pre(a) (pre(a) add(a)) \ del(a),
(b) add(a) = del(a),
(c) del(a) = add(a).
intentions behind requirements following. (1) (2) ensure
effects occur, (3a) ensures applicable, (3b) (3c) ensure
undoes effects. example, actions illustrative task Figure 2
invertible. example, = move(l, l0 ) action inverted = move(l0 , l). see that,
simply insert definitions: add(a) = {at(V, l0 )} inconsistent pre(a) = {at(V, l)};
del(a) = {at(V, l)} = pre(a); pre(a) = {at(V, l0 )} = add(a); add(a) = {at(V, l)} = del(a);
del(a) = {at(V, l0 )} = add(a). Similarly easily, one sees load(o, l) unload(o, l)
invert other. Examples benchmark domains invertible actions Blocksworld
(in variants), Logistics, Gripper.
Lemma 1 [Koehler & Hoffmann, 2000] Given STRIPS planning task (A, I, G).
actions invertible, state space task undirected.
Proof: state applicable action a, applicable Result(s, hai) due
condition (3a) invertibility. Conditions (1) (2) make sure effects fact
appear (condition (1) requires fact add list inconsistent least one
fact precondition), conditions (3b) (3c) make sure undoes exactly
effects.
2
remark that, contrast one may think first sight, task
undirected state space even actions invertible sense. Imagine,
example, action del(a) = {p} pre(a) = {p0 }, and, due domain
semantics, p0 true p also true. means delete effect always appears;
however, detected simple syntax check, del(a) pre(a), used
definition above.
next provide new criterion weaker broadly applicable
Lemma 1, implies non-existence dead ends. criterion based
weaker version invertibility, two alternative properties whose combination
make action safe.
make action lead dead end, already sufficient inverse action
re-achieves least deleted, delete facts true
12. may seem natural define inconsistency fact sets symmetrical fashion, demanding
every fact F inconsistent every fact F 0 . context here, definition would
stronger need.

699

fiHoffmann

before. is, given state applicable, applying Result(s, hai) leads
us back state s0 satisfies s0 s. Formally, action least invertible
action that:
(1) pre(a) (pre(a) add(a)) \ del(a),
(2) add(a) del(a),
(3) del(a) inconsistent pre(a).
Condition (1) ensures, before, applicable Result(s, hai). Condition
(2) ensures re-achieves every fact deleted a. Condition (3) ensures
facts deleted true anyway. Note invertible action
also least invertible. Conditions (1) (2) obviously given. condition (3),
del(a) = add(a) (condition (3c) invertibility), add(a) inconsistent pre(a)
(condition (1) invertibility), del(a) inconsistent pre(a). invertible
stronger least invertible; chose name least latter illustrate
that, definition invertibility, potentially re-achieves facts
original state s.
example, consider happens modify move(l, l0 ) action Figure 2
include visited(l0 ) fact add list. resulting action longer invertible
move(l0 , l) delete visited(l0 ). apply, state s, move(l, l0 ) move(l0 , l)
sequence, gets us state s0 identical except also
includes visited(l) visited(l0 ), may true before. Move actions
kind form Simple-Tsp domain. least invertible sense:
pre(move(l0 , l)) = {at(V, l0 )} = add(move(l, l0 )); add(move(l0 , l)) = {at(V, l), visited(l)}
{at(V, l)} = del(move(l, l0 )); del(move(l, l0 )) = {at(V, l0 )} inconsistent {at(V, l)} =
pre(move(l, l0 )).
Another property implying action lead dead ends this.
action must applied (because add effects remain true), deletes
nothing preconditions, action needs inverted. Formally,
action static add effects if:
[

add(a)

del(a0 ) = .

a0

action relevant delete effects, if:
del(a) (G

[

pre(a0 )) 6= .

a6=a0



del(a) (G a6=a0 pre(a0 )) = , say relevant delete effects,
property actually interested in. illustrative task Figure 2,
imagine disallow unloading object initial location, loading object
goal location. remaining unload actions (unload(O1 , L2 ) unload(O2 , L1 ))
static add effects action delete goal position object relevant
delete effects action needs object vehicle respective
unload goal location. Actions characteristics are, example,
700

fiWhere Ignoring Delete Lists Works

actions make passengers get lift Miconic-STRIPS (a passenger get
lift his/her origin floor, get lift his/her destination
floor). Another example contained Tireworld domain, action
inflates flat wheel: de-flating action add effects static;
action goal needs wheel flat relevant delete effects.
Lemma 2 Given solvable STRIPS planning task (A, I, G). holds actions
either
1. least invertible,
2. static add effects relevant delete effects,
state space task harmless.
Proof: short, reachable state = Result(I, ha1 , . . . , i) plan constructed
inverting ha1 , . . . , (applying respective inverse actions inverse order),
executing arbitrary plan (A, I, G) thereafter. processes, actions
(at least) invertible skipped prerequisite static add effects
relevant delete effects.
detail, proof argument proceeds follows. reachable state =
Result(I, ha1 , . . . , i) S, identify solution P (A, s, G). Let hp1 , . . . , pm
solution (A, I, G) (which exists (A, I, G) solvable prerequisite). construct
P algorithm shown Figure 3.
:=
:= n . . . 1
ai least invertible ai
ai 6 apply ai endif
else := {ai }
endif
endfor
:= 1 . . .
pi 6 apply pi endif
endfor
Figure 3: Constructing plans tasks actions either least invertible,
static add effects relevant delete effects.
algorithm, serves kind memory set actions could
inverted. need prove preconditions applied actions fulfilled
state applied, goals true upon termination. Let us start
first loop. denote si := result(I, ha1 , . . . , ai i) state executing
701

fiHoffmann

ith action path s, s0i state first loop starts value i.
prove:
[
[
s0i (si (G
add(a)
pre(a)))
aMi

aA\Mi

Mi denotes current state set. proceed backward induction i.
= n, got s0i = si Mi = , equation trivially true. assume
equation true 1. prove equation holds 1. ai least
invertible, action applied, s0i1 = s0i , Mi1 = Mi {ai }. Concerning
left hand side expression right hand side equation, observe ai

prerequisite delete fact G aA\Mi1 pre(a) (Mi1 contains ai ),
relevant facts si1 already true s0i . Concerning right hand side
expression right, observe facts add(ai ) never deleted

prerequisite, aMi1 add(a) contained s0i . assume ai least invertible
ai . got Mi1 = Mi . Assume ai applied, i.e., ai 6 Mi . applicable
preconditions contained si , element Mi . resulting state
s0i1 , facts ai deleted si1 added, facts deleted
true si1 anyway; also, none add effects actions Mi deleted,
equation fulfilled. Finally, ai applied, ai Mi , ai static add effects
applied before, add effects contained s0i , ai delete effects empty.
Inserting = 0 equation proved, get
s0 (I (G

[

pre(a)))

aA\M0

[

add(a)

aM0

second loop starts s0 . start solution plan, excluding actions
set M0 , state including initial facts contained goal
precondition action M0 . state additionally contains add effects
actions M0 , add effects deleted action, clear
simply skip actions M0 achieve goal.
2
example illustrate proof, consider reachable state Tireworld domain.
Every action invertible, except action inflates wheel. Say, proof,
state reached action sequence ha1 , . . . , i. algorithm Figure 3
is, undo everything done, applying respective ai actions, except
inflating actions ai . latter stored set . gets us state
identical initial state, except already inflated flat
wheels (those corresponding actions ). state, algorithm executes
arbitrary solution, skipping previously applied inflating actions (in ).
3.2 Local Minima
define important kind relationship role action real task
role relaxed task. Combining definition notions least
invertible actions, (no) relevant delete effects, yields criterion sufficient
non-existence local minima h+ (or, equivalently, 0 upper bound
maximal local minimum exit distance). criterion directly applied 7
702

fiWhere Ignoring Delete Lists Works

30 investigated domains, applied slight modifications 2 domains.
Many individual proofs make use similar, albeit somewhat complicated,
proof arguments.
key property behind lack local minima h+ is, time,
every action good solving real task also good solving relaxed task.
Formally, action respected relaxation if:
reachable state starts optimal plan (A, s, G),
optimal relaxed plan (A, s, G) contains a.
Note one assume relaxed plan start a, since relaxation
better apply action earlier.
actions illustrative task Figure 2 respected relaxation. Consider move(l, l0 ) actions, example. If, state s, optimal plan starts
move(l, l0 ), must good reason this. Either a) l0 object
yet transported, b) object truck must transported l0 .
cases, relaxed plan must also transport object, chance
without moving l0 point. Similarly, optimal plan starts load(o, l)
action, means must transported somewhere else, relaxed plan
get around loading it. Finally, optimal plan starts unload(o, l) action,
means l goal location o, relaxed plan include
action.
Similar arguments applied many transportation domains.
argument regarding move actions becomes little complicated non-trivial
road maps, unlike illustrative example two locations
reachable single step other. Say road map (any) directed graph,
modify move action Figure 2 add precondition fact
demanding existence edge l l0 . move actions still respected
relaxation, ignoring delete lists affect shape road map.
optimal real path location l location l0 coincides optimal relaxed path
movements l l0 (even though result executing path different).
there, claim follows argument above, namely, optimal
plans moves l l0 object provides reason so.
transportation domain features additional constraints on, side effects of, move
actions, may respected relaxation. give example below,
formulating main lemma regarding local minima h+ .
Note exist local minima even actions respected relaxation.
Consider following transportation task, featuring single-directional edges road
map graph. argued above, actions respected relaxation. vehicle
two objects o1 , o2 initially l; o1 must go l1 o2 must go l2 ; edge l
l1 single-directed edge l l2 single-directed; l1 l2 ,
path n bi-directional (undirected) edges. optimal relaxed plan state
where, initial state, o1 o2 loaded, length 4: move l l1 l2 ,
unload o1 o2 l1 l2 , respectively. However, one moved, s, either l1
l2 , optimal relaxed plan length goes n + 2, since entire path l1
703

fiHoffmann

l2 must traversed. lies local minimum, given n > 2; note that, setting
n arbitrarily high values, get local minimum arbitrarily large exit distance.
turns preventing example, precisely, making use notions
invertibility relevant delete effects, introduced above, suffices get rid local
minima h+ .
Lemma 3 Given solvable STRIPS task (A, I, G), state space (S, )
contain unrecognized dead ends. action
1. respected relaxation,
2. least invertible relevant delete effects,
local minima (S, ) evaluation h+ .
Proof: states gd(s) = local minima prerequisite, h+ (s) = .
prove that, every reachable state 0 < gd(s) 6= , action starts
optimal plan (A, s, G), h+ (Result(s, hai)) h+ (s). proves lemma:
iterating argument, obtain path goal state s0 , value h+
increase path. means exit reachable flat path
h(s0 ) = 0 < h(s) point path h+ value becomes lower h(s), thus
lie local minimum.
Let reachable state 0 < gd(s) 6= . Let action starts
optimal plan (A, s, G). denote s0 := Result(s, hai). action respected
relaxation, optimal relaxed plan P + (s) (A, s, G) starts a.
Case (A), removing P + (s) yields relaxed plan (A, s0 , G). h+ (s0 ) <
+
h (s) follows, finished. case, particular, relevant delete
effects: facts deletes needed action goal, P + (s)
without achieves goal starting s0 (where already applied).
Case (B), assume removing P + (s) yield relaxed plan s0 . Then,
said before, relevant delete effects, must thus least
invertible. is, action pre(a) (pre(a) add(a)) \ del(a)
add(a) del(a). action guaranteed applicable s0 , re-achieves
delete effects. Denote P + (s0 ) action sequence results replacing, P + (s),
a. P + (s0 ) relaxed plan (A, s0 , G). seen follows. Observe
that, definition, P + (s) without relaxed plan Result(s, ha+ i) (we abbreviate
notation somewhat improve readability). desired property follows
Result(s0 , ha+ i) superset Result(s, ha+ i): Result(s, ha+ i) = add(a),
s0 = (s add(a)) \ del(a), add(a) del(a). P + (s0 ) relaxed plan (A, s0 , G),
yielding h+ (s0 ) h+ (s).
2
proof Lemma 3 demonstrates along lines, typically, proof arguments
investigation proceed. Given state s, consider action starts optimal
plan s, consider optimal relaxed plan P + (that contains a, ideally). Then,
determine P + modified obtain relaxed plan state results
execution. technique forms basis literally proofs except concerned
dead ends. Note second prerequisite Lemma 3 fulfilled planning
704

fiWhere Ignoring Delete Lists Works

tasks qualifying undirectedness harmlessness criteria given Lemmas 1 2.
Note also that, said above, proved state space
illustrative example Figure 2 undirected, contain local minima
h+ .
Domains actions respected relaxation are, example, STRIPS
transportation domains Logistics, Gripper, Ferry, Miconic-STRIPS. cases,
respective proof arguments similar said above. instructive
look examples action respected relaxation.
transportation domain, can, example, happen due fuel usage side effect
moving. Concretely, Mystery domain, applying move action deletes fuel unit
start location (the location move starts). fuel running low
locations, (real) plan may move along fuel-rich deviations road map.
relaxed plan need always move along shortest connections
map because, there, actions delete fuel units.
Formulated somewhat generally, relaxed plans take short-cuts dont
work reality. short-cuts disjoint (in starting actions) real solution
paths, local minima may arise even actions (at least) invertible.
discussed transportation case, short-cuts correspond intuitive manner
one tends think short-cuts (on road map, namely). case
general, i.e., kinds domains. Consider Blocksworld-arm state depicted
Figure 4.

C
B

C



B

Figure 4: local minimum state Blocksworld-arm. goal B table,
C B.

depicted state, denoted s, B table, arm holds C.
goal B table, C B.13 optimal plan put C
table, unstack B put table, pickup C stack
onto B. optimal relaxed plan s, however, stack C onto B immediately,
unstack B A, put B table. short-cut
relaxed plan put C table, stacking C onto B
delete fact declares Bs surface unoccupied. result, lies local
13. Usually, Blocksworld goals demanding block table. example,
done sake simplicity: one could introduce one block demand B
goal.

705

fiHoffmann

minimum h+ .14 reason, intuitively, h+ yield local minima
many domains, vicious short-cuts like example dont happen.
3.3 Benches
could find nice general sufficient criterion implying upper bounds maximal
exit distance local minima except special case local
minima thus 0 upper bound maximal local minimum exit distance.
did, however, find simple proof argument determining upper bound maximal
exit distance benches, tasks qualify application Lemma 3. proof
argument works, sometimes slight modifications, 7 domains Lemma 3
directly applied domains, maximal bench exit distance bounded
1 (bounded 0, one case).
proof argument based observing that, many domains, actions
delete effects irrelevant (for relaxed plan, least) action
applied optimal solution path. Formally, action relaxed-plan relevant
delete effects if:
reachable state starts optimal plan (A, s, G),

optimal relaxed plan ha, a1 , . . . , (A, s, G) del(a) (G ni=1 pre(ai )) = .
If, reachable state starts optimal plan (A, s, G),

optimal relaxed plan ha, a1 , . . . , (A, s, G) del(a) (G ni=1 pre(ai )) = ,
say relaxed-plan relevant delete effects, property
actually interested in. notation, relaxed-plan relevant delete effects,
starts optimal plan s, relaxed plan Result(s, hai) constructed
sequence ha1 , . . . , i, i.e., skipping relaxed plan s. Thus h+
value decreases Result(s, hai). Note n set 0 results goal
state s. Note also that, definition, action relaxed-plan relevant delete
effects respected relaxation; action respected relaxation,
claim anything h+ anyway. Note finally that, assuming action
respected relaxation, relevant delete effects, i.e., delete
goal precondition another action, also relaxed-plan relevant delete
effects sense definition.
Consider illustrative example Figure 2. Say state
load(o, l) starts optimal plan. means yet transported, location
l0 6= l. particular, means at(o, l) goal, follows action
whose delete effect at(o, l) relevant delete effects (no action
at(o, l) precondition). Further, say unload(o, l) starts optimal plan s.
means l goal location o. applying action, goal
achieved, action need refer again, particular action require
inside vehicle, delete effect unload(o, l). action neither
14. h+ (s) = 3. h+ value after, s, putting C table 4 (any relaxed plan
apply two actions two goals). h+ value stacking, s, C onto B still 3 (the
relaxed plan unstack C B, unstack B A, put B), successor state
unstack C B again, going back s.

706

fiWhere Ignoring Delete Lists Works

relaxed-plan relevant delete effects. contrast, consider move(l, l0 ) action,
deletes at(V, l). Say state O1 loaded V initial
state task. move(L1 , L2 ) starts optimal plan s, relaxed plan
Result(s, hmove(L1 , L2 )i) include action move(L2 , L1 ), moving back L2
L1 order able transport O2 . delete effect move(L1 , L2 ), namely
at(V, L1 ), relaxed-plan relevant.
If, task satisfying prerequisites Lemma 3, optimal starting action
relaxed-plan relevant delete effects, one apply case (A) proof Lemma 3,
obtain smaller h+ value. bound maximal exit distance benches,
need identify maximum number steps happen.
Lemma 4 Given solvable STRIPS task (A, I, G) satisfies prerequisites
Lemma 3. Let constant that, every non dead-end state S,
optimal plan ha1 , . . . , d-th action, ad , relaxed-plan relevant delete effects. mbed(S, ) 1.
Proof: Let reachable state 0 < gd(s) 6= . Let ha1 , . . . , optimal plan
(A, s, G), ad relaxed-plan relevant delete effects. Denote, 0 n,
si := Result(s, ha1 , . . . , ai i). argumentation Lemma 3, h+ (si ) h+ (s)
i. Consider state sd1 . prerequisite, optimal relaxed plan

0
(A, sd1 , G) form , a01 , . . . , a0m i, del(ad ) (G
i=1 pre(ai )) = .
0
0
+
+
then, obviously, ha1 , . . . , relaxed plan sd , h (sd ) h (sd1 ) 1.
distance sd1 1, lemma follows.
2
Lemma 4 directly applied 5 7 domains qualify Lemma 3.
proof argument can, somewhat general version, applied 2 domains
well namely, Ferry Gripper, loading object deletes space vehicle
one domain namely, Miconic-SIMPLE, uses simple ADL constructs.
domains proved upper bound maximal exit distance
benches (and/or upper bound maximal exit distance local minima),
proof arguments (a lot, sometimes) complicated. Reconsidering illustrative
example, stated load unload actions relaxed-plan relevant delete
effects, move actions do. Now, obviously, since two locations accessible
single move, optimal plan applies one move action
row, i.e., optimal plan first second action load/unload.
Lemma 4 tells us maximal exit distance benches bounded 1.
similar argument applied transportation domains every pair
locations connected via single move (as in, example, Logistics). generally,
(the standard encoding of) transportation domain constraints (regarding,
example, fuel), undirected road map graph, exit distance bounded
diameter road map graph, i.e., maximum distance two locations
(nodes) graph. worst thing solution plan might traverse
entire road map loading/unloading object.15
15. directed road map graphs, explained above, local minima arise. technically, Lemma 3
applied, Lemma 4 applied either.

707

fiHoffmann

4. Planning Domain Taxonomy
list proved results, brief explanations obtained results.
summarize results form planning domain taxonomy.
group positive results prove non-existence topological
phenomena problematic heuristic search together single theorems.
negative results shown separately sketching counter examples. consider dead
ends, local minima, benches order. Remember that, respect dead ends,
problematic case heuristic search unrecognized dead ends, c.f.
Section 2.3.
Theorem 1 state space solvable instance
1. Blocksworld-arm, Blocksworld-no-arm, Briefcaseworld, Depots, Driverlog, Ferry,
Fridge, Gripper, Hanoi, Logistics undirected,
2. Grid, Miconic-SIMPLE, Miconic-STRIPS, Movie, Pipesworld, PSR, Satellite,
Simple-Tsp, Tireworld, Zenotravel harmless,
3. Dining-Philosophers, Optical-Telegraph, Rovers, Schedule recognized evaluation h+ .
Blocksworld-arm, Blocksworld-no-arm, Driverlog, Ferry, Gripper, Hanoi, Logistics, Lemma 1 directly applied. Briefcaseworld, Depots, Fridge, due
subtleties actions invertible syntactical sense, easy show
every action inverse counterpart. Movie, Miconic-STRIPS, Simple-Tsp,
Tireworld, Lemma 2 directly applied, Grid Miconic-SIMPLE similar proof
arguments used Lemma 2 suffice. Pipesworld, PSR, Satellite, Zenotravel,
easy-to-see individual domain properties prove absence dead ends. domains dead ends recognized h+ , individual domain properties exploited
proofs somewhat involved. example, Rovers plan state
if, soil/rock samples images need taken, rover
job, communicate gathered data lander.
chance run dead end take soil/rock sample rover reach
lander (the soil/rock sample available once). then, relaxed plan
state either.
6 domains mentioned Theorem 1 (Airport, Assembly, Freecell, MiconicADL, Mprime, Mystery), easy construct arbitrarily deep unrecognized dead ends
(arbitrarily long paths unrecognized dead ends). example, Mystery Mprime
relaxed plan still achieve goal situations much fuel consumed
already; Airport, two planes block others paths may move across
relaxed plan.
positive results regarding local minima these.
Theorem 2 h+ , maximal local minimum exit distance state space
solvable instance
708

fiWhere Ignoring Delete Lists Works

1. Blocksworld-no-arm, Briefcaseworld, Ferry, Fridge, Grid, Gripper, Hanoi, Logistics,
Miconic-SIMPLE, Miconic-STRIPS, Movie, Simple-Tsp, Tireworld 0,
2. Zenotravel 2, Satellite 4, Schedule 5, DiningPhilosophers 31.
Ferry, Gripper, Logistics, Miconic-STRIPS, Movie, Simple-Tsp, Tireworld,
Lemma 3 applied. Fridge Miconic-SIMPLE, actions adhere syntactically definitions invertibility (no) relevant delete effects, similar
semantics. Lemma 3 directly applied, similar arguments suffice: easy
see actions respected relaxation, proof Lemma 3 individually adapted take account particular properties regarding invertibility
relevant delete effects. (For example, passenger gets lift Miconic-SIMPLE,
delete effect passenger longer inside lift, matter
since passenger reached destination.) Blocksworld-no-arm, Briefcaseworld,
Grid, rather individual (and sometimes quite involved) arguments prove absence
local minima h+ . proof method is, cases, consider state
identify flat path state better h+ value. example, Grid done
moving along path locations contained relaxed plan s, key
picked up/put down, lock opened (this simplified description,
actual procedure quite complicated). Hanoi, one prove optimal relaxed
solution length state equal number discs yet final
goal position. suffices optimal plan moves disc away final position. Note that, thus, Hanoi state spaces h+ sequence benches decreasing
exponentially diameter size.
Zenotravel, Satellite, Schedule, proofs proceed identifying constant
number steps suffices execute one action optimal relaxed plan state
s, and, without deleting relevant add effects, re-achieve relevant facts
deleted a. Dining-Philosophers (as well Optical-Telegraph), due subtleties
PDDL encoding was, said, obtained automatic compilation
automata-based Promela language (Edelkamp, 2003a) h+ loosely connected
goal distance: relaxation, automaton (for example, philosopher) always
block 3 actions. bound Dining-Philosophers follows
rather constant restrictive domain structure, constant number process
transitions, namely 6, always suffices block one philosopher. proved bound
derived this, considering 4 planning actions needed process
transition, certain additional actions may needed due subtleties
PDDL encoding (where process two internal states). remark
bound valid even trivial heuristic function returning number yet
un-blocked philosophers. fact, proof h+ viewed corollary proof
heuristic function; get back end section. finally remark
highest exit distance h+ could actually construct Dining-Philosophers
15. conjecture (tight) upper bound.
Satellite, Schedule, Zenotravel, proved upper bounds tight.
Dining-Philosophers, Satellite, Schedule, Zenotravel, bounds valid nondead end state s. So, beside bound local minimum exit distance, results
709

fiHoffmann

also provide bound bench exit distance, re-used
section.
Airport, Assembly, Freecell, Miconic-ADL, Mprime, Mystery, stated
unrecognized dead ends, Proposition 1 local minimum exit distance
domains unbounded. domains mentioned Theorem 2, i.e.,
Blocksworld-arm, Depots, Driverlog, Optical-Telegraph, Pipesworld, PSR, Rovers, one
construct local minima arbitrarily large exit distances. complicated
example Optical-Telegraph, where, difference Dining-Philosophers, one construct
situations number process state transitions needed block one process
arbitrarily high. Optical-Telegraph basically version Dining-Philosophers
complicated philosophers, freedom next. freedom enables
situations whole row philosophers table must perform two transitions
order block one philosopher. Details Appendix A.2. simpler example
Blocksworld-arm (as well Depots, Blocksworld-arm situations embedded).
Consider following situation. n blocks b1 , . . . , bn initially form stack
bi bi+1 bn table. goal build stack top
another block bn+1 , i.e., goal stack b1 , . . . , bn , bn+1 . Reaching, initial state,
state better h+ value involves disassembling entire stack b1 , . . . , bn .
disassembling process, h+ increases. Note basically extended version
illustrative example Figure 4.
interesting side remark, note proved topological difference
Blocksworld-arm Blocksworld-no-arm: latter, local minima
h+ , former, exit distance arbitrarily large.
intriguing, quite clear general message learn it. One might
interpret telling us, formal way, encoding details significant impact
topology, search performance. FF, example, much efficient
Blocksworld-no-arm Blocksworld-arm. noted, however, two
domains differ also semantically, namely plans Blocksworld-no-arm half
long plans Blocksworld-arm. practical point view, would interesting
explore Blocksworld observation generalized encoding methods trying
model domain way making best suited h+ . said
Section 7.
positive results regarding benches these.
Theorem 3 h+ , maximal bench exit distance state space solvable
instance Simple-Tsp 0, Ferry 1, Gripper 1, Logistics
1, Miconic-SIMPLE 1, Miconic-STRIPS 1, Movie 1,
Zenotravel 2, Satellite 4, Schedule 5, Tireworld
6, Dining-Philosophers 31.
Simple-Tsp, Ferry, Gripper, Logistics, Miconic-STRIPS, Movie, Tireworld,
Lemma 4 directly applied. Determining actions (no) relaxed-plan relevant delete effects easy domains; Tireworld somewhat complicated
see when, latest, action applied optimal plan. MiconicSIMPLE, similar arguments Lemma 4 suffice. Zenotravel, Satellite, Schedule,
Dining-Philosophers, respective bounds shown already.
710

fiWhere Ignoring Delete Lists Works

Note that, Simple-Tsp, proved local minima exit
distance 0. implies h+ is, fact, identical real goal distance: entire
state space consists contours global minima.
topological distinctions divide planning domains taxonomy classes
differ terms behavior state spaces respect h+ . visualization
taxonomy, results 30 investigated domains, given Figure 5.

Blocksworldarm
Depots
Driverlog

Pipesworld
PSR

Rovers
OpticalTelegraph

Mystery
Mprime
MiconicADL
Freecell
Assembly
Airport

mbed <= c

mlmed <= c

Hanoi [0]
Blocksworldnoarm [0]
Fridge [0]
Grid [0]
Briefcaseworld [0]

Logistics [0,1]
Ferry [0,1]
Gripper [0,1]
undirected

Tireworld [0,6]
Satellite [4,4]
Zenotravel [2,2]
MiconicSIMPLE [0,1]
MiconicSTRIPS [0,1]
Movie [0,1]
SimpleTsp [0,0]
harmless

DiningPhil. [31,31]
Schedule [5,5]

recognized

unrecognized

Figure 5: planning domain taxonomy, overviewing results.
taxonomy, shown Figure 5, two dimensions. x-axis corresponds
four dead end classes. y-axis corresponds existence non-existence constant
upper bounds local minimum exit distance, bench exit distance. Note
visualization makes simplifying assumption domains bounded
bench exit distance subset ones bounded local minimum exit distance.
assumption justified general, holds true specific collection domains.
Also, question whether bound difficulty escaping benches
seem relevant when, anyway, arbitrarily difficult escape local minima.16
specific bounds proved individual domains given parentheses, local minimum
exit distance bound preceding bench exit distance bound cases both.
bottom right corner taxonomy crossed domain belong
respective classes.17
16. Similarly, benches arbitrarily large relevant local minima
small non-existent. sense respective results Briefcaseworld, Fridge, Grid, Blocksworldno-arm, Hanoi moderately important. Still constitute interesting properties
domains.
17. Proposition 1, existence unrecognized dead ends implies non-existence constant upper
bounds local minimum exit distance, given states gd(s) 6= 0 h+ (s) = 0.
states exist, domain features derived predicates appear negated negation

711

fiHoffmann

Figure 5 suggests h+ -approximating heuristic planners fast
many common benchmark domains lie easy regions taxonomy.
concretely, described introduction, provided h+ function, FFs
search algorithm enforced hill-climbing polynomial domains located lowermost classes taxonomy (i.e., domains constant bounds maximal
exit distances). empirical perspective, distinction lines taxonomy
coincide quite well practical performance FF. FF excels 11 12 domains
belong lowermost classes taxonomy (the difficult domain DiningPhilosophers, whose upper bound exceptionally high). 5 middle domains (no
local minima potentially large benches) FF performs well, scale
comfortably easier domains. complex domains: Blocksworld-arm,
Depots, Driverlog, Optical-Telegraph, Pipesworld, PSR amongst challenging domains FF. Mprime Mystery, FF performs bad
planners. Freecell Miconic-ADL, FF among top performing planners, often
runs unrecognized dead ends larger instances (for example, larger Freecell
instances used AIPS-2000). Airport, Assembly Rovers, FF performs pretty well
respective competition example suites; however, domains competition suites
hardly explore worst-cases domain topology (details Appendix A).
discuss detail relation taxonomy empirical performance heuristic planners make use h+ approximation one
way. One observation definitely made planners
trouble solving instances domains extreme h+ properties.
Simple-Tsp, Ferry, Gripper, Logistics, Miconic-SIMPLE, Miconic-STRIPS, Movie,
extent also Zenotravel, planners scale comfortably. particular,
scale much comfortably domains typically
domains, least without additional (for example, goal ordering) techniques.
next section, treat connection taxonomy FFs performance
analytical way, relating properties h+ properties FFs approximation
h+ , called hF F . so, remarks relation taxonomy
complexity theory order. question whether provable relation, i.e.,
relation distinction lines taxonomy, complexity deciding
plan existence respective domains. able construct NP-hard domain
(a domain deciding plan existence NP-hard) h+ yield local
minima; maximal bench exit distance domain is, however, unbounded. tried,
able come NP-hard domain constant bounds
maximal exit distances. remains open question whether domain exists
not. answer yes, lowermost classes taxonomy form group
domains worst-case hard, typically easy solve (at least far

normal form goal condition. even then, presence unrecognized dead ends
would fake-global minima, i.e., global minima consisting non-solution states, fact consisting
unrecognized dead ends.

712

fiWhere Ignoring Delete Lists Works

reflected hitherto benchmarks). answer no, identified
large polynomial sub-class planning.18
Talking polynomial sub-classes, intriguing observation made
trivial heuristic function returning, state s, number goals true
s. Lets call function hG . little thinking, one realizes that, fact,
12 domains proved constant bounds maximal exit distances h+ also
constant bounds hG . hand, remaining 18 30
domains (except Miconic-ADL) easy see constant bounds hG .
Logistics, example, clearly maximum number steps needed achieve one
goal 12: 4 steps (move, load, move, unload) within packages origin city,
origin city destination city, within destination city. DiningPhilosophers, example, upper bound h+ was, said, proved corollary
upper bound hG . Blocksworld, example, clearly take arbitrarily many
steps achieve one goal, namely block must moved buried beneath n
blocks need moved.
observation appears rather significant first sight, probably
important, neither theory practice. one thing, coincidence that,
here, set domains constant bounds h+ set
domains constant bounds hG . simple counter example general
case graph-search domain, task find path two nodes
directed graph, using obvious at-predicate connected-predicate based encoding.
There, h+ equal real goal distance (since one never needs move back),
hG can, clearly, arbitrarily bad. another thing, domains like Logistics
constant exit distance bounds hG , bounds large practically useful.
example, h+ , FF needs look 2 steps forward breadth-first
search iteration enforced hill-climbing, Logistics instance. hG , breadth-first
searches depth 12 would needed. So, most, observation regarding hG
noteworthy statement current planning benchmarks. remains open question
whether (coincidental) correspondence bounds h+ , hG ,
investigated 30 domains, exploited for, e.g., detecting bounds automatically.

5. Relating h+ hF F
discussion relating h+ hF F structured two separate sections. first one
briefly discusses provable relations h+ hF F . second section summarizes
results large-scale empirical investigation aimed identifying extent
topological properties h+ , benchmarks, get preserved hF F .
5.1 Provable Relations h+ hF F
One thing easy observe behavior h+ hF F provably
respect dead ends, i.e., heuristics return cases.
simply heuristics return state iff relaxed plan s.
18. Presumably, prove latter, one would need characterize class purely syntactic manner
level PDDL definitions, since h+ derived directly PDDL syntax. authors wild
guess going work, answer yes.

713

fiHoffmann

h+ follows definition. hF F follows completeness, relative
relaxation, algorithm computes relaxed plans (Hoffmann & Nebel, 2001a).
algorithm relaxed version Graphplan (Blum & Furst, 1995, 1997). state s,
FF runs Graphplan task initial state, delete lists actions
empty. Without delete lists, Graphplan guaranteed terminate polynomial time.
Graphplan terminates unsuccessfully, hF F (s) set . Otherwise, number
actions returned plan taken heuristic value hF F (s) state.19 Graphplan
complete algorithm terminates successfully plan
hF F set iff relaxed plan s. follows dead end classes
benchmarks h+ hF F .
relaxed plans found Graphplan (just general STRIPS) property
optimal terms number parallel time steps, terms
number actions. So, general, hF F h+ (even P NP).
FF uses following heuristic techniques action choice relaxed Graphplan, aiming
minimizing number selected actions (Hoffmann & Nebel, 2001a). First, fact
achieved NOOP (a dummy action propagating fact time step time
step + 1 Graphplans planning graph), NOOP selected. guarantees
every non-NOOP action selected (of course, selected NOOP actions
counted relaxed plan). Second, NOOP available action
minimal precondition weight chosen, weight defined summedup indices first layers appearance (in planning graph) precondition
facts. Third, actions selected parallel time step assumed linearized
order selection; action selected a0 assumed achieve fact
p add(a) pre(a0 ) even a0 selected parallel time step.
two restrictive sub-classes STRIPS hF F provably
h+ . first demands every fact one achiever.
Proposition 2 Let (A, I, G) STRIPS planning task that, facts p,
one action p add(a). Then, states task, h+ (s) = hF F (s).
Proof: proposition follows observation that, running relaxed Graphplan, choice points action selection; choice points always
empty unary case. implies actions selected Graphplan
contained relaxed plan. detail, latter proved induction
regression steps relaxed Graphplan. Let state relaxed
plan. top level regression, actions selected support goals
contained s. goals need supported relaxed plan,
actions so. holds true preconditions selected
actions: p pre(a) s, supporter must present relaxed plan,
supporter selected relaxed Graphplan. Iterating argument, get
desired property. claim follows because, proved Hoffmann Nebel
(2001a), relaxed Graphplan selects every action once.
2
19. Note estimate sequential relaxed plan length. length planning graph built
Graphplan corresponds optimal length parallel relaxed plan, admissible heuristic estimate.
However, indicated before, heuristic functions generally found provide useful
search guidance practice (see, example, Haslum & Geffner, 2000; Bonet & Geffner, 2001b).

714

fiWhere Ignoring Delete Lists Works

second sub-class STRIPS demands one goal,
one precondition per action.
Proposition 3 Let (A, I, G) STRIPS planning task |G| 1 and, A,
|pre(a)| 1. Then, states task, h+ (s) = hF F (s).
Proof: given restrictions, relaxed planning comes finding paths
graph nodes facts, edge p p0 iff action
pre(a) = p add(a) = p0 (empty preconditions modelled special fact
node assumed always true). state relaxed plan iff makes fact node
true path goal node. Relaxed Graphplan identifies shortest
path.
2
prerequisites Propositions 2 3 maximally generous, i.e., relaxing one
requirements, one loses h+ (s) = hF F (s) property. obtain sub-optimal relaxed
plans Graphplan, i.e., construct cases h+ (s) 6= hF F (s), suffices one
fact two achievers, either two goal facts one action two preconditions.
following example. facts g1 , g2 , p, p0 . goal {g1 , g2 },
current state empty. actions shown Figure 6.
name
opg1
opg2 -p
opg2 -p0
opp
opp0

=
=
=
=
=

(pre,

add,

del)

({p},
({p},
({p0 },
(,
(,

{g1 },
{g2 },
{g2 },
{p},
{p0 },

)
)
)
)
)

Figure 6: Actions example task hF F 6= h+ .
optimal relaxed plan hopp, opg1 , opg2 -pi. However, Graphplan might choose
achieve g2 opg2 -p0 , ending (parallel) relaxed plan h{opp, opp0 }, {opg1 ,
opg2 -p0 }i. Note action single precondition, single fact
one achiever, two goals. similar example constructed
case one goal one action two preconditions.
Obviously, syntax allowed either Propositions 2 3 far restrictive
adequate formulating practical domains.20 investigate whether
interesting situations h+ hF F same; intuition
case.
different question whether provable relations h+ hF F (some
of) 30 benchmark domains considered h+ investigation. investigate
question detail note investigation would involve constructing detailed
20. remark syntax identified Proposition 3 sub-class tractable class STRIPS
planning identified Bylander (1994). Bylanders class, constant number g goal facts allowed,
g greater 1; preconditions may positive negative.

715

fiHoffmann

arguments individual domains, clearly beyond scope paper.
None domains captured either Propositions 2 3. results
easy obtain following. Simple-TSP, Movie, Miconic-STRIPS, h+ hF F
same. follows extremely simple structure domains,
finding step-optimal relaxed plans Graphplan always results relaxed plans
optimal number actions. However, even slightly complicated domains
Ferry, Gripper, Logistics, Miconic-SIMPLE, Zenotravel, one easily construct states
Graphplans relaxed plans may unnecessarily long. Miconic-STRIPS
happen single vehicle (the lift), capacity restrictions
(on number loaded objects, i.e., passengers). several vehicles transportable
objects, occur Logistics Zenotravel (as well Driverlog, Depots, Mprime,
Mystery, Rovers), difference h+ hF F become arbitrarily large.
imagine n objects must transported l l0 , n vehicles available
l. parallel relaxed planning, makes difference single vehicle transports
objects, one different vehicle selected per individual object. particular, even
FFs action choice heuristics relaxed Graphplan, hF F may 2n + 1 well 3n.21
Ferry Gripper, single vehicle (with capacity restrictions),
may upper bound difference h+ hF F ;
check detail.
spite above, authors personal experience developing FF that,
least relatively simply structured domains many different operators/different
ways achieve facts, relaxed plans found relaxed Graphplan typically pretty
close optimal. are, presumably, following two reasons this. First,
employed action choice heuristics. example, Grid domain, relaxed plan may
choose pick key k sole purpose dropping picking
another key k0 pickup-and-lose action (c.f. Appendix B.12). happen
selecting actions minimal precondition weight (the pickup-and-lose action
higher weight pickup action unless one already holds k considered state).
Second, many published benchmark instance suites quite restricted. Logistics,
example, situation outlined above, n objects n vehicles waiting location l,
happen trucks single truck city. airplanes,
published benchmark instances usually these, n
small.
5.2 Empirical Relations h+ hF F
large-scale empirical investigation (Hoffmann, 2003b), turned hF F typically
preserves quality h+ . investigation aimed verifying, domains
h+ positive topological property (for example, yielding local minima),
extent property inherited hF F . considered 20 benchmark domains,
namely domains paper hand, except 10 IPC-3 IPC-4 domains.
21. One could circumvent particular phenomenon by, selecting action relaxed Graphplan,
employing minimization summed weight preconditions actions selected far.
topic future work explore effect FFs performance.

716

fiWhere Ignoring Delete Lists Works

Note that, latter 10 domains, three, namely Dining-Philosophers, Satellite,
Zenotravel, positive topological properties.
experimental approach take samples state spaces (a technique adapted
work Frank et al., 1997). precisely, method following.
domain, random generator used produce large set example instances.
instances grouped together according values domain parameters, i.e.,
input parameters generator (for example, number floors number passengers
Miconic-SIMPLE). Then, single instance, 100 states sampled, i.e., 100
random sequences actions executed initial state, sequence length
chosen randomly interval 0 2 times FFs plan length.22
resulting state s, exit distance ed(s) computed breadth-first search, another
search determined whether located valley, i.e., whether path
goal state hF F value decreased monotonically.23 maximal exit
distance instance approximated maximum exit distances
sample states. every group instances, mean number states valleys,
mean maximal exit distance, computed. results visualized plotting
values scaling domain parameters. give examples directly below,
summarizing overall results.
results experiment strongly suggested hF F typically preserves quality
h+ , considered benchmark domains. 13 domains h+ provably yields
local minima, almost sample states located valleys except 2 domains,
namely Grid Hanoi. precisely, 11 domains experiment considered
total 230 groups random instances; one groups, 5.0% sample states
lay valleys, another group 2.2%, another eight groups 1.0%,
remaining 220 groups single valley state found. maximal
exit distance benches, tested instances domains bound
h+ , single sample state exit distance larger bound, namely
exit distance 2 instead 1 Logistics domain.24
Blocksworld-no-arm
Gripper
Hanoi
Tireworld

0.0
0.0
0.0
0.0

0.0
0.0
0.0
0.0

0.0
0.0
96.0
0.0

0.1
0.0
100.0
0.0

0.0
0.0
100.0
0.0

Figure 7: Percentage sample states valleys. Mean values linear increase
respective domain parameter.
Figure 7 provides results regarding sample states valleys, considered
domains local minima (and thus valleys) h+ , in22. tried sampling strategies found make much difference terms
obtained results.
23. Intuitively, local minimum lies bottom valley. used valleys experiment since
may hard find local minimum state sampling.
24. authors guess results similar empirical investigation Dining-Philosophers, Satellite,
Zenotravel would similar, i.e., sampled maximal exit distances would hardly increase
upper bounds proved h+ .

717

fiHoffmann

stances characterized single domain parameter (Movie Simple-Tsp left
since hF F provably h+ ). Blocksworld-no-arm, parameter
number blocks (plus randomization initial goal states); Gripper
number balls transported; Hanoi number discs; Tireworld
number flat tires. domain, left right table entries correspond
linear increase domain parameter (2 . . . 11 blocks, 1 . . . 100 balls, 3 . . . 10 discs,
1 . . . 5 tires, respectively). Obviously, domain behave Hanoi
h+ isnt useful heuristic anyway, yielding large benches, c.f. Section 4.
Blocksworld-no-arm
Gripper
Hanoi
Tireworld

0.3
1.0
6.0
6.0

1.8
1.0
23.0
6.0

2.8
1.0
12.0
6.0

3.8
1.0
2.0
6.0

3.7
1.0
2.0
2.0

Figure 8: Sampled maximal exit distance. Mean values linear increase respective
domain parameter.
Figure 8 shows results regarding sampled maximal exit distance domains
characterized single domain parameter. Gripper Tireworld, sampled values
respect bound valid h+ (in largest Tireworld example, sampling
find maximum state rather large state space). comparison, sampled values
Blocksworld-no-arm, bound h+ , show clear increase. Again,
behavior Hanoi odd.
Figure 9 shows (part of) results domain characterized one
domain parameter, namely Logistics. domains least two domain parameters,
experimental method run one experiment pair them. experiment,
parameters except respective pair set fixed value. data could
visualized 3-dimensional plots like ones Figure 9. figure, parameters
scaled number cities number objects (packages) transported;
parameter range 1 . . . 9 cases. City size number airplanes
fixed 3. parameter value combination, 10 random instances generated (and
100 states sampled per instance). valley states found, except 3 cities
9 objects, 2 1000 sample states located valley. 5 cities
3 objects, single instance one sample state exit distance 2, rather bound
1 valid h+ single bound violation found entire experiment.25
indicated before, Grid domain was, Hanoi, domain
experiment suggested major difference topologies h+ hF F . Large
fractions sample states, 62.4%, located valleys. clear
tendency increase percentage, increasing grid size increasing
number keys transported.
all, experiment confirmed that, Blocksworld-no-arm, Briefcaseworld, Ferry, Fridge, Gripper, Logistics, Miconic-SIMPLE, Tireworld domains, hF F
25. decrease mean sampled maximal exit distance large parameter values suggests
becomes harder, sampling, find maximum states rather large state spaces.

718

fiWhere Ignoring Delete Lists Works

Z

Z

1

2

0.5

1

0

0
9

9

7
1

7
1

5

3
X

5

3


5


5

3
7

X

9 1

(a)

3
7

9 1

(b)

Figure 9: Mean sampled valley percentage (a) maximal exit distance (b) Logistics,
scaling cities (x-axis) objects (y-axis).
largely preserves quality h+ (no local minima and/or constant bound maximal exit distance benches). Remember Miconic-STRIPS, Movie, Simple-Tsp
three domains this, provably, applies.

6. Towards Automatically Detecting h+ Phenomena
lemmas presented Section 3 provide natural starting point investigations
domain analysis techniques trying detect topological phenomena automatically.
domain analysis techniques would useful configuring hybrid systems, i.e.,
automatic selection heuristic functions likely well-suited solving given
planning task. Further, techniques would useful avoiding need re-do
h+ investigation every single new planning domain. Finally, basis
analysis techniques one may able compute good lower bounds h+ ,
informative admissible heuristic function. discussion points contained
Section 7.
question addressed if, extent, how, application
lemmas Section 3 automated, i.e., one automatically check
whether prerequisites satisfied given STRIPS task. section hand,
present preliminary attempt made that. attempt
successful, believe investigation value showing one achieve
simple analysis techniques, weak points would needed improved
upon order obtain better results.
Invertible (or least invertible) actions, actions irrelevant delete/static add
effects, syntactically defined Section 3 thus easy detect. difficulty
find inconsistencies facts. hard planning itself,
several approximation techniques literature (for example, Blum & Furst, 1995, 1997;
Fox & Long, 1998; Gerevini & Schubert, 2000, 2001; Rintanen, 2000), tend work
well, least current benchmarks. challenge find syntactical
characterizations actions respected relaxation, actions
719

fiHoffmann

relaxed-plan relevant delete effects. Now, many domains phenomena
occur, example Ferry, Gripper, Logistics, Miconic-STRIPS, Movie, Simple-Tsp,
Tireworld, intuitively one looks domains causes phenomena
seem similar. getting actual syntax domain descriptions,
individual details different becomes difficult get hold
common ground. seem simple syntactical definition captures
behavior actions domains; least find syntactical
definition. Instead, tried reason additive structure domains,
possible interactions delete effects. (The intuition that, domains
simple h+ topology, interactions arent harmful.) captured
additive structure domain/of instance data structure called fact generation
trees. next subsection describes data structure basic properties,
subsection gives results extreme case h+ topology, subsection outlines
somewhat advanced analysis technique developed.
6.1 Fact Generation Trees
fact generation tree, short FGT, planning instance basically AND/OR tree
results regression search starting goals, ignoring delete effects
actions. Tree nodes labelled facts actions alternatingly. Fact nodes
nodes represent choice achieving actions action nodes nodes
preconditions represent sets facts must achieved together. assume goal
achievement action, known from, example, description UCPOP (Penberthy &
Weld, 1992). action root (AND) node FGT, top level goals form
sons. Obviously, sons fact node actions achieve fact,
sons action node precondition facts action. (For sake
simplicity, stayed pure STRIPS framework investigation.) Tree structures
kind were, example, described used Nebel, Dimopoulos, Koehler (1997)
work automatically detecting irrelevant facts operators. Note FGT
take account interactions may arise trying achieve facts
node together. effect ignoring delete lists, FGT treats
facts completely separately.
terminate FGT applying following two rules.
1. Say inserted action node N (a) labeled action a. fact
p pre(a) fact node labeled p occurs path root node
N (a), N (a) pruned.
2. Say inserted, son action node N (a), fact node N (p) labeled
fact p. action a0 p pre(a0 ), action node labeled
a0 occurs path root node N (a), N (p) pruned.
Intuitively, rules disallow generation branches FGT would redundant relaxed plan. Formally, call relaxed plan non-redundant strict subsequence still relaxed plan (i.e., action omitted). Every non-redundant
relaxed plan, every (not necessarily reachable) state, embedded connected,
rooted, non-redundant sub-tree FGT built way described above.
720

fiWhere Ignoring Delete Lists Works

precise introducing illustrative example Figure 10, use
throughout section.

E

E

== 1 EUR

mv E


+= 1 EUR

B

C


1 EUR


mv B

mv C

B

C

mv C

mv B



Figure 10: Sketch FGT illustrative example.
example, task reach location E. available actions moves along
(bi-directional) graph edges obvious encoding using predicate, except
move E, requires additional precondition possession
1 EUR. acquire 1 EUR add effect action moves
C. main part Figure 10 shows FGT example, picture top left
corner illustrates example showing road map graph indication role
1 EUR constructs. root node, i.e., artificial goal-achievement action,
included figure, simplicity. Due termination rule 1, (for example) moving
E included son fact node labeled (the precondition E
root node). Due termination rule 2, son action node labeled
mv C (at already occurs precondition mv E above).
Every action non-redundant relaxed plan (to arbitrary state) achieves
unique needed fact achieved preceding action, needed
goal precondition subsequent action.26 overly difficult prove
one thus embed relaxed plan FGT processing relaxed plan
back front, associating action corresponding node needed
fact added action, starting goal facts. resulting sub-tree connected
rooted sense actions associated consecutive nodes, starting
root node. sub-tree non-redundant sense that, every node,
26. observation made by, example, Hoffmann Nebel (2001b), used detect
actions participate non-redundant relaxed plan, thus need
considered heuristic computations done planners FF HSP.

721

fiHoffmann

one son gets associated action. Termination rule 1 valid since fact needed
end relaxed plan also needed start. Termination rule 2 valid
since every needed fact least one representative node corresponding subtree. illustration, consider different locations graph underlying example
Figure 10. one located, example, 1 EUR,
entire FGT except mv C node corresponds sub-tree non-redundant
relaxed plan. sub-tree obtained follows. relaxed plan mv B, mv B
D, mv C, mv E. needed facts added actions B, D, 1
EUR, E, respectively. Starting goal fact E, first mv E gets
associated respective action node. fact nodes 1 EUR
preconditions action dealt become open, mv B well
mv C get associated respective node respective needed fact.
consequence mv B action, fact node B becomes open, mv B gets
associated action node it. process stops. If, current state,
one is, example, located C 1 EUR, process selects sub-tree
consists mv C mv E nodes only.
Every non-redundant relaxed plan instance, particular every optimal relaxed
plan instance, corresponds sub-tree FGT. FGT summary
possible relaxed plans sense, idea examine FGT harmful interactions
conflicts potential appear relaxed plan. hope able draw
conclusions non-existence/restricted form conflicts topological properties
h+ . next outline extreme case analysis kind, namely one postulates
absence conflicts FGT. Note that, difference situation
illustrative example, general FGT contain action/fact labels multiple nodes.
worst-case size FGT exponential size instance description. So,
design practically usable domain analysis techniques, one would need approximate
FGT, instead building completely. aspect treated follows,
objective (only) find implications FGT structure h+ topology
first place.
6.2 Interaction-free Planning Tasks
Think conflict situation one part (non-redundant) relaxed plan
hinder execution/success another part relaxed plan.
conflicts, every (non-redundant) relaxed plan executable reality, implying
h+ equal real goal distance (which course implies local minima
etc). investigated 30 benchmark domains, case (only) Simple-Tsp,
use motivating example.
define three kinds conflicts FGT. call two action nodes, labeled
actions a0 , allied participate together non-redundant sub-tree, i.e.,
occur together embedding relaxed plan, descendants
other. (This case iff paths root node a0 separate
node.) first kind conflicts given pair allied action nodes labeled a0 ,
deletes precondition a0 . Second kind conflicts, pair action nodes labeled
a0 , descendant a0 , deletes precondition a0 added
722

fiWhere Ignoring Delete Lists Works

action path a0 . Third kind, action node labeled a,
deletes goal fact added action path respective root
node.
conflicts FGT, call task interaction-free. relatively
easy see that, without conflicts, every non-redundant relaxed plan (for every nonredundant sub-tree FGT) execution order works reality. h+
equals goal distance interaction-free tasks.
illustrative example Figure 10, conflict FGT
nodes mv C mv E nodes allied, mv C deletes
precondition mv E. Note conflict indeed capture reason
h+ equal goal distance example. order able move
E, one first move C get 1 EUR. latter deletes
precondition former. relaxation, move C, one
located C time, relaxed plan needs one step less
achieve goal (from states move C yet done).
example domain interaction-free tasks graph-search domain mentioned earlier, tasks demand find path two nodes directed
graph, using obvious at-predicate connected-predicate based encoding. (Our
illustrative example becomes instance domain one removes 1 EUR
constructs.) even come purely syntactic criterion captures
example domain.
Proposition 4 Let (A, I, G) STRIPS planning task
1. |G| 1,
2. A: |pre(a)| 1,
3. A: del(a) pre(a).
(A, I, G) interaction-free.
Proof: Due prerequisites 1 2, nodes FGT one son.
implies allied action nodes. Together prerequisite 3
termination rule 1, implies action node delete goal fact, precondition
fact ancestor node.
2
Instances graph-search domain fulfill prerequisites Proposition 4
static connected facts removed prior planning. Note syntax identified
Proposition 4 subset syntax identified Proposition 3, thus tasks
hF F identical h+ , and, since h+ identical real goal distance, plan existence
decided polynomial time. Intuitively, captured syntax
express graph-search domain: plans task qualifying Proposition 4
correspond exactly paths graph nodes facts, edges go
preconditions add effects. true relaxed plans.
instances Simple-Tsp domain interaction-free. conflicts
FGT pairs actions achieving different visited goals. example, say
723

fiHoffmann

three locations visit, l1 , l2 , l3 . action nodes mv l1 l2 mv l1
l3 allied since achieve goals visited l2 visited l3 participate
root node. actions mutually delete precondition, l1 ,
constitute conflict FGT. appear together relaxed plan,
relaxed plan executable reality (unless relaxed plan happens move back
l1 between). Observe, however, execution of, example, mv l1 l2 , one
replace mv l1 l3 mv l2 l3 repair conflict relaxed plan.
conflicts Simple-Tsp FGTs behave way.
general, say conflict allied action nodes a0 repaired
action a00 pre(a00 ) (pre(a) add(a)) \ del(a) (thus a00 executed
a), add(a00 ) add(a0 ) (thus a00 achieves a0 achieved). Similar
repairable cases identified two kinds conflicts. conflicts
FGT repaired, non-redundant relaxed plan relaxed plan
length executable reality, h+ equals goal distance.
case Simple-Tsp domain.
made preliminary implementation FGT analysis techniques.
implementation correctly detects Simple-Tsp instances (as well graph-search
instances), h+ equals goal distance. Simple-Tsp, less 18 locations analysis
takes split seconds; 18 locations, runtime taken explodes fairly
quickly.
6.3 Advanced Analysis
results encouraging, techniques applicability h+ topology
detect clearly far severely restricted. turns extremely difficult find
less restrictive implications FGT structure h+ topology, i.e., sufficient criteria
weaker topological properties. best could come criterion implies
non-existence local minima h+ , holds true Movie domain
extremely simple Logistics instances.
idea behind criterion following. imply non-existence local
minima h+ , suffices know that, every state s, starting action
optimal solution h+ (Result(s, hai)) h+ (s). Say considering planning
task actions (at least) invertible. Let state starting action
optimal solution s. optimal relaxed plan contains a,
done argument used Lemma 3. Else, let P + optimal relaxed plan
contain a. P + embedded sub-tree FGT.
delete leaf nodes sub-tree facts P + assumes true state
execution P + relaxed plan Result(s, hai) done, too. case left
open delete leaf node sub-tree occupied P + . Observe
matter (or repairable) conflicts sub-tree.
Then, P + executable reality, P + optimal plan s, starting action
P + falls first case done again. get following sufficient
criterion:
724

fiWhere Ignoring Delete Lists Works

local minima h+ actions holds least
invertible, non-redundant sub-trees FGT contain a, either
delete leaf sub-tree, sub-tree contain conflicts.
test criterion, one needs consider (redundant) sub-tree FGT
branches left start nodes labeled a. sub-tree
contains conflict, deletes fact occurring sub-tree, criterion
apply. Otherwise, test succeeds actions, proved local
minima h+ .
Reconsider illustrative example Figure 10, said conflict
FGT nodes mv C mv E. sub-tree
contain one nodes conflict-free. mv C mv E violate
criterion. Neither mv B D, mv C D, mv B violate criterion, since
none actions deletes fact occurring anywhere else precondition.
However, mv B mv B sub-tree looked entire FGT including
conflict, actions delete fact occurs FGT. criterion
apply illustrative example. Note mv B mv B never start
optimal plan really could left considerations; unclear
detect automatically, general way.
remark side order here. action appear FGT, then,
difference one may think first sight, imply appear
optimal plan. FGT termination rules, adequate relaxed planning,
restrictive real planning. following example. facts g1 , g2 ,
p. goal {g1 , g2 }, current state {g1 }. actions shown Figure 11.
name
opp
opg2
opg1

=
=
=

(pre,

add,

del)

({g1 },
(,
({p},

{p},
{g2 },
{g1 },

)
{g1 })
)

Figure 11: Actions example task FGT contain action (opp,
namely) needed reality.
optimal plan hopp, opg2 , opg1 i: order able re-achieve g1
applying opg2 , must achieve p first. However, opp appear FGT.
location FGT node N labeled opp could inserted
son precondition node p opg1 , inserted son g1 . N pruned
termination rule 1, opp g1 precondition, g1 appears path
root node N . Note that, indeed, opp never part relaxed plan
achieving p good re-achieving g1 deleted actions necessary
reach goals.
implementation criterion given easily within split seconds proves
non-existence local minima Movie instances, regardless size instance.
725

fiHoffmann

technique not, however, work domain tried, except Logistics
instances single city, two locations it, single truck,
single package transported. Note even simpler small
illustrative example used Section 3, two objects need transported.
open question better results achieved, i.e., state spaces
recognized feature local minima h+ . feeling backward
chaining approach domain analysis promising. But, successful, analysis
technique probably invest much effort analyzing way
goals achieved, many steps, rather crude
FGT approximation. information available goals achieved,
maybe would possible discover non-trivial cases actions respected
relaxation.27 detecting actions relaxed-plan relevant delete effects,
yet completely unclear us could accomplished.

7. Discussion
derived formal background understanding classes domains relaxed plan-based heuristic methods, wide-spread methods modern planning
landscape time writing, well suited for. formal approach taken
identify characteristics local search topology heuristic cost surface
idealized heuristic function h+ , forward searching framework. 30 commonly used
benchmark domains including competition examples, i.e., basically STRIPS
ADL benchmark domains used field time writing, proved
relevant topological properties are. results coincide well runtime behavior
FF. Indeed, empirical results suggest quality h+ often preserved FFs
approximation it.
results interesting give rare example successful theoretical
analysis connections typical-case problem structure, search performance.
practical point view, results provide clear picture strengths
weaknesses h+ lie, form good basis embarking improving heuristic
weak cases. Approaches kind already appeared literature (Fox &
Long, 2001; Gerevini et al., 2003). particularly, Fast-Downwards heuristic function
(Helmert, 2004) motivated observations regarding unrecognized dead ends h+
Mystery domain, large benches transportation domains non-trivial road
maps.
Regarding relevance topological results forward search algorithms
enforced hill-climbing, note things like non-existence unrecognized dead
ends non-existence local minima certainly useful heuristic search
algorithm, albeit form provable polynomiality result.28 generally,
relevance topological results performance planners using search
27. remark easy find even trivial syntactical restrictions actions are,
general, respected relaxation. example, even every fact added single action,
one construct cases non-respected actions. One case example Figure 11,
opp respected relaxation.
28. Except case heuristic function identifies precise goal distances, case
h+ 1 30 domains, namely, Simple-Tsp domain.

726

fiWhere Ignoring Delete Lists Works

paradigms, enhanced heuristics, like LPG Fast-Downward, matter needing investigation. One thing certainly clear that, easiest classes
taxonomy, particularly domains state space local minima h+ , benches escaped single step, planner using approximation
h+ likely work quite well. Indeed thats one observes practice. intuition
author topology h+ plays large role efficiency planners
generally, i.e., also domains. Proving disproving beyond scope
paper. case, investigation provides nice theoretical background
proved results idealized setting, results used starting point
investigations tailored individual systems FF.
investigation considers solvable planning tasks only, well justified
focus set international planning competitions. Turning focus unsolvable tasks,
one realizes much techniques results become useless. search space
solution, difference heuristic function make lies states
infinite heuristic value, i.e., states recognized dead ends. means
interesting question remaining kinds dead end states
relaxed plan. results herein tell us this? domains
identified unrecognized dead ends, results tell us relaxed plans generous
approximation.29 domains, things look hopeful. Still, results
relative solvable instances. Whether h+ detect many dead end states
unsolvable tasks depend reasons states. dead
ends unsolvable tasks may caused reasons solvable tasks,
since assumptions making tasks solvable given. Note many
benchmarks (for example, Blocksworld Logistics) unsolvable instances
standard definition. extent, makes existence non-existence
unrecognized dead ends choice domain designer extending domain definition.
Exploring issues detail topic future work.
Talking future work, biggest drawback research current form is,
obviously, needs re-done every single new planning domain. would
desirable, turns hard, come generic ideally, automatic
methods determine topological properties domain. outlined
attempt made develop automatic methods, based analyzing properties fact
generation trees. presented first promising results, regarding applicability
domains complexity one would like able handle, methods yet far
weak. left future research answer question approaches
topic work better practice. said, intuition better
approaches, based intelligent backchaining-style reasoning goals
achieved domain. But, time writing, pure speculation.
Beside easening burden proofs hand, benefits automatic domain analysis techniques would twofold. First, ambitious long-term vision domainindependent planning arsenal complementary heuristics, combine
hybrid system automatically configured best suit given arbitrary
planning task. contribution made towards vision results hand
29. Unsurprisingly, seeing deciding plan existence NP-hard in, example, Mystery, Mprime, MiconicADL, Freecell (Helmert, 2003).

727

fiHoffmann

clear picture strengths h+ lie; able automatically configure hybrid system, one would need multiple heuristics different strengths weaknesses
(i.e., heuristics high quality different classes domains), well ability
determine automatically heuristic likely work best. (At least approach could cost-effective, beside much insightful, trying
possible combinations techniques.)
Another benefit enhanced domain analysis techniques might lie ability
generate high-quality admissible heuristic function sequential planning. many domains, optimal relaxed plans mostly consist actions easy human
see (or one set similar actions) must contained optimal
relaxed plan (for example, loading unloading actions cant avoided
transportation task). number actions state could provide good lower
bound value h+ . Note phenomenon actions must contained
every relaxed plan stronger version notion actions respected
relaxation. promising approach seems try detect former sufficient
approximation latter.
Since observed arbitrarily deep local minima h+ Blocksworldarm, none Blocksworld-no-arm, one might try come encoding methods
trying model domain way making best suited h+ . Since Blocksworld-no-arm
basically version Blocksworld-arm possible pairs consecutive actions
(pickup-stack, unstack-stack, unstack-putdown) replaced macro-actions, good
(but somewhat obvious) heuristic modeling probably choose domain granularity
high level abstraction possible. insightful heuristics may obtained
considering h+ topology planning benchmarks enriched automatically
detected macro actions (Botea, Muller, & Schaeffer, 2004, 2005).
Apart above, important future direction adaption formal
framework, theoretical analysis methods, temporal numeric settings
dealt modern planning benchmarks modern planning systems. needed
adaptations straightforward numeric framework used Metric-FF (Hoffmann,
2003a). temporal planning, objective function estimated heuristic
number actions needed complete partial plan, adaptation framework
probably straightforward well. If, however, makespan estimated heuristic,
said article apply. most, setting
analysis techniques could relevant search uses estimation remaining action
steps secondary heuristic.

Acknowledgments
would like thank Drew McDermott, Fahiem Bacchus, Maria Fox, Derek Long
responses various questions concerning definitions of/intentions behind
competition domains. also thank anonymous reviewers, whose comments helped
improve paper.

728

fiWhere Ignoring Delete Lists Works

Appendix A. Proof Sketches
list proof sketches sections concerning dead ends, local minima, benches,
order.
A.1 Dead Ends
Theorem 1 state space solvable instance
1. Blocksworld-arm, Blocksworld-no-arm, Briefcaseworld, Depots, Driverlog, Ferry,
Fridge, Gripper, Hanoi, Logistics undirected,
2. Grid, Miconic-SIMPLE, Miconic-STRIPS, Movie, Pipesworld, PSR, Satellite,
Simple-Tsp, Tireworld, Zenotravel harmless,
3. Dining-Philosophers, Optical-Telegraph, Rovers, Schedule recognized evaluation h+ .
proofs simple applications Lemma 1 2. said, descriptions
domains looked Appendix B.
Proof Sketch: [Theorem 1]
actions Blocksworld-arm, Blocksworld-no-arm, Driverlog, Ferry, Gripper, Hanoi,
Logistics instances invertible, apply Lemma 1 finished.
inverse actions obvious ones cases, like stacking/unstacking block onto/from
block, loading/unloading object onto/from vehicle, moving l
l0 /moving l0 l (in case Driverlog, latter always done
underlying road map bi-directional, c.f. Appendix B.8). Briefcaseworld, Depots,
Fridge domains, actions strictly obey definition invertible
(neither least invertible), still invert obvious way,
i.e., every state applicable action action Result(s, ha, ai) = s.
Movie, actions getting snacks irrelevant delete effects static add effects,
rewinding movie resetting counter least invertible. Simple-Tsp action
moving l l0 least invertible moving back. Tireworld, working steps
inverse one, except inflating wheel. irrelevant delete effects
static add effects. Miconic-STRIPS, moving lift invertible, boarding passenger
least invertible, departing passenger irrelevant delete effects static add
effects. four domains, Lemma 2 thus applied. Miconic-SIMPLE
Grid domains, actions strictly adhere relevant definitions, similar
arguments like Lemma 2 prove non-existence dead ends. Miconic-SIMPLE, moving
lift invertible. Letting passengers lift inverted,
actions need applied (similar static add effects),
interfere anything else (similar irrelevant deletes). Grid, actions
inverse action, except opening lock. latter action excludes actions opening
lock (similar irrelevant deletes), lock needs opened once,
locks closed (static add effects). Zenotravel Satellite, facts
re-achieved sometimes one apply several actions so. Zenotravel,
729

fiHoffmann

flying airplane l l0 , get back l0 one might refuel airplane
top flying back. Satellite, switching instrument on, one might recalibrate it, always done involve several actions (turning satellite
right direction applying actual calibration action). Pipesworld,
push action inverted respective pop action, vice versa. state space
undirected since pushs/pops non-unitary pipeline segments split two parts.
PSR, dead end states since one always reach goal state waiting,
necessary, opening breakers, bringing (non-breaker) devices goal
position, closing needed breakers.
Dining-Philosophers, dead ends arise process (a philosopher) initiated impossible reading writing command (from/to empty/a full queue)
queue contents updated, actions applicable. (The derived
predicate rules determine process blocked apply case, since
require read/write command initiated yet.) Obviously, applicable
actions relaxed plan either. states, goal reached
traversing individual process state transitions philosophers one fork, try
take other.
Optical-Telegraph, dead ends arise two kinds situations. First, process
initiated impossible reading writing command, similarly Dining-Philosophers,
applicable actions thus relaxed plan. second possibility
two processes pair may take different decisions go next communication sequence: one may decide stop data exchange, may decide
send receive data. situation, least one processes state
two transitions available, already activated one transitions,
might already initiated respective write/read command. write/read command
impossible (since process took different decision), actions
applicable process. derived predicate blocking rules apply
process, never apply process states one available transition.
neither real relaxed plan exist state. reachable states,
goal reached traversing individual process state transitions pairs
communicating processes occupy one control channel, try write other.
Rovers, plan state if, soil/rock samples images
need taken, rover job, communicate
gathered data lander. chance run dead end take soil/rock
sample rover reach lander (the soil/rock sample available once).
then, relaxed plan state either.
Schedule, state gd(s) < solved applying, object
turn, certain sequence working steps. sequence applied object
follows preconditions needed action fulfilled, must
case cold (a do-roll action applied previously,
making hot). operator make cold again, i.e., operator adds respective
fact. Thus relaxed plan either.
2
Note worst cases Theorem 1 occur, i.e., domains whose instances
harmless, directed state transitions, domains whose instances
730

fiWhere Ignoring Delete Lists Works

recognized, dead ends. remark dead ends Dining-Philosophers
Optical-Telegraph due seem bugs encoding queues
(whose contents arent always updated correctly) blocked situations (whose rules
detection seem incomplete). Modifying operators straightforward way
fix (apparent) bugs, one gets dead-end free (harmless) state spaces.
domains mentioned Theorem 1 Airport, Assembly, Freecell, MiconicADL, Mprime, Mystery. domains, one construct arbitrarily deep
unrecognized dead ends. Airport, unrecognized dead ends arise two planes move
towards line segments, possibility changing direction.
deadlock situations arent recognized relaxed planning since, relaxation,
free space left two planes remains free, used navigate planes
across other. dead end becomes arbitrarily deep when, independently
deadlock situation, planes still moved. remark that, reality
IPC-4 example instances deadlock situations like rarely occur. Airplanes
movable along standard paths serve avoid deadlocks main connecting
routes airport. places airport deadlocks occur,
reality IPC-4 example instances, near parking areas, space
dense, airplanes need move directions airport segment.
deadlocks occur all, i.e., planes move target positions one
without hindering other, h+ delivers exact goal distance.
presumably reason heuristic planners performed well IPC-4 Airport
test suites. performance would probably become worse one use (unrealistic)
instances excessively many potential deadlock situations.
Assembly, unrecognized dead ends arise several objects stuck due
complex ordering constraints, imply solution plan would need go
cyclic assembly pattern. details rather complicated, interested reader
referred TR (Hoffmann, 2003c). proved that, unless ordering constraints
Assembly instance potential yield cyclic situation, dead
ends all. one IPC-1 competition instances, ordering constraints
potential. helps explain FF efficient test suite
(it solves even largest task within half second search time, finding plan 112
steps).
Freecell, unrecognized dead ends arise, example, one cautious
enough moving cards free cells. relaxed plan still achieve goal
single free cell, using cell intermediate store cards. reality,
however, moving card free cell occupies space (by deleting availability
free cell), thus exclude possibilities reaching goal. Thus moving card
free cell lead unrecognized dead end state. unrecognized dead end
arbitrarily deep cards still moved around independently deadlock
situation.
Miconic-ADL, unrecognized dead ends arise problem constraint violated,
violation goes unrecognized relaxed plan. example two passengers
p1 p2 lift, p1 transported downwards, p2 access
p1 destination floor, p2 destination floor p1 s. state dead end
one let p1 get first p2 access respective floor
731

fiHoffmann

neither one let p2 get first afterwards, lift would need drive upwards,
cant p1 board. relaxation, one stop destination floors
simultaneously at-facts deleted. unrecognized dead end becomes
arbitrarily deep several passengers moved around reaching p1
destination floor.
Mystery, unrecognized dead ends arise fuel scarce, vehicle makes suboptimal moves. relaxed plan achieve goal long relevant locations
still accessible least once. may suffice reality. dead end becomes arbitrarily deep additional objects transported independently problematic
situation. Mprime behaves similarly. difference Mystery example that,
avoid possibility transferring fuel items problematic locations, one must make
sure enough fuel enable transportation additional objects.
A.2 Local Minima
Theorem 2 h+ , maximal local minimum exit distance state space
solvable instance
1. Blocksworld-no-arm, Briefcaseworld, Ferry, Fridge, Grid, Gripper, Hanoi, Logistics,
Miconic-SIMPLE, Miconic-STRIPS, Movie, Simple-Tsp, Tireworld 0,
2. Zenotravel 2, Satellite 4, Schedule 5, DiningPhilosophers 31.
present proof sketch Theorem 2 terms three groups domains
similar proofs. Note domains maximal local minimum exit distance 0
domains local minima all. first focus domains
Lemma 3, slight extensions it, applied.
Proof Sketch: [Theorem 2, Ferry, Fridge, Gripper, Logistics, Miconic-SIMPLE, MiconicSTRIPS, Movie, Simple-Tsp, Tireworld]
Theorem 1, none listed domains contains dead ends. said proof
sketch theorem, actions Ferry, Gripper, Logistics, Miconic-STRIPS, Movie,
Simple-Tsp, Tireworld domains either least invertible, irrelevant delete
effects. Lemma 3 suffices show actions respected relaxation.
cases, except driving/flying actions Logistics, easy see
optimal starting action something avoided relaxed plan. (For
example, relaxed plan avoid load/unload objects onto/from vehicles,
avoid missing working steps Tireworld.) optimal starting action
Logistics drives truck/flies airplane location l, object must either
loaded unloaded l, relaxed plan choice apply action
moves transportation vehicle (of kind) there. vehicles equally good, except
clever choice, i.e., vehicle already carries objects unloaded
l. then, move one vehicles like optimal relaxed plan will,
vehicles equally good relaxation. (In Ferry, Gripper, Miconic-STRIPS,
732

fiWhere Ignoring Delete Lists Works

single vehicle, makes moving actions domains easier
reason about.)
Fridge Miconic-SIMPLE domains, actions adhere strictly
definitions invertibility irrelevant delete effects. proof Theorem 1
shown similar semantics, i.e., either inverted, delete
facts longer needed applied. Furthermore, actions
domains respected relaxation. Fridge, missing working steps must also
done relaxed plan. Miconic-SIMPLE, lift moves trivially respected, lift
stops respected since clever choices reality coincide clever choices relaxed
plan.
2
next four domains, local minima either, proofs
sophisticated make use rather individual properties respective domains.
cases proved path goal h+ increase.
Proof Sketch: [Theorem 2, Blocksworld-no-arm, Briefcaseworld, Grid, Hanoi]
Theorem 1, none domains contains dead ends. Blocksworld-no-arm,
optimal starting action stacks block goal position, also starts
optimal relaxed plan (because better thing achieve goal
immediately); relaxed plan, replaced inverse counterpart form
relaxed plan successor state. action state s, one
optimal plan starts putting block b must moved order access block
block c onto table, yielding state s0 . relaxed plan
s0 constructed relaxed plan P + by, taking account various case
distinctions, replacing move actions regarding b P + number
move actions. case distinctions kind action P + uses move b
away c one action a0 must contained P + . a0 moves b table
replace a0 P + action moves b back onto c, finished. Else,
must distinguish cases b required c goal,
block. cases, make successful use fact b moved
position position within single action, enabling us exchange actions
P + quite flexibly.
Briefcaseworld, actions inverted. Actions put objects briefcase
trivially respected relaxation. state optimal plan starts
take-out action, optimal relaxed plan also used successor state, since
taking object delete important facts. state optimal plan
starts move action l l0 , P + relaxed plan s, relaxed plan
successor state constructed replacing moves l l00 , l00 6= l0 , P + ,
moves l0 l00 .
Grid, rather complex procedure applied identify flat path state
better h+ value. state s, let P + optimal relaxed plan s, let
first unlock action P + , putdown unlock action. Identifying flat
path state s0 applied suffices, unlocking deletes facts
irrelevant lock open, deletes putting key irrelevant
locks must opened. selected action uses key k
733

fiHoffmann

position p. P + contains sequence actions moving p. Moving along path defined
actions increase h+ since actions contained relaxed plan,
inverted. k already held s, apply a. hand
empty s, key held, one use P + identify flat path state
one hold appropriate key k. hand empty, P + must contain
sequence actions moving location k picked up. key
held, P + must contain sequences actions moving locations series
keys picked put down, key series ends picking k.
Hanoi, proved optimal relaxed solution length state equal
number discs yet final goal position proceeding
smallest largest disc, respective goal achieved single action.
optimal plan moves disc away final position, h+ increase optimal
solution paths.
2
finally consider four domains local minima, one always
escape within constant number steps. cases, prove upper bound
distance non-dead end state state s0 h+ (s0 ) < h+ (s). immediately
implies 1 upper bound maximal local minimum exit distance (it also
implies 1 upper bound maximal bench exit distance; results
re-used Appendix A.3).
Dining-Philosophers, h+ loosely connected goal distance, bound,
holds even trivial heuristic function returning number yet un-blocked
philosophers, follows rather constant restrictive domain structure.
three domains, proofs proceed follows. reachable state s, identify constant
number steps suffices execute one action optimal relaxed plan s, and,
without deleting relevant add effects, re-achieve relevant facts deleted
a. Then, state s0 h+ (s0 ) < h+ (s) reached.
Proof Sketch: [Theorem 2, Dining-Philosophers, Satellite, Schedule, Zenotravel]
Theorem 1, dead ends Dining-Philosophers recognized. non
dead end state s, shortest relaxed plan blocks processes (philosophers)
yet blocked. individual process, 3 steps needed relaxation,
block process always suffices activate state transition, initiate read/write
command, queue update. update, queue empty full,
read/write impossible sense blocking rules apply. (With this,
process block relaxation, h+ value fairly loosely correlated
true goal distance.) Thus, reach state lower h+ value, obviously always
suffices block one process. prove upper bound determining constant
bound number steps needed that. bound exists because, beside
fact philosopher processes constant interfere respective
two neighbors table, philosophers fixed order try pick
forks: always first try pick fork right, fork left.
restricts possible combinations internal states neighbored philosophers.
detail, philosopher blocked iff tries pick fork
table. philosopher p, refer pL ps neighbor philosopher left side.
734

fiWhere Ignoring Delete Lists Works

description 5 different states philosopher process Appendix B.7. Let
non dead end state. Let p philosopher blocked (if p exists,
goal state nothing prove). prove desired upper bound
exhaustive case distinction states p pL. state {1, . . . , 5}
p, consider state iL {1, . . . , 5} pL. combination iL
possible, nothing. Else, determine number k process state transitions
leads state either: p blocked pL still blocked blocked
s; pL blocked blocked s. cases, also
make distinctions internal state pLs left neighbor pLL. worst case, k = 6,
occurs = 3, i.e., p holds adjacent forks. Then, pL either
state iL = 1 iL = 4 (which means, pL cant hold fork pL p since
held p). iL = 4, pL blocked s; pL put left fork, getting
state 1 pL blocked since waits pick right fork, held p. iL = 1
distinguish two cases state pLL. = 3 (p holds
adjacent forks), iL = 1 (pL waits pick fork p pL); pL
blocked. Case A, state pLL 0, 2, 3, pLL holds fork pLL
pL. go p 3 4, 4 1, 1 2, go pL 1 2.
Then, p pL blocked since wait pick fork left. Case B,
state pLL 1 4, fork pLL pL table, pLL
blocked. go pLL 4 1 (if 4), 1 2. that, pLL holds
fork pLL pL; case apply sequence, getting us
state pLL possibly blocked, p pL definitely blocked.
always need 6 process state transitions block one philosopher.
process state transitions take 4 planning actions each, makes 24 planning
steps. planning steps needed due subtleties PDDL encoding.
Subtlety A, process may already decided go state, yet arrived
i.e., respective transition activated read/write command initiated,
communication channel/queue occupied transition yet complete.
2 steps needed reach next internal state (update queue wrap
transition). Subtlety B, blocked state process must activate outgoing
transition. worst case described above, p, pL, pLL may require 2
steps induced subtlety A; p pL require step induced subtlety B.
get (at most) 32 planning actions. effect last action, one process
becomes blocked, upper bound exit distance 31.
Theorem 1, dead ends Satellite. Let reachable state.
determine upper bound distance state s0 h+ (s0 ) < h+ (s),
one look optimal relaxed plan P + s, distinguish four cases regarding
existence applicable actions different types P + . action type, constant
number steps suffices re-achieve deleted facts application action.
worst case, = 5, arises switch-on action applied. Switching instrument
deletes instruments calibration. re-achieve this, one must turn satellite
calibrate it. another turn taking image, state lower h+ value reached.
Theorem 1, dead ends Schedule recognized. Let non-dead
end state. determine upper bound distance state s0
h+ (s0 ) < h+ (s), one look optimal relaxed plan P + distinguish seven
735

fiHoffmann

cases regarding kinds applicable actions P + contains. worst case, = 6,
arises do-roll action available (and applicable) P + . One needs
apply time-step, do-lathe action achieve desired effects do-roll, another time
step, do-polish do-grind action re-achieve previous surface condition, another
time step, do-immersion-paint action re-achieve previous color.
Theorem 1, dead ends Zenotravel. reachable state s, determine
desired constant d, distinguishing two cases job. relaxed plan P +
contains applicable boarding, departing, refueling action, applying action
leads state lower h+ value. Else, P + starts flying action, better
state reached executing flight, refueling once, boarding departing
person. get = 3.
2
Note proved bound Dining-Philosophers holds even take heuristic
function trivial one returns number yet un-blocked philosophers.
extremely cumbersome figure exactly worst-case exit distance DiningPhilosophers h+ so, one consider combinations possible states
neighbored processes, possible developments lot action steps, rather
un-intuitive PDDL encoding made automated translation machinery. highest
exit distance could actually construct Dining-Philosophers 15. conjecture
(tight) upper bound.
Satellite, Schedule, Zenotravel, proved upper bounds tight.
Dining-Philosophers, Satellite, Schedule, Zenotravel, bounds valid nondead end state s. So, beside bound local minimum exit distance, results also
provide bound bench exit distance; re-use Appendix A.3.
Blocksworld-arm, Depots, Driverlog, Optical-Telegraph, Pipesworld, PSR, Rovers,
one construct local minima arbitrarily large exit distances. Blocksworld-arm,
example situation n blocks b1 , . . . , bn initially form stack bi
bi+1 bn table, goal build stack top
another block bn+1 , i.e., goal stack b1 , . . . , bn , bn+1 . Reaching, initial state,
state better h+ value, involves disassembling entire stack b1 , . . . , bn .
disassembling process, h+ increases. example used Depots.
Driverlog, local minima arise due different road maps trucks drivers,
example, takes one step drive location l another location l0 , n
steps walk. relaxed plan, driver drive truck goal
staying is, reality, driver walk way back.
Optical-Telegraph, treated easily reconsidering DiningPhilosophers domain, proved constant upper bound above. reason
Optical-Telegraph basically permissive version Dining-Philosophers,
philosophers choose fork pick first, and, hold forks,
fork want put first. Consider configuration depicted Figure 12.
configuration reachable given automata underlying Dining-Philosophers,
reachable given automata underlying Optical-Telegraph.
Figure 12, Nietzsche holds adjacent forks, Kant holds none tries
get access fork right. Nietzsche Kant, arbitrarily
many philosophers hold one fork each, trying access other.
736

fiWhere Ignoring Delete Lists Works

Kant

Nietzsche

Figure 12: unreachable situation Dining-Philosophers, unbounded local
minimum h+ would arise. Arrows indicate pickup-requests.

non-blocked philosopher Nietzsche, put forks again.
PDDL encoding this, world state Nietzsche activated transition
putting right (or left) fork, h+ value 2: relaxation, suffices
initiate write command, update queue contents. write command
initiated, however, h+ goes 3 transition become non-activated;
relaxed plan update queue contents, wrap transition, activate
(same) transition again. Reaching state h+ value 1 involves propagating
forks entire sequence philosophers Nietzsche Kant, either
right hand side, left hand side. example, say Nietzsche puts forks
picks right fork. philosopher left Nietzsche pick
requested fork (or Nietzsche pick gets us back started).
resulting state, situation before, except philosopher
Nietzsche-role sits one position left. iterating procedure
around left side table, Kant pick requested fork, request get
other, giving us goal state philosophers blocked. state h+ value 1
one Kant yet activated transition request fork.
configuration Figure 12 reachable Dining-Philosophers domain
used IPC-4, because, there, philosopher pick fork left hand
side first done Figure 12 philosophers Nietzsche Kant
Nietzsches left hand side. said, Optical-Telegraph philosophers
freedom choice, situation reachable. detail, described
Appendix B.22, Optical-Telegraph n pairs communicating processes.
pairs arranged cycle, pair control channel. Internally,
two processes within pair go fairly long, heavily interactive, sequence
operations, implementing possibility exchange data two stations.
737

fiHoffmann

operations begin, processes occupy (write into) one
control channel. is, one processes occupies channel, waits signal
process, indicating second control channel occupied well.
data exchange terminated, control channels get released (read)
arbitrary order. overall system blocked iff process pairs state
occupied one control channel, waiting occupy other. Thus,
process pairs correspond exactly philosophers choose fork pick (put
down) first, Figure 12 provides example arbitrarily high exit distance
local minimum state. Precisely, local minimum state one Nietzsche
process pair occupied channels, process blocked second
channel activated transition sending occupied-the-other-one signal:
state, h+ value 2 (all processes except active one blocked).
Pipesworld, consider situation several areas form circle unitary
connections. local minimum state s, single goal batch g go area a;
g currently segment adjacent a, contains batch b, areas empty.
shortest plan push b segment (not s) adjacent a, propagate
batches around circle g pushed a. shortest relaxed plan
is, however, push b push g side i.e., g used
push goal area. Reaching nearest state h+ value 1 requires n 1
steps n areas circle, path h+ value increases. Note
example uses neither tankage restrictions, interface restrictions, non-unitary
pipeline segments.
PSR, deep local minimum given n breakers feed individual goal line,
way breaker feed breakers goal line without breaker
also closed, breakers connected faulty line. one
breakers closed. h+ value state 1 (close single open breaker) since
unsatisfied goal condition (beside supplying line fed open breaker)
one postulating breaker affected; condition negated derived predicate,
thus ignored relaxation. applicable action state wait.
that, breakers open, shortest relaxed plan close all, yielding
h+ value n. Obviously, nearest state h+ value 0 least n steps away.30
Rovers, local minima arise taking image deletes calibration
camera. example this. n waypoints w1 , . . . , wn connected line
(i.e., wi1 connected wi ), lander w1 , one rover camera c must used
take two images w1 , c calibrated (only) wn . rover w1 ,
c calibrated, relaxed plan take two images communicate two
data pieces. taking one image, one navigate way wn , calibrate
c, get back. Note example makes use road map arbitrarily large
diameter, diameter Rovers instance longest way rover must travel
order get one waypoint another. general, distance state better
h+ value bounded 3d + 2 diameter instance (see details
TR). road map diameter IPC-3 Rovers instances varies around 1 6.
30. remark counter-example remains valid IPC-4 SIMPLE-ADL STRIPS formulations
PSR, use different encoding derived predicates, using negation formulate
goal breaker affected.

738

fiWhere Ignoring Delete Lists Works

Airport, Assembly, Freecell, Miconic-ADL, Mprime, Mystery domains,
seen Appendix A.1 contain unrecognized dead ends, so, Proposition 1,
local minimum exit distance domains unbounded. Assembly,
TR describes detail, initial state instance path goal
h+ decreases monotonically, unless complex interactions ordering
constraints present instance. None IPC-1 instances features complex
interactions. Assuming FFs search algorithm sticks monotonically decreasing
paths, gives another indication system efficient example
suite.
A.3 Benches
Theorem 3 h+ , maximal bench exit distance state space solvable
instance Simple-Tsp 0, Ferry 1, Gripper 1, Logistics
1, Miconic-SIMPLE 1, Miconic-STRIPS 1, Movie 1,
Zenotravel 2, Satellite 4, Schedule 5, Tireworld
6, Dining-Philosophers 31.
before, subdivide proof sketch Theorem 3 groups domains
similar proofs. first consider transportation-type domains. them, Lemma 4,
similar proof arguments, applied.
Proof Sketch: [Theorem 3, Ferry, Gripper, Logistics, Miconic-SIMPLE, Miconic-STRIPS]
proofs Theorems 1 2 shown that, domains, actions
respected relaxation, and, domains except Miconic-SIMPLE,
actions either invertible, relevant delete effects. determine upper bound
exit distance benches, thus apply Lemma 4. requires us show
that, state s, optimal plan + 1th action relaxedplan relevant delete effects. Miconic-SIMPLE, seen actions,
adhering syntactic conditions invertibility (no) relevant delete effects,
similar semantics; proof technique applied there.
(transportation-type) domains consideration, argument is, roughly,
load-type unload-type actions relaxed-plan relevant delete effects,
move-type actions need applied row locations
immediately accessible other. implies upper bound 1 maximal
exit distance. Concretely, say reachable state Logistics instance, starts
optimal plan s, P + optimal relaxed plan starts a, applying
yields state s0 . loading (unloading) action, delete at(in-) fact transported object; object loaded respective location
(unloaded respective vehicle) optimal relaxed plan P + ,
relaxed-plan relevant delete effects, exit. Otherwise, drives flies vehicle
v l l0 , s0 exit optimal plan s0 starts loading (unloading)
package (from) v. Miconic-STRIPS Miconic-SIMPLE, arguments
apply. Ferry, arguments also remain valid except that, optimal start action
state boards car, action also deletes available free space
739

fiHoffmann

ferry. then, relaxed plan P + also contains actions move ferry
location l, debark car l (otherwise would point boarding
car). Placing actions front P + , removing a, yields relaxed plan
state results applying s. similar argument applied prove
claim Gripper, gripper hands hold one ball time. (Note
argument Ferry Gripper uses somewhat weaker notion relaxed-plan relevant
delete effects, effects, undone actions contained
relaxed plan.)
2
Next come non-transportation domains also Lemma 4 applied.
Proof Sketch: [Theorem 3, Movie, Simple-Tsp, Tireworld]
proofs Theorems 1 2 shown domains actions
respected relaxation, either least invertible, irrelevant delete effects.
apply Lemma 4 cases.
Movie, actions no, therefore relaxed-plan relevant, delete effects,
single exception rewinding movie (which deletes counter zero).
Obviously, optimal plan rewinds movie twice row. Thus, = 1 desired
upper bound.
Simple-Tsp, = 0 suffices. Say reachable state one location
l. optimal plan starts action visiting yet unvisited location l0 . optimal
relaxed plan start a, visit remaining unvisited location l00
move l0 l00 . latter actions require preconditions deleted a,
every action relaxed-plan relevant delete effects.
Tireworld, lowest constant upper bound = 6. non-final working steps
(like jacking hub flat wheel on) need undone later on, i.e.,
relaxed-plan relevant delete effects. final working steps (like jacking hub)
need undone, i.e., relaxed-plan relevant delete effects. longest
sequence non-final working steps optimal plan row following
6-step one: open boot (it must closed again), fetch wrench jack (they
must put away again), loose nuts hub thats got flat wheel (the nuts must
tightened again), jack respective hub (it must jacked again), undo
nuts (they must done again). resulting state, one remove flat
wheel, needs undone.
2
remaining domains Theorem 3 claims constant upper bound
maximal bench exit distance, seen Appendix A.2 upper bounds
distance reachable state state s0 h+ (s0 ) < h+ (s). upper
bounds trivially also imply upper bounds maximal bench exit distance.
Proof Sketch: [Theorem 3, Dining-Philosophers, Satellite, Schedule, Zenotravel]
Follows directly proof Theorem 2.

2

domains, except last four, one easily construct examples
bench exit distance equal proved upper bound. Satellite, Schedule,
740

fiWhere Ignoring Delete Lists Works

Zenotravel, open question whether tighter bounds bench exit
distance local minimum exit distance; seem particularly relevant,
though. (For Dining-Philosophers, said may even bound
local minimum exit distance tight.)
Blocksworld-no-arm, Briefcaseworld, Fridge, Grid, Hanoi domains, Theorem 2 proves local minima. important know whether
arbitrarily difficult escape benches. answer yes cases. Blocksworldno-arm, example one already used Blocksworld-arm Depots
(to show bounds local minimum exit distances). n blocks
b1 , . . . , bn initially form stack bi bi+1 bn table, goal
build stack top another block bn+1 , i.e., goal stack b1 , . . . , bn , bn+1 .
shortest relaxed plan initial state n steps long (remove stack top
bn , move bn onto bn+1 ). nearest state h+ value n 1 one bn
already stacked onto bn+1 . state n steps away initial state.
Briefcaseworld, bench exit distance becomes large many objects must
taken briefcase relaxation, point taking objects out, since
moving briefcase delete at-facts. Consider state n objects
o1 , . . . , inside briefcase location l, goal o1 , . . . , l
briefcase another location l0 . h+ (s) = 1: moving briefcase l0 suffices
relaxation. nearest goal state, h+ = 0, n + 1 steps away: one must take
objects moving l0 .
Fridge, single fridge compressor held n screws, exit distance
initial state n + 1. reach better state, one must: stop fridge (which must
turned back relaxed plan); unfasten n screws (which must fastened
relaxed plan); remove broken compressor (which needs undone
deletes fact broken compressor attached fridge).31
Grid, consider instances robot located n1 grid (a line) without
locked locations, robot starts leftmost location, shall transport key
rightmost location left end. initial value h+ n + 2 (walk
key, pick up, put at-facts deleted), value get
better robot actually picked key.
Hanoi, seen h+ always equal number discs yet
goal position. Thus maximal bench exit distance grows exponentially
number discs. initial state instance n discs, takes 2n1 steps
move first (i.e., largest) disc goal position.
9 domains local minimum exit distance arbitrarily large,
relevant whether bench exit distance bounded not. Escaping bench
might planner better ending huge local minimum. remark that,
example, Driverlog, Rovers, Mprime, Mystery, one easily construct examples
large bench exit distances, defining road maps large diameters i.e., using
basically example used Grid domain.
31. fact, one easily prove n + 1 also upper bound bench exit distance, Fridge
instances compressors held n screws (details TR).

741

fiHoffmann

Appendix B. Domain Descriptions
following list brief descriptions 30 investigated domains. explain
overall idea behind domain, available operators, initial states
goals are. cases set instances obvious; restrictions, any, explained.
remark that, points, domain semantics seem bit odd (for example,
Zenotravel, difference flying zooming plane zooming consumes
fuel). odd points are, presumably, domain bugs overlooked
respective domain designers. corrected bugs as, all, investigation
meant determine properties benchmarks used community.
domains listed alphabetical order.
B.1 Airport
Airport domain, planner safely navigate ingoing outgoing traffic,
given point time, across airport. main problem constraint planes
must endanger other, come close others running
engines. constraint modeled letting plane block segments
engines currently endanger. Planes enter blocked areas. five operators.
plane moved one airport segment another, plane facing right
direction, planes get endangered action. Similarly, plane pushed
back cause trouble. One start engines plane, let plane
take off, let plane settle parking position. initial state specifies current
positions orientations planes, goal specifies planes outbound (have
take off), inbound parking positions.
B.2 Assembly
Assembly domain, complex object must constructed assembling parts
together, obeying certain ordering constraints. parts might need
assembled way beforehand. parts transient, means
must integrated temporarily. collection machines, resources,
might needed working steps. four operators. available resource
committed object, deleting resources availability. Releasing resource
object inverse action. available object x assembled object y,
x either part transient part y, resources requires committed
y, objects assemble order x already incorporated
y. effect, x incorporated longer available, becomes available
parts except x already incorporated, transient part incorporated.
incorporated object x removed y, resources requires committed
y, and, given x transient part (a part y), objects remove order
(an assemble order) x incorporated (not incorporated). effect, x available
longer incorporated, becomes available parts incorporated,
transient parts except x incorporated. instances, part-of relation
forms tree goal make root object tree available. Also,
742

fiWhere Ignoring Delete Lists Works

assemble remove order constraints consistent (cycle-free). restrictions hold
true AIPS-1998 competition examples.
B.3 Briefcaseworld
Briefcaseworld, number portables must transported, transportation
done via conditional effects move actions. three operators. Putting
portable location done portable briefcase respective
location, portable yet inside. Taking portable done inside.
move applied two locations, achieves, beside is-at-fact
briefcase, respective at-facts portables inside (i.e., portables inside
moved along conditional effects). goal briefcase, subset
portables, goal locations.
B.4 Blocksworld-no-arm
Blocksworld-no-arm variant widely known Blocksworld domain. three
operators. One move block table onto another block. One move block
another block table. One move block another block onto third
block. initial state instance specifies initial positions blocks, goal
state specifies (consistent, i.e., cycle-free) set facts.
B.5 Blocksworld-arm
instances Blocksworld-arm Blocksworld-no-arm. difference blocks moved via single robot arm hold one block time.
four operators. One pickup block table. One put block,
arm holding, onto table. One unstack block
block. Finally, one stack block, arm holding, onto block.
B.6 Depots
Depots domain kind mixture Logistics Blocksworld-arm.
set locations, set trucks, set pallets, set hoists, set crates.
trucks transport crates locations, hoists used stack crates onto
crates, onto pallets. six operators, move truck (different)
locations, load crate held hoist onto truck location, unload
crate hoist truck location, lift crate hoist surface (a
pallet crate) location, drop crate held hoist onto surface
location. hoist hold one crate time. crates initially arranged
arbitrary stacks, bottom crate stack standing pallet. goal
arrange crates arbitrary stacks (possibly) pallets,
involve transporting crates locations (as pallets moved).
743

fiHoffmann

B.7 Dining-Philosophers
Dining-Philosophers encoding well-known Dining-Philosophers problem,
task planner find deadlock situation arises every philosopher
taken single fork. PDDL domain created automatic translation
automata-based Promela language. automata also referred processes.
Promela, philosopher finite automaton/process works follows.
start state, state 0, transition puts right fork onto table (this initialization
step), getting state 1. loop four states. state 1 state
2, philosopher takes right fork. 2 3, takes left fork, 3 4
puts right fork, state 4 puts left fork gets back state
1. process communicates neighbors communication
channel, queue, either contains fork, empty (if one adjacent philosophers
currently holding fork).
PDDL encoding, process state transition broken four actions.
first action activates chosen transition. second action initiates write read
command needed queue, deleting activation transition setting flags
queue update. third action updates, possible, queue contents. update
possible write command shall done full queue (a queue already contains
fork), read command shall done empty queue. fourth action wraps
process state transition up, re-setting flags.
Derived predicates used model conditions process blocked.
rules require outgoing transitions current state process blocked.
transition blocked activated, would need perform impossible queue
write/read operation sense impossible write/read operation yet
initiated.32 applying planning action initiating impossible write/read
command, blocking rules dont apply anymore resulting state dead end
planning tasks state space (but blocking situation process network,
according derived predicate rules modeling blocking).
remark that, IPC-4, also version Dining-Philosophers modeled
process blocking via additional planning operators, derived predicates. chose
consider other, above, domain version since constitutes natural concise
formulation, since planners IPC-4 scaled version without
derived predicates.
B.8 Driverlog
Driverlog variation Logistics, drivers needed trucks,
drivers trucks move along arbitrary (bi-directional) road maps. road maps
drivers trucks different. operators load/unload object onto/from
truck location, board/disembark driver onto/from truck location, walk
32. one outgoing transition activated time, process never become blocked
state one outgoing state transition. appears bug translation
Promela PDDL intuitive requirement would activated transition needs
blocked, outgoing transition need activated order blocked. Note
that, Dining-Philosophers, every automaton state one outgoing transition.

744

fiWhere Ignoring Delete Lists Works

driver location another one, drive truck driver location
another one. preconditions effects loading/unloading objects obvious
ones. driver board truck truck empty; effect, truck longer
empty (as well driven driver). Disembarking driver inverse action.
order walk driver l l0 , must path l l0 . order drive
truck l l0 , link l l0 (and must driver
truck). Paths links form arbitrary (in particular, potentially different) graphs
locations, restriction undirected, i.e., truck driver
move l l0 also move back. restriction imposed Driverlog
instances generated IPC-3 generator.
B.9 Ferry
Ferry, single ferry used transport cars locations, one time.
three operators. One sail ferry two locations. One board car onto
ferry location, deletes empty-ferry fact (plus adding car
ferry deleting car location). One debark car ferry
location, achieves empty-ferry (plus adding car location
deleting car ferry). goal subset cars goal
locations.
B.10 Freecell
Freecell domain STRIPS formulation widely known solitaire card game
comes Microsoft Windows. number cards different suits initially
arranged random stacks number columns. cards must put home.
suit cards, separate home column, cards suit must
stacked increasing order card value. number free cells. cards
moved around according certain rules. card clear card top
it. clear card put free cell (if already there), free cell holds
one card time. clear card moved onto empty column. clear card
c put home last card put home suit one preceding c. c
c0 clear cards differently colored suits, one stack c top c0 c0
free cell, cs card value one less card value c0 (so stacks
built columns, decreasing order card value, alternating colors). goal
reached topmost cards suits put home.
B.11 Fridge
Fridge, one must replace broken compressor fridge. this, one must remove
compressor; involves unfastening screws hold compressor,
turn involves first switching fridge off. goal new compressor attached
fridge, screws fastened, fridge switched back on. origin domain
STRIPS formulation. consider adaptation allows arbitrary number
fridges screws, compressor fastened (arbitrary, least one)
number screws. adaptation involves ADL precondition: compressor
745

fiHoffmann

removed screws unfastened. six operators. One stop/start fridge.
One unfasten/fasten screw from/to compressor attached fridge; so,
fridge needs turned off, compressor needs attached, screw must fit
compressor. Finally, one remove/attach compressor from/to fridge. Removing
compressor requires fridge turned off, none screws fit
compressor fastened. effect, compressor longer attached fridge,
fridge compressor free. Attaching compressor requires fridge
turned off, compressor fits fridge. effect, compressor attached,
compressor fridge longer free.
B.12 Grid
Grid, robot must move along positions arranged grid-like reachability
relation. positions locked, keys different shapes open them.
goal keys goal positions. five operators. One
move position p position p0 , requires (apart obvious preconditions)
p p0 connected, p0 open (not locked). One pick key
position, requires arm empty (one hold one key time),
effects one holds key, arm longer empty, key
longer position. Putting key position inverse action. One
abbreviate two previous actions pickup-and-lose keys k k0
position; this, one must hold k, directly exchanged k0 , i.e., effects
one holds k k0 position. Finally, one unlock position p0 one
position p connected p0 , holds key shape locked
position p0 ; add effect p0 open, delete effect position longer
locked. instances specify initial locations keys, locked positions,
robot, well shapes keys locked positions. goal specifies
positions subset keys. robot always starts open position.
make significant difference: robot allowed start locked position,
local minima h+ .33 Otherwise none, c.f. Theorem 2. Intuitively, makes
sense let robot located open positions only; restriction also holds true
published benchmark examples.
B.13 Gripper
Gripper, task transport number balls one location another.
three operators. One move locations. One pick ball location
hand; apart obvious preconditions requires hand empty;
effects obvious ones (the ball hand longer room) plus
hand longer empty. One drop ball location hand, inverts
effects picking action. always exactly two locations, two gripper
hands. Instances thus differ terms number balls. severe restrictions
hold true AIPS-1998 instances. remark adding locations and/or hands
33. Moving away locked initial position lead need applying several steps re-open
position. relaxed plan initial state realize this, since ignores delete
initial at-fact.

746

fiWhere Ignoring Delete Lists Works

affect topological properties h+ , fact proof arguments given
Theorems 1, 2, 3 remain valid case.
B.14 Hanoi
Hanoi domain STRIPS encoding classical Towers Hanoi problem.
n discs d1 , . . . , dn , three pegs p1 , p2 , p3 . single operator moves
object x object onto object z (the operator parameters grounded
discs well pegs). preconditions move x y, x clear, z
clear, x smaller z. effects x z clear, x
longer z longer clear. semantics Towers Hanoi encoded via
smaller relation. relation holds obvious way discs, discs
smaller pegs (the pegs smaller anything moved).
instances differ terms number n discs must transferred p1
p3 .
B.15 Logistics
Logistics classical transportation domain, objects must transported within
cities using trucks, different cities using airplanes. six operators,
drive truck two locations within city, fly airplane two airports,
load (unload) object onto (from) truck location, load (unload) object
onto (from) airplane airport. operators obvious preconditions
effects (the complicated operator moving truck, whose precondition
requires locations within city). always least one city,
city non-zero number locations one airport. arbitrary
number objects, airplanes (which located airports). goal
subset objects goal locations.
B.16 Miconic-ADL
Miconic-ADL ADL formulation complex elevator control problem occurring
real-world application planning (Koehler & Schuster, 2000). number passengers
waiting number floors transported lift, obeying variety constraints.
always least one floor, arbitrary number passengers,
given origin destination floor. three operators. lift move
floor f floor f f (transitively) f, vice versa moving downwards.
lift also stop floor. floor f, conditional effects
stopping action passengers waiting f boarded, passengers wanting get
f depart. goal serve passengers, i.e., bring destination
floor. constraints must obeyed following.
cases, passenger p access floor f; lift stop f
p boarded.
passengers VIPs; long served, lift stop
floors VIP getting off.
747

fiHoffmann

passengers must transported non-stop, i.e., boarded, lift
make intermediate stops stopping destination floor.
passengers travel alone, others attend them; one former
kind boarded, must least one latter kind.
groups B passengers allowed people
groups boarded simultaneously.
passengers transported direction travel, i.e.,
need go (down), then, boarded, lift move
downwards (upwards).
constraints formulated means complex first order preconditions
operators.
B.17 Miconic-SIMPLE
Miconic-SIMPLE domain Miconic-ADL described above, except
constraints all.
B.18 Miconic-STRIPS
Miconic-STRIPS domain almost Miconic-SIMPLE domain, see above.
difference boarding departing passengers done conditional
effects stopping operator, explicitly separate STRIPS operators. One board
passenger floor. precondition (current) floor passengers origin,
effect passenger boarded. One let passenger depart
floor. preconditions (current) floor passengers destination
passenger boarded, effects passenger served longer
boarded.
B.19 Movie
Movie, task prepare watching movie. seven different operators.
One rewind tape, adds tape rewound, deletes counter
zero. One reset counter, effect counter zero. One
get five different kinds snacks, (add) effect one respective
snack. Instances differ terms number items sort
snacks. goal always one snack sort, tape rewound,
counter zero.
B.20 Mprime
Mprime transportation kind domain, objects must transported
locations means vehicles, vehicles use non-replenishable fuel. instance,
set L locations, set objects, set V vehicles. also
sets F fuel numbers space numbers. location initially certain fuel
748

fiWhere Ignoring Delete Lists Works

number number fuel items available location vehicle certain
space number number objects vehicle carry time. operators
move vehicles locations, load (unload) objects onto (from) vehicles,
transfer fuel units locations. move location l location l0
made l l0 connected (where connection relation arbitrary graph),
least one fuel unit available l (l fuel number lower neighbor).
effect move, respective vehicle located l0 , amount fuel l
decreased one unit, i.e., l assigned next lower fuel number. similar fashion,
object loaded onto vehicle space that, effect available
space decreases. Unloading object frees space again. transfer operator
transfer one fuel unit location l location l0 , l l0 connected, l
least two fuel units left. result applying operator, ls fuel number decreases
one, l0 fuel number increases one. Note way re-gain fuel items
(one transfer around one obtain new ones). goal transport
subset objects goal locations.
B.21 Mystery
Mystery exactly Mprime domain described above, except
operator transfer fuel items.
B.22 Optical-Telegraph
Like Dining-Philosophers domain described Appendix B.7, Optical-Telegraph
PDDL compilation problem originally formulated automata-based Promela
language. mechanics PDDL compilation Dining-Philosophers,
using derived predicates detect blocked situations. problem involves n pairs communicating processes, pair featuring process. pair go
fairly long, heavily interactive, sequence operations, implementing possibility exchange data two stations. data exchanged, various initializing
steps must taken, ensure processes working synchronously. importantly,
process writes token control channel (queue) beginning
sequence, reads token end. causes deadlock situation
n control channels, accessed two processes.
precisely, process pairs arranged cycle, pair control channel. overall system blocked iff process pairs state
occupied (written into) one control channel, waiting occupy other.
sense, Optical-Telegraph viewed version Dining-Philosophers
internal states philosophers complicated. particular, philosophers
(process pairs) choose order pick forks (occupy control
channels). turns out, see Appendix A.2, latter important impact
topology h+ .
remark that, IPC-4, also version Optical-Telegraph modeled
process blocking via additional planning operators, derived predicates. chose
consider other, above, domain version since constitutes natural concise
749

fiHoffmann

formulation, since planners IPC-4 scaled version without
derived predicates.
B.23 Pipesworld
Pipesworld, units oil derivatives, called batches, must propagated
pipeline network. network consists areas connected pipe segments different
length. pipes completely filled batches times, one pushes batch
one end pipe, last batch currently pipe comes end.
interface restrictions concerning types oil derivatives allowed
adjacent inside pipe, tankage restrictions concerning
number batches (of derivative type) stored point time
individual areas.
available planning operator push batch pipe. IPC4 encoding domain, look here, non-unitary pipe segments (pipes
containing one batch) operator split two parts, start finish
action (in order reduce number operator parameters needed correctly update
pipe contents). Also, pipe segments encoded directed fashion, making necessary
distinguish (symmetrical) push pop actions. initial state specifies
current batch positions etc., goal specifies batches brought
areas.
B.24 PSR
PSR domain, used IPC-4, task re-supply given set lines faulty
electricity network. nodes network breakers, feed electricity
network, devices, switches used change network
configuration. edges network lines, connecting two three nodes.
breakers devices open closed. open, disconnect
lines adjacent them. breakers closed, feed electricity adjacent
lines. lines faulty. goal ensure none breakers
affected, i.e., feeds electricity faulty line, transitive connections
network. Also, goal requires given set lines (transitively) fed
electricity breaker.
transitive network semantics, determining breaker feeds electricity
line, breaker affected, modeled means various derived predicates (with
recursive rule antecedents enable computation transitive closure). three
planning operators. One open device breaker currently closed, one
inverse closing action. actions require precondition breaker
currently affected. latter untrue, i.e., breaker currently affected,
available action wait. effect open breakers affected.
remark that, IPC-4, also different version PSR, formulated
pure STRIPS without derived predicates. version constitutes, however, relatively
superficial pre-compiled form domain (Hoffmann & Edelkamp, 2005; Edelkamp et al.,
2005). included IPC-4 order provide pure STRIPS planners
750

fiWhere Ignoring Delete Lists Works

domain formulation could tackle (the pre-compilation necessary order enable
formulation pure STRIPS).
B.25 Rovers
Rovers, number rovers must navigate road map waypoints, take rock
soil samples well images, communicate data number landers.
nine available operators following. One navigate rover one waypoint
another this, waypoints must connected rover. One sample
soil/rock rover waypoint using store so, rover must
(empty) store equipped soil/rock analysis, must soil/rock sample
waypoint; effect one soil/rock analysis, store full, soil/rock
sample longer waypoint. One empty full store dropping store. One
calibrate camera waypoint using objective, one take image
objective mode camera waypoint. operators, object must
visible waypoint, camera must board rover equipped
imaging. calibrate camera, object must calibration target it;
effect operator calibration camera. take image, camera must
calibrated, support required mode. effects one image data,
camera longer calibrated. Finally, three operators
rover communicate soil/rock/image data lander. so, landers waypoint
must visible rover; effect data communicated.
instances restricted visibility connectivity waypoints
bi-directional waypoint w visible waypoint w0 holds true vice
versa; rover move w w0 also move back. Another restriction
camera initially calibrated (this serves make sure that, reachable state,
calibrated camera least one calibration target). restrictions imposed
Rovers instances generated IPC-3 generator.
B.26 Satellite
Satellite, satellites need take images different directions, certain modes, using
appropriate instruments. number satellites, number directions, number
instruments, number modes. following five operators. One
turn satellite direction another one; preconditions effects obvious
ones, action applied pair directions (no connectivity constraints).
One switch instrument board satellite, satellite power available;
effect, instrument power longer calibrated, satellite
power available. One switch instrument board satellite, instrument
power; effect, satellite power available, instrument anymore.
One calibrate instrument board satellite direction, satellite points
direction, instrument power, direction calibration target
instrument. effect calibration camera. Finally, one take
image instrument board satellite direction mode. so,
satellite must point direction, camera must support mode, power,
calibrated; effect one image direction mode.
751

fiHoffmann

goal images number direction/mode pairs; also, satellites
goal requirement point specified direction. initial states
satellite (but instrument) power available, instrument calibrated.
former restriction makes sure satellite power run one instrument
time; latter restriction makes sure that, reachable state, calibrated instrument
least one calibration target. restrictions imposed Satellite instances
generated IPC-3 generator.

B.27 Schedule
Schedule, collection objects must processed number machines, applying
working steps change objects shape, surface condition, color; one also drill
holes varying widths varying orientations. nine operators. Eight
describe working steps object machine. Amongst things, operators
preconditions require scheduled elsewhere machine busy,
operators effect scheduled, machine busy. ninth
operator time step, whose effect object scheduled, machine
busy, longer. One apply do-roll action object o, makes cylindrical
hot (no longer cold, see also below), deleting surface conditions, colors,
holes might have. One apply do-lathe o, making cylindrical rough
surface, deleting colors might painted before. One apply
do-polish cold, giving polished surface. One apply do-grind o,
giving smooth surface colors. One apply do-punch o, width w
orientation o, cold, resulting hole w o, rough surface. One
also apply do-drill-press o, cold, making hole width w orientation
(changing none os properties except making hole). cold, one
also apply do-spray-paint color c, deleting surface conditions might have.
Finally, one apply do-immersion-paint o, changing none os properties except
color. Note operator change os temperature, except do-roll
makes hot; that, made cold (this reason dead
ends arise, c.f. Theorem 1). Initially, objects cold, shape
surface condition specified. objects also painted initially, object
none several holes. goal condition, objects required
cylindrical shape (the shape produced machines),
need surface condition, must painted, object required
arbitrary number holes.

B.28 Simple-Tsp
Simple-Tsp trivial version TSP problem. single operator move
locations. applied two (different) locations, effect
(besides obvious ones) destination location visited. instances specify
number locations must visited, starting one them.
752

fiWhere Ignoring Delete Lists Works

B.29 Tireworld
Tireworld, one must replace number flat tires. involves collection objects
must used appropriate working steps. Briefly summarized, situation
follows. thirteen operators. boot either opened closed;
initially closed shall end. pump, wrench, jack
fetched put away (from/into boot); initially boot
shall put back end. spare wheels initially inflated, inflated
using pump (the add effect wheel inflated, delete effect
longer not-inflated). hub fastened nuts; loosened tightened,
using wrench, respective hub ground. jack used either
jack jack hub. hub jacked up, one undo (loose) nuts,
up; nuts undone, one remove respective wheel, put one.
optimal solution plan this: open boot; fetch tools; inflate spare wheels; loosen
nuts; turn jack hub, undo nuts, remove flat wheel, put spare
wheel, nuts, jack hub again; tighten nuts; put away tools;
close boot.
B.30 Zenotravel
Zenotravel transportation domain variant vehicles (called aircrafts) use fuel
units replenished using refueling operator. number cities,
number aircrafts, number persons, number different possible fuel levels.
fuel levels encode natural numbers next predicate next(f,f0 ) true iff f0
next higher fuel level f. task transport subset persons
initial locations goal locations. following five operators. One
board/debark person onto/from aircraft city; obvious preconditions effects. One fly aircraft city different city, decreasing
aircrafts fuel level f f0 ; f must aircrafts current fuel level, f0 must
next lower level. One also zoom aircraft; exactly flying it, except
zooming uses fuel aircrafts fuel level decreased two units. Finally,
one refuel aircraft city fuel level f fuel level f0 . conditions
f aircrafts current fuel level, f0 next higher level. Thus aircrafts
refueled city, steps one unit.

References
Bacchus, F. (2001). AIPS00 planning competition. AI Magazine, 22 (3), 4756.
Biundo, S., & Fox, M. (Eds.). (1999). Recent Advances AI Planning. 5th European
Conference Planning (ECP99), Lecture Notes Artificial Intelligence, Durham,
UK. Springer-Verlag.
Blum, A. L., & Furst, M. L. (1995). Fast planning planning graph analysis.
Mellish, S. (Ed.), Proceedings 14th International Joint Conference Artificial
Intelligence (IJCAI-95), pp. 16361642, Montreal, Canada. Morgan Kaufmann.
753

fiHoffmann

Blum, A. L., & Furst, M. L. (1997). Fast planning planning graph analysis. Artificial
Intelligence, 90 (1-2), 279298.
Bonet, B., & Geffner, H. (1999). Planning heuristic search: New results.. Biundo, &
Fox (Biundo & Fox, 1999), pp. 6072.
Bonet, B., & Geffner, H. (2001a). Heuristic search planner 2.0. AI Magazine, 22 (3),
7780.
Bonet, B., & Geffner, H. (2001b). Planning heuristic search. Artificial Intelligence,
129 (12), 533.
Bonet, B., Loerincs, G., & Geffner, H. (1997). robust fast action selection mechanism
planning. Kuipers, B. J., & Webber, B. (Eds.), Proceedings 14th National
Conference American Association Artificial Intelligence (AAAI-97), pp.
714719, Portland, OR. MIT Press.
Botea, A., Muller, M., & Schaeffer, J. (2004). Using component abstraction automatic
generation macro-actions.. Koenig et al. (Koenig, Zilberstein, & Koehler, 2004),
pp. 181190.
Botea, A., Muller, M., & Schaeffer, J. (2005). Learning partial-order macros solutions.
Biundo, S., Myers, K., & Rajan, K. (Eds.), Proceedings 15th International
Conference Automated Planning Scheduling (ICAPS-05), pp. 231240, Monterey, CA, USA. Morgan Kaufmann.
Brazdil, P., & Jorge, A. (Eds.)., EPIA-01 (2001). Proceedings 10th Portuguese Conference Artificial Intelligence (EPIA-01), Porto, Portugal. Springer-Verlag.
Bylander, T. (1994). computational complexity propositional STRIPS planning.
Artificial Intelligence, 69 (12), 165204.
Cesta, A., & Borrajo, D. (Eds.). (2001). Recent Advances AI Planning. 6th European
Conference Planning (ECP01), Lecture Notes Artificial Intelligence, Toledo,
Spain. Springer-Verlag.
Chen, Y., Hsu, C., & Wah, B. (2004). SGPlan: Subgoal partitioning resolution
planning.. Edelkamp et al. (Edelkamp, Hoffmann, Littman, & Younes, 2004).
Chen, Y., & Wah, B. (2003). Automated planning scheduling using calculus variations
discrete space.. Giunchiglia et al. (Giunchiglia, Muscettola, & Nau, 2003), pp.
211.
Chien, S., Kambhampati, R., & Knoblock, C. (Eds.)., AIPS-00 (2000). Proceedings
5th International Conference Artificial Intelligence Planning Systems (AIPS-00),
Breckenridge, CO. AAAI Press, Menlo Park.
Do, M. B., & Kambhampati, S. (2001). Sapa: domain-independent heuristic metric
temporal planner.. Cesta, & Borrajo (Cesta & Borrajo, 2001), pp. 109120.
Edelkamp, S. (2003a). Promela planning. Ball, T., & Rajamani, S. (Eds.), Proceedings
10th International SPIN Workshop Model Checking Software (SPIN-03),
pp. 197212, Portland, OR. Springer-Verlag.
Edelkamp, S. (2003b). Taming numbers durations model checking integrated
planning system. Journal Artificial Intelligence Research, 20, 195238.
754

fiWhere Ignoring Delete Lists Works

Edelkamp, S., & Helmert, M. (2001). MIPS: model checking integrated planning system.
AI Magazine, 22 (3), 6771.
Edelkamp, S., Hoffmann, J., Englert, R., Liporace, F., Thiebaux, S., & Trug, S. (2005).
Engineering benchmarks planning: domains used deterministic part
IPC-4. Journal Artificial Intelligence Research. Submitted.
Edelkamp, S., Hoffmann, J., Littman, M., & Younes, H. (Eds.)., IPC-04 (2004). Proceedings
4th International Planning Competition, Whistler, BC, Canada. JPL.
Fox, M., & Long, D. (1998). automatic inference state invariants TIM. Journal
Artificial Intelligence Research, 9, 367421.
Fox, M., & Long, D. (2001). STAN4: hybrid planning strategy based subproblem
abstraction. AI Magazine, 22 (3), 8184.
Frank, J., Cheeseman, P., & Stutz, J. (1997). gravity fails: Local search topology.
Journal Artificial Intelligence Research, 7, 249281.
Gazen, B. C., & Knoblock, C. (1997). Combining expressiveness UCPOP
efficiency Graphplan.. Steel, & Alami (Steel & Alami, 1997), pp. 221233.
Gerevini, A., & Schubert, L. (2000). Inferring state constraints DISCOPLAN: new
results.. Kautz, & Porter (Kautz & Porter, 2000), pp. 761767.
Gerevini, A., & Schubert, L. (2001). DISCOPLAN: efficient on-line system computing
planning domain invariants.. Cesta, & Borrajo (Cesta & Borrajo, 2001), pp. 433
436.
Gerevini, A., Saetti, A., & Serina, I. (2003). Planning stochastic local search
temporal action graphs. Journal Artificial Intelligence Research, 20, 239290.
Gerevini, A., & Serina, I. (2002). LPG: planner based local search planning graphs
action costs.. Ghallab et al. (Ghallab, Hertzberg, & Traverso, 2002), pp.
1322.
Gerevini, A., Serina, I., Saetti, A., & Spinoni, S. (2003). Local search techniques temporal
planning LPG.. Giunchiglia et al. (Giunchiglia et al., 2003). Accepted
publication.
Ghallab, M., Hertzberg, J., & Traverso, P. (Eds.)., AIPS-02 (2002). Proceedings 6th
International Conference Artificial Intelligence Planning Scheduling (AIPS02), Toulouse, France. Morgan Kaufmann.
Giunchiglia, E., Muscettola, N., & Nau, D. (Eds.)., ICAPS-03 (2003). Proceedings
13th International Conference Automated Planning Scheduling (ICAPS-03),
Trento, Italy. Morgan Kaufmann.
Haslum, P., & Geffner, H. (2000). Admissible heuristics optimal planning.. Chien
et al. (Chien, Kambhampati, & Knoblock, 2000), pp. 140149.
Helmert, M. (2003). Complexity results standard benchmark domains planning.
Artificial Intelligence, 143, 219262.
Helmert, M. (2004). planning heuristic based causal graph analysis.. Koenig et al.
(Koenig et al., 2004), pp. 161170.
755

fiHoffmann

Helmert, M., & Richter, S. (2004). Fast downward making use causal dependencies
problem representation.. Edelkamp et al. (Edelkamp et al., 2004).
Hoffmann, J. (2000). heuristic domain independent planning use enforced
hill-climbing algorithm. Ras, Z. W., & Ohsuga, S. (Eds.), Proceedings 12th
International Symposium Methodologies Intelligent Systems (ISMIS-00), pp.
216227, Charlotte, NC. Springer-Verlag.
Hoffmann, J. (2001a). FF: fast-forward planning system. AI Magazine, 22 (3),
5762.
Hoffmann, J. (2001b). Local search topology planning benchmarks: empirical analysis.. Nebel (Nebel, 2001), pp. 453458.
Hoffmann, J. (2002). Extending FF numerical state variables. Harmelen, F. V. (Ed.),
Proceedings 15th European Conference Artificial Intelligence (ECAI-02), pp.
571575, Lyon, France. Wiley.
Hoffmann, J. (2003a). Metric-FF planning system: Translating ignoring delete lists
numeric state variables. Journal Artificial Intelligence Research, 20, 291341.
Hoffmann, J. (2003b). Utilizing Problem Structure Planning: Local Search Approach,
Vol. 2854 Lecture Notes Artificial Intelligence. Springer-Verlag.
Hoffmann, J. (2003c).
ignoring delete lists works: Local search topology planning benchmarks.
Tech. rep. 185, Albert-Ludwigs-Universitat,
Institut fur Informatik, Freiburg, Germany.
Available http://www.mpiinf.mpg.de/hoffmann/papers/jair05report.ps.gz.
Hoffmann, J., & Edelkamp, S. (2005). deterministic part IPC-4: overview. Journal
Artificial Intelligence Research. appear.
Hoffmann, J., & Nebel, B. (2001a). FF planning system: Fast plan generation
heuristic search. Journal Artificial Intelligence Research, 14, 253302.
Hoffmann, J., & Nebel, B. (2001b). RIFO revisited: Detecting relaxed irrelevance.. Cesta,
& Borrajo (Cesta & Borrajo, 2001), pp. 325336.
Kautz, H. A., & Porter, B. (Eds.)., AAAI-00 (2000). Proceedings 17th National
Conference American Association Artificial Intelligence (AAAI-00), Austin,
TX. MIT Press.
Koehler, J., & Hoffmann, J. (2000). reasonable forced goal orderings use
agenda-driven planning algorithm. Journal Artificial Intelligence Research,
12, 338386.
Koehler, J., & Schuster, K. (2000). Elevator control planning problem.. Chien et al.
(Chien et al., 2000), pp. 331338.
Koenig, S., Zilberstein, S., & Koehler, J. (Eds.)., ICAPS-04 (2004). Proceedings
14th International Conference Automated Planning Scheduling (ICAPS-04),
Whistler, Canada. Morgan Kaufmann.
Long, D., & Fox, M. (2000). Automatic synthesis use generic types planning..
Chien et al. (Chien et al., 2000), pp. 196205.
756

fiWhere Ignoring Delete Lists Works

Long, D., & Fox, M. (2003). 3rd international planning competition: Results
analysis. Journal Artificial Intelligence Research, 20, 159.
McDermott, D. (1996). heuristic estimator means-ends analysis planning. Drabble, B. (Ed.), Proceedings 3rd International Conference Artificial Intelligence
Planning Systems (AIPS-96), pp. 142149. AAAI Press, Menlo Park.
McDermott, D. (2000). 1998 AI planning systems competition. AI Magazine,
21 (2), 3555.
McDermott, D. V. (1999). Using regression-match graphs control search planning.
Artificial Intelligence, 109 (1-2), 111159.
Nebel, B. (Ed.)., IJCAI-01 (2001). Proceedings 17th International Joint Conference
Artificial Intelligence (IJCAI-01), Seattle, Washington, USA. Morgan Kaufmann.
Nebel, B., Dimopoulos, Y., & Koehler, J. (1997). Ignoring irrelevant facts operators
plan generation.. Steel, & Alami (Steel & Alami, 1997), pp. 338350.
Nguyen, X., & Kambhampati, S. (2000). Extracting effective admissible heuristics
planning graph.. Kautz, & Porter (Kautz & Porter, 2000), pp. 798805.
Nguyen, X., & Kambhampati, S. (2001). Reviving partial order planning.. Nebel (Nebel,
2001), pp. 459464.
Onaindia, E., Sapena, O., Sebastia, L., & Marzal, E. (2001). Simplanner: executionmonitoring system replanning dynamic worlds.. Brazdil, & Jorge (Brazdil &
Jorge, 2001), pp. 393400.
Penberthy, J. S., & Weld, D. S. (1992). UCPOP: sound, complete, partial order planner
ADL. Nebel, B., Swartout, W., & Rich, C. (Eds.), Principles Knowledge
Representation Reasoning: Proceedings 3rd International Conference (KR92), pp. 103114, Cambridge, MA. Morgan Kaufmann.
Refanidis, I., & Vlahavas, I. (1999). GRT: domain independent heuristic STRIPS
worlds based greedy regression tables.. Biundo, & Fox (Biundo & Fox, 1999),
pp. 4759.
Refanidis, I., & Vlahavas, I. (2001). GRT planning system: Backward heuristic construction forward state-space planning. Journal Artificial Intelligence Research,
15, 115161.
Rintanen, J. (2000). iterative algorithm synthesizing invariants.. Kautz, & Porter
(Kautz & Porter, 2000), pp. 806811.
Sebastia, L., Onaindia, E., & Marzal, E. (2001). Stella: optimal sequential parallel
planner.. Brazdil, & Jorge (Brazdil & Jorge, 2001), pp. 409416.
Srivastava, B., Nguyen, X., Kambhampati, S., Do, M. B., Nambiar, U., Nie, Z., Nigenda, R.,
& Zimmermann, T. (2001). Altalt: Combining graphplan heuristic state search.
AI Magazine, 22 (3), 8890.
Steel, S., & Alami, R. (Eds.). (1997). Recent Advances AI Planning. 4th European Conference Planning (ECP97), Vol. 1348 Lecture Notes Artificial Intelligence,
Toulouse, France. Springer-Verlag.
757

fiHoffmann

Thiebaux, S., Hoffmann, J., & Nebel, B. (2003). defence PDDL axioms. Gottlob, G.
(Ed.), Proceedings 18th International Joint Conference Artificial Intelligence
(IJCAI-03), pp. 961966, Acapulco, Mexico. Morgan Kaufmann.
Thiebaux, S., Hoffmann, J., & Nebel, B. (2005). defence PDDL axioms. Artificial
Intelligence. appear.
Younes, H., & Simmons, R. (2002). role ground actions refinement planning..
Ghallab et al. (Ghallab et al., 2002), pp. 5461.

758

fiJournal Artificial Intelligence Research 24 (2005) 889-917

Submitted 11/04; published 12/05

Ignorability Statistical Probabilistic Inference
Manfred Jaeger

jaeger@cs.aau.dk

Institut Datalogi, Aalborg Universitet
Fredrik Bajers Vej 7 E, DK-9220 Aalborg

Abstract
dealing incomplete data statistical learning, incomplete observations
probabilistic inference, one needs distinguish fact certain event observed
fact observed event happened. Since modeling computational
complexities entailed maintaining proper distinction often prohibitive, one asks
conditions safely ignored. conditions given missing
random (mar) coarsened random (car) assumptions. paper provide
in-depth analysis several questions relating mar/car assumptions. Main purpose
study provide criteria one may evaluate whether car assumption
reasonable particular data collecting observational process. question
complicated fact several distinct versions mar/car assumptions exist.
therefore first provide overview different versions, highlight
distinction distributional coarsening variable induced versions. show
distributional versions less restrictive sufficient applications.
address two different perspectives question mar/car assumption
warranted. First provide static analysis characterizes admissibility
car assumption terms support structure joint probability distribution
complete data incomplete observations. obtain equivalence characterization
improves extends recent result Grunwald Halpern. turn
procedural analysis characterizes admissibility car assumption terms
procedural models actual data (or observation) generating process. main
result analysis stronger coarsened completely random (ccar) condition
arguably reasonable assumption, alone corresponds data coarsening
procedures satisfy natural robustness property.

1. Introduction
Probabilistic models become preeminent tool reasoning uncertainty
AI. probabilistic model consists state space W , probability distribution
states x W . given probabilistic model used probabilistic inference based
observations. observation determines subset U W true state known
belong to. Probabilities updated conditioning U .
required probabilistic models often learned empirical data using statistical
parameter estimation techniques. data consist sampled exact states W ,
often consists incomplete observations, establish exact
data point x belongs subset U W . learning probabilistic model,
using probabilistic inference, one should, principle, distinguish event
certain observation U made (U observed) event true
state W member U (U occurred). Ignoring distinction probabilistic
c
2005
AI Access Foundation. rights reserved.

fiJaeger

inference lead flawed probability assignments conditioning. Illustrations
given well-known probability puzzles like Monty-Hall problem three prisoners paradox. Ignoring distinction statistical learning lead construction
models fit true distribution W . spite known difficulties,
one usually tries avoid extra complexity incurred making proper distinction
U observed U occurred. statistics exists sizable literature
ignorability conditions permit learning procedures ignore distinction.
AI literature dealing probabilistic inference topic received rather scant attention, though realized early (Shafer, 1985; Pearl, 1988). Recently, however,
Grunwald Halpern (2003) provided in-depth analysis ignorability
probabilistic inference point view.
ignorability conditions required learning inference basically
mathematical form, expressed missing random (mar ) coarsened
random (car ) conditions. paper investigate several questions relating
formal conditions. central theme investigation provide deeper insight
makes observational process satisfy, violate, coarsened random condition.
question studied two different angles: first (Section 3) identify qualitative properties joint distribution true states observations make car
assumption feasible all. qualitative properties consider constraints
states observations nonzero probabilities. directly extends work
Grunwald Halpern (2003) (henceforth also referred GH ). fact, main result
Section 3 extension improvement one main results GH. Secondly
(Section 4), investigate general types observational procedures lead car
observations. This, again, directly extends material GH, well earlier
work Gill, van der Laan & Robins (1997) (henceforth also referred GvLR).
develop formal framework allows us analyze previous new types procedural
models unified systematic way. particular, framework allows us specify
precise conditions makes certain types observational processes natural reasonable. somewhat surprising result analysis arguably natural
classes observational processes correspond exactly processes result
observations coarsened completely random (ccar ) strengthened version
car often considered unrealistically strong assumption.

2. Fundamentals Coarse Data Ignorability
exist numerous definitions literature means data missing
coarsened random (Rubin, 1976; Dawid & Dickey, 1977; Heitjan & Rubin, 1991; Heitjan,
1994, 1997; Gill et al., 1997; Grunwald & Halpern, 2003). capture
basic principle, various definitions subtly different way substantially affect
implications. Section 2.1 give fairly comprehensive overview variant
definitions, analyze relationships. survey aim providing uniform
framework terminology different mar /car variants. Definitions attributed
earlier sources basic content first appeared, even though definitions
terminology differ details original versions (cf. also remarks
end Section 2.1).
890

fiIgnorability Statistical Probabilistic Inference

Special emphasis placed distinction distributional coarsening
variable induced versions car . paper main focus distributional
versions. Section 2.2 summarize results showing distributional car sufficient
establish ignorability probabilistic inference.
2.1 Defining Car
begin concepts introduced Rubin (1976) special case data
missing values. Assume concerned multivariate random variable X =
(X1 , . . . , Xk ), Xi takes values finite state space V . Observations X
incomplete, i.e. observe values = (y 1 , . . . , yk ), yi either value
xi Vi Xi , special missingness symbol . One view realization
random variable function X missingness indicator, ,
random variable values {0, 1} k :
= f (X, ),

(1)



(2)

= f (x, m) defined
yi =

xi mi = 0
.
mi = 1

Rubins (1976) original definition missing random condition conditional
distribution : data missing random iff m:
P (M = | X) constant {x | P (X = x) > 0, f (x, m) = y}.

(3)

refer condition -mar condition, indicate fact expressed
terms missingness indicator .
Example 2.1 Let X = (X1 , X2 ) V1 = V2 = {p, n}. interpret X1 , X2 two
medical tests possible outcomes positive negative. Suppose test X 1 always
performed first patient, test X 2 performed X1 comes
positive. Possible observations made
(n, ) = f ((n, n), (0, 1)) = f ((n, p), (0, 1)),
(p, n) = f ((p, n), (0, 0)),
(p, p) = f ((p, p), (0, 0)).
= (n, ) = (0, 1) obtain
P (M = | X = (n, n)) = P (M = | X = (n, p)) = 1,
(3) satisfied. values condition (3) trivially holds,
sets x-values (3) singletons (or empty).
also eliminate random vector definition mar , formulate
definition directly terms joint distribution X. this, observe
observed identified set
U (y) := {x | : yi 6= xi = yi }.
891

(4)

fiJaeger

set U (y) contains complete data values consistent observed y.
rephrase -mar
P (Y = | X) constant {x | P (X = x) > 0, x U (y)}.

(5)

call distributional mar condition, abbreviated d-mar , terms
joint distribution complete data X, observed data .
Example 2.2 (continued Example 2.1)
U ((n, )) = {(n, n), (n, p)}, U ((p, n)) = {(p, n)}, U ((p, p)) = {(p, p)}.
compute
P (Y = (n, ) | X = (n, n))) = P (Y = (n, ) | X = (n, p))) = 1.
Together (again trivial) conditions two possible -values, shows
(5).
-mar d-mar equivalent, given X one-to-one correspondence
, i.e. exists function h x, x U (y):
= f (x, m) = h(y)

(6)

(h simply translates {0, 1}-vector replacing occurrences 1,
values 0). Using (6) one easily derive one-to-one correspondence
conditions (3) (5), hence obtain equivalence -mar d-mar .
One advantage -mar easily leads strengthened condition missing
completely random (Rubin, 1976):
P (M = | X) constant {x | P (X = x) > 0}.

(7)

refer -mcar condition.
Example 2.3 (continued Example 2.2) obtain
P (M = (0, 1) | X = (n, p)) = 1 6= 0 = P (M = (0, 1) | X = (p, p)).
Thus, observations -mcar.
distributional version mcar slightly complex, defer statement
general case coarse data, turn to.
Missing attribute values one special way observations incomplete. possibilities include imperfectly observed values (e.g. X known
either x Vi x0 Vi ), partly attributed values (e.g. x V = Vj known
Xi = x Xj = x), etc. cases, incomplete observation X defines set
possible instantiations X consistent observation. leads
general concept coarse data (Heitjan & Rubin, 1991), generalizes concept
missing data observations arbitrary subsets state space. general setting
892

fiIgnorability Statistical Probabilistic Inference

convenient abstract particular structure state space product
ki=1 Vi induced multivariate X, instead assume univariate random variable
X taking values set W = {x1 , . . . , xn } (of course, preclude possibility
fact W = ki=1 Vi ). Abstracting missingness indicator , one imagine
coarse data produced X coarsening variable G. Again, one also take
coarsening variable G picture, model coarse data directly joint
distribution X random variable (the observed data) values 2 W .
view mostly adopt, therefore motivation following definition.
Definition 2.4 Let W = {x1 , . . . , xn }. coarse data space W
(W ) := {(x, U ) | x W, U W : x U }.
coarse data distribution probability distribution P (W ).
coarse data distribution seen joint distribution P (X, ) random
variable X values W , random variable values 2 W \ . joint
distribution X constrained condition X . Note that, thus, coarse
data spaces coarse data distributions actually represent true complete data
coarsened observation. remainder paper, P without arguments
always denote coarse data distribution sense Definition 2.4,
used interchangeably P (X, ). need refer (joint) distributions
random variables, listed explicitly arguments P . E.g.: P (X, G)
joint distribution X G.
Coarsening variables introduced following definition means specifying
conditional distribution given X.
Definition 2.5 Let G random variable values finite state space ,
f : W 2W \ ,

(8)


x P (X = x) > 0: x f (x, g);
x, x0 P (X = x) > 0, P (X = x0 ) > 0, U 2W \ , g :
f (x, g) = U, x0 U f (x0 , g) = U.

(9)

call pair (G, f ) coarsening variable X. Often also refer G alone
coarsening variable, case function f assumed implicitly given.
coarse data distribution P induced X (G, f ) P joint distribution
X f (X, G).
condition (9) always made explicit introduction coarsening
variables. However, noted Heitjan (1997), usually implied concept
coarsening variable. GvLR (pp. 283-285) consider somewhat general setup
f (x, g) take values 2 W directly, = f (x, g) observable
893

fiJaeger

U = (y) W obtained via mapping . introduction
intermediate observable necessary, example, dealing real-valued
random variables X. Since statistically tractable models
general distributions 2R , parameterization small subset 2 R needed.
example, could take values R R, (y 1 , y2 ) might defined interval
[min{y1 , y2 }, max{y1 , y2 }]. GvLR require (9) general; instead call f Cartesian
(9) satisfied.
following definition generalizes property (6) missingness indicators arbitrary
coarsening variables.
Definition 2.6 coarsening variable (G, f ) called invertible exists function
h : 2W \ ,

(10)

x, U x U , g :
U = f (x, g) g = h(U ).

(11)

alternative reading (11) G observable: coarse observation U
value g reconstructed, G treated fully observable random
variable.
generalize definition missing (completely) random coarse
data setting. begin generalization -mar .
Definition 2.7 (Heitjan, 1997) Let G coarsening variable X. joint distribution
P (X, G) G-car U W , g :
P (G = g | X) constant {x | P (X = x) > 0, f (x, g) = U }.

(12)

marginalizing coarsening variable G (or assuming variable G
first place), obtain following distributional version car .
Definition 2.8 (Heitjan & Rubin, 1991) Let P coarse data distribution. P d-car
U W
P (Y = U | X) constant {x | P (X = x) > 0, x U }.

(13)

X multivariate, incompleteness observations consists missing values,
d-car coincides d-mar , -car -mar .
Condition (12) refers joint distribution X G, condition (13) joint
distribution X . Since function X G, one always determine
joint distribution X G whether d-car holds induced coarse data
distribution. Conversely, coarse data distribution P (X, ) coarsening
variable G inducing P (X, ) given, general possible determine whether
P (X, G) G-car , joint distribution P (X, G) cannot reconstructed
given information. However, suitable assumptions G possible infer
P (X, G) G-car induced P (X, ) d-car . following
two theorems clarify relationships G-car d-car . theorems
essentially restatements conceptual framework results already given GvLR (pp.
284-285).
894

fiIgnorability Statistical Probabilistic Inference

Theorem 2.9 coarse data distribution P (X, ) d-car iff exists coarsening
variable G inducing P (X, ), P (X, G) G-car.
Proof: First assume P (X, ) d-car . construct canonical coarsening variable
G inducing P (X, ) follows: let = 2 W \ f (x, U ) := U x W U .
Define -valued coarsening variable G P (G = U | X = x) := P (Y = U | X = x).
Clearly, coarse data distribution induced G original P (X, ), P (X, G)
G-car .
Conversely, assume P (X, G) G-car G inducing P (X, ). Let U W ,
x U .
P (Y = U | X = x) = P (G {g | f (x, g) = U } | X = x)
X
=
P (G = g | X = x).
g:f (x,g)=U

(9) summation values g x U .
G-car , conditional probabilities P (G = g | X = x) constant x U . Thus
P (Y = U | X = x) constant x U , i.e. d-car holds.

following example shows d-car general imply G-car ,
fixed coarse data distribution P (X, ) induced coarsening variable
G-car holds, another coarsening variable G-car hold.
Example 2.10 (continued Example 2.3) already seen coarse data
distribution d-mar -mar, hence d-car -car.
coarsening variable inducing P (X, ). fact, even
simplest: let G1 trivial random variable assume one state, i.e. 1 = {g}.
Define f1
f1 ((n, n), g) = f1 ((n, p), g) = {(n, n), (n, p)},
f1 ((p, n), g) = {(p, n)},
f1 ((p, p), g) = {(p, p)}.
G1 induces P (X, ), P (X, G1 ) also trivially G-car.
Finally, let G2 defined 2 = {g1 , g2 } f2 (x, gi ) = f1 (x, g) x W
= 1, 2. Thus, G2 like G1 , trivial state space G1 split two
elements identical meaning. Let conditional distribution G 2 given X
P (G2 = g1 | X = (n, n)) = P (G2 = g2 | X = (n, p)) = 2/3,
P (G2 = g2 | X = (n, n)) = P (G2 = g1 | X = (n, p)) = 1/3,
P (G2 = g1 | X = (p, n)) = P (G2 = g1 | X = (p, p)) = 1.
Again, G2 induces P (X, ). However, P (X, G2 ) G-car,
f2 ((n, n), g1 ) = f2 ((n, p), g1 ) = {(n, n), (n, p)},
P (G2 = g1 | X = (n, n)) 6= P (G2 = g1 | X = (n, p))
violates G-car condition. G2 invertible sense Definition 2.6: when,
example, U = {(n, n), (n, p)} observed, possible determine whether value
G2 g1 g2 .
895

fiJaeger

following theorem shows non-invertibility G 2 preceding example
reason cannot deduce G-car P (X, G 2 ) d-car property
induced P (X, ). theorem completes picture G-car / d-car relationship.
Theorem 2.11 Let P (X, ) coarse data distribution, G invertible coarsening variable inducing P (X, ). P (X, ) d-car, P (X, G) G-car.
Proof: Let U W , g , x U , P (X = x) > 0 f (x, g) = U . Since G
invertible, f (x, g 0 ) 6= U g 0 6= g, hence
P (G = g | X = x) = P (Y = U | X = x).
assumption P d-car follows right-hand probability constant
x U , hence holds left-hand side, i.e. G-car holds.

turn coarsening completely random (ccar ). straightforward generalize definition -mcar general coarsening variables:
Definition 2.12 (Heitjan, 1994) Let G coarsening variable X. joint distribution P (X, G) G-ccar g
P (G = g | X) constant {x | P (X = x) > 0}.

(14)

distributional version ccar seem formalized previously
literature. GvLR refer coarsening completely random, provide formal
definition. However, implicit discussion mind slightly
restricted version following definition (the restriction limitation case
k = 1 Theorem 2.14 below).
first observe one cannot give definition d-ccar variant Definition 2.12
way Definition 2.8 varies Definition 2.7, would lead us
condition P (Y = U | X) constant {x | P (X = x) > 0}. would inconsistent
existence x W \ U P (X = x) > 0. However, real semantic core
d-car , arguably, much captured Definition 2.8, characterization given
Theorem 2.9. d-ccar , therefore, make analogous characterization basis
definition:
Definition 2.13 coarse data distribution P (X, ) d-ccar iff exists coarsening
variable G inducing P (X, ), P (X, G) G-ccar.
following theorem provides constructive characterization d-ccar .
Theorem 2.14 coarse data distribution P (X, ) d-ccar iff exists family {W 1 ,
. . . , Wk } partitions W , probability distribution ( 1 , . . . , k ) (W1 , . . . , Wk ),
x W P (X = x) > 0:
X
P (Y = U | X = x) =
.
(15)
i1,...,k

xU Wi

896

fiIgnorability Statistical Probabilistic Inference



Missing values

d-mar -mar

Coarse observations
(c)



-mcar

G-car

(a)(b)
=
=


(c)


G-ccar

d-car


(a)
=
=

d-ccar

Figure 1: Versions car . (a): exists G implication holds; (b):
invertible G implication holds; (c): equivalence holds G = .

Proof: Assume P d-ccar . Let G coarsening variable inducing P (X, ),
P (X, G) G-ccar . (9), value g induces partition Wi =
{Ui,1 , . . . , Ui,k(i) }, f (x, gi ) = Ui,j x Ui,j . partitions Wi together
:= P (G = gi | X) provide representation P (X, ) form (15).
Conversely, P (X, ) given (15) via partitions W 1 , . . . , Wk parameters ,
one defines coarsening variable G = {1, . . . , k}, P (G = g | X = x) = x
P (X = x) > 0, f (x, i) U W containing x. P (X, G) G-ccar
induces P (X, ), hence P (X, ) d-ccar .

before, G-ccar property P (X, G) cannot determined
induced coarse data distribution:
Example 2.15 (continuation Example 2.10) P (X, ) d-ccar induced
three coarsening variables , G 1 , G2 . However, P (X, G1 ) G-ccar, P (X, )
P (X, G2 ) not.
previous example also shows analog Theorem 2.11 holds ccar :
invertible, d-ccar induced P (X, ) cannot infer G-ccar
P (X, ).
Figure 1 summarizes different versions mar /car considered. distributional versions d-car d-ccar weaker - G- counterparts,
therefore less restrictive assumptions. time, sufficient establish
ignorability statistical learning probabilistic inference tasks. case
probabilistic inference detailed Theorem 2.18 following section.
statistical inference problems, too, required ignorability results obtained
distributional car versions, unless specific coarsening variable explicitly part
inference problem. Whenever coarsening variable G introduced artificial
construct modeling connection incomplete observations complete data,
one must aware G-car G-ccar conditions unnecessarily restrictive,
may lead us reject ignorability when, fact, ignorability holds (cf. Examples 2.3
2.15).
897

fiJaeger

conclude section three additional important remarks definitions car ,
needed complete picture different approaches car literature:
Remark 1: definitions given weak versions mar /car . Corresponding strong versions obtained dropping restriction P (X = x) > 0
(3),(5),(7),(12),(13),(14), respectively (15). Differences weak strong versions
car studied previous work (Jaeger, 2005). results obtained indicate
context probability updating weak versions suitable. reason
go details strong versions here.
Remark 2: definitions car differ originally given Rubin Heitjan definitions global definitions view mar /car property
joint distribution complete coarse data. original definitions, hand,
conditional single observation = U , impose constraints joint
distribution X values . local mar /car assumptions
required justify application certain probabilistic statistical inference
techniques single observation = U . global mar /car conditions stated justify inference techniques general strategies would applied possible
observation. Local versions car natural Bayesian statistical philosophy,
whereas global versions required frequentist interpretation. Global versions
car also used works (e.g., Jacobsen & Keiding, 1995; Gill et al., 1997;
Nielsen, 1997; Cator, 2004).
Remark 3: definitions results stated strictly limited case
finite W . already indicated discussion following Definition 2.5, extensions car
general state spaces C typically require setup observations modeled
random variable taking values manageable state space 2 C . Several
formalizations car continuous state spaces investigated (e.g., Jacobsen &
Keiding, 1995; Gill et al., 1997; Nielsen, 2000; Cator, 2004).
2.2 Ignorability
Car mar assumptions needed ignoring distinction U observed
U occurred statistical inference probability updating. statistical inference, example, d-car required justify likelihood maximizing techniques like
EM algorithm (Dempster, Laird, & Rubin, 1977) learning incomplete data.
paper emphasis probability updating. therefore briefly review significance
car context. use well-known Monty Hall problem.
Example 2.16 contestant game show asked choose one three closed doors
A, B, C, behind one hidden valuable prize, others hiding goat.
contestant chooses door A, say. host opens door B, revealing goat. point
contestant allowed change choice C. Would advantageous?
savvy probabilistic reasoner, contestant knows analyze
situation using coarse data space ({A, B, C}), compute probabilities
P (X = | = {A, C}), P (X = C | = {A, C}).
898

fiIgnorability Statistical Probabilistic Inference

makes following assumptions: 1. A-priori doors equally likely hide
prize. 2. Independent contestants choice, host always open one door. 3.
host never open door chosen contestant. 4. host never open
door hiding prize. 5. one possible door remain host,
determine fair coin flip one open. this, contestant first obtains
P (Y = {A, C} | X = A) = 1/2, P (Y = {A, C} | X = C) = 1,

(16)


P (X = | = {A, C}) = 1/3, P (X = C | = {A, C}) = 2/3.
conclusion, thus, advantageous switch door C. different
conclusion obtained simply conditioning state space W {A, C} occurred:
P (X = | X {A, C}) = 1/2, P (X = C | X {A, C}) = 1/2.
Example 2.17 Consider similar situation previous example, assume
contestant decided would pick door A,
communicating choice host, host says let make things little easier
you, opens door B, reveals goat. Would changing C advantageous?
contestant performs similar analysis before, based following
assumptions: 1. A-priori doors equally likely hide prize. 2. hosts decision
open door independent location prize. 3. Given decision open
door, host chose fair coin flip one two doors hiding prize.
P (Y = {A, C} | X = A) = P (Y = {A, C} | X = C),

(17)

hence
P (X = | = {A, C}) = 1/2, P (X = C | = {A, C}) = 1/2.
particular
P (X = | = {A, C}) = P (X = | X {A, C})
P (X = C | = {A, C}) = P (X = C | X {A, C}),
i.e. difference {A, C} observed {A, C} occurred ignored
probability updating.
coarse data distribution Example 2.16 d-car (as evidenced (16)), whereas
coarse data distribution Example 2.17 d-car (as shown, part, (17)).
connection ignorability probability updating d-car assumption
shown GvLR GH. following theorem restates connection terminology.
Theorem 2.18 Let P coarse data distribution. following equivalent:
(i) P d-car.
(ii) x W , U W x U P (Y = U ) > 0:
P (X = x | = U ) = P (X = x | X U ).
899

fiJaeger

(iii) x W , U W x U P (X = x) > 0:
P (Y = U | X = x) =

P (Y = U )
.
P (X U )

equivalence (i)(ii) shown GH, based GvLR. equivalence (iii)
see (Jaeger, 2005).

3. Criteria Car Ccar
Given coarse data distribution P is, principle, easy determine whether P d-car
(d-ccar ) based Definition 2.8, respectively Theorem 2.14 (though case d-ccar
test might require search possible families partitions). However, typically P
completely known. Instead, usually partial information P .
case statistical inference problems information consists sample U 1 , . . . , UN
coarse data variable . case conditional probabilistic inference, know
marginal P W . cases would like decide whether partial knowledge
P possess, conjunction certain assumptions structure
P want make, consistent d-car , respectively d-ccar , i.e. whether
exists distribution P d-car (d-ccar ), satisfies partial knowledge
additional assumptions.
statistical problems, additional assumptions P usually come form
parametric representation distribution X. X = (X 1 , . . . , Xk ) multivariate,
parametric representation consist, example, factorization joint
distribution Xi , induced certain conditional independence assumptions.
probabilistic inference problems analysis evidence gathering process lead
assumptions likelihoods possible observations. cases, one
determine whether constraints imposed P partial knowledge assumptions
consistent constraints imposed d-car assumption. general,
lead computationally difficult optimization constraint satisfaction problems.
Like GH, focus section rather idealized special problem within
wider area, consider case constraints P establish values
variables X assume nonzero probability, i.e. constraints P consist
prescribed sets support X . interpret special case reduced
form specific statistical setting, assuming observed sample U 1 , . . . , UN
used infer observations possible, parametric model
X, too, used determine x W nonzero probabilities. Similarly,
probabilistic inference setting, special case occurs knowledge
distribution X used identify x P (X = x) > 0, assumptions
evidence generation pertain set possible observations.
GH represent specific support structure P form 0, 1-matrix,
call CARacterizing matrix. following definition provide equivalent,
different, encoding support structures P .
Definition 3.1 support hypergraph (for given coarse data space (W )) hypergraph
form (N , W 0 ),
900

fiIgnorability Statistical Probabilistic Inference

N 2W \ set nodes,
W 0 W set edges, edge x W 0 contains nodes
{U N | x U }.
(N , W 0 ) called support hypergraph distribution P (W ) iff N = {U
2W \ | P (Y = U ) > 0}, W 0 = {x W | P (X = x) > 0}. support hypergraph
car-compatible iff support hypergraph d-car distribution P .
PSfrag replacements

{A, C}

{A, B}

B

{A, B}
{A, C}

C B


{B, C}
C
(b)

(a)

Figure 2: Support hypergraphs Examples 2.16 2.17
Example 3.2 Figure 2 (a) shows support hypergraph coarse data distribution
Example 2.16; (b) Example 2.17.
definition support hypergraph may appear strange, much natural definition would take states x W P (X = x) > 0 nodes, observations
U W edges. support hypergraph Definition 3.1 dual
natural support hypergraph. turns duals useful purpose
analysis.
support hypergraph contain multiple edges containing nodes.
corresponds multiple states distinguished possible observations.
Similarly, support hypergraph contain multiple nodes belong exactly
edges. corresponds different observations U, U 0 U {x | P (X = x) > 0} =
U 0 {x | P (X = x) > 0}. hand, support hypergraph cannot contain
node contained least one edge (this would correspond observation U
P (Y = U ) > 0 P (X U ) = 0). Similarly, cannot contain empty edges.
restrictions support hypergraphs:
Theorem 3.3 hypergraph (N , E) finite N E support hypergraph
distribution P , iff node N contained least one edge E, edges
nonempty.
Proof: Let W = E define P (X = x) = 1/ | E | x W . node n N let
U (n) {x W | n x} (nonempty!), define P (Y = U (n) | X = x) = 1/ | x |.
(N , E) support hypergraph P .


901

fiJaeger

(almost) every hypergraph, thus, support hypergraph distribution, rather special hypergraphs support hypergraphs d-car distribution.
goal, now, characterize car -compatible support hypergraphs. following
proposition gives first characterization. similar lemma 4.3 GH.
Proposition 3.4 support hypergraph (N , W 0 ) car-compatible iff exists function : N (0, 1], x W 0
X

(U ) = 1

(18)

U N :U x

Proof: First note proposition looking x U edges nodes,
respectively, support hypergraph, writing U x makes sense, means
x U x U seen states, respectively sets states, coarse
data space.
Suppose (N , W 0 ) support hypergraph d-car distribution P . follows
Lemma 2.18 (U ) := P (Y = U )/P (X U ) defines function required
property. Conversely, assume given. Let P (X) distribution W
support W 0 . Setting P (Y = U | X = x) := (U ) U N , x W 0 U extends P
d-car distribution whose support hypergraph (N , W 0 ).


Corollary 3.5 support hypergraph contains (properly) nested edges,
car-compatible.
Example 3.6 support hypergraph Example 2.16 contains nested edges. Without
numerical computations, thus follows alone qualitative analysis
observations could made, coarse data distribution d-car, hence
conditioning valid update strategy.
proof Proposition 3.4 shows (as already observed GH ) support
hypergraph car -compatible, car -compatible given distribution P (X)
support W 0 , i.e. support assumptions encoded hypergraph, together
d-car assumption (if jointly consistent), impose constraints distribution
X (other prescribed set support). true
marginal : car -compatible support hypergraph (N , W 0 ) usually also
exist distributions P (Y ) N P (Y ) cannot extended d-car distribution
support structure specified hypergraph (N , W 0 ).
Proposition 3.4 already provides complete characterization car -compatible support
hypergraphs, used basis decision procedure car -compatibility
using methods linear constraint satisfaction. However, Proposition 3.4 provide
much real insight makes evidence hypergraph car -compatible. Much
intuitive insight provided Corollary 3.5. criterion provided Corollary 3.5
complete: following example shows, exist support hypergraphs without
nested edges car -compatible.
902

fiPSfrag replacements

Ignorability Statistical Probabilistic Inference

x1

x2

U1

U4

U2

U5

U3

U6

x3
x4

x5
Figure 3: car -incompatible support hypergraph without nested edges
Example 3.7 Let (N , W 0 ) shown Figure 3. assuming existence suitable
function , summing
(18) x 1 x2 , x3 , x4 , x5 , obtain
P
contradiction 2 = 6i=1 (Ui ) = 3. Thus, (N , W 0 ) car-compatible.
proceed extend partial characterization car -compatibility provided
Corollary 3.5 complete characterization. following result improves theorem 4.4
GH giving necessary sufficient condition car -compatibility, rather
several necessary ones, and, arguably, providing criterion intuitive
easier apply. characterization based following definition.

Definition 3.8 Let (N , W 0 ) support hypergraph. Let x = x1 , . . . , xk finite sequence edges W 0 , possibly containing repetitions edge. Denote
length k sequence | x |. x W denote 1 x indicator function N
induced x, i.e.

1 U x
1x (U ) :=
(U N ).
0 else
P
function 1x (U ) := xx 1x (U ) counts number edges x contain U .
two sequences x, x0 write 1x 1x0 iff 1x (U ) 1x0 (U ) U .
Example 3.9 evidence hypergraph Figure 3 1 (x1 ,x2 ) = 1(x3 ,x4 ,x5 )
function N constant 1.
x = (x1 , x3 , x4 , x5 ) one obtains 1x (U ) = 2 U = U1 , U2 , U3 , 1x (U ) = 1
U = U4 , U5 , U6 . function also defined x = (x 1 , x1 , x2 ).
evidence hypergraph, one two single edges x, x 0 : 1x < 1x0 iff x
proper subset x0 .
obtain following characterization (which partly inspired known conditions existence finitely additive measures, see Bhaskara Rao & Bhaskara Rao,
1983):
Theorem 3.10 support hypergraph (N , W 0 ) car-compatible iff every two sequences x, x0 edges W 0
1x = 1 x 0

| x |=| x0 |,

(19)
0

1x 1x0 , 1x 6= 1x0 | x |<| x | .
903

(20)

fiJaeger

Proof: Denote k :=| W 0 |, l :=| N |. Let = (ai,j ) incidence matrix (N , W 0 ), i.e.
k l matrix ai,j = 1 Uj xi , ai,j = 0 Uj 6 xi (using indexings
i, j W 0 N ).
Condition (3.4) reads:
exists (0, 1]l = 1

(21)

(here 1 vector k ones). edge indicator function 1 x represented row
vector z Nk , zi number times xi occurs x. 1x written
row vector zA, conditions Theorem 3.10 become: z, z 0 Nk :
zA = z 0 z 1 = z 0 1,
0

(22)

0

0

zA z A, zA 6= z z 1 < z 1.

(23)

Subtracting right sides, equivalent to: z Z k :
zA = 0 z 1 = 0,

(24)

zA 0, zA 6= 0 z 1 < 0.

(25)

Using Farkass lemma (see e.g. Schrijver, 1986, Section 7.3), one obtains conditions (24) (25) necessary sufficient (21). application Farkass
lemma particular setting one observe since 1 rational,
sufficient (24) (25) rational z (cf. Schrijver, 1986[p.85]). This, turn,
equivalent (24) (25) integer z. strict positivity solution
derived conditions (24) (25) analogous arguments Corollary 7.1k
(Schrijver, 1986).

Example 3.11 Example 3.9 immediately obtain nested edges x, x 0 violate
(20), hence obtain Corollary 3.5. Also sequences (x 1 , x2 ) (x3 , x4 , x5 )
support hypergraph Figure 3 violate (19), obtain car-incompatibility hypergraph.
PSfrag replacements

(a)

(b-i)

(b-ii)

(c)

(d)

Figure 4: Car -compatible support hypergraphs three nodes
Example 3.12 GH (Example 4.6) derive complete characterization car-compatibility
case exactly three different observations made positive probability.
framework amounts finding support hypergraphs three nodes satisfy
conditions Theorem 3.10. possible solutions shown Figure 4 (omitting
equivalent solutions obtained duplicating edges). labeling (a)-(d) solutions
904

fiIgnorability Statistical Probabilistic Inference

corresponds case enumeration GH. easy verify shown support
hypergraphs satisfy (19) (20). hypergraphs follows
facts adding new edge shown hypergraphs either leads hypergraph
already list (only possible pair (b-i) (b-ii)), introduces pair nested
edges. Similarly, deleting edge either leads hypergraph already shown,
invalid hypergraph nodes covered.

4. Procedural Models
far emphasized distributional perspective car . tried identify car joint distribution complete coarse data. point view
coarsening variables artificial construct introduced describe joint distribution. cases, however, coarsening variable also model actual physical,
stochastic process leads data coarsening. cases, analysis
obviously take concrete model underlying coarsening process account.
section study d-car distributions terms procedural models data
generating mechanism. results section extend previous investigations car
mechanisms GvLR GH.
first goal section determine canonical procedural models coarsening mechanisms leading d-car data. canonical models used practice
evaluating whether d-car assumption warranted particular data set investigation matching (partially known hypothesized) coarsening mechanism
data canonical models. investigation focus properties
one may expect reasonable natural procedural models possess. properties
captured two formal conditions honesty robustness. analysis
conditions provide new strong support d-ccar assumption.
following definition procedural model essentially generalization coarsening
variables, obtained omitting condition (9), replacing single variable G
(potentially infinite) sequence G.
Definition 4.1 Let P coarse data distribution (W ). procedural model P
given
random variable X distributed according marginal P W .
finite infinite sequence G = G1 , G2 , . . . , random variables, G takes
values finite set (i 1).
function f : W 2W \ , (X, f (X, G)) distributed according
P .
also call procedural model (X, G, f ) car model (ccar model), coarse data
distribution P defines d-car (d-ccar ). following denote .
natural coarsening processes modeled real-valued coarsening variables
(e.g. censoring times, Heitjan & Rubin, 1991). accommodate real-valued variables
Z framework identifying Z sequence binary random variables Z (i 1)
defining binary representation. sequence G containing continuous Z = G
905

fiJaeger

replaced sequence G0 original variables Gj (j 6= i) interleaved
binary Zi .
following, discuss measurability issues detail (only Appendix
small amount measure theory needed). mentioned, however,
always assumed W equipped -algebra equal powerset,
W generated product -algebra, f 1 (U ) measurable
U W .
f2.16
h



{A, C}
{A, B}

B
{A, B}
{A, B}

C
{A, C}
{A, C}

f2.17
h



{A, C}
{A, B}

B
{B, C}
{A, B}

C
{B, C}
{A, C}

Table 1: Procedural models Examples 2.16 2.17

Example 4.2 Natural procedural models coarse data distributions Examples 2.16
2.17 constructed letting G = F represent coin flip determines door
opened. Suppose examples host following rule matching
result coin flip potential doors opening: coin comes heads,
host opens door first alphabetical order among doors (two,
most) rules permit open. coin comes tails, opens door last
alphabetical order. formally represented procedural model X
{A, B, C}-valued, uniformly distributed random variable, G consists single {h, t}valued, uniformly distributed random variable F , X F independent.
Table 1 completes specification procedural models defining functions
f2.16 f2.17 respective examples. Note neither (F, f 2.16 ) (F, f2.17 )
coarsening variables sense Definition 2.5, e.g. f 2.16 (B, h) 6= f2.16 (A, h),
violation (9).
two procedures described preceding example appear quite similar, yet one
produces d-car distribution not. interested identifying
classes procedural models guaranteed induce d-car (d-ccar ) distributions.
Conversely, given d-car distribution P , would like identify procedural models
might induced P . begin class procedural models stands
trivial one-to-one correspondence d-car distributions.
Example 4.3 ( Direct car model) Let X W -valued random variable, G = G 1
1 = 2W \ . Let joint distribution X G 1 P (G1 = U | X = x) = 0
x 6 U ,
P (G1 = U | X = x) constant {x | P (X = x) > 0, x U }.

(26)

Define f (x, U ) = U . Procedural models form coarsening variable representations d-car distributions already encountered Theorem 2.9. Hence,
coarse data distribution P d-car iff induced direct car model.
906

fiIgnorability Statistical Probabilistic Inference

direct car models much restatement d-car definition.
help us much endeavor identify canonical observational datagenerating processes lead d-car distributions, condition (26)
correspond easily interpretable condition experimental setup.
d-ccar situation quite different: direct encoding d-ccar condition
leads rather natural class procedural models. class models described next
could called, analogy Example 4.3, direct ccar models. Since models
described permit natural interpretation, give different name, however.
Example 4.4 ( Multiple grouped data model, MGD) Let X W -valued random variable. Let (W1 , . . . , Wk ) family partitions W (cf. Theorem 2.14). Let G = G 1 ,
G1 takes values {1, . . . , k} independent X. Define f (x, i) U W
contains x. (X, G1 , f ) ccar. Conversely, every d-ccar coarse data model
induced multiple grouped data model.
multiple grouped data model corresponds exactly CARgen procedure GH.
allows intuitive interpretations representing procedures one randomly selects one
k different available sensors tests, reveal true value X
accuracy represented set U W containing x. special case k = 1
corresponds grouped censored data (Heitjan & Rubin, 1991). GH introduced CARgen
procedure guaranteed produce d-car distributions. consider dccar , therefore establish exact correspondence CARgen d-ccar .
similar vein, GvLR introduced general procedure generating d-car distributions.
following example rephrases construction GvLR terminology.
Example 4.5 ( Randomized monotone coarsening, RMC) Let X W -valued random
variable. Let G = H1 , S1 , H2 , S2 , . . . , Sn1 , Hn , Hi take values 2W , Si
{0, 1}-valued. Define

Hi
X Hi
Hi :=
W \ Hi X 6 Hi .
Let conditional distribution H given X H1 , . . . , Hi1 concentrated subsets
i1
j=1 Hj .
model represents procedure one successively refines current coarse data
set Ai := i1
h=1 Hh selecting random subset H Ai checking whether X Hi
not, thus computing Hi Ai+1 . process continued first time = 1
(i.e. Si represent stopping conditions). result procedure, represented
following function f :
min{k|Sk =1}

f (X, (H1 , S1 , . . . , Sn1 , Hn )) = i=1

Hi .

Finally, impose conditional independence condition distribution
Hi , Si depend X H1 , . . . , Hi1 , i.e.
P (Hi | X, H1 , . . . , Hi1 ) = P (Hi | H1 , . . . , Hi1 )
P (Si | X, H1 , . . . , Hi1 ) = P (Si | H1 , . . . , Hi1 ).
907

fiJaeger

shown GvLR, RMC model always generates d-car distribution, every
d-car distribution obtained way. GH state RMC models special case
CARgen models. see below, CARgen RMC actually equivalent,
thus, correspond exactly d-ccar distributions. distribution Example 2.17
standard example (already used slightly different form GvLR) d-car
distribution cannot generated RMC CARgen. question considerable
interest, then, whether exist natural procedural models correspond exactly
d-car distributions. GvLR state cannot conceive general mechanism
randomized monotone coarsening scheme constructing car mechanisms
one would expect meet practice,. . . (p.267). GH, hand, generalize
CARgen models class models termed CARgen , show exactly
comprise models inducing d-car distributions.
However, exact extent CARgen natural reasonable
trivial direct car models formally characterized. discuss issue
below. First present another class procedural models. rather intuitive class
contains models equivalent CARgen/RMC model.
Example 4.6 ( Uniform noise model) Let X W -valued random variable. Let G =
N1 , H1 , N2 , H2 , . . ., Ni {0, 1}-valued, Hi W -valued
P (Hi = x) = 1/ | W |

(x W ).

(27)

Let X, N1 , H1 , . . . independent. Define hi W, ni {0, 1}:
f (x, (n1 , h1 , . . .)) = {x} {hi | : ni = 1}.

(28)

model describes procedure several steps (perhaps infinitely many) uniformly
selected states W added noise observation. random variables N
represent events cause additional noise added. distributions generated
procedure d-car, x, U x U :
P (Y = U | X = x) = P ({hi | : ni = 1} = U ) + P ({hi | : ni = 1} = U \ {x}).
uniformity condition (27), independence family {X, N 1 , H1 , . . .},
last probability term equation constant x U .
uniform noise model generate exactly d-car distribution Example 2.17.
However, generate variant distribution originally given GvLR.
uniform noise model rather specialized, far able induce every
possible d-car distribution. mentioned above, GH proposed procedure called
CARgen generating exactly d-car distributions. procedure described GH
form randomized algorithm, easily recast form procedural
model sense Definition 4.1. shall pursue detail, however, instead
present procedure essential properties CARgen (especially
regard formal reasonableness conditions shall introduce below), somewhat
simpler perhaps slightly intuitive.
908

fiIgnorability Statistical Probabilistic Inference

Example 4.7 (Propose test model, P&T)) Let X W -valued random variable. Let
G = G1 , G2 , . . . infinite sequence random variables taking values 2 W \ . Let
X, G1 , G2 , . . . independent, Gi identically distributed,
X
P (Gi = U ) constant {x W | P (X = x) > 0}.
(29)
U :xU

Define
f (x, (U1 , U2 , . . .) :=



Ui
W

= min{j 1 | x Uj }
.
{j 1 | x Uj } =

P&T model describes procedure randomly propose set U W , test
whether x U , return U result positive (else continue). condition (29)
understood unbiasedness condition, ensures every x W (with
P (X = x) > 0) equally likely draw positive test x. following theorem
analogous Theorem 4.9 GH ; proof much simpler, however.
Theorem 4.8 coarse data distribution P d-car iff induced P&T model.
Proof: every distribution induced P&T model d-car follows immediately
X
P (Y = U | X = x) = P (Gi = U )/
P (Gi = U 0 ).
(30)
U 0 :xU 0

(29) constant {x U | P (X = x) > 0} (note, too, (29) ensures
sum denominator (30) nonzero x, definition f case
{j 1 | x Uj } = occurs probability zero).
P
Conversely, let P d-car distribution (W ). Define c := U 2W P (Y = U | X
U ),
P (Gi = U ) = P (Y = U | X U )/c.
Since
P (Y = U | X U ) = P (Y = U | X = x) x U P (X = x) > 0,
P
U :xU P (Y = U | X U ) = 1 x W P (X = x) > 0. follows (29)
satisfied 1/c constant. resulting P &T model induces original P :
P (f (X, G) = U | X = x) = (P (Y = U | X U )/c)/(

X

P (Y = U 0 | X U 0 )/c)

U 0 :xU 0

= P (Y = U | X U ) = P (Y = U | X = x).

P&T model looks like reasonable natural procedure. However, violates desideratum GvLR put forward natural coarsening procedure:
(D) coarsening procedure, information true value
X used finally revealed coarse data variable (Gill
et al., 1997, p.266, paraphrased).
909

fiJaeger

P&T model violates desideratum (D), first unsuccessfully test U 1 , . . . ,
Uk , require information x 6 ki=1 Ui , included final data
= Uk+1 . observation generating process Example 2.17, too, appears violate
(D), host requires precise value X following strategy. Finally,
uniform noise model violates (D), computation (28) final coarse data
output exact value X required. examples suggest (D) condition
one must necessarily expect every natural coarsening procedure possess. (D)
appropriate coarse data generated experimental process aimed
determining true value X, may unable precisely. scenario,
(D) corresponds assumption information value X collected
experimental process also reported final result. Apart experimental
procedures, also accidental processes corrupting complete data generate d-car data (as
represented, e.g., uniform noise model). procedures (D) immediately
seen necessary feature. However, Theorem 4.17 lend additional support
(D) also cases.
GH argue class CARgen procedures contains reasonable processes,
step algorithm depend information available experimenter, information encoded observations made experimenter
course running algorithm(GH, p. 260). said
P&T procedure. direct car model would reasonable sense,
simulation variable G one would need pick distribution dependent
true value X, assumed available. However, hard make rigorous
distinction direct car models one hand, CARgen /P&T
hand, latter procedures permit tests value X (through checking
X U test sets U using singleton sets U one even query exact value X),
continuation simulation dependent outcome tests.
establish solid foundation discussing reasonable vs. unreasonable coarsening procedures introducing two different rigorous conditions natural
reasonable car procedures. One formalization desideratum (D),
expresses invariance car property numerical parameter changes.
show conditions satisfied generated distribution
d-ccar . purpose analysis helpful restrict attention special type
procedural models.
Definition 4.9 procedural model (X, G, f ) Bernoulli-model family X, G 1 ,
G2 , . . . independent.
name Bernoulli model quite appropriate here, variables X, G
necessarily binary. However, clear one could also replace multinomial
X Gi suitable sets (independent) binary random variables. essence, then,
Bernoulli model sense Definition 4.9 seen infinite sequence
independent coin tosses (with coins varying bias). Focusing Bernoulli models
real limitation:
Theorem 4.10 Let (X, G, f ) procedural model. exists Bernoulli model
(X, G , f ) inducing coarse data distribution.
910

fiIgnorability Statistical Probabilistic Inference

reader may notice statement Theorem 4.10 really quite trivial:
coarse data distribution induced (X, G, f ) distribution finite coarse
data space (W ), many simple, direct constructions Bernoulli models
given distribution. significance Theorem 4.10, therefore, lies essentially
following proof, construct Bernoulli model (X, G , f ) preserves
essential procedural characteristics original model (X, G, f ). fact, model
(X, G , f ) understood implementation procedure (X, G, f ) using
generator independent random numbers.
understand intuition construction, consider randomized algorithm
simulating procedural model (X, G, f ). algorithm successively samples values
X, G1 , G2 , . . ., finally computes f (for natural procedural models value f
already determined finitely many initial G -values, infinitely many G
need sampled, algorithm actually terminates; considerations, however,
algorithms taking infinite time pose conceptual difficulties). distribution used
sampling Gi may depend values previously sampled G 1 , . . . , Gi1 , which,
computer implementation algorithm encoded current program state.
set possible runs algorithm represented tree, branching nodes correspond sampling steps G . single execution algorithm
generates one branch tree. One construct equivalent algorithm that,
instead, generates whole tree breadth-first, labels branching node
random value Gi associated node, sampled according distribution
determined program state corresponding node. algorithm, sampling
random values independent. labeling branching nodes identifies unique
branch tree, branch, probability identified labeling
equal probability branch representing execution original algorithm
(a similar transformation pre-computing random choices might become relevant
described Gill & J.M.Robins, 2001[Section 7]). following proof formalizes
preceding informal description.
Proof Theorem 4.10: random variable G introduce sequence random
variables Gi,1 , . . . , Gi,K(i) , K(i) =| W i1
j=1 j | size joint state space

X, G1 , . . . , Gi1 . state space Gi,h (with regard informal explanation,
Gi,h corresponds node full computation tree represent sampling G
previous execution resulted hth K(i) possible program states).
construct joint distribution X G i,h setting P (Gi,h = v) = P (Gi = v |
i1
j ), taking
(X, G1 , . . . , Gi1 ) = sh ) (sh hth state enumeration W j=1

X Gi,h independent.
straightforward define mapping
K(i)

h : W i1



(X, h (X, G )) distributed (X, G) (the mapping h corresponds extraction active branch full labeled computation tree). Defining f (x, g ) :=
f (x, h (x, g )) completes construction Bernoulli model.


911

fiJaeger

Definition 4.11 Bernoulli model (X, G , f ) obtained via construction proof
Theorem 4.10 called Bernoulli transform (X, G, f ).
Example 4.12 direct car model (X, G, f ) obtain Bernoulli transform (X, (G 1 ,
. . . , Gn ), f ),
P (Gi = U ) = P (G = U | X = xi ),
h (xi , U1 , . . . , Un ) = (xi , Ui ),
f (xi , U1 , . . . , Un ) = Ui .
coarsening procedure Bernoulli model, information X
used sampling variables G. part procedure X influences
outcome final computation = f (X, G). condition computation
much knowledge X required finally revealed basically
condition (9) coarsening variables. state space G (potentially)
uncountable, however appropriate replace universal quantification
g (9) almost g probabilistic sense. thus define:
Definition 4.13 Bernoulli model honest, x, x 0 P (X = x) > 0, P (X =
x0 ) > 0, U 2W \ :
P (G {g | f (x, g) = U, x0 U f (x0 , g) = U }) = 1.

(31)

Example 4.14 Bernoulli model Example 4.12 honest, one
U1 , . . . , Un P (G = (U1 , . . . , Un )) > 0: Uj 6= Ui , xi , xj Ui ,
f (xi , U1 , . . . , Un ) = Ui 6= Uj = f (xj , U1 , . . . , Un ).
Honest Bernoulli models certainly satisfy (D). hand, nonBernoulli models also seem satisfy (D) (notably RMC models,
developed (D) mind). However, non-Bernoulli models appears hard make
precise condition sampling G depend X beyond fact
X 1 . following theorem indicates formalization (D) terms Bernoulli
models narrow.
Theorem 4.15 Bernoulli transforms MGD, CARgen RMC models honest.
proof three types models elementary, though partly tedious. omit
details here.
turn second condition reasonable procedures. observe
MGD/CARgen/RMC models essentially defined terms mechanical procedure generating coarse data, whereas direct car , uniform noise,
P&T models (and similar way CARgen ) rely numerical conditions (26),(27),
respectively (29), distributional parameters. procedures, therefore, fragile
sense slight perturbations parameters destroy d-car property
induced distribution. would like distinguish robust car procedures
1. intuitive condition G must independent X given turns inadequate.

912

fiIgnorability Statistical Probabilistic Inference

d-car property guaranteed mechanics process alone (as determined
state spaces Gi , definition f ), depend parameter
constraints Gi (which, less subtle way, used mimic brute
force condition (26)). Thus, essentially consider car procedure robust,
stays car changes parameter settings G . two points consider state formal definition idea. First, observe concept
robustness based Bernoulli models, since non-Bernoulli models even
arbitrarily small parameter changes create destroy independence relations
variables X, G, independence relations, arguably, reflect qualitative rather
merely quantitative aspects coarsening mechanism.
Secondly, want limit permissible parameter changes lead
drastic quantitative changes outcomes previously nonzero probability become
zero-probability events, vice versa. line perspective Section 3,
set support distribution finite state space viewed basic
qualitative property. current context dealing distributions uncountable
state spaces, need replace notion identical support notion
absolute continuity: recall two distributions P, P state space called mutually
absolutely continuous, written P P , P (S) = 0 P (S) = 0 measurable .
distribution P (G) , G independent family, obtain P (G)
P P , example, changing finitely many parameter values P (G = g) = r > 0
new values P (Gi = g) = r > 0. hand, e.g. = {0, 1}, P (Gi = 0) = 1/2,
P (Gi = 0) = 1/2 + > 0, P () 6 P (). distribution
P (X) X alone one P (X) P (X) iff P P support.
Definition 4.16 Bernoulli model (X, G, f ) robust car ( robust ccar), car (ccar),
remains car (ccar) distributions P (X) P (G ) (i 1) replaced
distributions P (X) P (Gi ), P (X) P (X) P (G) P (G).
Bernoulli transforms MGD/CARgen robust ccar . class RMC
know, far, car . Bernoulli transform RMC seen robust car .
Bernoulli transforms CARgen /P&T, hand, robust (and neither
uniform noise model, already Bernoulli). come main result
section, basically identifies existence reasonable procedural models
d-ccar .
Theorem 4.17 following equivalent distribution P (W ):
(i) P induced robust car Bernoulli model.
(ii) P induced robust ccar Bernoulli model.
(iii) P induced honest Bernoulli model.
(iv) P d-ccar.
proof given Appendix A. Theorem 4.17 essentially identifies existence
natural procedural model d-car distribution property d-ccar , rather
913

fiJaeger

merely d-car . somewhat surprising result first sight, given -mcar
usually considered unrealistically strong assumption compared -mar .
real contradiction here, however, seen d-ccar weaker
-mcar . Theorem 4.17 indicates practice one may find many cases d-ccar
holds, -mcar fulfilled.

5. Conclusion
reviewed several versions car conditions. differ respect
formulation, terms coarsening variable, terms purely distributional constraint. different versions mostly non-equivalent. care, therefore,
required determining particular statistical probabilistic inference problem
appropriate car condition sufficient justify intended form inference,
assumption warranted observational process hand. argue
distributional forms car relevant ones: observations
fully described subsets W , coarse data distribution required
analysis, introduction artificial coarsening variable G skew
analysis.
main goal provide characterizations coarse data distributions satisfy
d-car . considered two types characterizations: first type static
description d-car distributions terms sets support. derived
quite intuitive, complete characterization means support hypergraph coarse
data distribution.
second type characterizations terms procedural models observational process generates coarse data. considered several models
observational processes, found arguably natural ones exactly
generate observations d-ccar , rather d-car . somewhat
surprising first, -ccar typically unrealistically strong assumption (cf.
Example 2.3). distributional form, d-ccar , contrary, turns perhaps
natural assumption. strongest support support d-ccar assumption provided equivalence (i) (iv) Theorem 4.17: assuming d-car , d-ccar , means
must dealing fragile coarsening mechanism produces d-car data
virtue specific parameter settings. Since usually know much
coarsening mechanism, assumption special parameter-equilibrium
(as exemplified (29)) typically unwarranted.

Acknowledgments
author would like thank Ian Pratt providing initial motivation investigating basis probabilistic inference conditioning. Richard Gill, Peter Grunwald,
James Robins provided valuable comments earlier versions paper.
particularly indebted Peter Grunwald suggestions organization material
Section 2.1, led great improvement presentation. Richard Gill must
credited short proof Theorem 3.10, replaced previous much
laborious one.
914

fiIgnorability Statistical Probabilistic Inference

Appendix A. Proof Theorem 4.17
Theorem 4.17 following equivalent distribution P (W ):
(i) P induced robust car Bernoulli model.
(ii) P induced robust ccar Bernoulli model.
(iii) P induced honest Bernoulli model.
(iv) P d-ccar .
begin measure theoretic preliminaries. Let product -algebra
generated powersets 2i . joint distribution P (X, G) defined
product 2W A. -algebra generated cylinder sets (g 1 , g2 , . . . , gk )
j>k j (k 0, gh h h = 1, . . . , k). cylinder sets also basis topology
. space (, O) compact (this seen directly, application
Tikhonovs theorem). follows every probability distribution P regular,
especially A:
P (A) = inf{P (O) | O}
(see e.g. Cohn, 1993, Prop. 7.2.3). following use interchangeably
notation P (A) P (G A). former notation sufficient reasoning
probability distributions A, latter emphasizes fact always dealing
distributions induced family G random variables.
Lemma A.1 Let P (G) joint distribution independent family G. Let
A1 , A2 A1 A2 = P (G A1 ) = P (G A2 ) > 0. exists joint
distribution P (G) P (G) P (G) P (G A1 ) 6= P (G A2 ).
Proof: Let p := P (A1 ). Let = p/2 A1 P (O) < p + . Using
disjointness A1 A2 one obtains P (A1 | O) > P (A2 | O). Since cylinder sets
basis O, = i0 Zi countable family cylinders Z . follows also
cylinder set Z = (g1 , g2 , . . . , gk ) j>k j P (Z) > 0: P (A1 | Z) > P (A2 | Z).
let > 0 define h = 1, . . . , k:
X
P (Gh = gh ) := 1 ; P (Gh = g) := (P (Gh = g)/
P (Gh = g 0 )) (g 6= gh )

g 0 :g 0 6=gh

h k + 1: P (Gh ) := P (Gh ). P (G) P (G), P (A1 | Z) = P (A1 | Z), P (A2 |
Z) = P (A2 | Z), therefore:
P (A1 ) (1 )k P (A1 | Z),

P (A2 ) (1 )k P (A2 | Z) + 1 (1 )k .

sufficiently small gives P (A1 ) > P (A2 ).



Proof Theorem 4.17: simplification may assume P (x) > 0 x W .
justified observation none conditions (i)-(iv) affected adding
deleting states zero probability W .
915

fiJaeger

implication (iv)(ii) follows Example 4.4 observation MGD models
robust d-ccar Bernoulli models. (ii)(i) trivial. show (i)(iii) (iii)(iv).
First assume (i), let (X, G, f ) robust car Bernoulli model inducing P .
x W U W denote
A(x, U ) := {g | f (x, g) = U }.
d-car property P equivalent
P (G A(x, U )) = P (G A(x0 , U )).

(32)

x, x0 U .
Condition (31) equivalent condition P (G A(x, U ) \ A(x 0 , U )) = 0
x, x0 U . Assume otherwise. A1 := A(x, U ) \ A(x0 , U ), A2 := A(x0 , U ) \ A(x, U ):
0 < P (G A1 ) = P (G A2 ). Applying Lemma A.1 obtain Bernoulli model
P (X, G) = P (X)P (G) P (X, G) P (X, G) P (G A1 ) 6= P (G A2 ). also
P (G A(x, U )) 6= P (G A(x0 , U )), P (X, G) d-car, contradicting (i).
(iii)(iv): Let
\
:=
{g | f (x, g) = U, x0 U f (x0 , g) = U }.
x,x0 W,U W :
x,x0 U

Since intersection finitely many x, x 0 , U , obtain (iii) P (G
) = 1. U W define A(U ) := A(x, U ) , x U arbitrary.
definition definition A(U ) independent particular choice x. Define
equivalence relation via
g g0



U W : g A(U ) g 0 A(U ).

(33)

equivalence relation partitions finitely many equivalence classes 1 , . . . , k .
show g system
Wi := {U | x W : f (x, g) = U }

(34)

partition W , definition W depend choice g.
latter claim immediate fact g
f (x, g) = U



g A(U ) x U.

(35)

first claim assume f (x, g) = U, f (x 0 , g) = U 0 U 6= U 0 . particular,
g A(U ) A(U 0 ). Assume exists x00 U U 0 . (35) would obtain
f (x00 , g) = U f (x00 , g) = U 0 , contradiction. Hence, sets U W
pairwise disjoint. also cover W , every x W exists U
x U = f (x, g).
thus obtain given Bernoulli model equivalent multiple grouped

data model defined partitions W parameters := P (G ).

916

fiIgnorability Statistical Probabilistic Inference

References
Bhaskara Rao, K. P. S., & Bhaskara Rao, M. (1983). Theory Charges: Study Finitely
Additive Measures. Academic Press.
Cator, E. (2004). testability CAR assumption. Annals Statistics,
32 (5), 19571980.
Cohn, D. (1993). Measure Theory. Birkhauser.
Dawid, A. P., & Dickey, J. M. (1977). Likelihood bayesian inference selectively
reported data. Journal American Statistical Association, 72 (360), 845850.
Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood incomplete
data via EM algorithm. Journal Royal Statistical Society, Ser. B, 39, 138.
Gill, R., & J.M.Robins (2001). Causal inference complex longitudinal data: continuous case. Annals Statistics, 29 (6), 17851811.
Gill, R. D., van der Laan, M. J., & Robins, J. M. (1997). Coarsening random: Characterizations, conjectures, counter-examples. Lin, D. Y., & Fleming, T. R. (Eds.),
Proceedings First Seattle Symposium Biostatistics: Survival Analysis, Lecture
Notes Statistics, pp. 255294. Springer-Verlag.
Grunwald, P. D., & Halpern, J. Y. (2003). Updating probabilities. Journal Artificial
Intelligence Research, 19, 243278.
Heitjan, D. F. (1994). Ignorability general incomplete-data models. Biometrika, 81 (4),
701708.
Heitjan, D. F. (1997). Ignorability, sufficiency ancillarity. Journal Royal Statistical
Society, B, 59 (2), 375381.
Heitjan, D. F., & Rubin, D. B. (1991). Ignorability coarse data. Annals Statistics,
19 (4), 22442253.
Jacobsen, M., & Keiding, N. (1995). Coarsening random general sample spaces
random censoring continuous time. Annals Statistics, 23 (3), 774786.
Jaeger, M. (2005). Ignorability categorical data. Annals Statistics, 33 (4), 1964
1981.
Nielsen, S. F. (1997). Inference missing data: Asymptotic results. Scandinavian Journal
Statistics, 24, 261274.
Nielsen, S. F. (2000). Relative coarsening random. Statistica Neerlandica, 54 (1), 7999.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems : Networks Plausible
Inference (rev. 2nd pr. edition). Morgan Kaufmann series representation
reasoning. Morgan Kaufmann, San Mateo, CA.
Rubin, D. (1976). Inference missing data. Biometrika, 63 (3), 581592.
Schrijver, A. (1986). Theory Linear Integer Programming. John Wiley & Sons.
Shafer, G. (1985). Conditional probability. International Statistical Review, 53 (3), 261277.

917

fiJournal Artificial Intelligence Research 24 (2005) 851-887

Submitted 08/05; published 12/05

First Probabilistic Track
International Planning Competition
Hakan L. S. Younes

lorens@cs.cmu.edu

Computer Science Department
Carnegie Mellon University
Pittsburgh, PA 15213 USA

Michael L. Littman
David Weissman
John Asmuth

mlittman@cs.rutgers.edu
dweisman@cs.rutgers.edu
jasmuth@cs.rutgers.edu

Department Computer Science
Rutgers University
Piscataway, NJ 08854 USA

Abstract
2004 International Planning Competition, IPC-4, included probabilistic planning
track first time. describe new domain specification language created
track, evaluation methodology, competition domains developed,
results participating teams.

1. Background
Fourth International Planning Competition (IPC-4) held part International Conference Planning Scheduling (ICAPS04) Vancouver, British Columbia
June 2004. request ICAPS04 organizers, Sven Koenig Shlomo Zilberstein,
asked create first probabilistic planning track part IPC-4.
overriding goal first probabilistic planning track bring together two
communities converging similar set research issues aid creating comparable tools evaluation metrics. One community consists Markov decision process
(MDP) researchers interested developing algorithms apply powerfully expressive
representations environments. consists planning researchers incorporating
probabilistic decision theoretic concepts planning algorithms. Cross fertilization begun, intent probabilistic planning track create set
shared benchmarks metrics could crystallize efforts area study.
created new domain description language called PPDDL1.0, described Section 2. PPDDL stands Probabilistic Planning Domain Definition Language, analogy PDDL (McDermott, 2000), introduced IPC-1. PPDDL modeled
PDDL2.1 (Fox & Long, 2003), domain-description language deterministic domains
used IPC-3. Syntactically, language STRIPS/ADL-like flavor, includes
probabilistic constructs. focus energy participants issues dealing uncertainty, chose include constructs durative actions PPDDL1.0.
basing domain-description language PDDL, sought remain spirit
existing planning competition, hope bring communities
c
2005
AI Access Foundation. rights reserved.

fiYounes, Littman, Weissman & Asmuth

together. PPDDL representation relational. Although representations
explicit objects traditional feature MDP-based domain-description languages,
algorithms exploit features begun appear. expected participants
propositionalize domains running planning algorithms and,
part, so.
fully functional parser PPDDL provided participants C++ form
plan validator simple planner. basic tools convert PPDDL decisiondiagram representation also provided. many ways, handling rich constructs
PPDDL main hurdle many participants tried provide much
assistance could dimension.
Although PPDDL supports numerical fluents, feature used fullest
extent competition. Numerical quantities used representing reward
values, reward effects required additive.
Since classical track well established point, helpful contrast
probabilistic track differs. defining difference, course, actions
uncertain effects. is, pickup action Blocksworld might behave differently
different occasions, even state. single difference number
significant consequences. First, optimal action choices reaching goal may
function probabilistic outcomes along waya single sequence actions may
sufficient. result, difficult output plan. reason,
decided separate plan synthesis execution two phases, instead evaluated
planners online. Second, unpredictability effects, even optimal plan
reaching goal may get unlucky fail probability. reason,
evaluated planner multiple times problem include separate
optimal planner track. addition, since planners may fail reach goal state
executions, needed way trading goal attainment action
cost. decided score execution goal reward minus action cost chose goal
reward problem. Section 3 describes evaluation methodology detail.
total, designed eight domains competition (Section 4). domains
simply noisy versions classical planning domains, domains designed
specifically thwart greedy replanning approaches ignore uncertainty.
Ten planners seven different groups entered competition. results
competition presented Section 5. deterministic replanner performed best overall,
primarily due disproportionate number noisy classical planning problems
evaluation suite. domains proved challenging participating planners.
latter domains could serve basis future probabilistic planning competitions.

2. Probabilistic PDDL
section describes input language, PPDDL1.0, used probabilistic
track. PPDDL1.0 essentially syntactic extension Levels 1 2 PDDL2.1 (Fox
& Long, 2003). complete syntax PPDDL1.0 given Appendix A. assume
reader familiar PDDL2.1, focus new language features,
include probabilistic effects rewards. detailed account PPDDL1.0 provided
852

fiThe First Probabilistic Track IPC

Name
bomb-in-package package1
bomb-in-package package2
toilet-clogged
bomb-defused

Type
boolean
boolean
boolean
boolean

Init 1
true
false
false
false

Init 2
false
true
false
false

Table 1: State variables initial values Bomb Toilet problem.
Younes Littman (2004). semantics PPDDL1.0 planning problem given
terms discrete-time Markov decision process (Howard, 1960, 1971; Puterman, 1994).
2.1 Probabilistic Effects
define probabilistic decision theoretic planning problems, need add support
probabilistic effects. syntax probabilistic effects
(probabilistic p1 e1 . . . pk ek )
meaning
Pk effect ei occurs probability pi . require constraints pi 0
i=1 pi = 1 fulfilled: probabilistic effect declares exhaustive set probabilityweighted outcomes. do, however, allow probability-effect pair left
effect empty. words,
(probabilistic p1 e1 . . . pl el )


Pl

i=1 pi

< 1 syntactic sugar
(probabilistic p1 e1 . . . pl el q (and))
Pl

q = 1 i=1 pi (and) representing empty effect (that is, state changes).
example, effect (probabilistic 0.9 (clogged)) means probability 0.9
state variable clogged becomes true next state, probability 0.1
state remains unchanged.
Figure 1 shows encoding PPDDL Bomb Toilet example described
Kushmerick, Hanks, Weld (1995). requirements flag :probabilistic-effects
signals probabilistic effects used domain definition. problem,
two packages, one contains bomb. bomb defused dunking
package containing bomb toilet. 0.05 probability toilet becoming
clogged package placed it, thus rendering goal state unreachable.
problem definition Figure 1 also shows initial conditions PPDDL
probabilistic. particular example, define two possible initial states equal
probability (0.5) true initial state given execution. Table 1 lists
state variables Bomb Toilet problem values two possible initial
states. Intuitively, think initial conditions PPDDL planning problem
effects action forced scheduled right time 0. Also, note
goal problem involves negation, problem definition declares
:negative-preconditions requirements flag.
853

fiYounes, Littman, Weissman & Asmuth

(define (domain bomb-and-toilet)
(:requirements :conditional-effects :probabilistic-effects)
(:predicates (bomb-in-package ?pkg) (toilet-clogged)
(bomb-defused))
(:action dunk-package
:parameters (?pkg)
:effect (and (when (bomb-in-package ?pkg)
(bomb-defused))
(probabilistic 0.05 (toilet-clogged)))))
(define (problem bomb-and-toilet)
(:domain bomb-and-toilet)
(:requirements :negative-preconditions)
(:objects package1 package2)
(:init (probabilistic 0.5 (bomb-in-package package1)
0.5 (bomb-in-package package2)))
(:goal (and (bomb-defused) (not (toilet-clogged)))))
Figure 1: PPDDL encoding Bomb Toilet example.

PPDDL allows arbitrary nesting conditional probabilistic effects (see example
Figure 2). feature contrast popular encodings, probabilistic STRIPS
operators (PSOs; Kushmerick et al., 1995) factored PSOs (Dearden & Boutilier, 1997),
allow conditional effects nested inside probabilistic effects. arbitrary
nesting add expressiveness language, allow exponentially
compact representations certain effects given set state variables
actions (Rintanen, 2003). PPDDL action can, however, translated set PSOs
polynomial increase size representation. Consequently, follows
results Littman (1997) PPDDL, grounding (that is, full instantiation
action schemata), representationally equivalent dynamic Bayesian networks (Dean
& Kanazawa, 1989), another popular representation MDP planning problems.
Still, worth noting single PPDDL action schema represent large number
actions single predicate represent large number state variables, meaning
PPDDL often represent planning problems succinctly representations. example, number actions represented using objects n
action schemata arity c nc , bounded polynomial size
original representation (m + n). Grounding means prerequisite PPDDL
planning, planners could conceivably take advantage compact representation
working directly action schemata.
2.2 Rewards
Markovian rewards, associated state transitions, encoded using fluents (numeric
state variables). PPDDL reserves fluent reward , accessed (reward) reward,
represent total accumulated reward since start execution. Rewards associated
854

fiThe First Probabilistic Track IPC

(define (domain coffee-delivery)
(:requirements :negative-preconditions
:disjunctive-preconditions
:conditional-effects :mdp)
(:predicates (in-office) (raining) (has-umbrella) (is-wet)
(has-coffee) (user-has-coffee))
(:action deliver-coffee
:effect (and (when (and (in-office) (has-coffee))
(probabilistic
0.8 (and (user-has-coffee)
(not (has-coffee))
(increase (reward) 0.8))
0.2 (and (probabilistic 0.5 (not (has-coffee)))
(when (user-has-coffee)
(increase (reward) 0.8)))))
(when (and (not (in-office)) (has-coffee))
(and (probabilistic 0.8 (not (has-coffee)))
(when (user-has-coffee)
(increase (reward) 0.8))))
(when (and (not (has-coffee)) (user-has-coffee))
(increase (reward) 0.8))
(when (not (is-wet))
(increase (reward) 0.2))))
... )

Figure 2: Part PPDDL encoding Coffee Delivery domain.

state transitions update rules action effects. use reward fluent
restricted action effects form (hadditive-opi hreward fluenti hf-expi),
hadditive-opi either increase decrease, hf-expi numeric expression involving reward . Action preconditions effect conditions allowed refer
reward fluent, means accumulated reward considered
part state space. initial value reward zero. restrictions use
reward fluent allow planner handle domains rewards without
implement full support fluents.
new requirements flag, :rewards, introduced signal support rewards
required. Domains require probabilistic effects rewards declare :mdp
requirements flag, implies :probabilistic-effects :rewards.
Figure 2 shows part PPDDL encoding coffee delivery domain described
Dearden Boutilier (1997). reward 0.8 awarded user coffee
deliver-coffee action executed, reward 0.2 awarded is-wet false
execution deliver-coffee. Note total reward 1.0 awarded
result executing deliver-coffee action execution action leads state
user -has-coffee is-wet hold.
855

fiYounes, Littman, Weissman & Asmuth

2.3 Plan Objectives
Regular PDDL goals used express goal-type performance objectives. goal statement
(:goal ) probabilistic planning problem encodes objective probability
achieving maximized, unless explicit optimization metric specified
planning problem. planning problems instantiated domain declaring
:rewards requirement, default plan objective maximize expected reward.
goal statement specification reward oriented planning problem identifies set
absorbing states. addition transition rewards specified action effects, possible
associate one-time reward entering goal state. done using (:goal-reward
f ) construct, f numeric expression.
general, statement (:metric maximize f ) problem definition means
expected value f maximized. Reward-oriented problems, example problem instance coffee-delivery domain Figure 2, would declare (:metric maximize
(reward)) optimization criterion (this declaration default :rewards
requirement specified). PPDDL defines goal-achieved special optimization
metric, used explicitly specify plan objective maximize (or
minimize) probability goal achievement. value goal-achieved fluent 1
execution ends goal state. expected value goal-achieved therefore equal
probability goal achievement. declaration (:metric maximize (goal-achieved))
takes precedence reward specifications domain problem definition,
default :rewards requirement specified (for example, Bomb
Toilet problem Figure 1).
2.4 PPDDL Semantics
completeness, present formal semantics PPDDL planning problems terms
mapping probabilistic transition system rewards. planning problem defines
set state variables V , possibly containing Boolean numeric state variables,
although consider planning problems without numeric state variables
section. assignment values state variables defines state, state space
planning problem set states representing possible assignments values
variables. addition
V , planning problem defines initial-state distribution
P
p0 : [0, 1] sS p0 (s) = 1 (that is, p0 probability distribution states),
formula G V characterizing set goal states G = {s | |= G }, one-time reward
rG associated entering goal state, set actions instantiated PPDDL
action schemata. goal-directed planning problems, without explicit rewards, use
rG = 1.
2.4.1 Probability Reward Structure
action consists precondition effect ea . Action applicable
state |= G . error apply state
6|= G . Goal states absorbing, action may applied state satisfying
G . requirement must hold order applicable consistent
semantics PDDL2.1 (Fox & Long, 2003) permits modeling forced chains
actions. Effects recursively defined follows (see also, Rintanen, 2003):
856

fiThe First Probabilistic Track IPC

1. > null-effect, represented PPDDL (and).
2. b b effects b V Boolean state variable.
3. r v, v R, effect.
4. c e effect c formula V e effect.
5. e1 en effect e1 , . . . , en effects.
6. p
1 e1 | . . . |pn en effect e1 , . . . , en effects, pi 0 {1, . . . , n},
P
n
i=1 pi = 1.
effect b sets Boolean state variable b true next state, b sets b false
next state. Effects form r v used associate rewards transitions
described below.
action = ha , ea defines transition probability matrix Pa state reward
vector Ra , Pa (i, j) probability transitioning state j applying
state i, Ra (i) expected reward executing action state i.
readily compute entries reward vector action effect formula ea . Let c
characteristic function Boolean formula c, is, c (s) 1 |= c 0
otherwise. expected reward effect e applied state s, denoted R(e; s),
computed using following inductive definition:
.
R(>; s) = 0
.
R(b; s) = 0
.
R(b; s) = 0
.
R(r v; s) = v
.
R(c e; s) = c (s) R(e; s)
n
. X
R(e1 en ; s) =
R(ei ; s)
i=1
n
. X
R(p1 e1 | . . . |pn en ; s) =
pi R(ei ; s).
i=1

factored representation probability matrix Pa obtained generating
dynamic Bayesian network (DBN) representation action effect formula ea .
use Bayesian inference DBN obtain monolithic representation Pa ,
structure factored representation exploited algorithms decision
theoretic planning (see, example, work Boutilier, Dearden, & Goldszmidt, 1995;
Hoey, St-Aubin, Hu, & Boutilier, 1999; Boutilier, Dean, & Hanks, 1999; Guestrin, Koller,
Parr, & Venkataraman, 2003).
Bayesian network directed graph. node graph represents state
variable, directed edge one node another represents causal dependence.
node associated conditional probability table (CPT). CPT state variable
Xs node represents probability distribution possible values X conditioned
values state variables whose nodes parents Xs node. Bayesian network
857

fiYounes, Littman, Weissman & Asmuth

factored representation joint probability distribution variables represented
network.
DBN Bayesian network specific structure aimed capturing temporal
dependence. state variable X, create duplicate state variable X 0 , X
representing situation present time X 0 representing situation one time
step future. directed edge present-time state variable X future-time
state variable 0 encodes temporal dependence. edges two presenttime state variables, future-time present-time state variable (the present
depend future). can, however, edge two future-time state
variables. edges, called synchronic edges, used represent correlated effects.
DBN factored representation joint probability distribution present-time
future-time state variables, also transition probability matrix discrete-time
Markov process.
show generate DBN representing transition probability matrix
PPDDL action. avoid representational blowup, introduce multi-valued auxiliary
variable probabilistic effect action effect. auxiliary variables introduced indicate possible outcomes probabilistic effect occurs, allowing
representation correlate effects specific outcome. auxiliary variable
associated probabilistic effect n outcomes take n different values.
PPDDL effect e size |e| consist O(|e|) distinct probabilistic effects. Hence,
number auxiliary variables required encode transition probability matrix
action effect e O(|e|). future-time versions auxiliary
variables necessary. PPDDL problem Boolean state variables, need
order 2m + maxaA |ea | nodes DBNs representing transition probability
matrices actions.
provide compositional approach generating DBN represents transition probability matrix PPDDL action precondition effect ea . assume
effect consistent, is, b b occur outcome
overlapping conditions. DBN empty effect > simply consists 2m nodes,
present-time node X connected future-time counterpart X 0 . CPT X 0
non-zero entries Pr[X 0 = > | X = >] = 1 Pr[X 0 = | X = ] = 1.
holds reward effect r v, change value state variables.
Next, consider simple effects b b. Let Xb state variable associated
PPDDL atom b. effects, eliminate edge Xb Xb0 . CPT
Xb0 entry Pr[Xb0 = >] = 1 effect b Pr[Xb0 = ] = 1 effect b.
conditional effects, c e, take DBN e add edges presenttime state variables mentioned formula c future-time state variables
DBN e.1 Entries CPT state variable X 0 correspond settings
present-time state variables satisfy c remain unchanged. entries set
1 X true 0 otherwise (the value X change effect condition
satisfied).
DBN effect conjunction e1 en constructed DBNs
n effect conjuncts. value Pr[X 0 = > | X] DBN conjunction set
1. transformation increase size DBNs exponentially unless context-specific DBNs
used (Boutilier, Friedman, Goldszmidt, & Koller, 1996).

858

fiThe First Probabilistic Track IPC

R

R

R:
HU:
IW :
UHC:
HC:
IO:

raining
has-umbrella
is-wet
user-has-coffee
has-coffee
in-office

HU

HU

IW

IW

UHC

UHC

Aux1

HC

HC

Aux2

IO

IO

Aux3

Aux 01
1
1
1
1
1
1
1
1
2
2
2
2
2
2
2
2

IO
>
>
>
>




>
>
>
>





HC
>
>


>
>


>
>


>
>



UHC
>

>

>

>

>

>

>

>


UHC 0
>
1
0
1
0
1
0
0
1
1
0
0
1
1
0
0
1
1
0
0
1
1
0
0
1
1
0
0
1
1
0
0
1

Figure 3: DBN structure (left) deliver-coffee action Coffee Delivery domain, CPT UHC 0 (the future-time version state variable
user -has-coffee) shown right.

maximum Pr[X 0 = > | X] DBNs conjuncts. maximum used
state variable set true (false) conjunctive effect set true
(false) one effect conjuncts (effects assumed consistent, result
taking maximum separate probability tables still probability table).
Finally, construct DBN probabilistic effect p1 e1 | . . . |pn en , introduce
auxiliary variable 0 used indicate one n outcomes occurred.
node 0 parents, entries CPT Pr[Y 0 = i] = pi .
Given DBN ei , add synchronic edge 0 state variables X.
value Pr[X 0 = > | X, 0 = j] set Pr[X 0 = > | X] j = 0 otherwise.
transformation repeated n outcomes, results n DBNs. DBNs
trivially combined single DBN probabilistic effect
mutually exclusive preconditions (the value Y).
example, Figure 3 shows DBN encoding transition probability matrix
deliver-coffee action, whose PPDDL encoding given Figure 2.
three auxiliary variables action effect contains three probabilistic effects.
node labeled UHC 0 (the future-time version state variable user -has-coffee) four
parents, including one auxiliary variable. Consequently, CPT node
24 = 16 rows (shown right Figure 3).
2.4.2 Optimality Criteria
shown construct MDP PPDDL encoding planning problem.
plan objective maximize expected reward MDP. objective
interpreted different ways, example expected discounted reward expected total
859

fiYounes, Littman, Weissman & Asmuth

reward. suitable interpretation depends problem. process-oriented planning problems (for example, Coffee Delivery problem), discounted reward typically
desirable, total reward often interpretation chosen goal-oriented problems
(for example, Bomb Toilet problem). PPDDL include facility
enforcing given interpretation specifying discount factor.
competition, used expected total reward optimality criterion. Without
discounting, care required design planning problems ensure
expected total reward bounded optimal policy. following restrictions
made problems used planning competition:
1. problem goal statement, identifying set absorbing goal states.
2. positive reward associated transitioning goal state.
3. negative reward (cost) associated action.
4. done action available states, could used end accumulation reward.
conditions ensure MDP model planning problem positive bounded
model (Puterman, 1994). positive reward transitioning goal state.
Since goal states absorbing (that is, outgoing transitions), maximum
value state bounded goal reward. Furthermore, done action ensures
action available state guarantees non-negative future reward.

3. Evaluation Methodology
classical planning, plan series operators. successful plan one that,
applied initial state, achieves goal. probabilistic planning, many
proposals plan representations (straight-line plans, plan trees, policy graphs, triangle
tables, example), none considered widely accepted standard. addition, even
simple plans challenging evaluate exactly non-deterministic environment,
possible outcomes need checked results combined (Littman, Goldsmith, &
Mundhenk, 1998).
reasons, chose evaluate planners simulation. is, plan validator server, individual planning algorithms acted clients. Planners connected
validator, received initial state, returned operator/action. dialog
continued terminating condition reached point validator evaluated
performance planner trajectory initial state terminating condition. entire process repeated several times results averaged multiple
runs.
evaluation scheme blurs distinction planner executor,
means computation longer one-time preprocessing cost, something integrated action selection itself. Planner quality, therefore, needs combination
expected utility running time. simplicity, set time threshold allowed
reward gathered time ran out. time threshold known competitors,
whose planners could take consideration deciding balance computation
860

fiThe First Probabilistic Track IPC

action. Since know whether participants would reuse results one trajectory speed planning next, set overall time limit applied total
repetitions evaluator given domain.
Concretely, evaluations, participants presented twenty previously unseen problems PPDDL format. evaluate problem, participants connected one
evaluation servers (at CMU Rutgers). server provided planner
initial state planner selected returned action. dialogue iterated
goal reached, time ran out, planner sent done action. value
obtained problem goal reward, goal reached, minus sum
action costs (if any). problem, procedure repeated 30 times maximum
15 minutes results averaged.
two types problems evaluation set: reward problems goal
problems. goal problems, success percentage determined participants score
problem (no action costs). reward problems, every action fixed cost. times
completion recorded, explicitly used ranking. Planners completed
less 30 runs 15 minutes given score 0 unfinished runs.
design server, believed time needed computation
planner would far outweigh possible communication delay. However, preliminary
evaluations, participantsespecially halfway across worldexperienced disruptive levels latency evaluating planners connecting remotely server.
formal evaluation, offered participants local accounts CMU nearly
availed option.
3.1 Communication Client Server
communication participants client program server took place
XML. made decision two reasons: first parsing messages
easily managed format trivial parties involvedmany solid XML parsers exist
public domain. second bandwidth great concernas mentioned
previous section, participants ran clients machine hosted
server. true excessively large messages take valuable processing
time, specific case large messages corresponded large state spaces,
took somewhat longer process altogether, XML parsing limiting
factor.
client connected server, would request certain problem run.
server would lead client running problem 30 times, sending state
problem, receiving clients action, creating new state old
state action, sending back again. Figure 4 gives schematic illustration
conversation client server. specific format XML element
described Appendix B.
Prior competition, example client written C++ distributed
participants minimize difficulties dealing nuts bolts protocol,
allowing instead focus design algorithms.
861

fiYounes, Littman, Weissman & Asmuth

client: hsession-requesti
server: hsession-initi
loop 30 rounds
client: hround-requesti
server: hround-initi
loop termination conditions
server: hstatei
client: hacti | hnoopi | hdonei
server: hend-round
server: hend-sessioni

Figure 4: interaction client (planners) server (environment) evaluation system.

3.2 Generator-Based Domains
Several example domains provided participants advance serve testbeds
parser planner development. addition, parameterized problem generators
provided two domain classesBlocksworld Boxworld, described detail
Section 4. availability domains served allow participants learn, either manually automatically, domains create domain-specific solutions.
approaches evaluated independently separate category.

4. Competition Domains
section describes domains used competition. Machine readable versions
domains found online competition Web site:
http://www.cs.rutgers.edu/mlittman/topics/ipc04-pt/
4.1 Blocksworld (Traditional)
traditional Blocksworld domain stray far original Blocksworld domain. domain consists two types objects, blocks tables. domain
exactly one table problem instance number blocks (the number
blocks problem specific). actions domain pick-up-block-from putdown-block-on. problem instance, initial configuration goal configuration
blocks given. goal problem move blocks initial configuration goal configuration. domain comes two flavors: goal version
reward version. Within reward version, cost one unit every time action
pick-up-block-from executed, reward 500 reaching goal configuration.
domains used competition, Blocksworld domain
incorporates probabilistic effects adding slip probability. is,
time block picked put down, block slip fall onto table
862

fiThe First Probabilistic Track IPC

probability 0.25. (Of course, intended action put block onto table,
effect always achieved.) Blocksworld domain extremely simple
domain, yet offers lot insight planning process. Two important features
domain are:
1. basic policy solve domain is:
(a) initial configuration, place blocks onto table block
top another block.
(b) Starting bottom up, place block place final configuration.
Note without noise, n blocks, policy takes 4n steps (2 steps
block Part 1a, 2 steps block Part 1b) hence costs 2n
units. So, basic, inexpensive way solve domain.
2. state space domain increases exponentially number blocks.
Thus, domain aims testing planners could find easy (maybe slightly
expensive) policy state space large find good policy. far
complexity domain concerned, one easier domains plan
hope many planners would quite well domain.
generation program random traditional Blocksworld domains provided
participants competition problems generated program.
availability generator allowed participants test planners many problems
liked advance evaluation.
4.2 Blocksworld (Color)
colored Blocksworld domain variant traditional Blocksworld presented above.
traditional Blocksworld, colored Blocksworld consists two types objects,
tables blocks. Again, domain exactly one table problem instance
number blocks. actions domain still pick-up-block-from
put-down-block-on, domain also comes two flavors: goal reward.
major difference traditional Blocksworld domain block colored
Blocksworld domain assigned color, goal configuration specified terms
block colors rather specific blocks. Thus, general, many different valid goal
configurations. Goal conditions expressed existential quantification. example,
PPDDL fragment
(:goal (and (exists (?b1) (is-green ?b1))
(exists (?b2) (and (is-blue ?b2) (on-top-of ?b1 ?b2)))))
states goal green block top blue block.
noise colored Blocksworld domain traditional Blocksworld domain. is, colored Blocksworld domain incorporates probabilistic effects
adding slip probability. time block picked put down, block
slip fall onto table probability 0.25.
863

fiYounes, Littman, Weissman & Asmuth

Notice although goal configuration existentially quantified hence precisely specified, basic policy used solve traditional Blocksworld
used solve colored Blocksworld. solve colored Blocksworld problem,
unstack blocks then, bottom fashion, choose block satisfies
color constraint place appropriate position.
colored Blocksworld domain aims add complexity traditional Blocksworld domain incorporating existential quantification goal configuration.
indeterminacy goal colored Blocksworld domain make planning problem
considerably harder traditional counterpart. Thus, colored Blocksworld problem
may impossible given planner solve reasonable amount time, whereas
planner would problem traditional Blocksworld problem
size.2
generation program random colored Blocksworld domains provided participants competition problems generated program.
4.3 Boxworld
Boxworld domain modeled traditional logistics domain. domain consists
four types objects: cities, boxes, trucks planes. problem, graph
superimposed cities two different types edges, one denoting ability
drive one city another denoting ability fly one city
other. actions domain load-box-on-truck-in-city, unload-boxfrom-truck-in-city, load-box-on-plane-in-city, unload-box-from-plane-in-city, drivetruck fly-plane. goal reward versions domain included
evaluation. Within reward version, cost 1 unit every time either
load-box-on-truck-in-city load-box-on-plane-in-city executed, cost 5 units
every time drive-truck executed cost 25 units every time fly-plane
executed. problem instance, initial configuration determines graph
superimposed cities, identifies locations boxes, trucks planes
determines final destination box arrive. goal configuration
specifies destination every box. goal problem move initial
configuration state box destined location.
Noise enters domain action drive-truck. action executed,
desired effect achieved probability 0.8 (that is, probability 0.8 truck
end expected destination). However, probability 0.2, truck get lost
end wrong destination. city, three cities truck
may get lost trying execute drive-truck action. truck actually gets
lost end cities equal probability (that is, probability
1/3).
Blocksworld domains, generation program random Boxworld domains
provided participants competition problems generated
program.
2. important note existentially quantified goal formula colored Blocksworld,
grounded, excessively long. fact serious bottleneck larger instances domain.
Planners avoid grounding benefit here, competition
plan validator grounded goal formula.

864

fiThe First Probabilistic Track IPC

4.4 Exploding Blocksworld
exploding Blocksworld domain dead-end version traditional Blocksworld
domain described earlier. traditional Blocksworld domain, two types
objects (tables blocks) two actions (pick-up-block-from put-down-blockon). initial configuration goal configuration blocks given goal
domain move blocks initial configuration goal configuration.
key difference domain traditional Blocksworld domain
every block exploding Blocksworld domain initially set detonate. Every time
put-down-block action executed, block put yet
detonated detonate probability 0.3; noise domain.
block detonates executing put-down-block action, object beneath block
(whether table another block) destroyed longer accessible within
domain. block detonates, safe longer detonate.
exploding Blocksworld domain aims testing planners ability think ahead.
formally, actions executed possible reach state goal
cannot reached. Consider, example, executing standard Blocksworld approach
blocks unstacked table goal configuration constructed.
seven blocks unstacked, 92% (1 (1 0.3)7 ) probability
table destroyed, rendering problem unsolvable.
One strategy solving exploding Blocksworld problem never place unsafe
block top something valuable (the table block needed final stack). Instead,
block first disarmed, placing top block needed
final configuration, block exists.
illustrate strategy problem instance used planning competition, shown Figure 5. Four blocks needed goal configuration: 4, 8, 9,
10. start repeatedly picking Block 0 placing Block 9 Block 0
detonates. Next, detonate Block 1 way using Block 10. Block 0
Block 1 safe, place Block 1 table Block 0 top Block 1. completes left-most tower. stage, safe moves Blocks 4 8
clear. pick Block 6 put Block 2. last action leads failure
probability 0.3. successful, right-most tower completed. Block 8 clear
use detonate Block 3. Block 3 safely placed top Block 5. Finally,
center tower completed placing Block 7 top Block 3, result failure
probability 0.3. total, success probability given plan (1 0.3)2 = 0.49,
which, fact, optimal given problem (there action costs).
Along several test domains, exploding Blocksworld specifically designed
replanning strategy performs suboptimally (gets stuck high probability).
replanning strategy would ignore 0.3 probability detonation try replan
something unexpected happens. However, high probability approach
render goal state unreachable.
4.5 Fileworld
Fileworld fairly basic domain. consists k files n folders files
filed into. actions domain get-type (reports folder given file
865

fiYounes, Littman, Weissman & Asmuth

initial state
0
1
3
7

2
4

5

6
8

9

goal

10

0
1

7
3
5

6
2

Figure 5: Exploding Blocksworld problem used planning competition. Note
goal condition require Block 2 table.

belongs in), get-folder-Fi (one {0, . . . , n 1}, retrieves Folder filing
cabinet), file-Fi (one {0, . . . , n 1}, inserts given file Folder i)
return-Fi (one 0, . . . , n 1}, returns Folder filing cabinet).
domain comes reward version. cost 100 executing action
get-folder-Fi cost 1 executing action file-Fi. actions
explicit costs since must used conjunction get-folder-Fi file-Fi.
initial configuration problem specifies many folders (the competition
problem used 30 files 5 folders) goal configuration specifies files
must filed. Note initial configuration specify folder file go
into, files cannot filed folder; constraint noise comes
domain.
file filed, destination folder must determined. destination
folder file obtained executing action get-type file question
parameter. action executed, file passed parameter assigned folder,
folder files destination equal probability (that is, probability 1/n).
file destination folder, filed (and this) folder.
Fileworld domain tests planners ability consider strategies choose
one minimizes cost. particular, straightforward plan achieve goal
carry following series actions file turn:
1. Get type get-type
2. Get destination folder executing get-folder-Fi
3. Place file appropriate folder executing file-Fi action
4. Return folder executing return-Fi action
Although plan works, costly. cost would 101k k number
files, get-folder-Fi (expensive) file-Fi (cheap) executed every file.
less costly (in fact, optimal) plan described. first executes get-type every
file. Then, folder {0, . . . , n 1} least one file destination,
runs get-folder-Fi. Next, files every file belongs folder using file-Fi.
uses return-Fi preparation getting next folder.
866

fiThe First Probabilistic Track IPC

expected reward optimal plan 600 (100n + k), n number
folders k number files (this analysis gives 70 optimal expected reward
competition problem). domain designed reward planners able
reason initial destination uncertainty files recognize second
plan much less costly preferred straightforward brute-force plan.
4.6 Tireworld
Tireworld another domain tests planners ability plan ahead uncertainty.
domain consists one type object, namely locations. domain comes two
flavors, goal version reward version. actions common versions
move-car, load-tire change-tire. reward version, additional
action call-AAA.
Within reward version, cost 1 every time one actions move-car,
load-tire change-tire executed cost 100 every time action callAAA executed. initial configuration problem defines set locations,
superimposed graph locations (roads), subset locations representing
locations spare tires, starting location graph. goal configuration
defines destination location graph. goal problem move
starting location goal location.
noise Tireworld comes action move-car. time action
executed, car drives one city another get flat tire probability
0.15. car flat tire, cannot execute action move-car
tire fixed. car ability store one spare tire, pick
executing action load-tire location spare tire. car
holding spare tire, change-tire action invoked fix flat. However,
car currently spare action disabled. goal version,
flat tire may result dead end car gets flat carries spare tire.
reward version, planner choice executing one actions change-tire (if
car spare) call-AAA (at high cost) repair flat. Thus, reward
version, dead ends goal always reachable. Notice since cost
call-AAA large compared costs change-tire load-tire, fixing flat
always less expensive car spare tire.
Figure 6 illustrates Tireworld problem used competition. next compare
probability reaching goal state two different plans problem illustrate
ideal plan looks like domain.
optimal plan would look ahead attempt keep spare tires accessible
possible avoid dead ends. start state, car must make three steps without
flat tire reach first spare cc, occur probability 0.853 0.61. Now,
car needs go four steps without getting two flats make next spare d5.
gets zero flats probability 0.854 0.52 one flat probability 4 0.853 0.15
0.37, four-step segment traversed probability 0.52 + 0.37 = 0.89 one
spare tire. three four-step segments must traversed successfully reach
ck. Finally, spare, last two steps traveled certainty. Thus, total
success probability event sequence 0.61 0.893 0.43. Note estimate
867

fiYounes, Littman, Weissman & Asmuth

spare tire
(all boxed locations)
start

goal
d6

d5

ca
c1

cn

cd

cc

c0

cm

cb
c2

ce

cf

cg

ch

ci
c6

c3

c4

cj

ck

c7 c8

c5

cl
c9
d4

d0
d1

d2

d3

Figure 6: Tireworld domain used competition.
lower bound success probability optimal strategy, factor
probability getting flat tire upon arrival state spare tire. Furthermore,
car location cf ch spare flat, unnecessary traverse
loop pick spare tire location d5 cm. accounting factors get
success probability 0.57.
contrast, greedy replanning algorithm would gather spares, since utility
comes realization something might go wrong. planner, best
plan go directly c0 c9 shortest (9-step) route. success probability
0.859 0.23, 40 percent best success probability computed above.
reward version planning problem, optimal success probability one
call-AAA action always available. However, cost action equals
reward reaching goal, always better end execution done
action repair flat tire call-AAA action. Hence, best strategy
goal version optimal reward version well gives reward
45. greedy strategy outlined would result expected reward 22.
call-AAA action used fix flat tires, expected reward drops 29.
4.7 Towers Hanoise
name suggests, domain noisy version famous Towers Hanoi
problem. domain two types objects, disks pegs. problem
used competition five disks three pegs. actions domain
single-move-big-not-moved, single-move-big-moved, double-move-big-not-moved
double-move-big-moved. action names suggest, one move either one two
868

fiThe First Probabilistic Track IPC

disks time (single-move/double-move) outcome move dependent
whether biggest disk moved yet (big-not-moved/big-moved). objective domain maximize probability reaching goal configuration (no
rewards).
initial configuration defines starting positions disks (as Towers
Hanoi, five disks stacked first peg bottom top, largest smallest
order). goal configuration defines destination positions disks (again,
destination positions Towers Hanoi, namely five disks
stacked order initial configuration last peg). goal
problem move disks starting configuration goal configuration.
actions Towers Hanoise noisy outcomes. particular, executing action
possible drop disk lost forever, thus bringing execution dead
end. success probabilities are:

Action
single-move-big-not-moved
single-move-big-moved
double-move-big-not-moved
double-move-big-moved

Success Probability
0.99
0.95
0.80
0.90

Notice probability succeeding move dependent number disks
moved whether big disk moved yet.
Every sequence actions success probability less one problem,
possible reach goal certainty. maximize probability reaching
goal, careful comparison must made. move big disk first last
peg, necessary move four smaller disks middle peg. subgoal
achieved executing single-move-big-not-moved fifteen times smaller disks,
resulting success probability 0.9915 0.86. also accomplished moving
four smaller disks two units two using double-move-big-not-moved three times,
resulting low success probability approximately 0.51.
Next, big disk moved first last peg success probability
0.99 (single-move-big-not-moved). Then, four smaller disks need moved,
time middle peg last peg. big disk moved,
success probabilities change two strategies yield success probabilities 0.46
single-move-big-moved 0.73 double-move-big-moved.
planner chooses optimally step would switch single moves double
moves big disk place resulting total success probability 0.9915
0.99 0.93 0.62. One ignores probabilities always uses single moves lower
success probability 0.9915 0.99 0.9515 0.39. planner ignores probabilities
minimizes number steps always using double moves lower success probability
still 0.83 0.990.93 0.37. Thus, optimum performance, planner must realize
policy consider success probabilities actions influenced
status big disk.
869

fiYounes, Littman, Weissman & Asmuth

4.8 Zeno Travel
last domain Zeno Travel, based domain used IPC-3. Problem instances
domain involve using airplanes move people cities. airplane requires fuel fly. flown two different speedsthe higher speed requiring
fuel. problem instance used one aircraft, two people, three cities seven
fuel levels. actions domain start-boarding, complete-boarding, startdebarking, complete-debarking, start-refueling, complete-refueling, start-flying,
complete-flying, start-zooming, complete-zooming. initial configuration
specifies location plane, initial fuel level plane location
people (as well initializations allow arithmetic type operations
fuel-level objects). goal configuration specifies destination plane destinations people. noise domain comes family complete-X
actions. time complete-X action executed desired effect
probability 1/k positive integer k (note k function action executed, specifically k = 20 complete-boarding k = 30 complete-debarking).
desired effect achieved effect, occurs probability
1 (1/k). structure meant represent actions random duration. durative action X represented two primitive actions start-X complete-X, giving
X duration geometrically distributed.
Ultimately, problem presented real challenge neglected include
action costs. Since actions either standard desired effect none all, planner
simple continue execute action effect achieved, without incurring cost.

5. Competition Results
Based initial announcement competition, put together mailing list
87 researchers expressing interest. development PPDDL, server, evaluation
criteria, practice domains progressed, kept community informed releasing
series FAQs (May 2003, FAQ 0.1; September 2003, FAQ 0.5; November 2003 FAQ 1.01).
early 2004, core group participants became evident competition logistics
finalized. Leading June 2004, participants ran planners previously
unseen test problems. tabulated scores set evaluation categories
presented ICAPS04 Vancouver, Canada.
following subsections describe competitions participants, evaluation tracks,
results.
5.1 Participants
Although twenty teams registered competition initially, seven teams four continents ultimately competed. produced ten different planners, evaluated
various subsets problem domains. groups planners were:
Group C. UMass
Participants: Zhengzhu Feng (University Massachusetts) Eric Hansen (Mississippi State University).
870

fiThe First Probabilistic Track IPC

Description: Symbolic heuristic search.
Group E. Dresden (FluCaP, formerly FCPlanner)
Participants: Eldar Karabaev Olga Skvortsova (both Dresden University
Technology).
Description: First-order heuristic search.
Group G. ANU (NMRDPP)
Participants: Charles Gretton, David Price Sylvie Thiebaux (all Australian
National University).
Descriptions: G1: Planner primarily designed domains non-Markovian rewards, G2: NMRDPP augmented control knowledge.
Group J. Purdue
Participants: SungWook Yoon, Alan Fern Robert Givan (all Purdue University).
Descriptions: J1: Human-written policy Classys policy language (Purdue-Humans), J2: Offline policy iteration reduction classification, automatically acquiring domain-specific policy (Classy), J3: Deterministic replanner using
FF (FF-rePlan).
Group P. Simon Bolvar (mGPT)
Participants: Blai Bonet (Universidad Simon Bolvar) Hector Geffner (Universitat
Pompeu Fabra).
Description: Labeled RTDP lower bounds extracted problem description.
Group Q. Michigan Tech (Probapop)
Participants: Nilufer Onder, Garrett C. Whelan Li Li (all Michigan Technological University).
Description: POP-style planner (no sensing).
Group R. CERT
Participants: Florent Teichteil-Konigsbuch Patrick Fabiani (both CERT).
Description: Probabilistic reachability heuristic DBNs.
5.2 Evaluation Tracks
clear discussions leading competition different groups
prioritizing efforts differently. wanted ensure diverse set powerful
approaches recognized decided tabulate results several different ways
acknowledge value different approaches. six tracks were:
871

fiYounes, Littman, Weissman & Asmuth

Overall. track used reward-based evaluation criterion domains (goal
achievement counted 500 goal-based domains). Domains: Blocksworld (7 problems), Colored Blocksworld (2), Boxworld (5), Exploding Blocksworld (1), Fileworld
(1), Tireworld (2), Towers Hanoise (1), Zeno Travel (1).
Goal-based. track, ignored action costs counted goal achievement
unit reward (thus emphasizing approaches maximized probability
reaching goal state). domains problems used
Overall track: Blocksworld (7), Colored Blocksworld (2), Boxworld (5), Exploding
Blocksworld (1), Fileworld (1), Tireworld (2), Towers Hanoise (1), Zeno Travel (1).
Overall, Non-Blocks/Box. Blocksworld Boxworld dominated full set
wanted see subtler problems handled. Domains: Exploding
Blocksworld (1), Fileworld (1), Tireworld (2), Towers Hanoise (1), Zeno Travel (1).
Domain-specific. Domain-specific allowed human-tuned rules; Domain-specific,
Tuning (only automatically generated rules specific domain
allowed). evaluated using generated domains: Blocksworld (8), Colored
Blocksworld (6), Boxworld (5).
Conformant. Planners category produce straight-line plans, blind
intermediate states encountered. prepared unobservable versions domains
evaluate planners category. Domains: Blocksworld (7), Colored Blocksworld
(2), Boxworld (5), Exploding Blocksworld (1), Fileworld (1), Tireworld (2), Towers
Hanoise (1), Zeno Travel (1).
5.3 Results
display results evaluation track, plotted cumulative reward achieved
participant set evaluation problems (reward accumulated left right).
reward-based tracks, goal achievement counted 500 problems without
explicitly specified goal reward. plots highlight one planner advantage
another (greater slope) well total difference score (height difference
lines).
Figure 7 displays results Overall category. Two planners, J3 P, produced
significantly positive results others, replanning algorithm J3 clearly
dominating others. J3 crowned Overall winner, P runner up. figure
also displays results Conformant category, consisted solely Q,
uncontested winner category.
Similar results visible Goal-based track, displayed Figure 8, J3
comes ahead P achieving runner-up status. Comparing Figures 7 8
reveals margin victory J3 P, R G1 diminished Goalbased category. suggests J3 sensitive rewards themselveschoosing
cheaper paths among multiple paths available goal. set problems used
competition, distinction significant graphs look similar.
However, different set test problems might revealed fundamental tradeoff
872

fi873
Zeno Travel

Tower Hanoise

Tireworld (reward)

Tireworld (goal)

Fileworld

Exploding Blocksworld

Boxworld (10, 10; goal)

Boxworld (5, 10; goal)

Boxworld (15, 10)

Boxworld (10, 10)

Boxworld (5, 10)

Colored Blocksworld (8; goal)

Colored Blocksworld (8)

Blocksworld (8; goal)

Blocksworld (21)

Blocksworld (18)

Blocksworld (15)

5000

Blocksworld (11)

Blocksworld (8)

Blocksworld (5)

cumulative reward

First Probabilistic Track IPC

J3
P
C
G1
R
Q

4000

3000

2000

1000

0

Figure 7: Competition results Overall category. result Conformant category line marked Q. numbers parentheses indicate problem size:
number blocks Blocksworld domains; number cities boxes, respectively, Boxworld domains.

fiYounes, Littman, Weissman & Asmuth

J3
P
C
G1
R
Q

14

cumulative goal probability

12

10

8

6

4

2

Zeno Travel

Tower Hanoise

Tireworld (reward)

Tireworld (goal)

Fileworld

Exploding Blocksworld

Boxworld (10, 10; goal)

Boxworld (5, 10; goal)

Boxworld (15, 10)

Boxworld (10, 10)

Boxworld (5, 10)

Colored Blocksworld (8; goal)

Colored Blocksworld (8)

Blocksworld (8; goal)

Blocksworld (21)

Blocksworld (18)

Blocksworld (15)

Blocksworld (11)

Blocksworld (8)

Blocksworld (5)

0

Figure 8: Competition results Goal-based category.
seeking maximize reward seeking reach goal high probability.
Future competitions could attempt highlight important issue.
interesting note J3s outstanding performance stems primarily
early problems, Blocksworld Boxworld problems amenable
replanning. later problems set handled well J3
planners.
Figure 9 displays results Non-Block/Box category. Indeed, J3 performed
much poorly problems category, Planner C taking top spot.
runner-up spot closely contested planners R G1, G1 pulled ahead
last problem claim honors. Planner P also performed nearly well
set.
Figure 10 gives detailed view results Non-Blocks/Box category.
optimal score problem indicated graphs.3 Note Planner Cs
performance Tireworld domain well optimal, result now-fixed bug
competition server allowed disabled actions executed. Planner P displayed
outstanding performance Fileworld goal-based Tireworld problems,
attempt solve Tower Hanoise therefore fell behind G1 R overall. Planner R
used time per round Planner G1 Zeno Travel domain, ultimately
cost R second place could complete 27 30 runs domain.
Note planners received negative score reward-oriented problems.
3. optimal scores necessarily apply Planner Q, conformant planner.

874

fiThe First Probabilistic Track IPC

C
G1
R
P
J3
Q

1000

cumulative reward

800

600

400

200

Zeno Travel

Tower Hanoise

Tireworld (reward)

Tireworld (goal)

Fileworld

Exploding Blocksworld

0

Figure 9: Summary competition results Overall, Non-Blocks/Box category.
counted negative scores individual problems zero overall evaluation
give advantage planners even attempt solve problems. Planner Q
entrant (except, possibly, C) receive positive score reward-based
Tireworld problem. planners negative score problem used expensive
call-AAA action ensure goal always reached.
results domain-specific planners shown Figure 11. highest scoring
planners J1 G2, difference primarily due two largest
Blocksworld problems, J1 solved effectively G2. performance
five domain-specific planners colored Blocksworld problems virtually indistinguishable. mentioned earlier, grounding goal condition validator prevented us
using larger problem instances, might otherwise separated planners
domain.
two planners domain specific category ineligible
tuning subcategory hand-tuned domains. Thus, J3 J2
took top spots subcategory. interesting note J3 spite
general-purpose plannerit not, fact, created domain specific. overtook
J2 due two small Boxworld problems J3 solved J2 missed.
Figure 12 summarizes competition results six evaluation categories.

6. Conclusion
happy outcomes first probabilistic track International Planning
Competition. addition bringing attention important set planning challenges,
875

fiYounes, Littman, Weissman & Asmuth

Exploding Blocksworld

Tireworld (goal)

1

1

**
max prob.

0.8

goal probability

0.6
0.4
0.2
0

0.8
0.6
0.4
0.2

*
C

G1

*
P

J3

*
Q

*
R

0
C

1

100
*

*

*

0
-100

prob.
max prob.
reward
max reward
G1

J3

Q

R

P

Q

prob.
max prob.
reward
max reward

0.8

200

C

P

**

300
goal probability

1
0.8
0.6
0.4
0.2
0

J3

Tireworld (reward)

reward

goal probability

Fileworld

G1

0.6

80
60

0.4

40

0.2

20

0

-200

reward

goal probability

max prob.

0

-300

-20

-400
R

C

G1

Tower Hanoise

J3

P

Q

R

Zeno Travel
max prob.

1

1

0.8

goal probability

goal probability

max prob.

0.6
0.4
0.2
0

0.8
0.6
0.4
0.2

*
C

G1

J3

*
P

*
Q

0
R

C

G1

J3

P

Q

R

Figure 10: Competition results Non-Blocks/Box problems (* indicates planner
attempt solve problem; ** indicates anomalous results due bug
server allowed execution disabled actions). Note two
graphs center reward scales right.

876

fiThe First Probabilistic Track IPC

J1*
G2*
J3
J2
E*

8000
7000

cumulative reward

6000
5000
4000
3000
2000
1000

Boxworld (10, 10; goal)

Boxworld (5, 10; goal)

Boxworld (15, 10)

Boxworld (10, 10)

Boxworld (5, 10)

Colored Blocksworld (11; goal)

Colored Blocksworld (8; goal)

Colored Blocksworld (5; goal)

Colored Blocksworld (11)

Colored Blocksworld (8)

Colored Blocksworld (5)

Blocksworld (8; goal)

Blocksworld (21)

Blocksworld (18)

Blocksworld (15)

Blocksworld (11)

Blocksworld (8)

Blocksworld (5)

0

Figure 11: Competition results Domain-specific categories. Tuning
category results, ignore J1, G2, E lines graph (marked
asterisks).

Category
Overall
Goal-based Domains
Overall, Non-Blocks/Box
Domain-specific, Tuning
Domain-specific
Conformant

1st
J3
J3
C
J3
J1
Q

2nd
P
P
G1
J2
G2

Figure 12: Summary competition results category.

877

fiYounes, Littman, Weissman & Asmuth

appears helped spur community use uniform comparison problems
providing domain language set benchmarks (Yoon, Fern, & Givan, 2005).
spite success, feel changes could made future competitions would increase value community. First, competition logistics
side, server logged outcomes interactions planners domains,
keep exhaustive record actions taken timing information. retrospect,
information would helpful identifying planners addressed
domains whether took suboptimal actions got unlucky. addition,
server provisions security. simple password and/or reservation system would
helped evaluations go much smoothly would prevented inadvertent
access server one group another assigned evaluation slot.
domain side, hope future competitions able focus interesting
domains. found simply adding noisy action failures deterministic domain
enough produce interesting probabilistic problemsfor domains, straightforward replanning effective. non-Blocksworld domains created
mastered planners hope retained form future
evaluations.
Like progression competitions classical track, hope future competitions
probabilistic track move toward domains grounded real-life data real-world
problems including handling partially observability time. second competition
slated held conjunction IPC 2006 urge interested members
planning community participate help keep competition moving productive
direction benefit field.

Acknowledgments
appreciate support National Science Foundation Royal Swedish
Academy Engineering Sciences, well feedback Sven Koenig, Shlomo Zilberstein, Paul Batchis, Bob Givan, Hector Geffner participants contributed
design competition. JAIR editor David Smith anonymous reviewers provided invaluable insights document tried reflect final manuscript.
material based upon work supported National Science Foundation
Grant No. 0315909 Royal Swedish Academy Engineering Sciences (IVA)
grants Hans Werthen fund. opinions, findings, conclusions recommendations expressed material author(s) necessarily reflect
views National Science Foundation IVA.

878

fiThe First Probabilistic Track IPC

Appendix A. BNF Grammar PPDDL1.0
provide full syntax PPDDL1.0 using extended BNF notation following conventions:
rule form hnon-terminal ::= expansion.
Alternative expansions separated vertical bar (|).
syntactic element surrounded square brackets ([ ]) optional.
Expansions optional syntactic elements superscripted requirements flag
available requirements flag specified domain problem currently
defined. example, [htypes-def i]:typing syntax domain definitions
means htypes-def may occur domain definitions include :typing
flag requirements declaration.
asterisk (*) following syntactic element x means zero occurrences
x ; plus (+ ) following x means least one occurrence x.
Parameterized non-terminals, example htyped list (x )i, represent separate rules
instantiation parameter.
Terminals written using typewriter font.
syntax Lisp-like. particular, case significant (for example, ?x ?X
equivalent), parenthesis essential part syntax semantic
meaning extended BNF notation, number whitespace characters
(space, newline, tab, etc.) may occur tokens.
A.1 Domains
syntax domain definitions PDDL2.1, except durative actions
allowed. Declarations constants, predicates, functions allowed
order respect one another, must come type declarations
precede action declarations.
hdomaini

hrequire-def
hrequire-keyi
htypes-def
hconstants-def
hpredicates-def

::= ( define ( domain hnamei )
[hrequire-def i]
[htypes-def i]:typing
[hconstants-def i]
[hpredicates-def i]
[hfunctions-def i]:fluents
hstructure-def i* )
::= ( :requirements hrequire-keyi* )
::= See Section A.4
::= ( :types htyped list (name)i )
::= ( :constants htyped list (name)i )
::= ( :predicates hatomic formula skeletoni* )
879

fiYounes, Littman, Weissman & Asmuth

hatomic formula skeletoni
hpredicatei
hfunctions-def
hfunction skeletoni
hfunction symbol
hstructure-def
haction-def
htyped list (x )i
htypei
hprimitive typei
hfunction typed list (x )i
hfunction typei

::= ( hpredicatei htyped list (variable)i )
::= hnamei
::= ( :functions hfunction typed list (function skeleton)i )
::= ( hfunction symbol htyped list (variable)i )
::= hnamei
::= haction-def
::= See Section A.2
::= hx i* |:typing hx i+ - htypei htyped list (x )i
::= ( either hprimitive typei+ ) | hprimitive typei
::= hnamei
::= hx i*
|:typing hx i+ - hfunction typei hfunction typed list (x )i
::= number

hnamei string characters starting alphabetic character followed
possibly empty sequence alphanumeric characters, hyphens (-), underscore characters ( ). hvariablei hnamei immediately preceded question mark (?).
example, in-office ball 2 names, ?gripper variable.
A.2 Actions
Action definitions goal descriptions syntax PDDL2.1.
haction-def

::= ( :action haction symbol
[:parameters ( htyped list (variable)i )]
haction-def bodyi )
haction symbol
::= hnamei
haction-def bodyi
::= [:precondition hGDi]
[:effect heffecti]
hGDi
::= hatomic formula (term)i | ( hGDi* )
|:equality ( = htermi htermi )
|:equality ( ( = htermi htermi ) )
|:negative-preconditions ( hatomic formula (term)i )
|:disjunctive-preconditions ( hGDi )
|:disjunctive-preconditions ( hGDi* )
|:disjunctive-preconditions ( imply hGDi hGDi )
|:existential-preconditions ( exists ( htyped list (variable)i )
hGDi )
|:universal-preconditions ( forall ( htyped list (variable)i )
hGDi )
|:fluents hf-compi
hatomic formula (x )i ::= ( hpredicatei hx i* ) | hpredicatei
htermi
::= hnamei | hvariablei
hf-compi
::= ( hbinary-compi hf-expi hf-expi )
hbinary-compi
::= < | <= | = | >= | >
hf-expi
::= hnumber | hf-head (term)i
880

fiThe First Probabilistic Track IPC

hf-head (x )i
hbinary-opi

| ( hbinary-opi hf-expi hf-expi ) | ( - hf-expi )
::= ( hfunction symbol hx i* ) | hfunction symbol
::= + | - | * | /

hnumber sequence numeric characters, possibly single decimal point (.)
position sequence. Negative numbers written (- hnumber i).
syntax effects extended allow probabilistic effects,
arbitrarily interleaved conditional effects universal quantification.
heffecti

::= hp-effecti | ( heffecti* )
|:conditional-effects ( forall ( htyped list (variable)i ) heffecti )
|:conditional-effects ( hGDi heffecti )
|:probabilistic-effects ( probabilistic hprob-effecti+ )
hp-effecti
::= hatomic formula (term)i | ( hatomic formula (term)i )
|:fluents ( hassign-opi hf-head (term)i hf-expi )
|:rewards ( hadditive-opi hreward fluenti hf-expi )
hprob-effecti
::= hprobabilityi heffecti
hassign-opi
::= assign | scale-up | scale-down | hadditive-opi
hadditive-opi ::= increase | decrease
hreward fluenti ::= ( reward ) | reward

hprobabilityi hnumber value interval [0, 1].
A.3 Problems
syntax problem definitions extended allow specification
probability distribution initial states, also permit association one-time
reward entering goal state. otherwise identical syntax PDDL2.1
problem definitions.
hproblemi

hobjects-def
hiniti
hinit-el
hp-init-el
hprob-init-el
ha-init-el
hgoal
hgoal-speci
hmetric-speci

::= ( define ( problem hnamei )
( :domain hnamei )
[hrequire-def i]
[hobjects-def i]
[hiniti]
hgoal )
::= ( :objects htyped list (name)i )
::= ( :init hinit-el i* )
::= hp-init-el
|:probabilistic-effects ( probabilistic hprob-init-el i* )
::= hatomic formula (name)i |:fluents ( = hf-head (name)i hnumber )
::= hprobabilityi ha-init-el
::= hp-init-el | ( hp-init-el i* )
::= hgoal-speci [hmetric-speci] | hmetric-speci
::= ( :goal hGDi ) [( :goal-reward hground-f-expi )]:rewards
::= ( :metric hoptimizationi hground-f-expi )
881

fiYounes, Littman, Weissman & Asmuth

hoptimizationi ::= minimize | maximize
hground-f-expi ::= hnumber | hf-head (name)i
| ( hbinary-opi hground-f-expi hground-f-expi )
| ( - hground-f-expi )
| ( total-time ) | total-time
| ( goal-achieved ) | goal-achieved
|:rewards hreward fluenti
A.4 Requirements
table requirements PPDDL1.0. requirements imply others;
abbreviations common sets requirements. domain stipulates requirements,
assumed declare requirement :strips.
Requirement
:strips
:typing
:equality
:negative-preconditions
:disjunctive-preconditions
:existential-preconditions
:universal-preconditions
:quantified-preconditions
:conditional-effects
:probabilistic-effects
:rewards
:fluents
:adl

:mdp

Description
Basic STRIPS-style adds deletes
Allow type names declarations variables
Support = built-in predicate
Allow negated atoms goal descriptions
Allow disjunctive goal descriptions
Allow exists goal descriptions
Allow forall goal descriptions
= :existential-preconditions
+ :universal-preconditions
Allow forall action effects
Allow probabilistic action effects
Allow reward fluent action effects
optimization metric
Allow numeric state variables
= :strips + :typing + :equality
+ :negative-preconditions
+ :disjunctive-preconditions
+ :quantified-preconditions
+ :conditional-effects
= :probabilistic-effects + :rewards

882

fiThe First Probabilistic Track IPC

CLIENT

SERVER

/ session-request \
\
/
/ session-init \
\
/

/ round-request \
\
/
/ round-init \
\
/

/ state \
\
/
/ action
\

spec \/

..
.
/ state \
\
/
/ action
\

spec \/

/ end-round \
\
/










repeat










/ end-session \
\
/

Figure 13: Successful communication session.

Appendix B. Communication Protocol
adopt XML-like syntax client/server communication protocol. use
extended BNF notation Appendix describe syntax protocol messages.
hnamei hnumber terminals defined exactly way PPDDL.
hinteger nonempty string numeric characters. hmessagei arbitrary character
string, possibly empty.
Figure 13 shows expected sequence messages. session starts client
sending hsession-requesti message server. server replies hsession-initi
message, tells client number evaluation rounds run. start
evaluation round, client sends hround-requesti message, server replies
hround-initi message. point evaluation round starts. server sends
hturn-responsei message client, hstatei message hend-round
message. every hstatei message client receives, sends haction speci message
return. client receives hend-round message, ends current evaluation
round. client starts new evaluation round hround-requesti message
server, waits hend-sessioni message server case rounds
already run. server sends herror message client error occurs,
example server receives unexpected message client.
883

fiYounes, Littman, Weissman & Asmuth

B.1 Client Messages
Client messages following form:
hsession-requesti ::= <session-request>
<name> hnamei </name>
<problem> hnamei </problem>
</session-request>
hround-requesti

::= <round-request/>

haction speci
hactioni
htermi

::= <act> hactioni </act> | <done/>
::= <action> <name> hnamei </name> htermi* </action>
::= <term> hnamei </term>

B.2 Server Messages
Server messages following form:
hsession-initi

::= <session-init>
<sessionID> hinteger </sessionID>
<setting>
<rounds> hinteger </rounds>
<allowed-time> hinteger </allowed-time>
<allowed-turns> hinteger </allowed-turns>
</setting>
</session-init>

hround-initi

::= <round-init>
<round> hinteger </round>
<sessionID> hinteger </sessionID>
<time-left> hinteger </time-left>
<rounds-left> hinteger </rounds-left>
</round-init>

hturn-responsei ::= hstatei | hend-round
hend-round
::= <end-round>
hstatei [<goal-reached/>]
<time-spent> hinteger </time-spent>
<turns-used> hinteger </turns-used>
</end-round>
hstatei
::= <state> [<is-goal/>] hatomi* hfluenti* </state>
hatomi
::= <atom> hpredicatei htermi* </atom>
hfluenti
::= <fluent> hfunctioni htermi* hvaluei </fluent>
hpredicatei
::= <predicate> hnamei </predicate>
hfunctioni
::= <function> hnamei </function>
htermi
::= <term> hnamei </term>
884

fiThe First Probabilistic Track IPC

hvaluei

::= <value> hnumber </value>

hend-sessioni

::= <end-session>
<sessionID> hinteger </sessionID>
<problem> hnamei </problem>
<rounds> hinteger </rounds>
<goals>
<failed> hinteger </failed>
<reached>
<successes> hinteger </successes>
[<time-average> hnumber </time-average>]
</reached>
</goals>
[<metric-average> hnumber </metric-average>]
</end-session>

herror

::= <error> hmessagei </error>

885

fiYounes, Littman, Weissman & Asmuth

References
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research,
11, 194.
Boutilier, C., Dearden, R., & Goldszmidt, M. (1995). Exploiting structure policy construction. Mellish, C. S. (Ed.), Proceedings Fourteenth International Joint
Conference Artificial Intelligence, pp. 11041111, Montreal, Canada. Morgan Kaufmann Publishers.
Boutilier, C., Friedman, N., Goldszmidt, M., & Koller, D. (1996). Context-specific independence Bayesian networks. Proceedings Twelfth Annual Conference
Uncertainty Artificial Intelligence (UAI 96), pp. 115123, Portland, OR.
Dean, T., & Kanazawa, K. (1989). model reasoning persistence causation.
Computational Intelligence, 5 (3), 142150.
Dearden, R., & Boutilier, C. (1997). Abstraction approximate decision-theoretic planning. Artificial Intelligence, 89 (12), 219283.
Fox, M., & Long, D. (2003). PDDL2.1: extension PDDL expressing temporal
planning domains. Journal Artificial Intelligence Research, 20, 61124.
Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003). Efficient solution algorithms
factored MDPs. Journal Artificial Intelligence Research, 19, 399468.
Hoey, J., St-Aubin, R., Hu, A., & Boutilier, C. (1999). SPUDD: Stochastic planning using
decision diagrams. Laskey, K. B., & Prade, H. (Eds.), Proceedings Fifteenth
Conference Uncertainty Artificial Intelligence, pp. 279288, Stockholm, Sweden.
Morgan Kaufmann Publishers.
Howard, R. A. (1960). Dynamic Programming Markov Processes. John Wiley & Sons,
New York, NY.
Howard, R. A. (1971). Dynamic Probabilistic Systems, Vol. I: Markov Models. John Wiley
& Sons, New York, NY.
Kushmerick, N., Hanks, S., & Weld, D. S. (1995). algorithm probabilistic planning.
Artificial Intelligence, 76 (12), 239286.
Littman, M. L. (1997). Probabilistic propositional planning: Representations complexity. Proceedings Fourteenth National Conference Artificial Intelligence,
pp. 748754, Providence, RI. American Association Artificial Intelligence, AAAI
Press.
Littman, M. L., Goldsmith, J., & Mundhenk, M. (1998). computational complexity
probabilistic planning. Journal Artificial Intelligence Research, 9, 136.
McDermott, D. (2000). 1998 AI planning systems competition. AI Magazine, 21 (2),
3555.
Puterman, M. L. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming. John Wiley & Sons, New York, NY.
886

fiThe First Probabilistic Track IPC

Rintanen, J. (2003). Expressive equivalence formalisms planning sensing.
Giunchiglia, E., Muscettola, N., & Nau, D. S. (Eds.), Proceedings Thirteenth International Conference Automated Planning Scheduling, pp. 185194, Trento,
Italy. AAAI Press.
Yoon, S., Fern, A., & Givan, R. (2005). Learning measures progress planning domains.
Proceedings Twentieth National Conference Artificial Intelligence, pp.
12171222.
Younes, H. L. S., & Littman, M. L. (2004). PPDDL1.0: extension PDDL expressing
planning domains probabilistic effects. Tech. rep. CMU-CS-04-167, Carnegie
Mellon University, Pittsburgh, PA.

887

fiJournal Artificial Intelligence Research 24 (2005) 305339

Submitted 11/04; published 8/05

Learning Concept Hierarchies Text Corpora
using Formal Concept Analysis
CIMIANO @ AIFB . UNI - KARLSRUHE . DE

Philipp Cimiano
Institute AIFB, University Karlsruhe
Englerstr. 11, 76131 Karlsruhe, Germany

HOTHO @ CS . UNI - KASSEL . DE

Andreas Hotho
Knowledge Data Engineering Group, University Kassel
Wilhelmshoher Allee 73, 34121 Kassel, Germany

STAAB @ UNI - KOBLENZ . DE

Steffen Staab
Institute Computer Science, University Koblenz-Landau
Universitatsstr. 1, 56016 Koblenz, Germany

Abstract
present novel approach automatic acquisition taxonomies concept hierarchies
text corpus. approach based Formal Concept Analysis (FCA), method mainly
used analysis data, i.e. investigating processing explicitly given information.
follow Harris distributional hypothesis model context certain term vector representing syntactic dependencies automatically acquired text corpus linguistic parser. basis context information, FCA produces lattice convert
special kind partial order constituting concept hierarchy. approach evaluated comparing resulting concept hierarchies hand-crafted taxonomies two domains: tourism
finance. also directly compare approach hierarchical agglomerative clustering
well Bi-Section-KMeans instance divisive clustering algorithm. Furthermore,
investigate impact using different measures weighting contribution attribute
well applying particular smoothing technique cope data sparseness.

1. Introduction
Taxonomies concept hierarchies crucial knowledge-based system, i.e. system
equipped declarative knowledge domain deals capable reasoning
basis knowledge. Concept hierarchies fact important allow structure
information categories, thus fostering search reuse. Further, allow formulate
rules well relations abstract concise way, facilitating development, refinement
reuse knowledge-base. Further, fact allow generalize words shown
provide benefits number applications Information Retrieval (Voorhees, 1994)
well text clustering (Hotho, Staab, & Stumme, 2003) classification (Bloehdorn & Hotho,
2004). addition, also important applications within Natural Language Processing (e.g.
Cimiano, 2003).
However, also well known knowledge-based system suffers so-called
knowledge acquisition bottleneck, i.e. difficulty actually model domain question.

c 2005 AI Access Foundation. rights reserved.

fiC IMIANO , H OTHO , & TAAB

order partially overcome problem present novel approach automatically learning
concept hierarchy text corpus.
Making knowledge implicitly contained texts explicit great challenge. example,
Brewster, Ciravegna, Wilks (2003) argued text writing reading fact process
background knowledge maintenance sense basic domain knowledge assumed,
relevant part knowledge issue text article mentioned
less explicit way. Actually, knowledge found texts different levels explicitness
depending sort text considered. Handbooks, textbooks dictionaries example contain
explicit knowledge form definitions tiger mammal mammals
tigers, lions elephants. fact, researchers exploited regular patterns discover
taxonomic part-of relations texts (Hearst, 1992; Charniak & Berland, 1999; Iwanska, Mata, &
Kruger, 2000; Ahmad, Tariq, Vrusias, & Handy, 2003). However, seems technical
specialized texts get, less basic knowledge find stated explicitly. Thus, interesting
alternative derive knowledge texts analyzing certain terms used rather
look explicit definition. lines distributional hypothesis (Harris, 1968) assumes
terms similar extent share similar linguistic contexts.
fact, different methods proposed literature address problem (semi-)
automatically deriving concept hierarchy text based distributional hypothesis. Basically, methods grouped two classes: similarity-based methods one hand
set-theoretical hand. methods adopt vector-space model represent
word term vector containing features attributes derived certain corpus.
certainly great divergence attributes used purpose, typically sort
syntactic features used, conjunctions, appositions (Caraballo, 1999) verb-argument
dependencies (Hindle, 1990; Pereira, Tishby, & Lee, 1993; Grefenstette, 1994; Faure & Nedellec,
1998).
first type methods characterized use similarity distance measure
order compute pairwise similarity distance vectors corresponding two words
terms order decide clustered not. prominent examples type
method developed Hindle (1990), Pereira et al. (1993), Grefenstette (1994), Faure
Nedellec (1998), Caraballo (1999) well Bisson, Nedellec, Canamero (2000). Settheoretical approaches partially order objects according inclusion relations
attribute sets (Petersen, 2002; Sporleder, 2002).
paper, present approach based Formal Concept Analysis, method based
order theory mainly used analysis data, particular discovering inherent relationships objects described set attributes one hand, attributes
(Ganter & Wille, 1999). order derive attributes certain corpus,
parse extract verb/prepositional phrase (PP)-complement, verb/object verb/subject
dependencies. noun appearing head argument positions use corresponding verbs attributes building formal context calculating formal concept
lattice basis.
Though different methods explored literature, actually lack comparative work concerning task automatically learning concept hierarchies clustering techniques. However, argued Cimiano, Hotho, Staab (2004c), ontology engineers need guidelines effectiveness, efficiency trade-offs different methods order decide
techniques apply settings. Thus, present comparison along lines
306

fiL EARNING C ONCEPT H IERARCHIES



EXT C ORPORA

USING

F ORMAL C ONCEPT NALYSIS

FCA-based approach, hierarchical bottom-up (agglomerative) clustering Bi-Section-KMeans
instance divisive algorithm. particular, compare learned concept hierarchies
terms similarity handcrafted reference taxonomies two domains: tourism finance.
addition, examine impact using different information measures weight significance
given object/attribute pair. Furthermore, also investigate use smoothing technique
cope data sparseness.
remainder paper organized follows: Section 2 describes overall process
Section 3 briefly introduces Formal Concept Analysis describes nature concept
hierarchies automatically acquire. Section 4 describes text processing methods apply
automatically derive context attributes. Section 5 discuss detail evaluation methodology
present actual results Section 6. particular, present comparison different
approaches well evaluation impact different information measures well
smoothing technique. concluding, discuss related work Section 7.

2. Overall Process
overall process automatically deriving concept hierarchies text depicted Figure 1.
First, corpus part-of-speech (POS) tagged 1 using TreeTagger (Schmid, 1994) parsed using
LoPar2 (Schmid, 2000), thus yielding parse tree sentence. Then, verb/subject, verb/object
verb/prepositional phrase dependencies extracted parse trees. particular, pairs
extracted consisting verb head subject, object prepositional phrase
subcategorize. Then, verb heads lemmatized, i.e. assigned base form.
order address data sparseness, collection pairs smoothed, i.e. frequency pairs
appear corpus estimated basis frequency pairs.
pairs weighted according statistical measure pairs certain
threshold transformed formal context Formal Concept Analysis applied.
lattice resulting this, ( , ), transformed partial order ( , ) closer
concept hierarchy traditional sense. FCA typically leads proliferation concepts,
partial order compacted pruning step, removing abstract concepts leading compacted
partial order ( , ) resulting concept hierarchy. process described detail
Section 3. process described formally Algorithm 1.







3. Formal Concept Analysis
Formal Concept Analysis (FCA) method mainly used analysis data, i.e. deriving
implicit relationships objects described set attributes one hand
attributes other. data structured units formal abstractions
concepts human thought, allowing meaningful comprehensible interpretation (Ganter & Wille,
1999). Thus, FCA seen conceptual clustering technique also provides intensional
descriptions abstract concepts data units produces. Central FCA notion
formal context:
1. Part-of-speech tagging consists assigning word syntactic category, i.e. noun, verb, adjective etc.
2. http://www.ims.uni-stuttgart.de/projekte/gramotron/SOFTWARE/LoPar-en.html

307

fiC IMIANO , H OTHO , & TAAB

Algorithm 1 ConstructConceptHierarchy(D,T)
/* construct hierarchy terms basis documents
1: Parses = parse(POS-tag( ));
2: SynDeps = tgrep(Parses);
3: lemmatize(SynDeps);
4: smooth(SynDeps);
5: weight(SynDeps);
6: SynDeps = applyThreshold(SynDeps);
7:
= getFormalContext( ,SynDeps);
8:
computeLattice
;
9:
transform
;
compact
;
10:
11: return
;







fi




*/


ff



Parser

tgrep

Lattice
Compaction

Lemmatizer

Smoothing

Pruning

FCA

Weighting

Figure 1: Overall Process

Definition 1 (Formal Context)
triple ( , , ) called formal context
sets
relation . elements called objects,
incidence context.













binary
attributes

!"# $&%(')"* '+,#-".0/
dually 123 : 1 ( 4'5".6$7%(8"*1 '+,#-"59/
Intuitively speaking, set attributes common objects , 1
set objects attributes 1 . Furthermore, define formal concept is:




, define:

Definition 2 (Formal Concept)
pair ( , ) formal concept ( ,

1

, ) :;1<3=> +?1

@A1 .
words, ( , 1 ) formal concept set attributes shared objects
identical 1 hand also set objects attributes 1 .
called extent 1 intent formal concept ( ,1 ). formal concepts
308



fiL EARNING C ONCEPT H IERARCHIES



EXT C ORPORA

USING

F ORMAL C ONCEPT NALYSIS

given context naturally ordered subconcept-superconcept relation defined by:


! 1 =
1 > 1;31
Thus, formal concepts partially ordered regard inclusion extents (which
equivalent) inverse inclusion intent.
give examples illustrate definitions. context tourism domain
one knows example things like hotel, apartment, car, bike, trip excursion
booked. Furthermore, know rent car, bike apartment. Moreover,
drive car bike, ride bike 3 . addition, know join excursion
trip. represent formal context corresponding knowledge formal context
(see Table 1). lattice produced FCA depicted Figure 2 (left) 4 . transformed
special type concept hierarchy shown Figure 2 (right) removing bottom element,
introducing ontological concept formal concept (named intent) introducing
subconcept element extent formal concept question.
partial order
,
order formally define transformation lattice
assume lattice represented using reduced labeling. Reduced labeling defined
(Ganter & Wille, 1999) means objects extension specific concept
attributes conversely intension general one. reduced labeling achieved
introducing functions
ff . particular, name object attached lower half
corresponding object concept, i.e.

, name attribute

located upper half attribute concept, i.e. ff
. given lattice
formal concepts formal context
, transform partial order
follows:





'
' 4'9/ 4'9/
fi# 2 ! / ! /
@


fi




)
Definition 3 (Transformation
First
contains objects well intents (sets attributes):



@ fi# 1 $
1 " #/
Further:

7'( 1 $
'
1 /fi.7
1 1 $
1 =
1 /
Finally, FCA typically produces high number concepts, compress resulting hierarchy ontological concepts removing inner node whose extension terms leave nodes
follows:
subsumed one child, i.e. create partial order





Definition 4 (Compacted Concept Hierarchy
)
Assuming set leave nodes dominated according

!



:

! " $ %"#>" ! # %$&'( ) +
* '( # /
Further:
3. According Longman Dictionary, American English also possible ride vehicles general. However,
purposes example gloss fact.
4. Concept Explorer software used produce lattice (see http://sourceforge.net/projects/conexp).

309

fiC IMIANO , H OTHO , & TAAB

bookable

joinable

excursion

rentable

hotel

driveable

trip

apartment

rideable

car

bike

Figure 2: lattice formal concepts (left) corresponding hierarchy ontological concepts (right) tourism example

i.e.



relation



$
restricted pairs elements

.

particular hierarchy figure 2 (right) would remove rideable concept.
hotel
apartment
car
bike
excursion
trip

bookable
x
x
x
x
x
x

rentable

driveable

rideable

x
x
x

x
x

x

joinable

x
x

Table 1: Tourism domain knowledge formal context
first glance, seems hierarchy shown Figure 2 (right) somehow odd due
fact labels abstract concepts verbs rather nouns typically assumed.
However, formal point view, concept identifiers meaning could
named concepts arbitrary symbols. reason handy
introduce meaningful concept identifiers purpose easier human readability. fact,
adopt extensional interpretation hierarchy, problems asserting
extension concept denoted bike subset extension concept rideable
objects world. view totally compatible interpreting concept hierarchy
310

fiL EARNING C ONCEPT H IERARCHIES



EXT C ORPORA

USING

F ORMAL C ONCEPT NALYSIS

% 7

& ,

terms formal subsumption given logical formula:
$ .
thus conclude extensional point view verb-like concept identifiers
status concept label based noun. intensional point view, may
even exist hypernym adequate intension label certain abstract concept,
using verb-like identifier may even appropriate choice. example, could easily
replace identifiers joinable, rideable driveable activity, two-wheeled vehicle vehicle,
respectively. However, certainly difficult substitute rentable meaningful term
denoting extension, i.e. things rented.
also important mention learned concept hierarchies represent conceptualization
domain respect given corpus sense represent relations
terms used text. However, corpora represent limited view world
certain domain due fact something mentioned, mean
relevant, simply issue text question. also leads fact
certain similarities terms respect corpus actually accidental, sense
map corresponding semantic relation, due fact texts
represent arbitrary snapshot domain. Thus, learned concept hierarchies merely
regarded approximations conceptualization certain domain.
task focusing is: given certain number terms referring concepts
relevant domain question, derive concept hierarchy them? terms
FCA, objects thus given need find corresponding attributes order build
incidence matrix, lattice transform corresponding concept hierarchy.
following section, describe acquire attributes automatically underlying
text collection.



4. Text Processing
already mentioned introduction, order derive context attributes describing terms
interested in, make use syntactic dependencies verbs appearing text
collection heads subject, object PP-complements subcategorize. fact,
previous experiments (Cimiano, Hotho, & Staab, 2004b) found using dependencies
general leads better results subsets them. order extract dependencies
automatically, parse text LoPar, trainable, statistical left-corner parser (Schmid, 2000).
parse trees extract syntactic dependencies verb subject, object PP-complement using tgrep 5 . Finally, also lemmatize verbs well head
subject, object PP-complement looking lemma lexicon provided LoPar.
Lemmatization maps word base form context used sort normalization
text. Lets take instance following two sentences:
museum houses impressive collection medieval modern art. building combines geometric abstraction classical references allude Roman influence
region.
parsing sentences, would extract following syntactic dependencies:
5. see http://mccawley.cogsci.uiuc.edu/corpora/treebank3.html

311

fiC IMIANO , H OTHO , & TAAB

houses subj(museum)
houses obj(collection)
combines subj(building)
combines obj(abstraction)
combine with(references)
allude to(influence)
lemmatization step, references mapped base form reference combines
houses combine house, respectively, yield result:
house subj(museum)
house obj(collection)
combine subj(building)
combine obj(abstraction)
combine with(reference)
allude to(influence)
addition, three important issues consider:
1. output parser erroneous, i.e. derived verb/argument dependencies
correct,
2. derived dependencies interesting sense help discriminate different objects,
3. assumption completeness information never fulfilled, i.e. text collection
never big enough find possible occurrences (compare Zipf, 1932).
deal first two problems, weight object/attribute pairs regard certain
information measure process verb/argument relations measure
threshold . particular, explore following three information measures (see
Cimiano, S.Staab, & Tane, 2003; Cimiano et al., 2004b):
ff

$
ff
fi


(
fi ' $
#
fi
fi $
!

$ ' .

#













ff
Furthermore, " total number occurrences term argument arg
ff

verb ,
number occurrences verb argument
relative frequency term compared terms. first information measure simply
conditional probability term given argument ' verb . second mea
sure ( called pointwise mutual information used Hindle (1990)






312

fiL EARNING C ONCEPT H IERARCHIES



EXT C ORPORA

USING

F ORMAL C ONCEPT NALYSIS

discovering groups similar terms. third measure inspired work Resnik (1997)
introduces additional factor
fi takes account terms appearing
argument position verb question. particular, factor measures relative
entropy prior posterior (considering verb appears with) distributions thus
selectional strength verb given argument position. important mention
approach values measures normalized interval [0,1].
third problem requires smoothing input data. fact, working text corpora,
data sparseness always issue (Zipf, 1932). typical method overcome data sparseness
smoothing (Manning & Schuetze, 1999) essence consists assigning non-zero probabilities unseen events. purpose apply technique proposed Cimiano, Staab,
Tane (2003) mutually similar terms clustered result occurrence
attribute one term also counted occurrence attribute term.
similarity measures examine Cosine, Jaccard, L1 norm, Jensen-Shannon divergence
Skew Divergence measures analyzed described Lee (1999):



'



$ $

$
$
fi

$ $



$




( $
fi $ $
fi ff $ $
fi fiffff / / $ $

( $ $ $ 4$
) (


fi
fi

















(





$ $ ' ( , : $ $ ' ( ,




( $ $ @ ! " :,
!



# : $ $ #:,
' %'&
$ ! ' (






)(*$

!,+



)(,&

!

particular, implemented measures using variants relying elements
common described Lee (1999). Strictly speaking, Jensen-Shannon well
Skew divergences dissimilarity functions measure average information loss
using one distribution instead other. fact transform similarity measures
ff
ff

, constant dissimilarity function question. cluster
terms mutually similar regard similarity measure question, counting
attribute/object pairs actually found text thus obtaining also non-zero frequencies
attribute/object pairs appear literally corpus. overall result thus
smoothing relative frequency landscape assigning non-zero relative frequencies
combinations verbs objects actually found corpus. follows
formal definition mutual similarity:
Definition 5 (Mutual Similarity)
Two terms mutually similar iff



( .



'7




313



'7 (




fiC IMIANO , H OTHO , & TAAB

Figure 3: Examples lattices automatically derived tourism-related texts without smoothing
(left) smoothing (right)

According definition, two terms mutually similar similar
term regard similarity measure question way round. Actually,
definition equivalent reciprocal similarity Hindle (1990).
Figure 3 (left) shows example lattice automatically derived set texts
acquired http://www.lonelyplanet.com well http://www.all-in-all.de, web page containing information history, accommodation facilities well activities Mecklenburg
Vorpommern, region northeast Germany. extracted verb/object pairs terms
Table 1 used conditional probability weight significance pairs. excursion,
dependencies extracted therefore considered computing lattice.
. Assuming
corpus size million words threshold used
car bike mutually similar, would clustered, i.e. car would get attribute startable
bike attribute needable. result thus lattice Figure 3 (right), car
bike extension one concept.







5. Evaluation
order evaluate approach need assess good automatically learned ontologies
reflect given domain. One possibility would compute many superconcept relations
automatically learned ontology correct. example done Hearst (1992)
Caraballo (1999). However, due fact approach, well many others (compare
Hindle, 1990; Pereira et al., 1993; Grefenstette, 1994), produce appropriate names
abstract concepts generated, seems difficult assess validity given superconcept
relation. Another possibility compute similar automatically learned concept hierarchy
respect given hierarchy domain question. crucial question
define similarity concept hierarchies. Though great amount work
AI community compute similarity trees (Zhang, Statman, & Shasha, 1992;
Goddard & Swart, 1996), concept lattices (Belohlavek, 2000), conceptual graphs (Maher, 1993;
Myaeng & Lopez-Lopez, 1992) (plain) graphs (Chartrand, Kubicki, & Schultz, 1998; Zhang,
Wang, & Shasha, 1996), clear similarity measures also translate concept

314

fiL EARNING C ONCEPT H IERARCHIES



EXT C ORPORA

USING

F ORMAL C ONCEPT NALYSIS

hierarchies. interesting work lines one presented Maedche Staab (2002)
ontologies compared along different levels: semiotic, syntactic pragmatic.
particular, authors present measures compare lexical taxonomic overlap two
ontologies. Furthermore, also present interesting study different subjects
asked model tourism ontology. resulting ontologies compared terms defined
similarity measures thus yielding agreement different subjects task modeling
ontology.
order formally define evaluation measures, introduce core ontology model line
ontological model presented Stumme et al. (2003):
Definition 6 (Core Ontology)
consisting (i) set concept identifiers, (ii)
core ontology structure
#
designated root element representing top element (iii) partial order fi
, called concept hierarchy taxonomy.
"

;

% "













/

sake notational simplicity adopt following convention: given ontology
, corresponding set concepts denoted partial order representing
concept hierarchy .
important mention approach presented here, terms directly identified
concepts, i.e. neglect fact terms polysemous. 6 Now, Lexical Recall (LR)
measured follows:7
two ontologies







$ $ $ $

Take example concept hierarchies
depicted Figure 4. example,

(fiff
Lexical Recall

fi( ff
.
order compare taxonomy two ontologies, use Semantic Cotopy (SC) presented Maedche Staab (2002). Semantic Cotopy concept defined set
super- subconcepts:













" $



/

follows illustrate definitions basis several example concept
hierarchies. Take instance concept hierarchies Figure 5. assume left concept
hierarchy automatically learned FCA approach concept hierarchy
right handcrafted one. Further, important point left ontology is,
terms arrangement leave nodes abstracting labels inner nodes,
perfectly learned concept hierarchy. thus reflected maximum similarity
ontologies. Semantic Cotopy concept vehicle right ontology Figure 5
example car, bike, two-wheeled vehicle, vehicle, object-to-rent Semantic Cotopy
driveable left ontology bike, car, rideable, driveable, rentable, bookable .
becomes thus already clear comparing cotopies concepts yield desired
results, i.e. maximum similarity concepts. Thus use modified version SC



/



/

6. principle, FCA able account polysemy terms. However, paper neglect aspect.
7. terms ordered hierarchically given need measure lexical precision.

315

fiC IMIANO , H OTHO , & TAAB

root

activity

object_to_rent

hotel

root
excursion

runable

apartment

offerable

startable

needable

attemptable, ...

bike

car

trip

vehicle

trip

twowheeled
vehicle

car

bike

hotel



Figure 4: Example automatically acquired concept hierarchy
reference concept hierarchy (right)

joinable

activity

rentable

hotel

driveable

trip



(fiff

(left) compared

root

bookable

excursion

apartment

rideable

excursion

apartment

object_to_rent

hotel

vehicle

trip

twowheeled
vehicle

car

apartment

car

bike

bike

Figure 5: Example perfectly learned concept hierarchy
ence concept hierarchy (right)




(

(left) compared refer-

Semantic Cotopy consider concepts common concept hierarchies
Semantic Cotopy
(compare Cimiano et al., 2004b, 2004c), i.e.





" $ $ $ /

using Common Semantic Cotopy thus exclude comparison concepts
runable, offerable, needable, activity, vehicle etc. one ontology. So,
concepts vehicle driveable identical ontologies
Common Semantic Cotopy
Figure 5, i.e. bike, car thus representing perfect overlap concepts,
certainly corresponds intuitions similarity concepts. However, lets
consider concept hierarchy Figure 6. common cotopy concept bike bike



/





316

/

fiL EARNING C ONCEPT H IERARCHIES



EXT C ORPORA

F ORMAL C ONCEPT NALYSIS

USING

root

activity

excursion

vehicle

trip

twowheeled
vehicle

root

excursion

trip

hotel

object_to_rent

hotel

apartment

car

apartment

car

bike

bike

Figure 6: Example trivial concept hierarchy
hierarchy (right)
(

(left) compared reference concept

concept hierarchies. fact, every leave concept left concept hierarchy maximum
overlap corresponding concept right ontology. certainly undesirable
fact leads high baselines comparing trivial concept hierarchies reference
standard (compare earlier results Cimiano et al., 2004b, 2004c). Thus, introduce
modification Semantic Cotopy excluding concept Common Semantic
Cotopy, i.e:


" $ $ $ /

maintains perfect overlap vehicle driveable concept hierarchies
Figure 5, yielding empty common cotopies leave concepts left ontology
Figure 6.
Now, according Maedche et al. Taxonomic Overlap (
) two ontologies

computed follows:





$


$ $


defined follows:






$$





fi
$
& $
317







fi

"
" * %

4$
4 $

fi 4 $
4$

fiC IMIANO , H OTHO , & TAAB



So,
gives similarity concepts ontologies comparing
gives similarity concept

respective semantic cotopies. contrast,
concept maximizes overlap respective semantic cotopies, i.e. makes
optimistic estimation assuming overlap happen show immediate
lexical surface (compare Maedche & Staab, 2002). Taxonomic Overlap

two ontologies calculated averaging taxonomic overlaps concepts
. case doesnt make sense calculate Semantic Cotopy concepts
ontologies represent leave nodes thus common semantic cotopies

empty. Thus, calculate Taxonomic Overlap two ontologies follows:








& ffff ( fi
$ &
Finally, want compute Taxonomic Overlap one direction, introduce precision, recall F-Measure calculating harmonic mean both:

"











$
$

$ $








!

4 $
4$















importance balancing recall precision clear discussion examples below. Lets consider example concept hierarchy

(
Figure 5. five concepts bookable, joinable, rentable, driveable rideable find
corresponding concept maximum Taxonomic Overlap
way
round concepts activity, object-to-rent, vehicle two-wheeled-vehicle ,






(
(
(

.





















concept hierarchy fiff shown Figure 7 precision still 100% reasons above, due fact rideable concept removed corresponding concept two-wheeled-vehicle. concept maximizing taxonomic similarity
two-wheeled-vehicle driveable+
+ + Taxonomic Overlap 0.5. recall

$











thus ff
ff
& F-Measure decreases







ff
.











5





5









concept hierarchy fiff Figure 8, additional
+ + + + concept planable introduced,

$





reduces precision fiff
recall stays obvi& ,





thus F-Measure fiff .
ously ff




)











)



becomes thus clear important measure precision recall automatically learned concept hierarchies balance harmonic mean
F-Measure. automatically
learned concept hierarchy
Figure
+
+
+
+
+!" + " 4+ precision
(fiff


& $

$ $
$
















&
fi( ff
, recall

$#

& &
&


fi
(
ff










thus F-Measure
# .
fi( ff



























318











fiL EARNING C ONCEPT H IERARCHIES



EXT C ORPORA

USING

F ORMAL C ONCEPT NALYSIS

root

activity

bookable

joinable

excursion

excursion

rentable

hotel

driveable

trip

vehicle

trip

twowheeled
vehicle

apartment

bike

object_to_rent

hotel

apartment

car

bike

car

Figure 7: Example concept hierarchy lower recall ( ff ) compared reference concept hierarchy

root

bookable

joinable

planable

driveable

trip

activity

rentable

hotel

excursion

apartment

vehicle

trip

excursion

rideable

object_to_rent

hotel

twowheeled
vehicle

car

apartment

car

bike

bike

Figure 8: Example concept hierarchy lower precision ( ff ) compared reference concept hierarchy

Figure 6 get
comparison, trivial concept hierarchy
! + +
+
(




& & $ (


(per definition),

.
(
(
important mention though toy examples difference respect
measures automatically learned concept hierarchy trivial concept hierfi( ff
archy big, considering real-world concept hierarchies much higher
(
number concepts clear F-Measures trivial concept hierarchies low
(see results Section 6).
Finally, also calculate harmonic mean lexical recall F-Measure follows:





















!







319















fiC IMIANO , H OTHO , & TAAB

No. Concepts
No. Leaves
Avg. Depth
Max. Depth
Max. Children
Avg. Children

Tourism
293
236
3.99
6
21
5.26

Finance
1223
861
4.57
13
33
3.5

Table 2: Ontology statistics
automatically learned concept hierarchy
, get example:
fi( ff





#


#

#

!





























6. Results
already mentioned above, evaluate approach two domains: tourism finance.
ontology tourism domain reference ontology comparison study presented
Maedche Staab (2002), modeled experienced ontology engineer. finance
ontology basically one developed within GETESS project (Staab et al., 1999);
designed purpose analyzing German texts Web, also English labels available
many concepts. Moreover, manually added English labels concepts whose
German label English counterpart result concepts ( 95%) finally
yielded also English label.8 tourism domain ontology consists 293 concepts,
finance domain ontology bigger total 1223 concepts 9 . Table 2 summarizes facts
concept hierarchies ontologies, total number concepts, total
number leave concepts, average maximal length paths leave root node
well average maximal number children concept (without considering leave
concepts).
domain-specific text collection tourism domain use texts acquired
mentioned web sites, i.e. http://www.lonelyplanet.com well http://www.all-in-all.de.
Furthermore, also used general corpus, British National Corpus 10 . Altogether, corpus
size 118 Million tokens. finance domain considered Reuters news 1987
185 Million tokens11 .
6.1 Comparison
best F-Measure tourism dataset

corresponding precision


(fiff







(fiff







(at threshold

recall
fi( ff

'











),
#
.








8. concepts direct counterpart language.
9. ontologies downloaded http://www.aifb.uni-karlsruhe.de/WBS/pci/TourismGoldStandard.isa
http://www.aifb.uni-karlsruhe.de/WBS/pci/FinanceGoldStandard.isa, respectively
10. http://www.natcorp.ox.ac.uk/
11. http://www.daviddlewis.com/resources/testcollections/reuters21578/

320

fiL EARNING C ONCEPT H IERARCHIES



EXT C ORPORA

USING

F ORMAL C ONCEPT NALYSIS



,
finance dataset, corresponding values


.

Lexical Recall obviously also decreases increasing threshold overall


F-Measure
also decreases inverse proportionally . Overall, best results terms F












finance
# tourism dataset

fi( ff reason results finance dataset slightly lower probably due
dataset.
technical nature domain (compared tourism domain) also fact
concept hierarchy learned bigger.
order evaluate FCA-based approach, compare hierarchical agglomerative
clustering Bi-Section-KMeans. Hierarchical agglomerative clustering (compare Duda, Hart, &
Stork, 2001) similarity-based bottom-up clustering technique beginning every
term forms cluster own. algorithm iterates step merges two
similar clusters still available, one arrives universal cluster contains terms.
experiments, use three different strategies calculate similarity clusters:
complete, average single-linkage. three strategies may based similarity
measure terms, i.e. cosine measure experiments, measure similarity
two non-trivial clusters different ways.


,
Single linkage defines similarity two clusters


considering closest pair two clusters. Complete linkage considers two

dissimilar terms, i.e.
. Finally, average-linkage computes average simi


. reader note
larity terms two clusters, i.e.
rather order fictive universal

prohibit merging clusters similarity
0
cluster root. corresponds exactly way FCA creates orders objects attributes
common. time complexity naive implementation agglomerative clustering ,
complete linkage
efficient implementations worst-time complexity
average linkas requires sorting similarity matrix (Day & Edelsbrunner, 1984),
age vectors length-normalized similarity measure cosine (see Manning &

Schuetze, 1999) O( ) single linkage (compare Sibson, 1973). 12
Bi-Section-KMeans defined outer loop around standard KMeans (Steinbach, Karypis,
& Kumar, 2000). order generate clusters, Bi-Section-KMeans repeatedly applies KMeans.
Bi-Section-KMeans initiated universal cluster containing terms. loops:
selects cluster largest variance 13 calls KMeans order split cluster

exactly two subclusters. loop repeated " times non-overlapping subclusters
generated. similarity measure also use cosine measure. complexity Bi-SectionKMeans . want generate complete cluster tree clusters complexity

thus O( ). Furthermore, Bi-Section-KMeans randomized algorithm, produce ten runs
average obtained results.
compare different approaches along lines measures described Section 5.


Figure 9 shows results terms F-Measure Lexical Recall domains
clustering approaches. particular, shows 8 data points corresponding thresholds
0.005, 0.01, 0.05, 0.1, 0.3, 0.5, 0.7 0.9. First seems important discuss baselines
approach. baselines approach trivial concept hierarchies
generated objects attributes common. trivial concept hierarchies generated
































fiff








fiff


fiff










'

4







12. See also http://www-csli.stanford.edu/ schuetze/completelink.html topic.
13. Though dont make use experiments, also possible select largest cluster splitting.

321

fiC IMIANO , H OTHO , & TAAB

Tourism
FCA
Complete Linkage
Average Linkage
Single Linkage
BiSection KMeans

0.5

FMeasure

0.4
0.3
0.2
0.1
0
0.36

0.38

0.4

0.42
0.44
Lexical Recall

0.46

0.48

0.5

Finance
FCA
Complete Linkage
Average Linkage
Single Linkage
BiSection KMeans

0.5

FMeasure

0.4
0.3
0.2
0.1
0
0.38

0.4

0.42

0.44
Lexical Recall

0.46

0.48

0.5

Figure 9: Results FCA-based approach: F-Measure Lexical Recall tourism
finance domains

threshold 0.7 datasets definition precision 100% recall close
0. baselines FCA agglomerative clustering algorithm same, BiSection-KMeans producing hierarchy random binary splits results higher F values.
trivial hierarchies represent absolute baseline sense algorithm could perform
worse. also seen Figure 9 FCA-based approach performs better
322

fiL EARNING C ONCEPT H IERARCHIES



EXT C ORPORA

USING

F ORMAL C ONCEPT NALYSIS

Tourism

0.7

FCA
Complete Linkage
Average Linkage
Single Linkage
BiSection KMeans

0.6

Recall

0.5
0.4
0.3
0.2
0.1
0
0.2

0.3

0.4

0.5

0.6
Precision

0.7

0.8

0.9

1

Finance

0.7

FCA
Complete Linkage
Average Linkage
Single Linkage
BiSection KMeans

0.6

Recall

0.5
0.4
0.3
0.2
0.1
0
0.2

0.3

0.4

0.5

0.6
Precision

0.7

0.8

0.9

1

Figure 10: Results FCA-based approach: Recall precision tourism finance
domains

approaches domains. observed Figure 10, showing recall precision,
main reason FCA-based approach yields higher recall
approaches, maintaining precision reasonable levels.
tourism domain, second best result achieved agglomerative algorithm
single-linkage strategy, followed ones average-linkage complete-linkage (in
323

fiC IMIANO , H OTHO , & TAAB

FCA
Complete Link
Average Link
Single Link
Bi-Sec. KMeans

P
29.33%
34.67%
35.21%
34.78%
32.85%

Tourism
R
F
65.49% 40.52%
31.98% 33.27%
31.45% 33.23%
28.71% 31.46%
28.71% 30.64%

F
44.69%
36.85%
36.55%
38.57%
36.42%

P
29.93%
24.56%
29.51%
25.23%
34.41%

Finance
R
F
37.05% 33.11%
25.65% 25.09%
24.65% 26.86%
22.44% 23..75%
21.77% 26.67%

F
38.85%
33.35%
32.92%
32.15%
32.77%

Table 3: Results comparison different clustering approaches
order), worst results obtained using Bi-Section-KMeans (compare Table 3).
finance domain, second best results achieved agglomerative algorithm
complete-linkage strategy followed one average-linkage strategy, Bi-SectionKMeans one single-linkage strategy (in order). Overall, valid claim
FCA outperforms clustering algorithms datasets. closer look Table 3,
reason becomes clear, i.e. FCA much higher recall approaches,
precision less comparable. due fact FCA generates higher number
concepts clustering algorithms thus increasing recall. Interestingly,
time precision concepts remains reasonably high thus also yielding higher F-Measures




.
interesting question thus big produced concept hierarchies are. Figure 11 shows
size concept hierarchies terms number concepts threshold parameter
different approaches domains. important explain number concepts
different different agglomerative algorithms well Bi-Section-KMeans principle

size always , number objects clustered. However,
objects similarity objects added directly fictive root element, size
concept hierarchies varies depending way similarities calculated. general,
sizes agglomerative divisive approaches similar, lower thresholds FCA yields
concept hierarchies much higher number concepts. threshold on, sizes
hierarchies produced different approaches quite similar. Table 4 shows results
approaches using thresholds 0.3 0.5. particular conclude FCA also
outperforms approaches domains producing similar number concepts.
general, determined statistical significance results presented paper FCA, contrast Bi-Section-K-Means, deterministic algorithm depend
random seeding. implementation agglomerative clustering algorithm also deterministic given certain order terms clustered. Thus, possibility calculate
significance results would produce different runs randomly leaving parts
corpus calculating statistical significance different runs. pursued
direction fact FCA performs better setting clear results Table
3.





324

fiL EARNING C ONCEPT H IERARCHIES

Threshold
FCA
Complete Link
Single Link
Average Link
Bi-Sec. KMeans



EXT C ORPORA

Tourism
0.3
0.5
37.53% 37.74%
36.85% 36.78%
29.84% 35.79%
35.36% 36.55%
31.50% 35.02%

USING

F ORMAL C ONCEPT NALYSIS

Finance
0.3
0.5
37.59% 34.92%
33.05% 30.37%
29.34% 27.79%
32.92% 31.30%
32.77% 31.38%

Table 4: Comparison results thresholds 0.3 0.5 terms F

Tourism
Finance
Tourism
Finance
Tourism
Finance
Tourism
Finance
Tourism
Finance

Conditional
PMI
FCA
44.69%
44.51%
38.85%
38.96%
Complete Linkage
36.85%
27.56%
33.35%
22.29%
Average Linkage
36.55%
26.90%
32.92%
23.78%
Single Linkage
38.57%
30.73%
32.15%
25.47%
Bi-Section-KMeans
36.42%
27.32%
32.77%
26.52%

Resnik
43.31%
38.87 %
23.52%
22.96%
23.93%
23.26%
28.63%
23.46%
29.33%
24.00%

Table 5: Comparison results different information measures terms F
6.2 Information Measures
already anticipated Section 4, different information measures also subject analysis. Table 5 presents best results different clustering approaches information measures. concluded results using PMI Resnik measures produces worse
results tourism dataset, yielding slightly better results finance dataset
FCA-based approach. also interesting observe compared FCA-based approach,
clustering approaches much sensitive information measure used. Overall,
use Conditional information measure seems reasonable choice.
6.3 Smoothing
applied smoothing method described section 4 datasets order find
far clustering terms improves results FCA-based approach. information
measure use experiment conditional probability performs reasonably well
325

fiC IMIANO , H OTHO , & TAAB

Tourism

2200

FCA
Complete Linkage
Average Linkage
Single Linkage
BiSectionKMeans

2000
1800
1600
1400
1200
1000
800
600
400
200
0

0

0.1

0.2

0.3

0.4

0.5
0.6
threshold

0.7

0.8

0.9

1

0.9

1

Finance

7000

FCA
Complete Linkage
Average Linkage
Single Linkage
BiSectionKMeans

6000
5000
4000
3000
2000
1000
0

0

0.1

0.2

0.3

0.4

0.5
0.6
threshold

0.7

0.8

Figure 11: Sizes concept hierarchies different approaches tourism finance
domains: number concepts threshold
shown Section 6.2. particular used following similarity measures: cosine measure, Jaccard coefficient, L1 norm well Jensen-Shannon Skew divergences
(compare Lee, 1999). Table 6 shows impact smoothing technique terms number
object/attribute terms added dataset. Skew Divergence excluded
326

fiL EARNING C ONCEPT H IERARCHIES

Baseline
525912
577607

Tourism
Finance



Jaccard
531041 (+ 5129)
599691 (+ 22084)

EXT C ORPORA

USING

Cosine
534709 (+ 8797)
634954 (+ 57347)

F ORMAL C ONCEPT NALYSIS

L1
530695 (+ 4783)
584821 (+ 7214)

JS
528892 (+ 2980)
583526 (+ 5919)

Table 6: Impact Smoothing Technique terms new object/attribute pairs
Tourism
Finance

Baseline
44.69%
38.85%

Jaccard
39.54%
38.63%

Cosine
41.81%
36.69%

L1
41.59%
38.48%

JS
42.35%
38.66%

Table 7: Results Smoothing terms F-Measure F
yield mutually similar terms. observed smoothing mutual similarity based
cosine measure produces previously unseen object/attribute pairs, followed
Jaccard, L1 Jensen-Shannon divergence (in order). Table 7 shows results different similarity measures. tables appendix list mutually similar terms different
domains similarity measures. results show smoothing technique actually yields
worse results domains similarity measures used.
6.4 Discussion
shown FCA-based approach reasonable alternative similarity-based cluster

measure defined
ing approaches, even yielding better results datasets regard
Section 5. main reason concept hierarchies produced FCA yield
higher recall due higher number concepts, maintaining precision relatively high
time. Furthermore, shown conditional probability performs reasonably
well information measure compared elaborate measures PMI one
used Resnik (1997). Unfortunately, applying smoothing method based clustering mutually
similar terms improve quality automatically learned concept hierarchies. Table
8 highlights fact every approach benefits drawbacks. main benefit
using FCA one hand datasets performed better algorithms thus
producing better concept hierarchies hand, generate clusters - formal
concepts specific - also provides intensional description clusters thus
contributing better understanding ontology engineer (compare Figure 2 (left)). contrast,
similarity-based methods provide level traceability due fact
numerical value similarity two high-dimensional vectors drives clustering
process thus remains opaque engineer. agglomerative divisive approach
different respect agglomerative paradigm, initial merges small-size clusters
correspond high degrees similarity thus understandable, divisive
paradigm splitting clusters aims minimizing overall cluster variance thus harder
trace.
clear disadvantage FCA size lattice get exponential size
context worst case thus resulting exponential time complexity compared
agglomerative clustering Bi-Section-KMeans, respectively.









327

fiC IMIANO , H OTHO , & TAAB

FCA
Agglomerative Clustering:
Complete Linkage
Average Linkage
Single Linkage
Bi-Section-KMeans

Effectiveness (F)
Tourism Finance
44.69% 38.85%
36.85%
36.55%
38.57%
36.42%

33.35%
32.92%
32.15%
32.77%

Worst Case
Time Complexity









Traceability
Good

Size
Hierarchies
Large

Fair

Small

Weak

Small

Table 8: Trade-offs different taxonomy construction methods
implementation FCA used concepts tool Christian Lindig 14 , basically
implements Ganters Next Closure algorithm (Ganter & Reuter, 1991; Ganter & Wille, 1999)
extension Aloui computing covering relation described (Godin, Missaoui, &
Alaoui, 1995). Figure 12 shows number seconds number attribute/object pairs
took FCA compute lattice formal concepts compared time needed naive
implementation agglomerative algorithm complete linkage. seen
FCA performs quite efficiently compared agglomerative clustering algorithm. due
fact object/attribute matrix sparsely populated. observations already
made before. Godin et al. (1995) example suspect lattice size linearly increases
number attributes per object. Lindig (2000) presents empirical results analyzing contexts
fill ratio 0.1 comes conclusion lattice size grows quadratically respect
size incidence relation . Similar findings also reported Carpineto Romano
(1996).
Figure 13 shows number attributes terms rank, rank natural
number indicating position word list ordered decreasing term frequencies.
appreciated amount (non-zero) attributes distributed Zipfian way (compare
Zipf, 1932), i.e. small number objects lot attributes, large number
few. particular, tourism domain, term attributes person
3077 attributes, average term approx. 178 attributes. total number attributes
considered 9738, conclude object/attribute matrix contains almost 98% zero
values. finance domain term highest rank percent 2870 attributes,
average ca. 202 attributes. total number attributes 21542, state
case 99% matrix populated zero-values thus much sparser
ones considered Lindig (2000). figures explain FCA performs efficiently
experiments. Concluding, though worst-time complexity exponential, FCA much
efficient agglomerative clustering algorithm setting.

!



7. Related Work
section, discuss work related automatic acquisition taxonomies. main
paradigms learning taxonomic relations exploited literature one hand clustering
14. http://www.st.cs.uni-sb.de/ lindig/src/concepts.html

328

fiL EARNING C ONCEPT H IERARCHIES

EXT C ORPORA



USING

F ORMAL C ONCEPT NALYSIS

Tourism
200
FCA
Complete Linkage

180
160

time (sec.)

140
120
100
80
60
40
20
0

0

2000

4000

6000

8000
10000 12000
object/attribute pairs

14000

16000

18000

Finance
6000
FCA
Complete Linkage
5000

time (sec.)

4000

3000

2000

1000

0

0

10000

20000

30000

40000 50000 60000
object/attribute pairs

70000

80000

90000

Figure 12: Comparison time complexities FCA agglomerative clustering
tourism finance domains
approaches based distributional hypothesis (Harris, 1968) hand approaches
based matching lexico-syntactic patterns corpus convey certain relation.
One first works clustering terms one Hindle (1990), nouns
grouped classes according extent appear similar verb frames. particular, uses verbs nouns appear subjects objects contextual attributes. Further,
also introduces notion reciprocal similarity, equivalent mutual similarity.
Pereira et al. (1993) also present top-down clustering approach build unlabeled hierarchy
nouns. present entropy-based evaluation approach, also show results
329

fiC IMIANO , H OTHO , & TAAB

3500
tourism
finance
3000

no. features

2500
2000
1500
1000
500
0

0

100

200

300

400

500

600

700

rank

Figure 13: Distribution Features: number (non-zero) features word rank



linguistic decision task: i.e. two verbs likely take given noun
object. Grefenstette also addressed automatic construction thesauri (Grefenstette, 1994).
presents results different various domains. Further, also compares window-based
syntactic approaches, finding results depend frequency words question.
particular, shows frequent words, syntactic-based approaches better,
rare words window-based approaches preferable (Grefenstette, 1992). work Faure
Nedellec (1998) also based distributional hypothesis; present iterative bottomup clustering approach nouns appearing similar contexts. step, cluster two
similar extents argument position two verbs. Interestingly, way
yield concept hierarchy, also ontologically generalized subcategorization frames verbs.
method semi-automatic involves users validation clusters created
step. authors present results system terms cluster accuracy dependency
percentage corpus used. Caraballo (1999) also uses clustering methods derive unlabeled hierarchy nouns using data conjunctions nouns appositions collected
Wall Street Journal corpus. Interestingly, second step also labels abstract concepts
hierarchy considering Hearst patterns (see below) children concept
question appear hyponyms. frequent hypernym chosen order label
concept. step also compresses produced ontological tree eliminating internal
nodes without label. final ontological tree evaluated presenting random choice
clusters corresponding hypernym three human judges validation. Bisson et al.
(2000) present interesting framework corresponding workbench - MoK - allowing users
design conceptual clustering methods assist ontology building task. particular
use bottom-up clustering compare different similarity measures well different pruning
parameters.
earlier work used collocation statistics learn relations terms using modification association rules extraction algorithm (Maedche & Staab, 2000). However,
relations inherently taxonomic work described paper di330

fiL EARNING C ONCEPT H IERARCHIES



EXT C ORPORA

USING

F ORMAL C ONCEPT NALYSIS

rectly compared it. Maedche, Pekar, Staab (2002) examined different supervised techniques
based collocations find appropriate hypernym unknown term, reaching accuracy
around 15% using combination tree ascending algorithm -Nearest-Neighbors well
Skew Divergence similarity measure. results neither comparable task
hand. Recently, Reinberger Spyns (2005) presented application clustering techniques biomedical domain. evaluate clusters directly comparing UMLS
thesaurus. results low (3-17% precision depending corpus clustering technique) comparable results obtained comparing clusters directly
gold standards reported paper though.
Furthermore, quite lot work related use linguistic patterns discover
certain ontological relations text. Hearsts seminal approach aimed discovering taxonomic
relations electronic dictionaries (Hearst, 1992). precision isa-relations learned
%
#
# (57.55%) measured WordNet gold standard. Hearsts idea

reapplied different researchers either slight variations patterns used (Iwanska et al.,
2000), specific domains (Ahmad et al., 2003), acquire knowledge anaphora resolution
(Poesio, Ishikawa, im Walde, & Viera, 2002), discover kinds semantic relations
part-of relations (Charniak & Berland, 1999) causation relations (Girju & Moldovan, 2002).
approaches Hearst others characterized (relatively) high precision
sense quality learned relations high. However, approaches suffer
low recall due fact patterns rare. possible solution
problem, approach Cimiano, Pivk, Schmidt-Thieme, Staab (2004, 2005) Hearst
patterns matched corpus Web well explicit information derived
resources heuristics combined yielding better results compared considering one
source evidence task learning superconcept relations. general, overcome data
sparseness problems, researchers resorting WWW example Markert,
Modjeska, Nissim (2003). approach, Hearst patterns searched WWW
using Google API order acquire background knowledge anaphora resolution. Agirre,
Ansa, Hovy, Martinez (2000), download related texts Web enrich given ontology.
Cimiano, Handschuh, Staab (2004a) well Cimiano, Ladwig, Staab (2005) used
Google API match Hearst-like patterns Web order (i) find best concept
unknown instance well (ii) appropriate superconcept certain concept given
ontology (Cimiano & Staab, 2004).
Velardi, Fabriani, Missikoff (2001) present OntoLearn system discovers i)
domain concepts relevant certain domain, i.e. relevant terminology, ii) named entities, iii)
vertical (is-a taxonomic) relations well iv) certain relations concepts based
specific syntactic relations. approach vertical relation established term
term , i.e. is-a() , ), gained ) stripping latters prenominal
modifiers adjectives modifying nouns. Thus, vertical relation example established term international credit card term credit card, i.e. is-a(international
credit card,credit card). paper (Velardi, Navigli, Cuchiarelli, & Neri, 2005), main
focus task word sense disambiguation, i.e. finding correct sense word
respect general ontology lexical database. particular, present novel algorithm called
SSI relying structure general ontology purpose. Furthermore, include
explanation component users consisting gloss generation component generates
definitions terms found relevant certain domain.
331

fiC IMIANO , H OTHO , & TAAB

Sanderson Croft (1999) describe interesting approach automatically derive hierarchy
considering document certain term appears context. particular, present
document-based definition subsumption according certain term special
term also appears documents appears.
Formal Concept Analysis applied many tasks within Natural Language Processing.
Priss (2004) example, mentions several possible applications FCA analyzing linguistic
structures, lexical semantics lexical tuning. Sporleder (2002) Petersen (2002) apply FCA
yield concise lexical inheritance hierarchies regard morphological features
numerus, gender etc. Basili, Pazienza, Vindigni (1997) apply FCA task learning
subcategorization frames corpora. However, knowledge applied
acquisition domain concept hierarchies approach presented paper.

8. Conclusion
presented novel approach automatically acquire concept hierarchies domainspecific texts. addition, compared approach hierarchical agglomerative clustering algorithm well Bi-Section-KMeans found approach produces better
results two datasets considered. examined different information measures
weight significance attribute/object pair concluded conditional probability
works well compared elaborate information measures. also analyzed
impact smoothing technique order cope data sparseness found doesnt
improve results FCA-based approach. Further, highlighted advantages disadvantages three approaches.
Though approach fully automatic, important mention believe
fully automatic ontology construction without user involvement. sense, future
explore users involved process presenting him/her ontological relations
validation way necessary user feedback kept minimum.
hand, involving users semi-automatic way necessary clarify good certain
approach works per se. research presented paper aim. Furthermore,
also proposed systematic way evaluating ontologies comparing certain humanmodeled ontology. sense aim also establish baseline research.

Acknowledgments
would like thank colleagues feedback comments, particular Gerd Stumme
clarifying FCA-related questions. would also like thank Johanna Volker comments first version well proof-reading final version paper. errors
course own. would also like acknowledge reviewers Journal Artificial
Intelligence Research well ones earlier workshops (ATEM04, FGML04) conferences (LREC04, ECAI04) work presented valuable comments. Philipp
Cimiano currently supported Dot.Kom project (http://www.dot-kom.org), sponsored
EC part framework V, (grant IST-2001-34038) well SmartWeb project
(http://smartweb.dfki.de), funded German Ministry Education Research.

332

fiL EARNING C ONCEPT H IERARCHIES



EXT C ORPORA

USING

F ORMAL C ONCEPT NALYSIS

Appendix A. Mutually Similar Terms
Jaccard
(art exhibition,thing)
(autumn,spring)
(balcony,menu)
(ballroom,theatre)
(banquet,ship)
(bar,pub)
(basilica,hair dryer)
(beach,swimming pool)
(billiard,sauna)
(bus,car)
(caravan,tree)
(casino,date)
(cinema,fitness studio)
(city,town)
(conference,seminar)
(conference room,volleyball field)
(cure,washing machine)
(day tour,place)
(distance,radio)
(exhibition,price list)
(ferry,telephone)
(gallery,shop)
(golf course,promenade)
(holiday,service)
(journey,terrace)
(kiosk,time interval)
(law,presentation)
(lounge,park)
(motel,port)
(nature reserve,parking lot)
(night,tourist)
(region,situation)

Cosine
(agreement,contract)
(animal,plant)
(art exhibition,washing machine)
(basilica,hair dryer)
(boat,ship)
(cabaret,email)
(cheque,pension)
(city,town)
(conference room,volleyball field)
(golf course,promenade)
(group,party)
(inn,yacht)
(journey,meal)
(kiosk,tennis court)
(law,view)
(library,museum)
(money,thing)
(motel,port)
(pilgrimage,whirlpool)
(sauna,swimming)

L1 norm
(day,time)
(golf course,promenade)
(group,person)

Jensen-Shannon divergence
(group,person)

Table 9: Mutually Similar Terms tourism domain

333

fiC IMIANO , H OTHO , & TAAB

Jaccard
(action,average)
(activity,downturn)
(addition,liquidity)
(afternoon,key)
(agency,purchase)
(agreement,push)
(alliance,project team)
(allocation,success)
(analysis,negotiation)
(animal,basis)
(anomaly,regression)
(archives,futures)
(area,profitability)
(argument,dismantling)
(arrangement,capital market)
(arranger,update)
(assembly,price decline)
(assurance,telephone number)
(automobile,oil)
(backer,trade partner)
(balance sheet,person)
(balancing,countenance)
(behaviour,business partnership)
(bike,moment)
(billing,grade)
(board,spectrum)
(board chairman,statement)
(bonus,nationality)
(bonus share,cassette)
(branch office,size)
(broker,competition)
(budget,regulation)
(builder,devices)
(building,vehicle)
(business volume,outlook)
(business year,quota)
(capital,material costs)
(capital increase,stock split)
(capital stock,profit distribution)
(caravan,seminar)
(cent,point)
(chance,hope)
(change,subsidiary)
(charge,suspicion)
(chip,woman)
(circle,direction)
(clock,ratio)
(code,insurance company)
(comment,foundation)
(commission,expansion)
(communication,radio)
(community,radius)
(company profile,intangible)
(compensation,participation)
(complaint,petition)
(computer,cooperation)
(conference,height)
(confidentiality,dollar)
(consultant,survey)
(contact,hint)
(contract,copyright)
(control,data center)
(conversation,output)
(copper,replacement)
(corporation,liabilities)
(cost,equity capital)
(course,step)
(court,district court)
(credit,disbursement)
(credit agreement,overview)
(currency,faith)
(curve,graph)
(decision,maximum)
(deficit,negative)
(diagram,support)
(difference,elimination)

Cosine
(access,advantage)
(acquisition,merger)
(action,measure)
(administration costs,treasury stock)
(advice,assurance)
(allocation,length)
(amount,total)
(analysis,component)
(area,region)
(arrangement,regime)
(assembly,chamber)
(assessment,receipt)
(backer,gamble)
(balancing,matrix)
(bank,company)
(barometer,market price)
(bid,offer)
(bond,stock)
(bonus share,cassette)
(boom,turnaround)
(bull market,tool)
(business deal,graph)
(buy,stop)
(capital stock,profit distribution)
(caravan,software company)
(cent,point)
(change,increase)
(commission,committee)
(company profile,intangible)
(complaint,request)
(controller,designer)
(copper,share index)
(copy,push)
(credit,loan)
(credit agreement,credit line)
(currency,dollar)
(decision,plan)
(detail,test)
(diagram,support)
(dimension,surcharge)
(discussion,negotiation)
(diversification,milestone)
(do,email)
(document,letter)
(effect,impact)
(equity fund,origin)
(evaluation,examination)
(example,hint)
(first,meter)
(forecast,stock market activity)
(function,profile)
(gesture,input)
(guarantee,solution)
(half,quarter)
(increment,rearrangement)
(information,trading company)
(insurance,percentage)
(interest rate,tariff)
(man,woman)
(maximum,supervision)
(meeting,talk)
(merchant,perspective)
(month,week)
(press conference,seminar)
(price,rate)
(productivity,traffic)
(profit,volume)
(share price,stock market)
(stock broker,theory)

L1 norm
(archives,futures)
(assurance,telephone number)
(balancing,countenance)
(cent,point)
(creation,experience)
(government,person)
(loss,profit)
(month,year)

Jensen-Shannon divergence
(cent,point)
(government,person)
(month,year)

Table 10: Mutually Similar Terms finance domain

334

fiL EARNING C ONCEPT H IERARCHIES

Jaccard
(disability insurance,pension)
(discrimination,union)
(diversification,request)
(do,email)
(effect,help)
(employer,insurance)
(energy,test)
(equity fund,origin)
(evening,purpose)
(event,manager)
(examination,registration)
(example,source)
(exchange,volume)
(exchange risk,interest rate)
(experience,questionnaire)
(expertise,period)
(faculty,sales contract)
(fair,product)
(flop,type)
(forecast,stock market activity)
(fusion,profit zone)
(gamble,thing)
(good,service)
(government bond,life insurance)
(happiness,question)
(hold,shareholder)
(hour,pay)
(house,model)
(idea,solution)
(impact,matter)
(improvement,situation)
(index,wholesale)
(information,trading company)
(initiation,middle)
(input,traffic)
(institute,organization)
(investment,productivity)
(knowledge,tradition)
(label,title)
(letter,reception)
(level,video)
(license,reward)
(loan,project)
(location,process)
(loss,profit)
(man,trainee)
(margin,software company)
(market,warranty)
(market access,name)
(matrix,newspaper)
(meeting,oscillation)
(meter,share)
(method,technology)
(milestone,state)
(month,year)
(mouse,option)
(multiplication,transfer)
(noon,press conference)
(occasion,talk)
(opinion,rivalry)
(personnel,resource)
(picture,surcharge)
(plane,tool)
(police,punishment)
(profession,writer)
(property,qualification)
(provision,revenue)
(requirement,rule)
(risk,trust)
(sales revenue,validity)
(savings bank,time)
(segment,series)
(show,team)
(speech,winter)
(stock broker,theory)
(supplier,train)
(tariff,treasury stock)
(weekend,wisdom)



EXT C ORPORA

Cosine

L1 norm

USING

F ORMAL C ONCEPT NALYSIS

Jensen-Shannon divergence

Table 11: Mutually Similar Terms finance domain (Contd)

335

fiC IMIANO , H OTHO , & TAAB

References
Agirre, E., Ansa, O., Hovy, E., & Martinez, D. (2000). Enriching large ontologies using
WWW. Proceedings ECAI Ontology Learning Workshop.
Ahmad, K., Tariq, M., Vrusias, B., & Handy, C. (2003). Corpus-based thesaurus construction
image retrieval specialist domains. Proceedings 25th European Conference
Advances Information Retrieval (ECIR), pp. 502510.
Basili, R., Pazienza, M., & Vindigni, M. (1997). Corpus-driven unsupervised learning verb
subcategorization frames. Proceedings 5th Congress Italian Association
Artificial Intelligence (AI*IA97).
Belohlavek, R. (2000). Similarity relations concept lattices. Journal Logic Computation,
10(6), 823845.
Bisson, G., Nedellec, C., & Canamero, L. (2000). Designing clustering methods ontology building - MoK workbench. Proceedings ECAI Ontology Learning Workshop, pp.
1319.
Bloehdorn, S., & Hotho, A. (2004). Text classification boosting weak learners based terms
concepts. Proceedings 4th IEEE International Conference Data Mining
(ICDM), pp. 331334.
Brewster, C., Ciravegna, F., & Wilks, Y. (2003). Background foreground knowledge dynamic
ontology construction. Proceedings SIGIR Semantic Web Workshop.
Caraballo, S. (1999). Automatic construction hypernym-labeled noun hierarchy text.
Proceedings 37th Annual Meeting Association Computational Linguistics
(ACL), pp. 120126.
Carpineto, C., & Romano, G. (1996). lattice conceptual clustering system application
browsing retrieval. Machine Learning, 24, 95122.
Charniak, E., & Berland, M. (1999). Finding parts large corpora. Proceedings 37th
Annual Meeting Association Computational Linguistics (ACL), pp. 5764.
Chartrand, G., Kubicki, G., & Schultz, M. (1998). Graph similarity distance graphs. Aequationes Mathematicae, 55(1-2), 129145.
Cimiano, P. (2003). Ontology-driven discourse analysis GenIE. Proceedings 8th International Conference Applications Natural Language Information Systems, pp. 7790.
Cimiano, P., Handschuh, S., & Staab, S. (2004a). Towards self-annotating web. Proceedings
13th World Wide Web Conference, pp. 462471.
Cimiano, P., Hotho, A., & Staab, S. (2004b). Clustering ontologies text. Proceedings
4th International Conference Language Resources Evaluation (LREC), pp. 1721
1724.
Cimiano, P., Hotho, A., & Staab, S. (2004c). Comparing conceptual, divisive agglomerative
clustering learning taxonomies text. Proceedings European Conference
Artificial Intelligence (ECAI), pp. 435439.
Cimiano, P., Ladwig, G., & Staab, S. (2005). Gimme context: Context-driven automatic semantic annotation C-PANKOW. Proceedings 14th World Wide Web Conference.
336

fiL EARNING C ONCEPT H IERARCHIES



EXT C ORPORA

USING

F ORMAL C ONCEPT NALYSIS

Cimiano, P., Pivk, A., Schmidt-Thieme, L., & Staab, S. (2004). Learning taxonomic relations
heterogeneous sources. Proceedings ECAI 2004 Ontology Learning Population
Workshop.
Cimiano, P., Pivk, A., Schmidt-Thieme, L., & Staab, S. (2005). Learning taxonomic relations
heterogeneous evidence. Buitelaar, P., Cimiano, P., & Magnini, B. (Eds.), Ontology Learning Text: Methods, Applications Evaluation. IOS Press. appear.
Cimiano, P., S.Staab, & Tane, J. (2003). Automatic acquisition taxonomies text: FCA
meets NLP. Proceedings PKDD/ECML03 International Workshop Adaptive
Text Extraction Mining (ATEM), pp. 1017.
Cimiano, P., & Staab, S. (2004). Learning googling. SIGKDD Explorations, 6(2), 2434.
Cimiano, P., Staab, S., & Tane, J. (2003). Deriving concept hierarchies text smooth formal
concept analysis. Proceedings GI Workshop Lehren Lernen - Wissen - Adaptivit
(LLWA), pp. 7279.
Day, W., & Edelsbrunner, H. (1984). Efficient algorithms agglomerative hierarchical clustering
methods. Journal Classification, 1, 724.
Duda, R. O., Hart, P. E., & Stork, D. G. (2001). Pattern Classification. John Wiley & Sons, Inc.
Faure, D., & Nedellec, C. (1998). corpus-based conceptual clustering method verb frames
ontology. Velardi, P. (Ed.), Proceedings LREC Workshop Adapting lexical
corpus resources sublanguages applications, pp. 512.
Ganter, B., & Reuter, K. (1991). Finding closed sets: general approach. Order, 8, 283290.
Ganter, B., & Wille, R. (1999). Formal Concept Analysis Mathematical Foundations. Springer
Verlag.
Girju, R., & Moldovan, M. (2002). Text mining causal relations. Proceedings FLAIRS
Conference, pp. 360364.
Goddard, W., & Swart, H. (1996). Distance graphs edge operations. Discrete Mathematics, 161, 121132.
Godin, R., Missaoui, R., & Alaoui, H. (1995). Incremental concept formation algorithms based
galois (concept) lattices. Computational Intelligence, 11(2), 246267.
Grefenstette, G. (1994). Explorations Automatic Thesaurus Construction. Kluwer.
Grefenstette, G. (1992). Evaluation techniques automatic semantic extraction: Comparing syntactic window-based approaches. Proceedings Workshop Acquisition Lexical Knowledge Text.
Harris, Z. (1968). Mathematical Structures Language. Wiley.
Hearst, M. (1992). Automatic acquisition hyponyms large text corpora. Proceedings
14th International Conference Computational Linguistics (COLING), pp. 539545.
Hindle, D. (1990). Noun classification predicate-argument structures. Proceedings
Annual Meeting Association Computational Linguistics (ACL), pp. 268275.
Hotho, A., Staab, S., & Stumme, G. (2003). Ontologies improve text document clustering.
Prodeedings IEEE International Conference Data Mining (ICDM), pp. 541544.
337

fiC IMIANO , H OTHO , & TAAB

Iwanska, L., Mata, N., & Kruger, K. (2000). Fully automatic acquisition taxonomic knowledge
large corpora texts. Iwanksa, L., & Shapiro, S. (Eds.), Natural Language Processing Knowledge Processing, pp. 335345. MIT/AAAI Press.
Lee, L. (1999). Measures distributional similarity. 37th Annual Meeting Association
Computational Linguistics (ACL), pp. 2532.
Lindig, C. (2000). Fast concept analysis. Stumme, G. (Ed.), Proceedings International
Conference Conceptual Structures (ICCS). Shaker Verlag, Aachen, Germany.
Maedche, A., Pekar, V., & Staab, S. (2002). Ontology learning part one - discovering taxonomic
relations web. Proceedings Web Intelligence conference, pp. 301322.
Springer Verlag.
Maedche, A., & Staab, S. (2002). Measuring similarity ontologies. Proceedings
European Conference Knowledge Engineering Knowledge Management (EKAW), pp.
251263. Springer Verlag.
Maedche, A., & Staab, S. (2000). Discovering conceptual relations text. Horn, W. (Ed.),
Proceedings 14th European Conference Artificial Intelligence (ECAI).
Maher, P. (1993). similarity measure conceptual graphs. Intelligent Systems, 8, 819837.
Manning, C., & Schuetze, H. (1999). Foundations Statistical Language Processing. MIT Press.
Markert, K., Modjeska, N., & Nissim, M. (2003). Using web nominal anaphora resolution.
EACL Workshop Computational Treatment Anaphora.
Myaeng, S., & Lopez-Lopez, A. (1992). Conceptual graph matching: flexible algorithm
experiments. Experimental Theoretical Artificial Intelligence, 4, 107126.
Pereira, F., Tishby, N., & Lee, L. (1993). Distributional clustering english words. Proceedings
31st Annual Meeting Association Computational Linguistics (ACL), pp. 183
190.
Petersen, W. (2002). set-theoretical approach induction inheritance hierarchies. Electronic Notes Theoretical Computer Science, 51.
Poesio, M., Ishikawa, T., im Walde, S. S., & Viera, R. (2002). Acquiring lexical knowledge
anaphora resolution. Proceedings 3rd Conference Language Resources Evaluation (LREC).
Priss, U. (2004). Linguistic applications formal concept analysis. Stumme, G., & Wille, R.
(Eds.), Formal Concept Analysis - State Art. Springer.
Reinberger, M.-L., & Spyns, P. (2005). Unsupervised text mining learning dogma-inspired
ontologies. Buitelaar, P., Cimiano, P., & Magnini, B. (Eds.), Ontology Learning Text:
Methods, Evaluation Applications. IOS Press. appear.
Resnik, P. (1997). Selectional preference sense disambiguation. Proceedings ACL
SIGLEX Workshop Tagging Text Lexical Semantics: Why, What, How?
Sanderson, M., & Croft, B. (1999). Deriving concept hierarchies text. Research Development Information Retrieval, pp. 206213.
Schmid, H. (1994). Probabilistic part-of-speech tagging using decision trees. Proceedings
International Conference New Methods Language Processing.
338

fiL EARNING C ONCEPT H IERARCHIES



EXT C ORPORA

USING

F ORMAL C ONCEPT NALYSIS

Schmid, H. (2000). Lopar: Design implementation. Arbeitspapiere des Sonderforschungsbereiches 340, No. 149.
Sibson, R. (1973). SLINK: optimally efficient algorithm single-link cluster method.
Computer Journal, 16(1), 3034.
Sporleder, C. (2002). galois lattice based approach lexical inheritance hierarchy learning.
Proceedings ECAI Workshop Machine Learning Natural Language Processing
Ontology Engineering (OLT 2002).
Staab, S., Braun, C., Bruder, I., Dusterhoft, A., Heuer, A., Klettke, M., Neumann, G., Prager, B.,
Pretzel, J., Schnurr, H.-P., Studer, R., Uszkoreit, H., & Wrenger, B. (1999). Getess - searching web exploiting german texts. Proceedings 3rd Workshop Cooperative
Information Agents, pp. 113124. Springer Verlag.
Steinbach, M., Karypis, G., & Kumar, V. (2000). comparison document clustering techniques.
KDD Workshop Text Mining.
Stumme, G., Ehrig, M., Handschuh, S., Hotho, A., Maedche, A., Motik, B., Oberle, D., Schmitz, C.,
Staab, S., Stojanovic, L., Stojanovic, N., Studer, R., Sure, Y., Volz, R., & Zacharias, V. (2003).
karlsruhe view ontologies. Tech. rep., University Karlsruhe, Institute AIFB.
Velardi, P., Fabriani, P., & Missikoff, M. (2001). Using text processing techniques automatically enrich domain ontology. Proceedings International Conference Formal
Ontology Information Systems (FOIS), pp. 270284.
Velardi, P., Navigli, R., Cuchiarelli, A., & Neri, F. (2005). Evaluation ontolearn, methodology
automatic population domain ontologies. Buitelaar, P., Cimiano, P., & Magnini, B.
(Eds.), Ontology Learning Text: Methods, Evaluation Applications. IOS Press.
appear.
Voorhees, E. (1994). Query expansion using lexical-semantic relations. Proceedings 17th
Annual International ACM SIGIR Conference Research Development Information
Retrieval, pp. 6169.
Zhang, K., Statman, R., & Shasha, D. (1992). editing distance unordered labeled
trees. Information Processing Letters, 42(3), 133139.
Zhang, K., Wang, J., & Shasha, D. (1996). editing distance undirected acyclic
graphs. International Journal Foundations Computer Science, 7(1), 4357.
Zipf, G. (1932). Selective Studies Principle Relative Frequency Language. Cambridge.

339

fiJournal Artificial Intelligence Research 24 (2005) 81-108

Submitted 12/04; published 07/05

Risk-Sensitive Reinforcement Learning Applied Control
Constraints
Peter Geibel

pgeibel@uos.de

Institute Cognitive Science, AI Group
University Osnabruck, Germany

Fritz Wysotzki

wysotzki@cs.tu-berlin.de

Faculty Electrical Engineering Computer Science, AI Group
TU Berlin, Germany

Abstract
paper, consider Markov Decision Processes (MDPs) error states. Error
states states entering undesirable dangerous. define risk
respect policy probability entering state policy
pursued. consider problem finding good policies whose risk smaller
user-specified threshold, formalize constrained MDP two criteria.
first criterion corresponds value function originally given. show
risk formulated second criterion function based cumulative return,
whose definition independent original value function. present model free,
heuristic reinforcement learning algorithm aims finding good deterministic policies.
based weighting original value function risk. weight parameter
adapted order find feasible solution constrained problem good
performance respect value function. algorithm successfully applied
control feed tank stochastic inflows lies upstream distillation
column. control task originally formulated optimal control problem
chance constraints, solved certain assumptions model obtain
optimal solution. power learning algorithm used even
restrictive assumptions relaxed.

1. Introduction
Reinforcement Learning, research area, provides range techniques applicable difficult nonlinear stochastic control problems (see e.g. Sutton & Barto, 1998;
Bertsekas & Tsitsiklis, 1996). reinforcement learning (RL) agent considered
learns control process. agent able perceive state process,
acts order maximize cumulative return based real valued reward
signal. Often, experiences process used improve agents policy instead
previously given analytical model.
notion risk RL related fact, even optimal policy may perform
poorly cases due stochastic nature problem. risk-sensitive RL
approaches concerned variance return, worst outcomes,
(e.g. Coraluppi & Marcus, 1999; Heger, 1994; Neuneier & Mihatsch, 1999), see also
discussion section 3. take alternative view risk defined Geibel (2001)
concerned variability return, occurrence errors
c
2005
AI Access Foundation. rights reserved.

fiGeibel & Wysotzki

undesirable states underlying Markov Decision Process (MDP). means
address different class problems compared approaches referring variability
return.
paper, consider constrained MDPs two criteria usual value function risk second value function. value optimized risk
must remain specified threshold. describe heuristic algorithm based
weighted formulation finds feasible policy original constrained problem.
order offer insight behavior algorithm, investigate application algorithm simple grid world problem discounted criterion function.
apply algorithm stochastic optimal control problem continuous states,
set feasible solutions restricted constraint required hold
certain probability, thus demonstrating practical applicability approach.
consider control feed tank lies upstream distillation column respect
two objectives: (1) outflow tank required stay close specified value
order ensure optimal operation distillation column, (2) tank level
substance concentrations required remain within specified intervals, certain
admissible chance constraint violation.
Li, Wendt, Arellano-Garcia, Wozny (2002) formulate problem quadratic
program chance constraints1 (e.g. Kall & Wallace, 1994), relaxed nonlinear
program case Gaussian distributions random input variables systems
whose dynamics given linear equations. nonlinear program solved
sequential quadratic programming.
Note approach Li et al. involves simulation based estimation
gradients chance constraints (Li et al., 2002, p. 1201). Like Q-learning (Watkins,
1989; Watkins & Dayan, 1992; Sutton & Barto, 1998), learning algorithm based
simulating episodes estimating value risk states, tank control task
correspond measure deviation optimal outflow probability
constraint violation, respectively.
contrast approach Li et al. (2002), RL algorithm applicable systems
continuous state spaces, whose system dynamics governed nonlinear equations
involve randomization noise arbitrary distributions random variables,
makes prior assumptions either aspect. special property
learning algorithm, also holds true e.g. Q-learning RL algorithms.
convergence Q-learning combined function approximation techniques necessary
continuous state spaces cannot guaranteed general (e.g. Sutton & Barto, 1998).
holds true algorithm. Nevertheless, RL algorithms successfully applied
many difficult problems continuous state spaces nonlinear dynamics (see e.g.
Sutton & Barto, 1998; Crites & Barto, 1998; Smart & Kaelbling, 2002; Stephan, Debes,
Gross, Wintrich, & Wintrich, 2001).
1. constraint seen relation domains variables restricting possible values.
variables constraint C = C(x1 , . . . , xn ) random, constraint hold certain
probability. Chance constrained programming particular approach stochastic programming
considers constrained optimization problems containing random variables so-called chance
constraints form P(C) p p [0, 1] formulated.

82

fiRisk-Sensitive Reinforcement Learning

article organized follows. section 2, RL framework described. Section 3 reviews related work risk-sensitive approaches. Section 4 describes approach
risk-sensitive RL. section 5, elucidate heuristic learning algorithm solving
constrained problem using weighted formulation. section 6, describe application
grid world problem. tank control task described section 7. section 8,
experiments feed tank control described. Section 9 concludes short
summary outlook.

2. RL Framework
RL one considers agent interacts process controlled.
discrete time-step, agent observes state x takes action u general
depends x. action agent causes environment change state x
according probability px,u (x ). section 7, consider set states, X,
finite set.
action set agent assumed finite, allowed depend
current state. state x, agent uses action set U (x) possible actions.
taking action u U (x), agent receives real valued reinforcement signal rx,u (x )
depends action taken successor state x . case random reward
signal, rx,u (x ) corresponds expected value. Markov property MDP requires
probability distribution successor states one rewards depend
current state action only. distributions change additional
information past states, actions rewards considered, i.e. independent
path leading current state.
aim agent find policy selecting actions maximizes
cumulative reward, called return. return defined
R=


X

rt ,

(1)

t=0

random variable rt denotes reward occurring t-th time step
agent uses policy . Let x0 , x1 , x2 , . . . denote corresponding probabilistic sequence
states, ui sequence actions chosen according policy .
constant [0, 1] discount factor allows control influence future
rewards. expectation return,
h



V (x) = E R | x0 = x ,

(2)

defined value x respect . well-known exist stationary

deterministic policies V (x) optimal (maximal) every state x. stationary deterministic policy function maps states actions particularly defined
independent time Markovian (independent history). work,
use term maximum-value policies instead optimal policies distinguish
minimum-risk policies also optimal sense, see section 4.1.
usual, define state/action value function
fi
fi

h



Q (x, u) = E r0 + V (x1 ) fi x0 = x, u0 = u .
83

(3)

fiGeibel & Wysotzki

Q (x, u) expected return agent first chooses action u, acts according
subsequent time steps. optimal Q-function Q , optimal policies
unique optimal values V derived (x) argmaxu Q (x, u) V (x) = Q (x, (x)).
Q computed using Watkins Q-learning algorithm.
RL one general distinguishes episodic continuing tasks treated
framework (see e.g. Sutton & Barto, 1998). episodic tasks, agent may
reach terminal absorbing state time . reaching absorbing state,
agent stays executes dummy action. reward defined rt = 0
. learning agent restarted according distribution
initial states reached absorbing state.

3. Related Work
P


random variable R =
t=0 rt (return) used define value state possesses
certain variance. risk-averse approaches dynamic programming (DP) reinforcement learning concerned variance R, worst outcomes.
example approach worst case control (e.g. Coraluppi & Marcus, 1999; Heger,
1994), worst possible outcome R optimized. risk-sensitive control based use exponential utility functions (e.g. Liu, Goodwin, & Koenig, 2003a;
Koenig & Simmons, 1994; Liu, Goodwin, & Koenig, 2003b; Borkar, 2002), return R
transformed reflect subjective measure utility. Instead maximizing
expected value R, objective maximize e.g. U = 1 log E(eR ),
parameter R usual return. shown depending parameter
, policies high variance V(R) penalized ( < 0) enforced ( > 0). value-criterion introduced Heger (1994) seen extension worst case control
bad outcomes policy occur probability less neglected.
Neuneier Mihatsch (1999) give model- free RL algorithm based
parameterized transformation temporal difference errors occurring (see also Mihatsch
& Neuneier, 2002). parameter transformation allows switch riskaverse risk-seeking policies. influence parameter value function cannot
expressed explicitly.
view risk concerned variance return worst possible
outcomes, instead fact processes generally possess dangerous undesirable states. Think chemical plant temperature pressure exceeding
threshold may cause plant explode. controlling plant, return corresponds plants yield. seems inappropriate let return also reflect
cost explosion, e.g. human lives affected.
work, consider processes undesirable terminal states. seemingly straightforward way handle error states system provide high
negative rewards systems enters error state. optimal policy avoid
error states general. drawback approach fact unknown
large risk (probability) entering error state is. Moreover, may want provide
threshold probability entering error state must exceeded
agents policy. general, impossible completely avoid error states, risk
controllable extend. precisely, agent placed state

84

fiRisk-Sensitive Reinforcement Learning

x, follow policy whose risk constrained . parameter [0, 1]
reflects agents risk-averseness. is, goal minimization risk,
maximization V risk kept threshold .
Markowitz (1952) considers combination different criteria equal discount
factors context portfolio selection. risk selected portfolio related
variance combined (weighted) criteria. Markowitz introduces notion
(E, V )-space. notion risk related variance V , depends
occurrence error states MDP. Therefore risk conceptually independent V ,
see e.g. tank control problem described section 7.
idea weighting return risk (Markowitz, 1959; Freund, 1956; Heger, 1994) leads
expected-value-minus-variance-criterion, E(R) kV(R), k parameter.
use idea computing feasible policy problem finding good policy
constrained risk (in regard probability entering error state): value
risk weighted using weight value weight 1 risk. value
increased, giving value weight compared risk, risk state
becomes larger user-specified threshold .
considering ordering relation tuples values, learning algorithm
fixed value also related ARTDP approach Gabor, Kalmar, Szepesvari
(1998). article, Gabor et al. additionally propose recursive formulation
MDP constraints may produce suboptimal solutions. applicable
case approach requires nonnegative reward function.
noted aforementioned approaches based variability
return suited problems like grid world problem discussed section 6,
tank control task section 7 risk related parameters (variables) state
description. example, grid world problem, policies worst case
outcome. regard approaches based variance, found policy leading
error states fast possible higher variance one reaches
goal states fast possible. policy small variance therefore large risk
(with respect probability entering error state), means address
different class control problems. underpin claim section 8.1.3.
Fulkerson, Littman, Keim (1998) sketch approach framework probabilistic planning similar although based complementary notion
safety. Fulkerson et al. define safety probability reaching goal state (see also
BURIDAN system Kushmerick, Hanks, & Weld, 1994). Fulkerson et al. discuss
problem finding plan minimum cost subject constraint safety (see
also Blythe, 1999). episodic MDP goal states, safety 1 minus risk.
continuing tasks absorbing states neither goal error states,
safety may correspond smaller value. Fulkerson et al. (1998) manipulate (scale)
(uniform) step reward undiscounted cost model order enforce agent reach
goal quickly (see also Koenig & Simmons, 1994). contrast, also consider
discounted MDPs, neither require existence goal states. Although
change original reward function, algorithm section 5 seen systematic
approach dealing idea Fulkerson et al. consists modification
relative importance original objective (reaching goal) safety. contrast
aforementioned approaches belonging field probabilistic planning,
85

fiGeibel & Wysotzki

operate previously known finite MDP, designed online learning algorithm
uses simulated actual experiences process. use neural network
techniques algorithm also applied continuous-state processes.
Dolgov Durfee (2004) describe approach computes policies
constrained probability violating given resource constraints. notion risk
similar described Geibel (2001). algorithm given Dolgov Durfee
(2004) computes suboptimal policies using linear programming techniques require
previously known model and, contrast approach, cannot easily extended
continuous state spaces. Dolgov Durfee included discussion DP approaches
constrained MDPs (e.g. Altman, 1999) also generalize continuous state
spaces (as tank control task) require known model. algorithm described
Feinberg Shwartz (1999) constrained problems two criteria applicable
case, requires discount factors strictly smaller 1,
limited finite MDPs.
Downside risk common notion finance refers likelihood security
investment declining price, amount loss could result
potential decline. scientific literature downside risk (e.g. Bawas, 1975; Fishburn,
1977; Markowitz, 1959; Roy, 1952) investigates risk-measures particularly consider
case return lower mean value, target value encountered.
contrast, notion risk coupled return R, fact state
x error state, example, parameters describing state lie outside
permissible ranges, state lies inside obstacle may occur
robotics applications.

4. Risk
define notion risk precisely, consider set
X

(4)

error states. Error states terminal states. means control agent
ends reaches state . allow additional set non-error terminal states
= .
Now, define risk x respect probability state sequence
(xi )i0 x0 = x, generated executing policy , terminates error state
x .
Definition 4.1 (Risk) Let policy, let x state. risk defined




(x) = P xi | x0 = x .

(5)

definition, (x) = 1 holds x . x , (x) = 0 = .
states 6 , risk depends action choices policy .
following subsection, consider computation minimum-risk policies
analogous computation maximum-value policies.
86

fiRisk-Sensitive Reinforcement Learning

4.1 Risk Minimization
risk considered value function defined cost signal r. see this,
augment state space MDP additional absorbing state
agent transfered reaching state . state introduced technical
reasons.
agent reaches state , reward signals r r become zero.
set r = 0 r = 1, agent reaches error state. states
longer absorbing states. new cost function r defined


rx,u (x ) =

(

1 x x =
0 else.

(6)

construction cost function r, episode states, actions costs
starting initial state x contains exactly cost r = 1 error state
occurs it. process enter error state, sequence r-costs contains
zeros only. Therefore, probability defining risk expressed expectation
cumulative return.
Proposition 4.1 holds


(x) = E

"
X
i=0

discount factor = 1.

#
fi
fi
ri fi x0 = x


(7)

Proof: r0 , r1 , . . . probabilistic sequence costs related risk. stated
P

above, holds R =def
i=0 ri = 1 trajectory leads error state; otherwise
P
i=0 ri = 0. means return R Bernoulli random variable,
probability q R = 1 corresponds risk x respect . Bernoulli random
variable holds ER = q (see e.g. Ross, 2000). Notice introduction together
fact r = 1 occurs transition error state
iwhen
fi
hP ,
fi


entering respective error state, ensures correct value E
i=0 ri fi x0 = x also
error states x. q.e.d.
Similar Q-function define state/action risk
h

Q (x, u) = E r0 + (x1 ) | x0 = x, u0 = u
=

X





px,u (x ) rx,u (x ) + (x ) .

x



(8)
(9)

Minimum-risk policies obtained variant Q-learning algorithm (Geibel,
2001).
4.2 Maximized Value, Constrained Risk
general, one interested policies minimum risk. Instead, want provide
parameter specifies risk willing accept. Let X X set
states interested in, e.g. X = X ( {}) X = {x0 } distinguished
87

fiGeibel & Wysotzki

starting state x0 . state x X , let px probability selecting starting
state. value
X
V =def
px V (x)
(10)
xX

corresponds performance states X . consider constrained problem
max V

(11)

x X : (x) .

(12)



subject
policy fulfills (12) called feasible. Depending , set feasible policies
may empty. Optimal policies generally depend starting state, nonstationary randomized (Feinberg & Shwartz, 1999; Gabor et al., 1998; Geibel, 2001).
restrict considered policy class stationary deterministic policies, constrained
problem generally well defined X singleton, need
stationary deterministic policy optimal states X . Feinberg Shwartz
(1999) shown case two unequal discount factors smaller 1
exist optimal policies randomized Markovian time step n (i.e.
depend history, may non-stationary randomized), stationary
deterministic (particularly Markovian) time step n onwards. Feinberg Shwartz
(1999) give DP algorithm case (cp. Feinberg & Shwartz, 1994). cannot
applied case = 1, also generalize continuous state
spaces. case equal discount factors, shown Feinberg Shwartz (1996)
(for fixed starting state) also exist optimal stationary randomized policies
case one constraint consider one action stationary deterministic
policy, i.e. one state policy chooses randomly two
actions.

5. Learning Algorithm
reasons efficiency predictability agents behavior
said end last section, restrict consideration stationary deterministic policies. following present heuristic algorithm aims
computing good policy. assume reader familiar Watkins Q-learning
algorithm (Watkins, 1989; Watkins & Dayan, 1992; Sutton & Barto, 1998).
5.1 Weighting Risk Value
define new (third) value function V state/action value function Q
weighted sum risk value
V (x) = V (x) (x)
Q (x, u)





= Q (x, u) Q (x, u) .

(13)
(14)

parameter 0 determines influence V -values (Q -values) compared
-values (Q -values). = 0, V corresponds negative . means
88

fiRisk-Sensitive Reinforcement Learning

maximization V0 lead minimization . , maximization
V leads lexicographically optimal policy unconstrained, unweighted 2-criteria
problem. one compares performance two policies lexicographically, criteria
ordered. large values , original value function multiplied dominates
weighted criterion.
weight successively adapted starting = 0, see section 5.3. adaptation
, discuss learning fixed proceeds.
5.2 Learning fixed
fixed value , learning algorithm computes optimal policy using
algorithm resembles Q-Learning also based ARTDP approach Gabor
et al. (1998).
learning, agent estimates Qt , Qt time 0, thus estimate
Qt performance current greedy policy, policy selects best
action respect current estimate Qt . values updated using example
state transitions: let x current state, u chosen action, x observed
successor state. reward risk signal example state transition given
r r respectively. x , greedy action defined following manner: action
u preferable u Qt (x , u) > Qt (x , u ) holds. equality holds, action
higher Qt -value preferred. write u u , u preferable u .
Let u greedy action x respect ordering . agents
estimates updated according
Qt+1 (x, u) = (1 )Qt (x, u) + (r + Qt (x , u ))

(15)

Qt+1 (x, u) = (1 )Qt (x, u) + (r + Qt (x , u ))

(16)

t+1
Qt+1
(x, u) Qt+1 (x, u)
(x, u) = Q

(17)

Every time new chosen, learning rate set 1. Afterwards decreases
time (cp. Sutton & Barto, 1998).
fixed , algorithm aims computing good stationary deterministic policy
weighted formulation feasible original constrained problem. Existence
optimal stationary deterministic policy weighted problem convergence
learning algorithm guaranteed criteria discount factor, i.e.
= , even < 1. case = , Q forms standard criterion function
rewards r r. consider risk second criterion function, = implies
= = 1. ensure convergence case also required either (a)
exists least one proper policy (defined policy reaches absorbing state
probability one), improper policies yield infinite costs (see Tsitsiklis, 1994), (b),
policies proper. case application example. conjecture
case < convergence possibly suboptimal policy guaranteed MDP forms
directed acyclic graph (DAG). cases oscillations non-convergence may occur,
optimal policies weighted problem generally found considered
policy class stationary deterministic policies (as constrained problem).
89

fiGeibel & Wysotzki

5.3 Adaptation
learning starts, agent chooses = 0 performs learning steps lead,
time, approximated minimum-risk policy 0 . policy allows agent
determine constrained problem feasible.
Afterwards value increased step step risk state X becomes
larger . Increasing increases influence Q-values compared
Q-values. may cause agent select actions result higher value,
perhaps also higher risk. increasing , agent performs learning
steps greedy policy sufficiently stable. aimed producing optimal
deterministic policy . computed Q- Q-values old (i.e. estimates




.
Q Q ) used initialization computing +
aim increasing give value function V maximum influence possible.
means value maximized, needs chosen user.
adaptation provides means searching space feasible policies.

5.4 Using Discounted Risk
order prevent oscillations algorithm section 5.2 case < , may
advisable set = corresponding using discounted risk defined
(x)

=E

"
X
i=0

#
fi
fi
ri fi x0 = x .


(18)

values ri positive, holds (x) (x) states x. discounted risk (x) gives weight error states occurring near future, depending
value .
finite MDP fixed , convergence algorithm optimal stationary
policy weighted formulation guaranteed Q (using (x)) forms
standard criterion function rewards r r. terminating adaptation
case risk state X becomes larger , one might still use original
(undiscounted) risk (x) learning done discounted version (x), i.e.
learning algorithm maintain two risk estimates every state, major
problem. Notice case = , effect considering weighted criterion
V corresponds modifying unscaled original reward function r adding
negative reward 1 agent enters error state: set optimal stationary
deterministic policies equal cases (where added absorbing state
single dummy action neglected).
section 6, experiments case < 1 = , X = X ( {}), finite
state space found. sections 7 8 consider application example
infinite state space, X = {x0 }, = = 1.

6. Grid World Experiment
following study behaviour learning algorithm finite MDP
discounted criterion. contrast continuous-state case discussed next
90

fiRisk-Sensitive Reinforcement Learning

E
E
E
a)
E
E G
E E
E
E
E
c)
E
E G
E E

E G
E
E
b)
E
E G
E E E E E E
E G
E
E
d)
E
E G
E E E E E E

G

E





E

E





E

E E
G




E E

Figure 1: a) example grid world, x : horizontal, : vertical. explanation see
text. b) Minimum risk policy ( = 0) 11 unsafe states. c) Maximum value
policy ( = 4.0) 13 unsafe states. d) Result algorithm: policy = 0.64
11 unsafe states.

section, function approximation neural networks needed value
function risk stored table. grid world, chosen <
1 = , X = X , state graph DAG. implies
stationary policy optimal every state X . Although oscillations therefore
expected, found algorithm stabilizes feasible policy
learning rate tends zero. also investigated use discounted risk
prevents oscillatory behaviour.
consider 6 6 grid world depicted Figure 1(a). empty field denotes
state, Es denote error states, two Gs denote two goal states. describe
states pairs (x, y) x, {1, 2, 3, 4, 5, 6}. I.e. = {(2, 2), (6, 6)}, = {(1, 1), (1,
2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)}. additional absorbing
state depicted.
chosen error states lower, i.e. extremal values x
dangerous. One goal states placed next error states, safer
part state space.
agent actions U = {, , , }. action u U takes agent
denoted direction possible. probability 0.21, agent transported
desired direction one three remaining directions.
agent receives reward 1 enters goal state. agent receives reward
0 every case. noted explicit punishment entering
error state, implicit one: agent enters error state, current
episode ends. means agent never receive positive reward
reached error state. Therefore, try reach one goal states,
< 1, try fast possible.
91

fiGeibel & Wysotzki

chosen X = X ( {}), = 0.9, equal probabilities px states.
Although convergence algorithm cannot guaranteed case, experimental results show algorithm yields feasible policy.
selected = 0.13. order illustrate behaviour algorithm
also computed minimum-risk maximum-value policy. Figure 1(b) shows
minimum risk policy. Though reward function r defined plays role
minimum risk policy, agent tries reach one two goal states.
goal state probability reaching error state 0. Clearly, respect
value function V , policy Figure 1(b) optimal: e.g. state (3, 3) agent
tries reach distant goal, causes higher discounting goal reward.
minimum risk policy Figure 1(b) 25 safe states, defined states
risk . minimum risk policy estimated mean value V = 0.442.
Figure 1(c) maximum-value policy shown. maximum-value policy
optimizes value without considering risk estimated value V = 0.46.
Thus, performs better minimum-risk policy Figure 1(b), risk (5, 2)
(2, 5) become greater . algorithm starts = 0 computes
minimum-risk policy Figure 1(b). increased step step risk state
changes value lower value > . algorithm stops = 0.64.
policy computed shown Figure 1(d). Obviously, lies minimum risk
policy Figure 1(b) maximum-value policy Figure 1(c).
also applied algorithm discounted version risk, , grid
world problem. discounted risk used learning, whereas original risk, ,
used selecting best weight . parameters described above, modified
algorithm also produced policy depicted figure 1(d). Seemingly, grid world
example, oscillations present major problem.
tank control task described next section, holds =
= .

7. Stochastic Optimal Control Chance Constraints
section, consider solution stochastic optimal control problem chance
constraints (Li et al., 2002) applying risk-sensitive learning method.
7.1 Description Control Problem
following, consider plant depicted Figure 2. task control
outflow tank lies upstream distillation column order fulfill several
objectives described below. purpose distillation column separation
two substances 1 2. consider finite number time steps 0, . . . , N . outflow
tank, i.e. feedstream distillation column, characterized flowrate
F (t) controlled agent, substance concentrations c1 (t) c2 (t) (for
0 N ).
purpose control designed keep outflow rate F (t) near specified
optimal flow rate Fspec order guarantee optimal operation distillation column.
92

fiRisk-Sensitive Reinforcement Learning

F1
c11
c12

distillation column

F2
c21
c22

ymax
y, h, c1, c2
ymin

F

tank

Fspec
c1min, c1max
c2min, c2max

Figure 2: plant. See text description.
Using quadratic objective function, goal specified
min

F (0),...,F (N 1)

N
1
X

(F (t) Fspec )2 ,

(19)

t=0

values obey
0 N 1 : Fmin F (t) Fmax .

(20)

tank characterized tank level y(t) holdup h(t), = A1 h
constant footprint tank. tank level y(t) concentrations
c1 (t) c2 (t) depend two stochastic inflow streams characterized flowrates
F1 (t) F2 (t), inflow concentrations c1,j (t) c2,j (t) substances j {1, 2}.
linear dynamics tank level given
y(t + 1) = y(t) + A1

X



Fj (t) F (t) .

(21)


A1 X
Fj (t)(cj,i (t) ci (t))
(
y(t) j=1,2

(22)

j=1,2

dynamics concentrations given
= 1, 2 : ci (t + 1) = ci (t) +

initial state system characterized
y(0) = y0 , c1 (0) = c01 , c2 (0) = c02 .

(23)

tank level required fulfill constraint ymin y(t) ymax . concentrations inside tank correspond concentrations outflow. substance
concentrations c1 (t) c2 (t) required remain intervals [c1,min , c1,max ]
93

fiGeibel & Wysotzki

[c2,min , c2,max ], respectively. assume inflows Fi (t) inflow concentrations
ci,j (t) random, governed probability distribution. Li et al. (2002)
assume multivariate Gaussian distribution. randomness variables,
tank level feedstream concentrations may violate given constraints.
therefore formulate stochastic constraint




P ymin y(t) ymax , ci,min ci (t) ci,max , 1 N, = 1, 2 p

(24)

expression (24) called (joint) chance constraint, 1 p corresponds
permissible probability constraint violation. value p given user.
stochastic optimization problem SOP-YC defined quadratic objective function (19) describing sum quadratic differences outflow rates Fspec ,
linear dynamics tank level (21), nonlinear dynamics concentrations
(22), initial state given (23), chance constraint (24).
Li et al. describe simpler problem SOP-Y concentrations considered;
see Figure 3. SOP-Y use cumulative inflow F = F1 + F2 description
tank level dynamics, see (27). SOP-Y describes dynamics linear system.
Li et al. solve SOP-Y relaxing nonlinear program solved sequential
quadratic programming. relaxation possible SOP-Y linear system,
multivariate Gaussian distribution assumed. Solving nonlinear systems like SOP-YC
non-Gaussian distributions difficult (e.g. Wendt, Li, & Wozny, 2002),
achieved RL approach.

min

F (0),...,F (N 1)

subject
0 N 1 :
y(t + 1)

N
1
X

(F (t) Fspec )2

(25)

t=0

Fmin F (t) Fmax


= y(t) + A1 F (t) F (t)
y(0) = y0



P ymin y(t) ymax , 1 N p

(26)
(27)
(28)
(29)

Figure 3: problem SOP-Y.
Note control F (t) optimization problems depends time step
t. means solutions SOP-YC SOP-Y yield open loop controls.
dependence initial condition (23), moving horizon approach taken
design closed loop control. discuss issue, goes beyond scope
paper.
94

fiRisk-Sensitive Reinforcement Learning

7.2 Formulation Reinforcement Learning Problem
Using RL instead analytical approach advantage probability distribution doesnt Gaussian unknown. state equations also need
known, nonlinear. learning agent must access simulated
empirical data, i.e. samples least random variables.
Independent chosen state representation, immediate reward defined
rx,u (x ) = (u Fspec )2 ,

(30)

u chosen action minus required RL value function
maximized. reward signal depends action chosen, current
successor state.
work consider finite (discretized) action sets, although approach
also extended continuous action sets, e.g. using actor-critic method (Sutton &
Barto, 1998). following, assume interval [Fmin , Fmax ] discretized
appropriate manner.
process reaches error state one constraints (24) (or (29), respectively) violated. process artificially terminated transferring agent
additional absorbing state giving risk signal r = 1. V -value error states
set zero, controller could choose action Fspec first constraint
violation, subsequent constraint violations make things worse respect
chance constraints (24) (29), respectively.
7.3 Definition State Space
following consider design appropriate state spaces result either
open loop control (OLC) closed loop control (CLC).
7.3.1 Open Loop Control
note SOP-YC SOP-Y time-dependent finite horizon problems
control F (xt ) = F (t) depends only. means state feedback
resulting controller open-looped. respect state definition xt = (t),
Markov property defined section 2 clearly holds probabilities rewards defining
V . Markov property hold rewards defining . Using xt = (t)
implies agent information state process. including
information history form past action, agent gets idea
current state process. Therefore, inclusion history information changes
probability r = 1, Markov property violated. Including past actions
state description ensures Markov property r. Markov property therefore
recovered considering augmented state definition
xt = (t, ut1 , . . . , u0 ) ,

(31)

past actions (ut1 , . . . , u0 ). first action u0 depends fixed initial tank level y0
fixed initial concentrations only. second action depends first action, i.e.
also initial tank level initial concentrations on. Therefore, learning
95

fiGeibel & Wysotzki

states (31) results open loop control, original problems SOP-YC
SOP-Y.
noted MDP, risk depend past actions,
future actions only. choice xt = (t), hidden state information,
MDP Markov property violated. Therefore probability
entering error state conditioned time step, i.e. P (r0 = 1|t), changes
additionally conditioned past actions yielding value P (r0 = 1|t, ut1 , . . . , u0 )
(corresponding agent remembers past actions). example, agent
remembers past time steps current learning episode always used
action F = 0 corresponding zero outflow, conclude increased
probability tank level exceeds ymax , i.e. knowledge increased risk.
If, hand, remember past actions, cannot know increased
risk knows index current time step, carries less information
current state.
well-known Markov property generally recovered including
complete state history state description. xt = (t), state history contains
past time indices, actions r-costs. tank control task, action history
relevant part state history previous r-costs necessarily zero,
indices past time steps already given actual time known
agent. Therefore, past rewards indices past time steps need
included expanded state. Although still complete state information
known agent, knowledge past actions suffices recover Markov property.
respect state choice (31) reward signal (30), expectation
definition value function needed, cp. eq. (2). means
h



V (x) = E R | x0 = x =

N
1
X

(F (t) Fspec )2

t=0

holds, i.e. direct correspondence value function objective
function SOP-YC SOP-Y.
7.3.2 Closed Loop Control
define alternative state space, expectation needed.
decided use state definition
xt = (t, y(t), c1 (t), c2 (t))

(32)

xt = (t, y(t))

(33)

problem SOP-YC
simpler problem SOP-Y. result learning state time-dependent closed
loop controller, achieve better regulation behavior open loop controller,
reacts actual tank level concentrations, whereas open loop control
not. agent access inflow rates concentrations,
included state vector, yielding improved performance controller.
96

fiRisk-Sensitive Reinforcement Learning

Parameter
N
y0
[ymin , ymax ]
A1
Fspec
[Fmin , Fmax ]
RL-YC-CLC:
c01
c02
[c1,min , c1,max ]
[c2,min , c2,max ]

Table 1: Parameter settings
Value
Explanation
16
number time steps
0.4
initial tank level
[0.25, 0.75] admissible interval tank level
0.1
constant, see (22)
0.8
optimal action value
[0.55, 1.05] interval actions, 21 discrete values
0.2
0.8
[0.1, 0.4]
[0.6, 0.9]

initial concentration subst. 1
initial concentration subst. 2
interval concentration 1
interval concentration 2

7.4 RL Problems
definitions, optimization problem defined via (11) (12)
= 1p (see (24) (29)). set X (see (10) (12)) defined contain unique
starting state, i.e X = {x0 }. experiments consider following instantiations
RL problem:
RL-Y-CLC Reduced problem SOP-Y using states xt = (t, y(t)), x0 = (0, y0 ) resulting closed loop controller (CLC).
RL-Y-OLC Open loop controller (OLC) reduced problem SOP-Y. state space
defined action history time, see eq. (31). starting state x0 = (0).
RL-YC-CLC Closed loop controller full problem SOP-YC using states xt =
(t, y(t), c1 (t), c2 (t)) x0 = (0, y0 , c01 , c01 ).
Solving problem RL-Y-OLC yields action vector. problems RL-YC-CLC
RL-Y-CLC result state dependent controllers. present results fourth
natural problem RL-YC-OLC, offer additional insights.
interpolation states used 2 16 multilayer perceptrons (MLPs, e.g.
Bishop, 1995) case RL-Y-OLC extremely large state space (15 dimensions = N 1). used radial basis function (RBF) networks case
RL-YC-CLC RL-Y-CLC, produced faster, stable robust results
compared MLPs.
training respective networks, used direct method corresponds
performing one gradient descent step current state-action pair new

estimate target value (see e.g. Baird, 1995). new estimate Q given

r + Qt (x , u ), Q r + Qt (x , u ) (compare right sides update
equations (15)-(17)).
97

fiGeibel & Wysotzki

(a)
2
1.8
1.6
1.4
1.2
1
0.8
0.6
0.4
0.2
0

outflow rate

Inflow

(b)

0

2

4

6

1
0.95
0.9
0.85
0.8
0.75
0.7
0.65

8 10 12 14 16
time

(c)

omega=0.01
0.8

0

2

4

6

8 10 12 14 16
time

omega=0.05
0.8
outflow rate

outflow rate

(d)
1
0.95
0.9
0.85
0.8
0.75
0.7
0.65
0

2

4

6

8 10 12 14 16
time

1
0.95
0.9
0.85
0.8
0.75
0.7
0.65

omega=0.1
0.8

0

2

4

6

8 10 12 14 16
time

Figure 4: RL-Y-CLC: (a) inflow rates F (t) 10 runs. (b), (c), (d) Example runs
policies = 0.01, 0.05, 0.10 (i.e. p = 0.99, 0.95, 0.90). holds Fspec = 0.8.

8. Experiments
section, examine experimental results obtained tank control task
( = = 1). section 8.1 discuss linear case compare results Li
et al. (2002). linear case, consider closed loop controller obtained solving
RL-Y-CLC (sect. 8.1.1) open loop controller related RL problem RL-Y-OLC
(sect. 8.1.2). closed loop controller, discuss problem non-zero covariances
variables different time steps. nonlinear case discussed section 8.2.
8.1 Problems RL-Y-CLC RL-Y-OLC
start simplified problems, RL-Y-CLC RL-Y-OLC, derived SOP-Y
discussed Li et al. (2002). SOP-Y concentrations considered,
one inflow rate F (t) = F1 (t) + F2 (t). parameter settings Table 1 (first five
lines) taken Li et al. (2002). minimum maximum values actions
determined preliminary experiments.
Li et al. define inflows (F (0), . . . , F (15))T Gaussian distribution
mean vector
(1.8, 1.8, 1.5, 1.5, 0.7, 0.7, 0.5, 0.3, 0.2, 0.2, 0.2, 0.2, 0.2, 0.6, 1.2, 1.2)T .
98

(34)

fiRisk-Sensitive Reinforcement Learning

0.3
0.2
0.1
risk
0
-0.1
value

-0.2

weighted
-0.3
-0.4
-0.5
0

5

10

15

20

xi






Figure 5: RL-Y-CLC: Estimates risk (x0 ), value V (x0 ), V (x0 ) =




V (x0 ) (x0 ) different values .

covariance matrix given





C=

0 1 r01
02
0 1 r01
...


0 N 1 r0(N 1)


0 N 1 r0(N 1)
...
...


2

N
1







(35)

= 0.05. correlation inflows time j defined
rij = rji = 1 0.05(j i)

(36)

0 N 1, < j N 1 (from Li et al., 2002). inflow rates ten example
runs depicted Figure 4(a).
8.1.1 Problem RL-Y-CLC (Constraints Tank Level)
start presentation results problem RL-Y-CLC, control
(i.e. outflow F ) depends time tank level. X = {x0 }
overall performance policy defined (10) corresponds performance x0 ,




V = V (x0 ) .


holds x0 = (0, y0 ). V (x0 ) value respect policy learned
weighted criterion function V , see also (13). respective risk


(x0 ) .




Figure 5 estimated2 risk (x0 ) estimated value V (x0 ) depicted


different values . estimate risk (x0 ) value V (x0 )
2. values policies presented following estimated learning algorithm. Note
order enhance readability, also denoted learned policy .

99

fiGeibel & Wysotzki

0.5
0.4
0.3
0.2
0.1
0
-0.1
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
xi

Figure 6: RL-Y-CLC: Difference weighted criteria. explanation see text.

increase . Given fixed value p admissible probability constraint violation,

appropriate = (p) obtained value risk (x0 ) lower

= 1p maximum V (x0 ). Due variation performance (see
Fig. 5) found works better selecting maximum . estimate






weighted criterion V (x0 ) = V (x0 ) (x0 ) also shown Figure 5.
outflow rate F (control variable) different values found Figure 4(bc). Note rates certain variance since depend probabilistic tank
level. randomly picked one example run value . found control
values F (t) tend approach Fspec increasing values (i.e. decreasing values p).
Correlations definition covariance matrix (35) (36) reveals high
correlation inflow rates neighboring time steps. order better account this,
possible include information past time steps state description time t.
level changes according inflow rate F , investigated inclusion
past values y. inflow rates measured, could included
state vector. Former rewards need included depend past tank
levels, i.e. represent redundant information.
compared performance algorithm augmented state space
defined xt = (t, y(t), y(t 1), y(t 2)) (depth 2 history) normal state space
xt = (t, y(t)) (no history). Fig. 6 shows












V (0, y0 , 0, 0) V (0, y0 ) ,
|

{z
x0

}

| {z }
x0

i.e. difference weighted criteria starting state respect learned
policies (history) (no history). Note starting state x0 , past values
defined 0. curve Figure 6 runs mainly 0. means using
augmented state space results better performance many values . Note
100

fiRisk-Sensitive Reinforcement Learning

(a)

(b)
0.3

1
Risk

0.2

0.95

0.1
outflow rate

0.9

0
-0.1
Value

-0.2

0.85
0.8
0.75

-0.3

0.7

-0.4

0.65
0

2

4

6

8

10

12

14

0

xi


2

4

6

8
time

10

12

14



Figure 7: RL-Y-OLC: (a) Estimates risk (x0 ) value V (x0 ) increasing


values . (b) Learned policy (x0 ) 0.098 V (x0 ) 0.055

larger values original value function overweights risk cases
policy always chooses outflow Fspec approximated. means
difference performance tends zero.
similar, quite pronounced effect observed using history
length 1 only. principle, assume possible achieve even better performance
including full history tank levels state description, tradeoff objective difficulty network training caused number
additional dimensions.
8.1.2 RL-Y-OLC (History Control Actions)
RL problem RL-Y-OLC comprises state descriptions consisting action history
together time, see eq. (31). starting state empty history, i.e. x0 = (0).
result learning time-dependent policy implicit dependence y0 .
learned policy therefore fixed vector actions F (0), . . . , F (15) forms feasible,
general suboptimal solution problem SOP-Y Figure 3.


progression risk estimate, i.e. (x0 ), value, V (x0 ),
different values found Figure 7. results good ones

RL-Y-CLC Figure 5: estimated minimum risk 0.021, risk (x0 ) grows
much faster RL-Y-CLC-risk Figure 5.

policy risk (x0 ) 0.098 depicted Figure 7(b). contrast
policies RL-Y-CLC (see Figure 4(b-c)), control values change different runs.
8.1.3 Comparison
Table 2, compared performance approach Li et al. RL-Y-CLC
RL-Y-OLC p = 0.8 p = 0.9. RL-Y-CLC RL-Y-OLC performed 10
learning runs. respective learned policy , risk (x0 ) value V (x0 )
estimated 1000 test runs. RL-Y-CLC RL-Y-OLC, table shows mean
performance averaged 10 runs together standard deviation parentheses.
101

fiGeibel & Wysotzki

Table 2: Comparison est. squared deviation Fspec (i.e. V (x0 )) results Li et
al. results RL-Y-CLC RL-Y-OLC p = 0.8 ( = 0.2) p = 0.9
( = 0.1). Smaller values better.
approach
Li et al. (2002)
RL-Y-CLC
RL-Y-OLC

p = 0.8
0.0123
0.00758 (0.00190)
0.0104 (0.000302)

p = 0.9
0.0484
0.02 (0.00484)
0.0622 (0.0047)

found that, average, policy determined RL-Y-CLC performs better
obtained approach Li et al. (2002) (with respect estimated squared
deviation desired outflow Fspec , i.e. respect V (x0 ).) policy obtained
RL-Y-OLC performs better p = 0.8 worse p = 0.9. maximal achievable
probability holding constraints 1.0 (sd 0.0) RL-Y-CLC, 0.99 (sd 0.0073)
RL-Y-OLC. Li et al. report p = 0.999 approach.
approach Neuneier Mihatsch (1999) considers worst-case outcomes
policy, i.e. risk related variability return. Neuneier Mihatsch show
learning algorithm interpolates risk-neutral worst-case criterion
limiting behavior exponential utility approach.
0.6

risk
value

0.5
0.4
0.3

risk

0.2
value

0.1
0
-0.1
-1

-0.5

0

0.5

1

kappa

Figure 8: Risk value several values
learning algorithm Neuneier Mihatsch parameter (1.0, 1.0)
allows switch risk-averse behavior ( 1), risk-neutral behavior ( = 0),
risk-seeking behavior ( 1). agent risk-seeking, prefers policies
good best-case outcome. Figure 8 shows risk (probability constraint violation) value
starting state regard policy computed algorithm Neuneier
Mihatsch. Obviously, algorithm able find maximum-value policy yielding zero
deviation Fspec , corresponding choosing F = Fspec = 0.8 states, learning
result sensitive risk parameter . reason worst-case
best-case returns policy always chooses outflow 0.8 also correspond
102

fiRisk-Sensitive Reinforcement Learning

(a)

Inflow

(b)
1

1

0.8

0.8
ymax
mu(t)+0.04

0.6



0.6

0.4

0.4
mu(t)-0.04

c1max
c1

ymin
0.2

0.2

c1min
0

0
0

2

4

6

8

10

12

14

0

Time

2

4

6

8

10

12

14

16

Time

Figure 9: RL-YC-CLC: (a) (t) + 0.04 (t) 0.04 (profiles two mode means).
(b) tank level y(t) concentration c1 (t) 10 example runs using
minimum risk policy.

0, best return possible (implying zero variance return). approach
Neuneier Mihatsch variance-based approaches therefore unsuited
problem hand.
8.2 Problem RL-YC-CLC (Constraints Tank Level Concentrations)
following consider full problem RL-YC-CLC. two inflows F1 F2
assumed equal Gaussian distributions distribution cumulative
inflow F (t) = F1 (t) + F2 (t) described covariance matrix (35) mean
vector (34); see also Figure 4(a).
order demonstrate applicability approach non-Gaussian distributions,
chosen bimodal distributions inflow concentrations c1 c2 . underlying
assumption upstream plants either increased output,
lower output, e.g. due different hours weekdays.
distribution inflow concentration ci,1 (t) characterized two Gaussian
distributions means
(t) + (1)k 0.04 ,
k = 1, 2 2 = 0.0025. value k {0, 1} chosen beginning
run equal probability outcome. means overall mean value
ci,1 (t) given (t). profiles mean values modes found
Figure 9(a). ci,2 given ci,2 (t) = 1.0 ci,1 (t). minimum maximum values
concentrations ci (t) found Table 1, also Figure 9(b). Note
concentrations controlled indirectly choosing appropriate outflow F .
developing risk value starting state shown Figure 10.
resulting curves behave similar problem RL-Y-CLC depicted Figure 5:
value risk increase . seen algorithm covers relatively
broad range policies different value-risk combinations.
103

fiGeibel & Wysotzki

0.4
0.3
0.2
risk
0.1
0
-0.1
-0.2

value

-0.3
-0.4
0

5

10

15

20

25

30

35

40

45

50

xi








Figure 10: RL-YC-CLC: Estimated risk (x0 ), value V (x0 ), V (x0 ) = V (x0 )


(x0 ) different values .

minimum risk policy, curves tank level concentration
c1 found Figure 9(b). bimodal characteristics substance 1 inflow
concentrations reflected c1 (t) (it holds c2 (t) = 1 c1 (t)). attainable minimum
risk 0.062. Increasing weight leads curves similar shown Figures 5
7. assume minimum achievable risk decreased inclusion
additional variables, e.g. inflow rates concentrations, and/or inclusion past
values discussed section 8.1.1. treatment version action history
analogous section 8.1.2. therefore conclude presentation experiments
point.

9. Conclusion
paper, presented approach learning optimal policies constrained risk
MDPs error states. contrast RL DP approaches consider risk
matter variance return worst outcomes, defined risk
probability entering error state.
presented heuristic algorithm aims learning good stationary policies
based weighted formulation problem. weight original value function
increased order maximize return risk required stay
given threshold. fixed weight finite state space, algorithm converges
optimal policy case undiscounted value function. case state
space finite, contains cycles, < 1 holds, conjecture convergence
learning algorithm policy, assume suboptimal weighted
formulation. optimal stationary policy exists weighted formulation,
feasible, generally suboptimal solution constrained problem.
104

fiRisk-Sensitive Reinforcement Learning

weighted approach combined adaptation heuristic searching space feasible stationary policies original constrained problem,
us seems relatively intuitive. conjecture better policies could found allowing
state-dependent weights (x) modified adaptation strategy, extending
considered policy class.
successfully applied algorithm control outflow feed tank
lies upstream distillation column. started formulation stochastic
optimal control problem chance constraints, mapped risk-sensitive learning
problem error states (that correspond constraint violation). latter problem
solved using weighted RL algorithm.
crucial point reformulation RL problem design state space.
found algorithm consistently performed better state information
provided learner. Using time action history resulted large state
spaces, poorer learning performance. RBF networks together sufficient state
information facilitated excellent results.
must mentioned use RL together MLP RBF network based
function approximation suffers usual flaws: non-optimality learned network,
potential divergence learning process, long learning times. contrast
exact method, priori performance guarantee given, course posteriori
estimate performance learned policy made. main advantage
RL method lies broad applicability. tank control task, achieved good
results compared obtained (mostly) analytical approach.
cases |X| > 1 < 1 theoretical investigations convergence
experiments required. Preliminary experiments shown oscillations may
occur algorithm, behavior tends oscillate sensible policies without
getting bad in-between although convergence usefulness policies remains
open issue.
Oscillations prevented using discounted risk leads underestimation
actual risk. existence optimal policy convergence learning
algorithm fixed guaranteed case finite MDP. probabilistic
interpretation discounted risk given considering 1 probability
exiting control MDP (Bertsekas, 1995). investigation discounted
risk may worthwhile right. example, task long episodes,
continuing, i.e. non-episodic, natural give larger weight error
states occurring closer current state.
designed learning algorithm online algorithm. means learning accomplished using empirical data obtained interaction simulated
real process. use neural networks allows apply algorithm processes
continuous state spaces. contrast, algorithm described Dolgov Durfee (2004)
applied case known finite MDP. model obtained
case continuous-state process finding appropriate discretization estimating state transition probabilities together reward function. Although
discretization prevents application Dolgov Durfees algorithm RL-Y-OLC,
15-dimensional state space encountered, probably applied case
RL-Y-OLC. plan investigate point future experiments.
105

fiGeibel & Wysotzki

question arises whether approach also applied stochastic optimal
control problems types chance constraints. Consider conjunction chance
constraints
P(C0 ) p1 , . . . , P(CN 1 ) pN 1 ,
(37)
Ct constraint system containing variables time t, pt
respective probability threshold. (37) requires alternative RL formulation risk
state depends next reward, time-step .
solution modified version RL algorithm difficult.
Ct (37) allowed constraint system state variables depending t, things get involved several risk functions needed
state. plan investigating cases future.

Acknowledgments thank Dr. Pu Li providing application example
helpful comments. thank Onder Gencaslan conducting first experiments
masters thesis.

References
Altman, E. (1999). Constrained Markov Decision Processes. Chapman Hall/CRC.
Baird, L. (1995). Residual algorithms: reinforcement learning function approximation. Proc. 12th International Conference Machine Learning, pp. 3037. Morgan
Kaufmann.
Bawas, V. S. (1975). Optimal rules ordering uncertain prospects. Journal Finance,
2 (1), 1975.
Bertsekas, D. P. (1995). Dynamic Programming Optimal Control. Athena Scientific,
Belmont, Massachusetts. Volumes 1 2.
Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific,
Belmont, MA.
Bishop, C. M. (1995). Neural Networks Pattern Recognition. Oxford University Press,
Oxford.
Blythe, J. (1999). Decision-theoretic planning. AI Magazine, 20 (2), 3754.
Borkar, V. (2002). Q-learning risk-sensitive control. Mathematics Operations Research,
27 (2), 294311.
Coraluppi, S., & Marcus, S. (1999). Risk-sensitive minimax control discrete-time,
finite-state Markov decision processes. Automatica, 35, 301309.
Crites, R. H., & Barto, A. G. (1998). Elevator group control using multiple reinforcement
learning agents. Machine Learning, 33 (2/3), 235262.
Dolgov, D., & Durfee, E. (2004). Approximating optimal policies agents limited
execution resources. Proceedings Eighteenth International Joint Conference
Artificial Intelligence, pp. 11071112. AAAI Press.
106

fiRisk-Sensitive Reinforcement Learning

Feinberg, E., & Shwartz, A. (1994). Markov decision models weighted discounted
criteria. Math. Operations Research, 19, 152168.
Feinberg, E., & Shwartz, A. (1996). Constrained discounted dynamic programming. Math.
Operations Research, 21, 922945.
Feinberg, E., & Shwartz, A. (1999). Constrained dynamic programming two discount
factors: Applications algorithm. IEEE Transactions Automatic Control,
44, 628630.
Fishburn, P. C. (1977). Mean-risk analysis risk associated below-target returns.
American Economics Review, 67 (2), 116126.
Freund, R. (1956). introduction risk programming model. Econometrica, 21,
253263.
Fulkerson, M. S., Littman, M. L., & Keim, G. A. (1998). Speeding safely: Multi-criteria
optimization probabilistic planning. Proceedings Fourteenth National
Conference Artificial Intelligence, p. 831. AAAI Press/MIT Press.
Gabor, Z., Kalmar, Z., & Szepesvari, C. (1998). Multi-criteria reinforcement learning.
Proc. 15th International Conf. Machine Learning, pp. 197205. Morgan Kaufmann,
San Francisco, CA.
Geibel, P. (2001). Reinforcement learning bounded risk. Brodley, E., & Danyluk,
A. P. (Eds.), Machine Learning - Proceedings Eighteenth International Conference (ICML01), pp. 162169. Morgan Kaufmann Publishers.
Heger, M. (1994). Consideration risk reinforcement learning. Proc. 11th International Conference Machine Learning, pp. 105111. Morgan Kaufmann.
Kall, P., & Wallace, S. W. (1994). Stochastic Programming. Wiley, New York.
Koenig, S., & Simmons, R. G. (1994). Risk-sensitive planning probabilistic decision
graphs. Doyle, J., Sandewall, E., & Torasso, P. (Eds.), KR94: Principles Knowledge Representation Reasoning, pp. 363373, San Francisco, California. Morgan
Kaufmann.
Kushmerick, N., Hanks, S., & Weld, D. S. (1994). algorithm probabilistic leastcommitment planning.. AAAI, pp. 10731078.
Li, P., Wendt, M., Arellano-Garcia, & Wozny, G. (2002). Optimal operation distillation
processes uncertain inflows accumulated feed tank. AIChe Journal, 48,
11981211.
Liu, Y., Goodwin, R., & Koenig, S. (2003a). Risk-averse auction agents. Rosenschein, J.,
Sandholm, T., & Wooldridge, M. Yokoo, M. (Eds.), Proceedings Second International Joint Conference Autonomous Agents MultiAgent Systems (AAMAS03), pp. 353360. ACM Press.
Liu, Y., Goodwin, R., & Koenig, S. (2003b). Risk-averse auction agents.. AAMAS, pp.
353360.
Markowitz, H. M. (1952). Portfolio selection. Journal Finance, 7 (1), 7791.
Markowitz, H. M. (1959). Portfolio Selection. John Wiley Sons, New York.
107

fiGeibel & Wysotzki

Mihatsch, O., & Neuneier, R. (2002). Risk-sensitive reinforcement learning. Machine Learning, 49 (2-3), 267290.
Neuneier, R., & Mihatsch, O. (1999). Risk-sensitive reinforcement learning. Michael
S. Kearns, Sara A. Solla, D. A. C. (Ed.), Advances Neural Information Processing
Systems, Vol. 11. MIT Press.
Ross, S. M. (2000). Introduction Probability Models. Academic Press, New York.
Roy, A. D. (1952). Safety first holding assets. Econometrica, 20 (3), 431449.
Smart, W. D., & Kaelbling, L. P. (2002). Effective reinforcement learning mobile robots. Proceedings 2002 IEEE International Conference Robotics
Automation (ICRA 2002).
Stephan, V., Debes, K., Gross, H.-M., Wintrich, F., & Wintrich, H. (2001). new control
scheme combustion processes using reinforcement learning based neural networks. International Journal Computational Intelligence Applications, 1 (2),
121136.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning Introduction. MIT
Press.
Tsitsiklis, J. N. (1994). Asynchronous stochastic approximation Q-learning. Machine
Learning, 16 (3), 185202.
Watkins, C. J. C. H. (1989). Learning Delayed Rewards. Ph.D. thesis, Kings College,
Oxford.
Watkins, C. J. C. H., & Dayan, P. (1992). Q-learning. Machine Learning, 8 (3/4). Special
Issue Reinforcement Learning.
Wendt, M., Li, P., & Wozny, G. (2002). Non-linear chance constrained process optimization
uncertainty. Ind. Eng. Chem. Res., 21, 36213629.

108

fiJournal Artificial Intelligence Research 24 (2005) 933944

Submitted 12/04; published 12/05

Engineering Note
mGPT: Probabilistic Planner Based Heuristic Search
Blai Bonet

bonet@ldc.usb.ve

Departamento de Computacion
Universidad Simon Bolvar, Venezuela

Hector Geffner

hector.geffner@upf.edu

ICREA & Universitat Pompeu Fabra
Paseo de Circunvalacion 8, Barcelona 08003, Spain

Abstract
describe version GPT planner used probabilistic track 4th
International Planning Competition (ipc-4). version, called mGPT, solves Markov
Decision Processes specified ppddl language extracting using different classes
lower bounds along various heuristic-search algorithms. lower bounds
extracted deterministic relaxations alternative probabilistic effects
action mapped different, independent, deterministic actions. heuristic-search
algorithms use lower bounds focusing updates delivering consistent
value function states reachable initial state greedy policy.

1. Introduction
mGPT planner based heuristic search solving Markov Decision Processes (MDPs)
specified high-level planning language ppddl. mGPT captures fragment
functionality GPT system handles non-determinism incomplete information,
qualitative probabilistic forms, including pomdps Conformant planning
(Bonet & Geffner, 2000).
mGPT supports several algorithms admissible heuristic functions (lower bounds)
combined generate wide range solvers. main algorithms lrtdp
hdp. heuristic-search algorithms solving MDPs make use lower bounds
computing consistent value function V : function Bellman residuals bounded
user-provided parameter states reachable given initial state s0
greedy policy based V (Bonet & Geffner, 2003b, 2003a).
lower bounds derived solving relaxations input problem. Since algorithms solving relaxations also based heuristic search, implemented
stackable software components created sequence computing complex heuristic functions simpler ones.

2. Algorithms
divide algorithms two groups: deliver consistent value functions
respect user-provided parameter , select actions real time. first

c
2005
AI Access Foundation. rights reserved.

fiBonet & Geffner

class algorithms compute -consistent value function V states reachable
initial state s0 , greedy policy V based V .
following subsection, give definitions admissible consistent value functions, greedy, partial proper policies. Then, present algorithms implemented
mGPT.
2.1 Consistent Value Functions, Greedy, Partial Proper Policies
value function V admissible non-overestimating; i.e. value V (s)
state lower bound optimal expected cost starting s. V -consistent
state Bellman residual s,
fi

fi
X
fi
fi
def
0
0 fi
fi
R(s) = fiV (s) min c(s, a) +
P r(s |s, a)V (s ) fi ,
(1)
aA(s)

s0

less equal . Here, A(s) denotes actions applicable s, c(s, a)
cost applying action s, P r() probabilistic transition function. V
0-consistent s, say V consistent s.
state reachable initial state s0 policy exists trajectory
s0 , s1 , . . . , sn sn = P (sk+1 |sk , (sk )) > 0 0 k < n. words,
state reached positive probability s0 zero steps using
policy .
known greedy policy V based value function V , defined


X
def
0
0
V (s) = argmin c(s, a) +
P r(s |s, a)V (s ) ,
(2)
aA(s)

s0

optimal V -consistent states sufficiently small . Yet, since goal
find optimal policy respect initial state s0 states reachable
it, sufficient V admissible -consistent states reachable
s0 V .
partial policy policy doesnt need defined states. closed
respect state defined states reachable ,
proper respect goal state reached every state reachable
, finally proper proper respect states.
2.2 Algorithms Compute -Consistent Value Functions
first group algorithms, mGPT implements Value Iteration (vi), Labeled RealTime Dynamic Programming (lrtdp), Heuristic Dynamic Programming (hdp).
Value Iteration (Bertsekas, 1995) applied states reached
given initial state available operators, yields -consistent value function
them.1 mGPTs vi serves bottom-line reference comparison
algorithms.
1. undiscounted problems like probabilistic planning, conditions neeeded order
VI finish -consistent value function (Bertsekas, 1995).

934

fimGPT: Probabilistic Planner Based Heuristic Search

Labeled Real-Time Dynamic Programming (Bonet & Geffner, 2003b) heuristicsearch algorithm implements labeling scheme top rtdp algorithm (Barto,
Bradtke, & Singh, 1995) improve convergence. Lrtdp works performing simulated
trials start initial state end solved states, selecting actions according
greedy policy V successor states according corresponding transition
probabilities. Initially, V input heuristic function, solved states
goal states. Then, time action picked state s, value updated
making consistent value successors. end trial, labeling
procedure called checks whether new states labeled solved: state solved
value value descendents -consistent. algorithm ends
initial state labeled solved. point states reachable initial state
s0 greedy policy V -consistent. labeling mechanism also guarantees
V proper partial policy respect s0 .
Heuristic Dynamic Programming (Bonet & Geffner, 2003a) second heuristic-search
algorithm supported mGPT solving MDPs. Hdp performs systematic depth-first
searches set states reachable initial state s0 greedy policy
V looking -inconsistent states updating values. top search,
labeling scheme based Tarjans strongly-connected components procedure (Tarjan,
1972), identifies states solved need revisited. initial
value function given heuristic function, algorithm ends initial state
solved. lrtdp, labeling mechanism guarantees V proper respect
s0 .
2.3 Algorithms Real-Time Action Selection
second class algorithms attempt solve given MDP; rather select
actions real-time limited amount processing without offering guarantees
quality resulting policies. Algorithms group include extension
Action Selection Planning algorithm (asp) (Bonet, Loerincs, & Geffner, 1997)
probabilistic domains, basically rtdp algorithm lookahead. Asp, like rtdp,
performs value function updates states cannot get trapped loop. Thus,
although policy delivered asp suboptimal, proper policy; i.e. policy
guaranteed reach goal state.

3. Heuristics
algorithms assume initial value function given heuristic function
provides good cost estimates, particular, lrtdp hdp expect heuristic
admissible. described Pearl (1983), informative admissible heuristics
obtained solving suitable relaxations input problem. Two relaxations
supported mGPT: min-min relaxation, Strips relaxation. first defines
(deterministic) shortest-path problem original state space; second used define
(deterministic) shortest-path problems atom space.2 Thus, first solved
2. Atoms refer propositional symbols used representation language, ppddl case,
define problem. number atoms polynomial size input, size
state space is, general, exponential number atoms.

935

fiBonet & Geffner

time polynomial number states, shortest-path problems defined second
solved time polynomial number atoms. methods yield lower bounds
expected cost goal given state, yet bounds produced min-min
relaxation stronger produced Strips relaxation.
3.1 Min-Min State Relaxation
idea behind min-min relaxation transform input probabilistic problem,
described Bellman equations


X
def

0
0
V (s) = min c(s, a) +
P r(s |s, a)V (s ) ,
(3)
aA(s)

s0

deterministic shortest-path problem Bellman equations form,

Vmin
(s) =

def


min c(s, a) + min {Vmin
(s0 ) : P (s0 |s, a) > 0} .

(4)

aA(s)

level representation language, min-min relaxation built transforming probabilistic operator form:
= h , [ p1 : 1 , . . . , pn : n ] ,

(5)

precondition ith probabilistic effect (with probability
pi ), set independent deterministic operators form:
oi = h , ,

1 n.

(6)

Thus, min-min relaxation one actually choose convenient non-deterministic effect operator, hence, cost relaxation lower bound
expected cost original probabilistic problem.
min-min relaxation deterministic problem solved means
standard path-finding algorithms. example, solved Dijkstras algorithm,
a*, ida*, deterministic version lrtdp (i.e. labeled lrta algorithm (Korf, 1990)).
mGPT provides two methods computing min-min heuristic relaxation:
min-min-ida*, uses ida*, min-min-lrtdp, uses lrtdp. versions
lazy sense heuristic values states computed needed
planner requires them.
3.2 Strips Relaxation
Strips relaxation turn converts deterministic problem obtained min-min
relaxation Strips problem, obtains lower bounds original MDP
computing lower bounds resulting Strips problem using methods developed
classical planning (e.g., Bonet & Geffner, 2001; Haslum & Geffner, 2000; Hoffmann & Nebel,
2001; Edelkamp, 2001; Nguyen & Kambhampati, 2000). methods run polynomial
time number atoms yet, unlike min-min relaxation, require casting minmin relaxation Strips format, conversion that, like conversion ADL Strips
(Gazen & Knoblock, 1997), may require exponential time space (see below).
936

fimGPT: Probabilistic Planner Based Heuristic Search

mGPT, Strips relaxation obtained directly original problem, first
transforming probabilistic operator form:
= h prec, [ p1 : (add1 , del1 ), . . . , pn : (addn , deln ) ] ,

(7)

prec, addi , deli conjunctions literals represents precondition, ith
add list, ith delete list operator respectively, pi probabilities sum
1. order take operators form (7), disjunctive preconditions, conditional
effects, quantifiers removed described Gazen Knoblock (1997).
operators form (7), Strips relaxation generated splitting
operators n independent Strips operators form:
oi = h prec, addi , deli ,

1 n.

(8)

following heuristics implemented mGPT upon Strips relaxation.
first two lower bounds optimal cost Strips relaxation hence
optimal (expected) cost original MDP, third one necessarily lower bound
either cost.
hm heuristics (h-m) (Haslum & Geffner, 2000) heuristics recursively
approximate cost achieving set atoms C initial state cost
achieving costly subset size C. computed shortestpath algorithm graph nodes standing sets atoms,
result values hm (s) estimate cost reaching goal state s. use
option h-m-k mGPT refer hm heuristic = k.
Pattern database heuristics (patterndb) (Edelkamp, 2001) compute optimal costs
relaxations Strips problem defined multi-valued variables
implicit problem (e.g. location block blocksworld domain
implicit multi-valued variable whose possible values either table top
block). heuristic also precomputed once, beginning,
provides lower bound cost arbitrary state goal. pattern
database computed projecting Strips problem respect set atoms
(those define multi-valued variables) solving resulting problem
optimally Dijkstras algorithm. Multiple pattern databases combined
either taking max sum. latter case, pattern database referred
additive.3 use additive pattern databases defined Haslum, Bonet,
Geffner (2005) constraints original problem preserved
projection; something often results stronger heuristics. Patterndb-k refers
pattern database heuristic defined k multi-valued variables.
FF (ff) heuristic implements heuristic function used FF planner (Hoffmann & Nebel, 2001). computed building so-called relaxed planning graph
finding plan it. heuristic number operators plan.
3. conditions required adding two pattern databases result remains admissible.
sufficient condition B = sets B used build projections
respectively.

937

fiBonet & Geffner

relaxed planning graph version graph constructed Graphplan
(Blum & Furst, 1997) delete lists ignored. shown computing
ff heuristic done polynomial time size input problem
(Hoffmann & Nebel, 2001). heuristic however informative non-admissible.
shown below, heuristics plugged directly planning algorithm
used compute informative heuristics. example, patterndb
heuristic used within ida* solve min-min relaxation, gives stronger
heuristic patterndb heuristic. Thus, mGPT implements algorithms heuristics
stackable software components element stack used solve elements
it.

4. Implementation
section gives details implementation mGPT together examples
use. mGPT system implemented C++ upon preliminary parser offered
organizers ipc-4.
4.1 Hash Tables
Perhaps important component modern search-based planners internal
representation states hash tables. Since mGPT uses different search algorithms
hash tables solve given instance (e.g. informative heuristics computed
less informative ones), good internal representations hash table implementation
critical good performance.
grounding atoms operators, state represented ordered list
atoms hold true state. state appear associated different
data multiple hash tables simultaneously. Thus, instead multiples copies
s, mGPT implements system-wide state-hash-table stores representation
states referenced hash tables entries tables simply contain reference
state-hash-table. way, planner saves time space.
Another issue large impact performance average number collisions
hash table. Two points relevant keeping number collisions low:
hashing function size hash table. former, seen
cryptographic hashing functions like md4 behave well even though slower
traditional choices. latter, mGPT uses hash tables whose size equal
large prime number (Cormen, Leiserson, & Rivest, 1990).
4.2 Algorithms Heuristics
algorithm mGPT implemented subclass abstract algorithm class
whose members reference problem and, cases, reference hash table
parameter . Similarly, heuristic mGPT implemented subclass
abstract heuristic class whose members reference problem function
maps states non-negative values. Simple heuristics like constant-zero function
straightforward, others like min-min-lrtdp implemented class whose members are,
addition above, references hash table lrtdp algorithm.
938

fimGPT: Probabilistic Planner Based Heuristic Search

4.3 Examples
main parameters call mGPT -a <algorithm> specifies algorithm
use, -h <heuristic> specifies heuristic function, -e <epsilon>
specifies threshold consistency check. typical call looks like:
mGPT -a lrtdp -h h-m-1 -e .001 <domain> <problem>
instructs mGPT use lrtdp algorithm h-m-1 heuristic = 0.001
domain problem files specified.
h-m-1 heuristic admissible weak. following example shows
compute min-min-lrtdp heuristic using h-m-1 base heuristic:
mGPT -a lrtdp -h "h-m-1|min-min-lrtdp" -e .001 <domain> <problem>
pipe symbol used instruct planner heuristics computed using
heuristics.
Another possibility use mGPT reactive planner decisions taken
on-line respect heuristic function improved time. example,
mGPT -a asp -h ff <domain> <problem>
uses asp algorithm ff heuristic,
mGPT -a asp -h "zero|min-min-ida*" <domain> <problem>
uses asp algorithm min-min-ida* heuristic computed constant-zero
heuristic. combinations algorithms heuristics possible. mGPT also accepts
parameters control initial hash size, weight heuristic function, values dead-end
states, verbosity level, lookahead settings asp, etc.

5. Competition
competition suite consisted 7 probabilistic domains named blocksworld, explodingblocksworld, boxworld, fileworld, tireworld, towers-of-hanoise, zeno. Blocksworld
exploding-blocksworld variations standard blocksworld domain classical planning. Boxworld logistics-like transportation domain. Fileworld file/folder domain
uncertainty present initial situation destination
file set. Tireworld towers-of-hanoise variations classical tireworld domain
towers-of-hanoi. Zeno traveling domain fuel resource.
domains come two variations: goal-oriented version goal
achieved certainty minimizing expected costs, reward-oriented version
involves rewards. mGPT planner handles first type tasks only.
competition used lrtdp algorithm patterndb-1 heuristic,
parameter = 0.001, weight W = 5 heuristic function. cases,
patterndb-1 heuristic poor, planner switched automatically asp
algorithm ff heuristic.

939

fiBonet & Geffner

problem name
blocksworld-5
blocksworld-8
blocksworld-11
blocksworld-15
blocksworld-18
blocksworld-21
exploding-bw
boxworld-c5-b10
boxworld-c10-b10
boxworld-c15-b10
fileworld-30-5
towers-of-hanoise
tireworld-g
tireworld-r
zeno

runs
30
30
30
30



30


30

30
30
30

failed
0
0
0
0



0


0

14
0
0

successful
30
30
30
30



30


30

16
30
30

time
43
60
130
7,706



6,370


2,220

48
39
162

reward
494.1
487.7
465.7
397.2



183.6


57.6

266.6
0
500

Table 1: Results mGPT planner competition problems. table shows
problem name, number runs, number failed successful runs (see text),
time reward averages. dash means mGPT able solve
problem. Times milliseconds.

5.1 Results
competition held client/server model. planner evaluated
problem number runs supervision server. planner initiated
session connecting server interacted exchanging messages.
run consisted actions sent planner whose effects transmitted back
server planner. Thus, current state problem maintained
planner server.
Table 1 shows results mGPT competition problems. problem,
30 runs executed. table shows number runs, number failed runs
(i.e. finished without reaching goal state), number successful runs (i.e.
finished goal states), time reward averages per run.4
blocksworld, problem blocksworld-xx means problem xx blocks, boxworld,
problem boxworld-cxx-byy means problem xx cities yy boxes.
seen table, mGPT solve exploding-bw, larger instances
blocksworld boxworld, also failed approximately half instances
tireworld-g. difficulties encountered mGPT solving problems often
much probabilities involved, domains, particular,
encodings. basic algorithms used mGPT try solve problems
4. competition format reward-based presentation cost-based. straightforward
go one format other.

940

fimGPT: Probabilistic Planner Based Heuristic Search

computing value function -residuals relevant states (those reachable
initial state optimal policy). this, mGPT computes admissible heuristic
function solving either min-min relaxation, Strips relaxation, both. problem
faced approach many instances neither relaxations could
solved. Here, give detailed explanation problems encountered mGPT
different domains. worth noting many difficulties would surface
Strips planner well, even probabilities ignored.
Blocksworld exploding blocksworld: operator encodings preconditions
containing universally-quantified negative literals, result using clear
predicate. example,
(:action pick-up-block-from
:parameters (?top - block ?bottom)
:precondition (and (not (= ?top ?bottom))
(forall (?b - block) (not (holding ?b)))
(on-top-of ?top ?bottom)
(forall (?b - block) (not (on-top-of ?b ?top))))
:effect (and (decrease (reward) 1)
(probabilistic
0.75 (and (holding ?top) (not (on-top-of ?top ?bottom)))
0.25 (when (not (= ?bottom table))
(and (not (on-top-of ?top ?bottom))
(on-top-of ?top table)))))
)

complex encoding standard planning makes atom-based heuristics almost useless. mGPT could solve instances 5, 8, 11 15 blocks
18 21 blocks. exploding blocksworld, mGPT unable
solve parser incomplete parse complex constructs.
Boxworld: encoding contains drive-truck operator moves truck
intended destination probability 0.8 one three wrong destinations
probability 0.2/3 each. encoding specifies unintended effects means
nested conditional effects form
(:action drive-truck
:parameters (?t - truck ?src - city ?dst - city)
:precondition (and (truck-at-city ?t ?src) (can-drive ?src ?dst))
:effect (and (not (truck-at-city ?t ?src))
(probabilistic
0.2 (forall (?c1 - city)
(when (wrong-drive1 ?src ?c1)
(forall (?c2 - city)
(when (wrong-drive2 ?src ?c2)
(forall (?c3 - city)
(when (wrong-drive3 ?src ?c3)
(probabilistic
1/3 (truck-at-city ?t ?c1)
1/3 (truck-at-city ?t ?c2)
1/3 (truck-at-city ?t ?c3))))))))
0.8 (truck-at-city ?t ?dst)))
)
941

fiBonet & Geffner

Strips relaxation, like planner converts ADL-style operators Strips,
suffers exponential blow domain: 10 cities,
thousand operators grounded ADL-operator. set included problems
5, 10 15 cities.
Fileworld: domain, 30 files need filed one 5 different
folders: exact destination determined probabilistically. optimal policy
problem, proper policy, must prescribe action 530 states,
relevant. consequence problem millions relevant states
need stored hash table task compute proper policy.
patterndb-1 heuristic problem informative, revealed analysis
values stored pattern database, thus mGPT switched automatically
asp algorithm ff heuristic.
Towers-of-hanoise: blocksworld domain, encoding complex operators disjunctions universally-quantified negative literals preconditions, complex conditional effects. Yet problem prevented mGPT
solving problem domain bug code implements conditional
effects surface domains.
Tireworld: two versions: goal-based version called tireworld-g
reward-based version called tireworld-r. domain contains multiple dead ends
locations car gets flat tire spare tire available.
dead ends unavoidable; i.e. proper policy problem. trials
reward-based version end successfully since requirement reach goal
position, rather objective maximize accumulated reward. mGPT treated
versions goal-based problems deal directly reward-based
problems.

6. Conclusions
mGPT planner entered probabilistic planning competition combines heuristicsearch algorithms methods obtaining lower bounds deterministic relaxations.
results obtained competition mixed difficulties
selection domains encodings match capabilities mGPT:
mGPT tries compute proper solutions using heuristics derived Strips relaxations.
described, domains could solved due number relevant
states, others due complexity Strips relaxations themselves.
definition good benchmarks MDP solvers, crucial define
constitutes solution bottom line assessing performance. classical
planning, example, solutions plans bottom line given blind-search
algorithms; progress field measured distance bottom line.
probabilistic setting, difficult always clear means
solve problem. This, however, needs defined way, otherwise performance
comparisons meaningful. Indeed, classical setting, one longer compares
optimal non-optimal planners since types planners different: one
provides guarantees apply solutions, provides guarantees

942

fimGPT: Probabilistic Planner Based Heuristic Search

apply one solution only. probabilistic setting even subtle
different types guarantees. example, restrict class MDPs
constitute simplest generalization classical setting task reaching
goal certainty minimizing expected number steps given initial
state s0 methods yield solutions (policies) ensure goal
reached certainty finite number steps (not necessarily optimal), methods
guarantees. types methods necessary practice, yet crucial
make distinction among identify useful benchmarks class.
methods yield optimal policies, least policies finite expected costs, standard
dynamic programming methods like value iteration provide useful bottom-line reference
assessing performance. case, believe useful benchmarks need defined
taking account types tasks various algorithms aim solve,
types guarantees, any, provide solutions.
GPT mGPT available download http://www.ldc.usb.ve/bonet.
Acknowledgements
mGPT built upon parser developed John Asmuth Rutgers University
Hakan Younes Carnegie Mellon University. also thank David E. Smith comments helped us improve note.

References
Barto, A., Bradtke, S., & Singh, S. (1995). Learning act using real-time dynamic programming. Artificial Intelligence, 72, 81138.
Bertsekas, D. (1995). Dynamic Programming Optimal Control, (2 Vols). Athena Scientific.
Blum, A., & Furst, M. (1997). Fast planning planning graph analysis. Artificial
Intelligence, 90, 281300.
Bonet, B., & Geffner, H. (2000). Planning incomplete information heuristic search
belief space. Chien, S., Kambhampati, S., & Knoblock, C. (Eds.), Proc. 6th
International Conf. Artificial Intelligence Planning Scheduling, pp. 5261,
Breckenridge, CO. AAAI Press.
Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129 (1
2), 533.
Bonet, B., & Geffner, H. (2003a). Faster heuristic search algorithms planning
uncertainty full feedback. Gottlob, G. (Ed.), Proc. 18th International Joint
Conf. Artificial Intelligence, pp. 12331238, Acapulco, Mexico. Morgan Kaufmann.
Bonet, B., & Geffner, H. (2003b). Labeled RTDP: Improving convergence real-time
dynamic programming. Giunchiglia, E., Muscettola, N., & Nau, D. (Eds.), Proc.
13th International Conf. Automated Planning Scheduling, pp. 1221, Trento,
Italy. AAAI Press.

943

fiBonet & Geffner

Bonet, B., Loerincs, G., & Geffner, H. (1997). robust fast action selection mechanism
planning. Kuipers, B., & Webber, B. (Eds.), Proc. 14th National Conf.
Artificial Intelligence, pp. 714719, Providence, RI. AAAI Press / MIT Press.
Cormen, T., Leiserson, C., & Rivest, R. (1990). Introduction Algorithms. MIT Press.
Edelkamp, S. (2001). Planning pattern databases. Cesta, A. (Ed.), Proc. 6th
European Conf. Planning, pp. 1324, Toledo, Spain. Springer: LNCS.
Gazen, B., & Knoblock, C. (1997). Combining expressiveness UCPOP
efficiency Graphplan. Steel, S., & Alami, R. (Eds.), Proc. 4th European Conf.
Planning, pp. 221233, Toulouse, France. Springer: LNCS.
Haslum, P., Bonet, B., & Geffner, H. (2005). New admissible heuristics domainindependent planning. Veloso, M., & Kambhampati, S. (Eds.), Proc. 20 National
Conf. Artificial Intelligence, pp. 11631168, Pittsburgh, PA. AAAI Press / MIT
Press.
Haslum, P., & Geffner, H. (2000). Admissible heuristic optimal planning. Chien, S.,
Kambhampati, S., & Knoblock, C. (Eds.), Proc. 6th International Conf. Artificial
Intelligence Planning Scheduling, pp. 140149, Breckenridge, CO. AAAI Press.
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation
heuristic search. Journal Artificial Intelligence Research, 14, 253302.
Korf, R. (1990). Real-time heuristic search. Artificial Intelligence, 42 (23), 189211.
Nguyen, X., & Kambhampati, S. (2000). Extracting effective admissible state-space
heuristics planning graph. Kautz, H., & Porter, B. (Eds.), Proc. 17th
National Conf. Artificial Intelligence, pp. 798805, Austin, TX. AAAI Press /
MIT Press.
Pearl, J. (1983). Heuristics. Morgan Kaufmann.
Tarjan, R. E. (1972). Depth first search linear graph algorithms. SIAM Journal
Computing, 1 (2), 146160.

944

fiJournal Artificial Intelligence Research 24 (2005) 195-220

Submitted 11/04; published 08/05

Perseus: Randomized Point-based
Value Iteration POMDPs
Matthijs T. J. Spaan
Nikos Vlassis

mtjspaan@science.uva.nl
vlassis@science.uva.nl

Informatics Institute, University Amsterdam
Kruislaan 403, 1098 SJ Amsterdam, Netherlands

Abstract
Partially observable Markov decision processes (POMDPs) form attractive principled framework agent planning uncertainty. Point-based approximate techniques POMDPs compute policy based finite set points collected advance
agents belief space. present randomized point-based value iteration algorithm called Perseus. algorithm performs approximate value backup stages, ensuring
backup stage value point belief set improved; key
observation single backup may improve value many belief points. Contrary
point-based methods, Perseus backs (randomly selected) subset
points belief set, sufficient improving value belief point set.
show idea extended dealing continuous action spaces.
Experimental results show potential Perseus large scale POMDP problems.

1. Introduction
major goal Artificial Intelligence build intelligent agents (Russell & Norvig, 2003).
intelligent agent, whether physical simulated, able autonomously perform
given task, often characterized sensethinkact loop: uses sensors observe
environment, considers information decide do, executes chosen
action. agent influences environment acting detect effect actions
sensing: environment closes loop. work interested computing
plan maps sensory input optimal action execute given task. consider
types domains agent uncertain exact consequence actions.
Furthermore, cannot determine full certainty state environment
single sensor reading, i.e., environment partially observable agent.
Planning kinds uncertainty challenging problem requires reasoning possible futures given possible histories. Partially observable Markov decision
processes (POMDPs) provide rich mathematical framework acting optimally
partially observable stochastic environments (Dynkin, 1965; Astrom, 1965; Aoki, 1965;
Sondik, 1971; Lovejoy, 1991; Kaelbling, Littman, & Cassandra, 1998). POMDP defines sensor model specifying probability observing particular sensor reading
specific state stochastic transition model captures uncertain outcome
executing action. agents task defined reward receives time step
goal maximize discounted cumulative reward. Assuming discrete models,
POMDP framework allows capturing uncertainty introduced transition
observation model defining operating belief state agent. belief
c
2005
AI Access Foundation. rights reserved.

fiSpaan & Vlassis

state probability distribution states summarizes information regarding
past.
use belief states allows one transform original discrete state POMDP
continuous state Markov decision process (MDP), turn solved
corresponding MDP techniques (Bertsekas & Tsitsiklis, 1996). However, optimal value
function POMDP exhibits particular structure (it piecewise linear convex)
one exploit order facilitate solving. Value iteration, instance, method
solving POMDPs builds sequence value function estimates converge
optimal value function current task (Sondik, 1971). value function
parameterized finite number hyperplanes, vectors, belief space,
partition belief space finite amount regions. vector maximizes value
function certain region action associated it, optimal action
take beliefs region. Computing next value function estimatelooking one
step deeper futurerequires taking account possible actions agent
take subsequent observations may receive. Unfortunately, leads
exponential growth vectors planning horizon. Many computed vectors
useless sense maximizing region empty, identifying
subsequently pruning expensive operation.
Exact value iteration algorithms (Sondik, 1971; Cheng, 1988; Kaelbling et al., 1998)
search value iteration step complete belief simplex minimal set belief
points generate necessary set vectors next horizon value function.
typically requires linear programming therefore costly high dimensions. Zhang
Zhang (2001) argued value iteration still converges optimal value function
exact value iteration steps interleaved approximate value iteration steps
new value function upper bound previously computed value function.
results speedup total algorithm, however, linear programming needed
order ensure new value function upper bound previous one
complete belief simplex. general, computing exact solutions POMDPs
intractable problem (Papadimitriou & Tsitsiklis, 1987; Madani, Hanks, & Condon, 1999),
calling approximate solution techniques (Lovejoy, 1991; Hauskrecht, 2000).
practical tasks one would like compute solutions parts belief
simplex reachable, i.e., actually encountered interacting
environment. recently motivated use approximate solution techniques
focus use sampled set belief points planning performed (Hauskrecht,
2000; Poon, 2001; Roy & Gordon, 2003; Pineau, Gordon, & Thrun, 2003; Spaan & Vlassis,
2004), possibility already mentioned Lovejoy (1991). idea instead
planning complete belief space agent (which intractable large state
spaces), planning carried limited set prototype beliefs
sampled letting agent interact (randomly) environment. PBVI (Pineau
et al., 2003), instance, builds successive estimates value function updating
value gradient points (dynamically growing) belief set.
work describe Perseus, randomized point-based value iteration algorithm
POMDPs (Vlassis & Spaan, 2004; Spaan & Vlassis, 2004). Perseus operates large
set beliefs gathered simulating random interactions agent
POMDP environment. belief set number value backup stages performed.
196

fiPerseus: Randomized Point-based Value Iteration POMDPs

algorithm ensures backup stage value point belief set
improved (or least decrease). Contrary point-based methods, Perseus
backs random subset belief points; key observation single backup
may improve value many points set. allows us compute value functions
consist small number vectors (relative belief set size), leading
significant speedups. evaluate performance Perseus benchmark problems
literature, show competitive methods terms solution
quality computation time.
Furthermore, extend Perseus compute plans agents continuous
(or large discrete) set actions disposal (Spaan & Vlassis, 2005). Examples
include navigating arbitrary location, rotating pan-and-tilt camera desired
angle. work POMDP solution techniques targets discrete action spaces; exceptions
include application particle filter continuous state action space (Thrun,
2000) certain policy search methods (Ng & Jordan, 2000; Baxter & Bartlett, 2001).
report experiments domain agent equipped proximity sensors
move continuous heading distance, present experimental results
navigation task involving mobile robot omnidirectional vision perceptually
aliased office environment.
remainder paper structured follows: Section 2 review POMDP
framework AI perspective, discuss exact methods solving POMDPs
tractability problems. Next, outline class approximate value iteration
algorithms, so-called point-based techniques. Section 3 describe discuss
Perseus algorithm, well extension continuous action spaces. Related work
approximate techniques POMDP planning discussed Section 4. present
experimental results several problem domains Section 5. Finally, wrap
conclusions Section 6.

2. Partially Observable Markov Decision Processes
partially observable Markov decision process (POMDP) models repeated interaction
agent stochastic environment, parts hidden agents view.
agents goal perform task choosing actions fulfill task best. Stated
otherwise, agent compute plan optimizes given performance measure.
assume time discretized time steps equal length, start
step agent execute action. time step agent also receives scalar
reward environment, performance measure directs agent maximize
cumulative reward gather. reward signal allows one define task
agent, e.g., one give agent large positive reward accomplishes certain
goal small negative reward action leading it. way agent
steered toward finding plan let accomplish goal fast possible.
POMDP framework models stochastic environments agent uncertain
exact effect executing certain action. uncertainty captured probabilistic transition model case fully observable Markov decision process (MDP)
(Sutton & Barto, 1998; Bertsekas & Tsitsiklis, 1996). MDP defines transition model
specifies probabilistic effect action changes state. Extending
197

fiSpaan & Vlassis

MDP setting, POMDP also deals uncertainty resulting agents imperfect sensors. allows planning environments partially observable
agent, i.e., environments agent cannot determine full certainty
true state environment. general partial observability stems two sources:
(1) multiple states give sensor reading, case agent sense limited
part environment, (2) sensor readings noisy: observing state
result different sensor readings. partial observability lead perceptual aliasing: different parts environment appear similar agents sensor system,
require different actions. POMDP captures partial observability probabilistic
observation model, relates possible observations states.
formally, POMDP assumes time step environment state
S, agent takes action receives reward r(s, a) environment
result action, environment switches new state s0 according
known stochastic transition model p(s0 |s, a). Markov property entails s0
depends previous state action a. agent perceives observation
O, may conditional action, provides information state s0
known stochastic observation model p(o|s, a). sets S, O, assumed
discrete finite (but generalize continuous Section 3.3).
order agent choose actions successfully partially observable environments form memory needed, observations agent receives provide
unique identification s. Given transition observation model POMDP
transformed belief-state MDP: agent summarizes information past
using belief vector b(s). belief b probability distribution S, forms
Markovian signal planning task. beliefs contained (|S| 1)-dimensional
simplex , means represent belief using |S| 1 numbers. POMDP
problem assumes initial belief b0 , instance set uniform distribution
states (representing complete ignorance regarding initial state environment). Every time agent takes action observes o, belief updated
Bayes rule:
p(o|s0 , a) X
p(s0 |s, a)b(s),
(1)
boa (s0 ) =
p(o|a, b)
sS
P
P
p(o|a, b) = s0 p(o|s0 , a) sS p(s0 |s, a)b(s) normalizing constant.
discussed above, goal agent choose actions fulfill task
well possible, i.e., compute optimal plan. plan called policy (b)
maps beliefs actions. Note that, contrary MDPs, policy (b) function
continuous set probability distributions S. policy characterized
value function V : R defined expected future discounted reward
V (b) agent gather following starting belief b:
V (b) = E


hX
t=0

fi

fi
r(bt , (bt ))fib0 = b ,

(2)

P
r(bt , (bt )) = sS r(s, (bt ))bt (s), discount rate, 0 < 1. discount
rate ensures finite sum usually chosen close 1. policy maximizes V
called optimal policy ; specifies b optimal action execute
198

fiPerseus: Randomized Point-based Value Iteration POMDPs

current step, assuming agent also act optimally future time steps. value
optimal policy defined optimal value function V , satisfies Bellman
optimality equation V = HV :


V (b) = max
aA

hX

r(s, a)b(s) +

sS

X

p(o|a, b)V





(boa )

,

(3)

oO

boa given (1), H Bellman backup operator (Bellman, 1957). (3)
holds every b ensured solution optimal.
V approximated iterating number stages, see next
section, stage considering step future. problems finite
planning horizon V piecewise linear convex (PWLC) (Smallwood & Sondik,
1973), infinite horizon tasks V approximated arbitrary well PWLC
value function. parameterize value function Vn stage n finite set vectors
(hyperplanes) {ni }, = 1, . . . , |Vn |. Additionally, vector action a(ni )
associated, optimal one take current step. vector defines
region belief space vector maximizing element Vn .
regions form partition belief space, induced piecewise linearity value
function. Examples value function two state POMDP shown Fig. 1(a)
|Vn |
stage n, value belief b given
1(d). Given set vectors {ni }i=1
Vn (b) = max b ni ,
{in }i

(4)

() denotes inner product. gradient value function b given
vector nb = arg max{in }i b ni , policy b given (b) = a(nb ).
2.1 Exact Value Iteration
Computing optimal plan agent means solving POMDP, classical method
value iteration (Puterman, 1994). POMDP framework, value iteration involves
approximating V applying exact dynamic programming operator H above,
approximate operator H, initially piecewise linear convex value function V0 .
H, many commonly used H, produced intermediate estimates V1 , V2 , . . .
also piecewise linear convex. main idea behind many value iteration algorithms
POMDPs given value function Vn particular belief point b
b
easily compute vector n+1
HVn

b
,
n+1
= arg max b n+1

(5)

{in+1 }i

|HV |


{n+1
}i=1 n (unknown) set vectors HVn . denote operation
b
n+1 = backup(b). computes optimal vector given belief b back-projecting
vectors current horizon value function one step future returning
vector maximizes value b. particular, defining ra (s) = r(s, a) using (1),

199

fiSpaan & Vlassis

(3), (4) have:
h

X
Vn+1 (b) = max b ra +
p(o|a, b)Vn (boa )


(6)




h
X
X
boa (s0 )ni (s0 )
p(o|a, b) max
= max b ra +

(7)

h

X
X
X
= max b ra +
max
p(o|s0 , a)
p(s0 |s, a)b(s)ni (s0 )

(8)

h

X

= max b ra +
max b ga,o
,

(9)



{in }i











{in }i

s0



s0

}
{ga,o




ga,o
(s) =

X

p(o|s0 , a)p(s0 |s, a)ni (s0 ).

(10)

s0

Applying identity maxj b j = b arg maxj b j (9) twice, compute vector
backup(b) follows:
backup(b) = arg max b gab ,



(11)

{gab }aA

gab = ra +

X



.
arg max b ga,o

(12)

}
{ga,o


Although computing vector backup(b) given b straightforward, locating
(minimal) set points b required compute vectors b backup(b) HVn costly.
b region belief space nb maximal, family algorithms
tries identify regions (Sondik, 1971; Cheng, 1988; Kaelbling et al., 1998).
corresponding b region called witness point, testifies existence
region. Another set exact POMDP value iteration algorithms focus
searching belief space, instead consider enumerating possible vectors HVn
pruning useless vectors (Monahan, 1982; Cassandra, Littman, & Zhang, 1997).
example exact value iteration let us consider straightforward way
computing HVn due Monahan (1982). involves calculating possible ways HVn
could constructed, exploiting known structure value function. operate
independent particular b (12) longer applied. Instead
o:
include ways selecting ga,o
HVn =

[

Ga , Ga =




Mn 1

ra + ga,o
,
|O|



(13)

L

denotes cross-sum operator.1 Unfortunately, stage number vectors
exponential |O| generated: |A||Vn ||O| . regions many generated vectors
empty vectors useless such, identifying subsequently pruning
requires linear programming introduces considerable additional cost (e.g.,
state space large).
1. Cross-sum sets defined as:

L

k

Rk = R1 R2 . . . Rk , P Q = { p + q | p P, q Q }.

200

fiPerseus: Randomized Point-based Value Iteration POMDPs

Zhang Zhang (2001) proposed alternative approach exact value iteration,
designed speed exact value iteration step. turns value iteration still
converges optimal value function exact value update steps interleaved
approximate update steps new value function Vn+1 computed Vn

Vn (b) Vn+1 (b) HVn (b),
b .
(14)
additionally requires value function appropriately initialized, choosing
1
mins,a r(s, a). vector
V0 single vector components equal 1
represents minimum cumulative discounted reward obtainable POMDP,
guaranteed V . Zhang Zhang (2001) compute Vn+1 backing witness
points Vn number steps. saw above, backing set belief points
relatively cheap operation. Thus, given Vn , number vectors HVn created
applying backup witness points Vn , set linear programs solved
ensure Vn+1 (b) Vn (b), b . repeated number steps,
exact value update step takes place. authors demonstrate experimentally
combination approximate exact backup steps speed exact value iteration.
general, however, computing optimal planning solutions POMDPs intractable
problem reasonably sized task (Papadimitriou & Tsitsiklis, 1987; Madani et al.,
1999). calls approximate solution techniques. describe next recent line
research approximate POMDP algorithms focus planning fixed set
belief points.
2.2 Approximate Value Iteration
major cause intractability exact POMDP solution methods aim computing optimal action every possible belief point . instance, use (13)
end series value functions whose size grows exponentially planning
horizon. natural way sidestep intractability settle computing approximate solution considering finite set belief points. backup stage reduces
applying (11) fixed number times, resulting small number vectors (bounded
size belief set). motivation using approximate methods ability
compute successful policies much larger problems, compensates loss
optimality.
approximate POMDP value iteration methods operating fixed set points
explored Lovejoy (1991) subsequent works (Hauskrecht, 2000; Poon, 2001; Pineau
et al., 2003; Spaan & Vlassis, 2004). Pineau et al. (2003) instance, use approximate
backup operator HPBVI instead H, computes value backup stage set
[
HPBVI Vn =
backup(b)
(15)
bB

using fixed set belief points B. general assumption underlying so-called
point-based methods updating value also gradient (the
vector) b B, resulting policy generalize well effective beliefs
outside set B. Whether assumption realistic depends POMDPs
structure contents B, intuition many problems set
201

fiSpaan & Vlassis

reachable beliefs (reachable following arbitrary policy starting b0 ) forms low
dimensional manifold belief simplex, thus covered densely enough
relatively small number belief points.
Crucial control quality computed approximate solution makeup B.
number schemes build B proposed. instance, one could use regular
grid belief simplex, computed, e.g., Freudenthal triangulation (Lovejoy, 1991).
options include taking extreme points belief simplex use random grid
(Hauskrecht, 2000; Poon, 2001). alternative scheme include belief points
encountered simulating POMDP: generate trajectories
belief space sampling random actions observations time step (Lovejoy, 1991;
Hauskrecht, 2000; Poon, 2001; Pineau et al., 2003; Spaan & Vlassis, 2004). sampling
scheme focuses contents B beliefs actually encountered
experiencing POMDP model.
PBVI algorithm (Pineau et al., 2003) instance point-based POMDP
algorithm. PBVI starts selecting small set beliefs B0 , performs number backup
stages (15) B0 , expands B0 B1 sampling beliefs, performs series
backups, repeats process satisfactory solution found (or
allowed computation time expires). set Bt+1 grows simulating actions every
b Bt , maintaining new belief points furthest away points
already Bt+1 . scheme heuristic let Bt cover wide area belief space,
comes cost requires computing distances b Bt . backing
b Bt PBVI algorithm generates stage approximately |Bt | vectors,
lead slow performance domains requiring large Bt .
next section present point-based POMDP value iteration method
require backing b B. compute backups subset B only,
seeing computed solution effective complete set B. result
limit growth number vectors successive value function estimates,
leading significant speedups.

3. Randomized Point-based Backup Stages
introduced POMDP framework models agents inhabiting stochastic
environments partially observable them, discussed exact approximate
methods computing successful plans agents. describe Perseus,
approximate solution method capable computing competitive solutions large POMDP
domains.
3.1 Perseus
Perseus approximate point-based value iteration algorithm POMDPs (Vlassis &
Spaan, 2004; Spaan & Vlassis, 2004). value update scheme Perseus implements
randomized approximate backup operator HPerseus increases (or least
decrease) value belief points B. operator efficiently
implemented POMDPs given shape value function. key idea
value backup stage improve value points belief set
updating value gradient (randomly selected) subset points.
202

fiPerseus: Randomized Point-based Value Iteration POMDPs

backup stage, given value function Vn , compute value function Vn+1 improves
value b B, i.e., build value function Vn+1 = HPerseus Vn upper bounds
Vn B (but necessarily would require linear programming):
Vn (b) Vn+1 (b),

b B.

(16)

first let agent randomly explore environment collect set B reachable
belief points, remains fixed throughout complete algorithm. initialize value
1
mins,a r(s, a) (Zhang &
function V0 single vector components equal 1
Zhang, 2001). Starting V0 , Perseus performs number backup stages
convergence criterion met. backup stage defined follows (where B auxiliary
set containing non-improved points):
Perseus backup stage: Vn+1 = HPerseus Vn
1. Set Vn+1 = . Initialize B B.
2. Sample belief point b uniformly random B compute = backup(b).
3. b Vn (b) add Vn+1 , otherwise add 0 = arg max{in }i b ni Vn+1 .
4. Compute B = {b B : Vn+1 (b) < Vn (b)}.
5. B = stop, else go 2.
Often, small number vectors sufficient improve Vn (b) b B, especially
first steps value iteration. idea compute vectors randomized
greedy manner sampling B, increasingly smaller subset B. keep track
set non-improved points B consisting b B whose new value Vn+1 (b)
still lower Vn (b). start backup stage, Vn+1 set means B
initialized B, indicating b B still need improved backup stage.
long B empty, sample point b B compute = backup(b).
improves value b (i.e., b Vn (b) step 3), add Vn+1 update
Vn+1 (b) b B computing inner product new . hope
improves value many points B, points removed B.
long B empty sample belief points add vectors.
ensure termination backup stage enforce B shrinks
adding vectors, i.e., actually improves least value b generated
it. (i.e., b < Vn (b) step 3), ignore insert copy maximizing
vector b Vn Vn+1 . Point b considered improved removed B
step 4, together belief points vector maximizing
one Vn . procedure ensures B shrinks backup stage terminate.
pictorial example backup stage presented Fig. 1.
Perseus performs backup stages convergence criterion met. pointbased methods several convergence criteria considered, one could instance bound
difference successive value function estimates maxbB (Vn+1 (b) Vn (b)). Another option would track number policy changes: number b B
different optimal action Vn compared Vn+1 (Lovejoy, 1991).
203

fiSpaan & Vlassis

replacemen
Vn

(1, 0)

Vn+1

b1 b2 b3 b4 b5

b6 b7 (0, 1)

(1, 0)

(0, 1)

b6
(b)

(a)

Vn+1

Vn+1

(1, 0)

(1, 0)

(0, 1)

(0, 1)

b3
(c)

(d)

Figure 1: Example Perseus backup stage two state POMDP. belief space
depicted x-axis y-axis represents V (b). Solid lines ni vectors

current stage n dashed lines n1
vectors previous
stage. operate B 7 beliefs, indicated tick marks. backup
stage computing Vn+1 Vn proceeds follows: (a) value function stage n;
(b) start computing Vn+1 sampling b6 , add = backup(b6 ) Vn+1
improves value b6 b7 ; (c) sample b3 {b1 , . . . , b5 }, add backup(b3 )
Vn+1 improves b1 b5 ; (d) value b B improved,
backup stage finished.

3.2 Discussion
key observation underlying Perseus algorithm belief b backed
up, resulting vector improves V (b) often also value many
belief points B. results value functions relatively small number vectors
(as compared to, e.g., Poon, 2001; Pineau et al., 2003). Experiments show indeed
number vectors grows modestly number backup stages (|Vn | |B|).
practice means afford use much larger B point-based
methods, positive effect approximation accuracy dictated
bounds Pineau et al. (2003). Furthermore, compared methods build
set B based various heuristics (Pineau et al., 2003; Smith & Simmons, 2004),
build-up B cheap requires sampling random trajectories starting b0 .
Moreover, duplicate entries B affect probability particular b
sampled value update stages, size Vn .
204

fiPerseus: Randomized Point-based Value Iteration POMDPs

alternative using single fixed set B collected following fixed policy
beginning algorithm, would resample new Bt every t-th backup
stage (or fixed intervals) following recent policy. approach could
justified fact agent executing optimal policy probably visit
(small) subset beliefs B. tested scheme would
affect solution quality Perseus trade-offs achieve additional
computational cost sampling multiple sets B. note similar off-policy learning
using fixed set sampled states also adopted recent algorithms like
LSPI (Lagoudakis & Parr, 2003) PSDP (Bagnell, Kakade, Ng, & Schneider, 2004).
backups Perseus fixed set B viewed particular instance
asynchronous dynamic programming (Bertsekas & Tsitsiklis, 1989). asynchronous dynamic programming algorithms full sweeps state space made, order
states backed arbitrary. allows algorithm focus backups
may high potential impact, instance prioritized sweeping algorithm solving fully observable MDPs (Moore & Atkeson, 1993; Andre, Friedman, &
Parr, 1998). drawback notion exact planning horizon somewhat lost:
general, performing n backup stages computed plan considering n
steps future, less. backing non-improved belief points asynchronously
Perseus focuses interesting regions (reachable) belief space, sampling
random ensures eventually b B taken account. ensure
value particular belief point never decreases, guaranteed Perseus converge: proof requires observing every added vector always V (Poon,
2001; Vlassis & Spaan, 2004). Moreover, explained above, Perseus handle large
belief sets B, thus obviating use dynamic belief point selection strategies like
proposed Hauskrecht (2000), Poon (2001), Pineau et al. (2003). Note
parameter set user size B; however, complexity resulting
policy seems mildly dependent size B.
interesting issue many new vectors generated backup stage
Perseus, may affect speed convergence algorithm. general,
smaller size |Vn | value function, faster backups (since backup operator
linear dependence |Vn |). hand, two consecutive value functions may
differ arbitrarily sizeand observed cases new value function
fewer vectors old value functionwhich makes hard derive bounds
speed convergence Perseus complicates analysis involved trade-offs.
mainly identified two cases small number new vectors added
value function. first case initial backup stages, V0
initialized low (e.g., large large negative immediate reward).
case single vector may improve points, number backup stages, value
function reached sufficient level. second case near convergence,
value function almost converged certain regions belief space. Sampling belief
point region result (near) copy old vector. Whereas former
case provides evidence value function initialized low (and adding
single vector efficient way correct this), latter case may viewed providing
evidence convergence Perseus.
205

fiSpaan & Vlassis

3.3 Extension Large Continuous Action Spaces
attractive feature Perseus naturally extended large
continuous action spaces, due improveonly principle backup stage. Note
backup operator (11) involves maximization actions A.
action space finite small, one cache advance transition, observation,
reward models A, therefore achieve optimized implementation
backup operator. large continuous action spaces, full maximization
actions (11) clearly infeasible, one resort sampling-based techniques.
idea replace full maximization actions sampled max operator
performs maximization random subset (Szepesvari & Littman, 1996).
also means one compute models fly sampled action,
requires algorithm (a parameterized model family) generate needed
models action given input. generated models cached later
use case action considered future iterations (see experimental
section using so-called old actions).
use sampled max operator well suited backup scheme
Perseus require values belief points decrease two
consecutive backup stages. particular, replace backup operator (11)
new backup operator = backup0 defined follows (Spaan & Vlassis, 2005):
backup0 (b) = arg max b gab ,

(17)

{gab }aA0

b

A0b random set actions drawn A, gab defined (12).
sampled action A0b generate POMDP models fly mentioned above,
models compute required vectors gab used backup0 .
backup0 operator simply replace backup operator step 2 Section 3.1. full maximization case, need check step 3 whether
vectors generated actions A0b improves value particular belief point.
not, keep old vector associated action selected previous
backup stage. Concerning sample complexity backup0 operator, derive
simple bounds involve number actions drawn probability find good
action (good terms value improvement b). easily show
probability least 1 , best action among n = |A0b | actions selected uniformly
random among best fraction actions A, n dlog / log(1 )e.
practice various sampling schemes possible, vary way A0b constructed. identified number proposal distributions sample
actions: (1) uniform A, (2) Gaussian distribution centered best known action
particular b, i.e., a(nb ), (3) Dirac distribution a(nb ). latter two take
account policy computed far focusing current action associated
input belief b (as recorded Vn ), sampling uniformly random uses
knowledge. Actions sampled uniformly random viewed exploring actions,
two distributions exploiting current knowledge. select makeup
A0b , choose combination distributions mentioned above, allowing us
explore exploit time. experiments (see Section 5.2) implement
backup0 operator using number different combinations analyze effects.
206

fiPerseus: Randomized Point-based Value Iteration POMDPs

4. Related Work
Section 2.2 reported class approximate solution techniques POMDPs
focus computing value function approximation based fixed set prototype belief
points. broaden picture approximate POMDP solution methods.
related overview provided Hauskrecht (2000).
heuristic control strategies proposed rely solution
underlying MDP. popular technique QMDP (Littman, Cassandra, & Kaelbling, 1995),
simple approximation technique treats POMDP fully observable
solves MDP, e.g., using value iteration.
resulting Q(s, a) values used
P
define control policy (b) = arg maxa b(s)Q(s, a). QMDP effective
domains, policies computes take informative actions, QMDP
solution assumes uncertainty regarding state disappear taking one
action. such, QMDP policies fail domains repeated information gathering
necessary.
One way sidestep intractability exact POMDP value iteration grid
belief simplex, using either fixed grid (Lovejoy, 1991; Bonet, 2002) variable grid
(Brafman, 1997; Zhou & Hansen, 2001). Value backups performed every grid point,
value grid point preserved gradient ignored. value
non-grid points defined interpolation rule. grid based methods differ mainly
grid points selected shape interpolation function takes. general,
regular grids scale well problems high dimensionality non-regular grids
suffer expensive interpolation routines.
alternative computing (approximate) value function policy search:
methods search good policy within restricted class controllers. instance, policy iteration (Hansen, 1998b) bounded policy iteration (BPI) (Poupart & Boutilier,
2004) search space (bounded-size) stochastic finite state controllers performing policy iteration steps. options searching policy space include gradient
ascent (Meuleau, Kim, Kaelbling, & Cassandra, 1999; Kearns, Mansour, & Ng, 2000; Ng
& Jordan, 2000; Baxter & Bartlett, 2001; Aberdeen & Baxter, 2002) heuristic methods like stochastic local search (Braziunas & Boutilier, 2004). particular, Pegasus
method (Ng & Jordan, 2000) estimates value policy simulating (bounded)
number trajectories POMDP using fixed random seed, takes steps
policy space order maximize value. Policy search methods demonstrated
success several cases, searching policy space often difficult prone
local optima.
Another approach solving POMDPs based heuristic search (Satia & Lave, 1973;
Hansen, 1998a; Smith & Simmons, 2004). Defining initial belief b0 root node,
methods build tree branches (a, o) pairs, recursively induces new
belief node. methods bear similarity Perseus since also focus reachable
beliefs b0 . However, differ way belief points selected back up;
methods branch bound techniques used maintain upper lower bounds
expected return fringe nodes search tree. Hansen (1998a) proposes policy
iteration method represents policy finite state controller, uses
belief tree focus search areas belief space controller
207

fiSpaan & Vlassis

Name

|S|

|O|

|A|

Tiger-grid
Hallway
Hallway2
Tag
Continuous navigation
cTRC

33
57
89
870
200
200

17
21
17
30
16
10

5
5
5
5



Table 1: Characteristics problem domains.
likely improved. However, applicability large problems limited use full
dynamic programming updates. HSVI (Smith & Simmons, 2004) approximate value
iteration technique performs heuristic search belief space beliefs
update bounds, similar work Satia Lave (1973). alternative
recent approach maintaining uncertainty estimates approximate value function
based Gaussian Processes (Tuttle & Ghahramani, 2004).
Compression techniques applied large POMDPs reduce dimensionality
belief space, facilitating computation approximate solution. Roy, Gordon,
Thrun (2005) apply Exponential family PCA sample set beliefs find lowdimensional representation, based approximate solution sought.
non-linear compression effective, requires learning reward transition
model reduced space. model learned, one compute approximate
solution original POMDP using, e.g., MDP value iteration. Alternatively linear
compression techniques used preserve shape value function (Poupart
& Boutilier, 2003). property desirable allows one exploit existing
POMDP machinery. instance, linear compression applied preprocessing
step BPI (Poupart & Boutilier, 2005) well Perseus (Poupart, 2005).
literature POMDPs continuous actions still relatively sparse (Thrun,
2000; Ng & Jordan, 2000; Baxter & Bartlett, 2001). Thrun (2000) applies real-time dynamic
programming POMDP continuous state action space. work beliefs
represented sets samples drawn state space, Q(b, a) values
approximated nearest-neighbor interpolation (growing) set prototype values
updated on-line exploration use sampling-based Bellman backups.
Pegasus also handle continuous action spaces, cost sample complexity
polynomial size state space (Theorem 3, Ng & Jordan, 2000).

5. Experiments
show experimental results applying Perseus benchmark problems
POMDP literature, present two POMDP domains testing Perseus problems
continuous action spaces. Table 5 summarizes domains terms size
S, A. belief set gathered simulating trajectories interactions
agent POMDP environment starting random state sampled b0 ,
208

fiPerseus: Randomized Point-based Value Iteration POMDPs

time step agent picked action uniformly random. domains discount
factor set 0.95.
5.1 Discrete Action Spaces
Hallway, Hallway2 Tiger-grid problems (introduced Littman et al., 1995)
maze domains commonly used test scalable POMDP solution techniques
(Littman et al., 1995; Brafman, 1997; Zhou & Hansen, 2001; Pineau et al., 2003; Smith &
Simmons, 2004; Spaan & Vlassis, 2004; Poupart, 2005). Tag domain (Pineau et al.,
2003) order magnitude larger first three problems, recent benchmark problem (Pineau et al., 2003; Smith & Simmons, 2004; Braziunas & Boutilier, 2004;
Poupart & Boutilier, 2004; Spaan & Vlassis, 2004; Poupart, 2005).
5.1.1 Benchmark Mazes
Littman et al. (1995) introduced three benchmark maze domains: Tiger-grid, Hallway,
Hallway2. navigation tasks: objective agent reach
designated goal state quickly possible. agent observes possible combination
presence wall four directions plus unique observation indicating goal
state; Hallway problem three landmarks also available. step
agent take one five actions: {stay place, move forward, turn right, turn
left, turn around}. transition observation model noisy. Table 2(a)
(c) compares performance Perseus algorithms. problem
sampled set B 1,000 beliefs, executed Perseus 10 times problem using
different random seeds. average expected discounted reward R computed 1,000
trajectories starting random states (drawn according b0 ) 10 Perseus
runs, following computed policy. reported reward R average
10,000 trajectories. Perseus reaches competitive control quality using small number
vectors resulting considerable speedup.2
5.1.2 Tag
goal Tag domain, described Pineau et al. (2003), robot search
moving opponent robot tag it. chasing robot cannot observe opponent
occupy position, time execute tag action order
win game, receive reward 10. opponent present
location, reward 10, robot penalized 1 reward
motion action takes. opponent tries escape tagged moving away
chasing robot, however, 0.2 probability remaining location.
chasing opponent robot start random location. chasing robot perfect
information regarding position movement actions {north, east, south, west}
deterministic. state space represented cross-product states
two robots. robots located one 29 positions depicted Fig. 2(a),
opponent also tagged state, resulting total 870 states. Tag rather
2. Perseus QMDP results (in Section 5.1) computed Matlab Intel Pentium IV 2.4 GHz;
results obtained different platforms, time comparisons rough.

209

fiSpaan & Vlassis

V

reward

#



C

10

0

(a) State space.

10

1

10

2

10

time (s)

3

4
6
8
10
12
14
16
18
20
10

0

(b) Value.

10

1

10

2

time (s)

10

3

(c) Reward.

2
8000
6000

10

1



# vectors

10000

10

4000
2000

10

0

10

0

10

1

2

10
time (s)

10

0

3

10

(d) Nr. vectors.

0

10

1

10

2

time (s)

10

3

(e) Policy changes.

Figure 2: Tag: (a) state space chasing opponent robot; (b)(e) performance
Perseus.

large benchmark problem compared POMDP problems studied literature,
exhibits sparse structure. applied Perseus belief set B 10,000 points.
Fig. 2(b)(e) show performance Perseus averaged 10 runs,
error bars indicate standard deviation within runs. evaluate computed policies
tested 10 trajectories (of 100 steps) times 100 starting positions
(sampled
starting belief b0 ). Fig. 2(b) displays value estimated B,
P
V
(b);
(c) expected discounted reward averaged 1,000 trajectories; (d)
bB
number vectors value function estimate, |{ni }|; (e) number policy
changes: number b B different optimal action Vn1 compared Vn .
latter regarded measure convergence point-based solution methods
(Lovejoy, 1991). see almost experiments Perseus reaches solutions
virtually equal quality size.
Table 2(d) compares performance Perseus state-of-the-art methods.
results show Tag problem Perseus displays better control quality
method computes solution order magnitude faster
methods. Specifically, solution computed |B| = 10,000 beliefs consists 280
vectors, much less PBVI maintains vector 1334 b B.
indicates randomized backup stage Perseus justified: takes advantage
large B size value function grows moderately planning horizon,
leading significant speedups. interesting compare two variations BPI,
bias (w/b) (Poupart, 2005) without (n/b) (Poupart & Boutilier, 2004). bias focuses
210

fiPerseus: Randomized Point-based Value Iteration POMDPs

R

||



2.35
2.34
2.30
2.25
2.22
0.94
0.23

4860
134
660
470
120
174
n.a.

10341
104
12116
3448
1000
n.a.
2.76

Tiger-grid
HSVI
Perseus
PBUA
PBVI
BPI w/b
Grid
QMDP

Hallway

R

||



PBVI
PBUA
HSVI
Perseus
BPI w/b
QMDP

0.53
0.53
0.52
0.51
0.51
0.27

86
300
1341
55
43
n.a.

288
450
10836
35
185
1.34

(b) Results Hallway.

(a) Results Tiger-grid.

Hallway2

R

||



Perseus
HSVI
PBUA
PBVI
BPI w/b
QMDP

0.35
0.35
0.35
0.34
0.32
0.09

56
1571
1840
95
60
n.a.

10
10010
27898
360
790
2.23

Tag
Perseus
HSVI
BPI w/b
BBSLS
BPI n/b
PBVI
QMDP

(c) Results Hallway2.

R

||



6.17
6.37
6.65
8.3
9.18
9.18
16.9

280
1657
17
30
940
1334
n.a.

1670
10113
250
105
59772
180880
16.1

(d) Results Tag.

Table 2: Experimental comparisons Perseus algorithms. Perseus results
averaged 10 runs. table lists method, average expected
discounted reward R, size solution || (value function controller
size), time (in seconds) used compute solution. Sources: PBVI
(Pineau et al., 2003), BPI bias (Poupart & Boutilier, 2004), BPI bias
(Poupart, 2005), HSVI (Smith & Simmons, 2004), Grid (Brafman, 1997), PBUA
(Poon, 2001), BBSLS (Braziunas & Boutilier, 2004) (approximate, read
figure).

reachable belief space incorporating initial belief dramatically increases
performance solution size computation time, reach control
quality Perseus.
5.2 Continuous Action Spaces
applied Perseus two domains continuous action spaces: agent equipped
proximity sensors moving continuous heading distance, navigation
task involving mobile robot omnidirectional vision perceptually aliased office
environment.
211

fiSpaan & Vlassis

(a) Continuous Navigation: state space.

(b) cTRC: example image.

(c) cTRC: environment.

Figure 3: Continuous action space domains: points indicate states, F depicts
goal state. (a) Environment Continuous Navigation problem: black
square represents agent, four beams indicate range proximity
sensors. (b) cTRC Problem: panoramic image corresponding prototype
feature vector ok O, (c) induced p(s|ok ). darker dot, higher
probability.

5.2.1 Continuous Navigation
first tested approach navigation task simulated environment,
agent move continuous heading distance. Continuous Navigation environment represents 2010m hallway highly perceptually aliased (see Fig. 3(a)).
agent inhabiting hallway equipped four proximity sensors, observing one
compass direction. assume proximity sensor detect whether
wall within range 2m not, resulting total number 16 possible sensor readings.
agents sensor system noisy: 0.9 probability correct wall configuration
observed, otherwise one 15 observations returned equal probability.
task reach goal location located open area walls near enough
agent detect. agent initialized random state environment,
learn movement actions take order reach goal fast possible.
Perseus assumes finite discrete state space (the set possible locations
agent) need discretize space; performed simple k-means clustering
random subset possible locations, resulting grid 200 locations depicted
Fig. 3(a). agents actions defined two parameters: heading
agent turns distance intends move direction. Executing
action transports according Gaussian distribution centered expected resulting
position, defined current (x, y) position translated meter direction
. standard deviation Gaussian transition model 0.25d I, means
agent wants travel, uncertainty regarding resulting
212

fiPerseus: Randomized Point-based Value Iteration POMDPs

position. distance parameter limited interval [0, 2]m heading
ranges [0, 2]. movement penalized reward 0.1 per step
reward obtainable goal location 10.
test feasibility Perseus continuous action spaces, i.e., whether
compute successful policies sampling actions random, experimented number
different sampling schemes backup0 operator. scheme defined
old
makeup A0b = {AU ,
b , Ab }, composed samples three distributions:
U
N
: uniformly random; Ab : Gaussian distribution centered best known action
a(nb ) b far, standard deviation = 5 = 0.1 d; Aold
b : Dirac
0
distribution best known action. describe Ab number samples
old
distribution {|AU |, |AN
b |, |Ab |}. tested following schemes: sampling single
action uniformly random {1, 0, 0}, Gaussian distribution a(nb ) {0, 1, 0};
adding a(nb ) schemes resulting {1, 0, 1} {0, 1, 1}; {k, k, 1}, sampling k
actions uniform Gaussian distributions including old action. latter
scheme explores option sampling one action particular distribution,
tested k = {1, 3, 10}. option try best known (old) action
particular b relatively cheap cache transition, observation, reward
model first time chosen (at previous backup stage).
problem used set B 10,000 belief points. evaluate control quality
computed value functions collected rewards sampling 10 trajectories 100
random starting locations particular time intervals, following policy computed
far. trajectory stopped maximum 100 steps (if agent
reached goal then), collected reward properly discounted. results
averaged 10 runs Perseus different random seed computed
Matlab Intel Xeon 3.4GHz.
Fig. 4 shows results sampling schemes mentioned above. top row
displays control quality indicated average discounted reward. Fig. 4(a)
see sampling single action uniformly random {1, 0, 0} already gives good
performance, extending A0b include best known action {1, 0, 1} improves control
quality. Gaussian sampling schemes {0, 1, 0} {0, 1, 1} learn slower take
small steps action space. additional disadvantage Gaussian sampling
need user specify standard deviation. Fig. 4(b) depicts control quality
schemes sample three distributions {k, k, 1}, different values
k. figure shows tested variations reach similar control quality, trying
actions particular b slow learning. However, looking size
value function (Fig. 4(c)(d)), see k = 10 resulting value function smaller
scheme tested. appears experiment sampling actions
increases chance finding high quality action generalizes well (so fewer vectors
eventually needed reach control quality), higher computational
cost per backup stage. Note tested schemes number vectors value
function remains two orders magnitude lower size B (10,000 belief points),
confirming efficient behavior Perseus randomized backup scheme.
obtain insight effect sampling different distributions A0b ,
computed relative frequency occurrence maximizing action AU ,
b ,
0 check whether vector computed using returned
Aold
.

executing

backup
b
213

fi7

7

6

6

5

5

4

4
reward

reward

Spaan & Vlassis

3

3
2

2
1

1

Uniform
Uniform/Old
Gauss
Gauss/Old

0
1 1
10

2

3

10

1 1
10

4

10

Uniform/Gauss/Old
Uniform*3/Gauss*3/Old
Uniform*10/Gauss*10/Old

0

10

2

350

350

300

300

250

250

# vectors

# vectors

400

200
150
100
50
3

200
150

50
0 1
10

4

10

Uniform/Gauss/Old
Uniform*3/Gauss*3/Old
Uniform*10/Gauss*10/Old

100

Uniform
Uniform/Old
Gauss
Gauss/Old
2

10

2

10

(d) Number vectors.

1

1

0.8

0.8
Origin best action

Origin best action

4

10
time (s)

(c) Number vectors.

Improved: Uniform
Improved: Old
improved

0.4

3

10

time (s)

0.6

10

(b) Reward.

400

10

4

10
time (s)

(a) Reward.

0 1
10

3

10

time (s)

0.2

0.6

Improved: Uniform
Improved: Gauss
Improved: Old
improved

0.4

0.2

0 0
10

1

10

2

10
time (s)

3

10

0 0
10

4

10

(e) Origin maximizing action.

1

10

2

10
time (s)

3

10

4

10

(f) Origin maximizing action.

Figure 4: Perseus results Continuous Navigation problem, averaged 10 runs.
old
left column shows performance {|AU |, |AN
b |, |Ab |} = {{1, 0, 0},
{1, 0, 1}, {0, 1, 0}, {0, 1, 1}}, right column displays {k, k, 1} k =
{1, 3, 10}. top row figures display average discounted reward obtained
vs. computation time, figures middle row show size value
function, bottom row details origin maximizing vector (see
main text).

214

fiPerseus: Randomized Point-based Value Iteration POMDPs

V
3

2
1.5
Discrete 4
Discrete 8
Discrete 16
Uniform*3/Old

1

2

10

3

10
time (s)

(a) Reward.

4

10

Origin best action

Discrete 4
Discrete 8
Discrete 16
Uniform*3/Old

2000
# vectors

reward

2.5

0.5 1
10

1

2500

1500
1000
500
0 1
10

2

10

3

10
time (s)

(b) Number vectors.

4

10

0.8
0.6

Improved: Uniform
Improved: Old
improved

0.4
0.2
0 1
10

2

10

3

10
time (s)

4

10

(c) Origin best action.

Figure 5: Performance Perseus cTRC domain, averaged 10 runs.
action actually improves V (b), so, record whether action originated AU ,
old

b , Ab . every backup stage normalize counts respect total
number backups backup stage (including improve V (b)).
resulting frequencies plotted bottom row Fig. 4 two sampling schemes:
sampling uniform old {1, 0, 1} (Fig. 4(e)) sampling one action three distributions {1, 1, 1} (Fig. 4(f)). see time relative frequency best
known action grows (Improved: Old), number instances none
sampled actions improves V (b) drops almost zero (Not improved). frequencies
actions sampled uniform Gaussian distribution (Improved: Uniform resp.
Improved: Gauss) resulting best action A0b (and improving V (b)) also drop.
observations confirm intuition sampling actions random Perseus
effectively explore action space (which advantageous beginning algorithm), time progresses algorithm seems able exploit actions
turn useful.
5.2.2 Arbitrary Heading Navigation
evaluate Perseus continuous actions realistic problem compare
discretized action spaces also include cTRC domain. problem (adapted
Spaan & Vlassis, 2005) mobile robot omnidirectional vision navigate
highly perceptually aliased office environment (see Fig. 3(b) (c)). use MEMORABLE3 robot database contains set approximately 8000 panoramic images
collected manually driving robot around 17 17 meters office environment.
robot decide move 5m arbitrary direction, i.e., actions parameterized heading ranging [0, 2]. applied technique Continuous
Navigation domain grid state space 200 states (Fig. 3(c)) assume Gaussian
error resulting position. observation model compressed images
PCA applied k-means clustering create 10 three-dimensional prototype feature vectors {o1 , . . . , o10 }. Fig. 3(c) shows inverse observation model p(s|o) one observation,
Fig. 3(b) displays image database closest particular prototype obser3. MEMORABLE database provided Tsukuba Research Center Japan, Real
World Computing project.

215

fiSpaan & Vlassis

vation. task reach certain goal state reward 10 obtained;
action yields reward 0.1. belief set B contained 10,000 belief points.
compared continuous action extension Perseus three discretized versions
problem, applied regular Perseus fixed discrete action set 4,
8 16 headings equal separation (offset random angle prevent bias).
old
Fig. 5 displays results Perseus {|AU |, |AN
b |, |Ab |} = {3, 0, 1} (other schemes
turned give similar results), three discrete action spaces. Fig. 5(a) shows
sampling continuous results control quality discrete 16
version, needs time reach (as backup0 requires generate transition,
observation reward models fly). discrete cases benefit optimized
implementation (we cache transition, observation reward models) continuous
action scheme needs computation time match performance outperform them.
However, employing continuous scheme, Perseus exploits ability move
arbitrary heading find better policy discrete 4 8 cases. see
providing robot fine-grained action space leads better control quality,
problem discretization 16 headings appears fine-grained enough
good control performance. Fig. 5(b) plots number vectors value function
scheme, see reaching control quality continuous
discrete 16 version need similar amount vectors. Fig. 5(c) shows relative frequency
occurrence maximizing action AU Aold
b , detailed Section 5.2.1.
Fig. 4(e)(f) see time best known action exploited, frequency
instances sampled action improves value b diminished near zero.

6. Conclusions
partially observable Markov decision process (POMDP) framework provides attractive principled model sequential decision making uncertainty. models
interaction agent stochastic environment inhabits. POMDP assumes agent imperfect information: parts environment hidden
agents sensors. goal compute plan allows agent act optimally
given uncertainty sensory input uncertain effect executing action. Unfortunately, expressiveness POMDPs counterbalanced intractability computing
exact solutions, calls efficient approximate solution techniques. work
considered recent line research approximate point-based POMDP algorithms
plan sampled set belief points.
presented Perseus, randomized point-based value iteration algorithm planning POMDPs. Perseus operates large belief set sampled simulating random
trajectories belief space. Approximate value iteration performed belief set
applying number backup stages, ensuring backup stage value
point belief set improved; key observation single backup may improve
value many belief points. Contrary point-based methods, Perseus backs
(randomly selected) subset points belief set, sufficient improving
value belief point set. Experiments confirm allows us compute
value functions consist small number vectors (relative belief set
size), leading significant speedups. performed experiments benchmark problems
216

fiPerseus: Randomized Point-based Value Iteration POMDPs

literature, Perseus turns competitive methods terms
solution quality computation time. extended Perseus compute plans agents
large continuous set actions disposal, sampling actions
action space. demonstrated viability Perseus two POMDP problems continuous action spaces: continuous navigation task robotic problem
involving mobile robot omnidirectional vision. analyzed number different
action sampling schemes compared discretized action spaces.
Perseus recently extended deal structured state spaces (Poupart, 2005;
Boger, Poupart, Hoey, Boutilier, Fernie, & Mihailidis, 2005), continuous observation spaces
(Hoey & Poupart, 2005), continuous state spaces (Porta, Spaan, & Vlassis, 2005).
future work would like explore alternative compact representations (Guestrin, Koller,
& Parr, 2001; Theocharous, Murphy, & Kaelbling, 2004), well applying Perseus
cooperative multiagent domains, extending recent approaches (Emery-Montemerlo, Gordon,
Schneider, & Thrun, 2004; Becker, Zilberstein, Lesser, & Goldman, 2004; Paquet, Tobin, &
Chaib-draa, 2005).

Acknowledgments
would like thank Bruno Scherrer, Geoff Gordon, Pascal Poupart, anonymous
reviewers comments. research supported PROGRESS, embedded
systems research program Dutch organization Scientific Research NWO, Dutch
Ministry Economic Affairs Technology Foundation STW, project AES 5414.

References
Aberdeen, D., & Baxter, J. (2002). Scaling internal-state policy-gradient methods
POMDPs. International Conference Machine Learning, Sydney, Australia.
Andre, D., Friedman, N., & Parr, R. (1998). Generalized prioritized sweeping. Advances
Neural Information Processing Systems 10. MIT Press.
Aoki, M. (1965). Optimal control partially observable Markovian systems. Journal
Franklin Institute, 280 (5), 367386.
Astrom, K. J. (1965). Optimal control Markov processes incomplete state information. Journal Mathematical Analysis Applications, 10, 174205.
Bagnell, J. A., Kakade, S., Ng, A. Y., & Schneider, J. (2004). Policy search dynamic
programming. Advances Neural Information Processing Systems 16. MIT Press.
Baxter, J., & Bartlett, P. (2001). Infinite-horizon policy-gradient estimation. Journal
Artificial Intelligence Research, 15, 319350.
Becker, R., Zilberstein, S., Lesser, V., & Goldman, C. (2004). Solving transition independent
decentralized Markov decision processes. Journal Artificial Intelligence Research,
22, 423455.
Bellman, R. (1957). Dynamic programming. Princeton University Press.
Bertsekas, D. P., & Tsitsiklis, J. N. (1989). Parallel Distributed Computation: Numerical
Methods. Prentice-Hall.
217

fiSpaan & Vlassis

Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific,
Belmont, MA.
Boger, J., Poupart, P., Hoey, J., Boutilier, C., Fernie, G., & Mihailidis, A. (2005). decisiontheoretic approach task assistance persons dementia. Proc. Int. Joint
Conf. Artificial Intelligence.
Bonet, B. (2002). epsilon-optimal grid-based algorithm partially observable Markov
decision processes. International Conference Machine Learning, pp. 5158,
Sydney, Australia. Morgan Kaufmann.
Brafman, R. I. (1997). heuristic variable grid solution method POMDPs. Proc.
National Conference Artificial Intelligence.
Braziunas, D., & Boutilier, C. (2004). Stochastic local search POMDP controllers.
Proc. National Conference Artificial Intelligence, San Jose, CA.
Cassandra, A. R., Littman, M. L., & Zhang, N. L. (1997). Incremental pruning: simple,
fast, exact method partially observable Markov decision processes. Proc.
Uncertainty Artificial Intelligence, Providence, Rhode Island.
Cheng, H. T. (1988). Algorithms partially observable Markov decision processes. Ph.D.
thesis, University British Columbia.
Dynkin, E. B. (1965). Controlled random sequences. Theory probability applications, 10 (1), 114.
Emery-Montemerlo, R., Gordon, G., Schneider, J., & Thrun, S. (2004). Approximate solutions partially observable stochastic games common payoffs. Proc. Int.
Joint Conference Autonomous Agents Multi Agent Systems.
Guestrin, C., Koller, D., & Parr, R. (2001). Solving factored POMDPs linear value
functions. IJCAI-01 workshop Planning Uncertainty Incomplete
Information.
Hansen, E. A. (1998a). Finite-memory control partially observable systems. Ph.D. thesis,
University Massachusetts, Amherst.
Hansen, E. A. (1998b). Solving POMDPs searching policy space. Proc. Uncertainty Artificial Intelligence, pp. 211219.
Hauskrecht, M. (2000). Value function approximations partially observable Markov
decision processes. Journal Artificial Intelligence Research, 13, 3395.
Hoey, J., & Poupart, P. (2005). Solving POMDPs continuous large discrete observation spaces. Proc. Int. Joint Conf. Artificial Intelligence.
Kaelbling, L. P., Littman, M. L., & Cassandra, A. R. (1998). Planning acting
partially observable stochastic domains. Artificial Intelligence, 101, 99134.
Kearns, M., Mansour, Y., & Ng, A. Y. (2000). Approximate planning large POMDPs
via reusable trajectories. Advances Neural Information Processing Systems 12.
MIT Press.
Lagoudakis, M. G., & Parr, R. (2003). Least-squares policy iteration. Journal Machine
Learning Research, 4, 11071149.
218

fiPerseus: Randomized Point-based Value Iteration POMDPs

Littman, M. L., Cassandra, A. R., & Kaelbling, L. P. (1995). Learning policies partially observable environments: Scaling up. International Conference Machine
Learning, San Francisco, CA.
Lovejoy, W. S. (1991). Computationally feasible bounds partially observed Markov
decision processes. Operations Research, 39 (1), 162175.
Madani, O., Hanks, S., & Condon, A. (1999). undecidability probabilistic planning
infinite-horizon partially observable Markov decision problems. Proc.
National Conference Artificial Intelligence, Orlando, Florida.
Meuleau, N., Kim, K.-E., Kaelbling, L. P., & Cassandra, A. R. (1999). Solving POMDPs
searching space finite policies. Proc. Uncertainty Artificial Intelligence.
Monahan, G. E. (1982). survey partially observable Markov decision processes: theory,
models algorithms. Management Science, 28 (1).
Moore, A. W., & Atkeson, C. G. (1993). Prioritized sweeping: Reinforcement learning
less data less time. Machine Learning, 13, 103130.
Ng, A. Y., & Jordan, M. (2000). PEGASUS: policy search method large MDPs
POMDPs. Proc. Uncertainty Artificial Intelligence.
Papadimitriou, C. H., & Tsitsiklis, J. N. (1987). complexity Markov decision processes. Mathematics operations research, 12 (3), 441450.
Paquet, S., Tobin, L., & Chaib-draa, B. (2005). online POMDP algorithm complex
multiagent environments. Proc. Int. Joint Conference Autonomous Agents
Multi Agent Systems.
Pineau, J., Gordon, G., & Thrun, S. (2003). Point-based value iteration: anytime
algorithm POMDPs. Proc. Int. Joint Conf. Artificial Intelligence, Acapulco,
Mexico.
Poon, K.-M. (2001). fast heuristic algorithm decision-theoretic planning. Masters
thesis, Hong-Kong University Science Technology.
Porta, J. M., Spaan, M. T. J., & Vlassis, N. (2005). Robot planning partially observable
continuous domains. Robotics: Science Systems, MIT, Cambridge, MA.
Poupart, P., & Boutilier, C. (2003). Value-directed compression POMDPs. Advances
Neural Information Processing Systems 15. MIT Press.
Poupart, P., & Boutilier, C. (2004). Bounded finite state controllers. Advances Neural
Information Processing Systems 16. MIT Press.
Poupart, P. (2005). Exploiting Structure Efficiently Solve Large Scale Partially Observable
Markov Decision Processes. Ph.D. thesis, University Toronto.
Poupart, P., & Boutilier, C. (2005). VDCBPI: approximate scalable algorithm large
scale POMDPs. Advances Neural Information Processing Systems 17. MIT
Press.
Puterman, M. L. (1994). Markov Decision ProcessesDiscrete Stochastic Dynamic Programming. John Wiley & Sons, Inc., New York, NY.
219

fiSpaan & Vlassis

Roy, N., & Gordon, G. (2003). Exponential family PCA belief compression POMDPs.
Advances Neural Information Processing Systems 15. MIT Press.
Roy, N., Gordon, G., & Thrun, S. (2005). Finding approximate POMDP solutions
belief compression. Journal Artificial Intelligence Research, 23, 140.
Russell, S. J., & Norvig, P. (2003). Artificial Intelligence: modern approach (2nd edition).
Prentice Hall.
Satia, J. K., & Lave, R. E. (1973). Markovian decision processes probabilistic observation states. Management Science, 20 (1).
Smallwood, R. D., & Sondik, E. J. (1973). optimal control partially observable
Markov decision processes finite horizon. Operations Research, 21, 10711088.
Smith, T., & Simmons, R. (2004). Heuristic search value iteration POMDPs. Proc.
Uncertainty Artificial Intelligence.
Sondik, E. J. (1971). optimal control partially observable Markov decision processes.
Ph.D. thesis, Stanford University.
Spaan, M. T. J., & Vlassis, N. (2004). point-based POMDP algorithm robot planning.
Proceedings IEEE International Conference Robotics Automation, pp.
23992404, New Orleans, Louisiana.
Spaan, M. T. J., & Vlassis, N. (2005). Planning continuous actions partially observable environments. Proceedings IEEE International Conference Robotics
Automation, pp. 34693474, Barcelona, Spain.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press.
Szepesvari, C., & Littman, M. L. (1996). Generalized Markov decision processes: Dynamicprogramming reinforcement-learning algorithms. Tech. rep. CS-96-11, Brown
University, Department Computer Science.
Theocharous, G., Murphy, K., & Kaelbling, L. P. (2004). Representing hierarchical
POMDPs DBNs multi-scale robot localization. Proceedings IEEE
International Conference Robotics Automation.
Thrun, S. (2000). Monte Carlo POMDPs. Advances Neural Information Processing
Systems 12. MIT Press.
Tuttle, E., & Ghahramani, Z. (2004). Propagating uncertainty POMDP value iteration
Gaussian processes. Tech. rep., Gatsby Computational Neuroscience Unit.
Vlassis, N., & Spaan, M. T. J. (2004). fast point-based algorithm POMDPs.
Benelearn 2004: Proceedings Annual Machine Learning Conference Belgium
Netherlands, pp. 170176, Brussels, Belgium. (Also presented NIPS 16
workshop Planning Real-World, Whistler, Canada, Dec 2003).
Zhang, N. L., & Zhang, W. (2001). Speeding convergence value iteration partially observable Markov decision processes. Journal Artificial Intelligence Research,
14, 2951.
Zhou, R., & Hansen, E. A. (2001). improved grid-based approximation algorithm
POMDPs. Proc. Int. Joint Conf. Artificial Intelligence, Seattle, WA.

220

fi
fffi

fi fi


!" #
$!


fffi

fi




fi


fffi

ff fi


ff
fi
fi
ff
fi


ff
fi


fffi
ff


ff fiff

ff





ff
fi ff
ff

ffffff ff
ff ff ff

fi ff
ff ff ff
ff ff

ff ff ff
ff
ff
fiff fi fi ff ff
ff
fi
ff
ff ff ff ff

fi fi ff
ff

ff
ff
fi ffff fiff ff
ffff ff

ff
fiff

ff ffffff ff ff ff
ff

ff ff ff

ff
fi ff
fiff

ff

ff


ff
ffff ff




ffff ff

fi
ff

fiff

! fi ff
ff ff
fi
fi ff

ff
ff
"
ff

fiff
ff
fi
fi! ff
fi ff
fi
fi ff
fiff
#

ff fiff ff
ff

ff fi ff
ff
fi ff

fiff


ff
$

ff

ff

fiff
ff

ff
ff ffff
ff

ff ff %

&ff
'

ff
(
)*+&,
ff ff ff
ffff


ff ff ff
fi


ff
ff ff

ff
ff
ff ff

fi -./
ff


ff0 fi
ff
1.../
ff


ff
ff0 ff

ff ff .23 fi
ff ff


fffi ff



fffi
ff

ff
ff




fffifi


fi

ff
fi
ff

fi ff
fi
ff

fi
ffff ff fi fi fi

fifi

ff!
fi

!$


ff ff
fi fi


fi
fifi



ff

fffi



fi

fffi
ff ff ff fi

fi ffff !" #fiff #fifi !$ % ff &' &
fifi

' ff & fi ff fi
'
fi fi'
fifi

( (ff& ) * * fi ff
" +
, -.." fifi + % fi !$
fi fifi %
&
' &

fi ffff fififi



ff
ffff "#$ fffffi


% fffffi


fi
ff
fifi

fifi fi



fi

fifi
ff


ff ff
&
ff
ff

fi
fi


fffi






'fi ff


!
ff (fi fi ) *

+,,-. (fi ) +,,-
+ ff
/



ff
fi ff


ff
ff
fi fi fi ff



fi ff
! fi

fi


! fi


! ff
ff


0


fi


fi

ff

ff


ff
0
fi fi fi
ff




fi fi
fffffi

fi ff
fi
ff fi fffffi

fffi


ff fffffi
ff

ff fffi
ff

&




1
fi





ff ff

ff fi fi 0
fifi fi !



2fi

ff

ff fi fi

ff


ff





ff
'fi

fi

0
ff


ff
fi ) 3 4556 78
fifi fi 9 1
) :! +,,;. ! ( ) 1

455<. +,,+ fi

ff
ff

ff
+

fi

78 fi

ff
!
ff
ff
=
ff



>? !



!

'fi

ff
=

$
fi 78


ff
fi
ff fiff
&



& fi
ff



ff
ffff

ff
ff !



ff

ff

fi @
:!
) ( 455+
78

fi fi


ff
fi

! fi ff ff

$
@

fi




!

&


&
ff ff ff
/ fiff
fi

fi
fffi
fi fi

!
3fi


fiff


ff

fi
ff ff

ff


fi






ff
ff
ffff



& !
4.5

fifi fi
ff
fi
ff ff fifi fi

ff ff

ff

&


fffffi


fi
ff
fi
ff

ff
fi


# "
!



! fi


ff ff

fi


ff
!
ff 0 fffffi



fiff fi

!

ff


ff ! $



ff

fi'fi fi

fi
ff


ff



ff

ff
= fiff


/
=
# "

ffff
ff ff
2 ff

;

fi
# "
ffff
fi
ff ff

ff

# "
ff


= fiff

ff

fi

fffi
ff
fi


fi fi







fi
fi



ff




fi (fi *
) fi +,,A
# "


ff
fi


ff fi

ff
ff
fi 00


!
ff
ff
fi
/
! 4566.
fiff +,,- ff

ff 'fi

ff
fi
# "


00
= 00

ff


fi fi

ff

fi 2fiff fi
fi ff
ff fffffi


ff fi
ff
00

ff
8 ) " +,,-. B
455C. Bfi
8 )

+,,4 fi


ff



ff

fffffi




E

ff!
ff







+ ff
3fi


ff
fi
fffffi






ff



fiff
&

ff
ff

ff

Ffi !


= fffffi








! fi

fi # " fi
ff

2
ffff

ff
ff fi

ff fi 00 &
fi

fffi fi

fffi

fi fi
ff
fi fi
/ ff

fi ff 0 1 ff & ff 'fifi fi fifi &
2
! / 3
fi

fi 4 0 1 ff ff ff & ff 4
ff & ff &ff fi
2 # ff fifi &fi
fi 5ff6
--7" 5 8 --9" 8 : ; --.$ ff & fi'
fi ff 6ff
fi
fi '
6ff ff ff ff & ) )ff
<
8 2$

4.6

fi ffff fififi



fffi
!

"fffffi

fi

fi # "


fi


ff

C
fi
ff
ff
!
ff fi ! fi
G 3 8
ffE
@ fi
3 ) 8
ff 455- ff #

F'fi


7
ff 8
#F 78 ) H 4555 ff

fi

ff
fi ff!

! fi



" ) (
4556. #!
) +,,+. +,,,

ff
fifi

ff

+,,, /

ff ff! ff


=

# " fi
ff
ff

ff

fi

=ff
ff
# "
9ff

fi
fi

ff



& !
! ff


fi


ff

fi # "
fi fi


ffff
fifi fi C,I

fi





! ff 4,,,I.


fi
fffi fffffi


ff
ff
ff
,+A fi # " ff ff!


ff

fi. fi




= 5AI =

fiffff
fi
fi

G
: fi fi
ff



fiff

ff



fi ff

: fffffi


ff
= fi J
! ff

J

ff
fi


:
fi
ff
# "


ff fi
ff fi
ff
ff

fi

ff

00
ff


: ff &
# " fi
ff

fi



fffi
fi
ff fi


ff




ff




+
fi


fffi


fi
= fi
ff



'fi

fffffi




-



fffi
ff
ff
fi
7 # fi

fi ff & ff fi fi ff &ffff fifi
ff fi fi &ff' ff ff ff ff &
' &ff ff

' fifi 6ff fifi
:' fffi fi
fi

fi 3 'ff
ff & ' &ff &
fi 6fi

fi fi ff & ff fi <%=
) >

<( &ffff ff fifi
fi
& ff ff fiff fi 3
% &'
fi ff
fi ff fi

41.

fifi fi
ff
fi
ff ff fifi fi

fi




!


fffi
ff

fi fi fffffi




; 'fi

fi
ff
ff fi

fffffi


ff

# "



ffff
fi ff









ffff
ff!
ff @ fi

#F 78




ff

fi
fi

ff fi

ff fi'fi



fffi




C

<
ff fffi


fi
ff
fi ff fi ff

fi
2

6 fi

ff!

= fi fifi !

fi ff



=
ffK
ff

!

fi ff


ff fi
ff
ff






ff

ff

+4
++
fi


78


=

4 78 ff!


ff!


fi

ff

! = fi



fi


ff!

ff! fi


= fi fi fffffi









ff ff



=
fi
fi


ff


2

+-
fi
fi
!


ff



ff
fi

ff


= fi


& ff

fifi

fi fiff fiff
fi


fi ffK
fi




fi
ff

fffffi



fi
fi
2 %"


fi
ff ff

fi



fi




8
9ff 4566 fi



ff
fi fifi

fi
fi fi
fi
fi
/

ff fi
ff
fi
ff
fi




fi fffffi

/
fi
fi


ff

&

fi
ff




ff

fi
fi 2 %"

fi fffffi



ff ff




= ! 'fi
ff

4 0 2 %"
fi >?


L fi

fi
fi

'fi


>?
fi
Ffi !

= fffffi


ff

411

fi ffff fififi



ff

fi fi
ff
ff


ff
ff

fi Kfi
= fi
ff

2 %"





ff

ff


fifi J
ff






fi
ff




ff ff J
ff " ) 1 4555


fi fifi

! fi ff
ff



!
ff
fifi
'fi
ff

4 ff



=

ff
ff

ff


fi fiff

ff
ff !

>
fi? )
ff
45A6


fi fi ! = fifi




fffffi


ff E



ff
! fi
fi
ff

ff

fi 'fi






fifi
=


ff ff



ff ff

#1#
(fi ) 8 4554
fi fi

ff



ff


ff


ff

K

!
0
#1# ff





fi


ff
fi


ff






! ff
ff


ff


ff ff


#1#E J
E
ff

fi

fi
ff ff
!

ff

fi
/
ff
'fi
ff
4
ff
fi

fffffi


9
#1# !
9
ff


fffi
ff! (! 455A 455A ff
ff


!
ff

$






fiG fffffi

fi
fi ff

fi
.

fi ff
. ff!%! ffff
ff
ff fi fi





1#1#
fi

ff
ff

fi (! ) 8 455A (



!
ff


ff
ff $
! #1#
1#1#

fi
fi
ff





G


ff
ff

ff
fi
fi

&
fi

412

fifi fi
ff
fi
ff ff fifi fi


ff ff
fi

fi

ff
ff

ff
ff
fi 1#1#
fi




ff


=

4
/ #1# 1#1# ff

ff



ff
ff fi


'fi



fi
ff
ff


ff



ff


ff

fi




fi
ff E




fi fi
ffff ff
ff 'fi
fi
=

fi


!

# ff ff

ff!


fi
fi

9 ff 455< *
455A. 7
)
455<

fi

K


" ) 8'fi 4554 K

ffff
ff *
455-
ff

>K

?
*#1 ff
K
ffff

ff ff


fffifi





9
*#1
G
>'fi? fi fi



fi
ffff
ff fi


>=ff?

ff
ffff
ff
ff >'fi? 2fi 9

ff >
? ff 1L ) Mfi 455C fi ff ff ffff
ffff fi

fi 9


ff!
fi



ff!

K


ff


fi

ff

! ff ! fi

fffffi

'fi





fi

ff
! fi


ff fi
9

fi fi


'fi

ff
K
ffff
ff ff ff ffff

= fffi fffffi


ff ff

fi




'fi



=
ff

fi


ff

ff
fi
!
fi 'fi


ff
ff
ffff
ff
fi Ffi


ff



! fifi


0
ff !

fi ff


'fi
fffi


ff
"#$ %fi
&

78

ff


fi ff

ff


! 3 8
ff 3 ) 8
ff 455- ! !
fi
ff
ff fffffi


fi C C


ff ff


ff
fi
!
417

fi ffff fififi



&

fi !


'fi


fi


ff

$



ff

fi 'fi

fi

ff

fffiff
ff ! fi fi
@




ff



ff

ff


fi
fi
ff fi
ff

fi





ff

fi
fi





ff
& ff
fi !





ff

fi



! fi fi ff

!



fi

ff

!
fffi !

!




&

!

ff

ff
@ fi

ff fifi
ff ff



ff

! 3 8
ff fi
ff fffffi




! fi ! fi

0 fffffi

fi

ff

ffff

fi fi
!
ff fi
fi

ff
fi fi



fifi
ff
ff fi
ff

fi
fi
ff
fi
fi

ff






ff

fi
! ff

ff

ff fi
ff


fi
ff
ff

3 8
ff 455-


! fi
@
ff


ff

fi 0


ff
fi

(,
fi 4566


>?
ff fi

# " ff




fi

fi fi # "

ff

3 8
ff 455-

@ fi

ff fi
ff! ff

fi
ff # "



'

(
$)


"ff

#'fi "


ff

ff #F 78
+,,, K
ff!
!

fi


ff


ff

ff
fiff


fi fi ff
fi

ff


ff "fiff 455C.
*!! ) * 455A fi
L

! / #F 78
& ff fi
ff



ff
ff
fi &


=
fi fi ff &
ff ! fi
fi





fi

414

fifi fi
ff
fi
ff ff fifi fi



fifi
ffff

fi
!
fi
ff
fffi



fi ! fi

#F 78
&

ff
ff
fifi


fffi
ff
) H 4555
fi fi #F 78
ff

fffi ! fi


ff
fi

E
K
! ff


ff
!
fi

2fiff
ff





fi


fi
=
ff
fi
#F 78
fi fffffi



fi
ff
ff

ff

fi
ff #F 78 fiff ff fffi

!

ff @ fi


fi




J
ff

fi



! fi

ff
& 0


ff




! 2





fi ff

ff


fi
ff
E
ffff
fi fi

ff
ff 'fi

fi
fi
fiff


!
'fi
ff
ff =


ff fi


fi
fi ff ff

! +,,,

fi

ff E
ff fi
fi

ff
ff


=

++4

ff fi
fi ! ff

ff



fi
fi
!
ff 2

#F 78
ff




fi fi
+,,, ff









ff
fi




ff

/
ff fi
ff
ff
fi # "

fi
ff

ffff
!
ff
fi ff
ff

ff

fi

ff &




#F 78 ff! ff


fi

# "
' fffi *



fi
78


fi ff




fi
) fi +,,,
78

ff
ff


fi fi



=

fi






ff
ff

ff
ff fi fi
ff
ff
ff
2 ff
! fi

ff ff

! fi

! fi


ff


fffi fi

ff
ff




ff fi ! fi
ff




ff !







fiff


fi

!
413

fi ffff fififi



ff


ff

!
fi


ff
ff J
ff

ff ! fi E


fi Kfi


ff



fffi fi


ff
J ff

fffffi


fi
!
ff
ff fi /

ff
fi
ff
!
ff fffffi




ff

=


ff
ff
ff



ff
fi






ff

ff
fi !

fi ! ff fi
ff
fi
ffff



4 fi



ff

ff
fi fi

:

ff 455+ 3 3 4555
#!
+,,+ ff ! ff



ff
ff fi
ff
ff!
ff fi
ff /
!
:

ff 455+ 3 3 4555
fffi
ff

'fi


fi

ff
fi

ff
fi

ff


ff
fi





fi


ff
ff

ff



!
! #!
+,,+ fi
fi
fi



fffffi



fi


! fifi

ffff


fi


fffffi

'fi





fi ! fffffi


fi
ff
fi



fi

fi ! & fi

fi




% +ff#


Bfi 8

+,,4 fffffi





E






fi fi

! (

# (# 2
) L +,,4
fffffi







fi




/ fffffi




ff
fi
fffffi




E (# fi



fffffi


fi / fi ff


fffffi


'fi
fi fi

ff E



ff
ff


!

fffi

(# 3fi

4555 fiff
ff


= fi
ff fi


fffffi




9 fi fifi ff ff & ' fifi ff % ff
' ff & fi ff & ff fi

41-

fifi fi
ff
fi
ff ff fifi fi


ff fi fffi
ff

fi (#

ff



fi

ff fffffi

ff

! Bfi +,,4
fi /

fffffi


E



fffffi



: 'fi

ff



ff
=
ff

# " ff
Ffi !
& ff Bfi +,,4



2



! fiff
fi 'fi fffffi

: ff
ff fi

fi fiff
fi fffffi

. fi
ff




ffff
F
ff




=


fffffi

2
fffffi


fi




fi ff





ffff fi fi !
fi
ff

fi !
!


fffi
ff ! ff


- /
fi !



fi ff
! fi
ff
.
!


fi

ff fi
, +

ff

ff

# "


ff
ff

fi


8 :
) /& 45C, fi fiff fffi


ff

!


fi
/
&




fiG
8 = fiff fi

>?
fi
ff
fi



ff
# "
! fi


fi
fiff
8
ff
ff

fiff
fffi


ff # "

ff
= fiff !

8
fi




ff F
fi ff # "
ff



=

ff
fiff
ff
fi

ff
# "


ff fi










!
'fi

ff





ff


455< fi
fi



fi


ff ff



@
ff









fi
fi
!


fiff
fi




2fi
ff
fffi

fi
ff
!


418

fi ffff fififi



!

'fi ! fi








fi
fi
fi


&
ff

fi

ff

ff



ff 'fi
ff
ff








ffff 7
'fi

fi


fi ff !

fi ff
!

&




$ %fi& !%
! '

fi
0!





ff ff !


fi
ff ff
! &


ff










! fffffi
Ffi

# "

ff
fi

ff


fi @
:!

) ( 455+

ff
fi
fi

ff
ff

ff





!

ff
fi !


fi fi fffiff ff

K
fi


!






*
) (
+,,+ /


fi
ff


! fi fi
fi fiff fi


E fffffi

fi
ff
>?


! fi fi
" ) (
4556
4556
!
fi
fi fi

ff

fi 3
fi

ff

fi
ff
ff





ff


fffiff N

fi 8
) 3! 4555.
7

" 7

ff /
! ) 3
fi! +,,, /
fi
'fi

ff


ff


fi



ff # "

ff fi


ff

ff

fi 2fi

fffiff

ff
fiff
! ff
&
ff
=
2

! 7

+,,,
!
ff
'fifi

&
'fifi


ff 3
@

ff


ff




fifi ff


fi


= ff

ff

ff ff ! ff fi 1 !

ff



fi ff fi
=
fi
3fi
ff


& fi !

& ff 'fi
! fi

'fi




fi
fi
4566. #fi! 3! ) "!
+,,4
ff ff
fi
fffifi

415

fifi fi
ff
fi
ff ff fifi fi


& fi


fffifi ff




= ff ff
fffifi *

) 3fiff +,,-
fi !
'fi


2 ff


fi
ff


'fi
ffff
'fi
ff



fi # "


'fi
ff
/
'fi
ff




ff

# ". # "
fiff
'fi
!


; ff
0




!

fi ! H
) H 455< fi

(!
) :! +,,; fffffi





Mff ) 4555 ff fi
&
&
fi
'fi
!
/
fi
= fi


fi
!
'fi

fffi
ff fi
ff

fffi
fi 'fi
!
fffifi fi 2fi


fi




fi ff


'fi

fi


fi
ff


fi ff


fi fi !

ff !

=



! 0






ffff fffffi

fi

# "
fi ff

0


ff




fi fi

fi




ffff ff


fi ff fi fi
ff


fiG fffi

fi

&
ff
!
ff

ff







fi




fifi
! fi
ff fi



fffi fi



fi

'fi
fiff fifi fi
0 fi
fi

fffffi



ff fi


9 fi



fffi


ff
fffiff fiff
fffifi 9 ff
fffi


fffffi





ff

J >
fi? " =
fi



ff
"

ff

fifi

fi

ff K
fi




fi fi



fi

ff
fffiff



ff
ff
7fi


ff
ff
fi
fi

fiff fifi fi

ff

E
ff

!


ff fi / !
ff
'fi fi

fffi


fi



fi !
fi ff fi




: fi
!



fi



!

&
ff
416

fi ffff fififi


# " 00



fffi

fi



fi
fi




C

# "

fi

ff








0 ff
2fiff
ffff

ff!
@ fi
#F 78




ffff
ff ff !




ffff &


ff

ff
!
fffffi

fi



G
"
ff
!

(
fi)


fffffi


/ ff
ff
ff

fffffi
ff

!
ff

fi
ffffff fi
fi
fi)
fifi

ff


ff

ff



ff 0
ff fi
ff


1

# "
&


fi


ff


*

fi


ff
ff fi ff




ff


ff

fi

ff



ff


!



fi
fi ff
! fi
ff

fifi ff!
ff
ff




fi'fi ! ff
ff


!
ff


ff

fi
!
ff
fi



! ff

ff fi &
fiff !

fi

ff
ff
fi

fi
ff


ff
ff fi

ff

'fi
ff

=




fi
ff

ff

ff 'fi


# "
00


ff # "



=
# "

ffff

ff Ffi
ffff
# "
0 ff

fi


;+
Kfi fi
2fi fi ff



# "

'fi
ff


fi fi fiff
0



!
fi


fi
K
ff



ff E ff
fi 7
fi ff ! fi !
fi
fi ff fi
/


fi ! 'fi

ff fi ff

42.

fifi fi
ff
fi
ff ff fifi fi

ff # " fi

fi
ff


fi !
fi ff
fi 'fi
'fi

fi
ff


fi
fi fffffi



# "

fi



fi
fi

ff



ff


= fi

@
fi'fi

# "

ffff
0
ff

fi





@ fi
#F 78
ffff


ff



+ ,

ff
@


ff
ff
! fi

fi fifffi
fi

'fi


ff
ff
ff
78


! fiff
fi !


fi

! ff

78 'fi


ff fiG
=

=

G



fi



!

G
fi
fi fi
!
0
78
G
ff

1

fi
fifffi




fi'fi ( ff 4 fi





4
(






























)

, fi
4

fi ff



ffff







0 fi
fi fi
=



fi

fiff !





E >
?
fiff
=
fiff

=
'fi


G
ff
+























ff

G




ff










P
ff








fi ff











-




fi fi


ff
9

-


ff
'fi


ff fi fi

0

ff ! fi fi


/
ff
ff
fi ! fi






! fi fifi @


ff



ff fi fi

!













421

fi

fi ffff fififi


fi
fi
G


P
ff



ff









fi ff










;




ff
fi
fi
ff
ff







ff




ff fi fi

fffi




ff




C

ff

fi
=

fi
fi




P
ff



ff







ff


fi ff





ff

<



:
fi !

fi
fi fi

<
ff fi


fi



fi fi :!
(
ff fi Q

fi fi :!
) ( 455+G
Q ($ 4 Q P R P ff Q
6







ff



ff

ff







ff



/

fi P4




, fi fi 4

fi Q
ff

fi
fi !




fi
3 Kfi
fi fi
fi Q
ff
ff fi fi :!
) ( 455+

fi fi

fi 6 fi




ff









ff











+
fi
-fi
fi
fifi
!%
!
fiff
fi fi(
fiff
0

fi
4




!

ff





fi
fi



-



E @
ff
= fi @
fi



fi




L @



fi
fi 0 @ fi

fi ff ff

!"#$
fi
ff 0


@ fi


fi


fi
&


ff
fffiff
3: ff fi



ff


'fi
fi fi
&


ff
ff





ff



ff



ff

ff

ff



ff



ff

422



fifi fi
ff
fi
ff ff fifi fi

fi @ fi

= >&
fi

?
ff


.
fi

fi


ff
fifi fi



fi
@ fi

ff
ff


fi
ff




0
ff
@ fi
fi
fi fi


fi
fi
@
3 ) 8
ff 455-
fi


fi

3:



fi
fi ff ff
ff



fi


fi ff

fi fi 3LffE
:!
4565 ff





fi
ff




$E 'fi

fi




2
fi 4 3


'fi





'fi $ fi


2
fi 4
fi



fifi



fi 2
fi 4 fi






ff
ff
! fi fi

fi
ff fi
9
fi

ff
fi
ff fi




2
fi 4
fi

ff ff

fi fi
/ ! fi
ff ff


ff
!
ff 'fi 'fi



# "

=

4



=
0 ff



/


fi

ff
ff
ff fi


2
fi 4


fi
ff
fi fi
ff

ff

fi



ff





ff
'fi
ff
fffiff fi



fiff

2





fi ! 'fi 'fi
ff

ff





fi


ff
fi'fi fi
fi

ff fi fi fi
fi




fi


fi
ff

C+



'fi



! ff fi

=
# "




ffff



ffff
ff!


ff

ff

ff

ff

ff





ff

ff

ff

ff

ff

ff

? / ff ' & & ff fi '
ff ff

ff
fi
fi ff fi ff ff' ' ff

fi ff fi
ff 'fifi fi ff ff fi
& fi
fifi @fifi

427

fi ffff fififi


Network

2

a2

sa

est

equ

r
a1

a1

(a)



Call source

Call destination

node / agent
a2 forwards request
a2

preallocate

a3

(b)
a1



Final route
a3

a2



sen

Allocate

a1

ds

con

nec

tm

ess

age

(c)



drop call
a3

a2

bandwidth a3

(d)

deallocate

a1

2
fi 4G

ff



C

ff

fi
fi ff
ffff




' #
# ff !)



"


fi ff $ fi


$


# "

fffffi




0 E

3: fi

3:
ff
ff

ff

fi
ff fi

fffffi


ff
$ fi


$ fi


ff E
3: fi
$

ff
fi
@ fi fi 'fi
6G $ 4 $ P

ff
>?
@ fi

@
ff fi'fi $ fffffi



ff 4 fi
fffffi



fi
ff


ff

fi


ff

ff fffffi
fiffff
ff

fi
fi fi
C- fi

fi



*
ff
fi


ff




4 fi

ff

ff $
fi


fi


fi

ff

fi fi
fi
$


ff
fi fffi


fi fiffff
ff ff fi


ff

ff

ff ff

ff



ff

ff

ff

ff

ff











ff



ff















ff



ff

ff

ff





ff

ff

. ff
ff A5

fi &ffff
fi ff
ff &


fi

424

fifi fi
ff
fi
ff ff fifi fi


C-


E
E



ff
fffi
ff


fiffff fi /

ff
0
!





fi
! &
fi




fi'fi 'fi F ff



ff




fi fi

fffi


ff fi


/

& ff





ff


ff


fi
fi
ff # "




# "
0 ff

ff fffffi


ff


ffff

fi

fiG

0


ff
!
fi'fi ff



ff
.

fffffi


ffff

fi .




ff
ff

'fi ff

fi
fi
fi /

& fffi
ff



# " ff
fffi


ff
ff
ff







fi


# "


fi


ff

ff

ff



fi 3fi


fi
ff fi
ff

ff
# "
=


fi


ff
ff ! ! ff



fi

ff
ff fi


=
0

fi



ff ff





fi fi
=


ff
!
ff
'fi fi


fi

fffffi

ff
>? @

fi
ff


ff




ff

'fi

@
ff

fi

ff &
E

fi



"#

@ fi

ff
00
fi

++4
@ fi
@7

fi
($
E fi
ff 3:





P +
fi
fi ($
ff
Q ($ ff
($ ff
($
ff
ff



fi ( ($


0

ff

fffiff



ff
ff
fffiff fiff

($ ff
ff

fffiff






>? ($

ff fi'fi
P 4 G P 4
fi



ff fi


ff
4 P 4 P Q ($
!

fi

E

ff
fi fi



2
fi 4


ff
2
fi 4
ff fi
@7

ff

fi fi fi
# "

;+4
&


ff

ff

ff

ff

ff





ff





ff

ff



ff











423







fi ffff fififi


G
@7

ff
ffff

fi
# "


fiffff fi
ff
fi'fi
'#$

#F 78

ffff
fi 0 ff




+,,,


fi #F 78 +,,, ff

ffff
G



fi



fi fi

ff
4,, fi
!


fi
A, J ff
fffiff

=


<+

+,,,.



ff fi fi

4,,
C+

ff
ff fi

ff fi :

fi
#F 78 ff

fi'fi
fi
ff fi







9 fffi
fi

!


fi @ fi
ff










fi

! fi ff


ff



! fi

3Lff
@
ff 7

fi
fi
#F 78

ff fi fi
ff
= fifi



fifffi
ff
ff



ff fi fi
ff



fifffi
ff
!

fi fi fi
@ fi




ff
$
fi
fi'fi ($ fi


fi

@ fi 0 fi

ff

ff fi'fi

ff

# "
;+4
ff

ff

ff

ff

ff

ff

" fi
ff #
#




ff

fi
ff


ff


00 :



= # "
fi


ff

ffff
fi ff

fi

= fi fiff



fi

fi



ff

ff


fi

ff





fi ff fi

ff




.
ff
fi ! fi
fi

-

!
'fi
'fi





fifi ff

fi
fi

fi $
$


! fi



! fiff
fi



!
G $
fiff

ff



!

$ fi
!
ff

ff

ff

ff

ff

ff

ff

42-

fifi fi
ff
fi
ff ff fifi fi

!
ff
fi
$



!

ff



;+

0 0
ff ! 'fi


! fffi
fi fi
fi



ff fi fi'fi
fi
fffffi

ff
fi

fi ff
fffi

fi # " 00 fi fi

fi



ff
=
fffffi

& fi

E !







'fi

fi fi




2fi
!
fifi

-
ff =
ff
fi

! fi fiff




!
ff
ff

ff
fi
fi'fi

AC fi ff



ff ff fi

'fi K



fi
!


>fi'fi? ff >
?
= : fi'fi

= ($

$

;+
fi
fi
2 ff

!
'fi



fi
fi

;+
fi
fffffi

ff
ff

fi'fi


ff

E ! E
ff
!


ff
G

O4

5

fi fi

G
4

4,
0
ff
ff

ff 2 ff
fffffi




ff fi
fi
ff fi ! fi

& ff fi fi

fi fi'fi ff

!



fi & fi

ff
!

ff fi
fi ff
fi'fi
! ff


0 ff
fi'fi


ff ff



ff

ff
fi


& fi


ff fi

fi ff
ff
fiff
fi
ff Ffi
ff


fi
7
fi
fi

ff
ff



ff

!
fi ff
E

fi
/
fi
ff

ff

ff

ff



ff

ff

ff

ff



ff



ff

ff

ff

ff





























ff



428







fi ffff fififi


fi fi



ff


fi E

fi





ff
ff fi

ff
ff

fi ff &

E


fi

ff

ff



& fffffi




. "

fi -fi
fi

(
fi



fffi
fi
ff
ff

fi
00 2
fi $ E ! fi
$

ff

ff $ !
fi 4 /

! 4 +

& ff

fi fffi 'fi 4 0
ff

ff



ff
fi
fi fffffi

fi

;++
fi

fi
ffff

@7 00 !

!


ff 4
4 'fi
fi
'fi ($ E !
ff 2
'fi

ff
ff ($ +T fiff
'fi

($ ($ ff ! fi
P +T 0 fffffi

ff

fffffi

7

fi


;++
+
($

ff

($
/
($ E !
ff


ff (

fi 'fi
(
fi 'fi ($ ( fi


fi !
P


P P +T

+T
ff
( ($

ff

(
ff

fi 'fi ( 'fi ( (
P +T +


P +T + P +T

+ +T 9

fi fi'fi
ff
P+T
ff
fi'fi

fffi 4 +T P 0

fi fi
P 4T 4 P +T
fi


ff
fi
ff P 4T 4 P +T



fiffff

4


fiff

ff ff fiff
ff


ff
ff ff

=
4
ff
ff fiff


ff
ff
fi'fi
fi
fi $ fiff

'fi E !
ff $

ff

ff P+T 4 fiff +
4 / ! fi fi'fi

$ 'fi ff
ff fi
ff

ff

ff



ff



















ff

ff









ff

ff

ff









ff



ff



ff

ff

ff

ff

ff

ff

ff







ff













ff

ff





ff

ff











ff









ff







ff







ff













ff





ff























ff

ff

ff





ff



ff

ff

- : ff 2 & BC &ff
fffi ff ff @
/ ff fi &
ff ff
ff fffi
3
fi ff
' ff
4 &fi

425

fifi fi
ff
fi
ff ff fifi fi

4G
ff
ff
fi


ff$

P +T




ff


$


P +T

P P +T

ff


ff
P +T +
P P +T +

P +T P +T +































= ff /
ff P +T

ff
$
$

G


ff

$(,

ff

4 P +T P












ff

+T P +T + +





44

0


fi
fi fi'fi
44


fi
4
ff fi

ff
ff

fi'fi

ff


fffi .

fi 2
P +T
44
fi








$



4 P












+T + +





fi
ff

4+





4




4-





fi 4+ ! $


fffi
fiff ff
=
!


fffiG
4;
4 P

fffi
fi
00
ff ff
# "
ff

ff



ff











.$ "

fi -fi
fi

(
fi
"


fffi
fi
ff
ff

fi
# "
ff



A+ fiff
!


ff $



!
'fi ff


# "


ff
fffffi
!
ff
!

ff



fi

ff

fi
ff
! ff
fiff

fffffi


fffffi

ff

ff


ff

ff





426

ff

fit + (n2)

2 tc

2 tc

+ (n2)

tc

+ (n2)



tc


1
Agent

2

3

Time

ffff fififi


n

2 communicating 1

n communicating n1

Information transmission

2
fi +G
ff
ff # "

ff


ff
$
ff
! ff

ff fi P P+ 1

$ ff



ff

ff P P P
PT P+


ff
$ ff
9



ff


!

$ P +T P +T P P +T P+
2
fi +

= fi


ff


ff


ff


fi fi
ff

$
ff
fi'fi



ff

fffi
fi $

ff
fi
fi'fi fiff



ff
ff
ff G
$ 4T 4

4A
fi

ff
4-
& ff
fi
fi 4A
ff
$


fffi
fiff ff

=
ff



fffiG

4C



fi fffi fffi
4C 4;

# " ff 00
ff

ff













ff









ff

ff











ff



ff

ff

ff

ff

ff









ff















ff



ff

ff















ff

ff



ff







.+ fi
"

fi -fi
fi

(
fi
" !


A- fi
# "
ff
!


ff

fffi 4C
fi 00

E
ff
4 P
fffi 4; "ff

fi
fifi

fi
%


























&& fi



ff


47.

fifi fi
ff
fi
ff ff fifi fi



fi

4









+T




4 P

4<



fi

! fi

fffi
fffffi


fffffi

$
/ fi # "

fi fffi 00
/

# "

fi
ff

ff
ff
ff
00 fi



# " ff fi

ff





.. -fi! '

fi ffffff
"



ff
ff

ff


fi
# "
ff

ff 'fi

ff
# " 00 !


fi

ff
ff ff fi
!
fi
ff

ff /

ff

fi ff
fi
$$
4









ff
:


ff

ff



ff 1

ff

fffi fi
fiff fi




ff fi
ff :

ff

fi fiff

ff


ff
ff



ff
ff

00
# "
A;

fi

ff

# "
=
G
*

fi 'fi
4
! $
fi



ff ff

fffi
fi
/ fi

fi

ff ff
( ! fi $
ff












































































fi ff

$
fi
&
ff

G
fiff

P 4 ff










ff






46



fi
($

fiff fi

L P 4

&
ff ff ff
fiff

P4

& ff








; 3
fi ff
& & ff ff ff
fi fi
& ' fifi ff &ff ff fi &
ff fifi
ff
$ fi ff ff 'fi

fi & ff / ff & ff
'fi ff ff

:' fffi
$ E

471

fi ffff fififi



$
0

fi
ff ff ff









ff
ff

fi ff


E >=?

ff fi
=

ff


ff ff / fiff 46
ff ff fi
'fi ff

fi fi

fi

&




fi

fi ff
ff







A; # "

00 fi


fi
fifi

fi % &&

fiff


ff !




ff





fiff
ff ff ff fi














































.0 fi
fi!
ff "& '
fi


A+ A- fiff
! ff



ff
fffi 4;
4C
fi

ff
!


fi



ff fi
! ff



fffi fffi

fi




ff

ff


00 fffi 4; fi fiff





ff ff 00

fi



fi



"




A+ ff







fi
fffi 4;
$


+T
45








ff

ff












)$

$ ff
ff


$
ff
ff

fi

A;

4C
ff
45 fi


G




+ +T
+,


























)$


fiffff



fifi

fi $ )
fi



% && ff fi


ff




/ E
ff ff 3
'fi ' 6ff @fi fifi /
ff &

fi ff ' ff &ff
ff ff fi

472


$






fifi fi
ff
fi
ff ff fifi fi



fi ff

+, ff 4


+T
+4



#

-

ff


4
fi
fi fi

ff
fi
!



fffi
fi
fffffi

ff
fffffi



fi

ff


ff
# "
00


ff

AA fi

! fiff

! fi # " fi

00
fifi

fi + )
fi %















&&



ff fi
fi
ff


ff


fi
'fi

ff
fi # "

ff


fi fi



ff :

fi


# "
!
ff

00

fi
ff ff ff
fi
# "
fi
fi
ff




fffi
!




fffi

ff

$


ffff
%

fi
ff
&'ff



= fiff fiff
ff

fi








fffi
fi ff

fi
&
ff fi'fi
fi
ffff


fi
ff fi


fi

!

fi

ffff
# " @7 #F 78




;+

fffi
2
fi


# "



ff



;+4

0 fi
fi

: fiff



fi
fffi
0



ff ! ) 3fi
+,,;



ff
fffffi



fffffi





ff

0
ff


0 ff


-
fffffi


ff

fiff


ff

fffffi




ff




ffff

fi
"

%ff


fi fi
fffi

=
fi
fi



fifi fi !
477

fi ffff fififi


E





ffG
ff
fi fi fffffi


ff
ff
fi



F fi



fi

fi

fi
fi fi fi


fi
fi


fi

!




9
ff 9
ff


fi


=


ff
fffiff





: =

ff


fi

fi ff
fffiff fiff fi

9





0 fifi
!%
! fiff
fi fi fi


;+
fi


'fi
fi

/ ff



fi
ffff

ff



ff
fi


;+
&

fi
ff

ff G
'fi

'fi


'fi

'fi









fi
= =


fi
fi

G
! $

.
fi . @ fi

@ fi

E
ff

G R, 4S







fi . G fi
. G . G !
ff


fi

ff
fi

fi
ff . !
ff ff
.
fffi
ff fi


fffffi

ff #F
78

&

@
ff ff



fi
#F 78 fi
fi fi


fiffff
&


ff





fi


fi
!


fi
fi


E

fi
fi


fi E @
ff








G

>
?
fi
fffi

ff


ff

>?

;+-
= fi fi ff

fi
ff
ff


ff
G
fi



fi

fi








ff





ff

ff









ff

ff

ff

ff



ff













ff

ff

ff









ff



ff

ff



ff

ff

ff



ff

ff







ff









ff

ff

474

fifi fi
ff
fi
ff ff fifi fi


ff


! fi fi



ff

fi fi
fi
ff
ff


fi


fi ($
fi





fi
$ fi

fi / fi fi
:


2
fi -


$


4
!
fi


ff
fffiff fi
ff
ff

+



ff

ff
;


fi $


--
fi

-; ff

fi
-C fi







-
= = !
fi
!



fi



< ff

6 fffi 4, 5($
4,
fi ff

=
fffi


44 fi





4+
ff
ff

fi

4- $

ff
A, fi

fi

@
ff

.

fi
#F 78 fi
A+ A;
fi
fi'fi


AA
fffi




fi

ff




A<
2

ff

fi
A6
fi



fi
ff


fi

fi
/
$
!
!




fi

4;




fi

4C ff


fi fi

+4
fi



;+
ff
;5 fi

.


ff
fi


/
fi #F 78


+4

ff



+,. fi
ff
#F 78



ff

fi


# "



C-4 C-+
ff
$ 9

46 ;<
fi
# " fi










ff

fi

ff







ff

ff







ff

ff







ff

ff











ff



ff

ff

ff





!



ff







ff



ff





ff





ff







ff





ff



! / 3
& ff' ' ff ff ff fifi ff = fi

% 'fi & fi fi


fifi

ff
2 ff A5

fi ' fi
fi % &' 36

fi fifi fi 3
fi

fi $ : ff ff A5
ff fi ff ' # ff' ff

fifi fi & ff' ' ff ff (# fifi
@fi ff fi fifi

473

fi ffff fififi



fffi fi fifi
fi
ff
fffffi


ff





fffi
ff ! !

ff " !



ff



fffi
ff ! # !

" "


# " $ !






ff



ff !

ff



fffi
ff ! !


!

ff !" %&'&( %&'&)

fi#

ff ! $!%&' *&)&'

ff
"
#


ff " !



! +, " !






#!$ff %

ff
&
,

ff ! $!%&'

fi# %
ff

ff
" !

ff (& *&)&)

!
" #


fffi' ) %

fi


%
(%
(

ff -
fffffi


&
,
ff "

ff
ff ..
/

fffffi

ff ! $!%&' fi# ! /-/,

)

)
ff fi fffffi

%
ff (%
ff ()



!

ff !" %&'&( %&'&)

! 0

)

)
ff fi fffffi

% (% ()

fi#
ff "

ff
ff -
./1
fffffi

ff ! $!%&'

%
ff (%
ff (



% (% (

ff

" "





&
,

ff
ff ! $!%&' 2 $ /-/,
ff* #
! " ff


ff * %


++#



fffi
ff !

ff ! 0



























































2
fi -G


fi ff

47-

fifi fi
ff
fi
ff ff fifi fi



ff
ff
ff fffi
fi
fffffi
fi





;A
C-4 C-+ = fi

fi

fi


fi fi
@
ff
;C fi fi
@



;4 fi

fi

ff

ff

ff
fi
F







fi
fi
ff


'fi
+;


=




fi
E @
ff

fi

fi



fi

G






ff



ff

ff



ff


'



)

ff

++





0 'fi
++
ff
ff # " @7
fi
#F 78
fi @ fi
'fi
++ /

>fffi? ff G R,4S fffi

&

fi @
ff fi &





ff !

fi

3Lff

:!
4565




fi'fi

fi


+A

+6 @7
fi


ff




fi


-4


'fi ff
K ff
@- ff .
;++ 'fi
fi
,

ff fi


ff
-+ #F 78

@
ff
+<



'fi
ff

'fi
#F 78
0
fiff


ff
#F 78
fi
2
ff

! fi

fi
C,

ff

fi
fffi fi

ff fi fi

ff
C4
ff
ff
fi

E
fi



= ff fi ff









-6

fi
ff ff
fi


2
fi - 9
ff fi fi


C-

fi
C;



ffff
fiff $

fffi
fi


ff
fi'fi
-5
ff

# " fi
@ fi


;,
fiff
fi
ff
fi fffi
#F
78 @
ff



ff
ff

A< fi :
fi ff
ff #F 78


C-+




ff



ff

"

"

ff



ff



ff

ff

ff



ff



ff



ff





ff



ff

ff



ff

ff





ff

ff













ff









478

fi ffff fififi



fi
ff


ff




-

=



ff





=
fi



ff


&
ff

fifi fi





!
@
ff ff fi fi






ff

!
ff

ff


!
ff


ff
fi

fffi
ff fi

# " fi =
fi


fi
fffi

# $ff

0$ "
1

ff

fi




C+
fi
# "
ff


ff
fi




ff

ff >ff?

ff

fi : fffi
ff fi


ff


# "
L fi
ff ff # " !

ff ff # "


$
- ' !) .


fi /'# 0

2
fi - fi

fi
# " fi

fffi
fi fi fi ff G



+-







ff

ff









% ff

ff




fi
fi ff

fi

2
fi -

ffff fi'fi

fi fi


@
ff fi
ff fi

ff
fi fi
fi >ff?

% ff





ff

ff

ff

# $ff

-

' !) +

fi /'#+0




ff
# " G fi






fi 2 ff fi
# " fi

fffi
G

+;
ff
P 4


ff

ff





ff fi


fi

ff





fi
fi


fi

ff
#F 78
fi
ff
ff









7 % ff fi ff ff fi fi 7 ff ff'

'fi ff &' ff

fi
fi3 fi fi 'fi 3
fi & ff
'fi ff 6
fi3 ff fi
ff & &
@ ff ff
ff ff & )D 4 fi6 ff

ff fi ff 5 + C'
$

475

fifi fi
ff
fi
ff ff fifi fi

( )*
) ff

3

fi

C fi

ff
ff

fi &
# " ff ff! @7 #F
78

fiff
fffi

ff
ff fi'fi fi
ff
ff fffi


2 fiff

fffi fi ff
fffffi




ff


0
1 &2 ) )ff
ffff

K

!
ff
ff
fiff fi
fi fi
fi





fi
ff
fi fi fi
fiff fifi ff
fifi

ff

ff fi fi ff fiff


fiff fifi fi
fi fi
ff

fifi fi

ff


fffiff !


fffi
fiff fifi fi ! ! fiff
fi
! fi !





fi
fi
fi

fffi








fi


fffi

ff : ff





fi >-fi 3 ? D(



! =

fiff
ff D(

ff fi



=
% $ ff fiff
fi

ff 4 fi +
fi
ff

fi fi


$

ff

fi fi fi

fi ff D(
+



ff
D( fi fi

+


=
fffi
fi


D(

ff ff



ff



fi
ff D(
! fi

! =

&

'

!

'

!

!

9 ff /F)
ff ff fi fi ff fi
' '
? : /F)
fi fifi
fifi ff fffi ff fi ff


fi fifi
/F)

476

fi ffff fififi


1

)ff $ ) %))

fi ff



<44 fffi fifi

ff


ff ff fffi fi



ff ff



fifi fffffi





ff
ff ff /


&






fi ff
fi

ff
fi 'fi
fi


fi

ff

"




fi fi

fi ff fi
ff
ff







ff

fi
fi
ff

fi fifi
fi
fffffi

fi


ff ff

fi



'fi
fi fffi fiff fifi

fi

fi


= ff

fffiff fi
fi


fffi ! !

fi fffi

fi fi



ff
fi
fifi
ff fi


fffi
fiff




fi


2
& fi

& fi fi fi ff


& fffffi




&


'





!

&





!

1 $
!)
+



fi ff fi
& ff fffffi


C+ fiff
/ ff
ff ff

ff

!
ff



fi fi


ff
fi


ff !
ff
fi
'fi


ff ff

fi @7 ff


ff
ff

fi


'fi
;++


ff
ff


# " ff ff ff


fiffff
ff

C-4 C-+

0

ff


fifi fi
ff
fiff $* fi
ff

ff

&
'fi
ff F








. # ff' fi &ff A5 ff fi fifi fi ff
' fi ff fi ff ff fifi
fi & ff ff BC
A>6C+ % &' fifi & & ff fifi ff ff A5
ff fi fi
fi & ff fi ff ff A5
fi ) fi 7$

44.

fifi fi
ff
fi
ff ff fifi fi

2
fi ;G -C
fi


fi
ffff
#F 78

ff




ff






fi'fi

ff

fi fi @ fi
<+

ff &



# " / ff #F 78
fffi fi
ff
fiff fi ff fi fffi


fffffi

J fiff ff



fiff

fi ff ff fffi fi fi

= fiff
ff

ff

E !
fffi
ff
fi

fffi
fi

ff ff



ff fi


fffi






fi fi

ff

ff

& fffffi


ff

fi ff




fi



fi



$ 7
ff

$


ff

2
fi AG 7ff !


2 !



ff @7 # " # " #F 78 ff

fffi


<4
441

fi ffff fififi


9
ff fi fiff
& !


fi fi
ff 2
fi ;

-C
fi
ff
J A,
ff 2
fi 4,, ff 2
fi -C

fi
fi

fi

78
!
fi

++
fi
fi
ff!

ff

fi fi


ff

ff = fi fi ff
&
L$+
= fi fiff




E
0 ff

fi

!


ff
fffiff




fffi ff




ff fi fi
ff fi

G
,,- 3Lff
fffi ,4
fi
ff -C A, 4,,
ff

= fi ;

: fi
ff





L ! fi
+,
ff fi
ff fi
>?
!










ff
!






fi &

& ! ff "

ff

ff :
fi



fffi






ff

ff fi fi

fffi
fi

ff


fffi







fi
fi
fffi
fi : fi
& fiff
fi







fffi
fi
&
fi fifi
ff # " @7 #F 78
ff







'fi



fffi
fi

fffi
fi A,,,,,
ff

2
fi ; 4,,,,,,
ff
2
fi +,,,,,,
ff

2
fi 7fi 4,
fffi
fi = fi




= 5AI = ff
fffiff

4, fi




fi fi fi
fi fffffi


fi





<+4 &
fi



fifi



<++ fi ff
fffi

ff

<+-


"

1 ')
3
ffff $


:


fi
ff fi
ff
fi



ff

/
fi

fi


ff D( fi
fi ff
=
ff ff


- G ff
fi & & ff ' '
ff
fi ff fi & ' % ff &
ff
fi
fi

442

fifi fi
ff
fi
ff ff fifi fi

fi fi! :
ff

fiG
fi




fffi fi ff D( fi



fi fi
ff fi
fi D( fi fffi fi


fffi
fi 4,
fffi
fi
fi





2fi fi
fffi

fi







ff ! fi
fffiff

+G " fi
J 2
fi ;
&ff
.1
.2
.4
.-

9
3.64
7241
1666
1458



(
...45
...74
...15
...12

:;<(
82--.-6
3378
3458

9
3.65
72-4
2.28
13.8


(
...8...78
...21
...11





:;<( 9 ( :;<( 9 (
8211
fffi
...32 8.23 2384 ...22
-.3- fi ...76 355- 1664 ...13327 fi ...2 3286 1452 ....6
3744 ff
fi ...14 3.- 1132 ...12

:;<(
6638
68-3
5644
532

-G " fi
J 2
fi
&ff
.1
.2
.4
.-

9
3871
7811
2265
1818



(
...42
...2
...12
...1

:;<(
5183
-683
-144
355

9
3513
7872
2773
1848


(
...32
...25
...12
....6





:;<( 9 ( :;<( 9 (
51-8
fi ...32 5.6 1215 ...28
-587 fi
...2- -577 1.21 ...11
-2- fi
ff ...17 -.47 84- ....8
-126 fffi ....5 3837 -11 ....4

:;<(
6666
665
665
665

;G " fi
J 2
fi
&ff
.1
.2
.4

9
7386
2418
1355



(
...72
...18
...11

:;<(
--32
3841
34.1

9
7352431-1-


(
...74
...2
....8





:;<( 9 ( :;<( 9
-335 fi ...7 -2-3 537
3615 fi ...14 3428 -12
3337 fffiff ....5 3.82 486

(
...71
...17
....-

:;<(
6655
6657
666

ff
+ fi


&
D( fi


& !
: :

fi
&ff & ff 'fifi ff & ff
& fifi
fi 3 fifi $ ff B6'fi ff & ff 'fifi
& ff 'fifi ff ff B6'fi % &' ff fifi 'fifi
&ffff ff &ff fifi
fi

447

fi ffff fififi









2
fi ; - ; ff
fffiff

2
fi
fi


fi fi fiff > ?



# " ff

fi
& !
2 ff
+
,4 # "

fi A46AI # "
A,56I @7 A,5;I #F 78 +A<;I




# " ff

ff fi
ff

! fi fi
# " !

ff





fi fi

!
fifi








=
fi
# "


fi
ff

fffiff
fi



ff







fi

fi


-15

PTC-A / QR
PTC-M / QR

% improvement deviation IZDS (relative TPORL)

% improvement deviation IZDS (relative QR)

0

-2

-4

-6

-8

-10

-12

-14
0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6
Call origination probability

$ A5 BC

PTC-A / TPOT-RL
PTC-M / TPOT-RL

-20
-25
-30
-35
-40
-45
-50
-55
-60
-65
0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6
Call origination probability

$ A5 A>6C+

2
fi CG ffff fi

ff D(
@7 #F 78
J 2
fi ;
: fffi
ffff
fi fi
ff
# "
ff


@7 #F 78 =

fi

ff D(
fffi +
+
<44 fi'fi
%) ,
, -,, -,)*)* ,
fi ff ! G
%)


2
fi C

ffff fi


ff D(
fi
# " @7 2
fi C #F 78
2
fi C
2
fi ;
fi 0

= fi fi




fi

fi )*+ fi ,- .-/

ff %

2ff

=
ffff


# "
@7 #F 78 fi
& fi !




=
5AI = 2 ff

>8? ,4
+





,4


fi ff D(
+C+I $* # " +55I +
444

fifi fi
ff
fi
ff ff fifi fi

1

-20

PTC-A / QR
PTC-M / QR

% improvement deviation IZDS (relative TPORL)

% improvement deviation IZDS (relative QR)

0
-1
-2
-3
-4
-5
-6
-7
-8
0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6

PTC-A / TPOT-RL
PTC-M / TPOT-RL

-25
-30
-35
-40
-45
-50
-55
-60
-65
-70
0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6

Call origination probability

Call origination probability

$ A5 BC

$ A5 A>6C+

2
fi <G ffff fi

ff D(
@7 #F 78
J 2
fi

2

-25

PTC-A / QR
PTC-M / QR

% improvement deviation IZDS (relative TPORL)

% improvement deviation IZDS (relative QR)

0

-2

-4

-6

-8

-10

-12

-14
0.1

0.15

0.2

0.25

0.3

0.35

0.4

Call origination probability

PTC-A / TPOT-RL
PTC-M / TPOT-RL

-30

-35

-40

-45

-50

-55

-60
0.1

0.15

0.2

0.25

0.3

0.35

0.4

Call origination probability

$ A5 BC

$ A5 A>6C+

2
fi 6G ffff fi

ff D(
@7 #F 78
J 2
fi

443

fi ffff fififi


+ D(
@7 fi fi # "
4+-<I ++
+

@7 fi

ff D( # " ff


@7
ff
ff
# "
#F 78 ff # "

+C+I

ff D(

= fi #F 78
<;4AI
$
++++ fi fi # "
C;CCI
$
D(
#F 78 ff # " ff
# "
fi ff @7 #F 78 fi
fi
ff

fffiff
fi

ff


fi fi




'fi


ff # " ff D( @7









ffff # " @7 #F 78 fi
fi
2
fi C
ffff # " @7
4+-<I
,4



-<I
,C
ff

2
fi C # "
C;CCI
#F 78 ,4 fi 466+I ,C 0


ff

fi


ff fi
!




ff
'fi




ff fi

fi
!

fi
ff



ff
& # "


:


ff # "
ff!


2
fi < fi
2
fi
2
fi 6
2
fi

ff
fi! fi fffi


ff

fi !
fifi
fi
ff fi ff




fi
ff


2
fi 5

ff

fi # " @7 #F 78







ff ,4 ,C

fffi
fi fi

2
fi ;$ ff # "

# " . # "
fi
ff fi

ff
# " @7 #F
78 fi ff


,4
ff A,


,C
ff A, fi
fi&





ff


fi
fi
+ : fi

ff
fffi
fifi

fffi
fi 2
fi 5
fi =
& fiG ,4 ,+ ,; ,C ,6

# "

fi fi
# " @7 #F 78 0
fi fi
&
fifi
G
,4 ,C ff



fi

fi ff fifi



=



fi
#
fi



!



ff


ff

&
ff
# ff' 3
& ff fifi ff ff
fi fifi ff fi ff

' ff fi fi fifi ff % & ff
fi

fi
fi ff



44-

fifi fi
ff
fi
ff ff fifi fi




fi



fi
ff ff



ff
fi fi
# " fiff
ff! fi




ff
fi

0.45

PTC-M
QR
TPOTRL

0.45

0.4

0.4

0.35

0.35

0.3

Call success rate

Call success rate

0.5

0.3

0.25

0.25

0.2

0.2

0.15

0.15

0.1

0.1

0

10

20

30

40

50
60
Time

70

80

90

PTC-M
QR
TPOTRL

0.05

100

$ # ff

0

10

20

30

40

50
60
Time

70

80

90

100

$ # ff 7

% Difference call success rates QR PTC-M

2
fi 5G
ff

fi @7 # " #F 78
!
fifi
J 2
fi ;
-2
-4
-6
-8
-10
-12
-14
-16
min
avg
max

-18
-20

1

2

3

4

5

6

Degree dynamism

2
fi 4,G fiffff

fi
& @7 # "

! fifi
J 2
fi ;
0
ff fiffff
& ff

!
fi

ff


=
fiff


fffi
fi > ff
ff? 2 ff 2
fi 5
ff
ff + 2
fi 5 ff
ff

ff
ff fffi
& fi @7
448

fi ffff fififi





, "

, "
, -, )*, "
#F 78 fi
# "
G %) , "

ff
fi 0

& fffi

ff
fiffff

ffff fi fi
# " = ff

fffiff
ff ff
fffiff

&
ff
fi


ff


fi
ffff



ff
ff

fi'fi ff


ff

fffiff ff ff
fffiff
&
fi
fffi
fiffff
&
ffff
fi
2 ff
2
fi 5 ff

fffiff ff
ff
fffiff
& fffi

,4


,C fi'fi ff



&

fffi 2
fi 4, ff
fffi
ff
ff fi
fi
ff @7
ff # "

#F 78

fi # "
@7 fi fiffff ff
#F 78
# "



L
2
fi 4,
ff
ff
fiffff


fi
&


= fi
ff
ff +


ff ,4 ,+. -

,4 ,+
,;. ;

,4 ,+ ,; ,C.

,4 ,+ ,; ,C ,6
fi
fi
&


fi = fi
ff

fffiff ff
fffiff
& fi
fiff
ff
ff 2



ff 6I
ff
ff
+

fi ;AI ff
ff


fi


fiff



fffi
fi

ff


ff / fi


fi
+ 0

fi

& # "


=
fi
ff
ff 2 ff

fi 4,+I
+ ff
ff 5AI

ff
ff


fi fi

fffi

ff








fi
ff

(



ff

0


2 ff



fi ff D(
fi 4+-<I
# " @7 fi CAI

# " #F 78 2fi
ff

# "

4,I
ffff
fi @7
=
&


fffi
fi
1

')
3 $
)
ffff ) %))

fi fi

<+4

ff # "
@7 #F 78

fffi &

ff


fi








ff fi
fffi
<4+
=


fffi

fi
7fi ff
ff


:
ff


fiffff




<+4 fi


ff # " ff! fi

!





445

fifi fi
ff
fi
ff ff fifi fi

AG " fi
fi
J 2
fi ;
&ff
.1
.2
.4
.-

(ff
'+
)=9
)=$
)*+&
'+
)=9
)=$
)*+&
'+
)=9
)=$
)*+&
'+
)=9
)=$
)*+&

1

fi

.5-7
.538
.-77

fi

.887
.8-5
.354

fi
.-83
.--8
.46-

fi
.-1
.36.415

$


7
4
3
8
fi .-7 .31 .42 .78 .733
.845 .-72 .31- .42- .784 .733
.837 fi fi
fi fi ff fi
.372 .73- .215 .1-4 .145 .12fi
.44 .71 .222 .185 .135
.357 .44 .713 .271 .151 .1-4
.357 fi fi fi fiff fiff
.4-2 .2-- .176 .1.1 ..65 ..5fiff .2-- .1-1 .1.7 ..84 ..-4
.418 .282 .18 .111 ..51 ..-5
.41- fi fiff fiffff fi ff fi
.783 .165 ..5- ..36 ..-7 ..34
fi .153 .1.7 ..-2 ..43 ..78
.727 .16 .111 ..-5 ..48 ..4
.722 fiff fiffff fi fi fi
.7.1 .145 ..-3 ..47 ..4- ..78
2

5
6
1.
.747 .744 .74
.743 .745 .734

fi
fi
fi

..64 ..81 ..36
.148 .148 .176
.133 .131 .131

fiff

fiff
ff fiff


..-- ..3- ..45
..3-7 ..37 ..3
..- ..33 ..35

fiff fi
fi

..4 ..78 ..26
..7 ..26 ..28
..73 ..72 ..7

fi
fi fi

..27 ..13 ..17

CG " fi
fi
J 2
fi
&ff
.1
.2
.4
.-

(ff
'+
)=9
)=$
)*+&
'+
)=9
)=$
)*+&
'+
)=9
)=$
)*+&
'+
)=9
)=$
)*+&

1

fi
.58.587
.158

fi
.88
.8-.214

fi

.-45
.-4
.2.2

fi


.3-.338
.188

$


7
4
3
8
fiff .- .3.4 .425 .786 .737
.84- .35- .463 .42- .751 .7-3
.837 fiff fi
ffff fi fi fi
.126 .11 .1.2 .1.4 .176 .2.7
fi
.781 .2-5 .168 .1-1 .141
.3-1 .7-6 .2-3 .2 .1-7 .143
.3-4 fi
fi fi fiff fiff

.128 ..53 ..-3 ..33 ..- ..-1
.757 .2.7 .12 .852 .35 .462
fi
.2.5 .12- .525 .-71 .37
.754 fiff fiff fi fi fi


.1.6 ..34 ..23 ..21 ..24 ..45
.25- .177 .812 .425 .7.3 .246
fi .14 .851 .451 .748 .258
.258 fiff fi fi
fiff fi

..63 ..4- ..18 ..11 ...8. ...3.
2

fi # "
ff




<+4
fi fi
&
fi ff






446

fi ffff fififi


<G " fi
fi
J 2
fi
&ff
.1
.2
.4
.-

(ff
'+
)=9
)=$
)*+&
'+
)=9
)=$
)*+&
'+
)=9
)=$
)*+&
'+
)=9
)=$
)*+&

1

2

7

fi fi

fiff
.56 .846 .356
.55 .825 .365
.22 .182 .14

fi fi fi

.578 .-25 .43
.527 .-22 .445
.2.2 .135 .11

fi fi
fiff


$


3
8
5
fi
.724 .248 .2.5 .183
.472 .718 .248 .22 .168
.447 fi fi fi fi
.1.4 ..86 ..38 ..31 ..43
fi .156 .127 ..65 ..86
.258 .185 .124 .1 ..58
.262 fiff fiff fiff fi
..82 ..48 ..72 ..26 ..23
.18 ..64 ..38 ..41 ..71
.1-1 ..6 ..38 ..42 ..74
4

.8-- .454 .265
.84- .48- .7.7 fiff
.156 .141 ..6 ..3fiff fi fi
.112
.8.- .767 .21- .1.6
.-55 .75- .221 fiffff
.181 .128 ..86 ..48

6
1.
11
12
.146 .12 ..58 ..52
.1-6 .141 .111 .1

fiffff fiff fiff fiff
..78 ..26 ..25 ..26
..-1 ..48 ..7- ..26
..81 ..3- ..4- ..76

fi fi fi
fi
..1- ..12 ...5 .....22 ..18 ..11 ..12
..2- ..21 ..143 ..13

fi fiff fi fi fiff fi fiff fiff

..74 ..2 ..1-8 ..11 ...- ...7 ...2 1. 4
..- ..7 ..24 ..15 ..12 ...6 ...- ...3
..38 ..71 ..23 ..168 ..14 ..118 ...5 ...83

fiff fi fi fi fiff fiff fi fi

..28 ..13 ..1 ...- ...7 1. 4 1. 4 1. 4

ff
C < fi
& fi >ff

fi? fi
& !
= fi ;




2

fi
- @7

fi # " /
fi



# "
fiff
@7

# " ff #F 78



fi
# "
@7 #F 78




ffff
,


fi
# "
. , -, )*
, . %)


@7 #F 78
, -, )*

%)



fi

ff

fffiff
fi

2

fi 44
fi
# " @7 2
fi 44
# " @7 2
fi 44 # " #F 78 2
fi 44 # "
#F 78 2
fi 44

fi ff

fffiff fi fi




fi
2
fi ; 9

= fi

& fi




2
fi 4+
4-

fffi fi

2
fi

2fi
= fi 44 44










fi
>ff

fffiff
fi?
fi 4 + @7 ff

# "
# "

ff


2 ff ,C @7

fi AI
ffff # "

4 2

fi 44 /



fi


!





!







(

)



!

ff 3 'fi ff ff
ff

ff
&

43.

fifi fi
ff
fi
ff ff fifi fi


>ff

fffiff fi?
- fifi


fffi
# "
@7

fi

2
ff
2
fi 44 fi ,C # "
ff 4AI
ff
ff @7




6
ff fi


ffff






fi # "
ff


ff &




fi

= fi 44
44 # " # " ff #F 78
fi
fi
20

load
load
load
load

20

0.1
0.2
0.4
0.6

10

5

0

10

5

0

-5

-10

0.1
0.2
0.4
0.6

15

% improvement success rates

% improvement success rates

15

load
load
load
load

1

2

3

4
5
6
7
Minimum hop count

8

9

-5

10

1

2

3

$ A56 BC

load
load
load
load

500

4
5
6
7
Minimum hop count

8

9

10

8

9

10

$ A56 BC
500

0.1
0.2
0.4
0.6

load
load
load
load

450

0.1
0.2
0.4
0.6

400

% improvement success rates

% improvement success rates

400

300

200

350
300
250
200
150
100

100

50
0

1

2

3

4

5

6

7

8

9

10

Minimum hop count

0

1

2

3

4

5

6

7

Minimum hop count

$ A56 A>6C+

$ A56 A>6C+

2
fi 44G " fi
fi
J 2
fi ;


# " fi


fi
fffi
fi



fi
ff





ff



ff



fifi fi



fi








fi
431

fi ffff fififi


25

load
load
load
load

16

0.1
0.2
0.4
0.6

20

0.1
0.2
0.4
0.6

12

% improvement success rates

% improvement success rates

load
load
load
load

14

15

10

5

10
8
6
4
2
0

0

-2
-5

1

2

3
4
5
Minimum hop count

6

-4

7

1

2

$ A56 BC
1000

load
load
load
load

1000

0.1
0.2
0.4
0.6

7

load
load
load
load

0.1
0.2
0.4
0.6

800

% improvement success rates

% improvement success rates

6

$ A56 BC

800

600

400

200

0

3
4
5
Minimum hop count

600

400

200

1

2

3
4
5
Minimum hop count

6

0

7

$ A56 A>6C+

1

2

3
4
5
Minimum hop count

$ A56 A>6C+

2
fi 4+G " fi
fi
J 2
fi

432

6

7

fifi fi
ff
fi
ff ff fifi fi

60

load
load
load
load

40

30

20

10

30

20

10

1

2

3

4
5
6
7
8
9
Minimum hop count

10

11

-10

12

1

2

3

$ A56 BC
1000

load
load
load
load

1000

0.1
0.2
0.4
0.6

10

11

12

load
load
load
load

10

11

12

0.1
0.2
0.4
0.6

% improvement success rates

800

600

400

200

0

4
5
6
7
8
9
Minimum hop count

$ A56 BC

800

% improvement success rates

0.1
0.2
0.4
0.6

0

0

-10

load
load
load
load

40

% improvement success rates

% improvement success rates

50

50

0.1
0.2
0.4
0.6

600

400

200

1

2

3

4
5
6
7
8
9
Minimum hop count

10

11

12

$ A56 A>6C+

0

1

2

3

4
5
6
7
8
9
Minimum hop count

$ A56 A>6C+

2
fi 4-G " fi
fi
J 2
fi

437

fi ffff fififi



fi
ff



! fi




ff
!




fi ff
fi :

ff fi
ff
# "




!
fi



ff





fi
@7


fi
# "

@7 fi





fifi fi
ff ff
fi



fi
ff 1



ff




fi




2
fi 44

# "
ff
&
@7 #F 78 fi
# "

ff &



# " fi @7
#F 78








# " @7
2
fi 44 # " @7 2
fi 44





# " #F 78 2
fi 44 # " #F 78 2
fi 44
ff






ff 2
fi 44
= fi 4+ 4-



= fi





fi







Kfi



fi




<+4

fi fi
ff


fiff



ff
fffi
0
fffffi


ff fi



ff



fi







ff @7 #F 78 ff # "



fi
ff
@7 #F 78
# "
# "


/

fi # "
ff!

2 ff
2
fi 44 6



fi +AI
,4 ff 4AI
,C




fiffff

!



!

!

!

ff
ff
ff

( fi fi




ffff
ff A,I

fifi
# " @7

4+
4,, ff

!
,C
2
fi 4- 2 ff ff fi # "


ffff #F 78 ff 4,,,I 2
fi 4-
1 ')
3 !)
+
$


fiff ff
<4-
=

ff



!
fffi
ff
fffi
fiff fi ff
fi

ff
fffi fffiff

7fi ff
ff =
ff ff


fi fi! 6 ff


fi



2
fi ; 5 4, ff

2
fi 2
fi
fi


434

fifi fi
ff
fi
ff ff fifi fi




ff fi fiff > ?


=

# "
@7 #F 78 2 ff
6

,+A
# " ,+C
# " ,-5 @7 ,A+- #F 78
,4





fi
ff fiff
ff >I
? fi
fi
, # ." ff
ff fi






%)


, .
, -, )*




fi fffi



%)

, -, )*
ff
fffffi




2 ff
6 ,4
# " fi -ACI $++ ff @7 fi A+I
$ #F 78 /


ff

fi 6,-I *$$
@7 fi <+6I *$$

#F 78


,C

fi


!


fiff ff
@7 #F 78
fffi



# "

6 ff
ff ,-5
4;A
@7 J +<+I
ff ,A+- 4,A
#F 78 J 4,4I

ff ,+A4 ,+6A
# " J 4-AI
J
ff ,4
,C










(

)



6G ff
ff
J 2
fi ;


.1
.2
.4
.-

'+
9 (
.76 ...45
.-- ...86
11 ..1
143 ..123



!

)=9
)=$
)*+& !"%. !"%/ !"%.
9 ( 9 ( 9 ( (&
(&
! $!%&'
.2- ...16 fi
ff ...16 .327 ...27 7777 73-4 3.25
.251 ...2 fi
...22 .-57 ...26 3842 3577 3553
.256 ...15 fi ...1- .561 ...7- 8787 8415 -83.2564 ...18 fi
...13 1.3 ...88 5..4 5.74 8247

!"%/
! $!%&'

32..
3687
-512
8253

5G ff
ff
J 2
fi


.1
.2
.4
.-

'+
9 (
.77 ...27
.33 ...45
.6 ...46
12 ...34



!

)=9
)=$
)*+& !"%. !"%/ !"%.
9 ( 9 ( 9 ( (&
(&
! $!%&'
.27 ...12 fi ...14 .836 ...34 7.7. 7.7. -6-6
.2- ...17 fi
...12 142 ...84 3287 3433 51-6
.28 ...1 fi ....6 21-7 ...61 8.. 8111 5831
.282 ....8 fi ...12 28. ..1.- 8877 8883 5662

!"%/
! $!%&'

-6-6
5276
5868
6.11

0
@7 ff

ff
ff

fiff
fi




fi

fiff ff fi ff ff
fi #F 78

ff

fi

fi

fi
fi
#F 78
ff fi fi
ff

ff
ff fi
fi

fi ff
433

fi ffff fififi


4,G ff
ff
J 2
fi



'+
9 (
.35 ..118
.57 ..112
12- ...65
1-7 ...63

.1
.2
.4
.-



!

)=9
)=$
)*+& !"%. !"%/ !"%.
9 ( 9 ( 9 ( (&
(&
! $!%&'
.214 ....6 fiff ...14 142 ..15 -71. -786 5462
.273 ...1 fi ...1 216 ...61 81-6 8241 5628
.246 ...1 fiff ....5 265 ...-1 5.24 5.58 61-4
.237 ....8 fi
....5 778 ...86 5445 5468 6246

!"%/
! $!%&'

5321
5634
6161
6282


fi
ff fiff fi

fi fiff fi ff
# "




=

ff

ff
ff


fi
ff


ff ff

fi

fi

ff
ff



ff
ff fi

3
@7 #F 78 fi

fi ff


=


# "
ff ff ff

@7 #F 78
fi fi 3fi
fi
# " ff
ff
fi

ff ff
ff




ff
fi!
ff
fi fffiff

<+4
ff


ff
ff

! fifi ff


fffi
fi
1.6

1.8

PTC-M
QR
TPOTRL

PTC-M
QR
TPOTRL

1.6

1.4

1.4

1.2

1.2

Message rate

Message rate

1

0.8

1
0.8

0.6
0.6
0.4

0.4

0.2

0

0.2

0

10

20

30

40

50

60

70

80

90

100

Time

0

0

10

20

30

40

50

60

70

80

90

100

Time

$ # ff

$ # ff 7

2
fi 4;G
ff

ff @7 # " #F 78
!
fifi
J 2
fi ;
43-

fi% Difference message rates QR PTC-M

500

max
avg
min

450
400
350
300
250
200
150
100
50

1

2

3
4
Degree dynamism

5

6

$ BC
A56

% Difference message rates TPOTRL PTC-M

fi fi
ff
fi
ff ff fifi fi

500

max
avg
min

450
400
350
300
250
200
150
100

1

2

3
4
Degree dynamism

5

6

$ A>6C+
A56

2
fi 4AG fiffff

ff
& @7 #F 78 # "

! fifi
J 2
fi ;
2
fi 4; ff

# " @7 #F 78
ff ,4 ,C

fffi
fi fi
2
fi ;
2
fi 4; ff

,4 ,+ ,; ,C ,6 'fi


ff
fi
fffi
fi 3 = fi # "


= ff @7 #F 78 fi fifi



2fi !
ff
@7 #F 78

fi

ff


# "



=
@7 #F 78
ff

ff
fi
fi fi fi
fi
#F 78
ff fi fi
ff / ff





! fiff fi
ff









#F 78 ff
@7 :



#F 78
@7
fi

fi @7

<+4
#F 78


@7



ff

#F 78 fiff ff
fififi

ff


#F 78

fi fffi

fiff ff
fi @7





ff
fi fi
fifi
fiffff

&
ff @7 # " #F 78 # "

= fi 4A 4A
= fi
ff
ff

L


ff
fi
@7 #F 78
# "




fi fi 2
fi 4,
2
fi 4A 4A
ff

fffiff ff
fffiff
& ff fi



ff 2

2
fi 4A

fi 4;,I
+ ff



C,I
ff 0 ff
&
ff # " @7 # " #F 78


438

fi ffff fififi




ff
ff 2 ff ff
&
ff 4A4I
-+4I
2
fi 4A


ff +,,I +6;I
2
fi 4A



# "
ff ff



ff
fiff ff ff
@7 #F 78
2ff

fi

fi ! 123$
( fi



! 122$ ff ff
fi 4
ff






2 ff # "
6,I


ff ff @7 <+I
ff #F 78


fi
! 2fi
ff


=
!
# " fi -+,I
ff @7 fi +6;I #F 78
fi # "


fi fi

ff
ff

+ ff
ff

fi , ff


fi


fi






ff ! 'fi



fffi

fifi ff




'fi
!



ff !


ff
0
fi

ff


fi
fi
ff fi
fi


K


ff ff ff
ff fiK
fifi
/
fi
fi


ff
fi

1



ff



&
ff

ff
ff fi "fi

ff
ff
fi @
fi fi

ff

fi

=
fi


fi

ff


fi



J ! ff

ff

J
ff


ff ff

ff
fiE
ff


fi
ff
fi
ff



ff fi
ff fi
ff
ff

fi

ff
2fi

ffff fffffi

fi

# "



fi

fffi
fi
ff fi


! : fi
ff

fi
ff
fi

ff!
ff

ff



& !
! ff

7fi
ff fi
ff ff! fi


fi fi C,I fi
ff ff 4,,,I



fifi fi
ff fi


ffff

= ff fi -,,I
ff!
: ff
# "

ff
ff
ff


ff

fi





ff

= fiff
ff /
= fffffi

fi

fi
435

fifi fi
ff
fi
ff ff fifi fi

# " # "


fi
ff
ff

ff fi
fi


! ff


fi

;
fi
ff
# " fi


ff

fi fi

!

ff




fi


= fi
ff




ff



fi fi

fiff







ff

ff =

ff ! ff
fffi

'fi



ff

fi fffffi



fi
ff







&
ff
ff




!
ff




ff 'fi


ff!

fi
ff
7fi ) 0
+,,+
fi

ff
fffi
! (

#
(9" (# 3!

8 ) 1ff +,,-. 3
1
ffffff
)

+,,+
!


ff
ff


fi fffffi



fi

=

=
fi
(9" (# ff

ff
3fi







fi
fffffi


fi ff fi
ff 'fi
fi




ff'fi

Ffi
!

ff


fi ffff
fi
ff fi
: ! Bfi 8fi 1fi

(ff 3


ffff fi
2


9#7" fi
K .
5 ) %
&!
F/" 0 17%7-+C5<%,4

!





( 0 3fiff # 3 * (fi 9 /
M! "
fi
0 ) ff " : +,,+ "


ffG fi







) ) 31 - +CU-A
3 * ) 3 # 8 4555 (


ff
G 1


ff

ff 7 ff


9

fi
0
$


3! 7

8 H ) 1ff " H +,,-




L ff!



)
6 %
! 2778$
;4U;6 fi " # 0 V!
3
( 1
7 ffffff 0 )

+,,+ ff


L ff!

. -
21 ; 645U6;,
436

fi ffff fififi


3fi

" 4555 'fi

ff



fffi
ff

) 6 % 4 )
!)6%)99$

;<6U;6A !ff
3 * ) 8
ff 8 455- #! fi

ff

!G

ff
" * ( fi 1 ) * 9

fi & ) H C C<4UC<6
" ) 1 8 4555 "fffi


:
1 9
:
+ff
4 ) +55U
--, # "ff

" 1 ( ) (
4556 0G (

fi
ff
fffffi


! 6 4 ) - 9 -4<U-CA
" 1 ( ) (
4556
ff & fi


ff !
)+ ) %

+ff
%
A;4UA;C 9(% "
#
"
3 455A fi




fi %
% 8; 44 ;5UA-
"!fi ( ) *
0 7 455C G

fi
=


ff

fi


FE/ 1 # ) *
0 7 9 <

+ff
4 ) -45U-;; :

" # 7 ) 8'fi / * 4554 ff! & 8= ; ;6<UA4+
fi
"



=


"ff / 8
" 9 7
7 8 )
" +,,4 )

+

+;G
fi # #
(! 455A 9G ff!
ff




ff
ff FE/ 1 ) *
0 9 <

+ff
4 ) 4C :


(! 455A fi




#(
$

fi ff fi
(! ) 8 H 7 455A (

ff



ff

< ) % <-U6,
2

(! 3
) :! # +,,; 5

H +<;;%+,,; / & % fi


fi

fi
4,, U 4,5

H /

(fi 9 / ) 8 H 4554 #

G

ff!


fi
ff
)
%ff
23 44C<U446-
(fi # (ff 1fi 7 *
0 7 ) fi 8 +,,; "


ff


ff

fi
7
/
fi "
46U+-
4-.

fifi fi
ff
fi
ff ff fifi fi

(fi # *
0 7 ) fi 8 +,,A

ff
'

!

ff
!
fi


< ) 6 %

! $


(fi # fi 8 ) *
0 7 +,,- 2



fi






# )6%)2778
%fi

) ;CUAA
(fi # ) +,,- 2ff

%fi -
- +44U++4
9 ( 1
) :! 8 +,,; # ff

G 7
ff

ff! ) 39 4 ;+<U ;-A
2
9 ) L +,,4 5
ff fi + :


Mfi ff
#fi

1L 3 ) Mfi 455C "
ff fi
4
) ;> + +C5U-A<
/
! " 4566 - ) !-<% 37=;$ 0! :!
1fi
9 2 fffi
*
) (
" +,,+ #G fffiff



fi
fi !$ #
4;U+A
*
0 7 455- "ffff
ff
G fi




fffi
ff ?
-fi ; - ++-U+A,
*
0 7 455A "

ff


fi
fffi

ff fi
K


4 ) 1= + 45AU+;,
*
0 7 ) 3fiff +,,- ff ) %
@ 28 - C4U<;
*
0 7 0ff * ) 2
# 4556 G
fi
ff ff % )'.+ 21 ; -+U-5
) 3fi
+,,; # & FE7
:
(
ff fifi ff
fifi fififi
8
) 3! 4555 fi


) )&<.%.
!3$ +-AU+;A
8 H 7 ) 9ff 8 ( 4566 (

fi

G ff
ff
3 / ) 1 8 9 -
+ff
4 )
4+,U4-5 Mfiff "
! 0 ( ) 1
455<
ff

ff
fi
fi

fifi
ff
ff


< ) / % +,+U+4,
Mfiff

7 8 H ) /
3 +,,- "



ff


fi fi


) 6 %
4-1

fi ffff fififi



! 2778$

A<CUA6-

fi " #
* 4566


-ff
% )

-%; A+AUA-,
* 1 )
ff / 45A6 .@ * :
)
"fiff 7 455C /

ff





=
)
%ff
" "
+C ;C; U ;<-

0 Mff / ) # 4555 "
ff
ff
!
fi

< %

H 30 - A;, CAA<6 C

455< / 4-G 7
ff 8
1 /

#fi! / H ( 3! ( ) "! * +,,4

fiG 2ff
fffifi
'fi
ff ff
)
%


; 4 ;AUA6
#!
8 ) H +,,+ 7
ff

fi


) 6 % & & !)6%&&$
7

H " 7

7 ff /
! 3 ) 3
fi! 7 +,,,
fi

ff
)% % )



7
" )
" 8 455< "F88 190G :


< ) % ! A91$
+6;U+54
7fi * ) 0
# +,,+ 4 ) :
+


4<G !
"ff (

#
/
* 8 H ) " 0 +,,-

ff
L
fffffi




fi
3
! fi

L (#

)
6 %
! 2778$
C<6UC6A " #

# *!! ) * 455A 7
ff



fi 1 fiL! ( ) 8 9
fi &
) H < -C4U-C6 #
# +,,, #F 78
! fi

)%/ 2777
5-AU5;+
# ) H 4555 ff

'fi


ff



% +,CU+4+
fi 7 (
) fi V +,,, #

ff

ff

fi

ff

fi & )
32 4,A<U4,C-
fi 7 4566 8

ff ff
&
/ 8 5U;;
4-2

fifi fi
ff
fi
ff ff fifi fi

fi 7 ) 3 1 4556

- /: )
!
fi
%
/$

#
!
9 ) ! V +,,- fi
&


ff
ff
2 + -+-U--6
ff 455<
ff! 6 4 ) - 1
6-U4+;
fiff +,,- % & ;

AG 0! 8
#
/ # 7
/ +,,+ 7
ff
ff

fi
fi 'fi




fffi
ff
! / 9 + 444U4-5
H
7 ) H # 455< (

fi

fffi
G #
fiff
) H 6A 4 A;UC-
: : 9 ) :ff # +,,- (
L fi
ff
G ff!
ff

'fi


fiff
6 4 ) -
39 A4-UAC<
:!
" * " / 4565 /


#(
# (
ff $

"ff

:!
" * " / ) ( # 455+
G @
/ ;
+<5U+5+
:
3 ) /& 9 45C,



fi
#%.& %fi
-
)B 5CU4,;
:

ff 7 * 455+
ff




ff



ff
/ ; - ++5U+AC
B
V 455C


ff!
fffi


fi



ff
L
fffffi

4 ) ;1 4 + +5AU-;+
Bfi # 8 H )

+,,4 "fffffi




fffi


G ff
ff
< ) %
!73$ C4CUC+-

4-7

fiJournal Artificial Intelligence Research 24 (2005) 263-303

Submitted 06/04; published 08/05

Integrating Learning Examples Search
Diagnostic Policies
Valentina Bayer-Zubek
Thomas G. Dietterich

School Electrical Engineering Computer Science,
Dearborn Hall 102, Oregon State University,
Corvallis, 97331-3102 USA

bayer@cs.orst.edu
tgd@cs.orst.edu

Abstract

paper studies problem learning diagnostic policies training examples.
diagnostic policy complete description decision-making actions diagnostician
(i.e., tests followed diagnostic decision) possible combinations test results.
optimal diagnostic policy one minimizes expected total cost,
sum measurement costs misdiagnosis costs. diagnostic settings,
tradeoff two kinds costs.
paper formalizes diagnostic decision making Markov Decision Process (MDP).
paper introduces new family systematic search algorithms based AO algorithm solve MDP. make AO ecient, paper describes admissible heuristic
enables AO prune large parts search space. paper also introduces several
greedy algorithms including improvements previously-published methods.
paper addresses question learning diagnostic policies examples.
probabilities diseases test results computed training data, great
danger overfitting. reduce overfitting, regularizers integrated search algorithms. Finally, paper compares proposed methods five benchmark diagnostic
data sets. studies show cases systematic search methods produce
better diagnostic policies greedy methods. addition, studies show
training sets realistic size, systematic search algorithms practical today's
desktop computers.

1. Introduction
patient arrives doctor's oce complaining symptoms fatigue, frequent
urination, frequent thirst. doctor performs sequence measurements.
measurements simple questions (e.g., asking patient's age, medical history,
family history medical conditions), others simple tests (e.g., measure body mass index,
blood pressure), others expensive tests (e.g., blood tests). measurement,
doctor analyzes known far decides whether enough information
make diagnosis whether tests needed. making diagnosis, doctor
must take account likelihood possible disease costs misdiagnoses.
example, diagnosing diabetic patient healthy incurs cost aggravating
patient's medical condition delaying treatment; diagnosing healthy patient
diabetes incurs costs unnecessary treatments. information
gathered suciently conclusive, doctor makes diagnosis.
c 2005


AI Access Foundation. rights reserved.

fiBayer-Zubek & Dietterich

formalize diagnostic task follows. Given patient, doctor execute
set N possible measurements x1 ; : : : ; xN . measurement xn executed, result
observed value vn . example, x1 \patient's age", v1 could 36 (years).
measurement xn associated cost C (xn ). doctor also choose one K
diagnosis actions. Diagnosis action fk diagnoses patient suffering disease k.
denote correct diagnosis patient y. misdiagnosis cost predicting
disease k correct diagnosis denoted MC (fk ; y).
process diagnosis consists sequence decisions. starting state,
measurements diagnoses made. denote empty set fg. Suppose
starting \knowledge state", doctor chooses measurement x1 receives
result x1 = 36 cost $0.50. modeled transition knowledge
state fx1 = 36g cost C (x1 ) = 0:5. suppose doctor chooses x3 ,
measures body mass index, receives result x3 = small cost $1. changes
knowledge state fx1 = 36; x3 = smallg cost C (x3 ) = 1. Finally, doctor makes
diagnosis \healthy". Suppose correct diagnosis = diabetes. illustrative
purposes,1 suppose cost misdiagnosis MC (healthy; diabetes) = $100.
diagnosis action terminates process, total cost :5 + 1 + 100 = 101:5.
summarize decision-making process doctor terms diagnostic
policy, . diagnostic policy specifies possible knowledge state s, action
(s) take, action one N measurement actions one K
diagnosis actions. Every diagnostic policy expected total cost, depends
joint probability distribution P (x1 ; : : : ; xN ; y) test results true disease
patients costs C (xn ) MC (fk ; y). optimal diagnostic policy
minimizes expected total cost choosing best tradeoff point cost
performing measurements cost misdiagnosis. Every measurement gathers
information, reduces risk costly misdiagnosis. every measurement incurs
measurement cost.
Diagnostic decision making challenging costs measurement
misdiagnosis similar magnitudes. measurement costs small compared
misdiagnosis costs, optimal diagnostic policy measure everything
make diagnostic decision. Conversely, misdiagnosis costs small compared
measurement costs, best policy measure nothing diagnose based
misdiagnosis costs prior probabilities diseases.
Learning cost-sensitive diagnostic policies important many domains, medicine
automotive troubleshooting network fault detection repair (Littman et al., 2004).
note formulation optimal diagnosis assumes costs expressed single numerical scale, that, although need correspond economic cost,
must support principle choosing actions minimizing expected total cost. medical diagnosis, large body work methods eliciting patient's preferences
summarizing utility cost function (e.g., Lenert & Soetikno, 1997).
paper studies problem learning diagnostic policies training examples.
assume given representative set complete training examples drawn
P (x1 ; : : : ; xN ; y) told measurement costs misdiagnosis costs.
1. true cost misdiagnosing diabetes would depend age patient degree
progression disease, case, would probably much higher $100.

264

fiLearning Diagnostic Policies Examples

kind training data could collected, example, clinical trial
measurements performed patients. costs involved collecting
data, assume training data sets relatively small (hundreds
thousands patients; millions). goal paper develop learning
algorithms finding good diagnostic policies modest-sized training data sets.
Unlike work test selection diagnosis (Heckerman, Horvitz, & Middleton, 1993;
van der Gaag & Wessels, 1993; Madigan & Almond, 1996; Dittmer & Jensen, 1997),
assume Bayesian network uence diagram provided; instead directly
learn diagnostic policy data.
framework diagnosis ignores several issues hope address future
research. First, assumes measurement action effect patient.
measurement action pure observation action. real medical equipment
diagnosis situations, actions may also attempted therapies attempted repairs.
repairs may help cure patient fix equipment, addition gathering
information. approach handle attempted repair actions.
Second, framework assumes measurement actions chosen executed oneat-a-time cost action depend order actions
executed. always true medical diagnosis. example, ordering
blood tests, physician choose order several different tests group, costs
much less tests ordered individually.
Third, framework assumes result measurement action available diagnostician must choose next action. medicine, often (stochastic)
delay time test ordered time results available. Fragmentary
results may arrive time, may lead physician order tests
previously-ordered results available.
Fourth, framework assumes measurement actions noise-free. is, repeating measurement action obtain exactly result. Therefore measurement
action executed, never needs repeated.
Fifth, framework assumes results measurements discrete values.
enforce via pre-processing discretization step.
assumptions allow us represent doctor's knowledge state set
partial measurement results: fx1 = v1 ; x3 = v3 ; : : :g represent entire diagnostic
process Markov Decision Process (MDP). optimal solution MDP provides
optimal diagnostic policy.
Given formalization, conceptually two problems must addressed
order learn good diagnostic policies. First, must learn joint probability distribution
P (x1 ; : : : ; xN ; y). Second, must solve resulting MDP optimal policy.
paper, begin addressing second problem. show apply

AO algorithm solve MDP optimal policy. define admissible heuristic
AO allows prune large parts state space, search becomes
ecient. addresses second conceptual problem.
However, instead solving first conceptual problem (learning joint distribution
P (x1 ; : : : ; xN ; y)) directly, argue best approach integrate learning
process AO search. three reasons pursue integration. First,
integrating learning search, ensure probabilities computed
265

fiBayer-Zubek & Dietterich

learning probabilities relevant task. instead separately learned
model joint distribution P (x1 ; : : : ; xN ; y), probabilities would
learned task-independent way, long experience machine learning shown
better exploit task guiding learning process (e.g., Friedman & Goldszmidt,
1996; Friedman, Geiger, & Goldszmidt, 1997).
Second, integrating learning search, introduce regularization methods
reduce risk overfitting. thoroughly learning algorithm searches
space possible policies, greater risk overfitting training data, results
poor performance new cases. main contribution paper (in addition showing
model diagnosis MDP) development careful experimental evaluation
several methods regularizing combined learning AO search process.
Third, integration learning AO provides additional opportunities prune
AO search thereby improve computational eciency learning process.
introduce pruning technique, called \statistical pruning", simultaneously reduces
AO search space also regularizes learning procedure.
addition applying AO algorithm perform systematic search space
diagnostic policies, also consider greedy algorithms constructing diagnostic policies.
algorithms much ecient AO , show experimentally
give worse performance several cases. experiments also show AO feasible
five diagnostic benchmark problems studied.
remainder paper organized follows. First, discuss relationship
problem learning minimum cost diagnostic policies previous work
cost-sensitive learning diagnosis. Section 3, formulate diagnostic learning
problem Markov Decision Problem. Section 4 presents systematic greedy search
algorithms finding good diagnostic policies. Section 5, take question
learning good diagnostic policies describe various regularization methods. Section 6
presents series experiments measure effectiveness eciency various
methods real-world data sets. Section 7 summarizes contributions paper
discusses future research directions.

2. Relationship Previous Research

problem learning diagnostic policies related several areas previous research
including cost-sensitive learning, test sequencing, troubleshooting. discuss
turn.

2.1 Cost-Sensitive Learning

term \cost-sensitive learning" denotes learning algorithm sensitive one
costs. Turney (2000) provides excellent overview. Cost-sensitive learning employs
classification terminology class possible outcome classification process.
corresponds case diagnosis. forms cost-sensitive learning
relevant work concern methods sensitive misclassification costs, methods sensitive
measurement costs, methods sensitive kinds costs.
Learning algorithms sensitive misclassification costs received significant attention. setting, learning algorithm given (at cost) results possible
266

fiLearning Diagnostic Policies Examples

measurements, (v1 ; : : : ; vN ). must make prediction y^ class example,
pays cost MC (^y; y) correct class y. Important work setting
includes papers Breiman et al. (1984), Pazzani et al. (1994), Fawcett Provost
(1997), Bradford et al. (1998), Domingos (Domingos, 1999), Zadrozny Elkan (2001),
Provost Fawcett (2001).
researchers machine learning studied application problems
cost measuring attribute (Norton, 1989; Nunez, 1991; Tan, 1993).
setting, goal minimize number misclassification errors biasing
learning algorithm favor less-expensive attributes. formal point view,
problem ill-defined, explicit definition objective function
trades cost measuring attributes number misclassification errors.
Nonetheless, several interesting heuristics implemented tested papers.
recently, researchers begun consider measurement misclassification costs (Turney, 1995; Greiner, Grove, & Roth, 2002). objective identical
one studied paper: minimize expected total cost measurements
misclassifications. algorithms learn data well.
Turney developed ICET, algorithm employs genetic search tune parameters
control classification-tree learning algorithm. classification tree built using
criterion selects attributes greedily, based information gain estimated
costs. measurement costs adjusted order build different classification trees;
trees evaluated internal holdout set using real measurement misclassification costs. best set measurement costs found genetic search employed
build final classification tree entire training data set.
Greiner et al.'s paper provides PAC-learning analysis problem learning
optimal diagnostic policy|provided policy makes L measurements,
L fixed constant. Recall N total number measurements. prove
exists algorithm runs time polynomial N , consumes number
training examples polynomial N , finds diagnostic policy that, high probability,
close optimal. Unfortunately, running time required number examples
exponential L. effect, algorithm works estimating, high confidence,
transition probabilities class probabilities states L values
x1 = v1, . . . , xN = vN observed. value iteration dynamic programming
algorithm applied compute best diagnostic policy L measurements.
theory, works well, dicult convert algorithm work practice.
theoretical algorithm chooses space possible policies
computes number training examples needed guarantee good performance, whereas
real setting, number available training examples fixed, space
possible policies must adapted avoid overfitting.

2.2 Test Sequencing
field electronic systems testing formalized studied problem called
test sequencing problem (Pattipati & Alexandridis, 1990). electronic system viewed
one K possible states. states include one fault-free state K , 1
faulty states. relationship tests (measurements) system states specified
267

fiBayer-Zubek & Dietterich

binary diagnostic matrix tells whether test xn detects fault fi not.
probabilities different system states specified known distribution P (y).
test sequencing policy performs series measurements identify state
system. test sequencing, assumed measurements sucient determine
system state probability 1. objective find test sequencing policy
achieves minimizing expected number tests. Hence, misdiagnosis costs
irrelevant, test sequencing policy must guarantee zero misdiagnoses. Several
heuristics AO applied compute optimal test sequencing policy (Pattipati & Alexandridis, 1990).
test sequencing problem involve learning examples. required
probabilities provided diagnostic matrix fault distribution P (y).

2.3 Troubleshooting
Another task related work task troubleshooting (Heckerman, Breese, &
Rommelse, 1994). Troubleshooting begins system known functioning
incorrectly ends system restored correctly-functioning state.
troubleshooter two kinds actions: pure observation actions (identical measurement actions) repair actions (e.g., removing replacing component, replacing
batteries, filling gas tank, rebooting computer, etc.). action cost,
goal find troubleshooting policy minimizes expected cost restoring
system correctly-functioning state.
Heckerman et al. (1994, 1995) show case actions pure
repair actions one broken component, ecient greedy
algorithm computes optimal troubleshooting policy. incorporate pure observation actions via one-step value information (VOI) heuristic. According
heuristic, compare expected cost repair-only policy expected cost
policy makes exactly one observation action executes repair-only policy.
observe-once-and-then-repair-only policy better, execute chosen observation
action, obtain result, compare best repair-only policy best
observe-once-and-then-repair-only policy. Below, define variant VOI heuristic
compare greedy systematic search algorithms developed
paper.
Heckerman et al. consider case joint distribution P (x1 ; : : : ; xN ; y)
provided known Bayesian network. convert approach learning approach,
could first learn Bayesian network compute troubleshooting policy.
suspect approach integrates learning probabilities
search good policies|along lines described paper|would give better results.
Exploring question important direction future research.

3. Formalizing Diagnosis Markov Decision Problem
process diagnosis sequential decision making process. every decision,
diagnostician must decide next (perform another measurement, terminate
making diagnosis). modeled Markov Decision Problem (MDP).
268

fiLearning Diagnostic Policies Examples

MDP mathematical model describing interaction agent
environment. MDP defined set states (including start state), action set
A, transition probabilities Ptr (s0 js; a) moving state state s0 executing
action a, (expected immediate) costs C (s; a; s0 ) associated transitions.
state representation contains relevant information future decisions,
said exhibit Markov property.
policy maps states actions. value state policy , V (s),
expected sum future costs incurred starting state following afterwards
(Sutton & Barto, 1999, chapter 3). value function V policy satisfies following
recursive relationship, known Bellman equation V :

V (s) =

X

2S
0

Ptr (s0 js; (s)) C (s; (s); s0) + V (s0 ) ; 8; 8s:




(1)

viewed one-step lookahead state next states s0 reached
executing action (s). Given policy , value state computed
value successor states s0 , adding expected costs transitions,
weighting transition probabilities.
Solving MDP means finding policy smallest value. policy called
optimal policy , value optimal value function V . Value iteration
algorithm solves MDPs iteratively computing V (Puterman, 1994).
problem learning diagnostic policies represented MDP. first
define actions MDP, states, finally transition probabilities
costs. costs positive.
discussed above, assume N measurement actions (tests) K
diagnosis actions. Measurement action n (denoted xn ) returns value attribute xn ,
assume discrete variable Vn possible values. Diagnosis action k (denoted
fk ) act predicting correct diagnosis example k. action
(measurement diagnosis) denoted a.
diagnostic setting, case completely described results N measurement actions correct diagnosis y: (v1 ; : : : ; vN ; y). framework, case
drawn independently according (unknown) joint distribution P (x1 ; : : : ; xN ; y).
case drawn, values defining stay constant. Test xn reveals diagnostic
agent value xn = vn case. consequence, case drawn,
order tests performed change values observed.
is, joint distribution P (xi = vi ; xj = vj ) independent order tests
xi xj .
follows define state MDP set attribute-value pairs
observed thus far. state representation Markov property contains
relevant past information. unique start state, s0 = fg, attributes
measured. set states contains one state possible combination
measured attributes, found training data. training example provides evidence
reachability 2N states. set A(s) actions executable state consists
attributes yet measured plus diagnosis actions.
also define special terminal state sf . Every diagnosis action makes transition
sf probability 1 (i.e., diagnosis made, task terminates). definition,
269

fiBayer-Zubek & Dietterich

actions executable terminal state, value function zero. Note
terminal state always reached, finitely-many measurement actions
diagnosis action must executed.
define transition probabilities immediate costs MDP.
measurement action xn executed state s, result state s0 = [ fxn = vn g,
vn observed value xn . expected cost transition denoted C (xn),
since assume depends measurement action xn executed,
state executed resulting value vn observed. probability
transition Ptr (s0 js; xn ) = P (xn = vn js).
misdiagnosis cost diagnosis action fk depends correct diagnosis
example. Let MC (fk ; y) misdiagnosis cost guessing diagnosis k correct
diagnosis y. correct diagnosis example part state
representation, cost diagnosis action (which depends y) performed state
must viewed random variable whose value MC (fk ; y) probability P (yjs),
probability correct diagnosis given current state s. Hence,
MDP stochastic cost function diagnosis actions. lead
diculties, required compute optimal policy MDP
expected cost action. case, expected cost diagnosis action fk state

X
C (s; fk ) = P (yjs) MC (fk ; y);
(2)


independent y.
uniformity notation, write expected immediate cost action
state C (s; a), either measurement action diagnosis action.
given start state s0 , diagnostic policy decision tree (Raiffa, 1968).
Figure 1 illustrates simple example diagnostic policy. root starting state
s0 = fg. node labeled state corresponding action (s). action
measurement action, xn , possible results different possible observed values
vn, leading children nodes. action diagnosis action, fk , possible results
diagnoses y. (s) measurement action, node called internal node,
(s) diagnosis action, node called leaf node. branch tree labeled
probability followed (conditioned reaching parent node). node
labeled V (s), expected total cost executing diagnostic policy starting
node s. Notice value leaf expected cost diagnosis, C (s; fk ).
fact diagnostic policy decision tree potentially confusing,
similar data structure, classification tree (often also called decision tree),
focus much work machine learning literature (e.g., Quinlan, 1993).
important remember whereas evaluation criterion classification tree
misclassification error rate, evaluation criterion decision tree diagnostic
policy expected total cost diagnosis. One way clarifying difference
note given classification tree transformed many equivalent classification
trees changing order tests performed (see Utgoff's work tree
manipulation operators, Utgoff, 1989). equivalent classifiers implement
classification function = f (x1 ; : : : ; xN ). consider \equivalent" trees
diagnostic policies, different expected total diagnosis costs, tests
270

fiLearning Diagnostic Policies Examples

low

{ BMI = large, Insulin = low}

.8
large

45.98

.5
{}
28.99

{ BMI = large }

.3

24

.2

BMI
1
.5
{ BMI = small }

.7

Insulin
22.78
high

small

Diabetes

Healthy

10

.9
.1

= Healthy
= Diabetes

{ BMI = large, Insulin = high }

Healthy

.8
.2

20

= Diabetes
= Healthy
= Healthy
= Diabetes

0
80

0
100

0
100

Figure 1: example diagnostic policy diabetes. Body Mass Index (BMI) tested
first. small, Healthy diagnosis made. BMI large, Insulin tested
making diagnosis. costs measurements (BMI Insulin)
written name variable. costs misdiagnoses written
next solid squares. Probabilities written branches. values
states written state. value start state, V (s0 ) =
28:99, computed single sweep, starting leaves, follows. First
expected costs diagnosis actions computed (e.g., upper-most
Diabetes diagnosis action expected cost 0:7 0 + 0:3 80 = 24).
value Insulin subtree computed cost measuring Insulin
(22.78) + 0:8 24 + 0:2 20 = 45:98. Finally, value whole tree
computed cost measuring BMI (1) + 0:5 45:98 + 0:5 10 = 28:99.

large
low
.57

.7
{ Insulin = low } BMI
1
21.4
.3
small

Insulin
{}
22.78
40.138
.43
high

{ Insulin = high }
12

Healthy .88
.12

{ BMI = large, Insulin = low}
24

{ BMI = small, Insulin = low }
12

= Healthy
= Diabetes

Diabetes

.7
.3

Healthy .88
.12

= Diabetes
= Healthy
= Healthy
= Diabetes

0
80

0
100

0
100

Figure 2: Another diagnostic policy 2 , making classification decisions
Figure 1, changed order tests, therefore different policy
value.
closer root tree executed often, measurement costs
make larger contribution total diagnosis cost. example, policy Figure 1
first performs cheap test, BMI. policy value 28:99. tree 2 Figure 2
makes classification decisions (with error rate 19%), first tests Insulin,
expensive, increases policy value 40:138.
271

fiBayer-Zubek & Dietterich

4. Searching Good Diagnostic Policies
consider systematic greedy search algorithms computing diagnostic policies.
section, assume necessary probabilities known. defer
question learning probabilities Section 5. note exactly
previous uses AO done. always assumed required probabilities
costs known.
Given MDP formulation diagnostic process, could proceed constructing
entire state space applying dynamic programming algorithms (e.g., value
iteration policy iteration) find optimal policy. However, size state space
exponential: given N measurement actions, V possible outcomes, (V +
1)N + 1 states MDP (counting special terminal state sf , taking account
measurement may performed yet). seek search algorithms
consider small fraction huge space. section, study two general
approaches dealing combinatorial explosion states: systematic search using
AO algorithm various greedy search algorithms.

4.1 Systematic Search

MDP unique start state (directed) cycles, space policies
represented AND/OR graph (Qi, 1994; Washington, 1997; Hansen, 1998).
AND/OR graph directed acyclic graph alternates two kinds nodes:
nodes nodes. node represents state MDP state space.
child node node represents one possible action executed
state s. child node node represents state s0 results
executing action state s. Figure 3 shows example AND/OR graph
diabetes diagnosis problem three tests (BMI, Glucose, Insulin) two diagnosis
actions (Diabetes Healthy).
diagnostic setting, root node corresponds starting state s0 = fg.
node one child (s; xn ) measurement action (test) xn
executed s. node could also one child possible diagnosis action
fk could performed s, save time memory, include one
diagnosis action fk minimum expected cost. denote fbest .
time node created, child fbest created immediately. leaf
node stores action-value function Q(s; fbest ) = C (s; fbest ). Note multiple paths
root may lead node, changing order tests.
implementation, node stores representation state s, current
policy (s) specifies test diagnosis action, current value function V (s).
node (s; xn ) stores probability distribution outcomes xn,
action-value function Q (s; xn ), expected cost measuring xn continuing
policy .
Every possible policy corresponds subtree full AND/OR graph.
node subtree (starting root) contains one child (s; a)
corresponding action = (s) chosen policy .
AO algorithm (Nilsson, 1980) computes optimal policy AND/OR graph.

AO guided heuristic function. describe heuristic function terms state272

fiLearning Diagnostic Policies Examples

{}
node
Healthy

Insulin
Diabetes

Glucose
BMI

node
node

node
small

large


H


G



H







G







low

high





H

H


G



G


low

high


H


low




H

high




H




H



Figure 3: example AND/OR graph. root node corresponds state
s0 = fg. child node test actions (BMI, Glucose
Insulin), also diagnosis actions (Healthy Diabetes).
choice BMI test root node leads node (s0 ; BMI ),
specifies expectation outcomes test BMI (small large).
BMI small, child node (s0 ; BMI ) node state
fBMI = smallg; node, choice among actions Healthy,
Diabetes, Glucose Insulin.
action pairs, h(s; a), instead terms states. heuristic function admissible
h(s; a) Q(s; a) states actions a. means h underestimates
total cost executing action state following optimal policy afterwards.
admissible heuristic allows AO algorithm safely ignore action a0 another
action known Q (s; a) < h(s; a0 ). conditions, (s; a0 ) cannot
part optimal policy.
AO search begins AND/OR graph containing root node.
repeats following steps: current best policy, selects node expand;
expands (expanding node creates children nodes); recomputes
(bottom-up) optimal value function policy revised graph. algorithm
terminates best policy unexpanded nodes (in words, leaf
273

fiBayer-Zubek & Dietterich


v
x

use hopt



evaluate

Figure 4: Qopt (s; x) unexpanded node (s; x) computed using one-step lookahead
hopt evaluate resulting states s0 . x attribute yet measured
state s, v one values.
nodes policy specify diagnosis actions, policy complete diagnostic
policy).
AO search, maintain two policies, whose actions value functions
stored nodes AND/OR graph. call first policy optimistic policy,
opt . show below, value function V opt lower bound optimal value
function V . policy appears Nilsson's original description AO ,
provides enough information compute optimal policy (Martelli & Montanari,
1973). search, optimistic policy opt incomplete policy,
includes unexpanded nodes; opt becomes complete policy, fact
optimal policy.
second policy maintain called realistic policy, real . show
value function, V real , upper bound optimal value function V .
realistic policy always complete policy, executable iteration AO .
maintaining realistic policy, AO becomes anytime algorithm.
define two policies detail introduce admissible heuristic.
4.1.1 Admissible Heuristic

admissible heuristic provides optimistic estimate, Qopt (s; x), expected cost
unexpanded node (s; x). based incomplete two-step lookahead search
(see
Figure 4). first step lookahead search computes Qopt (s; x) = C (s; x) +
P
0
opt 0
0
Ptr (s js; x) h (s ). iterates states resulting measuring test x.
second step lookahead defined function hopt (s0 ) = mina 2A(s ) C (s0 ; a0 );
minimum cost diagnosis action fbest cost
remaining tests x0 s0. is, rather considering states s00 would result
measuring x0 , consider cost measuring x0 itself. ItPfollows immediately
hopt (s0) V (s0 ); 8s0, C (s0; x0 ) Q (s0 ; x0 ) = C (s0; x0 ) + Ptr (s00 js0; x0 ) V (s00 ).
key thing notice cost single measurement x0 less equal
cost policy begins measuring x0 , policy must pay cost
least one action (diagnosis measurement) entering terminal state
sf . Consequently, Qopt(s; x) Q (s; x), Qopt admissible heuristic state
action x.
0

0

00

274

0

fiLearning Diagnostic Policies Examples

4.1.2 Optimistic Values Optimistic Policy

definition optimistic action-value value Qopt extended nodes
AND/OR graph following recursion:
8
>
< C (s; a), = fk (a diagnosis action)
opt
Q (s; a) = > C (s; a) + P
Ptr (s0js; a) hopt (s0 ), (s; a) unexpanded
(3)
Ps
:
0
opt
0
C (s; a) + Ptr (s js; a) V (s ), (s; a) expanded,
0
0

V opt (s) def
= mina2A(s) Qopt (s; a). Recall A(s) consists attributes yet
measured diagnosis actions.
optimistic policy opt (s) = argmina2A(s) Qopt (s; a): Every node stores
optimistic value V opt (s) policy opt (s), every node (s; a) stores Qopt (s; a).
Theorem 4.1 proves Qopt V opt form admissible heuristic. proofs
theorems paper appear thesis Bayer-Zubek (2003).

Theorem 4.1 states actions 2 A(s), Qopt(s; a) Q (s; a); V opt (s)
V (s):

4.1.3 Realistic Values Realistic Policy

current graph constructed AO , suppose delete unexpanded
nodes (s; a). call resulting graph realistic graph, every leaf node
select diagnosis action. optimal policy computed graph called realistic
policy, real . complete policy leaves specify diagnosis actions minimum expected
misdiagnosis cost.
Every node stores realistic value V real (s) policy real (s), every
node (s; a) stores realistic action-value value, Qreal (s; a). 2 A(s), define
8
>
= fk (a diagnosis action)
< C (s; a), ifP
real
Q (s; a) = > C (s; a) + Ptr (s0 js; a) V real (s0 ), (s; a) expanded
(4)
:
ignore, (s; a) unexpanded
0

V real (s) = mina2A (s) Qreal (s; a); set A0 (s) A(s) without unexpanded actions. realistic policy real (s) = argmina2A (s) Qreal (s; a):
0

0

Theorem 4.2 realistic value function V real upper bound optimal value
function: V (s) V real (s); 8s:
4.1.4 Selecting Node Expansion

current optimistic policy opt , choose expand unexpanded node
(s; opt (s)) largest impact root node. defined
argmax [V real (s) , V opt (s)] Preach (sjopt );


opt
Preach(sj ) probability reaching state start state following
policy opt . difference V real (s) , V opt (s) upper bound much value
state could change opt (s) expanded.

275

fiBayer-Zubek & Dietterich

rationale selection based observation AO terminates

V opt(s0 ) = V real (s0 ). Therefore, want expand node makes biggest step

toward goal.

4.1.5 Implementation AO (High Level)

implementation AO following:
repeat

select node (s; a) expand (using opt; V opt; V real ).
expand (s; a).
bottom-up updates Qopt; V opt; opt Qreal; V real; real.
unexpanded nodes reachable opt .

updates value functions based one-step lookaheads (Equations 3 4), using value functions children. iteration, start newly expanded
node (s; a), compute Qopt (s; a) Qreal (s; a), compute V opt (s); opt (s),
V real (s); real (s) parent node, propagate changes
AND/OR graph way root. Full details implementation AO appear
thesis Bayer-Zubek (2003).
nodes expanded, optimistic values V opt increase, becoming tighter lower
bounds optimal values V , realistic values V real decrease, becoming tighter
upper bounds. V opt V real converge value optimal policy: V opt (s) =
V real (s) = V (s), states reached .
admissible heuristic avoids exploring expensive parts AND/OR graph; indeed,
V real (s) < Qopt (s; a), action need expanded (this heuristic
cutoff). Initially, V real (s) = C (s; fbest ), explains measurement costs
large relative misdiagnosis costs produce many cutoffs.

4.2 Greedy Search

considered AO algorithm systematic search, turn attention
several greedy search algorithms finding good diagnostic policies. Greedy search
algorithms grow decision tree starting root, state s0 = fg. node
tree corresponds state MDP, stores corresponding action = (s)
chosen greedy algorithm. children node correspond states result
executing action state s. diagnosis action fk chosen state s,
node children decision tree (it leaf node).
greedy algorithms considered paper share general template,
shown pseudo-code Table 1. state s, greedy algorithm performs
limited lookahead search commits choice action execute
s, thereby defines (s) = a. generates child nodes corresponding
states could result executing action state s. algorithm invoked
recursively child nodes.
greedy algorithm committed xn = (s), choice final. Note however,
regularization methods may prune policy replacing measurement
action (and descendents) diagnosis action. general, greedy policies
optimal, perform complete analysis expected total cost
276

fiLearning Diagnostic Policies Examples

Table 1: Greedy search algorithm. Initially, function Greedy() called
start state s0 .

function Greedy(state s) returns policy (in form decision tree).
(1) (stopping conditions met)
(2) select measurement action xn execute
set (s) := xn
resulting value vn test xn add subtree
Greedy(state [ fxn = vn g)

else

(3) select diagnosis action fbest , set (s) := fbest :
executing xn committing action. Nevertheless, ecient
greediness.
following discussion, describe several different greedy algorithms. define
one describing refines numbered lines template Table 1.
4.2.1 InfoGainCost Methods

InfoGainCost methods inspired C4.5 algorithm constructing classification
trees (Quinlan, 1993). C4.5 chooses attribute xn highest conditional mutual
information class labels training examples. diagnostic setting,
analogous criterion choose measurement action predictive correct
diagnosis. Specifically, let xn proposed measurement action, define P (xn ; yjs)
joint distribution xn correct diagnosis conditioned information
already collected state s. conditional mutual information xn
y, (xn ; yjs), defined

(xn; yjs) = H (yjs) , H
(yjs; xn )
X
= H (yjs) , P (xn = vn js) H (yjs [ fxn = vn g)
vn

H (y) = ,P (y) log P (y) Shannon entropy random variable y.
mutual information also called information gain, quantifies
average amount information gain measuring xn .
InfoGainCost methods penalize information gain dividing cost
test. Specifically, choose action xn maximizes (xn ; yjs)=C (xn ). criterion
introduced Norton (1989). researchers considered various monotonic
transformations information gain prior dividing measurement cost (Tan,
1993; Nunez, 1991). defines step (2) algorithm template.
InfoGainCost methods employ stopping conditions defined C4.5.
first stopping condition applies P (yjs) 1 value = k. case,
diagnosis action chosen fbest = k. second stopping condition applies
P

277

fiBayer-Zubek & Dietterich

measurement actions available (i.e., tests performed). case,
diagnosis action set likely diagnosis: fbest := argmaxy P (yjs).
Notice InfoGainCost methods make use misdiagnosis costs
MC (fk ; y).
4.2.2 Modified InfoGainCost Methods (MC+InfoGainCost)

propose extending InfoGainCost methods consider misdiagnosis costs
stopping conditions. Specifically, step (3), MC+InfoGainCost methods set
fbest diagnosis action minimum expected cost:

(s) := fbest = argmin

X

fk



P (yjs) MC (fk ; y):

4.2.3 One-step Value Information (VOI)

previous greedy methods either ignore misdiagnosis costs consider
choosing final diagnosis actions, VOI approach considers misdiagnosis
costs (and measurement costs) step.
Traditionally, value information measurement defined difference
expected value best action performing measurement
expected value best action performing measurement. Since objective
cost minimization, need reverse sign definition. However, still keep
notation VOI instead cost information. Instead taking account future
decisions, make greedy approximation VOI, called one-step VOI,
consider cost best diagnosis action performing measurement
xn state s:
X

1-step-VOI(s; xn ) = min
P (yjs) MC (fk ; y)
fk
"

,

X

vn

P (xn = vn js) min
f
k

X



#

P (yjs [ fxn = vn g) MC (fk ; y) :

test xn performed value exceeds cost, 1-step-VOI(s; xn ) > C (xn ).
Intuitively, one-step VOI method repeatedly asks following question: worth
executing one measurement making diagnosis, better make
diagnosis now?
state s, one-step VOI method first computes cost stopping choosing
action fbest minimizes expected misdiagnosis costs:

C (s; fbest ) = min
f
k

X



P (yjs) MC (fk ; y):

Then, possible measurement action xn , method computes expected cost
measuring xn choosing minimum cost diagnosis actions resulting
278

fiLearning Diagnostic Policies Examples

states:
1-step-LA(s; xn ) = C (xn) +

X

vn

"

P (xn = vnjs) min
f
k

X



#

P (yjs [ fxn = vn g) MC (fk ; y) :
(5)

Define xbest = argminxn 1-step-LA(s; xn ).
definitions, describe one-step VOI method terms template Table 1 follows. stopping condition (1) C (s; fbest ) 1-step-LA(s; xbest );
method also stops tests performed. choice measurement action (2) xbest . choice final diagnosis action step (3) fbest .

5. Learning, Overfitting, Regularization

previous section, considered search algorithms finding good diagnostic policies.
algorithms require various probabilities, particularly P (xn = vn js) P (yjs)
every state-action pair (s; xn ) (s; fk ) generated search.
One way obtain probabilities fit probabilistic model P (x1 ; : : : ; xN ; y)
training data apply probabilistic inference model compute
desired probabilities. example, algorithm K2 (Cooper & Herskovits, 1992)
could applied learn Bayesian network training data. advantage
approach would cleanly separate process learning probabilities
process searching good policy.
chief disadvantage approach prevents us exploiting
problem solving task determine probabilities learned accurately
probabilities ignored (or learned less accurately). Consequently,
adopted different approach learning fully integrated search process.
important, enables us control overfitting also provides
additional opportunities speeding search.
basic way integrate learning search process simple. time
search algorithm needs estimate probability, algorithm examines training
data computes required probability estimate. example, algorithm needs
estimate P (x1 = v1 jfx3 = v3 ; x5 = v5 g), make pass training data
count number training examples x3 = v3 x5 = v5 . Denote
#(x3 = v3 ; x5 = v5 ). make second pass data count #(x1 = v1 ; x3 =
v3 ; x5 = v5). two quantities, compute maximum likelihood estimate:

P^ (x1 = v1 j fx3 = v3 ; x5 = v5g) = #(x1#(=xv1 ;=xv3 ;=xv3 ;=xv5 )= v5 ) :
3

general,

3

fxn = vng) :
P^ (xn = vnjs) = #(s [ #(
s)

5

5

Similarly, P (yjs) estimated fraction training examples matching state
diagnosis y:
s; y) :
P^ (yjs) = #(
#(s)
279

fiBayer-Zubek & Dietterich

process obviously made ecient allowing training data
\ ow" AND/OR graph (for AO algorithm) classification tree (for greedy
algorithms) constructed. Hence, starting state (the root) stores list
training examples. node state stores list training
examples match s. example matches state agrees measurement
results define state. node measures xn state viewed
partitioning training examples stored node disjoint subsets according
observed values test xn . method employed classification tree
algorithms many years (Breiman et al., 1984; Quinlan, 1993).
Unfortunately, straightforward approach, combined systematic
greedy search algorithms, often results overfitting|that is, finding policies give
good performance training data give quite poor performance new
cases.
Figure 5 illustrates AO . figure shows anytime graph
value V real (s0 ) current realistic policy, real , plotted node expansion (or
iteration algorithm). V real evaluated training data disjoint
test data set. training data, quality learned policy improves monotonically
number iterations|indeed, guaranteed AO algorithm.
test data, performance realistic policies gets worse 350 iterations. Upon
convergence, AO learned optimal policy respect training data,
policy performs badly test data.
Machine learning research developed many strategies reducing overfitting.
remainder section describes regularizers developed systematic greedy search algorithms. First, discuss regularizers AO . discuss
regularizers greedy search.

5.1 Regularizers AO Search
Overfitting tends occur learning algorithm extracts much detailed information training data. happen, example, learning algorithm
considers many alternative policies given amount training data. also
occur algorithm estimates probabilities small numbers training examples. problems arise AO . AO considers many different policies
large AND/OR graph. AND/OR graph grows deeper, probabilities
deeper nodes estimated fewer fewer training examples.
pursued three main strategies regularization: (a) regularizing probability
estimates computed search, (b) reducing amount search pruning
early stopping, (c) simplifying learned policy post-pruning eliminate parts
may overfit training data.
5.1.1 Laplace Correction (denoted `L')

regularize probability estimates, standard technique employ Laplace corrections. Suppose measurement xn Vn possible outcomes. discussed above,
280

fiLearning Diagnostic Policies Examples

45
AO* training data
AO* test data

Value realistic policy

40

35

30

25

20

15
1

10

100
iteration

1000

10000

Figure 5: Illustration AO overfitting. anytime graph shows best realistic
policy, according test data, discovered 350 iterations,
AO overfits.
maximum likelihood estimate P (xn = vn js)

fxn = vng) :
P^ (xn = vnjs) = #(s [ #(
s)
Laplace-corrected estimate obtained adding 1 numerator Vn
denominator:
fxn = vng) + 1 :
P^L (xn = vn j s) = #(s [#(
s) + V
n

Similarly, Laplace-corrected estimate diagnosis obtained adding 1
numerator K (the number possible diagnoses) denominator:

s; y) + 1 :
P^L (yjs) = #(
#(s) + K
One advantage Laplace correction probability value ever estimated 0 1. probability values extreme, hence, extremely dangerous.
281

fiBayer-Zubek & Dietterich

45
AO* training data
AO* test data
AO*-L training data
AO*-L test data

Value realistic policy

40

35

30

25

20

15
1

10

100
iteration

1000

10000

Figure 6: Anytime graphs AO AO Laplace correction. Laplace regularizer
helps AO , anytime graph value last policy learned.
example, AO believes P (xn = vn js) = 0, expand branch
tree. Even serious, AO believes P (y = cjs) = 0,
consider potential misdiagnosis cost MC (fk ; = c) computing expected costs
diagnosis actions fk state s.
Figure 6 shows AO Laplace regularizer gives worse performance
training data better performance test data AO . Despite improvement,
AO Laplace still overfits: better policy learned early discarded later
worse one.
5.1.2 Statistical Pruning (SP)

second regularization technique reduces size AO search space pruning
subtrees unlikely improve current realistic policy.
statistical motivation following: given small training data sample,
many pairs diagnostic policies statistically indistinguishable. Ideally, would
like prune policies AND/OR graph statistically indistinguishable
optimal policies. Since possible without first expanding graph, need
heuristic approximately implements following indifference principle:
282

fiLearning Diagnostic Policies Examples

state

unexpanded
optimistic policy
opt
V

realistic
policy

V

real

Figure 7: Statistical pruning (SP) checks whether V opt (s) falls inside confidence interval
around V real (s). does, SP prunes opt (s) (the unexpanded optimistic
policy).

Indifference Principle. Given two diagnostic policies whose values statistically

indistinguishable based training data set, learning algorithm choose arbitrarily
them.
heuristic called statistical pruning (abbreviated SP), applied
node whose optimistic policy selected expansion. two diagnostic policies
consideration currently unexpanded optimistic policy opt (s) current
realistic policy real (s). action specified opt (s) pruned graph
statistical test cannot reject null hypothesis V opt (s) = V real (s). words,
incomplete policy opt complete policy real , prefer latter.
statistical test computed follows. training examples te
matches state s, apply real compute total cost diagnosis (starting
state s). information, compute 95% confidence interval V real (s) (e.g.,
using standard normal distribution assumption). V opt (s) falls inside confidence
interval, cannot reject null hypothesis V opt (s) = V real (s). Therefore,
indifference principle, choose real (s) prune opt (s). illustrated
Figure 7.
V opt (s) lower bound V (s) (see Theorem 4.1) V real (s) upper
bound V (s) (see Theorem 4.2), relate statistical pruning indifference
principle slightly stronger way. V opt (s) falls inside confidence interval V real (s),
V (s) must also fall inside confidence interval, V opt (s) V (s) V real (s).
Hence, least 95% confidence, cannot reject null hypothesis V real (s) =
V (s). Hence, indifference principle authorizes us choose real , since statistically
indistinguishable optimal policy. However, argument remains true
long real remains unchanged. Subsequent expansions AO may change real
invalidate statistical decision.
SP heuristic applied AND/OR graph grown. node (s; a)
selected expansion, SP first checks see node pruned instead.
pruned, action ignored computations (SP deletes
283

fiBayer-Zubek & Dietterich

set available actions A(s)). AO updates Qopt ; V opt ; opt graph.
updates real V real needed, pruning change realistic graph.
previous work (Bayer-Zubek & Dietterich, 2002), described version SP
heuristic employed paired-difference statistical test instead simple confidence
interval test described here. synthetic problems, two statistical tests gave nearly
identical results. prefer confidence interval test, allows us relate
V real (s) V (s).
care must taken combining statistical pruning Laplace corrections.
Laplace corrections, mean observed total cost training examples
matching state processed real V real (s), latter
computed using Laplace-corrected probabilities. fix problem, compute width
confidence interval applying real training example matching state
use V real (s) center confidence interval.
5.1.3 Early Stopping (ES)

Another way limit size search space considered AO halt search
early. method long applied regularize neural networks (e.g., Lang, Waibel,
& Hinton, 1990). Early stopping employs internal validation set decide halt
AO . training data split half. One half called \subtraining data",
half called \holdout data". AO trained subtraining data,
every iteration, real evaluated holdout data. real gives lowest total
cost holdout data remembered, AO eventually terminates, best
realistic policy returned learned policy.
Early stopping combined Laplace correction simply running AO
Laplace corrections subtraining set. need Laplace-correct
evaluation real holdout set.
5.1.4 Pessimistic Post-Pruning (PPP) Based Misdiagnosis Costs

final AO regularizer pessimistic post-pruning. based well-known method
invented Quinlan pruning classification trees C4.5 (Quinlan, 1993). PPP takes
complete policy training data set produces \pruned" policy 0 hope
0 exhibits less overfitting. PPP applied final realistic policy computed
AO .
central idea PPP replace expected total cost V (s) state
statistical upper bound UB (s) takes account uncertainty due amount
variability training data. internal node s, upper bound shows
selecting best diagnosis action would preferred selecting measurement action (s),
node converted leaf node (and UB estimates ancestors policy
updated). PPP performed single traversal decision tree .
Computation begins leaves policy (i.e., states (s) chooses
diagnosis action fk ). Let UB (s) upper limit 95% normal confidence interval
C (s; fk ) (i.e., expected misdiagnosis cost choosing action fk state s).
computed taking training example matches state s, assigning diagnosis
284

fiLearning Diagnostic Policies Examples

fk , computing misdiagnosis cost MC (fk ; y), correct diagnosis
training example.
upper bound internal node computed according recursion
X
UB (s) = C (s; (s)) + Ptr (s0 js; (s)) UB (s0):


0

Bellman equation state value function replaced UB
function. (s) pruned, replaced diagnosis action fbest minimum
expected cost, upper bound C (s; fbest ) less UB (s) internal node,
computed above. case, UB (s) set upper bound C (s; fbest ).
PPP combined Laplace regularization follows. First, computing UB (s)
leaf node, K \virtual" training examples added state s, one virtual example diagnosis. words, normal confidence interval computed
using misdiagnosis costs training examples match plus one MC ((s); y)
possible diagnosis y. Note probabilities P (yjs) Ptr (s0 js; (s)) already
Laplace-corrected running AO Laplace corrections.
5.1.5 Summary AO Regularizers

described following regularizers: Laplace corrections (L), statistical pruning
(SP), early stopping (ES), pessimistic post-pruning (PPP). also shown
combine Laplace regularization others.

5.2 Regularizers Greedy Search

describe four regularizers employed greedy search.
5.2.1 Minimum Support Pruning

InfoGainCost InfoGainCost+MC methods, adopt minimum support
stopping condition C4.5 (Quinlan, 1993). order measurement action xn
chosen, least two possible outcomes vn must lead states least 2
training examples matching them. not, xn eligible selection step (2)
Table 1.
5.2.2 Pessimistic Post-Pruning (PPP) Based Misdiagnosis Rates

InfoGainCost method, applied C4.5's standard pessimistic post-pruning.
InfoGainCost grown decision tree, tree traversed post-order. leaf
node s, pessimistic error estimate computed
2



3

UB (s) = n 4p + zc p(1 n, p) + 21n 5 ;
n number training examples reaching leaf node, p error rate
committed diagnosis action training examples leaf, zc = 1:15
75% critical value normal distribution. UB (s) upper limit 75%
confidence interval binomial distribution (n; p) plus continuity correction.
285

fiBayer-Zubek & Dietterich

internal node s, pessimistic error estimate simply sum pessimistic
error estimates children. internal node converted leaf node sum
children's pessimistic errors greater equal pessimistic error would
converted leaf node.
Laplace regularization combined PPP replacing observed error rate
p Laplace-corrected version (this computed adding one \virtual" example
diagnosis).
5.2.3 Post-Pruning Based Expected Total Costs

MC+InfoGainCost method, apply post-pruning procedure based
pessimistic estimate rather estimated total cost diagnosis. Recall
MC+InfoGainCost grows decision tree way InfoGainCost, assigns diagnosis actions leaf nodes choosing action smallest expected
misdiagnosis cost training data.
regularized traversing resulting decision tree converting
internal node (s) = xn leaf node (where (s) = fbest ) expected cost
choosing diagnosis action fbest less expected total cost choosing measurement
action xn . implemented computing C (s; fbest ) Q (s; xn ) comparing
them. C (s; fbest) Q (s; xn ), node converted leaf node. computation
carried single post-order traversal decision tree corresponding .
Laplace corrections combined pruning procedure applying Laplace
corrections probabilities employed computing Q (s; xn ) C (s; fbest).
Bradford et al. (1998) present similar method pruning decision trees based
misclassification costs (and zero attribute costs), combined Laplace correction class
probability estimates (there Laplace correction transition probabilities).
interesting note post-pruning based total costs necessary
VOI, pruning already built-in. Indeed, internal node VOI policy
, (s) = xn, Q (s; xn ) V OI (s; xn ) < C (s; fbest ) (the proof theorem
appears thesis Bayer-Zubek (2003)).
5.2.4 Laplace Correction

AO , could apply Laplace corrections probabilities computed
greedy search.
InfoGainCost method, Laplace correction diagnosis probabilities P (yjs)
change likely diagnosis. MC+InfoGainCost method, Laplace correction
diagnosis probabilities may change diagnosis action minimum expected cost.
Laplace correction applied computation information gain (xn ; yjs).
InfoGainCost method, Laplace correction applied pruning phase,
error rate p. MC+InfoGainCost method, Laplace correction applied, policy
grown, P (yjs) computing C (s; fk ), also applied post-pruning
based expected total costs, P (xn = vn js) P (yjs).
VOI method, Laplace correction applied probabilities employed
Equation 5 computation C (s; fbest).
286

fiLearning Diagnostic Policies Examples

6. Experimental Studies
present experimental study measure compare effectiveness efficiency various search regularization methods described above. goal
identify one practical algorithms learn good diagnostic policies real problems modest-sized training data sets. main questions are: algorithm
best among algorithms proposed? overall winner,
robust algorithm?

6.1 Experimental Setup
performed experiments five medical diagnosis problems based real data sets found
University California Irvine (UCI) repository (Blake & Merz, 1998).
five problems listed along short name parentheses use
refer them: Liver disorders (bupa), Pima Indians Diabetes (pima), Cleveland Heart
Disease (heart), original Wisconsin Breast Cancer (breast-cancer), SPECT heart
database (spect). data sets describe patient vector attribute values
class label. define measurement action attribute; executed, action
returns measured value attribute. define one diagnosis action class
label.
domains chosen two reasons. First, real medical diagnosis
domains. Second, measurement costs provided three (bupa, pima,
heart) Peter Turney (Turney, 1995); two domains, set measurement
costs 1. Table 2 brie describes medical domains; information available
thesis Bayer-Zubek (2003).
pre-processing steps applied domains. First, training examples
contained missing attribute values removed data sets. Second, data
set contained two classes, selected classes merged two classes
(healthy sick) remained. Third, existing division data training
test sets ignored, data simply merged single set. real-valued
attribute xn discretized 3 levels (as defined two thresholds, 1 2 )
discretized variable takes value 0 xn 1 , value 1 1 < xn 2
value 2 otherwise. values thresholds chosen maximize information
gain discretized variable class. information gain computed
using entire data set.
domain, transformed data (2 classes, discretized attributes missing
values) used generate 20 random splits training sets (two thirds data)
test sets (one third data), sampling stratified class. split (training data,
test data) called replica. repeated experiments replicas
obtain rough idea amount variability expected one replica
another. However, important note replicas independent (i.e.,
share data points), must use caution combining results different replicas
drawing conclusions superiority one algorithm compared another.
287

fiBayer-Zubek & Dietterich

Table 2: Medical domains. domain, list number examples, number
tests, minimum maximum cost test.
domain
# examples # tests min test cost max test cost
bupa
345
5
7.27
9.86
pima
768
8
1
22.78
heart
297
13
1
102.9
breast-cancer
683
9
1
1
spect
267
22
1
1
6.1.1 Setting Misdiagnosis Costs (MC)

None five UCI domains specifies misdiagnosis costs, performed experiments
using five different levels misdiagnosis costs domain. cost levels
designed initial state s0 diagnosis decisions f0 f1 equal
expected cost diagnostic policies non-trivial (i.e., perform least
one measurement, perform possible measurements). call five MC
levels MC1, MC2, MC3, MC4, MC5, progressively make misdiagnosis
expensive. Full details methodology given thesis Bayer-Zubek (2003).
6.1.2 Memory Limit

large domains (with many measurements), AND/OR graph constructed AO
grows large, especially following cases: measurements informative; measurement costs low relative misdiagnosis costs, admissible
heuristic produce many cutoffs; optimal policy deep;
many policies tied optimal one AO needs expand prove
better alternative.
make systematic search feasible, need prevent AND/OR graph growing
large. imposing limit total amount memory AND/OR
graph occupy. measure memory usage based amount memory would
required optimized AND/OR graph data structure. \theoretical" memory
limit set 100 MB. actual implementation optimized, translates
limit 500 MB. memory limit reached, current realistic policy
returned result search. algorithms (greedy systematic)
converge within memory limit five domains, one exception: AO large
misdiagnosis costs reaches memory limit spect data set.
interesting note even domain many measurements, systematic
search algorithms may converge reaching memory limit. consequence
fact modest-sized training data sets, number reachable states MDP
(i.e., states reached non-zero probability policy) fairly small,
288

fiLearning Diagnostic Policies Examples

possible combinations attribute values appear modest-sized data
set.
6.1.3 Notations Learning Algorithms

remainder paper, employ following abbreviations identify
various search algorithms regularizers. cases, sux \L" indicates
Laplace corrections applied algorithm described Section 5.

Nor, Nor-L denote InfoGainCost Norton's criterion selecting actions pes






simistic post-pruning based misdiagnosis rates.
MC-N, MC-N-L denote MC+InfoGainCost Norton's criterion selecting measurement actions. Diagnosis actions selected minimize expected misdiagnosis
costs. Post-pruning based expected total costs.
VOI, VOI-L denote one-step Value Information greedy method.
AO , AO -L denote AO .
SP, SP-L denote AO Statistical Pruning.
ES, ES-L denote AO Early Stopping. early stopping, half training
data held choose stopping point, half used AO
compute transition probabilities.
PPP, PPP-L denote AO Pessimistic Post-Pruning.

6.1.4 Evaluation Methods

evaluate algorithm, train training set construct policy.
compute value policy test set, denote Vtest . compute
Vtest , sum measurement costs misdiagnosis cost test example,
processed policy, divide total cost examples number
test examples.
Note framework, Vtest always computed using measurement costs
misdiagnosis costs, even policy constructed learning algorithm (e.g.,
InfoGainCost) ignores misdiagnosis costs.
order compare learning algorithms, need way comparing Vtest
values see statistically significant difference among them. Even two learning
algorithms equally good, Vtest values may different random variation
choice training test data sets. Ideally, would employ statistical procedure
similar analysis variance determine whether observed differences Vtest
explained differences learning algorithm (rather random variation
data sets). Unfortunately, procedure exists suitable comparing diagnostic
policies. Hence, adopted following procedure.
discussed above, generated 20 replicas data sets. addition,
built five misdiagnosis cost matrices data set. apply learning
algorithm replica using five MC matrices, requires total 500
289

fiBayer-Zubek & Dietterich

runs learning algorithm domains. replica cost matrix
pair learning algorithms (call alg1 alg2), apply BDeltaCost bootstrap
statistical test (Margineantu & Dietterich, 2000) decide whether policy constructed
alg1 better than, worse than, indistinguishable policy constructed alg2
(based 95% confidence level). Depending BDeltaCost results, say
alg1 wins, loses, ties alg2.
BDeltaCost test applied replica data set. BDeltaCost
results combined produce overall score algorithm according
following chess metric. given pair algorithms, alg1 alg2, domain D, let
(wins; ties; losses) cumulative BDeltaCost results alg1 alg2, across five
misdiagnosis cost matrices 20 replicas. chess metric computed counting
win one point, tie half point, loss zero points:
Score(alg1; alg2; D) def
= wins + 0:5 ties:
also compute overall chess score algorithm summing chess scores
algorithms:
X
Score(alg1; D) =
Score(alg1; alg2; D):
alg26=alg1

Note total number \games" played algorithm Total = wins +
ties + losses, games turned ties, chess score would 0:5 Total,

call Tie-Score. algorithm's chess score greater Tie-Score,
algorithm wins losses.
pairwise BDeltaCost tests account variation Vtest resulting random choice test sets. purpose 20 replicas account also random
choice training sets. Ideally, 20 training sets would disjoint, would allow us compute unbiased estimate variability Vtest due training sets.
Unfortunately, amount training data limited, cannot make training sets independent, result, overall chess scores probably underestimate
source variability.

6.2 Results

present results experiments.
6.2.1 Laplace Correction Improves Algorithms

first studied effect Laplace regularizer algorithm.
seven algorithms Laplace correction, computed chess score respect
non-Laplace version, domain. total number \games" algorithm
plays non-Laplace version 100 (there 5 misdiagnosis costs 20 replicas);
therefore, Tie-Score = 50.
Figure 8 shows domain, Laplace-corrected algorithm scores wins
losses versus non-Laplace-corrected algorithm (because score greater
Tie-Score). supports conclusion Laplace correction improves performance algorithm. algorithms, AO , helped
others Laplace.
290

fiLearning Diagnostic Policies Examples

Chess score Laplace-corrected alg. vs. non-Laplace alg.

100

bupa
90

pima
heart

80

b-can

70

spect

60

Tie-Score

50
40
30
20
10
0
Nor-L

MC-N-L
greedy

VOI-L

AO*-L

SP-L

ES-L

PPP-L

systematic

Figure 8: score Laplace-corrected algorithm versus non-Laplace version,
domain, greater Tie-Score. Therefore Laplace version
wins losses.
Since Laplace regularizer improved algorithm, decided compare
Laplace-corrected versions algorithms subsequent experiments.
6.2.2 Robust Algorithm

determine algorithm robust across five domains, computed
overall chess score Laplace-corrected algorithm Laplacecorrected algorithms, domain. total number \games" 600 (there
5 misdiagnosis costs matrices, 20 replicas, 6 \opponent" algorithms); therefore,
Tie-Score 300.
Figure 9 shows best algorithm varies depending domain: ES-L best
bupa, VOI-L best pima spect, SP-L best heart, MC-N-L best
breast-cancer. Therefore single algorithm best everywhere. Nor-L consistently bad
domain; score always Tie-Score. expected, since
Nor-L use misdiagnosis costs learning policy. MC-N-L, use
misdiagnosis costs, always scores better Nor-L.
291

fiBayer-Zubek & Dietterich

400
bupa
380

pima
heart

360

b-can

Overall chess score

340

spect

320
Tie-Score

300
280
260
240
220
200
Nor-L

MC-N-L
greedy

VOI-L

AO*-L

SP-L

ES-L
systematic

PPP-L

Figure 9: overall chess score Laplace-corrected algorithm, versus
Laplace-corrected algorithms. robust algorithm SP-L;
one whose score greater Tie-Score (and therefore wins
losses) every domain.
fact VOI-L best two domains interesting, ecient
greedy algorithm. Unfortunately, VOI-L obtains worst score two domains: heart
breast-cancer.
algorithm wins losses every domain SP-L, combines AO search, Laplace corrections, statistical pruning. SP-L always scored among
top three algorithms. Consequently, recommend robust algorithm.
However, applications SP-L (or systematic search algorithms)
expensive run, VOI-L recommended, since best greedy methods.
addition looking overall chess scores, also studied actual Vtest values.
visualize differences Vtest values, plotted graph call \pair graph".
Figure 10 shows pair graphs comparing VOI-L SP-L five domains. horizontal
axis graph corresponds 20 replicas, vertical axis Vtest values
two algorithms (VOI-L SP-L) replica. 20 replicas sorted according
292

fiLearning Diagnostic Policies Examples

Vtest VOI-L. two algorithms tied replica (according BDeltaCost),
Vtest values connected vertical dotted line.
bupa heart, Vtest SP-L mostly smaller (better) Vtest VOI-L,
BDeltaCost finds tied. pima spect, situation reversed (VOI-L
almost always better SP-L), several replicas difference statistically significant. breast-cancer, SP-L better VOI-L, difference sometimes
significant. general, pair graphs confirm chess score results support main
conclusion SP-L robust learning algorithm.
6.2.3 Impact Heuristics Regularizers Memory Consumption

consider effect admissible heuristic Laplace Statistical Pruning regularizers amount memory required AO search. this, measured
amount memory consumed five different algorithm configurations: AO without
admissible heuristic, AO admissible heuristic, AO admissible heuristic Laplace correction, AO admissible heuristic statistical pruning,
and, finally, AO admissible heuristic, Laplace correction, statistical pruning.
AO without admissible heuristic, set action-value every unexpanded
node (s; xn ) zero, i.e., Qopt (s; xn ) = 0. results plotted Figure 11.
memory amounts plotted computed taking actual memory consumed
implementation converting memory would consumed optimized
implementation.
several important conclusions draw figures. First, note AO
without admissible heuristic requires much memory AO admissible
heuristic. Hence, admissible heuristic pruning large parts search space.
particularly evident low settings misdiagnosis costs (MC1 MC2). low
settings, AO able find many cutoffs expected cost diagnosis less
cost making additional measurements (as estimated admissible heuristic).
savings much smaller MC levels 4 5.
second important conclusion Laplace correction increases size
search space amount memory consumed. reason without Laplace
correction, many test outcomes zero probability, pruned AO .
Laplace correction, outcomes must expanded evaluated. effect
minor low MC levels, AND/OR graph much smaller, consequently
enough training data prevent zero-probability outcomes. high MC levels,
Laplace correction cause increases factor 10 amount memory
consumed.
third important conclusion statistical pruning significantly decreases size
AND/OR graph almost cases. exception heart MC4 MC5,
statistical pruning increases amount memory needed AO . seems paradoxical statistical pruning could lead overall increase size AND/OR
graph explored. explanation interaction statistical pruning one point AND/OR graph additional search elsewhere.
branch pruned would given significantly smaller value V , pre293

fiBayer-Zubek & Dietterich

130

2400
VOI-L
SP-L

VOI-L
SP-L
2300

125

2200
120
2100

V_test[replica]

V_test[replica]

115

110

105

2000
1900
1800
1700

100
1600
95

1500

90

1400
replica

replica

(a) bupa

(b) pima

550

9
VOI-L
SP-L

VOI-L
SP-L
8

500

450

V_test[replica]

V_test[replica]

7

400

6

5

4
350
3

300

2
replica

replica

(c) heart

(d) breast-cancer

45
VOI-L
SP-L

V_test[replica]

40

35

30

25

20
replica

(e) spect
Figure 10: Pair graphs VOI-L SP-L every domain replica, largest
misdiagnosis costs MC5. replicas sorted increasing order Vtest
VOI-L. Vertical lines connect Vtest values tied according BDeltaCost.
294

fiLearning Diagnostic Policies Examples

BUPA

Pima

30000

1e+07

AO*+L
AO*+L

20000
AO* heur

AO*
AO*+SP

Memory Consumed (bytes)

Memory Consumed (bytes)

AO*+SP+L

AO*+SP+L
AO* heur
AO*

1e+06

AO*+SP

100000

10000
MC1

MC2

MC3

MC4

MC5

MC1

MC2

Misdiagnosis Cost Level

MC3

MC4

MC5

Misdiagnosis Cost Level

(a) bupa

(b) pima

Heart

Breast-cancer

1e+09

1e+07
AO*+L
AO*+L

1e+08

1e+06

AO* heur
AO*+SP
AO*

1e+06

100000

Memory Consumed (bytes)

Memory Consumed (bytes)

AO*+SP+L
1e+07

AO*+SP+L
AO* heur

AO*

100000

AO*+SP

10000

10000
1000
1000

100

100
MC1

MC2

MC3

MC4

MC5

MC1

Misdiagnosis Cost Level

MC2

MC3

MC4

MC5

Misdiagnosis Cost Level

(c) heart

(d) breast-cancer

Spect

Memory Consumed (bytes)

2e+08

1e+08
AO* heur
AO*
AO*+L
AO*+SP
AO*+SP+L
5e+07

2e+07
MC1

MC2

MC3

MC4

MC5

Misdiagnosis Cost Level

(e) spect

Figure 11: Memory consumed domain five combinations AO without admissible heuristic, Laplace corrections, statistical pruning
five levels misdiagnosis costs.

295

fiBayer-Zubek & Dietterich

vent heuristic cutoffs elsewhere graph. cases, pruning increase overall
memory consumption.
final conclusion statistical pruning dramatically reduces amount memory required AO Laplace correction. Even cases, heart, statistical pruning causes AO (without Laplace) consume space, SP reduces amount
space needed Laplace correction nearly order magnitude. Nonetheless,
statistical pruning able completely compensate extra memory consumption
Laplace corrections, final algorithm (AO + SP + L) requires memory
AO without admissible heuristic high MC levels, AO + SP + L requires
much memory AO admissible heuristic.
Despite large amount memory required, one domain (spect
MC4 MC5) AO hit memory limit. Hence, see terms
memory, systematic search AO feasible today's desktop workstations.
6.2.4 CPU Time

addition measuring memory consumption, also measured CPU time required
algorithms. results plotted Figure 12. expected, systematic
search algorithms require several orders magnitude CPU time greedy
methods. However, even expensive algorithm configurations require less
1000 seconds execute. Note misdiagnosis cost level increases, amount
CPU time increases. direct ection corresponding increase size
AND/OR graph explored algorithms.

7. Conclusions
problem addressed paper learn diagnostic policy data set labeled
examples, given measurement costs misdiagnosis costs. tradeoff
two types costs important issue machine learning research begun
study.
formulated process diagnosis Markov Decision Problem. showed
apply AO algorithm solve MDP find optimal diagnostic policy.
also showed convert AO algorithm anytime algorithm computing
realistic policy point search (the realistic policy best complete policy
found far). defined admissible heuristic AO able prune large parts
search space problems. also presented three greedy algorithms finding
diagnostic policies.
paper discussed interaction learning training data searching good diagnostic policy. Experiments demonstrated overfitting serious
problem AO . central contribution paper development methods
regularizing AO search reduce overfitting and, cases, also reduce
size search space. Four regularization techniques (Laplace corrections, statistical
pruning, early stopping, pessimistic post-pruning) presented. paper also introduced regularizers greedy search algorithms extending existing methods
classification tree learning.
296

fiLearning Diagnostic Policies Examples

1

1000
MC1
MC3
MC5

MC1
MC3
MC5

average_replica CPU Time (in seconds)

average_replica CPU Time (in seconds)

100

0.1

0.01

10

1

0.1

0.001

0.01


Nor-L MC-NMC-N-L VOI VOI-L AO* AO*-L

ES

ES-L

SP

SP-L

PPP PPP-L



(a) bupa

Nor-L MC-N MC-N-L VOI

VOI-L AO* AO*-L

ES

ES-L

SP

SP-L

PPP PPP-L

ES

ES-L

SP

SP-L

PPP PPP-L

(b) pima

1000

100
MC1
MC3
MC5

MC1
MC3
MC5

100
average_replica CPU Time (in seconds)

average_replica CPU Time (in seconds)

10

10

1

0.1

1

0.1

0.01
0.01

0.001

0.001


Nor-L MC-NMC-N-L VOI VOI-L AO* AO*-L

ES

ES-L

SP

SP-L

PPP PPP-L



(c) heart

Nor-L MC-NMC-N-L VOI VOI-L AO* AO*-L

(d) breast-cancer

1000
MC1
MC3
MC5

average_replica CPU Time (in seconds)

100

10

1

0.1

0.01


Nor-L MC-N MC-N-L VOI

VOI-L AO* AO*-L

ES

ES-L

SP

SP-L

PPP PPP-L

(e) spect
Figure 12: CPU time 14 algorithm configurations five domains (in case
averaged 20 replicas). three curves plot CPU time misdiagnosis
cost levels MC1, MC3, MC5.

297

fiBayer-Zubek & Dietterich

various search regularization algorithms tested experimentally five
classification problems drawn UCI repository. methodology assigning misdiagnosis costs developed problems could converted cost-sensitive
diagnosis problems. paper also introduced methodology combining results
multiple training/test replicas overall \chess score" evaluating learning
algorithms.
experiments showed search algorithms improved including
Laplace corrections estimating probabilities training data. experiments
also showed systematic search algorithms generally robust
greedy search algorithms across five domains. best greedy algorithm VOI-L,
although obtained best score two domains, produced worst score two
domains. robust learning algorithm SP-L. combines systematic AO
search Laplace corrections statistical pruning.
Systematic search diagnostic policies studied previously machine
learning researchers, probably generally regarded computationally
infeasible. surprising conclusion paper AO computationally feasible
applied problem learning diagnostic policies training examples.
conclusion based experimental evidence|AO required less 500 MB
memory virtually benchmark scenarios|and theoretical analysis.
theoretical perspective, five factors help make AO feasible
setting: modest amount training data, modest number possible tests,
small number outcomes test, admissible heuristic, statistical pruning
regularizer. discuss factors turn:
Modest amount training data. learning diagnosis, cost measuring attribute training example. Consequently, training example
expensive collect, puts practical limit size training data
set. turn limits space reachable states MDP. result,
AND/OR graph searched AO grow large. amount training
data grows, graph gradually grow larger point, become
large available memory. Good results may still obtained imposing
memory limit, spect experiments.
Modest number possible tests. experiments considered domains 22
fewer tests. number tests determines branching factor nodes
graph, size graph scales exponentially quantity. However,
tests pruned admissible heuristic statistical pruning,
exponential explosion avoided. Whether possible particular
problem depends relative costs informativeness different tests.
Small number outcomes test. discretized continuous measurement
3 outcomes. number outcomes determines branching factor
nodes graph, graph size scales exponentially quantity
well. quantity controlled discretization (see below).
admissible heuristic. problem learning diagnosis non-trivial
costs making measurements comparable costs misdiagnosis.
298

fiLearning Diagnostic Policies Examples

true, admissible heuristic able prune large parts search
space.

Statistical pruning. Finally, statistical pruning regularizer able prune parts
search space unlikely produce improved policies.

Notice size AND/OR graph increase number possible
diagnoses increases. Hence, AO* search approach scales well number possible
diagnostic outcomes.
cases AND/OR graph becomes infeasibly large, recommend VOI-L, since
experiments showed best greedy method.
MDP framework diagnosis general enough handle several extensions
learning algorithms studied paper. example, experiments, considered
diagnosis problems involve two classes, \healthy" \sick." could easily
generalized consider arbitrary number classes. implementations assumed
cost measurement depends attribute measured, C (xn ).
easily generalized cost measurement depends tests
already executed results produced, also depend
result measurement. words, cost function measurement
generalized C (s; xn ; s0 ), current state MDP, xn measurement,
s0 resulting state s0 = [ fxn = vn g. implementations also assumed
misdiagnosis costs fixed patients, could extended allow
costs vary one patient another. changes diagnosis problem (multiple
classes complex costs) modify size complexity MDP.
important extensions diagnostic setting require extensions MDP
framework well. example, handle treatment actions side effects, noisy
actions may need repeated, actions delayed results, definition
state MDP needs extended. initial examination extensions
suggest cause MDP state space grow significantly,
may make infeasible search space diagnostic policies systematically. Hence,
extensions probably require new ideas solution.
Another important direction future work extend approach handle tests
large number possible outcomes, including particularly tests continuous
measured values. applied standard information-gain methods discretizing continuous attributes, interesting direction future work develop cost-sensitive
discretization methods.
final challenge future research learn good diagnostic policies incomplete training data. algorithms presented paper assume attribute
training example measured. data hard obtain. every day,
thousands patients seen physicians, medical tests performed, diagnostic
decisions made. data incomplete, physician following
diagnostic policy certainly perform possible medical tests.
resulting training examples many missing values, values \missing
random", standard methods handling missing values cannot applied. Methods
learning diagnostic policies data would valuable many applications.
299

fiBayer-Zubek & Dietterich

problem learning diagnostic policy data collected executing
diagnostic policy identical problem \off-policy" reinforcement learning
(Sutton & Barto, 1999). reinforcement learning, diagnostic policy generating
data called exploration policy. Much known creating exploration policies
enable learning optimal policies. example, exploration policy non-zero
probability executing every action every state, optimal policy still
learned. exploration policy controlled learning system, much
selective exploration produce optimal policy (Kearns & Singh, 1998). extending
ideas, may possible learn diagnostic policies data collected routinely
hospitals clinics.
problem learning diagnostic policies fundamental many application domains
including medicine, equipment diagnosis, autonomic computing. diagnostic policy
must balance cost gathering information performing measurements cost
making incorrect diagnoses. paper shown AO -based systematic search,
combined regularization methods preventing overfitting, feasible method
learning good diagnostic policies labeled examples.

Acknowledgments
authors gratefully acknowledge support National Science Foundation
grants IRI-9626584, EIA-9818414, IIS-0083292, EIA-0224012, ITR-5710001197.
authors also gratefully acknowledge support Air Force Oce Scientific Research
grant number F49620-98-1-0375.
paper extends conference paper Bayer-Zubek (2004).
authors thank anonymous reviewers comments.

References
Bayer-Zubek, V. (2003). Learning Cost-sensitive Diagnostic Policies Data. Ph.D.
thesis, Department Computer Science, Oregon State University, Corvallis,
http://eecs.oregonstate.edu/library/?call=2003-13.
Bayer-Zubek, V. (2004). Learning diagnostic policies examples systematic search.
Proceedings Twentieth Conference Uncertainty Artificial Intelligence,
pp. 27{35, Banff, Canada.
Bayer-Zubek, V., & Dietterich, T. (2002). Pruning improves heuristic search costsensitive learning. Proceedings Nineteenth International Conference Machine Learning, pp. 27{35, Sydney, Australia. Morgan Kaufmann.
Blake, C., & Merz, C. (1998). UCI repository machine learning databases.
http://www.ics.uci.edu/mlearn/MLRepository.html.
Bradford, J. P., Kunz, C., Kohavi, R., Brunk, C., & Brodley, C. E. (1998). Pruning decision trees misclassification costs. European Conference Machine Learning,
pp. 131{136. Longer version http://robotics.stanford.edu/users/ronnyk/ronnykbib.html, ECE TR 98-3, Purdue University.
300

fiLearning Diagnostic Policies Examples

Breiman, L., Friedman, J., Olshen, R. A., & Stone, C. (1984). Classification Regression
Trees. Wadsworth, Monterey, California.
Cooper, G. F., & Herskovits, E. (1992). Bayesian method induction probabilistic
networks data. Machine Learning, 9, 309{347.
Dittmer, S., & Jensen, F. (1997). Myopic value information uence diagrams.
Proceedings Thirteenth Conference Uncertainty Artificial Intelligence, pp.
142{149, San Francisco.
Domingos, P. (1999). MetaCost: general method making classifiers cost-sensitive.
Knowledge Discovery Data Mining, pp. 155{164.
Fawcett, T., & Provost, F. (1997). Adaptive fraud detection. Data Mining Knowledge
Discovery, 1(3), 1{28.
Friedman, N., Geiger, D., & Goldszmidt, M. (1997). Bayesian network classifiers. Machine
Learning, 29, 131{163.
Friedman, N., & Goldszmidt, M. (1996). Building classifiers using Bayesian networks.
Proceedings Thirteenth National Conference Artificial Intelligence, pp. 1277{
1284, Cambridge, MA. AAAI Press/MIT Press.
Greiner, R., Grove, A. J., & Roth, D. (2002). Learning cost-sensitive active classifiers.
Artificial Intelligence, 139:2, 137{174.
Hansen, E. (1998). Solving POMDPs searching policy space. Proceedings
Fourteenth International Conference Uncertainty Artificial Intelligence, pp.
211{219, San Francisco. Morgan Kaufmann.
Heckerman, D., Breese, J., & Rommelse, K. (1994). Troubleshooting uncertainty.
Tech. rep., MSR-TR-94-07, Microsoft Research.
Heckerman, D., Horvitz, E., & Middleton, B. (1993). approximate nonmyopic computation value information. IEEE Transactions Pattern Analysis Machine
Intelligence, 15, 292{298.
Heckerman, D., Breese, J., & Rommelse, K. (1995). Decision-theoretic troubleshooting.
Communications ACM, 38, 49{57.
Kearns, M., & Singh, S. (1998). Near-optimal reinforcement learning polynomial time.
Proceedings Fifteenth International Conference Machine Learning, pp.
260{268. Morgan Kaufmann, San Francisco, CA.
Lang, K. J., Waibel, A. H., & Hinton, G. E. (1990). time-delay neural network architecture
isolated word recognition. Neural Networks, 3, 33{43.
Lenert, L. A., & Soetikno, R. M. (1997). Automated computer interviews elicit utilities:
potential applications treatment deep venous thrombosis. Journal
American Medical Informatics Association, 4 (1), 49{56.
Littman, M. L., Ravi, N., Fenson, E., & Howard, R. (2004). instance-based state representation network repair. Proceedings Nineteenth National Conference
Artificial Intelligence (in press), San Jose, California.
301

fiBayer-Zubek & Dietterich

Madigan, D., & Almond, R. (1996). test selection strategies belief networks.
Fisher, D., & Lenz, H. (Eds.), Learning Data: AI Statistics, pp. 89{98.
Morgan Kaufmann.
Margineantu, D. D., & Dietterich, T. (2000). Bootstrap methods cost-sensitive
evaluation classifiers. Proceedings Seventeenth International Conference
Machine Learning, pp. 583{590, San Francisco, CA. Morgan Kaufmann.
Martelli, A., & Montanari, U. (1973). Additive AND/OR graphs. Proceedings
Third International Joint Conference Artificial Intelligence, pp. 1{11.
Nilsson, N. (1980). Principles Artificial Intelligence. Tioga Publishing Co., Palo Alto,
CA.
Norton, S. W. (1989). Generating better decision trees. Proceedings Eleventh
International Joint Conference Artificial Intelligence, pp. 800{805, San Francisco.
Morgan Kaufmann.
Nunez, M. (1991). use background knowledge decision tree induction. Machine
Learning, 6(3), 231{250.
Pattipati, K. R., & Alexandridis, M. G. (1990). Application heuristic search information theory sequential fault diagnosis. IEEE Transactions Systems, Man
Cybernetics, 20(4), 872{887.
Pazzani, M., Merz, C., Murphy, P., Ali, K., Hume, T., & Brunk, C. (1994). Reducing
misclassification costs. Proceedings Eleventh International Conference
Machine Learning, pp. 217{225, New Brunswick, New Jersey. Morgan Kaufmann.
Provost, F. J., & Fawcett, T. (2001). Robust classification imprecise environments.
Machine Learning, 42 (3), 203{231.
Puterman, M. L. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming. John Wiley & Sons, New York.
Qi, R. (1994). Decision Graphs: Algorithms Applications uence Diagram Evaluation High-Level Path Planning Uncertainty. Ph.D. thesis, University
British Columbia.
Quinlan, J. R. (1993). C4.5: Programs Machine Learning. Morgan Kaufmann, San
Mateo, California.
Raiffa, H. (1968). Decision Analysis. Adison-Wesley, Reading, MA.
Sutton, R. S., & Barto, A. (1999). Reinforcement Learning: Introduction. MIT Press,
Cambrdige, Massachusetts.
Tan, M. (1993). Cost-sensitive learning classification knowledge applications
robotics. Machine Learning, 13(1), 1{33.
Turney, P. (2000). Types cost inductive concept learning. Workshop CostSensitive Learning ICML2000, pp. 15{21, Stanford University, California.
Turney, P. D. (1995). Cost-sensitive classification: Empirical evaluation hybrid genetic
decision tree induction algorithm. Journal Artificial Intelligence Research, 2, 369{
409.
302

fiLearning Diagnostic Policies Examples

Utgoff, P. E. (1989). Incremental induction decision trees. Machine Learning, 4, 161{186.
van der Gaag, L., & Wessels, M. (1993). Selective evidence gathering diagnostic belief
networks. AISB Quarterly, 86, 23{34.
Washington, R. (1997). BI-POMDP: Bounded, incremental partially-observable Markovmodel planning. Proceedings Fourth European Conference Planning.
Zadrozny, B., & Elkan, C. (2001). Learning making decisions costs probabilities unknown. Proceedings Seventh International Conference
Knowledge Discovery Data Mining, pp. 204{213. ACM Press.

303

fiJournal Artificial Intelligence Research 24 (2005) 109156

Submitted 10/04; published 7/05

Solving Set Constraint Satisfaction Problems using ROBDDs
Peter Hawkins
Vitaly Lagoon

hawkinsp@cs.mu.oz.au
lagoon@cs.mu.oz.au

Department Computer Science Software Engineering
University Melbourne, VIC 3010, Australia

Peter J. Stuckey

pjs@cs.mu.oz.au
NICTA Victoria Laboratory, Department Computer Science Software Engineering
University Melbourne, VIC 3010, Australia

Abstract
paper present new approach modeling finite set domain constraint problems using Reduced Ordered Binary Decision Diagrams (ROBDDs). show
possible construct efficient set domain propagator compactly represents many
set domains set constraints using ROBDDs. demonstrate ROBDD-based
approach provides unprecedented flexibility modeling constraint satisfaction problems,
leading performance improvements. also show ROBDD-based modeling
approach extended modeling integer multiset constraint problems
straightforward manner. Since domain propagation always practical, also show
incorporate less strict consistency notions ROBDD framework, set
bounds, cardinality bounds lexicographic bounds consistency. Finally, present experimental results demonstrate ROBDD-based solver performs better various
conventional constraint solvers several standard set constraint problems.

1. Introduction
often natural express constraint satisfaction problem (CSP) using finite domain
variables relations variables, values variable drawn
finite universe possible values. One common methods solving finite
domain CSPs maintaining updating domain variable using
combination backtracking search incomplete local propagation algorithm.
local propagation algorithm attempts enforce consistency values variable
domains removing values cannot form part solution system constraints.
Various levels consistency defined, associated costs benefits.
consistency algorithms incompletethat is, incapable solving problem
themselves, must combined backtracking search procedure produce
complete constraint solver.
attempting apply general scheme task solving constraint satisfaction problems finite set variables quickly run practical problems. Since
universe possible values set variable usually large, nave representation
domain set variable set sets unwieldy solve realistic problems.
example, set variable take value subset set {1, . . . , N },
domain contains 2N elements, quickly becomes infeasible represent N increases
c
2005
AI Access Foundation. rights reserved.

fiHawkins, Lagoon, & Stuckey

magnitude. Accordingly, set constraint solvers date used approximation
true domain set variable order avoid combinatorial explosion.
common approximation true domain set variable v
maintain upper bound U lower bound L domain subset partial
ordering relation perform set bounds propagation bounds. is, L
contains elements must set v, U complement set elements
must v. Conventionally, fixed set inference rules specific constraint
used enforce consistency upper lower bounds. basic scheme
proposed Puget (1992), implemented set solvers Conjunto
(Gervet, 1997), fd sets ic sets libraries ECLi PSe (IC-PARC, 2003), Mozart
(Muller, 2001), ILOG Solver (ILOG, 2004).
Set bounds crude approximation set domain best, thus various refinements bounds propagation scheme proposed effectively
capture nature set domain. Azevedo (2002) demonstrated maintaining
performing inferences upon upper lower bounds cardinality set domain
leads significant performance improvement variety problems. earlier
set solvers Conjunto also maintained cardinality bounds, partial usage
made information. recently, Sadler Gervet (2004) showed incorporating upper lower bounds lexicographic ordering leads significantly stronger
propagation, albeit cost marked increase propagation time, leading
marginal performance improvement overall. approaches provide
effective propagation simple set bounds scheme, approach effectiveness true set domain propagator, ensures every value domain
set variable extended complete assignment every variable given
constraint.
Consequently, would like devise representation set domains constraints
domains tractable enough permit domain propagation. principal
observation permits implementation set domain propagator finite
integer set v represented characteristic function v :
v : Z {0, 1} v (i) = 1 iff v
Accordingly use set Boolean variables vi represent set v, correspond
propositions vi v. describe set domains set constraints terms
Boolean variables. Interestingly, set bounds propagation described
equivalent performing domain propagation nave way Boolean representation.
paper investigate Boolean modeling approach modeling finite domain
constraints, particular set constraints. show possible represent
domains set variables using Reduced Ordered Binary Decision Diagrams (ROBDDs),
data structure representing manipulating Boolean formul. representations
usually fairly compact, even correspond large domains. addition,
possible represent constraints ROBDDs, permitting us produce
efficient set domain constraint propagators solely using ROBDD operations.
ROBDD-based representation allows us easily conjoin constraints existentially quantify variables, thus permitting us remove intermediate variables merge
constraints stronger propagation. construction global constraints becomes
110

fiSolving Set Constraint Satisfaction Problems using ROBDDs

almost trivial exercise, without requirement write laboriously new propagators
every new constraint would like use.
also demonstrate minor changes needed operation set
domain propagator order implement other, less strict notions consistency. particular, show construct set bounds, cardinality bounds lexicographic bounds
propagators, utilize notions produce split domain solver combines
bounds domain reasoning.
key theme paper flexibility ROBDD-based modeling approach.
limited modeling set variablesfor example ROBDDs used
model integer variables integer constraints. ROBDD-based approach
modeling finite domain integer variables general efficient many existing
finite domain integer solvers, ability model integer constraints using ROBDDs
essential building block allows us construct set constraints cardinality
weighted sum, well allowing us represent multisets multiset constraints.
Finally, present experiments using variety standard set problems demonstrate
advantages modeling approach.
Many ideas paper previously published two previous works
(Lagoon & Stuckey, 2004; Hawkins, Lagoon, & Stuckey, 2004). paper contains
complete exposition ideas, well important extensions work
previously presented. include substantial improvements complexity
propagation algorithm, well cardinality lexicographic bounds solvers implemented
using ROBDDs. addition, show model integer expressions, allowing us
implement weighted-sum constraint, model multisets multiset constraints.
Using this, present new experimental results Hamming Code Balanced
Academic Curriculum problems. Finally, present results comparing ROBDD-based
solver solver good cardinality reasoning (Mozart).
remainder paper structured follows. Section 2 contains essential concepts
definitions necessary discussing finite domain solvers ROBDDs. Section 3
shows model set domains set constraints using ROBDDs, presents basic
outline ROBDD-based set constraint solver. Section 4 demonstrates improve
performance ROBDD-based set solver construction global constraints, removal intermediate variables, symmetry-breaking approaches.
Section 5 demonstrates model integer multiset expressions, well
implement weighted-sum constraint set multiset variables. Section 6 shows
construct efficient domain propagator, well set bounds, set cardinality,
lexicographic bounds propagators. Finally, Section 7 present experimental results
comparing ROBDD-based solver conventional set solvers variety
standard problems.

2. Preliminaries
section define concepts notation necessary discussing propagationbased constraint solvers. definitions largely identical presented Lagoon
Stuckey (2004) others. simplicity shall present definitions
case finite set variables; extensions multiset integer variables trivial.
111

fiHawkins, Lagoon, & Stuckey

2.1 Lattices, Domains, Valuations
Let L powerset lattice hP(U), i, P(x) denotes powerset x
universe U finite subset Z. say subset L convex a, c
relation b c implies b b L. interval [a, b] set = {x
L | x b}. Intervals obviously convex. Given subset K L, define convex
closure K:
"
#
\
[
conv (K) =
x,
x
xK

xK

convex closure operation satisfies properties extension (x conv (x)), idempotence (conv (x) = conv (conv (x))), monotonicity (if x conv (x) (y)) (Gervet,
1997).

Example 2.1. set X = {{1}, {1, 3}, {1, 4}, {1, 3, 4}} convex equivalent interval [{1}, {1, 3, 4}]. Conversely, set = {{1}, {1, 3}, {1, 3, 4}} convex. However,
convex closure precisely interval X, i.e. conv (Y ) = X.
Let V denote fixed finite collection set variables. variable domain,
finite collection possible values L (which sets).
generally, define domain complete mapping set V finite collections
finite sets integers. speak domain variable v, mean D(v).
domain D1 said stronger domain D2 , written D1 v D2 , D1 (v) D2 (v)
v V. Two domains said equal, written D1 = D2 , D1 (v) = D2 (v)
v V. call domain range domain D(v) interval v V.
extend concept convex closure domains defining ran(D) unique
(range) domain ran(D)(v) = conv (D(v)) v V.
valuation function V L, write using mapping notation
{v1 7 d1 , v2 7 d2 , . . . , vn 7 dn }, vi V di L N. Clearly valuation
extended constraints involving variables obvious way. define vars
function returns set variables involved constraint, expression
valuation. abuse notation, valuation said element domain
D, written D, (v) D(v) v vars().
say domain singleton valuation domain |D(v)| = 1 v V.
case corresponds single valuation D(v) = {(v)} v V.
2.2 Constraints, Propagators, Propagation Solvers
constraint restriction placed upon allowable values collection variables.
interested following primitive set constraints, k integer,
ground set value, u, v w set variables: k v (membership), k
/ v (nonmembership), u = v (equality), u = (constant equality), u v (non-strict subset),
u = v w (union), u = v w (intersection), u = v \ w (set difference), u = v (complement),
u 6= v (disequality), |u| = k (cardinality), |u| k (lower cardinality bound), |u| k
(upper cardinality bound). Later shall introduce non-primitive set constraints
formed composing primitive set constraints.
define solutions constraint c set valuations make
constraint true, i.e. solns(c) = { | vars() = vars(c) (c)}.
112

fiSolving Set Constraint Satisfaction Problems using ROBDDs

Example 2.2. Suppose v w set variables, domain D(v) =
{{1}, {1, 3}, {2, 3}}, D(w) = {{2}, {1, 2}, {1, 3}}. Let c constraint v w.
solutions c domain valuations {v 7 {1}, w 7 {1, 2}},
{v 7 {1}, w 7 {1, 3}}, {v 7 {1, 3}, w 7 {1, 3}}.
every constraint associate propagator f , monotonic decreasing
function domains domains, D1 v D2 f (D1 ) v f (D2 ) f (D1 ) v D1 .
propagator f said correct constraint c if:
{ | D} solns(c) = { | f (D)} solns(c)
Correctness strong restriction, since identity propagator correct constraints c. usually assume propagators correct checking, is,
singleton domain formed propagation associated valuation makes
(c) true.
use propagators form basis constraint solver. propagation solver
solv (F, D) takes set propagators F current domain D, repeatedly applies
propagators F current domain fixpoint reached. words
solv (F, D) weakest domain 0 v fixpoint (i.e. f (D 0 ) = D0 )
f F . fixpoint unique (Apt, 1999).
2.3 Local Consistency
notion local consistency importance considering solution constraint
satisfaction problems. define various levels consistency different strengths
levels difficulty enforce. describe two here.
domain said domain consistent constraint c strongest
domain contains solutions c; words exist
domain 0 v solns(c) implies 0 . set propagators
maintains domain consistency solv (F, D) domain consistent constraints c.
Definition 1. domain propagator constraint c function dom(c) mapping domains domains satisfies following identity:
(
{(v) | solns(c)} v vars(c)
dom(c)(D)(v) =
D(v)
otherwise
Lemma 2.1. domain propagator dom(c) constraint c correct, checking, monotonic, idempotent.
Proof. Straightforward definitions.
Example 2.3. Consider constraint v w domain Example 2.2. domain
propagation 0 = dom(c)(D) returns domain 0 0 (v) = {{1}, {1, 3}} 0 (w) =
{{1, 2}, {1, 3}}. missing values take part solution.
Domain consistency may difficult achieve set constraints, instead often
need weaker notion consistency. notion set bounds consistency commonly
113

fiHawkins, Lagoon, & Stuckey

used. domain bounds consistent constraint c every variable v vars(c)
upper bound D(v) union values v solutions c D,
lower bound D(v) intersection values v solutions c D.
above, set propagators F said maintain set bounds consistency constraint c
solv (F, D) bounds consistent domains D.
Definition 2. set bounds propagator constraint c function sb(c) mapping
domains domains satisfying following identity:
(
conv (dom(c)(ran(D))(v)) v vars(c)
sb(c)(D)(v) =
D(v)
otherwise
Lemma 2.2. set bounds propagator sb(c) constraint c correct, checking,
idempotent. propagator sb(c) also monotonic range domains.
Proof. follow trivially properties dom(c) extension
idempotence properties conv ran.
Clearly constraint c v vars(c) dom(c)(D)(v) sb(c)(D)(v)
domain propagators dom(c) set bounds propagators sb(c).
2.4 Boolean Formul Binary Decision Diagrams
use Boolean formul extensively model sets set relations. particular, make
use following Boolean operations: (conjunction), (disjunction), (negation),
(implication), (bi-directional implication), (exclusive OR), (existential quantification). use shorthand V F x1 xn F V = {x1 , . . . , xn }, use
V F mean V 0 F V 0 = vars(F ) \ V .
Binary Decision Trees (BDTs) well-known method modeling Boolean functions
Boolean variables. Binary Decision Tree complete binary tree,
internal node n(v, t, f ) labelled Boolean variable v leaf node labelled
truth value 0 (false) 1 (true). internal node corresponds if-then-else
test labelled variable, two outgoing arcsthe false arc (to BDT f )
true arc (to BDT t). order evaluate function represented binary tree,
tree traversed root leaf. reaching internal node, value
Boolean variable whose label appears node examined, corresponding
arc followed. traversal stops upon reaching leaf node, whereupon value
function taken label node.
Binary Decision Diagram (BDD) variant Binary Decision Tree, formed
relaxing tree structure requirement, instead representing functions directed acyclic
graphs. Binary Decision Diagram, node permitted multiple parents,
opposed tree structure requires node one parent.
effectively permits common portions tree shared multiple branches,
allowing compact representation many functions.
primary disadvantage Binary Decision Trees Binary Decision Diagrams
representation given function canonical (i.e. one function may
many representations). Two additional canonicity properties allow many operations
114

fiSolving Set Constraint Satisfaction Problems using ROBDDs

0123
7654
0123
7654
0123
7654
v E
v RRR
v RRR
EE
RRRR

RR)

l
u
l
"0123
0123
7654
0123
7654
l
(0123
v FF
v FF
0123
7654
7654
7654
v Ev
v E
v

|
"
|
"
E
E



E"
E"
0123
7654
0123
7654
0123
7654
0123
7654




|
|
|
v
v
v
v FF
FF
FF
FF
0123
7654
0123
7654
0123
7654
0123
7654
0123
7654
v
v
v
v
v
"0123
"
"
"
E
EE

2
E



7654
0123
7654
0123
7654
0123
7654
22
E" y|
v
v
v
v
' E" y|

y|
22
0123
7654
0123
7654
0123
7654
|
|
|
|
v
v
v

DD
0123
7654
0123
7654
0123
7654
0123
7654
/
( EEE
2
v
v
v
v
z
"
< 5 DDDD z z
/
|
|
|
|
0123
7654
v
0123
7654
0123
7654
0123
7654
0123
7654
5

6
h

0
v
v
v
v
R

FF
FF
FF
FF
:
b eiDD
z
z DD
"
"
"
"
"
! }z
# rt|z
0123
7654
0123
7654
0123
7654
0123
7654
v
v
v
v FF
F
F
F
0
1
1
F"
F"
F"
"
0123
7654
7654
0123
7654
7654
v FF 0123
v
v FF 0123
v
"0123
|
"
|
7654
0123
7654
v RRR
v
RR
l l
w

3

1

2

4

5

1

8

2

2

8

8

3

8

2

3

4

6

9

9

7

6

7

3

4

5

5

6

3

4

5

5

6

6

7

8

7

7

8

8

9

(b)

8

9

R(

(a)

4

1

vl

(c)

Figure 1: ROBDDs (a) LU = v3 v4 v5 v6 v7 (b) R = (v1 v9 ) (v2 v8 )
(c) LU R (omitting node 0 arcs it). Solid arcs arcs,
dashed arcs else arcs.

BDDs performed efficiently (Bryant, 1986, 1992). BDD said reduced
contains identical nodes (that is, nodes label identical
else arcs), redundant tests (there nodes
else arcs node). BDD said ordered total order
variables, arc node labelled v1 node labelled v2
v1 v2 . Reduced Ordered BDD (ROBDD) canonical function representation
reordering, permits efficient implementation many Boolean function operations.
details reader referred work Bryant (1992), introduction
Andersen (1998).
define size |R| number non-leaf nodes ROBDD R, well
defining VAR(R) set ROBDD variables appear labels internal
nodes R. shall interested stick ROBDDs, every internal node n(v, t, f )
exactly one f constant 0 node.
Example 2.4. Figure 1(a) gives example stick ROBDD LU representing formula
v3 v4 v5 v6 v7 . |LU | = 5 V AR(LU ) = {v3 , v4 , v5 , v6 , v7 }. Figure 1(b) gives
example complex ROBDD representing formula (v1 v9 ) (v2 v8 ).
|R| = 9 V AR(R) = {v1 , v2 , v8 , v9 }. One verify valuation {v1 7 1, v2 7
0, v8 7 1, v9 7 0} makes formula true following path right, left, right, left
root.
2.5 ROBDD Operations
efficient algorithms many Boolean operations applied ROBDDs.
complexity basic operations constructing new ROBDDs O(|R 1 ||R2 |) R1 R2 ,
115

fiHawkins, Lagoon, & Stuckey

node(v, t, f ) (t = f ) return else return n(v, t, f )
and(R1 , R2 )
(R1 = 0 R2 = 0) return 0
(R1 = 1) return R2
(R2 = 1) return R1
n(v1 , t1 , f1 ) := R1
n(v2 , t2 , f2 ) := R2
(v1 v2 ) return node(v1 ,and(t1 , R2 ),and(f1 , R2 ))
else (v2 v1 ) return node(v2 ,and(t2 , R1 ),and(f2 , R1 ))
else return node(v1 ,and(t1 , t2 ),and(f1 , f2 ))
exists(v, R)
(R = 0) return 0
(R = 1) return 1
n(vr , t, f ) := R
(vr v) return node(vr ,exists(v, t),exists(v, f ))
else (v vr ) return R
else return or(t, f )
Figure 2: Example ROBDD operations
R1 R2 R1 R2 , O(|R|) R, O(|R|2 ) v R. Note however test
whether two ROBDDs identical, whether R1 R2 equivalent true (1), O(1).
give code conjunction R1 R2 = and(R1 , R2 ) existential quantification (of
one variable) v R = exists(v, R). code disjunction R1 R2 = or(R1 , R2 ) dual
similar structure. code make use auxiliary function node
builds new ROBDD node. node function returns = f , practice
memoed call node arguments previous call returns reference
previously created ROBDD node.
Modern BDD packages provide many operations, including specialized implementations operations improved speed. important operations purposes
existential quantification multiple variables V formula R V R, combination conjunction existential quantification V R1 R2 .
Although theory number nodes ROBDDs exponential
number variables represented Boolean function, practice ROBDDs often
compact computationally efficient. due fact ROBDDs exploit
high-degree symmetry models Boolean formula.

3. Modeling Set CSPs Using ROBDDs
section discuss solve set constraint satisfaction problems using ROBDDs.
three parts thisthe modeling set domains ROBDDs, modeling
set constraints ROBDDs, use produce set solver.
116

fiSolving Set Constraint Satisfaction Problems using ROBDDs

z}
0123
7654
v
DD

0123
7654
v PP
PP

zz

1

0123
7654

PPP
P'
v2

DD

!


v3 @
"
~ @@@

+

1
7 <
H @
U -
2

0123
7654
0

(a)

0123
7654
x E
EE
1

0123
7654

0123
7654


{ 1 CCCC
{
C!
}{
s2 C

C
{
{ 2 CCCC
CC
{
{
C
C!
! }{
}{
s3 C
s3 C

{ CCC
{ CCC
{ 3
{
{
{
C
C
! }{
}{
! }{
s4 C
s4
s4 C
C
C
{
{
C
C

CC
CC
{
{
! }{
! }{

s5 C

CC
{ 5


C! }{
(

1
7
1
L
W U^ \` /0 pqt
0

0123
7654

EE
"
x

z 2
z

|z

x3 E
( EEE
E"
1
x
z 4AAA
:
z

L . q|z
0
1


0123
7654

0123
7654

(b)

0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

(c)

Figure 3: ROBDDs (a) {{1}, {1, 3}, {2, 3}}, (b) [{1, 3, 4, 5}, {1, 3, 4, 5, 6, . . . N }] (c)
{s {1, 2, 3, 4, 5} | |s| = 2}.

3.1 Modeling Set Domains using ROBDDs
Suppose universe U = {1, . . . , N }. assume set values subsets U.
Let x set variable, let domain V. Given size universe bounded, associate Boolean variable xi potential element
{1, . . . , N } x. Hence set variable x represented vector Boolean variables V (x) = hx1 , . . . , xN i.
Take set D(x). represent valuation variables
hx1 , . . . , xN defined = {x1 7 (1 A), . . . , xn 7 (n A)}. represent
valuation consequently set Boolean formula B(A)
valuation unique solution:
(
^
xi

B(A) =
yi yi =
xi otherwise
iU
Given represent element D(x) valuation, represent
D(x) Boolean formula B(D(x)) whose solutions correspond elements
D(x). is, B(D(x)) disjunction B(A) possible sets D(x):
_
B(D(x)) =
B(A) B(A) defined
AD(x)

solution (x) D(x) corresponds satisfying assignment Boolean
formula B(D(x)). overload notion domain equivalently
return set possible sets D(x) variable x, equivalent Boolean representation
B(D(x)).
Example 3.1. Let U = {1, 2, 3}. Suppose v set variable D(v) = {{1}, {1, 3}, {2, 3}}.
associate Boolean variables {v1 , v2 , v3 } v. represent D(v)
117

fiHawkins, Lagoon, & Stuckey

Boolean formula (v1 v2 v3 ) (v1 v2 v3 ) (v1 v2 v3 ). three solutions
formula correspond elements D(v). corresponding ROBDD B(D(v))
shown Figure 3(a).
representation useful since Boolean formul directly represented
reasonably compact ROBDDs. Given Boolean formula representing domain,
clearly construct corresponding ROBDD bottom-up fashion, practice
ever construct ROBDD domain implicitly constraint propagation.
show, ROBDDs permit surprisingly compact representation (many) subsets
P(U).
Since ROBDDs ordered, must specify variable ordering Boolean variables
use. arbitrarily order ROBDD variables single set variable x
follows: x1 x2 . . . xn . Assuming special relationship
elements universe, choice ordering ROBDD variables represent
particular set variable unimportant. However, relative ordering ROBDD variables
comprising different set variables drastic effect size ROBDDs representing
constraints, discussed Section 3.2.
Example 3.2. ROBDD representing 2N 5 sets interval [{1, 3, 4, 5}, {1, 3, 4, 5, 6, . . . N }]
shown Figure 3(b).
ROBDD representation flexible enough able represent compactly wide
variety domains, even might first seem difficult represent. example,
set subsets {1, 2, 3, 4, 5} cardinality 2 represented ROBDD
shown Figure 3(c).
convenience, set initial variable domains Dinit (x) = P(U),
corresponds constant 1 ROBDD. Restrictions initial bounds domain
instead expressed unary constraints.
3.2 Modeling Primitive Set Constraints Using ROBDDs
major benefit using ROBDDs model set constraint problems ROBDDs
used model constraints themselves, set domains. set constraint
c converted Boolean formula B(c) Boolean variables comprising set
variables vars(c), B(c) satisfied corresponding set variable
valuations satisfy c. usual, represent B(c) ROBDD.
Example 3.3. Let v w set variables universe U = {1, 2, 3}, let c
denote constraint v w. Assume Boolean variables associated v
w hv1 , v2 , v3 hw1 , w2 , w3 respectively. c represented Boolean
formula (v1 w1 ) (v2 w2 ) (v3 w3 ). formula turn represented
either ROBDDs shown Figure 4 (depending variable order).
Example 3.4 demonstrates order variables within ROBDDs
great effect size formula representations.
Example 3.4. Consider constraint v w described Example 3.3. Figure 4
shows effect two different variable orderings size resulting BDD.
118

fiSolving Set Constraint Satisfaction Problems using ROBDDs

0123
7654
v
z
z

z} 0123
0123
7654
7654
v
v
2

3

0123
7654

v
1 FFFF
F"
y|


3



#

$
)

;
/
7
?
G

1

0123
7654
v F
F
F"

0123
7654
0123
7654
v
v F
x
F
x
F"

|
x
0123
7654
0123
7654
0123
7654
0123
7654
w
w
w
w
1

-

0123
7654
v EE
E
%

+

2
3

3

1

1

1

0123
7654
0123
7654
w
w
}
+ 0123
7654
w
x

!

2

'

xx
% |xs x
1

2
3

(a) Order: v1 v2 v3 w1 w2 w3

0123
7654

EE

EE
"

5

1

0123
7654

E
E
Q Z ` E0 " v
2 EE
% EEE

"
+
!
w2 E
5
EEE
'
E
Q Z ` E0 " v
3 EE

EEE


"
4

w3

2 l n
;

b f h j R - }
0p
1

0123
7654

0123
7654

0123
7654

(b) Order: v1 w1 v2 w2 v3 w3

(Arcs 0 shown clarity)

Figure 4: Two ROBDDs v w

case, variable ordering v1 w1 v2 w2 gives much compact representation
constraint ordering v1 v2 w1 w2 . seen figure,
latter ordering size exponential n, whereas former size linear n.

variable set V = {v1 , . . . , vm } corresponding Boolean variables hv1,1 , v1,2 , . . . , v1,N i,
hv2,1 , v2,2 , . . . , v2,N i, . . . , hvm,1 , vm,2 , . . . , vm,N i, choose order Boolean variables
v1,1 vm,1 v1,2 vm,2 v1,N vm,N . ordering guarantees linear representation primitive set constraints except cardinality.
reason primitive set constraints except cardinality defined elementwise,
element v never constrains whether j w j
/ w 6= j. reason
interactions bits vi wj , 6= j. Placing bits
element adjacent order means interactions bits vi wi captured
small ROBDD, effectively separate ROBDD describing interactions
next elements bits. Table 1 contains list primitive set constraints,
corresponding Boolean formul sizes ROBDDs representing formul
point-wise ordering.
Cardinality constraints represented quadratic number ROBDD nodes
using simple recursive definition. define card (hvi1 , . . . , vin , l, u) Boolean
formula restricts number true bits vector hvi1 , . . . , vin l
119

fiHawkins, Lagoon, & Stuckey

c
Boolean expression B(c)
kv
vk
k 6 v
v
V
Vk
u 1iN,i6d ui
u=d
Vid
u=v
(u vi )
V1iN
uv
(u vi )
V1iN
u=vw
(u (vi wi ))
V1iN
(u (vi wi ))
u=vw
V1iN
(u (vi wi ))
u=vw
V1iN
(ui vi )
u=v
W1iN
u 6= v
1iN (ui vi )
|u| = k
card (V (u), k, k))
|u| k
card (V (u), k, N )
card (V (u), 0, k)
|u| k

size ROBDD
O(1)
O(1)
O(N )
O(N )
O(N )
O(N )
O(N )
O(N )
O(N )
O(N )
O(k(N k))
O(k(N k))
O(k(N k))

Table 1: Boolean representation set constraints size corresponding
ROBDD.

u inclusive.


1



0
card (hvi1 , . . . , vin , l, u) =

(vi1 card (hvi2 , . . . , vin , l, u))



(v card (hv , . . . , v , l 1, u 1)
i1
i2


l 0 n u
n < l u < 0
otherwise

clear structure card (hvi1 , . . . , vin , l, u) resulting ROBDD O(n2 )
size. general method characterising cardinality constraints presented
Section 5.5.
3.3 Basic Set Constraint Solver
show construct simple set domain propagator dom(c) constraint c.
vars(c) = {v1 , . . . , vn }, define function dom(c) mapping domains domains
follows:
(
V
V (vi ) B(c) ni=1 D(vi ) vi vars(c)
dom(c)(D)(vi ) =
D(vi )
otherwise
words, perform propagation take conjunction Boolean representations current domains variables vars(c) Boolean representation
constraint B(c) project result onto Boolean variables V (v ) representing
variable vi . Since B(c) D(vi ) ROBDDs, formula implemented
directly using ROBDD operations.
120

fiSolving Set Constraint Satisfaction Problems using ROBDDs

0123
7654

w
x 1FFFF
x
F"
|x
w2 WWWWW
w
x
WWWxWW 2FFFF

|x WWWWWF+ "
%
w
w3 F
FF
x 3
1
F
x
F" |x
= H
H
L 1
G"
W - p

0123
7654

0123
7654

0123
7654

0

0123
7654
v FF
F
1

0123
7654


















0123
7654

EE

FF
"













1



|y
0123
7654

EE

0123
7654 0123
7654




1

0123
7654


- D!
v2
B{ @@@@
}{
U Z .
1
0

0123
7654

EE
"
v2



2



0123
7654
v
' DD

0123
7654

EE
"
v3



0123
7654
w F
FF
1

~

0123
7654

FF
"
w2 F

FFF
x

F"
|x x
w3 F
w
$
x 3
| FFF
2
x
F" |x
~|
0c
1


0123
7654

0123
7654


|y
w3 w36

v


v

vv III 6
II 6
vvvv
II 6
I$
{vvv
p
n
0
1

(a)

(b)

(c)

(d)

Figure 5: ROBDDs used domain propagation c v w (a) D(w), (b) B(c)
D(v) D(w), (c) 0 (v), (d) 0 (w)

Example 3.5. Consider domain propagation constraint v w initial domain
D(v) = {{1}, {1, 3}, {2, 3}}, D(w) = {{2}, {1, 2}, {1, 3}} Examples 2.2 2.3.
conjoin ROBDD B(c) shown Figure 4(b) domain ROBDD D(v) shown
Figure 3(a) ROBDD D(w) shown Figure 5(a). result ROBDD
representing solutions formula v w v D(v) w D(w) shown Figure 5(b).
project resulting onto V (v) V (w), individually obtaining ROBDDs 0 (v) =
{{1}, {1, 3}} 0 (w) = {{1, 2}, {1, 3}} shown Figure 5(c) (d) respectively.
need verify correctness propagator:
Lemma 3.1. Let V collection set variables, let c set constraint
vars(c) = {v1 , . . . , vk } V. dom(c) domain propagator c.
Proof. need verify dom(c) satisfies identity Definition 1. Suppose domain
V. need V
check foreach v vars(c) {char ((v)) | solns(c)} =

u | u V (vi ) B(c) ni=1 D(vi ) , char (X) denotes characteristic vector X.
clearly true, since values solns(c) definition satisfying assignments
B(c), values definition satisfying assignments ni=1 D(vi ).
Hence equality holds, implying dom(c) domain propagator.
F set domain propagators, define complete propagation algorithm solv (F, D): simplicity use set constraints C rather
corresponding propagators.
solv(C, D)
121

fiHawkins, Lagoon, & Stuckey

Q := C
( c Q)
D0 := dom(c)(D)
(| vars(c)| = 1) C := C {c}
V := {v V | D(v) 6= 0 (v)}
Q := (Q {c0 C | vars(c0 ) V 6= }) {c}
:= D0
return
maintain queue Q constraints (re-)propagated, initially C. select
constraint c queue propagate, calculating new domain 0 . constraint
unary remove C, never considered again, since information captured
domain. determine variables V changed domain, add
queue constraints c0 C involving variables, exception current
constraint c.
combining algorithm modeling techniques described earlier,
shown construct simple ROBDD-based set domain propagator. Various improvements basic scheme discussed Section 4 Section 6.
reader may wonder whether section done anything map set
constraints Boolean constraints apply Boolean ROBDD solver them.
case. Crucially domain propagation original set variables,
Boolean variables make up. fact set bounds consistency approach (Puget,
1992; Gervet, 1997) considered simply mapping set constraints Boolean
constraints.

4. Effective Modeling Set Constraints Using ROBDDs
section demonstrate ROBDD-based modeling approach flexible,
allowing us produce highly efficient implementations many complex constraints.
4.1 Combining Constraints Removing Intermediate Variables
rarely possible express constraints real set problem directly primitive
set constraints variables original problem. Instead, would usually like
express complicated set constraints, decomposed multiple primitive
set constraints, often requiring introduction intermediate variables.
Example 4.1. Let c constraint |v w| k, requires v w
k elements common. constraint used modeling problem finding
Steiner systems (see Section 7.1). Since primitive set constraint, existing
set solvers would usually implicitly decompose two primitive set constraints
introduce intermediate variable u. representation constraint becomes
u u = v w |u| k.
case Example 4.1 decomposition affect strength resulting
propagator. prove fact, use two results presented Choi, Lee, Stuckey
122

fiSolving Set Constraint Satisfaction Problems using ROBDDs

(2003). Choi, Lee, Stuckey prove results case finite integer domain
solver, although proofs set domain case identical. 1
Lemma 4.1 (Choi et al., 2003). Let c1 c2 set constraints. solv ({dom(c1
c2 )}, D) v solv ({dom(c1 ), dom(c2 )}, D) domains D.
Lemma 4.2 (Choi et al., 2003). Let c1 c2 two set constraints sharing
one variable x V. solv ({dom(c1 ), dom(c2 )}, D) = solv ({dom(c1 c2 )}, D)
domains D.
Even strength propagator unaffected decomposition, splitting
propagator introduces new variable, thus slowing propagation process. cases
two set constraints share one variable Lemma 4.2 apply,
case also loss propagation strength.
ROBDD representation constraints allows us utilise complex constraints directly, thus avoiding problems associated splitting constraint.
directly construct ROBDD complex constraints forming conjunction
corresponding primitive constraints existentially quantifying away intermediate
variables.
Example 4.2. Consider constraint c |v w| k discussed Example 4.1.
build domain propagator dom(c) directly c constructing ROBDD
V (u) u = v w |u| k. case size resulting ROBDD O(kN ).
ROBDD |v w| 2, V (u) B(u = v w) B(|u| 2), U =
{1, 2, 3, 4, 5} shown Figure 6(a). ROBDD |u| 2 shown Figure 6(b)
comparison. Note ui node Figure 6(b) replaced vi wi (the formula
ui ) Figure 6(a).
4.2 Modeling Global Constraints
previous section demonstrates, possible join ROBDDs representing primitive set constraints single ROBDD representing conjunction constraints.
use join large numbers primitive constraints form global constraints,
many cases improve performance due stronger propagation.
one strengths ROBDD-based modeling approach trivial
construct global constraints simply using ROBDD operations primitive set constraints,
without laboriously writing code perform propagation global constraint.
approach powerful, feasible combinations primitive constraints.
shall see, global constraints might desire construct lead ROBDDs
exponentially large.
useful global constraint constraint partition(v1 , . . . , vn ), requires
sets v1 , v2 , . . . , vn form partition universe U = {1, . . . , N }. easily
1. observation Choi et al. Lemma 4.2 apply shared variable set variable
true performing set bounds propagation, set domain propagation.

123

fiHawkins, Lagoon, & Stuckey

0123
7654

v
1 EEEE
E"

w1 E
h

EEE
h h h h
E"
y| sh h
v2 EE
v

2 EEEE
E
E


E"
E"


h w2EE
h w2EE


h
h
EEE
EEE


h h
h h
y| sh h h
"
" y| sh h h
v3, EE
v3 EE
v3 EE


EEE
EEE
E


, EE"
"
"


w
, w'3E
h w3
h 3EE


h
h
EEE
h
h

E
,


h
h
EE

" y| sh h h
, ' E" v y| sh h h

v
'

4
4
E
E
EE
,

EEE

E"

, '
EE"


w4 E
, '
h w4


EEEE
, '
h h h h

" y| sh h
, '

v5 EE


,'


EEE


,'
"

w
',
h h 5DDD

,' h h h h
DD
"
|ysh h


0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

u
1 EEEE

E"
y|
u2 E
u2 E
EEE
EEE




E"
E
y|
" y|
u3, E
u
u3 E
EEE
3
EEE


E" y|
, E" y|
u

, u 4 EE
4
, EEE" y|

,
u5

, z z DDDD
|z
"

0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

0123
7654

1

0123
7654

0

0123
7654

0123
7654

1

0

(a)

(b)

Figure 6: ROBDDs (a) |v w| 2 v, w {1, 2, 3, 4, 5}, (b) |s| 2
{1, 2, 3, 4, 5}.

construct constraint primitive set constraints follows:
partition(v1 , . . . , vn ) =

n1
^

n
^

uij (uij = vi vj uij = )

i=1 j=i+1

w0 wn (w0 = (

n
^

wi = wi1 vi ) wn = U)

i=1

propagator dom(partition( )) stronger domain propagator
decomposition. example, consider constraint c partition(x, y, z) depicted
Figure 7, domain D(x) = D(y) = {{1}, {2}} D(z) = {{2}, {3}}.
Domain propagation using decomposition constraint alter D, domain
propagation using global constraint give dom(c)(D)(z) = {{3}}. Hence stronger
propagation gained global propagation using constraint.
Unfortunately global constraints modelled efficiently using approach.
particular, risk ROBDD representation global constraint could
extremely large, making infeasible construct use propagation.
example, consider constraint atmost(hv1 , . . . , vn , k) proposed Sadler
Gervet (2001), requires sets v1 , . . . , vn cardinality k
intersection pair sets 1 element size. constraint models
124

fiSolving Set Constraint Satisfaction Problems using ROBDDs

0123
7654

x
z 1 DDDD
z
D!
z}
y1
y1 QQQ
QQQ
w
Q
G&
QQ(
z1 DD
z
z 1
DDD
z
" |z
x2
DD
z
DD
z
z}
!
y2 QQQ
y2
w
QQQ

QQQ
G&
(z
z2 DD
2
z
DDD
z
" |z
x3
DDD
z
z
D!
z}
y3
y1 QQQ
QQQ
w
QQQ
G&
(z
z3 DD
3
z
DD
D! }z z

0123
7654
0123
7654

0123
7654
0123
7654

0123
7654
0123
7654

0123
7654

0123
7654

0123
7654

x
z 1 DDDD
z
D!
z}
y1
y1
DD
zz 9 3
z
! z} z
x2
(
DDD
z
z

z}
!
!
y2
y2
z
.
DD

zz
! z} z
)
x3$
z -
z} z
-y3 H
H

-H
H --
H -
H#

,1
0v

0123
7654 G
0123
7654 x w

0123
7654
0123
7654

0123
7654 G
0123
7654 x w

0123
7654

0123
7654 G
0123
7654 x w

0123
7654

0123
7654

0123
7654
0123
7654

1

partition(x, y, z)

lexlt(x, y)

(Arcs 0 omitted clarity)

Figure 7: ROBDDs constraints partition(x, y, z) lexlt(x, y), x, z
set variables taking values universe U = {1, 2, 3}.

Steiner triple systems Section 7.1. Bessiere, Hebrard, Hnich, Walsh (2004) proved
enforcing bounds consistency constraint NP-hard, follows enforcing
domain consistency constraint least NP-hard well. Theoretically still
construct ROBDD representing constraint primitive constraints follows:
n
^

i=1

|vi | = n

n1
^

n
^

uij (uij = vi vj |uij | 1)

i=1 j=i+1

Unfortunately, resulting ROBDD turns exponential size, making impractical use global propagator. surprising light NP-hardness
problem generalin fact would surprising resulting ROBDD
exponential size!
4.3 Avoiding Symmetry Ordering Constraints
important modeling constraint satisfaction problem minimize symmetries
model problem. model contains symmetrical solutions often greatly
enlarged search space, leading large amounts time spent searching sections
search tree identical symmetric rearrangement. therefore highly
desirable remove whatever symmetries exist problem.
125

fiHawkins, Lagoon, & Stuckey

One approach symmetry-breaking introduction additional ordering constraints variables problem. convenient ordering use sets
lexicographic order characteristic bit vectors sets. words, v w
set variables, v < w lexicographic ordering list bits V (v)
lexicographically smaller V (w). model lexicographic ordering constraint
lexlt(v, w, 1), defined recursively following manner:
(
0
n > N
lexlt(v, w, n) =
(vn wn ) ((vn wn ) lexlt(v, w, n + 1) otherwise
example ROBDD depicted Figure 7.
shall make use lexicographic ordering constraint extensively experiments
Section 7.

5. Modeling Integers, Multisets, Weighted Sum Constraints
section show model integer variables integer constraints using ROBDDs. general representations large, limits usefulness
ROBDDs basis general purpose finite-domain constraint solver. Despite this,
ability represent integers extremely useful component set solver.
propose two major uses integer representation.
Firstly, use integer representation model values weighted sum
elements set. Constraints weighted sum elements set
shown useful practical applications (Mailharro, 1998).
Secondly, model finite multisets using ROBDDs replacing individual
ROBDD variables set representation bundles ROBDD variables, bundle corresponding binary integer. Multiset operations constructed
composing integer operations variable bundles.
addition, integer representation described could used interface ROBDD-based set solver conventional integer finite-domain
solver. interface could easily implemented using channeling constraints
ROBDD integer finite-domain versions variable.
5.1 Representing Integer Values using ROBDDs
order model integers integer operations must choose appropriate representation terms Boolean formul. general free use encoding integer
binary sequence, unary, unsigned binary twos-complement encodings,
simplicity choose represent integers unsigned binary form.
represent arbitrary integer expression e list Boolean formul.
formula list corresponds single bit unsigned binary value expression.
denote list hen1 , en2 , . . . , e1 , e0 i, ei Boolean formula,
order significant bit least significant bit. interpret formula
1 bit formula logically true, 0 bit otherwise; simplicity
call formul bits expression. also use expression e
list constituent bits interchangeably. usual, represent Boolean formul
126

fiSolving Set Constraint Satisfaction Problems using ROBDDs

ROBDDs. shall see, notation flexible enough represent arbitrary integer
expressions.
Example 5.1. Consider integer constant k = 25, 11001 unsigned binary.
represent k list h1, 1, 0, 0, 1i.
order represent integer variable x, associate x fixed set Boolean
variables {xk1 , . . . , x0 }. value x taken value unsigned binary
integer hxk1 , . . . , x0 i. varying value xi variables, value x range
0 2k 1 inclusive. always ordering Boolean variables significant
effect sizes ROBDD representations formul. x = hx k1 , . . . , x0 i, =
hyk1 , . . . , y0 i, z = hzk1 , . . . , z0 i, choose order corresponding ROBDD
variables interleaved most-significant-bit-first order, i.e. xk1 yk1 zk1 xk2
x 0 y0 z0 .
Since permit arbitrary Boolean formul bits expression, also
model arbitrary integer expressions. example, suppose x integer variables
bits hx2 , x1 , x0 hy2 , y1 , y0 respectively. Then, example, represent expression xy (where denotes bitwise operator) list hx 2 y2 , x1 y1 , x0 y0 i.
limited logical operations, shall see next section.
5.2 Representing Integer Operations using ROBDDs
also use ROBDDs model arithmetic operations addition, analogy
design corresponding logic circuits. purpose set multiset
solvers, require implementations operations addition, left shift, minimum,
maximum, multiplication constant, multiplication single variable bit.
require general implementation multiplication using ROBDDs.
convenient assume integer expressions number bits.
may assume without loss generality since freely pad left shorter
pair expressions 0 bits.
model addition, simulate operation full binary adder. Suppose x
integer expressions, bit representations hxl1 , . . . , x0 hyl1 , . . . , y0 i.
use ROBDDs compute output bits plus(x, y) operation x + follows (here
ci denotes carry bit si denotes sum bit):
c1 = 0
si = xi yi ci1

0i<l

ci = (ci1 xi yi ) (ci1 (xi yi ))

0i<l

plus(x, y) = hcl1 , sl1 , . . . , s1 , s0
Note avoid overflow extending size result one bit.
Example 5.2. Suppose x integer variable, bits hx1 , x0 i. represent
expression x+3 bits h(x0 x1 ) x0 ), x1 1 x0 , x0 1i = hx0 x1 , x0 x1 , x0 i.
left shift operation trivial implement. x integer expression represented
hxl1 , . . . , x0 k non-negative integer, represent left shift x
127

fiHawkins, Lagoon, & Stuckey

e3

0123
7654
x
7654
0123
x
}
1





0

0



1

(x0 x1 )

0123
7654
x
1





e2

e1

0123
7654
x G



& zzz
|zz

0

0

1

ww

0123
7654

x1

0123
7654
x RRR
R


w
G'

0

0

(x0 x1 )

z

e0

0123
7654





l x0 G
RlRlRl
l
l
RR( w w
lv

}

0123
7654
x
0



0

1

1

(x0 x1 )

(x0 )

Figure 8: ROBDDs representing bits he3 , e2 , e1 , e0 expression e =
mul (hx1 , x0 , 3), together simplified Boolean expressions ei .

k bits shl (x, k) following formula:
shl (hxl1 , . . . , x0 , k) = hxl1 , . . . , x0 , 0, . . . , 0i
| {z }
k bits

implement operation multiplication constant using plus shl
operators. x integer expression bits hxl1 , . . . , x0 k non-negative
integer, x k corresponds mul (x, k) following formula:


k = 0
hi
k
(1)
mul (x, k) = mul (shl (x, 1), 2 )
k even k > 0


k
plus(x, mul (shl (x, 1), b 2 c)) k odd k > 0
Example 5.3. Let x = hx1 , x0 i, consider expression e = mul (x, 3). applying
Equation (1), obtain e = hx1 (x1 x0 ), x1 (x0 x1 ), x0 x1 , x0 simplified hx0 x1 , x0 x1 , x0 x1 , x0 i. corresponding ROBDD representations
shown Figure 8.
5.3 Integer Constraints using ROBDDs
also express constraints integer expressions using ROBDDs. particular,
show implement equality inequality constraints. usual, assume two
expressions x equal lengths l bits; not, pad shorter expression
0 bits right.
Equality two integer expressions x easy represent ROBDDthe
corresponding bits x must equal. Hence represent equality constraint
x = ROBDD B(x = y):
B(x = y) =

l1
^

i=0

128

xi

fiSolving Set Constraint Satisfaction Problems using ROBDDs

Note identical implementation equality two set expressions
addition zero-padding.
turns already implementation inequality constraints, albeit
different guise. Inequalities binary integers correspond inequalities
lexicographic ordering bit representations, implement, example,
strict less-than constraint x < two integer variables x using lexlt operation
Section 4.3.
B(x < y) = lexlt(x, y)
use construct reverse inequality swapping order
operands, non-strict inequality negating formula (reversed necessary).
implementation inequalities also leads us implementation minimum
maximum expressions. Consider problem finding smaller two integer
expressions x y. x bit vectors hxl1 , . . . , x0 hyl1 , . . . , y0 respectively,
recursively define min(x, y) follows:
= R l = 0
Li = Li+1 (Li+1 Ri+1 xi yi )

1i<l

Ri = Ri+1 (Li+1 Ri+1 xi yi )

1i<l

mi = (Li+1 xi ) (Ri+1 yi ) (Li+1 Ri+1 xi yi )

0i<l

min(x, y) = hml1 , . . . , m0
equation above, Li Ri values flag bits state whether higher
order bits already allowed us conclude one two values minimum.
maximum operation defined similarly.
5.4 Modeling Multisets Multiset Constraints
Various authors suggested multisets valuable addition modeling
abilities set constraint solver (Kiziltan & Walsh, 2002). section briefly show
multisets multiset constraints modelled using ROBDDs making use
integer building blocks described above.
multiset unordered list elements {{m0 , . . . , mn }} drawn universe U,
(unlike set) repetition elements permitted. set operations parallel
operations multisets, although multiset operations strict generalisations
set operations. Let occ(i, m) denote number occurrences element
multiset m. Suppose n multisets, k integer constant. define
following multiset relations operations actions number occurrences
element universe:
Equality: = n iff occ(i, m) = occ(i, n) U.
Subset: n iff occ(i, m) occ(i, n) U.
Union: occ(i, n) = occ(i, m) + occ(i, n) U.
Intersection: occ(i, n) = min{occ(i, m), occ(i, n)} U.
129

fiHawkins, Lagoon, & Stuckey

Difference: occ(i, \ n) = max{0, occ(i, m) occ(i, n)} U.
Cardinality: |m| =

P

iU

occ(i, m) U.

represent set variable x associated vector Boolean variables hx 1 , . . . , xn
bits characteristic vector valuation x. case multiset,
characteristic vector multiset vector integers, need associate
integer value mi potential element multiset m. model
integer value using approach described above.
multiset variable, associate bundle ROBDD variables every
U, contents comprise bits corresponding integer expression .
order represent multisets finite number bits, assume number
occurrences element multiset variable bounded reasonably small
, allowing us use k = dlog2 e Boolean variables per bundle. write
list bundles hm1 , . . . , mn i, mi turn list bits hmi,k1 , . . . , mi,0 i.
Given representation multiset variables, turn attention implementation multiset expressions constraints. Multiset expressions implemented
obvious way sequences integer expressions. example, suppose x multiset variables associated bundles hx1 , . . . , xN hy1 , . . . , yN respectively.
bundles corresponding expression xy hplus(x1 , y1 ), plus(x2 , y2 ), . . . , plus(xN , yN )i.
Similarly, bundles corresponding expression xy hmin(x1 , y1 ), . . . , min(xN , yN )i,
expressions. show implement cardinality weighted sum
constraints Section 5.5.
Multiset constraints also trivial implementfor example, two multisets x
equal constituent bundles equal, multiset equality
modelled conjunction integer equalities. Relations subset correspond
conjunction integer inequalities constituent bundles, implementation
described Section 5.3.
point left ordering ROBDD variables make
multiset variable unspecified. Unfortunately, unlike set case, single optimal
variable ordering guaranteed produce compact descriptions primitive
multiset constraints. example, subset constraint compactly represented
bundle-major bit ordering bit-major ordering (see Figure 9), since subset
constraint consists series integer inequalities corresponding bundles
two multiset variables, bundle-major ordering gives interleaving variables
above. However, opposite true cardinality constraint, consists sum
values bundles within variable, variables interleaved
bit-major ordering bundle-major ordering. two orderings mutually
exclusive, hence conclude general need optimal variable
ordering modeling multiset constraints.
5.5 Weighted Sum Cardinality Constraints
many practical applications interested placing constraints weighted sum
elements set variable. example, Balanced Academic Curriculum problem
(problem prob030 CSPLib), every course associated weight corresponding
130

fiSolving Set Constraint Satisfaction Problems using ROBDDs

Bundle 1

Bundle 2

Bundle 3

Bundle 1

Variable 1

Bit 1

Bit 2

Bit 3

Bit 1

Bit 2

Bit 3

Bit 1

Bit 2

Bit 3

Variable 2

Bit 1

Bit 2

Bit 3

Bit 1

Bit 2

Bit 3

Bit 1

Bit 2

Bit 3

Bit major

Bundle 2

Bundle 3

Variable 1

Bit 1

Bit 2

Bit 3

Bit 1

Bit 2

Bit 3

Bit 1

Bit 2

Bit 3

Variable 2

Bit 1

Bit 2

Bit 3

Bit 1

Bit 2

Bit 3

Bit 1

Bit 2

Bit 3

Bundle major

Figure 9: Bit bundle major orderings two multiset variables

academic load, limit total academic load undertaken
given time period. set model problem proposed Hnich, Kiziltan,
Walsh (2002), limits academic load period made use
weighted sum constraint. addition cardinality constraint already
described special case weighted sum constraint weights set
1. therefore seems essential implement constraint ROBDD framework.
Suppose x set multiset expression bit bundles hx1 , . . . , xn i. (If x set
expression, bit bundle size 1). use integer operations described
earlier produce integer expression wsum(x, w) corresponding weighted sum
P
n
i=1 xi wi , w vector integers hw1 , . . . , wn i:
0 = hi

= plus(i1 , mul (xi , wi ))
wsum(x, w) = n
Expressions involving cardinality set multiset variables expressed
special case weighted sum expression wi = 1 1 n.
already seen one method constructing ROBDDs constraints |x| = k, |x| k
|x| k set variable case; method general, since permits us directly
model constraints |x| + 5 |y| + |z|. great practical valuefor example
needed implement Hamming Code experiment Section 7.3. cases already
discussed Section 3.2 ROBDDs produced two methods identical since
ROBDDs canonical representation.

6. Efficient Constraint Propagation Using ROBDDs
section discuss improvements variants basic domain propagation
scheme presented Section 3.3.
implementation domain propagator dom(c) substantial effect
performance solver. definition dom(c) given purest mathematical
form simplicity. Section 6.1 discusses several implementation details lead
greatly improved efficiency performing domain propagation.
general, inferences obtained using domain propagator may
costly practical, circumstances may desirable enforce
131

fiHawkins, Lagoon, & Stuckey

weaker form consistency. Weaker consistency may substantially cheaper enforce,
permitting time spent searching solution space.
always compromise propagation time search time,
certain problems may productive spend time searching performing
accurate propagation, problems converse may true. ROBDD
based representation allows taken extremesin theory possible form
single ROBDD representing solutions constraint satisfaction problem forming
ROBDD conjunction constraints. solution could trivially read
ROBDD satisfying assignment. Usually ROBDD would prohibitively
expensive construct time space, forcing us maintain less strict consistency
levels.
Accordingly, show implement weaker levels consistency using ROBDD
representation combining domain propagator approximation operation.
approximation operation simplifies ROBDD representing domain bounds closure
suitable definition bounds. ROBDD representing bounds domain
almost always smaller domain itself, leading better performance future
operations domain. shall see, lead substantial performance
improvements overall solver.
6.1 Domain Propagation
Let c constraint, vars(c) = {v1 , . . . , vn }. Section 3.3 gave following definition
domain propagator:
dom(c)(D)(vi ) = V (vi ) (B(c)

n
^

D(vj ))

(2)

j=1

Since B(c) D(vj ) ROBDDs, directly implement Equation (2) using
ROBDD operations. practice efficient perform existential quantification
early possible limit size intermediate ROBDDs. make use
efficient combined conjunction existential quantification operation, well call
and-abstraction, provided ROBDD packages.
leads following implementation:
0i = B(c)
(
V (vj ) (D(vj ) j1
)

ji =
i1


1 i, j n, 6= j (and-abstraction)
i=j

(3)

dom(c)(D)(vi ) = D(vi ) ni
Q
worst case complexity still O(|B(c)| nj=1 |D(vj )|) vj . Clearly
computation shared propagation c different variables since ji = ji0
j < j < i0 . Even improvement algorithm Equation (3) uses
O(n2 ) and-abstraction operations (which experimentally shown occupy
majority execution time set solver).
domain propagator implementation Equation (3) significantly improved
observing case n-variable constraint (n 3) many similar sub-formul
132

fiSolving Set Constraint Satisfaction Problems using ROBDDs

dom divide conquer(D, , V ):
(|V | = 0) return
else (V = {vi })
D(vi ) := D(vi )
return
else
{v1 , . . . , vk } := V
h := b k2 c
R := V (v1 ) D(v1 ) V (v2 ) D(v2 ) V (vh ) D(vh )
L := V (vh+1 ) D(vh+1 ) V (vh+2 ) D(vh+2 ) V (vk ) D(vk )
D1 := dom divide conquer(D, L, {v1 , . . . , vh })
D2 := dom divide conquer(D1 , R, {vh+1 , . . . , vk })
return D2
Figure 10: divide conquer algorithm domain propagation

computed. Due need perform existential quantification operations early
possible, complete freedom rearrange order evaluation see
fit. However, simple divide-and-conquer strategy calculating dom(c)(D)(v ) allows us
perform domain propagation using O(n log n) and-abstraction operations. define
dom(c)(D) = dom divide conquer(D, B(c), vars(c)), dom divide conquer defined
Figure 10.
6.2 Set Bounds Propagation
domain propagation may prohibitively expensive enforce problems,
useful investigate less strict notions consistency. cases, speed propagation simplifying domains approximation. Since set bounds
subset partial ordering relation one commonly used approximations set
domain, seems natural implement set bounds propagator ROBDD framework.
relatively minor changes needed domain propagator turn set
bounds propagator.
Given ROBDD representation set domain, easily identify corresponding set bounds. ROBDD-based set domain representation, set bounds
domain correspond fixed variables ROBDD representing domain. say
ROBDD variable v fixed either nodes n(v, t, e) constant 0 node,
nodes n(v, t, e) e constant 0 node, node appears every path
root diagram 1 node.
nodes identified single pass domain ROBDD, time proportional size. ROBDD, write JK denote ROBDD representing
conjunction fixed variables . represents set sets S, JK represents
conv (S). ROBDD = JK stick ROBDD definition.
133

fiHawkins, Lagoon, & Stuckey

Example 6.1. Let ROBDD depicted Figure 1(c). JK ROBDD
Figure 1(a).
Using operation convert domain propagator set bounds propagator
discarding non-fixed variables domain ROBDDs propagation
step. Suppose D(v) stick ROBDD v V. c constraint,
vars(c) = {v1 , . . . , vn }, define set bounds propagator sb(c) thus:
n
z
r
^
D(vj ))
sb(c)(D)(vi ) = V (vi )(B(c)

(4)

j=1

Despite relatively minor differences set bounds propagator
domain propagator, set bounds propagator usually significantly faster domain propagator two reasons. Firstly, domains D(v) sticks,
ROBDD operations cheap, compared operations possibly large ROBDDs
representing arbitrary domains. entire propagator implemented O(|B(c)|)
complexity, since ROBDDs sticks. Secondly, use updated set
bounds simplify propagator ROBDD B(c). Since domains monotonic decreasing
size, fixed variables remain fixed backtracking, project
B(c), thus reducing size propagator ROBDD future propagation steps.
leads us following implementation propagator:
0 = B(c)
j = V AR(D(vj )) D(vj ) j1 1 j n
V (v ) Jn K
sb(c)(D)(vi ) = D(vi )
1in


(5)

propagation step replace representation constraint B(c) n
since fixed variables longer new impact.
Example 6.2. Consider bounds propagation constraint c v w N = 3.
ROBDD representation B(c) given Figure 4. Assume domains v w
respectively [{1}, {1, 2, 3}], represented formula v1 , [, {1, 2}], represented
formula w3 . ROBDD n v1 w3 B(c) v1 w3 shown Figure 11(a).
Jn K = w1 v3 . project fixed variables v1 , w1 , v3 , w3 B(c)
get new simplified form constraint v2 w2 shown Figure 11(b).
set bounds solver retains modeling advantages domain solver,
including ability easily conjoin existentially quantify constraints, remove intermediate variables form global constraints. cases permits substantial
performance improvement traditional set bounds solvers.
Experimentally appears direct implementation Equation (4), written
use divide conquer approach calculate and-abstractions, faster
implementation Equation (5), even divide conquer approach used calculating
existential quantification. former approach calculates fewer intermediate results,
leads faster propagator overall. Experimental results bounds propagator
given Section 7.
134

fiSolving Set Constraint Satisfaction Problems using ROBDDs

0123
7654

) EE
1

0123
7654

0123
7654
v EE
( E
2

E
+ E"
. v2 EE
1 % EEE
"
5 +
9 5 w(2EEE
E
DE Q Z. E"
`
L Pl Cl0 v3 @@
l V @@
XU [Z -.
vl l
1
0

0123
7654

0123
7654

(a)

0123
7654

EE
"
w
z 2BBB
C
|z z U [B.
0
1
.

(b)

Figure 11: Set bounds propagation constraint v w showing (a) resulting ROBDD
conjunction domains, (b) simplified constraint ROBDD
removing fixed variables.

6.3 Split Domain Propagation
combine set bounds propagator domain propagator produce
space efficient split domain propagator. separating domain representation fixed
unfixed parts, reduce total size representation, also hopefully speeding
propagation.
One unfortunate characteristics ROBDDs size ROBDD
representing domain highly dependent variable ordering. Consider ROBDD
representing set domain contains several fixed variables. variables
appear beginning variable ordering, ROBDD representing
domain effect contain several copies sticks representing fixed variables.
example, Figure 1(c) contains several copies stick Figure 1(a). Since many
ROBDD operations take time proportional product number ROBDD
nodes arguments, overly large representation performance cost.
solve problem two wayseither reordering ROBDD variables splitting
domain representation.
Variable reordering capable eliminating redundancy representation
individual domain, general cannot eliminate redundancy across set domains.
reordering ROBDD variables, reduce size domain placing fixed
variables beginning variable order, thus removing unnecessary duplication
domain. Unfortunately, variable order global property ROBDDs
existence, whereas fixed variables domain local property specific particular
domain, may variable ordering optimal domains
problem.
context applying ROBDDs groundness analysis logic programs, Bagnara (1996) demonstrated performance ROBDD-based program analyzer
could improved splitting ROBDDs fixed non-fixed parts.
apply technique here.
135

fiHawkins, Lagoon, & Stuckey

split ROBDD representing domain D(v) pair ROBDDs (LU , R). LU
stick ROBDD representing lower upper set bounds D(v), R remainder
ROBDD representing information unfixed part domain. Logically =
LU R. write LU (D(v)) R(D(v)) denote LU R parts D(v)
respectively.
following results provide upper bound size split domain representation:
Lemma 6.1. Let G ROBDD, let v fixed variable G. |v G| < |G|.
Proof. Since v fixed variable, either every node n(v, t, f ) G constant 0
node, every node f constant 0 node. Since node n(v, t, f ) corresponds
proposition (v t) (v f ), clear v n(v, t, f ) corresponds simply f ,
moreover since v fixed node one f zero. Hence existential quantification
fixed variable v simply removes nodes labelled v D. Since least one
node, result follows.
Lemma 6.2. Let G ROBDD, LU = JGK, R = VAR(LU ) G. G LU R
|LU | + |R| |G|.
Proof. result G LU R straightforward, prove result sizes.
Suppose VAR(LU ) = {v1 , . . . , vn } set fixed variables G. Then, since
|v1 G| < |G|, 1 + |v1 G| |G|. repeating operation vi , obtain n +
|VAR(LU ) G| |G|. LU stick, trivially |LU | = n, R = VAR(LU ) G
definition required inequality.
Note |D| O(|LU | |R|). example, considering ROBDDs Figure 1
LU shown (a), R (b), = LU R (c), |LU | = 5
|R| = 9 |D| = 9 + 4 5 = 29.
show construct propagator split domains. Firstly, eliminate
fixed variables (as bounds propagator) apply domain propagation
remainder domains R. propagator produces new pair (LU , R) consisting new
fixed variables new remainder. process shown below:
0 = B(c)
j = VAR(LU (D(vj ))) (LU (D(vj )) j1 )
= V (vi ) (n

n
^

R(D(vj )))

(6)

j=1

= LU (D(vi )) Ji K

dom(c)(D)(vi ) = (i , VAR(i ) )

efficiency components calculated using divide-and-conquer approach described domain propagator.
split domain representation three main advantages. Proposition 6.2 tells us
split domain representation larger original domain representation. However, often split representation substantially smaller, lead improvements
136

fiSolving Set Constraint Satisfaction Problems using ROBDDs

{1,2,3,4}
Upper bound
{1,2,3} {1,2,4} {1,3,4} {2,3,4}

{1,2}

{1,3}

{1,4}

{2,3}

{2,4}

{3,4}
Lower bound

{1}

{2}

{3}

{4}

{}

Figure 12: set interval [, {1, 2, 3, 4}] upper lower cardinality bounds u = 3
l = 2 respectively

propagation performance. split solver also use propagator simplification
technique bounds solver abstracting fixed variables propagator ROBDDs. Finally using split solver mix usage domain bounds
propagators problem.
Experimental results split domain propagator given Section 7.
6.4 Cardinality Bounds Propagation
Given able model set bounds propagator using ROBDDs, also appropriate consider might model levels consistency set constraint problems.
One level consistency commonly used (Azevedo, 2002; Muller, 2001)
combined set bounds cardinality consistency, upper lower bounds
cardinality domain maintained addition bounds subset partial ordering. hybrid approach allows accurate representation domains,
particularly constrained cardinality, common set problems.
Example 6.3. Figure 12 depicts set interval [, {1, 2, 3, 4}], together lower
upper cardinality bounds 2 3 respectively. general interval consists large
number sets, making crude approximation set domain. Cardinality bounds
permit fine grained representation effectively allowing us select subset
rows lattice diagram.
able implement set bounds propagator using domain propagator together function extracts set bounds domain,
create combined set bounds set cardinality propagator. extend split
domain solver simplifying remainder component split domain ROBDD
representing cardinality bounds.
137

fiHawkins, Lagoon, & Stuckey

bdd count cardinality(D, V ):
(D = 0) return h,
else (D = 1)
(|V | = 0) return h0, 0i
else
hv1 , v2 , . . . , vn := V
return h0, ni
else
(|V | = 0) error
n(v, t, e) :=
hv1 , v2 , . . . , vn := V
(v1 v) error
else (v = v1 )
hlt , ut := bdd count cardinality(t, hv2 , . . . , vn i)
hle , ue := bdd count cardinality(e, hv2 , . . . , vn i)
return hmin(lt + 1, le ), max(ut + 1, ue )i
else
hl, ui := bdd count cardinality(D, hv2 , . . . , vn i)
return hl, u + 1i
bdd card bounds(D, V ):
hl, ui := bdd count cardinality(D, V )
(l = u = ) return 0
return card (V, l, u)
Figure 13: algorithm determine cardinality bounds domain set variable
represented ROBDD D, V vector bits Boolean
representation set variable

before, need method extracting ROBDD representing cardinality
bounds arbitrary domain ROBDD. perform operation two stages. Firstly
define function bdd count cardinality takes ROBDD representing set domain
returns upper lower bounds cardinality. represent bounds
ROBDD form constructing new cardinality constraint ROBDD described
Section 3.2.
implementation bdd count cardinality shown Figure 13. function
implemented run O(|D||V |) time dynamic programming/caching used save
results intermediate recursive calls. practice since V highly interrelated, O(|D|). implementation utilise global cache mechanism
ROBDD library, also permits caching partial results multiple calls
bdd count cardinality.
138

fiSolving Set Constraint Satisfaction Problems using ROBDDs

0123
7654
x E
EE
1



%

0123
7654
x E
EE

EE
"

,

2

h0, 2i

1

h0, 2i

0123
7654

EE
"
4
x3

> z z AAA

G % z|


zt



JJJ
J$

h0, 1i

h0, 1i

zt



0
h0, 0i

(a)

JJJ
J$
zt

h0, 0i N



NNN
N&

h,

(b)

Figure 14: Cardinality propagation example showing (a) resulting ROBDD projected onto
x, (b) calculation cardinality bounds

use function construct function bdd card bounds takes
ROBDD list Boolean variables V returns new ROBDD representing
bounds cardinality solutions D. implementation bdd card bounds
shown Figure 13.
algorithm split set bounds set cardinality propagator constraint c
given sbc(c) following equation:
0 = B(c)
j = VAR(LU (D(vj ))) (LU (D(vj )) j1 )
= V (vi ) (n

n
^

R(D(vj )))

(7)

j=1

= LU (D(vi )) Ji K

sbc(c)(D)(vi ) = (i , bdd card bounds(VAR(i ) , V (vi ) \ VAR(i )))
Note keep cardinality bounds remaining non-fixed Boolean
variables set variable v rather original variables V (v), since
need consider fixed variables again, leads slightly smaller cardinality
ROBDD. usual Equation 7 implemented using divide-and-conquer approach
efficiency. Experimental results propagator shown Section 7.
Example 6.4. illustrate set bounds cardinality propagation constraint
c lexlt(x, y) whose ROBDD B(c) shown Figure 7(b). Assume original domains
x universal, D(x) = D(y) = [, {1, 2, 3}], represented ROBDD 1.
V (x) B(c) shown Figure 14(a), x = Jx K = 1. tree
ROBDD x =
calculations bdd card bounds(x , hx1 , x2 , x3 i) shown Figure 14(b). Overall
cardinality x determined range [0, 2].

139

fiHawkins, Lagoon, & Stuckey

6.5 Lexicographic Bounds Propagation
alternative form set consistency proposed Sadler Gervet (2004) maintain
bounds lexicographic ordering addition set bounds. lexicographic ordering
total ordering sets embeds subset partial ordering. Bounds
lexicographic ordering alone sufficient express effects many constraints (in
particular inclusion single element), Sadler Gervet constructed hybrid solver
combines lexicographic bounds traditional set bounds. demonstrated
set solver based upon lexicographic bounds consistency techniques produced stronger
propagation traditional set bounds solver, although came substantial cost
propagation performance. However, given use ROBDD representation
leads performance improvement case set bounds propagation, worth
investigating performance ROBDD-based lexicographic bounds propagator.
lexicographic bounds domain compactly represented ROBDD.
Like set bounds, ROBDD representing upper lower lexicographic bounds
domain ROBDD size O(N ), combination. ROBDDs
compact hopefully leads fast propagation. Moreover, given ROBDD domain,
easy extract lexicographic bounds domain single pass. process
analogous construction bounds cardinality propagator, use split
domain propagator combined function determines lexicographic bounds
domain construct highly efficient lexicographic bounds solver.
define two functions bdd lex lower bound bdd lex upper bound. functions,
given ROBDD representing domain variable V together list Boolean
variables B corresponding bits V , return lower upper lexicographic bounds
(respectively) D. bdd lex lower bound implemented shown Figure 15 (the implementation bdd lex upper bound similar).
define:
bdd lex bounds(D, B) = bdd lex lower bound(D, B) bdd lex upper bound(D, B)
split set lexicographic bounds propagator implemented exactly
Equation (7), using bdd lex bounds place bdd card bounds.
Example 6.5. Consider lexicographic bounds propagation constraint c |s| = 2
{1, 2, 3, 4, 5}. ROBDD B(c) shown Figure 3(b) initial domain
D(s) = [, {1, 2, 3, 4, 5}]. = B(c) = 1 call bdd lex bounds calculates lower bounds lexicographic ROBDD shown Figure 16(a), upper bounds
lexicographic ROBDD shown Figure 16(b), final answer conjunction shown
Figure 16(c). Note lost information relative original cardinality
ROBDD.
observed Section 5.3, lexicographic ordering set variables actually corresponds numeric ordering integer variables, pure lexicographic bounds propagator
would also coincidentally integer bounds propagator.
Experimental results lexicographic bounds propagator given Section 7.
140

fiSolving Set Constraint Satisfaction Problems using ROBDDs

bdd lex lower bound(D, B):
(|B| = 0 = 1) return 1
(D = 0) error
n(v, t, e) :=
hb1 , . . . , bn := B
(b1 v) error
else (b1 = v e = 0)
return b1 bdd lex lower bound(t, hb2 , . . . , bn i)
else
(b1 = v) r := bdd lex lower bound(e, hb2 , . . . , bn i)
else r := bdd lex lower bound(D, hb2 , . . . , bn i)
return b1 (b1 r)
Figure 15: algorithm extract lower lexicographic bounds domain set
variable represented ROBDD D, B vector (non-fixed) bits
Boolean representation set variable

0123
7654


}{ {

0123
7654


{

{ 2
{
}{

{ 3++
++
}{ {
s4 C
++
++
CCCC
!

s5 C +++
CC +


C! |
(

1
7
1
L
W U^ \` /0
0

0123
7654

0123
7654

0123
7654

(a)

0123
7654
C
CC

1

1

0123
7654

0123
7654

0123
7654

0123
7654


{ 1 CCCC
C!
s2
s2 C
{
CCCC
{
!
}{




{ 3
{ 3++
{
{
+

}{
}{
++
s4 C
s4

++
C
{
C
{

CC
+
!
}{

s5 C +++ s5
CC +
{


C! }{
(

1
7
1
L
W U^ \` /0 qtp
0

CC

!
s2 C

CCCC
!


s3

{

{

}{
s4


{
{
!
}{
$ ~5
~~

0123
7654

0123
7654

1

0 p qt
(b)

0123
7654

0123
7654

0123
7654

}{ {

0123
7654

0123
7654

0123
7654

0123
7654

(c)

Figure 16: Calculating lexicographic (a) lower (b) upper bounds (c) conjunction.

7. Experiments
implemented set solver using ideas described paper. implementation written primarily Mercury (Somogyi, Henderson, & Conway, 1996), using
interface C language ROBDD library CUDD platform ROBDD manipulations (Somenzi, 2004). ROBDD library effectively treated black box.
141

fiHawkins, Lagoon, & Stuckey

used solver implement series standard constraint benchmarks described
below. Many problems CSPLib library constraint satisfaction problems
(Gent, Walsh, & Selman, 2004). purposes comparison, also implemented
benchmarks using ic sets library ECLi PSe v5.62 finite sets library
Mozart v1.3.0. conducted experiments cluster 8 identical 2.8GHz
Pentium 4 machines, 1 Gb RAM running Debian GNU/Linux 3.1.
three solvers limited 1 Gb memory minimise swapping. experiments
repeated three times, lowest time three runs taken result.
7.1 Steiner Systems
commonly used benchmark set constraint solvers calculation small Steiner
systems. Steiner system S(t, k, N ) set X cardinality N collection C
subsets X cardinality k (called blocks), elements X exactly
one block. Steiner systems extensively studied combinatorial mathematics.
= 2 k = 3, so-called Steiner triple systems, often used
benchmarks (Gervet,
1997; Azevedo, 2002; Muller, 2001). Steiner system must
exactly = Nt / kt blocks (Theorem 19.2 van Lint & Wilson, 2001).
natural model Steiner system using set variables s1 , . . . , sm , set
variable corresponds single block, subject following constraints:

^

(|si | = k)

(8)

(uij uij = si sj |uij | (t 1)) (si < sj )

(9)

i=1



m1
^


^

i=1 j=i+1

lexicographic ordering constraint si < sj added remove symmetries
problem formed permuting blocks.
ki
/ ti
necessary condition existence Steiner system Nti
integer {0, 1, . . . , 1} (van Lint & Wilson, 2001); say set parameters
(t, k, N ) admissible satisfies condition. order choose test cases, ran
solver every admissible set (t, k, N ) values N < 32. Results shown
every test case least one solver able solve within time limit 10 minutes.
denotes abnormal termination due exceeding arbitrary limit maximum
number ROBDD variables imposed CUDD package, denotes failure
complete testcase within time limit.
cases use sequential variable-ordering heuristic, value-ordering heuristic
chooses largest unfixed value within variables domain. variable
unfixed value chosen labeling, either value member set
represented variable not. order try two alternatives
significant effect performance solver. case elect choose
element-not-in-set option first.
2. recently new sets library Cardinal added ECLi PSe supports better cardinality
reasoning. Unfortunately cannot directly compare benchmarks since

142

fiSolving Set Constraint Satisfaction Problems using ROBDDs

Table 2: Results Steiner systems, split constraints intermediate variables.
Testcase ECLi PSe Mozart Bounds
Domain
LU+R
LU+Lex LU+Card
Time Fails Time Fails Time Fails Time Fails Time Fails Time Fails Time Fails
/s

/s

S(2,3,7)
0.3
10
S(3,4,8)
0.5
21
S(2,3,9)
7.7 1394
S(2,4,13) 1.8 313
S(2,3,15) 3.6
65
S(3,4,16) 67.5 289
S(2,5,21) 3.2 421
S(3,6,22) 49.7 1619

/s

/s

/s

/s

/s

0.1 21 <0.1 10 0.1
0 0.1
0 0.1
4 <0.1
2
0.1 52 0.1 21 0.4
0 0.4
0 0.4
4 0.1
4
1.0 5102 1.6 1394 1.0 100 1.3 100 3.3 421 2.4 1072
0.4 1685 0.6 313 1.7 32 1.5 32 2.1 127 0.7 157
0.5 354 2.2 65 20.2
0 19.6
0 20.4 127 3.3 41






0.4 668 2.3 421 110.2
0 59.8
0 21.5 139 2.6 124







Table 3: Results Steiner systems, merged constraints intermediate variables.
Testcase

Bounds
Domain
LU+R
LU+Lex
LU+Card
Time Fails Time Fails Time Fails Time Fails Time Fails
/s

/s

/s

S(2,3,7) <0.1
8 <0.1
0
S(3,4,8)
0.1
18
0.1
0
S(2,3,9)
0.2
325
0.1
9
S(2,3,13)

109.2 24723
S(2,4,13) 0.1
157
0.1
0
S(2,3,15) 0.4
56
1.3
0
S(2,4,16) 421.4 522706
0.6
15
S(2,6,16)

80.7 15205
S(3,4,16) 9.7
274 548.7
0
S(2,5,21) 0.5
413
1.4
0
S(3,6,22) 8.3 1608


S(2,3,31) 23.3
280



/s

<0.1
0
0.1
0
0.1
9
144.6 24723
0.1
0
1.4
0
0.6
15
82.7 15205
485.3
0
1.4
0





/s

<0.1
0
0.1
0
0.1
11
518.1 30338
0.4
11
2.9
0
2.5
16


428.9
0
32.9
0





<0.1
0
0.1
0
0.2
113


0.1
27
0.7
32
577.0 209799


18.4
162
0.6
116
12.7
381
48.6
224

Table 4: All-solutions results Steiner systems. denotes failure complete test
case within one hour
ECLi PSe
Bounds
Problem Solns. time fails time fails
/s

S(2,3,7)
S(3,4,8)
S(2,3,9)
S(2,6,16)

/s

Domain
LU+R
time fails time fails
/s

/s

LU+Lex
LU+Card
time fails time fails
/s

/s

30 16.3 3,015 0.2
537 0.1
47 0.1
47 0.2
76 0.3
267
30
726.5 610271 1.4 492 2.1 492 22.4 3248 951.2 431801
840
398.1 391691 23.4 16794 37.8 16794 110.4 29133 593.3 224131
0


80.9 15205 83.0 15205





143

fiHawkins, Lagoon, & Stuckey

order compare raw performance various solvers, irrespective
modeling advantages ROBDD-based solver, performed experiments using model
problem contains primitive constraints makes use intermediate
variables. split model contains unary constraints corresponding Equation (8)
3m(m1)/2 binary constraints corresponding Equation (9) (containing intermediate
variables uij ). model used ECLi PSe , Mozart ROBDD-based
solvers, permitting direct comparison propagation performance. Results model
shown Table 2. particular, observe model ECLi PSe ROBDDbased bounds solver produce number failures, demonstrating search
spaces explored two solvers identical.
One main strengths ROBDD-based modeling approach gives us
freedom merge arbitrary constraints existentially quantify away intermediate
variables, allowing us model set constraint problems efficiently. case
Steiner systems, allows us model problem unary constraints corresponding
Equation (8), m(m 1)/2 binary constraints ij form ij = (|si sj |
(t 1)) (si < sj ). binary constraints contain intermediate variables
uij required since existentially quantified ROBDD
representation. Experimental results revised model shown Table 3.
cases revised model propagates much strongly original model,
leading substantial decrease solution time. addition, decrease number
set variables required permits solution larger test cases. Clearly beneficial
remove intermediate variables merge constraints.
Despite weaker propagation ROBDD bounds solver often fastest method
finding single solution Steiner System. order determine whether due
efficiency solver, whether solver lucky finding solution
quickly, also ran experiments find solutions Steiner systems reordering
blocks. results test cases least one solvers able solve
within time limit one hour shown Table 4. cases reduction
time number fails demonstrate superiority propagation approaches based
domain consistency.
7.2 Social Golfers
Another problem often used set benchmark Social Golfers problem (problem
prob010 CSPLib). aim problem arrange N = g golfers g groups
players w weeks, two players play together once.
model problem set constraint problem using w g matrix set variables
vij , 1 w week index 1 j g group index.

support lexicographic ordering constraints. Testing without lexicographic orderings showed
23 times slower LU + Card.

144

fiSolving Set Constraint Satisfaction Problems using ROBDDs

use following model problem:
w
^

(partition< (vi1 , . . . , vig ))

^

|vij | =

i=1 j=1

i=1



g
w ^
^

^

|vik vjl | 1

w1
^

w
^

(10)
vi1 vj1

i=1 j=i+1

i,j{1,...,w} k,l{1,...,g}
i6=j

partition< global constraint combined partitioning lexicographical ordering constraint, formed merging partition constraint Section 4.2 constraints
imposing lexicographic order variables. constraint trivial construct using
ROBDDs, available either ECLi PSe Mozart.3
Results solvers shown Table 5 Table 6. former table,
sequential smallest-element-in-set labeling strategy used enable fair comparison
propagation performance, whereas latter table first-fail labeling strategy
used order give measure peak performance solver. every test case
tables, single exception (5-8-3), least one ROBDD-based solvers
performs equal better ECLi PSe Mozart. also observed
using first-fail labeling strategy, domain split domain solvers
solvers able solve every test case.
several features results worth noting. case
Steiner systems, ROBDD-based set bounds solver often fastest, despite weak
propagation. Amongst solvers stronger propagation, split domain solver
almost always faster original domain solver due smaller domain sizes. is,
however, slower original domain solver presence backtracking (due
requirement trail valuesin particular propagator ROBDDs). lexicographic bounds solver almost effective domain solvers restricting search
space, although usually outperformed domain bounds solvers.
7.3 Weighted Hamming Codes
problem finding maximal Hamming Codes modelled set constraint
problem.
define l-bit codeword bit-string (or vector Boolean values) length l.
Given two l-bit codewords B, define Hamming distance d(A, B)
B number positions two bit-strings differ. (l, d)-Hamming
Code set l-bit codewords Hamming distance two codewords
set least d.
Given codeword length l minimum Hamming distance d, problem
construct Hamming code largest possible number codewords. variant
problem, used benchmark Sadler Gervet (2004), additional requirement
codeword fixed weight w, weight codeword defined
3. would, course, possible implement constraint ECLi PSe Mozart,
implementation would fairly laborious process. strength ROBDD-based modeling
approach construct global constraints extra code.

145

fiHawkins, Lagoon, & Stuckey

Table 5: First-solution performance results Social Golfers problem, using sequential
smallest-element-in-set labeling strategy. Time number failures given
solvers. denotes failure complete test case within 10 minutes.
cases 5-4-3, 6-4-3, 7-5-5 solutions
Problem
w-g-s
2-5-4
2-6-4
2-7-4
2-8-5
3-5-4
3-6-4
3-7-4
4-5-4
4-6-5
4-7-4
4-9-4
5-4-3
5-5-4
5-7-4
5-8-3
6-4-3
6-5-3
6-6-3
7-5-5

ECLi PSe
time fails
/s

Mozart
time fails
/s

7.6 10468
49.2 64308
95.1 114818


12.5 14092
76.3 83815
146.8 146419
14.1 14369


169.3 149767
27.3 19065


350.6 199632


5.0 2229


458.9 240296
3.3 1462



1.0 7638
6.4 42346
10.9 66637


2.5 10311
14.0 51134
27.3 88394
3.9 10715


46.4 90712
7.8 12489


217.7 416889


0.9 1820


287.4 471485
1.0 1462



Bounds
Domain LU+R LU+Lex LU+Card
time fails time fails time time fails time fails
/s

/s

0.1
30 0.1
0
0.6 2036 0.2
0
1.7 4447 0.4
0

2.0
0
0.1
30 0.3
0
1.6 2039 1.6
0
4.6 4492 8.9
0
0.2
30 0.8
0
21.9 12747 118.6
0
8.7 4498


2.6
71


113.9 63642 28.6 5165
7.0 2686 3.8 41
14.6 4583


1.1
14 9.2
0
158.2 61770 20.3 2132
4.1 1455 1.8 82
0.5
5 1.8
0

0.5
0

/s

0.1
0.1
0.4
1.6
0.3
1.4
8.4
0.6
80.7
481.6

32.1
2.3

7.8
23.0
1.5
1.4
0.4

/s

0.1
3
0.7 194
2.3 692


0.4
3
2.2 194
7.6 695
0.7
3
19.3 499
14.1 696
22.2
8
88.9 10210
12 313
23.7 700
3.2
3
60.8 4506
4.1 202
1.2
0
2.4
0

/s

0.1
5
0.4 326
1.6 1608


0.2
5
1.9 328
5.1 1629
0.4
5
32.0 2122
10.5 1632
8.9
33
202.7 50542
20.8 1584
17.5 1683
2.1
4
293.5 49966
8.3 1078
0.7
1
1.3
22

number 1 bits codeword contains. denote instance problem
H(l, d, w).
proposed Muller Muller (1997), model problem n codewords
using n set variables Si , 1 n . codeword Ci corresponds characteristic
function set Si , i.e. bit j set codeword Ci j Si . Hamming
distance d(Ci , Cj ) two codewords Ci Cj calculated associated
sets Si Sj thus:

d(Ci , Cj ) = l |Si Sj | |{1, . . . , l} \ (Si Sj )|

remove symmetries created permuting codewords introducing lexicographic ordering constraints Si < Sj , 1 < j n. complete model
146

fiSolving Set Constraint Satisfaction Problems using ROBDDs

Table 6: First-solution performance results Social Golfers problem, using first-fail
smallest-element-in-set labeling strategy. Time number failures given
solvers. cases 5-4-3, 6-4-3, 7-5-5 solutions
Problem
w-g-s
2-5-4
2-6-4
2-7-4
2-8-5
3-5-4
3-6-4
3-7-4
4-5-4
4-6-5
4-7-4
4-9-4
5-4-3
5-5-4
5-7-4
5-8-3
6-4-3
6-5-3
6-6-3
7-5-3
7-5-5

ECLi PSe
time fails

Mozart
time fails

/s

/s

7.9 10468
51.3 64308
99.9 114818


14.5 14092
91.8 83815
183.0 146419
18.0 14369


243.9 149767
40.9 19065


394.9 199632


5.4 2229


501.0 240296
3.6 1462





Bounds
time fails
/s

1.1 7638
6.5 42346
11.1 66637


2.6 10311
15.1 51134
28.7 88394
4.1 10715


49.6 90712
8.3 12489


224.5 416889


0.9 1820


294.2 471485
1.0 1462





Domain LU+R LU+Lex LU+Card
time fails time time fails time fails
/s

0.1
30
0.6 2036
1.7 4447


0.1
44
1.9 2361
5.2 5140
0.3
47
38.5 19376
9.9 5149
2.7
143
187.5 103972
4.5 2388
17.6 5494
1.1
19
234.2 90428
1.6
495







/s

0.1
0
0.2
0
0.4
0
1.9
0
0.3
0
1.1
0
1.9
0
0.8
0
62.5
0
6.5
0
152.0
0
23.2 3812
2.5 18
18.2
0
4.5
0
14.6 1504
1.2 34
1.6
7
16.9 528
0.5
0

0.1
0.1
0.4
1.6
0.3
0.9
1.7
0.6
40.1
5.1
107.4
26.0
1.7
12.8
3.9
15.2
1.0
1.3
13.1
0.4

/s

0.1
3
0.7 186
2.0 390


0.4
5
2.4 209
6.2 512
0.7
7
24.6 607
10.6 405
22.6
13
91.4 10422
23.4 776
16.9 447
3.4
2
54.0 4013
58.2 3787
5.1 292
288.8 9829
2.4
0

/s

0.4 447
3.8 3820
4.6 6424


1.3 481
13.7 3722
15.6 6067
2.6 494


29.5 5717
12.5 516
309.1 72669
41.4 4730
47.1 5473
2.7
83
349.9 59805
473.6 68673
1.0
8


1.3
22

problem is:
n
^

|Si | = w

(11)

i=1



n1
^

n
^

(|Si Sj | + |(Si Sj )| l d) (Si < Sj )

(12)

i=1 j=i+1

constraints described Equation (12) implemented using single ROBDD
pair j values. possible since model integer addition
comparison operations ROBDDs described Section 5, using representation
cardinality set variable integer expression described Section 5.5.
order find optimal solution, initially set n 1, repeatedly solve instances
problem, progressively incrementing n find larger larger codes. prove
optimality solution n = k failing solve problem n = k + 1;
know optimal value n k.
147

fiHawkins, Lagoon, & Stuckey

Table 7: Statistics 51 Weighted Hamming Code testcases solved
solvers.
Bounds
time
fails
/s

Domain
LU+R
time fails time fails
/s

Mean
17.7 110034
Total
903.3
Minimum
0.03
0
25th Percentile 0.03
19
Median
0.05
196
75th Percentile 0.67
5604
Maximum
415.55 3021057

LU+Lex
LU+Card
time fails time fails

/s

0.2 210.7
11.4
0.03
0
0.03
0
0.04
2
0.06
25
4.16 3740

/s

0.3 210.7
14.2
0.03
0
0.03
0
0.04
2
0.06
25
4.69 3740

/s

4.4 1886
222.6
0.03
0
0.03
3
0.04
20
0.18 143.5
113.9 45667

3.6 6604
184.6
0.03
0
0.03
0
0.04
2
0.09
112
92.09 211677

Table 8: Weighted Hamming Code testcases solved least one
solvers
Bounds
Domain
LU+R
time fails time fails time fails
/s

H(8,4,4)
H(9,4,3)
H(9,4,6)
H(10,6,5)






/s

/s

LU+Lex
time fails
/s

LU+Card
time fails
/s

1.6 224 1.9 224 8.5
986


11.3 5615 20.6 5615




25.4 16554 45.7 16554 321.9 56599


26.7 16635 29.6 16635 528.8 169457 428.3 762775

order assist timing comparisons, use set problem instances
Sadler Gervet (2004). consider sets values H(l, d, w) l {6, 7, 8, 9, 10},
{4, 6, 8, 10, 12}, w {3, 4, 5, 6, 7, 8}, < l w l (trivially
one solution l none w > l). 62 testcases; almost
identicalin particular testcases H(l, d, w) H(l, d, l w) solutions differ
complementation bits. ROBDD-based solver solve seven test
cases (namely H(9, 4, 4), H(9, 4, 5), H(10, 4, 3), H(10, 4, 4), H(10, 4, 5), H(10, 4, 6), H(10, 4, 7)),
reality contains three pairs mirror image testcases.
Since many results list testcase individually, performance statistics
testcases solvers able solve shown Table 7. cases
solved least one ROBDD-based solvers shown
Table 8.
Sadler Gervet (2004) report results problem using set bounds lexicographic bounds solvers implemented ECLi PSe . solvers able solve 50
testcases time limit 240 seconds testcase. individual testcases took
upwards 100 seconds. contrast, ROBDD-based domain solver capable solving 55 testcases 76.4 seconds total. Clearly case enforcing domain consistency
brings considerable reduction search space, leading highly efficient solver.
148

fiSolving Set Constraint Satisfaction Problems using ROBDDs

Moreover, set bounds lexicographic bounds solvers implemented using
ROBDD platform appear perform considerably better Sadler Gervet.
Due graphical nature presentation difficult quantify performance difference; exact figures presented two testcasesnamely H(9, 4, 7)
H(10, 6, 7). testcase H(9, 4, 7) ROBDD set bounds lexicographic bounds
solvers found proved optimal solution 0.6 0.3 seconds respectively,
compared > 240 167.1 seconds respectively quoted bounds lexicographic solvers Sadler Gervet. Similarly H(10, 6, 7) ROBDD set bounds
lexicographic bounds solvers found proved optimal solution 1.9 1.1 seconds
respectively, compared > 240 98.5 seconds. Given dramatic performance
difference, appears additional modeling flexibility ROBDD-based solver provides substantial performance gain.
noted performance results reported Sadler Gervet run
slightly slower machine (a 2 Ghz Pentium 4 machine). Nonetheless, contribution
performance difference due machine speed dwarfed performance gap
two solvers.
7.4 Balanced Academic Curricula
Balanced Academic Curriculum problem (problem prob030 CSPLib) involves planning academic curriculum sequence academic periods order provide
balanced load period.
curriculum consists courses (1 m) n academic periods. course
set prerequisites associated academic load ti . Every course must assigned
exactly one period. given period total number courses must least
minimum number c maximum number d. addition, within given
period total academic load courses must least minimum load
maximum load b. Let R set prequisite pairs hi, ji, j
courses. Prerequisite relationships must observed, pair courses hi, ji R,
course scheduled period p, course j must scheduled period strictly
prior p.
model problem using set variables set constraints proposed Hnich
et al. (2002), although experimental results presented model.
primal model, use one set variable Si per academic period. Si represents
set courses assigned academic period i, k Si course k assigned
period i. model problem using following constraints:
(S1) Every course taken exactly once: partition(S1 , . . . , Sn )
(S2) number courses period c d:
ni=1 ((c |Si |) (|Si | d))
(S3) total academic load period b:
ni=1 ((a wsum(Si , ht1 , . . . , tm i)) (wsum(Si , ht1 , . . . , tm i) b))
(S4) Prerequisites
respected:
V
/ Sj ))
ni=1 ij=1 ( hc,piR (p Si ) (c

149

fiHawkins, Lagoon, & Stuckey

general partition wsum constraints primal set model
large, making domain propagation impractical.
addition presenting results primal model, Choi et al. (2003) demonstrated
substantial performance improvement obtained problem
use redundant models together channelling constraints.
obtain better results dual set model, additional set variables
introduced model course. define set variables Xi (1 m) representing
course, k Xi course assigned period k. define
following constraints:
n
(CX) Channelling constraints:
i=1 j=1 (i Sj ) (j Xi )

(X1) course may assigned one period:
i=1 |Xi | = 1
(X2) Prerequisites respected: hi, ji R lexlt(Xj , Xi )
define dual model consist constraints {S2, S3, CX, X1, X2}. Constraints
S1 S4 longer required, since propagation redundant.
Unfortunately, dual model performs better primal set model, still
incapable proving optimality solutions problems. obtain
stronger propagation introducing redundant global constraints total academic
load number courses academic periods, suggested Choi et al. (2003).
academic period j define two integer variables lj , representing academic
load period j qj , representing number courses period j. define
following constraints new integer variables:
(CI1) Channeling constraints li : ni=1 wsum(Si , ht1 , . . . , tm i) = li
(CI2) Channeling constraints qi : ni=1 |Si | = qi
(I1) Range constraints li : ni=1 (a li ) (li b)
(I2) Range constraints qi : ni=1 (c qi ) (qi d)
Pn
Pn
(I3) loads undertaken:
i=1 ti
i=1 lj =
Pn
(I4) courses must taken:
i=1 qj =

define hybrid dual model consisting constraints {CX, X1, X2,
CI1, CI2, I1, I2, I3, I4}. Note none original constraints S1S4 remain.
completeness also possible define hybrid primal model consisting constraints
{S1, S4, CI1, CI2, I1, I2, I3, I4}, although large ROBDD sizes make domain
propagation impractical.
Experimental results Balanced Academic Curriculum problem shown Table 9. timing results Hybrid Dual model comparable best results
obtained Hnich et al. (2002) Choi et al. (2003). number failures required
solve problem orders magnitude smaller best results presented either
paper, emphasising value domain propagation case. examples also show
case LU+Lex solver competitive clearly robust solver
different models.
150

fiSolving Set Constraint Satisfaction Problems using ROBDDs

Table 9: Performance results Balanced Academic Curriculum Problem 8, 10
12 period problems. first column contains number periods,
second column contains model type (HD=hybrid dual, D=dual, P=primal,
HP=hybrid primal), third column contains maximum load per period
b. cases sequential smallest-element-in-set labeling method used

Problem

Bounds
Domain LU+R LU+Lex
time fails time fails time time fails
/s

HD


8
P

HP

HD


10
P

HP

HD


12
P

HP

/s

16

0.3
17
8.1 5586 1.7
18 35.7 30430 1.7
16


17
7.7 5348 1.1
18 32.8 29781 1.2
16


17
6.0 5353
18 16.3 29781
16


17
6.8 5586
18 19.3 30431
13

0.3
14 17.2 11439 1.3
15
2.1 630 1.4
13


14 26.8 21103 1.0
15
2.1 711 1.0
13


14 14.7 21105
15
3.5 711
13


14 11.8 11440
15
3.6 630
16

1.1
17

6.0
18
6.1 235 8.1
16


17


18
6.3 220 6.8
16


17


18 101.7 225
16


17


18 100.9 236

/s

0
3
5

3
5






0
2
1

2
1






0
9
4


4







151

/s

0.3
0.3
0
2.7
1.0
3
3.0
1.0
5



1.2
0.6
3
1.3
0.7
5



13.9 2046
53.1 26431

0.3
0
12.8 1510
69.8 26145
0.3
0.3
0
1.5
0.9
2
1.7
0.9
1



1.6
0.6
2
1.6
0.6
1



53.3 16275

9.6
593

0.4
0
25.6 4672
10.6 516
1.1
0.9
0
9.3
3.0
9
9.2
3.4
4






9.0
3.0
4






153.8 224

3.4
0
216.8 526
166.0 224

LU+Card
time fails
/s



2.3
3
2.3
5


1.7
3
1.6
5


32.7 4757
61.2 29628


40.5 5410
70.5 30141


2.6
2
2.6
1


2.4
2
2.1
1


52.1 11772
31.5 515


46.9 5773
31.7
533




15.7
4




13.1
4













fiHawkins, Lagoon, & Stuckey

Steiner system S(2, 3, 15)
500

Domain
Bounds
Lex Bounds
Card Bounds

1500

Total BDD size

log(Total Domain Size)

400

300

200

Domain
Split
Bounds
Lex Bounds
Card Bounds

1000

500

100

0
0

100

200

300

0

100

Labelling step

200

300

Labelling step

Social Golfers problem 4-5-4

1000

Total BDD size

log(Total Domain Size)

Domain
Split
Bounds
Lex Bounds
Card Bounds

Domain
Bounds
Lex Bounds
Card Bounds

300

200

500

100

0
0

20

40

60

80

100

Labelling step

0

20

40

60

80

100

Labelling step

Figure 17: Comparison total domain total ROBDD sizes labeling step set
bounds, set domain, split set domain, set lexicographic bounds, set
cardinality bounds solvers Steiner System S(2, 3, 15) Social Golfers
problem 4-5-4. Note axes total domain size graphs
logarithmic scale (base 2).

7.5 Comparing Propagation Performance Solvers
instructive compare propagation performance various ROBDD-based
solvers graphically. pick two small examples, namely Steiner System S(2, 3, 15)
Social Golfers problem 4-5-4, using default labeling problem, graph
BDD domain sizes number labeling steps time.
152

fiSolving Set Constraint Satisfaction Problems using ROBDDs

500

log(Total Domain Size)

400

300

200

Domain
Split
Bounds
Lex Bounds
Card Bounds

300

log(Total Domain Size)

Domain
Split
Bounds
Lex Bounds
Card Bounds

200

100

100

0

0
1

2

0.2

Time/s

0.4

0.6

0.8

Time/s

Steiner system S(2, 3, 15)

Social Golfers problem 4-5-4

Figure 18: Comparison total domain size time set bounds, set domain, split set
domain, set lexicographic bounds, set cardinality bounds solvers
Steiner System S(2, 3, 15) Social Golfers problem 4-5-4. Note
axes logarithmic scale (base 2).

Figure 17 depicts total domain sizes total ROBDD sizes (total number
internal nodes) vary labeling step solvers Steiner System
S(2, 3, 15) Social Golfers problem 4-5-4. particular, observe domain
split-domain propagators effective reducing domain size thus
restricting search space, although maintaining domain consistency costly due
size ROBDDs required representing arbitrary domains. seen
ROBDD size labeling step graph, notably case Social Golfers
problem 4-5-4. lexicographic bounds solver next effective domain size
reduction, requires smaller number ROBDD nodes store bounds
domain cardinality bounds solvers. bounds solver clearly weakest terms
domain size reduction, opposed solvers starts zero size domain
representation builds slowly ROBDDs representing answer.
concerned strength propagator abstract, since
efficiency solver whole dependent propagation labeling
processes. Figure 18 depicts graphs domain size time propagators discussed paper. see effective propagator
necessarily lead efficient set solver. Despite comparatively weak propagation,
set cardinality bounds solvers lead fastest reduction domain size per unit
time. Nonetheless, experimental timing results given demonstrate harder
cases additional cost maintaining domain consistency lexicographic bounds
justified consequent reduction search space.
153

fiHawkins, Lagoon, & Stuckey

Interestingly see graphs Figure 18 initial domain reduction
labeling, gap time 0 line starts, significant
part computation. particular, one weaknesses lexicographic bounds
solver large time required reach initial fixpoint lexicographic bounds
propagation. practical applications might preferable implement hybrid solver
utilises one propagators generate initial domains, uses
lexicographic bounds propagator labeling.

8. Conclusion
demonstrated ROBDDs form highly flexible platform constructing set
constraint solvers. ROBDDs allow compact representation many set domains
set constraints, making effective basis efficient set solver. Since ROBDDs
represent arbitrary Boolean formul easily conjoin existentially quantify
them, permitting removal intermediate variables making construction
global constraints trivial. demonstrated efficiently enforce various levels
consistency, including set domain, set bounds, cardinality bounds lexicographic bounds
consistency. Finally, presented experimental results demonstrate
ROBDD-based solver outperforms common set solvers wide variety standard
set constraint satisfaction problems.
single set solver uniformly better others. many examples simple
bounds propagation best approach, cases, particularly ask
solutions, domain consistency preferable. also examples lexicographic bounds cardinality bounds best approach. split-domain approach
somewhat disappointing, since appears many cases overhead
complicated calculation (Equation 6) rewarded terms smaller ROBDD sizes.
future plan explore robust general set constraint solver dynamically
chooses level consistency maintain examining big domain ROBDDs
becoming search progresses.

References
Andersen, H. R. (1998). introduction Binary Decision Diagrams. [Online, accessed
30 July 2004]. http://www.itu.dk/people/hra/notes-index.html.
Apt, K. R. (1999). essence constraint propagation. Theoretical Computer Science,
221 (12), 179210.
Azevedo, F. (2002). Constraint Solving Multi-valued Logics. Ph.D. thesis, Faculdade
de Ciencias e Tecnologia, Universidade Nova de Lisboa.
Bagnara, R. (1996). reactive implementation Pos using ROBDDs. Procs. PLILP,
Vol. 1140 LNCS, pp. 107121. Springer.
Bessiere, C., Hebrard, E., Hnich, B., & Walsh, T. (2004). Disjoint, partition intersection
constraints set multiset variables. Wallace, M. (Ed.), Proceedings
154

fiSolving Set Constraint Satisfaction Problems using ROBDDs

10th International Conference Principles Practice Constraint Programming,
Vol. 3258 LNCS, pp. 138152. Springer-Verlag.
Bryant, R. E. (1986). Graph-based algorithms Boolean function manipulation. IEEE
Trans. Comput., 35 (8), 677691.
Bryant, R. E. (1992). Symbolic Boolean manipulation ordered binary-decision diagrams. ACM Comput. Surv., 24 (3), 293318.
Choi, C., Lee, J., & Stuckey, P. J. (2003). Propagation redundancy redundant modelling.
Rossi, F. (Ed.), Proceedings 9th International Conference Principles
Practices Constraint Programming, Vol. 2833 LNCS, pp. 229243. SpringerVerlag.
Gent, I. P., Walsh, T., & Selman, B. (2004). CSPLib: problem library constraints.
[Online, accessed 24 Jul 2004]. http://www.csplib.org/.
Gervet, C. (1997). Interval propagation reason sets: Definition implementation
practical language. Constraints, 1 (3), 191246.
Hawkins, P., Lagoon, V., & Stuckey, P. (2004). Set bounds (split) set domain propagation using ROBDDs. Webb, G., & Yu, X. (Eds.), AI 2004: Advances Artificial
Intelligence, 17th Australian Joint Conference Artificial Intelligence, Vol. 3339
LNCS, pp. 706717. Springer-Verlag.
Hnich, B., Kiziltan, Z., & Walsh, T. (2002). Modelling balanced academic curriculum
problem. Proceedings Fourth International Workshop Integration AI
Techniques Constraint Programming Combinatorial Optimization Problems, pp. 121131.
IC-PARC (2003). ECLiPSe constraint logic programming system. [Online, accessed 31
May 2004]. http://www.icparc.ic.ac.uk/eclipse/.
ILOG (2004). ILOG Solver. [Online, accessed 30 Aug 2004]. http://www.ilog.com/.
Kiziltan, Z., & Walsh, T. (2002). Constraint programming multisets. Proceedings
2nd International Workshop Symmetry Constraint Satisfaction Problems
(SymCon-02).
Lagoon, V., & Stuckey, P. (2004). Set domain propagation using ROBDDs. Wallace, M.
(Ed.), Proceedings 10th International Conference Principles Practice
Constraint Programming, Vol. 3258 LNCS, pp. 347361. Springer-Verlag.
van Lint, J. H., & Wilson, R. M. (2001). Course Combinatorics (2nd edition). Cambridge University Press.
Mailharro, D. (1998). classification constraint-based framework configuration.
Artificial Intelligence Engineering Design, Analysis Manufacturing, 12, 383
397.
Muller, T. (2001). Constraint Propagation Mozart. Doctoral dissertation, Universitat des
Saarlandes, Naturwissenschaftlich-Technische Fakultat I, Fachrichtung Informatik,
Saarbrucken, Germany.
155

fiHawkins, Lagoon, & Stuckey

Muller, T., & Muller, M. (1997). Finite set constraints Oz. Bry, F., Freitag, B., &
Seipel, D. (Eds.), Workshop Logische Programmierung, Vol. 13. Technische Universitat
Munchen.
Puget, J.-F. (1992). PECOS: high level constraint programming language. Proceedings
SPICIS92, Singapore.
Sadler, A., & Gervet, C. (2001). Global reasoning sets. FORMUL01 workshop
modelling problem formulation, conjunction CP01.
Sadler, A., & Gervet, C. (2004). Hybrid set domains strengthen constraint propagation
reduce symmetries. Wallace, M. (Ed.), Proceedings 10th International
Conference Principles Practice Constraint Programming, Vol. 3258 LNCS,
pp. 604618. Springer-Verlag.
Somenzi, F. (2004). CUDD: Colorado University Decision Diagram package. [Online, accessed 31 May 2004]. http://vlsi.colorado.edu/~fabio/CUDD/.
Somogyi, Z., Henderson, F., & Conway, T. (1996). execution algorithm Mercury,
efficient purely declarative logic programming language. Journal Logic Programming, 29 (13), 1764.

156

fiJournal Artificial Intelligence Research 24 (2005) 49-79

Submitted 09/04; published 07/05

Framework Sequential Planning Multi-Agent Settings
Piotr J. Gmytrasiewicz
Prashant Doshi

PIOTR @ CS . UIC . EDU
PDOSHI @ CS . UIC . EDU

Department Computer Science
University Illinois Chicago
851 S. Morgan St
Chicago, IL 60607

Abstract
paper extends framework partially observable Markov decision processes (POMDPs)
multi-agent settings incorporating notion agent models state space. Agents
maintain beliefs physical states environment models agents,
use Bayesian updates maintain beliefs time. solutions map belief states actions.
Models agents may include belief states related agent types considered
games incomplete information. express agents autonomy postulating models directly manipulable observable agents. show important properties
POMDPs, convergence value iteration, rate convergence, piece-wise linearity convexity value functions carry framework. approach complements
traditional approach interactive settings uses Nash equilibria solution paradigm.
seek avoid drawbacks equilibria may non-unique capture
off-equilibrium behaviors. cost represent, process continuously
revise models agents. Since agents beliefs may arbitrarily nested, optimal solutions decision making problems asymptotically computable. However, approximate
belief updates approximately optimal plans computable. illustrate framework using
simple application domain, show examples belief updates value functions.

1. Introduction
develop framework sequential rationality autonomous agents interacting
agents within common, possibly uncertain, environment. use normative paradigm
decision-theoretic planning uncertainty formalized partially observable Markov decision
processes (POMDPs) (Boutilier, Dean, & Hanks, 1999; Kaelbling, Littman, & Cassandra, 1998;
Russell & Norvig, 2003) point departure. Solutions POMDPs mappings
agents beliefs actions. drawback POMDPs comes environments populated
agents agents actions represented implicitly environmental noise
within the, usually static, transition model. Thus, agents beliefs another agent part
solutions POMDPs.
main idea behind formalism, called interactive POMDPs (I-POMDPs), allow
agents use sophisticated constructs model predict behavior agents. Thus,
replace flat beliefs state space used POMDPs beliefs physical
environment agent(s), possibly terms preferences, capabilities,
beliefs. beliefs could include others beliefs others, thus nested arbitrary
levels. called interactive beliefs. space interactive beliefs rich
updating beliefs complex updating flat counterparts, use value
c
2005
AI Access Foundation. rights reserved.

fiG MYTRASIEWICZ & OSHI

function plots show solutions I-POMDPs least good as, usual cases superior
to, comparable solutions POMDPs. reason intuitive maintaining sophisticated models
agents allows refined analysis behavior better predictions actions.
I-POMDPs applicable autonomous self-interested agents locally compute actions execute optimize preferences given believe interacting
others possibly conflicting objectives. approach using decision-theoretic framework solution concept complements equilibrium approach analyzing interactions used
classical game theory (Fudenberg & Tirole, 1991). drawback equilibria could
many (non-uniqueness), describe agents optimal actions if, when,
equilibrium reached (incompleteness). approach, instead, centered optimality
best response anticipated action agent(s), rather stability (Binmore, 1990;
Kadane & Larkey, 1982). question whether, circumstances, kind
equilibria could arise solutions I-POMDPs currently open.
approach avoids difficulties non-uniqueness incompleteness traditional equilibrium approach, offers solutions likely better solutions traditional
POMDPs applied multi-agent settings. advantages come cost processing
maintaining possibly infinitely nested interactive beliefs. Consequently, approximate belief
updates approximately optimal solutions planning problems computable general.
define class finitely nested I-POMDPs form basis computable approximations infinitely nested ones. show number properties facilitate solutions POMDPs carry
finitely nested I-POMDPs. particular, interactive beliefs sufficient statistics
histories agents observations, belief update generalization update POMDPs,
value function piece-wise linear convex, value iteration algorithm converges
rate.
remainder paper structured follows. start brief review related
work Section 2, followed overview partially observable Markov decision processes
Section 3. There, include simple example tiger game. introduce concept
agent types Section 4. Section 5 introduces interactive POMDPs defines solutions.
finitely nested I-POMDPs, properties introduced Section 6. continue
example application finitely nested I-POMDPs multi-agent version tiger game
Section 7. There, show examples belief updates value functions. conclude
brief summary current research issues Section 8. Details proofs
Appendix.

2. Related Work
work draws prior research partially observable Markov decision processes,
recently gained lot attention within AI community (Smallwood & Sondik, 1973; Monahan,
1982; Lovejoy, 1991; Hausktecht, 1997; Kaelbling et al., 1998; Boutilier et al., 1999; Hauskrecht,
2000).
formalism Markov decision processes extended multiple agents giving rise
stochastic games Markov games (Fudenberg & Tirole, 1991). Traditionally, solution concept
used stochastic games Nash equilibria. recent work AI follows tradition
(Littman, 1994; Hu & Wellman, 1998; Boutilier, 1999; Koller & Milch, 2001). However,
mentioned before, pointed game theorists (Binmore, 1990; Kadane &
50

fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGS

Larkey, 1982), Nash equilibria useful describing multi-agent system when, if,
reached stable state, solution concept sufficient general control paradigm.
main reasons may multiple equilibria clear way choose among
(non-uniqueness), fact equilibria specify actions cases agents believe
agents may act according equilibrium strategies (incompleteness).
extensions POMDPs multiple agents appeared AI literature recently (Bernstein,
Givan, Immerman, & Zilberstein, 2002; Nair, Pynadath, Yokoo, Tambe, & Marsella, 2003).
called decentralized POMDPs (DEC-POMDPs), related decentralized control
problems (Ooi & Wornell, 1996). DEC-POMDP framework assumes agents fully cooperative, i.e., common reward function form team. Furthermore, assumed
optimal joint solution computed centrally distributed among agents execution.
game-theoretic side, motivated subjective approach probability
games (Kadane & Larkey, 1982), Bayesian games incomplete information (see Fudenberg &
Tirole, 1991; Harsanyi, 1967, references therein), work interactive belief systems (Harsanyi,
1967; Mertens & Zamir, 1985; Brandenburger & Dekel, 1993; Fagin, Halpern, Moses, & Vardi,
1995; Aumann, 1999; Fagin, Geanakoplos, Halpern, & Vardi, 1999), insights research
learning game theory (Fudenberg & Levine, 1998). approach, closely related decisiontheoretic (Myerson, 1991), epistemic (Ambruster & Boge, 1979; Battigalli & Siniscalchi, 1999;
Brandenburger, 2002) approach game theory, consists predicting actions agents given
available information, choosing agents action (Kadane & Larkey, 1982).
Thus, descriptive aspect decision theory used predict others actions, prescriptive
aspect used select agents optimal action.
work presented also extends previous work Recursive Modeling Method (RMM)
(Gmytrasiewicz & Durfee, 2000), adds elements belief update sequential planning.

3. Background: Partially Observable Markov Decision Processes
partially observable Markov decision process (POMDP) (Monahan, 1982; Hausktecht, 1997;
Kaelbling et al., 1998; Boutilier et al., 1999; Hauskrecht, 2000) agent defined
POMDPi = hS, Ai , Ti , , Oi , Ri

(1)

where: set possible states environment. Ai set actions agent execute. Ti
transition function Ti : Ai [0, 1] describes results agent actions.
set observations agent make. Oi agents observation function Oi : Ai
[0, 1] specifies probabilities observations given agents actions resulting states. Finally,
Ri reward function representing agent preferences R : Ai <.
POMDPs, agents belief state represented probability distribution S.
Initially, observations actions take place, agent (prior) belief, b 0i .
time steps, t, assume agent + 1 observations performed actions 1 .

assembled agent observation history: h ti = {o0i , o1i , .., ot1
, oi } time t. Let
Hi denote set observation histories agent i. agents current belief, b ti S,
continuously revised based new observations expected results performed actions. turns
1. assume action taken every time step; without loss generality since actions maybe
No-op.

51

fiG MYTRASIEWICZ & OSHI

agents belief state sufficient summarize past observation history
initial belief; hence called sufficient statistic.2
t1
belief update takes account changes initial belief, b t1
, due action, ai , executed


time 1, new observation, oi . new belief, bi , current state st , is:
bti (st ) = Oi (oti , st , at1
)

X

bit1 (st1 )Ti (st , ati , st1 )

(2)

st1

normalizing constant.
convenient summarize update performed states

bti = SE(bit1 , at1
, oi ) (Kaelbling et al., 1998).
3.1 Optimality Criteria Solutions
agents optimality criterion, OCi , needed specify rewards acquired time
handled. Commonly used criteria include:
finite horizon criterion,P
agent maximizes expected value sum
following rewards: E( Tt=0 rt ). Here, rt reward obtained time length
horizon. denote criterion fhT .
AnP
infinite horizon criterion discounting, according agent maximizes


E(
t=0 rt ), 0 < < 1 discount factor. denote criterion ih .

infinite horizon criterion averaging, according agent maximizes
average reward per time step. denote ihAV .

follows, concentrate infinite horizon criterion discounting, approach easily adapted criteria.
utility associated belief state, bi composed best immediate rewards
obtained bi , together discounted expected sum utilities associated
belief states following bi :

U (bi ) = max

ai Ai

X

bi (s)Ri (s, ai ) +

X

P r(oi |ai , bi )U (SEi (bi , ai , oi ))

oi

sS



(3)

Value iteration uses Equation 3 iteratively obtain values belief states longer time
horizons. step value iteration error current value estimate reduced
factor least (see example Russell & Norvig, 2003, Section 17.2.) optimal action, ,
element set optimal actions, OP (bi ), belief state, defined as:

OP (bi ) = argmax
ai Ai

X

bi (s)Ri (s, ai ) +

X

oi

sS

2. See (Smallwood & Sondik, 1973) proof.

52

P r(oi |ai , bi )U (SE(bi , ai , oi ))



(4)

fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGS

L


OL

10

Value Function(U)

8

6

4

2

0

0

0.2

0.4

0.6

0.8

1

pp_i(TL)
(TL)
POMDP noise

POMDP

Figure 1: value function single agent tiger game time horizon length 1, OC = fh1 .
Actions are: open right door - OR, open left door - OL, listen - L. value
time horizon value function POMDP noise factor identical single
agent POMDP.

3.2 Example: Tiger Game
briefly review POMDP solutions tiger game (Kaelbling et al., 1998). purpose
build insights POMDP solutions provide simple case illustrate solutions
interactive versions game later.
traditional tiger game resembles game-show situation decision maker
choose open one two doors behind lies either valuable prize dangerous tiger.
Apart actions open doors, subject option listening tigers growl
coming left, right, door. However, subjects hearing imperfect, given
percentages (say, 15%) false positive false negative occurrences. Following (Kaelbling et al.,
1998), assume value prize 10, pain associated encountering
tiger quantified -100, cost listening -1.
value function, Figure 1, shows values various belief states agents time
horizon equal 1. Values beliefs based best action available belief state,
specified Eq. 3. state certainty valuable agent knows location
tiger open opposite door claim prize certainly awaits. Thus,
probability tiger location 0 1, value 10. agent sufficiently uncertain,
best option play safe listen; value -1. agent indifferent opening
doors listening assigns probabilities 0.9 0.1 location tiger.
Note that, time horizon equal 1, listening provide useful information
since game continue allow use information. longer time horizons
benefits results listening results policies better ranges initial belief.
Since value function composed values corresponding actions, linear prob53

fiG MYTRASIEWICZ & OSHI

L\();L\(GL),OL\(GR)

L\();L\(*)

L\();OR\(GL),L\(GR)
L\();OR\(*)
OR\();L\(*)

L\();OL\(*)
OL\();L\(*)

8

Value Function(U)

6

4

2

0

-2
0

0.2

0.4

0.6

0.8

1

pp_i(TL)
(TL)
POMDP noise

POMDP

Figure 2: value function single agent tiger game compared agent facing noise factor, horizon length 2. Policies corresponding value lines conditional plans.
Actions, L, OL, conditioned observational sequences parenthesis.
example L\();L\(GL),OL\(GR) denotes plan perform listening action, L,
beginning (list observations empty), another L observation growl
left (GL), open left door, OL, observation GR. wildcard
usual interpretation.

ability tiger location, value function property piece-wise linear convex
(PWLC) horizons. simplifies computations substantially.
Figure 2 present comparison value functions horizon length 2 single
agent, agent facing noisy environment. presence noise could
due another agent opening doors listening probabilities. 3 Since POMDPs
include explicit models agents, noise actions included transition
model, .
Consequences folding noise two-fold. First, effectiveness agents optimal
policies declines since value hearing growls diminishes many time steps. Figure 3 depicts
comparison value functions horizon length 3. Here, example, two consecutive growls
noisy environment valuable agent knows acting alone since noise
may perturbed state system growls. time horizon length 1
noise matter value vectors overlap, Figure 1.
Second, since presence another agent implicit static transition model, agent
cannot update model agents actions repeated interactions. effect becomes important time horizon increases. approach addresses issue allowing
explicit modeling agent(s). results policies superior quality, show
Section 7. Figure 4 shows policy agent facing noisy environment time horizon 3.
compare corresponding I-POMDP policy Section 7. Note slightly different
3. assumed that, due noise, either door opens probabilities 0.1 turn, nothing happens
probability 0.8. explain origin assumption Section 7.

54

fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGS

L\();L\(*);OL\(GR;GR),L\(?)
L\();L\(GL),OL\(GR);OL\(GL;GR),L\(?)

L\();L\(*);OR\(GL;GL),L\(?)
L\();OR\(GL),L\(GR);OR\(GR;GL),L\(?)
L\();L\(*);OR\(GL;GL),OL\(GR;GR),L\(?)
OR\();L\(*);L\(*)
L\();L\(*);OR\(*)

OL\();L\(*);L\(*)
L\();L\(*);OL\(*)
8

Value Function(U)

7
6
5
4
3
2
1
0

0.2

0.4

0.6

0.8

1

p (TL)
p_i(TL)


POMDP noise

POMDP

Figure 3: value function single agent tiger game compared agent facing noise factor,
horizon length 3. ? description policy stands
perceptual sequences yet listed description policy.

[00.045)
OL
*

[0.0450.135) [0.1350.175) [0.1750.825)
L

L

GR

GL

GR

L
GR

GL

*

OL

L
GR

L
GL

GR


GL

*

GL

L
GL

[0.8650.955) [0.9551]

L

GR

OL

[0.8250.865)

L
*

L

GR


GL

*



Figure 4: policy graph corresponding value function POMDP noise depicted
Fig. 3.

55

fiG MYTRASIEWICZ & OSHI

policy without noise example Kaelbling, Littman Cassandra (1998) due
differences value functions.

4. Agent Types Frames
POMDP definition includes parameters permit us compute agents optimal behavior, 4
conditioned beliefs. Let us collect implementation independent factors construct
call agent type.
Definition 1 (Type). type agent is, = hbi , Ai , , Ti , Oi , Ri , OCi i, bi agent
state belief (an element (S)), OCi optimality criterion, rest elements
defined before. Let set agent types.
Given type, , assumption agent Bayesian-rational, set agents optimal
actions denoted OP (i ). next section, generalize notion type situations include interactions agents; coincides notion type used
Bayesian games (Fudenberg & Tirole, 1991; Harsanyi, 1967).
convenient define notion frame, bi , agent i:

b set
Definition 2 (Frame). frame agent is, bi = hAi , , Ti , Oi , Ri , OCi i. Let
agent frames.

brevity one write type consisting agents belief together frame: =
hbi , bi i.
context tiger game described previous section, agent type describes
agents actions results, quality agents hearing, payoffs, belief
tiger location.
Realistically, apart implementation-independent factors grouped type, agents behavior may also depend implementation-specific parameters, like processor speed, memory
available, etc. included (implementation dependent, complete) type, increasing accuracy predicted behavior, cost additional complexity. Definition use
complete types topic ongoing work.

5. Interactive POMDPs
mentioned, intention generalize POMDPs handle presence agents.
including descriptions agents (their types example) state space.
simplicity presentation, consider agent i, interacting one agent, j.
formalism easily generalizes larger number agents.
Definition 3 (I-POMDP). interactive POMDP agent i, I-POMDPi , is:
I-POMDPi = hISi , A, Ti , , Oi , Ri

(5)

4. issue computability solutions POMDPs subject much research (Papadimitriou & Tsitsiklis,
1987; Madani, Hanks, & Condon, 2003). obvious importance one uses POMDPs model agents;
return issue later.

56

fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGS

where:
ISi set interactive states defined ISi = Mj ,5 interacting agent i,
set states physical environment, Mj set possible models agent
j. model, mj Mj , defined triple mj = hhj , fj , Oj i, fj : Hj (Aj )
agent js function, assumed computable, maps possible histories js observations
distributions actions. hj element Hj , Oj function specifying way
environment supplying agent input. Sometimes write model j mj = hhj ,
b j i,

b j consists fj Oj . convenient subdivide set models two classes.
subintentional models, SMj , relatively simple, intentional models, IMj , use
notion rationality model agent. Thus, Mj = IMj SMj .
Simple examples subintentional models include no-information model fictitious play
model, history independent. no-information model (Gmytrasiewicz & Durfee,
2000) assumes agents actions executed equal probability. Fictitious
play (Fudenberg & Levine, 1998) assumes agent chooses actions according fixed
unknown distribution, original agents prior belief distribution takes form
Dirichlet distribution.6 example powerful subintentional model finite state
controller.
intentional models sophisticated ascribe agent beliefs,
preferences rationality action selection.7 Intentional models thus js types, j = hbj , bj i,
assumption agent j Bayesian-rational.8 Agent js belief probability distribution
states environment models agent i; b j (S Mi ). notion type
use coincides notion type game theory, defined consisting
agent private information relevant decision making (Harsanyi, 1967; Fudenberg
& Tirole, 1991). particular, agents beliefs private information, types involve
possibly infinitely nested beliefs others types beliefs others (Mertens & Zamir,
1985; Brandenburger & Dekel, 1993; Aumann, 1999; Aumann & Heifetz, 2002). 9 related
recursive model structures prior work (Gmytrasiewicz & Durfee, 2000). definition
interactive state space consistent notion completely specified state space put forward
Aumann (1999). Similar state spaces proposed others (Mertens & Zamir, 1985;
Brandenburger & Dekel, 1993).
= Ai Aj set joint moves agents.
Ti transition model. usual way define transition probabilities POMDPs
assume agents actions change aspect state description. case IPOMDPs, would mean actions modifying aspect interactive states, including
agents observation histories functions, or, modeled intentionally, beliefs
reward functions. Allowing agents directly manipulate agents ways, however,
violates notion agents autonomy. Thus, make following simplifying assumption:
1
5. agents, say N > 2, ISi = N
j=1 Mj
6. Technically, according notation, fictitious play actually ensemble models.
7. Dennet (1986) advocates ascribing rationality agent(s), calls assuming intentional stance towards
them.
8. Note space types far richer computable models. particular, since set computable
models countable set types uncountable, many types computable models.
9. Implicit definition interactive beliefs assumption coherency (Brandenburger & Dekel, 1993).

57

fiG MYTRASIEWICZ & OSHI

Model Non-manipulability Assumption (MNM): Agents actions change
agents models directly.
Given simplification, transition model defined : [0, 1]
Autonomy, formalized MNM assumption, precludes, example, direct mind control,
implies agents belief states changed indirectly, typically changing
environment way observable them. words, agents beliefs change, like POMDPs,
result belief update observation, direct result agents
actions.10
defined POMDP model.
Oi observation function. defining function make following assumption:
Model Non-observability (MNO): Agents cannot observe others models directly.
Given assumption observation function defined : [0, 1].
MNO assumption formalizes another aspect autonomy agents autonomous
observations functions, beliefs properties, say preferences, intentional
models, private agents cannot observe directly. 11
Ri defined Ri : ISi <. allow agent preferences physical
states models agents, usually physical state matter.
mentioned, see interactive POMDPs subjective counterpart objective external view stochastic games (Fudenberg & Tirole, 1991), also followed work
AI (Boutilier, 1999) (Koller & Milch, 2001) decentralized POMDPs (Bernstein et al.,
2002; Nair et al., 2003). Interactive POMDPs represent individual agents point view
environment agents, facilitate planning problem solving agents
individual level.
5.1 Belief Update I-POMDPs
show that, POMDPs, agents beliefs interactive states sufficient
statistics, i.e., fully summarize agents observation histories. Further, need show
beliefs updated agents action observation, solutions defined.
t1
new belief state, bti , function previous belief state, bt1
, last action, ai ,

new observation, oi , POMDPs. two differences complicate belief
update compared POMDPs. First, since state physical environment depends
actions performed agents prediction physical state changes
made based probabilities various actions agent. probabilities others
actions obtained based models. Thus, unlike Bayesian stochastic games,
assume actions fully observable agents. Rather, agents attempt infer
actions agents performed sensing results environment. Second, changes
models agents included update. reflect others observations
and, modeled intentionally, update agents beliefs. case, agent
update beliefs agent based anticipates agent observes
10. possibility agents influence observational capabilities agents accommodated
including factors change sensing capabilities set S.
11. Again, possibility agents observe factors may influence observational capabilities agents
allowed including factors S.

58

fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGS

updates. could expected, update possibly infinitely nested belief
others types is, general, asymptotically computable.
Proposition 1. (Sufficiency) interactive POMDP agent i, current belief, i.e., probability distribution set Mj , sufficient statistic past history observations.
t1
next proposition defines agent belief update function, b ti (ist ) = P r(ist |oti , at1
, bi ),
ist ISi interactive state. use belief state estimation function, SE , abt1
breviation belief updates individual states bti = SEi (bt1
, ai , oi ).
t1 t1
t1
t1
(bi , ai , oi , bi ) stand P r(bti |bi , ai , oti ). also define set
type-dependent optimal actions agent, OP (i ).

Proposition 2. (Belief Update) MNM MNO assumptions, belief update function
interactive POMDP hISi , A, Ti , , Oi , Ri i, mj ist intentional, is:
bti (ist ) =
Ti

P

t1 )
bt1
(is

ist1 :m
b t1
=bjt
j
P
t1
t1
(s , , st )
otj

P

t1
t1 , ot )
P r(at1

j |j )Oi (s ,

at1
j
t1 t1
t1 , ot )

(b
j j , aj , oj , bj )Oj (s ,
j

(6)

=m
b tj ,
mj ist subintentional first summation extends ist1 :
b t1
j
t1
t1
t1
t1 t1
P r(at1
j |j ) replaced P r(aj |mj ), jt (bj , aj , oj , bj ) replaced


Kronecker delta function K (APPEND(ht1
j , oj ), hj ).

Above, bt1
btj belief elements jt1 jt , respectively, normalizing constant,
j
t1
t1
P r(at1
Bayesian rational agent described type
j |j ) probability aj
t1
t1
1
j . probability equal |OP (j )| aj OP (j ), equal zero otherwise.
define OP Section 5.2.12 case js subintentional model, = (s, mj ), ht1

j
respectively, observation
htj observation histories part mt1
,


j
j
j
t1
t1
t1
function mtj , P r(at1
|m
)


probability
assigned




j
j
j
j . APPEND returns
string second argument appended first. proofs propositions
Appendix.
Proposition 2 Eq. 6 lot common belief update POMDPs,
expected. depend agent observation transition functions. However, since agent
observations also depend agent js actions, probabilities various actions j
included (in first line Eq. 6.) Further, since update agent js model depends
j observes, probabilities various observations j included (in second line
Eq. 6.) update js beliefs represented j term. belief update easily
generalized setting one agents co-exist agent i.
P
12. agents prior belief ISi given probability density function
ist1 replaced
:
, otj , btj ) takes form Dirac delta function argument bt1
, at1
integral. case jt (bt1
j
j
j
, otj ) btj ).
, at1
(SEjt (bt1
j
j

59

fiG MYTRASIEWICZ & OSHI

5.2 Value Function Solutions I-POMDPs
Analogously POMDPs, belief state I-POMDP associated value reflecting maximum payoff agent expect belief state:


P
P
b
ERi (is, ai )bi (is) +
U (i ) = max
P r(oi |ai , bi )U (hSEi (bi , ai , oi ), i)
(7)
ai Ai

oi



P
where, ERi (is, ai ) =
aj Ri (is, ai , aj )P r(aj |mj ). Eq. 7 basis value iteration IPOMDPs.
Agent optimal action, ai , case infinite horizon criterion discounting,
element set optimal actions belief state, OP (i ), defined as:


P
P
OP (i ) = argmax
ERi (is, ai )bi (is) +
P r(oi |ai , bi )U (hSEi (bi , ai , oi ), bi i)
ai Ai

oi



(8)
case belief update, due possibly infinitely nested beliefs, step value iteration
optimal actions asymptotically computable.

6. Finitely Nested I-POMDPs
Possible infinite nesting agents beliefs intentional models presents obvious obstacle
computing belief updates optimal solutions. Since models agents infinitely
nested beliefs correspond agent functions computable natural consider
finite nestings. follow approaches game theory (Aumann, 1999; Brandenburger & Dekel,
1993; Fagin et al., 1999), extend previous work (Gmytrasiewicz & Durfee, 2000), construct
finitely nested I-POMDPs bottom-up. Assume set physical states world S, two
agents j. Agent 0-th level beliefs, bi,0 , probability distributions S. 0-th level
types, i,0 , contain 0-th level beliefs, frames, analogously agent j. 0-level types
are, therefore, POMDPs.13 0-level models include 0-level types (i.e., intentional models)
subintentional models, elements SM . agents first level beliefs probability distributions
physical states 0-level models agent. agents first level types consist
first level beliefs frames. first level models consist types upto level 1
subintentional models. Second level beliefs defined terms first level models on.
Formally, define spaces:
ISi,0 = S,
j,0 = {hbj,0 , bj : bj,0 (ISj,0 )}, Mj,0 = j,0 SMj
ISi,1 = Mj,0 ,
j,1 = {hbj,1 , bj : bj,1 (ISj,1 )}, Mj,1 = j,1 Mj,0
.
.
.
.
.
.
ISi,l = Mj,l1 , j,l = {hbj,l , bj : bj,l (ISj,l )}, Mj,l = j,l Mj,l1
Definition 4. (Finitely Nested I-POMDP) finitely nested I-POMDP agent i, I-POMDP i,l , is:
I-POMDPi,l = hISi,l , A, Ti , , Oi , Ri
13. 0-level types agents actions folded , R functions noise.

60

(9)

fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGS

parameter l called strategy level finitely nested I-POMDP. belief update,
value function, optimal actions finitely nested I-POMDPs computed using Equation 6
Equation 8, recursion guaranteed terminate 0-th level subintentional models.
Agents strategic capable modeling others deeper levels (i.e., levels
strategy level l), always boundedly optimal. such, agents
could fail predict strategy sophisticated opponent. fact computability
agent function implies agent may suboptimal interactions pointed
Binmore (1990), proved recently Nachbar Zame (1996). Intuitively,
difficulty agents unbounded optimality would include capability model
agents modeling original agent. leads impossibility result due self-reference,
similar Godels incompleteness theorem halting problem (Brandenburger,
2002). positive note, convergence results (Kalai & Lehrer, 1993) strongly suggest
approximate optimality achievable, although applicability work remains open.
mentioned, 0-th level types POMDPs. provide probability distributions
actions agent modeled level models strategy level 1. Given probability
distributions agents actions level-1 models solved POMDPs,
provide probability distributions yet higher level models. Assume number models
considered level bound number, . Solving I-POMDP i,l equivalent
solving O(M l ) POMDPs. Hence, complexity solving I-POMDPi,l PSPACE-hard
finite time horizons,14 undecidable infinite horizons, like POMDPs.
6.1 Properties I-POMDPs
section establish two important properties, namely convergence value iteration
piece-wise linearity convexity value function, finitely nested I-POMDPs.
6.1.1 C ONVERGENCE



VALUE TERATION

agent I-POMDPi,l , show sequence value functions, {U n },
n horizon, obtained value iteration defined Eq. 7, converges unique fixed-point, U .
Let us define backup operator H : B B U n = HU n1 , B set
bounded value functions. order prove convergence result, first establish
properties H.
Lemma 1 (Isotonicity). finitely nested I-POMDP value functions V U , V U ,
HV HU .
proof lemma analogous one due Hauskrecht (1997), POMDPs.
also sketched Appendix. Another important property exhibited backup operator
property contraction.
Lemma 2 (Contraction). finitely nested I-POMDP value functions V , U discount
factor (0, 1), ||HV HU || ||V U ||.
proof lemma similar corresponding one POMDPs (Hausktecht,
1997). proof makes use Lemma 1. || || supremum norm.
14. Usually PSPACE-complete since number states I-POMDPs likely larger time horizon
(Papadimitriou & Tsitsiklis, 1987).

61

fiG MYTRASIEWICZ & OSHI

contraction property H, noting space value functions along
supremum norm forms complete normed space (Banach space), apply Contraction
Mapping Theorem (Stokey & Lucas, 1989) show value iteration I-POMDPs converges
unique fixed point (optimal solution). following theorem captures result.
Theorem 1 (Convergence). finitely nested I-POMDP, value iteration algorithm starting arbitrary well-defined value function converges unique fixed-point.
detailed proof theorem included Appendix.
case POMDPs (Russell & Norvig, 2003), error iterative estimates, U n ,
finitely nested I-POMDPs, i.e., ||U n U ||, reduced factor least iteration.
Hence, number iterations, N , needed reach error is:
N = dlog(Rmax /(1 ))/ log(1/)e

(10)

Rmax upper bound reward function.
6.1.2 P IECEWISE L INEARITY



C ONVEXITY

Another property carries POMDPs finitely nested I-POMDPs piecewise
linearity convexity (PWLC) value function. Establishing property allows us decompose I-POMDP value function set alpha vectors, represents policy
tree. PWLC property enables us work sets alpha vectors rather perform value
iteration continuum agents beliefs. Theorem 2 states PWLC property
I-POMDP value function.
Theorem 2 (PWLC). finitely nested I-POMDP, U piecewise linear convex.
complete proof Theorem 2 included Appendix. proof similar one
due Smallwood Sondik (1973) POMDPs proceeds induction. basis case
established considering horizon 1 value function. Showing PWLC inductive step
requires substituting belief update (Eq. 6) Eq. 7, followed factoring belief
terms equation.

7. Example: Multi-agent Tiger Game
illustrate optimal sequential behavior agents multi-agent settings apply I-POMDP
framework multi-agent tiger game, traditional version described before.
7.1 Definition
Let us denote actions opening doors listening OR, OL L, before. TL
TR denote states corresponding tiger located behind left right door, respectively.
transition, reward observation functions depend actions agents. Again,
assume tiger location chosen randomly next time step agents opened
doors current step. also assume agent hears tigers growls, GR GL,
accuracy 85%. make interaction interesting added observation
door creaks, depend action executed agent. Creak right, CR, likely due
62

fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGS

agent opened right door, similarly creak left, CL. Silence, S, good
indication agent open doors listened instead. assume accuracy
creaks 90%. also assume agents payoffs analogous single agent versions
described Section 3.2 make cases comparable. Note result assumption
agents actions impact original agents payoffs directly, rather indirectly
resulting states matter original agent. Table 1 quantifies factors.

hai , aj
hOL,
hOR,
h, OLi
h, ORi
hL, Li
hL, Li

State
*
*
*
*
TL
TR

TL
0.5
0.5
0.5
0.5
1.0
0

TR
0.5
0.5
0.5
0.5
0
1.0

hai , aj
hOR, ORi
hOL, OLi
hOR, OLi
hOL, ORi
hL, Li
hL, ORi
hOR, Li
hL, OLi
hOL, Li

Transition function: Ti = Tj

TL
10
-100
10
-100
-1
-1
10
-1
-100

TR
-100
10
-100
10
-1
-1
-100
-1
10

hai , aj
hOR, ORi
hOL, OLi
hOR, OLi
hOL, ORi
hL, Li
hL, ORi
hOR, Li
hL, OLi
hOL, Li

TL
10
-100
-100
10
-1
10
-1
-100
-1

TR
-100
10
10
-100
-1
-100
-1
10
-1

Reward functions agents j

hai , aj
hL, Li
hL, Li
hL, OLi
hL, OLi
hL, ORi
hL, ORi
hOL,
hOR,

State
TL
TR
TL
TR
TL
TR



h GL, CL
0.85*0.05
0.15*0.05
0.85*0.9
0.15*0.9
0.85*0.05
0.15*0.05
1/6
1/6

h GL, CR
0.85*0.05
0.15*0.05
0.85*0.05
0.15*0.05
0.85*0.9
0.15*0.9
1/6
1/6

h GL,
0.85*0.9
0.15*0.9
0.85*0.05
0.15*0.05
0.85*0.05
0.15*0.05
1/6
1/6

h GR, CL
0.15*0.05
0.85*0.05
0.15*0.9
0.85*0.9
0.15*0.05
0.85*0.05
1/6
1/6

h GR, CR
0.15*0.05
0.85*0.05
0.15*0.05
0.85*0.05
0.15*0.9
0.85*0.9
1/6
1/6

h GR,
0.15*0.9
0.85*0.9
0.15*0.05
0.85*0.05
0.15*0.05
0.85*0.05
1/6
1/6

hai , aj
hL, Li
hL, Li
hOL, Li
hOL, Li
hOR, Li
hOR, Li
h, OLi
h, ORi

State
TL
TR
TL
TR
TL
TR



h GL, CL
0.85*0.05
0.15*0.05
0.85*0.9
0.15*0.9
0.85*0.05
0.15*0.05
1/6
1/6

h GL, CR
0.85*0.05
0.15*0.05
0.85*0.05
0.15*0.05
0.85*0.9
0.15*0.9
1/6
1/6

h GL,
0.85*0.9
0.15*0.9
0.85*0.05
0.15*0.05
0.85*0.05
0.15*0.05
1/6
1/6

h GR, CL
0.15*0.05
0.85*0.05
0.15*0.9
0.85*0.9
0.15*0.05
0.85*0.05
1/6
1/6

h GR, CR
0.15*0.05
0.85*0.05
0.15*0.05
0.85*0.05
0.15*0.9
0.85*0.9
1/6
1/6

h GR,
0.15*0.9
0.85*0.9
0.15*0.05
0.85*0.05
0.15*0.05
0.85*0.05
1/6
1/6

Observation functions agents j.
Table 1: Transition, reward, observation functions multi-agent Tiger game.
agent makes choice multi-agent tiger game, considers believes
location tiger, well whether agent listen open door,
turn depends agents beliefs, reward function, optimality criterion, etc. 15 particular,
agent open doors tiger location next time step would
chosen randomly. Thus, information obtained hearing previous growls would
discarded. simplify situation considering I-POMDP single level nesting,
assuming agent js properties, except beliefs, known i, js time
horizon equal is. words, uncertainty pertains js beliefs
frame. Agent interactive state space is, ISi,1 = j,0 , physical state, S={TL,
15. assume intentional model agent here.

63

fiG MYTRASIEWICZ & OSHI

TR}, j,0 set intentional models agent js, differs js beliefs
location tiger.
7.2 Examples Belief Update
Section 5, presented belief update equation I-POMDPs (Eq. 6). consider
examples beliefs, bi,1 , agent i, probability distributions j,0 . 0-th
level type agent j, j,0 j,0 , contains flat belief location tiger,
represented single probability assignment bj,0 = pj (T L).
0.506
0.504

0.504

Pr(TL,p
Pr(TL,b_j) )
j

Pr(TL,p
Pr(TL,b_j)

j

)

0.506
0.502
0.5
0.498

0.502
0.5
0.498

0.496
0.496

0.494
0

0.2

0.4

0.6

0.8

1

0.494
0

0.2

0.4

0.6

0.8

1

0.8

1

pb_j
j (TL)

0.506

0.506

0.504

0.504

j

)

0.502

Pr(TR,p
Pr(TR,b_j)

Pr(TR,p
Pr(TR,b_j)

j

)

pjb_j
(TL)
j(TL)

0.5
0.498

0.502
0.5
0.498

0.496
0.494

0.496

0

0.2

0.4 0.6 0.8
ppb_j
(TL)
(TR)
(TL)

1
0.494

jj

0

0.2

0.4

0.6

p j (TL)
b_j

(i)

(ii)

Figure 5: Two examples singly nested belief states agent i. case information
tigers location. (i) agent knows j know location
tiger; single point (star) denotes Dirac delta function integrates height
point, 0.5 . (ii) agent uninformed js beliefs tigers location.

Fig. 5 show examples level 1 beliefs agent i. case know
location tiger marginals top bottom sections figure sum
0.5 probabilities TL TR each. Fig. 5(i), knows j assigns 0.5 probability tiger
behind left door. represented using Dirac delta function. Fig. 5(ii), agent
uninformed js beliefs. represented uniform probability density values
probability j could assign state TL.
make presentation belief update transparent decompose formula
Eq. 6 two steps:
64

fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGS

t1
Prediction: agent performs action at1
, given agent j performs aj ,
predicted belief state is:

bbt (ist ) = P r(ist |at1 , at1 , bt1 ) = P t1 bt1 bt bt1 (ist1 )P r(at1 |t1 )

j
j

j


|j =j
P
(st1 , at1 , st ) Oj (st , at1 , otj )

(11)

otj

t1
jt (bt1
j , j , j , bj )

Correction: agent perceives observation, ti , predicted belief states,
t1 t1
P r(|at1
, aj , bi ), combined according to:
bti (ist ) = P r(ist |oti , ait1 , bt1
)=

X

t1 t1
Oi (st , at1 , oti )P r(ist |at1
, j , bi )

(12)

at1
j

normalizing constant.

t1



0.496
0.494
0

0.2

0.4 0.6 0.8
pb_j(TL)

1

j

0.496
0.494
0.4 0.6 0.8
pb_j(TL)

1

0.8

1

0.7
0.6
0.5
0.4
0.3
L,<GL,S>
0.2
0.1
L,<GL,S> 0
0
0.8
1

L,<GL,S>

0

0.2

0.4

0.6

pjb_j(TL)

<GL,S>

<GL,S>
0.2

0.4

0.6

0.8

L,<GL,S>

0.1

L,<GL,S>

0.06

0.8

1

0.4 0.6 0.8
pb_j(TL)

1

0.02

0.01

0.005

0.04

L,<GL,S>
0.2

0.4

pjb_j
(TL)

0.6

pjb_j
(TL)

(b)

0.6

pjb_j(TL)

0.015

0.08

0

1

0.4

0.025

0.12

0.02
0

0.2

L,<GL,S>

0.14

0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05

j

(a)

0.6

pjb_j
(TL)

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1

j)

j)
0.4

Pr(TR,pj )

0.498

Pr(TR,b_j)

j)

Pr(TR,p
Pr(TR,b_j)

L,(L,GL)

0.5

0.2

0.2

L,(L,GR)

0.504

0

<GL,S>

0

0.506
0.502

L,<GL,S>

0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05

Pr(TL,p
Pr(TL,b_j)

L,(L,GR)

0.5
0.498

bi

Pr(TR,b_j)
Pr(TR,p
)
j

0.502

t+1

bi

<GL,S>

Pr(TL,p
Pr(TL,b_j)

0.504

Pr(TL,p
Pr(TL,b_j) )
j

Pr(TL,p
Pr(TL,b_j)

j)

0.506



bi

L,(L,GL)

Pr(TR,p
Pr(TR,b_j) )
j

bi

(c)

0.8

1

0
0

0.2

j

(d)

Figure 6: trace belief update agent i. (a) depicts prior. (b) result prediction
given listening action, L, pair denoting js action observation. knows
j listen could hear tigers growl right left, probabilities
j would assign TL 0.15 0.85, respectively. (c) result correction
observes tigers growl left creaks, hGL,Si. probability assigns
TL greater TR. (d) depicts results another update (both prediction
correction) another listen action observation, hGL,Si.
discrete point denotes, again, Dirac delta function integrates height
point.
Fig. 6, display example trace update singly nested belief. first
column Fig. 6, labeled (a), example agent prior belief introduced before, according
65

fiG MYTRASIEWICZ & OSHI

knows j uninformed location tiger. 16 Let us assume listens
hears growl left creaks. second column Fig. 6, (b), displays predicted
belief performs listen action (Eq. 11). part prediction step, agent must solve
js model obtain js optimal action belief 0.5 (term P r(a t1
j |j ) Eq. 11). Given
value function Fig. 3, evaluates probability 1 listen action, zero opening
doors. also updates js belief given j listens hears tiger growling either
t1
left, GL, right, GR, (term jt (bt1
j , aj , oj , bj ) Eq. 11). Agent js updated probabilities
tiger left 0.85 0.15, js hearing GL GR, respectively. tiger
left (top Fig. 6 (b)) js observation GL likely, consequently js assigning
probability 0.85 state TL likely (i assigns probability 0.425 state.)
tiger right j likely hear GR assigns lower probability, 0.075,
js assigning probability 0.85 tiger left. third column, (c), Fig. 6 shows
posterior belief correction step. belief column (b) updated account
hearing growl left creaks, hGL,Si. resulting marginalised probability
tiger left higher (0.85) tiger right. assume
next time step listens hears tiger growling left creaks, belief
state depicted fourth column Fig. 6 results.
Fig. 7 show belief update starting prior Fig. 5 (ii), according
agent initially information j believes tigers location.
traces belief updates Fig. 6 Fig. 7 illustrate changing state information agent
agents beliefs. benefit representing updates explicitly that,
stage, optimal behavior depends estimate probabilities js actions.
informative estimates value agent expect interaction. Below,
show increase value function I-POMDPs compared POMDPs noise factor.
7.3 Examples Value Functions
section compares value functions obtained solving POMDP static noise factor,
accounting presence another agent,17 value functions level-1 I-POMDP. advantage refined modeling update I-POMDPs due two factors. First ability
keep track agents state beliefs better predict future actions. second
ability adjust agents time horizon number steps go interaction
decreases. Neither possible within classical POMDP formalism.
continue simple example I-POMDPi,1 agent i. Fig. 8 display
value function time horizon 1, assuming initial belief value j assigns
TL, pj (T L), depicted Fig. 5 (ii), i.e. information j believes
tigers location. value function identical value function obtained agent using
traditional POMDP framework noise, well single agent POMDP described
Section 3.2. value functions overlap since agents update beliefs
advantage refined modeling agent j I-POMDP become apparent. Put
another way, agent models j using intentional model, concludes agent j open
door probability 0.1 listen probability 0.8. coincides noise factor
described Section 3.2.
16. points Fig. 7 denote Dirac delta functions integrate value equal points height.
17. POMDP noise level-0 I-POMDP.

66

fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGS

t1


bi

bi

L(L,GR)
L(L,GL)
0.5

0.5

L(L,GL)
0.4

0.4

L(L,GR)

0.2

0.5

0.3

0.2

0.498
0.1

0.1

L(L,GR)

0.496
0.494
0

0.2

0.4

0.6

0.8

0

L(OL/OR,*)

1

pjb_j(TL)

0

0.504
0.502

0.494
0

0.2

0.4

0.6

0.8

1

0.8

0

1

0

Pr(TL,b_j)

L(L,GR)

pjb_j(TL)

0.4

0.6

0.8

1

pjb_j
(TL)
0.02275
0.0227
0.02265

0.0226

0.0226

0.02255
0.0225

0.02245

0.02255
0.0225
0.02245

0.0224

0.0224

0.02235

0.02235

0.0223

L(OL/OR,*)

0.2

0.02265

Pr(TL, pj )

L(OL/OR,*)

0.496

0.6

0.0227

L(OL/OR,*)

0.498

0.4

0.02275

L(L,GL)

0.5

0.2

pjb_j
(TL)

L(L,GL)

0.506

Pr(TR,
pj )
Pr(TR,b_j)

0.3

Pr(TR,b_j)
Pr(TR,p
j)

Pr(TL,p
)
Pr(TL,b_j)
j

0.502

Pr(TR,b_j)
Pr(TR,p
j)

0.504

Pr(TL,b_j)
Pr(TL,
pj )

0.506

0.0223

0.02225

0.02225
0

0.2

0.4

0.6

0.8

1

0

pjb_j
(TL)

(a)

0.2

0.4

0.6

0.8

1

pjb_j
(TL)

(b)
<GL,S>



bi

0.3

1.8

1.6
0.25

Pr(TR,pj )

1.2

Pr(TR,b_j)

Pr(TL,p
)
Pr(TL,b_j)
j

1.4

1

0.8

0.2

0.15

0.1

0.6

0.4
0.05
0.2
0

0
0

0.2

0.4

0.6

pjb_j
(TL)

0.8

0

1

0.2

0.4

0.6

0.8

1

pj b_j
(TL)

(c)

Figure 7: trace belief update agent i. (a) depicts prior according
uninformed js beliefs. (b) result prediction step listening
action (L). top half (b) shows belief listened given j also
listened. two observations j make, GL GR, probability dependent
tigers location, give rise flat portions representing knows js belief
case. increased probability assigns js belief 0.472 0.528
due js updates hears GL hears GR resulting values
interval. bottom half (b) shows belief listened j opened
left right door (plots identical action one shown).
knows j information tigers location case. (c) result
correction observes tigers growl left creaks hGL,Si. plots (c)
obtained performing weighted summation plots (b). probability
assigns TL greater TR, information js beliefs allows refine
prediction js action next time step.

67

fiG MYTRASIEWICZ & OSHI

L


OL

10

Value Function (U)

8

6

4

2

0

0

0.2

0.4

0.6

0.8

1

pp_i(TL)
(TL)
Level 1 I-POMDP

POMDP noise

Figure 8: time horizon 1 value functions obtained solving singly nested I-POMDP
POMDP noise factor overlap.
L\();OL\(<GR,S>),L\(?)

L\();OR\(<GL,S>),L\(?)

L\();L\(<GL,*>),OL\(<GR,*>)

OL\();L\(*)

L\();L\(*)

L\();OR\(<GL,*>),L\(<GR,*>)

L\();L\(GL),OL\(GR)

L\();OR\(GL),L\(GR)

OR\();L\(*)

8

Value Function (U)

6

4

2

0

-2
0

0.2

0.4

0.6

0.8

1

pp_i(TL)
(TL)
Level 1 I-POMDP

POMDP noise

Figure 9: Comparison value functions obtained solving I-POMDP POMDP
noise time horizon 2. I-POMDP value function dominates due agent adjusting
behavior agent j remaining steps go interaction.

68

fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGS

8

Value Function (U)

7
6
5
4
3
2
1
0

0.2

0.4

0.6

0.8

1

p (TL)
p_i(TL)
Level 1 I-POMDP

POMDP noise

Figure 10: Comparison value functions obtained solving I-POMDP POMDP
noise time horizon 3. I-POMDP value function dominates due agent adjusting js remaining steps go, due modeling js belief update. factors
allow better predictions js actions interaction. descriptions individual policies omitted clarity; read Fig. 11.

Fig. 9 display value functions time horizon 2. value function
I-POMDPi,1 higher value function POMDP noise factor. reason
related advantages modeling agent js beliefs effect becomes apparent time
horizon 3 longer. Rather, I-POMDP solution dominates due agent modeling js time
horizon interaction: knows last time step j behave according optimal
policy time horizon 1, two steps go j optimize according 2 steps go
policy. mentioned, effect cannot modeled using POMDP static noise factor
included transition function.
Fig. 10 shows comparison I-POMDP noisy POMDP value functions
horizon 3. advantage refined agent modeling within I-POMDP framework
increased.18 factors, adjusting js steps go modeling js belief update
interaction responsible superiority values achieved using I-POMDP. particular,
recall second time step information js beliefs tigers location
depicted Fig. 7 (c). enables make high quality prediction that, two steps left
go, j perform actions OL, L, probabilities 0.009076, 0.96591 0.02501,
respectively (recall POMDP noise probabilities remained unchanged 0.1, 0,8,
0.1, respectively.)
Fig. 11 shows agent policy graph time horizon 3. usual, prescribes optimal
first action depending initial belief tigers location. subsequent actions depend
observations received. observations include creaks indicative agents
18. Note I-POMDP solution good solution POMDP agent operating alone environment shown Fig. 3.

69

fiG MYTRASIEWICZ & OSHI

[0 0.029)
OL

[0.029 0.089)

[0.089 0.211)

L
*

L

<GR,S>

<GL,CL/CR>
<GR,*>

[0.211 0.789)

[0.789 0.911)

L

*

OL


*

<GR,S>
<GL,CL\CR>

L

L
<GR,*>

[0.971 1]

L

<GR,CL\CR>
<GR,CL\CR>
<GL,CL\CR>
<GL,S>
<GR,*> <GL,*>
<GL,*>
<GR,S>
<GL,S>

<GL,S>
<GR,CL\CR>

OL

[0.911 0.971)

L

<GL,*>

L
*

<GR,*>


<GL,*>

*



L

Figure 11: policy graph corresponding I-POMDP value function Fig. 10.
opened door. creaks contain valuable information allow agent make
refined choices, compared ones noisy POMDP Fig. 4. Consider case agent
starts fairly strong belief tigers location, decides listen (according four
off-center top row L nodes Fig. 11) hears door creak. agent position
open either left right door, even counter initial belief. reason
creak indication tigers position likely reset agent j j
open doors following two time steps. Now, two growls coming
door lead enough confidence open door. agent hearing
tigers growls indicative tigers position state following agents actions,
Note value functions policy depict special case agent
information probability j assigns tigers location (Fig. 5 (ii)). Accounting
visualizing possible beliefs js beliefs difficult due complexity
space interactive beliefs. ongoing work indicates, drastic reduction complexity
possible without loss information, consequently representation solutions manageable
number dimensions indeed possible. report results separately.

8. Conclusions
proposed framework optimal sequential decision-making suitable controlling autonomous
agents interacting agents within uncertain environment. used normative
paradigm decision-theoretic planning uncertainty formalized partially observable Markov
decision processes (POMDPs) point departure. extended POMDPs cases agents
interacting agents allowing beliefs physical environment, also agents. could include beliefs others abilities, sensing
capabilities, beliefs, preferences, intended actions. framework shares numerous properties
POMDPs, analogously defined solutions, reduces POMDPs agents alone
environment.
contrast recent work DEC-POMDPs (Bernstein et al., 2002; Nair et al., 2003),
work motivated game-theoretic equilibria (Boutilier, 1999; Hu & Wellman, 1998; Koller
70

fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGS

& Milch, 2001; Littman, 1994), approach subjective amenable agents independently
computing optimal solutions.
line work presented opens area future research integrating frameworks
sequential planning elements game theory Bayesian learning interactive settings.
particular, one avenues future research centers proving formal properties
I-POMDPs, establishing clearer relations solutions I-POMDPs various flavors
equilibria. Another concentrates developing efficient approximation techniques solving
I-POMDPs. POMDPs, development approximate approaches I-POMDPs crucial
moving beyond toy problems. One promising approximation technique working particle
filtering. also devising methods representing I-POMDP solutions without assumptions
whats believed agents beliefs. mentioned, spite complexity
interactive state space, seem intuitive representations belief partitions corresponding
optimal policies, analogous POMDPs. research issues include suitable
choice priors models,19 ways fulfill absolute continuity condition needed
convergence probabilities assigned alternative models interactions (Kalai & Lehrer,
1993).

Acknowledgments
research supported National Science Foundation CAREER award IRI-9702132,
NSF award IRI-0119270.

Appendix A. Proofs
Proof Propositions 1 2. start Proposition 2, applying Bayes Theorem:

t1
bti (ist ) = P r(ist |oti , at1
, bi ) =

)
,bt1
P r(ist ,oti |at1


t1 t1

P r(oi |ai ,bi )

P
t1 )
= ist1 bit1 (ist1 )P r(ist , oti |at1
,
P
P
t1
t1 )P r(at1 |at1 , ist1 )
= ist1 bit1 (ist1 ) at1 P r(ist , oti |at1
, aj ,
j

j
P
P
(13)
t1
t1 )P r(at1 |ist1 )
,

,

= ist1 bit1 (ist1 ) at1 P r(ist , oti |at1
j
j

j
P
P
t1

t1 , ist1 )P r(ist |at1 , ist1 )
= ist1 bit1 (ist1 ) at1 P r(at1
j |mj )P r(ot |is ,
j
P
P
t1

t1 )P r(ist |at1 , ist1 )
= ist1 bit1 (ist1 ) at1 P r(at1
j |mj )P r(ot |is ,
j
P
P
t1
t1 , ot )P r(ist |at1 , ist1 )
= ist1 bit1 (ist1 ) at1 P r(at1

j |mj )Oi (s ,
j

19. looking Kolmogorov complexity (Li & Vitanyi, 1997) possible way assign priors.

71

fiG MYTRASIEWICZ & OSHI

simplify term P r(ist |at1 , ist1 ) let us substitute interactive state ist components. mj interactive states intentional: ist = (st , jt ) = (st , btj , bjt ).

P r(ist |at1 , ist1 ) = P r(st , btj , bjt |at1 , ist1 )
= P r(btj |st , bjt , at1 , ist1 )P r(st , bjt |at1 , ist1 )
= P r(btj |st , bjt , at1 , ist1 )P r(bjt |st , at1 , ist1 )P r(st |at1 , ist1 )
= P r(btj |st , bjt , at1 , ist1 )I(bjt1 , bjt )Ti (st1 , at1 , st )
(14)
b tj ).
mj subintentional: ist = (st , mtj ) = (st , htj ,

P r(ist |at1 , ist1 ) = P r(st , htj ,
b tj |at1 , ist1 )
b tj |at1 , ist1 )
b tj , at1 , ist1 )P r(st ,
= P r(htj |st ,
b tj , at1 , ist1 )P r(bjt |st , at1 , ist1 )P r(st |at1 , ist1 )
= P r(htj |st ,


= P r(hj |s ,
b tj , at1 , ist1 )I(m
b tj )Ti (st1 , at1 , st )
b t1
(14)
j ,m

joint action pair, at1 , may change physical state. third term right-hand
side Eqs. 14 140 captures transition. utilized MNM assumption replace
second terms equations boolean identity functions, I( bjt1 , bjt ) I(m
b t1
b tj )
j ,m
respectively, equal 1 two frames identical, 0 otherwise. Let us turn attention
first terms. mj ist ist1 intentional:
P
P r(btj |st , bjt , at1 , ist1 ) = ot P r(btj |st , bjt , at1 , ist1 , otj )P r(otj |st , bjt , at1 , ist1 )
Pj
= ot P r(btj |st , bjt , at1 , ist1 , otj )P r(otj |st , bjt , at1 )
Pj
t1
t1 , ot )
= ot jt (bt1
j
j , aj , oj , bj )Oj (st ,

(15)

j

Else subintentional:

P r(htj |st ,
b tj , at1 , ist1 ) =

=

=

P



Po j


Po j
otj

b tj , at1 , ist1 )
b tj , at1 , ist1 , otj )P r(otj |st ,
P r(htj |st ,

b tj , at1 )
b tj , at1 , ist1 , otj )P r(otj |st ,
P r(htj |st ,



t1 , ot )
K (APPEND(ht1
j
j , oj ), hj )Oj (st ,

(15)

t1
Eq. 15, first term right-hand side 1 agent js belief update, SE j (bt1
j , j , oj )
generates belief state equal btj . Similarly, Eq. 150 , first term 1 appending otj
ht1
results htj . K Kronecker delta function. second terms right-hand
j
side equations, MNO assumption makes possible replace P r(o |st , bt , at1 )
j

j

Oj (st , at1 , otj ), P r(otj |st ,
b tj , at1 ) Oj (st , at1 , otj ) respectively.
Let us substitute Eq. 15 Eq. 14.
P
t1
t1 , ot )I(
bt1 , bt )Ti (st1 , at1 , st )
P r(ist |at1 , ist1 ) = ot jt (bt1
j
j
j , aj , oj , bj )Oj (s ,
j
j
(16)
0
0
Substituting Eq. 15 Eq. 14 get,
P


t1 , ot )I(m
P r(ist |at1 , ist1 ) = ot K (APPEND(ht1
b t1
b tj )
j
j , oj ), hj )Oj (s ,
j ,m
j

Ti (st1 , at1 , st )

(16)

72

fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGS

Replacing Eq. 16 Eq. 13 get:
P
P
t1
t1
t1 )
P r(at1
|jt1 )Oi (st , at1 , oti ) ot jt (bt1
ist1 bi (is
j , j , j , bj )
j
at1
j
j
Oj (st , at1 , otj )I(bjt1 , bjt )Ti (st1 , at1 , st )

bti (ist ) =

P

(17)

Similarly, replacing Eq. 160 Eq. 13 get:

P
P
t1
t1 , ot )
t1 )
P r(at1
bti (ist ) = ist1 bt1

j |mj )Oi (s ,
(is
at1
j
P
t1
t1


t1

bj ,m
b tj )Ti (st1 , at1 , st )
ot K (APPEND(hj , oj ), hj )Oj (s , , oj )I(m
j

arrive final expressions belief update removing terms
I(m
b t1
b tj ) changing scope first summations.
j ,m
mj interactive states intentional:

I( bjt1 , bjt )

P
P
t1
t1 , ot )
bt1 (ist1 ) at1 P r(at1
bti (ist ) = ist1 :m

j |j )Oi (s ,
b t1
=bjt
j
j
P
t1 t1
t1
t1


t1

ot jt (bj , aj , oj , bj )Oj (s , , oj )Ti (s , , )

(170 )


(18)

j

Else, subintentional:
P
P
t1
t1
t1 , ot )
(ist1 ) at1 P r(at1
bti (ist ) = ist1 :m
bi

j |mj )Oi (s ,
=

b
b t1
j
j
j
P
), ht )O (st , at1 , ot )T (st1 , at1 , st )
,

ot K (APPEND(ht1
j
j
j
j
j

(19)

j

Since proposition 2 expresses belief bti (ist ) terms parameters previous time step
only, Proposition 1 holds well.
present proof Theorem 1 note Equation 7, defines value
iteration I-POMDPs, rewritten following form, U n = HU n1 . Here, H : B B
backup operator, defined as,
HU n1 (i ) = max h(i , ai , U n1 )
ai Ai

h : Ai B R is,
h(i , ai , U ) =

P


bi (is)ERi (is, ai ) +

P

oi

P r(oi |ai , bi )U (hSEi (bi , ai , oi ), i)

B set bounded value functions U . Lemmas 1 2 establish important
properties backup operator. Proof Lemma 1 given below, proof Lemma 2 follows
thereafter.
Proof Lemma 1. Select arbitrary value functions V U V ( i,l ) U (i,l ) i,l
i,l . Let i,l arbitrary type agent i.
73

fiG MYTRASIEWICZ & OSHI





P

P

HV (i,l ) = max
oi P r(oi |ai , bi )V (hSEi,l (bi , ai , oi ), i)
bi (is)ERi (is, ai ) +
ai Ai
P
P
= bi (is)ERi (is, ai ) + oi P r(oi |ai , bi )V (hSEi,l (bi , ai , oi ), i)
P
P



b
(is)ERi (is, ai ) +
oi P r(oi |ai , bi )U (hSEi,l (bi , ai , oi ), i)

P
P
max
oi P r(oi |ai , bi )U (hSEi,l (bi , ai , oi ), i)
bi (is)ERi (is, ai ) +
ai Ai

= HU (i,l )

Since i,l arbitrary, HV HU .
Proof Lemma 2. Assume two arbitrary well defined value functions V U V U .
Lemma 1 follows HV HU . Let i,l arbitrary type agent i. Also, let ai
action optimizes HU (i,l ).
0 HU (i,l ) HV (i,l )



P

= max sumis bi (is)ERi (is, ai ) + oi P r(oi |ai , bi )U (SEi,l (bi , ai , oi ), hi i)
ai Ai

P
P
max
bi (is)ERi (is, ai ) +
oi P r(oi |ai , bi )V (SEi,l (bi , ai , oi ), hi i)
ai Ai
P
P
bi (is)ERi (is, ai ) + oi P r(oi |ai , bi )U (SEi,l (bi , ai , oi ), hi i)
P
P



oi P r(oi |ai , bi )V (SEi,l (bi , ai , oi ), hi i)
bi (is)ERi (is, ai )
P


= oi P r(oi |ai , bi )U (SEi,l (bi , ai , oi ), hi i)
P

oi P r(oi |ai , bi )V (SE

i,l (bi , ai , oi ), hi i)
P



= oi P r(oi |ai , bi ) U (SEi,l (bi , ai , oi ), hi i) V (SEi,l (bi , ai , oi ), hi i)
P
oi P r(oi |ai , bi )||U V ||
= ||U V ||

supremum norm symmetrical, similar result derived HV ( i,l ) HU (i,l ).
Since i,l arbitrary, Contraction property follows, i.e. ||HV HU || ||V U ||.
Lemmas 1 2 provide stepping stones proving Theorem 1. Proof Theorem 1 follows
straightforward application Contraction Mapping Theorem. state Contraction
Mapping Theorem (Stokey & Lucas, 1989) below:
Theorem 3 (Contraction Mapping Theorem). (S, ) complete metric space :
contraction mapping modulus ,
1. exactly one fixed point U S,
2. sequence {U n } converges U .
Proof Theorem 1 follows.
74

fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGS

Proof Theorem 1. normed space (B, || ||) complete w.r.t metric induced supremum norm. Lemma 2 establishes contraction property backup operator, H. Using Theorem 3, substituting H, convergence value iteration I-POMDPs unique fixed
point established.
go piecewise linearity convexity (PWLC) property value function.
follow outlines analogous proof POMDPs (Hausktecht, 1997; Smallwood &
Sondik, 1973).
Let : R real-valued bounded function. Let space real-valued
bounded functions B(IS). define inner product.
Definition 5 (Inner product). Define inner product, h, : B(IS) (IS) R,
X
h, bi =
bi (is)(is)


next lemma establishes bilinearity inner product defined above.
Lemma 3 (Bilinearity). s, R, f, g B(IS), b, (IS) following equalities
hold:
hsf + tg, bi = shf, bi + thg, bi
hf, sb + ti = shf, bi + thf,
ready give proof Theorem 2. Theorem 4 restates Theorem 2 mathematically, proof follows thereafter.
Theorem 4 (PWLC). value function, U n , finitely nested I-POMDP piece-wise linear
convex (PWLC). Mathematically,
U n (i,l ) = max
n


X

bi (is)n (is)

n = 1, 2, ...



Proof Theorem 4. Basis Step: n = 1
Bellmans Dynamic Programming equation,
U 1 (i ) = max
ai

X

bi (is)ER(is, ai )

(20)



P
ERi (is, ai ) = aj R(is, ai , aj )P r(aj |mj ). Here, ERi () represents expectation
R w.r.t. agent js actions. Eq. 20 represents inner product using Lemma 3, inner product
linear bi . selecting maximum set linear vectors (hyperplanes), obtain PWLC
horizon 1 value function.
Inductive Hypothesis: Suppose U n1 (i,l ) PWLC. Formally have,
U n1 (i,l ) = max
n1

=

P

max

n1 ,

bi (is)

n1



P

n1 (is)

is:mj IMj bi

(is)n1 (is)
75

+

P

is:mj SMj bi

(is)n1 (is)



(21)

fiG MYTRASIEWICZ & OSHI

Inductive Proof: show U n (i,l ) PWLC.

U n (i,l ) = max
at1


(

X

t1
bt1
)ERi (ist1 , at1
(is
)+

X

t1
n1
P r(oti |at1
(i,l )
, bi )U

oti

ist1

inductive hypothesis:
(
P
t1
t1 )ER (ist1 , at1 )
U n (i,l ) = max

ist1 bi (is

at1


+

P

oti

t1
P r(oti |at1
, bi )

max

n1 n1

P


n1 (ist )
ist bi (is )

)

)

t1
t1 t1

Let l(bt1
, ai , oi ) index alpha vector maximizes value b = SE(bi , ai , oi ).
Then,
(
P
t1
t1 )ER (ist1 , at1 )
U n (i,l ) = max

ist1 bi (is

t1
ai
)
P
P
t1

n1
+ ot P r(oti |at1
ist bi (is )l(bt1 ,at1 ,ot )
, bi )








second equation inductive hypothesis:
(
P
P
t1
t1 )ER (ist1 , at1 ) +
n
t1 t1
U (i,l ) = max

ot P r(oi |ai , bi )
ist1 bi (is

at1








P


n1
ist :mtj IMj bi (is )l(bt1 ,at1 ,ot )




+

P


n1
ist :mtj SMj bi (is )l(bt1 ,at1 ,ot )




Substituting bti appropriate belief updates Eqs. 17 17 0 get:
(
P
P
t1
t1 t1
t1 )ER (ist1 , at1 ) +
U n (i,l ) = max

oti P r(oi |ai , bi )
ist1 bi (is

t1
ai
"


P
P
P
t1
t1 t1
t1

)
P r(aj |j ) Oi (st , at1 , oti )
ist :mtj IMj
ist1 bi (is
at1
j


P
t1 t1
t1


t1


t1
t1

ot Oj (s , , oj ) jt (bj , aj , oj , bj )I(bj , bj )Ti (s , , )

)

j

n1

l(b
t1 t1 (is )
,ai ,oi )



P
P
P
t1
t1
t1
t1
+ ist :mt SMj ist1 bi (is )
P r(aj |mj ) Oi (st , at1 , oti )
at1
j
j


P
t1
t1


t1



t1
t1

ot Oj (s , , oj ) K (APPEND(hj , oj ) hj )I(m
bj ,m
b j )Ti (s , , )
j
#)
n1

l(b
t1 t1 (is )
,a
,o )






76

fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGS


U n (i,l ) = max
at1





P

P

(

P

t1
t1 )ER (ist1 , at1 )

ist1 bi (is


t1
t1 )
ist1 bi (is



t1 , ot )
j
otj Oj (s ,

P



at1
j

+

P

oti

"

P

ist :mtj IMj


t1
P r(at1
|
)
Oi (st , at1 , oti )
j
j

t1
t1 , at1 , st )
bt1 bt
jt (bt1
j , aj , oj , bj )I(j , j )Ti (s



n1

l(b
t1 t1 (is )
,ai ,oi )



P
P
P
t1
t1
t1
t1
P r(aj |mj ) Oi (st , at1 , oti )
+ ist :mt SMj ist1 bi (is )
at1
j
j


P
t1
) ht )I(m
)T (st1 , at1 , st )
ot Ojt (st , at1 , otj ) K (APPEND(ht1
,

b
,

b
j
j
j
j
j
j
#)
n1

l(b
t1 t1 (is )
,a
,o )






Rearranging terms equation:
U n (

(


P
P P
t1
t1 ) ER (ist1 , at1 ) +
)
=
max
b
(is
t1
t1 :m

i,l
oti
ist :mtj IMj



IM
j
j
at1



P
P
t1 t1

P r(aj |j ) Oi (st , at1 , oti ) ot Ojt (st , at1 , otj )
at1
j
j



n1
t1 t1
t1

t1
t1


jt (bj , aj , oj , bj )I(bj , bj )Ti (s , , )
l(bt1 ,at1 ,ot ) (is )




P
P
P
P
+ ist1 :mt1 SMj bit1 (ist1 ) ERi (ist1 , at1
oti
ist :mtj SMj
oti
)+
j


P
P
P r(ajt1 |mt1
) Oi (st , at1 , oti ) ot Ojt (st , at1 , otj )

j
at1
j
j

)

n1



l(b
b t1
b tj )Ti (st1 , at1 , st )
K (APPEND(ht1
t1 t1 (is )
j ,m
j , oj ) hj )I(m
,ai ,oi )


P
t1
t1 )n (ist1 )
= max
ai
IMj bi (is
ist1 :mt1
j
at1


P
t1
t1
t1
n
+ ist1 :mt1 SMj bi (is )ai (is )
j

Therefore,
U n (

i,l )

= max
n
n
,

+
=

P



P

t1
t1 )n (ist1 )
ist1 :mt1
IMj bi (is
j



t1
t1 )n (ist1 )
SMj bi (is
ist1 :mt1
j
P
t1
t1 )n (ist1 ) = maxhbt1 , n
max
ist1 bi (is

n

n

77

(22)

fiG MYTRASIEWICZ & OSHI

where, mjt1 ist1 intentional n = n :
n (ist1 )

ERi (ist1 , at1
)



P P

P

t1
P r(at1
j |j )



Oi (ist , at1 , oti )
+ ot ist :mt IMj
at1
j
j


P
t1 t1
t1


t1


t1
t1

ot Oj (isj , , oj ) jt (bj , aj , oj , bj )I(bj , bj )Ti (s , , )

=

j

n1

l(b
t1 t1 (is )
,o )
,a






and, mjt1 subintentional n = n :
n (ist1 )

ERi (ist1 , at1
)



P P

P

t1
P r(at1
j |j )



Oi (ist , at1 , oti )
+ ot ist :mt SMj
at1

j
j


P
t1
t1
t1
t1



t1



bj ,m
b j )Ti (s , , )
ot Oj (isj , , oj ) K (APPEND(hj , oj ) hj )I(m

=

j

n1

l(b
t1 t1 (is )
,ai ,oi )


Eq. 22 inner product using Lemma 3, value function linear b t1
. Furthermore,
maximizing set linear vectors (hyperplanes) produces piecewise linear convex value
function.

References
Ambruster, W., & Boge, W. (1979). Bayesian game theory. Moeschlin, O., & Pallaschke, D. (Eds.), Game
Theory Related Topics. North Holland.
Aumann, R. J. (1999). Interactive epistemology i: Knowledge. International Journal Game Theory, pp.
263300.
Aumann, R. J., & Heifetz, A. (2002). Incomplete information. Aumann, R., & Hart, S. (Eds.), Handbook
Game Theory Economic Applications, Volume III, Chapter 43. Elsevier.
Battigalli, P., & Siniscalchi, M. (1999). Hierarchies conditional beliefs interactive epistemology
dynamic games. Journal Economic Theory, pp. 188230.
Bernstein, D. S., Givan, R., Immerman, N., & Zilberstein, S. (2002). complexity decentralized control
markov decision processes. Mathematics Operations Research, 27(4), 819840.
Binmore, K. (1990). Essays Foundations Game Theory. Blackwell.
Boutilier, C. (1999). Sequential optimality coordination multiagent systems. Proceedings
Sixteenth International Joint Conference Artificial Intelligence, pp. 478485.
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial intelligence Research, 11, 194.
Brandenburger, A. (2002). power paradox: recent developments interactive epistemology.
Tech. rep., Stern School Business, New York University, http://pages.stern.nyu.edu/ abranden/.
Brandenburger, A., & Dekel, E. (1993). Hierarchies beliefs common knowledge. Journal Economic
Theory, 59, 189198.
Dennett, D. (1986). Intentional systems. Dennett, D. (Ed.), Brainstorms. MIT Press.
Fagin, R. R., Geanakoplos, J., Halpern, J. Y., & Vardi, M. Y. (1999). hierarchical approach modeling
knowledge common knowledge. International Journal Game Theory, pp. 331365.
Fagin, R. R., Halpern, J. Y., Moses, Y., & Vardi, M. Y. (1995). Reasoning Knowledge. MIT Press.
Fudenberg, D., & Levine, D. K. (1998). Theory Learning Games. MIT Press.
78

fiA F RAMEWORK EQUENTIAL P LANNING ULTI -AGENT ETTINGS

Fudenberg, D., & Tirole, J. (1991). Game Theory. MIT Press.
Gmytrasiewicz, P. J., & Durfee, E. H. (2000). Rational coordination multi-agent environments. Autonomous Agents Multiagent Systems Journal, 3(4), 319350.
Harsanyi, J. C. (1967). Games incomplete information played Bayesian players. Management
Science, 14(3), 159182.
Hauskrecht, M. (2000). Value-function approximations partially observable markov decision processes.
Journal Artificial Intelligence Research, pp. 3394.
Hausktecht, M. (1997). Planning control stochastic domains imperfect information. Ph.D. thesis,
MIT.
Hu, J., & Wellman, M. P. (1998). Multiagent reinforcement learning: Theoretical framework algorithm. Fifteenth International Conference Machine Learning, pp. 242250.
Kadane, J. B., & Larkey, P. D. (1982). Subjective probability theory games. Management Science,
28(2), 113120.
Kaelbling, L. P., Littman, M. L., & Cassandra, A. R. (1998). Planning acting partially observable
stochastic domains. Artificial Intelligence, 101(2), 99134.
Kalai, E., & Lehrer, E. (1993). Rational learning leads nash equilibrium. Econometrica, pp. 12311240.
Koller, D., & Milch, B. (2001). Multi-agent influence diagrams representing solving games. Seventeenth International Joint Conference Artificial Intelligence, pp. 10271034, Seattle, Washington.
Li, M., & Vitanyi, P. (1997). Introduction Kolmogorov Complexity Applications. Springer.
Littman, M. L. (1994). Markov games framework multi-agent reinforcement learning. Proceedings
International Conference Machine Learning.
Lovejoy, W. S. (1991). survey algorithmic methods partially observed markov decision processes.
Annals Operations Research, 28(1-4), 4766.
Madani, O., Hanks, S., & Condon, A. (2003). undecidability probabilistic planning related
stochastic optimization problems. Artificial Intelligence, 147, 534.
Mertens, J.-F., & Zamir, S. (1985). Formulation Bayesian analysis games incomplete information.
International Journal Game Theory, 14, 129.
Monahan, G. E. (1982). survey partially observable markov decision processes: Theory, models,
algorithms. Management Science, 116.
Myerson, R. B. (1991). Game Theory: Analysis Conflict. Harvard University Press.
Nachbar, J. H., & Zame, W. R. (1996). Non-computable strategies discounted repeated games. Economic
Theory, 8, 103122.
Nair, R., Pynadath, D., Yokoo, M., Tambe, M., & Marsella, S. (2003). Taming decentralized pomdps: Towards
efficient policy computation multiagent settings. Proceedings Eighteenth International
Joint Conference Artificial Intelligence (IJCAI-03).
Ooi, J. M., & Wornell, G. W. (1996). Decentralized control multiple access broadcast channel.
Proceedings 35th Conference Decision Control.
Papadimitriou, C. H., & Tsitsiklis, J. N. (1987). complexity markov decision processes. Mathematics
Operations Research, 12(3), 441450.
Russell, S., & Norvig, P. (2003). Artificial Intelligence: Modern Approach (Second Edition). Prentice Hall.
Smallwood, R. D., & Sondik, E. J. (1973). optimal control partially observable markov decision
processes finite horizon. Operations Research, pp. 10711088.
Stokey, N. L., & Lucas, R. E. (1989). Recursive Methods Economic Dynamics. Harvard Univ. Press.

79

fi
