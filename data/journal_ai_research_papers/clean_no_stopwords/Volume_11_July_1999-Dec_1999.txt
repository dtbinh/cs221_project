Journal Artificial Intelligence Research 11 (1999) 199-240Submitted 7/98; published 9/99Unifying Class-Based Representation Formalismscalvanese@dis.uniroma1.itlenzerini@dis.uniroma1.itnardi@dis.uniroma1.itDiego CalvaneseMaurizio LenzeriniDaniele NardiDipartimento di Informatica e SistemisticaUniversita di Roma \La Sapienza"Via Salaria 113, I-00198 Roma, ItalyAbstractnotion class ubiquitous computer science central many formalismsrepresentation structured knowledge used knowledge representationdatabases. paper study basic issues underlying representation formalisms single common characteristics distinguishing features.investigation leads us propose unifying framework able capture fundamental aspects several representation languages used different contexts.proposed formalism expressed style description logics,introduced knowledge representation means provide semantically well-foundedbasis structural aspects knowledge representation systems. description logicconsidered paper subset first order logic nice computational characteristics. quite expressive features novel combination constructsstudied before. distinguishing constructs number restrictions, generalize existence functional dependencies, inverse roles, allow one refer inverserelationship, possibly cyclic assertions, necessary capturing real worlddomains. able show precisely combination constructs makeslogic powerful enough model essential set features defining class structurescommon frame systems, object-oriented database languages, semantic datamodels. consequence established correspondences, several significant extensionsformalisms become available. high expressiveness logicpropose need capturing reasoning different contexts forces us distinguish unrestricted finite model reasoning. notable feature proposalreasoning cases decidable. argue that, virtue high expressivepower associated reasoning capabilities unrestricted finite models,logic provides common core class-based representation formalisms.1. Introductionmany fields computer science find formalisms representation objectsclasses (Motschnig-Pitrik & Mylopoulous, 1992). Generally speaking, object denoteselement domain interest, class denotes set objects common characteristics. use term \class-based representation formalism" refer formalismallows one express several kinds relationships constraints (e.g., subclass constraints) holding among classes meaningful set applications. Moreover,class-based formalisms aim taking advantage class structure order providevarious information, whether class consistent, i.e., admits least one object,whether class subclass another class, generally, whether given constraintc 1999 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiCalvanese, Lenzerini, & Nardiholds given set classes. characterization, clearformalisms referred paper deal structural aspects objectsclasses, include features specification behavioral propertiesobjects.Three main families class-based formalisms identified paper. first onecomes knowledge representation particular work semantic networksframes (see example Lehmann, 1992; Sowa, 1991). second one originatesfield databases particular work semantic data models (seeexample Hull & King, 1987). third one arises work types programminglanguages object-oriented systems (see example Kim & Lochovsky, 1989).past several attempts establish relationships among variousfamilies class-based formalisms (see Section 6 brief survey). proposed solutionsfully general formalism capturing modeling constructsreasoning techniques families still missing. paper addressproblem proposing class-based representation formalism, based description logics(Brachman & Levesque, 1984; Schmidt-Schau & Smolka, 1991; Donini, Lenzerini, Nardi,& Schaerf, 1996), using comparing formalisms.description logics, structured knowledge described means called conceptsroles, denote unary binary predicates, respectively. Starting setatomic symbols one build complex concept role expressions applying suitableconstructors characterize description logic. Formally, concepts interpretedsubsets domain roles binary relations domain, constructsequipped precise set-theoretic semantics. common constructs includeboolean operations concepts, quantification roles. example, conceptPerson u 8child.Male, denotes set individuals instances conceptPerson connected role child instances concept Male,concept 9child denotes individuals connected role childindividual. constructs considered important includegeneral forms quantification, number restrictions, allow one state limitsnumber connections individual may via certain role, constructsroles, intersection, concatenation inverse. description logic knowledge base,expressing intensional knowledge modeled domain, built stating inclusionassertions concepts, satisfied models knowledge base.assertions used specify necessary and/or necessary sucient conditionsindividuals instances certain concepts. Reasoning knowledge bases includesdetection inconsistencies knowledge base itself, determining whether conceptpopulated model knowledge base, checking subsumption, i.e., whetherinstances concept necessarily also instances another concept modelsknowledge base.paper propose description logic called aluni, quite expressiveincludes novel combination constructs, including number restrictions, inverse roles,inclusion assertions restrictions cycles. features make aluni powerfulenough provide unified framework frame systems, object-oriented languages,semantic data models. show establishing precise correspondence framebased language style one proposed Fikes Kehler (1985),200fiUnifying Class-Based Representation FormalismsEntity-Relationship model (Chen, 1976), object-oriented language styleone introduced Abiteboul Kanellakis (1989). specifically, identifyrelevant features model classes cited settings showspecification class-based formalisms equivalently expressedknowledge base aluni. way, able identify commonalitiesamong families specificities family. Therefore, even thoughspecific features every family addressed aluni, ableshow formalism proposed paper provides important featurescurrently missing family, although relevance often stressed.sense, unifying framework points possible developments languages belongingthree families.One fundamental reason regarding aluni unifying framework class-basedrepresentation formalisms reasoning aluni hard, nonetheless decidable,shown Calvanese, Lenzerini, Nardi (1994), Calvanese (1996c). Consequently,language features arising different frameworks build class-based representationsgiven common semantic account, combined expressive settingone retains capability solving reasoning tasks. combination constructsincluded language makes necessary distinguish reasoning respectfinite models, i.e., models finite domain, reasoning respect unrestrictedmodels. Calvanese (1996c) devises suitable techniques unrestricted finite modelreasoning, enable reasoning different contexts arising assuming finitedomain, often case field databases, assuming domain alsoinfinite. paper, discuss results reasoning aluni, compareresults reasoning class-based representation formalisms.Summarizing, framework provides adequate expressive power accountsignificant features major families class-based formalisms. Moreover,equipped suitable techniques reasoning finite unrestricted models.Therefore, believe aluni captures essential core class-based representationformalisms belonging three families mentioned above.paper organized follows. next section present formalismSections 3, 4, 5 discuss three families class-based formalisms, namely, framelanguages, semantic data models, object-oriented data models, showing basicfeatures captured knowledge bases aluni. final sections contain reviewrelated work, including discussion reasoning aluni class-based formalism,concluding remarks.2. Unifying Class-Based Representation Languagesection, present aluni, class-based formalism style description logics(DLs) (Brachman & Levesque, 1984; Schmidt-Schau & Smolka, 1991; Donini et al., 1996;Donini, Lenzerini, Nardi, & Nutt, 1997). DLs domain interest modeled meansconcepts roles, denote classes binary relations, respectively. Generallyspeaking, DL formed three basic components:description language, specifies construct complex concept roleexpressions (also called simply concepts roles), starting set atomic201fiCalvanese, Lenzerini, & NardiConstructatomic conceptatomic negationconjunctiondisjunctionuniversal quantificationnumber restrictionsatomic roleinverse roleSyntax:AC1 u C2C1 C28R.C9nR9nRPPSemanticsAIn AIC1I \ C2IC1I [ C2Ifo j 8o0 . (o; o0 ) 2 RI ! o0 2 C gfo j ]fo0 j (o; o0 ) 2 RI g ng1fo j ]fo0 j (o; o0 ) 2 RI g ngPf(o; o0 ) j (o0 ; o) 2 P gTable 1: Syntax semantics ALUNIsymbols applying suitable constructors. set allowed constructscharacterizes description language.knowledge specification mechanism, specifies construct DL knowledge base, properties concepts roles asserted.set basic reasoning tasks provided DL.rest section describe specific form three components assumealuni.2.1 Description Languagealunidescription language aluni, called ALUNI , concepts roles formed according syntax shown Table 1, denotes atomic concept, P atomicrole, C arbitrary concept expression, R arbitrary role expression, n nonnegative integer. increase readability concept expressions, also introduce followingabbreviations:> :A; atomic concept? u :A; atomic concept9R 91R9=nR 9nR u 9nRConcepts interpreted subsets domain roles binary relationsdomain. Intuitively, :A represents negation atomic concept, interpretedcomplement respect domain interpretation. C1 u C2 representsconjunction two concepts interpreted set intersection, C1 C2 representsdisjunction interpreted set union. Consequently, > represents whole domain,1. ]S denotes cardinality set .202fiUnifying Class-Based Representation Formalisms? empty set. 8R.C called universal quantification roles useddenote elements interpretation domain connected role Rinstances concept C . 9nR 9nR called number restrictions, imposeinstances restrictions minimum maximum number objectsconnected role R. P , called inverse role P , represents inversebinary relation denoted P .formally, interpretation = (I ; ) consists interpretation domaininterpretation function maps every concept C subset Cevery role R subset RI according semantic rules specified Table 1.sets C RI called extensions C R respectively.Example 2.1 Consider concept expression8enrolls.Student u 92enrolls u 930 enrolls u8teaches .(Professor GradStudent) u 9=1teaches u:AdvCoursespecifying constraints object university course. expression ectsfact course enrolls students, restrictions minimum maximumnumber enrolled students. using role teaches inverse constructorstate property course taught exactly one individual, eitherprofessor graduate student. Finally, negation used express disjointnessconcept denoting advanced courses.2.2 Knowledge Basesalunialuni knowledge base, expresses knowledge classes relationsmodeled domain, formally defined triple K = (A; P ; ), finite setatomic concepts, P finite set atomic roles, finite set called inclusionassertions. assertion form_ Catomic concept C arbitrary concept expression. inclusionassertion states means concept C necessary properties element domainorder instance atomic concept A. Formally, interpretation satisfiesinclusion assertion _ C AI C . interpretation model knowledgebase K satisfies inclusion assertions K. finite model model finitedomain.Example 2.1 (cont.) assertion_ 8enrolls.Student u 92enrolls u 930enrolls uCourse8teaches .(Professor GradStudent) u 9=1teachesmakes use complex concept expression state necessary conditions objectinstance concept Course.203fiCalvanese, Lenzerini, & Nardialuni restrictions imposed form inclusion assertions mayassume. particular rule cyclic assertions, i.e., assertionsconcept expression right hand side refers, either directly indirectly viaassertions, atomic concept left hand side. presence cyclic assertionsdifferent semantics may adopted (Nebel, 1991). one defined above, called descriptivesemantics, accepts interpretations satisfy assertions knowledge base,hence interprets assertions constraints domain modeled. inclusionassertions, descriptive semantics claimed provide intuitive results(Buchheit, Donini, Nutt, & Schaerf, 1998). Alternative semantics proposedbased fixpoint constructions (Nebel, 1991; Schild, 1994; De Giacomo & Lenzerini,1994b), hence allow define unique way interpretation concepts.general, cycles knowledge base increase complexity reasoning (Nebel,1991; Baader, 1996; Calvanese, 1996b) require special treatment reasoning procedures (Baader, 1991; Buchheit, Donini, & Schaerf, 1993). reason, many DL basedsystems assume knowledge base acyclic (Brachman, McGuinness, Patel-Schneider,Alperin Resnick, & Borgida, 1991; Bresciani, Franconi, & Tessaris, 1995). However, assumption unrealistic practice, cycles definitely necessary correct modelingmany application domains. Indeed, use cycles allowed data models useddatabases, and, shown following sections, order capture semanticsaluni possibility using cyclic assertions fundamental.Besides inclusion assertions, DL based systems also make use equivalence assertions (Buchheit et al., 1993), express necessary sucient conditionsobject instance concept. Although possibility ruled aluni,limit ability capturing frame based systems database models,constraints expressed correspond naturally inclusion assertions.2.3 Reasoningalunibasic tasks consider reasoning aluni knowledge base conceptconsistency concept subsumption:Concept consistency problem deciding whether concept C consistentknowledge base K (written K 6j= C ?), i.e., whether K admits modelC 6= ;.Concept subsumption problem deciding whether concept C1 subsumedconcept C2 knowledge base K (written K j= C1 C2), i.e., whether C1I C2Imodel K.inclusion number restrictions inverse roles ALUNI abilityaluni using arbitrary, possibly cyclic inclusion assertions allows one construct knowledge base certain concept consistent necessarily empty extensionfinite models knowledge base. Similarly, subsumption relation twoconcepts may hold infinite models knowledge base ruled finitemodels considered.204fiUnifying Class-Based Representation FormalismsKeven = (A P ),= fNumber Eveng,P = fdoublesg,set assertions consists of:;;;NumberEven_ 9doubles u 8doubles .Even_ Number u 91 doubles u 8doubles.NumberFigure 1: aluni knowledge base two concepts equivalent finitemodelsLet Keven knowledge base shown Figure 1. Intuitively, assertions Keven state number even number doubles it,numbers double even. even number number, doublesone number, doubles numbers. Observe model Keven , universal quantifications together functionality doubles assertions imply]EvenI ]NumberI , direct inclusion assertion Even Number implies]EvenI ]NumberI . Therefore, two concepts cardinality, sinceone sub-concept other, domain finite, extensions coincide.necessarily hold infinite domains. fact, names chosen suggestalready infinite model knowledge base Number Even interpreteddifferently. model obtained taking natural numbers domain, interpreting Number whole domain, Even even numbers, doubles setf(2n; n) j n 0g.example shows aluni finite model property,states concept consistent knowledge base knowledge base admitsfinite model concept nonempty extension. Therefore, importantdistinguish reasoning respect unrestricted models reasoningrespect finite models. call (unrestricted) concept consistency (written K 6j=u C?) (unrestricted) concept subsumption (written K j=u C ) reasoning tasksdescribed above, i.e., carried without restricting attention finite models.corresponding reasoning tasks carried considering finite models only, called finiteconcept consistency (written K 6j=f C ?) finite concept subsumption (writtenK j=f C ).Example 2.2 (cont.) Summing previous considerations, say Numbersubsumed Even Keven , i.e., Keven 6j=u Number Even, finitely subsumed, i.e.,Keven j=f Number Even. Equivalently Numberu:Even consistent Keven , i.e., Keven 6j=uNumber u:Even ?, finitely consistent, i.e., Keven j=f Number u:Even ?.distinguishing feature aluni reasoning finite unrestricted case decidable. particular, unrestricted concept satisfiability conceptsubsumption decidable deterministic exponential time (De Giacomo & Lenzerini,Example 2.2205fiCalvanese, Lenzerini, & Nardi1994a; Calvanese et al., 1994), since reasoning strict sublanguages aluni already EXPTIME-hard (Calvanese, 1996c), known algorithms computationally optimal. Finite concept consistency aluni also decidable deterministic exponential timefinite concept subsumption (in general case) decidable deterministic doubleexponential time (Calvanese, 1996c). precise discussion methods reasoning aluni provided Section 6.2, detailed account adopted algorithmsanalysis computational complexity presented Calvanese (1996c).next sections show two forms reasoning respect unrestrictedfinite models, capture reasoning tasks typically considered differentformalisms structured representation knowledge.3. Frame Based SystemsFrame languages based idea expressing knowledge means frames,structures representing classes objects terms properties instancesmust satisfy. properties defined frame slots, constitute itemsframe definition. Since 70s large number frame systems developed,different goals different features. DLs bear close relationship kl-one familyframe systems (Woods & Schmolze, 1992). However, would like consider framesystems general perspective, discussed example Karp (1992), Karp,Myers, Gruber (1995), establish correspondence aluni knowledge basescontext.remark restricting attention aspects relatedtaxonomic structure. Moreover, discussed below, consider assertional knowledgebases, intensional knowledge characterized terms inclusion assertions ratherdefinitions. addition, consider features cannot capturedfirst-order framework, default values slots, attached procedures,specification overriding inheritance policies. issues concerning modelingaspects DLs addressed Donini, Lenzerini, Nardi, Nutt, Schaerf (1994),Donini, Nardi, Rosati (1995), within modal nonmonotonic extension DLs.3.1 Syntax Frame Based Systemsmake correspondence precise, need fix syntax semantics framesystems consider. Unfortunately, accepted standard chosenuse basically notation adopted Fikes Kehler (1985), used alsoKEE2 system.frame knowledge base, denoted F , formed set frameslot names, constituted set frame definitions following form:Definition 3.1Frame : F KB F E;2. KEE trademark Intellicorp. Note KEE user directly specify knowledge basenotation, allowed define frames interactively via graphical system interface.206fiUnifying Class-Based Representation Formalisms: Course KB University: enrollsValueClass: StudentCardinality.Min: 2Cardinality.Max: 30MemberSlot: taughtbyValueClass: (UNION GradStudentProfessor)Cardinality.Min: 1Cardinality.Max: 1Frame: BasCourse KB University: CourseMemberSlot: taughtbyValueClass: ProfessorFrameMemberSlotSuperClasses: ProfessorFrame: StudentFrameKBUniversityUniversity: GradStudent KB University: StudentMemberSlot: degreeValueClass: StringCardinality.Min: 1Cardinality.Max: 1FrameSuperClasses: AdvCourse KB University: CourseMemberSlot: enrollsValueClass: (INTERSECTIONFrameSuperClassesGradStudent(NOT Undergrad))KB: Undergrad KB University: StudentFrameSuperClasses: 20Cardinality.MaxFigure 2: KEE knowledge baseE frame expression, i.e., expression formed according following syntax:E ! SuperClasses : F1 ; : : : ; FhMemberSlot : S1ValueClass : H1Cardinality.Min : m1Cardinality.Max : n1MemberSlot : SkValueClass : HkCardinality.Min : mkCardinality.Max : nkF denote frame slot names, respectively, n denote positive integers,H denotes slot constraint, specified follows:H! Fj(INTERSECTION H1 H2) j(UNION H1 H2) j(NOT H )readers familiar KEE system, point omitspecification sub-classes frame present KEE, since directly derivedspecification super-classes.Example 3.2 Figure 2 shows simple example knowledge base modeling situationuniversity expressed frame language presented. frame Course207fiCalvanese, Lenzerini, & Nardirepresents courses enroll students taught either graduate studentsprofessors. Cardinality restrictions used impose minimum maximum numberstudents may enrolled course, express course taughtexactly one individual. frame AdvCourse represents courses enroll graduatestudents, i.e., students already degree. Basic courses, hand, maytaught professors.3.2 Semantics Frame Based Systemsgive semantics set frame definitions resort interpretation termsfirst-order predicate calculus (Hayes, 1979). According interpretation, frame namestreated unary predicates, slots considered binary predicates.frame expression E interpreted predicate logic formula E (x), onefree variable, consists conjunction sentences, obtained super-classspecification slot specification. particular, super-classes F1 ; : : : ; Fhhave:F1 (x) ^ : : : ^ Fh (x)slot specificationMemberSlot :ValueClass : HCardinality.Min :Cardinality.Max : n8y. (S (x; y) !VH (y)) ^9y1; : : : ; ym. (( i6=j yi 6= yj ) ^ (x; y1 ) ^ ^ (x; ym )) ^8y1; : : : ; yn+1. ((S (x; y1 ) ^ ^ (x; yn+1)) ! Wi6=j yi = yj );assumption within one frame definition occurrences x referfree variable. Finally constraints slots interpreted conjunction, disjunctionnegation, respectively, i.e.:(INTERSECTION H1 H2) interpreted H1(x) ^ H2(x)(UNION H1 H2)interpreted H1(x) _ H2(x)(NOT H )interpreted :H (x)frame definitionFrame : F KB F Econsidered universally quantified sentence form8x.(F (x) ! E (x)):whole frame knowledge base F considered conjunction first-order sentences corresponding frame definitions F .regard frame definitions necessary conditions, commonplaceframe systems known assertional frame systems, opposed definitional systems,frame definitions interpreted necessary sucient conditions.208fiUnifying Class-Based Representation Formalismsorder enable comparison formalisms representing structured knowledge restrict attention reasoning tasks involve frame knowledge base,independently assertional knowledge, i.e., frames instances. Fikes Kehler(1985) mention several reasoning services associated frames, as:Consistency checking, amounts verifying whether frame F satisfiableknowledge base. particular, involves reasoning cardinalitieschecking whether filler given slot belongs certain frame.Inheritance, which, case, amounts ability identifyingframes general given frame, sometimes called all-super-of (Karpet al., 1995). properties general frames inheritedspecific one. reasoning therefore based general abilitycheck mutual relationhips frame descriptions knowledge base.reasoning services formalized first-order semantics follows.Definition 3.3 Let F frame knowledge base F frame F . say Fconsistent F first-order sentence F ^ 9x.F (x) satisfiable. Moreover, sayframe description E general F F F j= 8x.(F (x) ! E (x)).3.3 Relationship Frame Based Systemsalunifirst-order semantics given allows us establish straightforward relationshipframe languages aluni. Indeed, present translation frameknowledge bases aluni knowledge bases.first define function maps frame expression ALUNI conceptexpression follows:Every frame name F mapped atomic concept (F ).Every slot name mapped atomic role (S ).Every slot constraint mapped follows(UNION H1 H2)mapped (H1) (H2):(INTERSECTION H1 H2) mapped (H1) u (H2):(NOT H )mapped :(H ):Every frame expression formSuperClasses : F1 ; : : : ; FhMemberSlot : S1ValueClass : H1Cardinality.Min : m1Cardinality.Max : n1MemberSlot : SkValueClass : HkCardinality.Min : mkCardinality.Max : nk209fiCalvanese, Lenzerini, & NardiK = (A P ),= fCourse AdvCourse BasCourse Professor Student GradStudent Undergrad Stringg,P = fenrolls taughtby degreeg,set assertions consists of:;;;;;CourseAdvCourseBasCourseGradStudentUndergrad;;;;;;_ 8enrolls.Student u 92 enrolls u 930 enrolls u8taughtby.(Professor GradStudent) u 9=1 taughtby_ Course u 8enrolls.(GradStudent u :Undergrad) u 920 enrolls_ Course u 8taughtby.Professor_ Student u 8degree.String u 9=1 degree_ StudentFigure 3: aluni knowledge base corresponding KEE knowledge base Figure 2mapped class expression(F1 ) u u (Fh ) u8(S1).(H1) u 9m (S1) u 9n (S1) u8(Sk ).(Hk ) u 9mk (Sk ) u 9nk (Sk):11mapping allows us translate frame knowledge base aluni knowledge base,specified following definition.aluni knowledge base (F ) = (A; P ; ) corresponding frameknowledge base F obtained follows:consists one atomic concept (F ) frame name F F .P consists one atomic role (S ) slot name F .consists inclusion assertion(F ) _ (E )frame definitionFrame : F KB F EF .Definition 3.4Example 3.2 (cont.) illustrate translation frame knowledge base Figure 2. corresponding aluni knowledge base shown Figure 3.210fiUnifying Class-Based Representation Formalismscorrectness translation follows correspondence settheoretic semantics aluni first-order interpretation frames (see exampleHayes, 1979; Borgida, 1996; Donini et al., 1996). observe inverse rolesfact necessary formalization frames. Indeed, possibility referringinverse slot rarely considered frame knowledge representation systems (Someexceptions reported Karp, 1992). Due absence inverse roles distinctionreasoning finite unrestricted models necessary3 . Consequently,mentioned forms reasoning captured unrestricted concept consistencyconcept subsumption aluni knowledge bases. summarized followingtheorem.Theorem 3.5 Let F frame knowledge-base, F frame F , E frame description, (F ), (F ), (E ) translations aluni. followinghold:F consistent F (F ) 6j=u (F ) ?.E general F F (F ) j=u (F ) (E ).claim directly follows semantics frame knowledge basestranslation DLs adopted.Theorem 3.5 becomes possible exploit methods unrestricted reasoningaluni knowledge bases order reason frame knowledge bases. Since problemreasoning, e.g., KEE already EXPTIME-complete, pay terms computational complexity expressiveness added constructs aluni. fact,resorting correspondence aluni becomes possible add frame systemsuseful features, possibility specifying inverse slot (Karp, 1992),still retain ability reason EXPTIME.Proof.4. Semantic Data ModelsSemantic data models introduced primarily formalisms database schema design.provide means model databases much richer way traditional datamodels supported Database Management Systems, becomingimportant adopted recent database design methodologiesComputer Aided Software Engineering tools.widespread semantic data model Entity-Relationship (ER) model introduced Chen (1976). become standard, extensively used designphase commercial applications. commonly accepted ER notation, classes calledentities represented boxes, whereas relationships entities representeddiamonds. Arrows entities, called ISA relationships, represent inclusion assertions. links entities relationships represent ER-roles, numberrestrictions associated. Dashed links used whenever restrictions refinedspecific entities. Finally, elementary properties entities modeled attributes,3. eliminateALUNI inverse roles, resulting DL finite model property.211fiCalvanese, Lenzerini, & Nardiwhose values belong one several predefined domains, Integer, String,Boolean.ER model provide constructs expressing explicit disjointness disjunction entities, extensions model allow use generalization hierarchiesrepresent combination two constructs. order keep presentation simple, consider generalization hierarchies formalization provide,although addition would straightforward. Similarly, omit attributes relations.show relevant aspects ER model captured aluni,thus reasoning ER schema reduced reasoning correspondingaluni knowledge base. Since aluni equipped capabilities reason knowledgebases, respect finite unrestricted models (see Section 6.2), reductionshows reasoning ER model, generally semantic data models,decidable.case frame-based systems, restrict attention aspectsconstitute core ER model. reason consider features,keys weak entities, introduced literature (Chen, 1976),appear formalizations ER model methodologiesconceptual modeling based model. proposal treatment keys descriptionlogics presented Borgida Weddell (1997).order establish correspondence ER model aluni, presentformal syntax semantics ER schemata.4.1 Syntax Entity-Relationship ModelAlthough ER model become industrial standard, several variantsextensions introduced, differ minor aspects expressivenessnotation (Chen, 1976; Teorey, 1989; Batini, Ceri, & Navathe, 1992; Thalheim, 1992, 1993).Also, ER schemata usually defined using graphical notation particularlyuseful easy visualization data dependencies, well suitedpurposes. Therefore chosen formalization ER model abstractsrespect important characteristics allows us develop correspondencealuni.following, two finite sets X call function subset XX -labeled tuple . labeled tuple maps xi 2 X yi 2 ,2 f1; : : : ; kg, denoted [x1 : y1 ; : : : ; xk : yk ]. also write [xi ] denote yi .ER schema tuple = (LS ; ; att ; rel ; card ),LS finite alphabet partitioned set ES entity symbols, set attributesymbols, set US role symbols, set RS relationship symbols, set DSdomain symbols; domain symbol associated predefined basic domainDBD , assume various basic domains pairwise disjoint.ES ES binary relation ES .att function maps entity symbol ES -labeled tuple DS .Definition 4.1212fiUnifying Class-Based Representation Formalismsfunction maps relationship symbol RS US -labeled tupleES . assume without loss generality that:{ role specific exactly one relationship, i.e., two relationshipsR; R0 2 RS R 6= R0 , rel (R) = [U1 : E1 ; : : : ; Uk : Ek ] rel (R0 ) =[U10 : E10 ; : : : ; Uk0 0 : Ek0 0 ], fU1; : : : ; Uk g fU10 ; : : : ; Uk0 0 g disjoint.{ role U 2 US relationship R entity Erel (R) = [: : : ; U : E; : : :].card function ES RS US IN0 (IN0 [ f1g) satisfies following condition: relationship R 2 RS rel (R) = [U1 : E1 ; : : : ; Uk : Ek ],card (E; R; U ) defined U = Ui 2 f1; : : : ; kg, E Ei(where denotes exive transitive closure ). first componentcard (E; R; U ) denoted cmin (E; R; U ) second componentcmax (E; R; U ). stated otherwise, cmin (E; R; U ) assumed 0cmax (E; R; U ) assumed 1.specifying formal semantics ER schemata give intuitive descriptioncomponents schema. relation models ISA-relationship entities.need make special assumption form acyclicityinjectivity. function att used model attributes entities. exampleatt associates -labeled tuple [A1 : Integer; A2 : String] entity E , Etwo attributes A1 ; A2 whose values integers strings respectively. simplicityassume attributes single-valued mandatory, could easily handle also multivalued attributes associated cardinalities. function rel associates set rolesrelationship symbol R, determining implicitly also arity R, roleU set distinguished entity, called primary entity U R. databasesatisfying schema instances primary entity allowed participaterelationship via role U . function card specifies cardinality constraints, i.e.,constraints minimum maximum number times instance entity mayparticipate relationship via role. Since constraints meaningfulentity effectively participate relationship, function definedsub-entities primary entity. special value 1 used restrictionposed maximum cardinality. constraints used specify existencedependencies functionality relations (Cosmadakis & Kanellakis, 1986).often used restricted form, minimum cardinality either 0 1maximum cardinality either 1 1. Cardinality constraints form consideredintroduced already Abrial (1974) subsequently studied GrantMinker (1984), Lenzerini Nobili (1990), Ferg (1991), Ye, Parent, Spaccapietra(1994), Thalheim (1992).Example 4.2 Figure 4 shows simple ER schema modeling state affairs similarone represented KEE knowledge base Figure 2. used standard graphicnotation ER schemata, except dashed link, represents refinementcardinality constraint participation sub-entity (in case AdvCourse)relationship (in case ENROLLING).rel213fiCalvanese, Lenzerini, & NardiTof(1,1)Course6Ein(2,30)TEACHINGENROLLINGTby(0,1)Eof(4,6)TeacherStudent6(2,20)AdvCoursedegree/StringGradStudentFigure 4: ER schema4.2 Semantics Entity-Relationship Modelsemantics ER schema given specifying database statesconsistent information structure represented schema. Formally, databasestate B corresponding ER schema = (LS ; ; att ; rel ; card ) constitutednonempty finite set B , assumed disjoint basic domains, function Bmapsevery domain symbol 2 DS corresponding basic domain DBD ,every entity E 2 ES subset E B B ,every attribute 2 set AB B SD2DS DBD ,every relationship R 2 RS set RB US -labeled tuples B .elements E B , AB , RB called instances E , A, R respectively.database state considered acceptable satisfies integrity constraintspart schema. captured definition legal database state.Definition 4.3 database state B said legal ER schema =(LS ; ; att ; rel ; card ), satisfies following conditions:pair entities E1; E2 2 ES E1 E2, holds E1B E2B .entity E 2 ES , att (E ) = [A1 : D1 ; : : : ; Ah : Dh], instancee 2 E B 2 f1; : : : ; hg following holds:{ exactly one element ai 2 ABi whose first component e,{ second component ai element DiBD .relationship R 2 RS rel (R) = [U1 : E1 ; : : : ; Uk : Ek ], instancesR form [U1: e1 ; : : : ; Uk : ek ], ei 2 EiB , 2 f1; : : : ; kg.214fiUnifying Class-Based Representation FormalismsNumber(1,1)6EvenDOUBLES(0,1)Figure 5: ER schema corresponding Example 2.2relationship R 2 RS rel (R) = [U1 : E1 ; : : : ; Uk : Ek ],2 f1; : : : ; kg, entity E 2 ES E Ei instance e E, holdscmin (E; R; Ui ) ]fr 2 RB j r[Ui ] = eg cmax (E; R; Ui ):Notice definition database state ects usual assumption databasesdatabase states finite structures (see also Cosmadakis, Kanellakis, & Vardi, 1990).fact, basic domains required finite, legal database stateschema, finite set values basic domains actually interest.define active domain Bact database state B set elements basicdomains DBD , 2 DS , effectively appear values attributes B. formally:Bact = fd 2 DBD j 2 DS ^ 9A 2 ; e 2 B . (e; d) 2 AB g:Since B finite contains finite number attributes, functionaldefinition, also Bact finite.Reasoning ER model includes verifying entity satisfiability deducing inheritance. Entity satisfiability amounts checking whether given entity populatedlegal database state (Atzeni & Parker Jr., 1986; Lenzerini & Nobili, 1990; Di Battista& Lenzerini, 1993), corresponds notion concept consistency DLs. Deducinginheritance amounts verifying whether databases legal schema,every instance entity also instance another entity. implied ISA relationships arise different reasons. Either trivially, transitive closureexplicit ISA relationships present schema, subtle ways, specificpatterns cardinality restrictions along cycles schema requirementdatabase state finite (Lenzerini & Nobili, 1990; Cosmadakis et al., 1990).Figure 5 shows ER schema modeling situation knowledgebase Example 2.2. Arguing exactly example conclude twoentities Number Even denote set elements every finite database legalschema, although ISA relation Number Even stated explicitly.implied, however, due cycle involving relationship two entities dueparticular form cardinality constraints.Example 4.4215fiCalvanese, Lenzerini, & Nardi4.3 Relationship Entity-Relationship Schemataalunishow different forms reasoning ER schemata captured finiteconcept consistency finite concept subsumption aluni. correspondencetwo formalisms established defining translation ER schemata aluniknowledge bases, proving correspondence legal databasestates finite models derived knowledge base.Definition 4.5 Let = (LS ; ; att ; rel ; card ) ER schema. aluni knowledge base (S ) = (A; P ; ) defined follows:set atomic concepts (S ) contains following elements:domain symbol 2 DS , atomic concept (D);entity E 2 ES , atomic concept (E );relationship R 2 RS , atomic concept (R).set P atomic roles (S ) contains following elements:attribute 2 , atomic role (A);relationship R 2 RS rel (R) = [U1 : E1 ; : : : ; Uk : Ek ], k atomic roles(U1 ); : : : ; (Uk ).set assertions (S ) contains following elements:pair entities E1; E2 2 ES E1 E2, assertion(E1 ) _ (E2 )(1)entity E 2 ES att (E ) = [A1 : D1 ; : : : ; Ah: Dh ], assertion(E ) _ 8(A1 ).(D1 ) u u 8(Ah ).(Dh ) u 9=1(A1 ) u u 9=1 (Ah ) (2)relationship R 2 RS rel (R) = [U1 : E1 ; : : : ; Uk : Ek ], assertions(R) _ 8(U1 ).(E1 ) u u 8(Uk ).(Ek ) u 9=1 (U1 ) u u 9=1(Uk ) (3)(Ei ) _ 8((Ui )) .(R);2 f1; : : : ; kg(4)relationship R 2 RS rel (R) = [U1 : E1 ; : : : ; Uk : Ek ], 2f1; : : : ; kg, entity E 2 ES E Ei,{ = cmin (E; R; Ui ) 6= 0, assertion(E ) _ 9m ((Ui )) :(5){ n = cmax (E; R; Ui ) 6= 1, assertion(E ) _ 9n ((Ui )) :(6)pair symbols X1 ; X2 2 ES [RS [DS X1 6= X2 X1 2 RS [DS ,assertion(X1 ) _ :(X2 ):(7)216fiUnifying Class-Based Representation FormalismsK = (A P ),= fCourse AdvCourse Teacher Student GradStudent TEACHING ENROLLING Stringg,P = fTof Tby Ein Eof degreeg,set assertions consists of:;;;;;;;;;;;;;TEACHINGENROLLINGCourseAdvCourseTeacherStudentGradStudent_ 8Tof.Course u 9=1 Tof u8Tby.Teacher u 9=1 Tby_ 8Ein.Course u 9=1 Ein u8Eof.Student u 9=1 Eof_ 8Tof .TEACHING u 9=1 Tof u8Ein .ENROLLING u 92 Ein u 930 Ein_ Course u 920 Ein_ 8Tby .TEACHING_ 8Eof .ENROLLING u 94 Eof u 96 Eof_ Student u 8degree.String u 9=1 degree:Figure 6: aluni knowledge base corresponding ER schema Figure 4illustrate translation ER schema Figure 4.knowledge base captures exactly semantics shown Figure 6,brevity disjointness assertions (7) omitted, assertions conceptleft hand side collapsed.translation makes use inverse attributes number restrictions capturesemantics ER schemata. observe that, means inverse constructor,binary relationship could treated simpler way choosing traversal directionmapping relationship directly role. Notice also assumption acyclicityresulting knowledge base unrealistic case, order exploit correspondence reasoning ER model, need techniques deal inverseattributes, number restrictions, cycles together. shown Example 2.2, combination factors causes finite model property fail hold, needresort reasoning methods finite models.fact, reduce reasoning ER model finite model reasoning aluniknowledge bases. purpose define mapping database states corresponding ER schema finite interpretations knowledge base derived it.Due possible presence relations arity greater 2, mapping howeverone-to-one first need characterize interpretations knowledge basedirectly correspond database states.Definition 4.6 Let = (LS ; ; att ; rel ; card ) ER schema (S ) definedabove. interpretation (S ) relation-descriptive, every relationship R 2RS , rel (R) = [U1 : E1 ; : : : ; Uk : Ek ], every d; d0 2 ((R))I ,^(8)( 8d00 2 . ((d; d00 ) 2 ((Ui ))I $ (d0 ; d00 ) 2 ((Ui ))I )) ! = d0 :Example 4.2 (cont.)aluni1ik217fiCalvanese, Lenzerini, & NardiIntuitively, extension relationship database state set labeled tuples,set contain element twice. Therefore implicitsemantics ER model cannot two labeled tuples connectedroles relationship exactly elements domain. modelaluni knowledge base corresponding ER schema, hand, tuplerepresented new individual, condition implicit anymore. alsocannot imposed aluni suitable assertions. following lemma, however, showsneed explicit condition, interested reasoningaluni knowledge base corresponding ER schema. due factalways restrict considering relation-descriptive models.ER schema, (S ) aluni knowledge base obtainedaccording Definition 4.5, C concept expression (S ). C finitely consistent(S ), finite relation-descriptive model (S ) C 6= ;.Lemma 4.7 LetLet I0 finite model (S ) C 6= ;. build finite relationdescriptive model 0 starting I0 applying following constructionrelationship RS .Let model obtained previous step let R 2 RS rel (R) =[U1 : E1 ; : : : ; Uk : Ek ] next relationship apply construction. construct model IR condition 8 satisfied relationship R.Given individual r 2 ((R))I , denote Ui(d), 2 f1; : : : ; kg (unique)individual e (r; e) 2 ((Ui ))I . ei 2 ((Ei ))I , 2 f1; : : : ; kg defineX(U :e ;:::;Uk :ek ) = fr 2 ((R))I j Ui (d) = ei ; 2 f1; : : : ; kgg. call con ict-setset X(U :e ;:::;Uk:ek ) one element. con ict-set X(U :e ;:::;Uk:ek)randomly choose one individual r, say others induce con ict(U1 : e1 ; : : : ; Uk : ek ). call Conf (finite) set objects inducing con ict(U1 : e1 ; : : : ; Uk : ek ).define interpretation I2Conf disjoint union 2]Conf copies , one copy,denoted IZ , every set Z 2 2Conf . denote dZ copy IZ individual. Since disjoint union two models aluni knowledge basemodel, I2Conf model (S ). Let IZ IZ 0 two copies I2Conf . callexchanging Uk (rZ ) Uk (rZ 0 ) operation I2Conf consisting replacing ((Uk ))IZpair (rZ ; Uk (rZ )) (rZ ; Uk (rZ 0 )) and, time, replacing ((Uk ))IZ0pair (rZ 0 ; Uk (rZ 0 )) (rZ 0 ; Uk (rZ )). Intuitively, exchanging Uk (rZ ) Uk (rZ 0 ),individuals rZ rZ 0 induce con icts anymore.construct I2Conf interpretation IR follows: r 2 ConfZ 2 2Conf r 2 Z , exchange Uk (rZ ) Uk (rZnfrg ). possibleshow con icts thus eliminated new con ict created. Hence,IR, condition 8 R satisfied. still show IR model (S )C IR 6= ;. Indeed, straightforward check induction every conceptexpression C 0 appearing (S ), Z 2 2Conf , 2 C 0I dZ 2 C 0IR . Thusassertions (S ) still satisfied IR C IR 6= ;.Proof.1 11 11 1218fiUnifying Class-Based Representation Formalismsresult, following correspondence legal database statesER schema relation-descriptive models resulting aluni knowledge baseestablished.Proposition 4.8 every ER schema = (LS ; ; att ; rel ; card ) exist twomappings ffS , database states corresponding finite interpretations translation (S ), fiS , finite relation-descriptive interpretations (S ) database statescorresponding , that:1. legal database state B , ffS (B) finite model (S ),symbol X 2 ES [ [ RS [ DS , X B = ((X ))ffS (B) .2. finite relation-descriptive model (S ), fiS (I ) legal database state, entity E 2 ES , ((E ))I = E fiS (I ) , symbol X 2 [RS [DS ,](X )I = ]X fiS (I ) .Proof.(1) Given database state B, define interpretation = ffS (B) (S )follows:= B [ Bact [ SR2RS RB .symbol X 2 ES [ [ RS [ DS ,((X ))I = X B :relationship R 2 RS rel (R) = [U1 : E1 ; : : : ; Uk : Ek ],((Ui ))I = f(r; e) 2 j r 2 RB ; r[Ui] = eg; 2 f1; : : : ; kg:(9)(10)Let B legal database state. prove claim (1) sucient show satisfiesevery assertion (S ). Assertions 1 satisfied since B satisfies set inclusionextensions corresponding entities. respect assertions 2, let E 2 ESentity att (E ) = [A1 : D1 ; : : : ; Ah : Dh], consider instance e 2 ((E ))I .show 2 f1; : : : ; hg, exactly one element ei 2(e; ei ) 2 ((Ai ))I , moreover ei 2 ((Di ))I . 9, e 2 E B , definition legaldatabase state exactly one element ai 2 ABi = ((Ai ))BI whose first component e.Moreover, second component ei ai element Di = ((Di ))I . respectassertions 3, let R 2 RS relationship rel (R) = [U1 : E1 ; : : : ; Uk : Ek ],consider instance r 2 ((R))I . show 2 f1; : : : ; kgexactly one element ei 2 (r; ei ) 2 ((Ui ))I , moreoverei 2 ((Ei ))I . 9, r 2 RB , definition legal database state, r labeled tupleform [U1 : e01 ; : : : ; Uk : e0k ], e0i 2 EiB , 2 f1; : : : ; kg. Therefore r functiondefined fU1 ; : : : ; Uk g, 10, ei unique equal e0i. Moreover, 9,ei 2 ((Ei ))I = EiB . Assertions 4 satisfied, since 10 first componentelement ((Ui ))I always element RB = ((R))I . respect assertions 5,let R 2 RS relationship rel (R) = [U1 : E1 ; : : : ; Uk : Ek ], let E 2 ESentity E Ei, 2 f1; : : : ; kg, = cmin (E; R; Ui ) 6= 0.219fiCalvanese, Lenzerini, & NardiConsider instance e 2 ((E ))I . show least pairs((Ui ))I e second component. Since assertions 4 satisfied knowfirst component pairs instance (R). 9 definitionlegal database state, least labeled tuples RB whose Ui componentequal e. 10, ((Ui ))I contains least pairs whose second component equale. respect assertions 6 proceed similar way. Finally, assertions 7satisfied since first, definition basic domains pairwise disjoint disjointB set labeled tuples, second, element B labeled tuple,third, labeled tuples corresponding different relationships cannot equal sincedefined different sets roles.(2) Let finite relation-descriptive interpretation (S ). basic domain2 DS , let fiD function DBD one-to-one onto. Sincefinite basic domain contains countable number elements, functionalways exists. order define fiS (I ) first specify mapping fi associatesindividual 2 element follows:2 ((E ))I entity E 2 ES , fi (d) = d.2 ((R))I relationship R 2 RS rel (R) = [U1 : E1 ; : : : ; Uk : Ek ],individuals d1; : : : ; dk 2 (d; di ) 2 ((Ui ))I , 2 f1; : : : ; kg,fi (d) = [U1 : d1 ; : : : ; Uk : dk ].2 ((D))I basic domain 2 DS , fi (d) = fiD (d).Otherwise fi (d) = d.pair individuals (d1 ; d2 ) 2 , fi((d1 ; d2 )) = (fi (d1 ); fi (d2 )), setX , fi (X ) = ffi (x) j x 2 X g.model (S ) rules define fi(d) every 2 . Indeed,assertions 7, 2 instance one atomic concept correspondingrelationship basic domain, case instance atomicconcept corresponding entity. Moreover, 2 ((R))I relationship R 2 RSrel (R) = [U1: E1 ; : : : ; Uk : Ek ], assertions 3, 2 f1; : : : ; kgexactly one element di 2 (d; di ) 2 ((Ui ))I . model (S )2 , fi(d) uniquely determined, choose nondeterministicallyone possible value.define database state B = fiS (I ) corresponding :B = nR2RS ((R)) [ D2DS ((D )) .symbol X 2 ES [ [ RS [ DS , X B = fi(((X ))I ).dicult see, model (S ), B defined way legaldatabase state active domain SD2DS ((D))I .220fiUnifying Class-Based Representation Formalismsfollowing theorem allows us reduce reasoning ER schemata finite modelreasoning aluni knowledge bases.Theorem 4.9 Let ER schema, E; E 0 two entities , (S ) translation . following holds:(S ) 6j=f (E ) ?.2. E inherits E 0 (S ) j=f (E ) (E 0 ).B 6 ;. part 1 Proposition 4.8,Proof. (1) \)" Let B legal database state E =ff(B)ffS (B) finite model (S ) ((E ))=6 ;.\(" Let (E ) finitely consistent (S ). Lemma 4.7 finite relationdescriptive model (S ) (E )I =6 ;. part 2 Proposition 4.8, fiS (I )database state legal E B =6 ;.(2) \)" Let (S ) 6j=f (E ) (E 0 ). (E ) u:(E 0 ) finitely consistent (S ).Lemma 4.7 finite relation-descriptive model (S ) 2 ((E ))I62 ((E 0 ))I , 2 . part 2 Proposition 4.8, fiS (I ) database state legal2 E B 62 E 0B . Therefore E inherit E 0.\(" Assume E inherit E 0. database state B legalinstance e 2 E B e 62 E 0B . part 1 Proposition 4.8,ffS (B) finite model (S ) e 2 ((E ))ffS (B) e 62 ((E 0 ))ffS (B) . Therefore(S ) 6j=f (E ) (E 0 ).1. E satisfiableTheorem 4.9 allows us effectively exploit reasoning methods developed aluni order reason ER schemas. complexity resulting methodreasoning ER schemata exponential. Observe however, known algorithmsreasoning ER schemata also exponential (Calvanese & Lenzerini, 1994b),precise computational complexity problem still open.Moreover, exploiting correspondence aluni, becomes possible addER model (and general semantic data models) several features modelingprimitives currently missing, considered important, fullytake account reasoning schemata. additional features includeexample possibility specify use arbitrary boolean combinations entities,refine properties entities along ISA hierarchies.5. Object-Oriented Data ModelsObject-oriented data models proposed goal devising database formalisms could integrated object-oriented programming systems (Kim, 1990).subject active area research database field, basedfollowing features:rely notion object identifier extensional level (as opposedtraditional data models value-oriented) notion classintensional level.221fiCalvanese, Lenzerini, & Nardistructure classes specified means typing inheritance.previous section, present common basis object-oriented data modelsclass-based formalisms introducing language specifying object-orientedschemata show schemata correctly represented aluni knowledgebases. analysis, concentrate attention structural aspects objectoriented data models. One characteristics object-oriented approach providemechanisms specifying also dynamic properties classes objects, typicallydefinition methods associated classes. aspects outsidescope investigations. Nevertheless, argue general techniques schema levelreasoning, particular, type consistency type inference, profitably exploitedrestricted forms reasoning methods (Abiteboul, Kanellakis, Ramaswamy, & Waller,1992).5.1 Syntax Object-Oriented Modeldefine simple object-oriented language style popular modelsfeaturing complex objects object identity. Although refer specificformalism, model inspired ones presented Abiteboul Kanellakis (1989),Hull King (1987).Definition 5.1 object-oriented schema tuple = (CS ; ; DS ), where:CS finite set class names, denoted letter C .finite set attribute names, denoted letter A.DS finite set class declarations formClass C is-a C1 ; : : : ; Ck type-is T;denotes type expression built according following syntax:! CjUnion T1 ; : : : ; Tk End jSet-of jRecord A1: T1 ; : : : ; Ak : Tk End:DS contains exactly one declaration class C 2 CS .Figure 7 shows fragment object-oriented schema correspondingKEE knowledge base Figure 2.class declaration imposes constraints instances class refers to.is-a part class declaration allows one specify inclusion sets instancesinvolved classes, type-is part specifies type expression structureassigned objects instances class.Example 5.2222fiUnifying Class-Based Representation FormalismsClass Teacher type-isUnion Professor, GradStudentEndClass GradStudent is-a Student type-isRecorddegree: StringEndClass Course type-isRecordenrolls: Set-of Student,taughtby: TeacherEndFigure 7: object-oriented schema5.2 Semantics Object-Oriented Modelmeaning object-oriented schema given specifying characteristicsinstance schema. definition instance makes use notions objectidentifier value.Let us first characterize set values constructed set symbols,called object identifiers. Given finite set symbols denoting real world objects, setVO values inductively defined follows:VO .v1 ; : : : ; vk 2 VO fjv1 ; : : : ; vk jg 2 VO .v1 ; : : : ; vk 2 VO [ A1 : v1 ; : : : ; Ak : vk ] 2 VO .Nothing else VO .database instance J schema = (CS ; ; DS ) constitutedfinite set OJ object identifiers;mapping J assigning class CS subset OJ ;mapping J assigning value VOJ object OJ .Although set VOJ values constructed set OJ object identifiersinfinite, database instance one needs consider finite subset VOJ .Definition 5.3 Given object-oriented schema instance J , set VJactive values respect J constituted by:set OJ object identifiers.set values assigned J elements OJ , including valuesexplicitly associated object identifiers, used form values.interpretation type expressions J defined interpretation function J assigns type expression subset VOJ following conditions satisfied:C J = J (C )223fiCalvanese, Lenzerini, & Nardi(Union T1 ; : : : ; Tk End)J = T1J [ [ TkJ(Set-of )J = ffjv1 ; : : : ; vk jg j k 0; vi 2 J ; 2 f1; : : : ; kgg(Record A1 : T1 ; : : : ; Ak : Tk End)J = f[ A1 : v1 ; : : : ; Ah : vh] j h k;vi 2 TiJ ; 2 f1; : : : ; kg;vj 2 VOJ ; j 2 fk + 1; : : : ; hgg:Notice instances type record may components specifiedtype class. Thus using open semantics records, typicalobject-oriented data models (Abiteboul & Kanellakis, 1989).order characterize object-oriented data models consider instancesadmissible schema.Definition 5.4 Let = (CS ; ; DS ) object-oriented schema. database instanceJ said legal (with respect ) declarationClass C is-a C1 ; : : : ; Cn type-isDS , holds C J CiJ 2 f1; : : : ; ng, J (C J ) J .Therefore, legal database instance, type expressions presentschema determine (finite) set active values must considered. constructionvalues limited depth type expressions.5.3 Relationship Object-Oriented Schemataaluniestablish relationship aluni object-oriented language presentedabove. done providing mapping object-oriented schemata aluniknowledge bases. Since interpretation domain aluni knowledge bases consistsatomic objects, whereas instance object-oriented schema assigned possiblystructured value (see definition VO ), need explicitly representnotions underlie object-oriented language. particular, correspondence concepts classes, one must explicitly account type structureclass. accomplished introducing aluni concepts AbstractClass,represent classes, RecType SetType represent corresponding types.associations classes types induced class declarations, wellbasic characteristics types, modeled means roles: (functional) role valuemodels association classes types, role member used specifyingtype elements set. Moreover, concepts representing types assumedmutually disjoint, disjoint concepts representing classes. constraintsexpressed adequate inclusion assertions part knowledge basegoing define.first define function maps type expression ALUNI conceptexpression follows:Every class C mapped atomic concept (C ).Every type expression Union T1; : : : ; Tk End mapped (T1 ) (Tk ).224fiUnifying Class-Based Representation FormalismsEvery type expression Set-of mapped SetType u 8member. (T ).Every attribute mapped atomic role (A), every type expressionRecord A1: T1 ; : : : ; Ak : Tk End mapped(A1 ). (T1 ) u 9=1 (A1 ) u u8 (Ak ). (Tk ) u 9=1 (Ak ):RecType u 8Using define aluni knowledge base corresponding object-oriented schema.aluni knowledge base (S ) = (A; P ; ) corresponding objectoriented schema = (CS ; ; DS ) obtained follows:Definition 5.5= fAbstractClass; RecType; SetTypeg [ f (C ) j C 2 CS g.P = fvalue; memberg [ f (A) j 2 g.consists following assertions:AbstractClassRecTypeSetType___9=1value8value.?8value.? u :RecTypeclass declarationClass C is-a C1 ; : : : ; Cn type-isDS , inclusion assertion(C ) _ AbstractClass u (C1 ) u u (Cn) u 8value. (T ):translation observe inverse roles necessaryformalization object-oriented data models. Indeed, possibility referringinverse attribute generally ruled models. However, strongly limitsexpressive power data model, pointed recent papers (see exampleAlbano, Ghelli, & Orsini, 1991; Cattell, 1994). Note also use number restrictionslimited value 1, corresponds existence constraints functionality,whereas union used general form example KEE system.illustrate translation fragment object-orientedschema Figure 7. corresponding aluni knowledge base shown Figure 8.Example 5.2 (cont.)225fiCalvanese, Lenzerini, & NardiK = (A P ),= fAbstractClass RecType SetType String;;;P;;;Course; Teacher; Professor; Student; GradStudentg,= fvalue; member; enrolls; taughtby; degreeg,set assertions consists of:Course_TeacherGradStudent__AbstractClassRecTypeSetTypeAbstractClass u8value.(RecType u 9=1 enrolls u 9=1 taughtby u8enrolls.(SetType u 8member.Student) u 8taughtby.Teacher)AbstractClass u 8value.(GradStudent Professor)AbstractClass u Student u8value.(RecType u 8degree.String u 9=1 degree)_ 9=1 value_ 8value.?_ 8value.? u :RecTypeFigure 8: aluni knowledge base corresponding object-oriented schema Figure 7discuss effectiveness translation . First observeknowledge base (S ) resulting translation object-oriented schemamay admit models direct counterpart among legal database instances. precisely, interpretation (S ) database instanceviewed directed labeled graph: case interpretation, nodes domainindividuals arcs labeled roles. case database instance,nodes either object identifiers active values, arc either connects objectidentifier associated value (in case labeled value), partsub-structure representing set record value (in case labeled memberattribute, accordance type value). legal database instance, value v represented sub-structure form finite tree vroot, set record values intermediate nodes, objects identifiers leaves. Clearly,substructure contain cycles. Conversely, model (S ), maycycles involving nodes instances SetType RecTyperoles different value. call cycles bad. model containing bad cyclescannot put directly correspondence legal database instance. Also, dueopen semantics records one cannot adopt different translation bad cyclesmodel ruled out.aluniExample 5.6Consider object-oriented schema , containing single class declarationClass C type-is Record a1 : Record a2 : Record a3 : C End End End226fiUnifying Class-Based Representation Formalismso1Cvaluev1RecTypea3a1a2o2Cv2RecTypevaluev3a1RecTypev4a2RecTypev5RecTypea3Figure 9: model containing cyclestranslatedC _ AbstractClass u8value.(RecType u 9=1a1 u 8a1.(RecType u 9=1a2 u 8a2.(RecType u 9=1a3 u 8a3.C ))):Figure 9 shows model (S ) represented graph. clarity, namedinstances C , hence AbstractClass, instances RecTypev. Observe two different types cycles graph. cycle involving individualso2 ; v3 ; v4 , v5 cause problems since contains arc labeled value,part structure constituting complex value. fact, v3 representsrecord value [ a1 :[[a2:[[a3: o2 ] ] ] . hand, due bad cycle involving v1v2 , individual v1 represents (together o2 connected via a3 v1 ) record infinitedepth.nevertheless establish correspondence finite models (S ) possiblycontaining bad cycles legal instances object-oriented schema .achieved unfolding bad cycles model (S ) infinite trees. Obviously,unfolding cycle infinite tree, generates infinite number nodes,would correspond infinite database state. However, restrict duplicationindividuals represent set record values, thus instances SetTypeRecType. instances AbstractClass, instead, duplicated processunfolding, therefore number remains finite. Moreover, since set possibleactive values associated object identifier bound depth schema,fact block unfolding bad cycles finite tree depth equal depthschema.Let us first formally define depth object-oriented schema .Definition 5.7 type expression define depth (T ) inductively follows:8 0;= C .>>< max= Union T1 ; : : : ; Tk End.1ik (depth (Ti ));depth (T ) =0 );>1+depth(= Set-of 0.>:1 + max1ik (depth (Ti )); = Record A1: T1 ; : : : ; Ak : Tk End.depth object-oriented schema defined maximum depth (T ) typeexpression .227fiCalvanese, Lenzerini, & Nardio1Cvaluea10v1RecTypea20v2RecTypea3a3CRecType1v2a2RecType2v1a1RecType:::a3valueo2a11v1a1v3RecTypev4RecTypea2v5RecTypea3Figure 10: unfolded version model Figure 9introduce notion unfolding aluni interpretation.Definition 5.8 Let object-oriented schema, (S ) translation alunifinite interpretation (S ). call unfolded version interpretation obtainedfollows: individual v part bad cycle, unfold bad cycle(infinite) tree v root, generating new individuals instancesRecType SetType. nonnegative integer m, call m-unfolded version ,denoted Ijm, interpretation obtained truncating depth infinite treegenerated process unfolding.Example 5.6 (cont.) Figure 10 shows unfolded version model Figure 9.Notice bad cycle unfolded infinite tree, arcs labeleda3 lead o2, instance AbstractClass duplicated.correctness (S ) sanctioned following proposition.Proposition 5.9 every object-oriented schema depth m, exist mappings:1. ffS instances finite interpretations (S ) ffV active valuesinstances domain elements finite interpretations (S ) that:legal instance J , ffS (J ) finite model (S ), typeexpression v 2 VJ , v 2 J ffV (v) 2 ( (T ))ffS (J ) .2. fiS finite interpretations (S ) instances fiV domain elements m-unfolded versions finite interpretations (S ) activevalues instances , that: finite model (S ), fiS (I ) legalinstance , concept (T ), translation type expression2 Ijm , 2 ( (T ))Ijm fiV (d) 2 fiS (I ) .Proof.follows:(1) Given database instance J define interpretation ffS (J ) (S )228fiUnifying Class-Based Representation FormalismsffV function mapping every element VJ distinct element ffS (J ) .Therefore ffS (J ) defined set elements ffV (v) v 2 VJ . Moreoverdenote id, rec, set elements ffS (J ) corresponding objectidentifiers, record set values, respectively.interpretation atomic concepts defined follows:( (C ))ffS (J ) = fffV (o) j 2 J (C )g;every (C ) corresponding class name CAbstractClassffS (J ) = idRecTypeffS (J ) = recSetTypeffS (J ) = setinterpretation atomic roles defined follows:( (A))ffS (J ) = f(d1 ; d2 ) j d1 2 rec ffV 1 (d1 ) = [ : : : ; A: ffV 1 (d2 ); : : :] g;every (A) corresponding attribute nameff(J)member= f(d1 ; d2 ) j d1 2 set ffV 1(d1 ) = fj: : : ; ffV 1 (d2 ); : : :jggff(J)value= f(d1 ; d2 ) j (ffV 1 (d1 ); ffV 1 (d2 )) 2 J gprove type v 2 VJ , v 2 J ffV (v) 2( (T ))ffS (J ) . first part thesis follows definition ffS (J ).proof induction structure type expression.Base case: = C (i.e., class1 name). 2 C J ffV (o) 2 ( (C ))ffS (J ) ,vice-versa 2 ( (C ))ffS (J ) ffV (d) 2 C J .Inductive case: = Record A1 : T1 ; : : : ; Ak : Tk End (T ) = RecType u8 (A1 ). (T1 ) u 9=1 (A1 ) u u 8 (Ak ). (Tk ) u 9=1 (Ak ). assume v 2 TiJiff ffV (v) 2 ( (Ti ))ffS (J ), 2 f1; : : : ; kg, show v 2 J iff ffV (v) 2 ( (T ))ffJS (J ).Suppose v 2 J , i.e., v = [ A1 : v1 ; : : : ; Ah: vh] h k vi 2 Ti2 f1; : : : ; kg. induction hypothesis ffV (vi ) 2 ( (Ti ))ffS (J ) , 2 f1; : : : ; kg,definition ffS , ffV (v) 2 RecTypeffS (J ) , (ffV (v); ffV (vi )) 2 ( (Ai ))ffS (J ) 2 f1; : : : ; kg,roles (A) corresponding attribute names functional. Therefore, ffV (v) 2( (T ))ffS (J ) .Conversely, suppose = ffV (v) 2 ( (T ))ffS (J ) . Then, 2 f1; : : : ; kgexactly one di 2 ffS (J ) (d; di ) 2 ( (Ai ))ffS (J ), moreover di 2 ( (T1i ))ffS (J ) .definition ffS v = [ A1: v1 ; : : : ; AhJ: vh] , h k vi = ffV (di ),2 f1; : : : ; kg. induction hypothesis vi 2 Ti , 2 f1; : : : ; kg, therefore v 2(Record A1 : T1 ; : : : ; Ak : Tk End)J .cases = Union T1; : : : ; Tk End = Set-of 0 treated analogously.(2) Given finite model (S ) depth m, define legal database instance fiS (I )follows:fiV function mapping every element Ijm distinct element VfiS (I )following conditions satisfied:{ OfiS (I ) VfiS (I ) set elements fiV (d) 2 AbstractClassIjm .229fiCalvanese, Lenzerini, & Nardi2 RecTypeIjm , (d;Idi ) 2 ( (Ai ))Ijm , 2 f1; : : : ; kg,individual d0 2 jm attribute A0 (d; d0 ) 2 ( (A0 ))Ijm ,fiV (d) = [ A1 : fiV (d1 ); : : : ; Ak : fiV (dk )]].{ 2 SetTypeIjm , (d; di ) 2 memberIjm , 2 f1; : : : ; kg,individual d0 2 Ijm (d; d0 ) 2 (member)Ijm , fiV (d) =ffiV (d1 ); : : : ; fiV (dk )g.every class name C , fiS (I ) (C ) = ffiV (d) j 2 ( (C ))Ijm g.fiS (I ) = f(o; v) j fiV (d1 ) = o; fiV (d2 ) = v; (d1 ; d2 ) 2 valueIjm g.first prove concept (T ), translation type expression, 2 Ijm , 2 ( (T ))Ijm fiV (d) 2 fiS (I ) . proofinduction structure concept expression. inductive partrestrict attention case record types.Base case: = C (i.e., (T ) atomicconcept).2 ( (C ))Ijm fiV (d) 2C fiS (I ) , vice-versa 2 C fiS (I ) fiV 1 (o) 2 ( (C ))Ijm .Inductive case: (T ) = RecType u 8 (A1 ). (T1 ) u 9=1 (A1 ) u u 8 (Ak ). (ITk ) u9=1 (Ak ) = Record A1: T1 ; : : : ; Ak : Tk End. assume 2 ( (Ti )) jm ifffiV (d) 2 TifiS (I ) , 2 f1; : : : ; kg, show 2 ( (T ))Ijm iff fiV (d) 2 fiS (I ) .Suppose 2 ( (T ))Ijm . 2I RecTypeIjm eachI 2 f1; : : : ; kgindividual di di 2 ( (Ti )) jm (d; di ) 2 ( (Ai )) jm . constructionfiV (d) = [ A1 : v1 ; : : : ; Ah : vh ] h k. Moreover, induction hypothesis fiV (di ) 2TifiS (I ) therefore fiV (d) 2 fiS (I ) .Conversely, suppose fiV (d) 2 fiS (I ) , i.e., fiV (d) = [ A1: v1 ; : : : ; Ah: vh ] h kvi 2 TifiS (I ) 2 f1; : : : ; kg. induction hypothesis di = fiV 1(vi ) 2 ( (Ti ))Ijm ,2 f1; : : : ; kg, definition fiV , 2 RecTypeIjm (d; di ) 2 ( (Ai ))Ijm ,2 f1; : : : ; kg. Since roles (A) corresponding attribute names functional,2 ( (T ))Ijm .remains show declarationClass C is-a C1 ; : : : ; Cn type-is{DS , (a) C fiS (I ) CifiS (I ) 2 f1; : : : ; ng, (b) fiS (I )(C fiS (I ) ) fiS (I ) .(a) follows fact (S ) contains assertion (C ) _ (C1 ) u u (Cn )definition fiS (I ) .(b) follows shown fact Ijm still satisfiesassertion (C ) _ AbstractClass u 8value. (T ). fact, 2 ( (C ))I let d0unique individual (d;I d0 ) 2 valueI . Since model (S ), d0 2 ( (T ))I .argue also d0 2 ( (T )) jm . d0 part bad cycle ,Ijm coincide sub-structure rooted d0 formed individuals reached viamember roles corresponding attributes, done. Otherwise, Ijmsub-structure expanded finite tree. Since construction depth treeleast depth (T ), connections individuals preserved Ijm,follows d0 2 ( (T ))Ijm .230fiUnifying Class-Based Representation Formalismsbasic reasoning services considered object-oriented databases subtyping(check whether type denotes subset another type every legal instance) typeconsistency (check whether type consistent legal instance). Based Proposition 5.9, show forms reasoning fully captured finite conceptconsistency finite concept subsumption aluni knowledge bases.object-oriented schema, T; 0 two type expressions ,translation . following holds:Theorem 5.10 Let(S )(S ) 6j=f (T ) ?.subtype 0 (S ) j=f (T ) (T 0 ).1. consistent2.proof analogous proof Theorem 4.9, makes use Proposition 5.9 instead Proposition 4.8.Again, correspondence aluni established Theorem 5.10 allows us makeuse reasoning techniques developed aluni reason object-oriented schemas.Observe reasoning object-oriented models already PSPACE-hard (Bergamaschi& Nebel, 1994) thus known algorithms exponential. However, resortingaluni, becomes possible take account reasoning also various extensionsobject-oriented formalism. extensions useful conceptual modelingalready proposed literature (Cattell & Barry, 1997). First all,considerations developed ER model regard use arbitrary booleanconstructs classes applied also object-oriented setting, providesdisjunction admit form negation. Additional features addedobject oriented models inverses attributes, cardinality constraints set-valuedattributes, general forms restrictions values attributes.Proof.6. Related Worksection brie discuss recent results correspondence class-basedformalisms techniques reasoning aluni class-based representationformalisms.6.1 Relationships among Class-Based Formalismspast several attempts establish relationships among class-basedformalisms. Blasius, Hedstuck, Rollinger (1990), Lenzerini, Nardi, Simi (1991)carry comparative analysis class-based languages attempt provide unifiedview. analysis makes clear several diculties arise identifying commonframework formalisms developed different areas. recent papers addressproblem. example, analysis relationships frame-based languagestypes programming languages carried Borgida (1992), BergamaschiSartori (1992), Piza, Schewe, Schmidt (1992) use frame-based languages enrichdeductive capabilities semantic object-oriented data models.231fiCalvanese, Lenzerini, & NardiArtale, Cesarini, Soda (1996) study reasoning object-oriented data modelspresenting translation DLs style one discussed Section 5. However,proposed translation applicable case shema contains recursiveclass declarations. limitation present work Bergamaschi Nebel(1994), formalism derived DLs used model complex objectsalgorithm computing subsumption classes provided.recent survey application DLs problem data managementpresented Borgida (1995) . application task data modeling reasoningtechniques derived correspondences presented Sections 4 5 discusseddetail Calvanese, Lenzerini, Nardi (1998).Recently, also proposals integrate object-oriented logicprogramming paradigms (Kifer & Wu, 1993; Kifer, Lausen, & Wu, 1995). proposalshowever directly related present work, since aim providing mechanismscomputing structured objects, rather means reasoning conceptual(object-oriented) representation domain interest.6.2 ReasoningaluniClass-Based Representation Formalismsequipped techniques reason respect unrestrictedrespect finite models. brie sketch main ideas underlying reasoningcontexts. detailed account reasoning techniques carried Calvanese(1996c).aluni6.2.1 Unrestricted Model Reasoningremind reasoning knowledge base respect unrestricted models amountscheck either concept consistency, i.e., determine whether knowledge base admits(possibly infinite) model given concept nonempty extension, conceptsubsumption, i.e., determine whether extension one concept contained extension another concept every model (including infinite ones) knowledgebase.method reason aluni respect unrestricted models exploits well knowncorrespondence DLs Propositional Dynamic Logics (PDLs) (Kozen & Tiuryn,1990), class logics specifically designed reason programs.correspondence, first pointed Schild (1991), relies substantialsimilarity interpretative structures formalisms, allows one exploitreasoning techniques developed PDLs reason corresponding DLs. particular,since ALUNI , description language aluni, includes construct inverse roles,correspondence one resort converse-PDL, variant PDL includesconverse programs (Kozen & Tiuryn, 1990). However, presence numberrestrictions ALUNI direct correspondence PDLs, cannot relytraditional techniques reasoning PDLs. Recently, encoding techniquesdeveloped, allow one eliminate number restrictions knowledge basepreserving concept consistency concept subsumption (De Giacomo & Lenzerini, 1994a).encoding applicable knowledge bases formulated expressive variants DLs,particular used reduce unrestricted model reasoning aluni knowledge232fiUnifying Class-Based Representation Formalismsbases (both concept consistency concept subsumption) deciding satisfiabilityformula converse-PDL. Reasoning converse-PDL decidable EXPTIME (Kozen &Tiuryn, 1990), since encoding polynomial (De Giacomo & Lenzerini, 1994a)obtain EXPTIME decision procedure unrestricted concept consistency conceptsubsumption aluni knowledge bases. simplified form encoding,applied decide unrestricted concept consistency aluni also presentedCalvanese et al. (1994).6.2.2 Finite Model Reasoningremind reasoning knowledge base respect finite models amountscheck either finite concept consistency finite concept subsumption,finite models knowledge base must considered.finite model reasoning, techniques based reduction reasoning PDLsapplicable. Indeed, PDL formula corresponding aluni knowledge basecontains constructs converse programs (corresponding inverse roles)functionality direct inverse programs, thus formula variant PDLfinite model property (Vardi, 1985). However, encodingfunctionality, one obtains converse-PDL formula, since converse-PDL finitemodel property (Fischer & Ladner, 1979), formula satisfiablefinitely satisfiable. shows encoding number restrictions (and particularencoding functionality), preserving unrestricted satisfiability preservefinite satisfiability (De Giacomo & Lenzerini, 1994a).finite model reasoning aluni one adopt different technique, basedidea separating reasoning process two distinct phases (see Calvanese, 1996c,full details). first phase deals constructs except number restrictions,builds \expanded knowledge base" constructs embedded implicitlyconcepts roles. second phase assertions involving number restrictionsused derive expanded knowledge base system linear inequalities.system defined way solutions certain type (acceptable solutions)directly related finite models original knowledge base. particular,acceptable solution one directly deduce cardinalities extensions conceptsroles possible finite model. proposed method allows one establish aluniEXPTIME decidability finite concept consistency special cases finite conceptsubsumption. resorting complicated encoding one obtain 2EXPTIMEdecision procedure finite concept subsumption aluni general (Calvanese, 1996a,1996c).Reasoning respect finite models also investigated context dependency theory databases. shown Casanova, Fagin, Papadimitriou (1984)relational model, functional inclusion dependencies interact, dependencyimplication problem finite case differs one unrestricted case.implication problem arbitrary functional inclusion dependencies undecidable(Chandra & Vardi, 1985; Mitchell, 1983), functional unary inclusion dependenciessolvable polynomial time, finite unrestricted case (Cosmadakiset al., 1990).233fiCalvanese, Lenzerini, & NardiConsistency respect finite models schemata expressed enriched EntityRelationship model cardinality constraints shown decidable polynomialtime Lenzerini Nobili (1990). Calvanese Lenzerini (1994b) extend decidability result include also ISA relationships, Calvanese Lenzerini (1994a) showEXPTIME decidability reasoning expressive object-oriented model. algorithmcomputing refinement ordering types (the analogue concept hierarchy)framework O2 object oriented model discussed Lecluse Richard (1989).Reasoning strict sublanguage aluni obtained omitting inverse rolesnumber restrictions already EXPTIME-hard (Calvanese, 1996b). Therefore, knownalgorithms deciding unrestricted concept consistency subsumption finite conceptconsistency essentially optimal.7. Conclusionspresented unified framework representing information class structuresreasoning them. pursued goal looking various class-basedformalisms proposed different fields computer science, namely frame based systemsused knowledge representation, semantic object-oriented data models useddatabases, rephrasing framework description logics. resulting description logic, called aluni includes combination constructs addressedbefore, although constructs previously considered separately.major achievement paper demonstration class-based formalismsgiven precise characterization means powerful fragment first-order logic,thus regarded essential core class-based representation formalismsbelonging three families mentioned above. several consequences.First all, formalisms considered paper enriched constructsoriginating formalisms treated general framework. sense,work reported provides common powerful representation formalism,may also contribute significant developments languages belonging threefamilies. example, usage inverse roles concept languages greatly enhancesexpressivity roles, combination ISA, number restrictions, union enrichesreasoning capabilities available semantic data models.Secondly, comparison class-based formalisms fields knowledge representation conceptual data modeling makes feasible address developmentreasoning tools support conceptual modeling (Calvanese et al., 1998). fact, reasoning capabilities become especially important complex scenarios arisingheterogenous database applications Data Warehousing. line work amongmotivations developing systems based expressive description logics (Horrocks,1998; Horrocks & Patel-Schneider, 1999), lead extending languagedescription logics support Information Integration and, specifically, conceptualmodeling Data Warehouses (Calvanese, De Giacomo, Lenzerini, Nardi, & Rosati, 1998).234fiUnifying Class-Based Representation FormalismsReferencesAbiteboul, S., Kanellakis, P., Ramaswamy, S., & Waller, E. (1992). Method schemas. Tech.rep. CS-92-33, Brown University. earlier version appeared.Abiteboul, S., & Kanellakis, P. (1989). Object identity query language primitive.Proceedings ACM SIGMOD International Conference Management Data,pp. 159{173.Abrial, J. R. (1974). Data semantics. Klimbie, J. W., & Koffeman, K. L. (Eds.), DataBase Management, pp. 1{59. North-Holland Publ. Co., Amsterdam.Albano, A., Ghelli, G., & Orsini, R. (1991). relationship mechanism strongly typedObject-Oriented database programming languages. Proceedings Seventeenth International Conference Large Data Bases (VLDB'91), pp. 565{575Barcelona.Artale, A., Cesarini, F., & Soda, G. (1996). Describing database objects conceptlanguage environment. IEEE Transactions Knowledge Data Engineering, 8 (2),345{351.Atzeni, P., & Parker Jr., D. S. (1986). Formal properties net-based knowledge representation schemes. Proceedings Second IEEE International Conference DataEngineering (ICDE'86), pp. 700{706 Los Angeles.Baader, F. (1991). Augmenting concept languages transitive closure roles: alternative terminological cycles. Proceedings Twelfth International JointConference Artificial Intelligence (IJCAI'91) Sydney, Australia.Baader, F. (1996). Using automata theory characterizing semantics terminologicalcycles. Annals Mathematics Artificial Intelligence, 18, 175{219.Batini, C., Ceri, S., & Navathe, S. B. (1992). Conceptual Database Design, EntityRelationship Approach. Benjamin Cummings Publ. Co., Menlo Park, California.Bergamaschi, S., & Nebel, B. (1994). Acquisition validation complex object databaseschemata supporting multiple inheritance. Applied Intelligence, 4 (2), 185{203.Bergamaschi, S., & Sartori, C. (1992). taxonomic reasoning conceptual design. ACMTransactions Database Systems, 17 (3), 385{422.Blasius, K. H., Hedstuck, U., & Rollinger, C.-R. (Eds.). (1990). Sorts Types ArtificialIntelligence, Vol. 418 Lecture Notes Artificial Intelligence. Springer-Verlag.Borgida, A. (1992). type systems knowledge representation: Natural semanticsspecifications description logics. Journal Intelligent Cooperative InformationSystems, 1 (1), 93{126.Borgida, A. (1995). Description logics data management. IEEE Transactions Knowledge Data Engineering, 7 (5), 671{682.Proc. 9thSymp. Principles Database Systems PODS-90235fiCalvanese, Lenzerini, & NardiBorgida, A. (1996). relative expressiveness description logics predicate logics.Artificial Intelligence, 82, 353{367.Borgida, A., & Weddell, G. E. (1997). Adding functional dependencies description logics.Proceedings Fifth International Conference Deductive Object-OrientedDatabases (DOOD'97).Brachman, R. J., & Levesque, H. J. (1984). tractability subsumption frame-baseddescription languages. Proceedings Fourth National Conference ArtificialIntelligence (AAAI'84), pp. 34{37.Brachman, R. J., & Levesque, H. J. (Eds.). (1985). Readings Knowledge Representation.Morgan Kaufmann, Los Altos.Brachman, R. J., McGuinness, D. L., Patel-Schneider, P. F., Alperin Resnick, L., & Borgida,A. (1991). Living CLASSIC: use KL-ONE-like language.Sowa, J. F. (Ed.), Principles Semantic Networks, pp. 401{456. Morgan Kaufmann,Los Altos.Bresciani, P., Franconi, E., & Tessaris, S. (1995). Implementing testing expressivedescription logics: Preliminary report. Borgida, A., Lenzerini, M., Nardi, D., &Nebel, B. (Eds.), Working Notes 1995 Description Logics Workshop, TechnicalReport, RAP 07.95, Dipartimento di Informatica e Sistemistica, Universita di Roma\La Sapienza", pp. 131{139 Rome (Italy).Buchheit, M., Donini, F. M., Nutt, W., & Schaerf, A. (1998). refined architectureterminological systems: Terminology = schema + views. Artificial Intelligence, 99 (2),209{260.Buchheit, M., Donini, F. M., & Schaerf, A. (1993). Decidable reasoning terminologicalknowledge representation systems. Journal Artificial Intelligence Research, 1, 109{138.Calvanese, D. (1996a). Finite model reasoning description logics. Aiello, L. C., Doyle,J., & Shapiro, S. C. (Eds.), Proceedings Fifth International ConferencePrinciples Knowledge Representation Reasoning (KR'96), pp. 292{303. MorganKaufmann, Los Altos.Calvanese, D. (1996b). Reasoning inclusion axioms description logics: Algorithmscomplexity. Wahlster, W. (Ed.), Proceedings Twelfth European Conference Artificial Intelligence (ECAI'96), pp. 303{307. John Wiley & Sons.Calvanese, D. (1996c). Unrestricted Finite Model Reasoning ClassBased Representation Formalisms.Ph.D. thesis, Dipartimento di Informatica e Sistemistica, Universita di Roma \La Sapienza". Availablehttp://www.dis.uniroma1.it/pub/calvanes/thesis.ps.gz.Calvanese, D., De Giacomo, G., Lenzerini, M., Nardi, D., & Rosati, R. (1998). Descriptionlogic framework information integration. Proceedings Sixth International236fiUnifying Class-Based Representation FormalismsConference Principles Knowledge Representation Reasoning (KR'98),pp.2{13.Calvanese, D., & Lenzerini, M. (1994a). Making object-oriented schemas expressive.Proceedings Thirteenth ACM SIGACT SIGMOD SIGART SymposiumPrinciples Database Systems (PODS'94), pp. 243{254 Minneapolis. ACM PressAddison Wesley.Calvanese, D., & Lenzerini, M. (1994b). interaction ISA cardinalityconstraints. Proceedings Tenth IEEE International Conference DataEngineering (ICDE'94), pp. 204{213 Houston (Texas). IEEE Computer Society Press.Calvanese, D., Lenzerini, M., & Nardi, D. (1994). unified framework class based representation formalisms. Doyle, J., Sandewall, E., & Torasso, P. (Eds.), ProceedingsFourth International Conference Principles Knowledge RepresentationReasoning (KR'94), pp. 109{120 Bonn. Morgan Kaufmann, Los Altos.Calvanese, D., Lenzerini, M., & Nardi, D. (1998). Description logics conceptual datamodeling. Chomicki, J., & Saake, G. (Eds.), Logics Databases InformationSystems, pp. 229{264. Kluwer Academic Publisher.Casanova, M. A., Fagin, R., & Papadimitriou, C. H. (1984). Inclusion dependenciesinteraction functional dependencies. Journal Computer SystemSciences, 28 (1), 29{59.Cattell, R. G. G. (Ed.). (1994). Object Database Standard: ODMG-93. Morgan Kaufmann, Los Altos. Release 1.1.Cattell, R. G. G., & Barry, D. K. (Eds.). (1997). Object Database Standard: ODMG2.0. Morgan Kaufmann, Los Altos.Chandra, A. K., & Vardi, M. Y. (1985). implication problem functional inclusiondependencies undecidable. SIAM Journal Computing, 14 (3), 671{677.Chen, P. P. (1976). Entity-Relationship model: Toward unified view data. ACMTransactions Database Systems, 1 (1), 9{36.Cosmadakis, S. S., & Kanellakis, P. C. (1986). Functional inclusion dependencies -graph theoretical approach. Kanellakis, P. C., & Preparata, F. P. (Eds.), AdvancesComputing Research, Vol. 3, pp. 163{184. JAI Press.Cosmadakis, S. S., Kanellakis, P. C., & Vardi, M. (1990). Polynomial-time implicationproblems unary inclusion dependencies. Journal ACM, 37 (1), 15{46.De Giacomo, G., & Lenzerini, M. (1994a). Boosting correspondence description logics propositional dynamic logics. Proceedings Twelfth NationalConference Artificial Intelligence (AAAI'94), pp. 205{212. AAAI Press/The MITPress.237fiCalvanese, Lenzerini, & NardiDe Giacomo, G., & Lenzerini, M. (1994b). Concept language number restrictionsfixpoints, relationship -calculus. Proceedings Eleventh EuropeanConference Artificial Intelligence (ECAI'94), pp. 411{415.Di Battista, G., & Lenzerini, M. (1993). Deductive entity-relationship modeling. IEEETransactions Knowledge Data Engineering, 5 (3), 439{450.Donini, F. M., Lenzerini, M., Nardi, D., & Nutt, W. (1997). complexity conceptlanguages. Information Computation, 134, 1{58.Donini, F. M., Lenzerini, M., Nardi, D., Nutt, W., & Schaerf, A. (1994). Queries, rulesdefinitions. Foundations Knowledge Representation Reasoning. SpringerVerlag.Donini, F. M., Lenzerini, M., Nardi, D., & Schaerf, A. (1996). Reasoning descriptionlogics. Brewka, G. (Ed.), Principles Knowledge Representation, Studies Logic,Language Information, pp. 193{238. CSLI Publications.Donini, F. M., Nardi, D., & Rosati, R. (1995). Non-first-order features concept languages. Gori, M., & Soda, G. (Eds.), Proceedings Fourth ConferenceItalian Association Artificial Intelligence (AI*IA'95), Vol. 992 Lecture NotesArtificial Intelligence, pp. 91{102. Springer-Verlag.Ferg, S. (1991). Cardinality concepts entity-relationship modeling. ProceedingsTenth International Conference Entity-Relationship Approach (ER'91), pp.1{30.Fikes, R., & Kehler, T. (1985). role frame-based representation reasoning. Communications ACM, 28 (9), 904{920.Fischer, M. J., & Ladner, R. E. (1979). Propositional dynamic logic regular programs.Journal Computer System Sciences, 18, 194{211.Grant, J., & Minker, J. (1984). Numerical dependencies. Gallaire, H., Minker, J., &Nicolas, J.-M. (Eds.), Advances Database Theory II. Plenum Publ. Co., New York.Hayes, P. J. (1979). logic frames. Metzing, D. (Ed.), Frame Conceptions TextUnderstanding, pp. 46{61. Walter de Gruyter Co. Republished (Brachman &Levesque, 1985).Horrocks, I. (1998). Using expressive description logic: FaCT fiction?. ProceedingsSixth International Conference Principles Knowledge RepresentationReasoning (KR'98), pp. 636{647.Horrocks, I., & Patel-Schneider, P. F. (1999). Optimizing description logic subsumption.Journal Logic Computation, 9 (3), 267{293.Hull, R. B., & King, R. (1987). Semantic database modelling: Survey, applicationsresearch issues. ACM Computing Surveys, 19 (3), 201{260.238fiUnifying Class-Based Representation FormalismsKarp, P. D. (1992). design space knowledge representation systems. Tech. rep. SRIAI Technical Note 520, SRI International, Menlo Park, CA.Karp, P. D., Myers, K. L., & Gruber, T. (1995). generic frame protocol. ProceedingsFourteenth International Joint Conference Artificial Intelligence (IJCAI'95),Vol. A, pp. 768{774 Montreal, Canada.Kifer, M., Lausen, G., & Wu, J. (1995). Logical foundations Object-Oriented framebased languages. Journal ACM, 42 (4), 741{843.Kifer, M., & Wu, J. (1993). logic programming complex objects. JournalComputer System Sciences, 47, 77{120.Kim, W. (1990). Introduction Object-Oriented Databases. MIT Press.Kim, W., & Lochovsky, F. H. (Eds.). (1989). Object-Oriented Concepts, Databases,Applications. ACM Press Addison Wesley, New York.Kozen, D., & Tiuryn, J. (1990). Logics programs. van Leeuwen, J. (Ed.), HandbookTheoretical Computer Science { Formal Models Semantics, pp. 789{840. ElsevierScience Publishers (North-Holland), Amsterdam.Lecluse, C., & Richard, P. (1989). Modeling complex structures object-oriented databases.Proceedings Eighth ACM SIGACT SIGMOD SIGART Symposium Principles Database Systems (PODS'89), pp. 362{369.Lehmann, F. (Ed.). (1992). Semantic Networks Artificial Intelligence. Pergamon Press,Oxford.Lenzerini, M., Nardi, D., & Simi, M. (Eds.). (1991). Inheritance Hierarchies KnowledgeRepresentation Programming Languages. John Wiley & Sons, Chichester.Lenzerini, M., & Nobili, P. (1990). satisfiability dependency constraints entityrelationship schemata. Information Systems, 15 (4), 453{461.Mitchell, J. C. (1983). implication problem functional inclusion dependencies.Information Control, 56, 154{173.Motschnig-Pitrik, R., & Mylopoulous, J. (1992). Classes instances. Journal Intelligent Cooperative Information Systems, 1 (1).Nebel, B. (1991). Terminological cycles: Semantics computational properties. Sowa,J. F. (Ed.), Principles Semantic Networks, pp. 331{361. Morgan Kaufmann, LosAltos.Piza, B., Schewe, K.-D., & Schmidt, J. W. (1992). Term subsumption type constructors. Yesha, Y. (Ed.), Proceedings International Conference InformationKnowledge Management (CIKM'92), pp. 449{456 Baltimore.239fiCalvanese, Lenzerini, & NardiSchild, K. (1991). correspondence theory terminological logics: Preliminary report.Proceedings Twelfth International Joint Conference Artificial Intelligence(IJCAI'91), pp. 466{471 Sydney, Australia.Schild, K. (1994). Terminological cycles propositional -calculus. Doyle, J.,Sandewall, E., & Torasso, P. (Eds.), Proceedings Fourth International Conference Principles Knowledge Representation Reasoning (KR'94), pp.509{520 Bonn. Morgan Kaufmann, Los Altos.Schmidt-Schau, M., & Smolka, G. (1991). Attributive concept descriptions complements. Artificial Intelligence, 48 (1), 1{26.Sowa, J. F. (Ed.). (1991). Principles Semantic Networks. Morgan Kaufmann, Los Altos.Teorey, T. J. (1989). Database Modeling Design: Entity-Relationship Approach.Morgan Kaufmann, Los Altos.Thalheim, B. (1992). Fundamentals cardinality constraints. Pernoul, G., & Tjoa,A. M. (Eds.), Proceedings Eleventh International Conference EntityRelationship Approach (ER'92), pp. 7{23. Springer-Verlag.Thalheim, B. (1993). Fundamentals Entity Relationship Model. Springer-Verlag.Vardi, M. Y. (1985). taming converse: Reasoning two-way computations.Parikh, R. (Ed.), Proc. 4th Workshop Logics Programs, Vol. 193Lecture Notes Computer Science, pp. 413{424. Springer-Verlag.Woods, W. A., & Schmolze, J. G. (1992). KL-ONE family. Lehmann, F. W. (Ed.),Semantic Networks Artificial Intelligence, pp. 133{178. Pergamon Press. Publishedspecial issue Computers & Mathematics Applications, Volume 23, Number2{9.Ye, X., Parent, C., & Spaccapietra, S. (1994). Cardinality consistency derived objectsDOOD systems. Loucopoulos, P. (Ed.), Proceedings Thirteenth InternationalConference Entity-Relationship Approach (ER'94), Vol. 881 Lecture NotesComputer Science, pp. 278{295 Manchester (UK). Springer-Verlag.240fiJournal Artificial Intelligence Research 11 (1999) 391-427Submitted 1/99; published 11/99Markov Localization Mobile RobotsDynamic Environmentsdfox@cs.cmu.eduDieter FoxComputer Science Department Robotics InstituteCarnegie Mellon UniversityPittsburgh, PA 15213-3891burgard@informatik.uni-freiburg.deWolfram BurgardDepartment Computer ScienceUniversity FreiburgD-79110 Freiburg, Germanythrun@cs.cmu.eduSebastian ThrunComputer Science Department Robotics InstituteCarnegie Mellon UniversityPittsburgh, PA 15213-3891AbstractLocalization, estimation robot's location sensor data, fundamental problem mobile robotics. papers presents version Markov localizationprovides accurate position estimates tailored towards dynamic environments. key idea Markov localization maintain probability densityspace locations robot environment. approach represents spacemetrically, using fine-grained grid approximate densities. able globally localizerobot scratch recover localization failures. robust approximate models environment (such occupancy grid maps) noisy sensors (suchultrasound sensors). approach also includes filtering technique allowsmobile robot reliably estimate position even densely populated environmentscrowds people block robot's sensors extended periods time. methoddescribed implemented tested several real-world applications mobilerobots, including deployments two mobile robots interactive museum tour-guides.1. IntroductionRobot localization recognized one fundamental problems mobilerobotics (Cox & Wilfong, 1990; Borenstein et al., 1996). aim localizationestimate postition robot environment, given map environmentsensor data. successful mobile robot systems date utilize localization, knowledgerobot's position essential broad range mobile robot tasks.Localization|often referred position estimation position control|is currentlyhighly active field research, recent book Borenstein colleagues (1996) suggests.localization techniques developed far distinguished according typec 1999 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiFox, Burgard & Thrunproblem attack. Tracking local techniques aim compensating odometric errorsoccurring robot navigation. require, however, initial locationrobot (approximately) known typically cannot recover lose trackrobot's position (within certain bounds). Another family approaches called globaltechniques. designed estimate position robot even globaluncertainty. Techniques type solve so-called wake-up robot problem,localize robot without prior knowledge position. furthermorehandle kidnapped robot problem, robot carried arbitrary locationit's operation1. Global localization techniques powerful local ones.typically cope situations robot likely experience seriouspositioning errors.paper present metric variant Markov localization, technique globallyestimate position robot environment. Markov localization uses probabilisticframework maintain position probability density whole set possible robotposes. density arbitrary forms representing various kinds informationrobot's position. example, robot start uniform distributionrepresenting completely uncertain position. furthermore containmultiple modes case ambiguous situations. usual case, robothighly certain position, consists unimodal distribution centered aroundtrue position robot. Based probabilistic nature approachrepresentation, Markov localization globally estimate position robot,deal ambiguous situations, re-localize robot case localizationfailures. properties basic preconditions truly autonomous robots designedoperate long periods time.method uses fine-grained metric discretization state space. approach several advantages previous ones, predominately used Gaussianscoarse-grained, topological representations approximating robot's belief. First, provides accurate position estimates, required many mobile robot tasks (e.g.,tasks involving mobile manipulation). Second, incorporate raw sensory inputsingle beam ultrasound sensor. previous approaches Markov localization,contrast, screen sensor data presence absence landmarks, pronefail environment align well underlying assumptions (e.g.,contain required landmarks).importantly, however, previous Markov localization techniques assumedenvironment static. Therefore, typically fail highly dynamic environments,public places crowds people may cover robot's sensors extended periodstime. deal situations, method applies filtering technique that,essence, updates position probability density using measurementshigh likelihood produced known objects contained map. result,permits accurate localization even densely crowded, non-static environments.Markov localization approach implemented evaluated various environments, using different kinds robots sensor modalities. Among applicationsdeployments mobile robots Rhino Minerva (see Figure 1) interac1. Please note wake-up problem special case kidnapped robot problemrobot told carried away.392fiMarkov Localization Mobile Robots Dynamic Environments(a)(b)Fig. 1. mobile robots Rhino (a) Minerva (b) acting interactive museum tour-guides.tive museum tour-guide robots (Burgard et al., 1998a, 2000; Thrun et al., 1999)Deutsches Museum Bonn National Museum American History Washington,DC, respectively. Experiments described paper illustrate ability Markovlocalization technique deal approximate models environment, occupancy grid maps noisy sensors ultrasound sensors, demonstrateapproach well-suited localize robots densely crowded environments,museums full people.paper organized follows. next section describes mathematical framework Markov localization. introduce metric version Markov localizationSection 3. section also presents probabilistic model proximity sensors filtering scheme deal highly dynamic environments. Thereafter, describe experimentalresults illustrating different aspects approach. Related work discussed Section 5followed concluding remarks.2. Markov Localizationintroduce major concepts, begin intuitive description Markovlocalization, followed mathematical derivation algorithm. reader maynotice Markov localization special case probabilistic state estimation, appliedmobile robot localization (see also Russell & Norvig, 1995; Fox, 1998 Koenig &Simmons, 1998).clarity presentation, initially make restrictive assumptionenvironment static. assumption, called Markov assumption, commonly maderobotics literature. postulates robot's location state environment systematically affects sensor readings. Markov assumption violatedrobots share environment people. below, Section 3.3,side-step assumption present Markov localization algorithm works well evenhighly dynamic environments, e.g., museums full people.2.1 Basic IdeaMarkov localization addresses problem state estimation sensor data. Markovlocalization probabilistic algorithm: Instead maintaining single hypothesis393fiFox, Burgard & ThrunFig. 2. basic idea Markov localization: mobile robot global localization.world robot might be, Markov localization maintains probability distributionspace hypotheses. probabilistic representation allows weighdifferent hypotheses mathematically sound way.delve mathematical detail, let us illustrate basic conceptssimple example. Consider environment depicted Figure 2. sake simplicity,let us assume space robot positions one-dimensional, is, robotmove horizontally (it may rotate). suppose robot placed somewhereenvironment, told location. Markov localization represents stateuncertainty uniform distribution positions, shown graphfirst diagram Figure 2. let us assume robot queries sensors findsnext door. Markov localization modifies belief raising probabilityplaces next doors, lowering anywhere else. illustrated seconddiagram Figure 2. Notice resulting belief multi-modal, ecting factavailable information insucient global localization. Notice also placesnext door still possess non-zero probability. sensor readings noisy,single sight door typically insucient exclude possibilitynext door.let us assume robot moves meter forward. Markov localization incorporatesinformation shifting belief distribution accordingly, visualized thirddiagram Figure 2. account inherent noise robot motion, inevitablyleads loss information, new belief smoother (and less certain) previousone. Finally, let us assume robot senses second time, finds nextdoor. observation multiplied current (non-uniform) belief, leadsfinal belief shown last diagram Figure 2. point time,probability centered around single location. robot quite certainposition.394fiMarkov Localization Mobile Robots Dynamic Environments2.2 Basic Notationmake formal, let us denote position (or: location) mobile robotthree-dimensional variable l = hx; y; i, comprising x-y coordinates (in Cartesiancoordinate system) heading direction . Let lt denote robot's true locationtime t, Lt denote corresponding random variable. Throughout paper,use terms position location interchangeably.Typically, robot know exact position. Instead, carries beliefmight be. Let Bel(Lt ) denote robot's position belief time t. Bel(Lt )probability distribution space positions. example, Bel(Lt = l)probability (density) robot assigns possibility location timel. belief updated response two different types events: arrival measurement robot's environment sensors (e.g., camera image, sonar scan),arrival odometry reading (e.g., wheel revolution count). Let us denote environment sensor measurements odometry measurements a, correspondingrandom variables A, respectively.robot perceives stream measurements, sensor measurements odometryreadings a. Let= fd0 ; d1 ; : : : ; dT g(1)denote stream measurements, dt (with 0 ) either sensormeasurement odometry reading. variable indexes data,recently collected data item (one might think \time"). set d, comprisesavailable sensor data, referred data.2.3 Recursive LocalizationMarkov localization estimates posterior distribution LT conditioned availabledata,P (LT = l j d) = P (LT = l j d0 ; : : : ; dT ):(2)deriving incremental update equations posterior, let us brie make explicitkey assumption underlying derivation, called Markov assumption. Markovassumption, sometimes referred static world assumption, specifies one knowsrobot's location lt , future measurements independent past ones (and vice versa):P (dt+1 ; dt+2 ; : : : j Lt = l; d0 ; : : : ; dt ) = P (dt+1 ; dt+2 ; : : : j Lt = l) 8t(3)words, assume robot's location state environment,knowing one needs know past predict future data. assumptionclearly inaccurate environment contains moving (and measurable) objectsrobot itself. below, Section 3.3, extend basic paradigmnon-Markovian environments, effectively devising localization algorithm works wellbroad range dynamic environments. now, however, adhere Markovassumption, facilitate derivation basic algorithm.395fiFox, Burgard & Thruncomputing P (LT = l j d), distinguish two cases, depending whetherrecent data item dT sensor measurement odometry reading.Case 1: recent data item sensor measurement dT = sT .P (LT = l j d) = P (LT = l j d0 ; : : : ; dT 1 ; sT ):(4)Bayes rule suggests term transformedP (sT j d0 ; : : : ; dT 1 ; LT = l) P (LT = l j d0 ; : : : ; dT 1 );(5)P (s j ; : : : ; )01which, Markov assumption, simplified to:P (sT j LT = l) P (LT = l j d0 ; : : : ; dT 1 ):(6)P (sT j d0 ; : : : ; dT 1 )also observe denominator replaced constant ffT , sincedepend LT . Thus,P (LT = l j d) = ffT P (sT j LT = l) P (LT = l j d0 ; : : : ; dT 1 ):(7)reader may notice incremental nature Equation (7): writeBel(LT = l) = P (LT = l j d0 ; : : : ; dT );(8)denote robot's belief Equation (7) becomesBel(LT = l) = ffT P (sT j l) Bel(LT 1 = l):(9)equation replaced term P (sT j LT = l) P (sT j l) based assumptionindependent time.Case 2: recent data item odometry reading: dT = .compute P (LT = l j d) using Theorem Total Probability:ZP (LT = l j d) =P (LT = l j d; LT 1 = l0 ) P (LT 1 = l0 j d) dl0 :(10)Consider first term right-hand side. Markov assumption suggestsP (LT = l j d; LT 1 = l0 ) = P (LT = l j d0 ; : : : ; dT 1 ; ; LT 1 = l0 )(11)0= P (LT = l j ; LT 1 = l )(12)second term right-hand side Equation (10) also simplified observingcarry information position LT 1:P (LT 1 = l0 j d) = P (LT 1 = l0 j d0 ; : : : ; dT 1 ; )(13)0= P (LT 1 = l j d0 ; : : : ; dT 1 )(14)396fiMarkov Localization Mobile Robots Dynamic EnvironmentsSubstituting 12 14 back Equation (10) gives us desired resultP (LT= l j d) =ZP (LT= l j ; LT 1 = l0) P (LT 1 = l0 j d0 ; : : : ; dT 1) dl0 : (15)Notice Equation (15) is, too, incremental form. definition beliefabove,Bel(LT= l) =ZP (l j ; l0 ) Bel(LT1= l0) dl0:(16)Please note used P (l j ; l0 ) instead P (LT = l j ; LT 1 = l0 ) since assumechange time.2.4 Markov Localization AlgorithmUpdate Equations (9) (16) form core Markov localization algorithm. fullalgorithm shown Table 1. Following Basye et al. (1992) Russell & Norvig (1995),denote P (l j a; l0 ) robot's motion model, since models motion effectrobot's position. conditional probability P (s j l) called perceptual model,models outcome robot's sensors.Markov localization algorithm P (L0 = l), initializes belief Bel(L0),ects prior knowledge starting position robot. distributioninitialized arbitrarily, practice two cases prevail: position robotrelative map entirely unknown, P (L0 ) usually uniformly distributed. initialposition robot approximately known, P (L0 ) typically narrow Gaussiandistribution centered robot's position.2.5 Implementations Markov Localizationreader may notice principle Markov localization leaves open1. robot's belief Bel(L) represented2. conditional probabilities P (l j a; l0 ) P (s j l) computed.Accordingly, existing approaches Markov localization mainly differ representationstate space computation perceptual model. sectionbrie discuss different implementations Markov localization focusing two topics(see Section 5 detailed discussion related work).1. State Space Representations: common approach representationrobots belief Bel(L) based Kalman filtering (Kalman, 1960; Smith et al.,1990) rests restrictive assumption position robotmodeled unimodal Gaussian distribution. Existing implementations (Leonard& Durrant-Whyte, 1992; Schiele & Crowley, 1994; Gutmann & Schlegel, 1996; Arras & Vestli, 1998) proven robust accurate keeping trackrobot's position. restrictive assumption Gaussian distributiontechniques lack ability represent situations position robot397fiFox, Burgard & Thrunlocation lBel(L0 = l)P (L0 = l)/* initialize belief */(17)endforevernew sensory input sT receivedffT0location l/* apply perception model */(LT = l)BelP (sT j l) Bel(LT 1 = l)(18)(LT = l)ffTffT + Bel(19)endlocation lBel(LT = l)ffT/* normalize belief */1 Bel(LT = l)(20)endendodometry reading receivedlocation lBel(LT= l)Z/* apply motion model */P (l j l0 ; ) Bel(LT1= l0 ) dl0(21)endendend foreverTab. 1. Markov localization algorithmmaintains multiple, distinct beliefs (c.f. 2). result, localization approaches usingKalman filters typically require starting position robot knownable re-localize robot case localization failures. Additionally,Kalman filters rely sensor models generate estimates Gaussian uncertainty. assumption, unfortunately, met situations (see exampleDellaert et al. 1999).398fiMarkov Localization Mobile Robots Dynamic Environmentsovercome limitations, different approaches used increasingly richerschemes represent uncertainty robot's position, moving beyond Gaussiandensity assumption inherent vanilla Kalman filter. Nourbakhsh et al. (1995),Simmons & Koenig (1995), Kaelbling et al. (1996) use Markov localizationlandmark-based corridor navigation state space organized accordingcoarse, topological structure environment generally four possibleorientations robot. approaches can, principle, solve problemglobal localization. However, due coarse resolution state representation,accuracy position estimates limited. Topological approaches typically giverough sense robot is. Furthermore, techniques requireenvironment satisfies orthogonality assumption certainlandmarks abstract features extracted sensor data.assumptions make dicult apply topological approaches unstructuredenvironments.2.addition different representations state space variousperception models developed different types sensors (see exampleMoravec, 1988; Kortenkamp & Weymouth, 1994; Simmons & Koenig, 1995; Burgardet al., 1996; Dellaert et al., 1999; Konolige, 1999). sensor models differway compute probability current measurement. Whereastopological approaches (Kortenkamp & Weymouth, 1994; Simmons & Koenig,1995; Kaelbling et al., 1996) first extract landmark information sensor scan,approaches (Moravec, 1988; Burgard et al., 1996; Dellaert et al., 1999; Konolige,1999) operate raw sensor measurements. techniques proximity sensorsdescribed (Moravec, 1988; Burgard et al., 1996; Konolige, 1999) mainly differeciency model characteristics sensors mapenvironment.Sensor Models:order combine strengths previous representations, approach reliesfine less restrictive representation state space (Burgard et al., 1996, 1998b;Fox, 1998). robot's belief approximated fine-grained, regularly spaced grid,spatial resolution usually 10 40 cm angular resolutionusually 2 5 degrees. advantage approach compared Kalman-filter basedtechniques ability represent multi-modal distributions, prerequisite globallocalization scratch. contrast topological approaches Markov localization,approach allows accurate position estimates much broader range environments,including environments might even possess identifiable landmarks. Sincedepend abstract features, incorporate raw sensor data robot's belief.typically yields results order magnitude accurate. obviousshortcoming grid-based representation, however, size state spacemaintained. Section 3.4 addresses issue directly introducing techniquesmake possible update extremely large grids real-time.399fiFox, Burgard & Thrun(a)(b)Fig. 3. Typical \banana-shaped" distributions resulting different motion actions.3. Metric Markov Localization Dynamic Environmentssection describe metric variant Markov localization. includesappropriate motion sensor models. also describe filtering techniquedesigned overcome assumption static world model generally made Markovlocalization allows localize mobile robot even densely crowded environments.describe fine-grained grid-based representation state space presenttechniques eciently update even large state spaces.3.1 Action Modelupdate belief robot moves, specify action model P (l j l0; ).Based assumption normally distributed errors translation rotation,use mixture two independent, zero-centered Gaussian distributions whose tails cut(Burgard et al., 1996). variances distributions proportional lengthmeasured motion.Figure 3 illustrates resulting densities two example paths robot's beliefstarts Dirac distribution. distributions three-dimensional (in hx; y; i-space)Figure 3 shows 2D projections hx; yi-space.3.2 Perception Model Proximity Sensorsmentioned above, likelihood P (s j l) sensor reading measured position l computed positions l update Markov localizationalgorithm (see Table 1). Therefore, crucial on-line position estimationquantity computed eciently. Moravec (1988) proposed method computegenerally non-Gaussian probability density function P (s j l) discrete set possibledistances measured ultrasound sensor location l. first implementationapproach (Burgard et al., 1996) used similar method, unfortunately turnedcomputationally expensive localization real-time.overcome disadvantage, developed sensor-model allows computeP (s j l) solely based distance ol closest obstacle map along directionsensor. distance computed ray-tracing occupancy grid maps400fiMarkov Localization Mobile Robots Dynamic Environments0.125ol0.1SonarLaserprobability Pu (di )probability Pm (di | l)0.1250.0750.050.0250SonarLaser0.10.0750.050.025100200300measured distance di [cm]4000500100200(a)300measured distance di [cm]400500(b)Fig. 4. Probability measuring distance di (a) obstacle distance ol detected (b) dueunknown obstacles.CAD-models environment. particular, consider discretization d1 ; : : : ; dnpossible distances measured proximity sensor. discretization, sizeranges = di+1 di i, dn corresponds maximal rangeproximity sensor2. Let P (di j l) denote probability measuring distance dirobot location l. order derive probability first consider following twocases (see also Hennig 1997 Fox 1998):a.) Known obstacles: sensor detects obstacle resulting distributionmodeled Gaussian distribution mean distance obstacle. LetPm (d j l) denote probability measuring distance robot location l,assuming sensor beam ected closest obstacle map (alongsensor beam). denote distance specific obstacle ol . probabilityPm (d j l) given Gaussian distribution mean ol :ol1(22)Pm (d j l) = p e2standard deviation distribution models uncertainty measureddistance, basedgranularity discretization L, represents robot's position,accuracy world model,accuracy sensor.Figure 4(a) gives examples Gaussian distributions ultrasound sensorslaser range-finders. distance ol closest obstacle 230cm. Observelaser sensor higher accuracy ultrasound sensor, indicatedsmaller variance.b.) Unknown obstacles: Markov localization, world model generally assumedstatic complete. However, mobile robot environments often populatedtherefore contain objects included map. Consequently,(2 2)22. Typical values n 64 256 maximal range dn typically 500cm 1000cm.401fiFox, Burgard & Thrunnon-zero probability sensor ected obstacle representedworld model. Assuming objects equally distributed environment,probability Pu (di ) detecting unknown obstacle distance di independentlocation robot modeled geometric distribution.distribution results following observation. distance di measuredsensor ected obstacle shorter distance dj<i ecteddistance di . resulting probability(0i=0Pu (di ) =(23)Pcr (1j<i Pu (dj )) otherwise:equation constant cr probability sensor ectedunknown obstacle range given discretization.typical distribution sonar laser measurements depicted Figure 4(b).example, relatively large probability measuring 500cm due factmaximum range proximity sensors set 500cm. Thus, distancerepresents probability measuring least 500cm.Obviously, one two cases occur certain point time, i.e.,sensor beam either ected known unknown object. Thus, P (di j l)mixture two distributions Pm Pu. determine combined probabilityP (di j l) measuring distance di robot location l consider followingtwo situations: distance di measured,a.) sensor beam1.) ected unknown obstacle reaching distance diXa1 = 1Pu (dj );(24)j<i2.)ected known obstacle distance dia2 = cd Pm (di j l)(25)b.) beam1.) ected neither unknown obstacle known obstaclereaching distance diXb1 = 1P (dj j l)(26)j<i2.)ected unknown obstacle distance dib2 = cr :402(27)fiMarkov Localization Mobile Robots Dynamic Environments0.125ApproximatedMeasured0.1probability p(d | l)probability p(d | l)0.125ol0.0750.050.0250ApproximatedMeasured0.1ol0.0750.050.0251002003004000500(a)measured distance di [cm]100200300measured distance di [cm]400500(b)Fig. 5. Measured approximated probabilities (a) sonar (b) laser measurements givendistance ol closest obstacle along sensing direction.parameter cd Equation (25) denotes probability sensor detects closestobstacle map. considerations combined probability summarizedEquation (28). double negation insertion Equations (24) (27), finallyget Equation (31).P (di j l) =p(a1 ^ a2 ) _ (b1 ^ b2)(28)= :p :(a1 ^ a2 ) ^ :(b1 ^ b2)(29)= 1 [1 P (a1a2 )] [1 P (b1 b2 )](30)XX= 1 1 (1Pu (dj )) cd Pm (di j l))) (1 (1P (dj )) cr (31)j<ij<iobtain probability measuring dn, maximal range sensor, exploitfollowing equivalence: probability measuring distance larger equalmaximal sensor range equivalent probability measuring distance shorterdn. incremental scheme, probability easily determined:XP (dn j l) = 1P (dj j l)(32)j<nsummarize, probability sensor measurements computed incrementallydifferent distances starting distance d1 = 0cm. distance consider probability sensor beam reaches corresponding distance ected eitherclosest obstacle map (along sensor beam), unknown obstacle.order adjust parameters , cr cd perception model collectedeleven million data pairs consisting expected distance ol measured distancedi typical operation robot. data able estimateprobability measuring certain distance di distance ol closest obstaclemap along sensing direction given. dotted line Figure 5(a) depictsprobability sonar measurements distance ol next obstacle 230cm. Again,high probability measuring 500cm due fact distance representsprobability measuring least 500cm. solid line figure representsdistribution obtained adapting parameters sensor model best fit403fiFox, Burgard & Thrunprobabilityprobability0.40.40.30.30.20.20.10.150005000400400300measured distance [cm]200100300expected distance [cm]300measured distance [cm]200100200200100300expected distance [cm]400100400(a)(b)probabilityprobability0.40.40.30.30.20.20.10.150005000400400300measured distance [cm]200100300expected distance [cm]300measured distance [cm]200100200200100300expected distance [cm]400(c)100400(d)Fig. 6. Measured approximated probability sonar (a,b) laser (c,d) measurements, respectively. table contains probabilities distance measurements given expected distanceol extracted map environment.measured data. corresponding measured approximated probabilities lasersensor plotted Figure 5(b).observed densities possible distances ol obstacle ultrasound sensorslaser range-finder depicted Figure 6(a) Figure 6(c), respectively. approximated densities shown Figure 6(b) Figure 6(d). figures, distance ollabeled \expected distance". similarity measured approximateddistributions shows sensor model yields good approximation data.Please note well-known types sensor noise explicitly represented sensor model. Among specular ections cross-talkoften regarded serious sources noise context ultra-sound sensors.However, sources sensor noise modeled implicitly geometric distributionresulting unknown obstacles.3.3 Filtering Techniques Dynamic EnvironmentsMarkov localization shown robust occasional changes environmentopened / closed doors people walking by. Unfortunately, fails localizerobot many aspects environment covered world model.case, example, densely crowded environments, groups people coverrobots sensors thus lead many unexpected measurements. mobile robotsRhino Minerva, deployed interactive museum tour-guides (Burgard et al.,1998a, 2000; Thrun et al., 1999), permanently faced situation. Figure 7404fiMarkov Localization Mobile Robots Dynamic EnvironmentsRHINO(a)(b)Fig. 7. Rhino surrounded visitors DeutschesMuseum Bonn.(a)(b)Fig. 8. Typical laser scans obtained Rhino surrounded visitors.shows two cases robot Rhino surrounded many visitors givingtour Deutsches Museum Bonn, Germany.reason Markov localization fails situations violation Markovassumption, independence assumption virtually localization techniquesbased. discussed Section 2.3, assumption states sensor measurementsobserved time independent measurements, given current stateLt world known. case localization densely populated environments,independence assumption clearly violated using static model world.illustrate point, Figure 8 depicts two typical laser scans obtainedmuseum projects (maximal range measurements omitted). figure also showsobstacles contained map. Obviously, readings are, large extent, corrupted,since people museum represented static world model. differentshading beams indicates two classes belong to: black lines correspondstatic obstacles map independent positionrobot known. grey-shaded lines beams ected visitors Museum.sensor beams cannot predicted world model therefore independentother. Since vicinity people usually increases robot's belief closemodeled obstacles, robot quickly loses track position incorporating405fiFox, Burgard & Thrunsensor measurements. reestablish independence sensor measurements couldinclude position robot position people state variable L.Unfortunately, infeasible since computational complexity state estimationincreases exponentially number dependent state variables estimated.closely related solution problem could adapt map accordingchanges environment. Techniques concurrent map-building localization(Lu & Milios, 1997a; Gutmann & Schlegel, 1996; Shatkey & Kaelbling, 1997; Thrun etal., 1998b), however, also assume environment almost static thereforeunable deal environments. Another approach would adapt perceptionmodel correctly ect situations. Note perceptual model already assignscertain probability events sensor beam ected unknown obstacle.Unfortunately, approaches capable model noise average.approaches turn work reliably occasional sensor blockage, sucientsituations fifty percent sensor measurements corrupted.localization system therefore includes filters designed detect whether certainsensor reading corrupted not. Compared modification static sensor modeldescribed above, filters advantage average possiblesituations decision based current belief robot.filters designed select readings complete scan comeobjects contained map. section introduce two different kinds filters.first one called entropy filter. Since filters reading based solely effectbelief Bel(L), applied arbitrary sensors. second filter distancefilter selects readings according much shorter expectedvalue. therefore especially designed proximity sensors.3.3.1 Entropy Filterentropy H (L) belief L definedXH (L) =Bel(L = l) log Bel(L = l)l(33)measure uncertainty outcome random variable L (Cover &Thomas, 1991). higher entropy, higher robot's uncertaintyis. entropy filter measures relative change entropy upon incorporating sensorreading belief Bel(L). specifically, let denote measurement sensor(in case single range measurement). change entropy Bel(L) givendefined as:H (L j s) := H (L j s) H (L)(34)term H (L j s) entropy belief Bel(L) incorporating sensor measurement (see Equations (18) { (20)). positive change entropy indicatesincorporating s, robot less certain position, negative change indicatesincrease certainty. selection scheme entropy filter exclude sensormeasurements H (L j s) < 0. words, uses sensor readingsconfirming robot's current belief.406fiMarkov Localization Mobile Robots Dynamic Environments1olprobability0.8Pshort (di j l)Pm (di j l)0.60.40.20100200300400500measured distance [cm]Fig. 9. Probability Pm (di j l) expected measurement probability Pshort (di j l) distancedi shorter expected measurement given location l.Entropy filters work well robot's belief focused correct hypothesis.However, may fail situations robot's belief state incorrect. topicanalyzed systematically experiments described Section 4.1. advantageentropy filter makes assumptions nature sensor datakind disturbances occurring dynamic environments.3.3.2 Distance Filterdistance filter specifically designed proximity sensors laser rangefinders. Distance filters based simple observation: proximity sensing, unmodeledobstacles typically produce readings shorter distance expectedmap. essence, distance filter selects sensor readings based distance relativedistance closest obstacle map.specific, filter removes sensor measurements probability higher (this threshold set 0:99 experiments) shorterexpected, therefore caused unmodeled object (e.g. person).see, let d1 ; : : : ; dn discrete set possible distances measured proximitysensor. Section 3.2, denote Pm (di j l) probability measuring distance dirobot position l sensor detects closest obstacle map alongsensing direction. distribution Pm describes sensor measurement expectedmap. described above, distribution assumed Gaussian meandistance ol closest obstacle along sensing direction. dashed line Figure 9represents Pm , laser range-finder distance ol 230cm. defineprobability P (di j l) measured distance di shorter expected one givenrobot position l. probability obviously equivalent probabilityexpected measurement ol longer di given robot location l thuscomputed follows:XP (di j l) =Pm (dj j l):(35)shortshortj>i407fiFox, Burgard & ThrunBel(Lt = l)x(0; 0; 0)Fig. 10. Grid-based representation state spacepractice, however, interested probability P (di ) di shorterexpected, given complete current belief robot. Thus, averagepossible positions robot:XP (di ) =P (di j l)Bel(L = l)(36)shortshortlshortGiven distribution P (di ), implement distance filter excludingsensor measurements di P (di ) > . Whereas entropy filter filters measurementsaccording effect belief state robot distance filter selects measurements solely based value regardless effect robot's certainty.noted Fox (1998) additionally developed blockage filter proximitysensors, based probabilistic description situations sensorblocked unknown obstacle. omit filter since derivation quite complexresulting filter significantly different distance filter described here.shortshort3.4 Grid-based Representation State Spacereturn issue represent compute belief distributionrobot eciently, describing one might think \nut bolts" gridbased Markov localization. Recall obtain accurate metric position estimates,approach Markov localization uses fine-grained discretization state space.L represented three-dimensional, regularly spaced grid, spatial resolutionusually 10cm 40cm angular resolution usually 2 5 degrees.Figure 10 illustrates structure position probability grid. layer gridcorresponds possible poses robot orientation.fine-grained approximation makes possible estimate robot's position high accuracy, obvious disadvantage fine-grained discretization lies408fiMarkov Localization Mobile Robots Dynamic Environmentshuge state space maintained. mid-size environment size30 30m2 , angular grid resolution 2 , cell size 15 15cm2 state spaceconsists 7; 200; 000 states. basic Markov localization algorithm updatesstates sensory input atomic movement robot. Current computerspeed, thus, makes impossible update matrices size real-time.update state spaces eciently, developed two techniques,described remainder section. first method, introduced Section 3.4.1,pre-computes sensor model. allows us determine likelihood P (s j l) sensormeasurements two look-up operations|instead expensive ray tracing operations.second optimization, described Section 3.4.2, selective update strategy. strategyfocuses computation, updating relevant part state space. Basedtwo techniques, grid-based Markov localization applied on-line estimateposition mobile robot operation, using low-cost PC.3.4.1 Pre-Computation Sensor Modeldescribed Section 3.2, perception model P (s j l) proximity sensors dependsdistance ol closest obstacle map along sensor beam. Basedassumption map environment static, approach pre-computes storesdistances ol possible robot location l environment. Following sensormodel, use discretization d1 ; : : : ; dn possible distances ol . discretizationexactly expected measured distances. storelocation l index expected distance ol three-dimensional table. Pleasenote table needs one byte per value 256 different values discretizationol used. probability P (di j ol ) measuring distance di closest obstacledistance ol (see Figure 6) also pre-computed stored two-dimensionallookup-table.result, probability P (s j l) measuring given location l quicklycomputed two nested lookups. first look-up retrieves distance ol closestobstacle sensing direction given robot location l. second lookupused get probability P (s j ol ). ecient computation based table look-upsenabled implementation quickly incorporate even laser-range scans consist180 values overall belief state robot. experiments, uselook-up tables led speed-up-factor 10, compared computationdistance closest obstacle run-time.3.4.2 Selective Updateselective update scheme based observation global localization,certainty position estimation permanently increases density quickly concentrates grid cells representing true position robot. probabilitygrid cells decreases localization key idea optimizationexclude unlikely cells updated.purpose, introduce threshold3 " update grid cells lBel(Lt = l) > ". allow selective update still maintaining density3. current implementation " set 1% priori position probability.409fiFox, Burgard & Thrunentire state space, approximate P (st j l) cells Bel(Lt = l) "priori probability measuring st . quantity, call Pe (st ), determinedaveraging possible locations robot:XPe (st ) = P (st j l) P (l)l(37)Please note Pe (st) independent current belief state robotdetermined beforehand. incremental update rule new sensor measurement stchanged follows (compare Equation (9)):(fft P (st j l) Bel(Lt 1 = l) Bel(Lt 1 = l) > "Bel(Lt = l)(38)fft P~ (st ) Bel(Lt 1 = l) otherwisemultiplying Pe (st) normalization factor fft , rewrite equation8< ff~ P (st jl) Bel(Lt 1 = l) Bel(Lt 1 = l) > "Pe(st )(39)Bel(Lt = l): ff~Bel(Lt 1 = l) otherwiseff~t = fft Pe (st ).key advantage selective update scheme given Equation (39) cellsBel(Lt 1 = l) " updated value ff~t . order obtain smoothtransitions global localization position tracking focus computationimportant regions state space L, example, case ambiguities usepartitioning state space. Suppose state space L partitioned n segmentsparts 1; : : : ; n. segment called active time contains locations probability threshold "; otherwise call part passive probabilitiescells threshold. Obviously, keep track individual probabilities within passive part accumulating normalization factors ff~t valuefii . Whenever segment becomes passive, i.e. probabilities locations withinlonger exceed ", normalizer fii (t) initialized 1 subsequently updatedfollows: fii(t + 1) = ff~t fii (t). soon part becomes active again, restoreprobabilities individual grid cells multiplying probabilities cellaccumulated normalizer fii (t). keeping track robot motion since part becamepassive, suces incorporate accumulated motion whenever part becomes activeagain. order eciently detect whether passive part activated again,store maximal probability Pimax cells part time becomes passive.Whenever Pimax fii (t) exceeds ", part activated contains leastone position probability threshold. current implementation partition state space L part consists locations equal orientationrelative robot's start location.illustrate effect selective update scheme, let us compare updateactive passive cells incoming sensor data. According Equation (39), differencelies ratio P (st j l)=P~ (st ). example ratio model proximity sensorsdepicted Figure 11 (here, replaced st proximity measurement di ).beginning localization process, cells active updated according ratio410fiMarkov Localization Mobile Robots Dynamic Environmentsol9LaserSonar8likelihood ratio76543210100200300400500measured distance di [cm]Fig. 11. Ratio PP~((ddiijl)) sonar laser measurements expected distance ol 230cm.depicted Figure 11. measured expected distances cells representtrue location robot usually deviate significantly. Thus, probabilitiescells quickly fall threshold ".effect selective update scheme becomes obvious: parts statespace align well orientation environment, quickly become passiverobot localizes itself. Consequently, small fraction state spaceupdated soon robot correctly determined position. If, however,position robot lost, likelihood ratios distances measuredactive locations become smaller one average. Thus probabilities activelocations decrease normalizers fii passive parts increase segmentsactivated again. true position robot among active locations,robot able re-establish correct belief.extensive experimental tests observe evidence selective updatescheme noticably negative impact robot's behavior. contrast, turnedhighly effective, since practice small fraction (generally less 5%)state space updated position robot determinedcorrectly, probabilities active locations generally sum least 0.99.Thus, selective update scheme automatically adapts computation time requiredupdate belief certainty robot. way, system able ecientlytrack position robot position determined. Additionally, Markovlocalization keeps ability detect localization failures relocalize robot.disadvantage lies fixed representation grid undesirableeffect memory requirement current implementation stays constant evenminor part state space updated. context would like mentionrecently promising techniques presented overcome disadvantageapplying alternative dynamic representations state space (Burgard et al., 1998b;Fox et al., 1999).4. Experimental Resultsmetric Markov localization technique, including sensor filters, implemented evaluated extensively various environments. section present411fiFox, Burgard & Thrunexperiments carried mobile robots Rhino Minerva (see Figure 1).Rhino ring 24 ultrasound sensors opening angle 15 degrees. Both,Rhino Minerva equipped two laser range-finders covering 360 degrees fieldview.first set experiments demonstrates robustness Markov localization tworeal-world scenarios. particular, systematically evaluates effect filteringtechniques localization performance highly dynamic environments. additionalexperiment illustrates advantage filtering technique, enables mobilerobot reliably estimate position even outline oce environmentgiven map.experiments described section, illustrate abilityMarkov localization technique globally localize mobile robot approximate worldmodels occupancy grid maps, even using inaccurate sensors ultrasoundsensors. Finally, present experiments analyzing accuracy eciency grid-basedMarkov localization respect size grid cells.experiments reported demonstrate Markov localization able globallyestimate position mobile robot, reliably keep track evenapproximate model possibly dynamic environment given, robot weakodometry, noisy sensors ultrasound sensors used.4.1 Long-term Experiments Dynamic Environmentsmobile robots Rhino Minerva, operated Deutsches Museum BonnUS-Smithsonian's National Museum American History, robustness reliability Markov localization system utmost importance. Accurate positionestimation crucial component, many obstacles \invisible" robots'sensors (such glass cages, metal bars, staircases, alike). Given estimaterobot's position (Fox et al., 1998b) integrated map information collision avoidance system order prevent robot colliding obstacles coulddetected.Figure 12(a) shows typical trajectory robot Rhino, recorded museumBonn, along map used localization. reader may noticeobstacles shown black actually used localization; others either invisiblecould detected reliably. Rhino used entropy filter identify sensor readingscorrupted presence people. Rhino's localization module able (1)globally localize robot morning robot switched (2) reliablyaccurately keep track robot's position. entire six-day deployment period,Rhino traveled 18km, approach led single software-related collision,involved \invisible" obstacle caused localization errorslightly larger 30cm safety margin.Figure 12(b) shows 2km long trajectory robot Minerva National MuseumAmerican History. Minerva used distance filter identify readings ectedunmodeled objects. filter developed Rhino's deployment museumBonn, based analysis localization failure reported attemptprevent similar effects future installations. Based distance filter, Minerva able412fiMarkov Localization Mobile Robots Dynamic EnvironmentsDuration: 4.8 hoursDistance: 1540 metersDuration: 1 hourDistance: 2000 meters(a)(b)Fig. 12. Typical trajectories (a) RhinoNational Museum American History.Deutsches Museum Bonn(b) Minervaoperate reliably period 13 days. time Minerva traveled total44km maximum speed 1.63m/sec.Unfortunately, evidence museum projects anecdotal. Based sensordata collected Rhino's deployment museum Bonn, also investigatedeffect filter techniques systematically, even extreme conditions.particular, interested localization resultsa.) environment densely populated (more 50% sensor readingcorrupted),b.) robot suffers extreme dead-reckoning errors (e.g. induced person carrying robot somewhere else). Since cases rare, manually ictederrors original data analyze effect.4.1.1 Datasetsexperiments, used two different datasets. sets differ mainlyamount sensor noise.a.) first dataset collected 2.0 hours robot motion, robottraveled approximately 1,000 meters. dataset collected museumclosed, robot guided remote Internet-visitors museum.robot's top speed 50cm/sec. Thus, dataset \ideal"environment sparsely populated, robot moved slowly.b.) second dataset recorded period 4.8 hours, Rhinotraveled approximately 1,540 meters. path dataset shown Figure 12(a). collecting data, robot operated peak trac hours.frequently faced situations one illustrated Figure 7.robot's top speed 80cm/sec.datasets consist logs odometry laser range-finder scans, collectedrobot moved museum. Using time stamps logs, tests413fiFox, Burgard & ThrunDenesely populatedSparcely populatedNoise [%]604020100040007000100001300016000Time [sec]Fig. 13. Percentage noisy sensor measurements averaged time intervals five minutes.conducted real-time simulation SUN-Ultra-Sparc 1 (177-MHz). first datasetcontained 32,000, second dataset 73,000 laser scans.evaluate different localization methods, generated two reference paths, averagingestimates nine independent runs filter datasets (with smallrandom noise added input data). verified correctness reference pathsvisual inspection; hence, taken \ground truth."Figure 13 shows estimated percentage corrupted sensor readings timedatasets. dashed line corresponds first data set, solid line illustratescorruption second (longer) data set. second dataset, halfmeasurements corrupted extended durations time, estimated analyzinglaser reading post-facto whether significantly shorter distancenext obstacle.4.1.2 Tracking Robot's Positionfirst series experiments, interested comparing ability threeapproaches|plain Markov localization without filtering, localization entropy filter,localization distance filter|to keep track robot's position normalworking conditions. three approaches tracked robot's position empty museumwell (first dataset), exhibiting negligible errors localization. results obtainedsecond, challenging dataset, however, quite different. nutshell,filter-based approaches tracked robot's position accurately, whereas conventionalMarkov localization failed frequently. Thus, used latter museum exhibit,would inevitably led large number collisions failures.FilterNoneEntropy Distancefailures [%] 1:6 0:4 0:9 0:4 0:0 0:0failures [%] 26:8 2:4 1:1 0:3 1:2 0:7IITable 2: Ability track robot's position.Table 2 summarizes results obtained different approaches trackingexperiment. first row Table 2 provides percentage failures different414fiMarkov Localization Mobile Robots Dynamic Environmentsfinal positionDistance final position: 19 cmCertainty final position: 0.003final position(a)Distance final position: 1 cmCertainty final position: 0.987final position(b)Distance final position: 1 cmCertainty final position: 0.998(c)Fig. 14. Estimated real paths robot along endpoints incorporated sensor measurements using (a) filter, (b) entropy filter, (c) distance filter.filters first dataset (error values represent 95% confidence intervals). Position estimates considered \failure" estimated location robot deviatedreference path 45cm least 20 seconds. percentage measuredtime position lost, relative total time dataset.seen here, three approaches work well, distance filter providesbest performance. second row provides failures second dataset. plainMarkov localization failed 26.8% overall time, filter techniques show almostequal results failure less 2%. Thus, two filter techniques robusthighly dynamic environments, plain Markov localization prone fail.shed light onto question Markov localization performs poorlycompared filter algorithms, analyzed sensor readings method usedlocalization task. Figure 14 shows, small fraction data, measurements incorporated robot's belief three different approaches. Shownend points sensor measurements used localization relative positionsreference path. Obviously, filter approaches manage focus attention\correct" sensor measurements, whereas plain Markov localization incorporates massiveamounts corrupted (misleading) measurements. also illustrated Figure 14,filter-based approaches produce accurate results higher certainty correctposition.4.1.3 Recovery Extreme Localization Failuresconjecture key advantage original Markov localization technique liesability recover extreme localization failures. Re-localization failure oftendicult global localization scratch, since robot starts beliefcentered completely wrong position. Since filtering techniques use currentbelief select readings incorporated, clear still maintainability recover global localization failures.analyze behavior filters extreme conditions, carriedseries experiments manually introduced failures datatest robustness methods extreme. specifically, \tele-ported"robot random points time locations. Technically, done changingrobot's orientation 18090 degree shifting 0100cm, without lettingrobot know. perturbations introduced randomly, probability 0:005 per415fiFox, Burgard & ThrunFiltertrec [sec]failures [%]trec [sec]failures [%]NoneEntropyDataset237 27 1779 54810:2 1:8 45:6 7:1Dataset II269 60 1310 90439:5 5:1 72:8 7:3Distance1886:8301:62357:8461:9Table 3: Summary recovery experiments.meter robot motion. Obviously, incidents make robot lose track position.method tested 20 differently corrupted versions datasets. resultedtotal 50 position failures dataset. failuresmeasured time methods re-localized robot correctly. Re-Localizationassumed succeeded distance estimated position referencepath smaller 45cm 10 seconds.Table 3 provides re-localization results various methods, based two different datasets. trec represents average time seconds needed recoverlocalization error. results remarkably different results obtainednormal operational conditions. conventional Markov localization techniqueusing distance filters relatively ecient recovering extreme positioning errorsfirst dataset, whereas entropy filter-based approach order magnitude lessecient (see first row Table 3). unsatisfactory performance entropy filterexperiment due fact disregards sensor measurementsconfirm belief robot. procedure reasonable belief correct,prevents robot detecting localization failures. percentage timeposition robot lost entire run given second row table. Pleasenote percentage includes both, failures due manually introduced perturbationstracking failures. Again, distance filter slightly better approach without filter, entropy filter performs poorly. average times trec recoverfailures second dataset similar first dataset. bottom rowTable 3 provides percentage failures dicult dataset. distancefilter-based approach performs significantly better approaches, sinceable quickly recover localization failures reliably track robot's position.results illustrate despite fact sensor readings processed selectively,distance filter-based technique recovers eciently extreme localization errorsconventional Markov approach.4.2 Localization Incomplete Mapsadvantage filtering techniques Markov localization requiredetailed map environment. Instead, suces provide outline416fiMarkov Localization Mobile Robots Dynamic Environments(b)(a)(c)Fig. 15. (a) Outline oce environment (b,c) examples filtered (grey) incorporated(black) sensor readings using distance filter.C22m3mB31m(a)20m(b)Fig. 16. (a) Occupancy grid map 1994 AAAI mobile robot competition arena. (b) Trajectoryrobot ultrasound measurements used globally localize robot map.merely includes aspects world static. Figure 15(a) shows ground plandepartment building, contains walls university building.complete map, including movable objects tables chairs, shown Figure 19.two Figures 15(b) 15(c) illustrate distance filter typically behavestracking robot's position sparse map environment. Filtered readingsshown grey, incorporated sensor readings shown black. Obviously,filter focuses known aspects map ignores objects (such desks,chairs, doors tables) contained outline. Fox (1998) describessystematic experiments supporting belief Markov localization combinationdistance filter able accurately localize mobile robots even relyingoutline environment.4.3 Localization Occupancy Grid Maps Using Sonarnext experiment described carried based data collected mobilerobot Rhino 1994 AAAI mobile robot competition (Simmons, 1995). Figure 16(a)shows occupancy grid map (Moravec & Elfes, 1985; Moravec, 1988) environment,constructed techniques described (Thrun et al., 1998a; Thrun, 1998b). sizemap 31 22m2 , grid resolution 15cm.417fiFox, Burgard & ThrunRobot position (A)Robot position (B)(a)Robot position (C)(b)(c)Fig. 17. Density plots incorporating 5, 18, 24 sonar scans (darker positionslikely).(a)(b)Fig. 18. Odometry information corrected path robot.Figure 16(b) shows trajectory robot along measurements 24 ultrasound sensors obtained robot moved competition arena. usesensor information globally localize robot scratch. time requiredprocess data 400MHz Pentium II 80 seconds, using position probability gridangular resolution 3 degrees. Please note exactly time neededrobot traverse trajectory; thus, approach works real-time. Figure 16(b)also marks positions robot perceiving 5 (A), 18 (B), 24 (C) sensor sweeps.belief states global localization three points time illustratedFigure 17.figures show belief robot projected onto hx; yi-plane plottinghx; yi-position maximum probability possible orientations. likelypositions darker illustration purposes, Figures 17(a) 17(b) use logarithmicscale intensity. Figure 17(a) shows belief state integrating 5 sensor sweeps (seealso position Figure 16(b)). point time, robot knows onecorridors environment. integrating 18 sweeps ultrasound sensors,robot almost certain end corridor (compare position B Figures 16(b) 17(b)). short time later, turning left integrating six sweepsultrasound ring, robot determined position uniquely. representedunique peak containing 99% whole probability mass Figure 17(c).Figure 18 illustrates ability Markov localization correct accumulated deadreckoning errors matching ultrasound data occupancy grid maps. Figure 18(a)shows typical 240m long trajectory, measured Rhino's wheel-encoders 1994418fiMarkov Localization Mobile Robots Dynamic Environments122810132167203 21519912114615 181714Fig. 19. Path robot reference positionsAAAI mobile robot competition arena. Obviously, rotational error odometryquickly increases. Already traveling 40m, accumulated error orientation(raw odometry) 50 degrees. Figure 18(b) shows path robot estimatedMarkov localization, significantly correct.4.4 Precision Performancedescribe experiments aimed characterizing precision position estimates. experiments also characterize time needed global localization relationsize grid cells. Figure 19 shows path robot Rhino ComputerScience Department's building University Bonn. path includes 22 referencepositions, true position robot determined using scan matchingtechnique presented (Gutmann & Schlegel, 1996; Lu & Milios, 1994). data recordedrun split four disjoint traces sensor data. differenttraces contained full length path, every fourth sensor readingsucient test localization performance.Figure 20(a) shows localization error averaged four runs referencepositions. error determined different sizes grid cells, using laser rangefinder ultrasound sensors. results demonstrate (1) average localizationerror sensors generally cell size (2) laser range-finders providesignificantly higher accuracy ultrasound sensors. using laser range-finderspatial resolution 4cm, average positioning error even reduced 3.5cm.Figure 20(b) shows average CPU-time needed globally localize robotfunction size grid cells. values represent computation time needed266MHz Pentium II global localization path starting pointposition 1. experiment, used fixed angular resolution four degrees.case 64cm cell size, average localization time approximately 2.2 seconds.419fiFox, Burgard & ThrunAverage localization time [sec]Average estimation error [cm]120Ultrasound sensorLaser-range finder302520151050Ultrasound sensorLaser-range finder100806040200010203040Grid cell size [cm]5060700(a)1020304050Grid cell size [cm]6070(b)Fig. 20. (a) Average localization error (b) average CPU-time needed global localization timeultrasound sensors laser range-finder depending grid resolution.course, effective time needed global localization practice highly dependsstructure environment amount information gathered pathrobot. example, due symmetry corridor oce environment,robot able localize unless enters room. reader may noticerecently, developed decision-theoretic method actively guiding robotplaces allow resolve ambiguities global localization (Fox et al., 1998a;Fox, 1998). Based method, localization process becomes ecient, especiallyoce environments lot indistinguishable places as, example, long corridors.experiments described demonstrate metric variant Markov localization able eciently estimate position mobile robot dynamic environments.furthermore deal approximate models environment occupancygrid maps rough outline maps. Finally, able eciently accurately estimateposition mobile robot even ultrasound sensors used.5. Related Worktechniques mobile robot localization literature belong classlocal approaches tracking techniques, designed compensate odometric erroroccurring navigation. assume initial position robot known(see Borenstein et al. 1996 comprehensive overview). example, Wei et al. (1994)store angle histograms constructed laser range-finder scans taken different locationsenvironment. position orientation robot calculated maximizingcorrelation stored histograms laser range-scans obtainedrobot moves environment. estimated position, together odometryinformation, used predict position robot select histogramused next match. Yamauchi (1996) Schulz et al. (1999) apply similar technique,use hill-climbing match local maps built ultrasound sensors globaloccupancy grid map. approach Wei et al. (1994), location robotrepresented position yielding best match. techniques, contrastMarkov localization, represent uncertainty robot current belieftherefore cannot deal appropriately globally ambiguous situations.420fiMarkov Localization Mobile Robots Dynamic Environmentspopular probabilistic framework position tracking Kalman filters (Maybeck,1990; Smith et al., 1990), signal processing technique introduced Kalman (1960).mentioned Section 2.4, Kalman filter-based methods represent belief robot'sposition unimodal Gaussian distribution three-dimensional state-spacerobot. mode distribution yields current position robot,variance represents robot's uncertainty. Whenever robot moves, Gaussianshifted according distance measured robot's odometry. Simultaneously,variance Gaussian increased according model robot's odometry. Newsensory input incorporated position estimation matching perceptsworld model.Existing applications Kalman filtering position estimation mobile robotssimilar model motion robot. differ mostly updateGaussian according new sensory input. Leonard Durrant-Whyte (1991) matchbeacons extracted sonar scans beacons predicted geometric mapenvironment. beacons consist planes, cylinders, corners. update current estimate robot's position, Cox (1991) matches distances measured infraredsensors line segment description environment. Schiele Crowley (1994)compare different strategies track robot's position based occupancy grid mapsultrasonic sensors. show matching local occupancy grid maps globalgrid map results similar localization performance matching based features extracted maps. Shaffer et al. (1992) compare robustnesstwo different matching techniques different sources noise. suggest combination map-matching feature-based techniques order inherit benefitsboth. Lu Milios (1994,1997b) Gutmann Schlegel (1996) use scan-matchingtechnique precisely estimate position robot based laser range-finder scanslearned models environment. Arras Vestli (1998) use similar techniquecompute position robot high accuracy. variants, however,rest assumption position robot represented single Gaussian distribution. advantage Kalman filter-based techniques lies eciencyhigh accuracy obtained. restriction unimodal Gaussiandistribution, however, prone fail position robot estimatedscratch, i.e. without knowledge starting position robot. Furthermore,technique typically unable recover localization failures. Recently, Jensfelt Kristensen (1999) introduced approach based multiple hypothesis tracking,allows model multi-modal probability distributions occur globallocalization.Markov localization, employed successfully several variants (Nourbakhsh et al., 1995; Simmons & Koenig, 1995; Kaelbling et al., 1996; Burgard et al., 1996;Hertzberg & Kirchner, 1996; Koenig & Simmons, 1998; Oore et al., 1997; Thrun, 1998a),overcomes disadvantage Kalman filter based techniques. different variantstechnique roughly distinguished type discretization used representation state space. Nourbakhsh et al. (1995), Simmons Koenig (1995),Kaelbling et al. (1996) use Markov localization landmark-based navigation,state space organized according topological structure environment.nodes topological graph correspond distinctive places hallways openings421fiFox, Burgard & Thrunjunctions connections places. Possible observations robotare, example, hallway intersections. advantage approachesrepresent ambiguous situations thus principle able globally localize robot.Furthermore, coarse discretization environment results relatively small statespaces maintained eciently. topological representations disadvantage provide coarse information robot's positionrely definition abstract features extracted sensor information.approaches typically make strong assumptions nature environments.Nourbakhsh et al. (1995), Simmons Koenig (1995), Kaelbling et al. (1996),example, consider four possible headings robot position assumingcorridors environment orthogonal other.method uses instead fine-grained, grid-based discretization state space.advantage approach compared Kalman filter based techniques comesability represent complex probability distributions. recent experimental comparison technique introduced Lu Milios (1994) GutmannSchlegel (1996), found Kalman filter based tracking techniques provide highly accurate position estimates less robust, since lack ability globally localizerobot recover localization errors (Gutmann et al., 1998). contrast topological implementations Markov localization, approach provides accurate position estimates applied even highly unstructured environments (Burgard et al., 1998a;Thrun et al., 1999). Using selective update scheme, technique able ecientlykeep track robot's position determined. also allows robotrecover localization failures.Finally, vast majority existing approaches localization differaddress localization static environments. Therefore, methods prone failhighly dynamic environments which, example, large crowds people surroundrobot (Fox et al., 1998c). However, dynamic approaches great practical importance,many envisioned application domains service robots involve people populatedenvironments.6. Discussionpaper presented metric variant Markov localization, robust techniqueestimating position mobile robot dynamic environments. key ideaMarkov localization maintain probability density whole state spacerobot relative environment. density updated whenever new sensory inputreceived whenever robot moves. Metric Markov localization represents statespace using fine-grained, metric grids. approach employs ecient, selective updatealgorithms update robot's belief real-time. uses filtering cope dynamicenvironments, making approach applicable wide range target applications.contrast previous approaches Markov localization, method uses finegrained discretization state space. allows us compute accurate positionestimates incorporate raw sensory input belief. result, systemexploit arbitrary features environment. Additionally, approach appliedarbitrary unstructured environments rely orthogonality assumption422fiMarkov Localization Mobile Robots Dynamic Environmentssimilar assumptions existence certain landmarks, approachesMarkov localization do.majority localization approaches developed far assume worldstatic state robot changing aspect world. ablelocalize mobile robot even dynamic densely populated environments, developedtechnique filtering sensor measurements corrupted due presencepeople objects contained robot's model environment.eciently update huge state spaces resulting grid-based discretization,developed two different techniques. First, use look-up operations eciently compute quantities necessary update belief robot given new sensory input.Second, apply selective update scheme focuses computation relevant parts state space. result, even large belief states updatedreal-time.technique implemented evaluated several real-world experimentsdifferent sites. Recently deployed mobile robots Rhino Deutsches Museum Bonn, Germany, Minerva Smithsonian's National Museum AmericanHistory, Washington, DC, interactive museum tour-guides. deployments,Markov localization technique reliably estimated position robots longperiods time, despite fact robots permanently surrounded visitorsproduced large amounts false readings proximity sensors robots.accuracy grid-based Markov localization turned crucial avoid evenobstacles could sensed robot's sensors. accomplishedintegrating map information collision avoidance system (Fox et al., 1998b).Despite encouraging results, several aspects warrant future research. key disadvantage current implementation Markov localization lies fixed discretizationstate space, always kept main memory. scale truly large environments, seems inevitable one needs variable-resolution representationsstate space, one suggested (Burgard et al., 1997; 1998b; Gutmann et al.,1998). Alternatively, one could use Monte-Carlo based representations state spacedescribed (Fox et al., 1999). Here, robot's belief represented samplesconcentrate likely parts state space.Acknowledgmentauthors would like thank research group autonomous intelligent systemsUniversity Bonn fruitful discussions, useful suggestions comments, especiallyDaniel Hennig Andreas Derr. would also like thank members CMU'sRobot Learning Lab many inspiring discussions. Finally, would like thankstaff Deutsches Museum Bonn National Museum American Historyenthusiasm willingness expose visitors one mobile robots.research sponsored part NSF (CAREER Award IIS-9876136) DARPAvia TACOM (contract number DAAE07-98-C-L032), Rome Labs (contract numberF30602-98-2-0137), gratefully acknowledged. views conclusions containeddocument authors interpreted necessarily423fiFox, Burgard & Thrunrepresenting ocial policies endorsements, either expressed implied, NSF, DARPA,TACOM, Rome Labs, United States Government.References[Arras & Vestli, 1998] K.O. Arras S.J. Vestli. Hybrid, high-precision localizationmail distributing mobile robot system MOPS. Proc. IEEE InternationalConference Robotics & Automation (ICRA), 1998.[Basye et al., 1992] K. Basye, T. Dean, J. Kirman, M. Lejter. decision-theoreticapproach planning, perception, control. IEEE Expert, 7(4), 1992.[Borenstein et al., 1996] J. Borenstein, B. Everett, L. Feng. Navigating Mobile Robots:Systems Techniques. A. K. Peters, Ltd., Wellesley, MA, 1996.[Burgard et al., 1996] W. Burgard, D. Fox, D. Hennig, T. Schmidt. Estimatingabsolute position mobile robot using position probability grids. Proc.National Conference Artificial Intelligence (AAAI), 1996.[Burgard et al., 1997] W. Burgard, D. Fox, D. Hennig. Fast grid-based position tracking mobile robots. Proc. German Conference Artificial Intelligence (KI),Germany. Springer Verlag, 1997.[Burgard et al., 1998a] W. Burgard, A.B. Cremers, D. Fox, D. Hahnel, G. Lakemeyer,D. Schulz, W. Steiner, S. Thrun. interactive museum tour-guide robot.Proc. National Conference Artificial Intelligence (AAAI), 1998.[Burgard et al., 1998b] W. Burgard, A. Derr, D. Fox, A.B. Cremers. Integrating globalposition estimation position tracking mobile robots: Dynamic Markov Localization approach. Proc. IEEE/RSJ International Conference IntelligentRobots Systems (IROS), 1998.[Burgard et al., 2000] W. Burgard, A.B. Cremers, D. Fox, D. Hahnel, G. Lakemeyer,D. Schulz, W. Steiner, S. Thrun. Experiences interactive museum tourguide robot. Artificial Intelligence, 114(1-2), 2000. appear.[Cover & Thomas, 1991] T.M. Cover J.A. Thomas. Elements Information Theory.Wiley Series Telecommunications. Wiley, New York, 1991.[Cox & Wilfong, 1990] I.J. Cox G.T. Wilfong, editors. Autonomous Robot Vehicles.Springer Verlag, 1990.[Cox, 1991] I.J. Cox. Blanche|an experiment guidance navigation autonomousrobot vehicle. IEEE Transactions Robotics Automation, 7(2):193{204, 1991.[Dellaert et al., 1999] F. Dellaert, W. Burgard, D. Fox, S. Thrun. Using condensation algorithm robust, vision-based mobile robot localization. Proc. IEEEComputer Society Conference Computer Vision Pattern Recognition (CVPR),1999.424fiMarkov Localization Mobile Robots Dynamic Environments[Fox et al., 1998a] D. Fox, W. Burgard, S. Thrun. Active Markov localizationmobile robots. Robotics Autonomous Systems, 25:195{207, 1998.[Fox et al., 1998b] D. Fox, W. Burgard, S. Thrun, A.B. Cremers. hybrid collisionavoidance method mobile robots. Proc. IEEE International ConferenceRobotics & Automation (ICRA), 1998.[Fox et al., 1998c] D. Fox, W. Burgard, S. Thrun, A.B. Cremers. Position estimationmobile robots dynamic environments. Proc. National ConferenceArtificial Intelligence (AAAI), 1998.[Fox et al., 1999] D. Fox, W. Burgard, F. Dellaert, S. Thrun. Monte Carlo Localization:Ecient position estimation mobile robots. Proc. National ConferenceArtificial Intelligence (AAAI), 1999.[Fox, 1998] D. Fox. Markov Localization: Probabilistic Framework Mobile Robot Localization Naviagation. PhD thesis, Dept. Computer Science, University Bonn,Germany, December 1998.[Gutmann & Schlegel, 1996] J.-S. Gutmann C. Schlegel. AMOS: Comparison scanmatching approaches self-localization indoor environments. Proc. 1stEuromicro Workshop Advanced Mobile Robots. IEEE Computer Society Press, 1996.[Gutmann et al., 1998] J.-S. Gutmann, W. Burgard, D. Fox, K. Konolige. experimental comparison localization methods. Proc. IEEE/RSJ InternationalConference Intelligent Robots Systems (IROS), 1998.[Hennig, 1997] D. Hennig. Globale und lokale Positionierung mobiler Roboter mittelsWahrscheinlichkeitsgittern. Master's thesis, Department Computer Science, UniversityBonn, Germany, 1997. German.[Hertzberg & Kirchner, 1996] J. Hertzberg F. Kirchner. Landmark-based autonomousnavigation sewerage pipes. Proc. First Euromicro Workshop AdvancedMobile Robots. IEEE Computer Society Press, 1996.[Jensfelt & Kristensen, 1999] P. Jensfelt S. Kristensen. Active global localisationmobile robot using multiple hypothesis tracking. Proc. IJCAI-99 WorkshopReasoning Uncertainty Robot Navigation, 1999.[Kaelbling et al., 1996] L.P. Kaelbling, A.R. Cassandra, J.A. Kurien. Actinguncertainty: Discrete Bayesian models mobile-robot navigation. Proc.IEEE/RSJ International Conference Intelligent Robots Systems (IROS), 1996.[Kalman, 1960] R.E. Kalman. new approach linear filtering prediction problems.Trans. ASME, Journal basic engineering, 82:35{45, March 1960.[Koenig & Simmons, 1998] S. Koenig R. Simmons. robot navigation architecturebased partially observable Markov decision process models. Kortenkamp et al.(1998).425fiFox, Burgard & Thrun[Konolige, 1999] K. Konolige. Markov localization using correlation. Proc. International Joint Conference Artificial Intelligence (IJCAI), 1999.[Kortenkamp & Weymouth, 1994] D. Kortenkamp T. Weymouth. Topological mappingmobile robots using combination sonar vision sensing. Proc. NationalConference Artificial Intelligence (AAAI), 1994.[Kortenkamp et al., 1998] D. Kortenkamp, R. P. Bonasso, R. Murphy, editors.MIT/AAAI Press, Cambridge, MA, 1998.[Leonard & Durrant-Whyte, 1991] J.J. Leonard H.F. Durrant-Whyte. Mobile robotlocalization tracking geometric beacons. IEEE Transactions Robotics Automation, 7(3):376{382, 1991.[Leonard & Durrant-Whyte, 1992] J.J. Leonard H.F. Durrant-Whyte. Directed SonarSensing Mobile Robot Navigation. Kluwer Academic, Boston, MA, 1992.[Lu & Milios, 1994] F. Lu E. Milios. Robot pose estimation unknown environmentsmatching 2d range scans. IEEE Computer Vision Pattern Recognition Conference (CVPR), 1994.[Lu & Milios, 1997a] F. Lu E. Milios. Globally consistent range scan alignmentenvironment mapping. Autonomous Robots, 4:333{349, 1997.[Lu & Milios, 1997b] F. Lu E. Milios. Robot pose estimation unknown environmentsmatching 2d range scans. Journal Intelligent Robotic Systems, 18, 1997.[Maybeck, 1990] P.S. Maybeck. Kalman filter: introduction concepts. Cox &Wilfong (1990).[Moravec & Elfes, 1985] H.P. Moravec A.E. Elfes. High resolution maps wideangle sonar. Proc. IEEE International Conference Robotics & Automation(ICRA), 1985.[Moravec, 1988] H.P. Moravec. Sensor fusion certainty grids mobile robots. AI Magazine, Summer 1988.[Nourbakhsh et al., 1995] I. Nourbakhsh, R. Powers, S. Birchfield. DERVISH ocenavigating robot. AI Magazine, 16(2), Summer 1995.[Oore et al., 1997] S. Oore, G.E. Hinton, G. Dudek. mobile robot learnsplace. Neural Computation, 1997.[Russell & Norvig, 1995] Stuart J. Russell Peter Norvig. Artificial Intelligence: Modern Approach, chapter 17. Number 0-13-103805-2 Series Artificial Intelligence. Prentice Hall, 1995.[Schiele & Crowley, 1994] B. Schiele J.L. Crowley. comparison position estimationtechniques using occupancy grids. Proc. IEEE International ConferenceRobotics & Automation (ICRA), 1994.426fiMarkov Localization Mobile Robots Dynamic Environments[Schultz et al., 1999] A. Schultz, W. Adams, B. Yamauchi. Integrating exploration,localization, navigation planning common representation. AutonomousRobots, 6(3), 1999.[Shaffer et al., 1992] G. Shaffer, J. Gonzalez, A. Stentz. Comparison two range-basedestimators mobile robot. SPIE Conf. Mobile Robots VII, pages 661{667, 1992.[Shatkey & Kaelbling, 1997] H. Shatkey L.P. Kaelbling. Learning topological mapsweak local odometric information. Proc. International Joint ConferenceArtificial Intelligence (IJCAI), 1997.[Simmons & Koenig, 1995] R. Simmons S. Koenig. Probabilistic robot navigationpartially observable environments. Proc. International Joint ConferenceArtificial Intelligence (IJCAI), 1995.[Simmons, 1995] R. Simmons. 1994 AAAI robot competition exhibition. AI Magazine, 16(2), Summer 1995.[Smith et al., 1990] R. Smith, M. Self, P. Cheeseman. Estimating uncertain spatialrelationships robotics. I. Cox G. Wilfong, editors, Autonomous Robot Vehicles.Springer Verlag, 1990.[Thrun et al., 1998a] S. Thrun, A. Bucken, W. Burgard, D. Fox, T. Frohlinghaus, D. Hennig, T. Hofmann, M. Krell, T. Schimdt. Map learning high-speed navigationRHINO. Kortenkamp et al. (1998).[Thrun et al., 1998b] S. Thrun, D. Fox, W. Burgard. probabilistic approachconcurrent mapping localization mobile robots. Machine Learning, 31:29{53,1998. Also appeared Autonomous Robots 5, pp. 253{271, joint issue.[Thrun et al., 1999] S. Thrun, M. Bennewitz, W. Burgard, A.B. Cremers, F. Dellaert,D. Fox, D. Hahnel, C. Rosenberg, N. Roy, J. Schulte, D. Schulz. MINERVA:second generation mobile tour-guide robot. Proc. IEEE International Conference Robotics & Automation (ICRA), 1999.[Thrun, 1998a] S. Thrun. Bayesian landmark learning mobile robot localization. Machine Learning, 33(1), 1998.[Thrun, 1998b] S. Thrun. Learning metric-topological maps indoor mobile robot navigation. Artificial Intelligence, 99(1):27{71, 1998.[Wei et al., 1994] G. Wei, C. Wetzler, E. von Puttkamer. Keeping track positionorientation moving indoor systems correlation range-finder scans. Proc.IEEE/RSJ International Conference Intelligent Robots Systems (IROS), 1994.[Yamauchi, 1996] B. Yamauchi. Mobile robot localization dynamic environments usingdead reckoning evidence grids. Proc. IEEE International ConferenceRobotics & Automation (ICRA), 1996.427fiJournal Artificial Intelligence Research 11 (1999) 361-390Submitted 6/99; published 11/99Complexity Reasoning Spatial CongruenceMatteo CristaniDipartimento Scientifico e Tecnologico,Universita di Verona,Ca Vignal 2, strada Le Grazie, I-37134 Veronacristani@sci.univr.itAbstractrecent literature Artificial Intelligence, intensive research effortspent, various algebras qualitative relations used representation temporalspatial knowledge, problem classifying computational complexity reasoningproblems subsets algebras. main purpose researches describerestricted set maximal tractable subalgebras, ideally exhaustive fashionrespect hosting algebras.paper introduce novel algebra reasoning Spatial Congruence, showsatisfiability problem spatial algebra MC-4 NP-complete, presentcomplete classification tractability algebra, based individuation threemaximal tractable subclasses, one containing basic relations. three algebrasformed 14, 10 9 relations 16 form full algebra.1. IntroductionQualitative spatial reasoning received increasing amount interest recentliterature. main reason this, already observed Jonsson Drakengren (1997),probably spatial reasoning proved applicable real-world problems,Geographical Information Systems (Egenhofer, 1991; Grigni, Papadias, & Papadimitriou,1995), Molecular Biology (Cui, 1994).specific stress qualitative reasoning space, observed Zimmermann(1995), justified fact qualitative spatial relations treated ecientlyquantitative counterparts, seem closer model relationshumans adopt spatial reasoning.Even though qualitative spatial reasoning extended literature, spiterelatively short history, certain aspects discipline neglected. particular,exhaustive computational perspective developed qualitative morphologicalreasoning space. term morphological reasoning intended suggest reasoninginternal structure objects. case spatial reasoning includesreasoning size, shape internal topology spatial regions.purpose present work analyse complexity reasoning relationscongruence, either actual partial, spatial regions, using spatial algebraMC-4 preliminarly analysed Cristani (1997).algebra MC-4 Constraint Algebra (Ladkin & Maddux, 1994) qualitativereasoning morphological relation congruence. Two spatial regions,models documented literature, considered equivalent shareinterior boundaries, namely spatial region. particular,c 1999 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiCristanirelation EQ, defined Randell, Cui Cohn (1989), analogously EgenhoferFranzosa (1991), becomes identity unique name assumption. Geometrytopology, conversely, allow kinds equivalence relations. relations weakeridentity, namely equivalence classes induce larger singletons.simplest weakening define congruence relation. Even though,relation studied (Borgo, Guarino, & Masolo, 1996, 1997; Cristani, 1997; Mutinelli,1998), complexity reasoning subalgebras yet deeply investigated.reason introduce new relation, provide algebraic structure hostrelations based (in particular relations compare regions, which, evencongruent, overlapped roto-translating one interiorother), that, many cases, knowledge represent systems necessarilyincludes internal structures. Consider following example.Example 1GIS dedicated representation geographical data industrial sites.system, structure factories described means various attributes,including size shape. One users wants query system opportunitymoving factory, works, present site new one. new siteprefabricated facilities already exist, problem consists deciding preservetopological layout factory minimise costs buying new engines, substitutecannot fit new facilities.order reason problems system made able representqualitative relations old new site parts, establishing, particular whetherspatial regions occupied engines \congruent", even \congruent part"ones chosen hosting new factory's site.Clearly cannot use topological information, since spatial region presently occupiedengine surely disjoint region engine going occupy newsite, information insucient deciding whether new site able hostengine itself.Though metric information involved final decision moving factory,qualitative reasoning used initial design phase.Figure 1 give pictorial representation one possible situation which, makedecisions, need represent spatial information topological.algebra MC-4 used represent four basic relations builtequivalence relation congruence: consider roto-translation region xrespect region y, four possible situations arise.least one roto-translation x coincides y. two regionscongruent.least one roto-translation x coincides proper part y.region x congruent proper part y.362fiThe Complexity Reasoning Spatial CongruenceFigure 1: pictorial representation relations analysed GIS movingfactory old new site. Note production lines newfacility may suitable hosting certain engines.least one roto-translation coincides proper part x.region x proper part congruent y.None above. region x cannot perfectly overlapped.would like stress three main aspects relations.1. relations established two spatial regions position space.specific need regions close, particular topological relation, provided relation compatible; congruence relationspurely morphological.2. equality two regions implies congruence. relation proper part excludesmorphological relations \congruent part". casemorphological side. region congruent part another region, evendisjoint, happen congruence, already stated point1.3. Even two regions size, may case regionscongruent. holds also partial congruence, possible regionsmaller another one cannot overlapped.practical relevance algebra proved exhibiting many examples,especially coming GIS. paper deal problem reasoningcongruence two-dimensional space domain. kind congruence assumeweakest one: roto-translability. Three-dimensional congruence type.\natural" notion three-dimensional congruence isometry, much generalroto-translability. example left right hands congruent (under simplifiedassumption shape size), cannot roto-translatedone. concentrate two-dimensional reasoning may363fiCristanianalysed terms roto-translation topological relations. analysis isometriesleft work.paper organised follows. Section 2 describes related workdeveloped area. Section 3 presents spatial algebra MC-4, Section 4 discussesclassification tractability found algebra. Finally, Section 5,conclusions given.2. Previous Workperspective individuating primitives describe space, significant effortlately spent, direction defining binary relations spatial regions,may used model space qualitative terms. Moreover, natural, AIcommunity, use Constraint Processing reasoning binary relations.specific attention Constraint Processing emerged Spatial Database community,community Geographical Information Science well.Two apparently independently developed models, shown essentiallyequivalent, exist Artificial Intelligence (Randell & Cohn, 1989; Randell, Cui, &Cohn, 1992) Spatial Database literatures (Egenhofer & Herring, 1990; Egenhofer &Franzosa, 1991; Franzosa & Egenhofer, 1992). Artificial Intelligence model, (Randell &Cohn, 1989; Randell et al., 1992) known RCC, acronym stands RegionConnection Calculus.RCC model centered primitive \connection" originally suggestedClarke (1981). Gotts (1994) Gotts, Gooday Cohn (1996) obtainedconnection primitive. original framework (Randell & Cohn, 1989;Randell et al., 1992) model formulated two versions, called RCC-5RCC-8. RCC-5 model model cannot distinguish interiorboundary spatial region (so external connection may tangencyoverlapping, example), RCC-8 model distinction possible.Bennett (1994, 1995), used propositional logic represent RCC reasoning problems.observed that, given propositional logic, interpreting truth values formulaspatial region, language RCC-5 sucient express satisfaction problemsemantical level. fact, however, due spatial interpretation,non-spatial interpretation RCC-5 relations still sucient representtruth condition semantical level found: set theory. Therefore, appliedresult Cook (1971) NP-completeness classical propositional logic restrictedmodel RCC-5, proving deciding consistency Constraint Satisfaction Problem(CSP) RCC-5 NP-complete problem too.complete model RCC-8, instead, analysed terms pure set theory,distinction boundary-connection interior-connection possible.distinction means minimal interpretation RCC-8 still providescorrect complete representation truth conditions semantical level requires topology.Statman (1979) proved intuitionistic logic along interpretations set theory forcestopology models sound theory. Bennett proved, thus, RCC-8 useddefine truth conditions formulas intuitionistic propositional logic. Statman(1979) proved intuitionistic propositional logic PSPACE-complete. However, since364fiThe Complexity Reasoning Spatial Congruenceneed complete truth verification procedure, procedure constraintprocessing, Bennett could reduce result, proving also RCC-8 NP-complete.results, even general negative practical purposes, encouragedresearches direction restricted models, way least certaincases may process finite set RCC constraints polynomial fashion deterministicmachines. particular, Nebel (1995) showed reasoning basic relationsRCC-5 RCC-8 tractable problems. Renz Nebel (1999) improved resultsabove, showing exists maximal tractable subclass RCC-5, denotedHb5, formed 28 relations 32, includes basic relations, maximaltractable subclass RCC-8, denoted Hb8 , formed 148 relations 256 includingbasic relations. maximal tractable subclass A, subset constraint algebra,problems defined tractable, problems defined proper supersetsnot. results obtained similar fashion work NebelBurckert (1995) temporal reasoning. result Renz Nebel anyway incomplete,since simply proved exists one maximal tractable subclass,classify every maximal tractable subclasses RCC-5. Jonsson Drakengren (1997)showed exist four maximal tractable subclasses RCC-5, one includingbasic relations. result obtained similar fashion (Drakengren & Jonsson, 1997;Jonsson, Drakengren, & Backstrom, 1999). complete analysis RCC-8 maximaltractable subclasses including basic relations provided Renz (1999).result analogous MC-4 Jonsson Drakengren result RCC-5.MC-4 algebra, describe paper, structured way AlgebraPartially Ordered Time (PO-time algebra), studied Anger, Mitra Rodriguez.would like stress two main aspects here:MC-4 algebra PO-time algebra algebraic structure:discussion paper stands different interpretation PO-time algebra, evendifferent spatial interpretation provided Anger, Mitra Rodriguezpapers.computational results present applied PO-time algebrawell, extend previous findings obtained Anger, Mitra Rodriguez.particular Anger, Mitra Rodriguez (1998, 1999), proved path-consistencyinsucient ensure consistency relations algebra, existstractable subalgebra treated O(n3 ) algorithm.Anger, Mitra Rodriguez (1999), showed deciding consistency PO-timenetwork NP-complete problem reducing analogous decision problemRCC-5.important observations needed, respect results Anger, MitraRodriguez:results complexity PO-time algebra applied MC-4,show MC-4 network consistent exhibit consistent scenario vertices network substituted spatial regions.Therefore, even show correspondence PO-time algebra too,NP-completeness result independent. Moreover, method used prove365fiCristaniintractability MC-4 independent well, main difference wayused exhibit problematic algebraic structure. proof derivedsimple way solve problems whenever possible polynomial time.discovery tractable subalgebras indicate M99 , M81 M72present paper, deserves acknowledgement priority Anger, Mitra Rodriguez. However, Anger, Mitra Rodriguez also classified one algebra,tractable, maximal, since contained M99 . Moreover, algorithmsfound M99 M81 substantially different one Anger, MitraRodriguez present ecient, O(n2 ) instead O(n3 ). Thereforetwo algorithmic solutions considered independent results well.classification presented complete, since classify maximal tractablesubalgebras MC-4, result may applied temporal reasoningwell, since obtained means algorithms completely independentinterpretation give relations (either spatial temporal).introduction morphological relations spatial reasoning novel too,study spatial congruence deserves, opinion, deep investigations henceforth.fact two algebras spatial temporal reasoning present substantial similarities novelty. RCC model corresponds subalgebras IntervalCalculus, stated Bennett (1994). Also Anger, Mitra Rodriguez statedproperty PO-time algebra respect RCC-5, interpretation completely different own, equality PO-time interpreted EQRCC-5, interpret congruence.Thus, even though similar algebraic structure partially investigated before,present paper presents substantial methodological differences obtained resultsindependent extensions ones obtained Anger, Mitra Rodriguez.remainder paper, result attributed Anger, MitraRodriguez note text.3. Spatial Algebra MC-4section present spatial algebra MC-4, previously presentedCristani (1997) largely analysed Mutinelli (1998).MC-4 Binary Constraint Algebra (henceforth indicated Constraint Algebra).Constraint Algebra Constraint Domain Algebra Base, formedmutually exclusive relations among elements Constraint Domain, whose unionform universal relation. converse basic relation basic relation too,composition basic relations union basic relations. Constraintestablishment one possible unions basic relations two variablesvary domain. constraint satisfied assignment one pair valuesdomain variables, pair values one relations constraintitself. Given finite set constraints two variables, problem decidingwhether exists assignment variables constraints366fiThe Complexity Reasoning Spatial Congruencexx CGxx CGPPxx CNOFigure 2: pictorial representation basic relations MC-4CGCGPPCGCGCGPPCGPPCGPPCGPPCGPP,1CGPP,1CGPP,1CGPP,1>CGPP,1CNOCNOCGPPCNOCGPP,1CNO>CNOCNOCGPPCNOCGPP,1CNO>Table 1: composition table MC-4. symbol > represents universal relationfCG; CGPP; CGPP,1 ; CNOg.simultaneously satisfied referred Constraint Satisfaction Problem, henceforthindicated CSP.MC-4 algebra formed unions four basic relations,established two-dimensional spatial regions, morphological point view,respect equivalence relation congruence.congruence relation variously interpreted geometry. interpretationrestrictive one: two regions congruent iff rigidly roto-translatedother.region x, interpretation, may congruent (x CG y) region y, congruentpart (x CGPP y) cannot perfectly overlapped (x CNO y). relationcongruent part may also inverted part congruent (y CGPP,1 x iffx CGPP y).Figure 2 pictorial representation three basic relations CG, CGPP CNOgiven. Table 1 present composition table MC-4 showing basic relationscompose other.367fiCristanix DRxx POx-1x PPx PPx EQxxxFigure 3: pictorial representation relations RCC-5.CSP represented Network Constraints. network constraintslabelled graph G = hV ; ; Ei, V finite set vertices, E binary relationV whose elements called edges, labelling function maps vertexG variable, edge relation Constraint Algebra given domainD. Given network constraints G , problem deciding consistency Gproblem establishing whether possible instantiate vertex label (the variables)elements D, way relations represented G labelsedges simultaneously satisfied. CSP represented network G often referred to,algebra A, A-SAT(G ). sake simplicity refer CSP representednetwork G MC-4 MSAT(G ).main result MC-4 algebra, respect MSAT, unfortunately negativecomputational account. general, deciding consistency hard solve networksconstraints variables representing spatial regions, stated Theorem 2.result already proved Cristani (1997).Anger, Mitra Rodriguez (1998), showed path-consistency cannot appliedsuccessfully Algebra Partially Ordered Time, isomorphic MC-4syntactic level. insucient prove CSP algebra NP-complete.showed (Anger et al., 1999) PO-time algebra NP-complete. proof liestranslation, shown analogous, identical,translationintroduced here, syntactical level, completely different semanticalone. However, proof insucient show arrange spatial solutions,since map defined purely syntactical. already observed Lemon (1996),representation space means relation algebra pure, obtainsatisfiable networks realizable space. proof, instead, appliedspatial interpretations. applied nonlinear time temporal interpretationswell, since syntactic level shown sucient space, nonlinear timeinterpreted space (Anger et al., 1999).getting proof negative result need describe relevantcorrespondences MC-4 algebra RCC-5 model, also used proofTheorem 2. well known RCC-5 algebra Constraint Algebra 5 basic relations:EQ , DR , PO , PP , PP,1 . five relations correspond pictorial representationFigure 3.two spatial regions one relations MC-4, certain relationsRCC-5 established them. Conversely, certain relations RCC-5established certain corresponding relations MC-4 are. correspondence, however,one-to-one. Consider, instance, region x region y, x DR y,368fiThe Complexity Reasoning Spatial CongruenceRel. MC-4 Rel. RCC-5CGCGPPCGPP,1CNOfEQ; DR; POgfPP; DR; POgfPP,1; DR; POgfDR; POgTable 2: basic relations MC-4 counterparts RCC-5. meaningTable relation MC-4 established, one relationsRCC-5 second column established well.Rel. RCC-5 Rel. MC-4EQPPPP,1PODRCGCGPPCGPP,1fCG; CGPP; CGPP,1; CNOgfCG; CGPP; CGPP,1; CNOgTable 3: basic relations RCC-5 counterparts MC-4.RCC-5, namely x disjoint y. Then, relation MC-4 establishedx y. However, x PP y, namely x proper part y, CGPP relationestablished x y. hand, two regions congruent,relations DR , PO EQ exist x y.Table 3 set correspondences MC-4 basic relations RCC-5,Table 2 set correspondences RCC-5 MC-4.correspondences Tables suciently strict, use proving MSAT(MC-4) NP-complete problem direct polynomial reduction.consider CSP MC-4, corresponding RCC-5 CSP intractable, sincerelations obtained Table 2 define intractable subset RCC-5, meanscomplete classification established Jonsson Drakengren (1997). Therefore,MSAT(MC-4) reducible RSAT(RCC-5) (the RSAT symbol represents satisfiability RCC models) corresponding relation mapping Table 2.Conversely, establish, means Tables, among possibleregions satisfying relation CG, exists least one pair regionsEQ, CGPP established, exists one pair PP relation, finallyCNO established, two regions PO relation. summarycorrespondence reported Table 4.correspondence obtained definition basic relations. Two regionsb congruent iff roto-translate way (a) EQ bconversely 0 0 (b) EQ a. Analogously congruent part b iff369fiCristaniRel. MC-4 Rel. RCC-5CGCGPPCGPP,1CNOEQPPPP,1POTable 4: basic relations MC-4 counterparts RCC-5 special mapping.roto-translate (a) PP b. Finally two regions CNO relation iffPO relation disjoint.correspondence Table 4 called, Network Constraints G MC-4translated RCC-5 denoted(G ). networks labelled edgesbasic relations MC-4 henceforth called scenarios MC-4.Consider consistent scenario MC-4. Applying composition tables MC-4RCC-5, clearly derive scenario RCC-5(S ) consistent, scenarioMC-4 so. consequence reasoning next lemma.Lemma 1 scenario MC-4 consistent,(G ) consistent.Ladkin Maddux (1994) proved network constraints consistent iffconsistent scenario. Therefore, immediate consequence Lemma 1 networkconstraints G MC-4 consistent,(G ) consistent. able provefirst theorem.Theorem 1 MSAT(MC-4) NP-hard.Proofobservation existence consistent scenarios Constraint Algebra dueMackworth Freuder (1985), obtain polynomial reduction RSAT(RCC-5)MSAT(MC-4).suces note solve MSAT solve RCC-5 problems obtainedtranslation well. Now, problems mapped MC-4 RCC-5 meanstrivially inverted,1 , sincetrivially one-to-one. meansproblem set relations obtained RCC-5corresponds problem MC-4,vice versa.set relations RCC-5 translatedcontains fPP; PP,1 g PO . NebelRenz (1999), proved set relations RCC-5 containing two relationsintractable. Therefore set(MC , 4) intractable.proves able solve problem MC-4 solve problemsubset RCC-5 intractable. Therefore MSAT(MC-4) NP-hard.370fiThe Complexity Reasoning Spatial CongruenceMackworth Freuder (1985) also proved backtracking applied CSPs.backtracking algorithm usually implemented linear non-deterministic technique,therefore polynomial algorithm non-deterministic machines.backtracking technique applicable MC-4 well, perform polynomial solution MSAT nondeterministic machines. shows MSAT NP,allows us claim:Theorem 2 MSAT(MC-4) NP-complete.negative result deep investigation needed define tractable subclasses set 16 relations allow us perform polynomial analysis leastsubset networks constraints definable MC-4.paper give definition three maximal tractable subclasses MC4, exhibiting therefore complete classification tractability algebra. threemaximal tractable subclasses already studied Anger, Mitra Rodriguez(1999). obtain maximality algebras, exhibited O(n3 ) algorithms.three main differences respect paper:1. number classes individuated lower theirs, found fourmaximal tractable subclasses. failed note one four subalgebrassubset another one. Table 10 subalgebra M88 corresponds fourthalgebra Anger, Mitra Rodriguez. subalgebra tractable, maximal.2. algorithms exhibit O(n2 ) Anger, Mitra Rodriguez exhibitedO(n3 ) algorithm one three maximal subsets.3. classification complete. Thus subset MC-4 subset onethree maximal tractable subalgebras individuated intractable. Anger, MitraRodriguez find result, since analyse subalgebrasPO-time algebra, MC-4.4. Maximal Tractable Subclasses MC-4Given subset constraint algebra A, indicate Sb set formedrelations written expressions algebra involving elementsoperations composition, intersection converse relations. setoften called transitive closure respect operations above. referclosure . set coincides closure called subalgebra.previous section recall result NP-completeness MC-4. firstimportant observation complexity subalgebras that, subalgebra Bcontain empty relation, network constraints B cannot entail strictcontradiction: consistent. far, problem necessarily polynomially solvable,O(1). stated next lemma.Lemma 2 Given algebra A, subalgebra B contain empty relation,SAT(B) polynomial.371fiCristanimain consequence Lemma 2 limit analysissubalgebras MC-4 subalgebras contain empty relation.Moreover, since network constraints represents relations implicit way,edge network labelled interpret representing universalrelation. Therefore, universal relation member subalgebrasinterested in. call algebras contain empty universalrelations expressive algebras.102 expressive subalgebras, denominate Mi varies 0101. Tables 5, 6, 7, 8, 10, 9 Appendix A, 102 expressive subalgebras MC-4listed.Lemma 3 Given subset MC-4, expressive subalgebra iff onesubalgebras Mi 0 101 .ProofConsider subset MC-4. test closure LISP program computesclosure composition, intersection converse subset MC-4, testpresence empty universal relation obvious membership test. LISPprocedure TRANSITIVE-CLOSURE listed Online Appendix 1, accompaniesarticle. test succeeds subalgebras Mi 0 101 fails216 , 102 = 65434 subsets MC-4. claim therefore proved.following technical lemma shows 102 subalgebras individuatedNP-hard. 20 subalgebras 102 intractable Lemma4. algebras presented Table 5 Appendix A. proof Lemma 5 trivialconsequence proof Theorem 2.Lemma 4 Given subalgebra MC-4, contains relations CNO fCGPP;CGPP,1 g MSAT(A) NP-hard.next three subsections show three maximal tractable subclasses MC-4found, intractable algebras 20 listed Table 5 Appendix A.4.1 CG -complete Subalgebra M725 tractable, Jonsson Drakengren (1997) observedproving class R28subalgebra RCC-5 containing relations including EQ tractable.result applies also MC-4 respect relation CG, also relations CNO,fCGPP; CGPP,1g, fCG; CNOg, fCG; CGPP; CGPP,1g.relevant cases CG , CNO fCGPP; CGPP,1 g , since twocases included two former three. algebra formed relationscontain CG relation ? tractable, obtain inconsistencyiff explicitly edge labelled ? network. Deciding consistencytherefore O(n2 ) problem.372fiThe Complexity Reasoning Spatial CongruenceALGORITHM M72-CONSISTENCYconstraint network M72INPUT:OUTPUT:1.2.Yes solution formed spatial regions R2 , not.edge , hx; yilabel hx; ?return inconsistencyLoopReturn consistencyFigure 4: Algorithm M72-consistency.M72 = f?, CG, fCG; CGPPg, fCG; CGPP,1g, fCG; CNOg, fCG; CGPP; CGPP,1g,fCG; CGPP; CNOg, fCG; CGPP,1; CNOg, >g.Since contradiction derives relation M72 except ?, Algorithm M72 -consistency(see Figure 4) solves consistency checking problem network constraints M72 .Thus claim following theorem:Theorem 3 Algorithm M72 -consistency correctly decides consistency networkconstraints M72 O(n2 ) time n number vertices .immediate consequence Theorem 3 following theorem:Theorem 4 MSAT(M72 ) polynomial.subalgebras included M72 Table 6 Appendix A.13 subalgebras Table 6 subalgebras theoreticallyobtained based method incorporated Algorithm M72 -consistency. algorithm applied subalgebras formed relations containing symmetricalrelation MC-4 empty relation. also prove polynomialitysubalgebras relations containing CNO, containing fCGPP; CGPP,1 g, subalgebras exist. subalgebra formed relations containing CNO empty relationM78 , subalgebra formed relations containing fCGPP; CGPP,1 g M31 .Table 7 Table 8 Appendix subalgebras M78 M31 shown.next subsection introduce maximal tractable subclass includes M78 ,subsection 4.3 introduce algebra containing M31 , proof tractability subalgebras Tables 7 8 derived tables well. Conversely,subalgebra M72 neither subalgebra M99 subalgebra M81 , Theorem 3independent result.373fiCristani4.2 Maximal Tractable Subclass M99look maximal tractable subalgebra containing basic relations. bestcandidate, based Table 5, M99 , algebra formed 13relations polynomial, show NP-hard reducingintractable problem RCC-5.M99 = f?, CG, CGPP, CGPP,1, CNO, fCG; CGPPg, fCG; CGPP,1g, fCG; CNOg,fCGPP; CNOg, fCGPP,1 ; CNOg, fCG; CGPP; CNOg, fCG; CGPP,1; CNOg, >g.Fortunately, prove tractability M99 , maximal based factalgebras containing basic relations either intractable Table 5 subsetsM99 .Consider subset M99 ,G99 = ffCG; CGPPg, fCG; CNOg, fCGPP; CGPP,1; CNOgg.following claim holds.Lemma 5 Gd99 = M99 .Prooffollowing expressions represent valid implementations relations M99 usingelements G99 operators composition, intersection converse.t.1.?= fCG; CGPPgt.2.CGfCG; CNOgfCGPP; CGPP,1; CNOg= fCG; CGPPg fCG; CGPPg ^t.3.CGPP= fCG; CGPPg fCGPP; CGPP,1 ; CNOgt.4.CGPP,1= fCG; CGPPg ^ fCGPP; CGPP,1 ; CNOgt.5.CNO= fCG; CNOg fCGPP; CGPP,1 ; CNOgt.6.>= fCG; CGPPgfCGPP; CGPP,1 ; CNOgt.7.fCG; CGPP,1g= fCG; CGPPg ^t.8.fCGPP; CNOg= (fCG; CGPPgt.9.fCGPP,1; CNOgt.10. fCG; CGPP; CNOgfCG; CNOg )fCGPP; CGPP,1; CNOg= (fCG; CGPPg ^fCG; CNOg )fCGPP; CGPP,1; CNOg= fCG; CGPPgfCG; CNOgt.11. fCG; CGPP,1 ; CNOg= fCG; CGPPg ^fCG; CNOg374fiThe Complexity Reasoning Spatial Congruencenetwork constraints M99 , implemented means Lemma 5 denoted henceforth 99 (T ).derive contradiction network constraints iff network derives tworelations R1 R2 , one pair vertices R1 \ R2 = ?. wayscontradiction derived networks labelled relations M99 , basedintersections relations (except empty relation obviously generates contradiction itself) are:a)b)c)d)e)f)g)h)i)l)m)n)CGCGCGCGCGPPCGPPCGPPCGPPCGPPCGPPCNOfCG; CGPPgCGPPCNOfCGPP; CNOgfCGPP; CGPP,1; CNOgCGPP,1CNOfCG; CGPP,1gfCG; CNOgfCGPP,1 ; CNOgfCG; CGPP,1; CNOgfCG; CGPPgfCGPP,1 ; CNOgsimply obtained considering pairs relations M99 whose intersectionempty.G99 contradictions only:fCG; CGPPg fCG; CGPPg ^ fCGPP; CGPP,1; CNOgfCG; CGPPg fCG; CNOg fCGPP; CGPP,1 ; CNOg .Henceforth represent relation fCG; CGPPg -, relation fCG; CNOg ./relation fCGPP; CGPP,1 ; CNOg 6. Since path labels corresponds representation - pair vertices path,./ = -, possible expressions contradictions G99 (-n-,n) 6 (-n-,(n,k)./-,k ) 6. Hence, cycle (-n-,n) called --cycle, cycle(-n-,(n,k)./-,k ) called quasi --cycle. graph representationtwo different contradictory situations G99 showed Figure 5. --cycle quasi--cycle, M99 force elements involved cycle relation CG .show contradictions represented G99 contradictionsobtained implementation suggested Lemma 5. important,may perform consistency checking simply checking cycles. resultstated next lemma.Lemma 6 Given network constraints M99 , inconsistent iff 99(T ) containseither --cycle quasi --cycle, two vertices one cycle connected edgelabelled 6.375fiCristaniProof (Sketch)Case case, contradictions a) n), table above, generate onetwo situations claim.example, contradiction a) CG CGPP , generates(fCG; CGPPgfCG; CGPPg ^ ) (fCG; CGPPg fCGPP; CGPP,1 ; CNOg )--cycle two vertices connected edge labelled 6, statedclaim. cases behave way easily checkedreader.Conversely, contradiction derives one possible implicit ways representing relations M99 , implementation also produces one cases claim.particular that, M99 , CGn = CG , CGPPn = CGPP , (CGPP,1 )n = CGPP,1 ,fCG; CGPPgn = fCG; CGPPg fCG; CGPP,1 gn = fCG; CGPP,1g idempotent relations. cases implicitness obtained considering14 14 = 196 pairs relations M99 , composing intersecting them. implicit casesarising thus listed below.i.1.CG= fCG; CGPPgn fCG; CGPP,1 gni.2.CG= fCG; CGPPgn fCG; CNOgi.3.CGPP= fCG; CGPPgn fCGPP; CNOgi.4.CNO= fCG; CNOg fCGPP; CNOgi.5.CNO= fCGPP; CNOg fCGPP,1 ; CNOgi.6.CNO= fCGPP; CNOg fCG; CGPP,1 ; CNOgi.7.fCG; CNOg= fCG; CGPP; CNOgi.8.fCGPP; CNOg= CGPPnCNOi.9.fCGPP; CNOg= CGPPnfCG; CNOgfCG; CGPP,1; CNOgi.10. fCGPP; CNOg= CGPPnfCG; CGPP; CNOgi.11. fCGPP; CNOg= fCG; CGPPgnCNOi.12. fCGPP; CNOg= fCG; CGPP; CNOgfCGPP; CGPP,1; CNOgi.13. fCG; CGPP; CNOg = fCG; CGPPgnfCG; CNOgReaders may directly express G99 relations along corresponding376fiThe Complexity Reasoning Spatial CongruenceFigure 5: Contradictions G99 : fg indicates ? R, S, respectively fCG; CGPPg,fCG; CNOg fCGPP; CGPP,1; CNOg.relation producing contradiction M99 immediately verify existence -cycles quasi --cycle one pair vertices connected edge labelled 6generated graphs.example express CG implicit relation i.1. table (formedrelations G99 ), CGPP implicit relation i.3. fCGPP; CNOg 99 t.8.,consider contradiction CG CGPP obtain quasi --cycle two verticesconnected edge labelled 6. Similarly derive cases.exhibit algorithm looks --cycles quasi --cycles,checks pairs cycle connected edge labelled 6.Figure 7 algorithm able solve Consistency Checking Problem networksconstraints labelled relations M99 presented. Based Lemma 6 provefollowing theorem.Theorem 5 Algorithm M99-CONSISTENCY correctly decides consistency network constraints M99 O(n2 ) steps n number vertices .ProofLemma 6 ensure correctness Algorithm M99-CONSISTENCY. complexity algorithm derived fact computation strongly377fiCristaniFigure 6: Contradictions M99 : R, S, respectively indicate fCG; CGPPg,fCG; CNOg fCGPP; CGPP,1; CNOg. Letters a) n) refertable page 375.378fiThe Complexity Reasoning Spatial CongruenceALGORITHM M99-CONSISTENCYconstraint network M99INPUT:OUTPUT:1.2.3.4.2.Yes solution formed spatial regions R2 , not.Translate generator set Lemma 5Look cycles labelled - one ./Check whether edges two vertices one cycle labelled 6otherwise return no.Substitute vertices cycle one vertex.cycles go Step 2., otherwise return yes.Figure 7: Algorithm M99-consistencyconnected components O(e) problem e number edges network.99 implementation adds, worst case, O(e0 ) edges, e0 numberedges , therefore number edges 99 (T ) O(2 e0 ), O(n2 ).immediate consequence Theorem 5 following theorem:Theorem 6 MSAT(M99 ) polynomial.subalgebras MC-4 included M99 Table 10 Appendix A.4.3 Maximal Tractable Subclass M81problem deciding consistency network constraints MC-4 tractable,means Tables 6, 7, 8 10 85 subalgebras. remainder formed 17subalgebras, either tractable intractable. setM81 = f ?, CG, CGPP, CGPP,1, fCG; CGPPg, fCG; CGPP,1g, fCGPP; CGPP,1g,fCG; CGPP; CGPP,1g, fCGPP; CGPP,1 ; CNOg, >gcontains subalgebras, M81 tractable algebras well.analogy schema previous section look small generator setM81 . G81 = ffCG; CGPPg, fCG; CGPP; CGPP,1 g, fCGPP; CGPP,1 ; CNOgg.following lemma states properties M81 respect G81 .Lemma 7 Gd81 = M81 .Prooffollowing expressions represent valid implementations relations M81 usingelements G81 operators composition, intersection converse.379fiCristanir.1. ?= fCG; CGPPg fCG; CGPPgr.2. CG= fCG; CGPPg fCG; CGPPg ^r.3. CGPP= fCG; CGPPg fCGPP; CGPP,1 ; CNOgr.4. CGPP,1= fCG; CGPPg ^ fCGPP; CGPP,1 ; CNOgr.5. fCG; CGPP,1 g= fCG; CGPPg ^fCGPP; CGPP,1 ; CNOgr.6. fCGPP; CGPP,1 g = fCG; CGPP; CGPP,1 gfCGPP; CGPP,1 ; CNOg^= fCG; CGPPgfCGPP; CGPP,1 ; CNOgr.7. >implementation relations M81 described Lemma 7 denoted 81 .contradictions M81 next table.a)b)c)d)e)CGCGCGCGPPCGPPCGPPfCGPP; CGPP,1gfCGPP; CGPP,1; CNOgCGPP,1fCG; CGPP,1gpossible contradiction G81fCG; CGPPg fCG; CGPPg ^ fCGPP; CGPP,1; CNOgcorresponds --cycle two vertices connected edge labelled 6.Lemma 8 Given network constraints M81 , inconsistent iff 81(T ) contains--cycle two vertices one cycle connected edge labelled 6.Proof (Sketch)Case case, contradictions a) e), table above, generate onetwo cases claimed here.example, contradiction CG fCGPP; CGPP,1 g , implemented(fCG; CGPPg fCG; CGPPg ^ ) (fCG; CGPP; CGPP,1 gfCGPP; CGPP,1; CNOg )--cycle two vertices connected edge labelled 6, statedclaim. cases behave way easily checkedreader.possible ways representing implicit relations provided schema81 . Therefore claim proved.380fiThe Complexity Reasoning Spatial CongruenceFigure 8: Contradictions M81 .R, S, respectively indicate fCG; CGPPg,,1fCG; CGPP; CGPP g, fCGPP; CGPP,1; CNOg. Letters a) e) refertable page 380.ALGORITHM M81-CONSISTENCYconstraint network M81INPUT:OUTPUT:1.2.3.4.2.Yes solution formed spatial regions R2 , not.Translate generator set Lemma 7Look cycles labelled Check whether edges two vertices one cycle labelled 6otherwise return no.Substitute vertices cycle one vertex.cycles go Step 2., otherwise return yes.Figure 9: Algorithm M81-consistency381fiCristaniFigure 9 algorithm presented solves problem consistency checkingsubalgebra M81 . show, particular, following claim.Theorem 7 Algorithm M81-CONSISTENCY correctly decides consistency network constraints M81 O(n2 ) steps n number vertices .ProofLemma 8 ensure correctness Algorithm M81-CONSISTENCY. complexity algorithm derived fact computation stronglyconnected components O(e) problem e number edges network.81 implementation adds, worst case, O(e0 ) edges, e0 numberedges , therefore number edges 81 (T ) O(2 e0 ), clearly O(n2 ).immediate consequence Theorem 3 followingTheorem 8 MSAT(M81 ) polynomial.subalgebras included M81 Table 9 Appendix A.5. Conclusionspresented classification tractability complete spatial algebra MC-4.classification states exist three maximal tractable subalgebras M72 , M99M81 include 92 102 expressive subalgebras MC-4.interest complete classifications tractability, already observed JonssonDrakengren (1997), determined need definition boundarytractable intractable problems. Nebl (1999) suggested knowledgeboundary used either preprocessing step way structure backtrackingsearch algebras.provision complete classification one step researching constraintalgebras. next step individuation useful heuristics give improvementsperformances various techniques. currently exploiting use techniquesassociation techniques based classification presented paper obtainecient reasoning algorithms used practice. Preliminary results pathconsistency encouraging, cannot yet guarantee percentage improvement,since algebra MC-4 simply structured networks randomly chosenhard obtain case inconsistency detectable path-consistency.Acknowledgementswould like thank Elena Mutinelli developed Laurea Thesis (Mutinelli, 1998)theme complexity reasoning congruence first discussed preliminary382fiThe Complexity Reasoning Spatial Congruenceresults used developing classification paper. workrelevant reaching results.would also like thank Bernhard Nebel important observations madestudent mine, Alessandro Fin, improved work. thanks go JochenRenz discussions early stages work.would also like thank anonymous referees Journal Artificial IntelligenceResearch careful comments suggestions allowed makepresentation simpler systematical. proofs paperrewritten thanks suggestions.Finally would like thank Tony Cohn reading near final version. commentsuseful enhancing scientific literary quality paper.work developed context National Project, MURST ex 40%\Metodologie e tecnologie per la gestione di dati e processi su reti internet ed intranet"(Methods technologies data process management internet intranet)directed L. Tanca.383fiCristaniAppendix A. Tables 102 subalgebras MC-4section present subalgebras MC-4 organized separated tables dependingcharacteristics. particular Table 5 shows subalgebras intractableLemma 4, Table 6 tractable Theorem 3, Tables 7, 8Algorithm used Theorem 3 applied (which including CNOfCGPP; CGPP,1g ). Table 10 subalgebras included M99 displyed,Table 9 present subalgebras included M81 .Rel.Alg.M30M43M44M46M54M56M67M77M83M84M85M89M90M92M93M95M97M98M100M101CGCGPPCGPP,1CNOTable 5: subalgebras MC-4 containing relations CNO fCGPP; CGPP,1 g384fiThe Complexity Reasoning Spatial CongruenceRel. CGAlg.M0M1M3M5M9M12M18M22M25M34M38M63M72CGPPCGPP,1CNOM2M6M10M15M24M28M37M39M47M58M64M78CGPPCGPP,1CNOTable 6: subalgebras MC-4 contained M72 .Rel. CGAlg.Table 7: subalgebras MC-4 contained M78 contained M72 .385fiCristaniRel. CGAlg.CGPPCGPP,1CNOTable 8: subalgebras MC-4 contained M31 contained M72 M78 .M4M13M16M31Rel. CGAlg.M11M20M21M23M29M32M33M35M42M45M55M59M60M66M70M74M81CGPPCGPP,1CNOTable 9: subalgebras MC-4 contained M81 contained M99 M72M78 M31 .386fiThe Complexity Reasoning Spatial CongruenceRel. CGAlg.CGPPCGPP,1CNOTable 10: subalgebras MC-4 contained M99 contained M72 M78M31 .M7M8M14M17M19M26M27M36M40M41M48M50M51M52M57M61M62M65M68M69M71M73M75M76M79M80M82M86M87M88M91M94M96M99387fiCristaniReferencesAnger, F., Mitra, D., & Rodriguez, R. (1998). Temporal Constraint Networks NonlinearTime. Workshop Notes Spatial Temporal Reasoning ECAI98 Brighton,UK.Anger, F., Mitra, D., & Rodriguez, R. (1999). Satisfiability Nonlinear Time: AlgorithmsComplexity. Proceedings Florida Artificial Intelligence Research Societyconference Orlando (USA).Bennett, B. (1994). Spatial reasoning propositional logic. Doyle, J., Sandewall, E.,& Torasso, P. (Eds.), Proceedings 4th International Conference PrinciplesKnowledge Representation Reasoning (KR-94), pp. 165{176. Morgan Kaufmann,San Francisco, CA, USA.Bennett, B. (1995). Carving Space: Existential Axioms Formal Theory SpatialRegions. Proceedings IJCAI 95 Workshop Spatial Temporal ReasoningMontreal.Borgo, S., Guarino, N., & Masolo, C. (1996). Pointless Theory Space BasedStrong Connection Congruence. Aiello, L. C., & Doyle, J. (Eds.), Proceedings6th International Conference Principles Knowledge RepresentationReasoning (KR-96). Morgan Kaufmann, San Francisco, CA, USA.Borgo, S., Guarino, N., & Masolo, C. (1997). Ontological Theory Physical Objects.Ironi, L. (Ed.), Proceedings Eleventh International Workshop QualitativeReasoning (QR 1997), pp. 223{231 Cortona, Italy.Clarke, B. L. (1981). Calculus Individuals Based \Connection". Notre DameJournal Formal Logic, 22, 204{218.Cook, S. A. (1971). complexity theorem-proving procedures. Proceedings3rd Symposium Theory Computation, pp. 151{158.Cristani, M. (1997). Morphological Spatial Reasoning: Preliminary Report. Tech. rep.08/97, LADSEB-CNR Padova (Italy).Cui, Z. (1994). Using interval logic order assembly. Proceedings Second International Conference Intelligent Systems Molecular Biology, pp. 103{111. AAAIPress.Drakengren, T., & Jonsson, P. (1997). Twenty-one large tractable subclasses Allen'salgebra. Artificial Intelligence, 93 (1-2), 297{319.Egenhofer, M. J. (1991). Reasoning binary topological relations. Gunther, O., &Schek, H. J. (Eds.), Advances Spatial Databases-Second Symposium SSD '91, No.525 Lecture Notes Computer Science, pp. 143{160. Springer-Verlag, New York,NY, USA.388fiThe Complexity Reasoning Spatial CongruenceEgenhofer, M. J., & Franzosa, R. (1991). Point-Set Topological Spatial Relations. International Journal Geographical Information Systems, 5 (2), 161{174.Egenhofer, M. J., & Herring, J. (1990). Mathematical Framework DefinitionTopological Relationships. Fourth International Symposium Spatial DataHandling, pp. 803{813 Zurich, Switzerland.Franzosa, R., & Egenhofer, M. J. (1992). Topological Spatial Relations Based Components Dimensions Set Intersections. SPIE's OE/Technology '92-VisionGeometry Boston, ,USA.Gotts, N. M. (1994). Far \C"? defining \Doughnut" Using ConnectionAlone. Doyle, J., Sandewall, E., & Torasso, P. (Eds.), Proceedings 4thInternational Conference Principles f Knowledge Representation Reasoning(KR-94), pp. 246{257. Morgan Kaufmann, San Francisco, CA, USA.Gotts, N. M., Gooday, J. M., & Cohn, A. G. (1996). Connection Based ApproachCommonsense Topological Description Reasoning. Monist: InternationalJournal General Philosofical Inquiry, 79 (1).Grigni, M., Papadias, D., & Papadimitriou, C. (1995). Topological Inference. Mellis, C.(Ed.), Proceeding 14th International Joint Conference Artificial Intelligence(IJCAI-95), pp. 901{906 Montreal, PQ, Canada. Morgan Kaufmann.Jonsson, P., & Drakengren, T. (1997). Complete Classification Tractability Spatial Theory RCC-5. Journal Artificial Intelligence Research, 6, 211{221. ResearchNote.Jonsson, P., Drakengren, T., & Backstrom, C. (1999). Computational complexity relatingtime points intervals. Artificial Intelligence, 109 (1-2), 273{295.Ladkin, P., & Maddux, R. (1994). Binary Constraint Problems. Journal ACM,41 (3), 435{469.Lemon, O. J. (1996). Semantical Foundations Spatial Logics. Aiello, L. C., & Doyle, J.(Eds.), Proceedings 6th International Conference Principles f KnowledgeRepresentation Reasoning (KR-96). Morgan Kaufmann, San Francisco, CA, USA.Mackworth, A., & Freuder, C. (1985). complexity polynomial network consistency algorithms constraint satisfation problems. Artificial Intelligence, 25 (1),65{74.Mutinelli, E. (1998). Sviluppo ed Analisi di Algoritmi per il Ragionamento Spaziale Qualitativo con Reti di Vincoli. Laurea thesis, Universita di Verona. Italian.Nebel, B. (1995). Computational properties qualitative spatial reasoning: First results.Advances artificial intelligence (KI-95), pp. 233{244 Bielefeld, Germany. SpringerVerlag, New York, NY, USA.389fiCristaniNebel, B. (1999). Observations complexity reasoning constraint algebras.Personal communication A. Fin M. Cristani.Nebel, B., & Burckert, H. J. (1995). Reasoning temporal relations: maximaltractable subclass Allen's interval algebra. Journal ACM, 42 (1), 43{66.Randell, D. A., & Cohn, A. G. (1989). Modelling topological metrical propertiesphysical processes. Brachman, R. J., Levesque, H. J., & Reiter, R. (Eds.),Proceedings 1st International Conference Knowledge RepresentationReasoning (KR-89), pp. 55{66 Toronto, ON, Canada. Morgan Kaufmann.Randell, D. A., Cui, Z., & Cohn, A. G. (1992). spatial logic based regionsconnection. Swartout, B., & Nebel, B. (Eds.), Proceedings 3rd InternationalConference Principles Knowledge Representation Reasoning (KR-92), pp.165{176 Cambridge, MA, USA. Morgan Kaufmann.Renz, J. (1999). Maximal Tractable Fragments Region Connection Calculus:Complete Analysis. Proccedings 17th International Conference ArtificialIntelligence (IJCAI 99).Renz, J., & Nebel, B. (1999). complexity qualitative spatial reasoning: maximaltractable fragment Region Connection Calculus. Artificial Intelligence, 108 (12), 69{123.Statman, R. (1979). Intuitionistic logic polynomial-space complete. Theoretical ComputerScience, 9 (1), 67{72.Zimmermann, K. (1995). Measuring without Measures: -Calculus. ProceedingsInternational Conference Spatial Information, pp. 59{67.390fiJournal Artificial Intelligence Research 11 (1999) 277-300Submitted 5/99; published 10/99Reasoning Minimal Belief Negation FailureRiccardo Rosatirosati@dis.uniroma1.itDipartimento di Informatica e SistemisticaUniversita di Roma \La Sapienza"Via Salaria 113, 00198 Roma, ItalyAbstractinvestigate problem reasoning propositional fragment MBNF,logic minimal belief negation failure introduced Lifschitz, considered unifying framework several nonmonotonic formalisms, including defaultlogic, autoepistemic logic, circumscription, epistemic queries, logic programming.characterize complexity provide algorithms reasoning propositional MBNF.particular, show skeptical entailment propositional MBNF p3 -complete,hence harder reasoning mentioned propositional formalismsnonmonotonic reasoning. also prove exact correspondence negationfailure MBNF negative introspection Moore's autoepistemic logic.1. IntroductionResearch formalization commonsense reasoning pointed need formalizing agents able reason introspectively knowledge ignorance(Moore, 1985; Levesque, 1990). Modal epistemic logics thus proposed,modalities interpreted terms knowledge belief. Generally speaking, conclusions introspective agent able draw depend knowsknow. Hence, conclusion may retracted new facts addedagent's knowledge. reason, many nonmonotonic modal formalismsproposed order characterize reasoning abilities introspective agent.Among nonmonotonic modal logics proposed literature, logic minimalbelief negation failure MBNF (Lifschitz, 1991, 1994) one studied formalisms (Chen, 1994; Bochman, 1995; Beringer & Schaub, 1993). Roughly speaking,logic built adding first-order logic two distinct modalities, \minimal belief"modality B \negation failure" modality . logic thus obtained characterized terms nice model-theoretic semantics. MBNF used ordergive declarative semantics general classes logic programs (Lifschitz & Woo,1992; Schwarz & Lifschitz, 1993; Inoue & Sakama, 1994), generalize stable modelsemantics negation failure logic programming (Gelfond & Lifschitz, 1988, 1990,1991). Also, MBNF viewed extension theory epistemic queriesdatabases (Reiter, 1990), deals problem querying first-order databaseknowledge. Due ability expressing many features nonmonotoniclogics (Lifschitz, 1994; Schwarz & Lifschitz, 1993), MBNF generally considered unifying framework several nonmonotonic formalisms, including default logic, autoepistemiclogic, circumscription, epistemic queries, logic programming.c 1999 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiRosatiAlthough several aspects logic MBNF thoroughly investigated (Schwarz& Lifschitz, 1993; Chen, 1994; Bochman, 1995), existing studies concerning computational properties MBNF limited subclasses propositional MBNF theories(Inoue & Sakama, 1994) restricted subset first-order case (Beringer &Schaub, 1993).paper present computational characterization deduction propositional fragment MBNF. particular, show logical implication propositional fragment MBNF p3 -complete problem: hence, harder (unless polynomial hierarchy collapses) reasoning best known propositional formalismsnonmonotonic reasoning, like autoepistemic logic (Niemela, 1992; Gottlob, 1992), default logic (Gottlob, 1992), circumscription (Eiter & Gottlob, 1993), (disjunctive) logicprogramming (Eiter & Gottlob, 1995), several McDermott Doyle's logics (Marek& Truszczynski, 1993). shown following, result also implies minimalknowledge computationally harder negation failure.Moreover, study subclass MBNF theories, i.e. MBNF theories without nested occurrences modalities, showing case logical implication p2 complete. case interesting one logic programming viewpoint.Indeed, implies that, stable model semantics, increasing syntax programrules, allowing propositional formulas goals rules, affect worst-casecomplexity query answering disjunctive logic programs negation failure.Furthermore, provide algorithms reasoning MBNF fragment,optimal respect worst-case complexity. Notably, deductive methodsconsidered generalizations known methods reasoning nonmonotonicformalisms default logic, autoepistemic logic, logic programming stablemodel semantics.also show \negation failure" modality MBNF exactly correspondsnegative introspection autoepistemic logic (Moore, 1985). result implieslogic MBNF considered \composition" two epistemic modalities:\minimal knowledge" operator due Halpern Moses (1985) Moore's autoepistemicoperator.Besides theoretical interest, believe computational epistemologicalanalysis MBNF interesting implications development knowledge representation systems nonmonotonic abilities, since allows better understandingcomparison different nonmonotonic formalisms captured MBNF. interestdefining deductive methods MBNF also arises fact logic, originallydeveloped framework comparison different logical approaches nonmonotonic reasoning, recently considered attractive knowledge representationformalism. particular, shown (Donini, Nardi, & Rosati, 1997a) fullpower MBNF necessary order logically formalize several features implementedframe-based knowledge representation systems.following, first brie recall logic MBNF. Section 3 addressrelationship MBNF Moore's autoepistemic logic. Then, Section 4 studyproblem reasoning propositional MBNF: first consider case general MBNFtheories, deal MBNF theories. Section 5 present computational278fiReasoning minimal belief negation failurecharacterization reasoning MBNF. conclude Section 6. paper extendedthoroughly revised version (Rosati, 1997).2. Logic MBNFsection brie recall logic MBNF (Lifschitz, 1994), modal logictwo epistemic operators: \minimal belief" modality B \negation failure"(also called \negation default") modality . use L denote fixed propositionallanguage built usual way from: (i) alphabet propositional symbols; (ii)symbols true, false; (iii) propositional connectives _; ^; :; . denote LMmodal extension L modalities B . say formula ' 2 LM(modal) depth (with 0) subformula ' lies within scopemodalities, exists subformula ' lies within scope exactlymodalities.denote LSM set subjective MBNF formulas, i.e. subset formulasLM occurrence propositional symbol lies within scope least onemodality, L1M set MBNF formulas, set formulas LMpropositional symbol lies within scope exactly one modality. callmodal formula ' LM positive (resp. negative ) modality (resp. B )occur '. LB denotes set positive formulas LM , LSB denotes setpositive formulas LSM .recall notion MBNF model. interpretation set propositionalsymbols. MBNF structure triple (I; Mb ; Mn ), interpretation (also calledinitial world) Mb ; Mn non-empty sets interpretations (worlds). Satisfiabilityformula MBNF structure defined inductively follows:1. ' propositional symbol, ' satisfied (I; Mb ; Mn ) iff ' 2 ;2. :' satisfied (I; Mb ; Mn ) iff ' satisfied (I; Mb ; Mn );3. '1 ^ '2 satisfied (I; Mb ; Mn ) iff '1 satisfied (I; Mb ; Mn ) '2 satisfied(I; Mb ; Mn );4. '1 _ '2 satisfied (I; Mb ; Mn ) iff either '1 satisfied (I; Mb ; Mn ) '2satisfied (I; Mb ; Mn );5. '1 '2 satisfied (I; Mb ; Mn ) iff either '1 satisfied (I; Mb ; Mn ) '2satisfied (I; Mb ; Mn );6. B' satisfied (I; Mb ; Mn ) iff, every J 2 Mb , ' satisfied (J; Mb ; Mn );7. ' satisfied (I; Mb ; Mn ) iff exists J 2 Mn ' satisfied(J; Mb ; Mn ).write (I; Mb ; Mn ) j= ' indicate ' satisfied (I; Mb ; Mn ). saytheory LM satisfied (I; Mb ; Mn ) (and write (I; Mb ; Mn ) j= ) iff formulasatisfied (I; Mb ; Mn ). ' 2 LSM , evaluation ' insensitiveinitial interpretation : thus, case also write (Mb ; Mn ) j= '. Analogously,279fiRosati' 2 LSB , evaluation ' insensitive initial interpretationset Mn , also write Mb j= '. ' 2 L evaluation ' dependsets Mb ; Mn , case write j= '.order relate MBNF structures standard interpretation structures modallogic (i.e. Kripke structures), remark that, due notion satisfiability,consider sets Mb , Mn MBNF interpretation structure two distinctuniversal Kripke structures, i.e. possible-world structures world connectedworlds structure. fact, since accessibility relation structureuniversal, without loss generality possible identify universal Kripke structureset interpretations contained it. recall class universal Kripkestructures characterizes logic S5 (Marek & Truszczynski, 1993, Theorem 7.52).nonmonotonic character MBNF obtained imposing following preferencesemantics interpretation structures satisfying given theory.Definition 2.1 structure (I; M; ), 6= ;, MBNF model theoryLM iff (I; M; ) j= and, interpretation J set interpretations0, 0 (J; 0 ; ) 6j= .say formula ' entailed (or logically implied ) MBNF (and writej=MBNF ') iff ' satisfied every MBNF model . order simplify notation,denote MBNF model (I; M; ) pair (I; ), and, 2 LSM , denote(I; M; ) , since case evaluation insensitive initial world ,namely, (I; ) model , then, interpretation J , (J; ) model .Example 2.2 Let = fBpg. MBNF models form (I; ),= fI : j= pg. Hence, j=MBNF Bp, j=MBNF :B 2 Lpropositional formula p valid. Therefore, agent modeled minimalbelief, sense believes p objective facts logically implied p.Example 2.3 Let = fnot married B hasNoChildren g. easy seemodels form (I; ) = fI : j= hasNoChildren g, since marriedassumed hold agent modeled , able conclude::marriedB hasNoChildren . Notably, meaning analogous default rule hasNoChildrenReiter's default logic (Lifschitz, 1994). Also, let = fB bird ^ : ies B ies ; B bird g.way analogous previous case, shown MBNF modelsform (I; ), = fI : j= bird ^ ies g. Therefore, j=MBNF B ies .: ies g; bird ).shown Lifschitz (1994), corresponds default theory (f bird iesGiven set interpretations , Th(M ) denotes set formulas B'B' 2 LB j= B'. Let M1; M2 sets interpretations. say M1equivalent M2 iff Th(M1 ) = Th(M2 ).Definition 2.4 set interpretations maximal iff, set interpretations0, 0 equivalent 0 .280fiReasoning minimal belief negation failureturns that, restricting theories composed subjective positive formulas,MBNF corresponds modal logic minimal knowledge due Halpern Moses(1985), also known ground nonmonotonic modal logic S5G (Kaminski, 1991; Donini,Nardi, & Rosati, 1997b). fact, S5G obtained modal logic S5 imposingfollowing preference order universal Kripke structures satisfying theory 2 LB :model iff j= and, 0 , 0 j= 0 6 (Shoham,1987). fact, immediate see MBNF semantics theories composedsubjective positive formulas corresponds semantics according S5G . Hence,following property holds.Proposition 2.5 Let LB . Then, S5G model iff, , (I; )MBNF model fB' : ' 2 g.previous proposition implies that, LSB , set interpretations satisfying compared sets interpretations satisfying , while, caseLM , compared sets 0 (M 0 ; ) satisfies .Hence, main difference MBNF S5G lies fact S5G modelsmaximal respect set containment (or minimal respect objectiveknowledge holds model), MBNF property generally true.E.g., theory = fnot married _ B married g two types models, possiblechoice initial world J : (J; M1 ), M1 corresponds set interpretations(which represents case married assumed hold); (J; M2 ),M2 = fI : j= married g. Namely, married assumed hold, forces oneconclude B married : is, initial assumption justified knowledge derivedbasis assumption (Lin & Shoham, 1992). remark that, Proposition 2.5,interpretation MBNF operator B exactly corresponds interpretationmodality B S5G .3. Relating MBNF Autoepistemic Logicsection study relationship autoepistemic logic MBNF. First,brie recall Moore's autoepistemic logic (AEL). order keep notation minimum,change language AEL, using modality B instead L. Thus, followingformula AEL formula LB .Definition 3.1 propositionally consistent set formulas LB stable expansionset initial knowledge LB satisfies following equation:= Cn( [ fB' j ' 2 g [ f:B' j ' 62 g)(1)Cn(S ) denotes propositional deductive closure modal theory LB .Given theory LB formula ' 2 LB , write j=AEL ' iff ' belongsstable expansions . stable expansion stable set accordingfollowing definition (Stalnaker, 1993).Definition 3.2 modal theory LB stable set281fiRosati1. = Cn(T );2. every ' 2 LB , ' 2 B' 2 ;3. every ' 2 LB , ' 62 :B' 2 .recall stable set corresponds maximal universal Kripke structure MTset formulas satisfied MT (Marek & Truszczynski, 1993).term AEL model thus refer set interpretations whose set theoremsTh(M ) corresponds stable expansion AEL.Finally, notice adopted notion consistent autoepistemic logic (Marek& Truszczynski, 1993), i.e. (1) allow inconsistent theory = LB composedmodal formulas (possible) stable expansion. results presentedsection easily extended case (corresponding Moore's original proposal):however, requires slightly change semantics MBNF, allowing Definition 2.1empty set interpretations possible component MBNF structures.following, use term embedding (or translation) indicate transformationfunction () modal theories. interested finding faithful embedding (Gottlob,1995; Schwarz, 1996; Janhunen, 1998), following sense: () faithful embeddingAEL MBNF if, theory LB model , AEL modeliff MBNF model ().already known AEL theories embedded MBNF theories. particular, proven (Lin & Shoham, 1992; Schwarz & Truszczynski, 1994) AELtheories nested occurrences B (called theories) embedded MBNF;now, since AEL theory transformed equivalent theory (whichgeneral size exponential size initial theory), follows AEL theoryembedded MBNF.However, prove much stronger result: negation failure MBNF exactlycorresponds negative introspection AEL, i.e. AEL's modality :B MBNF's modality semantically equivalent. Hence, correspondence limitedmodal theories without nested modalities, induces polynomial-time embeddingAEL theory MBNF.first define translation () modal theories AEL MBNF theories.Definition 3.3 Let ' 2 LB . Then, (') MBNF formula obtained ' substituting occurrence B :not. Moreover, LB , () denotes MBNFtheory fB (')j' 2 g.show translation () embeds AEL theories MBNF. aim,exploit semantic characterization AEL defined Schwarz (1992). Roughly speaking,according preference semantics possible-world structures, AEL modelset interpretations satisfying that, interpretation J contained, pair (J; ) satisfy . Formally:Proposition 3.4 (Schwarz, 1992, Proposition 4.1) Let LB . Then, AELmodel iff, interpretation 2 , (I; ) j= and, interpretationJ 62 , (J; ) 6j= .282fiReasoning minimal belief negation failurefollowing, say occurrence subformula formula ' 2 LMstrict lie within scope modal operator. E.g., let = B' ^ (B _ ).occurrence B' strict, occurrence B strict.Theorem 3.5 Let LB . Then, AEL model iff, , (I; )MBNF model ().part. Suppose (I; ) MBNF model (). Then, 0 ,(M 0 ; ) 6j= (). Since () set formulas form B', ' containoccurrence operator B , follows that, subformula form 'occurring (), (M 0 ; ) j= ' iff (M; ) j= '. let B' 2 (), let '0 denotepropositional formula obtained ' replacing strict occurrence 'formula form true (M; ) j= false otherwise, let0 = f'0 : B' 2 ()g. suppose exists interpretation J J j= 0J 62 . Then, definition satisfiability MBNF structures follows(M [fJ g; ) j= (), thus contradicting hypothesis (I; ) MBNF model(). Hence, = fI : j= 0g. consider pair (J; ): again, definitionsatisfiability MBNF structures follows immediately (J; ) j= iff J j= 0 .since contains interpretations satisfying 0 , follows that, interpretationJ 62 , (J; ) 6j= , therefore Proposition 3.4 follows AEL model .Only-if part. Suppose AEL model . Then, Proposition 3.4,interpretation 2 , (I; ) j= and, interpretation J 62 , (J; ) 6j= .' 2 , let '00 denote propositional formula obtained ' replacing strictoccurrence formula form B true j= B false otherwise,let 00 = f'00 : ' 2 g. Then, suppose exists interpretation J J j= 00J 62 . Then, definition satisfiability MBNF structures follows(J; ) j= , thus contradicting hypothesis AEL model . Hence,= fI : j= 00g. suppose that, interpretation , (I; ) MBNFmodel (). Then, exists 0 (M 0 ; ) j= (). definition(), follows interpretation 0 satisfies 00 , and, since 0 , existsJ 62 J j= 00. Contradiction. Therefore, (I; ) MBNF model .remark theorem could alternatively proved factK -free fragment logic MKNF (Lifschitz, 1991) equivalent AEL,stated (although without proof) Schwarz Truszczynski (1994, page 123),correspondence MBNF MKNF (Lifschitz, 1994).previous theorem implies interpretation modality MBNFmodal operator autoepistemic logic same. property extends previousresults relating MBNF AEL (Lin & Shoham, 1992; Schwarz & Lifschitz, 1993; Chen,1994), interesting consequences logic programming frameworknonmonotonic reasoning. particular, since MBNF generalizes stable model semanticslogic programs (Gelfond & Lifschitz, 1988), result strengthens ideaAEL true logic negation failure (as interpreted according stable modelsemantics). Moreover, positive theories interpretation MBNFlogic minimal knowledge S5G (Halpern & Moses, 1985): consequently, logicMBNF generalizes Halpern Moses' S5G Moore's AEL.Proof.283fiRosati4. Reasoning MBNFsection present algorithms reasoning propositional MBNF: particular,study entailment problem MBNF. on, assume deal finite MBNFtheories , therefore refer single formula (which corresponds conjunctionformulas contained finite theory ).4.1 Characterizing MBNF Modelspresent finite characterization MBNF models formula 2 LM .several methods reasoning nonmonotonic modal logics (Gottlob, 1992; Marek& Truszczynski, 1993; Eiter & Gottlob, 1992; Niemela, 1992; Donini et al., 1997b),technique employ based definition correspondence preferredmodels theory partitions set modal subformulas theory.fact, partitions used order provide finite characterization universalKripke structure: specifically, partition satisfying certain properties identifies particularuniversal Kripke structure , uniquely determining propositional theoryset interpretations satisfying theory.extend known techniques order deal preference semanticsMBNF. particular, characterize properties partition modal subformulasformula 2 LM must satisfy order identify MBNF model . way,provide method rely modal logic theorem prover, reducesproblem reasoning bimodal logic number reasoning problems propositionallogic.First, introduce preliminary definitions. call formula form B'', ' 2 LM , modal atom.Definition 4.1 Let 2 LM . call set modal atoms occurring modalatoms (and denote set MA()).Definition 4.2 Let 2 LM let (P; N ) partition set modal atoms.denote (P; N ) formula obtained substituting strict occurrenceformula P true, strict occurrence formula N false.Observe occurrences modal subformulas withinscope another modality replaced; notice also that, P [ N contains MA(),(P; N ) propositional formula. case, pair (P; N ) identifies guessmodal subformulas , i.e. P contains modal subformulas assumed hold,N contains modal subformulas assumed hold.Definition 4.3 Let 2 LM let (P; N ) partition MA(). denote ob (P; N )propositional formula^'(P; N )B'2PRoughly speaking, propositional formula ob (P; N ) represents \objective knowledge" implied guess (P; N ) formulas form B' belonging P .ob (P; N ) =284fiReasoning minimal belief negation failuresemantic viewpoint, structure (I; M; 0 ) satisfying guess modal atomsgiven (P; N ), propositional formula ob (P; N ) constrains interpretations ,since structure propositional formula ob (P; N ) must satisfiedinterpretation J 2 , i.e. J j= ob (P; N ).Example 4.4 Let= (Ba _ (b ^ c)) ^ ^ :B (:f _ g)Then, MA() = fBa; (b ^ c); B (:f _ g)g. supposeP = fBa; (b ^ c)gN = fB (:f _ g)gThen, (P; N ) = (true _ true) ^ ^ :false (which equivalent d), ob (P; N ) = a.Definition 4.5 say pair sets interpretations (M; 0 ) induces partition(P; N ) MA() if, modal atom 2 MA(), 2 P iff (M; 0 ) j= .Lemma 4.6 Let ' 2 LM , let interpretation, let M; 0 sets interpretations,let (P; N ) partition induced (M; 0 ) set modal atoms . Then,(I; M; 0 ) j= ' iff (I; M; 0 ) j= '(P; N ).Follows immediately Definitions 4.2 4.5, definitionsatisfiability MBNF structures.show that, (I; ) MBNF model induces partition (P; N )MA(), formula ob (P; N ) completely characterizes set interpretationsM.Proof.Theorem 4.7 Let 2 LM , let (I; ) MBNF model , let (P; N )partition MA() induced (M; ). Then, = fJ : J j= ob (P; N )g.Let 0 = fJ : J j= ob (P; N )g. Since (M; ) induces partition (P; N ),Definition 4.5 follows interpretation must satisfy ob (P; N ), hence 0 .suppose 0 , consider structure (I; 0 ; ). prove modalatom 2 MA() belongs P iff (I; 0 ; ) j= . proof induction depthProof.formulas MA().First, consider modal atom 2 L: definition satisfiabilityformula MBNF structure, follows immediately 2 P iff (I; 0 ; ) j=. Then, consider modal atom B 2 L: B 2 P , then, definitionob (P; N ), propositional formula ob (P; N ) valid, therefore (I; 0 ; ) j= B .B 2 N , exists interpretation J J 6j= , since 0 ,follows (I; 0 ; ) 6j= B . Hence, modal atom 2 MA() depth 1 belongsP iff (I; 0 ; ) j= .Suppose 2 P iff (I; 0 ; ) j= modal atom MA() depthless equal i. Consider modal atom B MA() depth + 1: inductionhypothesis, Lemma 4.6, (I; 0 ; ) j= B iff 0 j= B ( (P; N )). Now, B 2 P ,285fiRosatithen, definition ob (P; N ), propositional formula ob (P; N ) (P; N ) valid,since 0 = fJ : J j= ob (P; N )g, follows 0 j= B ( (P; N )), turn implies(I; 0 ; ) j= B ; hand, B 2 N , exists interpretation J(J; M; ) 6j= , hence, induction hypothesis Lemma 4.6, J 6j= (P; N ).Now, since 0 , follows 0 6j= B ( (P; N )), hence (I; 0 ; ) 6j= B .way possible show modal atom form depth + 1 belongsP iff (I; 0 ; ) j= .thus proved modal atom 2 MA() belongs P iff (I; 0 ; ) j= :turn implies (I; 0 ; ) j= iff j= (P; N ), since hypothesis (I; M; )satisfies (P; N ) partition MA() induced (M; ), Lemma 4.6follows j= (P; N ). Therefore, (I; 0 ; ) j= , contradicts hypothesis(I; ) MBNF model . Consequently, 0 = , proves thesis.Informally, theorem states MBNF model associatedpartition (P; N ) modal atoms ; moreover, propositional formula ob (P; N )exactly characterizes set interpretations MBNF model (I; ), senseset interpretations satisfying ob (P; N ). provides finite waydescribe MBNF models .define notion partition set modal atoms induced pairpropositional formulas.Definition 4.8 Let 2 LM , '1 ; '2 2 L. denote Prt (; '1 ; '2 ) partitionMA() induced (M1 ; M2 ), M1 = fI : j= '1 g, M2 = fI : j= '2 g.order simplify notation, denote Prt (; ') partition Prt (; '; ').following theorem provides constructive way build partition Prt (; '; ).Theorem 4.9 Let 2 LM , '; 2 L. Let (P; N ) partition MA() built follows:1. start P = N = ;;2. modal atom B MA() (P; N ) 2 L, propositional formula' (P; N ) valid, add B P , otherwise add B N ;3. modal atom MA() (P; N ) 2 L, propositionalformula (P; N ) valid, add P , otherwise add N ;4. iteratively apply rules P [ N = MA().Then, (P; N ) = Prt (; '; ).proof induction structure formulas MA(). First,fact Prt (; '; ) partition induced (M; 0 ), = fI : j='g, 0 = fI : j= g, definition satisfiability MBNF structures,follows that, 2 L, (M; 0 ) j= B ' valid propositionalformula, (M; 0 ) j= valid propositional formula.Therefore, (P; N ) agrees Prt (; '; ) modal atoms modal depth 1. Suppose(P; N ) Prt (; '; ) agree modal atoms modal depth less equalProof.286fiReasoning minimal belief negation failurei. Consider modal atom B MA() modal depth + 1. Lemma 4.6definition satisfiability MBNF structures, follows (M; 0 ) j= B' (Prt (; '; )) valid propositional formula, since Definition 4.2value formula (Prt (; '; )) depends guess modal atomsmodal depth less equal Prt (; '; ), induction hypothesis follows(Prt (; '; )) = (P; N ), hence B belongs P (M; 0 ) j= B. Analogously,proven modal atom depth + 1 form belongs P(M; 0 ) j= . Therefore, (P; N ) Prt (; '; ) agree modal atomsmodal depth + 1.algorithms present following reasoning MBNF use shownproperties partitions modal subformulas formula , together additionalconditions partitions (that vary according different classes theories acceptedinputs), order identify MBNF models .entailment problem j=MBNF ', point occurrences' equivalent occurrences :B , since MBNF model modalities' evaluated set interpretations. Therefore, original formulationMBNF (Lifschitz, 1994), restrict query answering MBNF positive formulas.Let ' 2 LB , 2 L, = fJ : J j= g. denote '( ) propositionalformula obtained ' substituting strict occurrence modal atom B' true j= B, false otherwise. immediately verified'( ) = '(Prt ('; )).Theorem 4.10 Let ; ' 2 LM . Let (I; ) MBNF model let (P; N )partition MA() induced (M; ). Then, ' satisfied (I; M; ) iff j='(ob (P; N )).proof follows immediately fact that, Theorem 4.9, '(ob (P; N )) ='(Prt ('; ob (P; N ))), Lemma 4.6.show entailment problem MBNF related membershipproblem stable sets (Gottlob, 1995), turn related notion (objective)kernel used characterize stable expansions autoepistemic theories (Marek& Truszczynski, 1993).Proof.Definition 4.11 Let 2 L. denote ST ( ) (unique) stable set LB\ L = f' 2 Lj ' validgTheorem 4.12 Let 2 LM , ' 2 LSB . Then, 6j=MBNF ' iff exists MBNF model(I; ) ' 62 ST (ob (P; N )), (P; N ) partition MA() induced(M; ).Let = fI : j= ob (P; N )g: definition Definition 3.2, followsimmediately ST (ob (P; N )) = Th(M ). Therefore, ' 2 LSB (I; M; ) j= ' iff' 2 ST (ob (P; N )).Proof.287fiRosatiAlgorithm MBNF-Not-Entails(; ')Input: formula 2 LM , formula ' 2 LB ;Output: true 6j=MBNF ', false otherwise.beginexists partition (P; N ) MA()(a) (P; N ) = Prt (; ob (P; N ))(b) (P; N ) ^ :'(ob (P; N )) satisfiable(c) partition (P 0 ; N 0 ) 6= (P; N ) MA(),(c1) (P 0 ; N 0 ) satisfiable(c2) (P 0 ; N 0 ) =6 Prt (; ob (P 0; N 0 ); ob (P; N ))(c3) ob (P; N ) ^ :ob (P 0 ; N 0 ) satisfiablereturn trueelse return falseendFigure 1: Algorithm MBNF-Not-Entails.4.2 Reasoning Propositional MBNFdefine deductive method reasoning general propositional MBNF theories.Specifically, present algorithm MBNF-Not-Entails, reported Figure 1, computing entailment MBNF.algorithm exploits finite characterization MBNF models given Theorem 4.7analogous finite characterization, terms partitions MA(), modelsrelevant establishing whether partition (P; N ) MA() identifies MBNF model.algorithm checks whether exists partition (P; N ) MA() satisfyingthree conditions (a), (b), (c). Intuitively, partition cannot self-contradictory (condition (a)): particular, condition (P; N ) = Prt (; ob (P; N )) establishesobjective knowledge implied partition (P; N ) (that is, formula ob (P; N )) identifies set interpretations = fI : j= ob (P; N )g (M; ) inducespartition (P; N ) MA(). Moreover, partition must consistent :'(condition (b)): condition implies exists interpretationsatisfied (I; M; ) ' satisfied structure (I; M; ). Finally,condition (c) corresponds check whether structure (I; M; ) identifies MBNFmodel according Definition 2.1, i.e. whether pair (J; 0 )0 (J; 0 ; ) satisfies . Again, search structure performedexamining whether exists partition MA(), different (P; N ),satisfy conditions (c1), (c2), (c3).illustrate algorithm following simple example.Example 4.13 Suppose= B (a _ Bb) ^ (not (c _ :d) _ B :not b) ^ c288fiReasoning minimal belief negation failure' = :Bb _ (:b ^ B (a ^ b))Then, MA() = fB (a _ Bb); Bb; (c _ :d); B :not b; bg. suppose (P; N ) =(P1 ; N1 ),P1 = fB (a _ Bb); (c _ :d); bgN1 = fBb; B :not bgThen, (P; N ) = true ^ (true _ false) ^ c (which equivalent c), ob (P; N ) = _ false(which equivalent a). Now, let = fI : j= ag: easy see (M; )satisfies modal atoms P , satisfy modal atoms N , hence(P; N ) = Prt (; ob (P; N )), thus satisfying condition (a) algorithm. Then, since^ b valid propositional formula, 6j= B (a ^ b), hence :'(ob (P; N )) =:(true _ (:b ^ false)), equivalent false. Therefore, (P; N ) ^ :'(ob (P; N ))satisfiable, thus condition (b) hold.Suppose (P; N ) = (P2 ; N2 ),P2 = fB (a _ Bb); (c _ :d); Bb; B :not bgN2 = fnot bgThen, (P; N ) = true ^ (true _ true) ^ c (which equivalent c), ob (P; N ) = (a _ true) ^b^true, equivalent b. Again, easy see (P; N ) = Prt (; ob (P; N )), thussatisfying condition (a) algorithm. Then, since b ^ b valid propositionalformula, :'(ob (P; N )) = :(false _ (:b ^ false)), equivalent true. Hence, (P; N ) ^:'(ob (P; N )) equivalent c, implies condition (b) holds. Finally, easyverify either condition (c1) condition (c2) holds partition MA()different (P2 ; N2 ), exception (P1 ; N1 ). let (P 0 ; N 0 ) = (P1 ; N1 ): shownbefore, ob (P 0 ; N 0 ) equivalent a, hence ob (P; N ) ^ :ob (P 0 ; N 0 ) equivalent b ^ :a,therefore condition (c3) holds (P 0 ; N 0 ) = (P1 ; N1 ), implies condition (c)holds (P; N ) = (P2 ; N2 ). Consequently, MBNF-Not-Entails(; ') returns true. fact,partition (P2 ; N2 ) identifies set MBNF models (I; )interpretation satisfying c = fI : j= bg. model satisfyquery ': indeed, immediately verified that, interpretation , (I; M; ) 6j=:Bb _ (:b ^ B (a ^ b)), since 6j= B (a ^ b) j= Bb.prove correctness algorithm MBNF-Not-Entails need following preliminary lemma.Lemma 4.14 Let 2 LM , let (P; N ) partition MA() induced (M 0; ).Let 00 = fI : j= ob (P; N )g. Then, (P; N ) partition induced (M 00 ; ).proof induction depth modal atoms MA(). Let2 MA() 2 L: then, (M 0 ; ) j= iff exists interpretation2 6j= , therefore (M 0 ; ) j= iff (M 00 ; ) j= . let B 2MA() 2 L: Definition 4.3, (M 0 ; ) j= B iff propositional formulaProof.289fiRosatiob (P; N ) valid, since 00 = fI : j= ob (P; N )g, follows (M 0 ; ) j= Biff (M 00 ; ) j= B .suppose that, modal atom depth i, (M 0 ; ) j= iff (M 00 ; ) j= ,let (P 0 ; N 0 ) denote partition modal atoms MA() depth less equalinduced (M 0 ; ). First, consider modal atom depth + 1. Then,Lemma 4.6, (M 0 ; ) j= iff (M 0 ; ) j= ( (P 0 ; N 0 )) and, inductivehypothesis Lemma 4.6, (M 00 ; ) j= iff (M 00 ; ) j= ( (P 0 ; N 0 )). Then, sincedepth i, (P 0 ; N 0 ) propositional formula, hence (M 0 ; ) j= ( (P 0 ; N 0 )) iffexists interpretation 2 6j= (P 0 ; N 0 ), immediately implies(M 0 ; ) j= iff (M 00 ; ) j= . consider modal atom B depth+ 1. Then, Lemma 4.6, (M 0 ; ) j= B iff (M 0; ) j= B ( (P 0 ; N 0 )) and,inductive hypothesis Lemma 4.6, (M 00 ; ) j= B iff (M 00 ; ) j= B ( (P 0 ; N 0 )).Definition 4.3, (M 0 ; ) j= B iff propositional formula ob (P; N ) (P 0 ; N 0 ) valid,since 00 = fI : j= ob (P; N )g, follows (M 0 ; ) j= B iff (M 00 ; ) j= B ,proves thesis.ready prove correctness algorithm MBNF-Not-Entails.Theorem 4.15 Let 2 LM , ' 2 LB . Then, MBNF-Not-Entails(; ') returns true iff6j=MBNF '.part. Suppose 6j=MBNF '. Then, exists pair (I; ) (I; )MBNF model (I; M; ) 6j= '. Let (P; N ) partition MA() induced(M; ). Theorem 4.7, = fI : j= ob (P; N )g. Therefore, Definition 4.8,(P; N ) = Prt (; ob (P; N )). Then, since (I; M; ) 6j= ', Theorem 4.10 follows6j= '(ob (P; N )), since (I; M; ) j= , Lemma 4.6 j= (P; N ), therefore j=(P; N ) ^:'(ob (P; N )). suppose exists partition (P 0 ; N 0) MA()(P 0 ; N 0 ) =6 (P; N ) none conditions (c1), (c2), (c3) holds. Then, since (P 0 ; N 0 )satisfiable, exists interpretation J J j= (P 0 ; N 0 ), since (P 0 ; N 0 ) =Prt (; ob (P 0 ; N 0 ); ob (P; N )), Lemma 4.6 follows exists interpretationJ (J; 0 ; ) j= , 0 = fI : j= ob (P 0 ; N 0)g. Then, since condition (c3)hold, propositional formula ob (P; N ) ob (P 0 ; N 0 ) valid, implies0 . Now, 0 = , (P 0 ; N 0 ) would partition induced (M; ), thuscontradicting hypothesis (P 0 ; N 0 ) =6 (P; N ). Hence, 0 , since (J; 0 ; ) j= ,Proof.follows (I; ) MBNF model . Contradiction. Consequently, condition(c) algorithm holds, therefore MBNF-Not-Entails(; ') returns true.Only-if part. Suppose MBNF-Not-Entails(; ') returns true. Then, exists partition (P; N ) MA() conditions (a), (b), (c) hold. Let = fI : j=ob (P; N )g. Since (P; N ) = Prt (; ob (P; N )), Definition 4.8 (P; N ) partition induced (M; ). since (P; N )^:'(ob (P; N )) satisfiable, follows existsinterpretation j= (P; N ) 6j= '(ob (P; N )), hence, Lemma 4.6,(I; M; ) j= (I; M; ) 6j= '. suppose (I; ) MBNF model .Then, exists set 0 interpretation J 0 (J; 0 ; ) j= .Let (P 0 ; N 0 ) partition MA() induced (M 0 ; ). Since = fI : j= ob (P; N )g,follows 0 containsV least one interpretation J satisfy ob (P; N ),since ob (P; N ) = B 2P (P; N ), J satisfy least one formula form290fiReasoning minimal belief negation failure(P; N ) B 2 P . Therefore, P 0 6= P , implies (P 0 ; N 0 ) 6= (P; N ).Then, since (J; 0 ; ) j= , Lemma 4.6 J j= (P 0 ; N 0 ), hence (P 0 ; N 0 ) satisfiable.let 00 = fI : j= ob (P 0 ; N 0 )g. Lemma 4.14, follows (P 0 ; N 0 ) partitioninduced (M 00 ; ), therefore, Definition 4.8, (P 0 ; N 0 ) = Prt (; ob (P 0 ; N 0 ); ob (P; N )).Moreover, since 0 , follows propositional formula ob (P; N ) ob (P 0 ; N 0 )valid, hence formula ob (P; N ) ^ :ob (P 0 ; N 0 ) unsatisfiable. Consequently, (P 0 ; N 0 )satisfy condition (c) algorithm, thus contradicting hypothesis. Therefore, (I; ) MBNF model , since (I; M; ) 6j= ', follows 6j=MBNF ',thus proving thesis.point fact algorithm MBNF-Not-Entails rely theoremprover modal logic: thus, \modal reasoning" actually needed reasoningMBNF. interesting peculiarity MBNF shares nonmonotonicmodal formalisms, like autoepistemic logic (Moore, 1985) autoepistemic logicknowledge (Schwarz, 1991).4.3 Reasoning Flat MBNFstudy reasoning MBNF theories. main reason taking accountfragment MBNF fact reasoning many best known nonmonotonicformalisms like default logic, circumscription, logic programming, reducedreasoning MBNF theories (Lifschitz, 1994).known that, 2 L1M ' 2 LSB , possible reduce entailmentj=MBNF ' reasoning logic S4FMDD , translating MBNF formulas unimodalformulas S4FMDD (Schwarz & Truszczynski, 1994). Thus, procedure decidingentailment logic S4FMDD presented Marek Truszczynski (1993) employed computing entailment j=MBNF '. following study generalproblem, entailment j=MBNF ' case 2 L1M ' 2 LB , presentspecialized algorithm problem, simpler general reasoningmethod S4FMDD .Figure 2 report algorithm Flat-Not-Entails computing entailment.algorithm, Pn denotes subset modal atoms P prefixed modality, i.e. Pn = fnot : 2 P g.Informally, correctness algorithm Flat-Not-Entails established fact that,2 L1M , (a), (b), (c) necessary sucient conditions partition (P; N )order establish whether induced pair (M; ) exists MBNFmodel form (I; ). particular, condition (c) states B (ob (P; N )) mustconsequence (Pn ; N ) modal logic S5,1 since shown (Pn ; N )B (ob (P; N )) valid S5, guess modal atoms form B' Pminimal. illustrate fact following example.Example 4.16 Let= (Ba ^ (c _ d)) _ (B (a ^ b) ^ :Bc) _ Bc1. denote B modal operator used S5.291fiRosatiAlgorithm Flat-Not-Entails(; ')Input: formula 2 L1M , formula ' 2 LB ;Output: true 6j=MBNF ', false otherwise.beginexists partition (P; N ) MA()(a) (P; N ) = Prt (; ob (P; N ))(b) (P; N ) ^ :'(ob (P; N )) satisfiable(c) (Pn ; N ) B (ob (P; N )) valid S5return trueelse return falseendFigure 2: Algorithm Flat-Not-Entails.supposeP = fBa; B (a ^ b); (c _ d)gN = fBcgThen,(Pn ; N ) = (Ba ^ true) _ (B (a ^ b) ^ :false) _ false;propositionally equivalent Ba _ B (a ^ b), ob (P; N ) = ^ (a ^ b),equivalent a^b. Now, Ba_B (a^b) B (a^b) valid S5, proved factset interpretations 0 = fI : j= ag 0 j= (Ba_B (a^b))^:B (a^b).Indeed, set interpretations 0 immediately used order prove (P; N )identify MBNF model . fact, let = fJ : J j= ^ bg: immediatesee that, interpretation , (I; 0 ; ) j= , since 0 , (I; )MBNF model .Finally, condition (b) corresponds check whether exists interpretationsatisfying :'(ob (P; N )): fact, interpretation exists, (I; ) MBNFmodel satisfy '.Therefore, algorithms MBNF-Not-Entails Flat-Not-Entails differway verified whether MBNF structure associated partition (P; N )satisfies preference semantics provided Definition 2.1, implementedcondition (c) algorithms. algorithm MBNF-Not-Entails, partition checkedpartitions MA(), algorithm Flat-Not-Entails sucientverify partition (P; N ) satisfies \local" property. shown next section,difference ects different computational properties entailment problemtwo cases.order establish correctness algorithm, need preliminary lemma.292fiReasoning minimal belief negation failureLemma 4.17 Let 2 L1M let (P; N ) partition induced structure (M; ).Then, (I; ) MBNF model iff 0 positive formula (Pn ; N )satisfied 0 .Suppose (I; ) MBNF model , let (P; N ) partition induced(M; ). Let 0 set interpretations 0 . Then, (M 0 ; ) 6j= .Since 2 L1M 0 , implies modal atom N , (M 0 ; ) 6j= .Moreover, modal atom 2 P , (M 0 ; ) j= . Therefore, Lemma 4.6,(M 0 ; ) 6j= (Pn ; N ). Now, since 2 L1M , (Pn ; N ) positive formula, hencesatisfiability depends structure 0 , therefore 0 6j= (Pn ; N ).Conversely, suppose (I; ) MBNF model , let (P; N ) partitioninduced (M; ). Then, exists set interpretations 0 0(M 0 ; ) j= . shown before, implies positive formula (Pn ; N ) satisfied0 .observed Section 2, class universal Kripke structures characterizes modallogic S5. immediately implies following property.Proof.Lemma 4.18 formula ' 2 LSB valid S5 iff, set interpretations ,formula :' satisfied .Based property, able prove correctness algorithmFlat-Not-Entails.Theorem 4.19 Let 2 L1M ' 2 LB . Then, Flat-Not-Entails(; ') returns true iff6j=MBNF '.If-part. 6j=MBNF ', exists MBNF model (I; )(I; M; ) 6j= '. Let (P; N ) partition MA() induced (M; ).Theorem 4.7 follows = fJ : J j= ob (P; N )g. Therefore, Definition 4.8,(P; N ) = Prt (; ob (P; N )), hence condition (a) algorithm holds.let 0 = (Pn ; N ), suppose formula 0 B (ob (P; N )) valid S5.Then, since formula 0 B (ob (P; N )) belongs LSB , Lemma 4.18 followsexists set interpretations 0 satisfying 0 ^ :B (ob (P; N )). Let (P 0 ; N 0 )partition VMA(0 ) induced (M 0 ; 0 ), let 00 = fI : j= ob (P 0 ; N 0 )g. Sinceob (P; N ) = B'2MA( ) ', Definition 4.3 follows ob (P; N ) ob (P 0 ; N 0 ) validpropositional formula, hence 00 . Now, since hypothesis 0 j= :B (ob (P; N )),follows 00 . Moreover, since 0 2 LB , Lemma 4.14 follows (P 0 ; N 0 )partition induced (M 00 ; 00 ), since 0 j= 0 0 at, 0 (P 0 ; N 0 ) equivalenttrue, therefore 00 j= 0 (P 0 ; N 0 ) and, Lemma 4.6, 00 j= 0 . hand, since00 , Lemma 4.17 follows 00 6j= 0. Contradiction. Hence, 0 B (ob (P; N ))Proof.0valid S5, consequently condition (c) algorithm holds.Finally, since (I; M; ) 6j= ' = fJ : J j= ob (P; N )g, Theorem 4.10 follows6j= '(ob (P; N )). Moreover, since (I; M; ) j= , Lemma 4.6 followsj= (P; N ), consequently j= (P; N ) ^ :'(ob (P; N )), hence propositional formula(P; N )^:'(ob (P; N )) satisfiable. Therefore, conditions (a), (b), (c) algorithmhold, implies Flat-Not-Entails(; ') returns true.293fiRosatiOnly-if-part. Flat-Not-Entails(; ') returns true, exists partition (P; N )MA() conditions (a), (b), (c) algorithm hold. Let = fJ : J j=ob (P; N )g. Definition 4.8, (P; N ) partition MA() induced (M; ). Now,since (P; N ) ^ :'(ob (P; N )) satisfiable, exists interpretation j=(P; N ) j= :'(ob (P; N )), hence Lemma 4.6 (I; M; ) j= , Theorem 4.10(I; M; ) 6j= ', therefore show (I; ) MBNF model . So,let us suppose (I; ) MBNF model . Then, Lemma 4.17 exists0 (Pn ; N ) satisfied 0 . Now, condition (c) algorithm impliesB (ob (P; N )) consequence (Pn ; N ) S5, therefore ob (P; N ) satisfiedinterpretation 0 , is, 0 fJ : J j= ob (P; N )g, contradicts hypothesis0 = fJ : J j= ob (P; N )g. Consequently, (I; ) MBNF model .remark fact algorithm Flat-Not-Entails seen generalizationknown methods query answering Reiter's default logic, Moore's autoepistemic logic,(disjunctive) logic programming stable model (and answer set) semantics.particular, condition (c) algorithm seen generalization minimalitycheck used (disjunctive) logic programming verifying stability model logicprogram (Gelfond & Lifschitz, 1990, 1991).5. Complexity Resultssection provide computational characterization reasoning MBNF.first brie recall complexity classes polynomial hierarchy, refer(Johnson, 1990; Papadimitriou, 1994) details complexity classesmentioned paper. PA (NPA ) class problems solved polynomialtime deterministic (nondeterministic) Turing machines using oracle (i.e.solves constant time problem A). classes pk , pk pk pof polynomialhierarchy defined p0 = p0 = p0 = P, k 0, pk+1 = NPk , pk+1 = copk+1ppk+1 = Pk . particular, complexity class p2 class problemssolved polynomial time nondeterministic Turing machine uses NP-oracle,p2 class problems complement problem p2 , p3class problems solved polynomial time nondeterministic Turing machineuses p2 -oracle, p3 class problems complement problemp3 . generally assumed polynomial hierarchy collapse: hence,problem class p2 p2 considered computationally easier p3 -hardp3 -hard problem.complexity entailment MBNF, start establishing lower boundreasoning propositional MBNF theories. end, exploit correspondenceMBNF logic minimal knowledge S5G (Halpern & Moses, 1985). Indeed,stated Proposition 2.5, one-to-one correspondence MBNF modelsS5G models positive subjective theories.Lemma5.1 Let 2 LSM let ' 2 LB . Then, problem deciding whether j=MBNFp' 3-hard.294fiReasoning minimal belief negation failureshown (Donini et al., 1997b), entailment S5G p3 -complete. Therefore,Proposition 2.5, subjective (and hence general) MBNF theories, entailmentp3 -hard.Then, show entailment problem propositional MBNF completerespect class p3 .Proof.Theorem 5.2 Let2 LM let ' 2 LB . Then, problem deciding whetherj=MBNF ' p3 -complete.Hardness respect p3 follows Lemma 5.1. membership p3 ,analyze complexity algorithm MBNF-Not-Entails reported Figure 1.particular, observe that:given (P; N ), formula ob (P; N ) computed polynomial time respectsize P . Moreover, Lemma 4.9 follows that, since MA() size linearrespect size , construction partition Prt (; ob (P; N ))performed linear number (with respect size ) calls NPoracle propositional satisfiability. Therefore, condition (a) checkedlinear number (in size input) calls NP-oracle;since '(ob (P; N )) = '(Prt ('; ob (P; N ))), formula :'(ob (P; N )) computedtime linear respect size ' ^ ob (P; N ) using NP-oracle. since,given (P; N ), (P; N ) computed polynomial time respectsize input, follows condition (b) computed linearnumber (in size input) calls NP-oracle;given partition (P 0 ; N 0), conditions (c1), (c2) (c3) (analogousconditions (a) (b)) checked polynomial time, respect size, using NP-oracle. Therefore, since guess partition (P 0 ; N 0 ) ofpMA()requires nondeterministic choice, falsity condition (c) decided 2 ,implies verifying whether condition (c) holds decided p2 .Since guess partition (P; N ) MA() requires nondeterministic choice,follows algorithm MBNF-Not-Entails, considered nondeterministic procedure, decides 6j=MBNF ' nondeterministic polynomial time (with respect size^ '), using p2-oracle. Thus, obtain upper bound p3 non-entailmentproblem, implies entailment MBNF p3 .previous analysis also allows computational characterization logic MKNF(Lifschitz, 1991), slight modification MBNF. Indeed, known (Lifschitz,1994) that, theory LM , MKNF model iff, interpretation, (I; ) MBNF model subjective theory 0 = fB' : ' 2 g. Therefore,Proposition 2.5 p3 -hardness entailment S5G (Donini et al., 1997b), followsentailment MKNF p3 -hard. Then, since j=MKNF ' iff 0 j=MBNF B' (Lifschitz,1994), follows entailment MKNF polynomially reduced entailmentMBNF, hence problem belongs p3 . Therefore, following property holds.Proof.Theorem 5.3 Entailment propositional MKNF p3-complete.295fiRosatiFinally, previous theorem provides computational characterization logicgrounded knowledge justified assumptions GK (Lin & Shoham, 1992). fact,logic GK considered syntactic variant propositional fragment MKNF.Therefore, skeptical entailment GK p3 -complete.Remark. computational properties MBNF variants relate formalismsground nonmonotonic modal logics (Eiter & Gottlob, 1992; Donini et al., 1997b; Rosati,1999). Notably, ground nonmonotonic modal logics share MBNF interpretationterms minimal knowledge (or minimal belief) modality B ; specifically, alreadymentioned, propositional fragment MBNF considered built upon S5Gadding second modality . Therefore, turns that, propositional case, adding\negation default" modality S5 logic minimal knowledge increasecomputational complexity reasoning, adding minimal knowledge modalityAEL increase complexity deduction. thus summarize follows: minimalknowledge computationally harder negation failure.study complexity entailment MBNF theories. First, knownthat, case MBNF theories subjective queries, entailment p2 -complete:membership class p2 consequence fact MKNF theoriespolynomially embedded McDermott Doyle's nonmonotonic modal logic S4F(Schwarz & Truszczynski, 1994, Proposition 3.2), whose entailment problem p2 -complete(Marek & Truszczynski, 1993), p2 -hardness follows existence polynomialtime embedding propositional default theories MBNF theories (Lifschitz, 1994).Therefore, following property holds.Proposition 5.4p Let 2 L1M let ' 2 LSB . Then, problem deciding whetherj=MBNF ' 2 -complete.complexity entailment generic queries respect MBNF theories,analyze complexity algorithm Flat-Not-Entails reported Figure 2. shownbefore, condition (a) condition (b) checked linear number (withrespect size input) calls NP-oracle. Moreover, validity modal logicS5 coNP-complete problem (Halpern & Moses, 1992). Hence, conditionsalgorithm computed number calls oracle propositionalvalidity problem polynomial size input, since guesspartition (P; N ) MA() requires nondeterministic choice, follows algorithmruns p2 . Therefore, following property holds.Theorem 5.5 Let2 L1M let ' 2 LB . Then, problem deciding whetherpj=MBNF ' 2 -complete.Membership problem class p2 implied algorithm Flat-notentails, whereas p2 -hardness implied Proposition 5.4.Hence, algorithm Flat-Not-Entails \optimal" sense matcheslower bound entailment problem.Proof.296fiReasoning minimal belief negation failureFinally, remark subset MBNF theories conjunctive normal formseen extension framework generalized logic programming introduced Inoue Sakama (1994), turn extension disjunctive logicprogramming framework stable model semantics (Gelfond & Lifschitz, 1991).Roughly speaking, MBNF theories conjunctive normal form correspond rulesgeneralized logic programs propositional formulas (instead literals) allowedgoals. computational characterization implies extensionframework logic programming stable model semantics affect worstcase complexity entailment problem, p2 -complete like entailment logicprograms disjunction stable model semantics (Eiter & Gottlob, 1995).result extends analogous properties (Marek, Truszczynski, & Rajasekar, 1995) casedisjunctive logic programs.6. Conclusionspaper investigated problem reasoning propositional fragmentMBNF. main results presented summarized follows:negation failure modality MBNF exactly corresponds negative introspection AEL. implies logic MBNF viewed conservativeextension two different nonmonotonic modal logics: Halpern Moses' logicminimal knowledge S5G Moore's AEL;reasoning propositional fragment MBNF lies third level polyno-mial hierarchy, hence (unless polynomial hierarchy collapse) reasoningMBNF harder reasoning best known propositional nonmonotonic logics,like default logic, autoepistemic logic, circumscription;defined methods reasoning MBNF, subsume generalize wellknown nonmonotonic reasoning algorithms used logic programming (Gelfond &Lifschitz, 1991), default logic (Gottlob, 1992), autoepistemic logic (Marek &Truszczynski, 1993);studied fragment MBNF relationship logic programming paradigm.computational aspects reasoning MBNF, results presented Section 5 prove one source complexity due presence nested occurrencesmodalities theory, since reasoning MBNF computationally easiergeneral case.proven another source complexity lies underlying objectivelanguage. fact, consider L0 tractable fragment propositional logic,complexity reasoning modal language L0M built upon L0 lowergeneral case. particular, easy see that, assumption entailmentL0 computed polynomial time, algorithm MBNF-Not-Entails providesupper bound p2 MBNF-entailment fragment L0M .297fiRosatiOne possible development present work towards analysis reasoningminimal belief negation failure first-order setting: particular,interesting see whether possible extend techniques developed propositional case expressive language. first attempt direction reportedDonini et al. (1997a).Acknowledgmentsresearch partially supported Consiglio Nazionale delle Ricerche, grant203.15.10.ReferencesBeringer, A., & Schaub, T. (1993). Minimal belief negation failure: feasibleapproach. Proc. 11th Nat. Conf. Artificial Intelligence (AAAI'93), pp.400{405.Bochman, A. (1995). bimodal nonmonotonic modal logics unimodalnonmodal equivalents. Proc. 14th Int. Joint Conf. Artificial Intelligence(IJCAI'95), pp. 1518{1524.Chen, J. (1994). logic knowing unified framework non-monotonicreasoning. Fundamenta Informaticae, 21, 205{220.Donini, F. M., Nardi, D., & Rosati, R. (1997a). Autoepistemic description logics. Proc.15th Int. Joint Conf. Artificial Intelligence (IJCAI'97), pp. 136{141.Donini, F. M., Nardi, D., & Rosati, R. (1997b). Ground nonmonotonic modal logics. J.Logic Computation, 7 (4), 523{548.Eiter, T., & Gottlob, G. (1992). Reasoning parsimonious moderately groundedexpansions. Fundamenta Informaticae, 17 (1,2), 31{54.Eiter, T., & Gottlob, G. (1993). Propositional circumscription extended closed worldreasoning p2 -complete. Theoretical Computer Science, 114, 231{245.Eiter, T., & Gottlob, G. (1995). computational cost disjunctive logic programming: propositional case. Annals Mathematics Artificial Intelligence, 15 (3,4).Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.Proceedings Fifth Logic Programming Symposium, pp. 1070{1080. MITPress.Gelfond, M., & Lifschitz, V. (1990). Logic programs classical negation. ProceedingsSeventh International Conference Logic Programming, pp. 579{597.MIT Press.Gelfond, M., & Lifschitz, V. (1991). Classical negation logic programs disjunctivedatabases. New Generation Computing, 9, 365{385.298fiReasoning minimal belief negation failureGottlob, G. (1992). Complexity results nonmonotonic logics. J. Logic Computation, 2, 397{425.Gottlob, G. (1995). NP trees Carnap's modal logic. J. ACM, 42 (2), 421{457.Halpern, J. Y., & Moses, Y. (1985). Towards theory knowledge ignorance: Preliminary report. Apt, K. (Ed.), Logic models concurrent systems. SpringerVerlag.Halpern, J. Y., & Moses, Y. (1992). guide completeness complexity modallogics knowledge belief. Artificial Intelligence, 54, 319{379.Inoue, K., & Sakama, C. (1994). positive occurrences negation failure. Proc.4th Int. Conf. Principles Knowledge Representation Reasoning(KR'94), pp. 293{304. Morgan Kaufmann, Los Altos.Janhunen, T. (1998). intertranslatability autoepistemic, default prioritylogics. Proc. 6th European Workshop Logics Artificial Intelligence(JELIA'98), pp. 216{232.Johnson, D. S. (1990). catalog complexity classes. van Leuven, J. (Ed.), HandbookTheoretical Computer Science, Vol. A, chap. 2. Elsevier Science Publishers (NorthHolland), Amsterdam.Kaminski, M. (1991). Embedding default system nonmonotonic logics. FundamentaInformaticae, 14, 345{354.Levesque, H. J. (1990). know: study autoepistemic logic. Artificial Intelligence,42, 263{310.Lifschitz, V., & Woo, T. (1992). Answer sets general nonmonotonic reasoning (preliminary report). Proc. 3rd Int. Conf. Principles Knowledge Representation Reasoning (KR'92), pp. 603{614. Morgan Kaufmann, Los Altos.Lifschitz, V. (1991). Nonmonotonic databases epistemic queries. Proc. 12thInt. Joint Conf. Artificial Intelligence (IJCAI'91), pp. 381{386.Lifschitz, V. (1994). Minimal belief negation failure. Artificial Intelligence, 70,53{72.Lin, F., & Shoham, Y. (1992). Epistemic semantics fixed-point non-monotonic logics.Artificial Intelligence, 57, 271{289.Marek, W., & Truszczynski, M. (1993). Nonmonotonic Logics { Context-Dependent Reasoning. Springer-Verlag.Marek, W., Truszczynski, M., & Rajasekar, A. (1995). Complexity computingextended propositional logic programs. Annals Mathematics Artificial intelligence, 15 (3,4).299fiRosatiMoore, R. C. (1985). Semantical considerations nonmonotonic logic. Artificial Intelligence, 25, 75{94.Niemela, I. (1992). decidability complexity autoepistemic reasoning. Fundamenta Informaticae, 17 (1,2), 117{156.Papadimitriou, C. H. (1994). Computational Complexity. Addison Wesley Publ. Co., Reading, Massachussetts.Reiter, R. (1990). database know?. J. Logic Programming, 14, 127{153.Rosati, R. (1997). Reasoning minimal belief negation failure: Algorithmscomplexity. Proc. 14th Nat. Conf. Artificial Intelligence (AAAI'97), pp.430{435. AAAI Press/The MIT Press.Rosati, R. (1999). Reasoning minimal knowledge nonmonotonic modal logics. J.Logic, Language Information, 8 (2), 187{203.Schwarz, G. (1991). Autoepistemic logic knowledge. Proc. 1st Int. WorkshopLogic Programming Non-monotonic Reasoning (LPNMR'91), pp. 260{274.MIT Press.Schwarz, G. (1992). Minimal model semantics nonmonotonic modal logics. Proc.7th IEEE Sym. Logic Computer Science (LICS'92), pp. 34{43. IEEEComputer Society Press.Schwarz, G. (1996). embedding default logic Moore's autoepistemic logic. ArtificialIntelligence, 80, 388{392.Schwarz, G., & Lifschitz, V. (1993). Extended logic programs autoepistemic theories.Proc. 2nd Int. Workshop Logic Programming Non-monotonic Reasoning(LPNMR'93), pp. 101{114. MIT Press.Schwarz, G., & Truszczynski, M. (1994). Minimal knowledge problem: new approach.Artificial Intelligence, 67, 113{141.Shoham, Y. (1987). Nonmonotonic logics: Meaning utility. Proc. 10th Int.Joint Conf. Artificial Intelligence (IJCAI'87), pp. 388{392.Stalnaker, R. (1993). note non-monotonic modal logic. Artificial Intelligence, 64 (2),183{196.300fiJournal Artificial Intelligence Research 11 (1999) 1{94Submitted 09/98; published 07/99Decision-Theoretic Planning: Structural AssumptionsComputational LeverageCraig Boutiliercebly@cs.ubc.caDepartment Computer Science, University British ColumbiaVancouver, BC, V6T 1Z4, CanadaThomas Deantld@cs.brown.eduDepartment Computer Science, Brown UniversityBox 1910, Providence, RI, 02912, USASteve Hankshanks@cs.washington.eduDepartment Computer Science Engineering, University WashingtonSeattle, WA, 98195, USAAbstractPlanning uncertainty central problem study automated sequentialdecision making, addressed researchers many different fields, includingAI planning, decision analysis, operations research, control theory economics.assumptions perspectives adopted areas often differ substantial ways,many planning problems interest researchers fields modeled Markovdecision processes (MDPs) analyzed using techniques decision theory.paper presents overview synthesis MDP-related methods, showingprovide unifying framework modeling many classes planning problems studiedAI. also describes structural properties MDPs that, exhibited particular classes problems, exploited construction optimal approximatelyoptimal policies plans. Planning problems commonly possess structure rewardvalue functions used describe performance criteria, functions used describestate transitions observations, relationships among features used describestates, actions, rewards, observations.Specialized representations, algorithms employing representations, achievecomputational leverage exploiting various forms structure. Certain AI techniques|particular based use structured, intensional representations|canviewed way. paper surveys several types representations classicaldecision-theoretic planning problems, planning algorithms exploit representations number different ways ease computational burden constructingpolicies plans. focuses primarily abstraction, aggregation decomposition techniques based AI-style representations.1. IntroductionPlanning using decision-theoretic notions represent domain uncertainty plan qualityrecently drawn considerable attention artificial intelligence (AI).1 Decision-theoreticplanning (DTP) attractive extension classical AI planning paradigmallows one model problems actions uncertain effects, decision maker1. See, example, recent texts (Dean, Allen, & Aloimonos, 1995; Dean & Wellman, 1991; Russell &Norvig, 1995) research reported (Hanks, Russell, & Wellman, 1994).c 1999 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiBoutilier, Dean, & Hanksincomplete information world, factors resource consumption leadsolutions varying quality, may absolute well-defined \goal"state. Roughly, aim DTP form courses action (plans policies)high expected utility rather plans guaranteed achieve certain goals.AI planning viewed particular approach solving sequential decision problemstype, connections DTP models used fields research|suchdecision analysis, economics operations research (OR)|become apparent.conceptual level, sequential decision problems viewed instances Markovdecision processes (MDPs), use MDP framework make connectionsexplicit.Much recent research DTP explicitly adopted MDP framework underlying model (Barto, Bradtke, & Singh, 1995; Boutilier & Dearden, 1994; Boutilier, Dearden,& Goldszmidt, 1995; Dean, Kaelbling, Kirman, & Nicholson, 1993; Koenig, 1991; Simmons& Koenig, 1995; Tash & Russell, 1994), allowing adaptation existing results algorithms solving MDPs (e.g., field OR) applied planning problems.so, however, work departed traditional definition \planningproblem" AI planning community|one goal paper make explicitconnection two lines work.Adopting MDP framework model posing solving planning problemsilluminated number interesting connections among techniques solving decisionproblems, drawing work AI planning, reasoning uncertainty, decision analysisOR. One interesting insights emerge body work manyDTP problems exhibit considerable structure, thus solved using special-purposemethods recognize exploit structure. particular, use feature-basedrepresentations describe problems, typical practice AI, often highlightsproblem's special structure allows exploited computationally little effort.two general impediments widespread acceptance MDPs withinAI general model planning. first absence explanations MDP modelmake connections current planning research explicit, either conceptualcomputational level. may due large part fact MDPsdeveloped studied primarily OR, dominant concerns are, naturally, ratherdifferent. One aim paper make connections clear: provide briefdescription MDPs conceptual model planning emphasizes connectionAI planning, explore relationship MDP solution algorithms AIplanning algorithms. particular, emphasize AI planning modelsviewed special cases MDPs, classical planning algorithms designedexploit problem characteristics associated cases.second impediment skepticism among AI researchers regarding computationaladequacy MDPs planning model: techniques scale solve planning problemsreasonable size? One diculty solution techniques MDPs tendency relyexplicit, state-based problem formulations. problematic AI planningsince state spaces grow exponentially number problem features. State space sizedimensionality somewhat lesser concern decision analysis.fields, operations researcher decision analyst often hand-craft model ignorescertain problem features deemed irrelevant, define features summarize2fiDecision-Theoretic Planning: Structural Assumptionswide class problem states. AI, emphasis automatic solution problemsposed users lack expertise decision analyst. Thus, assuming well-crafted,compact state space often appropriate.paper show specialized representations algorithms AI planningproblem solving used design ecient MDP solution techniques. particular,AI planning methods assume certain structure state space, actions (oroperators), specification goal success criteria. Representationsalgorithms designed make problem structure explicit exploitstructure solve problems effectively. demonstrate process identifyingstructure, making explicit, exploiting algorithmically brought bearsolution MDPs.paper several objectives. First, provides overview DTP MDPssuitable readers familiar traditional AI planning methods makes connectionswork. Second, describes types structure exploitedAI representations methods facilitate computationally effective planning MDPs.such, suitable introduction AI methods familiar classicalpresentation MDPs. Finally, surveys recent work use MDPs AIsuggests directions research regard, therefore interestresearchers DTP.1.1 General Problem DefinitionRoughly speaking, class problems consider involving systems whosedynamics modeled stochastic processes, actions decision maker,referred agent , uence system's behavior. system's currentstate choice action jointly determine probability distribution system'spossible next states. agent prefers certain system states (e.g., goal states)others, therefore must determine course action|also called \plan" \policy"paper|that likely lead target states, possibly avoiding undesirable statesalong way. agent may know system's state exactly making decisionact, however|it may rely incomplete noisy sensors forcedbase choice action probabilistic estimate state.help illustrate types problems interested, consider followingexample. Imagine robot agent designed help someone (the \user")oce environment (see Figure 1). three activities might undertake: pickinguser's mail, getting coffee, tidying user's research lab. robot movelocation location perform various actions tend achieve certain targetstates (e.g., bringing coffee user demand, maintaining minimal level tidinesslab).might associate certain level uncertainty effects robot's actions(e.g., tries move adjacent location might succeed 90% time failmove 10% time). robot might incomplete accesstrue state system sensors might supply incomplete information (itcannot tell whether mail available pickup mail room) incorrect3fiBoutilier, Dean, & HanksOfficeHallwayLabMailRoomCoffeeFigure 1: decision-theoretic planning probleminformation (even mail room sensors occasionally fail detect presencemail).Finally, performance robot might measured various ways: actionsguarantee goal achieved? maximize objective function definedpossible effects actions? achieve goal state sucient probability avoiding \disastrous" states near certainty? stipulation optimalacceptable behavior important part problem specification.types problems captured using general framework include classical (goal-oriented, deterministic, complete knowledge) planning problems extensionsconditional probabilistic planning problems, well generalproblem formulations.discussion point assumed extensional representation system'sstates|one state explicitly named. AI research, intensional representations common. intensional representation one states setsstates described using sets multi-valued features. choice appropriate setfeatures important part problem design. features might includecurrent location robot, presence absence mail, on. performancemetric also typically expressed intensionally. Figure 2 serves reference example problem, use throughout paper. lists basic features used describestates system, actions available robot exogenous eventsmight occur, together intuitive description features, actions events.remainder paper organized follows. Section 2, present MDPframework abstract, introducing basic concepts terminology noting relationship abstract model classical AI planning problem. Section 3 surveys common solution techniques|algorithms based dynamic programming generalMDP problems search algorithms planning problems|and points relationship problem assumptions solution techniques. Section 4 turns algorithmsrepresentations, showing various ways structured representations commonlyused AI algorithms used represent MDPs compactly well. Section 5 surveys4fiDecision-Theoretic Planning: Structural AssumptionsFeaturesLocationDenotedDescriptionLoc(M ), etc. Location robot. Five possible locations: mailroom (M), coffee room(C), user's oce (O), hallway (H), laboratory (L)Tidiness(0), etc.Degree lab tidiness. Five possible values: 0 (messiest) 4(tidiest)Mail presentM;mail user's mail box? True (M ) False (M )Robot mailRHM; RHM robot mail possession?Coffee requestCR; CRoutstanding (unfulfilled) request coffee user?Robot coffee RHC; RHC robot coffee possession?ActionsDenotedDescriptionMove clockwiseClkMove adjacent location (clockwise direction)Counterclockwise CClkMove adjacent location (counterclockwise direction)Tidy labTidyrobot lab, degree tidiness increased 1Pickup mailPUMrobot mailroom mail present, robottakes mail (RHM becomes true becomes false)Get coffeeGetCrobot coffee room, gets coffee (RHC becomes true)Deliver mailDelMrobot oce mail, hands mail user(RHM becomes false)Deliver coffeeDelCrobot oce coffee, hands coffeeuser (RHC CR become false)EventsDenotedDescriptionMail arrivalArrMMail arrives causing become trueRequest coffeeReqCUser issues coffee request causing CR become trueUntidy labMesslab becomes messier (one degree less tidy)Figure 2: Elements robot domain.recent work abstraction, aggregation problem decomposition methods,shows connection traditional AI methods goal regression. lastsection demonstrates representational computational methods AI planningused solution general MDPs. Section 5 also points additional waystype computational leverage might developed future.2. Markov Decision Processes: Basic Problem Formulationsection introduce MDP framework make explicit relationshipmodel classical AI planning models. interested controlling stochasticdynamical system: system point time one number distinctstates, system's state changes time response events. actionparticular kind event instigated agent order change system's state.assume agent control actions taken when, thougheffects taking action might perfectly predictable. contrast, exogenous eventsagent's control, occurrence may partially predictable.abstract view agent consistent \AI" view agentautonomous decision maker \control" view policy determined aheadtime, programmed device, executed without deliberation.5fiBoutilier, Dean, & Hanks2.1 States State Transitionsdefine state description system particular point time. onedefines states vary particular applications, notions naturalothers. However, common assume state captures information relevantagent's decision-making process. assume finite state space = fs1 ; : : : ; sN gpossible system states.2 cases agent complete informationcurrent state; uncertainty incomplete information captured usingprobability distribution states .discrete-time stochastic dynamical system consists state space probabilitydistributions governing possible state transitions|how next state system dependspast states. distributions constitute model system evolves timeresponse actions exogenous events, ecting fact effects actionsevents may perfectly predictable even prevailing state known.Although generally concerned agent chooses appropriate courseaction, remainder section assume agent's course actionfixed, concentrating problem predicting system's state occurrencepredetermined sequence actions. discuss action selection problem nextsection.assume system evolves stages, occurrence event markstransition one stage next stage + 1. Since events define changes stage,since events often (but necessarily) cause state transitions, often equate stagetransitions state transitions. course, possible event occur leavesystem state.system's progression stages roughly analogous passage time.two identical assume action (possibly no-op) takenstage, every action takes unit time complete. thus speak looselystages correspond units time, refer interchangeably set stagesset time points.3model uncertainty regarding system's state stage randomvariable takes values . assumption \forward causality" requiresvariable depend directly value future variable k (k > t). Roughly,requires model system past history \directly" determinesdistribution current states, whereas knowledge future states uenceestimate current state indirectly providing evidence current statemay lead future states. Figure 3(a) shows graphical perspectivediscrete-time, stochastic dynamical system. nodes random variables denotingstate particular time, arcs indicate direct probabilistic dependencestates previous states. describe system completely must also supplyconditional distributions Pr(S jS 0 ; 1 ; t,1 ) times t.States thought descriptions system modeled, question arises much detail system captured state description.2. discussion paper also applies cases state space countably infinite. See(Puterman, 1994) discussion infinite continuous-state problems.3. deal topics here, considerable literature communitycontinuous-time Markov decision processes (Puterman, 1994).6fiDecision-Theoretic Planning: Structural Assumptions(a)(b)(c)001122t-1t-1t-1Figure 3: general stochastic process (a), Markov chain (b), stationary Markovchain (c).detail implies information system, turn often translates betterpredictions future behavior. course, detail also implies larger set ,increase computational cost decision making.commonly assumed state contains enough information predict nextstate. words, information history system relevant predictingfuture captured explicitly state itself. Formally, assumption, Markovassumption, says knowledge present state renders information pastirrelevant making predictions future:Pr(S t+1 jS ; t,1 ; : : : ; 0 ) = Pr(S t+1 jS )Markovian models represented graphically using structure like Figure 3(b),ecting fact present state sucient predict future state evolution.4Finally, common assume effects event depend prevailingstate, stage time event occurs.5 distribution predictingnext state regardless stage, model said stationaryrepresented schematically using two stages, Figure 3(c). casesingle conditional distribution required. paper generally restrict attentiondiscrete-time, finite-state, stochastic dynamical systems Markov property, commonly called Markov chains. Furthermore, discussion restricted stationarychains.complete model must provide probability distribution initial states,ecting probability state stage 0. distribution repre4. worth mentioning Markov property applies particular model systemitself. Indeed, non-Markovian model system (of finite order, i.e., whose dynamics dependk previous states k) converted equivalent though larger Markov model.control theory, called conversion state form (Luenberger, 1979).5. course, also statement model detail, saying state carries enough informationmake stage irrelevant predicting transitions.7fiBoutilier, Dean, & Hanks.36.7.9.1.51.53.141.0.22.85.471.0.5Figure 4: state-transition diagram.sented real-valued (row) vector size N = jS j (one entry state). denotevector P 0 use p0i denote ith entry, is, probability starting statesi .represent -stage nonstationary Markov chain transition matrices,size N N , matrix P captures transition probabilities governingsystem moves stage stage + 1. matrix consists probabilities ptij ,ptij = Pr(S t+1 = sj jS = si ). process stationary, transition matrixstages one matrix (whose entries denoted pij ) suce. Giveninitialstates P 0 , probability distribution states n stagesQ0 Pdistributioni.i=nstationary Markov process also represented using state-transition diagramFigure 4. nodes correspond particular states stage representedexplicitly. Arcs denote possible transitions (those non-zero probability) labeledtransition probabilities pij = Pr(S t+1 = sj jS = si ). arc node nodej labeled pij pij > 0.6 size diagram least O(N )O(N 2 ), depending number arcs. useful representation transitiongraph relatively sparse, example, states immediate transitionsneighbors.Example 2.1 illustrate notions, imagine robot Figure 1 executingpolicy moving counterclockwise repeatedly. restrict attention twovariables, location Loc presence mail , giving state space size 10.suppose robot always moves adjacent location probability 1:0.addition, mail arrive mailroom probability 0:2 time (independent robot's location), causing variable become true.becomes true, robot cannot move state false, since actionmoving uence presence mail. state-transition diagramexample illustrated Figure 5. transition matrix also shown. 2structure Markov chain occasionally interest us planning. subsetC closed pij = 0 2 C j 62 C . proper closed set propersubset C enjoys property. sometimes refer proper closed sets recurrentclasses states. closed set consists single state, state calledabsorbing state. agent enters closed set absorbing state, remains6. important note nodes represent random variables earlier figures.8fiDecision-Theoretic Planning: Structural Assumptionss1s20.2OM0.80.80.2OMs7HMLM0.81.01.0s100.20.8CMMMMM0.2s3HMs9 1.0s40.8s1s2s3s4s5s6s7s8s9s10s61.0s5LM0.2s8CM1.0s10:00:00:00:00:80:00:00:00:00:0s20:80 :00:00:00:00:00:00:00:00 :0s30:00:80:00:00:00:00:00:00:00 :0s40:00:00:80:00:00:00:00:00:00:0s50:00:00:00:80:00:00:00:00:00:0s60:00 :00:00 :00:20 :00 :00 :00 :01:0s70:20:00:00:00:01:00:00:00:00:0s80:00:20:00:00:00:01:00:00:00:0s90:00:00:20:00:00:00:01:00:00:0s100:00:00:00:20:00:00:00:01:00:0Figure 5: state-transition diagram transition matrix moving robot.forever probability 1. example (Figure 5), set statesholds forms recurrent class. absorbing states example,program robot stay put whenever state hM; Loc(O)i, wouldabsorbing state altered chain. Finally, say state transientbelong recurrent class. Figure 5, state holds transient|eventually(with probability 1), agent leaves state never returns, since wayremove mail arrives.2.2 ActionsMarkov chains used describe evolution stochastic system,capture fact agent choose perform actions alter statesystem. key element MDPs set actions available decision maker.action performed particular state, state changes stochastically responseaction. assume agent takes action stage process,system changes state accordingly.stage process state s, agent available set actionsAts. called feasible set stage t. describe effects 2 Ats, mustsupply state-transition distribution Pr(S t+1 jS = s; = a) actions a, states s,stages t. Unlike case Markov chain, terms Pr(S t+1 jS = s; = a)true conditional distributions, rather family distributions parameterized, since probability part model. retain notation, however,suggestive nature.often assume feasible set actions stages states,case set actions = fa1 ; : : : ; aK g executed time.contrasts AI planning practice assigning preconditions actions definingstates meaningfully executed. model takes viewaction executed (or \attempted") state. action effectexecuted state, execution leads disastrous effects, notedaction's transition matrix. Action preconditions often computational conveniencerather representational necessity: make planning process ecientidentifying states planner even consider selecting action.Preconditions represented MDPs relaxing assumption set9fiBoutilier, Dean, & Hankss1s2s3s4s5s6s7s8s9s10s10:00:00:00:00:80:00:00:00:00:0s20:80:00:80:00:00:00:00:00:00:0s30:00:80:00:80:00:00:00:00:00:0s40:00:00:00:00:00:00:00:00:00:0s50:00:00:00:00:00:00:00:00:00:0s60:00:00:00:00:20:00:00:00:01:0s70:20:00:20:00:01:00:01:00:00:0s80:00:20:00:20:00:01:00:01:00:0s90:00:00:00:00:00:00:00:00:00:0s100:20:00:00:00:00:00:00:00:00:0s10.80.2OM0.8s2LMs3s7s101.0s91.00.8CMMMMMs8s40.20.21.0s6HMs50.80.81.0HM0.2LMOM0.2CM1.0Figure 6: transition matrix Clk induced transition diagram two-actionpolicy.feasible actions states. illustrate planning concepts below, however,sometimes assume actions preconditions.restrict attention stationary processes, case meanseffects action depends state stage. transitionmatrices thus take form pkij = Pr(S t+1 = sj jS = si ; = ak ), capturing probabilitysystem moves state sj ak executed state si . stationary modelsaction fully described single N N transition matrix P k . important notetransition matrix action includes direct effects executingaction also effects exogenous events might occur stage.7Example 2.2 example Figure 5 extended agent two availableactions: moving clockwise moving counterclockwise. transition matrixCClk (with assumption mail arrives probability 0:2) shown Figure 5.matrix Clk appears left Figure 6. Suppose agent fixes behaviormoves clockwise locations C counterclockwise locations H ,L (we address agent might come know locationactually implement behavior). defines Markov chain illustratedtransition diagram right Figure 6. 22.3 Exogenous EventsExogenous events events stochastically cause state transitions, much likeactions, beyond control decision maker. might correspondevolution natural process action another agent. Notice effectaction CClk Figure 5 \combines" effects robot's actionexogenous event mail arrival: state-transition probabilities incorporate motionrobot (causing change location) possible change mail status duemail arrival. purposes decision making, precisely combined effect7. possible assess effects actions exogenous events separately, combinesingle transition matrix certain cases (Boutilier & Puterman, 1995). discuss latersection.10fiDecision-Theoretic Planning: Structural Assumptionsimportant predicting distribution possible states resultingaction taken. call models actions implicit-event models, since effectsexogenous event folded transition probabilities associated action.However, often natural view transitions comprised two separateevents, effect state. generally, often think transitionsdetermined effects agent's chosen action certain exogenousevents beyond agent's control, may occur certain probability.effects actions decomposed fashion, call action modelexplicit-event model.Specifying transition function action zero exogenous eventsgenerally easy, actions events interact complex ways. instance, considerspecifying effect action PUM (pickup mail) state mail presentpossibility \simultaneous" mail arrival (i.e., \same unit" discretetime). event ArrM occurs, robot obtain newly arrived mail,mail remain mailbox? Intuitively, depends whether mail arrivedpickup completed (albeit within time quantum). state transitioncase viewed composition two transitions precise descriptioncomposition depends ordering agent's action exogenous event.mail arrives first, transition might ! s0 ! s00 , s0 state mailwaiting s00 state mail waiting robot holding mail;pickup action completed first, transition would ! ! s0 (i.e., PUMeffect, mail arrives remains box).picture complicated actions events truly occur simultaneouslyinterval|in case resulting transition need compositionindividual transitions. example, robot lifts side table glasswater situated, water spill; similarly exogenous event causes sideraised. action event occur simultaneously, result qualitativelydifferent (the water spilled). Thus, \interleaving" semantics describedalways appropriate.complications, modeling exogenous events combinationactions events approached many ways, depending modeling assumptions one willing make. Generally, specify three types information. First,provide transition probabilities actions events assumptionoccur isolation|these standard transition matrices. transition matrixFigure 5 decomposed two matrices shown Figure 7, one Clk oneArrM.8 Second, exogenous event, must specify probability occurrence.Since vary state, generally require vector length N indicatingprobability occurrence state. occurrence vector ArrM would[0:2 0:2 0:2 0:2 0:2 0:0 0:0 0:0 0:0 0:0]8. fact individual matrices deterministic artifact example. general,actions events represented using genuinely stochastic matrices.11fiBoutilier, Dean, & Hankss1s2s3s4s5s6s7s8s9s10s10:00:00:00:01:00:00:00:00:00:0s21:00:00:00:00:00:00:00:00:00:0s30:01:00:00:00:00:00:00:00:00:0s40:00:01:00:00:00:00:00:00:00:0s50:00:00:01:00:00:00:00:00:00:0s60:00:00:00:00:00:00:00:00:01:0s70:00:00:00:00:01:00:00:00:00:0s80:00:00:00:00:00:01:00:00:00:0s90:00:00:00:00:00:00:01:00:00:0s100:00:00:00:00:00:00:00:01:00:0s1s2s3s4s5s6s7s8s9s10Action Clks10 :00 :00 :00 :00 :00 :00 :00 :00 :00 :0s20:00:00:00:00:00:00:00:00:00:0s30 :00 :00 :00 :00 :00 :00 :00 :00 :00 :0s40:00:00:00:00:00:00:00:00:00:0s50:00:00:00:00:00:00:00:00:00:0s61:00:00:00:00:01:00:00:00:00:0s70:01:00:00:00:00:01:00:00:00:0s80:00:01:00:00:00:00:01:00:00:0s90:00:00:01:00:00:00:00:01:00:0s100:00:00:00:01:00:00:00:00:01:0Event ArrMFigure 7: transition matrices action exogenous event explicit-eventmodel.assume, illustration, mail arrives none present.9 finalrequirement combination function describes \compose" transitionsaction subset event transitions. indicated above, complex,sometimes almost unrelated individual action event transitions. However,certain assumptions combination functions specified reasonably concisely.One way modeling composition transitions assume interleaving semantics type alluded above. case, one needs specify probabilityaction events take place occur specific order. instance, one mightassume event occurs time|within discrete time unit|accordingcontinuous distribution (e.g., exponential distribution given rate). information, probability particular ordering transitions, given certain eventsoccur, computed, resulting distribution possible next states.example above, probability (composed) transitions s1 ! s2 ! s3 s1 ! s1 ! s2would given probabilities mail arrived first last, respectively.certain cases, probability ordering needed. illustrate anothercombination function, assume action always occurs exogenous events.Furthermore, assume events commutative: (a) initial state pairevents e1 e2 , distribution results applying event sequence e1 e2identical obtained sequence e2 e1 ; (b) occurrence probabilitiesintermediate states identical. Intuitively, set events domain, ArrM, ReqCMess, property. conditions combined transition distributionaction computed considering probability subset eventsapplying subset order distribution associated a.Generally, construct implicit-event model various componentsexplicit-event model; thus, \natural" specification converted form usuallyused MDP solution algorithms. two assumptions above, instance,form implicit event transition matrix Pr(si ; a; sj ) action a, given matrixPcra (si ; sj ) (which assumes event occurrences), matrices Pre (si ; sj ) eventse, occurrence vector Pre(si ) event e. effective transition matrix9. probability different events may correlated (possibly particular states). case,necessary specify occurrence probabilities subsets events. treat event occurrenceprobabilities independent ease exposition.12fiDecision-Theoretic Planning: Structural Assumptionsevent e defined follows:Pcre (si ; sj ) = Pre (si )Pre (si ; sj ) +(1 , Pre (si ) : = j0 : 6= jequation captures event transition probabilities probability event occurrence factored in. let E; E 0 denote diagonal matrices entries Ekk = Pre (sk )0 = 1 , Pre (sk ), Prc e(si; sj ) = E Pre +E 0. assumptions above,Ekkimplicit-event matrix Pr(si ; a; sj ) action given Pr = Pcre1 Pcren Praordering n possible events.Naturally, different procedures constructing implicit-event matrices requiredgiven different assumptions action event interaction. Whether implicit models constructed specified directly without explicit mention exogenous events,always assume unless stated otherwise action transition matrices take accounteffects exogenous events well, thus represent agent's best informationhappen takes particular action.2.4 ObservationsAlthough effects action depend aspect prevailing state,choice action depend agent observe current stateremember prior observations. model agent's observational sensingcapabilities introducing finite set observations = fo1 ; : : : ; oH g. agent receivesobservation set stage prior choosing action stage.model observation random variable Ot whose value taken O.probability particular Ot generated depend on:state system , 1action taken , 1state system taking action , 1 effectsexogenous events , 1 realized, action taken.let Pr(Ot = oh jS t,1 = si ; At,1 = ak ; = sj ) probability agent observesoh stage given performs ak state si ends state sj . actions,assume observational distributions stationary (independent stage), usingphi;j;k = Pr(ohjsi; ak ; sj ) denote quantity. view probabilistic dependenciesamong state, action observation variables graph time-indexed variablesshown nodes one variable directly probabilistically dependent anotheredge latter former; see Figure 8.model allows wide variety assumptions agent's sensing capabilities.one extreme fully observable MDPs (FOMDPs), agent knows exactlystate stage t. model case letting = settingPr(oh jsi ; ak ; sj ) =13(1 iff oh = sj0 otherwisefiBoutilier, Dean, & Hankst-1t-1Figure 8: Graph showing dependency relationships among states, actions observations different times.example above, means robot always knows exact location whethermail waiting mailbox, even mailroom mail arrives.agent thus receives perfect feedback results actions effectsexogenous events|it noisy effectors complete, noise-free, \instantaneous"sensors. recent AI research adopts MDP framework explicitly assumes fullobservability.extreme might consider non-observable systems (NOMDPs)agent receives information system's state execution. modelcase letting = fog. observation reported stage, revealinginformation state, Pr(sj jsi ; ak ; o) = Pr(sj jsi ; ak ). open-loopsystems, agent receives useful feedback results actions: agentnoisy effectors sensors. case agent chooses actions according planconsisting sequence actions executed unconditionally. effect, agent relyingpredictive model determine good action choices execution time.Traditionally, AI planning work implicitly made assumption non-observability,often coupled omniscience assumption|that agent knows initial statecertainty, predict effects actions perfectly, precisely predict occurrence exogenous events effects. circumstances, agentpredict exact outcome plan, thus obviating need observation.agent build straight-line plan|a sequence actions performed withoutfeedback|that good plan whose execution might depend information gathered execution time.two extremes special cases general observation model described above,allows agent receive incomplete noisy information system state(i.e., partially observable MDPs, POMDPs). example, robot might abledetermine location exactly, might able determine whether mail arrivesunless mailroom. Furthermore, \mail" sensors might occasionally reportinaccurately, leading incorrect belief whether mail waiting.Example 2.3 Suppose robot \checkmail" action change systemstate generates observation uenced presence mail, provided14fiDecision-Theoretic Planning: Structural AssumptionsLoc(M );Loc(M );Loc(M );Loc(M );Pr(Obs = mail) Pr(Obs = nomail)0:920:080:050:950:001:000:001:00Figure 9: Observation probabilities checking mailbox.robot mailroom time action performed. robotmailroom, sensor always reports \no mail." noisy \checkmail" sensordescribed probability distribution like one shown Figure 9.view error probabilities probability \false positives" (0:05) \falsenegatives" (0:08). 22.5 System Trajectories Observable Historiesuse terms trajectory history interchangeably describe system's behaviorcourse problem-solving episode, perhaps initial segment thereof.complete system history sequence states, actions, observations generatedstage 0 time point interest, finite infinite length. Completehistories represented (possibly infinite) sequence tuples formhhS 0 ; O0 ; A0 i; hS 1 ; O1 ; A1 i; : : : hS ; OT ; iidefine two alternative notions history contain less complete information.arbitrary stage define observable history sequencehhO0 ; A0 i; : : : ; hOt,1 ; At,1 iiO0 observation initial state. observable history stage comprisesinformation available agent history chooses action stage t.third type trajectory system trajectory, sequencehhS 0 ; A0 i; : : : ; hS t,1 ; At,1 i;describing system's behavior \objective" terms, independent agent's particularview system.evaluating agent's performance, generally interested systemtrajectory. agent's policy must defined terms observable history, sinceagent access system trajectory, except fully observable case,two equivalent.2.6 Reward Valueproblem facing decision maker select action performed stagedecision problem, making decision basis observable history.agent still needs way judge quality course action. done defining15fiBoutilier, Dean, & Hankst-1t-1CRFigure 10: Decision process rewards action costs.value function V() function mapping set system histories HS reals;is, V : HS ! R.10 agent prefers system history h h0 case V(h) > V(h0 ).Thus, agent judges behavior good bad depending effectunderlying system trajectory. Generally, agent cannot predict certaintysystem trajectory occur, best generate probability distributionpossible trajectories caused actions. case, computes expected valuecandidate course action chooses policy maximizes quantity.system dynamics, specifying value function arbitrary trajectoriescumbersome unintuitive. therefore important identify structurevalue function lead parsimonious representation.Two assumptions value functions commonly made MDP literaturetime-separability additivity. time-separable value function defined termsprimitive functions applied component states actions. rewardfunction R : ! R associates reward state s. Costs assignedtaking actions defining cost function C : ! R associates costperforming action state s. Rewards added value function, costssubtracted.11value function time-separable \simple combination" rewards costsaccrued stage. \Simple combination" means value taken functioncosts rewards stage, costs rewards depend stage t,function combines must independent stage, commonly linearcombination product.12 value function additive combination functionsum reward cost function values accrued history's stages. additionrewards action costs system time-separable value viewed graphicallyshown Figure 10.assumption time-separability restrictive. example, mightcertain goals involving temporal deadlines (have workplace tidy soon possible9:00 tomorrow morning) maintenance (do allow mail sit mailroom10. Technically, set histories interest also depends horizon chosen, described below.11. term \reward" somewhat misnomer reward could negative, case\penalty" might better word. Likewise, \costs" either positive (punitive) negative (beneficial). Thus, admit great exibility defining value functions.12. See (Luenberger, 1973) precise definition time-separability.16fiDecision-Theoretic Planning: Structural Assumptionsundelivered 10 minutes) require value functions non-separablegiven current representation state. Note, however, separability|likeMarkov property|is property particular representation. could add additionalinformation state example: clock time, interval time 9:00time tidiness achieved, length time mail sits mail roomrobot picks up, on. additional information could reestablish time-separable value function, expense increase numberstates ad hoc cumbersome action representation.132.7 Horizons Success Criteriaorder evaluate particular course action, need specify long (inmany stages) executed. known problem's horizon. finite-horizonproblems, agent's performance evaluated fixed, finite number stages .Commonly, aim maximize total expected reward associated courseaction; therefore define (finite-horizon) value length history h (Bellman,1957):V (h) =TX,1t=0fR(st ) , C (st; )g + R(sT )infinite-horizon problem, hand, requires agent's performanceevaluated infinite trajectory. case total reward may unbounded,meaning policy could arbitrarily good bad executed long enough.case may necessary adopt different means evaluating trajectory.common introduce discount factor, ensuring rewards costs accruedlater stages counted less accrued earlier stages. value functionexpected total discounted reward problem defined follows (Bellman, 1957; Howard,1960):1XV (h) = (R(st) , C (st; ))t=0fixed discount rate (0 < 1). formulation particularly simpleelegant way ensure bounded measure value infinite horizon, thoughimportant verify discounting fact appropriate. Economic justifications oftenprovided discounted models|a reward earned sooner worth one earnedlater provided reward somehow invested. Discounting also suitablemodeling process terminates probability 1 , point time (e.g.,robot break down), case discounted models correspond expected totalreward finite uncertain horizon. reasons, discounting sometimes usedfinite-horizon problems well.Another technique dealing infinite-horizon problems evaluate trajectorybased average reward accrued per stage, gain. gain history definednXg(h) = lim 1 fR(st ) , C (st ; )gn!1 n t=013. See (Bacchus, Boutilier, & Grove, 1996, 1997), however, systematic approach handling certaintypes history-dependent reward functions.17fiBoutilier, Dean, & HanksRefinements criterion also proposed (Puterman, 1994).Sometimes problem ensures total reward infinite trajectorybounded, thus expected total reward criterion well-defined. Consider casecommon AI planners agent's task bring system goal state.positive reward received goal reached, actions incur non-negativecost, goal reached system enters absorbing staterewards costs accrued. long goal reached certainty,situation formulated infinite-horizon problem total reward boundeddesired trajectory (Bertsekas, 1987; Puterman, 1994). general, problemscannot formulated (fixed) finite-horizon problems unless priori boundnumber steps needed reach goal established. problems sometimescalled indefinite-horizon problems: practical point view, agent continueexecute actions finite number stages, exact number cannot determinedahead time.2.8 Solution Criteriacomplete definition planning problem need specify constitutessolution problem. see split explicit MDP formulationswork AI planning community. Classical MDP problems generally statedoptimization problems: given value function, horizon, evaluation metric (e.g.,expected total reward, expected total discounted reward, expected average reward per stage)agent seeks behavioral policy maximizes objective function.Work AI often seeks satisficing solutions problems. planning literature,generally taken plan satisfies goal equally preferredplan satisfies goal, plan satisfies goal preferableplan not.14 probabilistic framework, might seek plan satisfiesgoal maximum probability (an optimization), lead situationsoptimal plan infinite length system state fully observable.satisficing alternative (Kushmerick, Hanks, & Weld, 1995) seek plan satisfiesgoal probability exceeding given threshold.Example 2.4 extend running example demonstrate infinite-horizon, fullyobservable, discounted reward situation. begin adding one new dimensionstate description, boolean variable RHM (does robot mail), giving ussystem 20 states. also provide agent two additional actions: PUM(pickup mail) DelM (deliver mail) described Figure 2. rewardagent way mail delivery encouraged: associate reward10 state RHM false 0 states.actions cost, agent gets total reward 20 six-stage systemtrajectory:hLoc(M ); M; RHMi; Stay; hLoc(M ); M; RHMi; PUM; hLoc(M ); M; RHMi;Clk; hLoc(H ); M; RHMi; Clk; hLoc(O); M; RHMi; DelM; hLoc(O); M; RHMi14. Though see (Haddawy & Hanks, 1998; Williamson & Hanks, 1994) restatement planningoptimization problem.18fiDecision-Theoretic Planning: Structural Assumptionsassign action cost ,1 action except Stay (which 0 cost),total reward becomes 16. use discount rate 0:9 discount futurerewards costs, initial segment infinite-horizon history would contribute10 + :9(,1) + :81(,1) + :729(,1) + :6561(,1) + :59054(,1 + 10) = 12:2 totalvalue trajectory (as subsequently extended). Furthermore, establishbound total expected value trajectory. best case, subsequentstages yield reward 10, expected total discounted reward bounded1X12:2 + :96 (10) + :97 (10) + : : : = 12:2 + 10 :96 0:9i < 66i=0similar effect behavior achieved penalizing states (i.e., negativerewards) either RHM true. 22.9 Policiesmentioned policies (or courses action, plans) informally point,provide precise definition. decision problem facing agent viewedgenerally deciding action perform given current observable history.define policy mapping set observable histories HO actions,is, : HO ! A. Intuitively, agent executes action= (hho0 ; a0 i; : : : ; hot,1 ; at,1 i; ot i)stage performed actions a0 ; at,1 made observations o0 ; ot,1earlier stages, made observation ot current stage.policy induces distribution Pr(hj) set system histories HS ; probability distribution depends initial distribution P 0 . define expected valuepolicy be:XEV() =V(h) Pr(hj)h2HSwould like agent adopt policy either maximizes expected value or,satisficing context, acceptably high expected value.general form policy, depending arbitrary observation history,lead complicated policies policy-construction algorithms. special cases,however, assumptions observability structure value function resultoptimal policies much simpler form.case fully observable MDP time-separable value function, optimalaction stage computed using information current statestage: is, restrict policies simpler form : ! withoutdanger acting suboptimally. due fact full observability allows stateobserved completely, Markov assumption renders prior history irrelevant.non-observable case, observational history contains vacuous observationsagent must choose actions using knowledge previous actionsstage; however, since incorporates previous actions, takes form : ! A.19fiBoutilier, Dean, & Hanksform policy corresponds linear, unconditional sequence actions ha1 ; a2 ; : : : ; i,straight-line plan AI nomenclature.152.10 Model Summary: Assumptions, Problems, ComputationalComplexityconcludes exposition MDP model planning uncertainty. generality allows us capture wide variety problem classes currentlystudied literature. section review basic components model,describe problems commonly studied DTP literature respect model,summarize known complexity results each. Section 3, describe specialized computational techniques used solve problems problem classes.2.10.1 Model Summary AssumptionsMDP model consists following components:state space , finite countable set states. generally make Markovassumption, requires state convey information necessary predicteffects actions events independent informationsystem history.set actions A. action ak represented transition matrix sizejS jjS j representing probability pkij performing action ak state si movesystem state sj . assume throughout action model stationary,meaning transition probabilities vary time. transition matrixaction generally assumed account exogenous events mightoccur stage action executed.set observation variables O. set \messages" sent agentaction performed, provide execution-time information currentsystem state. action ak pair states si , sj , pkij > 0,associate distribution possible observations: pkmij denotes probabilityobtaining observation om given action ak taken si resultedtransition state sj .value function V . value function maps state history real numberV (h1 ) V (h2 ) case agent considers history h1 least goodh2 . state history records progression states system assumes alongactions performed. Assumptions time-separability additivitycommon V . particular, generally use reward function R cost functionC defining value.horizon . number stages state historiesevaluated using V .15. Many algorithms AI literature produce partially ordered sequence actions. plansnot, however, involve conditional nondeterministic execution. Rather, represent factlinear sequence consistent partial order solve problem. Thus, partially orderedplan concise representation particular set straight-line plans.20fiDecision-Theoretic Planning: Structural Assumptionsoptimality criterion. provides criterion evaluating potential solutionsplanning problems.2.10.2 Common Planning Problemsuse general framework classify various problems commonly studiedplanning decision-making literature. case below, note modeling assumptions define problem class.Planning Problems OR/Decision Sciences TraditionFully Observable Markov Decision Processes (FOMDPs) | ex-tremely large body research studying FOMDPs, present basic algorithmic techniques detail next section. commonly used formulation FOMDPs assumes full observability stationarity, uses optimalitycriterion maximization expected total reward finite horizon, maximization expected total discounted reward infinite horizon, minimizationexpected cost goal state.FOMDPs introduced Bellman (1957) studied depthfields decision analysis OR, including seminal work Howard (1960). Recent texts FOMDPs include (Bertsekas, 1987) (Puterman, 1994). Average reward optimality also received attention literature (Blackwell, 1962; Howard,1960; Puterman, 1994). AI literature, discounted total reward modelspopular well (Barto et al., 1995; Dearden & Boutilier, 1997; Dean, Kaelbling, Kirman, & Nicholson, 1995; Koenig, 1991), though average-reward criterionproposed suitable modeling AI planning problems (Boutilier &Puterman, 1995; Mahadevan, 1994; Schwartz, 1993).Partially Observable Markov Decision Processes (POMDPs) | POMDPscloser FOMDPs general model decision processes described.POMDPs generally studied assumption stationarity optimality criteria identical FOMDPs, though average-reward criterionwidely considered. discuss below, POMDP viewedFOMDP state space consisting set probability distributions. probability distributions represent states belief: agent \observe"state belief system although exact knowledgesystem state itself.POMDPs widely studied control theory (Astrom, 1965; Lovejoy, 1991b; Smallwood & Sondik, 1973; Sondik, 1978), drawn increasingattention AI circles (Cassandra, Kaelbling, & Littman, 1994; Hauskrecht, 1998;Littman, 1996; Parr & Russell, 1995; Simmons & Koenig, 1995; Thrun, Fox, & Burgard, 1998; Zhang & Liu, 1997). uence diagrams (Howard & Matheson, 1984;Shachter, 1986) popular model decision making AI are, fact,structured representational method POMDPs (see Section 4.3).Planning Problems AI Tradition21fiBoutilier, Dean, & HanksClassical Deterministic Planning | classical AI planning model assumesdeterministic actions: action ak taken state si one successor sj .important assumptions non-observability value determinedreaching goal state: plan leads goal state preferrednot. Often preference shorter plans; representedusing discount factor \encourage" faster goal achievement assigningcost actions. Reward associated transitions goal states,absorbing. Action costs typically ignored, except noted above.classical models usually assumed initial state known certainty.contrasts general specification MDPs above, assumeknowledge even distributional information initial state. Policiesdefined applicable matter state (or distribution states) one findsoneself in|action choices defined every possible state history. Knowledgeinitial state determinism allow optimal straight-line plans constructed,loss value associated non-observability, unpredictable exogenousevents uncertain action effects cannot modeled consistently assumptions adopted.overview early classical planning research variety approachesadopted, see (Allen, Hendler, & Tate, 1990) well Yang's (1998) recent text.Optimal Deterministic Planning | separate body work retains classicalassumptions complete information determinism, tries recast planningproblem optimization relaxes implicit assumption \achieve goalcosts." time, methods use sort representationsalgorithms applied satisficing planning.Haddawy Hanks (1998) present multi-attribute utility model plannerskeeps explicit information initial state goals, allows preferences stated partial satisfaction goals well costresources consumed satisfying them. model also allows expression preferences phenomena like temporal deadlines maintenance intervalsdicult capture using time-separable additive value function. Williamson (1996)(see also Williamson & Hanks, 1994). implements model extending classical planning algorithm solve resulting optimization problem. HaddawySuwandi (1994) also implement model complete decision-theoretic framework.model planning, refinement planning, differs somewhat generativemodel discussed paper. model set possible plans pre-storedabstraction hierarchy, problem solver's job find hierarchyoptimal choice concrete actions particular problem.Perez Carbonell's (1994) work also incorporates cost information classicalplanning framework, maintains split classical satisficing planneradditional cost information provided utility model. cost informationused learn search-control rules allow classical planner generate low-costgoal-satisfying plans.22fiDecision-Theoretic Planning: Structural AssumptionsConditional Deterministic Planning | classical planning assumptionomniscience relaxed somewhat allowing state aspectsworld unknown. agent thus situation certainsystem one particular set states, know one. Unknowntruth values included initial state specification, taking actionscause proposition become unknown well.Actions provide agent information plan executed: conditional planners introduce idea actions providing runtime informationprevailing state, distinguishing action makes proposition P trueaction tell agent whether P true action executed.action causal informational effects, simultaneously changingworld reporting value one propositions. second sortinformation useful planning time except allows steps planexecuted conditionally, depending runtime information provided priorinformation-producing steps. value actions lies fact differentcourses action may appropriate different conditions|these informationaleffects allow runtime selection actions based observations produced, muchlike general POMDP model.Examples conditional planners classical framework include early workWarren (1976) recent CNLP (Peot & Smith, 1992), Cassandra (Pryor& Collins, 1993), Plynth (Goldman & Boddy, 1994), UWL (Etzioni, Hanks,Weld, Draper, Lesh, & Williamson, 1992) systems.Probabilistic Planning Without Feedback | direct probabilistic extensionclassical planning problem stated follows (Kushmerick et al., 1995):take input (a) probability distribution initial states, (b) stochastic actions(explicit implicit transition matrices), (c) set goal states, (d) probabilitysuccess threshold . objective produce plan reaches goal stateprobability least , given initial state distribution. provision madeexecution-time observation, thus straight-line plans form policypossible. restricted case infinite-horizon NOMDP problem, oneactions incur cost goal states offer positive reward absorbing.also special case objective find satisficing policy ratheroptimal one.Probabilistic Planning Feedback | Draper et al. (1994a) proposedextension probabilistic planning problem actions provide feedback,using exactly observation model described Section 2.4. Again, problemposed building plan leaves system goal state sucientprobability. plan longer simple sequence actions|it contain conditionals loops whose execution depends observations generated sensingactions. problem restricted case general POMDP problem: absorbing goal states cost-free actions used, objective find policy(conditional plan) leaves system goal state sucient probability.23fiBoutilier, Dean, & HanksComparing Frameworks: Task-oriented Versus Process-oriented Problemsuseful point pause contrast types problems considered classical planning literature typically studied within MDP framework. Althoughproblems AI planning literature emphasized goal-pursuit \one-shot" viewproblem solving, cases viewing problem infinite-horizon decision problemresults satisfying formulation. Consider running example involving ocerobot. simply possible model problem responding coffee requests, mailarrival keeping lab tidy strict goal-satisfaction problem capturingpossible nuances intuitively optimal behavior.primary diculty explicit persistent goal states exist.simply require robot attain state lab tidy, mail awaits,unfilled coffee requests exist, \successful" plan could anticipate possible system behaviorgoal state reached. possible occurrence exogenous events goalachievement requires robot bias methods achieving goals waybest suits expected course subsequent events. instance, coffee requestslikely point time unmet requests highly penalized, robotsituate coffee room order satisfy anticipated future request quickly.realistic decision scenarios involve task-oriented process-oriented behavior,problem formulations take account provide satisfying modelswider range situations.2.10.3 Complexity Policy Constructiondefined planning problem several different ways, differentset assumptions state space, system dynamics actions (deterministicstochastic), observability (full, partial, none), value function (time-separable, goal only,goal rewards action costs, partially satisfiable goals temporal deadlines), planninghorizon (finite, infinite, indefinite), optimality criterion (optimal satisficing solutions). set assumptions puts corresponding problem particular complexityclass, defines worst-case time space bounds representation algorithmsolving problem. summarize known complexity resultsproblem classes defined above.Fully Observable Markov Decision Processes Fully observable MDPs (FOMDPs)time-separable, additive value functions solved time polynomial sizestate space, number actions, size inputs.16 common algorithms solving FOMDPs value iteration policy iteration,described next section. finite-horizon discounted infinite-horizon problemsrequire polynomial amount computation per iteration|O(jS j2 jAj) O(jS j2 jAj+jS j3 ),respectively|and converge polynomial number iterations (with factor 1,1discounted case). hand, problems shown P-complete(Papadimitriou & Tsitsiklis, 1987), means ecient parallel solution algorithmunlikely.17 space required store policy n-stage finite-horizon problem16. precisely, maximum number bits required represent transition probabilitiescosts.17. See (Littman, Dean, & Kaelbling, 1995) summary complexity results.24fiDecision-Theoretic Planning: Structural AssumptionsO(jS jn). interesting classes infinite-horizon problems, specifically involving discounted models time-separable additive reward, optimal policyshown stationary, policy stored O(jS j) space.Bear mind worst-case bounds. many cases, better time boundscompact representations found. Sections 4 5 explore ways representsolve problems eciently.Partially Observable Markov Decision Processes POMDPs notoriouscomputational diculty. mentioned above, POMDP viewed FOMDPinfinite state space consisting probability distributions , distributionrepresenting agent's state belief point time (Astrom, 1965; Smallwood &Sondik, 1973). problem finding optimal policy POMDP objectivemaximizing expected total reward expected total discounted reward finitehorizon shown exponentially hard jS j (Papadimitriou& Tsitsiklis, 1987). problem finding policy maximizes approximatelymaximizes expected discounted total reward infinite horizon shownundecidable (Madani, Condon, & Hanks, 1999).Even restricted cases POMDP problem computationally dicult worstcase. Littman (1996) considers special case boolean rewards: determining whetherinfinite-horizon policy nonzero total reward given rewards associated states non-negative. shows problem EXPTIME-completetransitions stochastic, PSPACE-hard transitions deterministic.Deterministic Planning Recall classical planning problem defined quitedifferently MDP problems above: agent ability observe stateperfect predictive powers, knowing initial state effects actionscertainty. addition, rewards come reaching goal state, planachieves goal suces.Planning problems typically defined terms set P boolean featurespropositions: complete assignment truth values features describes exactly one state,partial assignment truth values describes set states. set propositions Pinduces state space size 2jPj. Thus, space required represent planning problemusing feature-based representation exponentially smaller requiredrepresentation problem (see Section 4).ability represent planning problems compactly dramatic impact worstcase complexity. Bylander (1994) shows deterministic planning problem withoutobservation PSPACE-complete. Roughly speaking, means worst planningtime increase exponentially P A, further, size solution plangrow exponentially problem size. results hold even actionspace severely restricted. example, planning problem NP-complete evencases action restricted one precondition feature one postconditionfeature. Conditional optimal planning PSPACE-complete well. resultsinputs generally compact (generally exponentially so)terms complexity FOMDP POMDP problems phrased.Probabilistic Planning probabilistic goal-oriented planning, POMDPs,typically search solution space probability distributions states (or25fiBoutilier, Dean, & Hanksformulas describe states). Even simplest problem probabilistic planning|oneadmits observability|is undecidable worst (Madani et al., 1999). intuitioneven though set states finite, set distributions states not,worst agent may search infinite number plans abledetermine whether solution exists. algorithm guaranteed findsolution plan eventually one exists, cannot guaranteed terminate finite timesolution plan. Conditional probabilistic planning generalizationnon-observable probabilistic planning problem, thus undecidable well.interesting note connection conditional probabilistic planningPOMDPs. actions observations two problems equivalent expressivepower, reward structure conditional probabilistic planning problem quiterestrictive: goal states positive rewards, states reward, goal statesabsorbing. Since cannot put priori bound length solution plan,conditional probabilistic planning must viewed infinite-horizon problemobjective maximize total expected undiscounted reward. Note, however, since goalstates absorbing, guarantee total expected reward non-negativebounded, even infinite horizon. Technically means conditional probabilistic planning problem restricted case infinite-horizon positive-bounded problem(Puterman, 1994, Section 7.2). therefore conclude problem solvingarbitrary infinite-horizon undiscounted positive-bounded POMDP also undecidable.commonly studied problem infinite-horizon POMDP criterion maximizing expected discounted total reward; finding optimal near-optimal solutionsproblem also undecidable, noted above.2.10.4 Conclusionend section noting results algorithm-independent describe worst-case behavior. effect, indicate badly algorithm madeperform \arbitrarily unfortunate" problem instance. interesting questionwhether build representations, techniques, algorithms typically performwell problem instances typically arise practice. concern leads us examineproblem characteristics eye toward exploiting restrictions placedstates actions, observability, value function optimality criterion.begin algorithmic techniques focus value function|particularlytake advantage time-separability goal orientation. following sectionexplore complementary techniques building compact problem representations.3. Solution Algorithms: Dynamic Programming Searchsection review standard algorithms solving problems describedterms \unstructured" \ at" problem representations. noted analysisabove, fully observable Markov decision processes (FOMDPs) far widelystudied models general class stochastic sequential decision problems. begindescribing techniques solving FOMDPs, focusing techniques exploit structurevalue function like time-separability additivity.26fiDecision-Theoretic Planning: Structural Assumptions3.1 Dynamic Programming ApproachesSuppose given fully-observable MDP time-separable, additive value function.words, given state space , action space A, transition matrix Pr(s0 js; a)action a, reward function R, cost function C . start problemfinding policy maximizes expected total reward fixed, finite-horizon .Suppose given policy (s; t) action performed agentstate stages remaining act (for 0 ).18 Bellman (1957) showsexpected value policy state computed using set t-stage-to-govalue functions Vt . define V0 (s) R(s), define:Vt (s) = R(s) + C ((s; t)) +X2S0fPr(s0j(s; t); s)Vt,1 (s0)g(1)definition value function makes its0 dependence initial state clear.say policy optimal VT (s) VT (s) policies 0 2 .optimal -stage-to-go value function, denoted VT , simply value functionoptimal -horizon policy. Bellman's principle optimality (Bellman, 1957) forms basisstochastic dynamic programming algorithms used solve MDPs, establishingfollowing relationship optimal value function tth stage optimal valuefunction previous stage:Vt (s) = R(s) + maxfC (a) +a2AXs0 2SPr(s0 ja; s)Vt,1 (s0 )g(2)3.1.1 Value IterationEquation 2 forms basis value iteration algorithm finite-horizon problems.Value iteration begins value function V0 = R, uses Equation 2 computesequence value functions longer time intervals, horizon . actionmaximizes right-hand side Equation 2 chosen policy element (s; t).resulting policy optimal -stage, fully observable MDP, indeedshorter horizon < .important note policy describes done every stageevery state system, even agent cannot reach certain states given system'sinitial configuration available actions. return point below.Example 3.1 Consider simplified version robot example, fourstate variables , CR, RHC, RHM (movement various locations ignored),four actions GetC, PUM, DelC, DelM. Actions GetC PUM make RHCRHM, respectively, true certainty. Action DelM, RHM holds, makesRHM false probability 1.0; DelC makes CR RHC falseprobability 0.3, leaving state unchanged probability 0.7. reward 3associated CR reward 1 associated . reward statesum rewards objective satisfied state. Figure 11 showsoptimal 0-stage, 1-stage 2-stage value functions various states, along18. Recall FOMDPs aspects history relevant.27fiBoutilier, Dean, & HanksStates0 = hM; RHM; CR; RHCis1 = hM; RHM; CR; RHCis2 = hM; RHM; CR; RHCis3 = hM; RHM; CR; RHCis4 = hM; CR; RHCis5 = hM; CR; RHCis6 = hM; RHM; CRis7 = hM; RHM; CRis8 = hM; CRiV0000011334V1010.912.92768(1)(2)1 PUMDelM 2 DelMDelC 2.43 DelCDelM 2.9 DelMDelC 5.43 DelC3.9 GetCDelM 11 DelM10 PUM12V2Figure 11: Finite-horizon optimal value policy.optimal choice action state-stage pairing (the values \state"missing variables hold instantiations variables). Note V0 (s)simply R(s) state s.illustrate application Equation 2, first consider calculation V1 (s3 ).robot choice delivering coffee delivering mail, expected valueoption, one stage remaining, given by:EV1 (s3; DelC) = 0:3V0(s6) + 0:7V0 (s3) = 0:9EV1(s3; DelM) =1:0V0 (s4 )= 1:0Thus (s3 ; 1) = DelM V1 (s3 ) value maximizing choice. Noticerobot one action perform aim \lesser" objective duerisk failure inherent delivering coffee. two stages remainingstate, robot deliver mail, certainty move s4 onestage go, attempt deliver coffee ( (s4 ; 1) = DelC).illustrate effects fixed finite horizon policy choice, note(s0; 2) = PUM. two stages remaining choice getting mail coffee,robot get mail subsequent delivery (in last stage) guaranteedsucceed, whereas subsequent coffee delivery may fail. However, compute(s0; 3), see:EV3(s0 ; GetC) = 1:0V2(s2 ) = 2:43EV3 (s0; PUM) = 1:0V2(s1 ) = 2:0three stages go, robot instead retrieve coffee s0 .coffee, two chances successful delivery. expected value courseaction greater (guaranteed) mail delivery. Note three stagesallow sucient time try achieve objectives s0 . fact,larger reward associated coffee delivery ensures greater numberstages remaining, robot focus first coffee retrieval delivery,attempt mail retrieval delivery coffee delivery successfully completed. 2Often faced tasks fixed finite horizon. example,may want robot perform tasks keeping lab tidy, picking mail whenever28fiDecision-Theoretic Planning: Structural Assumptionsarrives, responding coffee requests, on. fixed time horizon associatedtasks|they performed need arises. problems bestmodeled infinite-horizon problems.consider problem building policy maximizes discounted sumexpected rewards infinite horizon.19 Howard (1960) showed alwaysexists optimal stationary policy problems. Intuitively, casematter stage process in, still infinite number stages remaining;optimal action state independent stage. therefore restrictattention policies choose action state regardless stageprocess. restriction, policy size jSj regardlessnumber stages policy executed|the policy form : ! A.contrast, optimal policies finite-horizon problems generally nonstationary,illustrated Example 3.1.Howard also shows value policy satisfies following recurrence:V (s) = R(s) + fC ((s)) +Xs0 2Soptimal value function V satisfies:V (s) = R(s) + maxfC (a) +a2APr(s0 j(s); s)V (s0 )gX2S0Pr(s0 ja; s)V (s0 )g(3)(4)value fixed policy evaluated using method successive approximation, almost identical procedure described Equation 1 above. beginarbitrary assignment values V0 (s), define:Vt (s) = R(s) + C ((s; t)) +X2S0fPr(s0j(s; t); s)Vt,1 (s0)g(5)sequence functions Vt converges linearly true value function V .One also alter value-iteration algorithm slightly builds optimal policiesinfinite-horizon discounted problems. algorithm starts value function V0assigns arbitrary value 2 . Given value estimate Vt (s) state s, Vt+1 (s)calculated as:Vt+1 (s) = R(s) + maxfC (a) +a2AXs0 2SPr(s0 ja; s) Vt (s0 )g(6)sequence functions Vt converges linearly optimal value function V (s).finite number iterations n, choice maximizing action formsoptimal policy Vn approximates value.2019. far commonly studied problem literature, though argued (Boutilier &Puterman, 1995; Mahadevan, 1994; Schwartz, 1993) problems often best modeled usingaverage reward per stage optimality criterion. discussion average reward optimalitymany variants refinements, see (Puterman, 1994).20. number iterations n based stopping criterion generally involves measuring difference Vt Vt+1 . discussion stopping criteria convergence algorithm, see(Puterman, 1994).29fiBoutilier, Dean, & Hanks3.1.2 Policy IterationHoward's (1960) policy-iteration algorithm alternative value iteration infinitehorizon problems. Rather iteratively improving estimated value function, insteadmodifies policies directly. begins arbitrary policy 0 , iterates, computingi+1 i.iteration algorithm comprises two steps, policy evaluation policy improvement:1. (Policy evaluation) 2 , compute value function V (s) basedcurrent policy .2. (Policy improvement) 2 , find action maximizesQi+1(a; s) = R(s) + C (a) +Xs0 2SPr(s0 ja; s) V (s0 )(7)Qi+1 (a ; s) > V (s), let i+1 = ; otherwise i+1 (s) = (s).21algorithm iterates i+1 (s) = (s) states s. Step 1 evaluates currentpolicy solving N N linear system represented Equation 3 (one equation2 ), computationally expensive. However, algorithm convergesoptimal policy least linearly certain conditions converges superlinearlyquadratically (Puterman, 1994). practice, policy iteration tends converge manyfewer iterations value iteration. Policy iteration thus spends computationaltime individual stage, result fewer stages need computed.22Modified policy iteration (Puterman & Shin, 1978) provides middle groundpolicy iteration value iteration. structure algorithm exactlypolicy iteration, alternating evaluation improvement phases. key insightone need evaluate policy exactly order improve it. Therefore, evaluationphase involves (usually small) number iterations successive approximation (i.e.,setting V = Vt small t, using Equation 6). tuning valueused iteration, modified policy iteration work extremely well practice(Puterman, 1994). value iteration policy iteration special cases modifiedpolicy iteration, corresponding setting = 0 = 1, respectively.number variants value policy iteration proposed.instance, asynchronous versions algorithms require value functionconstructed, policy improved, state lockstep. case value iterationinfinite-horizon problems, long state updated suciently often, convergenceassured. Similar guarantees provided asynchronous forms policy iteration. variants important tools understanding various online approachessolving MDPs (Bertsekas & Tsitsiklis, 1996). nice discussion asynchronous dynamicprogramming, see (Bertsekas, 1987; Bertsekas & Tsitsiklis, 1996).21. Q-function defined Equation 7, called use Q-learning (Watkins & Dayan,1992), gives value performing action state assuming value function V accurately ectsfuture value.22. See (Littman et al., 1995) discussion complexity algorithm.30fiDecision-Theoretic Planning: Structural Assumptions3.1.3 Undiscounted Infinite-Horizon Problemsdiculty finding optimal solutions infinite-horizon problems total rewardgrow without limit time. Thus, problem definition must provide wayensure value metric bounded arbitrarily long horizons. use expectedtotal discounted reward optimality criterion offers particularly elegant wayguarantee bound, since infinite sum discounted rewards finite. However, althoughdiscounting appropriate certain classes problems (e.g., economic problems,system may terminate point certain probability), many realisticAI domains dicult justify counting future rewards less present rewards,discounted-reward criterion appropriate.variety ways bound total reward undiscounted problems.cases problem structured reward bounded. planning problems,example, goal reward collected once, actions incur cost.case total reward bounded problem legitimately posedterms maximizing total expected undiscounted reward many cases (e.g., goalreached certainty).cases discounting inappropriate total reward unbounded, differentsuccess criteria employed. example, problem instead posed onewish maximize expected average reward per stage, gain. Computationaltechniques constructing gain-optimal policies similar dynamic-programmingalgorithms described above, generally complicated, convergence ratetends quite sensitive communicating structure periodicity MDP.Refinements gain optimality also studied. example, bias optimalityused distinguish two gain-optimal polices giving preference policy whose totalreward initial segment policy execution larger. Again, algorithmscomplicated discounted problems, variants standardpolicy value iteration. See (Puterman, 1994) details.3.1.4 Dynamic Programming POMDPsDynamic programming techniques applied partially observable settings well(Smallwood & Sondik, 1973). main diculty building policies situationsstate fully observable that, since past observations provide informationsystem's current state, decisions must based information gleanedpast. result, optimal policy depend observations agent made sincebeginning execution. history-dependent policies grow size exponentiallength horizon. history-dependence precludes dynamic programming,observable history summarized adequately probability distribution(Astrom, 1965), policies computed function distributions, beliefstates.key observation Sondik (Smallwood & Sondik, 1973; Sondik, 1978)one views POMDP time-separable value function taking state spaceset probability distributions , one obtains fully observable MDPsolved dynamic programming. (computational) problem approach31fiBoutilier, Dean, & Hanksstate space FOMDP N -dimensional continuous space,23 specialtechniques must used solve (Smallwood & Sondik, 1973; Sondik, 1978).explore techniques here, note currently practicalsmall problems (Cassandra et al., 1994; Cassandra, Littman, & Zhang, 1997;Littman, 1996; Lovejoy, 1991b). number approximation methods, developed(Lovejoy, 1991a; White III & Scherer, 1989) AI (Brafman, 1997; Hauskrecht, 1997;Parr & Russell, 1995; Zhang & Liu, 1997), used increase range solvableproblems, even techniques presently limited practical value.POMDPs play key role reinforcement learning well, \natural statespace" consisting agent observations provides incomplete information underlying system state (see, e.g., McCallum, 1995).3.2 AI Planning State-Based Searchnoted Section 2.7 classical AI planning problem formulatedinfinite-horizon MDP therefore solved using algorithm like value iteration.Recall two assumptions classical planning specialize general MDP model, namelydeterminism actions use goal states instead general reward function.third assumption|that want construct optimal course action startingknown initial state|does counterpart FOMDP model presented above,since policy dictates optimal action state stage plan.see below, interest online algorithms within AI led revised formulationsFOMDPs take initial current states account.Though defined classical planning problem earlier non-observable process(NOMDP), solved fully observable. let G set goal statessinit initial state. Applying value iteration type problem equivalentdetermining reachability goal states system states. instance,make goal states absorbing, assign reward 1 transitions 2 , Gg 2 G 0 others, set states Vk (s) > 0 exactlyset states lead goal state.24 particular, Vk (sinit ) > 0,successful plan constructed extracting actions k-stage (finite-horizon)policy produced value iteration. determinism assumption means agentpredict state perfectly every stage execution; fact cannot observestate unimportant.assumptions commonly made classical planning exploited computationally value iteration. First, terminate process first iteration kVk (sinit) > 0, interested plans begin sinit, actingoptimally every possible start state. Second, terminate value iteration jS jiterations: VjS j(sinit ) = 0 point, algorithm searched every possiblestate guarantee solution plan exists. Therefore, view classical planning finite-horizon decision problem horizon jS j. use value iteration23. accurately, N -dimensional simplex, (N , 1)-dimensional space.24. Specifically, Vk (s) indicates probability one reaches goal region optimalpolicy 2 , G stochastic settings. deterministic case discussed, value must1 0.32fiDecision-Theoretic Planning: Structural Assumptionsequivalent using Floyd-Warshall algorithm find minimum-cost pathweighted graph (Floyd, 1962).3.2.1 Planning Searchvalue iteration can, theory, used classical planning, take advantagefact goal initial states known. particular, computes valuepolicy assignment states stages. wasteful since optimalactions computed states cannot reached sinit cannot possiblylead state g 2 G. also problematic jS j large, since iterationvalue iteration requires O(jS jjAj) computations. reason dynamic programmingapproaches used extensively AI planning.restricted form value function, especially fact initial goal statesgiven, makes advantageous view planning graph-search problem. Unlikegeneral FOMDPs, generally known priori states desirablerespect (long-term) value, well-defined set target states classical planningproblem makes search-based algorithms appropriate. approach takenAI planning algorithms.One way formulate problem graph search make node graphcorrespond state . initial state goal states identified,search proceed either forward backward graph, directionssimultaneously.forward search, initial state root search tree. node chosentree's fringe (the set leaf nodes), feasible actions applied.action application extends plan one step (or one stage) generates unique newsuccessor state, new leaf node tree. node pruned statedefines already tree. search ends state identified membergoal set (in case solution plan extracted tree), branchespruned (in case solution plan exists). Forward search attempts buildplan beginning end, adding actions end current sequence actions.Forward search never considers states cannot reached sinit .Backward search viewed several different ways. could arbitrarily selectg 2 G root search tree, expand search tree fringeselecting state fringe adding tree states action wouldcause system enter chosen state. general, action give riseone predecessor vertex, even actions deterministic. state prunedappears search tree already. search terminates initial state addedtree, solution plan extracted tree. search similardynamic-programming-based algorithms finding shortest path graph.difference backward search considers states depth k searchtree reach chosen goal state within k steps. Dynamic programming algorithms,contrast, visit every state every stage search.One diculty backward approach described commitmentparticular goal state. course, assumption relaxed, algorithm could\simultaneously" search paths goal states adding first level search33fiBoutilier, Dean, & Hankstree vertex reach g 2 G. see Section 5 goal regressionviewed this, least implicitly.generally thought regression (or backward) techniques effectivepractice progression (or forward) methods. reasoning branching factorforward graph, number actions feasibly applied givenstate, substantially larger branching factor reverse graph,number operators could bring system given state.25 especially truegoal sets represented small set propositional literals (Section 5). twoapproaches mutually exclusive, however: one mix forward backward expansions underlying problem graph terminate forward path backwardpath meet.important thing observe algorithms restrict attention relevant reachable states. forward search, statesreached sinit ever considered: provide benefit dynamic programmingmethods states reachable, since unreachable states cannot play role constructing successful plan. backward approaches, similarly, states lying pathgoal region G considered, significant advantages dynamicprogramming fraction state space connected goal region.contrast, dynamic programming methods (with exception asynchronous methods) must examine entire state space every iteration. course, ability ignoreparts state space comes planning's stringent definition relevant: statesG positive reward, states matter except extent move agentcloser goal, choice action states unreachable sinit interest.state-based search techniques use knowledge specific initial state specificgoal set constrain search process, forward search exploit knowledgegoal set, backward search exploit knowledge initial state. GraphPlanalgorithm (Blum & Furst, 1995) viewed planning method integratespropagation forward reachability constraints backward goal-informed search.describe approach Section 5. Furthermore, work partial order planning (POP)viewed slightly different approach form search. describedSection 5, discuss feature-based intensional representations MDPsplanning problems.3.2.2 Decision Trees Real-time Dynamic ProgrammingState-based search techniques limited deterministic, goal-oriented domains. Knowledge initial state exploited general MDPs well, forming basisdecision tree search algorithms. Assume given finite-horizon FOMDPhorizon initial state sinit . decision tree rooted sinit constructed muchway search tree deterministic planning problem (French, 1986). actionapplicable sinit forms level 1 tree. states s0 result positive probability actions occur applied sinit placed level 2, arc25. See Bacchus et al. (1995, 1998) recent work makes case progression goodsearch control, Bonet et al. (1997) argue progression deterministic planning usefulintegrating planning execution.34fiDecision-Theoretic Planning: Structural AssumptionsinitV = max(V1 , V2 )a1p1a2p2s1a1p3s2a2a1V1p4s3a2a1V2 = p V 3 + p V434s4a2a1a2V3V4Figure 12: initial stages decision tree evaluating action choices sinit .value action expected value successor states, valuestate maximum values successor actions (as indicateddashed arrows selected nodes).labeled probability Pr(s0 ja; sinit ) relating s0 a. Level 3 actions applicablestates level 2, on, tree grown depth 2T , pointbranch tree path consisting positive-probability length-T trajectory rootedsinit (see Figure 12).relevant part optimal -stage value function optimal policy easilycomputed using tree. say value node tree labeledaction expected value successor states tree (using probabilities labelingarcs), value node tree labeled state sum R(s)maximum value successor actions.26 rollback procedure, whereby valueleaves tree first computed values successively higher levels treedetermined using preceding values, is, fact, form value iteration. valuestate level 2t precisely VT,t (s) maximizing actions form optimalfinite-horizon policy. form value iteration directed: (T , t)-stage-to-go valuescomputed states reachable sinit within steps. Infinite-horizonproblems solved analogous fashion one determine priori depthrequired (i.e., number iterations value iteration needed) ensure convergenceoptimal policy.Unfortunately, branching factor stochastic problems generally much greaterdeterministic problems. troublesome still fact one mustconstruct entire decision tree sure proper values computed, henceoptimal policy constructed. stands contrast classical planning search,attention focused single branch: goal state reached, pathconstructed determines satisfactory plan. worst-case behavior planning mayrequire searching whole tree, decision-tree evaluation especially problematic26. States level 2T given value R(s).35fiBoutilier, Dean, & Hanksentire tree must generated general ensure optimal behavior. Furthermore,infinite-horizon problems pose diculty determining suciently deep tree.One way around diculty use real time search (Korf, 1990). particular,real-time dynamic programming, RTDP, proposed (Barto et al., 1995)way approximately solving large MDPs online fashion. One interleave searchexecution approximately optimal policy using form RTDP similar decisiontree evaluation follows. Imagine agent finds particular state sinit .build partial search tree depth, perhaps uniformly perhapsbranches expanded deeply others. Partial tree construction may halted duetime pressure due assessment agent expansion tree mayfruitful. decision act must made, rollback procedure appliedpartial, possibly unevenly expanded decision tree.Reward values used evaluate leaves tree, may offerinaccurate picture value nodes higher tree. Heuristic informationused estimate long-term value states labeling leaves. value iteration,deeper tree, accurate estimated value root (generally speaking)fixed heuristic. see Section 5 structured representations MDPsprovide means construct heuristics (Dearden & Boutilier, 1994, 1997). Specifically,admissible heuristics upper lower bounds true values leaf nodestree, methods A* branch-and-bound search used.key advantage integrating search execution actual outcomeaction taken used prune tree branches rooted unrealizedoutcomes. subtree rooted realized state expanded makenext action choice. algorithm Hansen Zilberstein (1998) viewedvariant methods stationary policies (i.e., state-action mappings)extracted search process.RTDP formulated Barto et al. (1995) generally form online, asynchronous value iteration. Specifically, values \rolled backed" cached usedimproved heuristic estimates value function states question. technique also investigated (Bonet et al., 1997; Dearden & Boutilier, 1994, 1997; Koenig& Simmons, 1995), closely tied Korf's (1990) LRTA* algorithm. valueupdates also need proceed strictly using decision tree determine states; keyrequirement RTDP simply actual state sinit one states whose valueupdated decision-action iteration.second way avoid computational diculties arise large searchspaces use sampling methods. methods sample space possible trajectories use sampled information provide estimates values specific coursesaction. approach quite common reinforcement learning (Sutton & Barto, 1998),simulation models often used generate experience value functionlearned. present context, Kearns, Mansour Ng (Kearns, Mansour, &Ng, 1999) investigated search methods infinite-horizon MDPs successorstates specific action randomly sampled according transition distribution.Thus, rather expand successor states, sampled states searched. Thoughmethod exponential \effective" horizon (or mixing rate) MDPrequired expand actions, number states expanded less required36fiDecision-Theoretic Planning: Structural Assumptionsfull search, even underlying transition graph sparse. able provide polynomial bounds (ignoring action branching horizon effects) numbertrajectories need sampled order generate approximately optimal behaviorhigh probability.3.3 Summaryseen dynamic programming methods state-based search methodsused fully observable non-observable MDPs, forward search methods interpretable \directed" forms value iteration. Dynamic programming algorithmsgenerally require explicit enumeration state space iteration, searchtechniques enumerate reachable states; branching factor may require that,sucient depth search tree, search methods enumerate individual states multipletimes, whereas considered per stage dynamic programming. Overcoming diculty search requires use cycle-checking multiple-path-checkingmethods.note search techniques applied partially observable problems well.One way search space belief states (just dynamic programming applied belief space MDP|see Section 2.10.2). Specifically, beliefstates play role system states stochastic effects actions belief statesinduced specific observation probabilities, since observation distinct, fixedeffect belief state. type approach pursued (Bonet & Geffner,1998; Koenig & Simmons, 1995).4. Factored Representationspoint discussion MDPs used explicit extensional representationset states (and actions) states enumerated directly. many casesadvantageous, representational computational point view, talkproperties states sets states: set possible initial states, setstates action executed, on. generally convenientcompact describe sets states based certain properties features enumerateexplicitly. Representations descriptions objects substitute objectscalled intensional technique choice AI systems.intensional representation planning systems often built defining setfeatures sucient describe state dynamic system interest.example Figure 2, state described set six features: robot's location,lab's tidiness, whether mail present, whether robot mail, whetherpending coffee request, whether robot coffee. firstsecond features take one five values, last four take one twovalues (true false). assignment values six features completely defines state;state space thus comprises possible combinations feature values, jSj = 400.feature, factor, typically assigned unique symbolic name, indicatedsecond column Figure 2. fundamental tradeoff extensional intensionalrepresentations becomes clear example. extensional representation coffeeexample views space possible states single variable takes 400 possible37fiBoutilier, Dean, & Hanksvalues, whereas intensional factored representation views state cross productsix variables, takes substantially fewer values. Generally, state spacegrows exponentially number features required describe system.fact state system described using set features allows oneadopt factored representations actions, rewards components MDP.factored action representation, instance, one generally describes effect actionspecific state features rather entire states. often provides considerable representational economy. instance, Strips action representation (Fikes & Nilsson,1971), state transitions induced actions represented implicitly describingeffects actions features change value action executed.Factored representations compact individual actions affect relativelyfeatures, effects exhibit certain regularities. Similar remarks applyrepresentation reward functions, observation models, on. regularitiesmake factored representations suitable many planning problems often exploitedplanning decision-making algorithms.factored representations long used classical AI planning, similarrepresentations also adopted recent use MDP models within AI.section (Section 4), focus economy representation afforded exploitingstructure inherent many planning domains. following section (Section 5),describe structure|when made explicit factored representations|canexploited computationally plan policy construction.4.1 Factored State Spaces Markov Chainsbegin examining structured states, systems whose state described usingfinite set state variables whose values change time.27 simplify illustrationpotential space savings, assume state variables boolean.variables, size state space jSj = N = 2M . large , specifyingrepresenting dynamics explicitly using state-transition diagrams N N matricesimpractical. Furthermore, representing reward function N -vector, specifyingobservational probabilities, similarly infeasible. Section 4.2, define classproblems dynamics represented O(M ) space many cases. beginconsidering represent Markov chains compactly consider incorporatingactions, observations rewards.let state variable X take finite number values letX standset possible values. assumeX finite, though much followsapplied countable state action spaces well. say state spacespecified using one state variable (this variable denoted general model, takingvalues ). state space factored one state variable. statepossible assignment values variables. Letting Xi represent ith statevariable, state space cross product value spaces individual statevariables; is, =i=1Xi . denotes state process stage t,let Xit random variable representing value ith state variable stage t.27. variables often called uents AI literature (McCarthy & Hayes, 1969). classicalplanning, atomic propositions used describe domain.38fiDecision-Theoretic Planning: Structural AssumptionsBayesian network (Pearl, 1988) representational framework compactly representing probability distribution factored form. Although networks typically used represent atemporal problem domains, apply techniquesrepresent Markov chains, encoding chain's transition probabilities networkstructure (Dean & Kanazawa, 1989).Formally, Bayes net directed acyclic graph vertices correspond randomvariables edge two variables indicates direct probabilistic dependencythem. network constructed also ects implicit independencies amongvariables. network must quantified specifying probability variable(vertex) conditioned possible values immediate parents graph. addition,network must include marginal distribution: unconditional probabilityvertex parents. quantification captured associating conditionalprobability table (CPT) variable network. Together independenceassumptions defined graph, quantification defines unique joint distributionvariables network. probability event spacecomputed using algorithms exploit independencies represented within graphicalstructure. refer Pearl (1988) details.Figures 3(a)-(c) (page 7) special cases Bayes nets called \temporal" Bayesiannetworks. networks, vertices graph represent system's state differenttime points arcs represent dependencies across time points. temporal networks,vertex's parent temporal predecessor, conditional distributions transitionprobability distributions, marginal distributions distributions initial states.networks Figure 3 ect extensional representation scheme statesexplicitly enumerated, techniques building performing inference probabilistic temporal networks designed especially application factored representations.Figure 13 illustrates two-stage temporal Bayes net (2TBN) describing state-transitionprobabilities associated Markov chain induced fixed policy executingaction CClk (repeatedly moving counterclockwise). 2TBN, set variablespartitioned corresponding state variables given time (or stage)corresponding state variables time + 1. Directed arcs indicate probabilistic dependencies variables Markov chain. Diachronic arcs directedtime variables time + 1 variables, synchronic arcs directedvariables time + 1. Figure 13 contains diachronic arcs; synchronic arcsdiscussed later section.Given state time t, network induces unique distribution states +1.quantification network describes state particular variable changesfunction certain state variables. lack direct arc (or generally directedpath synchronic arcs among + 1 variables) variable Xt anothervariable Yt+1 means knowledge Xt irrelevant prediction (immediate,one-stage) evolution variable Markov process.Figure 13 shows compact representation best circumstances,many potential links one stage next omitted. graphicalrepresentation makes explicit fact policy (i.e., action CClk) affectstate variable Loc, exogenous events ArrM, ReqC, Mess affect39fiBoutilier, Dean, & HanksLocLocCRCRP(Loc t+1 )Loc L C H0.1 0.9 0 0 00 0.1 0.9 0 0L0 0 0.1 0.9 0C0 0 0 0.1 0.9H 0.9 0 0 0 0.1P(CR t+1)CRfRHCf1.0 00.2 0.8RHCRHMRHMTimeTime t+1P(RHC t+1)RHC f1.0 0f0 1.0Figure 13: factored 2TBN Markov chain induced moving counterclockwise(with selected CPTs shown).variables , CR, Tidy, respectively.28 Furthermore, dynamics Loc (andvariables) described using knowledge state parentvariables; instance, distribution Loc +1 depends value Locprevious stage (e.g., Loct = O, Loct+1 = probability 0:9 Loct+1 =probability 0:1). Similarly, CR become true probability 0:2 (due ReqCevent), true, cannot become false (under simple policy); RHC remainstrue (or false) certainty true (or false) previous stage. Finally,effects relevant variables independent. instantiation variablestime t, distribution next states computed multiplying conditionalprobabilities relevant + 1 variables.ability omit arcs graph based locality independence actioneffects strong effect number parameters must supplied completemodel. Although full transition matrix CClk would size 4002 = 160000,transition model Figure 13 requires 66 parameters.29example shows 2TBNs exploit independence represent Markov chainscompactly, example extreme effectively relationshipvariables|the chain viewed product six independently evolving processes.28. show CPTs brevity.29. fact, exploit fact probabilities sum one leave one entry unspecified per rowCPT explicit transition matrix. case, 2TBN requires 48 explicit parameters,transition matrix requires 400 300 = 159; 600 entries. generally ignore fact comparingsizes representations.40fiDecision-Theoretic Planning: Structural AssumptionsLocLocCRCRRHCRHCRHMRHMTimeTime t+1Loc RHCLCHfLfCffHfP(Loc t+1 )L C H1.0 0 0 0 00 0.1 0.9 0 00 0 0.1 0.9 00 0 0 0.1 0.90.9 0 0 0 0.10.1 0.9 0 0 00 0.1 0.9 0 00 0 0.1 0.9 00 0 0 0.1 0.9P(CR t+1)0.9 0 0 0 0.1Loc RHC CR fP(RHC t+1)Loc RHCf0.0 1.0f 0.0 1.01.0 0.0Lf 0.0 1.0L1.0 0.0Cf 0.0 1.0Cetc.etc.LLLLffffetc.ffff.05 .950.2 0.81.0 0.00.2 0.81.0 0.00.2 0.81.0 0.00.2 0.8etc.Figure 14: 2TBN Markov chain induced moving counterclockwise delivering coffee.41fiBoutilier, Dean, & Hanksgeneral, \subprocesses" interact, still exhibit certain independenciesregularities exploited 2TBN representation. consider two distinctMarkov chains exhibit different types dependencies.Figure 14 illustrates 2TBN representing Markov chain induced followingpolicy: robot consistently moves counterclockwise unless ocecoffee, case delivers coffee user. Notice different variablesdependent: instance, predicting value RHC + 1 requires knowing valuesLoc RHC t. CPT RHC shows robot retains coffee stage + 1certainty, stage t, locations except (where executes DelC,thus losing coffee). variable Loc also depends value RHC. locationchange Figure 13 one exception: robot oce coffee,location remains (since robot move, executes DelC). effectvariable CR explained follows: robot oce delivers coffeepossession, fulfill outstanding coffee request. However, 0:05 chance CRremaining true conditions indicates 5% chance spilling coffee.Even though dependencies (i.e., additional diachronic arcs) 2TBN,still requires 118 parameters. Again, distribution resulting states determined multiplying conditional distributions individual variables. Even thoughvariables \related," state known, variables time + 1 (Loct+1 ,RHCt+1 , etc.) independent. words,Pr(Loct+1 ; t+1 ; CRt+1 ; RHCt+1 ; RHMt+1 ; t+1 jS ) =t)Pr(Loct+1 jS ) Pr(T t+1 jS ) Pr(CRt+1 jS ) Pr(RHCt+1 jS ) Pr(RHMt+1 jS ) Pr(M t+1 jS(8)Figure 15 illustrates 2TBN representing Markov chain induced policyabove, assume act moving counterclockwise slightlydifferent effect. suppose that, robot moves hallwayadjacent location, 0:3 chance spilling coffee possession:fragment CPT RHC Figure 15 illustrates possibility. Furthermore,robot carrying mail whenever loses coffee (whether \accidentally" \intentionally"via DelC action), 0:5 chance lose mail. Notice effectspolicy variables RHC RHM correlated: one cannot accurately predictprobability RHMt+1 without determining probability RHCt+1 . correlationmodeled synchronic arc RHC RHM + 1 slice network.independence +1 variables given hold 2TBNs synchronicarcs. Determining probability resulting state requires simple probabilisticreasoning, example, application chain rule. example, writePr(RHCt+1 ; RHMt+1 jS ) = Pr(RHMt+1 jRHCt+1 ; ) Pr(RHCt+1 jS )joint distribution + 1 variables given computed Equation 8 above, term replacing Pr(RHCt+1 jS ) Pr(RHMt+1 jS )|while twovariables correlated, remaining variables independent.refer 2TBNs synchronic arcs, like one Figure 14, simple 2TBNs.General 2TBNs allow synchronic well diachronic arcs, Figure 15.42fiDecision-Theoretic Planning: Structural AssumptionsLocLocCRCRRHCRHCRHMRHMTimeTime t+1Pr(RHC t+1 )Loc RHC f1.0 1.0f 0.0 1.00.7 0.3Hf 0.0 1.0H1.0 0.0Cf 0.0 1.0Cetc.etc.Pr(RHMt+1 )RHC RHC t+1 RHMt f1.0 0.00.0 1.0f0.5 0.5f0.0 1.0ff1.0 0.0f0.0 1.0ff1.0 0.0ff0.0 1.0fffFigure 15: 2TBN Markov chain induced moving counterclockwise delivering coffee correlated effects.4.2 Factored Action Representationsextended Markov chains account different actions, must extend2TBN representation account fact state transitions uencedagent's choice action. discuss variety techniques specifying transitionmatrices exploit factored state representation produce representationsnatural compact explicit transition matrices.4.2.1 Implicit-Event Modelsbegin implicit-event model Section 2.3 effects actionsexogenous events combined single transition matrix. consider explicitevent models Section 4.2.4. saw previous section, algorithms valuepolicy iteration require use transition models ect ultimate transitionprobabilities, including effects exogenous events.One way model dynamics fully observable MDP represent actionseparate 2TBN. 2TBN shown Figure 13 seen representationaction CClk (since policy inducing Markov chain example consistsrepeated application action alone). network fragment Figure 16(a)illustrates interesting aspects 2TBN DelC action including effectsexogenous events. above, robot satisfies outstanding coffee request deliverscoffee oce coffee (with 0:05 chance spillage), shownconditional probability table CR. effect RHC explained follows:43fiBoutilier, Dean, & HanksLocRHCCRTimeLocRHCCRTime t+1(a)Pr(RHC t+1 )Loc RHC f0.0 1.0f 0.0 1.0L0.3 0.7f 0.0 1.0L0.3 0.7Cf 0.0 1.0Cetc.etc.Pr(CR t+1 )Loc RHC CR f.05 .95f 0.2 0.81.0 0.0ff 0.2 0.8f1.0 0.0Lf 0.2 0.8L1.0 0.0fLf 0.2 0.8fLetc.etc.CR0.05RHCLocelseffCR0.2 1.0CR1.0ff0.20.2(b)CR0.05RHCfLocelseff0.2CR1.0(c)Figure 16: factored 2TBN action DelC (a) structured CPT representations (b,c).robot loses coffee (to user spillage) delivers oce; attemptsdelivery elsewhere, 0:7 chance random passerby take coffeerobot.case Markov chains, effects actions different variablescorrelated, case must introduce synchronic arcs. correlationsthought ramifications (Baker, 1991; Finger, 1986; Lin & Reiter, 1994).4.2.2 Structured CPTsconditional probability table (CPT) node CR Figure 16(a) 20 rows, oneassignment parents. However, CPT contains number regularities.Intuitively, ects fact coffee request met successfully (i.e.,variable becomes false) 95% time DelC executed, robot coffeeright location (the user's oce). Otherwise, CR remains true truebecomes true probability 0:2 not. words, three distinct casesconsidered, corresponding three \rules" governing (stochastic) effect DelCCR. represented compactly using decision tree representation(with \else" branches summarize groups cases involving multivalued variablesLoc) like shown Figure 16(b), compactly still using decision graph(Figure 16(c)). tree- graph-based representations CPTs, interior nodes labeledparent variables, edges values variables, leaves terminals distributionschild variable's values.30Decision-tree decision-graph representations used represent actions fullyobservable MDPs (Boutilier et al., 1995; Hoey, St-Aubin, Hu, & Boutilier, 1999)30. child boolean, label leaves probability variable true (theprobability variable false one minus value).44fiDecision-Theoretic Planning: Structural Assumptionsdescribed detail (Poole, 1995; Boutilier & Goldszmidt, 1996).31 Intuitively, treesgraphs embody rule-like structure present family conditional distributionsrepresented CPT, settings consider often yield considerable representational compactness. Rule-based representations used directly Poole (1995,1997a) context decision processes often compact trees (Poole,1997b). generically refer representations type 2TBNs structured CPTs.4.2.3 Probabilistic STRIPS Operators2TBN representation viewed oriented toward describing effects actionsdistinct variables. CPT variable expresses (stochastically) changes(or persists), perhaps function state certain variables. However,long noted AI research planning reasoning actionactions change state limited ways; is, affect relatively small numbervariables. One diculty variable-oriented representations 2TBNs onemust explicitly assert variables unaffected specific action persist value (e.g.,see CPT RHC Figure 13)|this instance infamous frame problem(McCarthy & Hayes, 1969).Another form representation actions might called outcome-oriented representation: one explicitly describes possible outcomes action possible jointeffects variables. idea underlying Strips representationclassical planning (Fikes & Nilsson, 1971).classical Strips operator described precondition set effects.former identifies set states action executed, latterdescribes input state changes result taking action. probabilisticStrips operator (PSO) (Hanks, 1990; Hanks & McDermott, 1994; Kushmerick et al., 1995)extends Strips representation two ways. First, allows actions differenteffects depending context, second, recognizes effects actionsalways known certainty.32Formally, PSO consists set mutually exclusive exhaustive logical formulae,called contexts, stochastic effect associated context. Intuitively, context discriminates situations action differing stochastic effects.stochastic effect set change sets|a simple list variable values|withprobability attached change set, requirement probabilities sumone. semantics stochastic effect described follows: stochasticeffect action applied state s, possible resulting states determinedchange sets, occurring corresponding probability; resulting state associated change set constructed changing variable values state matchchange set, unmentioned variables persist value. Note since one31. fact certain direct dependencies among variables Bayes net rendered irrelevantspecific variable assignments studied generally guise context-specific independence(Boutilier, Friedman, Goldszmidt, & Koller, 1996); see (Geiger & Heckerman, 1991; Shimony, 1993)related notions.32. conditional nature effects also feature deterministic extension Strips known ADL(Pednault, 1989).45fiBoutilier, Dean, & HanksRHCfLoc-CR -RHC +M-CR -RHC-RHC +M-RHC+CR +M+CR+Mnilelse-RHC +CR +M-RHC +CR-RHC +M-RHC+CR +M+CR+Mnil0.190.760.010.040.040.160.160.640.0280.1120.1120.4480.0120.0480.0480.192Figure 17: PSO representation DelC action.LocL+Loc(L) 0.9nil0.1+Loc(C) 0.9nil0.1HC+Loc(M) 0.9nil0.1+Loc(H) 0.9nil0.1+Loc(O) -RHC -RHM+Loc(O) -RHC+Loc(O)-RHC -RHM-RHCnil0.1350.1350.630.0150.0150.07Figure 18: PSO representation simplified CClk action.context hold state s, transition distribution action stateeasily determined.Figure 17 gives graphical depiction PSO DelC action (shown 2TBNFigure 16). three contexts :RHC, RHC ^ Loc(O) RHC ^:Loc(O) representedusing decision tree. leaf branch decision tree stochastic effect(set change sets associated probabilities) determined corresponding context.example, RHC ^ Loc(O) holds, action four possible effects: robot losescoffee; may may satisfy coffee request (due 0:05 chance spillage);mail may may arrive. Notice outcome spelled completely.number outcomes two contexts rather large due possible exogenousevents (we discuss Section 4.2.4).33key difference PSOs 2TBNs lies treatment persistence.variables unaffected action must given CPTs 2TBN model,variables mentioned PSO model (e.g., compare variable Locrepresentations DelC). way, PSOs said \solve" frame problem,since unaffected variables need mentioned action's description.3433. keep Figure 17 manageable, ignore effect exogenous event Mess variable .34. discussion frame problem 2TBNs, see (Boutilier & Goldszmidt, 1996).46fiDecision-Theoretic Planning: Structural AssumptionsArrMMessLocLocLocLocRHCRHCRHCRHCRHMRHMRHMRHMCRCRCRCRt+ 1t+ 2t+1Figure 19: simplified explicit-event model DelC.PSOs provide effective means representing actions correlated effects.Recall description CClk action captured Figure 15, robot maydrop coffee moves hallway, may drop mail dropscoffee. 2TBN representation CClk, one must RHCt RHCt+1parents RHMt+1 : must model dependence RHM change valuevariable RHC. Figure 18 shows CClk action PSO format (for simplicity, ignoreoccurrence exogenous events). PSO representation offer economicalrepresentation correlated effects since possible outcomes movinghallway spelled explicitly. Specifically, (possible) simultaneous change valuesvariables question made clear.4.2.4 Explicit-Event ModelsExplicit-event models also represented using 2TBNs somewhat different form.discussion Section 2.3, form taken explicit-event models depends crucially one's assumptions interplay effects actionexogenous events. However, certain assumptions even explicit-event modelsrather concise.illustrate, Figure 19 shows deliver-coffee action represented 2TBNexogenous events explicitly represented. first \slice" network shows effectsaction DelC without presence exogenous events. subsequent slices describeeffects events ArrM Mess (we use two events illustration). Noticepresence extra random variables representing occurrence events question.CPTs nodes ect occurrence probabilities events various47fiBoutilier, Dean, & Hanksconditions, directed arcs event variables state variables indicateeffects events. probabilities depend state variables general;thus, 2TBN represents occurrence vectors (see Section 2.3) compact form. Alsonotice that, contrast event occurrence variables, explicitly representaction occurrence variable network, since modeling effectsystem given action taken.35example ects assumptions described Section 2.3, namely, eventsoccur action takes place event effects commutative,reason ordering events ArrM Mess network irrelevant.model, system actually passes two intermediate though necessarily distinctstates goes stage stage + 1; use subscripts "1 "2 suggestprocess. course, described earlier, actions events combineddecomposable way; complex combination functions also modeled using 2TBNs(for one example, see Boutilier & Puterman, 1995).4.2.5 Equivalence Representationsobvious question one might ask concerns extent certain representationsinherently concise others. focus standard implicit-event models,describing domain features make different representations lesssuitable.2TBN PSO representations oriented toward representing changesvalues state variables induced action; key distinction lies fact2TBNs model uence variable separately, PSO model explicitlyrepresents complete outcomes. simple 2TBN|a network synchronic arcs|canused represent action cases correlations among action'seffect different state variables. worst case, effect variablediffers state, time + 1 variable must time variables parents.regularities exploited structured CPT representations,action requires specification O(n2n ) parameters (assuming boolean variables),compared 22n entries required explicit transition matrix. numberparents variable bounded k, need specify n2k conditionalprobabilities. reduced CPTs exhibit structure (e.g.,represented concisely decision tree). instance, CPT capturedrepresentation choice f (k) entries, f polynomial functionnumber parents variable, representation size, O(n f (k)), polynomialnumber state variables. often case, instance, actions one(stochastic) effects variable requires number (pre-) conditions hold;not, different effect comes play.PSO representation may concise 2TBN action multipleindependent stochastic effects. PSO requires possible change list enumerated corresponding probability occurrence. number changes growsexponentially number variables affected action. fact evident35. Sections 4.2.7 4.3 discuss representations model choice action explicitly variablenetwork.48fiDecision-Theoretic Planning: Structural AssumptionsRHCfLoc-RHC -CR-RHCnil+M 0.2nil 0.81.0else0.950.05-RHCnil0.70.3Figure 20: \factored" PSO representation DelC action.Figure 17, impact exogenous events affects number variables stochastically independently. problem arise respect \direct" action effects,well. Consider action set 10 unpainted parts spray painted; partsuccessfully painted probability 0:9, successes uncorrelated. Ignoringcomplexity representing different conditions action could take place,simple 2TBN represent action 10 parameters (one success probability perpart). contrast, PSO representation might require one list 210 distinct changelists associated probabilities. Thus, PSO representation exponentiallylarger (in number affected variables) simple 2TBN representation.Fortunately, certain variables affected deterministically, causePSO representation blow up. Furthermore, PSO representations also modifiedexploit independence action's effects different state variables (Boutilier &Dearden, 1994; Dearden & Boutilier, 1997), thus escaping combinatorial diculty.instance, might represent DelC action shown Figure 17 \factoredform" illustrated Figure 20 (for simplicity, show effect actionexogenous event ArrM). Much like 2TBN, determine overall effectcombining change sets (in appropriate contexts) multiplying correspondingprobabilities.Simple 2TBNs defined original set state variables sucient represent actions.36 Correlated action effects require presence synchronic arcs.worst case, means time + 1 variables 2n , 1 parents.fact,P acyclicity condition assures worst case, total number parentsnk=1 2k , 1; thus, end specifying O(22n ) entries, requiredexplicit transition matrix. However, number parents (whether occurring withintime slice + 1) bounded, regularities CPTs allow compactrepresentation, 2TBNs still profitably used.PSO representations compare favorably 2TBNs casesaction's effects different variables correlated. case, PSOs providesomewhat economical representation action effects, primarily one needn'tworry frame conditions. main advantage PSOs one need enlistaid probabilistic reasoning procedures determine transitions induced actionscorrelated effects. Contrast explicit specification outcomes PSOstype reasoning required determine joint effects action represented 2TBN36. However, Section 4.2.6 discusses certain problem transformations render simple 2TBNs sucientMDP.49fiBoutilier, Dean, & Hanksform synchronic arcs, described Section 4.1. Essentially, correlated effects\compiled" explicit outcomes PSOs.Recent results Littman (1997) shown simple 2TBNs PSOsused represent action represented 2TBN without exponential blowuprepresentation size. effected clever problem transformation newsets actions propositional variables introduced (using either simple 2TBNPSO representation). structure original 2TBN ected new planningproblem, incurring polynomial increase size input actiondescriptions description policy. Though resulting policy consists actionsexist underlying domain, extracting true policy dicult.noted, however, representation automatically constructedgeneral 2TBN specification, unlikely could provided directly, sinceactions variables transformed problem \physical" meaningoriginal MDP.4.2.6 Transformations Eliminate Synchronic Constraintsdiscussion assumed variables propositions used 2TBNPSO action descriptions original state variables. However, certain problem transformations used ensure one represent action using simple 2TBNs,long one require original state variables used. One transformationsimply clusters variables action correlated effect. new compoundvariable|which takes values assignments clustered variables|can used2TBN, removing need synchronic arcs. course, variabledomain size exponential number clustered variables.intuitions underlying PSOs used convert general 2TBN action descriptions simple 2TBN descriptions explicit \events" dictating precise outcomeaction. Intuitively, event occur k different forms, correspondingdifferent change list induced action (or change list respect variablesquestion). example, convert \action" description CClk Figure 15explicit-event model shown Figure 21.37 Notice \event" takes valuescorresponding possible effects correlated variables RHC RHM. Specifically, denotes event robot escaping hallway successfully without losingcargo, b denotes event robot losing coffee, c denotes event losingcoffee mail. effect, event space represents possible \combined"effects, obviating need synchronic arcs network.4.2.7 Actions Explicit Nodes NetworkOne diculty 2TBN PSO approach action description actionrepresented separately, offering opportunity exploit patterns across actions.instance, fact location persists actions except moving clockwise counterclockwise means \frame axiom" duplicated 2TBN actions(this case PSOs, course). addition, ramifications (or correlated action37. Figure 15 describes Markov chain induced policy, representation CClk easilyextracted it.50fiDecision-Theoretic Planning: Structural AssumptionsLocHalla: 1.0b: 0.0c: 0.0EventRHCRHMLocelsefa:0.7 a:0.7b:0.15 b:0.3c:0.15 c:0.0Locfa: 1.0b: 0.0c: 0.0RHCRHC1.0RHMTimeRHMTime t+1Loc1.00.0RHMb0.0b0.0f0.0c0.0f0.0elseEventEventRHCc1.0Figure 21: explicit-event model removes correlations.effects) duplicated across actions well. instance, coffee request occurs (withprobability 0:2) robot ends oce, correlation duplicatedacross actions. compelling example might one robot movebriefcase new location one number ways. We'd like capture fact (orramification) contents briefcase move location briefcaseregardless action moves briefcase.circumvent diculty, introduce choice action \random variable" network, conditioning distribution state variable transitionsvalue variable. Unlike state variables (or event variables explicit event models),generally require distribution action variable|the intent simplymodel schematically conditional state-transition distributions given particularchoice action. choice action dictated decision makerpolicy determined. reason, anticipating terminology used uencediagrams (see Section 4.3), call nodes decision nodes depict network diagrams boxes. variable take value action availableagent.2TBN explicit decision node shown Figure 22. restricted example,might imagine decision node take one two values, Clk CClk. factissuance coffee request t+1 depends whether robot successfully moved(or remained in) oce represented \once" arc Loct+1 CRt+1 ,rather repeated across multiple action networks. Furthermore, noisy persistenceactions also represented (adding action PUM, however,undercuts advantage see try combine actions).One diculty straightforward use decision nodes (which standardrepresentation uence diagram literature) adding candidate actionscause explosion network's dependency structure. example, consider two51fiBoutilier, Dean, & HanksActLocLocCRCRTimeTime t+1Figure 22: uence diagram restricted process.ActXXXXXActXelsea1a21.0fX0.9ZZ(a) action a1ZZZ(b) action a21.0f0f0.9Z1.0f0Z(c) influence diagramFigure 23: Unwanted dependencies uence diagrams.52(d) CPTf0fiDecision-Theoretic Planning: Structural Assumptionsaction networks shown Figure 23(a) (b). Action a1 makes true probability0:9 X true (having effect otherwise), a2 makes true Z true.Combining actions single network obvious way produces uencediagram shown Figure 23(c). Notice four parent nodes, inheritingunion parents individual networks (plus action node) requiringCPT 16 entries actions a1 a2 together eight additional entriesaction affect . individual networks ect fact dependsX a1 performed Z a2 performed. fact lostnaively constructed uence diagram. However, structured CPTs usedrecapture independence compactness representation: tree Figure 23(d)captures distribution much concisely, requiring eight entries. structuredrepresentation also allows us concisely express persists actions.large domains, expect variables generally unaffected substantial number(perhaps most) actions, thus requiring representations uence diagrams.See (Boutilier & Goldszmidt, 1996) deeper discussion issue relationshipframe problem.provide distributional information action choice, hardsee 2TBN explicit decision node used represent Markov chaininduced particular policy natural way. Specifically, adding arcs statevariables time decision node, value decision node (i.e., choiceaction point) dictated prevailing state.384.3 uence Diagramsuence diagrams (Howard & Matheson, 1984; Shachter, 1986) extend Bayesian networksinclude special decision nodes represent action choices, value nodes representeffect action choice value function. presence decision nodes meansaction choice treated variable decision maker's control. Value nodes treatreward variable uenced (usually deterministically) certain state variables.uence diagrams typically associated schematic representationstationary systems, instead used tool decision analysts sequentialdecision problem carefully handcrafted. generic use uence diagramsdiscussed Tatman Shachter (1990). event, theory planconstruction associated uence diagrams: choice possible actionsstage must explicitly encoded model. uence diagrams are, therefore, usuallyused model finite-horizon decision problems explicitly describing evolutionprocess stage terms state variables.Section 4.2.7, decision nodes take values specific actions, though setpossible actions tailored particular stage. addition, analyst generallyinclude stage state variables thought relevant decisionsubsequent stages. Value nodes also key feature uence diagramsdiscussed Section 4.5. Usually, single value node specified, arcs indicating38. generally, randomized policy represented specifying distribution possible actionsconditioned state.53fiBoutilier, Dean, & HanksRHMRHMRewCRetc.0CRetc.1 234-7 -6.5 -6 -5.5 -501 234-4 -3.5 -3 -2.5 -2Figure 24: representation reward function uence diagram.uence particular state decision variables (often multiple stages) overallvalue function.uence diagrams typically used model partially observable problems. arcstate variable decision node ects fact value state variableavailable decision maker time action chosen. words,variable's value forms part observation made time prior actionselected time +1, policy constructed refer variable. again,allows compact specification observation probabilities associated system.fact probability given observation depends directly certain variablesothers mean far fewer model parameters required.4.4 Factored Reward Representationalready noted common formulating MDP problems adoptsimplified value function: assigning rewards states costs actions, evaluating histories combining factors according simple function like addition.simplification alone allows representation value function significantlyparsimonious one based complex comparison complete histories. Evenrepresentation requires explicit enumeration state action space, however,motivating need compact representations parameters. Factored representations rewards action costs often obviate need enumerate stateaction parameters explicitly.Like action's effect particular variable, reward associated state oftendepends values certain features state. example, robotdomain, associate rewards penalties undelivered mail, unfulfilled coffeerequests untidiness lab. reward penalty independentvariables, individual rewards associated groups states differvalues relevant variables. relationship rewards state variablesrepresented value nodes uence diagrams, represented diamond Figure 24.conditional reward table (CRT) node table associates rewardevery combination values parents graph. table, shown Figure 24,locally exponential number relevant variables. Although Figure 24 showscase stationary Markovian reward function, uence diagrams used represent54fiDecision-Theoretic Planning: Structural Assumptionsnonstationary history-dependent rewards often used represent value functionsfinite-horizon problems.Although worst case CRT take exponential space store, manycases reward function exhibits structure, allowing represented compactly usingdecision trees graphs (Boutilier et al., 1995), Strips-like tables (Boutilier & Dearden,1994), logical rules (Poole, 1995, 1997a). Figure 24 shows fragment one possibledecision-tree representation reward function used running example.independence assumptions studied multiattribute utility theory (Keeney & Raiffa,1976) provide yet another way reward functions represented compactly.assume component attributes reward function make independent contributions state's total reward, individual contributions combined functionally.instance, might imagine penalizing states CR holds (partial) reward,3, penalizing situations undelivered mail (M _ RHM) ,2,penalizing untidiness (i) , 4 (i.e., proportion untidy things are).reward state determined simply adding individual penalties associated feature. individual component rewards along combinationfunction constitute compact representation reward function. tree fragmentFigure 24, ects additive independent structure described, considerablycomplex representation defines (independent) rewards individualpropositions separately. use additive reward functions MDPs considered(Boutilier, Brafman, & Geib, 1997; Meuleau, Hauskrecht, Kim, Peshkin, Kaelbling, Dean,& Boutilier, 1998; Singh & Cohn, 1998).Another example structured rewards goal structure studied classical planning.Goals generally specified single proposition (or set literals) achieved.such, generally represented compactly. Haddawy Hanks (1998)explore generalizations goal-oriented models permit extensions partial goalsatisfaction, yet still admit compact representations.4.5 Factored Policy Value Function Representationtechniques studied far concerned input specification MDP:states, actions, reward function. components problem's solution|the policy optimal value function|are also candidates compact structured representation.simplest case, stationary policy fully observable problem, policymust associate action every state, nominally requiring representation sizeO(jSj). problem exacerbated nonstationary policies POMDPs. example,policy finite-horizon FOMDP stages generates policy size O(T jSj).finite-horizon POMDP, possibleP observable history length < might requiredifferent action choice; many Tk=1 bk histories generated fixedpolicy, b maximum number possible observations one make followingaction.39fact policies require much space motivates need find compact functional representations, standard techniques like tree structures discussed39. methods dealing POMDPs, conversion FOMDPs belief space (see Section 2.10.2),complex still.55fiBoutilier, Dean, & HanksCRRHCetc.LocL CLocHHLCDelC Clk Clk Cclk Cclk HRM Clk GetCPUM CclkDelM CclkPUM CclkFigure 25: tree representation policy.actions reward functions used represent policies value functions well.focus stationary policies value functions FOMDPs, logicalfunction representation may used. example, Schoppers (1987) uses Strips-stylerepresentation universal plans, deterministic, plan-like policies. Decision treesalso used policies value functions (Boutilier et al., 1995; Chapman &Kaelbling, 1991). example policy robot domain specified decision treegiven Figure 25. policy dictates that, instance, CR RHC true: (a)robot deliver coffee user oce, (b) move toward oceoce, unless (c) mail mailroom, casepickup mail way.4.6 Summarysection discussed number compact factored representations componentsMDP. began discussing intensional state representations, temporal Bayesiannetworks device representing system dynamics. Tree-structured conditionalprobability tables (CPTs) probabilistic Strips operators (PSOs) introducedalternative transition matrices. Similar tree structures logical representationsintroduced representing reward functions, value functions, policies.representations often used describe problem compactly,offer guarantee problem solved effectively. nextsection explore algorithms use factored representations avoid iteratingexplicitly entire set states actions.5. Abstraction, Aggregation, Decomposition Methodsgreatest challenge using MDPs basis DTP lies discovering computationally feasible methods construction optimal, approximately optimal satisficingpolicies. course, arbitrary decision problems intractable|even producing satisficingapproximately optimal policies generally infeasible. However, previous sectionssuggest many realistic application domains may exhibit considerable structure,furthermore structure modeled explicitly exploited typicalproblems solved effectively. instance, structure type lead compact56fiDecision-Theoretic Planning: Structural Assumptionsfactored representations input data output policies, often polynomial-sizedrespect number variables actions describing problem. suggestscompact problem representations, policy construction techniques developed exploit structure tractable many commonly occurring probleminstances.dynamic programming state-based search techniques described Section 3 exploit structure different kind. Value functions decomposedstate-dependent reward functions, state-based goal functions, tackled dynamicprogramming regression search, respectively. algorithms exploit structuredecomposable value functions prevent search explicitly possiblepolicies. However, algorithms polynomial size state space,curse dimensionality makes even algorithms infeasible practical problems.Though compact problem representations aid specification large problems,clear large system specified compactly representation exploits\regularities" found domain. Recent AI research DTP stressed usingregularities implicit compact representations speed planning process.techniques focus optimal approximately optimal policy construction.following subsection focus abstraction aggregation techniques, especially manipulate factored representations. Roughly, techniques allowexplicit implicit grouping states indistinguishable respect certain characteristics (e.g., value optimal action choice). refer set states groupedmanner aggregate abstract state , sometimes cluster, assumeset abstract states constitutes partition state space; say, every stateexactly one abstract state union abstract states comprises entire statespace.40 grouping similar states, abstract state treated single state, thusalleviating need perform computations state individually. techniquesused approximation elements abstract state approximatelyindistinguishable (e.g., values states lie within small interval).look use problem decomposition techniques MDPbroken various pieces, solved independently; solutionspieced together used guide search global solution. subprocesses whosesolutions interact minimally treated independent, might expect approximatelyoptimal global solution. Furthermore, structure problem requires solutionparticular subproblem only, solutions subproblems ignoredaltogether.Related use reachability analysis restrict attention \relevant" regionsstate space. Indeed, reachability analysis communicating structure MDPused form certain types decompositions. Specifically, distinguish serialdecompositions parallel decompositions.result serial decomposition viewed partitioning state spaceblocks, representing (more less) independent subprocess solved.serial decomposition, relationship blocks generally complicatedcase abstraction aggregation. partition resulting decomposition,40. might also group states non-disjoint sets cover entire state space. considersoft-state aggregation here, see (Singh, Jaakkola, & Jordan, 1994).57fiBoutilier, Dean, & Hanksstates within particular block may behave quite differently respect (say) valuedynamics. important consideration choosing decomposition possiblerepresent block compactly compute eciently consequences movingone block another and, further, subproblems corresponding subprocessessolved eciently.parallel decomposition somewhat closely related abstract MDP.MDP divided \parallel sub-MDPs" decision action causesstate change within sub-MDP. Thus, MDP cross product joinsub-MDPs (in contrast union, serial decomposition). brie discuss severalmethods based parallel MDP decomposition.5.1 Abstraction AggregationOne way problem structure exploited policy construction relies notionaggregation|grouping states indistinguishable respect certain problemcharacteristics. example, might group together states optimalaction, value respect k-stage-to-go value function.aggregates constructed solution problem.AI, emphasis generally placed particular form aggregation, namelyabstraction methods, states aggregated ignoring certain problem features.policy Figure 25 illustrates type abstraction: states CR,RHC Loc(O) true grouped, action selectedstate. Intuitively, three propositions hold, problem features ignoredabstracted away (i.e., deemed irrelevant). decision-tree representationpolicy value function partitions state space distinct cluster leaftree. representations (e.g., Strips-like rules) abstract state space similarly.precisely type abstraction used compact, factored representations actions goals discussed Section 4. 2TBN shown Figure 16,effect action DelC variable CR given CPT CRt+1 ; however,(stochastic) effect state parent variablesvalue. representation abstracts away variables, combining statesdistinct values irrelevant (non-parent) variables. Intensional representations oftenmake easy decide features ignore certain stage problem solving,thus (implicitly) aggregate state space.least three dimensions along abstractions type compared. first uniformity: uniform abstraction one variables deemedrelevant irrelevant uniformly across state space, nonuniform abstraction allows certain variables ignored certain conditions others.distinction illustrated schematically Figure 26. tabular representation CPTviewed form uniform abstraction|the effect action variabledistinguished clusters states differ value parent variable,distinguished states agree parent variables disagree others|whiledecision tree representation CPT embodies nonuniform abstraction.second dimension comparison accuracy. States grouped togetherbasis certain characteristics, abstraction called exact states within58fiDecision-Theoretic Planning: Structural AssumptionsUniformABCABCABCABCABCABCABCABCNonuniformB5.35.3AB=ABCCABCExact5.35.3Approximate5.35.22.92.92.92.75.59.39.39.39.05.3AdaptiveFixedFigure 26: Different forms state space abstraction.cluster agree characteristic. non-exact abstraction called approximate.illustrated schematically Figure 26: exact abstraction groups together statesagree value assigned value function, approximate abstractionallows states grouped together differ value. extent statesdiffer often used measure quality approximate abstraction.third dimension adaptivity. Technically, property abstractionitself, abstractions used particular algorithm. adaptive abstractiontechnique one abstraction change course computation,fixed abstraction scheme groups together states (again, see Figure 26).example, one imagine using abstraction representation value functionV k , revising abstraction represent V k+1 accurately.Abstraction aggregation techniques studied literatureMDPs. Bertsekas Castanon (1989) develop adaptive aggregation (as opposedabstraction) technique. proposed method operates state spaces, however,therefore exploit implicit structure state space itself. adaptive, uniformabstraction method proposed Schweitzer et al. (1985) solving stochastic queuing models. methods, often referred aggregation-disaggregation procedures,typically used accelerate calculation value function fixed policy. Valuefunction calculation requires computational effort least quadratic size statespace, impractical large state spaces. aggregation-disaggregation procedures, states first aggregated clusters. system equations solved,series summations performed, requiring effort cubic numberclusters. Next, disaggregation step performed cluster, requiring effort leastlinear size cluster. net result total work, least lineartotal number states, worst cubic size largest cluster.DTP generally assumed computations even linear size fullstate space infeasible. Therefore important develop methods perform59fiBoutilier, Dean, & Hankswork polynomial log size state space. problems amenablereductions without (perhaps unacceptable) sacrifice solution quality.following section, review recent techniques DTP aimed achievingreductions.5.1.1 Goal Regression Classical PlanningSection 3.2 introduced general technique regression (or backward) searchstate space solve classical planning problems, involving deterministic actions performance criteria specified terms reaching goal-satisfying state. Onediculty search requires branch search tree lead particulargoal state. commitment goal state may retracted (by backtrackingsearch process) sequence actions lead particular goal stateinitial state. However, goal usually specified set literals G representing setstates, reaching state G equally suitable|it may, therefore, wastefulrestrict search finding plan reaches particular element G.Goal regression abstraction technique avoids problem choosing particular goal state pursue. regression planner works searching sequence actionsfollows: current set subgoals SG0 initialized G. iteration actionff selected achieves one current subgoals SGi without deletingothers, whose preconditions con ict \unachieved subgoals."subgoals achieved removed current subgoal set replaced formularepresenting context ff achieve current subgoals, forming SGi+1 .process known regressing SGi ff. process repeated onetwo conditions holds: (a) current subgoal set satisfied initial state,case current sequence actions selected successful plan; (b) actionapplied, case current sequence cannot extended successful planearlier action choice must reconsidered.Example 5.1 example, consider simplified version robot planning example used Section 3.1 illustrate value iteration: robot four actionsPUM, GetC, DelC DelM, make deterministic obvious way.initial state sinit hCR; M; RHC; RHMi goal set G fCR; g. Regressing G DelM results SG1 = fCR; M; RHMg. Regressing SG1DelC results SG2 = fRHC; M; RHMg. Regressing SG2 PUM resultsSG3 = fRHC; g. Regressing SG3 GetC results SG4 = fM g. Notesinit 2 SG4, sequence actions GetC, PUM, DelC, DelM successfully reachgoal state. 2see algorithm implements form abstraction, first note goalprovides initial partition state space, dividing one set statesgoal satisfied (G) second set (G). Viewed partitionzero-stage-to-go value function, G represents states whose value positiveG represents states whose value zero.Every regression step thought revising partition. planningalgorithm attempts satisfy current subgoal set SGi applying action ff, uses60fiDecision-Theoretic Planning: Structural AssumptionsGetCRHC4PUMRHCDelCCRDelMCRRHMRHMGoal321Figure 27: example goal regression.regression compute (largest) set states that, executing ff, subgoalssatisfied. particular, state space repartitioned two abstract states: SGi+1SGi+1 . way, abstraction mechanism implemented goal regressionconsidered adaptive. viewed (i + 1)-stage value function: statesatisfying SGi+1 reach goal state +1 steps using action sequence producedSGi+1 .41 regression process stopped initial state memberabstract state SGi+1 . Figure 27 illustrates repartitioning state spacedifferent regions SGi+1 steps example above.regression produces compact representation something like value function(as discussion deterministic, goal-based dynamic programming Section 3.2),analogy exact regions produced regression record propertygoal reachability contingent particular choice action action sequence.Standard dynamic programming methods implemented structured waysimply noticing number different regions produced ith iterationconsidering actions regressed stage. unionregressions form states positive values Vi , thus making representationi-stage-to-go value function exact. Notice iteration costly, sinceregression actions must attempted, approach obviates needbacktracking ensure shortest plan found. Standard regressionprovide guarantees without commitment particular search strategy (e.g., breadthfirst). use dynamic programming using Strips action descriptions forms basicidea Schoppers's universal planning method (Schoppers, 1987).Another general technique solving classical planning problems partial order planning (POP) (Chapman, 1987; Sacerdoti, 1975), embodied popular planning algorithms SNLP (McAllester & Rosenblitt, 1991) UCPOP (Penberthy & Weld, 1992).42main motivation least-commitment approach comes realizationregression techniques incrementally building plan end beginning (intemporal dimension). Thus, iteration must commit inserting step lastplan.many cases determined particular step must appear somewhereplan, necessarily last step plan; and, indeed, many cases step41. case, however, states SGi+1 cannot reach goal region + 1 steps.case cannot using specific sequence actions chosen far.42. type planning also sometimes called nonlinear least-commitment planning. See Weld's(1994) survey nice overview.61fiBoutilier, Dean, & Hanksconsideration cannot appear last, fact cannot recognized later choicesreveal inconsistency. cases, regression algorithm prematurely commitincorrect ordering eventually backtrack choice. example,suppose problem scenario robot hold one item time,coffee mail. Picking mail causes robot spill coffee possession,similarly grasping coffee makes drop mail. plan generated regression wouldlonger valid: first two actions (DelC DelM) insertedplan, action added achieve RHC RHM without making one false;search plan would backtrack. Ultimately would discoveredsuccessful plan end two actions performed sequence.Partial-order planning algorithms proceed much like regression algorithms, choosingactions achieve unachieved subgoals using regression determine new subgoals,leaving actions unordered whatever extent possible. Strictly speaking, subgoal setsaren't regressed; rather, unachieved goal action precondition addressed separately,actions ordered relative one another one action threatens negatedesired effect another. example above, algorithm might first place actionsDelC DelM plan, leave unordered. PUM added planachieve requirement RHM DelM; ordered DelM still unorderedrespect DelC. GetC finally added plan achieve RHCaction DelC, two threats arise. First, GetC threatens desired effect RHM PUM.resolved ordering GetC PUM DelM. Assume former orderingchosen. Second, PUM threatens desired effect RHC GetC. threat alsoresolved placing PUM GetC DelC; since first threat resolvedordering GetC PUM, latter ordering consistent one. resultplan GetC, DelC, PUM, DelM. backtracking required generate plan,actions initially unordered, orderings introduceddiscovery threats required them.terms abstraction, incomplete, partially ordered plan threat-free,perhaps certain \open conditions" (unachieved preconditions subgoals),viewed much way partially completed regression plan: state satisfyingopen conditions reach goal state executing total ordering plan'sactions consistent current set ordering constraints. See (Kambhampati, 1997)framework unifies various approaches solving classical plan-generation problems.techniques relying regression studied extensively deterministicsetting, recently applied probabilistic unobservable (Kushmericket al., 1995) partially observable (Draper, Hanks, & Weld, 1994b) domains.part, techniques assume goal-based performance criterion attemptconstruct plans whose probability reaching goal state exceeds threshold.augment standard POP methods techniques evaluating plan's probabilityachieving goal, techniques improving probability adding structureplan. next section, consider use regression-related techniquessolve MDPs performance criteria general goals.62fiDecision-Theoretic Planning: Structural Assumptions5.1.2 Stochastic Dynamic Programming Structured Representationskey idea underlying propositional goal regression|that one need regress relevant propositions action|can extended stochastic dynamic programmingmethods, like value iteration policy iteration, used solve general MDPs.are, however, two key diculties overcome: lack specific goal regionuncertainty associated action effects.Instead viewing state space partitioned goal non-goal clusters,consider grouping states according expected values. Ideally, might wantgroup states according value respect optimal policy. considersomewhat less dicult task, grouping states according value respectfixed policy. essentially task performed policy evaluation steppolicy iteration, insights used construct optimal policies.fixed policy, want group states value policy.Generalizing goal versus non-goal distinction, begin partition groupsstates according immediate rewards. Then, using analogue regression developedstochastic case, reason backward construct new partition statesgrouped according value respect one-stage-to-go value function.iterate manner kth iteration produce new partition groupsstates according k-stage-to-go value function.iteration, perform work polynomial number abstract states (andsize MDP representation) and, lucky, total number abstract statesbounded logarithmic factor size state space. implementscheme effectively, perform operations like regression without ever enumeratingset states, structured representations state-transition,value, policy functions play role.FOMDPs, approaches type taken (Boutilier, 1997; Boutilier & Dearden, 1996; Boutilier et al., 1995; Boutilier, Dearden, & Goldszmidt, 1999; Dietterich &Flann, 1995; Hoey et al., 1999). illustrate basic intuitions behind approachdescribing value iteration discounted infinite-horizon FOMDPs might work.assume MDP specified using compact representation reward function(such decision tree) actions (such 2TBNs).value iteration, produce sequence value functions V0 ; V1 ; ; Vn , Vkrepresenting utility optimal k-stage policy. aim produce compactrepresentation value function and, using Vn suitable n, produce compactrepresentation optimal stationary policy. Given compact representationreward function R, clear constitutes compact representation V0 .usual, think leaf tree cluster states identical utility.produce V1 compact form, proceed two phases.branch tree V0 provides intensional description|namely, conjunction variable values labeling branch|of abstract state, region, comprisingstates identical value respect initial value function V0 . deterministic action ff, perform regression step using description determineconditions which, perform ff, would end cluster. would,furthermore, determine region state space containing states identical future value63fiBoutilier, Dean, & HanksXXX1.0 0.0X0.91.0 0.0ZZ0.9TimeZTime t+11.0 0.0Figure 28: example action.respect execution ff one stage go.43 Unfortunately, nondeterministicactions cannot handled quite way: given state, action might leadseveral different regions V0 non-zero probability. However, leaf treerepresenting V0 (i.e., region V0 ), regress conjunction X describingregion action ff produce conditions X becomes truefalse specified probability. words, instead regressing standard fashion determine conditions X becomes true, produce set distinctconditions X becomes true different probabilities. piecing togetherregions produced different labels description V0 , constructset regions state given region: (a) transitions (under action ff)particular part V0 identical probability; hence (b) identical expected futurevalue (Boutilier et al., 1995). view generalization propositional goalregression suitable decision-theoretic problems.Example 5.2 illustrate, consider example action shown Figure 28 valuefunction V 0 shown left Figure 29. order generate set regionsconsisting states whose future value (w.r.t. V 0 ) identical, proceedtwo steps (see Figure 29). first determine conditions fixedprobability making true (hence fixed probability moving leftright subtree V 0 ). conditions given tree representing CPTnode , makes first portion tree representing V 1 |see Step 1Figure 29. Notice tree leaves labeled probability makingtrue (implicitly) false.makes true, know future value (i.e., value zero stagesgo) 8.1; becomes false, need know whether makes Z true (to43. ignore immediate reward cost distinctions within region produced description;recall value performing ff state given R(s), C (ff; s) expected future value.simply focus abstract states whose elements identical future expected value. Differencesimmediate reward cost added fact.64fiDecision-Theoretic Planning: Structural AssumptionsX8.1Z9.00.90.0X1.00.00.9Z 0.9Z0.9Z 1.00VStep 11.00.9Z 0.0Z0.0Z 1.00.0Z 0.0Step 2Figure 29: iteration decision-theoretic regression. Step 1 produces portiontree dashed lines, Step 2 produces portion dotted lines.determine whether future value 0 9:0). probability Z becomestrue given tree representing CPT node Z . Step 2 Figure 29,conditions CPT conjoined conditions required predicting's probability (by \grafting" tree Z tree given first step).grafting slightly different three leaves tree : (a)full tree Z attached leaf X = t; (b) tree Z simplifiedattached leaf X = f ^ = f removal redundant test variable; (c) notice need attach tree Z leaf X = f ^ = t,since makes true probability 1 conditions (and Z relevantdetermination V 0 false).leaves newly formed tree Pr(Y ) Pr(Z ).joint distributions Z (the effect variables independent semantics network) tells us probability Z truezero stages go given conditions labeling appropriate branchtree hold one stage go. words, new tree uniquely determines,state one stage remaining, probability making conditionslabeling branches V 0 true. computation expected future value obtainedperforming one stage go placed leaves treetaking expectation values leaves V 0 . 2new set regions produced way describes function Qff1 , Qff1 (s)value associated performing ff state one stage go acting optimallythereafter. functions (for action ff) pieced together (i.e., \maxed"|seeSection 3.1) determine V1 . course, process repeated number timesproduce Vn suitable n, well optimal policy respect Vn .basic technique used number different ways. Dietterich Flann(1995) propose ideas similar these, restrict attention MDPs goal regions65fiBoutilier, Dean, & Hanksdeterministic actions (represented using Strips operators), thus rendering true goalregression techniques directly applicable.44 Boutilier et al. (1995) develop versionmodified policy iteration produce tree-structured policies value functions,Boutilier Dearden (1996) develop version value iteration described above.algorithms extended deal correlations action effects (i.e., synchronic arcs2TBNs) (Boutilier, 1997). abstraction schemes categorized nonuniform,exact adaptive.utility exact abstraction techniques tested real-world problems date. (Boutilier et al., 1999), results series abstract process-planningexamples reported, scheme shown useful, especially largerproblems. example, one specific problem 1.7 million states, tree representation value function 40,000 leaves, indicating tremendous amountregularity value function. Schemes like exploit regularity solve problemsquickly (in example, much less half time required modified policy iteration) much lower memory demands. However, schemes involvesubstantial overhead tree construction, smaller problems little regularity,overhead repaid time savings (simple vector-matrix representations methodsfaster), though still generally provide substantial memory savings. mightviewed best- worst-case behavior also described (Boutilier et al., 1999).series \linear" examples (i.e., problems value functions representedtrees whose size linear number problem variables), tree-based scheme solvesproblems many orders magnitude faster classical state-based techniques. contrast, problems exponentially-many distinct values also tested (i.e., distinctvalue state): tree-construction methods required construct completedecision tree addition performing number expected value maximizationcomputations classical methods. worst case, tree-construction overhead makesalgorithm run 100 times slower standard modified policy iteration.(Hoey et al., 1999), similar algorithm described uses algebraic decisiondiagrams (ADDs) (Bahar, Frohm, Gaona, Hachtel, Macii, Pardo, & Somenzi, 1993) rathertrees. ADDs simple generalization boolean decision diagrams (BDDs) (Bryant,1986) allow terminal nodes labeled real values instead boolean values.Essentially, ADD-based algorithms similar tree-based algorithms exceptisomorphic subtrees shared. lets ADDs provide compact representationscertain types value functions. Highly optimized ADD manipulation evaluationsoftware developed verification community also applied solving MDPs.Initial results provided (Hoey et al., 1999) encouraging, showing considerable savingstree-based algorithms problems. example, ADD algorithm applied1.7-million-state example described revealed value function178 distinct values (cf. 40,000 tree leaves required) produced ADD descriptionvalue function less 2200 internal nodes. also solved problemseven minutes, 40 times faster earlier reported timing results using decisiontrees (though improvement due use optimized ADD softwarepackages). Similar results obtain problems (problems 268 million states44. Dietterich Flann (1995) also describe work context reinforcement learning rathermethod solving MDPs directly.66fiDecision-Theoretic Planning: Structural Assumptionssolved four hours). encouraging fact worst-case(exponential) examples, overhead associated using ADDs|compared classical,vector-based methods|is much less trees (about factor 20 compared \ at"modified policy iteration 12 state variables), lessens problems become larger.Like tree-based algorithms, methods yet applied real-world problems.exact abstraction schemes clear that, examples resulting policies value functions may compact, others set regions may getlarge (even reaching level individual states Boutilier et al., 1995), thus precludingcomputational savings. Boutilier Dearden (1996) develop approximation schemeexploits tree-structured nature value functions produced. stage k,value function Vk pruned produce smaller, less accurate tree approximates Vk . Specifically, approximate value functions represented using trees whose leaveslabeled upper lower bound value function region; decisiontheoretic regression performed bounds. Certain subtrees value treepruned leaves subtree close value tree largegiven computational constraints. scheme nonuniform, approximate adaptive.approximation scheme tailored provide (roughly) accurate valuefunction given maximum tree size, smallest value function (with respect treesize) given minimum accuracy. Results reported (Boutilier & Dearden, 1996)show approximation small set examples (including worst-case examplestree-based algorithms) allows substantial reduction computational cost. instance,10-variable worst-case example, small amount pruning introduced average error0.5% reduced computation time factor 50. aggressive pruning tendsincrease error decrease computation time rapidly; making appropriate tradeoffstwo dimensions still addressed. method remains testedevaluated realistic problems.Structured representations solution algorithms applied problemsFOMDPs. Methods solving uence diagrams (Shachter, 1986) exploit structurenatural way; Tatman Shachter (1990) explore connection uence diagrams FOMDPs relationship uence diagram solution techniquesdynamic programming. Boutilier Poole (1996) show classic history-independentmethods solving POMDPs, based conversion FOMDP belief states, exploit types structured representations described here. However, exploiting structuredrepresentations POMDPs remains explored depth.5.1.3 Abstract PlansOne diculties adaptive abstraction schemes suggested factdifferent abstractions must constructed repeatedly, incurring substantial computational overhead. overhead compensated savings obtained policyconstruction|e.g., reducing number backups|then problematic.many cases savings dominated time space required generateabstractions, thus motivates development cheaper less accurate approximateclustering schemes.67fiBoutilier, Dean, & HanksAnother way reduce overhead adopt fixed abstraction schemeone abstraction ever produced. approach adopted classical planning hierarchical abstraction-based planners, pioneered Sacerdoti's AbStrips system (Sacerdoti, 1974). similar form abstraction studied Knoblock (1993) (see alsoKnoblock, Tenenberg, & Yang, 1991). work, variables (in case propositional)ranked according criticality (roughly, important variables solutionplanning problem) abstraction constructed deleting problemdescription set propositions low criticality. solution abstract problemplan achieves elements original goal deleted. However,preconditions effects actions deleted accounted solution, might solution original problem. Even so, abstract solutionused restrict search solution underlying concrete space. oftenhierarchies refined abstractions used propositions introducedback domain stages.form abstraction uniform (propositions deleted uniformly) fixed. Sinceabstract solution need solution problem, might tempted viewapproximate abstraction method. However, best think abstractplan solution all, rather form heuristic information help solvetrue problem quickly.intuitions underlying Knoblock's scheme applied DTP Boutilier Dearden (1994, 1997): variables ranked according degree uence rewardfunction subset important variables deemed relevant. subsetdetermined, variables uence relevant variables effectsactions (which determined easily using Strips 2TBN action descriptions)also deemed relevant, on. remaining variables deemed irrelevantdeleted description problem (both action reward descriptions).leaves abstract MDP smaller state space (i.e., fewer variables) solvedstandard methods. Recall state space reduction exponential numbervariables removed. view method uniform fixed approximate abstractionscheme. Unlike output classical abstraction methods, abstract policy producedimplemented value. degree optimal abstract policytrue optimal policy differ value bounded priori abstraction fixed.Example 5.3 simple illustration, suppose reward satisfying coffee requests(or penalty satisfying them) substantially greater keepinglab tidy delivering mail. Suppose time pressure requires agent focusspecific subset objectives order produce small abstract state space.case, four reward-laden variables problem (see Figure 24), CRjudged important. action descriptions used determinevariables (directly indirectly) affect probability achieving CR,CR, RHC Loc deemed relevant, allowing , , RHMignored. state space thus reduced size 400 size 20. addition, severalaction descriptions (e.g., Tidy) become trivial deleted. 268fiDecision-Theoretic Planning: Structural Assumptionsadvantage abstractions easily computed incur littleoverhead. disadvantages uniform nature abstractions restrictive,relevant \reward variables" determined policy constructedwithout knowledge agent's ability control variables. result, importantvariables|those large impact reward|but agentcontrol, may taken account, less important variables agent actuallyuence ignored. However, series abstractions used takeaccount objectives decreasing importance, posteriori valuable objectivesdealt risk controllability taken account (Boutilier et al.,1997). policies generated abstract levels also used \seed" valuepolicy iteration less abstract levels, certain cases reducing time convergence(Dearden & Boutilier, 1997). also suggested (Dearden & Boutilier, 1994, 1997)abstract value function used heuristic online search policiesimprove abstract policy constructed, discussed Section 3.2.2. Thus, errorapproximate value function overcome extent search, heuristicfunction improved asynchronous updates.different use abstraction adopted DRIPS planner (Haddawy & Suwandi,1994; Haddawy & Doan, 1994). Actions abstracted collapsing \branches," possible outcomes, maintaining probabilistic intervals abstract, disjunctive effects.Actions also combined decomposition hierarchy, much like hierarchicaltask networks. Planning done evaluating abstract plans decomposition network, producing ranges utility possible instantiations plans, refiningplans possibly optimal. use task networks means searchrestricted finite-horizon, open-loop plans action choice restricted possible refinements network. task networks offer useful way encode priori heuristicknowledge structure good plans.5.1.4 Model Minimization Reduction Methodsabstraction techniques defined recast terms minimizing stochasticautomaton, providing unifying view different methods offering new insightsabstraction process (Dean & Givan, 1997). automata theory knowgiven finite-state machine recognizing language L exists unique minimalfinite-state machine 0 also recognizes L. could = 0 , might also0 exponentially smaller . minimal machine, called minimalmodel language L, captures every relevant aspect machinessaid equivalent. define similar notions equivalence MDPs. Sinceprimarily concerned planning, important equivalent MDPs agree valuefunctions policies. practical standpoint, may necessary findminimal model find reduced model suciently small still equivalent.apply idea model minimization (or model reduction) planning follows:begin using algorithm takes input implicit MDP model factored formproduces (if lucky) explicit, reduced model whose size within polynomialfactor size factored representation. use favorite state-baseddynamic programming algorithms solve explicit model.69fiBoutilier, Dean, & Hanksthink dynamic programming techniques rely structured representations discussed earlier operating reduced model without ever explicitly constructingmodel. cases, building reduced model may appropriate;cases, one might save considerable effort explicitly constructing partsreduced model absolutely necessary.potential computational problems model-minimization techniques sketched above. small minimal model may exist, may hard find.Instead, might look reduced model easier find necessarily minimal. could fail, case might look model small enough usefulapproximately equivalent original factored model. carefulmean \approximate," intuitively two MDPs approximately equivalentcorresponding optimal value functions within small factor one another.order practical, MDP model reduction schemes operate directly implicitfactored representation original MDP. Lee Yannakakis (1992) call onlinemodel minimization. Online model minimization starts initial partition states.Minimization iteratively refines partition splitting clusters smaller clusters.cluster split states cluster behave differently respecttransitions states clusters. local property satisfiedclusters given partition, model consisting aggregate states correspondclusters partition equivalent original model. addition,initial partition method splitting clusters satisfy certain properties,45guaranteed find minimal model. case MDP reduction, initial partitiongroups together states reward, nearly reward caseapproximation methods.clusters partitions manipulated online model reduction methods represented intensionally formulas involving state variables. instance, formulaRHC ^ Loc(M ) represents set states robot coffee locatedmail room. operations performed clusters require conjoining, complementing, simplifying, checking satisfiability. worst case, operationsintractable, successful application methods depends criticallyproblem way represented. illustrate basic idea simpleexample.Example 5.4 Figure 30 depicts simple version running example singleaction. three boolean state variables corresponding RHC|the robotcoffee (or not, RHC), CR|there outstanding request coffee (or not, CR),and, considering two location possibilities, Loc(C )|the robot coffeeroom (or not, Loc(C )). Whether outstanding coffee request dependswhether request previous stage whether robotcoffee room. Location depends location previous stage,reward depends whether outstanding coffee request.45. property required initial partition that, two states cluster partitiondefining minimal model (recall minimal model unique), must clusterinitial partition.70fiDecision-Theoretic Planning: Structural AssumptionsSt 1StCRCRPr(CR 1)CRCRLoc(C)Loc(C)0.80.70.9LocLocPr(Loc(C) 1) = 0.7RHCPr(RHC 1)Loc(C)Loc(C)RHCRHC0.50.71.0RR(S t) = 1 CR0 elseRHCFigure 30: Factored model illustrating model-reduction techniques.CR Loc(C)CRCRCRCR Loc(C)(a)(b)Figure 31: Models involving aggregate states: (a) model corresponding initialpartition (b) minimal model.initial partition shown Figure 31(a) defined terms immediate rewards.say states particular starting cluster behave respectparticular destination cluster probability ending destinationcluster states starting cluster. property satisfiedstarting cluster CR destination cluster CR Figure 31(a), splitcluster labeled CR obtain model Figure 31(b). property satisfiedpairs clusters model Figure 31(b) minimal model. 2Lee Yannakakis algorithm non-deterministic finite-state machinesextended Givan Dean handle classical Strips planning problems (Givan & Dean,1997) MDPs (Dean & Givan, 1997). basic step splitting cluster closelyrelated goal regression, relationship explored (Givan & Dean, 1997). Variantsmodel reduction approach apply action space large representedfactored form (Dean, Givan, & Kim, 1998); example, action specifiedset parameters corresponding allocations several differentresources optimization problem. also exist algorithms computing approxi71fiBoutilier, Dean, & HanksRGCGPBBEB(a)(b)(c)Figure 32: Reachability serial problem decomposition.mate models (Dean, Givan, & Leach, 1997) ecient planning algorithms useapproximate models (Givan, Leach, & Dean, 1997).5.2 Reachability Analysis Serial Problem Decomposition5.2.1 Reachability Analysisexistence goal states exploited different settings. instance, deterministic classical planning problems, regression viewed form directed dynamicprogramming. Without uncertainty, certain policy either reaches goal state not,dynamic programming backups need performed goal states,possible states. Regression, therefore, implicitly exploits certain reachability characteristics domain along special structure value function.Reachability analysis applied much broadly forms basis various typesproblem decomposition. decomposition problem solving, MDP broken severalsubprocesses solved independently, roughly independently, solutionspieced together. subprocesses whose solutions interact marginally treatedindependent, might expect good nonoptimal global solution result. Furthermore,structure problem requires solution particular subproblemneeded, solutions subproblems ignored need computedall. instance, regression analysis, optimal action states cannot reachgoal region irrelevant solution classical AI planning problem. shownschematically Figure 32(a), regions B never explored backwardsearch state space: states reach goal within search horizonever deemed relevant. regions B may reachable start state,fact reach goal state means known irrelevant.system dynamics stochastic, scheme form basis approximatelyoptimal solution method: regions B ignored unlikely transitionregression goal region (region R). Similar remarks using progression forwardsearch start state apply, illustrated Figure 32(b).72fiDecision-Theoretic Planning: Structural AssumptionsSeveral schemes proposed AI literature exploiting reachabilityconstraints, apart usual forward- backward-search approaches. Peot Smith(1993) introduce operator graph, structure computed prior problem solvingcaches reachability relationships among propositions. graph consultedplanning process deciding actions insert plan resolvethreats.GraphPlan algorithm Blum Furst (1995) attempts blend considerationsforward backward reachability deterministic planning context. Onediculties regression may regress goal region sequenceoperators find region cannot reached initial state.Figure 32(a), example, states region R may reachable initialstate. GraphPlan constructs variant operator graph called planning graph,certain forward reachability constraints posted. Regression implementedusual, current subgoal set violates forward reachability constraintspoint, subgoal set abandoned regression search backtracks.Conceptually, one might think GraphPlan constructing forward search treestate space initial state root, backward searchgoal region backward tree. course, process state-based:instead, constraints possible variable values hold simultaneously differentplanning stages recorded, regression used search backward planninggraph. sense, GraphPlan viewed constructing abstractionforward-reachable states distinguished unreachable states planning stage,using distinction among abstract states quickly identify infeasible regressionpaths. Note, however, GraphPlan approximates distinction overestimatingset reachable states. Overestimation (as opposed underestimation) ensuresregression search space contains legitimate plans.Reachability also exploited solution general MDPs. Deanet al. (1995) propose envelope method solving \goal-based" MDPs approximately.Assuming path generated quickly given start state goal region,MDP consisting states path perhaps neighboring states solved.deal transitions lead envelope, heuristic method estimates valuestates.46 time permits, set neighboring states expanded, increasingsolution quality accurately evaluating quality alternative actions.ideas underlying GraphPlan applied general MDPs(Boutilier, Brafman, & Geib, 1998), construction planning graph generalized deal stochastic, conditional action representation offered 2TBNs. Giveninitial state (or set initial states), algorithm discovers reachability constraintsform like GraphPlan | instance, two variable values X = x1= y3 cannot obtain simultaneously; is, action sequence startinggiven initial state lead state values hold.47 reachabilityconstraints discovered process used simplify action reward representation MDP refers reachable states. case, action46. approximate abstraction techniques described Section 5.1.3 might used generateheuristic information.47. General k-ary constraints type considered (Boutilier et al., 1998).73fiBoutilier, Dean, & Hanksrequires unreachable set values hold effectively deleted. cases, certainvariables discovered immutable given initial conditionsdeleted, leading much smaller MDPs. simplified representation retains originalpropositional structure standard abstraction methods applied reachableMDP. also suggested strong synergy exists abstraction reachability analysis together techniques reduce size \effective" MDPsolved much dramatically either isolation. reachability constraints used prune regression paths deterministic domains, usedprune value function policy estimates generated decision-theoretic regressionabstraction algorithms (Boutilier et al., 1998).results reported (Boutilier et al., 1998) limited single process-planningdomain, show reachability analysis together abstraction provide substantial reductions size effective MDP must solved, least domains.domain 31 binary variables, reachability considerations generally eliminatedorder 10 15 variables (depending initial state arity|binaryternary|of constraints considered), reducing state space size 231 anywhere222 215 . Incorporating abstraction reachable MDP provided considerablyreduction, reducing MDP sizes ranging 28 effectively zero states.latter case would occur discovered values variables impact rewardaltered|in case every course action expected utilityMDP needn't solved (or solved applying null actions zero cost).5.2.2 Serial Problem Decomposition Communicating Structurecommunicating reachability structure MDP provides way formalize different types problem decomposition. classify MDP according Markovchains induced stationary policies admits. fixed Markov chain, groupstates maximal recurrent classes transient states, described Section 2.1.MDP recurrent policy induces Markov chain single recurrent class.MDP unichain policy induces single recurrent class (possibly) transient states. MDP communicating pair states s; t, policyreach t. MDP weakly communicating exists closed setstates communicating plus (possibly) set states transient every policy.call MDPs noncommunicating.notions crucial construction optimal average-reward policies,also exploited problem decomposition. Suppose MDP discovered consistset recurrent classes C1 ; Cn (i.e., matter policy adopted, agent cannotleave class enters class) set transient states.48 clearoptimal policy restricted class Ci constructed without reference policydecisions made states outside Ci even values. Essentially, Civiewed independent subprocess.48. simple way view classes think agent adopting randomized policy actionadopted state positive probability. classes induced Markov chain correspondclasses MDP.74fiDecision-Theoretic Planning: Structural Assumptionsobservation leads following suggestion optimal policy construction:49solve subprocesses consisting recurrent classes MDPs; removestates MDP, forming reduced MDP consisting transient states.break reduced MDP recurrent classes solve independently.key effectively use value function original recurrentstates (computed solving independent subproblems Step 1) take accounttransitions recurrent classes reduced MDP. Figure 32(c) shows MDPbroken classes might constructed way. original MDP, classes CE recurrent solved independently. removed MDP, classrecurrent reduced MDP. can, course, solved without reference classesB , rely value states transitions class E . However,value function E available purpose, used solveconsisted jDj states. hand, B solved, finallysolved. Lin Dean (1995) provide version type decompositionalso employs factored representation. factored representation allows dimensionalityreduction different state subspaces aggregating states differ valuesirrelevant variables subspaces.key decomposition discovery recurrent classes MDP.Puterman (1994) suggests adaptation Fox-Landi algorithm (Fox & Landi, 1968)discovering structure Markov chains O(N 2 ) (recall N = jSj).50 alleviatediculties algorithms work explicit state-based representation, BoutilierPuterman (1995) propose variant algorithm works factored 2TBNrepresentation.One diculty form decomposition reliance strongly independentsubproblems (i.e., recurrent classes) within MDP. Others explored exact approximate techniques work less restrictive assumptions. One simple methodapproximation construct \approximately recurrent classes." Figure 32(c) mightimagine C E nearly independent sense transitionslow-probability high-cost. Treating independent might lead approximately optimal policies whose error bounded. solutions C E interactstrongly enough solutions constructed completely independently,different approach solving decomposed problem taken.optimal value function E then, pointed out, calculateoptimal value function D. first thing note don't need knowvalue function states E , value every state E reachablestate single step. set states outside reachable singlestep state inside referred states periphery D. valuesstates intersection E periphery summarize value exitingending E . refer set states periphery blockkernel MDP. different blocks interact one anotherstates kernel.49. Ross Varadarajan (1991) make related suggestion solving average-reward problems.50. slight correction made suggested algorithm (Boutilier & Puterman, 1995).75fiBoutilier, Dean, & HanksLoc(C)Loc(L)Loc(M )Loc(O)Figure 33: Decomposition based location.Loc(C)Loc(L)KernelLoc(M )Loc(O)Figure 34: Kernel-based decomposition depicting kernel states.76fiDecision-Theoretic Planning: Structural AssumptionsExample 5.5 Spatial features often provide natural dimension along decom-pose domain. running example, location robot might useddecompose state space blocks states, one block possible locations. Figure 33 shows decomposition superimposed state-transitiondiagram MDP. States kernel shaded might correspondentrances exits locations. star-shaped topology, induced kerneldecomposition used (Kushner & Chen, 1974) (Dean & Lin, 1995), illustratedFigure 34. Figure 33, hallway location explicitly represented.simplification may reasonable hallway conduit movingone room another; case function hallway accounteddynamics governing states kernel. Figures 33 34 idealized that, givenfull set features running example, kernel would contain manystates. 2One technique computing optimal policy entire MDP involves repeatedlysolving MDPs corresponding individual blocks. techniques works follows:initially, guess value every state kernel.51 Given current estimatevalues kernel states, solve component MDPs; solution produces newestimate states kernel. adjust values states kernelconsidering difference current new estimates iteratedifference negligible.iterative method solving decomposed MDP special case Lagrangianmethod finding extrema function. literature repletemethods linear nonlinear systems equations (Winston, 1992). possibleformulate MDP linear program (D'Epenoux, 1963; Puterman, 1994). DantzigWolfe (1960) developed method decomposing system equations involvinglarge number variables set smaller systems equations interacting setcoupling variables (variables shared two blocks). Dantzig-Wolfedecomposition method, original, large system equations solved iterativelysolving smaller systems adjusting coupling variables iterationadjustment required. linear programming formulation MDP,values states encoded variables.Kushner Chen (1974) exploit fact MDPs modeled linear programsusing Dantzig-Wolfe decomposition method solve MDPs involving large numberstates. Dean Lin (1995) describe general framework solving decomposed MDPspointing work Kushner Chen special case, neither work addressesissue decompositions come from. Dean et al. (1995) investigate methodsdecomposing state space two blocks: reachable k steps fewerreachable k steps (see discussion reachability above). set statesreachable k fewer steps used construct MDP basis policyapproximates optimal policy. k increases, size block states reachablek steps increases, ensuring better solution; amount time required compute51. Ideally would aggregate kernel states value provide compact representation.remainder section, however, won't consider opportunities combiningaggregation decomposition methods.77fiBoutilier, Dean, & Hankssolution also increases. Dean et al. (1995) discuss methods solving MDPs time-criticalproblems trading quality time.ignored issue obtain decompositions expedite calculations. Ideally, component decomposition would yield simplification viaaggregation abstraction, reducing dimensionality component therebyavoiding explicit enumeration states. Lin (1997) presents methods exploitingstructure certain special cases communicating structure revealeddomain expert. general, however, finding decomposition minimize effortspent solving component MDPs quite hard (at least hard finding smallest circuit consistent given input-output behavior) best hopegood heuristic methods. Unfortunately, aware particularly usefulheuristics finding serial decompositions Markov decision processes. Developingheuristics clearly area investigation.Related form decomposition development macro operators MDPs(Sutton, 1995). Macros long history classical planning problem solving (Fikes,Hart, & Nilsson, 1972; Korf, 1985), recently generalized MDPs(Hauskrecht, Meuleau, Kaelbling, Dean, & Boutilier, 1998; Parr, 1998; Parr & Russell, 1998;Precup, Sutton, & Singh, 1998; Stone & Veloso, 1999; Sutton, 1995; Thrun & Schwartz,1995). work, macro taken local policy region statespace (or block terminology). Given MDP comprising blocksset macros defined block, MDP solved selecting macro actionblock global policy induced set macros picked closeoptimal, least best combination macros set available.(Sutton, 1995; Precup et al., 1998), macros treated temporally-abstract actionsmodels defined macro treated single actionused policy value iteration (along concrete actions). (Hauskrecht et al., 1998;Parr, 1998; Parr & Russell, 1998), models exploited hierarchical fashion,high-level MDP consisting states lying boundaries blocks, macros\actions" chosen states. issue macro generation|constructing set macros guaranteed provide exibility select close optimalglobal behavior|is addressed (Hauskrecht et al., 1998; Parr, 1998). relationshipserial decomposition techniques quite close; thus, problems discovering gooddecompositions, constructing good sets macros, exploiting intensional representationsareas clearer, compelling solutions required. date, work areaprovided much computational utility solution MDPs|except casesgood, hand-crafted, region-based decompositions macros provided|and littlework taken account factored nature many MDPs. reason,discuss detail. However, general notion serial decomposition continuesdevelop shows great promise.5.3 Multiattribute Reward Parallel DecompositionAnother form decomposition parallel decomposition, MDP brokenset sub-MDPs \run parallel." Specifically, stage (global)decision process, state subprocess affected. instance, Figure 35, action78fiDecision-Theoretic Planning: Structural AssumptionsMDP1MDP2MDP3Figure 35: Parallel problem decomposition.affects state subprocess. Intuitively, action suitable executionoriginal MDP state reasonably good sub-MDPs.Generally, sub-MDPs form either product join decomposition originalstate space (contrast union decompositions state space determined serialdecompositions): state space formed taking cross product sub-MDP statespaces, join certain states subprocesses cannot linked. subprocessesmay identical action spaces (as Figure 35), may action space,global action choice factored choice subprocess. lattercase, sub-MDPs may completely independent, case (global) MDPsolved exponentially faster. challenging problem arises constraintslegal action combinations. example, actions subprocessesrequire certain shared resources, interactions global choice may arise.parallel MDP decomposition, wish solve sub-MDPs use policiesvalue functions generated help construct optimal approximately optimal solutionoriginal MDP, highlighting need find appropriate decompositions MDPsdevelop suitable merging techniques. Recent parallel decomposition methodsinvolved decomposing MDP subprocesses suitable distinct objectives. Sincereward functions often deal multiple objectives, associated independentreward, whose rewards summed determine global reward, oftennatural way decompose MDPs. Thus, ideas multiattribute utility theoryseen play role solution MDPs.Boutilier et al. (1997) decompose MDP specified using 2TBNs additive rewardfunction using abstraction technique described Section 5.1.3. componentreward function, abstraction used generate MDP referring variablesrelevant component.52 Since certain state variables may present multiplesub-MDPs (i.e., relevant one objective), original state space joinsubspaces. Thus, decomposition tackled automatically. Merging tackled severalways. One involves using sum value functions obtained solving sub-MDPsheuristic estimate true value function. heuristic used guide online,state-based search (see Section 3.2.1). sub-MDPs interact, heuristicperfect leads backtrack-free optimal action selection; interact, search52. Note existence factored MDP representation crucial abstraction method.79fiBoutilier, Dean, & Hanksrequired detect con icts. Note sub-MDP identical sets actions.action space large, branching factor search process may prohibitive.Singh Cohn (1998) also deal parallel decomposition, though assumeglobal MDP specified explicitly set parallel MDPs, thus generating decompositionsglobal MDP issue. global MDP given cross product stateaction spaces sub-MDPs reward functions summed. However,constraints feasible action combinations couple solutions sub-MDPs.solve global MDP, sum sub-MDP value functions used upper boundoptimal global value function, maximum (at global state)used lower bound. bounds form basis action-elimination procedurevalue-iteration algorithm solving global MDP.53 Unfortunately, value iterationrun explicit state space global MDP. Since action space also crossproduct, potential computational bottleneck value iteration, well.Meuleau et al. (1998) use parallel decomposition approximate solution stochastic resource allocation problems large state action spaces. Much like SinghCohn (1998), MDP specified terms number independent MDPs,involving distinct objective, whose action choices linked shared resource constraints. value functions individual MDPs constructed oine usedset online action-selection procedures. Unlike many approximation proceduresdiscussed, approach makes attempt construct policy explicitly (andsimilar real-time search RTDP respect) construct value functionexplicitly. method applied large MDPs, state spaces size21000 actions spaces even larger, solve problems roughly halfhour. solutions produced approximate, size problem precludesexact solution; good estimates solution quality hard derive. However,method applied smaller problems nature whose exact solutioncomputed, approximations high quality (Meuleau et al., 1998). ablesolve large MDPs (with large, factored, state action spaces), modelrelies somewhat restrictive assumptions nature local value functionsensure good solution quality. However, basic approach appears generalizable,offers great promise solving large factored MDPs.algorithms (Singh & Cohn, 1998) (Meuleau et al., 1998) seenrely least implicitly structured MDP representations involving almost independentsubprocesses. seems likely approaches could take advantage automaticMDP decomposition algorithms (Boutilier et al., 1997), factoredrepresentations explicitly play part.5.4 Summaryseen number ways intensional representations exploitedsolve MDPs effectively without enumeration state space. include techniquesabstraction MDPs, including based relevance analysis, goal regressiondecision-theoretic regression; techniques relying reachability analysis serial decomposition; methods parallel MDP decomposition exploiting multiattribute nature53. Singh Cohn (1998) also incorporate methods removing unreachable states value iteration.80fiDecision-Theoretic Planning: Structural Assumptionsreward functions. Many methods can, fortunate circumstances, offer exponential reduction solution time space required represent policy value function;none come guarantees reductions except certain special cases.methods described provide approximate solutions (often error bounds provided), offer optimality guarantees general, provide optimalsolutions suitable assumptions.One avenue explored detail relationship structured solution methods developed MDPs described techniques used solvingBayesian networks. Since many algorithms discussed section rely structure inherent 2TBN representation MDP, natural ask whetherembody intuitions underlie solution algorithms Bayes nets, thuswhether solution techniques Bayes nets (directly indirectly) appliedMDPs ways give rise algorithms similar discussed here. remainsopen question point, undoubtedly strong ties exist. Tatman Shachter(1990) explored connections uence diagrams MDPs. Kjaerulff(1992) investigated computational considerations involved applying join tree methodsreasoning tasks monitoring prediction temporal Bayes nets. abstraction methods discussed Section 5.1.2 interpreted form variable elimination(Dechter, 1996; Zhang & Poole, 1996). Elimination variables occurs temporal order,good orderings within time slice must also exploit tree graph structureCPTs. Approximation schemes based variable elimination (Dechter, 1997; Poole, 1998)may also related certain approximation methods developed MDPs.independence-based decompositions MDPs discussed Section 5.3 clearly viewedexploiting independence relations made explicit \unrolling" 2TBN. development connections Bayes net inference algorithms doubt proveuseful enhancing understanding existing methods, increasing rangeapplicability pointing new algorithms.6. Concluding Remarkssearch effective algorithms controlling automated agents long important history, problem continue grow importance decisionmaking functionality automated. Work several disciplines, among AI, decisionanalysis, OR, addressed problem, carried different problem definitions, different sets simplifying assumptions, different viewpoints, hencedifferent representations algorithms problem solving. often not, assumptions seem made historical reasons reasons convenience,often dicult separate essential assumptions accidental. importantclarify relationships among problem definitions, crucial assumptions, solutiontechniques, meaningful synthesis take place.paper analyzed various approaches particular class sequential decision problems studied OR, decision analysis, AI literature.started general, reasonably neutral statement problem, couched, convenience, language Markov decision processes. demonstratedvarious disciplines define problem (i.e., assumptions make), effect81fiBoutilier, Dean, & Hanksassumptions worst-case time complexity solving problem defined.Assumptions regarding two main factors seem distinguish commonly studiedclasses decision problems:observation sensing: sensing tend fast, cheap, accurate laborious,costly noisy?incentive structure agent: behavior evaluated ability performparticular task, ability control system interval time?Moving beyond worst-case analysis, generally assumed that, although pathological cases inevitably dicult, agent able solve \typical" \easy"cases effectively. so, agent needs able identify structure problemexploit structure algorithmically.identified three ways structural regularities recognized, represented,exploited computationally. first structure induced domain-level simplifyingassumptions like full observability, goal satisfaction time-separable value functions,on. second structure exploited compact domain-specific encodings states,actions, rewards. designer use techniques make structure explicit,decision-making algorithms exploit structural regularities applyparticular problem hand. third involves aggregation, abstraction decomposition techniques, whereby structural regularities discovered exploitedproblem-solving process itself. developing framework|one allows comparisondomains, assumptions, problems, techniques drawn different disciplines|wediscover essential problem structure required specific representations algorithmsprove effective; way insights techniques developedcertain problems, within certain disciplines, evaluated potentially appliednew problems, within disciplines.main focus work elucidation various forms structuredecision problems exploited representationally computationally.part, focused propositional structure, commonly associated planning AI circles. complete treatment would also includedcompact representations dynamics, rewards, policies, value functions oftenconsidered continuous, real-valued domains. instance, discussed lineardynamics quadratic cost functions, often used control theory (Caines, 1988),use neural-network representations value functions, frequently adopted withinreinforcement learning community (Bertsekas & Tsitsiklis, 1996; Tesauro, 1994),54discussed partitioning continuous state spaces often addressed reinforcementlearning (Moore & Atkeson, 1995). Neither addressed relational quantificational structure used first-order planning representations. However, even techniquescast within framework described here; example, use piecewise-linearvalue functions seen form abstraction different linear componentsapplied different regions clusters state space.54. Bertsekas Tsitsiklis (1996) provide in-depth treatment neural network linear functionapproximators MDPs reinforcement learning.82fiDecision-Theoretic Planning: Structural AssumptionsAlthough certain cases indicated devise methods exploit severaltypes structure once, research along lines limited. extent,many representations algorithms described paper complementarypose obstacles combination. remains seen interacttechniques developed forms structure, used continuous stateaction spaces.analysis raises opportunities challenges: understanding assumptions,techniques, relationships, designer decision-making agents manytools build effective problem solvers; challenges lie developmentadditional tools integration existing ones.AcknowledgmentsMany thanks careful comments referees. Thanks Ron Parr RobertSt-Aubin comments earlier draft paper. students taking CS3710(Spring 1999) taught Martha Pollack University Pittsburgh CPSC522(Winter 1999) University British Columbia also deserve thanks detailedcomments.Boutilier supported NSERC Research Grant OGP0121843, NCE IRISII program Project IC-7. Dean supported part National Science FoundationPresidential Young Investigator Award IRI-8957601 Air Force AdvancedResearch Projects Agency Department Defense Contract No. F30602-91-C0041. Hanks supported part ARPA / Rome Labs Grant F30602{95{1{0024part NSF grant IRI{9523649.ReferencesAllen, J., Hendler, J., & Tate, A. (Eds.). (1990). Readings Planning. Morgan-Kaufmann,San Mateo.Astrom, K. J. (1965). Optimal control Markov decision processes incomplete stateestimation. J. Math. Anal. Appl., 10, 174{205.Bacchus, F., Boutilier, C., & Grove, A. (1996). Rewarding behaviors. ProceedingsThirteenth National Conference Artificial Intelligence, pp. 1160{1167 Portland,OR.Bacchus, F., Boutilier, C., & Grove, A. (1997). Structured solution methods nonMarkovian decision processes. Proceedings Fourteenth National ConferenceArtificial Intelligence, pp. 112{117 Providence, RI.Bacchus, F., & Kabanza, F. (1995). Using temporal logic control searchforward chaining planner.Proceedings Third EuropeanWorkshop Planning (EWSP'95) Assisi, Italy. Available via URLftp://logos.uwaterloo.ca:/pub/tlplan/tlplan.ps.Z.Bacchus, F., & Teh, Y. W. (1998). Making forward chaining relevant. ProceedingsFourth International Conference AI Planning Systems, pp. 54{61 Pittsburgh, PA.83fiBoutilier, Dean, & HanksBahar, R. I., Frohm, E. A., Gaona, C. M., Hachtel, G. D., Macii, E., Pardo, A., & Somenzi,F. (1993). Algebraic decision diagrams applications. International Conference Computer-Aided Design, pp. 188{191. IEEE.Baker, A. B. (1991). Nonmonotonic reasoning framework situation calculus.Artificial Intelligence, 49, 5{23.Barto, A. G., Bradtke, S. J., & Singh, S. P. (1995). Learning act using real-time dynamicprogramming. Artificial Intelligence, 72 (1{2), 81{138.Bellman, R. (1957). Dynamic Programming. Princeton University Press, Princeton, NJ.Bertsekas, D. P., & Castanon, D. A. (1989). Adaptive aggregation infinite horizondynamic programming. IEEE Transactions Automatic Control, 34 (6), 589{598.Bertsekas, D. P. (1987). Dynamic Programming. Prentice-Hall, Englewood Cliffs, NJ.Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-dynamic Programming. Athena, Belmont,MA.Blackwell, D. (1962). Discrete dynamic programming. Annals Mathematical Statistics,33, 719{726.Blum, A. L., & Furst, M. L. (1995). Fast planning graph analysis. ProceedingsFourteenth International Joint Conference Artificial Intelligence, pp. 1636{1642 Montreal, Canada.Bonet, B., & Geffner, H. (1998). Learning sorting decision trees POMDPs.Proceedings Fifteenth International Conference Machine Learning, pp. 73{81Madison, WI.Bonet, B., Loerincs, G., & Geffner, H. (1997). robust fast action selection mechanism.Proceedings Fourteenth National Conference Artificial Intelligence, pp.714{719 Providence, RI.Boutilier, C. (1997). Correlated action effects decision theoretic regression. Proceedings Thirteenth Conference Uncertainty Artificial Intelligence, pp. 30{37Providence, RI.Boutilier, C., Brafman, R. I., & Geib, C. (1997). Prioritized goal decomposition Markovdecision processes: Toward synthesis classical decision theoretic planning.Proceedings Fifteenth International Joint Conference Artificial Intelligence,pp. 1156{1162 Nagoya, Japan.Boutilier, C., Brafman, R. I., & Geib, C. (1998). Structured reachability analysis Markovdecision processes. Proceedings Fourteenth Conference UncertaintyArtificial Intelligence, pp. 24{32 Madison, WI.Boutilier, C., & Dearden, R. (1994). Using abstractions decision-theoretic planningtime constraints. Proceedings Twelfth National Conference ArtificialIntelligence, pp. 1016{1022 Seattle, WA.84fiDecision-Theoretic Planning: Structural AssumptionsBoutilier, C., & Dearden, R. (1996). Approximating value trees structured dynamicprogramming. Proceedings Thirteenth International Conference MachineLearning, pp. 54{62 Bari, Italy.Boutilier, C., Dearden, R., & Goldszmidt, M. (1995). Exploiting structure policy construction. Proceedings Fourteenth International Joint Conference ArtificialIntelligence, pp. 1104{1111 Montreal, Canada.Boutilier, C., Dearden, R., & Goldszmidt, M. (1999). Stochastic dynamic programmingfactored representations. (manuscript).Boutilier, C., Friedman, N., Goldszmidt, M., & Koller, D. (1996). Context-specific independence Bayesian networks. Proceedings Twelfth Conference UncertaintyArtificial Intelligence, pp. 115{123 Portland, OR.Boutilier, C., & Goldszmidt, M. (1996). frame problem Bayesian network actionrepresentations. Proceedings Eleventh Biennial Canadian ConferenceArtificial Intelligence, pp. 69{83 Toronto.Boutilier, C., & Poole, D. (1996). Computing optimal policies partially observabledecision processes using compact representations. Proceedings ThirteenthNational Conference Artificial Intelligence, pp. 1168{1175 Portland, OR.Boutilier, C., & Puterman, M. L. (1995). Process-oriented planning average-reward optimality. Proceedings Fourteenth International Joint Conference ArtificialIntelligence, pp. 1096{1103 Montreal, Canada.Brafman, R. I. (1997). heuristic variable-grid solution method POMDPs. Proceedings Fourteenth National Conference Artificial Intelligence, pp. 727{733Providence, RI.Bryant, R. E. (1986). Graph-based algorithms boolean function manipulation. IEEETransactions Computers, C-35 (8), 677{691.Bylander, T. (1994). computational complexity propositional STRIPS planning.Artificial Intelligence, 69, 161{204.Caines, P. E. (1988). Linear stochastic systems. Wiley, New York.Cassandra, A. R., Kaelbling, L. P., & Littman, M. L. (1994). Acting optimally partiallyobservable stochastic domains. Proceedings Twelfth National ConferenceArtificial Intelligence, pp. 1023{1028 Seattle, WA.Cassandra, A. R., Littman, M. L., & Zhang, N. L. (1997). Incremental pruning: simple, fast, exact method pomdps. Proceedings Thirteenth ConferenceUncertainty Artificial Intelligence, pp. 54{61 Providence, RI.Chapman, D. (1987). Planning conjunctive goals. Artificial Intelligence, 32 (3), 333{377.85fiBoutilier, Dean, & HanksChapman, D., & Kaelbling, L. P. (1991). Input generalization delayed reinforcementlearning: algorithm performance comparisons. Proceedings TwelfthInternational Joint Conference Artificial Intelligence, pp. 726{731 Sydney, Australia.Dantzig, G., & Wolfe, P. (1960). Decomposition principle dynamic programs. OperationsResearch, 8 (1), 101{111.Dean, T., Allen, J., & Aloimonos, Y. (1995). Artificial Intelligence: Theory Practice.Benjamin Cummings.Dean, T., & Givan, R. (1997). Model minimization Markov decision processes.Proceedings Fourteenth National Conference Artificial Intelligence, pp. 106{111 Providence, RI. AAAI.Dean, T., Givan, R., & Kim, K.-E. (1998). Solving planning problems large stateaction spaces. Proceedings Fourth International Conference AI PlanningSystems, pp. 102{110 Pittsburgh, PA.Dean, T., Givan, R., & Leach, S. (1997). Model reduction techniques computing approximately optimal solutions Markov decision processes. ProceedingsThirteenth Conference Uncertainty Artificial Intelligence, pp. 124{131 Providence, RI.Dean, T., Kaelbling, L., Kirman, J., & Nicholson, A. (1993). Planning deadlinesstochastic domains. Proceedings Eleventh National Conference ArtificialIntelligence, pp. 574{579.Dean, T., Kaelbling, L., Kirman, J., & Nicholson, A. (1995). Planning time constraints stochastic domains. Artificial Intelligence, 76 (1-2), 3{74.Dean, T., & Kanazawa, K. (1989). model reasoning persistence causation.Computational Intelligence, 5 (3), 142{150.Dean, T., & Lin, S.-H. (1995). Decomposition techniques planning stochastic domains. Proceedings Fourteenth International Joint Conference ArtificialIntelligence, pp. 1121{1127.Dean, T., & Wellman, M. (1991). Planning Control. Morgan Kaufmann, San Mateo,California.Dearden, R., & Boutilier, C. (1994). Integrating planning execution stochasticdomains. Proceedings Tenth Conference Uncertainty Artificial Intelligence, pp. 162{169 Washington, DC.Dearden, R., & Boutilier, C. (1997). Abstraction approximate decision theoretic planning. Artificial Intelligence, 89, 219{283.Dechter, R. (1996). Bucket elimination: unifying framework probabilistic inference.Proceedings Twelfth Conference Uncertainty Artificial Intelligence, pp.211{219 Portland, OR.86fiDecision-Theoretic Planning: Structural AssumptionsDechter, R. (1997). Mini-buckets: general scheme generating approximationsautomated reasoning probabilistic inference. Proceedings Fifteenth International Joint Conference Artificial Intelligence, pp. 1297{1302 Nagoya, Japan.D'Epenoux, F. (1963). Sur un probleme de production et de stockage dans l'aleatoire.Management Science, 10, 98{108.Dietterich, T. G., & Flann, N. S. (1995). Explanation-based learning reinforcementlearning: unified approach. Proceedings Twelfth International ConferenceMachine Learning, pp. 176{184 Lake Tahoe, NV.Draper, D., Hanks, S., & Weld, D. (1994a). probabilistic model action leastcommitment planning information gathering. Proceedings Tenth Conference Uncertainty Artificial Intelligence, pp. 178{186 Washington, DC.Draper, D., Hanks, S., & Weld, D. (1994b). Probabilistic planning information gathering contingent execution. Proceedings Second International ConferenceAI Planning Systems, pp. 31{36.Etzioni, O., Hanks, S., Weld, D., Draper, D., Lesh, N., & Williamson, M. (1992).approach planning incomplete information. Proceedings Third International Conference Principles Knowledge Representation Reasoning, pp.115{125 Boston, MA.Fikes, R., Hart, P., & Nilsson, N. (1972). Learning executing generalized robot plans.Artificial Intelligence, 3, 251{288.Fikes, R., & Nilsson, N. J. (1971). STRIPS: new approach application theoremproving problem solving. Artificial Intelligence, 2, 189{208.Finger, J. (1986). Exploiting Constraints Design Synthesis. Ph.D. thesis, Stanford University, Stanford.Floyd, R. W. (1962). Algorithm 97 (shortest path). Communications ACM, 5 (6),345.Fox, B. L., & Landi, D. M. (1968). algorithm identifying ergodic subchainstransient states stochastic matrix. Communications ACM, 2, 619{621.French, S. (1986). Decision Theory. Halsted Press, New York.Geiger, D., & Heckerman, D. (1991). Advances probabilistic reasoning. ProceedingsSeventh Conference Uncertainty Artificial Intelligence, pp. 118{126 LosAngeles, CA.Givan, R., & Dean, T. (1997). Model minimization, regression, propositional STRIPSplanning. Proceedings Fifteenth International Joint Conference ArtificialIntelligence, pp. 1163{1168 Nagoya, Japan.87fiBoutilier, Dean, & HanksGivan, R., Leach, S., & Dean, T. (1997). Bounded-parameter Markov decision processes.Proceedings Fourth European Conference Planning (ECP'97), pp. 234|246Toulouse, France.Goldman, R. P., & Boddy, M. S. (1994). Representing uncertainty simple planners.Proceedings Fourth International Conference Principles KnowledgeRepresentation Reasoning, pp. 238{245 Bonn, Germany.Haddawy, P., & Doan, A. (1994). Abstracting probabilistic actions. ProceedingsTenth Conference Uncertainty Artificial Intelligence, pp. 270{277 Washington,DC.Haddawy, P., & Hanks, S. (1998). Utility Models Goal-Directed Decision-TheoreticPlanners. Computational Intelligence, 14 (3).Haddawy, P., & Suwandi, M. (1994). Decision-theoretic refinement planning using inheritence abstraction. Proceedings Second International Conference AI Planning Systems, pp. 266{271 Chicago, IL.Hanks, S. (1990). Projecting plans uncertain worlds. Ph.D. thesis 756, Yale University,Department Computer Science, New Haven, CT.Hanks, S., & McDermott, D. V. (1994). Modeling dynamic uncertain world I: Symbolicprobabilistic reasoning change. Artificial Intelligence, 66 (1), 1{55.Hanks, S., Russell, S., & Wellman, M. (Eds.). (1994). Decision Theoretic Planning: Proceedings AAAI Spring Symposium. AAAI Press, Menlo Park.Hansen, E. A., & Zilberstein, S. (1998). Heuristic search cyclic AND/OR graphs.Proceedings Fifteenth National Conference Artificial Intelligence, pp. 412{418 Madison, WI.Hauskrecht, M. (1997). heuristic variable-grid solution method POMDPs. Proceedings Fourteenth National Conference Artificial Intelligence, pp. 734{739Providence, RI.Hauskrecht, M. (1998). Planning Control Stochastic Domains Imperfect Information. Ph.D. thesis, Massachusetts Institute Technology, Cambridge.Hauskrecht, M., Meuleau, N., Kaelbling, L. P., Dean, T., & Boutilier, C. (1998). Hierarchicalsolution Markov decision processes using macro-actions. ProceedingsFourteenth Conference Uncertainty Artificial Intelligence, pp. 220{229 Madison,WI.Hoey, J., St-Aubin, R., Hu, A., & Boutilier, C. (1999). SPUDD: Stochastic planningusing decision diagrams. Proceedings Fifteenth Conference UncertaintyArtificial Intelligence Stockholm. appear.Howard, R. A. (1960). Dynamic Programming Markov Processes. MIT Press, Cambridge, Massachusetts.88fiDecision-Theoretic Planning: Structural AssumptionsHoward, R. A., & Matheson, J. E. (1984). uence diagrams. Howard, R. A., & Matheson, J. E. (Eds.), Principles Applications Decision Analysis. StrategicDecisions Group, Menlo Park, CA.Kambhampati, S. (1997). Refinement planning unifying framework plan synthesis.AI Magazine, Summer 1997, 67{97.Kearns, M., Mansour, Y., & Ng, A. Y. (1999). sparse sampling algorithm nearoptimal planning large markov decision processes. Proceedings SixteenthInternational Joint Conference Artificial Intelligence Stockholm. appear.Keeney, R. L., & Raiffa, H. (1976). Decisions Multiple Objectives: PreferencesValue Tradeoffs. John Wiley Sons, New York.Kjaerulff, U. (1992). computational scheme reasoning dynamic probabilistic networks. Proceedings Eighth Conference Uncertainty AI, pp. 121{129Stanford.Knoblock, C. A. (1993). Generating Abstraction Hierarchies: Automated ApproachReducing Search Planning. Kluwer, Boston.Knoblock, C. A., Tenenberg, J. D., & Yang, Q. (1991). Characterizing abstraction hierarchies planning. Proceedings Ninth National Conference ArtificialIntelligence, pp. 692{697 Anaheim, CA.Koenig, S. (1991). Optimal probabilistic decision-theoretic planning using Markoviandecision theory. M.sc. thesis UCB/CSD-92-685, University California Berkeley,Computer Science Department.Koenig, S., & Simmons, R. (1995). Real-time search nondeterministic domains.Proceedings Fourteenth International Joint Conference Artificial Intelligence,pp. 1660{1667 Montreal, Canada.Korf, R. (1985). Macro-operators: weak method learning. Artificial Intelligence, 26,35{77.Korf, R. E. (1990). Real-time heuristic search. Artificial Intelligence, 42, 189{211.Kushmerick, N., Hanks, S., & Weld, D. (1995). Algorithm Probabilistic Planning.Artificial Intelligence, 76, 239{286.Kushner, H. J., & Chen, C.-H. (1974). Decomposition systems governed Markovchains. IEEE Transactions Automatic Control, 19 (5), 501{507.Lee, D., & Yannakakis, M. (1992). Online minimization transition systems. Proceedings24th Annual ACM Symposium Theory Computing, pp. 264{274 Victoria,BC.Lin, F., & Reiter, R. (1994). State constraints revisited. Journal Logic Computation,4 (5), 655{678.89fiBoutilier, Dean, & HanksLin, S.-H. (1997). Exploiting Structure Planning Control. Ph.D. thesis, DepartmentComputer Science, Brown University.Lin, S.-H., & Dean, T. (1995). Generating optimal policies high-level plans conditional branches loops. Proceedings Third European WorkshopPlanning (EWSP'95), pp. 187{200.Littman, M. L. (1997). Probabilistic propositional planning: Representations complexity. Proceedings Fourteenth National Conference Artificial Intelligence,pp. 748{754 Providence, RI.Littman, M. L., Dean, T. L., & Kaelbling, L. P. (1995). complexity solvingMarkov decision problems. Proceedings Eleventh Conference UncertaintyArtificial Intelligence, pp. 394{402 Montreal, Canada.Littman, M. L. (1996). Algorithms sequential decision making. Ph.D. thesis CS{96{09,Brown University, Department Computer Science, Providence, RI.Lovejoy, W. S. (1991a). Computationally feasible bounds partially observed Markovdecision processes. Operations Research, 39 (1), 162{175.Lovejoy, W. S. (1991b). survey algorithmic methods partially observed Markovdecision processes. Annals Operations Research, 28, 47{66.Luenberger, D. G. (1973). Introduction Linear Nonlinear Programming. AddisonWesley, Reading, Massachusetts.Luenberger, D. G. (1979). Introduction Dynamic Systems: Theory, Models Applications. Wiley, New York.Madani, O., Condon, A., & Hanks, S. (1999). undecidability probabilistic planninginfinite-horizon partially observable Markov decision problems. ProceedingsSixteenth National Conference Artificial Intelligence Orlando, FL. appear.Mahadevan, S. (1994). discount discount reinforcement learning: casestudy comparing R-learning Q-learning. Proceedings Eleventh International Conference Machine Learning, pp. 164{172 New Brunswick, NJ.McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. ProceedingsNinth National Conference Artificial Intelligence, pp. 634{639 Anaheim, CA.McCallum, R. A. (1995). Instance-based utile distinctions reinforcement learninghidden state. Proceedings Twelfth International Conference MachineLearning, pp. 387{395 Lake Tahoe, Nevada.McCarthy, J., & Hayes, P. J. (1969). philosophical problems standpointartificial intelligence. Machine Intelligence, 4, 463{502.90fiDecision-Theoretic Planning: Structural AssumptionsMeuleau, N., Hauskrecht, M., Kim, K., Peshkin, L., Kaelbling, L., Dean, T., & Boutilier, C.(1998). Solving large weakly coupled Markov decision processes. ProceedingsFifteenth National Conference Artificial Intelligence, pp. 165{172 Madison,WI.Moore, A. W., & Atkeson, C. G. (1995). parti-game algorithm variable resolutionreinforcement learning multidimensional state spaces. Machine Learning, 21, 199{234.Papadimitriou, C. H., & Tsitsiklis, J. N. (1987). complexity Markov chain decisionprocesses. Mathematics Operations Research, 12 (3), 441{450.Parr, R. (1998). Flexible decomposition algorithms weakly coupled Markov decisionprocesses. Proceedings Fourteenth Conference Uncertainty ArtificialIntelligence, pp. 422{430 Madison, WI.Parr, R., & Russell, S. (1995). Approximating optimal policies partially observablestochastic domains. Proceedings Fourteenth International Joint ConferenceArtificial Intelligence, pp. 1088{1094 Montreal.Parr, R., & Russell, S. (1998). Reinforcement learning hierarchies machines.Jordan, M., Kearns, M., & Solla, S. (Eds.), Advances Neural Information ProcessingSystems 10, pp. 1043{1049. MIT Press, Cambridge.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks PlausibleInference. Morgan Kaufmann, San Mateo.Pednault, E. (1989). ADL: Exploring middle ground STRIPS situation calculus. Proceedings First International Conference PrinciplesKnowledge Representation Reasoning, pp. 324{332 Toronto, Canada.Penberthy, J. S., & Weld, D. S. (1992). UCPOP: sound, complete, partial order plannerADL. Proceedings Third International Conference Principles KnowledgeRepresentation Reasoning, pp. 103{114 Boston, MA.Peot, M., & Smith, D. (1992). Conditional Nonlinear Planning. Proceedings FirstInternational Conference AI Planning Systems, pp. 189{197 College Park, MD.Perez, M. A., & Carbonell, J. G. (1994). Control knowledge improve plan quality.Proceedings Second International Conference AI Planning Systems, pp. 323{328 Chicago, IL.Poole, D. (1995). Exploiting rule structure decision making within independentchoice logic. Proceedings Eleventh Conference Uncertainty ArtificialIntelligence, pp. 454{463 Montreal, Canada.Poole, D. (1997a). independent choice logic modelling multiple agents uncertainty. Artificial Intelligence, 94 (1{2), 7{56.91fiBoutilier, Dean, & HanksPoole, D. (1997b). Probabilistic partial evaluation: Exploiting rule structure probabilisticinference. Proceedings Fifteenth International Joint Conference ArtificialIntelligence, pp. 1284{1291 Nagoya, Japan.Poole, D. (1998). Context-specific approximation probabilistic inference. ProceedingsFourteenth Conference Uncertainty Artificial Intelligence, pp. 447{454Madison, WI.Precup, D., Sutton, R. S., & Singh, S. (1998). Theoretical results reinforcement learningtemporally abstract behaviors. Proceedings Tenth European ConferenceMachine Learning, pp. 382{393 Chemnitz, Germany.Pryor, L., & Collins, G. (1993). CASSANDRA: Planning contingencies. Technicalreport 41, Northwestern University, Institute Learning Sciences.Puterman, M. L. (1994). Markov Decision Processes. John Wiley & Sons, New York.Puterman, M. L., & Shin, M. (1978). Modified policy iteration algorithms discountedMarkov decision problems. Management Science, 24, 1127{1137.Ross, K. W., & Varadarajan, R. (1991). Multichain Markov decision processessample-path constraint: decomposition approach. Mathematics Operations Research, 16 (1), 195{207.Russell, S., & Norvig, P. (1995). Artificial Intelligence: Modern Approach. Prentice Hall,Englewood Cliffs, NJ.Sacerdoti, E. D. (1974). Planning hierarchy abstraction spaces. Artificial Intelligence,5, 115{135.Sacerdoti, E. D. (1975). nonlinear nature plans. Proceedings FourthInternational Joint Conference Artificial Intelligence, pp. 206{214.Schoppers, M. J. (1987). Universal plans reactive robots unpredictable environments.Proceedings Tenth International Joint Conference Artificial Intelligence,pp. 1039{1046 Milan, Italy.Schwartz, A. (1993). reinforcement learning method maximizing undiscounted rewards. Proceedings Tenth International Conference Machine Learning,pp. 298{305 Amherst, MA.Schweitzer, P. L., Puterman, M. L., & Kindle, K. W. (1985). Iterative aggregationdisaggregation procedures discounted semi-Markov reward processes. OperationsResearch, 33, 589{605.Shachter, R. D. (1986). Evaluating uence diagrams. Operations Research, 33 (6), 871{882.Shimony, S. E. (1993). role relevance explanation I: Irrelevance statisticalindependence. International Journal Approximate Reasoning, 8 (4), 281{324.92fiDecision-Theoretic Planning: Structural AssumptionsSimmons, R., & Koenig, S. (1995). Probabilistic robot navigation partially observableenvironments. Proceedings Fourteenth International Joint ConferenceArtificial Intelligence, pp. 1080{1087 Montreal, Canada.Singh, S. P., & Cohn, D. (1998). dynamically merge Markov decision processes.Advances Neural Information Processing Systems 10, pp. 1057{1063. MIT Press,Cambridge.Singh, S. P., Jaakkola, T., & Jordan, M. I. (1994). Reinforcement learning soft stateaggregation. Hanson, S. J., Cowan, J. D., & Giles, C. L. (Eds.), Advances NeuralInformation Processing Systems 7. Morgan-Kaufmann, San Mateo.Smallwood, R. D., & Sondik, E. J. (1973). optimal control partially observableMarkov processes finite horizon. Operations Research, 21, 1071{1088.Smith, D., & Peot, M. (1993). Postponing threats partial-order planning. ProceedingsEleventh National Conference Artificial Intelligence, pp. 500{506 Washington, DC.Sondik, E. J. (1978). optimal control partially observable Markov processesinfinite horizon: Discounted costs. Operations Research, 26, 282{304.Stone, P., & Veloso, M. (1999). Team-partitioned, opaque-transition reinforcement learning.Asada, M. (Ed.), RoboCup-98: Robot Soccer World Cup II. Springer Verlag, Berlin.Sutton, R. S. (1995). TD models: Modeling world mixture time scales.Proceedings Twelfth International Conference Machine Learning, pp. 531{539 Lake Tahoe, NV.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press,Cambridge, MA.Tash, J., & Russell, S. (1994). Control strategies stochastic planner. ProceedingsTwelfth National Conference Artificial Intelligence, pp. 1079{1085 Seattle,WA.Tatman, J. A., & Shachter, R. D. (1990). Dynamic programming uence diagrams.IEEE Transactions Systems, Man, Cybernetics, 20 (2), 365{379.Tesauro, G. J. (1994). TD-Gammon, self-teaching backgammon program, achieves masterlevel play. Neural Computation, 6, 215{219.Thrun, S., Fox, D., & Burgard, W. (1998). probabilistic approach concurrent mappinglocalization mobile robots. Machine Learning, 31, 29{53.Thrun, S., & Schwartz, A. (1995). Finding structure reinforcement learning. Tesauro,G., Touretzky, D., & Leen, T. (Eds.), Advances Neural Information ProcessingSystems 7 Cambridge, MA. MIT Press.Warren, D. (1976). Generating conditional plans programs. Proceedings AISBSummer Conference, pp. 344{354 University Edinburgh.93fiBoutilier, Dean, & HanksWatkins, C. J. C. H., & Dayan, P. (1992). Q-learning. Machine Learning, 8, 279{292.Weld, D. S. (1994). introduction least commitment planning. AI Magazine, Winter1994, 27{61.White III, C. C., & Scherer, W. T. (1989). Solutions procedures partially observedMarkov decision processes. Operations Research, 37 (5), 791{797.Williamson, M. (1996). value-directed approach planning. Ph.D. thesis 96{06{03,University Washington, Department Computer Science Engineering.Williamson, M., & Hanks, S. (1994). Optimal planning goal-directed utility model.Proceedings Second International Conference AI Planning Systems, pp.176{180 Chicago, IL.Winston, P. H. (1992). Artificial Intelligence, Third Edition. Addison-Wesley, Reading,Massachusetts.Yang, Q. (1998). Intelligent Planning : Decomposition Abstraction Based Approach.Springer Verlag.Zhang, N. L., & Liu, W. (1997). model approximation scheme planning partiallyobservable stochastic domains. Journal Artificial Intelligence Research, 7, 199{230.Zhang, N. L., & Poole, D. (1996). Exploiting causal independence Bayesian networkinference. Journal Artificial Intelligence Research, 5, 301{328.94fiJournal Artificial Intelligence Research 11 (1999) 335{360Submitted 8/98; published 11/99Committee-Based Sample SelectionProbabilistic ClassifiersShlomo Argamon-EngelsonDepartment Computer ScienceJerusalem College Technology, Machon LevP.O.B. 16031Jerusalem 91160, Israelargamon@mail.jct.ac.ilIdo DaganDepartment Mathematics Computer ScienceBar-Ilan University52900 Ramat Gan, Israeldagan@cs.biu.ac.ilAbstractmany real-world learning tasks expensive acquire sucient number labeledexamples training. paper investigates methods reducing annotation costsample selection. approach, training learning program examines manyunlabeled examples selects labeling informativestage. avoids redundantly labeling examples contribute little new information.work follows previous research Query Committee, extendscommittee-based paradigm context probabilistic classification. describefamily empirical methods committee-based sample selection probabilistic classification models, evaluate informativeness example measuring degreedisagreement several model variants. variants (the committee) drawnrandomly probability distribution conditioned training set labeled far.method applied real-world natural language processing task stochastic part-of-speech tagging. find variants method achieve significantreduction annotation cost, although computational eciency differs. particular,simplest variant, two member committee parameters tune, gives excellentresults. also show sample selection yields significant reduction sizemodel used tagger.1. IntroductionAlgorithms supervised concept learning build classifiers concept based givenset labeled examples. many real-world concept learning tasks, however, acquiringlabeled training examples expensive. Hence, objective develop automatedmethods reduce training cost within framework active learning,learner control choice examples labeled usedtraining.c 1999 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiArgamon & Dagantwo main types active learning. first uses membership queries,learner constructs examples asks teacher label (Angluin, 1988; MacKay,1992b; Plutowski & White, 1993). approach provides proven computationaladvantages (Angluin, 1987), always applicable since always possibleconstruct meaningful informative unlabeled examples training. diculty mayovercome large set unlabeled training data available. case secondtype active learning, sample selection, often applied: learner examines manyunlabeled examples, selects informative ones learning (Seung, Opper,& Sompolinsky, 1992; Freund, Seung, Shamir, & Tishby, 1997; Cohn, Atlas, & Ladner,1994; Lewis & Catlett, 1994; Lewis & Gale, 1994).paper, address problem sample selection training probabilisticclassifier. Classification framework performed probability-based model which,given input example, assigns score possible classification selectshighest score.research follows theoretical work sample selection Query Committee(QBC) paradigm (Seung et al., 1992; Freund et al., 1997). propose novel empiricalscheme applying QBC paradigm probabilistic classification models (allowing labelnoise), addressed original QBC framework (see Section 2.2).committee-based selection scheme, learner receives stream unlabeled examplesinput decides whether ask label not. end,learner constructs `committee' (two more) classifiers based statisticscurrent training set. committee member classifies candidate example,learner measures degree disagreement among committee members. exampleselected labeling depending degree disagreement, according selectionprotocol.previous work (Dagan & Engelson, 1995; Engelson & Dagan, 1996b) presentedparticular selection protocol probabilistic concepts. paper extends previouswork mainly generalizing selection scheme comparing variety differentselection protocols (a preliminary version appeared Engelson & Dagan, 1996a).1.1 Application Natural Language ProcessingMuch early work sample selection either theoretical nature,tested toy problems. We, however, motivated complex, real-world problemsarea statistical natural language text processing. work addressestask part-of-speech tagging, core task statistical natural language processing(NLP). work sample selection natural language tasks mainly focusedtext categorization problems, works Lewis Catlett (1994), LiereTadepalli (1997), McCallum Nigam (1998).statistical NLP, probabilistic classifiers often used select preferred analysislinguistic structure text, syntactic structure (Black, Jelinek, Lafferty,Magerman, Mercer, & Roukos, 1993), word categories (Church, 1988), word senses (Gale,336fiCommittee-Based Sample Selection Probabilistic ClassifiersChurch, & Yarowsky, 1993). parameters classification model estimatedtraining corpus (a collection text).common case supervised training, learner uses corpussentence manually annotated correct analysis. Manual annotation typicallyexpensive. consequence, large annotated corpora exist, mainly English language, covering genres text. situation makes dicult applysupervised learning methods languages English, adapt systems different genres text. Furthermore, infeasible many cases develop new supervisedmethods require annotations different currently available.cases, manual annotation avoided altogether, using self-organized methods, shown part-of-speech tagging English Kupiec (1992). EvenKupiec's tagger, though, manual (and somewhat unprincipled) biasing initial modelnecessary achieve satisfactory convergence. Elworthy (1994) Merialdo (1991)investigated effect self-converging re-estimation part-of-speech taggingfound initial manual training needed. generally, supervisedtraining provided, better results. fact, fully unsupervised methodsapplicable many NLP tasks, perhaps even part-of-speech tagginglanguages. Sample selection appropriate way reduce cost annotating corpora,easy obtain large volumes raw text smaller subsets selectedannotation.applied committee-based selection learning Hidden Markov Models (HMMs)part-of-speech tagging English sentences. Part-of-speech tagging task labelingword sentence appropriate part speech (for example, labelingoccurrence word `hand' noun verb). task non-trivial since determiningword's part speech depends linguistic context. HMMs used extensivelytask (e.g., Church, 1988; Merialdo, 1991), cases trained corporamanually annotated correct part speech word.experiments part-of-speech tagging, described Section 6.5, show using committeebased selection results substantially faster learning rates, enabling learner achievegiven level accuracy using far fewer training examples sequential training usingtext.2. Backgroundobjective sample selection select examples informative future. might determine informativeness example? Oneapproach derive explicit measure expected amount information gainedusing example (Cohn, Ghahramani, & Jordan, 1995; MacKay, 1992b, 1992a).example, MacKay (1992b) assesses informativeness example, neural networklearning task, expected decrease overall variance model's prediction,training example. Explicit measures appealing, since attemptgive precise characterization information content example. Also, membership querying, explicit formulation information content sometimes enables finding337fiArgamon & Daganinformative examples analytically, saving cost searching example space.use explicit methods may limited, however, since explicit measures generally(a) model-specific, (b) complex, often requiring various approximations practical,(c) depend accuracy current hypothesis given step.alternative measuring informativeness example explicitly measureimplicitly, quantifying amount uncertainty classification examplegiven current training data. informativeness example evaluated respectmodels derived training data stage learning. One approach usesingle model based training data seen far. approach taken LewisGale (1994), training binary classifier. select training exampleswhose classification probability closest 0.5, i.e, examples currentbest model uncertain.order better evaluate classification uncertainty respect entire spacepossible models, one may instead measure classification disagreement among sampleset possible models (a committee). Using entire model space enables measuringdegree training entails single (best) classification example.hand, referring single model measures degree modelcertain classification. example, classifier sucient training predicting ips coin heads probability 0.55 always predict heads, hencemake mistakes 45% time. However, although classifier quite uncertaincorrectness classification, additional training improve accuracy.two main approaches generating committee order evaluate exampleuncertainty: version space approach random sampling approach. versionspace approach, pursued Cohn et al. (1994) seeks choose committee membersborder space models allowed training data (the version space,Mitchell, 1982). Thus models chosen committee farpossible consistent training data. ensures modelsdisagree example whenever training example would restrict version space.version space approach dicult apply since finding models edgeversion space non-trivial general. Furthermore, approach directlyapplicable case probabilistic classification models, almost modelspossible, though equally probable, given training. alternative random sampling, exemplified Query Committee algorithm (Seung et al., 1992; Freundet al., 1997), inspired paper. approach, models sampled randomlyset possible models, according probability models giventraining data. work applies random sampling approach probabilistic classifierscomputing approximation posterior model distribution given training data,generating committee members distribution. McCallum Nigam (1998)use similar approach sample selection text categorization using naive Bayes classifier. primary difference skew example selection using density-weightedsampling, documents similar many documents trainingset selected labeling higher probability.338fiCommittee-Based Sample Selection Probabilistic ClassifiersMatan (1995) presents two methods random sampling. first method,trains committee members different subsets training data. second method,neural network models, Matan generates committee members backpropagation training using different initial weights networks reach different local minima.similar approach taken Liere Tadepalli (1997), applied committee-basedselection approach text categorization using Winnow learning algorithm (Littlestone,1988) learns linear classifiers. represented model space set classifiers (the model set). classifier model set learns independently labeledexamples, initialized different initial hypothesis (thus pointset gives selection possible hypotheses given training data). Labeling decisionsperformed based two models chosen random model set. modelsdisagree document's class, document's label requested, modelsspace updated.2.1 Query Committeementioned above, paper follows theoretical work sample selection QueryCommittee (QBC) paradigm (Seung et al., 1992; Freund et al., 1997). methodproposed learning binary (non-probabilistic) concepts cases exists priorprobability distribution measure concept class. QBC selects `informative' trainingexamples stream unlabeled examples. example selected learnerqueries teacher correct label adds training set. examplesselected training, restrict set consistent concepts, i.e, set conceptslabel training examples correctly (the version space).simple version QBC, analyzed Freund et al. (1997) (see alsosummary Freund, 1994), uses following selection algorithm:1. Draw unlabeled input example random probability distribution example space.2. Select random two hypotheses according prior probability distribution concept class, restricted set consistent concepts.3. Select example training two hypotheses disagree classification.Freund et al. prove that, assumptions, algorithm achieves exponentialreduction number labeled examples required achieve desired classificationaccuracy, compared random selection training examples. speedup achievedalgorithm tends select examples split version space two partssimilar size. One parts eliminated version space examplecorrect label added training set.2.2 Selection Probabilistic Classifiersaddress problem sample selection training probabilistic classifier. Classification framework performed probabilistic model which, given input339fiArgamon & Daganexample, assigns probability (or probability-based score) possible classificationselects best classification. Probabilistic classifiers fall within frameworkaddressed theoretical QBC work. Training probabilistic classifier involves estimating values model parameters determine probability estimate possibleclassification example. expect cases optimal classifierassign highest probability correct class, guaranteed always occur.Accordingly, notion consistent hypothesis generally applicable probabilisticclassifiers. Thus, posterior distribution classifiers given training data cannotdefined restriction prior set consistent hypotheses. Rather, withinBayesian framework, posterior distribution defined statistics trainingset, assigning higher probability classifiers likely given statistics.discuss desired properties examples selected training. Generally speaking, training example contributes data several statistics, turndetermine estimates several parameter values. informative example thereforeone whose contribution statistics leads useful improvement parameter estimates. Assuming existence optimal classification model given concept(such maximum likelihood model), identify three properties parametersacquiring additional statistics beneficial:1. current estimate parameter uncertain due insucient statisticstraining set. uncertain estimate likely far true valueparameter cause incorrect classification. Additional statistics would bringestimate closer true value.2. Classification sensitive changes current estimate parameter. Otherwise, acquiring additional statistics unlikely affect classification thereforebeneficial.3. parameter takes part calculating class probabilities large proportionexamples. Parameters relevant classifying examples, determined probability distribution input examples, low utility futureestimation.committee-based selection scheme, describe below, tends selectexamples affect parameters three properties. Property 1 addressedrandomly picking parameter values committee members posterior distributionparameter estimates (given current statistics). statistics parameterinsucient variance posterior distribution estimates large, hencelarge differences values parameter picked different committeemembers. Note property 1 addressed uncertainty classificationjudged relative single model (as in, e.g., Lewis & Gale, 1994). approachcaptures uncertainty respect given parameter values, sense property 2,model uncertainty choice values first place (the usesingle model criticized Cohn et al., 1994).Property 2 addressed selecting examples committee members highly disagree classification. Thus, algorithm tends acquire statistics uncertainty340fiCommittee-Based Sample Selection Probabilistic Classifiersparameter estimates entails uncertainty actual classification (this analogous splittingversion space QBC). Finally, property 3 addressed independently examininginput examples drawn input distribution. way, implicitlymodel expected utility statistics classifying future examples.2.3 Paper Outlinefollowing section defines basic concepts notation use restpaper. Section 4 presents general selection scheme along variant selectionalgorithms. next two sections demonstrate effectiveness sample selectionscheme. Section 5 presents results artificial \colorful coin ipper" problem, providingsimple illustration operation proposed system. Section 6 presents resultstask stochastic part-of-speech tagging, demonstrating usefulness committeebased sample selection real world.3. Definitionsconcern paper minimize number labeled examples neededlearn classifier accurately classifies input examples e classes c 2 C , Cknown set possible classes. learning, stream unlabeled examplessupplied free, examples drawn unknown probability distribution.cost, however, learning algorithm obtain true label given example.objective reduce cost much possible, still learning accurateclassifier.address specific case probabilistic classifiers, classification donebasis score function, FM (c; e), assigns score possible classinput example. classifier assigns input example class highest score.FM determined probabilistic model . many applications, FM conditionalprobability function, PM (cje), specifying probability class given example.Alternatively, score functions denote likelihood class may used(such odds ratio). particular type model used classification determinesspecific form score, function features example.probabilistic model , thus score function FM , defined set parameters, fffi g, giving probabilities various possible events. example, modelpart-of-speech tagging contains parameters probability particular wordverb noun. training, values parameters estimatedset statistics, , extracted training set labeled examples. particular modeldenoted = faig, ai specific value corresponding ffi .4. Committee-Based Sample Selectionsection describes algorithms apply committee-based approach evaluating classification uncertainty input example. learning algorithm evaluates341fiArgamon & Daganexample giving committee containing several versions, copies, classifier, `consistent' training data seen far. greater agreementcommittee members classification example, greater certaintyclassification. training data entails specific classification highcertainty, (in probabilistic sense) versions classifier consistentdata produce classification. example selected labeling, therefore,committee members disagree appropriate classification.4.1 Generating Committeegenerate committee k members, randomly choose k models accordingposterior distribution P (M jS ) possible models given current training statistics.sampling performed depends form distribution, turndepends form model. Thus implementing committee-based selectionparticular problem, appropriate sampling procedure must devised. illustrationcommittee generation, rest section describes sampling process modelsconsisting independent binomial parameters multinomial parameter groups.Consider first model containing single binomial parameter ff (the probabilitysuccess), estimated value a. statistics model given N ,number trials, x, number successes trials.Given N x, `best' model parameter value estimated severalestimation methods. example, maximum likelihood estimate (MLE) ff = Nx ,giving model = fff = Nx g. generating committee models, however,interested `best' model, rather sampling distribution models givenstatistics. example, need sample posterior density estimatesff, namely p(ff = ajS ). binomial case, density beta distribution (Johnson,1970). Sampling distribution yields set estimates scattered around Nx (assuminguniform prior), variance estimates gets smaller N gets larger.estimate participates different member committee. Thus, statisticsestimating parameter, closer estimates used different modelscommittee.consider model consisting single group interdependent parameters defining multinomial. case, posterior Dirichlet distribution (Johnson, 1972).Committee members generated sampling joint distribution, giving valuesmodel parameters.models consisting set independent binomials multinomials, samplingP (M jS ) amounts sampling parameters independently. modelscomplex dependencies among parameters sampling may dicult. practice,though, may possible make enough independence assumptions make samplingfeasible.Sampling posterior generates committee members whose parameter estimates differbased low training counts tend agree based highcounts. classification example relies parameters whose estimates com342fiCommittee-Based Sample Selection Probabilistic Classifiersunlabeled input example e:1. Draw 2 models randomly P (M jS ), statistics acquiredpreviously labeled examples;2. Classify e model, giving classifications c1 c2;3. c1 6= c2, select e annotation;4. e selected, get correct label update accordingly.Figure 1: two member sequential selection algorithm.mittee members differ, differences affect classification, example wouldselected learning. leads selecting examples contribute statisticscurrently unreliable estimates also effect classification. Thus addressProperties 1 2 discussed Section 2.2.4.2 Selection AlgorithmsWithin committee-based paradigm exist different methods selecting informative examples. Previous research sample selection used either sequential selection(Seung et al., 1992; Freund et al., 1997; Dagan & Engelson, 1995), batch selection (Lewis& Catlett, 1994; Lewis & Gale, 1994). present general algorithms sequential batch committee-based selection. cases, assumeselection algorithm applied small amount labeled initial training supplied, orderinitialize training statistics.4.2.1 Two Member Sequential SelectionSequential selection examines unlabeled examples supplied, one one,estimates expected information gain. examples determined sucientlyinformative selected training. simply, choose committee size twoposterior distribution models, select example two modelsdisagree classification. gives parameter-free, two member sequential selectionalgorithm, shown Figure 1. basic algorithm parameters.4.2.2 General Sequential Selectiongeneral selection algorithm results from:Using larger number k committee members, order evaluate example informativeness precisely,refined example selection criteria,343fiArgamon & Daganunlabeled input example e:1. Draw k models fMi g randomly P (M jS ) (possibly using temperature t);2. Classify e model Mi giving classifications fci g;3. Measure disagreement D(e) based fci g;4. Decide whether select e annotation, based valueD(e);5. e selected, get correct label update accordingly.Figure 2: general sequential selection algorithm.Tuning frequency selection replacing P (M jS ) distributiondifferent variance. effect adjusting variability among committeemembers chosen. many cases (eg., HMMs, described Section 6 below)implemented parameter (called temperature), used multipliervariance posterior parameter distribution.gives general sequential selection algorithm, shown Figure 2.easy see two member sequential selection special case general sequential selection. order instantiate general algorithm larger committees, needfix general measure D(e) disagreement (step 3), decision method selectingexamples according disagreement (step 4).measure disagreement entropy distribution classifications `voted for'committee members. vote entropy natural measure quantifyinguniformity classes assigned example different committee members1 .normalize entropy bound maximum possible value (log min(k; jcj)),giving value 0 1. Denoting number committee members assigningclass c input example e V (c; e), normalized vote entropy is:X V (c; e) V (c; e)1D(e) = ,log min(k; jC j) c k log kNormalized vote entropy value one committee members disagree,value zero agree, taking intermediate values cases partial agreement.consider two alternatives selection criterion (step 4). simplestthresholded selection, example selected annotation normalized voteentropy exceeds threshold . Another alternative randomized selection,example selected annotation based ip coin biased accordingvote entropy|a higher vote entropy corresponding higher probability selection.1. McCallum Nigam (1998) suggested alternative measure, KL-divergence mean(Pereira, Tishby, & Lee, 1993). clear whether measure advantage simplerentropy function.344fiCommittee-Based Sample Selection Probabilistic Classifiersbatch B N examples:1. example e B :(a) Draw k models randomly P (M jS );(b) Classify e model, giving classifications fcig;(c) Measure disagreement D(e) e based fcig;2. Select annotation examples highest D(e);3. Update statistics selected examples.Figure 3: batch selection algorithm.use simple model selection probability linear function normalized voteentropy: P (e) = gD(e), calling g entropy gain2 .4.2.3 Batch Selectionalternative sequential selection batch selection. Rather evaluating examplesindividually informativeness large batch N examples examined,best selected annotation. batch selection algorithm given Figure 3.procedure repeated sequentially successive batches N examples, returningstart corpus end. N equal size corpus, batch selectionselects globally best examples corpus stage (as Lewis & Catlett, 1994).Batch selection certain theoretical drawbacks (Freund et al., 1997), particularlyconsider distribution input examples. However, shown McCallumNigam (1998), distribution input examples modeled takenaccount selection. combining disagreement measuremeasure example density, produces good results batch selection (this workdiscussed detail Section 7.2). separate diculty batch selectioncomputational disadvantage must look large number examplesselecting any. batch size decreased, batch selection behaves similarlysequential selection.5. Example: Colorful Coin Flipperillustrative example learning task, define colorful coin- ipper (CCF)machine contains infinite number coins various colors. machine choosescoins ip, one one, color coin fixed (unknown) probabilitychosen. coin ipped, comes heads probability determined solelycolor. ips coin, machine tells learner color coin chosen2. selection method used (Dagan & Engelson, 1995) randomized sequential selection usinglinear selection probability model, parameters k, g.345fiArgamon & Daganip. order know outcome ip, however, learner must pay machine.training, learner may choose colors coins whose outcomes examine.objective selective sampling choose minimize training cost (numberips examined) required attain given prediction accuracy ip outcomes.case CCF, example e coin ip, characterized color,class c either heads tails. Note require ips given color alwaysclass. Therefore best hope classify accordinglikely class color.CCF, define model whose parameters heads probabilitiescoins particular color. So, CCF three colors, one possible model would= fr = 0:8; g = 0:66; b = 0:2g, giving probabilities heads red, green, bluecoins, respectively. coin given color classified `heads' score (givendirectly appropriate model parameter) > 12 , `tails' otherwise.5.1 Implementation Sample SelectionTraining model CCF amounts counting proportion heads color,providing estimates heads probabilities. complete training every coin ip trainingsequence examined added counts. sample selection seek labelcount training ips colors additional counts likely improvemodel's accuracy. Useful colors train either trainingexamples far seen, whose current probability estimates near 0.5(cf. Section 2.2).Recall sample selection build committee sampling models P (M jS ).case CCF, model parameters ffi (the heads probabilities differentcolors) independent, sampling P (M jS ) amounts sampling independentlyparameters.form posterior distribution P (ffi = ai jS ) given beta distribution, found technically easier use normal approximation, foundsatisfactory practice. Let Ni number coin ips color seen far, ninumber ips came heads. approximate P (ffi = ai jS ) truncated normal distribution (restricted [0,1]), estimated mean = Nn variancei2 = (1N, ). approximation made easy also incorporate `temperature' parameter (as Section 4.2.2), used multiplier variance estimate i2 . Thus,actually approximate P (ffi = aijS ) truncated normal distribution meanvariance i2 t. Sampling distribution done using algorithm given Press,Flannery, Teukolsky, Vetterling (1988) sampling normal distribution.5.2 Vote EntropyCCF useful illustrate importance determining classification uncertaintyusing vote entropy committee models rather using entropyclass distribution given single model (as discussed Section 2). Consider CCF346fiCommittee-Based Sample Selection Probabilistic ClassifiersModel0123Red0.55 (heads)0.55 (heads)0.60 (heads)0.60 (heads)Blue0.45 (tail)0.45 (tail)0.55 (heads)0.55 (heads)(a)Green0.48 (heads)0.75 (tail)0.85 (tail)0.95 (tail)Color D(e) ACDERed0.0 0.98Blue1.0 0.99Green 0.81 0.68(b)Figure 4: (a) committee CCF models. (b) resultant vote entropy color.CCF results 50 colorsCCF results 100 colors200PTMCommittee-Based SamplingComplete TrainingPTMCommittee-Based SamplingComplete Training200150Selected trainingSelected training150100100505000.500.550.60.65Desired accuracy0.70.750.80.5(a)0.550.60.65Desired accuracy0.70.750.8(b)Figure 5: CCF results random CCFs 50 100 different coin colors. Resultsaveraged 4 different CCFs, comparing complete training twomember sample selection. figures show amount training requireddesired classification accuracy: (a) 50 colors, (b) 100 colors.three coin colors, red, blue, green. Suppose 4-member committee Figure 4(a)generated. committee, estimate color vote entropy D(e), wellaverage class distribution entropies given individual models(ACDE), given Figure 4(b).compare entropies red blue, example, see entropiesexpected class probability distribution quite high (since estimatedclass probabilities near 0.5). However, consider vote entropies (overassigned classes), blue maximal entropy, since range possible models straddlesclass boundary (0.5), red minimal entropy, since range possible modelsstraddle class boundary. is, quite certain optimal classificationred \heads". also see green higher vote entropy red, althoughaverage class distribution entropy lower. shows importance using vote entropyselection.347fiArgamon & DaganCCF frequency selection150 color CCF100 color CCF0.90.8Selection frequency0.70.60.50.40.30.20.10020406080100120Selected training140160180200Figure 6: Frequency selection vs. amount selected training CCFs 50 100colors, averaged 4 different CCFs.5.3 Resultssimulated sample selection simple CCF model order illustrateproperties. following, generated random CCFs fixed number coinsrandomly generating occurrence probabilities heads probabilities coin color.generated learning curves complete training, input examples, twomember sample selection, using 50 coin- ips initial training. complete trainingsample selection run coin- ip sequences. Accuracy measuredcomputing expected accuracy (assuming infinite test set) MLE modelgenerated selected training. figures also show accuracy theoreticalperfectly trained model (PTM) knows parameters perfectly.Figure 5 summarizes average results 4 comparison runs complete vs. sampleselection CCFs 50 100 coins. Figures 5(a) (b), compare amountselected training required reach given desired accuracy. see casessoon sample selection starts operating, eciency higher complete training,gap increases size greater accuracy desired. Figure 6, examinecumulative frequency selection (ratio number selected examplestotal number examples seen) learning progresses. see exponential decreasefrequency selection, expected case QBC non-probabilistic models(analyzed Seung et al., 1992; Freund et al., 1997).6. Application: Stochastic Part-Of-Speech Taggingapplied committee-based selection real-world task learning Hidden MarkovModels (HMMs) part-of-speech tagging English sentences. Part-of-speech taggingtask labeling word sentence appropriate part speech (forexample, labeling occurrence word `hand' noun verb). task nontrivial since determining word's part speech depends linguistic context. HMMs348fiCommittee-Based Sample Selection Probabilistic Classifiersused extensively task (e.g., Church, 1988; Merialdo, 1991), casestrained corpora manually annotated correct part speechword.6.1 HMMs Part-Of-Speech Taggingfirst-order Hidden Markov Model (HMM) probabilistic finite-state string generator(Rabiner, 1989), defined set states Q = fqi g, set output symbols , settransition probabilities P (qi !qj ) possible transition states qi qj , setoutput probabilities P (ajq) state q output symbol 2 , distinguishedstart state q0 . probability string = a1a2 generated HMMgiven!nXP (qi,1 !qi )P (aijqi ) ;q1 qn 2Qn i=1sum, paths HMM, joint probability path traversedoutput given string. contrast ordinary Markov Models, HMMknown sequence states generated given string (hence term `hidden').HMMs used widely speech language processing. particular, HMMused provide classification model sequence elements: need classifyelement sequence, encode possible class state HMM. TrainingHMM amounts estimating values transition output probabilities.Then, given sequence classification, assume generated HMMcompute likely state sequence string, using Viterbi algorithm3 (Viterbi,1967).HMM used part-of-speech tagging words encoding possible partof-speech tag, (noun, verb, adjective, etc.), HMM state. output probabilities,P (wjt), give probability producing word w language conditionedcurrent tag t. transition probabilities, P (t1!t2), give probability generatingword tag t2 given previous word's tag t1 . constitutes weaksyntactic model language. model often termed tag-bigram model4 .Given input word sequence W = w1 wn , seek likely tag sequence= t1 tn :)arg maxT P (T jW ) = arg maxT PP(T;W(W )= arg maxT P (T; W )3. alternative classification scheme compute likely state individual element(instead likely state sequence) Forward-Backward algorithm (Rabiner, 1989) (alsocalled Baum-Welch algorithm Baum, 1972). address alternative,computationally expensive typically used part-of-speech tagging. possible,however, apply committee-based selection method also type classification.4. noted practical implementations part-of-speech tagging often employ tag-trigrammodel, probability tag depends last two tags rather last one.committee-based selection method apply bigram model easily applied alsotrigram case.349fiArgamon & Dagansince P (W ) constant. Thus seek maximizesP (T; W ) =ni=1P (ti,1!ti )P (wijti )technical convenience, use Bayes' theorem replace P (wijti ) term termP (t jw )P (w ), noting P (wi) effect maximization tag sequencesP (t )therefore omitted (following Church, 1988). parameters part-of-speech model,then, are: tag probabilities P (ti), transition probabilities P (ti,1!ti ), lexical probabilitiesP (tjw).Supervised training tagger performed using tagged corpus (text collection),manually labeled correct part-of-speech word. Maximum likelihood estimates (MLEs) parameters easily computed word tag countscorpus. example, MLE P (t) fraction tag occurrences corpus tag t, whereas P (tjw) ratio count word wlabeled tag total count w. committee-based selection scheme,counts used also compute posterior distributions parameter estimates,discussed Section 6.2.next describe application committee-based selection scheme HMMclassification framework. First discuss sample posterior distributions HMM parameters P (ti !tj ) P (tjw), given training statistics.5discuss question define example training|an HMM deals (inprinciple) infinite strings; substrings make decisions labeling? Finally,describe measure amount disagreement committee members.6.2 Posterior Distributions Multinomial Parameterssection, consider select committee members based posterior parameter distributions P (ffi = aijS ) HMM, assuming uniform prior. First noteparameters HMM define set multinomial probability distributions. multinomial corresponds conditioning event values given correspondingset conditioned events. example, transition probability parameter P (ti !tj )conditioning event ti conditioned event tj .Let fui g denote set possible values given multinomial variable (e.g.,possible tags given word), let = fni g denote set statistics extractedtraining set, ni number times value ui appears trainingPset. denote total number appearances multinomial variable N = ni .parameters whose distributions wish estimate ffi = P (ui ).maximum likelihood estimate multinomial's distribution parameters,ffi , ff^i = nN . practice, estimator usually smoothed way compensatedata sparseness. smoothing typically reduces estimates values positive5. sample model space tag probability parameters, since amount data tagfrequencies large enough make MLEs quite definite.350fiCommittee-Based Sample Selection Probabilistic Classifierscounts gives small positive estimates values zero count. simplicity,first describe approximation P (ffi = aijS ) unsmoothed estimator6 .posterior P (ffi = ai jS ) Dirichlet distribution (Johnson, 1972); easeimplementation, used generalization normal approximation described(Section 5.1) binomial parameters. assume first multinomial collectionindependent binomials, corresponds single value ui multinomial;separately apply constraint parameters binomials sum1. binomial, sample approximate distribution (possiblytemperature t). Then, generate particular multinomial distribution, renormalizesampled parameters sum 1.sample smoothed estimator, first note estimator smoothedmodel (interpolating uniform);ff^Si = (1(1,,))Nni++1 smoothing parameter controlling amount smoothing (in experiments = 0:05), number possible values given multinomial.sample truncated normal approximation (as Section 5)smoothed estimate, i.e, mean = ff^Si variance 2 = (1N,) . Normalizationmultinomial applied above.Finally, generate random HMM given statistics , note parametersP (ti !tj ) P (tjw) independent other. thus independently choose valuesHMM's parameters multinomial distribution.6.3 Examples HMM TrainingTypically, concept learning problems formulated set trainingexamples independent other. training HMM, however,state/output pair dependent previous state, presented (in principle)single infinite input string training. order perform sample selection,must divide infinite string (short) finite strings.part-of-speech tagging, problem may solved considering sentenceindividual example. generally, break text point taggingunambiguous. particular, common lexicon specifies partsof-speech possible word (i.e, parameters P (tjw) positive).bigram tagging, use unambiguous words (those one possible part speech)example boundaries. Similar natural breakpoints occur HMM applications;example, speech recognition consider different utterances separately.cases HMM learning, natural breakpoints occur, heuristicapplied, preferring break `almost unambiguous' points input.6. implementation smooth MLE interpolation uniform probability distribution,following Merialdo (1991). Adaptation P (ffi = ai ) smoothed version estimator givenbelow.j351fiArgamon & Dagan6.4 Quantifying DisagreementRecall selection algorithms decide whether select example basedmuch committee members disagree labeling. discussed Section 4.2.2,suggest use vote entropy measuring classification disagreement committee members. idea supported fact found empiricallyaverage normalized vote entropy words tagger (after training) classified correctly 0.25, whereas average entropy incorrectly classified words0.66. demonstrates vote entropy useful measure classification uncertainty(likelihood error) based training data.bigram tagging, example consists sequence several words. implementation, measured vote entropy separately word sequence, useaverage vote entropy sequence measurement disagreementexample. use average entropy rather entropy entire sequence,number committee members small respect total numberpossible tag sequences.6.5 Resultspresent results applying committee-based sample selection bigram part-ofspeech tagging, comparing complete training examples corpus. Evaluation performed using University Pennsylvania tagged corpus ACL/DCICD-ROM I. ease implementation, used complete (closed) lexicon containswords corpus.7 Approximately 63% word occurrences corpusambiguous lexicon (have one possible part-of-speech).committee-based selection algorithm initialized using first 1,000 wordscorpus, examined following examples corpus possiblelabeling. training set consisted first million words corpus, sentenceordering randomized compensate inhomogeneity corpus composition. test setseparate portion corpus consisting 20,000 words, starting first1,000,000.compared amount training required different selection methods achievegiven tagging accuracy test set, amount training taggingaccuracy measured ambiguous words.86.5.1 Labeling Efficiency7. use lexicon provided Brill's part-of-speech tagger (Brill, 1992). actual applicationcomplete lexicon would available, results using complete lexicon valid, evaluationcomplete training committee-based selection comparative.8. work tagging measured accuracy words, ambiguous ones. Completetraining system 1,000,000 words gave us accuracy 93.5% ambiguous words,corresponds accuracy 95.9% words test set, comparable published resultsbigram tagging.352fiCommittee-Based Sample Selection Probabilistic Classifiers40000Batch selection (m=5; N=100)Thresholded selection (th=0.3)Randomized selection (g=0.5)Two member selectionComplete training35000Selected training3000025000200001500010000500000.850.860.870.880.89Accuracy0.90.910.920.93Figure 7: Labeled training versus classification accuracy. batch, random, thresholded runs, k = 5 = 50.Figure 7 presents comparison results several selection methods. reported parameter settings best found selection method manual tuning.Figure 7 shows advantage sample selection gives regard annotation cost.example, complete training requires annotated examples containing 98,000 ambiguouswords achieve 92.6% accuracy, selection methods require 18,000{25,000ambiguous words achieve accuracy. also find that, first approximation,methods considered give similar results. Thus, seems refined choiceselection method crucial achieving large reductions annotation cost.6.5.2 Computational EfficiencyFigure 8 plots classification accuracy versus number words examined, insteadselected. Complete training clearly ecient terms, learnsexamples examined. selective methods similar, though two member selection seemsrequire somewhat fewer examples examination methods. Furthermore,since two committee members used method computationally ecientevaluating examined example.6.5.3 Model Sizeability committee-based selection focus informative partstraining corpus analyzed Figure 9. examined number lexical bigram353fiArgamon & Dagan400000Batch selection (m=5; N=100)Thresholded selection (th=0.3)Randomized selection (g=0.5)Two member selectionComplete training350000Examined training3000002500002000001500001000005000000.850.860.870.880.89Accuracy0.90.910.920.93Figure 8: Examined training (both labeled unlabeled) versus classification accuracy.batch, random, thresholded runs, k = 5 = 50.200001600Two member selectionComplete training18000Two member selectionComplete training140014000Bigram model sizeLexical model size16000120001000080006000120010008006004000400200000.850.860.870.880.89Accuracy0.90.910.922000.850.93(a)0.860.870.880.890.9Accuracy0.910.920.930.94(b)Figure 9: Numbers frequency counts > 0, plotted (y-axis) versus classification accuracy(x-axis). (a) Lexical counts (freq(t; w)) (b) Bigram counts (freq(t1 !t2 )).354fiCommittee-Based Sample Selection Probabilistic Classifiers1Two member selectionBatch selection (m=5; N=50)Batch selection (m=5; N=100)Batch selection (m=5; N=500)Batch selection (m=5; N=1000)0.98Accuracy0.960.940.920.90.880.860100000200000300000 400000Examined training500000600000Figure 10: Evaluating batch selection, = 5. Classification accuracy versus numberwords examined corpus different batch sizes.counts stored (i.e, non-zero) training, using two member selectionalgorithm complete training. graphs show, committee-based selection achievesaccuracy complete training fewer lexical bigram counts. achieve92% accuracy, two member selection requires 6200 lexical counts 750 bigram counts,compared 15,800 lexical counts 1100 bigram counts complete training.implies many counts data needed correct tagging, since smoothingestimates probabilities equally well.9 Committee-based selection ignores counts,focusing efforts parameters improve model's performance. behavioradditional practical advantage reducing size model significantly. Also,average count lower model constructed selective training fully trainedmodel, suggesting selection method tends avoid using examples increasecounts already known parameters.6.5.4 Batch Selectioninvestigated properties batch selection, varying batch size 50 1000examples, fixing number examples selected batch 5. foundterms number labeled examples required attain given accuracy, selectiondifferent batch sizes performed similarly. means increased batch size9. mentioned above, tagging phase smooth MLE estimates interpolation uniformprobability distribution, following Merialdo (1994).355fiArgamon & Daganseem improve effectiveness selection. hand, seedecrease performance increased batch size, might expected duepoorer modeling input distribution (as noted Section 2.2). may indicateeven batch size 1000 (selecting 1/200 examples seen) small enoughlet us model input distribution reasonable accuracy. However, similarityperformance different batch sizes sequential selectionhold respect amount unlabeled training used. Figure 10 shows accuracyattained function amount unlabeled training used. see quite clearly that,expected, using larger batch sizes required examining far larger number unlabeledtraining examples order obtain accuracy.7. Discussion7.1 Committee-Based Selection Monte-Carlo Techniqueview committee-based selection Monte-Carlo method estimating probability distribution classes assigned example possible models, giventraining data. proportion votes among committee members class c example e sample-based estimate probability, model chosen randomlyposterior model distribution, assigning c e. is, proportion votesc given e, V (kc;e) , Monte-Carlo estimateZP (cje; ) = TM (cje)P (M jS )dMranges possible models (vectors parameter values) model space M,P (M jS ) posterior probability density model given statistics , TM (cje) = 1c highest probability class e based (i.e, c = arg maxc PM (ci je),PM (cje) class probability distribution e given model ), 0 otherwise. Voteentropy, defined Section 4.2.2, thus approximation entropy P .entropy direct measure uncertainty example classification possible models.Note measure entropy final classes assigned example possiblemodels (i.e, TM ), class probabilities given single model (i.e, PM ),illustrated CCF example Section 5.2. Measuring entropy PM (say, lookingexpected probability models) would properly address properties 1 2discussed Section 2.2.7.2 Batch SelectionProperty 3 discussed Section 2.2 states parameters affect exampleslow overall utility, atypical examples useful learning. sequentialselection, property addressed independently examining input examplesdrawn input distribution. way, implicitly model distribution modelparameters used classifying input examples. modeling, however, inherentbasic form batch selection, lead less effective (Freund et al.,1997).356fiCommittee-Based Sample Selection Probabilistic Classifiersdiculty batch selection addressed directly McCallum Nigam (1998),describe version batch selection (called pool-based sampling), differsbasic batch selection scheme presented Section 4.2.3 two ways. First, quantify disagreement committee members KL-divergence mean (Pereiraet al., 1993), rather vote entropy. significantly, disagreement measurecombined explicit density measure density-weighted sampling, documents similar many documents training set probablyselected labeling. intended address property 3 Section 2.2. authorsfound empirically text classification using naive Bayes, density-weighted poolbased selection method using KL-divergence mean improved learning eciencycomplete training. also found sequential selection using vote entropy worsecomplete training problem.hypothesize due high degree sparseness example space(text documents), leads large proportion examples atypical (eventhough documents similar given atypical document rare, many different atypicaldocuments occur.) Since case, sequential variant may tend select manyatypical documents labeling, would degrade learner performance skewingstatistics. problem remedied adding density-weighting sequential selectionfuture research. may yield ecient sequential selection algorithm also workswell highly sparse domains.8. ConclusionsLabeling large training sets supervised classification often costly process, especiallycomplicated domain areas natural language processing. presentedapproach reducing cost significantly using committee-based sample selection,reduces redundant annotation examples contribute little new information.method applicable whenever possible estimate posterior distributionmodel space given training data. shown apply training HiddenMarkov Models, demonstrated effectiveness complex task part speechtagging. Implicit modeling uncertainty makes selection system generally applicablerelatively simple implement. practical settings, method may appliedsemi-interactive process, system selects several new examples annotationtime updates statistics receiving labels user.committee-based sampling method addresses three factors relateinformativeness training example model parameters affects. factorsare: (1) statistical significance parameter's estimate, (2) parameter's effectclassification, (3) probability parameter used classificationfuture. use committee models uncertainty classification relativeentire model space, sequential selection implicitly models distributionexamples.experimental study variants selection method suggests several practicalconclusions. First, found simplest version committee-based method,357fiArgamon & Daganusing two-member committee, yields reduction annotation cost comparablemulti-member committee. two-member version simpler implement,parameters tune computationally ecient. Second, generalizedselection scheme giving several alternatives optimizing method specific task.bigram tagging, comparative evaluation different variants method showedsimilar large reductions annotation cost, suggesting robustness committeebased approach. Third, sequential selection, implicitly models expected utilityexample relative example distribution, worked general better batchselection. Recent results improving batch selection modeling explicitly `typicality'examples suggest comparison two approaches (as discussed previoussection). Finally, studied effect sample selection size trained model,showing significant reduction model size selectively trained models.future research propose investigate applicability effectiveness committeebased sample selection additional probabilistic classification tasks. Furthermore,generality obtained implicitly modeling information gain suggests using variantscommittee-based sampling also non-probabilistic contexts, explicit modelinginformation gain may impossible. contexts, committee members might generated randomly varying decisions made learning algorithm.AcknowledgmentsDiscussions Yoav Freund, Yishai Mansour, Wray Buntine greatly enhancedwork. first author Bar-Ilan University work performed,supported Fulbright Foundation part work.ReferencesAngluin, D. (1987). Learning regular sets queries counterexamples. InformationComputation, 75 (2), 87{106.Angluin, D. (1988). Queries concept learning. Machine Learning, 2, 319{342.Baum, L. E. (1972). inequality associated maximization technique statisticalestimation probabilistic functions markov process. Inequalities, 3:1-8.Black, E., Jelinek, F., Lafferty, J., Magerman, D., Mercer, R., & Roukos, S. (1993). Towardshistory-based grammars: using richer models probabilistic parsing. Proc.Annual Meeting ACL, pp. 31{37.Brill, E. (1992). simple rule-based part speech tagger. Proc. ACL ConferenceApplied Natural Language Processing.Church, K. W. (1988). stochastic parts program noun phrase parser unrestrictedtext. Proc. ACL Conference Applied Natural Language Processing.Cohn, D., Atlas, L., & Ladner, R. (1994). Improving generalization active learning.Machine Learning, 15, 201{221.358fiCommittee-Based Sample Selection Probabilistic ClassifiersCohn, D. A., Ghahramani, Z., & Jordan, M. I. (1995). Active learning statisticalmodels. Tesauro, G., Touretzky, D., & Alspector, J. (Eds.), Advances NeuralInformation Processing, Vol. 7. Morgan Kaufmann, San Mateo, CA.Dagan, I., & Engelson, S. (1995). Committee-based sampling training probabilisticclassifiers. Proceedings International Conference Machine Learning.Elworthy, D. (1994). Baum-Welch re-estimation improve taggers?. Proc. ACLConference Applied Natural Language Processing, pp. 53{58.Engelson, S., & Dagan, I. (1996a). Minimizing manual annotation cost supervised learning corpora. Proceedings 34th Annual Meeting AssociationComputational Linguistics.Engelson, S., & Dagan, I. (1996b). Sample selection natural language learning.Wermter, S., Riloff, E., & Scheler, G. (Eds.), Symbolic, Connectionist, StatisticalApproaches Learning Natural Language Processing. Springer-Verlag.Freund, Y., Seung, H. S., Shamir, E., & Tishby, N. (1997). Selective sampling usingQuery Committee algorithm. Machine Learning, 28, 133{168.Freund, Y. (1994). Sifting informative examples random source. Working NotesWorkshop Relevance, AAAI Fall Symposium Series, pp. 85{89.Gale, W., Church, K., & Yarowsky, D. (1993). method disambiguating word senseslarge corpus. Computers Humanities, 26, 415{439.Johnson, N. L. (1970). Continuous Univariate Distributions { 2. John Wiley & Sons, NewYork.Johnson, N. L. (1972). Continuous Multivariate Distributions. John Wiley & Sons, NewYork.Kupiec, J. (1992). Robust part-of-speech tagging using hidden makov model. ComputerSpeech Language, 6, 225{242.Lewis, D. D., & Catlett, J. (1994). Heterogeneous uncertainty sampling supervisedlearning. Proceedings International Conference Machine Learning.Lewis, D. D., & Gale, W. A. (1994). sequential algorithm training text classifiers.Proceedings ACM SIGIR Conference.Liere, R., & Tadepalli, P. (1997). Active learning committees text categorization.Proceedings National Conference Artificial Intelligence.Littlestone, N. (1988). Learning quickly irrelevant features abound: new linearthreshold algorithm. Machine Learning, 2.MacKay, D. J. C. (1992a). evidence framework applied classification networks.Neural Computation, 4.359fiArgamon & DaganMacKay, D. J. C. (1992b). Information-based objective functions active data selection.Neural Computation, 4.Matan, O. (1995). On-site learning. Tech. rep. LOGIC-95-4, Stanford University.McCallum, A. K., & Nigam, K. (1998). Employing EM pool-based active learningtext classification. Proceedings International Conference MachineLearning.Merialdo, B. (1991). Tagging text probabilistic model. Proc. Int'l Conf.Acoustics, Speech, Signal Processing.Merialdo, B. (1994). Tagging text probabilistic model. Computational Linguistics,20 (2), 155{172.Mitchell, T. (1982). Generalization search. Artificial Intelligence, 18.Pereira, F., Tishby, N., & Lee, L. (1993). Distributional clustering english words.Proceedings Annual Meeting Association Computational Linguistics(ACL).Plutowski, M., & White, H. (1993). Selecting concise training sets clean data. IEEETrans. Neural Networks, 4 (2).Press, W. H., Flannery, B. P., Teukolsky, S. A., & Vetterling, W. T. (1988). NumericalRecipes C. Cambridge University Press.Rabiner, L. R. (1989). tutorial Hidden Markov Models selected applicationsspeech recognition. Proc. IEEE, 77 (2).Seung, H. S., Opper, M., & Sompolinsky, H. (1992). Query committee. ProceedingsACM Workshop Computational Learning Theory.Viterbi, A. J. (1967). Error bounds convolutional codes asymptotically optimaldecoding algorithm. IEEE Trans. Informat. Theory, T-13.360fiff fi"!$#%#'&#(((*)+#,-#"."#/0=+>@?$ACBEDFGHDIAKJML1*23456#78(9:;2!5<98((DNEOPCQR?6O?S>UTWVXPCD*AHD*AHJZY[P\B]P^H_`ba_dcHe4f@`hgXi'ajlkzl{| }*}~E}6<~{{~h X}h4+b*64h *bhbE *%]%* zmln+o+pqrbsXtCruv'w x y+n+py+rEw rlpy_`be'<`bj+i'abn+r pq tun%'w mly'w r py* <}4}| RX* E}h}zl*b%RX}}h X~|$*}}hE *}}hb]@- z6h E4 Xl4 % d- bb HHl- 4H-l%%-hC l4 Hh-X$ - b h-l*h- b %b- H-h H b C $"] C l-'- %S%'-l Ch +C%-4l'lEh l%hCH @l- @W%l hH- Rl@h"@- W l%hH$l4l6-C $-l% * SblHb4 -6l<h l-H l-- h%@6d-lb-- +%lH-X Ch-X $ -@ 46lS $l%Ch %-$ 4**@hbWl--$ bl@4 Rl Wl@"4l%X'4E $l-SE4bl4 4\*4*6hbl-4 hClSl-64 Kl"-'l- h % \l4 4@"h4l%6$ - 4h'l <4H@ l$l-Xh 4S6fffifi!"fi# ff$#&%'(#)* + ff',fi##-# ff.$ ',)/ 0fi!1fi#&2!3!) &)4)&%5&%2fi2) ) 76# ff89:; ff=<>ff# ff) fi#9? 1) $8!) &)4)'@A!'B#-0CEDE%='@A!'B'F9G2H%#I1fiJ<) ffK&%Lfi##$9M NO%=&B: ff&%<<$ ff<>2 ) )P 0&%E% ) Jfi#!"fi# ff>O%'Q; ffR&%&SCNDT%EUP ff V4) $!13%$; ff) )P ffJ!'@<$ J&%WLfi##$9" 0&!J&=19@# 7+9!GKfi#!'B!!G')fi1fi#!) &)=<> E K<<fi#9ff!M&%4H% )Mfi#!X2fi ff$#&%'MYO%$19M!$2) !Mfi2) ) 76# ff29CZ1fi#![ > ffB\ J+ ff)fi$) ff)@!fi!S[)&1^]_ ##_9Ya`bO$9?$ ffYff!L95 E&%J; ff 'J# ff5) c dfi!1Sfi/%3 ff1]$C@e1]$ #$9?'J93$#) @U%ff1) >I# ff)/J f1SEV B!4) ff'BPUEa9W)&%B)R#)) P) $#_94 ffgUW%4&%P; ff 'J# ff) 8 Mfi!1fiEh ff1]$=#)Bji0$b$ ff'k&%@!; ff '@5 MU%%c&%"fi#5fi# $#&%'UE#fi#fiW%) )C:l ff4A'@<fi#YRUW%8fi!1Sfi#m<#Afffi#)K!8'JK&Yn&%d2fi9) B$9^<#fi#fi#9) )E#)&fi0!<W&%o&%K&%='B$#fi!)W n&%+2&$ ffo ff >)&< ff!K B&%ff1) >I# ffpC4q ff'@2)4!3UW%#H%hA^<S$ )#)&ff>"$@&fiN<fi!)r+ )&1]$ #@fi!1fi#!$ $)ts;e'49&%pYuavvwxCEyzM O%E ff'J!)Yp&%t' ) Pb$L$9<= 2/ $ ffP#)='B#)V )'@#((%('fi+fi|5 X 5o}$% R~E *ff34 R2!bfib!*l5{fin+o+pqrbsm,Xn+r pq$!@a`bO$9C0O%>")W 0fi!1Sfi!K $ ffo$#) )PUW%J&%; ff 'J# ffK) " =fi!1fi%@ 1) $I2 # ffK#)E!L^2 CRl /A'@<fi#Y!K&%'B#fi0 '@!@#W'J9@ E1S=< ) )1fi#B<z; ff '(&%W) )*))&$9@ =ff*O%*4!ff ))P#)uCl ffR '@!)!BUW%#%=fi!1Sfi#B > ff$)n ffYBff'Jt'&% ffB fi#!'B!!B ffg ff $=')fi1fi#ff1) >I# ff)TUE#fifin!'@<$ &%=<>t29" R&%fi!) )j6; ff 'BKb$ ff'&%&!&SCzy 8&%#)"$fi#MUPd$))@&%M<$ ff1fi#' 2W# 7;9ff!8&!!8)&)@&%2$G')>`fi!1fi#0C8fi!Qs$uvwx'B ff)5O%)@ #) Kfi#fiP!$) )Yo$'B ff!5 #) Kb$ ff'O$!1 P; ff 'J# ffB$2) )/&%<$# #f29B O%W$)&fi# !Bfi!) ) 76R7O%*)O'BO$!1 = #) =#)W<>) T&%=2&4 "1fi!)) 760CEybMO%) /'B#) fi!1fi#3&2!K!`) &)fsfi!) )E #) xo&%T ff<< )W#)P& #&E&%&2!B&UTfi#fi>)&fi#/!Mfi!) )j6UE#&%)j6fi#9%#ff%:<$# #m9Cl ffKA'@<fi#YP$ fi9Ql$#fiGs>uvvwSYuvvw1xn#fifi!)K&%n; ffnfi!) )P #) Wfi#fi#)P 0fi#) )/O%BffY$'B ff!B'B#) fi!1fi#M!) &)b$ ff'&%&!!@&B$)OfiMM%#ff%<$# #=9G>fi2 # Bfi!) ) 76# ffM2`#)%dUE#&% ffJ fi#!"O%&!!"2&Ct!&$ @M'B&% d; ffT# 7;9ff!5'B#) fi!1Sfim!))&%#)t )&<76K9<$fi!fi!"fi# ff$#&%'Y^1E2&%o) $)E)P=fi0'B&% "O%P"1S=<<fi##d2&) P1O; ff$T+!B#*fi#@fi# $#&%'MC/DE%1) ##=#)P B) W4) / 2fi#fi# ff>O%'B)@ 3$Mfi2) ) 76$)K&%@@)"J*#;a+ B&%M&2!52&C?DT%d'B&% m)'B[195&%M %#L^M 2f$'B \ff;#=!m$ff$)) # ffmfi#9) #)Xs #)&1S$YuvxC3 ff fi##4)B)Xs;:!) &x4&%2 ff)B + fifi# U,O%@)&'BK'B fffiP)&%">) E&%&JX<<S$)W2)E&% ffff%#)W ff')P.> ff'B7i0$f<$ 11#fi#$9d#) O$!1 # ffpCWE2 )$2) )WUTO%dBfi!$t$) #fin $ C # #)&1S$?s$uvxo)&) )W1#fi!3@'B fiN) !Mfi#fiR&%&4A<P; ffP&%)&)O< : ff fi##WM) !@UW%&%T ff) ffo ff) W1fi# ff@O%='B fffin) !"&%A2fifi#9M) #-m7`b ) aC$YgU*K<<fi#9XO%)B#d195) !5K) = Efi!) )j6>)=; ff 'db$ ff'<$ P&%@&!&W )RUW%&%R!))/!B&%E$'J!@<> p&%E&!4&$E'B#) fi!1Sfi0CP!'@< $&Pji0$=1S$U*J ffoUP ff VBM<$ )W<<$ ff2H%)o B ff fi##/ # ffK#)E&%ff<<$ ff2H%:) )&'B)O%E&%B $ $)W!:&%Bfi!) )fi!1Sfi)B$4<SB /O%t<$fi!'B fiN1S!M6 "O%=&SCWyb:) )Yp ffW'&% ff5'@< )E "# 7+9:&K< ! )&%fffi#X1S ff fi##$)W!c'B fi;CWfi!ffP<<$H%J ff6&) )*O%*>f<$ W Bfi!1Sfi!K $ ff>)"UPT6&%46fi# $!8)&1) &!fi#fi#98'J<$ )"<_+ ff'@KUW%8fi!1fi#)d$M #) 9Cmybm2 pY/UPff'@<$6fi# $!M K'@]$ ff$#$9" ) 'B1fi#Bfi2) ) 76$) K#fifi!)B&%fi#&% ffff%:'@]$ ff$#$9=fi!) ) 76$)=<> I#B) ff'BB<$ # ff3!) f )9M&YS6fi# $!d$)&fi# )!:) #ff76fi#9%#ff%=29C@&%!$8A^<S$!'B4Ifi!)tO%<>) 5 E ff'&% ffch 7;9ff!fffi#9?'B#) fi!1Sfi#[&M<S !)C K fffi!MUE#&%5)) ) # ff8 Pb&$M$)$%3!$ # ff)!'BM*'!'B#-!K&%W<$ ff11fi##$9" 2#)$!t!))P&%*$EA< # ff)E&%&%#) COOn b_jI0_O;$bP jzbR$_I;PO$_b =;E /Pz!jb&P$OjOj Pp$z/pjBIb_O zI$Eab$;b;$IROzIzbOIPab a=j;;aIjfffi'@3pr v+hsvc%q+mr qhr pm6n++v+v5SIbXDE%"<> ff1fi#' W%fi#!5 #) "%)B1c&%B; ff) W'B%X2 # ff3!5'@%!"fi#"' ) R! #fi#!@fi# ff$#&%')/%W'B%#)&'(+ ffR%fi!@ #) !B&%E&!&Kfi!1Sfi#)C@l ffA^'@<fi#Y< !3!3#) # ff5O$)#)=) #ff8 d$@O%@H%@&%&%4&$=#) z6 !@ " #) B!:&%=O!!M&CP)f<S !X W19d4'B1$Y ZmqK- $ )&Vfs$uavvwxYR$' I!? #) .$ 'O%M&51SO+ ff>d%9< O%) #)@; ff '@2 # ff?%2)@&%&%E #) 9MA'@<fi#) " E!@%9^<S &%) #) ff) & pCDT%K 2Nfi#!'B!!d!))W @!'@<$ &%B<z; ff '@= /$) %ff1S ffEfi!)>`) 76$)E%)E1Mr; ff)P $)$%@!K1 &%K<@$"!)O`_1) Mfi#!C#fi) ff,s$uvx@)\`_$) d#ff%1 ff5s_ `_WxKfi!) )j68s!\A^<S$!'B)5dUE)K)&%$xo B) fi#E!))E&%oUP$WO%M) " =; ff 'KuO`_Wfi!) ) 76S fffi#9"!) &)E&%&%K `_fi!) ) 765 ff$ fi#93U*>>&!:+ ffO%GuH`_W4C0D0 'BV?s$uavwxPA 5O%)B<`<$ ff2H%3UTO%?:<$ ff>"&%2=fi#fi#) #fi#) ffp)2fi ff$#&%'k+ >) !5I2fi)J IC fi#)5$ !-ms$uvvSYWuvvvx@%a: < ff&%#)G<<$ ff%m! [5)OX 2=)&3) O`fi# # ff3 %#L^); ffTAff'J<fiz`_1) 5fi#2fi ff$#&%'B)CTf%SY01fi#4dfi!1$Ms$uvvuax'B ff)&4&%R) fi# !4)&)*12) B ffB$ ff$)R O% ff&$!1 # ff4 fi2) ) 76# ff29X!8c)&O`_1) 8fi!) ) 76B!'@<> I)=&%"295 E&%J&%"$)&fi# !5fi!)) 7`6CPeVfi!V5s>uvv ffx$3K!) &4) fi# # ff3'B%#)&'; ffE$) W#ff%1 ffTfi!) ) 76$)UE#&%J&% ff2fi N$!@&%!P '@<&# ff2fi ) aYffU%%K<)T ff@O%f'B1P 0) ff$!) &)aCdDE%K) fi# # ff8 WK;U)&)ds) #ff)B<$ _9<)Ox195:3 ffT$fi#)&'J<fi!@fi# ff>O%''B ff)&J&%/29@UE)/'@!&!G@K#) B; ffR)fi&T) )aC #fi#) ffds>uvvvxg<$ ff#)/ff'@<>%) #E $#Um !) &E)fi @ %#L^); ffPA'@<fi!z`_1) :fi#!G2fi ff$#&%'B)C%E#= 2) fi# !5 ff !) &)E%)Pfi#) t1S"<<fi##M O%R$9^<S)/ pfi!) ) 76$)C!) ffMs$uvxp'B ) &tO%fi##$9B ) fi# !3&n'B#) ) ) UW%fi!=) &&fi) $!< # ff)aC?eV2fiV?mP#) ) fi!s$uvvx) $!138<<$ ff%c d) fi# !8!) &)B; ff:#) # ffm&>Gfi# $#&%') !?:) O`_1) m$&>fiWfi# $#&%'M)4&ff ff'493 W) )ds; ff'@<fi# &%X' ) $`b ff`_<S !M2) ) ffxC Z UE#)dEfi# 5s$uvv2ffxB#fi#fi)&3&%2")&'@<fi#!) &)d)[[) !'@: =fi!) ) 76# ff$&!_9m) #fi#fi#9$)M&%5'B ff@&Jd @fi#B ff<Cff'@2 #fi#fi9$' I![!) &)d&%d15 $ fi#9fi!) ) 76Q)&%MO%9'B#ff%X1S5Aff< )X ?&%cfi= fi#C %\)&5#)XAff<:&%Mfio) YR#B<<SB)B&% ffff%hJ)B! ff > fi#9mfi1fi#0C5FV295L^) # ff8!!'@<$ 8&hL^fi##$9[#)M% IU ?#) )O%Aff< )@b$ ff' )C=9 ffpY/53<!V)ts$uvvwxR<<$H%J) )E@!; ff '@2 # ff@>$# ffK t')&$J)&)E$9<#fi#$9p$9<2fi*!))G$"O%[<$) 53%'@8A<$@ 5 'B!MUW%O%B&%9m$'B#) fi!1Sfi @A< # ff)C U*YE&%9 3&%M1) 5&%!d'&% ff#)X[ `bfi!'B&% =#n)&i0$)g.$ ' ff$$!Oi0 )CnV=R )&%#@s$uvvSYuvvwxp$BE'B&% B&%fi#)Rfi#-2 # ff)/=A< # ff)R) <fi#9t19='@!&!!=W> ff$= 2^&%o ff $fi9B! ff $fi9Kfi!) ) 76:<)E!K&%!t$# ffK 22H%K) ff$@A'@<fi#CPDE%f'H%#)&'; ff0#) )O%@ #) ob$ ff'A< # ff)R#)/1) B ff4W)z`b)&<76M<' YUW%#%B#)N))&>E&%R%4) ff>t)O'@<fi#)/fi!)) 76# ffKP#)/)&K fi#9"%#ff%pCRDg = ffRV UEfi#Y&%=<<> ff%M%)E fffi#9d1 )$ 76!fin&) )Cfin+o+pqrbsm,Xn+r pqe>#)&pY5fi ff@MP!5s$uvvxR) fB!+ ff'@# ffJ&% ff$<<$H%J 4A< # ff).> ff' #) B$!"&%4 ff) & # ffM /Bfi# #fin&% ff>9C/DE%!'B ## ffM#)&%&%$#)W @'B%#)&'19@UW%#H%MB ff`_' ff ff#fi#!")&9t"$fi#!1fi#9M#) !ff#)&%& A< # ff)b$ ff' #) Co3&% ff)1) Kfi ) 3U* $")O<!fi##-# ff[s;P!:5fi#O`ffpYuvvSuxp z6n&%/2&CDg ) fi#R&%EAffnfi!) PB E&%P $n&% ff$9Y &%9)fi&% ff&%ff $)*O%='B ) $ ff$)=sO%9B+ "'@<!$#fi#fi#9dO%P&%f' ff$$ ff1) E'B&%&%=2fi) ff) #$)=O%@ ff'@<fi#A$93 P&%Bfi) " )= !'@<B$)&fi# )&xCtDg$) )4&%<$ ff1fi#'&%P&%=1S) Efi!) B'@a9" W<$ =K!'@'B!=!$) 4!M ff'@<>) ) # ffpY&%9ff !ff4 @dfi!))YUE# !@ "'@V &%B<r6fi #fi0&%9K ff1&!:B ff'@<$)) # ffpCDE%#)PJ ffEI+ )2fifi!) )E%a1M0C/y+ ff'@<>) ) # ffKo ff'B)Y&%J&%fi!) 5s;5)O1) L^Bfi!) )&xB$K8 :&%@&% ff>9CGDT%B'BO% ff5#)@fi# ff)M<$O`_< !3 /#) # ffc&$)C=yz3&%!A<$!'B )Yn&%9:a]$ ?ff'fi2) ) 76# ff#) dsfi!!5 Z!$0YRuvxP! "&%4&CDE%#)#) #fiR K ff'B&% :+ ffT!a]_#) T+ E;RK# OO C0l ff/'Bfi# #fi!) )E))Y ffRA<$!'B&fi0'BO% ffK!a]_ )E #) !K&%'@&%E#EUP fffi#X2&fi#fi#9M ff&%= '@!5s) =e # ffffxC4'B1$/Zs$uvvwx/M='t1S$Y ZWKq"- $ )OVRs$uvvwx/%afi7`ff<S"'B&% B; ff%fi!@ #) &%g6$) /$' I)R ) #) /A'@<fi#)Rb$ ff'Q&%P&!&SCtyz ff) #) =A'@<fi#)t$B&% ) B&%=%aB&%J)&'BBI2fi)r+ &%B;&$)=17`;$fi!) )4fi1fi#)CBDE%9d&%:&)$; ff '&%4;&$)!"1!$9:;&$4) CTAff&%9'B!MUW%#H%8)t 2A'@<fi#)YoUW%8$'B 0YR$)@O%M &fi/'B14fi##fi#)M3$&!c&%G<> ff<$$93&%4&%@ >B) 4 E)&)@#)@ =! ff)) aCXDE%98%") z`b)@&%$)&% fimO%@'B ff# ff$)@% U1#5&%#)@A'@<fi#M) @)&% fi[1SCm#8$UP d) )B'@<fi#)E&%P$)&fi#E!MJL^2fi> # ffK!K&%f'B ff/ fi##2fi)aYUPWUP fffi#Kfi!V 4 =)fi&%)&'Jfi#fi1) : ffK&%=%$#) B&%2*##)f'B $Wfi#!V fi#9d "1B #) C%="T#)&%#Gs>uvvxgfiUE#&%@$fi!J))&EB&%W<$ 1fi'( )W!+O$E'Ba`)&$' )aCNDT%o<<$ ff2H%4A )Rb--9@fi# #)P<<$ ff%4 =$<$)&2 # ff@Bfi#fi!# ffE!@&CKDE%93# 7;9?!@ff3O%"1) #)= 2Lfi##&#K ff >fi2 # ff)'B f$fi!@&1) @ =O%* 1) $I2 # ff4&%R) ff'R;&$)/>*Lfi##&#fi#9B<)&%"2)/) 9'@< ff'J#E&4$O !"4<#)*#)2) CRl RA'@<fi#W7/=3uT ffo M) 9'@<`ff')!#&%R<#/%)/<$ #fi!n#))Y&%BUPE'B#ff%/1fi##&%n&%PIfi!EJ) 9^'J< ff'U2)E! ff $ fi#95'B)O$d ffT $0CDE%!'B&% 39^'2fifi#93 ')b--9@! >Ifi#)P; ffo!&BM$L!$)E&%o&%9"%ff'@!KVff UEfi# =#ff#&%P;&>)/! t) )/UW% ) W'B'B1>)*$TL^fi##&fi9K<C %" 4 ff'@!KVff UEfi7`4)=#fi1fiYpO%9M)&) ) !dBb--9Mfi# #B) 9ff) '&%%)W<> 'B!5! $I2fi); ffP&%;&$)aCefi$fi# ff<' )R%aRff$2 fi#9f%fi!<BUE#&%rfi#!WA< # ff)R!4&%nb* #) 9:&CPq# $#H%35PV>s$uavvxofi# ff<S?"'&% ff:; ffTfi!Mfi2) ) 76$); ff'Bfi# !<fifi!) ) )R!BU%%B > ffz`b ff > ! ff&<R )/$P'@<fi# 9@)/#) &$!1 @ &<$<$)&2 # ff?s2H%Kfi!) )#)f2) ) #ffXJL@1!$9M) &>K Rfi#&%dpxCPDE%9M#fi#fi!) &&%Kfi!) ) 761SX#UP)d8 ff'@'B## ff<$ 1fi'!UW%#H%&%3 #$9[&%K ff $B ffO<@fi!) )4+3UA'@<fi#M#)"1S &)O'B# 3 =3 #) 98H%fi+Cd'J<>2fi/I2fi2 # ff3'B ff)&:&%$ ff_`b ff $ !K ff)X1S") 3 K!'@<$<_+ ff'@Cnf &%P$o!# ffK#)E1 ) !ds;e%<!$YpuvvSff!fi!pY0uvvwxY UW%#%; ff 'B)=K) 4 *fi!)) 76$)BUW% ) "<> )$@ ff'B1!19d !C"o ) !d] ) )4&%UP#ff%)/ p&%WO!!=)&'J<fi)ER2H%J## ffpY<a9ff!t' ff$WB )&'J<fi)P&%2/$fipr v+hsvc%q+mr qhr pm6n++v+v5SIb7"fi#= "fi#pCK< !fiR<$ ff1fi#'UE#&%:&%) @'BO% ff)#)&%&%9d'@a9Mfi!) ) 76$)o&%/%aE1t6/ ) 9) '@E #) CX $ Ya&%#)/) #&t'J9B1E7"fi#PCDo9^<#fi#fi#9Y0 KI2fi#K<$fi!fi!)) 76 ffE'&% ff0Yp = )=@$ ) )$`bI2fi#@) /fi!1Sfic&Cy2fifin P&%=@UE)Efi!1Sfi#19M&%B)&'BB'B%#)&'&%:&%!$W2&) ffO!)*O%E)&'B) 9) '@2 #E $ ff>)CnW%#ff!"%#ff%K9J ff@O%)P$9<E!< : ) E) aY'@a9d'BM&%T&%t'BO% ff5%) fftMAfifi#E]$ ff1d2P6 !M&%) 9) 'J#= #) Cyz8&%d<) JY/O%d ff'@<O# fffiE'@%!dfi#!8 ff'@'B#$9%)J)$!# ff)E[fi#K&%P'B fi0&%_9< 2N #) &%E'B#ff%P ffMB$2fifi#ff!$ ff'"sfi!!5 Z2>0YRuv0efi# ffpYRuvq&YRuvvwxCE3 ff$B$fi9Yn'B fi)W ff`_7; ff 'fi!) )j62 # ffm #) 5s;efi# ffpYPuvvx=?<$ !fi* `_j; ff ' #) hs+q&YuvvxP%f1SM!O$ ff0CPDE%) B'B fi) " E))&'B&%P%K!) &B%)E&%)O'B'B#) fi!) )j62 # ff3K&%$O; ff$=$'B ff>f$2fi#) B'B fi) O%_9<)P / #) ff1)$!m$fi7`bUP ff$fi#m<<fi#2 # ff)C3$t!2 # ff8#)t Xfi# 4&%@fi#8<$ ff>K+ ffr&%V IU" #) =)=sq&YuavvxC UPo!M'B ) E$2fij`bUP ff>fiM)$# )P ffUE#fi#fi E%) )P B&%& #) =2 )/ n&%W$# ff)Efi!)) )C/yz@&%)) )Yq&s$uvvxR)&) ))>H%!B; ffo&% #) =) !"4$ ))$`bIfi### ff)$%pY1E&%#)E<<$ ff2H%K) )&')E&%ff=%) #) b$=2&4UE#&%MUW%#%M Bfi!=O%t$)&fi# )T NO%)$%pC4pDE%#)P) # ffK) >1S)W4fip<$ $+ R#j;9K'B#) fi!1fi#3!) &)P!M&!) CRDE%6>) P) <K#)E B#j;9M#!))W19G) !fffi#!Mfi# ff$#&%'B)Bsfi#fi#*#;aM ffO fi= xB c&5!) &)d)@ ff > fi#9m ffB! ff $fi9\fi!1fi#0CD0 c&%#)M0YE?S`; fi#?$ ) )$`bI2fi#5#)@<z; ff '5 &%J&!!3&CJl ffrH%h E&%"[<$ )Yg&%fffi# ff>O%'B)*>E&!K ffJ&%E &%o=3u<$ )CRDE%F$)OfiBfi!) )j6>)W$EO%") K&P%!)/!O%/Afi@<>)0#&%g ff $g ff0'B#) fi!1Sfi0Cfr##fifi!) )j6&)fh)&")=')fi1fi#m7#4fi2) ) 76)=&%J)&")=1Sfi# ff!3K7i>4fi2) )&%c&%4#8195# )B&!cfi1fi;C?T @O%BUW%? #)@L^2fi/ 3&%K &2fi/ff'B14&2!4)&)Y&%#)/'B&% t7i0$)nb$ ff' #)&1>)fs>uvx ff fi##R # ffB'BO% ffB fffi#9!M&%) W) : B 'B!BUW%&%E) #)fK ff fi##CT=&%Km W&%MS`;+ fim> ) )$`bfi#2 # ffm%c)&M!8&%K&!!5&3%)@1S&0C T) !M&%#)!+ ff'@# ffpY&%B) ff:) <:#) B; ff '@fi!) )j64) !d"U$) # ff&%dO!!?:+ BUW%#H%\fi#fiW 2f&%M!))M# 76)M'B#) fi!1fi#$d$'B 0ClR#fi# $!??1Sd1) ff8 ffK ffB'B ff>" &%12) Mfi#fiPfi2) ) 76$)o&)aCXDE%K6fi# >) E 2N&!K!) &)#)W<> I#5)E!<W @&%EPp#O&" & fiBCPDE%t$)Ofifi!) ) 76n#)n&%/@<$ 2^&%P<<$ ff2H%pCglR$WuR<# )RO%/2fiff<$ $C/e<76!'@<fi#'B&# ff)B P&%#)tfi/<$ $Kji0rc% IU&%B6fi# $!3#)t<Sz+ 'B0Y5!&%=$fi!)&%!<X1S$U*&%6fi#fi# ff$#&%'ds+)&xPd&%62fi0fi#!G2fi ff$#&%'ds)OxCe X]ajdWagE` "!#Ca j+`$<<$H%h)B 3) K&%")O'BKfi!?fi# ff$#&%'k ) & @1 &%5O%@6fi# B8&%6fifi2) ) 76CPDE%#)*<<$H%)E'B ) /) !'B#fi!B$'B ff!4 ff fi##$)PK$ff>) ) # ffKfi#9ff))aY; ffUW%#%K&%)&'B'B fip)) B ) o; ffo ff fi##$)WK; ff6 !B&%6fi0'B fip B&%&ff&%E fffi#$)E%aW1S">'B 0C0>fi2 "'B&% K)o&%P<$ ff< ) "19&% ff%Xs>uvvxg; ff('fi)TrainingInstancesFiltern+o+pqrbsm,Xn+r pqCorrectlyLabeledTrainingInstancesLearningAlgorithmClassifierlR#ff$Ku+*RDE%=fi0<$ $4+ ffofi#!'B!!X')fi1fi#3)&)C$'B !"&%4&!!M!) &)O%W$B< 519dCjds;!fi!pYouvvxC*e<Sj62fifi#9Y0; ff%@fi#a/ KO%f< MO$E; ffoUW%#%K&!!@!) &)$ ff1) $Jb$ ff',' ff$&%ff@fi!)),% %p)='B&% 5fi#!'B!)B&% ) B!) &)tO%f$" b$ ff'&%"'@2]_ $#_9Mfi!))CDE%@O$"#)4&%?>1fi#4b$ ff'O%"$m) 4 *&!3!) &)CdDE%#)@<$ ) )=#2 )#fi/ @b$&%< !d:1B ffCDE%@V 9M7i0$"1S_UP ff'B&% X% %p)#)P&%R ffo'B&% G) )P$ ) )$`bI2fi#K IR&%EO!!t2&UE#&%J ffE#@UW%>)% ff%p)W'B&%fi#)UE#&%K&%&!KA'@<fi#)W!$fi93d<_+ ff'B)W'Bfi# !<fiB#2 # ff)CQ) ff:UE9K @!'@<fi#'B6fi# $!M#)W @ ff) &WB6fi# ) !K fftfi# $#&%'Fff) =&%J6fiofi2) ) 76@) !5:ji0$t2fi ff$#&%'MCdDT%G))&'@< # ff8$fi#9ff!8&%#)<<$H%#)=&%) ff'tfi# ff>O%'B)=) ff6fi$)+ &%fi# ff$#&%'B)aY0't%Mfi#!V @) ff'Bfi# ff>O%'B)f2f)T ff M;&>=) fi# # ff5'&% ff)T; ffP &%>)s;T$#YuavvxCPDE%B<<$ ff%) $!1Sh19 #fi#) ff8s$uvxR 46fi# $!K&r; ffEKuO`_) !MK `_)KA^'@<fi#= R&%#)<<$H%pCc 0$-j1!-2'aj#e . /Ca j `$3)'t1fi#Pfi!) ) 76$)R 't1!P&%o ff&< )0 2P) n S12) O`bfi#fifi!) ) 76$)Ws) 4[efi!' ffpYu vvoV ) ) ffMeUE!pYuvv fi!<>YpuvvxCp'@]$ ff$#$9= P) 'B1fi#fi2) ) 76oUE#fififf&<Sz; ff '2H%K1) O`bfi#fipfi!) ) 76P @4&) R7$UP = )% fi,*s$uxRO%f<$ 11#fi#$9/4 ff $Efi!)) 76# ff319K%K!#fiRfi!) ) 76T#)Wff>o&%MC7t?s;xP&%$ ff$)!d<$# # ff) 2N&%=12) O`bfi#fifi!)) 76$)f$!<"s) defi!' ffpY0uvvxCyzK6fi# $!Y0M) 'B1fi#Bfi2) ) 76 )='B#) fi!1Sfi#5!) &)=19M ff) & !GJ) E4 H6 5_#( 7a, 8;O;sfi!)) 76$)&x=XO%X):&%!fi!) )j62 # ff3 $ $)W 7;9h')fiI`1fi#\)&)C5DE%K2fi<<$ ff%5#)B 3&3c)&)B'B#) fi!1fi#7:98 W&%;1) O`bfi#fiTfi2) ) 76$)KBfi!) ) 7;9mJ ff $ fi#9C8yb8&%#)@UP ff VhU*KA'B!X1S &%8'@]$ ff$#$98 ff) )&)46fi# $)aCd'@2]_ ff>$93 B6fi# 4&)=c!) &)@'B#) fi!1Sfi\7f'B ff$J&%%fi7R &%<1)fifi0fi!) ) 76$)fi!) ) 7;9"#E! ff > fi#9C/Q ff) )&)6fiW$L!$)E&%2f1) O`bfi#fin $)W'B) Pb#fi @fi!) ) 7;9dM!) &)EO%=fi!) )#d19K)W&!Kfi!1fi; ffP#E "1Sfi#'2 3b$ ff'&%&2!K&Cy.=#)B!'@< ff>&X J&%=O%G$fi#9!?<$'B#) Wc) 'B1fi#K6fi# 4ji0$)4b$ ff''B&% )Bfi# ff<m!8$ff$)) # ff?fi#9ff) #)Y8U%%c ff fi##$)@$KO6[$fi!#K X:<z`#fi!'B fi;C >tUPB) )&'B4&%) ff'B4!) &)!3&%4&K%at1S5'B#) fi!1fi#m&%T&%=fi!1Sfi > ff$)W><S4 /&%B<$ #fi!'B fffin1!K6W @&%=2&CPDE%$O`; ff$E fi#fi# !K; ff 'J# ff.$ '7i0$'B fffi#)PUE#fi#fi<$B1 *'&% ffJ; ffR'B#) fi!1Sfic)&)&%K fi#fi# !M!+ ff'@# ffJb$ ff'4) !fi#@'B fi;Ce$#_9: /&2!:&J)=M<> ff1fi#'!3'@9dfi!) ) 7653fi#!X<$ 1fi'k `'@!)Xs+CC!YR'B#fiP!ff ))OxC5l ff4)&H%82&) )aYUPKUE4 5'B!!'B#-d&%d<$ 11#fi#$9(=fipr v+hsvc%q+mr qhr pm6n++v+v5SIb>? >? >DiscardedMislabeled>? >>E1? >? >? >E2@ TrainingInstanceslR#ff>tA*RDo9^<S)W 2 # ff $ ff$)P)$!X:!) &@&%#)=:Aff< # ffc&%&%X$ C=yb0Ynq=9fiV:/> ) ts$uavvx B&%fi#!:.> ff'F )9X2&@#)4jKfi@1S) @##)t%>X "#) !`ff#)&%M1S_UPM #) =MAff< # ff)aY)&<!fi#fi#9d7R&% #) #)E) 9) '@Coy;fi#fi#9YO%f1!) )*fi#) ffB /&%Bfi#!Xfi# $#&%'B)UE#fi#fi/1fi#@# Kfi#:&%BA< # ffpCtDT%$O+ $YffE R'B ff$E 2&%Efi!)) 76$)P&%/ '@<$#) E&%1) O`bfi#fip) R 0 $)R@%aE7"fi#$9<&>BW<$ #fi!RA< # ffBUE#&% R) !=&%PA< # ffB =1SP $ ff ff)fi9Bfi#!'B!b$ ff'O%W&!BCRybJ&%#)*2) Y&%W ) )&)E'B&% "UTfi#fi'JV P;UPR # ffK$ ff$)&%4'@]$ ff$#$9 ff0)fiEfi# $#&%''B&% 0CRDV!=E ) )&)/O%0&%='@2]_ ff>$9#)*4'B ff$P ff) >I#<<$H%BJUE#fifi0$)Ofio!B;UPn)&)E1!Bfi#'2 K.> ff'Q&%&2!K&CoDE%=aUW12HVJ /B ff) $#B<<$ ff%M#)&%=3$#)&VK /$&!!d1&SCGyz8&%"AB) # ffcU*Mfi#9-"O%G<$ 11#fi# #)@ 2f'@V!d#j62 # ffm > ff$); ff1 &%M$&!!M1d&%$ UE!@aUE9J ff&t+ ffP'@2]_ $#_9Kff) )&)T6fi# $)CeB ij1CEDGFb_Ag,c`b`gE`$yb 7;9ff!@'B#) fi!1fi#K!) &)o&%$E$P$UP E$9^<S)R > ff0O%RB1W'J=s) PlR#ff$xC:DE%@6>) =$9<5sHKux ff>)tU%m3!) &M#)B! ff $fi98&?)B'B#) fi!1fi##)")O1) L^ fi#9m#)$sq=xCRDE%M) [$9^<SM $ ffMsHBx4 $)@UW%\X')fi1fi#!) &5s5x#)B&5)4 ff $fi93fi!1Sfi0C3ybc&%#)=) # ff5UP"fi#9ff-K&%"<$ 11#fi#$95%K R&%) $9^<S)W 2 $ ff>)P+ /O%= ff) )O)fd'J]$ ff$#$9B6fi# E'B&% )CIKJIKJLNMPORQTSRUVWXY<SZW0[DE%E R! ff $fi9MO!"B $P!) &B)W'B#) fi!1Sfi8%<<)UW%M'B ff>&%%fi7= =&%1)O`bfifiW ff$)J.#fiE ?fi!) )j;9m&%:)&3 ff $fi9C Z \@sHKu^]x@1S&%@<$ ff11fi##$93&%fi2) ) 76<_P'@V2)f-HKu > ffWd; ffT&%B)&V 4 /fi!$#$9X))&'BB&%fi#`fi1)O`bfifi/fi!) ) 76$)@%a@O%t)O'B"<$ 11#fi#$95 E'@V!X-HKuB $ ffO%#)=Lfi\@s HK^u ];xCKyEUP") )&'@&%4&%@ $ $) E&%"1)O`bfifi*fi!)) 76$)@$@!<Yo&%<$ ff11fi##$9M&%WJ'@]$ ff$#$9@ E6fi# TUE#fi#fi&%> IU ffT ff&4#)#d19K*\@sHKuxabdf c1e \@sHKu ] xbTgAe`h7bs>u*P\@siH"u ] x x(pekjb:lmonfin+o+pqrbsm,Xn+r pq%$q\@siH"u6]x s$uB \@sHKu^]x xbmrnekjb l><$) )"O%d%3> ff$)M'B ff5O%q1) O`bfi#fiTfi2) ) 76$)Cmy&%d<$ ff11#fi##$9? '@V8sHKuJ $ ff4#)@fi#) )@&%?C7Yn&%8&%'@2]_ ff>$9B6fi# UTfi#fiR'@V ;UPE$ ff$)EO%@)fiO`_2fi ff$#&%'6fi# + ff'BMb$ ff' = R&%1) O`bfi#finfi!) ) 76$)aCDT%f<$ 11#fi#$9@ R'B#) &V!4'B#) fi!1fi#:)&; ff/4 ff > fi#9tfi!1Sfi#d!) &"is Htx$)U%t' ff$R&%4%fi7 &%P1) O`bfi#fifi!) ) 76$)Rfi!)) 7+94&%/!) &2)0&%*')fi1fi#fi!) )C 7 Z &\@is Htt ]x1K&%"<$ 11#fi#$95&%2=M1) O`bfi#fiP ffu_'@V2)=: $ ffr *$9<HBCP) )&'B!K&%&%= > ff$)$!<@d&%2W&%B<$ ff11#fi## #)= /O%t1) O`bfi#fifi!) ) 76$)K'@V5vHt $ ff4$@O%")&'BYn&%5O%G<$ 11#fi#$98&%=O%"'@]$ ff$#$936fi# '@V )EB$9<<HBB $ /#)#M19\@sHBxadb f c1e \@sHB ];xbTgAe`h7bs>u*P\@siHtt]+x xekjb:lmonDE%$O; ff$Yp@'@2]_ $#_9K 6fiEUE#fi#fi/'@V2;U*wHt $ ff$)T&%J) !fi#O`_fi# ff>O%'6fiE7\@s HB ]x4#)Bfi#) )B&%8CjC %?2fifiE1)O`bfifi*fi!)) 76$)GHBM$ ff$)B$"'@2" ffh&%")O'B)&1) 0&%)&)Y&%W<> ff11#fi#$9@O%*4'@]$ ff$#$9= Pfi2) ) 76PUE#fi#fi0'@V ExHB $ ff#)W# #fin B&%t<$ 11#fi#$9M&%=)fiO`_2fi ff$#&%'6fi# TUE#fifiR'@V2f$ ffCIKJIKJy{zS"|,}~[A|,}(,}xV TW0[AU}l /) )&)P6fi#xKH $ ff ff>)*U%"fi#fip 0&%1) O`bfi#fip $)o.#fi =fi!) )j;9B!)W $ fi#9C Z k@\ sKH u^] x/1&%W<> ff11#fi#$9K&%/1)O`bfifi ffGn_ '@V2)*KH u$ /;1&%ff'B1S/ 2g12) O`bfi#fipfi2) ) 76$)YO%@&%2fi; ff ' 2O%f<$ 11#fi#$9/'@V!";KH u $ ffP#)#M19K*\@sHKuxa\@siH"u # dx \@siH"ux #\@sHKu^ HKu 07 HKu # ^# v + HKuekj#xR&%1) O`bfi#fin ff>)'JV $ ff$)P ffJ&%)&'BW!))E&%K&%=<> ff11#fi#$9M RffHKu$ #)BL^fio M&%M<$ ff11#fi##$95&%BM) !fi#d1) O`bfi#fiP ff='@V )th $ ff\@sHKu^]xCH"uT $ ff>)/ O%f1)O`bfifi0 ff>)$W!<SY&%M4 ff) )O)/6fi# T%)%K&%uK)&'@2fifi#B<$ ff11fi##$95 E'@V3HKuB $ ff&%3%d 2# )=12) O`bfi#fiP ff$)=5&%<$ ff11fi##$9M /'@VM;HKu $ ffo#)#d1K9 *\@siH"uaxRa e \@siH"u6]x] #cP&%@) )&'J< # ff3 /!<aM /&%@$ ff$) /&%"12) O`bfi#fiR ff>)=% fi#)Y0&%:UPfffi#MA^<SWB ff))&)P6fi# P @%a=4)&'@2fifi#<$ ff11#fi##$9" /'@V!"xHKuW$ ffo&%K) !fi#O`_fi# ff>O%'6fiC1 RIoRjjzjO;/$O;&T*; ;jW$ $zRI= R IR &;j$&zzj&; zb$Gp_$I;ojjo $/oz;b;o2RIzfPbRII nIO;nj$&zzj&; zbR*R <Pz;b jjp EaIabb$;jPO; jjzjO;0$&;On&;gIO $0$o;j$ IjjpjIO;_ 0b$aj;z ;_j$R$ ; b$R &;j$&zbjO;Izb$Inab a= &oz;b IRp*zjO;R$&;IRjjzj&;o$&;RbR$&o ;$IR;O*Rp(fipr v+hsvc%q+mr qhr pm6n++v+v5SIbDT%f<$ 11#fi#$9@ R'B#) &V!4'B#) fi!1fi#:)&; ff/4 ff > fi#9tfi!1Sfi#d!) &"siHtx$)EUW%:K!) &4)'B#) fi!1fi#?ffE'B ff>W R&%=1)O`bfififi!) )j6>)f<$# )&%@'B#) fi!1Sfi8fi!) )C Z <\@sHB ]x1B&%@<$ ff11#fi##$9XO%="12) O`bfi#fi/ ff_T'@V )$ P $9<&HBCg ff) )&)T6fi# E'@V )WB$9<<HB4 $ ffP7R ff= *' ff$ R&%=1) O`bfi#fifi!) ) 76$)K'@V )=_9<;HBK $ ffCGDT%)@<$ 11#fi#$95#)BL^2fi/ : ff"'B!)tO%G<$ 11#fi#$9&%= 2*&%@1) O`bfi#fio ff>)='@V )=HBJ $ ffCByus\@s HB ];x#)&%"<$ 11#fi#$9&%Bfi!) )j6x_ )" K'@VHB: $ ffY&%m&%d<> ff11#fi#$9m&%2h ff) )&)B6fi#'@V2)W;HB4 $ ffo#)Wd1K9 *\@siHtxRauTs$uPs\@siHt#x xs$uP\@sHB7HB#x x^#s$u/P\@siHteHt # ## HBewj#xx% 5O%G<$ 11#fi#$9m W31) O`bfi#fiPfi!) ) 76@'JV!?PHBM $ =#)B!<" 2W&%<$ ff11fi##$9M R&%= O%*12) O`bfi#fifi!)) 76$)f'JV!M;HB4 $ ffPO%)1 ff'B)~*\@sHBxa(uE e s$uEP\@sHB ]xx] #DE%$O; ff$Y!B!$P ffO) n <KH $ ff>)Y !c <= 2&%HB ] $ ff>)RBfi#@ =%#ff%fi#fitH r $ ffN+ /O%W ff))&)o6fiC/ybK)OH%J) )Y4) !fi#O`_fi# ff>O%'6fi# oUP fffi#G'JV;U*xBH 3 $ $)@&%\5 ) )&)K6fi# J&%K ffO!)"&%:) !fi#?fi# ff>O%')K ff: =# )1) O`bfi#finfi!) ) 76$)aCEe$ 12a_ <j aj+iB 0$6_0Fj$Ej ` $ ,$HcwRFbjAZgZ0$O+ $?'B [fi!# ff tO%?<<$ ff2H%pY&%3#) )&m'B) d1?2$) ) Q&%!) &)T&K)E'B#) fi!1fi#X19@&%1S<<> ff%B fffi#d1A< # ff)E B4fip fi#4&%$O; ff$/UP fffi#@=)O<!fi&$2&'BC %=!) &P#)/rAff< # ff4 T&%/fi) Y#/B<<S/)RO% ffff%B#R#)/! ff > fi#9@fi!1fi#0C %J<<fi#9ff!B %L)P #j;93fi#!'B!#) 93)&)Yg ffBU)#3)$!3 ff $ fi#9:fi1fi#?A< # ff)Cyb:e # ffdU*#) ))Eb&$=<fi!)T+ Pfi#!" @#) !ff#)&%3 #) b$ ff'A< # ff)C) m) #&# ffc!8UW%#H%8c)&d'B#ff%t1SM)$m $ ff) fi#9?195 ff6fi#<<$H%K#)E7*2fi ff$#&%'UE#&%MK<<$ ff<$!4fi#!G1!)T; ffo&%&B)*#)) 0C/yz)&%:) )Y&%@fi# ff$#&%')f><$) &# ff:fi!ff'J9d f<S 'B#=3t$<$)`&2/&%B ff<C=DE%#)B<$ ff1fi#'#)tfi# ff)W M) #&# ff)!3UW%#%3$'B ff!M fffi#$))/fi## fi#W =!'@<$ P&%P6of6$) $`b $nfi#*>ff$) ) # ffj0&%T ff $P'B fffi 2O%E&#)=LCrlR2fifi#9Yn) !@&%46fi# 4fi# ff$#&%'ds+)&xE ) & )=Kfi!)) 76=) !dO%t $#!fi#) 93&J) Yg&%B# 765 E'B#) fi!1fi#m!) &)=#)t1S ff5 K!fiM$ ff$)0)4fi!) ) 76+ ff'B@b$ ff''B#) fi!1Sfi#X!))W 'B!7/ &%o!) &)W$f')fi1fi#UE#fi#fifi#[ c) ff'B: $ ff$)aC #&%mO%))@!'0YPUP3 IU<$ ff 8m'@<!$#fi2fi2 # ffM R&%=<<> ff%pC4+6Xfi!K&%M1#fi#$9m E&%KI> )B6fi# $!?<<$H%)4 3# 7;9')fi1fi#[&!g!) &)PUPE% ) E '@!)o+ ffnU%%Jfi1fi#!" > ffn ff>)2&fi#fi#9C/Dg =) !'Bfi!&%E$9^<S)0 $ R&%R o!"<2 #YffUPE )&fi# ff'@!BA<> )o+ ff%B&)/ # 7+9K&%<!$)R pfi!) ) )Rfi#!V fi#9@ 1E .) 0CRDg ) R&%o6fi# $!B<<$ ff%UPE$j6!fi#fi#9@!&$(fiuwvuu un+o+pqrbsm,Xn+r pqPfi!))WW'B1$fi#aN$ff$J; ff$)ff7;$ ff)E$ff$G+ ff>) EUP ff fi!%#ff%fi2 #&=# ff); ff$) E(U* fi&# ff)$`b$ff$; ff$) EUP fffi!ffMff) ) fi!ff) ) fi!1>ff$ fffi# #I21$fi#aN# ff); ff$)(UP ff fi!)&%1)WX1$ff$ ffyb) &)wuuuffvuuuDn1fi#"u+* ZPfi!) ))#) M! 3&%"O!!Xfi!1Sfi#)G1S_UPc&%) M<!$)B Wfi!) ))C K[ =!O$ ffd )1$UPd2fifin<!$)W 2Nfi!) ))f)T&%#)WUP fffi#X W'B fi0&%=$9<)E 2Nfi!1Sfi!: $ ff$)T&%E!3<#CWTA<$!'B )=$4) #ff3) ) ) )T&%=7i0$_9<) n6fi# $)p1#fi#$93#j;9['B#) fi!1Sfi\!) &)M8&%MOi0tO%=fi#!'B!!['B#) fi!1Sfi!) &)"%)B ff<$# #@29C ) $!1St PA^<S$!'B&fiR'B&% M:e # ffMCjC'e {RgZ!i0$_DE%#)W$)$%@ ff>2 K.> ff'Oi $ )*2$) ) !K&%WO)&VB Rff'@2 @fi!`b E'@<<b$ ff')&2 fi#fi# 4&CRyzd<<fi#9d'JH%!4fi!" %#L^) @&%#)W<$ ff1fi#'UPfi# ff<&%P#)4 ff) )&)6fi# $)R $'B E'B#) fi!1SfiK&2!4)&)CRP)&fi# ).> ff'Q&%#)ff VJ1P; ff@!ds;P$ fi#9@l$#fi;YpuvvwYffuavvw1xC0Dg =A<fi# ff$EO%)oL^) # ff4b$&%Y% ) P; ffR# # fffi&) )n= ffR% #EUE)/1)@ ff@o] ff'B/ pUW%&%&%Efi!1fi#!<$ ) )E!fi!5)&1)2fifi#fi#) n)&1]$ #ff#$9M ffP #) CPybMO%)T) # ffpYUP#j;9d% Ufi!1fi#!M $ $)W'@a9">)=!M%K R&%6 ff'J!)C,JLAJL <0W0S"wOAW0[A,O"|,zSR[AUMPORAAV|ZDE%:6$)2&) MUP3A^'B! ff) #) )M 28 !'B5)$#)d =fi# ff12fifi#9#) O$!1 )Ofi#fi#ff1) >I# ff) /&% 3$&%p)E)&zbCEDE%4&) TU2)E ff'@<#fi#?19"qlp$#)=XDg UW)&%s$uvv ffxY:fi!)@vBfi# ff)W&%2W ff'J<) )fi#fiN'@2]_ / $) &>2fiN1# ff'B) ,:fiP$9<)ts)=D1fi#KuxCDT%>'B o) ) != ff1)$I)*$P'B)&>'B)R<'B gfi#fi#"&%E ff'@fi##-7i0$EO# ff4!As.Eq yzxC DE%#)RAJ)R '@'B fffi#9t)@ ;RO%'B ff pfi## ff@<$)PUE#&%!Kt<#Afi0/&%T !'BW 22&=L#) # # ffpCPDE%fTq yn) d%$UP$B fi#fi# 193&%BW$9 #ff%5) fi! # ff5E2 'B 51 ff$3&%"# fffi#t"EO'B )&<%$#'B!#) &K) $#)E N' ff$ fi#2fi)Ofi#fi#)C/DE%=%a1PdE^GjIpjbO_;pa2jOj=b$;;0Ia_;zb;$I0;z;b$;;j _$O;;;$*$O*gOoj$0 jOP$b0b&;jIa$fipr v+hsvc%q+mr qhr pm6n++v+v5SIblR#ff>=A*/Dn!!GM) !@) # )C1 \$O`b)&'J<fi\b$ ff'&%3aU )Ofi#fi#d&h ?%ad37+ ff')&<2 !fiW$) fi ffff$M 2Wfi!#&X?fi# ff#&C 3%5 Mff$d<#AfffiT)J) $!119m: !'BM) $#)@$UPfi=Eq yofi!)f'B ff&%fi#9M !'B=!$'B )T.> ff'uvYd19M# )Tfi2 #&YU%%:1E) Obfi+ ff)$!'B!!t' ffWfi!)) )UTO% &%>UE#) /) !'B#fi!)&<&fiff<$ ff<S$ #)WsqOb$#)Dg IU)&%0Ypuvv ffxCDE%='B &%fi#9@'@< fffip)&'@<fi#!"<$ $=fi#fi# UE)P&% ff'@<#fi!# ffKfi# ff`;b$Bff#UE) R&% 3>&%p)P)&zb3fi#) @<O$)W)) fffip9'B#)!M&# ffpCDE%: '@<fiE!; ff '@m#)d<$ #fi!$fi#9) O.fiT; ff@fi!)) 76# ff\ =O# ffm\fi)E)) fffip%)E!&$ ff R&%=1S) W!#$)W 2N&# ffJ$9^<SC\)&'@'@$9B &%)E&r)P<$ ff#K!@D1fiBuCRDE%Efi!))/fi!1fi#)EUP$P) fi# K B$Ob!$fi#9d1$ ff:fi2) ) )UE#&%MA ) #4 ff<%4Ch<)Efi# ff<h.$ ',O%)fi!)) 76`# ff) H%'f'@a94&%@1) K =$fi!Tfi" nfi!) ))* ) & &fi#fi9KBb # fffi#fi#9) #ff76W fi #fiN<> ff<$)aC/lp$ ff'@>'B ) )M<>)&< #Y&%#)fi2) ) 76# ff:) 9)$`'$O )@ff'@<$ ff')G1S_UPcfi!) )Bfi!1fi#)K&%$@) <1fi#K.$ ' ff>) "$) fi$'B @) ) !3&SY0?fi!))=fi!1fi#)@O%=$")O.fio d`_) >)t)OH%52)= fi# #) )CKl ffb$&%B&2fi#)M$ff>8&%M)&<S76h<> ff$)M) \ 3 ff'@<#fi#XO%d&SYR&%d$)$O; $M Jql$#)W3D0 UW)O%?s$uvv x*Z )A%) #t3DV =s>uvv ffxCZ1fi#!3 $ ffT ff>)=!3fi!`b!!d&; ff'@9X$2) ff)C=J) ff$"$#) )1) d#) $Mfi2) ) )M[1 ff$#)G>G) \ 3#) !ff#)&%'B ff3fi!) ))@&%@%)&1 fi#@1$#)!d)O<:&%W%ar.2>fi9M)O'@fi#fi7i0$)!M 'B) NO%<%9) #fiO$!1 )CRl ffoA^'J<fiY&%#) ! # ff31S_UPMB) ) fi!dUP ff Mff2) ) fi!M1SL"7"fi#B M#) pCd ff) L fi#9YR<#Afffi#)Bfi!1fi#[)4ff)) fi!?'@a9d!h.2=$<$)ff<SUP ff fi!$2)Gff#5>)&C,DE%#):) ff$3 B $ ffK#)d)O<!fi#fi#9<$ ff1fi#'@&%: ffdff>d)&<2fif$) fi! # ffm =O%d&c) %$Cf &%@) ff$d 2f > ffB#)M&%7i0$@1$UPd<2fiN3&fig&p`C n !fig&M$O+>)W J&%=$9<&# ffKO%P ff$)&fi#fi#9M!M@$# ffM12) ffK) #fi;Yfi#!'@Bfi# 4 ff&$ fi#)C&fin&X>O+$) K&%B&2 # ffd<$)!3&%@$ pCq7i>)=$#) @1)%'@)@%a")O1) &!fi#fi#9'B 76[&% 3$&%p)4)&zb@b$ ff'k# )"&fi/)C Z1fi#!$ K +[ $)d1S) ?<S !fi&2 # ff\fi1fi#)5$5) !&%51)5 &%!+ '@# ffpC&%) ff$4 N$ ffE>))f1S) = 2/fi`b IE%CPyb:$)W> !G<#ff ff'cfi# ff<'BsCC!YP&%5%ff')&1&$ ff<#)&xK!; ff '@2 # ffLVfi91S ff'B)d "fffin+o+pqrbsm,Xn+r pqCRDE%)f<$ 1fi')W$W1S) P#fifi!)d19@&%) ff$ 0 ffo&SYUW%#%@ ff'Eb$ ff'(&%$A) !"'@<)P fi 1fifi!s5O%UE)Yuvfffi#) ffpY)aYffWfi#fi##) ffpYnuv fi#)$) `_efifi#$)aYRuvxCN ff'@<$#) Rfi!Pfi!1Sfi#)='B ffB&%4&%$='@<))&% UE)&%P&%9d2ff$T+ ff fffi#9d<<$ Aff!'@2 fi#9G, 2N&% 3$&%p)*fi!:)&zb)CWs.elR$t4; fffi# ff2 # ff)=UW%>@&%@&%>"'@<)UP$B!?2ff$'BCjx8DE%"<$ 1fi'k ):&K fi#fi#b$ ff''Bfi<fi#BA<$ )%)W1SM 'B d!M &%P ff'@2))EUPfi#fi*s;e'49&%pYpuvvwxCl ffP&%#)UP ff VY1) : ffM ffTA<$)W)&) # ff)YSU*4!&> ff5' $ ff1$UP&%J+ fifi# UE!?<!$)B fi2) ) () *Ka`bYRa`_YRwa`_Yoa`&uuYRa`&u8s) MD1fi5uJ; ffO%G')t 2W&%fi!) ) )Ox=s;P$ fi9d(l$#fi;YnuvvwxC,JLAJy{zU[A,VW&AAUCSORDE%: fffiP =$#M<<$2fiE#)" c 'B!3UW%&%J 5#d[<<fi##3$#"$0C&) Tfi!)=wvB!) &)fi!1fi#?)< ) # #4 ffEff2 #C*DT%$t>=B#) $O$!1 )RUE#&%4$U* ; ff$ 4fi!)YB) #At ! ff)/O$!1 )CRE ffn'B ff$E&$!12fi)K$"'B#) ):b$ ff'M!) &)CXDT%"fi!) )4#) &$!1 # ff )4b!$fi#95UPfi#fi*1fi!0YoUE#&%4!) &)Wfi!1Sfi "d=!))Wfi!1Sfi#$`bCDT%)B ff'J!8U2)=% ) 81) MO%"% #M WUW%O%= d#d8<<fi##@$#B))&1]$ #!M&$C 3 $ ff#)*!&$ X1S) =@2) ) ) )&'P pb&$=1%a# ffo)1)ff\<) "1S%# ffCyz[#fi=<<fi### ffs;1M) !m57i0$") &xYf'B>3 A<$) )>` W+ @&%ofi@ 2"$)/UP$Tfi))*O%@Q $*2*<$# !@UW%O%&1S ffz`$fi#!@<<fi#)PUP fffi#@Obfi#/ ff4&%!fi)fs3#%YpuvvxC0DE%#)E'B)RO%/Q p&%fi!1fi#)4U*>t!3$ ffT ffEO%2 &$!1 )UP$@ f2L^"#) !ff#)&%c ff:b$ ff'15<`<fi##)CWs;y.*#)P!$) !B E&%P#) # ffK&>WUE)/1fi# 4fi!) ) 7;9"( 1 ff$>fi!<<fi##)W $ fi#9M!M&%<Q'B$#3 A^<>) )W '@!5s3#H%#YnuvvxxC,JLAJI{1[A|,[1[A"[A|0WOAW,V SR|l 0&%#)n&T) Ya&%/ fffi#)R Efi#= E) ff'BR!'@/! &%/) fi!) ) )~*)OV9Ya'BYUE! U=Y1>VY0ff2) )YS+ fi#!K?<&%pC 32H%: P&%Bfi2) ) )t%2)=K ff1) >I# ff)aY09fi#!uaE &fi ff1) $# ff)C 3%=!)E#)/&%4=UE! Um <#Afi)E$<>)19ufi# IU`bfifi+YE>fi7`bIfi!!'@J+2&$)C8DE%M!) &)@UP$MU?ff'Bfi#93b$ ff'&1) B E) 3 ff 'J)b$ ff'1#fi#!)M$ ff5O%#$) #$95 P5) )&%) )E'@%$)E'@<)CDT%tfi!1Sfi#)=; ffT&%#)=) U*><> ffm196$) !3&%B'J)&%$ ff%3K fi# ff) ff'&2 # fffi# ff$#&%'s&%/W4X2fi ff$#&%'sq=<SYP fi#fi#!)YP$ fi##) ffpY mP#) '@pYuvvx x=[&%m'@fffi#fi#9mfi!1fi#!m%m$# ff ffm: ff'@< @' ff# ffCmDE%#)M<$ ff><$ )"$UP 3$9^<S)@ fi1fi#![ $ $() *K ff1]$ )B&%"1fi#! 5 ffdO%Y/)OH% &%@$# ff &%@#)M<$ ff'B!fi#9[ M_9<: ff1]$"%)M<Afi#)K.> ff'O%B ff1]$@fi!) )K!#Em$# ff)B; ff4UW%#%8&%d1 ff$9?#)"fi#Y/c; ff4)OfiP)O< # ff19?%ff'J)sq=<YpuvvxC0l ffPA'@<fi#Y1S) =)OV9K ) 3&< ffV2&%$ ffff%4; fi#!Y)&V9MK+ fi!m1SM ff.)m8O%M&!!5&SC5yb8&%KA^<S$!'B )"O%; fi#fi# IUU*K!O$ ff\&%; fi#fi UE!K ffb) # ff() *o)&V9`;; fi#2<&%`b) )ff) )$`;; fi#!Ca1pI$;R$IjIRpzbRIO&$;;$; $0bb Ioj0IRzb$O; R IoO; &;Ofipr v+hsvc%q+mr qhr pm6n++v+v5SIbuwvPfi!) )W'BP ffP fffi#!=afi=2) )q!$l fi#!DVeVA9 Dn$eV9yz) )uffwvuu1fiBA*RP ff:) ff'B&Kfi2) ) )lR#ff$41*RP ff) (*n ff$#!fiRM) 'BM&!!"!'@2C,JLAJEkSOR C[AR[A|WOAW0V S"|DE%#)B&: ff'B)r.> ff':) 4 W!'@)B E ff&$95$)Bc5) )&2H%) )aC 3%3!) &$<$) )@:x?Mff>8 W<#Afffi#)@)$!1193&%$K fi# ffB3; ff4 A&$B;&$)aCdDE%fi!) ) )R$P$ ff0Y $ ff2fi!Y fffi+Yaff2) )Ya>Y; fi#!&VYa)&V9 O$*4)&V9CDE%$E>/w!) &)!M&%#)&B)W5uJ&$!1fi!)f$='B#) ) !CEDE%b$L9M#) &$!1 # ffWfi!)) )B)J)&% UW5!mDn1fi#dC3DE%Mfi!1fi#!<> ff$K; ff4&%#)B ff'@!8UE)4&%")O'BM); ff&%K) @) ff'&2 # ff3 ff'@2pCKlR#ff$Jd)&% UE)B3 ff$#!fio!'@@ 3&%@fi#O;5# )ff >)&< ff!4) ff'B&# ff419O%Pfi# ff>O%' ff4&%E$#ff%YaUW%#H%)/)19t%'@M$2 @&2!3fi!1fi#)CMy.=#)Bfib$ ff'&%#)BA^'@<fi#YO%&%"$ )t<$ 193&%) ff'&2 # ffMfi# ff$#&%'$B #) 9M!3&$K+ PA^'@<fi#tfi#!Mfi#fi /O%=&$O VK ff&%=$#ff%E R&%!'@t) !K&%=$# ff)W<> ff519"&%==fi# ff$#&%' )!'@< ) ) !1fi#Cyz@ RA<$!'B )PUPE!&> ffK&%T+ fi#fi# UE!B ff.) () *n; fi#2O`b)&V9s.wa`_vxffafi7`b!$s;a`_xff) )>`b>?s `_x4$ ff`bfffits$uO`_xff))$`;+ fi!s+ `_wx)&V9`b)OVA9 &$[s;vI`_xT+ fi!O`)&V9 2&$ffs;wa`_x*K+ fi#!O`bO Vs.wa`_xC1pI$;R$IjIRpzbRIO&$;;$; $0bb Ioj0IRzb$O; R IoO; &;Ofin+o+pqrbsm,Xn+r pq,JLAJ{VU[uOR|ZR[AUU[A,V CW,VS"|DE%: fffiP &%#)"2&) @#)K ?V36$)K!m 'B)@ &%!@)$#$9m ffm3)fi#: uH`_C[fi!1fiR 2u4!2 )t J6$= $3 ff&%a9G3fi!1Sfi)=I`_Y><$) E6$)Tb$ ff''B! ffs;x ")$Gs.xCEDE%@V!" 2*9M19d%'@)#)=) )&>fi#93)&1]$ #43O$Cl>&% 'B ff>Yff)6>)W$ )P&%P ff IR !'BYO%W%! ff))V!!$) )UE#&%&%H%=&%EB7i0$W<>) ffd'J9J "&%=V!CDT%)&2) PU2)E ff'@<#fi#3 ffd1)&%G6$t2 #ff#$9"!:&%='@2fifi#BO# ffM$$&%`UP) # ff$!Yp) &2fi!3sq UP= ) fi;YRuvvSYuavv1pY0uavv ffxCPDE%B&2) E ff&!)ff1) >I# ff)dsa9)&x2H%c) $!119c 3;&>)tO%t'B2)&$K&%G'JAff!'B' '@<Sa`&$Y&%'t1SP 0a9ff)P) !#Efi!) E20Y$ ff%P!AYS&% '@<S&$P<'MY&%UP$`_1fi!13 '@<S&>Y&%BUE!5)O<0Y0O%t$fi!#K%ff'B##$9Y0&%4; ff$) 6$B!AY&%!P<$) )&$YK&%W) )6$WCRybJ ffoA^<S$!'B )PU*&$#K t<>P&%A6$:) $#$9Y/U%$)"%#) $#fi#fi9\&%d'B )@ ff'@'B m) &%#)"3#)" 3&8K! ?1!$9"<> d<$ ff1fi#'&%o#) !ff#)&%)1$UP" 46$@sfi!) )uxo@6>sfi!)) )Ea`_xC) 4T) 'B)%%fi9dfi#!V fi#93&%E U* fi: $ ff ) fi#9"fi!1SfiN46>b$a9G)%!6>fJff#$)OUPE!&> ffMfi!) )P ffb) # ff)E'B &%f<2>() *Ra`_YffI`bY `_SYffa`_wYwa`_Yda`_SC'e#. wc R<j+`i!j11_a$j ]gXi)W) >1S1 ") WO%=) !fi#O`_fi# ff>O%'MY'@2]_ $#_9K: ff) )&)=<$ $)YUPB&$ ?ff'F )@! MO%tO!!d&K1$UP3<!$)= 2/fi2) ) )=O%f$@'B )fi#!V fi#9[ ?1Sd ffb) \ &%d $#!fiEfi!1fi#)Cyzm&%#)KUE9YU*d%aM)'Bfi!\&%d$9<Mfi!1fi#!m $ B&%B#)" '@'B ff8 3%8 ff'@2pCDE%d<!$)J ffi!)) )" XU%%m$ ffBUE)!O$ ff+ P%K ff'@!MUP$)$!13!M&%=<$# ff)) # ffpCl ffP%M 2N : )Y%K&) TU2)Wff'fi9M##5!B&!?s.v@xo)B ) !hs$ua@xo) CoE; PO%&BUE)E)O<fi#! @!<=&!d)E) )YSU*4&%ff < 3&%B&!!dM19:&$ !dfi!1Sfi!3 $ $)=) !d #) @fi#fi#)@!Kb$ ff'K MffF #) CBl ff#) @fi#fi 90Y0h##fiP ff1) $# ff3UW% ) Bfi2) )=UE) ff@ P&%#j6M<$ ff1fi#'@2 #W<!$)/%@9Q%E 21!B ff < 0Cnl ff0A'@<fi#Y&%Pfi`R '@!"@!) &.$ 'fi!) )E"s.1$ff$ ffxo%)E9%1!"%Kfi!) )uuts)O% 1)*K1$Eff> ffxYff"B!) &Eb$ ff'Qfi!) )uuW%2)*9%E 1S%5 :fi!) )tSffC T) !XO%)B'B&% 5&%M<$&@ *O%" !$@&!3) O%=UE)ff < d'@a9G1Sfi#) )WO%;9; ffP'Bfi# 7`bfi2) )f<> ff1fi#'B)f1S) 4 fffi#9M) ff'B<!$) fi!) ) )$4 ff) #$5<$ ff1fi#'@2 #CfDT%t&2fi<$&= * #) B!:&%= < :&!!M&#)f>< ff$M&1fi#)&%E<$) E&%4A^<S$!'BOfi$)&fi# )aCl ffP%d )=fi#fi;YpUP= ff'@<$d&%B=<>29M Rfi!) ) 76$)&!) !B6fi# $M$)&)E6fi# $M&SCl ffR2H%J &% K )P&%E'@V2W<@O%=); ffz`;; fi#@$ ))$`bIfi### ffK 6fi# RO%W ff < @!) &)/b$ ff'QO%W&!BCDg) )) )P&%=1#fi#$9M n&%) !fi#O`_fi# ff$#&%'Y'@2]_ $#_9@) )&)T6fiE'B&% )E B#j;9&%B ff < 3)&)=UP4&%3:%d 2/&%Bfi!Xfi# ff>O%'B)$UE#+ *E6>) f):&%6fi# $3&2) P&%d) !@O%6fi# $:&) aCfi'ejl_` Xpr v+hsvc%q+mr qhr pm6n++v+v5SIb# "!$Wa gE`bH% ) "O%$MUPfifi7`_V UWmfi# ff$#&%')=b$ ff'k&%M'@%Mfi#8) &) #fi*<K$ ff'@'B# #) B; ff '&%r6fi# $)(*o#) # ff:&$)Y$) %ff1S ffEfi!)) 76$)=fi#!='@2H%!)C @$)&$#&%@<$) &# ff: P ff'@<!$#fiP$)&fi# ) M&%)tO%$@fi# `$#&%'B)R %E&%Pfi!$#$9= p ffR<$) &= 2&%E'B&% @B =$EO%'B1n&1fi#)/<$) 0C U*Y!B# # ffB EO%*A<>' )/>< ff$0Y U*Pfi#)A<>' )UE#&%6B1) Bfi#fi/fi# ff$#&%')sO%=&%$B!:&%#)=<<<fi!)=a`_,Z 3q=Ds;P$ fi#9Xi/Y/uavvx xC"=>)&fi# )4+ ffr&%K>) 8) B Efi!h2fi ff$#&%'B)B)&% UP5&%@)O'B&$))E&% )=$< ff> M!M&%#)$ #fi#CRX+_`_Aj iXjAF $g,{`hjjdxd$`hjljC #)"#&%J3fi#ar &2!m:fi2) ) 76# ffffc&$!1 B )YpUE#&%:; ff%3I2fiJ E&%@&$!1 YnM1%3K#) # ffc&$C@Dgfi!) ) 7;9XK!)@) !GJ#) # ff:&$Y ff4) &> )WEO%t$ E ff@6)WO%t1%ff >)&< ff!m c&%dfi!X 2=&%d )"&>1d ff1) >[!mO%d!) &CQDE%#)d<$ ) )$<S)"B&%M)O1&$d$B&%@1%m #fiW:fiffM#)"$2H%0CmDE%M!) &#)"O%m) ) #ff\&%Mfi!) )@fi!1SfiW &%Mfi#a>C\dUPfi#fij`_V UW[<<$ ff%8 3 ff) & !?#) # ff8&$J)4 Mff$ U,&$" #fi/%3 P&%@ 'B!fi* )dsfi#)&x ff&!3!) &)b$ ff'@) !fi#@fi!))t:&%5< @1VM&%4&$BUE#&%:&%B ff1]$ #B R6!dO%t)O1&$UE#&%\&%3fi# U*)G'B#) fi!)) 76# ffQCK!'@<fi#'B2fi ff$#&%' ) )dPCj)"<'B&% MUE#&%:B ff6Bfi#fi0 /C!uMs;!fi!pYnuvvxC /Dg ) fi#/E )0; ffnW P&%/&>Y U*oH% ) o&%P ) n&%R'@A!'B#-)R&%P; ff 'J# ff`ff!8# 3'B&$#5s;!fipYEuvwxC"4!'@<fi#'B&# ff8) )=&%M'B!!'t''B14 E!`) &)E 4+ 'B ) = 1S=Lfi0 B$UPC W#$!4) dO$=fi# ff$#&%')W$L>&%%@ )*%#) $ ='B1o ff'B)CRDg t'BP&%#)E$L!$'BY%@ $$;&$uk]n#)f'J<<M @B)* 2N ff$$+2&$)E19J6!G4) ff fiK ) )E 2&%; ff' k]" YUW%$<T#)*!&%W 1) $df"#)W4W<S !Pw] CREfi# ff>O%'6)&%4Ifi!B G&%W'@2Aff!'B#-)&%4; ff 'J# ff`bff!:# CPD0 K&%#)0Y&%4 ff1) $dI2fi); ffk]p$P) ff> 0YB&%E'B#< ! )E1$UP4fi2) )*1S ff$#)*$PIfi!3s;!fipYuavwla99ffM,yz;Y0uvvxCZT]j_`hj$6-]j+#ZK2<g]`d-ffF a_1$($hED4j ` s+q="$aYuvxT)BK) 8!) &)Y%Bb$ ff' ff N'fi!) ))Y&%P$) 4fi2) ) 7+9d"fi!1Sfi3!) &=ff$!B B&%'@2]_ ff>$9fi!) )j62 # ff@ 2O%*!))kB$) P%ff1S ff$)C/yzB&%#)/$) # ffB p&%Wfi# $#&%'%8!) &M!8&%M&!c&3<$) 3&%Mfi# ff$#&%' )K$&!0CmD0 3 'B!&%K#) &M1$UP?:<! E!) &)@UP"<<fi#95&% 3 fi##8#) &M'B&>C:ybc ffA<$!'B u) KU2)E) E B ffC)J) W 2(fi!#) >'r. # ff)O%W$B) fifi#O`#fi#9d G)) #ff3:)&B K ffB /&%fi!) ))"s;E#fi#) ) pYRuvwxC Z u1KM!) &) $!< # ff3s;<ff xn ff)) != 0ff) &EuEB&%W;&$)R&%2R) $!1&%!) &CoDE%@2H%J#) $!'B!P.t] 3xR%)P&%E; ff' ] ?YU%$o]0#)E4 ffWxuB ffOK )C fi#!@'JH%!K!+$)B!) &ff1fi# ff)B Mfi!)) _T7W? fi937-!_1F+Xi]jEj_`a1=0.IO;0n + 7 $_I;gbzjoIbEOz;j*z;Ij$&;$IOj Ipz bP$o2$;&zbO;0a&PI$<a IabEp =&oIIobzjOj jM$$zt P;a t$( zI$Tj_Oz0 @Ij$&z j;o=IRa&;a'fi#) Z fi&fiT #)uO`_Eel3lPlEZel3lPlq`_Dn$Eel3lPlCjCjuCjCjuCjCjuCjCjuCjCjw CjvC!uu uCjvCjuCjvCjC!uCjw uCjCjuCjCjuCjwCjCjwn+o+pqrbsm,Xn+r pqCjCjuCjSCj,CjSCjuCjwSCuCjwSC,CjvSCjuCjwSCjuCjvSCj,CjSC!uu uCjSCjuCjSCj,CjSCjuCjvuwSCjuCjCjwSC!uu C!uwSCjw uCjwSC!uu CjSCjCSCjCjvSCjCvSCjw CjSCjCjCjuCjwSCjv uCjSCjuCjwuCjwCjuC7CuC7CjuC7CjuC7vwCjC7CjCuCjw C7CjC7Cjv uC7CjC7CjCuCjuCuCjSuCjv,C7Cjw ,C7CjuC7vCj,C7wCjv ,vC72Cj,C7wC,C7v2CjC7wvCjv uC7vCjw ,C7vC,C7C!uu ,C7ffvSCwCjCjCjCjCjCjvCjv CjwCjw CjSuCjQCjwSuCjCCjCjvwCjCjSuCjv CjwCjCSuCjC!u1fi#BA*/Pfi!) )j62 # ffd9@KfiPmm;aN_bxZ+]>sXx 3xCnl ffo&%=$) )TUW%#H%+]_s 3xa 3x*1#&$9@#) # ff#)f'J+R* ffP!'@<fi#'Bb &/Z % ff ))E&%=)O'@fi#fi#E _/b !M&%)) )CDg :6[&%MUP#ff% )@ &%Mfi#M'@%MUPd) :&%M&% 'JfiP&!!? fi#s.*> fffi#9i/YEuvvxCc $"'B 76# ff 5&%#)"<$ $ms;P$ fffi#9YuvvxB$) ))@&%<$ ff1fi#'O%/&%UP#ff%)R; ffG19@&%#)Wfi<: ffJ&%W $R!KUW%#%K&%W!))E$<$) 0E<S ff 0 ff>$!Wfi#4 Wr!ofi!) ) 76CRDg W'B!!'B#-E&%#)N<> ff1fi#'MY &%&% 'Jfi&!K<$ ff>)<<fi#: J !'B)Y) !"r7i>E $$!4+ ffo&%!) &)%8 !'BCmDE%#)"<$ )" Z m)aY/%cUE#&%m37i0$J) B fUP#ff% )C8DE% Z &%'@A!'B#-)WO%; ff 'J# ff`bff!:# "'BO$#=#)E&%H% )pC'eEc jAF gCCa#j+`bg,1$($hEDGFb_Ag, ;F+F `h_1Fbk^a_MDn1fi#=UP)&% U[&%29@; ffRO%Wfi!&4 0&%fi2) ) 76$)T+ ff'B"19@%@&%P&%$fi# ff$#&%'B)R) @) !t r6fiWs;T ffxY) !fi#O`_fi# $#&%'(6fiEs;el/x 0'@]$ ff$#$96fi# "s+Xl/xY5K ff) )&)r6fi# @s;Pl/xCpDE%46$) => IU$<S ff$ )&%@ #) KB) 5ff <W&%BCWT 4&%T+ ffT&%#)&2) WO%<S$&4 /&%B>tO!!M) &%#)= ff < 3; ff=)G2 B9cUE#fi#fi1S@fi#) )B&%91)" fffi#93) ff'"<!$)= 2*fi!) ) )$B ff)><$ 1fi'J#C@DE%"fiN<S$&@ 2* ff < 3&!!dK)B$< $!M&%) ffX$ U R&%&1fi#C%5 3 #) @#)=!&$ 0Yn6fi# $!3# ='JV @M) #ff76B7i>@; ff9d&%='BO% ff) ffK&%#)&) aCNe!B&% ff>2fi=#) Eff@1B #) b$YUP%a" 3UEa9d :Ifi!MU%&%6fi# $!5!'@<> I)tO%d;&Bfi!) ) 76[29h)&% )E&BaI#fi!1fi#@%$CK #=IR;j$$6@b zb0;PI/ jPj&;jIj;zNIz=Io;&Pnj$ ;aIj&;jIj0 ;_;b8O=I"j;zR W " zjO;Iz=fipr v+hsvc%q+mr qhr pm6n++v+v5SIbl ffn #) Efi#fi#)E<B UW%#B&b$ ff''@2]_ ff>$96fi#fi#fi'B&% )RUP$E1fi#@$&2fi# ) B&%!4 ^5$#&aff$a YUW%#H%UPO6= @14&%P ff1&2+ /O%)* #) @3 K6fi$!Cl ff #) Bfi#fi#)= /3ffMY^6fi$!d!'@<$ )9; ffRfi#fi&%>Wfi# ff$#&%')YUE#&%J'@]$ ff$#$96fi# $!@<_+ ff'B!=) fi##ff% fi#9"1 R&%ff) )&)o ff) !fi#O`_fi# ff>O%'6fi# $!Cl P&%#)&)Y&%B1) fi!) )j62 # ff3'B&% )U*>"uO`_#) # ff8&$)aYN2fiO% ffff%5B#) Kfi#fi/ 2fi#fio&%$"fi# $#&%'B)t2H%#m ff'J<1fi#2)aCdyb8D1fi3u8s) @<<#Ax@UP@)&% U&%M$)&fi# )B W:<!$7`b) = ff'J<$!T6fi# $!?s;T ffxP K%M R&%6fi# >d'&% ff)aCEDE%B&1fi#t$<S ff$ )&%B<`bIfi!YpUW%#%#)B&%"<$ ff11fi##$9?O%=&%Jji0$M!c&%K_UP M)&'@<fi#G'B)=#)B" :H%C 9 lR#ff$M)O% IUT)=Mff<%d 2O%"93fi!))35uO`_)=O%B6fiRfi!) ) 764 E&%B6fi# >&SCdE @&%B&%J$Kfi1fi#el$O;$)B d&%M$)&fi# )4b$ ff') !h:) !fi#dfi# $#&%'6fi# ff) & Mff!J&%)&'Bfi#fi# ff>O%')E&%62fi0fi!) ) 76C100NoneSFMFCFAccuracy90807060020103040Noise LevellR#ff$=A*R9K R&%fi!&r+ EMuO`_=Cl ffp&%>/ &%*>'@!!+ ffg&2) )0UPR)&% U5ff<%)N>< ff$&%P9%&%r+ ff*6fi$!d'B&% )s; Y) !fi#O`_fi# ff$#&%'Y0'@]$ ff$#$9Gff) )&)&xT!: ffa]>UE#&%:B6finfi!) ) 76Yp)fih19M% ff )J; ffP%M) E&%@'B ) W2 /&%4&%$fi#!2fi ff$#&%'B)MUW% \UE#&%c6fiMUE#&% ffM!a]_ #) Cl ffJ&%:6$&2) YU*B% ) @ ")&% U&%@$)Ofi); ffWK#) # ffc&$@1S) K&%) @$)&fi# )B< ) )) )&%fi!$)ji0$M!52951$UP:6fi# $!5? r6fi# $!CMDE%Bbfi#fi/&1fi#@ 2T>)&fi# ); ffP%K&)*d1; ff::D1fi)Bua`_SuW!&%f<<S#ACl ffP&%B$#XslR#ff>twxY&%4fi!4'@%!t#)=K1 Efi#!312)&%M#&%&%uO`_m ffg&%P#) # ffJ&$*2)Rff#M19# )/%#ff%o1) O`bfi#fi29Gs;SCjE$)&)RC!uMCjwxCyz@&%#)E2) f<<fi9!"4) !fi#O`_fi# ff$#&%' ff/'@2]_ $#_946fi# ofi#)E 4) fi##ff%fi9M1$)&fi# )T&%4 ff) )&)6fio+ * )=fi#fi#)f1 MCnEE #) =fi#fi#) Nd%%Y6fi# $!d2) ) K'J<$ Bfi2) ) 76# ff529CEF )Yp#)Bfi!V fi#95O%f9M&%P6fi# >@'BO% ff)o fffi#"!'@<$9@1) W!)&KW%#ff%BLfi##$9@&!!B&#)taI2fi!1fi#@ d1fi#m3=6fi# Ctyz0YN2Wff #) Y0&%@) B EK ff) )&)6fi#9fi#)fi# UP*29M$fi!#= /6fi# >Y)T&%=1!) )E R#) # ffMO$)W5uO`_fi2a1pI$;j _I$4b$j;IjK$ jzb$dIjoj;jB&gj$;;b;j.;ToIOPI;bO;$d &EIb$ ;$;nIO/tzj$ O;$pO20 z;b ffb$ Oz ffr;aIB;zt;jj$$O;@;j 0pj@TbIbjj 4;Eb= ;_;g;_;$an O/Ojj&;$= R&; oIjtIO0 R;_;g;_;g bn zb z$pfin+o+pqrbsm,Xn+r pq100NoneSelfMajorityConsensusAccuracy9080706001020Noise Level3040lR#ff$=wA*W29" R&%$#&4; ffPBfi#!'@%!C100NoneSFMFCFAccuracy90807060020103040Noise LevellR#ff$=A*W29" R&%=$M) ff'B&K&r+ EB#) # ff:&$C100Accuracy908070600NoneSFMFCF1020Noise Level3040lR#ff$= R* W9M &%4) =)ff'B&# ffJ&4; ffPMuO`_4Cfipr v+hsvc%q+mr qhr pm6n++v+v5SIb&%B'B&% X "fi#!'B!"'J9M ff d!) &)"sUP=UE#fi#fiRA^<d&%#)=< UW%:UP=#) ) )&% > ffE)* 2N&%6fi# >)W!de MCjSCjxlR#ff>)dm5)&% U&%5$)Ofi)M t&%5$) ff'B&# ff\) 3) 'BO# ff$)&<S #fi#9C*DT%) W$UP&2) )*$E) !'B#fi!P!J&%/O%9@UP$Efi!1fi#3) !tO%W)&'BE)Ofifi!1fi#!M<$ ff))fs) >1SM!"e # ffJC!uCjxY1oji0o!@O%P+2&$)*')&$""&%T)fi!)) )CRl ffo&%=$ ffK) ff'&2 # ffK&fi#fi0&%$6fi# >M'B&% )E<z; ff ' ff'@<1fi93!:H%) B)&1)2fifi#9:'J<$ @9d$fi!G T6fi# $!Cl ffP&%#))) !t#) # ffJ&$E)RT6fifi!) )j6o9#fiK) fi##ff% fi#91S R<Sz+ '@EO%BBuO`_W\UPB)&% U,$)&fi# ); ff&%#)='B&% 0C=l ff&%B) @)ff'B&# ff:&SY0duO`_UE)fK)fi#ff% fi#91 6fifi!) )j6T)P)&% UWB!MD1fiBuCnl ffR&%#)P&2) Yff2* #) fi#fi#)E N,Kff&%W'J]$ ff$#$96fi# P<z; ff ')*1 R&%@%B 0&%T &%$)PG>&!)*1)O`bfi!=9"#) CPDE%!'@<$ 'E!:9J.> ff'(6fi$!@; ffP%K O%) =$UP =) 'BO# ff&2) )=?1SG&$!1 8 d&%!4fi!) )B) <1#fi#$9C5e<76fi#fi#9ffYP#B#)@$fi!#fi#9?2) 95)&<S W fi#>)f1S) B&%$4 /&%;&$)!d2H%&) 'B)&$ fiX'@9K /&%fi!) ) )$UPfi#fi7`b) <2 d!M)O<&2fi0)&<CAccuracy80NoneSFMFCFfi7060020103040Noise LevellR#ff$tv*9M 2N&%6>) $#$9"2&4; ffPB#) # ff:&$CDT%W$)&fi# )o; ffR&%T6$) $#$9B&)/7i0/)O1) &!fi#fi#9B.> ff'&% &%N+ R&2) )ClR#ff$"v)&% UE)&%">)&fi# ); ff&%@#) # ff8O$"fi# ff>O%'$ ) )4&%@) #A5 #) @fi#fi#)Cl ff&%#)=2&) YS6fi# $!d!'@<> I)fi2) ) 76# ff529:+ W )CtP2fifio&%#) @UE)!O$ ff['B ff3fi!) ) )@a`_Yo1 t!8fi!) )MuC58fi# )=!) #ff2 # ffpYRUP"#) >&%KUW%<<fi#986fi# >\ 8&%d ff>2fi&) 3s;#) xMfi!'B )fi#fi =&%!) &)b$ ff'fi!) ) )=I`_@UP$4&3) #) 9X19dfi#fiR&%$r6fi'B&% )CD1fi#BM)&% UE)'@<$#) ffh E&%"#) O$!1 # ff8 E!) &)B!5O%@ ff$#!fiP&2) =8 E&%@!) &)fi#O+=I+K'@]$ ff$#$9@6fi# %2)f1S5<<fi##0C BA^'B!XO%')fi2) ) 76# ff5'J&$#AM; ff&% ff$#!fip&BJ; ff"O%*1S ffE%fi7N 2O%W > ff$)E$)&fi# J.> ff'fi2) ) 7+9!@!) &)fi!1 fi#a`_52)@fi!) )dudm&%d O%t%2fij=UP$Kb$ ff'fi!) )j;9mfi!)ff) 9)Bfi2) ) YoUW%$95 9 SCET+ 6fi# $!Yp&%B) E ff&!)=K<$<B /!) &)1fi# ffm 5fi!) )5uCeH%\[m#) &$!1 # ff ffi!)) )G>)&fi# )M!mfi!) ) 76$)d1!)UE$fi!) ) 7;9ff!$9!)*)nfi!) )PuYUW%#%4r&%/ $#!fiff#) O$!1 # ff4 ^O%/!) &)s;'@2&!K!@&% ff < K ) o!) &)&x#)> ffff%fi#9@MCRyb&$ !@'B ff$W )W!fi!) ) )=I`_K8 W%B&%#)=1S%# ff=XO%$O+ $YO%29d>)"s) BlR#ff$@vxfi$#!finq=&)5]$ ff$#$9tlR#fi#uffuCjvSCjn+o+pqrbsm,Xn+r pqCjCjC7uwCju CjCjuSuCjCwCjuCjvvCjCjCjC!uDn1fi#=1*EPfi!))E#) &$!1 # ffG+ ffo&%6>) $#$9@&2) PUE#&%MMUE#&% ffo6fi# $!M: )#)auZXPE ffPluCjuuCSuCuvC7SuCjuC7vffSuCjwuvCuC!uCffwCjwC7E$#ffPlwSC!u ffSCjvSCjSCjvvSCjSCjuuCjSCjuSCvSCjvuwSCjwSC!uP ff2ffPluCjvvC7wCjvC7uC!uvC7wCjuuuC7vvCjuuC7ffCjwuC7eEPlffSCjffCjvSC!uffCjuaCjuCjvuaCjwCjCjvC!uCuuwCjlR!$Be$#$9E ffPlC7uaCwC7vuaCjuC7vuaCjwC7uawCjv CuuawCjvC7uaC!uDn1fi#tA*/Dn$) #-rGff'B1SE Rfi#a)$'@2rR$ ) )N2fifi #) Pfi#fi#)C/yz=O%*O# # fffi) / 2&%#)R&) Es;<$# !r6$/>)&)M6>x=2)B ECjwU*>@ ff1) $3+ $ff$) ) 5<$# # ffpYRUW%#fi#K; ff&%@&2)&VM<$# !3fi# IUFs>uO`_x$)O)=%%5$#)&V:a9ff)"s2`_xEO%293UE)fCjs;) fi/q IUPYuvvxC/yzd)O'@'@$9Y^+ ff&%#)&) aYUP ffa]_O$=&%2W#&%T&%;&>)f>2L^#) $!'B!fi2) ) )Ea`_Y ff&%Efi!1Sfi)TJ&%E $#!fiffO!"ff>W p)&1]$ #ff#$9&%E'@V )E#W!'@<S ) ) !1fi#B @$2 =2 6fi# C'ec jAF gCCa#j+`bg,$`hjljvj<<fi9!:6fi$) K&%B&!!d@fi#)4 ")O1) &!fi#fi#9X)O'@fi#fi##) # ffc&$)C=Dn1fi#@$<S ff$ )P&%ff'B1SP fi#a)P!K) M&$)E<$ Kb$ ff'&% ff) )&)P6fi# >dM&%6fi# $MC ( l ffoa`_ #) Y&%T6fi$M&r$)P&$)PUE#&%;U*fi#)*O%@O$)) !'@2 :.$ '&%B ff$#!fin&)CEl ffEO%t$ ff2d) ff'&2 # ffd6$B) $#$9M&2) )Y4ff #) Yo&%K&$)@<$ mb$ ff'&%J6fi$m&3%aJ+UP4fi#)@&%c&%ff=<$ Mb$ ff'&%4 ff$#!fi02&) EE )C/DE%#)WOi0PUE)Wfi#) B ff1)$d1ff9 % %s$uvvx&>1? *4=1#fi#$98 X$' I5 ffb) !3!) &)Bb$ ff'k&%&2!52&Yn&%$19?$!8&%")-M 2W&%Kfi[#) # ff &$)C3)@%)s$uvvx4)&% UPm'@<!$#fi#fi9&%2B+ @'@9?2&) )J&%$M#)Gcfi#!">fi2 # ff)&%!<1$UP&$T) #-W@&%ff'B1 0&!!=!))R@ff'Bfi#9B!$) !B&%W'B1 &!!) &)/%2)R&%POin !$)4&$P) #-E4UW%B< !4)/<<fi#0C # DE%!Rfi#9ff))P4H4)&% UE)WO%WuCjw *&%B$2) Bh&$=)-J)B&>1O1fi#t G$ff"!$#%a1pIb$j;/ b$4 ;$;$O/ ; IoIb/ j$ O$RpjtIjIIaj;z;Ia^ 0nIORI'& zbzI$o=_O;$&;j0jI$/O0P$&ab_O0 n)( j$Oz!1pjgbzj&jIa@O I;o j;P bOI$b_$ ,IO/'& bbzg;aIP$I$'fiTrainingInstancesTrainingInstancesTrainingInstancespr v+hsvc%q+mr qhr pm6n++v+v5SIb* * ** * ,** * Filter** * *CorrectlyLabeledTrainingInstances-1 11 11 141 31Filter+LearningAlgorithmClassifier//C1-.Algorithm 1C20Algorithm N2CorrectlyLabeledTrainingInstances554Algorithm 1Algorithm NMajVoteCN66C1C27MajVoteCNlR#ff$@u* 3 fi#)W ff'J<$&%) # -W 2&%E&!J) CRDE%$'@!o#)EW =&%$'B2fi !+ '@#!) &)s; #) xCQ) ffMO$d!MO$) #-=#)<<$P&%t>)&fi# )W<$) ::D1fiBA*R)E&%= )fi#fi!$2) )P&%E) #- 0&%E&$)+ 'B4.> ff',6fi# $K&$ UE)/'B ff$TL^#Vfi#9@&%B&%) #- &%T&$)n; ff 'B4b$ ff'6fi# $K&CnDE%#)*$!; ff$)P&%PUPfi#fij`_V UWK<% ff'B ffJ&%#) @!:&%@fi!))fi1fi#)=!$))=&%B) #-@ E@#) # ffc&$Crf3A< # ff3 "&%#)fi&$K#)E ff1) >@; ff&%6$) $#$9@&2) CT &%o; ffRO%)T&) aYff29"K&$) #-M$"<<> IA!'@fi#93 ff)=2$ ) )$# ff)@ #) @fi#fi#)CdDT%)B$)&fi# )@1) @; ff%fi#fin N #) 4&%='B&% d&%> IUT)* Wfi!'B ) T&%)&'B)O1) E R&%!) &)aC'e8:9g1iKEj ` $ ,$Haj `biK%9< O%) #) N! $) T)UW%&%@'@2]_ $#_9J ) 'B1fi#tfi!)) 76M1B) d!)2R6fi# $!CBDg " )W&%#)=%9^<S &%) #)4U*r+ 'Bd$UP M'@]$ ff$#$9" =)'t1fi#@fi!)) 76$)(* ffb$ ff'&%46fi# $?5 ff4.> ff'F6fi# >?CtDT%'J]$ ff$#$9M 4) 'B1fiK) $)=)&%*a# & *n" P)/O%E6fi# s;)o)&% UWB!J&%f1S 'Q_UP 4) H%')/<# M!KlR#ff$uxCNDT%=$)&fi# !Mfi!) ) 76$)UP$&%M) : @fi!) ) 7;9M&%= ff < )E&CDT%"$)&fi# )4; ff&%@fi!8$B)&% UWh8Dn1fi#GwCKl ff%5 E&%>"'B&% );s ffY 5]$ ff$#$9W@P ff))&)&xgU*o ff'@<>/&%P94'@2]_ ff>$9 ofi!) ) 76n &%uO`_\fi2) ) 76YUW%#H%J#)/&%'B ) /E p&%E&%>W1) O`bfi#fifi2) ) 76$)o+ R&%#)/ '@!pCDE%&1fi!fi!)&%<`bIfi!) Rt<2>M$`b ) P @) )) )P&%) #ff76B!K&%7i>; ff1S$U*c&%M'@]$ ff$#$9dfi!)) 76@uO`_W fi2) ) 76C5DE%M'@]$ ff$#$9d @fi!) )j6)'@K<3cuO`_=Y0) 5&>"?Kfi#!B'@%!C @# =)"9XUP#ff% !) %'BT+ ff ff'B1!J&%!/ )Cnl R%B6fi# >B) %'BY&%'@]$ ff$#$9= Efi!) )j6T%)Lfi ffR1S9B&%&%tuH`_W\fi!) ) 76oUE#&%BO%EAff< K #) fi#fi#)P a`_; ffP&%B'@]$ ff$#$9B6fi# CoEEfi# UPE #) =fi#fi#)"s;I`&u@x6fi# $!M )f %=Bfi!$4'J<ff3O%293 *O%"'@]$ ff$#$9d Bfi!) ) 76C UPY0=%#ff%B #) Jfifi)ds;a`_@xY1 &%3'@]$ ff$#$9d5 ff))&)6fi# $!3'J<$ B&%@'@]$ ff$#$9M 4fi!) ) 76)@9d&%P ff1O!dUW%: B6fi# $!G'&% ff:UE)E<<fi#0C'fiE #)Z fiuffE @lR#fi#uO`_SCjCjuCjwSCjuCjvwSCj3%CjwC!uCjwC!uCjvSuCj<SCjSCjSCjSCjSCjwSCjn+o+pqrbsm,Xn+r pqh2]_ $#_9BlR#fi#3%uO`_<wCjCjCjCjCjCjCjwCjwCffCjwCjC!uuCjCjCjuCjvCjCjwff)3%C!uCjCjCCjCjw)&)lR#fiuO`_<CjCffCCff2wC!uCj2CjCjSuCjCjCjvCjDn1fi#twA*oP ff'@<>) ffK 06fi# $!M B !B"fi!&DT%f$)Ofi)P+ /O%=$'@!!@; ffo&2) )*$)&% UWJMDn1fi#)a`_r&%f<<SApCyb8) ?s$#&xY*8!#2fi='B&% sfi#"'@2H%!xBUE)@'B ff>GM&%pY ff<<$ A!'@fi#9@L#Ifi#W Y&%'@]$ ff$#$9= Efi!) )j6*+ ff$9B6fi# >K'B&% 0CRl ff&%&%o&%>W) )Y&%'@2]_ ff>$9B Wfi!) )j6U2)* "2W1 o&%K&%) !fi#t1S)fi!) ) 76C 3 Afi!3&%J) @) ff'&2 # ff:&Y0<<fi#9!Xd'J]$ ff$#$9" ff ) )&)6fi#M&%M1#fi#!d4fi2) ) 76W)K&%) !fi#t1S) Wfi# ff>O%' ff&<Sz+ 'BM@'@]$ ff$#$9Bfi!) ) 76UE#&% P6fi# $!K+ E #) =fi#fi#) EuX%#ff%C 3 Aff<T; ffP&%= #) 4); ff4&%d$ ff[m) M) ff'B&8&Y/m&%d) K; ff4&%M) :&Yn6fi# >!'@<$ \&%X9m &%X'@2]_ $#_98 Mfi2) ) 76K @ J6fi# $!Cyz[# # ffpYT!'@93) )ds;<> #fi$fi#9B%#ff%@ #) Mfi#fi#)&x46fi# >8<<fi#mUTO%8&%G1S) B!#fifi!) ) 76T ff1&!31#)&%<<fi#9MO%='@]$ ff$#$9B fi!) )j6T @6fi# $&SC=DE%) Bfi!) $UP G>)&fi# )'B ff)B&%T; ffEO%) @&2) )Yp'@]$ ff$#$9K Bfi!) ) 76$)$<fi!6fi# $!C'e ;<Ca j `AF $ ,`j gDg G)) ) )&%46fi$)p1#fi#$93 @# 7+95'B#) fi!1Sfi8!) &)aYpU*4A^'B!5&%=! $)1$UP4&%P) n !) &)o&%nU*>/ ff < @=&%P) R 2)&)R&%nUP$/OB)'B#) fi!1Sfi0CPyblR$EE&%#)o)RO%$CRDE%E$)Ofi)R &%#)/2fi9) #)n; ffn&%Pfi!`b&J$=)O% IUM!dDn1fi#@C 3%d> IU&%=O1fi#>< ff$)E&%tP&%4 d)W&%ff'B1SP 0!) &)E#)$d19JH%J6fi#Y&%'t1SP 0!) &)ff < ?!8&%M2&Y/8; ff2H%h6fi# B&%Mff'B1SB W!) &)@!8&%"! $)&%M) K ff <2&5m&%:) @ #)$Cmy;fi#fi#9&%M) @ !) &)#)$c)&% fffi#3 ff'@<fi# fi#93 $)&%=) * #) 9:!) &)C4eJU*B'@a9G%aB #) 9!) &)PG1 E&%'t1So$ 76!fi#fi#9" ff < K)&)PUPEEV IU\&%=ff'B1SC@DE%$O; ff$B!3&%#)tfi#9ff) #)4U*@<<> IA!'@B ff2fifi!)t 2<$#) # ff819) )O'B!"&%2E&% fffi#9d #) 9M!) &)f>=&% )&%EUPA<fi## fi#93 ff <0C*yzM&%#))UPWUP fffi#Mfi#!V &%! $) # ffM1S$U*KO%W!) &)E#)$3"O%)&)E ff <313uMCMyz?<2 #"UP@) K&%4&%#)B)@ 4&%@)CdP)&fi# )4; ff&%M$'@2!:; ff&2) )E$#!dDn1fi#)fwI`_v4 NO%f<<SApCyz@Dn1fi#)I`&uUPW$< $/) 'J)/ 2O%W<$ ff11#fi## #)E&%%46fi# /'@V `) HKuEffHB$ $)C \@is H"uaxE$<$) )&%B<$ ff11#fi##$9X 2/&%$ UE!" W X2&@331B) 'J)(*>= ff??A@)B ?CAB ?ADEB='fiE )Z fiuffpr v+hsvc%q+mr qhr pm6n++v+v5SIbyb)&)q)$?F@GBwCjC!uvwCjuuvCjuCj?wCFvCjB ?FwDC7BwwCjvCjuavCjuuv CjwC7ffwCuC7C7wyb))P ff < ?s5xuwCjC!uffCjwwCjvvCjvyz) &)E!:yb $) # ffvCuCjwuaCjvuCjCjwCjCjffC!uCjwCjH?A@GBI?CABH?AvDEuCjB vuCjCvCjwCjDn1fi#tA*EDE%) #- 0&%! >) # ffK 0#)$dG'B#) fi!1Sfi#X2&) )`Nfi!K&s;el auH`_Wx#)Z fiuffefi7/lR#fiPXuH`_W\@s HKux\@s HBxC!uaC7CjCuCj2C7CjC7CjSuCff5]$ ff$#$9tlR#fi#\@is HtxSC!uwSCjSC!uSCjvSCjSC!uSCjwSCjSCjvSCjff) )&)ElR#fi#\@is H"uax \@siHtxSCjwSC!uSCjwSCjSCjSCffSCjSCjSC!uSCjww\@sHKuxDn1fi#tA*lRfi# <$#) # ffG`*fi!\@siH"uaxRa? _KJMLNPOGQSRTQVUffEWRTOGJTRMLXW ? = ?Y>Z W[NS\p^] Z OGOG_a`bWRTQ>Y Z W[NS\p=\@sHBxP$<$) )T&%=<$ ff11#fi##$9d /V <!G12M&@M1=) !'@3)(*\@sHBxa] Z OGOG_a`bWRTQ4cUffEWRTOGJTRMLXW] Z OGOG_a`dW[RTQ= c= ?=l E&%4fi!`b&Y&%$B$@wds;v *vxP &2fi0&!!M!) &)aCfDT%$O+ $Y; ffEB #) =fi#fin /dO% ff) )&)T6fi#\@sHKuxawAj5vu+7vwmuwA77w\@siHtxRauawAj5vu+7vuAw juDn1fi#)a`&uB)&% U)'fi!O$)CPl P&%) 4&) )Y&%B$)&fi# )T+ ff&%= ff))&)E6fi#)&% U,O%&%"<$ 11#fi#$95 E&%> IUT: ff= ff 5&M>'@!)B)&'@fi#fiRh+ %%t )fi#fi#)Y#fi#fi!) &K&%P&% ff) )O)P6fi# o)T ff) $#!K#)$!@CRK&%W &%'fi#)Z fiuan+o+pqrbsm,Xn+r pqefi7/lR#fi# P Z\@s HKux \@sHBxCu7CCu7CC77CC7wC ffC7C ffh2]_ $#_9BlR#fi#\@s HBxC7C7C7C7C7C7C7uCffwCffC7u\@sHKuxP ) )&)lRfi#\@s HKux \@sHBxC7CffC7C7C7C7vC7vC7CuC7wDn1fi#tvA*lRfi# T<$#) # ff`*$#E#)Z fiuaefi7/lR#fi# PKq&$\@s HKux\@sHBxCjCuwCjC7uCjC7vCffC7vCjCffw2]_ $#_9BlR#fi#h\@sHKux \@sHBxCjCuCjC7CjC7CjC7CffvCP ) )&)lRfi#\@s HKux \@sHBxCuuC7CuuC7CuCuCuwC7C7C7vDn1fi#"uaA*nlRfi# <$#) # ff`*$ ff2M) ff'B&# ffK2&#)Z fiuffefi7/lR#fiPXuH`_W\@s HKux\@s HBxCjwC7CjvCuC!uC7C!uaC7CjCff5]$ ff$#$9tlR#fi#\@is HtxSCjSCjSCjwSCjvSCjSC!uSC!uuSCjSC!uSCj\@sHKuxff) )&)ElR#fi#\@is H"uax \@siHtxSCjuSC!uSCjuSCjuSCjuSCjSCjSCSCjSCjDn1fi#"uu*RlR#fiE<$#) # ff`*) )ff'B&# ffK#)Z fiuaefi7/lR#fi# PKq&$\@s HKux\@sHBxCjwCuCjwCuCjC7CjC7CjCffh2]_ $#_9BlR#fi#\@s HBxCjC7CjCuCjwC7uCjC7CjCff\@sHKuxP ) )&)lRfi#\@s HKux \@sHBxC7C7C7C7wC7uC7wC7CuCuvC71fi#KuA*nlR#fiW<$#) # ffG`/6$)$#$9"'fipr v+hsvc%q+mr qhr pm6n++v+v5SIb%0Yn&%M$)&fi# )4fi#fi!) &M&%O%G<$ 11#fi#$95 Wff) )&)46fi# 4fi# !X XV <81&4#)Pfi!$o&%J&%='@2]_ $#_94 T6fi# )o; ffR2H%M #) fi#fi0> ) )Efi#fip&) )CRyb; ff=3 #) Kfi#fiP EffMYn&%MPl%)B3ww s+fi? xYw s$#&xYov s.$ ffxYns) xYff"Fs6>xnH%$&2!@'B#) fi!1SfiM!))CRl ffn&%'@]$ ff$#$96fi# Y&%%N'@V!HKufHB$ ff$)P#)W'B ff>WLfi;C 3 Afi!!"&%>T&=2* #)&%M<$ ff11#fi##$9? E&%)" > ff$)tt>H%)B1 MCdP ff) #$!3&%B'@]$ ff$#$93<_+ ff'B)t1S O%3 ff) )O)=6fi# >)=; ff%#ff%B #))aY0&%#)=)O% IUT)=&%=ff) )&)6fi# )E<$ <) #$9@ UE$@'@V!Htr $ ff>)fs;$O!@1K&x/%!$)W<Sz+ '@W' ff$&%4'@]$ ff$#$9T6fi)nfi)) R1#fi#$9B W>&!4 ff =2&ts++CC!YI'J]$ ff$#$9f'@V )'B ff>`HKuR $ $)&xCDT%6$&)%2)$9@7i0$W<$ 6fi#CPDE%=<$ ff11#fi##$9M &%$ UE!@ * ff&$'@2)Bfi!'B ) ) &=$ ))W&%Jji0$t )@fi#fi#)C"DE%#)4)B1)@; ff&%#)=2&)"!) &)=<<"%aB"%#ff%:fi#fiR / #) C:&%= &%W%0Y&%@<$ 11#fi#$9&%E46fi# TUE#fi#fiN>&!M12&B$#) )f2)E&%= #) 4fifi0!$) )C+y ff3%)d8fi# KYP&%\fi#IH"u: $ @#)d<$ ff11fi9\fi#) )d8%!&%:Mfi#PHB=$ ff;CC!Y&%> IUTK ffE ffYUW%9 ffd%aBBfi# )fi#) ) ) fi9&%:$&!!X12d&SCWT* $) ffBU* fi:fi#V2@ K)O$B&%ff=#)= &%$ UE!K ffA< # ff)Ce f'SI4DE%#)E$ #fi#<$) )*<$ $T+ R#j;9K'B#) fi!1fi#M!) &)aC/DE%$)&fi# )/ 2gB'4`<!$#fiRI2fi2 # ff3'B ff)&:&%T6fi# $!d!'@<$ )fi!) ) 7659+ E) )&%< ) )) )fi!1fi#!d > ff$)CPlR#fi# $!X2fifi# UPX#)=E "&%B1) O`bfi#!"29d13$&! + ffJ #) dfi#fi#)M<m ?k+ ffJfi#fiE&) )YP[<m 8k+ B$U* 3) )s&%B$ ffd) 4) ff'B&# ff&) )&xC/TA<$!'B ))&% U&%2W)E&%B #) Bfi#fi!$) )aY&%1#fi#$9M 0&%='BO% ffK @$&!J&%=1) fi#!t29@$2) )CR3 ff$)#fi#fi)&819M&%r6$=)$#$9M&) aY7*&%B'B&% X)&$ )TUE#&%M@&%2E#) I$fi#9d #) 9Y#=; ff '5246fi# CK, '@<$#) ffh E !M 6fi$!X#fi#fi!) &2 ?O%&%'@2]_ ff>$9@ =fi!)) 76<z; ff 'B31 E&%M&%4##fi/fi!) )j6>)Y01WO%E#W$<fi!T6fi# $!=UW%&$E #) 9Co/$)&fi# )o)&% Um&%R&%E1S) *<<> ff%=#)o ff'B1!6fi# $!58 !CK3Ifi!8 E&%"<$#) # ff8 P6fi# $!3#fi#fi)&mO%ff) )&)6fi# $)@$J ff) $#Kc&%$ UE!3UEa9d ff 5&2=&%KA^<S) K WV <!h')fi1fi#&SYpUW%$); ff'@2]_ ff>$9M 6fi# $)4&%"<$ 11#fi#$93 *O%$ UE!M ff ff52&"5&%<$ ff11fi##$9" 2N$&!!"1K&4$'B ff$TpC/o) ='@2]_ $#_94 6fi$)W<_+ ff',1>`g ffBo&%4 ff) )O)n6fi$)R&%#)/)&% UE)n&%R$&2!B1B&%>)*<_+ ff'@'B ff>W&%K&%$ UE!@ ffP ffM2&r+ ffo&%)=&2) )CnDE%#)W&>M)<$ #fi!$fi#9M!'@< $&UW% ff=%)W1= R&SCDT%=#) )&B / 'B!MU%&% ffE<<fi#9M6fi# $!MJ#M@) 'B) W1Sff) #$0Col n&%WUP ffV) $!1Sd%$Y&%E&UP$$ 76!fi#fi#9" ff < 0C/DE%>O+ ff>E&%&>t'@OE &%Pfi!1fi#!B $ ff>)0UP$EVff UW4<$# ff$;CW; ff$&2 fi#9Y&%#)R$9^<S/!+ '@# ff#)f$fi#9GV UWJ+ E'B ) J&$fipUP ff$fi#"<<fi### ff)aCEybM) ff'B) #&)Y#'@a91< ) )1fi# =)E ff'@!@V UEfi#E ) !'@P&%W'B ffR fi!1Sfi #) !@&)Cnl ff) #&)=UW%$B&%#)BVff UEfi#B#)t =#fi1fiYn&%B ff)$I"&$B P&%B ff) )&)6fi# P#&)E&%E$fi!#fi#9K;U)&)UE#fifin1=#)$K+ /2&B) )PUE#&%Kfi# Ufi#fi#)W'('fin+o+pqrbsm,Xn+r pqfi!1fi#!8 $ ffCKDE%$O; ff$Yn&%M<<fi### ff8 E&%#)t'&% ff8 3$fi!#fi#9? #) J.>") ))&% fffi#3 E) #ff76fi#9d!'@<T&%t<Sz+ '@R&%6figfi2) ) 76# ff3<$ $C8b&$P!$ # ff &%#)/$)>H%4UE#fi#fi1P AfftO%/6fi# R<<$ ff%4 tOO$&afi!1fi#!$ $)/!J&!!@&SC0l RA'@<fi#Y ffEUEa9B = 4&%#)E'B#ff%E1SW B$fi!1fip!) &)E7&%ff) )O)Efi!) )P#)E7i>P&%J&% ff1) $Mfi2) )CRyb))P; ffoUW%#H%J&% ff) )O)/6fi#<$# )n$U* P ffg'B ff$Rfi!) ))UP fffi#) #fi#fi1/#)$0CRDE%#)!$ # ff4#)R<$ #fi!$fi#9!'@< $&1) = R&%=<#$9M /%#ff%MLfi##_9K&2!K&@#fi1fi4; ffP'@9G<<fi#)C/!Mff'@#fi#fi#9"$' I!=!) &)E&%E1 ff $fi9Jfi2) ) 76M#)E&%&%9'B#ff%N1S/A< # ff) E&%R2fiff fi#C %4!) &o#)NA< # ffr E&%Rfi) Y#/B<<S/)RO% ffff%B#R#)/! ff > fi#9@fi!1fi#0C %J<<fi#9ff!B %L)P #j;93fi#!'B!#) 93)&)Yg ffBU)#3)$!3 ff $ fi#9:fi1fi#?A< # ff)CDE%$O; ff$@MV 93L) # ff3!3!'@<> I!dKL^fi##$93)B% U M#) !ff#)&%cAff< # ff)4b$ ff'#) CE4) fi! # ffM @&%#)f<> ff1fi#'F'B#ff%1= @$!) #)&%Efi# ffVME&%@R!UW%#%MB!) &#)E'B#) fi!) )j6:!@ ff>/ = '7#P#)E@A< # ffJ ffPB > ffC<fi!: K)=U%&%UE#&%:fi#'3+12HVYp ff=dfi#@#) !ff#)&%cAff< # ff)b$ ff' #) t12) ffKO%Tfi!) ) 76d1%a# ffWM<;&>Ifi!)CDT%@A^<S$!'B )=) >1Sm!5&%#)B<<4%1S5 6? M!&$ !? #) @!&%E2&!"4'@RO%R#)*&fi+ R&%W<$ #fi!R ff'J!pC/DE%#)/UE)P) )&$9Y1); ff4&%M&) )@) mUPd%[ 5UEa95 W)&>m3 #) O`;b$dfi#2 # ffm )@) Cc V 9; ff)P .&>WUP ff VrUE#fi#fi1SW =2 W #) T.>EIfi### ffK2&) / ffo'B&% " B&%ff$#!fin&) C>= $ fi#9MUP ff V!@ ffM 1&!!d #) b$=fi### ff34+ P&%fi!fi2) ) 76# ff&)&VCdgbRfffi#Bfi!V &%VEO%Bql$#)n; ffg)&<<fi#9ff!B&%EEq yp&)YIP Tq=<g; ffP<$ !:&%=fi!) ) .) # ff); ffT&%B) @5$ ff:) ff'B&&SC B&%VM2 ##fi) ff + ffJ%B ff'@'B )C :&%Vc&%X9'B ff)">ff#UP$)M[ ff ffB; ffBO%$Obfi$2M:Afffi#fi#)O) # ff)aC*E$fi!@P$ fffi#9p)$)$%MUE)P)&<<S ff$ 519Gely$ybe`_vK3Ee,ffE=a`_wvuCR5VJl>fi;)=>)$%MUE)E)O<< ff$19GTfe,TffTW=I`_uC>hffh;"<j1Xi'Zjie<Wi'i< g ]_aA$ Xa($jDn1fi#fuaW$<S ff$ )n&%E$)&fi# )R 2W<!$:7`b ) g+ ffg&%Pfi!`b gfi2) ) 76# ffB2&) CnD1fi)u4 tu$< $/&%fi!) ) 769Y&%)&'@<fi#) &$@2 # ffMK&%W$)&fi# )PK<!$3$`b ) T+ P&%B$#=$#)&VY$X:) B) ff'B&pY:6$4) $#$9M&2) )CDn1fi#)W4 @4)&% U&%=$)&fi# )E 2N4 ff'@<$#) K N'@2]_ ff>$9B Wfi!) )j62 # ffM 46fi# $!Y; ffo&%W>$#)&VY$ ffM) ) 'BO# ffpYffK6$) $#$9@) )CRDn1fi#)Ww4 @v)&% U[O%W<$#) # ffK 0&%P6fi# >K'B&% )R; ffR&%$#E$#)&VYff$ ff2"K) W)ff'B&# ffpYK6$4) $#$9K&) )C'(=fipr v+hsvc%q+mr qhr pm6n++v+v5SIb#) Z fiuH`_We l3lPlelZ3lPlq`_Dn$el3lPlCffwCjCffwCjwuCjwCj ffwCjC!uCjvCjCjCjC!u2CjuavCjCjCjCjuSCjSCjSCjSCjwSCjuSC!uSCjSCjuSCjuCjCjCjCjCjCjuCjCjCjCjCjCjC!uCj2CjwvCjCjCjffSCjSCjSCjSCjuuSCjSCjuSCjSCjSCjDn1fi#"uA*E ff'@<$#) B 06fi# $!@ o6fi# $!Xs)&#) #fi) #ff76xtfi!&#) Z fi&fiT #)uO`_Eel3lPlEZel3lPlq`_Dn$Eel3lPlC!uuCjCjv QCjuCjCjuCjQCjCjQCjCCjCjw CjCjCjCjw wCjCjw CjCjv CjvuCjQCjCjSC!uu,wC!uSC,CjSC,wCjSCjw ,CjuCj,CjSC,CjwSCj,CjuCjw CjSCjv ,wCjSCj,CjvvSCj,CSC!uu CjuuC7uCjvQCjvSCjw QCjwSCQCjSCjw C!uuCjw QCjCjw C!uSCjCjSCjQCjSCjwCjwSCjQCjvSCjQCjvSCjCjuvCjwwCwC7vuCjv vC7CjwC7CjC7CQC7CjC7CjQC7uCjQC7wwCjwC7vCQC7CjQC7C!uu wC71fiKu1*/fi2) ) 76# ff:9J"$#&'(pSCwCjv,wC7wCjv ,C7SuCj,wCuwvCj,C7wCj,C7wCj,CCj,C7Cjv ,wC7w2C!uu ,wCwwCj,wC7wvCjv ,wC7vwCjw ,C7ffffSCjvvCjvCwCjw CjwCjQCjwCjCCjw CjCjQCj2CjCjCjCCjCjCjCjvw2Cjw CjwSuCjv wCfi#) Z fiuH`_We l3lPlelZ3lPlq`_Dn$el3lPlCjvCjCjCffwCjC!uwCjuC!uCjuwn+o+pqrbsm,Xn+r pqCjCjCjC!uC!uSuCjvvCjvC!uCjuSCjSCjSCjSC!uSCjuSCjwSCjSCjSCjuCjwCjCjCjCjuCjC!uuCjuCjCjCjCjSuC!uCjuaCjwCjCjwCffffSCjwwSC!uSCjSCjSCffvvSCffSCjSCjvSC!u1fi#KuA*/P '@<$#) ffK 206fi# $!M @ P6fi# $!5s) &2 #) #fi0) #ff76x"$#&#) Z fi&fiT #)uO`_Eel3lPlEZel3lPlq`_Dn$Eel3lPlCjvCjwuCjCjuCjCjw uCjuCjv uCwCjw QCjwCjv CjCjCjCjCjwCjuCuCjuCjuCjuCjCjuCjCuwC7&uCjC7&uCjuC7&w uCjuC7&w uCjwvSCjuuC7wC7&wSCjC7&SCwC:u SCjC7&SCjuC7&uCC7&uCjuC:u uCjuuCjwuC7&CjC7&v uCjC7&uCjvuC7&CjwC7&wCjC:u CjwC7&CjC7&(CjC7&CjC7&CjuC7&uCuC7&w CjSCjwwwCjw,C7vCuC7Cjv uC7Cjv uC7wwuC7&w uuC!uCjC7Cjw uC7v2Cj,wCuwCj,C7vCj,C7CjuCvCjuC7vwCjwCjC7CjuC7wvCjuC7wCjuCuwCjv CCjv C7vCjC7wCjv wC7wwCjC7Cjv CuCjuC7CjuC71fiKuwA*RPfi!) )j62 # ffd9K"$ ffM) 'BO# ffK&'(SCjCj,C72Cj,C7Cj,C7v2Cj,C7vC,C72Cjv ,C7wC,C7SuCjw C7vCjC7wCjuC7C,C7Cj,C7fipr v+hsvc%q+mr qhr pm6n++v+v5SIb#) Z fiuH`_We l3lPlelZ3lPlq`_Dn$el3lPlCjCjuCjuCjwCj ffCjuCjCjCjCjCjCjC!uvC!uC!uCjCjSuCjuSCjSCjSCjSCjuSCjvSCjuSCjSCjSCjCjCjCjCjCjuCjCjCjCjCjCjCjCj2CjSuCjCjCjCjffSCjSCjSCjSCjSCjSCjSCjSCjSCjDn1fi#"uA*E ff'@<$#) @ g6fi$!@ @ o6fi# $!Xs)#) #fip) #ff76x"$ ffK) ff'B&a`K&#) Z fi&fiT #)uO`_Eel3lPlEZel3lPlq`_Dn$Eel3lPlCjvwCjuC!uv CuCjv Cjw uCvCjuC!uvCjCvCjuCjwvCjC!uvuCjuCjvCjuCjwv CjCv CjuCjwvCjuC!uCjvSCjuC!uv CuCv Cjv uC!uvSCjuC!uvuCjuCjvSCj,CjvSCjuCvSCjuCjv CjuCvSCjv uCjwv CuCjvv Cjv uCjuwSCjvSCjvuCjvSCjuCjwv CjuCjvSCjuCjwvSC!uu CjvSCjuCjvvSCjuCjvuCjC!uvuCuCjwv C!uu Cjv CjuCjv CjuCjuCjwC!uuCvuCjuC7vCjuC7vCjw uC7wvCjC7vCjw C7vCjw uC7vvuCjC7wCjC7vCjC7vCjC7vCC7uvSCjCj,C7CjuC7vCj,C7vCj,C7Cj,C7vCjuC7vCjuC7vSuCj,C7SuCjv uC7wvCj,CuvCjw ,C7vCj,Cu1fi#KuA*RPfi!) ) 76X29J") =)ff'B&# ffK'(ffSCjwCjCjCjw CjvCjC!uCjCjwCjCjvCjuCjvCjCjvCjCjwCjw CCQCjvCjCjwCjv C!ufi#) Z fiuH`_We l3lPlelZ3lPlq`_Dn$el3lPlCjCjCj ffCjCjwC!uCjCj ffwCj ffn+o+pqrbsm,Xn+r pqC!uuCjCjCjCjCjC!uwvCjuaC!uvuSCjSCjSCjSCffvwSCjuSCjuSCjSCjuSCjCjCjCjCjvCffCj ffwCjuCjCjCjCjCjCjuCj vCjuuCjCjCjffSCjSCjSCjSCjSCjuSCjSCjSCjSCjDn1fi#"uvA*E ff'@<$#) o6fi$!M G 6fi$!s)#) #fi0)j6xM) @)ff'B`# ffK&#) Z fi&fiT #)uO`_Eel3lPlEZel3lPlq`_Dn$Eel3lPlwCuCjwC!uu CjwvCjv CjvwwCjw uC!uw CjCjwCjQCjwCjC!uwwC!uu CjwCjuCjwwvC!uu uCjCjw CjvwCjuCjuCwSCuCjwSCjuCjSC,CjwSC!uu uCwSCj,CwSCjCwSCj,CjwwSCj,CjwwSCjw uCjwSCjv uCjuCjuC!uwSCjuCjuSC!uwSCjuCjwwSCjuCjwSCjCjwSCjuC!uwSCjCjvwSCjCjwwSCjv CjwwwSCjuCjwuCuCjwvSCjuC!uSCjuC!uwSCjuCjwwCjvwCjC7wCjuC7CjuC7wCuC7wCjC7wCjw C7w CC7wC!uu C7wC!uu uC7wvCjuC7uCC7vwC!uu uC7wDn1fi#t N* fi2) ) 76# ff:9KB6$4&=uuCjwvCjuC7wCj,C7vCjv ,C7wCjuC7wwCjuC7wwCjC7wCj,C7wwCj,CwCjuC7wvCjw uC7CjuC7wCjuC7ffuSCjvvCjvCjwvC!uu uCjCjv uCjwCjv uCjwCjuCjvw2C!uu CjwCjv CjwC!uu CjvwCjv CwvCjuCjSuCCjwwCjw uCjfipr v+hsvc%q+mr qhr pm6n++v+v5SIb#) Z fiuH`_We l3lPlelZ3lPlq`_Dn$el3lPlCjCjCjCj ffCjuCjCjCjCjCjCjCjCjuCjvCjCjCjCjuSCjSCjSCjSCjwSC!uSCjSCjSCjSCjCjCjCjCjCffCjCjCjCjCjCjCjCjvwCjuaC!uwCjCjCjffSCjSCjSCjSCffvSC!uSC!uwSCjSCjSCjDn1fi#tu+*RP '@<$#) ffK 26fi# $!K @ P6fi# $!?s)&#) #fip) #ff76xTJ6$&E )Z fiX%SCjSCjvSCjSCjSCjwSCjuffB6fi#<ZSCjCjuCjCjwuCjwCjSCC!uuSCjC!uSCjwCjw5]$ ff$#$9B6fi#3%<ZCj2CjwCjSuCjCjCjCjvCjC!uuaCjvCjCjCjvCjCjvvCj2CjCjP ff))&)P6fi#3%<ZC!uCjC!uauC!uuCjwCCjCjC!uuCjuCjCjCjCjvCjwwCjCjCj1fiBA*RP ff'J<$#) ffK n6fi# $!K B !B">&E )Z fiuff3%CjuCjvCjCjCjwwCjE 6fiq`_D$CjCjCjwCjwwCjvCj<SCjuSCjSCjSCjSCjSCjX%SC!uSCjSCjuCjSCjvSCj5]$ ff$#$9B6fi#q`_Dn$SuCjCjSuCjCjCjC<CjuCjwCjCjSuCjuCjuff) )&)P6fi#3%q`_D>CjC7CjuCuCjuC7wuCjvC7vCjC7CjC7Dn1fi#tA*RP ff'@<>) ffK n6fi$!" J !B"$ ff2M) ff'B&# ffK2&=<CjuCjuCjCjCjCjfiE #)Z fi3%vwCjvwCjvCjvC!uvCjvwCjuffB6fi#uO`_vwSCjvSCjvSCjvwSC!uSCjwSCjn+o+pqrbsm,Xn+r pq<SCjSCjSCjSCjSCjSCj5]$ ff$#$9B6fi#3%uO`_vCv2CjwvCjv2CjvvCjv2Cjv CjvvCjv CjvCjvC!uvCj<C!uwC!uuCjCjuCjCjP ff))&)P6fi#3%uO`_<vwCjvCjCjvwCjvCjC!uvwCjvCjCjvCjvCjwCjv CjvCjCjvuCjCjCjDn1fi#t C*N ff'@<$#) K 6fi# >K @ !B") 4) ff'B&@E )Z fiuff3%wwCjw CjvwCjwwCjwCjvw CjvE 6fiq`_D$wCjwCjwwuCwC!uwCjwCjv<SCjSCjSCjSCjSCjSCj5]$ ff$#$9B6fi#X%q`_Dn$uCjCjwuCjSuCjuCCjuCjSuCuC!uCjuCjSuC<CCjCjwC!uavCjvCjw2ffff) )&)P6fi#3%q`_D>wvC!uwC7wvCjvwC7wvCjwC7wvCjvwCuwvCjvwC7CjwC7w<CjCjuCjCjuCjCju1fiBA*RP ff'J<$#) ffK n6fi# $!K @ t6>=&#)Z fiuffyb)&)q)$?A@GB ?uffCACjB ?AwDECBuCuC7uvC7CuwC7uauCjSuCjv2uCjC!uCjCjvuuCjuwSCjyb)&)P < ?s5xCjwwCjuavCjSuCjvCjyb)&):yb $)wC!uwSCjwSuC!uffvSCjvSuC!uSCjuCuuwSCjwuCjuffSC!uH?A@GBH?CABk?FuDCjBC!uCjwCjwCjDn1fi#twA*EDT%") # -: E&%M! >) # ff8 W#)$[['B#) fi!1Sfi) )r`=$#@&s.ela Z x=fi#)Z fiuffpr v+hsvc%q+mr qhr pm6n++v+v5SIbyb)&)q)$?A@GB ?ffSCAuCjB ?AwDEuCjBvCjwwCjvCjvuaCjuaCjvCjCjwSuCjvwCjCCjvSuCjCjvyz) &)P ff <?s5xv2CjuvCjuaCjwwCjv2Cjyb))E!dyz >) # ffvSCjCjwu CjuC7vSCjC7uSCjffC7SCjC7vH?A@)Bk?lCABH?ASDEuCjB wuwCjCjvwCjwffCjDn1fi#tA*EDT%=) #-= 2N&%4! >) # ffM 2N#)>hd'B#) fi!1fi#8&) )/`E$ ffM)ff'B`# ffK&Ms;elaQq`_Dn$x#)Z fiuffyb)&)q)$?A@GB ?uaCACjB ?ADECjBu C7wC7wffCuC7wwC7Cjw CjvCjw CjwuSC!uuvSCjCjvSCjyb)&)P < ?s5xCjua CjvCjCjCjyb)&):yb $)CjCjuCjuCjuuSC!uvvCjuv CjwuSCjwu C7CjwSCjvC7vC!uwSCjw C7H?A@GBH?CABk?FDBDn1fi#tA*EDT%W) #- n&%! >) # ffK 0#)$3M'B#) fi!1fi#3&) )R`/) )ff'B`# ffK&Ms;elauH`_WxE )Z fiuffyb)&)q)$? @GBuwvCjuCjuCjuCjuC!u? CFBuauCjuaCjuauC!uuauCjuauCj? DBvC7uCuC7C7vC7yb))P ff < ?s5xCjuCjffCjffC!uwuCjvyz) &)E!:yb $) # ffuC!uffC7CjvvCjv C7vCjwuavCuvCju CjwwCjCjCjCjvCju CjwH?@GBI? CABH? DEBDn1fi#tvA*EDT%=) #-B /&%4 $) # ff: /#)$53'B#) fi!1fi#8&) )P`P6$=ds;elaQq`_Dn$x=fin+o+pqrbsm,Xn+r pqSm3 &^n%Ynq@C!YR1fi#Yoq@C!YRWfi!1>Y/mCPs$uvvuaxCMyb) &O`_1) mfi#!?fi# $#&%'B)C 3^fiOOY ns$uxYawwCqpnfi!pYnq@C!Y Z!$0YRnCRs$uvxC Z!Mb$ ff' #) 93A'@<fi#)C 3^fiffa^Cjn"r&OY RsffxYtsuGrYnuaP!pYmC!Y(hfi# ffpYepCRs$uvvSuxCRE `_'B ff ff#=fi#!C 3^fi O;#j&aYuC^swvxvyvo!V )) ffpY%CYNeUE!pYCEs$uavvxCKP ff) )O)tO% ff$ #Kfi2) ) 76# ff\'B&% )C_; aH;~4 X /18 /+4O;Y NsxYwwa^ C|{z}~n d} |rrSnP$ fi9YrC 3 Cffs>uvvxCIP>) #Eff'@2 #/12)) fi# # ffr; ffpfi!) )j6n ) & # ffpC 3^fiOOY Ywa^v CraP$ fi9YoC 3 C!Y0lp$#fi;YRmC0BC*s$uvvwxC@y.j;98?fi#!'B!!?')fi1fi#[&!)&)CEyz P$O&T8 fifffiffO;&a fi f; $& O; P &;5ff&aYff<<pCpvva<n $ fi!0YCWfyo$) )CczP$ fi9YC 3 C!Yol>fi;YPmCRBCWs$uvvw1xCmyb'J<$ ff!mff'@2 ?fi!\ @'@<<!m197;9ff!ttfi#!'B!!@'B#) fi!1SfiM 1) $I2 # ff)n.> ff'O!!&Cyb P_a&OT8" fiff &;O; E&2HaaO@18 P(B; ^2HBY fi;Cy$y YR<<pC/uaau Z ! fi!pY0WCP$ fi9Y0rC 3 C!Y{T i/YAnCffa^SC3|{F{nCs$uvvxCn5fi$!B#) # ff3O$)C X6fiffuOOYlnE>YrCffs$uvvxC(T) !W#) # ff&$)0 T'J<$ /)O`_1) =fi#Cffyb X6fiff O&*$O&T 8 fiff fi &;O; $&aYff<<pCa^4'@%$) YSXBC3 ff$ff.'JpCzq=9fffi!VYBC!Yp{o$ ) YlECRs$uvvxC/e'@2fifiR#);] )!3# ff* Z!M @!ff )t$ ff$):&%4 fi#<% ff"$UP ff VJfi# fffiRfi# ff<pCyb X^fiff OO P$O&T8 @ fiff fi&;a&; / Ha$OY<<pCpuO'@%$) aY3tC3 ff>ffK.'JpCn~zq&Y*epCs$uvvwxC Z!8!%91$# #) :!$ ff'B )M) !m) &#)2fi*L$#)CyzlR)O%Yq@C!Y Z -Y C0s 3 )CjxY O& H$+ ; O; P &;#jO18 ;;T5; nY<<pC0uauSCffe<$! $fi!YTUQR ff VCPF{q&YepC*s>uvvxCffR@fi#3UE#&%c ff)>`_<$ # # ff3fi!)) 76# ffm #)?<<fi##a`# ff)E @#) # ff:&>=! # ffpCEyb X6fiff &O P$O&T8 fiff ffO;&a fi&;a&; / Ha$OY<<pCpavuW)&%ff#fi#fi#Y0DE4C3 ff$ffKb'@pCn~blqOb$#)YCepCYD0 UW)O%0YA%CC@Cs$uavv ffxCnEq `b>dfi!ofi!) )j62 # ff)=Efi# ff1fip)fi#C &;a&; ffO0 P( B; affY s>uxYwa^wCE{uaq# $#%pYDrC^JCs$uvvxCgf<<$ A!'@)# ) #fi0) )P; ffo ff'@<>K)&<S$ff#) 3fi!) )j6I`# ffKfi#!G2fi ff$#&%'B)C faff$ o+ ff;;Y Ns;xYpuvapuv Cu)=fipr v+hsvc%q+mr qhr pm6n++v+v5SIbq# $#%pYWDCP@CY/*V!$;YWJCWs$uvvxCe fi#!['tfi# #fi!) ):fi#![<$ ff1fi#'B)M!8 $ ffz`ff $ !@ &<E )C ffO r&; *a &;#jO *HO$^fiY YwawC>EsjqrFq UPYq@C Z C!Y ) fi;Y=Cs$uavvxC [#) # ffJ&$E'B fi 1)&%6$W2 #ff#$9Cyb P_a&OT8E fiff fi H;$# / $aO* &; *a &;#jOYa<<pCffI^vC ff$fi#e 76Cj{xq UPYq@C Z C!Yp ) fi;Y4C/s$uvv1xCE#) # ff5O$t'B fiR *1)&%6>"#$9C=Dg%pC0$<pCD0%#fiW$<S ff$"vuvYg3 ff)&%#$) #$9Y/3fi!1 YPf)&fi#!C?DT%)J H%#fi$< ff>M ff $ )K&%?$ #fi#?<<$![!&%?e#A&%) &2fi!% !d ff+>5 fff$j6!finyb fi#fi#CEsa#&;SHYq UPYq@C Z C!Y ) fi;Y=Cs$uavv ffxCq#) # ffB&$E'B fi#)/ 1)O%6$W##_9Cs;xYuO^SCq=<SYCs$uavvxC"n$) ff2fi '@'B2 # ffpC!Cq=<SYffC!YP fi#fi#!)YrC!YffP$ fi## Y%C!Y) ffpYtCYffQP#) '@pY 3 Cs$uavvxCDE%fe%'@4e9ff) 'MC&;a&; ffO0 /+ ; YvI^CEq=YCBCY$YnCe ff)YTtC| rC0s$uvxC~*;;a&V/# P&;MC8A{p&aff4#a!C,% %3#fi#9la99ff0Y14CCYyb;YnBCCRs$uvvxCE:&%t%fi#!d 2/ ff ff)$`bfi!2 &$!1 )!) dO$pC X6fiff OOffY s>uxYIuCn='t1S$Yq@C!Y ZY4C!YqK- $ )&V;YepCNs>uvvwxCEE #) Bfi#!'B!# ff3!:! #@ ff<fi!1*,2) B) &93!5'B#fiR!ff ))aC@yb p(7a fi &;O; afiffffO fit &Ofiff&& Y<<pC0uavva^uaCffe<$!CV{z>=9 ffpY*yC!YP5#YE4C!YE<!VY CWs$uvvwxCmq#) >8!+ '@#3<)G\&fiCyzmla99ff0YG4CRmC!YR!)&V9`_e%<!$ YEJC!Y/e'49&%pY`nC!YP T&%)&'=9YoC3 )C7xY 8+7&* =P#T 8ff !O+7a&418 ; XY<<pCuSuO^SCWy2hyzD/$) )aCjn^svyvyv z) pY Z CBCYefi!'B ffpY"CPs$uvvxC"TfiP$U* VM) 'B1fi#)C*;;a& #W18 3^fi &;7ffaOY Ns>uxYvvIuuCn% ff%pYRJCuGr$a;StVnCPs$uvvxCt ff1) B#) # ff5O$)(*BP'B ff!: ff fi##$)4.$ '&CKyb P_a&OT8= fiff / &;O; / Ha_aO =P#T8ff !&7O@C8 ; 3 ffY<<pCu uav3 ff&$fi;Y1Cpfy /$) )aC~s|) fi;Y=C!YPq UPYoq@C Z Cs$uvvxCo$# !1)&%6>h2 #ff#$9m![O%d5fi#fi#h># ffm&%= ff$&%UP) # $!") !MB#) # ff:&$='B fi;C*yz P_a&OT8W fiff &SH;;ff;B;$# EO ff$ Cfiff / Ha_aO/3fi!1 Y) &fi#SCcX^Z UE#)Yq@C!Y\Efi# Y~%Cs$uvv2ffxC $ )N$O!$9)&'J<fi!r+ ff)&<$#) @fi#!Cyb X6 fiff O& *$a&O8* = fiff P~7a fi &;a&; / Ha_aOY <<pCpuffauwBEUQ*) UE#HVYpk%CSX $ffKb'@pCnv=('fin+o+pqrbsm,Xn+r pqZ )aYffepCffBCY+%ff) YCBC!YffQDnHV YffC%Cs$uavv ffxCfi 1fi0uEff>f19MuEff$Eq yn&) R; ffRfi#!'@) &#)P$#K.> ff'&%!'@')/ ff !Ofi0Eq yn&C &;O;^O0 *( B; SHY ns$uxY ffvauvCl{qua5&%UT)Y 3 CRs$uvxCPfi# ff1fig&:fih)+*WTU %#ff%3$)fi2&@1) ); fffi!'@2 =) O)aC ^ffOn /# B;B18#T8 3;O$# IY Yff ffCrar3#H%#Yq@Cs$uvvxCo$ ff1fi#'B)o ff'J< z`_#K ff<R; ff '@2 # ffpC!Cyb@!fi!pYA%CffCs 3 0CjxYpO;^O a;( 4HY fi;CSCff#) ff` )fi9Y ffV!ff%'MY1BCvy x{Tfi#) ) ffpY4CA%Cns$uvwxC O&B^fiffHCX4aUP`fi#fi;YTUR VC)aY^DrC!Y %) pYq@C0s$uvvxC0DE%Oi0 )P n&!!@) E)- K) M&$ ff'@<fi#A#_9Cyb 3^fi OO P_a&OT8" fiff 0&;O fi &;O; / $&aY/<<pC^w=)&%ff#fi#fi#YDT=C3 ff>ffK.'JpCn^ffVSY*4C!YRR )&%#YEBCEs$uvvxC Z!$fi@m! $fffi!A^'J<fi)K) <fi#9C?yz*$O&T 8 fiff&;O; / Ha$OM faff$ ;RY<<pC0uuOpu Cy 3G3 3 o$) )CuaGVswvyvxvsxVSY=C!Ya[R )&%#YBC^s>uvvwxC[ #) O`b fi#N%9^1>@'B fiPfi# ff1fiBEfi#fifffi#'B fffi;Cyz *$a&O 8R * fiff5 MTfiff &;aff$; 3ff; # O&8 X(8H p_7M18 O# 3^ fi OOff& fi4HY<<pCpvauaCfy/>) )Cjs ffF{x>js apFXsffnnfi#) ffpYA%C!Y)aY+%C!YWfi#fi##) ffpY Z C0s$uvxC0E1 ffJ!Kfi#&# ffJ N'J]$ ffRUP ff$fi#K ) 9)$`'B)CPD0%pCp$<pCDg%2fiNP<S ff$ `_ ffa` 3 `_wSYeMq<$&'BE 3 $9YVP#t# fffi Z1ff>9Cxn!fi!pY%CCns$uvwxCyz # ff: N#) # ff:&>)C X6fiffquOOY ns$uxYuOpuwCEaP$ ff$+4B6fiff3#&OCm3 ff$ff.'JpYEe!fi!pY%C*rCWs$uvvxCh2 YfftCjz!fi!pY+%CaC^s>uvvwxCP!Y 1 ) !WtPC7CIyz P_a&OT8 * fiff fiffO;O fi ;/ $aO &; *a O;#j&aY<<pCa^n ff$ fi!0YCWy/$) )aCe%<!$YrC3jnCs>uvvxCDE%) O$&%K RUPVBfi#1fi##$9C X6fiffq&OY Yguva^CeV2fiVYpq@Cs>uvv ffxC`o$ $9<=+2&$=)fi X19M)&'J<fi!d5ff''B&# ff:%#fififi!'B1!G2fi ff$#&%'B)CRyz X6fiff O& P$O&T8E = fi P#(7a fi &;O;/ $aOY<<pCpva^uWTUP ) UE#VYpw%C3 ff$ff"b'@pC|nxtveV2fiVYPq@C!YoP#) ) fi!0Y 3 CWs>uvvxCyz #3fi#!?!5'B#A<#ff') !C[yz*$O&T 8W = fiff Pjfiff fi ; $& r&; *a &;a#7ff&aY<<pC2ffa^/ ) ffpY3tC3 ff$b'@pCvefi# ffpY=rCs>uvxCD/9<): " #) 8&+ K ff<3fi!Cyb *$a&O8d ? fi/H MT fiff 3 o+ ff;; && fiffOOIY<<pCvSuO^vwET'B1$#Y 3tC W/$) )aCXz=(=fipr v+hsvc%q+mr qhr pm6n++v+v5SIbVefi# ffpY/rC*s$uvvxCKl $9^<S)B W #) M!5K; ff<ffi#!C & TB; *$OOHa;;HY Ps;xY0uaauwC~e'49ffO%pYnCs$uavvwxCpo ff)P ffB&%'Bfi2) ) 76# ffK > ff/2 E 'Bfi# !<fiA<> )C *;;O*O&ff; ;;Y Y0uauCude$!#I)OpYptCY5fi# ffpYpepC!Y*2pYpmCs>uvvxCRq#) !ff#)&%!dA< # ff)b$ ff' #) 4!ff`_'B ff ff#tfi#C"yb P_a&OT8= K fiff p&OC8 &18; 7 P$ ff$+Bfi Y<<pCpvaua=Dg ffV9%ff<pCybEDs;DgH%#fiR$< $EDP:`&uuxCXA{xswvyvxv zDg ff'BVY^yC0s$uvwxCJA^<S$!'BUE#&%J#$) >`_%ff1S ffE fi#CaH;~ 4 X3C8 ot 4Oa;HY s.wxYffaffCp#)&1S$YpepCs$uvxCa#8K#&W$zff$OHC,% ff%{}~n$;Sfi#9de ff)aCswvxvyv#fi) ffpYq@Cs$uavxCW)9^'@< #W<$ ff<S$ #)/ 2$)/%ff1S ff/ fi#)P) !=# @C_ p a;( 4 XX18 /+4 a&;Y YaffffSuC#fi) ffpY q@CCffs>uvvxC 8+7&/B;O^5d4 2HT8E#&&W ff& fi4HC/%pCq@CO&%))aY*>%'R ffff$) #$9YKo$ YDC#fi) ffpY q@CIrC!Ym5> !-YDCCs$uvvxCyb)&*<H%#L)Cyb X6fiff O&*$O&T 8= " fiff 0&;O fi &;O; $&aY<<pCgff uuBW)O%#fifi#YRDE4CX $ffKb'@pC#fi) ffpYq@CC!Y5$-YDCCps$uvvvxCP # ffJ H%#L)o+ ffnA'@<fi!z`_12) "fi#fi# ff$#&%'B)aC 3^ fi OOffY $&C#fi) ffpYCalEC!Y $) `_efifi#$)aYtCs>uvxCfffi# ff12fi$%E fi!J IR@) #fi#)P&+ ffP) 4!M2fi!$fi!X' fffi#)C ^ffOg /# B;# IY YguuvauffC!) ffpY1nC Cs$uavxC Z!M)&fip) >< ).$ ',A'@<fi#)CPyb3 0CjxY fiff /I6fiff# B / pff;a n!C34aUP` #fi#fi;YTUR ffVCz|{}~n|rynFzFnffff") ffpY1nC C"fi!<S$Yq@C Cs$uavvxCne&V2fi#-pC $ ;RY uH^vC%YBC!Y0T#)&%#YDCRs$uvvxCE) !MLfi##&#@%9^<S &%) )4 "# 7+93!2 B&C^O0 &; *a &;a#7ffaO P&$6fiffY Y0uuvIuffC>ff=(pfiJournal Artificial Intelligence Research 11 (1999) 241-276Submitted 1/99; published 9/99Evolutionary Algorithms Reinforcement LearningDavid E. Moriartymoriarty@isi.eduUniversity Southern California, Information Sciences Institute4676 Admiralty Way, Marina del Rey, CA 90292Alan C. SchultzNavy Center Applied Research Artificial IntelligenceNaval Research Laboratory, Washington DC 20375-5337schultz@aic.nrl.navy.milJohn J. GrefenstetteInstitute Biosciences, Bioinformatics BiotechnologyGeorge Mason University, Manassas, VA 20110gref@ib3.gmu.eduAbstracttwo distinct approaches solving reinforcement learning problems, namely,searching value function space searching policy space. Temporal difference methods evolutionary algorithms well-known examples approaches. Kaelbling,Littman Moore recently provided informative survey temporal difference methods. article focuses application evolutionary algorithms reinforcementlearning problem, emphasizing alternative policy representations, credit assignment methods, problem-specific genetic operators. Strengths weaknesses evolutionaryapproach reinforcement learning presented, along survey representativeapplications.1. IntroductionKaelbling, Littman, Moore (1996) recently Sutton Barto (1998) provide informative surveys field reinforcement learning (RL). characterize twoclasses methods reinforcement learning: methods search space value functions methods search space policies. former class exemplifiedtemporal difference (TD) method latter evolutionary algorithm (EA)approach. Kaelbling et al. focus entirely first set methods provideexcellent account state art TD learning. article intended roundpicture addressing evolutionary methods solving reinforcement learningproblem.Kaelbling et al. clearly illustrate, reinforcement learning presents challenging arraydiculties process scaling realistic tasks, including problems associatedlarge state spaces, partially observable states, rarely occurring states, nonstationary environments. point, approach best remains open question,sensible pursue parallel lines research alternative methods. beyondscope article address whether better general search value functionspace policy space, hope highlight strengths evolutionaryapproach reinforcement learning problem. reader advised viewc 1999AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiMoriarty, Schultz, & Grefenstettearticle EA vs. TD discussion. cases, two methods provide complementarystrengths, hybrid approaches advisable; fact, survey implemented systemsillustrates many EA-based reinforcement learning systems include elements TDlearning well.next section spells reinforcement learning problem. order providespecific anchor later discussion, Section 3 presents particular TD method. Section 4 outlines approach call Evolutionary Algorithms Reinforcement Learning(EARL), provides simple example particular EARL system. following threesections focus features distinguish EAs RL EAs general function optimization, including alternative policy representations, credit assignment methods,RL-specific genetic operators. Sections 8 9 highlight strengths weaknessesEA approach. Section 10 brie surveys successful applications EA systemschallenging RL tasks. final section summarizes presentation pointsdirections research.2. Reinforcement Learningreinforcement learning methods share goal: solve sequential decision taskstrial error interactions environment (Barto, Sutton, & Watkins, 1990;Grefenstette, Ramsey, & Schultz, 1990). sequential decision task, agent interactsdynamic system selecting actions affect state transitions optimizereward function. formally, given time step t, agent perceives statest selects action at. system responds giving agent (possibly zero)numerical reward r(st) changing state st+1 = (st ; at). state transition maydetermined solely current state agent's action may also involve stochasticprocesses.agent's goal learn policy, : ! A, maps states actions.optimal policy, , defined many ways, typically defined policyproduces greatest cumulative reward states s:= argmaxV (s); (8s)(1)V (s) cumulative reward received state using policy . alsomany ways compute V (s). One approach uses discount rate discount rewardstime. sum computed infinite horizon:V(1X) = iri=0t+i(2)rt reward received time step t. Alternatively, V (s) could computedsumming rewards finite horizon h:V (st) =Xh ri=0t+i(3)agent's state descriptions usually identified values returnedsensors, provide description agent's current state state242fiEvolutionary Algorithms Reinforcement Learningworld. Often sensors give agent complete state information thusstate partially observable.Besides reinforcement learning, intelligent agents designed paradigms,notably planning supervised learning. brie note major differencesamong approaches. general, planning methods require explicit modelstate transition function (s; a). Given model, planning algorithm searchpossible action choices find action sequence guide agentinitial state goal state. Since planning algorithms operate using modelenvironment, backtrack \undo" state transitions enter undesirable states.contrast, RL intended apply situations suciently tractable actionmodel exist. Consequently, agent RL paradigm must actively exploreenvironment order observe effects actions. Unlike planning, RL agentscannot normally undo state transitions. course, cases may possiblebuild action model experience (Sutton, 1990), enabling planningexperience accumulates. However, RL research focuses behavior agentinsucient knowledge perform planning.Agents also trained supervised learning. supervised learning, agentpresented examples state-action pairs, along indication actioneither correct incorrect. goal supervised learning induce general policytraining examples. Thus, supervised learning requires oracle supplycorrectly labeled examples. contrast, RL require prior knowledge correctincorrect decisions. RL applied situations rewards sparse;example, rewards may associated certain states. cases, mayimpossible associate label \correct" \incorrect" particular decisions withoutreference agent's subsequent decisions, making supervised learning infeasible.summary, RL provides exible approach design intelligent agents situations planning supervised learning impractical. RL appliedproblems significant domain knowledge either unavailable costly obtain.example, common RL task robot control. Designers autonomous robots oftenlack sucient knowledge intended operational environment use either planningsupervised learning regime design control policy robot. case,goal RL would enable robot generate effective decision policies exploresenvironment.Figure 1 shows simple sequential decision task used example laterpaper. task agent grid world move state stateselecting among two actions: right (R) (D). sensor agent returnsidentity current state. agent always starts state a1 receives rewardindicated upon visiting state. task continues agent moves gridworld (e.g., taking action state a5). goal learn policy returnshighest cumulative rewards. example, policy results sequencesactions R; D; R; D; D; R; R; starting state a1 gives optimal score 17.243fiMoriarty, Schultz, & Grefenstettebce1021-1121120233-543141-2412511211Figure 1: simple grid-world sequential decision task. agent starts state a1receives row column current box sensory input. agent movesone box another selecting two moves (right down),agent's score increased payoff indicated box. goal findpolicy maximizes cumulative score.2.1 Policy Space vs. Value-Function SpaceGiven reinforcement learning problem described previous section,address main topic: find optimal policy, . consider two main approaches,one involves search policy space involves search value function space.Policy-space search methods maintain explicit representations policies modifyvariety search operators. Many search methods considered,including dynamic programming, value iteration, simulated annealing, evolutionaryalgorithms. paper focuses evolutionary algorithms specializedreinforcement learning task.contrast, value function methods maintain explicit representationpolicy. Instead, attempt learn value function V , returns expectedcumulative reward optimal policy state. focus research valuefunction approaches RL design algorithms learn value functionsexperience. common approach learning value functions temporal difference (TD) method, described next section.3. Temporal Difference Algorithms Reinforcement Learningstated Introduction, comprehensive comparison value function searchdirect policy-space search beyond scope paper. Nevertheless, usefulpoint key conceptual differences typical value function methods typicalevolutionary algorithms searching policy space. common approach learningvalue function V RL problems temporal difference (TD) method (Sutton, 1988).244fiEvolutionary Algorithms Reinforcement LearningTD learning algorithm uses observations prediction differences consecutivestates update value predictions. example, two consecutive states j returnpayoff prediction values 5 2, respectively, difference suggests payoffstate may overestimated reduced agree predictionsstate j . Updates value function V achieved using following update rule:V (st) = V (st) + ff(V (st+1) , V (st) + rt)(4)ff represents learning rate rt immediate reward. Thus, differencepredictions (V (st+1 ),V (st )) consecutive states used measure prediction error.Consider chain value predictions V (s0 )::V (sn ) consecutive state transitionslast prediction V (sn ) containing non-zero reward environment.many iterations sequence, update rule adjust values stateagree successors eventually reward received V (sn ).words, single reward propagated backwards chain value predictions.net result accurate value function used predict expected rewardstate system.mentioned earlier,goalTD methods learn value functionoptimal policy, V . Given V , optimal action, (s), computed usingfollowing equation:( (s; a))(s) = argmaxV(5)course, already stated RL state transition function (s; a) unknownagent. Without knowledge, way evaluating (5). alternativevalue function used compute (s) called Q-function, Q(s; a) (Watkins,1989; Watkins & Dayan, 1992). Q-function value function representsexpected value taking action state acting optimally thereafter:Q(s; a) = r(s) + V ((s; a))(6)r(s) represents immediate reward received state s. Given Q-function,actions optimal policy directly computed using following equation:(s) = argmaxQ(s; a)(7)Q(st; at) = Q(st; at) + ff(maxQ(st+1; at+1) , Q(st; at) + r(st))+1(8)Table 1 shows Q-function grid world problem Figure 1. table-basedrepresentation Q-function associates cumulative future payoffs state-actionpair system. (The letter-number pairs top represent state given rowcolumn Figure 1, R represent actions right down, respectively.)TD method adjusts Q-values decision. selecting next action,agent considers effect action examining expected value statetransition caused action.Q-function learned following TD update equation:245fiMoriarty, Schultz, & Grefenstettea1 a2 a3 a4 a5 b1 b2 b3 b4 b5 c1 c2 c3 c4 c5 d1 d2 d3 d4 d5 e1 e2 e3 e4 e5R 17 16 10 7 6 17 15 7 6 5 7 9 11 8 4 6 6 7 4 2 1 2 1 2 116 11 10 7 1 17 8 1 3 1 15 14 12 8 2 6 7 7 3 1 7 6 4 3 1Table 1: Q-function simple grid world. value associated state-actionpair.Essentially, equation updates Q(st ; at) based current reward predictedreward future actions selected optimally. Watkins Dayan (1992) provedupdates performed fashion every Q-value explicitly represented,estimates asymptotically converge correct values. reinforcement learningsystem thus use Q values select optimal action state. Qlearning widely known implementation temporal difference learning,use qualitative comparisons evolutionary approaches later sections.4. Evolutionary Algorithms Reinforcement Learning (EARL)policy-space approach RL searches policies optimize appropriate objectivefunction. many search algorithms might used, survey focuses evolutionaryalgorithms. begin brief overview simple EA RL, followed detaileddiscussion features characterize general class EAs RL.4.1 Design Considerations Evolutionary AlgorithmsEvolutionary algorithms (EAs) global search techniques derived Darwin's theoryevolution natural selection. EA iteratively updates population potentialsolutions, often encoded structures called chromosomes. iteration,called generation, EA evaluates solutions generates offspring based fitnesssolution task environment. Substructures, genes, solutionsmodified genetic operators mutation recombination. ideastructures associated good solutions mutated combined formeven better solutions subsequent generations. canonical evolutionary algorithmshown Figure 2. wide variety EAs developed, including geneticalgorithms (Holland, 1975; Goldberg, 1989), evolutionary programming (Fogel, Owens, &Walsh, 1966), genetic programming (Koza, 1992), evolutionary strategies (Rechenberg,1964).EAs general purpose search methods applied variety domainsincluding numerical function optimization, combinatorial optimization, adaptive control,adaptive testing, machine learning. One reason widespread success EAsrelatively requirements application, namely,1. appropriate mapping search space space chromosomes,2. appropriate fitness function.246fiEvolutionary Algorithms Reinforcement Learningprocedure EAbegin= 0;initialize P(t);evaluate structures P(t);termination condition satisfiedbegin= + 1;select P(t) P(t-1);alter structures P(t);evaluate structures P(t);endend.Figure 2: Pseudo-code Evolutionary Algorithm.example, case parameter optimization, common represent listparameters either vector real numbers bit string encodes parameters.either representations, \standard" genetic operators mutationcut-and-splice crossover applied straightforward manner produce geneticvariations required (see Figure 3). user must still decide (rather large) numbercontrol parameters EA, including population size, mutation rates, recombinationrates, parent selection rules, extensive literature studies suggestEAs relatively robust wide range control parameter settings (Grefenstette,1986; Schaffer, Caruana, Eshelman, & Das, 1989). Thus, many problems, EAsapplied relatively straightforward manner.However, many applications, EAs need specialized problem domain (Grefenstette, 1987). critical design choice facing user representation, is, mapping search space knowledge structures (or,phenotype space) space chromosomes (the genotype space). Many studiesshown effectiveness EAs sensitive choice representations.sucient, example, choose arbitrary mapping search space spacechromosomes, apply standard genetic operators hope best. makesgood mapping subject continuing research, general consensus candidate solutions share important phenotypic similarities must also exhibit similar forms\building blocks" represented chromosomes (Holland, 1975). followsuser EA must carefully consider natural way represent elementssearch space chromosomes. Moreover, often necessary design appropriatemutation recombination operators specific chosen representation.end result design process representation genetic operators selectedEA comprise form search bias similar biases machine learning meth247fiMoriarty, Schultz, & GrefenstetteParent 1:BCEFGParent 2:bcefgOffspring 1:BCefgOffspring 2:bcEFGFigure 3: Genetic operators fixed-position representation. two offspring generated crossing selected parents. operation shown called one-pointcrossover. first offspring inherits initial segment one parentfinal segment parent. second offspring inherits patterngenes opposite parents. crossover point position 3, chosenrandom. second offspring also incurred mutation shaded gene.ods. Given proper bias, EA quickly identify useful \building blocks" withinpopulation, converge promising areas search space.1case RL, user needs make two major design decisions. First,space policies represented chromosomes EA? Second, fitnesspopulation elements assessed? answers questions depend userchooses bias EA. next section presents simple EARL adoptsstraightforward set design decisions. example meant provide baselinecomparison elaborate designs.4.2 Simple EARLremainder paper shows, many ways use EAs search spaceRL policies. section provides concrete example simple EARL, callEarl1 . pseudo-code shown Figure 4. system provides EA counterpartsimple table-based TD system described Section 3.straightforward way represent policy EA use single chromosome per policy single gene associated observed state. Earl1 ,gene's value (or allele biological terminology) represents action value associatedcorresponding state, shown Figure 5. Table 2 shows part Earl1 populationpolicies sample grid world problem. number policies populationusually order 100 1000.fitness policy population must ect expected accumulated fitnessagent uses given policy. fixed constraints fitnessindividual policy evaluated. world deterministic, like sample grid-world,1. ways exploit problem specific knowledge EAs include use heuristics initializepopulation hybridization problem specific search algorithms. See (Grefenstette, 1987)discussions methods.248fiEvolutionary Algorithms Reinforcement Learningprocedure EARL-1begin= 0;initialize population policies, P(t);evaluate policies P(t);termination condition satisfiedbegin= + 1;select high-payoff policies, P(t), policies P(t-1);update policies P(t);evaluate policies P(t);endend.Figure 4: Pseudo-code Evolutionary Algorithm Reinforcement Learning system.Policy i:s1a1s1a1s3a3...sNFigure 5: Table-based policy representation. observed state gene indicatespreferred action state. representation, standard geneticoperators mutation crossover applied.fitness policy evaluated single trial starts agentinitial state terminates agent reaches terminal state (e.g., falls gridgrid-world). non-deterministic worlds, fitness policy usually averagedsample trials. options include measuring total payoff achievedagent fixed number steps, measuring number steps required achievefixed level payoff.fitness policies population determined, new populationgenerated according steps usual EA (Figure 2). First, parents selectedreproduction. typical selection method probabilistically select individuals basedrelative fitness:(pi )Pr(pi ) = PnFitnessj =1 Fitness(pj )(9)pi represents individual n total number individuals. Using selectionrule, expected number offspring given policy proportional policy'sfitness. example, policy average fitness might single offspring, whereas249fiMoriarty, Schultz, & GrefenstettePolicy12345a1RRa2Ra3a4Ra5RRRRRb1RRb2RRRRRb3RRRRb4RRRRb5RRRRRc1RRc2Rc3RRRc4RRRRc5RRd1RRRRd2Rd3RRRRRd4RRRRd5RRRRe1e2RRRRRe3Re4e5 FitnessR 8R 917R 1116Table 2: EA population five decision policies sample grid world. simplepolicy representation specifies action state world. fitnesscorresponds payoffs accumulated using policy gridworld.policy twice average fitness would two offspring.2 Offspring formedcloning selected parents. new policies generated applying standardgenetic operators crossover mutation clones, shown Figure 3. processgenerating new populations strategies continue indefinitely terminatedfixed number generations acceptable level performance achieved.simple RL problems grid-world, Earl1 may provide adequate approach. later sections, point ways even Earl1 exhibitsstrengths complementary TD methods RL. However, case TDmethods, EARL methods extended handle many challenges inherentrealistic RL problems. following sections survey extensions, organized around three specific biases distinguish EAs Reinforcement Learning (EARL)generic EAs: policy representations, fitness/credit-assignment models, RLspecific genetic operators.5. Policy Representations EARLPerhaps critical feature distinguishes classes EAs one anotherrepresentation used. example, EAs function optimization use simple stringvector representation, whereas EAs combinatorial optimization use distinctive representations permutations, trees graph structures. Likewise, EAs RL usedistinctive set representations policies. range potential policy representations unlimited, representations used EARL systems datelargely categorized along two discrete dimensions. First, policies may represented either condition-action rules neural networks. Second, policies may representedsingle chromosome representation may distributed onepopulations.5.1 Single-Chromosome Representation Policies5.1.1 Rule-based PoliciesRL problems practical interest, number observable states large,simple table-based representation Earl1 impractical. large scale state2. Many parent selection rules explored (Grefenstette, 1997a, 1997b).250fiEvolutionary Algorithms Reinforcement LearningPolicy i:c i1 ai1c i2 ai2c i3 ai3...c ik aikFigure 6: Rule-based policy representation. gene represents condition-action rulemaps set states action. general, rules independentposition along chromosome. Con ict resolution mechanisms mayneeded conditions rules allowed intersect.w1w k1Policy i:w1w2w3...wk=>...wkwjFigure 7: simple parameter representation weights neural network. fitnesspolicy payoff agent uses corresponding neural netdecision policy.spaces, reasonable represent policy set condition-action rulescondition expresses predicate matches set states, shown Figure 6. Earlyexamples representation include systems LS-1 (Smith, 1983) LS-2 (Schaffer& Grefenstette, 1985), followed later Samuel (Grefenstette et al., 1990).5.1.2 Neural Net Representation PoliciesTD-based RL systems, EARL systems often employ neural net representationsfunction approximators. simplest case (see Figure 7), neural networkagent's decision policy represented sequence real-valued connection weights.straightforward EA parameter optimization used optimize weightsneural network (Belew, McInerney, & Schraudolph, 1991; Whitley, Dominic, Das, &Anderson, 1993; Yamauchi & Beer, 1993). representation thus requires leastmodification standard EA. turn distributed representations policiesEARL systems.5.2 Distributed Representation Policiesprevious section outlined EARL approaches treat agent's decision policysingle genetic structure evolves time. section addresses EARL approachesdecompose decision policy smaller components. approaches twopotential advantages. First, allow evolution work detailed level task,e.g., specific subtasks. Presumably, evolving solution restricted subtask251fiMoriarty, Schultz, & GrefenstetteSensorsMessage ListRewardsClassifiersDecisionEvolutionaryAlgorithmFigure 8: Holland's Learning Classifier System.easier evolving monolithic policy complex task. Second, decomposition permitsuser exploit background knowledge. user might base decompositionsubtasks prior analysis overall performance task; example, might knowncertain subtasks mutually exclusive therefore learned independently.user might also decompose complex task subtasks certain componentsexplicitly programmed components learned.terms knowledge representation EARL, alternative single chromosomerepresentation distribute policy several population elements. assigningfitness individual elements policy, evolutionary selection pressurebrought bear detailed aspects learning task. is, fitnessfunction individual subpolicies individual rules even individual neurons. generalapproach analogous classic TD methods take approach extremelearning statistics concerning state-action pair. case single-chromosomerepresentations, partition distributed EARL representations rule-basedneural-net-based classes.5.2.1 Distributed Rule-based Policieswell-known example distributed rule-based approach EARL Learning Classifier Systems (LCS) model (Holland & Reitman, 1978; Holland, 1987; Wilson,1994). LCS uses evolutionary algorithm evolve if-then rules called classifiersmap sensory input appropriate action. Figure 8 outlines Holland's LCS framework(Holland, 1986). sensory input received, posted message list. lefthand side classifier matches message message list, right hand side postedmessage list. new messages may subsequently trigger classifiers postmessages invoke decision LCS, traditional forward-chaining modelrule-based systems.LCS, chromosome represents single decision rule entire populationrepresents agent's policy. general, classifiers map set observed states setmessages, may interpreted either internal state changes actions. example,252fiEvolutionary Algorithms Reinforcement Learningconditionaction strengtha#! R0.75#2!0.25d3:::!0.50Table 3: LCS population grid world. # don't care symbol allowsgenerality conditions. example, first rule says \Turn right columna." strength rule used con ict resolution parent selectiongenetic algorithm.LCSLCSLCSEnvironmentFigure 9: two-level hierarchical Alecsys system. LCS learns specific behavior.interactions among rule sets pre-programmed.learning agent grid world Figure 1 two sensors, one columnone row, population LCS might appear shown Table 3.first classifier matches state column recommends action R. classifierstatistic called strength estimates utility rule. strength statisticsused con ict resolution (when one action recommended)fitness genetic algorithm. Genetic operators applied highly fit classifiersgenerate new rules. Generally, population size (i.e., number rules policy)kept constant. Thus classifiers compete space policy.Another way EARL systems distribute representation policies partitionpolicy separate modules, module updated EA. DorigoColombetti (1998) describe architecture called Alecsys complex reinforcement learning task decomposed subtasks, learned via separateLCS, shown Figure 9. provide method called behavior analysis training(BAT) manage incremental training agents using distributed LCS architecture.single-chromosome representation also extended partitioning policy across multiple co-evolving populations. example, cooperative co-evolutionmodel (Potter, 1997), agent's policy formed combining chromosomes several independently evolving populations. chromosome represents set rules,Figure 6, rules address subset performance task. example,separate populations might evolve policies different components complex task,253fiMoriarty, Schultz, & GrefenstetteEAEA 1DomainModelcollaborationfitnessEvolutionaryAlgorithmPopulationrepresentativeMergerepresentativeindividualevaluatedrepresentativeEA 2EA nrepresentativeFigure 10: Cooperative coevolutionary architecture perspective ith EA instance. EA contributes representative, merged others'representatives form collaboration, policy agent. fitnessrepresentative ects average fitness collaborations.might address mutually exclusive sets observed states. fitness chromosomecomputed based overall fitness agents employ chromosome partcombined chromosomes. combined chromosomes represent decision policycalled collaboration (Figure 10).5.2.2 Distributed Network-based PoliciesDistributed EARL systems using neural net representations also designed.(Potter & De Jong, 1995), separate populations neurons evolve, evaluationneuron based fitness collaboration neurons selected population.SANE (Moriarty & Miikkulainen, 1996a, 1998), two separate populations maintainedevolved: population neurons population network blueprints. motivation SANE comes priori knowledge individual neurons fundamentalbuilding blocks neural networks. SANE explicitly decomposes neural network searchproblem several parallel searches effective single neurons. neuron-level evolution provides evaluation recombination neural network building blocks,population blueprints search effective combinations building blocks. Figure 11gives overview interaction two populations.individual blueprint population consists set pointers individualsneuron population. generation, neural networks constructedcombining hidden neurons specified blueprint. blueprint receives fitnessaccording well corresponding network performs task. neuron receivesfitness according well top networks participates performtask. aggressive genetic selection recombination strategy used quickly buildpropagate highly fit structures neuron blueprint populations.254fiEvolutionary Algorithms Reinforcement LearningNetwork Blueprint PopulationNeuron PopulationlwlwlwlwlwlwlwlwlwlwlwlwlwlwlwlwlwlwlwlwlwlwlwlwFigure 11: overview two populations SANE. member neuron population specifies series connections (connection labels weights)made within neural network. member network blueprint population specifies series pointers specific neurons used buildneural network.6. Fitness Credit Assignment EARLEvolutionary algorithms driven concept natural selection: populationelements higher fitness leave offspring later generations, thus uencingdirection search favor high performance regions search space. conceptfitness central EA. section, discuss features fitness modelcommon across EARL systems. specifically focus ways fitnessfunction ects distinctive structure RL problem.6.1 Agent Modelfirst common features EARL fitness models fitness computedrespect RL agent. is, however policy represented EA, mustconverted decision policy agent operating RL environment. agentassumed observe description current state, select next action consultingcurrent policy, collect whatever reward provided environment. EARLsystems, TD systems, agent generally assumed perform little additionalcomputation selecting next action. neither approach limits agentstrict stimulus-response behavior, usually assumed agent performextensive planning reasoning acting. assumption ects factRL tasks involve sort control activity agent must respond dynamicenvironment within limited time frame.255fiMoriarty, Schultz, & Grefenstette6.2 Policy Level Credit Assignmentshown previous section, meaning fitness EARL systems may vary depending population elements represent. single-chromosome representation,fitness associated entire policies; distributed representation, fitness may associated individual decision rules. case, fitness always ects accumulatedrewards received agent course interaction environment,specified RL model. Fitness may also ect effort expended, amount delay.worthwhile considering different approaches credit assignment TDEA methods. reinforcement learning problem, payoffs may sparse, is,associated certain states. Consequently, payoff may ect qualityextended sequence decisions, rather individual decision. example, robotmay receive reward movement places \goal" position within room.robot's reward, however, depends many previous movements leadingpoint. dicult credit assignment problem therefore exists apportionrewards sequence decisions individual decisions.general, EA TD methods address credit assignment problem different ways. TD approaches, credit reward signal explicitly propagateddecision made agent. many iterations, payoffs distributed acrosssequence decisions appropriately discounted reward value associatedindividual state decision pair.simple EARL systems Earl1 , rewards associated sequencesdecisions distributed individual decisions. Credit assignmentindividual decision made implicitly, since policies prescribe poor individual decisionsfewer offspring future generations. selecting poor policies, evolutionautomatically selects poor individual decisions. is, building blocks consistingparticular state-action pairs highly correlated good policies propagatedpopulation, replacing state-action pairs associated poorer policies.Figure 12 illustrates differences credit assignment TD Earl1grid world Figure 1. Q-learning TD method explicitly assigns credit blameindividual state-action pair passing back immediate reward estimated payoffnew state. Thus, error term becomes associated action performedagent. EA approach explicitly propagate credit action ratherassociates overall fitness entire policy. Credit assigned implicitly, basedfitness evaluations entire sequences decisions. Consequently, EA tend selectpolicies generate first third sequences achieve lower fitnessscores. EA thus implicitly selects action state b2, example,present bad sequences present good sequences.6.3 Subpolicy Credit AssignmentBesides implicit credit assignment performed building blocks, EARL systemsalso addressed credit assignment problem directly. shown Section 4,individuals EARL system might represent either entire policies componentspolicy (e.g., component rule-sets, individual decision rules, individual neurons).distributed-representation EARLs, fitness explicitly assigned individual components.256fiEvolutionary Algorithms Reinforcement LearningTD Explicit Credit Assignment2+Max(Q(b1,a))a1,Rb1,D2+Max(Q(b1,a))a1,R2+Max(Q(a2,a))a1,D1+Max(Q(b2,a))a2,Da1,Rb1,Db2,Db3,Dc32c3a1,Rb1,Db2,Rc2,Dc39c3a1,Da2,Rb2,Db3,Dc31d2a1,Da2,Db2,Rc2,Dd284+Max(Q(c3,a))4+Max(Q(c3,a))b3,D-5+Max(Q(c2,a))b2,Rc3c2,D-5+Max(Q(b3,a))b2,DFitness4+Max(Q(c3,a))b3,D-5+Max(Q(c2,a))b2,R1+Max(Q(b2,a))a2,R-5+Max(Q(b3,a))b2,D1+Max(Q(b2,a))b1,D2+Max(Q(a2,a))a1,D1+Max(Q(b2,a))EA Implicit Credit Assignment4+Max(Q(d2,a))c2,DFigure 12: Explicit vs. implicit credit assignment. Q-learning TD method assigns creditstate-action pair based immediate reward predicted futurerewards. EA method assigns credit implicitly associating fitness valuesentire sequences decisions.cases policy represented explicit components, different fitness functionsassociated different evolving populations, allowing implementer \shape"overall policy evolving subpolicies specific subtasks (Dorigo & Colombetti, 1998;Potter, De Jong, & Grefenstette, 1995). ambitious goal allow systemmanage number co-evolving species well form interactions (Potter, 1997).exciting research still early stage.example, LCS model, classifier (decision rule) strengthupdated using TD-like method called bucket brigade algorithm (Holland, 1986).bucket brigade algorithm, strength classifier used bid classifiersright post messages. Bids subtracted winning classifiers passed backclassifiers posted enabling message previous step. Classifier strengthsthus reinforced classifier posts message triggers another classifier.classifier invokes decision LCS receives strength reinforcement directlyenvironment. bucket brigade bid passing mechanism clearly bears strongrelation method temporal differences (Sutton, 1988). bucket brigade updatesgiven classifier's strength based strength classifiers fire direct resultactivation. TD methods differ slightly respect assign creditbased strictly temporal succession take account causal relations steps.remains unclear appropriate distributing credit.Even single chromosome representations, TD-like methods adoptedEARL systems. Samuel, gene (decision rule) also maintains quantity calledstrength used resolve con ict one rule matches agent's currentsensor readings. payoff obtained (thereby terminating trial), strengths257fiMoriarty, Schultz, & Grefenstetterules fired trial updated (Grefenstette, 1988). addition resolvingcon icts, rule's strength also plays role triggering mutation operations, describednext section.7. RL-Specific Genetic Operatorscreation special genetic operators provides another avenue imposing RLspecific bias EAs. Specialized operators EARL systems first appeared (Holland,1986), so-called triggered operators responsible creating new classifierslearning agent found classifier existing population matchedagent's current sensor readings. case, high-strength rule explicitly generalizedcover new set sensor readings. similar rule-creation operator includedearly versions Samuel (Grefenstette et al., 1990). Later versions Samuel includednumber mutation operators created altered rules based agent's earlyexperiences. example, Samuel's Specialization mutation operator triggeredlow-strength, general rule fires episode results high payoff.case, rule's conditions reduced generality closely match agent's sensorreadings. example, agent sensor readings (range = 40; bearing = 100)original rule is:range = [25; 55] bearing = [0; 180] SET turn = 24 (strength0.1)new rule would be:range = [35; 45] bearing = [50; 140] SET turn = 24 (strength0.8)Since episode triggering operator resulted high payoff, one might suspectoriginal rule over-generalized, new, specific version might leadbetter results. (The strength new rule initialized payoff receivedtriggering episode.) considered Lamarckian operator agent'sexperience causing genetic change passed later offspring.3Samuel also uses RL-specific crossover operator recombine policies. particular,crossover Samuel attempts cluster decision rules assigning offspring.example, suppose traces previous evaluations parent strategies follows (Ri;j denotes j th decision rule policy i):Trace parent #1:Episode:...8. R1;3 ! R1;1 ! R1;7 ! R1;5 High Payoff9. R1;2 ! R1;8 ! R1;4Low Payoff3. Jean Baptiste Lamarck developed evolutionary theory stressed inheritance acquired characteristics, particular acquired characteristics well adapted surrounding environment.course, Lamarck's theory superseded Darwin's emphasis two-stage adaptation: undirectedvariation followed selection. Research generally failed substantiate Lamarckian mechanismsbiological systems (Gould, 1980).258fiEvolutionary Algorithms Reinforcement Learning...Trace parent #2:...4. R2;7 ! R2;55. R2;6 ! R2;2 ! R2;4...one possible offspring would be:Low PayoffHigh PayofffR1;8 ; : : :; R1;3 ; R1;1 ; R1;7 ; R1;5 ; : : :; R2;6 ; R2;2 ; R2;4 ; : : :; R2;7gmotivation rules fire sequence achieve high payofftreated group recombination, order increase likelihood offspringpolicy inherit better behavior patterns parents. Rulesfire successful episodes (e.g., R1;8) randomly assigned one two offspring.form crossover Lamarckian (since triggered experiencesagent), directly related structure RL problem, since groupscomponents policies according temporal association among decision rules.8. Strengths EARLEA approach represents interesting alternative solving RL problems, offeringseveral potential advantages scaling realistic applications. particular, EARLsystems developed address dicult challenges RL problems, including:Large state spaces;Incomplete state information;Non-stationary environments.section focuses ways EARL address challenges.8.1 Scaling Large State SpacesMany early papers RL literature analyze eciency alternative learning methodstoy problems similar grid world shown Figure 1. studies usefulacademic exercises, number observed states realistic applications RL likelypreclude approach requires explicit storage manipulation statisticsassociated observable state-action pair. two ways EARL policyrepresentations help address problem large state spaces: generalization selectivity.8.1.1 Policy GeneralizationEARL policy representations specify policy level abstraction higherexplicit mapping observed states actions. case rule-based representations,rule language allows conditions match sets states, thus greatly reducing storage259fiMoriarty, Schultz, & Grefenstettea1 a2 a3 a4 a5 b1 b2 b3 b4 b5 c1 c2 c3 c4 c5 d1 d2 d3 d4 d5 e1 e2 e3 e4 e5R 16 7 ? 17 12 8 12 11 11 12 14 7 12 13 9 12 11 12 12 11 ? 12 7 ? 9L 9 13 12 11 ? 15 ? 17 16 ? 11 13 12 7 14 11 12 ? 11 16 12 ? 13 12 16Table 4: approximated value function population Table 2. table displays average fitness policies select state-action pair ectsestimated impact action overall fitness. Given tiny populationsize example, estimates particularly accurate. Note questionmarks states actions converged. Since policies select alternative action, population statistics impact actionsfitness. different simple TD methods, statistics actionsmaintained.required specify policy. noted, however, generality ruleswithin policy may vary considerably, level rules specify actionsingle observed state way completely general rules recommend actionregardless current state. Likewise, neural net representations, mapping functionstored implicitly weights connections neural net. either case,generalized policy representation facilitates search good policies grouping togetherstates action required.8.1.2 Policy SelectivityEARL systems selective representations policies. is, EA learns mappings observed states recommended actions, usually eliminating explicit informationconcerning less desirable actions. Knowledge bad decisions explicitly preserved,since policies make decisions selected evolutionary algorithmeventually eliminated population. advantage selective representations attention focused profitable actions only, reducing space requirementspolicies.Consider example simple EARL operating grid world. population evolves, policies normally converge best actions specific state,selective pressure achieve high fitness levels. example, population shownTable 2 converged alleles (actions) states a3; a5; b2; b5; d3; e1; e2.converged state-action pairs highly correlated fitness. example, policiesconverged action R state b2. Taking action R state b2 achieves much higherexpected return action (15 vs. 8 Table 1). Policies select actionstate b2 achieve lower fitness scores selected against. simple EARL, snapshot population (Table 2) provides implicit estimate corresponding TD valuefunction (Table 4), distribution biased toward profitable state-actionspairs.260fiEvolutionary Algorithms Reinforcement Learning.5L3.0LRedRBlueR1.0GreenLBlueL- 4.0RR1.0.75Figure 13: environment incomplete state information. circles representstates world colors represent agent's sensory input. agentequally likely start red state green state8.2 Dealing Incomplete State InformationClearly, favorable condition reinforcement learning occurs agentobserve true state dynamic system interacts. complete stateinformation available, TD methods make ecient use available feedback associatingreward directly individual decisions. real world situations, however, agent'ssensors likely provide partial view may fail disambiguate manystates. Consequently, agent often unable completely distinguish currentstate. problem termed perceptual aliasing hidden state problem.case limited sensory information, may useful associate rewardslarger blocks decisions. Consider situation Figure 13, agent mustact without complete state information. Circles represent specific states world,colors represent sensor information agent receives within state. Squarenodes represent goal states corresponding reward shown inside. state,agent choice two actions (L R). assume state transitionsdeterministic agent equally likely start either statered green sensor readings.example, two different states return sensor reading blue,agent unable distinguish them. Moreover, actions bluestate return different rewards. Q function applied problem treats sensorreading blue one observable state, rewards action averagedblue states. Thus, Q(blue; L) Q(blue; R) converge -0.5 1, respectively.Since reward Q(blue; R) higher alternatives observable states redgreen, agent's policy Q-learning choose enter observable state bluetime. final decision policy Q-learning shown Table 5. table alsoshows optimal policy respect agent's limited view world.261fiMoriarty, Schultz, & GrefenstetteValue Function Policy Optimal PolicyRRLRRLExpected Reward1.01.875RedGreenBlueTable 5: policy expected reward returned converged Q function comparedoptimal policy given sensory information.words, policy ects optimal choices agent cannot distinguish two bluestates.associating values individual observable states, simple TD methodsvulnerable hidden state problems. example, ambiguous state informationmisleads TD method, mistakenly combines rewards two different statessystem. confounding information multiple states, TD cannot recognizeadvantages might associated specific actions specific states, example,action L top blue state achieves high reward.contrast, since EA methods associate credit entire policies, relynet results decision sequences sensor information, may, all,ambiguous. example, evolutionary algorithm exploits disparity rewardsdifferent blue states evolves policies enter good blue state avoidbad one. agent remains unable distinguish two blue states, evolutionary algorithm implicitly distinguishes among ambiguous states rewarding policiesavoid bad states.example, EA method expected evolve optimal policy currentexample given existing, ambiguous state information. Policies choose actionsequence R,L starting red state achieve highest levels fitness,therefore selected reproduction EA. agents using policiesplaced green state select action L, receive lowest fitness score, sincesubsequent action, L blue sensors, returns negative reward. Thus, manypolicies achieve high fitness started red state selectedchoose L green state. course many generations, policies mustchoose action R green state maximize fitness ensure survival.confirmed hypotheses empirical tests. Q-learner using single-step updatestable-based representation converged values Table 5 every run.evolutionary algorithm4 consistently converged 80% population optimal policy.Figure 14 shows average percentage optimal policy population functiontime, averaged 100 independent runs.Thus even simple EA methods Earl1 appear robust presencehidden states simple TD methods. However, refined sensor information couldstill helpful. previous example, although EA policies achieve better averagereward TD policy, evolved policy remains unable procure 3.04. used binary tournament selection, 50 policy population, 0.8 crossover probability, 0.01mutation rate.262fiEvolutionary Algorithms Reinforcement Learning100Percentage Optimal80604020001020304050Generation60708090100Figure 14: optimal policy distribution hidden state problem evolutionaryalgorithm. graph plots percentage optimal policies population,averaged 100 runs.1.0 rewards two blue states. rewards could realized, however,agent could separate two blue states. Thus, method generates additionalfeatures disambiguate states presents important asset EA methods. Kaelblinget al. (1996) describe several promising solutions hidden state problem,additional features agent's previous decisions observations automaticallygenerated included agent's sensory information (Chrisman, 1992; Lin & Mitchell,1992; McCallum, 1995; Ring, 1994). methods effective disambiguatingstates TD methods initial studies, research required determineextent similar methods resolve significant hidden state information realisticapplications. would useful develop ways use methods augment sensorydata available EA methods well.8.3 Non-Stationary Environmentsagent's environment changes time, RL problem becomes even dicult,since optimal policy becomes moving target. classic trade-off explorationexploitation becomes even pronounced. Techniques encouraging explorationTD-based RL include adding exploration bonus estimated value state-actionpairs ects long since agent tried action (Sutton, 1990),building statistical model agent's uncertainty (Dayan & Sejnowski, 1996).Simple modifications standard evolutionary algorithms offer ability track nonstationary environments, thus provide promising approach RL dicultcases.fact evolutionary search based competition within population policiessuggest immediate benefits tracking non-stationary environments. extentpopulation maintains diverse set policies, changes environment bias263fiMoriarty, Schultz, & Grefenstetteselective pressure favor policies fit current environment.long environment changes slowly respect time required evaluatepopulation policies, population able track changing fitness landscapewithout alteration algorithm. Empirical studies show maintainingdiversity within population may require higher mutation rate usuallyadopted stationary environments (Cobb & Grefenstette, 1993).addition, special mechanisms explored order make EAs responsive rapidly changing environments. example, (Grefenstette, 1992) suggestsmaintaining random search within restricted portion population. randompopulation elements analogous immigrants populations uncorrelatedfitness landscapes. Maintaining source diversity permits EA respond rapidlylarge, sudden changes fitness landscape. keeping randomized portionpopulation less 30% population, impact search eciencystationary environments minimized. general approach easily appliedEARL systems.useful algorithms developed ensure diversity evolving popultions include fitness sharing (Goldberg & Richardson, 1987), crowding (De Jong, 1975),local mating (Collins & Jefferson, 1991). Goldberg's fitness sharing model, example, similar individuals forced share large portion single fitness valueshared solution point. Sharing decreases fitness similar individuals causesevolution select individuals overpopulated niches.EARL methods employ distributed policy representations achieve diversity automatically well-suited adaptation dynamic environments. distributedrepresentation, individual represents partial solution. Complete solutionsbuilt combining individuals. individual solve task own,evolutionary algorithm search several complementary individuals togethersolve task. Evolutionary pressures therefore present prevent convergencepopulation. Moriarty Miikkulainen (1998) showed inherent diversity specialization SANE allow adapt much quickly changes environmentstandard, convergent evolutionary algorithms.Finally, learning system detect changes environment, even directresponse possible. anytime learning model (Grefenstette & Ramsey, 1992),EARL system maintains case-base policies, indexed values environmentaldetectors corresponding environment given policy evolved.environmental change detected, population policies partially reinitialized,using previously learned policies selected basis similarity previouslyencountered environment current environment. result, environmentchanges cyclic, population immediately seeded policieseffect last occurrence current environment. populationpolicies, approach protected kinds errors detecting environmentalchanges. example, even spurious environmental change mistakenly detected,learning unduly affected, since part current population policiesreplaced previously learned policies. Zhou (1990) explored similar approach basedLCS.264fiEvolutionary Algorithms Reinforcement Learningsummary, EARL systems respond non-stationary environments, techniques generic evolutionary algorithms techniques specifically designed RL mind.9. Limitations EARLAlthough EA approach RL promising growing list successful applications (as outlined following section), number challenges remain.9.1 Online Learningdistinguish two broad approaches reinforcement learning |online learningoine learning. online learning, agent learns directly experiencesoperational environment. example, robot might learn navigate warehouseactually moving physical environment. two problems using EARLsituation. First, likely require large number experiences orderevaluate large population policies. Depending quickly agent performs tasksresult environmental feedback, may take unacceptable amount timerun hundreds generations EA evaluates hundreds thousands policies.Second, may dangerous expensive permit agent perform actionsactual operational environment might cause harm environment. Yetlikely least policies EA generates bad policies.objections apply TD methods well. example, theoretical resultsprove optimality Q-learning require every state visited infinitely often,obviously impossible practice. Likewise, TD methods may exploreundesirable states acceptable value-function found.TD EARL, practical considerations point toward use oine learning,RL system performs exploration simulation models environment.Simulation models provide number advantages EARL, including abilityperform parallel evaluations policies population simultaneously (Grefenstette,1995).9.2 Rare Statesmemory record observed states rewards differs greatly EA TDmethods. Temporal difference methods normally maintain statistics concerning every stateaction pair. states revisited, new reinforcement combined previousvalue. New information thus supplements previous information, information content agent's reinforcement model increases exploration. manner, TDmethods sustain knowledge good bad state-action pairs.pointed previously, EA methods normally maintain information goodpolicies policy components. Knowledge bad decisions explicitly preserved, sincepolicies make decisions selected evolutionary algorithmeventually eliminated population. example, refer Table 4,shows implicit statistics population Table 2. Note question265fiMoriarty, Schultz, & Grefenstettemarks states actions converged. Since policies population selectalternative action, EA statistics impact actions fitness.reduction information content within evolving population disadvantage respect states rarely visited. evolutionary algorithm, valuegenes real impact fitness individual tends drift randomvalues, since mutations tend accumulate genes. state rarely encountered,mutations may freely accumulate gene describes best action state.result, even evolutionary algorithm learns correct action rare state,information may eventually lost due mutations. contrast, since table-based TDmethods permanently record information state-action pairs, mayrobust learning agent encounter rare state. course, TD methoduses function approximator neural network value function,suffer memory loss concerning rare states, since many updates frequentlyoccurring states dominate updates rare states.9.3 Proofs OptimalityOne attractive features TD methods Q-learning algorithm proofoptimality (Watkins & Dayan, 1992). However, practical importance resultlimited, since assumptions underlying proof (e.g., hidden states, state visitedinfinitely often) satisfied realistic applications. current theory evolutionaryalgorithms provide similar level optimality proofs restricted classes search spaces(Vose & Wright, 1995). However, general theoretical tools availableapplied realistic RL problems. case, ultimate convergence optimal policymay less important practice eciently finding reasonable approximation.pragmatic approach may ask ecient alternative RL algorithms are,terms number reinforcements received developing policy withintolerance level optimal policy. model probably approximately correct(PAC) learning (Valiant, 1984), performance learner measured manylearning experiences (e.g., samples supervised learning) required convergingcorrect hypothesis within specified error bounds. Although developed initiallysupervised learning, PAC approach extended recently TD methods(Fiechter, 1994) general EA methods (Ros, 1997). analytic methodsstill early stage development, research along lines may one dayprovide useful tools understanding theoretical practical advantages alternativeapproaches RL. time, experimental studies provide valuable evidenceutility approach.10. Examples EARL MethodsFinally, take look significant examples EARL approach resultsRL problems. Rather attempt exhaustive survey, selected four EARLsystems representative diverse policies representations outlined Section 5.Samuel represents class single-chromosome rule-based EARL systems. Alecsysexample distributed rule-based EARL method. Genitor single chromosomeneural-net system, Sane distributed neural net system. brief survey266fiEvolutionary Algorithms Reinforcement Learningprovide starting point interested investigating evolutionary approachreinforcement learning.10.1SamuelSamuel (Grefenstette et al., 1990) EARL system combines Darwinian Lamarckian evolution aspects temporal difference reinforcement learning. Samuelused learn behaviors navigation collision avoidance, tracking, herding, robots autonomous vehicles.Samuel uses single-chromosome, rule-based representation policies, is,member population policy represented rule set gene rulemaps state world actions performed. example rule might be:range = [35; 45] bearing = [0; 45] SET turn = 16 (strength0.8)use high-level language rules offers several advantages low-level binarypattern languages typically adopted genetic learning systems. First, makes easierincorporate existing knowledge, whether acquired experts symbolic learning programs. Second, easier transfer knowledge learned human operators. Samuelalso includes mechanisms allow coevolution multiple behaviors simultaneously.addition usual genetic operators crossover mutation, Samuel uses traditional machine learning techniques form Lamarckian operators. Samuel keepsrecord recent experiences allow operators generalization, specialization,covering, deletion make informed changes individual genes (rules) basedexperiences.Samuel used successfully many reinforcement learning applications.brie describe three examples learning complex behaviors real robots.applications Samuel, learning performed simulation, ecting factinitial phases learning, controlling real system expensivedangerous. Learned behaviors tested on-line system.(Schultz & Grefenstette, 1992; Schultz, 1994; Schultz & Grefenstette, 1996), Samuelused learn collision avoidance local navigation behaviors Nomad 200 mobilerobot. sensors available learning task five sonars, five infrared sensors,range bearing goal, current speed vehicle. Samuellearned mapping sensors controllable actions { turning ratetranslation rate wheels. Samuel took human-written rule set could reachgoal within limited time without hitting obstacle 70 percent time,50 generations able obtain 93.5 percent success rate.(Schultz & Grefenstette, 1996), robot learned herd second robot \pasture". task, learning system used range bearing second robot,heading second robot, range bearing goal, input sensors.system learned mapping sensors turning rate steering rate.experiments, success measured percentage times robot couldmaneuver second robot goal within limited amount time. second robotimplemented random walk, plus behavior made avoid nearby obstacles.first robot learned exploit achieve goal moving second robot goal.267fiMoriarty, Schultz, & GrefenstetteSamuel given initial, human-designed rule set performance 27 percent,250 generations able move second robot goal 86 percenttime.(Grefenstette, 1996) Samuel EA system combined case-based learningaddress adaptation problem. approach, called anytime learning (Grefenstette &Ramsey, 1992), learning agent interacts external environmentinternal simulation. anytime learning approach involves two continuously runninginteracting modules: execution module learning module. executionmodule controls agent's interaction environment includes monitordynamically modifies internal simulation model based observations actual agentenvironment. learning module continuously tests new strategies agentsimulation model, using genetic algorithm evolve improved strategies,updates knowledge base used execution module best available results.Whenever simulation model modified due observed change agentenvironment, genetic algorithm restarted modified model. learning systemoperates indefinitely, execution system uses results learning becomeavailable. work Samuel shows EA method particularly well-suitedanytime learning. Previously learned strategies treated cases, indexedset conditions learned. new situation encountered,nearest neighbor algorithm used find similar previously learned cases.nearest neighbors used re-initialize genetic population policies new case.Grefenstette (1996) reports experiments mobile robot learns track anotherrobot, dynamically adapts policies using anytime learning encounters seriespartial system failures. approach blurs line online oine learning,since online system updated whenever oine learning system developsimproved policy. fact, oine learning system even executed on-boardoperating mobile robot.10.2Alecsysdescribed previously, Alecsys (Dorigo & Colombetti, 1998) distributed rule-basedEA supports approach design autonomous systems called behavioral engineering. approach, tasks performed complex autonomous systemsdecomposed individual behaviors, learned via learning classifier systems module, shown Figure 9. decomposition performed human designer,fitness function associated LCS carefully designed ect roleassociated component behavior within overall autonomous system. Furthermore,interactions among modules also preprogrammed. example, designer maydecide robot learn approach goal except threatening predatornear, case robot evade predator. overall architectureset behaviors set evasion behavior higher prioritygoal-seeking behavior, individual LCS modules evolve decision rulesoptimally performing subtasks.Alecsys used develop behavioral rules number behaviorsautonomous robots, including complex behavior groups Chase/Feed/Escape268fiEvolutionary Algorithms Reinforcement Learning(Dorigo & Colombetti, 1998). approach implemented testedsimulated robots real robots. exploits human design EARLmethods optimize system performance, method shows much promise scalingrealistic tasks.10.3GenitorGenitor (Whitley & Kauth, 1988; Whitley, 1989) aggressive, general purpose geneticalgorithm shown effective specialized use reinforcement-learningproblems. Whitley et al. (1993) demonstrated Genitor eciently evolve decisionpolicies represented neural networks using limited reinforcement domain.Genitor relies solely evolutionary algorithm adjust weights neuralnetworks. solving RL problems, member population Genitor representsneural network sequence connection weights. weights concatenated realvalued chromosome along gene represents crossover probability. crossovergene determines whether network mutated (randomly perturbed) whethercrossover operation (recombination another network) performed. crossovergene modified passed offspring based offspring's performance comparedparent. offspring outperforms parent, crossover probability decreased.Otherwise, increased. Whitley et al. refer technique adaptive mutation,tends increase mutation rate populations converge. Essentially, methodpromotes diversity within population encourage continual exploration solutionspace.Genitor also uses so-called \steady-state" genetic algorithm new parentsselected genetic operators applied individual evaluated. approachcontrasts \generational" GAs entire population evaluated replacedgeneration. steady-state GA, policy evaluated retainsfitness value indefinitely. Since policies lower fitness likelyreplaced, possible fitness based noisy evaluation function mayundesirable uence direction search. case pole-balancing RLapplication, fitness value depends length time policy maintaingood balance, given randomly chosen initial state. fitness therefore randomvariable depends initial state. authors believe noise fitnessfunction little negative impact learning good policies, perhapsdicult poor networks obtain good fitness good networks (ofmany copies population) survive occasional bad fitness evaluation.interesting general issue EARL needs analysis.Genitor adopts specific modification RL applications. First, representation uses real-valued chromosome rather bit-string representation weights.Consequently, Genitor always recombines policies weight definitions, thus reducing potentially random disruption neural network weights might result crossoveroperations occurred middle weight definition. second modificationhigh mutation rate helps maintain diversity promote rapid explorationpolicy space. Finally, Genitor uses unusually small populations order discouragedifferent, competing neural network \species" forming within population. Whit269fiMoriarty, Schultz, & Grefenstetteley et al. (1993) argue speciation leads competing conventions produces pooroffspring two dissimilar networks recombined.Whitley et al. (1993) compare Genitor Adaptive Heuristic Critic (Anderson,1989, AHC), uses TD method reinforcement learning. several differentversions common pole-balancing benchmark task, Genitor found comparable AHC learning rate generalization. One interesting differenceWhitley et al. found Genitor consistent AHC solvingpole-balancing problem failure signals occurs wider pole bounds (makeproblem much harder). AHC, preponderance failures appears cause statesoverpredict failure. contrast, EA method appears effective finding policiesobtain better overall performance, even success uncommon. difference seemsEA tends ignore cases pole cannot balanced, concentrate successful cases. serves another example advantages associatedsearch policy space, based overall policy performance, rather payingmuch attention value associated individual states.10.4SaneSane (Symbiotic, Adaptive Neuro-Evolution) system designed ecient methodbuilding artificial neural networks RL domains possible generatetraining data normal supervised learning (Moriarty & Miikkulainen, 1996a, 1998).Sane system uses evolutionary algorithm form hidden layer connectionsweights neural network. neural network forms direct mapping sensorsactions provides effective generalization state space. Sane's methodcredit assignment EA, allows apply many problemsreinforcement sparse covers sequence decisions. described previously, Saneuses distributed representation policies.Sane offers two important advantages reinforcement learning normallypresent implementations neuro-evolution. First, maintains diverse populations.Unlike canonical function optimization EA converge population single solution, Sane forms solutions unconverged population. several different typesneurons necessary build effective neural network, inherent evolutionarypressure develop neurons perform different functions thus maintain several different types individuals within population. Diversity allows recombination operatorscrossover continue generate new neural structures even prolonged evolution.feature helps ensure solution space explored eciently throughoutlearning process. Sane therefore resilient suboptimal convergenceadaptive changes domain.second feature Sane explicitly decomposes search complete solutions search partial solutions. Instead searching complete neural networksonce, solutions smaller problems (good neurons) evolved, combined form effective full solution (a neural network). words, Sane effectivelyperforms problem reduction search space neural networks.Sane shown effective several different large scale problems. one problem,Sane evolved neural networks direct focus minimax game-tree search (Moriarty270fiEvolutionary Algorithms Reinforcement Learning& Miikkulainen, 1994). selecting moves evaluated given gamesituation, Sane guides search away misinformation search tree towardseffective moves. Sane tested game tree search Othello usingevaluation function former world champion program Bill (Lee & Mahajan, 1990).Tested full-width minimax search, Sane significantly improved play Bill,examining subset board positions.second application, SANE used learn obstacle avoidance behaviorsrobot arm (Moriarty & Miikkulainen, 1996b). approaches learning robot armcontrol learn hand-eye coordination supervised training methods examplescorrect behavior explicitly given. Unfortunately domains obstaclesarm must make several intermediate joint rotations reaching target, generatingtraining examples extremely dicult. reinforcement learning approach, however,require examples correct behavior learn intermediate movementsgeneral reinforcements. Sane implemented form neuro-control networks capablemaneuvering OSCAR-6 robot arm among obstacles reach random target locations.Given camera-based visual infrared sensory input, neural networks learnedeffectively combine target reaching obstacle avoidance strategies.related examples evolutionary methods learning neural-net controlsystems robotics, reader see (Cliff, Harvey, & Husbands, 1993; Husbands,Harvey, & Cliff, 1995; Yamauchi & Beer, 1993).11. Summaryarticle began suggesting two distinct approaches solving reinforcement learningproblems; one search value function space one search policy space. TDEARL examples two complementary approaches. approaches assumelimited knowledge underlying system learn experimenting different policies using reinforcement alter policies. Neither approach requires precisemathematical model domain, may learn direct interactionsoperational environment.Unlike TD methods, EARL methods generally base fitness overall performancepolicy. sense, EA methods pay less attention individual decisions TDmethods do. first glance, approach appears make less ecient useinformation, may fact provide robust path toward learning good policies, especiallysituations sensors inadequate observe true state world.useful view path toward practical RL systems choice EATD methods. tried highlight strengths evolutionaryapproach, also shown EARL TD, complementary approaches,means mutually exclusive. cited examples successful EARL systemsSamuel Alecsys explicitly incorporate TD elements multilevel credit assignment methods. likely many practical applications dependkinds multi-strategy approaches machine learning.also listed number areas need work, particularly theoretical side. RL, would highly desirable better tools predictingamount experience needed learning agent reaching specified level per271fiMoriarty, Schultz, & Grefenstetteformance. existing proofs optimality Q-learning EA extremelylimited practical use predicting well either approach perform realistic problems. Preliminary results shown tools PAC analysis appliedEA TD methods, much effort needed direction.Many serious challenges remain scaling reinforcement learning methods realistic applications. pointing shared goals concerns two complementaryapproaches, hope motivate collaboration progress field.ReferencesAnderson, C. W. (1989). Learning control inverted pendulum using neural networks.IEEE Control Systems Magazine, 9, 31{37.Barto, A. G., Sutton, R. S., & Watkins, C. J. C. H. (1990). Learning sequentialdecision making. Gabriel, M., & Moore, J. W. (Eds.), Learning ComputationalNeuroscience. MIT Press, Cambridge, MA.Belew, R. K., McInerney, J., & Schraudolph, N. N. (1991). Evolving networks: Usinggenetic algorithm connectionist learning. Farmer, J. D., Langton, C.,Rasmussen, S., & Taylor, C. (Eds.), Artificial Life II Reading, MA. Addison-Wesley.Chrisman, L. (1992). Reinforcement learning perceptual aliasing: perceptualdistinctions approach. Proceedings Tenth National Conference ArtificialIntelligence, pp. 183{188 San Jose, CA.Cliff, D., Harvey, I., & Husbands, P. (1993). Explorations evolutionary robotics. AdaptiveBehavior, 2, 73{110.Cobb, H. G., & Grefenstette, J. J. (1993). Genetic algorithms tracking changing environments. Proc. Fifth International Conference Genetic Algorithms, pp. 523{530.Collins, R. J., & Jefferson, D. R. (1991). Selection massively parallel genetic algorithms.Proceedings Fourth International Conference Genetic Algorithms, pp.249{256 San Mateo, CA. Morgan Kaufmann.Dayan, P., & Sejnowski, T. J. (1996). Exploration bonuses dual control. MachineLearning, 25 (1), 5{22.De Jong, K. A. (1975). Analysis Behavior Class Genetic Adaptive Systems.Ph.D. thesis, University Michigan, Ann Arbor, MI.Dorigo, M., & Colombetti, M. (1998). Robot Shaping: Experiment Behavioral Engineering. MIT Press, Cambridge, MA.Fiechter, C.-N. (1994). Ecient reinforcement learning. Proceedings SeventhAnnual ACM Conference Computational Learning Theory, pp. 88{97. AssociationComputing Machinery.Fogel, L. J., Owens, A. J., & Walsh, M. J. (1966). Artificial Intelligence SimulatedEvolution. Wiley Publishing, New York.272fiEvolutionary Algorithms Reinforcement LearningGoldberg, D. E. (1989). Genetic Algorithms Search, Optimization, Machine Learning. Addison-Wesley, Reading, MA.Goldberg, D. E., & Richardson, J. (1987). Genetic algorithms sharing multimodalfunction optimization. Proceedings Second International Conference Genetic Algorithms, pp. 148{154 San Mateo, CA. Morgan Kaufmann.Grefenstette, J. J. (1986). Optimization control parameters genetic algorithms. IEEETransactions Systems, Man & Cybernetics, SMC-16 (1), 122{128.Grefenstette, J. J. (1987). Incorporating problem specific knowledge genetic algorithms.Davis, L. (Ed.), Genetic Algorithms Simulated Annealing, pp. 42{60 San Mateo,CA. Morgan Kaufmann.Grefenstette, J. J. (1988). Credit assignment rule discovery system based geneticalgorithms. Machine Learning, 3 (2/3), 225{245.Grefenstette, J. J. (1992). Genetic algorithms changing environments. Manner, R.,& Manderick, B. (Eds.), Parallel Problem Solving Nature, 2, pp. 137{144.Grefenstette, J. J. (1995). Robot learning parallel genetic algorithms networkedcomputers. Proceedings 1995 Summer Computer Simulation Conference(SCSC '95), pp. 352{257.Grefenstette, J. J. (1996). Genetic learning adaptation autonomous robots. RoboticsManufacturing: Recent Trends Research Applications, Volume 6, pp. 265{270. ASME Press, New York.Grefenstette, J. J. (1997a). Proportional selection sampling algorithms. HandbookEvolutionary Computation, chap. C2.2. IOP Publishing Oxford University Press.Grefenstette, J. J. (1997b). Rank-based selection. Handbook Evolutionary Computation, chap. C2.4. IOP Publishing Oxford University Press.Grefenstette, J. J., & Ramsey, C. L. (1992). approach anytime learning. Proc.Ninth International Conference Machine Learning, pp. 189{195 San Mateo, CA.Morgan Kaufmann.Grefenstette, J. J., Ramsey, C. L., & Schultz, A. C. (1990). Learning sequential decisionrules using simulation models competition. Machine Learning, 5, 355{381.Holland, J. H. (1975). Adaptation Natural Artificial Systems: IntroductoryAnalysis Applications Biology, Control Artificial Intelligence. UniversityMichigan Press, Ann Arbor, MI.Holland, J. H. (1986). Escaping brittleness: possibilities general-purpose learningalgorithms applied parallel rule-based systems. Machine Learning: ArtificialIntelligence Approach, Vol. 2. Morgan Kaufmann, Los Altos, CA.273fiMoriarty, Schultz, & GrefenstetteHolland, J. H. (1987). Genetic algorithms classifier systems: Foundations futuredirections. Proceedings Second International Conference Genetic Algorithms, pp. 82{89 Hillsdale, New Jersey.Holland, J. H., & Reitman, J. S. (1978). Cognitive systems based adaptive algorithms.Pattern-Directed Inference Systems. Academic Press, New York.Husbands, P., Harvey, I., & Cliff, D. (1995). Circle round: state space attractorsevolved sighted robots. Robot. Autonomous Systems, 15, 83{106.Kaelbling, L. P., Littman, M. L., & Moore, A. W. (1996). Reinforcement learning: survey.Journal Artificial Intelligence Research, 4, 237{285.Koza, J. R. (1992). Genetic Programming: Programming Computers MeansNatural Selection. MIT Press, Cambridge, MA.Lee, K.-F., & Mahajan, S. (1990). development world class Othello program.Artificial Intelligence, 43, 21{36.Lin, L.-J., & Mitchell, T. M. (1992). Memory approaches reinforcement learning nonMarkovian domains. Tech. rep. CMU-CS-92-138, Carnegie Mellon University, SchoolComputer Science.McCallum, A. K. (1995). Reinforcement Learning Selective Perception HiddenState. Ph.D. thesis, University Rochester.Moriarty, D. E., & Miikkulainen, R. (1994). Evolving neural networks focus minimaxsearch. Proceedings Twelfth National Conference Artificial Intelligence(AAAI-94), pp. 1371{1377 Seattle, WA. MIT Press.Moriarty, D. E., & Miikkulainen, R. (1996a). Ecient reinforcement learningsymbiotic evolution. Machine Learning, 22, 11{32.Moriarty, D. E., & Miikkulainen, R. (1996b). Evolving obstacle avoidance behaviorrobot arm. Animals Animats: Proceedings Fourth InternationalConference Simulation Adaptive Behavior (SAB-96), pp. 468{475 Cape Cod,MA.Moriarty, D. E., & Miikkulainen, R. (1998). Forming neural networks ecientadaptive co-evolution. Evolutionary Computation, 5 (4), 373{399.Potter, M. A. (1997). Design Analysis Computational Model CooperativeCoevolution. Ph.D. thesis, George Mason University.Potter, M. A., & De Jong, K. A. (1995). Evolving neural networks collaborativespecies. Proceedings 1995 Summer Computer Simulation Conference Ottawa,Canada.Potter, M. A., De Jong, K. A., & Grefenstette, J. (1995). coevolutionary approachlearning sequential decision rules. Eshelman, L. (Ed.), Proceedings SixthInternational Conference Genetic Algorithms Pittsburgh, PA.274fiEvolutionary Algorithms Reinforcement LearningRechenberg, I. (1964). Cybernetic solution path experimental problem. LibraryTranslation 1122. Royal Aircraft Establishment, Farnborough, Hants, Aug. 1965.Ring, M. B. (1994). Continual Learning Reinforcement Environments. Ph.D. thesis,University Texas Austin.Ros, J. P. (1997). Probably approximately correct (PAC) learning analysis. HandbookEvolutionary Computation, chap. B2.8. IOP Publishing Oxford University Press.Schaffer, J. D., Caruana, R. A., Eshelman, L. J., & Das, R. (1989). study controlparameters affecting online performance genetic algorithms function optimization. Proceedings Third International Conference Genetic Algorithms,pp. 51{60. Morgan Kaufmann.Schaffer, J. D., & Grefenstette, J. J. (1985). Multi-objective learning via genetic algorithms.Proceedings Ninth International Joint Conference Artificial Intelligence,pp. 593{595. Morgan Kaufmann.Schultz, A. C. (1994). Learning robot behaviors using genetic algorithms. IntelligentAutomation Soft Computing: Trends Research, Development, Applications,pp. 607{612. TSI Press, Albuquerque.Schultz, A. C., & Grefenstette, J. J. (1992). Using genetic algorithm learn behaviorsautonomous vehicles. Proceedings AiAA Guidance, Navigation, ControlConference Hilton Head, SC.Schultz, A. C., & Grefenstette, J. J. (1996). Robo-shepherd: Learning complex robotic behaviors. Robotics Manufacturing: Recent Trends Research Applications,Volume 6, pp. 763{768. ASME Press, New York.Smith, S. F. (1983). Flexible learning problem solving heuristics adaptive search.Proceedings Eighth International Joint Conference Artificial Intelligence,pp. 422{425. Morgan Kaufmann.Sutton, R. (1990). Integrated architectures learning, planning, reacting basedapproximate dynamic programming. Machine Learning: Proceedings SeventhInternational Conference, pp. 216{224.Sutton, R. S. (1988). Learning predict methods temporal differences. MachineLearning, 3, 9{44.Sutton, R. S., & Barto, A. (1998). Reinforcement Learning: Introduction. MIT Press,Cambridge, MA.Valiant, L. G. (1984). theory learnable. Communications ACM, 27, 1134{1142.Vose, M. D., & Wright, A. H. (1995). Simple genetic algorithms linear fitness. Evolutionary Computation, 2, 347{368.275fiMoriarty, Schultz, & GrefenstetteWatkins, C. J. C. H. (1989). Learning Delayed Rewards. Ph.D. thesis, UniversityCambridge, England.Watkins, C. J. C. H., & Dayan, P. (1992). Q-learning. Machine Learning, 8 (3), 279{292.Whitley, D. (1989). GENITOR algorithm selective pressure. ProceedingsThird International Conference Genetic Algorithms, pp. 116{121 San Mateo, CA.Morgan Kaufman.Whitley, D., & Kauth, J. (1988). GENITOR: different genetic algorithm. ProceedingsRocky Mountain Conference Artificial Intelligence, pp. 118{130 Denver, CO.Whitley, D., Dominic, S., Das, R., & Anderson, C. W. (1993). Genetic reinforcementlearning neurocontrol problems. Machine Learning, 13, 259{284.Wilson, S. W. (1994). ZCS: zeroth level classifier system. Evolutionary Computation,2 (1), 1{18.Yamauchi, B. M., & Beer, R. D. (1993). Sequential behavior learning evolveddynamical neural networks. Adaptive Behavior, 2, 219{246.Zhou, H. (1990). CSM: computational model cumulative learning. Machine Learning,5 (4), 383{406.276fiJournal Artificial Intelligence Research 11 (1999) 429{435Submitted 6/99; published 12/99Technical AddendumCox's Theorem RevisitedJoseph Y. HalpernCornell University, Computer Science DepartmentIthaca, NY 14853http://www.cs.cornell.edu/home/halpernhalpern@cs.cornell.eduAbstractassumptions needed prove Cox's Theorem discussed examined. Varioussets assumptions Cox-style theorem proved provided, althoughrather strong and, arguably, natural.recently wrote paper (Halpern, 1999) casting doubt compelling justificationprobability provided Cox's celebrated theorem (Cox, 1946). received (whatseems me, least) surprising amount response article. attemptclarify degree think Cox's theorem salvaged respond glaringinaccuracy part pointed Snow (1998). (Fortunately, inaccuracyaffect either correctness interpretation results paper.)tried write note enough detail read independentlyearlier paper, encourage reader consult earlier paper well twomajor sources based (Cox, 1946; Paris, 1994), details discussion.basic situation. Cox's goal \try show . . . possible deriverules probability two quite primitive notions independent notionensemble . . . appeal rather immediately common sense" (Cox, 1946).end, starts function Bel associates real number pair (U; V )subsets domain W U 6= ;. write Bel(V jU ) rather Bel(U; V ), sincethink Bel(V jU ) belief, credibility, likelihood V given U . Cox's Theoreminformally understood, states Bel satisfies two reasonable restrictions,Bel must isomorphic probability measure. first one says belief Vcomplement (denoted V ) given U function belief V given U ; second saysbelief V \ V 0 given U function belief V 0 given V \ U beliefV given U . Formally, assume functions : IR ! IR F : IR2 ! IRA1. Bel(V jU ) = (Bel(V jU )) U 6= ;, U; V W .A2. Bel(V \ V 0 jU ) = F (Bel(V 0 jV \ U ); Bel(V jU )) V \ U 6= ;, U; V; V 0 W .Bel probability measure, take (x) = 1 , x F (x; ) = xy .going on, notice Cox's result claim Bel probability measure,isomorphic probability measure. Formally, meanscontinuous one-to-one onto function g : IR ! IR g Bel probability measureW ,g (Bel(V jU )) g (Bel(U )) = g (Bel(V \ U )) U 6= ;,(1)c 1999 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiHalpernBel(U ) abbreviation Bel(U jW ).willing accept belief real valued (this strong assumption since,among things, commits us assumption beliefs cannot incomparable|two events U V , must either Bel(U ) Bel(V ) Bel(V ) Bel(U )),A1 A2 reasonable. took prove Cox's Theorem,indeed would compelling argument use probability.Unfortunately, well known A1 A2 suce proveCox's Theorem. Dubois Prade (1990) give example function Bel, definedfinite domain, satisfies A1 A2 F (x; ) = min(x; ) (x) = 1 , xisomorphic probability measure. Thus, prove Cox's Theorem, needadditional assumptions.hard dig Cox's papers (1946, 1978) exactly additional assumptionsproofs need. show paper result false quite strongassumptions (see below). result also suggests proofs givenCox-style theorems best incomplete (that is, require additional assumptionsbeyond stated authors); see previous paper discussion. goalnote clarify takes prove Cox-style theorem, giving numberhypotheses result proved. positive versions theoremstate proved straightforward way adapting proof given Paris(1994). (This one correct, rigorous proof result aware,hypotheses stated clearly.) Nevertheless, believe worth identifyingvariants, since philosophically quite different.Paris (1994) proves Cox's Theorem following additional assumptions:Par1. range Bel [0; 1].Par2. Bel(;jU ) = 0 Bel(U jU ) = 1 U 6= ;.Par3. A1 decreasing.Par4. F A2 strictly increasing (in coordinate) (0; 1]2 continuous.Par5. 0 ff; fi; 1 > 0, sets U1 U2 U3 U4 U3 6= ;,jBel(U4jU3 ) , ffj, jBel(U3jU2 ) , fi j, jBel(U2jU1) , j less .Theorem 1: (Paris, 1994) Par1-5 hold, Bel isomorphic probability measure.nothing special 0 1 Par1 Par2; need assumeinterval [e; E ] e < E Bel(V jU ) 2 [e; E ] V; U W ,Bel(;jU ) = e, Bel(U jU ) = E . assumptions certainly seem reasonable, providedaccept beliefs linearly ordered. hard hard justify Par3Par4 (indeed, Cox justifies original paper). problematic assumptionPar5 (called A4 earlier paper Co5 Paris (1994)). Par5 thoughtdensity requirement; among things, says fixed V , setvalues Bel(U jV ) takes dense [0; 1]. follows that, particular, satisfyPar5, W must infinite; Par5 cannot satisfied finite domains. \natural"\reasonable" are, course, eye beholder, strike natural430fiCox's Theorem Revisitedreasonable assumption obvious sense words. particularly true sincemany domains interest AI (and application areas) finite; version Cox'sTheorem uses Par5 simply applicable domains. weaken Par5?Cox require anything like Par5 paper. require various timesF twice differentiable, continuous second derivative, twicedifferentiable.1 differentiability assumptions perhaps compelling continuity assumptions, seem like reasonable technical restrictions. Unfortunately,counterexample give earlier paper shows assumptions suceprove Cox's theorem. show following.Theorem 2: (Halpern, 1999) function Bel0, finite domain W , functionsF satisfying A1 A2, respectively,Bel0(V jU ) 2 [0; 1] U 6= ;,(x) = 1 , x (so strictly decreasing infinitely differentiable),F infinitely differentiable, nondecreasing argument [0; 1]2, strictly increasing argument (0; 1]2. Moreover, F commutative, F (x; 0) = F (0; x) =0, F (x; 1) = F (1; x) = x.However, Bel0 isomorphic probability measure.understand makes counterexample tick role Par5, usefulreview part Cox's argument. course proof, Cox shows A2 forces Fassociative function, is,F (x; F (y; z )) = F (F (x; ); z ):(2)Cox's argument.Suppose U1 U2 U3 U4 . Let x = Bel(U4jU3), = Bel(U3jU2), z = Bel(U2jU1 ),u1 = Bel(U4 jU2), u2 = Bel(U3 jU1), u3 = Bel(U4 jU1). A2, u1 = F (x; ),u2 = F (y; z ), u3 = F (x; u2) = F (u1 ; z ). follows F (x; F (y; z )) = F (F (x; ); z ).Note argument show F (x; F (y; z )) = F (F (x; ); z ) x; y; z .shows equality holds x; y; z exist U1 U2 U3U4 x = Bel(U1 jU2), = Bel(U2jU3 ), z = Bel(U3jU4). Par5 guaranteesset x; y; z dense [0; 1]3. Combined continuity F assumedPar4, tells us (2) holds x; y; z .claimed earlier paper none authors proved variantsCox's Theorem, including Cox himself, Aczel, Reichenbach, seemed awareneed make (2) hold x; y; z .2 wrong including Cox list. (Thisglaring inaccuracy referred above.) Snow (1998) points out, Cox actuallyrealize F must satisfy (2) x; y; z , explicitly makes assumption1. Cox never collects assumptions one place, somewhat dicult tell exactlythinks needs proof. later.2. pointed earlier paper, Aczel recognized problem later work (Aczel & Daroczy,1975).431fiHalperncertain point first paper (Cox, 1946), although make assumptionexplicitly (more informal) later paper (Cox, 1978).Unfortunately, although Cox escapes criticism recognizing need makeassumption, make theorem less palatable. Indeed, anything,makes matters worse. Associativity rather strong assumption, Cox shows.fact, Cox shows F associative continuous second derivatives,F isomorphic multiplication, is, exists function f constant CCf [F (x; )] = f (x)f (y ). Let stress conclusion F isomorphicmultiplication follows fact associative continuous secondderivatives, nothing A2. course, time willing assumefunction F isomorphic multiplication satisfies A2,well way showing Bel isomorphic probability measure. futurereference, remark Paris shows (in Lemma 3.7) Par1, Par2, Par4, Par5suce show F isomorphic multiplication (and take C = 1).case, suppose willing strengthen Par4 require F associativewell continuous strictly increasing. suce get rid Par5 altogether?Unfortunately, seem to.Later argument, Cox shows must satisfy following two functionalequations sets U1 U2 U3 :[S (Bel(U2jU1 ))] = Bel(U2 jU1)(3)Bel(U2 jU1) (Bel(U3 jU1)=Bel(U2jU1)) = [S (Bel(U2jU1))=S (Bel(U3jU1 ))]S (Bel(U3jU1 ))(4)means x > 0 exist sets U1, U2 , U3x = Bel(U3jU1) = Bel(U2 jU1),(S (y )) =(5)yS (x=y ) = (x)S [S (y )=S (x)]:(6)Cox actually wants equations hold x . Paris shows followsPar1{5. (Here Paris's argument. Using Par3, shown continuous (see(Paris, 1994, Lemma 3.8)). combined Par5 easily gives us (5) holds2 [0; 1]. (6) follows Par5 fact F must isomorphic multiplication;mentioned above, latter fact shown Paris follow Par1, Par2, Par4,Par5.) Without Par5, need assume (5) (6) hold x ,Cox does.3proof given Paris Theorem 1, use made Par5 derivingassociativity F fact satisfies (5) (6). Thus, immediately getfollowing variant Cox's Theorem.3. Actually, Cox starts (4) derives symmetric functional equation yS [S (x)=y] =xS [S (y)=x], rather (6). latter functional equation assumes holds x y.replace x (x) everywhere use (5), get (6).432fiCox's Theorem RevisitedTheorem 3: Par1-4 hold and, addition, F A2 associative A1satisfies (5) (6) x; 2 [0; 1], Bel isomorphic probability measure.stress A1 A2 place constraints F act rangeBel (that is, elements x form Bel(U ) subset U W ), associativity,(5), (6) place constraints global behavior F , is, Fact even arguments range Bel. example give earlier paperviewed giving Bel possible find F satisfying A1 A2,F satisfying A2 associative [0; 1].get variant even closer Cox (1946) shows replacing Par4assumption F twice differentiable. Note need make continuity,monotonicity, differentiability assumptions F . mentioned earlier, DuboisPrade show Bel isomorphic probability function (x) =1 , x F (x; ) = min(x; ). min function differentiable (and fortiori continuous),twice differentiable, strictly increasing coordinate (0; 1]2(although nondecreasing).advantage replacing Par5 requirement F associativesatisfy (5) (6) variant Cox's Theorem applies even W finite.hand, hard (at least me) view (6) \natural" requirement.assumptions like associativity F idempotency (i.e., (5)) certainly naturalmathematical assumptions, justification requiring [0; 1] seemsprovably follow assumptions certain tuples rangeBel. reasonable compelling? course, reader judge.case, assumptions needed highlighted anyone using Cox's Theoremjustification probability, rather swept carpet. requirementmust satisfy (6) even mentioned Snow (1998), let alone discussed. Snowalone; seem mentioned discussion Cox's results either(other Paris). course, avoid mentioning (5) (6) requiring(x) = 1 , x (as Cox (1978) does). However, makes result less compelling.number variants Cox's Theorem correct discussed (Halpern,1999, Section 5). Let conclude formalizing two apply finite domains,use Par5 (or slight variants it), rather assuming F must associativemust satisfy (5) (6) pairs x; 2 [0; 1].first essentially assumes extend finite domain infinite domainadding suciently many \irrelevant" propositions, tosses fair coin.observed earlier paper, type extendability argument fairly standard.example, made Savage (1954) course justifying one axiomspreference. Snow (1998) essentially uses well. Formally, gives us followingvariant Cox's Theorem, whose proof trivial variant Theorem 1.Theorem 4: Given function Bel domain W , suppose exists domain W + Wfunction Bel+ extending Bel defined subsets W + A1 A2 holdBel+ subsets U; V; V 0 W + Par1-5 hold Bel+ . Bel+ (and henceBel) isomorphic probability measure.433fiHalpernproblem approach requires us extend Bel events neverinterested considering first place, way guaranteedcontinue satisfy Par1-5.second variant assumes Bel defined one domain W ,domains (or least, large family domains); functions Funiform across domains. precisely, would get following.Theorem 5: Suppose function Bel defined domains W set Wdomains, exist functions F F satisfy A1 A2domains W 2 W , Par1{4 hold F , following variant Par5 holds:Par50 . 0 ff; fi; 1 > 0, exists W 2 W sets U1 ; U2; U3; U4 WU1 U2 U3 U4 , U3 6= ;, jBel(U4 jU3) , ffj, jBel(U3jU2 ) , fi j,jBel(U2jU1 ) , j less .Bel uniformly isomorphic probability measure, exists functiong : IR ! IR W 2 W , g Bel probability measureW U; V W ,g (Bel(V jU )) g (Bel(U )) = g (Bel(V\ U )) U 6= ;.advantage formulation W consist finite domains; neverventure infinite (although W would include infinitely manyfinite domains). conception one function Bel defined uniformly familydomains seems consistent philosophy Cox Jaynes (see, particular,(Jaynes, 1996)).hypotheses Theorems 4 5 may seem reasonable others(at least, readers!), note still essentially require Par5 and, likevariants Cox's Theorem aware of, disallow notion belieffinitely many gradations. One justify notion belief takes values[0; 1] continuity considerations (again, assuming one accepts linearly-orderednotion belief), still nontrivial requirement.4stop point leave reader form beliefs.AcknowledgmentsI'd like thank Paul Snow useful email exchanges topic (and pointingCox fact realized need assume F associative (x; y; z )).work supported part NSF, grant IRI-96-25901.4. Snow (1998) quotes conference version (Halpern, 1999) (which appeared AAAI '96, pp. 1313{1319) saying `Cox's Theorem \disallows notion belief takes finitely many countablymany gradations",' say disallows notion belief Cox's Theorem, viewpointassumed Bel varies continuously 0 1. fact, Co5 compatible notionbelief takes countably many (although finitely many) values. (Essentially sentenceappears journal version paper, refer Cox's Theorem, without phrase\or countably".)434fiCox's Theorem RevisitedReferencesAczel, J., & Daroczy, Z. (1975). Measures Information Characterizations.Academic Press, New York.Cox, R. (1946). Probability, frequency, reasonable expectation. American JournalPhysics, 14 (1), 1{13.Cox, R. (1978). inference inquiry: essay inductive logic. Levine, R. D.,& Tribus, M. (Eds.), Maximum Entropy Formalism, pp. 119{167. MIT Press,Cambridge, Mass.Dubois, D., & Prade, H. (1990). logical view conditioning applicationpossibility evidence theories. International Journal Approximate Reasoning,4 (1), 23{46.Halpern, J. Y. (1999). counterexample theorems Cox Fine. Journal A.I.Research, 10, 76{85.Jaynes, E. T. (1996). Probability Theory|The Logic Science. Unpublished; availablehttp://bayes.wustl.edu.Paris, J. B. (1994). Uncertain Reasoner's Companion. Cambridge University Press,Cambridge, U.K.Savage, L. J. (1954). Foundations Statistics. John Wiley & Sons, New York.Snow, P. (1998). correctness reasonableness Cox's Theorem finite domains.Computational Intelligence, 14 (3), 452{459.435fiJournal Artificial Intelligence Research 11 (1999) 301-333Submitted 3/99; published 10/99Decentralized Markets versus Central Control:Comparative StudyFredrik Yggeygge@enersearch.seEnerSearch AB Uppsala UniversityChalmers Science ParkS-412 88 Gothenburg, Swedenwww.enersearch.se/yggeHans AkkermansHansAkkermans@cs.vu.nlAKMC Free University AmsterdamDepartment Information Management Software EngineeringComputer Science DivisionDe Boelelaan 1081a, NL-1081 HV Amsterdam, NetherlandsAbstractMulti-Agent Systems (MAS) promise offer solutions problems established,older paradigms fall short. order validate claims repeatedly madesoftware agent publications, empirical in-depth studies advantages weaknessesmulti-agent solutions versus conventional ones practical applications needed. Climatecontrol large buildings one application area multi-agent systems, marketoriented programming particular, reported successful, althoughcentral control solutions still standard practice. therefore constructedimplemented variety market designs problem, well different standardcontrol engineering solutions. article gives detailed analysis comparison,learn differences standard versus agent approaches, yielding newinsights benefits limitations computational markets. important outcomelocal information plus market communication produces global control.1. Introductionnew paradigms arise scientific horizon, must prove value comparison competition existing, established ones. multi-agent systems(MAS) paradigm exception. recent book software agents (Bradshaw, 1997),Norman observes perhaps relevant predecessors todays intelligent agentsservomechanisms control devices. indeed, number applicationsmulti-agent systems recently claimed success, close realmtraditionally called control engineering. One clear example climate control largebuildings many office rooms. Here, Huberman & Clearwater (1994, 1995) constructed tested working MAS solution based market approach, reportedoutperform existing conventional control.key question studied article is: respect extentmulti-agent solutions better (conventional) alternatives? believec1999AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiYgge & Akkermansabove-mentioned application provides nice opportunity study question detailed empirical way. practically relevant, lends alternative solutions,quite prototypical wide range industrial applications distributed resource allocation (including energy management applications (Ygge & Akkermans, 1996;Akkermans & Ygge, 1997; Ygge & Akkermans, 1998), telecoms applications, file allocation problem Kurose Simha (1989), flow problems investigated Wellman(1993)).article gives detailed analysis published MAS solution building climatecontrol, compares multi-agent markets traditional control approaches. alsointroduce improved novel multi-agent solution problem based equilibrium market. comparative analysis able draw general conclusionssuitability various approaches. Briefly, show computational marketsdesigned perform well centralized controllers global informationtotal system. However, major advantage market framework achievesfully decentralized fashion using locally available data. finally outlinepossible come general theory concerning connectionsmarkets conventional control concepts. Here, show considered typeapplications quasi-equation local data + market communication = global controlholds.structure article follows. introduction (Section 2) marketoriented programming available theory, Section 3 gives problem definition. Section 4introduces application domain: describes office environment gives physical model cooling power various temperature outside weather influences.discuss results standard control engineering solution, based localindependent integral controllers regulating building climate (Section 5). Next, review market-based approach put forward Huberman & Clearwater (1994, 1995)(Section 6), validate claim market approach performs better conventional independent controllers. subsequently analyze market protocol detailshow success related fact agents possess global informationauction started (Section 7). Section 8 develop improved standard control engineering scheme also exploits global data. control scheme turnsperform much better Huberman-Clearwater market. Finally, proposemarket design based general equilibrium theory. performs wellcontroller access global data, operates local data thus representsreally decentralized solution (Section 9). Section 10 puts results perspectivesummarizes general conclusions comparing different approaches.2. Market-oriented Programminguse market mechanisms resource allocation computer systems ratherlong history computer science, e.g. (Sutherland, 1968), recently marketsused number different application areas.302fiDecentralized Market Controlrather extensive theory available relations optimizationmarkets. example:Jennergren (1973) shown price schedule decomposition algorithmused solving linear programming problems.Kurose & Simha (1989) showed equilibrium constitutes optimal solutionfile allocation problem. similar result shown Bertsekas (1992)assignment problem.Bikhchandani & Mamer (1997) showed Pareto efficient outcome1 maximizessum utilities exchange market agents holding quasi-linear utilityfunctions2 significant extension above, also applies non-linearproblems.3results Bikhchandani Mamer extended markets include production uncertainty Ygge (1998, Chapter 3). relationstypes markets traditional optimization problems also made explicitlatter work.Markets approaches applied number different computerized applications, briefly discussed here. Already 1968 Sutherland proposedauction mechanism allocation computational resources PDP-1 computer (Sutherland, 1968). Different amounts money assigned different users accordanceimportance projects. reported users time learnbid properly computational resources. basic approach refinedby, example, Gagliano et al. (Gagliano et al., 1995).Kurose & Simha (1989) investigate file allocation problem. work agentsreport marginal utility (for certain amount storage) derivativeauctioneer, reallocates resource using resource-oriented Newton-Raphsonalgorithm (cf. Ygge & Akkermans, 1998) equilibrium reachedmarginal utilities agents same. Although paper based numbermicroeconomic abstractions, example utilize prices trade-offdifferent commodities. So, debatable whether approach referredreally market-based.4assigning problem allocating n objects n users investigated Bertsekas (1992). user valuation object, cannot assignedone object. reported user seen economic agent, shownauction (which essentially English auction) results equilibrium.1. allocation Pareto efficient Pareto optimal alternative allocation makesagent better without making outcome worse agent (Varian, 1996, p. 15).2. example quasi-linear utility function given Eq. (19).3. However, one remember theory provide computational advantages.hard find allocation maximizes sum utilities, also hard find Paretooptimal one (as case).4. One also note formulation Newton-Raphson scheme approach overlysimplistic, much better standard methods available (Press et al., 1994; Ygge & Akkermans,1998).303fiYgge & AkkermansTrading AgentAuctioneerInitiate Auction HHSupply = Demand?HHj Express demand1XXXXXYesz Register implementXFigure 1: High-level view equilibrium market mechanism.assumed agent behavior agent bids v w highly valued object (i.e.object highest difference, v, valuation price). wdifference valuation price second preferred object.however motivation given assumed agent behavior, clearagent would use strategy unless externally imposed. Thougheconomical interpretation prices, approach market-like duerather unrealistic assumptions agent behavior.equilibria applications Kurose Simha, Bertsekas provenoptimal. hard see problem Kurose Simha reformulatedproper market quasi-linear utility functions, competitive equilibrium equivalent equilibrium described Kurose Simha, cf. (Ygge, 1998,Corollary 3.3.1). Similarly, price vector obtained Bertsekas clearly constitutescompetitive equilibrium. time, shown Ygge (Ygge, 1998, Theorem 3.2),separable optimization problems formulated market terms (competitive) general equilibrium (if existing) identical optimal solution originaloptimization problem. Consequently, recent theory generalizes earlier theoryexample Kurose Simha, Bertsekas.Wellman et al. contributed significantly developing market-based approachesresource allocation programming paradigm, given name marketoriented programming, e.g. (Wellman, 1993; Mullen & Wellman, 1995; Wellman, 1995, 1996;Yamaki, Wellman, & Ishida, 1996; Hu & Wellman, 1996; Cheng & Wellman, 1998; Wellman& Hu, 1998; Walsh, Wellman, Wurman, & MacKie-Mason, 1998). Particularly, microeconomic framework general equilibrium theory successfully used resourceallocation mechanism. market call equilibrium market agents senddemand functions telling much like consume produce different prices.auctioneer tries establish equilibrium price vector supply meetsdemand commodities, cf. Figure 1.process submitting parts demand function may iterated equilibriumprice outside region captured submitted demand functions. One processbasic price tatonnement process, cf. e.g. (Cheng & Wellman, 1998), demandfunctions respective commodities sent auctioneer. demandsbased expected prices commodities. is, prices change, setnew demand functions may need submitted. auctioneer establishedequilibrium price, agents exchange resources stated bid304fiDecentralized Market Controlequilibrium price. (For example, agent states wants buy 1/p unitscommoditywhere p price commodity moneyand equilibrium pricebecomes 1, agent buy one unit resource one unit money.)Equilibrium markets many attractive theoretical properties. example,agents act competitively5 , outcome Pareto efficient. Furthermore, utility functions quasi-linear, outcome globally optimal (Ygge, 1998, Theorem 3.2),presence uncertainty, outcome maximizes expected global utility (Ygge,1998, Theorem 3.5). note equilibrium markets computationally implementedcomputationally efficient manner (Ygge, 1998, Chapter 4).Wellman et al. applied equilibrium markets number applications,multi-commodity flow problems, design problems, bandwidth allocation problems.also introduced market-based approach scheduling many similarities assignment problem Bertsekas described above, relies realisticassumptions agent behavior.present authors introduced market-oriented approach power load management (Ygge & Akkermans, 1996; Ygge, 1998; Ygge et al., 1999).note aim market-oriented programming computer science fundamentally different aim economic theory. visualized Figure 2.market-oriented programming, microeconomic theory taken given servestheory implementation computational agents. Whether microeconomictheory actually reflects human behavior critical issue. important questioninstead microeconomic theory utilized implementation successfulresource allocation mechanisms computer systems. example, even though (orleast few) people believe humans use explicit utility functions makingdecisions, functions appear useful concisely represent human preferencesuse computational agents.obviously interesting investigate use computational markets automating trades different self-interested parties, information privaterevealed expected gain so. However, use marketsalso proposed standard resource allocation true utility/costs nodesconsume produce resource assumed available (though possibly uncertainand/or distributed system). main arguments found literature applyingmarket types problems are:numerous similarities economic systems distributed computer systems suggest models methods previously developed within field mathematical economics serve blueprints engineering similar mechanismsdistributed computer systems (Kurose & Simha, 1989).Auction algorithms highly intuitive easy understand; explainedterms economic competition concepts, couched everyday experience (Bertsekas, 1992).5. agent acts competitively treats prices exogenous, is, impact prices duebehavior negligible (Varian, 1996, p. 516). reasonable assumption marketleast moderate size and/or uncertainty behavior agents (Sandholm& Ygge, 1997).305fiYgge & AkkermansMicro-economic theoryStudyGenerateComputerscientistEconomistStudyGenerateReal WorldHuman agentshuman marketsComputational agentscomputational marketsFigure 2: simplified view relation economics computer science respectmicroeconomic theory. Economists study humans generate theory usedexplanation human economic behavior. Computer scientists marketoriented programming use theory basis building working computational marketsystems.Market approaches enable natural decomposition, software engineeringperspective well computational perspective (Schreiber et al., 1999; Ygge,1998, Chapter 15).Market approaches flexible allow ongoing addition deletion agents. global changes requiredmerely demand/supply relationaltered (Ygge, 1998, Chapter 15).Markets informationally efficient terms information dimensionality (Jordan,1982), abstractions used natural ones user (Ygge, 1998,Chapter 15).introduction trading resources sort money enables evaluationlocal performance valuation resources, becomes apparent resources valuable agents using (Ygge,1998, Chapter 15).arguments mainly conceptual related software/system designengineering issues, must prove value acceptance software systemdesigners. also different respects stronger claims. example, Huberman Clearwater state (Huberman & Clearwater, 1995) applicationbuilding control that: principle omniscient central controller accessenvironmental thermal parameters building (i.e. perfect model) could306fiDecentralized Market Controloptimally control it, practice knowledge seldom available system. Instead,partial information local changes variables (such instantaneous office occupancy, external temperature, computer use) reliable source usedcontrolling building. alternative omniscient controller HubermanClearwater propose market-based multi-agent approach problem. raisesinteresting question: applications information structuremarket-based approaches better traditional approaches? papercarefully examine issue building climate control problem. investigate information different alternatives (traditional new market-based) require,performance different approaches are. use exactlyproblem formulation Huberman Clearwater order reproduce resultsevaluate new approaches original formulation. problem formulationgiven next section.3. Problem Definitiontask allocate resource (cold air) office building, given setpoint temperatures respective offices. measure success allocation, standarddeviation deviation setpoint used (Huberman & Clearwater, 1995), i.e.vuNu1 XsetpStdDev(Ti)=t[(Tio Tosetp ) (hTi hT setp i)]2 ,N(1)o=1hi denotes average value variable, Tio actual temperature office,Tosetp setpoint temperature. index denotes time interval observationindex denotes office observation. naming convention usedthroughout article. (In addition index k also used denote time periods.)may debated whether best measure, stickarticle order evaluate approach taken Huberman Clearwater usingmeasure.4. Office Environmentcase study consider comparison decentralized markets versus centralcontrol solutions building climate control large office environment.section, present mathematical-physical model office environment.first give conceptual summary possible understand basic ideasmodel without studying equations. offices attached piperesource (cold air) transported Figure 3. characteristics system similarcharacteristics district heating system, offices instead households.assume 100 offices total, equally distributed towardsEast, South, West, North.thermodynamics office environment actually quite simple. Every officeseen storage place heat, heat may dissipate environment. model,thermodynamic behavior office equivalent basic electrical RC-circuit. Here,307fiYgge & AkkermansNoon sunMorning sunAfternoon sunAirAirFigure 3: Offices air transportation.voltage analogous temperature, electrical current analogous heat flow. CR respectively denote heat capacitance thermal resistance.good general reference thermodynamic models one use bookIncropera & Witt (1990). heat equations continuous time, discretizedaccording standard procedures control engineering, cf. (Ogata, 1990). ontology reusability aspects involved thermodynamics model construction discussedextensively Borst, Akkermans, & Top (1997).4.1 Thermodynamic Propertiesresource treated cooling power. office make use fraction, ,available resource office, Pioavail ,Piocons Pioavail ,(2)Piocons consumed power. available resource one office equalavailable resource previous office minus consumed resource previous office.Throughout article assume 0.5.treat everything discrete time. time interval use calculationsone minute. offices temperature, Tio , obtained integrating differentialequation discretized form:Tio = T0,o +Xheatcons(PkoPko)/Co ,(3)k=1heatPkoheating power Co thermal capacitance. heating powerdescribedPioheat = (Tiovirt Tio )/Ro ,(4)308fiDecentralized Market ControlRo thermal resistance Tiovirt virtual outdoor temperature, describeddetail below.Eqs. (3) (4) see feedback loop office temperatureheating power. Solving temperature obtainTio =11+1Ro CoTi1,o +virtTioRoPioconsCo, > 0.(5)equation dynamics system directly computed.right-hand side known quantities, Co Ro externally given buildingparameters, Piocons output utilized controller (as described detail laterarticle various different controllers), Tiovirt obtained weather modelbelow.4.2 Weather Modelexternal weather influences office environment modeled virtual temperature, representing outdoor temperature, sun radiation, etc. assumesunshine every day outdoor temperature, outd , varies 22 35 Caccording2Tioutd = 22 + 13 e((is4) mod 2412) /20 ,(6)length time interval expressed hours, = 1/60.virtual temperature, Tiovirt , describedTiovirt = Tioutd + Tosun + Tiof luct,(7)f luct random disturbance, thought represent small fluctuations causedexample wind. f luct Gaussian distributed zero mean standard deviationequal unity. sun sun radiation component. offices located Eastside sun described2 /5Tisun,East = 8 e((is+4) mod 2412),(8)correspondingly South West offices2 /5Tisun,South = 15 e(is mod 2412),2 /5Tisun,W est = 8 e((is4) mod 2412)(9).(10)various temperatures plotted Figure 4.4.3 Office Temperatures without ControlFigure 5, temperature South-oriented office plotted different thermalresistances, Ro , thermal capacitances, Co . simplicity assume Ro equalCo equal. figure observe two things: first, higher Ro Co309fiYgge & Akkermans35Time day, hTime day, h242118159126024211815-524211815912630900504030201003512561031510020Temperature C1525Temperature CTemeprature C30Time day, hFigure 4: plot left shows outdoor temperature, Tioutd. middle plot shows sunradiation components, sun , (with peaks time 8, 12, 16 hours offices locatedEast, South, West sides, respectively). Finally, outdoor temperature plussun radiation components plotted right.45Temeperature C40R=0 C=035R= 10, C= 10,30R=10 C= 20 R=20C=1025R=20 C=2020222018161412108642015Time day, hFigure 5: indoor temperature uncontrolled office plotted different valuesthermal resistance heat capacitance. Small values thermal resistancecapacitance give higher peaks, higher values give smoother curves.bigger lag temperature changes, second, higher Ro Co smallerfluctuations temperature. simulation experiments article took Ro = 10Co = 10. Ro Co equal zero implies Tio = Tiovirt , seenletting Ro Co approach zero Eq. (5). Clearly, without control office temperaturesstrongly fluctuate reach unacceptably high values cases.310fiDecentralized Market Control5. Control-A: Conventional Independent Controllers5.1 Integral Control Officesapplication regulating office temperature long tradition control theory.widely known controllers different variants PID controller. letters PIDdenote control signal proportional (P) error (that is, differencesetpoint actual value); proportional integral (I) error;proportional derivative (D) error. Here, use variant integratingcontroller6 formFio = Fi1,o + (Tio Tosetp ),(11)F output signal controller, so-called gain parameter (thatset externally design controller). simulations assumedFio limited value zero three. order modelvalves closed cooling resources delivered one room another(the lower bound), maximum amount resourcesobtained opening valve fully (the upper bound). control signal Fio sentactuator actual Piocons obtained(Piocons=Fio ,Fio Pioavail.availPio , Fio > Pioavail(12)Plots office temperatures different gains shown Figure 6. gaincontroller critical application. high gain result controlleroverreacting temperature exceeds setpoint,setpoint quite time. leads larger error smaller adjustmentsmade. Also, amplitude control signal gets unnecessarily high, systemget dangerously unstable. note maximum deviation 0.06 C.Thus, controllers using three gains perform well. calculationsarticle gain equal 10 adopted.5.2 Implications Limited Resourcesfar, assumed total amount available resources unlimited. Now,suppose maximum value cooling power insertedsystem. situation, offices situated close air input obtainsufficient amount cool air, near end suffer totally uncoordinatedcontrollers used. Thus, smaller total amount available resources, largerstandard deviation be. visualized Figure 7. reasonable figurechosen upper limit total resource amount 140.conclude, shown example, independent integrating controllers performwell amount cooling resources unlimited. hand,6. main reason choosing integrating controller want setting closepossible setting described Huberman Clearwater (1995). controllersapplication may well considered, long performance good shown Figure 6,crucial central argument article.311fiYgge & Akkermans20,06Temperature, C20,0420,02Gain = 100Gain = 1020Gain = 119,9819,9619,9411121Minutes observed intervalFigure 6: indoor temperature office, utilizing integral controller, plotted differentcontroller gains. setpoint temperature 20 C.6Standard deviation5432124232221201918171615141312119108765432100Time day, hFigure 7: standard deviation (in C) , defined Eq. (1) interval, i, plotteddifferent amounts available cold air resources (130, 140, 150, 160) 100offices. lower amount available resources, higher standard deviation.312fiDecentralized Market Controlshortage available resources, standard deviation increases dramatically, yieldingpoor performance.6. Market-A: Approach Huberman Clearwatermulti-agent systems solution problem building control presentedHuberman Clearwater (1994, 1995). approach taken model resourceallocation problem building environment computational market agentsbuy sell cooling power resources. non-separability terms agents ignored.7basic idea every office represented agent responsiblemaking good use resources, end trades resources agents.agents send bids auctioneer, calculates clearing price, makes sureagent buy price higher bid sell price lowerbid.section give market protocol proposed Huberman Clearwater,reproduce results. order make paper self-contained, interested readerfind original equations underlying Huberman-Clearwater market protocolAppendix A.6.1 Market protocolbid constructed following tuple:bid = [sellio , vio , Bio ],(13)sell boolean variable indicating whether current bid sell bid (true)buy bid (f alse), v volume traded for, B price agent demands (sellbid) prepared pay (buy bid).variables Eq. (13) function variables accordingsellio = sellio (Tio , Tosetp , hTi i, hTosetp i),vio = vio (Ti , Tsetp , ),Bio = Bio (Tio , Tosetp , hTi i, hTosetp i, mio ),(14)setpTi = [Ti1 , Ti2 , . . . , Ti100 ], Tsetp = [T1setp , T2setp , . . . , T100], strength parameterauction, mio called money parameter. trade volume directly proportionaland, hence, doubling doubles traded volume auction. Thus, freeparameter externally set tune trade volumes proper levels.money parameter correspond real currency; merely control variable,varying 100 200, direct connection to, example,value cooling resource. money cannot saved auction rounds7. resource allocation problem separable total utility system system expressedsum utilities node (producer/consumer), constraints muchresource assigned node restricted sum must exceed totalavailable resource (Ibaraki & Katoh, 1988). Hence, problem treated paper separableconstraints resource distributed. example, assign sufficientlymuch penultimate agent, ultimate significant amount resource available.313fiYgge & AkkermansHuberman-Clearwater protocol, another indication simply functionsadjustment parameter protocol.auction consists following three phases:1. agents send bids, [sellio (Tio , Tosetp , hTi i, hTosetp i,Bio (Tio , Tosetp , hTi i, hTosetp i, mio )], auctioneer.vio (Ti , Tsetp , ),2. auctioneer computes market clearing price searching followingminimum:fifififiXXfififimin fiviovio fifi .pi fifio|sell=true,Bio pio|sell=f alse,Bio pi(15)yields price supply matches demand closely possible.3. Finally, resources allocated dictated bids obtainedmarket price, according rule: sellers offering vio price, Bio ,lower equal market price sell vio ; correspondinglybuyers.8example computation equilibrium price, assume auctioneerreceived following bids [true, 2, 4], [true, 1, 3], [true, 2, 2], [f alse, 1, 3], [f alse, 2, 2],[f alse, 2, 1]. market clearing price 3, leading acceptance bid 2, 3, 4, 5.(Bid 1 high sell price bid 6 low buy price.)6.2 SimulationsFigure 8 shows two plots simulation period 3 p.m. 7 p.m.9initial temperatures offices set 20 C. upper plot standard deviation independent integrating controllers used, lower one showsagent-based control scheme defined above. found adjustment parameter(see Eq. (23)) value 64 led smallest overall standard deviation. key observation figure agent approach offers least one order magnitudeimprovement.Compared independent conventional controllers indeed major advance,central claim made Huberman Clearwater. market approach givenleads reduced control error thus increased comfort compared standard controllers. simulations thus reproduce validate results Huberman &Clearwater (1994, 1995).8. Since bids given using discrete volumes, supply seldomly match demand exactlyclearing price. Normally, small excess demand supply. excess supply,buyers willing pay clearing price buy, sellers willingaccept least clearing price sell. situation, seller selected randomlyvalid candidates deliver fraction bid. corresponding procedure usedsmall excess demand.9. solutions discussed article implemented simulated authors usingC++ PC running Windows95. Furthermore, simulations independently recreatedverified Bengt Johannesson various relevant papers (Ygge & Akkermans, 1997; Huberman &Clearwater, 1995; Clearwater & Huberman, 1994)), part masters thesis project, using PythonPC running Linux.314fiDecentralized Market Control4,54Standard deviation3,532,52Control-A1,5Market-A10,519181716150Time day, hFigure 8: Standard deviation independent controllers (top) agent-based control (bottom).However, cannot last word successful system study. first questionraised whether find detail actual reason successmarket-based approach. second relevant question whetheralternative, market-based and/or central control-based, solutions building controlproblem even better. answer questions yes, setdemonstrate now.7. Market-A0: Suite Variationssection present suite variations scheme presented Section 6.main aim understand many factors involved actually responsiblegood performance Huberman-Clearwater market approach.7.1 Deleting Money Dependencyfirst simplification remove adjustment parameter called money. donesetting mio high value, C, regardless resource allocation.10 simplifiedmarket protocol is:1. agents send bids, [sellio (Tio , Tosetp , hTi i, hTosetp i,Bio (Tio , Tosetp , hTi i, hTosetp i, mio = C)], auctioneer.vio (Ti , Tsetp , ),2. auctioneer computes market pricefifififiXXfifimin fifiviovio fifi .pi fifio|sell=true,Bio pio|sell=f alse,Bio pi3. Allocate resource dictated bids market clearing price.315(16)fiYgge & Akkermans0,25Standard deviation0,20,15Market-AMarket-A',Money0,10,0519181716150Time day, hFigure 9: Standard deviation original Huberman-Clearwater scheme scheme withoutmoney dependencies.Plots standard deviation original scheme well schememoney dependencies removed shown Figure 9. scheme withoutmoney, setting parameter 66 turned optimal. scheme withoutmoney dependencies performs well original scheme. reasonBio dependency mio completely negligible.11 Hence, money parameterplay significant role success Huberman-Clearwater market scheme.7.2 Deleting Temperature DependencyAnother factor interest impact temperature bid prices. removedependency setting bid price 10 selling agents 100 buyingagents. is, use following market scheme:1. agents send bids,[sellio (Tio , Tosetp , hTi i, hTosetp i),(vio (Ti, Tsetp , ),Bio =10, sell = true],100, sell = f alseauctioneer.2. Now, prices larger 10 smaller 100 equally good candidates.mismatch supply demand, say, supply exceeds demand,agents sell picked randomly among valid candidates, resourcesallocated accordingly.10. precisely, done setting U (0, m) Eq. (28) (Appendix A) constant value, 2000.corresponds letting mio approach infinity.11. actual fact, U (0, m) Eq. (28) Appendix vary 1999.86 2000 possiblemio .316fiDecentralized Market Control0,25Standard deviation0,20,15Market-A',Money0,1Market A',Money,Temp0,050151617Time day, h1819Figure 10: Standard deviation scheme money dependencies removed, comparedscheme money temperature dependencies removed.Figure 10 standard deviation plotted scheme without money, mentionedabove, scheme dependency temperature removedwell. Here, setting fit parameter 65 turned optimal. see alsoperformance good original scheme. Note temperaturestill used determine vio boolean variable sell. conclusiontemperature dependency affect quality market-based solutionbuilding control problem.7.3 Deleting AuctionNext, let agents assign bids without auction whatsoever.means sum total controller outputs, Fio , might sometimes exceed totalresource amount sometimes that. physical model course still obeyed,total resource amount actually used, total consumed cooling power Piocons ,never exceed totally available resource amount, described Eq. (2). Hence,resource updates described by:(+vio (Ti , Tsetp , ), sell = f alsevio (Ti , Tsetp , ), sell = true0,Fio0 < 0Fio0 , 0 Fio0 33,Fio0 > 3Fio0 = Fi1,oFio =(17)result simulation shown Figure 11. Here, 17 turnedoptimal. surprising conclusion multi-agent scheme without performingauction roughly ten times better auction-based Market-A scheme.1212. practical point view pathological solution, revealing loophole problemdefinition Clearwater Huberman, cf. Section 3. revealed loophole problem definition317fiYgge & Akkermans0,250,2Standard deviationMarket-A0,15Market-A',Money,Temp,Auction0,10,0501516171819Time day, hFigure 11: Standard deviation auction mechanisms completely removed, comparedoriginal Huberman-Clearwater Market-A scheme.7.4 Discussionfirst glance, might seem counterintuitive performance actually improves significantly core mechanisms market removed. First showed introducingmarket improves performance considerably compared conventional independent control, showed market mechanisms superfluous. What, then, bigdifference uncoordinated integrating controller, Control-A scheme,multi-agent scheme without auction ended with? simple answer,view, access global data agent has, terms average temperature average setpoint temperature (as follows Eq. (14)), Market-AMarket-A0 schemes. Knowing average quantities means agent information agents c.q. offices. information available caseindependent conventional controllers. exploitation non-local information makesbig difference.take absolute temperature account, differences temperature(i.e. minimizing standard deviation potentially sacrificing average temperature). properapproaches introduced remainder article allow take advantageloophole, minimize differences using available resource. is, approachesintroduced solve problem strictly harder problem definedSection3. happens Market-A scheme without auction seen observingdefinition tio Eq. (22). based quotient setpoint temperature actualtemperature. request volume, Eq. (24), proportional quotient. always resultssignificant excess supply. (Hint, think small example two offices, setpoint 20,temperatures 19 21. Now, 20farther away 1 20, hence selling volume1921exceed buying volume.) implies trade occasion, many offices preventedselling (because poor definitions volumes). offices prevented sell deviatesignificantly, hence results high value measure. auction deleted,agents average distance setpoints able get rid resourcehence differences temperature decrease.318fiDecentralized Market ControlThus, upshot factor analysis success Huberman-Clearwatermarket scheme Section 6 agents share crucial office controlinformation first, auction takes place. one remove auctionwithout deterioration results: major function auction share necessaryinformation bidding procedure, Huberman-Clearwater protocolneeded information already shared. appropriate description marketscheme would therefore say consists three (as described Section 6),four phases, first phase agents send current temperaturesTio well setpoint temperatures Tosetp agents.sum, answered first question raised end previous section:reason success Huberman-Clearwater market scheme, comparedconventional independent controllers? single important factor containedfirst step above: market procedure carried out, agents communicate keyinformation current situation agents. done neither moneyauction mechanisms needed. conventional independent controllers,Huberman Clearwater compare approach, globally shared informationavailable, however. explains two solutions perform differently.Now, turn second question raised previous section: alternativeperhaps better solutions? analysis suggests look two differentdirections. one wants persuade control engineers value agent-based approaches,convincing compare Huberman-Clearwater scheme strictly localcontrollers, controllers access global information agentshave. Secondly, dependency global information agents highly undesirablefeature clearly runs counter decentralized computational market philosophy. So,one investigate whether possible design market protocol exploitsstrictly local information agents bid construction. issues investigatefollowing two sections, first treating central control subsequently devising strictlylocal market protocol. seen yield significantly improved performance.8. Control-B: Standard Controller Using Global Dataconcluded access global data crucial performance, courseinterest analyze performance would integrating controller, likeone introduced Eq. (11), incorporating global data.would like controller take account deviation setpoint, consider also deviations offices setpoints. Therefore,controller Eq. (11) extendedFio = Fi1,o + [(Tio Tosetp ) (hTi hT setp i)],(18)set 10 previously. Piocons is, before, obtained Eq. (12).plot simulation controller, compared Market-A simulation, Market-A0 simulation auction removed, shownFigure 12.see standard deviation approximately Control-BMarket-A0 schemes. Thus, Control-B scheme also performs roughly ten times319fiYgge & Akkermans0,25Standard deviation0,2Market-A0,15Market-A',Money,Temp,AuctionControl-B0,10,0519181716150Time day, hFigure 12: Standard deviation integrating controller utilizes global data comparedHuberman-Clearwater Market-A scheme, Market-A0 schemeauction removed.better Market-A. important difference, though, Control-B employswell-known integrating controller well-understood methods theoriese.g. stability analysis.13 contrast, Market-A scheme easily analyzableformal theory perspective, since rely well established concepts.Control-B relatively clear, see Eq. (18), much harder conceptually graspprinciples behind Market-A, consists large number complicatedeasily justified equations (see Eqs. (21)(33) Appendix A). main conclusionpresent section that, enable conventional controllers act upon globalinformation Huberman-Clearwater agents do, central control approach performsbest easiest understand.9. Market-B: Market Local DataThus, computational market Market-A outperformed global control schemeControl-B. Therefore, interesting follow-up question whether simple wellperforming computational market approach devised depend available global information, contrast schemes. sectionshow indeed case, decentralized market performs comparablyfully centralized conventional control. approach derived section reliesgeneral theory relations optimization problems markets(Ygge,1998, Chapter 3) (Bikhchandani & Mamer, 1997) applicable manyapplications.13. holds assumption characteristic time scale variations averagetemperature much larger fluctuation temperature. reasonableassumption present case.320fiDecentralized Market Controluse market-oriented programming approach based equilibrium market.basic protocol (cf. Figure 1):1. agent submits net demand function zio (p) auctioneer, describingchange allocation desired agent price p.2. auctioneer computes equilibrium, calculating price piPPzio (pi ) = 0 (or, strictly speaking, |zio (pi )| , small (positive)numerical tolerance).3. agent receives demanded resource zio (pi ) calculated obtained marketequilibrium price.computation zio (p) process computing equilibrium describedbelow. Note truly distributed approach, relyglobal data, communication temperatures agents market communication starts.9.1 Relation Markets Conventional Controllers utilizingGlobal Dataperformance measure system given Eq. (1). best system thereforeone minimizes equation. Hence, straightforward move one thinkcome market model, take measure representing utility functionoverall system. So, utility functions individual agents ideally related[(Tio Tosetp ) (hTi hT setp i)]2 . 14 However, still formulation containing globalinformation.Thus, want obtain purely local reformulation, getting rid termshT containing global information. might replace them, though, terms relatingchanges local resource. so, take inspiration standardcontroller equations Eqs. (11) (18), indicating get good results (for unconstrained resources) update equation Fio = Fi1,o + io , io formio = (Tio Tosetp ). intended interpretation io represent outputlocal controller would delivered acted independently unconstrained resources.market setting agent updates control signal Fio Fio = Fi1,o + Fio ,Fio determined outcome market. Since resource rePdistributed among agents, No=1 Fio = 0. Accordingly, stepdesign Market-B scheme, based local data only, employ following definition.Definition 9.1 Let utility function individual office agents definedu(Fio , m) = 2o (Fio io )2 + m,(19)strength parameter office representing physical propertiesRo Co . (The proper choice discussed Theorem 9.3 later on.)Furthermore, let agents price-takers.14. Since utilities expressions preference orderings, invariant monotonic transformations.321fiYgge & AkkermansDue simple quadratic form utility function Eq. (19), net demand,zio (p), easily computed price-taking agents analytical means. Note moneyfundamentally different money Market-A, c.f. Section 6.money represents commodity agent needs decide much money tradecommodity cold air. described above, money Section 6 controlvariable without intuitive interpretation.Theorem 9.1 utility functions behavior given Definition 9.1, existsPunique equilibrium price pi | zio (pi ) = 0, allocation obtained equilibriummarket Pareto optimal.Proof. See (Mas-Colell, Whinston, & Green, 1995; Varian, 1992; Takayama, 1985). 2setting, wide variety different algorithms guaranteedPconverge clearing price pi | zio (pi ) = 0, second step equilibriummarket protocol given above. Examples algorithms price tatonnement, Walras (Cheng & Wellman, 1998), various Newton-Raphson type methods. detaileddiscussion communication computation efficiency aspects algorithms givenYgge (1998, Chapter 4).Theorem 9.2 Pareto optimal outcome market agents hold utilityfunction Eq. (19) equivalent integrating controller exploits global information described following resource update equation :Fio = io2o1hi i,h1/2(20)given agent boundary. Here, h1/2 hi average 1/2o , i0respectively.Proof.Pareto-optimal allocation agent bounds,u(Fio )/Fio equal. (Assume u(Fip )/Fip < u(Fiq )/Fiq ,price u(Fip )/Fip < p < u(Fiq )/Fiq , exists (sufficiently small) amountFi , say , (Fip , mip + p) > (Fip , mip ) uq (Fiq + , miqp) > uq (Fiq , miq ). Correspondingly u(Fip )/Fip > u(Fiq )/Fiq . Hence,u(Fip )/Fip = u(Fiq )/Fiq ).2N2o (FiN ). SummingPN 1PN 1P 1 12equations yields o=1 Fio o=1 io = N (FiN ) No=1 2o . Adding FiNPsides dividing sides N togetherresource constraint ( No=1 Fio =PThus, hold every office Fio io =PNioN1o=1 2o=10) yields= 2N (FiN ) N equivalent FiN =N1h i. reasons symmetry, equation holds offices. 22 h1/2NCorollary 9.1 special case equal, io = (Tio Tosetp ), Eq. (20)becomes exactly Control-B scheme captured Eq. (18).322fiDecentralized Market ControlConsequently, also follows simulation results equilibrium Market-Bscheme, based utility function Eq. (19) provisions given corollary, identical centralized Control-B scheme, cf. Figure 12. fullydecentralized market scheme thus performs better original Huberman-Clearwatermarket protocol.sum, see (under suitable conditions fulfilled here) local data plusmarket communication equivalent conventional central control utilizing global data.Even though proof based assumption agents neverboundary values, close approximation many practical applications.also noted managing boundaries required successful implementation.seen above, omitting management boundaries current application leadsControl-B, shown high performance.9.2 Finding Optimal Utility Functionsection show optimal utility function constructed constrainedcase, optimal controller unconstrained case.15 Earlier noteddebatable whether measure Eq. (1) good one. One argumentallows pathological solutions, take average indoor temperatureconsideration. example increase indoor temperature every office10 C, could unbearably hot, measure might minimized.reasonable thing here, prevent kind solutions, treat averagetemperature given (the result using available resources). so, followingtheorem shows optimal utility function constructed constrained case,optimal controller unconstrained case.Theorem 9.3 Tio linear function Fio ,16 io minimizes Eq. (1)unconstrained case, market utility functions described Eq. (19),Tio= F, associated Pareto optimal allocation minimizes Eq. (1) coniostrained case, resource independently allocated among agents (i.e.,Pconstraint Fio upper lower bound, No=1 Fio = 0),average temperature considered given.PProof. Minimizing Eq. (1) boils minimizing f (Ti1 , Ti2 , . . . , Tin ) = No=1 [(TioTosetp )(hTi ihT setp i)]2 , since monotonic transformation. Due factfio minimizes Eq. (1), holds F= 0 Fio = io . Since average temperatureiofTioconsidered given, F= 2[(Tio (io ) Tosetp ) (hTi hT setp i)]ioioFio = io . gives Tio (io ) = Tosetp + (hTi hT setp i). Thus, fP2rewritten No=1 [Tio (Fio )Tio (io )] . Since Tio linear function Fio ,P2TioTioTio (Fio ) = Tio (io ) + F(Fio io ), hence f becomes N(Fioo=1 Fioio2io ) . reallocation effect total (summed) utility, minimizing15. resource constrained action agent limited Pio , see Eq. (12) Figure 7.unconstrained limitation present, cf. Figure 6.16. thermal model discussed Section 4 (especially Eqs. (5) (12)) note indeedcase reasonably wide range.323fiYgge & AkkermansPTiof equivalent minimizing No=1 uo , = Fio . Furthermore,Pareto optimal allocation market utility functions describedPEq. (19) maximizes No=1 uo . (Suppose allocation FioPNbbmaximize o=1 uo , Fio does. reallocating Fio Fio letting mbio =PNuo (F b ,mb )PNuo (F ,ma )ioioioioo=1maio + uo (Fioa , maio ) uo (Fiob , mbio ) + o=1always ParetoNimprovement. Hence, non-maximized sum implies non-Pareto optimal allocation,Pareto optimal allocation implies maximized sum.) (Ygge, 1998, Theorem 3.1,p. 44) implies Pareto-optimal allocation market utility functionsTiodescribed Eq. (19) = F, minimizes f . 2ioThus, constructed fully distributed market design yields optimaloutcome. Particularly note Theorem 9.3 based assumptionintegral controller used, rather said io (the desired resource controller)optimal, proposed utility function generates globally optimal outcome.9.3 DiscussionPreviously, saw independent controller Control-B incorporates globaldata, viz. average temperatures, performs well. present section positivelyanswered question one construct market, Market-B, based localdata performs well.result employed market approach based general equilibrium theory.course available mechanism resource allocation multi-agentsystems. seems interesting try mechanisms, like contract net protocol(Davis & Smith, 1983), see perform better. However, Theorem 9.3 tells usthat, treat problem building control separable terms agents (asalso done Huberman Clearwater), better scheme.17 example,assigned resources auctioneer, turn would iteratively assigntotal resource small portions bidders bidding true marginal utility, wouldend something close competitive equilibrium, cannot betterMarket-B. Furthermore, would computationally extremely inefficient wayarrive equilibrium compared available methods (Ygge, 1998, Chapter 4).is, use different mechanisms achieving competitive equilibrium,never hope find mechanism would better Market-B scheme.17. note that, mentioned earlier, problem actually fully separable terms agentstherefore better solutions may exist taken account. Another observation articleinvestigated case using currently available resource interesting commodity,accordance work Huberman Clearwater, found optimal mechanism that.note however extending negotiations future resources well could potentially increaseperformance. different problem setting different demands available local and/orglobal information items, predictions. given solution problem recent work,see Ygge et al. (1999).324fiDecentralized Market Control10. Conclusionsbelieve approach results, presented article, poseinteresting challenge software agent community. Multi-agent systems offer newway looking information systems development, potentially large future impact. However, new approaches must prove value comparison competitionexisting, established ones. agent paradigm exception.therefore deliberately played role devils advocate article.view, key question yet satisfactorily answered software agent communityis: respect extent multi-agent solutions betterconventional alternatives? article shown arguing favor multi-agentsystems approach require careful analysis beyond disciplinary boundaries computer science. Empirical comparative studies multi-agent literature kindcarried present article rare yet. shown technical detail, established paradigms conventional central control cannot easilydismissed. similar argument holds, way, regarding mathematical optimizationtechniques distributed resource allocation problems, cf. previous discussions (Ygge& Akkermans, 1996; Ygge, 1998). Many are, distributed guise, bettermany newly proposed market protocols.Abstract considerations alone, concerning general nature agenthood, autonomy,rationality, cooperation, sufficient prove value agent paradigm.theoretical reflections worthwhile, diminish need thorough analysis(agent market) failures successes real-life applications. Therefore, takendifferent approach, aimed obtaining experimental data points basisconvincing software agent claims established.data point considered article climate control within large building consisting many offices. Given measure, Eq. (1), local controller approach, Eq. (11),current temperatures, setpoint temperature, investigated problemproperly distribute resource among offices. rather prototypicalapplication relating general problem optimal resource allocation highly distributed environment. class problems already received much attentionmulti-agent area. Reportedly, type application suitable market-orientedprogramming (Huberman & Clearwater, 1995). hand, devisedbetter conventional control engineering solutions, well alternative better marketdesigns.main conclusions investigation are:market approach Huberman & Clearwater (1994, 1995) indeed outperformsstandard control solution based local, independent controllers. So, marketbased multi-agent approach indeed yields working solution type problem.analysis shown success market approach dependsagents communicating local information agents auctionstarts.However, conventional central control schemes allowed exploit globalinformation, perform even better.325fiYgge & Akkermansproposed alternative market design based general equilibrium theoryuses local data only. performs better Huberman-Clearwater marketwell centralized control scheme access global information.general conclusion formulated quasi-equation: local information+ market communication = global control. holds suitable conditions(existence market equilibrium, price-taking agents) validity specifically shown case building climate control (compare particularlyControl-B Market-B schemes developed). However, intendshow forthcoming work, much generally valid result.important difference computational markets global informationemergent property rather presupposed concept, central control.analysis focused market approach. tempting ask whetherthings different non-market multi-agent approach followed, say, usingcontract net (Davis & Smith, 1983). argued, answer opinion straightforward no. goal considered class problems find optimal distributedsolution. Alternative agent approaches, market well non-market ones, changemulti-agent dynamics way goal. might done better poorer way,possible change goal itself. goal state multi-agent approachis, however formulated, equivalent market equilibrium, yardstick achievedgiven quantitative performance measure discussed, stableacross different agent approaches.Thus, one main conclusions article one must carefulpromoting multi-agent approaches resource allocation problems traditionalapproaches available. particular, one cautious using arguments relateddistribution information (as done Huberman Clearwater), computational aspects. Still, argue conceptual advantages market-basedapproaches type problems, well advantages evaluation localperformance (cf. Section 2). advantages show clearly presentapplication setting example, assumed offices thermalcharacteristics office agents market added deleted continuouslyfly clearly visible general settings.final note article devised optimal market design givenproblem formulation rather devised optimal approach general problembuilding control. line objective paper give comparative studydifferent possible approaches. is, focused published well-knownproblem formulation order focus subject markets resource allocationalone. stated earlier article, several aspects improved, example:local controllers. I-controllers seldom used, rather PI- PID-controllerspreferred. Furthermore, kind computerized settings, modern digital controllers, based e.g. pole-placement methods preferable (Astrom & Wittenmark,1990).326fiDecentralized Market Controlmeasure. average value least important standard deviation.(We consequence excluded pathological solutions analysis takingaverage temperature given Theorem 9.3).incentives office agents reveal true preferences order avoid speculation. Reasonably, personnel offices opportunity maketrade-offs comfort economical value. (It shown generallyspeaking difficult benefit speculation number agentsmarket sufficiently large, and/or uncertainty agents behaviorexists (Sandholm & Ygge, 1997).)Taking several time periods account. office serves storage heat,agents example gain using relatively much resource certain hourstotal resource need small.is, realistic approach building control problem use minimizedcost measure, give users real incentives reveal energy preferences (byletting pay actual energy costs attempted speculation generallycost money), take future time periods account. Elsewhere solvedproblem dealing simultaneous optimization different time periods, meansmulti-commodity market (Ygge et al., 1999).realistic large-scale setting, market-based approach attractivecompared alternatives. abstractions used (prices demands) naturaleasily understood everyone, uniform types agents (even onesuse resource controlling temperature).major qualitative conclusion article local data plus market communication yields global control. conclusion based discussed application settingbuilding control, instance distributed resource allocation problem. suggestsgenerally type problem central control engineering multi-agentmarket solutions devised give comparable optimal control quality. next stepprove generally rigorous mathematical fashion, delineating preconditions detail. proof based upon (continuous matrix-algebraic)dynamic systems theory available control engineering, especially upon results concerning called optimal control. believe indeed done formalway, conjecture state following general result. Multi-agent equilibrium markets yield optimal decentralized solutions distributed resource allocation problemsquality, terms given overall systems performance index, solutionsgiven optimal central (multi-input, multi-output) systems controller accessrelevant local data. local data involve total system state control vectors(in building control vectors formed difference actualsetpoint temperatures office, cooling power office, respectively).Preconditions true are: (i) agents act competitively; (ii) equilibrium exists; (iii) systems performance index written linear combination localcontributions (implying diagonality certain matrices; not, agents independent).local contributions directly related agents utility functions. agentapproach readily generalizable large-scale systems non-linear control327fiYgge & Akkermanssolutions (linearity main case control engineering get analytical mathematical expressions). indeed strong general statement relationship(and even outcome equivalence) decentralized markets central control.Acknowledgmentspresent work mainly carried University Karlskrona/Ronneby.thank Rune Gustavsson Hans Ottosson support. special acknowledgmentgoes Olle Lindeberg whose detailed comments draft papers led significantimprovements simulations whose ideas also helped us design marketSection 9. benefit significantly several discussions Michael Wellman.also thank Bengt Johannesson, who, part masters thesis, went detailsarticle independently recreated verified simulations. thank ArneAndersson, Eric Astor, SoC team useful comments discussions draftmaterial. work partially sponsored NUTEK EnerSearch AB.earlier version paper presented MAAMAW97 workshop (Ygge &Akkermans, 1997).328fiDecentralized Market ControlAppendix A. Original Formulation Huberman-Clearwater Marketformulae section directly taken papers Huberman & Clearwater (1994, 1995).Trade volumesFirst, decision agent buy sell based(setphTitio =setpTio hTtio > 1, seller.tio < 1, buyer(21)Then, total trade volume, V , calculatedVi =NX|1 tio | ,(22)o=1N number offices.Every agent calculates request volume, v, accordingvio =|1 tio |.Vi(23)agent buys sells v actual movement valve, called V AV ,computedV AVio = f (f lowio , vio , V AVio ),(24)actual V AV position interval updated accordingV AVi+1,o = V AVio + V AVio .(25)function f Eq. (24) stems physics office control,easy derive general case neither explicitly given original papers(Clearwater & Huberman, 1994; Huberman & Clearwater, 1995). reasonable simplechoice assume linear relationship (the cited papers suggest practicewell), replacing Eq. (24) Eq. (25)Fi+1,o = Fio vio ,(26)plus minus depend whether refers accepted buy sell bid. Pcioobtained Eq. (12). employed Eq. (26) simulations. natureassumption crucial central line reasoning.Bidsbids based marginal utility 18 form described by19setpU (tio /Tosetp , mio ) = [U (0, mio )](1tio /To)(1= [U (0, mio )]hTi)Tio hT setp,(27)18. called utility work Huberman Clearwater. prefer use term marginal utilityinstead, directly related price. terminology conforms better microeconomictheory.19. notion utility function used Clearwater Huberman much based workSteiglitz & Honig (1992)329fiYgge & AkkermansU (0, mio ) = u3 (u3 u1 )emio ,= ln(28)u3 u 1,u3 u 2(29)u1 = 20, u2 = 200, u3 = 2000, amount money agent has,givenmio = 100(2 V AVio ).(30)relation Fio V AV , rewrite Eq. (30)mio = 100(2Fomax Fio).Fomax(31)Observing Eqs. (28) (29), note equations simplifiedU (0, mio ) = u3 (u3 u1 )emio = u3 (u3 u1 )(e )mio =u3 (u3 u1 )u3 u1u3 u2mio.(32)bids calculated multiplying marginal utility previous price,price, accordingBi,o = Uio (tio /Tosetp , mio ) pricei .(33)equation given Huberman Clearwater. Straightforward applicationEq. (33) turns produce major problems simulations, however. Equation (27)iishows U (tio /Tosetp , mio ) minimized minimized Tio maximized hThTsetp.expect Tio well 10 ChTihT setpwell 2, U (0, m) 2000,2sure U (tio /Tosetp , mio ) well 20001 10 437. Thus, biddingprice never 437. Then, Eq. (33) tells us market priceleast price0 437i . leads numerical overflow iterations. note howeverthat, since agents multiply bids previous price, effectreallocation itself: affects price level. Therefore, omit multiplyingprevious price simulations, agents bid prices Eq. (33) equalmarginal utilities Eq. (27). Huberman Clearwater state burn moneyauction round order avoid inflation overflow, indicating mayadopt similar procedure. case, procedure leads exactly allocationsavoids numerical overflow.330fiDecentralized Market ControlReferencesAkkermans, J. M., & Ygge, F. (1997). Smart software customer assistant large-scaledistributed load management. Proceedings Distribution Automation/DemandSide Management (DA/DSM) 97. PenWell Conferences Exhibitions.Bertsekas, D. (1992). Auction algorithms network flow problems: tutorial introduction. Computational Optimization Applications, pp. 766.Bikhchandani, S., & Mamer, J. W. (1997). Competitive equilibrium exchange economyindivisibilities. Journal Economic Theory, 74, 385413.Borst, W. N., Akkermans, J. M., & Top, J. L. (1997). Engineering ontologies. InternationalJournal Human-Computer Studies, 46, 365406. ISSN 1071-5819.Bradshaw, J. M. (Ed.). (1997). Software Agents. AAAI Press/The MIT Press, Menlo Park,CA.Cheng, J., & Wellman, M. P. (1998). walras algorithma convergent distributedimplementation general equilibrium outcomes. Computational Economics, 12, 124.Clearwater, S., & Huberman, B. A. (1994). Thermal markets controlling building environments. Energy Engineering, 91 (3), 2556.Davis, R., & Smith, R. G. (1983). Negotiation metaphor distributed problemsolving. Artificial Intelligence, 20 (1), 63109.Gagliano, R. A., Fraser, M. D., & Schaefer, M. E. (1995). Allocation compting resources.Communications ACM, 38, 88103.Hu, J., & Wellman, M. P. (1996). Self-fulfilling bias multiagent learning. Tokoro, M.(Ed.), Proceedings Second International Conference Multi-Agent Systems,ICMAS96, pp. 118125. AAAI Press, Menlo Park, CA.Huberman, B. A., & Clearwater, S. (1995). multi-agent system controlling buildingenvironments. Lesser, V. (Ed.), Proceedings First International ConferenceMulti-Agent Systems, ICMAS95, pp. 171176. AAAI Press / MIT Press,Menlo Park, CA.Ibaraki, T., & Katoh, N. (1988). Resource Allocation ProblemsAlgorithmic Approaches.MIT Press, Cambridge, MA.Incropera, F. P., & Witt, D. P. D. (1990). Fundamentals Heat Mass Transfer. WileySons, New York. Third Edition, ISBN 0-471-51729-1.Jennergren, P. (1973). price schedules decomposition algorithm linear programmingproblems. Econometrica, 41 (5), 965980.Jordan, J. S. (1982). competitive allocation process informationally efficient uniquely.Journal Economic Theory, 28, 118.331fiYgge & AkkermansKurose, J. F., & Simha, R. (1989). microeconomic approach optimal resource allocationdistributed computer systems. IEEE Transactions Computers, 38 (5), 705717.Mas-Colell, A., Whinston, M., & Green, J. R. (1995). Microeconomic Theory. OxfordUniversity Press.Mullen, T., & Wellman, M. P. (1995). simple computational market network information services. Lesser, V. (Ed.), Proceedings First International ConferenceMulti-Agent Systems, ICMAS95, pp. 283289 San Francisco, CA.Ogata, K. (1990). Modern Control Engineering. Prentice-Hall, Englewood Cliffs, NJ. SecondEdition, ISBN 0-13-589128-0.Press, W., Teukolsky, S., Vetterling, W., & Flannery, B. (1994). Numerical Recipies C.Cambridge University Press. Second Edition.Sandholm, T. W., & Ygge, F. (1997). gains losses speculation equilibriummarkets. Proceeding Fifteenth International Joint Conference ArtificialIntelligence, IJCAI 97, pp. 632638.Schreiber, A. T., Akkermans, J. M., & al. (1999). Knowledge Engineering Management.MIT Press, Cambridge, MA. Press.Steiglitz, K., & Honig, M. L. (1992). Chaotic behavior auction-based microeconomicmodel. Unpublished Manuscript.Sutherland, I. E. (1968). futures market computer time. Communications ACM,11 (6), 449451.Takayama, A. (1985). Mathematical Economics. Cambridge University Press.Varian, H. R. (1992). Microeconomic Analysis. New York: W. W. Norton. Third Edition.Varian, H. R. (1996). Intermediate MicroeconomicsA Modern Approach. W. W. NortonCompany, New York. Fourth Edition.Walsh, W. E., Wellman, M. P., Wurman, P. R., & MacKie-Mason, J. K. (1998).economics market-based distributed scheduling. Proceedings EighteenthInternational Conference Distributed Computing Systems, pp. 612621.Wellman, M. P. (1993). market-oriented programming environment applicationdistributed multicommodity flow problems. Journal Artificial Intelligence Research,pp. 123.Wellman, M. P. (1996). Market-oriented programming: early lessons. Clearwater,S. (Ed.), Market-Based Control: Paradigm Distributed Resource Allocation,chap. 4. World Scientific.Wellman, M. P. (1995). computational market model distributed configuration design.AI EDAM, 9, 125133.332fiDecentralized Market ControlWellman, M. P., & Hu, J. (1998). Conjectural equilibrium multiagent learning. MachineLearning, 33, 179200.Yamaki, H., Wellman, M. P., & Ishida, T. (1996). market-based approach allocatingQoS multimedia applications. Tokoro, M. (Ed.), Proceedings SecondInternational Conference Multi-Agent Systems, ICMAS96, pp. 385392. AAAIPress, Menlo Park, CA.Ygge, F. (1998). Market-Oriented Programming Application Power Load Management. Ph.D. thesis, Department Computer Science, Lund University. ISBN91-628-3055-4, CODEN LUNFD6/(NFCS-1012)/1-224/(1998).Ygge, F., & Akkermans, J. M. (1996). Power load management computational market.Tokoro, M. (Ed.), Proceedings Second International Conference MultiAgent Systems, ICMAS96, pp. 393400. AAAI Press, Menlo Park, CA.Ygge, F., & Akkermans, J. M. (1997). Making case multi-agent systems. Boman,M., & de Velde, W. V. (Eds.), Proceedings MAAMAW 97, pp. 156176. SpringerVerlag, Berlin. ISBN-3-540-63077-5.Ygge, F., & Akkermans, J. M. (1998). resource-oriented multi-commodity market computations. Demazeau, Y. (Ed.), Proceedings Third International ConferenceMulti-Agent Systems ICMAS98, pp. 365371. IEEE Computer Society.Ygge, F., Akkermans, J. M., Andersson, A., Krejic, M., & Boertjes, E. (1999). HomeBots system field tests: multi-commodity market predictive load management. Proceedings Fourth International Conference ExhibitionPractical Application Intelligent Agents Multi-Agents (PAAM99), pp. 363382.Astrom, K.-J., & Wittenmark, B. (1990). Computer-Controlled Systems - TheoryDesign. Prentice Hall, Englewood Cliffs, NJ. ISBN 0-13-168600-3.333fifffi ffffff!" #%$$'&$(((*)+$,(-$(.8:9<;>=>?A@CBEDGF>H+IKJML>?AION/012'34$5((*671ff"#3!.*5((IQPSR>9UT>HWVYXZF[DGJ\;>]B^]A_W@C?Y`aPS=>T>bcedgf^hikjmlnhoqpr+sutvgwx4y{zfi|~}Qv|uS}!*<un%+K{Cug4*u~*n*{:ghdidhQ{y{tx4'|}n|uS}+*QgCua*<ug4u*!~*g:{ufi%AA<W*^*g!Q u* <*AaA*0^00u<Au0C*fiCAAAn*4AC*%AAmA*0 {A^*uAA>*AA*>!U40a* A%*<AAu0W***%u*0uAU%AA<A'**'0%^***Q'fi*uAumA**nu*A**C*>A {A g*u%uu*0fiuA>AAAQ<Q*gACCAC%uuK*%4K4gA*SC*fiuAA0A'*W'A*0A****%C'00u WAA* u%figAW**Ug%'***%*% C%*a*AKaA*0U!0%%AuA!A0'*'u*C%%uA!*u^fiAACAu0A0AK*An>a*CA*0AA* UuA>u4A*0fiQu* QAAQ<gA*%**g'fi*U%fi!!A400A*+u4>0>*%uAnuAAC'fi*U0A%m{A<mu0uAA04!00%*uAA**'A*uSC*4*A+u!**AA<gA*%*QA%A!CkA*0A*<uAC{AuA {A >**Q**AgC0A<4fiff<0uASuA'uauAA0AfifiQ"!$#&%$#&!$'()#&!$%*(+-,+#/.0,+#&%21.0341#&561(+#71#&'()).08:9)#/;<='&;>?).0).0+3@1()#/A)!$#&5).0'B1.0;+%C;<=>9)D 1. EA)D0#'&D0%$%$.0F)#&!G%H1;IA)!G;J5)9+'&#7@%$.0)3D0#K'&D0%$%$.0F)#&!*LNMO!$#&.0>*+PRQSST'&UVWD0#&>*#&)PQSXSUZY#&!$!G;)#&PQSS[U\];D0A^#&!21P_QSS`a-b@cW()#!$#&%$9)D 1.0)3@'&D0%$%$.0F+#&!dLN()#&!$#&<e1#&!!$#&<N#&!$!$#&5d1;I%gf$h)ijf$kml-nofpaq.0%3#&)#&!$D0D>*;!$#r'&'&9)!$41#1(+6 g;<s1()#*.0+5). ,^.05+9)D_'&D0%$%$.0F)#&!G%7>*t:.0)3m9)A@1(+#*#&)%$#&>?)D0#&buMO;41(m1()#&;4E!$#B1.0'&DWLNvw)%$#&xzy)D0>r;)PsQSS{UH|}!$;3(ux~=#&5)#&D0%$?P_QSSaq)5#&>*A).0!$.0'&DLNv%G()#&>*PRQSSUA). 1/xy+()-,D0.0tJPwQSSTP=QSST?+ar!$#&%$#&!G'G(g()%r5)#&>*;)%21!G41#&51()413;:;J5g#&+%$#&>?+D0#/.0%*;)#()#&!G#H1(+#.0)5). ,.05)9)D'&D0%$%$.0F)#&!$%=.01()##&)%$#&>?)D0#!$#?^;41(I'&'&9)!$41#}+5/>*t#O1()#&.0!#&!$!G;!$%;5).0#&!$#&1dA)!21%;<1(+#*.0)A)91r%GA)'&#&buc ;mA^;A)9)D0!>r#B1();J5+%7<N;!}'&!$#&41.0)3'&'&9)!$41#@#&)%$#&>?)D0#&%!$#/MO33.0)3LNM!G#&.0>*)P=QSST'&a@)5MO;:;%21.0)3]LN)!$#&9+)5gxy)'()A).0!$#&PQSSTU}y)'G(+A).0!$#&PwQSS{a-bcW()#&%G#>*#B1(+;J5)%O!$#&D ;4!$#&%$>*A+D0.0)31#&'G()).08:9)#&%R1;C;?1.0/5+.0#&!$#&1O1!$.0).0)3K%$#B1%<N;!O#&'G(m;<1()#*'&D0%G%$.0F)#&!$%$bu@1().0%7A)A^#&! #CA+!$#&%$#&1dm'&;>*A)!G#&()#&)%$. ,+#C#B,D09)41.0;;<?^;41(MO33.0)3)5MO;J;%o1.0)3I;`[@5)41I%$#B1%q9)%$.0)3}1 ;d?+%$.0''&D0%G%$.0F)'&41.0;6>*#B1(+;J5)%Gw5+#&'&.0%$.0;d1!$#&#&%q)5+#&9)!$D)#B1 ;!$t:%$b$((('g""3 C 3 ^ 2' q*1ff"#"pfiffff*#A"S"3fistv{wz{y{tY!$#B,^.0;9+% ;!Gtd()%=5)#&>*;)%21!G41#&5K1()417MO33.0)3r+5/M;:;%21.0)3r!$#O,+#&!2#&#&'B1. ,+#<;!=5)#&'&. E%$.0;1!$#&#&%7LNMO9)#&!x|7;()-,.0PQSSSUq!$9)'t#&!xVW;!21#&%$P^QSSTUMO!$#&.0>*+PQSST'&PQSST?)U)!G#&9))5xy+'G()A).0!G#&PQSSTU79).0)D0)PqQSSTa-UK(); #B,+#&!$PO1(+#&!$#u()%d?^#&#&]D0. 1-1D0##&>*A).0!$.0'&DH1#&%21.0)3 . 1()#&9)!GD_)#B1 ;!$t:%@LN#&%$A^#&'&.0D0D . 1(I1(+#*)# MO;J;%o1.0)3uD03;!$. 1(+>*a-buq.0%$'&9)%G%$.0;)% . 1(A)!$#B,.0;9)%!$#&%$#&!G'G()#&!$%R!$#B,+#&D1()41>r r91(+;!$%'&;)'&#&1!$41#&5K;5)#&'&.0%$.0;=1!$#&#&%s5+9)#^1;_1(+#&.0!s<N%211!G.0).0)3%$A^#&#&5u+5 #&D0D EG#&%21?)D0.0%$()#&55)#&<N9)D 1KA)!$>*#B1#&!w%$#B1-1.0)3%$bw#&9)!$Ds)#B1 ;!$t:%qA)!$#&%$#&15).0*'&9+D 1.0#&%<N;!Z1#&%21.0+3r?^;41(u.0r1#&!$>*%w;<1()#7%G.03).0F)'&1A)!$;:'&#&%$%$.0+31.0>*#!$#&8J9+.0!$#&5u)5.0%G#&D0#&'B1.0)31!$.0E.0)3A)!$>*#B1#&!G%$U^(); #B,+#&!$P #w<N#&#&D1(+#&!$#=!$#w5).0%21.0+'B1q5,13#&%1;.0+'&D09)5).0)3)#&9)!$D)#B1 ;!$t:%.0;9)!%o19)5b.0!$%o1PA)!$#B,.0;9)%#&>rA).0!$.0'&D%219)5).0#&%()-,+#I5)#&>r;)%21!$41#&5u1()41/.0)5). ,.05)9)DH+#&9)!$D)#B1 ;!$t:%wA)!$;:5)9)'&#().03()D '&'&9+!$41#'&D0%G%$.0F)#&!$%Z1()41!$#%$;>*#B1.0>*#&%q>*;!G#}'&'&9)!$41#=1()u'&;!G!$#BE%$A^;)5).0+35)#&'&.0%G.0;w1!$#&#&%LN.0%$()#&!_x"'&|}9)%$.0'tJPQSXSU;:;)#BP+y)(+-,D0.0tJPcR; #&D0D0Px"7;-,+#&PQSXSa-by)#&'&;)5+P+#&9)!$DZ)#B1 ;!GtJ%K()$,+#d?^#&#&#B:1#&)%$. ,+#&D A)A)D0.0#&5'&!$;%$%K:9)>*#&!$;9)%5);>*.0)%ILN!G?).0?)PQSSa-bm.0)D0D P? %219)5^.0)3I)#&9+!$D)#B1 ;!$t:%7.05)5). 1.0;/1;m5)#&'&.0%$.0;I1!G#&#&% #C'&6#B^>r.0)#(); MO33.0)3@)5mMO;J;%o1.0)3r!$#.0))9)#&+'&#&5/? I1()#}D0#&!G).0)3rD03;!G. 1()>*P3. ,.0)3d<9)!o1()#&!.0)%$.03(1.01;K1()#*3#&)#&!GDZ'G()!G'B1#&!$.0%21.0'&%K;<1(+#&%$#*A)A)!G;'G()#&%$buM9+#&!7)56|7;()-,.LNQSSSaD0%$;m%219)5MO33.0)3u+56MO;J;%21.0+3mA)A)D0.0#&5I1;C1 ;mD0#&!$).0)3u>*#B1();:5)%$PZ.0I1(+#&.0!}'&%$#*5)#&'&.0%G.0;/1!$#&#&%}9+%$.0)3K,!$.01@;<VWb0m+5). ,+#BEGMO-+#&%C'&D0%G%$.0F)#&!$%$P?)9171()#&.0!7%219+5>r.0)D g'&;)'&#& 1!G41#&5;m1()#5)#&'&.0%$.0;*1!$#&#}!$#&%G9)D 1%$b9+!)#&9+!$Ds+#B1 ;!$tu)55)#&'&.0%G.0;@1!$#&#K!$#&%$9)D 1%qD0#&59)%1;Id:9)>?#&!w;<H.01#&!$#&%21.0+3@'&;+'&D09E%$.0;)%GbcW()#uF)!$%21u.0%}1()41MO33.0)3#&)%$#&>?)D0#u3#&+#&!$D0D A)!$;:5)9)'&#&%*'&D0%$%$.0F)#&!}1()41.0%d>*;!$#'&'&9)!$41#1()/C%21)5)!G5/'&D0%$%$.0F)#&!$b=cW(J9+%;)#q%$();9)D05/<N#&#&D'&;>*<N;!21?)D0#}D -%=MO33.0)3}1()#&.0!5)#&'&.0%$.0;r1!$#&#&%;!=)#&9)!GD)#B1 ;!$t:%$bw);!MO;:;%21.0)3PR(); #B,+#&!$P #);41#}>*;!$# .05)#&D I,!2^.0+3*!$#BE%$9)D 1%Gb=);!r<N# 5)41r%G#B1%=MO;J;%o1.0)3rA)!G;J5)9+'&#&5/5)!$>*41.0'!$#&5)9)'B1.0;)%=.0u#&!$!$;!LN#B,+#&'&;>*A+!$#&51;6MO33.0)3a-Pq?)91m<N;!*;41()#&!*5+41%$#B1%r. 1u'B19)D0D .0)'&!G#&%$#&%r.0#&!$!G;!*;-,+#&!d%$.0)3D0#/'&D0%$%$.0F+#&!LNA)!21.0'&9+D0!$D . 1(+#&9)!$DR)#B1 ;!$t:%$a-brB<9)!o1()#&!1#&%21% #K#B>*.0)#&5@1()#K#&#&'B1%};<H+;.0%$#C)5%$9)A+A;!o1K)!G#&9))56)5y+'G()A).0!G#&0%@LNQSSTa7'&;p#&'B19)!G#q1()41dMO;:;%21.0)30%7%G#&)%$. 1. ,. 11;m);.0%G#C>*-?^#A)!21D !$#&%$A^;)%$.0?+D0#<;!W. 1%;J'&'&%G.0;)D.0)'&!G#&%$#}.0m#&!$!G;!$bwID 1#&!$)41#}?)%G#&D0.0)#qA)A)!$;'( #q.0 ,+#&%o1.0341#&5 %R1()#w'&!$#&41.0;m;<K%$.0>rA)D0#+#&9)!$D)#B1-E;$!tK#&)%$#&>?)D0# ()#&!G##&'G(@)#B1 ;!$tC9)%$#&5w1(+#W<9+D0D1!$.0).0)37%$#B1)5*5+.0#&!$#&5r;)D m.0r. 1%H!G)5);>.0). 1.0D #&.03(1%$#B1-1.0+3%$b 9)!*!$#&%$9+D 1%*.0)5).0'&41#*1()41*1().0%d#&)%$#&>?)D0#K1#&'G(+).08J9+#u.0%*%$9+!$A)!$.0%$.0+3D#&#&'B1. ,+#&P_;<1#&A)!$;:5)9)'&.0)3C!G#&%$9)D 1%w%3;:;J5%MO33.0)3b=#&%$#&!G'G(? wD0.)5Y&&).OLNQSSTa5)#&>*;+%21!$41#&5m%$.0>r.0D0!=!$#&%$9+D 1%W9)%$.0)3C!G)5);>*.0&#&5m5+#&'&.0%$.0;C1!$#&#7D03;!$. 1()>*%$b9+!!$#&%G9)D 1%qD0%$;/%$(); 1(+41w1(+##&)%G#&>?)D0#K>*#B1(+;J5)%q!$#K3#&)#&!GD0D '&;)%$.0%o1#& 1LN.0d1#&!$>*%;<1()#&.0!s#&#&'B1O;}'&'&9)!$'Ba (+#&}A)A)D0.0#&5}#&. 1(+#&!)1;W+#&9)!$D)#B1 ;!$t:%;!)1;W5)#&'&.0%$.0;=1!$#&#&%$U(); #B,+#&!GP1()#&!$#@.0%KD0. 1-1D0#I.0 1#&!2EG'&;!G!$#&D041.0;]?^#B1 #&#&)#&9)!$D)#B1 ;!$t:%C)55)#&'&.0%$.0;1!$#&#&%C#B'&#&A1I<N;!1()#MO;J;%o1.0)3>r#B1();J5+%$bcW().0%d%$9)33#&%21%1()41%$;>*#;<1()#.0)'&!$#&%$#&%IA)!$;:5)9)'&#&5]? MO;:;%21.0)3!$#5)#&A^#&)5)#&1C;I1()#KA)!21.0'&9)D0!7'G()!$'B1#&!G.0%21.0'&%;<1()#C5)41/%$#B1r!G41()#&!1();@1()#C'&;>*A^;)#&1'&D0%$%$.0F+#&!$bzB]<N9)!21(+#&!1#&%21% #5+#&>*;)%21!$41#r1()41MO33.0)3.0%@>r;!$#u!$#&%G.0D0.0#& 1I1;);.0%$#r1()MO;J;%o1.0)3b.0)D0D P #q.0 ,+#&%o1.0341#&5*1()#q8:9)#&%21.0;/;<s(); >*'&;>*A^;)#&17'&D0%$%$.0F+#&!$%%$();9)D05I?^#w9)%$#&5.0]#&)%$#&>?)D0#&bV=;)%$.0%21#&1 . 1(]A)!$#B,.0;9)%d!$#&%$#&!$'(LN+!$#&9))5xy)'()A).0!$#&PQSSTUC79).0)D0)PQSSTa-PW;9)!!$#&%$9+D 1%7%$(); 1(+41I>*;%o1@;<R1()#d!$#&5)9)'B1.0;.0#&!G!$;!<N;!7#&+%$#&>?+D0#d>*#B1(+;J5)%;J'&'&9+!$%. 1(m1()#*F)!$%o1r<# 5)5). 1.0;)D'&D0%$%$.0F)#&!$%Gb*\. 1(MO;:;%21.0)35)#&'&.0%$.0;/1!G#&#&%$PO(); #B,+#&!$PO!$#&D041. ,+#&DD0!$3#}3.0+%=>*$?^#%$#&#&u9)Am9)1.0D?^;91`*'&D0%$%G.0F)#&!$%$b*fir+su}SmQzrvr++zcW(+.0%A)A^#&!w.0%q;!$3).0&#&5%q<;D0D0; %$bKr1()#)#B:1K%$#&'B1.0; #A)!$#&%$#&1K;-,+#&!o,^.0# ;<H'&D0%2E%$.0F)#&!#&)%$#&>?)D0#&%w)5m5).0%$'&9+%$%=MO33.0)3@)5uMO;:;%21.0)3d.0u5)#B1.0D0bw#BJ1 #A)!$#&%$#&1#BJ1#&)%G. ,+##&>*A).0!G.0'&D)D ^%G.0%=;<MO33.0)3d)5/MO;J;%o1.0)3b=);D0D0; .0)3}1()41 #A+!$#&%$#&17<919+!$#!G#&%$#&!$'G()55)5). 1.0;+D!$#&D041#&5 ;!$t@?^#&<;!G#'&;)'&D09)5).0)3bfi)Y.039)!$#CQ/.0D0D09)%o1!$41#&%1()#K?)%G.0'C<!$>r# ;!$t<N;!/'&D0%$%$.0F)#&!}#&+%$#&>?+D0#&b@Bd1().0%}#B>*A)D0#&PZ+#&9)!$D)#B1 ;!$t:%H!G#_1()#W?+%$.0'W'&D0%$%$.0F+'&41.0;@>r#B1();J5+P1();9)3(*'&;+'&#&A19)D0D m'&D0%$%$.0F)'&41.0;@>*#B1();:5LN#&b03b0P5)#&'&.0%$.0;q1!$#&#&%GaZ'&*?^#O%$9)?)%21. 191#&5*.0CA)D0'&#W;<1()#)#B1 ;!$t:%$bOH'(r)#B1 ;!Gt.0C.039)!G#Q0%#&)%$#&>?)D0#KLN)#B1 ;!$tCQO1()!G;9)3(*)#B1 ;!$t*.0}1().0%H'&%$#&a.0%1!$.0+#&5r9)%$.0+3O1()#1!$.0+.0)3}.0)%21+'&#&%<N;!H1(+41C+#B1 ;!$tJbKcW(+#&)Ps<N;!q#&'G(#B>*A)D0#&P1()#A)!$#&5+.0'B1#&5;91A)91C;<Z#&'G(;<1()#&%$#)#B1 ;!$t:%L24.0.039)!G#7Qaw.0%'&;>?).0)#&5r1;rA)!G;J5)9+'&#O1()#7;91A)91;<1()##&)%$#&>?)D0#@Lr.0u.039)!$#Qa-b}!$#&%$#&!G'G()#&!$%wLND0A)$^5+.0)P+QSS[U^MO!$#&.0>*)P+QSST'&U|7!$;3(*x~=#&5)#&D0%$?PQSSUs.0)'&;D0*xy)t:!$BA^#&tJPQSXSaq()-,+#5)#&>*;+%21!$41#&5C1(+41K#&#&'B1. ,+#K'&;>?).0).0)3d%$'G()#&>r#.0%H1;r%$.0>rA)D 6-,+#&!$3#1()#A)!$#BE5).0'B1.0;)%;<)1(+#})#B1 ;!$t:bV ;>?).0).0+3W1()#w;91A)91q;<%G#B,+#&!$D^'&D0%$%$.0F)#&!$%.0%O9)%G#&<9)D;)D .0<1(+#&!$#.0%O5).0%G3!$#&#&>*#&1>r;)3W1()#&>*b ?,^.0;9+%$D P}'&;>?).0).0)3%$#B,+#&!$Dq.05)#&1.0'&Dq'&D0%$%$.0F)#&!G%@A+!$;J5+9)'&#&%d+;3.0)bvw)%$#&)5y)D0>*;gLNQSS{a}A+!$;-,+#&5d1()41*.0<^1()#-,+#&!G3#*#&!$!$;!q!$41#K<N;!w#B>*A)D0#.0%D0#&%$%1(){)51()#w'&;>*A^;)#&1w'&D0%$%$.0F+#&!$%O.0}1()#w#&)%$#&>?)D0#w!$#w.0)5)#&A^#&)5)#&1.071()#A+!$;J5+9)'B1.0;r;<1(+#&.0!#&!$!G;!$%$P1()#/#BA^#&'B1#&5]#&!$!$;!C<N;!q1()41u#B>*A)D0#u'&g?^#/!$#&5)9)'&#&51;6&#&!G;%1()#/:9)>?#&!K;<q'&D0%$%$.0F+#&!$%'&;>?).0)#&53;:#&%1;u.0)F)). 1^U(); #B,+#&!$PO%$9)'(6%$%$9+>*A1.0;)%}!G!$#&D (+;D05.06A)!G'B1.0'&#&bu|}!$;3()5~=#&5)#&D0%$?LNQSSa=D041#&!WA)!$;$,+#&571(+411()##&+%$#&>?+D0#w#&!G!$;!O'&/?#w5). ,.05)#&5@.0 1;C1#&!$>>*#&%$9+!$.0)31()#6$,+#&!$3#3#&)#&!$D0.0&41.0;#&!$!$;!m;<K#&'(.0)5+. ,^.05)9+D'&D0%$%$.0F)#&!)51#&!$>>*#&%$9)!$.0+31()#5).0%$3!G#&#&>*#& 1>*;)3=1()#'&D0%$%$.0F)#&!$%GbR\()411()#Bu<N;!$>*D0D u%$(+; #&5 %1()41q@.05)#&D#&)%$#&>?)D0#'&;)%$.0%o1%7;<().03()D '&;!$!$#&'B1@'&D0%G%$.0F)#&!$%O1(+41d5).0%$3!$#&#r%7>9)'G(6%A^;%$%$.0?)D0#&b A+. 1C)56y)()$,^D0.0tLNQSSTPRQSST?)a=#&>*A+.0!$.0'&D0D /,+#&!$.0F)#&5K1(+41%$9)'(m#&)%$#&>?)D0#&%=3#&+#&!$D0.0&# #&D0D0b%H}!G#&%$9)D 1P+>r#B1();J5+%H<N;!Z'&!$#&41.0)3#&)%$#&>?)D0#&%H'&#&1#&!!$;9))5*A+!$;J5+9)'&.0)3q'&D0%$%$.0F)#&!G%1()41w5).0%2Ew3!$#&#O;=1()#&.0!sA+!$#&5).0'B1.0;)%$b}#&)#&!GD0D P1()#&%$#>*#B1();:5)%R<;:'&9)%;KD 1#&!$.0+3Z1()#1!$.0).0+3=A)!$;:'&#&%$%R.0ensemble outputcombine network outputs12network 1 network 2Nnetwork Ninput.039)!G#Q='&D0%$%$.0F)#&!#&)%$#&>?)D0#};<R)#&9)!$D)#B1 ;!GtJ%$b*fistv{wz{y{t1()#}(+;A#1()41=1()#}!$#&%$9+D 1.0)3*'&D0%$%$.0F+#&!$% .0D0DA+!$;J5+9)'&#5).0#&!$#& 1A)!$#&5).0'B1.0;)%GbW);!=#B>*A)D0#&P)#&9E!$D)#B1 ;!$tw1#&'G(+).08J9+#&%1()41q()-,+#?^#&#&r#&>*A)D0;$+#&5d.0+'&D09)5)#W>*#B1(+;J5)%<;!1!$.0).0)3 . 1(r5).0#&!$#&11;A^;D0;3.0#&%$PR5).0#&!G#& 1.0+. 1.0D #&.03( 1%GP5).0#&!$#&1A)!$>*#B1#&!G%$P)5C1!$.0).0)3*;+D ;*A^;!21.0;u;<1()#O1!G.0).0)3*%$#B1/LND0A)$^5+.0)PQSS[URw!G9)'Gt#&!$PVW;!21#&%$PJ'Gt#&D0PR#&VW9+)Px~=A)).0t:PQSSURv+%$#&xy)D0>*;+PZQSS{U'&D0.06xy)(+-,D0.0tJPZQSSa-bIB@1().0%A)A^#&! #C'&;+'&#& 1!$41#r;I1 ;/A^;A)9)D0!>*#B1();:5)%dLNMO33.0)3)5M;:;%21.0)3a=1()411!21;m3#&)#&!$41#@5).0%$3!$#&#&>r#& 1/>*;)3K1(+#r'&D0%$%$.0F+#&!$%?D 1#&!$.0+31()#1!$.0+.0)3*%$#B1#&'('&D0%G%$.0F)#&!W%$#&#&%GbShs+$ )d) *hNRgfiMO33.0)3LNM!G#&.0>*)POQSST'&aK.0%4?;:;41%21!$A+LNH<N!$;xcW.0?)%G().0!$).0PQSS[a#&)%G#&>?)D0#d>*#B1();:51()41/'&!$#&41#&%C.0)5). ,.05)9)D0%<N;!. 1%K#&)%G#&>?)D0#@?1!$.0).0)3#&'G('&D0%$%G.0F)#&!K;!$)5+;>!$#&5+.0%21!$. E?)91.0;;<1()#1!$.0+.0)3*%$#B1bqH'('&D0%G%$.0F)#&!$0%H1!$.0).0)3d%$#B1.0%w3#&)#&!$41#&5? 6!$+5);>*D 65)!$ .0)3P. 1(!$#&A+D0'&#&>*#& 1P#B>*A)D0#&% (+#&!$#.0%1()#C%$.0&#C;<1()#K;!$.03.0)D1!$.0).0+3/%$#B1UH>*;<1()#@;!$.03.0)DO#B>*A)D0#&%C>*$?^#r!$#&A^#&41#&5.01()#@!$#&%$9)D 1.0)3r1!$.0).0+3%$#B1 (+.0D0#d;41()#&!G%>r-?^#D0#&<e1/;91b]H'(.0)5). ,.05)9)D'&D0%$%$.0F)#&!r.0u1(+#@#&+%$#&>?+D0#@.0%C3#&+#&!$41#&5 . 1(5).0#&!$#& 1u!G)5);>%$>*A+D0.0)3C;<1()#1!$.0).0)3r%$#B1b.039)!$#`@3. ,+#&%}d%G>*A)D0#;<_(); MO33.0)3/>*.03(1 ;!$tm;@.0>*3.0)!2%$#B1*;<_5)41bKy).0)'&#MO33.0)3q!$#&%$>*A+D0#&%)1()#1!$.0).0)3w%$#B1 . 1(7!$#&A)D0'&#&>r#& 1P)%G;>*#H.0)%o1)'&#H!$#!$#&A)!$#&%G#& 1#&5>9+D 1.0A)D0#1.0>*#&% (+.0D0#;41()#&!G%w!G#D0#&<e1*;91bKy);@M33.0+30%1!$.0).0+34EG%$#B1-EGQ/>*.03(1C'&;1.0#B>*A)D0#&%[I)51 .0'&#&PH?)91*5);:#&%);41*'&;1.0#&. 1()#&!}#B>*A)D0#C/;!b@w%}/!$#&%$9)D 1P1(+#C'&D0%$%$.0F)#&!O1!G.0)#&5;1!$.0).0+34EG%$#B1-EGQ7>*.03(1=;?1.0*(+.03()#&!1#&%21-EG%$#B1#&!G!$;!1()q1()#O'&D0%$%G.0F)#&!Z9)%$.0+3wD0D+;<1()#5)41bB<N'B1P)D0DJ<N;9)!R;<)MO33.0)30%Z'&;>*A^;)#&1'&D0%$%$.0F)#&!$%_'&;9+D05!G#&%$9)D 1.0K().03(+#&!)1#&%21-EG%G#B1=#&!$!$;!$U(); #B,+#&!GP()#&'&;>?).0)#&5)P+1()#&%$#<;9+!'&D0%$%G.0F)#&!$%q'&gLN)5;<e1#&5);awA)!$;:5)9)'&#1#&%o1-EG%$#B1*#&!$!$;!wD0; #&!1()1()41K;<1()#}%$.0)3D0#'&D0%$%$.0F)#&!CLe1()#5). ,+#&!$%$. 1>*;)3}1()#&%$#7'&D0%G%$.0F)#&!$%w3#&)#&!$D0D '&;>*A^#&)%G41#&%<N;!1()#}.0+'&!$#&%$#}.0m#&!G!$;!W!$41#};<R.0+5). ,^.05+9)D'&D0%$%$.0F)#&!Ga-bMO!$#&.0>*LNQSST'&a/%$(); #&561()41M33.0+3.0%@#&#&'B1. ,+#;49))%21?+D0#&D0#&!$).0+3D03;!$. 1()>r%()#&!G#/%$>*D0DW'())3#&%@.01()#K1!$.0+.0)3%$#B1!$#&%G9)D 1.0gD0!$3#'G()+3#&%r.0gA)!G#&5).0'B1.0;)%$bM!G#&.0>*LNQSST'&a'&D0.0>*#&5d1()41K)#&9)!$Ds)#B1 ;!$t:%)55)#&'&.0%$.0;d1!$#&#&%w!$#7#B>*A)D0#&%q;<_9)+%21?)D0#7D0#&!G).0)3D03;!$. 1()>r%$b\]#C%219)5/1()##&#&'B1. ,+#&)#&%$%};<ZMO33.0)3/;?^;41(r1()#&%$#KD0#&!$).0)3@>*#B1();:5)%w.0d1().0%!21.0'&D0#&b+2K *oqhsd) qh2RjMO;J;%o1.0)3ILN+!$#&9))5@xy)'()A).0!$#&PQSSTUy)'()A).0!$#&PQSS{aO#&)'&;>*A)%$%G#&%<>*.0D ;<>*#B1();:5)%$bcW()#<N;J'&9)%q;<^1(+#&%$#K>*#B1();:5)%.0%1;IA)!G;J5)9+'&#7Iijf-4-f-i;<Z'&D0%G%$.0F)#&!$%$bCc=()#W1!G.0).0)3@%$#B1*9)%$#&5<;!q#&'(>*#&>?^#&!;<1()#C%G#&!$.0#&%}.0%}'();%$#&6?)%G#&56;I1()#CA^#&!$<N;!$>*)'&#K;<1()#C#&!$D0.0#&!}'&D0%G%$.0F)#&!fiLN%$a7.0I1()#%$#&!$.0#&%Gb6MO;:;%21.0)3P#B>*A)D0#&%=1()41@!G#r.0)'&;!$!G#&'B1D A)!$#&5).0'B1#&5? ]A+!$#B,^.0;9+%7'&D0%$%$.0F+#&!$%.0m1()#%$#&!$.0#&%7!$#K'G();%$#&>*;!$#K;<1#&/1()#B^>rA)D0#&%1()41 #&!$#C'&;!$!$#&'B1D gA)!$#&5+.0'B1#&5)brcW(:9)%qMO;J;%o1.0)341-1#&>*A1%1;@A)!$;:5)9)'&#}+# '&D0%$%$.0F+#&!$%Z1(+41K!$#?^#B1-1#&!?)D0#=1;@A)!$#&5).0'B1K#B^>*A+D0#&%<N;! ().0'G(r1()#'&9)!$!G#& 16#&)%$#&>?)D0#&0%/A^#&!$<N;!$>*)'&#.0%/A^;:;!$bLN;41#/1()416.0"M33.0+3Pw1()#!$#&%$>*A)D0.0+3;<W1()#1!$.0).0+3*%$#B1.0%W+;415)#&A^#&)5)#&1};K1()#}A^#&!$<N;!$>*)'&#;<+1()#}#&!GD0.0#&!='&D0%$%$.0F+#&!$%$b0aB/1().0% ;!$t #d#B^>*.0+#}1 ;)# +5A^; #&!$<N9)DZ<N;!$>*%7;<MO;:;%21.0)3Iw!$'&.0)3LNMO!$#&.0>r)PQSST?)am+5"5)4EGMO;:;%21.0)3LN+!$#&9))5"xy)'()A).0!$#&PQSSTa-b.0t#6MO33.0)3PCw!$'&.0)3'();J;%G#&%u1!$.0).0+3d%$#B1*;<Z%G.0&#K<;!q'&D0%$%$.0F+#&!q]QI? A)!$;?)?).0D0.0%o1.0'&D0D %$#&D0#&'B1.0)3L . 1(!G#&A)D0'&#&>*#&1a#B>*A)D0#&%W<N!$;>1()#;!G.03.0)D1!$.0).0)3C#B>*A)D0#&%$b=)D0.0t#7M33.0+3Ps(); #B,+#&!GP1()#A)!$;?+?).0D0. 1*fir+su}SmQzrvr++z%$>*A+D0#};<sr%$.0)3D0#}'&D0%$%G.0F)#&!=;m.0>*3.0)!26%$#B1;<s5)41bL !G.03.0)D0aWcR!$.0).0)3*y+#B1cR!$.0).0+34EG%$#B1-EGQQP`P[PPPTPPX%$>*A)D0#};<RMO33.0)3@;K1()#%$>*#75)41bLN#&%$>*A)D0#&5+aWcs!G.0).0)3Cy)#B1cs!$.0+.0)34EG%$#B1-EGQ`PPXP[PPTP[PQcs!$.0+.0)34EG%$#B1-EG`PXPPTPP`PPQcs!$.0+.0)34EG%$#B1-EG[[PTP`PPPTP`P`cs!$.0+.0)34EG%$#B1-EGPPQPPTPP[PX%$>*A)D0#7;<sMO;:;%21.0)3r;C1()#}%$>*#5+41bLN#&%$>*A)D0#&5+aWcs!G.0).0)3Cy)#B1cs!$.0+.0)34EG%$#B1-EGQ`PPXP[PPTP[PQcs!$.0+.0)34EG%$#B1-EG`QPPPPQPPTPcs!$.0+.0)34EG%$#B1-EG[PQPPXPQPXPQPcs!$.0+.0)34EG%$#B1-EGQPQPTPQPQP[PQP.039)!$#}`7vZA^;41()#B1.0'&Dq!$9))%d;<M33.0+3+5MO;:;%21.0)3b%$%G9)>*#C1(+#&!$#u!$##&.03(1@1!G.0).0)3#B^>*A+D0#&%$bw%$%$9+>*##B^>*A+D0#Q.0%/4;91D0.0#&!$g)5".0%/()!G5<N;!1()#'&;>*A^;)#&1D0#&!$).0)3D03;!$. 1()>1;'&D0%$%$.0<e'&;!$!G#&'B1D b6\. 1(gMO33.0)3Pw#&'G(1!$.0+.0)3%$#B1u.0%C.0)5)#&A^#&)5)#&1%$>rA)D0#u;<O1(+#5)41Uw1(:9)%$P7%$;>*##B^>*A+D0#&%@!G#>*.0%G%$.0)3)5;41(+#&!$%;J'&'&9)!=>9)D 1.0A+D0#O1.0>*#&%$bWc=()#qM;:;%21.0)3}1!$.0).0)3C%G#B1%=!$#D0%$;r%$>*A)D0#&%W;<+1()#};!G.03.0)D5)41d%G#B1Ps?)91W1()#@4(+!$5)*#B>*A)D0#/LN#B^>rA)D0#Qa;J'&'&9+!$%>r;!$#7.0D041#&!Z1!G.0).0)3@%$#B1%%$.0)'&#}MO;:;%21.0)3*'&;)'&#&1!$41#&%q;m'&;!$!G#&'B1D A)!$#&5).0'B1.0)3C. 1b;<)%$#&D0#&'B1.0+3#B>*A)D0#O.0%);41W#&8:9)DJ'&!G;%$%1()#1!$.0).0)3q%$#B1bOcW().0%RA)!$;?+?).0D0. 1I5)#&A^#&)5)%;K();;<e1#&I1()41d#B>*A)D0# %}>*.0%$'&D0%G%$.0F)#&5?u1(+#CA)!$#B,.0;9)%7'&D0%$%$.0F)#&!$%Gb/5)4EGMO;:;%21.0)3m'&9)%$#1()#A)A+!$;'G(C;<_LNa_%$#&D0#&'B1.0)3}%G#B1=;<+#B>*A)D0#&%Z?)%G#&5C;w1()#A)!$;?)?+.0D0. 1.0#&%Z;<1()##B>*A)D0#&%GP);!LN?)a_%$.0>rA)D I9+%$.0)3qD0D);<J1()##B>*A)D0#&%H+5 #&.03(1H1()##&!G!$;!Z;<#&'G(r#B>*A)D0#=? 1()#A)!$;?+?).0D0. 1<N;!W1()41/#B>*A)D0#LN.0b0#&b0P=#B^>*A+D0#&% . 1(().03(+#&!7A)!$;?+?).0D0. 1.0#&%K()-,+#@>*;!$#@#&#&'B1/;u1()#d#&!G!$;!$a-bcW().0%D041-1#&!WA)A+!$;'G(/()%s1()#w'&D0#&!5, 13#1()41q#&'(m#B>*A)D0#q.0%O.0)'&;!$A^;!$41#&56LN417D0#&%21}.0A)!21a.01()#1!$.0).0)3%$#B1bW+9)!21()#&!$>r;!$#&P^)!$.0#&5)>*I#B1}D0bLNQSSXa()$,+#5)#&>*;)%o1!$41#&51()41O1().0%<N;!$>;<^5+4EGM;:;%21.0)3'&r?^#R,.0# #&5@%H}<N;!$>;<^5)5+. 1. ,+#=>*;:5)#&D0.0)3<N;!H;A1.0>r.0&.0)37}D0;3.0%o1.0'D0;%$%Z<N9))'B1.0;+bBw1().0% ;!$t:P)(); #B,+#&!$P #(+-,+#W'();%$#&q1;}9+%$#s1()#A)A)!$;'(*;<%$9)?)%$>rA)D0.0)31()#5)411;I#&)%$9)!G#@<.0!#&>rA).0!$.0'&D'&;>*A)!$.0%G;LN.0A+!21K5+9)#W1;1()#!$#&%21!o1.0)3I!$#&%$;5).0%$'&9+%$%$#&5?^#&D0; a-bMO;41(!G'&.0)3I)5w5)4EGMO;:;%21.0)3I.0). 1.0D0D %G#B11()#A)!$;?+?).0D0. 1;<_A).0'Gt:.0)3I#&'G(#B>*A)D0#=1;?^#7Q&bCcW()#&%$#>*#B1();:5)%H1()#&!$#&'&D0'&9)D041#w1()#&%G#A+!$;?)?).0D0. 1.0#&%q<e1#&!#&'G(@1!$.0)#&5'&D0%$%G.0F)#&!.0%5)5)#&51;@1(+#@#&+%$#&>?+D0#&b);!r5)4EGMO;:;%21.0)3PqD0#B1?^#}1()#/%G9)>;<Z1()#IA)!G;?)?).0D0. 1.0#&%*;<H1()#fistv{wz{y{t>*.0%$'&D0%G%$.0F)#&5/.0)%21+'&#&%<;!s1()#q'&9)!$!G#& 1D *1!G.0)#&5/'&D0%$%$.0F)#&!W:bcW()#wA)!$;?+?).0D0. 1.0#&%<;!s1()#q)#B:11!$.0DZ!G#*3#&)#&!$41#&5? >9+D 1.0A)D ^.0+3K1()#CA)!$;?+?).0D0. 1.0#&%7;<OJ0%7.0)'&;!$!$#&'B1D ]'&D0%$%G.0F)#&56.0)%21+'&#&%?1(+#*<'B1;!=+uLNQ}Ja$+5I1()#&6!$#&+;!$>*D0.0&.0)3D0DHA)!$;?+?).0D0. 1.0#&%7%$;C1()41}1()#&.0!%$9)>#&8:9)D0%rQb"w5)4EGMO;J;%o1.0)3'&;>?).0)#&%}1()#/'&D0%$%$.0F)#&!G%r $&&&& 9)%$.0)3 #&.03( 1#&5,+;41.0)3 ()#&!$#()% #&.03(1uD0;3+L +a-bcW()#&%$# #&.03(1%CD0D0; w5)4EGMO;J;%o1.0)3d1;5+.0%$'&;9)171()#@A)!$#&5).0'B1.0;+%;<'&D0%$%$.0F+#&!$%1()41I!$#*);417,+#&!2g'&'&9)!$41#@;I1()#r;$,+#&!$D0DA)!$;?)D0#&>*bu)!$.0#&5)>*#B1@DLNQSSXaK()$,+#D0%$;*%G9)33#&%21#&5uuD 1#&!$)41. ,+#>*#&'G()+.0%$>1()417F1%1;3#B1()#&!H1()#A)!$#&5).0'B1.0;+%=;<+1()#}'&D0%$%$.0F+#&!$%%=u5)5). 1. ,+#}>*;:5)#&D9+%$.0)3K*>*4.0>9+>D0.0t#&D0.0();:;J5'&!$. 1#&!$.0;)bB1().0% ;!$tJP #9+%$#d1()#!$#B,^.0%G.0;5)#&%$'&!$.0?^#&5?MO!$#&.0>*LNQSST?)a ()#&!$# #!G#&%$#B1D0D1()# #&.03( 1%C1;?##&8:9)D)5!$#&%21!o1.0<#&. 1()#&!m].0%m+;41D0#&%G%K1()"{b0;!m?^#&'&;>*#&%m{b $Msg!$#&%$#B1-1.0)3K1(+# #&.03(1% #C5);m+;41r5).0%$5, 13#}1()#Cw5)4EGMO;J;%21.0+3uD0#&!$)#&!7.0I1();%$#*'&%G#&%()#&!G#w. 17!G#&'G()#&%Z1()#&%$#,D09)#&%;<RJU:1(+#ww5)4EGMO;:;%21.0)3*D0#&!$+#&!WD $^%.0)'&;!$A^;!$41#&%1(+#%$>*#:9)>?^#&!_;<'&D0%$%$.0F)#&!G%H%Z;41()#&!>*#B1();:5)% #R1#&%21#&5)bcR;}>*t#1(+.0%Z<#&%G.0?)D0#&P #!$#W<N;!$'&#&5q1;79)%$#1()#CA)A+!$;'G(6;<%$#&D0#&'B1.0)3u/5)41m%$#B1rA)!G;?)?).0D0.0%21.0'&D0D g!$41()#&!1(+ #&.03(1.0)3K1(+#C#B^>*A+D0#&%$P;41()#&! .0%$#}5)#B1#&!$>r.0).0%21.0'>*#B1();:5*%$9+'G(C%HV=b0 ;9)D05r'B^'&D0#W+5*3#&)#&!$41#W5+9)A)D0.0'&41#W>*#&>?^#&!$%;<1()#C#&)%$#&>?)D0#&b/cW()41r.0%GPH!$#&%$#B1-1.0+3K1()# #&.03( 1%W1;mQ& ;9)D05'&9+%$#q1()#CD0#&!$+#&!O1;m!$#&A^#&411()#65+#&'&.0%$.0;1!$#&#D0#&!$)#&5%*1()#6F)!$%o1>*#&>?^#&!/;<1()#6#&+%$#&>?+D0#&PC)51().0% ;9)D05D0#&5g1;!$# #&.03( 1.0+3*1()#r5)41u%$#B11()#*%$>r#r%7<N;!1(+#*%$#&'&;)5>*#&>?^#&!;<1(+#r#&)%$#&>?)D0#&P)56%$;;)b=+5);>*D %$#&D0#&'B1.0+3C#B^>*A+D0#&%<;!R1()#w5)41K%$#B1}?)%$#&5I;1()#w#B>*A)D0#qA)!$;?)?+.0D0. 1.0#&%D0D0#B,^.041#&%1().0%WA+!$;?)D0#&>*bw!$'&.0)34Eo6LNM!G#&.0>*)PQSST?)a*L ().0'( # .0D0Ds!$#&<N#&!H1;d%$.0>rA)D %q!$'&.0+3a%21!o1#&5;91K%q%$.0>*A+D0#C>*#&'G()+.0%$> <N;!}#B,D09+41.0)3K1()#C#&#&'B1@;<MO;J;%21.0+3m>*#B1();:5)% ()#&!G#w1()#C!$#&%$9)D 1.0+3/'&D0%2E%$.0F)#&!G% #&!$#u'&;>?).0+#&5 . 1();91 #&.03(1.0)3I1()#,+;41#&%$b!$'&.0+39)%$#&%*%$.0>rA)D0#/>*#&'G(+).0%$><N;!5)#B1#&!$>r.0).0)3O1()#A)!$;?)?+.0D0. 1.0#&%;<.0)'&D09+5).0)3}#B>*A)D0#&%.01()#_1!$.0).0)3%$#B1b);!1()# 1(d#B^>rA)D0#.0K1()#1!$.0).0)3*%G#B1P1()#O,D09)# !$#&<N#&!$%1;1(+#J9)>?^#&!W;<+1.0>*#&%_1()41K#B^>rA)D0# %=>*.0%$'&D0%G%$. EF)#&5? u1()#A+!$#B,^.0;9+%q'&D0%$%$.0F)#&!$%Gbc=()#7A)!G;?)?).0D0. 1W<N;!%G#&D0#&'B1.0)3/#B^>rA)D0# 1;I?^#7A+!21K;<'&D0%$%$.0F+#&!gQ0%_1!G.0).0)3C%$#B1.0%5)#&F))#&5/%QWmff$LNQWLNQaMO!$#&.0>*'G();%G#1()#},D09)#r;<R1()#*A^; #&!ILNa#&>*A).0!$.0'&D0D <1#&!=1!2.0)3m%$#B,+#&!$D5).0#&!$#&17,D09)#&%LNMO!$#&.0>*)PQSST?+a-bD 1();9+3(u1(+.0%>*#&'()).0%$>5);:#&%K);41/()-,+#1()# #&.03(1#&5,+;41.0)3;<Ww5)4EMO;J;%o1.0)3I. 1K%21.0D0DA)!G;J5)9+'&#&%='&'&9)!$41#K#&)%G#&>?)D0#&%q)5.0%q%$.0>*A)D0#=1;@.0>*A)D0#&>*#&1U1(J9+% #.0+'&D09)5)#1().0%W>r#B1();J5LND0;)3 . 1(u5)4EGMO;:;%21.0)3a.0m;9)!W#&>*A+.0!$.0'&D#B,D09)41.0;)b.039)!$#C`/%G(); %7/( A^;41()#B1.0'&DZ!$9);<MO;J;%21.0+3b/;41#q1(+411()#CF)!$%21q1!$.0+.0)3/%$#B1 ;9)D05?^#w1()#r%G>*#*%7MO33.0)3U=(); #B,+#&!$POD041#&!W1!G.0).0)3m%$#B1%'&'&#&19)41#d#B>*A)D0#&%=1()41 #&!$#d>*.0%2E'&D0%$%$.0F+#&5g? 1()#I#&!$D0.0#&!*>*#&>?^#&!K;<Z1()#I#&)%G#&>?)D0#&%GbB1().0%CF)39)!$#&P=#B^>*A+D0#/Q.0%C]4(+!$5)#B>*A)D0#H1()41qA+!$#B,^.0;9+%'&D0%$%G.0F)#&!$%1#&)5}1;>*.0%$'&D0%G%$.0<b_\. 1(1()#w%$#&'&;)571!$.0).0)3%$#B1P#B^>rA)D0#Q7;:'&'&9)!$%>9)D 1.0A)D0#H1.0>*#&%$P^%5+;7#B>*A)D0#&%O7)5@7%G.0)'&#Z1(+#B #&!$#D0#&<1;91;<:1()#=F+!$%21H1!G.0).0)3%$#B1+5)P^.0K1().0%W'&%$#&P>*.0%$'&D0%$%$.0F+#&5u?d1()#F+!$%21}D0#&!$)#&!$b=);!_1()#F+)D:1!$.0).0)3C%G#B1P#B^>rA)D0#}Qfi "! #$%& '(*)+ !$,- .0/213 *4#. 3fi56789 913;:<<=3,->13?@94#A13#BC>+=3=3DED;#139GFIHKJLM/KN ( :PORQEST.FU< =3BGC4 WV XYZ; A[,-W1\=3YE$1\?]! #$&$0' ( =313#B C#V^. 3_/2#>4>a`G=3,-# 13?b_6cd94 913;:d<@!e4@fX$=\BGg>4 h=3! =3V)G?i#jD ?i,-#1\1k>+=\=3DEgD#1\94/. 3..fi:l# P#Vj94=\V4Bg#@V4 B#=3DE-0.C< =3BG*2#! g/2=3*>4mh9!$ hj13=3BG13?])+$ * 913P#V]4#13 V4#*#>>#!n k=3V@>4=\13o94h=3 ;:Zpfir+su}SmQzrvr++z?^#&'&;>*#&%H1()#7A)!G#&5);>*.0)1#B>*A)D0#'G();%$#&gL (+#&!$#&%+;*%$.0)3D0##B^>rA)D0#7.0%w'&'&#& 19+41#&5 . 1(MO33.0)3a-U1(:9)%$PJ1()#w;-,+#&!$D0D:1#&%o1-EG%$#B17#&!$!$;!<;!s1().0%O'&D0%$%G.0F)#&!O>*.03( 1}?^#&'&;>*#H,+#&!2().03(+bw#&%GA). 1#1().0%$P(); #B,+#&!GPZMO;J;%21.0+3 .0D0DA)!$;?)?)D ;?1.0@D0; #&!7#&!$!$;!q!$41# ()#&. 1*'&;>?+.0)#&%1()#;91-EA)91K;<^1()#&%$#<N;9)!q'&D0%$%$.0F)#&!$%q%$.0+'&#. 1C<;:'&9)%$#&%q;'&;!$!$#&'B1D A)!$#&5).0'B1.0+3dA)!G#B,^.0;9)%GD >*.0%$'&D0%$%G.0F)#&5#B>*A)D0#&%W)5 #&.03( 1%Z1()#qA)!$#&5).0'B1.0;+%;<1()#5).0#&!$#&1}'&D0%$%$.0F)#&!$%=?)%$#&5/;1()#&.0!'&'&9)!G'B<N;!1()#1!$.0).0+3@%G#B1b*MO91*M;:;%21.0)3/'&D0%$;/;$,+#&!$F1r.0d1()#KA)!$#&%G#&)'&#K;<Z);.0%$#uLN% #K#&>*A).0!$.0'&D0D%$(); .0my)#&'B1.0;[a-b+rqtsvuRxw4dhdhd+lc/g<ylqhoqh=#&'&#&1D P^%$#B,+#&!$D91();!$%LNMO!$#&.0>r)P+QSST?)U^)!G.0#&5)>*)PQSSTU|7;()-,.)x\];D0A^#&!21PQSSTU^|};)3xq.0#B1-1#&!$.0'()PQSSaK()-,+#dA)!$;A^;%$#&5I1(+#&;!$.0#&%<N;!1(+#r#&#&'B1. ,+#&)#&%$%K;<MO33.0)3+5MO;J;%o1.0)3?)%$#&5;7#&>*#B1KD0b00%*LNQSS`aw?+.0%A)D09+%,!G.0)'&#5+#&'&;>*A^;%$. 1.0;;<_'&D0%G%$.0F)'&41.0;#&!$!$;!GbwB1().0%w5)#&'&;>*A^;%$. 1.0; #'&r,^.0# 1()#7#BA^#&'B1#&5#&!G!$;!;<_dD0#&!$).0)3@D03;!$. 1()>;dA)!o1.0'&9)D0!z;{ $ |:f zo}~ dh z h/+5 z { h)Nh |*if z iGv jfW%W()-,.0)3q1(+!$#&#}'&;>*A^;)#&1%$Qb}l- {1#&!$>>*#&%$9)!$.0+3(); '&D0;%G#H1(+#$,+#&!$3#'&D0%$%$.0F)#&!OA)!G;J5)9+'&#&5r?C1()#D0#&!G).0)3D03;4E!G. 1()> .0D0D?^#1;q1(+#1!$3#B1<N9))'B1.0;)U`b} { 4 { hdGfW1#&!$> >*#&%$9+!$.0)3(); >9+'G(#&'G(;<R1()#@D0#&!$).0)3D03;!$. 1()>r0%39+#&%$%$#&% .0D0D,!2 . 1(m!G#&%$A^#&'B11;*#&'G(;41()#&!LN(); ;<e1#&C1()#B5).0%$3!G#&#&a-U)5[b}1#&!$>>*#&%$9)!$.0+31()#W>*.0).0>9)>'&D0%G%$.0F)'&41.0;@#&!$!$;!Z%$%G;J'&.041#&5 . 1(q1()#=M$+#&%;A1.0>*D'&D0%G%$.0F)#&!K<;!=1()#}1!$3#B1m<9)+'B1.0;Le1().0%1#&!$> .0%%$;>*#B1.0>*#&%K!$#&<N#&!$!$#&5u1;%=1()#@.0 1!G.0)%$.0'1!G3#B1);.0%$#&a-bw%$.0)31().0%_<N!$>*# ;!$t7. 1W()%?^#&#&K%$9)33#&%21#&5LNMO!$#&.0>r)P)QSST?)a1()41=?^;41(KMO33.0)3)5CMO;:;%21-E.0)3!$#&5)9+'&#@#&!G!$;!K? !$#&5)9)'&.0)3r1()#,!$.0)'&#1#&!$>*b])!$#&9))5)5y)'()A).0!$#6LNQSSTa*!G39)#1()41MO;J;%o1.0)3CD0%$;K41-1#&>*A1%R1;C!$#&5+9)'&#Z1(+#w#&!G!$;!O.071(+#?).0%R1#&!G>%G.0)'&#q. 1<N;:'&9)%$#&%O;/>*.0%$'&D0%$%G.0F)#&5#B>*A)D0#&%$bWy+9)'G(IK<;:'&9)%>*$'&9)%G#1()#qD0#&!$)#&!R1;KA)!$;:5)9)'&#w/#&)%$#&>?)D0#q<9+)'B1.0;1()41}5).0#&!$%%$.03).0F+'& 1D <!$;>1()#d%$.0)3D0#@D0#&!$).0)3D03;!$. 1()>*bB<N'B1PMO;J;%21.0+3>r-'&;)%o1!$9)'B1/<N9))'BE1.0;C1(+417.0%=);417#B,+#&A)!$;:5)9)'&.0?)D0#q?. 1%W'&;>rA;+#& 1D0#&!G).0)3CD03;!$. 1()>LN#&b03b0P'())3.0)3dD0.0)#&!A)!$#&5+.0'B1.0;)%q.0 1;II'&D0%$%$.0F)#&!1()41*'&;1.0)%);EGD0.0+#&!wA+!$#&5).0'B1.0;)%$a-bK 1K.0%1(+.0%'&A)?+.0D0. 11()41>*t#&%MO;:;%21.0)3CIA)A)!$;A+!$.041#D03;!G. 1()><;!O'&;>?).0).0)31()#qA)!G#&5).0'B1.0;)%O;< #&tJ*D0#&!G).0)3D03;!$. 1()>r%LN.0b0#&b0PRD03;!$. 1()>*%Z1()41()$,+#7*%$.0>rA)D0#D0#&!$).0)3r?).0%$a-bWBK1()#&.0!W!G#&'&#& 1KA)A^#&!$PMO9)#&!)5@|};()$,^._LNQSSSa5)#&>*;)%o1!$41#&51()41qMO;:;%21.0)3K5);:#&%.0+5)#&#&5d%G#&#&>1;K!$#&5+9)'&#=?).0%O<N;!'&#&!o1.0!$#&D ;!$D05/A)!$;?+D0#&>*%$b;!$#%$9)!$A+!$.0%$.0)3D PJ1()#BD0%$;*%$(); #&51(+417M33.0+3r'&/D0%$;*!G#&5)9)'&#1()#?).0%WA^;!21.0;u;<+1(+##&!$!$;!$P;<e1#&m<N;!_1()#%G>*#}5)41*%G#B1%=<N;! ().0'(mMO;J;%21.0+3r!$#&5)9+'&#&%1()#?).0%$bcW(+;9)3(d1()#K?).0%2Eo,!$.0)'&#C5)#&'&;>*A^;%$. 1.0;.0%q.01#&!$#&%21.0)3P1()#&!$#K!$#K'&#&!21.06D0.0>*. 141.0;+%O1;A)A)D .0)3/. 1}1;!$#&D E ;!$D055)41u%$#B1%$bucR;m?^#K?)D0#q1;#&%21.0>*41#1(+#*?).0%$P,!$.0+'&#&PH)5I1!G3#B1);.0%$#7<;!rA)!21.0'&9+D0!=A)!$;?+D0#&>*P #})#&#&5C1;dtJ+; 1(+#}'B19)DR<9)+'B1.0;m?^#&.0)3*D0#&!$)#&5+bcW(+.0%W.0%9))$,.0D0?+D0#<N;!q>*;%21C!$#&D E ;!$D05A)!$;?)D0#&>r%$bcR;I5)#&D . 1(d1().0%qA)!$;?)D0#&>|};()$,^.)5r\];D0A^#&!21LNQSSTam%$9+33#&%216();D05).0)3;916%$;>*#;<1()#5)41P=1()#A)A)!$;'("9)%$#&5? M9+#&!@+5|7;()-,.LNQSSSa.0@1()#&.0!7%219+5bIcW()#C>*.06A+!$;?)D0#&> . 1(/1().0%O1#&'G(+).08J9+#*.0%O1()41}1(+#w1!$.0).0)3/%$#B1@%$.0&#.0%w3!$#&41D !$#&5+9)'&#&5u.0;!$5)#&!Z1;d3#B1C3;J;:5#&%21.0>*41#&%;<1()#?).0%+5*,!$.0)'&#=1#&!$>*%$b\]#K()$,+#'G(+;%$#&K1;K%21!$.0'B1D <;:'&9)%;/3#&)#&!GD0.0&41.0;u'&'&9)!$'B.0/;9)!%219+5P^.0@A+!21}?#&'&9+%$#qM9+#&!W)5|};()$,^.00% ;!Gtd()%=)% #&!$#&5K1()#}8:9)#&%21.0;u?;91 ()#B1()#&!WMO;:;%21.0)3*+5mMO33.0)3r!$#&5+9)'&#1()#fffistv{wz{y{t?).0%<;!!$#&D ;!GD05A+!$;?)D0#&>*%ILe1()#B?^;41(5+;a-P)5?^#&'&9)%$#71()#&.0!#B^A^#&!$.0>r#& 1%5)#&>*;)%o1!$41#1()41 ().0D0#O1().0%w5)#&'&;>*A^;%$. 1.0;3. ,+#&%w%$;>*#7.0+%$.03( 1K.0 1;@#&)%$#&>?)D0#>*#B1();:5)%$P. 1K.0%=;)D *%G>*D0DA)!21=;<1()#W#&8:9)41.0;)bO);!5).0#&!$#& 1w5)41}%$#B1%^1(+#B/;?+%$#&!2,+#'&%$#&% ()#&!$#OMO;:;%21.0)3})5rM33.0+3?^;41(r5)#&'&!G#&%$#q>*;%21D C1()#H,!G.0)'&#A^;!21.0;d;<1()##&!$!$;!$P)5r;41(+#&!'&%G#&% ()#&!$#WMO;:;%21.0)3K)5MO33.0)3m?^;41(!$#&5)9)'&#1()#K?).0%q)5@,!$.0)'&#C;<1()#K#&!$!$;!$bCc=()#&.0!1#&%21%D0%$;/%$#&#&>1;/.0+5).0'&41#1()417MO;:;%21.0)30%W3#&)#&!GD0.0&41.0;#&!$!G;!.0+'&!$#&%$#&%W;1()#q5);>r.0)% ()#&!$#qMO;:;%21.0)3C.0)'&!$#&%G#&%1()#,!$.0)'&#7A^;!21.0;;<1()#}#&!$!$;!GU?)91P. 1.0%=5).0r'&9)D 1=1;*5+#B1#&!$>*.0)# ()41%$A^#&'B1%;<+1(+#75)41d%$#B1%D0#&5K1;}1()#&%$#!$#&%$9+D 1%$bjc ().0%=%$#&'B1.0;5+#&%$'&!$.0?^#&%W;9)!W#&>rA).0!$.0'&D%o19)5;<RMO33.0)3PRw5)4EGMO;J;%21.0+3Ps)5u!$'&.0+3b=H'(;<W1()#&%$#1()!$#&#>*#B1();:5)% %_1#&%o1#&5 . 1(m?^;41(m5+#&'&.0%$.0;C1!$#&#&%)5/)#&9)!GD)#B1 ;!$t:%$bq+$"sgocedo*dcR;r#B,D09)41#1()#7A^#&!$<N;!$>*)'&#7;<_M33.0+3@+5MO;:;%21.0)3P #;?1.0)#&5r:9)>?#&!;<_5)41@%$#B1%<N!$;>1()#u). ,+#&!G%$. 1;<\.0%$'&;)%$.0'G().0)##&!G).0)36!$#&A^;%$. 1;!o"% #&D0D=%71()#mwVWK5)41%$#B1*!$#&A^;%$. 1;!2LN9)!$A+( xw()PQSSa-b*cW()#&%$#5)41@%$#B1% #&!$#(+)5%G#&D0#&'B1#&56%$9)'(*1()41q1()#BLNaZ'&>*#=<!$;>!G#&D E ;!$D05dA)!$;?)D0#&>r%$PLN?)a,!$.0#&5*.0C'G(+!$'B1#&!$.0%21.0'&%$P^)5uLN'&a #&!$#5+#&#&>*#&5*9)%$#&<N9)D?A)!G#B,^.0;9)%7!$#&%$#&!$'()#&!$%$b/cR?)D0#*Q/3. ,+#&%=1()#C'G(+!$'B1#&!$.0%21.0'&%K;<;9)!}5)41m%G#B1%$b/cW()#C5)41u%$#B1%'G(+;%$#&d,!2'&!G;%$%qr:9)>?^#&!;<Z5).0>*#&)%G.0;)%=.0)'&D09+5).0)31()#=1A#;<^1()#<#&419)!G#&%w.0r1()#5)41%$#B1]LN.0b0#&b0P7'&;1.0J9+;9)%$P75+.0%$'&!$#B1#&P};!@>r. ;<1()#r1 ;a-Uw1()#:9)>?^#&!r;<};91A+91'&D0%$%G#&%$UC)51()#K:9)>?^#&!w;<Z#B>*A)D0#&%.0d1()#K5)41I%$#B1bCcR?)D0#KQ@D0%G;@%G(); %1()#K!$'(). 1#&'B19)!$#C+5r1!G.0).0)3A)!$>r#B1#&!$%=9)%G#&5/.0m;9)!W)#&9+!$D)#B1 ;!$t:%=#BA^#&!$.0>*#&1%$bq+2goq8=#&%G9)D 1%$Pq9))D0#&%$%r;41()#&! .0%$#u);41#&5)Pw!$#m-,+#&!G3#&5;$,+#&!dF,+#m%21)5)!G5gQ{4EG<;D05'&!$;%$%},D0.05+41.0;#BA#&!G.0>*#& 1%Gb+;!#&'(dQ{4EG<N;D05I'&!$;%$%,D0.05)41.0;71()#=5+41}%$#B1w.0%F)!$%21=A+!21. 1.0;)#&5@.0 1;Q{7#&8:9)D E%$.0&#&5%$#B1%GP_1()#&#&'(g%$#B1m.0%C.019)!$9)%$#&5%w1()#1#&%21u%G#B1 ().0D0#1()#/'&D0%$%$.0F)#&!w1!G.0)%C;1()#;41()#&!O).0)#w%$#B1%$b+;!#&'G(/<N;D05dI#&)%$#&>?)D0#q;<`'&D0%$%$.0F)#&!G%.0%'&!G#&41#&5)bWVW!$;%G%,D0.05)41.0;/<N;D05)%#&!$#rA^#&!$<N;!$>*#&56.0+5)#&A^#&)5)#&1D <N;!#&'(D03;!G. 1()>*b@\]#71!$.0)#&5/1(+#r)#&9)!GDZ)#B1 ;!$t:%9+%$.0)3%21)5+!$5?+'Gt:A)!$;A)341.0;D0#&!G).0)3"LN=9)>*#&D0(+!21P7vw.0 1;+P7x\.0D0D0.0>*%GPQSXTa-bY!$>r#B1#&!%$#B1-1.0)3%7<;!1()#K)#&9)!GDs)#B1 ;!GtJ%.0)'&D09+5)#K@D0#&!G).0)3@!$41#C;<H{b0QPZI>*;>r#& 19)>z1#&!$>;<{b0SP)5 #&.03(1%K!$#@.0). 1.0D0.0&#&5!$)5);>rD 1;?^#r?^#B1 #&#&EG{b0)5{b0bcW()#dJ9+>?^#&!7;<(+.05)5)#&9)). 1%q)5#&A^;:'G()%q9)%$#&5<N;!1!$.0).0)3I!$#3. ,+#&6.0d1()#K)#B:1K%$#&'B1.0;+b\]#K'G();%G#w1()#KJ9)>?^#&!;<().05)5+#&d9)+. 1%?)%G#&5@;1()#w:9)>?^#&!;<.0)A)91q)5@;91A)91q9)+. 1%$bOcW().0%O'G();.0'&# %?)%$#&5I;1()#'&!$. 1#&!$.0;<O()-,.0)341@D0#&%21/;)#r(+.05)5)#&69)+. 1dA^#&!};91A)91P41@D0#&%o1@;)#d().05)5)#&69+). 1d<N;!7#B,+#&!21#&/.0)A)91%$P+5/F,+#q().05)5)#&@9)). 1%O?^#&.0)3KK>*.0).0>9)>*bcW()#w:9)>?^#&!;<#&A^;:'G()% %?)%$#&5/?^;41(;d1()#J9)>?^#&!=;<Z#B>*A)D0#&%q)5d1()#:9)>?^#&!;<ZA)!$>*#B1#&!G%CLN.0b0#&b0P1;A^;D0;34a;<^1()#)#B1 ;!$t:by)A^#&'&.0F)'&D0D P #9)%G#&5rT{=1;X{K#&A^;J'()%<;!%$>*D0DA)!$;?)D0#&>*%.0,+;D ,^.0)3K<N# #&!1()I`{#B^>*A+D0#&%$U{/#&A^;J'()%<N;!O1()#K>*.05EG%$.0&#&5A)!$;?)D0#&>*%'&;1.0).0)3u?#B1 #&#&`{K1;/{{m#B>*A)D0#&%$U)5`{1;{#&A;:'G(+%<N;!D0!G3#&!A)!$;?)D0#&>*%Gb+;!1(+#=5)#&'&.0%$.0;1!$#&#&% #9+%$#&5}1(+#VWb0=1;:;DLN}9+.0)D0)PQSS[a)5dA)!$9))#&5w1!G#&#&%qL (+.0'G(r#&>rA).0!$.0'&D0D uA)!$;:5)9)'&#?^#B1-1#&!A#&!G<;!$>r)'&#&aZ%%$9)33#&%21#&5@.0r}9+.0)D0)0%;!$tJb*fiq41ry)#B1?)!$#&%o1-EG'&)'&#&!2E'&!$#&5). 1-EG'&!$#&5). 1-EG35).0?^#B1#&%3D0%$%()#&!21-EG'&D0#B,+#&D0+5()#&A)41. 1.0%();9)%G#BEo,+;41#&%2EGX(^A^;.0;);%$A+()#&!$#.0!$.0%t:!2Eo,^%oEGtJAD0?^;!D0#B1-1#&!A)!$;>r;41#&!$%2EGS[T!$.0?^;%$;>*#BEG?+.0)5%$41#&D0D0. 1#%$#&3>*#&141.0;%$.0'%$;)!%$;$^?^#&%$A)D0.0'&#,+#&().0'&D0#V=%$#&%TSSTS{Q{{{TX`Q[{[Q[[`[QQS[QST`{{{{S[TQXT[`[Q{[``{XTX[[QS{XTr+su}SmQzrVWD0%$%````````[```T````QS[)#&419)!$#&%VW;1q.0%$'EQ[EEXQ[EQT``[EEE[TXXQTEEE[TEQSE``T{EE[ET{QXEvr++zB)A)91%T[XQ[[`QT[`SQT``XQST[TQST{Q[`{QX#&9)!GD#B1 ;!Gt91A)91%vw.05)5)#&)%QQQ{QQ{QQ{QQQ{QQQQ{[QQQQ{`T{Q`{Q`{QQQQ{QQ{QS```Q{HA^;J'()%`{[[{[{X{{T{{{{X{`{X{[{[{[[{`{{T{{[{{cR?)D0#}Q}y)9+>*>*!2r;<1(+#5)41q%$#B1%9)%G#&5.01().0%A)A^#&!$by)(); !$#s1()#:9)>?^#&!R;<)#B>*A)D0#&%.01()#w5)41K%$#B1U:1()#w:9)>?^#&!;<;91A)91q'&D0%$%G#&%$U:1()#qJ9+>?^#&!;<'&; 1.0:9);9)%+5d5).0%G'&!$#B1#.0)A+91<N#&419)!$#&%$U+1()#J9)>?^#&!W;<_.0)A)91P;91A)91P)5().05)5)#&9)). 1%=9+%$#&5.0*1()#7+#&9)!$D)#B1 ;!GtJ%Z1#&%21#&5)U+5/(); >* #&A^;J'()%W#&'()#&9+!$D)#B1 ;!$t %_1!$.0)#&5+bq+rq"sgox%cedo*d:cR?)D0#Z`W%$(+; %)1#&%21-EG%$#B1#&!G!$;!!$41#&%s<;!)1()#_5)41=%G#B1%5)#&%$'&!G.0?#&5.07cs?)D0#QW<N;!F,+#Z)#&9+!$D)#B1 ;!$t>*#B1();:5)%q)5<N;9)!q5)#&'&.0%$.0;@1!$#&#K>*#B1();:5)%$bmLNBcs?)D0#&%I)5 #%G(); 1()#&%$#K#&!$!G;!!$41#&%%#&D0Ds%1()#%21)5)!G5u5)#B,.041.0;<;!w#&'G(;<^1(+#&%$#W,D09)#&%$b0aD0;+3 . 1(d1()#W1#&%21-EG%$#B1*#&!$!$;!G%<N;!MO33.0)3P!$'&.0+3PZ)5w5)4EG?^;J;%21.0+3P #C.0+'&D09)5)#1()#w1#&%21-EG%$#B1@#&!$!$;!!$41#*<N;!/%$.0)3D0#C+#&9)!$D E)#B1 ;!$t)5d%$.0+3D0#5)#&'&.0%G.0;Eo1!$#&#C'&D0%$%$.0F+#&!$bW\]#KD0%$;I!$#&A^;!21K!$#&%$9)D 1%w<N;!w@%$.0>*A+D0#ILN?)%G#&D0.0)#&a)#&9)!GD EG)#B1 ;!$t@#&)%$#&>?)D0#A)A)!$;'(Ku'&!$#&41.0)3r/#&)%$#&>?)D0#;<s+#B1 ;!$tJ% ()#&!$#q#&'G()#B1 ;!$t,!$.0#&%7;)D g?!G)5);>*D .0). 1.0D0.0&.0)3r1()# #&.03( 1%;<s1()#*)#B1 ;!GtJb*\]#r.0)'&D09)5+#w1()#&%$#*!$#&%G9)D 1%.0/'&#&!21.0'&;>*A)!$.0%$;+%R1;C5)#&>*;)%21!G41#1()#&.0!W%$.0>*.0D0!G. 1I1;CMO33.0)3b +#w;?,.0;9)%W'&;)'&D09)%G.0;5)!$ <!$;>z1()#!$#&%$9+D 1%w.0%1()41*#&'(6#&)%$#&>?)D0#>*#B1();:5A+A#&!G%Z1;I!$#&5)9+'&#W1()##&!$!$;!q!$41#K<N;!D0>*;%21uD0D=;<_1()#/5)41%G#B1%$P=)5.0>*"'&%$#&%q1().0%C!$#&5+9)'B1.0;g.0%CD0!$3#&b<N'B1PH1()#1 ;4E1.0D0#&5%$.03r1#&%21K.0+5).0'&41#&%1()41#B,+#&!2#&)%$#&>?)D0#7>*#B1(+;J5.0%%$.03+.0F)'& 1D ?#B1-1#&!H1(). 1%%G.0)3D0#fistv{wz{y{t#&9+!$Dw#B1 ;!$tq41ry)#B1?)!$#&%o1-EG'&)'&#&!2E'&!$#&5). 1-EG'&!$#&5). 1-EG35).0?^#B1#&%3D0%$%()#&!21-EG'&D0#B,+#&D0+5()#&A)41. 1.0%();9)%G#BEo,+;41#&%2EGX(^A^;.0;);%$A+()#&!$#.0!$.0%t:!2Eo,^%oEGtJAD0?^;!D0#B1-1#&!A)!$;>r;41#&!$%2EGS[T!$.0?^;%$;>*#BEG?+.0)5%$41#&D0D0. 1#%$#&3>*#&141.0;%$.0'%$;)!%$;$^?^#&%$A)D0.0'&#,+#&().0'&D0#y1[b0Qb0X`b0S`[b0S[Xb0TQXb0T`{b0Qb0STb0Sb0b0[`b0[Tb0QQXb0{b0[Sb0[Q[b0{Tb0Tb0SQTb0TSb0`b0`b0Sy).0>rA[b0Q[b0`b0`[b0{[b0`Qb0QSb0b0XTb0`b0[b0S{b0X[b0`Q`b0Xb0XXb0Q{b0Sb0[b0Qb0STb0b0{`Qb0`;J;%21.0+3w!$'w5)[b0Xb0{Qb0XQb0`b0``b0[`b0`[b0[[`b0{[Qb0Q`{b0`Qb0QQSb0{QSb0b0Qb0[Tb0`Tb0`b0TXb0[[b0[b0S{b0{b0[[b0`[b0`b0b0Tb0b0TXb0QXb0`Sb0SQ{b0{[b0[b0[b0b0Q`b0SQ[b0{Tb0Tb0[b0{b0`QSb0QQSb0MO3[b0Q[b0X`b0```b0X[[b0QQb0{Qb0Xb0QTb0`Sb0`b0{{b0Xb0`Q{b0b0{Xb0Q{b0Tb0b0QTb0XTb0S[b0S`{b0V=b0y1b0{Qb0S`Sb0T`b0X[Qb0[`b0[`Qb0`[b0T{b0Xb0Qb0`{b0TQTb0Qb0{Q`b0XQQb0`Q[b0X[b0Qb0[`Sb0Xb0{b0S`Sb0MO3[b0Q[b0`b0``b0`b0XQSb0Qb0[[b0T{b0Tb0b0S{b0TQ[b0b0{Q{b0TQ{b0`Sb0S[b0{Qb0``b0[b0Sb0`b0Q;:;%21.0)3w!$'w5)[b0[b0Qb0{Q[b0`b0S`Tb0`Tb0{`b0`b0`[b0[`Qb0`{b0XQTb0SQb0`b0{b0X{b0{b0Tb0{Tb0Qb0Qb0T{b0[{b0Q[b0{QQb0Tb0Q[b0STb0XTb0Sb0[Sb0TXb0TXb0Qb0Qb0Qb0QQb0{`Qb0`Qb0b0`Tb0b0Qb0[``b0``b0ScR?)D0#}`}cR#&%21%$#B1=#&!G!$;!Z!$41#&%<;!1()#=5)41%$#B1%H9+%$.0)3*LNQaH%$.0+3D0#W)#&9)!$D)#B1 ;!Gt'&D0%G%$.0F)#&!$U_LN`a#&)%G#&>?)D0# (+#&!$#K#&'G(6.0)5+. ,^.05)9+Ds)#B1 ;!Gt.0%1!$.0+#&59)%$.0)371()#C;!$.03.0)D1!G.0).0)3%$#B1*)5@1(:9)%q;)D 5).0#&!G%w<N!$;>1()#K;41()#&!+#B1 ;!$tJ%.0@1(+##&+%$#&>?+D0#?. 1%!G)5);>.0). 1.0D #&.03( 1%GUKLN[a#&+%$#&>?+D0# (+#&!$#1()#@)#B1 ;!$t:%K!$#71!$.0)#&59)%$.0)3u!$)5);>*D!$#&%G>*A)D0#&51!$.0).0)3%$#B1%uLNMO33.0)3a-U#&)%G#&>?)D0# (+#&!$#}1(+#@+#B1 ;!$tJ%C!G#71!G.0)#&59)%G.0)3 #&.03( 1#&5!G#&%$>*A)D0#&5r1!$.0).0)3@%$#B1%*LNMO;J;%o1.0)3a ()#&!$#W1()#7!$#&%G>*A)D0.0)3@.0%?+%$#&5;}1()#LNa!$'&.0+37>*#B1();:5*)5LNaHw5)}>*#B1(+;J5)U_LNTaH%$.0)3D0#W5+#&'&.0%$.0;}1!G#&#='&D0%$%$.0F+#&!$ULNaKuMO33.0)3#&+%$#&>?+D0#d;<5)#&'&.0%G.0;u1!G#&#&%$U=)5"LNXa!$'&.0+3)5"LNSa5)MO;J;%o1.0)3#&)%G#&>?)D0#&%;<s5+#&'&.0%$.0;C1!$#&#&%Gb'&;>*A^;)#&1r'&D0%$%$.0F)#&!41}1()#CS'&;)F)5)#&)'&#CD0#B,+#&D0UO(); #B,+#&!GP);+#C;<1()#C#&+%$#&>?+D0#*>*#B1();:5)%!$#}%G.03).0F)'&1D ?^#B1-1#&!Z1()m;41(+#&!W#&)%$#&>?)D0#}A)A+!$;'G(41W1()#S'&;+F)5)#&)'&#}D0#B,+#&D0bcR;?^#B1-1#&!)D &#@cR?)D0#@`0%K!$#&%$9)D 1%$PO.039)!$#&%[)5A)D0;411()#rA^#&!$'&#&13#I!$#&5)9)'B1.0;.0#&!$!$;!O<N;!R1()#w5)4EGMO;:;%21.0)3Pw!$'&.0)3P+5@MO33.0)3C>r#B1();J5I%K<N9))'B1.0;I;<1()#q;!$.03.0+D#&!G!$;!!$41#&b >*.0).0)371()#&%$#F)39)!$#&% #+;41#W1()41*>*;<^1(+#3.0)%qA)!G;J5)9+'&#&5?/1()##&)%$#&>?)D0#>*#B1();:5)%@!$#>9)'(D0!$3#&!1()1()#%o1)5)!$55)#B,.041.0;,D09)#&%GbzB61#&!G>*%I;<}'&;>*A)!$.0%G;)%;<q5).0#&!$#& 1u>r#B1();J5+%$P. 1.0%*A)A)!$#&1<N!$;>?^;41(gF)39+!$#&%w1()41*1()#uM;:;%21.0)3>*#B1();:5)%LNw5)4EZfir+su}SmQzrvr++zkr-vs-kplettersegmentationlaborsoybeansatellitesicksonarvehicleglassionospherepromoters-936ribosome-bindirissplicecredit-gdiabetesAda-BoostinghypoArcinghepatitisBaggingcredit-ahouse-votes-84heart-clevelandbreast-cancer-w-40-20020406080100Percent Reduction Error.039)!$#}[7=#&5)9)'B1.0;].0#&!$!$;!*<N;!C5+4EGM;:;%21.0)3Pqw!$'&.0)3P)5MO33.0)3)#&9+!$DO)#B1 ;!$t#&E%$#&>?+D0#&%=%=rA#&!G'&#& 13#;<+1(+#};!$.03.0)D#&!G!$;!W!$41#ILN.0b0#&b0P*!$#&5+9)'B1.0;u<N!$;>m#&!G!$;!!$41#;<`b01;Qb0` ;9)D05@?#{!G#&5)9)'B1.0;@.0@#&!G!$;!!G41#&P-9)%21q%O!$#&5+9)'B1.0;<!$;>Q{b0{1;rb0{ ;9)D05uD0%G;r?^#*{!$#&5)9)'B1.0;)a-bD0%G;r%$(); L (+. 1#}A^;!21.0;;<Z#&'G(?)!$a.0%q;)#%o1)5)!$55)#B,^.041.0;<N;!H1()#&%$#!$#&%$9)D 1%$b7cW()#7%o1)5)!$55)#B,.041.0;.0%W%$(); m%=u5)5). 1.0;C1;1()##&!$!$;!W!G#&5)9)'B1.0;)b*fistv{wz{y{tlettersegmentationpromoters-936kr-vs-kpsatellitelaborbreast-cancer-whyposonarglassionospherevehiclesickhepatitissoybeanheart-clevelandribosome-bindAda-BoostingspliceArcingcredit-gBaggingcredit-adiabetesirishouse-votes-84-80-60-40-20020406080Percent Reduction Error.039)!$#}7=#&5)9)'B1.0;K.0#&!$!$;!R<;!Rw5)4EGMO;J;%21.0+3P)!G'&.0)3P)5M33.0+3w5+#&'&.0%$.0;1!$#&#O#&)%$#&>?)D0#&%%A^#&!$'&#&13#;<1(+#;!$.03.0+D#&!$!G;!!$41#&b=D0%$;%$(); L (). 1#wA;!o1.0;d;<#&'(/?)!$a.0%W;)#}%21+5)!$5m5)#B,.041.0;u<N;!1()#&%G#}!$#&%$9)D 1%GbZ*fir+su}SmQzrvr++zMO;J;%o1.0)36)5w!$'&.0)3aC!$#/%$.0>r.0D0!*.01()#&.0!C!$#&%$9+D 1%$P=?^;41(<;!r)#&9)!$DO)#B1 ;!$t:%*)55)#&'&.0%G.0;1!$#&#&%$b"+9)!21()#&!$>r;!$#&P_1()#/w5)4EGMO;:;%21.0)3+5!$'&.0+3>*#B1();:5)%CA)!$;:5)9)'&#I%$;>*#/;<1()#/D0!G3#&%21!$#&5)9+'B1.0;)%}.06#&!$!G;!$b I1(+#C;41()#&!7()+5)P ().0D0#w1(+#*MO33.0)3u>*#B1(+;J56'&;+%$.0%21#&1D ]A)!$;:5)9)'&#&%!$#&5)9+'B1.0;)%=.0#&!$!$;!<;!D0>*;%21CD0D;<1()#'&%$#&%$P . 1(u)#&9+!$D)#B1 ;!GtJ%H1()#7MO;:;%21.0)3@>*#B1();:5)%'&u%G;>*#B1.0>*#&%=!G#&%$9)D 17.0m.0)'&!$#&%$#}.0u#&!$!$;!$bs;J;t:.0)3411()#@;!$5)#&!G.0)3u;<R1()#@5)41%$#B1%K.0m1(+#1 ;F)39)!$#&%/Le1()#@!$#&%$9)D 1%!$#@%$;!21#&5?1()#*A^#&!$'&#&13#@;<!G#&5)9)'B1.0;9+%$.0)3K1()#r5)4EGMO;:;%21.0)3>*#B1();:5)a-P #r+;41#1()41}1(+#r5)41%$#B1%<N;! ().0'G(u1()#@#&)%$#&>?)D0#I>*#B1();:5)%%G#&#&>1; ;!$t #&D0D!G#@%G;>*# ()41/'&;)%$.0%21#&1m'&!$;%$%C?^;41()#&9)!GD)#B1 ;!$t:%q)5u5+#&'&.0%$.0;d1!$#&#&%$b});!1()#<# 5);>*.0+% (+.0'G(%$#&#7.0)'&!G#&%$#&%q.0#&!$!G;!$P. 1C.0%5).0*'&9+D 11;K!$#&'(m%21!$;+3'&;+'&D09)%$.0;)%%$.0+'&#H1(+#w#&+%$#&>?+D0#>*#B1();:5)%O%$#&#&>1;C5); #&D0D<N;!KD0!$3#:9)>?^#&!;<O5);>*.0+%$b )#C5+;>*.0; ().0'G(m1()#CMO;J;%21.0+3u>*#B1();:5)%}5+;/9)).0<N;!$>*D A;:;!$D .0%1()#q();9)%G#BEo,+;41#&%2EGX*5);>*.0+bW% #5).0%$'&9)%G%D041#&!GP:1()#&!$#q>*-);.0%$#q.01().0%5);>r.0)0%O#B^>*A+D0#&%1()41'&9+%$#&%_1()#MO;:;%21.0)3d>*#B1();:5)%W%$.03).0F+'& 1A+!$;?)D0#&>*%$bq+r %R2hpH!GD ;!$tLNv+%$#&uxy+D0>*;)PQSS{a;u#&)%$#&>?)D0#&%W%G9)33#&%21#&5r1()41#&)%$#&>?)D0#&% . 1(m%=<N#%1#&@>*#&>?^#&!$% #&!$#=5)#&8:9)41#Z1;7%$9)r'&.0#& 1D u!$#&5+9)'&#1#&%21-EG%$#B1#&!$!$;!Gb\().0D0#Z1().0%H'&D0.0>>*-u?^#1!$9)#=<;!1()#=#&!$D0.0#&!A)!$;A^;%$#&5r#&)%$#&>?)D0#&%$P1()#WMO;J;%o1.0)3D0. 1#&!G419)!$#LNy+'G()A).0!G#&P)!G#&9))5)PM!o1D0#B1-1Px#&#&PQSSa*()%C!$#&'&#&1D "%$9)33#&%21#&5LN?+%$#&5;<# 5)41%G#B1% . 1(5)#&'&.0%$.0;1!$#&#&%Gaw1()41. 1@.0%A^;%$%$.0?)D0#1;u<N9)!21()#&!}!G#&5)9)'&#1#&%o1-EG%$#B1I#&!G!$;!7#B,+#&<1#&!=1#&>*#&>?^#&!$%()-,+#@?^#&#&65)5)#&5m1;#&+%$#&>?+D0#LN)5/1(+#B+;41#1()411().0%7!$#&%G9)D 1dD0%$;A)A)D0.0#&%1;uM33.0+3a-bm1().0%7%$#&'B1.0;+P #A^#&!$<N;!$>5)5+. 1.0;)D#BA^#&!$.0>*#&1%Z1;@<9+!21()#&!=.0,+#&%21.0341#w1()#A)A)!$;A+!$.041#7%$.0&#;<_#&)%$#&>?)D0#&b.039)!$#du%$(); %=1()#r'&;>*A^;%$. 1#d#&!$!$;!!$41#r;$,+#&!KD0D;<O;9)!5)41u%G#B1%<N;!+#&9)!$DZ)#B1 ;!Gt6)55)#&'&.0%$.0;d1!$#&#K#&)%G#&>?)D0#&%q9)%G.0)3r9)Ar1;IQ{{I'&D0%$%$.0F)#&!$%Gb 9+!#BA^#&!$.0>*#&1%.0)5+.0'&41#=1(+41C>r;%21K;<1()#>*#B1(+;J5)%A+!$;J5+9)'&#q%$.0>*.0D0!$D 6%$()A^#&5I'&9)!2,+#&%GbW%=#B^A^#&'B1#&5)P>9)'(m;<)1(+#!$#&5)9)'B1.0;m.0/#&!G!$;!5)9)#1;d5)5).0)3r'&D0%$%$.0F)#&!$%Z1;rm#&+%$#&>?+D0#7'&;>*#&% . 1(K1()#7F)!$%217<N# '&D0%$%G.0F)#&!$%$Us(); #B,+#&!$P+1()#&!$#.0%W%$;>r#O,!G.041.0; . 1(u!$#&%$A^#&'B11; ()#&!G#1()#}#&!$!$;!=!$#&5)9)'B1.0;mF+)D0D %o^>*A1;41#&%$b);!?^;41(6MO33.0)3)56MO;J;%o1.0)3A+A)D0.0#&5I1;u+#&9)!$DZ)#B1 ;!GtJ%$P>9)'G(;<1(+#*!$#&5)9)'B1.0;.0#&!$!$;!A+A#&!G%H1;I()$,+#*;:'&'&9)!$!$#&5<e1#&!1#&@1;/F)<1#&#&'&D0%G%$.0F)#&!$%$bd%$.0>r.0D0!'&;)'&D09)%$.0;'&6?^#!$#&'()#&5*<N;!_M33.0+3})5C5)#&'&.0%$.0;1!$#&#&%$P (+.0'G(C.0%_'&;)%$.0%o1#& 1 . 1(CM!G#&.0>*uLNQSSTa-b=MO91=w5)4E?^;J;%o1.0)3u)5!G'&.0)3'&;1.0:9)#}1;>*#&%$9+!$?)D ].0>*A)!G;-,+#71()#&.0!W1#&%o1-EG%$#B1m#&!$!$;!9) 1.0D!$;9))5`'&D0%$%$.0F+#&!$%=<N;!W5)#&'&.0%$.0;*1!$#&#&%$bWR1`*'&D0%$%$.0F)#&!G%_1()##&!$!G;!W!$#&5)9)'B1.0;u<;!?;41(/>r#B1();J5+%WA)A^#&!$%1;()-,+#w)#&!$D u%2>*A1;41#&51;A)D041#&9+bcW()#&!$#&<N;!$#&P1()#=!$#&%G9)D 1%!G#&A;!o1#&5r.071().0%HA)A^#&!!$#;<@#&)%$#&>?)D0#%G.0&#w;<`ILN.0b0#&b0P%$9)*'&.0#&1+#B1q>*+3#&?)D0#q%$.0&#q<;!8J9+D0. 141. ,+#)D ^%G.0%$a-bW 1 %1!$5). 1.0;+D0D ?^#&D0.0#B,+#&5LN)!G#&9))5*xy)'G()A+.0!$#&PQSSTa1()41q%$>*D0D+!G#&5)9)'B1.0;)%.0q1#&%21-EG%$#B1}#&!$!$;!H>*-'&;1.0J9)#.0+5)#&F)). 1#&D d<N;!?^;J;%21.0+3U(); #B,+#&!$P+7!$;-,+#O)5Ky)'(J9)9+!$>*)%LNQSSXaZ5)#&>*;+%21!$41#1()41w5)4EG?^;J;%21.0+3'&.0)5)#&#&5?^#&3.0u1;;$,+#&!$F1 . 1( :f$ uD0!$3#I#&)%$#&>?)D0#I%$.0&#&%mLNQ{P0{{{6;!K>*;!$#>*#&>?^#&!$%$a-bq+rjgdSoqhcR:goqRw%%$9)33#&%21#&5m?^;$,+#&P. 17A)A^#&!$%R1()41O1()#A^#&!$<N;!$>*)'&#w;<R>* ;<)1(+#w#&+%$#&>?+D0#>*#B1();:5)%!$#().03()D '&;!$!$#&D041#&5 . 1(;)#C);41()#&!GbdcR;/()#&D0A.05)#&1.0<1()#&%$#C'&;+%$.0%21#&)'&.0#&%$Pcs?+D0#C[/A)!$#&%$#&1%1()#W'&;!G!$#&D041.0;d'&;:#&*'&.0#&1%;<J1()#=A#&!G<;!$>r)'&#;<^D0D)%$#B,+#&@#&)%$#&>?)D0#W>*#B1();:5)%$b);!#&'G(@5)41%$#B1PA#&!G<;!$>r)'&#.0%Z>*#&%$9+!$#&5*%1(+#W#&)%$#&>?)D0##&!$!$;!H!$41#=5). ,.05)#&5C?K1()#%$.0)3D0#BEG'&D0%$%G.0F)#&!#&!G!$;!Z*fistv{wz{y{t0.18DT-AdaDT-ArcDT-BagNN-AdaNN-ArcNN-BagComposite Error Rate0.160.140.120.100102030405060708090100Number Networks Ensemble.039)!$#}7Z,+#&!$3#@1#&%o1-EG%$#B1#&!$!$;!I;-,+#&!/D0Dq`[5)41%$#B1%I9)%$#&5.0;9)!I%219)5).0#&%I<N;!I#&)%$#&>?)D0#&%.0)'&;!$A^;!$41.0)3@<!G;>;+#=1;@Q{{/5)#&'&.0%$.0;@1!G#&#&%w;!q)#&9+!$Ds+#B1 ;!$tJ%GbCcW()#7#&!G!$;!q!$41#3!$A)()#&5}.0%s%$.0>*A)D q1()#H-,+#&!$3#;<fi1()#H#&!$!G;!!$41#&%R;<1(+#Z`[=5)41=%$#B1%$bcW()#ZD 1#&!$+41. ,+#;<_-,+#&!$3.0)31(+#7#&!$!$;!w;-,+#&!qD0DR5)41@A;.01%CLN.0b0#&b0P #&.03(1.0)3Ir5)41@%$#B10%q#&!$!$;!!$41#? . 1%=%$>rA)D0#}%$.0&#&aWA+!$;J5+9)'&#&%%$.0>*.0D0!$D 6%$(+A#&5/'&9+!2,+#&%$b!$41#&b}c=(J9)%=r().03('&;!$!$#&D041.0;gLN.0b0#&b0P;)#7+#&!=Qb0{aq%$9)33#&%21%H1()411 ;d>*#B1(+;J5)%!$#'&;)%$.0%21#&1.0K1()#75);>*.0)%W.0 ().0'G(C1()#B(+-,+#1(+#}3!$#&41#&%21K.0>*A)'B1;K1#&%o1-EG%$#B1#&!$!G;!W!$#&5)9)'B1.0;+bcR?)D0#m[6A+!$;-,.05)#&%r:9)>*#&!G;9)%*.01#&!$#&%21.0)3.0)%$.03(1%$bcW()#uF)!$%21m.0%1(+41*1()#m)#&9+!$D EG)#B1 ;!$t#&)%$#&>?)D0#>*#B1(+;J5)%=!$#%21!$;)3D '&;!$!$#&D041#&5 . 1(/;)#+;41()#&!W)5K1(+#5)#&'&.0%$.0;Eo1!$#&#7#&)%$#&>?)D0#>*#B1();:5)%*!G#m%21!$;)3D "'&;!$!$#&D041#&5 . 1(g;+#m);41()#&!$U7(); #B,+#&!$P1()#&!$#m.0%rD0#&%$%r'&;!$!G#&D041.0;?^#BE1 #&#&)#&9)!$D EG)#B1 ;!Gt#&+%$#&>?+D0#C>*#B1();:5)5 5)#&'&.0%$.0;Eo1!$#&#r#&)%G#&>?)D0#C>r#B1();J5+bdw;41%$9)!GA)!$.0%$.0)3D P5+4EG?;:;%21.0)3)5@!G'&.0)3!G#%21!G;)3D '&;!$!$#&D041#&5+P#B,+#&@'&!G;%$%5).0#&!$#& 1'&;>*A^;4E)#&1D0#&!$+.0)3rD03;!$. 1(+>*%$bcW().0%=%$9)33#&%21%H1()41MO;:;%21.0)30%q#&#&'B1. ,+#&)#&%$%5)#&A^#&)5)%=>*;!$#};r1()#5)41%$#B11() ()#B1()#&!1(+#d'&;>*A^;)#&1@D0#&!G).0)3D03;!$. 1()>.0%)#&9)!GDH)#B1 ;!$t;!5)#&'&.0%G.0;1!$#&#&bdM33.0+3m;@1()#K;41()#&!}()+5)P.0%);41*'&;!$!$#&D041#&5'&!G;%$%'&;>*A^;)#&1CD0#&!G).0)3/D03;!$. 1()>r%$bcW()#&%G#W!$#&%$9)D 1%!$#='&;+%$.0%21#&1 . 1(d;9)!HD041#&!'&D0.0>1(+41 ().0D0#=M;:;%21.0)3.0%HA^; #&!$<9+D#&)%$#&>?)D0#>*#B1();:5)P. 1.0%=>*;!$#}%$9+%$'&#&A1.0?)D0#O1;rC);.0%265)41*%$#B1=1()mMO33.0)3bZ*fiy).0>*A+D0#BEGMO33.0)34EGww!$'&.0)34EGww5)4EGMO33.0)34EGqcw!$'&.0)34EGqcw5)4EGqcy).0>rA)D0#Qb0{{{b0XX{b0X{b0XEG{b0Q{{b0[X{b0[r+su}SmQzrw#&9)!$Dw#B1 ;!$tMO33.0)3!$'&.0)3w{b0XX{ b0XQb0{{{ b0X{b0XQ b0{{{b0X{ b0SSEG{b0QQ{ b0Q{b0[{ b0TQ{b0[{ b0T{vr++z5){b0X{b0X{b0SSQb0{{{b0Q{b0T`{b0T[MO33.0)3EG{b0Q{EG{b0QQ{b0Q{b0QQb0{{{b0TX{b0TSw#&'&.0%G.0;cR!$#&#!$'&.0+3{b0[X{b0[{b0TQ{b0T`{b0TXQb0{{{b0STw5){b0[{b0[{b0T{{b0T[{b0TS{b0STQb0{{cR?)D0#}[}Y#&!$<N;!$>*)'&#'&;!$!$#&D041.0;'&;J#&*'&.0#&1%/'&!$;%$%I#&)%G#&>?)D0#D0#&!$+.0)3>r#B1();J5+%$bY#&!$<N;!2E>*+'&#.0%>*#&%$9)!G#&5r?C1()#=!$41.0;K;<:1()##&)%$#&>?)D0#w>*#B1();:5)0%1#&%21-EG%G#B1#&!G!$;!5+. ,^.05)#&5d?1()#7%$.0)3D0#}'&;>*A^;)#&17'&D0%$%$.0F+#&!$0%_1#&%21-EG%G#B1K#&!$!G;!$bq+rGusnhd)ShsGf+gjl2Rsgo2:.039)!$#T6%$(); %1()#uM33.0+3)5y).0>*A)D0#u)#B1 ;!$t#&)%$#&>?)D0#m!G#&%$9)D 1%r<N!$;>cs?)D0#`bc=()#&%$#!$#&%$9+D 1%*.0)5).0'&41#*1()41u;<1#&6y).0>*A+D0#/H)%$#&>?)D0#/A)A+!$;'G( .0D0DWA)!$;:5)9)'&#I!$#&%G9)D 1%q1()41!G#m%'&'&9)!$41#@%M33.0+3LN'&;!$!G#&D041.0;!$#&%$9)D 1%<!$;>cs?+D0#r[uD0%G;u%$9)A+A;!o11().0%7%2141#&>r#& 1a-bcW().0%%$9)33#&%o1%1(+41q>*#&'()).0%$> ().0'(d'&9)%G#&%D0#&!$).0+37>*#B1();:571;A)!G;J5)9+'&#W%$;>*#w!$)5);>r)#&%$%.0d1()#<;!$>r41.0;;<H. 1%q'&D0%$%$.0F)#&!G%'&?#9)%$#&5d1;I<;!G>'&'&9)!G41#C#&)%$#&>?)D0#&%$P_)5.0)5)#&#&5+PswD0.)5mY&&).OLNQSSTa(+-,+#}5)#&>r;)%21!$41#&5%$.0>*.0D0!=!G#&%$9)D 1%W<N;!W!$)5+;>*.0&#&5m5)#&'&.0%$.0;*1!$#&#&%$bq+rt udS 4f+gfiGuRc/gh2qhjJ:w);41()#&!W.01#&!$#&%21.0)3d8J9+#&%21.0;u.0%W(+; #&#&'B1. ,+#W1(+#}5).0#&!$#& 1>*#B1();:5)%!$#}<N;!W)#&9)!GD)#B1 ;!$t:%)5*5+#&'&.0%$.0;}1!G#&#&%$b.039)!$#&%HP+XP+)5*S'&;>*A)!$#_1()#W#&!$!$;!!$41#&%H+5r!$#&5)9+'B1.0;*.0r#&!$!G;!,D09)#&%<N;!w5)4EGMO;J;%o1.0)3P!$'&.0+3PR+5uMO33.0)3I!$#&%$A^#&'B1. ,+#&D b;41#=1()41 #3!$A)(#&!$!$;!w!$41#!G41()#&!1()*A^#&!$'&#&1=!$#&5)9+'B1.0;*.0*#&!$!$;!H!$41#W?^#&'&9)%$#R1()#?+%$#&D0.0)#W<N;!Z#&'G(d>*#B1();:5uLN5)#&'&.0%$.0;}1!$#&#&%H<N;!w5)4EGMO;J;%21.0+3;5)#&'&.0%$.0;1!G#&#&%),+#&!$%G9)%)#&9)!GD)#B1 ;!$t:%s<N;!w5)4EGMO;:;%21.0)3=;)#&9)!$D)#B1 ;!$t:%$a>*$A)!21.0D0D #BA)D0.0C1(+#75).0#&!$#&)'&#&%w.0uA^#&!$'&#&1!$#&5)9+'B1.0;)bq);!#B>*A)D0#&PR.0C1(+#7A)!$;>r;41#&!$%2ES[TmA)!G;?)D0#&>9)%$.0)3/w5)4EGMO;:;%21.0)3P1()#C>9+'G(6D0!$3#&!7!$#&5)9)'B1.0;6.0#&!$!$;!<N;!O1()#C5)#&'&.0%$.0;/1!$#&#A)A)!G;'G(>*-6?^#}5)9)#1;1()#}<N'B1=1(+415)#&'&.0%$.0;r1!$#&#&%w5);*);41%$#&#&>1;d?^#}%=#&#&'B1. ,+#K<;!Z1().0%A)!$;?+D0#&>*P_)5w5)4EGMO;J;%21.0+3K1()#&!$#&<N;!$#CA)!$;:5)9)'&#&%q/D0!$3#&!7A#&!G'&#& 1*!$#&5)9+'B1.0;.0I1()#K#&!$!$;!<N;!5)#&'&.0%$.0;*1!$#&#&%$bcW(+#!$#&%G9)D 1%I%$(); 1(+41.0>*'&%G#&%/.0<}%$.0)3D0#5)#&'&.0%$.0;1!$#&#(+5D0; #&!LN;!/(+.03()#&!$a#&!$!$;!H1()d%$.0+3D0#7)#&9)!GD)#B1 ;!$tu;d5)41d%G#B1P)1()#&*1()#5)#&'&.0%$.0;Eo1!$#&##&)%$#&>?)D0#>*#B1();:5)%D0%$;@()5D0; #&!CLN;!q().03(+#&!$a=#&!$!G;!Z1()r1()#&.0!w)#&9)!$Ds)#B1 ;!$tm'&;9+ 1#&!$A+!21b7cW(+#7#B'&#&A1.0;)%1;1().0%*!G9)D0#/3#&)#&!$D0D ()A)A^#&)#&5;1(+#/%$>*#/5)416%G#B1<;!CD0D_1()!$#&#/#&)%$#&>?)D0#m>r#B1();J5+%uLN#&b03b0P()#&A)41. 1.0%GPZ%$;-?^#&)P%$41#&D0D0. 1#&P'&!$#&5). 1-EGP_)5()#&!21-EG'&D0#B,+#&D0+5)a-bdc=()#&%$#K!$#&%$9)D 1%q%$9+33#&%211()41LNa1()#A#&!G<;!$>r)'&#};<1()##&)%$#&>?)D0#>r#B1();J5+%=.0%w5)#&A^#&)5)#&17;?^;41(C1(+#75)41@%$#B1+5u'&D0%$%$.0F+#&!>*#B1();:5)P)5]LN?)aq#&)%G#&>?)D0#&%'&+P_41rD0#&%21r.0%$;>*#K'&%$#&%$PH;-,+#&!$'&;>*#1()#K.0)5)9)'B1. ,+#C?).0%q;<. 1%'&;>*A^;)#&1D0#&!$).0+3CD03;!$. 1()>*bZfistv{wz{y{tkr-vs-kpletterlaborsoybeanpromoters-936segmentationsatellitesplicevehiclehouse-votes-84glasscredit-ghepatitisribosome-bindheart-clevelandiriscredit-aBaggingionosphereSimplediabeteshyposickbreast-cancer-wsonar-20020406080Percent Reduction Error.039)!$#}T7=#&5)9)'B1.0;.0#&!G!$;!7<N;!7MO33.0)3)5y+.0>*A)D0#*)#&9+!$DZ)#B1 ;!$t#&+%$#&>?+D0#&%%uA^#&!2E'&#& 13#K;<1()#;!$.03.0)D#&!G!$;!=!$41#&b7D0%$;d%$(); L (+. 1#7A^;!21.0;u;<_#&'(?)!$aW.0%w;)#%21)5)!$5u5)#B,^.041.0;<;!_1()#&%$#}!$#&%G9)D 1%$bZZpfir+su}SmQzrvr++zkr-vs-kplettersegmentationlaborsoybeansatellitesicksonarvehicleglassionospherepromoters-936ribosome-bindirissplicecredit-gdiabetesNeural NetworkhypoDecision Treehepatitiscredit-ahouse-votes-84heart-clevelandbreast-cancer-w010203040Error (%).039)!$#}7H!$!$;!=!$41#&%<N;!=w5)4EGMO;:;%21.0)3@#&)%$#&>?)D0#&%$bqcW()# (+. 1#7A^;!21.0;u%G(); %Z1()#}!$#&5+9)'B1.0;.06#&!$!$;!;<5+4EGM;:;%21.0)3'&;>*A)!$#&5/1;//%$.0)3D0#*'&D0%$%G.0F)#&! ().0D0#C.0+'&!$#&%$#&%7.0#&!G!$;!!$#%$(); *.0C?)D0'tJbcW(+#5)41}%$#B1%Z!G#%$;!21#&5r?71(+#W!$41.0;};<!$#&5)9)'B1.0;r.0C#&)%$#&>?)D0##&!$!$;!1;*;$,+#&!$D0DR#&!$!$;!W<N;!W)#&9)!GD)#B1 ;!$t:%$bZfffistv{wz{y{tkr-vs-kpletterlaborsegmentationsoybeansatellitevehiclesonarionospheresickglasspromoters-936irisspliceribosome-bindcredit-ghepatitisNeural NetworkhypoDecision Treediabeteshouse-votes-84credit-aheart-clevelandbreast-cancer-w010203040Error (%).039)!$#}X7H!$!$;!!$41#&%O<;!!G'&.0)37#&)%G#&>?)D0#&%GbcW()# (). 1#=A^;!21.0;d%$(); %1()#!$#&5)9)'B1.0;@.0r#&!G!$;!;<w!$'&.0)36'&;>rA)!$#&51;6%$.0)3D0#m'&D0%$%G.0F)#&! (+.0D0#/.0)'&!$#&%$#&%d.0g#&!$!$;!*!G#m%$(); .0?)D0'Gt:bcW()#d5)41%$#B1%K!$#I%$;!21#&5? 1()#d!G41.0;;<=!$#&5)9)'B1.0;.0#&)%$#&>?)D0#I#&!$!$;!=1;;-,+#&!$D0DR#&!$!$;!W<N;!W)#&9+!$D)#B1 ;!$t:%$bZ*fir+su}SmQzrvr++zkr-vs-kpletterlaborsoybeanpromoters-936segmentationsatellitesplicevehiclehouse-votes-84glasscredit-ghepatitisribosome-bindheart-clevelandiriscredit-aNeural NetworkionosphereDecision Treediabeteshyposickbreast-cancer-wsonar010203040Error (%).039)!$#}S7H!$!$;!C!G41#&%r<N;!*MO33.0)3#&)%G#&>?)D0#&%Gb"cW()# (). 1#/A^;!21.0;]%$(); %q1()#/!$#&5)9+'B1.0;g.0#&!$!$;!;<M33.0+3'&;>rA)!$#&51;7%G.0)3D0#'&D0%G%$.0F)#&! ().0D0#W.0+'&!$#&%$#&%O.0d#&!G!$;!H!$#w%$();.0u?)D0'tJbcW(+#}5)41r%G#B1%=!$#%$;!21#&5u?/1()#}!G41.0;d;<!$#&5)9+'B1.0;u.0u#&+%$#&>?+D0#7#&!$!$;!Z1;;-,+#&!$D0DR#&!$!$;!W<N;!W)#&9+!$D)#B1 ;!$t:%$bZfiq+rK*oqhsGdih2stv{wz{y{t)!$#&9+)5g)5gy+()A).0!$#6LNQSSTa@%$9)33#&%21#&561()41r1()#/%G;>*#B1.0>*#&%@A;:;!CA^#&!$<N;!$>*)'&#/;<qMO;J;%o1.0)3!$#&%$9+D 1%}<!G;> ;-,+#&!$F1-1.0)3C1()#1!$.0).0)3/%$#B1@%$.0)'&#*D041#&!W1!$.0).0)3m%G#B1%}>*-g?^#C;-,+#&!oEG#&>*A)()%$.0&.0+3#B>*A)D0#&%w1()41m!$#@);.0%$#6Le1(:9)%K'&!$#&41.0)3#BJ1!G#&>*#&D A^;:;!'&D0%G%$.0F)#&!$%$a-bc=().0%!G39)>*#&1/%G#&#&>*%#&%$A^#&'&.0D0D A^#&!21.0+#& 1@1;M;:;%21.0)3<N;!1 ;!$#&%$;)%$bcW(+#F)!G%21)5>*;%o1;?,^.0;9+%/!$#&%$;.0%1()41W1(+#&.0!W>*#B1();:5m<N;!W9)A^5)41.0)31()#A)!G;?)?).0D0. 1.0#&%=>r-6?^#;-,+#&!2EG#&>*A+()%$.0&.0)3d);.0%2#B^>*A+D0#&%$bcW()#u%$#&'&;)5!$#&%$;.0%}1()41d1()#u'&D0%G%$.0F)#&!$%@!$#u'&;>?).0)#&59)%$.0+3 #&.03( 1#&5,+;41.0)3bY!$#B,.0;9)%;!$tLNy);D0D0.0'(@x|}!$;3(+PQSSTa()%%$(); 71()41q;A1.0>*.0&.0)3=1()#'&;>?).0).0+3 #&.03( 1%'&@D0#&51;;-,+#&!GF1-1.0)3 ().0D0#Wd9) #&.03(1#&5,+;41.0)3%$'G(+#&>*#=.0%3#&)#&!$D0D u!$#&%$.0D0.0#&1H1;;-,+#&!$F1-1.0)3bW)!$.0#&5+>*#B1D0b@LNQSSXaw(A;41(+#&%$.0&#1()41CMO;J;%o1.0)3d>r#B1();J5+%$P%w5)5). 1. ,+#>*;J5+#&D0%$P>*$%$#&#.0)'&!$#&%$#&%w.0#&!$!$;!.01(+;%$#q%$. 19)41.0;)% ()#&!$#1()#?).0%;<)1()#?)%$#q'&D0%$%$.0F+#&!W.0%A)A)!$;A+!$.041#q<;!R1()#A+!$;?)D0#&>?^#&.0)37D0#&!G)#&5)bR\]#H1#&%21O1().0%(A;41(+#&%$.0%.0@;9)!%$#&'&;)5@%$#B1;<!$#&%$9)D 1%A)!$#&%G#& 1#&5@.0}1(+.0%%G#&'B1.0;)bcR;q#B,D09)41#_1()#O( A^;41()#&%$.0%1()41WMO;J;%o1.0)3>*-/?^#A+!$;)#1;;-,+#&!$F1-1.0+3 #A^#&!$<N;!$>*#&5q%$#B1;<#B^A^#&!$.0>r#& 1%9)%$.0)3q1(+#}<;9+!=#&)%$#&>?)D0#}+#&9)!$D)#B1 ;!Gt/>*#B1();:5)%$b_\]#.01!$;J5+9)'&#&5m*PsQ{*P`{*P)56[{ );.0%$#GK.01;u<N;9)!}5).0#&!$#&1d5)41%$#B1%$buR1I#&'G(D0#B,+#&D #r'&!$#&41#&5F,+#*5).0#&!$#&1);.0%25)41m%G#B1%$PHA^#&!$<N;!$>*#&5mQ{4EG<N;D05'&!G;%$%,D0.05)41.0;;#&'G()P1()#&6$,+#&!$3#&5;-,+#&!1(+#*F,+#!$#&%$9+D 1%$b/.039)!G#}Q{ #%G(); 1(+#!$#&5)9)'B1.0;m.0/#&!G!$;!W!$41#<N;!W#&'G(u;<)1()##&+%$#&>?+D0#}>*#B1();:5)%'&;>*A)!G#&51;9)%$.0)3%G.0)3D0#/)#&9)!$D+#B1 ;!$t'&D0%G%$.0F)#&!$b"cW(+#&%$#I!$#&%$9)D 1%*5+#&>*;)%21!$41#1(+41%1()#}+;.0%$#}D0#B,+#&D3!G; %$P)1()#}#&*'&'B;<+1()#}y+.0>*A)D0#})5uM33.0+3r#&)%$#&>?)D0#&%3#&)#&!$D0D .0)'&!$#&%G#&%().0D0#w1(+#C!$'&.0+3/)55+4EGM;:;%21.0)3u#&)%$#&>?)D0#&%}3.0)%}.0A#&!G<;!$>r)'&#K!$#C>9+'G(%$>*D0D0#&!ILN;!>*$'B19)D0D 5)#&'&!$#&%$#&a-b;41#@1(+41@1(+.0%@#&#&'B1.0%/>*;!$##B:1!$#&>*#<N;!@w5)4EGMO;:;%21.0)3 ().0'(%$9)A+A;!o1%;9)!}(^A^;41()#&%$.0%1()41dw5)4EGMO;J;%21.0+3u.0%7>r;!$#C#&'B1#&5?+;.0%$#&bmcW().0%7%$9)33#&%21%W1()41MO;J;%o1.0)30%A^;J;!A^#&!$<;!G>*)'&#w<;!'&#&!21.0/5)41K%$#B1%O>*$?^#=A)!o1.0D0D #BA)D0.0)#&5I? ;-,+#&!$F1-1.0+3);.0%$#&bcR;q<9)!o1()#&!s5+#&>*;)%21!$41#s1()#O#&#&'B1=;<));.0%$#O;KMO;J;%o1.0)3 #O'&!$#&41#&5C%G#B,+#&!$D%$#B1%_;<)!21.0F+'&.0D5)41%$A^#&'&.0F)'&D0D 5)#&%$.03)#&51;>*.0%GD0#&5gMO;J;%21.0+3>*#B1();:5)%$b);!C#&'(g5)41%$#B1 #/'&!$#&41#&5g%$.0>*A+D0#=(^A^#&!$A)D0+#='&;)'&#&A1?)%$#&5@;@%$#B1;<:1()#w<#&419+!$#&%qLN+5dD0%$;.0)'&D09)5+#&5d%$;>r#.0!$!G#&D0#B,1<N#&419)!$#&%$a-b%$#B1I;<!$)5);> A^;.0 1% #&!$#71()#&3#&)#&!$41#&5g+5D0?^#&D0#&5?)%$#&5; ().0'(%$.05)#;<H1()#/( A^#&!$A)D0)#1(+#B<N#&D0D0b"cW()#&6'&#&!o1.0gA^#&!$'&#& 13#;<Z1(+#/A;.01%*;g;+#m%$.05)#/;<H1()#(^A^#&!$A)D0+# #&!G#d>*.0%GD0?#&D0#&5%K?^#&.0)3mA)!21I;<1()#d;41()#&!'&D0%G%$b);!1()#d#B^A^#&!$.0>r#& 1%K%$();?^#&D0; #}3#&)#&!G41#&5uF,+#}5+41*%$#B1% ()#&!$#1()#}'&;)'&#&A1 %=?)%$#&5m;*1 ;*D0.0)#&!=<N#&419)!$#&%GP()5<N;9)!W.0!$!$#&D0#B,1<N#&419)!$#&%$Ps)5m`{;<1()#75)41 %=>*.0%GD0?#&D0#&5+b_\]#=1!$.0)#&5mF,+##&)%$#&>?)D0#&%=;<)#&9)!GDZ)#B1 ;!$t:%ILNA^#&!$'&#&A1!$;)%$a}<N;!7#&'(5+41u%$#B1I)5$,+#&!$3#&51()#r#&)%G#&>?)D0#&%GHA)!$#&5+.0'B1.0;)%$bcW(:9)%s1()#&%$##BA^#&!$.0>*#&1%.0 ,+;D ,+#}D0#&!G).0)3C.0/%$. 19)41.0;+% ()#&!$#H1()#;!$.03.0+D?).0%;<1()#D0#&!G)#&!LN%$.0)3D0#( A^#&!$A)D0)#uA)!$;:5)9)'&#&5]?A^#&!$'&#&A1!$;)ad.0%IA)A)!$;A)!G.041#u<N;!71(+#uA)!$;?+D0#&>*P})5%)!$.0#&5+>*I#B1D0bLNQSSXa%$9)33#&%21P9)%G.0)37I5)5). 1. ,+#q>*;:5)#&D>*-()!$>A^#&!$<;!G>*)'&#&b.039)!$#wQQ%$(); %1(+#r!$#&%$9+D 1.0)3u#&!$!G;!7!$41#&%K<N;!7w5)4EGMO;J;%21.0+3P!$'&.0+3P+5MO33.0)3? 1()#dJ9+>?^#&!7;<)#B1 ;!$t:%H?^#&.0)3q'&;>?).0)#&5*.0w1(+##&)%$#&>?)D0#&bcW()#&%$#O!$#&%G9)D 1%Z.0)5).0'&41#='&D0#&!$D K1()41=.0*'&%$#&% ()#&!$#1()#&!$#.0%q);.0%$#7MO33.0)30%7#&!$!$;!=!G41# .0D0DR);41K.0)'&!$#&%$#%1()#7#&)%G#&>?)D0#%$.0&#.0)'&!$#&%$#&% (+#&!$#&%1()##&!$!$;!@!$41#;<1(+#uMO;J;%o1.0)3>r#B1();J5+%r>*$.0)5)#&#&5.0)'&!$#&%$#%I#&)%$#&>?)D0#u%$.0&#.0)'&!$#&%G#&%$b5 6V=\*=3V4h=3! #$&#&$#!ng2$#94#=3V4=\V4B- `G#,>13 ;Fm)+A=\V4>94l#V4hg94>94l2 #9 ;Fm#h0-6!n#V4! [8)+ =3VBA#Vh4,-13?@>+$9)+ hW#V4$%2 #9CD#1\94C%4#d2 #9U/2%!$VG=3VZ9494%2 #9 ;Fk>+=\)413[ kD;#139$&X#o!n$V@)G?A$`Z#,-=3V=3VB#131I%#=3V=3VB-$`Z#,->13 ;:ZZfidiabetes4Reduction error rate (% pts)r+su}SmQzrsoybean-large9362310Bagging EnsembleBoosting (Arcing) EnsembleBoosting (Ada) Ensemble00510152025300promoters-9364Reduction error rate (% pts)vr++z5322110152025302530segmentation431000510152025300Noise rate (%)5101520Noise rate (%).039)!$#}Q{7y).0>*A)D0#&P_MO33.0)3P)5MO;J;%21.0+3LN!$'&.0+3/)55)a+#&9)!$DR)#B1 ;!$t#&)%$#&>?)D0#C!$#BE5)9)'B1.0;.0#&!$!$;!q%q'&;>*A)!$#&5d1;@9)%$.0)3@d%G.0)3D0#K)#&9)!$Ds)#B1 ;!$t:bC}!$A)()#&5.0%1()#A#&!G'&#& 13A# lNh z !$#&5+9)'B1.0;m.0/#&!$!$;!LN#&b03b0P<N;!W);.0%$#7.0K1()#%$#&3>*#&141.0;5)41%$#B1P.0<s1()#r%$.0)3D0#*)#B1 ;!Gt>r#B1();J5()56#&!G!$;!}!$41#d;<Qb0S )5I1()#rM33.0+3>*#B1();:5()5#&!$!$;!C!$41#/;<wQb0*PH1()#&1().0%*.0%C3!GA)()#&5%CQb0`6A^#&!$'&#&13#A;.01!$#&5+9)'B1.0;m.0K1()#7#&!$!$;!W!$41#&a-bw5)5). 1.0;)D1#&%o1%wLN);41q%$(); C()#&!$#&aZ%$(+;!$#&%21!o1.0)3*.0%=+;417#&>*A)D0;-+#&5+b1(+415+4EGM;:;%21.0)30%#&!$!$;!H!$41#W?^#&'&;>*#&% ;!$%$# ()#&cW(+.0%'&;+'&D09)%$.0;g5);$,+#B1.0D0%d+.0'&#&D . 1(y)'()A).0!$#I#B1uD0b00%LNQSSad!$#&'&#&1u5).0%$'&9)%$%G.0; ()#&!$#1()#B);41#*1()41*1()##&#&'B1. ,+#&+#&%$%/;<q/,+;41.0)3>*#B1();:5g'&?#u>*#&%$9)!$#&5? #B>*.0).0)3m1()#k { $ |Nh)i=;<+1()##B>*A)D0#&%$bLNcW()#>*!$3.0u.0%R1()#5).0#&!$#&)'&#}?^#B1 #&#&K1()#:9)>?^#&!;<s'&;!$!G#&'B1)5.0)'&;!$!G#&'B1r,+;41#&%I<;!r]#B>*A)D0#&b0a6%$.0>*A+D0#m!$#&%$>*A+D0.0)36>*#B1();:5]%G9)'G(%rMO33.0)3P}#&'(!$#&%$9+D 1.0)3}'&D0%$%$.0F+#&!H<N;J'&9)%G#&%H;r.0+'&!$#&%$.0)3O1(+#W>*!$3.0d<;!%H>*m;<1(+#W#B^>rA)D0#&%H%A;%G%$.0?)D0#&bMO91/.0MO;:;%21.0)3>*#B1();:5)PD041#&!C'&D0%$%$.0F+#&!$%K<;:'&9)%K;.0)'&!$#&%$.0)3r1()#I>*!$3.0+%<N;!#B^>*A+D0#&%. 1(A;:;!W'&9)!G!$#& 1>*!$3.0)%$bww%=y)'()A).0!$#}#B1KD0b*LNQSSa);41#&P)1().0%w.0%=q,+#&!2#&#&'B1. ,+#K%21!$41#&34.0<1()#};$,+#&!$D0D'&'&9)!$'B;<1()#!$#&%$9)D 1.0+3r'&D0%$%$.0F+#&!5);:#&%=+;415)!$;Au%$.03).0F)'&1D b});!qrA+!$;?)D0#&>. 1(6+;.0%$#&PH<N;J'&9+%$.0)3I;6>*.0%$'&D0%G%$.0F)#&56#B>*A)D0#&%>*-g'&9)%$#C/'&D0%G%$.0F)#&!1;u<;:'&9)%;6?^;:;%21.0)31()#}>r!$3.0)%W;<LN);.0%2aW#B>*A)D0#&%_1(+41 ;9+D05m.0m<N'B1?^#q>*.0%$D0#&5).0)3r.0u;-,+#&!GD0D'&D0%$%$.0F+'&41.0;)bZ*fistv{wz{y{t20Error rate18ArcAda1614Bag121005101520253020Error rate1816Arc14Ada12Bag1005101520253020Error rate1816Arc14Ada12Bag1005101520253020Error rate18ArcAda1614Bag121005101520253020Error rate1816Arc14Ada12Bag10051015202530Networks Ensemble.039)!$#}QQ7H!$!$;!w!$41#&%q?m1()#%$.0&#;<H#&)%$#&>?)D0#<N;!w5)4EGMO;:;%21.0)3P_w!$'&.0)3P)5MO33.0)3/#&E%$#&>?+D0#&%=<N;!=F,+#5).0#&!$#&1!21.0F)'&.0Ds5)41*%$#B1%'&; 1.0+.0)3r;)#BEG%G.05)#&5u);.0%G#dLN%$#&#O1#B:1<;!5)#&%$'&!$.0A1.0;+a-b**fijr+su}SmQzrvr++zQ)#7.0 1#&!$#&%o1.0)3d8:9)#&%21.0; #A)D0C1;d.0 ,+#&%o1.0341#.0%w(); #&#&'B1. ,+#d%$.0)3D0#'&D0%$%$.0F)#&!wA)A)!$;'(>*.03(1*?#.0<H. 1 %D0D0; #&5I1;/9)%$#=1()#1.0>*#K. 1q1t#&%O1()#K#&)%$#&>?)D0#K>*#B1();:5d1;1!$.0>9+D 1.0A)D0#'&D0%$%$.0F+#&!$%1;#B^A)D0;!G#. 1%/'&;+'&#&A16%$A)'&#&b);!m#B>*A)D0#&P)#&9)!$Dw)#B1 ;!$tA)A)!$;'("'&;9)D05A^#&!$<N;!$>A).0D0;41%219)5+.0#&%9)%$.0)31()#1!$.0+.0)3C%$#B11;*%$#&D0#&'B1A)A)!$;A)!G.041#H,D09)#&%W;<RA)!$>r#B1#&!$%W%$9)'(%=(+.05)5)#&/9)). 1%GPD0#&!$).0)3C!$41#&Ps#B1'&b\ #@A)D0/1;'&;>*A)!$#dMO33.0)3+5MO;J;%o1.0)3>r#B1();J5+%O1;u;41()#&!>*#B1();:5)%.0 1!$;:5)9)'&#&5!$#BE]'&#&1D bW@A)!21.0'&9+D0! #=.01#&)51;#B^>*.0+#Z1()#9)%$#;<y1'Gt:.0)3/Le\];D0A^#&!21PQSS`aO%>*#B1();:5;< z { h+h |I'&;>?+.0).0)3<9)+'B1.0;)P%G;%=1;u$,+;.051()#r#&#&'B1m;<()-,.0)3C1; #&.03( 1/'&D0%$%$.0F)#&!G%$b\]#}D0%$;rA)D01;*'&;>*A)!G#M33.0+3r)5/MO;:;%21.0)3q1;C;41()#&!=>*#B1();:5)%%$9)'(m% A). 1+5/y)()-,:ED0.0t:0%CLNQSST?+aA)A)!$;'(r1;I'&!$#&41.0+3@#&)%G#&>?)D0#&bKcW(+.0%A)A+!$;'G(9)%$#&%q3#&)#B1.0'K%$#&!G'G(@1;@F))5'&D0%$%$.0F+#&!$%_1()41!$#'&'&9)!$41#)5m5).0#&!W.0K1()#&.0!A)!$#&5).0'B1.0;+%$b.0)D0D P%G.0)'&#Z1(+#wMO;:;%21.0)3C>*#B1(+;J5)%!$#q#B:1!$#&>*#&D %$9)'&'&#&%$%$<N9)D.0I>* 5);>*.0)%GP #qA)D01;.0,+#&%21.0341#);$,+#&DA+A)!$;'G(+#&%71(+41 .0D0D!$#B1.061(+#u?^#&)#&F1%d;<wMO;:;%21.0)3bc=()#m3;D .0D0D?^#1;'&!G#&41#mD0#&!$)#&! (+#&!$#+;9'&g#&%$%$#&1.0D0D A)9)%$(%21!21u?)91-1;+5D0#B1u. 1u!$9))bcR;5);*1().0% # ;9)D05u1!21;A)!G#&%$#&!2,+#q1()#d?^#&)#&F1%7;<MO;:;%21.0)3 ().0D0#rA+!$#B,+#& 1.0+3;$,+#&!$F1-1.0)3;);.0%2g5)41%$#B1%$b )#CA^;%$%G.0?)D0#*A)A)!G;'G( ;9)D05?#1;u9)%$#rm();D05);9171!$.0).0)3%$#B1LNK19+).0)3%$#B1as1;C#B,D09)41#1()#wA#&!G<;!$>r)'&#;<)1()#wM;:;%21.0)3C#&+%$#&>?+D0#H1;K5)#B1#&!G>*.0)# ()#&71()#q'&'&9)!$'B.0%7+;uD0;)3#&!.0)'&!$#&%$.0+3bw);41()#&!A)A)!$;'( ;9)D05?#1;u9)%$#rA).0D0;41@%219+5).0#&%1;5)#B1#&!$>*.0+#*4;A1.0>*D0dJ9+>?^#&!;<'&D0%$%$.0F)#&!G%_1;*9)%G#.0mm#&)%$#&>?)D0#&bHg)w%>r#& 1.0;)#&5I?^#&<N;!$#&P1(+#=.05)#&K;<9)%$.0+37I#&)%$#&>?)D0#w;<'&D0%$%$.0F)#&!G%!G41()#&!1(+}1()#w%$.0)3D0#w?^#&%21'&D0%$%$.0F+#&!s()%R?^#&#&7A)!G;A;%G#&5}? r%G#B,+#&!$DJA^#&;A)D0#&bB7y)#&'B1.0;`P #A)!$#&%$#&1<!$>r# ;!$t<N;!1(+#&%$#%2%21#&>*%$P%$;>*#}1()#&;!$.0#&%7;< (+41d>*t#&%7#&#&'B1. ,+#@#&)%$#&>?)D0#&P#B:1#&)%$. ,+#d'&;-,+#&!$.0)3;<s1()#MO33.0)3})5KMO;:;%21.0)3D03;!$. 1()>r%$P+)5Kq5).0%$'&9+%$%$.0;K;w1()#O?).0%_A)D09)%,!$.0)'&#5)#&'&;>rA;%G. 1.0;)by)#&'B1.0;[!$#&<#&!G!$#&5m1;#&>*A).0!G.0'&D%o19)5).0#&%%$.0>*.0D0!1;;9+!$%$U1()#&%G#d>*#B1(+;J5)%5).0#&!<N!$;> ;9)!$%.01()41Z1(+#B #&!$#D0.0>*. 1#&51;5)#&'&.0%$.0;1!G#&#&%$P3#&+#&!$D0D . 1(*<N# #&!5)417%G#B1%$bs\]#='&;-,+#&!O5)5+. 1.0;)D!$#&D041#&5 ;!$tI.0K1(+.0%W%$#&'B1.0;)bs.0)'&;D0r)5ry)tJ!GB^A^#&t/LNQSXSa-P).sLNQSSQaO)51()#W<N;!$#&'&%21.0)3D0. 1#&!$419)!$#KLNVWD0#&>*#&)PQSXSU}!$+3#&!$P=QSXSa*.0+5).0'&41#1()41m%$.0>*A)D0#I$,+#&!$3.0)36;<Z1()#IA)!$#&5).0'B1;!$%C3#&+#&!$41#&%*@,+#&!23;J;:5'&;>*A^;%$. 1#>*;J5+#&D0U+(); #B,+#&!$P>*mD041#&!!$#&%G#&!$'G()#&!G%wLNwD0A)-5).0)PQSS[U^%$t#&!x'&D0.0)PQSSPQSS?)UMO!$#&.0>*+PQSST'&Uv%G()#&>*P^QSSU'&D0.0)PQSSXUY#&!$!$;)#&P^QSS`U\];D0A^#&!21P^QSS`kU ())3P#&%$.0!$;-,P^x\]D 1&P^QSS`aO()-,+#<9+!21()#&!Z.0>*A+!$;-,+#&5@3#&)#&!$D0.0&41.0; . 1(},+;41.0)3%$'G()#&>r#&%1()41q!$#'&;>*A)D0#Bg'&;>?).0)41.0;)%;<#&'(A)!G#&5).0'B1;!$0%};91A+91b )#C>9+%21r?^#'&!G#&<9)D_.0/1().0%'&%$#&P%$.0)'&#;A1.0>*.0&.0+3W1()#='&;>?).0+.0)3 #&.03( 1%O'&@#&%$.0D uD0#&571;1()#A)!$;?)D0#&>z;<;-,+#&!$F1-1.0+3 (+.0'G(r%G.0>*A)D0#-,+#&!G3.0)3d%G#&#&>*%1;r$,+;.05LNy);D0D0.0'(x|}!$;3()PQSSTa-b;%21A)A+!$;'G()#&%;)D mhd&&f; z n1!21;}3#&)#&!G41#=().03()D /'&;!$!$#&'B1w'&D0%$%$.0F)#&!$%1()415).0%$3!G#&#W%>9)'G(@%A^;%$%G.0?)D0#&bOcW()#&%$#>*#B1();:5)%1!o1;'&!$#&41#q5). ,+#&!$%G#='&D0%$%$.0F+#&!$%O? C1!$.0+.0)37'&D0%$%G.0F)#&!$% . 1(5).0%$%G.0>*.0D0!=D0#&!$+.0)3rA)!G>*#B1#&!$%LNwD0A)$^5).0+PQSS[a-PR5).0#&!G#& 1K'&D0%$%$.0F)#&!w!$'G(+. 1#&'B19)!$#&%CLNv%$(+#&>*PQSSa-P,!$.0;9+%_.0). 1.0D))#&9)!GD EG)#B1 ;!$t #&.03(1=%$#B1-1.0)3%qLN'&D0.0*x A). 1&P)QSSU^'&D0.0rx"y)()-,:ED0.0t:PQSSa-P;!%$#&A)!$41#dA)!21. 1.0;)%;<R1()#q1!G.0).0)3u%G#B1LNMO!$#&.0>*)POQSSTUW|7!$;3(x~=#&5)#&D0%$?PQSSa-b@M;:;%21.0)3/;d1()#K;41()#&!(+)5.0%'B1. ,+#r.0r1!o^.0)31;/3#&)#&!G41#C().03()D '&;!$!G#&'B1r)#B1 ;!$t:%**fistv{wz{y{t%$.0)'&#@. 1m'&'&#& 19+41#&%*#B^>rA)D0#&%K'&9)!$!$#&1D '&D0%$%$.0F+#&5.0)'&;!$!$#&'B1D ? ]A)!G#B,^.0;9)%K>*#&>?^#&!$%;<1()##&)%$#&>?)D0#&biodgk L A). 1uxy)()$,^D0.0t:PqQSSTPqQSST?)ad.0%d);41()#&!d#B^>*A+D0#u;<q]A)A+!$;'G(61()415).0!$#&'B1D 1!$.0#&%1;6'&!$#&41#m65+. ,+#&!$%$#/#&)%$#&>?)D0#&b iodgk 9)%$#&%C3#&)#B1.0'D03;!$. 1()>*%}1;%$#&!$'(#BA)D0.0'&. 1D <N;!7m().03(+D 5+. ,+#&!$%$#r%G#B1@;<O'&'&9)!$41#71!$.0)#&5)#B1 ;!$t:%$b jdogk ;!$t:%?gF)!$%21'&!$#&41.0)3.0). 1.0DA^;A)9)D041.0;+PO1()#&9)%$#&%I3#&)#B1.0';A^#&!$41;!$%1;'&!$#&41#)# )#B1 ;!$t:%I'&;E1.0:9)D0D Pt#&#&A+.0)31()#C%$#B1d;<)#B1 ;!$t:%O1()41@!$#C().03()D '&'&9)!$41# ().0D0#C5).0%$3!$#&#&.0+3 . 1(6#&'(;41()#&!q%q>9+'G(%qA;%G%$.0?)D0#&b idogk .0%D0%$;I#&#&'B1. ,+#*41C.0)'&;!$A^;!$41.0)3@A)!$.0;!wtJ+; D0#&5)3#&P_.0<-,.0D0?)D0#&P+1;*.0>*A)!G;-,+#O1()#78J9)D0. 16;<R. 1%#&)%$#&>?)D0#&bwD 1#&!$)41#/A)A+!$;'G(1;@1()#I#&)%G#&>?)D0#/<N!$>*# ;!$t.0%w1;r1!G.0.0)5). ,.05)9)D)#B1 ;!$t:%*;%$9)?1%$t:P)5m1;r1()#&'&;>?+.0)#}1(+#&%$#dA+!$#&5).0'B1.0;)% . 1(4341.0)3<N9))'B1.0;u1()41/5)#&A^#&)5)%;1()#.0+A)91b'&;?)%u#B1D0b00%LNQSSQa5)A1. ,+#>r. J19)!G#&%/;<D0;:'&D7#BA^#&!21%$PM4:10%LNQSS`a>*#B1();:5g<N;!*.05)#&1.0<.0)36>=+;:'&!$5).0D=.0+<!$'B1.0;+Pw+5; D0+5gy)#B-); %GtJ.00%LNQSS`a7,.0%$9)D>*;:5)#&DD0D1!$.0])#B1 ;!$t:%1;6D0#&!$]%$A^#&'&.0F)'/%$9)?1%GtJ%$bcW(+#/t#B".05+#&;<H1(+#&%$#1#&'G()+.08J9)#&%d.0%1()415)#&'&;>rA;%G. 1.0;;<1()#A)!$;?+D0#&>.01;%$A^#&'&.0F)'u%$9)?1%$t:%@>*.03( 1D0#&51;>*;!$##&*'&.0#&1!$#&A)!G#&%$#& 141.0;+%=)5K1!G.0).0)3LNvw>*A)%$(+.0!$#x\].0?^#&D0PQSXSa-b+'&#*mA)!$;?+D0#&> .0%7?)!G;t#&6.0 1;%$9)?1%GtJ%$P1()#*!$#&%G9)D 1.0)3/%$;D091.0;+%)#&#&5/1;m?^#C'&;>?).0+#&5)b'&;?+%#B1ID0bqLNQSSQaKA)!$;A^;%$#r()-,.0)3C1(+#r341.0)3<9+)'B1.0;?^#*)#B1 ;!$t@1()41mn2f { 4h)iK(); 1;D0D0;:'&41#r#B>*A)D0#&%O1;1()#K#BA^#&!21%$b@cW(J9+%H1(+#341.0+3m)#B1 ;!$tD0D0;J'&41#&%#&'G(#B^>rA)D0#w1;/;)#;!/>*;!$##BA^#&!21%$P7+51(+#?+'Gt:A)!$;A)341#&5#&!G!$;!$%I)5!$#&%$9)D 1.0+3 #&.03(1'G())3#&%u!$#d1()#&!$#&%21!G.0'B1#&571;W1()#&%$#)#B1 ;!$t:%LN+51()#341.0)3K<9)+'B1.0;)a-bOcs!$#&%GAd)5dcs+.039)'G().LNQSSaA)!$;A^;%$#*>*#B1(+;J5m<N;!W5)#B1#&!G>*.0).0)3q1(+#341.0)3r<N9))'B1.0; {$} z f$1()#A)!$;?)D0#&>()%=?^#&#&/5)#&'&;>*A^;%$#&5)51()#q#BA#&!o1%1!G.0)#&5)bcW()#&.0!341.0)3C<N9))'B1.0;I.0%I.0)A)91-EG5+#&A#&+5)#& 1PD0.0)#&!2E #&.03( 1.0+3*<9+)'B1.0;1()41r.0%}5+#B1#&!$>*.0)#&56?/'&;>?).0)41.0;;<1()#C)#B1 ;!$t:%$_5). ,+#&!$%G. 1g;I1()#C'&9)!G!$#& 1*.0)A+91 . 1(1()#}D0.0t#&D0.0(+;J;:5C1()41=1()#&%$#})#B1 ;!GtJ%()-,+#}%G#&#&u5)414+#&!$q1()41.0+A)91bwD 1();9)3(w1()#>r. J19)!G#&%R;<#B^A^#&!21%_+5#&+%$#&>?+D0#A)!$5).03>*%_%G#&#&>,+#&!2I%G.0>*.0D0!$P1()#BI!$#O.0<N'B18:9). 1#O5).0%21.0+'B1<N!$;>q%2141.0%21.0'&D)A^;.01O;<,^.0# bc=()#>r. J19)!G#&%2EG;<EG#BA^#&!21%>*;:5)#&DJ>rt#&%^1()#%$%$9+>*A1.0;71()41q%$.0)3D0#w#BA#&!o1w.0%!$#&%$A^;)%$.0?)D0#<;!#&'G(I#B>*A)D0#&bWB71().0%'&%G#&P#&'(/#B^A^#&!21q.0%C>*;:5)#&D^;<sC!G#&3.0;m;<)1(+#.0)A)91%$A)'&#&P+51()#p;?/;<+1()#q341.0)3*<N9))'B1.0;u.0%R1;C5)#&'&.05)#<N!$;>().0'(d>r;J5)#&D1()#=5)41A^;.0 1w;!$.03.0)41#&%$by).0)'&#W#&'(@+#B1 ;!$t*.071()#=#&)%G#&>?)D0#A)A)!$;'(dD0#&!G)%1()# ();D0#w1%Gt!$41(+#&!1()@p9+%21*%$;>*#K%$9)?1%Gtu)5@1(:9)%>*t#&%}+;@%G9)'G(>919)D#B'&D09)%$. ,. 1%$%$9+>*A1.0;)P^#&)%$#&>?)D0#&%O!$#qA)A)!G;A)!$.041# ()#&I);;)#q>*;:5)#&D.0%(+.03()D D0.0t#&D @1;C?#'&;!$!$#&'B17<N;!;+#A;.01.0K1(+#.0)A)917%$A+'&#&bjcW().0%IA)A^#&!IA)!$#&%G#& 1%/'&;>*A)!G#&()#&)%$. ,+##&>*A+.0!$.0'&Dq#B,D09)41.0;;<7MO33.0)3g+5MO;:;%21.0)3<N;!)#&9)!GDw+#B1 ;!$tJ%)5"5)#&'&.0%$.0;1!$#&#&%$b 9)!I!$#&%G9)D 1%m5)#&>*;+%21!$41#@1()41MO33.0)3]#&)%$#&>?)D0#)#&!$D rD -%_;91A^#&!$<N;!$>*%s%$.0+3D0#'&D0%$%G.0F)#&!$b 9)!!G#&%$9)D 1%RD0%$;%G(); 1()41OMO;:;%21.0)3w#&)%$#&>?)D0#'&63!$#&41D g;91A^#&!$<N;!$>?^;41(MO33.0)3m)5/%$.0)3D0#C'&D0%$%$.0F+#&!$bIv; #B,+#&!$P<N;!}%$;>*#C5)41u%$#B1%MO;J;%o1.0)3>*-"%$(); &#&!$;3.0g;!*#B,+#&5+#&'&!$#&%$#/.0A^#&!$<N;!$>*)'&#I<N!$;>%$.0)3D0#/'&D0%$%$.0F+#&!$b)9)!o1()#&!w1#&%21%*.0)5+.0'&41#1()41mM;:;%21.0)3>*-%$9)#&!C<!$;>;$,+#&!$F1-1.0)36.01(+#@A+!$#&%$#&)'&#I;<w);.0%$#().0'(m>*$#BA)D0.0%$;>*#};<1()#5)#&'&!G#&%$#&%.0uA#&!G<;!$>r)'&#<;!=M;:;%21.0)3bZ\]#7D0%$;r<;9)+51()41}%$.0>rA)D0#=#&)%G#&>?)D0#=A)A)!$;'(r;<9)%$.0+3)#&9)!$D)+#B1 ;!$tJ%1()415+.0#&!;)D m.01()#&.0!!$)5);>z.0). 1.0D#&.03( 1K%$#B1-1.0)3%=A^#&!$<N;!$>*#&5/%G9)!$A)!$.0%G.0)3D #&D0D0P;<e1#&m5);.0)3r% #&D0Ds%1()#}MO33.0)3b**fir+su}SmQzrvr++zw)D %$.0%;<_;9+!=!$#&%$9+D 1%=%$9)33#&%o1%H1(+41=1()#A#&!G<;!$>r)'&#};<_?^;41(mMO;J;%o1.0)3d>r#B1();J5+%LNw5)4EMO;J;%o1.0)3/)5!G'&.0)3aq.0%41CD0#&%o1rA)!21D 5)#&A^#&)5+#& 1C;d1()#K5)41I%$#B1*?#&.0+3@#B>*.0)#&5+P ()#&!$#MO33.0)3%$(); %H>9)'G(dD0#&%$%'&;!G!$#&D041.0;)bWcW(+#W%21!$;)37'&;!$!$#&D041.0;)%O<N;!HMO;J;%o1.0)37>*$u?^#WA)!21.0D0D#BA)D0.0)#&5]?. 1%r%$#&+%$. 1. ,^. 1g1;6);.0%G#&Pw'&D0.0>%G9)A)A^;!21#&5?5)5+. 1.0;)D_1#&%21%Gb.0)D0D P #%$(); 1()41>9)'(u;<+1()#}A^#&!$<N;!$>*)'&##&)(+)'&#&>*#&1<;!=m#&)%$#&>?)D0#}'&;>*#&% . 1(K1(+#F)!$%217<N#'&D0%$%$.0F+#&!$%'&;>?).0)#&5+P?+91Z1()41MO;J;%21.0+35)#&'&.0%G.0;}1!$#&#&%O>*$'&;1.0J9)#H1;<9)!o1()#&!Z.0>*A)!G;-,+# . 1(D0!$3#&!#&)%$#&>?)D0#}%$.0&#&%$bB/'&;)'&D09)%$.0;+P%WC3#&)#&!$D1#&'G()).08:9)#}<N;!W5)#&'&.0%G.0;K1!$#&#&%W)5u)#&9)!$D^)#B1 ;!$t:%$PMO33.0)3d.0%A)!$;?+?)D A)A)!G;A)!$.041#w<;!>*;%o1A+!$;?)D0#&>*%$P?)91 ()#&IA)A+!$;A)!$.041#&P^MO;J;%o1.0)3uLN#&. 1()#&!w!$'&.0)3K;!w5)aW>*$A+!$;J5+9)'&#qD0!$3#&!=3.0)%.0m'&'&9)!$'Bb<)[fic ().0%_!G#&%$#&!$'G( %_A)!o1.0D0D /%G9)A)A^;!21#&5? I). ,+#&!G%$. 1m;<+.0))#&%G;41}}!$1%2EG.0EGw.05q1;?^;41(C9EW1();!$%Gb}q-,+# A). 1 %qD0%$;@%$9)A)A^;!21#&5u? w41.0;)Dy)'&.0#&)'&#);9))5+41.0;3!G 1C EGS[QSP1()#;1) [HYy)VW;Y#B1!$;D0#&9)> =#&%G#&!2,+;.0!V=()!$'B1#&!$.0&41.0;Y!$;jp#&'B1Pd wcWy3!$1%G9)A)A^;!21#&5g?1()#uw). ,+#&!$%G. 1;<;1)P7)5;1)y+'&.0#&)'&#cR#&'G(+);D0;34wD ED0.0)'&#K3!$1bCcW().0%q.0%q#BJ1#&)5+#&5r,+#&!G%$.0;;<ZIA)A^#&!A+9)?)D0.0%$()#&5.0d1()# ~ z fGf-h z{Ez h { nh } f-&f-h Gf "h W z \ -- { &n -h z f$nn |f-dhZfpwD0.0P}|}b0PwxY&&).0PbKLNQSSTa-b!$!$;!d!$#&5)9)'B1.0;1()!$;9+3(]D0#&!$).0+3>9)D 1.0A)D0#5)#&%$'&!$.0A1.0;)%$b{ hsgf f { 4h)Nh |P MPQ[4+`{`bwD0A)-5).0)PHb=LNQSS[a-b9)D 1.0A+D0#*)#B1 ;!$t:%}<N;!}<9+)'B1.0;6D0#&!$).0+3bmEZGfGfNh|i }]z fEMMC[-h z f-4h {Ez h { n h } f-&f-hGfh f ~ { n f z fii$P~=;D0bP^A)A)b^`4+[`dy)/)!$)'&.0%G'&;bw!$?).0?)PbZLN5)b0a-bHLNQSSa-b]f {h l;Gmb }W { Nh ;f {h f ~ { n f z fii$bOcYH!G#&%$%$bw%$t#&!$P=sb0Px'&D0.0)Pw=b}LNQSSa-b")%$#&>?)D0#&%C%*%$#&8:9)#&)'&#/;<='&D0%G%$.0F)#&!$%$bREZG fGf Nh|}z f }z fGf$h z -h z f-4h {Ez h { nk& Nh z h } f$f$hdG fj hWz \-- { nl- h z f-nNn | f-hdfpPA)A)b+XT{4+XTw3;-+PJA))bw%$t#&!$Pb0PJx'&D0.0)P)bLNQSS?)a-b+#&419)!$#O#&)3.0)#&#&!$.0+3)5'&D0%$%$.0F)#&!%$#&D0#&'B1.0;+'&%G#%o19)5*.0~C#&:9)%$.0=,+;D0'&);5+#B1#&'B1.0;)bB]E ZGfGf Nh |U}*z *f % ~ z ff-h z -h z f-4h {Ez h { n &h } f$f$dh Gf&h { hsgf f { 4h)Nh | PsA)A)b^[4+QQrw%$(,^.0D0D0#&PRcWwbMO9)#&!$Pb0Px|};()$,^.0PbLNQSSSa-bw#&>rA).0!$.0'&D:'&;>*A)!$.0%$;K;<j,+;41.0)3q'&D0%$%G.0F)'&41.0;*D03;!$. 1()>r%$MO33.0)3PR?^;J;%o1.0)3P)5K,!$.01%$Ab { Nhsgf Rf { 4h)8h |P X4PQ{4EGQ[SbMO4J1P\b7LNQSS`a-bB>*A)!$;$,^.0+3@1()#/'&'&9)!$'B;<wg!21.0F)'&.0D=)#&9)!$D)#B1 ;!Gt9+%$.0)3>9+D 1.0A)D0#5+.0#&!$#&1D I1!$.0)#&5)#B1 ;!$t:%$b f ~ { n 0k ~z;{Ez h%P P`4+X{bMO!$#&.0>*)PbHLNQSSTa-bqMO33.0)3rA)!G#&5).0'B1;!$%$bA{hsf0f { 4 h)Nh| PMLN`a-PRQ`[4+Q{bMO!$#&.0>*)PbqLNQSST?)a-bMO.0%$Ps,!G.0)'&#&PO)56!$'&.0)3'&D0%$%$.0F)#&!G%$bcs#&'()bH!$#&A+bZT{POVEGMO#&!$t#&D0#BPMO#&!$t#&D0#BPRVWwb*fistv{wz{y{tMO!$#&.0>*)PbHLNQSST'&a-bqy1'Gt#&5!$#&3!$#&%G%$.0;)%$bW{Nhsfgf { 4 h)Nh| PMLNQa-PRS4+TbVWD0#&>*#&+PbZLNQSXSa-bWVW;>?).0).0)3K<N;!$#&'&%21%$W!$#B,.0#%&;f { z Nh | WP 4PS4+X[b)5/));4141#&5/?).0?+D0.0;3!$A)(b-&~{ Cn }4hq!$9)'t#&!$Pvwb0PxVW;!o1#&%$PVWbLNQSSTa-bwMO;J;%o1.0)3r5)#&'&.0%G.0;C1!$#&#&%$bucs;9)!G#B1%$t Pwb0Ps;&#&!GPb0Pxvw%$%$#&D0>r;Pb_LNH5)%$b0a-lP UE {h Gf-ih f ~ { Xn -h } &k {Ezh Hm GGf$iGiGNh |]i z f-kKiGP~=;D0b^XPA)A)bS4+XIVW>?)!$.05+3#&PwbcYH!$#&%$%Gbq!$9)'t#&!$PHvwb0PZVW;!21#&%GPZVWb0P_'t#&D0Psb0PZ#&V=9))P<Kb0PHx~=A)).0t:P^~Kb=LNQSSa-b/MO;:;%21.0)3m+5;41()#&!>r'G().0)#wD0#&!$).0+3}D03;!$. 1()>*%GbZHm GGf;f Nh |fii}-z f n2af :f-h z -h z f-4h {Ez h { n &h } f$f$dh Gf&h { hsgf f { 4h)Nh | PsA)A)b^[4+TQ@# MO!$9+)% .0'tJPwbH<N!$;)PMb0PRxc=.0?)%$().0!$+.0P=bOLNQSS[a-b]Wh-h z Gw# =;!GtJb~ z h z z f G z z { +bV=()A)>*)5uvwD0D0P.0%$()#&!$Pqb0Px'&|}9)%$.0'tJP|}bRLNQSXSa-bwd#&>*A+.0!$.0'&D'&;>rA)!$.0%$;@;<q[)5@?)'GtEGA)!$;A)341.0;+bBE ZGfGf Nh |}zf n2af :f-h z -h z f-4h {Ez h { gn l&h z h } f-&f-h G"fh W z 3 - { Wn -h z f$nn|f-dhfpPA+A)b^XX4+S[@q#B1!$;. 1PsBb)!$#&9+)5)PXCb0PZxy)'G(+A).0!$#&PZb=LNQSSTa-bmA^#&!$.0>*#&1% . 1(6/)#fGf 8h |U}%zf N z ff-h z -h z f-4h {Ez h { n h } -f &f-hdfAhxMO!$.0Ps 1D b?^;:;%21.0)3/D03;!$. 1()>rb/EEhsPf Rf {h+h |PA)A)bQX4+QT{)!$.0#&5+>*)PRbLNQSSTa-b ?).0%GP),!$.0)'&#&P_{+Q4EGD0;%$%GP_)5*1(+#'&9)!G%$#BEG;<EG5+.0>*#&)%$.0;)D0. 1bl}0x{Ez;{ uNh)8h | { dh jhd nof;E|f i;Ef-fiP-4b~4h{n)!$.0#&5+>*)Pb0Pv%21.0#&P^cWb0PxcW.0?)%$().0!G).0P+bRLNQSSXa-bHw5)5). 1. ,+#wD0;3.0%21.0'!$#&3!G#&%$%$.0;)O"%2141.0%21.0'&D,.0# ;<R?^;J;%o1.0)3bLN(1-1A) + WW EG%o141b0%21)<N;!$5)b0#&5)9 Bp(+<-a-b}#&>*+Py)b0PMO.0#&)#&)%21;:'Gt:PRHb0Pxq;9)!$%G41P=bHLNQSS`a-bww#&9)!$D)#B1 ;!GtJ%)5K1()#?).0%;4,!$.0+'&#5+.0D0#&>*>*b f ~ { n 0k ~z;{Ez h%P PQ4+Xb}!$+3#&!$PV=bLNQSXSa-bVW;>?).0).0)3/<N;!$#&'&%21%$@c #& 1+#&!$%D041#&!$b&QT4+Q[b~4hn } &f; { z Nh|PWP{g}!$;$,+#&Pqb0Pxy)'(J9+9)!$>*)%GPWqb7LNQSSXa-b"M;:;%21.0)3.01()#/D0.0>*. 14.0>*.0&.0)3m1()#I>*!$3.0g;<D0#&!G)#&5#&)%$#&>?)D0#&%$bKHm GfG;f &h |fi}z Uf } z ff-h zi{Ez h { n &h } f$f$dh Gfh W z \ -$ { n-h z f-nNn v |:f$dh Gf-PA)A)b^TS`4+TSSI5+.0%$;)P\bvw>*A)%$().0!G#&PJb0Px]\].0?^#&D0Pb_LNQSXSa-bOcW()#=>r#B14EGA).^)#B1 ;!$t:M9+.0D05).0)35).0%21!$.0?)91#&5dt:); D0#&5)3#!G#&A)!$#&%$#&141.0;)%I<;!@!$;?)9+%21A)41-1#&!$!$#&'&;3). 1.0;+bcs#&'()bw!$#&A)bWVWHEGVWyEGXS4EGQTTPVWwPY. 1-1%$?)9)!G3()PY^bvw)%$#&)Pb0Pqxy)D0>*;)PY^bCLNQSS{a-b#&9+!$Dq)#B1 ;!$t#&)%$#&>?)D0#&%$b[C+ { +h{Ezz f-4"h Wh { n iGNi {h ] { Nhsgf -h z f$nn v |:f-h GfpPCmPSS[4+Q{{Qbvw%$()#&>*Py)bLNQSSa-b A1.0>*DD0.0)#&!@'&;>?).0+41.0;)%d;<+#&9)!$DW)#B1 ;!GtJ%$bLNa-PRSS4+TQbZp*{ z h+i&hf ~ { n f z iGPfir+su}SmQzrvr++z'&;?+%$Pb0P7J;!$5))P}b0P; D0)Py)b0P7xvw.0 1;+P}b*LNQSSQa-b5+A1. ,+#>*. J19+!$#&%/;<7D0;:'&D#BA^#&!21%$b f ~ { n 0k ~z;{Ez hP%PS4+Xb|};()$,^.0PKb0Px\];D0A#&!o1PqbrLNQSSTa-bMO.0%mA)D09+%,!$.0+'&#5)#&'&;>*A^;%$. 1.0;<N;!m&#&!$;4EG;)#D0;%$%<N9))'B1.0;+%$bE GfGf 8h |c}zf N z ff-h z -h z f$h {mz h { n h } f$f$dh Gfh { hRff { 4h)Nh | PsA)A)b`4+`X[@MO!$.0P 1D b|};)3P:Hb0PJxgq.0#B1-1#&!$.0'G(+P)cWbLNQSSa-bH!$!G;!2EG'&;!$!$#&'B1.0)3=;91A)91'&;:5).0)3='&;!$!$#&'B1%R?).0%)5W,!G.0)'&#&bBHm GGf;f Nh |fif}Pz 0f f$n }z -h z f-4h {Ez h { n h } f-&f-dhgf &h { Nhs[f Rf {h)Nh |P)A)A)bJ[Q[4[`Qdcs(+;J#}V=. 1PVWwb|}!$;3(+P_b0P_x~=#&5)#&D0%G? Pb=LNQSSa-b/w#&9)!$D)#B1 ;!$t#&)%$#&>?)D0#&%$PZ'&!G;%$%O,D0.05)41.0;)PH+5'B1. ,+#D0#&!G).0)3b"cR#&%$9)!G;P7b0PcR;9)!$#B1&tPCqb0PKx#&#&)PKcWb*LNH5+%$b0a-P@E { hdf-ih f ~ { n-h } 4k {Ezh Hm Gf-iGi8h |xi z f$kiGP~=;D0bPA)A)b`[Q4+`[X@VW>?+!$.05)3#&PbBcYH!G#&%$%$b.0+'&;D0)P\b0Pxy)t:!$B^A^#&t:PJbOLNQSXSa-b*y^)#&!G34;<H'&D09)%21#&!G.0)3d>9)D 1.0A)D0#K?)'tuA)!G;A)341.0;)#B1-EP UE {h Gf$iNh f ~ {n -h } 4k {Ezh Hm GGf$iGiGNh |i z f$kiGP;!$t:%$bcR;9)!$#B1&tP_wbLNH5+b0a-%~=;D0bs`PA)A)bT{4+TS@y)m41#&;PRVWb;!$3|}9)<N>*))b'&D0.0)P=bLNQSSXa-bKMO;:;%21.0)3@'&D0%$%$.0F)#&!$%q!$#&3.0;+D0D b7BEGfGfh8|i^ }@z f@ }z fGf$h&h } f$f$dh Gfh W z \ -$ {n -h z f-nNn v |:f$dh Gf-PA)A)b{{4+{@5+.0%$;)P\bzb{Ez h {'&D0.0)P7b0Pwx A). 1&P7wb*LNQSSa-bw#&>*A).0!$.0'&Dw#B,D09+41.0;;<}?)33.0)3)5?^;J;%o1.0)3bzBE ZGfGf Nh|ix }z f% ~ z ff-h z{Ez &h { n h } f-&f-hdf]&hW z 3-$ { n<-h z f$nn v|:f-hGfpPA)A)b+T4QdYH!$;$,^.05+#&)'&#&P=Bb'&D0.0)PZ=b0Pxy)(+-,D0.0tJP_JbLNQSSa-b@VW;>?).0).0)31()#KA)!G#&5).0'B1.0;)%;<H>9)D 1.0A)D0#C'&D0%G%$.0F)#&!$%$w%$.0)3'&;>rA#B1. 1. ,+#=D0#&!$).0)31;.0). 1.0D0.0&#W+#&9)!$D:)#B1 ;!$t:%$bBiE ZGfGf Nh |f}[z [f % ~ z ff-h z -hfh W z 3 -$ {n -h z f$nn v |:f-h GfpPA)A+b`4+[{;1!$#&D0P)V=)5)bz f$h {Ez &h { n &h z h } f-&f-dh).0P)}bLNQSSQa-bs; #&!$.0)3,!$.0)'&#;<5)#&'&.0%$.0;)%_?@9)%G.0)3!o1.0F)'&.0D)#&9)!$D)#B1 ;!Gt7A^;!21<N;D0.0;%$bk ~z;{Ez hP%PX4+XTbf ~ { n 0;J;)#BP=b0Py)()$,^D0.0t:Pb0P7cR; #&D0D0PK}b0Px};-,+#&PKwbrLNQSXSa-bw#B^A^#&!$.0>*#&1D'&;>*A)!G.0%$;;<%o^>?^;D0.0')5'&;))#&'B1.0;).0%o1D0#&!$+.0)3D03;!G. 1()>*%$bBEZGfGfNh|i }z fn2fa:f$h z-h z f-4h {Ez h { n l&h z h } f-&f-h Gxfh W z \ -- { &n -h z f$nn |f-dhfpPA+A)b^4+X{@q#B1!$;. 1PsBb9)!$A)(PY^b}b0P}xw()PKqbO\brLNQSSa-bwVWr!G#&A;%G. 1;!2;<K>*'().0)#6D0#&!G).0)35)41?)%G#&%LN>r'G().0)#BEG!G#&5)?)D0#m5)41!G#&A;%G. 1;!2^a-b]). ,+#&!G%$. 1";<=VWD0.0<N;!$).04EGB!2,.0)#&P=q#&A)!o1>*#& 1u;<B)<N;!$>*41.0;)5/VW;>*A)91#&!Wy)'&.0#&)'&#&bw; D0)Py)b0Pxy)#Bp+; %$t:.0PcWb}LNQSS`a-b].0D 1#&!*%G#&D0#&'B1.0;]>*;:5)#&D<;!K3#&)#&!$41.0+3@,^.0%$9+D>r;41.0;%G.03)D0%$brv)%G;)P)y)b0PVW; )P+Jb0P+x7.0D0#&%$PV=bsLNH5)%Gb0a-P<UE { hGf-i=h f ~ { n8-h } 4k {mz hE ZGf-iiGNh |xi z f-kKi$P)~=;D0bPA)A)b[TS4+[TIy)/41#&;PRVWb;!$3|}9)<N>*))bA). 1&P:qb0Pxgy+()-,D0.0tJP:b+LNQSSTa-bw'B1. ,+#&D d%$#&!$'().0)3W<N;!}#&#&'B1. ,+#O)#&9)!$D EG+#B1 ;!$tq#&)%$#&>?)D0#&b&h)hs;f z &"h d--f-dhfpkP OLN+[ a-P[[4+[[b*ffnfistv{wz{y{tA). 1&POqb0PHxy)()$,^D0.0t:PObwLNQSST?+a-b6}#&)#&!$41.0+3'&'&9)!G41#d)55). ,+#&!$%$#d>*#&>?#&!G%7;<u+#&9)!$D E+#B1 ;!$t6#&)%$#&>?)D0#&bcs;9)!G#B1%$t Pqb0PO;&#&!$PWb0Pxvw%$%$#&D0>*;PbqLN5)%$b0a-P UE {h Gf-iNh f ~ { ln -h } &k {Ezh Hm GGf$iGih |ji z f$kKi$P:~=;D0b^XP^A)A)b+[4+QrVW>?+!$.05)3#&P^wbBcY!$#&%$%$bY#&!$!$;)#&P=bLNQSS`a-b]%G;<1-EG'&;>*A^#B1. 1. ,+#m%GA)D0. 1-1.0)3!$9)D0#@<;!K5)A1. ,+#71!G#&#BEG%21!$9)'B19)!G#&5+#&9)!$D+#B1 ;!$tJ%GbBHm GGf;f Nh |^}Uz ff -h z f-4h {Ez h { *n &Nh z h } f-&f-h Gf &h f ~ { n f z iGPA+A)bTXS4+TS[dMOD 1.0>*;!G#&PsqbY#&!$!$;)#&PqbLNQSS[a-b-k0EmNh|"f|fif$iGihi z Nk {Ez &hdW:f$ { |Nh|f z Gi } { 4 { hdGfw;f ~ z h z [ z f$h)iG h z f-hsf$ { n h:faf { ~ f"o z kKv {Ez hbYH()b0qb1(+#&%$.0%$PMO!$; uw). ,+#&!$%G. 1PY!$;-,.05)#&)'&#&P=Bb}9).0+D0)P+JbRLNQSS[a-bV=bXMCE |fi {ki} {hsfWRf {h+h|bZ;!$3d|79)<>r))P+y+r41#&;P}9).0+D0)PJb=brLNQSSTa-bM33.0+3PC?;:;%21.0)3PK)5'&b0bEGfGfh8|i }zffh W z 3 - { &n -h z f-nNn |f-dhfpPA)A+b`4+[{bY;!21D0)5+P =b{Ez h { n h } f-&f-dhxN z ff-h z=9+>*#&D0()!21POqb0Pv.01;)PO}b0Px\.0D0D0.0>r%$P=bLNQSXTa-bs#&!$).0)3.0 1#&!G)D!G#&A)!$#&%$#&141.0;)%K?#&!G!$;!A+!$;A)341.0;)b6B9)>*#&D0()!o1Pqb0Px'&VWD0#&D0D0)5)PJbwLNH5+%$b0a-P { { nNn2f$n z-l ~z fE ZGf-iiGNh |gCn {Ez h)iKh z fkK $E &i z ~ z~f } ; |fih) zh l&n ~ kmfMA ~ h {Ez h)i$PA+A)b[QX4+[T[bBcYH!G#&%$%$PVW>?)!$.05)3#&Pwby)'()A).0!$#&PbHLNQSS{a-bc=()#%21!$#&)341(u;< #&tID0#&!$)?).0D0. 1bg{hsfgf { 4 h)Nh| P-LN`a-PRQS4+``by)'()A).0!$#&P=b0P=+!$#&9))5)PPKb0PMO!21D0#B1-1PqYb0Pwx#&#&PH\b7LNQSSa-b"M;:;%21.0)3/1()#/>*!$3.0))##BA)D0)41.0;<N;!_1()#}#&#&'B1. ,+#&)#&%$%q;<,+;41.0)3d>*#B1();:5)%$bbE ZGfGf Nh |}gz gf % ~ z ff-h z-h z f-4h {Ez h { n h } f-&f-dhxfh { Nhs0f Rf {h+h |PA)A+b[``4+[[{dw%$(,^.0D0D0#&PscWby);D0D0.0'()PYb0Px|}!$;3()PRwbOLNQSSTa-bCs#&!$).0)3 . 1(#&)%$#&>?)D0#&%$}vw; ;-,+#&!oEGF1-1.0)3/'&?#9)%$#&<N9)D0bB*cR;9)!$#B1%$tPwb0P;&#&!$Pb0Pxv%G%$#&D0>*;PbLNH5)%$b0a-PX@m { hdf-iWNh f ~ { n8-h } 4k {mz hE ZGf-iiGNh |xi z f-kKi$P)~=;D0bXPA)A)bQS{4+QSTIVW>?)!$.05+3#&PwbcY!$#&%$%$bcR!$#&%$A)P~Cb0PxcR).039)'G(+.0P=b7LNQSSa-bV=;>?).0+.0)3#&%21.0>*41;!$%*9+%$.0)3);EG'&;)%o1 1 #&.03( 1.0+3<N9))'B1.0;+%$bcs#&%G9)!$;P}b0P}cR;9)!$#B1&tP}qb0P}x#&#&)PcWbKLNH5)%Gb0a-P @E {hf-imNh f ~ { n-h } 4k {Ezh Hm Gf-iGi8h |xi z f$kiGP~=;D0bPA)A)bQS4+`T@VW>?+!$.05)3#&PbBcYH!G#&%$%$b\];D0A^#&!21PqbLNQSS`a-bwy1't#&5u3#&)#&!$D0.0&41.0;+bf ~ { n f z iGP4P`Q4+`Sb()+3PCb0P^#&%G.0!$;-,Pb0P^x\]D 1&PqbZLNQSS`a-bWvH^?)!G.05d%2%21#&><N;!OA)!$;41#&.0/%$#&'&;)5+!2%21!$9+'B19)!$#A+!$#&5).0'B1.0;)bA& ~ 4h { n } nof; ~ n { n |ZjPM<4 PsQ{S4+Q{T[b**fi"[r+su}SmQzrvr++zHncR?)D0#&%O)5@%$();q41ry)#B1?)!$#&%o1-EG'&)'&#&!2E'&!$#&5). 1-EG'&!$#&5). 1-EG35).0?^#B1#&%3D0%$%()#&!21-EG'&D0#B,+#&D0+5()#&A)41. 1.0%();9)%G#BEo,+;41#&%2EGX(^A^;.0;);%$A+()#&!$#.0!$.0%t:!2Eo,^%oEGtJAD0?^;!D0#B1-1#&!A)!$;>r;41#&!$%2EGS[T!$.0?^;%$;>*#BEG?+.0)5%$41#&D0D0. 1#%$#&3>*#&141.0;%$.0'%$;)!%$;$^?^#&%$A)D0.0'&#,+#&().0'&D0#1()#'&;>*A)D0#B1#q!$#&%$9+D 1%<N;!1()#F+!$%21w%G#B1q;<#BA^#&!$.0>*#&1%9+%$#&5d.071().0%OA)A^#&!$bH!$![b0Qb0X`b0S`[b0S[Xb0TQXb0T`{b0Qb0STb0Sb0b0[`b0[Tb0QQXb0{b0[Sb0[Q[b0{Tb0Tb0SQTb0TSb0`b0`b0Sy+.0)3D0#y){b0[{b0{b0X{b0SQb0Qb0{Qb0T{b0T{b0`Qb0[Qb0{b0Qb0{b0[{b0T{b0{b0[{b0{b0Qb0Qb0Q{b0`Qb0`MO#&%21`b0SQ[b0T`Tb0```b0T[Tb0SQTb0XQSb0Qb0QTb0`b0`b0{Qb0[b0Qb0Tb0Xb0SQ`b0Tb0b0`Qb0Sb0{b0``b0S.0>rA)D0#)H!G!y)[b0{b0`Q[b0{b0`b0{b0``[b0{{b0[b0`Qb0QQb0Qb0QQSb0Qb0b0X{b0`Tb0`{b0Qb0{b0[b0S{b0[{b0X{b0Q[b0`{b0XQ`b0X{b0`b0X{b0[Xb0{b0[Q{b0S{b0`b0[{b0[b0{b0`Qb0SQb0`Tb0{b0b0{{b0``Qb0`{b0X33.0)3!$!y)[b0{b0`Q[b0X{b0T`b0`{b0``b0X{b0[[b0QQb0SQb0{{b0TQb0X{b0b0Q{b0`Tb0`{b0QSb0`Qb0`b0{{b0{b0X{b0`b0`Qb0{Q{b0{b0[b0{{b0[Xb0{b0Q{b0T{b0[b0{b0`b0{b0QQTb0XQb0QTb0S{b0[b0S{b0Q`{b0{b0T!$'&.0)3wH!$!y)[b0X{b0Qb0X{b0T`b0`{b0X`b0{b0`[`b0{`b0`{b0Qb0TQSb0{Qb0[b0Q{b0Tb0`{b0Qb0T{b0T[b0{b0T{b0{b0Q[b0`{b0Xb0{b0b0{b0`Xb0Q{b0`Sb0S{b0`[b0{b0`b0{b0`Q`b0SQb0Tb0{b0b0{{b0QQSb0QQb0{;J;%o1.0)3H!G!y)b0{{b0Qb0{b0T`b0[{b0Q`[b0[Qb0`[Qb0Q{b0S`Qb0Q{b0SQSb0{b0Sb0[{b0Tb0`{b0QXb0[{b0[b0SQb0{{b0[{b0Q[b0`{b0Xb0T{b0Qb0T{b0[Xb0`{b0[Q{b0{{b0[[b0[{b0`b0{b0[Q[b0{Qb0Tb0[{b0Tb0`{b0QQSb0Qb0{cR?)D0#}}w#&9)!$D)#B1 ;!$t*1#&%21*%$#B1C#&!$!$;!q!$41#&%)5%21)5+!$55+#B,^.041.0;@,D09)#&%<N;!H1(+;%$##&!G!$;!!$41#&%<N;!7LNQaK%$.0)3D0#q)#&9)!GD+#B1 ;!$tr'&D0%$%G.0F)#&!$UHLN`aK%$.0>*A)D0#q)#&9+!$D+#B1 ;!$td#&+%$#&>qE?)D0#&UwLN[a}IM33.0+3m#&)%$#&>?)D0#&UwLNaw!$'&.0)3I#&)%G#&>?)D0#&U)5]LNa)5w5)4EGMO;J;%21.0+3#&)%G#&>?)D0#&b=D0%$;K%$(+; 6LN!$#&%$9+D 1%'&;D09)>*I[a.0%R1()#C4?#&%o1!G#&%$9)D 1}A)!$;:5)9)'&#&5@<!G;>D0D;<1()#7%$.0)3D0#})#B1 ;!Gt@!G#&%$9)D 1%W!$9+/9)%$.0)3CD0D;<1()#1!G.0).0)3*5)41b*fiq41ry)#B1?)!$#&%o1-EG'&)'&#&!2E'&!$#&5). 1-EG'&!$#&5). 1-EG35).0?^#B1#&%3D0%$%()#&!21-EG'&D0#B,+#&D0+5()#&A)41. 1.0%();9)%G#BEo,+;41#&%2EGX(^A^;.0;);%$A+()#&!$#.0!$.0%t:!2Eo,^%oEGtJAD0?^;!D0#B1-1#&!A)!$;>r;41#&!$%2EGS[T!$.0?^;%$;>*#BEG?+.0)5%$41#&D0D0. 1#%$#&3>*#&141.0;%$.0'%$;)!%$;$^?^#&%$A)D0.0'&#,+#&().0'&D0#!$!b0{Qb0S`Sb0T`b0X[Qb0[`b0[`Qb0`[b0T{b0Xb0Qb0`{b0TQTb0Qb0{Q`b0XQQb0`Q[b0X[b0Qb0[`Sb0Xb0{b0S`Sb0y+.0)3D0#y){b0{b0XQb0{Qb0{`b0QQb0[Qb0`{b0[{b0Q{b0{b0{b0Q[b0{b0X{b0{b0T{b0{b0`{b0SQb0S{b0{b0[{b0stv{wz{y{t33.0)3H!$!y+[b0{b0Q[b0{b0`b0`{b0`b0{b0X`b0X{b0QSb0{b0Qb0[`b0{[b0T{b0`{b0{b0{Tb0{b0Tb0S{b0X{b0T{b0QQ[b0{b0Xb0{{b0QQ{b0T{b0TQ{b0`{b0QSb0S{b0`[b0{{b0`Qb0`{b0Q`b0[Qb0[b0S{b0b0{b0``b0Q{b0SMO#&%21b0{Qb0``Xb0`Tb0`Xb0``b0`{b0{[b0`{b0b0Qb0[{b0Q`b0Q`b0`Q`b0Q{b0XQ[b0[b0Qb0Q`Tb0Sb0b0`Xb0T!$'&.0)3w!$!y)[b0{b0TQb0{{b0S`b0SQb0{`Tb0{{b0T`b0Qb0`Qb0Qb0TQTb0SQb0Qb0{Qb0Q{b0{b0QTb0{{b0b0Q{b0T{b0[{b0QQ[b0{`b0Sb0Q{b0QTb0X{b0Sb0[{b0`Xb0T{b0QQb0{b0`Qb0Q{b0Q`Qb0[b0{b0`{b0`b0Q{b0Q``b0{b0X;:;%21.0)3H!$!y)[b0{b0[Q[b0{b0`Tb0{b0`b0{b0T`[b0[Qb0[`{b0XQb0{Qb0`Qb0[b0XQb0{{b0{b0{Tb0Q{b0b0TQb0Q{b0{b0{QQb0T`b0{[b0S{b0QTb0{b0[Sb0T{b0Xb0{b0`Qb0{b0`Qb0{{b0Q`Qb0`b0XTb0{b0Sb0[{b0```b0SQb0ScR?)D0#}}q#&'&.0%$.0;1!$#&#*1#&%21%$#B1#&!$!$;!d!$41#&%d+5g%21)5)!G5]5)#B,.041.0;6,D09)#&%@<;!}1();%$#m#&!G!$;!!$41#&%O<N;!qLNQa7%G.0)3D0#5+#&'&.0%$.0;}1!G#&#'&D0%$%G.0F)#&!$UZLN`aMO33.0)3K#&)%$#&>?)D0#&UZLN[a@w!$'&.0)3#&)%G#&>?)D0#&U)5LNaq)55)4EGMO;:;%21.0)3I#&)%$#&>?)D0#&bD0%G;d%$(+; LN!$#&%$9)D 1%w'&;D09)>*[aw.0%1()#m4?^#&%21/!$#&%G9)D 1*A)!$;:5)9)'&#&5<!$;>D0D_;<1()#K%$.0)3D0#w1!$#&#C!G#&%$9)D 1%q!$9)9)%$.0+3@D0D_;<1()#1!$.0+.0)3*5)41bZ*fiJournal Artificial Intelligence Research 11 (1999) 95-130Submitted 3/98; published 7/99Semantic Similarity Taxonomy: Information-BasedMeasure Application Problems AmbiguityNatural LanguagePhilip Resnikresnik@umiacs.umd.eduDepartment LinguisticsInstitute Advanced Computer StudiesUniversity MarylandCollege Park, MD 20742 USAAbstractarticle presents measure semantic similarity is-a taxonomy basednotion shared information content. Experimental evaluation benchmarkset human similarity judgments demonstrates measure performs bettertraditional edge-counting approach. article presents algorithms take advantage taxonomic similarity resolving syntactic semantic ambiguity, alongexperimental results demonstrating effectiveness.1. IntroductionEvaluating semantic relatedness using network representations problem longhistory artificial intelligence psychology, dating back spreading activationapproach Quillian (1968) Collins Loftus (1975). Semantic similarity representsspecial case semantic relatedness: example, cars gasoline would seemclosely related than, say, cars bicycles, latter pair certainly similar.Rada et al. (Rada, Mili, Bicknell, & Blettner, 1989) suggest assessment similaritysemantic networks fact thought involving taxonomic (is-a) links,exclusion link types; view also taken here, although admittedlylinks part-of also viewed attributes contribute similarity (cf.Richardson, Smeaton, & Murphy, 1994; Sussna, 1993).Although many measures similarity defined literature, seldomaccompanied independent characterization phenomenon measuring,particularly measure proposed service computational application (e.g.,similarity documents information retrieval, similarity cases case-based reasoning).Rather, worth similarity measure utility given task. cognitivedomain, similarity treated property characterized human perception intuition,much way notions like \plausibility" \typicality." such, worthsimilarity measure fidelity human behavior, measured predictionshuman performance experimental tasks. latter view underlies workarticle, although results presented comprise direct comparison humanperformance also practical application problems natural language processing.natural, time-honored way evaluate semantic similarity taxonomy measuredistance nodes corresponding items compared | shorterc 1999 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiResnikpath one node another, similar are. Given multiple paths, onetakes length shortest one (Lee, Kim, & Lee, 1993; Rada & Bicknell, 1989; Radaet al., 1989).widely acknowledged problem approach, however, reliesnotion links taxonomy represent uniform distances. Unfortunately, uniformlink distance dicult define, much less control. real taxonomies, widevariability \distance" covered single taxonomic link, particularly certainsub-taxonomies (e.g., biological categories) much denser others. example,WordNet (Miller, 1990; Fellbaum, 1998), widely used, broad-coverage semantic networkEnglish, dicult find links cover intuitively narrow distance(rabbit ears is-a television antenna) intuitively wide one (phytoplanktonis-a living thing). kinds examples found Collins COBUILDDictionary (Sinclair, ed., 1987), identifies superordinate terms many words (e.g.,safety valve is-a valve seems much narrower knitting machine is-a machine).first part article, describe alternative way evaluate semantic similarity taxonomy, based notion information content. Like edge-countingmethod, conceptually quite simple. However, sensitive problemvarying link distances. addition, combining taxonomic structure empiricalprobability estimates, provides way adapting static knowledge structure multiple contexts. Section 2 sets probabilistic framework defines measuresemantic similarity information-theoretic terms, Section 3 presents evaluationsimilarity measure human similarity judgments, using simple edge-countingmethod baseline.second part article, Sections 4 5, describe two applications semanticsimilarity problems ambiguity natural language. first concerns particularcase syntactic ambiguity involves coordination nominal compounds,pernicious source structural ambiguity English. Consider phrase foodhandling storage procedures: represent conjunction food handling storageprocedures, refer handling storage food? second applicationconcerns resolution word sense ambiguity | words running text,large open problem (though cf. Wilks & Stevenson, 1996), groups related wordsoften discovered distributional analysis text corpora found dictionariesthesauri. Finally, Section 6 discusses related work.2. Similarity Information ContentLet C set concepts is-a taxonomy, permitting multiple inheritance. Intuitively,one key similarity two concepts extent share information, indicated is-a taxonomy highly specific concept subsumes both.edge-counting method captures indirectly, since minimal path is-a links two nodes long, means necessary go high taxonomy,abstract concepts, order find least upper bound. example, WordNet, nickeldime subsumed coin, whereas specific superclass nickelcredit card share medium exchange (see Figure 1). feature-based setting(e.g., Tversky, 1977), would ected explicit shared features: nickels dimes96fiInformation-Based Semantic SimilarityMEDIUM EXCHANGEMONEYCASHCREDITCOINNICKELDIMECREDIT CARDFigure 1: Fragment WordNet taxonomy. Solid lines represent is-a links; dashed linesindicate intervening nodes omitted save space.small, round, metallic, on. features captured implicitlytaxonomy categorizing nickel dime subordinates coin.associating probabilities concepts taxonomy, possible captureidea edge-counting, avoiding unreliability edge distances. Lettaxonomy augmented function p : C ! [0; 1], c 2 C , p(c)probability encountering instance concept c. implies p monotonicallynondecreasing one moves taxonomy: c1 is-a c2, p(c1 ) p(c2). Moreover,taxonomy unique top node probability 1.Following standard argumentation information theory (Ross, 1976), information content concept c quantified negative log likelihood, , log p(c).Notice quantifying information content way makes intuitive sense setting: probability increases, informativeness decreases; abstract concept,lower information content. Moreover, unique top concept, informationcontent 0.quantitative characterization information provides new way measure semantic similarity. information two concepts share, similar are,information shared two concepts indicated information content conceptssubsume taxonomy. Formally, definemax [, log p(c)] ;sim(c1; c2) =(1)c 2 (c1 ; c2)(c1; c2) set concepts subsume c1 c2. class achievesmaximum value Equation 1 termed informative subsumer; oftenunique informative subsumer, although need true general case.Taking maximum respect information content analogous taking firstintersection semantic network marker-passing shortest path respect edgedistance (cf. Quillian, 1968; Rada et al., 1989); generalization taking maximumtaking weighted average introduced Section 3.4.Notice although similarity computed considering upper bounds twoconcepts, information measure effect identifying minimal upper bounds, sinceclass less informative superordinates. example, Figure 1, coin, cash,etc. members (nickel; dime), concept structurally minimal97fiResnikPERSONp=.2491info=2.005ADULTp=.0208info=5.584FEMALE_PERSONp=.0188info=5.736PROFESSIONALp=.0079info=6.993ACTOR1p=.0027info=8.522INTELLECTUALp=.0113info=6.471DOCTOR2p=.0005info=10.84NURSE2p=.0001info=13.17HEALTH_PROFESSIONALp=.0022info=8.844DOCTOR1p=.0018info=9.093GUARDIANp=.0058info=7.434LAWYERp=.0007info=10.39NURSE1p=.0001info=12.94Figure 2: Another fragment WordNet taxonomyupper bound, coin, also informative. make difference casesmultiple inheritance: two distinct ancestor nodes may minimal upper bounds,measured using distance graph, two nodes might differentvalues information content. Also notice is-a taxonomies WordNet,multiple sub-taxonomies unique top node, asserting zero similarityconcepts separate sub-taxonomies (e.g., liberty, aorta) equivalent unifyingsub-taxonomies creating virtual topmost concept.practice, one often needs measure word similarity , rather concept similarity.Using s(w) represent set concepts taxonomy senses word w,definewsim(w1; w2) = cmax(2)1; c2 [sim(c1; c2)] ;c1 ranges s(w1) c2 ranges s(w2). consistent Rada et al.'s(1989) treatment \disjunctive concepts" using edge-counting: define distancetwo disjunctive sets concepts minimum path length elementfirst set element second. Here, word similarity judged takingmaximal information content concepts words could instance. take example, consider word similarity wsim(doctor, nurse) wouldcomputed, using taxonomic information Figure 2. (Note noun sensesconsidered here.) Equation 2, must consider pairs concepts hc1; c2i,c1 2 fdoctor1; doctor2g c2 2 fnurse1; nurse2g, pair mustcompute semantic similarity sim(c1 ,c2) according Equation 1. Table 1 illustratescomputation.98fiInformation-Based Semantic Similarityc1 (description)c2 (description)sim(c1 ,c2)doctor1 (medical) nurse1 (medical) health professional8.844doctor1 (medical) nurse2 (nanny)person2.005doctor2 (Ph.D.) nurse1 (medical)person2.005doctor2 (Ph.D.) nurse2 (nanny)person2.005subsumerTable 1: Computation similarity doctor nursetable shows, senses doctor considered sensesnurse, maximum value 8.844, via health professional informativesubsumer; is, therefore, value word similarity doctor nurse.13. Evaluationsection describes simple, direct method evaluating semantic similarity, usinghuman judgments basis comparison.3.1 Implementationwork reported used WordNet's taxonomy concepts represented nouns (andcompound nominals) English.2 Frequencies concepts taxonomy estimatedusing noun frequencies Brown Corpus American English (Francis & Kucera,1982), large (1,000,000 word) collection text across genres ranging news articlesscience fiction. noun occurred corpus counted occurrencetaxonomic class containing it.3 example, Figure 1, occurrence noundime would counted toward frequency dime, coin, cash, forth. Formally,Xfreq(c) =count(n);(3)n2words(c)words(c) set words subsumed concept c. Concept probabilitiescomputed simply relative frequency:(4)p^(c) = freq(c) ;NN total number nouns observed (excluding subsumedWordNet class, course). Naturally frequency estimates Equation 3 would1. taxonomy Figure 2 fragment WordNet version 1.6, showing real quantitative informationcomputed using method described below. \nanny" sense nurse (nursemaid, womancustodian children) primarily British usage. example omits two senses doctorWordNet: theologian Roman Catholic Church, game played children. WordNetuse node labels like doctor1, created labels sake readability.2. Concept used refers Miller et al. (1990) call synset, essentially node taxonomy.experiment reported section used noun taxonomy WordNet version 1.4,approximately 50,000 nodes.3. Plural nouns counted instances singular forms.99fiResnikimproved taking account intended sense noun corpus |example, instance crane bird machine, both. Sense-taggedcorpora generally available, however, frequency estimates done usingweaker generally applicable technique.noted present method associating probabilities conceptstaxonomy based notion single random variable ranging concepts| case, \credit" noun occurrence would distributedconcepts noun, counts normalized across entire taxonomy sum 1.(That approach taken Resnik, 1993a, also see Resnik, 1998b discussion.)assigning taxonomic probabilities purposes measuring semantic similarity, presentmodel associates separate, binomially distributed random variable concept.4is, perspective given concept c, observed noun eitherinstance concept, probabilities p(c) 1 , p(c), respectively. Unlikemodel single multinomial variable ranging entire set concepts,formulation assigns probability 1 top concept taxonomy, leadingdesirable consequence information content zero.3.2 TaskAlthough standard way evaluate computational measures semantic similarity, one reasonable way judge would seem agreement human similarity ratings.assessed using computational similarity measure rate similarityset word pairs, looking well ratings correlate human ratingspairs.experiment Miller Charles (1991) provided appropriate human subject datatask. study, 38 undergraduate subjects given 30 pairs nounschosen cover high, intermediate, low levels similarity (as determined usingprevious study, Rubenstein & Goodenough, 1965), subjects askedrate \similarity meaning" pair scale 0 (no similarity) 4 (perfectsynonymy). average rating pair thus represents good estimate similartwo words are, according human judgments.5order get baseline comparison, replicated Miller Charles's experiment,giving ten subjects 30 noun pairs. subjects computer science graduatestudents postdoctoral researchers University Pennsylvania, instructionsexactly used Miller Charles, main differencereplication subjects completed questionnaire electronic mail (thoughinstructed complete whole task single uninterrupted sitting). Five subjectsreceived list word pairs random order, five received listreverse order. correlation Miller Charles mean ratings meanratings replication .96, quite close .97 correlation Miller Charlesobtained results ratings determined earlier study.4. similar spirit way probabilities used Bayesian network.5. anonymous reviewer points human judgments task may uenced prototypicality, e.g., pair bird/robin would likely yield higher ratings bird/crane. Issues kindbrie touched Section 6, part ignored since prototypicality, liketopical relatedness, captured is-a taxonomies.100fiInformation-Based Semantic Similaritysubject replication, computed well ratings correlatedMiller Charles ratings. average correlation 10 subjectsr = 0:88, standard deviation 0.08.6 value represents upper boundone expect computational attempt perform task.purposes evaluation, three computational similarity measures used.first similarity measurement using information content proposed previous section. second variant edge-counting method, converting distancesimilarity subtracting path length maximum possible path length:wsimedge (w1; w2) = (2 max) , cminlen(c1; c2);c12(5)c1 ranges s(w1), c2 ranges s(w2), max maximum depth taxonomy, len(c1; c2) length shortest path c1 c2 . (Recall s(w)denotes set concepts taxonomy represent senses word w.) sensesw1 w2 separate sub-taxonomies WordNet similarity takenzero. Note correlation used evaluation metric, conversiondistance similarity viewed expository convenience, affectresults: although sign correlation coecient changes positive negative,magnitude turns regardless whether minimum pathlength subtracted (2 max).third point comparison measure simply uses probability concept,rather information content, define semantic similarity conceptsmax [1 , p(c)]simp(c)(c1; c2) =(6)c 2 (c1 ; c2)corresponding measure word similarity:hwsimp(c)(w1; w2) = cmaxsimp(c)(c1; c2) ;;c12(7)c1 ranges s(w1) c2 ranges s(w2) Equation 7. probability-basedsimilarity score included order assess extent similarity judgments mightsensitive frequency per se rather information content. Again, differencemaximizing 1 , p(c) minimizing p(c) turns affect magnitudecorrelation. simply ensures value interpreted similarity value,high values indicating similar words.3.3 ResultsTable 2 summarizes experimental results, giving correlation similarityratings mean ratings reported Miller Charles. Note that, owing nounmissing WordNet 1.4 taxonomy, possible obtain computationalsimilarity ratings 28 30 noun pairs; hence proper point comparisonhuman judgments correlation 30 items (r = :88), rather correlation28 included pairs (r = :90). similarity ratings item given Table 3.6. Inter-subject correlation replication, estimated using leaving-one-out resampling (Weiss & Kulikowski, 1991), r = :90; stdev = 0:07.101fiResnikSimilarity methodCorrelationHuman judgments (replication) r = :9015Information contentr = :7911Probabilityr = :6671Edge-countingr = :6645Table 2: Summary experimental results.Word PaircargemjourneyboycoastasylummagicianmiddayfurnacefoodbirdbirdtoolbrothercraneladjourneymonkfoodcoastforestmonkcoastladchordglassnoonroosterautomobilejewelvoyageladshoremadhousewizardnoonstovefruitcockcraneimplementmonkimplementbrothercaroracleroosterhillgraveyardslaveforestwizardsmilemagicianstringvoyageMiller Charles Replicationwsim wsimedge wsimp(c)meansmeans3.923.9 8.041130 0.99623.843.5 14.928630 1.00003.843.5 6.753729 0.99073.763.5 8.424029 0.99713.703.5 10.807629 0.99943.613.6 15.665629 1.00003.503.5 13.665630 0.99993.423.6 12.392530 0.99983.112.6 1.713523 0.69513.082.1 5.007627 0.96893.052.2 9.313929 0.99842.972.1 9.313927 0.99842.953.4 6.078729 0.98522.822.4 2.968324 0.87221.680.3 2.968324 0.87221.661.2 2.935526 0.86931.160.7 0.00000 0.00001.100.8 2.968324 0.87220.891.1 1.010518 0.50360.870.7 6.234426 0.98670.840.6 0.00000 0.00000.550.7 2.968327 0.87220.420.6 0.00000 0.00000.420.7 2.968326 0.87220.130.1 2.354420 0.80440.110.1 1.010522 0.50360.080.0 0.00000 0.00000.080.0 0.00000 0.0000Table 3: Semantic similarity item.102fiInformation-Based Semantic Similarityn1tobaccotobaccotobaccon2wsim(n1 ,n2) subsumeralcohol7.63drugsugar3.56 substancehorse8.26 narcoticTable 4: Similarity tobacco computed maximizing information content3.4 Discussionexperimental results previous section suggest measuring semantic similarityusing information content provides results better traditional methodsimply counting number intervening is-a links.measure without problems, however. Like simple edge-counting,measure sometimes produces spuriously high similarity measures words basisinappropriate word senses. example, Table 4 shows word similarity several wordstobacco. Tobacco alcohol similar, drugs, tobacco sugarless similar, though entirely dissimilar, since classified substances.problem arises, however, similarity rating tobacco horse: word horseused slang term heroin, result information-based similarity maximized,path length minimized, two words categorized narcotics.contrary intuition.Cases like probably relatively rare. However, example illustratesgeneral concern: measuring similarity words, really relationship amongword senses matters, similarity measure able take account.absence reliable algorithm choosing appropriate word senses,straightforward way information-based setting consider conceptsnouns belong rather taking single maximally informative class.suggests defining measure weighted word similarity follows:wsimff(w1; w2) =Xff(ci)[, log p(ci)];(8)fcig set concepts dominating w1 w2 sense either word,ff weighting function concepts Pi ff(ci) = 1. measure similaritytakes information account previous one: rather relyingsingle concept maximum information content, allows class representing sharedproperties contribute information content according value ff(ci). Intuitively,ff values measure relevance. example, computing wsimff (tobacco,horse),ci would range concepts tobacco horse instances, includingnarcotic, drug, artifact, life form, etc. everyday context one might expect lowvalues ff(narcotic) ff(drug), context of, say, newspaper articledrug dealers, weights concepts might quite high. Although possibleinclude weighted word similarity comparison Section 3, since noun pairsjudged without context, Section 4 provides discussion weighting function ffdesigned particular natural language processing task.103fiResnik4. Using Taxonomic Similarity Resolving Syntactic Ambiguityconsidered direct evaluation information-based semantic similarity measure,turn application measure resolving syntactic ambiguity.4.1 Clues Resolving Coordination AmbiguitySyntactic ambiguity pervasive problem natural language. Church Patil(1982) point out, class \every way ambiguous" syntactic constructions |number analyses number binary trees terminal elements |includes frequent constructions prepositional phrases, coordination, nominalcompounds. last several years, researchers natural language made greatdeal progress using quantitative information text corpora provide neededconstraints. Progress broad-coverage prepositional phrase attachment ambiguityparticularly notable, dominant approach shifted structuralstrategies quantitative analysis lexical relationships (Whittemore, Ferrara, & Brunner,1990; Hindle & Rooth, 1993; Brill & Resnik, 1994; Ratnaparkhi & Roukos, 1994; Li & Abe,1995; Collins & Brooks, 1995; Merlo, Crocker, & Berthouzoz, 1997). Noun compoundsreceived comparatively less attention (Kobayasi, Takunaga, & Tanaka, 1994; Lauer, 1994,1995), problem coordination ambiguity (Agarwal & Boggess, 1992; Kurohashi& Nagao, 1992).section, investigate role semantic similarity resolving coordinationambiguities involving nominal compounds. began noun phrase coordinationsform n1 n2 n3, admit two structural analyses, one n1 n2two noun phrase heads conjoined (1a) one conjoined heads n1n3 (1b).(1) a. (bank warehouse) guardb. (policeman) (park guard)Identifying two head nouns conjoined necessary order arrive correctinterpretation phrase's content. example, analyzing (1b) according structure (1a) could lead machine translation system produce noun phrase describingsomebody guards policemen parks. Analyzing (1a) according structure (1b) could lead information retrieval system miss phrase lookingqueries involving term bank guard.Kurohashi Nagao (1992) point similarity form similarity meaningimportant cues conjoinability. English, similarity form great extentcaptured agreement number (singular vs. plural):(2)a. several business university groupsb. several businesses university groupsSimilarity form candidate conjoined heads thus thought Booleanvariable: number agreement either satisfied candidate heads not.Similarity meaning conjoined heads also appears play important role:(3)a. television radio personality104fiInformation-Based Semantic Similarityb. psychologist sex researcherClearly television radio similar television personality; correspondingly psychologist researcher. similarity meaning captured well semanticsimilarity taxonomy, thus second variable consider evaluating coordination structure semantic similarity measured overlap information contenttwo head nouns.addition, constructions considered here, appropriateness noun-nounmodification relevant:(4)a. mail securities fraudb. corn peanut butterOne reason prefer conjoin mail securities mail fraud salient compoundnominal phrase. hand, corn butter familiar concept; comparechange perceived structure phrase corn peanut crops. order measureappropriateness noun-noun modification, use quantitative measure selectionalfit called selectional association (Resnik, 1996), takes account lexical cooccurrence frequencies semantic class membership WordNet taxonomy. Brie y,selectional association word w WordNet class c givenp(cjw) log p(cjw)A(w; c) = D(p(C jw) k p(p(Cc) ))(9)D(p1 k p2) Kullback-Leibler distance (relative entropy) probabilitydistributions p1 p2. Intuitively, A(w, c) measuring extent class cpredicted word w; example, A(wool, clothing) would higher value than,say, A(wool, person). selectional association A(w1; w2) two words definedmaximum A(w1; c) taken classes c w2 belongs. example,A(wool, glove) would likely equal A(wool, clothing), compared to, say,A(wool, sports equipment) | latter value corresponding sense glovesomething used baseball boxing. (See Li & Abe, 1995, approachselectional relationships modeled using conditional probability.) simple way treatselectional association variable resolving coordination ambiguities prefer analyses include noun-noun modifications strong anities (e.g., bank modifierguard) disprefer weak noun-noun relationships (e.g., corn modifierbutter). Thresholds defining \strong" \weak" parameters algorithm, definedbelow.4.2 Resolving Coordination Ambiguity: First Experimentinvestigated roles sources evidence conducting straightforward disambiguation experiment using naturally occurring linguistic data. Two sets 100 nounphrases form [NP n1 n2 n3] extracted parsed Wall Street Journal(WSJ) corpus, found Penn Treebank (Marcus, Santorini, & Marcinkiewicz, 1993).disambiguated hand, one set used development105fiResnikSource evidence Conjoined ConditionNumber agreement n1 n2 number(n1) = number(n2) number(n1) 6= number(n3)n1 n3 number(n1) = number(n3) number(n1) 6= number(n2)undecided otherwiseSemantic similarity n1 n2 wsim(n1,n2) > wsim(n1,n3)n1 n3 wsim(n1,n3) > wsim(n1,n2)undecided otherwiseNoun-nounn1 n2 A(n1,n3) > A(n3,n1) >modificationn1 n3 A(n1,n3) < A(n3,n1) <undecided otherwiseTable 5: Rules number agreement, semantic similarity, noun-noun modificationresolving syntactic ambiguity noun phrases n1 n2 n3testing.7 set simple transformations applied WSJ data, including mapping proper names token someone, expansion month abbreviations,reduction nouns root forms.Number agreement determined using simple analysis suxes combinationWordNet's lists root nouns irregular plurals.8 Semantic similarity determined using information-based measure Equation (2) | noun class probabilitiesEquation (1) estimated using sample approximately 800,000 noun occurrencesAssociated Press newswire stories.9 purpose determining semantic similarity,nouns WordNet treated instances class hthingi. Appropriatenessnoun-noun modification determined computing selectional association (Equation 9),using co-occurrence frequencies taken sample approximately 15,000 noun-nouncompounds extracted WSJ corpus. (This sample include test data.)selection modifier head selection head modifierconsidered disambiguation algorithm. Table 5 provides details decision rulesource evidence used independently.10addition, investigated several methods combining three sources information. included: (a) simple form \backing off" (specifically, given numberagreement, noun-noun modification, semantic similarity strategies order, usechoice given first strategy isn't undecided); (b) taking vote amongthree strategies choosing majority; (c) classifying using results linear re7. Hand disambiguation necessary Penn Treebank encode NP-internal structure.phrases disambiguated using full sentence occurred, plus previousfollowing sentence, context.8. experiments section used WordNet version 1.2.9. grateful Donald Hindle making data available.10. Thresholds = 2:0 = 0:0 fixed manually based experience development setevaluating test data.106fiInformation-Based Semantic SimilarityStrategyDefaultNumber agreementNoun-noun modificationSemantic similarityBackingVotingNumber agreement + defaultNoun-noun modification + defaultSemantic similarity + defaultBacking + defaultVoting + defaultRegressionID3 TreeCoverage (%) Accuracy (%)100.053.075.066.095.089.0100.0100.0100.0100.0100.0100.0100.066.090.669.371.281.178.782.065.072.081.076.079.080.0Table 6: Syntactic disambiguation items form n1 n2 n3gression; (d) constructing decision tree classifier. latter two methods formssupervised learning; experiment development set used training data.11results shown Table 6. development set contained bias favorconjoining n1 n2; therefore \default" strategy, always choosing bracketing,used baseline comparison. default also used resolving undecided casesorder make comparisons individual strategies 100% coverage. example,\Number agreement + default" shows figures obtained number agreementused make choice default selected choice undecided.surprisingly, individual strategies perform reasonably well instancesclassify, coverage poor; strategy based similarity form highlyaccurate, arrives answer half time. However, heavy priori bias makesdifference | extent even though forms evidencevalue, combination beats number-agreement-plus-default combination.positive side, shows ambiguity resolved reasonably well usingsimple algorithm: viewed terms many errors made, number agreement makespossible cut baseline 34% error rate nearly half 18% incorrect analyses (a44% reduction). negative side, results fail make strong case semanticsimilarity add something useful.taking issue, let us assess contributions individual strategiesresults evidence combined, analyzing behavior unsupervisedevidence combination strategies. combining evidence voting, choice made89 cases. number agreement strategy agreed majority vote 57 cases,43 (75.4%) correct; noun-noun modification strategy agreedmajority 73 cases, 50 (68.5%) correct; semantic similarity strategy11. calling \backing off" related spirit Katz's well known smoothing technique (Katz,1987), \backing off" strategy used quantitative. retain double quotes orderhighlight distinction.107fiResnikagreed majority 58 cases, 43 (74.1%) correct. \backing off"form evidence combination, number agreement makes choice 53 cases correct48 (90.6%); then, remaining undecided, noun-noun modification makes choice35 cases correct 24 (68.6%); then, still undecided, semantic similaritymakes choice 7 cases 5 correct (71.4%); remaining 5 casesundecided.analysis above-baseline performance semantic-similarity-plus-defaultstrategy show semantic similarity contain information correct answer:agrees majority vote substantial portion time, selects correctanswers often one would expect default cases receives\backing off." However, default correct two thirds time,number agreement strategy correct nine ten times cases decide,potential contribution semantic similarity remains suggestive rather conclusive.second experiment, therefore, investigated dicult formulation problemorder obtain better assessment.4.3 Resolving Coordination Ambiguity: Second Experimentsecond experiment using data sources, investigated complex setcoordinations, looking noun phrases form n0 n1 n2 n3. syntacticanalyses phrases characterized top-level binary choice dataprevious experiment, either conjoining heads n1 n2 (5) conjoining n1n3 (6).12(5) a. freshman ((business marketing) major)b. (food (handling storage)) proceduresc. ((mail fraud) bribery) charges(6)a. Clorets (gum (breath mints))b. (baby food) (puppy chow)experiment, one set 89 items extracted Penn Treebank WSJ datadevelopment, another set 89 items set aside testing. developmentset showed significantly less bias data previous experiment, 53.9%items conjoining n1 n2.disambiguation strategies experiment refined versionused previous experiment, illustrated Table 7. Number agreement usedbefore. However, rather employing semantic similarity noun-noun modificationindependent strategies | something clearly warranted given lackluster performance modification strategy | two combined measure weightedsemantic similarity defined Equation (8). Selectional association used basisff. particular, ff1;2(c) greater A(n0,c) A(n3,c), capturing factn1 n2 conjoined, combined phrase potentially stands head-modifierrelationship n0 modifier-head relationship n3 . Correspondingly, ff1;3(c)greater A(n0,c) A(n2,c), capturing fact coordination n112. full 5-way classification problem structures (5) (6) investigated.108fiInformation-Based Semantic SimilaritySource evidence Conjoined ConditionNumber agreement n1 n2 number(n1) = number(n2) number(n1) 6= number(n3)n1 n3 number(n1) = number(n3) number(n1) 6= number(n2)undecided otherwiseWeighted semantic n1 n2 wsimff1 2 (n1,n2) > wsimff1 3 (n1,n3)similarityn1 n3 wsimff1 3 (n1,n3) > wsimff1 2 (n1,n2)undecided otherwise;;;;Table 7: Rules number agreement weighted semantic similarity resolving syntactic ambiguity noun phrases n0 n1 n2 n3StrategyDefaultNumber agreementWeighted semantic similarityBackingCoverage (%) Accuracy (%)100.040.469.785.444.980.677.481.6Table 8: Syntactic disambiguation items form n0 n1 n2 n3n3 takes place context n2 modifying n3 n1 (or coordinated phrasecontaining it) modified n0.example, consider instance ambiguous phrase:(7)telecommunications products services units.happens high-information-content connection exists productsense \a quantity obtained multiplication" unit sense \a single undividedwhole." result, although neither senses relevant example, nouns n1n3 would assigned high value (unweighted) semantic similarity chosenincorrectly conjoined heads example. However, unweighted similarity computation misses important piece context: syntactic analysis conjoining productunit (cf. examples 6a 6b), word telecommunications necessarily modifierconcept identified products. selectional association telecommunications products \multiplication" sense weak nonexistent. Weightingselection association, therefore, provides way reduce impact spurious sensessimilarity computation.order combine sources evidence, used \backing off" (from number agreementweighted semantic similarity) combine two individual strategies. baseline,results evaluated simple default strategy always choosing groupcommon development set. results shown Table 8.case, default strategy defined using development set misleading,yielding worse chance accuracy. reason, strategy-plus-default figuresreported. However, even default choices made using bias found test set,109fiResnikaccuracy would 55.1%. contrast equivocal results first experiment,experiment demonstrates clear contribution semantic similarity: employingsemantic similarity cases accurate number-agreement strategycannot apply, possible obtain equivalent even somewhat better accuracynumber agreement alone time doubling coverage.Comparison previous algorithms unfortunately possible, since researcherscoordination ambiguity established common data set evaluation evencommon characterization problem, contrast now-standard (v, n1, prep, n2)contexts used work propositional phrase attachment. crucial caveat,nonetheless interesting note results obtained broadly consistentKurohashi Nagao (1992), report accuracy results range 80-83%100% coverage analyzing broad range conjunctive structures Japanese usingcombination string matching, syntactic similarity, thesaurus-based similarity,Agarwal Boggess (1992), use syntactic types structure, along partlydomain-dependent semantic labels, obtain accuracies similar range identifyingconjuncts English.5. Using Taxonomic Similarity Word Sense Selectionsection considers application semantic similarity measure resolving anotherform ambiguity: selecting appropriate sense noun appears contextnouns related meaning.5.1 Associating Word Senses Noun GroupingsKnowledge groups related words plays role many natural language applications.examples, query expansion using related words well studied technique informationretrieval (e.g., Harman, 1992; Grefenstette, 1992), clusters similar words playrole smoothing stochastic language models speech recognition (Brown, Della Pietra,deSouza, Lai, & Mercer, 1992), classes verbs share semantic structure formbasis approach interlingual machine translation (Dorr, 1997), clusteringsrelated words used characterizing subgroupings retrieved documents largescale Web searches (e.g., Digital Equipment Corporation, 1998). wide bodyresearch use distributional methods measuring word similarity orderobtain groups related words (e.g., Bensch & Savitch, 1992; Brill, 1991; Brown et al., 1992;Grefenstette, 1992, 1994; McKeown & Hatzivassiloglou, 1993; Pereira, Tishby, & Lee, 1993;Schutze, 1993), thesauri WordNet another source word relationships (e.g.,Voorhees, 1994).Distributional techniques sometimes good job identifying groups relatedwords (see Resnik, 1998b, overview critical discussion), tasksrelevant relationships among words, among word senses. example, Brownet al. (1992) illustrate notion distributionally derived, \semantically sticky" clusterusing automatically derived word group containing attorney, counsel, trial, court,judge. Although semantic coherence cluster \pops out" human reader,naive computational system defense word sense ambiguity: using cluster110fiInformation-Based Semantic Similarityquery expansion could result retrieving documents involving advice (one sensecounsel) royalty (as one sense court).13Resnik (1998a) introduces algorithm uses taxonomically-defined semantic similarity order derive grouping relationships among word senses grouping relationships among words. Formally, problem stated follows. Consider set wordsW = fw1; : : :; wng, word wi associatedset Si = fsi;1 ; : : :; si;mg posSsible senses. Assume exists set W 0 Si , representing set wordsenses ideal human judge would conclude belong group senses corresponding word grouping W . (It follows W 0 must contain least one representativeSi .) goal define membership function ' takes si;j , wi ,W arguments computes value [0; 1], representing confidenceone state sense si;j belongs sense grouping W 0 . Note that, principle, nothingprecludes possibility multiple senses word included W 0.example, consider groupattorney, counsel, trial, court, judge.Restricting attention noun senses WordNet, every word attorney polysemous.Treating word group W , good algorithm computing ' assign value1 unique sense attorney, assign high value sense counsellawyer pleads cases court.Similarly, assign high values senses triallegal proceedings consisting judicial examination issues competent tribunaldetermination person's innocence guilt due process law.also assign high values senses courtassembly conduct judicial businessroom law court sits.assign high value sense judgepublic ocial authorized decide questions brought court justice.assign low values ' various word senses words clusterassociated group lesser extent all. would include sensecounseldirection advice decision course action;similarly, low value ' assigned senses court13. See Krovetz Kroft, 1992 Voorhees, 1993 experimentation discussion effectsword sense ambiguity information retrieval.111fiResnikAlgorithm (Resnik, 1998a). Given W = fw1 ; : : : ; w g, set nouns:nj = 1 n, < jfv = wsim(w , w )c = informative subsumer w wi;jji;jjk = 1 num senses(w )c ancestor senseincrement support[i, k] vi;ji;ki;jk = 1 num senses(w )c ancestor senseincrement support[j, k'] v0jj;k 0i;ji;jincrement normalization[i] vincrement normalization[j] vi;jgi;j= 1 nk = 1 num senses(w )f(normalization[i] > 0.0)' = support[i, k] / normalization[i]else' = 1 / num senses(w )i;kgi;kFigure 3: Disambiguation algorithm noun groupingsyard wholly partly surrounded walls buildings.disambiguation algorithm noun groups given Figure 3. Intuitively, twopolysemous words similar, informative subsumer provides informationsense word relevant one. observation similar spiritapproaches word sense disambiguation based maximizing relatedness meaning (e.g.,Lesk, 1986; Sussna, 1993). key idea behind algorithm consider nounsword group pairwise. pair algorithm goes possible combinationswords' senses, assigns \credit" senses basis shared information content,measured using information content informative subsumer.14example, WordNet lists doctor meaning either medical doctor someoneholding Ph.D., lists nurse meaning either health professional nanny,two words considered together, medical sense word obvioushuman reader. effect finds parallel operation algorithm. Giventaxonomy like Figure 2, consider case set W words contains w1 =doctor, w2 = nurse, w3 = actor. first pairwise comparison, doctor nurse,14. Figure 3, square bracket notation highlights fact support matrix normalizationarray. Conceptually v c (triangular) matrices also; however, use subscripts rathersquare brackets implementation time need implement sincevalues v c used discarded pass double loop.i;ji;j112fiInformation-Based Semantic Similarityinformative subsumer c1;2 = health professional, informationcontent v1;2 = 8.844. Therefore support doctor1 nurse1 incremented8.844. Neither doctor2 nurse2 receives increment support basedcomparison, since neither health professional ancestor. second pairwisecomparison, informative subsumer doctor actor c1;3 = person,information content v1;3 = 2.005, increment amountsupport doctor1, doctor2, actor1, person ancestor.Similarly, third pairwise comparison, informative subsumer nurseactor also person, nurse1, nurse2, actor1 support incremented2.005. end, therefore, doctor1 received support 8:884 + 2:005possible 8:884 + 2:005 pairwise comparisons participated,word sense ' = 1. contrast, doctor2 received support amount 2.005possible 8:884 + 2:005 comparisons involved, value '2:005 = 0:185.doctor2 8:884+2:005Resnik (1998a) illustrates algorithm Figure 3 using word groupings varietysources, including several sources distributional clustering cited above,evaluates algorithm rigorously task associating WordNet sensesnouns Roget's thesaurus, based thesaurus category membership. average,algorithm achieved approximately 89% performance human annotators performingtask.15 remainder section describe new applicationalgorithm, evaluate performance.5.2 Linking WordNet using Bilingual DictionaryMultilingual resources natural language processing dicult obtain, althoughpromising efforts underway projects like EuroWordNet (Vossen, 1998).many languages, however, large-scale resources unlikely availablenear future, individual research efforts continue build scratchadapt existing resources bilingual dictionaries (e.g., Klavans & Tzoukermann,1995). section describe application algorithm Figure 3 Englishdefinitions CETA Chinese-English dictionary (CETA, 1982). ultimate task,undertaken context Chinese-English machine translation project,associate Chinese vocabulary items nodes WordNet, much wayvocabulary Spanish, Dutch, Italian associated interlingual taxonomy nodesderived American WordNet, EuroWordNet project; task also similarattempts relate dictionaries thesauri monolingually (e.g., see Section 5.3Ji, Gong, & Huang, 1998). present study investigates extent semanticsimilarity might useful partially automating process.15. task performed independently two human judges. Treating Judge 1 benchmarkaccuracies achieved Judge 2, algorithm, random selection respectively 65.7%, 58.6%,34.8%; treating Judge 2 benchmark accuracies achieved Judge 1, algorithm,random selection respectively 68.6%, 60.5%, 33.3%. relatively low accuracies humanjudges demonstrate, disambiguation using WordNet's fine-grained senses quite bit dicultdisambiguation level homographs (Hearst, 1991; Cowie, Guthrie, & Guthrie, 1992). ResnikYarowsky (1997, 1999) discuss implications WordNet's fine-grainedness evaluation wordsense disambiguation, consider alternative evaluation methods.113fiResnikexample, consider following dictionary entries:(a): 1. hliti brother-in-law (husband's elder brother) 2. hregi father 3.hregi uncle (father's elder brother) 4. uncle (form address olderman): actress, player female roles.(b)order associate Chinese terms WordNet noun taxonomy,important avoid associations inappropriate senses | example, word, clearly associated father WordNet senses Churchentry (a),Father, priest, God-the-Father, founding father.16Although one traditional approach using dictionary entries compute wordoverlap respect dictionary definitions (e.g., Lesk, 1986), English glossesCETA dictionary generally short take advantage word overlap fashion.However, many definitions useful property: possess multiple subdefinitions similar meaning, cases illustrated above. Although onecannot always assume so, e.g.,(c): 1. case (i.e., upper case lower case) 2. dial (of watch, etc.),inspection dictionary confirms multiple definitions present tendtoward polysemy homonymy.Based observation, conducted experiment assess extentword sense disambiguation algorithm Figure 3 used identify relevant noun sensesWordNet Chinese words CETA dictionary, using English definitionssource similar nouns disambiguate. Nouns heading definitional noun phrasesextracted automatically via simple heuristic methods, randomly-selected sample100 dictionary entries containing multiple definitions used test set. example,noun groups associated definitions would(a') uncle, brother-in-law, father(b') actress, player.WordNet's noun database used automatically identify compound nominalspossible. So, example, word defined \record player" would compoundrecord player rather player head noun record player compoundnoun known WordNet.17noted attempt made exclude dictionary entries like (c)creating test set. Since general way automatically identify alternativedefinitions distinguished synonymy distinguished homonymy, entriesmust faced disambiguation algorithm task.Two independent judges recruited assistance annotating test set, onenative Chinese speaker, second Chinese language expert United Statesgovernment. judges independently annotated 100 test items. item,16. Annotations within dictionary entriesignored algorithm described section.17. WordNet version 1.5 used experiment.<lit>114(literary),<reg>(regional), likefiInformation-Based Semantic SimilarityWordNet definition, see 6 boxes: 1, 2, 3, 4, 5, is-a. definition:think Chinese word meaning, select number correspondingconfidence choice, 1 lowest confidence 5 highest confidence.Chinese word cannot meaning, specific meaning, select is-a.example, Chinese word means \truck" WordNet definition \automotive vehicle:self-propelled wheeled vehicle", would select option. (That is, makes sense sayChinese word describes concept KIND automotive vehicle.) pick 1,2, 3, 4, 5 confidence decision, 1 lowest confidence 5 highestconfidence.neither cases apply WordNet definition, don't check anythingdefinition.Figure 4: Instructions human judges selecting senses associated Chinese wordsjudge given Chinese word, full CETA dictionary definition (as examplesa{c), list WordNet sense descriptions associated sense headnoun associated noun group. example, list corresponding followingdictionary definition(d): urgent message, urgent dispatchwould contain following WordNet sense descriptions, generated via head nounsmessage dispatch:message, content, subject matter, substance: communicationsomethingdispatch, expedition, expeditiousness, fastness: subconcept celerity, quickness, rapiditydispatch, despatch, communique: ocial report (usually sent haste)message: communication (usually brief) written spokensignaled; \he sent three-word message"dispatch, despatch, shipment: act sending somethingdispatch, despatch: murder execution someoneitem, judge first asked whether knew Chinese word meaning;response negative, instructed proceed next item. itemsknown words, judges instructed Figure 4.Although use is-a selection used analysis results,important include provided judges way indicateChinese word could best classified WordNet noun taxonomy, withoutassert translational equivalence Chinese concept close WordNet (English)concept. So, example, judge could classify word(the spring festival, lunarnew year, Chinese new year) belonging WordNet sense glossedfestival: day period time set aside feasting celebration,115fiResniksensible choice given \Chinese New Year" appear WordNetconcept. Annotating is-a relationship set also important algorithm evaluated working groups head nouns, thereby potentially losinginformation pointing specific concept reading. example, definition: steel tube, steel pipe(e)would given algorithm group containing head nouns tube pipe.test set annotated, evaluation done according two paradigms:selection filtering. paradigms assume entry test set,annotator correctly specified WordNet senses considered correct,incorrect. algorithm tested set must identify, listedsense, whether sense included item whether excluded.example, WordNet sense corresponding \the murder execution someone"would identified annotator incorrect (d), algorithm marking\included" penalized.selection paradigm, goal identify WordNet senses include.therefore define precision paradigmcorrectly included sensesPselection = number(10)number included sensesrecallcorrectly included senses :Rselection = number(11)number correct sensescorrespond directly use precision recall information retrieval. Precision begins set senses included method, computes proportioncorrect. Recall begins set senses included,computes proportion method actually managed choose.Since number potential WordNet senses item quite large, equallyvalid alternative selection paradigm call filtering paradigm, accordinggoal identify WordNet senses exclude. One easily imaginerelevant paradigm | example, semi-automated setting onewishes reduce burden user selecting among alternatives. filtering paradigmone define filtering precisioncorrectly excluded sensesPfiltering = numbernumber excluded senses(12)correctly excluded senses :Rfiltering = numbernumber senses labeled incorrect(13)filtering recallfiltering paradigm, precision begins set senses method filteredcomputes proportion correctly filtered out. recall filteringbegins set senses excluded (i.e. incorrect ones)computes proportion method actually managed exclude.116fiInformation-Based Semantic SimilaritySense SelectionSense FilteringPrecision (%) Recall (%) Precision (%) Recall (%)Random29.531.288.087.1Algorithm36.969.993.879.3Judge 254.855.691.991.7Table 9: Evaluation using Judge 1 reference standard, considering items selectedconfidence 3 above.Judge 2AlgorithmRandomInclude Exclude Include Exclude Include ExcludeJudge 1 Include403258252657Exclude333639938061418Table 10: Agreement disagreement Judge 1Table 9 shows precision/recall figures using judgments Judge 1, nativeChinese speaker, reference standard, considering known items selected confidence 3 above.18 algorithm recorded 100 items known, confidencevalues scaled linearly continuous values range [0,1] discrete values 15. table shows algorithm's results choice thresholded confidence 3,Figure 5 shows recall precision vary confidence threshold changes.lower bound comparison, algorithm implemented considered wordsense item, selecting sense probabilistically (with complete confidence)way make average number senses per item close possible averagenumber senses per item reference standard (1.3 senses). Figures randombaseline average 10 runs. Table 10 illustrates choices underlyingfigures; example, 26 senses random procedure chose includealso included Judge 1.fact Judge 2 low precision recall selection indicatesmatching choices independent judge indeed dicult task. unsurprising, given previous experience problem selecting among WordNet's fine-grainedsenses (Resnik, 1998a; Resnik & Yarowsky, 1997). results clearly show algorithm better baseline, also indicate overgenerating senses,hurts selection precision. terms filtering, algorithm chooses filtersense tends reliably (filtering precision). However, propensity toward overgeneration ected below-baseline performance filtering recall; is, algorithmchoosing allow senses filtering out.18. Judge 1, native speaker Chinese, identified 65 words known him; Judge 2 identified69. on-line dictionary constructed large variety lexical resources, includes greatmany uncommon words, archaic usages, regionalisms, like.117fiResnikFiltering: AlgorithmHumanRandomSelection: AlgorithmHumanRandomPrecision10.80.60.40.20.20.40.60.8Recall1Figure 5: Precision/recall curves using Judge 1 reference standard, varying confidence thresholdpattern results suggests best use algorithm present levelperformance would filter lexical acquisition process humanloop, dividing candidate WordNet senses dictionary entries according higherlower priority. Chinese-English dictionary entries serve appropriate inputalgorithm (of approximately 37000 CETA dictionary), WordNetsense selected algorithm confidence least equal 3demoted lower priority group presentation alternatives, since algorithm'schoice exclude sense correct approximately 93% time. sensesselected algorithm necessarily included | human judge stillneeded make selection, since selection precision low | algorithm tendserr side caution, correct senses found higher priority group70% time.5.3 Linking WordNet English Dictionary/Thesaurusresults WordNet sense selection using bilingual dictionary demonstratealgorithm Figure 3 good job assigning low scores WordNet sensesfiltered out, even probably trusted make categorical decisions. Oneapplication proposed suitable, therefore, helping identify sensesfiltered within semi-automated process lexical acquisition. describe closelyrelated, real-world application algorithm deployed: adding pointersWordNet on-line dictionary/thesaurus Web.context application Wordsmyth English Dictionary-Thesaurus (WEDT,http://www.wordsmyth.net/), on-line educational dictionary aliated ARTFLtext database project (http://humanities.uchicago.edu/ARTFL/; Morrissey, 1993).designed useful educational contexts, and, part design,integrates thesaurus within structure dictionary. illustrated Figure 6,118fiInformation-Based Semantic SimilaritybarSYL:PRO:POS:DEF:EXA:EXA:EXA:SYN:SIM:DEF:SYN:SIM:...bar1barnoun1. length solid material, usu. rectangular cylindrical:bar soap;candy bar;iron bar.rod (1), stick1 (1,2,3)pole1 , shaft, stake1 , ingot, block, rail1 , railing,crowbar, jimmy, lever2. anything acts restraint hindrance.block (10), hindrance (1), obstruction (1), impediment (1),obstacle, barrier (1,3), stop (5)barricade, blockade, deterrent, hurdle, curb, stumblingblock, snag, jam1 , shoal1 , reef1 , sandbarFigure 6: Example Wordsmyth English Dictionary-Thesaurus (WEDT)WEDT contains traditional dictionary information, part speech, pronunciation,definitional information, many cases also includes pointers synonyms (SYN)similar words (SIM). Within on-line dictionary, thesaurus items hyperlinks| example, stake1 link first WEDT entry stake | parentheticalnumbers refer specific definitions within entry.thesaurus-like grouping similar words provides opportunity exploitalgorithm disambiguating noun groupings automatically linking WEDT entriesWordNet. value linking two resources comes compatability,properties thesaurus dictionary, well complementarity: beyond alternative source definitional information lists synonyms,WordNet provides ordering word senses frequency, estimates word familiarity, partof relationships, course overall taxonomic organization illustrated Figures 12. Figure 7 shows taxonomic information presented using WordNet Webserver (http://www.cogsci.princeton.edu/cgi-bin/webwn/).collaboration WEDT ARTFL, taken noun entriesWEDT dictionary and, grouping similar words, added set experimentalhyperlinks WordNet entries WordNet Web server. Figure 8 shows experimental WordNet links (XWN) look WEDT user. Links WordNet senses,pole1, appear together confidence level assigned sense disambiguation algorithm; senses confidence less threshold presented.19 XWNhyperlink selected user, WordNet taxonomic information selected senseappears parallel browser window, Figure 7.window, user entry point capabilities WordNetweb server. example, one might choose look WordNet senses pole19. current threshold, 0.1, chosen manually. may sub-optimal found workswell practice.119fiResnikSense 1pole(a long (usually round) rod wood metal plastic)=> rod(a long thin implement made metal wood)=> implement(a piece equipment tool used effect end)=> instrumentality, instrumentation(an artifact (or system artifacts)instrumental accomplishing end)=> artifact, artefact(a man-made object)=> object, physical object(a physical (tangible visible) entity; ``itfull rackets, balls objects'')=> entity, something(anything existence (living nonliving))Figure 7: WordNet entry (hypernyms) pole1barSYL:PRO:POS:DEF:EXA:EXA:EXA:SYN:SIM:XWN:DEF:SYN:SIM:XWN:...bar1barnoun1. length solid material, usu. rectangular cylindrical:bar soap;candy bar;iron bar.rod (1), stick1 (1,2,3)pole1 , shaft, stake1 , ingot, block, rail1 , railing,crowbar, jimmy, leverpole1 (0.82) ingot1 (1.00) block1 (0.16) rail1 (0.39)railing1 (1.00) crowbar1 (1.00)jimmy1 (1.00) lever1 (0.67) lever2(0.23) lever3(0.15)2. anything acts restraint hindrance.block (10), hindrance (1), obstruction (1), impediment (1),obstacle, barrier (1,3), stop (5)barricade, blockade, deterrent, hurdle, curb, stumblingblock, snag, jam1 , shoal1 , reef1 , sandbarbarricade1 (1.00) barricade2(1.00) blockade1 (0.25)blockade2 (0.75) deterrent1 (1.00) hurdle1 (0.50)hurdle2 (0.43) curb1 (0.56) curb2 (0.56)curb3 (0.29) curb4 (0.44) stumbling block1 (1.00)snag1 (1.00) jam1 (0.27) shoal1 (0.23) shoal2(0.91)reef1 (1.00) sandbar1 (1.00)Figure 8: Example WEDT experimental WordNet links120fiInformation-Based Semantic Similarity1. pole { (a long (usually round) rod wood metal plastic)2. Pole { (a native inhabitant Poland)3. pole { (one two divergent mutually exclusive opinions; \they opposite poles" \theypoles apart")4. perch, rod, pole { ((British) linear measure 16.5 feet)5. perch, rod, pole { (a square rod land)6. pole, celestial pole { (one two points intersection Earth's axis celestial sphere)7. pole { (one two antipodal points Earth's axis rotation intersects Earth's surface)8. terminal, pole { (a point electrical device (such battery) electric current entersleaves)9. pole { (a long fiberglass implement used pole vaulting)10. pole, magnetic pole { (one two ends magnet magnetism seems concentrated)Figure 9: List WordNet senses polenoun, displayed Figure 9. Notice user WEDT simply gone directlyWordNet server look pole, full list 10 senses would appearedindication potentially related WEDT dictionary entryconsideration. contrast, WEDT hyperlinks, introduced via sense selectionalgorithm, filter majority irrelevant senses provide user measureconfidence selecting among remain.Although formal evaluation WEDT/WordNet connection attempted,results bilingual dictionary experiment suggest application wordsense disambiguation | filtering least relevant senses, leaving userloop | task sense disambiguation algorithm well suited.supported user feedback XWN feature WEDT, favorable(Robert Parks, personal communication). site growing popularity,current estimate 1000-1500 hits per day.6. Related Workextensive literature measuring similarity general, word similarityparticular; classic paper see Tversky (1977). Recent work information retrievalcomputational linguistics emphasized distributional approach, wordsrepresented vectors space features similarity measures definedterms vectors; see Resnik (1998b) discussion, Lee (1997) good recentexample. Common traditional distributional approaches idea wordconcept representations include explicit features, whether features specifiedknowledge-based fashion (e.g., dog might features like mammal, loyal) definedterms distributional context (e.g., dog might features like \observed within 5words howl). representational assumption contrasts assumptions embodiedtaxonomic representation, often is-a relation stands nondecomposed concepts. two inconsistent, course, since concepts taxonomy121fiResniksometimes decomposed explicit features, is-a relation, usuallyinterpreted, implies inheritance features whether explicit implicit.respect, traditional approach counting edges viewed particularly simpleapproximation similarity measure based counting feature differences,assumption edge exists indicate difference least one feature.Information-theoretic concepts techniques have, recent years, emergedspeech recognition community find wide application natural language processing; e.g.,see Church Mercer (1993). information event fundamental notionstochastic language modeling speech recognition, contribution correctword prediction based conditional probability, p(wordjcontext), measuredinformation conveyed prediction, , log p(wordjcontext). forms basisstandard measures language model performance, cross entropy. Frequencyshared unshared features also long factor computing similarity vector representations. inverse document frequency (idf) term weighting informationretrieval makes use logarithmic scaling, serves identify terms discriminate well among different documents, concept similar spirit ideaterms low information content (Salton, 1989).Although counting edges is-a taxonomies seems something many peopletried, seem published descriptions attempts directly evaluateeffectiveness method. number researchers attempted make useconceptual distance information retrieval. example, Rada et al. (1989, 1989) Leeet al. (1993) report experiments using conceptual distance, implemented using edgecounting metric, basis ranking documents similarity query. Sussna(1993) uses semantic relatedness measured WordNet word sense disambiguation,defining measure distance weights different types links also explicitly takesdepth taxonomy account.Following original proposal measure semantic similarity taxonomy usinginformation content (Resnik, 1993b, 1993a), number related proposals explored. Leacock Chodorow (1994) define measure resembling information content,using normalized path length two concepts compared ratherprobability subsuming concept. Specifically, define2minlen(c1 ; c2) 3c;c(14)wsimndist (w1; w2) = , log 4 1 (22 max) 5 :(The notation Equation (5).) addition definition,also include several special cases, notably avoid infinite similarity c1c2 exact synonyms thus path length 0. Leacock Chodorowexperimented measure information content measure describedcontext word sense disambiguation, found yield roughly similar results.Implementing method testing task reported Section 3, foundactually outperformed information-based measure slightly data set; however,follow-up experiment using different larger set noun pairs (100 items),information-based measure performed significantly better (Table 11).Analyzing differences two studies illuminating. follow-up experiment, used netnews archives gather highly frequent nouns within related topic areas122fiInformation-Based Semantic SimilaritySimilarity methodCorrelationInformation contentr = :6894Leacock Chodorow r = :4320Edge-countingr = :4101Table 11: Summary experimental results follow-up study.(to ensure similar noun pairs occurred) selected noun pairings random (inorder avoid biasing follow-up study favor either algorithm). is, therefore,predominance low-similarity noun pairs test data. Looking distributionratings noun pairs, given two measures, evident LeacockChodorow measure overestimating semantic similarity many predominantlynon-similar pairs. stands reason since measure identical whenever edgedistance identical, regardless whether pair high low taxonomy (e.g.,distance plant animal distance white oak redoak). contrast, information-based measure sensitive difference, betteravoiding spuriously high similarity values non-similar pairs. related note,edge-counting measure used follow-up study variant computes path lengthvirtual top node, rather asserting zero similarity words pathconnecting existing WordNet taxonomy, done previously. Using dataset follow-up study, information-based measure, r = :6894, significantlybetter either edge-counting variants (r = :4101 r = :2777); going backoriginal Miller Charles data, virtual-top-node variant significantly betterassert-zero edge distance measure, correlation r = :7786 approachingmeasure based information content. comparison follow-upstudy original Miller Charles data illustrates quite clearly utilitysimilarity measure depend upon distribution items given task.Lin (1997, 1998) recently proposed alternative information-theoretic similaritymeasure, derived set basic assumptions similarity style reminiscentway entropy/information formal definition derivable setbasic properties (Khinchin, 1957). Formally, Lin defines similarity taxonomy as:log p( Ci)simLin(c1; c2) = log2 p(c1) + log p(c2)(15)Ci \maximally specific superclasses" ofT c1 c2 . Althoughpossibility multiple inheritance makes intersection Ci necessary principle, multiple inheritance fact rare WordNet practice one computes Equation (15)separately common ancestor Ci , using p(Ci) numerator, takesmaximum (Dekang Lin, p.c.). multiplicative constant 2, therefore,Lin's method determining similarity taxonomy essentially information-basedsimilarity measure Equation 1, normalized combined information contenttwo concepts assuming independence. Put another way, Lin's measure taking123fiResnikSimilarity method CorrelationInformation content r = :7947simWu&Palmerr = :8027simLinr = :8339Table 12: Summary Lin's results comparing alternative similarity measuresaccount commonalities differences items compared,expressing information-theoretic terms.Lin's measure theoretically well motivated elegantly derived. Moreover, Lin pointsmeasure definition yield value simLin(x; x) regardlessidentity x | unlike information content, criticized groundsvalue self-similarity depends specific concept x is, two nonidentical items x rated similar third item z(Richardson et al., 1994). cognitive perspective, however, similarity comparisonsinvolving self-similarity (\Robins similar robins"), well subclass relationships(\Robins similar birds"), criticized psychologists anomalous (Medin, Goldstone, & Gentner, 1993). Moreover, experimental evidence humanjudgments suggests identical objects judged equally similar, consistentinformation-content measure proposed contrary Lin's measure. example, objects identical complex, twins, seem similarobjects identical simple, two instances simple geometric shape (Goldstone, 1999; Tversky, 1977). would appear, therefore, insofarfidelity human judgments relevant, experimentation needed evaluatecompeting predictions alternative similarity measures.Wu Palmer (1994) propose similarity measure based edge distances,related Lin's measure way takes account specific node dominatingc1 c2, characterizing commonalities, normalizing way accountsdifferences. Revising Wu Palmer's notation slightly, measure is:c3)(16)simWu&Palmer(c1; c2) = d(2c ) +d(d(c2)1c3 maximally specific superclass c1 c2 , d(c3) depth, i.e. distanceroot taxonomy, d(c1) d(c2) depths c1 c2 pathc3.Lin (1998) repeats experiment Section 3 information content measure,simLin, simWu&Palmer, reporting results appear Table 12. Lin uses sensetagged corpus estimate frequencies, smoothed probabilities rather simple relative frequency. results show somewhat higher correlation simLinmeasures. experimentation needed order assess alternative measures,particularly respect competing predictions variability performanceacross data sets. seems clear, however, measures perform bettertraditional edge-counting measure.124fiInformation-Based Semantic Similarity7. Conclusionsarticle presented measure semantic similarity is-a taxonomy, basednotion information content. Experimental evaluation performed using large,independently constructed corpus, independently constructed taxonomy, previouslyexisting new human subject data, results suggest measure performsencouragingly well significantly better traditional edge-counting approach. Semantic similarity, measured using information content, shown usefulresolving cases two pervasive kinds linguistic ambiguity. resolving coordinationambiguity, measure employed capture intuition similarity meaningone indicator two words conjoined; suggestive results first experimentbolstered unequivocal results second study, demonstrating significant improvements disambiguation strategy based syntactic agreement. resolving wordsense ambiguity, semantic similarity measure used assign confidence valuesword senses nouns within thesaurus-like groupings. formal evaluation provided evidence technique produce useful results better suited semi-automatedsense filtering categorical sense selection. Application technique dictionary/thesaurus World Wide Web provides demonstration method actionreal-world setting.AcknowledgementsSections 1-3 article comprise revised extended version Resnik (1995).Section 4 describes previously presented algorithms data (Resnik, 1993b, 1993a), extended discussion analysis. Section 5 summarizes algorithm describedResnik (1998a), extends previous results presenting new applicationsalgorithm, Section 5.2 containing formal evaluation new setting Section 5.3giving real-world illustration approach put practice. Section 6adds substantial discussion related work authors taken place sinceinformation-based similarity measure originally proposed.Parts research done University Pennsylvania partialsupport IBM Graduate Fellowship grants ARO DAAL 03-89-C-0031, DARPAN00014-90-J-1863, NSF IRI 90-16592, Ben Franklin 91S.3078C-1; parts researchalso done Sun Microsystems Laboratories Chelmsford, Massachusetts; partswork supported University Maryland Department Defensecontract MDA90496C1250, DARPA/ITO Contract N66001-97-C-8540, Army ResearchLaboratory contract DAAL03-91-C-0034 Battelle, research grant SunMicrosystems Laboratories. author gratefully acknowledges comments threeanonymous JAIR reviewers helpful discussions John Kovarik, Claudia Leacock,Dekang Lin, Johanna Moore, Mari Broman Olsen, Jin Tong, well commentscriticism received various presentations work.ReferencesAgarwal, R., & Boggess, L. (1992). simple useful approach conjunct identifica125fiResniktion. Proceedings 30th Annual Meeting Association ComputationalLinguistics, pp. 15{21. Association Computational Linguistics.Bensch, P. A., & Savitch, W. J. (1992). occurrence-based model word categorization.Presented 3rd Meeting Mathematics Language (MOL3).Brill, E. (1991). Discovering lexical features language. Proceedings 29thAnnual Meeting Association Computational Linguistics, Berkeley, CA.Brill, E., & Resnik, P. (1994). rule-based approach prepositional phrase attachment disambiguation. Proceedings 15th International Conference ComputationalLinguistics (COLING-94).Brown, P. F., Della Pietra, V. J., deSouza, P. V., Lai, J. C., & Mercer, R. L. (1992).Class-based n-gram models natural language. Computational Linguistics, 18 (4),467{480.CETA (1982). Chinese Dictionaries: Extensive Bibliography Dictionaries ChineseLanguages. Chinese-English Translation Assistance Group, GreenwoodPublishing.Church, K. W., & Mercer, R. (1993). Introduction special issue computationallinguistics using large corpora. Computational Linguistics, 19 (1), 1{24.Church, K. W., & Patil, R. (1982). Coping syntactic ambiguity putblock box table. American Journal Computational Linguistics, 8 (3-4),139{149.Collins, A., & Loftus, E. (1975). spreading activation theory semantic processing.Psychological Review, 82, 407{428.Collins, M., & Brooks, J. (1995). Prepositional phrase attachment backed-offmodel. Third Workshop Large Corpora. Association ComputationalLinguistics. cmp-lg/9506021.Cowie, J., Guthrie, J., & Guthrie, L. (1992). Lexical disambiguation using simulated annealing. Proceedings 14th International Conference Computational Linguistics(COLING-92), pp. 359{365 Nantes, France.Digital Equipment Corporation (1998).AltaVista web page: Refine, cow9?..http://altavista.digital.com/av/content/about_our_technology_cow9.htm.Dorr, B. J. (1997). Large-Scale Dictionary Construction Foreign Language TutoringInterlingual Machine Translation. Machine Translation, 12 (4), 271{322.Fellbaum, C. (Ed.). (1998). WordNet: Electronic Lexical Database. MIT Press.Francis, W. N., & Kucera, H. (1982). Frequency Analysis English Usage: LexiconGrammar. Houghton Miin, Boston.126fiInformation-Based Semantic SimilarityGoldstone, R. L. (1999). Similarity. MIT Encyclopedia Cognitive Sciences. MITPress, Cambridge, MA.Grefenstette, G. (1992). Use syntactic context produce term association lists textretrieval. Proceedings Fifteenth Annual International ACM SIGIR Conference Research Development Information Retrieval, pp. 89{97.Grefenstette, G. (1994). Explorations Automatic Thesaurus Discovery. Kluwer, Boston.Harman, D. (1992). Relevance feedback revisited. Proceedings Fifteenth AnnualInternational ACM SIGIR Conference Research Development InformationRetrieval, pp. 1{10.Hearst, M. (1991). Noun homograph disambiguation using local context large corpora.Proceedings 7th Annual Conference University Waterloo CentreNew OED Text Research Oxford.Hindle, D., & Rooth, M. (1993). Structural ambiguity lexical relations. ComputationalLinguistics, 19 (1), 103{120.Ji, D., Gong, J., & Huang, C. (1998). Combining Chinese thesaurus Chinesedictionary. COLING-ACL '98, pp. 600{606. Universite de Montreal.Katz, S. M. (1987). Estimation probabilities sparse data language modelcomponent speech recognizer. IEEE Transactions Acoustics, Speech SignalProcessing, ASSP-35 (3), 400{401.Khinchin, A. I. (1957). Mathematical Foundations Information Theory. New York: DoverPublications. Translated R. A. Silverman M. D. Friedman.Klavans, J. L., & Tzoukermann, E. (1995). Dictionaries Corpora: Combining CorpusMachine-Readable Dictionary Data Building Bilingual Lexicons. MachineTranslation, 10, 185{218.Kobayasi, Y., Takunaga, T., & Tanaka, H. (1994). Analysis Japanese compound nounsusing collocational information. Proceedings 15th International ConferenceComputational Linguistics (COLING-94).Krovetz, R., & Croft, W. B. (1992). Lexical ambiguity information retrieval. ACMTransactions Information Systems, 10 (2), 115{141.Kurohashi, S., & Nagao, M. (1992). Dynamic programming method analyzing conjunctive structures Japanese. Proceedings 14th International ConferenceComputational Linguistics (COLING-92) Nantes, France.Lauer, M. (1994). Conceptual association compound noun analysis. Proceedings32nd Annual Meeting Association Computational Linguistics Las Cruces,New Mexico. Student Session.Lauer, M. (1995). Designing Statistical Language Learners: Experiments Noun Compounds. Ph.D. thesis, Macquarie University, Sydney, Australia.127fiResnikLeacock, C., & Chodorow, M. (1994). Filling sparse training space word senseidentification. ms.Lee, J. H., Kim, M. H., & Lee, Y. J. (1993). Information retrieval based conceptualdistance IS-A hierarchies. Journal Documentation, 49 (2), 188{207.Lee, L. (1997). Similarity-based approaches natural language processing. Tech. rep.TR-11-97, Harvard University. Doctoral dissertation. cmp-lg/9708011.Lesk, M. (1986). Automatic sense disambiguation using machine readable dictionaries:tell pine cone ice cream cone. Proceedings 1986 SIGDOCConference, pp. 24{26.Li, H., & Abe, N. (1995). Generalizing case frames using thesaurus MDL principle.Proceedings International Conference Recent Advances NLP Velingrad,Bulgaria.Lin, D. (1997). Using syntactic dependency local context resolve word sense ambiguity. Proceedings 35th Annual Meeting Association ComputationalLinguistics 8th Conference European Chapter Association Computational Linguistics Madrid, Spain.Lin, D. (1998). information-theoretic definition similarity. ProceedingsFifteenth International Conference Machine Learning (ICML-98) Madison, Wisconsin.Marcus, M. P., Santorini, B., & Marcinkiewicz, M. (1993). Building large annotatedcorpus English: Penn Treebank. Computational Linguistics, 19, 313{330.McKeown, K., & Hatzivassiloglou, V. (1993). Augmenting lexicons automatically: Clustering semantically related adjectives. Bates, M. (Ed.), ARPA Workshop HumanLanguage Technology. Morgan Kaufmann.Medin, D., Goldstone, R., & Gentner, D. (1993). Respects similarity. PsychologicalReview, 100 (2), 254{278.Merlo, P., Crocker, M., & Berthouzoz, C. (1997). Attaching multiple prepositional phrases:Generalized backed-off estimation. Proceedings Second Conference Empirical Methods Natural Language Processing (EMNLP-2). cmp-lg/9710005.Miller, G. (1990). WordNet: on-line lexical database. International Journal Lexicography, 3 (4). (Special Issue).Miller, G. A., & Charles, W. G. (1991). Contextual correlates semantic similarity. Language Cognitive Processes, 6 (1), 1{28.Morrissey,R.(1993). Texts contexts: ARTFL database French studies. Profession 93,27{33. http://humanities.uchicago.edu/homes/publications/romoart.html.128fiInformation-Based Semantic SimilarityPereira, F., Tishby, N., & Lee, L. (1993). Distributional clustering English words. Proceedings 31st Annual Meeting Association Computational Linguistics(ACL-93) Morristown, New Jersey. Association Computational Linguistics.Quillian, M. R. (1968). Semantic memory. Minsky, M. (Ed.), Semantic InformationProcessing. MIT Press, Cambridge, MA.Rada, R., & Bicknell, E. (1989). Ranking documents thesaurus. JASIS, 40 (5),304{310.Rada, R., Mili, H., Bicknell, E., & Blettner, M. (1989). Development applicationmetric semantic nets. IEEE Transaction Systems, Man, Cybernetics,19 (1), 17{30.Ratnaparkhi, A., & Roukos, S. (1994). maximum entropy model prepositional phraseattachment. Proceddings ARPA Workshop Human Language TechnologyPlainsboro, NJ.Resnik, P. (1993a). Selection Information: Class-Based Approach Lexical Relationships.Ph.D.thesis,UniversityPennsylvania.(ftp://ftp.cis.upenn.edu/pub/ircs/tr/93-42.ps.Z).Resnik, P. (1993b). Semantic classes syntactic ambiguity. Proceedings 1993ARPA Human Language Technology Workshop. Morgan Kaufmann.Resnik, P. (1995). Using information content evaluate semantic similarity taxonomy.Proceedings 14th International Joint Conference Artificial Intelligence(IJCAI-95). (cmp-lg/9511007).Resnik, P. (1996). Selectional constraints: information-theoretic model computational realization. Cognition, 61, 127{159.Resnik, P. (1998a). Disambiguating noun groupings respect Wordnet senses.Armstrong, S., Church, K., Isabelle, P., Tzoukermann, E., & Yarowsky, D. (Eds.),Natural Language Processing Using Large Corpora. Kluwer.Resnik, P. (1998b). WordNet class-based probabilities. Fellbaum, C. (Ed.), WordNet:Electronic Lexical Database. MIT Press.Resnik, P., & Yarowsky, D. (1997). perspective word sense disambiguation methodsevaluation. ANLP Workshop Tagging Text Lexical SemanticsWashington, D.C.Resnik, P., & Yarowsky, D. (1999). Distinguishing systems distinguishing senses: Newevaluation methods word sense disambiguation. Natural Language Engineering.(to appear).Richardson, R., Smeaton, A. F., & Murphy, J. (1994). Using WordNet knowledge base measuring semantic similarity words. Working paper CA1294, Dublin City University, School Computer Applications, Dublin, Ireland.ftp://ftp.compapp.dcu.ie/pub/w-papers/1994/CA1294.ps.Z.129fiResnikRoss, S. (1976). First Course Probability. Macmillan.Rubenstein, H., & Goodenough, J. (1965). Contextual correlates synonymy. CACM,8 (10), 627{633.Salton, G. (1989). Automatic Text Processing. Addison-Wesley.Schutze, H. (1993). Word space. Hanson, S. J., Cowan, J. D., & Giles, C. L. (Eds.), Advances Neural Information Processing Systems 5, pp. 895{902. Morgan KaufmannPublishers, San Mateo CA.Sinclair (ed.), J. (1987). Collins COBUILD English Language Dictionary. Collins: London.Sussna, M. (1993). Word sense disambiguation free-text indexing using massive semantic network. Proceedings Second International Conference InformationKnowledge Management (CIKM-93) Arlington, Virginia.Tversky, A. (1977). Features similarity. Psychological Review, 84, 327{352.Voorhees, E. M. (1993). Using WordNet disambiguate word senses text retrieval.Korfhage, R., Rasmussen, E., & Willett, P. (Eds.), Proceedings Sixteenth AnnualInternational ACM SIGIR Conference Research Development InformationRetrieval, pp. 171{180.Voorhees, E. M. (1994). Query expansion using lexical-semantic relations. 17th International Conference Research Development Information Retrieval (SIGIR'94) Dublin, Ireland.Vossen, P. (1998). Special issue EuroWordNet. Computers Humanities, 32 (2/3).Weiss, S. M., & Kulikowski, C. A. (1991). Computer systems learn: classificationprediction methods statistics, neural nets, machine learning, expert systems.Morgan Kaufmann, San Mateo, CA.Whittemore, G., Ferrara, K., & Brunner, H. (1990). Empirical study predictive powerssimple attachment schemes post-modifier prepositional phrases. Proceedings28th Annual Meeting Association Computational Linguistics, pp. 23{30.Pittsburgh, Pennsylvania.Wilks, Y., & Stevenson, M. (1996). grammar sense: word-sense tagging muchpart-of-speech tagging?.. Technical Report CS-96-05, cmp-lg/9607028.Wu, Z., & Palmer, M. (1994). Verb Semantics Lexical Selection. Proceedings32nd Annual Meeting Association Computational Linguistics Las Cruces,New Mexico.130fi