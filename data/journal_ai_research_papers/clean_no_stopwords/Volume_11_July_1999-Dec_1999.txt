Journal Artificial Intelligence Research 11 (1999) 199-240

Submitted 7/98; published 9/99

Unifying Class-Based Representation Formalisms

calvanese@dis.uniroma1.it
lenzerini@dis.uniroma1.it
nardi@dis.uniroma1.it

Diego Calvanese
Maurizio Lenzerini
Daniele Nardi

Dipartimento di Informatica e Sistemistica
Universita di Roma \La Sapienza"
Via Salaria 113, I-00198 Roma, Italy
Abstract

notion class ubiquitous computer science central many formalisms
representation structured knowledge used knowledge representation
databases. paper study basic issues underlying representation formalisms single common characteristics distinguishing features.
investigation leads us propose unifying framework able capture fundamental aspects several representation languages used different contexts.
proposed formalism expressed style description logics,
introduced knowledge representation means provide semantically well-founded
basis structural aspects knowledge representation systems. description logic
considered paper subset first order logic nice computational characteristics. quite expressive features novel combination constructs
studied before. distinguishing constructs number restrictions, generalize existence functional dependencies, inverse roles, allow one refer inverse
relationship, possibly cyclic assertions, necessary capturing real world
domains. able show precisely combination constructs makes
logic powerful enough model essential set features defining class structures
common frame systems, object-oriented database languages, semantic data
models. consequence established correspondences, several significant extensions
formalisms become available. high expressiveness logic
propose need capturing reasoning different contexts forces us distinguish unrestricted finite model reasoning. notable feature proposal
reasoning cases decidable. argue that, virtue high expressive
power associated reasoning capabilities unrestricted finite models,
logic provides common core class-based representation formalisms.
1. Introduction

many fields computer science find formalisms representation objects
classes (Motschnig-Pitrik & Mylopoulous, 1992). Generally speaking, object denotes
element domain interest, class denotes set objects common characteristics. use term \class-based representation formalism" refer formalism
allows one express several kinds relationships constraints (e.g., subclass constraints) holding among classes meaningful set applications. Moreover,
class-based formalisms aim taking advantage class structure order provide
various information, whether class consistent, i.e., admits least one object,
whether class subclass another class, generally, whether given constraint
c 1999 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiCalvanese, Lenzerini, & Nardi

holds given set classes. characterization, clear
formalisms referred paper deal structural aspects objects
classes, include features specification behavioral properties
objects.
Three main families class-based formalisms identified paper. first one
comes knowledge representation particular work semantic networks
frames (see example Lehmann, 1992; Sowa, 1991). second one originates
field databases particular work semantic data models (see
example Hull & King, 1987). third one arises work types programming
languages object-oriented systems (see example Kim & Lochovsky, 1989).
past several attempts establish relationships among various
families class-based formalisms (see Section 6 brief survey). proposed solutions
fully general formalism capturing modeling constructs
reasoning techniques families still missing. paper address
problem proposing class-based representation formalism, based description logics
(Brachman & Levesque, 1984; Schmidt-Schau & Smolka, 1991; Donini, Lenzerini, Nardi,
& Schaerf, 1996), using comparing formalisms.
description logics, structured knowledge described means called concepts
roles, denote unary binary predicates, respectively. Starting set
atomic symbols one build complex concept role expressions applying suitable
constructors characterize description logic. Formally, concepts interpreted
subsets domain roles binary relations domain, constructs
equipped precise set-theoretic semantics. common constructs include
boolean operations concepts, quantification roles. example, concept
Person u 8child.Male, denotes set individuals instances concept
Person connected role child instances concept Male,
concept 9child denotes individuals connected role child
individual. constructs considered important include
general forms quantification, number restrictions, allow one state limits
number connections individual may via certain role, constructs
roles, intersection, concatenation inverse. description logic knowledge base,
expressing intensional knowledge modeled domain, built stating inclusion
assertions concepts, satisfied models knowledge base.
assertions used specify necessary and/or necessary sucient conditions
individuals instances certain concepts. Reasoning knowledge bases includes
detection inconsistencies knowledge base itself, determining whether concept
populated model knowledge base, checking subsumption, i.e., whether
instances concept necessarily also instances another concept models
knowledge base.
paper propose description logic called aluni, quite expressive
includes novel combination constructs, including number restrictions, inverse roles,
inclusion assertions restrictions cycles. features make aluni powerful
enough provide unified framework frame systems, object-oriented languages,
semantic data models. show establishing precise correspondence framebased language style one proposed Fikes Kehler (1985),
200

fiUnifying Class-Based Representation Formalisms

Entity-Relationship model (Chen, 1976), object-oriented language style
one introduced Abiteboul Kanellakis (1989). specifically, identify
relevant features model classes cited settings show
specification class-based formalisms equivalently expressed
knowledge base aluni. way, able identify commonalities
among families specificities family. Therefore, even though
specific features every family addressed aluni, able
show formalism proposed paper provides important features
currently missing family, although relevance often stressed.
sense, unifying framework points possible developments languages belonging
three families.
One fundamental reason regarding aluni unifying framework class-based
representation formalisms reasoning aluni hard, nonetheless decidable,
shown Calvanese, Lenzerini, Nardi (1994), Calvanese (1996c). Consequently,
language features arising different frameworks build class-based representations
given common semantic account, combined expressive setting
one retains capability solving reasoning tasks. combination constructs
included language makes necessary distinguish reasoning respect
finite models, i.e., models finite domain, reasoning respect unrestricted
models. Calvanese (1996c) devises suitable techniques unrestricted finite model
reasoning, enable reasoning different contexts arising assuming finite
domain, often case field databases, assuming domain also
infinite. paper, discuss results reasoning aluni, compare
results reasoning class-based representation formalisms.
Summarizing, framework provides adequate expressive power account
significant features major families class-based formalisms. Moreover,
equipped suitable techniques reasoning finite unrestricted models.
Therefore, believe aluni captures essential core class-based representation
formalisms belonging three families mentioned above.
paper organized follows. next section present formalism
Sections 3, 4, 5 discuss three families class-based formalisms, namely, frame
languages, semantic data models, object-oriented data models, showing basic
features captured knowledge bases aluni. final sections contain review
related work, including discussion reasoning aluni class-based formalism,
concluding remarks.
2. Unifying Class-Based Representation Language

section, present aluni, class-based formalism style description logics
(DLs) (Brachman & Levesque, 1984; Schmidt-Schau & Smolka, 1991; Donini et al., 1996;
Donini, Lenzerini, Nardi, & Nutt, 1997). DLs domain interest modeled means
concepts roles, denote classes binary relations, respectively. Generally
speaking, DL formed three basic components:
description language, specifies construct complex concept role
expressions (also called simply concepts roles), starting set atomic
201

fiCalvanese, Lenzerini, & Nardi
Construct

atomic concept
atomic negation
conjunction
disjunction
universal quantification
number restrictions
atomic role
inverse role

Syntax

:A
C1 u C2
C1 C2
8R.C
9nR
9nR
P
P

Semantics
AI
n AI
C1I \ C2I
C1I [ C2I
fo j 8o0 . (o; o0 ) 2 RI ! o0 2 C g
fo j ]fo0 j (o; o0 ) 2 RI g ng1
fo j ]fo0 j (o; o0 ) 2 RI g ng
P
f(o; o0 ) j (o0 ; o) 2 P g

Table 1: Syntax semantics ALUNI
symbols applying suitable constructors. set allowed constructs
characterizes description language.
knowledge specification mechanism, specifies construct DL knowledge base, properties concepts roles asserted.
set basic reasoning tasks provided DL.
rest section describe specific form three components assume
aluni.
2.1 Description Language

aluni

description language aluni, called ALUNI , concepts roles formed according syntax shown Table 1, denotes atomic concept, P atomic
role, C arbitrary concept expression, R arbitrary role expression, n nonnegative integer. increase readability concept expressions, also introduce following
abbreviations:
> :A; atomic concept
? u :A; atomic concept
9R 91R
9=nR 9nR u 9nR

Concepts interpreted subsets domain roles binary relations
domain. Intuitively, :A represents negation atomic concept, interpreted
complement respect domain interpretation. C1 u C2 represents
conjunction two concepts interpreted set intersection, C1 C2 represents
disjunction interpreted set union. Consequently, > represents whole domain,
1. ]S denotes cardinality set .

202

fiUnifying Class-Based Representation Formalisms

? empty set. 8R.C called universal quantification roles used
denote elements interpretation domain connected role R
instances concept C . 9nR 9nR called number restrictions, impose
instances restrictions minimum maximum number objects
connected role R. P , called inverse role P , represents inverse
binary relation denoted P .
formally, interpretation = (I ; ) consists interpretation domain
interpretation function maps every concept C subset C
every role R subset RI according semantic rules specified Table 1.
sets C RI called extensions C R respectively.
Example 2.1 Consider concept expression
8enrolls.Student u 92enrolls u 930 enrolls u
8teaches .(Professor GradStudent) u 9=1teaches u
:AdvCourse

specifying constraints object university course. expression ects
fact course enrolls students, restrictions minimum maximum
number enrolled students. using role teaches inverse constructor
state property course taught exactly one individual, either
professor graduate student. Finally, negation used express disjointness
concept denoting advanced courses.
2.2 Knowledge Bases

aluni

aluni knowledge base, expresses knowledge classes relations
modeled domain, formally defined triple K = (A; P ; ), finite set
atomic concepts, P finite set atomic roles, finite set called inclusion
assertions. assertion form
_ C
atomic concept C arbitrary concept expression. inclusion
assertion states means concept C necessary properties element domain
order instance atomic concept A. Formally, interpretation satisfies
inclusion assertion _ C AI C . interpretation model knowledge
base K satisfies inclusion assertions K. finite model model finite
domain.
Example 2.1 (cont.) assertion
_ 8enrolls.Student u 92enrolls u 930enrolls u
Course
8teaches .(Professor GradStudent) u 9=1teaches
makes use complex concept expression state necessary conditions object
instance concept Course.
203

fiCalvanese, Lenzerini, & Nardi

aluni restrictions imposed form inclusion assertions may
assume. particular rule cyclic assertions, i.e., assertions
concept expression right hand side refers, either directly indirectly via
assertions, atomic concept left hand side. presence cyclic assertions
different semantics may adopted (Nebel, 1991). one defined above, called descriptive
semantics, accepts interpretations satisfy assertions knowledge base,
hence interprets assertions constraints domain modeled. inclusion
assertions, descriptive semantics claimed provide intuitive results
(Buchheit, Donini, Nutt, & Schaerf, 1998). Alternative semantics proposed
based fixpoint constructions (Nebel, 1991; Schild, 1994; De Giacomo & Lenzerini,
1994b), hence allow define unique way interpretation concepts.
general, cycles knowledge base increase complexity reasoning (Nebel,
1991; Baader, 1996; Calvanese, 1996b) require special treatment reasoning procedures (Baader, 1991; Buchheit, Donini, & Schaerf, 1993). reason, many DL based
systems assume knowledge base acyclic (Brachman, McGuinness, Patel-Schneider,
Alperin Resnick, & Borgida, 1991; Bresciani, Franconi, & Tessaris, 1995). However, assumption unrealistic practice, cycles definitely necessary correct modeling
many application domains. Indeed, use cycles allowed data models used
databases, and, shown following sections, order capture semantics
aluni possibility using cyclic assertions fundamental.
Besides inclusion assertions, DL based systems also make use equivalence assertions (Buchheit et al., 1993), express necessary sucient conditions
object instance concept. Although possibility ruled aluni,
limit ability capturing frame based systems database models,
constraints expressed correspond naturally inclusion assertions.
2.3 Reasoning

aluni

basic tasks consider reasoning aluni knowledge base concept
consistency concept subsumption:
Concept consistency problem deciding whether concept C consistent
knowledge base K (written K 6j= C ?), i.e., whether K admits model
C 6= ;.
Concept subsumption problem deciding whether concept C1 subsumed
concept C2 knowledge base K (written K j= C1 C2), i.e., whether C1I C2I
model K.
inclusion number restrictions inverse roles ALUNI ability
aluni using arbitrary, possibly cyclic inclusion assertions allows one construct knowledge base certain concept consistent necessarily empty extension
finite models knowledge base. Similarly, subsumption relation two
concepts may hold infinite models knowledge base ruled finite
models considered.
204

fiUnifying Class-Based Representation Formalisms
Keven = (A P ),
= fNumber Eveng,
P = fdoublesg,
set assertions consists of:
;

;

;

Number
Even

_ 9doubles u 8doubles .Even
_ Number u 91 doubles u 8doubles.Number

Figure 1: aluni knowledge base two concepts equivalent finite
models
Let Keven knowledge base shown Figure 1. Intuitively, assertions Keven state number even number doubles it,
numbers double even. even number number, doubles
one number, doubles numbers. Observe model Keven , universal quantifications together functionality doubles assertions imply
]EvenI ]NumberI , direct inclusion assertion Even Number implies
]EvenI ]NumberI . Therefore, two concepts cardinality, since
one sub-concept other, domain finite, extensions coincide.
necessarily hold infinite domains. fact, names chosen suggest
already infinite model knowledge base Number Even interpreted
differently. model obtained taking natural numbers domain, interpreting Number whole domain, Even even numbers, doubles set
f(2n; n) j n 0g.
example shows aluni finite model property,
states concept consistent knowledge base knowledge base admits
finite model concept nonempty extension. Therefore, important
distinguish reasoning respect unrestricted models reasoning
respect finite models. call (unrestricted) concept consistency (written K 6j=u C
?) (unrestricted) concept subsumption (written K j=u C ) reasoning tasks
described above, i.e., carried without restricting attention finite models.
corresponding reasoning tasks carried considering finite models only, called finite
concept consistency (written K 6j=f C ?) finite concept subsumption (written
K j=f C ).
Example 2.2 (cont.) Summing previous considerations, say Number
subsumed Even Keven , i.e., Keven 6j=u Number Even, finitely subsumed, i.e.,
Keven j=f Number Even. Equivalently Numberu:Even consistent Keven , i.e., Keven 6j=u
Number u:Even ?, finitely consistent, i.e., Keven j=f Number u:Even ?.
distinguishing feature aluni reasoning finite unrestricted case decidable. particular, unrestricted concept satisfiability concept
subsumption decidable deterministic exponential time (De Giacomo & Lenzerini,
Example 2.2

205

fiCalvanese, Lenzerini, & Nardi

1994a; Calvanese et al., 1994), since reasoning strict sublanguages aluni already EXPTIME-hard (Calvanese, 1996c), known algorithms computationally optimal. Finite concept consistency aluni also decidable deterministic exponential time
finite concept subsumption (in general case) decidable deterministic double
exponential time (Calvanese, 1996c). precise discussion methods reasoning aluni provided Section 6.2, detailed account adopted algorithms
analysis computational complexity presented Calvanese (1996c).
next sections show two forms reasoning respect unrestricted
finite models, capture reasoning tasks typically considered different
formalisms structured representation knowledge.
3. Frame Based Systems

Frame languages based idea expressing knowledge means frames,
structures representing classes objects terms properties instances
must satisfy. properties defined frame slots, constitute items
frame definition. Since 70s large number frame systems developed,
different goals different features. DLs bear close relationship kl-one family
frame systems (Woods & Schmolze, 1992). However, would like consider frame
systems general perspective, discussed example Karp (1992), Karp,
Myers, Gruber (1995), establish correspondence aluni knowledge bases
context.
remark restricting attention aspects related
taxonomic structure. Moreover, discussed below, consider assertional knowledge
bases, intensional knowledge characterized terms inclusion assertions rather
definitions. addition, consider features cannot captured
first-order framework, default values slots, attached procedures,
specification overriding inheritance policies. issues concerning modeling
aspects DLs addressed Donini, Lenzerini, Nardi, Nutt, Schaerf (1994),
Donini, Nardi, Rosati (1995), within modal nonmonotonic extension DLs.
3.1 Syntax Frame Based Systems

make correspondence precise, need fix syntax semantics frame
systems consider. Unfortunately, accepted standard chosen
use basically notation adopted Fikes Kehler (1985), used also
KEE2 system.
frame knowledge base, denoted F , formed set frame
slot names, constituted set frame definitions following form:
Definition 3.1

Frame : F KB F E;
2. KEE trademark Intellicorp. Note KEE user directly specify knowledge base
notation, allowed define frames interactively via graphical system interface.

206

fiUnifying Class-Based Representation Formalisms
: Course KB University
: enrolls
ValueClass: Student
Cardinality.Min: 2
Cardinality.Max: 30
MemberSlot: taughtby
ValueClass: (UNION GradStudent
Professor)
Cardinality.Min: 1
Cardinality.Max: 1

Frame

: BasCourse KB University
: Course
MemberSlot: taughtby
ValueClass: Professor

Frame

MemberSlot

SuperClasses

: Professor

Frame

: Student

Frame

KB

University

University

: GradStudent KB University
: Student
MemberSlot: degree
ValueClass: String
Cardinality.Min: 1
Cardinality.Max: 1

Frame

SuperClasses

: AdvCourse KB University
: Course
MemberSlot: enrolls
ValueClass: (INTERSECTION

Frame

SuperClasses

GradStudent
(NOT Undergrad))

KB

: Undergrad KB University
: Student

Frame

SuperClasses

: 20

Cardinality.Max

Figure 2: KEE knowledge base
E frame expression, i.e., expression formed according following syntax:
E ! SuperClasses : F1 ; : : : ; Fh
MemberSlot : S1
ValueClass : H1
Cardinality.Min : m1
Cardinality.Max : n1

MemberSlot : Sk
ValueClass : Hk
Cardinality.Min : mk
Cardinality.Max : nk
F denote frame slot names, respectively, n denote positive integers,
H denotes slot constraint, specified follows:
H

! Fj

(INTERSECTION H1 H2) j
(UNION H1 H2) j
(NOT H )

readers familiar KEE system, point omit
specification sub-classes frame present KEE, since directly derived
specification super-classes.
Example 3.2 Figure 2 shows simple example knowledge base modeling situation
university expressed frame language presented. frame Course
207

fiCalvanese, Lenzerini, & Nardi

represents courses enroll students taught either graduate students
professors. Cardinality restrictions used impose minimum maximum number
students may enrolled course, express course taught
exactly one individual. frame AdvCourse represents courses enroll graduate
students, i.e., students already degree. Basic courses, hand, may
taught professors.
3.2 Semantics Frame Based Systems

give semantics set frame definitions resort interpretation terms
first-order predicate calculus (Hayes, 1979). According interpretation, frame names
treated unary predicates, slots considered binary predicates.
frame expression E interpreted predicate logic formula E (x), one
free variable, consists conjunction sentences, obtained super-class
specification slot specification. particular, super-classes F1 ; : : : ; Fh
have:
F1 (x) ^ : : : ^ Fh (x)
slot specification
MemberSlot :
ValueClass : H
Cardinality.Min :
Cardinality.Max : n

8y. (S (x; y) !VH (y)) ^
9y1; : : : ; ym. (( i6=j yi 6= yj ) ^ (x; y1 ) ^ ^ (x; ym )) ^
8y1; : : : ; yn+1. ((S (x; y1 ) ^ ^ (x; yn+1)) ! Wi6=j yi = yj );
assumption within one frame definition occurrences x refer
free variable. Finally constraints slots interpreted conjunction, disjunction
negation, respectively, i.e.:
(INTERSECTION H1 H2) interpreted H1(x) ^ H2(x)
(UNION H1 H2)
interpreted H1(x) _ H2(x)
(NOT H )
interpreted :H (x)
frame definition
Frame : F KB F E
considered universally quantified sentence form
8x.(F (x) ! E (x)):
whole frame knowledge base F considered conjunction first-order sentences corresponding frame definitions F .
regard frame definitions necessary conditions, commonplace
frame systems known assertional frame systems, opposed definitional systems,
frame definitions interpreted necessary sucient conditions.
208

fiUnifying Class-Based Representation Formalisms

order enable comparison formalisms representing structured knowledge restrict attention reasoning tasks involve frame knowledge base,
independently assertional knowledge, i.e., frames instances. Fikes Kehler
(1985) mention several reasoning services associated frames, as:
Consistency checking, amounts verifying whether frame F satisfiable
knowledge base. particular, involves reasoning cardinalities
checking whether filler given slot belongs certain frame.
Inheritance, which, case, amounts ability identifying
frames general given frame, sometimes called all-super-of (Karp
et al., 1995). properties general frames inherited
specific one. reasoning therefore based general ability
check mutual relationhips frame descriptions knowledge base.
reasoning services formalized first-order semantics follows.
Definition 3.3 Let F frame knowledge base F frame F . say F
consistent F first-order sentence F ^ 9x.F (x) satisfiable. Moreover, say
frame description E general F F F j= 8x.(F (x) ! E (x)).
3.3 Relationship Frame Based Systems

aluni

first-order semantics given allows us establish straightforward relationship
frame languages aluni. Indeed, present translation frame
knowledge bases aluni knowledge bases.
first define function maps frame expression ALUNI concept
expression follows:
Every frame name F mapped atomic concept (F ).
Every slot name mapped atomic role (S ).
Every slot constraint mapped follows
(UNION H1 H2)
mapped (H1) (H2):
(INTERSECTION H1 H2) mapped (H1) u (H2):
(NOT H )
mapped :(H ):
Every frame expression form
SuperClasses : F1 ; : : : ; Fh
MemberSlot : S1
ValueClass : H1
Cardinality.Min : m1
Cardinality.Max : n1

MemberSlot : Sk
ValueClass : Hk
Cardinality.Min : mk
Cardinality.Max : nk
209

fiCalvanese, Lenzerini, & Nardi
K = (A P ),
= fCourse AdvCourse BasCourse Professor Student GradStudent Undergrad Stringg,
P = fenrolls taughtby degreeg,
set assertions consists of:
;

;

;

;

;

Course
AdvCourse
BasCourse
GradStudent
Undergrad

;

;

;

;

;

;

_ 8enrolls.Student u 92 enrolls u 930 enrolls u
8taughtby.(Professor GradStudent) u 9=1 taughtby
_ Course u 8enrolls.(GradStudent u :Undergrad) u 920 enrolls
_ Course u 8taughtby.Professor
_ Student u 8degree.String u 9=1 degree
_ Student

Figure 3: aluni knowledge base corresponding KEE knowledge base Figure 2
mapped class expression
(F1 ) u u (Fh ) u
8(S1).(H1) u 9m (S1) u 9n (S1) u

8(Sk ).(Hk ) u 9mk (Sk ) u 9nk (Sk):
1

1

mapping allows us translate frame knowledge base aluni knowledge base,
specified following definition.
aluni knowledge base (F ) = (A; P ; ) corresponding frame
knowledge base F obtained follows:
consists one atomic concept (F ) frame name F F .
P consists one atomic role (S ) slot name F .
consists inclusion assertion
(F ) _ (E )
frame definition
Frame : F KB F E
F .
Definition 3.4

Example 3.2 (cont.) illustrate translation frame knowledge base Figure 2. corresponding aluni knowledge base shown Figure 3.
210

fiUnifying Class-Based Representation Formalisms

correctness translation follows correspondence settheoretic semantics aluni first-order interpretation frames (see example
Hayes, 1979; Borgida, 1996; Donini et al., 1996). observe inverse roles
fact necessary formalization frames. Indeed, possibility referring
inverse slot rarely considered frame knowledge representation systems (Some
exceptions reported Karp, 1992). Due absence inverse roles distinction
reasoning finite unrestricted models necessary3 . Consequently,
mentioned forms reasoning captured unrestricted concept consistency
concept subsumption aluni knowledge bases. summarized following
theorem.
Theorem 3.5 Let F frame knowledge-base, F frame F , E frame description, (F ), (F ), (E ) translations aluni. following
hold:

F consistent F (F ) 6j=u (F ) ?.
E general F F (F ) j=u (F ) (E ).

claim directly follows semantics frame knowledge bases
translation DLs adopted.
Theorem 3.5 becomes possible exploit methods unrestricted reasoning
aluni knowledge bases order reason frame knowledge bases. Since problem
reasoning, e.g., KEE already EXPTIME-complete, pay terms computational complexity expressiveness added constructs aluni. fact,
resorting correspondence aluni becomes possible add frame systems
useful features, possibility specifying inverse slot (Karp, 1992),
still retain ability reason EXPTIME.
Proof.

4. Semantic Data Models

Semantic data models introduced primarily formalisms database schema design.
provide means model databases much richer way traditional data
models supported Database Management Systems, becoming
important adopted recent database design methodologies
Computer Aided Software Engineering tools.
widespread semantic data model Entity-Relationship (ER) model introduced Chen (1976). become standard, extensively used design
phase commercial applications. commonly accepted ER notation, classes called
entities represented boxes, whereas relationships entities represented
diamonds. Arrows entities, called ISA relationships, represent inclusion assertions. links entities relationships represent ER-roles, number
restrictions associated. Dashed links used whenever restrictions refined
specific entities. Finally, elementary properties entities modeled attributes,
3. eliminate

ALUNI inverse roles, resulting DL finite model property.
211

fiCalvanese, Lenzerini, & Nardi

whose values belong one several predefined domains, Integer, String,
Boolean.
ER model provide constructs expressing explicit disjointness disjunction entities, extensions model allow use generalization hierarchies
represent combination two constructs. order keep presentation simple, consider generalization hierarchies formalization provide,
although addition would straightforward. Similarly, omit attributes relations.
show relevant aspects ER model captured aluni,
thus reasoning ER schema reduced reasoning corresponding
aluni knowledge base. Since aluni equipped capabilities reason knowledge
bases, respect finite unrestricted models (see Section 6.2), reduction
shows reasoning ER model, generally semantic data models,
decidable.
case frame-based systems, restrict attention aspects
constitute core ER model. reason consider features,
keys weak entities, introduced literature (Chen, 1976),
appear formalizations ER model methodologies
conceptual modeling based model. proposal treatment keys description
logics presented Borgida Weddell (1997).
order establish correspondence ER model aluni, present
formal syntax semantics ER schemata.
4.1 Syntax Entity-Relationship Model

Although ER model become industrial standard, several variants
extensions introduced, differ minor aspects expressiveness
notation (Chen, 1976; Teorey, 1989; Batini, Ceri, & Navathe, 1992; Thalheim, 1992, 1993).
Also, ER schemata usually defined using graphical notation particularly
useful easy visualization data dependencies, well suited
purposes. Therefore chosen formalization ER model abstracts
respect important characteristics allows us develop correspondence
aluni.
following, two finite sets X call function subset X
X -labeled tuple . labeled tuple maps xi 2 X yi 2 ,
2 f1; : : : ; kg, denoted [x1 : y1 ; : : : ; xk : yk ]. also write [xi ] denote yi .
ER schema tuple = (LS ; ; att ; rel ; card ),
LS finite alphabet partitioned set ES entity symbols, set attribute
symbols, set US role symbols, set RS relationship symbols, set DS
domain symbols; domain symbol associated predefined basic domain
DBD , assume various basic domains pairwise disjoint.
ES ES binary relation ES .
att function maps entity symbol ES -labeled tuple DS .

Definition 4.1

212

fiUnifying Class-Based Representation Formalisms

function maps relationship symbol RS US -labeled tuple
ES . assume without loss generality that:
{ role specific exactly one relationship, i.e., two relationships
R; R0 2 RS R 6= R0 , rel (R) = [U1 : E1 ; : : : ; Uk : Ek ] rel (R0 ) =
[U10 : E10 ; : : : ; Uk0 0 : Ek0 0 ], fU1; : : : ; Uk g fU10 ; : : : ; Uk0 0 g disjoint.
{ role U 2 US relationship R entity E
rel (R) = [: : : ; U : E; : : :].
card function ES RS US IN0 (IN0 [ f1g) satisfies following condition: relationship R 2 RS rel (R) = [U1 : E1 ; : : : ; Uk : Ek ],
card (E; R; U ) defined U = Ui 2 f1; : : : ; kg, E Ei
(where denotes exive transitive closure ). first component
card (E; R; U ) denoted cmin (E; R; U ) second component
cmax (E; R; U ). stated otherwise, cmin (E; R; U ) assumed 0
cmax (E; R; U ) assumed 1.
specifying formal semantics ER schemata give intuitive description
components schema. relation models ISA-relationship entities.
need make special assumption form acyclicity
injectivity. function att used model attributes entities. example
att associates -labeled tuple [A1 : Integer; A2 : String] entity E , E
two attributes A1 ; A2 whose values integers strings respectively. simplicity
assume attributes single-valued mandatory, could easily handle also multivalued attributes associated cardinalities. function rel associates set roles
relationship symbol R, determining implicitly also arity R, role
U set distinguished entity, called primary entity U R. database
satisfying schema instances primary entity allowed participate
relationship via role U . function card specifies cardinality constraints, i.e.,
constraints minimum maximum number times instance entity may
participate relationship via role. Since constraints meaningful
entity effectively participate relationship, function defined
sub-entities primary entity. special value 1 used restriction
posed maximum cardinality. constraints used specify existence
dependencies functionality relations (Cosmadakis & Kanellakis, 1986).
often used restricted form, minimum cardinality either 0 1
maximum cardinality either 1 1. Cardinality constraints form considered
introduced already Abrial (1974) subsequently studied Grant
Minker (1984), Lenzerini Nobili (1990), Ferg (1991), Ye, Parent, Spaccapietra
(1994), Thalheim (1992).
Example 4.2 Figure 4 shows simple ER schema modeling state affairs similar
one represented KEE knowledge base Figure 2. used standard graphic
notation ER schemata, except dashed link, represents refinement
cardinality constraint participation sub-entity (in case AdvCourse)
relationship (in case ENROLLING).


rel

213

fiCalvanese, Lenzerini, & Nardi

Tof

(1,1)

Course

6

Ein

(2,30)

TEACHING

ENROLLING

Tby

(0,1)

Eof

(4,6)

Teacher

Student

6

(2,20)
AdvCourse

degree/String

GradStudent

Figure 4: ER schema
4.2 Semantics Entity-Relationship Model

semantics ER schema given specifying database states
consistent information structure represented schema. Formally, database
state B corresponding ER schema = (LS ; ; att ; rel ; card ) constituted
nonempty finite set B , assumed disjoint basic domains, function B
maps
every domain symbol 2 DS corresponding basic domain DBD ,
every entity E 2 ES subset E B B ,
every attribute 2 set AB B SD2DS DBD ,
every relationship R 2 RS set RB US -labeled tuples B .
elements E B , AB , RB called instances E , A, R respectively.
database state considered acceptable satisfies integrity constraints
part schema. captured definition legal database state.
Definition 4.3 database state B said legal ER schema =
(LS ; ; att ; rel ; card ), satisfies following conditions:
pair entities E1; E2 2 ES E1 E2, holds E1B E2B .
entity E 2 ES , att (E ) = [A1 : D1 ; : : : ; Ah : Dh], instance
e 2 E B 2 f1; : : : ; hg following holds:
{ exactly one element ai 2 ABi whose first component e,
{ second component ai element DiBD .
relationship R 2 RS rel (R) = [U1 : E1 ; : : : ; Uk : Ek ], instances
R form [U1: e1 ; : : : ; Uk : ek ], ei 2 EiB , 2 f1; : : : ; kg.
214

fiUnifying Class-Based Representation Formalisms
Number

(1,1)

6

Even

DOUBLES

(0,1)

Figure 5: ER schema corresponding Example 2.2
relationship R 2 RS rel (R) = [U1 : E1 ; : : : ; Uk : Ek ],
2 f1; : : : ; kg, entity E 2 ES E Ei instance e E
, holds
cmin (E; R; Ui ) ]fr 2 RB j r[Ui ] = eg cmax (E; R; Ui ):

Notice definition database state ects usual assumption databases
database states finite structures (see also Cosmadakis, Kanellakis, & Vardi, 1990).
fact, basic domains required finite, legal database state
schema, finite set values basic domains actually interest.
define active domain Bact database state B set elements basic
domains DBD , 2 DS , effectively appear values attributes B. formally:
Bact = fd 2 DBD j 2 DS ^ 9A 2 ; e 2 B . (e; d) 2 AB g:
Since B finite contains finite number attributes, functional
definition, also Bact finite.
Reasoning ER model includes verifying entity satisfiability deducing inheritance. Entity satisfiability amounts checking whether given entity populated
legal database state (Atzeni & Parker Jr., 1986; Lenzerini & Nobili, 1990; Di Battista
& Lenzerini, 1993), corresponds notion concept consistency DLs. Deducing
inheritance amounts verifying whether databases legal schema,
every instance entity also instance another entity. implied ISA relationships arise different reasons. Either trivially, transitive closure
explicit ISA relationships present schema, subtle ways, specific
patterns cardinality restrictions along cycles schema requirement
database state finite (Lenzerini & Nobili, 1990; Cosmadakis et al., 1990).
Figure 5 shows ER schema modeling situation knowledge
base Example 2.2. Arguing exactly example conclude two
entities Number Even denote set elements every finite database legal
schema, although ISA relation Number Even stated explicitly.
implied, however, due cycle involving relationship two entities due
particular form cardinality constraints.
Example 4.4

215

fiCalvanese, Lenzerini, & Nardi
4.3 Relationship Entity-Relationship Schemata

aluni

show different forms reasoning ER schemata captured finite
concept consistency finite concept subsumption aluni. correspondence
two formalisms established defining translation ER schemata aluni
knowledge bases, proving correspondence legal database
states finite models derived knowledge base.
Definition 4.5 Let = (LS ; ; att ; rel ; card ) ER schema. aluni knowledge base (S ) = (A; P ; ) defined follows:
set atomic concepts (S ) contains following elements:
domain symbol 2 DS , atomic concept (D);
entity E 2 ES , atomic concept (E );
relationship R 2 RS , atomic concept (R).
set P atomic roles (S ) contains following elements:
attribute 2 , atomic role (A);
relationship R 2 RS rel (R) = [U1 : E1 ; : : : ; Uk : Ek ], k atomic roles
(U1 ); : : : ; (Uk ).
set assertions (S ) contains following elements:
pair entities E1; E2 2 ES E1 E2, assertion
(E1 ) _ (E2 )
(1)
entity E 2 ES att (E ) = [A1 : D1 ; : : : ; Ah: Dh ], assertion
(E ) _ 8(A1 ).(D1 ) u u 8(Ah ).(Dh ) u 9=1(A1 ) u u 9=1 (Ah ) (2)
relationship R 2 RS rel (R) = [U1 : E1 ; : : : ; Uk : Ek ], assertions
(R) _ 8(U1 ).(E1 ) u u 8(Uk ).(Ek ) u 9=1 (U1 ) u u 9=1(Uk ) (3)
(Ei ) _ 8((Ui )) .(R);
2 f1; : : : ; kg
(4)
relationship R 2 RS rel (R) = [U1 : E1 ; : : : ; Uk : Ek ], 2
f1; : : : ; kg, entity E 2 ES E Ei,
{ = cmin (E; R; Ui ) 6= 0, assertion
(E ) _ 9m ((Ui )) :
(5)
{ n = cmax (E; R; Ui ) 6= 1, assertion
(E ) _ 9n ((Ui )) :
(6)
pair symbols X1 ; X2 2 ES [RS [DS X1 6= X2 X1 2 RS [DS ,
assertion
(X1 ) _ :(X2 ):
(7)
216

fiUnifying Class-Based Representation Formalisms
K = (A P ),
= fCourse AdvCourse Teacher Student GradStudent TEACHING ENROLLING Stringg,
P = fTof Tby Ein Eof degreeg,
set assertions consists of:
;

;

;

;

;

;

;

;

;

;

;

;

;

TEACHING
ENROLLING
Course
AdvCourse
Teacher
Student
GradStudent

_ 8Tof.Course u 9=1 Tof u
8Tby.Teacher u 9=1 Tby
_ 8Ein.Course u 9=1 Ein u
8Eof.Student u 9=1 Eof
_ 8Tof .TEACHING u 9=1 Tof u
8Ein .ENROLLING u 92 Ein u 930 Ein
_ Course u 920 Ein
_ 8Tby .TEACHING
_ 8Eof .ENROLLING u 94 Eof u 96 Eof
_ Student u 8degree.String u 9=1 degree

:

Figure 6: aluni knowledge base corresponding ER schema Figure 4
illustrate translation ER schema Figure 4.
knowledge base captures exactly semantics shown Figure 6,
brevity disjointness assertions (7) omitted, assertions concept
left hand side collapsed.
translation makes use inverse attributes number restrictions capture
semantics ER schemata. observe that, means inverse constructor,
binary relationship could treated simpler way choosing traversal direction
mapping relationship directly role. Notice also assumption acyclicity
resulting knowledge base unrealistic case, order exploit correspondence reasoning ER model, need techniques deal inverse
attributes, number restrictions, cycles together. shown Example 2.2, combination factors causes finite model property fail hold, need
resort reasoning methods finite models.
fact, reduce reasoning ER model finite model reasoning aluni
knowledge bases. purpose define mapping database states corresponding ER schema finite interpretations knowledge base derived it.
Due possible presence relations arity greater 2, mapping however
one-to-one first need characterize interpretations knowledge base
directly correspond database states.
Definition 4.6 Let = (LS ; ; att ; rel ; card ) ER schema (S ) defined
above. interpretation (S ) relation-descriptive, every relationship R 2
RS , rel (R) = [U1 : E1 ; : : : ; Uk : Ek ], every d; d0 2 ((R))I ,
^
(8)
( 8d00 2 . ((d; d00 ) 2 ((Ui ))I $ (d0 ; d00 ) 2 ((Ui ))I )) ! = d0 :
Example 4.2 (cont.)
aluni

1ik

217

fiCalvanese, Lenzerini, & Nardi

Intuitively, extension relationship database state set labeled tuples,
set contain element twice. Therefore implicit
semantics ER model cannot two labeled tuples connected
roles relationship exactly elements domain. model
aluni knowledge base corresponding ER schema, hand, tuple
represented new individual, condition implicit anymore. also
cannot imposed aluni suitable assertions. following lemma, however, shows
need explicit condition, interested reasoning
aluni knowledge base corresponding ER schema. due fact
always restrict considering relation-descriptive models.
ER schema, (S ) aluni knowledge base obtained
according Definition 4.5, C concept expression (S ). C finitely consistent
(S ), finite relation-descriptive model (S ) C 6= ;.
Lemma 4.7 Let

Let I0 finite model (S ) C 6= ;. build finite relationdescriptive model 0 starting I0 applying following construction
relationship RS .
Let model obtained previous step let R 2 RS rel (R) =
[U1 : E1 ; : : : ; Uk : Ek ] next relationship apply construction. construct model IR condition 8 satisfied relationship R.
Given individual r 2 ((R))I , denote Ui(d), 2 f1; : : : ; kg (unique)
individual e (r; e) 2 ((Ui ))I . ei 2 ((Ei ))I , 2 f1; : : : ; kg define
X(U :e ;:::;Uk :ek ) = fr 2 ((R))I j Ui (d) = ei ; 2 f1; : : : ; kgg. call con ict-set
set X(U :e ;:::;Uk:ek ) one element. con ict-set X(U :e ;:::;Uk:ek)
randomly choose one individual r, say others induce con ict
(U1 : e1 ; : : : ; Uk : ek ). call Conf (finite) set objects inducing con ict
(U1 : e1 ; : : : ; Uk : ek ).
define interpretation I2Conf disjoint union 2]Conf copies , one copy,
denoted IZ , every set Z 2 2Conf . denote dZ copy IZ individual
. Since disjoint union two models aluni knowledge base
model, I2Conf model (S ). Let IZ IZ 0 two copies I2Conf . call
exchanging Uk (rZ ) Uk (rZ 0 ) operation I2Conf consisting replacing ((Uk ))IZ
pair (rZ ; Uk (rZ )) (rZ ; Uk (rZ 0 )) and, time, replacing ((Uk ))IZ0
pair (rZ 0 ; Uk (rZ 0 )) (rZ 0 ; Uk (rZ )). Intuitively, exchanging Uk (rZ ) Uk (rZ 0 ),
individuals rZ rZ 0 induce con icts anymore.
construct I2Conf interpretation IR follows: r 2 Conf
Z 2 2Conf r 2 Z , exchange Uk (rZ ) Uk (rZnfrg ). possible
show con icts thus eliminated new con ict created. Hence,
IR, condition 8 R satisfied. still show IR model (S )
C IR 6= ;. Indeed, straightforward check induction every concept
expression C 0 appearing (S ), Z 2 2Conf , 2 C 0I dZ 2 C 0IR . Thus
assertions (S ) still satisfied IR C IR 6= ;.
Proof.

1 1

1 1

1 1

218

fiUnifying Class-Based Representation Formalisms

result, following correspondence legal database states
ER schema relation-descriptive models resulting aluni knowledge base
established.
Proposition 4.8 every ER schema = (LS ; ; att ; rel ; card ) exist two
mappings ffS , database states corresponding finite interpretations translation (S ), fiS , finite relation-descriptive interpretations (S ) database states
corresponding , that:

1. legal database state B , ffS (B) finite model (S ),
symbol X 2 ES [ [ RS [ DS , X B = ((X ))ffS (B) .

2. finite relation-descriptive model (S ), fiS (I ) legal database state
, entity E 2 ES , ((E ))I = E fiS (I ) , symbol X 2 [RS [DS ,
](X )I = ]X fiS (I ) .

Proof.

(1) Given database state B, define interpretation = ffS (B) (S )

follows:
= B [ Bact [ SR2RS RB .
symbol X 2 ES [ [ RS [ DS ,
((X ))I = X B :

relationship R 2 RS rel (R) = [U1 : E1 ; : : : ; Uk : Ek ],
((Ui ))I = f(r; e) 2 j r 2 RB ; r[Ui] = eg; 2 f1; : : : ; kg:

(9)
(10)

Let B legal database state. prove claim (1) sucient show satisfies
every assertion (S ). Assertions 1 satisfied since B satisfies set inclusion
extensions corresponding entities. respect assertions 2, let E 2 ES
entity att (E ) = [A1 : D1 ; : : : ; Ah : Dh], consider instance e 2 ((E ))I .
show 2 f1; : : : ; hg, exactly one element ei 2
(e; ei ) 2 ((Ai ))I , moreover ei 2 ((Di ))I . 9, e 2 E B , definition legal
database state exactly one element ai 2 ABi = ((Ai ))BI whose first component e.
Moreover, second component ei ai element Di = ((Di ))I . respect
assertions 3, let R 2 RS relationship rel (R) = [U1 : E1 ; : : : ; Uk : Ek ],
consider instance r 2 ((R))I . show 2 f1; : : : ; kg
exactly one element ei 2 (r; ei ) 2 ((Ui ))I , moreover
ei 2 ((Ei ))I . 9, r 2 RB , definition legal database state, r labeled tuple
form [U1 : e01 ; : : : ; Uk : e0k ], e0i 2 EiB , 2 f1; : : : ; kg. Therefore r function
defined fU1 ; : : : ; Uk g, 10, ei unique equal e0i. Moreover, 9,
ei 2 ((Ei ))I = EiB . Assertions 4 satisfied, since 10 first component
element ((Ui ))I always element RB = ((R))I . respect assertions 5,
let R 2 RS relationship rel (R) = [U1 : E1 ; : : : ; Uk : Ek ], let E 2 ES
entity E Ei, 2 f1; : : : ; kg, = cmin (E; R; Ui ) 6= 0.
219

fiCalvanese, Lenzerini, & Nardi

Consider instance e 2 ((E ))I . show least pairs
((Ui ))I e second component. Since assertions 4 satisfied know
first component pairs instance (R). 9 definition
legal database state, least labeled tuples RB whose Ui component
equal e. 10, ((Ui ))I contains least pairs whose second component equal
e. respect assertions 6 proceed similar way. Finally, assertions 7
satisfied since first, definition basic domains pairwise disjoint disjoint
B set labeled tuples, second, element B labeled tuple,
third, labeled tuples corresponding different relationships cannot equal since
defined different sets roles.
(2) Let finite relation-descriptive interpretation (S ). basic domain
2 DS , let fiD function DBD one-to-one onto. Since
finite basic domain contains countable number elements, function
always exists. order define fiS (I ) first specify mapping fi associates
individual 2 element follows:
2 ((E ))I entity E 2 ES , fi (d) = d.
2 ((R))I relationship R 2 RS rel (R) = [U1 : E1 ; : : : ; Uk : Ek ],
individuals d1; : : : ; dk 2 (d; di ) 2 ((Ui ))I , 2 f1; : : : ; kg,

fi (d) = [U1 : d1 ; : : : ; Uk : dk ].

2 ((D))I basic domain 2 DS , fi (d) = fiD (d).
Otherwise fi (d) = d.

pair individuals (d1 ; d2 ) 2 , fi((d1 ; d2 )) = (fi (d1 ); fi (d2 )), set
X , fi (X ) = ffi (x) j x 2 X g.
model (S ) rules define fi(d) every 2 . Indeed,
assertions 7, 2 instance one atomic concept corresponding
relationship basic domain, case instance atomic
concept corresponding entity. Moreover, 2 ((R))I relationship R 2 RS
rel (R) = [U1: E1 ; : : : ; Uk : Ek ], assertions 3, 2 f1; : : : ; kg
exactly one element di 2 (d; di ) 2 ((Ui ))I . model (S )
2 , fi(d) uniquely determined, choose nondeterministically
one possible value.
define database state B = fiS (I ) corresponding :
B = n







R2RS ((R)) [ D2DS ((D )) .

symbol X 2 ES [ [ RS [ DS , X B = fi(((X ))I ).

dicult see, model (S ), B defined way legal
database state active domain SD2DS ((D))I .
220

fiUnifying Class-Based Representation Formalisms

following theorem allows us reduce reasoning ER schemata finite model
reasoning aluni knowledge bases.
Theorem 4.9 Let ER schema, E; E 0 two entities , (S ) translation . following holds:

(S ) 6j=f (E ) ?.
2. E inherits E 0 (S ) j=f (E ) (E 0 ).
B 6 ;. part 1 Proposition 4.8,
Proof. (1) \)" Let B legal database state E =
ff
(
B
)

ffS (B) finite model (S ) ((E ))
=6 ;.
\(" Let (E ) finitely consistent (S ). Lemma 4.7 finite relationdescriptive model (S ) (E )I =6 ;. part 2 Proposition 4.8, fiS (I )
database state legal E B =6 ;.
(2) \)" Let (S ) 6j=f (E ) (E 0 ). (E ) u:(E 0 ) finitely consistent (S ).
Lemma 4.7 finite relation-descriptive model (S ) 2 ((E ))I
62 ((E 0 ))I , 2 . part 2 Proposition 4.8, fiS (I ) database state legal
2 E B 62 E 0B . Therefore E inherit E 0.
\(" Assume E inherit E 0. database state B legal
instance e 2 E B e 62 E 0B . part 1 Proposition 4.8,
ffS (B) finite model (S ) e 2 ((E ))ffS (B) e 62 ((E 0 ))ffS (B) . Therefore
(S ) 6j=f (E ) (E 0 ).
1. E satisfiable

Theorem 4.9 allows us effectively exploit reasoning methods developed aluni order reason ER schemas. complexity resulting method
reasoning ER schemata exponential. Observe however, known algorithms
reasoning ER schemata also exponential (Calvanese & Lenzerini, 1994b),
precise computational complexity problem still open.
Moreover, exploiting correspondence aluni, becomes possible add
ER model (and general semantic data models) several features modeling
primitives currently missing, considered important, fully
take account reasoning schemata. additional features include
example possibility specify use arbitrary boolean combinations entities,
refine properties entities along ISA hierarchies.
5. Object-Oriented Data Models

Object-oriented data models proposed goal devising database formalisms could integrated object-oriented programming systems (Kim, 1990).
subject active area research database field, based
following features:
rely notion object identifier extensional level (as opposed
traditional data models value-oriented) notion class
intensional level.
221

fiCalvanese, Lenzerini, & Nardi

structure classes specified means typing inheritance.

previous section, present common basis object-oriented data models
class-based formalisms introducing language specifying object-oriented
schemata show schemata correctly represented aluni knowledge
bases. analysis, concentrate attention structural aspects objectoriented data models. One characteristics object-oriented approach provide
mechanisms specifying also dynamic properties classes objects, typically
definition methods associated classes. aspects outside
scope investigations. Nevertheless, argue general techniques schema level
reasoning, particular, type consistency type inference, profitably exploited
restricted forms reasoning methods (Abiteboul, Kanellakis, Ramaswamy, & Waller,
1992).
5.1 Syntax Object-Oriented Model

define simple object-oriented language style popular models
featuring complex objects object identity. Although refer specific
formalism, model inspired ones presented Abiteboul Kanellakis (1989),
Hull King (1987).
Definition 5.1 object-oriented schema tuple = (CS ; ; DS ), where:
CS finite set class names, denoted letter C .
finite set attribute names, denoted letter A.
DS finite set class declarations form
Class C is-a C1 ; : : : ; Ck type-is T;
denotes type expression built according following syntax:


! Cj

Union T1 ; : : : ; Tk End j
Set-of j
Record A1: T1 ; : : : ; Ak : Tk End:
DS contains exactly one declaration class C 2 CS .
Figure 7 shows fragment object-oriented schema corresponding
KEE knowledge base Figure 2.
class declaration imposes constraints instances class refers to.
is-a part class declaration allows one specify inclusion sets instances
involved classes, type-is part specifies type expression structure
assigned objects instances class.
Example 5.2

222

fiUnifying Class-Based Representation Formalisms
Class Teacher type-is
Union Professor, GradStudent
End
Class GradStudent is-a Student type-is
Record
degree: String
End

Class Course type-is
Record
enrolls: Set-of Student,
taughtby: Teacher
End

Figure 7: object-oriented schema
5.2 Semantics Object-Oriented Model

meaning object-oriented schema given specifying characteristics
instance schema. definition instance makes use notions object
identifier value.
Let us first characterize set values constructed set symbols,
called object identifiers. Given finite set symbols denoting real world objects, set
VO values inductively defined follows:
VO .
v1 ; : : : ; vk 2 VO fjv1 ; : : : ; vk jg 2 VO .
v1 ; : : : ; vk 2 VO [ A1 : v1 ; : : : ; Ak : vk ] 2 VO .
Nothing else VO .
database instance J schema = (CS ; ; DS ) constituted
finite set OJ object identifiers;
mapping J assigning class CS subset OJ ;
mapping J assigning value VOJ object OJ .
Although set VOJ values constructed set OJ object identifiers
infinite, database instance one needs consider finite subset VOJ .
Definition 5.3 Given object-oriented schema instance J , set VJ
active values respect J constituted by:
set OJ object identifiers.
set values assigned J elements OJ , including values
explicitly associated object identifiers, used form values.
interpretation type expressions J defined interpretation function J assigns type expression subset VOJ following conditions satisfied:
C J = J (C )
223

fiCalvanese, Lenzerini, & Nardi

(Union T1 ; : : : ; Tk End)J = T1J [ [ TkJ
(Set-of )J = ffjv1 ; : : : ; vk jg j k 0; vi 2 J ; 2 f1; : : : ; kgg
(Record A1 : T1 ; : : : ; Ak : Tk End)J = f[ A1 : v1 ; : : : ; Ah : vh] j h k;
vi 2 TiJ ; 2 f1; : : : ; kg;
vj 2 VOJ ; j 2 fk + 1; : : : ; hgg:
Notice instances type record may components specified
type class. Thus using open semantics records, typical
object-oriented data models (Abiteboul & Kanellakis, 1989).
order characterize object-oriented data models consider instances
admissible schema.
Definition 5.4 Let = (CS ; ; DS ) object-oriented schema. database instance
J said legal (with respect ) declaration
Class C is-a C1 ; : : : ; Cn type-is
DS , holds C J CiJ 2 f1; : : : ; ng, J (C J ) J .
Therefore, legal database instance, type expressions present
schema determine (finite) set active values must considered. construction
values limited depth type expressions.
5.3 Relationship Object-Oriented Schemata

aluni

establish relationship aluni object-oriented language presented
above. done providing mapping object-oriented schemata aluni
knowledge bases. Since interpretation domain aluni knowledge bases consists
atomic objects, whereas instance object-oriented schema assigned possibly
structured value (see definition VO ), need explicitly represent
notions underlie object-oriented language. particular, correspondence concepts classes, one must explicitly account type structure
class. accomplished introducing aluni concepts AbstractClass,
represent classes, RecType SetType represent corresponding types.
associations classes types induced class declarations, well
basic characteristics types, modeled means roles: (functional) role value
models association classes types, role member used specifying
type elements set. Moreover, concepts representing types assumed
mutually disjoint, disjoint concepts representing classes. constraints
expressed adequate inclusion assertions part knowledge base
going define.
first define function maps type expression ALUNI concept
expression follows:
Every class C mapped atomic concept (C ).
Every type expression Union T1; : : : ; Tk End mapped (T1 ) (Tk ).
224

fiUnifying Class-Based Representation Formalisms

Every type expression Set-of mapped SetType u 8member. (T ).
Every attribute mapped atomic role (A), every type expression

Record A1: T1 ; : : : ; Ak : Tk End mapped

(A1 ). (T1 ) u 9=1 (A1 ) u u
8 (Ak ). (Tk ) u 9=1 (Ak ):

RecType u 8

Using define aluni knowledge base corresponding object-oriented schema.
aluni knowledge base (S ) = (A; P ; ) corresponding objectoriented schema = (CS ; ; DS ) obtained follows:
Definition 5.5

= fAbstractClass; RecType; SetTypeg [ f (C ) j C 2 CS g.
P = fvalue; memberg [ f (A) j 2 g.
consists following assertions:
AbstractClass
RecType
SetType

_
_
_

9=1value
8value.?
8value.? u :RecType

class declaration
Class C is-a C1 ; : : : ; Cn type-is
DS , inclusion assertion
(C ) _ AbstractClass u (C1 ) u u (Cn) u 8value. (T ):
translation observe inverse roles necessary
formalization object-oriented data models. Indeed, possibility referring
inverse attribute generally ruled models. However, strongly limits
expressive power data model, pointed recent papers (see example
Albano, Ghelli, & Orsini, 1991; Cattell, 1994). Note also use number restrictions
limited value 1, corresponds existence constraints functionality,
whereas union used general form example KEE system.
illustrate translation fragment object-oriented
schema Figure 7. corresponding aluni knowledge base shown Figure 8.
Example 5.2 (cont.)

225

fiCalvanese, Lenzerini, & Nardi
K = (A P ),
= fAbstractClass RecType SetType String
;

;

;

P

;

;

;

Course; Teacher; Professor; Student; GradStudentg,
= fvalue; member; enrolls; taughtby; degreeg,

set assertions consists of:
Course

_

Teacher
GradStudent

_
_

AbstractClass
RecType
SetType

AbstractClass u
8value.(RecType u 9=1 enrolls u 9=1 taughtby u
8enrolls.(SetType u 8member.Student) u 8taughtby.Teacher)
AbstractClass u 8value.(GradStudent Professor)
AbstractClass u Student u
8value.(RecType u 8degree.String u 9=1 degree)

_ 9=1 value
_ 8value.?
_ 8value.? u :RecType

Figure 8: aluni knowledge base corresponding object-oriented schema Figure 7
discuss effectiveness translation . First observe
knowledge base (S ) resulting translation object-oriented schema
may admit models direct counterpart among legal database instances
. precisely, interpretation (S ) database instance
viewed directed labeled graph: case interpretation, nodes domain
individuals arcs labeled roles. case database instance,
nodes either object identifiers active values, arc either connects object
identifier associated value (in case labeled value), part
sub-structure representing set record value (in case labeled member
attribute, accordance type value). legal database instance
, value v represented sub-structure form finite tree v
root, set record values intermediate nodes, objects identifiers leaves. Clearly,
substructure contain cycles. Conversely, model (S ), may
cycles involving nodes instances SetType RecType
roles different value. call cycles bad. model containing bad cycles
cannot put directly correspondence legal database instance. Also, due
open semantics records one cannot adopt different translation bad cycles
model ruled out.
aluni

Example 5.6

Consider object-oriented schema , containing single class declaration

Class C type-is Record a1 : Record a2 : Record a3 : C End End End
226

fiUnifying Class-Based Representation Formalisms

o1
C

value

v1

RecType
a3

a1

a2

o2
C

v2

RecType
value

v3

a1

RecType

v4

a2

RecType

v5

RecType

a3

Figure 9: model containing cycles
translated
C _ AbstractClass u
8value.(RecType u 9=1a1 u 8a1.(RecType u 9=1a2 u 8a2.(RecType u 9=1a3 u 8a3.C ))):
Figure 9 shows model (S ) represented graph. clarity, named
instances C , hence AbstractClass, instances RecType
v. Observe two different types cycles graph. cycle involving individuals
o2 ; v3 ; v4 , v5 cause problems since contains arc labeled value,
part structure constituting complex value. fact, v3 represents
record value [ a1 :[[a2:[[a3: o2 ] ] ] . hand, due bad cycle involving v1
v2 , individual v1 represents (together o2 connected via a3 v1 ) record infinite
depth.
nevertheless establish correspondence finite models (S ) possibly
containing bad cycles legal instances object-oriented schema .
achieved unfolding bad cycles model (S ) infinite trees. Obviously,
unfolding cycle infinite tree, generates infinite number nodes,
would correspond infinite database state. However, restrict duplication
individuals represent set record values, thus instances SetType
RecType. instances AbstractClass, instead, duplicated process
unfolding, therefore number remains finite. Moreover, since set possible
active values associated object identifier bound depth schema,
fact block unfolding bad cycles finite tree depth equal depth
schema.
Let us first formally define depth object-oriented schema .
Definition 5.7 type expression define depth (T ) inductively follows:
8 0;
= C .
>
>
< max
= Union T1 ; : : : ; Tk End.
1ik (depth (Ti ));
depth (T ) =
0 );
>
1
+
depth
(

= Set-of 0.
>
:
1 + max1ik (depth (Ti )); = Record A1: T1 ; : : : ; Ak : Tk End.
depth object-oriented schema defined maximum depth (T ) type
expression .
227

fiCalvanese, Lenzerini, & Nardi

o1
C

value

a1

0

v1

RecType

a2

0

v2

RecType

a3

a3

C

RecType

1

v2

a2

RecType

2

v1

a1

RecType

:::

a3

value
o2

a1

1

v1

a1

v3

RecType

v4

RecType

a2

v5

RecType

a3

Figure 10: unfolded version model Figure 9
introduce notion unfolding aluni interpretation.
Definition 5.8 Let object-oriented schema, (S ) translation aluni
finite interpretation (S ). call unfolded version interpretation obtained
follows: individual v part bad cycle, unfold bad cycle
(infinite) tree v root, generating new individuals instances
RecType SetType. nonnegative integer m, call m-unfolded version ,
denoted Ijm, interpretation obtained truncating depth infinite tree
generated process unfolding.
Example 5.6 (cont.) Figure 10 shows unfolded version model Figure 9.
Notice bad cycle unfolded infinite tree, arcs labeled
a3 lead o2, instance AbstractClass duplicated.

correctness (S ) sanctioned following proposition.
Proposition 5.9 every object-oriented schema depth m, exist mappings:

1. ffS instances finite interpretations (S ) ffV active values
instances domain elements finite interpretations (S ) that:
legal instance J , ffS (J ) finite model (S ), type
expression v 2 VJ , v 2 J ffV (v) 2 ( (T ))ffS (J ) .

2. fiS finite interpretations (S ) instances fiV domain elements m-unfolded versions finite interpretations (S ) active
values instances , that: finite model (S ), fiS (I ) legal
instance , concept (T ), translation type expression
2 Ijm , 2 ( (T ))Ijm fiV (d) 2 fiS (I ) .

Proof.

follows:

(1) Given database instance J define interpretation ffS (J ) (S )
228

fiUnifying Class-Based Representation Formalisms

ffV function mapping every element VJ distinct element ffS (J ) .
Therefore ffS (J ) defined set elements ffV (v) v 2 VJ . Moreover

denote id, rec, set elements ffS (J ) corresponding object
identifiers, record set values, respectively.
interpretation atomic concepts defined follows:
( (C ))ffS (J ) = fffV (o) j 2 J (C )g;
every (C ) corresponding class name C
AbstractClassffS (J ) = id
RecTypeffS (J ) = rec
SetTypeffS (J ) = set
interpretation atomic roles defined follows:
( (A))ffS (J ) = f(d1 ; d2 ) j d1 2 rec ffV 1 (d1 ) = [ : : : ; A: ffV 1 (d2 ); : : :] g;
every (A) corresponding attribute name
ff
(
J
)

member
= f(d1 ; d2 ) j d1 2 set ffV 1(d1 ) = fj: : : ; ffV 1 (d2 ); : : :jgg
ff
(
J
)
value
= f(d1 ; d2 ) j (ffV 1 (d1 ); ffV 1 (d2 )) 2 J g

prove type v 2 VJ , v 2 J ffV (v) 2
( (T ))ffS (J ) . first part thesis follows definition ffS (J ).
proof induction structure type expression.
Base case: = C (i.e., class1 name). 2 C J ffV (o) 2 ( (C ))ffS (J ) ,
vice-versa 2 ( (C ))ffS (J ) ffV (d) 2 C J .
Inductive case: = Record A1 : T1 ; : : : ; Ak : Tk End (T ) = RecType u
8 (A1 ). (T1 ) u 9=1 (A1 ) u u 8 (Ak ). (Tk ) u 9=1 (Ak ). assume v 2 TiJ
iff ffV (v) 2 ( (Ti ))ffS (J ), 2 f1; : : : ; kg, show v 2 J iff ffV (v) 2 ( (T ))ffJS (J ).
Suppose v 2 J , i.e., v = [ A1 : v1 ; : : : ; Ah: vh] h k vi 2 Ti
2 f1; : : : ; kg. induction hypothesis ffV (vi ) 2 ( (Ti ))ffS (J ) , 2 f1; : : : ; kg,
definition ffS , ffV (v) 2 RecTypeffS (J ) , (ffV (v); ffV (vi )) 2 ( (Ai ))ffS (J ) 2 f1; : : : ; kg,
roles (A) corresponding attribute names functional. Therefore, ffV (v) 2
( (T ))ffS (J ) .
Conversely, suppose = ffV (v) 2 ( (T ))ffS (J ) . Then, 2 f1; : : : ; kg
exactly one di 2 ffS (J ) (d; di ) 2 ( (Ai ))ffS (J ), moreover di 2 ( (T1i ))ffS (J ) .
definition ffS v = [ A1: v1 ; : : : ; AhJ: vh] , h k vi = ffV (di ),
2 f1; : : : ; kg. induction hypothesis vi 2 Ti , 2 f1; : : : ; kg, therefore v 2
(Record A1 : T1 ; : : : ; Ak : Tk End)J .
cases = Union T1; : : : ; Tk End = Set-of 0 treated analogously.
(2) Given finite model (S ) depth m, define legal database instance fiS (I )
follows:
fiV function mapping every element Ijm distinct element VfiS (I )
following conditions satisfied:
{ OfiS (I ) VfiS (I ) set elements fiV (d) 2 AbstractClassIjm .
229

fiCalvanese, Lenzerini, & Nardi

2 RecTypeIjm , (d;Idi ) 2 ( (Ai ))Ijm , 2 f1; : : : ; kg,

individual d0 2 jm attribute A0 (d; d0 ) 2 ( (A0 ))Ijm ,
fiV (d) = [ A1 : fiV (d1 ); : : : ; Ak : fiV (dk )]].
{ 2 SetTypeIjm , (d; di ) 2 memberIjm , 2 f1; : : : ; kg,
individual d0 2 Ijm (d; d0 ) 2 (member)Ijm , fiV (d) =
ffiV (d1 ); : : : ; fiV (dk )g.
every class name C , fiS (I ) (C ) = ffiV (d) j 2 ( (C ))Ijm g.
fiS (I ) = f(o; v) j fiV (d1 ) = o; fiV (d2 ) = v; (d1 ; d2 ) 2 valueIjm g.
first prove concept (T ), translation type expression
, 2 Ijm , 2 ( (T ))Ijm fiV (d) 2 fiS (I ) . proof
induction structure concept expression. inductive part
restrict attention case record types.
Base case: = C (i.e., (T ) atomic
concept).

2 ( (C ))Ijm fiV (d) 2
C fiS (I ) , vice-versa 2 C fiS (I ) fiV 1 (o) 2 ( (C ))Ijm .
Inductive case: (T ) = RecType u 8 (A1 ). (T1 ) u 9=1 (A1 ) u u 8 (Ak ). (ITk ) u
9=1 (Ak ) = Record A1: T1 ; : : : ; Ak : Tk End. assume 2 ( (Ti )) jm iff
fiV (d) 2 TifiS (I ) , 2 f1; : : : ; kg, show 2 ( (T ))Ijm iff fiV (d) 2 fiS (I ) .
Suppose 2 ( (T ))Ijm . 2I RecTypeIjm eachI 2 f1; : : : ; kg
individual di di 2 ( (Ti )) jm (d; di ) 2 ( (Ai )) jm . construction
fiV (d) = [ A1 : v1 ; : : : ; Ah : vh ] h k. Moreover, induction hypothesis fiV (di ) 2
TifiS (I ) therefore fiV (d) 2 fiS (I ) .
Conversely, suppose fiV (d) 2 fiS (I ) , i.e., fiV (d) = [ A1: v1 ; : : : ; Ah: vh ] h k
vi 2 TifiS (I ) 2 f1; : : : ; kg. induction hypothesis di = fiV 1(vi ) 2 ( (Ti ))Ijm ,
2 f1; : : : ; kg, definition fiV , 2 RecTypeIjm (d; di ) 2 ( (Ai ))Ijm ,
2 f1; : : : ; kg. Since roles (A) corresponding attribute names functional,
2 ( (T ))Ijm .
remains show declaration
Class C is-a C1 ; : : : ; Cn type-is
{

DS , (a) C fiS (I ) CifiS (I ) 2 f1; : : : ; ng, (b) fiS (I )(C fiS (I ) ) fiS (I ) .
(a) follows fact (S ) contains assertion (C ) _ (C1 ) u u (Cn )
definition fiS (I ) .
(b) follows shown fact Ijm still satisfies
assertion (C ) _ AbstractClass u 8value. (T ). fact, 2 ( (C ))I let d0
unique individual (d;I d0 ) 2 valueI . Since model (S ), d0 2 ( (T ))I .
argue also d0 2 ( (T )) jm . d0 part bad cycle ,
Ijm coincide sub-structure rooted d0 formed individuals reached via
member roles corresponding attributes, done. Otherwise, Ijm
sub-structure expanded finite tree. Since construction depth tree
least depth (T ), connections individuals preserved Ijm,
follows d0 2 ( (T ))Ijm .
230

fiUnifying Class-Based Representation Formalisms

basic reasoning services considered object-oriented databases subtyping
(check whether type denotes subset another type every legal instance) type
consistency (check whether type consistent legal instance). Based Proposition 5.9, show forms reasoning fully captured finite concept
consistency finite concept subsumption aluni knowledge bases.
object-oriented schema, T; 0 two type expressions ,
translation . following holds:

Theorem 5.10 Let

(S )



(S ) 6j=f (T ) ?.
subtype 0 (S ) j=f (T ) (T 0 ).

1. consistent
2.

proof analogous proof Theorem 4.9, makes use Proposition 5.9 instead Proposition 4.8.
Again, correspondence aluni established Theorem 5.10 allows us make
use reasoning techniques developed aluni reason object-oriented schemas.
Observe reasoning object-oriented models already PSPACE-hard (Bergamaschi
& Nebel, 1994) thus known algorithms exponential. However, resorting
aluni, becomes possible take account reasoning also various extensions
object-oriented formalism. extensions useful conceptual modeling
already proposed literature (Cattell & Barry, 1997). First all,
considerations developed ER model regard use arbitrary boolean
constructs classes applied also object-oriented setting, provides
disjunction admit form negation. Additional features added
object oriented models inverses attributes, cardinality constraints set-valued
attributes, general forms restrictions values attributes.
Proof.

6. Related Work

section brie discuss recent results correspondence class-based
formalisms techniques reasoning aluni class-based representation
formalisms.
6.1 Relationships among Class-Based Formalisms

past several attempts establish relationships among class-based
formalisms. Blasius, Hedstuck, Rollinger (1990), Lenzerini, Nardi, Simi (1991)
carry comparative analysis class-based languages attempt provide unified
view. analysis makes clear several diculties arise identifying common
framework formalisms developed different areas. recent papers address
problem. example, analysis relationships frame-based languages
types programming languages carried Borgida (1992), Bergamaschi
Sartori (1992), Piza, Schewe, Schmidt (1992) use frame-based languages enrich
deductive capabilities semantic object-oriented data models.
231

fiCalvanese, Lenzerini, & Nardi

Artale, Cesarini, Soda (1996) study reasoning object-oriented data models
presenting translation DLs style one discussed Section 5. However,
proposed translation applicable case shema contains recursive
class declarations. limitation present work Bergamaschi Nebel
(1994), formalism derived DLs used model complex objects
algorithm computing subsumption classes provided.
recent survey application DLs problem data management
presented Borgida (1995) . application task data modeling reasoning
techniques derived correspondences presented Sections 4 5 discussed
detail Calvanese, Lenzerini, Nardi (1998).
Recently, also proposals integrate object-oriented logic
programming paradigms (Kifer & Wu, 1993; Kifer, Lausen, & Wu, 1995). proposals
however directly related present work, since aim providing mechanisms
computing structured objects, rather means reasoning conceptual
(object-oriented) representation domain interest.
6.2 Reasoning

aluni

Class-Based Representation Formalisms

equipped techniques reason respect unrestricted
respect finite models. brie sketch main ideas underlying reasoning
contexts. detailed account reasoning techniques carried Calvanese
(1996c).
aluni

6.2.1 Unrestricted Model Reasoning

remind reasoning knowledge base respect unrestricted models amounts
check either concept consistency, i.e., determine whether knowledge base admits
(possibly infinite) model given concept nonempty extension, concept
subsumption, i.e., determine whether extension one concept contained extension another concept every model (including infinite ones) knowledge
base.
method reason aluni respect unrestricted models exploits well known
correspondence DLs Propositional Dynamic Logics (PDLs) (Kozen & Tiuryn,
1990), class logics specifically designed reason programs.
correspondence, first pointed Schild (1991), relies substantial
similarity interpretative structures formalisms, allows one exploit
reasoning techniques developed PDLs reason corresponding DLs. particular,
since ALUNI , description language aluni, includes construct inverse roles,
correspondence one resort converse-PDL, variant PDL includes
converse programs (Kozen & Tiuryn, 1990). However, presence number
restrictions ALUNI direct correspondence PDLs, cannot rely
traditional techniques reasoning PDLs. Recently, encoding techniques
developed, allow one eliminate number restrictions knowledge base
preserving concept consistency concept subsumption (De Giacomo & Lenzerini, 1994a).
encoding applicable knowledge bases formulated expressive variants DLs,
particular used reduce unrestricted model reasoning aluni knowledge
232

fiUnifying Class-Based Representation Formalisms

bases (both concept consistency concept subsumption) deciding satisfiability
formula converse-PDL. Reasoning converse-PDL decidable EXPTIME (Kozen &
Tiuryn, 1990), since encoding polynomial (De Giacomo & Lenzerini, 1994a)
obtain EXPTIME decision procedure unrestricted concept consistency concept
subsumption aluni knowledge bases. simplified form encoding,
applied decide unrestricted concept consistency aluni also presented
Calvanese et al. (1994).
6.2.2 Finite Model Reasoning

remind reasoning knowledge base respect finite models amounts
check either finite concept consistency finite concept subsumption,
finite models knowledge base must considered.
finite model reasoning, techniques based reduction reasoning PDLs
applicable. Indeed, PDL formula corresponding aluni knowledge base
contains constructs converse programs (corresponding inverse roles)
functionality direct inverse programs, thus formula variant PDL
finite model property (Vardi, 1985). However, encoding
functionality, one obtains converse-PDL formula, since converse-PDL finite
model property (Fischer & Ladner, 1979), formula satisfiable
finitely satisfiable. shows encoding number restrictions (and particular
encoding functionality), preserving unrestricted satisfiability preserve
finite satisfiability (De Giacomo & Lenzerini, 1994a).
finite model reasoning aluni one adopt different technique, based
idea separating reasoning process two distinct phases (see Calvanese, 1996c,
full details). first phase deals constructs except number restrictions,
builds \expanded knowledge base" constructs embedded implicitly
concepts roles. second phase assertions involving number restrictions
used derive expanded knowledge base system linear inequalities.
system defined way solutions certain type (acceptable solutions)
directly related finite models original knowledge base. particular,
acceptable solution one directly deduce cardinalities extensions concepts
roles possible finite model. proposed method allows one establish aluni
EXPTIME decidability finite concept consistency special cases finite concept
subsumption. resorting complicated encoding one obtain 2EXPTIME
decision procedure finite concept subsumption aluni general (Calvanese, 1996a,
1996c).
Reasoning respect finite models also investigated context dependency theory databases. shown Casanova, Fagin, Papadimitriou (1984)
relational model, functional inclusion dependencies interact, dependency
implication problem finite case differs one unrestricted case.
implication problem arbitrary functional inclusion dependencies undecidable
(Chandra & Vardi, 1985; Mitchell, 1983), functional unary inclusion dependencies
solvable polynomial time, finite unrestricted case (Cosmadakis
et al., 1990).
233

fiCalvanese, Lenzerini, & Nardi

Consistency respect finite models schemata expressed enriched EntityRelationship model cardinality constraints shown decidable polynomial
time Lenzerini Nobili (1990). Calvanese Lenzerini (1994b) extend decidability result include also ISA relationships, Calvanese Lenzerini (1994a) show
EXPTIME decidability reasoning expressive object-oriented model. algorithm
computing refinement ordering types (the analogue concept hierarchy)
framework O2 object oriented model discussed Lecluse Richard (1989).
Reasoning strict sublanguage aluni obtained omitting inverse roles
number restrictions already EXPTIME-hard (Calvanese, 1996b). Therefore, known
algorithms deciding unrestricted concept consistency subsumption finite concept
consistency essentially optimal.
7. Conclusions

presented unified framework representing information class structures
reasoning them. pursued goal looking various class-based
formalisms proposed different fields computer science, namely frame based systems
used knowledge representation, semantic object-oriented data models used
databases, rephrasing framework description logics. resulting description logic, called aluni includes combination constructs addressed
before, although constructs previously considered separately.
major achievement paper demonstration class-based formalisms
given precise characterization means powerful fragment first-order logic,
thus regarded essential core class-based representation formalisms
belonging three families mentioned above. several consequences.
First all, formalisms considered paper enriched constructs
originating formalisms treated general framework. sense,
work reported provides common powerful representation formalism,
may also contribute significant developments languages belonging three
families. example, usage inverse roles concept languages greatly enhances
expressivity roles, combination ISA, number restrictions, union enriches
reasoning capabilities available semantic data models.
Secondly, comparison class-based formalisms fields knowledge representation conceptual data modeling makes feasible address development
reasoning tools support conceptual modeling (Calvanese et al., 1998). fact, reasoning capabilities become especially important complex scenarios arising
heterogenous database applications Data Warehousing. line work among
motivations developing systems based expressive description logics (Horrocks,
1998; Horrocks & Patel-Schneider, 1999), lead extending language
description logics support Information Integration and, specifically, conceptual
modeling Data Warehouses (Calvanese, De Giacomo, Lenzerini, Nardi, & Rosati, 1998).
234

fiUnifying Class-Based Representation Formalisms
References

Abiteboul, S., Kanellakis, P., Ramaswamy, S., & Waller, E. (1992). Method schemas. Tech.
rep. CS-92-33, Brown University. earlier version appeared
.
Abiteboul, S., & Kanellakis, P. (1989). Object identity query language primitive.
Proceedings ACM SIGMOD International Conference Management Data,
pp. 159{173.
Abrial, J. R. (1974). Data semantics. Klimbie, J. W., & Koffeman, K. L. (Eds.), Data
Base Management, pp. 1{59. North-Holland Publ. Co., Amsterdam.
Albano, A., Ghelli, G., & Orsini, R. (1991). relationship mechanism strongly typed
Object-Oriented database programming languages. Proceedings Seventeenth International Conference Large Data Bases (VLDB'91), pp. 565{575
Barcelona.
Artale, A., Cesarini, F., & Soda, G. (1996). Describing database objects concept
language environment. IEEE Transactions Knowledge Data Engineering, 8 (2),
345{351.
Atzeni, P., & Parker Jr., D. S. (1986). Formal properties net-based knowledge representation schemes. Proceedings Second IEEE International Conference Data
Engineering (ICDE'86), pp. 700{706 Los Angeles.
Baader, F. (1991). Augmenting concept languages transitive closure roles: alternative terminological cycles. Proceedings Twelfth International Joint
Conference Artificial Intelligence (IJCAI'91) Sydney, Australia.
Baader, F. (1996). Using automata theory characterizing semantics terminological
cycles. Annals Mathematics Artificial Intelligence, 18, 175{219.
Batini, C., Ceri, S., & Navathe, S. B. (1992). Conceptual Database Design, EntityRelationship Approach. Benjamin Cummings Publ. Co., Menlo Park, California.
Bergamaschi, S., & Nebel, B. (1994). Acquisition validation complex object database
schemata supporting multiple inheritance. Applied Intelligence, 4 (2), 185{203.
Bergamaschi, S., & Sartori, C. (1992). taxonomic reasoning conceptual design. ACM
Transactions Database Systems, 17 (3), 385{422.
Blasius, K. H., Hedstuck, U., & Rollinger, C.-R. (Eds.). (1990). Sorts Types Artificial
Intelligence, Vol. 418 Lecture Notes Artificial Intelligence. Springer-Verlag.
Borgida, A. (1992). type systems knowledge representation: Natural semantics
specifications description logics. Journal Intelligent Cooperative Information
Systems, 1 (1), 93{126.
Borgida, A. (1995). Description logics data management. IEEE Transactions Knowledge Data Engineering, 7 (5), 671{682.
Proc. 9th

Symp. Principles Database Systems PODS-90

235

fiCalvanese, Lenzerini, & Nardi

Borgida, A. (1996). relative expressiveness description logics predicate logics.
Artificial Intelligence, 82, 353{367.
Borgida, A., & Weddell, G. E. (1997). Adding functional dependencies description logics.
Proceedings Fifth International Conference Deductive Object-Oriented
Databases (DOOD'97).
Brachman, R. J., & Levesque, H. J. (1984). tractability subsumption frame-based
description languages. Proceedings Fourth National Conference Artificial
Intelligence (AAAI'84), pp. 34{37.
Brachman, R. J., & Levesque, H. J. (Eds.). (1985). Readings Knowledge Representation.
Morgan Kaufmann, Los Altos.
Brachman, R. J., McGuinness, D. L., Patel-Schneider, P. F., Alperin Resnick, L., & Borgida,
A. (1991). Living CLASSIC: use KL-ONE-like language.
Sowa, J. F. (Ed.), Principles Semantic Networks, pp. 401{456. Morgan Kaufmann,
Los Altos.
Bresciani, P., Franconi, E., & Tessaris, S. (1995). Implementing testing expressive
description logics: Preliminary report. Borgida, A., Lenzerini, M., Nardi, D., &
Nebel, B. (Eds.), Working Notes 1995 Description Logics Workshop, Technical
Report, RAP 07.95, Dipartimento di Informatica e Sistemistica, Universita di Roma
\La Sapienza", pp. 131{139 Rome (Italy).
Buchheit, M., Donini, F. M., Nutt, W., & Schaerf, A. (1998). refined architecture
terminological systems: Terminology = schema + views. Artificial Intelligence, 99 (2),
209{260.
Buchheit, M., Donini, F. M., & Schaerf, A. (1993). Decidable reasoning terminological
knowledge representation systems. Journal Artificial Intelligence Research, 1, 109{
138.
Calvanese, D. (1996a). Finite model reasoning description logics. Aiello, L. C., Doyle,
J., & Shapiro, S. C. (Eds.), Proceedings Fifth International Conference
Principles Knowledge Representation Reasoning (KR'96), pp. 292{303. Morgan
Kaufmann, Los Altos.
Calvanese, D. (1996b). Reasoning inclusion axioms description logics: Algorithms
complexity. Wahlster, W. (Ed.), Proceedings Twelfth European Conference Artificial Intelligence (ECAI'96), pp. 303{307. John Wiley & Sons.
Calvanese, D. (1996c). Unrestricted Finite Model Reasoning ClassBased Representation Formalisms.
Ph.D. thesis, Dipartimento di Informatica e Sistemistica, Universita di Roma \La Sapienza". Available
http://www.dis.uniroma1.it/pub/calvanes/thesis.ps.gz.
Calvanese, D., De Giacomo, G., Lenzerini, M., Nardi, D., & Rosati, R. (1998). Description
logic framework information integration. Proceedings Sixth International
236

fiUnifying Class-Based Representation Formalisms
Conference Principles Knowledge Representation Reasoning (KR'98),

pp.
2{13.
Calvanese, D., & Lenzerini, M. (1994a). Making object-oriented schemas expressive.
Proceedings Thirteenth ACM SIGACT SIGMOD SIGART Symposium
Principles Database Systems (PODS'94), pp. 243{254 Minneapolis. ACM Press
Addison Wesley.
Calvanese, D., & Lenzerini, M. (1994b). interaction ISA cardinality
constraints. Proceedings Tenth IEEE International Conference Data
Engineering (ICDE'94), pp. 204{213 Houston (Texas). IEEE Computer Society Press.
Calvanese, D., Lenzerini, M., & Nardi, D. (1994). unified framework class based representation formalisms. Doyle, J., Sandewall, E., & Torasso, P. (Eds.), Proceedings
Fourth International Conference Principles Knowledge Representation
Reasoning (KR'94), pp. 109{120 Bonn. Morgan Kaufmann, Los Altos.
Calvanese, D., Lenzerini, M., & Nardi, D. (1998). Description logics conceptual data
modeling. Chomicki, J., & Saake, G. (Eds.), Logics Databases Information
Systems, pp. 229{264. Kluwer Academic Publisher.
Casanova, M. A., Fagin, R., & Papadimitriou, C. H. (1984). Inclusion dependencies
interaction functional dependencies. Journal Computer System
Sciences, 28 (1), 29{59.
Cattell, R. G. G. (Ed.). (1994). Object Database Standard: ODMG-93. Morgan Kaufmann, Los Altos. Release 1.1.
Cattell, R. G. G., & Barry, D. K. (Eds.). (1997). Object Database Standard: ODMG
2.0. Morgan Kaufmann, Los Altos.
Chandra, A. K., & Vardi, M. Y. (1985). implication problem functional inclusion
dependencies undecidable. SIAM Journal Computing, 14 (3), 671{677.
Chen, P. P. (1976). Entity-Relationship model: Toward unified view data. ACM
Transactions Database Systems, 1 (1), 9{36.
Cosmadakis, S. S., & Kanellakis, P. C. (1986). Functional inclusion dependencies -
graph theoretical approach. Kanellakis, P. C., & Preparata, F. P. (Eds.), Advances
Computing Research, Vol. 3, pp. 163{184. JAI Press.
Cosmadakis, S. S., Kanellakis, P. C., & Vardi, M. (1990). Polynomial-time implication
problems unary inclusion dependencies. Journal ACM, 37 (1), 15{46.
De Giacomo, G., & Lenzerini, M. (1994a). Boosting correspondence description logics propositional dynamic logics. Proceedings Twelfth National
Conference Artificial Intelligence (AAAI'94), pp. 205{212. AAAI Press/The MIT
Press.
237

fiCalvanese, Lenzerini, & Nardi

De Giacomo, G., & Lenzerini, M. (1994b). Concept language number restrictions
fixpoints, relationship -calculus. Proceedings Eleventh European
Conference Artificial Intelligence (ECAI'94), pp. 411{415.
Di Battista, G., & Lenzerini, M. (1993). Deductive entity-relationship modeling. IEEE
Transactions Knowledge Data Engineering, 5 (3), 439{450.
Donini, F. M., Lenzerini, M., Nardi, D., & Nutt, W. (1997). complexity concept
languages. Information Computation, 134, 1{58.
Donini, F. M., Lenzerini, M., Nardi, D., Nutt, W., & Schaerf, A. (1994). Queries, rules
definitions. Foundations Knowledge Representation Reasoning. SpringerVerlag.
Donini, F. M., Lenzerini, M., Nardi, D., & Schaerf, A. (1996). Reasoning description
logics. Brewka, G. (Ed.), Principles Knowledge Representation, Studies Logic,
Language Information, pp. 193{238. CSLI Publications.
Donini, F. M., Nardi, D., & Rosati, R. (1995). Non-first-order features concept languages. Gori, M., & Soda, G. (Eds.), Proceedings Fourth Conference
Italian Association Artificial Intelligence (AI*IA'95), Vol. 992 Lecture Notes
Artificial Intelligence, pp. 91{102. Springer-Verlag.
Ferg, S. (1991). Cardinality concepts entity-relationship modeling. Proceedings
Tenth International Conference Entity-Relationship Approach (ER'91), pp.
1{30.
Fikes, R., & Kehler, T. (1985). role frame-based representation reasoning. Communications ACM, 28 (9), 904{920.
Fischer, M. J., & Ladner, R. E. (1979). Propositional dynamic logic regular programs.
Journal Computer System Sciences, 18, 194{211.
Grant, J., & Minker, J. (1984). Numerical dependencies. Gallaire, H., Minker, J., &
Nicolas, J.-M. (Eds.), Advances Database Theory II. Plenum Publ. Co., New York.
Hayes, P. J. (1979). logic frames. Metzing, D. (Ed.), Frame Conceptions Text
Understanding, pp. 46{61. Walter de Gruyter Co. Republished (Brachman &
Levesque, 1985).
Horrocks, I. (1998). Using expressive description logic: FaCT fiction?. Proceedings
Sixth International Conference Principles Knowledge Representation
Reasoning (KR'98), pp. 636{647.
Horrocks, I., & Patel-Schneider, P. F. (1999). Optimizing description logic subsumption.
Journal Logic Computation, 9 (3), 267{293.
Hull, R. B., & King, R. (1987). Semantic database modelling: Survey, applications
research issues. ACM Computing Surveys, 19 (3), 201{260.
238

fiUnifying Class-Based Representation Formalisms

Karp, P. D. (1992). design space knowledge representation systems. Tech. rep. SRI
AI Technical Note 520, SRI International, Menlo Park, CA.
Karp, P. D., Myers, K. L., & Gruber, T. (1995). generic frame protocol. Proceedings
Fourteenth International Joint Conference Artificial Intelligence (IJCAI'95),
Vol. A, pp. 768{774 Montreal, Canada.
Kifer, M., Lausen, G., & Wu, J. (1995). Logical foundations Object-Oriented framebased languages. Journal ACM, 42 (4), 741{843.
Kifer, M., & Wu, J. (1993). logic programming complex objects. Journal
Computer System Sciences, 47, 77{120.
Kim, W. (1990). Introduction Object-Oriented Databases. MIT Press.
Kim, W., & Lochovsky, F. H. (Eds.). (1989). Object-Oriented Concepts, Databases,
Applications. ACM Press Addison Wesley, New York.
Kozen, D., & Tiuryn, J. (1990). Logics programs. van Leeuwen, J. (Ed.), Handbook
Theoretical Computer Science { Formal Models Semantics, pp. 789{840. Elsevier
Science Publishers (North-Holland), Amsterdam.
Lecluse, C., & Richard, P. (1989). Modeling complex structures object-oriented databases.
Proceedings Eighth ACM SIGACT SIGMOD SIGART Symposium Principles Database Systems (PODS'89), pp. 362{369.
Lehmann, F. (Ed.). (1992). Semantic Networks Artificial Intelligence. Pergamon Press,
Oxford.
Lenzerini, M., Nardi, D., & Simi, M. (Eds.). (1991). Inheritance Hierarchies Knowledge
Representation Programming Languages. John Wiley & Sons, Chichester.
Lenzerini, M., & Nobili, P. (1990). satisfiability dependency constraints entityrelationship schemata. Information Systems, 15 (4), 453{461.
Mitchell, J. C. (1983). implication problem functional inclusion dependencies.
Information Control, 56, 154{173.
Motschnig-Pitrik, R., & Mylopoulous, J. (1992). Classes instances. Journal Intelligent Cooperative Information Systems, 1 (1).
Nebel, B. (1991). Terminological cycles: Semantics computational properties. Sowa,
J. F. (Ed.), Principles Semantic Networks, pp. 331{361. Morgan Kaufmann, Los
Altos.
Piza, B., Schewe, K.-D., & Schmidt, J. W. (1992). Term subsumption type constructors. Yesha, Y. (Ed.), Proceedings International Conference Information
Knowledge Management (CIKM'92), pp. 449{456 Baltimore.
239

fiCalvanese, Lenzerini, & Nardi

Schild, K. (1991). correspondence theory terminological logics: Preliminary report.
Proceedings Twelfth International Joint Conference Artificial Intelligence
(IJCAI'91), pp. 466{471 Sydney, Australia.
Schild, K. (1994). Terminological cycles propositional -calculus. Doyle, J.,
Sandewall, E., & Torasso, P. (Eds.), Proceedings Fourth International Conference Principles Knowledge Representation Reasoning (KR'94), pp.
509{520 Bonn. Morgan Kaufmann, Los Altos.
Schmidt-Schau, M., & Smolka, G. (1991). Attributive concept descriptions complements. Artificial Intelligence, 48 (1), 1{26.
Sowa, J. F. (Ed.). (1991). Principles Semantic Networks. Morgan Kaufmann, Los Altos.
Teorey, T. J. (1989). Database Modeling Design: Entity-Relationship Approach.
Morgan Kaufmann, Los Altos.
Thalheim, B. (1992). Fundamentals cardinality constraints. Pernoul, G., & Tjoa,
A. M. (Eds.), Proceedings Eleventh International Conference EntityRelationship Approach (ER'92), pp. 7{23. Springer-Verlag.
Thalheim, B. (1993). Fundamentals Entity Relationship Model. Springer-Verlag.
Vardi, M. Y. (1985). taming converse: Reasoning two-way computations.
Parikh, R. (Ed.), Proc. 4th Workshop Logics Programs, Vol. 193
Lecture Notes Computer Science, pp. 413{424. Springer-Verlag.
Woods, W. A., & Schmolze, J. G. (1992). KL-ONE family. Lehmann, F. W. (Ed.),
Semantic Networks Artificial Intelligence, pp. 133{178. Pergamon Press. Published
special issue Computers & Mathematics Applications, Volume 23, Number
2{9.
Ye, X., Parent, C., & Spaccapietra, S. (1994). Cardinality consistency derived objects
DOOD systems. Loucopoulos, P. (Ed.), Proceedings Thirteenth International
Conference Entity-Relationship Approach (ER'94), Vol. 881 Lecture Notes
Computer Science, pp. 278{295 Manchester (UK). Springer-Verlag.

240

fiJournal Artificial Intelligence Research 11 (1999) 391-427

Submitted 1/99; published 11/99

Markov Localization Mobile Robots
Dynamic Environments
dfox@cs.cmu.edu

Dieter Fox
Computer Science Department Robotics Institute
Carnegie Mellon University
Pittsburgh, PA 15213-3891

burgard@informatik.uni-freiburg.de

Wolfram Burgard
Department Computer Science
University Freiburg
D-79110 Freiburg, Germany

thrun@cs.cmu.edu

Sebastian Thrun
Computer Science Department Robotics Institute
Carnegie Mellon University
Pittsburgh, PA 15213-3891

Abstract

Localization, estimation robot's location sensor data, fundamental problem mobile robotics. papers presents version Markov localization
provides accurate position estimates tailored towards dynamic environments. key idea Markov localization maintain probability density
space locations robot environment. approach represents space
metrically, using fine-grained grid approximate densities. able globally localize
robot scratch recover localization failures. robust approximate models environment (such occupancy grid maps) noisy sensors (such
ultrasound sensors). approach also includes filtering technique allows
mobile robot reliably estimate position even densely populated environments
crowds people block robot's sensors extended periods time. method
described implemented tested several real-world applications mobile
robots, including deployments two mobile robots interactive museum tour-guides.
1. Introduction

Robot localization recognized one fundamental problems mobile
robotics (Cox & Wilfong, 1990; Borenstein et al., 1996). aim localization
estimate postition robot environment, given map environment
sensor data. successful mobile robot systems date utilize localization, knowledge
robot's position essential broad range mobile robot tasks.
Localization|often referred position estimation position control|is currently
highly active field research, recent book Borenstein colleagues (1996) suggests.
localization techniques developed far distinguished according type
c 1999 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiFox, Burgard & Thrun

problem attack. Tracking local techniques aim compensating odometric errors
occurring robot navigation. require, however, initial location
robot (approximately) known typically cannot recover lose track
robot's position (within certain bounds). Another family approaches called global
techniques. designed estimate position robot even global
uncertainty. Techniques type solve so-called wake-up robot problem,
localize robot without prior knowledge position. furthermore
handle kidnapped robot problem, robot carried arbitrary location
it's operation1. Global localization techniques powerful local ones.
typically cope situations robot likely experience serious
positioning errors.
paper present metric variant Markov localization, technique globally
estimate position robot environment. Markov localization uses probabilistic
framework maintain position probability density whole set possible robot
poses. density arbitrary forms representing various kinds information
robot's position. example, robot start uniform distribution
representing completely uncertain position. furthermore contain
multiple modes case ambiguous situations. usual case, robot
highly certain position, consists unimodal distribution centered around
true position robot. Based probabilistic nature approach
representation, Markov localization globally estimate position robot,
deal ambiguous situations, re-localize robot case localization
failures. properties basic preconditions truly autonomous robots designed
operate long periods time.
method uses fine-grained metric discretization state space. approach several advantages previous ones, predominately used Gaussians
coarse-grained, topological representations approximating robot's belief. First, provides accurate position estimates, required many mobile robot tasks (e.g.,
tasks involving mobile manipulation). Second, incorporate raw sensory input
single beam ultrasound sensor. previous approaches Markov localization,
contrast, screen sensor data presence absence landmarks, prone
fail environment align well underlying assumptions (e.g.,
contain required landmarks).
importantly, however, previous Markov localization techniques assumed
environment static. Therefore, typically fail highly dynamic environments,
public places crowds people may cover robot's sensors extended periods
time. deal situations, method applies filtering technique that,
essence, updates position probability density using measurements
high likelihood produced known objects contained map. result,
permits accurate localization even densely crowded, non-static environments.
Markov localization approach implemented evaluated various environments, using different kinds robots sensor modalities. Among applications
deployments mobile robots Rhino Minerva (see Figure 1) interac1. Please note wake-up problem special case kidnapped robot problem
robot told carried away.
392

fiMarkov Localization Mobile Robots Dynamic Environments

(a)

(b)

Fig. 1. mobile robots Rhino (a) Minerva (b) acting interactive museum tour-guides.

tive museum tour-guide robots (Burgard et al., 1998a, 2000; Thrun et al., 1999)
Deutsches Museum Bonn National Museum American History Washington,
DC, respectively. Experiments described paper illustrate ability Markov
localization technique deal approximate models environment, occupancy grid maps noisy sensors ultrasound sensors, demonstrate
approach well-suited localize robots densely crowded environments,
museums full people.
paper organized follows. next section describes mathematical framework Markov localization. introduce metric version Markov localization
Section 3. section also presents probabilistic model proximity sensors filtering scheme deal highly dynamic environments. Thereafter, describe experimental
results illustrating different aspects approach. Related work discussed Section 5
followed concluding remarks.
2. Markov Localization

introduce major concepts, begin intuitive description Markov
localization, followed mathematical derivation algorithm. reader may
notice Markov localization special case probabilistic state estimation, applied
mobile robot localization (see also Russell & Norvig, 1995; Fox, 1998 Koenig &
Simmons, 1998).
clarity presentation, initially make restrictive assumption
environment static. assumption, called Markov assumption, commonly made
robotics literature. postulates robot's location state environment systematically affects sensor readings. Markov assumption violated
robots share environment people. below, Section 3.3,
side-step assumption present Markov localization algorithm works well even
highly dynamic environments, e.g., museums full people.
2.1 Basic Idea

Markov localization addresses problem state estimation sensor data. Markov
localization probabilistic algorithm: Instead maintaining single hypothesis
393

fiFox, Burgard & Thrun

Fig. 2. basic idea Markov localization: mobile robot global localization.

world robot might be, Markov localization maintains probability distribution
space hypotheses. probabilistic representation allows weigh
different hypotheses mathematically sound way.
delve mathematical detail, let us illustrate basic concepts
simple example. Consider environment depicted Figure 2. sake simplicity,
let us assume space robot positions one-dimensional, is, robot
move horizontally (it may rotate). suppose robot placed somewhere
environment, told location. Markov localization represents state
uncertainty uniform distribution positions, shown graph
first diagram Figure 2. let us assume robot queries sensors finds
next door. Markov localization modifies belief raising probability
places next doors, lowering anywhere else. illustrated second
diagram Figure 2. Notice resulting belief multi-modal, ecting fact
available information insucient global localization. Notice also places
next door still possess non-zero probability. sensor readings noisy,
single sight door typically insucient exclude possibility
next door.
let us assume robot moves meter forward. Markov localization incorporates
information shifting belief distribution accordingly, visualized third
diagram Figure 2. account inherent noise robot motion, inevitably
leads loss information, new belief smoother (and less certain) previous
one. Finally, let us assume robot senses second time, finds next
door. observation multiplied current (non-uniform) belief, leads
final belief shown last diagram Figure 2. point time,
probability centered around single location. robot quite certain
position.
394

fiMarkov Localization Mobile Robots Dynamic Environments
2.2 Basic Notation

make formal, let us denote position (or: location) mobile robot
three-dimensional variable l = hx; y; i, comprising x-y coordinates (in Cartesian
coordinate system) heading direction . Let lt denote robot's true location
time t, Lt denote corresponding random variable. Throughout paper,
use terms position location interchangeably.
Typically, robot know exact position. Instead, carries belief
might be. Let Bel(Lt ) denote robot's position belief time t. Bel(Lt )
probability distribution space positions. example, Bel(Lt = l)
probability (density) robot assigns possibility location time
l. belief updated response two different types events: arrival measurement robot's environment sensors (e.g., camera image, sonar scan),
arrival odometry reading (e.g., wheel revolution count). Let us denote environment sensor measurements odometry measurements a, corresponding
random variables A, respectively.
robot perceives stream measurements, sensor measurements odometry
readings a. Let
= fd0 ; d1 ; : : : ; dT g
(1)
denote stream measurements, dt (with 0 ) either sensor
measurement odometry reading. variable indexes data,
recently collected data item (one might think \time"). set d, comprises
available sensor data, referred data.
2.3 Recursive Localization

Markov localization estimates posterior distribution LT conditioned available
data,
P (LT = l j d) = P (LT = l j d0 ; : : : ; dT ):
(2)
deriving incremental update equations posterior, let us brie make explicit
key assumption underlying derivation, called Markov assumption. Markov
assumption, sometimes referred static world assumption, specifies one knows
robot's location lt , future measurements independent past ones (and vice versa):
P (dt+1 ; dt+2 ; : : : j Lt = l; d0 ; : : : ; dt ) = P (dt+1 ; dt+2 ; : : : j Lt = l) 8t
(3)
words, assume robot's location state environment,
knowing one needs know past predict future data. assumption
clearly inaccurate environment contains moving (and measurable) objects
robot itself. below, Section 3.3, extend basic paradigm
non-Markovian environments, effectively devising localization algorithm works well
broad range dynamic environments. now, however, adhere Markov
assumption, facilitate derivation basic algorithm.
395

fiFox, Burgard & Thrun

computing P (LT = l j d), distinguish two cases, depending whether
recent data item dT sensor measurement odometry reading.
Case 1: recent data item sensor measurement dT = sT .

P (LT = l j d) = P (LT = l j d0 ; : : : ; dT 1 ; sT ):
(4)
Bayes rule suggests term transformed
P (sT j d0 ; : : : ; dT 1 ; LT = l) P (LT = l j d0 ; : : : ; dT 1 )
;
(5)
P (s j ; : : : ; )




0

1

which, Markov assumption, simplified to:
P (sT j LT = l) P (LT = l j d0 ; : : : ; dT 1 )
:
(6)
P (sT j d0 ; : : : ; dT 1 )
also observe denominator replaced constant ffT , since
depend LT . Thus,
P (LT = l j d) = ffT P (sT j LT = l) P (LT = l j d0 ; : : : ; dT 1 ):
(7)
reader may notice incremental nature Equation (7): write
Bel(LT = l) = P (LT = l j d0 ; : : : ; dT );
(8)
denote robot's belief Equation (7) becomes
Bel(LT = l) = ffT P (sT j l) Bel(LT 1 = l):
(9)
equation replaced term P (sT j LT = l) P (sT j l) based assumption
independent time.
Case 2: recent data item odometry reading: dT = .
compute P (LT = l j d) using Theorem Total Probability:
Z
P (LT = l j d) =
P (LT = l j d; LT 1 = l0 ) P (LT 1 = l0 j d) dl0 :
(10)
Consider first term right-hand side. Markov assumption suggests
P (LT = l j d; LT 1 = l0 ) = P (LT = l j d0 ; : : : ; dT 1 ; ; LT 1 = l0 )
(11)
0
= P (LT = l j ; LT 1 = l )
(12)
second term right-hand side Equation (10) also simplified observing
carry information position LT 1:
P (LT 1 = l0 j d) = P (LT 1 = l0 j d0 ; : : : ; dT 1 ; )
(13)
0
= P (LT 1 = l j d0 ; : : : ; dT 1 )
(14)
396

fiMarkov Localization Mobile Robots Dynamic Environments

Substituting 12 14 back Equation (10) gives us desired result
P (LT

= l j d) =

Z

P (LT

= l j ; LT 1 = l0) P (LT 1 = l0 j d0 ; : : : ; dT 1) dl0 : (15)

Notice Equation (15) is, too, incremental form. definition belief
above,
Bel(LT

= l) =

Z

P (l j ; l0 ) Bel(LT

1

= l0) dl0:

(16)

Please note used P (l j ; l0 ) instead P (LT = l j ; LT 1 = l0 ) since assume
change time.
2.4 Markov Localization Algorithm

Update Equations (9) (16) form core Markov localization algorithm. full
algorithm shown Table 1. Following Basye et al. (1992) Russell & Norvig (1995),
denote P (l j a; l0 ) robot's motion model, since models motion effect
robot's position. conditional probability P (s j l) called perceptual model,
models outcome robot's sensors.
Markov localization algorithm P (L0 = l), initializes belief Bel(L0),
ects prior knowledge starting position robot. distribution
initialized arbitrarily, practice two cases prevail: position robot
relative map entirely unknown, P (L0 ) usually uniformly distributed. initial
position robot approximately known, P (L0 ) typically narrow Gaussian
distribution centered robot's position.
2.5 Implementations Markov Localization

reader may notice principle Markov localization leaves open
1. robot's belief Bel(L) represented
2. conditional probabilities P (l j a; l0 ) P (s j l) computed.
Accordingly, existing approaches Markov localization mainly differ representation
state space computation perceptual model. section
brie discuss different implementations Markov localization focusing two topics
(see Section 5 detailed discussion related work).
1. State Space Representations: common approach representation
robots belief Bel(L) based Kalman filtering (Kalman, 1960; Smith et al.,
1990) rests restrictive assumption position robot
modeled unimodal Gaussian distribution. Existing implementations (Leonard
& Durrant-Whyte, 1992; Schiele & Crowley, 1994; Gutmann & Schlegel, 1996; Arras & Vestli, 1998) proven robust accurate keeping track
robot's position. restrictive assumption Gaussian distribution
techniques lack ability represent situations position robot
397

fiFox, Burgard & Thrun



location l
Bel(L0 = l)

P (L0 = l)

/* initialize belief */
(17)

end

forever


new sensory input sT received
ffT
0
location l
/* apply perception model */
(LT = l)
Bel
P (sT j l) Bel(LT 1 = l)
(18)
(LT = l)
ffT
ffT + Bel
(19)
end


location l
Bel(LT = l)

ffT

/* normalize belief */
1 Bel
(LT = l)
(20)

end
end


odometry reading received
location l
Bel(LT

= l)

Z

/* apply motion model */

P (l j l0 ; ) Bel(LT

1

= l0 ) dl0

(21)

end
end
end forever

Tab. 1. Markov localization algorithm
maintains multiple, distinct beliefs (c.f. 2). result, localization approaches using
Kalman filters typically require starting position robot known
able re-localize robot case localization failures. Additionally,
Kalman filters rely sensor models generate estimates Gaussian uncertainty. assumption, unfortunately, met situations (see example
Dellaert et al. 1999).
398

fiMarkov Localization Mobile Robots Dynamic Environments

overcome limitations, different approaches used increasingly richer
schemes represent uncertainty robot's position, moving beyond Gaussian
density assumption inherent vanilla Kalman filter. Nourbakhsh et al. (1995),
Simmons & Koenig (1995), Kaelbling et al. (1996) use Markov localization
landmark-based corridor navigation state space organized according
coarse, topological structure environment generally four possible
orientations robot. approaches can, principle, solve problem
global localization. However, due coarse resolution state representation,
accuracy position estimates limited. Topological approaches typically give
rough sense robot is. Furthermore, techniques require
environment satisfies orthogonality assumption certain
landmarks abstract features extracted sensor data.
assumptions make dicult apply topological approaches unstructured
environments.
2.

addition different representations state space various
perception models developed different types sensors (see example
Moravec, 1988; Kortenkamp & Weymouth, 1994; Simmons & Koenig, 1995; Burgard
et al., 1996; Dellaert et al., 1999; Konolige, 1999). sensor models differ
way compute probability current measurement. Whereas
topological approaches (Kortenkamp & Weymouth, 1994; Simmons & Koenig,
1995; Kaelbling et al., 1996) first extract landmark information sensor scan,
approaches (Moravec, 1988; Burgard et al., 1996; Dellaert et al., 1999; Konolige,
1999) operate raw sensor measurements. techniques proximity sensors
described (Moravec, 1988; Burgard et al., 1996; Konolige, 1999) mainly differ
eciency model characteristics sensors map
environment.

Sensor Models:

order combine strengths previous representations, approach relies
fine less restrictive representation state space (Burgard et al., 1996, 1998b;
Fox, 1998). robot's belief approximated fine-grained, regularly spaced grid,
spatial resolution usually 10 40 cm angular resolution
usually 2 5 degrees. advantage approach compared Kalman-filter based
techniques ability represent multi-modal distributions, prerequisite global
localization scratch. contrast topological approaches Markov localization,
approach allows accurate position estimates much broader range environments,
including environments might even possess identifiable landmarks. Since
depend abstract features, incorporate raw sensor data robot's belief.
typically yields results order magnitude accurate. obvious
shortcoming grid-based representation, however, size state space
maintained. Section 3.4 addresses issue directly introducing techniques
make possible update extremely large grids real-time.
399

fiFox, Burgard & Thrun

(a)

(b)

Fig. 3. Typical \banana-shaped" distributions resulting different motion actions.
3. Metric Markov Localization Dynamic Environments

section describe metric variant Markov localization. includes
appropriate motion sensor models. also describe filtering technique
designed overcome assumption static world model generally made Markov
localization allows localize mobile robot even densely crowded environments.
describe fine-grained grid-based representation state space present
techniques eciently update even large state spaces.
3.1 Action Model

update belief robot moves, specify action model P (l j l0; ).
Based assumption normally distributed errors translation rotation,
use mixture two independent, zero-centered Gaussian distributions whose tails cut
(Burgard et al., 1996). variances distributions proportional length
measured motion.
Figure 3 illustrates resulting densities two example paths robot's belief
starts Dirac distribution. distributions three-dimensional (in hx; y; i-space)
Figure 3 shows 2D projections hx; yi-space.
3.2 Perception Model Proximity Sensors

mentioned above, likelihood P (s j l) sensor reading measured position l computed positions l update Markov localization
algorithm (see Table 1). Therefore, crucial on-line position estimation
quantity computed eciently. Moravec (1988) proposed method compute
generally non-Gaussian probability density function P (s j l) discrete set possible
distances measured ultrasound sensor location l. first implementation
approach (Burgard et al., 1996) used similar method, unfortunately turned
computationally expensive localization real-time.
overcome disadvantage, developed sensor-model allows compute
P (s j l) solely based distance ol closest obstacle map along direction
sensor. distance computed ray-tracing occupancy grid maps
400

fiMarkov Localization Mobile Robots Dynamic Environments

0.125

ol

0.1

Sonar
Laser
probability Pu (di )

probability Pm (di | l)

0.125

0.075

0.05

0.025

0

Sonar
Laser

0.1

0.075

0.05

0.025

100

200

300

measured distance di [cm]

400

0

500

100

200

(a)

300

measured distance di [cm]

400

500

(b)

Fig. 4. Probability measuring distance di (a) obstacle distance ol detected (b) due
unknown obstacles.

CAD-models environment. particular, consider discretization d1 ; : : : ; dn
possible distances measured proximity sensor. discretization, size
ranges = di+1 di i, dn corresponds maximal range
proximity sensor2. Let P (di j l) denote probability measuring distance di
robot location l. order derive probability first consider following two
cases (see also Hennig 1997 Fox 1998):
a.) Known obstacles: sensor detects obstacle resulting distribution
modeled Gaussian distribution mean distance obstacle. Let
Pm (d j l) denote probability measuring distance robot location l,
assuming sensor beam ected closest obstacle map (along
sensor beam). denote distance specific obstacle ol . probability
Pm (d j l) given Gaussian distribution mean ol :
ol
1
(22)
Pm (d j l) = p e
2
standard deviation distribution models uncertainty measured
distance, based
granularity discretization L, represents robot's position,
accuracy world model,
accuracy sensor.
Figure 4(a) gives examples Gaussian distributions ultrasound sensors
laser range-finders. distance ol closest obstacle 230cm. Observe
laser sensor higher accuracy ultrasound sensor, indicated
smaller variance.
b.) Unknown obstacles: Markov localization, world model generally assumed
static complete. However, mobile robot environments often populated
therefore contain objects included map. Consequently,
(

2 2

)2

2. Typical values n 64 256 maximal range dn typically 500cm 1000cm.
401

fiFox, Burgard & Thrun

non-zero probability sensor ected obstacle represented
world model. Assuming objects equally distributed environment,
probability Pu (di ) detecting unknown obstacle distance di independent
location robot modeled geometric distribution.
distribution results following observation. distance di measured
sensor ected obstacle shorter distance dj<i ected
distance di . resulting probability
(
0
i=0
Pu (di ) =
(23)
P
cr (1
j<i Pu (dj )) otherwise:
equation constant cr probability sensor ected
unknown obstacle range given discretization.
typical distribution sonar laser measurements depicted Figure 4(b).
example, relatively large probability measuring 500cm due fact
maximum range proximity sensors set 500cm. Thus, distance
represents probability measuring least 500cm.
Obviously, one two cases occur certain point time, i.e.,
sensor beam either ected known unknown object. Thus, P (di j l)
mixture two distributions Pm Pu. determine combined probability
P (di j l) measuring distance di robot location l consider following
two situations: distance di measured,
a.) sensor beam
1.) ected unknown obstacle reaching distance di
X
a1 = 1
Pu (dj );
(24)
j<i

2.)



ected known obstacle distance di
a2 = cd Pm (di j l)

(25)

b.) beam
1.) ected neither unknown obstacle known obstacle
reaching distance di
X
b1 = 1
P (dj j l)
(26)
j<i

2.)



ected unknown obstacle distance di
b2 = cr :
402

(27)

fiMarkov Localization Mobile Robots Dynamic Environments

0.125

Approximated
Measured

0.1

probability p(d | l)

probability p(d | l)

0.125

ol

0.075

0.05

0.025

0

Approximated
Measured

0.1

ol

0.075

0.05

0.025

100

200

300

400

0

500

(a)

measured distance di [cm]

100

200

300

measured distance di [cm]

400

500

(b)

Fig. 5. Measured approximated probabilities (a) sonar (b) laser measurements given
distance ol closest obstacle along sensing direction.

parameter cd Equation (25) denotes probability sensor detects closest
obstacle map. considerations combined probability summarized
Equation (28). double negation insertion Equations (24) (27), finally
get Equation (31).


P (di j l) =
p
(a1 ^ a2 ) _ (b1 ^ b2)
(28)


= :p :(a1 ^ a2 ) ^ :(b1 ^ b2)
(29)


= 1 [1 P (a1a2 )] [1 P (b1 b2 )]
(30)


X
X
= 1 1 (1
Pu (dj )) cd Pm (di j l))) (1 (1
P (dj )) cr (31)
j<i

j<i

obtain probability measuring dn, maximal range sensor, exploit
following equivalence: probability measuring distance larger equal
maximal sensor range equivalent probability measuring distance shorter
dn. incremental scheme, probability easily determined:
X
P (dn j l) = 1
P (dj j l)
(32)
j<n

summarize, probability sensor measurements computed incrementally
different distances starting distance d1 = 0cm. distance consider probability sensor beam reaches corresponding distance ected either
closest obstacle map (along sensor beam), unknown obstacle.
order adjust parameters , cr cd perception model collected
eleven million data pairs consisting expected distance ol measured distance
di typical operation robot. data able estimate
probability measuring certain distance di distance ol closest obstacle
map along sensing direction given. dotted line Figure 5(a) depicts
probability sonar measurements distance ol next obstacle 230cm. Again,
high probability measuring 500cm due fact distance represents
probability measuring least 500cm. solid line figure represents
distribution obtained adapting parameters sensor model best fit
403

fiFox, Burgard & Thrun

probability

probability

0.4

0.4

0.3

0.3

0.2

0.2

0.1

0.1
500

0

500

0

400

400

300
measured distance [cm]
200

100
300
expected distance [cm]

300
measured distance [cm]
200

100

200

200
100

300
expected distance [cm]

400

100
400

(a)

(b)

probability

probability

0.4

0.4

0.3

0.3

0.2

0.2

0.1

0.1
500

0

500

0

400

400

300
measured distance [cm]
200

100
300
expected distance [cm]

300
measured distance [cm]
200

100

200

200
100

300
expected distance [cm]

400

(c)

100
400

(d)

Fig. 6. Measured approximated probability sonar (a,b) laser (c,d) measurements, respectively. table contains probabilities distance measurements given expected distance
ol extracted map environment.

measured data. corresponding measured approximated probabilities laser
sensor plotted Figure 5(b).
observed densities possible distances ol obstacle ultrasound sensors
laser range-finder depicted Figure 6(a) Figure 6(c), respectively. approximated densities shown Figure 6(b) Figure 6(d). figures, distance ol
labeled \expected distance". similarity measured approximated
distributions shows sensor model yields good approximation data.
Please note well-known types sensor noise explicitly represented sensor model. Among specular ections cross-talk
often regarded serious sources noise context ultra-sound sensors.
However, sources sensor noise modeled implicitly geometric distribution
resulting unknown obstacles.
3.3 Filtering Techniques Dynamic Environments

Markov localization shown robust occasional changes environment
opened / closed doors people walking by. Unfortunately, fails localize
robot many aspects environment covered world model.
case, example, densely crowded environments, groups people cover
robots sensors thus lead many unexpected measurements. mobile robots
Rhino Minerva, deployed interactive museum tour-guides (Burgard et al.,
1998a, 2000; Thrun et al., 1999), permanently faced situation. Figure 7
404

fiMarkov Localization Mobile Robots Dynamic Environments

RHINO

(a)

(b)

Fig. 7. Rhino surrounded visitors Deutsches

Museum Bonn

.

(a)

(b)

Fig. 8. Typical laser scans obtained Rhino surrounded visitors.

shows two cases robot Rhino surrounded many visitors giving
tour Deutsches Museum Bonn, Germany.
reason Markov localization fails situations violation Markov
assumption, independence assumption virtually localization techniques
based. discussed Section 2.3, assumption states sensor measurements
observed time independent measurements, given current state
Lt world known. case localization densely populated environments,
independence assumption clearly violated using static model world.
illustrate point, Figure 8 depicts two typical laser scans obtained
museum projects (maximal range measurements omitted). figure also shows
obstacles contained map. Obviously, readings are, large extent, corrupted,
since people museum represented static world model. different
shading beams indicates two classes belong to: black lines correspond
static obstacles map independent position
robot known. grey-shaded lines beams ected visitors Museum.
sensor beams cannot predicted world model therefore independent
other. Since vicinity people usually increases robot's belief close
modeled obstacles, robot quickly loses track position incorporating
405

fiFox, Burgard & Thrun

sensor measurements. reestablish independence sensor measurements could
include position robot position people state variable L.
Unfortunately, infeasible since computational complexity state estimation
increases exponentially number dependent state variables estimated.
closely related solution problem could adapt map according
changes environment. Techniques concurrent map-building localization
(Lu & Milios, 1997a; Gutmann & Schlegel, 1996; Shatkey & Kaelbling, 1997; Thrun et
al., 1998b), however, also assume environment almost static therefore
unable deal environments. Another approach would adapt perception
model correctly ect situations. Note perceptual model already assigns
certain probability events sensor beam ected unknown obstacle.
Unfortunately, approaches capable model noise average.
approaches turn work reliably occasional sensor blockage, sucient
situations fifty percent sensor measurements corrupted.
localization system therefore includes filters designed detect whether certain
sensor reading corrupted not. Compared modification static sensor model
described above, filters advantage average possible
situations decision based current belief robot.
filters designed select readings complete scan come
objects contained map. section introduce two different kinds filters.
first one called entropy filter. Since filters reading based solely effect
belief Bel(L), applied arbitrary sensors. second filter distance
filter selects readings according much shorter expected
value. therefore especially designed proximity sensors.
3.3.1 Entropy Filter

entropy H (L) belief L defined
X
H (L) =
Bel(L = l) log Bel(L = l)
l

(33)

measure uncertainty outcome random variable L (Cover &
Thomas, 1991). higher entropy, higher robot's uncertainty
is. entropy filter measures relative change entropy upon incorporating sensor
reading belief Bel(L). specifically, let denote measurement sensor
(in case single range measurement). change entropy Bel(L) given
defined as:
H (L j s) := H (L j s) H (L)
(34)
term H (L j s) entropy belief Bel(L) incorporating sensor measurement (see Equations (18) { (20)). positive change entropy indicates
incorporating s, robot less certain position, negative change indicates
increase certainty. selection scheme entropy filter exclude sensor
measurements H (L j s) < 0. words, uses sensor readings
confirming robot's current belief.
406

fiMarkov Localization Mobile Robots Dynamic Environments

1

ol

probability

0.8

Pshort (di j l)
Pm (di j l)

0.6

0.4

0.2

0

100

200

300

400

500

measured distance [cm]

Fig. 9. Probability Pm (di j l) expected measurement probability Pshort (di j l) distance
di shorter expected measurement given location l.

Entropy filters work well robot's belief focused correct hypothesis.
However, may fail situations robot's belief state incorrect. topic
analyzed systematically experiments described Section 4.1. advantage
entropy filter makes assumptions nature sensor data
kind disturbances occurring dynamic environments.
3.3.2 Distance Filter

distance filter specifically designed proximity sensors laser rangefinders. Distance filters based simple observation: proximity sensing, unmodeled
obstacles typically produce readings shorter distance expected
map. essence, distance filter selects sensor readings based distance relative
distance closest obstacle map.
specific, filter removes sensor measurements probability higher (this threshold set 0:99 experiments) shorter
expected, therefore caused unmodeled object (e.g. person).
see, let d1 ; : : : ; dn discrete set possible distances measured proximity
sensor. Section 3.2, denote Pm (di j l) probability measuring distance di
robot position l sensor detects closest obstacle map along
sensing direction. distribution Pm describes sensor measurement expected
map. described above, distribution assumed Gaussian mean
distance ol closest obstacle along sensing direction. dashed line Figure 9
represents Pm , laser range-finder distance ol 230cm. define
probability P (di j l) measured distance di shorter expected one given
robot position l. probability obviously equivalent probability
expected measurement ol longer di given robot location l thus
computed follows:
X
P (di j l) =
Pm (dj j l):
(35)
short

short

j>i

407

fiFox, Burgard & Thrun
Bel(Lt = l)





x

(0; 0; 0)

Fig. 10. Grid-based representation state space

practice, however, interested probability P (di ) di shorter
expected, given complete current belief robot. Thus, average
possible positions robot:
X
P (di ) =
P (di j l)Bel(L = l)
(36)
short

short

l

short

Given distribution P (di ), implement distance filter excluding
sensor measurements di P (di ) > . Whereas entropy filter filters measurements
according effect belief state robot distance filter selects measurements solely based value regardless effect robot's certainty.
noted Fox (1998) additionally developed blockage filter proximity
sensors, based probabilistic description situations sensor
blocked unknown obstacle. omit filter since derivation quite complex
resulting filter significantly different distance filter described here.
short

short

3.4 Grid-based Representation State Space

return issue represent compute belief distribution
robot eciently, describing one might think \nut bolts" gridbased Markov localization. Recall obtain accurate metric position estimates,
approach Markov localization uses fine-grained discretization state space.
L represented three-dimensional, regularly spaced grid, spatial resolution
usually 10cm 40cm angular resolution usually 2 5 degrees.
Figure 10 illustrates structure position probability grid. layer grid
corresponds possible poses robot orientation.
fine-grained approximation makes possible estimate robot's position high accuracy, obvious disadvantage fine-grained discretization lies
408

fiMarkov Localization Mobile Robots Dynamic Environments

huge state space maintained. mid-size environment size
30 30m2 , angular grid resolution 2 , cell size 15 15cm2 state space
consists 7; 200; 000 states. basic Markov localization algorithm updates
states sensory input atomic movement robot. Current computer
speed, thus, makes impossible update matrices size real-time.
update state spaces eciently, developed two techniques,
described remainder section. first method, introduced Section 3.4.1,
pre-computes sensor model. allows us determine likelihood P (s j l) sensor
measurements two look-up operations|instead expensive ray tracing operations.
second optimization, described Section 3.4.2, selective update strategy. strategy
focuses computation, updating relevant part state space. Based
two techniques, grid-based Markov localization applied on-line estimate
position mobile robot operation, using low-cost PC.
3.4.1 Pre-Computation Sensor Model

described Section 3.2, perception model P (s j l) proximity sensors depends
distance ol closest obstacle map along sensor beam. Based
assumption map environment static, approach pre-computes stores
distances ol possible robot location l environment. Following sensor
model, use discretization d1 ; : : : ; dn possible distances ol . discretization
exactly expected measured distances. store
location l index expected distance ol three-dimensional table. Please
note table needs one byte per value 256 different values discretization
ol used. probability P (di j ol ) measuring distance di closest obstacle
distance ol (see Figure 6) also pre-computed stored two-dimensional
lookup-table.
result, probability P (s j l) measuring given location l quickly
computed two nested lookups. first look-up retrieves distance ol closest
obstacle sensing direction given robot location l. second lookup
used get probability P (s j ol ). ecient computation based table look-ups
enabled implementation quickly incorporate even laser-range scans consist
180 values overall belief state robot. experiments, use
look-up tables led speed-up-factor 10, compared computation
distance closest obstacle run-time.
3.4.2 Selective Update

selective update scheme based observation global localization,
certainty position estimation permanently increases density quickly concentrates grid cells representing true position robot. probability
grid cells decreases localization key idea optimization
exclude unlikely cells updated.
purpose, introduce threshold3 " update grid cells l
Bel(Lt = l) > ". allow selective update still maintaining density
3. current implementation " set 1% priori position probability.
409

fiFox, Burgard & Thrun

entire state space, approximate P (st j l) cells Bel(Lt = l) "
priori probability measuring st . quantity, call Pe (st ), determined

averaging possible locations robot:
X
Pe (st ) = P (st j l) P (l)
l

(37)

Please note Pe (st) independent current belief state robot
determined beforehand. incremental update rule new sensor measurement st
changed follows (compare Equation (9)):
(
fft P (st j l) Bel(Lt 1 = l) Bel(Lt 1 = l) > "
Bel(Lt = l)
(38)
fft P~ (st ) Bel(Lt 1 = l) otherwise
multiplying Pe (st) normalization factor fft , rewrite equation
8
< ff~ P (st jl) Bel(Lt 1 = l) Bel(Lt 1 = l) > "
Pe(st )
(39)
Bel(Lt = l)
: ff~
Bel(Lt 1 = l) otherwise
ff~t = fft Pe (st ).
key advantage selective update scheme given Equation (39) cells
Bel(Lt 1 = l) " updated value ff~t . order obtain smooth
transitions global localization position tracking focus computation
important regions state space L, example, case ambiguities use
partitioning state space. Suppose state space L partitioned n segments
parts 1; : : : ; n. segment called active time contains locations probability threshold "; otherwise call part passive probabilities
cells threshold. Obviously, keep track individual probabilities within passive part accumulating normalization factors ff~t value
fii . Whenever segment becomes passive, i.e. probabilities locations within
longer exceed ", normalizer fii (t) initialized 1 subsequently updated
follows: fii(t + 1) = ff~t fii (t). soon part becomes active again, restore
probabilities individual grid cells multiplying probabilities cell
accumulated normalizer fii (t). keeping track robot motion since part became
passive, suces incorporate accumulated motion whenever part becomes active
again. order eciently detect whether passive part activated again,
store maximal probability Pimax cells part time becomes passive.
Whenever Pimax fii (t) exceeds ", part activated contains least
one position probability threshold. current implementation partition state space L part consists locations equal orientation
relative robot's start location.
illustrate effect selective update scheme, let us compare update
active passive cells incoming sensor data. According Equation (39), difference
lies ratio P (st j l)=P~ (st ). example ratio model proximity sensors
depicted Figure 11 (here, replaced st proximity measurement di ).
beginning localization process, cells active updated according ratio
410

fiMarkov Localization Mobile Robots Dynamic Environments

ol

9

Laser
Sonar

8

likelihood ratio

7
6
5
4
3
2
1
0

100

200

300

400

500

measured distance di [cm]

Fig. 11. Ratio PP~((ddiijl)) sonar laser measurements expected distance ol 230cm.

depicted Figure 11. measured expected distances cells represent
true location robot usually deviate significantly. Thus, probabilities
cells quickly fall threshold ".
effect selective update scheme becomes obvious: parts state
space align well orientation environment, quickly become passive
robot localizes itself. Consequently, small fraction state space
updated soon robot correctly determined position. If, however,
position robot lost, likelihood ratios distances measured
active locations become smaller one average. Thus probabilities active
locations decrease normalizers fii passive parts increase segments
activated again. true position robot among active locations,
robot able re-establish correct belief.
extensive experimental tests observe evidence selective update
scheme noticably negative impact robot's behavior. contrast, turned
highly effective, since practice small fraction (generally less 5%)
state space updated position robot determined
correctly, probabilities active locations generally sum least 0.99.
Thus, selective update scheme automatically adapts computation time required
update belief certainty robot. way, system able eciently
track position robot position determined. Additionally, Markov
localization keeps ability detect localization failures relocalize robot.
disadvantage lies fixed representation grid undesirable
effect memory requirement current implementation stays constant even
minor part state space updated. context would like mention
recently promising techniques presented overcome disadvantage
applying alternative dynamic representations state space (Burgard et al., 1998b;
Fox et al., 1999).
4. Experimental Results

metric Markov localization technique, including sensor filters, implemented evaluated extensively various environments. section present
411

fiFox, Burgard & Thrun

experiments carried mobile robots Rhino Minerva (see Figure 1).
Rhino ring 24 ultrasound sensors opening angle 15 degrees. Both,
Rhino Minerva equipped two laser range-finders covering 360 degrees field
view.
first set experiments demonstrates robustness Markov localization two
real-world scenarios. particular, systematically evaluates effect filtering
techniques localization performance highly dynamic environments. additional
experiment illustrates advantage filtering technique, enables mobile
robot reliably estimate position even outline oce environment
given map.
experiments described section, illustrate ability
Markov localization technique globally localize mobile robot approximate world
models occupancy grid maps, even using inaccurate sensors ultrasound
sensors. Finally, present experiments analyzing accuracy eciency grid-based
Markov localization respect size grid cells.
experiments reported demonstrate Markov localization able globally
estimate position mobile robot, reliably keep track even
approximate model possibly dynamic environment given, robot weak
odometry, noisy sensors ultrasound sensors used.
4.1 Long-term Experiments Dynamic Environments

mobile robots Rhino Minerva, operated Deutsches Museum Bonn
US-Smithsonian's National Museum American History, robustness reliability Markov localization system utmost importance. Accurate position
estimation crucial component, many obstacles \invisible" robots'
sensors (such glass cages, metal bars, staircases, alike). Given estimate
robot's position (Fox et al., 1998b) integrated map information collision avoidance system order prevent robot colliding obstacles could
detected.
Figure 12(a) shows typical trajectory robot Rhino, recorded museum
Bonn, along map used localization. reader may notice
obstacles shown black actually used localization; others either invisible
could detected reliably. Rhino used entropy filter identify sensor readings
corrupted presence people. Rhino's localization module able (1)
globally localize robot morning robot switched (2) reliably
accurately keep track robot's position. entire six-day deployment period,
Rhino traveled 18km, approach led single software-related collision,
involved \invisible" obstacle caused localization error
slightly larger 30cm safety margin.
Figure 12(b) shows 2km long trajectory robot Minerva National Museum
American History. Minerva used distance filter identify readings ected
unmodeled objects. filter developed Rhino's deployment museum
Bonn, based analysis localization failure reported attempt
prevent similar effects future installations. Based distance filter, Minerva able
412

fiMarkov Localization Mobile Robots Dynamic Environments

Duration: 4.8 hours
Distance: 1540 meters

Duration: 1 hour
Distance: 2000 meters

(a)

(b)

Fig. 12. Typical trajectories (a) Rhino
National Museum American History.

Deutsches Museum Bonn

(b) Minerva

operate reliably period 13 days. time Minerva traveled total
44km maximum speed 1.63m/sec.
Unfortunately, evidence museum projects anecdotal. Based sensor
data collected Rhino's deployment museum Bonn, also investigated
effect filter techniques systematically, even extreme conditions.
particular, interested localization results
a.) environment densely populated (more 50% sensor reading
corrupted),
b.) robot suffers extreme dead-reckoning errors (e.g. induced person carrying robot somewhere else). Since cases rare, manually icted
errors original data analyze effect.
4.1.1 Datasets

experiments, used two different datasets. sets differ mainly
amount sensor noise.
a.) first dataset collected 2.0 hours robot motion, robot
traveled approximately 1,000 meters. dataset collected museum
closed, robot guided remote Internet-visitors museum.
robot's top speed 50cm/sec. Thus, dataset \ideal"
environment sparsely populated, robot moved slowly.
b.) second dataset recorded period 4.8 hours, Rhino
traveled approximately 1,540 meters. path dataset shown Figure 12(a). collecting data, robot operated peak trac hours.
frequently faced situations one illustrated Figure 7.
robot's top speed 80cm/sec.
datasets consist logs odometry laser range-finder scans, collected
robot moved museum. Using time stamps logs, tests
413

fiFox, Burgard & Thrun

Denesely populated
Sparcely populated

Noise [%]

60

40

20

1000

4000

7000

10000

13000

16000

Time [sec]

Fig. 13. Percentage noisy sensor measurements averaged time intervals five minutes.

conducted real-time simulation SUN-Ultra-Sparc 1 (177-MHz). first dataset
contained 32,000, second dataset 73,000 laser scans.
evaluate different localization methods, generated two reference paths, averaging
estimates nine independent runs filter datasets (with small
random noise added input data). verified correctness reference paths
visual inspection; hence, taken \ground truth."
Figure 13 shows estimated percentage corrupted sensor readings time
datasets. dashed line corresponds first data set, solid line illustrates
corruption second (longer) data set. second dataset, half
measurements corrupted extended durations time, estimated analyzing
laser reading post-facto whether significantly shorter distance
next obstacle.
4.1.2 Tracking Robot's Position

first series experiments, interested comparing ability three
approaches|plain Markov localization without filtering, localization entropy filter,
localization distance filter|to keep track robot's position normal
working conditions. three approaches tracked robot's position empty museum
well (first dataset), exhibiting negligible errors localization. results obtained
second, challenging dataset, however, quite different. nutshell,
filter-based approaches tracked robot's position accurately, whereas conventional
Markov localization failed frequently. Thus, used latter museum exhibit,
would inevitably led large number collisions failures.
Filter
None
Entropy Distance
failures [%] 1:6 0:4 0:9 0:4 0:0 0:0
failures [%] 26:8 2:4 1:1 0:3 1:2 0:7


II

Table 2: Ability track robot's position.
Table 2 summarizes results obtained different approaches tracking
experiment. first row Table 2 provides percentage failures different
414

fiMarkov Localization Mobile Robots Dynamic Environments

final position

Distance final position: 19 cm
Certainty final position: 0.003

final position

(a)

Distance final position: 1 cm
Certainty final position: 0.987

final position

(b)

Distance final position: 1 cm
Certainty final position: 0.998

(c)

Fig. 14. Estimated real paths robot along endpoints incorporated sensor measurements using (a) filter, (b) entropy filter, (c) distance filter.

filters first dataset (error values represent 95% confidence intervals). Position estimates considered \failure" estimated location robot deviated
reference path 45cm least 20 seconds. percentage measured
time position lost, relative total time dataset.
seen here, three approaches work well, distance filter provides
best performance. second row provides failures second dataset. plain
Markov localization failed 26.8% overall time, filter techniques show almost
equal results failure less 2%. Thus, two filter techniques robust
highly dynamic environments, plain Markov localization prone fail.
shed light onto question Markov localization performs poorly
compared filter algorithms, analyzed sensor readings method used
localization task. Figure 14 shows, small fraction data, measurements incorporated robot's belief three different approaches. Shown
end points sensor measurements used localization relative positions
reference path. Obviously, filter approaches manage focus attention
\correct" sensor measurements, whereas plain Markov localization incorporates massive
amounts corrupted (misleading) measurements. also illustrated Figure 14,
filter-based approaches produce accurate results higher certainty correct
position.
4.1.3 Recovery Extreme Localization Failures

conjecture key advantage original Markov localization technique lies
ability recover extreme localization failures. Re-localization failure often
dicult global localization scratch, since robot starts belief
centered completely wrong position. Since filtering techniques use current
belief select readings incorporated, clear still maintain
ability recover global localization failures.
analyze behavior filters extreme conditions, carried
series experiments manually introduced failures data
test robustness methods extreme. specifically, \tele-ported"
robot random points time locations. Technically, done changing
robot's orientation 18090 degree shifting 0100cm, without letting
robot know. perturbations introduced randomly, probability 0:005 per
415

fiFox, Burgard & Thrun

Filter
trec [sec]

failures [%]
trec [sec]

failures [%]

None
Entropy
Dataset
237 27 1779 548
10:2 1:8 45:6 7:1
Dataset II
269 60 1310 904
39:5 5:1 72:8 7:3

Distance
188
6:8

30
1:6

235
7:8

46
1:9

Table 3: Summary recovery experiments.
meter robot motion. Obviously, incidents make robot lose track position.
method tested 20 differently corrupted versions datasets. resulted
total 50 position failures dataset. failures
measured time methods re-localized robot correctly. Re-Localization
assumed succeeded distance estimated position reference
path smaller 45cm 10 seconds.
Table 3 provides re-localization results various methods, based two different datasets. trec represents average time seconds needed recover
localization error. results remarkably different results obtained
normal operational conditions. conventional Markov localization technique
using distance filters relatively ecient recovering extreme positioning errors
first dataset, whereas entropy filter-based approach order magnitude less
ecient (see first row Table 3). unsatisfactory performance entropy filter
experiment due fact disregards sensor measurements
confirm belief robot. procedure reasonable belief correct,
prevents robot detecting localization failures. percentage time
position robot lost entire run given second row table. Please
note percentage includes both, failures due manually introduced perturbations
tracking failures. Again, distance filter slightly better approach without filter, entropy filter performs poorly. average times trec recover
failures second dataset similar first dataset. bottom row
Table 3 provides percentage failures dicult dataset. distance
filter-based approach performs significantly better approaches, since
able quickly recover localization failures reliably track robot's position.
results illustrate despite fact sensor readings processed selectively,
distance filter-based technique recovers eciently extreme localization errors
conventional Markov approach.
4.2 Localization Incomplete Maps

advantage filtering techniques Markov localization require
detailed map environment. Instead, suces provide outline
416

fiMarkov Localization Mobile Robots Dynamic Environments

(b)

(a)

(c)

Fig. 15. (a) Outline oce environment (b,c) examples filtered (grey) incorporated
(black) sensor readings using distance filter.
C

22m

3m


B
31m

(a)

20m

(b)

Fig. 16. (a) Occupancy grid map 1994 AAAI mobile robot competition arena. (b) Trajectory
robot ultrasound measurements used globally localize robot map.

merely includes aspects world static. Figure 15(a) shows ground plan
department building, contains walls university building.
complete map, including movable objects tables chairs, shown Figure 19.
two Figures 15(b) 15(c) illustrate distance filter typically behaves
tracking robot's position sparse map environment. Filtered readings
shown grey, incorporated sensor readings shown black. Obviously,
filter focuses known aspects map ignores objects (such desks,
chairs, doors tables) contained outline. Fox (1998) describes
systematic experiments supporting belief Markov localization combination
distance filter able accurately localize mobile robots even relying
outline environment.
4.3 Localization Occupancy Grid Maps Using Sonar

next experiment described carried based data collected mobile
robot Rhino 1994 AAAI mobile robot competition (Simmons, 1995). Figure 16(a)
shows occupancy grid map (Moravec & Elfes, 1985; Moravec, 1988) environment,
constructed techniques described (Thrun et al., 1998a; Thrun, 1998b). size
map 31 22m2 , grid resolution 15cm.
417

fiFox, Burgard & Thrun
Robot position (A)
Robot position (B)

(a)

Robot position (C)

(b)

(c)

Fig. 17. Density plots incorporating 5, 18, 24 sonar scans (darker positions
likely).

(a)

(b)

Fig. 18. Odometry information corrected path robot.

Figure 16(b) shows trajectory robot along measurements 24 ultrasound sensors obtained robot moved competition arena. use
sensor information globally localize robot scratch. time required
process data 400MHz Pentium II 80 seconds, using position probability grid
angular resolution 3 degrees. Please note exactly time needed
robot traverse trajectory; thus, approach works real-time. Figure 16(b)
also marks positions robot perceiving 5 (A), 18 (B), 24 (C) sensor sweeps.
belief states global localization three points time illustrated
Figure 17.
figures show belief robot projected onto hx; yi-plane plotting
hx; yi-position maximum probability possible orientations. likely
positions darker illustration purposes, Figures 17(a) 17(b) use logarithmic
scale intensity. Figure 17(a) shows belief state integrating 5 sensor sweeps (see
also position Figure 16(b)). point time, robot knows one
corridors environment. integrating 18 sweeps ultrasound sensors,
robot almost certain end corridor (compare position B Figures 16(b) 17(b)). short time later, turning left integrating six sweeps
ultrasound ring, robot determined position uniquely. represented
unique peak containing 99% whole probability mass Figure 17(c).
Figure 18 illustrates ability Markov localization correct accumulated deadreckoning errors matching ultrasound data occupancy grid maps. Figure 18(a)
shows typical 240m long trajectory, measured Rhino's wheel-encoders 1994
418

fiMarkov Localization Mobile Robots Dynamic Environments

1

22
8

10
13

2

16
7

20

3 21

5

19
9

12

11

4
6

15 18

17
14

Fig. 19. Path robot reference positions

AAAI mobile robot competition arena. Obviously, rotational error odometry
quickly increases. Already traveling 40m, accumulated error orientation
(raw odometry) 50 degrees. Figure 18(b) shows path robot estimated
Markov localization, significantly correct.
4.4 Precision Performance

describe experiments aimed characterizing precision position estimates. experiments also characterize time needed global localization relation
size grid cells. Figure 19 shows path robot Rhino Computer
Science Department's building University Bonn. path includes 22 reference
positions, true position robot determined using scan matching
technique presented (Gutmann & Schlegel, 1996; Lu & Milios, 1994). data recorded
run split four disjoint traces sensor data. different
traces contained full length path, every fourth sensor reading
sucient test localization performance.
Figure 20(a) shows localization error averaged four runs reference
positions. error determined different sizes grid cells, using laser rangefinder ultrasound sensors. results demonstrate (1) average localization
error sensors generally cell size (2) laser range-finders provide
significantly higher accuracy ultrasound sensors. using laser range-finder
spatial resolution 4cm, average positioning error even reduced 3.5cm.
Figure 20(b) shows average CPU-time needed globally localize robot
function size grid cells. values represent computation time needed
266MHz Pentium II global localization path starting point
position 1. experiment, used fixed angular resolution four degrees.
case 64cm cell size, average localization time approximately 2.2 seconds.
419

fiFox, Burgard & Thrun

Average localization time [sec]

Average estimation error [cm]

120

Ultrasound sensor
Laser-range finder

30
25
20
15
10
5
0

Ultrasound sensor
Laser-range finder

100
80
60
40
20
0

0

10

20

30
40
Grid cell size [cm]

50

60

70

0

(a)

10

20

30
40
50
Grid cell size [cm]

60

70

(b)

Fig. 20. (a) Average localization error (b) average CPU-time needed global localization time
ultrasound sensors laser range-finder depending grid resolution.

course, effective time needed global localization practice highly depends
structure environment amount information gathered path
robot. example, due symmetry corridor oce environment,
robot able localize unless enters room. reader may notice
recently, developed decision-theoretic method actively guiding robot
places allow resolve ambiguities global localization (Fox et al., 1998a;
Fox, 1998). Based method, localization process becomes ecient, especially
oce environments lot indistinguishable places as, example, long corridors.
experiments described demonstrate metric variant Markov localization able eciently estimate position mobile robot dynamic environments.
furthermore deal approximate models environment occupancy
grid maps rough outline maps. Finally, able eciently accurately estimate
position mobile robot even ultrasound sensors used.
5. Related Work

techniques mobile robot localization literature belong class
local approaches tracking techniques, designed compensate odometric error
occurring navigation. assume initial position robot known
(see Borenstein et al. 1996 comprehensive overview). example, Wei et al. (1994)
store angle histograms constructed laser range-finder scans taken different locations
environment. position orientation robot calculated maximizing
correlation stored histograms laser range-scans obtained
robot moves environment. estimated position, together odometry
information, used predict position robot select histogram
used next match. Yamauchi (1996) Schulz et al. (1999) apply similar technique,
use hill-climbing match local maps built ultrasound sensors global
occupancy grid map. approach Wei et al. (1994), location robot
represented position yielding best match. techniques, contrast
Markov localization, represent uncertainty robot current belief
therefore cannot deal appropriately globally ambiguous situations.
420

fiMarkov Localization Mobile Robots Dynamic Environments

popular probabilistic framework position tracking Kalman filters (Maybeck,
1990; Smith et al., 1990), signal processing technique introduced Kalman (1960).
mentioned Section 2.4, Kalman filter-based methods represent belief robot's
position unimodal Gaussian distribution three-dimensional state-space
robot. mode distribution yields current position robot,
variance represents robot's uncertainty. Whenever robot moves, Gaussian
shifted according distance measured robot's odometry. Simultaneously,
variance Gaussian increased according model robot's odometry. New
sensory input incorporated position estimation matching percepts
world model.
Existing applications Kalman filtering position estimation mobile robots
similar model motion robot. differ mostly update
Gaussian according new sensory input. Leonard Durrant-Whyte (1991) match
beacons extracted sonar scans beacons predicted geometric map
environment. beacons consist planes, cylinders, corners. update current estimate robot's position, Cox (1991) matches distances measured infrared
sensors line segment description environment. Schiele Crowley (1994)
compare different strategies track robot's position based occupancy grid maps
ultrasonic sensors. show matching local occupancy grid maps global
grid map results similar localization performance matching based features extracted maps. Shaffer et al. (1992) compare robustness
two different matching techniques different sources noise. suggest combination map-matching feature-based techniques order inherit benefits
both. Lu Milios (1994,1997b) Gutmann Schlegel (1996) use scan-matching
technique precisely estimate position robot based laser range-finder scans
learned models environment. Arras Vestli (1998) use similar technique
compute position robot high accuracy. variants, however,
rest assumption position robot represented single Gaussian distribution. advantage Kalman filter-based techniques lies eciency
high accuracy obtained. restriction unimodal Gaussian
distribution, however, prone fail position robot estimated
scratch, i.e. without knowledge starting position robot. Furthermore,
technique typically unable recover localization failures. Recently, Jensfelt Kristensen (1999) introduced approach based multiple hypothesis tracking,
allows model multi-modal probability distributions occur global
localization.
Markov localization, employed successfully several variants (Nourbakhsh et al., 1995; Simmons & Koenig, 1995; Kaelbling et al., 1996; Burgard et al., 1996;
Hertzberg & Kirchner, 1996; Koenig & Simmons, 1998; Oore et al., 1997; Thrun, 1998a),
overcomes disadvantage Kalman filter based techniques. different variants
technique roughly distinguished type discretization used representation state space. Nourbakhsh et al. (1995), Simmons Koenig (1995),
Kaelbling et al. (1996) use Markov localization landmark-based navigation,
state space organized according topological structure environment.
nodes topological graph correspond distinctive places hallways openings
421

fiFox, Burgard & Thrun

junctions connections places. Possible observations robot
are, example, hallway intersections. advantage approaches
represent ambiguous situations thus principle able globally localize robot.
Furthermore, coarse discretization environment results relatively small state
spaces maintained eciently. topological representations disadvantage provide coarse information robot's position
rely definition abstract features extracted sensor information.
approaches typically make strong assumptions nature environments.
Nourbakhsh et al. (1995), Simmons Koenig (1995), Kaelbling et al. (1996),
example, consider four possible headings robot position assuming
corridors environment orthogonal other.
method uses instead fine-grained, grid-based discretization state space.
advantage approach compared Kalman filter based techniques comes
ability represent complex probability distributions. recent experimental comparison technique introduced Lu Milios (1994) Gutmann
Schlegel (1996), found Kalman filter based tracking techniques provide highly accurate position estimates less robust, since lack ability globally localize
robot recover localization errors (Gutmann et al., 1998). contrast topological implementations Markov localization, approach provides accurate position estimates applied even highly unstructured environments (Burgard et al., 1998a;
Thrun et al., 1999). Using selective update scheme, technique able eciently
keep track robot's position determined. also allows robot
recover localization failures.
Finally, vast majority existing approaches localization differ
address localization static environments. Therefore, methods prone fail
highly dynamic environments which, example, large crowds people surround
robot (Fox et al., 1998c). However, dynamic approaches great practical importance,
many envisioned application domains service robots involve people populated
environments.
6. Discussion

paper presented metric variant Markov localization, robust technique
estimating position mobile robot dynamic environments. key idea
Markov localization maintain probability density whole state space
robot relative environment. density updated whenever new sensory input
received whenever robot moves. Metric Markov localization represents state
space using fine-grained, metric grids. approach employs ecient, selective update
algorithms update robot's belief real-time. uses filtering cope dynamic
environments, making approach applicable wide range target applications.
contrast previous approaches Markov localization, method uses finegrained discretization state space. allows us compute accurate position
estimates incorporate raw sensory input belief. result, system
exploit arbitrary features environment. Additionally, approach applied
arbitrary unstructured environments rely orthogonality assumption
422

fiMarkov Localization Mobile Robots Dynamic Environments

similar assumptions existence certain landmarks, approaches
Markov localization do.
majority localization approaches developed far assume world
static state robot changing aspect world. able
localize mobile robot even dynamic densely populated environments, developed
technique filtering sensor measurements corrupted due presence
people objects contained robot's model environment.
eciently update huge state spaces resulting grid-based discretization,
developed two different techniques. First, use look-up operations eciently compute quantities necessary update belief robot given new sensory input.
Second, apply selective update scheme focuses computation relevant parts state space. result, even large belief states updated
real-time.
technique implemented evaluated several real-world experiments
different sites. Recently deployed mobile robots Rhino Deutsches Museum Bonn, Germany, Minerva Smithsonian's National Museum American
History, Washington, DC, interactive museum tour-guides. deployments,
Markov localization technique reliably estimated position robots long
periods time, despite fact robots permanently surrounded visitors
produced large amounts false readings proximity sensors robots.
accuracy grid-based Markov localization turned crucial avoid even
obstacles could sensed robot's sensors. accomplished
integrating map information collision avoidance system (Fox et al., 1998b).
Despite encouraging results, several aspects warrant future research. key disadvantage current implementation Markov localization lies fixed discretization
state space, always kept main memory. scale truly large environments, seems inevitable one needs variable-resolution representations
state space, one suggested (Burgard et al., 1997; 1998b; Gutmann et al.,
1998). Alternatively, one could use Monte-Carlo based representations state space
described (Fox et al., 1999). Here, robot's belief represented samples
concentrate likely parts state space.
Acknowledgment

authors would like thank research group autonomous intelligent systems
University Bonn fruitful discussions, useful suggestions comments, especially
Daniel Hennig Andreas Derr. would also like thank members CMU's
Robot Learning Lab many inspiring discussions. Finally, would like thank
staff Deutsches Museum Bonn National Museum American History
enthusiasm willingness expose visitors one mobile robots.
research sponsored part NSF (CAREER Award IIS-9876136) DARPA
via TACOM (contract number DAAE07-98-C-L032), Rome Labs (contract number
F30602-98-2-0137), gratefully acknowledged. views conclusions contained
document authors interpreted necessarily
423

fiFox, Burgard & Thrun

representing ocial policies endorsements, either expressed implied, NSF, DARPA,
TACOM, Rome Labs, United States Government.
References

[Arras & Vestli, 1998] K.O. Arras S.J. Vestli. Hybrid, high-precision localization
mail distributing mobile robot system MOPS. Proc. IEEE International
Conference Robotics & Automation (ICRA), 1998.
[Basye et al., 1992] K. Basye, T. Dean, J. Kirman, M. Lejter. decision-theoretic
approach planning, perception, control. IEEE Expert, 7(4), 1992.
[Borenstein et al., 1996] J. Borenstein, B. Everett, L. Feng. Navigating Mobile Robots:
Systems Techniques. A. K. Peters, Ltd., Wellesley, MA, 1996.
[Burgard et al., 1996] W. Burgard, D. Fox, D. Hennig, T. Schmidt. Estimating
absolute position mobile robot using position probability grids. Proc.
National Conference Artificial Intelligence (AAAI), 1996.
[Burgard et al., 1997] W. Burgard, D. Fox, D. Hennig. Fast grid-based position tracking mobile robots. Proc. German Conference Artificial Intelligence (KI),
Germany. Springer Verlag, 1997.
[Burgard et al., 1998a] W. Burgard, A.B. Cremers, D. Fox, D. Hahnel, G. Lakemeyer,
D. Schulz, W. Steiner, S. Thrun. interactive museum tour-guide robot.
Proc. National Conference Artificial Intelligence (AAAI), 1998.
[Burgard et al., 1998b] W. Burgard, A. Derr, D. Fox, A.B. Cremers. Integrating global
position estimation position tracking mobile robots: Dynamic Markov Localization approach. Proc. IEEE/RSJ International Conference Intelligent
Robots Systems (IROS), 1998.
[Burgard et al., 2000] W. Burgard, A.B. Cremers, D. Fox, D. Hahnel, G. Lakemeyer,
D. Schulz, W. Steiner, S. Thrun. Experiences interactive museum tourguide robot. Artificial Intelligence, 114(1-2), 2000. appear.
[Cover & Thomas, 1991] T.M. Cover J.A. Thomas. Elements Information Theory.
Wiley Series Telecommunications. Wiley, New York, 1991.
[Cox & Wilfong, 1990] I.J. Cox G.T. Wilfong, editors. Autonomous Robot Vehicles.
Springer Verlag, 1990.
[Cox, 1991] I.J. Cox. Blanche|an experiment guidance navigation autonomous
robot vehicle. IEEE Transactions Robotics Automation, 7(2):193{204, 1991.
[Dellaert et al., 1999] F. Dellaert, W. Burgard, D. Fox, S. Thrun. Using condensation algorithm robust, vision-based mobile robot localization. Proc. IEEE
Computer Society Conference Computer Vision Pattern Recognition (CVPR),
1999.
424

fiMarkov Localization Mobile Robots Dynamic Environments

[Fox et al., 1998a] D. Fox, W. Burgard, S. Thrun. Active Markov localization
mobile robots. Robotics Autonomous Systems, 25:195{207, 1998.
[Fox et al., 1998b] D. Fox, W. Burgard, S. Thrun, A.B. Cremers. hybrid collision
avoidance method mobile robots. Proc. IEEE International Conference
Robotics & Automation (ICRA), 1998.
[Fox et al., 1998c] D. Fox, W. Burgard, S. Thrun, A.B. Cremers. Position estimation
mobile robots dynamic environments. Proc. National Conference
Artificial Intelligence (AAAI), 1998.
[Fox et al., 1999] D. Fox, W. Burgard, F. Dellaert, S. Thrun. Monte Carlo Localization:
Ecient position estimation mobile robots. Proc. National Conference
Artificial Intelligence (AAAI), 1999.
[Fox, 1998] D. Fox. Markov Localization: Probabilistic Framework Mobile Robot Localization Naviagation. PhD thesis, Dept. Computer Science, University Bonn,
Germany, December 1998.
[Gutmann & Schlegel, 1996] J.-S. Gutmann C. Schlegel. AMOS: Comparison scan
matching approaches self-localization indoor environments. Proc. 1st
Euromicro Workshop Advanced Mobile Robots. IEEE Computer Society Press, 1996.
[Gutmann et al., 1998] J.-S. Gutmann, W. Burgard, D. Fox, K. Konolige. experimental comparison localization methods. Proc. IEEE/RSJ International
Conference Intelligent Robots Systems (IROS), 1998.
[Hennig, 1997] D. Hennig. Globale und lokale Positionierung mobiler Roboter mittels
Wahrscheinlichkeitsgittern. Master's thesis, Department Computer Science, University
Bonn, Germany, 1997. German.
[Hertzberg & Kirchner, 1996] J. Hertzberg F. Kirchner. Landmark-based autonomous
navigation sewerage pipes. Proc. First Euromicro Workshop Advanced
Mobile Robots. IEEE Computer Society Press, 1996.
[Jensfelt & Kristensen, 1999] P. Jensfelt S. Kristensen. Active global localisation
mobile robot using multiple hypothesis tracking. Proc. IJCAI-99 Workshop
Reasoning Uncertainty Robot Navigation, 1999.
[Kaelbling et al., 1996] L.P. Kaelbling, A.R. Cassandra, J.A. Kurien. Acting
uncertainty: Discrete Bayesian models mobile-robot navigation. Proc.
IEEE/RSJ International Conference Intelligent Robots Systems (IROS), 1996.
[Kalman, 1960] R.E. Kalman. new approach linear filtering prediction problems.
Trans. ASME, Journal basic engineering, 82:35{45, March 1960.
[Koenig & Simmons, 1998] S. Koenig R. Simmons. robot navigation architecture
based partially observable Markov decision process models. Kortenkamp et al.
(1998).
425

fiFox, Burgard & Thrun

[Konolige, 1999] K. Konolige. Markov localization using correlation. Proc. International Joint Conference Artificial Intelligence (IJCAI), 1999.
[Kortenkamp & Weymouth, 1994] D. Kortenkamp T. Weymouth. Topological mapping
mobile robots using combination sonar vision sensing. Proc. National
Conference Artificial Intelligence (AAAI), 1994.
[Kortenkamp et al., 1998] D. Kortenkamp, R. P. Bonasso, R. Murphy, editors.
MIT/AAAI Press, Cambridge, MA, 1998.
[Leonard & Durrant-Whyte, 1991] J.J. Leonard H.F. Durrant-Whyte. Mobile robot
localization tracking geometric beacons. IEEE Transactions Robotics Automation, 7(3):376{382, 1991.
[Leonard & Durrant-Whyte, 1992] J.J. Leonard H.F. Durrant-Whyte. Directed Sonar
Sensing Mobile Robot Navigation. Kluwer Academic, Boston, MA, 1992.
[Lu & Milios, 1994] F. Lu E. Milios. Robot pose estimation unknown environments
matching 2d range scans. IEEE Computer Vision Pattern Recognition Conference (CVPR), 1994.
[Lu & Milios, 1997a] F. Lu E. Milios. Globally consistent range scan alignment
environment mapping. Autonomous Robots, 4:333{349, 1997.
[Lu & Milios, 1997b] F. Lu E. Milios. Robot pose estimation unknown environments
matching 2d range scans. Journal Intelligent Robotic Systems, 18, 1997.
[Maybeck, 1990] P.S. Maybeck. Kalman filter: introduction concepts. Cox &
Wilfong (1990).
[Moravec & Elfes, 1985] H.P. Moravec A.E. Elfes. High resolution maps wide
angle sonar. Proc. IEEE International Conference Robotics & Automation
(ICRA), 1985.
[Moravec, 1988] H.P. Moravec. Sensor fusion certainty grids mobile robots. AI Magazine, Summer 1988.
[Nourbakhsh et al., 1995] I. Nourbakhsh, R. Powers, S. Birchfield. DERVISH ocenavigating robot. AI Magazine, 16(2), Summer 1995.
[Oore et al., 1997] S. Oore, G.E. Hinton, G. Dudek. mobile robot learns
place. Neural Computation, 1997.
[Russell & Norvig, 1995] Stuart J. Russell Peter Norvig. Artificial Intelligence: Modern Approach, chapter 17. Number 0-13-103805-2 Series Artificial Intelligence. Prentice Hall, 1995.
[Schiele & Crowley, 1994] B. Schiele J.L. Crowley. comparison position estimation
techniques using occupancy grids. Proc. IEEE International Conference
Robotics & Automation (ICRA), 1994.
426

fiMarkov Localization Mobile Robots Dynamic Environments

[Schultz et al., 1999] A. Schultz, W. Adams, B. Yamauchi. Integrating exploration,
localization, navigation planning common representation. Autonomous
Robots, 6(3), 1999.
[Shaffer et al., 1992] G. Shaffer, J. Gonzalez, A. Stentz. Comparison two range-based
estimators mobile robot. SPIE Conf. Mobile Robots VII, pages 661{667, 1992.
[Shatkey & Kaelbling, 1997] H. Shatkey L.P. Kaelbling. Learning topological maps
weak local odometric information. Proc. International Joint Conference
Artificial Intelligence (IJCAI), 1997.
[Simmons & Koenig, 1995] R. Simmons S. Koenig. Probabilistic robot navigation
partially observable environments. Proc. International Joint Conference
Artificial Intelligence (IJCAI), 1995.
[Simmons, 1995] R. Simmons. 1994 AAAI robot competition exhibition. AI Magazine, 16(2), Summer 1995.
[Smith et al., 1990] R. Smith, M. Self, P. Cheeseman. Estimating uncertain spatial
relationships robotics. I. Cox G. Wilfong, editors, Autonomous Robot Vehicles.
Springer Verlag, 1990.
[Thrun et al., 1998a] S. Thrun, A. Bucken, W. Burgard, D. Fox, T. Frohlinghaus, D. Hennig, T. Hofmann, M. Krell, T. Schimdt. Map learning high-speed navigation
RHINO. Kortenkamp et al. (1998).
[Thrun et al., 1998b] S. Thrun, D. Fox, W. Burgard. probabilistic approach
concurrent mapping localization mobile robots. Machine Learning, 31:29{53,
1998. Also appeared Autonomous Robots 5, pp. 253{271, joint issue.
[Thrun et al., 1999] S. Thrun, M. Bennewitz, W. Burgard, A.B. Cremers, F. Dellaert,
D. Fox, D. Hahnel, C. Rosenberg, N. Roy, J. Schulte, D. Schulz. MINERVA:
second generation mobile tour-guide robot. Proc. IEEE International Conference Robotics & Automation (ICRA), 1999.
[Thrun, 1998a] S. Thrun. Bayesian landmark learning mobile robot localization. Machine Learning, 33(1), 1998.
[Thrun, 1998b] S. Thrun. Learning metric-topological maps indoor mobile robot navigation. Artificial Intelligence, 99(1):27{71, 1998.
[Wei et al., 1994] G. Wei, C. Wetzler, E. von Puttkamer. Keeping track position
orientation moving indoor systems correlation range-finder scans. Proc.
IEEE/RSJ International Conference Intelligent Robots Systems (IROS), 1994.
[Yamauchi, 1996] B. Yamauchi. Mobile robot localization dynamic environments using
dead reckoning evidence grids. Proc. IEEE International Conference
Robotics & Automation (ICRA), 1996.
427

fiJournal Artificial Intelligence Research 11 (1999) 361-390

Submitted 6/99; published 11/99

Complexity Reasoning Spatial Congruence
Matteo Cristani

Dipartimento Scientifico e Tecnologico,
Universita di Verona,
Ca Vignal 2, strada Le Grazie, I-37134 Verona

cristani@sci.univr.it

Abstract

recent literature Artificial Intelligence, intensive research effort
spent, various algebras qualitative relations used representation temporal
spatial knowledge, problem classifying computational complexity reasoning
problems subsets algebras. main purpose researches describe
restricted set maximal tractable subalgebras, ideally exhaustive fashion
respect hosting algebras.
paper introduce novel algebra reasoning Spatial Congruence, show
satisfiability problem spatial algebra MC-4 NP-complete, present
complete classification tractability algebra, based individuation three
maximal tractable subclasses, one containing basic relations. three algebras
formed 14, 10 9 relations 16 form full algebra.

1. Introduction
Qualitative spatial reasoning received increasing amount interest recent
literature. main reason this, already observed Jonsson Drakengren (1997),
probably spatial reasoning proved applicable real-world problems,
Geographical Information Systems (Egenhofer, 1991; Grigni, Papadias, & Papadimitriou,
1995), Molecular Biology (Cui, 1994).
specific stress qualitative reasoning space, observed Zimmermann
(1995), justified fact qualitative spatial relations treated eciently
quantitative counterparts, seem closer model relations
humans adopt spatial reasoning.
Even though qualitative spatial reasoning extended literature, spite
relatively short history, certain aspects discipline neglected. particular,
exhaustive computational perspective developed qualitative morphological
reasoning space. term morphological reasoning intended suggest reasoning
internal structure objects. case spatial reasoning includes
reasoning size, shape internal topology spatial regions.
purpose present work analyse complexity reasoning relations
congruence, either actual partial, spatial regions, using spatial algebra
MC-4 preliminarly analysed Cristani (1997).
algebra MC-4 Constraint Algebra (Ladkin & Maddux, 1994) qualitative
reasoning morphological relation congruence. Two spatial regions,
models documented literature, considered equivalent share
interior boundaries, namely spatial region. particular,
c 1999 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiCristani

relation EQ, defined Randell, Cui Cohn (1989), analogously Egenhofer
Franzosa (1991), becomes identity unique name assumption. Geometry
topology, conversely, allow kinds equivalence relations. relations weaker
identity, namely equivalence classes induce larger singletons.
simplest weakening define congruence relation. Even though,
relation studied (Borgo, Guarino, & Masolo, 1996, 1997; Cristani, 1997; Mutinelli,
1998), complexity reasoning subalgebras yet deeply investigated.
reason introduce new relation, provide algebraic structure host
relations based (in particular relations compare regions, which, even
congruent, overlapped roto-translating one interior
other), that, many cases, knowledge represent systems necessarily
includes internal structures. Consider following example.

Example 1
GIS dedicated representation geographical data industrial sites.
system, structure factories described means various attributes,
including size shape. One users wants query system opportunity
moving factory, works, present site new one. new site
prefabricated facilities already exist, problem consists deciding preserve
topological layout factory minimise costs buying new engines, substitute
cannot fit new facilities.
order reason problems system made able represent
qualitative relations old new site parts, establishing, particular whether
spatial regions occupied engines \congruent", even \congruent part"
ones chosen hosting new factory's site.
Clearly cannot use topological information, since spatial region presently occupied
engine surely disjoint region engine going occupy new
site, information insucient deciding whether new site able host
engine itself.
Though metric information involved final decision moving factory,
qualitative reasoning used initial design phase.
Figure 1 give pictorial representation one possible situation which, make
decisions, need represent spatial information topological.


algebra MC-4 used represent four basic relations built
equivalence relation congruence: consider roto-translation region x
respect region y, four possible situations arise.
least one roto-translation x coincides y. two regions
congruent.
least one roto-translation x coincides proper part y.
region x congruent proper part y.
362

fiThe Complexity Reasoning Spatial Congruence

Figure 1: pictorial representation relations analysed GIS moving
factory old new site. Note production lines new
facility may suitable hosting certain engines.

least one roto-translation coincides proper part x.
region x proper part congruent y.
None above. region x cannot perfectly overlapped.
would like stress three main aspects relations.
1. relations established two spatial regions position space.
specific need regions close, particular topological relation, provided relation compatible; congruence relations
purely morphological.
2. equality two regions implies congruence. relation proper part excludes
morphological relations \congruent part". case
morphological side. region congruent part another region, even
disjoint, happen congruence, already stated point
1.
3. Even two regions size, may case regions
congruent. holds also partial congruence, possible region
smaller another one cannot overlapped.
practical relevance algebra proved exhibiting many examples,
especially coming GIS. paper deal problem reasoning
congruence two-dimensional space domain. kind congruence assume
weakest one: roto-translability. Three-dimensional congruence type.
\natural" notion three-dimensional congruence isometry, much general
roto-translability. example left right hands congruent (under simplified
assumption shape size), cannot roto-translated
one. concentrate two-dimensional reasoning may
363

fiCristani

analysed terms roto-translation topological relations. analysis isometries
left work.
paper organised follows. Section 2 describes related work
developed area. Section 3 presents spatial algebra MC-4, Section 4 discusses
classification tractability found algebra. Finally, Section 5,
conclusions given.

2. Previous Work
perspective individuating primitives describe space, significant effort
lately spent, direction defining binary relations spatial regions,
may used model space qualitative terms. Moreover, natural, AI
community, use Constraint Processing reasoning binary relations.
specific attention Constraint Processing emerged Spatial Database community,
community Geographical Information Science well.
Two apparently independently developed models, shown essentially
equivalent, exist Artificial Intelligence (Randell & Cohn, 1989; Randell, Cui, &
Cohn, 1992) Spatial Database literatures (Egenhofer & Herring, 1990; Egenhofer &
Franzosa, 1991; Franzosa & Egenhofer, 1992). Artificial Intelligence model, (Randell &
Cohn, 1989; Randell et al., 1992) known RCC, acronym stands Region
Connection Calculus.
RCC model centered primitive \connection" originally suggested
Clarke (1981). Gotts (1994) Gotts, Gooday Cohn (1996) obtained
connection primitive. original framework (Randell & Cohn, 1989;
Randell et al., 1992) model formulated two versions, called RCC-5
RCC-8. RCC-5 model model cannot distinguish interior
boundary spatial region (so external connection may tangency
overlapping, example), RCC-8 model distinction possible.
Bennett (1994, 1995), used propositional logic represent RCC reasoning problems.
observed that, given propositional logic, interpreting truth values formula
spatial region, language RCC-5 sucient express satisfaction problem
semantical level. fact, however, due spatial interpretation,
non-spatial interpretation RCC-5 relations still sucient represent
truth condition semantical level found: set theory. Therefore, applied
result Cook (1971) NP-completeness classical propositional logic restricted
model RCC-5, proving deciding consistency Constraint Satisfaction Problem
(CSP) RCC-5 NP-complete problem too.
complete model RCC-8, instead, analysed terms pure set theory,
distinction boundary-connection interior-connection possible.
distinction means minimal interpretation RCC-8 still provides
correct complete representation truth conditions semantical level requires topology.
Statman (1979) proved intuitionistic logic along interpretations set theory forces
topology models sound theory. Bennett proved, thus, RCC-8 used
define truth conditions formulas intuitionistic propositional logic. Statman
(1979) proved intuitionistic propositional logic PSPACE-complete. However, since
364

fiThe Complexity Reasoning Spatial Congruence

need complete truth verification procedure, procedure constraint
processing, Bennett could reduce result, proving also RCC-8 NP-complete.
results, even general negative practical purposes, encouraged
researches direction restricted models, way least certain
cases may process finite set RCC constraints polynomial fashion deterministic
machines. particular, Nebel (1995) showed reasoning basic relations
RCC-5 RCC-8 tractable problems. Renz Nebel (1999) improved results
above, showing exists maximal tractable subclass RCC-5, denoted
Hb5, formed 28 relations 32, includes basic relations, maximal
tractable subclass RCC-8, denoted Hb8 , formed 148 relations 256 including
basic relations. maximal tractable subclass A, subset constraint algebra,
problems defined tractable, problems defined proper supersets
not. results obtained similar fashion work Nebel
Burckert (1995) temporal reasoning. result Renz Nebel anyway incomplete,
since simply proved exists one maximal tractable subclass,
classify every maximal tractable subclasses RCC-5. Jonsson Drakengren (1997)
showed exist four maximal tractable subclasses RCC-5, one including
basic relations. result obtained similar fashion (Drakengren & Jonsson, 1997;
Jonsson, Drakengren, & Backstrom, 1999). complete analysis RCC-8 maximal
tractable subclasses including basic relations provided Renz (1999).
result analogous MC-4 Jonsson Drakengren result RCC-5.
MC-4 algebra, describe paper, structured way Algebra
Partially Ordered Time (PO-time algebra), studied Anger, Mitra Rodriguez.
would like stress two main aspects here:
MC-4 algebra PO-time algebra algebraic structure:
discussion paper stands different interpretation PO-time algebra, even
different spatial interpretation provided Anger, Mitra Rodriguez
papers.
computational results present applied PO-time algebra
well, extend previous findings obtained Anger, Mitra Rodriguez.
particular Anger, Mitra Rodriguez (1998, 1999), proved path-consistency
insucient ensure consistency relations algebra, exists
tractable subalgebra treated O(n3 ) algorithm.
Anger, Mitra Rodriguez (1999), showed deciding consistency PO-time
network NP-complete problem reducing analogous decision problem
RCC-5.
important observations needed, respect results Anger, Mitra
Rodriguez:
results complexity PO-time algebra applied MC-4,
show MC-4 network consistent exhibit consistent scenario vertices network substituted spatial regions.
Therefore, even show correspondence PO-time algebra too,
NP-completeness result independent. Moreover, method used prove
365

fiCristani

intractability MC-4 independent well, main difference way
used exhibit problematic algebraic structure. proof derived
simple way solve problems whenever possible polynomial time.

discovery tractable subalgebras indicate M99 , M81 M72

present paper, deserves acknowledgement priority Anger, Mitra Rodriguez. However, Anger, Mitra Rodriguez also classified one algebra,
tractable, maximal, since contained M99 . Moreover, algorithms
found M99 M81 substantially different one Anger, Mitra
Rodriguez present ecient, O(n2 ) instead O(n3 ). Therefore
two algorithmic solutions considered independent results well.

classification presented complete, since classify maximal tractable
subalgebras MC-4, result may applied temporal reasoning
well, since obtained means algorithms completely independent
interpretation give relations (either spatial temporal).

introduction morphological relations spatial reasoning novel too,

study spatial congruence deserves, opinion, deep investigations henceforth.
fact two algebras spatial temporal reasoning present substantial similarities novelty. RCC model corresponds subalgebras Interval
Calculus, stated Bennett (1994). Also Anger, Mitra Rodriguez stated
property PO-time algebra respect RCC-5, interpretation completely different own, equality PO-time interpreted EQ
RCC-5, interpret congruence.

Thus, even though similar algebraic structure partially investigated before,
present paper presents substantial methodological differences obtained results
independent extensions ones obtained Anger, Mitra Rodriguez.
remainder paper, result attributed Anger, Mitra
Rodriguez note text.

3. Spatial Algebra MC-4
section present spatial algebra MC-4, previously presented
Cristani (1997) largely analysed Mutinelli (1998).
MC-4 Binary Constraint Algebra (henceforth indicated Constraint Algebra).
Constraint Algebra Constraint Domain Algebra Base, formed
mutually exclusive relations among elements Constraint Domain, whose union
form universal relation. converse basic relation basic relation too,
composition basic relations union basic relations. Constraint
establishment one possible unions basic relations two variables
vary domain. constraint satisfied assignment one pair values
domain variables, pair values one relations constraint
itself. Given finite set constraints two variables, problem deciding
whether exists assignment variables constraints
366

fiThe Complexity Reasoning Spatial Congruence



x

x CG


x

x CGPP


x

x CNO

Figure 2: pictorial representation basic relations MC-4
CG
CGPP

CG
CG
CGPP

CGPP
CGPP
CGPP

CGPP,1
CGPP,1

CGPP,1

CGPP,1

>

CGPP,1

CNO

CNO

CGPP
CNO

CGPP,1
CNO




>

CNO
CNO
CGPP
CNO
CGPP,1
CNO

>

Table 1: composition table MC-4. symbol > represents universal relation
fCG; CGPP; CGPP,1 ; CNOg.
simultaneously satisfied referred Constraint Satisfaction Problem, henceforth
indicated CSP.
MC-4 algebra formed unions four basic relations,
established two-dimensional spatial regions, morphological point view,
respect equivalence relation congruence.
congruence relation variously interpreted geometry. interpretation
restrictive one: two regions congruent iff rigidly roto-translated
other.
region x, interpretation, may congruent (x CG y) region y, congruent
part (x CGPP y) cannot perfectly overlapped (x CNO y). relation
congruent part may also inverted part congruent (y CGPP,1 x iff
x CGPP y).
Figure 2 pictorial representation three basic relations CG, CGPP CNO
given. Table 1 present composition table MC-4 showing basic relations
compose other.
367

fiCristani

x DR
x

x PO


x



-1

x PP

x PP

x EQ

x

x

x

Figure 3: pictorial representation relations RCC-5.
CSP represented Network Constraints. network constraints
labelled graph G = hV ; ; Ei, V finite set vertices, E binary relation
V whose elements called edges, labelling function maps vertex
G variable, edge relation Constraint Algebra given domain
D. Given network constraints G , problem deciding consistency G
problem establishing whether possible instantiate vertex label (the variables)
elements D, way relations represented G labels
edges simultaneously satisfied. CSP represented network G often referred to,
algebra A, A-SAT(G ). sake simplicity refer CSP represented
network G MC-4 MSAT(G ).
main result MC-4 algebra, respect MSAT, unfortunately negative
computational account. general, deciding consistency hard solve networks
constraints variables representing spatial regions, stated Theorem 2.
result already proved Cristani (1997).
Anger, Mitra Rodriguez (1998), showed path-consistency cannot applied
successfully Algebra Partially Ordered Time, isomorphic MC-4
syntactic level. insucient prove CSP algebra NP-complete.
showed (Anger et al., 1999) PO-time algebra NP-complete. proof lies
translation, shown analogous, identical,
translation
introduced here, syntactical level, completely different semantical
one. However, proof insucient show arrange spatial solutions,
since map defined purely syntactical. already observed Lemon (1996),
representation space means relation algebra pure, obtain
satisfiable networks realizable space. proof, instead, applied
spatial interpretations. applied nonlinear time temporal interpretations
well, since syntactic level shown sucient space, nonlinear time
interpreted space (Anger et al., 1999).
getting proof negative result need describe relevant
correspondences MC-4 algebra RCC-5 model, also used proof
Theorem 2. well known RCC-5 algebra Constraint Algebra 5 basic relations:
EQ , DR , PO , PP , PP,1 . five relations correspond pictorial representation
Figure 3.
two spatial regions one relations MC-4, certain relations
RCC-5 established them. Conversely, certain relations RCC-5
established certain corresponding relations MC-4 are. correspondence, however,
one-to-one. Consider, instance, region x region y, x DR y,
368

fiThe Complexity Reasoning Spatial Congruence

Rel. MC-4 Rel. RCC-5
CG
CGPP
CGPP,1
CNO

fEQ; DR; POg
fPP; DR; POg
fPP,1; DR; POg
fDR; POg

Table 2: basic relations MC-4 counterparts RCC-5. meaning
Table relation MC-4 established, one relations
RCC-5 second column established well.

Rel. RCC-5 Rel. MC-4
EQ
PP
PP,1
PO
DR

CG
CGPP
CGPP,1
fCG; CGPP; CGPP,1; CNOg
fCG; CGPP; CGPP,1; CNOg

Table 3: basic relations RCC-5 counterparts MC-4.
RCC-5, namely x disjoint y. Then, relation MC-4 established
x y. However, x PP y, namely x proper part y, CGPP relation
established x y. hand, two regions congruent,
relations DR , PO EQ exist x y.
Table 3 set correspondences MC-4 basic relations RCC-5,
Table 2 set correspondences RCC-5 MC-4.
correspondences Tables suciently strict, use proving MSAT(MC-4) NP-complete problem direct polynomial reduction.
consider CSP MC-4, corresponding RCC-5 CSP intractable, since
relations obtained Table 2 define intractable subset RCC-5, means
complete classification established Jonsson Drakengren (1997). Therefore,
MSAT(MC-4) reducible RSAT(RCC-5) (the RSAT symbol represents satisfiability RCC models) corresponding relation mapping Table 2.
Conversely, establish, means Tables, among possible
regions satisfying relation CG, exists least one pair regions
EQ, CGPP established, exists one pair PP relation, finally
CNO established, two regions PO relation. summary
correspondence reported Table 4.
correspondence obtained definition basic relations. Two regions
b congruent iff roto-translate way (a) EQ b
conversely 0 0 (b) EQ a. Analogously congruent part b iff
369

fiCristani

Rel. MC-4 Rel. RCC-5
CG
CGPP
CGPP,1
CNO

EQ
PP
PP,1
PO

Table 4: basic relations MC-4 counterparts RCC-5 special mapping
.
roto-translate (a) PP b. Finally two regions CNO relation iff
PO relation disjoint.
correspondence Table 4 called
, Network Constraints G MC-4
translated RCC-5 denoted
(G ). networks labelled edges
basic relations MC-4 henceforth called scenarios MC-4.
Consider consistent scenario MC-4. Applying composition tables MC-4
RCC-5, clearly derive scenario RCC-5
(S ) consistent, scenario
MC-4 so. consequence reasoning next lemma.

Lemma 1 scenario MC-4 consistent,
(G ) consistent.
Ladkin Maddux (1994) proved network constraints consistent iff
consistent scenario. Therefore, immediate consequence Lemma 1 network
constraints G MC-4 consistent,
(G ) consistent. able prove
first theorem.

Theorem 1 MSAT(MC-4) NP-hard.
Proof

observation existence consistent scenarios Constraint Algebra due
Mackworth Freuder (1985), obtain polynomial reduction RSAT(RCC-5)
MSAT(MC-4).
suces note solve MSAT solve RCC-5 problems obtained

translation well. Now, problems mapped MC-4 RCC-5 means

trivially inverted
,1 , since
trivially one-to-one. means
problem set relations obtained RCC-5
corresponds problem MC-4,
vice versa.
set relations RCC-5 translated
contains fPP; PP,1 g PO . Nebel
Renz (1999), proved set relations RCC-5 containing two relations
intractable. Therefore set
(MC , 4) intractable.
proves able solve problem MC-4 solve problem
subset RCC-5 intractable. Therefore MSAT(MC-4) NP-hard.


370

fiThe Complexity Reasoning Spatial Congruence

Mackworth Freuder (1985) also proved backtracking applied CSPs.
backtracking algorithm usually implemented linear non-deterministic technique,
therefore polynomial algorithm non-deterministic machines.
backtracking technique applicable MC-4 well, perform polynomial solution MSAT nondeterministic machines. shows MSAT NP,
allows us claim:

Theorem 2 MSAT(MC-4) NP-complete.
negative result deep investigation needed define tractable subclasses set 16 relations allow us perform polynomial analysis least
subset networks constraints definable MC-4.
paper give definition three maximal tractable subclasses MC4, exhibiting therefore complete classification tractability algebra. three
maximal tractable subclasses already studied Anger, Mitra Rodriguez
(1999). obtain maximality algebras, exhibited O(n3 ) algorithms.
three main differences respect paper:
1. number classes individuated lower theirs, found four
maximal tractable subclasses. failed note one four subalgebras
subset another one. Table 10 subalgebra M88 corresponds fourth
algebra Anger, Mitra Rodriguez. subalgebra tractable, maximal.
2. algorithms exhibit O(n2 ) Anger, Mitra Rodriguez exhibited
O(n3 ) algorithm one three maximal subsets.
3. classification complete. Thus subset MC-4 subset one
three maximal tractable subalgebras individuated intractable. Anger, Mitra
Rodriguez find result, since analyse subalgebras
PO-time algebra, MC-4.

4. Maximal Tractable Subclasses MC-4

Given subset constraint algebra A, indicate Sb set formed
relations written expressions algebra involving elements
operations composition, intersection converse relations. set
often called transitive closure respect operations above. refer
closure . set coincides closure called subalgebra.
previous section recall result NP-completeness MC-4. first
important observation complexity subalgebras that, subalgebra B
contain empty relation, network constraints B cannot entail strict
contradiction: consistent. far, problem necessarily polynomially solvable,
O(1). stated next lemma.

Lemma 2 Given algebra A, subalgebra B contain empty relation,
SAT(B) polynomial.

371

fiCristani

main consequence Lemma 2 limit analysis
subalgebras MC-4 subalgebras contain empty relation.
Moreover, since network constraints represents relations implicit way,
edge network labelled interpret representing universal
relation. Therefore, universal relation member subalgebras
interested in. call algebras contain empty universal
relations expressive algebras.
102 expressive subalgebras, denominate Mi varies 0
101. Tables 5, 6, 7, 8, 10, 9 Appendix A, 102 expressive subalgebras MC-4
listed.

Lemma 3 Given subset MC-4, expressive subalgebra iff one
subalgebras Mi 0 101 .

Proof

Consider subset MC-4. test closure LISP program computes
closure composition, intersection converse subset MC-4, test
presence empty universal relation obvious membership test. LISP
procedure TRANSITIVE-CLOSURE listed Online Appendix 1, accompanies
article. test succeeds subalgebras Mi 0 101 fails
216 , 102 = 65434 subsets MC-4. claim therefore proved.


following technical lemma shows 102 subalgebras individuated
NP-hard. 20 subalgebras 102 intractable Lemma
4. algebras presented Table 5 Appendix A. proof Lemma 5 trivial
consequence proof Theorem 2.

Lemma 4 Given subalgebra MC-4, contains relations CNO fCGPP;
CGPP,1 g MSAT(A) NP-hard.
next three subsections show three maximal tractable subclasses MC-4
found, intractable algebras 20 listed Table 5 Appendix A.

4.1 CG -complete Subalgebra M72

5 tractable, Jonsson Drakengren (1997) observed
proving class R28
subalgebra RCC-5 containing relations including EQ tractable.
result applies also MC-4 respect relation CG, also relations CNO,
fCGPP; CGPP,1g, fCG; CNOg, fCG; CGPP; CGPP,1g.
relevant cases CG , CNO fCGPP; CGPP,1 g , since two
cases included two former three. algebra formed relations
contain CG relation ? tractable, obtain inconsistency
iff explicitly edge labelled ? network. Deciding consistency
therefore O(n2 ) problem.

372

fiThe Complexity Reasoning Spatial Congruence

ALGORITHM M72-CONSISTENCY
constraint network M72

INPUT:

OUTPUT:

1.

2.

Yes solution formed spatial regions R2 , not.



edge , hx; yi
label hx; ?

return inconsistency

Loop

Return consistency
Figure 4: Algorithm M72-consistency.

M72 = f?, CG, fCG; CGPPg, fCG; CGPP,1g, fCG; CNOg, fCG; CGPP; CGPP,1g,
fCG; CGPP; CNOg, fCG; CGPP,1; CNOg, >g.
Since contradiction derives relation M72 except ?, Algorithm M72 -consistency
(see Figure 4) solves consistency checking problem network constraints M72 .
Thus claim following theorem:

Theorem 3 Algorithm M72 -consistency correctly decides consistency network
constraints M72 O(n2 ) time n number vertices .
immediate consequence Theorem 3 following theorem:

Theorem 4 MSAT(M72 ) polynomial.
subalgebras included M72 Table 6 Appendix A.
13 subalgebras Table 6 subalgebras theoretically
obtained based method incorporated Algorithm M72 -consistency. algorithm applied subalgebras formed relations containing symmetrical
relation MC-4 empty relation. also prove polynomiality
subalgebras relations containing CNO, containing fCGPP; CGPP,1 g, subalgebras exist. subalgebra formed relations containing CNO empty relation
M78 , subalgebra formed relations containing fCGPP; CGPP,1 g M31 .
Table 7 Table 8 Appendix subalgebras M78 M31 shown.
next subsection introduce maximal tractable subclass includes M78 ,
subsection 4.3 introduce algebra containing M31 , proof tractability subalgebras Tables 7 8 derived tables well. Conversely,
subalgebra M72 neither subalgebra M99 subalgebra M81 , Theorem 3
independent result.
373

fiCristani

4.2 Maximal Tractable Subclass M99

look maximal tractable subalgebra containing basic relations. best
candidate, based Table 5, M99 , algebra formed 13
relations polynomial, show NP-hard reducing
intractable problem RCC-5.
M99 = f?, CG, CGPP, CGPP,1, CNO, fCG; CGPPg, fCG; CGPP,1g, fCG; CNOg,
fCGPP; CNOg, fCGPP,1 ; CNOg, fCG; CGPP; CNOg, fCG; CGPP,1; CNOg, >g.
Fortunately, prove tractability M99 , maximal based fact
algebras containing basic relations either intractable Table 5 subsets
M99 .
Consider subset M99 ,
G99 = ffCG; CGPPg, fCG; CNOg, fCGPP; CGPP,1; CNOgg.
following claim holds.

Lemma 5 Gd99 = M99 .
Proof

following expressions represent valid implementations relations M99 using
elements G99 operators composition, intersection converse.
t.1.

?

= fCG; CGPPg

t.2.

CG

fCG; CNOg
fCGPP; CGPP,1; CNOg
= fCG; CGPPg fCG; CGPPg ^



t.3.

CGPP

= fCG; CGPPg fCGPP; CGPP,1 ; CNOg

t.4.

CGPP,1

= fCG; CGPPg ^ fCGPP; CGPP,1 ; CNOg

t.5.

CNO

= fCG; CNOg fCGPP; CGPP,1 ; CNOg

t.6.

>

= fCG; CGPPg
fCGPP; CGPP,1 ; CNOg

t.7.

fCG; CGPP,1g

= fCG; CGPPg ^

t.8.

fCGPP; CNOg

= (fCG; CGPPg

t.9.

fCGPP,1; CNOg

t.10. fCG; CGPP; CNOg


fCG; CNOg )
fCGPP; CGPP,1; CNOg
= (fCG; CGPPg ^
fCG; CNOg )
fCGPP; CGPP,1; CNOg
= fCG; CGPPg
fCG; CNOg

t.11. fCG; CGPP,1 ; CNOg

= fCG; CGPPg ^
fCG; CNOg
374

fiThe Complexity Reasoning Spatial Congruence


network constraints M99 , implemented means Lemma 5 denoted henceforth 99 (T ).
derive contradiction network constraints iff network derives two
relations R1 R2 , one pair vertices R1 \ R2 = ?. ways
contradiction derived networks labelled relations M99 , based
intersections relations (except empty relation obviously generates contradiction itself) are:
a)
b)
c)
d)
e)
f)
g)
h)
i)
l)
m)
n)

CG
CG
CG
CG
CGPP
CGPP
CGPP
CGPP
CGPP
CGPP
CNO
fCG; CGPPg














CGPP
CNO
fCGPP; CNOg
fCGPP; CGPP,1; CNOg
CGPP,1
CNO
fCG; CGPP,1g
fCG; CNOg
fCGPP,1 ; CNOg
fCG; CGPP,1; CNOg
fCG; CGPPg
fCGPP,1 ; CNOg

simply obtained considering pairs relations M99 whose intersection
empty.
G99 contradictions only:
fCG; CGPPg fCG; CGPPg ^ fCGPP; CGPP,1; CNOg
fCG; CGPPg fCG; CNOg fCGPP; CGPP,1 ; CNOg .
Henceforth represent relation fCG; CGPPg -, relation fCG; CNOg ./
relation fCGPP; CGPP,1 ; CNOg 6. Since path labels corresponds representation - pair vertices path,
./ = -, possible expressions contradictions G99 (-n
-,n) 6 (-n

-,(n,k)
./
-,k ) 6. Hence, cycle (-n
-,n) called --cycle, cycle
(-n
-,(n,k)
./
-,k ) called quasi --cycle. graph representation
two different contradictory situations G99 showed Figure 5. --cycle quasi
--cycle, M99 force elements involved cycle relation CG .
show contradictions represented G99 contradictions
obtained implementation suggested Lemma 5. important,
may perform consistency checking simply checking cycles. result
stated next lemma.

Lemma 6 Given network constraints M99 , inconsistent iff 99(T ) contains
either --cycle quasi --cycle, two vertices one cycle connected edge
labelled 6.
375

fiCristani

Proof (Sketch)

Case case, contradictions a) n), table above, generate one
two situations claim.
example, contradiction a) CG CGPP , generates
(fCG; CGPPg
fCG; CGPPg ^ ) (fCG; CGPPg fCGPP; CGPP,1 ; CNOg )
--cycle two vertices connected edge labelled 6, stated
claim. cases behave way easily checked
reader.
Conversely, contradiction derives one possible implicit ways representing relations M99 , implementation also produces one cases claim.
particular that, M99 , CGn = CG , CGPPn = CGPP , (CGPP,1 )n = CGPP,1 ,
fCG; CGPPgn = fCG; CGPPg fCG; CGPP,1 gn = fCG; CGPP,1g idempotent relations. cases implicitness obtained considering
14 14 = 196 pairs relations M99 , composing intersecting them. implicit cases
arising thus listed below.
i.1.

CG

= fCG; CGPPgn fCG; CGPP,1 gn

i.2.

CG

= fCG; CGPPgn fCG; CNOg

i.3.

CGPP

= fCG; CGPPgn fCGPP; CNOg

i.4.

CNO

= fCG; CNOg fCGPP; CNOg

i.5.

CNO

= fCGPP; CNOg fCGPP,1 ; CNOg

i.6.

CNO

= fCGPP; CNOg fCG; CGPP,1 ; CNOg

i.7.

fCG; CNOg

= fCG; CGPP; CNOg

i.8.

fCGPP; CNOg

= CGPPn
CNO

i.9.

fCGPP; CNOg

= CGPPn
fCG; CNOg

fCG; CGPP,1; CNOg



i.10. fCGPP; CNOg

= CGPPn
fCG; CGPP; CNOg

i.11. fCGPP; CNOg

= fCG; CGPPgn
CNO

i.12. fCGPP; CNOg

= fCG; CGPP; CNOg

fCGPP; CGPP,1; CNOg
i.13. fCG; CGPP; CNOg = fCG; CGPPgn
fCG; CNOg



Readers may directly express G99 relations along corresponding
376

fiThe Complexity Reasoning Spatial Congruence

Figure 5: Contradictions G99 : fg indicates ? R, S, respectively fCG; CGPPg,
fCG; CNOg fCGPP; CGPP,1; CNOg.
relation producing contradiction M99 immediately verify existence -cycles quasi --cycle one pair vertices connected edge labelled 6
generated graphs.
example express CG implicit relation i.1. table (formed
relations G99 ), CGPP implicit relation i.3. fCGPP; CNOg 99 t.8.,
consider contradiction CG CGPP obtain quasi --cycle two vertices
connected edge labelled 6. Similarly derive cases.



exhibit algorithm looks --cycles quasi --cycles,
checks pairs cycle connected edge labelled 6.
Figure 7 algorithm able solve Consistency Checking Problem networks
constraints labelled relations M99 presented. Based Lemma 6 prove
following theorem.
Theorem 5 Algorithm M99-CONSISTENCY correctly decides consistency network constraints M99 O(n2 ) steps n number vertices .

Proof

Lemma 6 ensure correctness Algorithm M99-CONSISTENCY. complexity algorithm derived fact computation strongly
377

fiCristani

Figure 6: Contradictions M99 : R, S, respectively indicate fCG; CGPPg,
fCG; CNOg fCGPP; CGPP,1; CNOg. Letters a) n) refer
table page 375.
378

fiThe Complexity Reasoning Spatial Congruence

ALGORITHM M99-CONSISTENCY
constraint network M99

INPUT:

OUTPUT:

1.
2.
3.
4.
2.

Yes solution formed spatial regions R2 , not.

Translate generator set Lemma 5
Look cycles labelled - one ./
Check whether edges two vertices one cycle labelled 6
otherwise return no.
Substitute vertices cycle one vertex.
cycles go Step 2., otherwise return yes.
Figure 7: Algorithm M99-consistency

connected components O(e) problem e number edges network.
99 implementation adds, worst case, O(e0 ) edges, e0 number
edges , therefore number edges 99 (T ) O(2 e0 ), O(n2 ).



immediate consequence Theorem 5 following theorem:

Theorem 6 MSAT(M99 ) polynomial.
subalgebras MC-4 included M99 Table 10 Appendix A.

4.3 Maximal Tractable Subclass M81

problem deciding consistency network constraints MC-4 tractable,
means Tables 6, 7, 8 10 85 subalgebras. remainder formed 17
subalgebras, either tractable intractable. set
M81 = f ?, CG, CGPP, CGPP,1, fCG; CGPPg, fCG; CGPP,1g, fCGPP; CGPP,1g,
fCG; CGPP; CGPP,1g, fCGPP; CGPP,1 ; CNOg, >g
contains subalgebras, M81 tractable algebras well.
analogy schema previous section look small generator set
M81 . G81 = ffCG; CGPPg, fCG; CGPP; CGPP,1 g, fCGPP; CGPP,1 ; CNOgg.
following lemma states properties M81 respect G81 .
Lemma 7 Gd81 = M81 .

Proof

following expressions represent valid implementations relations M81 using
elements G81 operators composition, intersection converse.
379

fiCristani

r.1. ?

= fCG; CGPPg fCG; CGPPg

r.2. CG

= fCG; CGPPg fCG; CGPPg ^

r.3. CGPP

= fCG; CGPPg fCGPP; CGPP,1 ; CNOg

r.4. CGPP,1

= fCG; CGPPg ^ fCGPP; CGPP,1 ; CNOg

r.5. fCG; CGPP,1 g

= fCG; CGPPg ^

fCGPP; CGPP,1 ; CNOg

r.6. fCGPP; CGPP,1 g = fCG; CGPP; CGPP,1 g

fCGPP; CGPP,1 ; CNOg

^



= fCG; CGPPg
fCGPP; CGPP,1 ; CNOg

r.7. >


implementation relations M81 described Lemma 7 denoted 81 .
contradictions M81 next table.
a)
b)
c)
d)
e)

CG
CG
CG
CGPP
CGPP







CGPP
fCGPP; CGPP,1g
fCGPP; CGPP,1; CNOg
CGPP,1
fCG; CGPP,1g

possible contradiction G81

fCG; CGPPg fCG; CGPPg ^ fCGPP; CGPP,1; CNOg
corresponds --cycle two vertices connected edge labelled 6.
Lemma 8 Given network constraints M81 , inconsistent iff 81(T ) contains
--cycle two vertices one cycle connected edge labelled 6.
Proof (Sketch)

Case case, contradictions a) e), table above, generate one
two cases claimed here.
example, contradiction CG fCGPP; CGPP,1 g , implemented
(fCG; CGPPg fCG; CGPPg ^ ) (fCG; CGPP; CGPP,1 g
fCGPP; CGPP,1; CNOg )
--cycle two vertices connected edge labelled 6, stated
claim. cases behave way easily checked
reader.
possible ways representing implicit relations provided schema
81 . Therefore claim proved.
380

fiThe Complexity Reasoning Spatial Congruence

Figure 8: Contradictions M81 .
R, S, respectively indicate fCG; CGPPg,
,
1
fCG; CGPP; CGPP g, fCGPP; CGPP,1; CNOg. Letters a) e) refer
table page 380.

ALGORITHM M81-CONSISTENCY
constraint network M81

INPUT:

OUTPUT:

1.
2.
3.
4.
2.

Yes solution formed spatial regions R2 , not.

Translate generator set Lemma 7
Look cycles labelled Check whether edges two vertices one cycle labelled 6
otherwise return no.
Substitute vertices cycle one vertex.
cycles go Step 2., otherwise return yes.
Figure 9: Algorithm M81-consistency
381

fiCristani


Figure 9 algorithm presented solves problem consistency checking
subalgebra M81 . show, particular, following claim.

Theorem 7 Algorithm M81-CONSISTENCY correctly decides consistency network constraints M81 O(n2 ) steps n number vertices .
Proof

Lemma 8 ensure correctness Algorithm M81-CONSISTENCY. complexity algorithm derived fact computation strongly
connected components O(e) problem e number edges network.
81 implementation adds, worst case, O(e0 ) edges, e0 number
edges , therefore number edges 81 (T ) O(2 e0 ), clearly O(n2 ).


immediate consequence Theorem 3 following

Theorem 8 MSAT(M81 ) polynomial.
subalgebras included M81 Table 9 Appendix A.

5. Conclusions

presented classification tractability complete spatial algebra MC-4.
classification states exist three maximal tractable subalgebras M72 , M99
M81 include 92 102 expressive subalgebras MC-4.
interest complete classifications tractability, already observed Jonsson
Drakengren (1997), determined need definition boundary
tractable intractable problems. Nebl (1999) suggested knowledge
boundary used either preprocessing step way structure backtracking
search algebras.
provision complete classification one step researching constraint
algebras. next step individuation useful heuristics give improvements
performances various techniques. currently exploiting use techniques
association techniques based classification presented paper obtain
ecient reasoning algorithms used practice. Preliminary results pathconsistency encouraging, cannot yet guarantee percentage improvement,
since algebra MC-4 simply structured networks randomly chosen
hard obtain case inconsistency detectable path-consistency.

Acknowledgements

would like thank Elena Mutinelli developed Laurea Thesis (Mutinelli, 1998)
theme complexity reasoning congruence first discussed preliminary
382

fiThe Complexity Reasoning Spatial Congruence

results used developing classification paper. work
relevant reaching results.
would also like thank Bernhard Nebel important observations made
student mine, Alessandro Fin, improved work. thanks go Jochen
Renz discussions early stages work.
would also like thank anonymous referees Journal Artificial Intelligence
Research careful comments suggestions allowed make
presentation simpler systematical. proofs paper
rewritten thanks suggestions.
Finally would like thank Tony Cohn reading near final version. comments
useful enhancing scientific literary quality paper.
work developed context National Project, MURST ex 40%
\Metodologie e tecnologie per la gestione di dati e processi su reti internet ed intranet"
(Methods technologies data process management internet intranet)
directed L. Tanca.

383

fiCristani

Appendix A. Tables 102 subalgebras MC-4

section present subalgebras MC-4 organized separated tables depending
characteristics. particular Table 5 shows subalgebras intractable
Lemma 4, Table 6 tractable Theorem 3, Tables 7, 8
Algorithm used Theorem 3 applied (which including CNO
fCGPP; CGPP,1g ). Table 10 subalgebras included M99 displyed,
Table 9 present subalgebras included M81 .
Rel.

Alg.

M30
M43
M44
M46
M54
M56
M67
M77
M83
M84
M85
M89
M90
M92
M93
M95
M97
M98
M100
M101



CG
CGPP
CGPP,1
CNO



























































































































































































































Table 5: subalgebras MC-4 containing relations CNO fCGPP; CGPP,1 g

384

fiThe Complexity Reasoning Spatial Congruence



Rel. CG

Alg.

M0
M1
M3
M5
M9
M12
M18
M22
M25
M34
M38
M63
M72

CGPP
CGPP,1
CNO















M2
M6
M10
M15
M24
M28
M37
M39
M47
M58
M64
M78





































CGPP
CGPP,1
CNO








































































Table 6: subalgebras MC-4 contained M72 .

Rel. CG

Alg.








































Table 7: subalgebras MC-4 contained M78 contained M72 .
385

fiCristani



Rel. CG

Alg.

CGPP
CGPP,1
CNO






















Table 8: subalgebras MC-4 contained M31 contained M72 M78 .
M4
M13
M16
M31

Rel. CG

Alg.

M11
M20
M21
M23
M29
M32
M33
M35
M42
M45
M55
M59
M60
M66
M70
M74
M81

CGPP
CGPP,1
CNO





























































































































Table 9: subalgebras MC-4 contained M81 contained M99 M72
M78 M31 .

386

fiThe Complexity Reasoning Spatial Congruence



Rel. CG

Alg.

CGPP
CGPP,1
CNO




































































































































Table 10: subalgebras MC-4 contained M99 contained M72 M78
M31 .
M7
M8
M14
M17
M19
M26
M27
M36
M40
M41
M48
M50
M51
M52
M57
M61
M62
M65
M68
M69
M71
M73
M75
M76
M79
M80
M82
M86
M87
M88
M91
M94
M96
M99








































387

fiCristani

References
Anger, F., Mitra, D., & Rodriguez, R. (1998). Temporal Constraint Networks Nonlinear
Time. Workshop Notes Spatial Temporal Reasoning ECAI98 Brighton,
UK.
Anger, F., Mitra, D., & Rodriguez, R. (1999). Satisfiability Nonlinear Time: Algorithms
Complexity. Proceedings Florida Artificial Intelligence Research Society
conference Orlando (USA).
Bennett, B. (1994). Spatial reasoning propositional logic. Doyle, J., Sandewall, E.,
& Torasso, P. (Eds.), Proceedings 4th International Conference Principles
Knowledge Representation Reasoning (KR-94), pp. 165{176. Morgan Kaufmann,
San Francisco, CA, USA.
Bennett, B. (1995). Carving Space: Existential Axioms Formal Theory Spatial
Regions. Proceedings IJCAI 95 Workshop Spatial Temporal Reasoning
Montreal.
Borgo, S., Guarino, N., & Masolo, C. (1996). Pointless Theory Space Based
Strong Connection Congruence. Aiello, L. C., & Doyle, J. (Eds.), Proceedings
6th International Conference Principles Knowledge Representation
Reasoning (KR-96). Morgan Kaufmann, San Francisco, CA, USA.
Borgo, S., Guarino, N., & Masolo, C. (1997). Ontological Theory Physical Objects.
Ironi, L. (Ed.), Proceedings Eleventh International Workshop Qualitative
Reasoning (QR 1997), pp. 223{231 Cortona, Italy.
Clarke, B. L. (1981). Calculus Individuals Based \Connection". Notre Dame
Journal Formal Logic, 22, 204{218.
Cook, S. A. (1971). complexity theorem-proving procedures. Proceedings
3rd Symposium Theory Computation, pp. 151{158.
Cristani, M. (1997). Morphological Spatial Reasoning: Preliminary Report. Tech. rep.
08/97, LADSEB-CNR Padova (Italy).
Cui, Z. (1994). Using interval logic order assembly. Proceedings Second International Conference Intelligent Systems Molecular Biology, pp. 103{111. AAAI
Press.
Drakengren, T., & Jonsson, P. (1997). Twenty-one large tractable subclasses Allen's
algebra. Artificial Intelligence, 93 (1-2), 297{319.
Egenhofer, M. J. (1991). Reasoning binary topological relations. Gunther, O., &
Schek, H. J. (Eds.), Advances Spatial Databases-Second Symposium SSD '91, No.
525 Lecture Notes Computer Science, pp. 143{160. Springer-Verlag, New York,
NY, USA.
388

fiThe Complexity Reasoning Spatial Congruence

Egenhofer, M. J., & Franzosa, R. (1991). Point-Set Topological Spatial Relations. International Journal Geographical Information Systems, 5 (2), 161{174.
Egenhofer, M. J., & Herring, J. (1990). Mathematical Framework Definition
Topological Relationships. Fourth International Symposium Spatial Data
Handling, pp. 803{813 Zurich, Switzerland.
Franzosa, R., & Egenhofer, M. J. (1992). Topological Spatial Relations Based Components Dimensions Set Intersections. SPIE's OE/Technology '92-Vision
Geometry Boston, ,USA.
Gotts, N. M. (1994). Far \C"? defining \Doughnut" Using Connection
Alone. Doyle, J., Sandewall, E., & Torasso, P. (Eds.), Proceedings 4th
International Conference Principles f Knowledge Representation Reasoning
(KR-94), pp. 246{257. Morgan Kaufmann, San Francisco, CA, USA.
Gotts, N. M., Gooday, J. M., & Cohn, A. G. (1996). Connection Based Approach
Commonsense Topological Description Reasoning. Monist: International
Journal General Philosofical Inquiry, 79 (1).
Grigni, M., Papadias, D., & Papadimitriou, C. (1995). Topological Inference. Mellis, C.
(Ed.), Proceeding 14th International Joint Conference Artificial Intelligence
(IJCAI-95), pp. 901{906 Montreal, PQ, Canada. Morgan Kaufmann.
Jonsson, P., & Drakengren, T. (1997). Complete Classification Tractability Spatial Theory RCC-5. Journal Artificial Intelligence Research, 6, 211{221. Research
Note.
Jonsson, P., Drakengren, T., & Backstrom, C. (1999). Computational complexity relating
time points intervals. Artificial Intelligence, 109 (1-2), 273{295.
Ladkin, P., & Maddux, R. (1994). Binary Constraint Problems. Journal ACM,
41 (3), 435{469.
Lemon, O. J. (1996). Semantical Foundations Spatial Logics. Aiello, L. C., & Doyle, J.
(Eds.), Proceedings 6th International Conference Principles f Knowledge
Representation Reasoning (KR-96). Morgan Kaufmann, San Francisco, CA, USA.
Mackworth, A., & Freuder, C. (1985). complexity polynomial network consistency algorithms constraint satisfation problems. Artificial Intelligence, 25 (1),
65{74.
Mutinelli, E. (1998). Sviluppo ed Analisi di Algoritmi per il Ragionamento Spaziale Qualitativo con Reti di Vincoli. Laurea thesis, Universita di Verona. Italian.
Nebel, B. (1995). Computational properties qualitative spatial reasoning: First results.
Advances artificial intelligence (KI-95), pp. 233{244 Bielefeld, Germany. SpringerVerlag, New York, NY, USA.
389

fiCristani

Nebel, B. (1999). Observations complexity reasoning constraint algebras.
Personal communication A. Fin M. Cristani.
Nebel, B., & Burckert, H. J. (1995). Reasoning temporal relations: maximal
tractable subclass Allen's interval algebra. Journal ACM, 42 (1), 43{66.
Randell, D. A., & Cohn, A. G. (1989). Modelling topological metrical properties
physical processes. Brachman, R. J., Levesque, H. J., & Reiter, R. (Eds.),
Proceedings 1st International Conference Knowledge Representation
Reasoning (KR-89), pp. 55{66 Toronto, ON, Canada. Morgan Kaufmann.
Randell, D. A., Cui, Z., & Cohn, A. G. (1992). spatial logic based regions
connection. Swartout, B., & Nebel, B. (Eds.), Proceedings 3rd International
Conference Principles Knowledge Representation Reasoning (KR-92), pp.
165{176 Cambridge, MA, USA. Morgan Kaufmann.
Renz, J. (1999). Maximal Tractable Fragments Region Connection Calculus:
Complete Analysis. Proccedings 17th International Conference Artificial
Intelligence (IJCAI 99).
Renz, J., & Nebel, B. (1999). complexity qualitative spatial reasoning: maximal
tractable fragment Region Connection Calculus. Artificial Intelligence, 108 (12), 69{123.
Statman, R. (1979). Intuitionistic logic polynomial-space complete. Theoretical Computer
Science, 9 (1), 67{72.
Zimmermann, K. (1995). Measuring without Measures: -Calculus. Proceedings
International Conference Spatial Information, pp. 59{67.

390

fiJournal Artificial Intelligence Research 11 (1999) 277-300

Submitted 5/99; published 10/99

Reasoning Minimal Belief Negation Failure
Riccardo Rosati

rosati@dis.uniroma1.it

Dipartimento di Informatica e Sistemistica
Universita di Roma \La Sapienza"
Via Salaria 113, 00198 Roma, Italy

Abstract
investigate problem reasoning propositional fragment MBNF,
logic minimal belief negation failure introduced Lifschitz, considered unifying framework several nonmonotonic formalisms, including default
logic, autoepistemic logic, circumscription, epistemic queries, logic programming.
characterize complexity provide algorithms reasoning propositional MBNF.
particular, show skeptical entailment propositional MBNF p3 -complete,
hence harder reasoning mentioned propositional formalisms
nonmonotonic reasoning. also prove exact correspondence negation
failure MBNF negative introspection Moore's autoepistemic logic.

1. Introduction
Research formalization commonsense reasoning pointed need formalizing agents able reason introspectively knowledge ignorance
(Moore, 1985; Levesque, 1990). Modal epistemic logics thus proposed,
modalities interpreted terms knowledge belief. Generally speaking, conclusions introspective agent able draw depend knows
know. Hence, conclusion may retracted new facts added
agent's knowledge. reason, many nonmonotonic modal formalisms
proposed order characterize reasoning abilities introspective agent.
Among nonmonotonic modal logics proposed literature, logic minimal
belief negation failure MBNF (Lifschitz, 1991, 1994) one studied formalisms (Chen, 1994; Bochman, 1995; Beringer & Schaub, 1993). Roughly speaking,
logic built adding first-order logic two distinct modalities, \minimal belief"
modality B \negation failure" modality . logic thus obtained characterized terms nice model-theoretic semantics. MBNF used order
give declarative semantics general classes logic programs (Lifschitz & Woo,
1992; Schwarz & Lifschitz, 1993; Inoue & Sakama, 1994), generalize stable model
semantics negation failure logic programming (Gelfond & Lifschitz, 1988, 1990,
1991). Also, MBNF viewed extension theory epistemic queries
databases (Reiter, 1990), deals problem querying first-order database
knowledge. Due ability expressing many features nonmonotonic
logics (Lifschitz, 1994; Schwarz & Lifschitz, 1993), MBNF generally considered unifying framework several nonmonotonic formalisms, including default logic, autoepistemic
logic, circumscription, epistemic queries, logic programming.

c 1999 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiRosati

Although several aspects logic MBNF thoroughly investigated (Schwarz
& Lifschitz, 1993; Chen, 1994; Bochman, 1995), existing studies concerning computational properties MBNF limited subclasses propositional MBNF theories
(Inoue & Sakama, 1994) restricted subset first-order case (Beringer &
Schaub, 1993).
paper present computational characterization deduction propositional fragment MBNF. particular, show logical implication propositional fragment MBNF p3 -complete problem: hence, harder (unless polynomial hierarchy collapses) reasoning best known propositional formalisms
nonmonotonic reasoning, like autoepistemic logic (Niemela, 1992; Gottlob, 1992), default logic (Gottlob, 1992), circumscription (Eiter & Gottlob, 1993), (disjunctive) logic
programming (Eiter & Gottlob, 1995), several McDermott Doyle's logics (Marek
& Truszczynski, 1993). shown following, result also implies minimal
knowledge computationally harder negation failure.
Moreover, study subclass MBNF theories, i.e. MBNF theories without nested occurrences modalities, showing case logical implication p2 complete. case interesting one logic programming viewpoint.
Indeed, implies that, stable model semantics, increasing syntax program
rules, allowing propositional formulas goals rules, affect worst-case
complexity query answering disjunctive logic programs negation failure.
Furthermore, provide algorithms reasoning MBNF fragment,
optimal respect worst-case complexity. Notably, deductive methods
considered generalizations known methods reasoning nonmonotonic
formalisms default logic, autoepistemic logic, logic programming stable
model semantics.
also show \negation failure" modality MBNF exactly corresponds
negative introspection autoepistemic logic (Moore, 1985). result implies
logic MBNF considered \composition" two epistemic modalities:
\minimal knowledge" operator due Halpern Moses (1985) Moore's autoepistemic
operator.
Besides theoretical interest, believe computational epistemological
analysis MBNF interesting implications development knowledge representation systems nonmonotonic abilities, since allows better understanding
comparison different nonmonotonic formalisms captured MBNF. interest
defining deductive methods MBNF also arises fact logic, originally
developed framework comparison different logical approaches nonmonotonic reasoning, recently considered attractive knowledge representation
formalism. particular, shown (Donini, Nardi, & Rosati, 1997a) full
power MBNF necessary order logically formalize several features implemented
frame-based knowledge representation systems.
following, first brie recall logic MBNF. Section 3 address
relationship MBNF Moore's autoepistemic logic. Then, Section 4 study
problem reasoning propositional MBNF: first consider case general MBNF
theories, deal MBNF theories. Section 5 present computational
278

fiReasoning minimal belief negation failure

characterization reasoning MBNF. conclude Section 6. paper extended
thoroughly revised version (Rosati, 1997).

2. Logic MBNF

section brie recall logic MBNF (Lifschitz, 1994), modal logic
two epistemic operators: \minimal belief" modality B \negation failure"
(also called \negation default") modality . use L denote fixed propositional
language built usual way from: (i) alphabet propositional symbols; (ii)
symbols true, false; (iii) propositional connectives _; ^; :; . denote LM
modal extension L modalities B . say formula ' 2 LM
(modal) depth (with 0) subformula ' lies within scope
modalities, exists subformula ' lies within scope exactly
modalities.
denote LSM set subjective MBNF formulas, i.e. subset formulas
LM occurrence propositional symbol lies within scope least one
modality, L1M set MBNF formulas, set formulas LM
propositional symbol lies within scope exactly one modality. call
modal formula ' LM positive (resp. negative ) modality (resp. B )
occur '. LB denotes set positive formulas LM , LSB denotes set
positive formulas LSM .
recall notion MBNF model. interpretation set propositional
symbols. MBNF structure triple (I; Mb ; Mn ), interpretation (also called
initial world) Mb ; Mn non-empty sets interpretations (worlds). Satisfiability
formula MBNF structure defined inductively follows:
1. ' propositional symbol, ' satisfied (I; Mb ; Mn ) iff ' 2 ;
2. :' satisfied (I; Mb ; Mn ) iff ' satisfied (I; Mb ; Mn );

3. '1 ^ '2 satisfied (I; Mb ; Mn ) iff '1 satisfied (I; Mb ; Mn ) '2 satisfied
(I; Mb ; Mn );

4. '1 _ '2 satisfied (I; Mb ; Mn ) iff either '1 satisfied (I; Mb ; Mn ) '2
satisfied (I; Mb ; Mn );
5. '1 '2 satisfied (I; Mb ; Mn ) iff either '1 satisfied (I; Mb ; Mn ) '2
satisfied (I; Mb ; Mn );
6. B' satisfied (I; Mb ; Mn ) iff, every J 2 Mb , ' satisfied (J; Mb ; Mn );

7. ' satisfied (I; Mb ; Mn ) iff exists J 2 Mn ' satisfied
(J; Mb ; Mn ).
write (I; Mb ; Mn ) j= ' indicate ' satisfied (I; Mb ; Mn ). say
theory LM satisfied (I; Mb ; Mn ) (and write (I; Mb ; Mn ) j= ) iff formula
satisfied (I; Mb ; Mn ). ' 2 LSM , evaluation ' insensitive
initial interpretation : thus, case also write (Mb ; Mn ) j= '. Analogously,
279

fiRosati

' 2 LSB , evaluation ' insensitive initial interpretation
set Mn , also write Mb j= '. ' 2 L evaluation ' depend
sets Mb ; Mn , case write j= '.

order relate MBNF structures standard interpretation structures modal
logic (i.e. Kripke structures), remark that, due notion satisfiability,
consider sets Mb , Mn MBNF interpretation structure two distinct
universal Kripke structures, i.e. possible-world structures world connected
worlds structure. fact, since accessibility relation structure
universal, without loss generality possible identify universal Kripke structure
set interpretations contained it. recall class universal Kripke
structures characterizes logic S5 (Marek & Truszczynski, 1993, Theorem 7.52).
nonmonotonic character MBNF obtained imposing following preference
semantics interpretation structures satisfying given theory.

Definition 2.1 structure (I; M; ), 6= ;, MBNF model theory
LM iff (I; M; ) j= and, interpretation J set interpretations
0, 0 (J; 0 ; ) 6j= .
say formula ' entailed (or logically implied ) MBNF (and write
j=MBNF ') iff ' satisfied every MBNF model . order simplify notation,
denote MBNF model (I; M; ) pair (I; ), and, 2 LSM , denote
(I; M; ) , since case evaluation insensitive initial world ,
namely, (I; ) model , then, interpretation J , (J; ) model .

Example 2.2 Let = fBpg. MBNF models form (I; ),
= fI : j= pg. Hence, j=MBNF Bp, j=MBNF :B 2 L
propositional formula p valid. Therefore, agent modeled minimal
belief, sense believes p objective facts logically implied p.

Example 2.3 Let = fnot married B hasNoChildren g. easy see
models form (I; ) = fI : j= hasNoChildren g, since married
assumed hold agent modeled , able conclude
::married
B hasNoChildren . Notably, meaning analogous default rule hasNoChildren
Reiter's default logic (Lifschitz, 1994). Also, let = fB bird ^ : ies B ies ; B bird g.

way analogous previous case, shown MBNF models
form (I; ), = fI : j= bird ^ ies g. Therefore, j=MBNF B ies .
: ies g; bird ).
shown Lifschitz (1994), corresponds default theory (f bird ies

Given set interpretations , Th(M ) denotes set formulas B'
B' 2 LB j= B'. Let M1; M2 sets interpretations. say M1
equivalent M2 iff Th(M1 ) = Th(M2 ).

Definition 2.4 set interpretations maximal iff, set interpretations
0, 0 equivalent 0 .
280

fiReasoning minimal belief negation failure

turns that, restricting theories composed subjective positive formulas,
MBNF corresponds modal logic minimal knowledge due Halpern Moses
(1985), also known ground nonmonotonic modal logic S5G (Kaminski, 1991; Donini,
Nardi, & Rosati, 1997b). fact, S5G obtained modal logic S5 imposing
following preference order universal Kripke structures satisfying theory 2 LB :
model iff j= and, 0 , 0 j= 0 6 (Shoham,
1987). fact, immediate see MBNF semantics theories composed
subjective positive formulas corresponds semantics according S5G . Hence,
following property holds.

Proposition 2.5 Let LB . Then, S5G model iff, , (I; )
MBNF model fB' : ' 2 g.
previous proposition implies that, LSB , set interpretations satisfying compared sets interpretations satisfying , while, case
LM , compared sets 0 (M 0 ; ) satisfies .

Hence, main difference MBNF S5G lies fact S5G models
maximal respect set containment (or minimal respect objective
knowledge holds model), MBNF property generally true.
E.g., theory = fnot married _ B married g two types models, possible
choice initial world J : (J; M1 ), M1 corresponds set interpretations
(which represents case married assumed hold); (J; M2 ),
M2 = fI : j= married g. Namely, married assumed hold, forces one
conclude B married : is, initial assumption justified knowledge derived
basis assumption (Lin & Shoham, 1992). remark that, Proposition 2.5,
interpretation MBNF operator B exactly corresponds interpretation
modality B S5G .

3. Relating MBNF Autoepistemic Logic

section study relationship autoepistemic logic MBNF. First,
brie recall Moore's autoepistemic logic (AEL). order keep notation minimum,
change language AEL, using modality B instead L. Thus, following
formula AEL formula LB .

Definition 3.1 propositionally consistent set formulas LB stable expansion
set initial knowledge LB satisfies following equation:
= Cn( [ fB' j ' 2 g [ f:B' j ' 62 g)
(1)
Cn(S ) denotes propositional deductive closure modal theory LB .
Given theory LB formula ' 2 LB , write j=AEL ' iff ' belongs
stable expansions . stable expansion stable set according
following definition (Stalnaker, 1993).

Definition 3.2 modal theory LB stable set
281

fiRosati

1. = Cn(T );
2. every ' 2 LB , ' 2 B' 2 ;
3. every ' 2 LB , ' 62 :B' 2 .

recall stable set corresponds maximal universal Kripke structure MT
set formulas satisfied MT (Marek & Truszczynski, 1993).
term AEL model thus refer set interpretations whose set theorems
Th(M ) corresponds stable expansion AEL.
Finally, notice adopted notion consistent autoepistemic logic (Marek
& Truszczynski, 1993), i.e. (1) allow inconsistent theory = LB composed
modal formulas (possible) stable expansion. results presented
section easily extended case (corresponding Moore's original proposal):
however, requires slightly change semantics MBNF, allowing Definition 2.1
empty set interpretations possible component MBNF structures.
following, use term embedding (or translation) indicate transformation
function () modal theories. interested finding faithful embedding (Gottlob,
1995; Schwarz, 1996; Janhunen, 1998), following sense: () faithful embedding
AEL MBNF if, theory LB model , AEL model
iff MBNF model ().
already known AEL theories embedded MBNF theories. particular, proven (Lin & Shoham, 1992; Schwarz & Truszczynski, 1994) AEL
theories nested occurrences B (called theories) embedded MBNF;
now, since AEL theory transformed equivalent theory (which
general size exponential size initial theory), follows AEL theory
embedded MBNF.
However, prove much stronger result: negation failure MBNF exactly
corresponds negative introspection AEL, i.e. AEL's modality :B MBNF's modality semantically equivalent. Hence, correspondence limited
modal theories without nested modalities, induces polynomial-time embedding
AEL theory MBNF.
first define translation () modal theories AEL MBNF theories.

Definition 3.3 Let ' 2 LB . Then, (') MBNF formula obtained ' substituting occurrence B :not. Moreover, LB , () denotes MBNF
theory fB (')j' 2 g.
show translation () embeds AEL theories MBNF. aim,

exploit semantic characterization AEL defined Schwarz (1992). Roughly speaking,
according preference semantics possible-world structures, AEL model
set interpretations satisfying that, interpretation J contained
, pair (J; ) satisfy . Formally:

Proposition 3.4 (Schwarz, 1992, Proposition 4.1) Let LB . Then, AEL
model iff, interpretation 2 , (I; ) j= and, interpretation
J 62 , (J; ) 6j= .
282

fiReasoning minimal belief negation failure

following, say occurrence subformula formula ' 2 LM
strict lie within scope modal operator. E.g., let = B' ^ (B _ ).
occurrence B' strict, occurrence B strict.

Theorem 3.5 Let LB . Then, AEL model iff, , (I; )
MBNF model ().

part. Suppose (I; ) MBNF model (). Then, 0 ,
(M 0 ; ) 6j= (). Since () set formulas form B', ' contain
occurrence operator B , follows that, subformula form '
occurring (), (M 0 ; ) j= ' iff (M; ) j= '. let B' 2 (), let '0 denote
propositional formula obtained ' replacing strict occurrence '
formula form true (M; ) j= false otherwise, let
0 = f'0 : B' 2 ()g. suppose exists interpretation J J j= 0
J 62 . Then, definition satisfiability MBNF structures follows
(M [fJ g; ) j= (), thus contradicting hypothesis (I; ) MBNF model
(). Hence, = fI : j= 0g. consider pair (J; ): again, definition
satisfiability MBNF structures follows immediately (J; ) j= iff J j= 0 .
since contains interpretations satisfying 0 , follows that, interpretation
J 62 , (J; ) 6j= , therefore Proposition 3.4 follows AEL model .
Only-if part. Suppose AEL model . Then, Proposition 3.4,
interpretation 2 , (I; ) j= and, interpretation J 62 , (J; ) 6j= .
' 2 , let '00 denote propositional formula obtained ' replacing strict
occurrence formula form B true j= B false otherwise,
let 00 = f'00 : ' 2 g. Then, suppose exists interpretation J J j= 00
J 62 . Then, definition satisfiability MBNF structures follows
(J; ) j= , thus contradicting hypothesis AEL model . Hence,
= fI : j= 00g. suppose that, interpretation , (I; ) MBNF
model (). Then, exists 0 (M 0 ; ) j= (). definition
(), follows interpretation 0 satisfies 00 , and, since 0 , exists
J 62 J j= 00. Contradiction. Therefore, (I; ) MBNF model .
remark theorem could alternatively proved fact
K -free fragment logic MKNF (Lifschitz, 1991) equivalent AEL,
stated (although without proof) Schwarz Truszczynski (1994, page 123),
correspondence MBNF MKNF (Lifschitz, 1994).
previous theorem implies interpretation modality MBNF
modal operator autoepistemic logic same. property extends previous
results relating MBNF AEL (Lin & Shoham, 1992; Schwarz & Lifschitz, 1993; Chen,
1994), interesting consequences logic programming framework
nonmonotonic reasoning. particular, since MBNF generalizes stable model semantics
logic programs (Gelfond & Lifschitz, 1988), result strengthens idea
AEL true logic negation failure (as interpreted according stable model
semantics). Moreover, positive theories interpretation MBNF
logic minimal knowledge S5G (Halpern & Moses, 1985): consequently, logic
MBNF generalizes Halpern Moses' S5G Moore's AEL.
Proof.

283

fiRosati

4. Reasoning MBNF

section present algorithms reasoning propositional MBNF: particular,
study entailment problem MBNF. on, assume deal finite MBNF
theories , therefore refer single formula (which corresponds conjunction
formulas contained finite theory ).

4.1 Characterizing MBNF Models

present finite characterization MBNF models formula 2 LM .
several methods reasoning nonmonotonic modal logics (Gottlob, 1992; Marek
& Truszczynski, 1993; Eiter & Gottlob, 1992; Niemela, 1992; Donini et al., 1997b),
technique employ based definition correspondence preferred
models theory partitions set modal subformulas theory.
fact, partitions used order provide finite characterization universal
Kripke structure: specifically, partition satisfying certain properties identifies particular
universal Kripke structure , uniquely determining propositional theory
set interpretations satisfying theory.
extend known techniques order deal preference semantics
MBNF. particular, characterize properties partition modal subformulas
formula 2 LM must satisfy order identify MBNF model . way,
provide method rely modal logic theorem prover, reduces
problem reasoning bimodal logic number reasoning problems propositional
logic.
First, introduce preliminary definitions. call formula form B'
', ' 2 LM , modal atom.

Definition 4.1 Let 2 LM . call set modal atoms occurring modal
atoms (and denote set MA()).

Definition 4.2 Let 2 LM let (P; N ) partition set modal atoms.
denote (P; N ) formula obtained substituting strict occurrence
formula P true, strict occurrence formula N false.

Observe occurrences modal subformulas within
scope another modality replaced; notice also that, P [ N contains MA(),
(P; N ) propositional formula. case, pair (P; N ) identifies guess
modal subformulas , i.e. P contains modal subformulas assumed hold,
N contains modal subformulas assumed hold.

Definition 4.3 Let 2 LM let (P; N ) partition MA(). denote ob (P; N )
propositional formula

^
'(P; N )
B'2P
Roughly speaking, propositional formula ob (P; N ) represents \objective knowledge" implied guess (P; N ) formulas form B' belonging P .
ob (P; N ) =

284

fiReasoning minimal belief negation failure

semantic viewpoint, structure (I; M; 0 ) satisfying guess modal atoms
given (P; N ), propositional formula ob (P; N ) constrains interpretations ,
since structure propositional formula ob (P; N ) must satisfied
interpretation J 2 , i.e. J j= ob (P; N ).

Example 4.4 Let

= (Ba _ (b ^ c)) ^ ^ :B (:f _ g)
Then, MA() = fBa; (b ^ c); B (:f _ g)g. suppose
P = fBa; (b ^ c)g
N = fB (:f _ g)g
Then, (P; N ) = (true _ true) ^ ^ :false (which equivalent d), ob (P; N ) = a.

Definition 4.5 say pair sets interpretations (M; 0 ) induces partition
(P; N ) MA() if, modal atom 2 MA(), 2 P iff (M; 0 ) j= .
Lemma 4.6 Let ' 2 LM , let interpretation, let M; 0 sets interpretations,
let (P; N ) partition induced (M; 0 ) set modal atoms . Then,
(I; M; 0 ) j= ' iff (I; M; 0 ) j= '(P; N ).
Follows immediately Definitions 4.2 4.5, definition
satisfiability MBNF structures.
show that, (I; ) MBNF model induces partition (P; N )
MA(), formula ob (P; N ) completely characterizes set interpretations
M.
Proof.

Theorem 4.7 Let 2 LM , let (I; ) MBNF model , let (P; N )
partition MA() induced (M; ). Then, = fJ : J j= ob (P; N )g.
Let 0 = fJ : J j= ob (P; N )g. Since (M; ) induces partition (P; N ),
Definition 4.5 follows interpretation must satisfy ob (P; N ), hence 0 .
suppose 0 , consider structure (I; 0 ; ). prove modal
atom 2 MA() belongs P iff (I; 0 ; ) j= . proof induction depth
Proof.

formulas MA().
First, consider modal atom 2 L: definition satisfiability
formula MBNF structure, follows immediately 2 P iff (I; 0 ; ) j=
. Then, consider modal atom B 2 L: B 2 P , then, definition
ob (P; N ), propositional formula ob (P; N ) valid, therefore (I; 0 ; ) j= B .
B 2 N , exists interpretation J J 6j= , since 0 ,
follows (I; 0 ; ) 6j= B . Hence, modal atom 2 MA() depth 1 belongs
P iff (I; 0 ; ) j= .
Suppose 2 P iff (I; 0 ; ) j= modal atom MA() depth
less equal i. Consider modal atom B MA() depth + 1: induction
hypothesis, Lemma 4.6, (I; 0 ; ) j= B iff 0 j= B ( (P; N )). Now, B 2 P ,
285

fiRosati

then, definition ob (P; N ), propositional formula ob (P; N ) (P; N ) valid,
since 0 = fJ : J j= ob (P; N )g, follows 0 j= B ( (P; N )), turn implies
(I; 0 ; ) j= B ; hand, B 2 N , exists interpretation J
(J; M; ) 6j= , hence, induction hypothesis Lemma 4.6, J 6j= (P; N ).
Now, since 0 , follows 0 6j= B ( (P; N )), hence (I; 0 ; ) 6j= B .
way possible show modal atom form depth + 1 belongs
P iff (I; 0 ; ) j= .
thus proved modal atom 2 MA() belongs P iff (I; 0 ; ) j= :
turn implies (I; 0 ; ) j= iff j= (P; N ), since hypothesis (I; M; )
satisfies (P; N ) partition MA() induced (M; ), Lemma 4.6
follows j= (P; N ). Therefore, (I; 0 ; ) j= , contradicts hypothesis
(I; ) MBNF model . Consequently, 0 = , proves thesis.
Informally, theorem states MBNF model associated
partition (P; N ) modal atoms ; moreover, propositional formula ob (P; N )
exactly characterizes set interpretations MBNF model (I; ), sense
set interpretations satisfying ob (P; N ). provides finite way
describe MBNF models .
define notion partition set modal atoms induced pair
propositional formulas.

Definition 4.8 Let 2 LM , '1 ; '2 2 L. denote Prt (; '1 ; '2 ) partition
MA() induced (M1 ; M2 ), M1 = fI : j= '1 g, M2 = fI : j= '2 g.
order simplify notation, denote Prt (; ') partition Prt (; '; ').
following theorem provides constructive way build partition Prt (; '; ).

Theorem 4.9 Let 2 LM , '; 2 L. Let (P; N ) partition MA() built follows:
1. start P = N = ;;
2. modal atom B MA() (P; N ) 2 L, propositional formula
' (P; N ) valid, add B P , otherwise add B N ;
3. modal atom MA() (P; N ) 2 L, propositional
formula (P; N ) valid, add P , otherwise add N ;
4. iteratively apply rules P [ N = MA().
Then, (P; N ) = Prt (; '; ).

proof induction structure formulas MA(). First,
fact Prt (; '; ) partition induced (M; 0 ), = fI : j=
'g, 0 = fI : j= g, definition satisfiability MBNF structures,
follows that, 2 L, (M; 0 ) j= B ' valid propositional
formula, (M; 0 ) j= valid propositional formula.
Therefore, (P; N ) agrees Prt (; '; ) modal atoms modal depth 1. Suppose
(P; N ) Prt (; '; ) agree modal atoms modal depth less equal
Proof.

286

fiReasoning minimal belief negation failure

i. Consider modal atom B MA() modal depth + 1. Lemma 4.6
definition satisfiability MBNF structures, follows (M; 0 ) j= B
' (Prt (; '; )) valid propositional formula, since Definition 4.2
value formula (Prt (; '; )) depends guess modal atoms
modal depth less equal Prt (; '; ), induction hypothesis follows
(Prt (; '; )) = (P; N ), hence B belongs P (M; 0 ) j= B. Analogously,
proven modal atom depth + 1 form belongs P
(M; 0 ) j= . Therefore, (P; N ) Prt (; '; ) agree modal atoms
modal depth + 1.
algorithms present following reasoning MBNF use shown
properties partitions modal subformulas formula , together additional
conditions partitions (that vary according different classes theories accepted
inputs), order identify MBNF models .
entailment problem j=MBNF ', point occurrences
' equivalent occurrences :B , since MBNF model modalities
' evaluated set interpretations. Therefore, original formulation
MBNF (Lifschitz, 1994), restrict query answering MBNF positive formulas.
Let ' 2 LB , 2 L, = fJ : J j= g. denote '( ) propositional
formula obtained ' substituting strict occurrence modal atom B
' true j= B, false otherwise. immediately verified
'( ) = '(Prt ('; )).

Theorem 4.10 Let ; ' 2 LM . Let (I; ) MBNF model let (P; N )
partition MA() induced (M; ). Then, ' satisfied (I; M; ) iff j=

'(ob (P; N )).

proof follows immediately fact that, Theorem 4.9, '(ob (P; N )) =
'(Prt ('; ob (P; N ))), Lemma 4.6.
show entailment problem MBNF related membership
problem stable sets (Gottlob, 1995), turn related notion (objective)
kernel used characterize stable expansions autoepistemic theories (Marek
& Truszczynski, 1993).
Proof.

Definition 4.11 Let 2 L. denote ST ( ) (unique) stable set LB


\ L = f' 2 Lj ' validg

Theorem 4.12 Let 2 LM , ' 2 LSB . Then, 6j=MBNF ' iff exists MBNF model
(I; ) ' 62 ST (ob (P; N )), (P; N ) partition MA() induced

(M; ).

Let = fI : j= ob (P; N )g: definition Definition 3.2, follows
immediately ST (ob (P; N )) = Th(M ). Therefore, ' 2 LSB (I; M; ) j= ' iff
' 2 ST (ob (P; N )).
Proof.

287

fiRosati

Algorithm MBNF-Not-Entails(; ')
Input: formula 2 LM , formula ' 2 LB ;
Output: true 6j=MBNF ', false otherwise.
begin
exists partition (P; N ) MA()

(a) (P; N ) = Prt (; ob (P; N ))
(b) (P; N ) ^ :'(ob (P; N )) satisfiable
(c) partition (P 0 ; N 0 ) 6= (P; N ) MA(),
(c1) (P 0 ; N 0 ) satisfiable
(c2) (P 0 ; N 0 ) =
6 Prt (; ob (P 0; N 0 ); ob (P; N ))
(c3) ob (P; N ) ^ :ob (P 0 ; N 0 ) satisfiable
return true
else return false
end
Figure 1: Algorithm MBNF-Not-Entails.

4.2 Reasoning Propositional MBNF

define deductive method reasoning general propositional MBNF theories.
Specifically, present algorithm MBNF-Not-Entails, reported Figure 1, computing entailment MBNF.
algorithm exploits finite characterization MBNF models given Theorem 4.7
analogous finite characterization, terms partitions MA(), models
relevant establishing whether partition (P; N ) MA() identifies MBNF model.
algorithm checks whether exists partition (P; N ) MA() satisfying
three conditions (a), (b), (c). Intuitively, partition cannot self-contradictory (condition (a)): particular, condition (P; N ) = Prt (; ob (P; N )) establishes
objective knowledge implied partition (P; N ) (that is, formula ob (P; N )) identifies set interpretations = fI : j= ob (P; N )g (M; ) induces
partition (P; N ) MA(). Moreover, partition must consistent :'
(condition (b)): condition implies exists interpretation
satisfied (I; M; ) ' satisfied structure (I; M; ). Finally,
condition (c) corresponds check whether structure (I; M; ) identifies MBNF
model according Definition 2.1, i.e. whether pair (J; 0 )
0 (J; 0 ; ) satisfies . Again, search structure performed
examining whether exists partition MA(), different (P; N ),
satisfy conditions (c1), (c2), (c3).
illustrate algorithm following simple example.

Example 4.13 Suppose
= B (a _ Bb) ^ (not (c _ :d) _ B :not b) ^ c
288

fiReasoning minimal belief negation failure

' = :Bb _ (:b ^ B (a ^ b))
Then, MA() = fB (a _ Bb); Bb; (c _ :d); B :not b; bg. suppose (P; N ) =
(P1 ; N1 ),

P1 = fB (a _ Bb); (c _ :d); bg
N1 = fBb; B :not bg
Then, (P; N ) = true ^ (true _ false) ^ c (which equivalent c), ob (P; N ) = _ false
(which equivalent a). Now, let = fI : j= ag: easy see (M; )
satisfies modal atoms P , satisfy modal atoms N , hence
(P; N ) = Prt (; ob (P; N )), thus satisfying condition (a) algorithm. Then, since
^ b valid propositional formula, 6j= B (a ^ b), hence :'(ob (P; N )) =
:(true _ (:b ^ false)), equivalent false. Therefore, (P; N ) ^ :'(ob (P; N ))
satisfiable, thus condition (b) hold.
Suppose (P; N ) = (P2 ; N2 ),

P2 = fB (a _ Bb); (c _ :d); Bb; B :not bg
N2 = fnot bg
Then, (P; N ) = true ^ (true _ true) ^ c (which equivalent c), ob (P; N ) = (a _ true) ^
b^true, equivalent b. Again, easy see (P; N ) = Prt (; ob (P; N )), thus
satisfying condition (a) algorithm. Then, since b ^ b valid propositional
formula, :'(ob (P; N )) = :(false _ (:b ^ false)), equivalent true. Hence, (P; N ) ^
:'(ob (P; N )) equivalent c, implies condition (b) holds. Finally, easy
verify either condition (c1) condition (c2) holds partition MA()
different (P2 ; N2 ), exception (P1 ; N1 ). let (P 0 ; N 0 ) = (P1 ; N1 ): shown
before, ob (P 0 ; N 0 ) equivalent a, hence ob (P; N ) ^ :ob (P 0 ; N 0 ) equivalent b ^ :a,
therefore condition (c3) holds (P 0 ; N 0 ) = (P1 ; N1 ), implies condition (c)
holds (P; N ) = (P2 ; N2 ). Consequently, MBNF-Not-Entails(; ') returns true. fact,
partition (P2 ; N2 ) identifies set MBNF models (I; )
interpretation satisfying c = fI : j= bg. model satisfy
query ': indeed, immediately verified that, interpretation , (I; M; ) 6j=
:Bb _ (:b ^ B (a ^ b)), since 6j= B (a ^ b) j= Bb.
prove correctness algorithm MBNF-Not-Entails need following preliminary lemma.

Lemma 4.14 Let 2 LM , let (P; N ) partition MA() induced (M 0; ).
Let 00 = fI : j= ob (P; N )g. Then, (P; N ) partition induced (M 00 ; ).
proof induction depth modal atoms MA(). Let
2 MA() 2 L: then, (M 0 ; ) j= iff exists interpretation
2 6j= , therefore (M 0 ; ) j= iff (M 00 ; ) j= . let B 2
MA() 2 L: Definition 4.3, (M 0 ; ) j= B iff propositional formula
Proof.

289

fiRosati

ob (P; N ) valid, since 00 = fI : j= ob (P; N )g, follows (M 0 ; ) j= B
iff (M 00 ; ) j= B .
suppose that, modal atom depth i, (M 0 ; ) j= iff (M 00 ; ) j= ,
let (P 0 ; N 0 ) denote partition modal atoms MA() depth less equal
induced (M 0 ; ). First, consider modal atom depth + 1. Then,
Lemma 4.6, (M 0 ; ) j= iff (M 0 ; ) j= ( (P 0 ; N 0 )) and, inductive
hypothesis Lemma 4.6, (M 00 ; ) j= iff (M 00 ; ) j= ( (P 0 ; N 0 )). Then, since
depth i, (P 0 ; N 0 ) propositional formula, hence (M 0 ; ) j= ( (P 0 ; N 0 )) iff
exists interpretation 2 6j= (P 0 ; N 0 ), immediately implies
(M 0 ; ) j= iff (M 00 ; ) j= . consider modal atom B depth
+ 1. Then, Lemma 4.6, (M 0 ; ) j= B iff (M 0; ) j= B ( (P 0 ; N 0 )) and,
inductive hypothesis Lemma 4.6, (M 00 ; ) j= B iff (M 00 ; ) j= B ( (P 0 ; N 0 )).
Definition 4.3, (M 0 ; ) j= B iff propositional formula ob (P; N ) (P 0 ; N 0 ) valid,
since 00 = fI : j= ob (P; N )g, follows (M 0 ; ) j= B iff (M 00 ; ) j= B ,
proves thesis.
ready prove correctness algorithm MBNF-Not-Entails.

Theorem 4.15 Let 2 LM , ' 2 LB . Then, MBNF-Not-Entails(; ') returns true iff
6j=MBNF '.
part. Suppose 6j=MBNF '. Then, exists pair (I; ) (I; )
MBNF model (I; M; ) 6j= '. Let (P; N ) partition MA() induced
(M; ). Theorem 4.7, = fI : j= ob (P; N )g. Therefore, Definition 4.8,
(P; N ) = Prt (; ob (P; N )). Then, since (I; M; ) 6j= ', Theorem 4.10 follows
6j= '(ob (P; N )), since (I; M; ) j= , Lemma 4.6 j= (P; N ), therefore j=
(P; N ) ^:'(ob (P; N )). suppose exists partition (P 0 ; N 0) MA()
(P 0 ; N 0 ) =
6 (P; N ) none conditions (c1), (c2), (c3) holds. Then, since (P 0 ; N 0 )
satisfiable, exists interpretation J J j= (P 0 ; N 0 ), since (P 0 ; N 0 ) =
Prt (; ob (P 0 ; N 0 ); ob (P; N )), Lemma 4.6 follows exists interpretation
J (J; 0 ; ) j= , 0 = fI : j= ob (P 0 ; N 0)g. Then, since condition (c3)
hold, propositional formula ob (P; N ) ob (P 0 ; N 0 ) valid, implies
0 . Now, 0 = , (P 0 ; N 0 ) would partition induced (M; ), thus
contradicting hypothesis (P 0 ; N 0 ) =
6 (P; N ). Hence, 0 , since (J; 0 ; ) j= ,
Proof.

follows (I; ) MBNF model . Contradiction. Consequently, condition
(c) algorithm holds, therefore MBNF-Not-Entails(; ') returns true.
Only-if part. Suppose MBNF-Not-Entails(; ') returns true. Then, exists partition (P; N ) MA() conditions (a), (b), (c) hold. Let = fI : j=
ob (P; N )g. Since (P; N ) = Prt (; ob (P; N )), Definition 4.8 (P; N ) partition induced (M; ). since (P; N )^:'(ob (P; N )) satisfiable, follows exists
interpretation j= (P; N ) 6j= '(ob (P; N )), hence, Lemma 4.6,
(I; M; ) j= (I; M; ) 6j= '. suppose (I; ) MBNF model .
Then, exists set 0 interpretation J 0 (J; 0 ; ) j= .
Let (P 0 ; N 0 ) partition MA() induced (M 0 ; ). Since = fI : j= ob (P; N )g,
follows 0 contains
V least one interpretation J satisfy ob (P; N ),
since ob (P; N ) = B 2P (P; N ), J satisfy least one formula form
290

fiReasoning minimal belief negation failure

(P; N ) B 2 P . Therefore, P 0 6= P , implies (P 0 ; N 0 ) 6= (P; N ).
Then, since (J; 0 ; ) j= , Lemma 4.6 J j= (P 0 ; N 0 ), hence (P 0 ; N 0 ) satisfiable.
let 00 = fI : j= ob (P 0 ; N 0 )g. Lemma 4.14, follows (P 0 ; N 0 ) partition
induced (M 00 ; ), therefore, Definition 4.8, (P 0 ; N 0 ) = Prt (; ob (P 0 ; N 0 ); ob (P; N )).
Moreover, since 0 , follows propositional formula ob (P; N ) ob (P 0 ; N 0 )
valid, hence formula ob (P; N ) ^ :ob (P 0 ; N 0 ) unsatisfiable. Consequently, (P 0 ; N 0 )
satisfy condition (c) algorithm, thus contradicting hypothesis. Therefore, (I; ) MBNF model , since (I; M; ) 6j= ', follows 6j=MBNF ',
thus proving thesis.
point fact algorithm MBNF-Not-Entails rely theorem
prover modal logic: thus, \modal reasoning" actually needed reasoning
MBNF. interesting peculiarity MBNF shares nonmonotonic
modal formalisms, like autoepistemic logic (Moore, 1985) autoepistemic logic
knowledge (Schwarz, 1991).

4.3 Reasoning Flat MBNF

study reasoning MBNF theories. main reason taking account
fragment MBNF fact reasoning many best known nonmonotonic
formalisms like default logic, circumscription, logic programming, reduced
reasoning MBNF theories (Lifschitz, 1994).
known that, 2 L1M ' 2 LSB , possible reduce entailment
j=MBNF ' reasoning logic S4FMDD , translating MBNF formulas unimodal
formulas S4FMDD (Schwarz & Truszczynski, 1994). Thus, procedure deciding
entailment logic S4FMDD presented Marek Truszczynski (1993) employed computing entailment j=MBNF '. following study general
problem, entailment j=MBNF ' case 2 L1M ' 2 LB , present
specialized algorithm problem, simpler general reasoning
method S4FMDD .
Figure 2 report algorithm Flat-Not-Entails computing entailment.
algorithm, Pn denotes subset modal atoms P prefixed modality
, i.e. Pn = fnot : 2 P g.
Informally, correctness algorithm Flat-Not-Entails established fact that,
2 L1M , (a), (b), (c) necessary sucient conditions partition (P; N )
order establish whether induced pair (M; ) exists MBNF
model form (I; ). particular, condition (c) states B (ob (P; N )) must
consequence (Pn ; N ) modal logic S5,1 since shown (Pn ; N )
B (ob (P; N )) valid S5, guess modal atoms form B' P
minimal. illustrate fact following example.

Example 4.16 Let
= (Ba ^ (c _ d)) _ (B (a ^ b) ^ :Bc) _ Bc
1. denote B modal operator used S5.

291

fiRosati

Algorithm Flat-Not-Entails(; ')
Input: formula 2 L1M , formula ' 2 LB ;
Output: true 6j=MBNF ', false otherwise.
begin
exists partition (P; N ) MA()

(a) (P; N ) = Prt (; ob (P; N ))
(b) (P; N ) ^ :'(ob (P; N )) satisfiable
(c) (Pn ; N ) B (ob (P; N )) valid S5
return true
else return false
end
Figure 2: Algorithm Flat-Not-Entails.
suppose

P = fBa; B (a ^ b); (c _ d)g
N = fBcg
Then,

(Pn ; N ) = (Ba ^ true) _ (B (a ^ b) ^ :false) _ false;
propositionally equivalent Ba _ B (a ^ b), ob (P; N ) = ^ (a ^ b),
equivalent a^b. Now, Ba_B (a^b) B (a^b) valid S5, proved fact
set interpretations 0 = fI : j= ag 0 j= (Ba_B (a^b))^:B (a^b).
Indeed, set interpretations 0 immediately used order prove (P; N )
identify MBNF model . fact, let = fJ : J j= ^ bg: immediate
see that, interpretation , (I; 0 ; ) j= , since 0 , (I; )
MBNF model .
Finally, condition (b) corresponds check whether exists interpretation
satisfying :'(ob (P; N )): fact, interpretation exists, (I; ) MBNF
model satisfy '.
Therefore, algorithms MBNF-Not-Entails Flat-Not-Entails differ
way verified whether MBNF structure associated partition (P; N )
satisfies preference semantics provided Definition 2.1, implemented
condition (c) algorithms. algorithm MBNF-Not-Entails, partition checked
partitions MA(), algorithm Flat-Not-Entails sucient
verify partition (P; N ) satisfies \local" property. shown next section,
difference ects different computational properties entailment problem
two cases.
order establish correctness algorithm, need preliminary lemma.
292

fiReasoning minimal belief negation failure

Lemma 4.17 Let 2 L1M let (P; N ) partition induced structure (M; ).
Then, (I; ) MBNF model iff 0 positive formula (Pn ; N )
satisfied 0 .
Suppose (I; ) MBNF model , let (P; N ) partition induced
(M; ). Let 0 set interpretations 0 . Then, (M 0 ; ) 6j= .
Since 2 L1M 0 , implies modal atom N , (M 0 ; ) 6j= .
Moreover, modal atom 2 P , (M 0 ; ) j= . Therefore, Lemma 4.6,
(M 0 ; ) 6j= (Pn ; N ). Now, since 2 L1M , (Pn ; N ) positive formula, hence
satisfiability depends structure 0 , therefore 0 6j= (Pn ; N ).
Conversely, suppose (I; ) MBNF model , let (P; N ) partition
induced (M; ). Then, exists set interpretations 0 0
(M 0 ; ) j= . shown before, implies positive formula (Pn ; N ) satisfied
0 .
observed Section 2, class universal Kripke structures characterizes modal
logic S5. immediately implies following property.
Proof.

Lemma 4.18 formula ' 2 LSB valid S5 iff, set interpretations ,
formula :' satisfied .
Based property, able prove correctness algorithm
Flat-Not-Entails.

Theorem 4.19 Let 2 L1M ' 2 LB . Then, Flat-Not-Entails(; ') returns true iff
6j=MBNF '.
If-part. 6j=MBNF ', exists MBNF model (I; )
(I; M; ) 6j= '. Let (P; N ) partition MA() induced (M; ).
Theorem 4.7 follows = fJ : J j= ob (P; N )g. Therefore, Definition 4.8,
(P; N ) = Prt (; ob (P; N )), hence condition (a) algorithm holds.
let 0 = (Pn ; N ), suppose formula 0 B (ob (P; N )) valid S5.
Then, since formula 0 B (ob (P; N )) belongs LSB , Lemma 4.18 follows
exists set interpretations 0 satisfying 0 ^ :B (ob (P; N )). Let (P 0 ; N 0 )
partition VMA(0 ) induced (M 0 ; 0 ), let 00 = fI : j= ob (P 0 ; N 0 )g. Since
ob (P; N ) = B'2MA( ) ', Definition 4.3 follows ob (P; N ) ob (P 0 ; N 0 ) valid
propositional formula, hence 00 . Now, since hypothesis 0 j= :B (ob (P; N )),
follows 00 . Moreover, since 0 2 LB , Lemma 4.14 follows (P 0 ; N 0 )
partition induced (M 00 ; 00 ), since 0 j= 0 0 at, 0 (P 0 ; N 0 ) equivalent
true, therefore 00 j= 0 (P 0 ; N 0 ) and, Lemma 4.6, 00 j= 0 . hand, since
00 , Lemma 4.17 follows 00 6j= 0. Contradiction. Hence, 0 B (ob (P; N ))
Proof.

0

valid S5, consequently condition (c) algorithm holds.
Finally, since (I; M; ) 6j= ' = fJ : J j= ob (P; N )g, Theorem 4.10 follows
6j= '(ob (P; N )). Moreover, since (I; M; ) j= , Lemma 4.6 follows
j= (P; N ), consequently j= (P; N ) ^ :'(ob (P; N )), hence propositional formula
(P; N )^:'(ob (P; N )) satisfiable. Therefore, conditions (a), (b), (c) algorithm
hold, implies Flat-Not-Entails(; ') returns true.
293

fiRosati

Only-if-part. Flat-Not-Entails(; ') returns true, exists partition (P; N )
MA() conditions (a), (b), (c) algorithm hold. Let = fJ : J j=
ob (P; N )g. Definition 4.8, (P; N ) partition MA() induced (M; ). Now,
since (P; N ) ^ :'(ob (P; N )) satisfiable, exists interpretation j=
(P; N ) j= :'(ob (P; N )), hence Lemma 4.6 (I; M; ) j= , Theorem 4.10
(I; M; ) 6j= ', therefore show (I; ) MBNF model . So,
let us suppose (I; ) MBNF model . Then, Lemma 4.17 exists
0 (Pn ; N ) satisfied 0 . Now, condition (c) algorithm implies
B (ob (P; N )) consequence (Pn ; N ) S5, therefore ob (P; N ) satisfied
interpretation 0 , is, 0 fJ : J j= ob (P; N )g, contradicts hypothesis
0 = fJ : J j= ob (P; N )g. Consequently, (I; ) MBNF model .

remark fact algorithm Flat-Not-Entails seen generalization
known methods query answering Reiter's default logic, Moore's autoepistemic logic,
(disjunctive) logic programming stable model (and answer set) semantics.
particular, condition (c) algorithm seen generalization minimality
check used (disjunctive) logic programming verifying stability model logic
program (Gelfond & Lifschitz, 1990, 1991).

5. Complexity Results
section provide computational characterization reasoning MBNF.
first brie recall complexity classes polynomial hierarchy, refer
(Johnson, 1990; Papadimitriou, 1994) details complexity classes
mentioned paper. PA (NPA ) class problems solved polynomial
time deterministic (nondeterministic) Turing machines using oracle (i.e.
solves constant time problem A). classes pk , pk pk pof polynomial
hierarchy defined p0 = p0 = p0 = P, k 0, pk+1 = NPk , pk+1 = copk+1
p
pk+1 = Pk . particular, complexity class p2 class problems
solved polynomial time nondeterministic Turing machine uses NP-oracle,
p2 class problems complement problem p2 , p3
class problems solved polynomial time nondeterministic Turing machine
uses p2 -oracle, p3 class problems complement problem
p3 . generally assumed polynomial hierarchy collapse: hence,
problem class p2 p2 considered computationally easier p3 -hard
p3 -hard problem.
complexity entailment MBNF, start establishing lower bound
reasoning propositional MBNF theories. end, exploit correspondence
MBNF logic minimal knowledge S5G (Halpern & Moses, 1985). Indeed,
stated Proposition 2.5, one-to-one correspondence MBNF models
S5G models positive subjective theories.

Lemma
5.1 Let 2 LSM let ' 2 LB . Then, problem deciding whether j=MBNF
p
' 3-hard.

294

fiReasoning minimal belief negation failure

shown (Donini et al., 1997b), entailment S5G p3 -complete. Therefore,
Proposition 2.5, subjective (and hence general) MBNF theories, entailment
p3 -hard.
Then, show entailment problem propositional MBNF complete
respect class p3 .
Proof.

Theorem 5.2 Let
2 LM let ' 2 LB . Then, problem deciding whether
j=MBNF ' p3 -complete.

Hardness respect p3 follows Lemma 5.1. membership p3 ,
analyze complexity algorithm MBNF-Not-Entails reported Figure 1.
particular, observe that:
given (P; N ), formula ob (P; N ) computed polynomial time respect
size P . Moreover, Lemma 4.9 follows that, since MA() size linear
respect size , construction partition Prt (; ob (P; N ))
performed linear number (with respect size ) calls NPoracle propositional satisfiability. Therefore, condition (a) checked
linear number (in size input) calls NP-oracle;
since '(ob (P; N )) = '(Prt ('; ob (P; N ))), formula :'(ob (P; N )) computed
time linear respect size ' ^ ob (P; N ) using NP-oracle. since,
given (P; N ), (P; N ) computed polynomial time respect
size input, follows condition (b) computed linear
number (in size input) calls NP-oracle;
given partition (P 0 ; N 0), conditions (c1), (c2) (c3) (analogous
conditions (a) (b)) checked polynomial time, respect size
, using NP-oracle. Therefore, since guess partition (P 0 ; N 0 ) ofpMA()
requires nondeterministic choice, falsity condition (c) decided 2 ,
implies verifying whether condition (c) holds decided p2 .
Since guess partition (P; N ) MA() requires nondeterministic choice,
follows algorithm MBNF-Not-Entails, considered nondeterministic procedure, decides 6j=MBNF ' nondeterministic polynomial time (with respect size
^ '), using p2-oracle. Thus, obtain upper bound p3 non-entailment
problem, implies entailment MBNF p3 .
previous analysis also allows computational characterization logic MKNF
(Lifschitz, 1991), slight modification MBNF. Indeed, known (Lifschitz,
1994) that, theory LM , MKNF model iff, interpretation
, (I; ) MBNF model subjective theory 0 = fB' : ' 2 g. Therefore,
Proposition 2.5 p3 -hardness entailment S5G (Donini et al., 1997b), follows
entailment MKNF p3 -hard. Then, since j=MKNF ' iff 0 j=MBNF B' (Lifschitz,
1994), follows entailment MKNF polynomially reduced entailment
MBNF, hence problem belongs p3 . Therefore, following property holds.
Proof.

Theorem 5.3 Entailment propositional MKNF p3-complete.
295

fiRosati

Finally, previous theorem provides computational characterization logic
grounded knowledge justified assumptions GK (Lin & Shoham, 1992). fact,
logic GK considered syntactic variant propositional fragment MKNF.
Therefore, skeptical entailment GK p3 -complete.

Remark. computational properties MBNF variants relate formalisms

ground nonmonotonic modal logics (Eiter & Gottlob, 1992; Donini et al., 1997b; Rosati,
1999). Notably, ground nonmonotonic modal logics share MBNF interpretation
terms minimal knowledge (or minimal belief) modality B ; specifically, already
mentioned, propositional fragment MBNF considered built upon S5G
adding second modality . Therefore, turns that, propositional case, adding
\negation default" modality S5 logic minimal knowledge increase
computational complexity reasoning, adding minimal knowledge modality
AEL increase complexity deduction. thus summarize follows: minimal
knowledge computationally harder negation failure.
study complexity entailment MBNF theories. First, known
that, case MBNF theories subjective queries, entailment p2 -complete:
membership class p2 consequence fact MKNF theories
polynomially embedded McDermott Doyle's nonmonotonic modal logic S4F
(Schwarz & Truszczynski, 1994, Proposition 3.2), whose entailment problem p2 -complete
(Marek & Truszczynski, 1993), p2 -hardness follows existence polynomialtime embedding propositional default theories MBNF theories (Lifschitz, 1994).
Therefore, following property holds.

Proposition 5.4p Let 2 L1M let ' 2 LSB . Then, problem deciding whether
j=MBNF ' 2 -complete.
complexity entailment generic queries respect MBNF theories,
analyze complexity algorithm Flat-Not-Entails reported Figure 2. shown
before, condition (a) condition (b) checked linear number (with
respect size input) calls NP-oracle. Moreover, validity modal logic
S5 coNP-complete problem (Halpern & Moses, 1992). Hence, conditions
algorithm computed number calls oracle propositional
validity problem polynomial size input, since guess
partition (P; N ) MA() requires nondeterministic choice, follows algorithm
runs p2 . Therefore, following property holds.

Theorem 5.5 Let
2 L1M let ' 2 LB . Then, problem deciding whether
p
j=MBNF ' 2 -complete.
Membership problem class p2 implied algorithm Flat-notentails, whereas p2 -hardness implied Proposition 5.4.
Hence, algorithm Flat-Not-Entails \optimal" sense matches
lower bound entailment problem.

Proof.

296

fiReasoning minimal belief negation failure

Finally, remark subset MBNF theories conjunctive normal form
seen extension framework generalized logic programming introduced Inoue Sakama (1994), turn extension disjunctive logic
programming framework stable model semantics (Gelfond & Lifschitz, 1991).
Roughly speaking, MBNF theories conjunctive normal form correspond rules
generalized logic programs propositional formulas (instead literals) allowed
goals. computational characterization implies extension
framework logic programming stable model semantics affect worstcase complexity entailment problem, p2 -complete like entailment logic
programs disjunction stable model semantics (Eiter & Gottlob, 1995).
result extends analogous properties (Marek, Truszczynski, & Rajasekar, 1995) case
disjunctive logic programs.

6. Conclusions
paper investigated problem reasoning propositional fragment
MBNF. main results presented summarized follows:

negation failure modality MBNF exactly corresponds negative introspection AEL. implies logic MBNF viewed conservative
extension two different nonmonotonic modal logics: Halpern Moses' logic
minimal knowledge S5G Moore's AEL;

reasoning propositional fragment MBNF lies third level polyno-

mial hierarchy, hence (unless polynomial hierarchy collapse) reasoning
MBNF harder reasoning best known propositional nonmonotonic logics,
like default logic, autoepistemic logic, circumscription;

defined methods reasoning MBNF, subsume generalize wellknown nonmonotonic reasoning algorithms used logic programming (Gelfond &
Lifschitz, 1991), default logic (Gottlob, 1992), autoepistemic logic (Marek &
Truszczynski, 1993);

studied fragment MBNF relationship logic programming paradigm.

computational aspects reasoning MBNF, results presented Section 5 prove one source complexity due presence nested occurrences
modalities theory, since reasoning MBNF computationally easier
general case.
proven another source complexity lies underlying objective
language. fact, consider L0 tractable fragment propositional logic,
complexity reasoning modal language L0M built upon L0 lower
general case. particular, easy see that, assumption entailment
L0 computed polynomial time, algorithm MBNF-Not-Entails provides
upper bound p2 MBNF-entailment fragment L0M .
297

fiRosati

One possible development present work towards analysis reasoning
minimal belief negation failure first-order setting: particular,
interesting see whether possible extend techniques developed propositional case expressive language. first attempt direction reported
Donini et al. (1997a).

Acknowledgments

research partially supported Consiglio Nazionale delle Ricerche, grant
203.15.10.

References

Beringer, A., & Schaub, T. (1993). Minimal belief negation failure: feasible
approach. Proc. 11th Nat. Conf. Artificial Intelligence (AAAI'93), pp.
400{405.
Bochman, A. (1995). bimodal nonmonotonic modal logics unimodal
nonmodal equivalents. Proc. 14th Int. Joint Conf. Artificial Intelligence
(IJCAI'95), pp. 1518{1524.
Chen, J. (1994). logic knowing unified framework non-monotonic
reasoning. Fundamenta Informaticae, 21, 205{220.
Donini, F. M., Nardi, D., & Rosati, R. (1997a). Autoepistemic description logics. Proc.
15th Int. Joint Conf. Artificial Intelligence (IJCAI'97), pp. 136{141.
Donini, F. M., Nardi, D., & Rosati, R. (1997b). Ground nonmonotonic modal logics. J.
Logic Computation, 7 (4), 523{548.
Eiter, T., & Gottlob, G. (1992). Reasoning parsimonious moderately grounded
expansions. Fundamenta Informaticae, 17 (1,2), 31{54.
Eiter, T., & Gottlob, G. (1993). Propositional circumscription extended closed world
reasoning p2 -complete. Theoretical Computer Science, 114, 231{245.
Eiter, T., & Gottlob, G. (1995). computational cost disjunctive logic programming: propositional case. Annals Mathematics Artificial Intelligence, 15 (3,4).
Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming.
Proceedings Fifth Logic Programming Symposium, pp. 1070{1080. MIT
Press.
Gelfond, M., & Lifschitz, V. (1990). Logic programs classical negation. Proceedings
Seventh International Conference Logic Programming, pp. 579{597.
MIT Press.
Gelfond, M., & Lifschitz, V. (1991). Classical negation logic programs disjunctive
databases. New Generation Computing, 9, 365{385.
298

fiReasoning minimal belief negation failure

Gottlob, G. (1992). Complexity results nonmonotonic logics. J. Logic Computation, 2, 397{425.
Gottlob, G. (1995). NP trees Carnap's modal logic. J. ACM, 42 (2), 421{457.
Halpern, J. Y., & Moses, Y. (1985). Towards theory knowledge ignorance: Preliminary report. Apt, K. (Ed.), Logic models concurrent systems. SpringerVerlag.
Halpern, J. Y., & Moses, Y. (1992). guide completeness complexity modal
logics knowledge belief. Artificial Intelligence, 54, 319{379.
Inoue, K., & Sakama, C. (1994). positive occurrences negation failure. Proc.
4th Int. Conf. Principles Knowledge Representation Reasoning
(KR'94), pp. 293{304. Morgan Kaufmann, Los Altos.
Janhunen, T. (1998). intertranslatability autoepistemic, default priority
logics. Proc. 6th European Workshop Logics Artificial Intelligence
(JELIA'98), pp. 216{232.
Johnson, D. S. (1990). catalog complexity classes. van Leuven, J. (Ed.), Handbook
Theoretical Computer Science, Vol. A, chap. 2. Elsevier Science Publishers (NorthHolland), Amsterdam.
Kaminski, M. (1991). Embedding default system nonmonotonic logics. Fundamenta
Informaticae, 14, 345{354.
Levesque, H. J. (1990). know: study autoepistemic logic. Artificial Intelligence,
42, 263{310.
Lifschitz, V., & Woo, T. (1992). Answer sets general nonmonotonic reasoning (preliminary report). Proc. 3rd Int. Conf. Principles Knowledge Representation Reasoning (KR'92), pp. 603{614. Morgan Kaufmann, Los Altos.
Lifschitz, V. (1991). Nonmonotonic databases epistemic queries. Proc. 12th
Int. Joint Conf. Artificial Intelligence (IJCAI'91), pp. 381{386.
Lifschitz, V. (1994). Minimal belief negation failure. Artificial Intelligence, 70,
53{72.
Lin, F., & Shoham, Y. (1992). Epistemic semantics fixed-point non-monotonic logics.
Artificial Intelligence, 57, 271{289.
Marek, W., & Truszczynski, M. (1993). Nonmonotonic Logics { Context-Dependent Reasoning. Springer-Verlag.
Marek, W., Truszczynski, M., & Rajasekar, A. (1995). Complexity computing
extended propositional logic programs. Annals Mathematics Artificial intelligence, 15 (3,4).
299

fiRosati

Moore, R. C. (1985). Semantical considerations nonmonotonic logic. Artificial Intelligence, 25, 75{94.
Niemela, I. (1992). decidability complexity autoepistemic reasoning. Fundamenta Informaticae, 17 (1,2), 117{156.
Papadimitriou, C. H. (1994). Computational Complexity. Addison Wesley Publ. Co., Reading, Massachussetts.
Reiter, R. (1990). database know?. J. Logic Programming, 14, 127{153.
Rosati, R. (1997). Reasoning minimal belief negation failure: Algorithms
complexity. Proc. 14th Nat. Conf. Artificial Intelligence (AAAI'97), pp.
430{435. AAAI Press/The MIT Press.
Rosati, R. (1999). Reasoning minimal knowledge nonmonotonic modal logics. J.
Logic, Language Information, 8 (2), 187{203.
Schwarz, G. (1991). Autoepistemic logic knowledge. Proc. 1st Int. Workshop
Logic Programming Non-monotonic Reasoning (LPNMR'91), pp. 260{274.
MIT Press.
Schwarz, G. (1992). Minimal model semantics nonmonotonic modal logics. Proc.
7th IEEE Sym. Logic Computer Science (LICS'92), pp. 34{43. IEEE
Computer Society Press.
Schwarz, G. (1996). embedding default logic Moore's autoepistemic logic. Artificial
Intelligence, 80, 388{392.
Schwarz, G., & Lifschitz, V. (1993). Extended logic programs autoepistemic theories.
Proc. 2nd Int. Workshop Logic Programming Non-monotonic Reasoning
(LPNMR'93), pp. 101{114. MIT Press.
Schwarz, G., & Truszczynski, M. (1994). Minimal knowledge problem: new approach.
Artificial Intelligence, 67, 113{141.
Shoham, Y. (1987). Nonmonotonic logics: Meaning utility. Proc. 10th Int.
Joint Conf. Artificial Intelligence (IJCAI'87), pp. 388{392.
Stalnaker, R. (1993). note non-monotonic modal logic. Artificial Intelligence, 64 (2),
183{196.

300

fiJournal Artificial Intelligence Research 11 (1999) 1{94

Submitted 09/98; published 07/99

Decision-Theoretic Planning: Structural Assumptions
Computational Leverage
Craig Boutilier

cebly@cs.ubc.ca

Department Computer Science, University British Columbia
Vancouver, BC, V6T 1Z4, Canada

Thomas Dean

tld@cs.brown.edu

Department Computer Science, Brown University
Box 1910, Providence, RI, 02912, USA

Steve Hanks

hanks@cs.washington.edu

Department Computer Science Engineering, University Washington
Seattle, WA, 98195, USA

Abstract

Planning uncertainty central problem study automated sequential
decision making, addressed researchers many different fields, including
AI planning, decision analysis, operations research, control theory economics.
assumptions perspectives adopted areas often differ substantial ways,
many planning problems interest researchers fields modeled Markov
decision processes (MDPs) analyzed using techniques decision theory.
paper presents overview synthesis MDP-related methods, showing
provide unifying framework modeling many classes planning problems studied
AI. also describes structural properties MDPs that, exhibited particular classes problems, exploited construction optimal approximately
optimal policies plans. Planning problems commonly possess structure reward
value functions used describe performance criteria, functions used describe
state transitions observations, relationships among features used describe
states, actions, rewards, observations.
Specialized representations, algorithms employing representations, achieve
computational leverage exploiting various forms structure. Certain AI techniques|
particular based use structured, intensional representations|can
viewed way. paper surveys several types representations classical
decision-theoretic planning problems, planning algorithms exploit representations number different ways ease computational burden constructing
policies plans. focuses primarily abstraction, aggregation decomposition techniques based AI-style representations.

1. Introduction

Planning using decision-theoretic notions represent domain uncertainty plan quality
recently drawn considerable attention artificial intelligence (AI).1 Decision-theoretic
planning (DTP) attractive extension classical AI planning paradigm
allows one model problems actions uncertain effects, decision maker
1. See, example, recent texts (Dean, Allen, & Aloimonos, 1995; Dean & Wellman, 1991; Russell &
Norvig, 1995) research reported (Hanks, Russell, & Wellman, 1994).

c 1999 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiBoutilier, Dean, & Hanks

incomplete information world, factors resource consumption lead
solutions varying quality, may absolute well-defined \goal"
state. Roughly, aim DTP form courses action (plans policies)
high expected utility rather plans guaranteed achieve certain goals.
AI planning viewed particular approach solving sequential decision problems
type, connections DTP models used fields research|such
decision analysis, economics operations research (OR)|become apparent.
conceptual level, sequential decision problems viewed instances Markov
decision processes (MDPs), use MDP framework make connections
explicit.
Much recent research DTP explicitly adopted MDP framework underlying model (Barto, Bradtke, & Singh, 1995; Boutilier & Dearden, 1994; Boutilier, Dearden,
& Goldszmidt, 1995; Dean, Kaelbling, Kirman, & Nicholson, 1993; Koenig, 1991; Simmons
& Koenig, 1995; Tash & Russell, 1994), allowing adaptation existing results algorithms solving MDPs (e.g., field OR) applied planning problems.
so, however, work departed traditional definition \planning
problem" AI planning community|one goal paper make explicit
connection two lines work.
Adopting MDP framework model posing solving planning problems
illuminated number interesting connections among techniques solving decision
problems, drawing work AI planning, reasoning uncertainty, decision analysis
OR. One interesting insights emerge body work many
DTP problems exhibit considerable structure, thus solved using special-purpose
methods recognize exploit structure. particular, use feature-based
representations describe problems, typical practice AI, often highlights
problem's special structure allows exploited computationally little effort.
two general impediments widespread acceptance MDPs within
AI general model planning. first absence explanations MDP model
make connections current planning research explicit, either conceptual
computational level. may due large part fact MDPs
developed studied primarily OR, dominant concerns are, naturally, rather
different. One aim paper make connections clear: provide brief
description MDPs conceptual model planning emphasizes connection
AI planning, explore relationship MDP solution algorithms AI
planning algorithms. particular, emphasize AI planning models
viewed special cases MDPs, classical planning algorithms designed
exploit problem characteristics associated cases.
second impediment skepticism among AI researchers regarding computational
adequacy MDPs planning model: techniques scale solve planning problems
reasonable size? One diculty solution techniques MDPs tendency rely
explicit, state-based problem formulations. problematic AI planning
since state spaces grow exponentially number problem features. State space size
dimensionality somewhat lesser concern decision analysis.
fields, operations researcher decision analyst often hand-craft model ignores
certain problem features deemed irrelevant, define features summarize
2

fiDecision-Theoretic Planning: Structural Assumptions

wide class problem states. AI, emphasis automatic solution problems
posed users lack expertise decision analyst. Thus, assuming well-crafted,
compact state space often appropriate.
paper show specialized representations algorithms AI planning
problem solving used design ecient MDP solution techniques. particular,
AI planning methods assume certain structure state space, actions (or
operators), specification goal success criteria. Representations
algorithms designed make problem structure explicit exploit
structure solve problems effectively. demonstrate process identifying
structure, making explicit, exploiting algorithmically brought bear
solution MDPs.
paper several objectives. First, provides overview DTP MDPs
suitable readers familiar traditional AI planning methods makes connections
work. Second, describes types structure exploited
AI representations methods facilitate computationally effective planning MDPs.
such, suitable introduction AI methods familiar classical
presentation MDPs. Finally, surveys recent work use MDPs AI
suggests directions research regard, therefore interest
researchers DTP.

1.1 General Problem Definition
Roughly speaking, class problems consider involving systems whose
dynamics modeled stochastic processes, actions decision maker,
referred agent , uence system's behavior. system's current
state choice action jointly determine probability distribution system's
possible next states. agent prefers certain system states (e.g., goal states)
others, therefore must determine course action|also called \plan" \policy"
paper|that likely lead target states, possibly avoiding undesirable states
along way. agent may know system's state exactly making decision
act, however|it may rely incomplete noisy sensors forced
base choice action probabilistic estimate state.
help illustrate types problems interested, consider following
example. Imagine robot agent designed help someone (the \user")
oce environment (see Figure 1). three activities might undertake: picking
user's mail, getting coffee, tidying user's research lab. robot move
location location perform various actions tend achieve certain target
states (e.g., bringing coffee user demand, maintaining minimal level tidiness
lab).
might associate certain level uncertainty effects robot's actions
(e.g., tries move adjacent location might succeed 90% time fail
move 10% time). robot might incomplete access
true state system sensors might supply incomplete information (it
cannot tell whether mail available pickup mail room) incorrect
3

fiBoutilier, Dean, & Hanks

Office

Hallway

Lab
MailRoom

Coffee

Figure 1: decision-theoretic planning problem
information (even mail room sensors occasionally fail detect presence
mail).
Finally, performance robot might measured various ways: actions
guarantee goal achieved? maximize objective function defined
possible effects actions? achieve goal state sucient probability avoiding \disastrous" states near certainty? stipulation optimal
acceptable behavior important part problem specification.
types problems captured using general framework include classical (goal-oriented, deterministic, complete knowledge) planning problems extensions
conditional probabilistic planning problems, well general
problem formulations.
discussion point assumed extensional representation system's
states|one state explicitly named. AI research, intensional representations common. intensional representation one states sets
states described using sets multi-valued features. choice appropriate set
features important part problem design. features might include
current location robot, presence absence mail, on. performance
metric also typically expressed intensionally. Figure 2 serves reference example problem, use throughout paper. lists basic features used describe
states system, actions available robot exogenous events
might occur, together intuitive description features, actions events.
remainder paper organized follows. Section 2, present MDP
framework abstract, introducing basic concepts terminology noting relationship abstract model classical AI planning problem. Section 3 surveys common solution techniques|algorithms based dynamic programming general
MDP problems search algorithms planning problems|and points relationship problem assumptions solution techniques. Section 4 turns algorithms
representations, showing various ways structured representations commonly
used AI algorithms used represent MDPs compactly well. Section 5 surveys
4

fiDecision-Theoretic Planning: Structural Assumptions

Features
Location

Denoted
Description
Loc(M ), etc. Location robot. Five possible locations: mailroom (M), coffee room
(C), user's oce (O), hallway (H), laboratory (L)
Tidiness
(0), etc.
Degree lab tidiness. Five possible values: 0 (messiest) 4
(tidiest)
Mail present
M;
mail user's mail box? True (M ) False (M )
Robot mail
RHM; RHM robot mail possession?
Coffee request
CR; CR
outstanding (unfulfilled) request coffee user?
Robot coffee RHC; RHC robot coffee possession?
Actions
Denoted
Description
Move clockwise
Clk
Move adjacent location (clockwise direction)
Counterclockwise CClk
Move adjacent location (counterclockwise direction)
Tidy lab
Tidy
robot lab, degree tidiness increased 1
Pickup mail
PUM
robot mailroom mail present, robot
takes mail (RHM becomes true becomes false)
Get coffee
GetC
robot coffee room, gets coffee (RHC becomes true)
Deliver mail
DelM
robot oce mail, hands mail user
(RHM becomes false)
Deliver coffee
DelC
robot oce coffee, hands coffee
user (RHC CR become false)
Events
Denoted
Description
Mail arrival
ArrM
Mail arrives causing become true
Request coffee
ReqC
User issues coffee request causing CR become true
Untidy lab
Mess
lab becomes messier (one degree less tidy)

Figure 2: Elements robot domain.
recent work abstraction, aggregation problem decomposition methods,
shows connection traditional AI methods goal regression. last
section demonstrates representational computational methods AI planning
used solution general MDPs. Section 5 also points additional ways
type computational leverage might developed future.

2. Markov Decision Processes: Basic Problem Formulation
section introduce MDP framework make explicit relationship
model classical AI planning models. interested controlling stochastic
dynamical system: system point time one number distinct
states, system's state changes time response events. action
particular kind event instigated agent order change system's state.
assume agent control actions taken when, though
effects taking action might perfectly predictable. contrast, exogenous events
agent's control, occurrence may partially predictable.
abstract view agent consistent \AI" view agent
autonomous decision maker \control" view policy determined ahead
time, programmed device, executed without deliberation.
5

fiBoutilier, Dean, & Hanks

2.1 States State Transitions

define state description system particular point time. one
defines states vary particular applications, notions natural
others. However, common assume state captures information relevant
agent's decision-making process. assume finite state space = fs1 ; : : : ; sN g
possible system states.2 cases agent complete information
current state; uncertainty incomplete information captured using
probability distribution states .
discrete-time stochastic dynamical system consists state space probability
distributions governing possible state transitions|how next state system depends
past states. distributions constitute model system evolves time
response actions exogenous events, ecting fact effects actions
events may perfectly predictable even prevailing state known.
Although generally concerned agent chooses appropriate course
action, remainder section assume agent's course action
fixed, concentrating problem predicting system's state occurrence
predetermined sequence actions. discuss action selection problem next
section.
assume system evolves stages, occurrence event marks
transition one stage next stage + 1. Since events define changes stage,
since events often (but necessarily) cause state transitions, often equate stage
transitions state transitions. course, possible event occur leave
system state.
system's progression stages roughly analogous passage time.
two identical assume action (possibly no-op) taken
stage, every action takes unit time complete. thus speak loosely
stages correspond units time, refer interchangeably set stages
set time points.3
model uncertainty regarding system's state stage random
variable takes values . assumption \forward causality" requires
variable depend directly value future variable k (k > t). Roughly,
requires model system past history \directly" determines
distribution current states, whereas knowledge future states uence
estimate current state indirectly providing evidence current state
may lead future states. Figure 3(a) shows graphical perspective
discrete-time, stochastic dynamical system. nodes random variables denoting
state particular time, arcs indicate direct probabilistic dependence
states previous states. describe system completely must also supply
conditional distributions Pr(S jS 0 ; 1 ; t,1 ) times t.
States thought descriptions system modeled, question arises much detail system captured state description.
2. discussion paper also applies cases state space countably infinite. See
(Puterman, 1994) discussion infinite continuous-state problems.
3. deal topics here, considerable literature community
continuous-time Markov decision processes (Puterman, 1994).

6

fiDecision-Theoretic Planning: Structural Assumptions

(a)







(b)







(c)

0

0

1

1



2



2



t-1

t-1











t-1



Figure 3: general stochastic process (a), Markov chain (b), stationary Markov
chain (c).
detail implies information system, turn often translates better
predictions future behavior. course, detail also implies larger set ,
increase computational cost decision making.
commonly assumed state contains enough information predict next
state. words, information history system relevant predicting
future captured explicitly state itself. Formally, assumption, Markov
assumption, says knowledge present state renders information past
irrelevant making predictions future:
Pr(S t+1 jS ; t,1 ; : : : ; 0 ) = Pr(S t+1 jS )
Markovian models represented graphically using structure like Figure 3(b),
ecting fact present state sucient predict future state evolution.4
Finally, common assume effects event depend prevailing
state, stage time event occurs.5 distribution predicting
next state regardless stage, model said stationary
represented schematically using two stages, Figure 3(c). case
single conditional distribution required. paper generally restrict attention
discrete-time, finite-state, stochastic dynamical systems Markov property, commonly called Markov chains. Furthermore, discussion restricted stationary
chains.
complete model must provide probability distribution initial states,
ecting probability state stage 0. distribution repre4. worth mentioning Markov property applies particular model system
itself. Indeed, non-Markovian model system (of finite order, i.e., whose dynamics depend
k previous states k) converted equivalent though larger Markov model.
control theory, called conversion state form (Luenberger, 1979).
5. course, also statement model detail, saying state carries enough information
make stage irrelevant predicting transitions.

7

fiBoutilier, Dean, & Hanks

.3

6

.7

.9
.1

.5

1
.5

3

.1

4

1.0

.2

2

.8

5

.4

7
1.0

.5

Figure 4: state-transition diagram.
sented real-valued (row) vector size N = jS j (one entry state). denote
vector P 0 use p0i denote ith entry, is, probability starting state
si .
represent -stage nonstationary Markov chain transition matrices,
size N N , matrix P captures transition probabilities governing
system moves stage stage + 1. matrix consists probabilities ptij ,
ptij = Pr(S t+1 = sj jS = si ). process stationary, transition matrix
stages one matrix (whose entries denoted pij ) suce. Given
initial
states P 0 , probability distribution states n stages
Q0 Pdistribution
i.
i=n
stationary Markov process also represented using state-transition diagram
Figure 4. nodes correspond particular states stage represented
explicitly. Arcs denote possible transitions (those non-zero probability) labeled
transition probabilities pij = Pr(S t+1 = sj jS = si ). arc node node
j labeled pij pij > 0.6 size diagram least O(N )
O(N 2 ), depending number arcs. useful representation transition
graph relatively sparse, example, states immediate transitions
neighbors.

Example 2.1 illustrate notions, imagine robot Figure 1 executing

policy moving counterclockwise repeatedly. restrict attention two
variables, location Loc presence mail , giving state space size 10.
suppose robot always moves adjacent location probability 1:0.
addition, mail arrive mailroom probability 0:2 time (independent robot's location), causing variable become true.
becomes true, robot cannot move state false, since action
moving uence presence mail. state-transition diagram
example illustrated Figure 5. transition matrix also shown. 2

structure Markov chain occasionally interest us planning. subset

C closed pij = 0 2 C j 62 C . proper closed set proper
subset C enjoys property. sometimes refer proper closed sets recurrent
classes states. closed set consists single state, state called
absorbing state. agent enters closed set absorbing state, remains
6. important note nodes represent random variables earlier figures.

8

fiDecision-Theoretic Planning: Structural Assumptions

s1
s2

0.2

OM

0.8

0.8
0.2

OM

s7

HM

LM

0.8

1.0

1.0

s10
0.2

0.8
CM

MM

MM

0.2

s3

HM

s9 1.0

s4

0.8

s1
s2
s3
s4
s5
s6
s7
s8
s9
s10

s6

1.0

s5

LM

0.2

s8

CM

1.0

s1
0:0
0:0
0:0
0:0
0:8
0:0
0:0
0:0
0:0
0:0

s2
0:8
0 :0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0 :0

s3
0:0
0:8
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0 :0

s4
0:0
0:0
0:8
0:0
0:0
0:0
0:0
0:0
0:0
0:0

s5
0:0
0:0
0:0
0:8
0:0
0:0
0:0
0:0
0:0
0:0

s6
0:0
0 :0
0:0
0 :0
0:2
0 :0
0 :0
0 :0
0 :0
1:0

s7
0:2
0:0
0:0
0:0
0:0
1:0
0:0
0:0
0:0
0:0

s8
0:0
0:2
0:0
0:0
0:0
0:0
1:0
0:0
0:0
0:0

s9
0:0
0:0
0:2
0:0
0:0
0:0
0:0
1:0
0:0
0:0

s10
0:0
0:0
0:0
0:2
0:0
0:0
0:0
0:0
1:0
0:0

Figure 5: state-transition diagram transition matrix moving robot.
forever probability 1. example (Figure 5), set states
holds forms recurrent class. absorbing states example,
program robot stay put whenever state hM; Loc(O)i, would
absorbing state altered chain. Finally, say state transient
belong recurrent class. Figure 5, state holds transient|eventually
(with probability 1), agent leaves state never returns, since way
remove mail arrives.

2.2 Actions
Markov chains used describe evolution stochastic system,
capture fact agent choose perform actions alter state
system. key element MDPs set actions available decision maker.
action performed particular state, state changes stochastically response
action. assume agent takes action stage process,
system changes state accordingly.
stage process state s, agent available set actions
Ats. called feasible set stage t. describe effects 2 Ats, must
supply state-transition distribution Pr(S t+1 jS = s; = a) actions a, states s,
stages t. Unlike case Markov chain, terms Pr(S t+1 jS = s; = a)
true conditional distributions, rather family distributions parameterized
, since probability part model. retain notation, however,
suggestive nature.
often assume feasible set actions stages states,
case set actions = fa1 ; : : : ; aK g executed time.
contrasts AI planning practice assigning preconditions actions defining
states meaningfully executed. model takes view
action executed (or \attempted") state. action effect
executed state, execution leads disastrous effects, noted
action's transition matrix. Action preconditions often computational convenience
rather representational necessity: make planning process ecient
identifying states planner even consider selecting action.
Preconditions represented MDPs relaxing assumption set
9

fiBoutilier, Dean, & Hanks

s1
s2
s3
s4
s5
s6
s7
s8
s9
s10

s1
0:0
0:0
0:0
0:0
0:8
0:0
0:0
0:0
0:0
0:0

s2
0:8
0:0
0:8
0:0
0:0
0:0
0:0
0:0
0:0
0:0

s3
0:0
0:8
0:0
0:8
0:0
0:0
0:0
0:0
0:0
0:0

s4
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0

s5
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0

s6
0:0
0:0
0:0
0:0
0:2
0:0
0:0
0:0
0:0
1:0

s7
0:2
0:0
0:2
0:0
0:0
1:0
0:0
1:0
0:0
0:0

s8
0:0
0:2
0:0
0:2
0:0
0:0
1:0
0:0
1:0
0:0

s9
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0

s10
0:2
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0

s1
0.8

0.2

OM

0.8

s2

LM

s3

s7

s10

1.0

s9

1.0
0.8

CM

MM

MM

s8

s4

0.2
0.2

1.0

s6
HM

s5

0.8
0.8

1.0

HM

0.2

LM

OM

0.2

CM

1.0

Figure 6: transition matrix Clk induced transition diagram two-action
policy.
feasible actions states. illustrate planning concepts below, however,
sometimes assume actions preconditions.
restrict attention stationary processes, case means
effects action depends state stage. transition
matrices thus take form pkij = Pr(S t+1 = sj jS = si ; = ak ), capturing probability
system moves state sj ak executed state si . stationary models
action fully described single N N transition matrix P k . important note
transition matrix action includes direct effects executing
action also effects exogenous events might occur stage.7

Example 2.2 example Figure 5 extended agent two available

actions: moving clockwise moving counterclockwise. transition matrix
CClk (with assumption mail arrives probability 0:2) shown Figure 5.
matrix Clk appears left Figure 6. Suppose agent fixes behavior
moves clockwise locations C counterclockwise locations H ,
L (we address agent might come know location
actually implement behavior). defines Markov chain illustrated
transition diagram right Figure 6. 2

2.3 Exogenous Events

Exogenous events events stochastically cause state transitions, much like
actions, beyond control decision maker. might correspond
evolution natural process action another agent. Notice effect
action CClk Figure 5 \combines" effects robot's action
exogenous event mail arrival: state-transition probabilities incorporate motion
robot (causing change location) possible change mail status due
mail arrival. purposes decision making, precisely combined effect
7. possible assess effects actions exogenous events separately, combine
single transition matrix certain cases (Boutilier & Puterman, 1995). discuss later
section.

10

fiDecision-Theoretic Planning: Structural Assumptions

important predicting distribution possible states resulting
action taken. call models actions implicit-event models, since effects
exogenous event folded transition probabilities associated action.
However, often natural view transitions comprised two separate
events, effect state. generally, often think transitions
determined effects agent's chosen action certain exogenous
events beyond agent's control, may occur certain probability.
effects actions decomposed fashion, call action model
explicit-event model.
Specifying transition function action zero exogenous events
generally easy, actions events interact complex ways. instance, consider
specifying effect action PUM (pickup mail) state mail present
possibility \simultaneous" mail arrival (i.e., \same unit" discrete
time). event ArrM occurs, robot obtain newly arrived mail,
mail remain mailbox? Intuitively, depends whether mail arrived
pickup completed (albeit within time quantum). state transition
case viewed composition two transitions precise description
composition depends ordering agent's action exogenous event.
mail arrives first, transition might ! s0 ! s00 , s0 state mail
waiting s00 state mail waiting robot holding mail;
pickup action completed first, transition would ! ! s0 (i.e., PUM
effect, mail arrives remains box).
picture complicated actions events truly occur simultaneously
interval|in case resulting transition need composition
individual transitions. example, robot lifts side table glass
water situated, water spill; similarly exogenous event causes side
raised. action event occur simultaneously, result qualitatively
different (the water spilled). Thus, \interleaving" semantics described
always appropriate.
complications, modeling exogenous events combination
actions events approached many ways, depending modeling assumptions one willing make. Generally, specify three types information. First,
provide transition probabilities actions events assumption
occur isolation|these standard transition matrices. transition matrix
Figure 5 decomposed two matrices shown Figure 7, one Clk one
ArrM.8 Second, exogenous event, must specify probability occurrence.
Since vary state, generally require vector length N indicating
probability occurrence state. occurrence vector ArrM would
[0:2 0:2 0:2 0:2 0:2 0:0 0:0 0:0 0:0 0:0]
8. fact individual matrices deterministic artifact example. general,
actions events represented using genuinely stochastic matrices.

11

fiBoutilier, Dean, & Hanks

s1
s2
s3
s4
s5
s6
s7
s8
s9
s10

s1

0:0
0:0
0:0
0:0
1:0
0:0
0:0
0:0
0:0
0:0

s2

1:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0

s3

0:0
1:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0

s4

0:0
0:0
1:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0

s5

0:0
0:0
0:0
1:0
0:0
0:0
0:0
0:0
0:0
0:0

s6

0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
1:0

s7

0:0
0:0
0:0
0:0
0:0
1:0
0:0
0:0
0:0
0:0

s8

0:0
0:0
0:0
0:0
0:0
0:0
1:0
0:0
0:0
0:0

s9

0:0
0:0
0:0
0:0
0:0
0:0
0:0
1:0
0:0
0:0

s10
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
1:0
0:0

s1
s2
s3
s4
s5
s6
s7
s8
s9
s10

Action Clk

s1

0 :0
0 :0
0 :0
0 :0
0 :0
0 :0
0 :0
0 :0
0 :0
0 :0

s2

0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0

s3

0 :0
0 :0
0 :0
0 :0
0 :0
0 :0
0 :0
0 :0
0 :0
0 :0

s4

0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0

s5

0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0
0:0

s6

1:0
0:0
0:0
0:0
0:0
1:0
0:0
0:0
0:0
0:0

s7

0:0
1:0
0:0
0:0
0:0
0:0
1:0
0:0
0:0
0:0

s8

0:0
0:0
1:0
0:0
0:0
0:0
0:0
1:0
0:0
0:0

s9

0:0
0:0
0:0
1:0
0:0
0:0
0:0
0:0
1:0
0:0

s10
0:0
0:0
0:0
0:0
1:0
0:0
0:0
0:0
0:0
1:0

Event ArrM

Figure 7: transition matrices action exogenous event explicit-event
model.
assume, illustration, mail arrives none present.9 final
requirement combination function describes \compose" transitions
action subset event transitions. indicated above, complex,
sometimes almost unrelated individual action event transitions. However,
certain assumptions combination functions specified reasonably concisely.
One way modeling composition transitions assume interleaving semantics type alluded above. case, one needs specify probability
action events take place occur specific order. instance, one might
assume event occurs time|within discrete time unit|according
continuous distribution (e.g., exponential distribution given rate). information, probability particular ordering transitions, given certain events
occur, computed, resulting distribution possible next states.
example above, probability (composed) transitions s1 ! s2 ! s3 s1 ! s1 ! s2
would given probabilities mail arrived first last, respectively.
certain cases, probability ordering needed. illustrate another
combination function, assume action always occurs exogenous events.
Furthermore, assume events commutative: (a) initial state pair
events e1 e2 , distribution results applying event sequence e1 e2
identical obtained sequence e2 e1 ; (b) occurrence probabilities
intermediate states identical. Intuitively, set events domain, ArrM, ReqC
Mess, property. conditions combined transition distribution
action computed considering probability subset events
applying subset order distribution associated a.
Generally, construct implicit-event model various components
explicit-event model; thus, \natural" specification converted form usually
used MDP solution algorithms. two assumptions above, instance,
form implicit event transition matrix Pr(si ; a; sj ) action a, given matrix
Pcra (si ; sj ) (which assumes event occurrences), matrices Pre (si ; sj ) events
e, occurrence vector Pre(si ) event e. effective transition matrix
9. probability different events may correlated (possibly particular states). case,
necessary specify occurrence probabilities subsets events. treat event occurrence
probabilities independent ease exposition.

12

fiDecision-Theoretic Planning: Structural Assumptions

event e defined follows:
Pcre (si ; sj ) = Pre (si )Pre (si ; sj ) +

(

1 , Pre (si ) : = j
0 : 6= j

equation captures event transition probabilities probability event occurrence factored in. let E; E 0 denote diagonal matrices entries Ekk = Pre (sk )
0 = 1 , Pre (sk ), Pr
c e(si; sj ) = E Pre +E 0. assumptions above,
Ekk
implicit-event matrix Pr(si ; a; sj ) action given Pr = Pcre1 Pcren Pra
ordering n possible events.
Naturally, different procedures constructing implicit-event matrices required
given different assumptions action event interaction. Whether implicit models constructed specified directly without explicit mention exogenous events,
always assume unless stated otherwise action transition matrices take account
effects exogenous events well, thus represent agent's best information
happen takes particular action.

2.4 Observations

Although effects action depend aspect prevailing state,
choice action depend agent observe current state
remember prior observations. model agent's observational sensing
capabilities introducing finite set observations = fo1 ; : : : ; oH g. agent receives
observation set stage prior choosing action stage.
model observation random variable Ot whose value taken O.
probability particular Ot generated depend on:

state system , 1
action taken , 1
state system taking action , 1 effects
exogenous events , 1 realized, action taken.
let Pr(Ot = oh jS t,1 = si ; At,1 = ak ; = sj ) probability agent observes

oh stage given performs ak state si ends state sj . actions,

assume observational distributions stationary (independent stage), using

phi;j;k = Pr(ohjsi; ak ; sj ) denote quantity. view probabilistic dependencies

among state, action observation variables graph time-indexed variables
shown nodes one variable directly probabilistically dependent another
edge latter former; see Figure 8.
model allows wide variety assumptions agent's sensing capabilities.
one extreme fully observable MDPs (FOMDPs), agent knows exactly
state stage t. model case letting = setting
Pr(oh jsi ; ak ; sj ) =
13

(

1 iff oh = sj
0 otherwise

fiBoutilier, Dean, & Hanks



t-1





t-1







Figure 8: Graph showing dependency relationships among states, actions observations different times.
example above, means robot always knows exact location whether
mail waiting mailbox, even mailroom mail arrives.
agent thus receives perfect feedback results actions effects
exogenous events|it noisy effectors complete, noise-free, \instantaneous"
sensors. recent AI research adopts MDP framework explicitly assumes full
observability.
extreme might consider non-observable systems (NOMDPs)
agent receives information system's state execution. model
case letting = fog. observation reported stage, revealing
information state, Pr(sj jsi ; ak ; o) = Pr(sj jsi ; ak ). open-loop
systems, agent receives useful feedback results actions: agent
noisy effectors sensors. case agent chooses actions according plan
consisting sequence actions executed unconditionally. effect, agent relying
predictive model determine good action choices execution time.
Traditionally, AI planning work implicitly made assumption non-observability,
often coupled omniscience assumption|that agent knows initial state
certainty, predict effects actions perfectly, precisely predict occurrence exogenous events effects. circumstances, agent
predict exact outcome plan, thus obviating need observation.
agent build straight-line plan|a sequence actions performed without
feedback|that good plan whose execution might depend information gathered execution time.
two extremes special cases general observation model described above,
allows agent receive incomplete noisy information system state
(i.e., partially observable MDPs, POMDPs). example, robot might able
determine location exactly, might able determine whether mail arrives
unless mailroom. Furthermore, \mail" sensors might occasionally report
inaccurately, leading incorrect belief whether mail waiting.

Example 2.3 Suppose robot \checkmail" action change system

state generates observation uenced presence mail, provided
14

fiDecision-Theoretic Planning: Structural Assumptions

Loc(M );
Loc(M );
Loc(M );
Loc(M );

Pr(Obs = mail) Pr(Obs = nomail)
0:92
0:08
0:05
0:95
0:00
1:00
0:00
1:00

Figure 9: Observation probabilities checking mailbox.
robot mailroom time action performed. robot
mailroom, sensor always reports \no mail." noisy \checkmail" sensor
described probability distribution like one shown Figure 9.
view error probabilities probability \false positives" (0:05) \false
negatives" (0:08). 2

2.5 System Trajectories Observable Histories

use terms trajectory history interchangeably describe system's behavior
course problem-solving episode, perhaps initial segment thereof.
complete system history sequence states, actions, observations generated
stage 0 time point interest, finite infinite length. Complete
histories represented (possibly infinite) sequence tuples form

hhS 0 ; O0 ; A0 i; hS 1 ; O1 ; A1 i; : : : hS ; OT ; ii
define two alternative notions history contain less complete information.
arbitrary stage define observable history sequence

hhO0 ; A0 i; : : : ; hOt,1 ; At,1 ii
O0 observation initial state. observable history stage comprises
information available agent history chooses action stage t.
third type trajectory system trajectory, sequence

hhS 0 ; A0 i; : : : ; hS t,1 ; At,1 i;
describing system's behavior \objective" terms, independent agent's particular
view system.
evaluating agent's performance, generally interested system
trajectory. agent's policy must defined terms observable history, since
agent access system trajectory, except fully observable case,
two equivalent.

2.6 Reward Value

problem facing decision maker select action performed stage
decision problem, making decision basis observable history.
agent still needs way judge quality course action. done defining
15

fiBoutilier, Dean, & Hanks



t-1





t-1



C



R



Figure 10: Decision process rewards action costs.
value function V() function mapping set system histories HS reals;
is, V : HS ! R.10 agent prefers system history h h0 case V(h) > V(h0 ).
Thus, agent judges behavior good bad depending effect
underlying system trajectory. Generally, agent cannot predict certainty
system trajectory occur, best generate probability distribution
possible trajectories caused actions. case, computes expected value
candidate course action chooses policy maximizes quantity.
system dynamics, specifying value function arbitrary trajectories
cumbersome unintuitive. therefore important identify structure
value function lead parsimonious representation.
Two assumptions value functions commonly made MDP literature
time-separability additivity. time-separable value function defined terms
primitive functions applied component states actions. reward
function R : ! R associates reward state s. Costs assigned
taking actions defining cost function C : ! R associates cost
performing action state s. Rewards added value function, costs
subtracted.11
value function time-separable \simple combination" rewards costs
accrued stage. \Simple combination" means value taken function
costs rewards stage, costs rewards depend stage t,
function combines must independent stage, commonly linear
combination product.12 value function additive combination function
sum reward cost function values accrued history's stages. addition
rewards action costs system time-separable value viewed graphically
shown Figure 10.
assumption time-separability restrictive. example, might
certain goals involving temporal deadlines (have workplace tidy soon possible
9:00 tomorrow morning) maintenance (do allow mail sit mailroom
10. Technically, set histories interest also depends horizon chosen, described below.
11. term \reward" somewhat misnomer reward could negative, case
\penalty" might better word. Likewise, \costs" either positive (punitive) negative (beneficial). Thus, admit great exibility defining value functions.
12. See (Luenberger, 1973) precise definition time-separability.

16

fiDecision-Theoretic Planning: Structural Assumptions

undelivered 10 minutes) require value functions non-separable
given current representation state. Note, however, separability|like
Markov property|is property particular representation. could add additional
information state example: clock time, interval time 9:00
time tidiness achieved, length time mail sits mail room
robot picks up, on. additional information could reestablish time-separable value function, expense increase number
states ad hoc cumbersome action representation.13

2.7 Horizons Success Criteria

order evaluate particular course action, need specify long (in
many stages) executed. known problem's horizon. finite-horizon
problems, agent's performance evaluated fixed, finite number stages .
Commonly, aim maximize total expected reward associated course
action; therefore define (finite-horizon) value length history h (Bellman,
1957):

V (h) =

TX
,1
t=0

fR(st ) , C (st; )g + R(sT )

infinite-horizon problem, hand, requires agent's performance
evaluated infinite trajectory. case total reward may unbounded,
meaning policy could arbitrarily good bad executed long enough.
case may necessary adopt different means evaluating trajectory.
common introduce discount factor, ensuring rewards costs accrued
later stages counted less accrued earlier stages. value function
expected total discounted reward problem defined follows (Bellman, 1957; Howard,
1960):
1
X
V (h) = (R(st) , C (st; ))
t=0

fixed discount rate (0 < 1). formulation particularly simple
elegant way ensure bounded measure value infinite horizon, though
important verify discounting fact appropriate. Economic justifications often
provided discounted models|a reward earned sooner worth one earned
later provided reward somehow invested. Discounting also suitable
modeling process terminates probability 1 , point time (e.g.,
robot break down), case discounted models correspond expected total
reward finite uncertain horizon. reasons, discounting sometimes used
finite-horizon problems well.
Another technique dealing infinite-horizon problems evaluate trajectory
based average reward accrued per stage, gain. gain history defined
n
X
g(h) = lim 1 fR(st ) , C (st ; )g
n!1 n t=0

13. See (Bacchus, Boutilier, & Grove, 1996, 1997), however, systematic approach handling certain
types history-dependent reward functions.

17

fiBoutilier, Dean, & Hanks

Refinements criterion also proposed (Puterman, 1994).
Sometimes problem ensures total reward infinite trajectory
bounded, thus expected total reward criterion well-defined. Consider case
common AI planners agent's task bring system goal state.
positive reward received goal reached, actions incur non-negative
cost, goal reached system enters absorbing state
rewards costs accrued. long goal reached certainty,
situation formulated infinite-horizon problem total reward bounded
desired trajectory (Bertsekas, 1987; Puterman, 1994). general, problems
cannot formulated (fixed) finite-horizon problems unless priori bound
number steps needed reach goal established. problems sometimes
called indefinite-horizon problems: practical point view, agent continue
execute actions finite number stages, exact number cannot determined
ahead time.

2.8 Solution Criteria

complete definition planning problem need specify constitutes
solution problem. see split explicit MDP formulations
work AI planning community. Classical MDP problems generally stated
optimization problems: given value function, horizon, evaluation metric (e.g.,
expected total reward, expected total discounted reward, expected average reward per stage)
agent seeks behavioral policy maximizes objective function.
Work AI often seeks satisficing solutions problems. planning literature,
generally taken plan satisfies goal equally preferred
plan satisfies goal, plan satisfies goal preferable
plan not.14 probabilistic framework, might seek plan satisfies
goal maximum probability (an optimization), lead situations
optimal plan infinite length system state fully observable.
satisficing alternative (Kushmerick, Hanks, & Weld, 1995) seek plan satisfies
goal probability exceeding given threshold.

Example 2.4 extend running example demonstrate infinite-horizon, fully
observable, discounted reward situation. begin adding one new dimension
state description, boolean variable RHM (does robot mail), giving us
system 20 states. also provide agent two additional actions: PUM
(pickup mail) DelM (deliver mail) described Figure 2. reward
agent way mail delivery encouraged: associate reward
10 state RHM false 0 states.
actions cost, agent gets total reward 20 six-stage system
trajectory:
hLoc(M ); M; RHMi; Stay; hLoc(M ); M; RHMi; PUM; hLoc(M ); M; RHMi;
Clk; hLoc(H ); M; RHMi; Clk; hLoc(O); M; RHMi; DelM; hLoc(O); M; RHMi

14. Though see (Haddawy & Hanks, 1998; Williamson & Hanks, 1994) restatement planning
optimization problem.

18

fiDecision-Theoretic Planning: Structural Assumptions

assign action cost ,1 action except Stay (which 0 cost),
total reward becomes 16. use discount rate 0:9 discount future
rewards costs, initial segment infinite-horizon history would contribute
10 + :9(,1) + :81(,1) + :729(,1) + :6561(,1) + :59054(,1 + 10) = 12:2 total
value trajectory (as subsequently extended). Furthermore, establish
bound total expected value trajectory. best case, subsequent
stages yield reward 10, expected total discounted reward bounded

1
X
12:2 + :96 (10) + :97 (10) + : : : = 12:2 + 10 :96 0:9i < 66
i=0

similar effect behavior achieved penalizing states (i.e., negative
rewards) either RHM true. 2

2.9 Policies

mentioned policies (or courses action, plans) informally point,
provide precise definition. decision problem facing agent viewed
generally deciding action perform given current observable history.
define policy mapping set observable histories HO actions,
is, : HO ! A. Intuitively, agent executes action

= (hho0 ; a0 i; : : : ; hot,1 ; at,1 i; ot i)
stage performed actions a0 ; at,1 made observations o0 ; ot,1
earlier stages, made observation ot current stage.
policy induces distribution Pr(hj) set system histories HS ; probability distribution depends initial distribution P 0 . define expected value
policy be:
X
EV() =
V(h) Pr(hj)
h2HS

would like agent adopt policy either maximizes expected value or,
satisficing context, acceptably high expected value.
general form policy, depending arbitrary observation history,
lead complicated policies policy-construction algorithms. special cases,
however, assumptions observability structure value function result
optimal policies much simpler form.
case fully observable MDP time-separable value function, optimal
action stage computed using information current state
stage: is, restrict policies simpler form : ! without
danger acting suboptimally. due fact full observability allows state
observed completely, Markov assumption renders prior history irrelevant.
non-observable case, observational history contains vacuous observations
agent must choose actions using knowledge previous actions
stage; however, since incorporates previous actions, takes form : ! A.
19

fiBoutilier, Dean, & Hanks

form policy corresponds linear, unconditional sequence actions ha1 ; a2 ; : : : ; i,
straight-line plan AI nomenclature.15

2.10 Model Summary: Assumptions, Problems, Computational
Complexity

concludes exposition MDP model planning uncertainty. generality allows us capture wide variety problem classes currently
studied literature. section review basic components model,
describe problems commonly studied DTP literature respect model,
summarize known complexity results each. Section 3, describe specialized computational techniques used solve problems problem classes.
2.10.1 Model Summary Assumptions

MDP model consists following components:
state space , finite countable set states. generally make Markov
assumption, requires state convey information necessary predict
effects actions events independent information
system history.
set actions A. action ak represented transition matrix size
jS jjS j representing probability pkij performing action ak state si move
system state sj . assume throughout action model stationary,
meaning transition probabilities vary time. transition matrix
action generally assumed account exogenous events might
occur stage action executed.
set observation variables O. set \messages" sent agent
action performed, provide execution-time information current
system state. action ak pair states si , sj , pkij > 0,
associate distribution possible observations: pkm
ij denotes probability
obtaining observation om given action ak taken si resulted
transition state sj .
value function V . value function maps state history real number
V (h1 ) V (h2 ) case agent considers history h1 least good
h2 . state history records progression states system assumes along
actions performed. Assumptions time-separability additivity
common V . particular, generally use reward function R cost function
C defining value.
horizon . number stages state histories
evaluated using V .
15. Many algorithms AI literature produce partially ordered sequence actions. plans
not, however, involve conditional nondeterministic execution. Rather, represent fact
linear sequence consistent partial order solve problem. Thus, partially ordered
plan concise representation particular set straight-line plans.

20

fiDecision-Theoretic Planning: Structural Assumptions

optimality criterion. provides criterion evaluating potential solutions
planning problems.

2.10.2 Common Planning Problems

use general framework classify various problems commonly studied
planning decision-making literature. case below, note modeling assumptions define problem class.

Planning Problems OR/Decision Sciences Tradition
Fully Observable Markov Decision Processes (FOMDPs) | ex-

tremely large body research studying FOMDPs, present basic algorithmic techniques detail next section. commonly used formulation FOMDPs assumes full observability stationarity, uses optimality
criterion maximization expected total reward finite horizon, maximization expected total discounted reward infinite horizon, minimization
expected cost goal state.
FOMDPs introduced Bellman (1957) studied depth
fields decision analysis OR, including seminal work Howard (1960). Recent texts FOMDPs include (Bertsekas, 1987) (Puterman, 1994). Average reward optimality also received attention literature (Blackwell, 1962; Howard,
1960; Puterman, 1994). AI literature, discounted total reward models
popular well (Barto et al., 1995; Dearden & Boutilier, 1997; Dean, Kaelbling, Kirman, & Nicholson, 1995; Koenig, 1991), though average-reward criterion
proposed suitable modeling AI planning problems (Boutilier &
Puterman, 1995; Mahadevan, 1994; Schwartz, 1993).

Partially Observable Markov Decision Processes (POMDPs) | POMDPs

closer FOMDPs general model decision processes described.
POMDPs generally studied assumption stationarity optimality criteria identical FOMDPs, though average-reward criterion
widely considered. discuss below, POMDP viewed
FOMDP state space consisting set probability distributions
. probability distributions represent states belief: agent \observe"
state belief system although exact knowledge
system state itself.
POMDPs widely studied control theory (Astrom, 1965; Lovejoy, 1991b; Smallwood & Sondik, 1973; Sondik, 1978), drawn increasing
attention AI circles (Cassandra, Kaelbling, & Littman, 1994; Hauskrecht, 1998;
Littman, 1996; Parr & Russell, 1995; Simmons & Koenig, 1995; Thrun, Fox, & Burgard, 1998; Zhang & Liu, 1997). uence diagrams (Howard & Matheson, 1984;
Shachter, 1986) popular model decision making AI are, fact,
structured representational method POMDPs (see Section 4.3).

Planning Problems AI Tradition
21

fiBoutilier, Dean, & Hanks

Classical Deterministic Planning | classical AI planning model assumes

deterministic actions: action ak taken state si one successor sj .
important assumptions non-observability value determined
reaching goal state: plan leads goal state preferred
not. Often preference shorter plans; represented
using discount factor \encourage" faster goal achievement assigning
cost actions. Reward associated transitions goal states,
absorbing. Action costs typically ignored, except noted above.
classical models usually assumed initial state known certainty.
contrasts general specification MDPs above, assume
knowledge even distributional information initial state. Policies
defined applicable matter state (or distribution states) one finds
oneself in|action choices defined every possible state history. Knowledge
initial state determinism allow optimal straight-line plans constructed,
loss value associated non-observability, unpredictable exogenous
events uncertain action effects cannot modeled consistently assumptions adopted.
overview early classical planning research variety approaches
adopted, see (Allen, Hendler, & Tate, 1990) well Yang's (1998) recent text.

Optimal Deterministic Planning | separate body work retains classical

assumptions complete information determinism, tries recast planning
problem optimization relaxes implicit assumption \achieve goal
costs." time, methods use sort representations
algorithms applied satisficing planning.
Haddawy Hanks (1998) present multi-attribute utility model planners
keeps explicit information initial state goals, allows preferences stated partial satisfaction goals well cost
resources consumed satisfying them. model also allows expression preferences phenomena like temporal deadlines maintenance intervals
dicult capture using time-separable additive value function. Williamson (1996)
(see also Williamson & Hanks, 1994). implements model extending classical planning algorithm solve resulting optimization problem. Haddawy
Suwandi (1994) also implement model complete decision-theoretic framework.
model planning, refinement planning, differs somewhat generative
model discussed paper. model set possible plans pre-stored
abstraction hierarchy, problem solver's job find hierarchy
optimal choice concrete actions particular problem.
Perez Carbonell's (1994) work also incorporates cost information classical
planning framework, maintains split classical satisficing planner
additional cost information provided utility model. cost information
used learn search-control rules allow classical planner generate low-cost
goal-satisfying plans.
22

fiDecision-Theoretic Planning: Structural Assumptions

Conditional Deterministic Planning | classical planning assumption

omniscience relaxed somewhat allowing state aspects
world unknown. agent thus situation certain
system one particular set states, know one. Unknown
truth values included initial state specification, taking actions
cause proposition become unknown well.
Actions provide agent information plan executed: conditional planners introduce idea actions providing runtime information
prevailing state, distinguishing action makes proposition P true
action tell agent whether P true action executed.
action causal informational effects, simultaneously changing
world reporting value one propositions. second sort
information useful planning time except allows steps plan
executed conditionally, depending runtime information provided prior
information-producing steps. value actions lies fact different
courses action may appropriate different conditions|these informational
effects allow runtime selection actions based observations produced, much
like general POMDP model.
Examples conditional planners classical framework include early work
Warren (1976) recent CNLP (Peot & Smith, 1992), Cassandra (Pryor
& Collins, 1993), Plynth (Goldman & Boddy, 1994), UWL (Etzioni, Hanks,
Weld, Draper, Lesh, & Williamson, 1992) systems.

Probabilistic Planning Without Feedback | direct probabilistic extension

classical planning problem stated follows (Kushmerick et al., 1995):
take input (a) probability distribution initial states, (b) stochastic actions
(explicit implicit transition matrices), (c) set goal states, (d) probability
success threshold . objective produce plan reaches goal state
probability least , given initial state distribution. provision made
execution-time observation, thus straight-line plans form policy
possible. restricted case infinite-horizon NOMDP problem, one
actions incur cost goal states offer positive reward absorbing.
also special case objective find satisficing policy rather
optimal one.

Probabilistic Planning Feedback | Draper et al. (1994a) proposed

extension probabilistic planning problem actions provide feedback,
using exactly observation model described Section 2.4. Again, problem
posed building plan leaves system goal state sucient
probability. plan longer simple sequence actions|it contain conditionals loops whose execution depends observations generated sensing
actions. problem restricted case general POMDP problem: absorbing goal states cost-free actions used, objective find policy
(conditional plan) leaves system goal state sucient probability.
23

fiBoutilier, Dean, & Hanks

Comparing Frameworks: Task-oriented Versus Process-oriented Problems

useful point pause contrast types problems considered classical planning literature typically studied within MDP framework. Although
problems AI planning literature emphasized goal-pursuit \one-shot" view
problem solving, cases viewing problem infinite-horizon decision problem
results satisfying formulation. Consider running example involving oce
robot. simply possible model problem responding coffee requests, mail
arrival keeping lab tidy strict goal-satisfaction problem capturing
possible nuances intuitively optimal behavior.
primary diculty explicit persistent goal states exist.
simply require robot attain state lab tidy, mail awaits,
unfilled coffee requests exist, \successful" plan could anticipate possible system behavior
goal state reached. possible occurrence exogenous events goal
achievement requires robot bias methods achieving goals way
best suits expected course subsequent events. instance, coffee requests
likely point time unmet requests highly penalized, robot
situate coffee room order satisfy anticipated future request quickly.
realistic decision scenarios involve task-oriented process-oriented behavior,
problem formulations take account provide satisfying models
wider range situations.
2.10.3 Complexity Policy Construction

defined planning problem several different ways, different
set assumptions state space, system dynamics actions (deterministic
stochastic), observability (full, partial, none), value function (time-separable, goal only,
goal rewards action costs, partially satisfiable goals temporal deadlines), planning
horizon (finite, infinite, indefinite), optimality criterion (optimal satisficing solutions). set assumptions puts corresponding problem particular complexity
class, defines worst-case time space bounds representation algorithm
solving problem. summarize known complexity results
problem classes defined above.
Fully Observable Markov Decision Processes Fully observable MDPs (FOMDPs)
time-separable, additive value functions solved time polynomial size
state space, number actions, size inputs.16 common algorithms solving FOMDPs value iteration policy iteration,
described next section. finite-horizon discounted infinite-horizon problems
require polynomial amount computation per iteration|O(jS j2 jAj) O(jS j2 jAj+jS j3 ),
respectively|and converge polynomial number iterations (with factor 1,1
discounted case). hand, problems shown P-complete
(Papadimitriou & Tsitsiklis, 1987), means ecient parallel solution algorithm
unlikely.17 space required store policy n-stage finite-horizon problem
16. precisely, maximum number bits required represent transition probabilities
costs.
17. See (Littman, Dean, & Kaelbling, 1995) summary complexity results.

24

fiDecision-Theoretic Planning: Structural Assumptions

O(jS jn). interesting classes infinite-horizon problems, specifically involving discounted models time-separable additive reward, optimal policy
shown stationary, policy stored O(jS j) space.
Bear mind worst-case bounds. many cases, better time bounds
compact representations found. Sections 4 5 explore ways represent
solve problems eciently.
Partially Observable Markov Decision Processes POMDPs notorious
computational diculty. mentioned above, POMDP viewed FOMDP
infinite state space consisting probability distributions , distribution
representing agent's state belief point time (Astrom, 1965; Smallwood &
Sondik, 1973). problem finding optimal policy POMDP objective
maximizing expected total reward expected total discounted reward finite
horizon shown exponentially hard jS j (Papadimitriou
& Tsitsiklis, 1987). problem finding policy maximizes approximately
maximizes expected discounted total reward infinite horizon shown
undecidable (Madani, Condon, & Hanks, 1999).
Even restricted cases POMDP problem computationally dicult worst
case. Littman (1996) considers special case boolean rewards: determining whether
infinite-horizon policy nonzero total reward given rewards associated states non-negative. shows problem EXPTIME-complete
transitions stochastic, PSPACE-hard transitions deterministic.
Deterministic Planning Recall classical planning problem defined quite
differently MDP problems above: agent ability observe state
perfect predictive powers, knowing initial state effects actions
certainty. addition, rewards come reaching goal state, plan
achieves goal suces.
Planning problems typically defined terms set P boolean features
propositions: complete assignment truth values features describes exactly one state,
partial assignment truth values describes set states. set propositions P
induces state space size 2jPj. Thus, space required represent planning problem
using feature-based representation exponentially smaller required
representation problem (see Section 4).
ability represent planning problems compactly dramatic impact worstcase complexity. Bylander (1994) shows deterministic planning problem without
observation PSPACE-complete. Roughly speaking, means worst planning
time increase exponentially P A, further, size solution plan
grow exponentially problem size. results hold even action
space severely restricted. example, planning problem NP-complete even
cases action restricted one precondition feature one postcondition
feature. Conditional optimal planning PSPACE-complete well. results
inputs generally compact (generally exponentially so)
terms complexity FOMDP POMDP problems phrased.
Probabilistic Planning probabilistic goal-oriented planning, POMDPs,
typically search solution space probability distributions states (or
25

fiBoutilier, Dean, & Hanks

formulas describe states). Even simplest problem probabilistic planning|one
admits observability|is undecidable worst (Madani et al., 1999). intuition
even though set states finite, set distributions states not,
worst agent may search infinite number plans able
determine whether solution exists. algorithm guaranteed find
solution plan eventually one exists, cannot guaranteed terminate finite time
solution plan. Conditional probabilistic planning generalization
non-observable probabilistic planning problem, thus undecidable well.
interesting note connection conditional probabilistic planning
POMDPs. actions observations two problems equivalent expressive
power, reward structure conditional probabilistic planning problem quite
restrictive: goal states positive rewards, states reward, goal states
absorbing. Since cannot put priori bound length solution plan,
conditional probabilistic planning must viewed infinite-horizon problem
objective maximize total expected undiscounted reward. Note, however, since goal
states absorbing, guarantee total expected reward non-negative
bounded, even infinite horizon. Technically means conditional probabilistic planning problem restricted case infinite-horizon positive-bounded problem
(Puterman, 1994, Section 7.2). therefore conclude problem solving
arbitrary infinite-horizon undiscounted positive-bounded POMDP also undecidable.
commonly studied problem infinite-horizon POMDP criterion maximizing expected discounted total reward; finding optimal near-optimal solutions
problem also undecidable, noted above.
2.10.4 Conclusion

end section noting results algorithm-independent describe worst-case behavior. effect, indicate badly algorithm made
perform \arbitrarily unfortunate" problem instance. interesting question
whether build representations, techniques, algorithms typically perform
well problem instances typically arise practice. concern leads us examine
problem characteristics eye toward exploiting restrictions placed
states actions, observability, value function optimality criterion.
begin algorithmic techniques focus value function|particularly
take advantage time-separability goal orientation. following section
explore complementary techniques building compact problem representations.

3. Solution Algorithms: Dynamic Programming Search
section review standard algorithms solving problems described
terms \unstructured" \ at" problem representations. noted analysis
above, fully observable Markov decision processes (FOMDPs) far widely
studied models general class stochastic sequential decision problems. begin
describing techniques solving FOMDPs, focusing techniques exploit structure
value function like time-separability additivity.
26

fiDecision-Theoretic Planning: Structural Assumptions

3.1 Dynamic Programming Approaches

Suppose given fully-observable MDP time-separable, additive value function.
words, given state space , action space A, transition matrix Pr(s0 js; a)
action a, reward function R, cost function C . start problem
finding policy maximizes expected total reward fixed, finite-horizon .
Suppose given policy (s; t) action performed agent
state stages remaining act (for 0 ).18 Bellman (1957) shows
expected value policy state computed using set t-stage-to-go
value functions Vt . define V0 (s) R(s), define:

Vt (s) = R(s) + C ((s; t)) +

X

2S
0

fPr(s0j(s; t); s)Vt,1 (s0)g

(1)

definition value function makes its0 dependence initial state clear.
say policy optimal VT (s) VT (s) policies 0 2 .
optimal -stage-to-go value function, denoted VT , simply value function
optimal -horizon policy. Bellman's principle optimality (Bellman, 1957) forms basis
stochastic dynamic programming algorithms used solve MDPs, establishing
following relationship optimal value function tth stage optimal value
function previous stage:

Vt (s) = R(s) + max
fC (a) +
a2A

X

s0 2S

Pr(s0 ja; s)Vt,1 (s0 )g

(2)

3.1.1 Value Iteration

Equation 2 forms basis value iteration algorithm finite-horizon problems.
Value iteration begins value function V0 = R, uses Equation 2 compute
sequence value functions longer time intervals, horizon . action
maximizes right-hand side Equation 2 chosen policy element (s; t).
resulting policy optimal -stage, fully observable MDP, indeed
shorter horizon < .
important note policy describes done every stage
every state system, even agent cannot reach certain states given system's
initial configuration available actions. return point below.

Example 3.1 Consider simplified version robot example, four

state variables , CR, RHC, RHM (movement various locations ignored),
four actions GetC, PUM, DelC, DelM. Actions GetC PUM make RHC
RHM, respectively, true certainty. Action DelM, RHM holds, makes
RHM false probability 1.0; DelC makes CR RHC false
probability 0.3, leaving state unchanged probability 0.7. reward 3
associated CR reward 1 associated . reward state
sum rewards objective satisfied state. Figure 11 shows
optimal 0-stage, 1-stage 2-stage value functions various states, along

18. Recall FOMDPs aspects history relevant.

27

fiBoutilier, Dean, & Hanks

State
s0 = hM; RHM; CR; RHCi
s1 = hM; RHM; CR; RHCi
s2 = hM; RHM; CR; RHCi
s3 = hM; RHM; CR; RHCi
s4 = hM; CR; RHCi
s5 = hM; CR; RHCi
s6 = hM; RHM; CRi
s7 = hM; RHM; CRi
s8 = hM; CRi

V0

0
0
0
0
1
1
3
3
4

V1

0
1
0.9
1
2.9
2
7
6
8

(1)

(2)

1 PUM
DelM 2 DelM
DelC 2.43 DelC
DelM 2.9 DelM
DelC 5.43 DelC
3.9 GetC
DelM 11 DelM
10 PUM
12
V2

Figure 11: Finite-horizon optimal value policy.
optimal choice action state-stage pairing (the values \state"
missing variables hold instantiations variables). Note V0 (s)
simply R(s) state s.
illustrate application Equation 2, first consider calculation V1 (s3 ).
robot choice delivering coffee delivering mail, expected value
option, one stage remaining, given by:
EV1 (s3; DelC) = 0:3V0(s6) + 0:7V0 (s3) = 0:9
EV1(s3; DelM) =
1:0V0 (s4 )
= 1:0
Thus (s3 ; 1) = DelM V1 (s3 ) value maximizing choice. Notice
robot one action perform aim \lesser" objective due
risk failure inherent delivering coffee. two stages remaining
state, robot deliver mail, certainty move s4 one
stage go, attempt deliver coffee ( (s4 ; 1) = DelC).
illustrate effects fixed finite horizon policy choice, note
(s0; 2) = PUM. two stages remaining choice getting mail coffee,
robot get mail subsequent delivery (in last stage) guaranteed
succeed, whereas subsequent coffee delivery may fail. However, compute
(s0; 3), see:
EV3(s0 ; GetC) = 1:0V2(s2 ) = 2:43
EV3 (s0; PUM) = 1:0V2(s1 ) = 2:0
three stages go, robot instead retrieve coffee s0 .
coffee, two chances successful delivery. expected value course
action greater (guaranteed) mail delivery. Note three stages
allow sucient time try achieve objectives s0 . fact,
larger reward associated coffee delivery ensures greater number
stages remaining, robot focus first coffee retrieval delivery,
attempt mail retrieval delivery coffee delivery successfully completed. 2
Often faced tasks fixed finite horizon. example,
may want robot perform tasks keeping lab tidy, picking mail whenever
28

fiDecision-Theoretic Planning: Structural Assumptions

arrives, responding coffee requests, on. fixed time horizon associated
tasks|they performed need arises. problems best
modeled infinite-horizon problems.
consider problem building policy maximizes discounted sum
expected rewards infinite horizon.19 Howard (1960) showed always
exists optimal stationary policy problems. Intuitively, case
matter stage process in, still infinite number stages remaining;
optimal action state independent stage. therefore restrict
attention policies choose action state regardless stage
process. restriction, policy size jSj regardless
number stages policy executed|the policy form : ! A.
contrast, optimal policies finite-horizon problems generally nonstationary,
illustrated Example 3.1.
Howard also shows value policy satisfies following recurrence:

V (s) = R(s) + fC ((s)) +

X

s0 2S

optimal value function V satisfies:

V (s) = R(s) + max
fC (a) +
a2A

Pr(s0 j(s); s)V (s0 )g

X
2S
0

Pr(s0 ja; s)V (s0 )g

(3)
(4)

value fixed policy evaluated using method successive approximation, almost identical procedure described Equation 1 above. begin
arbitrary assignment values V0 (s), define:

Vt (s) = R(s) + C ((s; t)) +

X

2S
0

fPr(s0j(s; t); s)Vt,1 (s0)g

(5)

sequence functions Vt converges linearly true value function V .
One also alter value-iteration algorithm slightly builds optimal policies
infinite-horizon discounted problems. algorithm starts value function V0
assigns arbitrary value 2 . Given value estimate Vt (s) state s, Vt+1 (s)
calculated as:

Vt+1 (s) = R(s) + max
fC (a) +
a2A

X

s0 2S

Pr(s0 ja; s) Vt (s0 )g

(6)

sequence functions Vt converges linearly optimal value function V (s).
finite number iterations n, choice maximizing action forms
optimal policy Vn approximates value.20
19. far commonly studied problem literature, though argued (Boutilier &
Puterman, 1995; Mahadevan, 1994; Schwartz, 1993) problems often best modeled using
average reward per stage optimality criterion. discussion average reward optimality
many variants refinements, see (Puterman, 1994).
20. number iterations n based stopping criterion generally involves measuring difference Vt Vt+1 . discussion stopping criteria convergence algorithm, see
(Puterman, 1994).

29

fiBoutilier, Dean, & Hanks

3.1.2 Policy Iteration

Howard's (1960) policy-iteration algorithm alternative value iteration infinitehorizon problems. Rather iteratively improving estimated value function, instead
modifies policies directly. begins arbitrary policy 0 , iterates, computing
i+1 i.
iteration algorithm comprises two steps, policy evaluation policy improvement:
1. (Policy evaluation) 2 , compute value function V (s) based
current policy .
2. (Policy improvement) 2 , find action maximizes

Qi+1(a; s) = R(s) + C (a) +

X

s0 2S

Pr(s0 ja; s) V (s0 )

(7)

Qi+1 (a ; s) > V (s), let i+1 = ; otherwise i+1 (s) = (s).21
algorithm iterates i+1 (s) = (s) states s. Step 1 evaluates current
policy solving N N linear system represented Equation 3 (one equation
2 ), computationally expensive. However, algorithm converges
optimal policy least linearly certain conditions converges superlinearly
quadratically (Puterman, 1994). practice, policy iteration tends converge many
fewer iterations value iteration. Policy iteration thus spends computational
time individual stage, result fewer stages need computed.22
Modified policy iteration (Puterman & Shin, 1978) provides middle ground
policy iteration value iteration. structure algorithm exactly
policy iteration, alternating evaluation improvement phases. key insight
one need evaluate policy exactly order improve it. Therefore, evaluation
phase involves (usually small) number iterations successive approximation (i.e.,
setting V = Vt small t, using Equation 6). tuning value
used iteration, modified policy iteration work extremely well practice
(Puterman, 1994). value iteration policy iteration special cases modified
policy iteration, corresponding setting = 0 = 1, respectively.
number variants value policy iteration proposed.
instance, asynchronous versions algorithms require value function
constructed, policy improved, state lockstep. case value iteration
infinite-horizon problems, long state updated suciently often, convergence
assured. Similar guarantees provided asynchronous forms policy iteration. variants important tools understanding various online approaches
solving MDPs (Bertsekas & Tsitsiklis, 1996). nice discussion asynchronous dynamic
programming, see (Bertsekas, 1987; Bertsekas & Tsitsiklis, 1996).
21. Q-function defined Equation 7, called use Q-learning (Watkins & Dayan,
1992), gives value performing action state assuming value function V accurately ects
future value.
22. See (Littman et al., 1995) discussion complexity algorithm.

30

fiDecision-Theoretic Planning: Structural Assumptions

3.1.3 Undiscounted Infinite-Horizon Problems

diculty finding optimal solutions infinite-horizon problems total reward
grow without limit time. Thus, problem definition must provide way
ensure value metric bounded arbitrarily long horizons. use expected
total discounted reward optimality criterion offers particularly elegant way
guarantee bound, since infinite sum discounted rewards finite. However, although
discounting appropriate certain classes problems (e.g., economic problems,
system may terminate point certain probability), many realistic
AI domains dicult justify counting future rewards less present rewards,
discounted-reward criterion appropriate.
variety ways bound total reward undiscounted problems.
cases problem structured reward bounded. planning problems,
example, goal reward collected once, actions incur cost.
case total reward bounded problem legitimately posed
terms maximizing total expected undiscounted reward many cases (e.g., goal
reached certainty).
cases discounting inappropriate total reward unbounded, different
success criteria employed. example, problem instead posed one
wish maximize expected average reward per stage, gain. Computational
techniques constructing gain-optimal policies similar dynamic-programming
algorithms described above, generally complicated, convergence rate
tends quite sensitive communicating structure periodicity MDP.
Refinements gain optimality also studied. example, bias optimality
used distinguish two gain-optimal polices giving preference policy whose total
reward initial segment policy execution larger. Again, algorithms
complicated discounted problems, variants standard
policy value iteration. See (Puterman, 1994) details.
3.1.4 Dynamic Programming POMDPs

Dynamic programming techniques applied partially observable settings well
(Smallwood & Sondik, 1973). main diculty building policies situations
state fully observable that, since past observations provide information
system's current state, decisions must based information gleaned
past. result, optimal policy depend observations agent made since
beginning execution. history-dependent policies grow size exponential
length horizon. history-dependence precludes dynamic programming,
observable history summarized adequately probability distribution
(Astrom, 1965), policies computed function distributions, belief
states.
key observation Sondik (Smallwood & Sondik, 1973; Sondik, 1978)
one views POMDP time-separable value function taking state space
set probability distributions , one obtains fully observable MDP
solved dynamic programming. (computational) problem approach
31

fiBoutilier, Dean, & Hanks

state space FOMDP N -dimensional continuous space,23 special
techniques must used solve (Smallwood & Sondik, 1973; Sondik, 1978).
explore techniques here, note currently practical
small problems (Cassandra et al., 1994; Cassandra, Littman, & Zhang, 1997;
Littman, 1996; Lovejoy, 1991b). number approximation methods, developed
(Lovejoy, 1991a; White III & Scherer, 1989) AI (Brafman, 1997; Hauskrecht, 1997;
Parr & Russell, 1995; Zhang & Liu, 1997), used increase range solvable
problems, even techniques presently limited practical value.
POMDPs play key role reinforcement learning well, \natural state
space" consisting agent observations provides incomplete information underlying system state (see, e.g., McCallum, 1995).

3.2 AI Planning State-Based Search
noted Section 2.7 classical AI planning problem formulated
infinite-horizon MDP therefore solved using algorithm like value iteration.
Recall two assumptions classical planning specialize general MDP model, namely
determinism actions use goal states instead general reward function.
third assumption|that want construct optimal course action starting
known initial state|does counterpart FOMDP model presented above,
since policy dictates optimal action state stage plan.
see below, interest online algorithms within AI led revised formulations
FOMDPs take initial current states account.
Though defined classical planning problem earlier non-observable process
(NOMDP), solved fully observable. let G set goal states
sinit initial state. Applying value iteration type problem equivalent
determining reachability goal states system states. instance,
make goal states absorbing, assign reward 1 transitions 2 , G
g 2 G 0 others, set states Vk (s) > 0 exactly
set states lead goal state.24 particular, Vk (sinit ) > 0,
successful plan constructed extracting actions k-stage (finite-horizon)
policy produced value iteration. determinism assumption means agent
predict state perfectly every stage execution; fact cannot observe
state unimportant.
assumptions commonly made classical planning exploited computationally value iteration. First, terminate process first iteration k
Vk (sinit) > 0, interested plans begin sinit, acting
optimally every possible start state. Second, terminate value iteration jS j
iterations: VjS j(sinit ) = 0 point, algorithm searched every possible
state guarantee solution plan exists. Therefore, view classical planning finite-horizon decision problem horizon jS j. use value iteration
23. accurately, N -dimensional simplex, (N , 1)-dimensional space.
24. Specifically, Vk (s) indicates probability one reaches goal region optimal
policy 2 , G stochastic settings. deterministic case discussed, value must
1 0.

32

fiDecision-Theoretic Planning: Structural Assumptions

equivalent using Floyd-Warshall algorithm find minimum-cost path
weighted graph (Floyd, 1962).
3.2.1 Planning Search

value iteration can, theory, used classical planning, take advantage
fact goal initial states known. particular, computes value
policy assignment states stages. wasteful since optimal
actions computed states cannot reached sinit cannot possibly
lead state g 2 G. also problematic jS j large, since iteration
value iteration requires O(jS jjAj) computations. reason dynamic programming
approaches used extensively AI planning.
restricted form value function, especially fact initial goal states
given, makes advantageous view planning graph-search problem. Unlike
general FOMDPs, generally known priori states desirable
respect (long-term) value, well-defined set target states classical planning
problem makes search-based algorithms appropriate. approach taken
AI planning algorithms.
One way formulate problem graph search make node graph
correspond state . initial state goal states identified,
search proceed either forward backward graph, directions
simultaneously.
forward search, initial state root search tree. node chosen
tree's fringe (the set leaf nodes), feasible actions applied.
action application extends plan one step (or one stage) generates unique new
successor state, new leaf node tree. node pruned state
defines already tree. search ends state identified member
goal set (in case solution plan extracted tree), branches
pruned (in case solution plan exists). Forward search attempts build
plan beginning end, adding actions end current sequence actions.
Forward search never considers states cannot reached sinit .
Backward search viewed several different ways. could arbitrarily select
g 2 G root search tree, expand search tree fringe
selecting state fringe adding tree states action would
cause system enter chosen state. general, action give rise
one predecessor vertex, even actions deterministic. state pruned
appears search tree already. search terminates initial state added
tree, solution plan extracted tree. search similar
dynamic-programming-based algorithms finding shortest path graph.
difference backward search considers states depth k search
tree reach chosen goal state within k steps. Dynamic programming algorithms,
contrast, visit every state every stage search.
One diculty backward approach described commitment
particular goal state. course, assumption relaxed, algorithm could
\simultaneously" search paths goal states adding first level search
33

fiBoutilier, Dean, & Hanks

tree vertex reach g 2 G. see Section 5 goal regression
viewed this, least implicitly.
generally thought regression (or backward) techniques effective
practice progression (or forward) methods. reasoning branching factor
forward graph, number actions feasibly applied given
state, substantially larger branching factor reverse graph,
number operators could bring system given state.25 especially true
goal sets represented small set propositional literals (Section 5). two
approaches mutually exclusive, however: one mix forward backward expansions underlying problem graph terminate forward path backward
path meet.
important thing observe algorithms restrict attention relevant reachable states. forward search, states
reached sinit ever considered: provide benefit dynamic programming
methods states reachable, since unreachable states cannot play role constructing successful plan. backward approaches, similarly, states lying path
goal region G considered, significant advantages dynamic
programming fraction state space connected goal region.
contrast, dynamic programming methods (with exception asynchronous methods) must examine entire state space every iteration. course, ability ignore
parts state space comes planning's stringent definition relevant: states
G positive reward, states matter except extent move agent
closer goal, choice action states unreachable sinit interest.
state-based search techniques use knowledge specific initial state specific
goal set constrain search process, forward search exploit knowledge
goal set, backward search exploit knowledge initial state. GraphPlan
algorithm (Blum & Furst, 1995) viewed planning method integrates
propagation forward reachability constraints backward goal-informed search.
describe approach Section 5. Furthermore, work partial order planning (POP)
viewed slightly different approach form search. described
Section 5, discuss feature-based intensional representations MDPs
planning problems.
3.2.2 Decision Trees Real-time Dynamic Programming

State-based search techniques limited deterministic, goal-oriented domains. Knowledge initial state exploited general MDPs well, forming basis
decision tree search algorithms. Assume given finite-horizon FOMDP
horizon initial state sinit . decision tree rooted sinit constructed much
way search tree deterministic planning problem (French, 1986). action
applicable sinit forms level 1 tree. states s0 result positive probability actions occur applied sinit placed level 2, arc
25. See Bacchus et al. (1995, 1998) recent work makes case progression good
search control, Bonet et al. (1997) argue progression deterministic planning useful
integrating planning execution.

34

fiDecision-Theoretic Planning: Structural Assumptions

init
V = max(V1 , V2 )
a1
p1

a2
p2

s1
a1

p3

s2
a2

a1

V1
p4

s3
a2

a1

V2 = p V 3 + p V4
3
4

s4
a2

a1

a2

V3

V4

Figure 12: initial stages decision tree evaluating action choices sinit .
value action expected value successor states, value
state maximum values successor actions (as indicated
dashed arrows selected nodes).
labeled probability Pr(s0 ja; sinit ) relating s0 a. Level 3 actions applicable
states level 2, on, tree grown depth 2T , point
branch tree path consisting positive-probability length-T trajectory rooted
sinit (see Figure 12).
relevant part optimal -stage value function optimal policy easily
computed using tree. say value node tree labeled
action expected value successor states tree (using probabilities labeling
arcs), value node tree labeled state sum R(s)
maximum value successor actions.26 rollback procedure, whereby value
leaves tree first computed values successively higher levels tree
determined using preceding values, is, fact, form value iteration. value
state level 2t precisely VT,t (s) maximizing actions form optimal
finite-horizon policy. form value iteration directed: (T , t)-stage-to-go values
computed states reachable sinit within steps. Infinite-horizon
problems solved analogous fashion one determine priori depth
required (i.e., number iterations value iteration needed) ensure convergence
optimal policy.
Unfortunately, branching factor stochastic problems generally much greater
deterministic problems. troublesome still fact one must
construct entire decision tree sure proper values computed, hence
optimal policy constructed. stands contrast classical planning search,
attention focused single branch: goal state reached, path
constructed determines satisfactory plan. worst-case behavior planning may
require searching whole tree, decision-tree evaluation especially problematic
26. States level 2T given value R(s).

35

fiBoutilier, Dean, & Hanks

entire tree must generated general ensure optimal behavior. Furthermore,
infinite-horizon problems pose diculty determining suciently deep tree.
One way around diculty use real time search (Korf, 1990). particular,
real-time dynamic programming, RTDP, proposed (Barto et al., 1995)
way approximately solving large MDPs online fashion. One interleave search
execution approximately optimal policy using form RTDP similar decisiontree evaluation follows. Imagine agent finds particular state sinit .
build partial search tree depth, perhaps uniformly perhaps
branches expanded deeply others. Partial tree construction may halted due
time pressure due assessment agent expansion tree may
fruitful. decision act must made, rollback procedure applied
partial, possibly unevenly expanded decision tree.
Reward values used evaluate leaves tree, may offer
inaccurate picture value nodes higher tree. Heuristic information
used estimate long-term value states labeling leaves. value iteration,
deeper tree, accurate estimated value root (generally speaking)
fixed heuristic. see Section 5 structured representations MDPs
provide means construct heuristics (Dearden & Boutilier, 1994, 1997). Specifically,
admissible heuristics upper lower bounds true values leaf nodes
tree, methods A* branch-and-bound search used.
key advantage integrating search execution actual outcome
action taken used prune tree branches rooted unrealized
outcomes. subtree rooted realized state expanded make
next action choice. algorithm Hansen Zilberstein (1998) viewed
variant methods stationary policies (i.e., state-action mappings)
extracted search process.
RTDP formulated Barto et al. (1995) generally form online, asynchronous value iteration. Specifically, values \rolled backed" cached used
improved heuristic estimates value function states question. technique also investigated (Bonet et al., 1997; Dearden & Boutilier, 1994, 1997; Koenig
& Simmons, 1995), closely tied Korf's (1990) LRTA* algorithm. value
updates also need proceed strictly using decision tree determine states; key
requirement RTDP simply actual state sinit one states whose value
updated decision-action iteration.
second way avoid computational diculties arise large search
spaces use sampling methods. methods sample space possible trajectories use sampled information provide estimates values specific courses
action. approach quite common reinforcement learning (Sutton & Barto, 1998),
simulation models often used generate experience value function
learned. present context, Kearns, Mansour Ng (Kearns, Mansour, &
Ng, 1999) investigated search methods infinite-horizon MDPs successor
states specific action randomly sampled according transition distribution.
Thus, rather expand successor states, sampled states searched. Though
method exponential \effective" horizon (or mixing rate) MDP
required expand actions, number states expanded less required
36

fiDecision-Theoretic Planning: Structural Assumptions

full search, even underlying transition graph sparse. able provide polynomial bounds (ignoring action branching horizon effects) number
trajectories need sampled order generate approximately optimal behavior
high probability.

3.3 Summary

seen dynamic programming methods state-based search methods
used fully observable non-observable MDPs, forward search methods interpretable \directed" forms value iteration. Dynamic programming algorithms
generally require explicit enumeration state space iteration, search
techniques enumerate reachable states; branching factor may require that,
sucient depth search tree, search methods enumerate individual states multiple
times, whereas considered per stage dynamic programming. Overcoming diculty search requires use cycle-checking multiple-path-checking
methods.
note search techniques applied partially observable problems well.
One way search space belief states (just dynamic programming applied belief space MDP|see Section 2.10.2). Specifically, belief
states play role system states stochastic effects actions belief states
induced specific observation probabilities, since observation distinct, fixed
effect belief state. type approach pursued (Bonet & Geffner,
1998; Koenig & Simmons, 1995).

4. Factored Representations

point discussion MDPs used explicit extensional representation
set states (and actions) states enumerated directly. many cases
advantageous, representational computational point view, talk
properties states sets states: set possible initial states, set
states action executed, on. generally convenient
compact describe sets states based certain properties features enumerate
explicitly. Representations descriptions objects substitute objects
called intensional technique choice AI systems.
intensional representation planning systems often built defining set
features sucient describe state dynamic system interest.
example Figure 2, state described set six features: robot's location,
lab's tidiness, whether mail present, whether robot mail, whether
pending coffee request, whether robot coffee. first
second features take one five values, last four take one two
values (true false). assignment values six features completely defines state;
state space thus comprises possible combinations feature values, jSj = 400.
feature, factor, typically assigned unique symbolic name, indicated
second column Figure 2. fundamental tradeoff extensional intensional
representations becomes clear example. extensional representation coffee
example views space possible states single variable takes 400 possible
37

fiBoutilier, Dean, & Hanks

values, whereas intensional factored representation views state cross product
six variables, takes substantially fewer values. Generally, state space
grows exponentially number features required describe system.
fact state system described using set features allows one
adopt factored representations actions, rewards components MDP.
factored action representation, instance, one generally describes effect action
specific state features rather entire states. often provides considerable representational economy. instance, Strips action representation (Fikes & Nilsson,
1971), state transitions induced actions represented implicitly describing
effects actions features change value action executed.
Factored representations compact individual actions affect relatively
features, effects exhibit certain regularities. Similar remarks apply
representation reward functions, observation models, on. regularities
make factored representations suitable many planning problems often exploited
planning decision-making algorithms.
factored representations long used classical AI planning, similar
representations also adopted recent use MDP models within AI.
section (Section 4), focus economy representation afforded exploiting
structure inherent many planning domains. following section (Section 5),
describe structure|when made explicit factored representations|can
exploited computationally plan policy construction.

4.1 Factored State Spaces Markov Chains

begin examining structured states, systems whose state described using
finite set state variables whose values change time.27 simplify illustration
potential space savings, assume state variables boolean.
variables, size state space jSj = N = 2M . large , specifying
representing dynamics explicitly using state-transition diagrams N N matrices
impractical. Furthermore, representing reward function N -vector, specifying
observational probabilities, similarly infeasible. Section 4.2, define class
problems dynamics represented O(M ) space many cases. begin
considering represent Markov chains compactly consider incorporating
actions, observations rewards.
let state variable X take finite number values let
X stand
set possible values. assume
X finite, though much follows
applied countable state action spaces well. say state space
specified using one state variable (this variable denoted general model, taking
values ). state space factored one state variable. state
possible assignment values variables. Letting Xi represent ith state
variable, state space cross product value spaces individual state

variables; is, =
i=1
Xi . denotes state process stage t,
let Xit random variable representing value ith state variable stage t.
27. variables often called uents AI literature (McCarthy & Hayes, 1969). classical
planning, atomic propositions used describe domain.

38

fiDecision-Theoretic Planning: Structural Assumptions

Bayesian network (Pearl, 1988) representational framework compactly representing probability distribution factored form. Although networks typically used represent atemporal problem domains, apply techniques
represent Markov chains, encoding chain's transition probabilities network
structure (Dean & Kanazawa, 1989).
Formally, Bayes net directed acyclic graph vertices correspond random
variables edge two variables indicates direct probabilistic dependency
them. network constructed also ects implicit independencies among
variables. network must quantified specifying probability variable
(vertex) conditioned possible values immediate parents graph. addition,
network must include marginal distribution: unconditional probability
vertex parents. quantification captured associating conditional
probability table (CPT) variable network. Together independence
assumptions defined graph, quantification defines unique joint distribution
variables network. probability event space
computed using algorithms exploit independencies represented within graphical
structure. refer Pearl (1988) details.
Figures 3(a)-(c) (page 7) special cases Bayes nets called \temporal" Bayesian
networks. networks, vertices graph represent system's state different
time points arcs represent dependencies across time points. temporal networks,
vertex's parent temporal predecessor, conditional distributions transition
probability distributions, marginal distributions distributions initial states.
networks Figure 3 ect extensional representation scheme states
explicitly enumerated, techniques building performing inference probabilistic temporal networks designed especially application factored representations.
Figure 13 illustrates two-stage temporal Bayes net (2TBN) describing state-transition
probabilities associated Markov chain induced fixed policy executing
action CClk (repeatedly moving counterclockwise). 2TBN, set variables
partitioned corresponding state variables given time (or stage)
corresponding state variables time + 1. Directed arcs indicate probabilistic dependencies variables Markov chain. Diachronic arcs directed
time variables time + 1 variables, synchronic arcs directed
variables time + 1. Figure 13 contains diachronic arcs; synchronic arcs
discussed later section.
Given state time t, network induces unique distribution states +1.
quantification network describes state particular variable changes
function certain state variables. lack direct arc (or generally directed
path synchronic arcs among + 1 variables) variable Xt another
variable Yt+1 means knowledge Xt irrelevant prediction (immediate,
one-stage) evolution variable Markov process.
Figure 13 shows compact representation best circumstances,
many potential links one stage next omitted. graphical
representation makes explicit fact policy (i.e., action CClk) affect
state variable Loc, exogenous events ArrM, ReqC, Mess affect
39

fiBoutilier, Dean, & Hanks

Loc

Loc





CR

CR

P(Loc t+1 )
Loc L C H
0.1 0.9 0 0 0
0 0.1 0.9 0 0
L
0 0 0.1 0.9 0
C
0 0 0 0.1 0.9
H 0.9 0 0 0 0.1
P(CR t+1)
CR

f

RHC

f
1.0 0
0.2 0.8

RHC

RHM

RHM





Time

Time t+1

P(RHC t+1)
RHC f
1.0 0
f
0 1.0

Figure 13: factored 2TBN Markov chain induced moving counterclockwise
(with selected CPTs shown).
variables , CR, Tidy, respectively.28 Furthermore, dynamics Loc (and
variables) described using knowledge state parent
variables; instance, distribution Loc +1 depends value Loc
previous stage (e.g., Loct = O, Loct+1 = probability 0:9 Loct+1 =
probability 0:1). Similarly, CR become true probability 0:2 (due ReqC
event), true, cannot become false (under simple policy); RHC remains
true (or false) certainty true (or false) previous stage. Finally,
effects relevant variables independent. instantiation variables
time t, distribution next states computed multiplying conditional
probabilities relevant + 1 variables.
ability omit arcs graph based locality independence action
effects strong effect number parameters must supplied complete
model. Although full transition matrix CClk would size 4002 = 160000,
transition model Figure 13 requires 66 parameters.29
example shows 2TBNs exploit independence represent Markov chains
compactly, example extreme effectively relationship
variables|the chain viewed product six independently evolving processes.
28. show CPTs brevity.
29. fact, exploit fact probabilities sum one leave one entry unspecified per row
CPT explicit transition matrix. case, 2TBN requires 48 explicit parameters,
transition matrix requires 400 300 = 159; 600 entries. generally ignore fact comparing
sizes representations.

40

fiDecision-Theoretic Planning: Structural Assumptions

Loc

Loc





CR

CR

RHC

RHC

RHM

RHM





Time

Time t+1

Loc RHC


L

C



H


f
L
f
C
f

f
H
f

P(Loc t+1 )
L C H
1.0 0 0 0 0
0 0.1 0.9 0 0
0 0 0.1 0.9 0
0 0 0 0.1 0.9
0.9 0 0 0 0.1
0.1 0.9 0 0 0
0 0.1 0.9 0 0
0 0 0.1 0.9 0
0 0 0 0.1 0.9
P(CR t+1)
0.9 0 0 0 0.1
Loc RHC CR f

P(RHC t+1)
Loc RHC
f
0.0 1.0

f 0.0 1.0

1.0 0.0
L
f 0.0 1.0
L
1.0 0.0
C
f 0.0 1.0
C
etc.
etc.





L
L
L
L



f
f


f
f
etc.


f

f

f

f

.05 .95
0.2 0.8
1.0 0.0
0.2 0.8
1.0 0.0
0.2 0.8
1.0 0.0
0.2 0.8
etc.

Figure 14: 2TBN Markov chain induced moving counterclockwise delivering coffee.

41

fiBoutilier, Dean, & Hanks

general, \subprocesses" interact, still exhibit certain independencies
regularities exploited 2TBN representation. consider two distinct
Markov chains exhibit different types dependencies.
Figure 14 illustrates 2TBN representing Markov chain induced following
policy: robot consistently moves counterclockwise unless oce
coffee, case delivers coffee user. Notice different variables
dependent: instance, predicting value RHC + 1 requires knowing values
Loc RHC t. CPT RHC shows robot retains coffee stage + 1
certainty, stage t, locations except (where executes DelC,
thus losing coffee). variable Loc also depends value RHC. location
change Figure 13 one exception: robot oce coffee,
location remains (since robot move, executes DelC). effect
variable CR explained follows: robot oce delivers coffee
possession, fulfill outstanding coffee request. However, 0:05 chance CR
remaining true conditions indicates 5% chance spilling coffee.
Even though dependencies (i.e., additional diachronic arcs) 2TBN,
still requires 118 parameters. Again, distribution resulting states determined multiplying conditional distributions individual variables. Even though
variables \related," state known, variables time + 1 (Loct+1 ,
RHCt+1 , etc.) independent. words,
Pr(Loct+1 ; t+1 ; CRt+1 ; RHCt+1 ; RHMt+1 ; t+1 jS ) =
t)
Pr(Loct+1 jS ) Pr(T t+1 jS ) Pr(CRt+1 jS ) Pr(RHCt+1 jS ) Pr(RHMt+1 jS ) Pr(M t+1 jS(8)
Figure 15 illustrates 2TBN representing Markov chain induced policy
above, assume act moving counterclockwise slightly
different effect. suppose that, robot moves hallway
adjacent location, 0:3 chance spilling coffee possession:
fragment CPT RHC Figure 15 illustrates possibility. Furthermore,
robot carrying mail whenever loses coffee (whether \accidentally" \intentionally"
via DelC action), 0:5 chance lose mail. Notice effects
policy variables RHC RHM correlated: one cannot accurately predict
probability RHMt+1 without determining probability RHCt+1 . correlation
modeled synchronic arc RHC RHM + 1 slice network.
independence +1 variables given hold 2TBNs synchronic
arcs. Determining probability resulting state requires simple probabilistic
reasoning, example, application chain rule. example, write
Pr(RHCt+1 ; RHMt+1 jS ) = Pr(RHMt+1 jRHCt+1 ; ) Pr(RHCt+1 jS )
joint distribution + 1 variables given computed Equation 8 above, term replacing Pr(RHCt+1 jS ) Pr(RHMt+1 jS )|while two
variables correlated, remaining variables independent.
refer 2TBNs synchronic arcs, like one Figure 14, simple 2TBNs.
General 2TBNs allow synchronic well diachronic arcs, Figure 15.
42

fiDecision-Theoretic Planning: Structural Assumptions

Loc

Loc





CR

CR

RHC

RHC

RHM

RHM





Time

Time t+1

Pr(RHC t+1 )
Loc RHC f
1.0 1.0

f 0.0 1.0

0.7 0.3
H
f 0.0 1.0
H
1.0 0.0
C
f 0.0 1.0
C
etc.
etc.
Pr(RHMt+1 )
RHC RHC t+1 RHMt f
1.0 0.0



0.0 1.0
f


0.5 0.5

f

0.0 1.0
f
f

1.0 0.0


f
0.0 1.0
f

f
1.0 0.0

f
f
0.0 1.0
f
f
f

Figure 15: 2TBN Markov chain induced moving counterclockwise delivering coffee correlated effects.

4.2 Factored Action Representations

extended Markov chains account different actions, must extend
2TBN representation account fact state transitions uenced
agent's choice action. discuss variety techniques specifying transition
matrices exploit factored state representation produce representations
natural compact explicit transition matrices.
4.2.1 Implicit-Event Models

begin implicit-event model Section 2.3 effects actions
exogenous events combined single transition matrix. consider explicitevent models Section 4.2.4. saw previous section, algorithms value
policy iteration require use transition models ect ultimate transition
probabilities, including effects exogenous events.
One way model dynamics fully observable MDP represent action
separate 2TBN. 2TBN shown Figure 13 seen representation
action CClk (since policy inducing Markov chain example consists
repeated application action alone). network fragment Figure 16(a)
illustrates interesting aspects 2TBN DelC action including effects
exogenous events. above, robot satisfies outstanding coffee request delivers
coffee oce coffee (with 0:05 chance spillage), shown
conditional probability table CR. effect RHC explained follows:
43

fiBoutilier, Dean, & Hanks

Loc

RHC

CR
Time

Loc

RHC

CR
Time t+1

(a)

Pr(RHC t+1 )
Loc RHC f

0.0 1.0

f 0.0 1.0
L
0.3 0.7
f 0.0 1.0
L
0.3 0.7
C
f 0.0 1.0
C
etc.
etc.
Pr(CR t+1 )
Loc RHC CR f
.05 .95


f 0.2 0.8


1.0 0.0
f

f 0.2 0.8
f

1.0 0.0

L
f 0.2 0.8

L
1.0 0.0
f
L
f 0.2 0.8
f
L
etc.
etc.





CR

0.05

RHC

Loc

else

f

f




CR

0.2 1.0

CR

1.0

f

f

0.2

0.2

(b)




CR

0.05

RHC

f

Loc
else

f
f

0.2

CR



1.0

(c)

Figure 16: factored 2TBN action DelC (a) structured CPT representations (b,c).
robot loses coffee (to user spillage) delivers oce; attempts
delivery elsewhere, 0:7 chance random passerby take coffee
robot.
case Markov chains, effects actions different variables
correlated, case must introduce synchronic arcs. correlations
thought ramifications (Baker, 1991; Finger, 1986; Lin & Reiter, 1994).
4.2.2 Structured CPTs

conditional probability table (CPT) node CR Figure 16(a) 20 rows, one
assignment parents. However, CPT contains number regularities.
Intuitively, ects fact coffee request met successfully (i.e.,
variable becomes false) 95% time DelC executed, robot coffee
right location (the user's oce). Otherwise, CR remains true true
becomes true probability 0:2 not. words, three distinct cases
considered, corresponding three \rules" governing (stochastic) effect DelC
CR. represented compactly using decision tree representation
(with \else" branches summarize groups cases involving multivalued variables
Loc) like shown Figure 16(b), compactly still using decision graph
(Figure 16(c)). tree- graph-based representations CPTs, interior nodes labeled
parent variables, edges values variables, leaves terminals distributions
child variable's values.30
Decision-tree decision-graph representations used represent actions fully
observable MDPs (Boutilier et al., 1995; Hoey, St-Aubin, Hu, & Boutilier, 1999)
30. child boolean, label leaves probability variable true (the
probability variable false one minus value).

44

fiDecision-Theoretic Planning: Structural Assumptions

described detail (Poole, 1995; Boutilier & Goldszmidt, 1996).31 Intuitively, trees
graphs embody rule-like structure present family conditional distributions
represented CPT, settings consider often yield considerable representational compactness. Rule-based representations used directly Poole (1995,
1997a) context decision processes often compact trees (Poole,
1997b). generically refer representations type 2TBNs structured CPTs.
4.2.3 Probabilistic STRIPS Operators

2TBN representation viewed oriented toward describing effects actions
distinct variables. CPT variable expresses (stochastically) changes
(or persists), perhaps function state certain variables. However,
long noted AI research planning reasoning action
actions change state limited ways; is, affect relatively small number
variables. One diculty variable-oriented representations 2TBNs one
must explicitly assert variables unaffected specific action persist value (e.g.,
see CPT RHC Figure 13)|this instance infamous frame problem
(McCarthy & Hayes, 1969).
Another form representation actions might called outcome-oriented representation: one explicitly describes possible outcomes action possible joint
effects variables. idea underlying Strips representation
classical planning (Fikes & Nilsson, 1971).
classical Strips operator described precondition set effects.
former identifies set states action executed, latter
describes input state changes result taking action. probabilistic
Strips operator (PSO) (Hanks, 1990; Hanks & McDermott, 1994; Kushmerick et al., 1995)
extends Strips representation two ways. First, allows actions different
effects depending context, second, recognizes effects actions
always known certainty.32
Formally, PSO consists set mutually exclusive exhaustive logical formulae,
called contexts, stochastic effect associated context. Intuitively, context discriminates situations action differing stochastic effects.
stochastic effect set change sets|a simple list variable values|with
probability attached change set, requirement probabilities sum
one. semantics stochastic effect described follows: stochastic
effect action applied state s, possible resulting states determined
change sets, occurring corresponding probability; resulting state associated change set constructed changing variable values state match
change set, unmentioned variables persist value. Note since one
31. fact certain direct dependencies among variables Bayes net rendered irrelevant
specific variable assignments studied generally guise context-specific independence
(Boutilier, Friedman, Goldszmidt, & Koller, 1996); see (Geiger & Heckerman, 1991; Shimony, 1993)
related notions.
32. conditional nature effects also feature deterministic extension Strips known ADL
(Pednault, 1989).

45

fiBoutilier, Dean, & Hanks

RHC


f

Loc


-CR -RHC +M
-CR -RHC
-RHC +M
-RHC

+CR +M
+CR
+M
nil

else

-RHC +CR +M
-RHC +CR
-RHC +M
-RHC
+CR +M
+CR
+M
nil

0.19
0.76
0.01
0.04

0.04
0.16
0.16
0.64

0.028
0.112
0.112
0.448
0.012
0.048
0.048
0.192

Figure 17: PSO representation DelC action.
Loc


L

+Loc(L) 0.9
nil
0.1

+Loc(C) 0.9
nil
0.1

H

C



+Loc(M) 0.9
nil
0.1

+Loc(H) 0.9
nil
0.1

+Loc(O) -RHC -RHM
+Loc(O) -RHC
+Loc(O)
-RHC -RHM
-RHC
nil

0.135
0.135
0.63
0.015
0.015
0.07

Figure 18: PSO representation simplified CClk action.
context hold state s, transition distribution action state
easily determined.
Figure 17 gives graphical depiction PSO DelC action (shown 2TBN
Figure 16). three contexts :RHC, RHC ^ Loc(O) RHC ^:Loc(O) represented
using decision tree. leaf branch decision tree stochastic effect
(set change sets associated probabilities) determined corresponding context.
example, RHC ^ Loc(O) holds, action four possible effects: robot loses
coffee; may may satisfy coffee request (due 0:05 chance spillage);
mail may may arrive. Notice outcome spelled completely.
number outcomes two contexts rather large due possible exogenous
events (we discuss Section 4.2.4).33
key difference PSOs 2TBNs lies treatment persistence.
variables unaffected action must given CPTs 2TBN model,
variables mentioned PSO model (e.g., compare variable Loc
representations DelC). way, PSOs said \solve" frame problem,
since unaffected variables need mentioned action's description.34
33. keep Figure 17 manageable, ignore effect exogenous event Mess variable .
34. discussion frame problem 2TBNs, see (Boutilier & Goldszmidt, 1996).

46

fiDecision-Theoretic Planning: Structural Assumptions

ArrM

Mess

Loc

Loc

Loc

Loc

RHC

RHC

RHC

RHC

RHM

RHM

RHM

RHM

CR

CR

CR

CR



















t+ 1

t+ 2

t+1

Figure 19: simplified explicit-event model DelC.
PSOs provide effective means representing actions correlated effects.
Recall description CClk action captured Figure 15, robot may
drop coffee moves hallway, may drop mail drops
coffee. 2TBN representation CClk, one must RHCt RHCt+1
parents RHMt+1 : must model dependence RHM change value
variable RHC. Figure 18 shows CClk action PSO format (for simplicity, ignore
occurrence exogenous events). PSO representation offer economical
representation correlated effects since possible outcomes moving
hallway spelled explicitly. Specifically, (possible) simultaneous change values
variables question made clear.
4.2.4 Explicit-Event Models

Explicit-event models also represented using 2TBNs somewhat different form.
discussion Section 2.3, form taken explicit-event models depends crucially one's assumptions interplay effects action
exogenous events. However, certain assumptions even explicit-event models
rather concise.
illustrate, Figure 19 shows deliver-coffee action represented 2TBN
exogenous events explicitly represented. first \slice" network shows effects
action DelC without presence exogenous events. subsequent slices describe
effects events ArrM Mess (we use two events illustration). Notice
presence extra random variables representing occurrence events question.
CPTs nodes ect occurrence probabilities events various
47

fiBoutilier, Dean, & Hanks

conditions, directed arcs event variables state variables indicate
effects events. probabilities depend state variables general;
thus, 2TBN represents occurrence vectors (see Section 2.3) compact form. Also
notice that, contrast event occurrence variables, explicitly represent
action occurrence variable network, since modeling effect
system given action taken.35
example ects assumptions described Section 2.3, namely, events
occur action takes place event effects commutative,
reason ordering events ArrM Mess network irrelevant.
model, system actually passes two intermediate though necessarily distinct
states goes stage stage + 1; use subscripts "1 "2 suggest
process. course, described earlier, actions events combined
decomposable way; complex combination functions also modeled using 2TBNs
(for one example, see Boutilier & Puterman, 1995).
4.2.5 Equivalence Representations

obvious question one might ask concerns extent certain representations
inherently concise others. focus standard implicit-event models,
describing domain features make different representations less
suitable.
2TBN PSO representations oriented toward representing changes
values state variables induced action; key distinction lies fact
2TBNs model uence variable separately, PSO model explicitly
represents complete outcomes. simple 2TBN|a network synchronic arcs|can
used represent action cases correlations among action's
effect different state variables. worst case, effect variable
differs state, time + 1 variable must time variables parents.
regularities exploited structured CPT representations,
action requires specification O(n2n ) parameters (assuming boolean variables),
compared 22n entries required explicit transition matrix. number
parents variable bounded k, need specify n2k conditional
probabilities. reduced CPTs exhibit structure (e.g.,
represented concisely decision tree). instance, CPT captured
representation choice f (k) entries, f polynomial function
number parents variable, representation size, O(n f (k)), polynomial
number state variables. often case, instance, actions one
(stochastic) effects variable requires number (pre-) conditions hold;
not, different effect comes play.
PSO representation may concise 2TBN action multiple
independent stochastic effects. PSO requires possible change list enumerated corresponding probability occurrence. number changes grows
exponentially number variables affected action. fact evident
35. Sections 4.2.7 4.3 discuss representations model choice action explicitly variable
network.

48

fiDecision-Theoretic Planning: Structural Assumptions

RHC


f

Loc


-RHC -CR
-RHC

nil

+M 0.2
nil 0.8
1.0

else
0.95
0.05

-RHC
nil

0.7
0.3

Figure 20: \factored" PSO representation DelC action.
Figure 17, impact exogenous events affects number variables stochastically independently. problem arise respect \direct" action effects,
well. Consider action set 10 unpainted parts spray painted; part
successfully painted probability 0:9, successes uncorrelated. Ignoring
complexity representing different conditions action could take place,
simple 2TBN represent action 10 parameters (one success probability per
part). contrast, PSO representation might require one list 210 distinct change
lists associated probabilities. Thus, PSO representation exponentially
larger (in number affected variables) simple 2TBN representation.
Fortunately, certain variables affected deterministically, cause
PSO representation blow up. Furthermore, PSO representations also modified
exploit independence action's effects different state variables (Boutilier &
Dearden, 1994; Dearden & Boutilier, 1997), thus escaping combinatorial diculty.
instance, might represent DelC action shown Figure 17 \factored
form" illustrated Figure 20 (for simplicity, show effect action
exogenous event ArrM). Much like 2TBN, determine overall effect
combining change sets (in appropriate contexts) multiplying corresponding
probabilities.
Simple 2TBNs defined original set state variables sucient represent actions.36 Correlated action effects require presence synchronic arcs.
worst case, means time + 1 variables 2n , 1 parents.
fact,
P acyclicity condition assures worst case, total number parents
nk=1 2k , 1; thus, end specifying O(22n ) entries, required
explicit transition matrix. However, number parents (whether occurring within
time slice + 1) bounded, regularities CPTs allow compact
representation, 2TBNs still profitably used.
PSO representations compare favorably 2TBNs cases
action's effects different variables correlated. case, PSOs provide
somewhat economical representation action effects, primarily one needn't
worry frame conditions. main advantage PSOs one need enlist
aid probabilistic reasoning procedures determine transitions induced actions
correlated effects. Contrast explicit specification outcomes PSOs
type reasoning required determine joint effects action represented 2TBN
36. However, Section 4.2.6 discusses certain problem transformations render simple 2TBNs sucient
MDP.

49

fiBoutilier, Dean, & Hanks

form synchronic arcs, described Section 4.1. Essentially, correlated effects
\compiled" explicit outcomes PSOs.
Recent results Littman (1997) shown simple 2TBNs PSOs
used represent action represented 2TBN without exponential blowup
representation size. effected clever problem transformation new
sets actions propositional variables introduced (using either simple 2TBN
PSO representation). structure original 2TBN ected new planning
problem, incurring polynomial increase size input action
descriptions description policy. Though resulting policy consists actions
exist underlying domain, extracting true policy dicult.
noted, however, representation automatically constructed
general 2TBN specification, unlikely could provided directly, since
actions variables transformed problem \physical" meaning
original MDP.
4.2.6 Transformations Eliminate Synchronic Constraints

discussion assumed variables propositions used 2TBN
PSO action descriptions original state variables. However, certain problem transformations used ensure one represent action using simple 2TBNs,
long one require original state variables used. One transformation
simply clusters variables action correlated effect. new compound
variable|which takes values assignments clustered variables|can used
2TBN, removing need synchronic arcs. course, variable
domain size exponential number clustered variables.
intuitions underlying PSOs used convert general 2TBN action descriptions simple 2TBN descriptions explicit \events" dictating precise outcome
action. Intuitively, event occur k different forms, corresponding
different change list induced action (or change list respect variables
question). example, convert \action" description CClk Figure 15
explicit-event model shown Figure 21.37 Notice \event" takes values
corresponding possible effects correlated variables RHC RHM. Specifically, denotes event robot escaping hallway successfully without losing
cargo, b denotes event robot losing coffee, c denotes event losing
coffee mail. effect, event space represents possible \combined"
effects, obviating need synchronic arcs network.
4.2.7 Actions Explicit Nodes Network

One diculty 2TBN PSO approach action description action
represented separately, offering opportunity exploit patterns across actions.
instance, fact location persists actions except moving clockwise counterclockwise means \frame axiom" duplicated 2TBN actions
(this case PSOs, course). addition, ramifications (or correlated action
37. Figure 15 describes Markov chain induced policy, representation CClk easily
extracted it.

50

fiDecision-Theoretic Planning: Structural Assumptions

Loc

Hall

a: 1.0
b: 0.0
c: 0.0

Event



RHC

RHM


Loc

else

f

a:0.7 a:0.7
b:0.15 b:0.3
c:0.15 c:0.0

Loc

f

a: 1.0
b: 0.0
c: 0.0





RHC

RHC
1.0



RHM
Time

RHM
Time t+1

Loc

1.0
0.0



RHM

b
0.0

b
0.0

f

0.0

c
0.0

f

0.0

else

Event

Event

RHC

c
1.0

Figure 21: explicit-event model removes correlations.
effects) duplicated across actions well. instance, coffee request occurs (with
probability 0:2) robot ends oce, correlation duplicated
across actions. compelling example might one robot move
briefcase new location one number ways. We'd like capture fact (or
ramification) contents briefcase move location briefcase
regardless action moves briefcase.
circumvent diculty, introduce choice action \random variable" network, conditioning distribution state variable transitions
value variable. Unlike state variables (or event variables explicit event models),
generally require distribution action variable|the intent simply
model schematically conditional state-transition distributions given particular
choice action. choice action dictated decision maker
policy determined. reason, anticipating terminology used uence
diagrams (see Section 4.3), call nodes decision nodes depict network diagrams boxes. variable take value action available
agent.
2TBN explicit decision node shown Figure 22. restricted example,
might imagine decision node take one two values, Clk CClk. fact
issuance coffee request t+1 depends whether robot successfully moved
(or remained in) oce represented \once" arc Loct+1 CRt+1 ,
rather repeated across multiple action networks. Furthermore, noisy persistence
actions also represented (adding action PUM, however,
undercuts advantage see try combine actions).
One diculty straightforward use decision nodes (which standard
representation uence diagram literature) adding candidate actions
cause explosion network's dependency structure. example, consider two
51

fiBoutilier, Dean, & Hanks

Act

Loc

Loc

CR

CR





Time

Time t+1

Figure 22: uence diagram restricted process.

Act
X

X

X

X

X

Act

X

else

a1
a2














1.0



f


X

0.9

Z

Z
(a) action a1

Z

Z

Z

(b) action a2

1.0

f
0



f


0.9


Z

1.0

f
0

Z

(c) influence diagram

Figure 23: Unwanted dependencies uence diagrams.

52



(d) CPT



f
0

fiDecision-Theoretic Planning: Structural Assumptions

action networks shown Figure 23(a) (b). Action a1 makes true probability
0:9 X true (having effect otherwise), a2 makes true Z true.
Combining actions single network obvious way produces uence
diagram shown Figure 23(c). Notice four parent nodes, inheriting
union parents individual networks (plus action node) requiring
CPT 16 entries actions a1 a2 together eight additional entries
action affect . individual networks ect fact depends
X a1 performed Z a2 performed. fact lost
naively constructed uence diagram. However, structured CPTs used
recapture independence compactness representation: tree Figure 23(d)
captures distribution much concisely, requiring eight entries. structured
representation also allows us concisely express persists actions.
large domains, expect variables generally unaffected substantial number
(perhaps most) actions, thus requiring representations uence diagrams.
See (Boutilier & Goldszmidt, 1996) deeper discussion issue relationship
frame problem.
provide distributional information action choice, hard
see 2TBN explicit decision node used represent Markov chain
induced particular policy natural way. Specifically, adding arcs state
variables time decision node, value decision node (i.e., choice
action point) dictated prevailing state.38

4.3 uence Diagrams
uence diagrams (Howard & Matheson, 1984; Shachter, 1986) extend Bayesian networks
include special decision nodes represent action choices, value nodes represent
effect action choice value function. presence decision nodes means
action choice treated variable decision maker's control. Value nodes treat
reward variable uenced (usually deterministically) certain state variables.
uence diagrams typically associated schematic representation
stationary systems, instead used tool decision analysts sequential
decision problem carefully handcrafted. generic use uence diagrams
discussed Tatman Shachter (1990). event, theory plan
construction associated uence diagrams: choice possible actions
stage must explicitly encoded model. uence diagrams are, therefore, usually
used model finite-horizon decision problems explicitly describing evolution
process stage terms state variables.
Section 4.2.7, decision nodes take values specific actions, though set
possible actions tailored particular stage. addition, analyst generally
include stage state variables thought relevant decision
subsequent stages. Value nodes also key feature uence diagrams
discussed Section 4.5. Usually, single value node specified, arcs indicating
38. generally, randomized policy represented specifying distribution possible actions
conditioned state.

53

fiBoutilier, Dean, & Hanks


RHM


RHM
Rew

CR



etc.


0

CR

etc.

1 2


3

4

-7 -6.5 -6 -5.5 -5

0

1 2

3

4

-4 -3.5 -3 -2.5 -2

Figure 24: representation reward function uence diagram.
uence particular state decision variables (often multiple stages) overall
value function.
uence diagrams typically used model partially observable problems. arc
state variable decision node ects fact value state variable
available decision maker time action chosen. words,
variable's value forms part observation made time prior action
selected time +1, policy constructed refer variable. again,
allows compact specification observation probabilities associated system.
fact probability given observation depends directly certain variables
others mean far fewer model parameters required.

4.4 Factored Reward Representation

already noted common formulating MDP problems adopt
simplified value function: assigning rewards states costs actions, evaluating histories combining factors according simple function like addition.
simplification alone allows representation value function significantly
parsimonious one based complex comparison complete histories. Even
representation requires explicit enumeration state action space, however,
motivating need compact representations parameters. Factored representations rewards action costs often obviate need enumerate state
action parameters explicitly.
Like action's effect particular variable, reward associated state often
depends values certain features state. example, robot
domain, associate rewards penalties undelivered mail, unfulfilled coffee
requests untidiness lab. reward penalty independent
variables, individual rewards associated groups states differ
values relevant variables. relationship rewards state variables
represented value nodes uence diagrams, represented diamond Figure 24.
conditional reward table (CRT) node table associates reward
every combination values parents graph. table, shown Figure 24,
locally exponential number relevant variables. Although Figure 24 shows
case stationary Markovian reward function, uence diagrams used represent
54

fiDecision-Theoretic Planning: Structural Assumptions

nonstationary history-dependent rewards often used represent value functions
finite-horizon problems.
Although worst case CRT take exponential space store, many
cases reward function exhibits structure, allowing represented compactly using
decision trees graphs (Boutilier et al., 1995), Strips-like tables (Boutilier & Dearden,
1994), logical rules (Poole, 1995, 1997a). Figure 24 shows fragment one possible
decision-tree representation reward function used running example.
independence assumptions studied multiattribute utility theory (Keeney & Raiffa,
1976) provide yet another way reward functions represented compactly.
assume component attributes reward function make independent contributions state's total reward, individual contributions combined functionally.
instance, might imagine penalizing states CR holds (partial) reward
,3, penalizing situations undelivered mail (M _ RHM) ,2,
penalizing untidiness (i) , 4 (i.e., proportion untidy things are).
reward state determined simply adding individual penalties associated feature. individual component rewards along combination
function constitute compact representation reward function. tree fragment
Figure 24, ects additive independent structure described, considerably
complex representation defines (independent) rewards individual
propositions separately. use additive reward functions MDPs considered
(Boutilier, Brafman, & Geib, 1997; Meuleau, Hauskrecht, Kim, Peshkin, Kaelbling, Dean,
& Boutilier, 1998; Singh & Cohn, 1998).
Another example structured rewards goal structure studied classical planning.
Goals generally specified single proposition (or set literals) achieved.
such, generally represented compactly. Haddawy Hanks (1998)
explore generalizations goal-oriented models permit extensions partial goal
satisfaction, yet still admit compact representations.

4.5 Factored Policy Value Function Representation

techniques studied far concerned input specification MDP:
states, actions, reward function. components problem's solution|the policy optimal value function|are also candidates compact structured representation.
simplest case, stationary policy fully observable problem, policy
must associate action every state, nominally requiring representation size
O(jSj). problem exacerbated nonstationary policies POMDPs. example,
policy finite-horizon FOMDP stages generates policy size O(T jSj).
finite-horizon POMDP, possible
P observable history length < might require
different action choice; many Tk=1 bk histories generated fixed
policy, b maximum number possible observations one make following
action.39
fact policies require much space motivates need find compact functional representations, standard techniques like tree structures discussed
39. methods dealing POMDPs, conversion FOMDPs belief space (see Section 2.10.2),
complex still.

55

fiBoutilier, Dean, & Hanks

CR
RHC

etc.

Loc


L C

Loc


H

H

L

C



DelC Clk Clk Cclk Cclk HRM Clk GetC
PUM Cclk

DelM Cclk

PUM Cclk

Figure 25: tree representation policy.
actions reward functions used represent policies value functions well.
focus stationary policies value functions FOMDPs, logical
function representation may used. example, Schoppers (1987) uses Strips-style
representation universal plans, deterministic, plan-like policies. Decision trees
also used policies value functions (Boutilier et al., 1995; Chapman &
Kaelbling, 1991). example policy robot domain specified decision tree
given Figure 25. policy dictates that, instance, CR RHC true: (a)
robot deliver coffee user oce, (b) move toward oce
oce, unless (c) mail mailroom, case
pickup mail way.

4.6 Summary

section discussed number compact factored representations components
MDP. began discussing intensional state representations, temporal Bayesian
networks device representing system dynamics. Tree-structured conditional
probability tables (CPTs) probabilistic Strips operators (PSOs) introduced
alternative transition matrices. Similar tree structures logical representations
introduced representing reward functions, value functions, policies.
representations often used describe problem compactly,
offer guarantee problem solved effectively. next
section explore algorithms use factored representations avoid iterating
explicitly entire set states actions.

5. Abstraction, Aggregation, Decomposition Methods

greatest challenge using MDPs basis DTP lies discovering computationally feasible methods construction optimal, approximately optimal satisficing
policies. course, arbitrary decision problems intractable|even producing satisficing
approximately optimal policies generally infeasible. However, previous sections
suggest many realistic application domains may exhibit considerable structure,
furthermore structure modeled explicitly exploited typical
problems solved effectively. instance, structure type lead compact
56

fiDecision-Theoretic Planning: Structural Assumptions

factored representations input data output policies, often polynomial-sized
respect number variables actions describing problem. suggests
compact problem representations, policy construction techniques developed exploit structure tractable many commonly occurring problem
instances.
dynamic programming state-based search techniques described Section 3 exploit structure different kind. Value functions decomposed
state-dependent reward functions, state-based goal functions, tackled dynamic
programming regression search, respectively. algorithms exploit structure
decomposable value functions prevent search explicitly possible
policies. However, algorithms polynomial size state space,
curse dimensionality makes even algorithms infeasible practical problems.
Though compact problem representations aid specification large problems,
clear large system specified compactly representation exploits
\regularities" found domain. Recent AI research DTP stressed using
regularities implicit compact representations speed planning process.
techniques focus optimal approximately optimal policy construction.
following subsection focus abstraction aggregation techniques, especially manipulate factored representations. Roughly, techniques allow
explicit implicit grouping states indistinguishable respect certain characteristics (e.g., value optimal action choice). refer set states grouped
manner aggregate abstract state , sometimes cluster, assume
set abstract states constitutes partition state space; say, every state
exactly one abstract state union abstract states comprises entire state
space.40 grouping similar states, abstract state treated single state, thus
alleviating need perform computations state individually. techniques
used approximation elements abstract state approximately
indistinguishable (e.g., values states lie within small interval).
look use problem decomposition techniques MDP
broken various pieces, solved independently; solutions
pieced together used guide search global solution. subprocesses whose
solutions interact minimally treated independent, might expect approximately
optimal global solution. Furthermore, structure problem requires solution
particular subproblem only, solutions subproblems ignored
altogether.
Related use reachability analysis restrict attention \relevant" regions
state space. Indeed, reachability analysis communicating structure MDP
used form certain types decompositions. Specifically, distinguish serial
decompositions parallel decompositions.
result serial decomposition viewed partitioning state space
blocks, representing (more less) independent subprocess solved.
serial decomposition, relationship blocks generally complicated
case abstraction aggregation. partition resulting decomposition,
40. might also group states non-disjoint sets cover entire state space. consider
soft-state aggregation here, see (Singh, Jaakkola, & Jordan, 1994).

57

fiBoutilier, Dean, & Hanks

states within particular block may behave quite differently respect (say) value
dynamics. important consideration choosing decomposition possible
represent block compactly compute eciently consequences moving
one block another and, further, subproblems corresponding subprocesses
solved eciently.
parallel decomposition somewhat closely related abstract MDP.
MDP divided \parallel sub-MDPs" decision action causes
state change within sub-MDP. Thus, MDP cross product join
sub-MDPs (in contrast union, serial decomposition). brie discuss several
methods based parallel MDP decomposition.

5.1 Abstraction Aggregation
One way problem structure exploited policy construction relies notion
aggregation|grouping states indistinguishable respect certain problem
characteristics. example, might group together states optimal
action, value respect k-stage-to-go value function.
aggregates constructed solution problem.
AI, emphasis generally placed particular form aggregation, namely
abstraction methods, states aggregated ignoring certain problem features.
policy Figure 25 illustrates type abstraction: states CR,
RHC Loc(O) true grouped, action selected
state. Intuitively, three propositions hold, problem features ignored
abstracted away (i.e., deemed irrelevant). decision-tree representation
policy value function partitions state space distinct cluster leaf
tree. representations (e.g., Strips-like rules) abstract state space similarly.
precisely type abstraction used compact, factored representations actions goals discussed Section 4. 2TBN shown Figure 16,
effect action DelC variable CR given CPT CRt+1 ; however,
(stochastic) effect state parent variables
value. representation abstracts away variables, combining states
distinct values irrelevant (non-parent) variables. Intensional representations often
make easy decide features ignore certain stage problem solving,
thus (implicitly) aggregate state space.
least three dimensions along abstractions type compared. first uniformity: uniform abstraction one variables deemed
relevant irrelevant uniformly across state space, nonuniform abstraction allows certain variables ignored certain conditions others.
distinction illustrated schematically Figure 26. tabular representation CPT
viewed form uniform abstraction|the effect action variable
distinguished clusters states differ value parent variable,
distinguished states agree parent variables disagree others|while
decision tree representation CPT embodies nonuniform abstraction.
second dimension comparison accuracy. States grouped together
basis certain characteristics, abstraction called exact states within
58

fiDecision-Theoretic Planning: Structural Assumptions

Uniform
ABC
ABC

ABC
ABC

ABC
ABC

ABC
ABC

Nonuniform

B

5.3
5.3

AB

=

ABC

C

ABC

Exact
5.3
5.3



Approximate
5.3
5.2

2.9
2.9

2.9
2.7

5.5

9.3
9.3

9.3
9.0

5.3

Adaptive

Fixed

Figure 26: Different forms state space abstraction.
cluster agree characteristic. non-exact abstraction called approximate.
illustrated schematically Figure 26: exact abstraction groups together states
agree value assigned value function, approximate abstraction
allows states grouped together differ value. extent states
differ often used measure quality approximate abstraction.
third dimension adaptivity. Technically, property abstraction
itself, abstractions used particular algorithm. adaptive abstraction
technique one abstraction change course computation,
fixed abstraction scheme groups together states (again, see Figure 26).
example, one imagine using abstraction representation value function
V k , revising abstraction represent V k+1 accurately.
Abstraction aggregation techniques studied literature
MDPs. Bertsekas Castanon (1989) develop adaptive aggregation (as opposed
abstraction) technique. proposed method operates state spaces, however,
therefore exploit implicit structure state space itself. adaptive, uniform
abstraction method proposed Schweitzer et al. (1985) solving stochastic queuing models. methods, often referred aggregation-disaggregation procedures,
typically used accelerate calculation value function fixed policy. Valuefunction calculation requires computational effort least quadratic size state
space, impractical large state spaces. aggregation-disaggregation procedures, states first aggregated clusters. system equations solved,
series summations performed, requiring effort cubic number
clusters. Next, disaggregation step performed cluster, requiring effort least
linear size cluster. net result total work, least linear
total number states, worst cubic size largest cluster.
DTP generally assumed computations even linear size full
state space infeasible. Therefore important develop methods perform
59

fiBoutilier, Dean, & Hanks

work polynomial log size state space. problems amenable
reductions without (perhaps unacceptable) sacrifice solution quality.
following section, review recent techniques DTP aimed achieving
reductions.
5.1.1 Goal Regression Classical Planning

Section 3.2 introduced general technique regression (or backward) search
state space solve classical planning problems, involving deterministic actions performance criteria specified terms reaching goal-satisfying state. One
diculty search requires branch search tree lead particular
goal state. commitment goal state may retracted (by backtracking
search process) sequence actions lead particular goal state
initial state. However, goal usually specified set literals G representing set
states, reaching state G equally suitable|it may, therefore, wasteful
restrict search finding plan reaches particular element G.
Goal regression abstraction technique avoids problem choosing particular goal state pursue. regression planner works searching sequence actions
follows: current set subgoals SG0 initialized G. iteration action
ff selected achieves one current subgoals SGi without deleting
others, whose preconditions con ict \unachieved subgoals."
subgoals achieved removed current subgoal set replaced formula
representing context ff achieve current subgoals, forming SGi+1 .
process known regressing SGi ff. process repeated one
two conditions holds: (a) current subgoal set satisfied initial state,
case current sequence actions selected successful plan; (b) action
applied, case current sequence cannot extended successful plan
earlier action choice must reconsidered.
Example 5.1 example, consider simplified version robot planning example used Section 3.1 illustrate value iteration: robot four actions
PUM, GetC, DelC DelM, make deterministic obvious way.
initial state sinit hCR; M; RHC; RHMi goal set G fCR; g. Regressing G DelM results SG1 = fCR; M; RHMg. Regressing SG1
DelC results SG2 = fRHC; M; RHMg. Regressing SG2 PUM results
SG3 = fRHC; g. Regressing SG3 GetC results SG4 = fM g. Note
sinit 2 SG4, sequence actions GetC, PUM, DelC, DelM successfully reach
goal state. 2
see algorithm implements form abstraction, first note goal
provides initial partition state space, dividing one set states
goal satisfied (G) second set (G). Viewed partition
zero-stage-to-go value function, G represents states whose value positive
G represents states whose value zero.
Every regression step thought revising partition. planning
algorithm attempts satisfy current subgoal set SGi applying action ff, uses
60

fiDecision-Theoretic Planning: Structural Assumptions

GetC

RHC





4

PUM

RHC

DelC

CR

DelM

CR







RHM

RHM









Goal

3

2

1

Figure 27: example goal regression.
regression compute (largest) set states that, executing ff, subgoals
satisfied. particular, state space repartitioned two abstract states: SGi+1
SGi+1 . way, abstraction mechanism implemented goal regression
considered adaptive. viewed (i + 1)-stage value function: state
satisfying SGi+1 reach goal state +1 steps using action sequence produced
SGi+1 .41 regression process stopped initial state member
abstract state SGi+1 . Figure 27 illustrates repartitioning state space
different regions SGi+1 steps example above.
regression produces compact representation something like value function
(as discussion deterministic, goal-based dynamic programming Section 3.2),
analogy exact regions produced regression record property
goal reachability contingent particular choice action action sequence.
Standard dynamic programming methods implemented structured way
simply noticing number different regions produced ith iteration
considering actions regressed stage. union
regressions form states positive values Vi , thus making representation
i-stage-to-go value function exact. Notice iteration costly, since
regression actions must attempted, approach obviates need
backtracking ensure shortest plan found. Standard regression
provide guarantees without commitment particular search strategy (e.g., breadthfirst). use dynamic programming using Strips action descriptions forms basic
idea Schoppers's universal planning method (Schoppers, 1987).
Another general technique solving classical planning problems partial order planning (POP) (Chapman, 1987; Sacerdoti, 1975), embodied popular planning algorithms SNLP (McAllester & Rosenblitt, 1991) UCPOP (Penberthy & Weld, 1992).42
main motivation least-commitment approach comes realization
regression techniques incrementally building plan end beginning (in
temporal dimension). Thus, iteration must commit inserting step last
plan.
many cases determined particular step must appear somewhere
plan, necessarily last step plan; and, indeed, many cases step
41. case, however, states SGi+1 cannot reach goal region + 1 steps.
case cannot using specific sequence actions chosen far.
42. type planning also sometimes called nonlinear least-commitment planning. See Weld's
(1994) survey nice overview.

61

fiBoutilier, Dean, & Hanks

consideration cannot appear last, fact cannot recognized later choices
reveal inconsistency. cases, regression algorithm prematurely commit
incorrect ordering eventually backtrack choice. example,
suppose problem scenario robot hold one item time,
coffee mail. Picking mail causes robot spill coffee possession,
similarly grasping coffee makes drop mail. plan generated regression would
longer valid: first two actions (DelC DelM) inserted
plan, action added achieve RHC RHM without making one false;
search plan would backtrack. Ultimately would discovered
successful plan end two actions performed sequence.
Partial-order planning algorithms proceed much like regression algorithms, choosing
actions achieve unachieved subgoals using regression determine new subgoals,
leaving actions unordered whatever extent possible. Strictly speaking, subgoal sets
aren't regressed; rather, unachieved goal action precondition addressed separately,
actions ordered relative one another one action threatens negate
desired effect another. example above, algorithm might first place actions
DelC DelM plan, leave unordered. PUM added plan
achieve requirement RHM DelM; ordered DelM still unordered
respect DelC. GetC finally added plan achieve RHC
action DelC, two threats arise. First, GetC threatens desired effect RHM PUM.
resolved ordering GetC PUM DelM. Assume former ordering
chosen. Second, PUM threatens desired effect RHC GetC. threat also
resolved placing PUM GetC DelC; since first threat resolved
ordering GetC PUM, latter ordering consistent one. result
plan GetC, DelC, PUM, DelM. backtracking required generate plan,
actions initially unordered, orderings introduced
discovery threats required them.
terms abstraction, incomplete, partially ordered plan threat-free,
perhaps certain \open conditions" (unachieved preconditions subgoals),
viewed much way partially completed regression plan: state satisfying
open conditions reach goal state executing total ordering plan's
actions consistent current set ordering constraints. See (Kambhampati, 1997)
framework unifies various approaches solving classical plan-generation problems.
techniques relying regression studied extensively deterministic
setting, recently applied probabilistic unobservable (Kushmerick
et al., 1995) partially observable (Draper, Hanks, & Weld, 1994b) domains.
part, techniques assume goal-based performance criterion attempt
construct plans whose probability reaching goal state exceeds threshold.
augment standard POP methods techniques evaluating plan's probability
achieving goal, techniques improving probability adding structure
plan. next section, consider use regression-related techniques
solve MDPs performance criteria general goals.
62

fiDecision-Theoretic Planning: Structural Assumptions

5.1.2 Stochastic Dynamic Programming Structured Representations

key idea underlying propositional goal regression|that one need regress relevant propositions action|can extended stochastic dynamic programming
methods, like value iteration policy iteration, used solve general MDPs.
are, however, two key diculties overcome: lack specific goal region
uncertainty associated action effects.
Instead viewing state space partitioned goal non-goal clusters,
consider grouping states according expected values. Ideally, might want
group states according value respect optimal policy. consider
somewhat less dicult task, grouping states according value respect
fixed policy. essentially task performed policy evaluation step
policy iteration, insights used construct optimal policies.
fixed policy, want group states value policy.
Generalizing goal versus non-goal distinction, begin partition groups
states according immediate rewards. Then, using analogue regression developed
stochastic case, reason backward construct new partition states
grouped according value respect one-stage-to-go value function.
iterate manner kth iteration produce new partition groups
states according k-stage-to-go value function.
iteration, perform work polynomial number abstract states (and
size MDP representation) and, lucky, total number abstract states
bounded logarithmic factor size state space. implement
scheme effectively, perform operations like regression without ever enumerating
set states, structured representations state-transition,
value, policy functions play role.
FOMDPs, approaches type taken (Boutilier, 1997; Boutilier & Dearden, 1996; Boutilier et al., 1995; Boutilier, Dearden, & Goldszmidt, 1999; Dietterich &
Flann, 1995; Hoey et al., 1999). illustrate basic intuitions behind approach
describing value iteration discounted infinite-horizon FOMDPs might work.
assume MDP specified using compact representation reward function
(such decision tree) actions (such 2TBNs).
value iteration, produce sequence value functions V0 ; V1 ; ; Vn , Vk
representing utility optimal k-stage policy. aim produce compact
representation value function and, using Vn suitable n, produce compact
representation optimal stationary policy. Given compact representation
reward function R, clear constitutes compact representation V0 .
usual, think leaf tree cluster states identical utility.
produce V1 compact form, proceed two phases.
branch tree V0 provides intensional description|namely, conjunction variable values labeling branch|of abstract state, region, comprising
states identical value respect initial value function V0 . deterministic action ff, perform regression step using description determine
conditions which, perform ff, would end cluster. would,
furthermore, determine region state space containing states identical future value
63

fiBoutilier, Dean, & Hanks

X

X

X

1.0 0.0
X





0.9



1.0 0.0

Z

Z


0.9

Time

Z

Time t+1
1.0 0.0

Figure 28: example action.
respect execution ff one stage go.43 Unfortunately, nondeterministic
actions cannot handled quite way: given state, action might lead
several different regions V0 non-zero probability. However, leaf tree
representing V0 (i.e., region V0 ), regress conjunction X describing
region action ff produce conditions X becomes true
false specified probability. words, instead regressing standard fashion determine conditions X becomes true, produce set distinct
conditions X becomes true different probabilities. piecing together
regions produced different labels description V0 , construct
set regions state given region: (a) transitions (under action ff)
particular part V0 identical probability; hence (b) identical expected future
value (Boutilier et al., 1995). view generalization propositional goal
regression suitable decision-theoretic problems.
Example 5.2 illustrate, consider example action shown Figure 28 value
function V 0 shown left Figure 29. order generate set regions
consisting states whose future value (w.r.t. V 0 ) identical, proceed
two steps (see Figure 29). first determine conditions fixed
probability making true (hence fixed probability moving left
right subtree V 0 ). conditions given tree representing CPT
node , makes first portion tree representing V 1 |see Step 1
Figure 29. Notice tree leaves labeled probability making
true (implicitly) false.
makes true, know future value (i.e., value zero stages
go) 8.1; becomes false, need know whether makes Z true (to
43. ignore immediate reward cost distinctions within region produced description;
recall value performing ff state given R(s), C (ff; s) expected future value.
simply focus abstract states whose elements identical future expected value. Differences
immediate reward cost added fact.

64

fiDecision-Theoretic Planning: Structural Assumptions



X

8.1

Z

9.0

0.9

0.0

X



1.0



0.0

0.9
Z 0.9

Z

0.9
Z 1.0
0

V

Step 1



1.0

0.9
Z 0.0

Z

0.0
Z 1.0

0.0
Z 0.0

Step 2

Figure 29: iteration decision-theoretic regression. Step 1 produces portion
tree dashed lines, Step 2 produces portion dotted lines.
determine whether future value 0 9:0). probability Z becomes
true given tree representing CPT node Z . Step 2 Figure 29,
conditions CPT conjoined conditions required predicting
's probability (by \grafting" tree Z tree given first step).
grafting slightly different three leaves tree : (a)
full tree Z attached leaf X = t; (b) tree Z simplified
attached leaf X = f ^ = f removal redundant test variable
; (c) notice need attach tree Z leaf X = f ^ = t,
since makes true probability 1 conditions (and Z relevant
determination V 0 false).
leaves newly formed tree Pr(Y ) Pr(Z ).
joint distributions Z (the effect variables independent semantics network) tells us probability Z true
zero stages go given conditions labeling appropriate branch
tree hold one stage go. words, new tree uniquely determines,
state one stage remaining, probability making conditions
labeling branches V 0 true. computation expected future value obtained
performing one stage go placed leaves tree
taking expectation values leaves V 0 . 2
new set regions produced way describes function Qff1 , Qff1 (s)
value associated performing ff state one stage go acting optimally
thereafter. functions (for action ff) pieced together (i.e., \maxed"|see
Section 3.1) determine V1 . course, process repeated number times
produce Vn suitable n, well optimal policy respect Vn .
basic technique used number different ways. Dietterich Flann
(1995) propose ideas similar these, restrict attention MDPs goal regions
65

fiBoutilier, Dean, & Hanks

deterministic actions (represented using Strips operators), thus rendering true goalregression techniques directly applicable.44 Boutilier et al. (1995) develop version
modified policy iteration produce tree-structured policies value functions,
Boutilier Dearden (1996) develop version value iteration described above.
algorithms extended deal correlations action effects (i.e., synchronic arcs
2TBNs) (Boutilier, 1997). abstraction schemes categorized nonuniform,
exact adaptive.
utility exact abstraction techniques tested real-world problems date. (Boutilier et al., 1999), results series abstract process-planning
examples reported, scheme shown useful, especially larger
problems. example, one specific problem 1.7 million states, tree representation value function 40,000 leaves, indicating tremendous amount
regularity value function. Schemes like exploit regularity solve problems
quickly (in example, much less half time required modified policy iteration) much lower memory demands. However, schemes involve
substantial overhead tree construction, smaller problems little regularity,
overhead repaid time savings (simple vector-matrix representations methods
faster), though still generally provide substantial memory savings. might
viewed best- worst-case behavior also described (Boutilier et al., 1999).
series \linear" examples (i.e., problems value functions represented
trees whose size linear number problem variables), tree-based scheme solves
problems many orders magnitude faster classical state-based techniques. contrast, problems exponentially-many distinct values also tested (i.e., distinct
value state): tree-construction methods required construct complete
decision tree addition performing number expected value maximization
computations classical methods. worst case, tree-construction overhead makes
algorithm run 100 times slower standard modified policy iteration.
(Hoey et al., 1999), similar algorithm described uses algebraic decision
diagrams (ADDs) (Bahar, Frohm, Gaona, Hachtel, Macii, Pardo, & Somenzi, 1993) rather
trees. ADDs simple generalization boolean decision diagrams (BDDs) (Bryant,
1986) allow terminal nodes labeled real values instead boolean values.
Essentially, ADD-based algorithms similar tree-based algorithms except
isomorphic subtrees shared. lets ADDs provide compact representations
certain types value functions. Highly optimized ADD manipulation evaluation
software developed verification community also applied solving MDPs.
Initial results provided (Hoey et al., 1999) encouraging, showing considerable savings
tree-based algorithms problems. example, ADD algorithm applied
1.7-million-state example described revealed value function
178 distinct values (cf. 40,000 tree leaves required) produced ADD description
value function less 2200 internal nodes. also solved problem
seven minutes, 40 times faster earlier reported timing results using decision
trees (though improvement due use optimized ADD software
packages). Similar results obtain problems (problems 268 million states
44. Dietterich Flann (1995) also describe work context reinforcement learning rather
method solving MDPs directly.

66

fiDecision-Theoretic Planning: Structural Assumptions

solved four hours). encouraging fact worst-case
(exponential) examples, overhead associated using ADDs|compared classical,
vector-based methods|is much less trees (about factor 20 compared \ at"
modified policy iteration 12 state variables), lessens problems become larger.
Like tree-based algorithms, methods yet applied real-world problems.
exact abstraction schemes clear that, examples resulting policies value functions may compact, others set regions may get
large (even reaching level individual states Boutilier et al., 1995), thus precluding
computational savings. Boutilier Dearden (1996) develop approximation scheme
exploits tree-structured nature value functions produced. stage k,
value function Vk pruned produce smaller, less accurate tree approximates Vk . Specifically, approximate value functions represented using trees whose leaves
labeled upper lower bound value function region; decisiontheoretic regression performed bounds. Certain subtrees value tree
pruned leaves subtree close value tree large
given computational constraints. scheme nonuniform, approximate adaptive.
approximation scheme tailored provide (roughly) accurate value
function given maximum tree size, smallest value function (with respect tree
size) given minimum accuracy. Results reported (Boutilier & Dearden, 1996)
show approximation small set examples (including worst-case examples
tree-based algorithms) allows substantial reduction computational cost. instance,
10-variable worst-case example, small amount pruning introduced average error
0.5% reduced computation time factor 50. aggressive pruning tends
increase error decrease computation time rapidly; making appropriate tradeoffs
two dimensions still addressed. method remains tested
evaluated realistic problems.
Structured representations solution algorithms applied problems
FOMDPs. Methods solving uence diagrams (Shachter, 1986) exploit structure
natural way; Tatman Shachter (1990) explore connection uence diagrams FOMDPs relationship uence diagram solution techniques
dynamic programming. Boutilier Poole (1996) show classic history-independent
methods solving POMDPs, based conversion FOMDP belief states, exploit types structured representations described here. However, exploiting structured
representations POMDPs remains explored depth.
5.1.3 Abstract Plans

One diculties adaptive abstraction schemes suggested fact
different abstractions must constructed repeatedly, incurring substantial computational overhead. overhead compensated savings obtained policy
construction|e.g., reducing number backups|then problematic.
many cases savings dominated time space required generate
abstractions, thus motivates development cheaper less accurate approximate
clustering schemes.
67

fiBoutilier, Dean, & Hanks

Another way reduce overhead adopt fixed abstraction scheme
one abstraction ever produced. approach adopted classical planning hierarchical abstraction-based planners, pioneered Sacerdoti's AbStrips system (Sacerdoti, 1974). similar form abstraction studied Knoblock (1993) (see also
Knoblock, Tenenberg, & Yang, 1991). work, variables (in case propositional)
ranked according criticality (roughly, important variables solution
planning problem) abstraction constructed deleting problem
description set propositions low criticality. solution abstract problem
plan achieves elements original goal deleted. However,
preconditions effects actions deleted accounted solution, might solution original problem. Even so, abstract solution
used restrict search solution underlying concrete space. often
hierarchies refined abstractions used propositions introduced
back domain stages.
form abstraction uniform (propositions deleted uniformly) fixed. Since
abstract solution need solution problem, might tempted view
approximate abstraction method. However, best think abstract
plan solution all, rather form heuristic information help solve
true problem quickly.
intuitions underlying Knoblock's scheme applied DTP Boutilier Dearden (1994, 1997): variables ranked according degree uence reward
function subset important variables deemed relevant. subset
determined, variables uence relevant variables effects
actions (which determined easily using Strips 2TBN action descriptions)
also deemed relevant, on. remaining variables deemed irrelevant
deleted description problem (both action reward descriptions).
leaves abstract MDP smaller state space (i.e., fewer variables) solved
standard methods. Recall state space reduction exponential number
variables removed. view method uniform fixed approximate abstraction
scheme. Unlike output classical abstraction methods, abstract policy produced
implemented value. degree optimal abstract policy
true optimal policy differ value bounded priori abstraction fixed.

Example 5.3 simple illustration, suppose reward satisfying coffee requests

(or penalty satisfying them) substantially greater keeping
lab tidy delivering mail. Suppose time pressure requires agent focus
specific subset objectives order produce small abstract state space.
case, four reward-laden variables problem (see Figure 24), CR
judged important. action descriptions used determine
variables (directly indirectly) affect probability achieving CR,
CR, RHC Loc deemed relevant, allowing , , RHM
ignored. state space thus reduced size 400 size 20. addition, several
action descriptions (e.g., Tidy) become trivial deleted. 2
68

fiDecision-Theoretic Planning: Structural Assumptions

advantage abstractions easily computed incur little
overhead. disadvantages uniform nature abstractions restrictive,
relevant \reward variables" determined policy constructed
without knowledge agent's ability control variables. result, important
variables|those large impact reward|but agent
control, may taken account, less important variables agent actually
uence ignored. However, series abstractions used take
account objectives decreasing importance, posteriori valuable objectives
dealt risk controllability taken account (Boutilier et al.,
1997). policies generated abstract levels also used \seed" value
policy iteration less abstract levels, certain cases reducing time convergence
(Dearden & Boutilier, 1997). also suggested (Dearden & Boutilier, 1994, 1997)
abstract value function used heuristic online search policies
improve abstract policy constructed, discussed Section 3.2.2. Thus, error
approximate value function overcome extent search, heuristic
function improved asynchronous updates.
different use abstraction adopted DRIPS planner (Haddawy & Suwandi,
1994; Haddawy & Doan, 1994). Actions abstracted collapsing \branches," possible outcomes, maintaining probabilistic intervals abstract, disjunctive effects.
Actions also combined decomposition hierarchy, much like hierarchical
task networks. Planning done evaluating abstract plans decomposition network, producing ranges utility possible instantiations plans, refining
plans possibly optimal. use task networks means search
restricted finite-horizon, open-loop plans action choice restricted possible refinements network. task networks offer useful way encode priori heuristic
knowledge structure good plans.
5.1.4 Model Minimization Reduction Methods

abstraction techniques defined recast terms minimizing stochastic
automaton, providing unifying view different methods offering new insights
abstraction process (Dean & Givan, 1997). automata theory know
given finite-state machine recognizing language L exists unique minimal
finite-state machine 0 also recognizes L. could = 0 , might also
0 exponentially smaller . minimal machine, called minimal
model language L, captures every relevant aspect machines
said equivalent. define similar notions equivalence MDPs. Since
primarily concerned planning, important equivalent MDPs agree value
functions policies. practical standpoint, may necessary find
minimal model find reduced model suciently small still equivalent.
apply idea model minimization (or model reduction) planning follows:
begin using algorithm takes input implicit MDP model factored form
produces (if lucky) explicit, reduced model whose size within polynomial
factor size factored representation. use favorite state-based
dynamic programming algorithms solve explicit model.
69

fiBoutilier, Dean, & Hanks

think dynamic programming techniques rely structured representations discussed earlier operating reduced model without ever explicitly constructing
model. cases, building reduced model may appropriate;
cases, one might save considerable effort explicitly constructing parts
reduced model absolutely necessary.
potential computational problems model-minimization techniques sketched above. small minimal model may exist, may hard find.
Instead, might look reduced model easier find necessarily minimal. could fail, case might look model small enough useful
approximately equivalent original factored model. careful
mean \approximate," intuitively two MDPs approximately equivalent
corresponding optimal value functions within small factor one another.
order practical, MDP model reduction schemes operate directly implicit
factored representation original MDP. Lee Yannakakis (1992) call online
model minimization. Online model minimization starts initial partition states.
Minimization iteratively refines partition splitting clusters smaller clusters.
cluster split states cluster behave differently respect
transitions states clusters. local property satisfied
clusters given partition, model consisting aggregate states correspond
clusters partition equivalent original model. addition,
initial partition method splitting clusters satisfy certain properties,45
guaranteed find minimal model. case MDP reduction, initial partition
groups together states reward, nearly reward case
approximation methods.
clusters partitions manipulated online model reduction methods represented intensionally formulas involving state variables. instance, formula
RHC ^ Loc(M ) represents set states robot coffee located
mail room. operations performed clusters require conjoining, complementing, simplifying, checking satisfiability. worst case, operations
intractable, successful application methods depends critically
problem way represented. illustrate basic idea simple
example.

Example 5.4 Figure 30 depicts simple version running example single
action. three boolean state variables corresponding RHC|the robot
coffee (or not, RHC), CR|there outstanding request coffee (or not, CR),
and, considering two location possibilities, Loc(C )|the robot coffee
room (or not, Loc(C )). Whether outstanding coffee request depends
whether request previous stage whether robot
coffee room. Location depends location previous stage,
reward depends whether outstanding coffee request.

45. property required initial partition that, two states cluster partition
defining minimal model (recall minimal model unique), must cluster
initial partition.

70

fiDecision-Theoretic Planning: Structural Assumptions

St 1

St

CR

CR

Pr(CR 1)
CR
CR
Loc(C)
Loc(C)
0.8
0.7
0.9

Loc

Loc

Pr(Loc(C) 1) = 0.7

RHC

Pr(RHC 1)
Loc(C)
Loc(C)
RHC
RHC
0.5
0.7
1.0

R


R(S t) = 1 CR
0 else

RHC

Figure 30: Factored model illustrating model-reduction techniques.
CR Loc(C)

CR
CR

CR
CR Loc(C)
(a)

(b)

Figure 31: Models involving aggregate states: (a) model corresponding initial
partition (b) minimal model.
initial partition shown Figure 31(a) defined terms immediate rewards.
say states particular starting cluster behave respect
particular destination cluster probability ending destination
cluster states starting cluster. property satisfied
starting cluster CR destination cluster CR Figure 31(a), split
cluster labeled CR obtain model Figure 31(b). property satisfied
pairs clusters model Figure 31(b) minimal model. 2
Lee Yannakakis algorithm non-deterministic finite-state machines
extended Givan Dean handle classical Strips planning problems (Givan & Dean,
1997) MDPs (Dean & Givan, 1997). basic step splitting cluster closely
related goal regression, relationship explored (Givan & Dean, 1997). Variants
model reduction approach apply action space large represented
factored form (Dean, Givan, & Kim, 1998); example, action specified
set parameters corresponding allocations several different
resources optimization problem. also exist algorithms computing approxi71

fiBoutilier, Dean, & Hanks







R

G

C

G
P

B

B



E

B

(a)

(b)

(c)

Figure 32: Reachability serial problem decomposition.
mate models (Dean, Givan, & Leach, 1997) ecient planning algorithms use
approximate models (Givan, Leach, & Dean, 1997).

5.2 Reachability Analysis Serial Problem Decomposition
5.2.1 Reachability Analysis

existence goal states exploited different settings. instance, deterministic classical planning problems, regression viewed form directed dynamic
programming. Without uncertainty, certain policy either reaches goal state not,
dynamic programming backups need performed goal states,
possible states. Regression, therefore, implicitly exploits certain reachability characteristics domain along special structure value function.
Reachability analysis applied much broadly forms basis various types
problem decomposition. decomposition problem solving, MDP broken several
subprocesses solved independently, roughly independently, solutions
pieced together. subprocesses whose solutions interact marginally treated
independent, might expect good nonoptimal global solution result. Furthermore,
structure problem requires solution particular subproblem
needed, solutions subproblems ignored need computed
all. instance, regression analysis, optimal action states cannot reach
goal region irrelevant solution classical AI planning problem. shown
schematically Figure 32(a), regions B never explored backward
search state space: states reach goal within search horizon
ever deemed relevant. regions B may reachable start state,
fact reach goal state means known irrelevant.
system dynamics stochastic, scheme form basis approximately
optimal solution method: regions B ignored unlikely transition
regression goal region (region R). Similar remarks using progression forward
search start state apply, illustrated Figure 32(b).
72

fiDecision-Theoretic Planning: Structural Assumptions

Several schemes proposed AI literature exploiting reachability
constraints, apart usual forward- backward-search approaches. Peot Smith
(1993) introduce operator graph, structure computed prior problem solving
caches reachability relationships among propositions. graph consulted
planning process deciding actions insert plan resolve
threats.
GraphPlan algorithm Blum Furst (1995) attempts blend considerations
forward backward reachability deterministic planning context. One
diculties regression may regress goal region sequence
operators find region cannot reached initial state.
Figure 32(a), example, states region R may reachable initial
state. GraphPlan constructs variant operator graph called planning graph,
certain forward reachability constraints posted. Regression implemented
usual, current subgoal set violates forward reachability constraints
point, subgoal set abandoned regression search backtracks.
Conceptually, one might think GraphPlan constructing forward search tree
state space initial state root, backward search
goal region backward tree. course, process state-based:
instead, constraints possible variable values hold simultaneously different
planning stages recorded, regression used search backward planning
graph. sense, GraphPlan viewed constructing abstraction
forward-reachable states distinguished unreachable states planning stage,
using distinction among abstract states quickly identify infeasible regression
paths. Note, however, GraphPlan approximates distinction overestimating
set reachable states. Overestimation (as opposed underestimation) ensures
regression search space contains legitimate plans.
Reachability also exploited solution general MDPs. Dean
et al. (1995) propose envelope method solving \goal-based" MDPs approximately.
Assuming path generated quickly given start state goal region,
MDP consisting states path perhaps neighboring states solved.
deal transitions lead envelope, heuristic method estimates value
states.46 time permits, set neighboring states expanded, increasing
solution quality accurately evaluating quality alternative actions.
ideas underlying GraphPlan applied general MDPs
(Boutilier, Brafman, & Geib, 1998), construction planning graph generalized deal stochastic, conditional action representation offered 2TBNs. Given
initial state (or set initial states), algorithm discovers reachability constraints
form like GraphPlan | instance, two variable values X = x1
= y3 cannot obtain simultaneously; is, action sequence starting
given initial state lead state values hold.47 reachability
constraints discovered process used simplify action reward representation MDP refers reachable states. case, action
46. approximate abstraction techniques described Section 5.1.3 might used generate
heuristic information.
47. General k-ary constraints type considered (Boutilier et al., 1998).

73

fiBoutilier, Dean, & Hanks

requires unreachable set values hold effectively deleted. cases, certain
variables discovered immutable given initial conditions
deleted, leading much smaller MDPs. simplified representation retains original
propositional structure standard abstraction methods applied reachable
MDP. also suggested strong synergy exists abstraction reachability analysis together techniques reduce size \effective" MDP
solved much dramatically either isolation. reachability constraints used prune regression paths deterministic domains, used
prune value function policy estimates generated decision-theoretic regression
abstraction algorithms (Boutilier et al., 1998).
results reported (Boutilier et al., 1998) limited single process-planning
domain, show reachability analysis together abstraction provide substantial reductions size effective MDP must solved, least domains.
domain 31 binary variables, reachability considerations generally eliminated
order 10 15 variables (depending initial state arity|binary
ternary|of constraints considered), reducing state space size 231 anywhere
222 215 . Incorporating abstraction reachable MDP provided considerably
reduction, reducing MDP sizes ranging 28 effectively zero states.
latter case would occur discovered values variables impact reward
altered|in case every course action expected utility
MDP needn't solved (or solved applying null actions zero cost).
5.2.2 Serial Problem Decomposition Communicating Structure

communicating reachability structure MDP provides way formalize different types problem decomposition. classify MDP according Markov
chains induced stationary policies admits. fixed Markov chain, group
states maximal recurrent classes transient states, described Section 2.1.
MDP recurrent policy induces Markov chain single recurrent class.
MDP unichain policy induces single recurrent class (possibly) transient states. MDP communicating pair states s; t, policy
reach t. MDP weakly communicating exists closed set
states communicating plus (possibly) set states transient every policy.
call MDPs noncommunicating.
notions crucial construction optimal average-reward policies,
also exploited problem decomposition. Suppose MDP discovered consist
set recurrent classes C1 ; Cn (i.e., matter policy adopted, agent cannot
leave class enters class) set transient states.48 clear
optimal policy restricted class Ci constructed without reference policy
decisions made states outside Ci even values. Essentially, Ci
viewed independent subprocess.
48. simple way view classes think agent adopting randomized policy action
adopted state positive probability. classes induced Markov chain correspond
classes MDP.

74

fiDecision-Theoretic Planning: Structural Assumptions

observation leads following suggestion optimal policy construction:49
solve subprocesses consisting recurrent classes MDPs; remove
states MDP, forming reduced MDP consisting transient states.
break reduced MDP recurrent classes solve independently.
key effectively use value function original recurrent
states (computed solving independent subproblems Step 1) take account
transitions recurrent classes reduced MDP. Figure 32(c) shows MDP
broken classes might constructed way. original MDP, classes C
E recurrent solved independently. removed MDP, class
recurrent reduced MDP. can, course, solved without reference classes
B , rely value states transitions class E . However,
value function E available purpose, used solve
consisted jDj states. hand, B solved, finally
solved. Lin Dean (1995) provide version type decomposition
also employs factored representation. factored representation allows dimensionality
reduction different state subspaces aggregating states differ values
irrelevant variables subspaces.
key decomposition discovery recurrent classes MDP.
Puterman (1994) suggests adaptation Fox-Landi algorithm (Fox & Landi, 1968)
discovering structure Markov chains O(N 2 ) (recall N = jSj).50 alleviate
diculties algorithms work explicit state-based representation, Boutilier
Puterman (1995) propose variant algorithm works factored 2TBN
representation.
One diculty form decomposition reliance strongly independent
subproblems (i.e., recurrent classes) within MDP. Others explored exact approximate techniques work less restrictive assumptions. One simple method
approximation construct \approximately recurrent classes." Figure 32(c) might
imagine C E nearly independent sense transitions
low-probability high-cost. Treating independent might lead approximately optimal policies whose error bounded. solutions C E interact
strongly enough solutions constructed completely independently,
different approach solving decomposed problem taken.
optimal value function E then, pointed out, calculate
optimal value function D. first thing note don't need know
value function states E , value every state E reachable
state single step. set states outside reachable single
step state inside referred states periphery D. values
states intersection E periphery summarize value exiting
ending E . refer set states periphery block
kernel MDP. different blocks interact one another
states kernel.
49. Ross Varadarajan (1991) make related suggestion solving average-reward problems.
50. slight correction made suggested algorithm (Boutilier & Puterman, 1995).

75

fiBoutilier, Dean, & Hanks

Loc(C)

Loc(L)

Loc(M )

Loc(O)

Figure 33: Decomposition based location.

Loc(C)

Loc(L)
Kernel

Loc(M )

Loc(O)

Figure 34: Kernel-based decomposition depicting kernel states.

76

fiDecision-Theoretic Planning: Structural Assumptions

Example 5.5 Spatial features often provide natural dimension along decom-

pose domain. running example, location robot might used
decompose state space blocks states, one block possible locations. Figure 33 shows decomposition superimposed state-transition
diagram MDP. States kernel shaded might correspond
entrances exits locations. star-shaped topology, induced kernel
decomposition used (Kushner & Chen, 1974) (Dean & Lin, 1995), illustrated
Figure 34. Figure 33, hallway location explicitly represented.
simplification may reasonable hallway conduit moving
one room another; case function hallway accounted
dynamics governing states kernel. Figures 33 34 idealized that, given
full set features running example, kernel would contain many
states. 2

One technique computing optimal policy entire MDP involves repeatedly
solving MDPs corresponding individual blocks. techniques works follows:
initially, guess value every state kernel.51 Given current estimate
values kernel states, solve component MDPs; solution produces new
estimate states kernel. adjust values states kernel
considering difference current new estimates iterate
difference negligible.
iterative method solving decomposed MDP special case Lagrangian
method finding extrema function. literature replete
methods linear nonlinear systems equations (Winston, 1992). possible
formulate MDP linear program (D'Epenoux, 1963; Puterman, 1994). Dantzig
Wolfe (1960) developed method decomposing system equations involving
large number variables set smaller systems equations interacting set
coupling variables (variables shared two blocks). Dantzig-Wolfe
decomposition method, original, large system equations solved iteratively
solving smaller systems adjusting coupling variables iteration
adjustment required. linear programming formulation MDP,
values states encoded variables.
Kushner Chen (1974) exploit fact MDPs modeled linear programs
using Dantzig-Wolfe decomposition method solve MDPs involving large number
states. Dean Lin (1995) describe general framework solving decomposed MDPs
pointing work Kushner Chen special case, neither work addresses
issue decompositions come from. Dean et al. (1995) investigate methods
decomposing state space two blocks: reachable k steps fewer
reachable k steps (see discussion reachability above). set states
reachable k fewer steps used construct MDP basis policy
approximates optimal policy. k increases, size block states reachable
k steps increases, ensuring better solution; amount time required compute
51. Ideally would aggregate kernel states value provide compact representation.
remainder section, however, won't consider opportunities combining
aggregation decomposition methods.

77

fiBoutilier, Dean, & Hanks

solution also increases. Dean et al. (1995) discuss methods solving MDPs time-critical
problems trading quality time.
ignored issue obtain decompositions expedite calculations. Ideally, component decomposition would yield simplification via
aggregation abstraction, reducing dimensionality component thereby
avoiding explicit enumeration states. Lin (1997) presents methods exploiting
structure certain special cases communicating structure revealed
domain expert. general, however, finding decomposition minimize effort
spent solving component MDPs quite hard (at least hard finding smallest circuit consistent given input-output behavior) best hope
good heuristic methods. Unfortunately, aware particularly useful
heuristics finding serial decompositions Markov decision processes. Developing
heuristics clearly area investigation.
Related form decomposition development macro operators MDPs
(Sutton, 1995). Macros long history classical planning problem solving (Fikes,
Hart, & Nilsson, 1972; Korf, 1985), recently generalized MDPs
(Hauskrecht, Meuleau, Kaelbling, Dean, & Boutilier, 1998; Parr, 1998; Parr & Russell, 1998;
Precup, Sutton, & Singh, 1998; Stone & Veloso, 1999; Sutton, 1995; Thrun & Schwartz,
1995). work, macro taken local policy region state
space (or block terminology). Given MDP comprising blocks
set macros defined block, MDP solved selecting macro action
block global policy induced set macros picked close
optimal, least best combination macros set available.
(Sutton, 1995; Precup et al., 1998), macros treated temporally-abstract actions
models defined macro treated single action
used policy value iteration (along concrete actions). (Hauskrecht et al., 1998;
Parr, 1998; Parr & Russell, 1998), models exploited hierarchical fashion,
high-level MDP consisting states lying boundaries blocks, macros
\actions" chosen states. issue macro generation|
constructing set macros guaranteed provide exibility select close optimal
global behavior|is addressed (Hauskrecht et al., 1998; Parr, 1998). relationship
serial decomposition techniques quite close; thus, problems discovering good
decompositions, constructing good sets macros, exploiting intensional representations
areas clearer, compelling solutions required. date, work area
provided much computational utility solution MDPs|except cases
good, hand-crafted, region-based decompositions macros provided|and little
work taken account factored nature many MDPs. reason,
discuss detail. However, general notion serial decomposition continues
develop shows great promise.

5.3 Multiattribute Reward Parallel Decomposition
Another form decomposition parallel decomposition, MDP broken
set sub-MDPs \run parallel." Specifically, stage (global)
decision process, state subprocess affected. instance, Figure 35, action
78

fiDecision-Theoretic Planning: Structural Assumptions



MDP1



MDP2



MDP3

Figure 35: Parallel problem decomposition.

affects state subprocess. Intuitively, action suitable execution

original MDP state reasonably good sub-MDPs.
Generally, sub-MDPs form either product join decomposition original
state space (contrast union decompositions state space determined serial
decompositions): state space formed taking cross product sub-MDP state
spaces, join certain states subprocesses cannot linked. subprocesses
may identical action spaces (as Figure 35), may action space,
global action choice factored choice subprocess. latter
case, sub-MDPs may completely independent, case (global) MDP
solved exponentially faster. challenging problem arises constraints
legal action combinations. example, actions subprocesses
require certain shared resources, interactions global choice may arise.
parallel MDP decomposition, wish solve sub-MDPs use policies
value functions generated help construct optimal approximately optimal solution
original MDP, highlighting need find appropriate decompositions MDPs
develop suitable merging techniques. Recent parallel decomposition methods
involved decomposing MDP subprocesses suitable distinct objectives. Since
reward functions often deal multiple objectives, associated independent
reward, whose rewards summed determine global reward, often
natural way decompose MDPs. Thus, ideas multiattribute utility theory
seen play role solution MDPs.
Boutilier et al. (1997) decompose MDP specified using 2TBNs additive reward
function using abstraction technique described Section 5.1.3. component
reward function, abstraction used generate MDP referring variables
relevant component.52 Since certain state variables may present multiple
sub-MDPs (i.e., relevant one objective), original state space join
subspaces. Thus, decomposition tackled automatically. Merging tackled several
ways. One involves using sum value functions obtained solving sub-MDPs
heuristic estimate true value function. heuristic used guide online,
state-based search (see Section 3.2.1). sub-MDPs interact, heuristic
perfect leads backtrack-free optimal action selection; interact, search
52. Note existence factored MDP representation crucial abstraction method.

79

fiBoutilier, Dean, & Hanks

required detect con icts. Note sub-MDP identical sets actions.
action space large, branching factor search process may prohibitive.
Singh Cohn (1998) also deal parallel decomposition, though assume
global MDP specified explicitly set parallel MDPs, thus generating decompositions
global MDP issue. global MDP given cross product state
action spaces sub-MDPs reward functions summed. However,
constraints feasible action combinations couple solutions sub-MDPs.
solve global MDP, sum sub-MDP value functions used upper bound
optimal global value function, maximum (at global state)
used lower bound. bounds form basis action-elimination procedure
value-iteration algorithm solving global MDP.53 Unfortunately, value iteration
run explicit state space global MDP. Since action space also cross
product, potential computational bottleneck value iteration, well.
Meuleau et al. (1998) use parallel decomposition approximate solution stochastic resource allocation problems large state action spaces. Much like Singh
Cohn (1998), MDP specified terms number independent MDPs,
involving distinct objective, whose action choices linked shared resource constraints. value functions individual MDPs constructed oine used
set online action-selection procedures. Unlike many approximation procedures
discussed, approach makes attempt construct policy explicitly (and
similar real-time search RTDP respect) construct value function
explicitly. method applied large MDPs, state spaces size
21000 actions spaces even larger, solve problems roughly half
hour. solutions produced approximate, size problem precludes
exact solution; good estimates solution quality hard derive. However,
method applied smaller problems nature whose exact solution
computed, approximations high quality (Meuleau et al., 1998). able
solve large MDPs (with large, factored, state action spaces), model
relies somewhat restrictive assumptions nature local value functions
ensure good solution quality. However, basic approach appears generalizable,
offers great promise solving large factored MDPs.
algorithms (Singh & Cohn, 1998) (Meuleau et al., 1998) seen
rely least implicitly structured MDP representations involving almost independent
subprocesses. seems likely approaches could take advantage automatic
MDP decomposition algorithms (Boutilier et al., 1997), factored
representations explicitly play part.

5.4 Summary

seen number ways intensional representations exploited
solve MDPs effectively without enumeration state space. include techniques
abstraction MDPs, including based relevance analysis, goal regression
decision-theoretic regression; techniques relying reachability analysis serial decomposition; methods parallel MDP decomposition exploiting multiattribute nature
53. Singh Cohn (1998) also incorporate methods removing unreachable states value iteration.

80

fiDecision-Theoretic Planning: Structural Assumptions

reward functions. Many methods can, fortunate circumstances, offer exponential reduction solution time space required represent policy value function;
none come guarantees reductions except certain special cases.
methods described provide approximate solutions (often error bounds provided), offer optimality guarantees general, provide optimal
solutions suitable assumptions.
One avenue explored detail relationship structured solution methods developed MDPs described techniques used solving
Bayesian networks. Since many algorithms discussed section rely structure inherent 2TBN representation MDP, natural ask whether
embody intuitions underlie solution algorithms Bayes nets, thus
whether solution techniques Bayes nets (directly indirectly) applied
MDPs ways give rise algorithms similar discussed here. remains
open question point, undoubtedly strong ties exist. Tatman Shachter
(1990) explored connections uence diagrams MDPs. Kjaerulff
(1992) investigated computational considerations involved applying join tree methods
reasoning tasks monitoring prediction temporal Bayes nets. abstraction methods discussed Section 5.1.2 interpreted form variable elimination
(Dechter, 1996; Zhang & Poole, 1996). Elimination variables occurs temporal order,
good orderings within time slice must also exploit tree graph structure
CPTs. Approximation schemes based variable elimination (Dechter, 1997; Poole, 1998)
may also related certain approximation methods developed MDPs.
independence-based decompositions MDPs discussed Section 5.3 clearly viewed
exploiting independence relations made explicit \unrolling" 2TBN. development connections Bayes net inference algorithms doubt prove
useful enhancing understanding existing methods, increasing range
applicability pointing new algorithms.

6. Concluding Remarks
search effective algorithms controlling automated agents long important history, problem continue grow importance decisionmaking functionality automated. Work several disciplines, among AI, decision
analysis, OR, addressed problem, carried different problem definitions, different sets simplifying assumptions, different viewpoints, hence
different representations algorithms problem solving. often not, assumptions seem made historical reasons reasons convenience,
often dicult separate essential assumptions accidental. important
clarify relationships among problem definitions, crucial assumptions, solution
techniques, meaningful synthesis take place.
paper analyzed various approaches particular class sequential decision problems studied OR, decision analysis, AI literature.
started general, reasonably neutral statement problem, couched, convenience, language Markov decision processes. demonstrated
various disciplines define problem (i.e., assumptions make), effect
81

fiBoutilier, Dean, & Hanks

assumptions worst-case time complexity solving problem defined.
Assumptions regarding two main factors seem distinguish commonly studied
classes decision problems:

observation sensing: sensing tend fast, cheap, accurate laborious,
costly noisy?

incentive structure agent: behavior evaluated ability perform
particular task, ability control system interval time?

Moving beyond worst-case analysis, generally assumed that, although pathological cases inevitably dicult, agent able solve \typical" \easy"
cases effectively. so, agent needs able identify structure problem
exploit structure algorithmically.
identified three ways structural regularities recognized, represented,
exploited computationally. first structure induced domain-level simplifying
assumptions like full observability, goal satisfaction time-separable value functions,
on. second structure exploited compact domain-specific encodings states,
actions, rewards. designer use techniques make structure explicit,
decision-making algorithms exploit structural regularities apply
particular problem hand. third involves aggregation, abstraction decomposition techniques, whereby structural regularities discovered exploited
problem-solving process itself. developing framework|one allows comparison
domains, assumptions, problems, techniques drawn different disciplines|we
discover essential problem structure required specific representations algorithms
prove effective; way insights techniques developed
certain problems, within certain disciplines, evaluated potentially applied
new problems, within disciplines.
main focus work elucidation various forms structure
decision problems exploited representationally computationally.
part, focused propositional structure, commonly associated planning AI circles. complete treatment would also included
compact representations dynamics, rewards, policies, value functions often
considered continuous, real-valued domains. instance, discussed linear
dynamics quadratic cost functions, often used control theory (Caines, 1988),
use neural-network representations value functions, frequently adopted within
reinforcement learning community (Bertsekas & Tsitsiklis, 1996; Tesauro, 1994),54
discussed partitioning continuous state spaces often addressed reinforcement
learning (Moore & Atkeson, 1995). Neither addressed relational quantificational structure used first-order planning representations. However, even techniques
cast within framework described here; example, use piecewise-linear
value functions seen form abstraction different linear components
applied different regions clusters state space.
54. Bertsekas Tsitsiklis (1996) provide in-depth treatment neural network linear function
approximators MDPs reinforcement learning.

82

fiDecision-Theoretic Planning: Structural Assumptions

Although certain cases indicated devise methods exploit several
types structure once, research along lines limited. extent,
many representations algorithms described paper complementary
pose obstacles combination. remains seen interact
techniques developed forms structure, used continuous state
action spaces.
analysis raises opportunities challenges: understanding assumptions,
techniques, relationships, designer decision-making agents many
tools build effective problem solvers; challenges lie development
additional tools integration existing ones.

Acknowledgments

Many thanks careful comments referees. Thanks Ron Parr Robert
St-Aubin comments earlier draft paper. students taking CS3710
(Spring 1999) taught Martha Pollack University Pittsburgh CPSC522
(Winter 1999) University British Columbia also deserve thanks detailed
comments.
Boutilier supported NSERC Research Grant OGP0121843, NCE IRISII program Project IC-7. Dean supported part National Science Foundation
Presidential Young Investigator Award IRI-8957601 Air Force Advanced
Research Projects Agency Department Defense Contract No. F30602-91-C0041. Hanks supported part ARPA / Rome Labs Grant F30602{95{1{0024
part NSF grant IRI{9523649.

References

Allen, J., Hendler, J., & Tate, A. (Eds.). (1990). Readings Planning. Morgan-Kaufmann,
San Mateo.
Astrom, K. J. (1965). Optimal control Markov decision processes incomplete state
estimation. J. Math. Anal. Appl., 10, 174{205.
Bacchus, F., Boutilier, C., & Grove, A. (1996). Rewarding behaviors. Proceedings
Thirteenth National Conference Artificial Intelligence, pp. 1160{1167 Portland,
OR.
Bacchus, F., Boutilier, C., & Grove, A. (1997). Structured solution methods nonMarkovian decision processes. Proceedings Fourteenth National Conference
Artificial Intelligence, pp. 112{117 Providence, RI.
Bacchus, F., & Kabanza, F. (1995). Using temporal logic control search
forward chaining planner.
Proceedings Third European
Workshop Planning (EWSP'95) Assisi, Italy. Available via URL
ftp://logos.uwaterloo.ca:/pub/tlplan/tlplan.ps.Z.
Bacchus, F., & Teh, Y. W. (1998). Making forward chaining relevant. Proceedings
Fourth International Conference AI Planning Systems, pp. 54{61 Pittsburgh, PA.
83

fiBoutilier, Dean, & Hanks

Bahar, R. I., Frohm, E. A., Gaona, C. M., Hachtel, G. D., Macii, E., Pardo, A., & Somenzi,
F. (1993). Algebraic decision diagrams applications. International Conference Computer-Aided Design, pp. 188{191. IEEE.
Baker, A. B. (1991). Nonmonotonic reasoning framework situation calculus.
Artificial Intelligence, 49, 5{23.
Barto, A. G., Bradtke, S. J., & Singh, S. P. (1995). Learning act using real-time dynamic
programming. Artificial Intelligence, 72 (1{2), 81{138.
Bellman, R. (1957). Dynamic Programming. Princeton University Press, Princeton, NJ.
Bertsekas, D. P., & Castanon, D. A. (1989). Adaptive aggregation infinite horizon
dynamic programming. IEEE Transactions Automatic Control, 34 (6), 589{598.
Bertsekas, D. P. (1987). Dynamic Programming. Prentice-Hall, Englewood Cliffs, NJ.
Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-dynamic Programming. Athena, Belmont,
MA.
Blackwell, D. (1962). Discrete dynamic programming. Annals Mathematical Statistics,
33, 719{726.
Blum, A. L., & Furst, M. L. (1995). Fast planning graph analysis. Proceedings
Fourteenth International Joint Conference Artificial Intelligence, pp. 1636{
1642 Montreal, Canada.
Bonet, B., & Geffner, H. (1998). Learning sorting decision trees POMDPs.
Proceedings Fifteenth International Conference Machine Learning, pp. 73{81
Madison, WI.
Bonet, B., Loerincs, G., & Geffner, H. (1997). robust fast action selection mechanism.
Proceedings Fourteenth National Conference Artificial Intelligence, pp.
714{719 Providence, RI.
Boutilier, C. (1997). Correlated action effects decision theoretic regression. Proceedings Thirteenth Conference Uncertainty Artificial Intelligence, pp. 30{37
Providence, RI.
Boutilier, C., Brafman, R. I., & Geib, C. (1997). Prioritized goal decomposition Markov
decision processes: Toward synthesis classical decision theoretic planning.
Proceedings Fifteenth International Joint Conference Artificial Intelligence,
pp. 1156{1162 Nagoya, Japan.
Boutilier, C., Brafman, R. I., & Geib, C. (1998). Structured reachability analysis Markov
decision processes. Proceedings Fourteenth Conference Uncertainty
Artificial Intelligence, pp. 24{32 Madison, WI.
Boutilier, C., & Dearden, R. (1994). Using abstractions decision-theoretic planning
time constraints. Proceedings Twelfth National Conference Artificial
Intelligence, pp. 1016{1022 Seattle, WA.
84

fiDecision-Theoretic Planning: Structural Assumptions

Boutilier, C., & Dearden, R. (1996). Approximating value trees structured dynamic
programming. Proceedings Thirteenth International Conference Machine
Learning, pp. 54{62 Bari, Italy.
Boutilier, C., Dearden, R., & Goldszmidt, M. (1995). Exploiting structure policy construction. Proceedings Fourteenth International Joint Conference Artificial
Intelligence, pp. 1104{1111 Montreal, Canada.
Boutilier, C., Dearden, R., & Goldszmidt, M. (1999). Stochastic dynamic programming
factored representations. (manuscript).
Boutilier, C., Friedman, N., Goldszmidt, M., & Koller, D. (1996). Context-specific independence Bayesian networks. Proceedings Twelfth Conference Uncertainty
Artificial Intelligence, pp. 115{123 Portland, OR.
Boutilier, C., & Goldszmidt, M. (1996). frame problem Bayesian network action
representations. Proceedings Eleventh Biennial Canadian Conference
Artificial Intelligence, pp. 69{83 Toronto.
Boutilier, C., & Poole, D. (1996). Computing optimal policies partially observable
decision processes using compact representations. Proceedings Thirteenth
National Conference Artificial Intelligence, pp. 1168{1175 Portland, OR.
Boutilier, C., & Puterman, M. L. (1995). Process-oriented planning average-reward optimality. Proceedings Fourteenth International Joint Conference Artificial
Intelligence, pp. 1096{1103 Montreal, Canada.
Brafman, R. I. (1997). heuristic variable-grid solution method POMDPs. Proceedings Fourteenth National Conference Artificial Intelligence, pp. 727{733
Providence, RI.
Bryant, R. E. (1986). Graph-based algorithms boolean function manipulation. IEEE
Transactions Computers, C-35 (8), 677{691.
Bylander, T. (1994). computational complexity propositional STRIPS planning.
Artificial Intelligence, 69, 161{204.
Caines, P. E. (1988). Linear stochastic systems. Wiley, New York.
Cassandra, A. R., Kaelbling, L. P., & Littman, M. L. (1994). Acting optimally partially
observable stochastic domains. Proceedings Twelfth National Conference
Artificial Intelligence, pp. 1023{1028 Seattle, WA.
Cassandra, A. R., Littman, M. L., & Zhang, N. L. (1997). Incremental pruning: simple, fast, exact method pomdps. Proceedings Thirteenth Conference
Uncertainty Artificial Intelligence, pp. 54{61 Providence, RI.
Chapman, D. (1987). Planning conjunctive goals. Artificial Intelligence, 32 (3), 333{377.
85

fiBoutilier, Dean, & Hanks

Chapman, D., & Kaelbling, L. P. (1991). Input generalization delayed reinforcement
learning: algorithm performance comparisons. Proceedings Twelfth
International Joint Conference Artificial Intelligence, pp. 726{731 Sydney, Australia.
Dantzig, G., & Wolfe, P. (1960). Decomposition principle dynamic programs. Operations
Research, 8 (1), 101{111.
Dean, T., Allen, J., & Aloimonos, Y. (1995). Artificial Intelligence: Theory Practice.
Benjamin Cummings.
Dean, T., & Givan, R. (1997). Model minimization Markov decision processes.
Proceedings Fourteenth National Conference Artificial Intelligence, pp. 106{
111 Providence, RI. AAAI.
Dean, T., Givan, R., & Kim, K.-E. (1998). Solving planning problems large state
action spaces. Proceedings Fourth International Conference AI Planning
Systems, pp. 102{110 Pittsburgh, PA.
Dean, T., Givan, R., & Leach, S. (1997). Model reduction techniques computing approximately optimal solutions Markov decision processes. Proceedings
Thirteenth Conference Uncertainty Artificial Intelligence, pp. 124{131 Providence, RI.
Dean, T., Kaelbling, L., Kirman, J., & Nicholson, A. (1993). Planning deadlines
stochastic domains. Proceedings Eleventh National Conference Artificial
Intelligence, pp. 574{579.
Dean, T., Kaelbling, L., Kirman, J., & Nicholson, A. (1995). Planning time constraints stochastic domains. Artificial Intelligence, 76 (1-2), 3{74.
Dean, T., & Kanazawa, K. (1989). model reasoning persistence causation.
Computational Intelligence, 5 (3), 142{150.
Dean, T., & Lin, S.-H. (1995). Decomposition techniques planning stochastic domains. Proceedings Fourteenth International Joint Conference Artificial
Intelligence, pp. 1121{1127.
Dean, T., & Wellman, M. (1991). Planning Control. Morgan Kaufmann, San Mateo,
California.
Dearden, R., & Boutilier, C. (1994). Integrating planning execution stochastic
domains. Proceedings Tenth Conference Uncertainty Artificial Intelligence, pp. 162{169 Washington, DC.
Dearden, R., & Boutilier, C. (1997). Abstraction approximate decision theoretic planning. Artificial Intelligence, 89, 219{283.
Dechter, R. (1996). Bucket elimination: unifying framework probabilistic inference.
Proceedings Twelfth Conference Uncertainty Artificial Intelligence, pp.
211{219 Portland, OR.
86

fiDecision-Theoretic Planning: Structural Assumptions

Dechter, R. (1997). Mini-buckets: general scheme generating approximations
automated reasoning probabilistic inference. Proceedings Fifteenth International Joint Conference Artificial Intelligence, pp. 1297{1302 Nagoya, Japan.
D'Epenoux, F. (1963). Sur un probleme de production et de stockage dans l'aleatoire.
Management Science, 10, 98{108.
Dietterich, T. G., & Flann, N. S. (1995). Explanation-based learning reinforcement
learning: unified approach. Proceedings Twelfth International Conference
Machine Learning, pp. 176{184 Lake Tahoe, NV.
Draper, D., Hanks, S., & Weld, D. (1994a). probabilistic model action leastcommitment planning information gathering. Proceedings Tenth Conference Uncertainty Artificial Intelligence, pp. 178{186 Washington, DC.
Draper, D., Hanks, S., & Weld, D. (1994b). Probabilistic planning information gathering contingent execution. Proceedings Second International Conference
AI Planning Systems, pp. 31{36.
Etzioni, O., Hanks, S., Weld, D., Draper, D., Lesh, N., & Williamson, M. (1992).
approach planning incomplete information. Proceedings Third International Conference Principles Knowledge Representation Reasoning, pp.
115{125 Boston, MA.
Fikes, R., Hart, P., & Nilsson, N. (1972). Learning executing generalized robot plans.
Artificial Intelligence, 3, 251{288.
Fikes, R., & Nilsson, N. J. (1971). STRIPS: new approach application theorem
proving problem solving. Artificial Intelligence, 2, 189{208.
Finger, J. (1986). Exploiting Constraints Design Synthesis. Ph.D. thesis, Stanford University, Stanford.
Floyd, R. W. (1962). Algorithm 97 (shortest path). Communications ACM, 5 (6),
345.
Fox, B. L., & Landi, D. M. (1968). algorithm identifying ergodic subchains
transient states stochastic matrix. Communications ACM, 2, 619{621.
French, S. (1986). Decision Theory. Halsted Press, New York.
Geiger, D., & Heckerman, D. (1991). Advances probabilistic reasoning. Proceedings
Seventh Conference Uncertainty Artificial Intelligence, pp. 118{126 Los
Angeles, CA.
Givan, R., & Dean, T. (1997). Model minimization, regression, propositional STRIPS
planning. Proceedings Fifteenth International Joint Conference Artificial
Intelligence, pp. 1163{1168 Nagoya, Japan.
87

fiBoutilier, Dean, & Hanks

Givan, R., Leach, S., & Dean, T. (1997). Bounded-parameter Markov decision processes.
Proceedings Fourth European Conference Planning (ECP'97), pp. 234|246
Toulouse, France.
Goldman, R. P., & Boddy, M. S. (1994). Representing uncertainty simple planners.
Proceedings Fourth International Conference Principles Knowledge
Representation Reasoning, pp. 238{245 Bonn, Germany.
Haddawy, P., & Doan, A. (1994). Abstracting probabilistic actions. Proceedings
Tenth Conference Uncertainty Artificial Intelligence, pp. 270{277 Washington,
DC.
Haddawy, P., & Hanks, S. (1998). Utility Models Goal-Directed Decision-Theoretic
Planners. Computational Intelligence, 14 (3).
Haddawy, P., & Suwandi, M. (1994). Decision-theoretic refinement planning using inheritence abstraction. Proceedings Second International Conference AI Planning Systems, pp. 266{271 Chicago, IL.
Hanks, S. (1990). Projecting plans uncertain worlds. Ph.D. thesis 756, Yale University,
Department Computer Science, New Haven, CT.
Hanks, S., & McDermott, D. V. (1994). Modeling dynamic uncertain world I: Symbolic
probabilistic reasoning change. Artificial Intelligence, 66 (1), 1{55.
Hanks, S., Russell, S., & Wellman, M. (Eds.). (1994). Decision Theoretic Planning: Proceedings AAAI Spring Symposium. AAAI Press, Menlo Park.
Hansen, E. A., & Zilberstein, S. (1998). Heuristic search cyclic AND/OR graphs.
Proceedings Fifteenth National Conference Artificial Intelligence, pp. 412{
418 Madison, WI.
Hauskrecht, M. (1997). heuristic variable-grid solution method POMDPs. Proceedings Fourteenth National Conference Artificial Intelligence, pp. 734{739
Providence, RI.
Hauskrecht, M. (1998). Planning Control Stochastic Domains Imperfect Information. Ph.D. thesis, Massachusetts Institute Technology, Cambridge.
Hauskrecht, M., Meuleau, N., Kaelbling, L. P., Dean, T., & Boutilier, C. (1998). Hierarchical
solution Markov decision processes using macro-actions. Proceedings
Fourteenth Conference Uncertainty Artificial Intelligence, pp. 220{229 Madison,
WI.
Hoey, J., St-Aubin, R., Hu, A., & Boutilier, C. (1999). SPUDD: Stochastic planning
using decision diagrams. Proceedings Fifteenth Conference Uncertainty
Artificial Intelligence Stockholm. appear.
Howard, R. A. (1960). Dynamic Programming Markov Processes. MIT Press, Cambridge, Massachusetts.
88

fiDecision-Theoretic Planning: Structural Assumptions

Howard, R. A., & Matheson, J. E. (1984). uence diagrams. Howard, R. A., & Matheson, J. E. (Eds.), Principles Applications Decision Analysis. Strategic
Decisions Group, Menlo Park, CA.
Kambhampati, S. (1997). Refinement planning unifying framework plan synthesis.
AI Magazine, Summer 1997, 67{97.
Kearns, M., Mansour, Y., & Ng, A. Y. (1999). sparse sampling algorithm nearoptimal planning large markov decision processes. Proceedings Sixteenth
International Joint Conference Artificial Intelligence Stockholm. appear.
Keeney, R. L., & Raiffa, H. (1976). Decisions Multiple Objectives: Preferences
Value Tradeoffs. John Wiley Sons, New York.
Kjaerulff, U. (1992). computational scheme reasoning dynamic probabilistic networks. Proceedings Eighth Conference Uncertainty AI, pp. 121{129
Stanford.
Knoblock, C. A. (1993). Generating Abstraction Hierarchies: Automated Approach
Reducing Search Planning. Kluwer, Boston.
Knoblock, C. A., Tenenberg, J. D., & Yang, Q. (1991). Characterizing abstraction hierarchies planning. Proceedings Ninth National Conference Artificial
Intelligence, pp. 692{697 Anaheim, CA.
Koenig, S. (1991). Optimal probabilistic decision-theoretic planning using Markovian
decision theory. M.sc. thesis UCB/CSD-92-685, University California Berkeley,
Computer Science Department.
Koenig, S., & Simmons, R. (1995). Real-time search nondeterministic domains.
Proceedings Fourteenth International Joint Conference Artificial Intelligence,
pp. 1660{1667 Montreal, Canada.
Korf, R. (1985). Macro-operators: weak method learning. Artificial Intelligence, 26,
35{77.
Korf, R. E. (1990). Real-time heuristic search. Artificial Intelligence, 42, 189{211.
Kushmerick, N., Hanks, S., & Weld, D. (1995). Algorithm Probabilistic Planning.
Artificial Intelligence, 76, 239{286.
Kushner, H. J., & Chen, C.-H. (1974). Decomposition systems governed Markov
chains. IEEE Transactions Automatic Control, 19 (5), 501{507.
Lee, D., & Yannakakis, M. (1992). Online minimization transition systems. Proceedings
24th Annual ACM Symposium Theory Computing, pp. 264{274 Victoria,
BC.
Lin, F., & Reiter, R. (1994). State constraints revisited. Journal Logic Computation,
4 (5), 655{678.
89

fiBoutilier, Dean, & Hanks

Lin, S.-H. (1997). Exploiting Structure Planning Control. Ph.D. thesis, Department
Computer Science, Brown University.
Lin, S.-H., & Dean, T. (1995). Generating optimal policies high-level plans conditional branches loops. Proceedings Third European Workshop
Planning (EWSP'95), pp. 187{200.
Littman, M. L. (1997). Probabilistic propositional planning: Representations complexity. Proceedings Fourteenth National Conference Artificial Intelligence,
pp. 748{754 Providence, RI.
Littman, M. L., Dean, T. L., & Kaelbling, L. P. (1995). complexity solving
Markov decision problems. Proceedings Eleventh Conference Uncertainty
Artificial Intelligence, pp. 394{402 Montreal, Canada.
Littman, M. L. (1996). Algorithms sequential decision making. Ph.D. thesis CS{96{09,
Brown University, Department Computer Science, Providence, RI.
Lovejoy, W. S. (1991a). Computationally feasible bounds partially observed Markov
decision processes. Operations Research, 39 (1), 162{175.
Lovejoy, W. S. (1991b). survey algorithmic methods partially observed Markov
decision processes. Annals Operations Research, 28, 47{66.
Luenberger, D. G. (1973). Introduction Linear Nonlinear Programming. AddisonWesley, Reading, Massachusetts.
Luenberger, D. G. (1979). Introduction Dynamic Systems: Theory, Models Applications. Wiley, New York.
Madani, O., Condon, A., & Hanks, S. (1999). undecidability probabilistic planning
infinite-horizon partially observable Markov decision problems. Proceedings
Sixteenth National Conference Artificial Intelligence Orlando, FL. appear.
Mahadevan, S. (1994). discount discount reinforcement learning: case
study comparing R-learning Q-learning. Proceedings Eleventh International Conference Machine Learning, pp. 164{172 New Brunswick, NJ.
McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. Proceedings
Ninth National Conference Artificial Intelligence, pp. 634{639 Anaheim, CA.
McCallum, R. A. (1995). Instance-based utile distinctions reinforcement learning
hidden state. Proceedings Twelfth International Conference Machine
Learning, pp. 387{395 Lake Tahoe, Nevada.
McCarthy, J., & Hayes, P. J. (1969). philosophical problems standpoint
artificial intelligence. Machine Intelligence, 4, 463{502.
90

fiDecision-Theoretic Planning: Structural Assumptions

Meuleau, N., Hauskrecht, M., Kim, K., Peshkin, L., Kaelbling, L., Dean, T., & Boutilier, C.
(1998). Solving large weakly coupled Markov decision processes. Proceedings
Fifteenth National Conference Artificial Intelligence, pp. 165{172 Madison,
WI.
Moore, A. W., & Atkeson, C. G. (1995). parti-game algorithm variable resolution
reinforcement learning multidimensional state spaces. Machine Learning, 21, 199{
234.
Papadimitriou, C. H., & Tsitsiklis, J. N. (1987). complexity Markov chain decision
processes. Mathematics Operations Research, 12 (3), 441{450.
Parr, R. (1998). Flexible decomposition algorithms weakly coupled Markov decision
processes. Proceedings Fourteenth Conference Uncertainty Artificial
Intelligence, pp. 422{430 Madison, WI.
Parr, R., & Russell, S. (1995). Approximating optimal policies partially observable
stochastic domains. Proceedings Fourteenth International Joint Conference
Artificial Intelligence, pp. 1088{1094 Montreal.
Parr, R., & Russell, S. (1998). Reinforcement learning hierarchies machines.
Jordan, M., Kearns, M., & Solla, S. (Eds.), Advances Neural Information Processing
Systems 10, pp. 1043{1049. MIT Press, Cambridge.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible
Inference. Morgan Kaufmann, San Mateo.
Pednault, E. (1989). ADL: Exploring middle ground STRIPS situation calculus. Proceedings First International Conference Principles
Knowledge Representation Reasoning, pp. 324{332 Toronto, Canada.
Penberthy, J. S., & Weld, D. S. (1992). UCPOP: sound, complete, partial order planner
ADL. Proceedings Third International Conference Principles Knowledge
Representation Reasoning, pp. 103{114 Boston, MA.
Peot, M., & Smith, D. (1992). Conditional Nonlinear Planning. Proceedings First
International Conference AI Planning Systems, pp. 189{197 College Park, MD.
Perez, M. A., & Carbonell, J. G. (1994). Control knowledge improve plan quality.
Proceedings Second International Conference AI Planning Systems, pp. 323{
328 Chicago, IL.
Poole, D. (1995). Exploiting rule structure decision making within independent
choice logic. Proceedings Eleventh Conference Uncertainty Artificial
Intelligence, pp. 454{463 Montreal, Canada.
Poole, D. (1997a). independent choice logic modelling multiple agents uncertainty. Artificial Intelligence, 94 (1{2), 7{56.
91

fiBoutilier, Dean, & Hanks

Poole, D. (1997b). Probabilistic partial evaluation: Exploiting rule structure probabilistic
inference. Proceedings Fifteenth International Joint Conference Artificial
Intelligence, pp. 1284{1291 Nagoya, Japan.
Poole, D. (1998). Context-specific approximation probabilistic inference. Proceedings
Fourteenth Conference Uncertainty Artificial Intelligence, pp. 447{454
Madison, WI.
Precup, D., Sutton, R. S., & Singh, S. (1998). Theoretical results reinforcement learning
temporally abstract behaviors. Proceedings Tenth European Conference
Machine Learning, pp. 382{393 Chemnitz, Germany.
Pryor, L., & Collins, G. (1993). CASSANDRA: Planning contingencies. Technical
report 41, Northwestern University, Institute Learning Sciences.
Puterman, M. L. (1994). Markov Decision Processes. John Wiley & Sons, New York.
Puterman, M. L., & Shin, M. (1978). Modified policy iteration algorithms discounted
Markov decision problems. Management Science, 24, 1127{1137.
Ross, K. W., & Varadarajan, R. (1991). Multichain Markov decision processes
sample-path constraint: decomposition approach. Mathematics Operations Research, 16 (1), 195{207.
Russell, S., & Norvig, P. (1995). Artificial Intelligence: Modern Approach. Prentice Hall,
Englewood Cliffs, NJ.
Sacerdoti, E. D. (1974). Planning hierarchy abstraction spaces. Artificial Intelligence,
5, 115{135.
Sacerdoti, E. D. (1975). nonlinear nature plans. Proceedings Fourth
International Joint Conference Artificial Intelligence, pp. 206{214.
Schoppers, M. J. (1987). Universal plans reactive robots unpredictable environments.
Proceedings Tenth International Joint Conference Artificial Intelligence,
pp. 1039{1046 Milan, Italy.
Schwartz, A. (1993). reinforcement learning method maximizing undiscounted rewards. Proceedings Tenth International Conference Machine Learning,
pp. 298{305 Amherst, MA.
Schweitzer, P. L., Puterman, M. L., & Kindle, K. W. (1985). Iterative aggregationdisaggregation procedures discounted semi-Markov reward processes. Operations
Research, 33, 589{605.
Shachter, R. D. (1986). Evaluating uence diagrams. Operations Research, 33 (6), 871{
882.
Shimony, S. E. (1993). role relevance explanation I: Irrelevance statistical
independence. International Journal Approximate Reasoning, 8 (4), 281{324.
92

fiDecision-Theoretic Planning: Structural Assumptions

Simmons, R., & Koenig, S. (1995). Probabilistic robot navigation partially observable
environments. Proceedings Fourteenth International Joint Conference
Artificial Intelligence, pp. 1080{1087 Montreal, Canada.
Singh, S. P., & Cohn, D. (1998). dynamically merge Markov decision processes.
Advances Neural Information Processing Systems 10, pp. 1057{1063. MIT Press,
Cambridge.
Singh, S. P., Jaakkola, T., & Jordan, M. I. (1994). Reinforcement learning soft state
aggregation. Hanson, S. J., Cowan, J. D., & Giles, C. L. (Eds.), Advances Neural
Information Processing Systems 7. Morgan-Kaufmann, San Mateo.
Smallwood, R. D., & Sondik, E. J. (1973). optimal control partially observable
Markov processes finite horizon. Operations Research, 21, 1071{1088.
Smith, D., & Peot, M. (1993). Postponing threats partial-order planning. Proceedings
Eleventh National Conference Artificial Intelligence, pp. 500{506 Washington, DC.
Sondik, E. J. (1978). optimal control partially observable Markov processes
infinite horizon: Discounted costs. Operations Research, 26, 282{304.
Stone, P., & Veloso, M. (1999). Team-partitioned, opaque-transition reinforcement learning.
Asada, M. (Ed.), RoboCup-98: Robot Soccer World Cup II. Springer Verlag, Berlin.
Sutton, R. S. (1995). TD models: Modeling world mixture time scales.
Proceedings Twelfth International Conference Machine Learning, pp. 531{
539 Lake Tahoe, NV.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press,
Cambridge, MA.
Tash, J., & Russell, S. (1994). Control strategies stochastic planner. Proceedings
Twelfth National Conference Artificial Intelligence, pp. 1079{1085 Seattle,
WA.
Tatman, J. A., & Shachter, R. D. (1990). Dynamic programming uence diagrams.
IEEE Transactions Systems, Man, Cybernetics, 20 (2), 365{379.
Tesauro, G. J. (1994). TD-Gammon, self-teaching backgammon program, achieves masterlevel play. Neural Computation, 6, 215{219.
Thrun, S., Fox, D., & Burgard, W. (1998). probabilistic approach concurrent mapping
localization mobile robots. Machine Learning, 31, 29{53.
Thrun, S., & Schwartz, A. (1995). Finding structure reinforcement learning. Tesauro,
G., Touretzky, D., & Leen, T. (Eds.), Advances Neural Information Processing
Systems 7 Cambridge, MA. MIT Press.
Warren, D. (1976). Generating conditional plans programs. Proceedings AISB
Summer Conference, pp. 344{354 University Edinburgh.
93

fiBoutilier, Dean, & Hanks

Watkins, C. J. C. H., & Dayan, P. (1992). Q-learning. Machine Learning, 8, 279{292.
Weld, D. S. (1994). introduction least commitment planning. AI Magazine, Winter
1994, 27{61.
White III, C. C., & Scherer, W. T. (1989). Solutions procedures partially observed
Markov decision processes. Operations Research, 37 (5), 791{797.
Williamson, M. (1996). value-directed approach planning. Ph.D. thesis 96{06{03,
University Washington, Department Computer Science Engineering.
Williamson, M., & Hanks, S. (1994). Optimal planning goal-directed utility model.
Proceedings Second International Conference AI Planning Systems, pp.
176{180 Chicago, IL.
Winston, P. H. (1992). Artificial Intelligence, Third Edition. Addison-Wesley, Reading,
Massachusetts.
Yang, Q. (1998). Intelligent Planning : Decomposition Abstraction Based Approach.
Springer Verlag.
Zhang, N. L., & Liu, W. (1997). model approximation scheme planning partially
observable stochastic domains. Journal Artificial Intelligence Research, 7, 199{230.
Zhang, N. L., & Poole, D. (1996). Exploiting causal independence Bayesian network
inference. Journal Artificial Intelligence Research, 5, 301{328.

94

fiJournal Artificial Intelligence Research 11 (1999) 335{360

Submitted 8/98; published 11/99

Committee-Based Sample Selection
Probabilistic Classifiers
Shlomo Argamon-Engelson

Department Computer Science
Jerusalem College Technology, Machon Lev
P.O.B. 16031
Jerusalem 91160, Israel

argamon@mail.jct.ac.il

Ido Dagan

Department Mathematics Computer Science
Bar-Ilan University
52900 Ramat Gan, Israel

dagan@cs.biu.ac.il

Abstract
many real-world learning tasks expensive acquire sucient number labeled
examples training. paper investigates methods reducing annotation cost
sample selection. approach, training learning program examines many
unlabeled examples selects labeling informative
stage. avoids redundantly labeling examples contribute little new information.
work follows previous research Query Committee, extends
committee-based paradigm context probabilistic classification. describe
family empirical methods committee-based sample selection probabilistic classification models, evaluate informativeness example measuring degree
disagreement several model variants. variants (the committee) drawn
randomly probability distribution conditioned training set labeled far.
method applied real-world natural language processing task stochastic part-of-speech tagging. find variants method achieve significant
reduction annotation cost, although computational eciency differs. particular,
simplest variant, two member committee parameters tune, gives excellent
results. also show sample selection yields significant reduction size
model used tagger.

1. Introduction
Algorithms supervised concept learning build classifiers concept based given
set labeled examples. many real-world concept learning tasks, however, acquiring
labeled training examples expensive. Hence, objective develop automated
methods reduce training cost within framework active learning,
learner control choice examples labeled used
training.
c 1999 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiArgamon & Dagan

two main types active learning. first uses membership queries,
learner constructs examples asks teacher label (Angluin, 1988; MacKay,
1992b; Plutowski & White, 1993). approach provides proven computational
advantages (Angluin, 1987), always applicable since always possible
construct meaningful informative unlabeled examples training. diculty may
overcome large set unlabeled training data available. case second
type active learning, sample selection, often applied: learner examines many
unlabeled examples, selects informative ones learning (Seung, Opper,
& Sompolinsky, 1992; Freund, Seung, Shamir, & Tishby, 1997; Cohn, Atlas, & Ladner,
1994; Lewis & Catlett, 1994; Lewis & Gale, 1994).
paper, address problem sample selection training probabilistic
classifier. Classification framework performed probability-based model which,
given input example, assigns score possible classification selects
highest score.
research follows theoretical work sample selection Query Committee
(QBC) paradigm (Seung et al., 1992; Freund et al., 1997). propose novel empirical
scheme applying QBC paradigm probabilistic classification models (allowing label
noise), addressed original QBC framework (see Section 2.2).
committee-based selection scheme, learner receives stream unlabeled examples
input decides whether ask label not. end,
learner constructs `committee' (two more) classifiers based statistics
current training set. committee member classifies candidate example,
learner measures degree disagreement among committee members. example
selected labeling depending degree disagreement, according selection
protocol.
previous work (Dagan & Engelson, 1995; Engelson & Dagan, 1996b) presented
particular selection protocol probabilistic concepts. paper extends previous
work mainly generalizing selection scheme comparing variety different
selection protocols (a preliminary version appeared Engelson & Dagan, 1996a).

1.1 Application Natural Language Processing
Much early work sample selection either theoretical nature,
tested toy problems. We, however, motivated complex, real-world problems
area statistical natural language text processing. work addresses
task part-of-speech tagging, core task statistical natural language processing
(NLP). work sample selection natural language tasks mainly focused
text categorization problems, works Lewis Catlett (1994), Liere
Tadepalli (1997), McCallum Nigam (1998).
statistical NLP, probabilistic classifiers often used select preferred analysis
linguistic structure text, syntactic structure (Black, Jelinek, Lafferty,
Magerman, Mercer, & Roukos, 1993), word categories (Church, 1988), word senses (Gale,
336

fiCommittee-Based Sample Selection Probabilistic Classifiers

Church, & Yarowsky, 1993). parameters classification model estimated
training corpus (a collection text).
common case supervised training, learner uses corpus
sentence manually annotated correct analysis. Manual annotation typically
expensive. consequence, large annotated corpora exist, mainly English language, covering genres text. situation makes dicult apply
supervised learning methods languages English, adapt systems different genres text. Furthermore, infeasible many cases develop new supervised
methods require annotations different currently available.
cases, manual annotation avoided altogether, using self-organized methods, shown part-of-speech tagging English Kupiec (1992). Even
Kupiec's tagger, though, manual (and somewhat unprincipled) biasing initial model
necessary achieve satisfactory convergence. Elworthy (1994) Merialdo (1991)
investigated effect self-converging re-estimation part-of-speech tagging
found initial manual training needed. generally, supervised
training provided, better results. fact, fully unsupervised methods
applicable many NLP tasks, perhaps even part-of-speech tagging
languages. Sample selection appropriate way reduce cost annotating corpora,
easy obtain large volumes raw text smaller subsets selected
annotation.
applied committee-based selection learning Hidden Markov Models (HMMs)
part-of-speech tagging English sentences. Part-of-speech tagging task labeling
word sentence appropriate part speech (for example, labeling
occurrence word `hand' noun verb). task non-trivial since determining
word's part speech depends linguistic context. HMMs used extensively
task (e.g., Church, 1988; Merialdo, 1991), cases trained corpora
manually annotated correct part speech word.
experiments part-of-speech tagging, described Section 6.5, show using committeebased selection results substantially faster learning rates, enabling learner achieve
given level accuracy using far fewer training examples sequential training using
text.

2. Background
objective sample selection select examples informative future. might determine informativeness example? One
approach derive explicit measure expected amount information gained
using example (Cohn, Ghahramani, & Jordan, 1995; MacKay, 1992b, 1992a).
example, MacKay (1992b) assesses informativeness example, neural network
learning task, expected decrease overall variance model's prediction,
training example. Explicit measures appealing, since attempt
give precise characterization information content example. Also, membership querying, explicit formulation information content sometimes enables finding
337

fiArgamon & Dagan

informative examples analytically, saving cost searching example space.
use explicit methods may limited, however, since explicit measures generally
(a) model-specific, (b) complex, often requiring various approximations practical,
(c) depend accuracy current hypothesis given step.
alternative measuring informativeness example explicitly measure
implicitly, quantifying amount uncertainty classification example
given current training data. informativeness example evaluated respect
models derived training data stage learning. One approach use
single model based training data seen far. approach taken Lewis
Gale (1994), training binary classifier. select training examples
whose classification probability closest 0.5, i.e, examples current
best model uncertain.
order better evaluate classification uncertainty respect entire space
possible models, one may instead measure classification disagreement among sample
set possible models (a committee). Using entire model space enables measuring
degree training entails single (best) classification example.
hand, referring single model measures degree model
certain classification. example, classifier sucient training predicting ips coin heads probability 0.55 always predict heads, hence
make mistakes 45% time. However, although classifier quite uncertain
correctness classification, additional training improve accuracy.
two main approaches generating committee order evaluate example
uncertainty: version space approach random sampling approach. version
space approach, pursued Cohn et al. (1994) seeks choose committee members
border space models allowed training data (the version space,
Mitchell, 1982). Thus models chosen committee far
possible consistent training data. ensures models
disagree example whenever training example would restrict version space.
version space approach dicult apply since finding models edge
version space non-trivial general. Furthermore, approach directly
applicable case probabilistic classification models, almost models
possible, though equally probable, given training. alternative random sampling, exemplified Query Committee algorithm (Seung et al., 1992; Freund
et al., 1997), inspired paper. approach, models sampled randomly
set possible models, according probability models given
training data. work applies random sampling approach probabilistic classifiers
computing approximation posterior model distribution given training data,
generating committee members distribution. McCallum Nigam (1998)
use similar approach sample selection text categorization using naive Bayes classifier. primary difference skew example selection using density-weighted
sampling, documents similar many documents training
set selected labeling higher probability.

338

fiCommittee-Based Sample Selection Probabilistic Classifiers

Matan (1995) presents two methods random sampling. first method,
trains committee members different subsets training data. second method,
neural network models, Matan generates committee members backpropagation training using different initial weights networks reach different local minima.
similar approach taken Liere Tadepalli (1997), applied committee-based
selection approach text categorization using Winnow learning algorithm (Littlestone,
1988) learns linear classifiers. represented model space set classifiers (the model set). classifier model set learns independently labeled
examples, initialized different initial hypothesis (thus point
set gives selection possible hypotheses given training data). Labeling decisions
performed based two models chosen random model set. models
disagree document's class, document's label requested, models
space updated.

2.1 Query Committee
mentioned above, paper follows theoretical work sample selection Query
Committee (QBC) paradigm (Seung et al., 1992; Freund et al., 1997). method
proposed learning binary (non-probabilistic) concepts cases exists prior
probability distribution measure concept class. QBC selects `informative' training
examples stream unlabeled examples. example selected learner
queries teacher correct label adds training set. examples
selected training, restrict set consistent concepts, i.e, set concepts
label training examples correctly (the version space).
simple version QBC, analyzed Freund et al. (1997) (see also
summary Freund, 1994), uses following selection algorithm:
1. Draw unlabeled input example random probability distribution example space.
2. Select random two hypotheses according prior probability distribution concept class, restricted set consistent concepts.
3. Select example training two hypotheses disagree classification.
Freund et al. prove that, assumptions, algorithm achieves exponential
reduction number labeled examples required achieve desired classification
accuracy, compared random selection training examples. speedup achieved
algorithm tends select examples split version space two parts
similar size. One parts eliminated version space example
correct label added training set.

2.2 Selection Probabilistic Classifiers
address problem sample selection training probabilistic classifier. Classification framework performed probabilistic model which, given input
339

fiArgamon & Dagan

example, assigns probability (or probability-based score) possible classification
selects best classification. Probabilistic classifiers fall within framework
addressed theoretical QBC work. Training probabilistic classifier involves estimating values model parameters determine probability estimate possible
classification example. expect cases optimal classifier
assign highest probability correct class, guaranteed always occur.
Accordingly, notion consistent hypothesis generally applicable probabilistic
classifiers. Thus, posterior distribution classifiers given training data cannot
defined restriction prior set consistent hypotheses. Rather, within
Bayesian framework, posterior distribution defined statistics training
set, assigning higher probability classifiers likely given statistics.
discuss desired properties examples selected training. Generally speaking, training example contributes data several statistics, turn
determine estimates several parameter values. informative example therefore
one whose contribution statistics leads useful improvement parameter estimates. Assuming existence optimal classification model given concept
(such maximum likelihood model), identify three properties parameters
acquiring additional statistics beneficial:
1. current estimate parameter uncertain due insucient statistics
training set. uncertain estimate likely far true value
parameter cause incorrect classification. Additional statistics would bring
estimate closer true value.
2. Classification sensitive changes current estimate parameter. Otherwise, acquiring additional statistics unlikely affect classification therefore
beneficial.
3. parameter takes part calculating class probabilities large proportion
examples. Parameters relevant classifying examples, determined probability distribution input examples, low utility future
estimation.
committee-based selection scheme, describe below, tends select
examples affect parameters three properties. Property 1 addressed
randomly picking parameter values committee members posterior distribution
parameter estimates (given current statistics). statistics parameter
insucient variance posterior distribution estimates large, hence
large differences values parameter picked different committee
members. Note property 1 addressed uncertainty classification
judged relative single model (as in, e.g., Lewis & Gale, 1994). approach
captures uncertainty respect given parameter values, sense property 2,
model uncertainty choice values first place (the use
single model criticized Cohn et al., 1994).
Property 2 addressed selecting examples committee members highly disagree classification. Thus, algorithm tends acquire statistics uncertainty
340

fiCommittee-Based Sample Selection Probabilistic Classifiers

parameter estimates entails uncertainty actual classification (this analogous splitting
version space QBC). Finally, property 3 addressed independently examining
input examples drawn input distribution. way, implicitly
model expected utility statistics classifying future examples.

2.3 Paper Outline
following section defines basic concepts notation use rest
paper. Section 4 presents general selection scheme along variant selection
algorithms. next two sections demonstrate effectiveness sample selection
scheme. Section 5 presents results artificial \colorful coin ipper" problem, providing
simple illustration operation proposed system. Section 6 presents results
task stochastic part-of-speech tagging, demonstrating usefulness committeebased sample selection real world.

3. Definitions
concern paper minimize number labeled examples needed
learn classifier accurately classifies input examples e classes c 2 C , C
known set possible classes. learning, stream unlabeled examples
supplied free, examples drawn unknown probability distribution.
cost, however, learning algorithm obtain true label given example.
objective reduce cost much possible, still learning accurate
classifier.
address specific case probabilistic classifiers, classification done
basis score function, FM (c; e), assigns score possible class
input example. classifier assigns input example class highest score.
FM determined probabilistic model . many applications, FM conditional
probability function, PM (cje), specifying probability class given example.
Alternatively, score functions denote likelihood class may used
(such odds ratio). particular type model used classification determines
specific form score, function features example.
probabilistic model , thus score function FM , defined set parameters, fffi g, giving probabilities various possible events. example, model
part-of-speech tagging contains parameters probability particular word
verb noun. training, values parameters estimated
set statistics, , extracted training set labeled examples. particular model
denoted = faig, ai specific value corresponding ffi .

4. Committee-Based Sample Selection
section describes algorithms apply committee-based approach evaluating classification uncertainty input example. learning algorithm evaluates
341

fiArgamon & Dagan

example giving committee containing several versions, copies, classifier, `consistent' training data seen far. greater agreement
committee members classification example, greater certainty
classification. training data entails specific classification high
certainty, (in probabilistic sense) versions classifier consistent
data produce classification. example selected labeling, therefore,
committee members disagree appropriate classification.

4.1 Generating Committee
generate committee k members, randomly choose k models according
posterior distribution P (M jS ) possible models given current training statistics.
sampling performed depends form distribution, turn
depends form model. Thus implementing committee-based selection
particular problem, appropriate sampling procedure must devised. illustration
committee generation, rest section describes sampling process models
consisting independent binomial parameters multinomial parameter groups.
Consider first model containing single binomial parameter ff (the probability
success), estimated value a. statistics model given N ,
number trials, x, number successes trials.
Given N x, `best' model parameter value estimated several
estimation methods. example, maximum likelihood estimate (MLE) ff = Nx ,
giving model = fff = Nx g. generating committee models, however,
interested `best' model, rather sampling distribution models given
statistics. example, need sample posterior density estimates
ff, namely p(ff = ajS ). binomial case, density beta distribution (Johnson,
1970). Sampling distribution yields set estimates scattered around Nx (assuming
uniform prior), variance estimates gets smaller N gets larger.
estimate participates different member committee. Thus, statistics
estimating parameter, closer estimates used different models
committee.
consider model consisting single group interdependent parameters defining multinomial. case, posterior Dirichlet distribution (Johnson, 1972).
Committee members generated sampling joint distribution, giving values
model parameters.
models consisting set independent binomials multinomials, sampling
P (M jS ) amounts sampling parameters independently. models
complex dependencies among parameters sampling may dicult. practice,
though, may possible make enough independence assumptions make sampling
feasible.
Sampling posterior generates committee members whose parameter estimates differ
based low training counts tend agree based high
counts. classification example relies parameters whose estimates com342

fiCommittee-Based Sample Selection Probabilistic Classifiers

unlabeled input example e:
1. Draw 2 models randomly P (M jS ), statistics acquired
previously labeled examples;
2. Classify e model, giving classifications c1 c2;
3. c1 6= c2, select e annotation;
4. e selected, get correct label update accordingly.
Figure 1: two member sequential selection algorithm.
mittee members differ, differences affect classification, example would
selected learning. leads selecting examples contribute statistics
currently unreliable estimates also effect classification. Thus address
Properties 1 2 discussed Section 2.2.

4.2 Selection Algorithms
Within committee-based paradigm exist different methods selecting informative examples. Previous research sample selection used either sequential selection
(Seung et al., 1992; Freund et al., 1997; Dagan & Engelson, 1995), batch selection (Lewis
& Catlett, 1994; Lewis & Gale, 1994). present general algorithms sequential batch committee-based selection. cases, assume
selection algorithm applied small amount labeled initial training supplied, order
initialize training statistics.
4.2.1 Two Member Sequential Selection

Sequential selection examines unlabeled examples supplied, one one,
estimates expected information gain. examples determined suciently
informative selected training. simply, choose committee size two
posterior distribution models, select example two models
disagree classification. gives parameter-free, two member sequential selection
algorithm, shown Figure 1. basic algorithm parameters.
4.2.2 General Sequential Selection

general selection algorithm results from:

Using larger number k committee members, order evaluate example informativeness precisely,

refined example selection criteria,
343

fiArgamon & Dagan

unlabeled input example e:
1. Draw k models fMi g randomly P (M jS ) (possibly using temperature t);
2. Classify e model Mi giving classifications fci g;
3. Measure disagreement D(e) based fci g;
4. Decide whether select e annotation, based value
D(e);
5. e selected, get correct label update accordingly.
Figure 2: general sequential selection algorithm.

Tuning frequency selection replacing P (M jS ) distribution
different variance. effect adjusting variability among committee
members chosen. many cases (eg., HMMs, described Section 6 below)
implemented parameter (called temperature), used multiplier
variance posterior parameter distribution.

gives general sequential selection algorithm, shown Figure 2.
easy see two member sequential selection special case general sequential selection. order instantiate general algorithm larger committees, need
fix general measure D(e) disagreement (step 3), decision method selecting
examples according disagreement (step 4).
measure disagreement entropy distribution classifications `voted for'
committee members. vote entropy natural measure quantifying
uniformity classes assigned example different committee members1 .
normalize entropy bound maximum possible value (log min(k; jcj)),
giving value 0 1. Denoting number committee members assigning
class c input example e V (c; e), normalized vote entropy is:
X V (c; e) V (c; e)
1
D(e) = ,
log min(k; jC j) c k log k
Normalized vote entropy value one committee members disagree,
value zero agree, taking intermediate values cases partial agreement.
consider two alternatives selection criterion (step 4). simplest
thresholded selection, example selected annotation normalized vote
entropy exceeds threshold . Another alternative randomized selection,
example selected annotation based ip coin biased according
vote entropy|a higher vote entropy corresponding higher probability selection.
1. McCallum Nigam (1998) suggested alternative measure, KL-divergence mean
(Pereira, Tishby, & Lee, 1993). clear whether measure advantage simpler
entropy function.

344

fiCommittee-Based Sample Selection Probabilistic Classifiers

batch B N examples:
1. example e B :
(a) Draw k models randomly P (M jS );
(b) Classify e model, giving classifications fcig;
(c) Measure disagreement D(e) e based fcig;
2. Select annotation examples highest D(e);
3. Update statistics selected examples.
Figure 3: batch selection algorithm.
use simple model selection probability linear function normalized vote
entropy: P (e) = gD(e), calling g entropy gain2 .
4.2.3 Batch Selection

alternative sequential selection batch selection. Rather evaluating examples
individually informativeness large batch N examples examined,
best selected annotation. batch selection algorithm given Figure 3.
procedure repeated sequentially successive batches N examples, returning
start corpus end. N equal size corpus, batch selection
selects globally best examples corpus stage (as Lewis & Catlett, 1994).
Batch selection certain theoretical drawbacks (Freund et al., 1997), particularly
consider distribution input examples. However, shown McCallum
Nigam (1998), distribution input examples modeled taken
account selection. combining disagreement measure
measure example density, produces good results batch selection (this work
discussed detail Section 7.2). separate diculty batch selection
computational disadvantage must look large number examples
selecting any. batch size decreased, batch selection behaves similarly
sequential selection.

5. Example: Colorful Coin Flipper
illustrative example learning task, define colorful coin- ipper (CCF)
machine contains infinite number coins various colors. machine chooses
coins ip, one one, color coin fixed (unknown) probability
chosen. coin ipped, comes heads probability determined solely
color. ips coin, machine tells learner color coin chosen
2. selection method used (Dagan & Engelson, 1995) randomized sequential selection using
linear selection probability model, parameters k, g.

345

fiArgamon & Dagan

ip. order know outcome ip, however, learner must pay machine.
training, learner may choose colors coins whose outcomes examine.
objective selective sampling choose minimize training cost (number
ips examined) required attain given prediction accuracy ip outcomes.
case CCF, example e coin ip, characterized color,
class c either heads tails. Note require ips given color always
class. Therefore best hope classify according
likely class color.
CCF, define model whose parameters heads probabilities
coins particular color. So, CCF three colors, one possible model would
= fr = 0:8; g = 0:66; b = 0:2g, giving probabilities heads red, green, blue
coins, respectively. coin given color classified `heads' score (given
directly appropriate model parameter) > 12 , `tails' otherwise.

5.1 Implementation Sample Selection
Training model CCF amounts counting proportion heads color,
providing estimates heads probabilities. complete training every coin ip training
sequence examined added counts. sample selection seek label
count training ips colors additional counts likely improve
model's accuracy. Useful colors train either training
examples far seen, whose current probability estimates near 0.5
(cf. Section 2.2).
Recall sample selection build committee sampling models P (M jS ).
case CCF, model parameters ffi (the heads probabilities different
colors) independent, sampling P (M jS ) amounts sampling independently
parameters.
form posterior distribution P (ffi = ai jS ) given beta distribution, found technically easier use normal approximation, found
satisfactory practice. Let Ni number coin ips color seen far, ni
number ips came heads. approximate P (ffi = ai jS ) truncated normal distribution (restricted [0,1]), estimated mean = Nn variance
i2 = (1N, ). approximation made easy also incorporate `temperature' parameter (as Section 4.2.2), used multiplier variance estimate i2 . Thus,
actually approximate P (ffi = aijS ) truncated normal distribution mean
variance i2 t. Sampling distribution done using algorithm given Press,
Flannery, Teukolsky, Vetterling (1988) sampling normal distribution.










5.2 Vote Entropy
CCF useful illustrate importance determining classification uncertainty
using vote entropy committee models rather using entropy
class distribution given single model (as discussed Section 2). Consider CCF
346

fiCommittee-Based Sample Selection Probabilistic Classifiers

Model
0
1
2
3

Red
0.55 (heads)
0.55 (heads)
0.60 (heads)
0.60 (heads)

Blue
0.45 (tail)
0.45 (tail)
0.55 (heads)
0.55 (heads)
(a)

Green
0.48 (heads)
0.75 (tail)
0.85 (tail)
0.95 (tail)

Color D(e) ACDE
Red
0.0 0.98
Blue
1.0 0.99
Green 0.81 0.68
(b)

Figure 4: (a) committee CCF models. (b) resultant vote entropy color.
CCF results 50 colors

CCF results 100 colors

200
PTM
Committee-Based Sampling
Complete Training

PTM
Committee-Based Sampling
Complete Training

200

150

Selected training

Selected training

150

100

100

50
50

0
0.5

0
0.55

0.6

0.65
Desired accuracy

0.7

0.75

0.8

0.5

(a)

0.55

0.6

0.65
Desired accuracy

0.7

0.75

0.8

(b)

Figure 5: CCF results random CCFs 50 100 different coin colors. Results
averaged 4 different CCFs, comparing complete training two
member sample selection. figures show amount training required
desired classification accuracy: (a) 50 colors, (b) 100 colors.

three coin colors, red, blue, green. Suppose 4-member committee Figure 4(a)
generated. committee, estimate color vote entropy D(e), well
average class distribution entropies given individual models
(ACDE), given Figure 4(b).
compare entropies red blue, example, see entropies
expected class probability distribution quite high (since estimated
class probabilities near 0.5). However, consider vote entropies (over
assigned classes), blue maximal entropy, since range possible models straddles
class boundary (0.5), red minimal entropy, since range possible models
straddle class boundary. is, quite certain optimal classification
red \heads". also see green higher vote entropy red, although
average class distribution entropy lower. shows importance using vote entropy
selection.
347

fiArgamon & Dagan

CCF frequency selection
1
50 color CCF
100 color CCF

0.9
0.8

Selection frequency

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

20

40

60

80

100
120
Selected training

140

160

180

200

Figure 6: Frequency selection vs. amount selected training CCFs 50 100
colors, averaged 4 different CCFs.

5.3 Results
simulated sample selection simple CCF model order illustrate
properties. following, generated random CCFs fixed number coins
randomly generating occurrence probabilities heads probabilities coin color.
generated learning curves complete training, input examples, two
member sample selection, using 50 coin- ips initial training. complete training
sample selection run coin- ip sequences. Accuracy measured
computing expected accuracy (assuming infinite test set) MLE model
generated selected training. figures also show accuracy theoretical
perfectly trained model (PTM) knows parameters perfectly.
Figure 5 summarizes average results 4 comparison runs complete vs. sample
selection CCFs 50 100 coins. Figures 5(a) (b), compare amount
selected training required reach given desired accuracy. see cases
soon sample selection starts operating, eciency higher complete training,
gap increases size greater accuracy desired. Figure 6, examine
cumulative frequency selection (ratio number selected examples
total number examples seen) learning progresses. see exponential decrease
frequency selection, expected case QBC non-probabilistic models
(analyzed Seung et al., 1992; Freund et al., 1997).

6. Application: Stochastic Part-Of-Speech Tagging
applied committee-based selection real-world task learning Hidden Markov
Models (HMMs) part-of-speech tagging English sentences. Part-of-speech tagging
task labeling word sentence appropriate part speech (for
example, labeling occurrence word `hand' noun verb). task nontrivial since determining word's part speech depends linguistic context. HMMs
348

fiCommittee-Based Sample Selection Probabilistic Classifiers

used extensively task (e.g., Church, 1988; Merialdo, 1991), cases
trained corpora manually annotated correct part speech
word.

6.1 HMMs Part-Of-Speech Tagging
first-order Hidden Markov Model (HMM) probabilistic finite-state string generator
(Rabiner, 1989), defined set states Q = fqi g, set output symbols , set
transition probabilities P (qi !qj ) possible transition states qi qj , set
output probabilities P (ajq) state q output symbol 2 , distinguished
start state q0 . probability string = a1a2 generated HMM
given
!
n
X

P (qi,1 !qi )P (aijqi ) ;
q1 qn 2Qn i=1

sum, paths HMM, joint probability path traversed
output given string. contrast ordinary Markov Models, HMM
known sequence states generated given string (hence term `hidden').
HMMs used widely speech language processing. particular, HMM
used provide classification model sequence elements: need classify
element sequence, encode possible class state HMM. Training
HMM amounts estimating values transition output probabilities.
Then, given sequence classification, assume generated HMM
compute likely state sequence string, using Viterbi algorithm3 (Viterbi,
1967).
HMM used part-of-speech tagging words encoding possible partof-speech tag, (noun, verb, adjective, etc.), HMM state. output probabilities,
P (wjt), give probability producing word w language conditioned
current tag t. transition probabilities, P (t1!t2), give probability generating
word tag t2 given previous word's tag t1 . constitutes weak
syntactic model language. model often termed tag-bigram model4 .
Given input word sequence W = w1 wn , seek likely tag sequence
= t1 tn :
)
arg maxT P (T jW ) = arg maxT PP(T;W
(W )
= arg maxT P (T; W )
3. alternative classification scheme compute likely state individual element
(instead likely state sequence) Forward-Backward algorithm (Rabiner, 1989) (also
called Baum-Welch algorithm Baum, 1972). address alternative,
computationally expensive typically used part-of-speech tagging. possible,
however, apply committee-based selection method also type classification.
4. noted practical implementations part-of-speech tagging often employ tag-trigram
model, probability tag depends last two tags rather last one.
committee-based selection method apply bigram model easily applied also
trigram case.

349

fiArgamon & Dagan

since P (W ) constant. Thus seek maximizes

P (T; W ) =

n

i=1

P (ti,1!ti )P (wijti )

technical convenience, use Bayes' theorem replace P (wijti ) term term
P (t jw )P (w )
, noting P (wi) effect maximization tag sequences
P (t )
therefore omitted (following Church, 1988). parameters part-of-speech model,
then, are: tag probabilities P (ti), transition probabilities P (ti,1!ti ), lexical probabilities
P (tjw).
Supervised training tagger performed using tagged corpus (text collection),
manually labeled correct part-of-speech word. Maximum likelihood estimates (MLEs) parameters easily computed word tag counts
corpus. example, MLE P (t) fraction tag occurrences corpus tag t, whereas P (tjw) ratio count word w
labeled tag total count w. committee-based selection scheme,
counts used also compute posterior distributions parameter estimates,
discussed Section 6.2.
next describe application committee-based selection scheme HMM
classification framework. First discuss sample posterior distributions HMM parameters P (ti !tj ) P (tjw), given training statistics.5
discuss question define example training|an HMM deals (in
principle) infinite strings; substrings make decisions labeling? Finally,
describe measure amount disagreement committee members.








6.2 Posterior Distributions Multinomial Parameters
section, consider select committee members based posterior parameter distributions P (ffi = aijS ) HMM, assuming uniform prior. First note
parameters HMM define set multinomial probability distributions. multinomial corresponds conditioning event values given corresponding
set conditioned events. example, transition probability parameter P (ti !tj )
conditioning event ti conditioned event tj .
Let fui g denote set possible values given multinomial variable (e.g.,
possible tags given word), let = fni g denote set statistics extracted
training set, ni number times value ui appears training
P
set. denote total number appearances multinomial variable N = ni .
parameters whose distributions wish estimate ffi = P (ui ).
maximum likelihood estimate multinomial's distribution parameters,
ffi , ff^i = nN . practice, estimator usually smoothed way compensate
data sparseness. smoothing typically reduces estimates values positive


5. sample model space tag probability parameters, since amount data tag
frequencies large enough make MLEs quite definite.

350

fiCommittee-Based Sample Selection Probabilistic Classifiers

counts gives small positive estimates values zero count. simplicity,
first describe approximation P (ffi = aijS ) unsmoothed estimator6 .
posterior P (ffi = ai jS ) Dirichlet distribution (Johnson, 1972); ease
implementation, used generalization normal approximation described
(Section 5.1) binomial parameters. assume first multinomial collection
independent binomials, corresponds single value ui multinomial;
separately apply constraint parameters binomials sum
1. binomial, sample approximate distribution (possibly
temperature t). Then, generate particular multinomial distribution, renormalize
sampled parameters sum 1.
sample smoothed estimator, first note estimator smoothed
model (interpolating uniform)

;
ff^Si = (1(1,,))Nni++
1 smoothing parameter controlling amount smoothing (in experiments = 0:05), number possible values given multinomial.
sample truncated normal approximation (as Section 5)
smoothed estimate, i.e, mean = ff^Si variance 2 = (1N,) . Normalization
multinomial applied above.
Finally, generate random HMM given statistics , note parameters
P (ti !tj ) P (tjw) independent other. thus independently choose values
HMM's parameters multinomial distribution.

6.3 Examples HMM Training
Typically, concept learning problems formulated set training
examples independent other. training HMM, however,
state/output pair dependent previous state, presented (in principle)
single infinite input string training. order perform sample selection,
must divide infinite string (short) finite strings.
part-of-speech tagging, problem may solved considering sentence
individual example. generally, break text point tagging
unambiguous. particular, common lexicon specifies partsof-speech possible word (i.e, parameters P (tjw) positive).
bigram tagging, use unambiguous words (those one possible part speech)
example boundaries. Similar natural breakpoints occur HMM applications;
example, speech recognition consider different utterances separately.
cases HMM learning, natural breakpoints occur, heuristic
applied, preferring break `almost unambiguous' points input.
6. implementation smooth MLE interpolation uniform probability distribution,
following Merialdo (1991). Adaptation P (ffi = ai ) smoothed version estimator given
below.
j

351

fiArgamon & Dagan

6.4 Quantifying Disagreement
Recall selection algorithms decide whether select example based
much committee members disagree labeling. discussed Section 4.2.2,
suggest use vote entropy measuring classification disagreement committee members. idea supported fact found empirically
average normalized vote entropy words tagger (after training) classified correctly 0.25, whereas average entropy incorrectly classified words
0.66. demonstrates vote entropy useful measure classification uncertainty
(likelihood error) based training data.
bigram tagging, example consists sequence several words. implementation, measured vote entropy separately word sequence, use
average vote entropy sequence measurement disagreement
example. use average entropy rather entropy entire sequence,
number committee members small respect total number
possible tag sequences.

6.5 Results
present results applying committee-based sample selection bigram part-ofspeech tagging, comparing complete training examples corpus. Evaluation performed using University Pennsylvania tagged corpus ACL/DCI
CD-ROM I. ease implementation, used complete (closed) lexicon contains
words corpus.7 Approximately 63% word occurrences corpus
ambiguous lexicon (have one possible part-of-speech).
committee-based selection algorithm initialized using first 1,000 words
corpus, examined following examples corpus possible
labeling. training set consisted first million words corpus, sentence
ordering randomized compensate inhomogeneity corpus composition. test set
separate portion corpus consisting 20,000 words, starting first
1,000,000.
compared amount training required different selection methods achieve
given tagging accuracy test set, amount training tagging
accuracy measured ambiguous words.8
6.5.1 Labeling Efficiency
7. use lexicon provided Brill's part-of-speech tagger (Brill, 1992). actual application
complete lexicon would available, results using complete lexicon valid, evaluation
complete training committee-based selection comparative.
8. work tagging measured accuracy words, ambiguous ones. Complete
training system 1,000,000 words gave us accuracy 93.5% ambiguous words,
corresponds accuracy 95.9% words test set, comparable published results
bigram tagging.

352

fiCommittee-Based Sample Selection Probabilistic Classifiers

40000
Batch selection (m=5; N=100)
Thresholded selection (th=0.3)
Randomized selection (g=0.5)
Two member selection
Complete training

35000

Selected training

30000
25000
20000
15000
10000
5000
0
0.85

0.86

0.87

0.88

0.89
Accuracy

0.9

0.91

0.92

0.93

Figure 7: Labeled training versus classification accuracy. batch, random, thresholded runs, k = 5 = 50.

Figure 7 presents comparison results several selection methods. reported parameter settings best found selection method manual tuning.
Figure 7 shows advantage sample selection gives regard annotation cost.
example, complete training requires annotated examples containing 98,000 ambiguous
words achieve 92.6% accuracy, selection methods require 18,000{25,000
ambiguous words achieve accuracy. also find that, first approximation,
methods considered give similar results. Thus, seems refined choice
selection method crucial achieving large reductions annotation cost.
6.5.2 Computational Efficiency

Figure 8 plots classification accuracy versus number words examined, instead
selected. Complete training clearly ecient terms, learns
examples examined. selective methods similar, though two member selection seems
require somewhat fewer examples examination methods. Furthermore,
since two committee members used method computationally ecient
evaluating examined example.
6.5.3 Model Size

ability committee-based selection focus informative parts
training corpus analyzed Figure 9. examined number lexical bigram
353

fiArgamon & Dagan

400000
Batch selection (m=5; N=100)
Thresholded selection (th=0.3)
Randomized selection (g=0.5)
Two member selection
Complete training

350000

Examined training

300000
250000
200000
150000
100000
50000
0
0.85

0.86

0.87

0.88

0.89
Accuracy

0.9

0.91

0.92

0.93

Figure 8: Examined training (both labeled unlabeled) versus classification accuracy.
batch, random, thresholded runs, k = 5 = 50.

20000

1600
Two member selection
Complete training

18000

Two member selection
Complete training

1400

14000

Bigram model size

Lexical model size

16000

12000
10000
8000
6000

1200
1000
800
600

4000
400

2000
0
0.85

0.86

0.87

0.88

0.89
Accuracy

0.9

0.91

0.92

200
0.85

0.93

(a)

0.86

0.87

0.88

0.89
0.9
Accuracy

0.91

0.92

0.93

0.94

(b)

Figure 9: Numbers frequency counts > 0, plotted (y-axis) versus classification accuracy
(x-axis). (a) Lexical counts (freq(t; w)) (b) Bigram counts (freq(t1 !t2 )).

354

fiCommittee-Based Sample Selection Probabilistic Classifiers

1
Two member selection
Batch selection (m=5; N=50)
Batch selection (m=5; N=100)
Batch selection (m=5; N=500)
Batch selection (m=5; N=1000)

0.98

Accuracy

0.96
0.94
0.92
0.9
0.88
0.86
0

100000

200000

300000 400000
Examined training

500000

600000

Figure 10: Evaluating batch selection, = 5. Classification accuracy versus number
words examined corpus different batch sizes.
counts stored (i.e, non-zero) training, using two member selection
algorithm complete training. graphs show, committee-based selection achieves
accuracy complete training fewer lexical bigram counts. achieve
92% accuracy, two member selection requires 6200 lexical counts 750 bigram counts,
compared 15,800 lexical counts 1100 bigram counts complete training.
implies many counts data needed correct tagging, since smoothing
estimates probabilities equally well.9 Committee-based selection ignores counts,
focusing efforts parameters improve model's performance. behavior
additional practical advantage reducing size model significantly. Also,
average count lower model constructed selective training fully trained
model, suggesting selection method tends avoid using examples increase
counts already known parameters.
6.5.4 Batch Selection

investigated properties batch selection, varying batch size 50 1000
examples, fixing number examples selected batch 5. found
terms number labeled examples required attain given accuracy, selection
different batch sizes performed similarly. means increased batch size
9. mentioned above, tagging phase smooth MLE estimates interpolation uniform
probability distribution, following Merialdo (1994).

355

fiArgamon & Dagan

seem improve effectiveness selection. hand, see
decrease performance increased batch size, might expected due
poorer modeling input distribution (as noted Section 2.2). may indicate
even batch size 1000 (selecting 1/200 examples seen) small enough
let us model input distribution reasonable accuracy. However, similarity
performance different batch sizes sequential selection
hold respect amount unlabeled training used. Figure 10 shows accuracy
attained function amount unlabeled training used. see quite clearly that,
expected, using larger batch sizes required examining far larger number unlabeled
training examples order obtain accuracy.

7. Discussion
7.1 Committee-Based Selection Monte-Carlo Technique
view committee-based selection Monte-Carlo method estimating probability distribution classes assigned example possible models, given
training data. proportion votes among committee members class c example e sample-based estimate probability, model chosen randomly
posterior model distribution, assigning c e. is, proportion votes
c given e, V (kc;e) , Monte-Carlo estimate
Z

P (cje; ) = TM (cje)P (M jS )dM


ranges possible models (vectors parameter values) model space M,
P (M jS ) posterior probability density model given statistics , TM (cje) = 1
c highest probability class e based (i.e, c = arg maxc PM (ci je),
PM (cje) class probability distribution e given model ), 0 otherwise. Vote
entropy, defined Section 4.2.2, thus approximation entropy P .
entropy direct measure uncertainty example classification possible models.
Note measure entropy final classes assigned example possible
models (i.e, TM ), class probabilities given single model (i.e, PM ),
illustrated CCF example Section 5.2. Measuring entropy PM (say, looking
expected probability models) would properly address properties 1 2
discussed Section 2.2.


7.2 Batch Selection
Property 3 discussed Section 2.2 states parameters affect examples
low overall utility, atypical examples useful learning. sequential
selection, property addressed independently examining input examples
drawn input distribution. way, implicitly model distribution model
parameters used classifying input examples. modeling, however, inherent
basic form batch selection, lead less effective (Freund et al.,
1997).
356

fiCommittee-Based Sample Selection Probabilistic Classifiers

diculty batch selection addressed directly McCallum Nigam (1998),
describe version batch selection (called pool-based sampling), differs
basic batch selection scheme presented Section 4.2.3 two ways. First, quantify disagreement committee members KL-divergence mean (Pereira
et al., 1993), rather vote entropy. significantly, disagreement measure
combined explicit density measure density-weighted sampling, documents similar many documents training set probably
selected labeling. intended address property 3 Section 2.2. authors
found empirically text classification using naive Bayes, density-weighted poolbased selection method using KL-divergence mean improved learning eciency
complete training. also found sequential selection using vote entropy worse
complete training problem.
hypothesize due high degree sparseness example space
(text documents), leads large proportion examples atypical (even
though documents similar given atypical document rare, many different atypical
documents occur.) Since case, sequential variant may tend select many
atypical documents labeling, would degrade learner performance skewing
statistics. problem remedied adding density-weighting sequential selection
future research. may yield ecient sequential selection algorithm also works
well highly sparse domains.

8. Conclusions
Labeling large training sets supervised classification often costly process, especially
complicated domain areas natural language processing. presented
approach reducing cost significantly using committee-based sample selection,
reduces redundant annotation examples contribute little new information.
method applicable whenever possible estimate posterior distribution
model space given training data. shown apply training Hidden
Markov Models, demonstrated effectiveness complex task part speech
tagging. Implicit modeling uncertainty makes selection system generally applicable
relatively simple implement. practical settings, method may applied
semi-interactive process, system selects several new examples annotation
time updates statistics receiving labels user.
committee-based sampling method addresses three factors relate
informativeness training example model parameters affects. factors
are: (1) statistical significance parameter's estimate, (2) parameter's effect
classification, (3) probability parameter used classification
future. use committee models uncertainty classification relative
entire model space, sequential selection implicitly models distribution
examples.
experimental study variants selection method suggests several practical
conclusions. First, found simplest version committee-based method,
357

fiArgamon & Dagan

using two-member committee, yields reduction annotation cost comparable
multi-member committee. two-member version simpler implement,
parameters tune computationally ecient. Second, generalized
selection scheme giving several alternatives optimizing method specific task.
bigram tagging, comparative evaluation different variants method showed
similar large reductions annotation cost, suggesting robustness committeebased approach. Third, sequential selection, implicitly models expected utility
example relative example distribution, worked general better batch
selection. Recent results improving batch selection modeling explicitly `typicality'
examples suggest comparison two approaches (as discussed previous
section). Finally, studied effect sample selection size trained model,
showing significant reduction model size selectively trained models.
future research propose investigate applicability effectiveness committeebased sample selection additional probabilistic classification tasks. Furthermore,
generality obtained implicitly modeling information gain suggests using variants
committee-based sampling also non-probabilistic contexts, explicit modeling
information gain may impossible. contexts, committee members might generated randomly varying decisions made learning algorithm.

Acknowledgments
Discussions Yoav Freund, Yishai Mansour, Wray Buntine greatly enhanced
work. first author Bar-Ilan University work performed,
supported Fulbright Foundation part work.

References
Angluin, D. (1987). Learning regular sets queries counterexamples. Information
Computation, 75 (2), 87{106.
Angluin, D. (1988). Queries concept learning. Machine Learning, 2, 319{342.
Baum, L. E. (1972). inequality associated maximization technique statistical
estimation probabilistic functions markov process. Inequalities, 3:1-8.
Black, E., Jelinek, F., Lafferty, J., Magerman, D., Mercer, R., & Roukos, S. (1993). Towards
history-based grammars: using richer models probabilistic parsing. Proc.
Annual Meeting ACL, pp. 31{37.
Brill, E. (1992). simple rule-based part speech tagger. Proc. ACL Conference
Applied Natural Language Processing.
Church, K. W. (1988). stochastic parts program noun phrase parser unrestricted
text. Proc. ACL Conference Applied Natural Language Processing.
Cohn, D., Atlas, L., & Ladner, R. (1994). Improving generalization active learning.
Machine Learning, 15, 201{221.
358

fiCommittee-Based Sample Selection Probabilistic Classifiers

Cohn, D. A., Ghahramani, Z., & Jordan, M. I. (1995). Active learning statistical
models. Tesauro, G., Touretzky, D., & Alspector, J. (Eds.), Advances Neural
Information Processing, Vol. 7. Morgan Kaufmann, San Mateo, CA.
Dagan, I., & Engelson, S. (1995). Committee-based sampling training probabilistic
classifiers. Proceedings International Conference Machine Learning.
Elworthy, D. (1994). Baum-Welch re-estimation improve taggers?. Proc. ACL
Conference Applied Natural Language Processing, pp. 53{58.
Engelson, S., & Dagan, I. (1996a). Minimizing manual annotation cost supervised learning corpora. Proceedings 34th Annual Meeting Association
Computational Linguistics.
Engelson, S., & Dagan, I. (1996b). Sample selection natural language learning.
Wermter, S., Riloff, E., & Scheler, G. (Eds.), Symbolic, Connectionist, Statistical
Approaches Learning Natural Language Processing. Springer-Verlag.
Freund, Y., Seung, H. S., Shamir, E., & Tishby, N. (1997). Selective sampling using
Query Committee algorithm. Machine Learning, 28, 133{168.
Freund, Y. (1994). Sifting informative examples random source. Working Notes
Workshop Relevance, AAAI Fall Symposium Series, pp. 85{89.
Gale, W., Church, K., & Yarowsky, D. (1993). method disambiguating word senses
large corpus. Computers Humanities, 26, 415{439.
Johnson, N. L. (1970). Continuous Univariate Distributions { 2. John Wiley & Sons, New
York.
Johnson, N. L. (1972). Continuous Multivariate Distributions. John Wiley & Sons, New
York.
Kupiec, J. (1992). Robust part-of-speech tagging using hidden makov model. Computer
Speech Language, 6, 225{242.
Lewis, D. D., & Catlett, J. (1994). Heterogeneous uncertainty sampling supervised
learning. Proceedings International Conference Machine Learning.
Lewis, D. D., & Gale, W. A. (1994). sequential algorithm training text classifiers.
Proceedings ACM SIGIR Conference.
Liere, R., & Tadepalli, P. (1997). Active learning committees text categorization.
Proceedings National Conference Artificial Intelligence.
Littlestone, N. (1988). Learning quickly irrelevant features abound: new linearthreshold algorithm. Machine Learning, 2.
MacKay, D. J. C. (1992a). evidence framework applied classification networks.
Neural Computation, 4.
359

fiArgamon & Dagan

MacKay, D. J. C. (1992b). Information-based objective functions active data selection.
Neural Computation, 4.
Matan, O. (1995). On-site learning. Tech. rep. LOGIC-95-4, Stanford University.
McCallum, A. K., & Nigam, K. (1998). Employing EM pool-based active learning
text classification. Proceedings International Conference Machine
Learning.
Merialdo, B. (1991). Tagging text probabilistic model. Proc. Int'l Conf.
Acoustics, Speech, Signal Processing.
Merialdo, B. (1994). Tagging text probabilistic model. Computational Linguistics,
20 (2), 155{172.
Mitchell, T. (1982). Generalization search. Artificial Intelligence, 18.
Pereira, F., Tishby, N., & Lee, L. (1993). Distributional clustering english words.
Proceedings Annual Meeting Association Computational Linguistics
(ACL).
Plutowski, M., & White, H. (1993). Selecting concise training sets clean data. IEEE
Trans. Neural Networks, 4 (2).
Press, W. H., Flannery, B. P., Teukolsky, S. A., & Vetterling, W. T. (1988). Numerical
Recipes C. Cambridge University Press.
Rabiner, L. R. (1989). tutorial Hidden Markov Models selected applications
speech recognition. Proc. IEEE, 77 (2).
Seung, H. S., Opper, M., & Sompolinsky, H. (1992). Query committee. Proceedings
ACM Workshop Computational Learning Theory.
Viterbi, A. J. (1967). Error bounds convolutional codes asymptotically optimal
decoding algorithm. IEEE Trans. Informat. Theory, T-13.

360

fi
ff fi


"!$#%#'&#(((*)+#,-#"."#/0

=+>@?$ACBEDFGHDIAKJML

1*23456#78(9:;2
!5<98((

DNEOPCQR?6O?S>UTWVXPCD*AHD*AHJZY[P\B]P

^H_`ba_dcHe4f@`hgXi'ajlk
zl{| }*}~E}6<~{{~h X}h4+b*64h *
bhbE *
%]%* z

mln+o+pqrbsXtCruv'w x y+n+py+rEw rlpy

_`be'<`bj+i'a

bn+r pq tun%'w mly'w r py

* <}4}| RX* E}h}zl*b
%RX}}h X~|$*
}}hE *
}}hb]@- z

6h E
4 Xl4 % d- bb HHl- 4H-l%%-
hC l4 Hh-X$ - b h-l*h
- b %b- H-h H b C $"] C l-
'- %S%'-l Ch +C%-4l'lEh l%
hCH @l- @W%l hH- Rl@h"@- W l%
hH$l4l6-C $-l% * SblHb4 -6l<
h l-H l-- h%@6d-lb-
- +%lH-X Ch-X $ -@ 46lS $l%C
h %-$ 4**@hbWl--$ bl@4 Rl Wl
@"4l%X'4E $l-SE4bl4 4\*4*6hbl-
4 hClSl-64 Kl"-'l- h % \l
4 4@"h4l%6$ - 4h'l <4H@ l$
l-
Xh 4S6

ff
fi
fi
!"
fi# ff$#&%'(#)* + ff',

fi##-
# ff.$ ',
)/ 0fi!
1fi#

&
2!3!) &
)4)&%5&%
2fi
2) ) 76
# ff8

9:; ff=<>ff# ff) fi#9? 1) $8!) &
)4)
'@
A!'B#-0CEDE%='@
A!'B'F

9G
2H%#I
1fiJ<) ffK&%L
fi##$9M NO%=
&
B
: ff
&%
<<$ ff<>
2 ) )P 0&%E% ) Jfi#
!"
fi# ff>O%'Q; ffR&%
&
SCNDT%EUP ff V4) $!13%$
; ff) )P ffJ!'@<$ J&%WL
fi##$9" 0&
!J
&
=19@# 7+9!G
Kfi#!'B!
!G')fi
1fi#
!) &
)=<> E K
<<fi#9ff!M&%4H% )Mfi#
!X
2fi ff$#&%'MYO%$19M!$
2) !Mfi
2) ) 76
# ff


29C
Z
1fi#![ > ffB
\ J+ ff)
fi$
) ff)@!fi!S[)&1^]_ ##_9Y

a`bO$9?$ ffY
ff!
L
95 E&%J; ff 'J
# ff5) c dfi!
1Sfi/
%3 ff1]$C@e1]$ #$9?'J
93
$#) @U%
ff1) >I
# ff)/J f1SE
V B!4) ff'BPUE
a9W)&%B
)R#)
) P) $#_94 ffgUW%4&%P; ff 'J
# ff
) 8 Mfi!
1fiE
h ff1]$=#)Bji0$b$ ff'k&%@!; ff '@
5 MU%%c&%"fi#
5
fi# $#&%'
UE#fi#fiW%

) )C:l ff4A
'@<fi#YRUW%8fi!
1Sfi#m<#Afffi#)K!8'J
K
&
Yn&%d

2fi9) B$9^<#
fi#fi#9
) )E#)&
fi0!<W
&%o&%
K&%='B$#
fi!)W n&%+
2&$ ffo ff >)&< ff!K B&%
ff1) >I
# ffpC4q ff'@
2)4!3UW%#H%hA^<S$ )#)&
ff>"
$@
&
fiN<fi!
)r+ )&1]$ #@fi!
1fi#!
$ $)ts;e'49&%pYuavvwxCEyzM O%E ff'J
!)Yp&%t' ) Pb$L$9<= 2/ $ ffP#)='B#)
V )'@

#((%('fi+fi|5 X 5o}$% R~E *ff34 R2
!bfi

b!*l5
{

fi

n+o+pqrbsm,Xn+r pq

$!@

a`bO$9C0O%>"
)W 0fi!
1Sfi!K $ ffo
$#) )PUW%J&%; ff 'J
# ffK) " =fi!
1fi

%@ 1) $I
2 # ffK#)E!
L^
2 CRl /A
'@<fi#Y!K&%'B#
fi0 '@
!@#W'J
9@ E1S=< ) )1fi#
B<z; ff '(&%W) )*))&
$9@ =ff

*O%
*
4!
ff ))P#)u

Cl ffR '@
!)
!BUW%#%=fi!
1Sfi#B > ff$)n ffY
B
ff'J
t'&% ffB fi#!'B!
!B ffg ff $=')fi
1fi#
ff1) >I
# ff)TUE#fifin!'@<$ &%=<>t

29" R&%fi!
) )j6; ff 'BKb$ ff'&%&
!

&
SC
zy 8&%#)"
$fi#MUPd
$))@&%M<$ ff1fi#' 2W# 7;9ff!8&
!!8)&
)@&%
2
$G')>`
fi!
1fi#0C8fi!
Qs$uvwx'B ff)
5O%

)@ #) Kfi#fiP!$
) )Yo$'B ff!5 #) Kb$ ff'

O$!1 P; ff 'J
# ffB$
2) )/&%<$# #f
2
9B O%W$)&fi# !Bfi!
) ) 76R7O%*)O
'B

O$!1 = #) =#)W<>) T&%=
2&
4 "1fi!
)) 760CEybMO%
) /'B#) fi!
1fi#3&
2!K!`
) &
)fsfi!
) )E #) xo&%T ff<< )W#)P& #&E&%&
2!B
&
UTfi#fi>)&fi#/!M
fi!
) )j6
UE#&%)j6
fi#9%#ff%:<$# #m

9Cl ffKA
'@<fi#YP$ fi9Q
l$#fiGs>uvvw
SY
uvvw1xn#fifi!)
K&%
n; ffnfi!
) )P #) Wfi#fi#)P 0fi#) )/O%
BffY$'B ff!B'B#) fi!
1fi#M!) &
)
b$ ff'&%&
!!@
&
B$)OfiMM%#ff%<$# #=

9G>fi
2 # Bfi!
) ) 76
# ffM
2`

#)
%dUE#&% ffJ fi#
!"O%&
!!"
2&
C
t!&$ @
M'B&% d; ffT# 7;9ff!5'B#) fi!
1Sfim!)
)&%
#)t )&<76K
9
<
$fi!
fi
!"
fi# ff$#&%'Y^1E
2&%o) $)E
)P
=
fi0'B&% "O%
P
"1S=
<<fi##d


2&
) P1O; ff$T+!B#*
fi#
@
fi# $#&%'MC/DE%1
) ##
=#)P B) W
4) / 2fi#


fi# ff>O%'B)@ 3$
Mfi
2) ) 76$)K&%
@
@
)"
J*#;a+ B&%M&
2!5
2&
C?DT%d'B&% m)
'B
[195&%M %#L^M 2f$'B \ff;#=!m$ff$)) # ffm

fi#9) #)Xs #)&1S$YuvxC
3 ff fi##4)B

)Xs;
:!) &
x4&%
2 ff)B + fifi# U,O%@)&
'BK'B fffiP
)&%">) E&%

&
J
X
<<S
$)W
2)E&% ffff%#)W ff')P.> ff'
B7i0$f<$ 1
1#fi#$9d#) O$!1 # ffpCWE

2 )

$
2) )WUTO%d
Bfi!
$t$) #
fin $ C # #)&1S$?s$uvxo)&) )W1#fi!3
@'B fiN) !M
fi#fi
R&%
&
4A<P; ffP&%)&)O< : ff fi##W
M) !@UW%&%T ff) ffo ff) W1fi# ff
@O%='B fffin) !"&%A
2fifi#9M) #-m7`b ) aC
$YgU*K
<<fi#9XO%)B#
d195) !5
K) = Efi!
) )j6>)=; ff 'db$ ff'<
$ P&%@&
!

&
W )RUW%&%R!)
)/!B&%E$'J
!@<
> p&%E&
!4
&

$E'B#) fi!
1Sfi0CP
!'@< $&
Pji0$=1S$U*J ffoUP ff VB
M<$ )W
<<$ ff
2H%)o B ff fi##/ # ffK#)E&%

ff
<<$ ff
2H%:
) )&'B)O%
E&%B $ $)W!:&%Bfi!
) )fi!
1Sfi)B
$4<SB /O%t<
$fi!

'B fiN1S!M6 "O%=
&
SCWyb:) )Yp ffW'&% ff5
'@< )E "# 7+9:
&
K< ! )&%

fffi#X1S ff fi##$)W!c'B fi;C
W
fi!
ffP
<<$
H%J ff6
&
) )*O%
*
>f<$ W Bfi!
1Sfi!K $ ff>)
"UPT6
&%
46fi# $!8)&1) &
!
fi#fi#98'J<$ )"<_+ ff'@
KUW%8fi!
1fi#)d
$M #) 9Cmybm
2 pY/UP
ff'@<
$6fi# $!M K'@
]$ ff$#$9" ) 'B1fi#Bfi
2) ) 76$) K#fifi!)
B&%

fi#&% ffff%:'@
]$ ff$#$9
=fi!
) ) 76$)=<> I#B) ff'BB<$ # ff3

!) f )9M
&
YS6fi# $!d$)&fi# )!:) #ff76
fi#9
%#ff%=
2
9C@&%!$8A^<S$!'B4I
fi!
)tO%<>) 5 E ff'&% ffch 7;9ff!
fffi#9?'B#) fi!
1Sfi#[
&
M<S !)C K fffi!MUE#&%5
)) ) # ff8 Pb&$M$)
$%3!$ # ff)

!'BM
*'!'B#-!K&%W<$ ff1
1fi##$9" 2#)
$!t!)
)P&%
*
$EA< # ff)E
&%&%

#) C

OOn b_jI0_O;$bP jzbR$_I;PO$_b =;E /Pz!jb&P$OjOj Pp$z/pjBI
b_O zI$Eab$;b;$IROzIzbOIPab a=j;;aIjff


fi

'@3






pr v+hsvc%q+mr qhr pm6n++v+v5SIb

X

DE%"<> ff1fi#' W%
fi#!5 #) "%
)B1c&%B; ff) W'B%X
2 # ff3!5'@
%!"fi#


"' ) R! #fi#
!@
fi# ff$#&%')/%
W
'B%
#)&'(+ ffR%
fi!@ #) !B&%E&
!

&
Kfi!
1Sfi#)C@l ffA^
'@<fi#Y< !3!3#) # ff5O$)#)=) #ff8 d$@O%@H%
@&%

&%4&$=#) z6 !@ " #) B!:&%=O
!!M
&
CP)f<S !X W19d4
'B1$Y Z



mqK- $ )&Vfs$uavvwxYR$' I!? #) .$ 'O%M
&
51SO+ ff>d%9< O%) #)@; ff '@
2 # ff?%
2)@&%



&%
E #) 9MA
'@<fi#) " E!@%9^<S &%) #) ff) & pC
DT%
K 2Nfi#!'B!
!d!)
)W @!'@<$ &%B<z; ff '@
= /
$) %ff1S ffEfi!
)>`
) 76$)E%
)E1M
r; ff)P $)
$%@!K1 &%K<
@$
"!)
O`_1
) Mfi#
!C
#fi) ff,s$uvx@)
\`_
$) d#ff%1 ff5s_ `_WxKfi!
) )j68s!\A^<S$!'B)5dUE
)K)
&%$xo B) fi#E!)
)E&%
oUP$WO%M) " =; ff '
KuO`_Wfi!
) ) 76S fffi#9"!) &
)E&%

&%K `_fi!
) ) 765 ff$ fi#93U*>>&
!:+ ffO%GuH`_W4C0D0 'BV?s$uavwxPA 5O%)B
<`
<$ ff
2H%3UTO%?
:<$ ff>"&%
2=
fi#fi#) #fi#) ffp)
2fi ff$#&%'k+ >
) !5I
2fi)J IC fi#)

5
$ !-ms$uvvSYWuvvvx@%
a: < ff
&%#)G
<<$ ff
%m! [
5)OX 2=)&
3) O`
fi# # ff3 %#L^); ffTAff'J<fi
z`_1
) 5fi#

2fi ff$#&%'B)CTf%
SY01fi#4
dfi!1$Ms$uvvuax
'B ff)&
4&%
R) fi# !4)&
)*1
2) B ffB$ ff$)R O% ff&$!1 # ff4 fi
2) ) 76
# ff


29X!8
c)&
O`_1
) 8fi!
) ) 76B!'@<> I)=&%"
2
95 E&%J&%"$)&fi# !5fi!
)) 7`
6CPeV
fi!
V5s>uvv ffx$
3
K!) &
4) fi# # ff3'B%
#)&'; ffE
$) W#ff%1 ffTfi!
) ) 76$)
UE#&%J&% ff
2fi N$!@&%!P '@<&
# ff
2fi ) aYffU%%K<)T ff@O%f'B1P 0) ff$
!) &
)aCdDE%K) fi# # ff8 W
K;U)&
)ds) #ff

)B<$ _9<)Ox195
:3 ffT
$fi#
)&
'J<fi!@
fi# ff>O%''B ff)&
J&%
/

29@UE
)/'@
!&
!G
@K
#) B; ffR)
fi

&
T) )aC #fi#) ffds>uvvvxg<$ ff#)/
ff'@<>%) #E $#Um !) &
E)fi @ %#L^)
; ffPA'@<fi!
z`_1
) :fi#
!G
2fi ff$#&%'B)C
%E#
= 2) fi# !5 ff !) &
)E%
)P
fi#) t1S"
<<fi##M O%R$9^<S)/ pfi!
) ) 76$)C

!) ffMs$uvxp'B ) &
tO%fi##$9B ) fi# !3&
n'B#) ) ) UW%fi
!=) &&
fi
) $!< # ff)aC?eV
2fi
V?
mP#) ) fi!
s$uvvx) $!13
8
<<$ ff
%c d) fi# !8!) &
)B; ff

:#) # ffm&>G
fi# $#&%') !?
:
) O`_1
) m$&>
fiW
fi# $#&%'M)4&
ff ff'493 W
) )ds; ff

'@<fi# &%X' ) $`b ff`_<S !M
2) ) ffxC Z UE#)d
E
fi# 5s$uvv2ffxB#fi#fi)&
3&%
2")&
'@<fi#
!) &
)d)[
[) !'@
: =fi!
) ) 76
# ff$&
!_9m
) #
fi#fi#9$)M&%5
'B ff@

&
Jd @fi#

B ff<C


ff'@
2 #
fi#fi9$' I![!) &
)d&%

d15 $ fi#9fi!
) ) 76Q)
&%
MO%9'B#ff%X1S5Aff< )X ?&%c
fi= fi#C %
\)&
5#)X
Aff<
:&%M
fio
) YR#B

<<S
B
)B&% ffff%hJ)B! ff > fi#9mfi
1fi#0C5FV295L^) # ff8!
!'@<$ 8
&
hL^
fi##$9[#)M% IU ?#) )O%Aff< )@b$ ff' )C=9 ffpY/5
3


<!V)ts$uvvwxR
<<$
H%J) )E
@!; ff '@
2 # ff@>$# ffK t'
)&$
J)&
)E$9<#
fi#$9p

$9<
2fi*!)
)G
$"O%[<$) 5
3%'@
8A<$@ 5 'B!MUW%O%B&%9m
$
'B#) fi!
1Sfi @A< # ff)C U*YE&%9 3&%
M1
) 5&%!d'&% ff#)X
[ `bfi!
'B&% =#n)&i0$)g.$ ' ff$$!Oi0 )CnV

=R )&%#
@s$uvvSYuvvwxp$
B
E'B&% B&%

fi#
)R
fi#-
2 # ff)/
=A< # ff)R) <

fi#9t19='@
!&
!!=
W> ff$= 2^&%o ff $fi9B

! ff $fi9Kfi!
) ) 76:<)E!K&%!t$# ffK 2
2H%K) ff$@A
'@<fi#CPDE%f'H%
#)&'
; ff0#) )O%@ #) ob$ ff'A< # ff)R#)/1
) B ff4
W)z`b)&<76M<

' YUW%#%B#)N)
)&>E&%
R
%4) ff>t)O
'@<fi#)/fi!
)) 76
# ffK
P#)/)&K fi#9"%#ff%pCRDg = ffRV UEfi#Y
&%=
<<> ff
%M%
)E fffi#9d1 )
$ 76!
fin
&
) )C


fi

n+o+pqrbsm,Xn+r pq

e>#
)&
pY5fi ff@
MP
!5s$uvvxR) f
B!+ ff'@
# ffJ&% ff$
<<$
H%J 4
A< # ff).> ff' #) B$!"&%4 ff) & # ffM /
Bfi# #
fin&% ff>9C/DE%!'B #
# ffM#)&%

&%$#)W @'B%
#)&'19@UW%#H%M
B ff`_' ff ff#fi#
!")&
9t
"$fi#!
1fi#9M#) !ff#)&%
& A< # ff)b$ ff' #) Co3&% ff)1
) Kfi ) 3U* $")O<!
fi##-
# ff[s;P
!:5fi#O`
ffpYuvvSuxp z6n&%/
2&
CDg ) fi#R&%EAffnfi!
) P
B E&%P $n&% ff$9Y &%9)fi
&% ff&%
ff $)*O%='B ) $ ff$)=sO%9B+ "'@<!$#
fi#fi#9dO%
P&%f' ff$$ ff1) E'B&%
&%
=
2fi) ff) #$)=O%@ ff'@<fi#A$93 P&%Bfi
) " )= !'@<
B$)&fi# )&xCtDg
$) )4&%
<$ ff1fi#'&%
P&%=1S) Efi!
) B'@
a9" W<$ =
K!'@'B!
=!$
) 4!M ff'@<>) ) # ffpY&%9
ff !ff4 @
dfi!
))YUE
# !@ "'@
V &%B<
r6
fi #fi0&%9K ff1&
!:
B ff'@<$)) # ffpC
DE%#)P
J ffE
I+ )
2fifi!
) )E%
a1M
0C/y+ ff'@<>) ) # ffKo ff'B)Y&%J&%
fi!
) 5s;
5)O1) L^Bfi!
) )&xB
$K
8 :&%@&% ff>9CGDT%B'BO% ff5#)@

fi# ff)
M<$O`_< !3 /#) # ffc&$)C=yz3&%!A<$!'B )Yn&%9:a]$ ?
ff'fi
2) ) 76
# ff
#) dsfi!!5 Z
!$0YRuvxP! "&%4
&
CDE%#)#) #
fiR K ff'B&% :+ ffT!a]_
#) T+ E;RK# OO C0l ff/'Bfi# #fi!
) )E
))Y ffRA<$!'B&
fi0'BO% ffK!a]_ )E #) !K&%
'@
&%
E#EUP fffi#X
2&
fi#fi#9M ff&%= '@
!5s) =e # ffffxC
4
'B1$/
Z


s$uvvwx/
M=
't1S$Y Z

W

Kq"- $ )OVRs$uvvwx/%
afi7`
ff<S"
'B&% B; ff%
fi!@ #) &%
g6$) /$' I)R ) #) /A
'@<fi#)Rb$ ff'Q&%P&
!

&
SCtyz ff) #) =A
'@<fi#)t
$B&% ) B&%
=%
aB&%J)&
'BBI
2fi)r+ &%B;
&$)=17`
;$fi!
) )4fi
1fi#)CBDE%9d&%:&
)$; ff '&%4;
&$)!
"1!
$9:;
&$4) CTAff&%9

'B!MUW%#H%8)t 2A
'@<fi#)YoUW%8$'B 0YR$)@O%M &
fi/'B14fi##
fi#)M
3$&
!c&%G<> ff<$$93&%
4&%@ >B) 4 E)&
)@#)@ =! ff)) aCXDE%98%
"

) z`b)@&%$)&% fimO%
@'B ff# ff$)@% U1#5&%#)@A
'@<fi#M) @)&% fi[1SCm#8$UP d) )B

'@<fi#)E&%
P$)&fi#E!M
JL^
2fi> # ffK!K&%f
'B ff/ fi##
2fi)aYUPWUP fffi#Kfi!V 4 =)fi
&%)&'J
fi#fi1
) : ffK&%=%$#) B&%
2*##)f'B $Wfi#!V fi#9d "1B #) C
%
=
"T#)&%#
Gs>uvvxg
fiUE#&%@
$fi!
J))&EB&%W<$ 1fi'( )W!+
O$E'B
a`
)&$' )aCNDT%o
<<$ ff
2H%4A )Rb--9@fi# #)P
<<$ ff
%4 =$<$)&
2 # ff@
B
fi#fi!
# ff
E!

@
&
CKDE%93# 7;9?!

@

ff3O%"1
) #)= 2L
fi##&
#K ff >fi
2 # ff)

'B f$fi!
@
&
1
) @ =O%* 1) $I
2 # ff4&%
R) ff'R;
&$)/
>*L
fi##&
#fi#9B<
)&%"
2)/) 9'@< ff'J
#E
&
4$O !"
4<
#)*#)
2) CRl RA
'@<fi#W7/=3uT ffo M) 9'@<`
ff')!#
&%
R
<
#/%
)/
<
$ #fi!
n#)
)Y&%BUPE'B#ff%/1fi##&%
n&%PI
fi!E
J) 9^'J< ff'U
2)E! ff $ fi#95'B
)O$d ffT $0CDE%!'B&% 39^
'
2fifi#93 ')
b--9@! >I
fi#)P; ffo!


&
B
M$L!$)E&%
o&%9"%
ff'@
!KVff UEfi# =#ff#
&%P;
&>)/! t) )/UW% ) W'B'B1>)*
$TL^
fi##&
fi9K<C %" 4 ff'@
!KVff UEfi7`
4)=

#fi
1fiYpO%9M)&) ) !d
Bb--9Mfi# #B) 9ff) '&%
%
)W<> 'B!5! $I
2fi)
; ffP&%;
&$)aC
e
fi$fi# ff<' )R%
aRff$
2 fi#9f%fi!<BUE#&%rfi#
!WA< # ff)R!4&%nb

* #) 9:
&
CPq# $#H%3
5P
V>s$uavvxofi# ff<S?
"'&% ff:; ffTfi
!Mfi
2) ) 76$); ff
'Bfi# !<fifi!
) ) )R!BU%%B > ffz`b ff > ! ff&<R )/
$P'@<fi# 9@
)/
#) &$!1 @ &<
$<$)&
2 # ff?s
2H%Kfi!
) )#)f
2) ) #ffX
JL@1!
$9M) &>K Rfi#&%dpxCPDE%9M#fi#fi!) &

&%
Kfi!
) ) 76

1SX#UP
)d
8 ff'@'B#
# ff<$ 1fi'!UW%#H%&%3 #$9[
&%K ff $B ffO<@fi!
) )4+
3UA
'@<fi#M#)"1S &
)O'B# 3 =
3 #) 98H%
fi+C
d'J<>
2fi/I
2fi
2 # ff3'B ff)&
:&%
$ ff_`b ff $ !K ff)
X1S") 3 K!'@<$
<_+ ff'@
Cnf &%P$o!
# ffK#)E1 ) !ds;e%
<!$YpuvvSff!fi!
pY0uvvwxY UW%#%
; ff 'B)=
K) 4 *fi!
)) 76$)BUW% ) "<> )
$@ ff'B1!19d !C"o ) !d
] ) )4&%
UP#ff%)/ p&%WO
!!=)&
'J<fi)E
R
2H%J#
# ffpY<
a9ff!t' ff$W
B )&
'J<fi)P&%
2/
$


fi

pr v+hsvc%q+mr qhr pm6n++v+v5SIb

7"fi#= "fi#
pCK< !
fiR<$ ff1fi#'UE#&%:&%) @'BO% ff)#)&%
&%9d'@
a9M

fi!
) ) 76$)o&%
/%
aE1t6/ ) 9) '@
E #) CX $ Ya&%#)/) #&
t'J
9B1E7"fi#P
CDo9^<#
fi#fi#9Y0 KI
2fi#

K<
$fi!
fi!
)) 76 ffE'&% ff0Yp = )=
@$ ) )$`bI
2fi#


@) /fi!
1Sfic
&
Cy
2fifin P&%=

@UE
)Efi!
1Sfi#19M&%B)&
'BB'B%
#)&'&%:&%
!$W
2&
) ffO
!)*O%E)&
'B) 9) '@
2 #E $ ff>)CnW%#ff!"%#ff%K

9J ff@O%)P$9<E
!< : ) E) aY'@
a9d'B
M&%
T&%t'BO% ff5%
) fft
MAfifi#E]$ ff1d
2P6 !M
&%) 9) 'J
#= #) C
yz8&%d<
) J
Y/O%d ff'@<O
# ff
fiE'@
%!dfi#
!8 ff'@'B#$9%
)J)


$!
# ff)E
[fi#
K&%
P'B fi0&%_9< 2N #) &%
E'B#ff%P ffM
B$
2fifi#

ff!$ ff'"sfi!!5 Z
2>0YRuv0efi# ff
pYRuvq
&YRuvvwxCE3 ff$B$fi9Yn'B fi)
W ff`_7; ff 'fi!
) )j6
2 # ffm #) 5s;efi# ff
pYPuvvx=
?<
$ !
fi* `_j; ff ' #) hs+q
&Y
uvvxP%
f1SM!O$ ff0CPDE%) B'B fi) " E
))&'B&%
P
%K!) &
B%
)E&%)O
'B
'B#) fi!
) )j6
2 # ff3

K&%$O; ff$=
$'B ff>f$
2fi#) B'B fi) O%_9<)P / #) ff1)$
!m$
fi7`bUP ff$fi#m
<<fi#
2 # ff)C3$t!
2 # ff8#)t X
fi# 4&%@fi#
8<$ ff>K+ ffr&%
V IU" #) =
)=sq
&YuavvxC UPo!M'B ) E$
2fij`bUP ff>fiM)
$# )P ffUE#fi#fi E%


) )P B&%& #) =
2 )/ n&%W
$# ff)Efi!
)) )C/yz@&%)
) )Yq
&s$uvvxR)&) )
)
>H%!B; ffo&% #) =
) !"
4$ ))$`bI
fi##
# ff)
$%pY1E&%#)E
<<$ ff
2H%K
) )&')E&%

ff=%
) #) b$=
2&
4UE#&%MUW%#%M B
fi!
=O%t$)&fi# )T NO%)
$%pC

4






p







DE%#)P) # ffK) >1S)W
4
fip<$ $+ R#j;9K'B#) fi!
1fi#3!) &
)P!M
&
!
) CRDE%6>) P) <K#)E B#j;9M
#
!)
)W19G) !ff
fi#
!M
fi# ff$#&%'B)Bs
fi#fi#
*#;aM ffO fi= xB c&
5!) &
)d
)@ ff > fi#9m ffB! ff $fi9\fi!
1fi#0CD0 c&%#)M0YE
?S`
; fi#?$ ) )$`bI
2fi#
5#)@<z; ff '5 &%J&
!!3
&
CJl ffr
H%h E&%"[<
$ )Yg&%ff


fi# ff>O%'B)*
>E&
!K ffJ&%E &%o=3u<
$ )CRDE%
F$)OfiBfi!
) )j6>)W
$EO%") K
&
P
%!)
/!O%/Afi@<
>
)0#&%g ff $g ff0'B#) fi!
1Sfi0Cfr##
fifi!
) )j6
&
)f
h)&
"
)=')fi
1fi#m7#4fi
2) ) 76)=&%J)&
"
)=1Sfi# ff!3
K7i>4fi
2) )
&%
c&%
4#8195# )B&
!cfi
1fi;C?T @O%
BUW%? #)@L^
2fi/ 3&%K &
2fi/ff'B14
&
2!4)&
)Y&%#)/'B&% t7i0$)nb$ ff' #)&1>)fs>uvx ff fi##R # ffB'BO% ffB fffi#9
!M&%) W) : B 'B!BUW%&%E

) #)f
K ff fi##C
T=&%Km W&%MS`;+ fim> ) )$`b
fi#
2 # ffm
%c)&
M!8&%K&
!!5
&
3%
)@1S
&
0
C T) !M&%#)!+ ff'@
# ffpY&%B) ff:) <:#) B; ff '
@fi!
) )j64) !d
"U$) # ff
&%dO
!!?

:+ BUW%#H%\
fi#fiW 2f&%M!)
)M# 76
)M'B#) fi!
1fi#
$d$'B 0C
lR#fi# $!?
?1Sd1
) ff8 ffK ffB'B ff>" &%

1
2) Mfi#fiPfi
2) ) 76$)o&
)aCXDE%K6fi# >
) E 2N&
!K!) &
)#)W<> I#5
)E!<W @&%EPp#O&" & fiBCPDE%t$)Ofi
fi!
) ) 76n#)n&%/@<$ 2^&%P
<<$ ff
2H%pCglR$WuR<# )RO%/
2fiff<$ $C/e<76
!'@<fi#'B&
# ff)B P&%#)t
fi/<$ $Kji0rc% IU&%B6fi# $!3#)t<Sz+ 'B0Y
5!
&%=$fi!
)&%!<X1S$U*&%6fi#
fi# ff$#&%'ds+)&xP
d&%6
2fi0fi#
!G
2fi ff$#&%'ds)OxC

e X]ajdWagE` "!

#

Ca j+`

$


<<$
H%h)B 3) K&%")O
'BKfi
!?
fi# ff$#&%'k ) & @1 &%5O%@6fi# B
8&%

6
fifi
2) ) 76CPDE%#)*
<<$
H%)E'B ) /) !'B#fi!
B$'B ff!4 ff fi##$)PK$ff>) ) # ffK

fi#9ff))aY; ff
UW%#%K&%)&
'B'B fip)) B ) o; ffo ff fi##$)W
K; ff6 !B&%6
fi0'B fip B&%
&

ff&%E fffi#$)E%
aW1S">'B 0C0>fi
2 "'B&% K)o&%
P<$ ff< ) "19&% ff%Xs>uvvxg; ff
('

fi

)

Training
Instances

Filter

n+o+pqrbsm,Xn+r pq

Correctly
Labeled
Training
Instances

Learning
Algorithm

Classifier

lR#ff$Ku+*RDE%=
fi0<$ $4+ ffofi#!'B!
!X')fi
1fi#3)&
)C
$'B !"&%4&
!!M!) &
)O%
W
$B< 519dCjds;!fi!
pYouvvxC*e<Sj6
2fifi#9Y0; ff

%@fi#
a/ KO%f< MO$E; ffoUW%#%K&
!!@!) &
)
$ ff1) $Jb$ ff',' ff$&%

ff@fi!
)),
% %p)='B&% 5fi#!'B!
)B&% ) B!) &
)tO%
f
$" b$ ff'&%"'@
2]_ $#_9Mfi!
))C
DE%@O$"#)4&%?>1fi#4b$ ff'O%"$m) 4 *&
!3!) &
)CdDE%#)@<$ ) )=#
2 )
#fi/ @b$&%< !d
:1B ffCDE%@V 9M7i0$"1S_UP ff'B&% X
% %p)
#)P&%
R ffo'B&% G) )P
$ ) )$`bI
2fi#
K IR&%EO
!!t
2&
UE#&%J ffE#
@UW%>
)
% ff%p)W'B&%
fi#)UE#&%K&%&
!KA
'@<fi#)W!$fi93
d<_+ ff'B)W'Bfi# !<fiB#
2 # ff)C
Q) ff:UE
9K @!'@<fi#'B6fi# $!M#)W @ ff) &W
B6fi# ) !K fft
fi# $#&%'F

ff) =&%J6
fiofi
2) ) 76@) !5
:ji0$t
2fi ff$#&%'MCdDT%G
))&'@< # ff8$fi#9ff!8&%#)

<<$
H%#)=&%
) ff't
fi# ff>O%'B)=

) ff6fi$)+ &%
fi# ff$#&%'B)aY0't%Mfi#!V @) ff'B

fi# ff>O%'B)f
2f
)T ff M;
&>=) fi# # ff5'&% ff)T; ffP &%>)s;T
$#YuavvxCPDE%B
<<$ ff
%
) $!1Sh19 #fi#) ff8s$uvxR 46fi# $!K
&
r; ffE
KuO`_) !M
K `_)
KA^
'@<fi#= R&%#)

<<$
H%pC
c 0$-j1!-2'aj
#e . /



Ca j `

$

3

)'t1fi#Pfi!
) ) 76$)R 't1!P&%o ff&< )0 2
P) n S1
2) O`bfi#fifi!
) ) 76$)Ws
) 4[e
fi!
' ffpY
u vvoV ) ) ffMeUE
!pYuvv fi!<>YpuvvxCp'@
]$ ff$#$9= P) 'B1fi#fi
2) ) 76oUE#fifi
ff&<Sz; ff '
2H%K1
) O`bfi#fipfi!
) ) 76P @
4
&
) R7$UP = )% fi,*s$uxRO%f<$ 1
1#fi#$9
/
4 ff $Efi!
)) 76
# ff319K
%K!#
fiRfi!
) ) 76T#)Wff>
o&%
MC7t
?s;xP&%$ ff$)
!d<$# # ff) 2N&%=1
2) O`bfi#fifi!
)) 76$)f
$!<"s
) de
fi!
' ffpY0uvvxC
yzK6fi# $!Y0
M) 'B1fi#Bfi
2) ) 76 )='B#) fi!
1Sfi#5!) &
)=19M ff) & !G
J) E
4 H6 5_#( 7a, 8;O;sfi!
)) 76$)&x=
XO%X):&%!fi!
) )j6
2 # ff3 $ $)W 7;9h')fi
I`
1fi#\)&
)C5DE%K
2fi
<<$ ff
%5#)B 3&
3
c)&

)B'B#) fi!
1fi#7:
98 W&%;


1
) O`bfi#fiTfi
2) ) 76$)K
Bfi!
) ) 7;9mJ ff $ fi#9C8yb8&%#)@UP ff VhU*KA
'B!X1S &%8'@
]$ ff$#$9

8 ff) )&)46fi# $)aCd'@
2]_ ff>$93 B6fi# 4&
)=
c!) &

)@'B#) fi!
1Sfi\7f'B ff$J&%

%
fi7R &%<

1
)fifi0fi!
) ) 76$)fi!
) ) 7;9"#E! ff > fi#9C/Q ff) )&)6fiW$L!$)E&%
2f
1
) O`bfi#fin $)W'B) Pb
#fi @fi!
) ) 7;9d
M!) &

)EO%=fi!
) )#d19K)W&
!Kfi!
1fi
; ffP#E "1Sfi#'
2 3b$ ff'&%&
2!K
&
C
y.=#)B!'@< ff>&
X J&%
=O%G$fi#9!?<$'B#) W
c) 'B1fi#K6fi# 4ji0$)4b$ ff'
'B&% )Bfi# ff<m!8$ff$)) # ff?

fi#9ff) #)Y8U%%c ff fi##$)@
$KO6[$fi!
#K X
:<
z`
#fi!
'B fi;C >tUPB
) )&'B4&%
) ff'B4!) &
)!3&%4
&
K%
at1S5'B#) fi!
1fi#m

&%
T&%=fi!
1Sfi > ff$)W
><S4 /&%B<
$ #fi!
'B fffin1!K6W @&%=
2&
CPDE%$O`
; ff$E fi#fi# !K; ff 'J
# ff.$ '7i0$'B fffi#)PUE#fi#fi<$
B1 *'&% ffJ; ffR
'B#) fi!
1Sfic)&
)&%
K fi#fi# !M!+ ff'@
# ffJb$ ff'
4) !fi#@'B fi;C
e
$#_9: /&
2!:
&
J)=
M<> ff1fi#'!3'@
9dfi!
) ) 76
5
3fi#
!X<$ 1fi'k `
'@
!)Xs+CC!YR'B#
fiP!
ff ))OxC5l ff4)&H%8
2&
) )aYUPKUE
4 5'B!!'B#-d&%d<$ 1
1#fi#$9
(=

fi

pr v+hsvc%q+mr qhr pm6n++v+v5SIb

>

? >

? >

Discarded

Mislabeled

>

? >
>

E1

? >

? >



? >

E2

@ Training
Instances

lR#ff>tA*RDo9^<S)W 2 # ff $ ff$)
P)
$!X
:!) &
@&%
#)=
:Aff< # ffc
&%&%
X
$ C=yb0Ynq=
9fiV:

/> ) ts$uavvx B&%
fi#
!:.> ff'F )9X
2&
@#)4jKfi@1S
) @##)t%
>X "#) !`
ff#)&%M1S_UPM #) =
MAff< # ff)aY)&<!
fi#fi#9d7R&% #) #)E) 9) '@
Coy;
fi#fi#9YO%f1!
) )
*
fi#
) ffB /&%Bfi#
!X
fi# $#&%'B)UE#fi#fi/
1fi#@# Kfi#
:&%BA< # ffpCtDT%$O+ $Y
ffE R'B ff$E 2&%Efi!
)) 76$)P&%
/ '@<$#) E&%1
) O`bfi#fip) R 0 $)R
@%
aE7"fi#$9

<&>B
W<
$ #fi!
RA< # ffBUE#&% R
) !=&%PA< # ffB =1SP $ ff ff)fi9Bfi#!'B!

b$ ff'O%W&
!B

CRybJ&%#)*
2) Y&%W ) )&)E'B&% "UTfi#fi'J
V P;UPR # ffK$ ff$)
&%
4
'@
]$ ff$#$9 ff0)fiE
fi# $#&%''B&% 0CRD
V!=
E ) )&)/
O%0&%
=
'@
2]_ ff>$9
#)*
4'B ff$P ff) >I
#
<<$
H%B
JUE#fifi0$)Ofio!B;UPn)&
)E1!Bfi#'
2 K.> ff'Q&%
&
2!K
&
CoDE%=
aUW1
2HVJ /
B ff) $
#B
<<$ ff
%M#)&%=
3$#)&VK /$&
!!d1


&
SCGyz8&%"AB) # ffcU*M

fi#9-"O%G<$ 1
1#fi# #)@ 2f'@
V!d#j6
2 # ffm > ff$); ff
1 &%M$&
!!M1



d&%$ UE!@
aUE
9J ff
&
t+ ffP'@
2]_ $#_9K
ff) )&)T6fi# $)C

e
B ij1CEDGFb_Ag,

c`b`gE`

$

yb 7;9ff!@'B#) fi!
1fi#K!) &
)o&%$E
$P$UP E$9^<S)R > ff0O%
R
B1W'J
=s) PlR#ff$
xC:DE%@6>) =$9<5sHKux ff>)tU%m
3!) &
M#)B! ff $fi98&
?
)B'B#) fi!
1fi#

#)")O1) L^ fi#9m#)
$sq=xCRDE%M) [$9^<SM $ ffMsHBx4 $)@UW%\
X')fi
1fi#
!) &
5s5x#)B&
5
)4 ff $fi93fi!
1Sfi0C3ybc&%#)=) # ff5UP"

fi#9ff-K&%"<$ 1
1#fi#$95

%K R&%) $9^<S)W 2 $ ff>)P+ /O%= ff) )O)f
d'J
]$ ff$#$9B6fi# E'B&% )C

IKJIKJLNMPORQTSRUVWXY<SZW0[
DE%E R! ff $fi9MO
!"
B $P!) &
B
)W'B#) fi!
1Sfi8%
<<)UW%M'B ff>&%

%
fi7= =&%
1
)O`bfifiW ff$)J.
#fiE ?fi!
) )j;9m&%:)&
3 ff $fi9C Z \@sHKu^]x@1S
&%@<$ ff1
1fi##$93&%
fi
2) ) 76<_P'@
V2)f
-HKu > ffW
d; ffT&%B)&
V 4 /fi!
$#$9X
))&'BB&%


fi#`
fi
1
)O`bfifi/fi!
) ) 76$)@%
a@O%t)O
'B"<$ 1
1#fi#$95 E'@
V!X
-HKuB $ ffO%
#)=L
fi

\@s HK^u ];xCKyEUP"
) )&'@&%
4&%@ $ $) E&%"1
)O`bfifi*fi!
)) 76$)@
$@!<Yo&%
<$ ff1
1fi##$9M&%
W
J'@
]$ ff$#$9@ E6fi# TUE#fi#fi&%> IU ffT ff
&
4#)#d19K*

\@sHKuxa

bdf c1e \@sHKu ] x
bTgAe`h

7

b

s>u*P\@siH"u ] x x
(p

ekjb:l


mon

fin+o+pqrbsm,Xn+r pq



%$q\@siH"u6]x s$uB \@sHKu^]x x


b


mrn

ekjb l

><$) )"O%d%
3



> ff$)M
'B ff5O%q


1
) O`bfi#fiTfi
2) ) 76$)Cmy&%d<$ ff1
1#fi##$9? '@
V8
sHKuJ $ ff4#)@fi#) )@&%
?C7Yn&%8&%
'@
2]_ ff>$9B6fi# UTfi#fiR'@
V ;UPE$ ff$)EO%

@)fiO`_
2fi ff$#&%'6fi# + ff'BMb$ ff' = R&%
1
) O`bfi#finfi!
) ) 76$)aC
DT%f<$ 1
1#fi#$9@ R'B#) &
V!
4'B#) fi!
1fi#:)&
; ff/
4 ff > fi#9tfi!
1Sfi#d!) &
"is Htx
$)U%t' ff$R&%
4%
fi7 &%P1
) O`bfi#fifi!
) ) 76$)Rfi!
)) 7+94&%/!) &

2)0&%*')fi
1fi#
fi!
) )C 7 Z &
\@is Htt ]x1K&%"<$ 1
1#fi#$95&%
2=
M1
) O`bfi#fiP ffu
_'@
V2)=
: $ ffr *$9<
HBCP) )&'B!K&%
&%= > ff$)
$!<@
d&%
2W&%B<$ ff1
1#fi## #)= /O%t1
) O`bfi#fi
fi!
) ) 76$)K'@
V5
v
Ht $ ff4
$@O%")&
'BYn&%5O%G<$ 1
1#fi#$98&%
=O%"'@
]$ ff$#$93
6fi# '@
V )E
B$9<<
HBB $ /#)#M19

\@sHBxa

db f c1e \@sHB ];x
bTgAe`h

7

b

s>u*P\@siHtt]+x x

ekjb:l


mon

DE%$O; ff$Yp
@'@
2]_ $#_9K 6fiEUE#fi#fi/'@
V2;U*wHt $ ff$)T&%

J) !fi#O`_
fi# ff>O%'6fiE7
\@s HB ]x4#)Bfi#) )B&%
8CjC %?
2fifiE1
)O`bfifi*fi!
)) 76$)GHBM$ ff$)B
$"'@
2" ffh&%")O
'B
)&1) 0&%)&
)Y&%W<> ff1
1#fi#$9@O%
*
4'@
]$ ff$#$9= Pfi
2) ) 76PUE#fi#fi0'@
V E
x
HB $ ff
#)W# #
fin B&%t<$ 1
1#fi#$9M&%

=)fiO`_
2fi ff$#&%'6fi# TUE#fifiR'@
V2f
$ ffC

IKJIKJy{zS"|,}~[A|,}(,}xV TW0[AU}
l /
) )&)P6fi#
xK
H $ ff ff>)*U%"
fi#fip 0&%1
) O`bfi#fip $)o.
#fi =fi!
) )j;9

B!)
W $ fi#9C Z k@
\ sK
H u^] x/1&%W<> ff1
1#fi#$9K&%
/1
)O`bfifi ffGn_ '@
V2)*
K
H u
$ /
;

1&%ff'B1S/ 2g1
2) O`bfi#fipfi
2) ) 76$)YO%@&%
2fi; ff ' 2O%f<$ 1
1#fi#$9
/'@
V!"
;K
H u $ ffP#)#M19K*
\@sHKuxa\@siH"u # dx \@siH"u
x #\@sHKu^ HKu 0
7 HKu # ^
# v + HKu

ekj

#

x

R&%1
) O`bfi#fin ff>)'J
V $ ff$)P ffJ&%)&
'BW!)
)E&%K&%=<> ff1
1#fi#$9M R
ffHKu
$ #)BL^
fio M&%M<$ ff1
1#fi##$95&%
B
M) !fi#d1
) O`bfi#fiP ff='@
V )t
h $ ff\@sHKu^]xC
H"uT $ ff>)/ O%f1
)O`bfifi0 ff>)
$W!<SY&%M
4 ff) )O)/6fi# T%
)
%K&%u

K)&'@
2fifi#B<$ ff1
1fi##$95 E'@
V3
HKuB $ ff&%
3
%d 2# )=1
2) O`bfi#fiP ff$)=
5&%
<$ ff1
1fi##$9M /'@
VM
;
HKu $ ffo#)#d1K
9 *

\@siH"uaxRa e \@siH"u6]x
] #
c

P&%@
) )&'J< # ff3 /!<aM /&%@$ ff$) /&%"1
2) O`bfi#fiR ff>)=% fi#)Y0&%:UP
fffi#MA^<SW
B ff))&)P6fi# P @%
a=
4)&'@
2fifi#<$ ff1
1#fi##$9" /'@
V!"
xHKuW$ ffo&%
K

) !fi#O`_
fi# ff>O%'6fiC

1 RIoRjjzjO;/$O;&T*; ;jW$ $zRI= R IR &;j$&zzj&; zb$Gp_$I;o
jjo $/o
z;b;o2RIzfPbRII nIO;nj$&zzj&; zbR*R <Pz;b j

jp EaIabb$;jPO; jjzjO;0$&;On&;gIO $0$o;j$ IjjpjIO;_ 0b$aj;
z ;_j$R$ ; b$R &;j$&zbjO;Izb$Inab a= &oz;b IRp*zjO;R$&;
IRjjzj&;o$&;RbR$&o ;$IR;O*Rp
(

fi

pr v+hsvc%q+mr qhr pm6n++v+v5SIb

DT%f<$ 1
1#fi#$9@ R'B#) &
V!
4'B#) fi!
1fi#:)&
; ff/
4 ff > fi#9tfi!
1Sfi#d!) &
"siHtx
$)EUW%:
K!) &
4)'B#) fi!
1fi#?
ffE'B ff>W R&%=1
)O`bfififi!
) )j6>)f<$# )
&%@'B#) fi!
1Sfi8fi!
) )C Z <\@sHB ]x1B&%@<$ ff1
1#fi##$9XO%
=
"1
2) O`bfi#fi/ ff_T'@
V )

$ P $9<&
HBCg ff) )&)T6fi# E'@
V )W
B$9<<HB4 $ ffP7R ff= *' ff$ R&%=1
) O`bfi#fi
fi!
) ) 76$)K'@
V )=
_9<;
HBK $ ffCGDT%)@<$ 1
1#fi#$95#)BL^
2fi/ : ff"'B!)tO%G<$ 1
1#fi#$9
&%
= 2*&%@1
) O`bfi#fio ff>)='@
V )=
HBJ $ ffCByus
\@s HB ];x#)&%"<$ 1
1#fi#$9
&%
Bfi!
) )j6x
_ )" K'@
V

HB: $ ffY&%m&%d<> ff1
1#fi#$9m&%
2
h ff) )&)B6fi#
'@
V2)W
;
HB4 $ ffo#)Wd1K
9 *

\@siHtxRauTs$uPs\@siHt
#

x xs$uP\@sHB
7

HB
#

x x^#s$u/P\@siHt

e

Ht # ## HB

ewj

#

xx

% 5O%G<$ 1
1#fi#$9m W
31
) O`bfi#fiPfi!
) ) 76@'J
V!?
PHBM $ =#)B!<" 2W&%

<$ ff1
1fi##$9M R&%= O%*1
2) O`bfi#fifi!
)) 76$)f'J
V!M
;HB4 $ ffPO%)1 ff'B)~*


\@sHBxa(uE e s$uEP\@sHB ]xx
] #
DE%$O; ff$Y!B!$P ffO
) n <K
H $ ff>)Y !c <= 2&%HB ] $ ff>)R
Bfi#
@ =%#ff%

fi#fit
H r $ ffN+ /O%W ff))&)o6fiC/ybK)OH%J
) )Y
4) !fi#O`_
fi# ff>O%'6fi# oUP fffi#G'J
V
;U*xB
H 3 $ $)@&%
\
5 ) )&)K6fi# J&%
K ffO
!)"&%:) !fi#?
fi# ff>O%'
)K ff: =# )
1
) O`bfi#finfi!
) ) 76$)aC

Ee


$ 12

a_ <j aj+i

B 0$6_0Fj$Ej ` $ ,$HcwRFbjAZgZ0$

O+ $?'B [

fi!
# ff tO%?
<<$ ff
2H%pY&%3#) )&m'B) d1?
2$) ) Q&%


!) &
)T&
K
)E'B#) fi!
1fi#X19@&%
1S
<<> ff
%B fffi#d1A< # ff)E B
4
fip fi#

4&%$O; ff$/UP fffi#@=)O<!
fi&$
2&'BC %=
!) &
P#)/
rAff< # ff4 T&%/
fi

) Y#/
B
<<S
/
)RO% ffff%B#R#)/! ff > fi#9@fi!
1fi#0C %J
<<fi#9ff!B %L)P #j;9

3fi#!'B!
#) 93)&
)Yg ffBU
)
#3)
$!3 ff $ fi#9:fi
1fi#?A< # ff)C
yb:e # ffdU*#) ))Eb&$=<fi!
)T+ Pfi#
!" @#) !ff#)&%3 #) b$ ff'A< # ff)C
) m) #&
# ffc!8UW%#H%8
c)&
d'B#ff%t1SM)
$m $ ff) fi#9?195 ff6fi#

<<$
H%K#)E7*

2fi ff$#&%'UE#&%M
K
<<$ ff<$!
4fi#
!G1!
)T; ffo&%
&
B)*#)) 0C/yz
)&%:
) )Y&%@
fi# ff$#&%')f><$) &
# ff:fi!
ff
'J
9d f<S 'B#=
3

t$<$)`
&
2/&%B ff<C=DE%#)B<$ ff1fi#'#)t

fi# ff)W M) #&
# ff)!3UW%#%3$'B ff!M fffi#$)
)/fi## fi#W =!'@<$ P&%P6o
f6$) $`b $nfi#
*>ff$) ) # ffj0&%T ff $P'B fffi 2O%E
&

#)=L

CrlR
2fifi#9Yn) !@&%46fi# 4
fi# ff$#&%'ds+)&xE ) & )=
Kfi!
)) 76=) !dO%t $#!
fi
#) 93
&
J) Yg&%B# 76
5 E'B#) fi!
1fi#m!) &
)=#)t1S ff5 K!fiM$ ff$)0)

4fi!
) ) 76+ ff'B@b$ ff''B#) fi!
1Sfi#X!)
)W 'B!7/ &%o!) &
)W
$f')fi
1fi#
UE#fi#fifi#
[ c) ff'B: $ ff$)aC #&%mO%)

)@!'0YPUP3 IU<$ ff 8
m'@<!$#
fi

2fi
2 # ffM R&%=
<<> ff
%pC

4

+






6

X
fi!
K&%M
1#fi#$9m E&%KI
> )B6fi# $!?
<<$
H%)4 3# 7;9')fi
1fi#[&
!
g
!) &
)PUPE% ) E '@
!)o+ ffnU%%Jfi
1fi#!" > ffn ff>)
2&
fi#fi#9C/Dg =) !'Bfi!
&%E$9^<S)
0 $ R&%
R o!"<
2 #YffUPE )&fi# ff'@
!BA<> )o+ ff
%B
&
)/ # 7+9K&%
<
!$)R pfi!
) ) )Rfi#!V fi#9@ 1E .) 0CRDg ) R&%o6fi# $!B
<<$ ff
%UPE
$j6!
fi#fi#9@!&$
(

fi

u





w


v

u
u u

n+o+pqrbsm,Xn+r pq

Pfi!
))WW
'B
1$
fi#
aN$ff$J; ff$)
ff7;$ ff)E$ff$G+ ff>) EUP ff fi!

%#ff%fi
2 #&=# ff); ff$) E(U* fi

&

# ff)$`b$ff$; ff$) EUP fffi!

ffMff
) ) fi!

ff
) ) fi!

1
>ff$ ff
fi# #I
2
1$
fi#
aN# ff); ff$)(UP ff fi!

)&%1)W
X1
$ff$ ff

yb) &
)
w

uu


u
ff
vu

u
u

Dn
1fi#"u+* Z
Pfi!
) ))
#) M! 3&%"O
!!Xfi!
1Sfi#)G1S_UPc&%) M<
!$)B Wfi!
) ))C K[ =!O$ ffd )
1$UPd
2fifin<
!$)W 2Nfi!
) ))f
)T&%#)WUP fffi#X W'B fi0&%=$9<)E 2Nfi!
1Sfi!: $ ff$)T&%
E
!3<
#CWTA<$!'B )=
$4) #ff3
) ) ) )T&%=7i0$_9<) n6fi# $)p
1#fi#$93
#j;9['B#) fi!
1Sfi\!) &
)M
8&%MOi0tO%
=fi#!'B!
!['B#) fi!
1Sfi!) &
)"%
)B ff
<$# #@

29C ) $!1St PA^<S$!'B&
fiR'B&% M:e # ffMCjC

'e {RgZ!

i0$

_

DE%#)W$)
$%@ ff>
2 K.> ff'Oi $ )*
2$) ) !K&%WO
)&VB R
ff'@
2 @fi!
`b E'@
<<
b$ ff')&
2 fi#fi# 4
&
CRyzd
<<fi#9d'J
H%!4fi
!" %#L^) @&%#)W<$ ff1fi#'UPfi# ff<
&%P#
)4 ff) )&)6fi# $)R $'B E'B#) fi!
1SfiK&
2!4)&
)CRP)&fi# ).> ff'Q&%#)
ff V
J1P; ff@!ds;P$ fi#9@l$#fi;Ypuvvw
Yffuavvw1xC0Dg =A<fi# ff$EO%)oL^) # ff4b$&%Y
% ) P; ffR
# # ff
fi
&
) )n= ffR% #EUE
)/1
)@ ff@
o] ff'B/ pUW%&%&%Efi!
1fi#!
<$ ) )E!fi!5)&1)

2fifi#fi#) n)&1]$ #ff#$9M ffP #) CPybMO%)T) # ffpYUP#j;9d% U
fi!
1fi#!M $ $)W'@
a9"
>)=!M
%K R&%6 ff'J
!)C

,JLAJL <0W0S"wOAW0[A,O"|,zSR[AUMPORAAV|Z
DE%:6$)
2&
) MUP3A^
'B! ff) #) )M 2
8 !'B5)$#)d =fi# ff1
2fifi#9#) O$!1 )O
fi#fi#
ff1) >I
# ff) /&% 3
$&%p)E)&zb
CEDE%4
&
) TU
2)E ff'@<#fi#?19"qlp$#)=
XDg UW)&%
s$uvv ffxY
:fi!)@vBfi# ff
)W&%
2W ff'J<
) )
fi#fiN'@
2]_ / $) &>
2fiN1# ff'B) ,
:fi

P$9<)ts)=D
1fi#KuxC
DT%>'B o) ) != ff1)$I
)*
$P'B
)&>'B)R
<

'B g
fi#fi#"&%E ff'@
fi##-
7i0$EO
# ff4!As.Eq yzxC DE%#)RAJ)R '@'B fffi#9t)@ ;RO%
'B ff pfi#

# ff@<$)PUE#&%!K
t<#Afi0
/&%T !'BW 2
2&
=
L#) # # ffpCPDE%fTq yn

) d%$
UP$B fi#fi# 193&%BW
$9 #ff%5) fi! # ff5E
2 'B 51 ff
$3&%"
# ff
fi

#t
"EO'B )&<%$#'B!#) &
K) $#)E N' ff$ fi#
2fi)O
fi#fi#)C/DE%

=%


a1PdE^GjIpjbO_;pa2jOj=
b$;;0Ia_;zb;$

I0;z;b$;;j _$O;;;$*$O*gOoj$0 jOP$b0b&;jIa$


fi

pr v+hsvc%q+mr qhr pm6n++v+v5SIb

lR#ff>=A*/Dn
!!G
M) !@) # )C
1 \$O`b)&
'J<fi\b$ ff'&%3
aU )O
fi#fi#d
&
h ?%
ad
37+ ff')&<
2 !
fiW$) fi ff

ff$M 2Wfi!
#&X
?fi# ff#&C 3
%5 Mff$d<#AfffiT)J) $!119m
: !'BM) $#)@
$UPfi=Eq yo
fi!)f
'B ff&%fi#9M !'B=!$'B )T.> ff'uvY
d19M# )Tfi
2 #&YU%%:

1E) Obfi+ ff)$!'B!
!t
' ffWfi!
)) )UTO% &%>UE#) /) !'B#fi!
)&<&
fiff<$ ff<S$ #)WsqOb$#)
Dg IU)&%0Ypuvv ffxCDE%='B &%fi#9@'@< ff
fip)&
'@<fi#!"<$ $=
fi#fi# UE)P&% ff'@<#fi!
# ffK
fi# ff`;b$Bff#UE) R&% 3
>&%p)P)&zb

3
fi#) @
<O$)W)
) ff
fip9
'B#)!M&
# ffpC
DE%: '@<
fiE!; ff '@
m#)d<
$ #fi!
$fi#9) O.fiT; ff@fi!
)) 76
# ff\ =O
# ffm
\fi


)E)
) ff
fip%
)E!&

$ ff R&%=1S) W!#
$)W 2N&
# ffJ$9^<SC
\)&'@'@
$9B &%)E
&
r)P<$ ff#K!@D
1fiBuCRDE%Efi!
))/fi!
1fi#)EUP$P) fi# K B$O
b
!$fi#9d1$ ff
:fi
2) ) )UE#&%MA ) #4 ff
<%4
Ch
<)Efi# ff<h.$ ',O%)fi!
)) 76`

# ff) H%'f'@
a94&%@1) K =$fi!
Tfi
" nfi!
) ))* ) & &
fi#fi9K
Bb # ff
fi#fi#9
) #ff76
W fi #
fiN<> ff<$)aC/lp$ ff'
@>'B ) )M<>)&< #Y&%#)fi
2) ) 76
# ff:) 9)$`
'$O )@
ff'@<$ ff')G1S_UPcfi!
) )Bfi!
1fi#)K&%

$@) <

1fi#K.$ ' ff
>) "$) fi
$'B @) ) !3
&
SY0
?fi!
))=fi!
1fi#)@O%
=
$")O.fio d`_) >)t)OH%5
2)= fi# #) )CKl ff
b$&%B&
2fi#)M$ff
>8&%M)&<S76h<> ff$)M) \ 3 ff'@<#fi#XO%d
&
SYR&%d$
)
$O; $M Jql$#)W
3D0 UW)O%?s$uvv x*
Z )A
%) #t
3DV =s>uvv ffxC
Z
1fi#!3 $ ffT ff>)=!3fi!
`b
!!d
&
; ff'@
9X$
2) ff)C=J) ff$"
$#) )
1
) d#) $Mfi
2) ) )M
[1 ff
$#)G
>G) \ 3#) !ff#)&%
'B ff3fi!
) ))@&%
@%

)&1 fi#@1
$#)!d)O<

:&%
W%
ar.
2>fi9M)O'@
fi#fi7i0$)!M 'B) NO%<%9) #
fi

O$!1 )CRl ffoA^
'J<fiY&%#) ! # ff31S_UPM
B
) ) fi!

dUP ff Mff
2) ) fi!

M1S
L"7"fi#B M#) pCd ff) L fi#9YR<#Afffi#)Bfi!
1fi#[
)4ff
)) fi!
?'@
a9d!h.
2=$<$)
ff<SUP ff fi!

$
2)G
ff#5>)&
C,DE%#):) ff$3 B $ ffK#)d)O<!
fi#fi#9<$ ff1fi#'@


&%: ffdff>d)&<

2fif$) fi! # ffm =O%d
&
c) %$Cf &%@) ff$d 2f > ffB#)M&%
7i0$@1$UPd<
2fiN
3
&
fig&
p`
C n !
fig&
M$O+>)W J&%=$9<
&
# ffKO%
P ff$)
&
fi#fi#9M!M
@$# ffM1
2) ffK) #fi;Yfi#!'@
B
fi# 4 ff&$ fi#)C
&
fin&
X>O+$) K&%B&
2 # ffd<$)!3&%@$ pCq7i>)=
$#) @1
)
%'@
)@%
a")O1) &
!
fi#fi#9'B 76[&% 3
$&%p)4)&zb
@b$ ff'k# )"
&
fi/)
C Z
1fi#!
$ K +[ $)d1S
) ?<S !
fi&
2 # ff\fi
1fi#)5
$5) !&%5
1)5 &%
!+ '@
# ffpC
&%) ff$4 N$ ffE
>))f1S
) = 2/fi
`b IE%
CPyb:
$
)W> !G
<#
ff ff'cfi# ff<'BsCC!YP&%5%ff')&1&$ ff<#)&xK!; ff '@
2 # ffLVfi91S ff'B)d "
ff

fi

n+o+pqrbsm,Xn+r pq


CRDE%)f<$ 1fi')W
$W1S) P#fifi!)
d19@&%) ff$ 0 ffo
&
SYUW%#%@ ff'Eb$ ff'(&%$
A) !"'@
<)P fi 1
fifi!
s5
O%UE)Yuvfffi#) ffpY
)aYffWfi#fi##) ffpYnuv fi#)
$) `_efifi#$)aYRuvxCN ff'@<
$#) Rfi!
Pfi!
1Sfi#)=
'B ffB&%4&%$='@
<))&% UE)
&%
P&%9d
2ff$T+ ff fffi#9d
<<$ Aff!'@
2 fi#9G, 2N&% 3
$&%p)*fi!
:)&zb
)CWs.elR$t4; ff
fi# ff
2 # ff)=UW%>@&%@&%>"'@
<)UP$B!?
2ff$'BCjx8DE%"<$ 1fi'k ):
&
K fi#fi#
b$ ff''Bfi<fi#BA<$ )%
)W1SM 'B d!M &%P ff'@
2)
)EUPfi#fi*s;e'49&%pYpuvvwxC
l ffP&%#)UP ff VY1
) : ffM ffTA<$)W)&) # ff)YSU*4!&> ff5
' $ ff1$UP
&%J+ fifi# UE!?<
!$)B fi
2) ) () *Ka`bYRa`_YRwa`_Yoa`&uuYRa`&u8s) MD
1fi5uJ; ffO%G
')t 2W&%
fi!
) ) )Ox=s;P$ fi9d(l$#fi;Ynuvvw
xC

,JLAJy{zU[A,VW&AAUCSOR
DE%: ff
fiP =$#M
<<$
2fiE#)" c 'B!3UW%&%J 5#d
[
<<fi##

3$#"
$0C

&
) Tfi!)=wvB!) &
)fi!
1fi#?
)< ) # #4 ffEff
2 #C*DT%$t
>=B#) $

O$!1 )RUE#&%4$U* ; ff$ 4
fi!)Y
B) #At ! ff)/
O$!1 )CRE ffn'B ff$E
&$!1

2fi)K
$"'B#) ):b$ ff'M!) &
)CXDT%"fi!
) )4#) &$!1 # ff )4b
!$fi#95UPfi#fi*1
fi!
0YoUE#&%
4!) &
)Wfi!
1Sfi "
d=!)
)Wfi!
1Sfi#$`bC
DT%)B ff'J
!8U
2)=% ) 81
) MO%"% #M WUW%O%= d#d
8
<<fi##
@$#B)
)&1]$ #!M
&$C 3 $ ff#)*!&$ X1S
) =
@
2) ) ) )&'P pb&$=1%
a# ffo)1
)
ff\<
) "1S%
# ffCyz[
#
fi=
<<fi##
# ffs;1M) !m
57i0$"

) &xYf'B>

3 A<$) )>` W+ @&%
ofi
@ 2"$)/UP$Tfi))*O%
@Q $*
2*<$# !@UW%O%&1S ffz`
$fi#!@
<<fi#
)PUP fffi#@Ob
fi#/ ff4&%!fi
)fs3#%YpuvvxC0DE%#)E'B
)RO%
/Q p&%
fi!
1fi#)4U*>t!3$ ffT ffEO%
2 &$!1 )UP$@ f
2L^
"#) !ff#)&%c ff:b$ ff'1
5
<`
<fi##
)CWs;y.*#)P!$) !B E&%
P
#) # ffK&>WUE
)/
1fi# 4fi!
) ) 7;9"( 1 ff$>fi!

<<fi##
)W $ fi#9M!M&%<
Q'B$#
3 A^<>) )W '@
!5s3#H%#YnuvvxxC

,JLAJI{1[A|,[1[A"[A|0WOAW,V SR|
l 0&%#)n
&
T) Ya&%/ ff
fi#)R Efi#
= E) ff'BR
!'@
/! &%/) fi!
) ) )~*)OV9Ya'BY
UE! U=Y1>VY0ff
2) )YS+ fi#!
K
?<
&%pC 3
2H%: P&%Bfi
2) ) )t%
2)=K ff1) >I
# ff)aY09fi#!
uaE &
fi ff1) $
# ff)C 3
%=!)
E#)/&%


4=UE! Um <#Afi)E$<>)
19ufi# IU`bfifi+YE>
fi7`bI
fi!!'@
J+
2&$)C8DE%M!) &
)@UP$M
U?
ff'Bfi#93b$ ff'


&
1
) B E) 3 ff 'J
)b$ ff'1#fi#!)M
$ ff5O%
#$) #$95 P5
) )&
%) )

E'@%$)E
'@<)C
DT%tfi!
1Sfi#)=; ffT&%#)=

) U*><> ffm196$) !3&%B'J
)&%$ ff%3
K fi# ff
) ff'&
2 # ff
fi# ff$#&%'s&%/W4X
2fi ff$#&%'sq=
<SYP fi#fi#!)YP$ fi##
) ffpY mP#) '@
pY
uvvx x=
[&%m'@
ff
fi#fi#9mfi!
1fi#!m
%m$# ff ffm
: ff'@< @' ff# ffCmDE%#)M<$ ff>
<$ )"$UP 3$9^<S)@ fi
1fi#![ $ $() *K ff1]$ )B&%
"1fi#! 5 ffd
O%Y/)OH% &%
@

$# ff &%
@#)M<$ ff'B!
fi#9[ M_9<: ff1]$"%
)M<Afi#)K.> ff'
O%B ff1]$@fi!
) )K!
#E
m$# ff)B; ff4UW%#%8&%d1 ff
$9?#)"fi#
Y/c; ff4)O
fiP)O< # ff19?%ff'J
)
sq=
<YpuvvxC0l ffPA
'@<fi#Y1S
) =)OV9K ) 3&< ffV2&%$ ffff%4; fi#!
Y)&V9M
K+ fi!


m1SM ff.)m8O%M&
!!5
&
SC5yb8&%KA^<S$!'B )"O%
; fi#fi# IUU*K!O$ ff\&%
; fi#fi UE!K ffb) # ff() *o)&V9`;; fi#
2<
&%`b
) )ff
) )$`;; fi#!
C

a1pI$;R$

IjIRpzbRIO&$;;$; $0bb Ioj0IRzb$O; R IoO; &;O


fi

pr v+hsvc%q+mr qhr pm6n++v+v5SIb



u



w




v

Pfi!
) )W
'B
P ff

P ff
fi#!
=
afi
=
2) )
q!$
l fi#!

DV
eVA
9 Dn$
eV9

yz) )

u
ff
w
v
u
u




1fiBA*RP ff
:) ff'B&
Kfi
2) ) )

lR#ff$41*RP ff


) (*n ff$#!
fiR
M) 'BM&
!!"!'@
2C

,JLAJEkSOR C[AR[A|WOAW0V S"|
DE%#)B
&
: ff'B)r.> ff'
:) 4 W!'@
)B E ff&$95$
)Bc5
) )&
2H%) )aC 3
%3!) &

$<$) )@
:x
?Mff>8 W<#Afffi#)@)$!1193&%$K fi# ffB
3; ff4 A&$B;
&$)aCdDE%
fi!
) ) )R
$P$ ff
0Y $ ff
2fi!Y ff
fi+Yaff
2) )Ya>Y; fi#!
&VYa)&V
9 O$*
4)&V9CDE%$E
>/w
!) &
)!M&%#)
&
B)W
5uJ
&$!1
fi!)f
$='B#) ) !CEDE%b$L9M#) &$!1 # ff
Wfi!
)) )B)J)&% UW5!mDn
1fi#dC3DE%Mfi!
1fi#!<> ff$K; ff4&%#)B ff'@
!8UE
)4&%")O
'BM
)
; ff&%K) @) ff'&
2 # ff3 ff'@
2pCKlR#ff$Jd)&% UE)B
3 ff$#!
fio!'@
@ 3&%@fi#O;
5# )
ff >)&< ff!4) ff'B&
# ff419O%P
fi# ff>O%' ff4&%E$#ff%YaUW%#H%)/)19t
%'@

M$
2 @&
2!3fi!
1fi#)CMy.=#)Bfi
b$ ff'&%#)BA^
'@<fi#YO%
&%"$ )t<$ 193&%
) ff'&
2 # ffM
fi# ff$#&%'
$B #) 9M!3
&$K+ PA^
'@<fi#tfi#
!M
fi#fi /O%=&$O VK ff
&%=$#ff%E R&%!'@
t) !K&%=$# ff)W<> ff519"&%==
fi# ff$#&%' )!'@< ) ) !1fi#C
yz@ RA<$!'B )PUPE!&> ffK&%T+ fi#fi# UE!B ff.) () *n; fi#
2O`b)&V9s.wa`_vxff
afi7`b!$
s;a`_xff
) )>`b>?s `_x4$ ff
`bff
fits$uO`_xff
))$`;+ fi!
s+ `_wx)&V9`b)OVA
9 &$[s;vI`_xT+ fi!
O`
)&V
9 2&$ffs;wa`_x*
K+ fi#!
O`bO Vs.wa`_xC

1pI$;R$

IjIRpzbRIO&$;;$; $0bb Ioj0IRzb$O; R IoO; &;O


fi

n+o+pqrbsm,Xn+r pq

,JLAJ{VU[uOR|ZR[AUU[A,V CW,VS"|
DE%: ff
fiP &%#)"
2&
) @#)K ?
V36$)K!m 'B)@ &%!@)$#$9m ffm
3)
fi#: uH`_C[
fi!
1fiR 2u4!
2 )t J6$= $3 ff&%

a9G
3fi!
1Sfi)=I`_Y><$) E6$)Tb$ ff''B! ff
s;x ")$Gs.xCEDE%@
V!" 2*
9M19d%'@
)#)=) )&
>fi#93)&1]$ #43
O$C
l>&% 'B ff>Yff)6>)W
$ )P&%
P ff IR !'BYO%W%
! ff))
V!
!$
) )UE#&%&%H%
=&%
E
B7i0$W<>) ffd'J
9J "&%=
V!C
DT%)
&
2) PU
2)E ff'@<#fi#3 ffd1)&%G6$t
2 #ff#$9"!:&%='@
2fifi#BO
# ffM
$
$&%`
UP) # ff$!
Yp) &
2fi!
3sq UP= ) fi;YRuvv
SYuavv1pY0uavv ffxCPDE%B
&
2) E ff&
!)
ff1) >I
# ff)ds
a9)&x
2H%c) $!119c 3;
&>)tO%
t'B
2)&$K&%G'J
Aff!'B' '@<S
a`
&$Y&%'t1SP 0
a9ff)P) !#Efi!
) E
20Y
$ ff%P!AYS&% '@<S
&$
P<'MY&%
UP$`_1fi!13 '@<S
&>Y&%BUE!5)O<0Y0O%t$fi!
#K%ff'B##$9Y0&%4; ff$) 6$B
!AY
&%
!P<$) )&$Y
K&%W
) )6$W
CRybJ ffoA^<S$!'B )PU*&$#K t<>P&%A

6$:) $#$9Y/U%$
)"%#) $#
fi#fi9\&%d'B )@ ff'@'B m) &%#)"

3#)" 3&8K! ?

1!
$9"<> d<$ ff1fi#'&%
o#) !ff#)&%)1$UP" 46$@sfi!
) )uxo
@6>sfi!
)) )Ea`_xC

) 4T) 'B)%%fi9dfi#!V fi#93&%
E U* fi: $ ff ) fi#9"fi!
1SfiN
46>b$
a9G
)%
!

6>f
Jff#$)O
UPE!&> ffMfi!
) )P ffb) # ff)E
'B &%f<
2>() *Ra`_YffI`bY `_SYffa`_wYwa`_Y

da`_SC

'e#. w
c R<j+`i!j11_a$j ]gXi
)W) >1S
1 ") WO%=) !fi#O`_
fi# ff>O%'MY'@
2]_ $#_9K
: ff) )&)=<$ $)Y
UPB&$ ?
ff'F )@! MO%tO
!!d
&
K1$UP3<
!$)= 2/fi
2) ) )=O%
f
$@'B )
fi#!V fi#9[ ?1Sd ffb) \ &%d $#!
fiEfi!
1fi#)Cyzm&%#)KUE
9YU*d%
aM)'Bfi!
\&%d$9<M
fi!
1fi#!m $ B&%
B#)" '@'B ff8 3
%8 ff'@
2pCDE%d<
!$)J ffi!
)) )" XU%%m$ ffBUE
)
!O$ ff+ P
%K ff'@
!MUP$)$!13!M&%=<$# ff)) # ffpC
l ffP
%M 2N : )Y
%K
&
) TU
2)W
ff'fi9M##5!
B&
!?s.v@xo)



B ) !hs$ua@xo) CoE; PO%
&
BUE
)E)O<fi#! @!<=&
!d
)E) )YSU*4&%
ff < 3&%B&
!!d

M19:&$ !dfi!
1Sfi!3 $ $)=) !d #) @fi#fi#)@
!Kb$ ff'
K MffF #) CBl ff
#) @fi#
fi 90Y0
h##
fiP ff1) $
# ff3UW% ) Bfi
2) )=UE
) ff@ P&%
#j6M<$ ff1fi#'@
2 #W<
!$)/%
@

9Q%
E 21!B ff < 0Cnl ff0A
'@<fi#Y&%Pfi
`
R '@
!"
@!) &
.$ 'fi!
) )E"s.1
$ff$ ffxo%
)E

9%
1!"%
K
fi!
) )uuts)O% 1)*
K1
$Eff> ffxYff
"
B!) &
Eb$ ff'Qfi!
) )uuW%
2)*

9%
E 1S
%
5 :fi!
) )tSff
C T) !XO%)B'B&% 5&%M<$&
@ *O%" !$@&
!3) O%
=UE
)
ff < d'@
a9G1Sfi#) )WO%
;
9; ffP'Bfi# 7`bfi
2) )f<> ff1fi#'B)f1S
) 4 fffi#9M) ff'B<
!$) fi!
) ) )

$4 ff) #$5<$ ff1fi#'@
2 #CfDT%t
&
2fi<$&
= * #) B!:&%= < :&
!!M
&

#)f>< ff$M&
1fi#)&%
E<$) E&%4A^<S$!'BO
fi$)&fi# )aC
l ffP
%d )=fi#fi;YpUP= ff'@<
$d&%B

=<>
2
9M Rfi!
) ) 76$)&
!

) !B6fi# $M$)&)E6fi# $M
&
SCl ffR
2H%J &% K )P&%
E'@
V2W<@O%=


)
; ffz`;; fi#@$ ))$`bI
fi##
# ffK 6fi# RO%W ff < @!) &
)/b$ ff'QO%W&
!B

CDg

) )) )P&%=
1#fi#$9M n&%) !fi#O`_
fi# ff$#&%'Y'@
2]_ $#_9@
) )&)T6fiE'B&% )E B#j;9
&%B ff < 3)&
)=UP4&%3
:
%d 2/&%Bfi
!X
fi# ff>O%'B)$UE#+ *E6>) f):&%
6fi# $3
&
2) P&%d) !@O%6fi# $:
&
) aC


fi

'e



jl_` X



pr v+hsvc%q+mr qhr pm6n++v+v5SIb

# "!$

Wa gE`b

H% ) "O%$MUPfifi7`_V UWm
fi# ff$#&%')=b$ ff'k&%M'@
%Mfi#

8) &
) #
fi*<

K
$ ff'@'B# #) B; ff '&%r6fi# $)(*o#) # ff:&$)Y
$) %ff1S ffEfi!
)) 76$)=

fi#!
='@
2H%!)C @$)&$#&%@<$) &
# ff: P ff'@<!$#
fiP$)&fi# ) M&%)tO%$@
fi# `
$#&%'B)R %
E&%Pfi!
$#$9= p ffR<$) &
= 2&%E'B&% @
B =$EO%'B1n
&
1fi#)/<$) 0C U*Y!B
# # ffB EO%*A<>' )/>< ff$0Y U*P
fi#)
A<>' )
UE#&%6B1
) Bfi#fi/
fi# ff$#&%')sO%=&%$B!:&%#)=<
<<fi!)=a`_,
Z 3q=Ds;P$ fi#9X
i/Y/uavvx xC"=>)&fi# )4+ ffr&%K>
) 8) B Efi
!h
2fi ff$#&%'B)B)&% UP5&%@)O
'B
&$)
)E&% )=$< ff> M!M&%#)
$ #fi#C

RX+_`_Aj iXjAF $g,{`hjjdxd$`hjljC #)"#&%J
3fi#
ar &
2!m
:fi
2) ) 76
# ff
ff
c
&$!1 B )YpUE#&%:; ff
%3I
2fiJ E&%@
&$!1 Yn
M1
%3
K#) # ffc&$C@Dg
fi!
) ) 7;9X
K!)
@) !G
J#) # ff:&$Y ff4) &
> )W
EO%t$ E ff@
6)WO%t1
%
ff >)&< ff!m c&%d
fi!X 2=&%d )"
&>1d ff1) >[!mO%d!) &
CQDE%#)d<$ ) )
$<S
)"
B&%M)O1&$d$
B&%
@1
%m #fiW
:fi
ffM#)"$
2H%0CmDE%M!) &

#)"O%m
) ) #ff\&%Mfi!
) )@fi!
1SfiW &%Mfi#
a>C\dUPfi#fij`_V UW[
<<$ ff
%8 3 ff) & !?

#) # ff8&$J)4 Mff$ U,
&$" #fi/
%3 P&%@ 'B!
fi* )dsfi#
)&x ff&
!3!) &
)
b$ ff'
@) !fi#@fi!
))t
:&%5< @1
VM&%4&$BUE#&%:&%B ff1]$ #B R6!dO%t)O1&$
UE#&%\&%3fi# U*)G'B#) fi!
)) 76
# ffQ
CK!'@<fi#'B
2fi ff$#&%' ) )dPCj)"<
'B&% MUE#&%:
B ff6Bfi#fi0 /C!uMs;!fi!
pYnuvvxC /
Dg ) fi#/
E )0; ffn
W P&%/&>Y U*oH% ) o&%P ) n&%
R'@
A!'B#-)R&%P; ff 'J
# ff`
ff
!8
# 3'B&$#5s;!fi
pYEuvwxC"4!'@<fi#'B&
# ff8) )=&%M'B!!'t''B14 E!`
) &
)E 4+ '
B ) = 1S=L
fi0 B$UP
C W#
$!
4) dO$=
fi# ff$#&%')W$L>
&%

%@ )*%

#) $ ='B1o ff'B)CRDg t'BP&%#)E$L!$'BY
%@ $$
;
&$u
k]n#)f'J
<<M @
B)* 2N ff$$+
2&$)E19J6!G
4) ff fi
K ) )E 2&%
; ff
' k]" YUW%$<
T#)*!&%W 1) $d
f
"#)W
4W<S !P
w] CRE
fi# ff>O%'6)
&%4I
fi!B G
&%
W'@
2Aff!'B#-)&%4; ff 'J
# ff`bff
!:
# CPD0 K&%#)0Y&%4 ff1) $dI
2fi)
; ff
k]p
$P) ff> 0Y
B&%E'B#< ! )E1$UP4fi
2) )*1S ff
$#)*
$PI
fi!
3s;!fi
pYuavw
l
a99ff
M,yz
;Y0uvvxC
ZT]j_`hj$6-]j+#ZK2<g]`d-ffF a_1$($hED4j ` s+q=
"

$aYuvxT)B
K) 8!) &
)Y

%Bb$ ff' ff N'fi!
) ))Y&%
P
$) 4fi
2) ) 7+9d
"fi!
1Sfi3!) &
=
ff$!B B&%
'@
2]_ ff>$9fi!
) )j6
2 # ff@ 2O%*!)
)kB
$) P%ff1S ff$)C/yzB&%#)/$) # ffB p&%W
fi# $#&%'

%8!) &
M!8&%M&
!c
&
3<$) 3&%M
fi# ff$#&%' )K$&
!0CmD0 3 'B!
&%K#) &
M1$UP?
:<
! E!) &
)@UP"
<<fi#95&% 3 fi##
8#) &
M'B&>C:ybc ff
A<$!'B u
) KU
2)E) E B ffC

)
J) W 2(fi!
#) >'
r. # ff)O%
W
$B) fifi#O`
#fi#9d G
)) #ff3
:)&
B K ffB /&%fi!
) ))"s;E#fi#) ) pYRuvwxC Z u1K
M!) &

) $!< # ff3s;
<
ff xn ff)) != 0
ff) &
EuE
B&%W;
&$)R&%
2R) $!1&%
!) &
CoDE%@
2H%J#) $!'B!
P.
t] 3xR%
)P&%E; ff
' ] ?YU%$
o]0#)E
4 ff
WxuB ffOK )C fi#!
@'J
H%!K!+$)B!) &
ff
1fi# ff)B Mfi!
)
) _T7W
? fi937




-!_1F+Xi]j



Ej_`

a1=0.IO;0n + 7 $_I;gbzjoIbEOz;j*z;Ij$&;$IOj Ipz bP$o2$;&zbO;
0a&PI$<a IabEp =&oIIobzjOj jM$$zt P;a t$( zI$Tj_Oz0 @I
j$&z j;o=IRa&;a

'

fi

#) Z fi
&
fiT #)
uO`_
E
el
3l
Pl
E
Z
el
3l
Pl
q`_Dn$
E
el
3l
Pl


Cj
CjuCj
CjuCj
Cj
uCj
Cj
uCj
Cj
w Cj
vC!u
u uCj
vCj
uCjv
Cj
C!u
Cj
w uCj
Cj
uCj
Cj
uCjw
Cj
Cjw

n+o+pqrbsm,Xn+r pq


Cj
CjuCj
SCj,Cj
SCj
uCjw
SC
uCjw
SC
,Cj
vSCj
uCjw
SCj
uCj
vSCj
,Cj
SC!u
u uCj
SCj
uCj
SCj
,Cj
SCj
uCjv

u
wSCj
uCjCj
wSC!u
u C!u
wSCj
w uCj
wSC!u
u Cj
SCj
C
SCj
Cj
vSCj
C
vSCj
w Cj
SCj
Cj
Cj
uCjw
SCj
v uCj
SCj
uCjw


uCj
wCjuC7
C
uC7
Cj
uC7
Cj
uC7v
wCj
C7
Cj
Cu
Cj
w C7
Cj
C7
Cj
v uC7
Cj
C7
Cj
Cu
Cj
uC


uCj
SuCjv,C7
Cj
w ,C7
Cj
uC7v
Cj
,C7
wCj
v ,vC7
2Cj
,C7
wC
,C7v
2Cj
C7
wvCj
v uC7
vCj
w ,C7
vC
,C7
C!u
u ,C7

ff
vSC
wCjCj
Cj
Cj
Cj
Cjv
Cj
v Cj
wCj
w Cj
SuCj
QCjw
SuCj
C
Cj
Cjv
wCj
Cj
SuCj
v Cjw
Cj
C
SuCj
C!u


1fi#BA*/Pfi!
) )j6
2 # ffd

9@Kfi
P



mm;

aN_bxZ+]>sXx 3xCnl ffo&%=
$
) )TUW%#H%+]_s 3xa 3x*


1#&
$9@#) # ff
#)f'J
+R
* ffP!'@<fi#'Bb &
/
Z % ff ))E&%=)O'@
fi#fi#E _/
b !M&%)
) )C

Dg :6[&%MUP#ff% )@ &%Mfi#
M'@
%MUPd) :&%M&% 'J
fiP&
!!? fi#s.*> fffi#9
i/YEuvvxCc $"'B 76
# ff 5&%#)"<$ $ms;P$ fffi#9YuvvxB
$) ))@&%
<$ ff1fi#'O%
/&%UP#ff%)R; ffG19@&%#)Wfi<: ffJ&%W $R!KUW%#%K&%W!)
)E
$
<$) 0
E<S ff 0 ff>$!W
fi#
4 W
r!

ofi!
) ) 76CRDg W'B!!'B#-E&%#)N<> ff1fi#'MY &%
&% 'J
fi&
!K<$ ff>)
<<fi#: J !'B)Y) !"
r7i>E $$!4+ ffo&%!) &
)

%8 !'BCmDE%#)"<$ )" Z m)aY/
%cUE#&%m
37i0$J) B fUP#ff% )C8DE% Z &%

'@
A!'B#-)WO%; ff 'J
# ff`bff
!:
# "'BO$#=#)E&%H% )pC

'eE
c jAF gCCa#j+`bg,

1$($hEDGFb_Ag, ;
F+F `h_1Fbk

^a_

MDn
1fi#=UP)&% U[&%

29@; ffRO%Wfi!

&
4 0&%fi
2) ) 76$)T+ ff'B"19@
%@
&%P&%$
fi# ff$#&%'B)R) @) !t r6fiWs;T ffxY
) !fi#O`_
fi# $#&%'(6fiEs;el/x 0
'@
]$ ff$#$9
6fi# "s+Xl/xY
5
K ff) )&)r6fi# @s;Pl/xCpDE%46$) => IU$<S ff$ )&%@ #) K
B) 5
ff <W&%B

CWT 4&%
T+ ffT&%#)
&
2) WO%<S$&
4 /&%B>tO
!!M) &%

#)= ff < 3; ff=
)G
2 B
9cUE#fi#fi1S@fi#) )B&%
91
)" fffi#93) ff'"<
!$)= 2*fi!
) ) )

$B ff)><$ 1fi'J
#C@DE%"

fiN<S$&
@ 2* ff < 3&
!!d

K)B$< $
!M&%) ffX$ U R&%&
1fi#C
%5 3 #) @#)=!&$ 0Yn6fi# $!3# ='J
V @
M) #ff76
B7i>@; ff
9d
&%='BO% ff) ffK&%#)
&
) aCNe!B&% ff>
2fi

=#) Eff

@1B #) b$YUP
%
a" 3UE
a9d :I
fi!
MU%&%6fi# $!5!'@<> I)tO%d;&Bfi!
) ) 76
[

29h)
&% )E
&
B
aI
#fi!
1fi#@%$C

K #=

IR;j$$6@b zb0;PI/ jPj&;jIj;zNIz=Io;&Pnj$ ;aIj&;jIj0 ;_;
b8O=I"j;zR W " zjO;Iz
=

fi

pr v+hsvc%q+mr qhr pm6n++v+v5SIb

l ffn #) Efi#fi#)E<B UW%#B
&
b$ ff'
'@
2]_ ff>$96fi#
fi#fi'B&% )RUP$E
1fi#
@
$&
2fi# ) B&%!4 ^5$#&aff$a YUW%#H%UPO6= @14&%
P ff1&
2+ /O%
)
* #) @
3 K6fi$!Cl ff #) Bfi#fi#)= /
3ffMY^6fi$!d!'@<$ )

9
; ffR
fi#fi&%>W
fi# ff$#&%')YUE#&%J'@
]$ ff$#$96fi# $!@<_+ ff'B!=) fi##ff% fi#9"1 R&%
ff) )&)o ff
) !fi#O`_
fi# ff>O%'6fi# $!Cl P&%#)
&
)Y&%B1) fi!
) )j6
2 # ff3'B&% )U*>"uO`_

#) # ff8&$)aYN
2fiO% ffff%5
B
#) Kfi#fi/ 2
fi#fio&%$"
fi# $#&%'B)t
2H%#m ff'J<

1fi#


2)aCdyb8D
1fi3u8s) @<<#Ax@UP@)&% U&%M$)&fi# )B W
:<
!$7`b) = ff'J<
$!
T6fi# $!?s;T ffxP K
%M R&%6fi# >d'&% ff)aCEDE%B&
1fi#t$<S ff$ )&%B<`bI
fi!YpUW%#%
#)B&%"<$ ff1
1fi##$9?O%
=&%Jji0$M!c&%K_UP M)&
'@<fi#G'B
)=#)B" :H%
C 9 lR#ff$
M)O% IUT)=
Mff
<%d 2O%"

93
fi!))3
5uO`_
)=O%B6
fiRfi!
) ) 764 E&%B6fi# >

&
SCdE @&%
B&%J$Kfi
1fi#el$O;$)B d&%M$)&fi# )4b$ ff') !h
:) !fi#d
fi# $#&%'
6fi# ff) & Mff!
J&%)&
'Bfi#

fi# ff>O%'
)E&%6
2fi0fi!
) ) 76C
100

None
SF
MF
CF

Accuracy

90
80
70

60
0

20

10

30

40

Noise Level

lR#ff$=A*R
9K R&%fi!

&
r+ E
MuO`_=C
l ffp&%>/ &%*>'@
!!+ ffg
&
2) )0UPR)&% U5ff
<%)N>< ff$&%P

9
%
&%r+ ff*6fi$!d'B&% )s; Y) !fi#O`_
fi# ff$#&%'Y0'@
]$ ff$#$9G
ff) )&)&xT!: ffa]>
UE#&%:
B6
finfi!
) ) 76Yp)fih19M% ff )J; ffP
%M

) E&%@'B ) W

2 /&%4&%$
fi#
!
2fi ff$#&%'B)MUW% \UE#&%
c6fiM
UE#&% ffM!a]_ #) Cl ffJ&%:6$

&
2) YU*B% ) @ ")&% U&%@$)Ofi); ffW
K#) # ffc&$@1S
) K&%) @$)&fi# )B< ) )) )&%
fi!
$)ji0$M!5
2
951$UP:6fi# $!5
? r6fi# $!CMDE%Bbfi#fi/&
1fi#@ 2T>)&fi# )
; ffP
%K
&
)*
d1; ff::D
1fi)Bua`_SuW!&%f<<S#AC
l ffP&%B$#

XslR#ff>twxY&%4fi!
4'@
%!t#)=
K1 Efi#
!31
2)&%
M#&%
&%uO`_m ffg&%P#) # ffJ&$*
2)Rff#M19# )/%#ff%o1
) O`bfi#fi

29Gs;SCjE$)&)RC!u

MCjwxCyz@&%#)E
2) f
<<fi9!"
4) !fi#O`_
fi# ff$#&%' ff/'@
2]_ $#_946fi# ofi#
)E 4) fi##ff%fi9M1
$)&fi# )T&%

4 ff) )&)6fio+ * )=fi#fi#)f
1 MCnEE #) =fi#fi#) N
d%%Y
6fi# $!d
2) ) K'J<$ Bfi
2) ) 76
# ff5
2
9CEF )Yp#)Bfi!V fi#95O%
f
9M
&%P6fi# >@'BO% ff)o fffi#"!'@<$

9@1
) W!)&KW%#ff%BL
fi##$9@&
!!B
&

#)t
aI
2fi!
1fi#@ d1fi#m
3

=6fi# Ctyz0YN
2Wff #) Y0&%@) B E
K ff) )&)6fi#
9fi#)fi# UP*
2
9M$fi!
#= /6fi# >Y
)T&%=1!
) )E R#) # ffMO$)W
5uO`_fi
2

a1pI$;j _I$4b$j;IjK$ jzb$dIjoj;jB&gj$;;b;j.;ToIOPI;bO;$d &E
Ib$ ;$;nIO/tzj$ O;$p
O20 z;b ff
b$ Oz ffr;aIB;zt;jj$$O;@;j 0pj@Tb
Ibjj 4;Eb= ;_;g;_;$an O/Ojj&;$= R&; oIjtIO0 R;_;g;_;g bn zb z$
p

fi

n+o+pqrbsm,Xn+r pq

100

None
Self
Majority
Consensus

Accuracy

90
80
70

60
0

10

20
Noise Level

30

40

lR#ff$=wA*W
29" R&%$#
&
4; ffP
Bfi#!
'@
%!C

100

None
SF
MF
CF

Accuracy

90
80
70

60
0

20

10

30

40

Noise Level

lR#ff$=A*W
29" R&%=$
M) ff'B&
K
&
r+ E
B#) # ff:&$C

100

Accuracy

90
80
70

60
0

None
SF
MF
CF

10

20
Noise Level

30

40

lR#ff$= R
* W
9M &%4) =)ff'B&
# ffJ
&
4; ffP
MuO`_4C


fi

pr v+hsvc%q+mr qhr pm6n++v+v5SIb

&%B'B&% X "fi#!'B!
"'J
9M ff d!) &
)"sUP=UE#fi#fiRA^<
d&%#)=< UW%:UP=#) ) )
&% > ffE
)* 2N&%6fi# >)W!de MCjSCjx
lR#ff>)dm
5)&% U&%5$)Ofi)M t&%5$
) ff'B&
# ff\
) 3) 'BO
# ff
$)&<S #fi#9C*DT%) W$UP
&
2) )*
$E) !'B#fi!
P!J&%
/O%9@UP$Efi!
1fi#3) !tO%W)&
'BE)O
fi
fi!
1fi#!M<$ ff))fs) >1SM!"e # ffJC!uCjxY1oji0o!@O%P+
2&$)*'
)&$"
"&%T)
fi!
)) )CRl ffo&%=$ ff
K) ff'&
2 # ffK
&

fi#fi0&%$6fi# >M'B&% )E<z; ff ' ff'@<

1fi9

3!:
H%
) B)&1)

2fifi#9:'J<$ @

9d$fi!
G T6fi# $!Cl ffP&%#)

)
) !t
#) # ffJ&$E
)R
T6
fifi!
) )j6o9#fiK) fi##ff% fi#91S R<Sz+ '@
EO%
B
BuO`_W\

UPB)&% U,$)&fi# ); ff&%#)='B&% 0C=l ff&%B) @)ff'B&
# ff:
&
SY0
duO`_UE
)f
K)fi#ff% fi#9
1 6
fifi!
) )j6T
)P)&% UWB!MD
1fiBuCnl ffR&%#)P
&
2) Yff
2* #) fi#fi#)E N,
Kff
&%W'J
]$ ff$#$96fi# P<z; ff ')*1 R&%
@
%B 0&%T &%$)P
G>&
!)*1
)O`bfi!=

9"

#) CPDE%!'@<$ 'E!:

9J.> ff'(6fi$!@; ffP
%K O%) =$UP =) 'BO
# ff

&
2) )=
?1SG
&$!1 8 d&%!4fi!
) )B) <

1#fi#$9C5e<76
fi#fi#9ffYP#B#)@$fi!
#fi#9?
2) 95
)&<S W fi#>)f1S
) B&%$4 /&%;
&$)!d
2H%
&
) 'B
)&$ fi
X'@
9K /&%
fi!
) ) )
$UPfi#fi7`b) <

2 d!M)O<&
2fi0)&<
C

Accuracy

80

None
SF
MF
CF

fi70
60
0

20

10

30

40

Noise Level

lR#ff$tv
*
9M 2N&%6>) $#$9"
2&
4; ffP
B#) # ff:&$C
DT%W$)&fi# )o; ffR&%T6$) $#$9B
&
)/7i0/)O1) &
!
fi#fi#9B.> ff'&% &%N+ R
&
2) )C
lR#ff$"v)&% UE)&%">)&fi# ); ff&%@#) # ff8O$"
fi# ff>O%'
$ ) )4&%@) #A5 #) @fi#fi#)Cl ff
&%#)=
2&
) YS6fi# $!d!'@<> I)fi
2) ) 76
# ff5
2
9:+ W )CtP
2fifio&%
#) @UE
)
!O$ ff[
'B ff3fi!
) ) )@a`_Yo1 t!8fi!
) )MuC58fi# )=!) #ff
2 # ffpYRUP"#) >
&%
KUW%
<<fi#986fi# >\ 8&%d ff>
2fi
&
) 3s;
#) xM
fi!'B )
fi#fi =&%
!) &
)b$ ff'fi!
) ) )=I`_@UP$4&
3
) #) 9X19d
fi#fiR&%$r6fi'B&% )CD
1fi#BM)&% UE)

'@<
$#) ffh E&%"#) O$!1 # ff8 E!) &
)B!5O%@ ff$#!
fiP
&
2) =
8 E&%@!) &
)
fi#O+=
I+
K'@
]$ ff$#$9@6fi# %
2)f1S5
<<fi##0C BA^
'B!XO%')fi
2) ) 76
# ff5'J
&$#AM; ff
&% ff$#!
fip
&
B
J; ff"O%
*
1S ffE%
fi7N 2O%W > ff$)E$)&fi# J.> ff'fi
2) ) 7+9!@!) &
)
fi!
1 fi#a`_5
2)@fi!
) )dud
m&%d O%t%
2fij=UP$Kb$ ff'fi!
) )j;9mfi!
)ff
) 9
)Bfi
2) ) YoUW%$
9
5 9 SCET+ 6fi# $!Yp&%B

) E ff&
!)=
K<$<
B /!) &
)
1fi# ffm 5fi!
) )5uCeH%\
[m#) &$!1 # ff ffi!
)) )G>)&fi# )M!mfi!
) ) 76$)d1!
)
UE
$fi!
) ) 7;9ff!$9!)
*
)nfi!
) )PuYUW%#%4r&%/ $#!
fiff#) O$!1 # ff4 ^O%/!) &
)
s;'@
2&
!K!@&% ff < K ) o!) &
)&x#)> ffff%fi#9@MCRyb&$ !@'B ff$W )W!
fi!
) ) )=I`_K8 W%
B&%#)=1S%
# ff=
XO%$O+ $YO%
2
9d>)"s) BlR#ff$@vx











fi

$#!
finq=
&
)

5
]$ ff$#$9tlR#fi#

u
ffuCj
vSCj

n+o+pqrbsm,Xn+r pq


Cj
Cj


C7
uwCj


u Cj
Cj


uSuCj
C

w
Cj
uCjv


vCj
Cj


Cj
C!u

Dn
1fi#=1*EPfi!
))E#) &$!1 # ffG+ ffo&%6>) $#$9@
&
2) PUE#&%M
MUE#&% ffo6fi# $!M


: )

#)



au






Z
XP
E ff
Pl
uCj
uuC
SuC
uvC7
SuCj
uC7v
ffSuCjw
uvCu
C!u
C
ffwCj
wC7

E$#
ff
Pl
wSC!u ffSCj
vSCj
SCj
vvSCj
SCj
uuCj
SCj
uSC
vSCjv
uwSCjw
SC!u

P ff
2
ff
Pl
uCjv
vC7w
Cj
vC7
uC!u
vC7w
Cj
uuuC7v
vCj
uuC7
ffCjw
uC7

e
E
Pl
ffSCj
ffCj
vSC!u
ffCj
uaCj
uCjv
uaCj
wCj
Cj
vC!u
C
uuwCj

lR!$Be$#$9
E ff
Pl
C7
uaC
wC7v
uaCj
uC7v
uaCj
wC7
uawCj
v Cu
uawCj
vC7
uaC!u

Dn
1fi#tA*/Dn$) #-rGff'B1SE Rfi#
a)
$'@
2r
R
$ ) )N
2fifi #) Pfi#fi#)C/yz=O%*O
# # ff
fi) / 2&%#)R
&
) Es;<$# !r6$/>)&)
M6>x=

2)B ECjwU*>@ ff1) $3+ $ff$) ) 5<$# # ffpYRUW%#fi#K; ff&%@&
2)&VM
<$# !3fi# IUFs>uO`_x$)O)=%%5$#)&V:
a9ff)"s2`_xEO%
2
93UE
)fCjs;) fi/q IUPY
uvvxC/yzd)O'@'@
$9Y^+ ff&%#)
&
) aYUP ffa]_O$=&%
2W#&%T&%;
&>)f
>
2L^

#) $!'B!
fi
2) ) )Ea`_Y ff&%Efi!
1Sfi)TJ&%E $#!
fi

ffO
!"
ff>W p)&1]$ #ff#$9
&%
E'@
V )E#W!'@<S ) ) !1fi#B @$
2 =


2 6fi# C

'e
c jAF gCCa#j+`bg,$`hjljv



j

<<fi9!:6fi$) K&%B&
!!d

@fi#
)4 ")O1) &
!
fi#fi#9X)O'@
fi#fi##) # ffc&$)C=Dn
1fi#@
$<S ff$ )P&%ff'B1SP fi#
a)P!K) M&$)E<$ Kb$ ff'&% ff) )&)P6fi# >d
M&%
6fi# $M

C ( l ffoa`_ #) Y&%T6fi$M
&
r$
)P&$)PUE#&%;U*fi#
)*O%
@O$)
) !'@
2 :.$ '&%B ff$#!
fin
&
)CEl ffEO%t$ ff
2d) ff'&
2 # ffd
6$B) $#$9M
&
2) )Y

4ff #) Yo&%K&$)@<$ mb$ ff'&%J6fi$m
&
3%
aJ+UP4fi#
)@&%
c&%
ff=<$ Mb$ ff'&%4 ff$#!
fi0
2&
) E
E )C/DE%#)WOi0PUE
)W
fi#) B ff1)$d1ff
9 % %
s$uvvx

&>1? *
4
=
1#fi#$98 X$' I5 ffb) !3!) &
)Bb$ ff'k&%
&
2!5
2&
Yn&%$19?$!8&%")-M 2W&%Kfi
[#) # ff &$)C3
)@

%)
s$uvvx4)&% UPm'@<!$#
fi#fi9&%
2B+ @'@
9?
2&
) )J&%$M#)G
cfi#!
">fi
2 # ff)&%!<1$UP
&$T) #-W
@&%ff'B1 0&
!!=!)
)R@
ff'Bfi#9B!$
) !B&%W'B1 &
!
!) &
)/%
2)R&%POin !$
)4&$P) #-E4UW%B< !4)/
<<fi#0C # DE%!R

fi#9ff))
P
4H
4)&% UE)WO%
WuCjw *&%B$
2) Bh&$=)-J)B
&>1O
1fi#t G$



ff

"!

$#

%

a1pIb$j;/ b$4 ;$;$O/ ; IoIb/ j$ O$RpjtIjIIaj;z;Ia^ 0nIORI
'& zbzI$o=_O;$&;j0jI$/O0P$&ab_O0 n)( j$Oz!
1pjgbzj&jIa@O I;o j;P bOI$b_$ ,IO/'& bbzg;aIP$I$
'

fi

Training
Instances

Training
Instances

Training
Instances

pr v+hsvc%q+mr qhr pm6n++v+v5SIb

* * *
* * ,*
* * Filter*
* * *

Correctly
Labeled
Training
Instances

-

1 1
1 1
1 14
1 31

Filter

+

Learning
Algorithm

Classifier

/
/

C1

-.

Algorithm 1

C2

0

Algorithm N

2

Correctly
Labeled
Training
Instances

5

54

Algorithm 1
Algorithm N

Maj
Vote

CN

6
6

C1
C2

7

Maj
Vote

CN

lR#ff$@u
* 3 fi#)W ff'J<
$
&%) # -W 2&%E&
!J) CRDE%$'@
!o#)EW =&%$'B
2fi !+ '@
#!) &
)
s; #) xC
Q) ffMO$d!MO$) #-=#)
<<
$P&%t>)&fi# )W<$) ::D
1fiBA*R
)E&%= )
fi#fi!$
2) )P&%E) #- 0&%E&$)+ 'B4.> ff',6fi# $K
&
$ UE)/'B ff$TL^#Vfi#9@&%
B&%
) #- &%T&$)n; ff 'B4b$ ff'6fi# $K
&
CnDE%#)*$!; ff$)P&%PUPfi#fij`_V UWK<% ff'B ffJ&%

#) @!:&%@fi!
))fi
1fi#)=!$
))=&%B) #-@ E
@#) # ffc&$Crf3A< # ff3 "&%#)
fi
&$K#)E ff1) >@; ff&%6$) $#$9@
&
2) CT &%
o; ffRO%)T
&
) aYff

29"
K&$
) #-M
$"
<<> IA!'@
fi#93 ff)
=
2$ ) )
$# ff)@ #) @fi#fi#)CdDT%)B$)&fi# )@1
) @; ff
%
fi#fin N #) 4&%='B&% d&%> IUT)* W
fi!'B ) T&%)&
'B)O1) E R&%!) &
)aC

'e8:9g1iKEj ` $ ,$Haj `biK
%9< O%) #) N! $) T)UW%&%
@'@
2]_ $#_9J ) 'B1fi#tfi!
)) 76
M1B) d!)
2
R6fi# $!CBDg " )W&%#)=%9^<S &%) #)4U*r+ 'Bd$UP M'@
]$ ff$#$9" =)'t1fi#@fi!
)) 76$)(* ff
b$ ff'&%46fi# $?
5 ff4.> ff'F6fi# >?

CtDT%'J
]$ ff$#$9M 4) 'B1fiK) $)=
)&%
*a# & *n
" P
)/O%E6fi# s;
)o)&% UWB!J&%f1S 'Q_UP 4) H%')/<# M!KlR#ff$
uxCNDT%=$)&fi# !Mfi!
) ) 76$)UP$&%M) : @fi!
) ) 7;9M&%= ff < )E
&
C
DT%"$)&fi# )4; ff&%@fi!
8


$B)&% UWh8Dn
1fi#GwCKl ff
%5 E&%>"'B&% )
;s ffY 5
]$ ff$#$9W
@P ff))&)&xgU*o ff'@<
>/&%P

94
'@
2]_ ff>$9 ofi!
) ) 76n &%
uO`_\fi
2) ) 76YUW%#H%J#)/&%'B ) /

E p&%E&%>W1
) O`bfi#fifi
2) ) 76$)o+ R&%#)/ '@
!pC
DE%&
1fi!fi!)&%<`bI
fi!) R
t<
2>M$`b ) P @
) )) )P&%) #ff76
B!K&%7i>
; ff1S$U*c&%M'@
]$ ff$#$9dfi!
)) 76@
uO`_W fi
2) ) 76C5DE%M'@
]$ ff$#$9d @fi!
) )j6)
'@
K<3
cuO`_=Y0
) 5&>"
?
Kfi#!
B'@
%!C @# =)"
9XUP#ff% !
) %'BT+ ff ff'B1!J&%!/ )Cnl R
%B6fi# >B) %'BY&%'@
]$ ff$#$9= Efi!
) )j6T%
)
L
fi ffR1S

9B&%
&%tuH`_W\fi!
) ) 76oUE#&%BO%EAff< K #) fi#fi#)P a`_
; ffP&%B'@
]$ ff$#$9B6fi# CoEEfi# UPE #) =fi#fi#)"s;I`&u@x6fi# $!M )f %
=
Bfi!
$4'J<

ff3O%
2
93 *O%"'@
]$ ff$#$9d Bfi!
) ) 76C UPY0
=%#ff%B #) Jfifi)ds;a`_@xY
1 &%3'@
]$ ff$#$9d
5 ff))&)6fi# $!3'J<$ B&%@'@
]$ ff$#$9M 4fi!
) ) 76)@

9d
&%
P ff1O
!dUW%: B6fi# $!G'&% ff:UE
)E
<<fi#0C
'

fi

E #)
Z fi



u



ff

E @lR#fi#
uO`_
SCj
Cj
uCj
wSCj
uCjv
wSCj

3%
Cj
wC!u
Cjw
C!u
Cjv
SuCj

<
SCj
SCj
SCj
SCj
SCjw
SCj

n+o+pqrbsm,Xn+r pq

h
2]_ $#_9BlR#fi#
3%
uO`_
<
wCj
Cj
Cj
Cj
Cj
Cj
Cj
wCjw
Cff
Cjw
Cj
C!uu
Cj
Cj
Cju
Cjv
Cj
Cjw

ff)
3%
C!u
Cj
Cj
C
Cj
Cjw

)&)lR#fi
uO`_
<
Cj
Cff
C
Cff2
wC!u
Cj2
Cj
CjSu
Cj
Cj
Cjv
Cj

Dn
1fi#twA*oP ff'@<
>) ffK 06fi# $!M B !B"fi!

&

DT%f$)Ofi)P+ /O%=$'@
!!@; ffo
&
2) )*
$)&% UWJMDn
1fi#)a`_r&%f<<SApC
yb8
) ?s$#&xY*
8!#
2fi='B&% sfi#
"'@
2H%!xBUE
)@'B ff>G

M&%
pY ff

<<$ A!'@
fi#9@L#I
fi#W Y&%'@
]$ ff$#$9= Efi!
) )j6*+ ff$9B6fi# >K'B&% 0CRl ff&%
&%o&%>W

) )Y&%'@
2]_ ff>$9B Wfi!
) )j6U
2)* "

2W1 o&%
K&%) !fi#t1S)
fi!
) ) 76C 3 Afi!3&%J) @) ff'&
2 # ff:
&
Y0
<<fi#9!X
d'J
]$ ff$#$9" ff ) )&)6fi#

M&%M1#fi#!d
4fi
2) ) 76W)K&%) !fi#t1S) W
fi# ff>O%' ff&<Sz+ 'BM
@'@
]$ ff$#$9B
fi!
) ) 76UE#&% P6fi# $!K+ E #) =fi#fi#) Eu
X%#ff%C 3 Aff<T; ffP&%= #) 4
)
; ff4&%d$ ff
[
m) M) ff'B&
8
&
Y/
m&%d
) K; ff4&%M) :
&
Yn6fi# >
!'@<$ \&%X

9m &%X'@
2]_ $#_98 Mfi
2) ) 76K @ J6fi# $!Cyz[
# # ffpYT!
'@
93
) )ds;<
> #fi
$fi#9
B%#ff%@ #) Mfi#fi#)&x46fi# >8
<<fi#mUTO%8&%G1S) B!#
fi
fi!
) ) 76T ff1&
!31

#)&%

<<fi#9MO%='@
]$ ff$#$9B fi!
) )j6T @6fi# $

&
SC=DE%) Bfi!
) $UP G>)&fi# )'B ff)
B&%
T; ffEO%) @
&
2) )Yp'@
]$ ff$#$9K Bfi!
) ) 76$)

$<fi!
6fi# $!C

'e ;



<

Ca j `

AF $ ,

`j g

Dg G
)) ) )&%46fi$)p
1#fi#$93 @# 7+95'B#) fi!
1Sfi8!) &
)aYpU*4A^
'B!5&%=! $)
1$UP4&%P) n !) &
)o&%
nU*>/ ff < @
=&%P) R 2)&
)R&%
nUP$/O
B
)
'B#) fi!
1Sfi0CPyblR$EE&%#)o)RO%
$

CRDE%E$)Ofi)R &%#)/

2fi9) #)n; ffn&%Pfi!
`b

&
J
$=)O% IUM!dDn
1fi#@C 3
%d> IU&%=O
1fi#>< ff$)E&%t

P&%4 d)W
&%ff'B1SP 0!) &
)E#)
$d19J
H%J6fi#


Y&%'t1SP 0!) &
)
ff < ?!8&%M
2&
Y/
8; ff
2H%h6fi# B&%Mff'B1SB W!) &
)@!8&%"! $)
&%M) K ff <
2&
5
m&%:) @ #)
$

Cmy;
fi#fi#9&%M) @ !) &
)
#)
$c)&% fffi#3 ff'@<fi# fi#93 $)&%=) * #) 9:!) &
)C4eJU*B'@
a9G%
aB #) 9
!) &
)P
G
1 E&%'t1So
$ 76!
fi#fi#9" ff < K)&
)PUPE
EV IU\&%

=ff'B1SC@DE%$O; ff$B!3&%#)t

fi#9ff) #)4U*@
<<> IA!'@
B ff
2fifi!
)t 2<$#) # ff819

) )O'B!"&%
2E&% fffi#9d #) 9M!) &
)f
>=&% )&%
EUPA<fi## fi#93 ff <0C*yzM&%#)
)
UPWUP fffi#Mfi#!V &%! $) # ffM1S$U*KO%W!) &
)E#)
$3
"O%)&
)E ff <
313uMCMyz?<
2 #"UP@) K&%
4&%#)B)@ 4&%@
)CdP)&fi# )4; ff&%M$'@
2!:; ff

&
2) )E
$#!dDn
1fi#)fwI`_v4 NO%f<<SApC
yz@Dn
1fi#)I`&uUPW$< $/) 'J
)/ 2O%W<$ ff1
1#fi## #)E&%

%46fi# /'@
V `
) HKuE
ff
HB
$ $)
C \@is H"uaxE$<$) )&%B<$ ff1
1#fi##$9X 2/&%$ UE!" W X
2&
@
3
31B) 'J


)(*

>= ff?

?A@)B ?CAB ?ADEB

=

'

fi

E )
Z fi


u



ff

pr v+hsvc%q+mr qhr pm6n++v+v5SIb

yb)&
)q)
$

?F@GB

wCj
C!u
vwCj
uuvCj
uCj

?wCFvCjB ?FwDC7B

wwCj
vCj
uavCj
uuv Cjw

C7
ffwC
uC7
C7w

yb)
)
P ff < ?s5x
uwCj
C!u
ffCj
wwCj
vvCjv

yz) &
)E!:yb $) # ff


vC
uCjw
uaCjv
uCj
Cj
wCj
Cj
ffC!u
Cj
wCj

H?A@GB


I?CAB

H?AvDEuCjB v
uCj
C
vCjw
Cj

Dn
1fi#tA*EDE%) #- 0&%! >) # ffK 0#)
$d
G'B#) fi!
1Sfi#X
2&
) )`Nfi!
K
&

s;e
l auH`_Wx

#)
Z fi


u


ff

efi7/lR#fiPXuH`_W
\@s HKux
\@s HBx
C!ua
C7
Cj
Cu
Cj2
C7
Cj
C7
CjSu
Cff

5
]$ ff$#$9tlR#fi#
\@is Htx
SC!uw
SCj
SC!u
SCjv
SCj
SC!u
SCjw
SCj
SCjv
SCj

ff) )&)ElR#fi#
\@is H"uax \@siHtx
SCjw
SC!u
SCjw
SCj
SCj
SCff
SCj
SCj
SC!u
SCjww

\@sHKux

Dn
1fi#tA*lRfi# <$#) # ffG`*fi!




\@siH"uaxRa

? _KJMLNPOGQSRTQVUffEWRTOGJTRMLXW ? = ?
Y>Z W[NS\p^] Z OGOG_a`bWRTQ
>Y Z W[NS\p=

\@sHBxP$<$) )T&%=<$ ff1
1#fi##$9d /V <!G1
2M
&
@

M1=) !'@
3
)(*
\@sHBxa

] Z OGOG_a`bWRTQ4cUffEWRTOGJTRMLXW
] Z OGOG_a`dW[RTQ



= c= ?
=

l E&%4fi!
`b
&
Y&%$B
$@wds;v *vxP &
2fi0&
!!M!) &
)aCfDT%$O+ $Y

; ffE
B #) =fi#fin /
dO% ff) )&)T6fi#

\@sHKuxa

wAj5vu+7v

wmuwA7

7w

\@siHtxRa

uawAj5vu+7v
uA
w j

u




Dn
1fi#)a`&uB)&% U)'fi!
O$)CPl P&%) 4
&
) )Y&%B$)&fi# )T+ ff&%= ff))&)E6fi#
)&% U,O%
&%"<$ 1
1#fi#$95 E&%> IUT: ff= ff 5
&
M>'@
!)B)&'@
fi#fiRh+ %%t )
fi#fi#)Y#fi#fi!) &
K&%
P&% ff) )O)P6fi# o)T ff) $
#!K#)
$!@

CRK&%W &%
'

fi

#)
Z fi


ua





n+o+pqrbsm,Xn+r pq

efi7/lR#fi# P Z
\@s HKux \@sHBx
Cu
7C
Cu
7C
C7
7C
C7w
C ff
C7
C ff

h
2]_ $#_9BlR#fi#
\@s HBx
C7
C7
C7
C7
C7
C7
C7u
Cffw
Cff
C7u

\@sHKux

P ) )&)lRfi#
\@s HKux \@sHBx
C7
Cff
C7
C7
C7
C7v
C7v
C7
Cu
C7w

Dn
1fi#tvA*lRfi# T<$#) # ff`*$#E


#)
Z fi


ua





efi7/lR#fi# PKq&$
\@s HKux
\@sHBx
Cj
Cuw
Cj
C7u
Cj
C7v
Cff
C7v
Cj
Cffw


2]_ $#_9BlR#fi#
h
\@sHKux \@sHBx
Cj
Cu
Cj
C7
Cj
C7
Cj
C7
Cffv
C

P ) )&)lRfi#
\@s HKux \@sHBx
Cuu
C7
Cuu
C7
Cu
Cu
Cuw
C7
C7
C7v

Dn
1fi#"uaA*nlRfi# <$#) # ff`*$ ff
2M) ff'B&
# ffK
2&

#)
Z fi


u


ff

efi7/lR#fiPXuH`_W
\@s HKux
\@s HBx
Cjw
C7
Cjv
Cu
C!u
C7
C!ua
C7
Cj
Cff

5
]$ ff$#$9tlR#fi#
\@is Htx
SCj
SCj
SCjw
SCjv
SCj
SC!u
SC!uu
SCj
SC!u
SCj

\@sHKux

ff) )&)ElR#fi#
\@is H"uax \@siHtx
SCju
SC!u
SCju
SCju
SCju
SCj
SCj
SC
SCj
SCj

Dn
1fi#"uu*RlR#fiE<$#) # ff`*) )ff'B&
# ffK


#)
Z fi


ua





efi7/lR#fi# PKq&$
\@s HKux
\@sHBx
Cjw
Cu
Cjw
Cu
Cj
C7
Cj
C7
Cj
Cff

h
2]_ $#_9BlR#fi#
\@s HBx
Cj
C7
Cj
Cu
Cjw
C7u
Cj
C7
Cj
Cff

\@sHKux

P ) )&)lRfi#
\@s HKux \@sHBx
C7
C7
C7
C7w
C7u
C7w
C7
Cu
Cuv
C7


1fi#KuA*nlR#fiW<$#) # ffG`/6$)$#$9"


'

fi

pr v+hsvc%q+mr qhr pm6n++v+v5SIb

%
0Yn&%M$)&fi# )4fi#fi!) &
M&%
O%G<$ 1
1#fi#$95 W
ff) )&)46fi# 4fi# !X XV <81


&
4#)Pfi!
$o&%
J&%='@
2]_ $#_94 T6fi# )o; ffR
2H%M #) fi#fi0
> ) )E
fi#fip
&
) )CRyb

; ff=
3 #) Kfi#fiP EffMYn&%MPl%
)B
3ww s+fi
? xYw s$#&xYov s.$ ff
xYn
s) xYff
"Fs6>xnH%
$&
2!@'B#) fi!
1SfiM!)
)CRl ffn&%'@
]$ ff$#$96fi# Y&%
%
N'@
V!
HKuf
HB$ ff$)P#)W'B ff>WL
fi;C 3 Afi!!"&%>T
&
=
2* #)
&%M<$ ff1
1#fi##$9? E&%)" > ff$)tt>
H%)B
1 MCdP ff) #$!3&%
B'@
]$ ff$#$93
<_+ ff'B)t1S O%
3 ff) )O)=6fi# >)=; ff%#ff%B #)
)aY0&%#)=)O% IUT)=&%
=
ff) )&)
6fi# )E<$ <) #$9@ UE
$@'@
V!
Htr $ ff>)fs;$O
!@1
K
&
x/%!$)W<Sz+ '@
W' ff$
&%
4'@
]$ ff$#$9T6fi)nfi)) R
1#fi#$9B W>&
!4 ff =
2&
ts++CC!YI'J
]$ ff$#$9f'@
V )'B ff>`
HKuR $ $)&xC
DT%6$
&
)%
2)
$9@7i0$W<$ 6fi#CPDE%=<$ ff1
1#fi##$9M &%$ UE!@ * ff
&

$'@
2)B
fi!'B ) ) &
=
$ ))W&%Jji0$t )@fi#fi#)C"DE%#)4)B1
)@; ff&%#)=
2&
)
"!) &
)=
<<
"%
aB
"%#ff%:fi#fiR / #) C:&%= &%W%
0Y&%@<$ 1
1#fi#$9
&%
E
46fi# TUE#fi#fiN>&
!M1

2&
B$#) )f
2)E&%= #) 4fifi0!$
) )C
+y ff3%
)d
8fi# K

YP&%
\fi#I
H"u: $ @#)d<$ ff1
1fi9\fi#) )d
8%!

&%
:
Mfi#
PHB=$ ff;CC!Y&%> IUTK ffE ff

YUW%9 ffd%
aB
Bfi# )fi#) ) ) fi9
&%
:$&
!!X1
2d
&
SCWT* $) ffBU* fi:fi#V2@ K)O$B&%
ff=#)= &%$ UE!K ff
A< # ff)C

e f
'





SI



4









DE%#)E
$ #fi#<$) )*
<$ $T+ R#j;9K'B#) fi!
1fi#M!) &
)aC/DE%$)&fi# )/ 2g
B'4`
<!$#
fiRI
2fi
2 # ff3'B ff)&
:&%
T6fi# $!d!'@<$ )fi!
) ) 76
5

9+ E

) )
&%
< ) )) )fi!
1fi#!d > ff$)CPlR#fi# $!X
2fifi# UPX

#)=
E "&%B1
) O`bfi#!"

29d
13$&
! + ffJ #) dfi#fi#)M<m ?k+ ffJ
fi#fiE
&
) )YP
[<m 8k+ B$U* 3

) )
s&%B$ ff

d) 4) ff'B&
# ff
&
) )&xC/TA<$!'B ))&% U&%
2W
)E&%B #) Bfi#fi
!$
) )aY&%
1#fi#$9M 0&%='BO% ffK @$&
!J&%=1
) fi#!t
2
9@$
2) )CR3 ff$
)
#fi#fi)&
819M&%r6$=)$#$9M
&
) aY7*&%B'B&% X)&
$ )TUE#&%M

@&%
2E#) I$fi#9d #) 9Y
#=
; ff '
5
2
46fi# CK, '@<
$#) ffh E !M 6fi$!X#fi#fi!) &
2 ?O%
&%
'@
2]_ ff>$9@ =fi!
)) 76<z; ff 'B31 E&%
M&%4##
fi/fi!
) )j6>)Y01WO%
E#W

$<fi!
T6fi# $!=UW%
&

$E #) 9Co/$)&fi# )o)&% Um&%
R&%E1S) *
<<> ff
%=#)o ff'B1!
6fi# $!5
8 !CK3I
fi!
8 E&%"<$#) # ff8 P6fi# $!3#fi#fi)&
mO%
ff) )&)
6fi# $)@
$J ff) $
#Kc&%$ UE!3
UE
a9d ff 5
&

2=&%KA^<S) K WV <!h')fi
1fi#

&
SYpUW%$
); ff'@
2]_ ff>$9M 6fi# $)4&%"<$ 1
1#fi#$93 *O%$ UE!M ff ff5
2&
"
5&%
<$ ff1
1fi##$9" 2N$&
!!"1
K
&
4
$'B ff$TpC/o
) ='@
2]_ $#_94 6fi$)W<_+ ff',1>`
g ffB

o&%
4 ff) )O)n6fi$)R&%#)/)&% UE)n&%
R$&
2!B1
B
&
%>)*<_+ ff'@

'B ff>W&%
K&%$ UE!@ ffP ffM
2&
r+ ffo&%)=
&
2) )CnDE%#)W&>M)<
$ #fi!
$fi#9M!'@< $&

UW% ff=%
)W

1
= R
&
SC
DT%=#) )&B / 'B!MU%&% ffE
<<fi#9M6fi# $!M
J#M

@) 'B) W1S
ff) #$0Col n&%WUP ffV) $!1Sd%$Y&%E
&
UP$
$ 76!
fi#fi#9" ff < 0C/DE%>O+ ff>E&%

&>
t'@
OE &%Pfi!
1fi#!B $ ff>)0UP$EVff UW4
<$# ff$;CW; ff$&
2 fi#9Y&%#)R$9^<S/
!+ '@
# ff#)f
$fi#9GV UWJ+ E'B ) J&$
fipUP ff$fi#"
<<fi##
# ff)aCEybM) ff'B) #&
)Y#'@
a9
1< ) )1fi# =)E ff'@
!@V UEfi#E ) !'@
P&%W
'B ffR fi!
1Sfi #) !@

&
)Cnl ff
) #&
)=UW%$B&%#)BVff UEfi#B#)t =

#fi
1fiYn&%B ff)$I
"
&$B P&%B ff) )&)
6fi# P#&
)E&%
E$fi!
#fi#9K;U)&
)UE#fifin1=#)
$K+ /
2&
B) )PUE#&%Kfi# Ufi#fi#)W
'('

fi

n+o+pqrbsm,Xn+r pq

fi!
1fi#!8 $ ffCKDE%$O; ff$Yn&%M
<<fi##
# ff8 E&%#)t'&% ff8 3$fi!
#fi#9? #) J.>"

) )
)&% fffi#3 E) #ff76
fi#9d!'@<
T&%t<Sz+ '@
R&%6
figfi
2) ) 76
# ff3<$ $C
8b&$P!$ # ff &%#)/$)
>H%4UE#fi#fi1P AfftO%/6fi# R
<<$ ff
%4 tOO$&afi!
1fi#!
$ $)/!J&
!!@
&
SC0l RA
'@<fi#Y ffEUE
a9B = 4&%#)E'B#ff%E1SW B$fi!
1fip!) &
)E7&%
ff) )O)Efi!
) )P#)E7i>P&%
J&% ff1) $Mfi
2) )CRyb)
)P; ffoUW%#H%J&% ff) )O)/6fi#
<$# )n$U* P ffg'B ff$Rfi!
) ))UP fffi#) #fi#fi1/#)
$0CRDE%#)!$ # ff4#)R<
$ #fi!
$fi#9!'@< $&

1
) = R&%=<
#$9M /%#ff%ML
fi##_9K&
2!K
&
@

#fi
1fi4; ffP'@
9G
<<fi#
)C

/!M
ff'@
#
fi#fi#9"$' I!=!) &
)E&%

E1 ff $fi9Jfi
2) ) 76M#)E&%

&%9'B#ff%N1S/A< # ff) E&%R
2fiff fi#C %4
!) &
o#)N
A< # ffr E&%R
fi

) Y#/
B
<<S
/
)RO% ffff%B#R#)/! ff > fi#9@fi!
1fi#0C %J
<<fi#9ff!B %L)P #j;9

3fi#!'B!
#) 93)&
)Yg ffBU
)
#3)
$!3 ff $ fi#9:fi
1fi#?A< # ff)C
DE%$O; ff$@
MV 93L) # ff3!3!'@<> I!d

KL^
fi##$93)B% U M#) !ff#)&%cAff< # ff)4b$ ff'
#) CE4) fi! # ffM @&%#)f<> ff1fi#'F'B#ff%1= @$
!
) #)&%
Efi# ffVM
E&%@R!
UW%#%M
B!) &
#)E'B#) fi!
) )j6:!@ ff>/ = '7#P#)E
@A< # ffJ ffP
B > ffC
<fi!
: K)
=U%&%UE#&%:fi#'3+1
2HVYp ff=
dfi#
@#) !ff#)&%cAff< # ff)
b$ ff' #) t1
2) ffKO%Tfi!
) ) 76
d1%
a# ffW
M<;
&>I
fi!)C
DT%@A^<S$!'B )=) >1Sm!5&%#)B<
<4%
1S5 6? M!&$ !? #) @!
&%E
2&
!"
4'@
RO%
R#)*
&
fi+ R&%W<
$ #fi!
R ff'J
!pC/DE%#)/UE
)P) )&
$9Y1
)
; ff4&%M
&
) )@) mUPd%
[ 5UE
a95 W)&>m
3 #) O`;b$d
fi#
2 # ffm )@) Cc V 9
; ff)P .&>WUP ff VrUE#fi#fi1SW =
2 W #) T.>EI
fi##
# ffK
2&
) / ffo'B&% " B&%
ff$#!
fin
&
) C
>= $ fi#9MUP ff V!@ ffM 1&
!!d #) b$=
fi##
# ff3

4+ P&%
fi!
fi
2) ) 76
# ff&
)&VC

dg



b


R



fffi#Bfi!V &%
VEO%Bql$#)n; ffg)&<<fi#9ff!B&%EEq yp
&
)YI
P Tq=
<g; ff
P
<$ !:&%=fi!
) ) .) # ff); ffT&%B) @
5$ ff
:) ff'B&

&
SC B&%
VM
2 #
#fi) ff + ffJ%B ff'@'B )C :&%
Vc&%X
9'B ff)">ff#UP$)M
[ ff ffB; ffBO%

$Obfi$
2M
:Afffi#fi#)O) # ff)aC*E
$fi!
@P$ fffi#9p)$)
$%MUE
)P)&<<S ff$ 519Gel
y$ybe`_vK
3Ee,ff
E=a`_wvuCR5
VJl>fi;)=>)
$%MUE
)E)O<< ff$
19GTfe,Tff
TW=I`_uC

>h

ffh

;"<j1Xi'


Z

ji

e<Wi'i< g ]_a

A$ Xa($

j

Dn
1fi#fuaW$<S ff$ )n&%E$)&fi# )R 2
W<
!$:7`b ) g+ ffg&%Pfi!
`b gfi
2) ) 76
# ffB
2&
) CnD
1fi)
u4 tu$< $/&%fi!
) ) 76


9Y&%)&
'@<fi#) &

$@
2 # ffM
K&%W$)&fi# )P

K<
!$3$`b ) T+ P&%B$#=$#)&VY$
X
:) B) ff'B&
pY
:6$4) $#$9M
&
2) )C
Dn
1fi#)W4 @4)&% U&%=$)&fi# )E 2N
4 ff'@<
$#) K N'@
2]_ ff>$9B Wfi!
) )j6
2 # ffM 46fi# $!Y
; ffo&%W>$#)&VY$ ff

M) ) 'BO
# ffpYff
K6$) $#$9@

) )CRDn
1fi#)Ww4 @v
)&% U[O%W<$#) # ffK 0&%P6fi# >K'B&% )R; ffR&%$#E$#)&VYff$ ff
2"
K) W)ff'B&
# ffpY

K6$4) $#$9K
&
) )C

'(=

fi

pr v+hsvc%q+mr qhr pm6n++v+v5SIb

#) Z fi
uH`_W
e l

3l
Pl
el
Z
3l
Pl
q`_Dn$
el
3l
Pl


Cffw
Cj
Cffw
Cjwu
Cjw
Cj ffw
Cj
C!u
Cjv


Cj
Cj
Cj
C!u2
Cjuav
Cj
Cj
Cj
Cj

u
SCj
SCj
SCj
SCjw
SCju
SC!u
SCj
SCju
SCju


Cj
Cj
Cj
Cj
Cj
Cju
Cj
Cj
Cj


Cj
Cj
Cj
C!u
Cj2
Cjwv
Cj
Cj
Cj

ff
SCj
SCj
SCj
SCjuu
SCj
SCju
SCj
SCj
SCj

Dn
1fi#"uA*E ff'@<
$#) B 06fi# $!@ o6fi# $!Xs)&
#) #
fi) #ff76
xtfi!

&


#) Z fi

&
fiT #)
uO`_
E
el
3l
Pl
E
Z
el
3l
Pl
q`_Dn$
E
el
3l
Pl




C!uuCj
Cj
v QCj
uCj
Cj
uCj
QCj
Cj
QCj
C
Cj
Cj
w Cj
Cj
Cj
Cj
w wCj
Cj
w Cj
Cj
v Cjv
uCj
QCj


Cj

SC!uu,wC!u
SC
,Cj
SC
,wCj
SCj
w ,Cj
uCj
,Cj
SC
,Cjw
SCj
,Cj
uCj
w Cj
SCj
v ,wCj
SCj
,Cjv
vSCj
,C
SC!u
u Cj

u
uC7
uCjvQCjv
SCj
w QCjw
SC
QCj
SCj
w C!u
uCj
w QCj
Cj
w C!u
SCj
Cj
SCj
QCj
SCj
wCj
wSCj
QCjv
SCj
QCjv
SCj
Cj


uvCjw
wCwC7v
uCj
v vC7
Cj
wC7
Cj
C7
C
QC7
Cj
C7
Cj
QC7
uCj
QC7w
wCj
wC7v
C
QC7
Cj
QC7
C!u
u wC7


1fiKu1*/fi
2) ) 76
# ff:

9J"$#
&


'(p



SC
wCjv,wC7
wCj
v ,C7
SuCj
,wCu
wvCj
,C7w
Cj
,C7
wCj
,C
Cj
,C7
Cj
v ,wC7
w2C!u
u ,wC
wwCj
,wC7
wvCj
v ,wC7v
wCj
w ,C7


ff
ffSCjv
vCjvC
wCj
w Cj
wCj
QCj
wCj
C
Cj
w Cj
Cj
QCj
2Cj
Cj
Cj
C
Cj
Cj
Cj
Cjv
w2Cj
w Cj
wSuCj
v wC

fi

#) Z fi
uH`_W
e l

3l
Pl
el
Z
3l
Pl
q`_Dn$
el
3l
Pl


Cjv
Cj
Cj
Cffw
Cj
C!uw
Cju
C!u
Cjuw

n+o+pqrbsm,Xn+r pq


Cj
Cj
Cj
C!u
C!uSu
Cjvv
Cjv
C!u
Cj

u
SCj
SCj
SCj
SC!u
SCju
SCjw
SCj
SCj
SCju


Cjw
Cj
Cj
Cj
Cju
Cj
C!uu
Cju
Cj



Cj
Cj
CjSu
C!u
Cjua
Cjw
Cj
Cjw
Cff


ff
SCjww
SC!u
SCj
SCj
SCffvv
SCff
SCj
SCjv
SC!u


1fi#KuA*/P '@<
$#) ffK 206fi# $!M @ P6fi# $!5s) &
2 #) #
fi0) #ff76
x"$#
&


#) Z fi

&
fiT #)
uO`_
E
el
3l
Pl
E
Z
el
3l
Pl
q`_Dn$
E
el
3l
Pl


Cj

vCjwuCj
CjuCj
Cj
w uCj
uCj
v uC
wCj
w QCj
wCj
v Cj
Cj
Cj
Cj
Cjw
Cj
uC
uCj
uCj
uCj
uCj
Cj
uCj


Cu

wC7&uCj
C7&uCj
uC7&
w uCj
uC7&
w uCj
wvSCj
uuC7
wC7&
wSCj
C7&
SC
wC:
u SCj
C7&
SCj
uC7&
uC
C7&
uCj
uC:
u uCj

u
uCjw
uC7&Cj
C7&
v uCj
C7&
uCjv
uC7&
Cj
wC7&
wCj
C:
u Cj
wC7&
Cj
C7&
(Cj
C7&
Cj
C7&
Cj
uC7&
uC
uC7&
w Cj



SCjw
wwCjw,C7
vC
uC7
Cj
v uC7
Cj
v uC7w
wuC7&
w uuC!u
Cj
C7
Cj
w uC7v
2Cj
,wCu
wCj
,C7
vCj
,C7
Cj
uC
vCj
uC7v



wCj
wCjC7
Cj
uC7w
vCj
uC7
wCj
uCu
wCj
v C
Cj
v C7v
Cj
C7w
Cj
v wC7
wwCj
C7
Cj
v Cu
Cj
uC7
Cj
uC7


1fiKuwA*RPfi!
) )j6
2 # ffd

9K"$ ff
M) 'BO
# ffK
&


'(



SCj
Cj,C7
2Cj
,C7
Cj
,C7v
2Cj
,C7
vC
,C7
2Cj
v ,C7
wC
,C7
SuCj
w C7
vCj
C7
wCj
uC7
C
,C7
Cj
,C7

fi

pr v+hsvc%q+mr qhr pm6n++v+v5SIb

#) Z fi
uH`_W
e l

3l
Pl

el
Z
3l
Pl
q`_Dn$
el
3l
Pl


Cj
Cju
Cju
Cjw
Cj ff
Cju
Cj
Cj
Cj


Cj
Cj
Cj
C!uv
C!u
C!u
Cj
CjSu
Cj

u
SCj
SCj
SCj
SCju
SCjv
SCju
SCj
SCj
SCj


Cj
Cj
Cj
Cj
Cju
Cj
Cj
Cj
Cj


Cj
Cj
Cj
Cj2
CjSu
Cj
Cj
Cj
Cj

ff
SCj
SCj
SCj
SCj
SCj
SCj
SCj
SCj
SCj

Dn
1fi#"uA*E ff'@<
$#) @ g6fi$!@ @ o6fi# $!Xs)
#) #
fip) #ff76
x"$ ff
K) ff'B&
a`
K
&


#) Z fi
&
fiT #)
uO`_
E
el
3l
Pl
E
Z
el
3l
Pl
q`_Dn$
E
el
3l
Pl


Cj
vwCjuC!u
v CuCj
v Cj
w uC
vCj
uC!u
vCj
C
vCj
uCjw
vCj
C!u
vuCj
uCj
vCj
uCjw
v Cj
C
v Cj
uCjw
vCj
uC!u


Cj
vSCjuC!u
v CuC
v Cj
v uC!u
vSCj
uC!u
vuCj
uCj
vSCj
,Cj
vSCj
uC
vSCj
uCj
v Cj
uC
vSCj
v uCjw
v C
uCjv
v Cj
v uCj

u
wSCj
vSCjvuCj
vSCj
uCjw
v Cj
uCj
vSCj
uCjw
vSC!u
u Cj
vSCj
uCjv
vSCj
uCj
vuCj
C!u
vuC
uCjw
v C!u
u Cj
v Cj
uCj
v Cj
uCj


uCj
wC!uuC
vuCj
uC7
vCj
uC7
vCj
w uC7w
vCj
C7
vCj
w C7
vCj
w uC7v
vuCj
C7
wCj
C7
vCj
C7
vCj
C7
vC
C7


uvSCj
Cj,C7
Cj
uC7
vCj
,C7
vCj
,C7
Cj
,C7
vCj
uC7
vCj
uC7
vSuCj
,C7
SuCj
v uC7w
vCj
,Cu
vCj
w ,C7
vCj
,Cu


1fi#KuA*RPfi!
) ) 76
X
2
9J") =)ff'B&
# ffK



'(

ff
SCj
wCjCj
Cj
w Cj
vCj
C!u
Cj
Cj
wCj
Cj
vCj
uCj
vCj
Cj
vCj
Cjw
Cj
w C
C
QCj
vCj
Cj
wCj
v C!u

fi

#) Z fi
uH`_W
e l

3l
Pl

el
Z
3l
Pl
q`_Dn$
el
3l
Pl


Cj
Cj
Cj ff
Cj
Cjw
C!u
Cj
Cj ffw
Cj ff

n+o+pqrbsm,Xn+r pq


C!uu
Cj
Cj
Cj
Cj
Cj
C!uwv
Cjua
C!uv

u
SCj
SCj
SCj
SCffvw
SCju
SCju
SCj
SCju
SCj


Cj
Cj
Cj
Cjv
Cff
Cj ffw
Cju
Cj
Cj


Cj
Cj
Cj
Cju
Cj v
Cjuu
Cj
Cj
Cj

ff
SCj
SCj
SCj
SCj
SCju
SCj
SCj
SCj
SCj

Dn
1fi#"uvA*E ff'@<
$#) o6fi$!M G 6fi$!s)
#) #
fi0)j6
xM) @)ff'B`

# ffK
&


#) Z fi
&
fiT #)
uO`_
E
el
3l
Pl
E
Z
el
3l
Pl
q`_Dn$
E
el
3l
Pl


wCuCj
wC!u
u Cj
wvCj
v Cjv
wwCj
w uC!u
w Cj
Cj
wCj
QCj
wCj
C!u
wwC!u
u Cj
wCj
uCjw
wvC!u
u uCj
Cj
w Cjv
wCj
uCj


uC
wSCuCj
wSCj
uCj
SC
,Cj
wSC!u
u uC
wSCj
,C
wSCj
C
wSCj
,Cj
wwSCj
,Cjw
wSCj
w uCj
wSCj
v uCj
uCj
uC!u
wSCj
uCj

u
SC!u
wSCjuCjw
wSCj
uCjw
SCj
Cj
wSCj
uC!u
wSCj
Cjv
wSCj
Cj
wwSCj
v Cjw
wwSCj
uCj
wuC
uCj
wvSCj
uC!u
SCj
uC!u
wSCj
uCjw


wCjv
wCjC7
wCjuC7
Cj
uC7
wC
uC7
wCj
C7
wCj
w C7
w C
C7
wC!u
u C7
wC!u
u uC7
wvCj
uC7
uC
C7v
wC!u
u uC7w

Dn
1fi#t N
* fi
2) ) 76
# ff:

9KB6$4
&


=


uuCjw
vCjuC7
wCj
,C7v
Cj
v ,C7
wCj
uC7
wwCj
uC7w
wCj
C7
wCj
,C7w
wCj
,C
wCj
uC7
wvCj
w uC7
Cj
uC7
wCj
uC7

ff
uSCjv
vCjvCj
wvC!u
u uCj
Cj
v uCj
wCj
v uCj
wCj
uCjv
w2C!u
u Cj
wCj
v Cj
wC!u
u Cjv
wCj
v C
wvCj
uCj
SuC
Cjw
wCj
w uCj

fi

pr v+hsvc%q+mr qhr pm6n++v+v5SIb

#) Z fi
uH`_W
e l

3l
Pl
el
Z
3l
Pl
q`_Dn$
el
3l
Pl


Cj
Cj
Cj
Cj ff
Cju
Cj
Cj
Cj
Cj


Cj
Cj
Cj
Cju
Cjv
Cj
Cj
Cj
Cj

u
SCj
SCj
SCj
SCjw
SC!u
SCj
SCj
SCj
SCj


Cj
Cj
Cj
Cj
Cff
Cj
Cj
Cj
Cj



Cj
Cj
Cj
Cjvw
Cjua
C!uw
Cj
Cj
Cj


ff
SCj
SCj
SCj
SCffv
SC!u
SC!uw
SCj
SCj
SCj

Dn
1fi#tu+*RP '@<
$#) ffK 26fi# $!K @ P6fi# $!?s)&
#) #
fip) #ff76
xTJ6$
&


E )
Z fi

X%
SCj
SCj
vSCj
SCj
SCj
wSCj




u



ff

B6fi#
<
Z
SCj
Cj

uCj
Cjw

uCjw
Cj

SC
C!uu

SCj
C!u

SCjw
Cjw


5
]$ ff$#$9B6fi#
3%
<
Z
Cj
2Cjw
Cj
SuCj
Cj
Cj
Cjv
Cj
C!uua
Cjv
Cj
Cj
Cjv
Cj
Cjvv
Cj
2Cj
Cj

P ff))&)P6fi#
3%
<
Z
C!u
Cj
C!uau
C!u
uCjw
C
Cj
Cj
C!uu
Cj
uCj
Cj
Cj
Cjv
Cjw
wCj
Cj
Cj


1fiBA*RP ff'J<
$#) ffK n6fi# $!K B !B">
&


E )
Z fi



u



ff

3%
Cj
uCj
vCj
Cj
Cjw
wCj

E 6fi
q`_D$
Cj
Cj
Cj
wCj
wwCj
vCj

<
SCju
SCj
SCj
SCj
SCj
SCj

X%
SC!u
SCj
SCj
uCj
SCj
vSCj

5
]$ ff$#$9B6fi#
q`_Dn$
SuCj
Cj
SuCj
Cj
Cj
C



<
Cju
Cjw
Cj
CjSu
Cju
Cju

ff) )&)P6fi#
3%
q`_D>
Cj
C7
Cj
uCu
Cj
uC7w
uCj
vC7
vCj
C7
Cj
C7

Dn
1fi#tA*RP ff'@<
>) ffK n6fi$!" J !B"$ ff
2M) ff'B&
# ffK
2&


=



<
Cju
Cju
Cj
Cj
Cj
Cj

fiE #)
Z fi

3%
vwCj
vwCj
vCj
vC!u
vCjv
wCj




u



ff

B6fi#
uO`_
vwSCj
vSCj
vSCjv
wSC!u
SCj
wSCj



n+o+pqrbsm,Xn+r pq

<
SCj
SCj
SCj
SCj
SCj
SCj

5
]$ ff$#$9B6fi#
3%
uO`_
vC
v2Cjw
vCj
v2Cjv
vCj
v2Cj
v Cjv
vCj
v Cj
vCj
vC!u
vCj



<
C!uw
C!uu
Cj
Cju
Cj
Cj

P ff))&)P6fi#
3%
uO`_
<
vwCj
vCj
Cj
vwCj
vCj
C!u
vwCj
vCj
Cj
vCj
vCjw
Cj
v Cj
vCj
Cj
vuCj
Cj
Cj

Dn
1fi#t C*N ff'@<
$#) K 6fi# >K @ !B") 4) ff'B&
@



E )
Z fi



u



ff

3%
wwCj
w Cjv
wCjw
wCj
wCjv
w Cjv

E 6fi
q`_D$
wCj
wCjw
wuC
wC!u
wCj
wCjv

<
SCj
SCj
SCj
SCj
SCj
SCj

5
]$ ff$#$9B6fi#
X%
q`_Dn$
uCj
Cjw
uCj
SuCj
uC
Cj
uCj
SuC
uC!u
Cj
uCj
SuC



<
C
Cj
Cjw
C!uav
Cjv
Cjw2ff

ff) )&)P6fi#
3%
q`_D>
wvC!u
wC7
wvCjv
wC7
wvCj
wC7
wvCjv
wCu
wvCjv
wC7
Cj
wC7w



<
Cj
Cju
Cj
Cju
Cj
Cju


1fiBA*RP ff'J<
$#) ffK n6fi# $!K @ t6>=
&


#)
Z fi


u



ff

yb)&
)q)
$

?A@GB ?uffCACjB ?AwDECB

uC
uC7
uvC7
Cu
wC7

uauCj
SuCjv
2uCj
C!u

Cj
Cjv
uuCj
uwSCj

yb)&
)
P < ?s5x
Cj
wwCj
uavCj
SuCj
vCj


yb)&
):yb $)


wC!u
wSCjw
SuC!u
ffvSCj
vSuC!u
SCj
uC
uuwSCjw
uCj
uffSC!u

H?A@GB

H?CAB

k?FuDCjB

C!u
Cj
wCj
wCj

Dn
1fi#twA*EDT%") # -: E&%M! >) # ff8 W#)
$[
['B#) fi!
1Sfi

) )r`=$#@
&

s.ela Z x

=

fi

#)
Z fi


u



ff

pr v+hsvc%q+mr qhr pm6n++v+v5SIb

yb)&
)q)
$

?A@GB ?ffSCAuCjB ?AwDEuCjB

vCjw
wCj
vCj
vuaCj
uaCjv

Cj
Cj
wSuCj
vwCj

C
Cjv
SuCj
Cjv

yz) &
)
P ff <?s5x
v2Cj
uvCj
uaCj
wwCj
v2Cj

yb)
)E!dyz >) # ff


vSCj
Cjw
u Cj
uC7
vSCj
C7
uSCj
ffC7
SCj
C7v

H?A@)B


k?lCAB

H?ASDEuCjB w
uwCj
Cjv
wCjw
ffCj

Dn
1fi#tA*EDT%=) #-= 2N&%4! >) # ffM 2N#)
>h
d'B#) fi!
1fi#8
&
) )/`E$ ff
M)ff'B`

# ffK
&
Ms;elaQq`_Dn$x

#)
Z fi


u



ff

yb)&
)q)
$

?A@GB ?uaCACjB ?ADECjB

u C7
wC7w
ffC
uC7
wwC7

Cj

w Cj
vCj
w Cjw

uSC!u
uvSCj
Cj
vSCj

yb)&
)
P < ?s5x
Cj
ua Cj
vCj
Cj
Cj

yb)&
):yb $)


Cj
Cj
uCj
uCj
uuSC!u
vvCj
uv Cjw
uSCjw
u C7
Cjw
SCjv
C7
vC!u
wSCj
w C7

H?A@GB


H?CAB

k?FDB

Dn
1fi#tA*EDT%W) #- n&%! >) # ffK 0#)
$3
M'B#) fi!
1fi#3
&
) )R`/) )ff'B`

# ffK
&
Ms;elauH`_Wx

E )
Z fi


u



ff

yb)&
)q)
$

? @GB

uwvCj
uCj
uCj
uCj
uC!u

? CFB

uauCj
uaCj
uauC!u
uauCj
uauCj

? DB

vC7
uCu
C7
C7
vC7

yb)
)
P ff < ?s5x
Cj
uCj
ffCj
ffC!u
wuCjv


yz) &
)E!:yb $) # ff


uC!u
ffC7
Cjv
vCj
v C7
vCjw
uavC
uvCj
u Cj
wwCj
Cj
Cj
Cjv
Cj
u Cjw

H?

@GB

I? CAB

H? DEB

Dn
1fi#tvA*EDT%=) #-B /&%4 $) # ff: /#)
$5
3'B#) fi!
1fi#8
&
) )P`P6$=

ds;el
aQq`_Dn$x

=

fin+o+pqrbsm,Xn+r pq



Sm

3 &







^n

%
Ynq@C!YR1fi#Yoq@C!YRWfi!1>Y/mCPs$uvvuaxCMyb) &
O`_1
) mfi#
!?
fi# $#&%'B)C 3^fi
OOY ns$uxYawwC

qp



n

fi!pYnq@C!Y Z
!$0YRnCRs$uvxC Z
!Mb$ ff' #) 93A
'@<fi#)C 3^fi
ffa^C

jn



"r

&OY RsffxY

ts

uGrYnua

P
!pYmC!Y(hfi# ffpYepCRs$uvvSuxCRE `_'B ff ff#=fi#
!C 3^fi O;#j&aY
uC

^swvxvyv

o!V )) ffpY%CYNeUE
!pYCEs$uavvxCKP ff) )O)tO% ff$ #Kfi
2) ) 76
# ff\'B&% )C
_; aH;~4 X /18 /+4O;Y NsxYwwa^ C

|{

z

}~n d} |

rr

Sn

P$ fi9YrC 3 Cffs>uvvxCIP>) #E
ff'@
2 #/1
2)) fi# # ffr; ffpfi!
) )j6n ) & # ffpC 3^fi
OOY Ywa^v C

ra



P$ fi9YoC 3 C!Y0lp$#fi;YRmC0BC*s$uvvw
xC@y.j;98
?fi#!'B!
!?')fi
1fi#[&
!
)&
)CEyz P$O&T8 fiff
fiffO;&a fi f; $& O; P &;5
ff&aYff<<pCpvva<n $ fi!
0YCWfyo$) )C

c





z







P$ fi9YC 3 C!Yol>fi;YPmCRBCWs$uvvw1xCmyb'J<$ ff!m
ff'@
2 ?fi!
\ @'@
<<!m19
7;9ff!t
tfi#!'B!
!@'B#) fi!
1SfiM 1) $I
2 # ff)n.> ff'O
!!
&
Cyb P_a&OT8
" fiff &;O; E&2HaaO@18 P(B; ^2HBY fi;Cy$y YR<<pC/uaa
u Z ! fi!pY0WC





P$ fi9Y0rC 3 C!Y{T i/YAnC
ffa^SC

3

|

{

F

{

n

Cs$uvvxCn5fi
$!
B#) # ff3O$)C X6fiff



u

OOY

ln





E
>YrCffs$uvvxC(T) !W#) # ff&$)0 T'J<$ /
)O`_1
) =fi#
Cffyb X6fiff O&
*$O&T 8 fiff fi &;O; $&aYff<<pCa^4'@%$) YSXBC3 ff$ff


.'J
pC





z





q=
9fffi!VYBC!Yp{o$ ) YlECRs$uvvxC/e'@
2fifiR#);] )!3
# ff* Z
!M @!
ff )t$ ff$)
:&%4 fi#<% ff"$UP ff VJfi# ff
fiRfi# ff<pCyb X^fiff OO P$O&T8 @ fiff fi
&;a&; / Ha$OY<<pCpuO'@%$) aY3tC3 ff>ff
K
.'J
pC



n

~







z

q
&Y*epCs$uvvwxC Z
!8!%91$# #) :!$ ff'B )M) !m) &
#)
2fi*L$#)Cyz
lR)O%Yq@C!Y Z -Y C0s 3 )CjxY O& H$+ ; O; P &;#jO18 ;;T5
; nY<<pC0uauSCffe<$! $fi!
YTUQR ff VC

P







F{

q
&YepC*s>uvvxCffR
@fi#
3UE#&%c ff)
>`_<
$ # # ff3fi!
)) 76
# ffm #)
?
<<fi##
a`
# ff)E @#) # ff:&>=! # ffpCEyb X6fiff &O P$O&T8 fiff ffO;&a fi
&;a&; / Ha$OY<<pCpavuW
)&%ff#fi#fi#Y0DE4C3 ff$ff
K
b'@
pC



n

~

b



l

qOb$#)YCepCYD0 UW)O%0YA%CC@Cs$uavv ffxCnEq `b>dfi!
ofi!
) )j6
2 # ff)=
E

fi# ff1
fip)
fi#C &;a&; ffO0 P( B; affY s>uxYwa^wC



E



{

ua

q# $#%pYDrC^JCs$uvvxCgf<<$ A!'@
)
# ) #
fi0) )P; ffo ff'@<
>K)&<S$ff#) 3fi!
) )j6
I`
# ffKfi#
!G
2fi ff$#&%'B)C faff$ o+ ff;;Y Ns;xYpuvapuv C





u)

=

fipr v+hsvc%q+mr qhr pm6n++v+v5SIb



q# $#%pYWDCP@CY/*
V!$;YWJCWs$uvvxCe fi#!['tfi# #fi!
) ):fi#
![<$ ff1fi#'B)M!
8 $ ffz`
ff $ !@ &<E )C ffO r&; *a &;#jO *HO$^fiY YwawC



>

Es

j

qr

F

q UPYq@C Z C!Y ) fi;Y=Cs$uavv
xC [#) # ffJ&$E'B fi 1)&%6$W
2 #ff#$9Cyb P_a&OT8
E fiff fi H;$# / $aO* &; *a &;#jOYa<<pCffI^vC ff$fi#
e 76C

j{



x





q UPYq@C Z C!Yp ) fi;Y4C/s$uvv1xCE#) # ff5O$t'B fiR *1)&%6>"
#$9C=Dg%pC0$<pC
D0%#
fiW$<S ff$"vuvYg3 ff
)&%#$) #$9Y/3fi!1 YPf)&
fi#!
C?DT%)J H%#
fi
$< ff>M ff $ )K&%?
$ #fi#?
<<
$![!&%?e#A&%) &
2fi!
% !d ff+>5 ff
f$j6!
finyb fi#fi#C

Esa#&;SHY

q UPYq@C Z C!Y ) fi;Y=Cs$uavv ffxCq#) # ffB&$E'B fi#)/ 1)O%6$W
##_9C
s;xYuO^SC



q=
<SYCs$uavvxC"n$) ff
2fi '@'B
2 # ffpC!C
q=
<SYffC!YP fi#fi#!)YrC!YffP$ fi## Y%C!Y
) ffpYtCYffQP#) '@
pY 3 Cs$uavvxCDE%fe%'@
4e9ff) 'MC
&;a&; ffO0 /+ ; YvI^C



E

q=
YCBCY
$YnC
e ff)YTtC

| r
C0s$uvxC~*;;a&V/# P&;MC8A{p&aff4#a!C,% %

3

#fi#9


l
a99ff
0Y14CCYyb
;YnBCCRs$uvvxCE:&%t%
fi#!d 2/ ff ff)$`b
fi!
2 &$!1 )!
) dO$
pC X6fiff OOffY s>uxYIuC

n





=
't1S$Yq@C!Y Z

Y4C!YqK- $ )&V;YepCNs>uvvwxCEE #) Bfi#!'B!
# ff3!:! #@ ff<
fi
!1
*,
2) B) &93!5'B#
fiR!
ff ))aC@yb p(7a fi &;O; afiff
ffO fit &O
fiff&& Y<<pC0uavva^uaCffe<$!C





V{

z



>



=9 ffpY*yC!YP5
#YE4C!YE
<!VY CWs$uvvwxCmq#) >8!+ '@
#3<
)G
\
&

fi
Cyzml
a99ff
0YG4CRmC!YR!
)&V9`_e%
<!$ YEJC!Y/e'49&%pY`nC!YP T&%
)&
'=9YoC
3 )C7xY 8+7&* =P#T 8ff !O+7a&418 ; XY<<pCuSuO^SCWy2hyzD
/$) )aC





j

n

^svyvyv z


) pY Z CBCYe
fi!
'B ffpY"CPs$uvvxC"T
fiP$U* VM) 'B1fi#)C
*;;a& #W18 3^fi &;7ffaOY Ns>uxYvvIuuC





n



% ff%pYRJC

uGr



$a;St

V
n

CPs$uvvxCt ff1) B#) # ff5O$)(*BP'B ff!: ff fi##$)4.$ '
&
CKyb P_a&OT8
= fiff / &;O; / Ha_aO =P#T8ff !&7O@C8 ; 3 ffY<<pC
u uav3 ff&$
fi;Y1Cpfy /$) )aC

~s



|



) fi;Y=C!YPq UPYoq@C Z Cs$uvvxCo$# !1)&%6>h
2 #ff#$9m![O%d5
fi#fi#h># ffm
&%= ff$&%UP) # $!
") !M
B#) # ff:&$='B fi;C*yz P_a&OT8W fiff &SH;;ff;B
;$# EO ff$ Cfiff / Ha_aO/3fi!1 Y) &
fi#
SC



c

X

^







Z UE#)Yq@C!Y\E
fi# Y~%Cs$uvv2ffxC $ )N$O
!$9)&
'J<fi!r+ ff)&<$#) @fi#
!C
yb X6 fiff O& *$a&O8* = fiff P~7a fi &;a&; / Ha_aOY <<pCpuffa
uwBEUQ*) UE#HVYpk%CSX $ff
K
b'@
pC

n





v
=('





fi

n+o+pqrbsm,Xn+r pq

Z )aYffepCffBCY+%ff) YCBC!YffQDnHV YffC%Cs$uavv ffxCfi 1
fi0uEff>f19MuEff$Eq yn
&

) R; ffRfi#!'@
) &#)P$#K.> ff'&%!'@')/ ff !O
fi0Eq yn
&
C &;O;
^O0 *( B; SHY ns$uxY ffvauvC





l{



qua

5
&%UT)Y 3 CRs$uvxCPfi# ff1
fig&

:fi
h)+*WTU %#ff%3$)
fi
2&
@1
) ); ff
fi!'@
2 =) O)aC ^ffOn /# B;B18
#T8 3;O$# IY Yff ffC







rar

3#H%#Yq@Cs$uvvxCo$ ff1fi#'B)o ff'J< z`_
#K ff<R; ff '@
2 # ffpC!Cyb@!fi!
pYA%CffCs 3 0
CjxY
pO;
^O a;( 4HY fi;CSCff#) ff` )fi9Y ffV!ff%
'MY1BC



vy x{
Tfi#) ) ffpY4CA%Cns$uvwxC O&B^fiffHCX4
aUP`

fi#fi;YTUR VC


)aY^DrC!Y %) pYq@C0s$uvvxC0DE%Oi0 )P n&
!!@) E)- K) M&$ ff'@<fi#A#_9C
yb 3^fi OO P_a&OT8" fiff 0&;O fi &;O; / $&aY/<<pC
^w=
)&%ff#fi#fi#YDT=C3 ff>ff
K
.'J
pC

n





^



ff

V
SY*4C!YRR )&%#
YEBCEs$uvvxC Z
!$fi
@
m! $fffi!
A^
'J<fi)K) <

fi#9C?yz
*$O&T 8 fiff
&;O; / Ha$OM faff$ ;RY
<<pC0uuOpu Cy 3G3 3 o$) )C



uaGVswvyvxvs







x

V
SY=C!Ya[R )&%#
YBC^s>uvvwxC[ #) O`b fi#
N%9^1>@'B fi
Pfi# ff1
fi
B
Efi#
fifffi#

'B fffi;Cyz *$a&O 8R * fiff
5 MTfiff &;aff$; 3ff; # O&8 X(8
H p_
7M1
8 O# 3^ fi OO
ff& fi4HY<<pCpvauaCfy/>) )C



js ff

F{

x>js apF



Xs


ffn

n

fi#) ffpYA%C!Y
)aY+%C!YWfi#fi##) ffpY Z C0s$uvxC0E
1 ffJ!Kfi#&
# ffJ N'J
]$ ffRUP ff$fi#K ) 9)$`
'B)CPD0%pCp$<pCDg%
2fiNP<S ff$ `_ ffa` 3 `_wSYeMq<
$&'BE 3 $9Y
V
P#t
# ff
fi Z
1
ff>9C

xn

!fi!
pY%CCns$uvwxCyz # ff: N#) # ff:&>)C X6fiff



qu

OOY ns$uxYuOpuwC

EaP$ ff$+4B6fiff3#&OCm3 ff$ff

.'J
pYEe


!fi!
pY%C*rCWs$uvvxC
h
2 YfftC





j

z

!fi!
pY+%CaC^s>uvvwxCP
!Y 1 ) !W
tPC7CIyz P_a&OT8 * fiff fiffO;O fi ;
/ $aO &; *a O;#j&aY<<pCa^n ff$ fi!
0YCWy/$) )aC



e%
<!$YrC

3





jn

Cs>uvvxCDE%) O$&%K RUP
VBfi#

1fi##$9C X6fiff



q

&OY Yguva^C

eV
2fi
VYpq@Cs>uvv ffxC`o$ $9<=
+
2&$=)fi X19M)&
'J<fi!d
5
ff''B&
# ff:%#fifi
fi!'B1!G
2fi ff$#&%'B)CRyz X6fiff O& P$O&T8E = fi P#(7a fi &;O;
/ $aOY<<pCpva^uWTUP ) UE#VYpw
%C3 ff$ff
"
b'@
pC

|n



x



tv



eV
2fi
VYPq@C!YoP#) ) fi!
0Y 3 CWs>uvvxCyz #3fi#
!?!
5'B#A<

#ff') !C[yz
*$O&T 8W = fiff Pjfiff fi ; $& r&; *a &;a#7ff&aY<<pC2ffa^
/ ) ffpY3tC3 ff$

b'@
pC



v













efi# ff
pY=rCs>uvxCD/9<): " #) 8
&
+ K ff<3fi
!Cyb *$a&O8d ? fi
/H MT fiff 3 o+ ff;; && fiffOOIY<<pCvSuO^vwET
'B1$#Y 3tC W
/$) )aC



X



z

=(=

fi

pr v+hsvc%q+mr qhr pm6n++v+v5SIb



V

efi# ff
pY/rC*s$uvvxCKl $9^<S)B W #) M!5

K; ff<ffi#
!C & TB; *$OOH
a;;HY Ps;xY0uaauwC





~

e'49ffO%pYnCs$uavvwxCpo ff)P ffB&%'B
fi
2) ) 76
# ffK > ff/
2 E 'Bfi# !<fiA<> )C *;;O
*O&ff; ;;Y Y0uauC



ud



e$!#I
)O
pYptCY5fi# ffpYpepC!Y*
2pYpmCs>uvvxCRq#) !ff#)&%!dA< # ff)b$ ff' #) 4!
ff`_'B ff ff#tfi#
C"yb P_a&OT8= K fiff p&OC8 &18; 7 P$ ff$+B
fi Y<<pCpvaua=Dg ffV9
%ff
<
pCybEDs;DgH%#
fiR$< $EDP:`&uuxC





X

A{





xswvyvxv z

Dg ff'BVY^yC0s$uvwxCJA^<S$!'BUE#&%J#
$) >`_%ff1S ffE fi#C
aH;~ 4 X3C
8 ot 4Oa;HY s.wxYffaffC


p
#)&1S$YpepCs$uvxCa
#8K#&W$zff$OHC,% ff%



{

}~n

$;S

fi#9de ff)aC


swvxvyv



#fi) ffpYq@Cs$uavxCW)9^'@< #W<$ ff<S$ #)/ 2
$)/%ff1S ff/ fi#)P) !=# @

C
_ p a;( 4 XX18 /+4 a&;Y YaffffSuC


#fi) ffpY q@CCffs>uvvxC 8+7&/B;O^5d4 2HT8E#&&W ff& fi4HC/%pCq@CO&%))aY*>%
'
R ffff
$) #$9YKo$ YDC


#fi) ffpY q@CIrC!Ym5
> !-YDCCs$uvvxCyb)&
*<H%#L)Cyb X6fiff O&
*$O&T 8= " fiff 0&;O fi &;O; $&aY<<pCgff uuBW
)O%#fifi#YRDE4C
X $ff
K
b'@
pC


#fi) ffpYq@CC!Y5
$-YDCCps$uvvvxCP # ffJ H%#L)o+ ffnA'@<fi!
z`_1
2) "fi#


fi# ff$#&%'B)aC 3^ fi OOffY $&C


#fi) ffpYCalEC!Y $) `_efifi#$)aYtCs>uvxCfffi# ff1
2fi
$%E fi!
J IR
@) #fi#)P
&

+ ffP) 4!M
2fi!$fi!
X' fffi#)C ^ffOg /# B;# IY YguuvauffC


!) ff
pY1nC Cs$uavxC Z
!M)
&
fip) >< ).$ ',A
'@<fi#)CPyb
3 0CjxY fiff /I6fiff# B / pff
;a n!C34
aUP` #fi#fi;YTUR ffVC

z

|{





}~n



|

r



yn









F



z

Fn



ff

ff



"

) ffpY1nC C

"

fi!<S$Yq@C Cs$uavvxCne&
V
2fi#-
pC $ ;RY uH^vC
%
YBC!Y0T#)&%#
YDCRs$uvvxCE) !ML
fi##&
#@%9^<S &%) )4 "# 7+93!

2 B
&
C
^O0 &; *a &;a#7ffaO P&$6fiffY Y0uuvIuffC



>



ff



=(p

fiJournal Artificial Intelligence Research 11 (1999) 241-276

Submitted 1/99; published 9/99

Evolutionary Algorithms Reinforcement Learning
David E. Moriarty

moriarty@isi.edu

University Southern California, Information Sciences Institute
4676 Admiralty Way, Marina del Rey, CA 90292

Alan C. Schultz

Navy Center Applied Research Artificial Intelligence
Naval Research Laboratory, Washington DC 20375-5337

schultz@aic.nrl.navy.mil

John J. Grefenstette

Institute Biosciences, Bioinformatics Biotechnology
George Mason University, Manassas, VA 20110

gref@ib3.gmu.edu

Abstract

two distinct approaches solving reinforcement learning problems, namely,
searching value function space searching policy space. Temporal difference methods evolutionary algorithms well-known examples approaches. Kaelbling,
Littman Moore recently provided informative survey temporal difference methods. article focuses application evolutionary algorithms reinforcement
learning problem, emphasizing alternative policy representations, credit assignment methods, problem-specific genetic operators. Strengths weaknesses evolutionary
approach reinforcement learning presented, along survey representative
applications.

1. Introduction
Kaelbling, Littman, Moore (1996) recently Sutton Barto (1998) provide informative surveys field reinforcement learning (RL). characterize two
classes methods reinforcement learning: methods search space value functions methods search space policies. former class exemplified
temporal difference (TD) method latter evolutionary algorithm (EA)
approach. Kaelbling et al. focus entirely first set methods provide
excellent account state art TD learning. article intended round
picture addressing evolutionary methods solving reinforcement learning
problem.
Kaelbling et al. clearly illustrate, reinforcement learning presents challenging array
diculties process scaling realistic tasks, including problems associated
large state spaces, partially observable states, rarely occurring states, nonstationary environments. point, approach best remains open question,
sensible pursue parallel lines research alternative methods. beyond
scope article address whether better general search value function
space policy space, hope highlight strengths evolutionary
approach reinforcement learning problem. reader advised view
c 1999


AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiMoriarty, Schultz, & Grefenstette

article EA vs. TD discussion. cases, two methods provide complementary
strengths, hybrid approaches advisable; fact, survey implemented systems
illustrates many EA-based reinforcement learning systems include elements TDlearning well.
next section spells reinforcement learning problem. order provide
specific anchor later discussion, Section 3 presents particular TD method. Section 4 outlines approach call Evolutionary Algorithms Reinforcement Learning
(EARL), provides simple example particular EARL system. following three
sections focus features distinguish EAs RL EAs general function optimization, including alternative policy representations, credit assignment methods,
RL-specific genetic operators. Sections 8 9 highlight strengths weaknesses
EA approach. Section 10 brie surveys successful applications EA systems
challenging RL tasks. final section summarizes presentation points
directions research.

2. Reinforcement Learning

reinforcement learning methods share goal: solve sequential decision tasks
trial error interactions environment (Barto, Sutton, & Watkins, 1990;
Grefenstette, Ramsey, & Schultz, 1990). sequential decision task, agent interacts
dynamic system selecting actions affect state transitions optimize
reward function. formally, given time step t, agent perceives state
st selects action at. system responds giving agent (possibly zero)
numerical reward r(st) changing state st+1 = (st ; at). state transition may
determined solely current state agent's action may also involve stochastic
processes.
agent's goal learn policy, : ! A, maps states actions.
optimal policy, , defined many ways, typically defined policy
produces greatest cumulative reward states s:

= argmax
V (s); (8s)


(1)

V (s) cumulative reward received state using policy . also
many ways compute V (s). One approach uses discount rate discount rewards
time. sum computed infinite horizon:

V

(

1
X
) = ir



i=0

t+i

(2)

rt reward received time step t. Alternatively, V (s) could computed
summing rewards finite horizon h:

V (st) =

Xh r
i=0

t+i

(3)

agent's state descriptions usually identified values returned
sensors, provide description agent's current state state
242

fiEvolutionary Algorithms Reinforcement Learning

world. Often sensors give agent complete state information thus
state partially observable.
Besides reinforcement learning, intelligent agents designed paradigms,
notably planning supervised learning. brie note major differences
among approaches. general, planning methods require explicit model
state transition function (s; a). Given model, planning algorithm search
possible action choices find action sequence guide agent
initial state goal state. Since planning algorithms operate using model
environment, backtrack \undo" state transitions enter undesirable states.
contrast, RL intended apply situations suciently tractable action
model exist. Consequently, agent RL paradigm must actively explore
environment order observe effects actions. Unlike planning, RL agents
cannot normally undo state transitions. course, cases may possible
build action model experience (Sutton, 1990), enabling planning
experience accumulates. However, RL research focuses behavior agent
insucient knowledge perform planning.
Agents also trained supervised learning. supervised learning, agent
presented examples state-action pairs, along indication action
either correct incorrect. goal supervised learning induce general policy
training examples. Thus, supervised learning requires oracle supply
correctly labeled examples. contrast, RL require prior knowledge correct
incorrect decisions. RL applied situations rewards sparse;
example, rewards may associated certain states. cases, may
impossible associate label \correct" \incorrect" particular decisions without
reference agent's subsequent decisions, making supervised learning infeasible.
summary, RL provides exible approach design intelligent agents situations planning supervised learning impractical. RL applied
problems significant domain knowledge either unavailable costly obtain.
example, common RL task robot control. Designers autonomous robots often
lack sucient knowledge intended operational environment use either planning
supervised learning regime design control policy robot. case,
goal RL would enable robot generate effective decision policies explores
environment.
Figure 1 shows simple sequential decision task used example later
paper. task agent grid world move state state
selecting among two actions: right (R) (D). sensor agent returns
identity current state. agent always starts state a1 receives reward
indicated upon visiting state. task continues agent moves grid
world (e.g., taking action state a5). goal learn policy returns
highest cumulative rewards. example, policy results sequences
actions R; D; R; D; D; R; R; starting state a1 gives optimal score 17.
243

fiMoriarty, Schultz, & Grefenstette



b

c



e

1

0

2

1

-1

1

2

1

1

2

0

2

3

3

-5

4

3

1

4

1

-2

4

1

2

5

1

1

2

1

1

Figure 1: simple grid-world sequential decision task. agent starts state a1
receives row column current box sensory input. agent moves
one box another selecting two moves (right down),
agent's score increased payoff indicated box. goal find
policy maximizes cumulative score.

2.1 Policy Space vs. Value-Function Space
Given reinforcement learning problem described previous section,
address main topic: find optimal policy, . consider two main approaches,
one involves search policy space involves search value function space.
Policy-space search methods maintain explicit representations policies modify
variety search operators. Many search methods considered,
including dynamic programming, value iteration, simulated annealing, evolutionary
algorithms. paper focuses evolutionary algorithms specialized
reinforcement learning task.
contrast, value function methods maintain explicit representation
policy. Instead, attempt learn value function V , returns expected
cumulative reward optimal policy state. focus research value
function approaches RL design algorithms learn value functions
experience. common approach learning value functions temporal difference (TD) method, described next section.

3. Temporal Difference Algorithms Reinforcement Learning
stated Introduction, comprehensive comparison value function search
direct policy-space search beyond scope paper. Nevertheless, useful
point key conceptual differences typical value function methods typical
evolutionary algorithms searching policy space. common approach learning
value function V RL problems temporal difference (TD) method (Sutton, 1988).
244

fiEvolutionary Algorithms Reinforcement Learning

TD learning algorithm uses observations prediction differences consecutive
states update value predictions. example, two consecutive states j return
payoff prediction values 5 2, respectively, difference suggests payoff
state may overestimated reduced agree predictions
state j . Updates value function V achieved using following update rule:

V (st) = V (st) + ff(V (st+1) , V (st) + rt)
(4)
ff represents learning rate rt immediate reward. Thus, difference
predictions (V (st+1 ),V (st )) consecutive states used measure prediction error.
Consider chain value predictions V (s0 )::V (sn ) consecutive state transitions
last prediction V (sn ) containing non-zero reward environment.

many iterations sequence, update rule adjust values state
agree successors eventually reward received V (sn ).
words, single reward propagated backwards chain value predictions.
net result accurate value function used predict expected reward
state system.
mentioned earlier,
goal
TD methods learn value function




optimal policy, V . Given V , optimal action, (s), computed using
following equation:
( (s; a))
(s) = argmax
V


(5)

course, already stated RL state transition function (s; a) unknown
agent. Without knowledge, way evaluating (5). alternative
value function used compute (s) called Q-function, Q(s; a) (Watkins,
1989; Watkins & Dayan, 1992). Q-function value function represents
expected value taking action state acting optimally thereafter:

Q(s; a) = r(s) + V ((s; a))

(6)
r(s) represents immediate reward received state s. Given Q-function,
actions optimal policy directly computed using following equation:

(s) = argmax
Q(s; a)


(7)

Q(st; at) = Q(st; at) + ff(max
Q(st+1; at+1) , Q(st; at) + r(st))
+1

(8)

Table 1 shows Q-function grid world problem Figure 1. table-based
representation Q-function associates cumulative future payoffs state-action
pair system. (The letter-number pairs top represent state given row
column Figure 1, R represent actions right down, respectively.)
TD method adjusts Q-values decision. selecting next action,
agent considers effect action examining expected value state
transition caused action.
Q-function learned following TD update equation:


245

fiMoriarty, Schultz, & Grefenstette

a1 a2 a3 a4 a5 b1 b2 b3 b4 b5 c1 c2 c3 c4 c5 d1 d2 d3 d4 d5 e1 e2 e3 e4 e5
R 17 16 10 7 6 17 15 7 6 5 7 9 11 8 4 6 6 7 4 2 1 2 1 2 1
16 11 10 7 1 17 8 1 3 1 15 14 12 8 2 6 7 7 3 1 7 6 4 3 1

Table 1: Q-function simple grid world. value associated state-action
pair.
Essentially, equation updates Q(st ; at) based current reward predicted
reward future actions selected optimally. Watkins Dayan (1992) proved
updates performed fashion every Q-value explicitly represented,
estimates asymptotically converge correct values. reinforcement learning
system thus use Q values select optimal action state. Qlearning widely known implementation temporal difference learning,
use qualitative comparisons evolutionary approaches later sections.

4. Evolutionary Algorithms Reinforcement Learning (EARL)
policy-space approach RL searches policies optimize appropriate objective
function. many search algorithms might used, survey focuses evolutionary
algorithms. begin brief overview simple EA RL, followed detailed
discussion features characterize general class EAs RL.

4.1 Design Considerations Evolutionary Algorithms

Evolutionary algorithms (EAs) global search techniques derived Darwin's theory
evolution natural selection. EA iteratively updates population potential
solutions, often encoded structures called chromosomes. iteration,
called generation, EA evaluates solutions generates offspring based fitness
solution task environment. Substructures, genes, solutions
modified genetic operators mutation recombination. idea
structures associated good solutions mutated combined form
even better solutions subsequent generations. canonical evolutionary algorithm
shown Figure 2. wide variety EAs developed, including genetic
algorithms (Holland, 1975; Goldberg, 1989), evolutionary programming (Fogel, Owens, &
Walsh, 1966), genetic programming (Koza, 1992), evolutionary strategies (Rechenberg,
1964).
EAs general purpose search methods applied variety domains
including numerical function optimization, combinatorial optimization, adaptive control,
adaptive testing, machine learning. One reason widespread success EAs
relatively requirements application, namely,
1. appropriate mapping search space space chromosomes,
2. appropriate fitness function.
246

fiEvolutionary Algorithms Reinforcement Learning

procedure EA
begin
= 0;
initialize P(t);
evaluate structures P(t);
termination condition satisfied
begin
= + 1;
select P(t) P(t-1);
alter structures P(t);
evaluate structures P(t);
end
end.
Figure 2: Pseudo-code Evolutionary Algorithm.
example, case parameter optimization, common represent list
parameters either vector real numbers bit string encodes parameters.
either representations, \standard" genetic operators mutation
cut-and-splice crossover applied straightforward manner produce genetic
variations required (see Figure 3). user must still decide (rather large) number
control parameters EA, including population size, mutation rates, recombination
rates, parent selection rules, extensive literature studies suggest
EAs relatively robust wide range control parameter settings (Grefenstette,
1986; Schaffer, Caruana, Eshelman, & Das, 1989). Thus, many problems, EAs
applied relatively straightforward manner.
However, many applications, EAs need specialized problem domain (Grefenstette, 1987). critical design choice facing user representation, is, mapping search space knowledge structures (or,
phenotype space) space chromosomes (the genotype space). Many studies
shown effectiveness EAs sensitive choice representations.
sucient, example, choose arbitrary mapping search space space
chromosomes, apply standard genetic operators hope best. makes
good mapping subject continuing research, general consensus candidate solutions share important phenotypic similarities must also exhibit similar forms
\building blocks" represented chromosomes (Holland, 1975). follows
user EA must carefully consider natural way represent elements
search space chromosomes. Moreover, often necessary design appropriate
mutation recombination operators specific chosen representation.
end result design process representation genetic operators selected
EA comprise form search bias similar biases machine learning meth247

fiMoriarty, Schultz, & Grefenstette

Parent 1:



B

C



E

F

G

Parent 2:



b

c



e

f

g

Offspring 1:



B

C



e

f

g

Offspring 2:



b

c



E

F

G

Figure 3: Genetic operators fixed-position representation. two offspring generated crossing selected parents. operation shown called one-point
crossover. first offspring inherits initial segment one parent
final segment parent. second offspring inherits pattern
genes opposite parents. crossover point position 3, chosen
random. second offspring also incurred mutation shaded gene.
ods. Given proper bias, EA quickly identify useful \building blocks" within
population, converge promising areas search space.1
case RL, user needs make two major design decisions. First,
space policies represented chromosomes EA? Second, fitness
population elements assessed? answers questions depend user
chooses bias EA. next section presents simple EARL adopts
straightforward set design decisions. example meant provide baseline
comparison elaborate designs.

4.2 Simple EARL

remainder paper shows, many ways use EAs search space
RL policies. section provides concrete example simple EARL, call
Earl1 . pseudo-code shown Figure 4. system provides EA counterpart
simple table-based TD system described Section 3.
straightforward way represent policy EA use single chromosome per policy single gene associated observed state. Earl1 ,
gene's value (or allele biological terminology) represents action value associated
corresponding state, shown Figure 5. Table 2 shows part Earl1 population
policies sample grid world problem. number policies population
usually order 100 1000.
fitness policy population must ect expected accumulated fitness
agent uses given policy. fixed constraints fitness
individual policy evaluated. world deterministic, like sample grid-world,
1. ways exploit problem specific knowledge EAs include use heuristics initialize
population hybridization problem specific search algorithms. See (Grefenstette, 1987)
discussions methods.

248

fiEvolutionary Algorithms Reinforcement Learning

procedure EARL-1
begin
= 0;
initialize population policies, P(t);
evaluate policies P(t);
termination condition satisfied
begin
= + 1;
select high-payoff policies, P(t), policies P(t-1);
update policies P(t);
evaluate policies P(t);
end
end.
Figure 4: Pseudo-code Evolutionary Algorithm Reinforcement Learning system.
Policy i:

s1
a1

s1
a1

s3
a3

...

sN


Figure 5: Table-based policy representation. observed state gene indicates
preferred action state. representation, standard genetic
operators mutation crossover applied.
fitness policy evaluated single trial starts agent
initial state terminates agent reaches terminal state (e.g., falls grid
grid-world). non-deterministic worlds, fitness policy usually averaged
sample trials. options include measuring total payoff achieved
agent fixed number steps, measuring number steps required achieve
fixed level payoff.
fitness policies population determined, new population
generated according steps usual EA (Figure 2). First, parents selected
reproduction. typical selection method probabilistically select individuals based
relative fitness:
(pi )
Pr(pi ) = PnFitness
j =1 Fitness(pj )

(9)

pi represents individual n total number individuals. Using selection
rule, expected number offspring given policy proportional policy's
fitness. example, policy average fitness might single offspring, whereas
249

fiMoriarty, Schultz, & Grefenstette

Policy
1
2
3
4
5

a1


R

R

a2
R





a3






a4


R



a5
R
R
R
R
R

b1
R
R




b2
R
R
R
R
R

b3
R
R

R
R

b4
R
R
R
R


b5
R
R
R
R
R

c1



R
R

c2
R





c3

R

R
R

c4

R
R
R
R

c5
R


R


d1
R
R
R

R

d2



R


d3
R
R
R
R
R

d4
R
R
R

R

d5
R
R
R
R


e1






e2
R
R
R
R
R

e3
R





e4






e5 Fitness
R 8
R 9
17
R 11
16

Table 2: EA population five decision policies sample grid world. simple
policy representation specifies action state world. fitness
corresponds payoffs accumulated using policy grid
world.
policy twice average fitness would two offspring.2 Offspring formed
cloning selected parents. new policies generated applying standard
genetic operators crossover mutation clones, shown Figure 3. process
generating new populations strategies continue indefinitely terminated
fixed number generations acceptable level performance achieved.
simple RL problems grid-world, Earl1 may provide adequate approach. later sections, point ways even Earl1 exhibits
strengths complementary TD methods RL. However, case TD
methods, EARL methods extended handle many challenges inherent
realistic RL problems. following sections survey extensions, organized around three specific biases distinguish EAs Reinforcement Learning (EARL)
generic EAs: policy representations, fitness/credit-assignment models, RLspecific genetic operators.

5. Policy Representations EARL

Perhaps critical feature distinguishes classes EAs one another
representation used. example, EAs function optimization use simple string
vector representation, whereas EAs combinatorial optimization use distinctive representations permutations, trees graph structures. Likewise, EAs RL use
distinctive set representations policies. range potential policy representations unlimited, representations used EARL systems date
largely categorized along two discrete dimensions. First, policies may represented either condition-action rules neural networks. Second, policies may represented
single chromosome representation may distributed one
populations.

5.1 Single-Chromosome Representation Policies
5.1.1 Rule-based Policies

RL problems practical interest, number observable states large,
simple table-based representation Earl1 impractical. large scale state
2. Many parent selection rules explored (Grefenstette, 1997a, 1997b).

250

fiEvolutionary Algorithms Reinforcement Learning

Policy i:

c i1 ai1

c i2 ai2

c i3 ai3

...

c ik aik

Figure 6: Rule-based policy representation. gene represents condition-action rule
maps set states action. general, rules independent
position along chromosome. Con ict resolution mechanisms may
needed conditions rules allowed intersect.
w1
w k1
Policy i:

w1

w2

w3

...

wk

=>
...

wk
wj

Figure 7: simple parameter representation weights neural network. fitness
policy payoff agent uses corresponding neural net
decision policy.
spaces, reasonable represent policy set condition-action rules
condition expresses predicate matches set states, shown Figure 6. Early
examples representation include systems LS-1 (Smith, 1983) LS-2 (Schaffer
& Grefenstette, 1985), followed later Samuel (Grefenstette et al., 1990).
5.1.2 Neural Net Representation Policies

TD-based RL systems, EARL systems often employ neural net representations
function approximators. simplest case (see Figure 7), neural network
agent's decision policy represented sequence real-valued connection weights.
straightforward EA parameter optimization used optimize weights
neural network (Belew, McInerney, & Schraudolph, 1991; Whitley, Dominic, Das, &
Anderson, 1993; Yamauchi & Beer, 1993). representation thus requires least
modification standard EA. turn distributed representations policies
EARL systems.

5.2 Distributed Representation Policies

previous section outlined EARL approaches treat agent's decision policy
single genetic structure evolves time. section addresses EARL approaches
decompose decision policy smaller components. approaches two
potential advantages. First, allow evolution work detailed level task,
e.g., specific subtasks. Presumably, evolving solution restricted subtask
251

fiMoriarty, Schultz, & Grefenstette

Sensors

Message List

Rewards

Classifiers

Decision

Evolutionary
Algorithm

Figure 8: Holland's Learning Classifier System.
easier evolving monolithic policy complex task. Second, decomposition permits
user exploit background knowledge. user might base decomposition
subtasks prior analysis overall performance task; example, might known
certain subtasks mutually exclusive therefore learned independently.
user might also decompose complex task subtasks certain components
explicitly programmed components learned.
terms knowledge representation EARL, alternative single chromosome
representation distribute policy several population elements. assigning
fitness individual elements policy, evolutionary selection pressure
brought bear detailed aspects learning task. is, fitness
function individual subpolicies individual rules even individual neurons. general
approach analogous classic TD methods take approach extreme
learning statistics concerning state-action pair. case single-chromosome
representations, partition distributed EARL representations rule-based
neural-net-based classes.
5.2.1 Distributed Rule-based Policies

well-known example distributed rule-based approach EARL Learning Classifier Systems (LCS) model (Holland & Reitman, 1978; Holland, 1987; Wilson,
1994). LCS uses evolutionary algorithm evolve if-then rules called classifiers
map sensory input appropriate action. Figure 8 outlines Holland's LCS framework
(Holland, 1986). sensory input received, posted message list. left
hand side classifier matches message message list, right hand side posted
message list. new messages may subsequently trigger classifiers post
messages invoke decision LCS, traditional forward-chaining model
rule-based systems.
LCS, chromosome represents single decision rule entire population
represents agent's policy. general, classifiers map set observed states set
messages, may interpreted either internal state changes actions. example,
252

fiEvolutionary Algorithms Reinforcement Learning

condition
action strength
a#
! R
0.75
#2
!
0.25
d3

:::
!



0.50

Table 3: LCS population grid world. # don't care symbol allows
generality conditions. example, first rule says \Turn right column
a." strength rule used con ict resolution parent selection
genetic algorithm.

LCS
LCS

LCS

Environment

Figure 9: two-level hierarchical Alecsys system. LCS learns specific behavior.
interactions among rule sets pre-programmed.
learning agent grid world Figure 1 two sensors, one column
one row, population LCS might appear shown Table 3.
first classifier matches state column recommends action R. classifier
statistic called strength estimates utility rule. strength statistics
used con ict resolution (when one action recommended)
fitness genetic algorithm. Genetic operators applied highly fit classifiers
generate new rules. Generally, population size (i.e., number rules policy)
kept constant. Thus classifiers compete space policy.
Another way EARL systems distribute representation policies partition
policy separate modules, module updated EA. Dorigo
Colombetti (1998) describe architecture called Alecsys complex reinforcement learning task decomposed subtasks, learned via separate
LCS, shown Figure 9. provide method called behavior analysis training
(BAT) manage incremental training agents using distributed LCS architecture.
single-chromosome representation also extended partitioning policy across multiple co-evolving populations. example, cooperative co-evolution
model (Potter, 1997), agent's policy formed combining chromosomes several independently evolving populations. chromosome represents set rules,
Figure 6, rules address subset performance task. example,
separate populations might evolve policies different components complex task,
253

fiMoriarty, Schultz, & Grefenstette

EA
EA 1

Domain
Model
collaboration

fitness

Evolutionary
Algorithm

Population

representative

Merge

representative

individual

evaluated

representative

EA 2

EA n

representative

Figure 10: Cooperative coevolutionary architecture perspective ith EA instance. EA contributes representative, merged others'
representatives form collaboration, policy agent. fitness
representative ects average fitness collaborations.

might address mutually exclusive sets observed states. fitness chromosome
computed based overall fitness agents employ chromosome part
combined chromosomes. combined chromosomes represent decision policy
called collaboration (Figure 10).
5.2.2 Distributed Network-based Policies

Distributed EARL systems using neural net representations also designed.
(Potter & De Jong, 1995), separate populations neurons evolve, evaluation
neuron based fitness collaboration neurons selected population.
SANE (Moriarty & Miikkulainen, 1996a, 1998), two separate populations maintained
evolved: population neurons population network blueprints. motivation SANE comes priori knowledge individual neurons fundamental
building blocks neural networks. SANE explicitly decomposes neural network search
problem several parallel searches effective single neurons. neuron-level evolution provides evaluation recombination neural network building blocks,
population blueprints search effective combinations building blocks. Figure 11
gives overview interaction two populations.
individual blueprint population consists set pointers individuals
neuron population. generation, neural networks constructed
combining hidden neurons specified blueprint. blueprint receives fitness
according well corresponding network performs task. neuron receives
fitness according well top networks participates perform
task. aggressive genetic selection recombination strategy used quickly build
propagate highly fit structures neuron blueprint populations.
254

fiEvolutionary Algorithms Reinforcement Learning

Network Blueprint Population

Neuron Population

l

w

l

w

l

w

l

w

l

w

l

w

l

w

l

w

l

w

l

w

l

w

l

w

l

w

l

w

l

w

l

w

l

w

l

w

l

w

l

w

l

w

l

w

l

w

l

w

Figure 11: overview two populations SANE. member neuron population specifies series connections (connection labels weights)
made within neural network. member network blueprint population specifies series pointers specific neurons used build
neural network.

6. Fitness Credit Assignment EARL

Evolutionary algorithms driven concept natural selection: population
elements higher fitness leave offspring later generations, thus uencing
direction search favor high performance regions search space. concept
fitness central EA. section, discuss features fitness model
common across EARL systems. specifically focus ways fitness
function ects distinctive structure RL problem.

6.1 Agent Model

first common features EARL fitness models fitness computed
respect RL agent. is, however policy represented EA, must
converted decision policy agent operating RL environment. agent
assumed observe description current state, select next action consulting
current policy, collect whatever reward provided environment. EARL
systems, TD systems, agent generally assumed perform little additional
computation selecting next action. neither approach limits agent
strict stimulus-response behavior, usually assumed agent perform
extensive planning reasoning acting. assumption ects fact
RL tasks involve sort control activity agent must respond dynamic
environment within limited time frame.
255

fiMoriarty, Schultz, & Grefenstette

6.2 Policy Level Credit Assignment

shown previous section, meaning fitness EARL systems may vary depending population elements represent. single-chromosome representation,
fitness associated entire policies; distributed representation, fitness may associated individual decision rules. case, fitness always ects accumulated
rewards received agent course interaction environment,
specified RL model. Fitness may also ect effort expended, amount delay.
worthwhile considering different approaches credit assignment TD
EA methods. reinforcement learning problem, payoffs may sparse, is,
associated certain states. Consequently, payoff may ect quality
extended sequence decisions, rather individual decision. example, robot
may receive reward movement places \goal" position within room.
robot's reward, however, depends many previous movements leading
point. dicult credit assignment problem therefore exists apportion
rewards sequence decisions individual decisions.
general, EA TD methods address credit assignment problem different ways. TD approaches, credit reward signal explicitly propagated
decision made agent. many iterations, payoffs distributed across
sequence decisions appropriately discounted reward value associated
individual state decision pair.
simple EARL systems Earl1 , rewards associated sequences
decisions distributed individual decisions. Credit assignment
individual decision made implicitly, since policies prescribe poor individual decisions
fewer offspring future generations. selecting poor policies, evolution
automatically selects poor individual decisions. is, building blocks consisting
particular state-action pairs highly correlated good policies propagated
population, replacing state-action pairs associated poorer policies.
Figure 12 illustrates differences credit assignment TD Earl1
grid world Figure 1. Q-learning TD method explicitly assigns credit blame
individual state-action pair passing back immediate reward estimated payoff
new state. Thus, error term becomes associated action performed
agent. EA approach explicitly propagate credit action rather
associates overall fitness entire policy. Credit assigned implicitly, based
fitness evaluations entire sequences decisions. Consequently, EA tend select
policies generate first third sequences achieve lower fitness
scores. EA thus implicitly selects action state b2, example,
present bad sequences present good sequences.

6.3 Subpolicy Credit Assignment

Besides implicit credit assignment performed building blocks, EARL systems
also addressed credit assignment problem directly. shown Section 4,
individuals EARL system might represent either entire policies components
policy (e.g., component rule-sets, individual decision rules, individual neurons).
distributed-representation EARLs, fitness explicitly assigned individual components.
256

fiEvolutionary Algorithms Reinforcement Learning

TD Explicit Credit Assignment
2+Max(Q(b1,a))

a1,R

b1,D

2+Max(Q(b1,a))

a1,R

2+Max(Q(a2,a))

a1,D

1+Max(Q(b2,a))

a2,D

a1,R

b1,D

b2,D

b3,D

c3

2

c3

a1,R

b1,D

b2,R

c2,D

c3

9

c3

a1,D

a2,R

b2,D

b3,D

c3

1

d2

a1,D

a2,D

b2,R

c2,D

d2

8

4+Max(Q(c3,a))

4+Max(Q(c3,a))

b3,D

-5+Max(Q(c2,a))

b2,R

c3

c2,D

-5+Max(Q(b3,a))

b2,D

Fitness

4+Max(Q(c3,a))

b3,D

-5+Max(Q(c2,a))

b2,R

1+Max(Q(b2,a))

a2,R

-5+Max(Q(b3,a))

b2,D

1+Max(Q(b2,a))

b1,D

2+Max(Q(a2,a))

a1,D

1+Max(Q(b2,a))

EA Implicit Credit Assignment

4+Max(Q(d2,a))

c2,D

Figure 12: Explicit vs. implicit credit assignment. Q-learning TD method assigns credit
state-action pair based immediate reward predicted future
rewards. EA method assigns credit implicitly associating fitness values
entire sequences decisions.
cases policy represented explicit components, different fitness functions
associated different evolving populations, allowing implementer \shape"
overall policy evolving subpolicies specific subtasks (Dorigo & Colombetti, 1998;
Potter, De Jong, & Grefenstette, 1995). ambitious goal allow system
manage number co-evolving species well form interactions (Potter, 1997).
exciting research still early stage.
example, LCS model, classifier (decision rule) strength
updated using TD-like method called bucket brigade algorithm (Holland, 1986).
bucket brigade algorithm, strength classifier used bid classifiers
right post messages. Bids subtracted winning classifiers passed back
classifiers posted enabling message previous step. Classifier strengths
thus reinforced classifier posts message triggers another classifier.
classifier invokes decision LCS receives strength reinforcement directly
environment. bucket brigade bid passing mechanism clearly bears strong
relation method temporal differences (Sutton, 1988). bucket brigade updates
given classifier's strength based strength classifiers fire direct result
activation. TD methods differ slightly respect assign credit
based strictly temporal succession take account causal relations steps.
remains unclear appropriate distributing credit.
Even single chromosome representations, TD-like methods adopted
EARL systems. Samuel, gene (decision rule) also maintains quantity called
strength used resolve con ict one rule matches agent's current
sensor readings. payoff obtained (thereby terminating trial), strengths
257

fiMoriarty, Schultz, & Grefenstette

rules fired trial updated (Grefenstette, 1988). addition resolving
con icts, rule's strength also plays role triggering mutation operations, described
next section.

7. RL-Specific Genetic Operators

creation special genetic operators provides another avenue imposing RLspecific bias EAs. Specialized operators EARL systems first appeared (Holland,
1986), so-called triggered operators responsible creating new classifiers
learning agent found classifier existing population matched
agent's current sensor readings. case, high-strength rule explicitly generalized
cover new set sensor readings. similar rule-creation operator included
early versions Samuel (Grefenstette et al., 1990). Later versions Samuel included
number mutation operators created altered rules based agent's early
experiences. example, Samuel's Specialization mutation operator triggered
low-strength, general rule fires episode results high payoff.
case, rule's conditions reduced generality closely match agent's sensor
readings. example, agent sensor readings (range = 40; bearing = 100)
original rule is:
range = [25; 55] bearing = [0; 180] SET turn = 24 (strength
0.1)
new rule would be:
range = [35; 45] bearing = [50; 140] SET turn = 24 (strength
0.8)
Since episode triggering operator resulted high payoff, one might suspect
original rule over-generalized, new, specific version might lead
better results. (The strength new rule initialized payoff received
triggering episode.) considered Lamarckian operator agent's
experience causing genetic change passed later offspring.3
Samuel also uses RL-specific crossover operator recombine policies. particular,
crossover Samuel attempts cluster decision rules assigning offspring.
example, suppose traces previous evaluations parent strategies follows (Ri;j denotes j th decision rule policy i):
Trace parent #1:
Episode:
..
.
8. R1;3 ! R1;1 ! R1;7 ! R1;5 High Payoff
9. R1;2 ! R1;8 ! R1;4
Low Payoff
3. Jean Baptiste Lamarck developed evolutionary theory stressed inheritance acquired characteristics, particular acquired characteristics well adapted surrounding environment.
course, Lamarck's theory superseded Darwin's emphasis two-stage adaptation: undirected
variation followed selection. Research generally failed substantiate Lamarckian mechanisms
biological systems (Gould, 1980).

258

fiEvolutionary Algorithms Reinforcement Learning

..
.
Trace parent #2:
..
.
4. R2;7 ! R2;5
5. R2;6 ! R2;2 ! R2;4
..
.
one possible offspring would be:

Low Payoff
High Payoff

fR1;8 ; : : :; R1;3 ; R1;1 ; R1;7 ; R1;5 ; : : :; R2;6 ; R2;2 ; R2;4 ; : : :; R2;7g
motivation rules fire sequence achieve high payoff
treated group recombination, order increase likelihood offspring
policy inherit better behavior patterns parents. Rules
fire successful episodes (e.g., R1;8) randomly assigned one two offspring.
form crossover Lamarckian (since triggered experiences
agent), directly related structure RL problem, since groups
components policies according temporal association among decision rules.

8. Strengths EARL

EA approach represents interesting alternative solving RL problems, offering
several potential advantages scaling realistic applications. particular, EARL
systems developed address dicult challenges RL problems, including:
Large state spaces;
Incomplete state information;
Non-stationary environments.
section focuses ways EARL address challenges.

8.1 Scaling Large State Spaces

Many early papers RL literature analyze eciency alternative learning methods
toy problems similar grid world shown Figure 1. studies useful
academic exercises, number observed states realistic applications RL likely
preclude approach requires explicit storage manipulation statistics
associated observable state-action pair. two ways EARL policy
representations help address problem large state spaces: generalization selectivity.
8.1.1 Policy Generalization

EARL policy representations specify policy level abstraction higher
explicit mapping observed states actions. case rule-based representations,
rule language allows conditions match sets states, thus greatly reducing storage
259

fiMoriarty, Schultz, & Grefenstette

a1 a2 a3 a4 a5 b1 b2 b3 b4 b5 c1 c2 c3 c4 c5 d1 d2 d3 d4 d5 e1 e2 e3 e4 e5
R 16 7 ? 17 12 8 12 11 11 12 14 7 12 13 9 12 11 12 12 11 ? 12 7 ? 9
L 9 13 12 11 ? 15 ? 17 16 ? 11 13 12 7 14 11 12 ? 11 16 12 ? 13 12 16

Table 4: approximated value function population Table 2. table displays average fitness policies select state-action pair ects
estimated impact action overall fitness. Given tiny population
size example, estimates particularly accurate. Note question
marks states actions converged. Since policies select alternative action, population statistics impact actions
fitness. different simple TD methods, statistics actions
maintained.

required specify policy. noted, however, generality rules
within policy may vary considerably, level rules specify action
single observed state way completely general rules recommend action
regardless current state. Likewise, neural net representations, mapping function
stored implicitly weights connections neural net. either case,
generalized policy representation facilitates search good policies grouping together
states action required.
8.1.2 Policy Selectivity

EARL systems selective representations policies. is, EA learns mappings observed states recommended actions, usually eliminating explicit information
concerning less desirable actions. Knowledge bad decisions explicitly preserved,
since policies make decisions selected evolutionary algorithm
eventually eliminated population. advantage selective representations attention focused profitable actions only, reducing space requirements
policies.
Consider example simple EARL operating grid world. population evolves, policies normally converge best actions specific state,
selective pressure achieve high fitness levels. example, population shown
Table 2 converged alleles (actions) states a3; a5; b2; b5; d3; e1; e2.
converged state-action pairs highly correlated fitness. example, policies
converged action R state b2. Taking action R state b2 achieves much higher
expected return action (15 vs. 8 Table 1). Policies select action
state b2 achieve lower fitness scores selected against. simple EARL, snapshot population (Table 2) provides implicit estimate corresponding TD value
function (Table 4), distribution biased toward profitable state-actions
pairs.
260

fiEvolutionary Algorithms Reinforcement Learning

.5
L

3.0
L

Red

R

Blue

R
1.0

Green

L

Blue

L

- 4.0

R
R
1.0
.75

Figure 13: environment incomplete state information. circles represent
states world colors represent agent's sensory input. agent
equally likely start red state green state

8.2 Dealing Incomplete State Information

Clearly, favorable condition reinforcement learning occurs agent
observe true state dynamic system interacts. complete state
information available, TD methods make ecient use available feedback associating
reward directly individual decisions. real world situations, however, agent's
sensors likely provide partial view may fail disambiguate many
states. Consequently, agent often unable completely distinguish current
state. problem termed perceptual aliasing hidden state problem.
case limited sensory information, may useful associate rewards
larger blocks decisions. Consider situation Figure 13, agent must
act without complete state information. Circles represent specific states world,
colors represent sensor information agent receives within state. Square
nodes represent goal states corresponding reward shown inside. state,
agent choice two actions (L R). assume state transitions
deterministic agent equally likely start either state
red green sensor readings.
example, two different states return sensor reading blue,
agent unable distinguish them. Moreover, actions blue
state return different rewards. Q function applied problem treats sensor
reading blue one observable state, rewards action averaged
blue states. Thus, Q(blue; L) Q(blue; R) converge -0.5 1, respectively.
Since reward Q(blue; R) higher alternatives observable states red
green, agent's policy Q-learning choose enter observable state blue
time. final decision policy Q-learning shown Table 5. table also
shows optimal policy respect agent's limited view world.
261

fiMoriarty, Schultz, & Grefenstette

Value Function Policy Optimal Policy
R
R
L
R
R
L
Expected Reward
1.0
1.875

Red
Green
Blue

Table 5: policy expected reward returned converged Q function compared
optimal policy given sensory information.
words, policy ects optimal choices agent cannot distinguish two blue
states.
associating values individual observable states, simple TD methods
vulnerable hidden state problems. example, ambiguous state information
misleads TD method, mistakenly combines rewards two different states
system. confounding information multiple states, TD cannot recognize
advantages might associated specific actions specific states, example,
action L top blue state achieves high reward.
contrast, since EA methods associate credit entire policies, rely
net results decision sequences sensor information, may, all,
ambiguous. example, evolutionary algorithm exploits disparity rewards
different blue states evolves policies enter good blue state avoid
bad one. agent remains unable distinguish two blue states, evolutionary algorithm implicitly distinguishes among ambiguous states rewarding policies
avoid bad states.
example, EA method expected evolve optimal policy current
example given existing, ambiguous state information. Policies choose action
sequence R,L starting red state achieve highest levels fitness,
therefore selected reproduction EA. agents using policies
placed green state select action L, receive lowest fitness score, since
subsequent action, L blue sensors, returns negative reward. Thus, many
policies achieve high fitness started red state selected
choose L green state. course many generations, policies must
choose action R green state maximize fitness ensure survival.
confirmed hypotheses empirical tests. Q-learner using single-step updates
table-based representation converged values Table 5 every run.
evolutionary algorithm4 consistently converged 80% population optimal policy.
Figure 14 shows average percentage optimal policy population function
time, averaged 100 independent runs.
Thus even simple EA methods Earl1 appear robust presence
hidden states simple TD methods. However, refined sensor information could
still helpful. previous example, although EA policies achieve better average
reward TD policy, evolved policy remains unable procure 3.0
4. used binary tournament selection, 50 policy population, 0.8 crossover probability, 0.01
mutation rate.

262

fiEvolutionary Algorithms Reinforcement Learning

100

Percentage Optimal

80

60

40

20

0
0

10

20

30

40

50
Generation

60

70

80

90

100

Figure 14: optimal policy distribution hidden state problem evolutionary
algorithm. graph plots percentage optimal policies population,
averaged 100 runs.
1.0 rewards two blue states. rewards could realized, however,
agent could separate two blue states. Thus, method generates additional
features disambiguate states presents important asset EA methods. Kaelbling
et al. (1996) describe several promising solutions hidden state problem,
additional features agent's previous decisions observations automatically
generated included agent's sensory information (Chrisman, 1992; Lin & Mitchell,
1992; McCallum, 1995; Ring, 1994). methods effective disambiguating
states TD methods initial studies, research required determine
extent similar methods resolve significant hidden state information realistic
applications. would useful develop ways use methods augment sensory
data available EA methods well.

8.3 Non-Stationary Environments

agent's environment changes time, RL problem becomes even dicult,
since optimal policy becomes moving target. classic trade-off exploration
exploitation becomes even pronounced. Techniques encouraging exploration
TD-based RL include adding exploration bonus estimated value state-action
pairs ects long since agent tried action (Sutton, 1990),
building statistical model agent's uncertainty (Dayan & Sejnowski, 1996).
Simple modifications standard evolutionary algorithms offer ability track nonstationary environments, thus provide promising approach RL dicult
cases.
fact evolutionary search based competition within population policies
suggest immediate benefits tracking non-stationary environments. extent
population maintains diverse set policies, changes environment bias
263

fiMoriarty, Schultz, & Grefenstette

selective pressure favor policies fit current environment.
long environment changes slowly respect time required evaluate
population policies, population able track changing fitness landscape
without alteration algorithm. Empirical studies show maintaining
diversity within population may require higher mutation rate usually
adopted stationary environments (Cobb & Grefenstette, 1993).
addition, special mechanisms explored order make EAs responsive rapidly changing environments. example, (Grefenstette, 1992) suggests
maintaining random search within restricted portion population. random
population elements analogous immigrants populations uncorrelated
fitness landscapes. Maintaining source diversity permits EA respond rapidly
large, sudden changes fitness landscape. keeping randomized portion
population less 30% population, impact search eciency
stationary environments minimized. general approach easily applied
EARL systems.
useful algorithms developed ensure diversity evolving popultions include fitness sharing (Goldberg & Richardson, 1987), crowding (De Jong, 1975),
local mating (Collins & Jefferson, 1991). Goldberg's fitness sharing model, example, similar individuals forced share large portion single fitness value
shared solution point. Sharing decreases fitness similar individuals causes
evolution select individuals overpopulated niches.
EARL methods employ distributed policy representations achieve diversity automatically well-suited adaptation dynamic environments. distributed
representation, individual represents partial solution. Complete solutions
built combining individuals. individual solve task own,
evolutionary algorithm search several complementary individuals together
solve task. Evolutionary pressures therefore present prevent convergence
population. Moriarty Miikkulainen (1998) showed inherent diversity specialization SANE allow adapt much quickly changes environment
standard, convergent evolutionary algorithms.
Finally, learning system detect changes environment, even direct
response possible. anytime learning model (Grefenstette & Ramsey, 1992),
EARL system maintains case-base policies, indexed values environmental
detectors corresponding environment given policy evolved.
environmental change detected, population policies partially reinitialized,
using previously learned policies selected basis similarity previously
encountered environment current environment. result, environment
changes cyclic, population immediately seeded policies
effect last occurrence current environment. population
policies, approach protected kinds errors detecting environmental
changes. example, even spurious environmental change mistakenly detected,
learning unduly affected, since part current population policies
replaced previously learned policies. Zhou (1990) explored similar approach based
LCS.
264

fiEvolutionary Algorithms Reinforcement Learning

summary, EARL systems respond non-stationary environments, techniques generic evolutionary algorithms techniques specifically designed RL mind.

9. Limitations EARL
Although EA approach RL promising growing list successful applications (as outlined following section), number challenges remain.

9.1 Online Learning
distinguish two broad approaches reinforcement learning |online learning
oine learning. online learning, agent learns directly experiences
operational environment. example, robot might learn navigate warehouse
actually moving physical environment. two problems using EARL
situation. First, likely require large number experiences order
evaluate large population policies. Depending quickly agent performs tasks
result environmental feedback, may take unacceptable amount time
run hundreds generations EA evaluates hundreds thousands policies.
Second, may dangerous expensive permit agent perform actions
actual operational environment might cause harm environment. Yet
likely least policies EA generates bad policies.
objections apply TD methods well. example, theoretical results
prove optimality Q-learning require every state visited infinitely often,
obviously impossible practice. Likewise, TD methods may explore
undesirable states acceptable value-function found.
TD EARL, practical considerations point toward use oine learning,
RL system performs exploration simulation models environment.
Simulation models provide number advantages EARL, including ability
perform parallel evaluations policies population simultaneously (Grefenstette,
1995).

9.2 Rare States
memory record observed states rewards differs greatly EA TD
methods. Temporal difference methods normally maintain statistics concerning every stateaction pair. states revisited, new reinforcement combined previous
value. New information thus supplements previous information, information content agent's reinforcement model increases exploration. manner, TD
methods sustain knowledge good bad state-action pairs.
pointed previously, EA methods normally maintain information good
policies policy components. Knowledge bad decisions explicitly preserved, since
policies make decisions selected evolutionary algorithm
eventually eliminated population. example, refer Table 4,
shows implicit statistics population Table 2. Note question
265

fiMoriarty, Schultz, & Grefenstette

marks states actions converged. Since policies population select
alternative action, EA statistics impact actions fitness.
reduction information content within evolving population disadvantage respect states rarely visited. evolutionary algorithm, value
genes real impact fitness individual tends drift random
values, since mutations tend accumulate genes. state rarely encountered,
mutations may freely accumulate gene describes best action state.
result, even evolutionary algorithm learns correct action rare state,
information may eventually lost due mutations. contrast, since table-based TD
methods permanently record information state-action pairs, may
robust learning agent encounter rare state. course, TD method
uses function approximator neural network value function,
suffer memory loss concerning rare states, since many updates frequently
occurring states dominate updates rare states.

9.3 Proofs Optimality

One attractive features TD methods Q-learning algorithm proof
optimality (Watkins & Dayan, 1992). However, practical importance result
limited, since assumptions underlying proof (e.g., hidden states, state visited
infinitely often) satisfied realistic applications. current theory evolutionary
algorithms provide similar level optimality proofs restricted classes search spaces
(Vose & Wright, 1995). However, general theoretical tools available
applied realistic RL problems. case, ultimate convergence optimal policy
may less important practice eciently finding reasonable approximation.
pragmatic approach may ask ecient alternative RL algorithms are,
terms number reinforcements received developing policy within
tolerance level optimal policy. model probably approximately correct
(PAC) learning (Valiant, 1984), performance learner measured many
learning experiences (e.g., samples supervised learning) required converging
correct hypothesis within specified error bounds. Although developed initially
supervised learning, PAC approach extended recently TD methods
(Fiechter, 1994) general EA methods (Ros, 1997). analytic methods
still early stage development, research along lines may one day
provide useful tools understanding theoretical practical advantages alternative
approaches RL. time, experimental studies provide valuable evidence
utility approach.

10. Examples EARL Methods

Finally, take look significant examples EARL approach results
RL problems. Rather attempt exhaustive survey, selected four EARL
systems representative diverse policies representations outlined Section 5.
Samuel represents class single-chromosome rule-based EARL systems. Alecsys
example distributed rule-based EARL method. Genitor single chromosome
neural-net system, Sane distributed neural net system. brief survey
266

fiEvolutionary Algorithms Reinforcement Learning

provide starting point interested investigating evolutionary approach
reinforcement learning.

10.1

Samuel
Samuel (Grefenstette et al., 1990) EARL system combines Darwinian Lamarckian evolution aspects temporal difference reinforcement learning. Samuel

used learn behaviors navigation collision avoidance, tracking, herding, robots autonomous vehicles.
Samuel uses single-chromosome, rule-based representation policies, is,
member population policy represented rule set gene rule
maps state world actions performed. example rule might be:
range = [35; 45] bearing = [0; 45] SET turn = 16 (strength
0.8)
use high-level language rules offers several advantages low-level binary
pattern languages typically adopted genetic learning systems. First, makes easier
incorporate existing knowledge, whether acquired experts symbolic learning programs. Second, easier transfer knowledge learned human operators. Samuel
also includes mechanisms allow coevolution multiple behaviors simultaneously.
addition usual genetic operators crossover mutation, Samuel uses traditional machine learning techniques form Lamarckian operators. Samuel keeps
record recent experiences allow operators generalization, specialization,
covering, deletion make informed changes individual genes (rules) based
experiences.
Samuel used successfully many reinforcement learning applications.
brie describe three examples learning complex behaviors real robots.
applications Samuel, learning performed simulation, ecting fact
initial phases learning, controlling real system expensive
dangerous. Learned behaviors tested on-line system.
(Schultz & Grefenstette, 1992; Schultz, 1994; Schultz & Grefenstette, 1996), Samuel
used learn collision avoidance local navigation behaviors Nomad 200 mobile
robot. sensors available learning task five sonars, five infrared sensors,
range bearing goal, current speed vehicle. Samuel
learned mapping sensors controllable actions { turning rate
translation rate wheels. Samuel took human-written rule set could reach
goal within limited time without hitting obstacle 70 percent time,
50 generations able obtain 93.5 percent success rate.
(Schultz & Grefenstette, 1996), robot learned herd second robot \pasture". task, learning system used range bearing second robot,
heading second robot, range bearing goal, input sensors.
system learned mapping sensors turning rate steering rate.
experiments, success measured percentage times robot could
maneuver second robot goal within limited amount time. second robot
implemented random walk, plus behavior made avoid nearby obstacles.
first robot learned exploit achieve goal moving second robot goal.
267

fiMoriarty, Schultz, & Grefenstette

Samuel given initial, human-designed rule set performance 27 percent,
250 generations able move second robot goal 86 percent
time.
(Grefenstette, 1996) Samuel EA system combined case-based learning
address adaptation problem. approach, called anytime learning (Grefenstette &
Ramsey, 1992), learning agent interacts external environment
internal simulation. anytime learning approach involves two continuously running
interacting modules: execution module learning module. execution
module controls agent's interaction environment includes monitor
dynamically modifies internal simulation model based observations actual agent
environment. learning module continuously tests new strategies agent
simulation model, using genetic algorithm evolve improved strategies,
updates knowledge base used execution module best available results.
Whenever simulation model modified due observed change agent
environment, genetic algorithm restarted modified model. learning system
operates indefinitely, execution system uses results learning become
available. work Samuel shows EA method particularly well-suited
anytime learning. Previously learned strategies treated cases, indexed
set conditions learned. new situation encountered,
nearest neighbor algorithm used find similar previously learned cases.
nearest neighbors used re-initialize genetic population policies new case.
Grefenstette (1996) reports experiments mobile robot learns track another
robot, dynamically adapts policies using anytime learning encounters series
partial system failures. approach blurs line online oine learning,
since online system updated whenever oine learning system develops
improved policy. fact, oine learning system even executed on-board
operating mobile robot.

10.2

Alecsys

described previously, Alecsys (Dorigo & Colombetti, 1998) distributed rule-based
EA supports approach design autonomous systems called behavioral engineering. approach, tasks performed complex autonomous systems
decomposed individual behaviors, learned via learning classifier systems module, shown Figure 9. decomposition performed human designer,
fitness function associated LCS carefully designed ect role
associated component behavior within overall autonomous system. Furthermore,
interactions among modules also preprogrammed. example, designer may
decide robot learn approach goal except threatening predator
near, case robot evade predator. overall architecture
set behaviors set evasion behavior higher priority
goal-seeking behavior, individual LCS modules evolve decision rules
optimally performing subtasks.
Alecsys used develop behavioral rules number behaviors
autonomous robots, including complex behavior groups Chase/Feed/Escape
268

fiEvolutionary Algorithms Reinforcement Learning

(Dorigo & Colombetti, 1998). approach implemented tested
simulated robots real robots. exploits human design EARL
methods optimize system performance, method shows much promise scaling
realistic tasks.

10.3

Genitor

Genitor (Whitley & Kauth, 1988; Whitley, 1989) aggressive, general purpose genetic

algorithm shown effective specialized use reinforcement-learning
problems. Whitley et al. (1993) demonstrated Genitor eciently evolve decision
policies represented neural networks using limited reinforcement domain.
Genitor relies solely evolutionary algorithm adjust weights neural
networks. solving RL problems, member population Genitor represents
neural network sequence connection weights. weights concatenated realvalued chromosome along gene represents crossover probability. crossover
gene determines whether network mutated (randomly perturbed) whether
crossover operation (recombination another network) performed. crossover
gene modified passed offspring based offspring's performance compared
parent. offspring outperforms parent, crossover probability decreased.
Otherwise, increased. Whitley et al. refer technique adaptive mutation,
tends increase mutation rate populations converge. Essentially, method
promotes diversity within population encourage continual exploration solution
space.
Genitor also uses so-called \steady-state" genetic algorithm new parents
selected genetic operators applied individual evaluated. approach
contrasts \generational" GAs entire population evaluated replaced
generation. steady-state GA, policy evaluated retains
fitness value indefinitely. Since policies lower fitness likely
replaced, possible fitness based noisy evaluation function may
undesirable uence direction search. case pole-balancing RL
application, fitness value depends length time policy maintain
good balance, given randomly chosen initial state. fitness therefore random
variable depends initial state. authors believe noise fitness
function little negative impact learning good policies, perhaps
dicult poor networks obtain good fitness good networks (of
many copies population) survive occasional bad fitness evaluation.
interesting general issue EARL needs analysis.
Genitor adopts specific modification RL applications. First, representation uses real-valued chromosome rather bit-string representation weights.
Consequently, Genitor always recombines policies weight definitions, thus reducing potentially random disruption neural network weights might result crossover
operations occurred middle weight definition. second modification
high mutation rate helps maintain diversity promote rapid exploration
policy space. Finally, Genitor uses unusually small populations order discourage
different, competing neural network \species" forming within population. Whit269

fiMoriarty, Schultz, & Grefenstette

ley et al. (1993) argue speciation leads competing conventions produces poor
offspring two dissimilar networks recombined.
Whitley et al. (1993) compare Genitor Adaptive Heuristic Critic (Anderson,
1989, AHC), uses TD method reinforcement learning. several different
versions common pole-balancing benchmark task, Genitor found comparable AHC learning rate generalization. One interesting difference
Whitley et al. found Genitor consistent AHC solving
pole-balancing problem failure signals occurs wider pole bounds (make
problem much harder). AHC, preponderance failures appears cause states
overpredict failure. contrast, EA method appears effective finding policies
obtain better overall performance, even success uncommon. difference seems
EA tends ignore cases pole cannot balanced, concentrate successful cases. serves another example advantages associated
search policy space, based overall policy performance, rather paying
much attention value associated individual states.

10.4

Sane

Sane (Symbiotic, Adaptive Neuro-Evolution) system designed ecient method
building artificial neural networks RL domains possible generate
training data normal supervised learning (Moriarty & Miikkulainen, 1996a, 1998).
Sane system uses evolutionary algorithm form hidden layer connections
weights neural network. neural network forms direct mapping sensors
actions provides effective generalization state space. Sane's method
credit assignment EA, allows apply many problems
reinforcement sparse covers sequence decisions. described previously, Sane
uses distributed representation policies.
Sane offers two important advantages reinforcement learning normally
present implementations neuro-evolution. First, maintains diverse populations.
Unlike canonical function optimization EA converge population single solution, Sane forms solutions unconverged population. several different types
neurons necessary build effective neural network, inherent evolutionary
pressure develop neurons perform different functions thus maintain several different types individuals within population. Diversity allows recombination operators
crossover continue generate new neural structures even prolonged evolution.
feature helps ensure solution space explored eciently throughout
learning process. Sane therefore resilient suboptimal convergence
adaptive changes domain.
second feature Sane explicitly decomposes search complete solutions search partial solutions. Instead searching complete neural networks
once, solutions smaller problems (good neurons) evolved, combined form effective full solution (a neural network). words, Sane effectively
performs problem reduction search space neural networks.
Sane shown effective several different large scale problems. one problem,
Sane evolved neural networks direct focus minimax game-tree search (Moriarty
270

fiEvolutionary Algorithms Reinforcement Learning

& Miikkulainen, 1994). selecting moves evaluated given game
situation, Sane guides search away misinformation search tree towards
effective moves. Sane tested game tree search Othello using
evaluation function former world champion program Bill (Lee & Mahajan, 1990).
Tested full-width minimax search, Sane significantly improved play Bill,
examining subset board positions.
second application, SANE used learn obstacle avoidance behaviors
robot arm (Moriarty & Miikkulainen, 1996b). approaches learning robot arm
control learn hand-eye coordination supervised training methods examples
correct behavior explicitly given. Unfortunately domains obstacles
arm must make several intermediate joint rotations reaching target, generating
training examples extremely dicult. reinforcement learning approach, however,
require examples correct behavior learn intermediate movements
general reinforcements. Sane implemented form neuro-control networks capable
maneuvering OSCAR-6 robot arm among obstacles reach random target locations.
Given camera-based visual infrared sensory input, neural networks learned
effectively combine target reaching obstacle avoidance strategies.
related examples evolutionary methods learning neural-net control
systems robotics, reader see (Cliff, Harvey, & Husbands, 1993; Husbands,
Harvey, & Cliff, 1995; Yamauchi & Beer, 1993).

11. Summary
article began suggesting two distinct approaches solving reinforcement learning
problems; one search value function space one search policy space. TD
EARL examples two complementary approaches. approaches assume
limited knowledge underlying system learn experimenting different policies using reinforcement alter policies. Neither approach requires precise
mathematical model domain, may learn direct interactions
operational environment.
Unlike TD methods, EARL methods generally base fitness overall performance
policy. sense, EA methods pay less attention individual decisions TD
methods do. first glance, approach appears make less ecient use
information, may fact provide robust path toward learning good policies, especially
situations sensors inadequate observe true state world.
useful view path toward practical RL systems choice EA
TD methods. tried highlight strengths evolutionary
approach, also shown EARL TD, complementary approaches,
means mutually exclusive. cited examples successful EARL systems
Samuel Alecsys explicitly incorporate TD elements multilevel credit assignment methods. likely many practical applications depend
kinds multi-strategy approaches machine learning.
also listed number areas need work, particularly theoretical side. RL, would highly desirable better tools predicting
amount experience needed learning agent reaching specified level per271

fiMoriarty, Schultz, & Grefenstette

formance. existing proofs optimality Q-learning EA extremely
limited practical use predicting well either approach perform realistic problems. Preliminary results shown tools PAC analysis applied
EA TD methods, much effort needed direction.
Many serious challenges remain scaling reinforcement learning methods realistic applications. pointing shared goals concerns two complementary
approaches, hope motivate collaboration progress field.

References

Anderson, C. W. (1989). Learning control inverted pendulum using neural networks.
IEEE Control Systems Magazine, 9, 31{37.
Barto, A. G., Sutton, R. S., & Watkins, C. J. C. H. (1990). Learning sequential
decision making. Gabriel, M., & Moore, J. W. (Eds.), Learning Computational
Neuroscience. MIT Press, Cambridge, MA.
Belew, R. K., McInerney, J., & Schraudolph, N. N. (1991). Evolving networks: Using
genetic algorithm connectionist learning. Farmer, J. D., Langton, C.,
Rasmussen, S., & Taylor, C. (Eds.), Artificial Life II Reading, MA. Addison-Wesley.
Chrisman, L. (1992). Reinforcement learning perceptual aliasing: perceptual
distinctions approach. Proceedings Tenth National Conference Artificial
Intelligence, pp. 183{188 San Jose, CA.
Cliff, D., Harvey, I., & Husbands, P. (1993). Explorations evolutionary robotics. Adaptive
Behavior, 2, 73{110.
Cobb, H. G., & Grefenstette, J. J. (1993). Genetic algorithms tracking changing environments. Proc. Fifth International Conference Genetic Algorithms, pp. 523{530.
Collins, R. J., & Jefferson, D. R. (1991). Selection massively parallel genetic algorithms.
Proceedings Fourth International Conference Genetic Algorithms, pp.
249{256 San Mateo, CA. Morgan Kaufmann.
Dayan, P., & Sejnowski, T. J. (1996). Exploration bonuses dual control. Machine
Learning, 25 (1), 5{22.
De Jong, K. A. (1975). Analysis Behavior Class Genetic Adaptive Systems.
Ph.D. thesis, University Michigan, Ann Arbor, MI.
Dorigo, M., & Colombetti, M. (1998). Robot Shaping: Experiment Behavioral Engineering. MIT Press, Cambridge, MA.
Fiechter, C.-N. (1994). Ecient reinforcement learning. Proceedings Seventh
Annual ACM Conference Computational Learning Theory, pp. 88{97. Association
Computing Machinery.
Fogel, L. J., Owens, A. J., & Walsh, M. J. (1966). Artificial Intelligence Simulated
Evolution. Wiley Publishing, New York.
272

fiEvolutionary Algorithms Reinforcement Learning

Goldberg, D. E. (1989). Genetic Algorithms Search, Optimization, Machine Learning. Addison-Wesley, Reading, MA.
Goldberg, D. E., & Richardson, J. (1987). Genetic algorithms sharing multimodal
function optimization. Proceedings Second International Conference Genetic Algorithms, pp. 148{154 San Mateo, CA. Morgan Kaufmann.
Grefenstette, J. J. (1986). Optimization control parameters genetic algorithms. IEEE
Transactions Systems, Man & Cybernetics, SMC-16 (1), 122{128.
Grefenstette, J. J. (1987). Incorporating problem specific knowledge genetic algorithms.
Davis, L. (Ed.), Genetic Algorithms Simulated Annealing, pp. 42{60 San Mateo,
CA. Morgan Kaufmann.
Grefenstette, J. J. (1988). Credit assignment rule discovery system based genetic
algorithms. Machine Learning, 3 (2/3), 225{245.
Grefenstette, J. J. (1992). Genetic algorithms changing environments. Manner, R.,
& Manderick, B. (Eds.), Parallel Problem Solving Nature, 2, pp. 137{144.
Grefenstette, J. J. (1995). Robot learning parallel genetic algorithms networked
computers. Proceedings 1995 Summer Computer Simulation Conference
(SCSC '95), pp. 352{257.
Grefenstette, J. J. (1996). Genetic learning adaptation autonomous robots. Robotics
Manufacturing: Recent Trends Research Applications, Volume 6, pp. 265{
270. ASME Press, New York.
Grefenstette, J. J. (1997a). Proportional selection sampling algorithms. Handbook
Evolutionary Computation, chap. C2.2. IOP Publishing Oxford University Press.
Grefenstette, J. J. (1997b). Rank-based selection. Handbook Evolutionary Computation, chap. C2.4. IOP Publishing Oxford University Press.
Grefenstette, J. J., & Ramsey, C. L. (1992). approach anytime learning. Proc.
Ninth International Conference Machine Learning, pp. 189{195 San Mateo, CA.
Morgan Kaufmann.
Grefenstette, J. J., Ramsey, C. L., & Schultz, A. C. (1990). Learning sequential decision
rules using simulation models competition. Machine Learning, 5, 355{381.
Holland, J. H. (1975). Adaptation Natural Artificial Systems: Introductory
Analysis Applications Biology, Control Artificial Intelligence. University
Michigan Press, Ann Arbor, MI.
Holland, J. H. (1986). Escaping brittleness: possibilities general-purpose learning
algorithms applied parallel rule-based systems. Machine Learning: Artificial
Intelligence Approach, Vol. 2. Morgan Kaufmann, Los Altos, CA.
273

fiMoriarty, Schultz, & Grefenstette

Holland, J. H. (1987). Genetic algorithms classifier systems: Foundations future
directions. Proceedings Second International Conference Genetic Algorithms, pp. 82{89 Hillsdale, New Jersey.
Holland, J. H., & Reitman, J. S. (1978). Cognitive systems based adaptive algorithms.
Pattern-Directed Inference Systems. Academic Press, New York.
Husbands, P., Harvey, I., & Cliff, D. (1995). Circle round: state space attractors
evolved sighted robots. Robot. Autonomous Systems, 15, 83{106.
Kaelbling, L. P., Littman, M. L., & Moore, A. W. (1996). Reinforcement learning: survey.
Journal Artificial Intelligence Research, 4, 237{285.
Koza, J. R. (1992). Genetic Programming: Programming Computers Means
Natural Selection. MIT Press, Cambridge, MA.
Lee, K.-F., & Mahajan, S. (1990). development world class Othello program.
Artificial Intelligence, 43, 21{36.
Lin, L.-J., & Mitchell, T. M. (1992). Memory approaches reinforcement learning nonMarkovian domains. Tech. rep. CMU-CS-92-138, Carnegie Mellon University, School
Computer Science.
McCallum, A. K. (1995). Reinforcement Learning Selective Perception Hidden
State. Ph.D. thesis, University Rochester.
Moriarty, D. E., & Miikkulainen, R. (1994). Evolving neural networks focus minimax
search. Proceedings Twelfth National Conference Artificial Intelligence
(AAAI-94), pp. 1371{1377 Seattle, WA. MIT Press.
Moriarty, D. E., & Miikkulainen, R. (1996a). Ecient reinforcement learning
symbiotic evolution. Machine Learning, 22, 11{32.
Moriarty, D. E., & Miikkulainen, R. (1996b). Evolving obstacle avoidance behavior
robot arm. Animals Animats: Proceedings Fourth International
Conference Simulation Adaptive Behavior (SAB-96), pp. 468{475 Cape Cod,
MA.
Moriarty, D. E., & Miikkulainen, R. (1998). Forming neural networks ecient
adaptive co-evolution. Evolutionary Computation, 5 (4), 373{399.
Potter, M. A. (1997). Design Analysis Computational Model Cooperative
Coevolution. Ph.D. thesis, George Mason University.
Potter, M. A., & De Jong, K. A. (1995). Evolving neural networks collaborative
species. Proceedings 1995 Summer Computer Simulation Conference Ottawa,
Canada.
Potter, M. A., De Jong, K. A., & Grefenstette, J. (1995). coevolutionary approach
learning sequential decision rules. Eshelman, L. (Ed.), Proceedings Sixth
International Conference Genetic Algorithms Pittsburgh, PA.
274

fiEvolutionary Algorithms Reinforcement Learning

Rechenberg, I. (1964). Cybernetic solution path experimental problem. Library
Translation 1122. Royal Aircraft Establishment, Farnborough, Hants, Aug. 1965.
Ring, M. B. (1994). Continual Learning Reinforcement Environments. Ph.D. thesis,
University Texas Austin.
Ros, J. P. (1997). Probably approximately correct (PAC) learning analysis. Handbook
Evolutionary Computation, chap. B2.8. IOP Publishing Oxford University Press.
Schaffer, J. D., Caruana, R. A., Eshelman, L. J., & Das, R. (1989). study control
parameters affecting online performance genetic algorithms function optimization. Proceedings Third International Conference Genetic Algorithms,
pp. 51{60. Morgan Kaufmann.
Schaffer, J. D., & Grefenstette, J. J. (1985). Multi-objective learning via genetic algorithms.
Proceedings Ninth International Joint Conference Artificial Intelligence,
pp. 593{595. Morgan Kaufmann.
Schultz, A. C. (1994). Learning robot behaviors using genetic algorithms. Intelligent
Automation Soft Computing: Trends Research, Development, Applications,
pp. 607{612. TSI Press, Albuquerque.
Schultz, A. C., & Grefenstette, J. J. (1992). Using genetic algorithm learn behaviors
autonomous vehicles. Proceedings AiAA Guidance, Navigation, Control
Conference Hilton Head, SC.
Schultz, A. C., & Grefenstette, J. J. (1996). Robo-shepherd: Learning complex robotic behaviors. Robotics Manufacturing: Recent Trends Research Applications,
Volume 6, pp. 763{768. ASME Press, New York.
Smith, S. F. (1983). Flexible learning problem solving heuristics adaptive search.
Proceedings Eighth International Joint Conference Artificial Intelligence,
pp. 422{425. Morgan Kaufmann.
Sutton, R. (1990). Integrated architectures learning, planning, reacting based
approximate dynamic programming. Machine Learning: Proceedings Seventh
International Conference, pp. 216{224.
Sutton, R. S. (1988). Learning predict methods temporal differences. Machine
Learning, 3, 9{44.
Sutton, R. S., & Barto, A. (1998). Reinforcement Learning: Introduction. MIT Press,
Cambridge, MA.
Valiant, L. G. (1984). theory learnable. Communications ACM, 27, 1134{
1142.
Vose, M. D., & Wright, A. H. (1995). Simple genetic algorithms linear fitness. Evolutionary Computation, 2, 347{368.
275

fiMoriarty, Schultz, & Grefenstette

Watkins, C. J. C. H. (1989). Learning Delayed Rewards. Ph.D. thesis, University
Cambridge, England.
Watkins, C. J. C. H., & Dayan, P. (1992). Q-learning. Machine Learning, 8 (3), 279{292.
Whitley, D. (1989). GENITOR algorithm selective pressure. Proceedings
Third International Conference Genetic Algorithms, pp. 116{121 San Mateo, CA.
Morgan Kaufman.
Whitley, D., & Kauth, J. (1988). GENITOR: different genetic algorithm. Proceedings
Rocky Mountain Conference Artificial Intelligence, pp. 118{130 Denver, CO.
Whitley, D., Dominic, S., Das, R., & Anderson, C. W. (1993). Genetic reinforcement
learning neurocontrol problems. Machine Learning, 13, 259{284.
Wilson, S. W. (1994). ZCS: zeroth level classifier system. Evolutionary Computation,
2 (1), 1{18.
Yamauchi, B. M., & Beer, R. D. (1993). Sequential behavior learning evolved
dynamical neural networks. Adaptive Behavior, 2, 219{246.
Zhou, H. (1990). CSM: computational model cumulative learning. Machine Learning,
5 (4), 383{406.

276

fiJournal Artificial Intelligence Research 11 (1999) 429{435

Submitted 6/99; published 12/99

Technical Addendum
Cox's Theorem Revisited
Joseph Y. Halpern

Cornell University, Computer Science Department
Ithaca, NY 14853
http://www.cs.cornell.edu/home/halpern

halpern@cs.cornell.edu

Abstract

assumptions needed prove Cox's Theorem discussed examined. Various
sets assumptions Cox-style theorem proved provided, although
rather strong and, arguably, natural.

recently wrote paper (Halpern, 1999) casting doubt compelling justification
probability provided Cox's celebrated theorem (Cox, 1946). received (what
seems me, least) surprising amount response article. attempt
clarify degree think Cox's theorem salvaged respond glaring
inaccuracy part pointed Snow (1998). (Fortunately, inaccuracy
affect either correctness interpretation results paper.)
tried write note enough detail read independently
earlier paper, encourage reader consult earlier paper well two
major sources based (Cox, 1946; Paris, 1994), details discussion.
basic situation. Cox's goal \try show . . . possible derive
rules probability two quite primitive notions independent notion
ensemble . . . appeal rather immediately common sense" (Cox, 1946).
end, starts function Bel associates real number pair (U; V )
subsets domain W U 6= ;. write Bel(V jU ) rather Bel(U; V ), since
think Bel(V jU ) belief, credibility, likelihood V given U . Cox's Theorem
informally understood, states Bel satisfies two reasonable restrictions,
Bel must isomorphic probability measure. first one says belief V
complement (denoted V ) given U function belief V given U ; second says
belief V \ V 0 given U function belief V 0 given V \ U belief
V given U . Formally, assume functions : IR ! IR F : IR2 ! IR

A1. Bel(V jU ) = (Bel(V jU )) U 6= ;, U; V W .
A2. Bel(V \ V 0 jU ) = F (Bel(V 0 jV \ U ); Bel(V jU )) V \ U 6= ;, U; V; V 0 W .
Bel probability measure, take (x) = 1 , x F (x; ) = xy .
going on, notice Cox's result claim Bel probability measure,
isomorphic probability measure. Formally, means
continuous one-to-one onto function g : IR ! IR g Bel probability measure
W ,
g (Bel(V jU )) g (Bel(U )) = g (Bel(V \ U )) U 6= ;,
(1)

c 1999 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiHalpern

Bel(U ) abbreviation Bel(U jW ).
willing accept belief real valued (this strong assumption since,
among things, commits us assumption beliefs cannot incomparable|
two events U V , must either Bel(U ) Bel(V ) Bel(V ) Bel(U )),
A1 A2 reasonable. took prove Cox's Theorem,
indeed would compelling argument use probability.
Unfortunately, well known A1 A2 suce prove
Cox's Theorem. Dubois Prade (1990) give example function Bel, defined
finite domain, satisfies A1 A2 F (x; ) = min(x; ) (x) = 1 , x
isomorphic probability measure. Thus, prove Cox's Theorem, need
additional assumptions.
hard dig Cox's papers (1946, 1978) exactly additional assumptions
proofs need. show paper result false quite strong
assumptions (see below). result also suggests proofs given
Cox-style theorems best incomplete (that is, require additional assumptions
beyond stated authors); see previous paper discussion. goal
note clarify takes prove Cox-style theorem, giving number
hypotheses result proved. positive versions theorem
state proved straightforward way adapting proof given Paris
(1994). (This one correct, rigorous proof result aware,
hypotheses stated clearly.) Nevertheless, believe worth identifying
variants, since philosophically quite different.
Paris (1994) proves Cox's Theorem following additional assumptions:
Par1. range Bel [0; 1].
Par2. Bel(;jU ) = 0 Bel(U jU ) = 1 U 6= ;.
Par3. A1 decreasing.
Par4. F A2 strictly increasing (in coordinate) (0; 1]2 continuous.
Par5. 0 ff; fi; 1 > 0, sets U1 U2 U3 U4 U3 6= ;,
jBel(U4jU3 ) , ffj, jBel(U3jU2 ) , fi j, jBel(U2jU1) , j less .

Theorem 1: (Paris, 1994) Par1-5 hold, Bel isomorphic probability measure.
nothing special 0 1 Par1 Par2; need assume
interval [e; E ] e < E Bel(V jU ) 2 [e; E ] V; U W ,
Bel(;jU ) = e, Bel(U jU ) = E . assumptions certainly seem reasonable, provided
accept beliefs linearly ordered. hard hard justify Par3
Par4 (indeed, Cox justifies original paper). problematic assumption
Par5 (called A4 earlier paper Co5 Paris (1994)). Par5 thought
density requirement; among things, says fixed V , set
values Bel(U jV ) takes dense [0; 1]. follows that, particular, satisfy
Par5, W must infinite; Par5 cannot satisfied finite domains. \natural"
\reasonable" are, course, eye beholder, strike natural
430

fiCox's Theorem Revisited

reasonable assumption obvious sense words. particularly true since
many domains interest AI (and application areas) finite; version Cox's
Theorem uses Par5 simply applicable domains. weaken Par5?
Cox require anything like Par5 paper. require various times
F twice differentiable, continuous second derivative, twice
differentiable.1 differentiability assumptions perhaps compelling continuity assumptions, seem like reasonable technical restrictions. Unfortunately,
counterexample give earlier paper shows assumptions suce
prove Cox's theorem. show following.

Theorem 2: (Halpern, 1999) function Bel0, finite domain W , functions

F satisfying A1 A2, respectively,

Bel0(V jU ) 2 [0; 1] U 6= ;,
(x) = 1 , x (so strictly decreasing infinitely differentiable),
F infinitely differentiable, nondecreasing argument [0; 1]2, strictly increasing argument (0; 1]2. Moreover, F commutative, F (x; 0) = F (0; x) =
0, F (x; 1) = F (1; x) = x.

However, Bel0 isomorphic probability measure.

understand makes counterexample tick role Par5, useful
review part Cox's argument. course proof, Cox shows A2 forces F
associative function, is,
F (x; F (y; z )) = F (F (x; ); z ):

(2)

Cox's argument.
Suppose U1 U2 U3 U4 . Let x = Bel(U4jU3), = Bel(U3jU2), z = Bel(U2jU1 ),
u1 = Bel(U4 jU2), u2 = Bel(U3 jU1), u3 = Bel(U4 jU1). A2, u1 = F (x; ),
u2 = F (y; z ), u3 = F (x; u2) = F (u1 ; z ). follows F (x; F (y; z )) = F (F (x; ); z ).
Note argument show F (x; F (y; z )) = F (F (x; ); z ) x; y; z .
shows equality holds x; y; z exist U1 U2 U3
U4 x = Bel(U1 jU2), = Bel(U2jU3 ), z = Bel(U3jU4). Par5 guarantees
set x; y; z dense [0; 1]3. Combined continuity F assumed
Par4, tells us (2) holds x; y; z .
claimed earlier paper none authors proved variants
Cox's Theorem, including Cox himself, Aczel, Reichenbach, seemed aware
need make (2) hold x; y; z .2 wrong including Cox list. (This
glaring inaccuracy referred above.) Snow (1998) points out, Cox actually
realize F must satisfy (2) x; y; z , explicitly makes assumption
1. Cox never collects assumptions one place, somewhat dicult tell exactly
thinks needs proof. later.
2. pointed earlier paper, Aczel recognized problem later work (Aczel & Daroczy,
1975).

431

fiHalpern

certain point first paper (Cox, 1946), although make assumption
explicitly (more informal) later paper (Cox, 1978).
Unfortunately, although Cox escapes criticism recognizing need make
assumption, make theorem less palatable. Indeed, anything,
makes matters worse. Associativity rather strong assumption, Cox shows.
fact, Cox shows F associative continuous second derivatives,
F isomorphic multiplication, is, exists function f constant C
Cf [F (x; )] = f (x)f (y ). Let stress conclusion F isomorphic
multiplication follows fact associative continuous second
derivatives, nothing A2. course, time willing assume
function F isomorphic multiplication satisfies A2,
well way showing Bel isomorphic probability measure. future
reference, remark Paris shows (in Lemma 3.7) Par1, Par2, Par4, Par5
suce show F isomorphic multiplication (and take C = 1).
case, suppose willing strengthen Par4 require F associative
well continuous strictly increasing. suce get rid Par5 altogether?
Unfortunately, seem to.
Later argument, Cox shows must satisfy following two functional
equations sets U1 U2 U3 :
[S (Bel(U2jU1 ))] = Bel(U2 jU1)

(3)


Bel(U2 jU1) (Bel(U3 jU1)=Bel(U2jU1)) = [S (Bel(U2jU1))=S (Bel(U3jU1 ))]S (Bel(U3jU1 ))
(4)
means x > 0 exist sets U1, U2 , U3
x = Bel(U3jU1) = Bel(U2 jU1),
(S (y )) =

(5)



yS (x=y ) = (x)S [S (y )=S (x)]:
(6)
Cox actually wants equations hold x . Paris shows follows
Par1{5. (Here Paris's argument. Using Par3, shown continuous (see

(Paris, 1994, Lemma 3.8)). combined Par5 easily gives us (5) holds
2 [0; 1]. (6) follows Par5 fact F must isomorphic multiplication;
mentioned above, latter fact shown Paris follow Par1, Par2, Par4,
Par5.) Without Par5, need assume (5) (6) hold x ,
Cox does.3
proof given Paris Theorem 1, use made Par5 deriving
associativity F fact satisfies (5) (6). Thus, immediately get
following variant Cox's Theorem.
3. Actually, Cox starts (4) derives symmetric functional equation yS [S (x)=y] =
xS [S (y)=x], rather (6). latter functional equation assumes holds x y.
replace x (x) everywhere use (5), get (6).

432

fiCox's Theorem Revisited

Theorem 3: Par1-4 hold and, addition, F A2 associative A1
satisfies (5) (6) x; 2 [0; 1], Bel isomorphic probability measure.
stress A1 A2 place constraints F act range
Bel (that is, elements x form Bel(U ) subset U W ), associativity,
(5), (6) place constraints global behavior F , is, F
act even arguments range Bel. example give earlier paper
viewed giving Bel possible find F satisfying A1 A2,
F satisfying A2 associative [0; 1].
get variant even closer Cox (1946) shows replacing Par4
assumption F twice differentiable. Note need make continuity,
monotonicity, differentiability assumptions F . mentioned earlier, Dubois
Prade show Bel isomorphic probability function (x) =
1 , x F (x; ) = min(x; ). min function differentiable (and fortiori continuous),
twice differentiable, strictly increasing coordinate (0; 1]2
(although nondecreasing).
advantage replacing Par5 requirement F associative
satisfy (5) (6) variant Cox's Theorem applies even W finite.
hand, hard (at least me) view (6) \natural" requirement.
assumptions like associativity F idempotency (i.e., (5)) certainly natural
mathematical assumptions, justification requiring [0; 1] seems
provably follow assumptions certain tuples range
Bel. reasonable compelling? course, reader judge.
case, assumptions needed highlighted anyone using Cox's Theorem
justification probability, rather swept carpet. requirement
must satisfy (6) even mentioned Snow (1998), let alone discussed. Snow
alone; seem mentioned discussion Cox's results either
(other Paris). course, avoid mentioning (5) (6) requiring
(x) = 1 , x (as Cox (1978) does). However, makes result less compelling.
number variants Cox's Theorem correct discussed (Halpern,
1999, Section 5). Let conclude formalizing two apply finite domains,
use Par5 (or slight variants it), rather assuming F must associative
must satisfy (5) (6) pairs x; 2 [0; 1].
first essentially assumes extend finite domain infinite domain
adding suciently many \irrelevant" propositions, tosses fair coin.
observed earlier paper, type extendability argument fairly standard.
example, made Savage (1954) course justifying one axioms
preference. Snow (1998) essentially uses well. Formally, gives us following
variant Cox's Theorem, whose proof trivial variant Theorem 1.

Theorem 4: Given function Bel domain W , suppose exists domain W + W
function Bel+ extending Bel defined subsets W + A1 A2 hold
Bel+ subsets U; V; V 0 W + Par1-5 hold Bel+ . Bel+ (and hence
Bel) isomorphic probability measure.

433

fiHalpern

problem approach requires us extend Bel events never
interested considering first place, way guaranteed
continue satisfy Par1-5.
second variant assumes Bel defined one domain W ,
domains (or least, large family domains); functions F
uniform across domains. precisely, would get following.

Theorem 5: Suppose function Bel defined domains W set W

domains, exist functions F F satisfy A1 A2
domains W 2 W , Par1{4 hold F , following variant Par5 holds:

Par50 . 0 ff; fi; 1 > 0, exists W 2 W sets U1 ; U2; U3; U4 W
U1 U2 U3 U4 , U3 6= ;, jBel(U4 jU3) , ffj, jBel(U3jU2 ) , fi j,
jBel(U2jU1 ) , j less .
Bel uniformly isomorphic probability measure, exists function
g : IR ! IR W 2 W , g Bel probability measure
W U; V W ,
g (Bel(V jU )) g (Bel(U )) = g (Bel(V

\ U )) U 6= ;.

advantage formulation W consist finite domains; never
venture infinite (although W would include infinitely many
finite domains). conception one function Bel defined uniformly family
domains seems consistent philosophy Cox Jaynes (see, particular,
(Jaynes, 1996)).
hypotheses Theorems 4 5 may seem reasonable others
(at least, readers!), note still essentially require Par5 and, like
variants Cox's Theorem aware of, disallow notion belief
finitely many gradations. One justify notion belief takes values
[0; 1] continuity considerations (again, assuming one accepts linearly-ordered
notion belief), still nontrivial requirement.4
stop point leave reader form beliefs.

Acknowledgments

I'd like thank Paul Snow useful email exchanges topic (and pointing
Cox fact realized need assume F associative (x; y; z )).
work supported part NSF, grant IRI-96-25901.
4. Snow (1998) quotes conference version (Halpern, 1999) (which appeared AAAI '96, pp. 1313{
1319) saying `Cox's Theorem \disallows notion belief takes finitely many countably
many gradations",' say disallows notion belief Cox's Theorem, viewpoint
assumed Bel varies continuously 0 1. fact, Co5 compatible notion
belief takes countably many (although finitely many) values. (Essentially sentence
appears journal version paper, refer Cox's Theorem, without phrase
\or countably".)

434

fiCox's Theorem Revisited

References

Aczel, J., & Daroczy, Z. (1975). Measures Information Characterizations.
Academic Press, New York.
Cox, R. (1946). Probability, frequency, reasonable expectation. American Journal
Physics, 14 (1), 1{13.
Cox, R. (1978). inference inquiry: essay inductive logic. Levine, R. D.,
& Tribus, M. (Eds.), Maximum Entropy Formalism, pp. 119{167. MIT Press,
Cambridge, Mass.
Dubois, D., & Prade, H. (1990). logical view conditioning application
possibility evidence theories. International Journal Approximate Reasoning,
4 (1), 23{46.
Halpern, J. Y. (1999). counterexample theorems Cox Fine. Journal A.I.
Research, 10, 76{85.
Jaynes, E. T. (1996). Probability Theory|The Logic Science. Unpublished; available
http://bayes.wustl.edu.
Paris, J. B. (1994). Uncertain Reasoner's Companion. Cambridge University Press,
Cambridge, U.K.
Savage, L. J. (1954). Foundations Statistics. John Wiley & Sons, New York.
Snow, P. (1998). correctness reasonableness Cox's Theorem finite domains.
Computational Intelligence, 14 (3), 452{459.

435

fiJournal Artificial Intelligence Research 11 (1999) 301-333

Submitted 3/99; published 10/99

Decentralized Markets versus Central Control:
Comparative Study
Fredrik Ygge

ygge@enersearch.se

EnerSearch AB Uppsala University
Chalmers Science Park
S-412 88 Gothenburg, Sweden
www.enersearch.se/ygge

Hans Akkermans

HansAkkermans@cs.vu.nl

AKMC Free University Amsterdam
Department Information Management Software Engineering
Computer Science Division
De Boelelaan 1081a, NL-1081 HV Amsterdam, Netherlands

Abstract
Multi-Agent Systems (MAS) promise offer solutions problems established,
older paradigms fall short. order validate claims repeatedly made
software agent publications, empirical in-depth studies advantages weaknesses
multi-agent solutions versus conventional ones practical applications needed. Climate
control large buildings one application area multi-agent systems, marketoriented programming particular, reported successful, although
central control solutions still standard practice. therefore constructed
implemented variety market designs problem, well different standard
control engineering solutions. article gives detailed analysis comparison,
learn differences standard versus agent approaches, yielding new
insights benefits limitations computational markets. important outcome
local information plus market communication produces global control.

1. Introduction
new paradigms arise scientific horizon, must prove value comparison competition existing, established ones. multi-agent systems
(MAS) paradigm exception. recent book software agents (Bradshaw, 1997),
Norman observes perhaps relevant predecessors todays intelligent agents
servomechanisms control devices. indeed, number applications
multi-agent systems recently claimed success, close realm
traditionally called control engineering. One clear example climate control large
buildings many office rooms. Here, Huberman & Clearwater (1994, 1995) constructed tested working MAS solution based market approach, reported
outperform existing conventional control.
key question studied article is: respect extent
multi-agent solutions better (conventional) alternatives? believe
c
1999
AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiYgge & Akkermans

above-mentioned application provides nice opportunity study question detailed empirical way. practically relevant, lends alternative solutions,
quite prototypical wide range industrial applications distributed resource allocation (including energy management applications (Ygge & Akkermans, 1996;
Akkermans & Ygge, 1997; Ygge & Akkermans, 1998), telecoms applications, file allocation problem Kurose Simha (1989), flow problems investigated Wellman
(1993)).
article gives detailed analysis published MAS solution building climate
control, compares multi-agent markets traditional control approaches. also
introduce improved novel multi-agent solution problem based equilibrium market. comparative analysis able draw general conclusions
suitability various approaches. Briefly, show computational markets
designed perform well centralized controllers global information
total system. However, major advantage market framework achieves
fully decentralized fashion using locally available data. finally outline
possible come general theory concerning connections
markets conventional control concepts. Here, show considered type
applications quasi-equation local data + market communication = global control
holds.
structure article follows. introduction (Section 2) marketoriented programming available theory, Section 3 gives problem definition. Section 4
introduces application domain: describes office environment gives physical model cooling power various temperature outside weather influences.
discuss results standard control engineering solution, based local
independent integral controllers regulating building climate (Section 5). Next, review market-based approach put forward Huberman & Clearwater (1994, 1995)
(Section 6), validate claim market approach performs better conventional independent controllers. subsequently analyze market protocol detail
show success related fact agents possess global information
auction started (Section 7). Section 8 develop improved standard control engineering scheme also exploits global data. control scheme turns
perform much better Huberman-Clearwater market. Finally, propose
market design based general equilibrium theory. performs well
controller access global data, operates local data thus represents
really decentralized solution (Section 9). Section 10 puts results perspective
summarizes general conclusions comparing different approaches.

2. Market-oriented Programming
use market mechanisms resource allocation computer systems rather
long history computer science, e.g. (Sutherland, 1968), recently markets
used number different application areas.

302

fiDecentralized Market Control

rather extensive theory available relations optimization
markets. example:
Jennergren (1973) shown price schedule decomposition algorithm
used solving linear programming problems.
Kurose & Simha (1989) showed equilibrium constitutes optimal solution
file allocation problem. similar result shown Bertsekas (1992)
assignment problem.
Bikhchandani & Mamer (1997) showed Pareto efficient outcome1 maximizes
sum utilities exchange market agents holding quasi-linear utility
functions2 significant extension above, also applies non-linear
problems.3
results Bikhchandani Mamer extended markets include production uncertainty Ygge (1998, Chapter 3). relations
types markets traditional optimization problems also made explicit
latter work.
Markets approaches applied number different computerized applications, briefly discussed here. Already 1968 Sutherland proposed
auction mechanism allocation computational resources PDP-1 computer (Sutherland, 1968). Different amounts money assigned different users accordance
importance projects. reported users time learn
bid properly computational resources. basic approach refined
by, example, Gagliano et al. (Gagliano et al., 1995).
Kurose & Simha (1989) investigate file allocation problem. work agents
report marginal utility (for certain amount storage) derivative
auctioneer, reallocates resource using resource-oriented Newton-Raphson
algorithm (cf. Ygge & Akkermans, 1998) equilibrium reached
marginal utilities agents same. Although paper based number
microeconomic abstractions, example utilize prices trade-off
different commodities. So, debatable whether approach referred
really market-based.4
assigning problem allocating n objects n users investigated Bertsekas (1992). user valuation object, cannot assigned
one object. reported user seen economic agent, shown
auction (which essentially English auction) results equilibrium.
1. allocation Pareto efficient Pareto optimal alternative allocation makes
agent better without making outcome worse agent (Varian, 1996, p. 15).
2. example quasi-linear utility function given Eq. (19).
3. However, one remember theory provide computational advantages.
hard find allocation maximizes sum utilities, also hard find Pareto
optimal one (as case).
4. One also note formulation Newton-Raphson scheme approach overly
simplistic, much better standard methods available (Press et al., 1994; Ygge & Akkermans,
1998).

303

fiYgge & Akkermans

Trading Agent

Auctioneer
Initiate Auction H
H
Supply = Demand?

HH
j Express demand

1






XX
XXX
Yes
z Register implement
X

Figure 1: High-level view equilibrium market mechanism.
assumed agent behavior agent bids v w highly valued object (i.e.
object highest difference, v, valuation price). w
difference valuation price second preferred object.
however motivation given assumed agent behavior, clear
agent would use strategy unless externally imposed. Though
economical interpretation prices, approach market-like due
rather unrealistic assumptions agent behavior.
equilibria applications Kurose Simha, Bertsekas proven
optimal. hard see problem Kurose Simha reformulated
proper market quasi-linear utility functions, competitive equilibrium equivalent equilibrium described Kurose Simha, cf. (Ygge, 1998,
Corollary 3.3.1). Similarly, price vector obtained Bertsekas clearly constitutes
competitive equilibrium. time, shown Ygge (Ygge, 1998, Theorem 3.2),
separable optimization problems formulated market terms (competitive) general equilibrium (if existing) identical optimal solution original
optimization problem. Consequently, recent theory generalizes earlier theory
example Kurose Simha, Bertsekas.
Wellman et al. contributed significantly developing market-based approaches
resource allocation programming paradigm, given name marketoriented programming, e.g. (Wellman, 1993; Mullen & Wellman, 1995; Wellman, 1995, 1996;
Yamaki, Wellman, & Ishida, 1996; Hu & Wellman, 1996; Cheng & Wellman, 1998; Wellman
& Hu, 1998; Walsh, Wellman, Wurman, & MacKie-Mason, 1998). Particularly, microeconomic framework general equilibrium theory successfully used resource
allocation mechanism. market call equilibrium market agents send
demand functions telling much like consume produce different prices.
auctioneer tries establish equilibrium price vector supply meets
demand commodities, cf. Figure 1.
process submitting parts demand function may iterated equilibrium
price outside region captured submitted demand functions. One process
basic price tatonnement process, cf. e.g. (Cheng & Wellman, 1998), demand
functions respective commodities sent auctioneer. demands
based expected prices commodities. is, prices change, set
new demand functions may need submitted. auctioneer established
equilibrium price, agents exchange resources stated bid
304

fiDecentralized Market Control

equilibrium price. (For example, agent states wants buy 1/p units
commoditywhere p price commodity moneyand equilibrium price
becomes 1, agent buy one unit resource one unit money.)
Equilibrium markets many attractive theoretical properties. example,
agents act competitively5 , outcome Pareto efficient. Furthermore, utility functions quasi-linear, outcome globally optimal (Ygge, 1998, Theorem 3.2),
presence uncertainty, outcome maximizes expected global utility (Ygge,
1998, Theorem 3.5). note equilibrium markets computationally implemented
computationally efficient manner (Ygge, 1998, Chapter 4).
Wellman et al. applied equilibrium markets number applications,
multi-commodity flow problems, design problems, bandwidth allocation problems.
also introduced market-based approach scheduling many similarities assignment problem Bertsekas described above, relies realistic
assumptions agent behavior.
present authors introduced market-oriented approach power load management (Ygge & Akkermans, 1996; Ygge, 1998; Ygge et al., 1999).
note aim market-oriented programming computer science fundamentally different aim economic theory. visualized Figure 2.
market-oriented programming, microeconomic theory taken given serves
theory implementation computational agents. Whether microeconomic
theory actually reflects human behavior critical issue. important question
instead microeconomic theory utilized implementation successful
resource allocation mechanisms computer systems. example, even though (or
least few) people believe humans use explicit utility functions making
decisions, functions appear useful concisely represent human preferences
use computational agents.
obviously interesting investigate use computational markets automating trades different self-interested parties, information private
revealed expected gain so. However, use markets
also proposed standard resource allocation true utility/costs nodes
consume produce resource assumed available (though possibly uncertain
and/or distributed system). main arguments found literature applying
market types problems are:
numerous similarities economic systems distributed computer systems suggest models methods previously developed within field mathematical economics serve blueprints engineering similar mechanisms
distributed computer systems (Kurose & Simha, 1989).
Auction algorithms highly intuitive easy understand; explained
terms economic competition concepts, couched everyday experience (Bertsekas, 1992).
5. agent acts competitively treats prices exogenous, is, impact prices due
behavior negligible (Varian, 1996, p. 516). reasonable assumption market
least moderate size and/or uncertainty behavior agents (Sandholm
& Ygge, 1997).

305

fiYgge & Akkermans

Micro-economic theory
Study
Generate
Computer
scientist

Economist
Study
Generate
Real World

Human agents
human markets

Computational agents
computational markets

Figure 2: simplified view relation economics computer science respect
microeconomic theory. Economists study humans generate theory used
explanation human economic behavior. Computer scientists marketoriented programming use theory basis building working computational market
systems.

Market approaches enable natural decomposition, software engineering
perspective well computational perspective (Schreiber et al., 1999; Ygge,
1998, Chapter 15).
Market approaches flexible allow ongoing addition deletion agents. global changes requiredmerely demand/supply relation
altered (Ygge, 1998, Chapter 15).
Markets informationally efficient terms information dimensionality (Jordan,
1982), abstractions used natural ones user (Ygge, 1998,
Chapter 15).
introduction trading resources sort money enables evaluation
local performance valuation resources, becomes apparent resources valuable agents using (Ygge,
1998, Chapter 15).
arguments mainly conceptual related software/system design
engineering issues, must prove value acceptance software system
designers. also different respects stronger claims. example, Huberman Clearwater state (Huberman & Clearwater, 1995) application
building control that: principle omniscient central controller access
environmental thermal parameters building (i.e. perfect model) could
306

fiDecentralized Market Control

optimally control it, practice knowledge seldom available system. Instead,
partial information local changes variables (such instantaneous office occupancy, external temperature, computer use) reliable source used
controlling building. alternative omniscient controller Huberman
Clearwater propose market-based multi-agent approach problem. raises
interesting question: applications information structure
market-based approaches better traditional approaches? paper
carefully examine issue building climate control problem. investigate information different alternatives (traditional new market-based) require,
performance different approaches are. use exactly
problem formulation Huberman Clearwater order reproduce results
evaluate new approaches original formulation. problem formulation
given next section.

3. Problem Definition
task allocate resource (cold air) office building, given setpoint temperatures respective offices. measure success allocation, standard
deviation deviation setpoint used (Huberman & Clearwater, 1995), i.e.
v
u
N
u1 X
setp
StdDev(Ti
)=t
[(Tio Tosetp ) (hTi hT setp i)]2 ,

N

(1)

o=1

hi denotes average value variable, Tio actual temperature office,
Tosetp setpoint temperature. index denotes time interval observation
index denotes office observation. naming convention used
throughout article. (In addition index k also used denote time periods.)
may debated whether best measure, stick
article order evaluate approach taken Huberman Clearwater using
measure.

4. Office Environment
case study consider comparison decentralized markets versus central
control solutions building climate control large office environment.
section, present mathematical-physical model office environment.
first give conceptual summary possible understand basic ideas
model without studying equations. offices attached pipe
resource (cold air) transported Figure 3. characteristics system similar
characteristics district heating system, offices instead households.
assume 100 offices total, equally distributed towards
East, South, West, North.
thermodynamics office environment actually quite simple. Every office
seen storage place heat, heat may dissipate environment. model,
thermodynamic behavior office equivalent basic electrical RC-circuit. Here,
307

fiYgge & Akkermans

Noon sun

Morning sun

Afternoon sun

Air
Air
Figure 3: Offices air transportation.
voltage analogous temperature, electrical current analogous heat flow. C
R respectively denote heat capacitance thermal resistance.
good general reference thermodynamic models one use book
Incropera & Witt (1990). heat equations continuous time, discretized
according standard procedures control engineering, cf. (Ogata, 1990). ontology reusability aspects involved thermodynamics model construction discussed
extensively Borst, Akkermans, & Top (1997).
4.1 Thermodynamic Properties
resource treated cooling power. office make use fraction, ,
available resource office, Pioavail ,
Piocons Pioavail ,

(2)

Piocons consumed power. available resource one office equal
available resource previous office minus consumed resource previous office.
Throughout article assume 0.5.
treat everything discrete time. time interval use calculations
one minute. offices temperature, Tio , obtained integrating differential
equation discretized form:
Tio = T0,o +


X

heat
cons
(Pko
Pko
)/Co ,

(3)

k=1
heat
Pko


heating power Co thermal capacitance. heating power
described
Pioheat = (Tiovirt Tio )/Ro ,
(4)
308

fiDecentralized Market Control

Ro thermal resistance Tiovirt virtual outdoor temperature, described
detail below.
Eqs. (3) (4) see feedback loop office temperature
heating power. Solving temperature obtain


Tio =

1
1+

1
Ro Co

Ti1,o +

virt
Tio
Ro

Piocons
Co


, > 0.

(5)

equation dynamics system directly computed.
right-hand side known quantities, Co Ro externally given building
parameters, Piocons output utilized controller (as described detail later
article various different controllers), Tiovirt obtained weather model
below.
4.2 Weather Model
external weather influences office environment modeled virtual temperature, representing outdoor temperature, sun radiation, etc. assume
sunshine every day outdoor temperature, outd , varies 22 35 C
according
2
Tioutd = 22 + 13 e((is4) mod 2412) /20 ,
(6)
length time interval expressed hours, = 1/60.
virtual temperature, Tiovirt , described
Tiovirt = Tioutd + Tosun + Tiof luct,

(7)

f luct random disturbance, thought represent small fluctuations caused
example wind. f luct Gaussian distributed zero mean standard deviation
equal unity. sun sun radiation component. offices located East
side sun described
2 /5

Tisun,East = 8 e((is+4) mod 2412)

,

(8)

correspondingly South West offices
2 /5

Tisun,South = 15 e(is mod 2412)


,

2 /5

Tisun,W est = 8 e((is4) mod 2412)

(9)

.

(10)

various temperatures plotted Figure 4.
4.3 Office Temperatures without Control
Figure 5, temperature South-oriented office plotted different thermal
resistances, Ro , thermal capacitances, Co . simplicity assume Ro equal
Co equal. figure observe two things: first, higher Ro Co
309

fiYgge & Akkermans

35

Time day, h

Time day, h

24

21

18

15

9

12

6

0

24

21

18

15

-5

24

21

18

15

9

12

6

3

0

9

0

0

50
40
30
20
10
0

3

5

12

5

6

10

3

15

10

0

20

Temperature C

15

25

Temperature C

Temeprature C

30

Time day, h

Figure 4: plot left shows outdoor temperature, Tioutd. middle plot shows sun
radiation components, sun , (with peaks time 8, 12, 16 hours offices located
East, South, West sides, respectively). Finally, outdoor temperature plus
sun radiation components plotted right.

45

Temeperature C

40

R=0 C=0

35

R= 10, C= 10,
30
R=10 C= 20 R=20
C=10
25

R=20 C=20

20

22

20

18

16

14

12

10

8

6

4

2

0

15
Time day, h

Figure 5: indoor temperature uncontrolled office plotted different values
thermal resistance heat capacitance. Small values thermal resistance
capacitance give higher peaks, higher values give smoother curves.

bigger lag temperature changes, second, higher Ro Co smaller
fluctuations temperature. simulation experiments article took Ro = 10
Co = 10. Ro Co equal zero implies Tio = Tiovirt , seen
letting Ro Co approach zero Eq. (5). Clearly, without control office temperatures
strongly fluctuate reach unacceptably high values cases.
310

fiDecentralized Market Control

5. Control-A: Conventional Independent Controllers
5.1 Integral Control Offices
application regulating office temperature long tradition control theory.
widely known controllers different variants PID controller. letters PID
denote control signal proportional (P) error (that is, difference
setpoint actual value); proportional integral (I) error;
proportional derivative (D) error. Here, use variant integrating
controller6 form
Fio = Fi1,o + (Tio Tosetp ),
(11)
F output signal controller, so-called gain parameter (that
set externally design controller). simulations assumed
Fio limited value zero three. order model
valves closed cooling resources delivered one room another
(the lower bound), maximum amount resources
obtained opening valve fully (the upper bound). control signal Fio sent
actuator actual Piocons obtained
(

Piocons

=

Fio ,
Fio Pioavail
.
avail
Pio , Fio > Pioavail

(12)

Plots office temperatures different gains shown Figure 6. gain
controller critical application. high gain result controller
overreacting temperature exceeds setpoint,
setpoint quite time. leads larger error smaller adjustments
made. Also, amplitude control signal gets unnecessarily high, system
get dangerously unstable. note maximum deviation 0.06 C.
Thus, controllers using three gains perform well. calculations
article gain equal 10 adopted.
5.2 Implications Limited Resources
far, assumed total amount available resources unlimited. Now,
suppose maximum value cooling power inserted
system. situation, offices situated close air input obtain
sufficient amount cool air, near end suffer totally uncoordinated
controllers used. Thus, smaller total amount available resources, larger
standard deviation be. visualized Figure 7. reasonable figure
chosen upper limit total resource amount 140.
conclude, shown example, independent integrating controllers perform
well amount cooling resources unlimited. hand,
6. main reason choosing integrating controller want setting close
possible setting described Huberman Clearwater (1995). controllers
application may well considered, long performance good shown Figure 6,
crucial central argument article.

311

fiYgge & Akkermans

20,06

Temperature, C

20,04

20,02
Gain = 100
Gain = 10

20

Gain = 1
19,98

19,96

19,94
1

11

21

Minutes observed interval

Figure 6: indoor temperature office, utilizing integral controller, plotted different
controller gains. setpoint temperature 20 C.

6

Standard deviation

5
4
3
2
1

24

23

22

21

20

19

18

17

16

15

14

13

12

11

9

10

8

7

6

5

4

3

2

1

0

0
Time day, h

Figure 7: standard deviation (in C) , defined Eq. (1) interval, i, plotted
different amounts available cold air resources (130, 140, 150, 160) 100
offices. lower amount available resources, higher standard deviation.

312

fiDecentralized Market Control

shortage available resources, standard deviation increases dramatically, yielding
poor performance.

6. Market-A: Approach Huberman Clearwater
multi-agent systems solution problem building control presented
Huberman Clearwater (1994, 1995). approach taken model resource
allocation problem building environment computational market agents
buy sell cooling power resources. non-separability terms agents ignored.7
basic idea every office represented agent responsible
making good use resources, end trades resources agents.
agents send bids auctioneer, calculates clearing price, makes sure
agent buy price higher bid sell price lower
bid.
section give market protocol proposed Huberman Clearwater,
reproduce results. order make paper self-contained, interested reader
find original equations underlying Huberman-Clearwater market protocol
Appendix A.
6.1 Market protocol
bid constructed following tuple:
bid = [sellio , vio , Bio ],

(13)

sell boolean variable indicating whether current bid sell bid (true)
buy bid (f alse), v volume traded for, B price agent demands (sell
bid) prepared pay (buy bid).
variables Eq. (13) function variables according
sellio = sellio (Tio , Tosetp , hTi i, hTosetp i),
vio = vio (Ti , Tsetp , ),
Bio = Bio (Tio , Tosetp , hTi i, hTosetp i, mio ),

(14)

setp
Ti = [Ti1 , Ti2 , . . . , Ti100 ], Tsetp = [T1setp , T2setp , . . . , T100
], strength parameter
auction, mio called money parameter. trade volume directly proportional
and, hence, doubling doubles traded volume auction. Thus, free
parameter externally set tune trade volumes proper levels.
money parameter correspond real currency; merely control variable,
varying 100 200, direct connection to, example,
value cooling resource. money cannot saved auction rounds

7. resource allocation problem separable total utility system system expressed
sum utilities node (producer/consumer), constraints much
resource assigned node restricted sum must exceed total
available resource (Ibaraki & Katoh, 1988). Hence, problem treated paper separable
constraints resource distributed. example, assign sufficiently
much penultimate agent, ultimate significant amount resource available.

313

fiYgge & Akkermans

Huberman-Clearwater protocol, another indication simply functions
adjustment parameter protocol.
auction consists following three phases:
1. agents send bids, [sellio (Tio , Tosetp , hTi i, hTosetp i,
Bio (Tio , Tosetp , hTi i, hTosetp i, mio )], auctioneer.

vio (Ti , Tsetp , ),

2. auctioneer computes market clearing price searching following
minimum:
fi
fi
fi
fi
X
X
fi
fi
fi
min fi
vio
vio fifi .
pi fi
fi
o|sell=true,Bio pi
o|sell=f alse,Bio pi

(15)

yields price supply matches demand closely possible.
3. Finally, resources allocated dictated bids obtained
market price, according rule: sellers offering vio price, Bio ,
lower equal market price sell vio ; correspondingly
buyers.8
example computation equilibrium price, assume auctioneer
received following bids [true, 2, 4], [true, 1, 3], [true, 2, 2], [f alse, 1, 3], [f alse, 2, 2],
[f alse, 2, 1]. market clearing price 3, leading acceptance bid 2, 3, 4, 5.
(Bid 1 high sell price bid 6 low buy price.)
6.2 Simulations
Figure 8 shows two plots simulation period 3 p.m. 7 p.m.9
initial temperatures offices set 20 C. upper plot standard deviation independent integrating controllers used, lower one shows
agent-based control scheme defined above. found adjustment parameter
(see Eq. (23)) value 64 led smallest overall standard deviation. key observation figure agent approach offers least one order magnitude
improvement.
Compared independent conventional controllers indeed major advance,
central claim made Huberman Clearwater. market approach given
leads reduced control error thus increased comfort compared standard controllers. simulations thus reproduce validate results Huberman &
Clearwater (1994, 1995).
8. Since bids given using discrete volumes, supply seldomly match demand exactly
clearing price. Normally, small excess demand supply. excess supply,
buyers willing pay clearing price buy, sellers willing
accept least clearing price sell. situation, seller selected randomly
valid candidates deliver fraction bid. corresponding procedure used
small excess demand.
9. solutions discussed article implemented simulated authors using
C++ PC running Windows95. Furthermore, simulations independently recreated
verified Bengt Johannesson various relevant papers (Ygge & Akkermans, 1997; Huberman &
Clearwater, 1995; Clearwater & Huberman, 1994)), part masters thesis project, using Python
PC running Linux.

314

fiDecentralized Market Control

4,5
4

Standard deviation

3,5
3
2,5
2
Control-A

1,5

Market-A

1
0,5

19

18

17

16

15

0
Time day, h

Figure 8: Standard deviation independent controllers (top) agent-based control (bottom).
However, cannot last word successful system study. first question
raised whether find detail actual reason success
market-based approach. second relevant question whether
alternative, market-based and/or central control-based, solutions building control
problem even better. answer questions yes, set
demonstrate now.

7. Market-A0: Suite Variations
section present suite variations scheme presented Section 6.
main aim understand many factors involved actually responsible
good performance Huberman-Clearwater market approach.
7.1 Deleting Money Dependency
first simplification remove adjustment parameter called money. done
setting mio high value, C, regardless resource allocation.10 simplified
market protocol is:
1. agents send bids, [sellio (Tio , Tosetp , hTi i, hTosetp i,
Bio (Tio , Tosetp , hTi i, hTosetp i, mio = C)], auctioneer.

vio (Ti , Tsetp , ),

2. auctioneer computes market price
fi
fi
fi
fi
X
X
fi
fi
min fifi
vio
vio fifi .
pi fi
fi
o|sell=true,Bio pi
o|sell=f alse,Bio pi

3. Allocate resource dictated bids market clearing price.
315

(16)

fiYgge & Akkermans

0,25

Standard deviation

0,2

0,15

Market-A
Market-A',
Money

0,1

0,05

19

18

17

16

15

0
Time day, h

Figure 9: Standard deviation original Huberman-Clearwater scheme scheme without
money dependencies.

Plots standard deviation original scheme well scheme
money dependencies removed shown Figure 9. scheme without
money, setting parameter 66 turned optimal. scheme without
money dependencies performs well original scheme. reason
Bio dependency mio completely negligible.11 Hence, money parameter
play significant role success Huberman-Clearwater market scheme.
7.2 Deleting Temperature Dependency
Another factor interest impact temperature bid prices. remove
dependency setting bid price 10 selling agents 100 buying
agents. is, use following market scheme:
1. agents send bids,
[sellio (Tio , Tosetp , hTi i, hTosetp i),

(

vio (Ti

, Tsetp , ),

Bio =

10, sell = true
],
100, sell = f alse

auctioneer.
2. Now, prices larger 10 smaller 100 equally good candidates.
mismatch supply demand, say, supply exceeds demand,
agents sell picked randomly among valid candidates, resources
allocated accordingly.
10. precisely, done setting U (0, m) Eq. (28) (Appendix A) constant value, 2000.
corresponds letting mio approach infinity.
11. actual fact, U (0, m) Eq. (28) Appendix vary 1999.86 2000 possible
mio .

316

fiDecentralized Market Control

0,25

Standard deviation

0,2

0,15
Market-A',
Money
0,1
Market A',
Money,
Temp

0,05

0
15

16

17
Time day, h

18

19

Figure 10: Standard deviation scheme money dependencies removed, compared
scheme money temperature dependencies removed.

Figure 10 standard deviation plotted scheme without money, mentioned
above, scheme dependency temperature removed
well. Here, setting fit parameter 65 turned optimal. see also
performance good original scheme. Note temperature
still used determine vio boolean variable sell. conclusion
temperature dependency affect quality market-based solution
building control problem.
7.3 Deleting Auction
Next, let agents assign bids without auction whatsoever.
means sum total controller outputs, Fio , might sometimes exceed total
resource amount sometimes that. physical model course still obeyed,
total resource amount actually used, total consumed cooling power Piocons ,
never exceed totally available resource amount, described Eq. (2). Hence,
resource updates described by:
(

+vio (Ti , Tsetp , ), sell = f alse
vio (Ti , Tsetp , ), sell = true
0,
Fio0 < 0
Fio0 , 0 Fio0 3
3,
Fio0 > 3

Fio0 = Fi1,o




Fio =




(17)

result simulation shown Figure 11. Here, 17 turned
optimal. surprising conclusion multi-agent scheme without performing
auction roughly ten times better auction-based Market-A scheme.12
12. practical point view pathological solution, revealing loophole problem
definition Clearwater Huberman, cf. Section 3. revealed loophole problem definition

317

fiYgge & Akkermans

0,25

0,2

Standard deviation

Market-A

0,15
Market-A',
Money,
Temp,
Auction

0,1

0,05

0
15

16

17

18

19

Time day, h

Figure 11: Standard deviation auction mechanisms completely removed, compared
original Huberman-Clearwater Market-A scheme.

7.4 Discussion
first glance, might seem counterintuitive performance actually improves significantly core mechanisms market removed. First showed introducing
market improves performance considerably compared conventional independent control, showed market mechanisms superfluous. What, then, big
difference uncoordinated integrating controller, Control-A scheme,
multi-agent scheme without auction ended with? simple answer,
view, access global data agent has, terms average temperature average setpoint temperature (as follows Eq. (14)), Market-A
Market-A0 schemes. Knowing average quantities means agent information agents c.q. offices. information available case
independent conventional controllers. exploitation non-local information makes
big difference.
take absolute temperature account, differences temperature
(i.e. minimizing standard deviation potentially sacrificing average temperature). proper
approaches introduced remainder article allow take advantage
loophole, minimize differences using available resource. is, approaches
introduced solve problem strictly harder problem defined
Section3. happens Market-A scheme without auction seen observing
definition tio Eq. (22). based quotient setpoint temperature actual
temperature. request volume, Eq. (24), proportional quotient. always results
significant excess supply. (Hint, think small example two offices, setpoint 20,
temperatures 19 21. Now, 20
farther away 1 20
, hence selling volume
19
21
exceed buying volume.) implies trade occasion, many offices prevented
selling (because poor definitions volumes). offices prevented sell deviate
significantly, hence results high value measure. auction deleted,
agents average distance setpoints able get rid resource
hence differences temperature decrease.

318

fiDecentralized Market Control

Thus, upshot factor analysis success Huberman-Clearwater
market scheme Section 6 agents share crucial office control
information first, auction takes place. one remove auction
without deterioration results: major function auction share necessary
information bidding procedure, Huberman-Clearwater protocol
needed information already shared. appropriate description market
scheme would therefore say consists three (as described Section 6),
four phases, first phase agents send current temperatures
Tio well setpoint temperatures Tosetp agents.
sum, answered first question raised end previous section:
reason success Huberman-Clearwater market scheme, compared
conventional independent controllers? single important factor contained
first step above: market procedure carried out, agents communicate key
information current situation agents. done neither money
auction mechanisms needed. conventional independent controllers,
Huberman Clearwater compare approach, globally shared information
available, however. explains two solutions perform differently.
Now, turn second question raised previous section: alternative
perhaps better solutions? analysis suggests look two different
directions. one wants persuade control engineers value agent-based approaches,
convincing compare Huberman-Clearwater scheme strictly local
controllers, controllers access global information agents
have. Secondly, dependency global information agents highly undesirable
feature clearly runs counter decentralized computational market philosophy. So,
one investigate whether possible design market protocol exploits
strictly local information agents bid construction. issues investigate
following two sections, first treating central control subsequently devising strictly
local market protocol. seen yield significantly improved performance.

8. Control-B: Standard Controller Using Global Data
concluded access global data crucial performance, course
interest analyze performance would integrating controller, like
one introduced Eq. (11), incorporating global data.
would like controller take account deviation setpoint, consider also deviations offices setpoints. Therefore,
controller Eq. (11) extended
Fio = Fi1,o + [(Tio Tosetp ) (hTi hT setp i)],

(18)

set 10 previously. Piocons is, before, obtained Eq. (12).
plot simulation controller, compared Market-A simulation, Market-A0 simulation auction removed, shown
Figure 12.
see standard deviation approximately Control-B
Market-A0 schemes. Thus, Control-B scheme also performs roughly ten times
319

fiYgge & Akkermans

0,25

Standard deviation

0,2
Market-A
0,15
Market-A',
Money,
Temp,
Auction
Control-B

0,1

0,05

19

18

17

16

15

0
Time day, h

Figure 12: Standard deviation integrating controller utilizes global data compared

Huberman-Clearwater Market-A scheme, Market-A0 scheme
auction removed.

better Market-A. important difference, though, Control-B employs
well-known integrating controller well-understood methods theories
e.g. stability analysis.13 contrast, Market-A scheme easily analyzable
formal theory perspective, since rely well established concepts.
Control-B relatively clear, see Eq. (18), much harder conceptually grasp
principles behind Market-A, consists large number complicated
easily justified equations (see Eqs. (21)(33) Appendix A). main conclusion
present section that, enable conventional controllers act upon global
information Huberman-Clearwater agents do, central control approach performs
best easiest understand.

9. Market-B: Market Local Data
Thus, computational market Market-A outperformed global control scheme
Control-B. Therefore, interesting follow-up question whether simple well
performing computational market approach devised depend available global information, contrast schemes. section
show indeed case, decentralized market performs comparably
fully centralized conventional control. approach derived section relies
general theory relations optimization problems markets(Ygge,
1998, Chapter 3) (Bikhchandani & Mamer, 1997) applicable many
applications.
13. holds assumption characteristic time scale variations average
temperature much larger fluctuation temperature. reasonable
assumption present case.

320

fiDecentralized Market Control

use market-oriented programming approach based equilibrium market.
basic protocol (cf. Figure 1):
1. agent submits net demand function zio (p) auctioneer, describing
change allocation desired agent price p.
2. auctioneer computes equilibrium, calculating price pi
P
P
zio (pi ) = 0 (or, strictly speaking, |
zio (pi )| , small (positive)
numerical tolerance).
3. agent receives demanded resource zio (pi ) calculated obtained market
equilibrium price.
computation zio (p) process computing equilibrium described
below. Note truly distributed approach, rely
global data, communication temperatures agents market communication starts.
9.1 Relation Markets Conventional Controllers utilizing
Global Data
performance measure system given Eq. (1). best system therefore
one minimizes equation. Hence, straightforward move one think
come market model, take measure representing utility function
overall system. So, utility functions individual agents ideally related
[(Tio Tosetp ) (hTi hT setp i)]2 . 14 However, still formulation containing global
information.
Thus, want obtain purely local reformulation, getting rid terms
hT containing global information. might replace them, though, terms relating
changes local resource. so, take inspiration standard
controller equations Eqs. (11) (18), indicating get good results (for unconstrained resources) update equation Fio = Fi1,o + io , io form
io = (Tio Tosetp ). intended interpretation io represent output
local controller would delivered acted independently unconstrained resources.
market setting agent updates control signal Fio Fio = Fi1,o + Fio ,
Fio determined outcome market. Since resource reP
distributed among agents, N
o=1 Fio = 0. Accordingly, step
design Market-B scheme, based local data only, employ following definition.
Definition 9.1 Let utility function individual office agents defined
u(Fio , m) = 2o (Fio io )2 + m,

(19)

strength parameter office representing physical properties
Ro Co . (The proper choice discussed Theorem 9.3 later on.)
Furthermore, let agents price-takers.
14. Since utilities expressions preference orderings, invariant monotonic transformations.

321

fiYgge & Akkermans

Due simple quadratic form utility function Eq. (19), net demand,
zio (p), easily computed price-taking agents analytical means. Note money
fundamentally different money Market-A, c.f. Section 6.
money represents commodity agent needs decide much money trade
commodity cold air. described above, money Section 6 control
variable without intuitive interpretation.
Theorem 9.1 utility functions behavior given Definition 9.1, exists
P
unique equilibrium price pi | zio (pi ) = 0, allocation obtained equilibrium
market Pareto optimal.
Proof. See (Mas-Colell, Whinston, & Green, 1995; Varian, 1992; Takayama, 1985). 2
setting, wide variety different algorithms guaranteed
P
converge clearing price pi | zio (pi ) = 0, second step equilibrium
market protocol given above. Examples algorithms price tatonnement, Walras (Cheng & Wellman, 1998), various Newton-Raphson type methods. detailed
discussion communication computation efficiency aspects algorithms given
Ygge (1998, Chapter 4).
Theorem 9.2 Pareto optimal outcome market agents hold utility
function Eq. (19) equivalent integrating controller exploits global information described following resource update equation :
Fio = io

2o

1
hi i,
h1/2

(20)

given agent boundary. Here, h1/2 hi average 1/2o , i0
respectively.
Proof.
Pareto-optimal allocation agent bounds,
u(Fio )/Fio equal. (Assume u(Fip )/Fip < u(Fiq )/Fiq ,
price u(Fip )/Fip < p < u(Fiq )/Fiq , exists (sufficiently small) amount
Fi , say , (Fip , mip + p) > (Fip , mip ) uq (Fiq + , miq
p) > uq (Fiq , miq ). Correspondingly u(Fip )/Fip > u(Fiq )/Fiq . Hence,
u(Fip )/Fip = u(Fiq )/Fiq ).

2N
2o (FiN ). Summing
PN 1
PN 1
P 1 1
2
equations yields o=1 Fio o=1 io = N (FiN ) N
o=1 2o . Adding FiN
P
sides dividing sides N together
resource constraint ( N
o=1 Fio =
P

Thus, hold every office Fio io =



PN

io

N
1
o=1 2

o=1
0) yields
= 2N (FiN ) N equivalent FiN =
N
1
h i. reasons symmetry, equation holds offices. 2
2 h1/2
N

Corollary 9.1 special case equal, io = (Tio Tosetp ), Eq. (20)
becomes exactly Control-B scheme captured Eq. (18).
322

fiDecentralized Market Control

Consequently, also follows simulation results equilibrium Market-B
scheme, based utility function Eq. (19) provisions given corollary, identical centralized Control-B scheme, cf. Figure 12. fully
decentralized market scheme thus performs better original Huberman-Clearwater
market protocol.
sum, see (under suitable conditions fulfilled here) local data plus
market communication equivalent conventional central control utilizing global data.
Even though proof based assumption agents never
boundary values, close approximation many practical applications.
also noted managing boundaries required successful implementation.
seen above, omitting management boundaries current application leads
Control-B, shown high performance.
9.2 Finding Optimal Utility Function
section show optimal utility function constructed constrained
case, optimal controller unconstrained case.15 Earlier noted
debatable whether measure Eq. (1) good one. One argument
allows pathological solutions, take average indoor temperature
consideration. example increase indoor temperature every office
10 C, could unbearably hot, measure might minimized.
reasonable thing here, prevent kind solutions, treat average
temperature given (the result using available resources). so, following
theorem shows optimal utility function constructed constrained case,
optimal controller unconstrained case.
Theorem 9.3 Tio linear function Fio ,16 io minimizes Eq. (1)
unconstrained case, market utility functions described Eq. (19),
Tio
= F
, associated Pareto optimal allocation minimizes Eq. (1) conio
strained case, resource independently allocated among agents (i.e.,
P
constraint Fio upper lower bound, N
o=1 Fio = 0),
average temperature considered given.
P

Proof. Minimizing Eq. (1) boils minimizing f (Ti1 , Ti2 , . . . , Tin ) = N
o=1 [(Tio
Tosetp )(hTi ihT setp i)]2 , since monotonic transformation. Due fact
f
io minimizes Eq. (1), holds F
= 0 Fio = io . Since average temperature
io

f
Tio
considered given, F
= 2[(Tio (io ) Tosetp ) (hTi hT setp i)]
io
io
Fio = io . gives Tio (io ) = Tosetp + (hTi hT setp i). Thus, f
P
2
rewritten N
o=1 [Tio (Fio )Tio (io )] . Since Tio linear function Fio ,

P



2

Tio
Tio
Tio (Fio ) = Tio (io ) + F
(Fio io ), hence f becomes N
(Fio
o=1 Fio
io
2
io ) . reallocation effect total (summed) utility, minimizing

15. resource constrained action agent limited Pio , see Eq. (12) Figure 7.
unconstrained limitation present, cf. Figure 6.
16. thermal model discussed Section 4 (especially Eqs. (5) (12)) note indeed
case reasonably wide range.

323

fiYgge & Akkermans

P

Tio
f equivalent minimizing N
o=1 uo , = Fio . Furthermore,
Pareto optimal allocation market utility functions described
P

Eq. (19) maximizes N
o=1 uo . (Suppose allocation Fio
PN
b
b
maximize o=1 uo , Fio does. reallocating Fio Fio letting mbio =

PN

uo (F b ,mb )

PN

uo (F ,ma )

io
io
io
io
o=1
maio + uo (Fioa , maio ) uo (Fiob , mbio ) + o=1
always Pareto
N
improvement. Hence, non-maximized sum implies non-Pareto optimal allocation,
Pareto optimal allocation implies maximized sum.) (Ygge, 1998, Theorem 3.1,
p. 44) implies Pareto-optimal allocation market utility functions
Tio
described Eq. (19) = F
, minimizes f . 2
io
Thus, constructed fully distributed market design yields optimal
outcome. Particularly note Theorem 9.3 based assumption
integral controller used, rather said io (the desired resource controller)
optimal, proposed utility function generates globally optimal outcome.

9.3 Discussion
Previously, saw independent controller Control-B incorporates global
data, viz. average temperatures, performs well. present section positively
answered question one construct market, Market-B, based local
data performs well.
result employed market approach based general equilibrium theory.
course available mechanism resource allocation multi-agent
systems. seems interesting try mechanisms, like contract net protocol
(Davis & Smith, 1983), see perform better. However, Theorem 9.3 tells us
that, treat problem building control separable terms agents (as
also done Huberman Clearwater), better scheme.17 example,
assigned resources auctioneer, turn would iteratively assign
total resource small portions bidders bidding true marginal utility, would
end something close competitive equilibrium, cannot better
Market-B. Furthermore, would computationally extremely inefficient way
arrive equilibrium compared available methods (Ygge, 1998, Chapter 4).
is, use different mechanisms achieving competitive equilibrium,
never hope find mechanism would better Market-B scheme.

17. note that, mentioned earlier, problem actually fully separable terms agents
therefore better solutions may exist taken account. Another observation article
investigated case using currently available resource interesting commodity,
accordance work Huberman Clearwater, found optimal mechanism that.
note however extending negotiations future resources well could potentially increase
performance. different problem setting different demands available local and/or
global information items, predictions. given solution problem recent work,
see Ygge et al. (1999).

324

fiDecentralized Market Control

10. Conclusions
believe approach results, presented article, pose
interesting challenge software agent community. Multi-agent systems offer new
way looking information systems development, potentially large future impact. However, new approaches must prove value comparison competition
existing, established ones. agent paradigm exception.
therefore deliberately played role devils advocate article.
view, key question yet satisfactorily answered software agent community
is: respect extent multi-agent solutions better
conventional alternatives? article shown arguing favor multi-agent
systems approach require careful analysis beyond disciplinary boundaries computer science. Empirical comparative studies multi-agent literature kind
carried present article rare yet. shown technical detail, established paradigms conventional central control cannot easily
dismissed. similar argument holds, way, regarding mathematical optimization
techniques distributed resource allocation problems, cf. previous discussions (Ygge
& Akkermans, 1996; Ygge, 1998). Many are, distributed guise, better
many newly proposed market protocols.
Abstract considerations alone, concerning general nature agenthood, autonomy,
rationality, cooperation, sufficient prove value agent paradigm.
theoretical reflections worthwhile, diminish need thorough analysis
(agent market) failures successes real-life applications. Therefore, taken
different approach, aimed obtaining experimental data points basis
convincing software agent claims established.
data point considered article climate control within large building consisting many offices. Given measure, Eq. (1), local controller approach, Eq. (11),
current temperatures, setpoint temperature, investigated problem
properly distribute resource among offices. rather prototypical
application relating general problem optimal resource allocation highly distributed environment. class problems already received much attention
multi-agent area. Reportedly, type application suitable market-oriented
programming (Huberman & Clearwater, 1995). hand, devised
better conventional control engineering solutions, well alternative better market
designs.
main conclusions investigation are:
market approach Huberman & Clearwater (1994, 1995) indeed outperforms
standard control solution based local, independent controllers. So, marketbased multi-agent approach indeed yields working solution type problem.
analysis shown success market approach depends
agents communicating local information agents auction
starts.
However, conventional central control schemes allowed exploit global
information, perform even better.
325

fiYgge & Akkermans

proposed alternative market design based general equilibrium theory
uses local data only. performs better Huberman-Clearwater market
well centralized control scheme access global information.
general conclusion formulated quasi-equation: local information
+ market communication = global control. holds suitable conditions
(existence market equilibrium, price-taking agents) validity specifically shown case building climate control (compare particularly
Control-B Market-B schemes developed). However, intend
show forthcoming work, much generally valid result.
important difference computational markets global information
emergent property rather presupposed concept, central control.
analysis focused market approach. tempting ask whether
things different non-market multi-agent approach followed, say, using
contract net (Davis & Smith, 1983). argued, answer opinion straightforward no. goal considered class problems find optimal distributed
solution. Alternative agent approaches, market well non-market ones, change
multi-agent dynamics way goal. might done better poorer way,
possible change goal itself. goal state multi-agent approach
is, however formulated, equivalent market equilibrium, yardstick achieved
given quantitative performance measure discussed, stable
across different agent approaches.
Thus, one main conclusions article one must careful
promoting multi-agent approaches resource allocation problems traditional
approaches available. particular, one cautious using arguments related
distribution information (as done Huberman Clearwater), computational aspects. Still, argue conceptual advantages market-based
approaches type problems, well advantages evaluation local
performance (cf. Section 2). advantages show clearly present
application setting example, assumed offices thermal
characteristics office agents market added deleted continuously
fly clearly visible general settings.
final note article devised optimal market design given
problem formulation rather devised optimal approach general problem
building control. line objective paper give comparative study
different possible approaches. is, focused published well-known
problem formulation order focus subject markets resource allocation
alone. stated earlier article, several aspects improved, example:
local controllers. I-controllers seldom used, rather PI- PID-controllers
preferred. Furthermore, kind computerized settings, modern digital controllers, based e.g. pole-placement methods preferable (Astrom & Wittenmark,
1990).
326

fiDecentralized Market Control

measure. average value least important standard deviation.
(We consequence excluded pathological solutions analysis taking
average temperature given Theorem 9.3).
incentives office agents reveal true preferences order avoid speculation. Reasonably, personnel offices opportunity make
trade-offs comfort economical value. (It shown generally
speaking difficult benefit speculation number agents
market sufficiently large, and/or uncertainty agents behavior
exists (Sandholm & Ygge, 1997).)
Taking several time periods account. office serves storage heat,
agents example gain using relatively much resource certain hours
total resource need small.
is, realistic approach building control problem use minimized
cost measure, give users real incentives reveal energy preferences (by
letting pay actual energy costs attempted speculation generally
cost money), take future time periods account. Elsewhere solved
problem dealing simultaneous optimization different time periods, means
multi-commodity market (Ygge et al., 1999).
realistic large-scale setting, market-based approach attractive
compared alternatives. abstractions used (prices demands) natural
easily understood everyone, uniform types agents (even ones
use resource controlling temperature).
major qualitative conclusion article local data plus market communication yields global control. conclusion based discussed application setting
building control, instance distributed resource allocation problem. suggests
generally type problem central control engineering multi-agent
market solutions devised give comparable optimal control quality. next step
prove generally rigorous mathematical fashion, delineating preconditions detail. proof based upon (continuous matrix-algebraic)
dynamic systems theory available control engineering, especially upon results concerning called optimal control. believe indeed done formal
way, conjecture state following general result. Multi-agent equilibrium markets yield optimal decentralized solutions distributed resource allocation problems
quality, terms given overall systems performance index, solutions
given optimal central (multi-input, multi-output) systems controller access
relevant local data. local data involve total system state control vectors
(in building control vectors formed difference actual
setpoint temperatures office, cooling power office, respectively).
Preconditions true are: (i) agents act competitively; (ii) equilibrium exists; (iii) systems performance index written linear combination local
contributions (implying diagonality certain matrices; not, agents independent).
local contributions directly related agents utility functions. agent
approach readily generalizable large-scale systems non-linear control
327

fiYgge & Akkermans

solutions (linearity main case control engineering get analytical mathematical expressions). indeed strong general statement relationship
(and even outcome equivalence) decentralized markets central control.

Acknowledgments
present work mainly carried University Karlskrona/Ronneby.
thank Rune Gustavsson Hans Ottosson support. special acknowledgment
goes Olle Lindeberg whose detailed comments draft papers led significant
improvements simulations whose ideas also helped us design market
Section 9. benefit significantly several discussions Michael Wellman.
also thank Bengt Johannesson, who, part masters thesis, went details
article independently recreated verified simulations. thank Arne
Andersson, Eric Astor, SoC team useful comments discussions draft
material. work partially sponsored NUTEK EnerSearch AB.
earlier version paper presented MAAMAW97 workshop (Ygge &
Akkermans, 1997).

328

fiDecentralized Market Control

Appendix A. Original Formulation Huberman-Clearwater Market
formulae section directly taken papers Huberman & Clearwater (1994, 1995).
Trade volumes

First, decision agent buy sell based
(

setp
hTi
tio =
setp
Tio hT


tio > 1, seller
.
tio < 1, buyer

(21)

Then, total trade volume, V , calculated
Vi =

N
X

|1 tio | ,

(22)

o=1

N number offices.
Every agent calculates request volume, v, according
vio =

|1 tio |
.
Vi

(23)

agent buys sells v actual movement valve, called V AV ,
computed
V AVio = f (f lowio , vio , V AVio ),
(24)
actual V AV position interval updated according
V AVi+1,o = V AVio + V AVio .

(25)

function f Eq. (24) stems physics office control,
easy derive general case neither explicitly given original papers
(Clearwater & Huberman, 1994; Huberman & Clearwater, 1995). reasonable simple
choice assume linear relationship (the cited papers suggest practice
well), replacing Eq. (24) Eq. (25)
Fi+1,o = Fio vio ,

(26)

plus minus depend whether refers accepted buy sell bid. Pcio
obtained Eq. (12). employed Eq. (26) simulations. nature
assumption crucial central line reasoning.
Bids

bids based marginal utility 18 form described by19
setp

U (tio /Tosetp , mio ) = [U (0, mio )](1tio /To

)

(1

= [U (0, mio )]

hTi
)
Tio hT setp

,

(27)

18. called utility work Huberman Clearwater. prefer use term marginal utility
instead, directly related price. terminology conforms better microeconomic
theory.
19. notion utility function used Clearwater Huberman much based work
Steiglitz & Honig (1992)

329

fiYgge & Akkermans



U (0, mio ) = u3 (u3 u1 )emio ,



= ln

(28)



u3 u 1
,
u3 u 2

(29)

u1 = 20, u2 = 200, u3 = 2000, amount money agent has,
given
mio = 100(2 V AVio ).
(30)
relation Fio V AV , rewrite Eq. (30)
mio = 100(2

Fomax Fio
).
Fomax

(31)

Observing Eqs. (28) (29), note equations simplified
U (0, mio ) = u3 (u3 u1 )emio = u3 (u3 u1 )(e )mio =
u3 (u3 u1 )



u3 u1
u3 u2

mio

.

(32)

bids calculated multiplying marginal utility previous price,
price, according
Bi,o = Uio (tio /Tosetp , mio ) pricei .
(33)
equation given Huberman Clearwater. Straightforward application
Eq. (33) turns produce major problems simulations, however. Equation (27)
ii
shows U (tio /Tosetp , mio ) minimized minimized Tio maximized hThTsetp
.
expect Tio well 10 C

hTi
hT setp

well 2, U (0, m) 2000,
2

sure U (tio /Tosetp , mio ) well 20001 10 437. Thus, bidding
price never 437. Then, Eq. (33) tells us market price
least price0 437i . leads numerical overflow iterations. note however
that, since agents multiply bids previous price, effect
reallocation itself: affects price level. Therefore, omit multiplying
previous price simulations, agents bid prices Eq. (33) equal
marginal utilities Eq. (27). Huberman Clearwater state burn money
auction round order avoid inflation overflow, indicating may
adopt similar procedure. case, procedure leads exactly allocations
avoids numerical overflow.

330

fiDecentralized Market Control

References
Akkermans, J. M., & Ygge, F. (1997). Smart software customer assistant large-scale
distributed load management. Proceedings Distribution Automation/Demand
Side Management (DA/DSM) 97. PenWell Conferences Exhibitions.
Bertsekas, D. (1992). Auction algorithms network flow problems: tutorial introduction. Computational Optimization Applications, pp. 766.
Bikhchandani, S., & Mamer, J. W. (1997). Competitive equilibrium exchange economy
indivisibilities. Journal Economic Theory, 74, 385413.
Borst, W. N., Akkermans, J. M., & Top, J. L. (1997). Engineering ontologies. International
Journal Human-Computer Studies, 46, 365406. ISSN 1071-5819.
Bradshaw, J. M. (Ed.). (1997). Software Agents. AAAI Press/The MIT Press, Menlo Park,
CA.
Cheng, J., & Wellman, M. P. (1998). walras algorithma convergent distributed
implementation general equilibrium outcomes. Computational Economics, 12, 1
24.
Clearwater, S., & Huberman, B. A. (1994). Thermal markets controlling building environments. Energy Engineering, 91 (3), 2556.
Davis, R., & Smith, R. G. (1983). Negotiation metaphor distributed problem
solving. Artificial Intelligence, 20 (1), 63109.
Gagliano, R. A., Fraser, M. D., & Schaefer, M. E. (1995). Allocation compting resources.
Communications ACM, 38, 88103.
Hu, J., & Wellman, M. P. (1996). Self-fulfilling bias multiagent learning. Tokoro, M.
(Ed.), Proceedings Second International Conference Multi-Agent Systems,
ICMAS96, pp. 118125. AAAI Press, Menlo Park, CA.
Huberman, B. A., & Clearwater, S. (1995). multi-agent system controlling building
environments. Lesser, V. (Ed.), Proceedings First International Conference
Multi-Agent Systems, ICMAS95, pp. 171176. AAAI Press / MIT Press,
Menlo Park, CA.
Ibaraki, T., & Katoh, N. (1988). Resource Allocation ProblemsAlgorithmic Approaches.
MIT Press, Cambridge, MA.
Incropera, F. P., & Witt, D. P. D. (1990). Fundamentals Heat Mass Transfer. Wiley
Sons, New York. Third Edition, ISBN 0-471-51729-1.
Jennergren, P. (1973). price schedules decomposition algorithm linear programming
problems. Econometrica, 41 (5), 965980.
Jordan, J. S. (1982). competitive allocation process informationally efficient uniquely.
Journal Economic Theory, 28, 118.
331

fiYgge & Akkermans

Kurose, J. F., & Simha, R. (1989). microeconomic approach optimal resource allocation
distributed computer systems. IEEE Transactions Computers, 38 (5), 705717.
Mas-Colell, A., Whinston, M., & Green, J. R. (1995). Microeconomic Theory. Oxford
University Press.
Mullen, T., & Wellman, M. P. (1995). simple computational market network information services. Lesser, V. (Ed.), Proceedings First International Conference
Multi-Agent Systems, ICMAS95, pp. 283289 San Francisco, CA.
Ogata, K. (1990). Modern Control Engineering. Prentice-Hall, Englewood Cliffs, NJ. Second
Edition, ISBN 0-13-589128-0.
Press, W., Teukolsky, S., Vetterling, W., & Flannery, B. (1994). Numerical Recipies C.
Cambridge University Press. Second Edition.
Sandholm, T. W., & Ygge, F. (1997). gains losses speculation equilibrium
markets. Proceeding Fifteenth International Joint Conference Artificial
Intelligence, IJCAI 97, pp. 632638.
Schreiber, A. T., Akkermans, J. M., & al. (1999). Knowledge Engineering Management.
MIT Press, Cambridge, MA. Press.
Steiglitz, K., & Honig, M. L. (1992). Chaotic behavior auction-based microeconomic
model. Unpublished Manuscript.
Sutherland, I. E. (1968). futures market computer time. Communications ACM,
11 (6), 449451.
Takayama, A. (1985). Mathematical Economics. Cambridge University Press.
Varian, H. R. (1992). Microeconomic Analysis. New York: W. W. Norton. Third Edition.
Varian, H. R. (1996). Intermediate MicroeconomicsA Modern Approach. W. W. Norton
Company, New York. Fourth Edition.
Walsh, W. E., Wellman, M. P., Wurman, P. R., & MacKie-Mason, J. K. (1998).
economics market-based distributed scheduling. Proceedings Eighteenth
International Conference Distributed Computing Systems, pp. 612621.
Wellman, M. P. (1993). market-oriented programming environment application
distributed multicommodity flow problems. Journal Artificial Intelligence Research,
pp. 123.
Wellman, M. P. (1996). Market-oriented programming: early lessons. Clearwater,
S. (Ed.), Market-Based Control: Paradigm Distributed Resource Allocation,
chap. 4. World Scientific.
Wellman, M. P. (1995). computational market model distributed configuration design.
AI EDAM, 9, 125133.
332

fiDecentralized Market Control

Wellman, M. P., & Hu, J. (1998). Conjectural equilibrium multiagent learning. Machine
Learning, 33, 179200.
Yamaki, H., Wellman, M. P., & Ishida, T. (1996). market-based approach allocating
QoS multimedia applications. Tokoro, M. (Ed.), Proceedings Second
International Conference Multi-Agent Systems, ICMAS96, pp. 385392. AAAI
Press, Menlo Park, CA.
Ygge, F. (1998). Market-Oriented Programming Application Power Load Management. Ph.D. thesis, Department Computer Science, Lund University. ISBN
91-628-3055-4, CODEN LUNFD6/(NFCS-1012)/1-224/(1998).
Ygge, F., & Akkermans, J. M. (1996). Power load management computational market.
Tokoro, M. (Ed.), Proceedings Second International Conference MultiAgent Systems, ICMAS96, pp. 393400. AAAI Press, Menlo Park, CA.
Ygge, F., & Akkermans, J. M. (1997). Making case multi-agent systems. Boman,
M., & de Velde, W. V. (Eds.), Proceedings MAAMAW 97, pp. 156176. Springer
Verlag, Berlin. ISBN-3-540-63077-5.
Ygge, F., & Akkermans, J. M. (1998). resource-oriented multi-commodity market computations. Demazeau, Y. (Ed.), Proceedings Third International Conference
Multi-Agent Systems ICMAS98, pp. 365371. IEEE Computer Society.
Ygge, F., Akkermans, J. M., Andersson, A., Krejic, M., & Boertjes, E. (1999). HomeBots system field tests: multi-commodity market predictive load management. Proceedings Fourth International Conference Exhibition
Practical Application Intelligent Agents Multi-Agents (PAAM99), pp. 363382.
Astrom, K.-J., & Wittenmark, B. (1990). Computer-Controlled Systems - Theory
Design. Prentice Hall, Englewood Cliffs, NJ. ISBN 0-13-168600-3.

333

fi
fffi ffffff
!" #%$$'&$(((*)+$,(-$(.

8:9<;>=>?A@CBEDGF>H+IKJML>?AION

/012'34$5((*671ff"#3!.*5((

IQPSR>9UT>HWVYXZF[DGJ\;>]B^]A_W@C?Y`aPS=>T>b

cedgf^hikjmlnhoqp

r+sutvgwx4y{zfi|~}Qv|uS}

!*<
un%+K{
Cu

g
4*u
~*n*{:g
hdidh

Q{y{tx4'|}n|uS}

+*QgC
ua*<
u
g
4u*
!~*g:{u

fi
%AA<W*^*g!Q u* <
*AaA*0^00u<Au0C*fi
CA
AAn*4AC*%AAmA*0 {A^
*uAA>
*AA*>!U
40a* A%*<AAu0
W***
%u*
0uAU%AA<A'**'0%^***Q'fi*
uAumA
**nu*A**C*>A {A g*u%
uu*0fiuA>AA
AQ<Q*gACC
AC%
uuK*%
4K4gA*SC*fi

uAA0A'*W'A*0A
****
%C'00u WAA* u
%figAW
**U
g%'***%*% C%*a*A
K
aA*0
U!0%
%AuA!A0
'*'u*C%%
uA!*u^fiAA


CAu0A0AK*An
>a*CA*0AA* UuA>u4A*
0fiQu* QAA
Q<gA*%**g'fi*
U%
fi!!A
40
0
A*+
u4>0>*%uAn
uAA
C
'fi*
U0A%m{A<mu
0
uAA04
!00%*uAA
*

*'
A*uSC*4*A
+

u!**AA<

gA*%*QA%A
!CkA*0A*<uAC{AuA {A >**Q**A
gC0A<
4fiff<0uASuA'uauAA0A

fi

fiQ



"!$#&%$#&!$'
()#&!$%*(+-,+#/.0,+#&%21.0341#&561(+#71#&'
()).08:9)#/;<='&;>?).0).0+3@1()#/A)!$#&5).0'B1.0;+%C;<=>9)D 1. E
A)D0#'&D0%$%$.0F)#&!G%H1;IA)!G;J5)9+'&#7@%$.0)3D0#K'&D0%$%$.0F)#&!*LNMO!$#&.0>*+PRQSST'&UVWD0#&>*#&)PQSXSUZY#&!$!G;)#&PQSS[U
\];D0A^#&!21P_QSS`a-b@cW()#!$#&%$9)D 1.0)3@'&D0%$%$.0F+#&!dLN()#&!$#&<e1#&!!$#&<N#&!$!$#&5d1;I%gf$h)ijf$kml-nofpaq.0%3#&)#&!$D0D
>*;!$#r'&'&9)!$41#1(+6 g;<s1()#*.0+5). ,^.05+9)D_'&D0%$%$.0F)#&!G%7>*t:.0)3m9)A@1(+#*#&)%$#&>?)D0#&buMO;41(m1()#&;4E
!$#B1.0'&DWLNvw)%$#&xzy)D0>r;)PsQSS{UH|}!$;3(ux~=#&5)#&D0%$?P_QSSaq)5#&>*A).0!$.0'&DLNv%G()#&>*PRQSSU
A). 1/xy+()-,D0.0tJPwQSSTP=QSST?+ar!$#&%$#&!G'G(g()%r5)#&>*;)%21!G41#&51()413;:;J5g#&+%$#&>?+D0#/.0%*;)#
()#&!G#H1(+#.0)5). ,.05)9)D'&D0%$%$.0F)#&!$%=.01()##&)%$#&>?)D0#!$#?^;41(I'&'&9)!$41#}+5/>*t#O1()#&.0!#&!$!G;!$%;
5).0#&!$#&1dA)!21%;<1(+#*.0)A)91r%GA)'&#&buc ;mA^;A)9)D0!>r#B1();J5+%7<N;!}'&!$#&41.0)3'&'&9)!$41#@#&)%$#&>?)D0#&%
!$#/MO33.0)3LNM!G#&.0>*)P=QSST'&a@)5MO;:;%21.0)3]LN)!$#&9+)5gxy)'
()A).0!$#&PQSSTU}y)'G(+A).0!$#&PwQSS{a-b
cW()#&%G#>*#B1(+;J5)%O!$#&D ;4!$#&%$>*A+D0.0)31#&'G()).08:9)#&%R1;C;?1.0/5+.0#&!$#&1O1!$.0).0)3K%$#B1%<N;!O#&'G(m;<
1()#*'&D0%G%$.0F)#&!$%$bu@1().0%7A)A^#&! #CA+!$#&%$#&1dm'&;>*A)!G#&()#&)%$. ,+#C#B,D09)41.0;;<?^;41(MO33.0)3)5
MO;J;%o1.0)3I;`[@5)41I%$#B1%q9)%$.0)3}1 ;d?+%$.0''&D0%G%$.0F)'&41.0;6>*#B1(+;J5)%Gw5+#&'&.0%$.0;d1!$#&#&%q)5+#&9)!$D
)#B1 ;!$t:%$b


$((('g""
3 C 3 ^ 2' q*1
ff"#"pfiffff*#A"S"3

fi

stv{wz{y{t

Y!$#B,^.0;9+% ;!Gtd()%=5)#&>*;)%21!G41#&5K1()417MO33.0)3r+5/M;:;%21.0)3r!$#O,+#&!2#&#&'B1. ,+#<;!=5)#&'&. E
%$.0;1!$#&#&%7LNMO9)#&!x|7;()-,.0PQSSSUq!$9)'
t#&!xVW;!21#&%$P^QSSTUMO!$#&.0>*+PQSST'&PQSST?)U)!G#&9))5
xy+'G()A).0!G#&PQSSTU79).0)D0)PqQSSTa-UK(); #B,+#&!$PO1(+#&!$#u()%d?^#&#&]D0. 1-1D0##&>*A).0!$.0'&DH1#&%21.0)3 . 1(
)#&9)!GD_)#B1 ;!$t:%@LN#&%$A^#&'&.0D0D . 1(I1(+#*)# MO;J;%o1.0)3uD03;!$. 1(+>*a-buq.0%$'&9)%G%$.0;)% . 1(A)!$#B,.0;9)%
!$#&%$#&!G'G()#&!$%R!$#B,+#&D1()41>r r91(+;!$%'&;)'&#&1!$41#&5K;5)#&'&.0%$.0;=1!$#&#&%s5+9)#^1;_1(+#&.0!s<N%211!G.0).0)3
%$A^#&#&5u+5 #&D0D EG#&%21?)D0.0%$()#&55)#&<N9)D 1KA)!$>*#B1#&!w%$#B1-1.0)3%$bw#&9)!$Ds)#B1 ;!$t:%qA)!$#&%$#&15).0*'&9+D 1.0#&%
<N;!Z1#&%21.0+3r?^;41(u.0r1#&!$>*%w;<1()#7%G.03).0F)'&1A)!$;:'&#&%$%$.0+31.0>*#!$#&8J9+.0!$#&5u)5.0%G#&D0#&'B1.0)31!$.0E
.0)3A)!$>*#B1#&!G%$U^(); #B,+#&!$P #w<N#&#&D1(+#&!$#=!$#w5).0%21.0+'B1q5,13#&%1;.0+'&D09)5).0)3)#&9)!$D)#B1 ;!$t:%
.0;9)!%o19)5b.0!$%o1PA)!$#B,.0;9)%#&>rA).0!$.0'&D%219)5).0#&%()-,+#I5)#&>r;)%21!$41#&5u1()41/.0)5). ,.05)9)DH+#&9)!$D
)#B1 ;!$t:%wA)!$;:5)9)'&#().03()D '&'&9+!$41#'&D0%G%$.0F)#&!$%Z1()41!$#%$;>*#B1.0>*#&%q>*;!G#}'&'&9)!$41#=1()u'&;!G!$#BE
%$A^;)5).0+35)#&'&.0%G.0;w1!$#&#&%LN.0%$()#&!_x"'&|}9)%$.0'
tJPQSXSU;:;)#BP+y)(+-,D0.0tJPcR; #&D0D0Px"7;-,+#&PQSXSa-b
y)#&'&;)5+P+#&9)!$DZ)#B1 ;!GtJ%K()$,+#d?^#&#&#B:1#&)%$. ,+#&D A)A)D0.0#&5'&!$;%$%K:9)>*#&!$;9)%5);>*.0)%ILN!G?).0?)P
QSSa-bm.0)D0D P? %219)5^.0)3I)#&9+!$D)#B1 ;!$t:%7.05)5). 1.0;/1;m5)#&'&.0%$.0;I1!G#&#&% #C'&6#B^>r.0)#
(); MO33.0)3@)5mMO;J;%o1.0)3r!$#.0))9)#&+'&#&5/? I1()#}D0#&!G).0)3rD03;!G. 1()>*P3. ,.0)3d<9)!o1()#&!.0)%$.03(1
.01;K1()#*3#&)#&!GDZ'G()!G'B1#&!$.0%21.0'&%K;<1(+#&%$#*A)A)!G;'G()#&%$buM9+#&!7)56|7;()-,.LNQSSSaD0%$;m%219)5
MO33.0)3u+56MO;J;%21.0+3mA)A)D0.0#&5I1;C1 ;mD0#&!$).0)3u>*#B1();:5)%$PZ.0I1(+#&.0!}'&%$#*5)#&'&.0%G.0;/1!$#&#&%}9+%$.0)3
K,!$.01@;<VWb0m+5). ,+#BEGMO-+#&%C'&D0%G%$.0F)#&!$%$P?)9171()#&.0!7%219+5>r.0)D g'&;)'&#& 1!G41#&5;m1()#
5)#&'&.0%$.0;*1!$#&#}!$#&%G9)D 1%$b
9+!)#&9+!$Ds+#B1 ;!$tu)55)#&'&.0%G.0;@1!$#&#K!$#&%$9)D 1%qD0#&59)%1;Id:9)>?#&!w;<H.01#&!$#&%21.0+3@'&;+'&D09E
%$.0;)%GbcW()#uF)!$%21u.0%}1()41MO33.0)3#&)%$#&>?)D0#u3#&+#&!$D0D A)!$;:5)9)'&#&%*'&D0%$%$.0F)#&!}1()41.0%d>*;!$#
'&'&9)!$41#1()/C%21)5)!G5/'&D0%$%$.0F)#&!$b=cW(J9+%;)#q%$();9)D05/<N#&#&D'&;>*<N;!21?)D0#}D -%=MO33.0)3}1()#&.0!
5)#&'&.0%$.0;r1!$#&#&%;!=)#&9)!GD)#B1 ;!$t:%$bw);!MO;:;%21.0)3PR(); #B,+#&!$P #);41#}>*;!$# .05)#&D I,!2^.0+3*!$#BE
%$9)D 1%Gb=);!r<N# 5)41r%G#B1%=MO;J;%o1.0)3rA)!G;J5)9+'&#&5/5)!$>*41.0'!$#&5)9)'B1.0;)%=.0u#&!$!$;!LN#B,+#&'&;>*A+!$#&5
1;6MO33.0)3a-Pq?)91m<N;!*;41()#&!*5+41%$#B1%r. 1u'B19)D0D .0)'&!G#&%$#&%r.0#&!$!G;!*;-,+#&!d%$.0)3D0#/'&D0%$%$.0F+#&!
LNA)!21.0'&9+D0!$D . 1(+#&9)!$DR)#B1 ;!$t:%$a-brB<9)!o1()#&!1#&%21% #K#B>*.0)#&5@1()#K#&#&'B1%};<H+;.0%$#C)5
%$9)A+A;!o1K)!G#&9))56)5y+'G()A).0!G#&0%@LNQSSTa7'&;p#&'B19)!G#q1()41dMO;:;%21.0)30%7%G#&)%$. 1. ,. 11;m);.0%G#C>*-
?^#A)!21D !$#&%$A^;)%$.0?+D0#<;!W. 1%;J'&'&%G.0;)D.0)'&!G#&%$#}.0m#&!$!G;!$b
wID 1#&!$)41#}?)%G#&D0.0)#qA)A)!$;'
( #q.0 ,+#&%o1.0341#&5 %R1()#w'&!$#&41.0;m;<K%$.0>rA)D0#+#&9)!$D)#B1-E
;

$
!
tK#&)%$#&>?)D0# ()#&!G##&'G(@)#B1 ;!$tC9)%$#&5w1(+#W<9+D0D1!$.0).0)37%$#B1)5*5+.0#&!$#&5r;)D m.0r. 1%H!G)5);>

.0). 1.0D #&.03(1%$#B1-1.0+3%$b 9)!*!$#&%$9+D 1%*.0)5).0'&41#*1()41*1().0%d#&)%$#&>?)D0#K1#&'G(+).08J9+#u.0%*%$9+!$A)!$.0%$.0+3D
#&#&'B1. ,+#&P_;<1#&A)!$;:5)9)'&.0)3C!G#&%$9)D 1%w%3;:;J5%MO33.0)3b=#&%$#&!G'G(? wD0.)5Y&&).OLNQSSTa
5)#&>*;+%21!$41#&5m%$.0>r.0D0!=!$#&%$9+D 1%W9)%$.0)3C!G)5);>*.0&#&5m5+#&'&.0%$.0;C1!$#&#7D03;!$. 1()>*%$b
9+!!$#&%G9)D 1%qD0%$;/%$(); 1(+41w1(+##&)%G#&>?)D0#K>*#B1(+;J5)%q!$#K3#&)#&!GD0D '&;)%$.0%o1#& 1LN.0d1#&!$>*%;<
1()#&.0!s#&#&'B1O;}'&'&9)!$'Ba (+#&}A)A)D0.0#&5}#&. 1(+#&!)1;W+#&9)!$D)#B1 ;!$t:%;!)1;W5)#&'&.0%$.0;=1!$#&#&%$U(); #B,+#&!GP
1()#&!$#@.0%KD0. 1-1D0#I.0 1#&!2EG'&;!G!$#&D041.0;]?^#B1 #&#&)#&9)!$D)#B1 ;!$t:%C)55)#&'&.0%$.0;1!$#&#&%C#B'&#&A1I<N;!1()#
MO;J;%o1.0)3>r#B1();J5+%$bcW().0%d%$9)33#&%21%1()41%$;>*#;<1()#.0)'&!$#&%$#&%IA)!$;:5)9)'&#&5]? MO;:;%21.0)3!$#
5)#&A^#&)5)#&1C;I1()#KA)!21.0'&9)D0!7'G()!$'B1#&!G.0%21.0'&%;<1()#C5)41/%$#B1r!G41()#&!1();@1()#C'&;>*A^;)#&1
'&D0%$%$.0F+#&!$bzB]<N9)!21(+#&!1#&%21% #5+#&>*;)%21!$41#r1()41MO33.0)3.0%@>r;!$#u!$#&%G.0D0.0#& 1I1;);.0%$#r1()
MO;J;%o1.0)3b
.0)D0D P #q.0 ,+#&%o1.0341#&5*1()#q8:9)#&%21.0;/;<s(); >*'&;>*A^;)#&17'&D0%$%$.0F+#&!$%%$();9)D05I?^#w9)%$#&5
.0]#&)%$#&>?)D0#&bV=;)%$.0%21#&1 . 1(]A)!$#B,.0;9)%d!$#&%$#&!$'
(LN+!$#&9))5xy)'
()A).0!$#&PQSSTUC79).0)D0)P
QSSTa-PW;9)!!$#&%$9+D 1%7%$(); 1(+41I>*;%o1@;<R1()#d!$#&5)9)'B1.0;.0#&!G!$;!<N;!7#&+%$#&>?+D0#d>*#B1(+;J5)%;J'&'&9+!$%
. 1(m1()#*F)!$%o1r<# 5)5). 1.0;)D'&D0%$%$.0F)#&!$%Gb*\. 1(MO;:;%21.0)35)#&'&.0%$.0;/1!G#&#&%$PO(); #B,+#&!$PO!$#&D041. ,+#&D
D0!$3#}3.0+%=>*$?^#%$#&#&u9)Am9)1.0D?^;91`*'&D0%$%G.0F)#&!$%$b
*

fi

r+su}SmQz
r

vr++z

cW(+.0%A)A^#&!w.0%q;!$3).0&#&5%q<;D0D0; %$bKr1()#)#B:1K%$#&'B1.0; #A)!$#&%$#&1K;-,+#&!o,^.0# ;<H'&D0%2E
%$.0F)#&!#&)%$#&>?)D0#&%w)5m5).0%$'&9+%$%=MO33.0)3@)5uMO;:;%21.0)3d.0u5)#B1.0D0bw#BJ1 #A)!$#&%$#&1#BJ1#&)%G. ,+#
#&>*A).0!G.0'&D)D ^%G.0%=;<MO33.0)3d)5/MO;J;%o1.0)3b=);D0D0; .0)3}1()41 #A+!$#&%$#&17<919+!$#!G#&%$#&!$'G()5
5)5). 1.0;+D!$#&D041#&5 ;!$t@?^#&<;!G#'&;)'&D09)5).0)3b


fi

)Y


.039)!$#CQ/.0D0D09)%o1!$41#&%1()#K?)%G.0'C<!$>r# ;!$t<N;!/'&D0%$%$.0F)#&!}#&+%$#&>?+D0#&b@Bd1().0%}#B>*A)D0#&PZ+#&9)!$D
)#B1 ;!$t:%H!G#_1()#W?+%$.0'W'&D0%$%$.0F+'&41.0;@>r#B1();J5+P1();9)3(*'&;+'&#&A19)D0D m'&D0%$%$.0F)'&41.0;@>*#B1();:5
LN#&b03b0P5)#&'&.0%$.0;q1!$#&#&%GaZ'&*?^#O%$9)?)%21. 191#&5*.0CA)D0'&#W;<1()#)#B1 ;!$t:%$bOH'
(r)#B1 ;!Gt.0C.039)!G#Q0%
#&)%$#&>?)D0#KLN)#B1 ;!$tCQO1()!G;9)3(*)#B1 ;!$t*.0}1().0%H'&%$#&a.0%1!$.0+#&5r9)%$.0+3O1()#1!$.0+.0)3}.0)%21+'&#&%
<N;!H1(+41C+#B1 ;!$tJbKcW(+#&)Ps<N;!q#&'G(#B>*A)D0#&P1()#A)!$#&5+.0'B1#&5;91A)91C;<Z#&'G(;<1()#&%$#)#B1 ;!$t:%
L24.0.039)!G#7Qaw.0%'&;>?).0)#&5r1;rA)!G;J5)9+'&#O1()#7;91A)91;<1()##&)%$#&>?)D0#@Lr
.0u.039)!$#Qa-b}
!$#&%$#&!G'G()#&!$%wLND0A)$^5+.0)P+QSS[U^MO!$#&.0>*)P+QSST'&U|7!$;3(*x~=#&5)#&D0%$?PQSSUs.0)'&;D0*xy)t:!$BA^#&tJP
QSXSaq()-,+#5)#&>*;+%21!$41#&5C1(+41K#&#&'B1. ,+#K'&;>?).0).0)3d%$'G()#&>r#.0%H1;r%$.0>rA)D 6-,+#&!$3#1()#A)!$#BE
5).0'B1.0;)%;<)1(+#})#B1 ;!$t:b

V ;>?).0).0+3W1()#w;91A)91q;<%G#B,+#&!$D^'&D0%$%$.0F)#&!$%.0%O9)%G#&<9)D;)D .0<1(+#&!$#.0%O5).0%G3!$#&#&>*#&1>r;)3
W
1()#&>*b ?,^.0;9+%$D P}'&;>?).0).0)3%$#B,+#&!$Dq.05)#&1.0'&Dq'&D0%$%$.0F)#&!G%@A+!$;J5+9)'&#&%d+;3.0)bvw)%$#&)5
y)D0>*;gLNQSS{a}A+!$;-,+#&5d1()41*.0<^1()#-,+#&!G3#*#&!$!$;!q!$41#K<N;!w#B>*A)D0#.0%D0#&%$%1(){)5
1()#w'&;>*A^;)#&1w'&D0%$%$.0F+#&!$%O.0}1()#w#&)%$#&>?)D0#w!$#w.0)5)#&A^#&)5)#&1.071()#A+!$;J5+9)'B1.0;r;<1(+#&.0!#&!$!G;!$%$P
1()#/#BA^#&'B1#&5]#&!$!$;!C<N;!q1()41u#B>*A)D0#u'&g?^#/!$#&5)9)'&#&51;6&#&!G;%1()#/:9)>?#&!K;<q'&D0%$%$.0F+#&!$%
'&;>?).0)#&53;:#&%1;u.0)F)). 1^U(); #B,+#&!$PO%$9)'
(6%$%$9+>*A1.0;)%}!G!$#&D (+;D05.06A)!G'B1.0'&#&bu|}!$;3()5
~=#&5)#&D0%$?LNQSSa=D041#&!WA)!$;$,+#&571(+411()##&+%$#&>?+D0#w#&!G!$;!O'&/?#w5). ,.05)#&5@.0 1;C1#&!$>>*#&%$9+!$.0)3
1()#6$,+#&!$3#3#&)#&!$D0.0&41.0;#&!$!$;!m;<K#&'
(.0)5+. ,^.05)9+D'&D0%$%$.0F)#&!)51#&!$>>*#&%$9)!$.0+31()#
5).0%$3!G#&#&>*#& 1>*;)3=1()#'&D0%$%$.0F)#&!$%GbR\()411()#Bu<N;!$>*D0D u%$(+; #&5 %1()41q@.05)#&D#&)%$#&>?)D0#
'&;)%$.0%o1%7;<().03()D '&;!$!$#&'B1@'&D0%G%$.0F)#&!$%O1(+41d5).0%$3!$#&#r%7>9)'G(6%A^;%$%$.0?)D0#&b A+. 1C)56y)()$,^D0.0t
LNQSSTPRQSST?)a=#&>*A+.0!$.0'&D0D /,+#&!$.0F)#&5K1(+41%$9)'
(m#&)%$#&>?)D0#&%=3#&+#&!$D0.0&# #&D0D0b
%H}!G#&%$9)D 1P+>r#B1();J5+%H<N;!Z'&!$#&41.0)3#&)%$#&>?)D0#&%H'&#&1#&!!$;9))5*A+!$;J5+9)'&.0)3q'&D0%$%$.0F)#&!G%1()41w5).0%2E
w
3!$#&#O;=1()#&.0!sA+!$#&5).0'B1.0;)%$b}#&)#&!GD0D P1()#&%$#>*#B1();:5)%R<;:'&9)%;KD 1#&!$.0+3Z1()#1!$.0).0+3=A)!$;:'&#&%$%R.0


ensemble output
combine network outputs


1

2

network 1 network 2



N

network N

input
.039)!G#Q='&D0%$%$.0F)#&!#&)%$#&>?)D0#};<R)#&9)!$D)#B1 ;!GtJ%$b
*

fi

stv{wz{y{t

1()#}(+;A#1()41=1()#}!$#&%$9+D 1.0)3*'&D0%$%$.0F+#&!$% .0D0DA+!$;J5+9)'&#5).0#&!$#& 1A)!$#&5).0'B1.0;)%GbW);!=#B>*A)D0#&P)#&9E
!$D)#B1 ;!$tw1#&'G(+).08J9+#&%1()41q()-,+#?^#&#&r#&>*A)D0;$+#&5d.0+'&D09)5)#W>*#B1(+;J5)%<;!1!$.0).0)3 . 1(r5).0#&!$#&1
1;A^;D0;3.0#&%$PR5).0#&!G#& 1.0+. 1.0D #&.03( 1%GP5).0#&!$#&1A)!$>*#B1#&!G%$P)5C1!$.0).0)3*;+D ;*A^;!21.0;u;<
1()#O1!G.0).0)3*%$#B1/LND0A)$^5+.0)PQSS[URw!G9)'Gt#&!$PVW;!21#&%$PJ'Gt#&D0PR#&VW9+)Px~=A)).0t:PQSSURv+%$#&
xy)D0>*;+PZQSS{U'&D0.06xy)(+-,D0.0tJPZQSSa-bIB@1().0%A)A^#&! #C'&;+'&#& 1!$41#r;I1 ;/A^;A)9)D0!
>*#B1();:5)%dLNMO33.0)3)5M;:;%21.0)3a=1()411!21;m3#&)#&!$41#@5).0%$3!$#&#&>r#& 1/>*;)3K1(+#r'&D0%$%$.0F+#&!$%
?D 1#&!$.0+31()#1!$.0+.0)3*%$#B1#&'
('&D0%G%$.0F)#&!W%$#&#&%Gb
Shs
+$ )

d) *
hNRgfi

MO33.0)3LNM!G#&.0>*)POQSST'&aK.0%4?;:;41%21!$A+LNH<N!$;xcW.0?)%G().0!$).0PQSS[a#&)%G#&>?)D0#d>*#B1();:5
1()41/'&!$#&41#&%C.0)5). ,.05)9)D0%<N;!. 1%K#&)%G#&>?)D0#@?1!$.0).0)3#&'G('&D0%$%G.0F)#&!K;!$)5+;>!$#&5+.0%21!$. E
?)91.0;;<1()#1!$.0+.0)3*%$#B1bqH'
('&D0%G%$.0F)#&!$0%H1!$.0).0)3d%$#B1.0%w3#&)#&!$41#&5? 6!$+5);>*D 65)!$ .0)3P
. 1(!$#&A+D0'&#&>*#& 1P#B>*A)D0#&% (+#&!$#.0%1()#C%$.0&#C;<1()#K;!$.03.0)D1!$.0).0+3/%$#B1UH>*;<
1()#@;!$.03.0)DO#B>*A)D0#&%C>*$?^#r!$#&A^#&41#&5.01()#@!$#&%$9)D 1.0)3r1!$.0).0+3%$#B1 (+.0D0#d;41()#&!G%>r-?^#
D0#&<e1/;91b]H'
(.0)5). ,.05)9)D'&D0%$%$.0F)#&!r.0u1(+#@#&+%$#&>?+D0#@.0%C3#&+#&!$41#&5 . 1(5).0#&!$#& 1u!G)5);>
%$>*A+D0.0)3C;<1()#1!$.0).0)3r%$#B1b
.039)!$#`@3. ,+#&%}d%G>*A)D0#;<_(); MO33.0)3/>*.03(1 ;!$tm;@.0>*3.0)!2%$#B1*;<_5)41bKy).0)'&#
MO33.0)3q!$#&%$>*A+D0#&%)1()#1!$.0).0)3w%$#B1 . 1(7!$#&A)D0'&#&>r#& 1P)%G;>*#H.0)%o1)'&#H!$#!$#&A)!$#&%G#& 1#&5>9+D 1.0A)D0#
1.0>*#&% (+.0D0#;41()#&!G%w!G#D0#&<e1*;91bKy);@M33.0+30%1!$.0).0+34EG%$#B1-EGQ/>*.03(1C'&;1.0#B>*A)D0#&%[I)5
1 .0'&#&PH?)91*5);:#&%);41*'&;1.0#&. 1()#&!}#B>*A)D0#C/;!b@w%}/!$#&%$9)D 1P1(+#C'&D0%$%$.0F)#&!O1!G.0)#&5;
1!$.0).0+34EG%$#B1-EGQ7>*.03(1=;?1.0*(+.03()#&!1#&%21-EG%$#B1#&!G!$;!1()q1()#O'&D0%$%G.0F)#&!Z9)%$.0+3wD0D+;<1()#5)41bB
<N'B1P)D0DJ<N;9)!R;<)MO33.0)30%Z'&;>*A^;)#&1'&D0%$%$.0F)#&!$%_'&;9+D05!G#&%$9)D 1.0K().03(+#&!)1#&%21-EG%G#B1=#&!$!$;!$U(); #B,+#&!GP
()#&'&;>?).0)#&5)P+1()#&%$#<;9+!'&D0%$%G.0F)#&!$%q'&gLN)5;<e1#&5);awA)!$;:5)9)'&#1#&%o1-EG%$#B1*#&!$!$;!wD0; #&!1()
1()41K;<1()#}%$.0)3D0#'&D0%$%$.0F)#&!CLe1()#5). ,+#&!$%$. 1>*;)3}1()#&%$#7'&D0%G%$.0F)#&!$%w3#&)#&!$D0D '&;>*A^#&)%G41#&%<N;!
1()#}.0+'&!$#&%$#}.0m#&!G!$;!W!$41#};<R.0+5). ,^.05+9)D'&D0%$%$.0F)#&!Ga-b
MO!$#&.0>*LNQSST'&a/%$(); #&561()41M33.0+3.0%@#&#&'B1. ,+#;49))%21?+D0#&D0#&!$).0+3D03;!$. 1()>r%
()#&!G#/%$>*D0DW'
())3#&%@.01()#K1!$.0+.0)3%$#B1!$#&%G9)D 1.0gD0!$3#'G()+3#&%r.0gA)!G#&5).0'B1.0;)%$bM!G#&.0>*
LNQSST'&a'&D0.0>*#&5d1()41K)#&9)!$Ds)#B1 ;!$t:%)55)#&'&.0%$.0;d1!$#&#&%w!$#7#B>*A)D0#&%q;<_9)+%21?)D0#7D0#&!G).0)3
D03;!$. 1()>r%$b\]#C%219)5/1()##&#&'B1. ,+#&)#&%$%};<ZMO33.0)3/;?^;41(r1()#&%$#KD0#&!$).0)3@>*#B1();:5)%w.0d1().0%
!21.0'&D0#&b
+2K *oqhs

d) q
h2Rj

MO;J;%o1.0)3ILN+!$#&9))5@xy)'
()A).0!$#&PQSSTUy)'
()A).0!$#&PQSS{aO#&)'&;>*A)%$%G#&%<>*.0D ;<>*#B1();:5)%$bcW()#
<N;J'&9)%q;<^1(+#&%$#K>*#B1();:5)%.0%1;IA)!G;J5)9+'&#7Iijf-4-f-i;<Z'&D0%G%$.0F)#&!$%$bCc=()#W1!G.0).0)3@%$#B1*9)%$#&5<;!q#&'
(
>*#&>?^#&!;<1()#C%G#&!$.0#&%}.0%}'
();%$#&6?)%G#&56;I1()#CA^#&!$<N;!$>*)'&#K;<1()#C#&!$D0.0#&!}'&D0%G%$.0F)#&!fiLN%$a7.0I1()#
%$#&!$.0#&%Gb6MO;:;%21.0)3P#B>*A)D0#&%=1()41@!G#r.0)'&;!$!G#&'B1D A)!$#&5).0'B1#&5? ]A+!$#B,^.0;9+%7'&D0%$%$.0F+#&!$%.0m1()#
%$#&!$.0#&%7!$#K'G();%$#&>*;!$#K;<1#&/1()#B^>rA)D0#&%1()41 #&!$#C'&;!$!$#&'B1D gA)!$#&5+.0'B1#&5)brcW(:9)%qMO;J;%o1.0)3
41-1#&>*A1%1;@A)!$;:5)9)'&#}+# '&D0%$%$.0F+#&!$%Z1(+41K!$#?^#B1-1#&!?)D0#=1;@A)!$#&5).0'B1K#B^>*A+D0#&%<N;! ().0'G(r1()#
'&9)!$!G#& 16#&)%$#&>?)D0#&0%/A^#&!$<N;!$>*)'&#.0%/A^;:;!$bLN;41#/1()416.0"M33.0+3Pw1()#!$#&%$>*A)D0.0+3;<W1()#
1!$.0).0+3*%$#B1.0%W+;415)#&A^#&)5)#&1};K1()#}A^#&!$<N;!$>*)'&#;<+1()#}#&!GD0.0#&!='&D0%$%$.0F+#&!$%$b0a
B/1().0% ;!$t #d#B^>*.0+#}1 ;)# +5A^; #&!$<N9)DZ<N;!$>*%7;<MO;:;%21.0)3Iw!$'&.0)3LNMO!$#&.0>r)P
QSST?)am+5"5)4EGMO;:;%21.0)3LN+!$#&9))5"xy)'
()A).0!$#&PQSSTa-b.0t#6MO33.0)3PCw!$'&.0)3'
();J;%G#&%u
1!$.0).0+3d%$#B1*;<Z%G.0&#K<;!q'&D0%$%$.0F+#&!q]QI? A)!$;?)?).0D0.0%o1.0'&D0D %$#&D0#&'B1.0)3L . 1(!G#&A)D0'&#&>*#&1a
#B>*A)D0#&%W<N!$;>1()#;!G.03.0)D1!$.0).0)3C#B>*A)D0#&%$b=)D0.0t#7M33.0+3Ps(); #B,+#&!GP1()#A)!$;?+?).0D0. 1
*

fi

r+su}SmQz
r

vr++z

%$>*A+D0#};<sr%$.0)3D0#}'&D0%$%G.0F)#&!=;m.0>*3.0)!26%$#B1;<s5)41b
L !G.03.0)D0aWcR!$.0).0)3*y+#B1
cR!$.0).0+34EG%$#B1-EGQ
QP`P[PPPTPPX
%$>*A)D0#};<RMO33.0)3@;K1()#%$>*#75)41b
LN#&%$>*A)D0#&5+aWcs!G.0).0)3Cy)#B1
cs!$.0+.0)34EG%$#B1-EGQ
`PPXP[PPTP[PQ
cs!$.0+.0)34EG%$#B1-EG`
PXPPTPP`PPQ
cs!$.0+.0)34EG%$#B1-EG[
[PTP`PPPTP`P`
cs!$.0+.0)34EG%$#B1-EG
PPQPPTPP[PX
%$>*A)D0#7;<sMO;:;%21.0)3r;C1()#}%$>*#5+41b
LN#&%$>*A)D0#&5+aWcs!G.0).0)3Cy)#B1
cs!$.0+.0)34EG%$#B1-EGQ
`PPXP[PPTP[PQ
cs!$.0+.0)34EG%$#B1-EG`
QPPPPQPPTP
cs!$.0+.0)34EG%$#B1-EG[
PQPPXPQPXPQP
cs!$.0+.0)34EG%$#B1-EG
QPQPTPQPQP[PQP
.039)!$#}`7vZA^;41()#B1.0'&Dq!$9))%d;<M33.0+3+5MO;:;%21.0)3b%$%G9)>*#C1(+#&!$#u!$##&.03(1@1!G.0).0)3
#B^>*A+D0#&%$bw%$%$9+>*##B^>*A+D0#Q.0%/4;91D0.0#&!$g)5".0%/()!G5<N;!1()#'&;>*A^;)#&1
D0#&!$).0)3D03;!$. 1()>1;'&D0%$%$.0<e'&;!$!G#&'B1D b6\. 1(gMO33.0)3Pw#&'G(1!$.0+.0)3%$#B1u.0%C
.0)5)#&A^#&)5)#&1%$>rA)D0#u;<O1(+#5)41Uw1(:9)%$P7%$;>*##B^>*A+D0#&%@!G#>*.0%G%$.0)3)5;41(+#&!$%
;J'&'&9)!=>9)D 1.0A+D0#O1.0>*#&%$bWc=()#qM;:;%21.0)3}1!$.0).0)3C%G#B1%=!$#D0%$;r%$>*A)D0#&%W;<+1()#};!G.03.0)D
5)41d%G#B1Ps?)91W1()#@4(+!$5)*#B>*A)D0#/LN#B^>rA)D0#Qa;J'&'&9+!$%>r;!$#7.0D041#&!Z1!G.0).0)3@%$#B1%
%$.0)'&#}MO;:;%21.0)3*'&;)'&#&1!$41#&%q;m'&;!$!G#&'B1D A)!$#&5).0'B1.0)3C. 1b

;<)%$#&D0#&'B1.0+3#B>*A)D0#O.0%);41W#&8:9)DJ'&!G;%$%1()#1!$.0).0)3q%$#B1bOcW().0%RA)!$;?+?).0D0. 1I5)#&A^#&)5)%;K();
;<e1#&I1()41d#B>*A)D0# %}>*.0%$'&D0%G%$.0F)#&5?u1(+#CA)!$#B,.0;9)%7'&D0%$%$.0F)#&!$%Gb/5)4EGMO;:;%21.0)3m'&9)%$#
1()#A)A+!$;'G(C;<_LNa_%$#&D0#&'B1.0)3}%G#B1=;<+#B>*A)D0#&%Z?)%G#&5C;w1()#A)!$;?)?+.0D0. 1.0#&%Z;<1()##B>*A)D0#&%GP);!
LN?)a_%$.0>rA)D I9+%$.0)3qD0D);<J1()##B>*A)D0#&%H+5 #&.03(1H1()##&!G!$;!Z;<#&'G(r#B>*A)D0#=? 1()#A)!$;?+?).0D0. 1
<N;!W1()41/#B>*A)D0#LN.0b0#&b0P=#B^>*A+D0#&% . 1(().03(+#&!7A)!$;?+?).0D0. 1.0#&%K()-,+#@>*;!$#@#&#&'B1/;u1()#d#&!G!$;!$a-b
cW().0%D041-1#&!WA)A+!$;'G(/()%s1()#w'&D0#&!5, 13#1()41q#&'
(m#B>*A)D0#q.0%O.0)'&;!$A^;!$41#&56LN417D0#&%21}.0
A)!21a.01()#1!$.0).0)3%$#B1bW+9)!21()#&!$>r;!$#&P^)!$.0#&5)>*I#B1}D0bLNQSSXa()$,+#5)#&>*;)%o1!$41#&51()41O1().0%
<N;!$>;<^5+4EGM;:;%21.0)3'&r?^#R,.0# #&5@%H}<N;!$>;<^5)5+. 1. ,+#=>*;:5)#&D0.0)3<N;!H;A1.0>r.0&.0)37}D0;3.0%o1.0'
D0;%$%Z<N9))'B1.0;+bBw1().0% ;!$t:P)(); #B,+#&!$P #(+-,+#W'
();%$#&q1;}9+%$#s1()#A)A)!$;'
(*;<%$9)?)%$>rA)D0.0)31()#
5)411;I#&)%$9)!G#@<.0!#&>rA).0!$.0'&D'&;>*A)!$.0%G;LN.0A+!21K5+9)#W1;1()#!$#&%21!o1.0)3I!$#&%$;5).0%$'&9+%$%$#&5
?^#&D0; a-b
MO;41(!G'&.0)3I)5w5)4EGMO;:;%21.0)3I.0). 1.0D0D %G#B11()#A)!$;?+?).0D0. 1;<_A).0'Gt:.0)3I#&'G(#B>*A)D0#=1;
?^#7Q&bCcW()#&%$#>*#B1();:5)%H1()#&!$#&'&D0'&9)D041#w1()#&%G#A+!$;?)?).0D0. 1.0#&%q<e1#&!#&'G(@1!$.0)#&5'&D0%$%G.0F)#&!.0%
5)5)#&51;@1(+#@#&+%$#&>?+D0#&b);!r5)4EGMO;:;%21.0)3PqD0#B1?^#}1()#/%G9)>;<Z1()#IA)!G;?)?).0D0. 1.0#&%*;<H1()#


fi

stv{wz{y{t

>*.0%$'&D0%G%$.0F)#&5/.0)%21+'&#&%<;!s1()#q'&9)!$!G#& 1D *1!G.0)#&5/'&D0%$%$.0F)#&!W:bcW()#wA)!$;?+?).0D0. 1.0#&%<;!s1()#q)#B:1
1!$.0DZ!G#*3#&)#&!$41#&5? >9+D 1.0A)D ^.0+3K1()#CA)!$;?+?).0D0. 1.0#&%7;<OJ0%7.0)'&;!$!$#&'B1D ]'&D0%$%G.0F)#&56.0)%21+'&#&%
?1(+#*<'B1;!=+uLNQ}Ja$+5I1()#&6!$#&+;!$>*D0.0&.0)3D0DHA)!$;?+?).0D0. 1.0#&%7%$;C1()41}1()#&.0!%$9)>
#&8:9)D0%rQb"w5)4EGMO;J;%o1.0)3'&;>?).0)#&%}1()#/'&D0%$%$.0F)#&!G%r $&&&& 9)%$.0)3 #&.03( 1#&5,+;41.0)3 ()#&!$#
()% #&.03(1uD0;3+L +a-bcW()#&%$# #&.03(1%CD0D0; w5)4EGMO;J;%o1.0)3d1;5+.0%$'&;9)171()#@A)!$#&5).0'B1.0;+%;<
'&D0%$%$.0F+#&!$%1()41I!$#*);417,+#&!2g'&'&9)!$41#@;I1()#r;$,+#&!$D0DA)!$;?)D0#&>*bu)!$.0#&5)>*#B1@DLNQSSXaK()$,+#
D0%$;*%G9)33#&%21#&5uuD 1#&!$)41. ,+#>*#&'G()+.0%$>1()417F1%1;3#B1()#&!H1()#A)!$#&5).0'B1.0;+%=;<+1()#}'&D0%$%$.0F+#&!$%
%=u5)5). 1. ,+#}>*;:5)#&D9+%$.0)3K*>*4.0>9+>D0.0t#&D0.0();:;J5'&!$. 1#&!$.0;)b
B1().0% ;!$tJP #9+%$#d1()#!$#B,^.0%G.0;5)#&%$'&!$.0?^#&5?MO!$#&.0>*LNQSST?)a ()#&!$# #!G#&%$#B1D0D
1()# #&.03( 1%C1;?##&8:9)D)5!$#&%21!o1.0<#&. 1()#&!m].0%m+;41D0#&%G%K1()"{b0;!m?^#&'&;>*#&%m{b $
Msg!$#&%$#B1-1.0)3K1(+# #&.03(1% #C5);m+;41r5).0%$5, 13#}1()#Cw5)4EGMO;J;%21.0+3uD0#&!$)#&!7.0I1();%$#*'&%G#&%
()#&!G#w. 17!G#&'G()#&%Z1()#&%$#,D09)#&%;<RJU:1(+#ww5)4EGMO;:;%21.0)3*D0#&!$+#&!WD $^%.0)'&;!$A^;!$41#&%1(+#%$>*#
:9)>?^#&!_;<'&D0%$%$.0F)#&!G%H%Z;41()#&!>*#B1();:5)% #R1#&%21#&5)bcR;}>*t#1(+.0%Z<#&%G.0?)D0#&P #!$#W<N;!$'&#&5q1;79)%$#
1()#CA)A+!$;'G(6;<%$#&D0#&'B1.0)3u/5)41m%$#B1rA)!G;?)?).0D0.0%21.0'&D0D g!$41()#&!1(+ #&.03(1.0)3K1(+#C#B^>*A+D0#&%$P
;41()#&! .0%$#}5)#B1#&!$>r.0).0%21.0'>*#B1();:5*%$9+'G(C%HV=b0 ;9)D05r'B^'&D0#W+5*3#&)#&!$41#W5+9)A)D0.0'&41#W>*#&>?^#&!$%
;<1()#C#&)%$#&>?)D0#&b/cW()41r.0%GPH!$#&%$#B1-1.0+3K1()# #&.03( 1%W1;mQ& ;9)D05'&9+%$#q1()#CD0#&!$+#&!O1;m!$#&A^#&41
1()#65+#&'&.0%$.0;1!$#&#D0#&!$)#&5%*1()#6F)!$%o1>*#&>?^#&!/;<1()#6#&+%$#&>?+D0#&PC)51().0% ;9)D05D0#&5g1;
!$# #&.03( 1.0+3*1()#r5)41u%$#B11()#*%$>r#r%7<N;!1(+#*%$#&'&;)5>*#&>?^#&!;<1(+#r#&)%$#&>?)D0#&P)56%$;;)b
=+5);>*D %$#&D0#&'B1.0+3C#B^>*A+D0#&%<;!R1()#w5)41K%$#B1}?)%$#&5I;1()#w#B>*A)D0#qA)!$;?)?+.0D0. 1.0#&%D0D0#B,^.041#&%
1().0%WA+!$;?)D0#&>*b
w!$'&.0)34Eo6LNM!G#&.0>*)PQSST?)a*L ().0'
( # .0D0Ds!$#&<N#&!H1;d%$.0>rA)D %q!$'&.0+3a%21!o1#&5;91K%q
%$.0>*A+D0#C>*#&'G()+.0%$> <N;!}#B,D09+41.0)3K1()#C#&#&'B1@;<MO;J;%21.0+3m>*#B1();:5)% ()#&!G#w1()#C!$#&%$9)D 1.0+3/'&D0%2E
%$.0F)#&!G% #&!$#u'&;>?).0+#&5 . 1();91 #&.03(1.0)3I1()#,+;41#&%$b!$'&.0+39)%$#&%*%$.0>rA)D0#/>*#&'G(+).0%$><N;!
5)#B1#&!$>r.0).0)3O1()#A)!$;?)?+.0D0. 1.0#&%;<.0)'&D09+5).0)3}#B>*A)D0#&%.01()#_1!$.0).0)3%$#B1b);!1()# 1(d#B^>rA)D0#
.0K1()#1!$.0).0)3*%G#B1P1()#O,D09)
# !$#&<N#&!$%1;1(+#J9)>?^#&!W;<+1.0>*#&%_1()41K#B^>rA)D0# %=>*.0%$'&D0%G%$. E
F)#&5? u1()#A+!$#B,^.0;9+%q'&D0%$%$.0F)#&!$%Gbc=()#7A)!G;?)?).0D0. 1
W<N;!%G#&D0#&'B1.0)3/#B^>rA)D0# 1;I?^#7A+!21K;<
'&D0%$%$.0F+#&!gQ0%_1!G.0).0)3C%$#B1.0%5)#&F))#&5/%





QWm

ff
$

LNQW





LNQa

MO!$#&.0>*'G();%G#1()#},D09)#r;<R1()#*A^; #&!ILNa#&>*A).0!$.0'&D0D <1#&!=1!2.0)3m%$#B,+#&!$D5).0#&!$#&17,D09)#&%
LNMO!$#&.0>*)PQSST?+a-bD 1();9+3(u1(+.0%>*#&'
()).0%$>5);:#&%K);41/()-,+#1()# #&.03(1#&5,+;41.0)3;<Ww5)4E
MO;J;%o1.0)3I. 1K%21.0D0DA)!G;J5)9+'&#&%='&'&9)!$41#K#&)%G#&>?)D0#&%q)5.0%q%$.0>*A)D0#=1;@.0>*A)D0#&>*#&1U1(J9+% #.0+'&D09)5)#
1().0%W>r#B1();J5LND0;)3 . 1(u5)4EGMO;:;%21.0)3a.0m;9)!W#&>*A+.0!$.0'&D#B,D09)41.0;)b
.039)!$#C`/%G(); %7/( A^;41()#B1.0'&DZ!$9);<MO;J;%21.0+3b/;41#q1(+411()#CF)!$%21q1!$.0+.0)3/%$#B1 ;9)D05
?^#w1()#r%G>*#*%7MO33.0)3U=(); #B,+#&!$POD041#&!W1!G.0).0)3m%$#B1%'&'&#&19)41#d#B>*A)D0#&%=1()41 #&!$#d>*.0%2E
'&D0%$%$.0F+#&5g? 1()#I#&!$D0.0#&!*>*#&>?^#&!K;<Z1()#I#&)%G#&>?)D0#&%GbB1().0%CF)39)!$#&P=#B^>*A+D0#/Q.0%C]4(+!$5)
#B>*A)D0#H1()41qA+!$#B,^.0;9+%'&D0%$%G.0F)#&!$%1#&)5}1;>*.0%$'&D0%G%$.0<b_\. 1(1()#w%$#&'&;)571!$.0).0)3%$#B1P#B^>rA)D0#
Q7;:'&'&9)!$%>9)D 1.0A)D0#H1.0>*#&%$P^%5+;7#B>*A)D0#&%O7)5@7%G.0)'&#Z1(+#B #&!$#D0#&<1;91;<:1()#=F+!$%21H1!G.0).0)3
%$#B1+5)P^.0K1().0%W'&%$#&P>*.0%$'&D0%$%$.0F+#&5u?d1()#F+!$%21}D0#&!$)#&!$b=);!_1()#F+)D:1!$.0).0)3C%G#B1P#B^>rA)D0#}Q

fi "! #$%& '(*)+ !$,- .0/213 *4#. 3fi56789 913;:<<=3,->13?@94#A13#BC>+=3=3DE
D;#139GFIHKJLM/KN ( :PORQEST.FU< =3BGC4 WV XYZ; A[,-W1\=3YE$1\?]! #$&$0' ( =313#B C#V^. 3_
/2#>4>a`G=3,-# 13?b_6cd94 913;:d<@!e4@fX$=\BGg>4 h=3! =3V)G?i#jD ?i,-#1\1k>+=\=3DEgD#1\94
/. 3..fi:l# P#Vj94=\V4Bg#@V4 B#=3DE-0.C< =3BG*2#! g/2=3*>4mh9!$ hj13=3BG13?])+$ * 913P#V]4
#13 V4#*#>>#!n k=3V@>4=\13o94h=3 ;:
Zp



fi

r+su}SmQz
r

vr++z

?^#&'&;>*#&%H1()#7A)!G#&5);>*.0)1#B>*A)D0#'G();%$#&gL (+#&!$#&%+;*%$.0)3D0##B^>rA)D0#7.0%w'&'&#& 19+41#&5 . 1(
MO33.0)3a-U1(:9)%$PJ1()#w;-,+#&!$D0D:1#&%o1-EG%$#B17#&!$!$;!<;!s1().0%O'&D0%$%G.0F)#&!O>*.03( 1}?^#&'&;>*#H,+#&!2().03(+bw#&%GA). 1#
1().0%$P(); #B,+#&!GPZMO;J;%21.0+3 .0D0DA)!$;?)?)D ;?1.0@D0; #&!7#&!$!$;!q!$41# ()#&. 1*'&;>?+.0)#&%1()#;91-E
A)91K;<^1()#&%$#<N;9)!q'&D0%$%$.0F)#&!$%q%$.0+'&#. 1C<;:'&9)%$#&%q;'&;!$!$#&'B1D A)!$#&5).0'B1.0+3dA)!G#B,^.0;9)%GD >*.0%$'&D0%$%G.0F)#&5
#B>*A)D0#&%W)5 #&.03( 1%Z1()#qA)!$#&5).0'B1.0;+%;<1()#5).0#&!$#&1}'&D0%$%$.0F)#&!$%=?)%$#&5/;1()#&.0!'&'&9)!G'B<N;!
1()#1!$.0).0+3@%G#B1b*MO91*M;:;%21.0)3/'&D0%$;/;$,+#&!$F1r.0d1()#KA)!$#&%G#&)'&#K;<Z);.0%$#uLN% #K#&>*A).0!$.0'&D0D
%$(); .0my)#&'B1.0;[a-b

+rqts

vuRxw4dhd

hd+l

c/g

<y
l

qhoqh


=#&'&#&1D P^%$#B,+#&!$D91();!$%LNMO!$#&.0>r)P+QSST?)U^)!G.0#&5)>*)PQSSTU|7;()-,.)x\];D0A^#&!21PQSSTU^|};)3
xq.0#B1-1#&!$.0'
()PQSSaK()-,+#dA)!$;A^;%$#&5I1(+#&;!$.0#&%<N;!1(+#r#&#&'B1. ,+#&)#&%$%K;<MO33.0)3+5MO;J;%o1.0)3
?)%$#&5;7#&>*#B1KD0b00%*LNQSS`aw?+.0%A)D09+%,!G.0)'&#5+#&'&;>*A^;%$. 1.0;;<_'&D0%G%$.0F)'&41.0;#&!$!$;!GbwB
1().0%w5)#&'&;>*A^;%$. 1.0; #'&r,^.0# 1()#7#BA^#&'B1#&5#&!G!$;!;<_dD0#&!$).0)3@D03;!$. 1()>;dA)!o1.0'&9)D0!
z;{ $ |:f zo}~ dh z h/+5 z { h)Nh |*if z iGv jfW%W()-,.0)3q1(+!$#&#}'&;>*A^;)#&1%$
Qb}l- {
1#&!$>>*#&%$9)!$.0+3(); '&D0;%G#H1(+#$,+#&!$3#'&D0%$%$.0F)#&!OA)!G;J5)9+'&#&5r?C1()#D0#&!G).0)3D03;4E
!G. 1()> .0D0D?^#1;q1(+#1!$3#B1<N9))'B1.0;)U
`b} { 4 { hdGfW1#&!$> >*#&%$9+!$.0)3(); >9+'G(#&'G(;<R1()#@D0#&!$).0)3D03;!$. 1()>r0%39+#&%$%$#&% .0D0D
,!2 . 1(m!G#&%$A^#&'B11;*#&'G(;41()#&!LN(); ;<e1#&C1()#B5).0%$3!G#&#&a-U)5
[b}1#&!$>>*#&%$9)!$.0+31()#W>*.0).0>9)>'&D0%G%$.0F)'&41.0;@#&!$!$;!Z%$%G;J'&.041#&5 . 1(q1()#=M$+#&%;A1.0>*D
'&D0%G%$.0F)#&!K<;!=1()#}1!$3#B1m<9)+'B1.0;Le1().0%1#&!$> .0%%$;>*#B1.0>*#&%K!$#&<N#&!$!$#&5u1;%=1()#@.0 1!G.0)%$.0'
1!G3#B1);.0%$#&a-b
w%$.0)31().0%_<N!$>*# ;!$t7. 1W()%?^#&#&K%$9)33#&%21#&5LNMO!$#&.0>r)P)QSST?)a1()41=?^;41(KMO33.0)3)5CMO;:;%21-E
.0)3!$#&5)9+'&#@#&!G!$;!K? !$#&5)9)'&.0)3r1()#,!$.0)'&#1#&!$>*b])!$#&9))5)5y)'
()A).0!$#6LNQSSTa*!G39)#1()41
MO;J;%o1.0)3CD0%$;K41-1#&>*A1%R1;C!$#&5+9)'&#Z1(+#w#&!G!$;!O.071(+#?).0%R1#&!G>%G.0)'&#q. 1<N;:'&9)%$#&%O;/>*.0%$'&D0%$%G.0F)#&5
#B>*A)D0#&%$bWy+9)'G(IK<;:'&9)%>*$'&9)%G#1()#qD0#&!$)#&!R1;KA)!$;:5)9)'&#w/#&)%$#&>?)D0#q<9+)'B1.0;1()41}5).0#&!$%
%$.03).0F+'& 1D <!$;>1()#d%$.0)3D0#@D0#&!$).0)3D03;!$. 1()>*bB<N'B1PMO;J;%21.0+3>r-'&;)%o1!$9)'B1/<N9))'BE
1.0;C1(+417.0%=);417#B,+#&A)!$;:5)9)'&.0?)D0#q?. 1%W'&;>rA;+#& 1D0#&!G).0)3CD03;!$. 1()>LN#&b03b0P'
())3.0)3dD0.0)#&!
A)!$#&5+.0'B1.0;)%q.0 1;II'&D0%$%$.0F)#&!1()41*'&;1.0)%);EGD0.0+#&!wA+!$#&5).0'B1.0;)%$a-bK 1K.0%1(+.0%'&A)?+.0D0. 11()41
>*t#&%MO;:;%21.0)3CIA)A)!$;A+!$.041#D03;!G. 1()><;!O'&;>?).0).0)31()#qA)!G#&5).0'B1.0;)%O;< #&tJ*D0#&!G).0)3
D03;!$. 1()>r%LN.0b0#&b0PRD03;!$. 1()>*%Z1()41()$,+#7*%$.0>rA)D0#D0#&!$).0)3r?).0%$a-bWBK1()#&.0!W!G#&'&#& 1KA)A^#&!$PMO9)#&!
)5@|};()$,^._LNQSSSa5)#&>*;)%o1!$41#&51()41qMO;:;%21.0)3K5);:#&%.0+5)#&#&5d%G#&#&>1;K!$#&5+9)'&#=?).0%O<N;!'&#&!o1.0
!$#&D ;!$D05/A)!$;?+D0#&>*%$b;!$#%$9)!$A+!$.0%$.0)3D PJ1()#BD0%$;*%$(); #&51(+417M33.0+3r'&/D0%$;*!G#&5)9)'&#1()#
?).0%WA^;!21.0;u;<+1(+##&!$!$;!$P;<e1#&m<N;!_1()#%G>*#}5)41*%G#B1%=<N;! ().0'
(mMO;J;%21.0+3r!$#&5)9+'&#&%1()#?).0%$b
cW(+;9)3(d1()#K?).0%2Eo,!$.0)'&#C5)#&'&;>*A^;%$. 1.0;.0%q.01#&!$#&%21.0)3P1()#&!$#K!$#K'&#&!21.06D0.0>*. 141.0;+%O1;
A)A)D .0)3/. 1}1;!$#&D E ;!$D055)41u%$#B1%$bucR;m?^#K?)D0#q1;#&%21.0>*41#1(+#*?).0%$P,!$.0+'&#&PH)5I1!G3#B1
);.0%$#7<;!rA)!21.0'&9+D0!=A)!$;?+D0#&>*P #})#&#&5C1;dtJ+; 1(+#}'B19)DR<9)+'B1.0;m?^#&.0)3*D0#&!$)#&5+bcW(+.0%W.0%
9))$,.0D0?+D0#<N;!q>*;%21C!$#&D E ;!$D05A)!$;?)D0#&>r%$bcR;I5)#&D . 1(d1().0%qA)!$;?)D0#&>|};()$,^.)5r\];D0A^#&!21
LNQSSTam%$9+33#&%216();D05).0)3;916%$;>*#;<1()#5)41P=1()#A)A)!$;'
("9)%$#&5? M9+#&!@+5|7;()-,.
LNQSSSa.0@1()#&.0!7%219+5bIcW()#C>*.06A+!$;?)D0#&> . 1(/1().0%O1#&'G(+).08J9+#*.0%O1()41}1(+#w1!$.0).0)3/%$#B1@%$.0&#
.0%w3!$#&41D !$#&5+9)'&#&5u.0;!$5)#&!Z1;d3#B1C3;J;:5#&%21.0>*41#&%;<1()#?).0%+5*,!$.0)'&#=1#&!$>*%$b\]#K()$,+#
'G(+;%$#&K1;K%21!$.0'B1D <;:'&9)%;/3#&)#&!GD0.0&41.0;u'&'&9)!$'B.0/;9)!%219+5P^.0@A+!21}?#&'&9+%$#qM9+#&!W)5
|};()$,^.00% ;!Gtd()%=)% #&!$#&5K1()#}8:9)#&%21.0;u?;91 ()#B1()#&!WMO;:;%21.0)3*+5mMO33.0)3r!$#&5+9)'&#1()#
ff

fi

stv{wz{y{t

?).0%<;!!$#&D ;!GD05A+!$;?)D0#&>*%ILe1()#B?^;41(5+;a-P)5?^#&'&9)%$#71()#&.0!#B^A^#&!$.0>r#& 1%5)#&>*;)%o1!$41#
1()41 ().0D0#O1().0%w5)#&'&;>*A^;%$. 1.0;3. ,+#&%w%$;>*#7.0+%$.03( 1K.0 1;@#&)%$#&>?)D0#>*#B1();:5)%$P. 1K.0%=;)D *%G>*D0D
A)!21=;<1()#W#&8:9)41.0;)bO);!5).0#&!$#& 1w5)41}%$#B1%^1(+#B/;?+%$#&!2,+#'&%$#&% ()#&!$#OMO;:;%21.0)3})5rM33.0+3
?^;41(r5)#&'&!G#&%$#q>*;%21D C1()#H,!G.0)'&#A^;!21.0;d;<1()##&!$!$;!$P)5r;41(+#&!'&%G#&% ()#&!$#WMO;:;%21.0)3K)5
MO33.0)3m?^;41(!$#&5)9)'&#1()#K?).0%q)5@,!$.0)'&#C;<1()#K#&!$!$;!$bCc=()#&.0!1#&%21%D0%$;/%$#&#&>1;/.0+5).0'&41#
1()417MO;:;%21.0)30%W3#&)#&!GD0.0&41.0;#&!$!G;!.0+'&!$#&%$#&%W;1()#q5);>r.0)% ()#&!$#qMO;:;%21.0)3C.0)'&!$#&%G#&%1()#
,!$.0)'&#7A^;!21.0;;<1()#}#&!$!$;!GU?)91P. 1.0%=5).0r'&9)D 1=1;*5+#B1#&!$>*.0)# ()41%$A^#&'B1%;<+1(+#75)41d%$#B1%
D0#&5K1;}1()#&%$#!$#&%$9+D 1%$b

j





c ().0%=%$#&'B1.0;5+#&%$'&!$.0?^#&%W;9)!W#&>rA).0!$.0'&D%o19)5;<RMO33.0)3PRw5)4EGMO;J;%21.0+3Ps)5u!$'&.0+3b=H'
(;<
W
1()#&%$#1()!$#&#>*#B1();:5)% %_1#&%o1#&5 . 1(m?^;41(m5+#&'&.0%$.0;C1!$#&#&%)5/)#&9)!GD)#B1 ;!$t:%$b

q+$

"sgo

cedo*d



cR;r#B,D09)41#1()#7A^#&!$<N;!$>*)'&#7;<_M33.0+3@+5MO;:;%21.0)3P #;?1.0)#&5r:9)>?#&!;<_5)41@%$#B1%
<N!$;>1()#u). ,+#&!G%$. 1;<\.0%$'&;)%$.0'G().0)##&!G).0)36!$#&A^;%$. 1;!o"% #&D0D=%71()#mwVWK5)41
%$#B1*!$#&A^;%$. 1;!2LN9)!$A+( xw()PQSSa-b*cW()#&%$#5)41@%$#B1% #&!$#(+)5%G#&D0#&'B1#&56%$9)'
(*1()41q1()#B
LNaZ'&>*#=<!$;>!G#&D E ;!$D05dA)!$;?)D0#&>r%$PLN?)a,!$.0#&5*.0C'G(+!$'B1#&!$.0%21.0'&%$P^)5uLN'&a #&!$#5+#&#&>*#&5*9)%$#&<N9)D
?A)!G#B,^.0;9)%7!$#&%$#&!$'
()#&!$%$b/cR?)D0#*Q/3. ,+#&%=1()#C'G(+!$'B1#&!$.0%21.0'&%K;<;9)!}5)41m%G#B1%$b/cW()#C5)41u%$#B1%
'G(+;%$#&d,!2'&!G;%$%qr:9)>?^#&!;<Z5).0>*#&)%G.0;)%=.0)'&D09+5).0)31()#=1A#;<^1()#<#&419)!G#&%w.0r1()#5)41
%$#B1]LN.0b0#&b0P7'&;1.0J9+;9)%$P75+.0%$'&!$#B1#&P};!@>r. ;<1()#r1 ;a-Uw1()#:9)>?^#&!r;<};91A+91'&D0%$%G#&%$UC)5
1()#K:9)>?^#&!w;<Z#B>*A)D0#&%.0d1()#K5)41I%$#B1bCcR?)D0#KQ@D0%G;@%G(); %1()#K!$'
(). 1#&'B19)!$#C+5r1!G.0).0)3
A)!$>r#B1#&!$%=9)%G#&5/.0m;9)!W)#&9+!$D)#B1 ;!$t:%=#BA^#&!$.0>*#&1%$b

q+2

goq




8

=#&%G9)D 1%$Pq9))D0#&%$%r;41()#&! .0%$#u);41#&5)Pw!$#m-,+#&!G3#&5;$,+#&!dF,+#m%21)5)!G5gQ{4EG<;D05'&!$;%$%},D0.05+41.0;
#BA#&!G.0>*#& 1%Gb+;!#&'
(dQ{4EG<N;D05I'&!$;%$%,D0.05)41.0;71()#=5+41}%$#B1w.0%F)!$%21=A+!21. 1.0;)#&5@.0 1;Q{7#&8:9)D E
%$.0&#&5%$#B1%GP_1()#&#&'
(g%$#B1m.0%C.019)!$9)%$#&5%w1()#1#&%21u%G#B1 ().0D0#1()#/'&D0%$%$.0F)#&!w1!G.0)%C;1()#
;41()#&!O).0)#w%$#B1%$b+;!#&'G(/<N;D05dI#&)%$#&>?)D0#q;<`'&D0%$%$.0F)#&!G%.0%'&!G#&41#&5)bWVW!$;%G%,D0.05)41.0;/<N;D05)%
#&!$#rA^#&!$<N;!$>*#&56.0+5)#&A^#&)5)#&1D <N;!#&'
(D03;!G. 1()>*b@\]#71!$.0)#&5/1(+#r)#&9)!GDZ)#B1 ;!$t:%9+%$.0)3
%21)5+!$5?+'Gt:A)!$;A)341.0;D0#&!G).0)3"LN=9)>*#&D0(+!21P7vw.0 1;+P7x\.0D0D0.0>*%GPQSXTa-bY!$>r#B1#&!
%$#B1-1.0)3%7<;!1()#K)#&9)!GDs)#B1 ;!GtJ%.0)'&D09+5)#K@D0#&!G).0)3@!$41#C;<H{b0QPZI>*;>r#& 19)>z1#&!$>;<{b0SP
)5 #&.03(1%K!$#@.0). 1.0D0.0&#&5!$)5);>rD 1;?^#r?^#B1 #&#&EG{b0)5{b0bcW()#dJ9+>?^#&!7;<(+.05)5)#&
9)). 1%q)5#&A^;:'G()%q9)%$#&5<N;!1!$.0).0)3I!$#3. ,+#&6.0d1()#K)#B:1K%$#&'B1.0;+b\]#K'G();%G#w1()#KJ9)>?^#&!;<
().05)5+#&d9)+. 1%?)%G#&5@;1()#w:9)>?^#&!;<.0)A)91q)5@;91A)91q9)+. 1%$bOcW().0%O'G();.0'&# %?)%$#&5I;1()#
'&!$. 1#&!$.0;<O()-,.0)341@D0#&%21/;)#r(+.05)5)#&69)+. 1dA^#&!};91A)91P41@D0#&%o1@;)#d().05)5)#&69+). 1d<N;!7#B,+#&!2
1#&/.0)A)91%$P+5/F,+#q().05)5)#&@9)). 1%O?^#&.0)3KK>*.0).0>9)>*bcW()#w:9)>?^#&!;<#&A^;:'G()% %?)%$#&5/?^;41(
;d1()#J9)>?^#&!=;<Z#B>*A)D0#&%q)5d1()#:9)>?^#&!;<ZA)!$>*#B1#&!G%CLN.0b0#&b0P1;A^;D0;34a;<^1()#)#B1 ;!$t:b
y)A^#&'&.0F)'&D0D P #9)%G#&5rT{=1;X{K#&A^;J'
()%<;!%$>*D0DA)!$;?)D0#&>*%.0,+;D ,^.0)3K<N# #&!1()I`{#B^>*A+D0#&%$U
{/#&A^;J'
()%<N;!O1()#K>*.05EG%$.0&#&5A)!$;?)D0#&>*%'&;1.0).0)3u?#B1 #&#&`{K1;/{{m#B>*A)D0#&%$U)5`{1;
{#&A;:'G(+%<N;!D0!G3#&!A)!$;?)D0#&>*%Gb+;!1(+#=5)#&'&.0%$.0;1!$#&#&% #9+%$#&5}1(+#VWb0=1;:;DLN}9+.0)D0)PQSS[a
)5dA)!$9))#&5w1!G#&#&%qL (+.0'G(r#&>rA).0!$.0'&D0D uA)!$;:5)9)'&#?^#B1-1#&!A#&!G<;!$>r)'&#&aZ%%$9)33#&%21#&5@.0r}9+.0)D0)0%
;!$tJb
*

fi

q41ry)#B1
?)!$#&%o1-EG'&)'&#&!2E
'&!$#&5). 1-EG
'&!$#&5). 1-EG3
5).0?^#B1#&%
3D0%$%
()#&!21-EG'&D0#B,+#&D0+5
()#&A)41. 1.0%
();9)%G#BEo,+;41#&%2EGX
(^A^;
.0;);%$A+()#&!$#
.0!$.0%
t:!2Eo,^%oEGtJA
D0?^;!
D0#B1-1#&!
A)!$;>r;41#&!$%2EGS[T
!$.0?^;%$;>*#BEG?+.0)5
%$41#&D0D0. 1#
%$#&3>*#&141.0;
%$.0'

%$;)!
%$;$^?^#&
%$A)D0.0'&#
,+#&().0'&D0#

V=%$#&%
TSS
TS{
Q{{{
TX
`Q
[{[
Q
[
[`
[Q
QS
[QST

`{{{{
S[T
QX
T[
`[Q{
[`
`{X
TX[
[QS{
XT

r+su}SmQz
r

VWD0%$%
`
`
`
`

`
`
`

`
[
`
`
`T
`
`


`
`
QS
[


)#&419)!$#&%
VW;1
q.0%$'

E



Q[

E

E
X


Q[
E
QT

``
[
E

E
E
[T
X
X
QT
E
E

E

[T
E
QS
E

``
T{
E
E
[
E
T{
QX
E

vr++z

B)A)91%


T[
X

Q[
[`
QT

[


`S
QT
``X
QST
[T
QS

T{
Q[
`{
QX

#&9)!GD#B1 ;!Gt
91A)91%
vw.05)5)#&)%
Q

Q
Q{
Q
Q{
Q


Q{
Q

Q
Q{
Q


Q
Q
Q{
[

Q
Q
Q
Q{
`T
{
Q
`{
Q
`{

Q

Q
Q
Q{
Q
Q{
QS
`
`
`

Q{

HA^;J'
()%
`{
[
[{
[{
X{
{
T{
{
{
{
X{
`{
X{
[{
[{
[
[{
`{
{
T{
{
[{
{

cR?)D0#}Q}y)9+>*>*!2r;<1(+#5)41q%$#B1%9)%G#&5.01().0%A)A^#&!$by)(); !$#s1()#:9)>?^#&!R;<)#B>*A)D0#&%.0
1()#w5)41K%$#B1U:1()#w:9)>?^#&!;<;91A)91q'&D0%$%G#&%$U:1()#qJ9+>?^#&!;<'&; 1.0:9);9)%+5d5).0%G'&!$#B1#
.0)A+91<N#&419)!$#&%$U+1()#J9)>?^#&!W;<_.0)A)91P;91A)91P)5().05)5)#&9)). 1%=9+%$#&5.0*1()#7+#&9)!$D
)#B1 ;!GtJ%Z1#&%21#&5)U+5/(); >* #&A^;J'
()%W#&'
()#&9+!$D)#B1 ;!$t %_1!$.0)#&5+b

q+rq

"sgox%

cedo*d





:

cR?)D0#Z`W%$(+; %)1#&%21-EG%$#B1#&!G!$;!!$41#&%s<;!)1()#_5)41=%G#B1%5)#&%$'&!G.0?#&5.07cs?)D0#QW<N;!F,+#Z)#&9+!$D)#B1 ;!$t
>*#B1();:5)%q)5<N;9)!q5)#&'&.0%$.0;@1!$#&#K>*#B1();:5)%$bmLNBcs?)D0#&%I)5 #%G(); 1()#&%$#K#&!$!G;!!$41#&%%
#&D0Ds%1()#%21)5)!G5u5)#B,.041.0;<;!w#&'G(;<^1(+#&%$#W,D09)#&%$b0aD0;+3 . 1(d1()#W1#&%21-EG%$#B1*#&!$!$;!G%<N;!
MO33.0)3P!$'&.0+3PZ)5w5)4EG?^;J;%21.0+3P #C.0+'&D09)5)#1()#w1#&%21-EG%$#B1@#&!$!$;!!$41#*<N;!/%$.0)3D0#C+#&9)!$D E
)#B1 ;!$t)5d%$.0+3D0#5)#&'&.0%G.0;Eo1!$#&#C'&D0%$%$.0F+#&!$bW\]#KD0%$;I!$#&A^;!21K!$#&%$9)D 1%w<N;!w@%$.0>*A+D0#ILN?)%G#&D0.0)#&a
)#&9)!GD EG)#B1 ;!$t@#&)%$#&>?)D0#A)A)!$;'
(Ku'&!$#&41.0)3r/#&)%$#&>?)D0#;<s+#B1 ;!$tJ% ()#&!$#q#&'G()#B1 ;!$t
,!$.0#&%7;)D g?!G)5);>*D .0). 1.0D0.0&.0)3r1()# #&.03( 1%;<s1()#*)#B1 ;!GtJb*\]#r.0)'&D09)5+#w1()#&%$#*!$#&%G9)D 1%
.0/'&#&!21.0'&;>*A)!$.0%$;+%R1;C5)#&>*;)%21!G41#1()#&.0!W%$.0>*.0D0!G. 1I1;CMO33.0)3b +#w;?,.0;9)%W'&;)'&D09)%G.0;
5)!$ <!$;>z1()#!$#&%$9+D 1%w.0%1()41*#&'
(6#&)%$#&>?)D0#>*#B1();:5A+A#&!G%Z1;I!$#&5)9+'&#W1()##&!$!$;!q!$41#K<N;!
D0>*;%21uD0D=;<_1()#/5)41%G#B1%$P=)5.0>*"'&%$#&%q1().0%C!$#&5+9)'B1.0;g.0%CD0!$3#&b<N'B1PH1()#1 ;4E
1.0D0#&5%$.03r1#&%21K.0+5).0'&41#&%1()41#B,+#&!2#&)%$#&>?)D0#7>*#B1(+;J5.0%%$.03+.0F)'& 1D ?#B1-1#&!H1(). 1%%G.0)3D0#


fi

stv{wz{y{t

#&9+!$Dw#B1 ;!$t
q41ry)#B1
?)!$#&%o1-EG'&)'&#&!2E
'&!$#&5). 1-EG
'&!$#&5). 1-EG3
5).0?^#B1#&%
3D0%$%
()#&!21-EG'&D0#B,+#&D0+5
()#&A)41. 1.0%
();9)%G#BEo,+;41#&%2EGX
(^A^;
.0;);%$A+()#&!$#
.0!$.0%
t:!2Eo,^%oEGtJA
D0?^;!
D0#B1-1#&!
A)!$;>r;41#&!$%2EGS[T
!$.0?^;%$;>*#BEG?+.0)5
%$41#&D0D0. 1#
%$#&3>*#&141.0;
%$.0'

%$;)!
%$;$^?^#&
%$A)D0.0'&#
,+#&().0'&D0#

y1
[b0
Qb0X
`b0S
`[b0S
[Xb0T
QXb0T
`{b0Q
b0S
Tb0
Sb0
b0[
`b0[
Tb0Q
QXb0{
b0[
Sb0[
Q[b0{
Tb0T
b0S
QTb0T
Sb0`
b0
`b0S

y).0>rA
[b0
Q[b0
`b0
`[b0{
[b0`
Qb0
QSb0
b0X
Tb0`
b0
[b0S
{b0X
[b0`
Q`b0X
b0X
Xb0
Q{b0S
b0[
b0
Qb0S
Tb0
b0{
`Qb0`

;J;%21.0+3

w!$'
w5)
[b0X
b0{
Qb0X
Qb0
`b0`
`b0[
`b0
`[b0[
[`b0{
[Qb0Q
`{b0
`Qb0Q
QSb0{
QSb0
b0Q
b0[
Tb0`
Tb0`
b0T
Xb0[
[b0
[b0S
{b0
{b0[
[b0`
[b0`
b0
b0T
b0
b0T
Xb0Q
Xb0`
Sb0S
Q{b0{
[b0
[b0[
b0
b0
Q`b0S
Q[b0{
Tb0
Tb0[
b0{
b0`
QSb0Q
QSb0

MO3
[b0
Q[b0X
`b0`
``b0X
[[b0Q
Qb0{
Qb0X
b0Q
Tb0`
Sb0`
b0{
{b0X
b0`
Q{b0
b0{
Xb0
Q{b0T
b0
b0
QTb0X
Tb0S
[b0S
`{b0

V=b0
y1
b0{
Qb0S
`Sb0T
`b0X
[Qb0[
`b0[
`Qb0`
[b0T
{b0
Xb0Q
b0`
{b0T
QTb0
Qb0{
Q`b0X
QQb0`
Q[b0X
[b0
Qb0[
`Sb0
Xb0{
b0S
`Sb0

MO3
[b0
Q[b0
`b0`
`b0
`b0X
QSb0
Qb0[
[b0T
{b0
Tb0
b0S
{b0T
Q[b0
b0{
Q{b0T
Q{b0`
Sb0S
[b0{
Qb0`
`b0[
b0S
b0
`b0Q

;:;%21.0)3

w!$'
w5)
[b0
[b0
Qb0{
Q[b0
`b0S
`Tb0
`Tb0{
`b0
`b0
`[b0[
`Qb0
`{b0X
QTb0S
Qb0`
b0{
b0X
{b0
{b0
Tb0{
Tb0Q
b0Q
b0T
{b0[
{b0
Q[b0{
QQb0T
b0Q
[b0S
Tb0X
Tb0
Sb0[
Sb0T
Xb0T
Xb0
Qb0
Qb0
Qb0Q
Qb0{
`Qb0
`Qb0
b0`
Tb0
b0Q
b0[
``b0
``b0S

cR?)D0#}`}cR#&%21%$#B1=#&!G!$;!Z!$41#&%<;!1()#=5)41%$#B1%H9+%$.0)3*LNQaH%$.0+3D0#W)#&9)!$D)#B1 ;!Gt'&D0%G%$.0F)#&!$U_LN`a
#&)%G#&>?)D0# (+#&!$#K#&'G(6.0)5+. ,^.05)9+Ds)#B1 ;!Gt.0%1!$.0+#&59)%$.0)371()#C;!$.03.0)D1!G.0).0)3
%$#B1*)5@1(:9)%q;)D 5).0#&!G%w<N!$;>1()#K;41()#&!+#B1 ;!$tJ%.0@1(+##&+%$#&>?+D0#?. 1%!G)5);>
.0). 1.0D #&.03( 1%GUKLN[a#&+%$#&>?+D0# (+#&!$#1()#@)#B1 ;!$t:%K!$#71!$.0)#&59)%$.0)3u!$)5);>*D
!$#&%G>*A)D0#&51!$.0).0)3%$#B1%uLNMO33.0)3a-U#&)%G#&>?)D0# (+#&!$#}1(+#@+#B1 ;!$tJ%C!G#71!G.0)#&5
9)%G.0)3 #&.03( 1#&5!G#&%$>*A)D0#&5r1!$.0).0)3@%$#B1%*LNMO;J;%o1.0)3a ()#&!$#W1()#7!$#&%G>*A)D0.0)3@.0%?+%$#&5
;}1()#LNa!$'&.0+37>*#B1();:5*)5LNaHw5)}>*#B1(+;J5)U_LNTaH%$.0)3D0#W5+#&'&.0%$.0;}1!G#&#='&D0%$%$.0F+#&!$U
LNaKuMO33.0)3#&+%$#&>?+D0#d;<5)#&'&.0%G.0;u1!G#&#&%$U=)5"LNXa!$'&.0+3)5"LNSa5)MO;J;%o1.0)3
#&)%G#&>?)D0#&%;<s5+#&'&.0%$.0;C1!$#&#&%Gb

'&;>*A^;)#&1r'&D0%$%$.0F)#&!41}1()#CS'&;)F)5)#&)'&#CD0#B,+#&D0UO(); #B,+#&!GP);+#C;<1()#C#&+%$#&>?+D0#*>*#B1();:5)%
!$#}%G.03).0F)'&1D ?^#B1-1#&!Z1()m;41(+#&!W#&)%$#&>?)D0#}A)A+!$;'G(41W1()#S'&;+F)5)#&)'&#}D0#B,+#&D0b
cR;?^#B1-1#&!)D &#@cR?)D0#@`0%K!$#&%$9)D 1%$PO.039)!$#&%[)5A)D0;411()#rA^#&!$'&#&13#I!$#&5)9)'B1.0;.0
#&!$!$;!O<N;!R1()#w5)4EGMO;:;%21.0)3Pw!$'&.0)3P+5@MO33.0)3C>r#B1();J5I%K<N9))'B1.0;I;<1()#q;!$.03.0+D#&!G!$;!
!$41#&b >*.0).0)371()#&%$#F)39)!$#&% #+;41#W1()41*>*;<^1(+#3.0)%qA)!G;J5)9+'&#&5?/1()##&)%$#&>?)D0#
>*#B1();:5)%@!$#>9)'
(D0!$3#&!1()1()#%o1)5)!$55)#B,.041.0;,D09)#&%GbzB61#&!G>*%I;<}'&;>*A)!$.0%G;)%
;<q5).0#&!$#& 1u>r#B1();J5+%$P. 1.0%*A)A)!$#&1<N!$;>?^;41(gF)39+!$#&%w1()41*1()#uM;:;%21.0)3>*#B1();:5)%LNw5)4E

Z



fi

r+su}SmQz
r

vr++z

kr-vs-kp
letter
segmentation
labor
soybean
satellite
sick
sonar
vehicle
glass
ionosphere
promoters-936
ribosome-bind
iris
splice
credit-g
diabetes
Ada-Boosting
hypo
Arcing
hepatitis

Bagging

credit-a
house-votes-84
heart-cleveland
breast-cancer-w
-40

-20

0

20

40

60

80

100

Percent Reduction Error

.039)!$#}[7=#&5)9)'B1.0;].0#&!$!$;!*<N;!C5+4EGM;:;%21.0)3Pqw!$'&.0)3P)5MO33.0)3)#&9+!$DO)#B1 ;!$t#&E
%$#&>?+D0#&%=%=rA#&!G'&#& 13#;<+1(+#};!$.03.0)D#&!G!$;!W!$41#ILN.0b0#&b0P*!$#&5+9)'B1.0;u<N!$;>m#&!G!$;!
!$41#;<`b01;Qb0` ;9)D05@?#{!G#&5)9)'B1.0;@.0@#&!G!$;!!G41#&P-9)%21q%O!$#&5+9)'B1.0;
<!$;>Q{b0{1;rb0{ ;9)D05uD0%G;r?^#*{!$#&5)9)'B1.0;)a-bD0%G;r%$(); L (+. 1#}A^;!21.0;
;<Z#&'G(?)!$a.0%q;)#%o1)5)!$55)#B,^.041.0;<N;!H1()#&%$#!$#&%$9)D 1%$b7cW()#7%o1)5)!$55)#B,.041.0;
.0%W%$(); m%=u5)5). 1.0;C1;1()##&!$!$;!W!G#&5)9)'B1.0;)b

*

fi

stv{wz{y{t

letter
segmentation
promoters-936
kr-vs-kp
satellite
labor
breast-cancer-w
hypo
sonar
glass
ionosphere
vehicle
sick
hepatitis
soybean
heart-cleveland
ribosome-bind
Ada-Boosting
splice
Arcing
credit-g

Bagging

credit-a
diabetes
iris
house-votes-84
-80

-60

-40

-20

0

20

40

60

80

Percent Reduction Error

.039)!$#}7=#&5)9)'B1.0;K.0#&!$!$;!R<;!Rw5)4EGMO;J;%21.0+3P)!G'&.0)3P)5M33.0+3w5+#&'&.0%$.0;1!$#&#O#&)%$#&>?)D0#&%
%A^#&!$'&#&13#;<1(+#;!$.03.0+D#&!$!G;!!$41#&b=D0%$;%$(); L (). 1#wA;!o1.0;d;<#&'
(/?)!$a
.0%W;)#}%21+5)!$5m5)#B,.041.0;u<N;!1()#&%G#}!$#&%$9)D 1%Gb

Z

*

fi

r+su}SmQz
r

vr++z

MO;J;%o1.0)36)5w!$'&.0)3aC!$#/%$.0>r.0D0!*.01()#&.0!C!$#&%$9+D 1%$P=?^;41(<;!r)#&9)!$DO)#B1 ;!$t:%*)55)#&'&.0%G.0;
1!$#&#&%$b"+9)!21()#&!$>r;!$#&P_1()#/w5)4EGMO;:;%21.0)3+5!$'&.0+3>*#B1();:5)%CA)!$;:5)9)'&#I%$;>*#/;<1()#/D0!G3#&%21
!$#&5)9+'B1.0;)%}.06#&!$!G;!$b I1(+#C;41()#&!7()+5)P ().0D0#w1(+#*MO33.0)3u>*#B1(+;J56'&;+%$.0%21#&1D ]A)!$;:5)9)'&#&%
!$#&5)9+'B1.0;)%=.0#&!$!$;!<;!D0>*;%21CD0D;<1()#'&%$#&%$P . 1(u)#&9+!$D)#B1 ;!GtJ%H1()#7MO;:;%21.0)3@>*#B1();:5)%
'&u%G;>*#B1.0>*#&%=!G#&%$9)D 17.0m.0)'&!$#&%$#}.0u#&!$!$;!$b
s;J;t:.0)3411()#@;!$5)#&!G.0)3u;<R1()#@5)41%$#B1%K.0m1(+#1 ;F)39)!$#&%/Le1()#@!$#&%$9)D 1%!$#@%$;!21#&5?
1()#*A^#&!$'&#&13#@;<!G#&5)9)'B1.0;9+%$.0)3K1()#r5)4EGMO;:;%21.0)3>*#B1();:5)a-P #r+;41#1()41}1(+#r5)41%$#B1%
<N;! ().0'G(u1()#@#&)%$#&>?)D0#I>*#B1();:5)%%G#&#&>1; ;!$t #&D0D!G#@%G;>*# ()41/'&;)%$.0%21#&1m'&!$;%$%C?^;41(
)#&9)!GD)#B1 ;!$t:%q)5u5+#&'&.0%$.0;d1!$#&#&%$b});!1()#<# 5);>*.0+% (+.0'G(%$#&#7.0)'&!G#&%$#&%q.0#&!$!G;!$P. 1C.0%
5).0*'&9+D 11;K!$#&'
(m%21!$;+3'&;+'&D09)%$.0;)%%$.0+'&#H1(+#w#&+%$#&>?+D0#>*#B1();:5)%O%$#&#&>1;C5); #&D0D<N;!KD0!$3#
:9)>?^#&!;<O5);>*.0+%$b )#C5+;>*.0; ().0'G(m1()#CMO;J;%21.0+3u>*#B1();:5)%}5+;/9)).0<N;!$>*D A;:;!$D .0%
1()#q();9)%G#BEo,+;41#&%2EGX*5);>*.0+bW% #5).0%$'&9)%G%D041#&!GP:1()#&!$#q>*-);.0%$#q.01().0%5);>r.0)0%O#B^>*A+D0#&%
1()41'&9+%$#&%_1()#MO;:;%21.0)3d>*#B1();:5)%W%$.03).0F+'& 1A+!$;?)D0#&>*%$b

q+r %R
2hp
H!GD ;!$tLNv+%$#&uxy+D0>*;)PQSS{a;u#&)%$#&>?)D0#&%W%G9)33#&%21#&5r1()41#&)%$#&>?)D0#&% . 1(m%=<N#
%1#&@>*#&>?^#&!$% #&!$#=5)#&8:9)41#Z1;7%$9)r'&.0#& 1D u!$#&5+9)'&#1#&%21-EG%$#B1#&!$!$;!Gb\().0D0#Z1().0%H'&D0.0>>*-u?^#
1!$9)#=<;!1()#=#&!$D0.0#&!A)!$;A^;%$#&5r#&)%$#&>?)D0#&%$P1()#WMO;J;%o1.0)3D0. 1#&!G419)!$#LNy+'G()A).0!G#&P)!G#&9))5)PM!o1D0#B1-1P
x#&#&PQSSa*()%C!$#&'&#&1D "%$9)33#&%21#&5LN?+%$#&5;<# 5)41%G#B1% . 1(5)#&'&.0%$.0;1!$#&#&%Gaw1()41
. 1@.0%A^;%$%$.0?)D0#1;u<N9)!21()#&!}!G#&5)9)'&#1#&%o1-EG%$#B1I#&!G!$;!7#B,+#&<1#&!=1#&>*#&>?^#&!$%()-,+#@?^#&#&65)5)#&5m1;
#&+%$#&>?+D0#LN)5/1(+#B+;41#1()411().0%7!$#&%G9)D 1dD0%$;A)A)D0.0#&%1;uM33.0+3a-bm1().0%7%$#&'B1.0;+P #
A^#&!$<N;!$>5)5+. 1.0;)D#BA^#&!$.0>*#&1%Z1;@<9+!21()#&!=.0,+#&%21.0341#w1()#A)A)!$;A+!$.041#7%$.0&#;<_#&)%$#&>?)D0#&b
.039)!$#du%$(); %=1()#r'&;>*A^;%$. 1#d#&!$!$;!!$41#r;$,+#&!KD0D;<O;9)!5)41u%G#B1%<N;!+#&9)!$DZ)#B1 ;!Gt6)5
5)#&'&.0%$.0;d1!$#&#K#&)%G#&>?)D0#&%q9)%G.0)3r9)Ar1;IQ{{I'&D0%$%$.0F)#&!$%Gb 9+!#BA^#&!$.0>*#&1%.0)5+.0'&41#=1(+41C>r;%21K;<
1()#>*#B1(+;J5)%A+!$;J5+9)'&#q%$.0>*.0D0!$D 6%$()A^#&5I'&9)!2,+#&%GbW%=#B^A^#&'B1#&5)P>9)'
(m;<)1(+#!$#&5)9)'B1.0;m.0/#&!G!$;!
5)9)#1;d5)5).0)3r'&D0%$%$.0F)#&!$%Z1;rm#&+%$#&>?+D0#7'&;>*#&% . 1(K1()#7F)!$%217<N# '&D0%$%G.0F)#&!$%$Us(); #B,+#&!$P+1()#&!$#
.0%W%$;>r#O,!G.041.0; . 1(u!$#&%$A^#&'B11; ()#&!G#1()#}#&!$!$;!=!$#&5)9)'B1.0;mF+)D0D %o^>*A1;41#&%$b
);!?^;41(6MO33.0)3)56MO;J;%o1.0)3A+A)D0.0#&5I1;u+#&9)!$DZ)#B1 ;!GtJ%$P>9)'G(;<1(+#*!$#&5)9)'B1.0;.0
#&!$!$;!A+A#&!G%H1;I()$,+#*;:'&'&9)!$!$#&5<e1#&!1#&@1;/F)<1#&#&'&D0%G%$.0F)#&!$%$bd%$.0>r.0D0!'&;)'&D09)%$.0;'&6?^#
!$#&'
()#&5*<N;!_M33.0+3})5C5)#&'&.0%$.0;1!$#&#&%$P (+.0'G(C.0%_'&;)%$.0%o1#& 1 . 1(CM!G#&.0>*uLNQSSTa-b=MO91=w5)4E
?^;J;%o1.0)3u)5!G'&.0)3'&;1.0:9)#}1;>*#&%$9+!$?)D ].0>*A)!G;-,+#71()#&.0!W1#&%o1-EG%$#B1m#&!$!$;!9) 1.0D!$;9))5`
'&D0%$%$.0F+#&!$%=<N;!W5)#&'&.0%$.0;*1!$#&#&%$bWR1`*'&D0%$%$.0F)#&!G%_1()##&!$!G;!W!$#&5)9)'B1.0;u<;!?;41(/>r#B1();J5+%WA)A^#&!$%
1;()-,+#w)#&!$D u%2>*A1;41#&51;A)D041#&9+bcW()#&!$#&<N;!$#&P1()#=!$#&%G9)D 1%!G#&A;!o1#&5r.071().0%HA)A^#&!!$#;<
@#&)%$#&>?)D0#%G.0&#w;<`ILN.0b0#&b0P%$9)*'&.0#&1+#B1q>*+3#&?)D0#q%$.0&#q<;!8J9+D0. 141. ,+#)D ^%G.0%$a-bW 1 %
1!$5). 1.0;+D0D ?^#&D0.0#B,+#&5LN)!G#&9))5*xy)'G()A+.0!$#&PQSSTa1()41q%$>*D0D+!G#&5)9)'B1.0;)%.0q1#&%21-EG%$#B1}#&!$!$;!H>*-
'&;1.0J9)#.0+5)#&F)). 1#&D d<N;!?^;J;%21.0+3U(); #B,+#&!$P+7!$;-,+#O)5Ky)'
(J9)9+!$>*)%LNQSSXaZ5)#&>*;+%21!$41#1()41
w5)4EG?^;J;%21.0+3'&.0)5)#&#&5?^#&3.0u1;;$,+#&!$F1 . 1
( :f$ uD0!$3#I#&)%$#&>?)D0#I%$.0&#&%mLNQ{P0{{{6;!K>*;!$#
>*#&>?^#&!$%$a-b

q+r



jgdSoqh



c


R:goq


R

w%%$9)33#&%21#&5m?^;$,+#&P. 17A)A^#&!$%R1()41O1()#A^#&!$<N;!$>*)'&#w;<R>* ;<)1(+#w#&+%$#&>?+D0#>*#B1();:5)%!$#
().03()D '&;!$!$#&D041#&5 . 1(;)#C);41()#&!GbdcR;/()#&D0A.05)#&1.0<1()#&%$#C'&;+%$.0%21#&)'&.0#&%$Pcs?+D0#C[/A)!$#&%$#&1%
1()#W'&;!G!$#&D041.0;d'&;:#&*'&.0#&1%;<J1()#=A#&!G<;!$>r)'&#;<^D0D)%$#B,+#&@#&)%$#&>?)D0#W>*#B1();:5)%$b);!#&'G(@5)41
%$#B1PA#&!G<;!$>r)'&#.0%Z>*#&%$9+!$#&5*%1(+#W#&)%$#&>?)D0##&!$!$;!H!$41#=5). ,.05)#&5C?K1()#%$.0)3D0#BEG'&D0%$%G.0F)#&!#&!G!$;!

Z

*

fi

stv{wz{y{t

0.18

DT-Ada
DT-Arc
DT-Bag
NN-Ada
NN-Arc
NN-Bag

Composite Error Rate

0.16

0.14

0.12

0.10
0

10

20

30

40

50

60

70

80

90

100

Number Networks Ensemble

.039)!$#}7Z,+#&!$3#@1#&%o1-EG%$#B1#&!$!$;!I;-,+#&!/D0Dq`[5)41%$#B1%I9)%$#&5.0;9)!I%219)5).0#&%I<N;!I#&)%$#&>?)D0#&%
.0)'&;!$A^;!$41.0)3@<!G;>;+#=1;@Q{{/5)#&'&.0%$.0;@1!G#&#&%w;!q)#&9+!$Ds+#B1 ;!$tJ%GbCcW()#7#&!G!$;!q!$41#
3!$A)()#&5}.0%s%$.0>*A)D q1()#H-,+#&!$3#;<fi1()#H#&!$!G;!!$41#&%R;<1(+#Z`[=5)41=%$#B1%$bcW()#ZD 1#&!$+41. ,+#
;<_-,+#&!$3.0)31(+#7#&!$!$;!w;-,+#&!qD0DR5)41@A;.01%CLN.0b0#&b0P #&.03(1.0)3Ir5)41@%$#B10%q#&!$!$;!!$41#
? . 1%=%$>rA)D0#}%$.0&#&aWA+!$;J5+9)'&#&%%$.0>*.0D0!$D 6%$(+A#&5/'&9+!2,+#&%$b

!$41#&b}c=(J9)%=r().03('&;!$!$#&D041.0;gLN.0b0#&b0P;)#7+#&!=Qb0{aq%$9)33#&%21%H1()411 ;d>*#B1(+;J5)%!$#'&;)%$.0%21#&1
.0K1()#75);>*.0)%W.0 ().0'G(C1()#B(+-,+#1(+#}3!$#&41#&%21K.0>*A)'B1;K1#&%o1-EG%$#B1#&!$!G;!W!$#&5)9)'B1.0;+b
cR?)D0#m[6A+!$;-,.05)#&%r:9)>*#&!G;9)%*.01#&!$#&%21.0)3.0)%$.03(1%$bcW()#uF)!$%21m.0%1(+41*1()#m)#&9+!$D EG)#B1 ;!$t
#&)%$#&>?)D0#>*#B1(+;J5)%=!$#%21!$;)3D '&;!$!$#&D041#&5 . 1(/;)#+;41()#&!W)5K1(+#5)#&'&.0%$.0;Eo1!$#&#7#&)%$#&>?)D0#
>*#B1();:5)%*!G#m%21!$;)3D "'&;!$!$#&D041#&5 . 1(g;+#m);41()#&!$U7(); #B,+#&!$P1()#&!$#m.0%rD0#&%$%r'&;!$!G#&D041.0;?^#BE
1 #&#&)#&9)!$D EG)#B1 ;!Gt#&+%$#&>?+D0#C>*#B1();:5)5 5)#&'&.0%$.0;Eo1!$#&#r#&)%G#&>?)D0#C>r#B1();J5+bdw;41
%$9)!GA)!$.0%$.0)3D P5+4EG?;:;%21.0)3)5@!G'&.0)3!G#%21!G;)3D '&;!$!$#&D041#&5+P#B,+#&@'&!G;%$%5).0#&!$#& 1'&;>*A^;4E
)#&1D0#&!$+.0)3rD03;!$. 1(+>*%$bcW().0%=%$9)33#&%21%H1()41MO;:;%21.0)30%q#&#&'B1. ,+#&)#&%$%5)#&A^#&)5)%=>*;!$#};r1()#
5)41%$#B11() ()#B1()#&!1(+#d'&;>*A^;)#&1@D0#&!G).0)3D03;!$. 1()>.0%)#&9)!GDH)#B1 ;!$t;!5)#&'&.0%G.0;
1!$#&#&bdM33.0+3m;@1()#K;41()#&!}()+5)P.0%);41*'&;!$!$#&D041#&5'&!G;%$%'&;>*A^;)#&1CD0#&!G).0)3/D03;!$. 1()>r%$b
cW()#&%G#W!$#&%$9)D 1%!$#='&;+%$.0%21#&1 . 1(d;9)!HD041#&!'&D0.0>1(+41 ().0D0#=M;:;%21.0)3.0%HA^; #&!$<9+D#&)%$#&>?)D0#
>*#B1();:5)P. 1.0%=>*;!$#}%$9+%$'&#&A1.0?)D0#O1;rC);.0%265)41*%$#B1=1()mMO33.0)3b

Z

*

fi

y).0>*A+D0#BEG
MO33.0)34EGw
w!$'&.0)34EGw
w5)4EG
MO33.0)34EGqc
w!$'&.0)34EGqc
w5)4EGqc

y).0>rA)D0#
Qb0{{
{b0XX
{b0X
{b0X
EG{b0Q{
{b0[X
{b0[

r+su}SmQz
r

w#&9)!$Dw#B1 ;!$t
MO33.0)3
!$'&.0)3
w
{b0XX
{ b0X

Qb0{{
{ b0X

{b0X
Q b0{{

{b0X
{ b0SS

EG{b0QQ
{ b0Q

{b0[
{ b0TQ

{b0[
{ b0T{


vr++z

5)
{b0X
{b0X
{b0SS
Qb0{{
{b0Q
{b0T`
{b0T[

MO33.0)3
EG{b0Q{
EG{b0QQ
{b0Q
{b0Q
Qb0{{
{b0TX
{b0TS

w#&'&.0%G.0;cR!$#&#
!$'&.0+3
{b0[X
{b0[
{b0TQ
{b0T`
{b0TX
Qb0{{
{b0ST

w5)
{b0[
{b0[
{b0T{
{b0T[
{b0TS
{b0ST
Qb0{{

cR?)D0#}[}Y#&!$<N;!$>*)'&#'&;!$!$#&D041.0;'&;J#&*'&.0#&1%/'&!$;%$%I#&)%G#&>?)D0#D0#&!$+.0)3>r#B1();J5+%$bY#&!$<N;!2E
>*+'&#.0%>*#&%$9)!G#&5r?C1()#=!$41.0;K;<:1()##&)%$#&>?)D0#w>*#B1();:5)0%1#&%21-EG%G#B1#&!G!$;!5+. ,^.05)#&5d?
1()#7%$.0)3D0#}'&;>*A^;)#&17'&D0%$%$.0F+#&!$0%_1#&%21-EG%G#B1K#&!$!G;!$b

q+r

Gusnh

d)ShsGf+gj

l2

R


sgo

2:

.039)!$#T6%$(); %1()#uM33.0+3)5y).0>*A)D0#u)#B1 ;!$t#&)%$#&>?)D0#m!G#&%$9)D 1%r<N!$;>cs?)D0#`bc=()#&%$#
!$#&%$9+D 1%*.0)5).0'&41#*1()41u;<1#&6y).0>*A+D0#/H)%$#&>?)D0#/A)A+!$;'G( .0D0DWA)!$;:5)9)'&#I!$#&%G9)D 1%q1()41!G#m%
'&'&9)!$41#@%M33.0+3LN'&;!$!G#&D041.0;!$#&%$9)D 1%<!$;>cs?+D0#r[uD0%G;u%$9)A+A;!o11().0%7%2141#&>r#& 1a-bcW().0%
%$9)33#&%o1%1(+41q>*#&'
()).0%$> ().0'
(d'&9)%G#&%D0#&!$).0+37>*#B1();:571;A)!G;J5)9+'&#W%$;>*#w!$)5);>r)#&%$%
.0d1()#<;!$>r41.0;;<H. 1%q'&D0%$%$.0F)#&!G%'&?#9)%$#&5d1;I<;!G>'&'&9)!G41#C#&)%$#&>?)D0#&%$P_)5.0)5)#&#&5+PswD0.
)5mY&&).OLNQSSTa(+-,+#}5)#&>r;)%21!$41#&5%$.0>*.0D0!=!G#&%$9)D 1%W<N;!W!$)5+;>*.0&#&5m5)#&'&.0%$.0;*1!$#&#&%$b

q+rt udS 4f+gfiGuRc/gh2qh




jJ:

w);41()#&!W.01#&!$#&%21.0)3d8J9+#&%21.0;u.0%W(+; #&#&'B1. ,+#W1(+#}5).0#&!$#& 1>*#B1();:5)%!$#}<N;!W)#&9)!GD)#B1 ;!$t:%
)5*5+#&'&.0%$.0;}1!G#&#&%$b.039)!$#&%HP+XP+)5*S'&;>*A)!$#_1()#W#&!$!$;!!$41#&%H+5r!$#&5)9+'B1.0;*.0r#&!$!G;!,D09)#&%
<N;!w5)4EGMO;J;%o1.0)3P!$'&.0+3PR+5uMO33.0)3I!$#&%$A^#&'B1. ,+#&D b;41#=1()41 #3!$A)(#&!$!$;!w!$41#!G41()#&!
1()*A^#&!$'&#&1=!$#&5)9+'B1.0;*.0*#&!$!$;!H!$41#W?^#&'&9)%$#R1()#?+%$#&D0.0)#W<N;!Z#&'G(d>*#B1();:5uLN5)#&'&.0%$.0;}1!$#&#&%H<N;!
w5)4EGMO;J;%21.0+3;5)#&'&.0%$.0;1!G#&#&%),+#&!$%G9)%)#&9)!GD)#B1 ;!$t:%s<N;!w5)4EGMO;:;%21.0)3=;)#&9)!$D)#B1 ;!$t:%$a
>*$A)!21.0D0D #BA)D0.0C1(+#75).0#&!$#&)'&#&%w.0uA^#&!$'&#&1!$#&5)9+'B1.0;)bq);!#B>*A)D0#&PR.0C1(+#7A)!$;>r;41#&!$%2E
S[TmA)!G;?)D0#&>9)%$.0)3/w5)4EGMO;:;%21.0)3P1()#C>9+'G(6D0!$3#&!7!$#&5)9)'B1.0;6.0#&!$!$;!<N;!O1()#C5)#&'&.0%$.0;/1!$#&#
A)A)!G;'G(>*-6?^#}5)9)#1;1()#}<N'B1=1(+415)#&'&.0%$.0;r1!$#&#&%w5);*);41%$#&#&>1;d?^#}%=#&#&'B1. ,+#K<;!Z1().0%
A)!$;?+D0#&>*P_)5w5)4EGMO;J;%21.0+3K1()#&!$#&<N;!$#CA)!$;:5)9)'&#&%q/D0!$3#&!7A#&!G'&#& 1*!$#&5)9+'B1.0;.0I1()#K#&!$!$;!<N;!
5)#&'&.0%$.0;*1!$#&#&%$b
cW(+#!$#&%G9)D 1%I%$(); 1(+41.0>*'&%G#&%/.0<}%$.0)3D0#5)#&'&.0%$.0;1!$#&#(+5D0; #&!LN;!/(+.03()#&!$a
#&!$!$;!H1()d%$.0+3D0#7)#&9)!GD)#B1 ;!$tu;d5)41d%G#B1P)1()#&*1()#5)#&'&.0%$.0;Eo1!$#&##&)%$#&>?)D0#>*#B1();:5)%
D0%$;@()5D0; #&!CLN;!q().03(+#&!$a=#&!$!G;!Z1()r1()#&.0!w)#&9)!$Ds)#B1 ;!$tm'&;9+ 1#&!$A+!21b7cW(+#7#B'&#&A1.0;)%1;
1().0%*!G9)D0#/3#&)#&!$D0D ()A)A^#&)#&5;1(+#/%$>*#/5)416%G#B1<;!CD0D_1()!$#&#/#&)%$#&>?)D0#m>r#B1();J5+%uLN#&b03b0P
()#&A)41. 1.0%GPZ%$;-?^#&)P%$41#&D0D0. 1#&P'&!$#&5). 1-EGP_)5()#&!21-EG'&D0#B,+#&D0+5)a-bdc=()#&%$#K!$#&%$9)D 1%q%$9+33#&%211()41LNa
1()#A#&!G<;!$>r)'&#};<1()##&)%$#&>?)D0#>r#B1();J5+%=.0%w5)#&A^#&)5)#&17;?^;41(C1(+#75)41@%$#B1+5u'&D0%$%$.0F+#&!
>*#B1();:5)P)5]LN?)aq#&)%G#&>?)D0#&%'&+P_41rD0#&%21r.0%$;>*#K'&%$#&%$PH;-,+#&!$'&;>*#1()#K.0)5)9)'B1. ,+#C?).0%q;<. 1%
'&;>*A^;)#&1D0#&!$).0+3CD03;!$. 1()>*b

Z


fi

stv{wz{y{t

kr-vs-kp
letter
labor
soybean
promoters-936
segmentation
satellite
splice
vehicle
house-votes-84
glass
credit-g
hepatitis
ribosome-bind
heart-cleveland
iris
credit-a
Bagging

ionosphere

Simple
diabetes
hypo
sick
breast-cancer-w
sonar
-20

0

20

40

60

80

Percent Reduction Error

.039)!$#}T7=#&5)9)'B1.0;.0#&!G!$;!7<N;!7MO33.0)3)5y+.0>*A)D0#*)#&9+!$DZ)#B1 ;!$t#&+%$#&>?+D0#&%%uA^#&!2E
'&#& 13#K;<1()#;!$.03.0)D#&!G!$;!=!$41#&b7D0%$;d%$(); L (+. 1#7A^;!21.0;u;<_#&'
(?)!$aW.0%w;)#
%21)5)!$5u5)#B,^.041.0;<;!_1()#&%$#}!$#&%G9)D 1%$b

ZZp


fi

r+su}SmQz
r

vr++z

kr-vs-kp
letter
segmentation
labor
soybean
satellite
sick
sonar
vehicle
glass
ionosphere
promoters-936
ribosome-bind
iris
splice
credit-g
diabetes
Neural Network

hypo

Decision Tree
hepatitis
credit-a
house-votes-84
heart-cleveland
breast-cancer-w
0

10

20

30

40

Error (%)

.039)!$#}7H!$!$;!=!$41#&%<N;!=w5)4EGMO;:;%21.0)3@#&)%$#&>?)D0#&%$bqcW()# (+. 1#7A^;!21.0;u%G(); %Z1()#}!$#&5+9)'B1.0;
.06#&!$!$;!;<5+4EGM;:;%21.0)3'&;>*A)!$#&5/1;//%$.0)3D0#*'&D0%$%G.0F)#&! ().0D0#C.0+'&!$#&%$#&%7.0#&!G!$;!
!$#%$(); *.0C?)D0'
tJbcW(+#5)41}%$#B1%Z!G#%$;!21#&5r?71(+#W!$41.0;};<!$#&5)9)'B1.0;r.0C#&)%$#&>?)D0#
#&!$!$;!1;*;$,+#&!$D0DR#&!$!$;!W<N;!W)#&9)!GD)#B1 ;!$t:%$b

Zff


fi

stv{wz{y{t

kr-vs-kp
letter
labor
segmentation
soybean
satellite
vehicle
sonar
ionosphere
sick
glass
promoters-936
iris
splice
ribosome-bind
credit-g
hepatitis
Neural Network

hypo

Decision Tree
diabetes
house-votes-84
credit-a
heart-cleveland
breast-cancer-w
0

10

20

30

40

Error (%)

.039)!$#}X7H!$!$;!!$41#&%O<;!!G'&.0)37#&)%G#&>?)D0#&%GbcW()# (). 1#=A^;!21.0;d%$(); %1()#!$#&5)9)'B1.0;@.0r#&!G!$;!
;<w!$'&.0)36'&;>rA)!$#&51;6%$.0)3D0#m'&D0%$%G.0F)#&! (+.0D0#/.0)'&!$#&%$#&%d.0g#&!$!$;!*!G#m%$(); .0
?)D0'Gt:bcW()#d5)41%$#B1%K!$#I%$;!21#&5? 1()#d!G41.0;;<=!$#&5)9)'B1.0;.0#&)%$#&>?)D0#I#&!$!$;!=1;
;-,+#&!$D0DR#&!$!$;!W<N;!W)#&9+!$D)#B1 ;!$t:%$b

Z

*

fi

r+su}SmQz
r

vr++z

kr-vs-kp
letter
labor
soybean
promoters-936
segmentation
satellite
splice
vehicle
house-votes-84
glass
credit-g
hepatitis
ribosome-bind
heart-cleveland
iris
credit-a
Neural Network

ionosphere

Decision Tree
diabetes
hypo
sick
breast-cancer-w
sonar
0

10

20

30

40

Error (%)

.039)!$#}S7H!$!$;!C!G41#&%r<N;!*MO33.0)3#&)%G#&>?)D0#&%Gb"cW()# (). 1#/A^;!21.0;]%$(); %q1()#/!$#&5)9+'B1.0;g.0
#&!$!$;!;<M33.0+3'&;>rA)!$#&51;7%G.0)3D0#'&D0%G%$.0F)#&! ().0D0#W.0+'&!$#&%$#&%O.0d#&!G!$;!H!$#w%$();
.0u?)D0'
tJbcW(+#}5)41r%G#B1%=!$#%$;!21#&5u?/1()#}!G41.0;d;<!$#&5)9+'B1.0;u.0u#&+%$#&>?+D0#7#&!$!$;!Z1;
;-,+#&!$D0DR#&!$!$;!W<N;!W)#&9+!$D)#B1 ;!$t:%$b

Z


fi

q+rK

*oqhsGdi



h2

stv{wz{y{t



)!$#&9+)5g)5gy+()A).0!$#6LNQSSTa@%$9)33#&%21#&561()41r1()#/%G;>*#B1.0>*#&%@A;:;!CA^#&!$<N;!$>*)'&#/;<qMO;J;%o1.0)3
!$#&%$9+D 1%}<!G;> ;-,+#&!$F1-1.0)3C1()#1!$.0).0)3/%$#B1@%$.0)'&#*D041#&!W1!$.0).0)3m%G#B1%}>*-g?^#C;-,+#&!oEG#&>*A)()%$.0&.0+3
#B>*A)D0#&%w1()41m!$#@);.0%$#6Le1(:9)%K'&!$#&41.0)3#BJ1!G#&>*#&D A^;:;!'&D0%G%$.0F)#&!$%$a-bc=().0%!G39)>*#&1/%G#&#&>*%
#&%$A^#&'&.0D0D A^#&!21.0+#& 1@1;M;:;%21.0)3<N;!1 ;!$#&%$;)%$bcW(+#F)!G%21)5>*;%o1;?,^.0;9+%/!$#&%$;.0%
1()41W1(+#&.0!W>*#B1();:5m<N;!W9)A^5)41.0)31()#A)!G;?)?).0D0. 1.0#&%=>r-6?^#;-,+#&!2EG#&>*A+()%$.0&.0)3d);.0%2#B^>*A+D0#&%$b
cW()#u%$#&'&;)5!$#&%$;.0%}1()41d1()#u'&D0%G%$.0F)#&!$%@!$#u'&;>?).0)#&59)%$.0+3 #&.03( 1#&5,+;41.0)3bY!$#B,.0;9)%
;!$tLNy);D0D0.0'
(@x|}!$;3(+PQSSTa()%%$(); 71()41q;A1.0>*.0&.0)3=1()#'&;>?).0).0+3 #&.03( 1%'&@D0#&51;
;-,+#&!GF1-1.0)3 ().0D0#Wd9) #&.03(1#&5,+;41.0)3%$'G(+#&>*#=.0%3#&)#&!$D0D u!$#&%$.0D0.0#&1H1;;-,+#&!$F1-1.0)3bW)!$.0#&5+>*
#B1D0b@LNQSSXaw(A;41(+#&%$.0&#1()41CMO;J;%o1.0)3d>r#B1();J5+%$P%w5)5). 1. ,+#>*;J5+#&D0%$P>*$%$#&#.0)'&!$#&%$#&%w.0
#&!$!$;!.01(+;%$#q%$. 19)41.0;)% ()#&!$#1()#?).0%;<)1()#?)%$#q'&D0%$%$.0F+#&!W.0%A)A)!$;A+!$.041#q<;!R1()#A+!$;?)D0#&>
?^#&.0)37D0#&!G)#&5)bR\]#H1#&%21O1().0%(A;41(+#&%$.0%.0@;9)!%$#&'&;)5@%$#B1;<!$#&%$9)D 1%A)!$#&%G#& 1#&5@.0}1(+.0%%G#&'B1.0;)b
cR;q#B,D09)41#_1()#O( A^;41()#&%$.0%1()41WMO;J;%o1.0)3>*-/?^#A+!$;)#1;;-,+#&!$F1-1.0+3 #A^#&!$<N;!$>*#&5q%$#B1
;<#B^A^#&!$.0>r#& 1%9)%$.0)3q1(+#}<;9+!=#&)%$#&>?)D0#}+#&9)!$D)#B1 ;!Gt/>*#B1();:5)%$b_\]#.01!$;J5+9)'&#&5m*PsQ{*P
`{*P)56[{ );.0%$#GK.01;u<N;9)!}5).0#&!$#&1d5)41%$#B1%$buR1I#&'G(D0#B,+#&D #r'&!$#&41#&5F,+#*5).0#&!$#&1
);.0%25)41m%G#B1%$PHA^#&!$<N;!$>*#&5mQ{4EG<N;D05'&!G;%$%,D0.05)41.0;;#&'G()P1()#&6$,+#&!$3#&5;-,+#&!1(+#*F,+#
!$#&%$9+D 1%$b/.039)!G#}Q{ #%G(); 1(+#!$#&5)9)'B1.0;m.0/#&!G!$;!W!$41#<N;!W#&'G(u;<)1()##&+%$#&>?+D0#}>*#B1();:5)%
'&;>*A)!G#&51;9)%$.0)3%G.0)3D0#/)#&9)!$D+#B1 ;!$t'&D0%G%$.0F)#&!$b"cW(+#&%$#I!$#&%$9)D 1%*5+#&>*;)%21!$41#1(+41%
1()#}+;.0%$#}D0#B,+#&D3!G; %$P)1()#}#&*'&'B;<+1()#}y+.0>*A)D0#})5uM33.0+3r#&)%$#&>?)D0#&%3#&)#&!$D0D .0)'&!$#&%G#&%
().0D0#w1(+#C!$'&.0+3/)55+4EGM;:;%21.0)3u#&)%$#&>?)D0#&%}3.0)%}.0A#&!G<;!$>r)'&#K!$#C>9+'G(%$>*D0D0#&!ILN;!
>*$'B19)D0D 5)#&'&!$#&%$#&a-b;41#@1(+41@1(+.0%@#&#&'B1.0%/>*;!$##B:1!$#&>*#<N;!@w5)4EGMO;:;%21.0)3 ().0'
(
%$9)A+A;!o1%;9)!}(^A^;41()#&%$.0%1()41dw5)4EGMO;J;%21.0+3u.0%7>r;!$#C#&'B1#&5?+;.0%$#&bmcW().0%7%$9)33#&%21%W1()41
MO;J;%o1.0)30%A^;J;!A^#&!$<;!G>*)'&#w<;!'&#&!21.0/5)41K%$#B1%O>*$?^#=A)!o1.0D0D #BA)D0.0)#&5I? ;-,+#&!$F1-1.0+3
);.0%$#&b
cR;q<9)!o1()#&!s5+#&>*;)%21!$41#s1()#O#&#&'B1=;<));.0%$#O;KMO;J;%o1.0)3 #O'&!$#&41#&5C%G#B,+#&!$D%$#B1%_;<)!21.0F+'&.0D
5)41%$A^#&'&.0F)'&D0D 5)#&%$.03)#&51;>*.0%GD0#&5gMO;J;%21.0+3>*#B1();:5)%$b);!C#&'
(g5)41%$#B1 #/'&!$#&41#&5g
%$.0>*A+D0#=(^A^#&!$A)D0+#='&;)'&#&A1?)%$#&5@;@%$#B1;<:1()#w<#&419+!$#&%qLN+5dD0%$;.0)'&D09)5+#&5d%$;>r#.0!$!G#&D0#B,1
<N#&419)!$#&%$a-b%$#B1I;<!$)5);> A^;.0 1% #&!$#71()#&3#&)#&!$41#&5g+5D0?^#&D0#&5?)%$#&5; ().0'
(%$.05)#
;<H1()#/( A^#&!$A)D0)#1(+#B<N#&D0D0b"cW()#&6'&#&!o1.0gA^#&!$'&#& 13#;<Z1(+#/A;.01%*;g;+#m%$.05)#/;<H1()#
(^A^#&!$A)D0+# #&!G#d>*.0%GD0?#&D0#&5%K?^#&.0)3mA)!21I;<1()#d;41()#&!'&D0%G%$b);!1()#d#B^A^#&!$.0>r#& 1%K%$();
?^#&D0; #}3#&)#&!G41#&5uF,+#}5+41*%$#B1% ()#&!$#1()#}'&;)'&#&A1 %=?)%$#&5m;*1 ;*D0.0)#&!=<N#&419)!$#&%GP()5
<N;9)!W.0!$!$#&D0#B,1<N#&419)!$#&%$Ps)5m`{;<1()#75)41 %=>*.0%GD0?#&D0#&5+b_\]#=1!$.0)#&5mF,+##&)%$#&>?)D0#&%=;<
)#&9)!GDZ)#B1 ;!$t:%ILNA^#&!$'&#&A1!$;)%$a}<N;!7#&'
(5+41u%$#B1I)5$,+#&!$3#&51()#r#&)%G#&>?)D0#&%GHA)!$#&5+.0'B1.0;)%$b
cW(:9)%s1()#&%$##BA^#&!$.0>*#&1%.0 ,+;D ,+#}D0#&!G).0)3C.0/%$. 19)41.0;+% ()#&!$#H1()#;!$.03.0+D?).0%;<1()#D0#&!G)#&!
LN%$.0)3D0#( A^#&!$A)D0)#uA)!$;:5)9)'&#&5]?A^#&!$'&#&A1!$;)ad.0%IA)A)!$;A)!G.041#u<N;!71(+#uA)!$;?+D0#&>*P})5%
)!$.0#&5+>*I#B1D0bLNQSSXa%$9)33#&%21P9)%G.0)37I5)5). 1. ,+#q>*;:5)#&D>*-()!$>A^#&!$<;!G>*)'&#&b.039)!$#wQQ
%$(); %1(+#r!$#&%$9+D 1.0)3u#&!$!G;!7!$41#&%K<N;!7w5)4EGMO;J;%21.0+3P!$'&.0+3P+5MO33.0)3? 1()#dJ9+>?^#&!7;<
)#B1 ;!$t:%H?^#&.0)3q'&;>?).0)#&5*.0w1(+##&)%$#&>?)D0#&bcW()#&%$#O!$#&%G9)D 1%Z.0)5).0'&41#='&D0#&!$D K1()41=.0*'&%$#&% ()#&!$#
1()#&!$#.0%q);.0%$#7MO33.0)30%7#&!$!$;!=!G41# .0D0DR);41K.0)'&!$#&%$#%1()#7#&)%G#&>?)D0#%$.0&#.0)'&!$#&%$#&% (+#&!$#&%
1()##&!$!$;!@!$41#;<1(+#uMO;J;%o1.0)3>r#B1();J5+%r>*$.0)5)#&#&5.0)'&!$#&%$#%I#&)%$#&>?)D0#u%$.0&#.0)'&!$#&%G#&%$b

5 6V=\*=3V4h=3! #$&#&$#!ng2$#94#=3V4=\V4B- `G#,>13 ;Fm)+A=\V4>94l#V4hg94>94l2 #9 ;Fm#h0-6
!n#V4! [8)+ =3VBA#Vh4,-13?@>+$9)+ hW#V4$%2 #9CD#1\94C%4#d2 #9U/2%!$VG=3VZ9494%2 #9 ;F
k>+=\)413[ kD;#139$&X#o!n$V@)G?A$`Z#,-=3V=3VB#131I%#=3V=3VB-$`Z#,->13 ;:
ZZ


fi

diabetes

4

Reduction error rate (% pts)

r+su}SmQz
r

soybean-large

9

3
6
2
3
1

0

Bagging Ensemble
Boosting (Arcing) Ensemble
Boosting (Ada) Ensemble

0
0

5

10

15

20

25

30

0

promoters-936

4

Reduction error rate (% pts)

vr++z

5

3

2

2

1

1

0

15

20

25

30

25

30

segmentation

4

3

10

0
0

5

10

15

20

25

30

0

Noise rate (%)

5

10

15

20

Noise rate (%)

.039)!$#}Q{7y).0>*A)D0#&P_MO33.0)3P)5MO;J;%21.0+3LN!$'&.0+3/)55)a+#&9)!$DR)#B1 ;!$t#&)%$#&>?)D0#C!$#BE
5)9)'B1.0;.0#&!$!$;!q%q'&;>*A)!$#&5d1;@9)%$.0)3@d%G.0)3D0#K)#&9)!$Ds)#B1 ;!$t:bC}!$A)()#&5.0%1()#
A#&!G'&#& 13A
# lNh z !$#&5+9)'B1.0;m.0/#&!$!$;!LN#&b03b0P<N;!W);.0%$#7.0K1()#%$#&3>*#&141.0;5)41
%$#B1P.0<s1()#r%$.0)3D0#*)#B1 ;!Gt>r#B1();J5()56#&!G!$;!}!$41#d;<Qb0S )5I1()#rM33.0+3
>*#B1();:5()5#&!$!$;!C!$41#/;<wQb0*PH1()#&1().0%*.0%C3!GA)()#&5%CQb0`6A^#&!$'&#&13#
A;.01!$#&5+9)'B1.0;m.0K1()#7#&!$!$;!W!$41#&a-b

w5)5). 1.0;)D1#&%o1%wLN);41q%$(); C()#&!$#&aZ%$(+;
!$#&%21!o1.0)3*.0%=+;417#&>*A)D0;-+#&5+b

1(+415+4EGM;:;%21.0)30%#&!$!$;!H!$41#W?^#&'&;>*#&% ;!$%$# ()#&

cW(+.0%'&;+'&D09)%$.0;g5);$,+#B1.0D0%d+.0'&#&D . 1(y)'
()A).0!$#I#B1uD0b00%LNQSSad!$#&'&#&1u5).0%$'&9)%$%G.0; ()#&!$#
1()#B);41#*1()41*1()##&#&'B1. ,+#&+#&%$%/;<q/,+;41.0)3>*#B1();:5g'&?#u>*#&%$9)!$#&5? #B>*.0).0)3m1()#
k { $ |Nh)i=;<+1()##B>*A)D0#&%$bLNcW()#>*!$3.0u.0%R1()#5).0#&!$#&)'&#}?^#B1 #&#&K1()#:9)>?^#&!;<s'&;!$!G#&'B1)5
.0)'&;!$!G#&'B1r,+;41#&%I<;!r]#B>*A)D0#&b0a6%$.0>*A+D0#m!$#&%$>*A+D0.0)36>*#B1();:5]%G9)'G(%rMO33.0)3P}#&'
(
!$#&%$9+D 1.0)3}'&D0%$%$.0F+#&!H<N;J'&9)%G#&%H;r.0+'&!$#&%$.0)3O1(+#W>*!$3.0d<;!%H>*m;<1(+#W#B^>rA)D0#&%H%A;%G%$.0?)D0#&b
MO91/.0MO;:;%21.0)3>*#B1();:5)PD041#&!C'&D0%$%$.0F+#&!$%K<;:'&9)%K;.0)'&!$#&%$.0)3r1()#I>*!$3.0+%<N;!#B^>*A+D0#&%
. 1(A;:;!W'&9)!G!$#& 1>*!$3.0)%$bww%=y)'
()A).0!$#}#B1KD0b*LNQSSa);41#&P)1().0%w.0%=q,+#&!2#&#&'B1. ,+#K%21!$41#&34
.0<1()#};$,+#&!$D0D'&'&9)!$'B;<1()#!$#&%$9)D 1.0+3r'&D0%$%$.0F+#&!5);:#&%=+;415)!$;Au%$.03).0F)'&1D b});!qrA+!$;?)D0#&>
. 1(6+;.0%$#&PH<N;J'&9+%$.0)3I;6>*.0%$'&D0%G%$.0F)#&56#B>*A)D0#&%>*-g'&9)%$#C/'&D0%G%$.0F)#&!1;u<;:'&9)%;6?^;:;%21.0)3
1()#}>r!$3.0)%W;<LN);.0%2aW#B>*A)D0#&%_1(+41 ;9+D05m.0m<N'B1?^#q>*.0%$D0#&5).0)3r.0u;-,+#&!GD0D'&D0%$%$.0F+'&41.0;)b

Z

*

fi

stv{wz{y{t

20

Error rate

18
Arc
Ada

16
14

Bag

12
10
0

5

10

15

20

25

30

20

Error rate

18
16
Arc
14

Ada

12

Bag

10
0

5

10

15

20

25

30

20

Error rate

18
16
Arc
14
Ada
12
Bag

10
0

5

10

15

20

25

30

20

Error rate

18
Arc
Ada

16
14

Bag
12
10
0

5

10

15

20

25

30

20

Error rate

18
16
Arc
14

Ada

12

Bag

10
0

5

10

15

20

25

30

Networks Ensemble

.039)!$#}QQ7H!$!$;!w!$41#&%q?m1()#%$.0&#;<H#&)%$#&>?)D0#<N;!w5)4EGMO;:;%21.0)3P_w!$'&.0)3P)5MO33.0)3/#&E
%$#&>?+D0#&%=<N;!=F,+#5).0#&!$#&1!21.0F)'&.0Ds5)41*%$#B1%'&; 1.0+.0)3r;)#BEG%G.05)#&5u);.0%G#dLN%$#&#O1#B:1
<;!5)#&%$'&!$.0A1.0;+a-b

**

fi

j

r+su}SmQz
r

vr++z

Q

)
#7.0 1#&!$#&%o1.0)3d8:9)#&%21.0; #A)D0C1;d.0 ,+#&%o1.0341#.0%w(); #&#&'B1. ,+#d%$.0)3D0#'&D0%$%$.0F)#&!wA)A)!$;'
(
>*.03(1*?#.0<H. 1 %D0D0; #&5I1;/9)%$#=1()#1.0>*#K. 1q1t#&%O1()#K#&)%$#&>?)D0#K>*#B1();:5d1;1!$.0>9+D 1.0A)D0#
'&D0%$%$.0F+#&!$%1;#B^A)D0;!G#. 1%/'&;+'&#&A16%$A)'&#&b);!m#B>*A)D0#&P)#&9)!$Dw)#B1 ;!$tA)A)!$;'
("'&;9)D05
A^#&!$<N;!$>A).0D0;41%219)5+.0#&%9)%$.0)31()#1!$.0+.0)3C%$#B11;*%$#&D0#&'B1A)A)!$;A)!G.041#H,D09)#&%W;<RA)!$>r#B1#&!$%W%$9)'
(
%=(+.05)5)#&/9)). 1%GPD0#&!$).0)3C!$41#&Ps#B1'&b
\ #@A)D0/1;'&;>*A)!$#dMO33.0)3+5MO;J;%o1.0)3>r#B1();J5+%O1;u;41()#&!>*#B1();:5)%.0 1!$;:5)9)'&#&5!$#BE
]
'&#&1D bW@A)!21.0'&9+D0! #=.01#&)51;#B^>*.0+#Z1()#9)%$#;<y1'Gt:.0)3/Le\];D0A^#&!21PQSS`aO%>*#B1();:5
;< z { h+
h |I'&;>?+.0).0)3<9)+'B1.0;)P%G;%=1;u$,+;.051()#r#&#&'B1m;<()-,.0)3C1; #&.03( 1/'&D0%$%$.0F)#&!G%$b
\]#}D0%$;rA)D01;*'&;>*A)!G#M33.0+3r)5/MO;:;%21.0)3q1;C;41()#&!=>*#B1();:5)%%$9)'
(m% A). 1+5/y)()-,:E
D0.0t:0%CLNQSST?+aA)A)!$;'
(r1;I'&!$#&41.0+3@#&)%G#&>?)D0#&bKcW(+.0%A)A+!$;'G(9)%$#&%q3#&)#B1.0'K%$#&!G'G(@1;@F))5
'&D0%$%$.0F+#&!$%_1()41!$#'&'&9)!$41#)5m5).0#&!W.0K1()#&.0!A)!$#&5).0'B1.0;+%$b
.0)D0D P%G.0)'&#Z1(+#wMO;:;%21.0)3C>*#B1(+;J5)%!$#q#B:1!$#&>*#&D %$9)'&'&#&%$%$<N9)D.0I>* 5);>*.0)%GP #qA)D0
1;.0,+#&%21.0341#);$,+#&DA+A)!$;'G(+#&%71(+41 .0D0D!$#B1.061(+#u?^#&)#&F1%d;<wMO;:;%21.0)3bc=()#m3;D .0D0D
?^#1;'&!G#&41#mD0#&!$)#&! (+#&!$#+;9'&g#&%$%$#&1.0D0D A)9)%$(%21!21u?)91-1;+5D0#B1u. 1u!$9))bcR;
5);*1().0% # ;9)D05u1!21;A)!G#&%$#&!2,+#q1()#d?^#&)#&F1%7;<MO;:;%21.0)3 ().0D0#rA+!$#B,+#& 1.0+3;$,+#&!$F1-1.0)3;
);.0%2g5)41%$#B1%$b )#CA^;%$%G.0?)D0#*A)A)!G;'G( ;9)D05?#1;u9)%$#rm();D05);9171!$.0).0)3%$#B1LNK19+).0)3
%$#B1as1;C#B,D09)41#1()#wA#&!G<;!$>r)'&#;<)1()#wM;:;%21.0)3C#&+%$#&>?+D0#H1;K5)#B1#&!G>*.0)# ()#&71()#q'&'&9)!$'B
.0%7+;uD0;)3#&!.0)'&!$#&%$.0+3bw);41()#&!A)A)!$;'
( ;9)D05?#1;u9)%$#rA).0D0;41@%219+5).0#&%1;5)#B1#&!$>*.0+#*
4;A1.0>*D0dJ9+>?^#&!;<'&D0%$%$.0F)#&!G%_1;*9)%G#.0mm#&)%$#&>?)D0#&b



H



g





)

w%>r#& 1.0;)#&5I?^#&<N;!$#&P1(+#=.05)#&K;<9)%$.0+37I#&)%$#&>?)D0#w;<'&D0%$%$.0F)#&!G%!G41()#&!1(+}1()#w%$.0)3D0#w?^#&%21
'&D0%$%$.0F+#&!s()%R?^#&#&7A)!G;A;%G#&5}? r%G#B,+#&!$DJA^#&;A)D0#&bB7y)#&'B1.0;`P #A)!$#&%$#&1<!$>r# ;!$t<N;!1(+#&%$#
%2%21#&>*%$P%$;>*#}1()#&;!$.0#&%7;< (+41d>*t#&%7#&#&'B1. ,+#@#&)%$#&>?)D0#&P#B:1#&)%$. ,+#d'&;-,+#&!$.0)3;<s1()#
MO33.0)3})5KMO;:;%21.0)3D03;!$. 1()>r%$P+)5Kq5).0%$'&9+%$%$.0;K;w1()#O?).0%_A)D09)%,!$.0)'&#5)#&'&;>rA;%G. 1.0;)b
y)#&'B1.0;[!$#&<#&!G!$#&5m1;#&>*A).0!G.0'&D%o19)5).0#&%%$.0>*.0D0!1;;9+!$%$U1()#&%G#d>*#B1(+;J5)%5).0#&!<N!$;> ;9)!$%.0
1()41Z1(+#B #&!$#D0.0>*. 1#&51;5)#&'&.0%$.0;1!G#&#&%$P3#&+#&!$D0D . 1(*<N# #&!5)417%G#B1%$bs\]#='&;-,+#&!O5)5+. 1.0;)D
!$#&D041#&5 ;!$tI.0K1(+.0%W%$#&'B1.0;)b

s.0)'&;D0r)5ry)tJ!GB^A^#&t/LNQSXSa-P).sLNQSSQaO)51()#W<N;!$#&'&%21.0)3D0. 1#&!$419)!$#KLNVWD0#&>*#&)PQSXSU
}!$+3#&!$P=QSXSa*.0+5).0'&41#1()41m%$.0>*A)D0#I$,+#&!$3.0)36;<Z1()#IA)!$#&5).0'B1;!$%C3#&+#&!$41#&%*@,+#&!23;J;:5
'&;>*A^;%$. 1#>*;J5+#&D0U+(); #B,+#&!$P>*mD041#&!!$#&%G#&!$'G()#&!G%wLNwD0A)-5).0)PQSS[U^%$t#&!x'&D0.0)PQSSP
QSS?)UMO!$#&.0>*+PQSST'&Uv%G()#&>*P^QSSU'&D0.0)PQSSXUY#&!$!$;)#&P^QSS`U\];D0A^#&!21P^QSS`k
U ())3P
#&%$.0!$;-,P^x\]D 1&P^QSS`aO()-,+#<9+!21()#&!Z.0>*A+!$;-,+#&5@3#&)#&!$D0.0&41.0; . 1(},+;41.0)3%$'G()#&>r#&%1()41q!$#
'&;>*A)D0#Bg'&;>?).0)41.0;)%;<#&'
(A)!G#&5).0'B1;!$0%};91A+91b )#C>9+%21r?^#'&!G#&<9)D_.0/1().0%'&%$#&P%$.0)'&#
;A1.0>*.0&.0+3W1()#='&;>?).0+.0)3 #&.03( 1%O'&@#&%$.0D uD0#&571;1()#A)!$;?)D0#&>z;<;-,+#&!$F1-1.0+3 (+.0'G(r%G.0>*A)D0#
-,+#&!G3.0)3d%G#&#&>*%1;r$,+;.05LNy);D0D0.0'
(x|}!$;3()PQSSTa-b
;%21A)A+!$;'G()#&%;)D mhd&&f; z n1!21;}3#&)#&!G41#=().03()D /'&;!$!$#&'B1w'&D0%$%$.0F)#&!$%1()415).0%$3!G#&#W%

>9)'G(@%A^;%$%G.0?)D0#&bOcW()#&%$#>*#B1();:5)%1!o1;'&!$#&41#q5). ,+#&!$%G#='&D0%$%$.0F+#&!$%O? C1!$.0+.0)37'&D0%$%G.0F)#&!$% . 1(
5).0%$%G.0>*.0D0!=D0#&!$+.0)3rA)!G>*#B1#&!$%LNwD0A)$^5).0+PQSS[a-PR5).0#&!G#& 1K'&D0%$%$.0F)#&!w!$'G(+. 1#&'B19)!$#&%CLNv%$(+#&>*P
QSSa-P,!$.0;9+%_.0). 1.0D))#&9)!GD EG)#B1 ;!$t #&.03(1=%$#B1-1.0)3%qLN'&D0.0*x A). 1&P)QSSU^'&D0.0rx"y)()-,:E
D0.0t:PQSSa-P;!%$#&A)!$41#dA)!21. 1.0;)%;<R1()#q1!G.0).0)3u%G#B1LNMO!$#&.0>*)POQSSTUW|7!$;3(x~=#&5)#&D0%$?P
QSSa-b@M;:;%21.0)3/;d1()#K;41()#&!(+)5.0%'B1. ,+#r.0r1!o^.0)31;/3#&)#&!G41#C().03()D '&;!$!G#&'B1r)#B1 ;!$t:%
**

fi

stv{wz{y{t

%$.0)'&#@. 1m'&'&#& 19+41#&%*#B^>rA)D0#&%K'&9)!$!$#&1D '&D0%$%$.0F+#&5.0)'&;!$!$#&'B1D ? ]A)!G#B,^.0;9)%K>*#&>?^#&!$%;<1()#
#&)%$#&>?)D0#&b
iodgk L A). 1uxy)()$,^D0.0t:PqQSSTPqQSST?)ad.0%d);41()#&!d#B^>*A+D0#u;<q]A)A+!$;'G(61()41
5).0!$#&'B1D 1!$.0#&%1;6'&!$#&41#m65+. ,+#&!$%$#/#&)%$#&>?)D0#&b iodgk 9)%$#&%C3#&)#B1.0'D03;!$. 1()>*%}1;%$#&!$'
(
#BA)D0.0'&. 1D <N;!7m().03(+D 5+. ,+#&!$%$#r%G#B1@;<O'&'&9)!$41#71!$.0)#&5)#B1 ;!$t:%$b jdogk ;!$t:%?gF)!$%21
'&!$#&41.0)3.0). 1.0DA^;A)9)D041.0;+PO1()#&9)%$#&%I3#&)#B1.0';A^#&!$41;!$%1;'&!$#&41#)# )#B1 ;!$t:%I'&;E
1.0:9)D0D Pt#&#&A+.0)31()#C%$#B1d;<)#B1 ;!$t:%O1()41@!$#C().03()D '&'&9)!$41# ().0D0#C5).0%$3!$#&#&.0+3 . 1(6#&'
(
;41()#&!q%q>9+'G(%qA;%G%$.0?)D0#&b idogk .0%D0%$;I#&#&'B1. ,+#*41C.0)'&;!$A^;!$41.0)3@A)!$.0;!wtJ+; D0#&5)3#&P_.0<
-,.0D0?)D0#&P+1;*.0>*A)!G;-,+#O1()#78J9)D0. 16;<R. 1%#&)%$#&>?)D0#&b
wD 1#&!$)41#/A)A+!$;'G(1;@1()#I#&)%G#&>?)D0#/<N!$>*# ;!$t.0%w1;r1!G.0.0)5). ,.05)9)D)#B1 ;!$t:%*;
%$9)?1%$t:P)5m1;r1()#&'&;>?+.0)#}1(+#&%$#dA+!$#&5).0'B1.0;)% . 1(4341.0)3<N9))'B1.0;u1()41/5)#&A^#&)5)%
;1()#.0+A)91b'&;?)%u#B1D0b00%LNQSSQa5)A1. ,+#>r. J19)!G#&%/;<D0;:'&D7#BA^#&!21%$PM4:10%LNQSS`a
>*#B1();:5g<N;!*.05)#&1.0<.0)36>=+;:'&!$5).0D=.0+<!$'B1.0;+Pw+5; D0+5gy)#B-); %GtJ.00%LNQSS`a7,.0%$9)D
>*;:5)#&DD0D1!$.0])#B1 ;!$t:%1;6D0#&!$]%$A^#&'&.0F)'/%$9)?1%GtJ%$bcW(+#/t#B".05+#&;<H1(+#&%$#1#&'G()+.08J9)#&%d.0%
1()415)#&'&;>rA;%G. 1.0;;<1()#A)!$;?+D0#&>.01;%$A^#&'&.0F)'u%$9)?1%$t:%@>*.03( 1D0#&51;>*;!$##&*'&.0#&1
!$#&A)!G#&%$#& 141.0;+%=)5K1!G.0).0)3LNvw>*A)%$(+.0!$#x\].0?^#&D0PQSXSa-b
+'&#*mA)!$;?+D0#&> .0%7?)!G;t#&6.0 1;%$9)?1%GtJ%$P1()#*!$#&%G9)D 1.0)3/%$;D091.0;+%)#&#&5/1;m?^#C'&;>?).0+#&5)b
'&;?+%#B1ID0bqLNQSSQaKA)!$;A^;%$#r()-,.0)3C1(+#r341.0)3<9+)'B1.0;?^#*)#B1 ;!$t@1()41mn2f { 4h)iK(); 1;
D0D0;:'&41#r#B>*A)D0#&%O1;1()#K#BA^#&!21%$b@cW(J9+%H1(+#341.0+3m)#B1 ;!$tD0D0;J'&41#&%#&'G(#B^>rA)D0#w1;/;)#
;!/>*;!$##BA^#&!21%$P7+51(+#?+'Gt:A)!$;A)341#&5#&!G!$;!$%I)5!$#&%$9)D 1.0+3 #&.03(1'G())3#&%u!$#d1()#&
!$#&%21!G.0'B1#&571;W1()#&%$#)#B1 ;!$t:%LN+51()#341.0)3K<9)+'B1.0;)a-bOcs!$#&%GAd)5dcs+.039)'G().LNQSSaA)!$;A^;%$#
*>*#B1(+;J5m<N;!W5)#B1#&!G>*.0).0)3q1(+#341.0)3r<N9))'B1.0; {$} z f$1()#A)!$;?)D0#&>()%=?^#&#&/5)#&'&;>*A^;%$#&5)5
1()#q#BA#&!o1%1!G.0)#&5)bcW()#&.0!341.0)3C<N9))'B1.0;I.0%I.0)A)91-EG5+#&A#&+5)#& 1PD0.0)#&!2E #&.03( 1.0+3*<9+)'B1.0;
1()41r.0%}5+#B1#&!$>*.0)#&56?/'&;>?).0)41.0;;<1()#C)#B1 ;!$t:%$_5). ,+#&!$%G. 1g;I1()#C'&9)!G!$#& 1*.0)A+91 . 1(
1()#}D0.0t#&D0.0(+;J;:5C1()41=1()#&%$#})#B1 ;!GtJ%()-,+#}%G#&#&u5)414+#&!$q1()41.0+A)91b
wD 1();9)3(w1()#>r. J19)!G#&%R;<#B^A^#&!21%_+5#&+%$#&>?+D0#A)!$5).03>*%_%G#&#&>,+#&!2I%G.0>*.0D0!$P1()#BI!$#O.0
<N'B18:9). 1#O5).0%21.0+'B1<N!$;>q%2141.0%21.0'&D)A^;.01O;<,^.0# bc=()#>r. J19)!G#&%2EG;<EG#BA^#&!21%>*;:5)#&DJ>rt#&%^1()#
%$%$9+>*A1.0;71()41q%$.0)3D0#w#BA#&!o1w.0%!$#&%$A^;)%$.0?)D0#<;!#&'G(I#B>*A)D0#&bWB71().0%'&%G#&P#&'
(/#B^A^#&!21q.0%
C>*;:5)#&D^;<sC!G#&3.0;m;<)1(+#.0)A)91%$A)'&#&P+51()#p;?/;<+1()#q341.0)3*<N9))'B1.0;u.0%R1;C5)#&'&.05)#<N!$;>
().0'
(d>r;J5)#&D1()#=5)41A^;.0 1w;!$.03.0)41#&%$by).0)'&#W#&'
(@+#B1 ;!$t*.071()#=#&)%G#&>?)D0#A)A)!$;'
(dD0#&!G)%
1()# ();D0#w1%Gt!$41(+#&!1()@p9+%21*%$;>*#K%$9)?1%Gtu)5@1(:9)%>*t#&%}+;@%G9)'G(>919)D#B'&D09)%$. ,. 1
%$%$9+>*A1.0;)P^#&)%$#&>?)D0#&%O!$#qA)A)!G;A)!$.041# ()#&I);;)#q>*;:5)#&D.0%(+.03()D D0.0t#&D @1;C?#'&;!$!$#&'B17<N;!
;+#A;.01.0K1(+#.0)A)917%$A+'&#&b






j


cW().0%IA)A^#&!IA)!$#&%G#& 1%/'&;>*A)!G#&()#&)%$. ,+##&>*A+.0!$.0'&Dq#B,D09)41.0;;<7MO33.0)3g+5MO;:;%21.0)3<N;!
)#&9)!GDw+#B1 ;!$tJ%)5"5)#&'&.0%$.0;1!$#&#&%$b 9)!I!$#&%G9)D 1%m5)#&>*;+%21!$41#@1()41MO33.0)3]#&)%$#&>?)D0#
)#&!$D rD -%_;91A^#&!$<N;!$>*%s%$.0+3D0#'&D0%$%G.0F)#&!$b 9)!!G#&%$9)D 1%RD0%$;%G(); 1()41OMO;:;%21.0)3w#&)%$#&>?)D0#
'&63!$#&41D g;91A^#&!$<N;!$>?^;41(MO33.0)3m)5/%$.0)3D0#C'&D0%$%$.0F+#&!$bIv; #B,+#&!$P<N;!}%$;>*#C5)41u%$#B1%
MO;J;%o1.0)3>*-"%$(); &#&!$;3.0g;!*#B,+#&5+#&'&!$#&%$#/.0A^#&!$<N;!$>*)'&#I<N!$;>%$.0)3D0#/'&D0%$%$.0F+#&!$b
)9)!o1()#&!w1#&%21%*.0)5+.0'&41#1()41mM;:;%21.0)3>*-%$9)#&!C<!$;>;$,+#&!$F1-1.0)36.01(+#@A+!$#&%$#&)'&#I;<w);.0%$#
().0'
(m>*$#BA)D0.0%$;>*#};<1()#5)#&'&!G#&%$#&%.0uA#&!G<;!$>r)'&#<;!=M;:;%21.0)3bZ\]#7D0%$;r<;9)+51()41
}%$.0>rA)D0#=#&)%G#&>?)D0#=A)A)!$;'
(r;<9)%$.0+3)#&9)!$D)+#B1 ;!$tJ%1()415+.0#&!;)D m.01()#&.0!!$)5);>z.0). 1.0D
#&.03( 1K%$#B1-1.0)3%=A^#&!$<N;!$>*#&5/%G9)!$A)!$.0%G.0)3D #&D0D0P;<e1#&m5);.0)3r% #&D0Ds%1()#}MO33.0)3b
**

fi

r+su}SmQz
r

vr++z

w)D %$.0%;<_;9+!=!$#&%$9+D 1%=%$9)33#&%o1%H1(+41=1()#A#&!G<;!$>r)'&#};<_?^;41(mMO;J;%o1.0)3d>r#B1();J5+%LNw5)4E
MO;J;%o1.0)3/)5!G'&.0)3aq.0%41CD0#&%o1rA)!21D 5)#&A^#&)5+#& 1C;d1()#K5)41I%$#B1*?#&.0+3@#B>*.0)#&5+P ()#&!$#
MO33.0)3%$(); %H>9)'G(dD0#&%$%'&;!G!$#&D041.0;)bWcW(+#W%21!$;)37'&;!$!$#&D041.0;)%O<N;!HMO;J;%o1.0)37>*$u?^#WA)!21.0D0D
#BA)D0.0)#&5]?. 1%r%$#&+%$. 1. ,^. 1g1;6);.0%G#&Pw'&D0.0>%G9)A)A^;!21#&5?5)5+. 1.0;)D_1#&%21%Gb.0)D0D P #
%$(); 1()41>9)'
(u;<+1()#}A^#&!$<N;!$>*)'&##&)(+)'&#&>*#&1<;!=m#&)%$#&>?)D0#}'&;>*#&% . 1(K1(+#F)!$%217<N#
'&D0%$%$.0F+#&!$%'&;>?).0)#&5+P?+91Z1()41MO;J;%21.0+35)#&'&.0%G.0;}1!$#&#&%O>*$'&;1.0J9)#H1;<9)!o1()#&!Z.0>*A)!G;-,+# . 1(
D0!$3#&!#&)%$#&>?)D0#}%$.0&#&%$b
B/'&;)'&D09)%$.0;+P%WC3#&)#&!$D1#&'G()).08:9)#}<N;!W5)#&'&.0%G.0;K1!$#&#&%W)5u)#&9)!$D^)#B1 ;!$t:%$PMO33.0)3d.0%
A)!$;?+?)D A)A)!G;A)!$.041#w<;!>*;%o1A+!$;?)D0#&>*%$P?)91 ()#&IA)A+!$;A)!$.041#&P^MO;J;%o1.0)3uLN#&. 1()#&!w!$'&.0)3K;!
w5)aW>*$A+!$;J5+9)'&#qD0!$3#&!=3.0)%.0m'&'&9)!$'Bb

<



)[

fi

c ().0%_!G#&%$#&!$'G( %_A)!o1.0D0D /%G9)A)A^;!21#&5? I). ,+#&!G%$. 1m;<+.0))#&%G;41}}!$1%2EG.0EGw.05q1;?^;41(C9E
W
1();!$%Gb}q-,+# A). 1 %qD0%$;@%$9)A)A^;!21#&5u? w41.0;)Dy)'&.0#&)'&#);9))5+41.0;3!G 1C EGS[QSP
1()#;1) [HYy)VW;Y#B1!$;D0#&9)> =#&%G#&!2,+;.0!V=()!$'B1#&!$.0&41.0;Y!$;jp#&'B1Pd wcWy
3!$1%G9)A)A^;!21#&5g?1()#uw). ,+#&!$%G. 1;<;1)P7)5;1)y+'&.0#&)'&#cR#&'G(+);D0;34wD E
D0.0)'&#K3!$1bCcW().0%q.0%q#BJ1#&)5+#&5r,+#&!G%$.0;;<ZIA)A^#&!A+9)?)D0.0%$()#&5.0d1()
# ~ z fGf-h z{Ez h { n
h } f-&f-h G
f "
h W z \ -- { &
n -h z f$nn |f-d
h
Zf

p




wD0.0P}|}b0PwxY&&).0PbKLNQSSTa-b!$!$;!d!$#&5)9)'B1.0;1()!$;9+3(]D0#&!$).0+3>9)D 1.0A)D0#5)#&%$'&!$.0A1.0;)%$b
{ hsg
f f { 4h)N
h |
P MPQ[4+`{`b
wD0A)-5).0)PHb=LNQSS[a-b9)D 1.0A+D0#*)#B1 ;!$t:%}<N;!}<9+)'B1.0;6D0#&!$).0+3bmEZGfGfNh|i }]z fEMM
C[-h z f-4h {Ez h { n h } f-&f-hGfh f ~ { n f z fii$P~=;D0bP^A)A)b^`4+[`dy)/)!$)'&.0%G'&;b
w!$?).0?)PbZLN5)b0a-bHLNQSSa-b]

f {
h l;Gmb }W { Nh ;f {
h f ~ { n f z fii$bOcYH!G#&%$%$b

w%$t#&!$P=sb0Px'&D0.0)Pw=b}LNQSSa-b")%$#&>?)D0#&%C%*%$#&8:9)#&)'&#/;<='&D0%G%$.0F)#&!$%$bR
EZG fGf Nh|
}z f }z fGf$h z -h z f-4h {Ez h { nk& Nh z h } f$f$hdG fj hW
z \-- { nl- h z f-nNn | f-hd
fpPA)A)b+XT{4+XT
w3;-+PJA))b

w%$t#&!$Pb0PJx'&D0.0)P)bLNQSS?)a-b+#&419)!$#O#&)3.0)#&#&!$.0+3)5'&D0%$%$.0F)#&!%$#&D0#&'B1.0;+'&%G#%o19)5*.0
~C#&:9)%$.0=,+;D0'&);5+#B1#&'B1.0;)bB]
E ZGfGf N
h |U
}*z *
f % ~ z f
f-h z -h z f-4h {Ez h { n &h } f$f$d
h Gf
&
h { hsg
f f { 4h)N
h | PsA)A)b^[4+QQrw%$(,^.0D0D0#&PRcWwb
MO9)#&!$Pb0Px|};()$,^.0PbLNQSSSa-bw#&>rA).0!$.0'&D:'&;>*A)!$.0%$;K;<j,+;41.0)3q'&D0%$%G.0F)'&41.0;*D03;!$. 1()>r%$
MO33.0)3PR?^;J;%o1.0)3P)5K,!$.01%$A
b { Nhsg
f Rf { 4h)8
h |
P X4PQ{4EGQ[Sb
MO4J1P\b7LNQSS`a-bB>*A)!$;$,^.0+3@1()#/'&'&9)!$'B;<wg!21.0F)'&.0D=)#&9)!$D)#B1 ;!Gt9+%$.0)3>9+D 1.0A)D0#
5+.0#&!$#&1D I1!$.0)#&5)#B1 ;!$t:%$b f ~ { n 0
k ~z;{Ez h%
P P`4+X{b
MO!$#&.0>*)PbHLNQSSTa-bqMO33.0)3rA)!G#&5).0'B1;!$%$bA

{

hsf0f { 4 h)Nh| PMLN`a-PRQ`[4+Q{b

MO!$#&.0>*)PbqLNQSST?)a-bMO.0%$Ps,!G.0)'&#&PO)56!$'&.0)3'&D0%$%$.0F)#&!G%$bcs#&'
()bH!$#&A+bZT{POVEGMO#&!$t#&D0#BP
MO#&!$t#&D0#BPRVWwb
*

fi

stv{wz{y{t

MO!$#&.0>*)PbHLNQSST'&a-bqy1'Gt#&5!$#&3!$#&%G%$.0;)%$bW

{

Nhsfgf { 4 h)Nh| PMLNQa-PRS4+Tb

VWD0#&>*#&+PbZLNQSXSa-bWVW;>?).0).0)3K<N;!$#&'&%21%$W!$#B,.0#
%&;f { z Nh | W
P 4PS4+X[b

)5/));4141#&5/?).0?+D0.0;3!$A)(b-&

~

{ Cn }

4h

q!$9)'
t#&!$Pvwb0PxVW;!o1#&%$PVWbLNQSSTa-bwMO;J;%o1.0)3r5)#&'&.0%G.0;C1!$#&#&%$bucs;9)!G#B1%$t Pwb0Ps;&#&!GPb0Px
vw%$%$#&D0>r;Pb_LNH5)%$b0a-l
P UE {
h Gf-ih f ~ { X
n -h } &
k {Ez
h Hm GGf$iGiGN
h |]i z f-kKiGP~=;D0b^XPA)A)b
S4+XIVW>?)!$.05+3#&PwbcYH!$#&%$%Gb
q!$9)'
t#&!$PHvwb0PZVW;!21#&%GPZVWb0P_'
t#&D0Psb0PZ#&V=9))P<Kb0PHx~=A)).0t:P^~Kb=LNQSSa-b/MO;:;%21.0)3m+5;41()#&!
>r'G().0)#wD0#&!$).0+3}D03;!$. 1()>*%GbZ
Hm GGf
;f N
h |fii
}-z f n2af :f-h z -h z f-4h {Ez h { n &h } f$f$d
h Gf
&
h { hsg
f f { 4h)N
h | PsA)A)b^[4+TQ@# MO!$9+)% .0'
tJPwb
H<N!$;)PMb0PRxc=.0?)%$().0!$+.0P=bOLNQSS[a-b]Wh-h z G
w# =;!GtJb

~ z h z z f G z z { +bV=()A)>*)5uvwD0D0P

.0%$()#&!$Pqb0Px'&|}9)%$.0'
tJP|}bRLNQSXSa-bwd#&>*A+.0!$.0'&D'&;>rA)!$.0%$;@;<q[)5@?)'GtEGA)!$;A)341.0;+b
B
E ZGfGf N
h |
}z
f n2af :f-h z -h z f-4h {Ez h { g
n l&h z h } f-&f-
h G"
f
h W z 3 - { W
n -h z f$nn
|f-dh
fpPA+A)b^XX4+S[@q#B1!$;. 1PsBb
)!$#&9+)5)PXCb0PZxy)'G(+A).0!$#&PZb=LNQSSTa-bmA^#&!$.0>*#&1% . 1(6/)#

fGf 8h |U
}%z
f N z f
f-h z -h z f-4h {Ez h { n h } -f &f-hd
fAhx
MO!$.0Ps 1D b

?^;:;%21.0)3/D03;!$. 1()>rb/EE
hsP
f Rf {
h+
h |PA)A)bQX4+QT

{

)!$.0#&5+>*)PRbLNQSSTa-b ?).0%GP),!$.0)'&#&P_{+Q4EGD0;%$%GP_)5*1(+#'&9)!G%$#BEG;<EG5+.0>*#&)%$.0;)D0. 1bl
}0x{Ez;{ uNh)8h | { dh jhd nof;E|f i;Ef-fiP-4b

~

4h

{
n

)!$.0#&5+>*)Pb0Pv%21.0#&P^cWb0PxcW.0?)%$().0!G).0P+bRLNQSSXa-bHw5)5). 1. ,+#wD0;3.0%21.0'!$#&3!G#&%$%$.0;)O"%2141.0%21.0'&D
,.0# ;<R?^;J;%o1.0)3bLN(1-1A) + WW EG%o141b0%21)<N;!$5)b0#&5)
9 Bp(+<-a-b
}#&>*+Py)b0PMO.0#&)#&)%21;:'Gt:PRHb0Pxq;9)!$%G41P=bHLNQSS`a-bww#&9)!$D)#B1 ;!GtJ%)5K1()#?).0%;4,!$.0+'&#
5+.0D0#&>*>*b f ~ { n 0
k ~z;{Ez h%
P PQ4+Xb
}!$+3#&!$PV=bLNQSXSa-bVW;>?).0).0)3/<N;!$#&'&%21%$@c #& 1+#&!$%D041#&!$b&
QT4+Q[b

~

4h

n } &f; { z Nh|PWP
{g

}!$;$,+#&Pqb0Pxy)'
(J9+9)!$>*)%GPWqb7LNQSSXa-b"M;:;%21.0)3.01()#/D0.0>*. 14.0>*.0&.0)3m1()#I>*!$3.0g;<
D0#&!G)#&5#&)%$#&>?)D0#&%$bK
Hm G
fG;f &
h |fi
}z U
f } z f
f-h zi{Ez h { n &h } f$f$d
h G
f
h W z \ -$ { n
-h z f-nNn v |:f$dh Gf-PA)A)b^TS`4+TSSI5+.0%$;)P\b
vw>*A)%$().0!G#&PJb0Px]\].0?^#&D0Pb_LNQSXSa-bOcW()#=>r#B14EGA).^)#B1 ;!$t:M9+.0D05).0)35).0%21!$.0?)91#&5dt:); D0#&5)3#
!G#&A)!$#&%$#&141.0;)%I<;!@!$;?)9+%21A)41-1#&!$!$#&'&;3). 1.0;+bcs#&'
()bw!$#&A)bWVWHEGVWyEGXS4EGQTTPVWwP
Y. 1-1%$?)9)!G3()PY^b
vw)%$#&)Pb0Pqxy)D0>*;)PY^bCLNQSS{a-b#&9+!$Dq)#B1 ;!$t#&)%$#&>?)D0#&%$b[C+ { +
h
{Ezz f-4"
h Wh { n iGNi {
h ] { Nhsg
f -h z f$nn v |:f-
h GfpPCmPSS[4+Q{{Qb
vw%$()#&>*Py)bLNQSSa-b A1.0>*DD0.0)#&!@'&;>?).0+41.0;)%d;<+#&9)!$DW)#B1 ;!GtJ%$b
LNa-PRSS4+TQb

Zp

*

{ z h+i&h

f ~ { n f z iGP

fi

r+su}SmQz
r

vr++z

'&;?+%$Pb0P7J;!$5))P}b0P; D0)Py)b0P7xvw.0 1;+P}b*LNQSSQa-b5+A1. ,+#>*. J19+!$#&%/;<7D0;:'&D
#BA^#&!21%$b f ~ { n 0
k ~z;{Ez hP%PS4+Xb
|};()$,^.0PKb0Px\];D0A#&!o1PqbrLNQSSTa-bMO.0%mA)D09+%,!$.0+'&#5)#&'&;>*A^;%$. 1.0;<N;!m&#&!$;4EG;)#D0;%$%
<N9))'B1.0;+%$b
E G
fGf 8
h |c
}z
f N z f
f-h z -h z f$
h {mz h { n h } f$f$d
h G
f
h { hRf
f { 4h)Nh | PsA)A)b`4+`X[@MO!$.0P 1D b
|};)3P:Hb0PJxgq.0#B1-1#&!$.0'G(+P)cWbLNQSSa-bH!$!G;!2EG'&;!$!$#&'B1.0)3=;91A)91'&;:5).0)3='&;!$!$#&'B1%R?).0%)5W,!G.0)'&#&b
B
Hm GGf
;f N
h |fif
}Pz 0
f f$n }z -h z f-4h {Ez h { n h } f-&f-d
h
g
f &
h { Nhs[
f Rf {
h)N
h |P)A)A)bJ[Q[4
[`Qdcs(+;J#}V=. 1PVWwb
|}!$;3(+P_b0P_x~=#&5)#&D0%G? Pb=LNQSSa-b/w#&9)!$D)#B1 ;!$t#&)%$#&>?)D0#&%$PZ'&!G;%$%O,D0.05)41.0;)PH+5'B1. ,+#
D0#&!G).0)3b"cR#&%$9)!G;P7b0PcR;9)!$#B1&tPCqb0PKx#&#&)PKcWb*LNH5+%$b0a-P@E { hd
f-ih f ~ { n
-h } 4k {Ez
h Hm G
f-iGi
8
h |xi z f$kiGP~=;D0bPA)A)b`[Q4+`[X@VW>?+!$.05)3#&PbBcYH!G#&%$%$b
.0+'&;D0)P\b0Pxy)t:!$B^A^#&t:PJbOLNQSXSa-b*y^)#&!G34;<H'&D09)%21#&!G.0)3d>9)D 1.0A)D0#K?)'
tuA)!G;A)341.0;)#B1-E
P UE {
h Gf$iNh f ~ {
n -h } 4k {Ez
h Hm GGf$iGiGN
h |i z f$kiGP
;!$t:%$bcR;9)!$#B1&tP_wbLNH5+b0a-%
~=;D0bs`PA)A)bT{4+TS@y)m41#&;PRVWb;!$3|}9)<N>*))b
'&D0.0)P=bLNQSSXa-bKMO;:;%21.0)3@'&D0%$%$.0F)#&!$%q!$#&3.0;+D0D b7BEG
fGfh8|i^ }@z f@ }z fGf$h
&h } f$f$dh G
f
h W z \ -$ {
n -h z f-nNn v |:f$d
h Gf-PA)A)b{{4+{@5+.0%$;)P\b

zb{Ez h {

'&D0.0)P7b0Pwx A). 1&P7wb*LNQSSa-bw#&>*A).0!$.0'&Dw#B,D09+41.0;;<}?)33.0)3)5?^;J;%o1.0)3bzB
E ZGfGf Nh|ix }z f% ~ z f
f-h z{Ez &h { n h } f-&f-hd
f]&hW z 3-$ { n<-h z f$nn v|:f-hGfpPA)A)b+T4
QdYH!$;$,^.05+#&)'&#&P=Bb
'&D0.0)PZ=b0Pxy)(+-,D0.0tJP_JbLNQSSa-b@VW;>?).0).0)31()#KA)!G#&5).0'B1.0;)%;<H>9)D 1.0A)D0#C'&D0%G%$.0F)#&!$%$w%$.0)3
'&;>rA#B1. 1. ,+#=D0#&!$).0)31;.0). 1.0D0.0&#W+#&9)!$D:)#B1 ;!$t:%$bBi
E ZGfGf N
h |f
}[z [
f % ~ z f
f-h z -
h
f
h W z 3 -$ {
n -h z f$nn v |:f-
h GfpPA)A+b`4+[{;1!$#&D0P)V=)5)b
z f$
h {Ez &h { n &h z h } f-&f-dh

).0P)}bLNQSSQa-bs; #&!$.0)3,!$.0)'&#;<5)#&'&.0%$.0;)%_?@9)%G.0)3!o1.0F)'&.0D)#&9)!$D)#B1 ;!Gt7A^;!21<N;D0.0;%$b
k ~z;{Ez hP%PX4+XTb
f ~ { n 0
;J;)#BP=b0Py)()$,^D0.0t:Pb0P7cR; #&D0D0PK}b0Px};-,+#&PKwbrLNQSXSa-bw#B^A^#&!$.0>*#&1D'&;>*A)!G.0%$;
;<%o^>?^;D0.0')5'&;))#&'B1.0;).0%o1D0#&!$+.0)3D03;!G. 1()>*%$bBEZGfGfNh|i }z fn2fa:f$h z
-h z f-4h {Ez h { n l&h z h } f-&f-h Gx
f
h W z \ -- { &
n -h z f$nn |f-d
h
fpPA+A)b^4+X{@q#B1!$;. 1PsBb
9)!$A)(PY^b}b0P}xw()PKqbO\brLNQSSa-bwVWr!G#&A;%G. 1;!2;<K>*'
().0)#6D0#&!G).0)35)41?)%G#&%
LN>r'G().0)#BEG!G#&5)?)D0#m5)41!G#&A;%G. 1;!2^a-b]). ,+#&!G%$. 1";<=VWD0.0<N;!$).04EGB!2,.0)#&P=q#&A)!o1>*#& 1u;<
B)<N;!$>*41.0;)5/VW;>*A)91#&!Wy)'&.0#&)'&#&b
w; D0)Py)b0Pxy)#Bp+; %$t:.0PcWb}LNQSS`a-b].0D 1#&!*%G#&D0#&'B1.0;]>*;:5)#&D<;!K3#&)#&!$41.0+3@,^.0%$9+D>r;41.0;
%G.03)D0%$brv)%G;)P)y)b0PVW; )P+Jb0P+x7.0D0#&%$PV=bsLNH5)%Gb0a-P<UE { hGf-i=h f ~ { n8-h } 4k {mz h
E ZGf-i
iGNh |xi z f-kKi$P)~=;D0bPA)A)b[TS4+[TIy)/41#&;PRVWb;!$3|}9)<N>*))b
A). 1&P:qb0Pxgy+()-,D0.0tJP:b+LNQSSTa-bw'B1. ,+#&D d%$#&!$'
().0)3W<N;!}#&#&'B1. ,+#O)#&9)!$D EG+#B1 ;!$tq#&)%$#&>?)D0#&b
&h)hs;f z &"
h d--f-d
h
fpk
P OLN+
[ a-P[[4+[[b
*ff

n

fi

stv{wz{y{t

A). 1&POqb0PHxy)()$,^D0.0t:PObwLNQSST?+a-b6}#&)#&!$41.0+3'&'&9)!G41#d)55). ,+#&!$%$#d>*#&>?#&!G%7;<u+#&9)!$D E
+#B1 ;!$t6#&)%$#&>?)D0#&bcs;9)!G#B1%$t Pqb0PO;&#&!$PWb0Pxvw%$%$#&D0>*;PbqLN5)%$b0a-
P UE {
h Gf-i
Nh f ~ { l
n -h } &
k {Ez
h Hm GGf$iGi

h |ji z f$kKi$P:~=;D0b^XP^A)A)b+[4+QrVW>?+!$.05)3#&P^wbBc
Y!$#&%$%$b
Y#&!$!$;)#&P=bLNQSS`a-b]%G;<1-EG'&;>*A^#B1. 1. ,+#m%GA)D0. 1-1.0)3!$9)D0#@<;!K5)A1. ,+#71!G#&#BEG%21!$9)'B19)!G#&5+#&9)!$D
+#B1 ;!$tJ%GbB
Hm GGf
;f N
h |^
}Uz f
f -h z f-4h {Ez h { *
n &Nh z h } f-&f-
h G
f &h f ~ { n f z iGP
A+A)bTXS4+TS[dMOD 1.0>*;!G#&Psqb
Y#&!$!$;)#&PqbLNQSS[a-b-k0EmNh|"f|fif$iGi
hi z Nk {Ez &hdW:f$ { |Nh|f z Gi } { 4 { hdGf
w;f ~ z h z [ z f$h)iG h z f-hsf$ { n h:faf { ~ f"o z kKv {Ez hbYH()b0qb1(+#&%$.0%$P
MO!$; uw). ,+#&!$%G. 1PY!$;-,.05)#&)'&#&P=Bb
}9).0+D0)P+JbRLNQSS[a-b
V=b

XMCE |fi {

ki

} {

hsfWRf {
h+h|bZ;!$3d|79)<>r))P+y+r41#&;P

}9).0+D0)PJb=brLNQSSTa-bM33.0+3PC?;:;%21.0)3PK)5'&b0bEG
fGfh8|i }z
f
f
h W z 3 - { &
n -h z f-nNn |f-d
h
fpPA)A+b`4+[{bY;!21D0)5+P =b
{Ez h { n h } f-&f-dh
x

N z f
f-h z

=9+>*#&D0()!21POqb0Pv.01;)PO}b0Px\.0D0D0.0>r%$P=bLNQSXTa-bs#&!$).0)3.0 1#&!G)D!G#&A)!$#&%$#&141.0;)%K?
#&!G!$;!A+!$;A)341.0;)b6B9)>*#&D0()!o1Pqb0Px'&VWD0#&D0D0)5)PJbwLNH5+%$b0a-P { { nNn2f$n z
-l ~z f
E ZGf-i
iGNh |gCn {Ez h)iKh z fkK $E &i z ~ z~
f } ; |fih) z
h l&n ~ kmfMA ~ h {Ez h)i$P
A+A)b[QX4+[T[bBcYH!G#&%$%$PVW>?)!$.05)3#&Pwb
y)'
()A).0!$#&PbHLNQSS{a-bc=()#%21!$#&)341(u;< #&tID0#&!$)?).0D0. 1bg

{

hsfgf { 4 h)Nh| P-LN`a-PRQS4+``b

y)'
()A).0!$#&P=b0P=+!$#&9))5)PPKb0PMO!21D0#B1-1PqYb0Pwx#&#&PH\b7LNQSSa-b"M;:;%21.0)3/1()#/>*!$3.0))#
#BA)D0)41.0;<N;!_1()#}#&#&'B1. ,+#&)#&%$%q;<,+;41.0)3d>*#B1();:5)%$bb
E ZGfGf N
h |
}gz g
f % ~ z f
f-h z
-h z f-4h {Ez h { n h } f-&f-dh
x
f
h { Nhs0
f Rf {
h+
h |PA)A+b[``4+[[{dw%$(,^.0D0D0#&PscWb
y);D0D0.0'
()PYb0Px|}!$;3()PRwbOLNQSSTa-bCs#&!$).0)3 . 1(#&)%$#&>?)D0#&%$}vw; ;-,+#&!oEGF1-1.0)3/'&?#9)%$#&<N9)D0b
B*cR;9)!$#B1%$tPwb0P;&#&!$Pb0Pxv%G%$#&D0>*;PbLNH5)%$b0a-PX@m { hd
f-iWNh f ~ { n8-h } 4k {mz h
E ZGf-i
iGNh |xi z f-kKi$P)~=;D0bXPA)A)bQS{4+QSTIVW>?)!$.05+3#&PwbcY!$#&%$%$b
cR!$#&%$A)P~Cb0PxcR).039)'G(+.0P=b7LNQSSa-bV=;>?).0+.0)3#&%21.0>*41;!$%*9+%$.0)3);EG'&;)%o1 1 #&.03( 1.0+3
<N9))'B1.0;+%$bcs#&%G9)!$;P}b0P}cR;9)!$#B1&tP}qb0P}x#&#&)PcWbKLNH5)%Gb0a-
P @E {
h
f-imNh f ~ { n
-h } 4k {Ez
h Hm G
f-iGi
8
h |xi z f$kiGP~=;D0bPA)A)bQS4+`T@VW>?+!$.05)3#&PbBcYH!G#&%$%$b
\];D0A^#&!21PqbLNQSS`a-bwy1'
t#&5u3#&)#&!$D0.0&41.0;+b

f ~ { n f z iGP4P`Q4+`Sb

()+3PCb0P^#&%G.0!$;-,Pb0P^x\]D 1&PqbZLNQSS`a-bWvH^?)!G.05d%2%21#&><N;!OA)!$;41#&.0/%$#&'&;)5+!2%21!$9+'B19)!$#
A+!$#&5).0'B1.0;)bA& ~ 4h { n } nof; ~ n { n |Zj
PM<4 PsQ{S4+Q{T[b

**

fi

"[


r+su}SmQz
r

vr++z

Hn

cR?)D0#&%O)5@%$();

q41ry)#B1
?)!$#&%o1-EG'&)'&#&!2E
'&!$#&5). 1-EG
'&!$#&5). 1-EG3
5).0?^#B1#&%
3D0%$%
()#&!21-EG'&D0#B,+#&D0+5
()#&A)41. 1.0%
();9)%G#BEo,+;41#&%2EGX
(^A^;
.0;);%$A+()#&!$#
.0!$.0%
t:!2Eo,^%oEGtJA
D0?^;!
D0#B1-1#&!
A)!$;>r;41#&!$%2EGS[T
!$.0?^;%$;>*#BEG?+.0)5
%$41#&D0D0. 1#
%$#&3>*#&141.0;
%$.0'

%$;)!
%$;$^?^#&
%$A)D0.0'&#
,+#&().0'&D0#

1()#'&;>*A)D0#B1#q!$#&%$9+D 1%<N;!1()#F+!$%21w%G#B1q;<#BA^#&!$.0>*#&1%9+%$#&5d.071().0%OA)A^#&!$b

H!$!
[b0
Qb0X
`b0S
`[b0S
[Xb0T
QXb0T
`{b0Q
b0S
Tb0
Sb0
b0[
`b0[
Tb0Q
QXb0{
b0[
Sb0[
Q[b0{
Tb0T
b0S
QTb0T
Sb0`
b0
`b0S

y+.0)3D0#
y)
{b0[
{b0
{b0X
{b0S
Qb0
Qb0{
Qb0T
{b0T
{b0`
Qb0[
Qb0
{b0
Qb0
{b0[
{b0T
{b0
{b0[
{b0
{b0
Qb0
Qb0Q
{b0`
Qb0`

MO#&%21
`b0S
Q[b0T
`Tb0`
``b0T
[Tb0S
QTb0X
QSb0Q
b0Q
Tb0`
b0
`b0{
Qb0
[b0
Qb0T
b0
Xb0S
Q`b0T
b0
b0`
Qb0S
b0{
b0
``b0S

.0>rA)D0#
)
H!G!
y)
[b0
{b0`
Q[b0
{b0
`b0
{b0`
`[b0{
{b0
[b0`
Qb0Q
Qb0
Qb0Q
QSb0
Qb0
b0X
{b0`
Tb0`
{b0Q
b0
{b0
[b0S
{b0[
{b0X
{b0Q
[b0`
{b0X
Q`b0X
{b0`
b0X
{b0[
Xb0
{b0[
Q{b0S
{b0`
b0[
{b0[
b0
{b0`
Qb0S
Qb0`
Tb0
{b0
b0{
{b0`
`Qb0`
{b0X

33.0)3

!$!
y)
[b0
{b0`
Q[b0X
{b0T
`b0`
{b0
``b0X
{b0
[[b0Q
Qb0S
Qb0{
{b0T
Qb0X
{b0
b0Q
{b0`
Tb0`
{b0Q
Sb0`
Qb0`
b0{
{b0
{b0X
{b0`
b0`
Qb0{
Q{b0
{b0[
b0{
{b0[
Xb0
{b0
Q{b0T
{b0[
b0
{b0`
b0
{b0Q
QTb0X
Qb0Q
Tb0S
{b0
[b0S
{b0Q
`{b0
{b0T

!$'&.0)3
w
H!$!
y)
[b0X
{b0
Qb0X
{b0T
`b0`
{b0X
`b0
{b0`
[`b0{
`b0
`{b0
Qb0T
QSb0{
Qb0[
b0Q
{b0
Tb0`
{b0Q
b0T
{b0T
[b0
{b0T
{b0
{b0Q
[b0`
{b0X
b0
{b0
b0
{b0`
Xb0Q
{b0`
Sb0S
{b0`
[b0
{b0`
b0
{b0`
Q`b0S
Qb0
Tb0
{b0
b0{
{b0Q
QSb0Q
Qb0{

;J;%o1.0)3

H!G!
y)
b0{
{b0
Qb0
{b0T
`b0[
{b0Q
`[b0[
Qb0`
[Qb0Q
{b0S
`Qb0Q
{b0S
QSb0
{b0S
b0[
{b0
Tb0`
{b0Q
Xb0[
{b0
[b0S
Qb0{
{b0[
{b0Q
[b0`
{b0X
b0T
{b0Q
b0T
{b0[
Xb0`
{b0[
Q{b0{
{b0[
[b0[
{b0`
b0
{b0[
Q[b0{
Qb0
Tb0[
{b0T
b0`
{b0Q
QSb0
Qb0{

cR?)D0#}}w#&9)!$D)#B1 ;!$t*1#&%21*%$#B1C#&!$!$;!q!$41#&%)5%21)5+!$55+#B,^.041.0;@,D09)#&%<N;!H1(+;%$##&!G!$;!
!$41#&%<N;!7LNQaK%$.0)3D0#q)#&9)!GD+#B1 ;!$tr'&D0%$%G.0F)#&!$UHLN`aK%$.0>*A)D0#q)#&9+!$D+#B1 ;!$td#&+%$#&>qE
?)D0#&UwLN[a}IM33.0+3m#&)%$#&>?)D0#&UwLNaw!$'&.0)3I#&)%G#&>?)D0#&U)5]LNa)5w5)4EGMO;J;%21.0+3
#&)%G#&>?)D0#&b=D0%$;K%$(+; 6LN!$#&%$9+D 1%'&;D09)>*I[a.0%R1()#C4?#&%o1!G#&%$9)D 1}A)!$;:5)9)'&#&5@<!G;>D0D;<
1()#7%$.0)3D0#})#B1 ;!Gt@!G#&%$9)D 1%W!$9+/9)%$.0)3CD0D;<1()#1!G.0).0)3*5)41b

*

fi

q41ry)#B1
?)!$#&%o1-EG'&)'&#&!2E
'&!$#&5). 1-EG
'&!$#&5). 1-EG3
5).0?^#B1#&%
3D0%$%
()#&!21-EG'&D0#B,+#&D0+5
()#&A)41. 1.0%
();9)%G#BEo,+;41#&%2EGX
(^A^;
.0;);%$A+()#&!$#
.0!$.0%
t:!2Eo,^%oEGtJA
D0?^;!
D0#B1-1#&!
A)!$;>r;41#&!$%2EGS[T
!$.0?^;%$;>*#BEG?+.0)5
%$41#&D0D0. 1#
%$#&3>*#&141.0;
%$.0'

%$;)!
%$;$^?^#&
%$A)D0.0'&#
,+#&().0'&D0#

!$!
b0{
Qb0S
`Sb0T
`b0X
[Qb0[
`b0[
`Qb0`
[b0T
{b0
Xb0Q
b0`
{b0T
QTb0
Qb0{
Q`b0X
QQb0`
Q[b0X
[b0
Qb0[
`Sb0
Xb0{
b0S
`Sb0

y+.0)3D0#
y)
{b0
{b0X
Qb0{
Qb0{
`b0Q
Qb0[
Qb0`
{b0[
{b0Q
{b0
{b0
{b0Q
[b0
{b0X
{b0
{b0T
{b0
{b0`
{b0S
Qb0S
{b0
{b0[
{b0

stv{wz{y{t

33.0)3

H!$!
y+
[b0
{b0
Q[b0
{b0
`b0`
{b0
`b0
{b0X
`b0X
{b0
QSb0
{b0
Qb0[
`b0{
[b0T
{b0`
{b0
{b0{
Tb0
{b0T
b0S
{b0X
{b0T
{b0Q
Q[b0
{b0X
b0{
{b0Q
Q{b0T
{b0T
Q{b0`
{b0Q
Sb0S
{b0`
[b0{
{b0`
Qb0`
{b0Q
`b0[
Qb0[
b0S
{b0
b0
{b0`
`b0Q
{b0S

MO#&%21
b0{
Qb0`
`Xb0
`Tb0
`Xb0
``b0
`{b0{
[b0`
{b0
b0Q
b0[
{b0
Q`b0
Q`b0`
Q`b0
Q{b0X
Q[b0
[b0
Qb0Q
`Tb0S
b0
b0
`Xb0T

!$'&.0)3
w
!$!
y)
[b0
{b0T
Qb0{
{b0S
`b0S
Qb0{
`Tb0{
{b0T
`b0
Qb0
`Qb0
Qb0T
QTb0S
Qb0Q
b0{
Qb0Q
{b0
{b0Q
Tb0{
{b0
b0Q
{b0T
{b0[
{b0Q
Q[b0{
`b0S
b0Q
{b0Q
Tb0X
{b0
Sb0[
{b0`
Xb0T
{b0Q
Qb0
{b0`
Qb0Q
{b0Q
`Qb0
[b0{
b0`
{b0`
b0Q
{b0Q
``b0
{b0X

;:;%21.0)3

H!$!
y)
[b0
{b0[
Q[b0
{b0
`Tb0
{b0
`b0
{b0T
`[b0[
Qb0[
`{b0X
Qb0{
Qb0`
Qb0[
b0X
Qb0{
{b0
{b0{
Tb0Q
{b0
b0T
Qb0Q
{b0
{b0{
QQb0T
`b0{
[b0S
{b0Q
Tb0
{b0[
Sb0T
{b0
Xb0
{b0`
Qb0
{b0`
Qb0{
{b0Q
`Qb0
`b0X
Tb0
{b0S
b0[
{b0`
``b0S
Qb0S

cR?)D0#}}q#&'&.0%$.0;1!$#&#*1#&%21%$#B1#&!$!$;!d!$41#&%d+5g%21)5)!G5]5)#B,.041.0;6,D09)#&%@<;!}1();%$#m#&!G!$;!
!$41#&%O<N;!qLNQa7%G.0)3D0#5+#&'&.0%$.0;}1!G#&#'&D0%$%G.0F)#&!$UZLN`aMO33.0)3K#&)%$#&>?)D0#&UZLN[a@w!$'&.0)3
#&)%G#&>?)D0#&U)5LNaq)55)4EGMO;:;%21.0)3I#&)%$#&>?)D0#&bD0%G;d%$(+; LN!$#&%$9)D 1%w'&;D09)>*[aw.0%
1()#m4?^#&%21/!$#&%G9)D 1*A)!$;:5)9)'&#&5<!$;>D0D_;<1()#K%$.0)3D0#w1!$#&#C!G#&%$9)D 1%q!$9)9)%$.0+3@D0D_;<1()#
1!$.0+.0)3*5)41b

Z

*

fiJournal Artificial Intelligence Research 11 (1999) 95-130

Submitted 3/98; published 7/99

Semantic Similarity Taxonomy: Information-Based
Measure Application Problems Ambiguity
Natural Language
Philip Resnik

resnik@umiacs.umd.edu

Department Linguistics
Institute Advanced Computer Studies
University Maryland
College Park, MD 20742 USA

Abstract

article presents measure semantic similarity is-a taxonomy based
notion shared information content. Experimental evaluation benchmark
set human similarity judgments demonstrates measure performs better
traditional edge-counting approach. article presents algorithms take advantage taxonomic similarity resolving syntactic semantic ambiguity, along
experimental results demonstrating effectiveness.

1. Introduction
Evaluating semantic relatedness using network representations problem long
history artificial intelligence psychology, dating back spreading activation
approach Quillian (1968) Collins Loftus (1975). Semantic similarity represents
special case semantic relatedness: example, cars gasoline would seem
closely related than, say, cars bicycles, latter pair certainly similar.
Rada et al. (Rada, Mili, Bicknell, & Blettner, 1989) suggest assessment similarity
semantic networks fact thought involving taxonomic (is-a) links,
exclusion link types; view also taken here, although admittedly
links part-of also viewed attributes contribute similarity (cf.
Richardson, Smeaton, & Murphy, 1994; Sussna, 1993).
Although many measures similarity defined literature, seldom
accompanied independent characterization phenomenon measuring,
particularly measure proposed service computational application (e.g.,
similarity documents information retrieval, similarity cases case-based reasoning).
Rather, worth similarity measure utility given task. cognitive
domain, similarity treated property characterized human perception intuition,
much way notions like \plausibility" \typicality." such, worth
similarity measure fidelity human behavior, measured predictions
human performance experimental tasks. latter view underlies work
article, although results presented comprise direct comparison human
performance also practical application problems natural language processing.
natural, time-honored way evaluate semantic similarity taxonomy measure
distance nodes corresponding items compared | shorter

c 1999 AI Access Foundation Morgan Kaufmann Publishers. rights reserved.

fiResnik

path one node another, similar are. Given multiple paths, one
takes length shortest one (Lee, Kim, & Lee, 1993; Rada & Bicknell, 1989; Rada
et al., 1989).
widely acknowledged problem approach, however, relies
notion links taxonomy represent uniform distances. Unfortunately, uniform
link distance dicult define, much less control. real taxonomies, wide
variability \distance" covered single taxonomic link, particularly certain
sub-taxonomies (e.g., biological categories) much denser others. example,
WordNet (Miller, 1990; Fellbaum, 1998), widely used, broad-coverage semantic network
English, dicult find links cover intuitively narrow distance
(rabbit ears is-a television antenna) intuitively wide one (phytoplankton
is-a living thing). kinds examples found Collins COBUILD
Dictionary (Sinclair, ed., 1987), identifies superordinate terms many words (e.g.,
safety valve is-a valve seems much narrower knitting machine is-a machine).
first part article, describe alternative way evaluate semantic similarity taxonomy, based notion information content. Like edge-counting
method, conceptually quite simple. However, sensitive problem
varying link distances. addition, combining taxonomic structure empirical
probability estimates, provides way adapting static knowledge structure multiple contexts. Section 2 sets probabilistic framework defines measure
semantic similarity information-theoretic terms, Section 3 presents evaluation
similarity measure human similarity judgments, using simple edge-counting
method baseline.
second part article, Sections 4 5, describe two applications semantic
similarity problems ambiguity natural language. first concerns particular
case syntactic ambiguity involves coordination nominal compounds,
pernicious source structural ambiguity English. Consider phrase food
handling storage procedures: represent conjunction food handling storage
procedures, refer handling storage food? second application
concerns resolution word sense ambiguity | words running text,
large open problem (though cf. Wilks & Stevenson, 1996), groups related words
often discovered distributional analysis text corpora found dictionaries
thesauri. Finally, Section 6 discusses related work.

2. Similarity Information Content

Let C set concepts is-a taxonomy, permitting multiple inheritance. Intuitively,
one key similarity two concepts extent share information, indicated is-a taxonomy highly specific concept subsumes both.
edge-counting method captures indirectly, since minimal path is-a links two nodes long, means necessary go high taxonomy,
abstract concepts, order find least upper bound. example, WordNet, nickel
dime subsumed coin, whereas specific superclass nickel
credit card share medium exchange (see Figure 1). feature-based setting
(e.g., Tversky, 1977), would ected explicit shared features: nickels dimes
96

fiInformation-Based Semantic Similarity

MEDIUM EXCHANGE
MONEY
CASH

CREDIT

COIN
NICKEL

DIME

CREDIT CARD

Figure 1: Fragment WordNet taxonomy. Solid lines represent is-a links; dashed lines
indicate intervening nodes omitted save space.
small, round, metallic, on. features captured implicitly
taxonomy categorizing nickel dime subordinates coin.
associating probabilities concepts taxonomy, possible capture
idea edge-counting, avoiding unreliability edge distances. Let
taxonomy augmented function p : C ! [0; 1], c 2 C , p(c)
probability encountering instance concept c. implies p monotonically
nondecreasing one moves taxonomy: c1 is-a c2, p(c1 ) p(c2). Moreover,
taxonomy unique top node probability 1.
Following standard argumentation information theory (Ross, 1976), information content concept c quantified negative log likelihood, , log p(c).
Notice quantifying information content way makes intuitive sense setting: probability increases, informativeness decreases; abstract concept,
lower information content. Moreover, unique top concept, information
content 0.
quantitative characterization information provides new way measure semantic similarity. information two concepts share, similar are,
information shared two concepts indicated information content concepts
subsume taxonomy. Formally, define
max [, log p(c)] ;
sim(c1; c2) =
(1)
c 2 (c1 ; c2)

(c1; c2) set concepts subsume c1 c2. class achieves
maximum value Equation 1 termed informative subsumer; often
unique informative subsumer, although need true general case.
Taking maximum respect information content analogous taking first
intersection semantic network marker-passing shortest path respect edge
distance (cf. Quillian, 1968; Rada et al., 1989); generalization taking maximum
taking weighted average introduced Section 3.4.
Notice although similarity computed considering upper bounds two
concepts, information measure effect identifying minimal upper bounds, since
class less informative superordinates. example, Figure 1, coin, cash,
etc. members (nickel; dime), concept structurally minimal
97

fiResnik

PERSON
p=.2491
info=2.005

ADULT
p=.0208
info=5.584

FEMALE_PERSON
p=.0188
info=5.736

PROFESSIONAL
p=.0079
info=6.993

ACTOR1
p=.0027
info=8.522

INTELLECTUAL
p=.0113
info=6.471

DOCTOR2
p=.0005
info=10.84

NURSE2
p=.0001
info=13.17

HEALTH_PROFESSIONAL
p=.0022
info=8.844

DOCTOR1
p=.0018
info=9.093

GUARDIAN
p=.0058
info=7.434

LAWYER
p=.0007
info=10.39

NURSE1
p=.0001
info=12.94

Figure 2: Another fragment WordNet taxonomy
upper bound, coin, also informative. make difference cases
multiple inheritance: two distinct ancestor nodes may minimal upper bounds,
measured using distance graph, two nodes might different
values information content. Also notice is-a taxonomies WordNet,
multiple sub-taxonomies unique top node, asserting zero similarity
concepts separate sub-taxonomies (e.g., liberty, aorta) equivalent unifying
sub-taxonomies creating virtual topmost concept.
practice, one often needs measure word similarity , rather concept similarity.
Using s(w) represent set concepts taxonomy senses word w,
define
wsim(w1; w2) = cmax
(2)
1; c2 [sim(c1; c2)] ;

c1 ranges s(w1) c2 ranges s(w2). consistent Rada et al.'s
(1989) treatment \disjunctive concepts" using edge-counting: define distance
two disjunctive sets concepts minimum path length element
first set element second. Here, word similarity judged taking
maximal information content concepts words could instance. take example, consider word similarity wsim(doctor, nurse) would
computed, using taxonomic information Figure 2. (Note noun senses
considered here.) Equation 2, must consider pairs concepts hc1; c2i,
c1 2 fdoctor1; doctor2g c2 2 fnurse1; nurse2g, pair must
compute semantic similarity sim(c1 ,c2) according Equation 1. Table 1 illustrates
computation.
98

fiInformation-Based Semantic Similarity

c1 (description)

c2 (description)

sim(c1 ,c2)
doctor1 (medical) nurse1 (medical) health professional
8.844
doctor1 (medical) nurse2 (nanny)
person
2.005
doctor2 (Ph.D.) nurse1 (medical)
person
2.005
doctor2 (Ph.D.) nurse2 (nanny)
person
2.005
subsumer

Table 1: Computation similarity doctor nurse
table shows, senses doctor considered senses
nurse, maximum value 8.844, via health professional informative
subsumer; is, therefore, value word similarity doctor nurse.1

3. Evaluation

section describes simple, direct method evaluating semantic similarity, using
human judgments basis comparison.

3.1 Implementation

work reported used WordNet's taxonomy concepts represented nouns (and
compound nominals) English.2 Frequencies concepts taxonomy estimated
using noun frequencies Brown Corpus American English (Francis & Kucera,
1982), large (1,000,000 word) collection text across genres ranging news articles
science fiction. noun occurred corpus counted occurrence
taxonomic class containing it.3 example, Figure 1, occurrence noun
dime would counted toward frequency dime, coin, cash, forth. Formally,
X
freq(c) =
count(n);
(3)
n2words(c)
words(c) set words subsumed concept c. Concept probabilities
computed simply relative frequency:
(4)
p^(c) = freq(c) ;

N

N total number nouns observed (excluding subsumed
WordNet class, course). Naturally frequency estimates Equation 3 would
1. taxonomy Figure 2 fragment WordNet version 1.6, showing real quantitative information
computed using method described below. \nanny" sense nurse (nursemaid, woman
custodian children) primarily British usage. example omits two senses doctor
WordNet: theologian Roman Catholic Church, game played children. WordNet
use node labels like doctor1, created labels sake readability.
2. Concept used refers Miller et al. (1990) call synset, essentially node taxonomy.
experiment reported section used noun taxonomy WordNet version 1.4,
approximately 50,000 nodes.
3. Plural nouns counted instances singular forms.

99

fiResnik

improved taking account intended sense noun corpus |
example, instance crane bird machine, both. Sense-tagged
corpora generally available, however, frequency estimates done using
weaker generally applicable technique.
noted present method associating probabilities concepts
taxonomy based notion single random variable ranging concepts
| case, \credit" noun occurrence would distributed
concepts noun, counts normalized across entire taxonomy sum 1.
(That approach taken Resnik, 1993a, also see Resnik, 1998b discussion.)
assigning taxonomic probabilities purposes measuring semantic similarity, present
model associates separate, binomially distributed random variable concept.4
is, perspective given concept c, observed noun either
instance concept, probabilities p(c) 1 , p(c), respectively. Unlike
model single multinomial variable ranging entire set concepts,
formulation assigns probability 1 top concept taxonomy, leading
desirable consequence information content zero.

3.2 Task

Although standard way evaluate computational measures semantic similarity, one reasonable way judge would seem agreement human similarity ratings.
assessed using computational similarity measure rate similarity
set word pairs, looking well ratings correlate human ratings
pairs.
experiment Miller Charles (1991) provided appropriate human subject data
task. study, 38 undergraduate subjects given 30 pairs nouns
chosen cover high, intermediate, low levels similarity (as determined using
previous study, Rubenstein & Goodenough, 1965), subjects asked
rate \similarity meaning" pair scale 0 (no similarity) 4 (perfect
synonymy). average rating pair thus represents good estimate similar
two words are, according human judgments.5
order get baseline comparison, replicated Miller Charles's experiment,
giving ten subjects 30 noun pairs. subjects computer science graduate
students postdoctoral researchers University Pennsylvania, instructions
exactly used Miller Charles, main difference
replication subjects completed questionnaire electronic mail (though
instructed complete whole task single uninterrupted sitting). Five subjects
received list word pairs random order, five received list
reverse order. correlation Miller Charles mean ratings mean
ratings replication .96, quite close .97 correlation Miller Charles
obtained results ratings determined earlier study.
4. similar spirit way probabilities used Bayesian network.
5. anonymous reviewer points human judgments task may uenced prototypicality, e.g., pair bird/robin would likely yield higher ratings bird/crane. Issues kind
brie touched Section 6, part ignored since prototypicality, like
topical relatedness, captured is-a taxonomies.

100

fiInformation-Based Semantic Similarity

subject replication, computed well ratings correlated
Miller Charles ratings. average correlation 10 subjects
r = 0:88, standard deviation 0.08.6 value represents upper bound
one expect computational attempt perform task.
purposes evaluation, three computational similarity measures used.
first similarity measurement using information content proposed previous section. second variant edge-counting method, converting distance
similarity subtracting path length maximum possible path length:


wsimedge (w1; w2) = (2 max) , cmin
len(c1; c2)
;c
1

2



(5)

c1 ranges s(w1), c2 ranges s(w2), max maximum depth taxonomy, len(c1; c2) length shortest path c1 c2 . (Recall s(w)
denotes set concepts taxonomy represent senses word w.) senses
w1 w2 separate sub-taxonomies WordNet similarity taken
zero. Note correlation used evaluation metric, conversion
distance similarity viewed expository convenience, affect
results: although sign correlation coecient changes positive negative,
magnitude turns regardless whether minimum path
length subtracted (2 max).
third point comparison measure simply uses probability concept,
rather information content, define semantic similarity concepts
max [1 , p(c)]
simp(c)(c1; c2) =
(6)
c 2 (c1 ; c2)

corresponding measure word similarity:

h



wsimp(c)(w1; w2) = cmax
simp(c)(c1; c2) ;
;c
1

2

(7)

c1 ranges s(w1) c2 ranges s(w2) Equation 7. probability-based
similarity score included order assess extent similarity judgments might
sensitive frequency per se rather information content. Again, difference
maximizing 1 , p(c) minimizing p(c) turns affect magnitude
correlation. simply ensures value interpreted similarity value,
high values indicating similar words.

3.3 Results

Table 2 summarizes experimental results, giving correlation similarity
ratings mean ratings reported Miller Charles. Note that, owing noun
missing WordNet 1.4 taxonomy, possible obtain computational
similarity ratings 28 30 noun pairs; hence proper point comparison
human judgments correlation 30 items (r = :88), rather correlation
28 included pairs (r = :90). similarity ratings item given Table 3.
6. Inter-subject correlation replication, estimated using leaving-one-out resampling (Weiss & Kulikowski, 1991), r = :90; stdev = 0:07.

101

fiResnik

Similarity method
Correlation
Human judgments (replication) r = :9015
Information content
r = :7911
Probability
r = :6671
Edge-counting
r = :6645
Table 2: Summary experimental results.
Word Pair
car
gem
journey
boy
coast
asylum
magician
midday
furnace
food
bird
bird
tool
brother
crane
lad
journey
monk
food
coast
forest
monk
coast
lad
chord
glass
noon
rooster

automobile
jewel
voyage
lad
shore
madhouse
wizard
noon
stove
fruit
cock
crane
implement
monk
implement
brother
car
oracle
rooster
hill
graveyard
slave
forest
wizard
smile
magician
string
voyage

Miller Charles Replication
wsim wsimedge wsimp(c)
means
means
3.92
3.9 8.0411
30 0.9962
3.84
3.5 14.9286
30 1.0000
3.84
3.5 6.7537
29 0.9907
3.76
3.5 8.4240
29 0.9971
3.70
3.5 10.8076
29 0.9994
3.61
3.6 15.6656
29 1.0000
3.50
3.5 13.6656
30 0.9999
3.42
3.6 12.3925
30 0.9998
3.11
2.6 1.7135
23 0.6951
3.08
2.1 5.0076
27 0.9689
3.05
2.2 9.3139
29 0.9984
2.97
2.1 9.3139
27 0.9984
2.95
3.4 6.0787
29 0.9852
2.82
2.4 2.9683
24 0.8722
1.68
0.3 2.9683
24 0.8722
1.66
1.2 2.9355
26 0.8693
1.16
0.7 0.0000
0 0.0000
1.10
0.8 2.9683
24 0.8722
0.89
1.1 1.0105
18 0.5036
0.87
0.7 6.2344
26 0.9867
0.84
0.6 0.0000
0 0.0000
0.55
0.7 2.9683
27 0.8722
0.42
0.6 0.0000
0 0.0000
0.42
0.7 2.9683
26 0.8722
0.13
0.1 2.3544
20 0.8044
0.11
0.1 1.0105
22 0.5036
0.08
0.0 0.0000
0 0.0000
0.08
0.0 0.0000
0 0.0000
Table 3: Semantic similarity item.
102

fiInformation-Based Semantic Similarity

n1
tobacco
tobacco
tobacco

n2
wsim(n1 ,n2) subsumer
alcohol
7.63
drug
sugar
3.56 substance
horse
8.26 narcotic

Table 4: Similarity tobacco computed maximizing information content

3.4 Discussion

experimental results previous section suggest measuring semantic similarity
using information content provides results better traditional method
simply counting number intervening is-a links.
measure without problems, however. Like simple edge-counting,
measure sometimes produces spuriously high similarity measures words basis
inappropriate word senses. example, Table 4 shows word similarity several words
tobacco. Tobacco alcohol similar, drugs, tobacco sugar
less similar, though entirely dissimilar, since classified substances.
problem arises, however, similarity rating tobacco horse: word horse
used slang term heroin, result information-based similarity maximized,
path length minimized, two words categorized narcotics.
contrary intuition.
Cases like probably relatively rare. However, example illustrates
general concern: measuring similarity words, really relationship among
word senses matters, similarity measure able take account.
absence reliable algorithm choosing appropriate word senses,
straightforward way information-based setting consider concepts
nouns belong rather taking single maximally informative class.
suggests defining measure weighted word similarity follows:
wsimff(w1; w2) =

X



ff(ci)[, log p(ci)];

(8)

fcig set concepts dominating w1 w2 sense either word,
ff weighting function concepts Pi ff(ci) = 1. measure similarity

takes information account previous one: rather relying
single concept maximum information content, allows class representing shared
properties contribute information content according value ff(ci). Intuitively,
ff values measure relevance. example, computing wsimff (tobacco,horse),
ci would range concepts tobacco horse instances, including
narcotic, drug, artifact, life form, etc. everyday context one might expect low
values ff(narcotic) ff(drug), context of, say, newspaper article
drug dealers, weights concepts might quite high. Although possible
include weighted word similarity comparison Section 3, since noun pairs
judged without context, Section 4 provides discussion weighting function ff
designed particular natural language processing task.
103

fiResnik

4. Using Taxonomic Similarity Resolving Syntactic Ambiguity

considered direct evaluation information-based semantic similarity measure,
turn application measure resolving syntactic ambiguity.

4.1 Clues Resolving Coordination Ambiguity

Syntactic ambiguity pervasive problem natural language. Church Patil
(1982) point out, class \every way ambiguous" syntactic constructions |
number analyses number binary trees terminal elements |
includes frequent constructions prepositional phrases, coordination, nominal
compounds. last several years, researchers natural language made great
deal progress using quantitative information text corpora provide needed
constraints. Progress broad-coverage prepositional phrase attachment ambiguity
particularly notable, dominant approach shifted structural
strategies quantitative analysis lexical relationships (Whittemore, Ferrara, & Brunner,
1990; Hindle & Rooth, 1993; Brill & Resnik, 1994; Ratnaparkhi & Roukos, 1994; Li & Abe,
1995; Collins & Brooks, 1995; Merlo, Crocker, & Berthouzoz, 1997). Noun compounds
received comparatively less attention (Kobayasi, Takunaga, & Tanaka, 1994; Lauer, 1994,
1995), problem coordination ambiguity (Agarwal & Boggess, 1992; Kurohashi
& Nagao, 1992).
section, investigate role semantic similarity resolving coordination
ambiguities involving nominal compounds. began noun phrase coordinations
form n1 n2 n3, admit two structural analyses, one n1 n2
two noun phrase heads conjoined (1a) one conjoined heads n1
n3 (1b).
(1) a. (bank warehouse) guard
b. (policeman) (park guard)
Identifying two head nouns conjoined necessary order arrive correct
interpretation phrase's content. example, analyzing (1b) according structure (1a) could lead machine translation system produce noun phrase describing
somebody guards policemen parks. Analyzing (1a) according structure (1b) could lead information retrieval system miss phrase looking
queries involving term bank guard.
Kurohashi Nagao (1992) point similarity form similarity meaning
important cues conjoinability. English, similarity form great extent
captured agreement number (singular vs. plural):
(2)

a. several business university groups
b. several businesses university groups
Similarity form candidate conjoined heads thus thought Boolean
variable: number agreement either satisfied candidate heads not.
Similarity meaning conjoined heads also appears play important role:
(3)

a. television radio personality
104

fiInformation-Based Semantic Similarity

b. psychologist sex researcher
Clearly television radio similar television personality; correspondingly psychologist researcher. similarity meaning captured well semantic
similarity taxonomy, thus second variable consider evaluating coordination structure semantic similarity measured overlap information content
two head nouns.
addition, constructions considered here, appropriateness noun-noun
modification relevant:
(4)

a. mail securities fraud
b. corn peanut butter

One reason prefer conjoin mail securities mail fraud salient compound
nominal phrase. hand, corn butter familiar concept; compare
change perceived structure phrase corn peanut crops. order measure
appropriateness noun-noun modification, use quantitative measure selectional
fit called selectional association (Resnik, 1996), takes account lexical cooccurrence frequencies semantic class membership WordNet taxonomy. Brie y,
selectional association word w WordNet class c given
p(cjw) log p(cjw)
A(w; c) = D(p(C jw) k p(p(Cc) ))

(9)

D(p1 k p2) Kullback-Leibler distance (relative entropy) probability
distributions p1 p2. Intuitively, A(w, c) measuring extent class c
predicted word w; example, A(wool, clothing) would higher value than,
say, A(wool, person). selectional association A(w1; w2) two words defined
maximum A(w1; c) taken classes c w2 belongs. example,
A(wool, glove) would likely equal A(wool, clothing), compared to, say,
A(wool, sports equipment) | latter value corresponding sense glove
something used baseball boxing. (See Li & Abe, 1995, approach
selectional relationships modeled using conditional probability.) simple way treat
selectional association variable resolving coordination ambiguities prefer analyses include noun-noun modifications strong anities (e.g., bank modifier
guard) disprefer weak noun-noun relationships (e.g., corn modifier
butter). Thresholds defining \strong" \weak" parameters algorithm, defined
below.

4.2 Resolving Coordination Ambiguity: First Experiment

investigated roles sources evidence conducting straightforward disambiguation experiment using naturally occurring linguistic data. Two sets 100 noun
phrases form [NP n1 n2 n3] extracted parsed Wall Street Journal
(WSJ) corpus, found Penn Treebank (Marcus, Santorini, & Marcinkiewicz, 1993).
disambiguated hand, one set used development
105

fiResnik

Source evidence Conjoined Condition
Number agreement n1 n2 number(n1) = number(n2) number(n1) 6= number(n3)
n1 n3 number(n1) = number(n3) number(n1) 6= number(n2)
undecided otherwise
Semantic similarity n1 n2 wsim(n1,n2) > wsim(n1,n3)
n1 n3 wsim(n1,n3) > wsim(n1,n2)
undecided otherwise
Noun-noun
n1 n2 A(n1,n3) > A(n3,n1) >
modification
n1 n3 A(n1,n3) < A(n3,n1) <
undecided otherwise

Table 5: Rules number agreement, semantic similarity, noun-noun modification
resolving syntactic ambiguity noun phrases n1 n2 n3
testing.7 set simple transformations applied WSJ data, including mapping proper names token someone, expansion month abbreviations,
reduction nouns root forms.
Number agreement determined using simple analysis suxes combination
WordNet's lists root nouns irregular plurals.8 Semantic similarity determined using information-based measure Equation (2) | noun class probabilities
Equation (1) estimated using sample approximately 800,000 noun occurrences
Associated Press newswire stories.9 purpose determining semantic similarity,
nouns WordNet treated instances class hthingi. Appropriateness
noun-noun modification determined computing selectional association (Equation 9),
using co-occurrence frequencies taken sample approximately 15,000 noun-noun
compounds extracted WSJ corpus. (This sample include test data.)
selection modifier head selection head modifier
considered disambiguation algorithm. Table 5 provides details decision rule
source evidence used independently.10
addition, investigated several methods combining three sources information. included: (a) simple form \backing off" (specifically, given number
agreement, noun-noun modification, semantic similarity strategies order, use
choice given first strategy isn't undecided); (b) taking vote among
three strategies choosing majority; (c) classifying using results linear re7. Hand disambiguation necessary Penn Treebank encode NP-internal structure.
phrases disambiguated using full sentence occurred, plus previous
following sentence, context.
8. experiments section used WordNet version 1.2.
9. grateful Donald Hindle making data available.
10. Thresholds = 2:0 = 0:0 fixed manually based experience development set
evaluating test data.

106

fiInformation-Based Semantic Similarity

Strategy

Default
Number agreement
Noun-noun modification
Semantic similarity
Backing
Voting
Number agreement + default
Noun-noun modification + default
Semantic similarity + default
Backing + default
Voting + default
Regression
ID3 Tree

Coverage (%) Accuracy (%)

100.0
53.0
75.0
66.0
95.0
89.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0

66.0
90.6
69.3
71.2
81.1
78.7
82.0
65.0
72.0
81.0
76.0
79.0
80.0

Table 6: Syntactic disambiguation items form n1 n2 n3
gression; (d) constructing decision tree classifier. latter two methods forms
supervised learning; experiment development set used training data.11
results shown Table 6. development set contained bias favor
conjoining n1 n2; therefore \default" strategy, always choosing bracketing,
used baseline comparison. default also used resolving undecided cases
order make comparisons individual strategies 100% coverage. example,
\Number agreement + default" shows figures obtained number agreement
used make choice default selected choice undecided.
surprisingly, individual strategies perform reasonably well instances
classify, coverage poor; strategy based similarity form highly
accurate, arrives answer half time. However, heavy priori bias makes
difference | extent even though forms evidence
value, combination beats number-agreement-plus-default combination.
positive side, shows ambiguity resolved reasonably well using
simple algorithm: viewed terms many errors made, number agreement makes
possible cut baseline 34% error rate nearly half 18% incorrect analyses (a
44% reduction). negative side, results fail make strong case semantic
similarity add something useful.
taking issue, let us assess contributions individual strategies
results evidence combined, analyzing behavior unsupervised
evidence combination strategies. combining evidence voting, choice made
89 cases. number agreement strategy agreed majority vote 57 cases,
43 (75.4%) correct; noun-noun modification strategy agreed
majority 73 cases, 50 (68.5%) correct; semantic similarity strategy
11. calling \backing off" related spirit Katz's well known smoothing technique (Katz,
1987), \backing off" strategy used quantitative. retain double quotes order
highlight distinction.

107

fiResnik

agreed majority 58 cases, 43 (74.1%) correct. \backing off"
form evidence combination, number agreement makes choice 53 cases correct
48 (90.6%); then, remaining undecided, noun-noun modification makes choice
35 cases correct 24 (68.6%); then, still undecided, semantic similarity
makes choice 7 cases 5 correct (71.4%); remaining 5 cases
undecided.
analysis above-baseline performance semantic-similarity-plus-default
strategy show semantic similarity contain information correct answer:
agrees majority vote substantial portion time, selects correct
answers often one would expect default cases receives
\backing off." However, default correct two thirds time,
number agreement strategy correct nine ten times cases decide,
potential contribution semantic similarity remains suggestive rather conclusive.
second experiment, therefore, investigated dicult formulation problem
order obtain better assessment.

4.3 Resolving Coordination Ambiguity: Second Experiment

second experiment using data sources, investigated complex set
coordinations, looking noun phrases form n0 n1 n2 n3. syntactic
analyses phrases characterized top-level binary choice data
previous experiment, either conjoining heads n1 n2 (5) conjoining n1
n3 (6).12
(5) a. freshman ((business marketing) major)
b. (food (handling storage)) procedures
c. ((mail fraud) bribery) charges
(6)

a. Clorets (gum (breath mints))
b. (baby food) (puppy chow)

experiment, one set 89 items extracted Penn Treebank WSJ data
development, another set 89 items set aside testing. development
set showed significantly less bias data previous experiment, 53.9%
items conjoining n1 n2.
disambiguation strategies experiment refined version
used previous experiment, illustrated Table 7. Number agreement used
before. However, rather employing semantic similarity noun-noun modification
independent strategies | something clearly warranted given lackluster performance modification strategy | two combined measure weighted
semantic similarity defined Equation (8). Selectional association used basis
ff. particular, ff1;2(c) greater A(n0,c) A(n3,c), capturing fact
n1 n2 conjoined, combined phrase potentially stands head-modifier
relationship n0 modifier-head relationship n3 . Correspondingly, ff1;3(c)
greater A(n0,c) A(n2,c), capturing fact coordination n1
12. full 5-way classification problem structures (5) (6) investigated.

108

fiInformation-Based Semantic Similarity

Source evidence Conjoined Condition
Number agreement n1 n2 number(n1) = number(n2) number(n1) 6= number(n3)
n1 n3 number(n1) = number(n3) number(n1) 6= number(n2)
undecided otherwise
Weighted semantic n1 n2 wsimff1 2 (n1,n2) > wsimff1 3 (n1,n3)
similarity
n1 n3 wsimff1 3 (n1,n3) > wsimff1 2 (n1,n2)
undecided otherwise
;

;

;

;

Table 7: Rules number agreement weighted semantic similarity resolving syntactic ambiguity noun phrases n0 n1 n2 n3
Strategy

Default
Number agreement
Weighted semantic similarity
Backing

Coverage (%) Accuracy (%)

100.0
40.4
69.7
85.4

44.9
80.6
77.4
81.6

Table 8: Syntactic disambiguation items form n0 n1 n2 n3
n3 takes place context n2 modifying n3 n1 (or coordinated phrase
containing it) modified n0.
example, consider instance ambiguous phrase:
(7)

telecommunications products services units.

happens high-information-content connection exists product
sense \a quantity obtained multiplication" unit sense \a single undivided
whole." result, although neither senses relevant example, nouns n1
n3 would assigned high value (unweighted) semantic similarity chosen
incorrectly conjoined heads example. However, unweighted similarity computation misses important piece context: syntactic analysis conjoining product
unit (cf. examples 6a 6b), word telecommunications necessarily modifier
concept identified products. selectional association telecommunications products \multiplication" sense weak nonexistent. Weighting
selection association, therefore, provides way reduce impact spurious senses
similarity computation.
order combine sources evidence, used \backing off" (from number agreement
weighted semantic similarity) combine two individual strategies. baseline,
results evaluated simple default strategy always choosing group
common development set. results shown Table 8.
case, default strategy defined using development set misleading,
yielding worse chance accuracy. reason, strategy-plus-default figures
reported. However, even default choices made using bias found test set,
109

fiResnik

accuracy would 55.1%. contrast equivocal results first experiment,
experiment demonstrates clear contribution semantic similarity: employing
semantic similarity cases accurate number-agreement strategy
cannot apply, possible obtain equivalent even somewhat better accuracy
number agreement alone time doubling coverage.
Comparison previous algorithms unfortunately possible, since researchers
coordination ambiguity established common data set evaluation even
common characterization problem, contrast now-standard (v, n1, prep, n2)
contexts used work propositional phrase attachment. crucial caveat,
nonetheless interesting note results obtained broadly consistent
Kurohashi Nagao (1992), report accuracy results range 80-83%
100% coverage analyzing broad range conjunctive structures Japanese using
combination string matching, syntactic similarity, thesaurus-based similarity,
Agarwal Boggess (1992), use syntactic types structure, along partly
domain-dependent semantic labels, obtain accuracies similar range identifying
conjuncts English.

5. Using Taxonomic Similarity Word Sense Selection
section considers application semantic similarity measure resolving another
form ambiguity: selecting appropriate sense noun appears context
nouns related meaning.

5.1 Associating Word Senses Noun Groupings
Knowledge groups related words plays role many natural language applications.
examples, query expansion using related words well studied technique information
retrieval (e.g., Harman, 1992; Grefenstette, 1992), clusters similar words play
role smoothing stochastic language models speech recognition (Brown, Della Pietra,
deSouza, Lai, & Mercer, 1992), classes verbs share semantic structure form
basis approach interlingual machine translation (Dorr, 1997), clusterings
related words used characterizing subgroupings retrieved documents largescale Web searches (e.g., Digital Equipment Corporation, 1998). wide body
research use distributional methods measuring word similarity order
obtain groups related words (e.g., Bensch & Savitch, 1992; Brill, 1991; Brown et al., 1992;
Grefenstette, 1992, 1994; McKeown & Hatzivassiloglou, 1993; Pereira, Tishby, & Lee, 1993;
Schutze, 1993), thesauri WordNet another source word relationships (e.g.,
Voorhees, 1994).
Distributional techniques sometimes good job identifying groups related
words (see Resnik, 1998b, overview critical discussion), tasks
relevant relationships among words, among word senses. example, Brown
et al. (1992) illustrate notion distributionally derived, \semantically sticky" cluster
using automatically derived word group containing attorney, counsel, trial, court,
judge. Although semantic coherence cluster \pops out" human reader,
naive computational system defense word sense ambiguity: using cluster
110

fiInformation-Based Semantic Similarity

query expansion could result retrieving documents involving advice (one sense
counsel) royalty (as one sense court).13
Resnik (1998a) introduces algorithm uses taxonomically-defined semantic similarity order derive grouping relationships among word senses grouping relationships among words. Formally, problem stated follows. Consider set words
W = fw1; : : :; wng, word wi associated
set Si = fsi;1 ; : : :; si;mg posS
sible senses. Assume exists set W 0 Si , representing set word
senses ideal human judge would conclude belong group senses corresponding word grouping W . (It follows W 0 must contain least one representative
Si .) goal define membership function ' takes si;j , wi ,
W arguments computes value [0; 1], representing confidence
one state sense si;j belongs sense grouping W 0 . Note that, principle, nothing
precludes possibility multiple senses word included W 0.
example, consider group
attorney, counsel, trial, court, judge.
Restricting attention noun senses WordNet, every word attorney polysemous.
Treating word group W , good algorithm computing ' assign value
1 unique sense attorney, assign high value sense counsel

lawyer pleads cases court.
Similarly, assign high values senses trial
legal proceedings consisting judicial examination issues competent tribunal
determination person's innocence guilt due process law.
also assign high values senses court
assembly conduct judicial business
room law court sits.
assign high value sense judge
public ocial authorized decide questions brought court justice.
assign low values ' various word senses words cluster
associated group lesser extent all. would include sense
counsel
direction advice decision course action;
similarly, low value ' assigned senses court
13. See Krovetz Kroft, 1992 Voorhees, 1993 experimentation discussion effects
word sense ambiguity information retrieval.

111

fiResnik

Algorithm (Resnik, 1998a). Given W = fw1 ; : : : ; w g, set nouns:
n

j = 1 n, < j
f

v = wsim(w , w )
c = informative subsumer w w
i;j



j

i;j



j

k = 1 num senses(w )
c ancestor sense
increment support[i, k] v


i;j

i;k

i;j

k = 1 num senses(w )
c ancestor sense
increment support[j, k'] v
0

j

j;k 0

i;j

i;j

increment normalization[i] v
increment normalization[j] v

i;j

g

i;j

= 1 n
k = 1 num senses(w )
f



(normalization[i] > 0.0)
' = support[i, k] / normalization[i]
else
' = 1 / num senses(w )
i;k

g

i;k



Figure 3: Disambiguation algorithm noun groupings
yard wholly partly surrounded walls buildings.
disambiguation algorithm noun groups given Figure 3. Intuitively, two
polysemous words similar, informative subsumer provides information
sense word relevant one. observation similar spirit
approaches word sense disambiguation based maximizing relatedness meaning (e.g.,
Lesk, 1986; Sussna, 1993). key idea behind algorithm consider nouns
word group pairwise. pair algorithm goes possible combinations
words' senses, assigns \credit" senses basis shared information content,
measured using information content informative subsumer.14
example, WordNet lists doctor meaning either medical doctor someone
holding Ph.D., lists nurse meaning either health professional nanny,
two words considered together, medical sense word obvious
human reader. effect finds parallel operation algorithm. Given
taxonomy like Figure 2, consider case set W words contains w1 =
doctor, w2 = nurse, w3 = actor. first pairwise comparison, doctor nurse,
14. Figure 3, square bracket notation highlights fact support matrix normalization
array. Conceptually v c (triangular) matrices also; however, use subscripts rather
square brackets implementation time need implement since
values v c used discarded pass double loop.
i;j

i;j

112

fiInformation-Based Semantic Similarity

informative subsumer c1;2 = health professional, information
content v1;2 = 8.844. Therefore support doctor1 nurse1 incremented
8.844. Neither doctor2 nurse2 receives increment support based
comparison, since neither health professional ancestor. second pairwise
comparison, informative subsumer doctor actor c1;3 = person,
information content v1;3 = 2.005, increment amount
support doctor1, doctor2, actor1, person ancestor.
Similarly, third pairwise comparison, informative subsumer nurse
actor also person, nurse1, nurse2, actor1 support incremented
2.005. end, therefore, doctor1 received support 8:884 + 2:005
possible 8:884 + 2:005 pairwise comparisons participated,
word sense ' = 1. contrast, doctor2 received support amount 2.005
possible 8:884 + 2:005 comparisons involved, value '
2:005 = 0:185.
doctor2 8:884+2
:005
Resnik (1998a) illustrates algorithm Figure 3 using word groupings variety
sources, including several sources distributional clustering cited above,
evaluates algorithm rigorously task associating WordNet senses
nouns Roget's thesaurus, based thesaurus category membership. average,
algorithm achieved approximately 89% performance human annotators performing
task.15 remainder section describe new application
algorithm, evaluate performance.

5.2 Linking WordNet using Bilingual Dictionary
Multilingual resources natural language processing dicult obtain, although
promising efforts underway projects like EuroWordNet (Vossen, 1998).
many languages, however, large-scale resources unlikely available
near future, individual research efforts continue build scratch
adapt existing resources bilingual dictionaries (e.g., Klavans & Tzoukermann,
1995). section describe application algorithm Figure 3 English
definitions CETA Chinese-English dictionary (CETA, 1982). ultimate task,
undertaken context Chinese-English machine translation project,
associate Chinese vocabulary items nodes WordNet, much way
vocabulary Spanish, Dutch, Italian associated interlingual taxonomy nodes
derived American WordNet, EuroWordNet project; task also similar
attempts relate dictionaries thesauri monolingually (e.g., see Section 5.3
Ji, Gong, & Huang, 1998). present study investigates extent semantic
similarity might useful partially automating process.
15. task performed independently two human judges. Treating Judge 1 benchmark
accuracies achieved Judge 2, algorithm, random selection respectively 65.7%, 58.6%,
34.8%; treating Judge 2 benchmark accuracies achieved Judge 1, algorithm,
random selection respectively 68.6%, 60.5%, 33.3%. relatively low accuracies human
judges demonstrate, disambiguation using WordNet's fine-grained senses quite bit dicult
disambiguation level homographs (Hearst, 1991; Cowie, Guthrie, & Guthrie, 1992). Resnik
Yarowsky (1997, 1999) discuss implications WordNet's fine-grainedness evaluation word
sense disambiguation, consider alternative evaluation methods.

113

fiResnik

example, consider following dictionary entries:
(a)
: 1. hliti brother-in-law (husband's elder brother) 2. hregi father 3.
hregi uncle (father's elder brother) 4. uncle (form address older
man)
: actress, player female roles.
(b)
order associate Chinese terms WordNet noun taxonomy,
important avoid associations inappropriate senses | example, word
, clearly associated father WordNet senses Church
entry (a),
Father, priest, God-the-Father, founding father.16
Although one traditional approach using dictionary entries compute word
overlap respect dictionary definitions (e.g., Lesk, 1986), English glosses
CETA dictionary generally short take advantage word overlap fashion.
However, many definitions useful property: possess multiple subdefinitions similar meaning, cases illustrated above. Although one
cannot always assume so, e.g.,
(c)
: 1. case (i.e., upper case lower case) 2. dial (of watch, etc.),
inspection dictionary confirms multiple definitions present tend
toward polysemy homonymy.
Based observation, conducted experiment assess extent
word sense disambiguation algorithm Figure 3 used identify relevant noun senses
WordNet Chinese words CETA dictionary, using English definitions
source similar nouns disambiguate. Nouns heading definitional noun phrases
extracted automatically via simple heuristic methods, randomly-selected sample
100 dictionary entries containing multiple definitions used test set. example,
noun groups associated definitions would
(a') uncle, brother-in-law, father
(b') actress, player.
WordNet's noun database used automatically identify compound nominals
possible. So, example, word defined \record player" would compound
record player rather player head noun record player compound
noun known WordNet.17
noted attempt made exclude dictionary entries like (c)
creating test set. Since general way automatically identify alternative
definitions distinguished synonymy distinguished homonymy, entries
must faced disambiguation algorithm task.
Two independent judges recruited assistance annotating test set, one
native Chinese speaker, second Chinese language expert United States
government. judges independently annotated 100 test items. item,
16. Annotations within dictionary entries
ignored algorithm described section.
17. WordNet version 1.5 used experiment.

<lit>

114

(literary),

<reg>

(regional), like

fiInformation-Based Semantic Similarity

WordNet definition, see 6 boxes: 1, 2, 3, 4, 5, is-a. definition:
think Chinese word meaning, select number corresponding
confidence choice, 1 lowest confidence 5 highest confidence.
Chinese word cannot meaning, specific meaning, select is-a.
example, Chinese word means \truck" WordNet definition \automotive vehicle:
self-propelled wheeled vehicle", would select option. (That is, makes sense say
Chinese word describes concept KIND automotive vehicle.) pick 1,
2, 3, 4, 5 confidence decision, 1 lowest confidence 5 highest
confidence.
neither cases apply WordNet definition, don't check anything
definition.

Figure 4: Instructions human judges selecting senses associated Chinese words
judge given Chinese word, full CETA dictionary definition (as examples
a{c), list WordNet sense descriptions associated sense head
noun associated noun group. example, list corresponding following
dictionary definition
(d)
: urgent message, urgent dispatch
would contain following WordNet sense descriptions, generated via head nouns
message dispatch:
message, content, subject matter, substance: communication
something
dispatch, expedition, expeditiousness, fastness: subconcept celerity, quickness, rapidity
dispatch, despatch, communique: ocial report (usually sent haste)
message: communication (usually brief) written spoken
signaled; \he sent three-word message"
dispatch, despatch, shipment: act sending something
dispatch, despatch: murder execution someone
item, judge first asked whether knew Chinese word meaning;
response negative, instructed proceed next item. items
known words, judges instructed Figure 4.
Although use is-a selection used analysis results,
important include provided judges way indicate
Chinese word could best classified WordNet noun taxonomy, without
assert translational equivalence Chinese concept close WordNet (English)
concept. So, example, judge could classify word
(the spring festival, lunar
new year, Chinese new year) belonging WordNet sense glossed
festival: day period time set aside feasting celebration,
115

fiResnik

sensible choice given \Chinese New Year" appear WordNet
concept. Annotating is-a relationship set also important algorithm evaluated working groups head nouns, thereby potentially losing
information pointing specific concept reading. example, definition
: steel tube, steel pipe
(e)
would given algorithm group containing head nouns tube pipe.
test set annotated, evaluation done according two paradigms:
selection filtering. paradigms assume entry test set,
annotator correctly specified WordNet senses considered correct,
incorrect. algorithm tested set must identify, listed
sense, whether sense included item whether excluded.
example, WordNet sense corresponding \the murder execution someone"
would identified annotator incorrect (d), algorithm marking
\included" penalized.
selection paradigm, goal identify WordNet senses include.
therefore define precision paradigm
correctly included senses
Pselection = number
(10)
number included senses
recall
correctly included senses :
Rselection = number
(11)
number correct senses
correspond directly use precision recall information retrieval. Precision begins set senses included method, computes proportion
correct. Recall begins set senses included,
computes proportion method actually managed choose.
Since number potential WordNet senses item quite large, equally
valid alternative selection paradigm call filtering paradigm, according
goal identify WordNet senses exclude. One easily imagine
relevant paradigm | example, semi-automated setting one
wishes reduce burden user selecting among alternatives. filtering paradigm
one define filtering precision
correctly excluded senses
Pfiltering = number
number excluded senses

(12)

correctly excluded senses :
Rfiltering = number
number senses labeled incorrect

(13)

filtering recall

filtering paradigm, precision begins set senses method filtered
computes proportion correctly filtered out. recall filtering
begins set senses excluded (i.e. incorrect ones)
computes proportion method actually managed exclude.
116

fiInformation-Based Semantic Similarity

Sense Selection
Sense Filtering
Precision (%) Recall (%) Precision (%) Recall (%)
Random
29.5
31.2
88.0
87.1
Algorithm
36.9
69.9
93.8
79.3
Judge 2
54.8
55.6
91.9
91.7
Table 9: Evaluation using Judge 1 reference standard, considering items selected
confidence 3 above.
Judge 2
Algorithm
Random
Include Exclude Include Exclude Include Exclude
Judge 1 Include
40
32
58
25
26
57
Exclude
33
363
99
380
61
418
Table 10: Agreement disagreement Judge 1
Table 9 shows precision/recall figures using judgments Judge 1, native
Chinese speaker, reference standard, considering known items selected confidence 3 above.18 algorithm recorded 100 items known, confidence
values scaled linearly continuous values range [0,1] discrete values 1
5. table shows algorithm's results choice thresholded confidence 3,
Figure 5 shows recall precision vary confidence threshold changes.
lower bound comparison, algorithm implemented considered word
sense item, selecting sense probabilistically (with complete confidence)
way make average number senses per item close possible average
number senses per item reference standard (1.3 senses). Figures random
baseline average 10 runs. Table 10 illustrates choices underlying
figures; example, 26 senses random procedure chose include
also included Judge 1.
fact Judge 2 low precision recall selection indicates
matching choices independent judge indeed dicult task. unsurprising, given previous experience problem selecting among WordNet's fine-grained
senses (Resnik, 1998a; Resnik & Yarowsky, 1997). results clearly show algorithm better baseline, also indicate overgenerating senses,
hurts selection precision. terms filtering, algorithm chooses filter
sense tends reliably (filtering precision). However, propensity toward overgeneration ected below-baseline performance filtering recall; is, algorithm
choosing allow senses filtering out.
18. Judge 1, native speaker Chinese, identified 65 words known him; Judge 2 identified
69. on-line dictionary constructed large variety lexical resources, includes great
many uncommon words, archaic usages, regionalisms, like.

117

fiResnik

Filtering: Algorithm
Human
Random
Selection: Algorithm
Human
Random

Precision

1
0.8
0.6
0.4
0.2

0.2

0.4

0.6

0.8
Recall

1

Figure 5: Precision/recall curves using Judge 1 reference standard, varying confidence threshold
pattern results suggests best use algorithm present level
performance would filter lexical acquisition process human
loop, dividing candidate WordNet senses dictionary entries according higher
lower priority. Chinese-English dictionary entries serve appropriate input
algorithm (of approximately 37000 CETA dictionary), WordNet
sense selected algorithm confidence least equal 3
demoted lower priority group presentation alternatives, since algorithm's
choice exclude sense correct approximately 93% time. senses
selected algorithm necessarily included | human judge still
needed make selection, since selection precision low | algorithm tends
err side caution, correct senses found higher priority group
70% time.

5.3 Linking WordNet English Dictionary/Thesaurus

results WordNet sense selection using bilingual dictionary demonstrate
algorithm Figure 3 good job assigning low scores WordNet senses
filtered out, even probably trusted make categorical decisions. One
application proposed suitable, therefore, helping identify senses
filtered within semi-automated process lexical acquisition. describe closely
related, real-world application algorithm deployed: adding pointers
WordNet on-line dictionary/thesaurus Web.
context application Wordsmyth English Dictionary-Thesaurus (WEDT,
http://www.wordsmyth.net/), on-line educational dictionary aliated ARTFL
text database project (http://humanities.uchicago.edu/ARTFL/; Morrissey, 1993).
designed useful educational contexts, and, part design,
integrates thesaurus within structure dictionary. illustrated Figure 6,
118

fiInformation-Based Semantic Similarity

bar

SYL:
PRO:
POS:
DEF:
EXA:
EXA:
EXA:
SYN:
SIM:
DEF:
SYN:
SIM:
..
.

bar1
bar
noun
1. length solid material, usu. rectangular cylindrical:
bar soap;
candy bar;
iron bar.
rod (1), stick1 (1,2,3)
pole1 , shaft, stake1 , ingot, block, rail1 , railing,
crowbar, jimmy, lever
2. anything acts restraint hindrance.
block (10), hindrance (1), obstruction (1), impediment (1),
obstacle, barrier (1,3), stop (5)
barricade, blockade, deterrent, hurdle, curb, stumbling
block, snag, jam1 , shoal1 , reef1 , sandbar

Figure 6: Example Wordsmyth English Dictionary-Thesaurus (WEDT)
WEDT contains traditional dictionary information, part speech, pronunciation,
definitional information, many cases also includes pointers synonyms (SYN)
similar words (SIM). Within on-line dictionary, thesaurus items hyperlinks
| example, stake1 link first WEDT entry stake | parenthetical
numbers refer specific definitions within entry.
thesaurus-like grouping similar words provides opportunity exploit
algorithm disambiguating noun groupings automatically linking WEDT entries
WordNet. value linking two resources comes compatability,
properties thesaurus dictionary, well complementarity: beyond alternative source definitional information lists synonyms,
WordNet provides ordering word senses frequency, estimates word familiarity, partof relationships, course overall taxonomic organization illustrated Figures 1
2. Figure 7 shows taxonomic information presented using WordNet Web
server (http://www.cogsci.princeton.edu/cgi-bin/webwn/).
collaboration WEDT ARTFL, taken noun entries
WEDT dictionary and, grouping similar words, added set experimental
hyperlinks WordNet entries WordNet Web server. Figure 8 shows experimental WordNet links (XWN) look WEDT user. Links WordNet senses,
pole1, appear together confidence level assigned sense disambiguation algorithm; senses confidence less threshold presented.19 XWN
hyperlink selected user, WordNet taxonomic information selected sense
appears parallel browser window, Figure 7.
window, user entry point capabilities WordNet
web server. example, one might choose look WordNet senses pole
19. current threshold, 0.1, chosen manually. may sub-optimal found works
well practice.

119

fiResnik

Sense 1
pole
(a long (usually round) rod wood metal plastic)
=> rod
(a long thin implement made metal wood)
=> implement
(a piece equipment tool used effect end)
=> instrumentality, instrumentation
(an artifact (or system artifacts)
instrumental accomplishing end)
=> artifact, artefact
(a man-made object)
=> object, physical object
(a physical (tangible visible) entity; ``it
full rackets, balls objects'')
=> entity, something
(anything existence (living nonliving))

Figure 7: WordNet entry (hypernyms) pole1
bar

SYL:
PRO:
POS:
DEF:
EXA:
EXA:
EXA:
SYN:
SIM:
XWN:
DEF:
SYN:
SIM:
XWN:

..
.

bar1
bar
noun
1. length solid material, usu. rectangular cylindrical:
bar soap;
candy bar;
iron bar.
rod (1), stick1 (1,2,3)
pole1 , shaft, stake1 , ingot, block, rail1 , railing,
crowbar, jimmy, lever
pole1 (0.82) ingot1 (1.00) block1 (0.16) rail1 (0.39)
railing1 (1.00) crowbar1 (1.00)
jimmy1 (1.00) lever1 (0.67) lever2(0.23) lever3(0.15)
2. anything acts restraint hindrance.
block (10), hindrance (1), obstruction (1), impediment (1),
obstacle, barrier (1,3), stop (5)
barricade, blockade, deterrent, hurdle, curb, stumbling
block, snag, jam1 , shoal1 , reef1 , sandbar
barricade1 (1.00) barricade2(1.00) blockade1 (0.25)
blockade2 (0.75) deterrent1 (1.00) hurdle1 (0.50)
hurdle2 (0.43) curb1 (0.56) curb2 (0.56)
curb3 (0.29) curb4 (0.44) stumbling block1 (1.00)
snag1 (1.00) jam1 (0.27) shoal1 (0.23) shoal2(0.91)
reef1 (1.00) sandbar1 (1.00)

Figure 8: Example WEDT experimental WordNet links
120

fiInformation-Based Semantic Similarity

1. pole { (a long (usually round) rod wood metal plastic)
2. Pole { (a native inhabitant Poland)
3. pole { (one two divergent mutually exclusive opinions; \they opposite poles" \they
poles apart")
4. perch, rod, pole { ((British) linear measure 16.5 feet)
5. perch, rod, pole { (a square rod land)
6. pole, celestial pole { (one two points intersection Earth's axis celestial sphere)
7. pole { (one two antipodal points Earth's axis rotation intersects Earth's surface)
8. terminal, pole { (a point electrical device (such battery) electric current enters
leaves)
9. pole { (a long fiberglass implement used pole vaulting)
10. pole, magnetic pole { (one two ends magnet magnetism seems concentrated)

Figure 9: List WordNet senses pole
noun, displayed Figure 9. Notice user WEDT simply gone directly
WordNet server look pole, full list 10 senses would appeared
indication potentially related WEDT dictionary entry
consideration. contrast, WEDT hyperlinks, introduced via sense selection
algorithm, filter majority irrelevant senses provide user measure
confidence selecting among remain.
Although formal evaluation WEDT/WordNet connection attempted,
results bilingual dictionary experiment suggest application word
sense disambiguation | filtering least relevant senses, leaving user
loop | task sense disambiguation algorithm well suited.
supported user feedback XWN feature WEDT, favorable
(Robert Parks, personal communication). site growing popularity,
current estimate 1000-1500 hits per day.

6. Related Work
extensive literature measuring similarity general, word similarity
particular; classic paper see Tversky (1977). Recent work information retrieval
computational linguistics emphasized distributional approach, words
represented vectors space features similarity measures defined
terms vectors; see Resnik (1998b) discussion, Lee (1997) good recent
example. Common traditional distributional approaches idea word
concept representations include explicit features, whether features specified
knowledge-based fashion (e.g., dog might features like mammal, loyal) defined
terms distributional context (e.g., dog might features like \observed within 5
words howl). representational assumption contrasts assumptions embodied
taxonomic representation, often is-a relation stands nondecomposed concepts. two inconsistent, course, since concepts taxonomy
121

fiResnik

sometimes decomposed explicit features, is-a relation, usually
interpreted, implies inheritance features whether explicit implicit.
respect, traditional approach counting edges viewed particularly simple
approximation similarity measure based counting feature differences,
assumption edge exists indicate difference least one feature.
Information-theoretic concepts techniques have, recent years, emerged
speech recognition community find wide application natural language processing; e.g.,
see Church Mercer (1993). information event fundamental notion
stochastic language modeling speech recognition, contribution correct
word prediction based conditional probability, p(wordjcontext), measured
information conveyed prediction, , log p(wordjcontext). forms basis
standard measures language model performance, cross entropy. Frequency
shared unshared features also long factor computing similarity vector representations. inverse document frequency (idf) term weighting information
retrieval makes use logarithmic scaling, serves identify terms discriminate well among different documents, concept similar spirit idea
terms low information content (Salton, 1989).
Although counting edges is-a taxonomies seems something many people
tried, seem published descriptions attempts directly evaluate
effectiveness method. number researchers attempted make use
conceptual distance information retrieval. example, Rada et al. (1989, 1989) Lee
et al. (1993) report experiments using conceptual distance, implemented using edgecounting metric, basis ranking documents similarity query. Sussna
(1993) uses semantic relatedness measured WordNet word sense disambiguation,
defining measure distance weights different types links also explicitly takes
depth taxonomy account.
Following original proposal measure semantic similarity taxonomy using
information content (Resnik, 1993b, 1993a), number related proposals explored. Leacock Chodorow (1994) define measure resembling information content,
using normalized path length two concepts compared rather
probability subsuming concept. Specifically, define
2
min
len(c1 ; c2) 3
c
;
c
(14)
wsimndist (w1; w2) = , log 4 1 (22 max) 5 :
(The notation Equation (5).) addition definition,
also include several special cases, notably avoid infinite similarity c1
c2 exact synonyms thus path length 0. Leacock Chodorow
experimented measure information content measure described
context word sense disambiguation, found yield roughly similar results.
Implementing method testing task reported Section 3, found
actually outperformed information-based measure slightly data set; however,
follow-up experiment using different larger set noun pairs (100 items),
information-based measure performed significantly better (Table 11).
Analyzing differences two studies illuminating. follow-up experiment, used netnews archives gather highly frequent nouns within related topic areas
122

fiInformation-Based Semantic Similarity

Similarity method
Correlation
Information content
r = :6894
Leacock Chodorow r = :4320
Edge-counting
r = :4101
Table 11: Summary experimental results follow-up study.
(to ensure similar noun pairs occurred) selected noun pairings random (in
order avoid biasing follow-up study favor either algorithm). is, therefore,
predominance low-similarity noun pairs test data. Looking distribution
ratings noun pairs, given two measures, evident Leacock
Chodorow measure overestimating semantic similarity many predominantly
non-similar pairs. stands reason since measure identical whenever edge
distance identical, regardless whether pair high low taxonomy (e.g.,
distance plant animal distance white oak red
oak). contrast, information-based measure sensitive difference, better
avoiding spuriously high similarity values non-similar pairs. related note,
edge-counting measure used follow-up study variant computes path length
virtual top node, rather asserting zero similarity words path
connecting existing WordNet taxonomy, done previously. Using data
set follow-up study, information-based measure, r = :6894, significantly
better either edge-counting variants (r = :4101 r = :2777); going back
original Miller Charles data, virtual-top-node variant significantly better
assert-zero edge distance measure, correlation r = :7786 approaching
measure based information content. comparison follow-up
study original Miller Charles data illustrates quite clearly utility
similarity measure depend upon distribution items given task.
Lin (1997, 1998) recently proposed alternative information-theoretic similarity
measure, derived set basic assumptions similarity style reminiscent
way entropy/information formal definition derivable set
basic properties (Khinchin, 1957). Formally, Lin defines similarity taxonomy as:


log p( Ci)
simLin(c1; c2) = log2 p(
c1) + log p(c2)

(15)

Ci \maximally specific superclasses" ofT c1 c2 . Although
possibility multiple inheritance makes intersection Ci necessary principle, multiple inheritance fact rare WordNet practice one computes Equation (15)
separately common ancestor Ci , using p(Ci) numerator, takes
maximum (Dekang Lin, p.c.). multiplicative constant 2, therefore,
Lin's method determining similarity taxonomy essentially information-based
similarity measure Equation 1, normalized combined information content
two concepts assuming independence. Put another way, Lin's measure taking
123

fiResnik

Similarity method Correlation
Information content r = :7947
simWu&Palmer
r = :8027
simLin
r = :8339
Table 12: Summary Lin's results comparing alternative similarity measures
account commonalities differences items compared,
expressing information-theoretic terms.
Lin's measure theoretically well motivated elegantly derived. Moreover, Lin points
measure definition yield value simLin(x; x) regardless
identity x | unlike information content, criticized grounds
value self-similarity depends specific concept x is, two nonidentical items x rated similar third item z
(Richardson et al., 1994). cognitive perspective, however, similarity comparisons
involving self-similarity (\Robins similar robins"), well subclass relationships
(\Robins similar birds"), criticized psychologists anomalous (Medin, Goldstone, & Gentner, 1993). Moreover, experimental evidence human
judgments suggests identical objects judged equally similar, consistent
information-content measure proposed contrary Lin's measure. example, objects identical complex, twins, seem similar
objects identical simple, two instances simple geometric shape (Goldstone, 1999; Tversky, 1977). would appear, therefore, insofar
fidelity human judgments relevant, experimentation needed evaluate
competing predictions alternative similarity measures.
Wu Palmer (1994) propose similarity measure based edge distances,
related Lin's measure way takes account specific node dominating
c1 c2, characterizing commonalities, normalizing way accounts
differences. Revising Wu Palmer's notation slightly, measure is:
c3)
(16)
simWu&Palmer(c1; c2) = d(2c ) +d(d(
c2)
1
c3 maximally specific superclass c1 c2 , d(c3) depth, i.e. distance
root taxonomy, d(c1) d(c2) depths c1 c2 path
c3.
Lin (1998) repeats experiment Section 3 information content measure,
simLin, simWu&Palmer, reporting results appear Table 12. Lin uses sensetagged corpus estimate frequencies, smoothed probabilities rather simple relative frequency. results show somewhat higher correlation simLin
measures. experimentation needed order assess alternative measures,
particularly respect competing predictions variability performance
across data sets. seems clear, however, measures perform better
traditional edge-counting measure.
124

fiInformation-Based Semantic Similarity

7. Conclusions
article presented measure semantic similarity is-a taxonomy, based
notion information content. Experimental evaluation performed using large,
independently constructed corpus, independently constructed taxonomy, previously
existing new human subject data, results suggest measure performs
encouragingly well significantly better traditional edge-counting approach. Semantic similarity, measured using information content, shown useful
resolving cases two pervasive kinds linguistic ambiguity. resolving coordination
ambiguity, measure employed capture intuition similarity meaning
one indicator two words conjoined; suggestive results first experiment
bolstered unequivocal results second study, demonstrating significant improvements disambiguation strategy based syntactic agreement. resolving word
sense ambiguity, semantic similarity measure used assign confidence values
word senses nouns within thesaurus-like groupings. formal evaluation provided evidence technique produce useful results better suited semi-automated
sense filtering categorical sense selection. Application technique dictionary/thesaurus World Wide Web provides demonstration method action
real-world setting.

Acknowledgements
Sections 1-3 article comprise revised extended version Resnik (1995).
Section 4 describes previously presented algorithms data (Resnik, 1993b, 1993a), extended discussion analysis. Section 5 summarizes algorithm described
Resnik (1998a), extends previous results presenting new applications
algorithm, Section 5.2 containing formal evaluation new setting Section 5.3
giving real-world illustration approach put practice. Section 6
adds substantial discussion related work authors taken place since
information-based similarity measure originally proposed.
Parts research done University Pennsylvania partial
support IBM Graduate Fellowship grants ARO DAAL 03-89-C-0031, DARPA
N00014-90-J-1863, NSF IRI 90-16592, Ben Franklin 91S.3078C-1; parts research
also done Sun Microsystems Laboratories Chelmsford, Massachusetts; parts
work supported University Maryland Department Defense
contract MDA90496C1250, DARPA/ITO Contract N66001-97-C-8540, Army Research
Laboratory contract DAAL03-91-C-0034 Battelle, research grant Sun
Microsystems Laboratories. author gratefully acknowledges comments three
anonymous JAIR reviewers helpful discussions John Kovarik, Claudia Leacock,
Dekang Lin, Johanna Moore, Mari Broman Olsen, Jin Tong, well comments
criticism received various presentations work.

References
Agarwal, R., & Boggess, L. (1992). simple useful approach conjunct identifica125

fiResnik

tion. Proceedings 30th Annual Meeting Association Computational
Linguistics, pp. 15{21. Association Computational Linguistics.
Bensch, P. A., & Savitch, W. J. (1992). occurrence-based model word categorization.
Presented 3rd Meeting Mathematics Language (MOL3).
Brill, E. (1991). Discovering lexical features language. Proceedings 29th
Annual Meeting Association Computational Linguistics, Berkeley, CA.
Brill, E., & Resnik, P. (1994). rule-based approach prepositional phrase attachment disambiguation. Proceedings 15th International Conference Computational
Linguistics (COLING-94).
Brown, P. F., Della Pietra, V. J., deSouza, P. V., Lai, J. C., & Mercer, R. L. (1992).
Class-based n-gram models natural language. Computational Linguistics, 18 (4),
467{480.
CETA (1982). Chinese Dictionaries: Extensive Bibliography Dictionaries Chinese
Languages. Chinese-English Translation Assistance Group, Greenwood
Publishing.
Church, K. W., & Mercer, R. (1993). Introduction special issue computational
linguistics using large corpora. Computational Linguistics, 19 (1), 1{24.
Church, K. W., & Patil, R. (1982). Coping syntactic ambiguity put
block box table. American Journal Computational Linguistics, 8 (3-4),
139{149.
Collins, A., & Loftus, E. (1975). spreading activation theory semantic processing.
Psychological Review, 82, 407{428.
Collins, M., & Brooks, J. (1995). Prepositional phrase attachment backed-off
model. Third Workshop Large Corpora. Association Computational
Linguistics. cmp-lg/9506021.
Cowie, J., Guthrie, J., & Guthrie, L. (1992). Lexical disambiguation using simulated annealing. Proceedings 14th International Conference Computational Linguistics
(COLING-92), pp. 359{365 Nantes, France.
Digital Equipment Corporation (1998).

AltaVista web page: Refine, cow9?..
http://altavista.digital.com/av/content/about_our_technology_cow9.htm.

Dorr, B. J. (1997). Large-Scale Dictionary Construction Foreign Language Tutoring
Interlingual Machine Translation. Machine Translation, 12 (4), 271{322.
Fellbaum, C. (Ed.). (1998). WordNet: Electronic Lexical Database. MIT Press.
Francis, W. N., & Kucera, H. (1982). Frequency Analysis English Usage: Lexicon
Grammar. Houghton Miin, Boston.
126

fiInformation-Based Semantic Similarity

Goldstone, R. L. (1999). Similarity. MIT Encyclopedia Cognitive Sciences. MIT
Press, Cambridge, MA.
Grefenstette, G. (1992). Use syntactic context produce term association lists text
retrieval. Proceedings Fifteenth Annual International ACM SIGIR Conference Research Development Information Retrieval, pp. 89{97.
Grefenstette, G. (1994). Explorations Automatic Thesaurus Discovery. Kluwer, Boston.
Harman, D. (1992). Relevance feedback revisited. Proceedings Fifteenth Annual
International ACM SIGIR Conference Research Development Information
Retrieval, pp. 1{10.
Hearst, M. (1991). Noun homograph disambiguation using local context large corpora.
Proceedings 7th Annual Conference University Waterloo Centre
New OED Text Research Oxford.
Hindle, D., & Rooth, M. (1993). Structural ambiguity lexical relations. Computational
Linguistics, 19 (1), 103{120.
Ji, D., Gong, J., & Huang, C. (1998). Combining Chinese thesaurus Chinese
dictionary. COLING-ACL '98, pp. 600{606. Universite de Montreal.
Katz, S. M. (1987). Estimation probabilities sparse data language model
component speech recognizer. IEEE Transactions Acoustics, Speech Signal
Processing, ASSP-35 (3), 400{401.
Khinchin, A. I. (1957). Mathematical Foundations Information Theory. New York: Dover
Publications. Translated R. A. Silverman M. D. Friedman.
Klavans, J. L., & Tzoukermann, E. (1995). Dictionaries Corpora: Combining Corpus
Machine-Readable Dictionary Data Building Bilingual Lexicons. Machine
Translation, 10, 185{218.
Kobayasi, Y., Takunaga, T., & Tanaka, H. (1994). Analysis Japanese compound nouns
using collocational information. Proceedings 15th International Conference
Computational Linguistics (COLING-94).
Krovetz, R., & Croft, W. B. (1992). Lexical ambiguity information retrieval. ACM
Transactions Information Systems, 10 (2), 115{141.
Kurohashi, S., & Nagao, M. (1992). Dynamic programming method analyzing conjunctive structures Japanese. Proceedings 14th International Conference
Computational Linguistics (COLING-92) Nantes, France.
Lauer, M. (1994). Conceptual association compound noun analysis. Proceedings
32nd Annual Meeting Association Computational Linguistics Las Cruces,
New Mexico. Student Session.
Lauer, M. (1995). Designing Statistical Language Learners: Experiments Noun Compounds. Ph.D. thesis, Macquarie University, Sydney, Australia.
127

fiResnik

Leacock, C., & Chodorow, M. (1994). Filling sparse training space word sense
identification. ms.
Lee, J. H., Kim, M. H., & Lee, Y. J. (1993). Information retrieval based conceptual
distance IS-A hierarchies. Journal Documentation, 49 (2), 188{207.
Lee, L. (1997). Similarity-based approaches natural language processing. Tech. rep.
TR-11-97, Harvard University. Doctoral dissertation. cmp-lg/9708011.
Lesk, M. (1986). Automatic sense disambiguation using machine readable dictionaries:
tell pine cone ice cream cone. Proceedings 1986 SIGDOC
Conference, pp. 24{26.
Li, H., & Abe, N. (1995). Generalizing case frames using thesaurus MDL principle.
Proceedings International Conference Recent Advances NLP Velingrad,
Bulgaria.
Lin, D. (1997). Using syntactic dependency local context resolve word sense ambiguity. Proceedings 35th Annual Meeting Association Computational
Linguistics 8th Conference European Chapter Association Computational Linguistics Madrid, Spain.
Lin, D. (1998). information-theoretic definition similarity. Proceedings
Fifteenth International Conference Machine Learning (ICML-98) Madison, Wisconsin.
Marcus, M. P., Santorini, B., & Marcinkiewicz, M. (1993). Building large annotated
corpus English: Penn Treebank. Computational Linguistics, 19, 313{330.
McKeown, K., & Hatzivassiloglou, V. (1993). Augmenting lexicons automatically: Clustering semantically related adjectives. Bates, M. (Ed.), ARPA Workshop Human
Language Technology. Morgan Kaufmann.
Medin, D., Goldstone, R., & Gentner, D. (1993). Respects similarity. Psychological
Review, 100 (2), 254{278.
Merlo, P., Crocker, M., & Berthouzoz, C. (1997). Attaching multiple prepositional phrases:
Generalized backed-off estimation. Proceedings Second Conference Empirical Methods Natural Language Processing (EMNLP-2). cmp-lg/9710005.
Miller, G. (1990). WordNet: on-line lexical database. International Journal Lexicography, 3 (4). (Special Issue).
Miller, G. A., & Charles, W. G. (1991). Contextual correlates semantic similarity. Language Cognitive Processes, 6 (1), 1{28.
Morrissey,
R.
(1993). Texts contexts: ARTFL database French studies. Profession 93,
27{33. http://humanities.uchicago.edu/homes/publications/romoart.html.
128

fiInformation-Based Semantic Similarity

Pereira, F., Tishby, N., & Lee, L. (1993). Distributional clustering English words. Proceedings 31st Annual Meeting Association Computational Linguistics
(ACL-93) Morristown, New Jersey. Association Computational Linguistics.
Quillian, M. R. (1968). Semantic memory. Minsky, M. (Ed.), Semantic Information
Processing. MIT Press, Cambridge, MA.
Rada, R., & Bicknell, E. (1989). Ranking documents thesaurus. JASIS, 40 (5),
304{310.
Rada, R., Mili, H., Bicknell, E., & Blettner, M. (1989). Development application
metric semantic nets. IEEE Transaction Systems, Man, Cybernetics,
19 (1), 17{30.
Ratnaparkhi, A., & Roukos, S. (1994). maximum entropy model prepositional phrase
attachment. Proceddings ARPA Workshop Human Language Technology
Plainsboro, NJ.
Resnik, P. (1993a). Selection Information: Class-Based Approach Lexical Relationships.
Ph.D.
thesis,
University

Pennsylvania.
(ftp://ftp.cis.upenn.edu/pub/ircs/tr/93-42.ps.Z).
Resnik, P. (1993b). Semantic classes syntactic ambiguity. Proceedings 1993
ARPA Human Language Technology Workshop. Morgan Kaufmann.
Resnik, P. (1995). Using information content evaluate semantic similarity taxonomy.
Proceedings 14th International Joint Conference Artificial Intelligence
(IJCAI-95). (cmp-lg/9511007).
Resnik, P. (1996). Selectional constraints: information-theoretic model computational realization. Cognition, 61, 127{159.
Resnik, P. (1998a). Disambiguating noun groupings respect Wordnet senses.
Armstrong, S., Church, K., Isabelle, P., Tzoukermann, E., & Yarowsky, D. (Eds.),
Natural Language Processing Using Large Corpora. Kluwer.
Resnik, P. (1998b). WordNet class-based probabilities. Fellbaum, C. (Ed.), WordNet:
Electronic Lexical Database. MIT Press.
Resnik, P., & Yarowsky, D. (1997). perspective word sense disambiguation methods
evaluation. ANLP Workshop Tagging Text Lexical Semantics
Washington, D.C.
Resnik, P., & Yarowsky, D. (1999). Distinguishing systems distinguishing senses: New
evaluation methods word sense disambiguation. Natural Language Engineering.
(to appear).
Richardson, R., Smeaton, A. F., & Murphy, J. (1994). Using WordNet knowledge base measuring semantic similarity words. Working paper CA1294, Dublin City University, School Computer Applications, Dublin, Ireland.
ftp://ftp.compapp.dcu.ie/pub/w-papers/1994/CA1294.ps.Z.
129

fiResnik

Ross, S. (1976). First Course Probability. Macmillan.
Rubenstein, H., & Goodenough, J. (1965). Contextual correlates synonymy. CACM,
8 (10), 627{633.
Salton, G. (1989). Automatic Text Processing. Addison-Wesley.
Schutze, H. (1993). Word space. Hanson, S. J., Cowan, J. D., & Giles, C. L. (Eds.), Advances Neural Information Processing Systems 5, pp. 895{902. Morgan Kaufmann
Publishers, San Mateo CA.
Sinclair (ed.), J. (1987). Collins COBUILD English Language Dictionary. Collins: London.
Sussna, M. (1993). Word sense disambiguation free-text indexing using massive semantic network. Proceedings Second International Conference Information
Knowledge Management (CIKM-93) Arlington, Virginia.
Tversky, A. (1977). Features similarity. Psychological Review, 84, 327{352.
Voorhees, E. M. (1993). Using WordNet disambiguate word senses text retrieval.
Korfhage, R., Rasmussen, E., & Willett, P. (Eds.), Proceedings Sixteenth Annual
International ACM SIGIR Conference Research Development Information
Retrieval, pp. 171{180.
Voorhees, E. M. (1994). Query expansion using lexical-semantic relations. 17th International Conference Research Development Information Retrieval (SIGIR
'94) Dublin, Ireland.
Vossen, P. (1998). Special issue EuroWordNet. Computers Humanities, 32 (2/3).
Weiss, S. M., & Kulikowski, C. A. (1991). Computer systems learn: classification
prediction methods statistics, neural nets, machine learning, expert systems.
Morgan Kaufmann, San Mateo, CA.
Whittemore, G., Ferrara, K., & Brunner, H. (1990). Empirical study predictive powers
simple attachment schemes post-modifier prepositional phrases. Proceedings
28th Annual Meeting Association Computational Linguistics, pp. 23{30.
Pittsburgh, Pennsylvania.
Wilks, Y., & Stevenson, M. (1996). grammar sense: word-sense tagging much
part-of-speech tagging?.. Technical Report CS-96-05, cmp-lg/9607028.
Wu, Z., & Palmer, M. (1994). Verb Semantics Lexical Selection. Proceedings
32nd Annual Meeting Association Computational Linguistics Las Cruces,
New Mexico.

130

fi
