Journal Artificial Intelligence Research 40 (2011) 523-570

Submitted 9/10; published 2/11

Efficient Planning Uncertainty Macro-actions
Ruijie

RUIJIE @ CSAIL . MIT. EDU

Computer Science Artificial Intelligence Laboratory
Massachusetts Institute Technology
Cambridge, 02139 USA

Emma Brunskill

EMMA @ CS . BERKELEY. EDU

Electrical Engineering Computer Science Department
University California, Berkeley
Berkeley, CA 94709 USA

Nicholas Roy

NICKROY @ CSAIL . MIT. EDU

Computer Science Artificial Intelligence Laboratory
Massachusetts Institute Technology
Cambridge, 02139 USA

Abstract
Deciding act partially observable environments remains active area research.
Identifying good sequences decisions particularly challenging good control performance
requires planning multiple steps future domains many states. Towards addressing
challenge, present online, forward-search algorithm called Posterior Belief Distribution (PBD). PBD leverages novel method calculating posterior distribution beliefs
result sequence actions taken, given set observation sequences could
received process. method allows us efficiently evaluate expected reward
sequence primitive actions, refer macro-actions. present formal analysis
approach, examine performance two large simulation experiments: scientific exploration target monitoring domain. also demonstrate algorithm used control
real robotic helicopter target monitoring experiment, suggests approach
practical potential planning real-world, large partially observable domains multi-step
lookahead required achieve good performance.

1. Introduction
Consider autonomous helicopter tasked protecting ships anchored busy harbor.
time step, helicopter must know anything moving close ships guarding,
due sensor limits, helicopter cannot observe whole harbor once. way
keep ships safe keep moving continuously throughout harbor, keeping track
moving agents. helicopter well senses another boat moved close
one charges, false alarms costly. helicopters controller must decide
move around, report when, order maximize performance.
problem requires decision-making uncertain, partially observable domain, common challenge agent operating real-world environment. helicopter problem
described example general class problems particularly difficult two reasons.
First, make decision, agent must take consideration present estimate location orientation targets. quantities typically real-valued.
c
2011
AI Access Foundation. rights reserved.

fiH E , B RUNSKILL , & ROY

standard terminology Markov decision processes (MDPs), state space consists large
number continuous variables. Second, make decision now, agent must reason
estimate state world may change many time steps future, different
possible helicopter target actions. problem many variables consider long
time horizon plan suffers curse dimensionality curse history (Pineau,
Gordon, & Thrun, 2003a). refer problems large long.
paper present new planning algorithm large, long, partially observable MDPs
(POMDPs), target monitoring example. Beyond target monitoring, numerous
problems, scientific exploration extreme environments autonomous management retirement portfolios, may posed large, long POMDPs.
Though substantial progress POMDP planning last decade,
approaches still struggle scale large domains described many state variables,
variable may take large infinite number potential values. Symbolic Perseus (Poupart,
2005) used find good solution hand-washing domain 11 state variables,
variable took relatively small number values (at 10 values). Recently online
forward search approaches used achieve encouraging performance large1
POMDPs, work Ross, Chaib-draa Pineau (2008b) Paquet, Tobin Chaibdraa (2005). However, cost performing generic forward search scales exponentially
search horizon. target monitoring example described large solved
offline approaches, but, demonstrate later, also requires long horizon search achieve
good performance, limiting effectiveness standard forward search long problems.
effort towards scaling large, long, partially observable decision making, introduce Posterior Belief Distribution (PBD) algorithm. PBD leverages insight certain
environments specific structure, distribution belief states (which turn distributions states) arise fixed sequence actions computed efficiently
analytically. distribution beliefs, posterior belief distribution, allows us scale large,
long POMDP problems using efficient forward search temporally-extended action sequences,
refer macro-actions. PBD selects action current belief planning
restricted policy space defined input macro-action set, re-plans selected
action taken new observation received. Note implies policy executed
necessarily equal policy space used planning, since first step macroaction executed re-planning performed. characteristic PBD similar
receding horizon controllers (RHC) (such Mayne, Rawlings, Rao, & Scokaert, 2000; Kuwata
& How, 2004). RHCs consider finite-horizon policy space performing planning,
execute much longer horizon repeatedly re-planning.
paper demonstrate PBD algorithm achieves good performance large, long
POMDP problems either outside scope prior approaches, prior approaches fail find good quality policies. experimental results demonstrate PBD performs
well attractive computational cost several large, long simulation problems, including
variant ROCKSAMPLE POMDP benchmark problem (Smith & Simmons, 2005) simulated target monitoring example. also demonstrate PBD algorithm real-world version
target monitoring problem, use robotic helicopter platform monitor multiple
ground vehicles (Section 6.4). demonstration suggests PBD practical potential real
1. Unless otherwise specified, describe domain large referring domain described
values number state variables, variable take many infinite number values.

524

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

robotic domains. paper, macro-actions assumed provided domain expert2 ;
however, decouple impact specific choice macro-actions, also provide experimental results modify alternate approaches (including state-of-the-art planner) use
macro-actions, still find performance advantages presented methods.
rest paper organized follows. Section 2 first provides brief background
planning uncertainty using forward search. introduce PBD algorithm Section 3, consider slight variant PBD applicable larger set domains Section 4.
Section 5 provide formal analysis PBD algorithm, Section 6 present
experimental results. present related work Section 7 finally conclude Section 8.

2. Background: Planning Uncertainty using Forward Search
Formally, assume decision-making state-uncertainty problem consists following known components:
set states. state consists assignment values L state
variables, sl . domain state variable may either discrete continuous.
set actions (controls) A, either discrete continuous.
Z set observations z Z, either discrete continuous.
p(s |s, a) transition function (also known dynamics model) encodes probability transitioning state taking action state s. assume dynamics
satisfy Markov assumption new state function immediately prior
state action.
p(z|s) observation function (also known measurement sensor model) encodes
probability receiving observation z state s.3
b0 distribution possible initial states, b0 (s) probability initial
state s. distribution known initial belief state, well-formed distribution
sums one across states.
r(s, a) reward (or cost) function describes utility agent receives taking
action state s. Slightly abusing notation, r(b, a) expected reward taking action
given distribution current states (belief) b.
discount factor determines weights immediate rewards relative rewards
received later time step.
states fully observable. Instead, every time step, agent receives observation taking action. agent must therefore make decisions based prior history
observations received, z1:t , actions taken, a1:t , time t. world states
assumed Markov, instead maintaining ever-expanding list past observations
2. work demonstrated automatically construct good macro-actions smaller
POMDPs (He, Brunskill, & Roy, 2010b). Integrating two lines work interesting area future work
outside scope paper.
3. easy extend framework allow observation depend prior state, action, posterior state.

525

fiH E , B RUNSKILL , & ROY

actions, sufficient statistic, known belief bt (s), used summarize probability
world state given past history,
bt (s) = P r(st = s|a0 , z1 , . . . , zt1 , at1 , zt ).

(1)

agent therefore plan based current belief state, rather past actions
observations (Smallwood & Sondik, 1973). example, target monitoring problem
introduced Section 1, agent maintains belief possible locations target.
agent updates belief step, taking action receiving observation z (such
camera image far target), using Bayes filter:
Z
p(s |s, a)b(s)ds
(2)
b (s ) = (b, a, z) = p(z|a, )
sS

(b, a, z) represents belief update function normalization constant.
planning problem compute policy : b a, mapping belief states
actions, maximizes expected sum future4 discounted utilities:
"
#
X

= argmax
E[r(bi )] ,
(3)
i=1

E[r(bi )] denotes expected reward time step given actions specified
possible observations received.
Many POMDP solvers, Smith Simmons (2005), Porta, Vlassis, Spaan,
Poupart (2006) Kurniawati, Hsu, Lee (2008), perform POMDP planning offline
calculating value function belief space V : b R. V (b) expected total reward
starting belief state b following optimal policy5 ,
Z


p(z|b, a)V ( (b, a, z)) ,
(4)
V (b) = max r(b, a) +
aA

zZ

R
p(z|b, a) = p(z|s, a)b(s)ds. Given value function belief space, policy
extracted finding action maximizes Equation 4.
Instead computing value function entire belief space advance acting, take
alternate approach planning online, explicitly computing policy (that is, action)
current belief. particular, action selected performing fixed-horizon forward search
used estimate values possible action choices starting current
belief. action-selection approach closely related methods controls community,
including Model Predictive/Receding Horizon Control, forward search also received recent
attention AI POMDP community (see recent survey Ross, Pineau, Paquet, & Chaibdraa, 2008a).
select action current belief, generic forward search approaches compute lookahead AND-OR tree (Figure 1). goal tree estimate value taking
4. assume paper interested problems infinite horizon. problem finite
horizon, discount factor set 1, forward search process (which shortly describe)
search depth problems finite horizon.
5. often intractable compute, practice value function often approximate.

526

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

Figure 1: forward search tree. actions, z observations, b beliefs. b0 initial
belief, bi,j refers jth belief leaf node depth i.

possible actions current belief b, order take action greatest value. Given
root belief b, tree constructed first branching possible actions root.
action, tree branches possible observations. distinct action-observation
combination, compute resulting internal belief would occur action-observation
trajectory followed using Equation 2. process alternately branching actions observations repeated finite depth. depth, known search horizon, determines
far future effects actions considered selecting possible action
root (current) belief state.
tree constructed, value actions root computed propagating rewards beliefs leaf nodes back root. Starting leaf node
rewards, take expectation observations. add expected immediate reward
taking parent action, next take maximum reward across sibling action nodes.
process repeated way root node. expected rewards maximized across
actions summed across observations agent choose action take, must
optimize expected distribution observations.
planning phase, forward search procedure executes action root
largest value, receives observation. Given previous belief, action taken,
observation received, new belief computed using Equation 2. forward search planning
process repeats, new belief root node. Re-planning every time step enables
agent condition action selected actual observation received.
number attractive characteristics online, forward-search framework. First,
computational effort directed towards belief states reachable current belief
different actions. property enables forward search planner compute meaningful
policy arbitrarily large environment, since subset environment relevant
point. Second, online, forward-search fits well systems need good, time constrained
solutions large amount advance computation possible. Lastly, forward search
527

fiH E , B RUNSKILL , & ROY

compute explicit representation value function, advantage
factored domains belief updating immediate expected reward calculations relatively
simple, value function complex represent.6
However, computational cost generic forward search still scale cost belief updating immediate expected reward calculations, multiplied number tree nodes
grows exponentially search horizon. costs belief updating calculating
immediate expected reward typically scale either linearly exponentially number
state variables size respective domains, depending independence relations
among state variables. state variables continuously-valued, therefore take
infinite number values, typically need employ parametric compressed
representation order make calculations tractable. number tree nodes scales exponentially horizon according O((|A||Z|)H ), |A| |Z| number actions
observations respectively H search horizon. Therefore, standard forward search approaches typically struggle many state variables and/or state variables large
domains large H-step lookahead necessary achieve good performance.
One approach accelerating planning large, long horizon problems use temporally
extended macro-actions, technique used successfully fully observable settings
years (Sutton, Precup, & Singh, 1999). limited exploration ideas
partially observable settings (exceptions include Theocharous & Kaelbling, 2003; Hsiao,
Lozano-Perez, & Kaelbling, 2008; Kurniawati, Du, Hsu, & Lee, 2009). work define
macro-action finite open-loop sequence primitive actions executed without regard
observations received execution action sequence. example, target
monitoring problem, one macro-action could helicopter travel key region,
might involve sequence individual turns straight line moves. restricting action space
set length L macro-actions, number expanded nodes due action branching factor
reduced from|A|H |A|H set length L (or longer) macro-actions,
7
H = H
L macro-action horizon depth .
2.1 Macro-action Construction
small set macro-actions evaluated search, restricted action space
result significant computational savings due smaller exponent H (vs. H) computational complexity expression. However, restriction also result poor algorithmic performance macro-actions evaluated unsuitable. paper, assume
macro-actions provided domain expert part comprehensive strategy scaling
large problems multi-step lookahead. macro-actions use experimental results consist open-loop policies function properties belief state
macro-action originated, either computed stored offline computed online
every timestep. details provided experimental section.
reliance domain knowledge paper similar prior work fully observable
community separately investigated potential advantage macro-actions turning
6. example domain one state space set independent variables, reward
aggregate function variables.
7. macro-action depth refers number macro-actions executed sequence root belief node
leaves.

528

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

challenge learning macro-actions (see work Sutton et al., 1999 overview
one particular formalism). Although constructing macro-actions automatically beyond scope
paper, presented related work domain-independent algorithm (PUMA) automatically generates macro-actions planning partially observable domains (He et al., 2010b).
Borrowing notion sub-goal states fully-observable planning literature (McGovern,
1998; Stolle & Precup, 2002), PUMA uses heuristic macro-actions designed take
agent, fully-observable model, possible start state current belief
sub-goal state. PUMA algorithm tested variations experimental domains
used paper, encourage reader refer above-mentioned paper
details.
Regardless set macro-actions generated, several key computational challenges
remain scale macro-action forward-search large, long environments. First, recall number
nodes generic forward search scales O(|A|H |Z|H ). Using macro-actions reduces first
term product, directly change second term, number tree nodes still
exponential function search horizon H. Second, using macro-actions directly
alleviate cost performing belief updates expected reward computations tree node,
computational costs substantial large domains. central contribution
paper method efficiently analytically computing result macro-action given
possible observation sequence received execution. allow us use temporallyextended actions scale certain types large, long POMDPs.

3. Posterior Belief Distribution Algorithm
plan macro-actions forward search manner, must compute expected reward received macro-action, well expected future value taking macro-action.
reward planner expect receive macro-action expected sum rewards posterior beliefs agent reach action macro-action.
However, process complicated fact posterior belief also result receiving
observation. agent know observations received macroaction, cannot compute single posterior belief reached macro-action, therefore
cannot compute expected reward.
course, easy solution consider possible observations, compute expected
reward possible beliefs result possible observations could received
macro-action. computing expected reward observation node, AND-OR
tree constructed forward search implicitly computes expectation possible observation sequences. But, computing expected reward macro-action requires enumerating
possible observation sequences could experienced execution, evaluation
macro-action grow intractable quickly (see Figure 2(a)). number observation sequences
considered grow exponentially length macro-action, enumerating
possible observations may even feasible domains continuous observations. One alternative may sample observation sequences given macro-action (Figure 2(b)), sampling
likely still computationally intensive due per-sample cost performing belief update
expected reward calculation step sampled observation sequence.
avoid computational burden realizing sometimes possible analytically
represent distribution posterior beliefs. given sequence actions, need
529

fiH E , B RUNSKILL , & ROY

(a) Exhaustive

(b) Sampled

(c) Analytic

Figure 2: Three methods represent resulting set beliefs single macro-action. (a)
possible observations expanded. (b) subset possible observation trajectories
sampled. (c) Compute analytic distribution posterior beliefs, could
generated via exhaustive enumeration possible observation sequences.
b0 initial belief, bi,j refers j th belief leaf node depth i.

expected reward actions; cannot compute distribution states ahead time,
compute distribution state distributions, still compute expected reward.
graphical depiction process shown Figure 2(c). analytically computing distribution
beliefs, avoid exponential explosion potential observation sequences (as
function macro-action length), also costly step performing many individual belief
updates along possible observation sequences.
define bdist posterior distribution beliefs macro-action. show
next subsection (3.1) parametric form model belief
always Gaussian, distribution posterior beliefs Gaussian Gaussian
beliefs, illustrated Figure 3. property follows fact future beliefs
Gaussian. random variables described distribution posterior beliefs therefore
means covariances posterior beliefs. case, bdist consists expression
distribution belief means expression distribution covariances
macro-action. show means distributed according Gaussian
covariances delta function single covariance, allowing us represent entire
distribution beliefs Gaussian distribution beliefs means single belief covariance.
Section 3.2 show analytically compute expected reward
distribution beliefs resulting macro-action certain classes reward functions. Given
ability analytically compute distribution posterior beliefs, show Section 5
computational complexity forward search reduced function macro-action horizon
H: macro-actions length 2 (L 2) see significantly faster search
long horizons.
530

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

Figure 3: Distribution posterior beliefs. a) single Gaussian posterior belief result
incorporating observation sequence. b) possible observation sequences,
distribution posterior means Gaussian (black line), posterior mean,
Gaussian (blue curve) describes agents posterior belief.

3.1 Exact Computation Posterior Belief Distribution
Let us assume moment agents belief exactly represented Gaussian
distribution continuous state space, observation transition models
linear-Gaussian. Formally, state transition observation models represented follows:
N (0, P )

st = Ast1 + Bat + ,

N (0, Q)

zt = Cst + ,

(5)
(6)

B dynamics matrices, C observation matrix, P covariance
Gaussian dynamics process Q covariance measurement noise.
state-transition observation models normally distributed linear functions
state, Kalman filter (1960) provides closed-form solution posterior belief
states, N (t , ) given prior belief states, N (t1 , t1 ),
= + Kt (zt Ct )

= At1 + Bat
= At1 + P

= (C Q1 C +

1
)1 ,

(7)
(8)

N (f, F ) D-dimensional Gaussian mean f covariance matrix F ,
Kt = C (Ct C + Q)1 Kalman gain mean covariance
action taken incorporating measurement.
key interest represent distribution possible beliefs could result taking
particular action, receiving possible observations. Note current setup,
posterior beliefs Gaussians, therefore completely characterized mean
covariance. derive expression distribution posterior belief means,
possible observation, prior distribution beliefs simply delta function
single belief. first re-express observation model
zt N (Cst , Q)
531

(9)

fiH E , B RUNSKILL , & ROY

use compute expression probability observation given belief
mean, p(zt |t ), marginalizing st N (t , ),
R
(10)
p(zt |t ) = p(zt |st )p(st |t )dst
= N (Ct , Ct C + Q).

(11)

perform linear transformations obtain expression distribution posterior means, potential observation:
zt N (Ct , Ct C + Q)

zt Ct N (0, Ct C + Q)

Kt (zt Ct )

+ Kt (zt Ct )





N (0, Kt (Ct C + Q)KtT )
N (t , Kt (Ct C + Q)KtT )
N (t , Kt (Ct C + Q)KtT )
N (t , C KtT )

(12)
(13)
(14)
(15)
(16)
(17)

Equation 17 computed substituting definition Kalman gain.
point, somewhat unusual change occurred, , mean distribution
itself, random variable. Without knowing value particular observation
occurs primitive action, cannot deterministically predict posterior mean belief.8
However, model probability specific belief state, effectively means
compute distribution belief means covariances . Equation 17 shows
distribution belief means normally distributed , covariance
depends prior covariance observation model parameters. Sampling mean
distribution equivalent selecting particular observation.
presented formula calculating posterior distribution belief means
one action, possible observation. wish show posterior distribution
beliefs means sequence actions remains Gaussian distribution. allow us
compute analytic expression posterior distribution beliefs could result
macro-action. therefore require method iteratively use Equation 17 order compute
posterior distribution beliefs complete macro-action possible observation
sequence.
first combine process measurement updates single primitive action belief update order get expression posterior belief means terms prior belief mean.
marginalize , theR posterior belief transition update observation
update, using p(t |t1 ) = p(t |t )p(t |t1 )dt . deterministic function t1 (see
Equation 7a), p(t |t1 ) simply delta function, means p(t |t1 ) identical
Equation 17 substituting using Equation 7a:
p(t |t1 ) = N (At1 + Bat , C KtT ).

(18)

one-step belief update, belief mean prior time step, t1 , assumed known
value. However, macro-action, first primitive action taken, posterior be8. Note show later section deterministically predict posterior belief covariance.
distribution Dirac delta independent specific observation received.

532

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

lief mean depend received observation. absence knowledge received observation, instead distribution belief means. Therefore, second primitive action macro-action, prior belief given Gaussian t1 N (mt1 , t1 )
mt1 t1 random variables. order compute probability distribution
, must integrate distribution prior belief means t1 :
Z
(19)
p(t |t1 )p(t1 |mt1 , t1 )dt1 .
p(t |mt1 , t1 ) =
t1

Since terms inside integral Gaussian distributions, analytically combine
two Gaussians, one independent t1 one dependent t1 . Integrating t1 , done Equations 9-11, find mean posterior belief
means conveniently still Gaussian distribution function prior mean belief
means covariance:
N (Amt1 + Bat , At1 + C KtT )

(20)

N (mt , )

(21)



mt = Amt1 + Bat = At1 + C KtT . Equation 20 used
predict posterior mean distribution multi-step action sequence. Assuming agent
currently time particular prior mean (which also express Gaussian
zero covariance, N (t , 0)), posterior mean action sequence time steps
distributed follows:
t+D N (mt+D , t:t+D )

(22)


mt+D = f (t1 , A, B, at+1:t+D )
= mt+D1 + B at+D

X
ADi Bat+i ,
= AD mt +

(23)
(24)
(25)

i=1


t:t+D

=

t+D
X

At+Di CiT DiT (At+Di )T .

(26)

i=t

Note mt+D depend observations; gives mean distribution beliefs
might result received observations. mt+D dependent state-transition model
parameters calculated via recursive update along action sequence.
consider covariance posterior beliefs may result taking macroaction. Recall single belief, posterior covariance taking primitive action
receiving particular observation calculated using Equation 8. Note formula independent actual received observation zt , prior t1 posterior mean . Formally,
533

fiH E , B RUNSKILL , & ROY

property exists Fisher information associated observation model independent
specific observations. Therefore, posterior covariance observation sequence
known length calculated closed form given prior covariance, without needing know
observations received along way.
specify form bdist , posterior distribution beliefs macro-action:
bdist (t+T , ) = N (f (t1 , A, B, at:t+T ), t:T ) (, )

(27)

bdist (t+T , ) probability arriving posterior belief b = N (t+T , ) taking
particular macro-action, Equation 22 defines distribution belief means, computed
iteratively applying Equation 8. expression shows problems linear-Gaussian
state-transition observation models, exactly calculate distribution posterior beliefs
associated macro-action.
3.2 Calculating Expected Reward
prior section outlined procedure calculating posterior set beliefs macroaction. reason compute distribution turn able calculate expected reward
macro-action, used compute best action current belief.
calculate expected reward macro-action, start considering expected reward
starting particular belief state b0 executing L-length macro-action consisting
actions a1 , a2 , . . . , aL . may expressed
Z
r(b0 , a1:L ) = r(b0 , a1 ) +
p(z1 |b0 , a)Q(ba1 ,z1 , a2:L )
(28)
z1

ba1 ,z1

represent updated belief taking action a1 receiving obserwhere used
vation z1 b0 , a2:L represent macro-action consisting second L-th primitive
actions macro-action a, Q(ba1 ,z1 , a2:L ) represent future expected reward taking
remaining actions belief ba1 ,z1 . Recursively expanding second term Equation 28
obtain following expression
Z
p(z1 |b0 , a1 )r(ba1 ,z1 , a2 ) +
r(b0 , a1:L ) = r(b0 , a1 ) +
z1
Z
2

p(z1 |b0 , a1 )p(z2 |ba1 ,z1 , a2 )r(ba1 ,z1 ,a2 ,z2 , a3 ) +
(29)
z1 ,z2



L1

Z

z1 ,...,zL

"L1

i=1

p(zi |b

a1 ,z1 ,...,ai1 ,zi1

#

, ai ) r(ba1 ,...aL1 ,zL1 , aL ). (30)

first term Equation 29 represents expected reward taking first primitive action
macro-action initial belief state. remaining terms represent expected
reward i-th primitive action macro-action, expectation taken
possible 1 length sequences observations could received point (as
well standard integration state space). Equation 27 closed form
expression distribution belief states possible sequence primitive actions.
use re-express Equation 29 function distributions beliefs:
r(b0 , a1:L ) = r(b0 , a1 ) +

L
X
i=2

534

i1 r(bi1
dist , ai )

(31)

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

bi1
dist used represent posterior distribution beliefs results taking
first 1 primitive actions macro action a. Slightly abusing notation, r(bdist , ai ) represents
expected reward taking action ai given posterior distribution beliefs bdist ,
expressed
Z Z
b(s)bdist (b)r(s, ai )dsdb.
(32)
r(bdist , ai ) =
b



Combining Equations 31 32, see expected reward macro-action
calculated sum expected reward taking primitive action posterior
distribution beliefs step along macro-action.
Recall prior section posterior distribution beliefs factored
Gaussian distribution belief means (Equation 22), Dirac delta distribution
belief covariances (since beliefs identical covariances):
bdist (, ) = N (|ma , )(, )

(33)

mean belief means primitive action a, covariance belief
means primitive action a, covariance belief state primitive action a.
belief state Gaussian,
b(s) = N (s|, ),
re-express reward
Z Z
r(s, a)N (s|, )N (|ma , )(, )dsdd
r(bdist , a) =
,
Z Z
r(s, a)N (s|, )N (|ma , )dds,
=


(34)

(35)
(36)



second line follows due Dirac delta distribution belief covariances. Expanding formula N (s|, ) see identical formula N (|s, ):
1
1
exp( (s )1 (s )T )
N
/2

2
2||
1
1
exp( ( s)1 ( s)T )
=
2
2||Nd /2
= N (|s, ).


N (s|, ) =

Therefore, substitute equivalent expression yield
Z Z
r(s, a)N (|s, )N (|ma , )dds.
r(bdist , a) =


(37)
(38)
(39)

(40)



Completing square exponent, re-express product two Gaussians
Z Z
r(s, a)N (s|ma , + )N (|c, C)dds,
(41)
r(bdist , a) =




535

fiH E , B RUNSKILL , & ROY

1 1
C = (1
c = C(ma (a )1 + 1
+ (a ) )
). integrate get
Z
r(s, a)N (s|ma , + )ds.
(42)
r(bdist , a) =


reward model weighted sum Nr Gaussians,
r(s, a) =

Nr
X
j=1

wj N (s|j , j ),

(43)

integral Equation 42 evaluated closed form
Z X
Nr
r(bdist , a) =
wj N (s|j , j )N (s|ma , + )ds

(44)

j=1

=

Nr
X
j=1

wj N (j |ma , j + +

)

Z



N (s|c1 , C1 ),

(45)

completed square exponent, defined new constants C1 = (1
j +
1 1
1
1
(a + ) ) c1 = C1 (j j + (a + ) ). Integrating obtain analytic
expression expected reward primitive action distribution beliefs:
r(bdist , a) =

Nr
X
j=1

wj N (j |ma , j + + ).

(46)

similar closed-form expression available reward model polynomial function
state,
r(s, a) =

Nr
X

wj sj ,

(47)

j=1

instead weighted sum Gaussians. Substituting Equation 47 Equation 42 yields
Z X
Nr
r(bdist , a) =
wj sj N (s|ma , + )ds
j=1

=

Nr
X
j=1

wj

Z



sj N (s|ma , + )ds.

(48)

Therefore, evaluating expected reward involves calculating first Nr moments Gaussian
distribution. moments analytic expression Gaussian mean covariance.9 So, reward models either weighted sum Gaussians, polynomial
functions state space, expected reward macro-action (Equation 28) computed
analytically.
arbitrary reward models may possible analytically compute expected
reward taking primitive action particular distribution beliefs. cases,
approximate expectation Equation 42 sampling.
9. Gaussian distribution completely described first two moments; higher order moments simply
functions first two moments.

536

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

Figure 4: PBD, individual beliefs b sampled posterior distribution beliefs bdist ,
implicitly sampling particular observation trajectory. best macro-action
selected sampled posterior belief. sum taken sampled beliefs,
corresponding sum implicitly sampled observation sequences. Here,
bi refers beliefs macro-action depth i.

3.3 Branching Posterior Beliefs
far discussed compute posterior distribution beliefs arise
executing single macro-action, compute expected reward associated
distribution. planning wish compute value taking single macroaction, sequences macro-actions. allows us consider scenarios much
future, useful selecting best action take current belief. example,
consider large office space domain robot trying navigate goal location,
macro-actions go end hallway turn left right. Assuming robot starts
far goal location, series macro-actions likely needed order reach
goal, therefore important forward search consider search horizon
multiple macro-actions.
However, constructing forward search tree, immediately clear evaluate
branch three end macro-action. closed form expression
posterior distribution beliefs end macro-action. posterior set represents
distribution beliefs possible given possible observation sequences could received
macro-actions execution. However, different individual posterior beliefs, different
subsets posterior belief distribution, may associated different best subsequent macroactions tree, different individual posterior beliefs implicitly result receiving
different set observations macro-action execution may reveal important information environment result different best subsequent macro-actions. Though
motivation behind macro-actions reasonable act open-loop fashion limited
537

fiH E , B RUNSKILL , & ROY

Algorithm 1 Forward Search Macro-Actions
Require: Initial belief b0 , Discount factor , Macro-action search depth H, Sampling number Ns
1: 0
2: loop
3:
Compute set macro-actions
4:
macro-action ai
5:
Q(bt , ai ) = E XPAND(ai , bt , , H, Ns ) {See Algorithm 2}
6:
end
7:
Execute first action a1 = argmaxa Q(bt , a)
8:
Obtain new observation zt reward rt
9:
bt+1 = (bt , , zt )
10:
tt+1
11: end loop

time period, received observation sequence provide information underlying belief
likely useful selecting future macro-actions.
Since know advance subsets posterior beliefs associated
best subsequent macro-action, instead sample posterior belief distribution,
evaluate future macro-actions samples (see Figure 4 illustration). Sampling
posterior belief equivalent implicitly sampling observation sequence planned macroaction, without actually perform belief updates along action-observation trajectory.
Note potential space observation sequences grows exponentially macro-action
length. posterior distribution beliefs Gaussian, properties completely
described mean covariance, means posterior distribution beliefs
typically much lower dimension observation sequence space. Experimentally
see much better performance sampling posterior belief distribution sampling
space observation sequences. sampled beliefs essentially form non-parametric,
particle estimate posterior distribution beliefs present taking macro-action.
number samples Ns goes infinity, sampled distribution become arbitrarily
good approximation full posterior distribution beliefs. covariance Dirac delta
distribution, sampling needed posterior mean distribution, generating posterior belief
samples associating posterior mean sample posterior covariance t+T .
3.4 PBD Algorithm Summary
ready present PBD forward search algorithm (Algorithm 1). Given current
belief, select action constructing macro-action forward search tree. Placing current
belief root, expand possible macro-action (Algorithm 2), computing expected
reward resulting posterior set beliefs. sample fixed number posterior beliefs.
Forward search proceeds sampled beliefs. repeat process
fixed horizon depth select action current belief estimating value, starting
search leaf nodes. executing action, observation received, new
belief state computed. whole process repeats new belief state. Note PBD
ever select actions first action macro-action. primitive actions
538

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

Algorithm 2 E XPAND Expand Macro-actions via PBD
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:

Input: Macro-action a, Belief state bt , Discount factor , Macro-action search depth H,
No. posterior belief samples per macro-action Ns
H = 0
return 0
else {Expand Macro-action a={a1 , . . . , aL }}
Ra = 0
bdist = bt
j = 1 L
Ra = Ra + r(bdist , aj )
Update posterior distribution beliefs bdist
end
= 1 Ns
Sample posterior mean ni according N (mt+T , t+T )
bi N (ni , t+T )
Generate next set macro-actions Anext
Anext
anext

next
Q(bi , ai ) = E XPAND(anext
,bi ,,H 1,Ns )

end
V = Ra + N1s L maxanext
Q(bi , anext
))


end
return V
end

considered, number macro-actions evaluated root belief every timestep
must least size primitive action space, primitive action must
first action least one macro-action.

4. Approximate Computation Posterior Belief Distributions
PBD algorithm described far assumes transition observation functions linear functions state Gaussian noise. functions non-linear, traditional
Kalman filter model longer provides exact belief update, PBD algorithm, distribution posterior beliefs cannot calculated exactly. section briefly describe
extension PBD algorithm handle wider class observation models, namely parametric models members exponential family distributions (Barndorff-Nielsen, 1979).
non-linear transition models, exist techniques extended Kalman filter approximate posterior Gaussian; however, formally consider incorporating
techniques PBD algorithm here.
choose consider exponential family observation models since family includes wide
array distributions, Gaussian, Bernoulli, Poisson distributions, certain appealing mathematical properties. particular, leverage work West, Harrison Migon (1985)
constructed linear-Gaussian models approximate non-Gaussian exponential family observation model neighborhood conditional mode, st |zt . used approximate
539

fiH E , B RUNSKILL , & ROY

linear-Gaussian observation mode traditional Kalman filter, maintain closed-form Gaussian
representation posterior belief, creating exponential family Kalman Filter (efKF). completeness include West et al.s derivation filter Appendix A, present main
equations here.
Constructing approximate linear-Gaussian observation model requires computation
first two moments distribution linearization around mean estimate every time
step. exponential family observation model represented follows,
p(zt |t ) = exp(ztT (t ) + (zt )),

= W (st )

(49)

st hidden state system, (t ) canonical parameter normalization factor distribution, W (.) maps states canonical parameter values. W (.)
also known canonical link function, depends particular member exponential
family.
first two moments distribution (West et al., 1985)
(t ) fifi
E(zt |t ) = =
fi
=W (t )

2 (t ) fifi
V ar(zt |t ) = =
fi
tT =W (t )

(50)

derivatives exponential family distributions normalization factor,
linearized = W (t ).
Given action-observation sequence, posterior mean agents belief efKF
updated according
= At1 + Bat
= At1 + P

= + Kt (zt W (t )),

(51)

=

(52)

1
(t

+ YtT Yt )1 ,

Kt = Yt (Yt YtT + t1 )1 efKF Kalman gain, zt = t1 (t zt )
projection fiof observation onto parameter space exponential family observation
tfi
model. Yt =
st st =t gradient exponential family distributions canonical parameter,
linearized .
incorporate results compute modified form posterior belief mean
covariance distributions, represented Equations 8 22 observation
model linear Gaussian. Now, exponential family observation models, posterior belief
covariance comes Equation 52. expression distribution posterior means
modified based efKF equations:

t+T N (f (t1 , At:t+T , Bt:t+T , at:t+T ),

t+T
X

YiT KiT ).

(53)

i=t

worth noting contrast prior expressions posterior belief distribution
(Equations 8 22), exact completely independent received observations,
Equations 52 53 longer independent observations obtained observation model parameters linearized prior mean . Hence parameters
independent observation obtained macro-action sequence length 1,
540

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

longer macro-action, observation model parameters depend prior observations obtained.
approximate update linearizing mean prior mean distribution mt
step along action sequence, rather true prior belief mean . shortly see
still obtain good experimental results using approximation.
alternate popular approach non-Gaussian systems use particle filter represent
system state. However, high dimensional, continuous environments similar ones considered
paper, particle filters often suffer particle depletion, require large number
particles accurately capture posterior. costs belief updating expected reward
calculations scale number particles. contrast, approximate PBD computation
computational complexity exact PBD computation, demonstrate
later sections scale polynomially number state dimensions.
approximate method computing posterior distribution beliefs used
substitute exactly calculating posterior distribution beliefs PBD algorithm.

5. Analysis
provide formal analysis accuracy computational complexity PBD algorithm. Throughout section assume belief states represented exactly Gaussian
distributions: words, assume linear-Gaussian system. following sections
demonstrate experimentally PBD algorithm useful wider variety problems
using EKF efKF described Section 4, incorporating error approximate
filtering techniques analysis algorithm topic future research.
5.1 Performance
PBD selects actions performing limited-horizon forward search using restricted policy space
induced macro-actions. However, execution, first step macro-action
taken. observation received, belief state updated, planning repeated
resulting belief. taking first primitive action, system may take sequences
actions correspond known macro-actions, effectively expanding
considered policy space. result, performance least good actually executing
entire macro-action. However, would useful determine claims made
belief-action values calculated part PBD algorithm. Obviously, received rewards
executed policy always less equal optimal policys rewards, since
policy space considered planning smaller full policy space. However, values
calculated PBD algorithm approximate values due approximations (such
sampling subset posterior beliefs) made computation process. prove
linear-Gaussian systems, values computed PBD, minus additional epsilon term due
approximations incurred sampling subset posterior beliefs macro-action,
probabilistically guaranteed lower bound true optimal values. purpose
analysis assume rewards scaled lie 0 1. maximum
number macro-actions.
Theorem 5.1 Given linear-Gaussian system, initial belief b, > 0,
reward model either weighted sum Gaussians, polynomial function, following
541

fiH E , B RUNSKILL , & ROY

lower bound optimal value b holds
VP BD (b) H V (b)
q

2

H

Vmax
(M Ns )
probability least 1 , H =
)), Vmax
max +
Ns log(

10
bound maximum value , VP BD (b) best value computed b PBD planning
algorithm.

H V

1
1 (

Proof First recall PBD algorithm macro-action, subset possible posterior beliefs sampled posterior belief distribution, tree expanded.
Note equivalent implicitly sampling subset observation trajectories might
received macro-action: sampled posterior belief corresponds belief
would result following macro-action receiving particular sequence observations.
Consider alternate variant macro-action forward search observation sequences
exhaustively enumerated11 : is, macro-action length L, |Z|L possible observation
sequences expanded. case, forward search tree constructed precisely subset
full POMDP forward search tree, since macro-actions mean subset actions
expanded. Therefore, computed values alternate algorithm directly lower bound
optimal finite-horizon value, since policy space considered strict subset full
optimal finite-horizon policy space.
However, computational reasons, macro-action tree node, subset observation sequences sampled, results averaged across observation sequences.
observation sequences happen lead higher rewards may be, chance, disproportionately
sampled, resulting VP BD value could upper bound true optimal value. However,
probabilistically bound error induced observation sampling,
Prior work Kearns, Mansour Ng (2002) proved bounds MDP state values computed using sampled-states forward search given certain constraints number samples,
horizon forward search. McAllester Singh (1999) extended ideas POMDPs,
showing similar bounds calculated values POMDP belief state could computed
sufficient number observations sampled, forward search computed
sufficiently large horizon. results applied little modification PBD algorithm. Essentially consider new meta-POMDP available actions
macro-actions, observations sequences primitive observations. Since compute
expected reward macro-actions analytically (due assumed form reward model),
errors evaluating root belief node values macro-action policy come limited sampling observation trajectories, performing finite horizon lookahead. prior
results McAllester Singh directly apply meta-POMDP, therefore, values computed PBD.
obtain final result, depart slightly presentation Kearns, Mansour Ng
sought compute number samples required, horizon required, ensure
resulting root state-action values within specified bound true value. contrast,
seek compute resulting error input number samples Ns fixed horizon H.
10. maximum value trivially upper bounded maxs,a r(s, a)/(1 ).
11. possible finite number observations.

542

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

proof Kearns, Mansour Ng, show error calculated Hhorizon state-action value QH (b, a) true infinite-horizon policy value Q(b, a)
|QH (b, a) Q(b, a)| H Vmax +


1

(54)

probability least 1
2
(M Ns )H exp(2 Ns /Vmax
).

solve Equation 55 , yield

2
Vmax
(M Ns )H
.
log

Ns


(55)

(56)

Substituting Equation 56 Equation 54 re-arranging yields desired result.
reward macro-action cannot analytically computed, approximate value
sampling Nr samples primitive action along length-L macro-action. input
compute probabilistic bound resulting error approximate value
primitive action using Chernoffs bound. Using union bound, probability true error
exceed threshold primitive action along macro-action L ,
resulting error sum error primitive action. error (and probability
error) easily incorporated extend Theorem 1 case generic reward models.
Note Theorem 1 states high probability VP BD H lower bound
optimal value: provide tight bound close computed VP BD
optimal value. state alternate way, H provides bound error introduced
sampling observation sequences, PBD still designed search limited policy
space, defined macro-actions chosen used forward search. Therefore general
computed values, even large number observation sequences sampled, may
substantially less value optimal policy.
5.2 Computational Complexity
One central contributions work providing efficient macro-action forward search
algorithm scale long horizons large problems. analyze computational
complexity approach. computational cost function two operations: computing posterior distribution beliefs, computing expected reward distribution
beliefs. shortly see, computational complexity operations polynomial
function state space dimension.12 low order relationship possible due particular parametric representation employed posterior distribution beliefs: representing
posterior distribution beliefs Gaussian requires number parameters scales
quadratically number state dimensions.13 PBD therefore able scale large domains. computational complexity results summarized Table 1. Throughout analysis
12. multiple independent state variables, factors, complexity increases linearly number
independent factors.
13. represent Gaussian X dimensions requires X-dimensional vector specify mean, O(X 2 ) parameters specify covariance.

543

fiH E , B RUNSKILL , & ROY

presume macro-actions selected computed advance; general,
cost computing domain-relevant macro-actions depend particular domain,
analyze possible additional computational cost incurred macro-action
construction.
5.2.1 C OMPLEXITY



G AUSSIAN B ELIEF U PDATING



L ENGTH L ACRO - ACTION

computation posterior distribution beliefs resulting macro-action presented Equation 53, consists set matrix multiplications inversions. Matrix multiplication O(D2 ) computation, state space dimension. Matrix inversion
done O(D3 ) time. Therefore computational cost performing single update posterior belief states O(D3 ) operation. update must performed primitive
action length-L macro-action a, resulting computational cost
O(LD3 )

(57)

single macro-action.
Section 4 presented set equations (Equations 50- 53) use approximately
compute posterior distribution beliefs observation model Gaussian,
exponential family. equations consist set matrix multiplications, cost
single update, cost updating length-L macro-action O(D3 )
O(LD3 ), respectively.14
5.2.2 C OMPLEXITY NALYTICALLY C OMPUTING
L ACRO - ACTION



E XPECTED R EWARD



L ENGTH

second component computational cost comes evaluate expected reward
macro-action. reward weighted sum Nr Gaussians, specified Equation 43,
operation involves evaluating value Nr L Gaussians particular fixed points. Evaluating
D-dimensional Gaussian single point O(D3 ) operation, due inverse covariance
must computed. cost performing operation Nr L times simply O(Nr LD3 ).
Therefore total cost evaluating expected reward macro-action reward model
weighted sum Nr Gaussians is:
O(LD3 (Nr + 1)).

(58)

instead reward model Nr -th degree polynomial function state, expected
reward calculation consists cost calculating Nr -moments D-dimensional Gaussian
distribution (Equation 48). Assume without loss generality computing Nr -th
central moment D-dimensional Gaussian: non-central moment always converted
central moment adding subtracting mean term. Let Nr -th central moment denote
moments form E[(s1 E[s1 ])2 (s2 E[s2 ]) . . . (sD E[sD ])] E[(s2 E[s2 ])Nr ],
ij denote ij-th entry covariance matrix. work Triantafyllopoulos (2003)
know Nr odd, central Nr -th moments zero, Nr even (Nr = 2k) Nr -th
14. actual computational cost higher efKF filter since additional operations must performed link
observation parameter space, operations similarly cubic lower functions state
space dimension.

544

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

central moments decomposed sum products k covariance terms. example,
four-dimensional Gaussian, one fourth central moments (k = 2, 4 = 2k)
X
ij kl (59)
E[(s1 1 )(s2 2 )(s3 3 )(s4 4 )] = 12 34 + 14 23 + 13 24 =
1,2,3,4

sum taken permutations product pairs (in case, 12/34, 14/23, 13/24).
2k-th central moment,
X
E[(si1 E[si1 ])(sj1 E[sj1 ]) . . . (sik E[sik ])(sjk E[sjk ])] =
i1 j1 i2 j2 . . . ik jk (60)

sum taken permutations product pairs. sum yields (Nr
1)!/(2k1 (k 1)!) terms consist covariance elements power k.
particular central moment, cost independent dimension state space. Therefore
cost dominated number terms, grows slightly less O(Nr !).
also additional cost original polynomial central moment calculation,
involve Nr D-dimensional matrix multiplications, yielding cost O(Nr D2 ).
summary, cost computing expected reward reward polynomial function

O(L(D3 + Nr ! + Nr D2 )).
5.2.3 C OMPLEXITY



(61)

C ONDITIONAL ACRO - ACTION P LANNING (PBD)

Sampling beliefs posterior distribution beliefs requires sampling multivariate
Gaussian distribution belief means, accomplish computing Cholesky
decomposition covariance matrix, = AAT , O(D3 ) operation. belief mean
generated first constructing D-dimensional vector q, consisting independent samples
standard (scalar) normal distribution. sample desired multivariate Gaussian
N (s|, ) simply + Aq. Sampling Ns times involves one-time cost computing
Cholesky decomposition plus matrix-vector multiplication sample, yielding cost
O(D3 + Ns D2 ).

(62)

procedure performed every branch point forward search tree (in words,
macro-action nodes except tree leaves). concreteness, consider horizon two
macro-actions (H = 2). expanding |A| macro-actions, sample Ns
beliefs. resulting belief state, expand |A| macro-actions: refer
back Figure 4 illustration. computational complexity sum cost
horizon one two:
O(|A|(LD3 Nr + Ns D2 + D3 ) + |A|2 Ns LD3 Nr ) = O(|A|(Ns D2 + D3 ) + |A|2 Ns LD3 C), (63)
second expression derived considering higher order terms. general,
computational complexity selecting action using PBD considering future horizon
H macro-actions
O(|A|H1 NsH2 (Ns D2 + D3 ) + |A|H NsH1 LD3 C).
545

(64)

fiH E , B RUNSKILL , & ROY

Algorithm
PBD Analytic Expected Reward
PBD Arbitrary Reward Model

Computational Complexiy
O(|A|H1 NsH2 (Ns D2 + D3 ) + |A|H NsH1 LD3 C) (Eqn.
O(|A|H NsH LD3 + |A|H NsH LD2 ) (Eqn. 66)

Table 1: Computational complexity selecting action using PBD algorithm closely related
alternatives. number state dimensions, H macro-action forward search
horizon, Ns number sampled beliefs. Slightly abusing notation, also use
Ns represent number sampled states, case arbitrary reward models.

5.2.4 C OMPLEXITY



PBD



RBITRARY R EWARD ODELS

arbitrary reward models possible analytically compute expected reward.
Instead expected reward primitive action within macro-action approximated sampling D-dimensional states estimating expected reward averaging
reward sampled state.15 cost sampling Ns states multivariate Gaussian
O(D3 + Ns D2 ) operation (from Equation 62). Assuming calculating reward
sample takes time linear state dimension, sampling rewards adds additional
O(D3 + Ns D2 D) = O(D3 (Ns + 1))

(65)

cost primitive action within macro-action, yielding total complexity PBD planning
reward sampling of:
O(|A|H NsH LD3 + |A|H NsH LD2 ).

(66)

6. Experimental Results
section test algorithm planning uncertainty problems. PBD algorithm
assumes transition models problem domains approximated linear Gaussians.
results problems inspired two different research communities, scientific exploration
POMDP literature (Smith & Simmons, 2005) target monitoring sensor resource
management domain, suggest numerous domains satisfy assumption. generally,
using linear Gaussian dynamics models common approximation controls community,
used approximate even complex dynamics physiological changes
involved glucose control diabetics (Patek, Breton, Chen, Solomon, & Kovatchev, 2007).
Despite different origins state space representations two problems
shortly present results for, involve reasoning multiple steps future order
make good decisions large domain. PBD algorithm outperforms existing approaches
settings. also demonstrate algorithm target monitoring problem actual
15. Note rewards bounded, given , sampling sufficient number samples Ns = f (, ),
guarantees estimate expected reward primitive action -close true expected value,
probability least 1 . proof simple application Hoeffdings inequality (1963). Ns set
estimated reward primitive action L close true expected primitive action reward
probability least 1 , triangle inequality union bound guarantee expected reward entire
length-L macro-action -close true expected reward macro-action probability least 1 .

546

64)

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

helicopter platform, underscoring applicability algorithm real-world domains.
results macro-action search horizon H chosen empirically given computational constraints,
common forward search approaches. explicitly explore performance changes
search horizon varied Table 3. use domain-specific estimate future node
value search tree leaf nodes: domains may easier specify macro-actions
heuristic value function, side benefit PBD able efficiently search sufficient
depths heuristic required.
6.1 Generic Baselines
problems compare PBD algorithm state-of-the-art approaches relevant
research community POMDP planners sensor resource management algorithms scientific exploration target monitoring problems respectively.
fully examine impact analytically computing posterior distribution beliefs,
also constructed variety algorithms currently exist literature. algorithms given access hand-coded macro-actions used PBD algorithm.
first constructed comparison algorithms use macro-action forward search sample
observation trajectories rather working posterior distribution beliefs. Sampling
observation sequences produces particle approximation resulting distribution beliefs,
thereby providing baseline algorithm use analytic representation posterior
belief distribution. algorithms referred macro-action discrete (MAD) algorithm
underlying state space discrete, macro-action continuous (MAC) algorithm
state space continuous.
also implemented offline point-based POMDP solver given access macroactions used forward search algorithms.16 Specifically, modified state-of-the-art
POMDP planner SARSOP (Kurniawati et al., 2008) algorithm Approximate POMDP Planning (APPL) Toolkit17 incorporated macro-actions guide sampling belief points
used point-based value backups. Instead SARSOP algorithm using performance
bounds guide sampling point-based beliefs, modified SARSOP algorithm uses
macro-action sampled, same-length observation sequence generate additional point-based
belief samples. implementation also modified version MiGS (Kurniawati et al.,
2009) authors. However, due offline, point-based nature modified algorithm, able evaluate algorithm two five problem domains used
paper.
Finally, considered experimental comparison open-loop version PBD,
conditioning received observations ever performed; however, initial experiments suggested
variant performed poorly domains interest, explore
further.
6.2 Rocksample
scientific exploration ROCKSAMPLE problem benchmark POMDP problem proposed
Smith Simmons (2005), subsequently extended FieldVisionRockSample (FVRS)
16. formal discussion differences offline point-based online forward search POMDP algorithms, refer reader survey paper Ross et al. (2008a).
17. Approximate POMDP Planning Toolkit. http://bigbird.comp.nus.edu.sg/pmwiki/farm/appl/

547

fiH E , B RUNSKILL , & ROY

(a) ISRS(8,5)

(b) SARSOP policy

(c) PBD policy

Figure 5: Information Search Rocksample (ISRS) problem. (a) Initial (hidden) problem state.
agent (pink square) explores samples rocks (circles) world. White circles correspond rocks positive value, black otherwise. Yellow squares indicate locations
rock information beacons. blue sidebar exit region. Red lines indicate
paths taken agent executing (b) SARSOP (c) PBD policies. see
SARSOP policy explores rocks beacons; cannot search far enough
ahead model value beacons. contrast, PBD plan visits beacons
heads directly high-value rocks.

problem Ross Chaib-draa (2007). Initial experiments domains revealed searching shallow depth sufficient obtain good policies. interest domains
require long-horizon lookahead, created new variant ROCKSAMPLE problem
called Information Search Rocksample (ISRS) problem, shown Figure 5(a). ISRS agent
explores samples k rocks n n grid world. positions agent (pink square)
rocks (circles) fully observable, value rock (good bad) unknown
agent. every time step, agent receives binary observation value rock.
accuracy observation depends agents proximity rocks
agents proximity rock information beacons (yellow squares), correspond
particular rock (for example, information beacons could mountain tops offer particularly good view far geologic formation). key characteristic ISRS present
ROCKSAMPLE FVRS rock information beacons locations
rock themselves. Unlike previous ROCKSAMPLE formulations, information gathering reward
exploitation require different actions ISRS.
agent gets fixed positive reward collecting good rock (white circle), negative reward
collecting bad rock (black circle), smaller positive reward exiting problem (the
blue sidebar right). discount factor = 0.99 encourages agent collect rewards
sooner. actions zero rewards.
observation model Bernoulli distribution noise distribution scaled
distance beacon, that:
p(zi,t |si , rt , RBi ) =

(

0.5 + (si 0.5)2
0.5 (si 0.5)2
548

krt RBi k2
D0
krt RBi k2
D0

zi,t = 1
zi,t = 0

(67)

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

zi,t
si
rt
RBi
D0

binary {0 1} observation value rock time t,
true value {0 1} rock,
agents position time t,
location information beacon associated rock i,
tuning parameter controls quickly accuracy observations
decrease greater distance agent beacon.

example, information beacon, agent, absolute certainty, receives observation
matches true value corresponding rock, whereas distance agent
beacon infinite, agent receives accurate observation 0.5 probability.
variants ROCKSAMPLE problem, including new ISRS problem, formulated
discrete state, action observation sets. allow use PBD MAC algorithms,
approximate agents belief rocks value Gaussian distribution [0,1]
state space, take advantage efKF presented Section 4 represent ROCKSAMPLE
problems Bernoulli observation model (Equation 67: see Appendix B details).
macro-action finite, open-loop sequence primitive actions. ROCKSAMPLE
problem, five primitive actions: single steps four cardinal directions rock
sampling action. Recall agents position fully observable actions deterministic.
Using domain knowledge, macro-actions considered particular belief state macroactions that, given agents current position, consist sequence actions enables
agent move rock, information beacon, nearest exit. results 2k + 1
macro-actions considered forward search every belief node. agent operates
grid world, may multiple action sequences same, shortest distance two
grid squares: macro-action considered one agent would move diagonally
possible, replicate agents shortest path movement continuous map. addition,
agent currently rock (which fully observable), additional macro-actions
agent first collects rock executing one 2k + 1 default macro-actions considered,
resulting twice many macro-actions. set macro-actions therefore varies every
belief node.18 ISRS problem 5 rocks 8 8 grid world, average macro-action
length 4.76, minimum maximum macro-action length 1 12 respectively.
ROCKSAMPLE family problems originates POMDP literature, compared
macro-action algorithms existing state-of-the-art POMDP solvers: fast upper-bound
QMDP (Littman, Cassandra, & Kaelbling, 1995), point-based offline value-iteration techniques
HSVI2 (Smith & Simmons, 2005) SARSOP (Kurniawati et al., 2008), well RTBSS (Paquet, Chaib-draa, & Ross, 2006), online, factored, forward search algorithm. also evaluated
modified version SARSOP algorithm given access macro-actions used
forward search macro-action algorithms. Since approaches, including own, approximations, also include upper bound value fully observable problem.
Table 2 compares performance different algorithms ISRS problem. algorithm tested 10 different initial conditions (which rocks high valued
low valued), scenario tested 20 times. HSVI2 SARSOP algorithms executed offline range durations,19 forward search algorithms allowed search
18. However, two belief nodes agent position, macro-actions identical.
19. offline execution durations HSVI2 SARSOP chosen empirically. HSVI2 able search
solutions ISRS[8,5] problem 1,000s offline running memory. found values
computed SARSOP remained constant 25,000s.

549

fiH E , B RUNSKILL , & ROY

Avg rewards
QMDP
HSVI2
SARSOP
SARSOP(macros)
RTBSS (d5, s10)
RTBSS (d7, s2)
RTBSS (d10, s1)
MAC (d3,s50)
MAD (d3,s50)
PBD (d3,s50)
Fully observable

1.11 0.15
6.78 0.62
8.46 0.70
18.78 1.59
9.78 0.49
12.41 0.46
15.39 0.45
13.68 0.65
15.88 0.54
14.76 0.57
21.37

ISRS[8,5]
Online
time (s)
0.0001
0.051
0.070
0.015
17.64
3.28
7.0357
15.39
4.81
1.26
N.A.

Offline
time (s)
3.03
1000
25000
1000
0
0
0
0
0
0
N.A.

Table 2: ISRS results. HSVI2 SARSOP executed offline range durations.
forward search algorithms, numbers brackets represent search depth (d)
number posterior beliefs obtained (s) end action/macro-action. Online
time indicates average time taken planner return decision every time step.
Standard error values shown.

pre-defined depths. Here, depth refers primitive action depth RTBSS algorithm,
macro-action depth macro-action algorithms (MAC, PBD MAD). addition,
pre-defined number samples used obtain posterior beliefs every action/macro-action.
abuse notation slightly using samples refer observations RTBSS algorithm,
observation sequences MAD MAC algorithms, samples posterior belief
distribution PBD algorithm.
also attempted allow RTBSS algorithm search primitive action search
depth macro-action algorithms average, i.e. 4.76 3 14, reducing number
observations sampled per action. found even 1 observation sampled per
action, RTBSS could achieve search depth 10 reasonable computation time.
macro-action algorithms significantly better benchmark solvers.
Figure 5(b) 5(c) compare policies generated SARSOP algorithm PBD algorithm ISRS problem. SARSOP HSVI2 explore parts belief space guided
upper bound belief-action values. long lookahead required realize visiting beacons
rocks higher value visiting rocks, many iterations therefore substantial
computation time required SARSOP HSVI2 sample beliefs lead
computing higher-value policy. considerable offline computation time provided, SARSOP HSVI2 discover valuable agent make detour information
beacons approaching rocks. Instead, directly approach rocks make decisions
based noisy observations obtained due large distance information
beacons.
RTBSS algorithm reasonably well able search deep enough,
emphasizing need planning uncertainty algorithms search far future order
perform well. Nevertheless, amount online planning time available, MAD
algorithm still outperforms RTBSS algorithm. Macro-actions allow algorithms uncover
550

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

MAC
MAD
PBD

Depth 1, Samples 50
Avg
Online
rewards
time(s)
4.610
0
4.610
0
4.610
0

Depth 2, Samples 50
Avg
Online
rewards
time(s)
9.630.77
0.022
7.510.84
0.0083
7.730.77
0.002

Depth 3, Samples 50
Avg
Online
rewards
time(s)
13.680.65 15.39
15.880.54 4.81
14.760.57 1.26

Depth 4, Samples 20
Avg
Online
rewards
time(s)
15.071.62 660.50
17.430.78 225.74
15.820.77 75.06

Table 3: Performance macro-action algorithms different macro-action depth ISRS.
depth 4, smaller number posterior beliefs sampled computational reasons.

potential value moving information beacon without incurring computational cost
primitive-action forward search; allows macro-action forward search approaches perform
better prior primitive-action approaches. Figure 5(c) shows PBD agents policy involves
visiting information beacons gather information rocks good
(white circles), traveling rocks sample them. domain, MAD better
PBD algorithm since problem specification made discrete states, whereas
parametric approaches must approximate world models planning. addition, fullyfactored nature problem domain, state rock value independent, keeps
computational requirements MAD algorithm relatively small.
Similarly, SARSOP algorithm modified incorporate hand-coded macroactions, offline, point-based algorithm performed much better existing offline approaches,
including SARSOP algorithm without access macro-actions. result re-emphasizes
well-designed macro-actions valuable generating good policies partially observable
domains. However, problem domains, especially large, factored domains
interest paper, represented solved offline manner, shall shortly see
benefit PBD settings.
also performed additional analysis three macro-action forward search algorithms.
Table 3 compares different rewards obtained macro-action algorithms different macroaction depths, well time taken planner return decision every time step.
sharp performance jump occurs macro-action search depth increased 2 3
emphasizes need search longer horizon ISRS problem good policy
generated. However, computational cost algorithms also increases exponentially
macro-action search depth. table also illustrates small loss performance induced
approximating discrete problem continuous representation either MAC PBD,
substantial increase computational speed using PBD.
Next examine relative performance computational cost PBD, MAC MAD,
number samples changes (Table 4) search depth 3. Recall PBD algorithm
samples posterior belief node search tree, evaluates expected future
reward subsequent macro-actions sample. Different regions posterior belief space
may plan use different subsequent macro-actions, allowing planner implicitly condition
plans received observations. However, sampling used partition posterior belief
space assign different actions different beliefs introduces source approximation error
additional computational complexity. predicted earlier computational complexity
analysis, PBD scales best three algorithms number samples increases, since
551

fiH E , B RUNSKILL , & ROY

MAC
MAD
PBD

5 Samples
Avg
Online
rewards
time(s)
12.760.54 0.15
15.310.52 0.056
12.920.57 0.035

50 Samples
Avg
Online
rewards
time(s)
13.680.65 15.39
15.880.54 4.81
14.760.57 1.26

100 Samples
Avg
Online
rewards
time(s)
12.470.70 58.90
15.570.66 20.72
14.560.59 4.52

500 Samples
Avg
Online
rewards
time(s)
12.942.57 1732.52
16.322.18 552.64
15.361.15 108.64

Table 4: Performance macro-action algorithms ISRS depth 3 different numbers
samples.

(b) ISRS(100,30)

(a) ISRS(15,6)

Avg rewards
SARSOP
SARSOP(macros)
RTBSS(d7,s2)
RTBSS(d10,s1)
MAC(d3,s20)
MAD(d3,s20)
PBD(d3,s20)
Fully obs.

9.43 1.03
11.42 0.49
8.37 0.55
9.35 0.65
15.94 0.92
17.57 0.82
17.00 0.83
30.95

Online
time (s)
0.00006
0.00006
4.98
10.91
7.01
2.74
0.58
N.A.

Offline
time (s)
10000
900
0
0
0
0
0
N.A.

Avg rewards
SARSOP
SARSOP(macros)
MAC(d3,s5)
MAD(d3,s5)
PBD(d3,s5)
Fully obs.

N.A.
N.A.
42.64 3.78
51.70 3.46
43.68 2.00
66.61

Online
time (s)
N.A.
N.A.
310.05
101.92
60.81
N.A.

Table 5: Performance larger ISRS problems

perform belief updates along sampled trajectory explicitly. general, performance
improves samples, although improvement statistically significant ISRS
problem. However, decision-making uncertainty problem requires large number
posterior beliefs sampled every macro-action, PBD algorithm results consistently
faster performance number samples. again, MAD slight performance
edge due approximation discrete ISRS problem continuous variables implicit
PBD, difference significant.
macro-action forward search nature algorithm also allows us scale much larger
versions ROCKSAMPLE problem, since unlike offline techniques, unnecessary generate
policy spans entire belief space. compared algorithms two additional ISRS
problems 16 16 grid 6 rocks, 100 100 grid 30 rocks.
problem domains large benchmark solvers originally
used comparison, though SARSOP RTBSS algorithms could implemented
ISRS[15,6] problem domain. Table 5(a) shows performance SARSOP forward search
algorithms ISRS[15,6] problem domain. modified SARSOP algorithm incorporates macro-actions ran memory computing policy offline 900s. forward search macro-action algorithms better able concentrate computational resources
reachable belief space agents current belief, forward search macro-action algorithms
perform much better SARSOP algorithm modified version incorporates
macro-actions. Similarly, forward search single-action RTBSS algorithm performed reasonably well ISRS[8,5] problem search depth sufficiently large, algorithm
552

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

Figure 6: TARGET ONITOR problem. helicopter must track multiple targets moving noisy
dynamics. field-of-view agents sensor (shaded circle) increases
agents altitude.

unable search sufficiently deep reasonable time larger ISRS[15,6] problem, resulting
poorer performance forward search macro-action algorithms.
implemented macro-action algorithms ISRS[100,30] problem domain,
far exceeds problem solved traditional POMDP solver, including modified
SARSOP algorithm incorporates macro-actions. Table 5(b) compares results three
macro-action algorithms fully observable value, provides strict upper bound
maximum possible reward problem. large problems also underscore value
macro-actions limit branching factor forward search.

6.3 Target Monitoring
next consider target monitoring problem related studied sensor resource management literature (Scott, Harris, & Chong, 2009). problem (Figure 6), helicopter agent
track multiple targets moving independently noisy dynamics. helicopter
operates 3D space, targets move 2D ground plane. helicopter equipped
downward-facing camera monitoring environment, target within fieldof-view camera sensor, agent receives noisy observation location orientation
target. assume simplicity observations target unique, allowing us
ignore data association problem addressed elsewhere.
noise associated agents observation target depends agents position
relative target. helicopter close ground observe small region, determine position objects within small region high level accuracy.
helicopter flies higher altitude, view wider region environment,
553

fiH E , B RUNSKILL , & ROY

Greedy
WT-Single
WT-Macro
NBO
MAC(d2,s10)
MAD(d2,s3)
PBD(d2,s10)
Greedy
WT-Single
WT-Macro
NBO
MAC(d2,s10)
MAD(d2,s3)
PBD(d2,s10)

1 Target
Avg rewards
Online time (s)
-21.50 7.65
0.0657
65.14 8.64
0.00075
64.64 8.28
0.00076
-5.80 7.92
0.051
41.73 6.96
4.73
1.27 5.23
1.66
36.21 6.52
0.89
3 Targets
-18.00 7.15
0.46
-23.52 10.89
0.00080
-10.53 17.12
0.00037
-8.27 8.84
0.63
37.89 12.49
70.91
-1.86 5.19
26.96
55.78 13.84
13.02

2 Targets
Avg rewards
Online time (s)
-26.50 5.00
0.19
-27.03 8.06
0.00068
-19.05 7.64
0.00042
-10.78 6.95
0.21
46.67 18.91
22.13
0.97 5.82
8.46
68.00 16.65
4.33
8 Targets
-95.00 23.37
2.01
-71.17 14.53
0.00063
-52.98 21.74
0.00025
-5.98 18.00
5.78
83.86 25.65
711.67
27.36 14.74
432.13
120.80 25.77 132.50

Table 6: TARGET ONITOR Results. Run 200 time steps.
measurements less precise. Similarly, closer helicopter particular target,
accurate helicopters observation target expected be. Reflecting intuition,
use Gaussian observation model noise covariance function position
helicopter target: details sensor model provided Appendix C. One desirable
attribute sensor model helicopter uncertain targets location, even
helicopter close targets mean location, single observation unlikely localize
target. target location uncertain, low probability target within
helicopters field view.
agents pose fully observable, though actions takes subject small amount
additive Gaussian noise. result, unlike ROCKSAMPLE domains, open-loop nature
macro-actions means planner cannot perfectly predict vehicles pose end
macro-action. targets motion determined translational rotational velocities.
model provides agent prior velocities, every time step, targets true
velocities additive functions fixed input controls Gaussian noise. parametric
formulation, agent maintains Gaussian belief targets state, order compare
MAD, discretize continuous state spaces agents targets positions, maintain
probability distribution discrete target state. Due computational memory constraints,
100m 100m 20m target monitoring problem x, z directions, limited
discretization 10m resolution x, directions, 5m z direction, 45 angular
resolution.
focus particular decision-theoretic version sensor resource management problem,
time step agent must decide targets inside area interest.
areas interest indicated yellow squares Figure 6. agent receives positive
reward successfully reports target interest region, negative reward wrongly
decides target region, reward decides target region,
regardless targets actual state. Small costs incurred agents motion. call
TARGET ONITOR problem.
554

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

Given current location agent, macro-actions generated computing sequence actions enable agent move particular altitude means
target belief. particular desired destination, macro-action constructed first computing shortest path agents current desired location, dividing path
primitive actions based maximum length primitive action. also included
hovering macro-action consists hovering agents current location four time steps.
Note agents current location fully-observable, purpose generating macroactions, assume primitive actions noise-free. Hence, primitive action,
helicopter assumed move mean expected change. Similar ROCKSAMPLE problem,
although macro-actions generated according policy relies domain knowledge,
macro-actions evaluated forward-search algorithms open-loop sequences
primitive actions. compare forward search macro-action algorithms range intuitive strategies prior approaches. first algorithm greedy strategy, returns
primitive action results largest expected reward next step. next two approaches
Worst Target (WT) policies, hand-coded policies traveling target
largest uncertainty targets tracked. intuition agents goal
general localize targets environment. two algorithms differ based whether
agent chooses new target travel time step (WT-single), re-plans
reached target initially chosen (WT-macro). Finally, compared algorithm
nominal belief optimization (NBO) algorithm proposed Scott, Harris Chong (2009).
NBO algorithm also assumes Kalman filter model target monitoring problem, rather
considering entire distribution posterior beliefs, likely posterior belief action considered. algorithm, likely posterior belief Gaussian belief
update given posterior mean without incorporating observations, covariance
given linearizing likely mean step. Although original algorithm uses
optimization approach search action sequences, modify NBO algorithm
adopting forward search approach, evaluating macro-action based likely posterior belief.20
Table 6 presents results TARGET ONITOR problem, comparing algorithms scenarios different number targets. results demonstrate PBD algorithm,
closed form representation distribution posterior beliefs action, finds significantly better policy alternate approaches. Figure 7 demonstrates typical policy executed
PBD algorithm. agent begins middle grid world, approaches target
high altitude (Figure 7(b)), maximizing likelihood localizing target. none targets
seem approaching region interest, agent hovers position conserve energy
(Figure 7(c)). one targets may potentially entering region interest, agent
focuses target, tracking carefully ensure knows target exactly
region interest (Figure 7(d),(e)). agent subsequently travels high altitude repeats
process localizing another target potential rewards (Figure 7(f)).
Considering entire distribution posterior beliefs, rather maximum likelihood
posterior belief, valuable agent able reason possibility
20. noted authors, NBO algorithm focuses new method approximating Q-value, rather
optimization techniques. adopt generic search approach performing optimization, authors
also point forward-search POMDP algorithms good search techniques Q-value approximations
could incorporated. use forward search NBO Q-value approximation affect results.

555

fiH E , B RUNSKILL , & ROY

(a)

(b)

(c)

(d)

(e)

(f)

Figure 7: Snapshots PBD policy executed. black circle indicates field-of-view
agents sensor, directly proportionate agents height. size
error ellipses indicate agents uncertainty associated target time
step. agent alternates flying high altitude maximize likelihood
observing targets (b),(f) focusing single target near/has entered area
interest (e).

target could within region interest. contrast, NBO approach considers
likely posterior belief, seek localize target mean belief appears
heading region interest. consideration entire distribution posterior
beliefs necessarily incurs greater computational cost, demonstrate Section 6.4 able
track two targets real-time using implementation PBD algorithm
optimized speed.
Table 6 also shows PBD algorithm directly computes distribution posterior beliefs macro-action, computational cost PBD algorithm significantly lower
MAC algorithm. MAC algorithm suffers greater computational cost generates
set posterior beliefs macro-action sampling observation sequences explicitly
performing belief updating along sample trajectory. addition, TARGET ITOR problem state space fundamentally continuous, resolution state space
556

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

(a) Quadrotor helicopter

(b) Multiple cars tracked. (c) Helicopter tracking car
area interest

Figure 8: TARGET ONITOR demonstration helicopter. helicopter simultaneously
track two cars report whenever either car enters area interest.

discretization achievable given computational memory constraints still unable capture inherent characteristics target monitoring problem, resulting poor performance
MAD TARGET ONITOR problem.
single-target case, also observed result PBD algorithm worse
hand-coded policy agent traveling target largest uncertainty (WT-single).
problem involves single target, policy equates agent hover
sole target every step, optimal policy single target case. contrast, observe
MAC PBD algorithms return policies result agent periodically leaving
target fly higher altitude, resulting greater noise observations corresponding loss
rewards average. restricting MAC PBD algorithms planning macro-actions,
restrict set plans agent consider order search deeper, rather shorter
conditional plan conditioned observations primitive action. Even though
agent re-plans every time step, without conditional plan, agent executing MAC
PBD algorithms execute safe policy fly higher altitude, maximizes
likelihood keeping target well-localized unable condition actions based
subsequent observations. example highlights trade-off make considering smaller
class policies (those expressed chains macro-actions) compared full
policy set. simple problems, single-target TARGET ONITOR problem, policy
restriction clearly limitation, macro-action algorithms perform significantly better
benchmark approaches multiple targets, scenarios arguably
complicated require sophisticated planning algorithms.
6.4 Real-world Helicopter Experiments
Finally, proof concept, demonstrate PBD algorithm live instantiation
TARGET ONITOR problem. motivating application monitoring problem involvement (He et al., 2010a) 1st US-Asian Demonstration Assessment Micro Aerial Vehicle
(MAV) Unmanned Ground Vehicle (UGV) Technology (MAV08 competition). mission
hostage rescue scenario, aerial vehicle guide ground units hostage building avoiding enemy guard vehicle. aerial vehicle therefore plan paths order
557

fiH E , B RUNSKILL , & ROY

Figure 9: helicopter (blue/red cross) uses onboard laser scanner localize itself. downward pointing camera used observe ground targets. figure, camera
image onboard camera projected onto ground plane.

able monitor different ground objects report whenever arrived
area interest.
demonstrate scenario actual helicopter platform monitoring multiple ground vehicles indoor environment (Figure 8b). previous work (He, Prentice, & Roy, 2008; Bachrach,
He, & Roy, 2009), developed quadrotor helicopter (Figure 8a) capable autonomous
flight unstructured unknown indoor environments. helicopter uses laser rangefinder
localize environment.
mounted downward-facing camera make observations target. Since target detection focus paper, ground vehicles known, distinctive color,
detected distinguished easily simple blob detection algorithm. Given helicopters
position world image coordinates detected object, able recover
estimate position orientation target observation global coordinates. helicopter
received observation target target within cameras field-of-view,
although helicopter platform hovered relatively stably, slight oscillations persisted,
resulted noisier observations helicopter flying higher altitudes. Hence, helicopter choose actions balanced obtaining accurate observations low
altitudes larger field-of-view flying high.
Two ground vehicles driven autonomously environment open-loop control,
helicopter plan actions would accurately localize targets. replicate
TARGET ONITOR problem, marked three areas interest helicopter
558

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

(a)

(b)

(c)

(d)

Figure 10: Birds eye-view snapshots helicopters trajectory (red), based policy generated
PBD algorithm. helicopter (blue/red cross) alternates observing
white (b,d) blue (c) cars order accurately report either car area
interest. area field-of-view agents camera sensor varies directly
height agent flying at.

WT-Single
NBO
PBD

# Target entry detections
1
1
4

# True target entries
7
4
6

Flight time (s)
484.15
435.25
474.64

Dist. traveled (m)
243.36
247.01
282.51

Table 7: Performance algorithms real-world helicopter experiment. Ground truth found
using overhead video camera.

predict every time step targets within areas (Figure 8c). applied PBD
algorithm plan paths helicopter maximized likelihood could accurately
report whenever target area interest. However, rather sending open-loop control
actions helicopter, simulation experiments, safety reasons closed
loop around position helicopter, sending desired waypoints wanted helicopter
navigate to. helicopters true state world actually partially observable,
helicopter rely onboard laser scanner localize position environment.
Figure 9 shows 3D view helicopter monitors reports locations
ground targets. helicopter flew around environment, obtained observations target,
used update agents belief targets. Figure 10 provides snapshots
helicopter executing plan computed online PBD algorithm. helicopter exhibited similar behaviors observed simulation experiments. helicopter
alternated two targets environment report either target area
interest. agent large uncertainty particular targets location, would also fly
higher altitude order increase sensor field-of-view, thereby maximizing likelihood
able re-localize targets. video complete system action available
at: http://groups.csail.mit.edu/rrg/index.php?n=Main.Videos.
559

fiH E , B RUNSKILL , & ROY

coarse measure achieved reward, evaluated well helicopter running PBD
monitoring target entered area interest, compared WT-Single
NBO algorithms. ground truth number times targets actually entered areas
interests trial found using video camera mounted overhead environment.
Table 7 indicates PBD algorithm much better job monitoring targets positions
WT-Single NBO algorithms. particular, observed WT-Single
NBO algorithms seldom took advantage ability increase agents sensor field-ofview agent fly higher altitude. agent applying two algorithms therefore
higher probability losing track targets completely.

7. Related Work
Decision-making uncertainty states partially observable commonly discussed Partially Observable Markov Decision Process (POMDP) framework, though
problem also analyzed research domains similar assumptions.
beyond scope paper provide comprehensive survey POMDP techniques, pointbased methods HSVI2 (Smith & Simmons, 2005) SARSOP (Kurniawati et al., 2008)
often considered state-of-the-art offline methods, leveraging piece-wise convex aspects
value function perform value updates selected beliefs. approaches assume discretestate representation, offline approaches use parametric representations proposed
continuous-valued state spaces (Brooks, Makarenko, Williams, & Durrant-Whyte, 2006; Brunskill, Kaelbling, Lozano-Perez, & Roy, 2008; Porta et al., 2006). Hoey Poupart (2005)
also addressed continuous observation spaces finding lossless partitions observation space.
Recent work Bonet Geffner (2009) suggests alternate point-based approaches use
tabular representations value function may also competitive prior point-based approaches used -vector representations, alternate representation may useful
continuous domains. ideas paper closely related body online, forward
search POMDP techniques compute action current belief, recently
surveyed Ross et al. (2008a).
Macro-actions considered depth within fully observable Markov decision process community, typically known options (Sutton et al., 1999), posed part
semi-Markov decision process (Mahadevan, Marchalleck, Das, & Gosavi, 1997). prior
formalisms temporally-extended actions include closed-loop policies persist termination state achieved. would interesting explore future richer notions
macro-actions could incorporated approach.
Several offline POMDP approaches use macro-actions Pineau, Gordon,
Thrun (2003b), Hansen Zhou (2003), Charlin, Poupart, Shioda (2007), Foka Trahanias (2007), Theocharous Kaelbling (2003) Kurniawati et al. (2009). Pineau et al.s
PolCA+ (2003b) algorithm uses hierarchical approach solving discrete-state POMDPs. Similarly, Hansen Zhou (2003) propose hierarchical controllers exploit user-specified hierarchy planning, Charlin et al. (2007) provide method automatically discovering
problem hierarchy. Yu, Chuang, Gerkey, Gordon Ng (2005) provide optimal algorithm
planning observations available. Foka Trahaniass (2007) solution involves building
hierarchy nested representations solutions. focus discrete-state problems, particularly navigation applications. Theocharous Kaelblings (2003) discrete-state reinforcement
learning approach samples observation trajectories solves expected reward discrete
560

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

set belief points using function approximation. Kurniawati et al. (2009) recently used macroactions guide sampling belief points use offline point-based POMDP solver.
However, prior macro-action POMDP approaches compute value function off-line,
aimed scaling large domains, struggle environments considered
paper. exception work Hsiao colleagues (2008, 2010) used form
macro-actions robot manipulation tasks involve large state space. focus
work robust manipulation uncertainty, work considers short
horizon action trajectories. Except work Kurniawati et al. (2009), macroaction POMDP approaches, like PBD algorithm, assume macro-actions provided
domain expert.
sensor resource management domain, planning uncertainty techniques used
context planning sensor placements track single multiple targets. Existing algorithms
often adopt myopic, greedy strategy comes planning (Krause & Guestrin, 2007),
notable exceptions include work Scott et al. (2009) Kreucher, Hero III, Kastella,
Chang (2004). Kreucher et al. describe multi-target tracking problem, non-myopic
sensor management necessary multi-target tracking. authors use particle filter approach
represent agents belief targets location, seek find paths result
greatest KL divergence density measurement. look ahead
one action, algorithm uses Monte Carlo sampling generate possible observation outcomes.
also provide information-directed path searching scheme reduce complexity
Monte Carlo sampling, well value heuristics help direct search. possible
insights could used combination macro-action formulation
strengthen approaches. experimental section compared approach work
Scott et al. (2009), directly formulated target tracking POMDP, proposed Nominal
Belief Optimization (NBO) algorithm computes likely belief action deeper
forward search. contrast, algorithm explicitly computes entire set possible posterior
beliefs macro-action. Recently two groups (Erez & Smart, 2010; Platt, Tedrake, LozanoPerez, & Kaelbling, 2010) independently proposed approach lies middle
spectrum: beliefs updated assuming likely observation received,
variance increased. contrast, approach represents resulting belief may fairly
peaked, mean beliefs may spread out. complete representation may
advantageous sharp changes reward function.
stated introduction, finite-horizon forward search, act, re-plan strategy PBD
follows seen instance Model Predictive Control/Receding Horizon Control
(MPC/ RHC) framework controls community. Examples MPC RHC include
work Kuwata (2004), Bellingham, Richards, (2002), Richards, Kuwata,
(2003). special case RHC control Certainty Equivalence Control, CEC (see Bertsekas, 2007 overview). fully observable systems, CEC first assumes stochastic operations (such transitions) take expected value, solves finite-horizon deterministic
control problem. CEC may applied partially observable environments first sampling
initial state belief state. Though CEC efficient large domains, key limitation use partially observable environments CEC-style controller never take
information-gathering actions. Returning generic class MPC approaches, knowledge
prior model predictive controllers used macro-actions developed notion pos561

fiH E , B RUNSKILL , & ROY

terior distribution beliefs, enables PBD approach scale large uncertain domains
multi-step lookahead required.

8. Conclusion
paper presented Posterior Belief Distribution algorithm. PBD forwardsearch algorithm large (consisting many variables, take many values)
partially observable domains. PBD analytically efficiently computes resulting distribution
posterior belief states possible sequence actions. allows computational cost
evaluating reward associated macro-action tractable, leverage enable longer horizon lookahead search online planning. presented theoretical
experimental results evaluating performance computational cost macro-action algorithms. algorithms applied problem domains span multiple research communities,
consistently performed better prior approaches large domains require multi-step
lookahead good performance. Finally, demonstrated algorithm real robotic helicopter, underscoring applicability algorithm planning real-world, long-horizon,
partially observable domains.

9. Acknowledgments
Ruijie He, E. Brunskill N. Roy supported National Science Foundation (NSF)
Division Information Intelligent Systems (IIS) Grant #0546467 Office
Naval Research Decentralized Reasoning Reduced Information Spaces project,
Contract # N00014-09-1-1052.
wish thank Finale Doshi-Velez, Alborz Geramifard, Josh Joseph, Brandon Luders, Javier
Velez, Matthew Walter valuable discussions feedback. Daniel Gurdan, Jan Stumpf
Markus Achtelik provided quadrotor helicopter support Ascending Technologies. Abraham Bachrach, Anton De Winter, Garrett Hemann, Albert Huang, Samuel Prentice
assisted development software hardware helicopter demonstration.
also appreciate early POMDP forward search discussions Leslie Pack Kaelbling Tomas
Lozano-Perez.

Appendix A: Exponential Family Kalman Filter
Building statistical economics research time-series analysis non-Gaussian observations (Durbin
& Koopman, 2000), present Kalman filter equivalent systems linear-Gaussian statetransitions observation models belong exponential family distributions.
state-transition observation models represented follows:
st = st1 + Bt + ,
p(zt |t ) =

exp(ztT

(t ) + (zt )),

st1 N (t1 , t1 ),
= W (st ).

N (0, Pt )

(68)
(69)

state-transition model, st systems hidden state, control actions, Bt
linear transition matrices, state-transition Gaussian noise covariance Pt .
observation model belongs exponential family distributions. (t )
canonical parameter normalization factor distribution, W (.) maps states
canonical parameter values. W (.) depends particular member exponential family.
562

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

ease notation, let
(zt |t ) = log p(zt |t ) = ztT + (t ) + (zt ).

(70)

Following traditional Kalman filter, process update written
= t1 ATt + Pt ,

= t1 + Bt ,

(71)

mean covariances posterior belief process update
measurement udpate. measurement update, seek find conditional mode
= arg max p(st |zt )

(72)

st

= arg max p(zt |st )b(st )

(Bayes rule)

st

(73)

= arg max p(zt |t )b(st )

(74)

st



1
1
= arg max exp(Jt ), Jt = log p(zt |t ) + (st )T (st )
st
2
Jt fifi
(zt , )
1
0=
=
+ (t ).
fi
st st =t

st

Taking derivative = W (st ) prior mean , let
fi
W (st ) fifi
.
Yt =
st fist =t

(76)

(77)

(zt |t )
Similarly, performing Taylor expansion
= W (t ),

fi
fi
2 (zt |t ) fifi
(zt |t ) (zt |t ) fifi
=
+
(t )
fi


tT fit =t
=t

(zt |t )
=t + (t )

fi
fi


(zt + (t ) (zt ))fifi
,

=

=t
fi
(t ) fifi
zt
=
fi

(75)

(Eqn. 70)

(78)
(79)
(80)
(81)

=t

=t zt



fi
2 (zt |t ) fifi
=
fi




=t

(t ).

(82)
(83)

=t

(84)

Plugging Equations 82 84 Equation 79, Equation 76,
1

YtT (t zt + (t )) = (t )
1

YtT (t1 (t zt ) + ) = (t )
1

YtT ((t t1 (t zt )) ) =t (t )
1

YtT (zt W (st )) =t (t ),
563

(85)
(86)
(87)
(88)

fiH E , B RUNSKILL , & ROY

zt = (t t1 (t zt )) projection observation onto parameter space
exponential family distribution, independent st . Equation 88 substituted using
Equation 69.
Mean Update
Using Equation 88 substituting st ,
1

(t ) = YtT (zt W (t ))
=

=
Linearizing W (st ) ,

YtT
YtT

(89)

(zt W (t )) + W (t ) W (t )

(zt W (t )) YtT (W (t ) W (t )).

W (st ) = W (t ) + W (st )st =t (st )


1
(t

= W (t ) + Yt (t )

) = YtT (zt W (t )) YtT Yt (t )

YtT (zt W (t )) =
=



=

1
(t + YtT Yt )(t
1
(t )
YtT (zt W (t )),

)

(90)
(91)
(92)
(93)
(94)
(95)
(96)
(97)

YtT = Kt Kalman gain non-Gaussian exponential family distributions. Via
standard transformation, Kalman gain written terms covariances ,



Kt = YtT (Yt YtT + t1 )1

(98)

= + Kt (zt W (t )).

(99)

Covariance Update
Given Gaussian posterior belief,

2J
s2t

inverse covariance agents belief

2J
s2t

1
=
(t (st ) YtT (zt W (st )))
x
1
= + YtT Yt

1
=

=

1
(t

+ YtT Yt )1 .

(100)
(101)
(102)
(103)

Appendix B. Rock Sample Observation Model
Rocksample problem, Bernoulli observation function written follows. Recall
rt agents position time t, RBi location information beacon associated
rock i, zi,t binary observation value rock time t, si,t true value
564

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

rock time t. let di,t =k rt RBi k2 ,
p(zi,t |RVi,t = si,t , rt , RBi )

(104)

= (0.5 + (si,t 0.5)2di,t /D0 )zi,t (0.5 (si,t 0.5)2di,t /D0 )1zi,t

(105)

= exp(zi,t ln

(106)

0.5)2di,t /D0

0.5 + (si,t
+ ln(0.5 (si,t 0.5)2di,t /D0 ))
0.5 (si,t 0.5)2di,t /D0

= exp(zi,t (t )).

(107)

therefore parameters exponential family observation model
i,t = W (si,t , rt , RBi )
= ln

(108)

0.5 + (si,t 0.5)2di,t /D0
0.5 (si,t 0.5)2di,t /D0

(109)

i,t = ln(0.5 (si,t 0.5)2di,t /D0 )
= ln(exp(i,t ) + 1).

derive derivatives Yi,t i,t
fi
W (si,t , rt , RBi ) fifi
Yt =
fi
si,t
si,t =mi,t

(111)

(112)

fi
0.5 + (si,t 0.5)2di,t /D0 fifi

=
ln
si,t 0.5 (si,t 0.5)2di,t /D0 fisi,t =mi,t
=

(110)

(113)

1
2di,t /D0


/D
0.5 + (mi,t 0.5)2 i,t 0 0.5 (mi,t 0.5)2di,t /D0

(114)

si,t mean belief used linearization. Since


i,t = ln(exp(i,t ) + 1),

(115)


i,t

fi
2 bi,t fifi
=
2 fi
i,t
i,t =i,t

=

exp(i,t )

exp(i,t ) + 1

(116)


exp(2i,t )
(exp(i,t ) + 1)2

.

(117)

Appendix C. Target Tracking Observation Model
adopt observation model target tracking target observation obtained Gaussian noise noise covariance zi function position helicopter target
i:




xi
zxi
zyi = f yi + N (0, zi )

zi
zi = g(xi , yi , xa , ya , ha ),
565

fiH E , B RUNSKILL , & ROY

Figure 11: observation noise covariance function height helicopter, distance
helicopter mean target belief, covariance target
belief. lower altitudes, helicopter make better observations targets close
it, limited field vision. higher heights, helicopter see larger area
even close targets noisily observed.

xi , yi , pose target i, xa , ya , ha correspond agents position height
environment. zxi , zyi , zi observation target image coordinates.
covariance function specified





xi
xa
xi
xa


yi
ya
yi
ya
g(xi , yi , xa , ya , ha ) = C1 ha + C2
+ C3 ,
ha
C1 , C2 C3 constants.
generic belief update expression target position, si = [xi ; yi ; ], unknown,
Z
Z



b (si ) p(z|si , a, zi )
p(si |si , a)b(si )dsi s.t.
b (si )dsi = 1,
si

si

means possible si would associated different covariance zi . Performing
integration exactly would keep distribution Gaussian. Instead, approximate observation model computing single expected covariance zi given current belief distribution:
Z
b(si )zi (si )dsi .
zi = E[zi ] =
si

Substituting exact expressions covariance function belief action
taken incorporating measurement, ba (s) N (si |, ), get:
!


Z fi
C2
xi fifi
xa
xi
xa
xi
+ C3 dxi dyi .
E[zi ] = N
,


C1 ha
yi fi xy xy
ya
yi
ya
yi
ha
566

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

adding subtracting xy second term, reduces
C2
E[zi ] = C1 ha +
ha






C2
xa
xa
xy
xy
xy
+
ya
ya
ha

xy , xy refer translational components agents belief.
contrast simpler observation models, observation model desirable characteristic
targets location uncertain, namely covariance xy large, even
targets mean location close helicopters mean location, expected benefit receiving
observation (in terms reducing targets uncertainty) still small. property comes
automatically derivation, since E[zi ] includes current target covariance xy .
Figure 11 provides illustration expected covariance different locations target
relative agent, agent heights, target belief covariances.

References
Bachrach, A., He, R., & Roy, N. (2009). Autonomous flight unstructured unknown indoor
environments. Proceedings European Micro Aerial Vehicle (EMAV) Conference.
Barndorff-Nielsen, O. (1979). Information exponential families statistical theory. Bulletin
American Mathematics Society, 273, 667668.
Bellingham, J., Richards, A., & How, J. (2002). Receding horizon control autonomous aerial
vehicles. Proceedings American Control Conference (ACC), Vol. 5, pp. 37413746.
Bertsekas, D. (2007). Dynamic Programming Optimal Control, vol. 1 & 2, 2nd. Athena Scientific.
Bonet, B., & Geffner, H. (2009). Solving POMDPs: RTDP-Bel vs. point-based algorithms. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 1641
1646.
Brooks, A., Makarenko, A., Williams, S., & Durrant-Whyte, H. (2006). Parametric POMDPs
planning continuous state spaces. Robotics Autonomous Systems, 54(11), 887897.
Brunskill, E., Kaelbling, L., Lozano-Perez, T., & Roy, N. (2008). Continuous-state POMDPs
hybrid dynamics. Proceedings International Symposium Artificial Intelligence
Mathematics (ISAIM).
Charlin, L., Poupart, P., & Shioda, R. (2007). Automated hierarchy discovery planning
partially observable environments. Advances Neural Information Processing Systems
(NIPS).
Durbin, J., & Koopman, S. (2000). Time series analysis non-Gaussian observations based state
space models classical Bayesian perspectives. Journal Royal Statistical
Society: Series B (Methodological), 62(1), 356.
Erez, T., & Smart, W. (2010). Scalable Method Solving High-Dimensional Continuous
POMDPs Using Local Approximation. Proceedings Conference Uncertainty
Artificial Intelligence (UAI).
Foka, A., & Trahanias, P. (2007). Real-time hierarchical POMDPs autonomous robot navigation.
Robotics Autonomous Systems, 55(7), 561571.
567

fiH E , B RUNSKILL , & ROY

Hansen, E., & Zhou, R. (2003). Synthesis hierarchical finite-state controllers POMDPs.
Proceedings Thirteenth International Conference Automated Planning Scheduling (ICAPS).
He, R., Bachrach, A., Achtelik, M., Geramifard, A., Gurdan, D., Prentice, S., Stumpf, J., & Roy,
N. (2010a). design use micro air vehicle track avoid adversaries.
International Journal Robotics Research, 29(5), 529546.
He, R., Brunskill, E., & Roy, N. (2010b). PUMA: planning uncertainty macro-actions.
Proceedings Association Advancement Artificial Intelligence (AAAI).
He, R., Prentice, S., & Roy, N. (2008). Planning information space quadrotor helicopter
GPS-denied environments. Proceedings International Conference Robotics
Automation (ICRA), pp. 18141820.
Hoeffding, W. (1963). Probability inequalities sums bounded random variables. Journal
American Statistical Association, 58(301), 1330.
Hoey, J., & Poupart, P. (2005). Solving POMDPs continuous large discrete observation
spaces. Proceedings International Joint Conference Artificial Intelligence (IJCAI).
Hsiao, K., Kaelbling, L., & Lozano-Perez, T. (2010). Task-driven tactile exploration. Proceedings
Robotics: Science Systems (RSS).
Hsiao, K., Lozano-Perez, T., & Kaelbling, L. (2008). Robust belief-based execution manipulation programs. Proceedings Workshop Algorithmic Foundations Robotics
(WAFR).
Kalman, R. E. (1960). new approach linear filtering prediction problems. Transactions
ASMEJournal Basic Engineering, 82(Series D), 3545.
Kearns, M., Mansour, Y., & Ng, A. (2002). sparse sampling algorithm near-optimal planning
large Markov decision processes. Machine Learning, 49(2-3), 193209.
Krause, A., & Guestrin, C. (2007). Near-optimal observation selection using submodular functions.
Proceedings National Conference Artificial Intelligence (AAAI), Vol. 22, pp.
16501654.
Kreucher, C., Hero III, A., Kastella, K., & Chang, D. (2004). Efficient methods non-myopic
sensor management multitarget tracking. Proceedings IEEE Conference
Decision Control (CDC), Vol. 1, pp. 722727.
Kurniawati, H., Du, Y., Hsu, D., & Lee, W. (2009). Motion planning uncertainty robotic
tasks long time horizons. Proceedings International Symposium Robotics
Research (ISRR).
Kurniawati, H., Hsu, D., & Lee, W. (2008). SARSOP: Efficient point-based POMDP planning
approximating optimally reachable belief spaces. Proceedings Robotics: Science
Systems (RSS).
Kuwata, Y., & How, J. (2004). Three dimensional receding horizon control UAVs. Proceedings AIAA Guidance, Navigation, Control Conference Exhibit (GNC), pp.
1619.
568

fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS

Littman, M., Cassandra, A., & Kaelbling, L. (1995). Learning policies partially observable
environments: scaling up. Proceedings Twlfth International Conference Machine
Learning (ICML), pp. 362370.
Mahadevan, S., Marchalleck, N., Das, T., & Gosavi, A. (1997). Self-improving factory simulation
using continuous-time average-reward reinforcement learning. Proceedings International Conference Machine Learning (ICML), pp. 202210.
Mayne, D. Q., Rawlings, J. B., Rao, C. V., & Scokaert, P. O. M. (2000). Constrained model predictive control: Stability optimality. Automatica, 36, 789814.
McAllester, D., & Singh, S. (1999). Approximate planning factored POMDPs using belief state
simplification. Proceedings Conference Uncertainty Artificial Intelligence
(UAI), pp. 409416.
McGovern, A. (1998). acQuire-macros: algorithm automatically learning macro-actions.
NIPS 98 Workshop Abstraction Hierarchy Reinforcement Learning.
Paquet, S., Chaib-draa, B., & Ross, S. (2006). Hybrid POMDP algorithms. Workshop MultiAgent Sequential Decision Making Uncertain Domains (MSDM), pp. 133147.
Paquet, S., Tobin, L., & Chaib-draa, B. (2005). online POMDP algorithm complex multiagent environments. Proceedings Conference Autonomous agents Multiagent
systems (AAMAS), pp. 970977.
Patek, S., Breton, M., Chen, Y., Solomon, C., & Kovatchev, B. (2007). Linear quadratic gaussianbased closed-loop control type 1 diabetes. Journal Diabetes Science Technology,
1.
Pineau, J., Gordon, G., & Thrun, S. (2003a). Point-based value iteration: anytime algorithm
POMDPs. Proceedings International Joint Conference Artificial Intelligence
(IJCAI), Vol. 18, pp. 10251032.
Pineau, J., Gordon, G., & Thrun, S. (2003b). Policy-contingent abstraction robust robot control.
Proceedings Conference Uncertainty Artificial Intelligence (UAI).
Platt, R., Tedrake, R., Lozano-Perez, T., & Kaelbling, L. (2010). Belief space planning assuming
maximum likelihood observations. Proceedings Robotics: Science Systems (RSS).
Porta, J., Vlassis, N., Spaan, M., & Poupart, P. (2006). Point-based value iteration continuous
POMDPs. Journal Machine Learning Research, 7, 23292367.
Poupart, P. (2005). Exploiting Structure Efficiently Solve Large Scale Partially Observable
Markov Decision Processes. Ph.D. thesis, University Toronto.
Richards, A., Kuwata, Y., & How, J. (2003). Experimental demonstrations real-time MILP control. Proceeding AIAA Guidance, Navigation, Control Conference (GNC).
Ross, S., & Chaib-draa, B. (2007). AEMS: anytime online search algorithm approximate
policy refinement large POMDPs. Proceedings International Joint Conference
Artificial Intelligence (IJCAI), pp. 25922598.
Ross, S., Pineau, J., Paquet, S., & Chaib-draa, B. (2008a). Online planning algorithms POMDPs.
Journal Artificial Intelligence Research, 32(1), 663704.
569

fiH E , B RUNSKILL , & ROY

Ross, S., Chaib-draa, B., & Pineau, J. (2008b). Bayesian reinforcement learning continuous
POMDPs application robot navigation. Proceedings International Conference Robotics Automation (ICRA). IEEE.
Scott, A., Harris, Z., & Chong, E. (2009). POMDP framework coordinated guidance
autonomous UAVs multitarget tracking. EURASIP Journal Advances Signal Processing, 2009, 117.
Smallwood, R., & Sondik, E. (1973). optimal control partially observable Markov processes
finite horizon. Operations Research, 21(5), 10711088.
Smith, T., & Simmons, R. (2005). Point-based POMDP algorithms: Improved analysis implementation. Proceedings Conference Uncertainty Artificial Intelligence (UAI).
Stolle, M., & Precup, D. (2002). Learning options reinforcement learning. Lecture Notes
Computer Science, 212223.
Sutton, R., Precup, D., & Singh, S. (1999). MDPs semi-MDPs: framework
temporal abstraction reinforcement learning. Artificial Intelligence, 112, 181211.
Theocharous, G., & Kaelbling, L. (2003). Approximate planning POMDPs macro-actions.
Advances Neural Processing Information Systems (NIPS).
Triantafyllopoulos, K. (2003). central moments multidimensional Gaussian distribution. Mathematical Scientist, 28, 125128.
West, M., Harrison, P., & Migon, H. (1985). Dynamic generalized linear models Bayesian
forecasting. Journal American Statistical Association, 80(389), 7383.
Yu, C., Chuang, J., Gerkey, B., Gordon, G., & Ng, A. (2005). Open-loop plans multi-robot
POMDPs. Tech. rep., Stanford University.

570

fiJournal Artificial Intelligence Research 40 (2011) 657-676

Submitted 12/10; published 03/11

Complexity Integer Bound Propagation
Lucas Bordeaux

lucasb@microsoft.com

Microsoft Research, 7 J J Thomson Avenue, CB30FB
Cambridge, UNITED KINGDOM

George Katsirelos

gkatsi@gmail.com

LRI, Universite Paris-Sud 11
Paris, FRANCE

Nina Narodytska

ninan@cse.unsw.edu.au

NICTA Neville Roach Laboratory
University New South Wales
223 Anzac Parade Kensington NSW 2052, AUSTRALIA

Moshe Y. Vardi

vardi@cs.rice.edu

Rice University, P. O. Box 1892
Houston, TX 77251-1892, U.S.A.

Abstract
Bound propagation important Artificial Intelligence technique used Constraint
Programming tools deal numerical constraints. typically embedded within
search procedure (branch prune) used every node search tree narrow
search space, critical fast. procedure invokes constraint
propagators common fixpoint reached, known algorithms
pseudo-polynomial worst-case time complexity: fast indeed variables
small numerical range, well-known problem prohibitively
slow ranges large. important question therefore whether stronglypolynomial algorithms exist compute common bound consistent fixpoint set
constraints. paper answers question. particular show fixpoint
computation fact NP-complete, even restricted binary linear constraints.

1. Introduction Overview Main Results
Constraint solvers typically solve problems interleaving search propagation. Propagation iterative procedure which, iteration, propagates every constraint
problem narrow domains variables. iteration stops constraint
changes domains variables. case, propagation reached common fixpoint constraints. iterative algorithm guaranteed compute fixpoint
polynomial time propagating constraint takes polynomial time domains
variables defined lists values. often, however, inconvenient infeasible list values explicitly: instead domains defined lower upper bounds.
focus representation, variables taking integer values. setting,
computing fixpoint iterative algorithm may require exponential time even
constraint propagated polynomial time. show exponential behaviour
simply due iterative algorithm suboptimal; rather intrinsic
c
2011
AI Access Foundation. rights reserved.

fiBordeaux, Katsirelos, Narodytska, & Vardi

problem computing fixpoint, NP-complete even system constraints
restricted binary linear inequality constraints.
1.1 Bound Propagation Slow Convergence
illustrate behaviour iterative fixpoint algorithm using system two constraints:
x + = 7, x + 1 2y,

initial bounds:

x [0, 5], [0, 10]

possible trace fixpoint computation following. lower bound
initially 0 constraint x + = 7 deduce cannot take values 0 1:
does, sum < 7, even fix x highest allowed value. Therefore
intervals narrowed x [0, 5], [2, 10]. Similarly:



x + = 7,
x + 1 2y,

back

x + = 7,

deduce:
deduce:
and:
deduce:

x [0, 5],
x [3, 5],
x [3, 5],
x [4, 5],

[2, 7];
[2, 7];
[2, 3];
[2, 3].

point reached common fixpoint constraints, cannot
deduce domains need narrowed further.
algorithm, however, exhibits slow convergence behaviour even deceivingly simple
examples as:
x < y, < x

initial bounds:

x [0, 108 ], [0, 108 ]

(1)

iterative algorithm fixpoint computation shrinks bounds one unit
iteration, means 108 iterations required reach fixpoint,
case empty. slow convergence fact exponential size problem
representation, log(108 ) bits enough represent bound. behaviour
limited artificial examples previous one fact happens time
solving problems large numerical ranges. severely limits application CP
areas software verification theorem proving large ranges needed (e.g.,
whole 32-bit integer range).
Due importance problem, efforts made alleviate slow convergence, notably Jaffar, Maher, Stuckey, Yap (1994), Lhomme, Gottlieb, Rueher,
Taillibert (1996), Lebbah Lhomme (2002), Leconte Berstel (2006); proposed
algorithmic improvements prevent slow convergence specific cases. Fully addressing
slow convergence problem would require strongly polynomial algorithm fixpoint
computation. Therefore question is: algorithm exist, bound propagation fact intractable?
1.2 Prior Complexity Results Propagation
Standard propagation algorithms iterative processes apply propagators, i.e., narrowing functions associated constraint, reaching fixpoint. complexity
therefore determined two complementary questions:
658

fiThe Complexity Integer Bound Propagation

Q1: hard compute propagator?
Q2: hard find common fixpoint propagators?
complexity constraint propagation sense extremely well-studied,
results aware bound propagation deal Question 1 only. prior
hardness results showed complex constraints cannot polynomial-time
propagators reaching certain levels consistency. Two results are:
Given linear equality observed (Yuanlin & Yap, 2000; Choi, Harvey,
Lee, & Stuckey, 2006) propagator reaches arc consistency bound(Z)
consistency1 needs solve knapsack problem, NP-complete weak
sense. reason propagators linear constraints used practice either reach
weaker consistency bound(R) consistency, restricted small
domains, proposed instance Trick (2001).
Results Bessiere (2006) prove even bounded-arity (two-variable) constraints
constructed checking bound(Z) consistency NP-complete.
Question 2 makes sense, course, common case propagators
polynomial-time computable (if not, computing common fixpoint cannot
easy general). known fact case standard, iterative propagation
algorithms often take exponential number steps reach fixpoint practice,
mentioned illustrated Section 1.1. leaves open question whether better
algorithms exist fixpoint computation is, fact, intrinsically hard.
1.3 Main Results
paper consider simple, common propagators address Question 2.
show general even surprisingly simple propagators lead fixpoint computation problem NP-hard. explains standard, iterative fixpointcomputation algorithms exponential worst-case practice, also shows unlikely exists algorithm better worst case. particular important
class simple propagators whose fixpoint computation NP-hard bound(R) consistency propagators linear constraints (Proposition 1). ubiquitous constraints,
weak widely used propagators constraints. Many problems
use numerical computations large domains tend include least linear constraints,
therefore cases slow convergence avoidable. nevertheless
identify one case: coefficients linear constraints unit (1 absolute
value), bound(R) consistency obtained polynomial time non-standard
propagation algorithm based Linear Programming. also study types basic
numerical constraints: multiplication max.
1.4 Outline
Section 2 summarize required material Constraint Satisfaction Problems
bound propagation. Section 3 focuses linear constraints. prove
1. give formal definitions bound(R) bound(Z) consistency Section 2.2.

659

fiBordeaux, Katsirelos, Narodytska, & Vardi

aforementioned Proposition 1, identify restricted forms linear constraints
propagation tractable. Section 4 presents results basic propagators:
quadratic constraints, hardness result strengthened holds even fixed
number variables; max constraints, fixpoint computation interesting complexity
(between P NP-complete) proved equivalent important open problem;
last comment max-closed constraints. conclude Section 5.

2. Formal Background
section summarize required material Constraint Satisfaction Problems
bound propagation. details material found papers e.g. Schulte
Carlsson (2006), Bessiere (2006).
2.1 Constraint Satisfaction Problems
Constraint Satisfaction Problem (CSP) triple hX, D, Ci, where: X = {x1 xn }
set variables, = {D1 Dn } set finite domains (finite sets values), one
variable, C set constraints. paper consider discrete domains:
elements integers. moment simply define constraints generally
logical predicates subsets X; later paper consider specific types
constraints, instance linear ones. assignment function assigns value
(xi ) Di every variable xi . solution CSP assignment satisfies
constraints. Throughout paper, keep following conventions:
n = |X| denotes number variables;
= |C| number constraints;
= maxi1..n |Di | size largest domain.
important note Di may represented interval, rather explicit
set values. work, consider domains represented intervals: domain
form Di = [li , ui ], li ui lower upper bounds domain.
2.2 Propagators Notions Bound Consistency
constraints problem associated propagators. (In setting
be, general, several propagators per constraint.) follow classical presentation
propagators operators lattice, initiated work Benhamou (1996)
details found papers Apt (1999), Schulte Carlsson (2006):
propagator function narrow domains (some of) variables, removing
values cannot appear solution. Thus, talk current domain
variable xi , result narrowed application one propagators.
+

denote x
current lower bound xi xi current upper bound. xi
+
xi initially set initial bounds li , ui remain afterwards constrained
+
li x
xi ui . denote Cartesian product intervals [li , ui ]
1..n.
660

fiThe Complexity Integer Bound Propagation

Definition 1 (Propagator) propagator constraint k 1..m function f :
P(D) P(D), is:
monotone, i.e., A0 f (A0 ) f (A);
contracting, i.e., f (A) A;
correct, i.e., point \ f (A) satisfies constraint.
restrict propagators polynomial-time computable. Bound consistency propagators additionally restricted elements P(D) representable
Cartesian products intervals, plus special value .
Several types propagators used numerical constraints; propagators
characterized level consistency enforce. Since restricted
focus interval domains, present bound consistency. two main variants
bound(Z) bound(R) consistency:
Definition 2 (Bound(Z|R) support) bound(Z) (bound(R)) support constraint k
+
assignment integer (real) values variables X x
(xi ) xi
1..n satisfies constraint k.
Definition 3 (Bound(Z|R) consistency) constraint k bound(Z) (bound(R)) consistent iff every variable xi X, exists bound(Z) (bound(R)) support
+ + (x ) = x+ .
(xi ) = x


bound(Z) (bound(R)) support
difference two easily understood example:
Example 1 Consider constraint 2x + 2y + 3z = 4.
intervals x, y, z [0, 1] bound(R) consistent since integer bounds
real-valued support: x = 0 supported tuple (x = 0, = 1, z = 2/3);
z = 1 = 0 tuple (x = 1/2, = 0, z = 1); x = 1, = 1 z = 0
tuple (x = 1, = 1, z = 0).
intervals are, however, bound(Z) consistent: integer solution
(x = 1, = 1, z = 0), means bound(Z) consistency would reduce bounds
x [1, 1], [1, 1], z [0, 0].
Bound(Z) consistency requires check existence integer-valued support,
classes constraints linear equalities propagator would need
solve NP-complete problem. Since focus computation common fixpoint
simple operators, consider bound(R) consistency paper. noted previously
literature (Schulte & Stuckey, 2005), bound(R) consistency fact bound
consistency implemented primitive constraints, precisely often
one propagators easy compute general large domains.
rest paper focus several main basic types numerical constraints (in
particular linear ones), give details bound(R) consistency propagators
obtained constraints. cases consider propagators simple
indeed.
661

fiBordeaux, Katsirelos, Narodytska, & Vardi

:=
change := true
change
change := false
foreach f F
oldA :=
= f (A)
6= oldA change := true
done
done
Figure 1: simple fixpoint computation algorithm.
2.3 Fixpoints
Propagators monotone narrowing operators, thus may consider problem identifying greatest common fixpoint set propagators.
Definition 4 (Greatest Common Fixpoint) greatest common fixpoint gfp(F )
set propagators F largest Cartesian product intervals
operator f F , f (A) = A.
two computational problems related fixpoints:
Function Problem: Effectively compute gfp(F );
Decision Problem: Decide whether gfp(F ) 6= , i.e., whether exists (nonempty) fixpoint. (Note definition propagators implies f () =
f F . Therefore always common fixpoint.) words: propagators
stabilize non-empty domains?
often complexity work mostly focus Decision problem paper.
reason basic complexity classes (NP particular) defined decision
problems, hardness results decision problem also imply function
problem hard. place refer function problem section,
describe basic greatest fixpoint computation algorithm.
algorithm computing gfp(F ) specified Fig. 1. presented simplest
form, excludes several possible optimizations related, particular, fact
constraints necessarily deal variables. (These optimizations well-known
orthogonal discussion paper.) algorithm initialize Cartesian
+
product domains D, words initially x
= li xi = ui ,
1..n; simply apply propagators stable state reached, i.e.,
propagator shrinks domain further. reader verify algorithm specifies
formally reasoning presented informally introductory example (Sec. 1.1).
662

fiThe Complexity Integer Bound Propagation

2.4 Complexity Upper Bound Fixpoint Propagation
worst-case time upper bound fixpoint computation analyzed follows2 .
Let p = |F | number propagators. (Note general one
propagators per constraint, i.e., p m.) enter loop nd times since
every new iteration must reduce least one bound one unit, time
foreach loop entered p times. Overall algorithm therefore terminates
number propagator applications of:
O(npd).
words, fact exponential number bits encoding: complexity
written O(np2b ), b number bits bound encoding. despite
fact propagator polynomial size encoding. algorithms
called pseudo-polynomial. contrast algorithms truly polynomial number
bits encoding, i.e., whose worst-case time complexity O((n, m, log d)),
polynomial , called strongly polynomial (Papadimitiou, 1994). problem
pseudo-polynomial algorithm problem scales linearly size
domains, may exponentially large. Since propagators consider
take strongly polynomial time, analyis upper bound summarized follows:
Observation 1 naive fixpoint computation algorithm (Fig. 1) always terminates
pseudo-polynomial-time.
question whether strongly polynomial algorithms exist. rest paper
focusses question, several classes propagators.

3. Linear Constraints
section consider linear inequalities, i.e., set constraints C contains
inequalities form:
X
ai,k xi ck ,
k 1...m
(2)
i1...n

ck ai,k integers. convenient introduce extra notation:
denote si,k sign ith term constraint k, i.e.,:
si,k =

(

+ ai,k 0
ai,k < 0

(3)

Moreover, given sign {, +}, sign defined + =

otherwise. sign +s simply denote s. notation terms ai,k xi i,k
+s
+
ai,k xi i,k simply represent smallest largest elements set {ai,k v | v [x
, xi ]}.
2. papers give explicit upper bounds complexity computing fixpoint set bound
consistency propagators. earliest reference aware work Lhomme (1993);
considers constraints reals assumes finite precision (floating points), analysis directly
adapts discrete intervals.

663

fiBordeaux, Katsirelos, Narodytska, & Vardi

3.1 Bound(R) Consistency Propagators Linear Inequalities
briefly summarize material need bound(R) consistency case linear
inequalities. refer reader literature details, particular papers
Harvey Stuckey (2003), Schulte Carlsson (2006), Bessiere (2006), Apt
Zoeteweij (2007) substantial material bound(R) consistency linear constraints.
Also interest works show improve bound propagation long linear
constraints (Harvey & Schimpf, 2002; Katriel, Sellmann, Upfal, & Van Hentenryck, 2007).

Consider variable xi . bound xi i,k bound(R) inconsistent w.r.t. kth inequality
system iff: even fix terms maximum, obtain something
lower ck . bound consistent opposite true i.e., iff:
+s1,k

a1,k x1

+s

si,k

+ . . . + ai1,k xi1i1,k + ai,k xi

+sn,k

+s

+ ai+1,k xi+1i+1,k + . . . + an,k xn

ck

(4)

call bound consistency inequality variable xi w.r.t. constraint k.
bound consistency propagator linear inequality simply shrinks bounds
variable xi . Let:
X
+s
aj,k xj j,k
qi,k = ck
j[1,n], j6=i



minimal quantity reached ai,k xi i,k satisfy bound consistency

inequality (in words: xi bound consistent w.r.t. constraint k iff ai,k xi i,k qi,k ).
(bound(R) consistency) propagator associated constraint k 1..m variable
1..n function reduces bound xi closest bound consistent value.
defined following pseudo-code:
ai,k > 0 x
:=

Li,k :
ai,k < 0

x+


:=



l



j

max x
,
min

x+
,

qi,k
ai,k

qi,k
ai,k



(5)

k

(The propagator nothing ai,k = 0.)
3.2 NP-completeness Integer Fixpoint Computation
prove propagators Li,k introduced previous sub-section (Eq. 5),
although simple considered independently, give rise complex fixpoints.
precisely, show NP-completeness following decision problem:
Decision Problem 1 (Bound(R)-Consistency Linear Constraints)
INPUT: CSP whose set constraints C linear inequalities.
QUESTION: Let F = {Li,k : 1..n, k 1..m} set bound(R) consistency propagators associated CSP. propagators F non-empty common fixpoint?
3.2.1 Characterising Fixpoints Inequalities
first observation bounds obtained fixpoint reached characterized
bound consistency conditions Eq. 4. words fixpoint reached iff
664

fiThe Complexity Integer Bound Propagation

+
lower upper bounds x
xi satisfy following inequalities, variable
constraint k:


+s
+s1,k
+s

+s


+ .. + ai1,k xi1i1,k + ai,k xi i,k + ai+1,k xi+1i+1,k + .. + an,k xn n,k ck
a1,k x1




li

x




x+


k 1 . . . m, 1 . . . n
1 . . . n

ui

(6)

clear Decision Problem 1 answered positively iff integer values
+
bounds x
xi , 1..n, satisfy Linear Program 6. (If fixpoint exists
bounds given fixpoint satisfy inequalities within initial bounds
li , ui . Conversely inequalities satisfied fixpoint.)
first consequence Decision Problem 1 membership NP straightforward since solvable Integer Programming.
3.2.2 Linear Inequalities Two-Variables-Per-inequality
key understanding Decision Problem 1 hard connect fixpoint computation
special case Integer (Linear) Programming constraints Two Variables
Per Inequality (TVPI LP terminology, see Bar-Yehuda & Rawitz, 2001):
Definition 5 TVPI instance constraints n variables Integer Linear
Program following form:
(

ak xik + bk xjk ck k 1 . . .
li xi ui
1 . . . n

a, b, c vectors arbitrary (possibly negative) integers.
feasibility TVPI constraints NP-complete3 decided pseudopolynomial time. early pseudo-polynomial time algorithm found work
Aspvall Shiloach (1980); algorithm essentially reduces problem 2-SAT
instance size d, solvable linear time (the overall algorithm therefore
runs pseudo-polynomial time, also pseudo-polynomial space requirement).
particularly relevant algorithm TVPI constraints proposed work BarYehuda Rawitz (2001). algorithm pseudo-polynomial time complexity
low, strongly polynomial space requirements. Interestingly, algorithm essentially uses
bound propagation (in fact, precisely bound(R) consistency), embeds amounts
backtrack-free search parallel improvement allows amortize overall
runtime.
seems suggest strong relation propagation TVPI constraints;
particular one could easily mistaken believe propagation decision procedure
systems TVPI constraints. say propagation provides decision procedure
class constraints propagation fails exactly constraints unsatisfiable (in
3. focus feasibility only. optimization problem, i.e., optimizing linear function
TVPI constraints, strongly NP-hard, i.e., NP-hard even bounded domain sizes (in fact domains
{0, 1} enough), trivially encodes Max-2SAT (Bar-Yehuda & Rawitz, 2001).

665

fiBordeaux, Katsirelos, Narodytska, & Vardi

words: existence bound consistent state suffices guarantee existence
solution). usual condition guarantees backtrack-free search;
propagation rarely achieves general case fact decision procedure
TVPI constraints:
Example 2 Consider problem x + = 1, x = x, [0, 1]. problem
inconsistent yet bound(R) consistent (and also, fact, bound(Z) consistent).
prove main result need identify restricted case TVPI constraints
fixpoint computation indeed decision procedure. particular case
monotone TVPI constraints, two variables inequality coefficients
opposite signs, i.e., problem following form:
Definition 6 monotone TVPI instance constraints n variables Integer Linear Program following form:
(

ak xik bk xjk ck k 1 . . .
li xi ui
1 . . . n

ak 0, bk 0, k 1 . . . m.
prove NP-hardness result monotone TVPI constraints, using
following result:
Theorem 1 (Lagarias, 1985) feasibility Two-Variable-Per-Inequality monotone Integer Programming NP-complete.
3.2.3 NP-hardness
prove Decision Problem 1 NP-hard. already know NP,
therefore state main result bound(R) consistency linear constraints as:
Proposition 1 Decision problem 1 NP-complete.
Proof. show fixpoint computation decides systems monotone TVPI constraints.
Consider monotone TVPI instance Q form given Def. 6. want show
equivalence: Q integer solution iff set bound(R) consistency propagators
obtained Q non-empty common fixpoint.
Q integer solution means exist integer values vi variable
xi satisfying li vi ui and, k 1 . . . m:
ak vik bk vjk ck

(7)

+
exists common fixpoint means bounds x
, xi , found
+

1 . . . n, satisfying li xi xi ui and, k 1 . . . m:

ak x
ik bk xjk ck

+
ak x +
ik bk xjk ck

(8)

(These simply constraints Eq. 6 variable xik (left) xjk (right),
rewritten taking account > 0, b > 0.)
666

fiThe Complexity Integer Bound Propagation

prove two directions iff:
Consider integer solution Q variable xi takes value vi . easy
+

+
verify bounds x
= xi = vi satisfy li xi xi ui Eq. 8.
+
Consider bound consistent state described bounds x
, xi . easy verify
solution v defined vi = x+
, 1 . . . n satisfies li vi ui Eq. 7.

means reduce problem monotone TVPI feasibility existence
fixpoint, Decision Problem 1 therefore NP-hard. 2
Note NP-hardness result Decision Problem 1 holds even (monotone)
TVPI constraints, pseudo-polynomial upper bound Section 2.4 holds general
linear constraints unbounded sizes; said earlier membership NP also valid
general linear constraints.
3.3 Comment Linear Equalities
beginning section focused linear inequalities reasons
become clear sub-section. Readers may wonder whether considering equalities
would make difference. short answer no.
P
first observation inequality i1...n ai xi c directly encoded
P
P
equality i1...n ai xi = c new variable ranging [0, u] u > ai xi+si ,
bijection solutions two constraints. Therefore problem
propagating inequalities reduces problem propagating equalities, NPcompleteness result still holds problems whose linear constraints equalities (or
mix equalities / inequalities).
second observation following: focus bound(R) consistency,
P
propagation obtained equality i1...n ai xi = c one obtained using
P
P
two constraints i1...n ai xi c i1...n ai xi c. reason convenient
assume constraints homogeneous form, restrict linear
inequalities4 .
3.4 Tractable Classes Linear Constraints
Intractable problems often become tractable additional restrictions imposed
topology constraint graph, constraints themselves. subsection
identify one significant class linear constraints propagated strongly
polynomial time, based restriction coefficients constraints.
initial observation one source complexity propagators Li,k Eq.
5 use rounding: update variables bounds, obtain
variables real value rounded upwards lower bounds downwards upper
bounds. effects rounding noticed previous authors used optimize
4. Note also case inequalities propagators bound(Z) consistency
bound(R) consistency. Since want propagators polynomial-time computable, case want
avoid however bound(Z) consistency linear equalities, cannot define polynomial-time
computable propagators unless P=NP.

667

fiBordeaux, Katsirelos, Narodytska, & Vardi

propagation (Harvey & Stuckey, 2003). Rounding effectively means propagation stabilizes integral solutions Linear Programs. Linear Programs question
specific form, intractability due integrality. Therefore sub-section
(1) observe remove rounding, problem becomes tractable; (2) use
observation show coefficients unit (i.e., belong {1, 0, +1}),
effectively rounding, means tractability result holds.
3.4.1 Linear Propagators without Rounding
consider operators similar Eq. 5 without rounding, words
associate linear constraints following operators:
ai,k > 0 x
:=




Si,k :
ai,k < 0

x+


:=

q

i,k
max x
, ai,k

min



qi,k
x+
, ai,k



(9)



Even initial bounds integers assumed throughout paper,
operators general reduce bounds real-values. Note propagators
effectively used deal variables real-valued domain, indeed used
Constraint Programming community (Behamou & Granvilliers, 2006)
Operations Research community, different terminology used (Feasibility-Based
Bounds Tightening, see e.g. Belotti, Cafieri, Lee & Liberti, 2010).
decision problem focus whether exist real-valued bounds
fixpoint. note problem tractable; similar result reported
independently work Belotti, Cafieri, Lee, Liberti (2010).
Decision Problem 2 (Fixpoint Continuous Linear Propagators)
INPUT: CSP whose set constraints C linear inequalities.
QUESTION: set real-valued propagators F = {Si,k : 1..n, k 1..m} associated C common fixpoint?
Observation 2 Decision problem 2 decided Linear Programming.
easy see fixpoints operators Si,k exactly real-valued solutions
system linear constraints Eq. 6. Note careful statement
Observation 2: whether Linear Programming strongly polynomial fact longstanding open question (Smale, 1998). best polynomial-time LP algorithms are,
encouragingly, time complexity O((n, m, b)) polynomial , b
number bits number encodingthis looks strongly polynomial (Khachian, 1979).
catch: complexity counted number operations, operations
rationals principle expand size numbers (repeated multiplications
blow-up representation exponentially). However, practical purposes, typical LP
implementations prevent blow-up number representation limiting precision
b bits throughout execution; solvability Linear Programming widely regarded
synonymous strong tractability, provably sub-exponential LP algorithms exist
(Matousek, Sharir, & Welzl, 1996). words, Observation 2 really read
carefully phrased way say Problem 2 efficiently solvable practice.
668

fiThe Complexity Integer Bound Propagation

3.4.2 Linear Constraints Unit Coefficients
unit linear constraint usual form i1...n ai,k xi ck additional
restriction coefficient ai,k chosen {1, 0, +1}. introductory example
slow convergence (Eq. 1) (particularly simple) example unit linear constraints,
slow convergence could particular case avoided. Note considering
linear unit constraints number variables. special case unit constraints
widely studied class unit-TVPI constraints (i.e., unit TVPI).
perhaps important class linear constraints whose integer feasibility
solved strongly polynomial time, see instance work Jaffar et al. (1994).
P

Proposition 2 constraints unit coefficients, Decision Problem 1
decided Linear Programming.
Proof. LP is, course, form given Eq. 6. observation is, short,
rounding needed coefficients unit.

precisely, Cartesian product intervals A, let L(A) = i,k Li,k (A)

S(A) = i,k Si,k (A). show coefficients unit (as defined)
bounds initial Cartesian product integral, Lt (D) = (D),
0. first note bounds Lt (D) integral since original
state integral bounds operator L applies rounding. equality
Lt (D) = (D) proved induction t. = 0, Lt (D) = (D) = D.
induction hypothesis holds step t, t+1 (D) = S(S (D)) = S(Lt (D)).
t+1 (D) = L(Lt (D)) = Lt+1 (D) Lt (D) integral bounds, hence applying L
Cartesian product gives result. (In Eq. 5 qi,k integral case
ai,k unit therefore division qi,k /ai,k gives integer, means
propagators Li,k rounding return result non-rounded propagators Si,k
Eq. 9.)
Lt (D) = (D), 0 easy see gfp{Li,k } = gfp{Si,k }.
domains finite Lt (D) stabilizes finite t. particular t, Lt (D)
greatest fixpoint L greatest Cartesian product (D) also greatest
fixpoint S. 2
Note general Linear Programming necessarily find integer solutions
system Eq. 6; result shows LP find solution iff integer one
+
exists. want actually compute largest consistent bounds x
xi certain

+
variable xi , simply minimize xi maximize xi constraints Eq. 6.
previous proof shows extremal values integral.
3.4.3 Tractable Cases?
interesting consider whether properties make propagation solvable
strongly polynomial time. respect restrictions constraint graph,
nevertheless reasons pessimistic: note feasibility monotone TVPI Integer
Programming remains NP-complete strict restrictions constraint graph,
shown work Hochbaum Naor (1994). suggests restrictions
unlikely lead interesting tractable classes fixpoint computation.
669

fiBordeaux, Katsirelos, Narodytska, & Vardi

Regarding restrictions coefficients, note general NP-completeness
(monotone) TVPI constraints assumes coefficients ak , bk , ck arbitrary.
Unit restriction imposes, contrary, strongest restriction coefficients:
absolute value 1. impose general bound absolute values
one may wonder whether problem exhibits form fixed-parameter tractability.
leave question open future work.

4. Generalizations Non-Linear Constraints
Proposition 1, fixpoint computation numerical constraints basic common
linear constraints intractable. Several cases non-linear constraints nevertheless interest. First, show simplest possible type polynomials (a single
squaring operation) added linear constraints, general hardness result
strengthened. Second, interesting note enrich unit linear constraints
simple min max constraints, fixpoint computation equivalent puzzling open
problem discussed recently theorem-proving literature. Last, briefly comment
connections results tractability max-closed constraints.
4.1 Quadratic Constraints
purposes section sufficient enrich linear constraint language
(constraints form given Eq. 2) squaring constraints form:
xi = x2j
also sufficient restrict non-negative values variables xi xj , i.e.,
0 li ui 0 lj uj . setting bound(R) consistency propagators
defined following instructions:




x
:= max(xi , xj

x
j

:=

max(x
j ,

2

q

x




)

+
+
x+
:= min(xi , xj



x+
j

)

:=

min(x+
j ,

q

2

x+


)



)

words fixpoints integer solutions following bound consistency
inequalities:



x
xj

2

;



+
x+
xj

2

;

x
j

q

x
;

x+
j

q

x+


(10)

simple quadratic constraints added language linear constraints,
NP-completeness result strengthened: problem NP-complete even
considering bounded(!) number variables constraints; fact one TVPI constraint
one squaring constraint. due fact fixpoint computation converges
state encodes complex number-theoretic problem.
Proposition 3 Given CSP 3 variables 2 constraints a1 x1 + a2 x2 = c, x1 = x23 ,
determining whether associated bound(R) consistency propagators fixpoint
NP-complete.
670

fiThe Complexity Integer Bound Propagation

Proof. Membership NP straightforward. show hardness result special
case ai 0, {1, 2, 3} focus, said, positive intervals. first note
bound consistency inequalities (Eq. 10) squaring constraint x1 = x23
2
+
+ 2
satisfied iff x
1 = (x3 ) x1 = (x3 ) since focus integer bounds. (This property
squaring propagator noticed slightly different form Schulte & Stuckey, 2005).
propagation viewpoint equality a1 x1 + a2 x2 = c seen two inequalities
a1 x1 + a2 x2 c a1 x1 a2 x2 c whose bound consistent inequalities (Eq. 4)

+
+
effectively satisfied iff a1 x
1 + a2 x2 = c a1 x1 + a2 x2 = c.
rely theorem (Manders & Adleman, 1978) shows deciding whether
equation form a1 x23 + a2 x2 = c integer solutions, a1 , a2 c
non-negative integers, NP-complete. reduce problem existence bound
consistent bounds conjunction a1 x1 + a2 x2 = c, x1 = x23 initial bounds l1 = l2 =
l3 = 0 u1 = u2 = u3 = c. need show fixpoint computation complete
systema bound consistent state found iff original equation solution:
original equation solution, i.e., pair non-negative integer values

+
+
2
hv2 , v3 satisfying a1 v32 + a2 v2 = c, define x
1 = x1 = v3 , x2 = x2 = v2 ,

+

+
x3 = x3 = v3 . bounds 0 xi xi c satisfy bound
consistency conditions Eq. 10 Eq. 4.

2

+
conjunction bound consistent state, i.e., bounds x
, xi Eq. 10

Eq. 4 satisfied, solution v defined v2 = x+
2 v3 = x3 satisfies
2
original equation a1 v3 + a2 v2 = c.

4.2 Connections Max-Atom Problem
Another common type primitive non-linear constraints form:
xh = max(xi , xj )
bound(R) consistency propagators constraint following (Schulte &
Stuckey, 2005):
+ +
x+
:= min(xi , xh )


x
h := max(xh , xi , xj )

+ +
+
+ +
+
x+
h := min(xh , max(xi , xj )) xj := min(xj , xh )

(In fact strictly reach bound(R) consistency one would need additionally check
whether bounds xh empty intersection bounds one max-ed
variables, say xi , case essentially impose constraint xj = xh ;
purposes section simpler formulation equivalent.) words
fixpoints characterized following inequalities:
+ +
x+
h max(xi , xj )

+
x+
xh

+
x+
j xh


x
h xi


x
h xj

fixpoint computation max constraints mixed unit linear constraints interesting
complexity open problem. Note rounding use
671

fiBordeaux, Katsirelos, Narodytska, & Vardi

coefficients definition bound consistency inequalities, therefore complexity
arising rounding NP-complete variants propagation arise here.
open problem connect called Max-Atom work Bezem, Nieuwenhuis,
Rodrguez-Carbonell (2008); see reference prior problems interest
shown equivalent Max-Atom. max-atom constraint form: max(xi , xj )+c xh .
work reported Bezem et al. (2008) shows number results feasibility
conjunctions max-atom constraints: (1) significant complexity difference
integer real feasibility; (2) problem decided pseudo-polynomial
time using amounts fixpoint computation algorithm; (3) problem short
proofs unsatisfiability therefore NPcoNP; means
different nature NP-complete variants. fact, recent result (Atserias &
Maneva, 2010) shows complexity Max-Atom equivalent well-known open
problems called mean-payoff games, turn connections important open
questions model-checking: parity games, class games reducible mean-payoff games,
equivalent model-checking problem -calculus (Emerson, Jutla, & Sistla, 1993;
Jurdzinski, 1998).
draw simple connection follows observation bound
+ +
consistency inequalities upper bounds include constraint x+
h max(xi , xj )
encode max-atom constraints almost directly.
Proposition 4 Bound(R) consistency combination unit linear max constraints
solved polynomial time Max-Atom also solved polynomial time.
Proof. reduce Max-Atom instance variables xi , 1 . . . n constraints
fixpoint computation problem simply introduce one fresh variable yk , k 1 . . . m.
Let kth constraint form max(xik , xjk ) + ck xhk , rewrites conjunction
max(xik , xjk ) = yk , yk + ck xhk . lower bounds variables fixed 0
P
upper bounds need set k1...m ck small model property (Lemma 2)
paper Bezem et al. (2008). bound consistency equations upper bounds directly
encode problem. 2

4.3 Max-Closed Constraints
last note connection results class max-closed constraints
introduced Jeavons Cooper (1995) (more in, e.g., Petke & Jeavons, 2009).
constraint R(x1 , . . . , xn ) max-closed whenever two solutions hv1 . . . vn
hw1 . . . wn i, maximum defined hmax(v1 , w1 ), . . . , max(vn , wn )i also solution.
Results Jeavons Cooper (1995) show max-closed constraints tractable:
system constraints max-closed, feasibility determined polynomial
time. However note result essentially assumes explicit (or table) representation
constraint, i.e., assumed constraint defined explicitly listing
tuples solutions it. contrast important types constraints
numerical constraints considered paper implicitly defined: know
list solutions R(x1 , . . . , xn ) verify efficiently whether particular tuple
accepted constraint.
672

fiThe Complexity Integer Bound Propagation

Implicitly-defined max-closed constraints played important role paper:
monotone TVPI constraints, considered Section 3.2 Max-atom constraints
considered Section 4.2, max-closed, shown respectively Hochbaum Naor
(1994), Bezem et al. (2008). sharp contrast case explicitly-defined constraints, resolution implicitly-defined max-closed constraints therefore pseudopolynomial fact intractable, shown special case monotone TVPI
constraints:
Observation 3 feasibility implicitly-defined max-closed constraints NP-complete.
shown Section 3.2 particular example monotone TVPI constraints,
even fixpoint computation implicitly defined max-closed constraints is, fact, NPcomplete general.

5. Conclusion
Reasoning intervals introduced AI literature works Cleary (1987),
Davis (1987)5 . substantial body AI work ensued (see, e.g. Hyvonen, 1992);
bound computation used finite-domain CP solvers (Schulte & Carlsson,
2006).
paper theoretically investigated complexity computing common
fixpoint set bound consistency propagators. shown even
propagators simple, fixpoint computation used algorithms
complex, indeed NP-complete even restricted constraint class linear
monotone inequalities two variables per inequality. also considered special
classes constraints, like quadratic constraints max constraints. Finally, identified
class constraints, namely, linear inequalities unit coefficients, allows tractable
fixpoint computation algorithm.
Bound propagation successful widely used technique Constraint Programing.
large literature propagating single constraints (Van Hoeve & Katriel, 2006;
Bessiere, 2006; Rossi, van Beek, & Walsh, 2006) perhaps surprise prior
study exists complexity fixpoint computation. NP-completeness fixpoint
computation simple types constraints fundamental somewhat surprising
result, one sheds light slow convergence phenomena.
result also puts bound propagation map AI computational problems:
together knapsack constraints forms learning neural nets (Schaeffer &
Yannakakis, 1991), one important AI problems aware
pseudo-polynomial complexity yet intractable.
Acknowledgments
Preliminary results Bordeaux, Hamadi, Vardi (2007) showed NP-completeness
propagation case quadratic constraints considered (Prop. 3).
5. often, good case made similar ideas already present earlier work, particular
work Lauriere (1978). Interval computations course also used areas fixpoint
computation methods consider relate broader theme interval arithmetic pioneered Moore
(1966).

673

fiBordeaux, Katsirelos, Narodytska, & Vardi

paper thoroughly revised version whose central result linear constraints new
general. Part work done G. Katsirelos, N. Narodytska
M. Vardi visiting Microsoft Research, Cambridge. Part work done
G. Katsirelos employed NICTA, Australia. NICTA funded Australian
Governments Department Broadband, Communications, Digital Economy
Australian Research Council. work partially supported ANR UNLOC
project: ANR 08-BLAN-0289-01. Discussions Youssef Hamadi Claude-Guy Quimper gratefully acknowledged. Thanks also anonymous reviewers whose feedback
helped improve paper.

References
Apt, K. R. (1999). essence constraint propagation. Theoretical Computer Science
(TCS), 221 (1-2), 179210.
Apt, K. R., & Zoeteweij, P. (2007). analysis arithmetic constraints integer intervals.
Constraints, 12 (4), 429468.
Aspvall, B., & Shiloach, Y. (1980). polynomial time algorithm solving systems
linear inequalities two variables per inequality. SIAM J. Computing, 9 (4),
827845.
Atserias, A., & Maneva, E. (2010). Mean-payoff games max-atom problem. Tech.
rep., Universitat Politecnica de Catalunya.
Bar-Yehuda, R., & Rawitz, D. (2001). Efficient algorithms integer programs two
variables per constraint. Algorithmica, 29 (4), 595609.
Behamou, F., & Granvilliers, L. (2006). Continuous interval constraints. Rossi, F.,
van Beek, P., & Walsh, T. (Eds.), Handbook Constraint Programming, chap. 16.
Elsevier.
Belotti, P., Cafieri, S., Lee, J., & Liberti, L. (2010). Feasibility-based bounds tightening via
fixed points. Proc. Int. Conf. Combinatorial Optimization Applications
(COCOA), p. Appear.
Benhamou, F. (1996). Heterogeneous constraint solving. Proc. Int. Conf. Algebraic
Logic Programming (ALP), pp. 6276.
Bessiere, C. (2006). Constraint propagation. Rossi, F., van Beek, P., & Walsh, T. (Eds.),
Handbook Constraint Programming, chap. 3. Elsevier.
Bezem, M., Nieuwenhuis, R., & Rodrguez-Carbonell, E. (2008). max-atom problem
relevance. Proc. Int. Conf. Logic Programming, Artificial Intelligence Reasoning (LPAR), pp. 4761.
Bordeaux, L., Hamadi, Y., & Vardi, M. Y. (2007). analysis slow convergence
interval propagation. Proc. Int. Conf. Principles Practice Constraint
Programming (CP), pp. 790797.
674

fiThe Complexity Integer Bound Propagation

Choi, C. W., Harvey, W., Lee, J. H. M., & Stuckey, P. J. (2006). Finite domain bounds
consistency revisited. Australian Conf. Artificial Intelligence, pp. 4958.
Cleary, J. G. (1987). Logical arithmetic. Future Computing Systems, 2 (2), 125149.
Davis, E. (1987). Constraint propagation interval labels. Artificial Intelligence, 32 (3),
281331.
Emerson, E. A., Jutla, C. S., & Sistla, A. P. (1993). model-checking fragments
-calculus. Proc. Int. Conf. Computer-Aided Verification (CAV), pp. 385396.
Harvey, W., & Schimpf, J. (2002). Bound consistency techniques long linear constraints.
Proc. CP workshop Techniques Implementing Constraint Propgramming
Systems (TRICS).
Harvey, W., & Stuckey, P. J. (2003). Improving linear constraint propagation changing
constraint representation. Constraints, 8 (2), 173207.
Hochbaum, D. S., & Naor, J. (1994). Simple fast algorithms linear integer
programs two variables per inequality. SIAM J. Computing, 23 (6), 1179
1192.
Hyvonen, E. (1992). Constraint reasoning based interval arithmetic: tolerance
propagation approach. Artificial Intelligence, 58 (1-3), 71112.
Jaffar, J., Maher, M. J., Stuckey, P. J., & Yap, R. H. C. (1994). Beyond finite domains.
Proc. Int. Workshop Principles Practice Constraint Programming
(PPCP), pp. 8694.
Jeavons, P., & Cooper, M. C. (1995). Tractable constraints ordered domains. Artificial
Intelligence, 79 (2), 327339.
Jurdzinski, M. (1998). Deciding winner parity games co-UP. Inf. Process.
Lett., 68 (3), 119124.
Katriel, I., Sellmann, M., Upfal, E., & Van Hentenryck, P. (2007). Propagating knapsack
constraints sublinear time. Proc. (North Amer.) Nat. Conf. Artificial
Intelligence (AAAI), pp. 231236.
Khachian, L. (1979). polynomial algorithm linear programming. Doklady Akad. USSR,
244, 10931096.
Lagarias, J. C. (1985). computational complexity simultaneous diophantine approximation problems. SIAM J. Computing, 14 (1), 196209.
Lauriere, J.-L. (1978). language program stating solving combinatorial
problems. Artificial Intelligence, 10 (1), 29127.
Lebbah, Y., & Lhomme, O. (2002). Accelerating filtering techniques numeric CSPs.
Artificial Intelligence, 139 (1), 109132.
675

fiBordeaux, Katsirelos, Narodytska, & Vardi

Leconte, M., & Berstel, B. (2006). Extending CP solver congruences domains
program verification. CP Workshop Software Testing, Verification Analysis,
pp. 2233.
Lhomme, O. (1993). Consistency techniques numeric CSPs. Proc. Int. Joint. Conf.
Artificial Intelligence (IJCAI), pp. 232238.
Lhomme, O., Gottlieb, A., Rueher, M., & Taillibert, P. (1996). Boosting interval
narrowing algorithm. Proc.of Joint Int. Conf. Symp. Logic Programming
(JICSLP), pp. 378392. MIT Press.
Manders, K. L., & Adleman, L. M. (1978). NP-complete decision problems binary
quadratics. J. Computer System Sciences, 16 (2), 168184.
Matousek, J., Sharir, M., & Welzl, E. (1996). subexponential bound linear programming. Algorithmica, 16 (4/5), 498516.
Moore, R. E. (1966). Interval Analysis. Prentice-Hall.
Papadimitiou, C. (1994). Computational Complexity. Addison Wesley.
Petke, J., & Jeavons, P. (2009). Tractable benchmarks constraint programming. Tech.
rep. CS-RR-09-07, Oxford University Computing Laboratory.
Rossi, F., van Beek, P., & Walsh, T. (2006). Handbook Constraint Programming. Elsevier.
Schaeffer, A. A., & Yannakakis, M. (1991). Simple local search problems hard
solve. SIAM J. Computing, 20 (1), 5687.
Schulte, C., & Carlsson, M. (2006). Finite domain constraint programming. Rossi, F.,
van Beek, P., & Walsh, T. (Eds.), Handbook Constraint Programming, chap. 14.
Elsevier.
Schulte, C., & Stuckey, P. J. (2005). bounds domain propagation lead
search space?. ACM Trans. Programming Languages Systems
(TOPLAS), 27 (3), 388425.
Smale, S. (1998). Mathematical problems next century. Mathematical Intelligencer,
20, 715.
Trick, M. A. (2001). dynamic programming approach consistency propagation
knapsack constraints. Proc. Int. Conf. Integration AI Techniques
CP Combinatorial Optimisation Problems (CP-AI-OR).
Van Hoeve, W.-J., & Katriel, I. (2006). Global constraints. Rossi, F., Van Beek, P., &
Walsh, T. (Eds.), Handbook Constraint Programming, chap. 6. Elsevier.
Yuanlin, Z., & Yap, R. H. C. (2000). Arc consistency n-ary monotonic linear constraints. Proc. Int. Conf. Principles Practice Constraint Programming
(CP), pp. 470483.

676

fiJournal Artificial Intelligence Research 40 (2011) 143174

Submitted 07/10; published 01/11

Automated Search Impossibility Theorems
Social Choice Theory: Ranking Sets Objects
Christian Geist
Ulle Endriss

cgeist@gmx.net
ulle.endriss@uva.nl

Institute Logic, Language Computation
University Amsterdam
Postbus 94242
1090 GE Amsterdam
Netherlands

Abstract
present method using standard techniques satisfiability checking automatically verify discover theorems area economic theory known ranking
sets objects. key question area, important applications social
choice theory decision making uncertainty, extend agents preferences number objects preference relation nonempty sets objects.
Certain combinations seemingly natural principles kind preference extension
result logical inconsistencies, led number important impossibility
theorems. first prove general result shows wide range principles, characterised syntactic form expressed many-sorted first-order
logic, impossibility exhibited fixed (small) domain size necessarily extend
general case. show formulate candidates impossibility theorems
fixed domain size propositional logic, turn enables us automatically search
(general) impossibility theorems using SAT solver. applied space 20
principles preference extension familiar literature, method yields total
84 impossibility theorems, including known nontrivial new results.

1. Introduction
area economic theory known ranking sets objects (Barbera, Bossert, & Pattanaik, 2004; Kannai & Peleg, 1984) addresses question extend preference relation defined certain individual objects preference relation defined nonempty
sets objects. question important applications. instance, agent
uncertain effects two alternative actions, may want rank relative
desirability two sets possible outcomes corresponding two actions.
absence probability distribution possible outcomes, principles methods
developed literature ranking sets objects guide kind decision making (complete) uncertainty (e.g., see Gravel, Marchant, & Sen, 2008; Ben Larbi,
Konieczny, & Marquis, 2010). second example applications voting theory.
want analyse incentives voter manipulate election, i.e., obtain
better election outcome misrepresenting true preferences ballot
sheet, need able reason preferences case election produce
tie return set winners (e.g., see Gardenfors, 1976; Duggan & Schwartz, 2000;
c
2011
AI Access Foundation. rights reserved.

fiGeist & Endriss

Taylor, 2002). scenarios, decision making uncertainty manipulation
elections sets tied winners, agents assumed preferences simple
objects (states world, election outcomes) need extend sets
objects able use extended preferences guide decisions.
One line research applied axiomatic method, practised particular social
choice theory (Gaertner, 2009), problem ranking sets objects formulated
certain principles extending preferences set preferences axioms. instance,
dominance axiom states prefer set {x} set whenever prefer
individual object x element (and {x} case x worse
element A); independence axiom states prefer set set B,
preference get inverted add new object x sets.
intuition, Kannai Peleg (1984) shown that, domain least six
objects, impossible rank sets objects manner satisfies dominance
independence. original seminal result field, since 1984
small number additional impossibility theorems established.
paper develop method automatically search impossibility theorems
like Kannai-Peleg Theorem, enable us verify correctness known results
discover new ones. number reasons useful. First,
ability discover new theorems clearly useful whenever theorems (potentially)
interesting. also verification known results merits: verification increase
confidence correctness result (the manual proof may tedious
prone errors); verification forces us fully formalise problem domain,
often result deeper understanding subtleties; verification theorems new
fields (here social economic sciences) help advance discipline automated
reasoning providing new test cases challenges.
first time techniques logic automated reasoning
applied modelling verifying results economic theory. briefly review
number recent contributions applying tools social choice theory, closely
related problem domain focus paper. lot work concentrated
Arrows Theorem, establishes impossibility aggregating preferences
group agents manner satisfies certain seemingly natural principles (Arrow, 1963;
Gaertner, 2009). Agotnes, van der Hoek, Wooldridge (2010), instance, introduce
modal logic modelling preferences aggregation, Grandi Endriss
(2009) show Arrows Theorem equivalent statement certain set
sentences classical first-order logic possess finite model.
Besides formally modelling problem domain theorem, also
number attempts automatically re-prove Arrows Theorem. One approach
encode individual steps known proofs higher-order logic verify
correctness proofs proof checker. Examples line work
contributions Wiedijk (2007), formalised proof Arrows Theorem
Mizar proof checker, Nipkow (2009), using Isabelle
system. particularly interesting approach due Tang Lin (2009). authors
first prove two lemmas reduce general claim Arrows Theorem statement
pertaining special case two agents three alternatives. show
statement equivalently modelled (large) set clauses propositional
144

fiAutomated Search Impossibility Theorems Social Choice Theory

logic. inconsistency set clauses verified using SAT solver,
turn (together lemmas) proves full theorem. Tang Lin able
extend method verification number results social choice
theory also shown method serve useful tool support
(semi-automatic) testing hypotheses search new results (Tang & Lin, 2009;
Tang, 2010).1 contributions neatly fit broad heading computational
social choice, discipline concerned study computational aspects social
choice, application computational techniques problems social choice theory,
integration methods social choice theory AI areas computer
science (Chevaleyre, Endriss, Lang, & Maudet, 2007).
starting point developing method automatically proving impossibility theorems area ranking sets objects work Tang Lin (2009).
adapted extended approach follows. Rather proving new lemma
reducing general impossibility impossibility small domain every
theorem want verify, first contribution broadly applicable result,
Preservation Theorem, entails combinations axioms satisfying certain
syntactic conditions, impossibility established domain (small) fixed
size n unravel full impossibility theorem domains size n. able
formulate result, introduce many-sorted first-order logic expressing axioms
relating preferences individual objects preferences sets objects.
able express axioms literature language, facilitates fully
automated search impossibility theorems within space axioms.
show impossibility theorems regarding extension preferences
modelled propositional logic, provided size domain fixed. Given Preservation Theorem, inconsistency found help SAT solver immediately
corresponds general impossibility theorem. implemented kind automated theorem search scheduling algorithm exhaustively searches space
potential impossibility theorems given set axioms given critical domain size n.
Together number heuristics pruning search space, approach represents
practical method verifying existing discovering new impossibility theorems.
Finally, applied method search space defined 20 important preference extension axioms literature, exhaustively searched
space (of around one million possible combinations) domains eight objects.
search resulted 84 (minimal) impossibility theorems. theorem states,
particular n 8 particular set axioms , exists preference ordering
nonempty sets objects satisfies axioms n
objects domain. 84 theorems minimal sense strict subset
would still result impossibility (at given domain size n) sense
axioms satisfied domain fewer n objects.
84 impossibility theorems found include known results (such Kannai-Peleg
Theorem), simple consequences known results, well new nontrivial theorems
constitute relevant contributions literature ranking sets objects. One
impossibility combining independence weakened form dominance
1. See work Lin (2007) outline general methodology well several examples
applications domains social choice theory.

145

fiGeist & Endriss

two axioms known simple uncertainty aversion simple top monotonicity (see
Appendix A). particularly interesting, (in context characterisation
particular type set preference orders) set axioms previously
claimed consistent (Bossert, Pattanaik, & Xu, 2000). later found
mistake, corrected Arlegi (2003), even work establish actual impossibility theorem. certainly demonstrates nontrivial nature
problem. interesting theorems discovered method include variants
Kannai-Peleg Theorem involving weakened versions independence axiom, impossibility theorems rely dominance axiom (which integral component
results field), impossibility theorems critical domain
size n different featuring known results literature.
remainder paper organised follows. Section 2 introduces formal
framework ranking sets objects recalls seminal result field, KannaiPeleg Theorem. Section 3 prove Preservation Theorem, allows us reduce
general impossibilities small instances. Section 4 shows model small
instance sets clauses propositional logic. Building insights, Section 5
finally presents method automatically search impossibility theorems, well
84 impossibility theorems able obtain using method. Section 6
concludes brief summary discussion possible directions future work.
Appendix provides list 20 axioms used automated theorem search.
reader find additional detail, regarding method impossibility theorems
discovered, Masters thesis first author (Geist, 2010).

2. Ranking Sets Objects
Ranking sets objects deals question agent rank sets objects,
given preferences individual objects. Answers question depend
concrete interpretation assigned sets (Barbera et al., 2004):
Complete uncertainty. interpretation, sets considered containing
mutually exclusive alternatives final outcome selected later
stage, agent influence selection procedure.
Opportunity sets. Here, again, sets contain mutually exclusive alternatives,
time agent pick final outcome set herself.
Sets final outcomes. setting, sets contain compatible objects assumed materialise simultaneously (i.e., agent receive together).
Suppose agent prefers object x object y. first interpretation
reasonable assume rank {x} (receiving x certainty) {x, y}
(receiving either x y). second interpretation might indifferent
{x} {x, y}, simply pick x latter set. third interpretation,
finally, might prefer {x, y}, give top x. paper, focus
idea complete uncertainty, studied three. important
application interpretation voting theory: want analyse whether voter
incentive manipulate election often reason preferences
146

fiAutomated Search Impossibility Theorems Social Choice Theory

alternative outcomes, producing set tied winning candidates (Gardenfors,
1976; Duggan & Schwartz, 2000; Taylor, 2002).
Next, introduce notation mathematical framework usually employed treat
problems field ranking sets objects (e.g., see Barbera et al., 2004),
present aforementioned Kannai-Peleg Theorem detail (Kannai & Peleg, 1984).
2.1 Formal Framework

Let X (usually finite) set alternatives (or objects), (preference) order

defined. order assumed linear, i.e., reflexive, complete, transitive
>,
i.e., x >

antisymmetric binary relation. denote strict component
x. interpretation

x
x
x
considered least good decision maker.
Similarly, binary relation set nonempty subsets X (denoted
X := 2X \{}). relation assumed weak order (reflexive, complete,
transitive); later on, however, proof method allow explore weaker assumptions
regarding , too. Like above, use strict component . Additionally,
also define indifference relation setting B B B A.

X write max(A) maximal element respect

min(A) minimal element respect .
2.2 Kannai-Peleg Theorem
Kannai Peleg (1984) probably first treat specific problem extending
preferences elements subsets problem right axiomatic
fashion. previous work, authors regarded problem side issue
problems, particularly analysis manipulation elections (e.g., see
Fishburn, 1972; Gardenfors, 1976), merely axiomatised specific methods extension
without considering general problem (e.g., see Packard, 1979).
Kannai-Peleg Theorem makes use two axioms, plausible
interpretation complete uncertainty. First, Gardenfors principle
(Gardenfors, 1976, 1979), also known dominance. principle consists two parts
requires
elements given set,
(1) adding element, strictly better (>)
given set produces strictly better set respect order ,
elements given set,
(2) adding element, strictly worse (<)
given set produces strictly worse set respect order .
Formally, Gardenfors principle (GF) written following two axioms:
(GF1)
(GF2)

a) {x}
((a A)x >
a) {x}
((a A)x <

x X X ,
x X X .

Second, monotonicity principle called independence, states that,
set strictly better another one, adding alternative (which
contained either sets before) sets simultaneously reverse strict
147

fiGeist & Endriss

order. equivalent way stating (in light completeness order)
require least non-strict preference remains original strict preference (such
becomes ). formal statement reads follows:
(IND)

B {x} B {x}

A, B X x X \ (A B).

get main theorem, present lemma, also due Kannai Peleg
(1984). says specific rankings satisfy conditions (GF) (IND).
Lemma 1. satisfies Gardenfors principle (GF) independence (IND),
{max(A), min(A)} X .
Proof. Let nonempty subset X. |A| 2 lemma holds trivially
reflexivity since = {max(A), min(A)}. suppose |A| 3 define
:= A\max(A). Note that, |A| 3, set nonempty thus {min(A)} =
{min(A )}. repeated application (GF1) get {min(A)} = {min(A )} .
add max(A) sides, showing {min(A), max(A)} (IND).
completely analogous way get {min(A), max(A)} A+ {min(A)} = (GF2)
(IND), A+ := \ min(A).
is, Lemma 1 shows ranking subsets completely determined
worst best elements. ready state prove theorem.
Theorem 1 (Kannai Peleg, 1984). Let X linearly ordered set |X| 6.
exists weak order X satisfying Gardenfors principle (GF) independence (IND).
Proof. Let xi , {1, 2, . . . , 6} denote six distinct elements X ordered
respect index, i.e., x1 >
x2 >
x3 >
x4 >
x5 >
x6 . way contraby >
diction, suppose exists weak order X satisfying Gardenfors principle (GF)
independence (IND). first claim
{x2 , x5 } {x3 }.

(1)

order prove claim, suppose contrary case, completeness
{x3 } {x2 , x5 }. then, (IND), include x6 , yields {x3 , x6 }
{x2 , x5 , x6 }. Note together Lemma 1 (and transitivity) implies
{x3 , x4 , x5 , x6 } {x2 , x3 , x4 , x5 , x6 },
contradicting (GF1). Thus, claim (1) must true follows {x3 } {x3 , x4 }
{x4 } (which consequence Gardenfors principle) together transitivity
{x2 , x5 } {x4 }. Using (IND) again, add (the far unused) x1 get {x1 , x2 , x5 }
{x1 , x4 }. before, fill intermediate elements sets obtain,
Lemma 1 transitivity, {x1 , x2 , x3 , x4 , x5 } {x1 , x2 , x3 , x4 }, time
contradicts (GF2).
148

fiAutomated Search Impossibility Theorems Social Choice Theory

Put differently, Kannai-Peleg Theorem says Gardenfors principle (GF)
independence (IND) inconsistent domain six elements. Thus,
way extending linear order set least six objects weak order
collection nonempty sets objects. Kannai-Peleg Theorem
also referred impossibility theorem.
Many axioms discussed literature aware two impossibility theorems regarding choice complete uncertainty (Barbera et al., 2004).
selection 20 important axioms found Appendix A.

3. Reduction Impossibilities Small Instances
Kannai-Peleg Theorem applies set X least six elements,
proof given (which closely follows original proof Kannai Peleg) works
exhibiting case exactly six elements. fact impossibility theorem
applies larger domains well clear particular case. goal
section prove approach elevated general proof technique:
prove general impossibility theorem sufficient establish impossibilities small
instance. Specifically, prove call Preservation Theorem, says
certain axioms preserved specific substructures. corollary theorem
universal reduction step, says non-existence satisfying relation
small domain shows larger satisfying relation exist either.2
work framework mathematical logic order access syntactic well semantic features axioms. Section 3.1, first describe many-sorted
language specific problem ranking sets objects, apply techniques
model theory prove Preservation Theorem, Section 3.2, universal
reduction step corollary. universal step powerful enough cater
axioms literature able formalise language, including
listed Appendix A.
3.1 Many-Sorted Logic Set Preferences
natural well-understood language problem domain many-sorted (first-order)
logic, has, compared first-order logic, different quantifiers (allowing
quantification different domains containing elements respective sort),
still reducible first-order logic. Apart quantifiers, many-sorted logic practically equivalent first-order logic thus many results (e.g., soundness, completeness,
compactness, Lowenheim-Skolem properties, etc.) transferred first-order logic
directly proven (Manzano, 1996; Enderton, 1972).
Many-sorted logic characterised use set different sorts S.
structure (or model ) many-sorted logic like one first-order logic,
2. universal reduction step plays similar role inductive lemmas Tang Lin (2009) play
work computer-aided proof Arrows Theorem theorems social choice theory.
important difference domain ranking sets objects able prove single
result, allows us perform reductions wide range problems, Tang Lin
prove new (albeit similar) lemmas every new result tackled.

149

fiGeist & Endriss

separate domains doms (A) sort instead one single domain.
corresponding quantifiers sort s, equipped intuitive semantics:
|= x(x) |= (a) doms (A),
|= x(x) |= (a) doms (A).
that, many-sorted logic analogous first-order logic slight difference separate variable, function, relation symbols different sorts
combinations sorts.
case, two sorts (S = {, }): elements () sets ().
type
demand relation type h, well two relations
h, h, i, respectively. later interpreted usual membership
relation linear weak orders, respectively. one many relations
functions signature, use following time again:
Relations:
, type h, (intuitively: set inclusion)
disjoint, type h, (intuitively: true iff sets disjoint)
evencard, type hi (intuitively: true iff cardinality set even)
equalcard, type h, (intuitively: true sets cardinality)
Functions:
, type h, , (intuitively: set union)
{}, type h, (intuitively: transforms element singleton set)
replaceInBy, type h, , (intuitively: replace element set another
element; e.g., (A \ {a}) {b})
call language many-sorted logic (with two sorts signature
containing exactly relations functions) MSLSP (Many-Sorted Logic Set
Preferences). Notation-wise sometimes use (the common) infix notation
certain relations functions. instance write B, A, B
{x} instead (A, B), (a, A), (A, B) {}(x), respectively. Furthermore,
sometimes use negated symbols like x
/ (x A) well strict relation symbols
(y
x), respectively.
mean B (B A) x
B x >
Generally, use (standard model-theoretic) notation Hodges (1997).
MSLSP expressive enough formulate many axioms literature (including
20 axioms Appendix A) example give representations principle
independence Gardenfors principle (see Section 2.2):
Example 1. (IND) formulated MSLSP:
B x [(x
/ (A B) B) {x} B {x}]
150

fiAutomated Search Impossibility Theorems Social Choice Theory

Example 2. (GF) formulated MSLSP:
a)) {x} A]
x [( a(a x >
x)) {x}]
x [( a(a >
axioms, however, straightforward representations MSLSP.
concept weak preference dominance, proposed (in slightly stronger form) Sen
(1991), example axiom:
(WPD)

[(|A| = |B| exists bijective function : B


(a) B two sets A, B X .


Even though obvious way express axiom MSLSP, Puppe (1995)
showed (WPD) actually equivalent axiom much closer formalism,
calls preference-basedness easily seen expressible MSLSP.3


(A \ {a}) {b} X , A, b
(PB)
b
/ A,
might, however, case axioms expressible MSLSP all.
have, instance, able translate axiom neutrality (Nitzan & Pattanaik,
1984; Pattanaik & Peleg, 1984), says manner ranking lifted
objects sets objects depend names objects. axiom
usually defined terms function objects objects postulates
invariant , .
whenever


(x)
(y)
x (y)
(x)
(NEU)
x
x A, B]
[A B (A) (B) B (B) (A)]
two sets A, B X injective mapping : B X.
3.2 Preservation Theorem Universal Reduction Step
famous Los-Tarski Theorem classical model theory offers weak version result
going prove.4 does, however, cover certain axioms therefore
find stronger result classical model theory offer. idea able
preserve larger class axioms making use problem-specific features: like,
instance, element-set framework. Thus, define concepts structure set
preferences well subset-consistent substructures:
Definition 1. MSLSP-structure B structure set preferences fulfils
following criteria:
`


replaceInBy(a, A, b)
3. b b
/ Ab
4. exact statement theorem (for first-order logic) can, example, found Hodges book
(1997) Corollary 2.4.2 proof idea relatively simple: contradiction suffices show
1 -formulas preserved embeddings (Hodges, 1997, Thm 2.4.1). proof latter proceeds
induction complexity formula critical case existential quantifier
cause trouble witnesses lost moving larger structure.

151

fiGeist & Endriss

1. dom (B) 2dom (B) , i.e., domain sort contains sets elements
domain sort .
2. relation symbol type h, interpreted natural way.
substructure structure set preferences B structure set preferences,
too, called subset-consistent substructure.
Note substructure structure set preferences B
=B |dom(A) ,
i.e., symbol must interpreted restriction interpretation B. Hence,
sufficient fulfill first condition subset-consistent substructure B.
two semantic conditions suffice extending Los-Tarski Theorem larger
class axioms. axioms treat? Let us look
following (purely syntactic) definition first explain reasons choosing
particular class.
Definition 2. class existentially set-guarded (ESG) formulas smallest class
MSLSP-formulas recursively defined follows:
quantifier-free formulas ESG,
(x) 0 (x) ESG, (x) := ( 0 )(x) well 0 (x) := ( 0 )(x)
ESG,
(y, x) ESG, (x) := y(y, x) ESG sort {, },
(y, x) ESG, (x) := y(y t(x) (y, x)), term sort
occur x, ESG.
atomic formulas t(x) last condition called set-guards respective
quantifiers.
class ESG formulas consists MSLSP-formulas contain set-guarded
existential quantifiers sort , existential quantifiers sort all.
Note write (x), necessarily mean contains
variables sequence x = (x0 , x1 , x2 , . . . ), (free) variables
among x. also use notation [a], sequence elements,
mean elements a0 , a1 , a2 , . . . assigned variables x0 , x1 , x2 , . . . .
Intuitively, following: axioms allow existential quantifiers (but
elements, i.e., sort ) long guarded sub-formulas saying
respective witness belongs set. sets also unions sets formed
different way term t. important part moving structure
substructure set-guard guarantees witness existential quantifier
lost. witness within set (as required set-guard)
situated substructure.
explain give formal proof claim, let us look
examples ESG non-ESG sentences:
152

fiAutomated Search Impossibility Theorems Social Choice Theory

Example 3. axiom (GF1) (and similarly (GF2)) ESG sentence:

a(a
a(a
x[ a(a


x
a)
x

(quantifier-free)
(adding )

a) {x}
x
a) {x} A]
x

( quantifier-free)
(adding ).

Considering last line example, one understand removing elements X affect axiom. universal quantifiers restriction
domain problem anyway. also existential witness lost: suppose
removed set A, would set itself, -domain
contain sets elements -domain (by Definition 1). removed
need witness anymore.
one cannot allow arbitrary existential quantifiers without set-guards
seen considering following example, shows simple sentence (with
unguarded existential quantifiers) preserved substructures.
Example 4. MSLSP-sentence (axiom)
x z [x 6= x 6= z 6= z] ,
says least three distinct elements -domain structure
set preferences, clearly preserved substructures: holds structures
set preferences B least three elements dom (B), fails hold
substructures less three elements dom (A).
examples reader developed understanding ESG
sentences preserved substructures cannot allow much more. formal
proof Preservation Theorem explain first part further.
Note that, apart case existential quantifier, proof essentially
identical one direction proof Los-Tarski Theorem many-sorted logic,
carried model-theoretic grounds alone. last part
proof (the induction step existential quantifier) requires syntactic restriction
(to ESG sentences) well semantic restriction (to subset-consistent substructures),
latter allow particular problem domain.
Theorem 2 (Preservation Theorem). ESG sentences preserved subset-consistent
substructures, i.e., subset-consistent substructure structure set preferences
B B |= implies |= ESG sentence .
Proof. prove stronger statement ESG formulas (instead sentences) induction
complexity formula:
subset-consistent substructure structure set preferences B
B |= [a] implies |= [a] ESG formula (x) tuple
elements dom(A) (matching types x).
153

fiGeist & Endriss

let B structure set preferences subset-consistent substructure A, let (x)
ESG formula and, furthermore, let tuple elements dom(A) (matching
types x).
Quantifier-free Formulas: (x) quantifier-free, routine tedious proof leads
desired results. One carry nested inductions complexity terms
formulas, examples proofs found textbook Model Theory
(e.g., see Hodges, 1997, Theorem 1.3.1). First, one shows one induction terms
interpreted substructure interpreted superstructure B, i.e.,
tA [a] = tB [a]

(2)

terms t(x). practically immediately follows definition substructure.
one proceeds another induction proving atomic formulas hold
hold B, i.e.,
|= [a] B |= [a]
(3)
atomic formulas (x). typical example, suppose (x) form
R(s(x), t(x)), R relation symbol s(x) well t(x) terms (matching
type R). Assume |= R(s[a], t[a]), i.e., holds RA (sA [a], tA [a]). (2)
equivalent RA (sB [a], tB [a]). Since furthermore RA = RB |dom(A) , even
equivalence RB (sB [a], tB [a]), another way saying B |= R(s[a], t[a]).
Finally, one proves claim quantifier-free formula carrying induction
steps conjunction , disjunction negation . Note step
required directions (3).
Conjunction Disjunction: show part conjunction here; one
disjunction completely analogous. (x) form (x) 0 (x) furthermore
B |= [a], [a] 0 [a] must true B. induction hypothesis,
carries get |= [a] 0 [a].
Universal Quantification: (x) form y(y, x) sort {, }
furthermore B |= [a], b sort doms (B) B |= (b, a). Since
doms (A) doms (B) use induction hypothesis obtain |= (b, a)
b doms (A). saying |= y(y, a), i.e., |= [a].
Existential Quantification: (x) form y[y t(x) (y, x)], t(x)
term sort occur x, furthermore B |= [a], must exist
element b dom (B)
B |= (y t(x) (y, x)) [b, a], i.e., B |= t(x)[b, a] B |= [b, a].
Hence, show b -domain B, follows
induction hypothesis also
|= [b, a],
since (b, a) tuple elements A.
interpreted naturally structure set preferences B and, additionally,
cannot occur x, statement B |= t(x)[b, a] boils b tB [a],
equivalent
b tA [a]
(4)
154

fiAutomated Search Impossibility Theorems Social Choice Theory

since tA [a] = tB [a], stated (2).
fact b element dom (A) (and dom (B)) implied

[a] dom (A), together subset-consistent substructure:
()

b tA [a] dom (A) 2dom (A)
= b tA [a] 2dom (A)
= b tA [a] dom (A),
() marks point subset-consistency used.
Hence, can, indicated before, apply induction hypothesis B |= [b, a]
obtain |= [b, a]. Together b tA [a] follows
|= y(y t(x) (y, x))[a].
way done proof stronger claim (about formulas),
implies claim theorem (about sentences).
almost ready apply theorem setting. Note first, however,
theorem hold axioms ESG, also axioms
equivalent ESG sentence structures set preferences (the reason
truth value structure). refer axioms
ESG-equivalent axioms. particular applies sentences logically equivalent
(i.e., equivalent structures) ESG sentence.
Now, finally state prove corollary applying general result particular
problem domain ranking sets objects.
Corollary 1 (Universal Reduction Step). Let set ESG (or ESG-equivalent) axioms
let n N natural number. If, linearly ordered set n elements,
exists binary relation = 2Y \ {} satisfying , also linearly ordered set
X n elements binary relation X = 2X \ {} satisfies .
Proof. Let set ESG (or ESG-equivalent) axioms let n N natural
number. Assume linearly ordered set n elements, exists binary
relation = 2Y \ {} satisfying . way contradiction, suppose X linearly
ordered set |X| > n binary relation X = 2X \ {} satisfies .
view X X structure set preferences define subset-consistent substructure
restricting X X domain X, |Y | = n := 2Y \ {}.
Preservation Theorem ESG(-equivalent) axioms preserved subset-consistent
substructure Y. Hence, must linearly ordered set (as order axioms ESG)
and, furthermore, binary relation satisfying . Contradiction!
Remark. say given set ESG axioms, deserves explanation. mean axioms ESG MSLSP. One consider additional relations
functions added signature, holds hidden challenges.
instance, possible include predicate isWholeSet, true whole
domain only, function ()c complement, even constant symbol X referring whole domain, since three would (in natural interpretation) prevent
155

fiGeist & Endriss

substructure: example, X, isWholeSet(Y ) (or
equivalently, = X) false X X , true Y. Similarly, run problems
including functions like , \ ()c , (in natural interpretation)
functions strict sense structure like X X produce empty set,
X . Therefore, attention paid adding new relation
function symbols language order capture axioms.
basis Corollary 1 finally hoping for: order
prove new impossibility theorems check existing ones, look base
cases (as long axioms involved expressible MSLSP ESG-equivalent).
shall see next, small instances efficiently checked computer.

4. Representing Small Instances Propositional Logic
small instances, reduce impossibilities to, need checked
computer. requires clever approach direct check far expensive.
therefore modify extend technique due Tang Lin (2009).
remarkable Tang Lin (2009) able formulate base case
Arrows Theorem propositional logic, even though axioms intuitively
second-order statements. trick used introduce situations names
preference profiles, transforms second-order axioms first-order statements,
(because finiteness base case) translated propositional
logic. going use similar approach since axioms ranking sets objects
stated (somewhat enriched)5 second-order format, too. setting ranking sets
objects will, however, require different treatment (which going discuss
sequel) since also apply functions like union () singleton set ({}) sets
elements, respectively, whereas functions needed applied Tang Lins
situations. Instead coding operations sets within propositional language,
let program generates final formula handle them.
section, first show translate axioms ranking sets objects
propositional logic explain instantiate instances axioms fixed
domain sizes computer.
4.1 Conversion Propositional Logic
example, consider Kannai-Peleg Theorem (Theorem 1). light
universal reduction step (Corollary 1), proving theorem reduces proving small base
case exactly six elements:
Lemma 2 (Base case Kannai-Peleg Theorem). Let X linearly ordered set
exactly 6 elements. exists weak order X satisfying Gardenfors
principle (GF) independence (IND).
might seem tempting perform direct check involved axioms weak
orders nonempty subsets six-element space. This, however, seen
practically impossible around 1.525 1097 orderings (Sloane, 2010, integer
5. also order (i.e., relation) sets.

156

fiAutomated Search Impossibility Theorems Social Choice Theory

sequence A000670). Therefore, stick idea transforming axioms
Kannai-Peleg Theorem propositional logic checked SAT
solver, usually operates propositional formulas conjunctive normal form (CNF)
only. describe following instances axioms, like ones stated
Appendix A, converted language.
sufficient formalisation two kinds propositions only: w(A, B)
l(x, y) (corresponding propositional variables wA,B lx,y ) intended meanings
ranked least high B weak order (or short: B), x ranked
(or short: x
y), respectively. example,
least high linear order
base case Kannai-Peleg Theorem leads maximum |X |2 + |X|2 =
(26 1)2 + 62 = 4005 different propositional variables.
indicated earlier, axioms linear weak orders X X , respectively,
entirely unproblematic contain first-order quantifications and, thus,
easily transformed. example, include transformation transitivity
axiom orders sets:
(TRANS )

(A X )(B X )(C X ) [A B B C C]
^ ^ ^

[wA,B wB,C wA,C ] .
=
AX BX CX

Note, that, due finiteness X (and thus X ), derived formulas actually
finite objects therefore instantiated hand (requiring lot effort) using
computer. Furthermore, little work needed convert CNF.
axioms, like (GF) (IND), appear difficult transform
functions like singleton set {} : X X set union : X X X , occur
within axioms. fact, however, simple conversion technique
applied since going take care (and similar) functions automatically
computer program instantiation axioms. briefly
described Section 4.2 treat terms like B
corresponding objects functions range, i.e., images respective functions.
example, leads following conversion (GF1):
(GF1)

a) {x} A]
(A X )(x X)[((a A)x >
"
!
#
^ ^
^


lx,a la,x wA{x},A wA,A{x}
=
AX xX

aA

"


!

^ ^

_

AX xX

aA

lx,a la,x

!
wA{x},A

!


_

lx,a la,x

!#
wA,A{x}

,

aA

last step serves purpose converting CNF.
remaining problematic parts formula propositional variable index
{x}, disjunction domain criterion A. order write formula
explicitly (which need able feed SAT solver) determine
set represented A{x} also decide whether X. different
words, need explicit access elements set also able
157

fiGeist & Endriss

manipulate them. would theoretically possible hand; practically, however,
instantiation formula far large written manually. Therefore,
need computer program final conversion step, going describe
following section.
second example, consider axiom independence (IND), also
transformed fashion first using finiteness replace quantifiers,
normalising formula CNF:
(IND)

(A, B X )(x X \ (A B)) [A B {x} B {x}]
^
^


(wA,B wB,A ) wA{x},B{x}
=


A,BX

xX
x(AB)
/

^

^

A,BX

xX
x(AB)
/



wA,B wB,A wA{x},B{x} .

problematic terms x
/ (A B), {x} B {x}. But, see,
like critical terms mentioned handled program.
method translation easily extends axioms, particular
listed Appendix (Geist, 2010).
4.2 Instantiation Axioms Computer
indicated above, make use computer program order write formulas
derived explicitly. briefly discuss ideas implementation and,
particular, methods employed cater previously problematic expressions,
{x} A. Full details implementation given Geist (2010).
widely used SAT solvers work input files written according DIMACS
CNF format (DIMACS, 1993). words, format requires propositional variables represented natural numbers (starting 1, since 0 used separator)
minus (-) front negated literals. Furthermore, whole file needs
CNF; contain exactly one clause per line.
achieve formulation axioms target format, main idea fix
enumeration propositional variables (of type lx,y wA,B x, X
A, B X ) first enumerating sets elements, subsequently combining pairs
using pairing function. Functions relations like union element
defined operate numbers directly, quantifiers translated conjunctive
disjunctive iterations respective domains. all, easily readable code
used instantiate axioms.
Since numberings items consideration (here: elements, sets later
propositional variables) form core implementation, start translation process first fixing (arbitrary) numbering n elements x X, i.e., bijective
function cn : X {0, 1, . . . , n 1}.6 Kannai-Peleg Theorem six elements,
instance, codes hence range 0 5.
6. contrast propositional variables, numbering constraints elements
numbers allowed start 0.

158

fiAutomated Search Impossibility Theorems Social Choice Theory

specify corresponding numbering sets X . requires special
attention want define way treating problematic terms
(as mentioned above) easy possible. natural way looking
set characteristic function converting corresponding finite string zeros
ones natural number. allows us perform operations codes sets directly
hence straightforward instantiate formulas Appendix automatically.
needs done translating specific source code style. Quantifiers
correspond -loops elements sets, respectively, restrictions
quantification domain well operations elements sets taken care
functions operating codes sets elements directly.

5. Automated Exhaustive Theorem Search
Section 4 described generate (long) formula propositional logic representing
small instances impossibility theorems ranking sets objects. Let us denote
formula . formula describes model linear order universe
given number elements weak order satisfying given set axioms set
nonempty subsets universe. model exists, satisfying assignment (the
explicit description orders) and, thus, (complete) SAT solver discover
(assuming time memory bounds). If, conversely, model
exist exactly statement impossibility theorem unsatisfiable
and, again, SAT solver able detect (assuming, again, time
memory bounds).
universal reduction step (Corollary 1), full impossibility theorem therefore
equivalent lemma form formula unsatisfiable.
example, feeding KP (a description base case Kannai-Peleg Theorem
generated program) SAT solver zChaff (SAT Research Group, Princeton
University, 2007) returns correct result (UNSAT) 5 seconds thus
automatic verification theorem complete.
Using technique single theorems likely produce good results might
helpful tool practical perspective, more: going present
method fully automated exhaustive theorem search impossibility theorems.
theorem search will, given set axioms, systematically check subsets
inconsistent smallest domain size onwards impossibilities occur, thereby automatically identifying impossibility theorems given axioms
produce.7 sense, search method exhaustive space given axioms.
test fruitfulness approach ran search set 20 axioms
literature (Barbera et al., 2004), list describe Appendix A. search
algorithm returned total 84 impossibilities, known already (and
hence automatically verified), others immediate consequences known results,
others surprising new. search method also
run arbitrary ESG axioms field ranking sets objects, including,
instance, ones interpretation sets opportunity sets decision
7. Since practical reasons check base cases certain domain size |X| = n, could
theoretically impossibilities hidden occur larger domain sizes onwards.

159

fiGeist & Endriss

maker select favourite outcome, or, similarly, axioms case
assuming agent receives whole set alternatives (see Section 2).
remainder section, first describe method automated theorem
search list discuss impossibilities found.
5.1 Approach
search method systematically decides whether combinations given axioms compatible incompatible. therefore following refer axiom subsets problems,
particular domain size speak problem instance.
generation problem instance computer program (as described
Section 4.2) instance passed SAT solver, returns whether
possible impossible one. implemented interfaces commonly used solvers
PrecoSAT (Biere, 2010) zChaff (SAT Research Group, Princeton University, 2007).
latter provides additional layer verification generating proof trace
checked using external tools, former usually faster practice,
extra feature.
could run program possible problem instances given set
axioms maximal domain size individually collect results. Note, however,
space 20 axioms maximal domain size eight elements, already
deal total (220 1) 8 8, 400, 000 problem instances.
requires running time one second,8 whole job would take roughly 100 days.
Therefore, designed scheduler makes sure axiom subsets treated
domain sizes sensible order. order check problem instances
big effect overall running time one make use combination four
different effects:
(1) set axioms inconsistent domain size |X| = n, also inconsistent
larger domain sizes |X| > n (Corollary 1),
(2) set axioms inconsistent domain size |X| = n, also (axiom)
supersets inconsistent domain size |X| = n,
(3) set axioms consistent domain size |X| = n, also consistent
smaller domain sizes |X| < n. (Theorem 2),
(4) set axioms consistent domain size |X| = n, also (axiom) subsets
consistent domain size |X| = n.
Since larger instances require exponentially time (there exponentially
variables satisfiability problem due exponentially subsets X ), start
search smallest domain size completely solving level move
next domain size.9 new level, problems considered still
status possible condition (1) above.
8. tests, especially larger instances required much time solved average.
9. reason condition (3) helpful practice.

160

fiAutomated Search Impossibility Theorems Social Choice Theory

level, soon find impossibility, can, condition (2), mark
axiom supersets impossible current domain size (if found
impossible smaller domain size already). order use mechanism efficiently
possible, must check small axiom sets first. also dual approach starting
large axiom sets marking axiom subsets compatible soon find
possibility (condition 4), option. experiments, found best performance
achieved combining two approaches decided run search
alternating directions (switching every 15 minutes):10 large axiom sets small ones
way around.
practical point view, implementation comes limitations
able treat 21 axioms time (stack overflows occurred larger
axiom sets) domain size eight elements (due memory limits SAT
solvers). better memory management improved versions SAT solvers,
(practical) boundaries extendable further.
5.2 Results
theorem search (checking problem instances domain size eight) yields total
84 minimal impossibility theorems space 20 selected axioms. results
minimal two senses:
corresponding axiom set minimal respect set inclusion, i.e., proper
subsets compatible given domain size;
domain size minimal, i.e., smaller domain sizes given axiom set
still compatible.
Counting total number incompatible axiom sets (i.e., including supersets), find
312,432 inconsistent axiom sets one million possible combinations.
whole experiment required running time roughly one day handling
nearly 8.5 million instances.11 order externally verify many impossibilities
possible, used solver zChaff, create computer-verifiable proof trace,
instances domain size 7, switched faster solver PrecoSAT,
feature, instances (exponentially larger) domain size 8.12
Table 1 list minimal impossibilities search method able find (and
hence are) domain sizes 8. Recall that, Corollary 1,
directly correspond full impossibility results (from given domain size upwards).
results presented ascending order minimal domain size, ascending order
number axioms involved second criterion, stronger easier
grasp impossibilities higher table. axioms abbreviated names listed
Appendix A.
10. Switching every 15 minutes turned result good performance, attempted
systematically optimise parameter.
11. experiment performed Intel Xeon 2,26 GHz octo-core machine using one core
5GB available 24GB memory. machine part Dutch national compute cluster Lisa.
12. five impossibilities occurring domain size 8 onwards therefore verified
externally. Using zChaff instances (and subsequently verifying them) would also
possible, slower factor 10.

161

fiREFL

COMPL

TRANS

EXT

SDom

GF1

GF2

IND

strictIND

SUAv

SUAp

STopMon

SBotMon

topIND

botIND

disIND

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X















































X















































X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X





X





X


X






X






















X








X


X


X


X









X

X

X

X

X

X

X




X





X
X
X
X


X

X










X
X
X

X





X

X
X




X
X
X
X
X
X
X


X
X
X



X

X

X
X




X

X
X


X

X



X

X









X
X

X
X

X
X

X
X


X

X



















X

X
X
X
X
X
X


X


X


X


X
X

X

X



















X



X


X
X
X



X
X
X



X


X
X
X
X
X
X


X
X




X
X
X
X



X









X
X
X



X
X
X

X
X






X
X


X
X
X
X




X








X






X
X
X






X
X
X
X




X
X




X
X










X










X
X
X













X
X
X
X

































X
X
X
X
X
X
X
X


X
X


X


























X

X
X
X
X
X
X
X
X
X
X


X
X
X




X
X
X
X
X












X
X
X
X
X
X
X X








X
X
X
X
X
X
X
Continued. . .

Table 1: Results automated exhaustive theorem search
space 20 axioms (including orders).

162

MC

LIN

3
3
3
3
3
3
3
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4
4

evenExt

Size

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42

intIND

No.

Geist & Endriss

fiNo.

Size

LIN

REFL

COMPL

TRANS

EXT

SDom

GF1

GF2

IND

strictIND

SUAv

SUAp

STopMon

SBotMon

topIND

botIND

disIND

intIND

evenExt

MC

Automated Search Impossibility Theorems Social Choice Theory

43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84

4
5
5
5
5
5
5
5
5
5
5
5
5
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
7
7
8
8
8
8
8

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X





















































X




X
X
X
X
X






X

X
X
X
X
X
X
X
X


X
X
X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X



























































X
X
X


X


X



X
X
X



X
X




X
X



X
X


X


X


X
X

X

X

X
X
X
X
X





X


X

X

X

X
X
X



X


X
X

X
X






X
X


X
X


X
X
X
X
X
X


X
X
X



X
X
X

X
X


X

X










X
X
X
X







X



















X

X




X
X


X






























X
X


X


X
X
X
X
X
X





X
X
X













X







X


X
X

X
X














X
X
X

X









X





















X

X



X



X

X

X
X

X

X





X
X











X





X
X






X



X
X



X
X




X








X
X

X









X



X
X
X

X
X
X
X
X





X

X

X
X

X




X
X
X



X






X
X
X
X





X
X
X
X
X
X
X
X
X

X

X



X






X
X



X


















X
X
X
X


X
X
X
X
X




















X
X
X
X
X
X

X








X
X
X
X
X
X
X












































X








X
X
X
X
X











X
X



X
X
X
X
X






X

Table 1: Results automated exhaustive theorem search
space 20 axioms (including orders).

163

fiGeist & Endriss

Observing results, first note impossibilities occur
tested domain sizes larger 2 onwards. novel right since
impossibilities |X| k, k {3, 4, 6} known.
results differ much level appeal interestingness.
find impossibilities least five (potentially overlapping) categories, namely known
results, variations known results, direct consequences results, straightforward
results, and, importantly, new results.
previously known results easily recognise among ones list:
Kannai-Peleg Theorem corresponds Impossibility No. 57; impossibility theorem
Barbera Pattanaik (1984) found Impossibility No. 1.
aware one known impossibility interpretation complete
uncertainty, could unfortunately encode framework since uses
axiom neutrality (see Section 3.1). variant Kannai-Peleg Theorem presented
Barbera et al. (2004), number elements lowered four
adding aforementioned axiom.
Variations known results also easy spot keeping axioms fixed
browsing results involving these. Impossibilities No. 80 No. 10, instance,
variations Kannai-Peleg Theorem, former weakening axioms
makes impossibility occur larger domain size. latter variation
direction: additional axiom (SUAv) causes impossibility domain size 4
elements already. many variations known theorems found (e.g.,
No. 33, 37, 40, etc.).
used set axioms certain axioms imply others, expect
results direct consequences others. particular, every result involving
(weak) form independence also occur standard strict independence
only, similarly simple dominance, weaker form Gardenfors principle.
Examples results Impossibilities No. 3 (implied No. 1) Impossibility
No. 9 (implied No. 28).
Straightforward results could find one: Impossibility No. 2 says binary
relation cannot fulfill (SUAv) (SUAp), reflect contradictory principles
uncertainty aversion uncertainty appeal. immediate (especially examining
exact statement axioms).
left new, i.e., previously unknown, results. quite
them, differ interesting are. instance,
reasonable postulate (GF1) (GF2), makes new Impossibility No. 11
fascinating all. also find results like Impossibilities No. 52 No. 56,
combination axioms appears reasonable yet leads impossibility.
return results below. let us moment shift
perspective problems, i.e., combinations axioms, special role individual

axioms respect results. one hand, axiom (LIN ) linear order
X occurs impossibilities. means impossibility without axiom
(on given axiom space domain size 8). could anticipated:
axioms say anything
use empty relation X ,
anymore hence cannot incompatible. Also note impossibility without
form independence (straightforward) Impossibility No. 2. hand,
164

fiAutomated Search Impossibility Theorems Social Choice Theory

axioms (evenExt) (REFL ) occur impossibility. Therefore,
conclude must particularly well-compatible axioms. put
differently, adding given set axioms cause impossibility.
axiom (intIND) intermediate independence contained discovered impossibilities
domain sizes 7 8 (and cause impossibilities sizes 5 below).
axiom involved somewhat larger instances makes great deal sense intuitively:
application axiom add two elements (one above, one
set apply to), expected larger domain sizes necessary
contradiction.
following discuss obtained impossibilities also provide
example manual proof. able quickly construct manual proofs
theorems discussed underpins usefulness theorem search heuristic,
even sceptic may willing accept output SAT solver rigorous
proof.13 Knowing impossible axiom sets critical domain sizes beforehand simplified
construction manual proofs significantly. Additionally, one run search
program slightly modified axioms, get even better understanding
borderline lies possible impossible, also
assistance choosing right steps proving results hand.
even one application program searching manual proof: one run
instances single axioms left inspect orders satisfying remaining
axioms order understand structural properties imply.
5.2.1 Unintuitive Impossibility
Let us start striking result. Theorem 3 important paper Bossert
et al. (2000) states axioms (SDom), (IND), (SUAv) (STopMon) characterise
so-called min-max ordering, defined


max(B) .
min(B) min(A) = min(B) max(A)
mnx B min(A) >
theorem also covers dual result max-min ordering (characterized
axioms (SDom), (IND), (SUAp), (SBotMon)).
reader check contradicts results theorem search since
axiom sets among impossibility theorems Table 1 (Impossibilities
No. 16 19). Indeed, turns proofs Bossert et al. (2000) flawed
Arlegi (2003) pointed three years later. Arlegi, however, notes minmax max-min orderings satisfy axiom independence (IND), i.e.,
orders cannot characterized axioms (SDom), (IND), (SUAv), (STopMon), (SDom),
(IND), (SUAp), (SBotMon), respectively. shows unintuitiveness findings (as
contrary believed time), yield counterexample
original publication: additionally get four axioms consideration
inconsistent (in presence transitivity) hence transitive binary relation
whatsoever satisfy them. give manual proof result.
13. included one example manual proof here. complete set given Geist (2010).

165

fiGeist & Endriss

Theorem 3 (Impossibility No. 16). Let X linearly ordered set |X| 4.
exists transitive binary relation X satisfying simple dominance (SDom), independence (IND), simple uncertainty aversion (SUAv), simple top monotonicity (STopMon).

Proof. Let xi , {1, 2, 3, 4} denote four distinct elements X ordered >
x4 . way contradiction, suppose
x3 >
x2 >
respect index, i.e., x1 >
exists transitive binary relation X satisfying simple dominance (SDom), independence
(IND), simple uncertainty aversion (SUAv), simple top monotonicity (STopMon).
x3
x2 >
one hand, follows simple uncertainty aversion applied x1 >
{x2 } {x1 , x3 }, adding x4 sets yields (by independence):
{x2 , x4 } {x1 , x3 , x4 }.

(5)

x4 ) show {x3 , x4 }
hand, use simple dominance (applied x3 >
{x4 },
{x1 , x3 , x4 } {x1 , x4 }
(6)
x2 >
x4
follows independence. Furthermore, simple top monotonicity applied x1 >
directly gives {x1 , x4 } {x2 , x4 }, able combine (6) transitivity.
thus obtain
{x1 , x3 , x4 } {x2 , x4 },
directly contradicts (5).
Note four axioms used proof above, necessary
result also logically independent following automatically
x2 >
x3 >
x4 ):
constructed examples weak orders show (let X = {x1 , x2 , x3 , x4 } x1 >
1. weak order given
{x1 } {x2 } {x3 } {x4 } {x1 , x2 } {x1 , x3 } {x2 , x3 } {x1 , x4 } {x2 , x4 }
{x3 , x4 } {x1 , x2 , x3 } {x1 , x2 , x4 } {x1 , x3 , x4 } {x2 , x3 , x4 } {x1 , x2 , x3 , x4 }
satisfies (IND), (SUAv), (STopMon), (SDom).
2. weak order given
{x1 } {x1 , x2 } {x2 } {x1 , x3 } {x2 , x3 } {x3 } {x1 , x2 , x3 } {x1 , x4 }
{x2 , x4 } {x1 , x2 , x4 } {x3 , x4 } {x4 } {x1 , x3 , x4 } {x2 , x3 , x4 } {x1 , x2 , x3 , x4 }
satisfies (SDom), (SUAv), (STopMon), (IND).
3. weak order given
{x1 } {x1 , x2 } {x1 , x3 } {x1 , x2 , x3 } {x2 } {x2 , x3 } {x3 } {x1 , x4 }
{x1 , x2 , x4 } {x1 , x3 , x4 } {x1 , x2 , x3 , x4 } {x2 , x4 } {x2 , x3 , x4 } {x3 , x4 } {x4 }
satisfies (SDom), (IND), (STopMon), (SUAv).
4. weak order given
{x1 } {x1 , x2 } {x2 } {x1 , x3 } {x1 , x2 , x3 } {x2 , x3 } {x3 } {x1 , x4 }
{x1 , x3 , x4 } {x2 , x4 } {x1 , x2 , x4 } {x2 , x3 , x4 } {x1 , x2 , x3 , x4 } {x3 , x4 } {x4 }
satisfies (SDom), (IND), (SUAv), (STopMon).
166

fiAutomated Search Impossibility Theorems Social Choice Theory

also seen subset four axioms suffices characterise
min-max ordering. subset containing (IND) rejected immediately since (IND)
violated min-max ordering (as noted earlier), subset containing
cannot suffice characterisation either, since example 2 differs min-max
ordering mnx (in {x2 , x3 , x4 } mnx {x1 , x2 , x3 , x4 }).
Finally, emphasise fact neither reflexivity completeness used
proof Theorem 3 (as also indicated Table 1). Thus, impossibility already
holds arbitrary transitive binary relations instead weak orders.
5.2.2 Variations Kannai-Peleg Theorem
Impossibility No. 9 offers interesting variation Kannai-Peleg Theorem trades
additional axiom (simple uncertainty aversion) impossibility occurring domain size 4 rather 6 elements.
Theorem 4 (Impossibility No. 9). Let X linearly ordered set |X| 4.
exists transitive binary relation X satisfying Gardenfors principle (GF),
independence (IND) simple uncertainty aversion (SUAv).
impossibility result also holds simple uncertainty appeal (SUAp) place
simple uncertainty aversion (SUAv); Impossibility No. 12.
even closer look Table 1, see even
stronger form Theorem 4: Impossibility No. 28 corresponds axioms (GF),
(SUAv), (botIND), (topIND) impossible domain size 4 on. contrast (IND),
axioms (botIND) (topIND) allow principle independence certain situations
only: element added ranked elements sets,
respectively.14 Therefore, immediately following stronger version Theorem 4.
Theorem 5 (Impossibility No. 28). Let X linearly ordered set |X| 4.
exists transitive binary relation X satisfying Gardenfors principle (GF), bottom
(botIND) well top independence (topIND), simple uncertainty aversion (SUAv).
interesting insight obtained comparing Impossibility No. 48
previous result. shows us drop second Gardenfors axiom add
one element domain, i.e., |X| 5. exact result following:
Theorem 6 (Impossibility No. 48). Let X linearly ordered set |X| 5.
exists transitive binary relation X satisfying first axiom Gardenfors
principle (GF1), bottom (botIND) well top independence (topIND), simple uncertainty aversion (SUAv).
Alternatively, could replaced (botIND) (disIND) (No. 51), (topIND)
(intIND), then, however, requiring least seven elements domain (No. 78).
Two variants Kannai-Peleg Theorem found Impossibilities No. 80
81, considered strengthenings original theorem contain
weaker versions independence only. strengthening, however, comes cost
14. Actually, already original proof Kannai-Peleg Theorem (Kannai & Peleg, 1984)
weaker forms (IND) used (cf. also Impossibility No. 61).

167

fiGeist & Endriss

impossibility starting domain size eight elements instead six. form
independence remains combination intermediate, disjoint, bottom top
independence, respectively, (even together) weaker standard independence.
5.2.3 Impossibilities without Dominance
existing impossibilities literature aware involve Gardenfors principle
(GF) least simple dominance (SDom). let us consider kinds results
obtain without dominance principle.
striking impossibility without principle dominance i.e., without either (GF)
(SDom) Impossibility No. 52: axioms strict independence (strictIND), simple uncertainty aversion (SUAv), monotone consistency (MC) incompatible
presence completeness transitivity domain size 5 on.
Theorem 7 (Impossibility No. 52). Let X linearly ordered set |X| 5.
exists weak order X satisfying strict independence (strictIND), simple uncertainty
aversion (SUAv) monotone consistency (MC).
One might tempted think impossibility mostly due problems
(SUAv) (MC) since seem express contrary ideas: whereas (SUAv) favours small sets
large ones, (MC) tells us unions two sets preferred least one
sets. actually even characterisation result min-max ordering Arlegi
(2003) involving axioms (SUAv) (MC), demonstrating natural ordering
fulfils two axioms. Therefore, see considered
unreasonable axioms act together.
found quite variants impossibility. According results,
completeness could replaced simple bottom monotonicity (Impossibility No. 53)
even dropped price one element domain (Impossibility
No. 56). Alternatively, one weaken strict independence either bottom disjoint
independence shrink domain one element, price adding axiom
simple top monotonicity (Impossibilities No. 26 27, respectively). seemingly
variant obtained trading axiom extension (EXT) smaller domain.
is, however, direct consequence Impossibilities No. 26 27, respectively, since (EXT)
(strictIND) together imply (STopMon).
Since strict independence considered relatively strong axiom, Impossibility
No. 26 (and corresponding No. 27) worth emphasising well, postulate
weak form independence.
Theorem 8 (Impossibility No. 26). Let X linearly ordered set |X| 4.
exists transitive binary relation X satisfying bottom independence (botIND),
simple uncertainty aversion (SUAv), simple top monotonicity (STopMon) monotone consistency (MC).
result comes quite surprise since Arlegi (2003) characterises min-max
ordering axiom set including (SUAv), (STopMon), (MC) (as well two
axioms). follows adding tiny bit independence three axioms turns
possibility general impossibility.
168

fiAutomated Search Impossibility Theorems Social Choice Theory

6. Conclusion
presented method automatically verifying discovering theorems
subarea economic theory concerned problem formulating principles lifting
preferences individual objects preferences nonempty sets objects.
theorems question impossibility theorems establish certain combinations
principles (called axioms) inconsistent. method three components:
general result, universal reduction step (a corollary Preservation Theorem), shows combination axioms, meeting certain conditions,
inconsistent fixed domain size n, also inconsistent domain
n objects. conditions axioms applicability result
purely syntactic: axiom (equivalent to) existentially set-guarded (ESG)
sentence many-sorted logic set preferences (MSLSP) qualifies.
method translating axioms propositional formulas CNF, method
instantiating axioms computer fixed domain size. allows us
verify small instances impossibility theorem using SAT solver. Together
universal reduction step, constitutes proof respective impossibility theorem also larger domain sizes.
scheduling algorithm search large space axiom combinations different
domain sizes. This, finally, allows us systematically search discover new
impossibility theorems.
applied method set 20 axioms proposed
literature means formalising various principles ranking sets objects
sets interpreted representing mutually exclusive alternatives object
selected manner cannot influenced decision maker (so-called complete
uncertainty). yield total 84 (minimal) impossibility theorems, including
known results new theorems. commented interesting
previous section. results clearly demonstrate power method.
work extended number ways. First, method applied
sets axioms (including axioms order types linear weak orders).
Implementing axioms done quickly, long covered
universal reduction step, results read short computation. Especially
opportunity sets, knowledge impossibility results known,
potential success high.
Second, method implementation refined further. would
attractive integrate parser read language MSLSP axioms
longer transformed coded hand. idea implement
dependencies axioms. would make sure absolutely minimal
results returned, whereas results trivial consequences others
(since axioms immediately implied others).
Third, case particular combination axioms lead impossibility,
may possible use output SAT solver infer useful information
class set preference orderings satisfying axioms. preliminary steps
direction already taken (Geist, 2010).
169

fiGeist & Endriss

Finally, tentative suggestion, would interesting explore
extent method adapted different disciplines problem domains.
starting point might Preservation Theorem, potentially still strengthened larger class axioms. One could try find exact borderline lies
formulas preserved certain substructures not.
arbitrary first-order models done famous Los-Tarski Theorem,
class structures set preferences still open question.

Acknowledgments
would like thank Umberto Grandi three anonymous JAIR reviewers host
helpful comments suggestions earlier versions paper.

Appendix A. List Axioms
appendix provide complete list axioms used theorem search
presented Section 5. axioms (or variations thereof) references
found survey Barbera et al. (2004).
first axioms given order axioms. one, axioms describ X, another, ones describing weak order X = 2X \{}.
ing linear order
former denoted (LIN ), whereas latter split three
components reflexivity (REFL ), completeness (COMPL ) transitivity (TRANS ),
treated separate axioms order investigate parts actually necessary
impossibilities. axioms intuitive form are:
(LIN )

(REFL )

x x X
x
yx
x 6= X
x
yy
zx
z x, y, z X
x
yy
x x = x, X
x
X

(reflexivity)
(completeness)
(transitivity)
(antisymmetry)
(reflexivity)

(COMPL )

B B 6= B X

(TRANS )

B B C C A, B, C X

(completeness)
(transitivity)

Next axiom extension, natural requirement thus also
implied axioms (e.g., Gardenfors principle):
(EXT)

{x} {y} x, X
x

set axioms included search one dealing concept
dominance, i.e., idea adding object x set objects dominated
(or dominating) object x produces better (or worse) set, respectively. chose
well-known Gardenfors principle (GF), introduced Section 2.2 already,
170

fiAutomated Search Impossibility Theorems Social Choice Theory

well weaker version Barbera (1977) called simple dominance (SDom), restricts
(GF) small sets:
(GF1)
(GF2)
(SDom)

a) {x} x X X
((a A)x >
a) {x} x X X
((a A)x <
({x} {x, y} {x, y} {y}) x, X
x>

Independence axioms also commonly postulated especially weaker variants
versions thereof, like bottom, top, disjoint intermediate independence, frequently
play role characterisation results (e.g., see Pattanaik & Peleg, 1984; Nitzan & Pattanaik, 1984). decided include standard independence (as already introduced
Section 2.2), stronger version (strictIND), implies strict preferences,
weaker versions, viz. bottom (botIND), top (topIND), disjoint (disIND) intermediate
independence (intIND), apply certain combinations sets elements.
(IND)

B {x} B {x} A, B X x X \ (A B)

(strictIND)

B {x} B {x} A, B X x X \ (A B)

(botIND)

B {x} B {x} A, B X
x B
x X \ (A B) >

(topIND)

B {x} B {x} A, B X
B
x X \ (A B) x >

(disIND)

B {x} B {x} A, B X ,
B = , x X \ (A B)

(intIND)

B {x, y} B {x, y} A, B X x, X \ (A B)
z z >
z B
x >

Bossert (1997) introduced axioms describing attitude decision maker towards
uncertainty. formalise weakenings axioms apply small sets only, since
sufficient characterisation results like Arlegi (2003). Uncertainty
aversion postulates decision maker will, alternative x, (strictly) prefer
alternative set containing better worse alternative. Uncertainty appeal,
hand, says ranking way around: set
better worse element (strictly) preferred single element x.
(SUAv)
(SUAp)

yy
(x >
yy
(x >

z) {y} {x, z} x, y, z X
>
z) {x, z} {y} x, y, z X
>

Arlegi (2003) also uses two monotonicity axioms, called simple top bottom monotonicity. underlying idea simple: given two alternatives, better get better
one two together third element (instead worse one
third element). two variants axiom apply alternatives
ranked higher (top) third alternative, ranked lower (bottom), respectively.
(STopMon)
(SBotMon)

{x, z} {y, z} x, y, z X x >
z >
z
x>
z {x, y} {x, z} x, y, z X x >
x >
z
y>
171

fiGeist & Endriss

rather odd axiom principle even-numbered extension equivalence. says
that, sets even number elements, decision maker indifferent
whether set added two distinct singleton sets, also
indifferent whether added union two singleton sets. Even though
lacks intuitive support, axiom useful (together principles)
characterises median-based ordering proposed Nitzan Pattanaik (1984).
(evenExt)

(A {x} {x} {y} {y}) {x, y} {x, y}
X , |A| even, x, X \

final axiom list monotone consistency (MC), put forward
Arlegi (2003) characterise (in connection axioms) min-max ordering (see
also Section 5.2). (MC) expresses set objects least good another
set B, union two least good latter. implies
complete binary relations equivalent potentially worse set B strictly
better union two. Intuitively, means adding alternatives
(weakly preferred) set set B, decision maker maintains alternatives
B plus ones contained A, weakly preferred B. Thus,
process produce set strictly worse B.
(MC)

B B B A, B X

Although (MC) appears similar first axiom Gardenfors principle,
fact quite different since dictate existence strict preferences.

References
Agotnes, T., van der Hoek, W., & Wooldridge, M. (2010). logic preference
judgment aggregation. Journal Autonomous Agents Multiagent Systems. (In
press)
Arlegi, R. (2003). note Bossert, Pattanaik Xus Choice complete uncertainty: axiomatic characterization decision rules. Economic Theory, 22 (1),
219225.
Arrow, K. J. (1963). Social choice individual values. Yale University Press, New Haven.
Cowles Foundation Monograph 12.
Barbera, S. (1977). manipulation social choice mechanisms leave
much chance. Econometrica, 45 (7), 15731588.
Barbera, S., Bossert, W., & Pattanaik, P. K. (2004). Ranking sets objects. S. Barbera,
P. J. Hammond, & C. Seidl (Eds.), Handbook utility theory (Vol. II: Extensions,
pp. 893977). Kluwer Academic Publishers, Dordrecht.
Barbera, S., & Pattanaik, P. K. (1984). Extending order set power set:
remarks Kannai Pelegs approach. Journal Economic Theory, 32 (1),
185191.
Ben Larbi, R., Konieczny, S., & Marquis, P. (2010). characterization optimality criteria
decision making complete ignorance. Proceedings 12th International
Conference Principles Knowledge Representation Reasoning (KR-2010).
AAAI Press.
172

fiAutomated Search Impossibility Theorems Social Choice Theory

Biere, A. (2010). PrecoSAT. Available http://fmv.jku.at/precosat/.
Bossert, W. (1997). Uncertainty aversion nonprobabilistic decision models. Mathematical
Social Sciences, 34 (3), 191203.
Bossert, W., Pattanaik, P. K., & Xu, Y. (2000). Choice complete uncertainty:
Axiomatic characterizations decision rules. Economic Theory, 16 (2), 295
312.
Chevaleyre, Y., Endriss, U., Lang, J., & Maudet, N. (2007). short introduction
computational social choice. Proceedings 33rd Conference Current Trends
Theory Practice Computer Science (SOFSEM-2007) (pp. 5169). SpringerVerlag.
DIMACS. (1993). DIMACS satisfiability suggested format. Available ftp://
dimacs.rutgers.edu/pub/challenge/satisfiability/doc/satformat.dvi. Center Discrete Mathematics & Theoretical Computer Science.
Duggan, J., & Schwartz, T. (2000). Strategic manipulation without resoluteness shared
beliefs: Gibbard-Satterthwaite generalized. Social Choice Welfare, 17 (1), 8593.
Enderton, H. B. (1972). mathematical introduction logic. Academic Press.
Fishburn, P. C. (1972). Even-chance lotteries social choice theory. Theory Decision,
3 (1), 1840.
Gaertner, W. (2009). primer social choice theory: Revised edition. Oxford University
Press, USA.
Gardenfors, P. (1976). Manipulation social choice functions. Journal Economic
Theory, 13 (2), 217228.
Gardenfors, P. (1979). definitions manipulation social choice functions. J. J. Laffont (Ed.), Aggregation revelation preferences (pp. 2936). North-Holland.
Geist, C. (2010). Automated search impossibility theorems choice theory: Ranking sets
objects. M.Sc. thesis. Institute Logic, Language Computation. University
Amsterdam.
Grandi, U., & Endriss, U. (2009). First-order logic formalisation Arrows Theorem.
Proceedings 2nd International Workshop Logic, Rationality Interaction
(LORI-2009) (pp. 133146). Springer-Verlag.
Gravel, N., Marchant, T., & Sen, A. (2008). Ranking completely uncertain decisions
uniform expected utility criterion. Presented 3rd World Congress Game
Theory Society, Evanston, IL.
Hodges, W. (1997). shorter model theory. Cambridge University Press.
Kannai, Y., & Peleg, B. (1984). note extension order set power
set. Journal Economic Theory, 32 (1), 172175.
Lin, F. (2007). Finitely-verifiable classes sentences. Presented 8th International
Symposium Logical Formalizations Commonsense Reasoning, Stanford, CA.
Manzano, M. (1996). Extensions first-order logic. Cambridge University Press.
Nipkow, T. (2009). Social choice theory HOL. Journal Automated Reasoning, 43 (3),
289304.
Nitzan, S. I., & Pattanaik, P. K. (1984). Median-based extensions ordering
set power set: axiomatic characterization. Journal Economic Theory,
34 (2), 252261.
173

fiGeist & Endriss

Packard, D. J. (1979). Preference relations. Journal Mathematical Psychology, 19 (3),
295306.
Pattanaik, P. K., & Peleg, B. (1984). axiomatic characterization lexicographic
maximin extension ordering set power set. Social Choice
Welfare, 1 (2), 113122.
Puppe, C. (1995). Freedom choice rational decisions. Social Choice Welfare,
12 (2), 137153.
SAT Research Group, Princeton University. (2007). zChaff. Available http://
www.princeton.edu/chaff/zchaff.html.
Sen, A. (1991). Welfare, preference freedom. Journal Econometrics, 50 (1-2), 1529.
Sloane, N. J. A. (Ed.). (2010). on-line encyclopedia integer sequences (OEIS).
Published electronically http://www.research.att.com/njas/sequences/.
Tang, P. (2010). Computer-aided theorem discovery new adventure application
economic theory. Ph.D. thesis. Hong Kong University Science Technology.
Tang, P., & Lin, F. (2009). Computer-aided proofs Arrows impossibility
theorems. Artificial Intelligence, 173 (11), 10411053.
Taylor, A. D. (2002). manipulability voting systems. American Mathematical
Monthly, 109 (4), 321337.
Wiedijk, F. (2007). Arrows Impossibility Theorem. Formalized Mathematics, 15 (4), 171
174.

174

fiJournal Artificial Intelligence Research 40 (2011) 375413

Submitted 06/10; published 02/11

Evaluating Temporal Graphs Built Texts via Transitive Reduction
Xavier Tannier

XTANNIER @ LIMSI . FR

LIMSI-CNRS Univ. Paris-Sud
B.P. 133
91403 ORSAY Cedex, France

Philippe Muller

MULLER @ IRIT. FR

ALPAGE-INRIA Toulouse University
IRIT, Univ. Paul Sabatier
118 Route de Narbonne
F-31062 Toulouse Cedex 04, France

Abstract
Temporal information focus recent attention information extraction, leading
standardization effort, particular task relating events text. task raises
problem comparing two annotations given text, relations events story
intrinsically interdependent cannot evaluated separately. proper evaluation measure
also crucial context machine learning approach problem. Finding common
comparison referent text level obvious, argue favor shift eventbased measures measures unique textual object, minimal underlying temporal graph,
formally transitive reduction graph relations event boundaries. support
investigation properties synthetic data well-know temporal corpus.

1. Introduction
Temporal processing texts somewhat recent field methodological point view, even
though temporal semantics long tradition, dating back least 1940s (Reichenbach, 1947).
theoretical formal linguistic approaches temporal interpretation discourse level
active late 1980s early 1990s (Kamp & Reyle, 1993; Asher & Lascarides,
1993; Steedman, 1995; Webber, 1988), empirical approaches less frequent, natural
language processing systems evaluated beyond instances (Grover, Hitzeman, & Moens,
1995; Kameyama, Passonneau, & Poesio, 1993; Passonneau, 1988; Song & Cohen, 1991).
Temporal information essential interpretation text thus crucial applications
summarization information extraction, received growing attention 2000s (Mani,
Pustejovsky, & Gaizauskas, 2005) lead standardization effort TimeML
initiative (Saur, Littman, Knippen, Gaizauskas, Setzer, & Pustejovsky, 2006). address central part task, namely evaluating extraction network temporal relations
events described text. Since temporal information easily broken local bits information, many equivalent ways express ordering events. Human annotation
thus notoriously difficult (Setzer, Gaizauskas, & Hepple, 2006) comparisons annotations cannot rely simple precision/recall-type measures. given practice nowadays
compute sort transitive closure network/graph constraints temporal events
(usually expressed well-known Allen algebra (Allen, 1983), sub-algebra), either
compare sets simple temporal relations deduced standard precision
recall, measure agreement relations, including disjunctions information (Verhagen, Gaizauskas, Schilder, Hepple, Katz, & Pustejovsky, 2007). reasoning model also used
c
2011
AI Access Foundation. rights reserved.

fiTANNIER & ULLER



X

X




X
meets


starts

X


overlaps X



X
equals

X
finishes





Figure 1: Allen relations. relation r inverse relation ri.
help build representations temporal situations imposing global constraints top local
decision problems (Chambers & Jurafsky, 2008a; Tatu & Srikanth, 2008; Bramsen, Deshpande, Lee,
& Barzilay, 2006).
take different route here, extracting single referent graph, minimal graph constraints. number ways argue basing graph relations
event boundaries. aim accomplish two things so: find graph
easy compute, eliminate bias introduced measures take account
combinatorial aspect agreement transitive closure graphs.
next section presents detail usual way comparing annotation graphs
temporal entities extracted text, problems raises. argue comparing event
boundaries instead events define two new metrics apply type information.
focus convex relations, tractable sub-algebra Allen relations covers human annotations.
Finally, present empirical study behavior measures generated data
TimeBank Corpus (Pustejovsky, Hanks, Saur, See, Gaizauskas, Setzer, Radev, Sundheim, Day,
Ferro, & Lazo, 2003) support claim practicality methodology.

2. Comparing Temporal Constraint Networks
Work temporal annotation texts strongly relies Allens interval algebra. Allen represents
time events intervals, states 13 basic relations hold intervals (see
Figure 1 Table 1), considering every possible ordering interval endpoints. binary
relations, existing amongst intervals collection (in case, corresponding temporal entities
text), define graph nodes intervals edges labelled set
relations may hold pair nodes. relations mutually exclusive. TimeML
specification linguistic temporal annotation uses Allen relations different names,
projects either use subset groupings relations (see below).
interested paper evaluating systems annotating texts temporal relations holding
events temporal expressions events. example, consider following text,
extracted TimeBank corpus:

376

fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION

Relation
bJ
mJ
oJ
sJ
dJ
IfJ
= J

Meaning
J
meets J
overlaps J
starts J
J
finishes J
equals J

Endpoint relations
I2 < J1
I2 = J1
(I1 < J1 ) (I2 < J2 ) (J1 < I2 )
(I1 = J1 ) (I2 < J2 )
(J1 < I1 ) (I2 < J2 )
(J1 < I1 ) (I2 = J2 )
(I1 = J1 ) (I2 = J2 )

Inverse relation
bi
mi
oi
si
di
fi

Table 1: Allen relations. relation r inverse relation ri. interval starts I1 ends
I2 .

(1)

wasnt twenty years first astronauts chosene1 NASA finally includede2 six women, scientists, pilots. woman actually
charge missione3 nowt1 .

correct annotation temporal relations could given graph shown Figure 2.
relations could explicited, i.e. e1 bt1 , complete evaluation could consider possible edges.

chosen_e1

b

included_e2

b
fi

now_t1

charge mission_e3

Figure 2: Example annotation example 1.
Precision recall evaluations often performed graphs relations events
text however, subproblem ordering pairs successively described events (Mani &
Schiffman, 2005; Verhagen et al., 2007) even same-sentence events (Lapata & Lascarides, 2006)
(in example, e1 b e2 e3 f t1 1 ). main reason choice difficulty task,
even human beings, assigning temporal relations large text (Setzer et al., 2006). Another
issue evaluation full temporal graphs open question. discussed
section, metrics traditionally used task, namely recall precision metrics (either strict
relaxed), raise specific problems still addressed.
detail important notions concerning temporal networks comparison networks. example relations given section expressed terms Allen algebra, whose
set relations abbreviations recalled Table 1. Here, use classical symbols <
> order temporal points.
2.1 Temporal Closure
Temporal closure inferential closure mechanism consists composing known pairs temporal relations order obtain new relations, fixed point. E.g.: b B C B,
1. Exceptions exist, work Mani et al. (2006) Mani et al. (2007).

377

fiTANNIER & ULLER

%
b
bi

di

b
b

b
{b, o, m, di, fi}

bi

bi
bi
{bi, oi, di, mi, si}


{b, o, m, d, }
{bi, oi, mi, d, f}

{o, oi, d, s, f, di, si, fi, =}

di
b
bi

di

Table 2: Composition Allen relations.
b C; operation lead disjunction relations, example b B B C
b C C C C C. also noted A{b, o, m, d, s}C.
consider generalized relations, i.e. set R disjunctions basic temporal relations,
seen set base relations, set union intersection composition relations
define algebra R (the algebra subsets set Allen relations). Composition
relations operation generalizes inferences basic relations sets relations. Taking
previous example, B B C, = {t1 , t2 , ...tk } = {s1 , s2 , ...sm }, ti ,
si base relations:
[
= {t1 , t2 , ...tk } {s1 , s2 , ...sm } = (ti sj )
i,j

composition relations computed 13x13 compositions base relations.
table composition rules Allen algebra found work Allen (1983) Rodriguez et al. (2004), sample basic relations given Table 2. new relations
express new intrinsic constraints, make temporal situation explicit. also
make information precise, disjunctions inferred edge intersected
combine inferences different compositions.
constraint propagation algorithm ensures existing temporal relations added
network, labelling inconsistency (Allen, 1983). path-consistency algorithm sound,
complete, detect cases inconsistency. See simple version presented
Algorithm 1. efficient versions also developed (Vilain, Kautz, & van Beek, 1990),
put use experiments, main focus here.
desirable compare temporal graphs without performing temporal closure them.
Indeed, several ways encode temporal information graph, shown
(very simple) example Figure 3. Closure seen computationally simple way expliciting
temporal information annotation, allowing precise comparisons. temporal
closure also produces redundant information, lead evaluation issues, explained
Section 2.4.
paper, call G temporal closure (also called saturated graph) graph G.
=


<

B
<

C

=





<

B
<

C

=





<

B
<

C

Figure 3: Three identical annotations. last one result temporal closure.

378

fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION

Algorithm 1 Temporal closure
Let U = disjunction 13 Allen relations,
Rm,n = current relation nodes n
procedure CLOSURE(G)
A=G.edges()
N=G.vertices()
changed = True
changed
changed = False
pairs nodes (i, j) N N
k N ((i, k) (k, j) A)
. composition via k
R1i,j = (Ri,k Rk,j )
. find info (i,j)
edge (a relation R2i,j ) existed j R2i,j = U
end
Ri,j = R1i,j R2i,j
. intersect new already known
Ri,j = error
. inconsistency detected
else Ri,j = U nothing
. new information
else
update edge (i,j)
changed = True
end
end
end
end
end procedure

379

fiTANNIER & ULLER

A1

<

A2
<

=

=

C1

<

C2

<
B1

<

B2

Figure 4: Endpoint graph (same temporal information Figure 3).
2.2 Time Point Algebra Convex Relations
Interval graphs converted easily graphs points (Vilain et al., 1990), event
split beginning ending point; mapping Allen relations point relations
given Table 1. leads smaller set simple relations: equality (=) precedence
(< >), simpler algebra, 7 consistent sets ({<},{<, =},{=},{<, =, >},{>},{>=
}, {<, >} set denotes disjunction relations). point algebra obtained four
relations r1 ... r4 hold endpoints two intervals J started Ib Jb
ended Ie Je respectively. four relations Ib r1 Jb , Ie r2 Je , Ib r3 Je Ie r4 Jb .
Converting Allen graph endpoint graph thus straightforward. Figure 4 shows point
graph equivalent interval graph Figure 3.
interval algebra, pairs point relations combined temporal closure
computed way. relation two time points continuous assigned
set simple relations convex (Vilain et al., 1990).
so-called convex relation corresponds cases relations r1 r4 assigned one
6 possible relations {<}, {<, =}, {=}, {<, =, >}, {>}, {>=}2 , considered conceptual neighbors (Freksa, 1992). Using relations endpoints restricts interval relations sets
Allen relations conceptual neighbors. means encode relations may
vague intervals endpoints convex subsets time-line. Figure 5
shows Allen relations conceptual neighbors. Another useful way seeing conceptual neighbors considering continuous transformations interval endpoints time-line:
relation r holds two intervals I1 I2 , moving continuously endpoints
change relation conceptual neighbor r. instance, conceptual transformation
cannot change situation I1 starts I2 situation I1 < I2 without going (at
least) intermediary situations I1 overlaps I2 I1 meets I2 .
Finally, instead 213 possible disjunctive relations Allen algebra, set corresponding
interval convex relations reduced 82. corresponding sub-algebra tractable, problem satisfiability set constraints sound complete polynomial time algorithm3 .
Moreover, ensure uniqueness minimal graphs, defined described
paper.
important note temporal graph built annotated text contains convex
relations, since graph generated finite set base relations (annotators allowed
2. 7 relations described above, except {<, >}, also noted 6=. 6 relations form sub-algebra: compositions
disjunctions relations disjunctions relations.
3. See work Schilder (1997) complete presentation within natural language processing perspective.

380

fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION







<



f

oi

eq

fi

di

mi

>

si

Figure 5: Temporal relations conceptual neighbors
use disjunctions), since set convex relations stable composition thus forms
sub-algebra.
2.3 Strict Relaxed Recall Precision
general case, humans systems may assign disjunctions atomic relations
two events (i.e. b B B), directly indirectly (after saturation). way reduce
vagueness even exact relation known.
presence disjunctions raises question score relations partly
correct, like b B B instead b B reverse. response issue, different
variations usual precision recall measures proposed.
strict measure counts exact matching success, example score 0 latter
example.
However, argued evaluation measure take better account close matches.
example, suppose gold standard relation B b B. system chooses
disjunction b B B, must rewarded less b B > B nothing.
system vaguer correct, annotation logical consequence standard annotation.
proposed (Muller & Tannier, 2004) gradual measure might call temporal
precision recall. Si,j (possibly disjunctive) relation j given system
Ki,j (possibly disjunctive) gold standard, then:
Ptemp i,j =

Card( Si,j Ki,j )
Card( Ki,j )

Rtemp i,j =

Card( Si,j Ki,j )
Card( Si,j )

Card(Gi,j ) = number atomic relations present disjunction. Thus, example, system S1 answered overlaps j get:
Ptemp i,j,S1 =

Card({b, o} {b} )
=1
Card( {b} )

Rtemp i,j,S1 =

Card({b, o} {b} )
1
=
Card({b, o})
2

S2 answered get Ptemp i,j,S2 = Rtemp i,j,S2 = 0.

381

fiTANNIER & ULLER

final precision (resp. recall) average number relations given system
(resp. reference):
j=n
i=n X
X

Ptemp =

j=n
i=n X
X

Ptemp i,j
i=1 j=i+1
Card(S)

Rtemp =

Rtemp i,j
i=1 j=i+1
Card(K)

Similar measures also used TempEval evaluation campaign 2007 (Verhagen et al., 2007), reduced set relations : before, overlaps overlaps.
measures called relaxed recall precision. use words strict relaxed
designate two ways score temporal relations.
2.4 Relative Importance Relations
shown above, temporal closure necessary order able compare properly two temporal
graphs. temporal graph, relations importance. Applying basic recall
precision scores (either strict relaxed) closed temporal graphs enough. Consider
simple graph examples Figure 6, first graph K gold standard. S1 contains
two relations, six K. seems unfair consider recall score 62 , since adding
one relation (B b C) would enough infer others. intuitive recall would around 23 .
counts many relations missing order recover whole annotation graph.
Still, even suppose way distinguish unambiguously major relations (solid
lines K) minor (deducible) relations (dashed lines), would enough. Indeed, graph
S2 finds relation B b D. relation minor K, found composing
relations; S2 , case, relation actually carries piece information must
rewarded. However, even amount temporal information brought S2 S3 seems
equivalent, S3 get higher score. Indeed, amount missing relations (needed infer
full graph) much lower S3 (only C b missing) S2 . Finally, S4 get better
recall one. General cases involving relations obviously much complex.
kind problems could found co-reference task MUC-6, co-reference
links define equivalence relation. thus necessary specify pair-wise co-reference
relations retrieve them, consequences evaluation recall. addressed
considering spanning tree graph co-reference enough evaluate recall
links (Vilain, Burger, Aberdeen, Connolly, & Hirschman, 1995). equivalence class
considered, consisting n entities, n 1 links enough define class, recall error depends
number missing links needed reconnect equivalence class. Recall class

1 n1
. Precision defined symmetrically. much simpler framework, similar
problem redundancy.4
2.5 Minimal Graphs
said previous section, good, insufficient way deal relative importance graph
relations would work called major relations, minimal graph.
consider temporal graph minimal graph graph G if:
4. MUC measures problems later addressed measures B3 CEAF,
relevance evaluation temporal graph. main issue tendency favor prediction co-reference
link every pair mentions; counterpart temporal case since event pairs linked different
relations different inferential properties, opposed one equivalence relation.

382

fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION

K



B

C



S1



B

C



S2



B

C



S3



B

C



S4



B

C



Figure 6: metric deal with. K reference annotations, Si candidate annotations. S4 better S1 S3 , better S2 . Solid lines indicate annotated
relations, dashed lines indicate relations inferred annotated relations. events
related relation here.

1. temporal closure leads temporal information G.
2. relation removed graph without breaking first property.
Unfortunately, unique minimal graph exist general case, particular
Allen relations. Rodriguez et al. (2004) propose way find minimal graphs given temporal
graph. algorithm first finds core relations, relations every minimal graph, intersecting derivations, computes possible remaining combinations order find
composing minimal graph.
example, relation RA,B B, derivations RA,C RC,B , RA,D RD,B ,
RA,E RE,B , etc. intersection derived relations equals RA,B , means RA,B
core relation, since obtained composing relations. Otherwise, relation
core relation, since removing always leads loss information. way kernel
obtained ensures uniqueness.
However, second part procedure (compute remaining combinations) computationally
impractical, even medium-sized graphs, since every subset relations must considered
determine minimal graph top core relations. authors detail much empirical
investigations, offering support usability method. Moreover, lead
unique graph could compared reference.
Going back evaluation, Tannier Muller (2008) suggest comparison graphs
core relations, easy compute give good idea important relations
graph. core relations contain information provided closed graphs,
383

fiTANNIER & ULLER

Figure 7: Recall behavior removing information vs. ideal behavior.
measures core graphs approximation assessed. paper,
propose method obtain unique graph respecting constraints mentioned Section 2.4.
2.6 Behavior Existing Metrics
stated work Tannier Muller (2008), recall measure expected decrease
linear way amount information decreases. Otherwise, evaluation measures could
non-gradual changes complicate comparisons models. Besides, expect amount information grow roughly proportionally number events text.
behavior evaluated comparing given annotation annotation
temporal information taken out.
Figure 7 shows recall measures evolve removing relations temporal graph,
relations present. shows different values strict recall according proportion
relations kept graph, well ideal = x line. considered illustration
consequences annotator forgetting annotate relations, respect ideal
reference.
slope reveals two major drawbacks, leading lack stability metric:
non-linear progression curve intuitively correspond expect
good metric: example, system provides 60% correct information system B, system get 60% better recall.
shown later, parabolic shape due irregular redundancy sparseness
human annotation. Then, two systems providing amount correct information
get different recall values, depending whether human annotation information
redundant not.
Figure presents idealized case; thorough experiments done whole TimeBank corpus (Pustejovsky et al., 2003) explained details Section 6. now, enough
note measure decreases parabolic way, since annotators roughly tag O(n) relations
n number events, inferred relations O(n2 ), number edges n nodes.
384

fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION

A1
B1

<

A2

<

C1

<

C2

B2

Figure 8: Endpoint graph merges (same temporal information Figure 4). Gray dashed arcs
trivial relations coming definitions endpoints (C1 starts C, C2 ends C).

Full graphs contain redundant information, recall thus decreases artificial, irregular ways
removed. hypothesis working minimal graphs suppress redundancy lead controlled behavior.
Moreover, fact reference graphs contain O(n2 ) relations closure biases evaluation
towards larger texts (or least texts containing large clusters related events).

3. Proposed New Metric
confronting graph gold standard, similarity measure necessary. Many similarity
measures exist two graphs many-to-many correspondence found nodes
graphs (Sorlin, 2006).
Node matching, major problem graph comparison general, difficult
case, since consider graphs annotate events expressions5 .
traditional similarity function two graphs following (Sorlin, 2006):
sim(K, G) =

f (K um G) g(splits(m))
f (K G)

K um G set relations shared graphs according node matching function m,
K G union K G relations, splits(m) number node splits imposed
matching obtain graph mapped (see examples later). Functions f g depend
types graphs applications.
kind metrics appropriate temporal relations, transitivity relations implies different features; also, metrics symmetrical, whereas two distinct recall-
precision-like values desirable. adapted general idea two functions split nodes
relation similarity, arrived algorithm described below.
3.1 Transitive Reduction Endpoint Graph
address problem finding minimal graphs take account relative importance
relations, take inspiration work Dubois Schwer (2000) two main ideas. First,
graphs saturated (i.e. temporal closure applied), converted endpoint graphs. Second,
two nodes linked equality relation merged together (this help guarantee uniqueness
minimal graph, see below), useful procedure point-based graph (van Beek, 1992). Figure 8
presents graph Figure 3 transformation. resulting point graph saturated,
definition composition event relations Allens algebra.
Recall graph consider built convex annotations, i.e. cannot <
> relation two points. keep relations < without loss information, since
> obtained symmetry.
5. case, creating fictitious unlinked nodes one graph enough.

385

fiTANNIER & ULLER

specifications, graph boils directed graph transitive relation
edge two points x means x y. coherent graph thus acyclic, since
collapse equal points single nodes. important note consequence, edge
transitive closure labelled equality relation only. Thus see problem
searching transitive reduction graph labelled transitive relation (but
keep additional information edges precisely labelled < instead
disjunctive ). important minimal graph transitive reduction
graph, transitive reduction directed acyclic graph unique (Aho, Garey, & Ullman, 1972;
La Poutr & van Leeuwen, 1988). transitive reduction graph G definition subgraph
corresponding minimal set edges (with respect inclusion) transitive
closure G, i.e. minimal graph G0 G0 subgraph G G0 = G G
transitive closure G. simply determined G /(G G ). Algorithm 2 details simple
computation transitive reduction Figure 9 shows illustration procedure
simple transitive graph. Figure 10 shows process initial endpoint graph <
labels, minimal graph, via transitive reduction unlabelled graph.
Algorithm 2 Transitive reduction simple computation
procedure COMPOSE(G)
. find relations inferable others
newRels={}
base_rels= { x x G.edges() x.relation() {<, }}
one base_rels
related ={x x G.edges() x.source()=one.target() x.relation() {<, } }
related
relation = compose(one.relation(),other.relation())
newRels.add(Edge(one.source(),other.target(),relation))
end
end
return newRels
end procedure
procedure RANSITIVE - REDUCTION(G)
G = closure(G)
non_min=compose(G)
one non_min
G.edges().remove(one)
end
one G.edges()

. remove relations deduced composition

one!=before one!=before_or_equals
G.edges().remove(one)
. keep <, remove symmetric relations
end
end
end procedure

386

fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION

1+4
1+5

4

2
3

5+7

7

5
6

1

8

6+7
(b)

(a)

(c)

Figure 9: Transitive reduction acyclic graph; (a) initial closure transitive relation
graph; (b) set edges obtained composition edges (a), examples composition edge; (c) transitive reduction, difference
(a) (b).

387

fiTANNIER & ULLER

<
<

<
<=

<
<=

<
<
(b)

(a)

<=

<
<=

<

(d)

(c)

Figure 10: Transitive reduction point-based graph; (a) initial annotation transformed
graph events endpoints; (b) corresponding graph every label , (c)
transitive reduction (d) final minimal graph precise initial information reported.

388

fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION

call:
Major relations, relations transitive reduction, Gmaj .
Minor relations, relations temporal closure present transitive reduction, i.e. G Gmaj .
Formally:
Let G = {(x, y, R)/R {<, }}, temporal point graph, saturated respect relation < . G = G
Let E(G) = {(x, y)/R, (x, y, R) G}, unlabelled corresponding graph. function f
associates (x, y, R) G (x, y) E(G) obvious bijection, original graph G
one relation holding two vertices. E(G) = f (G). Since G closed,
E(G).
Let P roj(G0 , G) = {(x, y, R) G/(x, y) G0 } projection unlabelled graph
labelled one. function associating edge (x, y) G0 (x, y, R) G inverse f , f 1 .
P roj(G0 , G) = f 1 (G0 ), obviously P roj(E(G), G)) = G.
enough prove E(G) (or G) graph transitive, acyclic relation prove
E(G) unique transitive reduction (Aho et al., 1972).
First, E(G) transitive: let (x, y) E(G) (y, z) E(G) (x, y, <) (x, y,
) G (y, z, <) (y, z, ) G four possibilities infer either (x, z, <)
(x, z, ) G (because < transitive, transitive x < z x < z imply
x < z); words composition < <, i.e. ((< ) = ( <) = (<))
(x, z) also E(G) E(G) graph transitive relation. reason said
keeping record < relations considering G graph change graph
property.
Second, G acyclic since < irreflexive, x < z implies x < z way
cycles G paths x z ... x. case infer
x = = z = ... nodes would merged beforehand. E(G) also acyclic (it
exactly edges G).
So, E(G) acyclic transitive thus admits unique transitive reduction E(G)tr .
Since graphs G E(G) exactly edges, necessarily reductions, thus unique transitive reduction. project back original relations
G E(G)tr , (P roj(E(G)tr , G)), properly labelled reduction G.
3.2 Temporal Recall Precision
idea compare minimal graphs. Temporal closure used well.
showed Section 2.4, reference minor relations still rewarded redundant
evaluated graph. However, must carry lower weight.
Minor relations considered temporal recall, precision. reason
recall evaluates proportion reference relations found system, system
find minor relations without major relations produced reference (see B b
S4 example, Figure 6). opposite, precision evaluates proportion system relations
reference graph, minor (i.e. deducible) relations found system definition
redundant.
recall-like measure combination two values. Given K reference graph G
evaluated graph:

389

fiTANNIER & ULLER

major temporal recall rate reference major relations (Kmaj ) found G .
minor temporal recall rate reference minor relations (K Kmaj ) found Gmaj .
first case, temporal closure applied G, since reason restrain search
good relations evaluated graph. second case, transitive reduction Gmaj
considered; reference minor relations must rewarded minor G (case B b
example S2 , Figure 6). G minor relations already assessed major relations
(case b C example S4 ).
final value temporal recall weighted sum two figures.
precision-like measure single value corresponding ratio correct relations
Gmaj total number relations. G minor relations must considered precision. Unlike recall reference major relations may retrieved system, precision
necessarily considers major relations system. Minor relations redundant.
precision well recall, merge must considered relation way,
corresponds = relation.
3.3 Notations
note:
G K event graphs, K reference (key);
Gpt K pt , corresponding endpoint graphs, equals points merged.
(N, R) set nodes relations graph G, mutatis mutandis others.
examples, non-trivial relations listed. Trivial relations involving two
points interval. example, A1 < A2 Figure 8 trivial, thus considered.
figures, trivial relations dashed gray lines. Non-trivial relations node list
enough find full graph.
temporal closure G noted G .
transitive reduction G noted Gmaj .
3.4 Temporal Recall Precision
new metrics temporal recall precision rely notions defined above. respect
recall value, shown important distinguish major relations, i.e. relations
belong minimal graph, other, minor relations. suggest compute
recall two steps. Precision concerned issue.
3.4.1 G RAPH VALUES
Lets consider Gpt set merged nodes relations (N pt , Rpt ) evaluated respect
pt
pt
reference K pt = (NK
, RK
). need take account number relations expressed
original point graph nodes merged (called value(Gpt )), number equalities expressed merged nodes, node_values(Gpt ), plus number relations relation_value(Gpt ).
Then:
pt )
value(Gpt ) = node_value(G
+ relation_value(Gpt )
P
pt
=
ni N pt (|m(ni )| 1) + |R |
= |N | 2 |N pt |
+ |Rpt |
390

fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION

Here, m(ni ) number points merged node (m points node correspond 1
merges). Similarly, compute value reference graph.
pairing nodes evaluated graph reference graph must taken
account. Lets call split operation mapping one node reference graph many
nodes evaluated one, conflation, converse operation. map graphs, first
need split node reference evaluated graph nodes
maybe extra nodes, conflate, necessary, remaining nodes evaluated nodes (see
Sections 4 5 illustration). split like = relation provided reference
evaluated graph. conflation = wrongly predicted evaluated graph.
Therefore, number correct answers evaluated graph, correct value vc , number
correct = < relations6 . number correct = node value - nb conflations,
number correct < relation value - wrongly predicted relations (errors).
simple way calculating number splits necessary match two graphs G1 G2
count node x G1 number different nodes G2 intersect x. one,
node mapped directly, otherwise 1 splits needed. Thus:
P
|split(K pt , Gpt )| = xN pt |{y N pt /x 6= }|
K

number conflation necessary match G1 G2 also number splits necessary match
G2 G1, so:
|conf lation(K pt , Gpt )| = |split(Gpt , K pt )|
vc (Gpt ) =
=
=
=

correct equalities + correct precedences
(node_value(Gpt ) conflations)) + (relation_value(Gpt ) errors)
v(Gpt ) (|conf lation(K pt , Gpt )| + errors)
v(Gpt ) (|split(Gpt , K pt )| + |R RK |/|R|)

3.4.2 EMPORAL R ECALL P RECISION
precision value deals errors (incorrect relations) conflations correct value vc .
hand, recall value must take account misses (reference relations missed
pt
point-based reference, G = Gpt
graph) splits. simplicity, lets note K = KK
graph evaluate. Kmaj Gmaj transitive reductions these. define:
Major temporal recall Rt (G) number reference major relations found G .

Rt (G) =
Rt (G) =

v(Kmaj ) (splits + misses)
v(Kmaj )
v(Kmaj ) (|split(K, G)| + |(RK R )/RK |)
v(Kmaj )

misses number relations Kmaj missed G splits number splits
(a split missed = relation).
6. consider course non trivial relations.

391

fiTANNIER & ULLER

Symmetrically, Temporal precision P (G) ratio correct value Gmaj ,
vc (Gmaj ), full value v(Gmaj ).
P (G) =
P (G) =

v(Gmaj ) (conf lations + errors)
v(Gmaj )
vc (Gmaj )
v(Gmaj )

But, already stated, minor relations also taken account. consider
major recall, systems find minor (but correct) relations disadvantaged. case
system S2 Figure 6 (B b correct minor). add minor temporal recall:
Minor temporal recall rt (G) proportion reference minor relations (K Kmaj ) found
Gmaj . Minor relations seeked minimal evaluated graph. Indeed, already
said, comparing two relations non-minimal graphs redundant, since major relations
produced already taken account.
Full temporal recall R could defined value pair (Rt (G), rt (G)), preferably
combination:
R(G) = Rt (G) +

1
rt (G)
v(Kmaj )

(2)

formula, ensure one single major relation better minor ones
recall exceed 1 (see next Section).
symmetrical precision property, i.e. proportion system minor relations existing
reference, always null. System minor relations are, definition, always redundant.
temporal precision need two-fold figure.
tool computing different precision recall values (strict, relaxed, core, well
new one) made available paper7 . accepts several input formats, including TimeML.
computed data also available, instructions reproduce experiments presented end
paper.
3.4.3 YNTHESIS
Evaluating interval graph G gold reference K achieved following steps:
1. Perform transitive closure G K.
2. Convert graphs endpoint graphs.
3. Merge equality relations single nodes.
4. Perform transitive reduction.
5. Compute values temporal recall precision.
7. http://www.irit.fr/~Philippe.Muller/resources.html

392

fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION

costly operation first one, common standard evaluation procedure; time O(|N |3 ) worst case algorithm 1 page 379, N set events
largest graph G K. straightforwardly linear number relations
graph (conversion endpoints, merge equalities closed graph), worse O(|N |2 )
transitive reduction (one composition relations graph set difference),
computation number splits conflations. Overall, whole procedure dominated
first step, common evaluation procedures task. proposition thus
change worst-case complexity evaluation procedure.
3.4.4 B OUNDARIES
Temporal precision. Temporal precision value 0 1 since vr (G) v(G) (errors
conflations zero positive).
Temporal recall.

Major recall 0 1.

1, minor recall rt (G) = 0, relations Gmaj already Kmaj (and
cannot K Kmaj ). case temporal recall cannot exceed 1.
1,
Rt (G) (v(Kmaj ) 1)/v(Kmaj ). Yet,
stays 1.

1
v(Kmaj ) rt (G)

<

1
v(Kmaj ) ,

full temporal recall

Thus 0 R(G) 1.
order make measure clearer, present metric detail developing basic
example transitive closure made simple relations (the 13 basic Allen relations),
turn general case closure made convex temporal relations (disjunctions
neighboring Allen relations).
3.4.5 IMPLE E XAMPLES
Temporal recall precision described lead expected values sample graphs
pictured Figure 6 analyzed Section 2.4.
Figure 11 recalls graphs details temporal recall values (given
v(Kmaj ) = 3). precision, graph Si , P (Si ) = 1.
attentive reader would note system providing minor relations, < C, <
B < C, i.e. half deducible relations, would get recall 0.33, could seem unfair.
However, even three relations present, three others still missing (the number missing
relations graph relation all). Moreover, fact minor relations get
better score one major relation condition boundaries go 1. Finally,
case rare affect general behavior metric.
sophisticated examples provided following sections.

4. First Simple Case: Non-Disjunctive Allen Relations
Consider sample graph K1 made Allen non-disjunctive relations (see also graph Figure 12):

393

fiTANNIER & ULLER

K

B





C

S1



B

C



R(S1 ) = 3(1+0)
+ 03 = 0.67
3
(2 major relations, 1 missing)

S2



B

C



1
R(S2 ) = 3(2+0)
+ 33
= 0.44
3
(1 major 1 minor relations)



R(S3 ) = 3(1+0)
+ 03 = 0.67
3
(2 major 1 redundant minor relations)



1
R(S4 ) = 3(1+0)
+ 33
= 0.77
3
(2 major 1 non-redundant minor
relations)

S3

S4





B

C

B

C

Figure 11: Temporal recall simple graphs, compared reference K.

B C E

bi b
B
bi
K1 =
C
b b

f
E

F
b

b
e
fi

conversion relations endpoints leads following graph, event
split A1 A2. Edges labelled since relation < considered point.

A1

K1maj

C1

C2

B1
E1

A2

B2

E2

D1

D2

F1

F2

Figure 12: Reference simple relations, K1maj .
Note merging equal nodes equivalent labelling arcs =, latter
case minimal graph would unique more. example, necessary choice
A1 < A2, B1 < A2 E1 < A2 would lead three equivalent different graphs.
Consider reference K1 compared following graph G1 (Figure 13; bold edges
correct relations, thin edges wrong relations, dashed edges trivial relations, i.e. involving
two endpoints interval).
Following notations defined Section 3.3:
list nodes graphs K1maj G1maj are:

394

fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION

G1maj

C1

B1

C2

A1
B2

D1
A2

E1
F1

E2
F2

D2

Figure 13: Evaluated graph simple relations, G1maj .
K1maj : N 1 = {C1, C2, (A1, B1, E1), A2, (B2, D1, F 1), (E2, D2, F 2)} : 6 nodes
G1maj : N 2 = {C1, B1, C2, (A1, B2), A2, (D1, E1, F 1), (E2, F 2), D2} : 8 nodes
Non-trivial relations are:
K1maj : R1 = {[C2; (A1, B1, E1)], [A2; (B2, D1, F 1)]} : 2 relations
G1maj : R2 = {[C1; B1], [B1; C2], [C2; (A1, B2)], [A2; (D1, E1, F 1)],
[(E2, F 2); D2]}] : 5 relations
temporal closures Gi computed listed (bold relations added
minimal graph, i.e. K1 K1maj G1 G1maj ). Relations line share
arguments (at least one point common argument). Figures 14 15 also represent
closures.
K1
[C2; (A1, B1, E1)]
[A2; (B2, D1, F 1)]
[C1; (A1, B1, E1)]
[C1; A2]
[C1; (B2, D1, F1)]
[C1; (E2, D2, F2)]
[C2; A2]
[C2; (B2, D1, F1)]
[A2; (E2, D2, F2)]
[C2; (E2, D2, F2)]

G1
[C2; (A1, B2)]
[A2; (D1, E1, F 1)]
[C1; B1]
[C1; A2]
[C1; (A1, B2)]
[C1; (D1, E1, F1)]
[C1; D2]
[C1; (E2, F2)]
[C2; A2]
[C2; (D1, E1, F1)]
[A2; (E2, F2)]
[A2; D2]
[C2; (E2, F2)]
[C2; D2]
[B1; C2]
[(E2, F 2); D2]
[B1; A2]
[B1; (D1, E1, F1)]
[B1; (E2, F2)]
[B1; D2]
[(A1, B2); (D1, E1, F1)]
[(A1, B2); (E2, F2)]
[(A1, B2); D2]

pairing nodes list splits conflations needed match sets nodes
also computed (see also Figure 16):
395

fiTANNIER & ULLER

K1

A1
C1

C2

A2

B1
E1

B2

E2

D1

D2

F1

F2

Figure 14: Temporal closure K1 . Dotted relations represent K1 K1maj .

G1

C1

B1

A1

C2

B2

D1
A2

E1
F1

E2
F2

D2

Figure 15: Temporal closure G1 . Dotted relations represent G1 Gmaj .
(A1, B1, E1)K1 : 2 splits (breaking 2 equality relations); (B2, D1, F 1)K1 : 1 split
(D1 F 1 stay together G1); (E2, D2, F 2)K1 : 1 split
(A1, B2)G1 : 1 conflation (joining two nodes); (D1, E1, F 1)G1 : 1 conflation (joining E1
two others); (E2, F 2)G1 : nothing (already together K1)
Total: 4 splits 2 conflations.
stated above, edge correct relation correct least one pair points
nodes. example, relation {A2}G1 {D1, E1, F 1}G1 correct {A2}K1
{B2, D1, F 1}K1 , even sub-relation A2 < E1 true. latter relation penalized anyway split necessary matching graphs.
definitions lead following values;
Graph values:
v(K1maj ) = node value + relation value = 6 + 2 = 8
v(G1maj ) = 4 + 5 = 9
Correct value G1:
vc (G1maj ) = (node value conf lations) + (relation value errors)
= v(G1maj ) (conf lations + errors)
= 9 (2 + 2) = 5
Major temporal recall:
Rt (G1) =
=

v(K1maj ) (misses + splits)
v(K1maj )
8 (0 + 4)
= 0.5
8

Minor temporal recall: rt (G1) = 28 = 0.25
(this corresponds [C1; {A1, B1, E1}] [C2; (B2, D1, F 1)]).
396

fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION

A1

K1

C1

C2

A2

B1
E1

split


splits

C1

B1

C2

split

A1

B2

A2

merg.

G1
(after
conations)

C1

B1

E2
D2

F1

F2

split

split

E1

D1

E2

F1

F2

D2

merg.

D1

A1

C2

B2
D1

A2

B2

E1
F1

E2
F2

D2

Figure 16: Split conflation operations K1 G1.
Full temporal recall:
R(G1) = (R(G1), r(G1))
= (0.5, 0.25)
R(G1) = Rt (G1) +
= 0.5 +

1
rt (G1)
v(Kmaj )

0.25
= 0.53
8

Temporal precision
P (G1) =
=

vc (Gmaj )
v(Gmaj )
5
= 0.56
9

5. Disjunctive Convex Relations
apply metric sets convex relations. Convex relations set relations
conceptual neighbors, encode relations may vague intervals endpoints
convex subsets time-line (see Section 2.2).
Building minimal graph follows procedure explained (transitive reduction).
measures differ choose strict scoring scheme (see Section 2.3).
relaxed scheme, disjunctions, becomes necessary apply weighting procedure; response
longer assigned binary value (0 1), example one values Table 3, manner
similar done TempEval (Verhagen et al., 2007).
shown table, relaxed measure effect misses values vc (a relation
get half-point), also conflation split values (where half-points also possible).
397

fiTANNIER & ULLER

%
Rel.



Repres.



<

B

1

0







>

B



B

<

<, =

B

0.5

B

<





>
B

<



B

<, =



B



=



<

=

0

( 12 -split)

0

B

1

0.5

0.5
( 12 -split)

0

0

(disjunction)
<, =

<

B

0.5

0.5

( 12 -confl.)

(disjunction)

0

0



1

0

0.5
(disjunction)

0

1

0.5
(disjunction)

<, =



0.5

0

( 12 -confl.)

0.5

0.5

(disjunction)

(disjunction)

1

Table 3: Example weights relaxed measures.
Consider new reference K2 convex relations (see also Figure 17):
B
C

E
F

{bi, mi, oi, f i, =, f, di, si} b

b
B
{di, si, oi, mi, bi}



C
b {d, s, o, m, b }
b

f
{s, =, si}
E
{di, f i, o}
characteristics K2 are:
7 nodes 6 events (5 equality relations)
2 relations: [C2 A2], [A2 < {B2, D1, F 1}]
K2 =
[C2 A2], [A2 < {B2, D1, F 1}], C1 < A2, C1 < {B2, D1, F1}, C1 < {E2, D2},
C1 < F2, C2 < {B2, D1, F1}, C2 < {E2, D2}, C2 < F2, {A1, B1, E1} < F2,
A2 < {E2, D2}, A2 < F2
v(K2maj ) = (12 7) + 2 = 7.
Let us consider evaluated graph G2 (Figure 18) has:
10 nodes 6 events (2 equality relations)
5 relations: [C1 D1], [D2 < C2], [C2 A2], [{A1, B1} E1], [A2 < {B2, F 1}]
G2 = [C1 D1], [D2 < C2], [C2 A2], [{A1, B1} E1], [A2 < {B2, F 1}],
[C1 < D2], [C1 < A2], [C1 < {B2, F1}], [C1 < F2], [D1 < C2], [D1 < A2],
[D1 < {B2, F1}],
[D1 < F2],
[D2 < A2],
[D2 < {B2, F1}],
[D2 < F2],
[C2 < {B2, F1}], [C2 < F2], [A2 < F2], [{A1, B1} < F2], [{A1, B1} < E2]
v(G2maj ) = (12 10) + 5 = 7.
398

fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION

A1
B1
E1

K2maj
C1

<

E2
<
<,=

<

A2

B2

<

D1

<

F1

D2
F2

C2

Figure 17: Reference convex relations, K2maj .

C1

<,=

D1

<

D2

<

C2
<,=

A1

G2maj

<

B1

A2

<

B2
F1

<

F2

<,= (1/2-split)
E1

<

E2

Figure 18: Evaluated graph convex relations, G2maj .
conflation number splits 2.5. half-split comes fact
E1 may equal {A1, B1}, edge.
application measures leads following values:
Rt (G2) =

7 (0 + 2.5)
= 0.64
7
rt (G2) = 0

R(G2) = 0.64
vc (G2) = (12 + 2 1/2) + 2 = 15
two half-points vc (G2) hold relations C1 D1 (instead C1 < D1 reference)
B1 E1 (instead B1 = E1 reference).
example, following Table 3, see E1 leaving group {A1, B1, E1} costs
half-point recall value, relation B1 E1, correct imprecise, gets half-point
precision. results seem logical behaviors measure.

6. Experiments
push change evaluation measures temporal annotation graphs motivated
beginning paper examples show undesirable side effects common
399

fiTANNIER & ULLER

evaluation procedures. present thorough methodology, aiming evaluate
evaluation procedure itself. used two kinds data purpose. Obviously, test
compare measures freely available temporal annotated data provided TimeBank
corpus. also introduce set artificially built temporal graphs, control
relevant parameters. TimeBank annotations rather heterogenous, human annotators make
mistakes, forget relations, introduce inconsistencies, thus creating fair amount noise. Besides,
wanted test aspects temporal annotation easier generate scratch. One
factor amount information present annotation. seen result
annotation less underspecified: relation events simple, precise
relation, disjunction simple relations. size graph also probably important,
somewhat hidden human annotations, really relevant object considering
inferred information connected component. Small subgraphs nodes allow
lot inferences, bias want study probably happens certain
threshold. human annotations, size subgraphs vary lot, common events
related one two events, even graph enriched inference
procedures.
main experiment performed study behavior commonly adopted measures
proposal based comparison annotation weakened version itself.
graph, remove portion event-event relations random, use measures estimate
loss information. Obviously, interesting recall-like measures, precision
affected. vary amount removed information steps, relations vague: eventually,
universal disjunction hold two events text. designed another experiment
watch also behavior precision measures : instead removing relations, disturbed graph
changing simple relation another one (simulating error annotation, way).
meaningful keep graph consistent time.
follows, present results synthetic graphs (6.1) TimeBank
data (6.2).
6.1 Artificial Graphs
order control amount information present temporal graph, built set
artificial temporal graphs following way:
given number events E, temporal graph built randomly choosing set E
integer pairs (bi , ei ), within given range N , level indeterminacy I,
width around boundaries bi ei .
pair events (i, j), determine temporal relation intervals, considering endpoints lie anywhere interval [bi I/2, bi + I/2]
[ei I/2, ei + I/2], endpoints j lie anywhere interval [bj I/2, bj + I/2]
[ej I/2, ej + I/2].
graph closed, leading N = (E (E 1))/2 relations.
Events considered intervals uncertainty endpoints, comparable
graph built text, give rise possibly disjunctive relations generated
events. graph thus contain kind convex (possibly disjunctive) Allen relations.
example generated events provided Figure 19. varying N I, control
400

fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION

beginning
E5

end
E5

E5
E4
E3
E2
E1
0

1

5

10

15

20

Figure 19: Example random artificial graph N = 20 (X-axis), E = 5 = 3 (maximum
uncertainty endpoint). indeterminacy leads disjunctive relations, example ((E5 < E3) (E5 meets E3) (E5 overlaps E3)). building graphs
representation, relations disjunctive graph fully connected,
case real data like TimeBank.

amount vagueness information put graph. smaller N is, tighter model
generate, likely vague boundaries intersect, creating disjunctive relations.
larger also contributes vaguer representation. quantify amount vagueness v
much relations disjunctive graph:
P
1
redges(G) 1 |r|
v=
|edges(G)|
r edge graph |r| number simple Allen relations disjunction
(i.e.: r = {b, o}, |r| = 2).
Figure 20 shows different values strict recall temporal recall (called point recall)
according proportion relations kept graph, lines joining values derived
graphs.
interesting note curves based minimal graphs almost linear, simpler measures decrease slowly first sharply, parabolic way. analyze
(Section 6.2.2) difference y=x.
shows overall effect observable roughly every graph considered. effect
even marked number events higher.
also compare point-based measure relaxed recall measure, similar measure
used TempEval campaign computes overlap simple disjunctive
relations every edge graph. also want see behavior measure based core
set relations extracted annotation previous work (Tannier & Muller, 2008).
see Figure 21 measure behaves linearly point-based one. Here,
plotted estimates parabolic regression data set, clarity. others measures show clearly parabolic behaviors, different undesirable effects: relaxed recall much
permissive information actually provided (since disjunction relations,

401

fiTANNIER & ULLER

experiment : remove

1.0

experiment : remove

1.0

strict recall
id

0.6

0.6
score

0.8

score

0.8

recall/point graph
id

0.4

0.4

0.2

0.2

0.00.0

0.2

0.4

% modified

0.6

0.8

0.00.0

1.0

0.2

0.4

% modified

0.6

0.8

1.0

Figure 20: Behaviors graph 30 events, strict recall (left) point-based recall (right).
carry information, gets non-zero score), recall respect core relations similar
strict recall, surprisingly even less linear. effect stronger number
events increases.

experiment : remove

1.2

recall/core
strict recall
recall/point graph
relaxed recall
id

1.0

score

0.8
0.6
0.4
0.2
0.00.0

0.2

0.4

% modified

0.6

0.8

1.0

Figure 21: Parabolic regressions recall measures considered (30 event graphs).
Finally, Figure 22 shows influence different levels vagueness annotation (and
thus underlying temporal description) measures used. plotted experiment
(recall respect quantity information removed) vagueness considered graphs third parameter. surface shown departure y=x line,
readabilitys sake.
observe less vague temporal descriptions values mainly y=x
line parabolic measures, vaguer data show less obvious parabolic behavior, sometimes
402

fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION

line. curves point-based recall seems insensitive aspect, consistent
average behavior already discussed.

0.8

0.8

recall/point graph

0.6
strict recall

0.4
0.2

d0.2
isjunc 0.4
tion le 0.6
vel

0.8

0.8

0.6

0.2
0.4 oved
em
r
%

0.6
0.4
0.2

dis0.2
junct 0.4
ion le 0.6
vel

0.8

0.8

0.6

0.2
0.4 ved

% rem

Figure 22: Influence vagueness annotation behavior different measures (30
event graphs), strict recall left point recall right.

6.2 TimeBank Corpus
presenting results evaluations real annotated data TimeBank corpus,
show characteristics temporal graphs induced annotations. helps understand
differences behavior observe synthetic temporal graphs
ecological ones.
6.2.1 NALYSIS IME BANK C ORPUS
TimeBank corpus consists 186 news report document (for 65, 000 tokens). made
news articles Associated Press, Wall Street Journal, L.A. Times San
Jos Mercury News, transcripts broadcast news CNN, ABC, VOA. documents
initially collected DUC ACE evaluation campaigns. corpus version 1.1
available http://www.timeml.org/site/timebank/timebank.html.8
Documents annotated using TimeML standard tagging events states, dates, times,
durations, temporal relations well various aspectual modalities. entities
also tagged attributes: tense, aspect verbs, values dates durations, normalized
according ISO standard 8601.
Eventualities denoted verbs, nouns, adjectives prepositional phrases.
temporal relations encode topological information time intervals occurring eventualities, using relations equivalent Allen relations, although different names.
TimeML standard specifies relations events, anchoring events times (dates,
hours) relations times. 7000 annotated relations temporal
entities. Additions set proposed (Bethard, Martin, & Klingenstein, 2007), order
complete annotations. noted Setzer (2001), tagging temporal relations hard
8. somewhat cleaned-up version, 1.2, available via Linguistic Data Consortium. used freely available
version, checking recent version exhibit significant differences experiments.

403

fiTANNIER & ULLER

Figure 23: Frequencies TimeBank texts respect number temporal entities.
Mode
Consistent annotations
Average number relations
Average nb components/text
Component Average size
Max component average size

Raw
186
43
5.28
7.94
19.64

+time-time relations
186
58
7.15
5.89
27.04

Saturated
131
134
5.28
7.94
19.64

Saturated + t-t
146
281
7.15
5.89
27.04

Table 4: Timebank1.1 statistics (Average number temporal entities=42)
annotators, tend miss relations, produce inconsistent annotations.
obvious sizes texts increase, since number possible links grows square
number temporal entities. Figure 23 shows distribution events among texts.
annotators could expected keep track possible relations events small texts,
task probably different numerous larger texts, noted tend produce sets disconnected temporal subgraphs majority corpus (Chambers & Jurafsky,
2008b).
Table 4 shows two important consequences considering relations inferred annotation: (a) lot annotations TimeBank 1.1 actually inconsistent temporal graph
saturated using procedures introduced earlier paper (b) text gives rise several connected components various sizes. worse compute missing (but obvious) relations
dates whose values fully specified (noted t-t table). seen, procedure
checking consistency say set relations globally inconsistent, without hint
relation(s) isolated repair situation. texts thus ignored
evaluations.
fact temporal graphs texts actually split components different
sizes consequences considering size referent graph: fully connected graph
n entities n (n 1)/2 non-vague edges saturation, text scattered
annotations might yield relation much smaller graph.
compared number relations present minimal graph obtained transitive
reduction number temporal closure interval-based graph, respect
number events present text, whole TimeBank Corpus 1.1. (Figure 24). Figure,
point corresponds text, number events along x-axis number relations

404

fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION

reference used evaluation given measure along y-axis. appears minimal
graph grows roughly linearly expected (the variance due variable multiple branching
lot uncertainty). hand, temporal closure annotation larger, much
irregular, greater variance number events grows. even worse
relaxed measures necessarily consider every possible edge two events, even though
might bear non-informative vague relations consisting disjunction many relations.
Note however reference size quadratic number events, due high number
small self-connected components, noted previous paragraph.
taken account considering evaluation entire corpus, deciding contribution made one text, set temporal relations. case
strict recall, practice add edges temporal closures, possibly giving given
text weight proportional square number events. Micro-averaging results
text probably desirable either, giving much importance small texts relations.
reference size linear number events solves problem, providing sort
smoothing respect factor.

influence size reference graph size

1200

strict recall
recall/point graph
relaxed recall
y=x
id

1000

size reference

800

600

400

200

00

50

100

150

200
nb events

250

300

350

400

Figure 24: Number relations considered reference vs. number events texts, according measure used.

405

fiTANNIER & ULLER

6.2.2 EASURES IME BANK
Recall performed experiments TimeBank synthetic data,
observe phenomenon (a linear decrease point recall), raw results much
irregular (Figure 25), larger unstability almost relations removed.
Note synthetic graph measures values mainly y=x line,
variation, annotated data show kind parabolic behavior line.
main difference reference structured. way generated graphs built
ensures fully connected, relations saturated graphs considered
reference, since reason distinguish subset particular. hand,
human-annotated corpus, removed relations set initial relations tagged
annotators.
first case (artificial data), reference graph resistant removal random
relations, since redundancy, extreme manner: enough relations
removed information actually lost. leads parabolic curve y=x
line, showing redundancy improperly assessed regular recall. point graph immune
effect since relevant relations isolated first.
natural graphs contrary, annotation fragile: annotators tend put
much redundant information annotation. Then, removing removes also
lot inferred relations time (in quadratic quantity). would problem
evaluation could stick annotated relations everyone tagged event pairs. But,
already noticed, case. consider system trying build temporal graph
text scratch, reason provide event pairs reference.
reason, soon redundancy broken removing relations, recall improperly falls
faster y=x does. Again, point-based graphs isolate likely underlying models
behavior thus controlled.
Remember also level vagueness influences shape curves, human
annotations less specified thus highly disjunctive.
also assume human choices, annotating, important. Annotated relations
probably regarded central annotators, hence close ideal core set, especially since
annotators tend minimize number relations tag. assumption verified
experiments human assessments.
Precision estimate behavior precision measures, slightly changed experiment
switching relations different ones, thus disturbing initial graph, trying
keep consistent. Again, number times, averaged results points
similar rates undisturbed relations. result, shown Figure 26, restricted smaller values
change, since increase proportion changed relations, graph gets closer purely
random annotation. arbitrarily kept values 0 40% relations changed random.
course, without control kind change allowed, generate lot different
types modifications, minor well totally change inferences drawn
annotation. reflected huge variance results observed detailed data
(not shown here), even close origin, i.e. unchanged graph. Still, experiment seems
confirm point-based measure follows closely ideal y=x function, would
stable others, previous caveat variance.
System prediction Finally, last indication importance evaluation methodology,
made comparison behavior measures predictions real system.

406

fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION

experiment : remove

1.0
0.8

experiment : remove

1.0

strict recall
strict recall
id

recall/point graph
recall/point graph
id

0.8

score

0.6

score

0.6
0.4

0.4

0.2

0.2

0.00.0

0.2

0.4

% modified

0.6

0.8

0.00.0

1.0

0.2

0.4

% modified

0.6

0.8

1.0

Figure 25: Behavior recall measures TimeBank according amount temporal information removed, (left) strict recall (right) recall point-based graph, solid lines
showing parabolic regression.

experiment : disturb
precision/point graph
relaxed precision
simple precision
id

1.0
0.8

score

0.6
0.4
0.2
0.00.0

0.2

0.4

% modified

0.6

0.8

1.0

Figure 26: Linear regression precision measures according amount temporal information
disturbed reference (TimeBank) range 0-40%

407

fiTANNIER & ULLER

rather tricky issue, since want see measure distinguishes better method others,
way evaluating better method measure want assess.
motivation set experiments presented above. Still, legitimate wonder
least observe differences context real system. One must cautious
conclusions drawn this. order so, took implementation
temporal relation classifier reproducing standard work, instance work Mani et
al. (2006), used one authors another study (Denis & Muller, 2010). applied
TimeBank 1.1, checked correlations usual (strict) precision/recall
counterparts based transitive reduction. Figure 27 shows relations scores
text, subfigure precision one recall. spearman correlation, estimates
one variable monotonically related without assumption, 0.86 precision,
0.61 recall, high significance levels (p < 1020 ). tentative interpretation
make obviously related, types measures show lot variance
different texts, obviously sensitive differences predictions. Texts indeed
ordered differently different sets measures. especially true recall. also
note point-based scores generally higher, easily explained since relations
event correct relations endpoints correct time. Inferences still
muddy waters yield different results respect, could interesting investigate
differences detail.
Correlation precision point precision base classifier TB 1.1
1.0

Correlation recall point recall base classifier TB 1.1
0.9

0.8
0.8

0.7

pt_recall

pt_precision

0.6
0.6
0.4

0.5
0.4
0.3
0.2

0.2

0.1
0.00.0

0.2

0.4

precision

0.6

0.8

0.00.0

1.0

0.2

0.4

recall

0.6

0.8

1.0

Figure 27: Correlations classical measures proposal. Precisions left, recalls right.

7. Conclusion
Comparing temporal constraints graphs crucial task extracting temporal information
texts, evaluation point view perspective incorporating global constraints
statistical learning procedures.
argue comparison measures devoid biases inherent commonly
used comparisons closures Allen-based temporal graphs. measure defined transitive
reductions graph (partially) ordered interval endpoints. Transitive reduction conceptually
intuitive, easy compute unique cases considered. shown empirically
behavior kind measure appropriate goals mind.
408

fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION

claim ordering interval endpoints considered annotation provided
humans, translation possible useful. remains unclear could also
acceptable way presenting temporal information humans, resulting minimal graphs
could meaningfully re-translated interval-based relations. claim either point
relations target automated procedures extract temporal information. bulk
work done event relation classification deals primarily extended intervals,
literature temporal semantics (Steedman, 1997; Kamp & Reyle, 1993).
plan check assumption procedure translating interval constraints endpoint constraints could useful task learning temporal constraints integration global
constraints (for instance good indication close two temporal situations may be).
also useful designing distances structures order make structured predictions,
manner similar done tree kernels syntactic parsing (Collins & Duffy, 2002).
far automated attempts aim predicting relations given event-pairs,
rely local learning strategy take account temporal constraints whole
text. exceptions (Chambers & Jurafsky, 2008b; Bramsen et al., 2006) make use subsets
relations, instance subset {before, after}, relation considered vague.
able use integer linear programming using transitivity constraints temporal order.
simplicity could preserved endpoint translation full algebra.
issues presented relevant also graph-based representations natural language processing tasks, long inference issues: instance discourse representations
often build set rhetorical relations segments (Marcu & Echihabi, 2002). Inference
properties relations remain investigated, automated processes still quite rare (but
see works Sagae, 2009; Wellner, Pustejovsky, Havasi, Rumshisky, & Saur, 2006; Subba & Di Eugenio, 2009), however widely adopted structures behave like partial orders (narrative chains,
topic elaborations) thus follow patterns investigated. case partial annotations partial agreement, finding minimally equivalent representation could used
comparison.
limitations methodological study also limitations knowledge
way human readers process temporal information, whole, found texts.
best knowledge, psycholinguistics literature little interest specific question.
Work exists local temporal interpretation, i.e. way temporal order two events
determined, respect linguistic extra-linguistic factors (Zwaan & Razdvansky, 2001).
global context, studies focussed way reader builds situation corresponding
text (Speer, Zacks, & Reynolds, 2007; Zwaan, 2008), temporal, spatial, causal aspects,
seems events grouped time-frames, sets events causal relations, comprehension
shifts one time-frame representation another. approaches right, readers build
mental models correspond situation given time-frame, explicitly record
relations time-frames. could explain structure lot annotations (a set small
connected components), say much nature knowledge represented.
remains seen investigations process human comprehension could beneficial
computationally oriented approaches process.

8. Acknowledgments
work benefited tremendously helpful feedback several colleagues, mainly Pierre
Zweigenbaum Pascal Denis, Nicholas Asher. Pascal Denis also contributed development temporal tools used work, allowed us use results system
409

fiTANNIER & ULLER

developed Philippe Muller temporal relation identification. also thank Michel Gagnon,
suggested comparison annotation degraded version evaluation
measure, long time ago.

References
Aho, A., Garey, M., & Ullman, J. (1972). Transitive Reduction Directed Graph. SIAM
Journal Computing, 1(2), 131137.
Allen, J. (1983). Maintaining Knowledge Temporal Intervals. Communications ACM,
832843.
Asher, N., & Lascarides, A. (1993). Temporal interpretation, discourse relations, commonsense
entailment. Linguistics Philosophy, 16, 437493.
Bethard, S., Martin, J. H., & Klingenstein, S. (2007). Timelines text: Identification syntactic temporal relations. International Conference Semantic Computing, pp. 1118, Los
Alamitos, CA, USA. IEEE Computer Society.
Bramsen, P., Deshpande, P., Lee, Y. K., & Barzilay, R. (2006). Inducing temporal graphs. Proceedings 2006 Conference Empirical Methods Natural Language Processing, pp.
189198, Sydney, Australia.
Chambers, N., & Jurafsky, D. (2008a). Unsupervised Learning Narrative Event Chains. Proceedings ACL-08: HLT, pp. 789797, Columbus, Ohio. Association Computational Linguistics, Morristown, NJ, USA.
Chambers, N., & Jurafsky, D. (2008b). Jointly combining implicit constraints improves temporal ordering. Proceedings 2008 Conference Empirical Methods Natural Language
Processing, pp. 698706, Honolulu, Hawaii. Association Computational Linguistics, Morristown, NJ, USA.
Collins, M., & Duffy, N. (2002). New ranking algorithms parsing tagging: Kernels
discrete structures, voted perceptron. Proceedings 40th Annual Meeting
Association Computational Linguistics, pp. 263270, Philadelphia, Pennsylvania, USA. Association Computational Linguistics.
Denis, P., & Muller, P. (2010). Comparison different algebras inducing temporal structure
texts. Proceedings Coling 2010, pp. 250258, Beijing.
Dubois, M. F., & Schwer, S. R. (2000). Classification topologique des ensembles convexes de Allen.
Proceedings Reconnaissance des Formes et Intelligence Artificielle (RFIA), Vol. III, pp.
5968.
Freksa, C. (1992). Temporal reasoning based semi-intervals. Artificial Intelligence, 54(1-2), 199
227.
Grover, C., Hitzeman, J., & Moens, M. (1995). Algorithms analysing temporal structure
discourse. Sixth International Conference European Chapter Association
Computational Linguistics. ACL.
Kameyama, M., Passonneau, R., & Poesio, M. (1993). Temporal centering. Proceedings ACL
1993, pp. 7077.
Kamp, H., & Reyle, U. (1993). Discourse Logic. Kluwer Academic Publishers.

410

fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION

La Poutr, J., & van Leeuwen, J. (1988). Maintenance transitive closures transitive reductions
graphs. Gttler, H., & Schneider, H.-J. (Eds.), Graph-Theoretic Concepts Computer
Science, Vol. 314 Lecture Notes Computer Science, pp. 106120. Springer Berlin / Heidelberg.
Lapata, M., & Lascarides, A. (2006). Learning Sentence-internal Temporal Relations. Journal
Artificial Intelligence Research, 27, 85117.
Mani, I., Pustejovsky, J., & Gaizauskas, R. (Eds.). (2005). Language Time: Reader. Oxford
University Press.
Mani, I., & Schiffman, B. (2005). Temporally Anchoring Ordering Events News. Pustejovsky, J., & Gaizauskas, R. (Eds.), Time end Event Recognition Natural Language. John
Benjamin.
Mani, I., Verhagen, M., Wellner, B., Lee, C. M., & Pustejovsky, J. (2006). Machine learning
temporal relations. Proceedings 21st International Conference Computational
Linguistics 44th Annual Meeting Association Computational Linguistics, pp.
753760, Sydney, Australia. Association Computational Linguistics.
Mani, I., Wellner, B., Verhagen, M., & Pustejovsky, J. (2007). Three Approaches Learning TLINKs
TimeML. Tech. rep., Computer Science Department, Brandeis University. Waltham, USA.
Marcu, D., & Echihabi, A. (2002). unsupervised approach recognizing discourse relations.
Proceedings 40th Annual Meeting Association Computational Linguistics, pp.
368375, Philadelphia, Pennsylvania, USA. Association Computational Linguistics.
Muller, P., & Tannier, X. (2004). Annotating measuring temporal relations texts. Proceedings
20th International Conference Computational Linguistics (Coling 04), pp. 5056,
Geneva, Switzerland. COLING.
Passonneau, R. J. (1988). computational model semantics tense aspect. Computational
Linguistics, 14(2), 4460.
Pustejovsky, J., Hanks, P., Saur, R., See, A., Gaizauskas, R., Setzer, A., Radev, D., Sundheim, B.,
Day, D., Ferro, L., & Lazo, M. (2003). TIMEBANK Corpus. Proceedings Corpus
Linguistics, pp. 647656, Lancaster University, UK.
Reichenbach, H. (1947). Elements Symbolic Logic. McMillan, New York.
Rodrguez, A., de Weghe, N. V., & Maeyer, P. D. (2004). Simplifying Sets Events Selecting
Temporal Relations. Geographic Information Science, Third International Conference, GIScience 2004, Vol. 3234/2004 Lecture Notes Computer Science, pp. 269284, Adelphi,
MD, USA. Springer Berlin / Heidelberg.
Sagae, K. (2009). Analysis discourse structure syntactic dependencies data-driven shiftreduce parsing. Proceedings 11th International Conference Parsing Technologies
(IWPT09), Paris, France.
Saur, R., Littman, J., Knippen, R., Gaizauskas, R., Setzer, A., & Pustejovsky, J. (2006). TimeML
Annotation Guidelines, Version 1.2.1.. http://timeml.org/site/.
Schilder, F. (1997). hierarchy convex relations. Proceedings 4th International Workshop
Temporal Representation Reasoning (TIME 97), pp. 8693, Washington, DC, USA.
IEEE Computer Society.

411

fiTANNIER & ULLER

Setzer, A. (2001). Temporal Information Newswire Articles: Annotation Scheme Corpus
Study. Ph.D. thesis, University Sheffield, UK.
Setzer, A., Gaizauskas, R., & Hepple, M. (2006). Role Inference Temporal Annotation
Analysis Text. Language Resources Evaluation, 39, 243265.
Song, F., & Cohen, R. (1991). Tense interpretation context narrative. Proceedings
AAAI91, pp. 131136.
Sorlin, S. (2006). Mesurer la similarit de graphes. Ph.D. thesis, Universit Claude Bernard, Lyon I.
Speer, N., Zacks, J., & Reynolds, J. (2007). Human brain activity time-locked narrative event
boundaries. Psychological Science, 18(5), 449.
Steedman, M. (1997). Temporality. van Benthem, J., & ter Meulen, A. (Eds.), Handbook Logic
Language. Elsevier.
Steedman, M. (1995). Dynamic semantics tense aspect. Proceedings IJCAI95, pp.
12921298.
Subba, R., & Di Eugenio, B. (2009). effective discourse parser uses rich linguistic information.
Proceedings Human Language Technologies: 2009 Annual Conference North
American Chapter Association Computational Linguistics, pp. 566574, Boulder,
Colorado. Association Computational Linguistics.
Tannier, X., & Muller, P. (2008). Evaluation Metrics Automatic Temporal Annotation Texts.
ELRA (Ed.), Proceedings Sixth International Language Resources Evaluation
(LREC08).
Tatu, M., & Srikanth, M. (2008). Experiments Reasoning Temporal Relations
Events. Proceedings og 22nd International Conference Computational Linguistics
(Coling 2008), pp. 857864, Manchester, UK.
van Beek, P. (1992). Reasoning qualitative temporal information. Artificial Intelligence, 58(13), 297326.
Verhagen, M., Gaizauskas, R., Schilder, F., Hepple, M., Katz, G., & Pustejovsky, J. (2007). SemEval2007 - 15: TempEval Temporal Relation Identification. Proceedings SemEval workshop
ACL 2007, Prague, Czech Republic. Association Computational Linguistics, Morristown,
NJ, USA.
Vilain, M., Burger, J., Aberdeen, J., Connolly, D., & Hirschman, L. (1995). model-theoretic coreference scoring scheme. MUC6 95: Proceedings 6th conference Message understanding, pp. 4552, Columbia, Maryland, USA. Association Computational Linguistics,
Morristown, NJ, USA.
Vilain, M., Kautz, H., & van Beek, P. (1990). Constraint propagation algorithms temporal reasoning: revised report. Readings qualitative reasoning physical systems, pp. 373381.
Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.
Webber, B. L. (1988). Tense discourse anaphor. Computational Linguistics, 14(2), 6173.
Wellner, B., Pustejovsky, J., Havasi, C., Rumshisky, A., & Saur, R. (2006). Classification discourse
coherence relations: exploratory study using multiple knowledge sources. Proceedings
7th SIGdial Workshop Discourse Dialogue, pp. 117125, Sydney, Australia. Association Computational Linguistics.

412

fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION

Zwaan, R. A., & Razdvansky, G. A. (2001). Time narrative comprehension. Schram, D., &
Steen, G. (Eds.), Psychology Sociology Literature. John Benjamins, Amsterdam.
Zwaan, R. (2008). Time language, situation models, mental simulations. Language Learning,
58(s1), 1326.

413

fiJournal Articial Intelligence Research 40 (2011) 571-598

Submitted 11/10; published 03/11

Multiagent Learning Large Anonymous Games
Ian A. Kash

kash@seas.harvard.edu

Center Research Computation Society
Harvard University

Eric J. Friedman

ejf27@cornell.edu

Department Operations Research
Information Engineering
Cornell University

Joseph Y. Halpern

halpern@cs.cornell.edu

Department Computer Science
Cornell University

Abstract
large systems, important agents learn act eectively, sophisticated
multi-agent learning algorithms generally scale. alternative approach nd
restricted classes games simple, ecient algorithms converge. shown
stage learning eciently converges Nash equilibria large anonymous games bestreply dynamics converge. Two features identied improve convergence. First,
rather making learning dicult, agents actually benecial many
settings. Second, providing agents statistical information behavior others
signicantly reduce number observations needed.

1. Introduction
Designers distributed systems frequently unable determine agent
system behave, optimal behavior depends users preferences
actions others. natural approach agents use learning algorithm.
Many multiagent learning algorithms proposed including simple strategy update
procedures ctitious play (Fudenberg & Levine, 1998), multiagent versions Qlearning (Watkins & Dayan, 1992), no-regret algorithms (Cesa-Bianchi & Lugosi, 2006).
goal work help designers distributed systems understand
learning practical. discuss Section 2, existing algorithms generally unsuitable
large distributed systems. distributed system, agent limited view
actions agents. Algorithms require knowing, example, strategy chosen
every agent cannot implemented. Furthermore, size distributed systems requires
fast convergence. Users may use system short periods time conditions
system change time, practical algorithm system thousands millions
users needs convergence rate sublinear number agents. Existing
algorithms tend provide performance guarantees polynomial even exponential.
Finally, large number agents system guarantees noise. Agents
make mistakes behave unexpectedly. Even agent changes strategy,
still noise agent payos. example, gossip protocol match dierent

c
2011
AI Access Foundation. rights reserved.

fiKash, Friedman, & Halpern

agents round round; congestion underlying network may eect message delays
agents. learning algorithm needs robust noise.
nding algorithm satises requirements arbitrary games may
dicult, distributed systems characteristics make problem easier. First,
involve large number agents. agents may seem make learning
harderafter all, possible interactions. However, advantage
outcome action typically depends weakly agents do.
makes outcomes robust noise. large number agents also make less useful
agent try inuence others; becomes better policy try learn optimal
response. contrast, small number agents, agent attempt guide learning
agents outcome benecial him.
Second, distributed systems often anonymous; matter something, rather many agents it. example, congestion link,
experience single agent depend sending packets,
many sent. Anonymous games long history economics literature
(e.g., Blonski, 2001) subject recent interest computer science
literature (Daskalakis & Papadimitriou, 2007; Gradwohl & Reingold, 2008).
Finally, perhaps importantly, distributed system system designer
controls game agents playing. gives us somewhat dierent perspective
work, takes game given. need solve hard problem
nding ecient algorithm games. Instead, nd algorithms work
eciently interesting classes games, us interesting means type
games system designer might wish agents play. games well behaved,
since would strange design system agents decisions inuence
agents pathological ways.
Section 3, show stage learning (Friedman & Shenker, 1998) robust, implementable minimal information, converges eciently interesting class
games. algorithm, agents divide rounds game series stages.
stage, agent uses xed strategy except occasionally explores. end
stage, agent chooses strategy next stage whatever strategy
highest average reward current stage. prove that, appropriate conditions,
large system stage learners follow (approximate) best-reply dynamics1 despite errors
exploration.
games best-reply dynamics converge, theorem guarantees learners
play approximate Nash equilibrium. contrast previous results, convergence guarantee scales poorly number agents, theorem guarantees convergence nite amount time innite number agents. assumption
best-reply dynamics converge strong one, many interesting games converge best-reply dynamics, including dominance-solvable games, games monotone best
replies, max-solvable games (Nisan, Schapira, & Zohar, 2008). class max-solvable
games particular includes many important games Transmission Control Protocol
(TCP) congestion control, interdomain routing Border Gateway Protocol (BGP),
cost-sharing games, stable-roommates games (Nisan, Schapira, Valiant, & Zohar, 2011).
1. paper, consider best-reply dynamics agents update strategy time.
results best-reply dynamics assume agents update strategy one time.

572

fiMultiagent Learning Large Anonymous Games

Marden, Arslan, Shamma (2007a) observed convergence best-reply dynamics often property games humans design (although observation
slightly dierent notion best-reply dynamics). Moreover, convergence best-reply dynamics weaker assumption common assumption made mechanism design
literature, games interest dominant strategies (each agent strategy
optimal matter agents do).
Simulation results, presented Section 4, show convergence fast practice:
system thousands agents converge thousand rounds. Furthermore,
identify two factors determine rate quality convergence. One number
agents: agents makes noise system consistent agents
learn using fewer observations. giving agents statistical information
behavior agents; speed convergence order magnitude. Indeed,
even noisy statistical information agent behavior, relatively easy
obtain disseminate, signicantly improve performance.
theoretical results limited stage learning, provide intuition
well behaved learning algorithms also converge. simulations,
include two learning algorithms, bear out. Furthermore, demonstrate
applicability stage learning realistic settings, simulate results learning
scrip system (Kash, Friedman, & Halpern, 2007). results demonstrate stage
learning robust factors churn (agents joining leaving system)
asynchrony (agents using stages dierent lengths). However, stage learning robust
changes. include simulations games small number agents, games
anonymous, games continuous. games violate
assumptions theoretical results; simulations show that, games, stage
learning converges slowly all.
Finally, participants system necessarily behave expected. learning
useful real system, needs robust behavior. Section 5, show
continuity utility functions key property makes stage learning robust
Byzantine behavior small fraction agents.

2. Related Work
One approach learning play games generalize reinforcement learning algorithms
Q-learning (Watkins & Dayan, 1992). One nice feature approach
handle games state, important distributed systems. Q-learning,
agent associates value state-action pair. chooses action state ,
updates value (, ) based reward received best value
achieve resulting state (max ( , )). generalizing multiple agents,
become vectors state action every agent max replaced
prediction behavior agents. Dierent algorithms use dierent predictions;
example, Nash-Q uses Nash equilibrium calculation (Hu & Wellman, 2003). See
work Shoham, Powers, Grenager (2003) survey.
Unfortunately, algorithms converge slowly large distributed system.
algorithm needs experience possible action prole many times guarantee convergence. So, agents strategies, naive convergence time ( ). Even
573

fiKash, Friedman, & Halpern

better representation anonymous games, convergence time still ( ) (typically
). also fundamental problem approach: assumes information agent unlikely have. order know value update,
agent must learn action chosen every agent. practice, agent learn
something actions agents directly interacts, unlikely
gain much information actions agents.
Another approach no-regret learning, agents choose strategy round
guarantees regret choices low. Hart Mas-Colell (2000)
present learning procedure converges correlated equilibrium 2 given knowledge payos every action would round. also provide variant algorithm requires information agents actual
payos (Hart & Mas-Colell, 2001). However, guarantee convergence within
correlated equilibrium requires (/2 log ), still slow large systems. Furthermore, convergence guarantee distribution play converges equilibrium;
strategies individual learners converge. Many no-regret algorithms
exist (Blum & Mansour, 2007). Section 4, use Exp3 algorithm (Auer, CesaBianchi, Freund, & Schapire, 2002). achieve even better convergence restricted
settings. example, Blum, Even-Dar, Ligett (2006) showed routing games
continuum no-regret learners approximate Nash equilibrium nite amount
time. Jafari, Greenwald, Gondek, Ercal (2001) showed no-regret learners converge
Nash equilibrium dominance solvable, constant sum, general sum 2 2 games.
Foster Young (2006) use stage-learning procedure converges Nash equilibrium two-player games. Germano Lugosi (2007) showed converges generic
-player games (games best replies unique). Young (2009) uses similar algorithm without explicit stages also converges generic -player games. Rather
selecting best replies, algorithms agents choose new actions randomly
equilibrium. Unfortunately, algorithms involve searching whole strategy space,
convergence time exponential. Another algorithm uses stages provide
stable learning environment ESRL algorithm coordinated exploration (Verbeeck,
Nowe, Parent, & Tuyls, 2007).
Marden, Arslan, Shamma (2007b) Marden, Young, Arslan, Shamma (2009)
use algorithm experimentation best replies without explicit stages
converges weakly acyclic games, best-reply dynamics converge agents move
one time, rather moving once, assume here. Convergence based
existence sequence exploration moves lead equilibrium.
agents explore probability , analysis gives convergence time (1/ ).
Furthermore, guarantee requires suciently small agents essentially explore
one time, needs (1/).
Adlakha, Johari, Weintraub, Goldsmith (2010) independently given conditions
existence oblivious equilibrium, mean eld equilibrium, stochastic
games. model require game large, anonymous, continuous. oblivious equilibrium, player reacts average states
2. Correlated equilibrium general solution concept Nash equilibrium (see Osborne & Rubenstein, 1994); every Nash equilibrium correlated equilibrium, may correlated equilibria
Nash equilibria.

574

fiMultiagent Learning Large Anonymous Games

strategies players rather exact values. However, model assumes
players payo depends state players actions. Adlakha
Johari (2010) consider stochastic games strategic complementarities show
mean eld equilibria exist, best-reply dynamics converge, myopic learning dynamics
(which require knowledge aggregate states players) nd them.
long history work examining simple learning procedures ctitious
play (Fudenberg & Levine, 1998), agent makes best response assuming
players strategy characterized empirical frequency observed
moves. contrast algorithms convergence guarantees general games, algorithms fail converge many games. classes games converge,
tend rapidly. However, work area assumes actions
agents observed agents, agents know payo matrix, payos deterministic. recent approach tradition based Win Learn Fast principle,
limited convergence guarantees often performs well practice (Bowling &
Veloso, 2001). Hopkins (1999) showed many procedures converge symmetric
games innite number learners, although results provide guarantees
rate convergence.
also body empirical work convergence learning algorithms
multiagent settings. Q-learning empirical success pricing games (Tesauro &
Kephart, 2002), -player cooperative games (Claus & Boutilier, 1998), grid world
games (Bowling, 2000). Greenwald al. (2001) showed number algorithms,
including stage learning, converge variety simple games. Marden et al. (2009) found
algorithm converged must faster congestion game theoretical analysis
would suggest. theorem suggests explanation empirical observations: bestreply dynamics converge games. theorem applies directly
stage learning, provides intuition algorithms learn quickly enough
change behavior slowly enough rapidly converge Nash equilibrium practice.

3. Theoretical Results
section present theoretical analysis model. provide support
simulations following section.
3.1 Large Anonymous Games
interested anonymous games countably many agents. Assuming
countably many agents simplies proofs; straightforward extend results
games large nite number agents. model adapted Blonski (2001). Formally, large anonymous game characterized tuple = (, , , Pr).
countably innite set agents.
nite set actions agent choose (for simplicity, assume
agent choose set actions).
(), set probability distributions , two useful interpretations.
rst set mixed actions. abuse notation denote
575

fiKash, Friedman, & Halpern

mixed action probability 1 . round agent chooses one
mixed actions. second interpretation () fraction
agents choosing action . important notion anonymity,
says agents utility depend many agents choose
action rather chooses it.
= { : ()} set (mixed) action proles (i.e. action
agent chooses). Given mixed action every agent, want know fraction
agents end choosing action . , let ()() denote probability
agent plays according () ().We express fraction
agents choose action lim (1/) =0 ()(), limit exists.
limit exists actions , let () give value limit
. proles use determined simple random process.
proles , strong law large numbers (SLLN) guarantees probability
1 well dened. Thus typically well dened (using similar limits) us
talk fraction agents something.
nite set payos agents receive.
Pr : () ( ) denotes distribution payos results
agent performs action agents follow action prole . use probability
distribution payos rather payo model fact agent payos may
change even agent changes strategy. expected utility agent
performs

mixed action agents follow action distribution (, ) =

() Pr, (). denition Pr terms () rather
ensures game anonymous. require Pr (and thus ) Lipschitz
continuous.3 deniteness, use L1 norm notion distance
specifying continuity (the L1 distance two vectors sum absolute
values dierences component). Note formulation assumes
agents share common utility function. assumption relaxed allow
agents nite number types, show Appendix A.
example large anonymous game one where, round, agent plays
two-player game opponent chosen random. random matching games
common literature (e.g., Hopkins, 1999), meaning opponent chosen
random made formal (Boylan, 1992). game, set actions
two-player game set payos game. every agent chooses
action, distribution opponent actions characterized (). Let ,
denote payo agent plays agent plays . utility
mixed action given distribution

(, ) =
()( ), .
, 2

3. Lipschitz continuity imposes additional constraint constant Pr(, )
Pr(, )/ 1 . Intuitively, ensures distribution outcomes
change fast. standard assumption easily seen hold games
typically considered literature.

576

fiMultiagent Learning Large Anonymous Games

3.2 Best-Reply Dynamics
Given game action distribution , natural goal agent play
action maximizes expected utility respect : argmax (, ). call
action best reply . practical amount time, agent may diculty
determining two actions close expected utilities better, allow
agents choose actions close best replies. best reply ,
-best reply ( , ) + (, ). may one -best reply;
denote set -best replies ABR ().
single agent looking best reply; every agent trying nd one
time. agents start action distribution 0 , nd
best reply new action distribution 1 . assume 0 () = 1/ (agents
choose initial strategy uniformly random), results apply distribution
used determine initial strategy. say sequence (0 , 1 , . . .) -bestreply sequence support +1 subset ABR ( ); +1 gives positive
probability approximate best replies . best-reply sequence converges
exists > , = . Note particularly
strong notion convergence require converge nite time
merely limit. game may innitely many best-reply sequences, say
approximate best-reply dynamics converge exists > 0 every -bestreply sequence converges. limit distribution determines mixed strategy
-Nash equilibrium (i.e. support subset ( )).
main result shows learners successfully learn large anonymous games
approximate best-reply dynamics converge. number stages needed converge
determined number best replies needed sequence converges. possible design games long best-reply sequences, practice games
short sequences. One condition guarantees 0 degenerate action
distributions (i.e., distributions assign probability 1 ) unique
best replies. case, best replies equilibrium reached,
assumed agents utility function. Furthermore,
games distinction -best replies best replies irrelevant; suciently small , -best reply best reply. hard show property
degenerate strategies unique best replies generic; holds almost every game.
3.3 Stage Learners
agent wants nd best reply may know set payos , mapping
actions distributions payos Pr, action distribution (and, indeed,
may changing time), use type learning algorithm learn
it. approach divide play game sequence stages. stage,
agent almost always plays xed action , also explores actions.
end stage, chooses new next stage based learned.
important feature approach agents maintain actions entire stage,
stage provides stable environment agents learn. simplify
results, specify way exploring learning within stage (originally described
Friedman & Shenker, 1998), results generalize reasonable learning
577

fiKash, Friedman, & Halpern

algorithm used learn within stage. (We discuss reasonable Section 6.)
section, show that, given suitable parameter, stage agents
learned best reply environment stage.
Given game , round agent needs select mixed action , .
agents use strategies denote , , () = 1 ( = ) =
/( 1). Thus, , agent almost always plays , probability explores
strategies uniformly random. Thus far specied information
agent use choose ,. Dierent games may provide dierent information.
require agent know previous actions previous payos.
precisely, < , knows action () (which determined , )
payos () (which determined Pr(, , ), action distribution
round ; note assume agent knows .) Using information,
express average value action previous = 1/2 rounds (the length
stage).4 Let (, , ) = { < () = }
set recent rounds
played . average value (, , ) = (,,) ()/(, , )
(, , ) > 0 0 otherwise. need value times
multiples , convenience dene arbitrary times .
say agent -stage learner chooses actions follows. = 0,
chosen random { }. nonzero multiple , , = (, )
(, ) = argmax (, , ). Otherwise, , = ,1 . Thus, within stage, mixed
action xed; end stage updates use action highest average
value previous stage.
evolution game played stage learners deterministic; agent chooses
random ,0 sequence () () observes also random. However,
countably innite set agents, use SLLN make statements overall
behavior game. Let () = ,. run game consists sequence triples
( , , ). SLLN guarantees probability 1 fraction agents choose
strategy (). Similarly, fraction agents chose receive
payo Pr(, )() probability 1.
make notion stage precise, refer sequence tuples
( , , ) . . . ((+1) 1 , (+1) 1 , (+1) 1 ) stage run. stage
stationary action distribution denote . ,(+1) = ABR ( ),
say agent learned -best reply stage run. following lemma shows, suciently small , agents learn -best reply.
Lemma 3.1. large anonymous games , action proles, approximations > 0,
probabilities error > 0, exists > 0 < ,
agents -stage learners, least 1 fraction agents learn -best reply
stage .
Proof. (Sketch) average, agent using strategy plays action (1 ) times
stage plays actions /( 1) times each. large, realized number
times played close expectation value high probability. Thus,
suciently large, average payo action exponentially close
4. use exponent 2 arbitrary. require expected number times strategy
explored increases decreases.

578

fiMultiagent Learning Large Anonymous Games

true expected value (via standard Hoeding bound sums i.i.d. random variables),
thus learner correctly identify action approximately highest expected
payo probability least 1 . SLLN, least 1 fraction agents
learn -best reply. detailed version proof general setting found
work Friedman Shenker (1998).
3.4 Convergence Theorem
Thus far dened large anonymous games approximate best-reply dynamics
converge. agents game -stage learners, sequence 0 , 1 , . . .
action distributions run game best-reply sequence, close.
action used agents time action used
approximate best reply sequence.
order prove this, need dene close. denition based error rate
exploration rate introduces noise . Intuitively, distribution close
if, changing strategies fraction agents agents explore
fraction time, go action prole corresponding action distribution
one corresponding distribution . Note denition symmetric.
denition, identies (pure) action agent using leads ,
allows fraction agents use action, incorporates fact
agent exploring, strategy (the agent usually plays explores
probability ).
Denition 3.2. Action distribution (, )-close exist , ,
that:
= = ;
() ;
1 2 (this allows fraction agents play dierent strategy
);
, () = () = .
use nal requirement ensures two distributions (, )-close
also ( , )-close . example asymmetry
denition, (0, ) close , reverse true. (, )-closeness
useful distance measure analysis, unnatural notion distance specifying
continuity , used L1 norm. following simple lemma shows
distinction unimportant; suciently (, )-close close according
L1 measure well.
Lemma 3.3. (, )-close ,
1 2( + ).
Proof. Since (, )-close , exist , , Denition 3.2. Consider
distributions = , , = . view three distributions vectors,
calculate L1 distances. Denition 3.2, 1 2. 1 2
fraction agents explore. Thus triangle inequality, L1 distance
2( + ).
579

fiKash, Friedman, & Halpern

assumed approximate best reply sequences converge,
run game agents actually learning approximate best replies .
following lemma shows distinction matter suciently close.
Lemma 3.4. exists (, )-close , > 0, > 0,
+ < ABR (/2) (
) ABR ().
Proof. Let maximum Lipschitz constants (, ) (one constant
) = /(8). (, )-close , (, ) (, )

1 2/(8) = /4 Lemma 3.3.
Let
/ ABR () argmax ( , ). (, ) + < ( , ). Combining
gives (, ) + /2 < ( , ). Thus
/ ABR/2 (
).
Lemmas 3.1 3.4 give requirements (, ). statement theorem, call
(, ) -acceptable satisfy requirements lemmas /2 -best-reply
sequences converge .
Theorem 3.5. Let large anonymous game approximate best-reply dynamics
converge let (, ) -acceptable . agents -stage learners then,
runs, exists -best-reply sequence 0 , 1 , . . . stage least 1
fraction learn best reply probability 1.
Proof. 0 = 0 (both uniform distribution), 0 (, )-close . Assume
(, )-close . Lemma 3.1 least 1 fraction learn /2-best reply .
Lemma 3.4, -best reply . Thus +1 (, )-close +1 .
Theorem 3.5 guarantees nite number stages, agents close
approximate Nash equilibrium prole. Specically, (, )-close -Nash
equilibrium prole . Note means actually -Nash equilibrium
larger depends ,,, Lipschitz constant .
three requirements practical learning algorithm require minimal
information, converge quickly large system, robust noise. Stage learning
requires agent know payos, rst condition satised. Theorem 3.5 shows satises two requirements. Convergence guaranteed
nite number stages. number stages depends game, Section 3.2
argued many cases quite small. Finally, robustness comes tolerating
fraction errors. proofs assumed errors due learning,
analysis noise sources churn agents
making errors. discuss issue Section 6.

4. Simulation Results
section, discuss experimental results demonstrate practicality learning
large anonymous games. Theorem 3.5 guarantees convergence suciently small
exploration probability , decreasing also increases , length stage.
rst set experiments shows necessary values quite reasonable
practice. theorem applies stage learning, analysis provides intuition
580

fiMultiagent Learning Large Anonymous Games

reasonable algorithm changes slowly enough learners chance
learn best replies converge well. demonstrate this, also implemented two
learning algorithms, also quickly converged.
theoretical results make two signicant predictions factors inuence
rate convergence. Lemma 3.1 tells us length stage determined
number times strategy needs explored get accurate estimate
value. Thus, amount information provided observation large eect
rate convergence. example, random matching game, agents payo
provides information strategy one agent. hand,
receives expected payo matched, single observation provides information
entire distribution strategies. latter case agent learn many
fewer observations. related prediction agents lead faster
convergence, particularly games payos determined average behavior
agents, variance payos due exploration mistakes decreases
number agents increases. experimental results illustrate phenomena.
game used rst set experiments, like many simple games used test
learning algorithms, symmetric. Hopkins (1999) showed many learning algorithms
well behaved symmetric games large populations. demonstrate
main results due something symmetry, also tested stage learning
asymmetric game, observed convergence even small population.
explore applicability stage learning practical setting violates
number assumptions theorem, implemented variant stage learning
game based scrip system (Kash et al., 2007). demonstrate applicability
approach real systems, included experiments churn (agents leaving
replaced new agents) agents learning dierent rates.
Finally, give examples games large, anonymous, continuous, provide simulations showing stage learners learn far slowly
games satisfy hypotheses Theorem 3.5, learn play
equilibrium all. examples demonstrate assumptions essential
results.
4.1 Contribution Game
rst set experiments, agents play contribution game (also called Diamondtype search model work Milgrom & Roberts, 1990). contribution game,
two agents choose strategies 0 19, indicating much eort contribute
collective enterprise. value agent depends much contributes, well
much agent contributes. contributes contribution
agent , utility 4 ( 5)3 . round game, agent
paired random agent play contribution game. game, best-reply
dynamics converge within 4 stages starting distribution.
implemented three learning algorithms run game. implementation
stage learners described Section 3.3, = 0.05. Rather taking length
stage 1/2 , set = 2500 suciently long stages value , rather
decreasing stages long enough. second algorithm based

581

fiKash, Friedman, & Halpern

6
2 Agents
10 Agents
100 Agents

Distance Equilibrium

5

4

3

2

1

0

0

1

2

3

4

Time

5
4

x 10

Figure 1: Stage learners random matching.
3.5
2 Agents
10 Agents
100 Agents

Distance Equilibrium

3

2.5

2

1.5

1

0.5

0

1

2

3
Time

4

5
4

x 10

Figure 2: Hart Mas-Colell random matching.
Hart Mas-Colell (2001), improvements suggested Greenwald, Friedman,
Shenker (2001). algorithm takes parameters (the exploration probability).
used = 16 = 0.05. nal learning algorithm Exp3 (Auer et al., 2002).
set , exploration probability, 0.05. algorithm requires payos
normalized lie [0, 1]. Since choices strategies lead large negative
payos, naive normalization leads almost every payo close 1. better
performance, normalized payos payos fell range [0, 1]
outside set 0 1 appropriate.
results three algorithms shown Figures 1, 2, 3. curve
shows distance equilibrium function number rounds population
agents given size using given learning algorithm. results averaged
ten runs. Since payos nearby strategies close, want notion distance
take account agents playing 7 closer equilibrium (8) thanthose playing
zero. Therefore, consider expected distance equilibrium:
() 8.
determine , counted number times action taken length
582

fiMultiagent Learning Large Anonymous Games

5
2 Agents
10 Agents
100 Agents

4.5

Distance Equilibrium

4
3.5
3
2.5
2
1.5
1
0.5

0

1

2

3

4

Time

5
4

x 10

Figure 3: Exp3 random matching.
6
2 Agents
10 Agents
100 Agents

Distance Equilibrium

5

4

3

2

1

0

0

1

2

3
Time

4

5
4

x 10

Figure 4: Stage learning average-based payos.
stage, practice distance never zero due mistakes exploration.
ease presentation, graph shows populations size 100; similar results
obtained populations 5000 agents.
stage learning, increasing population size dramatic impact. two
agents, mistakes best replies results mistakes cause behavior quite
chaotic. ten agents, agents successfully learn, although mistakes suboptimal
strategies quite frequent. one hundred agents, agents converge quickly
near equilibrium strategies signicant mistakes rare.
Despite lack theoretical guarantees, two algorithms also converge, although
somewhat slowly. long-run performance Exp3 similar stage learning.
Hart Mas-Colells algorithm asymptotic convergence guarantees, tends
converge slowly practice tuned tight convergence. get converge
reasonable amount time tuned parameters accept somewhat weaker convergence
(although particular game shown dierence convergence dramatic).

583

fiKash, Friedman, & Halpern

1.8
2 Agents
10 Agents
100 Agents

1.6

Distance Equilibrium

1.4
1.2
1
0.8
0.6
0.4
0.2
0

0

0.5

1

1.5
Time

2

2.5
4

x 10

Figure 5: Stage learners congestion game.
Convergence stage learning random-matching game takes approximately 10,000
rounds, slow many applications. system design requires type
matching, makes learning problematic. However, results Figure 4 suggest
learning could done much faster system designer could supply agents
information. suggests collecting statistical information behavior
agents may critical feature ensuring fast convergence. model scenario,
consider related game where, rather matched random opponent,
agents contribute project reward based average contribution
agents. results stage learning game shown Figure 4.
much information available agents observation, able cut
length stage factor 10. number stages needed reach equilibrium
remained essentially same. Convergence tighter well; mistakes rare
almost distance equilibrium due exploration.
4.2 Congestion Game
dierent game, tested performance stage learners congestion game.
game models situation two agents share network link. gain utility
proportional transmission rate link, penalized based resulting
congestion experience. game asymmetric two dierent types
agents place dierent values transmission rate. game described detail
Greenwald, Friedman, Shenker (2001), showed no-regret learners able
nd equilibrium game. extension theoretical results games
multiple types presenting Appendix A.
Figure 5 shows stage learners able learn quickly game, using
stages length 250 even though randomly matched player
type. dierent types agents dierent equilibrium strategies,
distance measure use treat observed distribution strategies
equilibrium distribution vectors compute L1 distance.

584

fiMultiagent Learning Large Anonymous Games

1

Fraction Playing Equilibrium Strategy

0.9
0.8
0.7
0.6
0.5
0.4
0.3

Capacity 2
Capacity 4
Capacity 5

0.2
0.1
0

0

5

10
Number Stages

15

20

Figure 6: Stage learners TCP-like game.
4.3 TCP-like Game
previous example, considered random-matching game two agents
dierent types share link. consider game large number agents share
several links (this game variant congestion control game studied Nisan et al.,
2011).
three types agents using network. agent chooses integer rate
transmit 0 10. Links network maximum average rate
agents transmit; exceeded share capacity evenly among agents.
agents utility overall transmission rate network minus penalty
trac dropped due congestion. agent attempts transmit rate
actual rate penalty 0.5( ).5
agents share link average capacity 5. One third agents
constrained sharing link average capacity 2 another third share link
average capacity 4. game unique equilibrium agents rst
third choose rate 2, agents second third choose rate 4, agents
nal third choose rate 9 (so overall average rate 5). results game
best-reply dynamics converge stages uniform starting distribution.
Figure 6 shows results 90 learners (30 type) = 50000 = 0.01,
averaged ten runs. Agents constrained average capacity two quickly learn
equilibrium strategy, followed average capacity four. Agents constrained
average capacity learn equilibrium strategy, sawtooth pattern
small fraction alternately plays 10 rather 9. because, exploration,
actually optimal small number agents play 10. noticeable fraction
so, 9 uniquely optimal. demonstrates that, strictly speaking, game
satisfy continuity requirement. equilibrium, demand bandwidth exactly
equal supply. Thus, small changes demand agents due exploration
large eect amount actually demanded thus payos
5. penalty used work Nisan et al. (2011); using avoids tie-breaking issues
consider.

585

fiKash, Friedman, & Halpern

1

Fraction Playing Equilibrium Strategy

0.9
0.8
0.7
0.6
0.5
0.4
0.3
Type 1
Type 2
Type 3

0.2
0.1
0

0

5

10
Number Stages

15

20

Figure 7: Stage learners random TCP-like games.
various strategies. However, structure game play still tends
remain close equilibrium terms rates agents choose.
addition specic parameters mentioned above, also ran 100 simulations
three capacities randomly chosen integer 0 10. Figure 7
shows that, average, results similar. three types agents share common
constraint; type 1 type 2 additional constraint. Unsurprisingly, since
two types symmetric results almost identical. three types demonstrate
sawtooth behavior, type 3 runs due examples like Figure 6
fewer constraints gives agents exibility. primarily comes runs
type 1 type 2 constraints larger overall constraint (i.e.
overall constraint matters). Thus three types ability benet resources
demanded agents explore.
4.4 Scrip System Game
motivation work help designers distributed systems understand
learning practical. order demonstrate stage learning could applied
setting, tested variant stage learners model scrip system used
Kash et al. (2007). model, agents pay agents provide service
turn provide service earn money pay future service. Agents may place
dierent values receiving service (), incur dierent costs provide service (), discount
future utility dierent rates (), dierent availabilities provide service ().
used single type agent parameters = 1.0, = 0.05, = 0.9, = 1, average
amount money per agent = 1, stages 200 rounds per agent (only one agent
makes request round).
model large anonymous game whether agent provide
service depends much money currently has. Thus, stage learning specied
work, take account current state (stochastic) game.
Despite this, still implement variant stage learning: x strategy
stage end stage use algorithm designed game determine
586

fiMultiagent Learning Large Anonymous Games

1.6
10 Agents
100 Agents

1.4

Distance Equilibrium

1.2
1
0.8
0.6
0.4
0.2
0
0.2

0.4

0.6

0.8

1

1.2

1.4

1.6

1.8

Time

2
4

x 10

Figure 8: Stage learners scrip system.
1.6
10 Agents
100 Agents

1.4

Distance Equilibrium

1.2
1
0.8
0.6
0.4
0.2
0
0.2

0.4

0.6

0.8

1

1.2
Time

1.4

1.6

1.8

2
4

x 10

Figure 9: scrip system churn.
new strategy best reply agent observed. algorithm works
estimating agents probabilities making request chosen volunteer
round, uses probabilities compute optimal policy. Figure 8
shows quite eective. distance measure used based directly measuring
distance agents chosen (threshold) strategy equilibrium strategy, since
unlike previous games impossible directly infer agents strategy round
solely decision whether volunteer. Note number rounds
normalized based number agents Figure 8 later gures; stages actually
lasted ten times long 100 agents.
Real systems static population learning agents. demonstrate
robustness stage learning churn, replaced ten percent agents new agents
randomly chosen initial strategies end period. Figure 9 shows,
essentially eect convergence.

587

fiKash, Friedman, & Halpern

1.6
10 Agents
100 Agents

1.4

Distance Equilibrium

1.2
1
0.8
0.6
0.4
0.2
0
0.2

0.4

0.6

0.8

1

1.2
Time

1.4

1.6

1.8

2
4

x 10

Figure 10: scrip system dierent stage lengths.
Finally, real system often unreasonable expect agents able update
strategies time. Figure 10 shows half agents use stages
222 rounds per agent rather 200 signicant eect convergence.6
4.5 Learning Counterexamples
rst glance, Theorem 3.5 may seem trivial. game best-reply dynamics
guaranteed converge, seems obvious agents attempt nd best replies
successfully nd reach equilibrium. However, show section,
fact alone sucient. particular, three key features games
studythat large, anonymous, continuousare required theorem
hold.
First, game small number agents, mistake made single
agent could quite important, point learning essentially start over.
So, results converted results probability none
nite number agents make mistake given stage, expected time reach
equilibrium following algorithm signicantly longer best-reply dynamics
would suggest. following example game number best replies
needed reach equilibrium approximately number strategies, experimental
results show number stages needed stage learners nd equilibrium
signicantly longer. (We conjecture fact learning time exponentially longer.)
contrast, Theorem 3.5 guarantees that, games satisfying requirements, number
stages needed equal number best replies.
Consider game three agents, , set actions, {0, 1, . . . , }.
utility functions agents symmetric; rst agents utility function given
following table:
6. general expect small variations stage lengths aect convergence; however large
enough dierences result non-Nash convergence. See work Greenwald et al. (2001)
simulations analysis.

588

fiMultiagent Learning Large Anonymous Games

actions
(0, , )
(, , )
(0, 1, 0)
(0, 0, 1)
(1, 1, 0)
(1, 0, 1)
(, , )
(, , )
(, , )
(, , )

payo
1
0
0
0
1
1
1
0
1
0

conditions
= either > 1 > 1
= > 0 either > 1 > 1

= + 1
= + 1 <
=

Agents learning best replies viewed climbing ladder. best reply
(, , ) ( + 1, + 1, + 1) agents reach (, , ), Nash equilibrium.
However, mistake made, agents essentially start over. see works,
suppose agents (3, 3, 3) next stage one makes mistake
select (5, 4, 4). leads best reply sequence (5, 0, 0), (1, 0, 0), (1, 1, 1),
point agents begin climbing again. somewhat complicated structure payos
near 0 ensures agents begin climbing arbitrary patterns mistakes.
typical run, + 2 stages best replies needed reach equilibrium: one stage
initial randomly-chosen strategies, one stage three agents switch strategy 0,
stages climbing. exact number stages vary two agents choose
initial strategy, never greater + 3.
following table gives number rounds (averaged ten runs) stage learners
game rst reach equilibrium. number strategies varies, length
stage = 100( + 1), exploration probability = 0.05.
rounds reach
4
7.0
9
19.3
14
25.8
19
39.5
24
37.3
29
102.7
34
169.4
39
246.6
= 4, stage learners typically require + 2 stages, occasional error raising
average slightly. 9 24, majority runs feature least one agent
making mistake, number stages required closer 2. = 29 up,
many opportunities agents make mistake, number stages required
average range 3 6. Thus learning slower best-reply dynamics,
disparity grows number strategies increases.
small modication example shows problems arise games
anonymous. non-anonymous game large number agents, payos
depend entirely actions small number agents. example, split
set agents three disjoint sets, 0 , 1 , 2 , choose agents 0 0 , 1 1 ,
589

fiKash, Friedman, & Halpern

1
0.9
0.8

Fraction Playing 0

0.7
0.6
0.5
10 agents
100 agents
1000 agents

0.4
0.3
0.2
0.1
0

0

5

10
Number Stages

15

20

Figure 11: Stage learners discontinuous game.
2 2 . Again, agent chooses action {0, . . . , }. payos agents 0, 1,
2 determined above; everyone 0 gets payo 0, everyone 1
gets payo 1, everyone 2 gets payo 2. Again, convergence
equilibrium signicantly slower best-reply dynamics.
Finally, consider following game, large anonymous, satisfy
continuity requirement. set actions = {0, 1}, agent always receives
payo = {0, 1, 10}. agent chooses action 0, payo always 1 (Pr0, (1) = 1).
chooses action 1, payo 10 every agent chooses action 1, 10 every
agent chooses action 0, 0 otherwise (Pr1,(1,0) (10) = 1, Pr1,(0,1) (10) = 1,
Pr1, (0) = 1) {(1, 0), (0, 1)}).
game, suppose approximate best-reply dynamics start (0.5, 0.5) (each action
chosen half agents). coordinated, unique approximate best
reply agents action 0, one best reply, action distribution (1, 0).
Since agents coordinated, another round approximate best replies leads
equilibrium (0, 1). agents stage learners, rst stage learn
approximate best reply (0.5, 0.5) (exploration change action prole
case), adopt mixed action 0 : playing 0 probability 1 1
probability . Thus, even agents make mistake, action distribution next
stage least fraction playing action 1. Thus unique approximate best
reply action 0; stage learners stuck 0, never reach equilibrium
1.
Figure 11 shows fraction times strategy 0 played stage (averaged
ten runs) 10, 100, 1000 agents ( = 100 = 0.05). ten agents,
initial mistakes made, stage 10 strategy 0 played 2.5%
time runs, corresponds fraction time expect see simply
exploration. 100 agents see another sawtooth pattern agents
stuck playing 0, alternating rounds small fraction plays 1. happens
because, rounds playing 0, small fraction lucky explore 1
agents explore. result, adopt strategy 1 next stage. However,
not, following stage agents return playing 0. oscillating
590

fiMultiagent Learning Large Anonymous Games

behavior observed learning contexts, example among competing myopic
pricebots (Kephart, Hanson, & Greenwald, 2000). 1000 agents, lucky agents
quite rare, essentially agents constantly stuck playing 0.

5. Learning Byzantine Agents
practice, learning algorithms need robust presence agents
following algorithm. seen stage learning large anonymous games
robust agents learn instead follow xed strategy stage.
analysis, agents simply treated agents made mistake
previous stage. However, agent need follow xed strategy; agent attempting
interfere learning malicious reasons personal gain likely adapt
strategy time. However, show section, stage learning also handle
manipulation large anonymous games.
Gradwohl Reingold (2008) examined several classes games introduced
notion stable equilibrium one change strategy small fraction
agents small eect payo agents. denition
games nite number agents, easily adapted notion large
anonymous game. take notion step characterize game, rather
equilibrium, stable every strategy stable.
Denition 5.1. large anonymous game (, )-stable , ()
1 , (, ) (, ) .
One class games consider -continuous games. -continuity essentially
version Lipschitz continuity nite games, easy show large anonymous
games stable, amount manipulation tolerated depends
Lipschitz constants agents utility functions.
Lemma 5.2. large anonymous games , exists constant
, (, / )-stable
Proof. , (, ) Lipschitz continuous constant (, )
(, )/ 1 . Take = max . 1
/ ,
(, ) (, ) 1
1
(
)

( )

.

Gradwohl Reingold (2008) show stable equilibria several nice properties.
small fraction agents deviate, payos agent decrease much
relative equilibrium. Additionally, following strategies still approximate
591

fiKash, Friedman, & Halpern

equilibrium despite deviation. Finally, means strategies still constitute
approximate equilibrium even asynchronous play causes strategies fraction
agents revealed others.
show that, game stable, learning also robust actions small
fraction Byzantine agents. following lemma adapts Lemma 3.1 show that,
stage, agents learn approximate best replies despite actions Byzantine agents.
Thus agents successfully reach equilibrium, shown Theorem 3.5.
state lemma, need dene actions Byzantine agent.

Byzantine agents, stage would stationary strategy

corresponding fraction agents choosing action . fraction Byzantine agents
change actions arbitrarily round, eect
actions agents. Thus, Byzantine agents cause observed fraction
agents choosing strategy round 1 < 2. refer
sequence , . . . , ( +1)1 condition holds consistent
sequence. say agents learn -best reply stage , mean
, actions players
strategy learn approximate best reply
would used Byzantine players, actual action prole,
includes strategies used Byzantine players.
Lemma 5.3. large anonymous games , action distributions , approximations
> 0, probabilities error > 0, fractions agents < /6 , exists > 0
< , , consistent sequences , . . . , ( +1)1 , agents
-stage learners, least 1 fraction agents learn -best reply
stage despite fraction Byzantine agents.
Proof. Consider agent round stage . agents stage learners
action distribution would = . However, Byzantine agents changed
2. Fix action . Lemma 5.2,
(, ) (, ) 2 <

2

=
6
3

means Byzantine agents adjust agents expected estimate value
action /3. Let best reply (the action used stage learners
stage ). round stage ,
( , ) ( , ) <


.
3

action -best reply,
( , ) (, ) = (( , ) (, ) + ((, ) (, )) >


2
=
.
3
3

Thus, regardless actions fraction Byzantine agents, agent expected
estimate value exceeds expected estimate value least /3.
Using Hoeding bounds before, suciently large , estimates exponentially
close expectations, probability least 1 , select best
action -best reply. SLLN, means least 1 fraction
agents learn -best reply.
592

fiMultiagent Learning Large Anonymous Games

Thus, Lemma 5.3 shows, stage learners learn despite agents learning incorrect values, also tolerate suciently small number agents behaving
arbitrarily.

6. Discussion
results show natural learning algorithm learn eciently interesting class games, many issues merit exploration.
6.1 Learning Algorithms
theorem assumes agents use simple rule learning within stage:
average value payos received. However, certainly rules estimating value action; used long rule guarantees
errors made arbitrarily rare given sucient time. also necessary restrict
agents stage learning. Stage learning guarantees stationary environment period
time, strict behavior may needed practical. approaches,
exponentially discounting weight observations (Greenwald et al., 2001; Marden
et al., 2009) Win Learn Fast (Bowling & Veloso, 2001) allow algorithm focus
learning recent observations provide stable environment agents
learn.
6.2 Update Rules
addition using dierent algorithms estimate values actions, learner could
also change way uses values update behavior. example, rather
basing new strategy last stage, could base entire history
stages use rule spirit ctitious play. Since games ctitious
play converges best-reply dynamics not, could extend results another
interesting class games, long errors period accumulate time.
Another possibility update probabilistically use tolerance determine whether
update (see, e.g., Foster & Young, 2006; Hart & Mas-Colell, 2001). could allow
convergence games best-reply dynamics oscillate decrease fraction agents
make mistakes system reaches equilibrium.
6.3 Model Assumptions
model makes several unrealistic assumptions, notably countably
many agents share utility function. Essentially results holds
large, nite number agents, adding error terms. particular, since
always small probability every agent makes mistake time,
prove 1 fraction agents make errors rounds,
agents spend time playing equilibrium strategies.
also implicitly assumed set agents xed. Figure 9 shows,
could easily allow churn. natural strategy newly arriving agents pick
random use next stage. agents this, follows convergence
unaected: treat new agents part fraction made mistake
593

fiKash, Friedman, & Halpern

last stage. Furthermore, tells us newly arriving agents catch quickly.
single stage, new agents guaranteed learned best reply probability
least 1 .
Finally, assumed agents utility function. results
easily extended include nite number dierent types agents,
utility function, since SLLN applied type agent. extension
discussed Appendix A. believe results hold even set possible
types innite. happen, example, agents utility depends valuation
drawn interval. However, care needed dene best-reply sequences
case.
6.4 State
One common feature distributed systems addressed theoretical portion
work state. saw scrip system Section 4.4, agents current state
often important factor choosing optimal action.
principle, could extend framework games state: stage
agent chooses policy usually follow explores actions probability .
agent could use o-policy algorithm (one agent learn without
controlling sequence observations; see Kaelbling, Littman, & Moore, 1996 examples) learn optimal policy use next stage. One major problem
approach standard algorithms learn slowly purposes. example, Q-learning (Watkins & Dayan, 1992) typically needs observe state-action pair
hundreds times practice. low exploration probability means expected
/ rounds needed explore pair even large. Ecient learning requires
specialized algorithms make better use structure problem. However, use specialized algorithms makes providing general guarantee convergence
dicult. Another problem that, even agent explores action
possible local states, payo receives depend states agents,
thus actions chose. need property game guarantee
distribution states sense well behaved. Adlakha Joharis (2010) work
mean eld equilibria gives one condition. setting, use publicly available
statistics might provide solution problems.
6.5 Mixed Equilibria
Another restriction results agents learn pure strategies. One way
address discretize mixed strategy space (see, e.g., Foster & Young, 2006).
one resulting strategies suciently close equilibrium strategy bestreply dynamics converge discretized strategies, expect agents converge
near-equilibrium distribution strategies. empirical success using
approach learn play rock-paper-scissors.

594

fiMultiagent Learning Large Anonymous Games

7. Conclusion
Learning distributed systems requires algorithms scalable thousands agents
implemented minimal information actions agents.
general-purpose multiagent learning algorithms fail one requirements.
shown stage learning ecient solution large anonymous games
approximate best-reply dynamics lead approximate pure strategy Nash equilibria.
Many interesting classes games property, frequently found designed
games. contrast previous work, time convergence guaranteed theorem
increase number agents. system designers nd appropriate
game satisfying properties base systems, condent
nodes eciently learn appropriate behavior.
results also highlight two factors aid convergence. First, learners often improves performance. learners, noise introduced payos
exploration mistakes becomes consistent. Second, information typically improves performance. Publicly available statistics observed behavior
agents allow agent learn eectively making fewer local observations.
simulations demonstrate eects two factors, well results generalize
situations learning algorithms, churn, asynchrony, Byzantine behavior.
7.1 Acknowledgments
work done IK Cornell University. EF, IK, JH supported
part NSF grant ITR-0325453. JH also supported part NSF grant IIS-0812045
AFOSR grants FA9550-08-1-0438 FA9550-05-1-0055. EF also supported
part NSF grant CDI-0835706.

Appendix A. Multiple Types
section, extend denition large anonymous game settings
agents may dierent utility functions. so, introduce notion type.
Agents utilities may depend type fraction type taking action.
results rely strong law large numbers, restrict set types
nite. Formally, large anonymous game types characterized tuple =
(, , , , , Pr). dene , , , before. remaining terms:
nite set agent types.
: function mapping agent type.
before, () set probability distributions , viewed
set mixed actions available agent. now, describe fraction
agents type choosing action, must use element () .
Pr : () ( ) determines distribution payos results
agent type performs action agents follow action prole .
expected utility agent type performs mixed action agents

595

fiKash, Friedman, & Halpern



follow action distribution (, , ) = () Pr,, (). before,
require Pr (and thus ) Lipschitz continuous.
revised denitions -best reply, -Nash equilibrium, -best-reply sequence, convergence approximate best-reply dynamics, (, )-close follow naturally
revised denitions . Lemma 3.1 applies type agent separately, shows small fraction type learn approximate best
reply stage. Lemma 3.3 Lemma 3.4 hold given revised denitions
. Thus Theorem 3.5, combines these, also still holds.

References
Adlakha, S., & Johari, R. (2010). Mean eld equilibrium dynamic games complementarities. IEEE Conference Decision Control (CDC).
Adlakha, S., Johari, R., Weintraub, G. Y., & Goldsmith, A. (2010). Mean eld analysis
large population stochastic games. IEEE Conference Decision Control
(CDC).
Auer, P., Cesa-Bianchi, N., Freund, Y., & Schapire, R. E. (2002). nonstochastic multiarmed bandit problem. SIAM Journal Computing, 32 (1), 4877.
Blonski, M. (2001). Equilibrium characterization large anonymous games. Tech. rep.,
U. Mannheim.
Blum, A., Even-Dar, E., & Ligett, K. (2006). Routing without regret: convergence
Nash equilibria regret-minimizing algorithms routing games. 25th ACM
Symp. Principles Distributed Computing (PODC), pp. 4552.
Blum, A., & Mansour, Y. (2007). Learning, regret minimization, equilibria. Nisan,
N., Roughgarden, T., Tardos, E., & Vazirani, V. (Eds.), Algorithmic Game Theory,
pp. 79102. Cambridge University Press.
Bowling, M. H. (2000). Convergence problems general-sum multiagent reinforcement
learning. 17th Int. Conf. Machine Learning (ICML 2000), pp. 8994.
Bowling, M. H., & Veloso, M. M. (2001). Rational convergent learning stochastic
games. 17th Int. Joint Conference Articial Intelligence (IJCAI 2001), pp.
10211026.
Boylan, R. T. (1992). Laws large numbers dynamical systems randomly matched
indviduals. Journal Economic Theory, 57, 473504.
Cesa-Bianchi, N., & Lugosi, G. (2006). Prediction, Learning Games. Cambridge University Press.
Claus, C., & Boutilier, C. (1998). dynamics reinforcement learning cooperative
multiagent systems. AAAI-97 Workshop Multiagent Learning, pp. 746752.
Daskalakis, C., & Papadimitriou, C. H. (2007). Computing equilibria anonymous games.
48th Annual IEEE Symposium Foundations Computer Science (FOCS 2007),
pp. 8393.

596

fiMultiagent Learning Large Anonymous Games

Foster, D. P., & Young, P. (2006). Regret testing: Learning play Nash equilibrium without
knowing opponent. Theoretical Economics, 1, 341367.
Friedman, E. J., & Shenker, S. (1998). Learning implementation internet. Tech.
rep., Cornell University.
Fudenberg, D., & Levine, D. (1998). Theory Learning Games. MIT Press.
Germano, F., & Lugosi, G. (2007). Global Nash convergence Foster Youngs regret
testing. Games Economic Behavior, 60 (1), 135154.
Gradwohl, R., & Reingold, O. (2008). Fault tolerance large games. Proc. 9th ACM
Conference Electronic Commerce (EC 2008), pp. 274283.
Greenwald, A., Friedman, E. J., & Shenker, S. (2001). Learning networks contexts:
Experimental results simulations. Games Economic Behavior, 35 (1-2), 80
123.
Hart, S., & Mas-Colell, A. (2000). simple adaptive procedure leading correlated equilibrium. Econometrica, 68 (5), 11271150.
Hart, S., & Mas-Colell, A. (2001). reinforecement learning procedure leading correlated
equilibrium. Debreu, G., Neuefeind, W., & Trockel, W. (Eds.), Economic Essays,
pp. 181200. Springer.
Hopkins, E. (1999). Learning, matching, aggregation. Games Economic Behavior,
26, 79110.
Hu, J., & Wellman, M. P. (2003). Nash Q-learning general-sum stochastic games. Journal
Machine Learning Research, 4, 10391069.
Jafari, A., Greenwald, A. R., Gondek, D., & Ercal, G. (2001). no-regret learning,
ctitious play, nash equilibrium. Proc. Eighteenth International Conference
Machine Learning (ICML), pp. 226233.
Kaelbling, L. P., Littman, M. L., & Moore, A. P. (1996). Reinforcement learning: survey.
J. Artif. Intell. Res. (JAIR), 4, 237285.
Kash, I. A., Friedman, E. J., & Halpern, J. Y. (2007). Optimizing scrip systems: Eciency,
crashes, hoarders altruists. Eighth ACM Conference Electronic Commerce
(EC 2007), pp. 305315.
Kephart, J. O., Hanson, J. E., & Greenwald, A. R. (2000). Dynamic pricing software
agents. Computer Networks, 32 (6), 731752.
Marden, J. R., Arslan, G., & Shamma, J. S. (2007a). Connections cooperative
control potential games. Proc. 2007 European Control Conference (ECC).
Marden, J. R., Arslan, G., & Shamma, J. S. (2007b). Regret based dynamics: convergence
weakly acyclic games. 6th Int. Joint Conf. Autonomous Agents Multiagent
Systems (AAMAS), pp. 4249.
Marden, J. R., Young, H. P., Arslan, G., & Shamma, J. S. (2009). Payo-based dynamics
multi-player weakly acyclic games. SIAM Journal Control Optimization,
48 (1), 373396.

597

fiKash, Friedman, & Halpern

Milgrom, P., & Roberts, J. (1990). Rationalizability, learning, equilibrium games
strategic complement- arities. Econometrica, 58 (6), 12551277.
Nisan, N., Schapira, M., Valiant, G., & Zohar, A. (2011). Best-response mechanisms.
Proc. Second Syposium Innovations Computer Science (ICS). Appear.
Nisan, N., Schapira, M., & Zohar, A. (2008). Asynchronous best-reply dynamics.
Proc. 4th International Workshop Internet Netwrok Economics (WINE), pp.
531538.
Osborne, M., & Rubenstein, A. (1994). Course Game Theory. MIT Press.
Shoham, Y., Powers, R., & Grenager, T. (2003). Multi-agent reinforcement learning:
critical survey. Tech. rep., Stanford.
Tesauro, G., & Kephart, J. O. (2002). Pricing agent economies using multi-agent Qlearning. Autonomous Agents Multi-Agent Systems, 5 (3), 289304.
Verbeeck, K., Nowe, A., Parent, J., & Tuyls, K. (2007). Exploring selsh reinforcement
learning repeated games stochastic rewards. Journal Autonomous Agents
Multi-agent Systems, 14, 239269.
Watkins, C. J., & Dayan, P. (1992). Technical note Q-learning. Machine Learning, 8,
279292.
Young, H. P. (2009). Learning trial error. Games Economic Behavior, 65 (2),
626643.

598

fiJournal Artificial Intelligence Research 40 (2011) 353-373

Submitted 07/10; published 01/11

Clause-Learning Algorithms Many Restarts
Bounded-Width Resolution
Albert Atserias

atserias@lsi.upc.edu

Universitat Politecnica de Catalunya
Barcelona, Spain

Johannes Klaus Fichte

fichte@kr.tuwien.ac.at

Vienna University Technology
Vienna, Austria

Marc Thurley

marc.thurley@googlemail.com

University California Berkeley
Berkeley, USA

Abstract
offer new understanding aspects practical SAT-solvers based
DPLL unit-clause propagation, clause-learning, restarts. analyzing
concrete algorithm claim faithful practical solvers do. particular,
making new decision restart, solver repeatedly applies unit-resolution
rule saturation, leaves component mercy non-determinism except
internal randomness. prove perhaps surprising fact that, although
solver explicitly designed it, high probability ends behaving width-k
resolution O(n2k+2 ) conflicts restarts, n number
variables. words, width-k resolution thought O(n2k+2 ) restarts
unit-resolution rule learning.

1. Introduction
discovery method introduce practically feasible clause learning non-chronological backtracking DPLL-based solvers layed foundation sometimes called
modern SAT-solving (Silva & Sakallah, 1996; Bayardo & Schrag, 1997). methods
set ground new effective implementations (Moskewicz, Madigan, Zhao, Zhang, &
Malik, 2001) spawned tremendous gains efficiency SAT-solvers many
practical applications. great somewhat unexpected success seemed contradict
widely assumed intractability SAT, time uncovered need
formal understanding capabilities limitations underlying methods.
Several different approaches suggested literature developing rigorous understanding. Among find proof-complexity approach, captures
power SAT-solvers terms propositional proof systems (Beame, Kautz, & Sabharwal, 2003, 2004; Hertel, Bacchus, Pitassi, & Gelder, 2008; Pipatsrisawat & Darwiche,
2009), rewriting approach, provides useful handle reason
properties underlying algorithms correctness (Nieuwenhuis, Oliveras, &
Tinelli, 2006). approaches, SAT-solvers viewed algorithms search
proofs underlying proof system propositional logic. view mind,
illuminating understand proof system underlying modern solvers always
c
2011
AI Access Foundation. rights reserved.

fiAtserias, Fichte, & Thurley

subsystem resolution (Beame et al., 2003). particular, means performance never beat resolution lower bounds, time provides many
explicit examples SAT-solvers require exponential time. Complementing
result idealized SAT-solver relies non-determinism apply techniques
best possible way able perform good general resolution (weak forms
statement first established Beame et al., 2003, 2004; Hertel et al., 2008,
current form Pipatsrisawat & Darwiche, 2009). Beame et al. (2004) put it,
negative proof complexity results uncover examples inherent intractability even
perfect choice strategies, positive proof complexity results give hope finding
good choice strategy.
work add new perspective kind rigorous result. try avoid
non-deterministic choices components abstract solver still get positive proof
complexity results. main finding concrete family SAT-solvers
rely non-determinism besides mild randomness least powerful bounded-width
resolution. precise proof-complexity result unit-propagation rule
standard learning scheme considered state-of-the-art solvers, totally random decision strategy needs O(k 2 ln(kn)n2k+1 ) conflicts deterministic restarts
detect unsatisfiability CNF formula n variables width-k resolution
refutation, probability least 1/2. Remarkably, analysis provide exact expression upper bound holds values n k particular bound
get asymptotic. Another remarkable feature analysis insensitive
whether algorithm implements non-chronological backtracking heuristic-based decisions provided restarts often enough, provided performs totally random decisions
often enough. details given Section 2.
result nice theoretical consequences, shall sketch briefly.
First, although explicitly designed purpose, SAT-solvers able solve instances 2-SAT polynomial time since every unsatisfiable 2-CNF formula resolution
refutation width two. strongly, result interpreted showing widthk resolution simulated O(k 2 ln(kn)n2k+1 ) rounds unit-clause propagation.
knowledge, tight connection width-k resolution repeated application
width-one methods unknown before. Another consequence SAT-solvers
able solve formulas bounded branch-width (and hence bounded treewidth) polynomial time. elaborate later paper. Finally, partial automatizability
results Ben-Sasson Wigderson (1999), follows SAT-solvers able solve
formulas polynomial-size tree-like resolution proofs quasipolynomial time,
formulas polynomial-size general resolution proofs subexponential time.
Concerning techniques, perhaps surprising proof main result
proceed showing width-k refutation learned algorithm.
know produced proof much larger width. thing show
every width-k clause refutation absorbed algorithm, means
behaves learned, even though might not. particular, literal
complement absorbed, algorithm correctly declares formula
unsatisfiable. sort analysis main technical contribution paper.
354

fiClause-Learning Algorithms

1.1 Related Work
first attempt compare power SAT-solvers power resolution
proof system made Beame et al. (2003, 2004). main positive result
work clause learning specific learning scheme without restarts
provide exponentially shorter proofs proper refinements resolution tree,
regular, positive resolution. Furthermore, show modification standard
solver allow multiple assignments variable would able simulate general
resolution efficiently, assuming ideal decision strategy. Following work showed
requirement multiple assignments variable technical issue
avoided given CNF formula pre-processed appropriately (Hertel et al., 2008).
work avoid two maneuvers introducing concept clause-absorption
help us analyze standard algorithms directly.
Interestingly, clauses logical consequences input formulas, concept
clause-absorption turns dual concept 1-empowerment introduced
independently Pipatsrisawat Darwiche (2009)1 . used 1-empowerment show
SAT-solvers without conceptual modification operation able simulate
general resolution efficiently, assuming ideal decision strategy. comparison,
goal settles weaker simulation result, bounded-width resolution instead general
resolution, rely non-determinism ideal decision. show
totally random decision strategy good enough purpose, provided restart often
enough. complete point, worth noting non-automatizability results
Alekhnovich Razborov (2008) indicate cannot expect efficient simulation
general resolution completely avoid non-determinism time.
fact concepts discovered independently adds confidence belief
play role subsequent studies power SAT-solvers. Indeed,
techniques recently extended show SAT-solvers totally random decision
strategy able efficiently simulate local consistency techniques general constraint
satisfaction problems (Jeavons & Petke, 2010).
1.2 Organization
Section 2 introduce basic notation define algorithm analyze. also
discuss dependence results choice learning scheme, restart policy
decision strategy used algorithm. Section 3 starts elementary
facts runs algorithm, continues key definitions absorption
beneficial rounds, analysis running time algorithm. Section 4
contains discussion consequences, including implications formulas bounded
treewidth.

2. Clause Learning Algorithms
section define algorithm discuss choice components.
start preliminary definitions.
1. Note that, originally, weaker version 1-empowerment introduced Pipatsrisawat Darwiche
(2008).

355

fiAtserias, Fichte, & Thurley

2.1 Preliminaries
Let V = {v1 , . . . , vn } fixed set propositional variables. literal propositional
variable x negation x. use notation x0 x x1 x. Note xa
defined way assignment x = satisfies it. {0, 1}, also use
1 a, literal ` = xa use ` x1a . clause set literals,
formula conjunctive normal form (CNF-formula) set clauses. width
clause number literals it. following, formulas set
variables V every clause contains literals variables V .
two clauses = {x, `1 , . . . , `r } B = {x, `01 , . . . , `0s } define resolvent
B x Res(A, B, x) = {`1 , . . . , `r , `01 , . . . , `0s }. variable resolve on, x,
implicit simply write Res(A, B). clause may contain literal negation. Note
resolvent Res(A, B, x) B x still well-defined case. resolution
refutation CNF formula F sequence clauses C1 , . . . , Cm Cm =
clause Ci sequence either belongs F resolvent previous clauses
sequence. length refutation number clauses sequence.
clause C, variable x, truth value {0, 1}, restriction C x =
constant 1 literal xa belongs C, C \ {x1a } otherwise. write C|x=a
restriction C x = a.
partial assignment sequence assignments (x1 = a1 , . . . , xr = ar )
variables distinct. Let partial assignment. say satisfies literal xa
contains x = a. say falsifies contains x = 1 a. C clause, let
C| result applying restrictions x1 = a1 , . . . , xr = ar C. Clearly order
matter. say satisfies C satisfies least one literals; i.e.,
C| = 1. say falsifies C falsifies literals; i.e., C| = . set
clauses, let D| denote result applying restriction clause D,
removing resulting 1s. call D| residual set clauses.
2.2 Definition Algorithm
state sequence assignments (x1 = a1 , . . . , xr = ar ) variables

distinct assignments marked decisions. use notation xi = ai
denote assignment xi = ai decision assignment. case xi called
decision variable. rest assignments called implied assignments. use
denote states. empty state one without assignments. Define decision level
assignment xi = ai number decision assignments (x1 = a1 , . . . , xi = ai ).
convenient, identify state underlying partial assignment
decision marks ignored.
2.2.1 Operation
algorithm maintains current state current set clauses D. four
modes operation DEFAULT, CONFLICT, UNIT, DECISION. algorithm starts
DEFAULT mode empty state current state given CNF formula
current set clauses:
356

fiClause-Learning Algorithms

DEFAULT. sets variables satisfies clauses D, stop output
SAT together current state S. Otherwise, D|S contains empty clause,
move CONFLICT mode. Otherwise, D|S contains unit clause, move UNIT
mode. Finally, control reaches point, move DECISION mode.
CONFLICT. Apply learning scheme add new clause C D. C empty
clause, stop output UNSAT. Otherwise, apply restart policy decide whether
continue restart DEFAULT mode current initialized
empty state. case continue further, repeatedly remove assignments
tail long C|S = , go UNIT mode.
UNIT. unit clause {xa } D|S , add x = go back DEFAULT
mode.


DECISION. Apply decision strategy determine decision x = added
go back DEFAULT mode.

guarantee correctness termination, learning scheme always add clause C
logical consequence D, C|S = holds time added,
contains one variable maximum decision level. hard see
properties prevent clause learned twice, since number clauses
variables finite, implies termination. Clauses characteristics
always exist include asserting clauses (Zhang, Madigan, Moskewicz, & Malik,
2001) discussed Section 2.3.3.
well-known DPLL-procedure precursor algorithm where, CONFLICT
mode, learning scheme never adds new clause, restart policy dictate
restart all, assignments removed tail latest decision


assignment, say x = a, replaced x = 1 a. say DPLL-procedure
backtracks latest decision. contrast, modern SAT-solvers implement learning
schemes backtrack literal, determined learned clause, necessarily latest decision. called non-chronological backtracking. Besides learning
schemes non-chronological backtracking, modern SAT-solvers also implement restart
policies appropriate decision strategies. discuss choice components
algorithm Section 2.3.
2.2.2 Runs Algorithm
Consider run algorithm started DEFAULT mode empty state initial
set clauses D, either clause falsified variables set. run called
complete round started represent sequence states S0 , . . . , Sm
algorithm goes through, S0 empty state Sm state
either variables set, falsified clause found. generally, round
initial segment S0 , . . . , Sr complete round state either D|Sr contains
empty clause D|Sr contain unit clause. D|Sr contains empty clause
say round conclusive. round conclusive call inconclusive.
357

fiAtserias, Fichte, & Thurley

term inconclusive means reflect fact clause learned round.
particular, (complete) round ends satisfying assignment inconclusive2 .
round S0 , . . . , Sr , note {1, . . . , r}, state Si extends Si1 exactly

one assignment form xi = ai xi = ai depending whether UNIT DECISION
executed iteration; mode assigns variables. lead
confusion, identify round last state interpreted partial assignment.
particular, say round satisfies clause C C|Sr = 1, falsifies
C|Sr = .
2.3 Restart Policy, Learning Scheme, Decision Strategy
following discuss choice learning scheme, restart policy
decision strategy used algorithm. discussion particularly focus
dependence results choice.
2.3.1 Restart Policy
restart policy determines whether restart search clause learned.
important characteristic need restart policy dictate
restarts often enough. particular, analysis work equally well aggressive restart policies, one dictates restart every conflict,
less aggressive strategy allows bounded number conflicts restarts.
fact analysis insensitive follow monotonicity property
performance algorithm prove Lemma 5. precisely,
follow monotonicity lemma decide use policy allows c > 1
conflicts restart, upper bound number required restarts
decrease (or stay same). upper bound number conflicts would
appear multiplied factor c, even though truth might even decrease
well. simplicity exposition, rest paper assume restart
policy dictates restart every conflict.
2.3.2 Decision Strategy
decision strategy determines variable assigned next, value. Again,
important characteristic need decision strategy
allow round totally random decisions often enough. Here, totally random decision
defined follows: current state algorithm S, choose variable x
uniformly random among variables V appear S, value
{0, 1} also uniformly random independently choice x. Thus, analysis
actually applies decision strategy allows bounded number rounds
heuristic-based decisions totally random ones. precisely, allow say c > 1
rounds non-random decisions random ones, number required restarts
conflicts would appear multiplied factor c. follow
2. Let us note definitions round, conclusive round inconclusive round differ slightly
given conference version paper (Atserias, Fichte, & Thurley, 2009). current
definitions make concepts robust.

358

fiClause-Learning Algorithms

monotonicity lemma referred above. said, simplicity exposition assume
following every decision totally random.
2.3.3 Learning Scheme
learning scheme determines clause added set clauses
conflict occurs. Let S0 , . . . , Sr conclusive round started set clauses

ends falsifying clause D. Let xi = ai xi = ai i-th assignment
round. annotate Si clause Ai reverse induction {1, . . . , r}:
1. Let Ar+1 clause falsified Sr .


2. r xi = ai decision, let Ai = Ai+1 .
3. r xi = ai implied, let Bi clause Bi |Si1
unit clause {xai }, let Ai = Res(Ai+1 , Bi , xi ) clauses resolvable
xi , let Ai = Ai+1 otherwise.
quite clear construction Ai resolution proof clauses
D. fact, resolution proof linear even trivial sense Beame et al.
(2004). call clause Ai conflict clause. denotes maximum decision level
assignments Sr , conflict clause called asserting clause contains exactly
one variable decision level d. Asserting clauses, originally defined Zhang et al. (2001),
capture properties conflict clauses learned virtually modern SAT-solver.
brevity, describe two concrete learning schemes detail. schemes see
work Zhang et al. (2001).
Decision learning scheme adds clause A1 current set clauses
conflict. hard check A1 asserting clause. Furthermore, every literal
A1 negation decision literal Sr ; important later on.
1UIP learning scheme, stands 1st Unique Implication Point, one adds
clause Ai r maximal subject condition Ai asserting
clause.
following assume, tacitly, algorithm employs asserting
learning scheme, is, one whose learned clauses always asserting, except
empty clause.
2.3.4 Clause Bookkeeping
mentioned analysis relies crucially assumption learned
clauses never removed current set clauses. However, practical SAT-solvers
periodically delete learned clauses save memory avoid overhead
introduce. Thus interesting question whether results made work
without assumption. respect, strong proof-complexity results Nordstrom
(2009) showing every small-width resolution refutation made work
small clause-space seems indicate assumption similar indeed needed.
Another remark worth making point concerns width learned clauses.
Since goal show algorithm simulate small-width resolution, seems
natural ask whether restrict learning scheme learn clauses small width
359

fiAtserias, Fichte, & Thurley

only. mentioned introduction, analysis seem allow it. Moreover,
recent results Ben-Sasson Johannsen (2010) show that, general, learning short
clauses provably weaker scheme learning arbitrarily long clauses. Thus,
examples Ben-Sasson Johannsen (2010) small-width resolution
refutations therefore show keeping long clauses actually required
case, conceivable might.

3. Analysis Algorithm
section analyze running time algorithm. this,
however, introduce key technical concepts absorption beneficial
rounds, study important properties.
3.1 Runs Algorithm
Let R R0 rounds, let C clause. say R0 subsumes R if, decision
marks, every assignment R appears also R0 . say R R0 agree C
restrictions R R0 variables C equal: every variable C either unassigned
both, assigned value both. say R branches C decision
variables R variables C. Note properties agree C branches C
depend set variables C. define clauses simplify notation
later on.
prove two rather technical lemmas. goal show inconclusive rounds
robust respect order assignments made. example, first
lemma shows inconclusive round subsumes round agrees
decisions. fact need slightly stronger claim involves rounds two
different sets clauses.
Lemma 1. Let D0 sets clauses D0 , let C clause, let R0
inconclusive round started D0 . Then, every round R started branches
C agrees R0 C, holds R0 subsumes R.
Proof. Let R = (S0 , . . . , Sr ). induction i, prove every {0, . . . , r}, every
assignment Si also made R0 . = 0 nothing prove since S0 = . Let

> 0 assume every assignment Si1 also made R0 . Let x = x =
last assignment Si . Since R R0 agree C R branches C, every decision

assignment made R also made R0 . takes care case x = a. Suppose
last assignment x = Si implied. means exists clause
A|Si1 = {xa }. Since D0 every assignment made Si1 also
made R0 , necessarily x = appears R0 R0 inconclusive cannot leave
unit clauses unset.
next lemma shows universal quantifier conclusion previous
lemma void. addition, round chosen inconclusive.
Lemma 2. Let D0 sets clauses D0 , let C clause, let R0
inconclusive round started D0 . Then, exists inconclusive round R started
branches C agrees R0 C, R0 subsumes R.
360

fiClause-Learning Algorithms

Proof. Let R0 = (T0 , . . . , Tt ). Define {0, . . . , t} set indices i-th

assignment R0 assigns variable C. I, let xi = ai xi = ai i-th
assignment R0 .
construct round R = (S0 , . . . , Ss ) started inductively. Associated
Sj set Ij indices xi left unassigned Sj . Recall S0
empty state definition. Hence I0 = I. define following process:
1. Sj falsifies clause sets variables V set = j stop.
2. Otherwise, unit clause {xa } D|Sj let Sj+1 Sj plus x = a.
3. Otherwise, Ij non-empty, let minimum element Ij , let Sj+1

obtained adding decision xi = ai Sj .
none cases applies set = j stop process.
construction R valid round started D. Let us see R0 subsumes R: let
set literals made true decisions R. construction, R R0 agree
hence R0 subsumes R Lemma 1. Furthermore, R inconclusive: D0
R0 inconclusive, D|R0 contain empty clause, R0 subsumes
R, also D|R contain empty clause. Further, every variable C belongs
V R inconclusive, process stops = . Together fact R0
subsumes R, shows R R0 agree C. Note finally R branches C
construction.
3.2 Absorption
One key feature definition round inconclusive, residual set
clauses contain unit clauses and, particular, closed unit propagation.
means inconclusive round R started D, clause R
falsifies literals one, R must satisfy remaining literal, hence
well. Besides D, clauses may property, important enough
deserve definition:
Definition 3 (Absorption). Let set clauses, let non-empty clause let
xa literal A. say absorbs xa every inconclusive round started
falsifies \ {xa } assigns x a. say absorbs absorbs every
literal A.
Naturally, absorbs xa also say absorbed xa .
Intuitively, one way think absorbed clauses learned implicitly. rest
section devoted make intuition precise. now, let us note
inconclusive rounds started D, every clause absorbed. agrees
given intuition since absence inconclusive rounds means unit-clause propagation
applied produces empty clause. section also show notion
clause-absorption tightly connected concept 1-empowerment independently
introduced Pipatsrisawat Darwiche (2009).
361

fiAtserias, Fichte, & Thurley

3.2.1 Properties Absorption
continue, let us discuss key properties absorption. argued already
every clause absorbed D. give example showing may absorb
clauses. Let set consisting three clauses
b

bc

b e.

example, clause c belong absorbed since every inconclusive round sets = 0 must set c = 1 unit-propagation, every inconclusive
round sets c = 0 must set = 1 also unit-propagation. may absorb
clauses saw, note every non-empty clause absorbed logical
consequence D. write |= C, every satisfying assignment satisfies C.
Lemma 4. Let set clauses let C non-empty clause. absorbs C,
|= C.
Proof. Let full assignment satisfies clauses D. want show
satisfies C well. Let R = (S0 , . . . , Sr ) complete round algorithm started
sets decision variables set S. induction {0, . . . , r},
show Si follow R stopped conflict therefore
Sr = S. particular R inconclusive, falsifies literals C one, must
satisfy remaining one C absorbed. Since R sets variables C Sr = S,
means satisfies C.
remains show Si every i. = 0 nothing show since

S0 = . Fix > 0 assume Si1 S. Let x = x = last assignment

Si . case x = taken care assumption decision variables R set
S. Suppose last assignment x = implied. means exists
clause A|Si1 = {xa }. Since satisfies Si1 S, necessarily x
set S.
Next, let us see converse lemma hold; namely, see
every implied clause absorbed. previous example, instance, note
bde consequence (resolve first third clause a) absorbed


(consider inconclusive round = 0, e = 0).
One interesting property illustrated example C resolvent
two absorbed clauses B, C absorbed literal `, ` appears
B. example above, absorb b e b, b appears
clauses b b e D, whose resolvent precisely b e.
prove general fact next section objects study non-absorbed
resolvents absorbed clauses.
Next show three key monotonicity properties clause-absorption, first
one motivated definition.
Lemma 5. Let E sets clauses let B non-empty clauses.
following hold:
1. belongs D, absorbs A,
362

fiClause-Learning Algorithms

2. B absorbs A, absorbs B,
3. E absorbs A, E absorbs A.
Proof. prove 1. assume contradiction literal ` inconclusive
round S0 , . . . , Sr started falsifies A\{`} satisfy A. round
inconclusive, cannot A|Sr = , means A|Sr = {`}, contradiction
definition round.
proof 2. let ` literal B define B 0 = B \ {`}. consider two
different cases. `
/ B 0 and, absorbed D, inconclusive
round falsifies B 0 . Thus B absorbed case. ` A, let A0 = \ {`} let
S0 , . . . , Sr inconclusive round started falsifies B 0 . falsifies A0
satisfies absorption. Thus satisfies B, B absorbed case well.
remains prove 3. Let ` literal A0 = \ {`}. Let R0
inconclusive round started E falsifies A0 . Lemma 2, inconclusive
round R started falsifies A0 subsumed R0 . absorbed
D, see R (and hence R0 ) satisfies A.
3.2.2 Absorption Empowerment
next goal show absorption empowerment dual notions. assignments , write every assignment also . Let us reproduce
definition 1-empowerment work Pipatsrisawat Darwiche (2009), slightly
adapted better suit notation terminology.
Definition 6 (1-Empowerment Pipatsrisawat & Darwiche, 2009). Let set
clauses, let C non-empty clause let xa literal C. Let assignment
sets = 1 b every literal b C \ {xa }. say C 1-empowering via xa
respect D, following three conditions met:
1. C logical consequence D; i.e. |= C,
2. repeated applications unit-clause propagation D| yield empty clause,
3. repeated applications unit-clause propagation D| assign x a.
also say xa empowering literal C. say C 1-empowering
1-empowering via literal C.
preliminary version definition given Pipatsrisawat Darwiche (2008)
second three conditions required.
definition absorption, see non-empty clause absorbed
set clauses D, inconclusive round R started literal xa
R falsifies \ {xa } satisfy {xa }. logical consequence
D, witnesses precisely fact 1-empowering via xa . show
converse also true:
Lemma 7. Let set clauses, let C non-empty clause |= C,
let xa literal C. Then, C 1-empowering via xa respect
absorb C xa .
363

fiAtserias, Fichte, & Thurley

Proof. Let C 0 = C\{xa }. Assume first absorb C xa . Let R = (S0 , . . . , Sr )
inconclusive round started witnessing fact, i.e. Sr falsifies C 0
assign x = a. particular Sr . Furthermore, every unit clause {y b } D|
= b Sr , R inconclusive round. straightforward induction,
see every obtained repeated applications unit-clause propagation
D| also satisfies Sr . directly implies conditions 2. 3. definition
1-empowerment. Condition 1. met assumption.
converse, assume C 1-empowering via xa respect D.
show inconclusive round started falsifies C 0 assign
x = a. Let R = (S0 , . . . , Sr ) round started every decision assignment
chosen falsify literal C 0 , that, among rounds property, assigns
many literals C 0 possible. Clearly maximal round exists since one
make decision meets property.
shall show R round seek. {0, . . . , r}, let
maximal assignment Si , let obtained repeated applications
unit-clause propagation D|i , let subset assignments
also Si . particular Si . shall prove, induction i, Si hence
Si = .
base case = 0 trivial since S0 = . Assume > 0 Si1 i1 .
i-th assignment Si decision assignment, construction falsifies literal
C 0 hence belongs . also belongs , required.
i-th assignment Si implied distinguish two cases: whether also belongs
not. implied assignment also , , required.
implied assignment , = i1 hence = i1 . then, since
Si1 i1 induction hypothesis i1 i1 , unit clause responsible
definition Si appears process forming i1 hence process forming
. Therefore assignment also .
completes induction shows, particular, Sr = r . point 2.
definition 1-empowerment, R inconclusive. Furthermore, point 3. definition
1-empowerment, Sr assign x = a. remains show Sr falsifies C 0 . First
note that, maximality R fact R inconclusive, every literal C 0
assigned R. Moreover, since decision assignments R chosen falsify
literals C 0 , suffices show implied assignments R satisfy literal
C 0 . Thus, suppose contradiction = b implied assigned R
b literal C 0 . Let {0, . . . , r} {y b } unit-clause D|Si . Since
Si Sr r assigned 1 b , unit-clause {y b } D|Si appears
empty clause closure unit-clause propagation D| ; contradicts point 2.
definition 1-empowerment completes proof.

Let us note point condition 1. definition 1-empowerment
dropped, hypothesis |= C also dropped Lemma 7. would
make 1-empowerment absorption literally dual other.
364

fiClause-Learning Algorithms

3.3 Beneficial Rounds
shall study key situation explains algorithm possibly simulate
resolution proofs. Consider resolvent C = Res(A, B) two absorbed clauses B
itself, however, absorbed. goal study A, B C look like
case. start showing C absorbed literal ` C, `
appears B. property held key discovering concept clauseabsorption relevance simulation resolution proofs. similar connection
clause learning observed Pipatsrisawat Darwiche (2008), also pointed
condition literal C appears B known merge
resolution (Andrews, 1968).
Lemma 8. Let set clauses, let B two resolvable clauses absorbed
D, let C = Res(A, B). ` literal C absorb C `, `
appears B.
Proof. Let C = Res(A, B, y), let A0 = \ {y} B 0 = B \ {y}. Let
` = xa literal C assume absorb C `. exists
inconclusive round R falsifies C \ {xa } set x a. Since ` belongs C
C = A0 B 0 ` belongs B, both. belongs both,
done. Otherwise, assume without loss generality belongs
B. case R falsifies B \ {y}, since B absorbed, set 0 R. R
falsifies \ {xa }, since absorbed, x set R. contradicts choice
R x set a.
continue showing situation interest, always exist beneficial
round algorithm predicts eventual absorption.
Definition 9 (Beneficial Round). Let set clauses, let non-empty clause,
let xa literal A, let R inconclusive round started D. say R
beneficial xa falsifies \ {xa }, branches \ {xa }, leaves x unassigned,

yields conclusive round extended decision x = . conclusive round obtained

extending R x = also called beneficial xa . say R beneficial
beneficial literal A.
words, round started beneficial xa witness
absorb xa , minimal property, yet yields conflict
x set wrong value. Thus, informally, beneficial round witness
almost absorbs xa .
Lemma 10. Let set clauses, let B two resolvable clauses
absorbed D, let C = Res(A, B). C non-empty absorbed D,
round started beneficial C.
Proof. identify literal xa C able build beneficial round C
xa .
Let C = Res(A, B, y), let A0 = \ {y} B 0 = B \ {y}. C
non-empty absorbed D, literal xa C inconclusive round R0
365

fiAtserias, Fichte, & Thurley

started falsifies C 0 = C \ {xa } set x a. Also x assigned
R0 since otherwise would falsify C, C = A0 B 0 absorbs
B, would satisfied R0 . shows x unassigned R0 .
Let R inconclusive round started obtained applying Lemma 2
C 0 given inconclusive round R0 . claim R beneficial C xa :
round R falsifies C 0 , agrees R0 C 0 . Also R branches C 0 and, R0 subsumes
R, leaves x unassigned. Finally, note R R0 also agree \ {y} B \ {y}.

Hence extending round R decision x = yields conclusive round; otherwise
would satisfied since B absorbed D.
3.4 Main Technical Lemma
start analyzing number complete rounds takes resolvent
two absorbed clauses absorbed function width. However, trivial
first determine number complete rounds takes sufficient prerequisite
absorption occurs: beneficial round.
Lemma 11. Let set clauses, let B two resolvable clauses
absorbed non-empty resolvent C = Res(A, B). Let n total
number variables D, k width C. every 1, let R0 , . . . , Rt1 denote
consecutive complete rounds algorithm started D, let D0 , . . . , Dt1
denote intermediate sets clauses. Then, probability none Ri beneficial
k
C none Di absorbs C et/(4n ) .
Proof. Let R0 , . . . , Rt1 denote consecutive complete rounds algorithm started
D, let D0 , . . . , Dt1 intermediate sets clauses. particular D0 =
Ri round started Di . every {0, . . . , 1} let Ri event Ri
beneficial let Di event Di absorb C. want compute
upper bound joint probability events. Note
"t1
# t1 "
# t1 "
#
j1
fi j1
fi
\


\
fi \
fi
Pr
Ri =
Pr Rj Dj fi
Ri
Pr Rj fi Dj
Ri
(1)
i=0

j=0

i=0

j=0

i=0

Hence, shall give appropriate upper bounds factors right hand side
inequality. this, let us first bound Pr Rj | Dj , Rj1 , Dj1 , . . . , R0 , D0
below. conditions Dj , Rj1 , Dj1 , . . . , R0 , D0 , Lemma 10 implies
inconclusive round R started Dj beneficial C xa C.
probability Rj beneficial C bounded probability Rj
beneficial C xa . therefore bound latter below.
First let us compute lower bound probability first k 1 decisions

decision strategy chosen falsify C \ {xa } k-th choice x = a. probability
choices made least






k1
k2
1
1
(k 1)!
1


k.
k
k
2n
2(n 1)
2(n k + 2)
2(n k + 1)
2 n
4n
Note round started Dj follows choices may even able
decisions corresponding assignments may implied. However,
366

fiClause-Learning Algorithms



decision x = made, round following choices perform decisions
agree R C \ {xa } therefore stay subsumed R every new decision,

Lemma 1. particular, right decision x = inconclusive, falsify
C \ {xa }, leave x unset. Also Lemma 1 performed assignments

R order, therefore addition x = make conclusive. follows
probability round beneficial C xa bigger.
Consequently, probability Rj conditional Dj , Rj1 , Dj1 , . . . , R0 , D0 bounded
1 4n1k . Therefore, equation (1)
Pr

"t1
\
i=0

#
Ri



1
k
1 k
et/(4n )
4n

second inequality used fact 1 + x ex every real number x.
3.5 Bounds
tools given above, able prove main result paper:
simulation width-k resolution algorithm. shall first give proof
algorithm employing Decision learning scheme. proof easier
instructive, also get slightly better bounds special case. Afterwards,
see result asserting learning schemes general.
3.5.1 Decision Scheme
fact makes Decision easier analyze that, learning scheme,
occurrence beneficial round immediately yields absorption next step. Indeed,
R beneficial C, branches C, means clause learned
complete round subset C. particular means next set clauses
absorb subset C, hence C well Lemma 5. obtain following result
direct consequence Lemma 11.
Lemma 12. Let set clauses, let B two resolvable clauses
absorbed non-empty resolvent C = Res(A, B). Let n total
number variables k width C. Then, 1, using Decision
learning scheme, probability C absorbed current set clauses
k
restarts et/(4n ) .
Proof. Let R0 , . . . , Rt1 denote consecutive complete rounds algorithm started
D, let D0 , . . . , Dt intermediate sets clauses. particular D0 =
Ri round started Di . every {0, . . . , 1} let Ri event
Ri beneficial C let Di event Di absorb C. one
Ri beneficial C, Di+1 absorbs C. see this, note R branches
C, clause Ci learned Ri satisfies Ci C. Hence Di+1 absorbs Ci C
Lemma 5. Further, Dt also absorbs C, one Di absorbs Lemma
5. Hence,
probability C absorbed Dt bounded Pr[ t1
i=0 Ri Di ].
k)
t/(4n
Lemma 11 implies bounded e
.
367

fiAtserias, Fichte, & Thurley

Theorem 13. Let F set clauses n variables resolution refutation
width k length m. probability least 1/2, algorithm started F , using
Decision learning scheme, learns empty clause 4m ln(4m)nk conflicts
restarts.
Proof. resolution refutation must terminate application resolution rule
form Res(x, x). show ` = x ` = x, probability
{`} absorbed current set clauses 4m ln(4m)nk restarts 1/4.
Thus, {x} {x} absorbed probability least 1/2. case,
straightforward every complete round algorithm conclusive. particular,
round make decision conclusive, case empty
clause learned.
Let C1 , C2 , . . . , Cr = {`} resolution proof {`} included width-k
resolution refutation F . particular r m1 every Ci non-empty width
k. Let D0 , D1 , . . . , Ds sequence clause-sets produced algorithm
= rt = d4 ln(4r)nk e. every {0, . . . , r}, let Ei event every
clause initial segment C1 , . . . , Ci absorbed Dit , let E negation. Note
Pr[ E0 ] = 1 vacuously hence Pr[ E 0 ] = 0. > 0, bound probability
Ei hold conditional Ei1 cases. Let pi = Pr[ E | Ei1 ] probability.
Ci clause F , pi = 0 Lemma 5. Ci derived two previous clauses,
k
pi et/(4n ) Lemma 12, 1/(4r) choice t.
law total probability gives






Pr E = Pr E | Ei1 Pr [Ei1 ] + Pr E | E i1 Pr E i1




Pr E | Ei1 + Pr E i1 .



P
Adding {1, . . . , r}, together Pr E 0 = 0, gives Pr E r ri=1 pi
r
1
4r = 4 . Since probability Cr absorbed Drt bounded Pr[ E r ],
proof follows.
3.5.2 Asserting Learning Schemes General
shall study algorithm applying arbitrary asserting learning scheme.
analysis bit complex Decision scheme since general clause
learned complete round R cannot assumed subset decisions R.
Therefore show resolvent eventually absorbed little detour.
note proof overcome similar difficulties as, inspired by3 , proof
Proposition 2 work Pipatsrisawat Darwiche (2009).
need preparation. Let C clause set clauses. Let WC,D
denote set literals ` C exists inconclusive round started
beneficial C `. Let u`,C,D denote number variables left unassigned
inconclusive round started beneficial C `. round
exists, define u`,C,D = 0. Note number well-defined, follows easily
3. thank anonymous reviewer pointing original proof Proposition 2 work
Pipatsrisawat Darwiche (2009) contained error corrected version paper
webpage. proof affected error.

368

fiClause-Learning Algorithms

Lemma 1 every inconclusive round started beneficial C ` leaves
number variables unassigned. Further, define
uC,D =

X

u`,C,D .

`WC,D

Note C absorbed D, WC,D = . Moreover, hypothesis
Lemma 10, converse also true. Analogously, C absorbed D, uC,D = 0
and, hypothesis Lemma 10, converse also true.
Lemma 14. Let D0 sets clauses D0 . Let B two resolvable
clauses absorbed D, let C = Res(A, B). Then, WC,D0 WC,D u`,C,D0
u`,C,D ` WC,D .
Proof. WC,D0 = , nothing shown. Otherwise, xa WC,D0 , start
showing xa belongs WC,D . Let R0 inconclusive round started D0
beneficial C `. Application Lemma 2 R0 C \{xa } yields inconclusive round
R started following properties: R0 subsumes R, agree C \ {xa },
R branches C \ {xa }. show R beneficial C xa , remains

prove extending R x = yields conclusive round. Let R round defined
extension. Let C = Res(A, B, y). R falsifies B \ {y} \ {y}.
absorption, R cannot inconclusive, otherwise, would satisfied R .
proves WC,D0 WC,D .
Now, show u`,C,D0 u`,C,D every ` WC,D . ` belong WC,D0
nothing shown since u`,C,D0 = 0 case. Otherwise, let R0 R inconclusive
rounds beneficial C ` R0 started D0 R started D.
Lemma 1, R0 subsumes R, finishes proof.
Lemma 15. Let set clauses, let B two resolvable clauses
absorbed D, let C = Res(A, B). Let R conclusive round started let
D0 obtained adding asserting clause learned R. C empty
R beneficial C ` C, u`,C,D0 < u`,C,D uC,D0 < uC,D .
Proof. Lemma 14 already know uC,D0 uC,D u`,C,D0 u`,C,D . Therefore,
suffices demonstrate that, presence R, second inequality strict.
hypothesis, R beneficial C `. Let C 0 asserting clause learned R.
Let R unique inconclusive round contained R beneficial C `;
round contain last decision made R. Lemma 1, number
assignments made two rounds started beneficial C `
same. Hence, number variables left unassigned R equals u`,C,D , u`,C,D 1
since least one variable unset.
u`,C,D0 = 0 already u`,C,D0 < u`,C,D . Therefore, assume u`,C,D0 1.
particular, exists inconclusive round R0 started D0 beneficial C
`. Lemma 1 round R0 subsumes R . definition asserting clauses, C 0 |R
unit clause, since C 0 belongs D0 , absorbed D0 hence R0 satisfies C 0 .
proves R0 sets least one variable R therefore u`,C,D0 < u`,C,D .
369

fiAtserias, Fichte, & Thurley

two technical lemmas hand ready state prove analogue
Lemma 12 arbitrary asserting learning schemes.
Lemma 16. Let set clauses, let B two resolvable clauses
absorbed non-empty resolvent C = Res(A, B). Let n total
number variables let k width C. Then, 1, using arbitrary
asserting learning scheme, probability C absorbed current set clauses
k
kn restarts kn et/(4n ) .
Proof. Let b = uC,D , = bt, let D0 , . . . , Ds sequence sets clauses
produced algorithm, starting D0 = D. every {0, . . . , b}, let Xi = uC,Dit
let Ei event Xi b i.
bound probability C absorbed Dbt above. Since
event implies Xb 6= 0, suffices bound Pr[ E b ]. Note Pr[ E0 ] = 1 vacuously
hence Pr[ E 0 ] = 0. > 0, bound probability Ei hold. law
total probability gives






Pr E = Pr E | Ei1 Pr [Ei1 ] + Pr E | E i1 Pr E i1




Pr E | Ei1 + Pr E i1 .
Let pi = Pr[ E | Ei1 ] note Pr[ E | Xi1 < b + 1 ] = 0. Hence pi
Pr[ E | Xi1 = b + 1 ]. Consider sequence D(i1)t+1 , . . . , Dit sets clauses
corresponding complete rounds algorithm. Conditional Xi1 = b + 1,
event E implies Xi = Xi1 6= 0 hence none sets clauses absorbs
C. Furthermore, Lemma 15, none corresponding rounds beneficial C. Thus,
k
Lemma 11, pi et/(4n ) . Adding {1, . . . , r}, together



Pb
k
Pr E 0 = 0, gives Pr E b i=1 pi b et/(4n ) . Lemma follows necessarily
b kn.
able prove main theorem.
Theorem 17. Let F set clauses n variables resolution refutation width
k length m. probability least 1/2, algorithm started F , using arbitrary asserting learning scheme, learns empty clause 4km ln(4knm)nk+1
conflicts restarts.
Proof. proof analogous proof Theorem 13 Lemma 16 playing role
Lemma 12, choosing = d4 ln(4m kn)nk e now.

4. Consequences

total number clauses width k n variables bounded 2k nk ,
2nk every n k. Therefore, F n variables resolution refutation width
k, may assume length 4nk following estimate

k

k
k
X
X
n 1
n

1+2
n = 1 + 2n
4nk .
2

n1
i=0

i=1

obtain following consequence Theorem 17.
370

fiClause-Learning Algorithms

Corollary 18. Let F set clauses n variables resolution refutation
width k. probability least 1/2, algorithm started F , using arbitrary
asserting learning scheme, learns empty clause 16k(k + 1) ln(16kn)n2k+1
conflicts restarts.
application Corollary 18 that, even though explicitly defined
purpose, algorithm used decide satisfiability CNF formulas treewidth
k time O(k 2 log(kn)n2k+3 ). follows known fact every unsatisfiable formula treewidth k resolution refutation width k + 1
(Alekhnovich & Razborov, 2002; Dalmau, Kolaitis, & Vardi, 2002; Atserias & Dalmau,
2008).
interested producing satisfying assignment exists, proceed
self-reducibility: assign variables one time, running algorithm log2 (n) + 1 times
assignment detect current partial assignment cannot extended
further, case choose complementary value variable. use
fact F treewidth k, F |x=a also treewidth k.
analysis, note since run algorithm correct probability least
1/2, new assignment correct probability least
1 2(log2 (n)+1) = 1

1
.
2n

means iterations correct probability least (1
running time algorithm O(k 2 (log(kn))2 n2k+4 ).

1 n
2n )



1
2.



Acknowledgments
thank Martin Grohe suggesting problem comparing power SAT-solvers
bounded-width resolution. also thank Knot Pipatsrisawat Adnan Darwiche
pointing connection 1-empowering absorption. Thanks also
Peter Jeavons comments conference version paper, anonymous
referees detailed comments.
first author supported part CYCIT TIN2007-68005-C04-03. second
author supported part European Research Council (ERC), Grant 239962.
third author supported part fellowship within Postdoc-Programme
German Academic Exchange Service (DAAD). preliminary version paper appeared
Proceedings 12th International Conference Theory Applications
Satisfiability Testing, SAT09 (Atserias et al., 2009).

References
Alekhnovich, M., & Razborov, A. A. (2002). Satisfiability, branch-width Tseitin tautologies. Proceedings 43rd Symposium Foundations Computer Science
(FOCS 2002), pp. 593603. IEEE Computer Society.
Alekhnovich, M., & Razborov, A. A. (2008). Resolution automatizable unless W[P]
tractable. SIAM J. Comput., 38 (4), 13471363.
371

fiAtserias, Fichte, & Thurley

Andrews, P. B. (1968). Resolution merging. J. ACM, 15 (3), 367381.
Atserias, A., & Dalmau, V. (2008). combinatorial characterization resolution width.
J. Comput. Syst. Sci., 74 (3), 323334.
Atserias, A., Fichte, J. K., & Thurley, M. (2009). Clause-learning algorithms many
restarts bounded-width resolution. Kullmann, O. (Ed.), Proceedings 12th
International Conference Theory Applications Satisfiability Testing (SAT),
Vol. 5584 Lecture Notes Computer Science, pp. 114127. Springer.
Bayardo, R. J., & Schrag, R. C. (1997). Using CSP look-back techniques solve real-world
SAT instances. Proceedings Fourtheenth National Conference Artificial
Intelligence (AAAI97), pp. 203208.
Beame, P., Kautz, H. A., & Sabharwal, A. (2003). Understanding power clause
learning. Gottlob, G., & Walsh, T. (Eds.), Proceedings Eighteenth International Joint Conference Artificial Intelligence (IJCAI-03), pp. 11941201. Morgan
Kaufmann.
Beame, P., Kautz, H. A., & Sabharwal, A. (2004). Towards understanding harnessing
potential clause learning. J. Artif. Intell. Res. (JAIR), 22, 319351.
Ben-Sasson, E., & Johannsen, J. (2010). Lower bounds width-restricted clause learning
small width formulas. Strichman, O., & Szeider, S. (Eds.), Proceedings 13th
International Conference Theory Applications Satisfiability Testing (SAT),
Vol. 6175 Lecture Notes Computer Science, pp. 1629. Springer.
Ben-Sasson, E., & Wigderson, A. (1999). Short proofs narrow - resolution made simple.
Proceedings Thirty-First Annual ACM Symposium Theory Computing
(STOC 1999), pp. 517526.
Dalmau, V., Kolaitis, P. G., & Vardi, M. Y. (2002). Constraint satisfaction, bounded
treewidth, finite-variable logics. CP 02: Proceedings 8th International
Conference Principles Practice Constraint Programming, pp. 310326, London, UK. Springer-Verlag.
Fox, D., & Gomes, C. P. (Eds.). (2008). Proceedings Twenty-Third AAAI Conference
Artificial Intelligence, AAAI 2008, Chicago, Illinois, USA, July 13-17, 2008. AAAI
Press.
Hertel, P., Bacchus, F., Pitassi, T., & Gelder, A. V. (2008). Clause learning effectively
p-simulate general propositional resolution.. Fox, & Gomes (Fox & Gomes, 2008),
pp. 283290.
Jeavons, P., & Petke, J. (2010). Local consistency sat-solvers. Proceedings
16th International Conference Principles Practice Constraint Programming
- CP 2010, Vol. 6308 Lecture Notes Computer Science, pp. 398413. Springer.
Moskewicz, M. W., Madigan, C. F., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineering efficient SAT solver. Proceedings 38th Design Automation Conference
(DAC01).
Nieuwenhuis, R., Oliveras, A., & Tinelli, C. (2006). Solving SAT SAT Modulo Theories: abstract DavisPutnamLogemannLoveland procedure DPLL(T).
Journal ACM, 53 (6), 937977.
372

fiClause-Learning Algorithms

Nordstrom, J. (2009). Narrow proofs may spacious: Separating space width
resolution. SIAM J. Comput., 39 (1), 59121.
Pipatsrisawat, K., & Darwiche, A. (2008). new clause learning scheme efficient unsatisfiability proofs.. Fox, & Gomes (Fox & Gomes, 2008), pp. 14811484.
Pipatsrisawat, K., & Darwiche, A. (2009). power clause-learning SAT solvers
restarts. Gent, I. P. (Ed.), Proceedings 15th International Conference
Principles Practice Constraint Programming - CP 2009, Vol. 5732 Lecture
Notes Computer Science, pp. 654668. Springer.
Silva, J. P. M., & Sakallah, K. A. (1996). Grasp - new search algorithm satisfiability.
Proceedings IEEE/ACM International Conference Computer-Aided Design,
pp. 220227.
Zhang, L., Madigan, C. F., Moskewicz, M. W., & Malik, S. (2001). Efficient conflict driven
learning boolean satisfiability solver. International Conference ComputerAided Design (ICCAD01), pp. 279285.

373

fiJournal Artificial Intelligence Research 40 (2011) 221-267

Submitted 06/10; published 01/11

Probabilistic Approach Maintaining Trust
Based Evidence
Yonghong Wang

yhwang@andrew.cmu.edu

Robotics Institute
Carnegie Mellon University
5000 Forbes Ave
Pittsburgh, PA 15213 USA

Chung-Wei Hang
Munindar P. Singh

chang@ncsu.edu
singh@ncsu.edu

Department Computer Science
North Carolina State University
Raleigh, NC 27695-8206 USA

Abstract
Leading agent-based trust models address two important needs. First, show
agent may estimate trustworthiness another agent based prior interactions.
Second, show agents may share knowledge order cooperatively assess
trustworthiness others. However, real-life settings, information relevant trust
usually obtained piecemeal, once. Unfortunately, problem maintaining
trust drawn little attention. Existing approaches handle trust updates heuristic,
principled, manner.
paper builds formal model considers probability certainty two
dimensions trust. proposes mechanism using agent update amount
trust places agents ongoing basis. paper shows via simulation
proposed approach (a) provides accurate estimates trustworthiness agents
change behavior frequently; (b) captures dynamic behavior agents.
paper includes evaluation based real dataset drawn Amazon Marketplace,
leading e-commerce site.

1. Introduction
Let us consider applications domains electronic commerce, social networks, collaborative games, virtual worlds populated multiple virtual characters.
applications exhibit two important common features: (1) naturally involve multiple
entities, real (humans businesses) fictional; (2) entities areor behave
areautonomous heterogeneous. reason, view entities
computational surrogates agents. success agent application, evaluated terms
quality experience enjoyed user economic value derived business, depends felicitous interactions among agents. Since agents functionally
autonomous, felicity interactions cannot centrally ensured. Further,
agent usually limited knowledge others interacts. Therefore,
agent relies upon notion trust identify agents interact.
c
2011
AI Access Foundation. rights reserved.

fiWang, Hang, & Singh

Given intended applications, narrow scope agents provide
consume services, also share information regarding trustworthiness
agents. assume agent behaves according fixed type, meaning although
behavior could complex, trustworthiness based incentives sanctions
might receive, behavior different toward different participants. One
imagine settings service encounters service provider selectively
favor customers. Hence, purpose trust model distinguish good
bad agents, directly cause agents behave good manner. Further,
assume setting empirical, meaning agents base extent trust
others upon outcomes prior interactions. level trust agent Alice places
agent Bob viewed Alices prediction Bob providing good service outcome
future. empirically reliable, Alice estimate Bobs trustworthiness based
past experience Bob. (1) parties agent deals may
alter behavior (2) agent receives information parties incrementally,
important agent able update assessments trust.
one would expect important subject, several researchers developed
formal ways represent reason trust. Interestingly, however, existing approaches
concentrate maintain representations. might seem researchers
believe heuristic approach would adequate. typical approach based
exponential discounting, requires programmer hand-tune parameters
discount factor.
paper contributes model method updating trust ratings light incremental evidence. Specifically, develops principled, mathematical approach maintaining trust historically (as way evaluate agents provide services) socially (as
way evaluate agents provide information agents). Further, paper
shows avoid hand-tuned parameter.
1.1 Technical Motivation
common way estimate trustworthiness provider evaluate probability
future service outcome good based number good service outcomes
provider past. However, traditional scalar representation (i.e., probability)
cannot distinguish getting one good outcome two interactions, getting
100 good outcomes 200 interactions. But, intuitively, significant difference
terms confidence one would place two scenarios.
reason, modern trust models define trust terms probability certainty
good outcome (Jsang & Ismail, 2002; Wang & Singh, 2007; Gomez, Carbo, & Earle,
2007; Teacy, Patel, Jennings, & Luck, 2006; Harbers, Verbrugge, Sierra, & Debenham, 2007;
Paradesi, Doshi, & Swaika, 2009). certainty measure confidence agent
may place trust information. Computing certainty help agent filter
parties insufficient information, even nominally probability
good outcome high. general, certainty trust value (a) increase
amount information increases fixed probability, (b) decrease number
conflicts increases fixed total number experiences (Wang & Singh, 2010).
222

fiA Probabilistic Approach Maintaining Trust Based Evidence

Open systems dynamic distributed. words, agent often needs
select service provider previous interaction. Referral networks
enable agents collect trust information service providers distributed manner
(Yu & Singh, 2002; Procaccia, Bachrach, & Rosenschein, 2007). referral network,
agent requests agents, called referrers, provide trust information service
provider. referrer lacks direct experience service provider, may refer
another (prospective) referrer. Existing trust models (e.g., Barber & Kim, 2001), specify
agent may aggregate trust information multiple sources (which could include
combination referrals direct interactions).
view referrals services referrers provide. Consequently,
agent ought able estimate referrers trustworthiness based quality
referrals provides. However, existing trust models lack principled mechanism
update trust placed referrer.
Besides, reflect dynamism agents time, discount factor needed
help trust models provide accurate predictions future behavior (Zacharia & Maes, 2000;
Huynh, Jennings, & Shadbolt, 2006). low discount factor, past behavior forgotten
quickly estimated trustworthiness reflects recent behavior. Conversely,
high discount factor, estimated trustworthiness considers emphasizes long-term
overall behavior rated agent. Different discount factors yield different accuracy
behavior predictions. Choosing proper discount factor different types agents
varied settings involves crucial trade-off accuracy evidence. trade-off,
however, drawn much attention trust research community.
propose probabilistic approach updating trust builds Wang Singhs
(2010) probability-certainty trust model. trust update method enriches Wang
Singhs trust model two ways. First, trust update applies estimating trustworthiness referrers based referrals provide. Second, method adjusts
discount factor dynamically updating dynamism agents without requiring
manual tuning.
select Wang Singhs trust model supports features
crucial purposes. One, defines trustworthiness agent evidence space,
representing trust using probability certainty. Two, defines certainty
amount trust placed agent increases amount evidence (if extent
conflict held constant) decreases increasing conflict (if amount evidence
held constant). Three, supports operators propagating trust referrals. Wang
Singh (2006) define mathematical operators propagating trust. incorporate
operators bases addressing specific technical problems computing trust
updates discounting referrers provide erroneous referrals.
1.2 Contributions
paper proposes principled, evidence-based approach agent update
amount trust places another agent. introduces formal definitions updating
trust placed studies mathematical properties. achieve self-tuning approach
trust updates, paper proposes new notion trust history, contrast
traditional notion discounting history via hand-tuned discount factor. paper
223

fiWang, Hang, & Singh

evaluates proposed approach (1) conceptually via comparison existing approaches
terms formal properties (2) via simulation different agent behavior profiles;
(3) respect data real-life marketplace. main outcomes
approach
require fine-tuning parameters hand, thereby reducing
burden system administrator programmer, also expanding range
potential applications include behavior profiles agents
known ahead time.
Yields precision estimating probability component trust.
Yields appropriate level certainty component trust existing
approaches. particular, recognizes effect conflict evidence
compute certainty based certainty input information.
robust agents provide wrong information.
1.3 Organization
rest paper organized follows. Section 2 provides essential technical
background approach. Section 3 introduces general model trust update
uniformly handles historical social updates. Section 4 introduces series trust
update methods culminating proposed method. Section 5 evaluates methods
theoretical grounds establishing theorems regarding desirable undesirable
properties. Section 6 specifies historical social update scenarios precisely. Section 7
conducts extensive experimental evaluation methods, including simulations
evaluation using real marketplace data Amazon. Section 8 studies literature. Section 9 concludes discussion directions future work. Appendix
presents proofs theorems.

2. Background Probabilistic Trust Representation
section introduces key background Wang Singhs (2007) approach
necessary understanding present contribution.
2.1 Probability-Certainty Distribution Function
Considering binary event hr, si, r represent number positive
negative outcomes, respectively. Let x [0, 1] probability positive outcome.
posterior probability evidence hr, si conditional probability x given
hr, si (Casella & Berger, 1990). conditional probability x given hr, si
f (x|hr, si) =

R1

g(hr,si|x)f (x)
g(hr,si|x)f (x)dx

R1

xr (1x)s
xr (1x)s dx

0

=

0

224

fiA Probabilistic Approach Maintaining Trust Based Evidence



g(hr, si|x) =



r+s r
x (1 x)s .
r
PCDF vs r

6

5

r=20,s=4

certainty

4
r=8,s=2

3

r=4,s=1

2
r=0,s=0
1

0

0

0.1

0.2

0.3

0.4

0.5
0.6
probability

0.7

0.8

0.9

1.0

Figure 1: Examples probability-certainty distribution functions, varying r s.
f (x) probability distribution function x, probability
positive outcome. signature
R 1 f given f : [0, 1] 7 [0, ). f
probability density, 0 f (x)dx = 1. Following Jsang (2001), interpret
probability probability probability-certainty distribution function
(PCDF). probability probability
positive outcome lies [x1 , x2 ] equals
R1
R x2
f
(x)dx
0
= 1. Figure 1 gives examples f (x)
10
x1 f (x)dx. mean value f
different numbers positive negative outcomes. Notice
evidence (i.e., hr, si = h0, 0i), obtain uniform distribution. evidence mounts,
distribution becomes focused around expected value.
aside, notice although consider integral values r
examples, actual values r would usually integral effect
discounting information received others remembered past interactions.
particular, possible total evidence positive less one, i.e., 0 < r +s <
1.
2.2 Trust Representation
Jsangs approach, Wang Singhs model represents trust values
evidence belief spaces. evidence space, trust value form hr, si,
r + > 0. Here, r 0 number positive experiences (that, say, agent Alice
agent Bob) 0 number negative experiences Bob. r
225

fiWang, Hang, & Singh

r
real numbers. Given hr, si, = r+s
expected value probability positive
outcome r + > 0 set = 0.5 r + = 0. belief space, trust
value modeled triple belief, disbelief, uncertainty weights, hb, d, ui,
b, d, u greater 0 b + + u = 1. intuitive terms, certainty c = 1 u
represents confidence placed probability. Trust values translated
evidence belief space.
Wang Singh (2007) differ Jsang (2001) definition certainty. Wang
Singhs definition based following intuition. Figure 1 shows hr, si = h0, 0i
know nothing, f uniform distribution probabilities x. is, f (x) = 1
x [0, 1] 0 elsewhere. reflects Bayesian intuition assuming equiprobable
prior. Intuitively, uniform distribution certainty 0. additional knowledge
acquired, probability mass shifts f (x) 1 values x
1 values x. reason, Wang Singh (2007) define certainty
area uniform distribution f (x) = 1.

Definition 1 certainty based evidence hr, si, given
c(r, s) =
=

R1

1
2
1
2

0

R1
0

|f (x) 1|dx
r



| R 1(xr (1x)s

x (1x) dx

0

1|dx

Certainty

1

0

.

9

0

.

8

0

.

7

0

.

6

0

.

5

0

.

4

0

.

3

0

.

2

0

1

0

0

2

0

0

3

0

0

4

0

0

5

0

0

6

0

0

7

0

0

8

0

0

9

0

0

1

0

0

0

Total number transactions ratio positive negative fixed

Figure 2: Certainty increases mounting evidence provided amount conflict
evidence held constant. X-axis measures total number outcomes,
equally positive negative.
Conflict evidence setting means evidence positive
negative. Thus conflict maximized r = minimized r zero.
Wang Singh (2007) prove certainty increases total number transactions
increases conflict fixed, Figure 2. also show certainty decreases
conflict increases total number transactions fixed, Figure 3.
226

fiA Probabilistic Approach Maintaining Trust Based Evidence

0

.

9

4

0

.

9

2

Certainty

0

.

9

0

.

8

8

0

.

8

6

0

.

8

4

0

.

8

0

2

.

8

0

.

7

8

0

.

7

6

0

.

7

4

0

1

0

2

0

3

0

4

0

5

0

6

0

7

0

8

0

9

0

1

0

0

Number positive transactions total number transactions fixed

Figure 3: Certainty decreases increasing conflict provided amount evidence
held constant. X-axis measures number positive outcomes
fixed total number outcomes.

2.3 Trust Propagation
real-life settings, agent (a prospective client) may lack direct experience another
agent (a prospective service provider) considers interacting. case,
client ask referrers trust referrals. referrer lacks direct experience, may
refer referrers, on. essential idea behind referral networks.
calculate trust referral networks? Many researchers studied
trust propagation. chosen framework, Wang Singh (2006) define mathematical
operators propagating trust, leverage present goals.
Wang Singh (2006) provide concatenation operator (similar Jsangs, 1998,
recommendation operator) enables client C compute much trust
place service provider based direct experience referrer R referral
provided R. idea that, compute trust S, C simply concatenates
trust R Rs report S. Definition 2 captures Wang Singhs concatenation
operator. setting, let MR = hrR , sR agent Cs trust referrer R. Here, cR
certainty determined trust value. Further, let MS = hr , Rs
report trust provider S. amount trust placed C
given MR MS .
Definition 2 Concatenation . Let MR = hbR , dR , uR MS = hb , , u two trust
values. MR MS = hbR b , bR , 1 bR b bR i.
handle situation C collects trust information one
source, use Jsangs aggregation operator (Jsang, 2001; Wang & Singh, 2007),
simply sums available evidence pro con. C use operator combine independent reports trust place S. Definition 3 captures aggregation operator.
setting, Mi = hri , si would trust C would place based exactly
227

fiWang, Hang, & Singh

one path C S. paths mutually independent, i.e., nonoverlapping, Cs
aggregate trust would given M1 . . . Mk .
Definition 3 Aggregation . Let M1 = hr1 , s1 M2 = hr2 , s2 two trust values.
Then, M1 M2 = hr1 + r2 , s1 + s2 i.

3. General Model Updating Trust
observed above, existing trust models provide suitable trust update
method agent may maintain trust places another agent. model,
trust updates arise two major settings, consolidate universal model
trust update. settings follows.
Trust update referrers, wherein agent updates trust places referrer
based accurate referrals are. way agent maintain
social relationship referrer.
Trust update trust history, wherein agent updates trust places
service provider tuning relative weight (discount factor) assigned service
providers past behavior respect current behavior. way
agent accommodate dynamism service provider.
Target
Trust
!rR , sR "

R
Compare

C
Client

Estimated Trust
!r , "


Actual Trust
!r, s"

Source

Figure 4: Schematic illustration generalized trust update approach. Throughout

r
R
, = r r+s , R = rRr+s
paper, use = r+s
R
Interestingly, approach treats settings variations common theme,
term general model updating trust. Figure 4 presents model,
summarizes process consisting following steps based client C, target R,
service provider S. client C seeks update amount trust hrR , sR C
places target R.
C estimates Rs trustworthiness (before update) hrR , sR i.
R reports Ss trustworthiness hr , i.
delivers outcome C obtains direct information estimate actual trustworthiness hr, si S.
228

fiA Probabilistic Approach Maintaining Trust Based Evidence

Using information (apparent) trustworthiness S, C determines
accuracy estimated trust value previously received R. Based
, empirical
measure Rs accuracy, C updates trust places R hrR
R
grounds.
Trust update methods differentiated compare estimated
actual trust values. rest section discusses general structure trust update
investigates trust update methods along shortcomings. Section 4
introduces preferred approach.
Let us follow setting Figure 4. accuracy estimated trust value defined
closeness estimated trust value hr , actual trust value hr, si. Instead
interpreting transaction (one estimation trust target) either good
bad, interpret q good 1 q bad transactions. Notice good bad
present context target providing estimates refers accuracy otherwise
estimates respect actual outcomes client receives service provider.
Thus targets estimate could good bad independently whether actual service
outcome good bad.
Thus, q reflects close estimation hr , actual trust hr, si. require
0 q 1 ranging perfectly inaccurate perfectly accurate referral. weight
assign estimation increase certainty. example, suppose
actual trustworthiness h10, 0i. Say, one target RA estimates Ss trustworthiness
h0, 1i another target RB estimates h0, 100i. estimates agree
trustworthy, RA claims much lower certainty (c(0, 1) = 0.25) RB
(c(0, 100) = 0.99). RA punished less RB estimates turn
inaccurate. And, similarly, rewarding case accuracy. Therefore, instead
treating transaction one transaction, treat c transactions, c < 1
certainty estimation. is, interpret estimation c q good
c (1 q) bad transactions.
addition, discount past transaction age (Zacharia & Maes, 2000; ?,
?, ?, ?, ?). let hrR , sR trust placed R C; hr , estimation
, updated trust placed R C. Algorithm 1 presents
c = c(r , ); hrR
R
modular specification generic trust update approach, highlighting key inputs
outputs. Let temporal discount factor. Based actual observations hr, si,
let q represent accurate estimation p represent bad estimation is.
specific approaches consider differ computes measure
accuracy, q.
Note assume client updates trust referral conducted
transactions service provider, r + > 0 case. hr, si = h0, 0i,
client cannot update trust according formulation, since discount update
certainty hr, si hr, si = h0, 0i, certainty 0. matter
hrR , sR = 0 update method. initialize hrR , sR predefined
number, example, h1, 1i h0, 0i. initial value corresponds prior distribution
trust. uniform distribution corresponds initial setting hrR , sR h0, 0i.
also set prior deem fit system. trust update referrers,
initialize hrR , sR h1, 1i (to suggest client willing consider referral
229

fiWang, Hang, & Singh

Algorithm 1: generalUpdate: Abstract method revise trust placed target
R.
input q, p, , c , hrR , sR i;
rR c q;
sR c p;
r + (1 )r ;
rR
R
R

sR sR + (1 )sR ;
, i;
return hrR
R
referrer) hr, si h0, 0i (to suggest client prior experience
provider). perform trust update client done transactions
service provider (i.e., r+s > 0). trust history setting, initialize hrR , sR
h0.9, 0.1i (to suggest client trust past experience little confidence)
hr, si h0, 0i (to suggest client prior experience provider).
let us consider certainty density function based hr, si, reflects
actual trustworthiness S. Here, f (x) probability (density) quality service
provided x.
xr (1 x)s
f (x) = R 1
(1)
r (1 x)s dx
x
0

density maximizes x = meaning likely provide service outcome
quality . Consider probability density function based estimation
hr , i, Rs estimate Ss trustworthiness reflects Rs assessment
quality provide. words, R expects provide service outcome
likely quality x = .

4. Trust Update Based Average Accuracy
Based background, study trust update problem systematically.
analyze shortcomings series approaches, culminating approach
yields characteristics desire.
4.1 Linear Update Shortcomings
Linear common trust update method, serves baseline comparison. Linear
defines accuracy absolute difference quality estimated trust
value hr , quality actual trust value hr, si. is,
q = 1 | |

(2)

Using Equation 2, construct two trust update methods, Linear-WS Jsang,
inserting q defined Linear general trust update model described Algorithm 1. Note that, Linear-WS Jsang use trust representations separate
definitions certainty, thereby yielding different trust update methods. Linear-WS,
shown Algorithm 2, adopts Wang Singhs notion certainty underlying trust (Definition 1), whereas Algorithm 3 depicts Jsang trust update method, certainty
230

fiA Probabilistic Approach Maintaining Trust Based Evidence









c defined rr+s+s +2 (Jsang, 2001). Jsang (1998) defines certainty rr+s+s +1 ,
yields little difference later work Jsang (2001) trust update. motivation
introducing Linear-WS help distinguish benefit trust update methods
benefit using Wang Singhs static trust representation. show below, Linear-WS (which combines Wang Singhs static model heuristic update)
performs worse proposed update methods, thereby establishing proposed
methods yield benefits beyond static model incorporate.
shortcoming Linear consider certainty. Consider agent
reports h0.1, 0.1i service provider little information provider
reports h90, 10i later gathered additional information. Suppose service
providers quality service indeed 0.9. agent accorded high
trust, since reports correct trust value service provider high certainty
reports wrong trust value low certainty. words, updating trust
agent, second referral given weight first one. However,
Linear treats referrals thus ends wrong updated trust value
agent.
Algorithm 2: Linear-WS: trust update method revise trust placed target
R.
input hr, si, hr , i, , hrR , sR i;


r
r+s



r
r +

q 1 | |
c c(r , )
return generalUpdate(q, 1 q, , c , hrR , sR i);

Algorithm 3: Jsang: trust update method revise trust placed agent R.
input hr, si, hr , i, , hrR , sR i;


r+1
r+s+2



r + 1
r + + 2

q 1 | |
c

r +
r + + 2

return generalUpdate(q, 1 q, , c , hrR , sR i);

231

fiWang, Hang, & Singh

4.2 Update Based Max-Certainty Shortcomings
Hang, Wang, Singh (2008) proposed Max-Certainty trust update method,
applies Wang Singhs trust representation. Max-Certainty supports interesting
features, suffers shortcomings, present approach avoids. MaxCertainty follows general update model Section 3, defines q Algorithm 4.
Algorithm 4: Max-Certainty: trust update method revise trust placed
target R.
input hr, si, hr , i, , hrR , sR i;


r
r+s



r
r +

q

r (1 )s
r (1 )s

c c(r , )
return generalUpdate(q, 1 q, , c , hrR , sR i);
intuition behind Algorithm 4s definition q follows. Equation 1,
)
q = ff(
() , since provide service likely quality
likely quality . is, q measures ratio likelihoods
service provided qualities , respectively. words, measure
accuracy q ratio probability computed estimate R respect
probability computed measurement made C itself. Figure 5 illustrates
computation.
malicious target (such referrer) present setting one wrong
over-confidentthat is, agent exaggerates amount evidence claims
behind report service provider. Although Max-Certainty tells us likely
target R trustworthy, sensitive malicious targets. Since combined
trust naturally weighed amount evidence, trust report malicious target
may falsely dominate truthful reports based apparently smaller amount evidence.
Max-Certainty, takes C long time pinpoint malicious target. example, suppose actual trustworthiness h2, 1i R reports h5, 5i. According
Max-Certainty, hrR , sR = h0.37, 0.07i. R reported trust h1000, 1000i,
hrR , SR would equal h0.79, 0.15i. words, Max-Certainty treats new evidence
confirmatory. Instead, claim report h1000, 1000i bad exaggerates available evidence thus highly misleading effect. particular, may
end overriding many accurate reports (of lower certainty). Therefore, consider
report h1000, 1000i inaccurate, treat evidence disconfirmatory.
observation leads following update approaches.
update formula based Max-Certainty, let Rs trust hr, si. r +
r
large, formula highly sensitive, since PCDF maximized x = = r+s
,
232

fiA Probabilistic Approach Maintaining Trust Based Evidence

3

.

5

.

5

3

c

e

r

p

2





r





n

b









b



l

e





n

















0

.

f

8

1






q





2

ne









n

1



.

5



r

e

c

c

e

r







n







e

n











f

1

p

r



b



b



l











0

.

6

q

0

.

5

0

0

.

1

0

.

2

0

.

3

0

.

4

0

p

r



b

.

5



0

b



l





.

6

0

.

7

0

.

8

0

.

9

1

.

0



Figure 5: Illustration trust update method Max-Certainty hr, si = h8, 2i
hr , = h6, 4i.

decreases quickly x deviates (in words, close x = , magnitude
slope high). example, let (actual) trustworthiness h800, 200i.
referrer reports h19, 6i, predicts quality 0.76. quite close
actual quality S, namely, 0.80. However, Max-Certainty yields hrR , sR = h0.06, 0.58i,
indicates Max-Certainty treats poor estimation.
4.3 Update Based Sensitivity Shortcomings
foregoing leads us another update method, term Sensitivity. intuition underlying Sensitivity identified Teacy et al. (2006). motivate Sensitivity,
consider Rs estimate, probability quality equals p, given


l(p) = R 1
0

pr (1 p)s



xr (1 x)s dx

Clearly, l(p) maximizes , means R estimates quality service
provided likely . normalize l( ) 1,


q =



r (1 )s
r (1 )s

(3)

measures likely Rs assessment would quality service provider .
Figure 6 illustrates formulas using hr, si = h8, 2i hr , = h6, 4i. Returning previous example, hrR , sR = h0.01, 0.93i, means Sensitivity
considers h1000, 1000i inaccurate reportas should.
Although Sensitivity improves Max-Certainty, like Max-Certainty, remains susceptible excessively sensitive number transactions large. numerical
233

fiWang, Hang, & Singh

3

2

.

5

c

c

e

r







n







e

n













0

.

e

r







n







e

n













0

.

8

6

2









1



q

ne

c

e

r







n







e

e



n









f

u

n

c







n



1

.

5

b













n

(

6

,

4

)



n



r

e

c

1

0

.

5

q

0

0

.

1

0

.

2

0

.

3

0

.

4

0

p

r



b

.

5



0

b



l





.

6

0

.

7

0

.

8

0

.

9

1

.

0



Figure 6: Illustration trust update method based Sensitivity hr, si = h8, 2i
hr , = h6, 4i. Thus = 0.8 = 0.6.

example susceptibility Sensitivity presented Section 4.2. Let trustworthiness h800, 200i, whereas referrer reports h190, 60i. method,
incorporates uncertainty, yields hrR , sR = h0.24, 0.55i. words, treats referral bad. However, 190/(190 + 60) = 0.76 quite close 800/(800 + 200) = 0.80,
indicates ought treated good referralhence discrepancy.
problem Sensitivity treats referral disconfirmed evidence
simply referrer confident even though referral accurate. Theorem 3
Section 5 demonstrates problem, general setting.
bottom-line Max-Certainty Sensitivity produce undesirable results.
4.4 Average Accuracy Disregarding Uncertainty
foregoing discussion leads us penultimate step coming desired
approach. final approach (detailed Section 4.5) consider average
accuracy estimations. present variant simpler two
disregards uncertainty inherent belief regarding source S.
Suppose idealization actual trustworthiness source equals h, 1
, 0i, expressed belief-disbelief-uncertainty triple. case arises know
sure source provide quality service referral probability .
Therefore, uncertainty 0, indicating ideal case.
Figure 7 shows, suppose target reports trust value service provider
hr , i. Let c = c(r , ) certainty based hr , i. PCDF hr , means
target estimates provider produce quality x (0, 1) certainty
f (x):


f (x) = R 1
0

xr (1 x)s



xr (1 x)s dx
234

fiA Probabilistic Approach Maintaining Trust Based Evidence

providers actual quality x = . square estimation error x
(x )2 . multiply square error certainty f (x), integrate
x 0 1 obtain average square estimation error. square
root integration yields average error. is, calculate error
estimation according following formula:
v
uR 1
u xr (1 x)s (x )2 dx
e = 0 R1
r

0 x (1 x) dx
3

certainty density

2.5

2

certainty density function
based (6,4)
1.5

1

0.5

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0

probability

Figure 7: Illustration average trust update method r = 6 = 4, = 0.8
(dashed line). error e average length arrows.
many ways compute average errors, including L1 L norms,
on. use L2 norm simple mathematical properties. choice
unique common one (the variance) convenient manipulate
mathematically.
give alternative definition q based e, i.e., q = 1 e.
PCDF corresponding estimation hrR , sR i, see q corresponds average
accuracy estimation. updated estimate trustworthiness hrR , sR R based
q usual manner Algorithm 1.
4.5 Average Accuracy Incorporating Uncertainty
Let us consider complex variant method, uses q
definition above, explicitly incorporates uncertainty inherent belief
regarding S. Treating trust placed belief function uncertainty corresponding hr, si evidence space, would like discount updates rR sR
additional factor certainty actual observations hr, si made C.
235

fiWang, Hang, & Singh

Algorithm 5: Average- : trust update method revise trust placed agent R.
input hr, si, hr , i, , hrR , sR i;


r
r+s

c c(r, s)
q =1



(

r

(r + 1)(s + 1)
r + 1 2
) +

+s +2
(r + + 2)2 (r + + 3)
c c(r , )
c = cc

return generalUpdate(q, 1 q, , c , hrR , sR i);

words, would begin definition q discount certainty
determined hr, si. Algorithm 5 captures intuition.
reason consider certainty certain actual quality
S, certain evaluate targets estimation either,
discount update additional factor c. Returning previous example, let
trustworthiness h800, 200i, whereas target reports h19, 6i. method,
incorporates uncertainty, yields hrR , sR = h0.53, 0.06i, indicates
report good estimationas supposed since 19/(19 + 6) = 0.76,
quite close 800/(800 + 200) = 0.8. Therefore, close , matter large
total number transactions is, method considers targets estimation
confirmative. holds true general, Theorem 4 Section 5 shows.
4.6 Understanding Trade Offs
following tables illustrate pros cons update method. compare
accuracy measurements q used Max-Certainty (Algorithm 4), Sensitivity (Equation 3),
Average- (Algorithm 5).
Table 1 summarizes various situations interest, especially Max-Certainty
Sensitivity cannot handle well. explained Section 4.3, r + large, MaxCertainty highly sensitive, thus treats good report bad. r + large,
Sensitivity highly sensitive, also treats good report bad.
Table 2 provides numerical examples corresponding situations specified Table 1.
table, let actual quality service provider 0.50 quality indicated
referral 0.55.
4.7 Estimating Certainty
evaluate methods respect ability infer track
certainty incoming trust reports. Figure 8 compares q values produced different
trust update methods. -axis q, calculated different trust update methods
introduced above. estimates quality fixed 0.55 r + , amount
236

fiA Probabilistic Approach Maintaining Trust Based Evidence

Table 1: Comparing effectiveness trust update methods conceptually.
Case
r+s

r

small

Accuracy
+



Max-Certainty

Sensitivity

Linear

Average-

small

good

good

fair

good

small

large

good

poor

good

good

large

small

poor

good

fair

good

large

large

poor

poor

good

good

Table 2: Trust update methods comparison via numerical examples.
Case
hr, si

hr ,

h1, 1i

Accuracy (q)
Max-Certainty

Sensitivity

Linear

Average-

h1.1, 0.9i

0.99

0.99

0.95

0.78

h1, 1i

h220, 180i

0.99

0.13

0.95

0.95

h200, 200i

h1.1, 0.9i

0.13

0.99

0.95

0.78

h200, 200i

h220, 180i

0.13

0.13

0.95

0.95

evidence estimate, increases. left right plots show resulting q
actual quality hr, si = h1, 1i, hr, si = h200, 200i, respectively. Linear always high,
independent certainty report. Max-Certainty over-estimates q r +s low
under-estimates q r + high, vary certainty. Averages
estimate q reflects certainty reports cases.
4.8 Methods Summarized
Figure 9 illustrates trust update methods compare, including Jsang, LinearWS, Max-Certainty, Sensitivity, Average-. categorize methods respect
accuracy measurements underlying trust representation. Regarding
accuracy measurement technique, Jsang Linear-WS measure accuracy based
linear approach. Max-Certainty, Sensitivity, Average- defines specific
accuracy measurement. approaches Jsang follow Wang Singhs
trust representation.

5. Theoretical Evaluation Accuracy Measurement Techniques
section evaluates trust update methods theoretical terms consolidating
important technical results. may skipped first reading. section seeks
give technical intuitions results.
237

fiWang, Hang, & Singh

1
1

0.9
0.95

0.8

0.9

0.7
0.6

0.85

q

q

0.5

0.8

0.4
0.75

0.7

Average

0.3

MaxCertainty
LinearWS

0.2

0.65

0

Average
MaxCertainty
LinearWS

0.1

40

80

120

160

200

240

280

320

360

0
0

400

40

80

120

160

200

240

280

320

360

400

r+s

r+s

Figure 8: Comparison trust update methods based accuracy measurements q.
graphs use fixed referral expected quality = 0.55 vary amount
reported evidence r + . actual quality values hr, si low (set h1, 1i
left graph) high (set h200, 200i right graph), respectively.

Linear-WS

Max-Certainty

Sensitivity

Average-

Accuracy
Measurement

Linear

Max-Certainty

Sensitivity

Average

Trust
Representation

Jsang

Jsang

Wang & Singh

GeneralUpdate
Figure 9: Trust update methods specified terms trust representation
accuracy measurement methods.

Figure 9 shows, trust update method three main components. accuracy
measurement technique main contribution paper, one evaluate
theoretically.
5.1 Bounded Range
explained above, update q means estimate treated q good
1 q bad transactions. range bounded merely serves sanity check
definitions. Theorem 1 establishes accuracy measurement definitions
consider.
238

fiA Probabilistic Approach Maintaining Trust Based Evidence

Definition 4 Let trust update method compute q based description. say
trust update method bounded if, inputs,
0q1
Theorem 1 four definitions accuracy q given Equation 2, Algorithm 4,
Algorithm 5, Equation 3 satisfies boundedness.
Proof : range trivially bounded Linear. Max-Certainty Sensitivity
r
methods, show PCDF function, f () achieves maximum x = = r+s
,
(x)
0 1. Average, first show |x | less 1,
ff ()
show rest integral 1.
rR
1 r

2
0 xR (1x) (x) dx
.
Specifically, need show 0 e 1, e = 1q =
1 r

0

x (1x) dx

Since (x ) 1 0 x 1. Thus obtain
R1





xr (1x)s (x)2 dx
R1

xr (1x)s dx
R 10 r

x (1x)s dx
= 1.
R01 r

0 x (1x) dx
R 1 r

x (1x)s dx
Since R01 r
=

0 x (1x) dx
0

1, obtain

0 e 1.

2

5.2 Monotonicity
introduce important property trust updates, term monotonicity.
Monotonicity means fixed trust estimate , farther actual quality
service provider quality predicted estimate larger resulting
correction. Here, correction corresponds inversely q Algorithm 1. words,
monotonicity means error greater, correction due trust update larger
well.
Definition 5 Let trust update method compute q1 q2 (corresponding = 1
= 2 , respectively) based description. define method
monotonic 1 < 2 < < 2 < 1 , trust estimate
(0, 1),
q 1 < q2
Theorem 2 establishes accuracy measurement definitions consider
satisfy monotonicity.
Theorem 2 four definitions accuracy q given Equation 2, Algorithm 4,
Equation 3, Algorithm 5 satisfies monotonicity.
Proof : Linear trivially seen monotonic. prove Max-Certainty
Sensitivity monotonic, need show PCDF function increasing
r
r
) decreasing x ( r+s
, 1). show showing derivative
x (0, r+s
239

fiWang, Hang, & Singh

r
r
PCDF function positive x (0, r+s
) negative x ( r+s
, 1).
r+1
prove Average monotonic, use Theorem 5 let c = r+s+2 .
specifically, theorem equivalent showing q() increasing


0 < < r r+s decreasing r r+s < < 1, q defined Equation 3.


Definition 3, q() =

r (1)s












, = ( r r+s )r ( r s+s )s . Hence,
r r

1







(1)s r (1)s 1



r 1 (1)s 1 (r (1)s )



r 1 (1)s 1 (r (r +s ))
.


q () =
=
=




Thus q () > 0 0 < < r r+s q () < 0 r r+s < < 1.


Hence q() increasing 0 < < r r+s decreasing r r+s < < 1.
prove monotonicity Max-Certainty, equivalent show q() increasing
r
r
0 < < r+s
decreasing r+s
< < 1, q defined Algorithm 4.
rest proof above.
2

Calculated quality estimate q

0.5
Average accuracy method
Sensitivity method
0.4

0.3

0.2

0.1

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
Estimated probability

Figure 10: Monotonicity update methods illustrated: here, trust update method
calculates quality estimate q given fixed trust estimate hr , = h2, 8i,
[0, 1.0].

Figure 10 shows Average method Sensitivity method satisfy property.
Max-Certainty method Sensitivity method except uses r, instead
r , . Thus, figure Max-Certainty would Figure 10 provided use
r = 2 = 8.
5.3 Sensitivity Problems
property sensitivity alludes problem trust update methods face.
idea overly sensitive update method creates unjustifiably large updates.
result, trust placed oscillate rapidly, leading near chaotic conditions.
240

fiA Probabilistic Approach Maintaining Trust Based Evidence

Following Figure 4, Definition 6 specifies means update method asymptotically sensitive. intuition behind Definition 6 amount evidence used
assess trustworthiness source goes up, causes potentially erratic updates
amount trust placed target R. Notice Definition 6 undesirable
property.
Definition 6 Let trust update method compute q based referral hr , actual
experience hr, si. assume 6= . define trust update method
asymptotically sensitive fixed, least one following
holds:
lim
q=0


r +s

lim q = 0

r+s

Theorem 3 establishes Max-Certainty Sensitivity satisfy asymptotic sensitivity.
means methods susceptible sensitivity problems amount
evidence judge target increases.
Theorem 3 Algorithm 4 Equation 3 satisfy asymptotic sensitivity.
Proof sketch: Max-Certainty method, let f (x) PCDF function. want
r
, x 6= .
show f () goes infinity f (x) goes zero, = r+s
q=

f ( )
f ()

goes infinity r + goes infinity 6= .

1
Calculated quality estimate

Calculated quality estimate

0.5
0.4
0.3
0.2
0.1

0.8
0.6
0.4

50
100
150
Total number transactions: r+s

200

(a) r + goes 1 200, quality
calculated Max-Certainty falls.

Average Accuracy Method
Sensitivity method
Quality calculated sensitivity method

0.2
0

0

Quality calculated
average accuracy method

20
40
60
Total number referred transactions: r+s

80

(b) r + goes 1 200, quality calculated Sensitivity falls whereas
quality calculated Average rises
slightly.

Figure 11: Evaluating update methods respect quality. graphs, = 0.6,
= 0.5.

241

fiWang, Hang, & Singh

Figure 11(a) shows Max-Certainty suffers asymptotic sensitivity total
number observations r+s becomes large. And, Figure 11(b) shows Sensitivity suffers
asymptotic sensitivity total number transactions estimate becomes large.
fixed, Average Sensitivity depend total number
transactions r +s . Figure 11(b), quality calculated Sensitivity goes 1 0
quality calculated Average goes 0.73 0.90. demonstrates
Sensitivity suffers asymptotic sensitivity since treats good estimate bad
one r + becomes large, whereas Average suffer problem.
Definition 7 captures opposite intuition sensitivity accuracy measurement q converges difference observed reported probabilities. Theorem 4 shows Average, contrast Max-Certainty Sensitivity, susceptible
sensitivity thus robust methods.
Definition 7 Let trust update method compute q based description.
define method convergent fixed ,
lim

r +s

q = 1 | |

Theorem 4 Following Figure 4, fixed, Average method convergent.
Proof sketch: convergence Average follows naturally Theorem 5, given
below.
5.4 Calculating Average Accuracy
following formula shows calculate Average. important feature
formula closed form calculating updates. exact require
computing integrals, expensive compute numerically. Hence,
computational respect too, method superior Max-Certainty Sensitivity.
Theorem 5 Let q defined Algorithm 5.

2
r + 1
(r + 1)(s + 1)
q =1

+

r +s +2
(r + + 2)2 (r + + 3)
R1

r!s!
Proof sketch: need show 0 xr (1 x)s = (r+s+1)!
. accomplish via integration parts. boundary terms zeros. details
Appendix.
summarize technical results, find methods consider satisfy
property accuracy measure lying within range [0, 1]. Max-Certainty
Sensitivity satisfy undesirable property asymptotic sensitivity, whereas Linear
Average satisfy oppositedesirableproperty converging toward actual measure
accuracy. advantage Average Linear shows respect speed
learning, demonstrate simulation studies.

6. Trust Update Scenarios
discuss two use case scenarios apply trust update.
242

fiA Probabilistic Approach Maintaining Trust Based Evidence

6.1 Trust Update Referrers
Existing trust models lack update methods agent update extent trust
places referrer, based referrals referrer gives. general, trustworthiness
referrer best estimated based accurate referrals are.
Referrer
Clients trust Referrer
MR = !rR , sR "

R

Referrers referral
MS = !r , "

Compare

C
Client


Clients actual experiences
Service Provider
= !r, s"

Figure 12: Illustration trust update referrers.
accuracy determined comparing referrals observed trustworthiness
source, illustrated Figure 12. process mirrors exactly process described
Figure 4, target referrer.
6.2 Trust Combination
Referrers
Clients trust Referrer

R1

Referrers referral

R2
C
Client


R3

Service Provider

Clients actual experiences

Figure 13: Illustration trust combination.
client C determined amount trust places service provider
based referrals referrers Ri , C consolidates trust estimates using
propagation operators introduced Section 2.3. Figure 13 shows situation one
client, three referrers, one service provider. C predicts trustworthiness service
provider based information received three referrers. C would make
prediction selecting service providertypically, obtained sufficient
direct experience S.
C uses concatenation operator discount trust report received
referrer according Cs trust referrer.
C uses aggregation operator combine discounted trust reports. combined trust report yields Cs estimated trust service provider.
243

fiWang, Hang, & Singh

6.3 Trust Update Trust History
accommodate updating trust placed service provider, introduce idea
trust history. imagine ghost target reflecting clients previous level
trust specific service provider. ghost target, essence, estimates outcome
obtained service provider. Based estimate (and others), client may
estimate trust provider. client evaluates ghost target par
real referrer.
History
Trust History
MR = !rR , sR "

R

Past Behavior
MS = !r , "

Compare

C
Client


Current Behavior
= !r, s"

Service Provider

Figure 14: Illustration trust update trust history.
Figure 14 illustrates scenario instantiation general model trust
updates, Section 3. essential idea client tries estimate much
trust place past information provider. manner, avoid hardcoding discount factor weigh past information. Instead, trust placed history
serves dynamically computed discount factor tells us much weigh past.
Algorithm 6 describes method, Average-, calculates discount factor dynamically trust history. Average- similar Average-. main difference
two whereas Average- applies referrers setting, Average- applies
trust history setting (both settings introduced Section 3).
Algorithm 6, first, compare current behavior hr , past behavior
hr, si determine consistent behavior provider is. current behavior hr , close past behavior hr, si, trust history increases; otherwise,
decreases. closeness measured method averageAccuracy, defined Algorithm 5. trust placed history, hrR , sR i, reflects static behavior is.
Thus, probability trust history used discount factor ,
high new behavior consistent past low not. Here,
initially set hrR , sR h0.9, 0.1i, i.e., client trusts past experience small amount
confidence. initially set hr, si h0, 0i, trust update client
done transactions service provider.
key point distinction approach trust placed history hrR , sR
fixed discount factor; based much history matches subsequent
transactions. sources behavior changes lot cannot accurately predicted
history, trust placed history becomes low, historical information
consequently discounted greater extent. result, net past evidence
brought bear prediction goes addition evidence including
conflict would otherwise. Thus certainty resulting prediction lower
new information agrees past.
244

fiA Probabilistic Approach Maintaining Trust Based Evidence

Algorithm 6: Average-: Yields discount factor based Cs prior experiences
S.
input hr, si, hr , i, hrR , sR i;


r
r+s

c c(r, s)
c c(r , )
v

uR 1
u xr (1 x)s (x )2 dx

q 1 0 R 1
r

0 x (1 x) dx



rR
rR + cc (1 q)

sR sR + cc q



rR
+
rR
R

rT r + r
sT +
return hrT , sT i;

7. Experimental Evaluation
evaluate approach via simulations supplement theoretical analysis.
consider following main hypotheses study.
Hypothesis 1: Effectiveness Average trust history worse prediction
existing approaches variety possible behaviors service providers (Section 7.2,
Section 7.3, Section 7.4, Section 7.5).
Hypothesis 2: tuning Average trust history offer accuracy similar
traditional approaches without requiring tuning parameters (Section 7.4
Section 7.5).
Hypothesis 3: Dynamism detection certainty computed Average trust
history reflects dynamism service providers. (Section 7.4).
divide simulations two parts. first part evaluates effectiveness
trust update method. Section 7.2 compares approach three models
predicting behavior based estimated trustworthiness referrers. Section 7.3
shows trustworthiness estimated approach identifies honest malicious
referrers, yields accurate reports regarding service providers.
second part simulation shows benefits using trust history. Section 7.4
compares trust update without trust history predicting behavior different
245

fiWang, Hang, & Singh

profiles. Section 7.5 shows effectiveness trust history real dataset Amazon
Marketplace.
begin Section 7.1 introducing behavior profiles accuracy metric
throughout evaluation.
7.1 Behavior Profiles Accuracy Metrics
conduct simulation studies evaluate trust update method. end,
introduce interesting behavior profiles providers capture variety situations
arise practice. profile simply means formal characterization behavior
type agent. use agent profiles evaluate effectiveness approaches
different kinds agents.
Table 3: Behavior tracking different behavior profiles used Sections 7.2 7.4.
Profile

Example

Probability

Amazon ratings

Periodic

Restaurant
(lunch

dinner)

Behavior Function Xt


1.0 90%
0.0 10%


1.0 (t/2 mod 2) 1
0.0 otherwise

Damping

Scam artist




Random

Stock market

U (0, 1)

Random Walk

Flight
price

ticket

Xt1 + U (1, 1)

Momentum

Flight
price

ticket

Xt1 + U (1, 1) + [Xt1 Xt2 ]

1.0 /2
0.0 otherwise

include following behavior profiles study. Table 3 summarizes
profiles Figure 15 shows resulting behaviors schematically. define profiles
formally, introduce Xt , behavior function represent probability providing
good service timestep t. Here, U (1, 1) represents uniform distribution [1, 1].
parameters real numbers 0 1. timestep t, calculate
Xt first, next determine quality service based Xt .
Probability captures providers travel agency seller Amazon Marketplace. instance, travel agency might able fulfill passengers request
pleasure trip booking certain probability.
Random emulates totally unpredictable service.
246

fiA Probabilistic Approach Maintaining Trust Based Evidence

Quality

1

Quality

1

0

0

1

2

3

4

5

6

7

8

9

10

1

2

3

4

Timestep

5

6

7

8

9

10

8

9

10

8

9

10

Timestep

(a) Probability

(b) Periodic

Quality

1

Quality

1

0

0

1

2

3

4

5

6

7

8

9

10

1

2

3

4

Timestep

5

6

7

Timestep

(c) Damping

(d) Random

Quality

1

Quality

1

0

0

1

2

3

4

5

6

7

8

9

10

1

Timestep

2

3

4

5

6

7

Timestep

(e) Random Walk

(f) Momentum

Figure 15: Behavior profiles shown schematically.
Periodic describes service changes behavior regularly. example, restaurant
may employ experienced waiters dinner, novices lunch.
Damping models agents turn bad building reputation.
Random Walk generalizes providers whose current behavior depends highly
immediately previous behavior. example, quality service provided
hotel would depend upon recent investments infrastructure staff training;
thus next quality service would show dependence previous quality
service.
Momentum similar Random Walk except current behavior depends highly
two immediately previous steps.
247

fiWang, Hang, & Singh

Among profiles, Probability, Damping, Random Walk yield predictable behaviors others next outcome relates closely previous outcome.
Conversely, Random, Periodic, Momentum less predictable.
introduce average prediction error E measure effectiveness update
method. idea update method makes prediction timestep
compare prediction trustworthiness observed client.
Definition 8 Let hrt , st hrt , st predicted observed behaviors timestep t.
Define usual. Then, average prediction error E total timesteps
equals:
PT
| |
E = t=1

7.2 Predicting Referrers Different Behavior Profiles
conduct simulation study demonstrate effectiveness trust update method.
Table 4 shows, simulation includes study Average- (our approach fixed
discount factor ) along three trust models: Max-Certainty, Linear-WS,
Jsang.
Table 4: Trust update methods compared Section 7.2.
Update Method

Description

Static Model

Linear-WS (Algorithm 2)

Linear fixed

Wang Singh

Jsang (Algorithm 3)

Linear fixed

Jsang

Max-Certainty (Algorithm 4)

Max-Certainty fixed

Wang Singh

Average- (Algorithm 5)

Average fixed

Wang Singh

experiment, 100 timesteps, client conducts 50
transactions service provider. concreteness, simulations, set hrR , sR
hr, si h1, 1i h0, 0i study. initial value reflects intuition
client might place little trust stranger (as referrer), knowledge
service provider.
first simulation compares Average- trust update method methods.
simulation, one client C one service provider S. timestep, C
obtains referral referrer R S, performs 50 transactions S.
Using various trust update methods, C updates estimate trustworthiness
R based comparing referral R gave Cs actual experience. behavior
referrer R defined using profiles. Note using different randomness,
Random Walk Momentum generating behavior profile yields
similar results. show one example particular set profile parameters.
Figure 16 shows average prediction error trust update methods discount
factors = 0.00, 0.01, . . . , 1.00 behavior profiles. example,
predictable profiles Probability, Damping, Random Walk, Momentum, high
248

fiA Probabilistic Approach Maintaining Trust Based Evidence

1

1

0.9

0.9

0.8

0.8
Average
MaxCertainty
LinearWS
Josang

0.6

0.7
Prediction error

Prediction error

0.7

0.5
0.4

0.6
0.5
0.4

0.3

0.3

0.2

0.2

0.1
0
0

Average
MaxCertainty
LinearWS
Josang

0.1
0.1

0.2

0.3

0.4

0.5


0.6

0.7

0.8

0.9

0
0

1

0.1

0.2

(a) Probability

0.8

0.7

0.8

0.9

1

0.8

0.9

1

0.8

0.9

1

0.7
Prediction error

Prediction error

0.6

Average
MaxCertainty
LinearWS
Josang

0.9

0.7
0.6
0.5
0.4

0.6
0.5
0.4

0.3

0.3

0.2

0.2

0.1

0.1
0.1

0.2

0.3

0.4

0.5


0.6

0.7

0.8

0.9

0
0

1

0.1

0.2

(c) Damping

0.3

0.4

0.5


0.6

0.7

(d) Random

1

1
Average
MaxCertainty
LinearWS
Josang

0.9
0.8

Average
MaxCertainty
LinearWS
Josang

0.9
0.8
0.7
Prediction error

0.7
Prediction error

0.5


1
Average
MaxCertainty
LinearWS
Josang

0.8

0.6
0.5
0.4

0.6
0.5
0.4

0.3

0.3

0.2

0.2

0.1
0
0

0.4

(b) Periodic

1
0.9

0
0

0.3

0.1
0.1

0.2

0.3

0.4

0.5


0.6

0.7

0.8

0.9

0
0

1

(e) Random Walk

0.1

0.2

0.3

0.4

0.5


0.6

0.7

(f) Momentum

Figure 16: Prediction errors various discount factors. Although Average-
dominate graphs, yields competitive results, whereas others
fail least cases.

discount factor yields better predictions focuses recent results, even though
sacrifices large amount evidence. Conversely, less predictable profiles
Periodic Random, difficult determine best discount factor,
appears depend extraneous factors random seed chosen.
249

fiWang, Hang, & Singh

1

1

0.9

0.9

0.8

0.8

0.7

0.7
Trust referrer

Trust referrer

Recall Average one update methods considers certainty.
However, deficiency Max-Certainty Linear overcome multiplying certainty
hrR , sR i. result, difference average prediction errors significant.
Section 4.6 describes cases Max-Certainty fails predicate accurately.
context Probability Random profiles, probability-certainty density
distribution steep (indicating strong evidence), small difference based
observed trustworthiness based referral yield significant punishment
Max-Certainty.
highlight advantages Average-, create two new profiles: Rumor
Honest. Rumor referrer provides accurate reports first exaggerates evidence
second half simulation. Suppose actual experience h4, 1i. exaggerated
referral might be, example, h40, 10i. Honest referrer provides referrals whose
strength depends experience. accommodate situation
beginning may sufficient experience provider: Honest referrer
would provide neutral referrals low certainty.
Figure 17 shows estimated trustworthiness, respectively, referrer following
Rumor referrer following Honest profile. Rumor referrer provides fair referrals
beginning begins exaggerate later simulation. Honest referrer
provides fair referrals throughout: little certainty beginning generally
greater certainty later simulation. Rumor, Average- detects exaggeration
lowers trust placed referrer accordingly. However, approaches
sensitive exaggeration. Honest, Average- punish referrer
even though referral inaccurate beginning. referrer gathers enough
experience provides good reports, trust placed built accordingly. MaxCertainty suffers case, because, discussed Section 4.6, punishes Honest
reports turning false.

0.6
0.5
0.4
0.3

0.1
0

0

10

20

30

40

50
60
Timestep

0.5
0.4
0.3

Average
MaxCertainty
LinearWS
Josang

0.2

0.6

Average
MaxCertainty
LinearWS
Josang

0.2
0.1
70

80

90

0

100

(a) Rumor

0

10

20

30

40

50
60
Timestep

70

80

90

100

(b) Honest

Figure 17: Trust (with discount factor = 0.2) placed Rumor (exaggerates timestep
50) Honest (has little knowledge timestep 50) profiles time.
result shows approach Average- (a) punishes exaggeration (later
simulation) (b) stays neutral evidence low confidence (at
beginning simulation).

250

fiA Probabilistic Approach Maintaining Trust Based Evidence

Summary
foregoing shows Average effective evaluating trustworthiness referrers
various behavior profiles. Average provides competitive predictions behavior
profiles, whereas approaches either suffer profiles fail provide
accurate predictions. Hence, conclude supports Hypothesis 1: Effectiveness.
7.3 Identifying Robust Malicious Referrers
Referrers might honest cooperative. simulation verifies even
referrers maliciously provide trust reports indicating falsely exaggerated amount evidence, long client access good referrers, obtain good overall
estimate trustworthiness service provider. experiment involves one client
agent, one service provider, two referrers: one good throughout one good
first 50 timesteps turns bad.
0.95
Actual trust service provider: 0.9
0.9
Clients estimated trust
service provider

Trust

0.85

0.8

0.75

0.7
0

10

20

30

40

50 60
Time

70

80

90 100

Figure 18: Estimated versus actual trustworthiness service provider based referrals
two referrers, one good throughout one compromised midway.

Figure 18 shows case where, one good referrer counterbalance one malicious referrer, client predict trustworthiness service provider accurately.
service provider offers good outcome probability 0.90 times.
trustworthiness estimated service provider actual trustworthiness
50th timestep, one referrers turns bad, result estimate
drops 0.71. estimate returns 0.88 five timesteps
increases slowly back 0.90.
Figure 19 shows amount trust placed good corrupted referrers.
trust placed good referrer begins 0.90 increases nearly 1.
trust placed corrupted referrer begins 0.90 reaches 0.98
50th timestep, drops quickly 0.15 ten timesteps. drop trust
corrupted referrer key return accuracy overall assessment
service provider.
251

fiWang, Hang, & Singh

1
Trust placed good referrer
0.8

Trust

0.6

0.4

0.2
Trust placed damping referrer
0

10

20

30

40

50 60
Time

70

80

90

100

Figure 19: Trust placed good referrer versus trust placed corrupted referrer.
Summary
foregoing shows Average effective identifying malicious referrers. Besides,
Average provides accurate predictions despite erroneous reports malicious referrers.
Hence, conclude supports Hypothesis 1: Effectiveness.
7.4 Predicting Agents Different Behavior Profiles using Trust History
evaluate effectiveness trust history tracking different behaving agents.
simulation, one client C one service provider S. 100 timesteps,
C performs 50 transactions S. behavior service provider defined
using profiles Table 3. Using three different approaches, update estimate
trustworthiness predict future behavior based estimate. scenario,
set hrR , sR (in Definition 8) h0.9, 0.1i study. initial value reflects
intuition whereas client would place fair amount trust past experience
(as history), might place little trust stranger (as referrer Section 7.2).
Table 5: Trust update methods compared Section 7.4.
Update Method

Description

Static Model

Amazon

discount

Wang Singh

Average- (Algorithm 5)

Discount past fixed

Wang Singh

Average- (Algorithm 6)

Discount past trust history

Wang Singh

Table 5 shows three approaches compared simulation. approaches
discount past experience differently. Amazon, like marketplace web sites Amazon eBay, retains past experience; Average- decays past information
fixed discount factor ; and, Average- decays past information dynamically
computed trust history. example, suppose C h40, 10i h25, 25i first two
timesteps. Amazon estimates trustworthiness h40 + 25, 10 + 25i. Average- yields
252

fiA Probabilistic Approach Maintaining Trust Based Evidence

h40 + 25, 10 + 25i, fixed value [0, 1]. see Amazon special case
Average- = 0. Average- uses adaptive discount factor based trust
history. Figure 20 shows average prediction error methods discount factor
= 0.00, 0.01, . . . , 1 behavior profiles defined Table 3.

1

1
Amazon
Average
Average

0.8

0.8

0.7

0.7

0.6
0.5
0.4

0.6
0.5
0.4

0.3

0.3

0.2

0.2

0.1

0.1

0
0

0.1

0.2

0.3

0.4

0.5


0.6

0.7

0.8

0.9

Amazon
Average
Average

0.9

Prediction error

Prediction error

0.9

0
0

1

0.1

0.2

(a) Probability
1

0.8

0.7

0.7
Prediction error

Prediction error

0.6

0.7

0.8

0.9

1

0.6
0.5
0.4

0.6
0.5
0.4

0.3

0.3

0.2

0.2

0.1

0.1
0.1

0.2

0.3

0.4

0.5


0.6

0.7

0.8

0.9

Amazon
Average
Average

0.9

0
0

1

0.1

0.2

(c) Damping

0.3

0.4

0.5


0.6

0.7

0.8

0.9

1

(d) Random

1

1
Amazon
Average
Average

0.9
0.8

0.8

0.7

0.7

0.6
0.5
0.4

0.6
0.5
0.4

0.3

0.3

0.2

0.2

0.1

0.1
0.1

0.2

0.3

0.4

0.5


0.6

0.7

0.8

0.9

Amazon
Average
Average

0.9

Prediction error

Prediction error

0.5


1
Amazon
Average
Average

0.8

0
0

0.4

(b) Periodic

0.9

0
0

0.3

0
0

1

(e) Random Walk

0.1

0.2

0.3

0.4

0.5


0.6

0.7

0.8

0.9

1

(f) Momentum

Figure 20: Prediction error various discount factors (lower better). graph,
Amazon Average- yield horizontal lines since take discount
factor input.

253

fiWang, Hang, & Singh

Probability, Average- dominates Average- different values . Recall
Probability performs poorly while. happens, Average- adapts
dynamically increasing discount factor. Subsequently, Average- adjusts discount
factor back lower value behavior becomes predictable. adjustment
yields better predictions fixed discount factor. Note Probability yields behavior quite similar real-life agents. example sellers Amazon Marketplace,
discuss Section 7.5.
observed above, profiles predictable others. example,
Damping, Random Walk, Momentum, next outcome significantly depends upon
previous outcomes. cases, discounting old information using high value
yields predictions improved accuracy. However, although Average- high discount
factors provides highly accurate predictions, high discount factors yield low certainty
concomitant tendency consider recent evidence results
reduced evidence, shown Figure 21.
profiles, especially Random Periodic, less predictable. Random,
need overall information (high ) make best prediction. Periodic, higher
lower values yield lower error values middle, although error
unacceptably high: error exceeds 0.50. Note Periodic changes quality back
forth every two timesteps. Using = 1 yields perfect prediction Periodic stays
worst error immediately following timestep (because alternation
Periodic). Conversely, using = 0 considers overall behavior: predicts 0.50
time except initial several warmup timesteps. values yields
error close 0.50. Periodic case behavior cannot predicted
approaches. However, Periodic realistic practical cases provider
followed would gain much utilityAverage- detect unstable behavior
places low trust history thus yielding low certainty. client C react
accordingly.
Figure 21 compares certainty Amazon, Average-, Average- respect
yields best trust prediction. Recall certainty reflects two facts: (1)
amount evidence collected, (2) conflict evidence. first half
experiment, conflict clients observations. Therefore, example,
Damping, certainty Average- goes history discount decreases (and
evidence increases). referrer turns bad middle experiment,
certainty drops dramatically, partly conflict evidence partly
because, using high discount factor discount old evidence significantly, Average essence reduces amount evidence considers. Conversely, certainty
Average- fixed fixed discount factor, except conflict occurs
middle, certainty falls briefly. profiles Random Periodic,
Average- yields lower certainty Average-, behavior unpredictable.
low certainty trust prediction guide client C interact target
behavior unpredictable.
254

fi1

1

0.9

0.9

0.8

0.8
Certainty trust provider

Certainty trust provider

Probabilistic Approach Maintaining Trust Based Evidence

0.7
0.6
0.5
0.4
0.3
Amazon
Average
Average

0.2
0.1
0

0

10

20

30

40

50
60
Timestep

0.7
0.6
0.5
0.4
0.3

Amazon
Average
Average

0.2
0.1
70

80

90

0

100

0

10

20

1

1

0.9

0.9

0.8

0.8

0.7
0.6
0.5
Amazon
Average
Average

0.4
0.3

30

40

50
60
Timestep

70

80

90

0

100

1
0.9

0.8

0.8
Certainty trust provider

Certainty trust provider

1

0.7
0.6
0.5
0.4
0.3

0

Amazon
Average
Average

0

10

20

30

40

50
60
Timestep

70

80

90

100

80

90

100

Amazon
Average
Average

0

10

20

30

40

50
60
Timestep

(d) Random

0.9

0.1

100

0.3

(c) Damping

0.2

90

0.4

0.1
20

80

0.5

0.2

10

70

0.6

0.1
0

50
60
Timestep

0.7

0.2

0

40

(b) Periodic

Certainty trust provider

Certainty trust provider

(a) Probability

30

0.7
0.6
0.5
0.4
0.3

Amazon
Average
Average

0.2
0.1

70

80

90

0

100

(e) Random Walk

0

10

20

30

40

50
60
Timestep

70

(f) Momentum

Figure 21: Certainty trust prediction various discount approaches. graph
shows certainty values Amazon, Average- (choosing yields
accurate prediction), Average- approaches.

Summary
foregoing shows Average trust history effective tracking various
dynamic behaviors. Average trust history provides competitive predictions without
255

fiWang, Hang, & Singh

prior knowledge behaviors tuning parameter. Besides, certainty
Average trust history served indicator dynamism behavior.
Hence, conclude supports Hypothesis 1: Effectiveness; Hypothesis 2:
tuning; Hypothesis 3: Dynamism detection.
7.5 Predicting Amazon Marketplace Data using Trust History
order evaluate effectiveness method predicting data real world,
studied manually collected feedback profiles five sellers Amazon. sellers
obtained 60, 107, 180, 235, 452 feedbacks, respectively. feedback integer
1 5. treat feedback equaling quality service seller provided
rated transaction. precisely, normalize rating {1, 2, 3, 4, 5}
{0, 0.25, 0.5, 0.75, 1} treat normalized rating probability obtained ten
transactions. example, rating 5 translated h10, 0i rating 2 translated
h2.5, 7.5i. timestep, current feedback predicted using feedbacks
past. example, consider seller receives feedbacks 3, 1, 2, 4, respectively,
first four timesteps. use feedbacks basis predicting next
feedback. simple approach, supported Amazon, use average
feedbacks predict fifth feedback. example, would predict feedback
(3 + 1 + 2 + 4)/4 = 2.50. Suppose fifth timestep, seller actually receives
feedback 3. Thus prediction error would 0.50. approach weighs
feedback given past equally.
0

.

0

4

.

1

4

H

0

.

3









r









c



u

n



f



c





r

9



r



e



f

r







0



1

.

0

v



e

r



g

e

p

r

e





c







n

e

r

r



r

v

0

.

3

8

u

0

.

3

7

0

.

3

6

0

.

3

5





n

g



r

u







n

h









r



.

r



r

r

e

F



r

f



x

e



h









r









c



u

n





p

p

r





c

h

,

e

g



h

e



e

r



g

e

p

r

e





c







n

e

r

r



r













n





u



v



r

h

e

n







c



u

n



r





e

=

w

0

.

8

2

,



e

r



g

e

e

r

r



r





0

.

3

5

3

9

v

e

v



0

.

3

4

0

.

3

3

0

.

3

2

0

.

3

1

0

.

3

0

0

0

.

1

0

.

2

0

.

3

0

.

h

4

0









r









.

c

5



0

u

n



f



c





.

6

0

.

7

0

.

8

0

.

9

1

.

0

r

Figure 22: Prediction error feedback Amazon seller. Trust history versus different
history discount factors.

Alternatively, may discount history factor [0, 1]. example,
= 0.90, 3 3 + 1 2 + 2 1 + 4 0 )/( 3 + 2 + + 1), equals
1 0.93 + 2 0.92 + 3 0.9 + 4)/(0.93 + 0.92 + 0.9 + 1) = 2.56. scheme,
case, prediction error would 0.44. use different discount factor
256

fiA Probabilistic Approach Maintaining Trust Based Evidence

history, would general obtain different prediction error. experiment,
normalize feedback real number [0, 1]. is, feedback 1, 2, 3, 4,
5 corresponds trust value 0, 0.25, 0.50, 0.75, 1, respectively. compare
prediction error using trust history prediction error using specified
discount factor. Figure 22 shows, using fixed discount history, discount
factor 0.82, average error prediction lowest, 0.35. general,
error would higher unless happened correctly guess optimal discount factor.
contrast, using trust history, average prediction error 0.34, turns
lower using specific fixed discount factor (Hypothesis 1 ).
important engineering challenge facing traditional approaches that, since
require fixed discount factor history parameter, need manually tune
discount factor application scenario. tuning limits applicability
traditional approaches substantially. contrast, method uses trust history
automatically adapts agents changing behavior, thus require manual
tuning (Hypothesis 2 ).
Summary
foregoing shows Average trust history effective tracking ratings
Amazon without tuning parameters. Hence, conclude supports
Hypothesis 1: Effectiveness Hypothesis 2: tuning.
7.6 Summarizing Experimental Results
results twofold. First, Section 7.2, show Average provides competitive
accuracy measurement referrals. deal various behavior effectively, detect
exaggerated reports, forgive referrers trust information (Hypothesis 1 ). Section 7.3 demonstrates trust update method identifies malicious referrer provides
accurate report referrals containing false information (Hypothesis 1 ). Second,
show effectiveness benefits trust history. Section 7.4 presents trust
history tracks various artificial behavior competitively without parameter tuning (Hypotheses 1 2 ). show trust history preserve greater amount evidence
approaches thereby provide additional information dynamism
service provider (Hypothesis 3 ). Section 7.5 shows works well practical
behavior real datasets (Hypothesis 1 ).
Although Average- accurate method circumstances (Hypothesis
1 ), consider Average- best solution among methods. Average- requires
tuning discount factor. two main advantages tune
hand.
Tuning discount factor difficult variety reasons. nontrivial
determine providers behavior profile. difficult determine best value
specific profile maintain value even agent changes profile
dynamically. Using dynamically changing discount factor adapt
kinds profiles.
257

fiWang, Hang, & Singh

dynamically tuning discount factor, Average- provide dynamic certainty
information, reflects predictability referrers (Hypothesis 3 ).
provider changes behavior frequently, certainty computed trust history
build up. Knowing certainty may affect agents decision-making
strategy. Even probability high, provider may trusted, due low
certainty. Conversely, using discount factor cannot provide information
discounts history equally regardless conflict (Hypothesis 3 ).

8. Literature
Trust models widely studied (Sabater & Sierra, 2005; Jsang, Ismail, & Boyd,
2007). focus well-known trust models also ones study trust
update evaluate trustworthiness referrers based referrals.
Beta Reputation System (BRS) (Jsang & Ismail, 2002) SPORAS (Zacharia &
Maes, 2000) two trust models support idea discount factor. define
fixed damping factor control much past experience discounted.
similar , manually coded discount factor experiments. approach,
discount factor automatically tuned based dynamic agent behavior
is. Besides, BRS SPORAS fail provide trust update mechanism update
estimated trustworthiness agents based accuracy trust information
provide.
FIRE (Huynh et al., 2006) REGRET (Sabater & Sierra, 2002) two trust models
consider trust information individual social aspects. FIRE estimates
trust four sources: interactions, roles, witnesses, certified reputations. trust
information REGRET includes individual social dimensions. However, FIRE
REGRET lack trust update mechanism. Although FIRE cope dynamism, experiments, Huynh et al. assume agent behavior involves minor
changes extremely low probability. trust update approach copes various
kinds dynamism. evaluate trust update introducing several dynamic behavior
profiles. experiments show trust update provides accurate trust estimation
variety natural behavior profiles.
Teacy et al. (2006) develop Travos, one trust models based beta distribution. Travos calculates trust based direct experience trust information
third parties. Travos also provides mechanism measure accuracy referrals. Given
referral hr , (i.e., beta distribution), Travos divides probability density several
disjoint intervals. Suppose probability actual experience hr, si lies interval k.
accuracy referral defined probability density ratio interval k
intervals. Similar Sensitivity, accuracy measurement suffers number
transactions large. Besides, number intervals requires human tuning. Teacy et
al. suggest good trust model satisfy three requirements: provide
comparable trust metric without personal experience; provide confidence
measure; able assess reliability trust information sources discount information provided unreliable sources. approach satisfies three
requirements good trust model. Besides, approach makes assumption
agent behavior. However, Travos assumes agent behavior remains unchanged time.
258

fiA Probabilistic Approach Maintaining Trust Based Evidence

Teacy et al. agree time-based behavioral strategy necessary agents deal
dynamic behavior. using automatically adjusted discount factor, approach
provides time-based strategy dealing variety dynamic behavior profiles.
Fullam Barber (2007) study choose trust direct experience
(experience-based) referrals (reputation-based). adopt reinforcement learning learn parameter controls aggregate information experience-based
reputation-based trust. Based reward client gains transactions,
Fullam Barber dynamically update weights reputation providers (referrers)
linear manner. Wang Vassileva (2003) present Bayesian network-based trust
reputation model peer-to-peer networks. model also treats trust update linear
manner. predefine fixed discount factor discount past information. approach
updates trust based probability theory. show approach performs better
linear-based trust update approach theoretically experimentally.
Ries Heinemann (2008) propose CertainTrust, similar Jsangs approach.
define trust terms numbers positive negative experiences.
certainty reflect conflict evidence, reflects amount evidence.
Trust propagated using two operators: consensus (our aggregation) discounting (our
concatenation). Context dependence supported predefining maximum amount
expected evidence, trivial. Ries Heinemann update trust two ways.
update trust feedback f (a scalar 1 1), increment number
positive experiences (1 + f )/2 increment number negative experiences
(1 f )/2. alternative update trust placed agent based accuracy
recommendations provides. accuracy recommendations defined
tendency actual behavior. Ries Heinemann adopt aging factor analogous
discount factor. aging factor normalizes trust values exceed predefined
maximum number experiences. aging factor defined used
normalization. shown Section 7, using fixed aging factors poorly deals various
kinds behavior profiles parameters require human tuning. contrast,
approach track dynamic behavior well adjust discount factor based
dynamic agents are.
Khosravifar, Gomrokchi, Bentahar (2009) design maintenance-based trust model.
define timely relevance factor discount past experience updating trust.
timely relevance factor reflects time difference current time
time last update. amount discounted information determined domaindependent variable , similar discount factor discussed paper.
high, past experience forgotten faster. low, trust values tend
consider overall experience. However, Khosravifar et al.s timely relevance factor requires
manual tuning, also common limitation trust update methods
discount factor. discount factor Average- requires manual tuning.
Poyraz (Sensoy, Zhang, Yolum, & Cohen, 2009) trust-based service selection approach. Poyraz calculates estimated trustworthiness web services based
direct experience referrals. Poyraz filters referrals provided untrustworthy advisors (i.e., referrers). assesses trustworthiness advisors based private credit
public credit. private credit evaluated comparing consumers actual experience referral. comparison produces either satisfactory unsatisfactory
259

fiWang, Hang, & Singh

assessment based consumers preferences. consumer lacks experience,
public credit calculated comparing referral advisors referrals.
referral deviates majority, advisor considered untrustworthy. Poyraz also
provides time window discard old trust information. approach compares actual
experience referrals based probability density rather consumers preferences.
discount old trust information using discount factor. Instead manually adjust
size time window, discount factor automatically tuned based dynamic
agent behavior is.
Paradesi et al. (2009) incorporate trust based certainty work web service
composition. Like approach, definition trust certainty based Wang
Singhs (2007) approach. trust framework, Wisp, Paradesi et al. study four
types frequently encountered web service flows composition. provide operators
calculate trust certainty composed web service case. Paradesi et al.s
method update trust intuitive based Wang Singh Jsangs approach:
simply adds number positive number negative transactions separately.
Importantly, consider history discount effect aging information,
here. manner, Paradesi et al.s work complements proposed approach,
could refined adopt sophisticated definitions trust update.
Mistry, Gursel, Sen (2009) estimate reputation scores sensor nodes based measurement accuracy sensor networks. framework, parent node receives reports
children nodes. Based aggregated (average) report, parent evaluates
trustworthiness children. parent compares aggregated report sensed data
child, calculates error based Wilcoxon Signed Rank Test
(Wilcoxon, 1945). reputation child reflects new evidence (the error) based
two update schemes, -reputation (Jsang & Ismail, 2002) Q-learning (Watkins &
Dayan, 1992). -reputation Q-learning schemes use fixed parameter (discount
factor -reputation learning rate Q-learning) exponentially discount
past evidence, similar general update (Algorithm 1). update schemes
require manual tuning thus lack ability dealing dynamism.
Vogiatzis, MacGillivray, Chli (2010) build trust framework Hidden Markov
Models. apply probabilistic model estimate quality service provider
varying behavior. important differences approach
ours. Vogiatzis et al. assume changes behavior service provider slowly
varying described Wiener process quality sequence. Wiener process
analogous Brownian motion supports properties well-motivated
talking service providers. example, requires behavior service
provider mean 0 deviation proportional time (that is, offer
quality average beginning). model makes sense
Brownian motion apply agents may vary quality service due
environmental effects well investments infrastructure, motivated above. Further,
Vogiatzis et al. make additional unjustified assumptions opinions
honest provider normal distribution mean true quality opinions
dishonest provider uniform distribution. Thus, approach models
agents randomly decision making, apply agents deliberately
260

fiA Probabilistic Approach Maintaining Trust Based Evidence

provide extremely high extremely low referrals. Overall, model Vogiatzis et al.
limited practical applicability connection services agents.
Vogiatzis et al. (2010) evaluate approach respect two types behaviors:
static damping. treat dynamism extensively defining six dynamic behavior
profiles show approach performs profiles. However, definition
reputation target (referrer) satisfies required mathematical properties
rigorous. use heuristics update trust referrals. justified heuristics
proving models satisfy important mathematical properties, example,
farther referrals believed actual quality service provider, higher
update (q Algorithm 1) trust placed referrer. model computationally efficient. excessive need computation big shortcoming Vogiatzis
et al.s traditional approaches. example, order estimate quality
service provider varying behavior, based 100 transactions, Vogiatzis et al.s
approach would need calculate multiple integrals dimension 100. efficiency
would suffer calculating honesty multiple opinion providers.
Hazard Singh (2010) identify axiomatize common intuitions trust
viewed perspective incentives agents. relate trustworthiness agent discounts future payoffs: trustworthy agents
longer time horizon, intuition also shared Smith desJardins (2009).
approaches complementary deal agents strategically
alter behavior whereas concern agents fixed type, whose provided quality service attempt estimate. Also, incentives perspective, Jurca
Faltings (2007) study mechanisms ensure agents offer truthful feedback others.
approach deals incorporate new evidence maintaining trust rating.
approach applies settings one sanction false reporters thus promote
good behavior.

9. Conclusions Directions
paper proposes approach perform trust updates. makes following contributions. One, problem updating trust placed referrers continuing basis,
develops mathematically well-justified probabilistic approach performing updates.
Importantly, approach works top conceptually simple representation trust
reflects common intuitions trust evidence. Further, proposed approach
although cast heuristic calculating trust updates evaluated (along
competing heuristics) mathematical grounds properties monotonicity
sensitivity. Two, paper adapts referrals approach updating trust provider
modeling trust assessments referrals history prior interactions. Three,
paper shows proposed approach yields performance compares well
existing approaches without requiring hand tuning parameters common previous
approaches.
investigations opened interesting natural directions future study.
First, obvious theme experimental evaluation. would instructive
consider additional types agents, instance, discriminative agents. Second, promising
line inquiry relating decision-making strategies agents compare
261

fiWang, Hang, & Singh

trust estimates service selection. would interesting examine discounting
past, showed above, relates discounting valuations future. Third, certain
settings, especially widespread sharing information, updating trust estimates
significant dynamical effects. Hazard (2010) studied dynamical properties
various mechanisms without explicitly considering referrals. instructive
combine approach his.
Fourth, current definition accommodate multivalued events
tell us referral overestimates underestimates quality service provider.
Multivalued events useful practical cases. Further, underestimate might
desirable overestimatein former case, get pleasant surprise,
although always ideal would miss selecting good providers
underestimation. begun address suitable representation trust.
However, would nontrivial provide appropriate updating methods.

Acknowledgments
thank Chris Hazard Scott Gerard helpful comments. Chris provided dataset
use study. work partially supported U.S. Army Research Office (ARO) grant W911NF-08-1-0105 managed NCSU Secure Open Systems
Initiative (SOSI) partially sponsored Army Research Laboratory Network Sciences Collaborative Technology Alliance (NS-CTA) Cooperative Agreement
Number W911NF-09-2-0053.

Appendix A. Proofs Theorems
Lemma 6
Z

1

r

xr (1 x)s dx =

0


1

r+s+1
r+s+1i
i=1

Proof:
integration
parts.
R
R 1 r use
dx = 1 xr d( 1 (1 x)s+1 )
x
(1

x)
0
0
R 1 s+1
xr (1x)s+1 1
r
= s+1 |0 + s+1 0 xr1 (1 x)s+1 dx
R 1 r1
r
= s+1
(1 x)s+1 dx
0 x
=
R1
r(r1)1
r+s dx
= (r+s)(r+s1)(s+1)
0 (1 x)
r
Q
1

= r+s+1
r+s+1i .

2

i=1

Lemma 7 Given r above,
v
u r
uY


r
lim
=
r
r + r + 1
(1 + )+1
i=1

r positive integer.

262

fiA Probabilistic Approach Maintaining Trust Based Evidence

Proof: lemma used next lemma, show right side equation
approaches constant, equation duplicated roots, two roots
equation approach duplicated root.
r
Q

limr 1r ln
r+r+1i
i=1

=

limr 1r

ln(

=

1
r+r+1i )

i=1 i=1
r
r
Q
Q

= limr 1r ln(
=

r
r
Q
Q


1
r+i )



i=1 i=1
i=r
P

limr 1r
ln r+i
i=1
i=r

P
limr 1r
ln +r
r
i=1
R1
x
0 ln +x dx

ln (1+)
+1

=
=
Therefore,

limr

r

r
Q

i=1


r+r+1i

Lemma 8 Let =


r

=


.
(1+)+1

2

fixed. Let A(r) B(r) two values x satisfy
xr (1 x)r
=c
R1
r (1 x)r
x
0

c > 0.

lim A(r) = lim B(r) =

r

r

(4)
1
1+

(5)

r positive integer.
Proof: idea show A(r) B(r) two roots equation g(x) = (r).
limr (r) = equation g(x) = duplicated roots ,
limr A(r) = limr B(r) =
A(r) B(r)
two roots equation
q
R
1
x(1 x) = r c 0 xr (1 x)r dx
since q
R1
limr r c 0 xr (1 x)r dx

r
Q

1
= limr r c r+r+1
r+r+1i (by Lemma 6)
i=1

= (1+)+1 (by Lemma 7)
1
1
(1 1+
)
= 1+

since x(1 x) achieves

maximum x =

equation
1
1
x(1 x) = 1+
(1 1+
)
Therefore,
limr A(r) = limr B(r) =

1
1+ .

1
1+ ,

x =

1
1+

root

2
263

fiWang, Hang, & Singh

Lemma 9 Let =

r
r+s

= r + s. Let fixed c 6= .
lim R



lim R




ct (1 c)(1)t
=0
xt (1 x)(1)t dx

(6)

(1 )(1)t
=
xt (1 x)(1)t dx

(7)

(1)t

(1x)
Proof: Let f (x) = R xxt (1x)
(1)t dx
Proof Equation 6:
Without losing generality, assume 0 < c < .
> 0, let A(t) B(t) defined Equation 4 c = . According
Lemma 8, > 0 c < A(t) < > . Since f (c) < f (A(t)) = ,

f (c) < . Thus > 0, > 0,
> , proves Equation 6.
Proof Equation 7:


(1)t
R c (1c)
xt (1x)(1)t dx

<

N > 0, let A(t) B(t) defined Equation 4 c = 0.50. Since
f (x) < f (A(t)) = 0.50 x < A(t) f (x) < f (B(t)) = 0.50 x > B(t).
R A(t)
R1
R1
f (x)dx + B(t) f (x)dx < 0 0.50dx = 0.50.
0
R1
R A(t)
R B(t)
R1
Thus A(t) f (x)dx = 0 f (x)dx 0 f (x)dx B(t) f (x)dx
R1
R A(t)
1 0 f (x)dx B(t) f (x)dx > 0.50 Since f (x) f () x (A(t), B(t)).
Thus obtain (B(t) A(t))f () > 0.50
1
According Lemma 8, > 0 B(t) A(t) < 2N
> .
Thus f () > 0.50/(B(t) A(t)) > N > .
Therefore, N > 0, > 0 f () > N > , proves
Equation 7.
2
Proof Theorem
3
r (1)s
f ()
q = r (1
=
)
f ( )
Lemma 9, limt f () = 0 limt f ( ) = ,
limt q = 0.
case Sensitivity above.
Proof Theorem 4 Let = r + . Theorem 5, equivalent prove

r + 1 2
(r + 1)(s + 1)
lim (
) +
= | |


r +s +2
(r + + 2)2 (r + + 3)
q

(r +1)(s +1)
2
limt ( r r+s+1
+2 ) + (r +s +2)2 (r +s +3)
q

)+1)
+1
)2 + (t +1)(t(1
= limt ( tt+2
(t+2)2 (t+3)

2

= | |



+1
= limt
since limt tt+2
Proof Theorem 5

(t +1)(t(1 )+1)
(t+2)2 (t+3)

264

=0

2

fiA Probabilistic Approach Maintaining Trust Based Evidence

lemma 6,
R1





xr (1 x)s (x )2 dx
R1

= 0 xr (1 x)s (x2 2x + 2 )dx
R1





= 0 xr +2 (1 x)s 2xr +1 (1 x)s + 2 xr (1 x)s dx
0

=




(r +2)!s !
(r +s +3)!

rR

q =1


=1

=1
=1
2

q

q



+1)!s !
r !s !
2
2 (r(r +s
+2)! + (r +s +1)!

1
0









xr (1x)s (x)2 dx
R1
r

0 x (1x) dx

(r +1)!s !
(r +2)!s !
r !s !
2 (r +s +2)! +2 (r +s
+1)!
(r +s +3)!
r !s !
(r +s +1)!

(r +1)(r +2)
(r +s +2)(r +s +3)
(r +1)(s +1)
(r +s +2)2 (r +s +3)

2 2 r r+s+1
+2 +


(

r +1
2
r +s +2 )

+

References
Barber, K. S., & Kim, J. (2001). Belief revision process based trust: Agents evaluating
reputation information sources. Falcone, R., Singh, M. P., & Tan, Y.-H. (Eds.),
Trust Cyber-Societies, Vol. 2246 LNAI, pp. 7382, Berlin. Springer.
Casella, G., & Berger, R. L. (1990). Statistical Inference. Duxbury Press, Pacific Grove,
CA.
Fullam, K., & Barber, K. S. (2007). Dynamically learning sources trust information:
experience vs. reputation. Proceedings 6th International Conference Autonomous Agents Multiagent Systems (AAMAS), pp. 10621069, Honolulu, HI,
USA. IFAAMAS.
Gomez, M., Carbo, J., & Earle, C. B. (2007). Honesty trust revisited: advantages
neutral others cognitive models. Autonomous Agents Multi-Agent
Systems, 15 (3), 313335.
Hang, C.-W., Wang, Y., & Singh, M. P. (2008). adaptive probabilistic trust model
evaluation. Proceedings 7th International Conference Autonomous
Agents MultiAgent Systems (AAMAS), pp. 14851488, Estoril, Portugal. IFAAMAS. Short paper.
Harbers, M., Verbrugge, R., Sierra, C., & Debenham, J. (2007). examination
information-based approach trust. MALLOW Workshop Coordination, Organization, Institutions Norms agent systems (COIN), pp. 101112, Durham,
UK. Springer-Verlag.
Hazard, C. J. (2010). Trust Reputation Multiagent Systems: Strategies Dynamics Reference Electronic Commerce. Ph.D. thesis, Department Computer
Science, North Carolina State University.
265

fiWang, Hang, & Singh

Hazard, C. J., & Singh, M. P. (2010). Intertemporal discount factors measure
trustworthiness electronic commerce. IEEE Transactions Knowledge Data
Engineering. press.
Huynh, T. D., Jennings, N. R., & Shadbolt, N. R. (2006). integrated trust reputation
model open multi-agent systems. Autonomous Agents Multi-Agent Systems,
13 (2), 119154.
Jsang, A. (1998). subjective metric authentication. Quisquater, J.-J., Deswarte,
Y., Meadows, C., & Gollmann, D. (Eds.), Proceedings 5th European Symposium
Research Computer Security (ESORICS), Lecture Notes Computer Science,
pp. 329344, Louvain-la-Neuve, Belgium. Springer.
Jsang, A. (2001). logic uncertain probabilities. International Journal Uncertainty,
Fuzziness Knowledge-Based Systems (IJUFKS), 9 (3), 279311.
Jsang, A., & Ismail, R. (2002). Beta reputation system. Proceedings 15th
Bled Electronic Commerce Conference, pp. 324337, Bled, Slovenia.
Jsang, A., Ismail, R., & Boyd, C. (2007). survey trust reputation systems
online service provision. Decision Support Systems, 43 (2), 618644.
Jurca, R., & Faltings, B. (2007). Obtaining reliable feedback sanctioning reputation
mechanisms. Journal Artificial Intelligence Research (JAIR), 29, 391419.
Khosravifar, B., Gomrokchi, M., & Bentahar, J. (2009). Maintenance-based trust multiagent systems. Sierra, C., Castelfranchi, C., Decker, K. S., & Sichman, J. S. (Eds.),
Proceedings 8th International Conference Autonomous Agents Multiagent Systems (AAMAS), Vol. 2, pp. 10171024, Budapest, Hungary. IFAAMAS.
Mistry, O., Gursel, A., & Sen, S. (2009). Comparing trust mechanisms monitoring
aggregator nodes sensor networks. Sierra, C., Castelfranchi, C., Decker, K. S., &
Sichman, J. S. (Eds.), Proceedings 8th International Conference Autonomous
Agents Multiagent Systems (AAMAS), Vol. 2, pp. 985992, Budapest, Hungary.
IFAAMAS.
Paradesi, S., Doshi, P., & Swaika, S. (2009). Integrating behavioral trust web service compositions. Proceedings 7th IEEE International Conference Web Services
(ICWS), pp. 453460, Los Angeles, CA, USA. IEEE Computer Society.
Procaccia, A. D., Bachrach, Y., & Rosenschein, J. S. (2007). Gossip-based aggregation
trust decentralized reputation systems. Veloso, M. M. (Ed.), Proceedings
20th International Joint Conference Artificial Intelligence (IJCAI), pp. 14701475,
Hyderabad, India. IJCAI.
Ries, S., & Heinemann, A. (2008). Analyzing robustness CertainTrust. Proceedings
2nd Joint iTrust PST Conference Privacy, Trust Management
Security, IFIP International Federation Information Processing, pp. 5167, Boston,
MA, USA. Springer.
Sabater, J., & Sierra, C. (2002). Reputation social network analysis multi-agent
systems. Proceedings 1st International Joint Conference Autonomous
Agents Multiagent Systems (AAMAS), pp. 475482, Bologna, Italy. ACM Press.
266

fiA Probabilistic Approach Maintaining Trust Based Evidence

Sabater, J., & Sierra, C. (2005). Review computational trust reputation models.
Artificial Intelligence Review, 24 (1), 3360.
Sensoy, M., Zhang, J., Yolum, P., & Cohen, R. (2009). Poyraz: Context-aware service
selection deception. Computational Intelligence, 25 (4), 335366.
Smith, M. J., & desJardins, M. (2009). Learning trust competence commitment
agents. Autonomous Agents Multi-Agent Systems, 18 (1), 3682.
Teacy, W. T. L., Patel, J., Jennings, N. R., & Luck, M. (2006). TRAVOS: Trust
reputation context inaccurate information sources. Autonomous Agents
Multi-Agent Systems, 12 (2), 183198.
Vogiatzis, G., MacGillivray, I., & Chli, M. (2010). probabilistic model trust
reputation. van der Hoek, W., Kaminka, G. A., Lesperance, Y., Luck, M., & Sen,
S. (Eds.), Proceedings 9th International Conference Autonomous Agents
Multiagent Systems (AAMAS), Vol. 1, pp. 225232, Toronto, Canada. IFAAMAS.
Wang, Y., & Vassileva, J. (2003). Trust reputation model peer-to-peer networks.
Shahmehri, N., Graham, R. L., & Caronni, G. (Eds.), Proceedings 3rd International Conference Peer-to-Peer Computing (P2P), pp. 150157, Linkoping,
Sweden. IEEE Computer Society.
Wang, Y., & Singh, M. P. (2006). Trust representation aggregation distributed
agent system. Proceedings 21st National Conference Artificial Intelligence
(AAAI), pp. 14251430, Boston, MA, USA. AAAI Press.
Wang, Y., & Singh, M. P. (2007). Formal trust model multiagent systems. Veloso,
M. M. (Ed.), Proceedings 20th International Joint Conference Artificial
Intelligence (IJCAI), pp. 15511556, Hyderabad, India. IJCAI.
Wang, Y., & Singh, M. P. (2010). Evidence-based trust: mathematical model geared
multiagent systems. ACM Transactions Autonomous Adaptive Systems
(TAAS), 5 (4), 14:114:28.
Watkins, C., & Dayan, P. (1992). Q-learning. Machine Learning, 8 (3), 279292.
Wilcoxon, F. (1945). Individual comparisons ranking methods. Biometrics Bulletin,
1 (6), 8083.
Yu, B., & Singh, M. P. (2002). Distributed reputation management electronic commerce.
Computational Intelligence, 18 (4), 535549.
Zacharia, G., & Maes, P. (2000). Trust management reputation mechanisms. Applied Artificial Intelligence, 14 (9), 881907.

267

fiJournal Artificial Intelligence Research 40 (2011) 469521

Submitted 06/10; published 02/11

Narrowing Modeling Gap:
Cluster-Ranking Approach Coreference Resolution
Altaf Rahman
Vincent Ng

altaf@hlt.utdallas.edu
vince@hlt.utdallas.edu

Human Language Technology Research Institute
University Texas Dallas
800 West Campbell Road; Mail Station EC31
Richardson, TX 75080-3021 U.S.A.

Abstract
Traditional learning-based coreference resolvers operate training mention-pair
model determining whether two mentions coreferent not. Though conceptually
simple easy understand, mention-pair model linguistically rather unappealing
lags far behind heuristic-based coreference models proposed pre-statistical
NLP era terms sophistication. Two independent lines recent research attempted improve mention-pair model, one acquiring mention-ranking model
rank preceding mentions given anaphor, training entity-mention
model determine whether preceding cluster coreferent given mention.
propose cluster-ranking approach coreference resolution, combines strengths
mention-ranking model entity-mention model, therefore theoretically
appealing models. addition, seek improve cluster rankers
via two extensions: (1) lexicalization (2) incorporating knowledge anaphoricity
jointly modeling anaphoricity determination coreference resolution. Experimental results ACE data sets demonstrate superior performance cluster rankers
competing approaches well effectiveness two extensions.

1. Introduction
Noun phrase (NP) coreference resolution task identifying NPs (or mentions
ACE terminology1 ) text dialogue refer real-world entity concept.
computational perspective, coreference clustering task, goal partitioning
set mentions coreference clusters cluster contains
mentions co-referring. mathematical perspective, coreference relation
equivalence relation defined pair mentions, satisfies reflexivity, symmetry,
transitivity. Following previous work coreference resolution, use term
anaphoric describe mention part coreference chain head
chain. Given anaphoric mention mk , antecedent mk mention coreferent
mk precedes associated text, set candidate antecedents mk
consists mentions precede mk .2
1. precisely, mention instance reference entity real world. article,
treat terms mention noun phrase synonymous use interchangeably.
2. Note definitions somewhat overloaded. Linguistically, anaphor noun phrase
depends antecedent semantic interpretation. Hence, Barack Obama anaphoric
definition formal definition.
c
2011
AI Access Foundation. rights reserved.

fiRahman & Ng

research focus computational coreference resolution exhibited gradual shift
heuristic-based approaches machine learning approaches past decade. shift
attributed part advent statistical natural language processing (NLP)
era, part public availability coreference-annotated corpora produced
result MUC-6 MUC-7 conferences series ACE evaluations. One
influential machine learning approaches coreference resolution classificationbased approach, coreference recast binary classification task (e.g., Aone &
Bennett, 1995; McCarthy & Lehnert, 1995). Specifically, classifier trained
coreference-annotated data used determine whether pair mentions co-referring
not. However, pairwise classifications produced classifier (which commonly known mention-pair model) may satisfy transitivity property inherent
coreference relation, since possible model classify (A,B) coreferent,
(B,C) coreferent, (A,C) coreferent. result, separate clustering mechanism needed coordinate possibly contradictory pairwise classification decisions
construct partition given mentions.
mention-pair model significantly influenced learning-based coreference research
past fifteen years. fact, many recently published coreference papers
still based classical learning-based coreference model (e.g., Bengtson & Roth, 2008;
Stoyanov, Gilbert, Cardie, & Riloff, 2009). Despite popularity, model least
two major weaknesses. First, since candidate antecedent mention resolved
(henceforth active mention) considered independently others, model
determines good candidate antecedent relative active mention,
good candidate antecedent relative candidates. words, fails
answer critical question candidate antecedent probable. Second,
limitations expressiveness: information extracted two mentions
alone may sufficient making informed coreference decision, especially
candidate antecedent pronoun (which semantically empty) mention lacks
descriptive information gender (e.g., Clinton).
Recently, coreference researchers investigated alternative models coreference
aim address aforementioned weaknesses mention-pair model. address
first weakness, researchers proposed mention-ranking model. model determines candidate antecedent probable given active mention imposing
ranking candidate antecedents (e.g., Denis & Baldridge, 2007b, 2008; Iida, Inui,
& Matsumoto, 2009). Ranking arguably natural formulation coreference resolution classification, ranker allows candidate antecedents considered
simultaneously therefore directly captures competition among them. Another desirable consequence exists natural resolution strategy ranking approach:
mention resolved candidate antecedent highest rank. contrasts
classification-based approaches, many clustering algorithms employed
co-ordinate pairwise coreference decisions (because unclear one best).
address second weakness, researchers proposed entity-mention coreference
model (e.g., Luo, Ittycheriah, Jing, Kambhatla, & Roukos, 2004; Yang, Su, Zhou, & Tan,
2004; Yang, Su, Lang, Tan, & Li, 2008). Unlike mention-pair model, entity-mention
model trained determine whether active mention belongs preceding, possibly
partially-formed, coreference cluster. Hence, employ cluster-level features (i.e., fea470

fiA Cluster-Ranking Approach Coreference Resolution

tures defined subset mentions preceding cluster), makes
expressive mention-pair model.
entity-mention model mention-ranking model conceptually simple
extensions mention-pair model, born nearly ten years mention-pair
model proposed, particular, contributions under-estimated:
paved new way thinking supervised modeling coreference represents
significant departure mention-pair counterpart, many years
learning-based coreference model NLP researchers. proposal two models
facilitated part advances statistical modeling natural languages: statistical
NLP models evolved capturing local information global information,
employing classification-based models ranking-based models. context
coreference resolution, entity-mention model enables us compute features based
variable number mentions, mention-ranking model enables us rank variable
number candidate antecedents. Nevertheless, neither models addresses
weaknesses mention-pair model satisfactorily: mention-ranking model allows
candidate antecedents ranked compared simultaneously, enable
use cluster-level features; hand, entity-mention model employ
cluster-level features, allow candidates considered simultaneously.
Motivated part observation, propose learning-based approach coreference resolution theoretically appealing mention-ranking model
entity-mention model: cluster-ranking approach. Specifically, recast coreference problem determining set preceding coreference clusters
best link active mention using learned cluster-ranking model. essence,
cluster-ranking model combines strengths mention-ranking model entitymention model, addresses weaknesses associated mention-pair model.
cluster-ranking model appears conceptually simple natural extension entity-mention model mention-ranking model, believe
simplicity stems primarily choice presentation concepts easiest
reader understand. particular, note mental processes involved
design cluster-ranking model means simple way model
presented: requires analysis strengths weaknesses existing
approaches learning-based coreference resolution connection them,
also formulation view entity-mention model mention-ranking
model addressing two complementary weaknesses mention-pair model. believe
significance cluster-ranking model lies bridging two rather independent
lines learning-based coreference research going past years,
one involving entity-mention model mention-ranking model.
addition, seek improve cluster-ranking model two sources linguistic knowledge. First, propose exploit knowledge anaphoricity (i.e., knowledge
whether mention anaphoric not). Anaphoricity determination means new
problem, neither use anaphoricity information improve coreference resolution. innovation lies way learn knowledge anaphoricity. Specifically,
previous work typically adopted pipeline coreference architecture,
anaphoricity determination performed prior coreference resolution resulting
information used prevent coreference system resolving mentions de471

fiRahman & Ng

termined non-anaphoric (for overview, see work Poesio, Uryupina, Vieira,
Alexandrov-Kabadjov, & Goulart, 2004), propose model jointly learning anaphoricity determination coreference resolution. Note major weakness pipeline
architecture lies fact errors anaphoricity determination could propagated
coreference resolver, possibly leading deterioration coreference performance
(Ng & Cardie, 2002a). joint model potential solution error-propagation
problem.
Second, examine kind linguistic features exploited majority
existing supervised coreference resolvers: word pairs composed strings (or
head nouns) active mention one preceding mentions. Intuitively,
word pairs contain useful information. example, may help improve precision
model, allowing learner learn moderate probability
anaphoric, contrary taken phrase contrary never
anaphoric. may also help improve recall, allowing learner determine,
instance, airline carrier coreferent. Hence, offer convenient
means attack one major problems coreference research: identifying coreferent
common nouns lexically dissimilar semantically related. Note
extremely easy compute, even so-called cheap features stringmatching grammatical features (Yang, Zhou, Su, & Tan, 2003), majority
existing supervised coreference systems unlexicalized hence exploiting
them. Somewhat unexpectedly, however, researchers lexicalize coreference
models employing word pairs features (e.g., Luo et al., 2004; Daume III & Marcu, 2005;
Bengtson & Roth, 2008), feature analysis experiments indicate lexical features
best marginally useful. instance, Luo et al. Daume III Marcu report
leaving lexical features feature ablation experiments causes ACE value
drop 0.8 0.7, respectively. previous attempts lexicalization merely
append word pairs conventional coreference feature set, goal investigate
whether make better use lexical features learning-based coreference resolution.
sum up, propose cluster-ranking approach coreference resolution joint
model exploiting anaphoricity information, investigate role lexicalization
learning-based coreference resolution. Besides empirically demonstrating clusterranking model significantly outperforms competing approaches ACE 2005 coreference
data set, two extensions model, namely lexicalization joint modeling,
effective improving performance, believe work makes four contributions
coreference resolution:
Narrowing modeling gap. machine learning approaches coreference resolution received lot attention since mid-1990s, mention-pair model
heavily influenced learning-based coreference research decade, yet
model lags far behind heuristic-based coreference models proposed 1980s
1990s terms sophistication. particular, notion ranking traced back
centering algorithms (for information, see books Mitkov, 2002; Walker, Joshi,
& Prince, 1998), idea behind ranking preceding clusters (in heuristic manner)
found Lappin Leasss (1994) influential paper pronoun resolution.
cluster-ranking model completely close gap simplicity machine
learning approaches sophistication heuristic approaches coreference resolu472

fiA Cluster-Ranking Approach Coreference Resolution

tion, believe represents important step towards narrowing gap. Another
important gap cluster-ranking model helps bridge two independent lines
learning-based coreference research going past years, one
involving entity-mention model mention-ranking model.
Promoting use ranking models. mention-ranking model
empirically shown outperform mention-pair model (Denis & Baldridge, 2007b, 2008),
former received much attention among coreference researchers should.
particular, mention-pair model continues popularly used investigated
past years mention-ranking model. believe lack excitement
ranking-based approaches coreference resolution attributed least part
lack theoretical understanding ranking, previous work ranking-based coreference
resolution employed ranking algorithms essentially black box. Without opening
black box, could difficult researchers appreciate subtle difference
ranking classification. attempt promote use ranking-based models,
provide brief history use ranking coreference resolution (Section 2),
tease apart differences classification ranking showing constrained
optimization problem support vector machine (SVM) attempts solve classificationbased ranking-based coreference models (Section 3).
Gaining better understanding existing learning-based coreference models.
Recall lexicalization one two linguistic knowledge sources propose
use improve cluster-ranking model. Note lexicalization applied
cluster-ranking model, essentially learning-based coreference models. However,
mentioned before, vast majority existing coreference resolvers unlexicalized.
fact, mention-ranking model shown improve mention-pair model
unlexicalized feature set. attempt gain additional insights behavior
different learning-based coreference models, compare performance lexicalized
feature set. Furthermore, analyze via experiments involving feature ablation
data source adaptability, well report performance resolving different types
anaphoric expressions.
Providing implementation cluster-ranking model. stimulate
research ranking-based approaches coreference resolution, facilitate use
coreference information high-level NLP applications, make software implements cluster-ranking model publicly available.3
rest article organized follows. Section 2 provides overview use
ranking coreference resolution. Section 3 describes baseline coreference models:
mention-pair model, entity-mention model, mention-ranking model.
discuss cluster-ranking approach joint model anaphoricity determination
coreference resolution Section 4. Section 5 provides details lexicalize
coreference models. present evaluation results experimental analyses different
aspects coreference models Section 6 Section 7, respectively. Finally,
conclude Section 8.
3. software available http://www.hlt.utdallas.edu/~ altaf/cherrypicker/.

473

fiRahman & Ng

2. Ranking Approaches Coreference Resolution: Bit History
ranking theoretically empirically better formulation learning-based coreference resolution classification, mention-ranking model popularly
used investigated mention-pair counterpart since proposed. promote
ranking-based coreference models, set stage discussion learningbased coreference models next section, provide section brief history
use ranking heuristic-based learning-based coreference resolution.
broader sense, many heuristic anaphora coreference resolvers rankingbased. example, find antecedent anaphoric pronoun, Hobbss (1978) seminal syntax-based resolution algorithm considers sentences given text reverse
order, starting sentence pronoun resides searching potential
antecedents corresponding parse trees left-to-right, breadth-first manner
obeys binding agreement constraints. Hence, keep searching beginning
text reached (i.e., stop even algorithm proposes antecedent),
obtain ranking candidate antecedents pronoun consideration, rank candidate determined order proposed
algorithm. fact, rank antecedent obtained via method commonly
known Hobbss distance, used linguistic feature statistical
pronoun resolvers (e.g., Ge, Hale, & Charniak, 1998; Charniak & Elsner, 2009). general,
search-based resolution algorithms like Hobbss consider candidate antecedents particular order (typically) propose first candidate satisfies linguistic constraints
antecedent.
Strictly speaking, however, may want consider heuristic resolution algorithm
ranking-based algorithm considers candidate antecedents simultaneously,
example assigning rank score candidate selecting highest-ranked
highest-scored candidate antecedent. Even stricter definition
ranking, still many heuristic resolvers ranking-based. resolvers
typically assign rank score candidate antecedent based number factors,
knowledge sources, propose one highest rank score
antecedent (e.g., Carbonell & Brown, 1988; Cardie & Wagstaff, 1999). factor belongs
one two types: constraints preferences (Mitkov, 1998). Constraints must satisfied
two mentions posited coreferent. Examples constraints include gender
number agreement, binding constraints, semantic compatibility. Preferences indicate likelihood candidate antecedent. preference factors measure
compatibility anaphor candidate (e.g., syntactic parallelism favors candidates grammatical role anaphor), preference factors
computed based candidate only, typically capturing salience candidate.
constraint preference manually assigned weight indicating importance.
instance, gender disagreement typically assigned weight , indicating
candidate anaphor must agree gender, whereas preference factors typically
finite weight. score candidate obtained summing weights
factors associated candidate.
ranking-based resolution algorithms assign score candidate antecedent. Rather, simply impose ranking candidates based salience.
474

fiA Cluster-Ranking Approach Coreference Resolution

Perhaps representative family algorithms employ salience rank candidates centering algorithms (for descriptions specific centering algorithms, see
work Grosz, Joshi, & Weinstein, 1983, 1995; Walker et al., 1998; Mitkov, 2002),
salience mention, typically estimated using grammatical role, used rank
forward-looking centers.
work related Lappin Leass (1994), whose goal perform pronoun resolution assigning anaphoric pronoun highest-ranked preceding
cluster, therefore heuristic cluster-ranking model. Like many heuristic-based
resolvers, Lappin Leasss algorithm identifies highest-ranked preceding cluster
active mention first applying set linguistic constraints filter candidate antecedents grammatically incompatible active mention, ranking
preceding clusters, contain mentions survive filtering process, using
salience factors. Examples salience factors include sentence recency (whether preceding cluster contains mention appears sentence currently processed),
subject emphasis (whether cluster contains mention subject position), existential emphasis (whether cluster contains mention predicate nominal
existential construction), accusative emphasis (whether cluster contains mention
appears verbal complement accusative case). salience factor associated
manually-assigned weight indicates importance relative factors,
score cluster sum weights salience factors applicable
cluster. Lappin Leasss paper widely read paper pronoun resolution,
cluster ranking aspect algorithm rarely emphasized. fact,
aware recent work learning-based coreference resolution establishes
connection entity-mention model Lappin Leasss algorithm.
Despite conceptual similarities, cluster-ranking model Lappin Leasss
(1994) algorithm differ several respects. First, Lappin Leass tackle pronoun resolution rather full coreference task. Second, apply linguistic constraints
filter incompatible candidate antecedents, resolution strategy learned without applying hand-coded constraints separate filtering step. Third, attempt
compute salience preceding cluster respect active mention, attempt
determine compatibility cluster active mention, using factors
determine salience also lexical grammatical compatibility, instance.
Finally, algorithm heuristic-based, weights associated salience
factor encoded manually rather learned, unlike system.
first paper learning-based coreference resolution written Connolly, Burger,
Day (1994) published year Lappin Leasss (1994) paper.
Contrary common expectation, coreference model paper proposes rankingbased model, influential mention-pair model. main idea behind Connolly et
al.s approach convert problem ranking N candidate antecedents set
pairwise ranking problems, involves ranking exactly two candidates.
rank two candidates, classifier trained using training set instance
corresponds active mention well two candidate antecedents possesses
class value indicates two candidates better. idea certainly ahead
time, embodied many advanced ranking algorithms developed
machine learning information retrieval communities past years.
475

fiRahman & Ng

later re-invented almost time, independently, Yang et al. (2003)
Iida, Inui, Takamura, Matsumoto (2003), refer twin-candidate model
tournament model, respectively. name twin-candidate model motivated
fact model considers two candidates time, whereas name tournament
model assigned ranking two candidates viewed tournament
(with higher-ranked candidate winning tournament) candidate wins
largest number tournaments chosen antecedent active mention.
bit history rarely mentioned literature, reveals three somewhat interesting
perhaps surprising facts. First, ranking first applied train coreference models
much earlier people typically think. Second, despite first learning-based
coreference model, Connolly et al.s ranking-based model theoretically appealing
classification-based mention-pair model, later shown Yang et al.
Iida et al.. empirically better well. Finally, despite theoretical empirical
superiority, Connolly et al.s model largely ignored NLP community received
attention re-invented nearly decade later, time period
mention-pair counterpart essentially dominated learning-based coreference research.4
conclude section making important observation distinction classification ranking applies discriminative models generative models.
Generative models try capture true conditional probability event. context coreference resolution, probability mention particular
antecedent referring particular entity (i.e., preceding cluster). Since probabilities normalize, similar ranking objective: system trying raise
probability mention refers correct antecedent entity expense
probabilities refers other. Thus, antecedent version generative
coreference model proposed Ge et al. (1998) resembles mention-ranking model,
entity version proposed Haghighi Klein (2010) similar spirit
cluster-ranking model.

3. Baseline Coreference Models
section, describe three coreference models serve baselines:
mention-pair model, entity-mention model, mention-ranking model. illustrative purposes, use text segment shown Figure 1. mention
segment annotated [m]cid
mid , mid mention id cid id cluster
belongs. see, mentions partitioned four sets, Barack
Obama, his, one cluster, remaining mentions cluster.

4. may possible (and perhaps crucial) determine mention-pair model received
lot attention Connolly et al.s model, since days academic papers
could accessed easily electronic form, speculate publication venue played role:
Connolly et al.s work published New Methods Language Processing conference 1994
(and later book chapter 1997), whereas mention-pair model introduced Aone
Bennetts (1995) paper McCarthy Lehnerts (1995) paper, appeared proceedings
two comparatively higher-profile AI conferences: ACL 1995 IJCAI 1995.

476

fiA Cluster-Ranking Approach Coreference Resolution

[Barack Obama]11 nominated [Hillary Rodham Clinton]22 [[his]13 secretary state]34 [Monday]45 .
[He]16 ...

Figure 1: illustrative example
3.1 Mention-Pair Model
noted before, mention-pair model classifier decides whether
active mention mk coreferent candidate antecedent mj . instance i(mj , mk )
represents mj mk . implementation, instance consists 39 features shown
Table 1. features largely employed state-of-the-art learning-based
coreference systems (e.g., Soon, Ng, & Lim, 2001; Ng & Cardie, 2002b; Bengtson & Roth,
2008), computed automatically. seen, features divided four
blocks. first two blocks consist features describe properties mj mk ,
respectively, last two blocks features describe relationship mj
mk . classification associated training instance either positive negative,
depending whether mj mk coreferent.
one training instance created pair mentions, negative instances
would significantly outnumber positives, yielding skewed class distribution
typically adverse effect model training. result, subset mention
pairs generated training. Following Soon et al. (2001), create (1) positive
instance anaphoric mention mk closest antecedent mj ; (2) negative
instance mk paired intervening mentions, mj+1 , mj+2 , . . . , mk1 .
running example shown Figure 1, three training instances generated He:
i(Monday, He), i(secretary state, He), i(his, He). first two instances
labeled negative, last one labeled positive. train mention-pair
model, use SVM learning algorithm SVMlight package (Joachims, 1999).5
mentioned introduction, previous work learning-based coreference
resolution typically treats underlying machine learner simply black-box tool,
choose provide reader overview SVMs, learner employing
work. Note self-contained overview, means comprehensive
introduction maximum-margin learning: goal provide reader
details believe needed understand difference classification
ranking perhaps appreciate importance ranking.6
begin with, assume given data set consisting positively labeled
points, class value +1, negatively labeled points, class
5. Since SVMlight assumes real-valued features, cannot operate features multiple discrete values
directly. Hence, need convert features shown Table 1 equivalent set features
used directly SVMlight . uniformity, perform conversion feature
Table 1 (rather multi-valued features) follows: create one binary-valued feature
SVMlight feature-value pair derived feature set Table 1. example,
pronoun 1 two values, N. derive two binary-valued features, pronoun 1=Y
pronoun 1=N. One value 1 value 0 instance.
6. overview theory maximum-margin learning, refer reader Burgess (1998)
tutorial.

477

fiRahman & Ng

Features describing mj , candidate antecedent
1 pronoun 1
mj pronoun; else N
2 subject 1
mj subject; else N
3 nested 1
mj nested NP; else N
Features describing mk , mention resolved
4 number 2
singular plural, determined using lexicon
male, female, neuter, unknown, determined using list
5 gender 2
common first names
mk pronoun; else N
6 pronoun 2
7 nested 2
mk nested NP; else N
8 semclass 2
semantic class mk ; one person, location, organization, date, time, money, percent, object, others, determined using WordNet (Fellbaum, 1998) Stanford NE recognizer (Finkel, Grenager, & Manning, 2005)
9 animacy 2
mk determined human animal WordNet NE
recognizer; else N
nominative case mk pronoun; else NA. E.g.,
10 pro type 2
feature value
Features describing relationship mj , candidate antecedent mk ,
mention resolved
11 head match
C mentions head noun; else
12 str match
C mentions string; else
13 substr match
C one mention substring other; else
C mentions pronominal string; else
14 pro str match
15 pn str match
C mentions proper names string; else
16 nonpro str match C two mentions non-pronominal
string; else
17 modifier match
C mentions modifiers; NA one
dont modifier; else
C mentions pronominal either pronoun
18 pro type match
different respect case; NA least one
pronominal; else
19 number
C mentions agree number; disagree; NA
number one mentions cannot determined
20 gender
C mentions agree gender; disagree; NA gender
one mentions cannot determined
21 agreement
C mentions agree gender number; disagree
number gender; else NA
22 animacy
C mentions match animacy; dont; NA
animacy one mentions cannot determined
C mentions pronouns; neither pronouns; else NA
23 pronouns
24 proper nounsC mentions proper nouns; neither proper nouns;
else NA
25 maximalnp
C two mentions maximial NP projection; else
26 span
C neither mention spans other; else
27 indefinite
C mk indefinite NP appositive relationship;
else
28 appositive
C mentions appositive relationship; else
29 copular
C mentions copular construction; else

478

fiA Cluster-Ranking Approach Coreference Resolution

Features describing relationship mj , candidate antecedent mk ,
mention resolved (continued previous page)
30 semclass
C mentions semantic class (where set
semantic classes considered enumerated description
semclass 2 feature); dont; NA semantic class
information one mentions cannot determined
31 alias
C one mention abbreviation acronym other; else

32 distance
binned values sentence distance mentions
Additional features describing relationship mj , candidate antecedent
mk , mention resolved
33 number
concatenation number 2 feature values mj mk .
E.g., mj Clinton mk they, feature value singularplural, since mj singular mk plural
34 gender
concatenation gender 2 feature values mj mk
35 pronoun
concatenation pronoun 2 feature values mj mk
36 nested
concatenation nested 2 feature values mj mk
37 semclass
concatenation semclass 2 feature values mj mk
38 animacy
concatenation animacy 2 feature values mj mk
concatenation pro type 2 feature values mj mk
39 pro type

Table 1: Feature set coreference resolution. Non-relational features describe mention
cases take value Yes No. Relational features describe relationship
two mentions indicate whether Compatible, Incompatible
Applicable.
value 1. used classification mode, SVM learner aims learn hyperplane
(i.e., linear classifier) separates positive points negative points.
one hyperplane achieves zero training error, learner choose
hyperplane maximizes margin separation (i.e., distance
hyperplane training example closest it), larger margin proven
provide better generalization unseen data (Vapnik, 1995). formally, maximum
margin hyperplane defined w x b = 0, x feature vector representing
arbitrary data point, w (a weight vector) b (a scalar) parameters
learned solving following constrained optimization problem:
Optimization Problem 1: Hard-Margin SVM Classification
arg min
subject

1
kwk2
2

yi (w xi b) 1,

1 n,

yi {+1, 1} class i-th training point xi . Note data point
xi , exactly one linear constraint optimization problem ensures xi
correctly classified. particular, using value 1 right side inequality
479

fiRahman & Ng

constraint ensures certain distance (i.e., margin) xi hyperplane.
shown margin inversely proportional length weight vector.
Hence, minimizing length weight vector equivalent maximizing margin.
resulting SVM classifier known hard-margin SVM: margin hard
data point correct side hyperplane.
However, cases data set linearly separable, hyperplane
perfectly separate positives negatives, result,
constrained optimization problem solution. Instead asking SVM
learner give return solution, solve relaxed version problem
also consider hyperplanes produce non-zero training errors potential solutions.
words, modify linear constraints associated data point
training errors allowed. However, modify linear constraints
leave objective function is, learner search maximum-margin
hyperplane regardless training error produces. Since training error correlates
positively generalization error, crucial objective function also take
consideration training error hyperplane large margin low training
error found. However, non-trivial maximize margin minimize
training error simultaneously, since training error typically increases maximize
margin. result, need find trade-off two criteria, resulting
objective function linear combination margin size training error.
formally, find optimal hyperplane solving following constrained optimization
problem:
Optimization Problem 2: Soft-Margin SVM Classification
arg min

X
1
kwk2 + C

2


subject
yi (w xi b) 1 , 1 n.
before, yi {+1, 1} class i-th training point xi . C regularization
parameter balances training error margin size. Finally, non-negative slack
variable represents degree misclassification xi ; particular, > 1,
data point wrong side hyperplane. SVM allows data points
appear wrong side hyperplane, also known soft-margin SVM.
Given optimization problem, rely training algorithm employed SVMlight
finding optimal hyperplane.
training, resulting SVM classifier used clustering algorithm identify
antecedent mention test text. Specifically, active mention compared
turn preceding mention. pair, test instance created training
presented SVM classifier, returns value indicates likelihood
two mentions coreferent. Mention pairs class values 0 considered
coreferent; otherwise pair considered coreferent. Following Soon et al. (2001),
apply closest-first linking regime antecedent selection: given active mention mk ,
480

fiA Cluster-Ranking Approach Coreference Resolution

select antecedent closest preceding mention classified coreferent
mk . mk classified coreferent preceding mention, considered
non-anaphoric (i.e., antecedent selected mk ).
3.2 Entity-Mention Model
Unlike mention-pair model, entity-mention model classifier decides whether
active mention mk belongs partial coreference cluster cj precedes mk .
training instance, i(cj , mk ), represents cj mk . features instance
divided two types: (1) features describe mk (i.e, shown second block
Table 1), (2) cluster-level features, describe relationship cj
mk . cluster-level feature created feature employed mention-pair
model applying logical predicate. example, given number feature (i.e., feature
#19 Table 1), determines whether two mentions agree number, apply
predicate create cluster-level feature value yes mk agrees
number mentions cj otherwise. Motivated previous work (Luo
et al., 2004; Culotta, Wick, & McCallum, 2007; Yang et al., 2008), create cluster-level
features mention-pair features using four commonly-used logical predicates: none,
most-false, most-true, all. Specifically, feature x shown last two
blocks Table 1, first convert x equivalent set binary-valued features
multi-valued. Then, resulting binary-valued feature xb , create four binaryvalued cluster-level features: (1) none-xb true xb false mk
mention cj ; (2) most-false-xb true xb true mk less half
(but least one) mentions cj ; (3) most-true-xb true xb true
mk least half (but all) mentions cj ; (4) all-xb true xb
true mk mention cj . Hence, xb , exactly one four
cluster-level features evaluates true.7
Following Yang et al. (2008), create (1) positive instance anaphoric mention
mk preceding cluster cj belongs; (2) negative instance mk
paired preceding cluster whose last mention appears mk closest
antecedent (i.e., last mention cj ). Consider running example. Three
training instances generated He: i({Monday}, He), i({secretary state}, He),
i({Barack Obama, his}, He). first two instances labeled negative,
last one labeled positive. mention-pair model, train
entity-mention model using SVM learner.
Since entity-mention model classifier, use SVMlight classification
mode, resulting constrained optimization problem essentially Optimization Problem 2, except training example xi represents active mention
one preceding clusters rather two mentions.
7. Note cluster-level feature also represented probabilistic feature. Specifically, recall
four logical predicates partitions [0,1] interval. predicate evaluates true given
cluster-level feature depends probability obtained computation feature. Instead
applying logical predicates convert probability one four discrete values,
simply use probability value cluster-level feature. However, choose employ
probabilistic representation, preliminary experiments indicated using probabilistic features
yielded slightly worse results using logical features.

481

fiRahman & Ng

training, resulting classifier used identify preceding cluster mention
test text. Specifically, mentions processed left-to-right manner.
active mention mk , test instance created mk preceding clusters
formed far. test instances presented classifier. Finally, adopt
closest-first clustering regime, linking mk closest preceding cluster classified
coreferent mk . mk classified coreferent preceding cluster,
considered non-anaphoric. Note partial clusters preceding mk formed
incrementally based predictions classifier first k 1 mentions;
gold-standard coreference information used formation.
3.3 Mention-Ranking Model
noted before, ranking model imposes ranking candidate antecedents
active mention mk . train ranking-model, use SVM ranker-learning algorithm
Joachimss (2002) SVMlight package.
Like mention-pair model, training instance i(mj , mk ) represents mk
preceding mention mj . fact, features represent instance method
creating training instances identical employed mention-pair model.
difference lies labeling training instances. Assuming Sk set
training instances created anaphoric mention mk , rank value i(mj , mk ) Sk
rank mj among competing candidate antecedents, 2 mj closest
antecedent mk , 1 otherwise.8 exemplify, consider running example.
mention-pair model, three training instances generated He: i(Monday,
He), i(secretary state, He), i(his, He). third instance rank value 2,
remaining two rank value 1.
first glance, seems training set generated learning mentionranking model, identical one learning mention-pair model, instance
represents two mentions labeled one two possible values. Since previous work
ranking-based coreference resolution attempt clarify difference
two, believe could difficult reader appreciate idea using
ranking coreference resolution.
Let us first describe difference classification ranking high level,
beginning training sets employed mention-ranking model mentionpair model. difference label associated instance training
mention-ranking model rank value, whereas label associated instance
training mention-pair model class value. specifically, since ranking SVM
learns rank set candidate antecedents, relative ranks two candidates,
rather absolute rank candidate, matter training process.
words, point view ranking SVM, training set instance #1
rank value 2 instance #2 rank value 1 functionally equivalent one
#1 rank value 10 #2 rank value 5, assuming remaining
instances generated anaphor two training sets identical
rank value 1 10.
8. larger rank value implies better rank SVMlight .

482

fiA Cluster-Ranking Approach Coreference Resolution

Next, take closer look ranker-training process. denote training set
created described . addition, assume instance
denoted (xjk , yjk ), xjk feature vector created anaphoric mention
mk candidate antecedent mj , yjk rank value. training ranker,
SVM ranker-learning algorithm derives training set original training set
follows. Specifically, every pair training instances (xik , yik ) (xjk , yjk )
yik 6= yjk , create new training instance (xijk , yijk ) , xijk = xik xjk ,
yijk {+1, 1} 1 xik larger rank value xjk (and 1 otherwise). way,
creation resembles Connolly et al.s (1994) pairwise ranking approach saw
Section 2, convert ranking problem pairwise classification problem.9
goal ranker-learning algorithm, then, find hyperplane minimizes
number misclassifications . Note since yijk {+1, 1}, class value
instance depends relative ranks two candidate antecedents,
absolute rank values.
Given conversion ranking problem pairwise classification problem,
constrained optimization problem SVM ranker-learning algorithm attempts
solve, described below, similar Optimization Problem 2:
Optimization Problem 3: Soft-Margin SVM Ranking
X
1
ijk
arg min kwk2 + C
2
subject
yijk (w (xik xjk ) b) 1 ijk ,
ijk non-negative slack variable represents degree misclassification
xijk , C regularization parameter balances training error margin size.
Two points deserve mention. First, optimization problem equivalent one
classification SVM pairwise difference feature vectors xik xjk . result,
training algorithm used solve Optimization Problem 2 also applicable
optimization problem. Second, number linear inequality constraints
generated document optimization problems training mention-pair
model entity-mention model quadratic number mentions d,
number constraints generated ranking SVM cubic number mentions,
since instance represents three (rather two) mentions.
training, mention-ranking model applied rank candidate antecedents
active mention test text follows. Given active mention mk , follow Denis
Baldridge (2008) use independently-trained classifier determine whether mk
non-anaphoric. so, mk resolved. Otherwise, create test instances mk
pairing preceding mentions. test instances presented
ranker, computes rank value instance taking dot product
9. main difference training set employed Connolly et al.s approach
, instance formed taking difference feature vectors two instances , whereas
Connolly et al.s training set, instance formed concatenating feature vectors two
instances .

483

fiRahman & Ng

instance vector weight vector. preceding mention assigned largest
value ranker selected antecedent mk . Ties broken preferring
antecedent closest distance mk .
anaphoricity classifier used resolution step trained using publicly-available
implementation10 maximum entropy (MaxEnt) modeling. instance corresponds
mention represented 26 features deemed useful distinguishing
anaphoric non-anaphoric mentions (see Table 2 details). Linguistically,
features broadly divided three types: string-matching, grammatical,
semantic. either relational feature, compares mention one
preceding mentions, non-relational feature, encodes certain linguistic property
mention whose anaphoricity determined (e.g., NP type, number, definiteness).

4. Coreference Cluster Ranking
section, describe cluster-ranking approach NP coreference. noted
before, approach aims combine strengths entity-mention model
mention-ranking model.
4.1 Training Applying Cluster Ranker
ease exposition, describe subsection train apply clusterranking model used pipeline architecture, anaphoricity determination
performed prior coreference resolution. next subsection, show
two tasks learned jointly.
Recall cluster-ranking model ranks set preceding clusters active
mention mk . Since cluster-ranking model hybrid mention-ranking model
entity-mention model, way trained applied also hybrid
two. particular, instance representation employed cluster-ranking model
identical used entity-mention model, training instance i(cj , mk )
represents preceding cluster cj anaphoric mention mk consists clusterlevel features formed predicates. Unlike entity-mention model, however,
cluster-ranking model, (1) training instance created anaphoric mention mk
preceding clusters; (2) since training model ranking clusters,
assignment rank values training instances similar mention-ranking
model. Specifically, rank value training instance i(cj , mk ) created mk
rank cj among competing clusters, 2 mk belongs cj , 1 otherwise.
train cluster-ranking model, use SVM learner ranking mode, resulting
constrained optimization problem essentially Optimization Problem
3, except training example xijk represents active mention mk two
preceding clusters, ci cj , rather two preceding mentions.
Applying learned cluster ranker test text similar applying mentionranking model. Specifically, mentions processed left-to-right manner.
active mention mk , first apply independently-trained classifier determine mk
non-anaphoric. so, mk resolved. Otherwise, create test instances mk
10. See http://homepages.inf.ed.ac.uk/s0450736/maxent_toolkit.html.

484

fiA Cluster-Ranking Approach Coreference Resolution

Feature Type
Lexical

Feature
str match

head match

Grammatical
(NP type)

uppercase
definite
demonstrative
indefinite
quantified
article

Grammatical
(NP
property/
relationship

pronoun
proper noun
bare singular
bare plural
embedded
appositive
prednom
number

contains pn
Grammatical
(Syntactic
Pattern)

n
2n
pn
pn n
adj n
num n
ne
sing n

Semantic

alias

Description
exists mention mj preceding mk that,
discarding determiners, mj mk string; else
N.
exists mention mj preceding mk mj
mk head; else N.
mk entirely uppercase; else N.
mk starts the; else N.
mk starts demonstrative this, that,
these, those; else N.
mk starts an; else N.
mk starts quantifiers every, some, all,
most, many, much, few, none; else N.
definite mk definite NP; quantified mk quantified NP; else indefinite.
mk pronoun; else N.
mk proper noun; else N.
mk singular start article; else N.
mk plural start article; else N.
mk prenominal modifier; else N.
mk first two mentions appositive
construction; else N.
mk first two mentions predicate nominal
construction; else N.
singular mk singular number; plural mk plural
number; unknown number information cannot
determined.
mk proper noun contains proper noun; else
N.
mk starts followed exactly one common
noun; else N.
mk starts followed exactly two common
nouns; else N.
mk starts followed exactly proper noun;
else N.
mk starts followed exactly proper noun
common noun; else N.
mk starts followed exactly adjective
common noun; else N.
mk starts followed exactly cardinal
common noun; else N.
mk starts followed exactly named entity;
else N.
mk starts followed singular NP containing proper noun; else N.
exists mention mj preceding mk mj
mk aliases; else N.

Table 2: Feature set anaphoricity determination. instance represents single mention,
mk , characterized 26 features.
485

fiRahman & Ng

pairing preceding clusters. test instances presented
ranker, mk linked cluster assigned highest value ranker. Ties
broken preferring cluster whose last mention closest distance mk . Note
partial clusters preceding mk formed incrementally based predictions
ranker first k 1 mentions.
4.2 Joint Anaphoricity Determination Coreference Resolution
cluster ranker described used determine preceding cluster
anaphoric mention linked to, cannot used determine whether mention anaphoric not. reason simple: training instances generated
anaphoric mentions. Hence, jointly learn anaphoricity determination coreference
resolution, must train ranker using instances generated anaphoric
non-anaphoric mentions.
Specifically, training ranker, provide active mention option
start new cluster creating additional instance (1) contains features solely
describe active mention (i.e., features shown second block Table 1), (2)
highest rank value among competing clusters (i.e., 2) non-anaphoric
lowest rank value (i.e., 1) otherwise. main advantage jointly learning two tasks
allows ranking model evaluate possible options active mention
(i.e., whether resolve it, so, preceding cluster best) simultaneously.
Essentially method applied jointly learn two tasks mentionranking model.
training, resulting cluster ranker processes mentions test text
left-to-right manner. active mention mk , create test instances pairing
preceding clusters. allow possibility mk non-anaphoric,
create additional test instance contains features solely describe active
mention (similar training step above). test instances
presented ranker. additional test instance assigned highest rank value
ranker, mk classified non-anaphoric resolved. Otherwise,
mk linked cluster highest rank, ties broken preferring
antecedent closest mk . before, partial clusters preceding mk formed
incrementally based predictions ranker first k 1 mentions.
Finally, note model jointly learning anaphoricity determination coreference resolution different recent attempts perform joint inference anaphoricity
determination coreference resolution using integer linear programming (ILP),
anaphoricity classifier coreference classifier trained independently other,
ILP applied postprocessing step jointly infer anaphoricity coreference decisions consistent (e.g., Denis & Baldridge, 2007a).
Joint inference different joint-learning approach, allows two tasks
learned jointly independently.

5. Lexicalization Coreference Resolution
Next, investigate role lexicalization (i.e., use word pairs linguistic features)
learning-based coreference resolution. motivation behind investigation two486

fiA Cluster-Ranking Approach Coreference Resolution

fold. First, lexical features easy compute yet under-investigated
coreference resolution. particular, attempts made employ
train mention-pair model (e.g., Luo et al., 2004; Daume III & Marcu, 2005;
Bengtson & Roth, 2008). contrast, want determine whether improve
performance cluster-ranking model. Second, mention-pair model
mention-ranking model compared respect non-lexical feature set
(Denis & Baldridge, 2007b, 2008), clear perform relative
trained lexical features. desire answer question,
allow us gain additional insights strengths weaknesses
learning-based coreference models.
Recall introduction previous attempts lexicalizing mention-pair
model show lexical features best marginally useful. Hence, one goals
determine whether make better use lexical features learning-based
coreference resolver. particular, unlike aforementioned attempts lexicalization,
simply append word pairs conventional coreference feature set consisting
string-matching, grammatical, semantic, distance (i.e., proximity-based) features (e.g.,
feature set shown Table 1), investigate model exploits lexical features
combination small subset conventional coreference features.
would allow us better understanding significance conventional
features. example, features encode agreement gender, number, semantic
class two mentions employed virtually learning-based coreference resolver,
never question whether better alternatives features. could
build lexicalized coreference model without commonly-used features
observe performance deterioration, would imply conventional features
replaceable, prototypical way building learning-based coreference
system.
question is: small subset conventional features use
combination lexical features? mentioned above, since one advantages
lexical features extremely easy compute, desire conventional
features also easy compute, especially require dictionary
compute. see, choose use two features, alias feature
distance feature (see features 31 32 Table 1), rely off-the-shelf named
entity (NE) recognizer compute NE types.
Note, however, usefulness lexical features could limited part data
sparseness: many word pairs appear training data may appear test
data. employing conventional features described (e.g., distance)
help alleviate problem, seek improve generalizability introducing
two types features: semi-lexical unseen features. henceforth refer
feature set comprises two types features, lexical features, alias feature,
distance feature Lexical feature set. addition, refer feature
set shown Table 1 Conventional feature set.
first describe Lexical feature set training mention-pair model
mention-ranking model (Section 5.1). that, show create cluster-level
features feature set training entity-mention model cluster-ranking
487

fiRahman & Ng

model, well issues training joint model anaphoricity determination coreference resolution (Section 5.2).
5.1 Lexical Feature Set
Unlike previous work lexicalizing learning-based coreference models, Lexical feature
set consists four types features: lexical features, semi-lexical features, unseen features,
well two conventional features (namely, alias distance).
compute features, preprocess training text randomly replacing 10%
nominal mentions (i.e., common nouns) label unseen. mention mk
replaced unseen, mentions string mk also replaced
unseen. test text preprocessed differently: simply replace mentions whose
strings seen training data unseen. Hence, artificially creating unseen
labels training text allow learner learn handle unseen words
test text, potentially improving generalizability.
preprocessing, compute features instance. Assuming
training mention-pair model mention-ranking model, instance corresponds
two mentions, mj mk , mj precedes mk text. features
divided four groups: unseen, lexical, semi-lexical, conventional. describing
features, two points deserve mention. First, least one mj mk unseen,
lexical, semi-lexical, conventional features created them, since features
involving unseen mention likely misleading learner sense
may yield incorrect generalizations training set. Second, since use SVM
training testing, instance contain number features, unless otherwise
stated, feature value 1.
Unseen feature. mj mk unseen, determine whether
string. so, create unseen-same feature; otherwise, create unseendiff feature. one unseen, feature created.
Lexical feature. create lexical feature mj mk , ordered
pair consisting heads mentions. pronoun common noun, head
assumed last word mention11 ; proper noun, head taken
entire noun phrase.
Semi-lexical features. features aim improve generalizability. Specifically,
exactly one mj mk tagged NE Stanford NE recognizer (Finkel et al.,
2005), create semi-lexical feature identical lexical feature described above,
except NE replaced NE label (i.e., person, location, organization).
mentions NEs, check whether string. so, create
feature *ne*-same, *ne* replaced corresponding NE label. Otherwise,
check whether NE tag word-subset match (i.e., whether
11. see evaluation section, mention extractor trained extract base NPs. Hence,
heuristic extracting head nouns arguably overly simplistic, applied
recursive NPs (e.g., NPs contain prepositional phrases), phrases likely
make mistakes. However, desire better extraction accuracy, extract head nouns
syntactic parsers provide head information, Collinss (1999) parser.

488

fiA Cluster-Ranking Approach Coreference Resolution

word tokens one mention appear others list tokens). so, create feature
*ne*-subsame, *ne* replaced NE label. Otherwise, create feature
concatenation NE labels two mentions.
Conventional features. improve generalizability, incorporate two easy-to
compute features Conventional feature set: alias distance.
5.2 Feature Generation
Lexical feature set training mention-pair model mentionranking model, describe two extensions feature set needed
(1) train entity-mention model cluster-ranking model, (2) perform joint
learning anaphoricity determination coreference resolution.
first extension concerns generation cluster-level features entity-mention
model cluster-level model. Recall Section 3.2 create cluster-level features given Conventional feature set, first convert feature employed
mention-pair model equivalent set binary-valued features, create
cluster-level feature resulting binary-valued features. hand,
given Lexical feature set, method producing cluster-level features applicable two conventional features (i.e., alias distance), also appear
Conventional feature set. unseen, lexical, semi-lexical feature, create
feature active mention mention preceding cluster, described
Section 5.112 , value feature number times appears instance. Encoding feature values frequency rather binary values allows us capture
cluster-level information shallow manner.
second extension concerns generation features representing additional
instance created training joint version mention-ranking model
cluster-ranking model. Recall Section 4.2 Conventional feature set
used, represented additional instance using features computed solely
active mention. hand, given Lexical feature set, longer
use method representing additional instance, feature
Lexical feature set computed solely active mention. result,
represent additional instance using one feature, null-x, x head
active mention, help learner learn x likely non-anaphoric.

6. Evaluation
evaluation driven following questions, focusing (1) comparison among
different learning-based coreference models, (2) effect lexicalization
models. Specifically:
learning-based coreference models (namely, mention-pair model,
entity-mention model, mention-ranking model, cluster-ranking model)
compare other?
12. Strictly speaking, resulting feature cluster-level feature, computed active
mention one mentions preceding cluster.

489

fiRahman & Ng

joint modeling anaphoricity determination coreference resolution offer
benefits pipeline architecture, anaphoricity performed prior
coreference resolution?
lexicalized coreference models perform better unlexicalized counterparts?
rest section, first describe experimental setup (Section 6.1),
show performance four models, including effect lexicalization
joint modeling whenever applicable, three different feature sets (Section 6.2).
6.1 Experimental Setup
begin providing details data sets, automatic mention extraction
method, scoring programs.
6.1.1 Corpus
use ACE 2005 coreference corpus released LDC, consists 599
training documents used official ACE evaluation.13 ensure diversity, corpus
created selecting documents six different sources: Broadcast News (BN), Broadcast
Conversations (BC), Newswire (NW), Webblog (WB), Usenet (UN), Conversational
Telephone Speech (CTS). number documents belonging source shown
Table 3.
Data set
# documents

BN
226

BC
60

NW
106

WL
119

UN
49

CTS
39

Table 3: Statistics ACE 2005 corpus

6.1.2 Mention Extraction
evaluate coreference model using system mentions. extract system mentions
test text, trained mention extractor training texts. Following Florian
et al. (2004), recast mention extraction sequence labeling task, assign
token test text label indicates whether begins mention, inside
mention, outside mention. Hence, learn extractor, create one training
instance token training text derive class value (one b, i, o)
annotated data. instance represents wi , token consideration,
consists 29 linguistic features, many modeled systems Bikel,
Schwartz, Weischedel (1999) Florian et al. (2004), described below.
Lexical (7):

Tokens window 7: {wi3 , . . . , wi+3 }.

Capitalization (4): Determine whether wi IsAllCap, IsInitCap, IsCapPeriod,
IsAllLower.
13. Since participate ACE 2005, access official test set.

490

fiA Cluster-Ranking Approach Coreference Resolution

Morphological (8): wi prefixes suffixes length one, two, three, four.
Grammatical (1): part-of-speech (POS) tag wi obtained using Stanford loglinear POS tagger (Toutanova, Klein, Manning, & Singer, 2003).
Semantic (1): named entity (NE) tag wi obtained using Stanford CRF-based
NE recognizer (Finkel et al., 2005).
Dictionaries (8): employ eight dictionary-based features indicate presence
absence wi particular dictionary. eight dictionaries contain pronouns (77
entries), common words words names (399.6k), person names (83.6k),
person titles honorifics (761), vehicle words (226), location names (1.8k), company
names (77.6k), nouns extracted WordNet hyponyms person (6.3k).
employ CRF++14 , C++ implementation conditional random fields, training
mention detector training set. Overall, detector achieves F-measure
86.7 (86.1 recall, 87.2 precision) test set. extracted mentions used
system mentions coreference experiments.
6.1.3 Scoring Programs
score output coreference model, employ two scoring programs, B3 (Bagga
& Baldwin, 1998) 3 -CEAF15 (Luo, 2005), address inherent weaknesses
MUC scoring program (Vilain, Burger, Aberdeen, Connolly, & Hirschman, 1995).16
B3 CEAF score response (i.e., system-generated) partition, R, key
(i.e., gold-standard) partition, K, report coreference performance terms recall,
precision, F-measure. B3 first computes recall precision mention, mk ,
follows:
recall(mk ) =

|Rmk Kmk |
|Rmk Kmk |
, precision(mk ) =
,
|Kmk |
|Rmk |

Rmk coreference cluster containing mk R, Kmk coreference cluster
containing mk K. computes overall recall (resp. precision) averaging
per-mention recall (resp. precision) scores.
hand, CEAF first constructs optimal one-to-one mapping
clusters key partition response partition. Specifically, assume
K = {K1 , K2 , . . . , Km } set clusters key partition, R = {R1 , R2 , . . . , Rn }
set clusters response partition. compute recall, CEAF first computes
score cluster, Ki , K follows:
score(Ki ) = |Ki Rj |,
14. Available http://crfpp.sourceforge.net
15. CEAF two versions: 3 -CEAF 4 -CEAF. two versions differ similarity two
aligned clusters computed. refer reader Luos (2005) paper details. 3 -CEAF chosen
commonly-used version CEAF.
16. Briefly, MUC scoring program suffers two often-cited weaknesses. First, link-based measure,
reward successful identification singleton clusters, since mentions clusters
linked mentions. Second, tends under-penalize partitions overly large clusters.
See work Bagga Baldwin (1998), Luo (2005), Recasens Hovy (2011) details.

491

fiRahman & Ng

Rj cluster Ki mapped optimal one-to-one mapping,
constructed efficiently using Kuhn-Munkres algorithm (Kuhn, 1955). Note
Ki mapped cluster R, score(Ki ) = 0. CEAF computes recall
summing score cluster K dividing sum number mentions
K. Precision computed manner, except reverse roles
K R.
complication arises B3 used score response partition containing system
mentions. Recall B3 constructs mapping mentions response
key. Hence, response generated using gold-standard mentions,
every mention response mapped mention key vice versa.
words, twinless (i.e., unmapped) mentions (Stoyanov et al., 2009).
case system mentions used, original description B3
specify twinless mentions scored (Bagga & Baldwin, 1998). address
problem, set per-mention recall precision twinless mention zero,
regardless whether mention appears key response. Note CEAF
compare partitions twinless mentions without modification, since operates
aligning clusters, mentions.
Additionally, apply preprocessing step response partition scoring it:
remove twinless system mentions singletons. reason
simple: since coreference resolver successfully identified mentions singletons,
penalized, removing allows us avoid penalty. Note
remove twinless (as opposed all) system mentions singletons: allows
us reward resolver successful identification singleton mentions twins.
hand, retain (1) twinless system mentions non-singletons (as
resolver penalized identifying spurious coreference relations) (2) twinless
mentions key partition (as want ensure resolver makes correct
coreference non-coreference decisions them).17
6.2 Results
showing results learning-based coreference models, let us consider head
match baseline, commonly-used heuristic baseline coreference resolution.
posits two mentions coreferent head nouns match. Head nouns
determined described Section 5.1: head proper noun string entire
mention, whereas head pronoun common noun last word mention.
Since one goals examine effect lexicalization coreference model,
head match baseline provide information well one simplest
kinds string matching. Results baseline, shown row 1 Table 4, expressed
terms recall (R), precision (P), F-measure (F) obtained via B3 CEAF.
see Table 4, baseline achieves F-measure scores 54.9 49.6 according
B3 CEAF, respectively.
17. addition method described here, number methods proposed address
mapping problem. refer reader work Enrique, Gonzalo, Artiles, Verdejo (2009),
Stoyanov et al. (2009), Cai Strube (2010) details.

492

fiA Cluster-Ranking Approach Coreference Resolution

Next, train evaluate learning-based coreference models using five-fold cross
validation. data set si shown Table 3, partition documents si
five folds approximately equal size, si1 , . . . , si5 . train coreference model
four folds use generate coreference chains documents remaining
fold, repeating step five times fold used test fold exactly once.
that, apply B3 CEAF entire set automatically coreference-annotated
documents obtain scores Table 4. discuss results learningbased coreference models obtained used combination three feature sets:
Conventional feature set (Section 6.2.1), Lexical feature set (Section 6.2.2),
Combined feature set, composed features Conventional Lexical
(Section 6.2.3).
6.2.1 Results Using Conventional Features
gauge performance cluster-ranking model, employ baselines mentionpair model, entity-mention model, mention-ranking model.
mention-pair baseline. train first learning-based baseline, mentionpair model, using SVM learning algorithm implemented SVMlight package.18
see row 2 Table 4, mention-pair model achieves F-measure scores
58.6 (B3 ) 54.4 (CEAF), represent statistically significant improvement 3.7%
4.8% F-measure corresponding results head match baseline.19
entity-mention baseline. Next, train second learning-based baseline,
entity-mention model, using SVM learner. see row 3 Table 4,
baseline achieves F-measure scores 58.9 (B3 ) 54.8 (CEAF), represent small
statistically significant improvements mention-pair model. significant performance difference perhaps particularly surprising given improved expressiveness
entity-mention model mention-pair model.
mention-ranking baseline. third baseline mention-ranking model,
trained using ranker-learning algorithm SVMlight . identify non-anaphoric mentions, employ two methods. first method, follow Denis Baldridge (2008)
adopt pipeline architecture, train MaxEnt classifier anaphoricity determination independently mention ranker training set using 26 features
described Section 3.3. apply resulting classifier test text filter nonanaphoric mentions prior coreference resolution. Results pipeline mention ranker
shown row 4 Table 4. see, ranker achieves F-measure scores 57.7
(B3 ) 53.0 (CEAF), yielding significant performance deterioration comparison
entity-mention baseline.
second method, perform anaphoricity determination jointly coreference
resolution using method described Section 4.2. discussed joint learning
method context cluster ranking, easy see method
equally applicable mention-ranking model. Results mention ranker using
18. subsequent uses SVM learner, set parameters default values.
particular, employ linear kernel obtain results article.
19. statistical significance results article obtained using paired t-test, p < 0.05.

493

fiRahman & Ng

R
44.1

B3
P
72.9

CEAF
P
F
60.8 49.6

1

Coreference Model
Head match

F
54.9

R
41.9

2
3
4
5
6
7

Using Conventional feature set
Mention-pair model
49.7 71.4 58.6
Entity-mention model
49.9 71.7 58.9
Mention-ranking model (Pipeline)
48.1 72.1 57.7
Mention-ranking model (Joint)
49.1 76.1 59.7
Cluster-ranking model (Pipeline)
49.9 71.6 58.8
Cluster-ranking model (Joint)
51.1 73.3 60.2

49.5
51.0
51.7
52.9
53.4
54.1

60.5
59.2
54.4
59.2
54.6
60.2

54.4
54.8
53.0
55.9
54.0
57.0

8
9
10
11
12
13

Using Lexical feature set
Mention-pair model
53.0 75.3 62.2
Entity-mention model
53.1 75.8 62.5
Mention-ranking model (Pipeline)
55.7 67.5 61.0
Mention-ranking model (Joint)
56.6 73.1 63.8
Cluster-ranking model (Pipeline)
51.0 67.1 58.0
Cluster-ranking model (Joint)
51.3 75.7 61.1

55.6
55.7
56.3
58.5
53.1
53.3

62.0
62.2
62.0
65.0
55.3
58.6

58.6
58.8
59.0
61.6
54.1
55.8

14
15
16
17
18
19

Using Combined
Mention-pair model
50.4
Entity-mention model
50.5
Mention-ranking model (Pipeline)
50.6
Mention-ranking model (Joint)
49.9
Cluster-ranking model (Pipeline)
52.9
Cluster-ranking model (Joint)
54.3

53.8
54.1
54.1
54.7
57.5
57.6

61.9
62.3
61.8
61.4
62.1
64.3

57.5
57.9
57.7
57.9
59.7
60.8

feature
73.1
73.4
74.6
79.3
70.9
75.1

set
59.6
59.8
60.3
61.3
60.6
63.0

Table 4: Five-fold cross-validation coreference results obtained using B3 CEAF.
best F-measure achieved feature set/scoring program combination boldfaced.

joint architecture shown row 5 Table 4. see, ranker achieves Fmeasure scores 59.7 (B3 ) 55.9 (CEAF), represent significant improvements
entity-mention model pipeline counterpart. results
demonstrate superiority joint mention-ranking model entity-mention model,
substantiate hypothesis joint modeling offers benefits pipeline modeling.
cluster-ranking model. Finally, evaluate cluster-ranking model.
mention-ranking baselines, employ pipeline architecture joint architecture anaphoricity determination. Results shown rows 6 7 Table 4,
respectively, two architectures. see, pipeline architecture yields Fmeasure scores 58.8 (B3 ) 54.0 (CEAF), represent significant improvement
mention ranker adopting pipeline architecture. joint architecture,
cluster ranker achieves F-measure scores 60.2 (B3 ) 57.0 (CEAF). also rep494

fiA Cluster-Ranking Approach Coreference Resolution

resents significant improvement mention ranker adopting joint architecture,
best baselines. Taken together, results demonstrate superiority
cluster ranker mention ranker. Finally, fact joint cluster ranker performs
significantly better pipeline counterpart provides empirical support
benefits joint modeling pipeline modeling.
6.2.2 Results Using Lexical Features
Next, evaluate learning-based coreference models using Lexical features. Results
shown rows 813 Table 4. comparison results obtained using Conventional features, see different trend: joint mention-ranking model replaces
cluster-ranking model best-performing model. Moreover, improvement
second best-performing model, entity-mention model according B3
pipeline mention-ranking model according CEAF, statistically significant regardless
scoring program used. closer examination results reveals employing
Lexical rather Conventional features substantially improves performance
mention-ranking model: comparison unlexicalized joint mention-ranking model
(row 5), F-measure scores lexicalized joint mention-ranking model (row 11) rise
4.1% (B3 ) 5.7% (CEAF). increase F-measure attributed primarily
substantial rise recall, even though also large increase CEAF precision.
Besides joint mention-ranking model, mention-pair model entity-mention
model also benefit substantially Conventional features replaced Lexical features: see F-measure scores increase 3.6% (B3 ) 4.2% (CEAF)
mention-pair model, 3.6% (B3 ) 4.0% (CEAF) entity-mention model.
gains F-measure two models attributed large increases
recall precision. hand, joint cluster-ranking model always
improve replace Conventional features Lexical features. fact,
performance difference cluster-ranking model entity-mention model
statistically indistinguishable. Finally, see benefits jointly learning anaphoricity
determination coreference resolution again: joint version mentionranking model used rather pipeline version (compare rows 10 11),
F-measure scores rise significantly 2.8% (B3 ) 2.6% (CEAF). Similarly clusterranking model: joint version improves pipeline version significantly 3.1% (B3 )
1.7% (CEAF) F-measure.
Overall, results somewhat unexpected: recall Lexical features
knowledge-lean, consisting lexical, semi-lexical, unseen features, well
two Conventional features. particular, employ conventional coreference
features encode agreement gender number. implies many existing
implementations mention-pair model, entity-mention model, mentionranking model, unlexicalized rely heavily conventional features,
making effective use labeled data. Perhaps importantly, results indicate
coreference models perform well (and fact better) even without conventional
coreference features. Since Lexical computed extremely easily,
readily applied languages, another advantage feature set.
hand, interesting see versions cluster-ranking model exhibit
495

fiRahman & Ng

less dramatic changes performance replace Conventional features
Lexical features.
6.2.3 Results Using Combined Features
Since Conventional features Lexical features represent two fairly different sources
knowledge, examine whether improve coreference models combining
two feature sets. Results coreference models using Combined features
shown rows 1419 Table 4. results exhibit essentially trend
obtained Conventional features, joint cluster-ranking model performing
best mention-pair model performing worst. fact, joint cluster-ranking
model yields significantly better performance used Combined features
Conventional features Lexical features alone. Similarly pipeline
cluster-ranking model, achieves significantly better performance Combined
features Conventional Lexical features. results seem suggest
cluster-ranking model able exploit potentially different sources information
provided two feature sets improve performance. addition, demonstrate
benefits joint modeling: mention-ranking model, joint version improves
pipeline version significantly 1.0% (B3 ) 0.2% (CEAF) F-measure;
cluster-ranking model, joint version improves pipeline counterpart significantly
2.4% (B3 ) 1.1% (CEAF) F-measure.
remaining coreference models exhibit drop performance Combined
features used lieu Lexical features. results seem suggest
cluster-ranking model offers robust performance face changes underlying feature set coreference models, feature selection, issue
under-explored coreference resolution, may crucial employ coreference models.20 Perhaps importantly, despite fact Conventional features
Lexical features represent two fairly different sources information,
cluster-ranking model unable exploit potentially richer amount information
contained Combined feature set. Hence, virtually linguistic features
recently developed supervised coreference resolution evaluated using
mention-pair model (see, example, work Strube, Rapp, & Muller, 2002; Ji,
Westbrook, & Grishman, 2005; Ponzetto & Strube, 2006), utility features may
better demonstrated using cluster-ranking model.
natural question is: joint cluster-ranking model compare existing
coreference systems? Since participate ACE evaluations,
access official test sets compare model ACE
participating coreference systems. comparison complicated fact
existing coreference systems evaluated different data sets, including two
MUC data sets (MUC-6, 1995; MUC-7, 1998) various ACE data sets (e.g., ACE-2,
ACE 2003, ACE 2004, ACE 2005), well different partitions given data set.
knowledge, coreference model evaluated test
data Haghighi Kleins (2010) unsupervised coreference model. model
20. fact, Ng Cardie (2002b), Strube Muller (2003), Ponzetto Strube (2006) show
mention-pair model improved using feature selection.

496

fiA Cluster-Ranking Approach Coreference Resolution

recently shown surpass performance Stoyanov et al.s (2009) system,
one best existing implementations mention-pair model. test
data, Haghighi Kleins model achieves B3 F-measure 62.7, achieves
B3 F-measure 62.8.21 results provide suggestive evidence cluster-ranking
model achieves performance comparable one best existing coreference
models.
Nevertheless, caution results allow one claim anything
fact model compares favorably Haghighi Kleins (2010) model.
instance, one cannot claim model better achieves level
performance without using labeled data. reasons (1) mentions
used two models coreference process extracted differently (2)
linguistic features employed two models way features computed
also different other. Since previous work shown linguistic
preprocessing steps considerable impact performance resolver (Barbu
& Mitkov, 2001; Stoyanov et al., 2009), possible one model employed features
mentions model currently using, results would different.
Hence, one fairly compare two coreference models, evaluated
set mentions (rather set documents) given access
set knowledge sources, essentially way compare various
learning-based coreference models article.

7. Experimental Analyses
attempt gain insights different aspects coreference models,
conduct additional experiments analyses. Rather report five-fold cross-validation
results, section report results one fold (i.e., fold designate test
set) use remaining four folds solely training.
7.1 Improving Classification-Based Coreference Models
Given generally poorer performance classification-based coreference models, natural question is: improved? answer question, investigate whether
models improved employing different clustering algorithm different
learning algorithm. reasons decision focus two dimensions.
First, noted introduction, one weaknesses models
clear clustering algorithm offers best performance. Given observation,
examine whether improve models replacing Soon et al.s (2001)
closest-first linking regime best-first linking strategy, shown
offer better performance mention-pair model MUC data sets (Ng & Cardie,
2002b). Second, discussed end Section 2, may able achieve
advantage ranking classification-based models employing learning algorithm
optimizes conditional probabilities instead 0/1 decisions. Motivated observation, examine whether improve classification-based models training
using MaxEnt, employs likelihood-based loss function. Note MaxEnt one
21. Note Haghighi Klein report CEAF scores paper.

497

fiRahman & Ng

popular learning algorithms training coreference models (see, example,
Morton, 2000; Kehler, Appelt, Taylor, & Simma, 2004; Ponzetto & Strube, 2006; Denis &
Baldridge, 2008; Finkel & Manning, 2008; Ng, 2009).
evaluate two modifications, apply isolation combination
two classification-based models (i.e., mention-pair model entity-mention
model) trained using three different feature sets (i.e., Conventional, Lexical, Combined). train MaxEnt-based coreference models using YASMET22 ,
follow Ng Cardies (2002b) implementation best-first clustering algorithm.
Specifically, among candidate antecedents preceding clusters classified
coreferent active mention mk , best-first clustering links mk likely one.
MaxEnt model, pair classified coreferent classification value
0.5, likely antecedent/preceding cluster mk one
highest probability coreference mk . SVMlight -trained model, pair
classified coreferent classification value 0, likely
antecedent/preceding cluster mk one positive classification
value.
Table 5 presents B3 CEAF results two classification-based coreference models
trained using two learning algorithms (i.e., SVM MaxEnt) used
combination two clustering algorithms (i.e., closest-first clustering best-first
clustering). study choice clustering algorithm impacts performance,
compare results closest-first clustering best-first clustering Table 5
combination learning algorithm, feature set, coreference model, scoring
program. instance, comparing rows 1 2 Table 5 enables us examine
two clustering algorithms better mention-pair model trained
Conventional feature set two learners. Overall, see fairly consistent
trend: best-first clustering yields results slightly worse obtained using
closest-first clustering, regardless choice clustering algorithm, learning
algorithm, feature set, scoring program. first glance, results seem
contradictory Ng Cardie (2002b), demonstrate superiority bestfirst clustering closest-first clustering coreference resolution. speculate
contradictory results attributed two reasons. First, best-first clustering
experiments, still employed Soon et al.s (2001) training instance selection method,
created positive training instance anaphoric mention closest
antecedent/preceding cluster, unlike Ng Cardie, claim proposed bestfirst clustering successful, however, different method training instance selection
would needed. particular, propose use confident antecedent,
rather closest antecedent, generate positive instances anaphoric mention.
Second, Ng Cardie demonstrate success best-first clustering MUC data
sets, possible success may carry ACE data sets. Additional
experiments needed determine reason, however.
22. See http://www.fjoch.com/YASMET.html. reason YASMET chosen provides
capability rank, allows us compare results MaxEnt-trained classification models
ranking models. See work Ravichandran, Hovy, Och (2003) discussion differences
training two types MaxEnt models.

498

fiA Cluster-Ranking Approach Coreference Resolution

Coreference Model

R

SVM
P

F

R

MaxEnt
P
F

1
2
3
4

B3 results using Conventional feature
Mention-pair model (Closest first)
46.2 72.0 56.2
Mention-pair model (Best first)
45.7 71.0 55.6
Entity-mention model (Closest first) 46.8 72.5 56.8
Entity-mention model (Best first)
46.3 72.1 56.3

set
59.6
59.2
59.7
59.3

55.3
54.8
55.9
55.1

57.3
56.9
57.7
57.1

5
6
7
8

B3 results using Lexical feature set
Mention-pair model (Closest first)
52.8 73.0 61.2
Mention-pair model (Best first)
52.1 72.1 60.5
Entity-mention model (Closest first) 52.8 73.6 61.2
Entity-mention model (Best first)
52.4 72.2 60.8

52.8
52.1
52.8
52.2

64.6
64.2
64.6
64.3

58.1
57.5
58.2
57.6

Combined feature set
49.1 73.2 58.8
50.3
48.7 72.8 58.3
49.3
49.5 73.2 59.1 50.5
49.1 72.7 58.6
50.1

65.9
65.2
66.1
65.6

57.0
56.1
57.3
56.8

13
14
15
16

CEAF results using Conventional feature set
Mention-pair model (Closest first)
48.5 55.3 51.6
51.4
Mention-pair model (Best first)
48.1 54.9 51.2
51.1
Entity-mention model (Closest first) 49.5 55.8 52.5
51.4
Entity-mention model (Best first)
49.2 55.1 51.9
51.1

56.5
56.1
56.7
56.2

53.8
53.4
53.9
53.5

17
18
19
20

CEAF results using
Mention-pair model (Closest first)
Mention-pair model (Best first)
Entity-mention model (Closest first)
Entity-mention model (Best first)

56.8
56.2
57.4
56.9

55.1
54.6
55.3
54.9

21
22
23
24

CEAF results using Combined
Mention-pair model (Closest first)
53.8 60.0
Mention-pair model (Best first)
53.1 59.7
Entity-mention model (Closest first) 54.1 60.9
Entity-mention model (Best first)
53.7 60.3

56.3
55.8
56.8
56.2

55.5
55.0
55.9
55.3

9
10
11
12

B3 results using
Mention-pair model (Closest first)
Mention-pair model (Best first)
Entity-mention model (Closest first)
Entity-mention model (Best first)

(a) B3 results

Lexical feature set
54.6 61.2 57.7
53.5
54.2 60.7 57.3
53.1
54.9 61.7 58.1 53.5
54.5 61.1 57.6
53.1
feature
56.7
56.2
57.3
56.8

set
54.9
54.3
55.1
54.5

(b) CEAF3 results

Table 5: SVM vs. MaxEnt results classification-based coreference models. one-fold
B3 CEAF scores obtained training coreference models using SVM MaxEnt.
best F-measure achieved feature set/scoring program combination boldfaced.
499

fiRahman & Ng

Next, examine whether minimizing likelihood-based loss via MaxEnt training instead
SVMs classification loss would enable us achieve advantage ranking
(and hence leads better performance), compare two columns Table 5.
see, Conventional feature set used, MaxEnt outperforms SVM, regardless
choice clustering algorithm, scoring program, coreference model.
hand, Lexical features Combined features used, SVM outperforms
MaxEnt consistently. Overall, mixed results seem suggest whether MaxEnt
offers better performance SVM extent dependent underlying feature
set.
7.2 Performance Maximum-Entropy-Based Ranking Models
prior work suggests MaxEnt-based ranking may provide better gains SVMbased ranking, since generate reliable confidence values dynamically adjust
relative ranks according baseline results (e.g., Ji, Rudin, & Grishman, 2006). determine whether case coreference resolution, conduct experiments
train ranking-based coreference models using ranker-learning algorithm YASMET.
B3 CEAF results mention-ranking model cluster-ranking model
trained using MaxEnt combination three different feature sets (i.e., Conventional,
Lexical, Combined) shown MaxEnt column Table 6. comparison,
also show corresponding results obtained via SVM-based ranking table
(see SVM column). Comparing two columns, see mixed results: 24
experiments involve ranking models, MaxEnt-based ranking outperforms SVM-based
ranking six them. words, results suggest coreference task,
SVM-based ranking generally better MaxEnt-based ranking.
7.3 Accuracy Anaphoricity Determination
Section 6.2, saw joint ranking model always performs significantly better
pipeline counterpart. words, joint modeling coreference anaphoricity
improves coreference resolution. natural question is: joint modeling also improve
anaphoricity determination?
answer question, measure accuracy anaphoricity information resulting pipeline modeling joint modeling. Recall pipeline modeling, rely
output anaphoricity classifier trained independently coreference
system uses anaphoricity information (see Section 3.3). accuracy classifier test set shown Acc column row 1 Table 7. addition,
show table recall (R), precision (P), F-measure (F) identifying anaphoric
mentions. see, classifier achieves accuracy 81.1 F-measure score
83.8.
hand, joint modeling, compute accuracy anaphoricity
determination output joint coreference model. Specifically, given output
joint model, determine mentions resolved preceding antecedent
not. Assuming mention resolved anaphoric one
resolved non-anaphoric, compute accuracy anaphoricity determination
500

fiA Cluster-Ranking Approach Coreference Resolution

Coreference Model

R

SVM
P

F

R

MaxEnt
P
F

1
2
3
4

B3 results using Conventional feature
Mention-ranking model (Pipeline)
46.7 71.5 56.5
Mention-ranking model (Joint)
47.6 74.8 58.2
Cluster-ranking model (Pipeline)
53.6 59.5 56.4
Cluster-ranking model (Joint)
52.2 73.8 61.2

set
58.7
59.1
51.7
52.1

59.1
59.3
69.9
70.6

58.8
59.2
59.3
60.0

5
6
7
8

B3 results using Lexical feature set
Mention-ranking model (Pipeline)
53.8 68.3 60.1
Mention-ranking model (Joint)
54.6 72.8 62.4
Cluster-ranking model (Pipeline)
51.7 68.2 58.8
Cluster-ranking model (Joint)
52.9 73.4 61.5

56.6
56.3
48.4
48.0

61.1
64.4
66.6
72.9

58.8
60.1
56.1
57.8

Combined feature set
49.8 72.6 59.1
51.4
50.5 77.6 61.2
52.5
53.8 71.2 61.3
54.1
54.4 74.8 62.8 54.5

68.3
70.3
67.5
68.3

58.7
60.1
60.1
60.6

Conventional feature set
49.4 55.7 52.4
51.5
50.5 56.3 53.2
51.8
53.6 59.5 56.4
53.1
55.2 61.6 58.2 53.2

56.6
56.9
58.7
59.3

53.9
54.2
55.8
56.1

9
10
11
12

B3 results using
Mention-ranking model (Pipeline)
Mention-ranking model (Joint)
Cluster-ranking model (Pipeline)
Cluster-ranking model (Joint)

(a) B3 results

13
14
15
16

CEAF results using
Mention-ranking model (Pipeline)
Mention-ranking model (Joint)
Cluster-ranking model (Pipeline)
Cluster-ranking model (Joint)

17
18
19
20

CEAF results using
Mention-ranking model (Pipeline)
Mention-ranking model (Joint)
Cluster-ranking model (Pipeline)
Cluster-ranking model (Joint)

Lexical feature set
54.7 59.8 57.1
55.7
56.9 63.3 59.9 55.4
52.7 58.4 55.4
50.9
55.0 61.4 58.1
50.5

56.6
60.7
52.3
56.6

56.1
57.9
51.5
53.3

21
22
23
24

CEAF results
Mention-ranking model (Pipeline)
Mention-ranking model (Joint)
Cluster-ranking model (Pipeline)
Cluster-ranking model (Joint)

Combined feature set
53.7 58.8 56.1
54.9 61.7 58.1
55.1 60.1 57.4
58.4 65.1 61.6

58.7
56.3
60.0
62.5

55.9
55.5
57.9
59.5

53.4
54.9
56.1
56.7

(b) CEAF results

Table 6: SVM vs. MaxEnt results ranking-basd coreference models. one-fold B3
CEAF scores obtained training coreference models using SVM MaxEnt. best
F-measure achieved feature set/scoring program combination boldfaced.
501

fiRahman & Ng

1
2
3
4
5
6
7

Source Anaphoricity Information
Anaphoricity Classifier
Mention-ranking (Conventional)
Cluster-ranking (Conventional)
Mention-ranking (Lexical)
Cluster-ranking (Lexical)
Mention-ranking (Combined)
Cluster-ranking (Combined)

Acc
81.1
78.7
81.9
84.2
83.1
79.1
83.1

R
87.6
83.1
87.8
88.3
87.9
84.3
87.4

P
80.3
79.3
80.4
82.1
81.8
79.1
82.1

F
83.8
81.2
83.9
85.1
84.7
81.6
84.6

Table 7: Anaphoricity determination results.

well precision, recall, F-measure identifying anaphoric mentions. Since
performance numbers derived output joint model, compute
two joint ranking models (i.e., mention-ranking model
cluster-ranking model) used combination three coreference feature
sets (i.e., Conventional, Lexical, Combined). results six sets performance
numbers, shown rows 27 Table 4. see, accuracies range
78.7 84.2, F-measure scores range 81.2 85.1.
comparison results anaphoricity classifier shown row 1, see
joint modeling improves performance anaphoricity determination except two
cases, namely, mention-ranking/Conventional mention-ranking/Combined.
words, two cases, joint modeling benefits coreference resolution anaphoricity determination. seems counter-intuitive one achieve better coreference
performance lower accuracy determining anaphoricity, difficult
see reason: joint model trained maximize pairwise ranking accuracy,
presumably correlates coreference performance, whereas anaphoricity classifier trained maximize accuracy determining anaphoricity mention,
may always correlation coreference performance. words,
improvements anaphoricity accuracy generally necessarily imply corresponding
improvements clustering-level coreference accuracy.
Finally, important bear mind conclusions drawn regarding
pipeline joint modeling based results anaphoricity classifier trained
26 features. possible different conclusions could drawn trained
anaphoricity classifier different set features. Therefore, interesting future direction
would improve anaphoricity classifier employing additional features,
proposed Uryupina (2003). may also able derive sophisticated features
harnessing recent advances lexical semantics research, specifically using methods
phrase clustering (e.g., Lin & Wu, 2009), lexical chain discovery (e.g., Morris & Hirst,
1991), paraphrase discovery (see survey papers Androutsopoulos & Malakasiotis,
2010; Madnani & Dorr, 2010).
502

fiA Cluster-Ranking Approach Coreference Resolution

7.4 Joint Inference Versus Joint Learning Mention-Pair Model
mentioned end Section 4.2, joint modeling anaphoricity determination
coreference resolution fundamentally different joint inference two tasks.
Recall joint inference using ILP, anaphoricity classifier coreference classifier
trained independently other, ILP applied postprocessing step
jointly infer anaphoricity coreference decisions consistent
(e.g., Denis & Baldridge, 2007a). subsection, investigate joint learning
compares joint inference anaphoricity determination coreference resolution.
Let us begin overview ILP approach proposed Denis Baldridge
(2007a) joint inference anaphoricity determination coreference resolution.
ILP approach motivated observation output anaphoricity model
coreference model given document satisfy certain constraints.
instance, coreference model determines mention mk coreferent
mentions associated text, anaphoricity model determine
mk non-anaphoric. practice, however, since two models trained independently
other, constraints cannot enforced.
Denis Baldridge (2007a) provide ILP framework jointly determining anaphoricity coreference decisions given set mentions based probabilities provided
anaphoricity model PA mention-pair coreference model PC ,
resulting joint decisions satisfy desired constraints respecting much possible probabilistic decisions made independently-trained PA PC . Specifically, ILP program composed objective function optimized subject
set linear constraints, created test text follows. Let
set mentions D, P set mention pairs formed (i.e., P =
{(mj , mk ) | mj , mk M, j < k}). ILP program set indicator variables.
case, one binary-valued variable anaphoricity decision coreference
decision made ILP solver. Following Denis Baldridges notation, use
yk denote anaphoricity decision mention mk , xhj,ki denote coreference
decision involving mentions mj mk . addition, variable associated
assignment cost. Specifically, let cC
hj,ki = log(PC (mj , mk )) cost setting xhj,ki
C
1, chj,ki = log(1 PC (mj , mk )) complementary cost setting xhj,ki 0.
similarly define cost associated yk , letting cA
k = log(PA (mk ))
=

log(1

P
(m
))


complementary
cost setting
cost setting yk 1, cA

k
k
yk 0. Given costs, aim optimize following objective function:
min

X

C
cC
hj,ki xhj,ki + chj,ki (1 xhj,ki ) +

X


cA
k yk + ck (1 yk )

mk

(mj ,mk )P

subject set manually-specified linear constraints. Denis Baldridge specify four
types constraints: (1) indicator variable take value 0 1; (2) mj
mk coreferent (xhj,ki =1), mk anaphoric (yk =1); (3) mk anaphoric (yk =1),
must coreferent preceding mention mj ; (4) mk non-anaphoric,
cannot coreferent mention.
Two points deserve mention. First, minimizing objective function, since
assignment cost expressed negative logarithm value. Second, since transitivity
503

fiRahman & Ng

guaranteed constraints23 , use closest-link clustering algorithm
put two mentions posited coreferent cluster. Note
best-link clustering strategy applicable here, since binary decision assigned
pair mentions ILP solver. use lp solve24 , publicly-available ILP solver,
solve program.
B3 CEAF results performing joint inference outputs anaphoricity
model mention-pair model using ILP shown Joint Inference column
Tables 8a 8b, respectively, rows correspond results obtained training
coreference models different feature sets. Since one goals compare joint
inference joint learning, also show Joint Learning column results
joint mention-ranking model, anaphoricity determination coreference resolution
learned joint fashion. Note reason using mention-ranking model
(rather cluster-ranking model) joint model want ensure
fair comparison joint learning joint inference much possible: chosen
cluster-ranking model joint model, difference joint learning results
joint inference results could caused increased expressiveness
cluster-ranking model. Finally, better understand whether mention-pair model
benefits joint inference using ILP, show Inference column relevant
mention-pair model results Table 4, output model postprocessed
inference mechanism.
Table 8, see joint learning results substantially better
joint inference results, except one case (Conventional/CEAF), two achieve
comparable performance. Previous work Roth (2002) Roth Yih (2004)
suggested often effective learn simple local models use complicated
integration strategies make sure constraints output satisfied learn
models satisfy constraints directly. results imply true
coreference task.
Comparing joint inference Inference results Table 8, see
mention-pair model benefit application ILP. fact, performance
deteriorates ILP used. results inconsistent reported Denis
Baldridge (2007a), show joint inference using ILP improve mentionpair model. speculate inconsistency accures fact Denis
Baldridge evaluate ILP approach true mentions (i.e., gold-standard mentions),
evaluate system mentions. Additional experiments needed determine
reason, however.
7.5 Data Source Adaptability
One may argue since train test model documents data
source (i.e., model trained documents BC tested documents
23. Finkel Manning (2008) show formulate linear constraints ILP solver outputs
coreference decisions satisfy transitivity. However, since number additional constraints needed
guarantee transitivity grows cubically number mentions previous work shows
additional constraints yield substantial performance improvements applied
system mentions (Ng, 2009), decided employ experiments.
24. Available http://lpsolve.sourceforge.net/

504

fiA Cluster-Ranking Approach Coreference Resolution

1
2
3

Feature Set
Conventional
Lexical
Combined

Joint Learning
R
P
F
47.6 74.8 58.2
54.6 72.8 62.4
50.5 77.6 61.2

Joint Inference
R
P
F
58.2 55.9 57.0
49.1 70.1 57.8
53.2 56.9 54.9


R
59.6
52.8
50.3

Inference
P
F
55.3 57.3
64.6 58.1
65.9 57.0


R
51.4
53.5
54.9

Inference
P
F
56.5 53.8
56.8 55.1
56.3 55.5

(a) B3 results

1
2
3

Feature Set
Conventional
Lexical
Combined

Joint Learning
R
P
F
50.5 56.3 53.2
56.9 63.3 59.9
54.9 61.7 58.1

Joint Inference
R
P
F
49.7 57.5 53.3
50.6 58.6 54.3
53.2 56.9 54.9

(b) CEAF results

Table 8: Joint learning vs. joint inference results. joint modeling results obtained
using mention-ranking model. joint inference results obtained applying ILP
anaphoricity classifier mention-pair model. inference results produced
mention-pair model. coreference models trained using MaxEnt.

BC, example), surprising lexicalization helps, since word pairs
training set likely found test set training test texts
data source. examine whether models employ Lexical features
suffer trained tested different data sources, perform set data
source adaptability experiments, apply coreference model trained
Lexical features documents one data source documents data sources.
Here, show results obtained using mention-ranking model, primarily
yielded best performance Lexical features among learning-based coreference
models. comparison, also show data source adaptability results obtained using
mention-ranking model trained (non-lexical) Conventional feature set.
B3 CEAF F-measure scores experiments shown Tables 9a
9b, left half right half table contain lexicalized mention-ranking
model results unlexicalized mention-ranking model results, respectively. row
corresponds data source model trained, except last two rows,
explain shortly. column corresponds test set particular data
source.
answer question whether performance coreference model employs
Lexical features deteriorate trained tested different data sources,
look diagonal entries left half Tables 9a 9b, contain
results obtained lexicalized mention-ranking model trained tested
documents source. model indeed performs worse trained
tested documents different sources, diagonal entry contain
highest score among entries column. see left half
two tables, large extent correct: four six diagonal entries contain
highest scores respective columns according scoring programs. provides
505

fiRahman & Ng

Lexical features
PP
PP Test
Train PPP
P
BC
BN
CTS
NW
UN
WL
MaxMin
Std. Dev.

Conventional features

BC

BN

CTS NW UN

WL

BC

BN

CTS NW UN

WL

56.5
57.6
55.5
55.6
56.4
56.4
2.1
0.76

61.0
63.5
61.1
62.1
62.8
62.8
2.5
1.01

58.7
60.7
62.7
56.7
60.0
58.5
6.0
2.07

66.6
67.0
65.9
59.2
67.3
68.7
9.5
3.36

52.1
51.8
51.8
51.5
52.7
51.5
1.2
0.45

55.9
59.7
58.4
55.3
57.3
56.5
4.4
1.64

55.1
58.4
59.5
55.7
59.2
55.1
4.4
2.09

63.8
62.8
64.2
60.3
64.2
64.0
3.9
1.52

64.2
63.5
61.9
65.4
62.9
63.4
3.5
1.18

57.2
55.4
54.9
56.4
56.3
55.9
2.3
0.81

59.1
58.7
59.2
58.5
59.0
59.0
0.7
0.26

52.8
52.5
53.6
52.1
53.2
52.7
1.5
0.53

(a) B3 results

Lexical features
PP
PP Test
Train PPP
P
BC
BN
CTS
NW
UN
WL
MaxMin
Std. Dev.

Conventional features

BC

BN

CTS NW UN

WL

BC

BN

CTS NW UN

WL

52.0
53.8
51.9
50.5
52.5
53.4
3.3
1.18

57.2
61.3
58.6
58.9
60.3
61.1
4.1
1.60

55.5
58.8
62.0
53.3
58.3
55.7
8.7
3.07

65.7
66.0
64.8
54.5
67.0
67.1
12.7
4.82

46.0
45.9
44.7
45.5
46.0
45.7
1.3
0.50

49.3
54.8
52.3
49.2
51.3
50.4
5.6
2.11

52.7
55.2
56.5
52.6
56.2
51.4
5.1
2.14

60.8
60.1
61.0
56.5
60.8
61.1
4.6
1.77

61.5
60.5
58.4
62.7
59.3
59.8
4.3
1.55

56.5
54.1
53.7
54.6
55.7
55.0
2.8
1.04

53.1
52.9
53.8
52.7
52.8
52.9
1.1
0.40

49.1
48.0
50.0
48.4
48.8
50.1
2.1
0.85

(b) CEAF results

Table 9: Results data source adaptability. row shows results obtained training
mention ranking model data set shown first column row, column
corresponds test set particular data source. best result obtained test set
two coreference models boldfaced.

suggestive evidence answer question affirmative. Nevertheless, look
right half two tables, show results obtained using unlexicalized
mention-ranking model, see similar, perhaps weaker, trend: according CEAF,
four six diagonal entries contain highest scores respective columns,
according B3 , two six diagonal entries exhibit trend. Hence, fact
model performs worse trained tested different data sources cannot
attributed solely lexicalization.
Perhaps informative question is: lexicalized models trained different data
sources exhibit varied performance given test set (composed documents
source) unlexicalized models trained different data sources? affirmative
answer question provide empirical support hypothesis lexicalized
model fits data trained unlexicalized counterpart. answer
question, compute column two models (1) difference
highest lowest scores (see MaxMin row), (2) standard
deviation six scores corresponding column (see Std. Dev. row).
506

fiA Cluster-Ranking Approach Coreference Resolution

compare corresponding columns two coreference models, see except
BN, lexicalized model exhibit varied performance given test set
unlexicalized model according scoring programs, regardless whether
measuring variation using MaxMin standard deviation.
7.6 Feature Analysis
subsection, analyze effects linguistic features performance
coreference models. Given large number models trained three
feature sets, feasible us analyze features model feature
set. Since cluster-ranking model, used Combined feature set, yields
best performance, analyze features. addition, since Lexical features
yielded good performance mention-ranking model, would informative see
Lexical features greatest contribution performance. result,
perform feature analysis two model/feature set combinations.
Although identified two particular model/feature set combinations, actually
total 12 model/feature set combinations: recall except row 1, row
Table 4 shows aggregated result six data sets, trained one model
data set. words, two combinations selected above,
six learned models. reduce number models need analyze yet maximize
insights gain, choose analyze models trained data sets
two fairly different domains: Newswire (NW) Broadcast News (BN).
next question is: analyze features? apply backward elimination feature selection algorithm (see survey paper Blum & Langley, 1997),
starts full feature set removes iteration feature whose removal
yields best system performance. Despite greedy nature, algorithm runs time
quadratic number features, making computationally expensive run
feature sets. reduce computational cost, divide features feature types
apply backward elimination eliminate one feature type per iteration.
features grouped follows. Lexical feature set, divide features
five types: (1) unseen features, (2) lexical features, (3) semi-lexical features, (4) distance, (5) alias. words, division corresponds roughly one described
Section 5.1, except put two conventional features two different groups,
since linguistically one positional feature semantic feature.
Combined feature set, divide features seven groups, first four
identical division Lexical features above. remaining features,
divide string-matching features, comprise features 1118 Table 1;
grammatical features, comprise features 17, 910, 1929, 3336, 3839;
semantic features, comprise features 8, 30, 31. Note alias, semantic feature Lexical feature set, combined semantic features
Conventional feature set form semantic feature type.
Results shown Tables 1013. Specifically, Tables 10a 10b show B3
CEAF F-measure scores feature analysis experiments involving mention-ranking
model, using Lexical feature set NW data set. table, first row shows
system would perform class features removed. remove least
507

fi60.6
60.1
59.2
60.7

62.4
53.1
59.7
60.9

63.3
60.1
61.8

64.6
63.5

ee
n
U
ns


lia



ist

ce

i-l
ex
ic
al
Se


Le
xi
ca
l

Rahman & Ng

65.2

58.4
44.7
53.4
54.7

56.0
55.0
53.5
55.6

60.7
55.3
58.7

61.7
59.3

ee
n
U
ns


lia



ist

ce

Le
xi
ca
l

Se


i-l
ex
ic
al

(a) B3 results

62.1

(b) CEAF results

Table 10: Feature analysis results (in terms F-measure scores) mention-ranking
model using Lexical features NW data set. feature types used train
model, B3 CEAF F-measure scores 65.4 62.7, respectively.

important feature class (i.e., feature class whose removal yields best performance),
next row shows adjusted system would perform without remaining
class. According scoring programs, removing unseen features yields least
drop performance (note caption full feature set, B3 score
65.4 CEAF score 62.7). fact, two scorers agree lexical
semi-lexical features important unseen, alias, distance features.
Nevertheless, results suggest five feature types important, since best
performance achieved using full feature set.
Tables 11a 11b show B3 CEAF F-measure scores feature analysis
experiments involving cluster-ranking model, using Combined feature set NW
data set. Recall Combined feature set, seven types features.
see, two scorers agree completely order features removed.
particular, important features lexical semi-lexical features,
whereas least important features present Lexical feature
set, namely, grammatical, string-matching, semantic features. suggests
lexical features general important non-lexical features
used combination. somewhat surprising, non-lexical features
commonly-used features coreference resolution, whereas Lexical features
comparatively much less investigated coreference researchers. Nevertheless, unlike
saw Table 10, feature types appear relevant, Table 11a, see
508

fi57.6
58.6
59.9
63.9


ica
l



ch

g


tic
Se

59.7
60.2
62.4

G
ra


58.5
58.8
58.9
57.5
63.8


ist

ce

U
ns

ee
n

i-l
ex
ica
l
59.7
60.4
61.1
62.3
61.9
67.2

St
rin

54.7
56.6
58.9
58.3
63.2
63.2

Se


Le
xi
ca
l

Cluster-Ranking Approach Coreference Resolution

59.6
61.1

60.4

55.6
56.9
58.8
60.0


ica
l



ch

g


tic
Se

57.7
58.5
60.1

G
ra


56.9
57.6
58.2
56.7
60.0


ist

ce

U
ns

ee
n

i-l
ex
ica
l
53.3
54.3
57.1
57.2
55.3
61.9

St
rin

50.2
50.6
51.4
51.0
57.9
57.9

Se


Le
xi
ca
l

(a) B3 results

58.4
60.6

58.7

(b) CEAF results

Table 11: Feature analysis results (in terms F-measure) cluster-ranking model
using Combined features NW data set. feature types used train
model, B3 CEAF F-measure scores 64.6 62.3, respectively.

best B3 F-measure score 67.2, achieved using lexical features.
represents 2.6% absolute gain F-measure model trained seven
feature types, suggesting learning-based coreference model could improved via feature
selection.
Next, investigate whether similar trends observed models trained
different source: Broadcast News. Specifically, show Tables 12a 12b B3
CEAF F-measure scores feature analysis experiments involving mentionranking model, using Lexical feature set BN data set. Table 11,
see two scorers agree completely order features
removed. fact, similar observed Table 10 (on NW data set),
scorers determine lexical semi-lexical features important,
whereas distance alias features least important, although five feature
types appear relevant according scorers.
Finally, show Tables 13a 13b B3 CEAF F-measure scores feature
analysis experiments involving cluster-ranking model, using Combined feature set
509

fi53.4
53.4
52.3
52.9

62.7
62.3
61.2
61.6

60.9
59.9
61.7

62.9
62.9


lia


ee
n
U
ns


ist

ce

i-l
ex
ica
l
Se


Le
xi
ca
l

Rahman & Ng

63.4

47.1
47.1
44.9
45.5

59.6
59.1
57.4
57.5

58.6
57.8
58.0

59.9
60.0


lia


ee
n
U
ns


ist

ce

i-l
ex
ica
l
Se


Le
xi
ca
l

(a) B3 results

61.2

(b) CEAF results

Table 12: Feature analysis results (in terms F-measure) mention-ranking model
using Lexical features BN data set. feature types used train
model, B3 CEAF F-measure scores 63.5 61.3, respectively.

BN data set. Tables 11 12, two scorers agree completely order
features removed. far feature contribution concerned, two
tables resemble Tables 11a 11b: cases, lexical, semi-lexical, unseen
features important; string-matching grammatical features
least important; semantic distance features middle. case,
however, seven feature types seem relevant, best performance achieved
using full feature set according scorers. Perhaps interestingly, numbers
column generally increasing move column. means
feature type becomes progressively less useful remove feature types.
also suggests interactions different feature types non-trivial
feature type may useful presence another feature type.
summary, results two data sets (NW BN) two scoring programs demonstrate (1) general feature types crucial overall performance, (2)
little-investigated Lexical features contribute overall performance
commonly-used Conventional features.
7.7 Resolution Performance
gain additional insights results, analyze behavior coreference
models different types anaphoric expressions trained different
feature sets. Specifically, partition mentions different resolution classes.
510

fiat
ica
l





ch
51.8
53.3
56.6

g


ist

ce


tic
51.2
54.3
60.6
61.3

G
ra


52.3
53.9
56.6
59.5
61.3

Se


U
ns

ee
n

i-l
ex
ica
l
52.7
54.2
56.9
60.4
57.4
60.6

St
rin

54.7
55.2
55.4
55.5
56.9
56.9

Se


Le
xi
ca
l

Cluster-Ranking Approach Coreference Resolution

53.9
55.6

54.8


ica
l





ch
47.1
50.0
58.5

g


ist

ce


tic
44.3
51.0
54.0
57.7

G
ra


45.2
50.7
54.9
57.0
57.1

Se


U
ns

ee
n

i-l
ex
ica
l
45.7
51.3
52.9
56.7
50.5
55.4

St
rin

44.4
44.3
45.5
46.3
48.5
48.6

Se


Le
xi
ca
l

(a) B3 results

46.4
51.8

52.1

(b) CEAF results

Table 13: Feature analysis results (in terms F-measure) cluster-ranking model
using Combined features BN data set. feature types used train
model, B3 CEAF F-measure scores 63.6 61.3, respectively.

previous work focused mainly three rather coarse-grained resolution classes (namely,
pronouns, proper nouns, common nouns), follow Stoyanov et al. (2009) subdivide
class three fine-grained classes. worth mentioning none Stoyanov et
al.s classes corresponds non-anaphoric expressions. Since believe non-anaphoric
expressions play important role analysis performance coreference
model, propose three additional classes correspond non-anaphoric pronouns,
non-anaphoric proper nouns, non-anaphoric common nouns. Finally, certain
types anaphoric pronouns (e.g., wh-pronouns) fall Stoyanov et
al.s pronoun categories. fill gap, create another category serves
default category anaphoric pronouns covered Stoyanov et al.s classes.
results 13 resolution classes, discussed detail.
Proper nouns. Four classes defined proper nouns. (1) e: proper noun assigned
exact string match class preceding mention two
coreferent string; (2) p: proper noun assigned partial string
match class preceding mention two coreferent
511

fiRahman & Ng

content words common; (3) n: proper noun assigned string match class
preceding mention two coreferent content
words common; (4) na: proper noun assigned non-anaphor class
coreferent preceding mention.
Common nouns. Four analogous resolution classes defined mentions whose head
common noun: (5) e; (6) p; (7) n; (8) na.
Pronouns. three pronoun classes. (9) 1+2: 1st 2nd person pronouns; (10)
G3: gendered 3rd person pronouns (e.g., she); (11) U3: ungendered 3rd person pronouns;
(12) oa: anaphoric pronouns belong (9), (10), (11); (13) na:
non-anaphoric pronouns.
Next, score resolution class. Unlike Stoyanov et al. (2009), use modified
version MUC scorer, employ B3 . reasons MUC scorer (1)
reward singleton clusters, (2) inflate systems performance clusters
overly large. compute score class C, process mentions test text
left-to-right manner. mention encountered, check whether belongs C.
so, use coreference model decide resolve it. Otherwise, use oracle
make correct resolution decision25 (so end mistakes attributed
incorrect resolution mentions C, thus allowing us directly measure
impact overall performance). test documents processed, compute
B3 F-measure score mentions belong C.
Performance resolution class, aggregated test sets six data
sources way before, shown Table 14, provides nice diagnosis
strengths weaknesses coreference model used combination
feature set. also show table percentage mentions belonging
class name class, abbreviate name model follows: HM
corresponds head match baseline, whereas MP, EM, MR, CR denote mentionpair model, entity-mention model, mention-ranking model, cluster-ranking
model, respectively. ranking model two versions, pipeline version (denoted
P) joint version (denoted J).
points deserve mention. Recall Table 4 Conventional features
used, joint mention-ranking model performs better mention-pair model
entity-mention model. Comparing row 5 rows 2 3 Table 14,
see improvements attributed primarily better handling one proper
25. oracle determines mention anaphoric antecedents cluster
(because model previously made mistake), employ following heuristic select
antecedent resolve mention to: try resolve closest preceding antecedent
belong class C, antecedent exists, resolve closest preceding antecedent
belongs class C. reason behind heuristics preference preceding antecedent
belong class C simple: since resolving mention using oracle, want choose
antecedent allows us maximize overall score; resolving mention antecedent
belong C likely yield better score resolving antecedent
belongs C, since former resolved using oracle latter not. heuristic
applies trying use oracle resolve mention preceding cluster: first attempt
resolve closest preceding cluster containing mention belong C,
antecedent exists, resolve closest preceding cluster containing mention belongs C.

512

fiA Cluster-Ranking Approach Coreference Resolution

Proper nouns
p
n
na
1.6
3.2
13.9

e
6.3

Common nouns
p
n
na
0.3
4.7
19.2

Class
%

e
15.2

1

HM

68.3

33.0

34.4

63.5

48.1

2
3
4
5
6
7

MP
EM
MR-P
MR-J
CR-P
CR-J

69.6
69.9
78.3
79.4
79.9
79.9

35.4
35.9
41.1
42.5
42.5
43.9

35.6
35.9
32.7
33.4
34.2
34.4

Using
65.8
65.8
76.0
76.4
75.9
76.7

8
9
10
11
12
13

MP
EM
MR-P
MR-J
CR-P
CR-J

78.8
79.1
78.3
79.5
75.3
76.4

41.9
41.8
66.4
67.1
65.7
68.4

32.1
32.4
40.7
41.3
40.4
41.1

Using Lexical feature set
78.6 66.5 54.2 24.1 77.6
78.4 66.5 54.7 24.1 77.9
75.8 53.2 60.7 28.3 83.3
76.3 54.4 61.1 28.6 83.5
76.6 50.2 61.4 30.3 81.9
77.2 50.8 63.2 31.1 83.1

14
15
16
17
18
19

MP
EM
MR-P
MR-J
CR-P
CR-J

73.8
73.9
76.4
77.2
78.3
79.9

40.1
40.6
50.9
52.3
61.3
62.0

38.8
39.2
33.3
34.7
41.5
42.4

Using
67.6 55.9
68.2 56.3
80.7 53.4
82.0 54.3
78.3 60.9
79.1 62.8

Pronouns
U3
oa
5.1
4.4

1+2
15.1

G3
4.9

50.7

46.3

41.7

23.2

55.7

Conventional feature set
56.1 54.7 24.0 70.4 53.8
57.3 55.1 24.3 70.9 54.2
48.5 58.3 27.2 78.2 54.1
48.2 59.0 27.6 78.5 54.4
64.1 58.6 27.1 80.8 57.9
65.0 59.2 27.4 82.1 58.6

55.6
56.0
57.1
57.7
61.8
62.5

46.1
46.4
44.9
45.8
49.7
50.7

24.1
24.6
22.7
23.0
25.6
26.3

51.9
51.7
61.6
62.2
58.1
59.7

55.5
55.7
62.1
62.6
60.3
61.9

57.4
57.8
60.6
62.3
61.0
62.6

44.1
44.1
47.3
47.9
50.6
51.8

24.3
24.2
29.1
31.3
36.2
37.6

61.8
62.1
61.8
62.6
66.3
67.0

58.6
58.7
58.3
59.5
62.1
62.7

60.7
61.6
56.1
59.5
65.5
66.2

49.3
49.6
44.3
45.8
51.4
52.8

27.6
26.2
25.8
26.5
34.7
35.5

58.1
58.3
66.4
67.1
62.7
64.4

55.6

24.7

68.1

Combined feature set
54.8 25.0 73.7
55.8 25.0 74.4
55.4 23.2 78.9
56.8 24.7 80.9
55.4 24.4 79.3
56.8 25.5 79.9

na
6.1

Table 14: B3 F-measure scores different resolution classes.
noun class (e) three classes correspond non-anaphoric mentions (na).
results indicate important take account non-anaphoric mentions
analyzing performance coreference model. time, see
joint mention-ranking model resolve type e common nouns well
mention-pair model entity-mention model. Also, results rows 5 7 indicate
joint cluster-ranking model better joint mention-ranking model due
better handling type e common nouns, non-anaphoric common nouns,
well anaphoric pronouns.
Next, recall Table 4 Lexical features used lieu Conventional features, mention-pair model, entity-mention model, joint mentionranking model exhibit significant improvements performance. mention-pair
model entity-mention model, improvements stem primarily better handling three proper noun classes (e,p,na), two common noun classes (e,na), nonanaphoric pronouns (compare rows 2 8 well rows 3 9 Table 14). joint
mention-ranking model, hand, improvements accrue better handling
two proper noun classes (p,n), two common classes (e,na), anaphoric pronouns,
513

fiRahman & Ng

seen rows 5 11. joint cluster-ranking model show
overall improvement switch Conventional Lexical features (compare rows 7
13), resulting models behave differently. Specifically, using Lexical features,
model gets worse handling one proper noun class (e) one common noun class (e),
better handling another proper noun class (n), two common noun classes (p,n),
one anaphoric pronoun class (1+2), non-anaphoric pronouns.
Finally, recall Combined features used lieu Lexical features,
cluster-ranking model show deterioration performance. mention-pair
model entity-mention model, deterioration performance attributed
poorer handling two proper noun classes (e,na), two common noun classes (e,na),
non-anaphoric pronouns, although better handling one proper noun
class (n) anaphoric pronouns (compare rows 8 14 well rows 9 15
Table 14). Overall, poorer handling anaphoricity appears major factor responsible
performance deterioration. joint mention-ranking model, reasons
performance deterioration slightly different: comparing rows 11 17, see poorer
handling two proper noun classes (p,n), three common noun classes (p,n,na),
anaphoric pronouns, although better handling non-anaphoric proper nouns
pronouns. mentioned before, two versions cluster-ranking model improve
trained Combined features. However, improvements stem
improvements classes (compare rows 12 18 well rows 13 19).
instance, replacing Lexical features Combined features joint
cluster-ranking model, see improvements two proper noun classes (e,na), one common
noun class (e), several pronoun classes (1+2,G3,U3), performance drops another
proper noun class (p), three common noun classes (p,n,na), two pronoun classes
(oa,na).
Overall, results provide us additional insights strengths weaknesses learning-based coreference model well directions future work. particular, even two models yield similar overall performance, quite different
resolution class level. Since single coreference model outperforms
others resolution classes, may beneficial apply ensemble approach,
anaphor belonging particular resolution class resolved model offers
best performance class.

8. Conclusions
Mitkov (2001, p. 122) puts it, coreference resolution difficult, intractable
problem, researchers making steady progress improving machine learning approaches problem past fifteen years. progress slow, however.
Despite deficiencies, mention-pair model widely thought learningbased coreference model almost decade. entity-mention model mentionranking model emerged mention-pair model dominated learning-based
coreference research nearly ten years. Although two models conceptually simple, represent significant departure mention-pair model new way
thinking alternative models coreference designed. cluster-ranking
model advances learning-based coreference research theoretically combining
514

fiA Cluster-Ranking Approach Coreference Resolution

strengths two models, thereby addressing two commonly cited weaknesses
mention-pair model. bridges gap two independent lines learningbased coreference research one concerning entity-mention model
mention-ranking model going past years, also narrows modeling gap sophistication rule-based coreference models
simplicity learning-based coreference models. Empirically, shown using
ACE 2005 coreference data set cluster-ranking model acquired jointly learning
anaphoricity determination coreference resolution surpasses performance several
competing approaches, including mention-pair model, entity-mention model,
mention-ranking model. Perhaps equally importantly, cluster-ranking model
model considered profitably exploit information provided two
fairly different sources information, Conventional features Lexical features.
ranking natural formulation coreference resolution classification,
ranking-based coreference models popularly used influential
mention-pair model. One goals article promote application ranking
techniques coreference resolution. Specifically, attempted clarify difference classification-based ranking-based coreference models showing constrained
optimization problem SVM learner needs solve type models, hoping
help reader appreciate importance ranking coreference resolution. addition, provided ample empirical evidence ranking-based models
superior classification-based models coreference resolution.
Another contribution work lies empirical demonstration benefits
lexicalizing learning-based coreference models. previous work showed lexicalization provides marginal benefits coreference model, showed lexicalization significantly improve mention-pair model, entity-mention model,
mention-ranking model, point approach even surpass performance
cluster-ranking model. Interestingly, showed models benefit lexicalization conventional coreference features used. challenges
common belief prototypical set linguistic features (e.g., gender
number agreement) must used constructing learning-based coreference systems.
addition, feature analysis experiments indicated conventional features contributed less overall performance rarely studied lexical features joint
cluster-ranking coreference model two types features used combination.
Finally, examined performance coreference model resolving mentions
belonging different resolution classes. found even two models achieve similar
overall performance, quite different resolution class level. Overall,
results provide us additional insights strengths weaknesses learningbased coreference model well promising directions future research.

Bibliographic Note
Portions work previously presented conference publication (Rahman &
Ng, 2009). current article extends work several ways, notably: (1)
overview literature ranking approaches coreference resolution (Section 2); (2)
detailed explanation difference classification ranking (Section 3); (3)
515

fiRahman & Ng

investigation issues lexicalizing coreference models (Section 5); (4) in-depth
analysis different aspects coreference system (Section 7).

Acknowledgments
authors acknowledge support National Science Foundation (NSF) grant IIS0812261. thank three anonymous reviewers insightful comments unanimously recommending article publication JAIR. opinions, findings, conclusions recommendations expressed article authors
necessarily reflect views official policies, either expressed implied, NSF.

References
Androutsopoulos, I., & Malakasiotis, P. (2010). survey paraphrasing textual
entailment methods. Journal Artificial Intelligence Research, 38 , 135187.
Aone, C., & Bennett, S. W. (1995). Evaluating automated manual acquisition
anaphora resolution strategies. Proceedings 33rd Annual Meeting
Association Computational Linguistics (ACL), pp. 122129.
Bagga, A., & Baldwin, B. (1998). Algorithms scoring coreference chains. Proceedings
Linguistic Coreference Workshop First International Conference
Language Resources Evaluation (LREC), pp. 563566.
Barbu, C., & Mitkov, R. (2001). Evaluation tool rule-based anaphora resolution methods. Proceedings 39th Annual Meeting Association Computational
Linguistics (ACL), pp. 3441.
Bengtson, E., & Roth, D. (2008). Understanding values features coreference
resolution. Proceedings 2008 Conference Empirical Methods Natural
Language Processing (EMNLP), pp. 294303.
Berger, A. L., Della Pietra, S. A., & Della Pietra, V. J. (1996). maximum entropy
approach natural language processing. Computational Linguistics, 22 (1), 3971.
Bikel, D. M., Schwartz, R., & Weischedel, R. M. (1999). algorithm learns whats
name. Machine Learning: Special Issue Natural Language Learning, 34 (13),
211231.
Blum, A., & Langley, P. (1997). Selection relevant features examples machine
learning. Artificial Intelligence, 97 (12), 245271.
Burges, C. J. C. (1998). tutorial support vector machines pattern recognition.
Data Mining Knowledge Discovery, 2 (2), 121167.
Cai, J., & Strube, M. (2010). Evaluation metrics end-to-end coreference resolution
systems. Proceedings 11th Annual SIGdial Meeting Discourse Dialogue
(SIGDIAL), pp. 2836.
Carbonell, J., & Brown, R. (1988). Anaphora resolution: multi-strategy approach.
Proceedings 12th International Conference Computational Linguistics (COLING), pp. 96101.
516

fiA Cluster-Ranking Approach Coreference Resolution

Cardie, C., & Wagstaff, K. (1999). Noun phrase coreference clustering. Proceedings
1999 Joint SIGDAT Conference Empirical Methods Natural Language
Processing Large Corpora (EMNLP/VLC), pp. 8289.
Charniak, E., & Elsner, M. (2009). EM works pronoun anaphora resolution. Proceedings 12th Conference European Chapter Association Computational Linguistics (EACL), pp. 148156.
Collins, M. J. (1999). Head-Driven Statistical Models Natural Language Parsing. Ph.D.
thesis, Department Computer Information Science, University Pennsylvania,
Philadelphia, PA.
Connolly, D., Burger, J. D., & Day, D. S. (1994). machine learning approach anaphoric
reference. Proceedings International Conference New Methods Language
Processing, pp. 255261.
Culotta, A., Wick, M., & McCallum, A. (2007). First-order probabilistic models coreference resolution. Human Language Technologies 2007: Conference North
American Chapter Association Computational Linguistics; Proceedings
Main Conference (NAACL HLT), pp. 8188.
Daume III, H., & Marcu, D. (2005). large-scale exploration effective global features
joint entity detection tracking model. Proceedings Human Language
Technology Conference Conference Empirical Methods Natural Language
Processing (HLT/EMNLP), pp. 97104.
Denis, P., & Baldridge, J. (2007a). Global, joint determination anaphoricity coreference resolution using integer programming. Human Language Technologies 2007:
Conference North American Chapter Association Computational
Linguistics; Proceedings Main Conference (NAACL HLT), pp. 236243.
Denis, P., & Baldridge, J. (2007b). ranking approach pronoun resolution. Proceedings
Twentieth International Conference Artificial Intelligence (IJCAI), pp. 1588
1593.
Denis, P., & Baldridge, J. (2008). Specialized models ranking coreference resolution.
Proceedings 2008 Conference Empirical Methods Natural Language
Processing (EMNLP), pp. 660669.
Enrique, A., Gonzalo, J., Artiles, J., & Verdejo, F. (2009). comparison extrinsic clustering evaluation metrics based formal constraints. Information Retrieval, 12 (4),
461486.
Fellbaum, C. (1998). WordNet: electronic lexical database. MIT Press, Cambridge, MA.
Finkel, J. R., Grenager, T., & Manning, C. (2005). Incorporating non-local information
information extraction systems Gibbs sampling. Proceedings 43rd Annual
Meeting Association Computational Linguistics (ACL), pp. 363370.
Finkel, J. R., & Manning, C. (2008). Enforcing transitivity coreference resolution.
Proceedings ACL-08: HLT Short Papers (Companion Volume), pp. 4548.
Florian, R., Hassan, H., Ittycheriah, A., Jing, H., Kambhatla, N., Luo, X., Nicolov, N., &
Roukos, S. (2004). statistical model multilingual entity detection tracking.
HLT-NAACL 2004: Main Proceedings, pp. 18.
517

fiRahman & Ng

Ge, N., Hale, J., & Charniak, E. (1998). statistical approach anaphora resolution.
Proceedings Sixth Workshop Large Corpora (WVLC), pp. 161170.
Grosz, B. J., Joshi, A. K., & Weinstein, S. (1983). Providing unified account definite noun phrases discourse. Proceedings 21th Annual Meeting
Association Computational Linguistics (ACL), pp. 4450.
Grosz, B. J., Joshi, A. K., & Weinstein, S. (1995). Centering: framework modeling
local coherence discourse. Computational Linguistics, 21 (2), 203226.
Haghighi, A., & Klein, D. (2010). Coreference resolution modular, entity-centered
model. Human Language Technologies: 2010 Annual Conference North
American Chapter Association Computational Linguistics (NAACL HLT),
pp. 385393.
Hobbs, J. (1978). Resolving pronoun references. Lingua, 44, 311338.
Iida, R., Inui, K., & Matsumoto, Y. (2009). Capturing salience trainable cache
model zero-anaphora resolution. Proceedings Joint Conference 47th
Annual Meeting ACL 4th International Joint Conference Natural
Language Processing AFNLP (ACL-IJCNLP), pp. 647655.
Iida, R., Inui, K., Takamura, H., & Matsumoto, Y. (2003). Incorporating contextual cues
trainable models coreference resolution. Proceedings EACL Workshop
Computational Treatment Anaphora.
Ji, H., Rudin, C., & Grishman, R. (2006). Re-Ranking algorithms name tagging.
Proceedings Workshop Computationally Hard Problems Joint Inference
Speech Language Processing, pp. 4956.
Ji, H., Westbrook, D., & Grishman, R. (2005). Using semantic relations refine coreference
decisions. Proceedings Human Language Technology Conference Conference
Empirical Methods Natural Language Processing (HLT/EMNLP), pp. 1724.
Joachims, T. (1999). Making large-scale SVM learning practical. Scholkopf, B., Burges,
C., & Smola, A. (Eds.), Advances Kernel Methods Support Vector Learning, pp.
4456. MIT Press, Cambridge, MA.
Joachims, T. (2002). Optimizing search engines using clickthrough data. Proceedings
Eighth ACM SIGKDD International Conference Knowledge Discovery
Data Mining (KDD), pp. 133142.
Kehler, A., Appelt, D., Taylor, L., & Simma, A. (2004). (non)utility predicateargument frequencies pronoun interpretation. Proceedings Human Language Technology Conference North American Chapter Association
Computational Linguistics (HLT/NAACL), pp. 289296.
Kuhn, H. W. (1955). Hungarian method assignment problem. Naval Research
Logistics Quarterly, 2, 8397.
Lappin, S., & Leass, H. (1994). algorithm pronominal anaphora resolution. Computational Linguistics, 20 (4), 535562.
Lin, D., & Wu, X. (2009). Phrase clustering discriminative learning. Proceedings
Joint Conference 47th Annual Meeting ACL 4th International
518

fiA Cluster-Ranking Approach Coreference Resolution

Joint Conference Natural Language Processing AFNLP (ACL-IJCNLP), pp.
10301038.
Luo, X. (2005). coreference resolution performance metrics. Proceedings Human
Language Technology Conference Conference Empirical Methods Natural
Language Processing (HLT/EMNLP), pp. 2532.
Luo, X., Ittycheriah, A., Jing, H., Kambhatla, N., & Roukos, S. (2004). mentionsynchronous coreference resolution algorithm based Bell tree. Proceedings
42nd Annual Meeting Association Computational Linguistics (ACL),
pp. 135142.
Madnani, N., & Dorr, B. (2010). Generating phrasal sentential paraphrases: survey
data-driven methods. Computational Linguistics, 36 (3), 341387.
McCarthy, J., & Lehnert, W. (1995). Using decision trees coreference resolution. Proceedings Fourteenth International Conference Artificial Intelligence (IJCAI),
pp. 10501055.
Mitkov, R. (1998). Robust pronoun resolution limited knowledge. Proceedings
36th Annual Meeting Association Computational Linguistics 17th
International Conference Computational Linguistics (COLING/ACL), pp. 869
875.
Mitkov, R. (2001). Outstanding issues anaphora resolution. Gelbukh, A. (Ed.),
Computational Linguistics Intelligent Text Processing, pp. 110125. Springer.
Mitkov, R. (2002). Anaphora Resolution. Longman.
Morris, J., & Hirst, G. (1991). Lexical cohesion computed thesaural relations
indicator struture text. Computational Linguistics, 17 (1), 2148.
Morton, T. (2000). Coreference NLP applications. Proceedings 38th Annual
Meeting Association Computational Linguistics (ACL).
MUC-6 (1995). Proceedings Sixth Message Understanding Conference (MUC-6).
Morgan Kaufmann, San Francisco, CA.
MUC-7 (1998). Proceedings Seventh Message Understanding Conference (MUC-7).
Morgan Kaufmann, San Francisco, CA.
Ng, V. (2009). Graph-cut-based anaphoricity determination coreference resolution.
Proceedings 2009 Conference North American Chapter Association
Computational Linguistics: Human Language Technologies (NAACL HLT), pp.
575583.
Ng, V., & Cardie, C. (2002a). Identifying anaphoric non-anaphoric noun phrases
improve coreference resolution. Proceedings 19th International Conference
Computational Linguistics (COLING), pp. 730736.
Ng, V., & Cardie, C. (2002b). Improving machine learning approaches coreference resolution. Proceedings 40th Annual Meeting Association Computational
Linguistics (ACL), pp. 104111.
519

fiRahman & Ng

Poesio, M., Uryupina, O., Vieira, R., Alexandrov-Kabadjov, M., & Goulart, R. (2004).
Discourse-new detectors definite description resolution: survey preliminary
proposal. Proeedings ACL Workshop Reference Resolution.
Ponzetto, S. P., & Strube, M. (2006). Exploiting semantic role labeling, WordNet
Wikipedia coreference resolution. Proceedings Human Language Technology Conference Conference North American Chapter Association
Computational Linguistics (HLT/NAACL), pp. 192199.
Rahman, A., & Ng, V. (2009). Supervised models coreference resolution. Proceedings 2009 Conference Empirical Methods Natural Language Processing
(EMNLP), pp. 968977.
Ravichandran, D., Hovy, E., & Och, F. J. (2003). Statistical QA - classifier vs. re-ranker:
Whats difference? Proceedings ACL 2003 Workshop Multilingual
Summarization Question Answering, pp. 6975.
Recasens, M., & Hovy, E. (2011). BLANC: Implementing Rand Index coreference
resolution. Natural Language Engineering (to appear).
Roth, D. (2002). Reasoning classifiers.. Proceedings 13th European Conference
Machine Learning (ECML), pp. 506510.
Roth, D., & Yih, W.-T. (2009). linear programming formulation global inference
natural language tasks.. Proceedings Eighth Conference Computational
Natural Language Learning (CoNLL), pp. 18.
Soon, W. M., Ng, H. T., & Lim, D. C. Y. (2001). machine learning approach coreference
resolution noun phrases. Computational Linguistics, 27 (4), 521544.
Stoyanov, V., Gilbert, N., Cardie, C., & Riloff, E. (2009). Conundrums noun phrase
coreference resolution: Making sense state-of-the-art. Proceedings
Joint Conference 47th Annual Meeting ACL 4th International
Joint Conference Natural Language Processing AFNLP (ACL-IJCNLP), pp.
656664.
Strube, M., & Muller, C. (2003). machine learning approach pronoun resolution
spoken dialogue. Proceedings 41st Annual Meeting Association
Computational Linguistics (ACL), pp. 168175.
Strube, M., Rapp, S., & Muller, C. (2002). influence minimum edit distance
reference resolution. Proceedings 2002 Conference Empirical Methods
Natural Language Processing (EMNLP), pp. 312319.
Toutanova, K., Klein, D., Manning, C. D., & Singer, Y. (2003). Feature-rich part-of-speech
tagging cyclic dependency network. HLT-NAACL 2003: Proceedings
Main Conference, pp. 173180.
Uryupina, O. (2003). High-precision identification discourse new unique noun
phrases. Proceedings 41st Annual Meeting Association Computational Linguistics: Companion Volume, pp. 8086.
Vapnik, V. N. (1995). Nature Statistical Learning. Springer, New York.
520

fiA Cluster-Ranking Approach Coreference Resolution

Vilain, M., Burger, J., Aberdeen, J., Connolly, D., & Hirschman, L. (1995). modeltheoretic coreference scoring scheme. Proceedings Sixth Message Understanding Conference (MUC-6), pp. 4552.
Walker, M., Joshi, A., & Prince, E. (Eds.). (1998). Centering Theory Discourse. Oxford
University Press.
Yang, X., Su, J., Lang, J., Tan, C. L., & Li, S. (2008). entity-mention model
coreference resolution inductive logic programming. Proceedings 46th
Annual Meeting Association Computational Linguistics: Human Language
Technologies (ACL-08: HLT), pp. 843851.
Yang, X., Su, J., Zhou, G., & Tan, C. L. (2004). NP-cluster based approach coreference
resolution. Proceedings 20th International Conference Computational
Linguistics (COLING), pages 226232.
Yang, X., Zhou, G., Su, J., & Tan, C. L. (2003). Coreference resolution using competitive
learning approach. Proceedings 41st Annual Meeting Association
Computational Linguistics (ACL), pp. 176183.

521

fiJournal Artificial Intelligence Research 40 (2011) 1-24

Submitted 09/10; published 01/11

Non-Deterministic Policies
Markovian Decision Processes
Mahdi Milani Fard
Joelle Pineau

mmilan1@cs.mcgill.ca
jpineau@cs.mcgill.ca

Reasoning Learning Laboratory
School Computer Science, McGill University
Montreal, QC, Canada

Abstract
Markovian processes long used model stochastic environments. Reinforcement learning emerged framework solve sequential planning decision-making
problems environments. recent years, attempts made apply methods
reinforcement learning construct decision support systems action selection
Markovian environments. Although conventional methods reinforcement learning
proved useful problems concerning sequential decision-making, cannot applied current form decision support systems, medical domains,
suggest policies often highly prescriptive leave little room users
input. Without ability provide flexible guidelines, unlikely methods
gain ground users systems.
paper introduces new concept non-deterministic policies allow flexibility users decision-making process, constraining decisions remain near
optimal solutions. provide two algorithms compute non-deterministic policies
discrete domains. study output running time method set
synthetic real-world problems. experiment human subjects, show
humans assisted hints based non-deterministic policies outperform human-only
computer-only agents web navigation task.

1. Introduction
Planning decision-making well studied AI community. Intelligent
agents designed developed act in, interact with, variety environments. usually involves sensing environment, making decision using
intelligent inference mechanism, performing action environment (Russell & Norvig, 2003). Often times, process involves level learning, along
decision-making process, make agent efficient performing intended
goal.
Reinforcement Learning (RL) branch AI tries develop computational
approach solving problem learning interaction. RL process
learning dohow map situations actionsso maximize numerical
reward signal (Sutton & Barto, 1998). Many methods developed solve
RL problem different types environments different types agents. However,
work RL focused autonomous agents robots software
agents. RL controllers thus designed issue single action time-step
c
2011
AI Access Foundation. rights reserved.

fiMilani Fard & Pineau

executed acting agent. past years, methods developed
RL community started used sequential decision support systems (Murphy,
2005; Pineau, Bellemare, Rush, Ghizaru, & Murphy, 2007; Thapa, Jung, & Wang, 2005;
Hauskrecht & Fraser, 2000). many systems, human makes final
decision. Usability acceptance issues thus become important cases.
RL methods therefore require level adaptation used decision support
systems. adaptations main contribution paper.
Medical domains among cases RL needs adaptation. Although
RL framework correctly models sequential decision-making complex medical scenarios, including long-term treatment design, standard RL methods cannot applied
medical settings current form lack flexibility suggestions.
requirements are, course, specific medical domains and, instance, might
needed aircraft controller provides suggestions pilot.
important difference decision support system classical RL problem
stems fact decision support system, acting agent often human
being, course his/her decision process. Therefore, assumption
controller send one clear commanding signal acting agent
appropriate. accurate assume aspect decision-making process
influenced user system.
view decision process particularly relevant two different situations.
First, many practical cases, exact model system. Instead,
may noisy model built finite number interactions environment.
leads type uncertainty usually referred extrinsic uncertainty.
RL algorithms ignore uncertainty assume model perfect. However
look closely, performance optimal action based imperfect model might
statistically different next best action. Bayesian approaches looked
problem providing confidence measure agents performance (Mannor, Simester,
Sun, & Tsitsiklis, 2007). cases acting agent human being, use
confidence measures provide user complete set actions, might
optimal enough evidence differentiate. user
use his/her expertise make final decision. methods guarantee
suggestions provided system statistically meaningful plausible.
hand, even complete knowledge system
identify optimal action, might still actions roughly equal
performance. point, decision near-optimal options could left
acting agentnamely human using decision support system.
could many advantages, ranging better user experience, increased robustness
flexibly. Among near-optimal solutions, user select based domain
knowledge, preferences, captured system. instance,
medical diagnosis system suggests treatments, providing physician several
options might useful final decision could made based knowledge
patients medical status, preferences regarding side effects.
Throughout paper address latter issue combination theoretical
empirical investigations. introduce new concept non-deterministic policies
capture decision-making process intended decision support systems. policies
2

fiNon-Deterministic Policies Markovian Decision Processes

involve suggesting set actions, non-deterministic choice made
user. apply formulation solve problem finding near-optimal policies
provide flexible suggestions user.
particular, investigate suggest several actions acting agent,
providing performance guarantees worst-case analysis. Section 2 introduces
necessary technical background material. Section 3 defines concept non-deterministic
policies related concepts. Section 4 addresses problem providing choice
acting agent keeping near-optimality guarantees performance worst-case
scenario. propose two algorithms solve problems provide approximation
techniques speed computation larger domains.
Methods introduced paper general enough apply decision support system observable Markovian environment. empirical investigations focus
primarily sequential decision-making problems clinical domains, system
provide suggestions best treatment options patients. decisions
provided sequence treatment phases. systems specifically interesting
often times, different treatment options seem provide slightly different results. Therefore, providing physician several suggestions would beneficial
improving usability system performance final decision.

2. Definitions Notations
section introduces main notions behind sequential decision-making mathematical formulations used RL.
2.1 Markov Decision Processes
Markov Decision Process (MDP) model system dynamics sequential decision
problems involves probabilistic uncertainty future states system (Bellman,
1957). MDPs used model interactions agent observable
Markovian environment. system assumed state given time.
agent observes state performs action accordingly. system makes
transition next state agent receives reward.
Formally, MDP defined 5-tuple (S, A, T, R, ):
States: set states. state usually captures complete configuration
system. state system known, future system
independent previous system transitions. means state
system sufficient statistic history system.
Actions: : 2A set actions allowed state set
actions. A(s) set actions agent choose from, interacting
system state s.
Transition Probabilities: : [0, 1] defines transition probabilities
system. function specifies likely end state, given
current state specific action performed agent. Transition probabilities
3

fiMilani Fard & Pineau

specified based Markovian assumption. is, state system
time denoted st action time , have:
Pr(st+1 |at , st , at1 , at1 , . . . , a0 , s0 ) = P r(st+1 |at , st ).

(1)

focus homogeneous processes system dynamics independent
time. Thus transition function stationary respect time:
def

(s, a, s0 ) = P r(st+1 = s0 |at = a, st = s).

(2)

Rewards: R : R [0, 1] probabilistic reward model. Depending
current state system action taken, agent receive reward
drawn model. focus homogeneous processes which, again,
reward distribution change time. reward time denoted
rt , have:
rt R(st , ).

(3)

Depending domain, reward could deterministic stochastic. use
general stochastic model throughout paper. mean distribution
denoted R(s, a).
Discount Factor: [0, 1) discount rate used calculate long-term
return.
agent starts initial state s0 S. time step t, action A(st )
taken agent. system makes transition st+1 (st , ) agent
receives immediate reward rt R(st , ).
goal agent maximize discounted sum rewards planning
horizon h (could infinite). usually referred return (denoted D):
D=

h
X

rt .

(4)

t=0

finite horizon case, sum taken horizon limit discount factor
set 1. However, infinite horizon case discount factor less
1 return finite value. return process depends
stochastic transitions rewards, well actions taken agent.
Often times transition structure MDP contains loop non-zero probability. transition graph modeled directed acyclic graph (DAG).
class MDPs interesting includes multi-step decision-making finite horizons,
found medical domains.
2.2 Policy Value Function
policy way defining agents action selection respect changes
environment. (probabilistic) policy MDP mapping state space
distribution action space:
: [0, 1].
4

(5)

fiNon-Deterministic Policies Markovian Decision Processes

deterministic policy policy defines single action per state. is, (s)
A(s). later introduce notion non-deterministic policies MDPs deal
sets actions.
agent interacts environment takes actions according policy.
value function policy defined expectation return given
agent acts according policy:
"
#
X
def
V (s) = E[D (s)] = E
rt |s0 = s, = (st ) .
(6)
t=0

Using linearity expectation, write expression recursive
form, known Bellman equation (Bellman, 1957):
"
#
X
X

0
0
V (s) =
(s, a) R(s, a) +
(s, a, )V (s ) .
(7)
s0

aA

value function used primary measure performance much
RL literature. are, however, ideas take risk variance
return account measure optimality (Heger, 1994; Sato & Kobayashi, 2000).
common criteria, though, assume agent trying find policy
maximizes value function. policy referred optimal policy.
also define value function state-action pairs. usually referred
Q-function, Q-value, pair. definition:
"
#
X
def
(8)
Q (s, a) = E[D (s, a)] = E
rt |s0 = s, a0 = a, 1 : = (st ) .
t=0

is, Q-value expectation return, given agent starts state
s, takes action a, follows policy . Q-function also satisfies Bellman
equation:
X
X
Q (s, a) = R(s, a) +
(s, a, s0 )
(s0 , a0 )Q (s0 , a0 ),
(9)
s0

a0

rewritten as:
Q (s, a) = R(s, a) +

X

(s, a, s0 )V (s0 ).

(10)

s0

Q-function often used compare optimality different actions given fixed
subsequent policy.
2.3 Planning Algorithms Optimality
optimal policy, denoted , defined policy maximizes value
function initial state:
= argmax V (s0 ).


5

(11)

fiMilani Fard & Pineau

shown (Bellman, 1957) MDP, exists optimal deterministic policy worse policy MDP. value optimal
policy V satisfies Bellman optimality equation:
"
#
X
V (s) = max R(s, a) +
(s, a, s0 )V (s0 ) .
(12)
aA

s0

deterministic optimal policy follows this:
"
#
X

0
0
(s) = argmax R(s, a) +
(s, a, )V (s ) .
aA

(13)

s0

Alternatively write equations Q-function:
X
Q (s, a) = R(s, a) +
(s, a, s0 )V (s0 ).

(14)

s0

Thus V (s) = maxa Q (s, a) (s) = argmaxa Q (s, a).
Much literature RL focused finding optimal policy. many
methods developed policy optimization. One way find optimal policy solve
Bellman optimality equation use Eqn 13 choose actions. Bellman
optimality equation formulated simple linear program (Bertsekas, 1995):
minV V, subject
P
V (s) R(s, a) + s0 (s, a, s0 )V (s0 ) s, a,

(15)

represents initial distribution states. solution problem optimal value function. Notice V represented matrix form
equation. known linear programs solved polynomial time (Karmarkar,
1984). However, solving might become impractical large (or infinite) state spaces.
Therefore often times methods based dynamic programming preferred linear
programming solution.

3. Non-Deterministic Policies: Definition Motivation
begin section considering problem decision-making sequential decision
support systems. Recently, MDPs emerged useful frameworks optimizing action
choices context medical decision support systems (Schaefer, Bailey, Shechter, &
Roberts, 2004; Hauskrecht & Fraser, 2000; Magni, Quaglini, Marchetti, & Barosi, 2000;
Ernst, Stan, Concalves, & Wehenkel, 2006). Given adequate MDP model (or data
source), many methods used find good action-selection policy. policy
usually deterministic stochastic function. policies types face substantial
barrier terms gaining acceptance medical community, highly
prescriptive leave little room doctors input. problems are, course,
specific medical domain present application actions
executed human. cases, may preferable provide several equivalently
6

fiNon-Deterministic Policies Markovian Decision Processes

good action choices, agent pick among according
heuristics preferences.
address problem, work introduces notion non-deterministic policy,
function mapping state set actions, acting agent
choose.
Definition 1. non-deterministic policy MDP (S, A, T, R, ) function
maps state non-empty set actions denoted (s) A(s).
agent choose action (s) whenever MDP state s.
Definition 2. size non-deterministic
policy , denoted ||, sum
P
cardinality action sets : || = |(s)|.
following sections discuss two scenarios non-deterministic policies
useful. show used implement robust decision support
systems statistical guarantees performance.
3.1 Providing Choice Acting Agent
Even cases complete knowledge dynamics planning problem
hand, accurately calculate actions utilities, might desirable
provide user optimal choice action time step. domains,
difference utility top actions may substantial. medical
decision-making, instance, difference may medically significant based
given state variables.
cases, seems natural let user decide top actions,
using his/her expertise domain. results injection domain
knowledge decision-making process, thus making robust practical.
decisions based facts known user incorporated automated
planning system. also based preferences might change case case.
instance, doctor get several recommendations treat patient
maximize chance remission, decide medication apply considering
also patients medical record, preferences regarding side effects, medical expenses.
idea providing choice user accompanied reasonable guarantees performance final decision, regardless choice made user.
notion near-optimality enforced make sure actions never far
best possible option. guarantees enforced providing worst-case analysis
decision process.
3.2 Handling Model Uncertainty
many practical cases complete knowledge system hand. Instead,
may get set trajectories collected system according specific policy.
cases, may given chance choose policy (in on-line active RL),
cases may access data fixed policy. medical
trials, particular, data usually collected according randomized policy, fixed ahead
time consultation clinical researchers.
7

fiMilani Fard & Pineau

Given set sample trajectories, either build model domain (in modelbased approaches) directly estimate utility different actions (with model-free approaches). However models estimates always accurate
observe finite amount data. many cases, data may sparse incomplete
uniquely identify best option. is, difference performance measure
different actions statistically significant.
cases might useful let user decide final choice
actions enough evidence differentiate.
comes assumption user identify best choice among
recommended. task therefore provide user small set actions
almost surely include optimal one.
paper focus problem providing flexible policies nearoptimal performance. Using non-deterministic policies handling model uncertainty remains interesting future work.

4. Near-Optimal Non-Deterministic Policies
Often times, beneficial provide user decision support system set
near-optimal solutions. MDPs, would suggest set near-optimal actions
user let user make decision among proposed actions. notion
near-optimality therefore set possible policies consistent
proposed actions. is, matter action chosen among proposed
options state, final performance close optimal policy.
constraint suggests worst-case analysis decision-making process. Therefore,
opt guarantee performance action selection consistent non-deterministic
policy putting near-optimality constraint worst-case selection actions
user.
Definition 3. (worst-case) value state-action pair (s, a) according nondeterministic policy MDP = (S, A, T, R, ) given recursive definition:

X

0

0 0
QM (s, a) = R(s, a) +
(s, a, ) min QM (s , ) ,
(16)
a0 (s0 )

s0

worst-case expected return allowed set actions.
Definition 4. define (worst-case) value state according non (s), be:
deterministic policy , denoted VM
min Q
(s, a).

(17)

a(s)

calculate value non-deterministic policy, construct evaluation MDP,
0 = (S, A0 , R0 , T, ), A0 = R0 = R.
Theorem 1. negated value non-deterministic policy equal
optimal policy evaluation MDP:

Q
(s, a) = QM 0 (s, a).

8

(18)

fiNon-Deterministic Policies Markovian Decision Processes

Proof. show QM 0 satisfies Bellman optimality equation 0 ,
negated values satisfy Eqn 16 :
X
QM 0 (s, a) = R0 (s, a) +
(s, a, s0 ) max
QM 0 (s0 , a0 )
(19)
0
0


s0

QM 0 (s, a) = R0 (s, a)

X

(s, a, s0 ) max
QM 0 (s0 , a0 )
0
0

(20)

(s, a, s0 ) min QM 0 (s0 , a0 ),

(21)



s0

QM 0 (s, a) = R(s, a) +

X
s0

a0 (s0 )


equivalent Eqn 16 Q
(s, a) = QM 0 (s, a).

means policy evaluation non-deterministic policy achieved
method finds optimal policy MDP.
Definition 5. non-deterministic policy said augmented state-action pair
(s, a), denoted 0 = + (s, a), satisfies:
(
(s0 ),
s0 6=
0 (s0 ) =
(22)
(s0 ) {a}, s0 = s.
policy achieved number augmentations policy 0 , say
includes 0 .
Definition 6. non-deterministic policy said non-augmentable according
constraint satisfies , state-action pair (s, a), + (s, a)
satisfy .
paper working constraints particular property:
policy satisfy , policy includes satisfy .
refer constraints monotonic. One constraint -optimality,
discussed next section.
4.1 -Optimal Non-Deterministic Policies
Definition 7. non-deterministic policy MDP said -optimal,
[0, 1], have1 :


VM
(s) (1 )VM
(s), S.

(23)

thought constraint space non-deterministic policies, set
ensure worst-case expected return within range optimal value.
Theorem 2. -optimality constraint monotonic.

1. MDP literature, -optimality defined additive constraint (Q
QM ) (Kearns
& Singh, 2002). derivations analogous case. chose multiplicative constraint
cleaner derivations.

9

fiMilani Fard & Pineau

Proof. Suppose -optimal. augmentation 0 = + (s, a), have:

X
0
0
0 0 0
Q
(s,
a)
=
R(s,
a)
+


(s,
a,

)
min
Q
(s
,

)


s0

a0 0 (s0 )


X
0
0 0 0
(s, a, ) min QM (s , )
R(s, a) +
s0

a0 (s0 )

Q
(s, a),
implies:
0



VM
(s) VM
(s).

-optimal, means 0 -optimal either value function
decrease policy augmentation.
intuitively, follows fact adding options cannot increase
minimum utility former worst case choice still available augmentation.
Definition 8. conservative -optimal non-deterministic policy MDP
policy non-augmentable according following constraint:
X



R(s, a) +
(s, a, s0 )(1 )VM
(s0 ) (1 )VM
(s), (s).
(24)
s0

constraint indicates add actions policy whose reward plus
(1 ) future optimal return within sub-optimal margin. ensures
non-deterministic policy -optimal using inequality:
X


Q
(s, a, s0 )(1 )VM
(s0 ) ,
(25)
(s, a) R(s, a) +
s0

instead solving Eqn 16 using inequality constraint Eqn 23. Applying Eqn 24
guarantees non-deterministic policy -optimal may still augmentable
according Eqn 23, hence name conservative.
also shown conservative policy unique.
two different conservative policies, union would conservative,
violates assumption non-augmentable according Eqn 24.
Definition 9. non-augmentable -optimal non-deterministic policy MDP
policy non-augmentable according constraint Eqn 23.
non-deterministic policy adding actions violates nearoptimality constraint worst-case performance. search -optimal policies,
non-augmentable one locally maximal size. means although policy
might largest among -optimal policies, cannot add actions
without removing actions, hence locally maximal reference.
non-augmentable -optimal policy includes conservative policy.
always add conservative policy policy remain within bound.
10

fiNon-Deterministic Policies Markovian Decision Processes

However, non-augmentable -optimal policies necessarily unique,
locally maximal size.
remainder section, focus problem searching space
non-augmentable -optimal policies, maximize criteria. Specifically,
aim find non-deterministic policies give acting agent options staying
within acceptable sub-optimal margin.
present example clarifies concepts introduced far. simplify
presentation example, assume deterministic transitions. However, concepts
apply well probabilistic MDP. Figure 1 shows example MDP. labels
arcs show action names corresponding rewards shown parentheses.
assume ' 1 = 0.05. Figure 2 shows optimal policy MDP.
conservative -optimal non-deterministic policy MDP shown Figure 3.

Figure 1: Example MDP

Figure 2: Optimal policy

Figure 3: Conservative -optimal policy

Figure 4: Two non-augmentable -optimal policies

Figure 4 includes two possible non-augmentable -optimal policies. Although policies Figure 4 -optimal, union -optimal. due fact
adding option one states removes possibility adding options
11

fiMilani Fard & Pineau

states, illustrates local changes policy always appropriate
searching space -optimal policies.
4.2 Optimization Criteria
formalize problem finding -optimal non-deterministic policy terms
optimization problem. several optimization criteria formulated,
still complying -optimality constraint.
Maximizing size policy: According criterion, seek nonaugmentable -optimal policies biggest overall size (Def 2). provides
options agent still keeping -optimal guarantees. algorithms
proposed later sections use optimization criterion. Notice solution
optimization problem non-augmentable according -optimal constraint,
maximizes overall size policy.
variant this, try maximize sum log size action
sets:
X
log |(s)|.
(26)
sS

enforces even distribution choice action set. However,
using basic case maximizing overall size easier optimization
problem.
Maximizing margin: aim maximize margin non-deterministic
policy :
max (),

(27)



where:

() = min
sS

min



Q(s, a) Q(s, ) .
0

a(s),a0 (s)
/

(28)

optimization criterion useful one wants find clear separation
good bad actions state.
Minimizing uncertainty: learn models data
uncertainty optimal action state. use variance estimation value function (Mannor, Simester, Sun, & Tsitsiklis, 2004) along
Z-Test get confidence level comparisons find probability
wrong order comparing actions according values. Let Q
value true model Q empirical estimate based dataset
D. aim minimize uncertainty non-deterministic policy :
min (),


(29)

where:

() = max
sS

max

a(s),a0 (s)
/

12




P r Q(s, a) < Q(s, a0 )|D
.

(30)

fiNon-Deterministic Policies Markovian Decision Processes

Notice last two criteria defined space -optimal policies,
non-augmentable ones.
following sections provide algorithms solve first optimization problem
mentioned above, aims maximize size policy. focus criterion
seems appropriate medical decision support systems, desirable
acceptability system find policies provide much choice possible
acting agent. Developing algorithms address two optimization criteria
remains interesting open problem.
4.3 Maximal -Optimal Policy
exact computational complexity finding maximal -optimal policy yet known.
problem certainly NP, one find value non-deterministic policy
polynomial time solving evaluation MDP linear program. suspect
problem NP-complete, yet find reduction known NP-complete
problem.
order find largest -optimal policy, present two algorithms. first present
Mixed Integer Program (MIP) formulation problem, present search algorithm uses monotonic property -optimal constraint. MIP method
useful general theoretical formulation problem, search algorithm
potential extensions heuristics.
4.3.1 Mixed Integer Programming Solution
Recall formulate problem finding optimal deterministic policy
MDP simple linear program (Bertsekas, 1995):
minV V, subject
P
V (s) R(s, a) + s0 (s, a, s0 )V (s0 ) s, a,

(31)

thought initial distribution states. solution
problem optimal value function (V ). Similarly, computed V using
Eqn 31, problem searching optimal non-deterministic policy according
size criterion rewritten Mixed Integer Program:2
maxV, (T V + (Vmax Vmin )eTs ea ), subject
V (s) (1 )V (s)

P
(s, a) > 0

P
0
0
V (s) R(s, a) + s0 (s, a, )V (s ) + Vmax (1 (s, a)) s, a.

(32)

overloading notation define binary matrix representing policy,
(s, a) 1 (s), 0 otherwise. define Vmax = Rmax /(1 )
Vmin = Rmin /(1 ). es column vectors 1 appropriate dimensions.
first set constraints makes sure stay within optimal return.
2. Note MIP, unlike standard LP MDPs, choice affect solution cases
tie size .

13

fiMilani Fard & Pineau

second set constraints ensures least one action selected per state. third
set ensures state-action pairs chosen policy, Bellman
constraint holds, otherwise, constant Vmax makes constraint trivial. Notice
solution problem maximizes || result non-augmentable.
Theorem 3. solution mixed integer program Eqn 32 non-augmentable
according -optimality constraint.
Proof. First, notice solution -optimal, due first set constraints
(worst-case) value function. show non-augmentable, counter argument,
suppose could add state-action pair solution , still staying suboptimal margin. adding pair, objective function increased (Vmax Vmin ),
bigger possible decrease V term, thus objective
improved, conflicts solution.
use MIP solver solve problem. Note however
make use monotonic nature constraints. general purpose MIP solver could
end searching space possible non-deterministic policies, would
require running time exponential number state-action pairs (O(2|S||A|+ )).
4.3.2 Heuristic Search
Alternatively, develop heuristic search algorithm find maximal -optimal policy.
make use monotonic property -optimal policies narrow
search. start computing conservative policy. augment arrive
non-augmentable policy. also make use fact policy -optimal,
neither policy includes it, thus cut search tree
point.
Table 1: Heuristic search algorithm find -optimal policies maximum size
Function getOptimal(, startIndex, )

startIndex |S||A|
(s, a) pi

/ (s) & V ( + (s, a)) (1 )V
0 getOptimal ( + (s, a), + 1, )
g(0 ) > g(o )
0
end
end
end
return
algorithm presented Table 1 one-sided recursive depth-first-search algorithm
searches space plausible non-deterministic policies maximize function
g(). assume ordering set state-action pairs {pi } =
14

fiNon-Deterministic Policies Markovian Decision Processes

{(sj , ak )}. ordering chosen according heuristic along mechanism
cut parts search space. V optimal value function function
V returns value non-deterministic policy calculated solving
corresponding evaluation MDP.
make call function passing conservative policy
starting first state-action pair: getOptimal(m , 0, ).
asymptotic running time algorithm O((|S||A|)d (tm + tg )),
maximum size -optimal policy minus size conservative policy, tm
time solve original MDP (polynomial relevant parameters), tg time
calculate function g. Although worst-case running time still exponential
number state-action pairs, run-time much less search space sufficiently
small. |A| term due fact check possible augmentations
state. Note algorithm searches space -optimal policies rather
non-augmentable ones. set function g() = ||, algorithm
return biggest non-augmentable -optimal policy.
search improved using heuristics order state-action pairs
prune search. One also start search policy rather
conservative policy. potentially useful constraints
problem.
4.3.3 Directed Acyclic Transition Graphs
One way narrow search add action maximum value
state s, ignore rest actions adding top action result values
-optimality bound:
!
0 = +

s, argmax Q (s, a) .
a(s)
/

modified algorithm follows:
Table 2: Modified heuristic search algorithm augmentation rule Eqn 33.
Function getOptimal(, )

(s) 6= A(s)
argmaxa(s)
Q (s, a)
/
V ( + (s, a)) (1 )V
0 getOptimal ( + (s, a), )
g(0 ) > g(o )
0
end
end
end
return

15

(33)

fiMilani Fard & Pineau

algorithm Table 2 leads running time O(|S|d (tm + tg )). However
guarantee see non-augmentable policies. due fact
adding action, order values might change. transition structure MDP
contains loop non-zero probability (transition graph directed acyclic, i.e. DAG),
heuristic produce optimal result cutting search time.
Theorem 4. MDPs DAG transition structure, algorithm Table 2 generate non-augmentable -optimal policies would generated full search.
Proof. prove this, first notice sort DAG topological sort. Therefore, arrange states levels, state make transitions states
future level. easy see adding actions state non-deterministic
policy change worst-case value past levels. effect
Q-values current level future level.
given non-augmentable -optimal policy generated full search,
sequence augmentations generated policy. permutation sequence
would create policy intermediate polices -optimal. rearrange sequence add actions reverse order level.
point mentioned above, Q-value actions point added
change target policy realized. Therefore actions Q-values
minimum value must policy, otherwise add them, conflicts
target policy non-augmentable. Since actions certain Q-value
must added, add order. Therefore target policy realized
rule Eqn 33.
transition structure DAG, one might partial evaluation
augmented policy approximate value adding actions, possibly
backups rather using original Q-values. offers possibility trading-off
computation time better solutions.

5. Empirical Results
evaluate framework proposed algorithms, first test MIP search
formulations MDPs created randomly, test search algorithm real-world
treatment design scenario. Finally, conduct experiment computer-aided web
navigation task human subjects assess usefulness non-deterministic policies
assisting human decision-making.
5.1 Random MDPs
first experiment, aim study non-deterministic policies change
value two algorithms compare terms running time. begin,
generated random MDPs 5 states 4 actions. transitions deterministic
(chosen uniformly random) rewards random values 0 1, except
one states reward 10 one actions; set 0.95. MIP
method implemented MATLAB CPLEX.
16

fiNon-Deterministic Policies Markovian Decision Processes

=0

= 0.01

= 0.02

= 0.03

Figure 5: MIP solution different values {0, 0.01, 0.02, 0.03}. labels
edges action indices, followed corresponding immediate rewards.
Figure 5 shows solution MIP defined Eqn 32 particular randomly
generated MDP. see size non-deterministic policy increases performance threshold relaxed. see even small values several
actions included policy state. course result Q-values
close other. property typical many medical scenarios different
treatments provide slightly different results.
compare running time MIP solver search algorithm, constructed
random MDPs described state-action pairs. Figure 6 shows running
time averaged 20 different random MDPs 5 states, assuming = 0.01 (which
allows several solutions). expected, algorithms running time exponential
number state-action pairs (note exponential scale time axis).
running time search algorithm bigger constant factor (possibly due naive
implementation), smaller exponent base, results faster asymptotic
running time. Even exponential running time, one still use search algorithm
solve problems hundred state-action pairs. sufficient
many practical domains, including real-world medical decision scenarios shown
next section.
observe effect choice running time algorithms, fix
size random MDPs 7 states 5 actions state, change
17

fiMilani Fard & Pineau

Figure 6: Running time MIP search algorithm function number
state-action pairs = 0.01.
value measure running time algorithms 100 trials. Figure 7 shows
average running time algorithms different values . expected,
search algorithm go deeper search tree optimality threshold relaxed
running time thus increase. running time MIP method,
hand, remains relativity constant exhaustively searches space possible
non-deterministic policies. results representative relative behaviour
two approaches range problems.

Figure 7: Running time MIP search algorithm function , 7 states
5 actions. Many actions included policy = 0.02.

5.2 Medical Decision-making
demonstrate non-deterministic policies used presented medical
domain, tested full search algorithm MDP constructed medical decisionmaking task involving real patient data. data collected part large (4000+
patients) multi-step randomized clinical trial, designed investigate comparative effectiveness different treatments provided sequentially patients suffering depression
(Fava et al., 2003). goal find treatment plan maximizes chance
18

fiNon-Deterministic Policies Markovian Decision Processes

remission. dataset includes large number measured outcomes. current
experiment, focus numerical score called Quick Inventory Depressive Symptomatology (QIDS), used study assess levels depression (including
patients achieved remission). purposes experiment, discretize
QIDS scores (which range 5 27) uniformly quartiles, assume this,
along treatment step (up 4 steps allowed), completely describe patients state. Note underlying transition graph treated DAG,
study limited four steps treatment action choices change steps.
19 actions (treatments) total. reward 1 given patient achieves
remission (at step) reward 0 given otherwise. transition reward
models estimated empirically medical database using frequentist approach.
Table 3: Policy running time full search algorithm medical problem.
= 0.02

= 0.015

= 0.01

=0

118.7

12.3

3.5

1.4

CT
SER
BUP
CIT+BUS

CT
SER

CT

CT

9 QIDS < 12

CIT+BUP
CIT+CT

CIT+BUP
CIT+CT

CIT+BUP

CIT+BUP

VEN
CIT+BUS
CT

VEN
CIT+BUS

VEN

VEN

12 QIDS < 16

16 QIDS 27

CT
CIT+CT

CT
CIT+CT

CT
CIT+CT

CT

Time (seconds)
5 < QIDS < 9

Table 3 shows non-deterministic policy obtained state second
step trial (each acronym refers specific treatment). computed using
search algorithm, assuming different values . Although problem tractable
MIP formulation (304 state-action pairs), full search space -optimal policies
still possible. Table 3 also shows running time algorithm, expected,
increases relax threshold . Here, use heuristics. However,
underlying transition graph DAG, could use heuristic discussed previous
section (Eqn 33) get policies even faster.
interesting question set priori. practice, doctor may use
full table guideline, using smaller values he/she wants rely
decision support system, larger values relying his/her assessments.
believe particular presentation non-deterministic policies could used
accepted clinicians, excessively prescriptive keeps physician
patient decision cycle. contrast traditional notion policies
reinforcement learning, often leaves place physicians intervention.
19

fiMilani Fard & Pineau

5.3 Human Subject Interaction
Finally, conduct experiment assess usefulness non-deterministic policies
human subjects. Ideally, would like conduct experiments medical settings
physicians, studies costly difficult conduct given require
participation many medical professionals. therefore study non-deterministic policies
easier domain constructing web-based game played computer
human (either jointly separately).
game defined follows. user given target word asked navigate
around pages Wikipedia visit pages contain target word. user
click word page. system uses Google search Wiki website
clicked word keyword current page (the choice keyword
discussed later). randomly chooses one top eight search results moves
page. process mimics hyperlink structure web (extending
hyperlink structure Wiki make target words easily reachable).
user given ten attempts asked reach many pages target word
possible. similar game used another work infer semantic distances
concepts (West, Pineau, & Precup, 2009). game, however, designed way
computer model provide results similar human player thus enable us
assess effectiveness computer-aided decisions non-deterministic policies.
construct task CD version Wikipedia (Schools-Wikipedia, 2009),
structured manageable version Wikipedia intended use schools. test
approach also need build MDP model task. done using empirical data
follows. First, use Latent Dirichlet Allocation (LDA) using Gibbs sampling (Griffiths
& Steyvers, 2004) divide pages Wikipedia 20 topics. topic corresponds
state MDP. LDA algorithm identifies topic set keywords
occur often pages topic. define sets keywords
action (20 actions totals, corresponding 20 keywords). randomly navigate
around Wiki using protocol described (with computer player
clicks LDA keywords) collect 200,000 transitions. use observed data build
transition reward model MDP (the reward 1 hit 0 otherwise).
specific choices LDA parameter number states actions
MDP made way best policy provided model comparable
performance human player.
Using Amazon Mechanical Turk (MTurk, 2010), consider three experimental conditions task. one experiment, given target, computer chooses word
(uniformly random) set keywords (the action) comes optimal
policy MDP model. another experiment, human subjects choose click
word without help. Finally, test domain human users
computer highlights, hints, words come non-deterministic policy
= 0.1. record time taken process number times target word
observed (number hits). Table 4 summarizes average outcomes experiment
four target words (we used seven target words, could collect enough data
them). also include p-value t-test comparing results human
agents without hints. computer score averaged 1000 runs.
20

fiNon-Deterministic Policies Markovian Decision Processes

Table 4: Comparison different agents web navigation task. t-test
number hits human player uses hints one not.
Target

Computer

Human

Human hint

t-Test

Marriage

1.88 hits

1.94 hits
103 seconds
(86 subjects)

2.63 hits
93 seconds
(86 subjects)

0.012

4.86 hits
91 seconds
(67 subjects)

5.61 hits
84 seconds
(97 subjects)

0.049

3.67 hits
85 seconds
(98 subjects)

4.39 hits
89 seconds
(83 subjects)

0.014

3.18 hits
96 seconds
(92 subjects)

3.42 hits
85 seconds
(123 subjects)

0.46

(1000 runs)
Military

4.72 hits
(1000 runs)

Book

3.77 hits
(1000 runs)

Animal

2.50 hits
(1000 runs)

first three target words, performance computer agent close
human user, observe providing hints user results statistically significant
increase number hits. fact see computer-aided human outperforms
computer human agents. shows non-deterministic policies
provide means inject human domain knowledge computer models way
final outcome superior decision-making solely performed one party.
last word, computer model working poorly, judging low hit rate. Thus,
surprising see hints provide much help human agent
case (as seen non-significant p-value). also observe general speedup
(for three targets) time taken agent choose click words,
shows usefulness non-deterministic policies accelerating human
subjects decision-making process.

6. Discussion
paper introduces new concept non-deterministic policies potential use
decision support systems based Markovian processes. context, investigate
assumption decision-making system return single optimal action
relaxed, instead return set near-optimal actions.
Non-deterministic policies inherently different stochastic policies. Stochastic
policies assume randomized action selection strategy specific probabilities,
whereas non-deterministic policies impose constraint. thus use bestcase worst-case analysis non-deterministic policies highlight different scenarios
human user.
21

fiMilani Fard & Pineau

benefits non-deterministic policies sequential decision-making two-fold.
First, several actions difference performance negligible,
report actions near-optimal options. instance, medical setting,
difference outcome two treatment options might medically
significant. case, may beneficial provide near-optimal options.
makes system robust user-friendly. medical decision-making
process, instance, physician make final decision among near-optimal
options based side effects burden, patients preferences, expense, criteria
captured model used decision support system. key constraint,
however, make sure regardless final choice actions, performance
executed policy always bounded near optimal. framework, property
maintained -optimality guarantee worst-case scenario.
Another potential use non-deterministic action sets Markovian decision processes capture uncertainties optimality actions. Often times, amount
data models constructed sufficient clearly identify single optimal
action. forced chose one action optimal one, might high
chance making wrong decision. However, given chance provide set
possibly-optimal actions, ensure include promising options
cutting obviously bad ones. setting, task trim action set much
possible providing guarantee optimal action still among top
possible options.
solve first problem, paper introduces two algorithms find flexible nearoptimal policies. First derive exact solution MIP formulation find maximal
-optimal policy. MIP solution is, however, computationally expensive
scale large domains. describe search algorithm solve problem
less computational cost. algorithm fast enough applied real world medical
domains. also show use heuristics search algorithm find solution
DAG structures even faster. heuristic search also provide approximate solutions
general case.
Another way scale problem larger domains approximate solution
MIP program relaxing constraints. One relax constraints
allow non-integral solutions penalize objective values away 0 1.
study approximation methods remains interesting direction future work.
idea non-deterministic policies introduces wide range new problems
research topics. Section 4, discuss idea near optimal non-deterministic policies
address problem finding one largest action set. mentioned,
optimization criteria might useful decision support systems.
include maximizing decision margin (the margin worst selected action
best one selected), alternatively minimizing uncertainty wrong selection.
Formalizing problems MIP formulation, incorporating heuristic
search, might prove useful.
evidenced human interaction experiments, non-deterministic policies substantially improve outcome planning decision-making tasks human
user assisted robust computer-generated plan. Allowing several suggestions
step provides effective way incorporating domain knowledge human side
22

fiNon-Deterministic Policies Markovian Decision Processes

decision-making process. medical domains physicians domain knowledge
often hard capture computer model, collaborative model decision-making
non-deterministic policies could offer powerful framework selecting effective,
clinically acceptable, treatment strategies.

Acknowledgments
authors wish thank A. John Rush (Duke-NUS Graduate Medical School), Susan
A. Murphy (University Michigan), Doina Precup (McGill University) helpful
discussions regarding work. Funding provided National Institutes Health
(grant R21 DA019800) NSERC Discovery Grant program.

References
Bellman, R. (1957). Dynamic Programming. Princeton University Press.
Bertsekas, D. (1995). Dynamic Programming Optimal Control, Vol 2. Athena Scientific.
Ernst, D., Stan, G. B., Concalves, J., & Wehenkel, L. (2006). Clinical data based optimal
STI strategies HIV: reinforcement learning approach. Proceedings
Fifteenth Machine Learning conference Belgium Netherlands (Benelearn),
pp. 6572.
Fava, M., Rush, A., Trivedi, M., Nierenberg, A., Thase, M., Sackeim, H., Quitkin, F., Wisniewski, S., Lavori, P., Rosenbaum, J., & Kupfer, D. (2003). Background rationale
sequenced treatment alternatives relieve depression (STAR* D) study. Psychiatric Clinics North America, 26 (2), 457494.
Griffiths, T. L., & Steyvers, M. (2004). Finding scientific topics. Proceedings National
Academy Sciences, 101 (Suppl. 1), 52285235.
Hauskrecht, M., & Fraser, H. (2000). Planning treatment ischemic heart disease
partially observable Markov decision processes. Artificial Intelligence Medicine,
18 (3), 221244.
Heger, M. (1994). Consideration risk reinforcement learning. Proceedings
Eleventh International Conference Machine Learning (ICML), pp. 105111.
Karmarkar, N. (1984). new polynomial-time algorithm linear programming. Combinatorica, 4 (4), 373395.
Kearns, M., & Singh, S. (2002). Near-optimal reinforcement learning polynomial time.
Machine Learning, 49.
Magni, P., Quaglini, S., Marchetti, M., & Barosi, G. (2000). Deciding intervene:
Markov decision process approach. International Journal Medical Informatics,
60 (3), 237253.
Mannor, S., Simester, D., Sun, P., & Tsitsiklis, J. N. (2004). Bias variance value
function estimation. Proceedings Twenty-First International Conference
Machine Learning (ICML), pp. 308322.
23

fiMilani Fard & Pineau

Mannor, S., Simester, D., Sun, P., & Tsitsiklis, J. N. (2007). Bias variance approximation value function estimates. Management Science, 53 (2), 308322.
MTurk (2010). Amazon mechanical turk. http://www.mturk.com/.
Murphy, S. A. (2005). experimental design development adaptive treatment
strategies. Statistics Medicine, 24 (10), 14551481.
Pineau, J., Bellemare, M. G., Rush, A. J., Ghizaru, A., & Murphy, S. A. (2007). Constructing evidence-based treatment strategies using methods computer science. Drug
Alcohol Dependence, 88 (Supplement 2), S52 S60.
Russell, S. J., & Norvig, P. (2003). Artificial Intelligence: Modern Approach (Second
Edition). Prentice Hall.
Sato, M., & Kobayashi, S. (2000). Variance-penalized reinforcement learning risk-averse
asset allocation. Proceedings Second International Conference Intelligent
Data Engineering Automated Learning, Data Mining, Financial Engineering,
Intelligent Agents, pp. 244249. Springer-Verlag.
Schaefer, A., Bailey, M., Shechter, S., & Roberts, M. (2004). Handbook Operations
Research / Management Science Applications Health Care, chap. Medical decisions
using Markov decision processes. Kluwer Academic Publishers.
Schools-Wikipedia (2009).
wikipedia.org/.

2008/9 wikipedia selection schools.

http://schools-

Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction (Adaptive
Computation Machine Learning). MIT Press.
Thapa, D., Jung, I., & Wang, G. (2005). Agent based decision support system using reinforcement learning emergency circumstances. Lecture Notes Computer
Science, 3610, 888.
West, R., Pineau, J., & Precup, D. (2009). Wikispeedia: online game inferring
semantic distances concepts. Proceedings Twenty-First International
Jont Conference Artifical Intelligence (IJCAI), pp. 15981603, San Francisco, CA,
USA. Morgan Kaufmann Publishers Inc.

24

fiJournal Artificial Intelligence Research 40 (2011) 701-728

Submitted 10/10; published 4/11

Computing Small Unsatisfiable Cores
Satisfiability Modulo Theories
Alessandro Cimatti

cimatti@fbk.eu

FBK-IRST,
Via Sommarive 18, 38123 Povo, Trento, Italy

Alberto Griggio

griggio@fbk.eu

FBK-IRST,
Via Sommarive 18, 38123 Povo, Trento, Italy

Roberto Sebastiani

rseba@disi.unitn.it

DISI, Universita di Trento,
Via Sommarive 14, 38123 Povo, Trento, Italy

Abstract
problem finding small unsatisfiable cores SAT formulas recently received
lot interest, mostly applications formal verification. However, propositional
logic often expressive enough representing many interesting verification problems,
naturally addressed framework Satisfiability Modulo Theories,
SMT. Surprisingly, problem finding unsatisfiable cores SMT received
little attention literature.
paper present novel approach problem, called Lemma-Lifting
approach. main idea combine SMT solver external propositional
core extractor. SMT solver produces theory lemmas found search,
dynamically lifting suitable amount theory information Boolean level.
core extractor called Boolean abstraction original SMT problem
theory lemmas. results unsatisfiable core original SMT problem,
remaining theory lemmas removed.
approach conceptually interesting, several advantages practice.
fact, extremely simple implement update, interfaced
every propositional core extractor plug-and-play manner, benefit free
unsat-core reduction techniques made available.
evaluated algorithm extensive empirical test SMT-LIB
benchmarks, confirms validity potential approach.

1. Motivations Goals
last decade witnessed impressive advance efficiency SAT techniques, brought large previously-intractable problems reach stateof-the-art SAT solvers. consequence, SAT solvers fundamental tool many
industrial-strength applications, including formal verification design flows hardware
systems, equivalence, property checking, ATPG. particular, one relevant problems context, thanks many important applications, finding
small unsatisfiable cores, is, small unsatisfiable subsets unsatisfiable sets clauses.
c
2011
AI Access Foundation. rights reserved.

fiCimatti, Griggio, & Sebastiani

Examples applications include use SAT instead BDDs unbounded symbolic
model checking (McMillan, 2002), automatic predicate discovery abstraction refinement
frameworks (McMillan & Amla, 2003; Wang, Kim, & Gupta, 2007), decision procedures
(Bryant, Kroening, Ouaknine, Seshia, Strichman, & Brady, 2009), under-approximation
refinement context bounded model checking multi-threaded systems (Grumberg,
Lerda, Strichman, & Theobald, 2005), debugging design errors circuits (Suelflow, Fey,
Bloem, & Drechsler, 2008). reason, problem finding small unsat cores
SAT addressed many authors recent years (Zhang & Malik, 2003; Goldberg & Novikov, 2003; Lynce & Marques-Silva, 2004; Oh, Mneimneh, Andraus, Sakallah,
& Markov, 2004; Mneimneh, Lynce, Andraus, Marques-Silva, & Sakallah, 2005; Huang,
2005; Dershowitz, Hanna, & Nadel, 2006; Zhang, Li, & Shen, 2006; Biere, 2008; Gershman,
Koifman, & Strichman, 2008; van Maaren & Wieringa, 2008; Asn, Nieuwenhuis, Oliveras,
& Rodrguez Carbonell, 2008; Nadel, 2010).
formalism plain propositional logic, however, often suitable expressive
enough representing many real-world problems, including verification RTL
designs, real-time hybrid control systems, analysis proof obligations
software verification. problems naturally expressible satisfiability problems decidable first-order theories Satisfiability Modulo Theories, SMT. Efficient SMT
solvers developed last five years, called lazy SMT solvers, combine
Conflict-Driven Clause Learning (CDCL) SAT solver based DPLL algorithm (Davis
& Putnam, 1960; Davis, Logemann, & Loveland, 1962; Marques-Silva & Sakallah, 1996;
Zhang & Malik, 2002) hereafter simply DPLL ad-hoc decision procedures
many theories interest (see, e.g., Nieuwenhuis, Oliveras, & Tinelli, 2006; Barrett
& Tinelli, 2007; Bruttomesso, Cimatti, Franzen, Griggio, & Sebastiani, 2008; Dutertre &
de Moura, 2006; de Moura & Bjrner, 2008).
Surprisingly, problem finding unsatisfiable cores SMT received virtually
attention literature. Although SMT tools compute unsat cores, done
either byproduct general task producing proofs, modifying
embedded DPLL solver apply basic propositional techniques produce unsat
core. particular, aware work aiming producing small unsatisfiable
cores SMT.
paper present novel approach addressing problem, call
Lemma-Lifting approach. main idea combine SMT solver external
propositional core extractor. SMT solver stores returns theory lemmas
prove order refute input formula; external core extractor called
Boolean abstraction original SMT problem theory lemmas.
algorithm based following two key observations: i) theory lemmas discovered
SMT solver search valid clauses theory consideration,
therefore affect satisfiability formula ; ii) conjunction
original SMT formula theory lemmas propositionally unsatisfiable.
Therefore, external (Boolean) core extractor finds unsatisfiable core (the Boolean
abstraction of) conjunction original formula theory lemmas,
refined back subset original clauses simply removing (the
Boolean abstractions of) theory lemmas. result unsatisfiable core original
SMT problem.
702

fiComputing Small Unsatisfiable Cores Satisfiability Modulo Theories

Although simple principle, approach conceptually interesting: basically,
SMT solver used dynamically lift suitable amount theory information
Boolean level. Furthermore, approach several advantages practice: first,
extremely simple implement update; second, effective finding small cores;
third, core extraction prone complex SMT reasoning; finally, interfaced
every propositional core extractor plug-and-play manner, benefit free
unsat-core reduction techniques made available.
evaluated approach extensive empirical test SMT-LIB benchmarks, terms effectiveness (reduction size cores) efficiency (execution
time). results confirm validity versatility approach.
byproduct, also produced extensive insightful evaluation
main Boolean unsat-core-generation tools currently available.
Content. paper organized follows. 2 3 provide background
knowledge techniques SAT SMT (2), extraction unsatisfiable cores
SAT SMT (3). 4 present discuss new approach algorithm.
5 present comment empirical tests. 6 conclude, suggesting
future developments.

2. SAT SMT
setting standard first order logic. 0-ary function symbol called constant.
term first-order term built function symbols variables. t1 , . . . , tn terms
p predicate symbol, p(t1 , . . . , tn ) atom. formula built
usual way universal existential quantifiers, Boolean connectives, atoms.
literal either atom negation. call formula quantifier-free
contain quantifiers, ground contain free variables. clause disjunction
literals. formula said conjunctive normal form (CNF) conjunction
clauses. every non-CNF formula , equisatisfiable CNF formula generated
polynomial time (Tseitin, 1983).
also assume usual first-order notions interpretation, satisfiability, validity,
logical consequence, theory, given, e.g., Enderton (1972). write |=
denote formula logical consequence (possibly infinite) set formulas.
first-order theory, , set first-order sentences. structure model theory
satisfies every sentence . formula satisfiable (or -satisfiable)
satisfiable model . (We sometimes use word -formula ground formula
interested determining -satisfiability.)
follows, little abuse notation, might sometimes denote conjunctions
literals l1 . . . ln sets {l1 , . . . , ln } vice versa. {l1 , . . . , ln }, might write
mean l1 . . . ln . Moreover, following terminology SAT SMT
communities, shall refer predicates arity zero propositional variables,
uninterpreted constants theory variables.
Given first-order theory (ground) satisfiability problem decidable,
call theory solver , -solver, tool able decide satisfiability
sets/conjunctions ground atomic formulas negations theory literals literals language . input set -literals -unsatisfiable,
703

fiCimatti, Griggio, & Sebastiani

1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.

SatValue DPLL (formula , assignment ) {
(1) {
decide next branch(, );
(1) {
status = deduce(, );
(status == sat)
return sat;
else (status == conflict) {
hblevel, = analyze conflict(, );
(blevel < 0) return unsat;
else backtrack(blevel, , , );
}
else break;
}}}
Figure 1: Schema modern DPLL engine.

typical -solver returns unsat, also returns subset -literals
found -unsatisfiable. ( hereafter called theory conflict set, theory
conflict clause.) -satisfiable, -solver returns sat, may also
able discover one (or more) deductions form
Wn{l1 , . . . , ln } |=T l, s.t. {l1 , . . . , ln }
l unassigned -literal. so, call ( i=1 li l) theory-deduction clause.
Importantly, notice theory-conflict clauses theory-deduction clauses valid
. call theory lemmas -lemmas.
Satisfiability Modulo (the) Theory SMT (T ) problem deciding
satisfiability Boolean combinations propositional atoms theory atoms. Examples
useful theories equality uninterpreted functions (EU F), difference logic (DL)
linear arithmetic (LA), either reals (LA(Q)) integers (LA(Z)), theory
arrays (AR), bit vectors (BV), combinations. call SMT (T ) tool
tool able decide SMT (T ). Notice that, unlike -solver, SMT (T ) tool must
handle also Boolean connectives.
Hereafter adopt following terminology notation. symbols , denote
-formulas, , denote sets -literals; p , p denote propositional formulas, p ,
p denote sets propositional literals, interpreted truth assignments
variables.
2.1 Propositional Satisfiability DPLL Algorithm
state-of-the-art SAT procedures evolutions Davis-Putnam-Longeman-Loveland
(DPLL) procedure (Davis & Putnam, 1960; Davis et al., 1962). high-level schema
modern DPLL engine, adapted description given Zhang Malik (2002),
704

fiComputing Small Unsatisfiable Cores Satisfiability Modulo Theories

1.
2.
3.
4.
5.
6.
7.
8.
9.

SatValue Lazy SMT Solver (T -formula ) {
p = 2P();
(DPLL(p , p ) == sat) {
h, = -solver(P2T (p ))
( == sat) return sat;
p = p 2P();
};
return unsat;
};

Figure 2: simplified schema lazy SMT (T ) procedures.
reported Figure 1.1 Boolean formula CNF; assignment initially
empty, updated stack-based manner.
main loop, decide next branch(, ) chooses unassigned literal l
according heuristic criterion, adds . (This operation called decision, l
called decision literal end number decision literals operation called
decision level l.) inner loop, deduce(, ) iteratively deduces literals l deriving
current assignment updates accordingly; step repeated either
satisfies , falsifies , literals deduced, returning sat, conflict
unknown respectively. (The iterative application Boolean deduction steps deduce
also called Boolean Constraint Propagation, BCP.) first case, DPLL returns sat.
second case, analyze conflict(, ) detects subset caused conflict
(conflict set) decision level blevel backtrack. blevel < 0, conflict exists
even without branching, DPLL returns unsat. Otherwise, backtrack(blevel, , )
adds clause (learning) backtracks blevel (backjumping), updating
accordingly. (E.g., popular 1st-UIP schema, backtracks smallest blevel
one literal assigned, hence deduces negation remaining
literal applying BCP learned clause ; see Zhang, Madigan, Moskewicz, & Malik,
2001.) third case, DPLL exits inner loop, looking next decision.
much deeper description modern DPLL-based SAT solvers, refer reader,
e.g., work Zhang Malik (2002).
2.2 Lazy Techniques SMT
idea underlying every lazy SMT (T ) procedure (a complete set of) truth
assignments propositional abstraction enumerated checked satisfiability ; procedure either returns sat one -satisfiable truth assignment found,
returns unsat otherwise.
introduce following notation. 2P bijective function (theory propositional), called Boolean (or propositional) abstraction, maps propositional variables
themselves, ground -atoms fresh propositional variables, homomorphic
1. remark many details provided critical understanding rest paper,
mentioned sake completeness.

705

fiCimatti, Griggio, & Sebastiani

w.r.t. Boolean operators set inclusion. function P2T (propositional theory), called refinement, inverse 2P. (E.g., 2P({((x 3) A3 ), (A2
(x = z))}) = {(B1 A3 ), (A2 B2 )}, B1 B2 fresh propositional variables,
P2T ({A1 , A2 , B1 , B2 }) = {A1 , A2 , (x 3), (x = z)}.) follows, shall
use p superscript denoting Boolean abstraction formula/truth assignment
(e.g., p denotes 2P(), denotes P2T (p )). Given -formula , say
propositionally unsatisfiable 2P() |= . .
Figure 2 presents simplified schema lazy SMT (T ) procedure, called off-line
schema. propositional abstraction p input formula given input
SAT solver based DPLL algorithm (Davis et al., 1962; Zhang & Malik, 2002),
either decides p unsatisfiable, hence -unsatisfiable, returns
satisfying assignment p ; latter case, P2T (p ) given input -solver.
P2T (p ) found -consistent, -consistent. not, -solver returns conflict
set caused -inconsistency P2T (p ); abstraction -lemma ,
2P(), added clause p . DPLL solver restarted scratch
resulting formula.
Practical implementations follow elaborated schema, called on-line schema
(see Barrett, Dill, & Stump, 2002; Audemard, Bertoli, Cimatti, Kornilowicz, & Sebastiani,
2002; Flanagan, Joshi, Ou, & Saxe, 2003). before, p given input modified
version DPLL, satisfying assignment p found, refinement p
fed -solver; found -consistent, -consistent; otherwise, -solver
returns conflict set caused -inconsistency P2T (p ). clause
p added conjunction p , either temporarily permanently (T -learning), and,
rather starting DPLL scratch, algorithm backtracks highest point
search one literals p unassigned (T -backjumping), therefore
value (propositionally) implied others p .
important variant schema (Nieuwenhuis et al., 2006) building
mixed Boolean+theory conflict clause, starting p applying backwardtraversal implication graph built DPLL (Zhang et al., 2001), one
standard conditions (e.g., 1st UIP Zhang et al., 2001) achieved.
important optimizations early pruning theory propagation: -solver
invoked also (the refinement of) intermediate assignment : found unsatisfiable, procedure backtrack, since extension -satisfiable;
not, -solver performs deduction {l1 , . . . , ln } |=T l s.t. {l1 , . . . , lnW
} ,
2P(l) unit-propagated, Boolean abstraction -lemma ( ni=1 li l)
learned.
on-line lazy SMT (T ) schema coarse description procedures underlying
state-of-the-art lazy SMT (T ) tools like, e.g., BarceLogic, CVC3, MathSAT, Yices,
Z3. interested reader pointed to, e.g., work Nieuwenhuis et al. (2006), Barrett
Tinelli (2007), Bruttomesso et al. (2008), Dutertre de Moura (2006), de Moura
Bjrner (2008), details references, work Sebastiani (2007)
Barrett, Sebastiani, Seshia, Tinelli (2009) survey.
706

fiComputing Small Unsatisfiable Cores Satisfiability Modulo Theories

3. Extracting Unsatisfiable Cores
Without loss generality, following consider formulas CNF. Given
unsatisfiable CNF formula , say unsatisfiable CNF formula unsatisfiable
core iff = 0 (possibly empty) CNF formula 0 . Intuitively, subset
clauses causing unsatisfiability . unsatisfiable core minimal iff
formula obtained removing clauses satisfiable. minimum unsat
core minimal unsat core smallest possible cardinality.
3.1 Techniques Unsatisfiable-Core Extraction SAT
last years, several algorithms computing small, minimal minimum unsatisfiable cores propositional formulas proposed. approach Zhang
Malik (2003) Goldberg Novikov (2003), computed byproduct
DPLL-based proof-generation procedure. computed unsat core simply collection
original clauses DPLL solver used derive empty clause resolution. returned core minimal general, reduced iterating
algorithm fixpoint, using input iteration core computed
previous one. algorithm Gershman et al. (2008), instead, manipulates resolution
proof shrink size core, using also fixpoint iteration Zhang Malik
(2003) enhance quality results. Oh et al. (2004) present algorithm
compute minimal unsat cores. technique based modifications standard DPLL
engine, works adding extra variables (selectors) original clauses,
performing branch-and-bound algorithm modified formula. procedure
presented Huang (2005) extracts minimal cores using BDD manipulation techniques,
removing one clause time remaining core minimal. construction
minimal core Dershowitz et al. (2006) also uses resolution proofs, works iteratively removing proof one input clause time, longer possible
prove inconsistency. clause removed, resolution proof modified prevent
future use clause.
far computation minimum unsatisfiable cores concerned, algorithm Lynce Marques-Silva (2004) searches unsat cores input problem;
done introducing selector variables original clauses, increasing
search space DPLL solver include also variables; then, (one of) unsatisfiable subformulas smallest number selectors assigned true returned.
approach described Mneimneh et al. (2005) instead based branch-and-bound
algorithm exploits relation maximal satisfiability minimum unsatisfiability. relation used also procedure Zhang et al. (2006),
instead based genetic algorithm.
3.2 Techniques Unsatisfiable-Core Extraction SMT
best knowledge, literature explicitly addressing problem
computing unsatisfiable cores SMT 2 . However, four SMT solvers (i.e. CVC3, Barrett &
Tinelli, 2007, MathSAT, Bruttomesso et al., 2008, Yices, Dutertre & de Moura, 2006
2. Except previous short version present paper (Cimatti, Griggio, & Sebastiani, 2007).

707

fiCimatti, Griggio, & Sebastiani

((x = 0) (x = 1))LA(Z)

((x = 0) (x = 1) A2 )

((x = 0) (x = 1) A1 )

((x = 0) (x = 1) A2 )

((x = 0) A1 A2 )

((x = 0) A2 )
(A1 (y = 2))

(A1 A2 )

((y = 2) A2 )

((y = 2) (y < 0))LA(Z)

(A2 (y < 0))
((y = 1) (y < 0))LA(Z)

(y < 0)

(A2 (y = 1))

((y < 0) (y = 1))

((y < 0))


Figure 3: Resolution proof SMT formula (1) found MathSAT. Boxed clauses
correspond unsatisfiable core.

Z3, de Moura & Bjrner, 2008) support unsat core generation3 . following, describe
underlying approaches, generalize techniques propositional UC extraction.
preliminarily remark none solvers aims producing minimal minimum
unsat cores, anything reduce size.
Strictly related work, Liffiton Sakallah (2008) presented general technique
enumerating minimal unsatisfiable subsets given inconsistent set constraints,
implemented tool CAMUS. Although description properties
algorithms focuses pure SAT, authors remark approach extends easily
SMT, implemented inside CAMUS SMT version procedure.
Therefore following briefly describe also approach.
3.2.1 Proof-Based UC Extraction.
CVC3 MathSAT run proof-producing mode, compute unsatisfiable cores
byproduct generation proofs. Similarly approach Zhang Malik
(2003), idea analyze proof unsatisfiability backwards, return
unsatisfiable core collection assumptions (i.e. clauses original
problem) used proof derive contradiction.

3. information reported computation unsat cores CVC3, Yices Z3 comes
private communications authors user manual CVC3.

708

fiComputing Small Unsatisfiable Cores Satisfiability Modulo Theories

Example 1 order show described approaches work, consider small unsatisfiable SMT (T ) formula, LA(Z):
((x = 0) (x = 1) A1 ) ((x = 0) (x = 1) A2 ) ((x = 0) (x = 1) A2 )
(A2 (y = 1)) (A1 (x + > 3)) (y < 0) (A2 (x = 4))
((y = 2) A1 ) (x 0), (1)
x real variables A1 A2 Booleans.
proof-based approach, resolution proof unsatisfiability built
search. E.g., Figure 3 shows proof tree found MathSAT. leaves tree
either original clauses (boxed Figure) LA(Z)-lemmas (denoted LA(Z)
suffix). unsatisfiable core built collecting original clauses appearing
leaves proof. case, is:
{((x = 0) (x = 1) A1 ), ((x = 0) (x = 1) A2 ), ((x = 0) (x = 1) A2 ),
(A2 (y = 1)), (y < 0), ((y = 2) A1 )}. (2)
case, unsat core minimal.
3.2.2 Assumption-Based UC Extraction
approach used Yices (Dutertre & de Moura, 2006) Z3 (de Moura & Bjrner,
2008) adaptation method Lynce Marques-Silva (2004): clause
Ci problem, new Boolean selector variable Si created; then, Ci replaced
(Si Ci ); finally, starting search Si forced true. way,
conflict decision level zero found DPLL solver conflict clause contains
selector variables, unsat core returned union clauses whose selectors
appear conflict clause.
Example 2 Consider formula (1) Example 1. assumption-based approach, 9 input clauses augmented extra variable Si , asserted
true beginning search. formula therefore becomes:
^

Si



(S1 ((x = 0) (x = 1) A1 )) (S2 ((x = 0) (x = 1) A2 ))
(S3 ((x = 0) (x = 1) A2 )) (S4 (A2 (y = 1)))

(3)

(S5 (A1 (x + > 3))) (S6 (y < 0))
(S7 (A2 (x = 4))) (S8 ((y = 2) A1 )) (S9 (x 0))
final conflict clause generated conflict analysis (Zhang et al., 2001) is:
S1 S2 S3 S4 S6 S7 S8 ,
4. using Yices.

709

4

(4)

fiCimatti, Griggio, & Sebastiani

corresponding following unsat core:
{((x = 0) (x = 1) A1 ), ((x = 0) (x = 1) A2 ), ((x = 0) (x = 1) A2 ),
(A2 (y = 1)), (y < 0), (A2 (x = 4)), ((y = 2) A1 )}. (5)
Notice minimal, presence redundant clause (A2 (xy =
4)), corresponding S7 final conflict clause (4).
Remark 1 idea behind two techniques illustrated essentially same.
exploit implication graph built DPLL conflict analysis detect subset
input clauses used decide unsatisfiability. main difference
proof-based approach done explicitly constructing proof tree,
activation-based one done implicitly labeling original clauses.
deeper comparison two approaches (and variants them),
refer reader work Asn et al. (2008) Nadel (2010).
3.2.3 CAMUS Approach Extracting Minimal UCs.
completely different approach, aiming generating minimal UCs given
inconsistent set propositional clauses , presented Liffiton Sakallah (2008)
implemented tool CAMUS. nutshell, approach works two distinct phases:
(a) enumerate set Minimal Correction Subsets (MCSs) . 5 performed specialized algorithm, using backend engine incremental SAT solver
able handle also AtMost constraints;
(b) enumerate set U minimal UCs minimal hitting sets set .
also performed specialized algorithm. Alternatively, another algorithm
produce one minimal UC much less effort.
important notice sets U returned exponentially big wrt.
size . Thus, procedure may produce exponential amount MCSs phase
(a) producing one UC. extent, authors provide also modified
efficient version technique, sacrifice completeness approach.
refer reader work Liffiton Sakallah (2008) detailed explanation
technique features.
mentioned above, although description algorithms focuses pure SAT,
authors remark approach extends easily SMT, implemented
inside CAMUS version algorithm working also SMT, using Yices backend
SMT solver. Unfortunately, provide details extension. 6
5. MCS unsatisfiable set constraint complement set maximal consistent subset
: \ consistent and, every Ci , \ ( \ Ci ) inconsistent (Liffiton & Sakallah, 2008).
6. See 10 Conclusions Future Work. article Liffiton Sakallah (2008).

710

fiComputing Small Unsatisfiable Cores Satisfiability Modulo Theories

Example 3 Consider LA(Z)-formula (1) Example 1 form clause set

def

=





























c1
c2
c3
c4
c5
c6
c7
c8
c9

:
:
:
:
:
:
:
:
:

(x = 0) (x = 1) A1 ,
(x = 0) (x = 1) A2 ,
(x = 0) (x = 1) A2 ,
A2 (y = 1),
A1 (x + > 3),
(y < 0),
A2 (x = 4),
(y = 2) A1 ,
(x 0)
















.

(6)















run (6), CAMUS returns following two minimal UCs:
def

uc
1 =
c1 :




c2 :



c3 :
c4 :





c
:

5
c6 :

def


(x = 0) (x = 1) A1 ,


(x = 0) (x = 1) A2 ,



(x = 0) (x = 1) A2 ,
,
A2 (y = 1),





A1 (x + > 3),


(y < 0)

uc
2 =
c1 :




c2 :



c3 :
c4 :





c :

6
c8 :

(x = 0) (x = 1) A1 ,
(x = 0) (x = 1) A2 ,
(x = 0) (x = 1) A2 ,
A2 (y = 1),
(y < 0),
(y = 2) A1










.

(7)









(Notice uc2 identical UC found Example 1.)
understand Liffiton Sakallah (2008) that, order produce uc1 uc2 ,
CAMUS enumerates first (not necessarily order) following set MCSs:
{{c1 }, {c2 }, {c3 }, {c4 }, {c6 }, {c5 , c8 }}

(8)

computes uc1 uc2 minimal hitting sets (8).
Notice (8) set MCSs , \ {c5 } \ {c8 } LA(Z)-inconsistent,

{A1 = , A2 = , x = 1, = 3} |=LA(Z) \ {c1 },
{A1 = , A2 = , x = 2, = 6} |=LA(Z) \ {c2 },
{A1 = , A2 = , x = 0, = 4} |=LA(Z) \ {c3 },
{A1 = , A2 = >, x = 0, = 1} |=LA(Z) \ {c4 },
{A1 = , A2 = >, x = 3, = 1}
|=LA(Z) \ {c6 },
{A1 = >, A2 = , x = 1, = 1} |=LA(Z) \ {c5 , c8 }.
Moreover, contains MCSs also \ {c9 }, \ {c5 , c9 } \ {c8 , c9 }
LA(Z)-inconsistent.

4. Novel Approach Building Unsatisfiable Cores SMT
present novel approach, called Lemma-Lifting approach, unsatisfiable
core computed posteriori w.r.t. execution SMT solver, formula found -unsatisfiable. done means external (and possibly
optimized) propositional unsat core extractor.
711

fiCimatti, Griggio, & Sebastiani

4.1 Main Ideas
following, assume lazy SMT (T ) procedure run unsatisfiable set SMT (T ) clauses =def {C1 , . . . , Cn }, D1 , . . . , Dk denote
-lemmas, theory-conflict theory-deduction clauses, returned -solver run. (Notice that, definition, -lemmas -valid
clauses.) case mixed Boolean+theory-conflict clauses (Nieuwenhuis et al., 2006) (see
2.2), -lemmas returned -solver used compute
mixed Boolean+theory-conflict clause, including initial theory-conflict clause
theory-deduction clauses corresponding theory-propagation steps performed. 7
assumptions, two simple facts hold.
(i) Since -lemmas Di valid , affect -satisfiability formula:
( Di ) |=T |=T .
(ii) conjunction
-lemmas D1 , . . . , Dk propositionally unsatisfiable:
Vn
2P( i=1 Di ) |= .
Fact (i) self-evident. Fact (ii) termination condition lazy SMT tools
input formula -unsatisfiable. InVthe off-line schema Figure 2, procedure ends
DPLL establishes 2P( ni=1 Di ) unsatisfiable, Di negation
theory-conflict set returned i-th call -solver. Fact (ii) generalizes
on-line schema, noticing -backjumping theory-conflict clause Di produces
analogous effect re-invoking DPLL p 2P(Di ), whilst theory propagation
deduction {l1 , . . . , lk }W|=T l seen form unit propagation theorydeduction clause 2P ( li l).
Example 4 Consider formula (1) Example 1. order decide unsatisfiability, MathSAT generates following set LA(Z)-lemmas:
{((x = 1) (x = 0)), ((y = 2) (y < 0)), ((y = 1) (y < 0))}. (9)
Notice LA(Z)-valid (fact (i)). Then, Boolean abstraction (1)
conjoined Boolean abstraction LA(Z)-lemmas, resulting following
propositional formula:
(B1 B2 A1 ) (B1 B2 A2 ) (B1 B2 A2 ) (A2 B3 )
(A1 B4 ) B5 (A2 B6 ) (B7 A1 ) B8
(B2 B1 ) (B7 B5 ) (B3 B5 ), (10)
where:
B1
B2
B3
B4

def

= 2P(x = 0)
def
= 2P(x = 1)
def
= 2P(y = 1)
def
= 2P(x + > 3)

B5
B6
B7
B8

def

= 2P(y < 0)
= 2P(x = 4)
def
= 2P(y = 2)
def
= 2P(x 0).
def

7. case, SMT solver provide original -lemmas feature using mixed
Boolean+theory-conflict clauses active, latter feature disabled.

712

fiComputing Small Unsatisfiable Cores Satisfiability Modulo Theories

propositional formula (10) unsatisfiable (fact (ii)), demonstrated following
resolution proof.
(B2 B1 )

(B1 B2 A1 )

(B1 B2 A2 )

(B1 B2 A2 )

(B1 A1 A2 )

(B1 A2 )
(B7 A1 )

(A1 A2 )

(B7 A2 )

(B7 B5 )
(A2 B5 )

(B3 B5 )

(A2 B3 )

(B5 B3 )
B5

B5


Fact (ii) holds also SMT tools learn mixed Boolean+theory-clauses
F1 , . . . , Fn (instead -lemmas), obtained -lemmasVD1 , . . . , Dn backward
traversal
implication graph. fact, case, 2P( ni=1 Fi ) |= holds. Since
Vn V
i=1 Di |= ni=1 Fi , way Fi built, 8 (ii) holds.
SMT tools implement theory-propagation slightly different way (e.g. BarceLogic, Nieuwenhuis et al., 2006). l1 , . . . , ln |=T l, instead learning -lemma
l1 . . . ln l unit-propagating l it, simply propagate value l, without
learning clause. propagation leads conflict later search,
theory-deduction clause learned used conflict-analysis. validity fact (ii)
affected optimization, -lemmas used conflict analysis
needed hold (Nieuwenhuis et al., 2006).
Overall, variants on-line schema, embedded DPLL engine builds either
explicitly implicitly resolution refutation Boolean abstraction conjunction
original clauses -lemmas returned -solver. Thus fact (ii) holds.
4.2 Extracting SMT Cores Lifting Theory Lemmas
Facts (i) (ii) discussed 4.1 suggest new approach generation unsatisfiable
cores SMT. main idea theory lemmas used SMT search
lifted Boolean clauses, unsat core extracted purely propositional
core extractor. Therefore, call technique Lemma-Lifting approach.
algorithm presented Figure 4. procedure -Unsat Core receives
input set clauses =def {C1 , . . . , Cn } invokes lazy SMT (T ) tool
Lazy SMT Solver, instructed store somewhere -lemmas returned
Vi1
8. clause 2P(Fi ) obtained resolving clause 2P(Di ) clauses 2P( j=1
Fj ),
Vi1
Vn
Vn
2P(

F


)
|=

2P(F
).
Thus,

induction,

2P(


)
|=

2P(



j=1 Vj
i=1
i=1 Fi ),
V
n
n

|=
F
.


i=1
i=1

713

fiCimatti, Griggio, & Sebastiani

Input clauses:

Result:

{C1 , . . . , Cn }

sat/unsat

-unsat core:
0 }
{C10 , . . . , Cm

Lazy SMT Solver

-valid clauses:
{D10 , . . . , Dj0 }

Stored -Lemmas:
{D1 , . . . , Dk }
Boolean abstraction:

Refinement:

2P

P2T

Boolean unsatcore:

2P({C1 , . . . , Cn , D1 , . . . , Dk })

0 , 0 , . . . , 0 })
2P({C10 , . . . , Cm
1
j

Boolean Unsat Core Extractor

hSatValue,Clause seti -Unsat Core(Clause set ) {
// {C1 , . . . , Cn }
(Lazy SMT Solver() == sat)
return hsat,i;
// D1 , . . . , Dk -lemmas stored Lazy SMT Solver
p =Boolean Unsat Core Extractor(T 2P({C1 , . . . , Cn , D1 , . . . , Dk }));
0 , 0 , . . . , 0 }));
// p 2P({C10 , . . . , Cm
1
j
0 }i;
return hunsat,{C10 , . . . , Cm
}

Figure 4: Schema -Unsat Core procedure: architecture (above) algorithm (below).

-solver, namely D1 , . . . , Dk . Lazy SMT Solver returns sat, whole procedure
returns sat. Otherwise, Boolean abstraction {C1 , . . . , Cn , D1 , . . . , Dk }, inconsistent (ii), fed external tool Boolean Unsat Core, able
return Boolean unsat core p input. construction, p Boolean ab0 , 0 , . . . , 0 } s.t. {C 0 , . . . , C 0 } {C , . . . , C }
straction clause set {C10 , . . . , Cm
1
n

1
1
j
0
0
0 , 0 , . . . , 0 } {D1 , . . . , Dj } {D1 , . . . , Dk }. p unsatisfiable, {C10 , . . . , Cm
1
j
unsatisfiable. (i), -valid clauses D10 , . . . , Dj0 role -unsatisfiability
0 , 0 , . . . , 0 }, thrown away, procedure returns
{C10 , . . . , Cm
1
j
0 }.
unsat -unsatisfiable core {C10 , . . . , Cm
Notice resulting -unsatisfiable core guaranteed minimal, even
Boolean Unsat Core returns minimal Boolean unsatisfiable cores. fact, might
0 }\{C 0 } -unsatisfiable C 0 even though 2P({C 0 , . . . , C 0 }\
case {C10 , . . . , Cm

1


{Ci0 }) satisfiable, truth assignments p satisfying latter
P2T (p ) -unsatisfiable.
714

fiComputing Small Unsatisfiable Cores Satisfiability Modulo Theories

Example 5 Consider unsatisfiable SMT formula LA(Z):
((x = 0) (x = 1)) ((x = 0) (x = 1)) ((x = 0) (x = 1))
((x = 0) (x = 1))
propositional abstraction 2P():
2P() (B1 B2 ) (B1 B2 ) (B1 B2 ) (B1 B2 ).
Then, 2P() minimal Boolean unsatisfiable core itself, minimal core
LA(Z), since last clause valid theory, hence safely dropped.
procedure implemented simply modifying SMT solver
store -lemmas interfacing state-of-the-art Boolean unsat core
extractor used external black-box device. Moreover, SMT solver provide
set -lemmas output, whole procedure may reduce control device
interfacing SMT solver Boolean core extractor black-box external
devices.
Remark 2 Notice storing -lemmas mean learning them, is,
SMT solver required add -lemmas formula search. Instead, instance sufficient store ad-hoc data structure, even
dump file. causes overhead Boolean search SMT
solver, imposes constraint lazy strategy adopted (e.g., offline/online, permanent/temporary learning, usage mixed Boolean+theory conflict clauses, etc.).
Example 6 again, consider formula (1) Example 1, corresponding formula
(10) Example 4, Boolean abstraction (1) LA(Z)-lemmas (9) found
MathSAT search. Lemma-Lifting approach, (10) given input
external Boolean unsat core device. resulting propositional unsatisfiable core is:
{(B1 B2 A1 ), (B1 B2 A2 ), (B1 B2 A2 ), (A2 B3 ), B5 ,
(B7 A1 ), (B2 B1 ), (B7 B5 ), (B3 B5 )},
corresponds (via P2T ) to:
{((x = 0) (x = 1) A1 ), ((x = 0) (x = 1) A2 ), ((x = 0) (x = 1) A2 ),
(A2 (y = 1)), B5 , ((y = 2) A1 ),
((x = 1) (x = 0)), ((y = 2) (y < 0)), ((y = 1) (y < 0))}.
Since last three clauses included LA(Z)-lemmas, thus LA(Z)-valid,
eliminated. resulting core consists first 6 clauses. case,
core turns minimal, identical modulo reordering computed
MathSAT proof-tracing (see Example 1).
observed end previous section, technique works also SMT tool
learns mixed Boolean+theory clauses (provided original -lemmas stored),
715

fiCimatti, Griggio, & Sebastiani

uses lazy theory deduction Nieuwenhuis et al. (2006). Moreover, works also
-lemmas contain new atoms (i.e. atoms appear ), approaches
Flanagan et al. (2003), Barrett, Nieuwenhuis, Oliveras, Tinelli (2006), since
Facts (ii) (i) hold also case.
side observation, remark technique works also per-constraintencoding eager SMT approach Goel, Sajid, Zhou, Aziz, Singhal (1998), Strichman, Seshia, Bryant (2002). eager SMT approach, input -formula
translated equi-satisfiable Boolean formula, SAT solver used check
satisfiability. per-constraint-encoding Goel et al. (1998) Strichman et al.
(2002), resulting Boolean formula conjunction propositional abstraction p
formula propositional abstraction conjunction
-valid clauses. Therefore, plays role -lemmas lazy approach,
approach still works. idea falls scope work, expanded
further.
4.3 Discussion
Despite simplicity, proposed approach appealing several reasons.
First, extremely simple implement. building unsat cores delegated
external device, fully decoupled internal DPLL-based enumerator.
Therefore, need implementing internal unsat core constructor
modify embedded Boolean device. Every possible external device interfaced
plug-and-play manner simply exchanging couple DIMACS files9 .
Second, approach fully compatible optimizations carried core
extractor Boolean level: every original clause Boolean unsat core device
able drop, also dropped final formula. Notably, involves also Boolean
unsat-core techniques could difficult adapt SMT setting (and
implement within SMT solver), ones based genetic algorithms (Zhang
et al., 2006).
Third, benefits free research propositional unsat-core extraction, since
trivial update: novel, efficient effective Boolean unsat core
device available, used plug-and-play way. require modifying
DPLL engine embedded SMT solver.
One may remark that, principle, number -lemmas generated solver huge, storing -lemmas might cause memory-exhaustion problems
generation Boolean formulas big handled Boolean unsatcore extractor. practice, however, real problem. fact, even hardest
SMT formulas reach current lazy SMT solvers rarely need generating
105 -lemmas, whereas current Boolean unsat core extractors handle formulas
order 106 107 clauses. fact, notice default choice MathSAT learn
-lemmas permanently anyway, never encountered problems due
fact. Intuitively, unlike plain SAT, lazy SMT computational effort typically
dominated search theory , number clauses stored
reasonable amount memory, fed SAT solver, typically much
9. DIMACS standard format representing Boolean CNF formulas.

716

fiComputing Small Unsatisfiable Cores Satisfiability Modulo Theories

bigger number calls -solver overall accomplished within
reasonable amount time.
Like SMT unsat-core techniques adopted current SMT solvers, also
novel approach resulting -unsatisfiable core guaranteed minimal,
even Boolean Unsat Core returns minimal Boolean unsatisfiable cores. However,
Lemma-Lifting technique possible perform reductions done
considering Boolean skeleton formula. Although general
enough guarantee minimality, still significant gain, shall show
next section. Moreover, notice also possible obtain minimal UCs iteratively
calling one SMT core extractor, time dropping one (or more) clause(s) current
UC checking -inconsistency. minimization technique orthogonal wrt.
SMT core-extractor adopted, investigated here.

5. Empirical Evaluation
carried extensive experimental evaluation Lemma-Lifting approach.
implemented approach within MathSAT (Bruttomesso et al., 2008) system.
MathSAT extended interface external Boolean unsatisfiable core extractors (UCE) exchange Boolean formulas relative cores form files DIMACS
format. (No modification needed storage -lemmas, MathSAT
already learn permanently them.)
tried eight different external UCEs, namely Amuse (Oh et al., 2004), PicoSAT
(Biere, 2008), Eureka (Dershowitz et al., 2006), MiniUnsat (van Maaren & Wieringa,
2008), MUP (Huang, 2005), Trimmer (Gershman et al., 2008), ZChaff (Zhang & Malik,
2003), tool proposed Zhang et al. (2006) (called Genetic here).
tools explicitly target core size reduction (or minimality), exception PicoSAT,
conceived speeding core generation, claims minimality. fact,
PicoSAT turned fastest least effective reducing size
cores. reasons, adopted baseline choice, ideal starting point
evaluating trade-off efficiency (in execution time) effectiveness (in core
size reduction). Thus, start evaluating approach using PicoSAT external
UCE (5.1) investigate usage effective though expensive
UCEs ( 5.2).
experiments performed subset SMT-LIB (Ranise & Tinelli,
2006) benchmarks. used total 561 -unsatisfiable problems, taken QF UF
(126), QF IDL (89), QF RDL (91), QF LIA (135) QF LRA (120) divisions, selected
using criteria used annual SMT competition. particular, benchmarks
selected randomly available instances SMT-LIB, giving higher
probability real-world instances, opposed randomly generated handcrafted ones.
(See http://www.smtcomp.org/ additional details.)
used preprocessor convert instances CNF (when required),
cases translate SMT language native language particular
SMT solver. 10
10. particular, CVC3 Yices compute unsatisfiable cores problems given
native format.

717

fiCimatti, Griggio, & Sebastiani

100

100

PicoSAT time

1000

PicoSAT time

1000

10

1

0.1

10

1

0.1
0.1

1

10

100

1000

Total time

0.1

1

10

100

1000

MathSAT time

Figure 5: Overhead PicoSAT wrt. total execution time MathSAT+PicoSAT
(left) wrt. execution time MathSAT (right).

tests performed 2.66 GHz Intel Xeon machines 16 GB RAM
running Linux. tested instance (unless explicitly stated otherwise) timeout
set 600 seconds, memory limit 2 GB. Boolean UCEs,
used default configurations.
5.1 Costs Effectiveness Unsat-Core Extraction Using PicoSAT
two scatter plots Figure 5 give first insight price Lemma-Lifting
approach pay running external UCE. plot left compares
execution time PicoSAT total time MathSAT+PicoSAT, whilst plot
right shows comparison time PicoSAT MathSAT
solving time only. two figures, clearly seen that, except cases,
time required PicoSAT much lower even negligible wrt. MathSAT solving
time. Notice also price payed case unsatisfiable benchmarks.
analyze approach respect size unsat cores returned.
compare baseline implementation approach, MathSAT+PicoSAT,
MathSAT+ProofBasedUC (i.e. MathSAT proof tracing), CVCLite (Barrett &
Tinelli, 2007), 11 Yices. 12 also performed comparison (the SMT version
of) CAMUS (Liffiton & Sakallah, 2008), running SingleMUS mode (generate
one minimal UC, CAMUS-one hereafter). also tried run CAMUS AllMUS
mode (generate minimal UCs), encountered unexpected results (in

11. tried use newer CVC3, difficulties extraction unsatisfiable cores
it. Therefore, reverted older CVCLite experiments.
12. CVCLite version 20061231 Yices version 1.0.19.

718

fiComputing Small Unsatisfiable Cores Satisfiability Modulo Theories

Core/Problem size ratio

MathSAT+PicoSAT

MathSAT+ProofBasedUC

1

1

1/2

1/2

1/5

1/5

1/10

1/10

1/100

1/100

1/1000

1/1000
10

100

1000

10000

100000

10

Core/Problem size ratio

Yices

100

1000

10000

100000

10000

100000

CVCLite

1

1

1/2

1/2

1/5

1/5

1/10

1/10

1/100

1/100

1/1000

1/1000
10

100

1000

10000

100000

10

100

1000

CAMUS-one
1

Core/Problem size ratio

1/2

1/5
1/10

1/100

1/1000
10

100

1000

10000

100000

Size problem (# clauses)

Size problem (# clauses)

Figure 6: Ratio size original formula unsat core computed
various solvers.

719

fiCimatti, Griggio, & Sebastiani

CVCLite w.u.c.

MathSAT+ProofBasedUC

MathSAT+PicoSAT

MathSAT+PicoSAT

3

3

2

2

3/2

3/2

1

1

2/3

2/3

1/2

1/2

1/3

1/3
10

100

1000

10000

100000

10

100

Yices w.u.c.

1000

10000

100000

CAMUS-one

MathSAT+PicoSAT

MathSAT+PicoSAT

3

3

2

2

3/2

3/2

1

1

2/3

2/3

1/2

1/2

1/3

1/3
10

100

1000

10000

core size ratio
CVCLite w.u.c.
MathSAT+PicoSAT
MathSAT+ProofBasedUC
MathSAT+PicoSAT
Yices w.u.c.
MathSAT+PicoSAT
CAMUS-one
MathSAT+PicoSAT

100000

10

100

1000

10000

100000

1st quartile

median

mean

3rd quartile

1.00

1.16

1.33

1.36

1.00

1.03

1.09

1.10

0.97

1.03

1.08

1.09

0.88

1.02

1.32

1.18

Figure 7: Comparison size unsat cores computed MathSAT+PicoSAT
CVCLite, MathSAT+ProofBasedUC, Yices unsat
cores CAMUS-one, statistics unsat core ratios.
Points middle line values greater 1.00 mean better core quality
MathSAT+PicoSAT, vice versa.

executions generated MUSes larger unsat cores found
tools13 ), exclude experiments.
13. surprising because, definition, output produced CAMUS AllMUS mode
always contain UCs minimum size, thus smaller found
tools. Therefore, explanation results, apart conjecturing presence
bug CAMUS, incorrect use side (although followed indications authors),

720

fiComputing Small Unsatisfiable Cores Satisfiability Modulo Theories

order allow CAMUS-one terminate significant amount samples,
run increased timeout 1800 seconds. Even so, CAMUS-one able produce one UC within timeout 144 formulas 561. record, MathSAT+PicoSAT, MathSAT+ProofBasedUC, CVCLite, Yices solved within
timeout 474, 503, 253 494 problems 561 respectively.
Notice present comparison time different tools
significant determining relative cost unsat-core computation, since (i)
former four tools time completely dominated solving time,
varies lot solver solver (even within MathSAT, proof production requires setting
ad-hoc options, may result significantly-different solving times since different
search space explored); (ii) comparison CAMUS terms speed would
fair, since ultimate goal CAMUS enumerate mimimal UCs,
first runs very-expensive step enumerating MCSs (see 3.2).
Figure 6 shows absolute reduction size performed different solvers:
x-axis displays size (number clauses) problem, whilst y-axis displays
ratio size unsat core size problem. instance, point
value 1/10 means unsatisfiability due 10% problem
clauses.
Figure 7(top) shows relative comparisons data Figure 6. plot compares
MathSAT+PicoSAT solvers. plots, shall call
core-ratio plots, following meaning: x-axis displays size (number
clauses) problem, whilst y-axis displays ratio size unsat
core computed CVCLite, MathSAT+ProofBasedUC, Yices CAMUS-one
computed MathSAT+PicoSAT. instance, point value 1/2 means
unsat core computed current solver half size computed
MathSAT+PicoSAT; values 1 mean smaller core MathSAT+PicoSAT.
core-ratio plots, consider instances solvers terminated successfully, since interested size cores computed,
execution times. Figure 7(bottom) reports statistics ratios unsat core sizes
computed two different solvers.
comment order. results reported CAMUS-one quite surprising
wrt. expectations, since CAMUS-one supposed return minimal UC,
would expect greater reductions core sizes. explained fact
minimal UC produced CAMUS-one necessarily minimum. fact,
manually verified samples biggest core-size ratio UCs returned
CAMUS-one actually minimal, although significantly bigger returned
MathSAT+PicoSAT.
Overall, results presented show that, even using Boolean UCE PicoSAT,
least effective reducing size cores, effectiveness baseline
version approach slightly better tools.

activation default incomplete heuristics CAMUS use order cope
combinatorial explosion number MCSs UCs generated (see 3.2.)

721

fiCimatti, Griggio, & Sebastiani

reduction

core size

execution time

wrt. baseline

1
3

1000

1/2

2

Amuse

1/5

100
3/2

1/10

1

1/100

10

2/3
1

1/2

1/3
1/1000

0.1
10

100

1000

10000

100000

10

100

1000

10000

100000

0.1

1

10

100

1000

0.1

1

10

100

1000

0.1

1

10

100

1000

1
3

1000

1/2

2

1/5

100
3/2

Genetic

1/10

1

1/100

10

2/3
1

1/2

1/3
1/1000

0.1
10

100

1000

10000

100000

10

100

1000

10000

100000

1
3

1000

Eureka

1/2

2

1/5

100
3/2

1/10

1

1/100

10

2/3
1

1/2

1/3
1/1000

0.1
10

100

1000

10000

100000

10

100

1000

10000

100000

Figure 8: Comparison core sizes (left), core ratios (middle) run times (right)
using different propositional unsat core extractors. core-ratio plots (2nd
column), X-axis represents size problem, Y-axis represents
ratio size cores computed two systems: point
middle line means better quality baseline system. scatter
plots (3rd column), baseline system (MathSAT+PicoSAT) always
X-axis.

5.2 Impact Costs Effectiveness Using Different Boolean Unsat Core
Extractors
second part experimental evaluation compare results obtained using
different UCEs terms costs effectiveness reducing size core. show
that, depending UCE used, possible reduce significantly size cores,
trade core quality speed execution (and vice versa), implementation
722

fiComputing Small Unsatisfiable Cores Satisfiability Modulo Theories

reduction

core size

execution time

wrt. baseline

1
3

1000

MiniUnsat

1/2

2

1/5

100
3/2

1/10

1

1/100

10

2/3
1

1/2

1/3
1/1000

0.1
10

100

1000

10000

100000

10

100

1000

10000

100000

0.1

1

10

100

1000

0.1

1

10

100

1000

0.1

1

10

100

1000

1
3

1000

Trimmer

1/2

2

1/5

100
3/2

1/10

1

1/100

10

2/3
1

1/2

1/3
1/1000

0.1
10

100

1000

10000

100000

10

100

1000

10000

100000

1
3

1000

ZChaff

1/2

2

1/5

100
3/2

1/10

1

1/100

10

2/3
1

1/2

1/3
1/1000

0.1
10

100

1000

10000

100000

10

100

1000

10000

100000

Figure 9: Comparison core sizes (left), core ratios (middle) run times (right)
using different propositional unsat core extractors (continued).

effort. compare baseline configuration MathSAT+PicoSAT, six
configurations, calling different propositional UCE.
results collected Figures 8-9. first column shows absolute reduction
size performed tool (as Figure 6). second column shows core-ratio plots
comparing configuration baseline one using PicoSAT (as Figure 7,
points 1.00 meaning better performance current configuration). Finally,
scatter plots third column compare execution times (with PicoSAT always
X-axis). evaluated six configurations use, respectively, Amuse (Oh et al.,
2004), Genetic (Zhang et al., 2006), Eureka (Dershowitz et al., 2006), MiniUnsat (van
Maaren & Wieringa, 2008), Trimmer (Gershman et al., 2008), ZChaff (Zhang &
Malik, 2003), baseline configuration, using PicoSAT. also compared
MUP (Huang, 2005), stop experiments memory exhaustion
723

fiCimatti, Griggio, & Sebastiani

CVCLite w.u.c.

MathSAT+ProofBasedUC

MathSAT+Eureka

MathSAT+Eureka

3

3

2

2

3/2

3/2

1

1

2/3

2/3

1/2

1/2

1/3

1/3
10

100

1000

10000

100000

10

Yices w.u.c.

100

1000

10000

100000

CAMUS-one

MathSAT+Eureka

MathSAT+Eureka

3

3

2

2

3/2

3/2

1

1

2/3

2/3

1/2

1/2

1/3

1/3
10

100

1000

10000

core size ratio
CVCLite w.u.c.
MathSAT+Eureka
MathSAT+ProofBasedUC
MathSAT+Eureka
Yices w.u.c.
MathSAT+Eureka
CAMUS-one
MathSAT+Eureka

100000

10

100

1000

10000

100000

1st quartile

median

mean

3rd quartile

1.03

1.32

1.55

1.73

1.03

1.17

1.27

1.35

1.00

1.16

1.28

1.34

0.98

1.05

1.41

1.26

Figure 10: Ratios unsat-core sizes computed MathSAT+Eureka
CVCLite, MathSAT+ProofBasedUC, Yices CAMUS-one.
Points middle line values greater 1.00 mean better core
quality MathSAT+Eureka, vice versa.

problems. Looking second column, notice Eureka, followed MiniUnsat
ZChaff, seems effective reducing size final unsat cores,
1/3 size obtained plain PicoSAT. Looking third column,
notice Genetic, Amuse, MiniUnsat ZChaff, part Eureka,
efficiency degrades drastically, many problems cannot solved within timeout.
Trimmer performance gap dramatic, still order magnitude
slower baseline version.
724

fiComputing Small Unsatisfiable Cores Satisfiability Modulo Theories

Finally, Figure 10 compare effectiveness MathSAT+Eureka,
effective extractor Figures 8-9, directly three solvers, CVCLite,
MathSAT+ProofBasedUC Yices, CAMUS. (Also compare
results Figure 7.) gain core reduction wrt. previous state-of-the-art
SMT core-reduction techniques evident.
important notice that, due limited know-how, used Boolean UCEs
default configurations. Therefore, believe even better results, terms
effectiveness efficiency, could obtained means accurate tuning
parameters core extractors.
side remark, notice results Figures 8-9 produced byproduct
insightful evaluation main Boolean unsat-core-generation tools currently available.
extent, notice performances MUP (Huang, 2005) Genetic (Zhang
et al., 2006) seem rather poor; PicoSAT (Biere, 2008) definitely fastest tool, though
least effective reducing size final core; opposite side, Eureka
(Dershowitz et al., 2006) effective task, pays fee terms CPU
time; Trimmer (Gershman et al., 2008) represents good compromise effectiveness
efficiency.

6. Conclusions
presented novel approach generating small unsatisfiable cores SMT,
computes posteriori, relying external propositional unsat core extractor.
technique simple concept, straightforward implement update. Moreover, benefits free advancements propositional unsat core computation.
experimental results shown that, using different core extractors, possible
reduce significantly size cores trade core quality speed execution (and
vice versa), implementation effort.
byproduct, also produced insightful evaluation main Boolean
unsat-core-generation tools currently available.

Acknowledgments
wish thank Mark Liffiton help CAMUS tool. also thank
anonymous referees helpful suggestions.
A. Griggio supported part European Communitys FP7/2007-2013 grant
agreement Marie Curie FP7 - PCOFUND-GA-2008-226070 progetto Trentino, project
Adaptation.
R. Sebastiani supported part SRC GRC Custom Research Project 2009-TJ1880 WOLFLING.

References
Asn, R., Nieuwenhuis, R., Oliveras, A., & Rodrguez Carbonell, E. (2008). Efficient Generation Unsatisfiability Proofs Cores SAT. Cervesato, I., Veith, H., &
Voronkov, A. (Eds.), Proceedings LPAR08, Vol. 5330 LNCS, pp. 1630. Springer.
725

fiCimatti, Griggio, & Sebastiani

Audemard, G., Bertoli, P., Cimatti, A., Kornilowicz, A., & Sebastiani, R. (2002). SAT
Based Approach Solving Formulas Boolean Linear Mathematical Propositions. Proc. CADE2002., Vol. 2392 LNAI. Springer.
Barrett, C., Nieuwenhuis, R., Oliveras, A., & Tinelli, C. (2006). Splitting Demand
SAT Modulo Theories.. Hermann, M., & Voronkov, A. (Eds.), LPAR, Vol. 4246
LNCS, pp. 512526. Springer.
Barrett, C., & Tinelli, C. (2007). CVC3. Damm, W., & Hermanns, H. (Eds.), CAV, Vol.
4590 LNCS, pp. 298302. Springer.
Barrett, C. W., Dill, D. L., & Stump, A. (2002). Checking Satisfiability First-Order
Formulas Incremental Translation SAT. Brinksma, E., & Larsen, K. G. (Eds.),
Computer Aided Verification, 14th International Conference, CAV 2002, Copenhagen,
Denmark, July 27-31, 2002, Proceedings, Vol. 2404 LNCS, pp. 236249. Springer.
Barrett, C. W., Sebastiani, R., Seshia, S. A., & Tinelli, C. (2009). Satisfiability modulo
theories. Biere, A., Heule, M., & van Maaren, H. (Eds.), Handbook Satisfiability.
IOS Press.
Biere, A. (2008). Picosat essentials. Journal Satisfiability, Boolean Modeling Computation (JSAT), 4, 7597.
Bruttomesso, R., Cimatti, A., Franzen, A., Griggio, A., & Sebastiani, R. (2008).
MathSAT 4 SMT Solver. Gupta, A., & Malik, S. (Eds.), CAV, Vol. 5123 LNCS,
pp. 299303. Springer.
Bryant, R. E., Kroening, D., Ouaknine, J., Seshia, S. A., Strichman, O., & Brady, B. (2009).
abstraction-based decision procedure bit-vector arithmetic. Int. J. Softw. Tools
Technol. Transf., 11 (2), 95104.
Cimatti, A., Griggio, A., & Sebastiani, R. (2007). Simple Flexible Way Computing
Small Unsatisfiable Cores SAT Modulo Theories.. Marques-Silva, J., & Sakallah,
K. A. (Eds.), SAT, Vol. 4501 LNCS, pp. 334339. Springer.
Davis, M., & Putnam, H. (1960). computing procedure quantification theory. Journal
ACM, 7, 201215.
Davis, M., Logemann, G., & Loveland, D. W. (1962). machine program theoremproving.. Commun. ACM, 5 (7), 394397.
de Moura, L., & Bjrner, N. (2008). Z3: Efficient SMT Solver. Ramakrishnan, C. R.,
& Rehof, J. (Eds.), TACAS, Vol. 4963 LNCS, pp. 337340. Springer.
Dershowitz, N., Hanna, Z., & Nadel, A. (2006). Scalable Algorithm Minimal Unsatisfiable Core Extraction.. Proceedings SAT06, Vol. 4121 LNCS. Springer.
Dutertre, B., & de Moura, L. (2006). Fast Linear-Arithmetic Solver DPLL(T).
Proc. CAV06, Vol. 4144 LNCS. Springer.
Enderton, H. (1972). Mathematical Introduction Logic. Academic Pr.
Flanagan, C., Joshi, R., Ou, X., & Saxe, J. B. (2003). Theorem Proving Using Lazy Proof
Explication.. Jr., W. A. H., & Somenzi, F. (Eds.), CAV, Vol. 2725 LNCS, pp.
355367. Springer.
726

fiComputing Small Unsatisfiable Cores Satisfiability Modulo Theories

Gershman, R., Koifman, M., & Strichman, O. (2008). approach extracting small
unsatisfiable core. Formal Methods System Design, 33 (1-3), 127.
Goel, A., Sajid, K., Zhou, H., Aziz, A., & Singhal, V. (1998). BDD Based Procedures
Theory Equality Uninterpreted Functions.. Hu, A. J., & Vardi, M. Y.
(Eds.), CAV, Vol. 1427 LNCS, pp. 244255. Springer.
Goldberg, E. I., & Novikov, Y. (2003). Verification Proofs Unsatisfiability CNF
Formulas. Proceedings 2003 Design, Automation Test Europe Conference
Exposition (DATE 2003), pp. 886891. IEEE Computer Society.
Grumberg, O., Lerda, F., Strichman, O., & Theobald, M. (2005).
Proof-guided
underapproximation-widening multi-process systems. SIGPLAN Not., 40 (1), 122
131.
Huang, J. (2005). MUP: minimal unsatisfiability prover. Proceedings ASP-DAC 05.
ACM Press.
Liffiton, M., & Sakallah, K. (2008). Algortithms Computing Minimal Unsatisfiable
Subsets Constraints. Journal Automated Reasoning, 40 (1).
Lynce, I., & Marques-Silva, J. P. (2004). Computing Minimum Unsatisfiable Cores.
SAT 2004 - Seventh International Conference Theory Applications
Satisfiability Testing, 10-13 May 2004, Vancouver, BC, Canada, Online Proceedings.
Marques-Silva, J. P., & Sakallah, K. A. (1996). GRASP - new Search Algorithm
Satisfiability. Proc. ICCAD96.
McMillan, K. L. (2002). Applying SAT Methods Unbounded Symbolic Model Checking.
Brinksma, E., & Larsen, K. G. (Eds.), Proceedings CAV02, Vol. 2404 LNCS,
pp. 250264. Springer.
McMillan, K. L., & Amla, N. (2003). Automatic abstraction without counterexamples.
Garavel, H., & Hatcliff, J. (Eds.), Proceedings TACAS03, Vol. 2619 LNCS, pp.
217. Springer.
Mneimneh, M. N., Lynce, I., Andraus, Z. S., Marques-Silva, J. P., & Sakallah, K. A. (2005).
Branch-and-Bound Algorithm Extracting Smallest Minimal Unsatisfiable Formulas.. Proc. SAT05, Vol. 3569 LNCS. Springer.
Nadel, A. (2010). Boosting Minimal Unsatisfiable Core Extraction. Bloem, R., & Sharygina, N. (Eds.), Proceedings 10th International Conference Formal Methods
Computer-Aided Design (FMCAD2010), pp. 221229.
Nieuwenhuis, R., Oliveras, A., & Tinelli, C. (2006). Solving SAT SAT Modulo Theories:
abstract DavisPutnamLogemannLoveland procedure DPLL(T). J.
ACM, 53 (6), 937977.
Oh, Y., Mneimneh, M. N., Andraus, Z. S., Sakallah, K. A., & Markov, I. L. (2004).
Amuse: Minimally-Unsatisfiable Subformula Extractor. Proceedings DAC04.
ACM/IEEE.
Ranise, S., & Tinelli, C. (2006). Satisfiability Modulo Theories Library (SMT-LIB).
www.SMT-LIB.org.
727

fiCimatti, Griggio, & Sebastiani

Sebastiani, R. (2007). Lazy Satisfiability Modulo Theories. Journal Satisfiability, Boolean
Modeling Computation, JSAT, Volume 3.
Strichman, O., Seshia, S. A., & Bryant, R. E. (2002). Deciding Separation Formulas
SAT. Brinksma, E., & Larsen, K. G. (Eds.), CAV, Vol. 2404 LNCS, pp. 209222.
Springer.
Suelflow, A., Fey, G., Bloem, R., & Drechsler, R. (2008). Using unsatisfiable cores debug
multiple design errors. Proceedings GLSVLSI08, pp. 7782, New York, NY,
USA. ACM.
Tseitin, G. S. (1983). complexity derivation propositional calculus. Automation
Reasoning: Classical Papers Computational Logic 1967-1970Studies Constructive Mathematics Mathematical Logic, Part 2, 2. Originally published 1970.
van Maaren, H., & Wieringa, S. (2008). Finding Guaranteed MUSes Fast. SAT, Vol.
4996 LNCS, pp. 291304. Springer.
Wang, C., Kim, H., & Gupta, A. (2007). Hybrid CEGAR: combining variable hiding
predicate abstraction. Proceedings ICCAD07, pp. 310317, Piscataway, NJ,
USA. IEEE Press.
Zhang, J., Li, S., & Shen, S. (2006). Extracting Minimum Unsatisfiable Cores Greedy
Genetic Algorithm.. Proceedings ACAI, Vol. 4304 LNCS. Springer.
Zhang, L., Madigan, C. F., Moskewicz, M. H., & Malik, S. (2001). Efficient conflict driven
learning boolean satisfiability solver. Proceedings ICCAD 01. IEEE Press.
Zhang, L., & Malik, S. (2002). quest efficient boolean satisfiability solvers..
Voronkov, A. (Ed.), CADE, Vol. 2392 LNCS, pp. 295313. Springer.
Zhang, L., & Malik, S. (2003). Extracting Small Unsatisfiable Cores Unsatisfiable
Boolean Formulas. Proceedings 6th International Conference Theory
Applications Satisfiability Testing (SAT2003).

728

fiJournal Articial Intelligence Research 40 (2011) 599-656

Submitted 11/10; published 03/11

Decidability Undecidability Results
Propositional Schemata
Vincent Aravantinos
Ricardo Caferra
Nicolas Peltier

Vincent.Aravantinos@imag.fr
Ricardo.Caferra@imag.fr
Nicolas.Peltier@imag.fr

Universite de Grenoble (LIG/CNRS)
Bat. IMAG C, 220, rue de la Chimie
38400 Saint Martin dHeres, France

Abstract
dene logic propositional formula schemata adding
syntax
propositional logic indexed propositions (e.g., pi ) iteratedconnectives

ranging
n
intervals parameterized arithmetic variables (e.g., i=1 pi , n parameter ).
satisability problem shown undecidable new logic, introduce
general class schemata, called bound-linear, problem becomes decidable. result obtained reduction particular class schemata called regular,
provide sound complete terminating proof procedure. schemata
calculus (called stab) allows one capture proof patterns corresponding large class
problems specied propositional logic. also show satisability problem becomes undecidable slight extensions class, thus demonstrating
bound-linear schemata represent good compromise expressivity decidability.

1. Introduction
able solve classes problems possibly eciently elegantly strongly depends
language specied. decisive lot applications
Articial Intelligence. One language long used humans schemata.
general characterizations notion schema would useless, focused
particular class schemata arising naturally practice, quite expressive (as
shown) good computational properties. schemata generated
unbounded repetitions patterns, call iterated schemata.
motivate approach via example, frequently used well-known
AI community: circuit verication. Circuit verication problems often modeled
sequences propositional problems parameterized natural number n encodes
size data (e.g., number bits, number layers circuit, etc.). call
sequences iterated schemata, simply schemata. typical example n-bit sequential
adder circuit i.e. circuit computes sum two bit-vectors length n.
circuit built composing n 1-bit adders. ith bits operand written pi
qi . ri ith bit result ci+1 carried next bit (thus c1 = 0).
set notations ( denotes exclusive or):
Sumi (p, q, c, r) = ri (pi qi ) ci
def

c
2011
AI Access Foundation. rights reserved.

fiAravantinos, Caferra & Peltier


Carryi (p, q, c) = ci+1 (pi qi ) (ci pi ) (ci qi ).
def

formula:
def

Adder(p, q, c, r) =

n


Sumi (p, q, c, r)

i=1

n


Carryi (p, q, c) c1

i=1

constraint n 1, schematises adder circuit (it states r encodes sum
p q). Adder contains iterations ranging intervals depending n. n instantiated
natural number expression reduces propositional formula. Therefore
instance schema solved propositional logic. However, proving
schema unsatisable (or satisable) every instance n much harder.
problem cannot specied propositional logic and, shall see, even
scope rst-order logic. expressed higher order logics well-known
languages less suitable automation (see Section 3 details).
iteration schemata ubiquitous formalized reasoning. Problems nite
domains specied generic propositional formulae tting pattern,
parameter (nite unbounded) size domain. Among patterns,
corresponding pigeonhole principle, Ramsey theory, coloring graphs problems
constraint programming specications n-queens problem (Marriott, Nethercote,
Rafeh, Stuckey, Garca de la Banda, & Wallace, 2008) mentioned. Iterated
schemata also extremely useful formalization mathematical proofs,
allow one express innite proof sequences, avoid, instance, explicit
use induction principle. idea used, e.g., work Hetzl, Leitsch,
Weller, Woltzenlogel Paleo (2008).
paper present rst (to best knowledge) thorough analysis
propositional iterated schemata. dene logic handling arithmetic variables, indexed
propositions iterated connectives. satisability problem obviously semi-decidable
sense (straightforward) algorithm exists enumerate satisable schemata
(i.e. schemata satisable instance). However set (unrestricted) unsatisable
schemata recursively enumerable. Thus restrict particular class
schemata, called bound-linear provide decision procedure class.
procedure based reduction simple class schemata, called regular,
tableaux-based proof procedure presented. provide undecidability
results (rather natural) extensions class.
rest paper structured follows.
Section 2 introduce logic (syntax semantics) handling propositional
schemata establish basic properties. propositional symbols
indexed arithmetic expressions (e.g., pn+1 ) containing arithmetic variables.
variables either parameters (i.e.free variables),
bound variables introduced

generalized connectives form bi=a bi=a . connectives read
[a, b] [a, b], a, b arithmetic expressions possibly containing (free
bound) variables. restrict monadic schemata (i.e. propositions
600

fiDecidability Undecidability Results Propositional Schemata

indexed one expression) linear arithmetic expressions1 .
introduce particular subclass schemata, called bound-linear. Intuitively, schema
bound-linear every arithmetic expression occurring contains one
bound variable. Furthermore, coecient variable expression
1 (or 0). Thus expressions 1, n, 2n + 2 allowed (where n
parameter bound variable), 2i + j (where i, j bound)
not. coecient parameter n constrained.
Section 3 contains brief survey existing work propositional schemata well
(informal) comparisons related logics.
Section 4 introduce simpler class schemata, called regular, provide
algorithm transform every bound-linear schema (sat-)equivalent regular
schema.
Section 5 tableaux-based proof procedure, called stab (standing schemata
tableaux), introduced reasoning propositional schemata. proof procedure sound complete (w.r.t. satisability) terminates every regular
schema. Together results Section 4 implies class boundlinear schemata decidable.
Section 6 shows relaxing slightly conditions bound-linear schemata
makes satisability problem undecidable. Thus class seen canonical, good trade-o expressivity, simplicity denition
decidability.
Finally, Section 7 summarizes results provides lines future work.

2. Schemata Propositional Formulae
section, introduce syntax semantics propositional schemata.
2.1 Syntax
set linear arithmetic expressions (denoted N ) built usual signature
0, s, +, xed countably innite set arithmetic variables V, quotiented
usual properties arithmetic symbols (e.g., n + s(0) + n + s(s(s(0)))
n + n + s(s(s(s(0)))) assumed equivalent). usual, (0) denoted
+ . . . + ( times) .i. n arithmetic variable denote Nn set
arithmetic expressions form .n + , Z (with possibly = 0)
Nn set expressions form n + Z. Obviously Nn Nn N .
n + , n + Nn write n + n + .
1. one two conditions hold satisability problem trivially undecidable.
instance, Post correspondence problem easily encoded schemata non monadic
variables (Aravantinos, Caferra, & Peltier, 2009b). Similarly, non linear arithmetic expressions
considered 10th Hilberts problem encoded.

601

fiAravantinos, Caferra & Peltier

sake readability, adopt following conventions. Integers denoted
Greek letters , , , 2 , natural numbers , arithmetic variables i, j, k, n,
propositional variables p, q, r (with indices). Arithmetic expressions denoted

a,
b,
c,
d.
Schemata

denoted

,
.



denote
generic
iteration
connectives


.
Definition 2.1 (Indexed propositions)
Let P xed countably innite set propositional symbols. indexed proposition
expression form pa p P linear arithmetic expression (the
index ). indexed proposition pa s.t. Z called propositional variable. literal
indexed proposition negation.
contrast previous work (Aravantinos et al., 2009b) consider monadic
propositions, i.e. every proposition one index.
Definition 2.2 (Schemata)
set formula schemata smallest set satisfying following properties.
, formula schemata.
a, b integer expressions < b formula schema.
indexed proposition formula schema.
1 , 2 schemata 1 2 , 1 2 1 formula schemata.
formula
b containing <, a, b N , arithmetic
b schema
variable, i=a i=a formula schemata.
Notice that, denition, every schema mustbe nite. Schemata
form < b, pa

, called atoms. Schemata form bi=a bi=a called iterations,
b bounds iteration b length (notice b may contain
variables). schema arithmetic formula contains iteration every atom
occurring form , < b. particular, every boolean combination
arithmetic atoms schema. b (or b a) = b used abbreviations
(b < a) (b < a) (a < b) respectively. arithmetic expressions, arithmetic
formulae taken arithmetic equivalence, e.g., n = 1 n < 2n > 0 considered
identical. usual priority rules apply disambiguate reading formula schemata.
Analogously
rst-order logic quantiers,
n iteration operators highest priority
n
(e.g., i=1 pi pn p1 read ( i=1 pi ) (pn p1 )).
Example 2.3

= q1

n

i=1


pi+2n



2n+1


(qnj qj+1 ) n 0

formula schema.

j=n

)
n (
2n+1
q1 , pi , qj qj+1 indexed propositions.
p

(q

q
)

i+2n
nj
j+1
i=1
j=n
2n+1
j=n (qnj qj+1 ) iterations occurring S.
2. slightly unusual convention used avoid confusion arithmetic variables integers.

602

fiDecidability Undecidability Results Propositional Schemata

Remark 2.4
Notice
narithmetic atoms forman < b occur
noutside iterations,
i.e. n 1 i=1 pi allowed, neither i=1 (i 3 pi ) i=1 (n 1 pi ).
restriction used simplify technicalities. shall see Denition 2.5
(semantics
schemata), arithmetic atom form < b equivalent schema bi=a+1 .


variable bound contains iteration form bi=a ( { , }),
free (or parameter ) occurrence scope
iteration bi=a . on, assume thatno variable simultaneously free
bound schema (thus schematasuch
pn 10
n=1 pn well-formed)

b


i=a j=c (where , { , }) two distinct iterations occurring
j distinct.
substitution function mapping every arithmetic variable linear arithmetic
expression. write [a1 /i1 , . . . , /i ] substitution mapping respectively i1 , . . . ,
a1 , . . . , . application substitution schema (or arithmetic expression)
dened usual denoted . Notice arithmetic expression
substitution mapping every variable ground term (i.e. term variable)
integer (since identify, e.g., 2 1 1).
previous notation also used denote replacement subexpressions:
schema, expression (schema arithmetic expression) occurring
expression type , [ /] denotes formula obtained replacing
occurrences .

2.2 Semantics
interpretation schemata language function mapping every integer variable
integer every propositional variable truth value F. interpretation
substitution, denote interpretation dened follows:
def
coincide every propositional variable every variable n, I(n) = I(n). Consider
instance following interpretation I:

n 7 5
7 2
p1 7
p2 7 F
p3 7 F
p4 7 F
603

fiAravantinos, Caferra & Peltier

whose denition unsignicant (integer propositional) variables. Let also
substitution {n 7 n 1, 7 2}. is:
n 7 4
7 0
p1 7
p2 7 F
p3 7 F
p4 7 F
interpretation, denote restriction V, i.e. substitution
mapping every variable n I(n). arithmetic expression, denote JaKI
expression aI . Since aI ground, (equivalent to) integer.
Definition 2.5 (Semantics)
truth value JKI propositional schema interpretation inductively dened
as:
JKI = T, JKI = F
Ja < bKI = JaKI < JbKI .
Jpa KI = I(pJaKI ) p P.
JKI = JKI = F.
J KI = JKI = J KI = T.
J KI = JKI = J KI = T.

J bi=a KI = integer s.t. JaKI JbKI JKI[/i] = T.
J

b

i=a KI

= every integer s.t. JaKI JbKI : JKI[/i] = T.

schema satisable interpretation s.t. JKI = T. called model
(written |= ). Two schemata , equivalent (written ) |= |= .
sat-equivalent (written ) satisable
unsatisable.
following, assume every free variable n every model
, I(n) N. ensured explicitly adding arithmetic atom n 0 3 .
Let following system rewrite rules:
3. Thus assume parameters mapped natural numbers. convention convenient
allows one use mathematical induction parameters (see Section 5.2). restrictive since
schema n Z could replaced (equivalent) disjunction schemata n 0
[m/n] 0 (i.e. case n negative, every occurrence n simply replaced
m).

604

fiDecidability Undecidability Results Propositional Schemata




i=



i=
S=


i=


i=









( 1
i= ) [/i]
1
( i= ) [/i]






,
,
,
,

Z,
Z,
Z,
Z,

<
<



instance following formula:
p1

3


(pi pi+1 )

i=1

rewritten into:
p1 (p1 p2 ) (p2 p3 ) (p3 p4 )

Notice rule applies p1 ni=1 (pi pi+1 ) upper bound iteration
contains parameter. actually designed used schemas whose parameters
instantiated number.
Proposition 2.6
convergent preserves equivalence.
Proof
Termination immediate since length iteration strictly decreases step.
Conuence obvious since critical pairs trivially joinable. fact obtained
schema equivalent original one straightforward consequence Denition 2.5.
denote (unique) normal form . substitution mapping every
free variable natural number, called propositional realization .
trivially semi-decidable know schema satisable:
Proposition 2.7
set satisable schemata recursively enumerable.
Proof
Denition 2.5, every interpretation every schema , (I |= )
(I |= ), = . Thus satisable exists substitution
satisable. prove exists algorithm checking satisability
. Proposition 2.6, . denition , contains free
variable. Let bi=a outermost iteration . denition b must ground,
thus one rules applies impossible. Thus contains iteration
hence propositional formula (in usual sense) built set propositional
variables. Consequently, exists algorithm check whether formula
satisable not. Since set ground substitutions recursively enumerable,
since satisable satisable least one substitution , implies
semi-decidable check whether satisable not.

605

fiAravantinos, Caferra & Peltier

every schema every substitution denote [] formula .
every arithmetic expression (possibly containing bound variables) schema ,
compute interval [min (a), max (a)] min (a), max (a) arithmetic expressions containing variables free . intuition always belongs
interval. Lemma 2.8 formalizes property.
integer variable free min (a) = max (a) = a.
def

def

form b + c min (a) = min (b) + min (c) max (a) = max (b) +
max (c).
def

def

form b max (a) = min (b) min (a) = max (b).
def

def

bound variable, occurring iteration form bi=a min (i) =
def
min (a) max (i) = max (b).

def

ground substitution -expansion another ground substitution subschema every variable bound , (i) [(min (i)), (max (i))]
(since , ground, expressions (i), (min (i)), (max (i)) considered integers). intuition behind -expansions following: substitution aect
bound variables schema; values given bound variables
unsignicant; contrary, denition -expansion imposes that:
1. value given variable bound indeed falls set values
take context ;
2. value given variable free one given .
W.r.t. substitution application, dierence . next lemma
shows importance -expansions.
Lemma 2.8
Let schema let variable (possibly bound) occurring . expressions
min (i) max (i) well-dened. Moreover, every ground substitution
atoms p occurring [] exist atom pa occurring -expansion
pa s.t. (a) = .
Proof
immediate consequence Denition 2.5 (by straightforward induction
depth schema).

write IC () (standing Interval Constraints) conjunction arithmetic
constraints form min (i) max (i) variable bound .
IC () extended sets
schemata handling conjunctions.
Consider, e.g., = p0 n1
i=1 (pi+1 qi ). have: min (i) = 1 max (i) = n 1.
Consider furthermore = {n 7 4} p = p3 . take pa = pi+1 (which indeed
occurs ) = {n 7 4, 7 2}.
see informally use -expansions: allow, sense, make
connection propositional variable occurring instance schema
indexed proposition comes from.
606

fiDecidability Undecidability Results Propositional Schemata

2.3 Class Bound-Linear Schemata
shall see (in, e.g., Theorem 6.2) satisability problem undecidable schemata.
order characterize decidable subclass, introduce following denition:
Definition 2.9
schema bound-linear following conditions hold:
1. contains one free arithmetic variable n (called parameter ).
2. Every non arithmetic atom form p.n+.i+ p P bound
variable, , Z {1, 0, 1}.

3. bi=a iteration (where { , }) a, b respectively form
.n + .n + + .j , , , Z, {1, 0, 1} j bound variable.
class comprehensive enough respect decidable satisability. key
point indices iteration bounds contain one bound variable.
Furthermore, coecient variable must 1 (or 0).
2.4 Expressiveness Bound-Linear Schemata
order show evidence class bound-linear schemata articial
narrow one, provide section examples problems naturally
encoded bound-linear schemata.
easy check schema Adder(p, q, c, r) dened Introduction (formalizing sequential adder) bound-linear. Various properties circuit encoded.
instance, following schema checks 0 (left) neutral element:
(Adder(p, q, c, r)

n


n


pi )

i=1

(ri qi )

i=1

schema checks adder function i.e. sum two operands
unique.
n

(Adder(p, q, c, r) Adder(p, q, c , r ))
(ri ri )
i=1

next one checks commutative:
(Adder(p, q, c, r) Adder(q, p, c , r ))

n


(ri ri )

i=1

Many similar circuits formalized similar way, carry look-ahead
adder (a faster version n-bit adder reduces amount time required
compute carry bits):

def

CLA-Adder(p, q, c) =

n


(ri ((pi qi ) ci ))

i=1

n


(ci+1 (pi qi ) (ci (pi qi )))

i=1

607

fiAravantinos, Caferra & Peltier

equivalence two denitions encoded follows:




(Adder(p, q, c, r) CLA-Adder(p, q, c , r ))

n


(ri ri )

i=1

Comparison two natural numbers easily formalized, e.g. rn holds p q:
r0

n


(ri (ri1 (pi qi ) pi qi ))

i=1

composing previous schemata, (quantier-free) formula Presburger arithmetic
encoded.
generally, one formalize every circuit composed serially putting together n
layers basic circuit. circuits usually dened inductively,
easily encoded formalism formula form:
(p0 base )

n1


(pi+1 ind ),

i=0

base ind formulae corresponding base case inductive case,
respectively. ind contains occurrences pi encodes basic circuit
composed sequence. course, complex circuits, pi may replaced vector
bits pi , qi , ri dened inductively pi1 , qi1 , ri1 ,. . . . inductively-dened
circuits appear frequently practice (Gupta & Fisher, 1993).
index proposition denotes time, various nite state sequential
systems encoded. state system described set propositional
variables, pi encodes value p step i. parameter n denotes number
steps transformation (which assumed nite unbounded). transition
function state + 1 easily formalized bound-linear schema.
instance, inclusion two automata encoded (the parameter length
run). provide another example. Consider register three cells p, q, r
assume two possible actions rl rr rotate values cells
left right respectively. behavior system modeled following
schema (the propositions rli rri indicate action applied step i). First L(i)
expresses state registers time depending state time 1,
rli applied it:
L(i) rli ((pi qi1 ) (qi ri1 ) (ri pi1 ))
R(i) similar rr:
R(i) rri ((pi ri1 ) (qi pi1 ) (ri qi1 ))
Finally, state holds time:
n

n


L(i)

i=1

n

i=1

608

R(i)

fiDecidability Undecidability Results Propositional Schemata

express properties registers. instance, following formula states
n rotations right followed n rotations left equivalent identity:
(2n

n

i=1

rri

2n


rli ) (p0 p2n ) (q0 q2n ) (r0 r2n )

i=n+1

3. Related Work
Dierent forms schemata used several authors, either propositional logic
(Baaz & Zach, 1994) rst-order logic obtain results proof theory, particular related number proof lines (Parikh, 1973; Baaz, 1999; Krajicek & Pudlak,
1988; Orevkov, 1991). Parikh (1973) presents notion schematic systems, Baaz (1999)
uses concept unication, Krajicek Pudlak (1988) introduce notion proof
skeleton, similar schema, Orevkov (1991) studies schemata rst-order
Hilbert-type system. Pragmatically, schemata successfully used, e.g., solving
open questions equivalential calculus (i.e. eld formal logic concerned
notion equivalence) theorem-prover Otter (Wos, Overbeek, Lush, & Boyle,
1992). However, best knowledge, formal handling schemata
object level never considered. Although notion schema recognized
important one, deserves applied works opinion. Sometimes schemata
suciently emphasized, e.g., work Barendregt Wiedijk (2005) nice
deep analysis challenge computer mathematics given. authors overview
state art (by describing comparing powerful existing systems use)
structuring proofs explicitly mentioned (maybe feature included
call mathematical style support reasoning gaps). approach
schemata clear way structuring proofs also help overcome
one obstacles automation reasoning pointed Wos (1988), i.e. size
deduction steps.
exist term languages expressive enough denote iteration schemata
introduced Denition 2.2: particular, term schematisation languages used
denote innite sequences structurally similar terms formulae. instance



primal grammar
n (Hermann & Galbavy, 1997) f (n) (p(n) f (n 1)), f (0) denotes
iteration i=1 pi . worth mentioning iteration cannot denoted
term schematisation languages (Chen, Hsiang, & Kong, 1990; Comon, 1995)
inductive context constant. However, term schematisation languages allow
reason iterations (they useful represent them).
Encoding schemata first-order logic natural idea, interpreting iterated
connectives bounded quantiers. Additional axioms
beadded express arithmetic

properties needed. instance schema ( ni=1 pi ) ( ni=1 pi ) encoded
i.(1 n p(i)) i.(1 n p(i)) obviously unsatisable.
However, since inductive domains cannot dened rst-order logic, translation
necessarily introduces unintended interpretations hence yield complete
procedure (satisability always preserved, although unsatisability obtained
formula
necessarily entails unsatisability original one). instance, schema
p0 ni=1 (pi1 pi )pn translated p(0)i.(1 ii np(i1) p(i)p(n)),
609

fiAravantinos, Caferra & Peltier

actually satisable (we know n N way express
property). order obtain unsatisable formula, inductive axioms must
added allow (necessarily restricted) applications induction principle.
particular case, proof obtained simple induction using inductive
lemma i.(i n p(i)), thus could add axiom: [q(0)i.(q(i) q(i+1))] i.q(i)
q(i) n p(i). axiom, easy check previous formula
becomes unsatisable. However, general case hard determine priori right
axiom (if one). Actually termination proof Section 5 implicitly provides way
determine candidate axioms (for particular class regular schemata): every looping
node tableaux constructed proof procedure stab (see Section 5) corresponds
application induction principle, hence induction axiom. termination
proof precisely shows size inductive lemmata bounded, thus whole
set potential induction axioms could principle computed added formula
beginning search. practical interest transformation
obviously highly questionable.
Several procedures designed proving inductive theorems, (Boyer &
Moore, 1979; Bouhoula, Kounalis, & Rusinowitch, 1992; Comon, 2001; Bundy, van Harmelen, Horn, & Smaill, 1990; Bundy, 2001). Since schemata seen explicit way
handling mathematical induction, using proof procedures proving
natural idea. general, induction used dene terms (e.g., recursive functions operating inductive data structures), whereas case formulae dened
inductively. Obviously problem could solved using appropriate encoding
formulae. However decidability results inductive theorem proving
known classes (Giesl & Kapur, 2001) expressive enough encode propositional
schemata. Notice systems concentrate universal quantications,
handle iterated conjunctions (which interpreted universal quantication
nite domain) iterated disjunctions (i.e. analogous existential quantications). Adding existential quantication inductive theorem proving known
dicult problem. inductive theorem provers designed prove universal theorems
form x. quantier-free formula (usually clause) variables
x range set (nite) terms. context, would contain nite quantication
(over intervals constrained n), corresponding iterated connectives. particular,
schemata may several models, thus implicit induction (Comon, 2001) (which explicitly
requires underlying Herbrand model unique) cannot (directly) used.
course, problems overcome encoding interpretations terms (for
instance vectors ordered lists truth values) schemata functions mapping
every interpretation truth value. inductive theorem provers may used prove
inductive properties functions (showing instance value every
interpretation). However provers complete (due well-known theoretical
limitations) thus practical interest encoding unclear. instance,
tried use theorem prover acl2 prove validity benchmarks
considered Section 5, fails non trivial examples. conjecture
due eciency problems, additional inductive lemmata needed,
hard determine advance.
610

fiDecidability Undecidability Results Propositional Schemata

denitions also remind reader fixed point logics.
Indeed
iterated schemata obviously particular cases xed points, e.g., schema ni=1 pi
might represented (X(i).i 0(p(i)X(i1)))(n). standard xed point logic
(propositional) modal -calculus (Bradeld & Stirling, 2007) many temporal
logics encoded, e.g., LTL CTL. However involved logic dierent
actually simpler theoretical point view. Indeed modal -calculus
decidable (and thus complete) whereas shall see Section 6 iterated schemata
(nor complete). Furthermore, language allows one use complex
(though carefully restricted) arithmetic operations denition iterations,
indices bounds. instance may relate truth values two
propositions whose index arbitrary far (such pi pni ). far
aware, operations cannot directly encoded propositional -calculus.
Actually iterated schemata share much least fixpoint logic, LFP (Immerman, 1982), studied nite model theory (Fagin, 1993; Ebbinghaus & Flum, 1999):
LFP logic allowing iterate rst-order formulae maintaining constant number
variables. However know calculus deciding satisability
LFP. see two reasons this: rst, LFP undecidable complete, second
purposes logic mainly theoretical, hence fact research eld
focussed decision procedures subclasses. contrast propositional calculus, first-order -calculus (Park, 1976) clearly
embeds iterated schemata (allowing

instance xed-point expression ni=1 pi ), published research seems
focused identication complete subclasses. similar expressive power
one also nds logics inductive denitions (Aczel, 1977) quite widespread
proof assistants (Paulin-Mohring, 1993), range automated theorem
provers. far know study complete subclass xed point logics
work Baelde (2009), iterated schemata denitely lie class
reduced it.
shall see Section 5.2, completeness bound-linear schemata (or precisely
regular schemata) lies detection cycles proof search. idea
new, used, e.g., tableaux methods dealing modal logics transitive frames
(Gore, 1999), -calculi (Cleaveland, 1990; Bradeld & Stirling, 1992). However cycle
detection work quite dierent use prove induction. Notice
particular cannot general ensure termination (contrarily methods).
relevant consider method particular instance cyclic proofs,
studied proof theory precisely context proofs induction. works
Brotherston (2005), Sprenger Dam (2003), shown cyclic proofs seem
powerful systems dealing classically induction. particular advantage cyclic
proofs nding invariant needed, making particularly suited automation. However, studies essentially theoretical
completeness results particular subclasses.
summarize, known decidable logics (such propositional -calculus) even semidecidable ones rst-order logic expressive enough directly embed iterated
schemata, whereas suciently expressive (such xpoint higher order
logics) suitable automation. Together potential applications mentioned
Section 2.4, justies opinion interest considered language.
611

fiAravantinos, Caferra & Peltier

4. Reduction Regular Schemata
section reduce satisability problem bound-linear schemata (see Denition
2.9) much simpler class schemata, called regular. class dened follows:
Definition 4.1
schema is:
every iteration bi=a occurring , contain iteration (i.e.
iterations cannot nested ).
bounded propagation every atom occurs iteration bi=a
form pi+ Z. Since number atoms nite, exist , Z
s.t. every atom pi+ occurring iteration [, ]. , called
propagation limits.
aligned [c, d] iterations occurring form di=c (i.e. iterations
must bounds).
regular unique parameter n at, bounded propagation
aligned [, n ] , Z.
example, schema Adder dened Introduction regular, last
example Section 2.4 (three cells register shift) not. Obviously, every regular schema
also bound-linear (see Denition 2.9). dene algorithm transforms every
bound-linear schema sat-equivalent regular one. result somewhat surprising
class regular schemata seems much simpler bound-linear schemata.
sense, points regular schemata canonical decidable class schemata.
4.1 Overview Transformation Algorithm
rst give informal overview algorithm reducing every bound-linear schema
regular one, together examples illustrating transformation steps.
high level description intended help reader grasp intuitive ideas behind
formal denitions technical explanations provided next section.
transformation divided several steps.
rst step elimination iterations
n occurring
n inside iteration. Consider
instance following schema : i=1 (pi j=1 qj ). reader check
bound-linearbut non regular. easy transform sat-equivalent
regular schema: since nj=1 qj depend counter i, one simply
replace
n
formula new propositional variable r
add equivalence
r

j=1 qj
n
n
outside iteration. yields schema: i=1 (pi r) (r j=1 qj ),
clearly regular sat-equivalent (but equivalent) . process
generalized; however, replacing iteration proposition possible
iteration contains
n
nvariable bound
n original schema. Consider

schema: : i=1 j=1 (pi qj ). j=1 (pi qj ) cannot replaced
variable r, since depends i. solution get variable pi containing
612

fiDecidability Undecidability Results Propositional Schemata


theiteration nj=1 (pi qj ):
pi involve j, easily seen
turn nj=1 (pi qj ) pi nj=1 qj . transformation generalized
using case-splitting: indeed, well-known every formula equivalent
(r [/r]) (r [/r]),
every propositional variable
r. Applying
n
n
decomposition
scheme j=1 (pi qj ) pi get:
) (pi
j=1 (pi qj
n
n
n
(

q
))

(p

(

q
)),
i.e.
(by
usual
transformations):
j

j
j=1
j=1
j=1 (pi
n
n
qj ) (pi j=1 qj )pi . Afterwards, remaining iteration j=1 qj replaced
new variable r.
decomposition scheme explained applied every variable occurring
iteration, containing counter iteration. denition
bound-linear schemata, propositional symbols one index index contains one bound variable, thus technique actually removes every
atom containing counter variable distinct one considered iteration.
However, remove variables occur
inthe bound iteration.
def
Consider instance following formula: = ni=1 ij=1 qj . occurs
bound iteration thus cannot
removed previous technique.
idea encode formula j=1 qj new variable ri , dened
inductively
follows: r0 ri+1 ri qi+1 . expressed schema:

(r
r0 n1
i=0 i+1 (ri qi+1 )).
Notice ri needs dened = 0, . . . , n ranges
interval [1, n] .
order get regular schema one guarantee every iteration ranges
interval form [, n ] (where Z). actually
simple
2n
ensure unfolding
shifting

iterations.

instance

schema
i=1 pi
2n
n
n
n
transformed i=1 pi i=n+1 pi i=1 pi i=1 pi+n . Similarly
n1
n1
n1
n
i=2 pi pn q1 j=2 qj get iterations dened
i=2 pi j=1 qj reduced
interval.
major dierence regular schemata bound-linear ones that,
regular schema, indexed variablesoccurring inside iteration cannot contain
parameters (e.g., iteration ni=1 pi+n forbidden). Therefore
replace every variable form p.n+i new variable qi , depending i.
problem order preserve sat-equivalence, one also encode
relation variables. instance, assume pn+i replaced qi
p2nj replaced rj . obviously, must qi rj n+i = 2nj, i.e.
qi rni . step may problematic general innitely many
axioms. However, dening translation carefully, show actually
nitely many equivalences required. aim, assume
initial coecient parameter even every index (see Denition 4.2),
easy ensure case splitting. maximal number overlaps
newly dened variable actually bounded (this shown crucial lemma 4.6).


instance, formula ni=0 (pi p2ni ) replaced ni=0 (pi qi ) (pn qn ).
qi denotes atom p2ni equivalence encodes fact qn p2nn = pn .
613

fiAravantinos, Caferra & Peltier

Since ranges interval [0..n] equation relevant w.r.t.
(e.g. p0 q2n useless).
algorithm transforming every bound-linear schema sat-equivalent regular schema specied sequence rewriting rules, operating schemata
preserving sat-equivalence. rules depicted Figure 1. must applied
order presentation. shall see Section 4.3, rewrite system terminates (in
exponential time). Moreover satisability preserved irreducible schemata regular
(see Section 4.4).
4.2 Formal Definition Algorithm
give detailed precise description transformation algorithm (readers interested technical details skip section). assume initial
schema satises following condition:
Definition 4.2
bound-linear schema normalized coecient parameter n even
expression occurring formula (either index symbol P bound
iteration).
Considering exclusively normalized schemata restrictive schema
satisfying property replaced [2n/n] [2n + 1/n] (e.g. p3n turned
p6n p6n+3 ). obtained schema obviously sat-equivalent normalized4 .
use normalized schemata explained later (see Remark 4.7).
Remark 4.3
property normalized useful algorithm Figure 1 welldened. schema obtained application algorithm actually normalized general.
explain details dierent steps transformation.
4.2.1 Elimination Nested Iterations
explained Section 4.1, rst step remove iterations bi=a occurring inside
another iteration dj=c . done rules 1 , 2 , 3 , 4 . 2 moves bi=a
introducing new variable p explained before. possible contain
free variable except parameter n. Removing variables precisely
role 1 :
1

bi=a (pc bi=a [/pc ]) (pc bi=a [/pc ])
variables c free bi=a , pc occurs
every iteration dj=c containing bi=a , pc contains either j
variable bound dj=c .

4. two formulae equivalent general. instance, = pn , interpretation
def
def
dened I(n) = 1 I(p ) = = 1 validates pn obviously p2n p2n+1 .

614

fiDecidability Undecidability Results Propositional Schemata

1

2

3

3

4

4

5
6

7

8
9

10

bi=a
(pc bi=a [/pc ]) (pc bi=a [/pc ])
variables c free bi=a , pc occurs
every iteration dj=c containing bi=a , pc contains either j
variable bound dj=c .

(p bi=a ) [p/bi=a ]
p fresh symbol, global schema, bi=a occurs iteration
contains free variable except n.
ab1


j=min (j) pj
max (j)
b+j
j=ab
(pj (pj1 [b + j/i])) ([pj / i=a ])
b+j
p fresh symbol, i=a occurs iteration , j bound ,
a, b contain free variable except n, global schema.
ab1


j=min (j) pj
max (j)
b+j
j=ab
(pj (pj1 [b + j/i])) ([pj / i=a ])
b+j
p fresh symbol, i=a occurs iteration , j bound ,
a, b contain free variable except n, global schema.
max (j)


j=ba+1 pj
ba
bj
j=min (j) (pj (pj+1 [b j/i])) ([pj / i=a ])
bj
p fresh symbol, i=a occurs iteration , j bound ,
a, b contain free variable except n, global schema.
max (j)


j=ba+1 pj
ba
bj
j=min (j) (pj (pj+1 [)/b j]) ([pj / i=a ])
bj
p fresh symbol, i=a occurs iteration , j bound ,
a, b contain free variable except n, global schema.
().n
.n
i=
[i + .n/i]
i=.n+
= 0, Z.

[]n70 . . . []n7 (n > [/.n
])
i=

contains .n
,

,
,


Z,

<
0



{
,
},
i=


= = = .
=


(( 1).n [ /.n
]) ([]n70 . . . []n7 )
i=
.n
contains iteration i= > 1,

(1).n
i=
ni=1 [i + ( 1).n /i], { , },


= , = = .
=
1 , =
n
n
i=
i= [n i/i]
indices variables form (2 + 1).n + c, c Ni .


()
contains variable p occurring V V + ,
() dened Denitions 4.4, 4.5 Lemma 4.6.
n
(n < + )
i=


(n + n1+
[i + /i] [n /i])
i=

maximal lower bound iteration occurring

whole formula
= = ,
minimal upper bound,

= , = = = , = .

Figure 1: Transformation Regular Schemata

615

fiAravantinos, Caferra & Peltier

rule aims eliminating, body iteration bi=a , every variable distinct
iteration counter (unique) parameter n. feasible
index contain two variables distinct n (by denition bound-linear schemata).
implies indexed variables containing arithmetic variable distinct
n cannot contain thus taken iteration bi=a case splitting.
Notice rule 1 increase exponentially size formula.
contains free variable except n i, bi=a may taken global
iteration dj=c renaming. easy bounds iteration depend
n, case bi=a contains free variable except n, thus may replaced
fresh variable p equivalence p bi=a may added axiom.
done rule 2 :
2

(p bi=a ) [p/bi=a ]
p fresh symbol, global schema, bi=a occurs iteration
contains free variable except n.

Things get
bounds iteration contain bound variable j (e.g.,

complicated
schema nj=1 (qi ji=1 ri )) case iteration cannot taken
j cannot eliminated 1 . Notice that, case, lower bound cannot contain
j coecient j upper bound b must 1. case, bi=a
replaced new variable pj dened inductively. instance previous


example, ji=1 ri replaced variable pj dened follows: p0 nj=1 [pj (rj pj1 )].
transformation formally specied rules 3 (if coecient j 1) 4
(if coecient j 1). Notice denotes global schema, pj must
dened every j [min (j), max (j)].
3





ab1

j=min (j) pj
max (j)
j=ab
(pj


(pj1 [b + j/i])) ([pj / b+j
i=a ])
b+j
p fresh symbol, i=a occurs iteration , j bound ,
a, b contain free variable except n, global schema.

max (j)
j=ba+1 pj

bj
ba
j=min (j) (pj (pj+1 [b j/i])) ([pj / i=a ])

p fresh symbol, bj
i=a occurs iteration , j bound ,
a, b contain free variable except n, global schema.

rules 3 4
dened similar way (see Figure 1).
4





4.2.2 Transforming every Iteration Iterations Intervals
Form [, n ]
next step ensure every iteration bi=a , integer b
form n , constant (initially b must form 2..n +
(since initial schema normalized iteration contained inside another one
bound variable occurs upper bound). rst point easily performed
616

fiDecidability Undecidability Results Propositional Schemata

appropriate translation iteration counter (rule 5 ):
5

.n
i=.n+
= 0, Z.

().n

i=

[i + .n/i]

ensure coecient n b positive. Fortunately, coecient
negative N s.t. every interpretation s.t. I(n) > , interval
[I(a), I(b)] empty, case bi=a either (depending ). Since
value n positive, exist nitely many values n s.t. iteration non empty.
One eliminate iteration considering cases separately. done
rule 6 :
6

[]n70 . . . []n7 (n > [/.n
i= ])

.n
contains i= , , , Z, < 0 { , },


= = = .
=


Finally, obtain desired result (recursively) decomposing iteration interval
form [, .n + ] (where > 1) two smaller intervals [, ( 1).n + ]
[( 1).n + + 1, .n + ]. Obviously, possible ( 1).n + , thus
case ( 1).n + < must considered separately. easy achieve, since
case nitely many possible values n, namely 0, 1, . . . ,
1 .
7

(( 1).n [ /.n
i= ]) ([]n70 . . . []n7 )
.n
contains iteration i= > 1,

(1).n
i=
ni=1 [i + ( 1).n /i], { , },


=
= , = = .
1 , =

4.2.3 Removing Parameter Indices Iterations
next phase consists removing indexed variables form p.n+.i+
Z either = 0 = 1 (to get variables indexed expressions form
+ only). rst ensure even. Although initially coecient every
occurrence n even, property hold anymore point
rule 7 . Suppose variable p(2+1).n+c , c contain n, occurs iteration
bi=a . (since schema normalized) variable must introduced
rule 7 shifted ( ).n (by denition 7 ). shift
applied every index containing (by denition 7 ), i.e. every index variable
occurring bi=a (otherwise iteration would reducible 1 ). consequence
every index iteration odd coecient n. Hence add n index
retrieve even coecients iteration. Fortunately commutativity ,
iteration bi=a equivalent ba
i=0 [b i/i]. case b form n
Z applying transformation
precisely adds n index

(and substracts
). instance, iteration ni=1 (pn+i pni ) replaced n1
i=0 (p2ni pi) .
idea formalized rule 8 :
8

n
n
i=
i= [n i/i]
indices variables form (2 + 1).n + c, c Ni .
617

fiAravantinos, Caferra & Peltier

coecient n every indexed variable even, introduce, every variable
+

+

p every integer , two new (fresh) variables p p s.t. pa pa denote
respectively p2..n+a p2..na Ni Z i.e. form .i +
+
{0, 1}, Z (rule 9 ). index pa contain n anymore. Furthermore,

index pa contains +i instead i. Thus transformation indeed achieves
goal however preserve sat-equivalence two variables p2.n+a
p2.nb (respectively p2.n+a p2.n+b , p2.na p2.nb ) s.t. 2.n + = 2.n b
(respectively 2.n + = 2.n + b 2.n = 2.n b) may replaced distinct

+

+
+

variables pa pb (respectively pa pb , pa pb ). Notice important
distinguish sign + front b, integers expressions
Ni Z. order preserve sat-equivalence one would explicitly add following
axioms schema:

+
2.n + = 2.n (p p )

+

+





2.n + = 2.n + (p p )


2.n = 2.n (p p )
every tuple (, , , ) Z4 .
transformation problematic, exist innitely many formulae.
Fortunately, add equivalences, concerning propositional variables occur propositional realization schema. shall see,
set (denoted ()) nite, expression , ranges set
form [, ] [n , n + ], N.
formally, let V + V two disjoint subsets P, distinct symbols
already occurring considered formula. assume every pair (p, ) p
+
variable occurring formula integer mapped two variables p V +

+

p V . pi pi denote atoms p2.n+i p2.ni respectively.
denote schema obtained replacing every variable form p2.n+a
+
(where Ni N bound variable i) pa variable form p2.na

pa (in cases may = 0, moreover, = 0 replacement may
+

+

done arbitrarily p0 p0 ). Notice atoms form pa pa ,
Ni N bound variable i. 9 dened follows:

9 ()
contains variable p occurring V V + ,
() dened Denitions 4.4, 4.5 Lemma 4.6.
4.2.4 Aligning Iterations
Finally, remains ensure iterations bounds. point


every iteration form n
i= , Z. Let , greatest integers , .
n1
= = , unfold iteration once, yielding i=
[n/i].
n1
n1+
translation iteration counter, i=
equivalent i=
[i + /i].

lower bound obtained iteration identical length
618

fiDecidability Undecidability Results Propositional Schemata

decreased. repeated obtain iteration interval [ , ]. rule
10 formalizes transformation:
10

n
i=



(n < + )

(n + n1+
[i + /i] [n /i])
i=
maximal lower bound iteration occurring

whole formula
= = ,
minimal upper bound,


= , = = = , = .

4.2.5 Definition ()
dicult part transformation removal variable n index
performed rule 9 , precisely denition (). establish
results ensuring feasability transformation.
Definition 4.4
denote set schemata form:
+



+

+





2.n + = 2.n b (pa pb )


2.n + = 2.n + b (pa pb )


2.n = 2.n b (pa pb )
, Z, a, b Nn Z.
set innite. Thus add restriction:
Definition 4.5
Let schema containing unique parameter n. schema (p q) occurring
said relevant w.r.t. following conditions hold:
p q syntactically identical.
exists natural number s.t. [/n] true [/n] contains p[/n]
q[/n]
occur itself. instance, take =
n Notice p q
n necessarily

+
2
0
2
0+
i=1 (p2ni pi ). =
i=1 (pi pi ). 2n n = 4 (pn p4 )
+

easily seen relevant, however p2n p04 occur .
next lemma provides simple necessary condition relevant equivalences
. also shows every schema number relevant equivalences nite
(up equivalence).
Lemma 4.6
Let schema containing unique parameter n. Assume coecient n
n+
even every index every iteration form i=
, , Z
619

fiAravantinos, Caferra & Peltier

(, may depend iteration). Let greatest natural number occurring
(possibly coecient n expression form ).

+
every relevant formula form 2.n + = 2.n b (pa pb ), 2.n + =


+

+



2.n + b (pa pb ) 2.n = 2.n b (pa pb ) , have, every
N: , [, ] a[/n], b[/n] [2, 6] [ 2, + 2].
Proof
Let stand substitution [/n]. denition relevant formula, must exist
+



+

+

N pa pb (respectively pb ) occur [] (but notice pa , pb



+

pb necessarily occur ). Furthermore must 2. + = 2. b
(resp. 2. + = 2. + b).
Since coecient n even every index since a, b Nn Z, 2, 2
necessarily occur . Thus , [/2, /2] [, ].

+
+
Moreover, Lemma 2.8, exist two atoms pa pb (respectively pb )


+

occur two -expansions pa pb (respectively pb ) s.t.
= b = b . denition, , b come replacement
+

+
proposition p2.n+a (resp. p2.nb p2.n+b ) pka (resp. pkb pkb ). Thus
b contain n. Thus b either Z (and case must
a, b [, ] [2, + 2]) respectively form + +
bound variable , Z. since , -expansions
, [min (i), max (i)]. min (i) = max (i) = n + n + .
Thus a, b [2, + 2].
Assume 2. + = 2. b. + b = 2.( )..
+

+ b 0. Since a, b 2, deduce a, b 2. Thus
a, b [2, 6].
> + b 2. Since + 2 b + 2 must
2 b 2. Thus a, b [ 2, + 2].
Now, assume 2. + = 2. + b. b = 2.( )..
= must = b. contradicts rst condition Denition
4.5 (the indexed variables cannot syntactically identical).
< b > 2. possible > 2 + b > 2 2, hence
+ 2 > 2 2, i.e. 4 > . since must a, b [2, + 2] deduce
a, b [2, 6].
proof symmetric > .
Finally 2. = 2. b b = 2.( ). proof follows exactly
previous case.

Lemma 4.6 implies set relevant formulae nite (up equivalence). Indeed,
suces instantiate , every integer [, ] a, b either elements [, 6]
620

fiDecidability Undecidability Results Propositional Schemata

expressions form n + , integer [2, 2]. Thus denote
() nite subset containing relevant formulae (up equivalence). set
easily computed applying Lemma 4.6, using rened criteria possible, thus
opt generic denition.
Remark 4.7
fact coecient n even (see Denition 4.2 normalized schemata)
essential point. arbitrary coecients allowed n, coecients 2
2 must replaced respectively. second item proof
Lemma 4.6 obtain + b (instead + b 2). Thus get eventually
, b > 2 (instead 2). means a, b range interval
[2, + 2] instead [, 6] [ 2, + 2]. interval unbounded, thus ()
innite (even equivalence).
instance, suppose allow
coecient n (i.e. odd oreven)
+
+

1
p.n+ turned p . Consider = ni=1 (pi pni ). get: = ni=0 (p0i p1i ).


+

equivalence p0i p1ni obviously needed every [1, n], cannot
expressed nite number equivalences.
hand, allow normalized
schemata, i.e. even coecients

n
2n
7 ) = i=1 (pi
n,
(pi p2ni ) hence(by
rst turn = i=1
n1
(p2ni pi ).
p2ni ) ni=1 (pn+i pni ), (by 8 ) = ni=1 (pi p2ni ) i=0


+

1
0+
= ni=1 (p0i p1i ) n1
i=0 (pi pi ). equivalence needed simple case.
Lemma 4.8
Let schema containing unique parameter n s.t. every iteration form
n+
i= , , Z. satisable () satisable.
Proof
Let interpretation satisfying . Let = I(n). dene interpretation J
+

follows: J (n) = every pair integers (, ): J (p ) = I(p2.+ ) =
def



def

J (p ) = I(p2. ) = . denition , J |= . obtained
replacing every atom form p2.n+a (respectively p2.na ) Ni Z
+

+
(for bound variable i) pa (respectively pa ). denition J , J |= p
def



|= p2.n+ J |= p |= p2.n . Since |= clear J |= .
Thus J |= ().
Conversely, let |= (). Let = I(n). Let J interpretation dened
+
+

def
follows. J (n) = , J (p2.+ ) = I(p ) p occurs []I , J (p2. ) = I(p )


p occurs []I . easy check J well-dened since |= () ()
+



contains necessary equivalences. denition, pa (respectively pa ) occurs
p2.n+a (respectively p2.n+a ) occurs . Thus, since |= J |= .

4.3 Termination Complexity
section, investigate complexity transformation algorithm show
exponential. every schema , denote || size , i.e. number
symbols occurring . denotes system rewrite rules Figure 1.
621

fiAravantinos, Caferra & Peltier

Theorem 4.9
Let normalized bound-linear schema. normal form w.r.t. computed
O(2|| ) rewriting steps. Moreover, || = O(2|| ).
Proof
rst notice rules always applied sequentially: easy check rule
cannot introduce formula previous rule applies. Thus consider rule
sequence.
First, consider rule 1 . call 1 -atoms atoms pc rule possibly
applies, i.e. atom occurring iteration bi=a containing iteration
counter i. rule removes atom occurring iteration containing
iteration counter. Due control (i.e. application conditions rules), atom
satisfying condition introduced formula (indeed, atom pc occurs
iteration then, second application condition rule, must contain
corresponding iteration counter iteration). Therefore, number applications
rule iteration bounded number 1 -atoms contains. Since rule
duplicates considered iteration total number applications rule bounded
2m , total number 1 -atoms. Obviously ||.
sucient prove second result, i.e. size formula
O(2|| ), since application rule double size formula (which would
yield double exponential blow-up since 2m rule applications). Consider set
leaf positions considered formula. position p set, denote |p|
length p rp number possible applications rule 1 along p.
application rule 1 removes positions p set (those corresponding
leaves subformula rule applied) replaces new positions
p1 , . . . , p . number positions length possibly increase. However,
remark rule increase length positions 2 (by adding
disjunction conjunctions), i.e. [1, ], |p | |p| + 2. Furthermore, number
rp necessarily decreases: [1, ], rp < rp . Consequently, value |p| + 2 rp cannot
increase (i.e. [1, ], |p | + 2 rp |p| + 2 rp ), implies length
nal positions (when rp = 0) lower |pmax | + 2 rmax , rmax denotes
maximal number possible applications rule 1 along position initial
formula (i.e. max rp initial formula) pmax position maximal
length initial formula. |pmax | rmax O(||), thus depth nal
formula O(||), implies size O(2|| ).
consider rules. First analyze transformation due single
application rules (then analyze number applications).
Since proofs dierent cases actual similar, consider rule
separately, rather factorize part analysis.
application rule 2 increases size formula constant
number symbols, since xed number new connectives added part
formula duplicated.
application rules 3 , 3 , 4 , 4 , 5 , 8 10 adds constant number
new connectives formula replaces occurrence counter
622

fiDecidability Undecidability Results Propositional Schemata

formula expression form b + j, b j, + .n n i. size
expressions bounded size original formula, thus size formula
increases quadratically (since number occurrences also bound size
formula).
consider rules 6 7 . rules introduce constant number new
connectives occurrences atoms duplicate times subformula .
value bounded natural number occurs , thus size
formula increases polynomially (since natural numbers encoded unary terms
s(. . . (s(0)) . . .) setting, hence bounded size formula notice
would case numbers encoded sequences digits5 ).
Thus show number applications rules
polynomially bounded size initial formula. again, distinguish several
cases:
rules 2 , 3 , 3 , 4 , 4 apply iterations occurring inside another iteration.
application rule, iteration replaced atom, hence removed
outermost iteration. rule introduces new iterations, however
occur root level, outside scope iteration. Thus total number
possible applications rules bounded number iterations initially
occurring inside another iteration, hence ||.
rules 5 , 6 8 apply iteration: 5 applies iteration
lower bound contain n gets rid occurrence n lower
bound. 6 applies iterations upper bound contains n replaces
iterations purely propositional formulae. 8 applies coecient n
every index odd. Since rule adds n index, application
rule, coecient n must even rule cannot apply
iteration.
rule 7 decreases value coecient n upper bound 1. Thus
number applications rule 7 iteration lower initial
value (which bound size formulae since integers encoded
terms). Similarly, since 10 unfolds iteration iteration length n
obtained, number applications rule 10 iteration bound
value + + .
Finally, rule 9 applies whole schema. rule adds conjunction equivalence schema, Lemma 4.6, size conjunction
polynomially bounded greatest natural number occurring schema,
hence size formula.

every schema , denote normal form w.r.t. rules .
5. Actually translation doubly exponential case.

623

fiAravantinos, Caferra & Peltier

4.4 Soundness Completeness
prove rules preserve sat-equivalence every irreducible formula
regular. need two propositions below:
Lemma 4.10
Let , schemata. Let interpretation every ground
substitution parameters every -expansion , , have:
JKI = J KI . JKI = J[ /]KI .
Proof
proof induction . contain proof trivial. =
[ /] = . denition JKI = JI KI J KI = J KI . ground
substitution parameters = thus course -expansion
. Thus JI KI = J KI hence JKI = J KI .
Assume = . J[ /]KI = J [ /]KI = J KI (by induction).
Thus J[ /]KI = JKI . proof similar = (1 2 ) = (1 2 ).

assume = bi=a . |= every integer [JaKI , JbKI ]
def
I[/i] |= . Let substitution (i) = (x) = (x) x = i.
Let -expansion . denition [Jmin (i)KI , Jmax (i)KI ], thus
also -expansion . Therefore JKI = J KI , hence JKI[/i] = J KI[/i]
(since contain i). Consequently, induction hypothesis,
J KI[/i] = J [ /]KI[/i] . Hence |= every integer [JaKI , JbKI ]


I[/i] |= [ /] i.e. |= [ /]. proof similar = bi=a .
Lemma 4.11
every schema every indexed proposition p contain variable
bound :
(p [/p]) (p [/p])
Proof
p p hence distributivity (p ) (p ). show
every interpretation I, Jp KI = Jp [/p]KI . JpKI = F p p [/p]
false I. Otherwise, Lemma 4.10, JKI = J[/p]KI . Similarly,
Jp KI = Jp [/p]KI . Hence (p [/p]) (p [/p]).

Theorem 4.12
Let normalized bound-linear schema. satisable satisable.
Proof
proof inspection dierent rules (see denition rules
notations):
1 . proof direct application Lemma 4.11.
2 . every model , one construct interpretation J (p bi=a )
[p/bi=a ] interpreting p Jbi=a KI . denition J |= (p bi=a ).
624

fiDecidability Undecidability Results Propositional Schemata

Since |= J |= . Lemma 4.10 deduce |= [p/bi=a ]. Hence
J |= (p bi=a ) [p/bi=a ].
Conversely, model (p bi=a )[p/bi=a ], due rst conjunct
bi=a p truth value hence since |= [p/bi=a ], deduce
|= , Lemma 4.10.
3 . Assume |= . Let J extension obtained interpreting p
b+

J i=a
KI . Lemma 4.10 J |= ([pj / b+j
i=a ]). Furthermore denition
b+
semantics, J i=a KI = F Jb+aKI < 0 hence J |= p < ab.

Thus J |= pab1 ab1
j=min (j) (pj pab1 ). Furthermore, every JabKI ,
b+

J i=a KI = either J b+1
KI = J[b + /j]KI = T. Hence Jp KI =
i=a
max (j)
either Jp1 KI = J[b + /j]KI = T. Therefore |= j=ab
(pj (pj1 )).
ab1
max (j)
Conversely, let model pab1 j=min
(pj pab1 ) j=ab
(pj
(j)
b+j
(pj1 [b + j/i])) ([pj / i=a ]). show induction |= (p
b+
i=a ) every [Jmin (j)KI , Jmax (j)KI ]:
b+
< Ja bKI denition J i=a
KI = F. Moreover rst two
conjuncts previous formula must Jp KI = F.


[b+/i]KI . Hence induction
KI = J b+1
Otherwise, J b+
i=a
i=a
b+
hypothesis: J i=a KI = Jp1 KI [b + /i], third conjunct

formula above, get: J b+
i=a KI = Jp KI .
Lemma 4.10 deduce |= . proofs rules 3 , 4 4
similar.


.n+

5 . Assume = (the case = similar). denition |= i=.n+
exists [J.n + KI , J.n + KI ] |= [/i], i.e. exists
().n+
[JKI , J().n+KI ] |= [+J.nKI /i], i.e. |= i=
[i+.n/i].
6 . assume = = (the case = , = similar). Since
assume I(n) 0 every parameter n, |= (n = 0. . .n = n > )
hence equivalent to: (n = 0 . . . n = n > ) . distributivity get

(n = 0). . . (n = )(n > ). .n+
empty (thus equivalent
i=

) I(n) > , hence, Lemma 4.10, (n = 0 ) . . . (n =

) (n > [/ .n+
]). every [0, ], n = |= []n7 ,
i=

hence |= []n70 . . . []n7 (n > [/ .n+
]).
i=
Conversely, |= []n7 holds, straightforwardly extended model
n = interpreting n . Thus model []n70 . . . []n7 (n >

[/ .n+
]) exists model , 6 preserves satisability.
i=

7 . Again, assume = = . (( 1).n+ < ( 1).n +
) hence (( 1).n + < (( 1).n + ) (( 1).n +
) (( 1).n + < ). Since parameters interpreted natural
625

fiAravantinos, Caferra & Peltier

numbers, |= ( 1).n + < I(n) [0,
1 ]. denition

JKI = J[]n7I(n) KI . |= ( 1).n + then, unfolding, J .n+
KI =
i=
(1).n+
(1).n+
.n+
n
J i=
i=(1).n++1 KI = J i=
i=1 [i + ( 1).n + /i]KI .
Hence 7 preserves satisability.
8 : proof similar one 6 .
soundness rule 9 direct consequence Lemma 4.8.

n

10 . assume = = . i=
(n < + n
i= )(n
n
n
+ i= ). every interpretation I, I(n) < + J i= KI = F


thus n < + n
(n < + ). I(n) + , J n
i=
i= KI
n
J[/i] i=+1 KI . Furthermore translation iteration counter
n
n


i=+1
i=+1 + [i + /i]. Hence 10 preserves equivalence.

Theorem 4.13
Let normalized bound-linear schema. regular.
Proof
Firstly, remark application rules bound-linear schema generates
schema still bound-linear. Notice however obtained schema normalized
general.
Let bound-linear formula, irreducible . Assume obtained
normalized schema application rules . need prove
regular.
rst prove contains nested iteration. Let = bi=a iteration
occurring . Assume contains iteration dj=c . W.l.o.g. assume
contains iteration (otherwise could simply take = ). irreducibility w.r.t.
rule 1 , indices must contain j. denition class bound-linear
schemata, implies indices cannot contain i. j occurs one
rule 3 ,3 , 4 4 applies. Consequently free variable dj=c n. Thus rule
2 applies impossible irreducibility.
remark iterations bi=a , Z b form n +
Z. Indeed, contains n rule 5 applies coecient n b
dierent 1 rule 6 7 applies.
rule 8 eliminates indexed propositions coecient n odd (since
initial schema normalized, indexed variables necessarily introduced
rule 7 , thus must occur iteration indices iteration must
odd coecient front n).
9 eliminates variables form p2.na , Z Ni N,
bound variable i, replaces variables indexed a.
Finally 10 ensures iterations bounds.

626

fiDecidability Undecidability Results Propositional Schemata

5. STAB: Decision Procedure Regular Schemata
shown transform bound linear schema regular one, show
satisability problem decidable regular schemata. done providing
set block tableaux rules (Smullyan, 1968) complete w.r.t. satisability.
rules concise natural, and, compared naive procedure described proof
Proposition 2.7, much ecient terminate often (see end
Section 5.1). procedure called stab (standing schemata tableaux). Notice
applies schema (not regular ones). assume (w.l.o.g) schemata
negative normal form.
5.1 Inference Rules
Definition 5.1 (Tableau)
tableau tree s.t. node N occurring labeled set schemata written
(N ).
usual tableau generated another tableau applying extension rules.
P
Let r =
rule P denotes set schemata (the premises),
C1 . . . C
C1 , . . . , C denote conclusions. Let N leaf tree . subset (N )
matches P extend tableau adding children N , labeled
C (T (N ) \ S) = 1, . . . , matching substitution. leaf N
closed set arithmetic formulae (i.e. schemata containing atoms form
. . . < . . . iteration) (N ) unsatisable. detected using decision
procedures arithmetic without multiplication (Cooper, 1972).
Definition 5.2 (Extension rules)
extension rules stab dened follows.
usual rules propositional tableaux:

():





():







Rules proper schemata (iteration rules)6 :
b

b

i=a

(Iterated ):

ba
b1
i=a [b/i]

i=a

b<a

(Iterated ):

ba
b1
i=a [b/i]

6. right branch conclusion Iterated rule required, e.g., detect
satisable n = 0.

627

n
i=1



fiAravantinos, Caferra & Peltier

closure rule adds constraints needed branch closed. rule
applied = b already occur branch.
pa
(Closure):

pb

pa , pb , = b

stab without loop detection rule described next section already better
straightforward procedure introduced proof Proposition 2.7. First, terminates cases schema unsatisable (whereas naive procedure never
terminates case, unless schema
nis unsatisable propositional formula).
trivially case schema i=1 n 1, propositionally
unsatisable.
Second, nd model much faster naive procedure. Consider,

e.g., ( 10000
p)
(p ) unsatisable formula. case stab immediately
i=n
nds model n > 10000 p interpreted F.
Remark 5.3
Using tableaux-based system deciding regular schemata may seem surprising, since
DPLL procedures (Davis, Logemann, & Loveland, 1962) usually ecient propositional logic. However, extending procedures schemata straightforward.
main problem evaluating atom schema immediate, since atom may
well appear realization schema without appearing schema itself. Thus,
contrast propositional case, sucient replace syntactically
atom
n
truth value. instance, atom p2 (implicitly) appears schema
i=1 pi
n
p
)

n1
n > 1. Thus
evaluating
p
to,
say,
F
would
yield
two
distinct
branches:
(
2
i=1
n
(p1 i=3 pi ) n > 1. Thus one would dene rules operating deep positions
schema order unfold iterations instantiate counter variables
needed. contrast, tableaux method operates formulae occurring root level
compares literals instantiated (using unfolding). makes
procedure much easier dene reason (in particular termination behavior
easier control). Actually DPLL procedure schemata presented previous
work (Aravantinos, Caferra, & Peltier, 2009a, 2010), much complicated
calculus presented here.
course, one could combine iteration rules tableaux procedure SATsolver used black box could charge purely propositional part.
However also straightforward, mainly due fact partial evaluation
needed propagate values propositional variables iterations.
5.2 Discarding Infinite Derivations: Looping Rule
stab terminate general. reason iteration is, general, innitely
unfolded iteration rules.
n Assume instance propositional unsatisable
formula.
starting
n i=1 one could derive innite sequence formulae
form n1
,
.
.
.
,
i=1
i=1 , every N. introduce loop detection rule
aims improving termination behavior stab. Detecting looping natural
way avoid divergence: if, extending tableau, nd schema
already seen, possibly shift arithmetic variables, need
628

fiDecidability Undecidability Results Propositional Schemata

consider stop procedure. loopings also interpreted
well-foundedness arguments inductive proof.
Definition 5.4 (Looping)
shift substitution mapping every variable n expression form n ,
N s.t. least one variable n s.t. n < n (which always case since
may = 0).
I, J two interpretations, write < J exists shift s.t. J = I.
Let , two schemata (or sets schemata). write |=s every model
, exists J < s.t. J |= .
Let N, N two nodes tableau . N loops N (N ) |=s (N ).
existing work cyclic proofs, N sometimes called bud node N
companion node N (Brotherston, 2005). leaf loops, treated closed
leaf (though necessarily unsatisable). distinguish particular case closed
leaf usual one, say blocked (blocked leaves closed). Notice
N N may dierent branches, thus looping may occur often, allowing
simplications.
Example
5.5

Let = { ni=1 pi } = { ni=2 qi }. Intuitively, structure:
stab behave similarly formulae. relation |=s supposed formalize
notion. show example case, expected, i.e.
|=s . Indeed, consider model . construct interpretation J follows:
def
def
J (n) = I(n) 1 every [1, J (n)], J (p ) = I(q+1 ). Since |= exists
[2, I(n)] I(q ) = T. Thus exists [1, I(n)1] I(q+1 ) = T,
i.e. exists [1, J (n)] J (p ) = T. Therefore J |= .
Proposition 5.6
Let schema. satisable model minimal w.r.t. < (i.e.
every interpretation J , J < J |= ).
Proof
Let V set parameters . Notice V nite. every interpretation
denote I(V ) integer: I(V ) = nV I(n). Since assumed I(n) N every
variable n, deduce I(V ) 0.
Let model I(V ) minimal. Since truth value
depend values variables V , may assume n V, I(n) =
0. Let J model J < I. denition exists shift
J = I. every arithmetic variable n, n = n n , n N; furthermore,
exists least one variable > 0. Thus J (n) = I((n)) I(n)
J (m) < I(m). Consequently must J (V ) I(V ), thus J (V ) = I(V ) (since I(V )
minimal). denition, entails n = 0 every n V . Thus V ,
case I(m) = 0 hence J (m) < 0 impossible (since assume parameters
interpreted natural numbers).

def

apply looping rule practice one nd shift check implication
holds. Unfortunately, relation |=s obviously undecidable (for instance = ,
629

fiAravantinos, Caferra & Peltier

easily checked |=s unsatisable, shall see Section 6
satisability problem undecidable propositional schemata). Thus, following,
shall use much stronger criterion sucient purpose. obvious solution
would use set inclusion: indeed, |=s exists shift s.t. . However,
criterion strong, following example shows.
Example 5.7

schema = pn (pn qn ) q0 ni=1 (qi qi1 ) obviously unsatisable.
reader easily check stab generates innite sequence sets schemata
form:
n

{pn , qn , q0 , qn1 , . . . , qn ,
(qi qi1 )}, N
i=1

None sets contains previous one shift n indexed
proposition pn must occur every set.
Thus introduce renement set inclusion based purity principle. pure
literal rule standard propositional theorem proving. consists evaluating literal
L formula (in NNF) complement L occur . literal
called pure. well-known operation preserves satisability may allow
many simplications.
show extend pure literal rule schemata. conditions L
strengthened
order take iterations account. instance, L = pn
2n
contains i=1 pi L pure , since pi complement L = n (and
since 1 n 2n). hand p2n+1 may pure (since 2n + 1 [1, 2n]).
every set schemata
denote N conjunction purely arithmetic
def
formulae : N = , arithmetic .7
Definition 5.8 (Pure literal)
literal pa (respectively pa ) pure set schemata every occurrence
literal pb (respectively pb ) , arithmetic formula N IC ()a = b unsatisable8 .
Definition 5.9
Let , two sets schemata. write exists shift set
parameters s.t. every :
Either arithmetic formula N |= .
pure literal .
.
rst third items correspond roughly set inclusion (up arithmetic properties). second item deals . corresponds informal
idea pure literal removed. course important one.
7. possible improvement would add N formulae obvious logical consequences .
instance, = {pn (n > 1), p1 } N would contain n > 1. would make notion
pure literal slightly general, e.g., pn would pure , case current
denition.
8. See page 606 denition IC ().

630

fiDecidability Undecidability Results Propositional Schemata

Example 5.10

n1
Let = {n 0, pn+1 , pn , ni=1 (pi pi1 ), p0 } = {n 1, pn1 , i=1
(pi
pi1 ), p0 }. . Indeed, consider shift = {n 7 n 1}. denition N = {n 1}. (n 0) = n 1 0 n 1, thus N |= (n 0). Since
n 0 [1, n], p
pn+1 , thus pn+1 pure . Finally,
cannot identical
pn = pn1 ni=1 (pi pi1 ) = n1
i=1 (pi pi1 ) .
show decidable. First all, trivial syntactic equality
decidable shown following denition proposition:
Definition 5.11
Let U(, ) arithmetic formula dened follows:
= pa = pb U(, ) = (a = b).
def

= (a b) = (c d) (with {, <}) U(, ) = (a = c) (b = d).
def

= = U(, ) = U( , ).
= (1 2 ) (with {, }) = (1 2 ) U(, ) = U (1 , 1 )
U(2 , 2 ).
= bi=a = di=c U(, ) = (a = c) (b = d) U( , ).
def

Otherwise U(, ) = .
def

Proposition 5.12
Let , two schemata. every substitution , U(, ) valid
syntactically identical.
Proof
straightforward induction formulae.



prove decidability :
Proposition 5.13
decidable.
Proof
Since linear arithmetic decidable, possible check whether literal pure
set formulae . pure literals simply removed (since
satisfy second condition Denition 5.9). One nd shift every
remaining formula satises rst third condition. Let n1 , . . . , n variables
, . Let substitution mapping every parameter n (1 ) n l ,
l distinct variables occurring , . One check exists
substitution mapping every variable l integer that:
[1, ], (l ) 0 [1, ], (l ) > 0. Since xed, condition
stated arithmetic formula.
631

fiAravantinos, Caferra & Peltier

every formula , one following conditions holds:
arithmetic formula N |= , i.e. formula n1 , . . . , n .N
valid.
occurs . holds contains formula ,
identical every value parameters, i.e., Proposition 5.12,
n1 , . . . , nk .U(, ) valid.
Since every condition equivalent arithmetic formula, whole condition
expressed arithmetic formula (taking conjunction formulae corresponding
). formula satisable exists substitution satisfying desired property. proof follows straightforwardly decidability
linear arithmetic.

prove stronger relation |=s .
Proposition 5.14
Let , two sets schemata. |=s .
Proof
Let shift satisfying conditions Denition 5.9. Let interpretation
satisfying . Let = . show exists J < s.t. J |= , i.e.
exists shift s.t. J = J |= . Equivalently, show exists
model J , i.e. = convenient. Let J interpretation s.t. J (L) =
def
L literal pure J (L) = I(L) otherwise. Let .
show J |= . distinguish three cases, according three items Denition
5.9.
N |= , since |= since J coincide every arithmetic
variable must J |= .
literal pure pure , thus J |= denition.
, |= . Thus every literal pure must pure .
complementary literals cannot occur [] . Since J coincide
literals since negative normal form, must J |= .
Consequently J |= , hence J |= .



strictly less general |=s evidenced following:
Example
5.15

5.5).
Let = { ni=1 pi } = { ni=2 pi }. shown
n|=s (see Example
n
However, , since shift ( i=1 pi ) = i=2 pi (this
obvious since 1 cannot equal 2 whatever ).
5.3 Examples
proving soundness, completeness termination stab, provide
examples tableaux.
632

fiDecidability Undecidability Results Propositional Schemata

(n 0) p0
n 0, p0 ,

n

(1)

i=1 (pi1

n

i=1 (pi1

pi ) pn

pi ), pn

n = 0

n1
i=1

n1
(pi1 pi )

pn1 pn
pn1

n<1



pn

(1)
n = n


Figure 2: Simple Example Closed Tableau

5.3.1 Simple Example


Let following formula: (n 0) p0 ni=1 (pi1 pi ) pn .
construct tableau . First -rule applies transform conjunction
set schemata. closure rule applies
pn p0 , yielding constraint n = 0.
iteration rule applies schema ni=1 (pi1 pi ), yielding two branches.
rst one
corresponds case iteration non empty unfolded,
yielding n1
i=1 (pi1 pi ) pn1 pn second one corresponds case
iteration empty (hence true), yielding constraint n < 1. latter branch
closed immediately due constraints n 0 n = 0. former branch,
-rule applies formula pn1 pn , yielding two branches pn1 pn
respectively. closure rule applies latter one, yielding unsatisable constraint
n = n hence branch closed. last remaining branch loops initial one,
shift n 7 n 1. obtained tableau depicted Figure 2. Closed leaves (resp.
blocked leaves looping ) marked (resp. ()). new (w.r.t. previous
block) formulae presented blocks.
5.3.2 n-Bit Adder

section provide slightly complicated example. use stab prove
simple property n-bit Adder dened Introduction. aim proving
+ 0 = A. SAT-solver easily refute formula xed n (say n = 10).
prove n N. simple example chosen sake readability
conciseness, notice commutativity associativity n-bit adder could proven
(see Section 5.7).

express fact second operand null: ni=1 qi , fact
result equals rst operand: ni=1 (pi ri ), gives ni=1 (pi ri ) refutation.
633

fiAravantinos, Caferra & Peltier

n

n1

n

c1

n1
n1
i=1 Sumi

(1)

i=1 Sumi

i=1 Carryi

n
i=1

n

i=1

c1
Sumn

i=1 Carryi
n1
i=1 qi

qi

n1
n1
i=1 Sumi
n1
i=1 pi ri
n1
i=1 Carryi
n1
i=1 qi

pn rn

n1

pi ri

Carryn
qn

c1
Sumn
Carryn
qn

(1)
rn

cn

pn

qn

rn

pn

cn

(2)

qn

(2)

(2)

n11
n2
i=1 Carryi
Carryn1

n1

n1<1

cn

c1



n2
(pn1 qn1 ) (cn1 pn1 ) (cn1 qn1 )

pn1 qn1

cn1 pn1


cn1

pn1

cn1 qn1



rn1

(2)

Figure 3: Closed Tableau + 0 =

want prove Adder
schema regular.

n

i=1 qi



n

i=1 (pi

ri ) unsatisable. Notice

corresponding tableau sketched Figure 3. Sequences propositional extension
rules detailed.
634

fiDecidability Undecidability Results Propositional Schemata

Explanations.
rst big step decomposes

iterations. branching due
ni=1 pi ri : rst pn rn ,then n1
. right branch loops
i=1 pi r
n
n1
steps iterated conjunctions i=1 . . . contain i=1
. . . left one extended
propositional rules (the reader easily check Sumn , Carryn , pn rn qn
indeed lead presented branches, notice cn must hold, otherwise would
pn rn ).
(2) start decomposing iterations second time. Iterations aligned
[1, n 1] introduce constraints i.e. either n 1 1 (rst branch)
n 1 < 1 (second branch). second case, introduced constraint implies
n = 1, thus cn = c1 closes branch. rst case decompose Carryn1
consider various cases. Two
trivially discarded imply qn1 , whereas
easily obtain qn1 unfolding ni=1 qi . remains one case easily
seen loop (2). branch (2 ) similar (2).
5.4 Soundness Completeness
leaf irreducible extension rule applies it. derivation (possibly innite)
sequence tableaux (T )I s.t. either [0, ] 0, N s.t.
\ {0}, obtained T1 applying one extension rules. derivation
fair either s.t. contains irreducible closed leaf
every closed blocked leaf N s.t. rule applied N
(i.e. leaf freezed).
Definition 5.16 (Tableau Semantics)
every node N tableau , (N ) interpreted conjunction elements.
satised interpretation exists leaf N s.t. |= (N ).
Lemma 5.17
tableau obtained applying one extension rules leaf N tableau
|= (N ) exists leaf N s.t. N child N
|= (N ) (i.e. rules sound invertible).
Proof
Obvious, inspection extension rules.



Lemma 5.18
leaf N irreducible closed satisable.
Proof
def
Let set arithmetic formulae (N ) = (N ) \ . N closed
satisable (by denition), let solution . contains formula
literal, one extension rules applies deletes , impossible. Let
cT (N ) number pairs pa , pb (N ) s.t. interpretation validating
s.t. JaKI = JbKI . cT (N ) = 0, closure rule applies pa , pb impossible.
Hence cT (N ) = 0 particular implies propositionally satisable (i.e.
contains pair complementary literals). Thus (N ) satisable denition
satisable.

635

fiAravantinos, Caferra & Peltier

Theorem 5.19 (Soundness Completeness w.r.t. Satisfiability)
Let (T )I derivation.
exists s.t. contains irreducible, closed leaf T0 satisable.
derivation fair T0 satisable exist leaf
irreducible neither closed blocked.
Proof
rst item (i.e. soundness) follows Lemmata 5.17 5.18.
prove procedure complete w.r.t. satisability (the second item). Let
interpretation schema. dene mI () follows:
mI () = 0 arithmetic atom (i.e. atom form . . . < . . .).
def

mI () = 1 indexed proposition negation, .
def

mI (1 2 ) = mI (1 ) + mI (2 ) {, }.
def

mI (bi=a ) = 2 JbKI < JaKI
def


def
mI (bi=a ) = + 2 + = mI[/] () { , }, = JaKI , = JbKI ,
.
set, mI () = {mI () | }. tableau N leaf
def
mI (N, ) = (mI (T (N )), cT (N )) cT (N ) dened proof Lemma 5.18.
measure ordered using multiset lexicographic extensions usual ordering
natural numbers. Thus, obviously well-founded. need following:
def

Lemma 5.20
Let interpretation. Let tableau. deduced applying
extension rule leaf N s.t. |= (N ), every child N N s.t.
|= (N ), mI (N , ) < mI (N, ).
Proof
rules except iteration rule closure rule replace formula simpler ones,
hence easy see mI (T (N )) decreases. iteration rules replace iteration
length either disjunction/conjunction iterated disjunction/conjunction
length 1, smaller formula. Since > 1, mI (T (N )) decreases. closure
rule aect mI (T (N )) obviously decreases cT (N ).

Let model T0 . Proposition 5.6, assume minimal w.r.t
ordering < introduced Denition 5.4.
Lemma 5.17, I, contains leaf N s.t. |= (N ). Let s.t.
mI (N , ) minimal ( exists since mI (Ni , Ti ) well-founded). Assume rule applied
N derivation, tableau . Lemma 5.17 child N N
s.t. |= (N ). Lemma 5.20 mI (N , ) < mI (Nk , ) impossible.
Thus rule applied N . Assume N blocked. exists node N
s.t. N loops N . Denition 5.4 exists interpretation J s.t. J |= N
636

fiDecidability Undecidability Results Propositional Schemata

J <V I. Lemma 5.17 (only implication), J |= T0 , contradicts
minimality I. Since derivation fair, N irreducible (or another leaf
irreducible). Furthermore, N cannot closed since satisable (I |= (N )).
worth emphasizing stab sound complete (w.r.t. satisability)
schema, bound-linear regular ones. termination result next
section holds regular schemata.
5.5 Termination Regular Schemata
consider following strategy ST applying extension rules:
propositional extension rules, looping closure rules applied soon
possible leaves, highest priority. rules obviously terminate
schema.
iteration rules applied iterations maximal length (w.r.t. natural
ordering arithmetic expressions). instance
schema
n partial
n1
n
p

q


iteration
rules


apply


rst
iteration

j
i=1
j=1
i=1 pi .
relation introduced Section 5.2 used block looping nodes.
Theorem 5.21
ST terminates every regular schema.
Proof
Let , , , Z regular schema aligned [, n ], propagation limits , .
Assume innite branch constructed. denition strategy,
time, last ranks every iteration unfolded iteration rules. Thus
remaining iterations form n
arithmetic constraint
i=
n + 1 0, i.e. n + + 1.
on, consider nodes irreducible w.r.t. propositional rules.
show nite set formulae generated stab, shift n.
consequence looping rule must apply, worst possible formulae
generated.
arithmetic formulae occurring initial formula must form .n >
.n < . last ranks unfolded, constraint n + + 1
must added. Thus suciently big, .n > equivalent .n <
equivalent . Thus every arithmetic formula occurring initial formula either
false redundant w.r.t. n + + 1. remaining arithmetic formulae must
introduced closure rule (since iterations contain occurrence <).
necessarily form = b a, b arithmetic expressions (appearing
indices formula derivation). a, b contain n, a, b Z
= b equivalent either . Thus consider case contains
n b Z. occurs initial formula must form .n +
, Z. Since n + + 1, suciently big, disequation .n + = b
must false. occur initial formula must come ( )th
unfolding iteration, [0, 1]. Since (by denition regular schema)
637

fiAravantinos, Caferra & Peltier

indices form + , [, ], disequation actually form
n + + = b, [, ], [0, 1] (since iteration counter may
replaced n , n 1, . . . , n + 1) b occurs initial formula.
previous equation equivalent , then, since constraint n ++1,
must [0, b + 1 ]. Hence nitely many formulae,
translation n 7 n .
Now, consider non arithmetic formulae occurring branch. schemata
must either iterations literals (by irreducibility w.r.t. propositional extension
rules).

iterations form n
, n
i=
i= iteration occurring
initial formula. Obviously, number iterations nite translation
n 7 n .
literals occurring branch (but scope iteration) either
literals initial schema literals introduced previous applications iteration
rules. former indexed expressions form n + , Z
latter n + , [ + 1, + ].
literal indexed expression n + outside [ + , n + ],
must pure every iteration, hence (by irreducibility w.r.t. closure rule) must
pure node. Actually, large enough then, arithmetic constraints,
n + cannot [ + , n + ] = 0. Indeed, negative,
suces take > +
+ 1 ensure n + < + , otherwise

enough n + > n + (as , n 1). Thus every literal indexed
integer terms form pure, since denition index cannot uniable
index occurring iteration (after unfolding).
Similarly literals indexed expressions form n + > pure,
thus may assume [, ]. Consequently nitely many literals
shift n 7 n .
implies number possible schemata obtained unfolding steps
nite, translation n. pigeonhole principle, looping rule necessarily
applies point branch, contradicts initial assumption innite
branch constructed.

Termination strategy also ensures fairness:
Lemma 5.22
derivation constructed ST (applied irreducibility) fair.
Proof
Let (T )I derivation constructed ST. Since ST terminates, cannot
innite derivation, thus necessarily form [0, ] N. denition,
every node either blocked closed irreducible (the strategy applied
irreducibility). contains closed irreducible leaf proof completed (by
denition notion fairness). Otherwise, consider . Let N
irreducible, closed blocked leaf occurring . Assume
s.t. rule applied N (which would contradict denition fairness).
means extension possibly aect N , thus N must also occur nal tableau
638

fiDecidability Undecidability Results Propositional Schemata

(and labeled set schemata ). Thus N must closed
irreducible. Moreover cannot blocked , since rule aect nodes
branch behind N . impossible since nodes must either blocked
closed irreducible.

immediate corollary, following:
Theorem 5.23
satisability problem decidable bound-linear schemata.
Proof
Theorems 4.12 4.13, every bound-linear schema transformed satequivalent regular one. Theorem 5.21 shows stab terminates every regular schema,
hence Theorem 5.19 Lemma 5.22, stab used decide satisability
problem regular schemata.

ne analysis previous termination proof ensures solve satisability problem regular schemata exponential time (if natural numbers written
unary notation). seen furthermore (Theorem 4.9) translation boundlinear schemata regular ones exponential, conclude satisability
problem bound-linear schemata solved double exponential time.
5.6 Model Building
existence non closed irreducible branch ensures root schema satisable,
shown Theorem 4.12. arithmetic constraints branch specify possible
values parameter. remaining formulae must literals, since extension rules
apply complex formula (in particular, iteration schema).
literals specify truth value propositional variables exactly usual case
propositional logic (the value propositional variables appear branch
may chosen arbitrarily). Since branch closed, cannot contain pair
complementary literals.
illustrate construction simple example. consider following tableau:
pn , q2 , r1 ,

n 1,

n1
i=1

n

i=1 (pi

qi ri )

n 1, pn qn rn

(pi qi ri )

pn , qn , rn
n 1,

n2
i=1

pi qi ri

...

n 1 1, pn1 qn1 rn1
pn1 , qn1 , rn1
n 1 = n, n 1 = 2, n 1 = 1

(1)
639

n = n



fiAravantinos, Caferra & Peltier

branch (1) irreducible. contains following formulae: pn , q2 , r1 , n1 1,
pn1 , qn1 , rn1 , n 1 = n, n 1 = 2, n 1 = 1. value n determined
nding solution arithmetic constraints. choose instance solution
n = 4. instantiation get remaining formulae: {p4 , q2 , r1 , p3 , q3 , r3 },
gives instance following interpretation p, q r: p true = 4 q , r
true = 3. easy check obtained interpretation satises initial
schema.
possible extension simple algorithm would be, given tableau, compute
symbolic representation whole set models root schema. set innite
must dened induction. closed irreducible branches correspond concrete
models, base cases, whereas loops correspond inductive construction rules.
rules take model construct new model J strictly greater cardinality (the
values parameters increase strictly). would require dene formal language
denoting sets interpretations (one could use, e.g., automata recognizing sequences
tuples Boolean values).
5.7 System
decision procedure implemented program (called RegStab) freely
available web page http://regstab.forge.ocamlcore.org/. written OCaml
successfully tested MacOSX (10.5), Win32 (Windows XP SP3) GNU Linux
(Ubuntu 9.04) x86 platforms. system comes manual including installation
usage instructions description input syntax. Functions dened make
input le readable (see Sum(i) Carry(i) below). input le
adder example Section 5.3.2.
// A+0=A
let Sum(i)
let Carry(i)
let Adder
let NullB
let Conclusion

:=
:=
:=
:=
:=

S_i <-> (A_i (+) B_i (+) C_i)
C_i+1 <-> (A_i /\ B_i \/ C_i /\ A_i \/ C_i /\ B_i)
/\i=1..n (Sum(i) /\ Carry(i)) /\ ~C_1
/\i=1..n ~B_i
\/i=1..n (A_i (+) S_i)

Adder() /\ NullB() /\ Conclusion()
software simply prints status schema (satisable unsatisable). Options
provided get information search space (number inference rules,
depth unfolding etc.), see manual details. additional tool oered expand
schema propositional formula DIMACS format (by xing value n).
Figure 4 gives examples problems solved RegStab
corresponding running times (please refer distribution input les additional
information).
example output, proving 0 neutral element carry-propagate
adder. ran system verbose mode, prints useful information
search: number application extension rules, number closed looping leaves,
unfolding depth set lemmata (companion nodes).
640

fiDecidability Undecidability Results Propositional Schemata

Ripple-carry adder
x+0=x
commutativity
associativity
3+4=7
x + = z1 x + = z2 z1 = z2
Carry-propagate adder
x+0=x
commutativity
associativity
equivalence two dierent denitions adder
equivalence ripple-carry adder
Comparisons bit-vectors
x0
Symmetry (i.e. x x x = y)
Totality (i.e. x > x y)
Transitivity
12
Presburger arithmetic bit vectors
x+y x
x1 x2 x3 x1 + x2 + x3 +
x1 x2 y1 y2 x1 + y1 x2 + y2
x1 x2 x3 y1 y2 y3 x1 + y1 x2 + y2 x3 + y3
1x+y 5x3y 4
iterations factorized

automata
inclusion
n

Pi ni=1 Pi
i=1
P1 ni=1 (Pi Pi + 1) Pn+1 |n 0
model checking safety property
Figure 4: Experimental Results

641

0.017s
0.267s
28.902s
2.719s
0.490s
0.016s
0.165s
8.522s
0.164s
0.194s
0.004s
0.009s
0.006s
0.011s
0.010s
0.026s
1m42s
2.949s
46m57s
7m9s
2m14s
2.324s
0.001s
0.001s
5.251s

fiAravantinos, Caferra & Peltier

Conjecture:
(((/\i=1..n ((S_i <-> ((A_i (+) B_i) (+) C_i)) /\
(C_i+1 <-> (((A_i /\ B_i) \/ (C_i /\ A_i))
\/ (C_i /\ B_i))))) /\ ~C_1) /\ (/\i=1..n ~B_i)) /\
(\/i=1..n (A_i (+) S_i))

Applications tableau rules:
/\: 67
\/: 84
(+): 38
<->: 32
->: 0
Iterated /\: 12
Iterated \/: 3
------Total propositional rules: 221
Total iterated rules:
15
Number closed leaves: 137
Number looping leaves: 30
Number lemmas:
4
Maximum number unfoldings: 3
(if number surprising, notice tableau
constructed depth-first)
Lemmas:
[\/i=1..n (A_i (+) S_i) ; /\i=1..n ((S_i <-> ((A_i (+) B_i) (+) C_i))
/\ (C_i+1 <-> (((A_i /\ B_i) \/ (C_i /\ A_i)) \/ (C_i /\ B_i)))) ;
/\i=1..n ~B_i ; ~C_1]
[\/i=1..n-1 (A_i (+) S_i) ; /\i=1..n-1 ((S_i <-> ((A_i (+) B_i) (+) C_i))
/\ (C_i+1 <-> (((A_i /\ B_i) \/ (C_i /\ A_i)) \/ (C_i /\ B_i)))) ;
/\i=1..n-1 ~B_i ; ~C_n ; ~C_1] (n > 0)
[/\i=1..n-2 ((S_i <-> ((A_i (+) B_i) (+) C_i)) /\ (C_i+1 <-> (((A_i /\ B_i)
\/ (C_i /\ A_i)) \/ (C_i /\ B_i)))) ;
/\i=1..n-2 ~B_i ; C_n-1 ; ~C_1] (n > 1)
[\/i=1..n-2 (A_i (+) S_i) ; /\i=1..n-2 ((S_i <-> ((A_i (+) B_i) (+) C_i))
/\ (C_i+1 <-> (((A_i /\ B_i) \/ (C_i /\ A_i)) \/ (C_i /\ B_i)))) ;
/\i=1..n-2 ~B_i ; C_n-1 ; ~C_1] (n > 1)
UNSATISFIABLE

642

fiDecidability Undecidability Results Propositional Schemata

6. Undecidability Results
provide undecidability results two natural extensions class regular
schemata.
6.1 Homothetic Transformations Iteration Counters
consider class schemata Ch dened follows.
Definition 6.1
Ch (h stands homothetic) set schemata satisfying following properties:
contains one parameter n.


Every iteration form ni=1 ni=1 , where:
contains iteration.
Every atomic formula belongs {pi , p2i , pi1 , p2i1 } p variable.
atomic formulae occurring scope iteration
form p0 pn p variable9 .
Ch rather simple close class regular schemata. one
parameter n, iterations bounds 1 n, nested iteration
indices symbol P must ane images iteration counter.
dierence regular class that, Ch coecient iteration counter
indexed variables may equal 2 whereas must equal 0 1 regular schemata.
Thus regular schemata contain translations iteration counter, whereas Ch may
involve (very simple) homothetic transformations.
Due closeness, one could expect satisability problem decidable
Ch , next theorem shows case.
Theorem 6.2
set unsatisable formulae Ch recursively enumerable.
proof Theorem 6.2 dicult remaining part section devoted
it. precisely, shall prove Post correspondence problem encoded
Ch . Notice problem easily encoded general schemata (Aravantinos
et al., 2009b), whereas, here, whole diculty proof lies strong restrictions
imposed Ch . Observe dicult proof really worth one would easily believe
allowing multiplication constant unsignicant change.
6.1.1 Notations
rst recall basic denitions introduce useful notations. Let
alphabet. Let natural number. Let = (a1 , . . . , ) b = (b1 , . . . , b ) two
sequences words . w {a, b} [1, ], |w | denotes length w w
denotes -th character word w (1 |w |).
9. Notice p0 pn occur scope negation.

643

fiAravantinos, Caferra & Peltier

= (1 , . . . , ) sequence indices [1, ] w = (w1 , . . . , w ) -tuple
words (where w {a, b}) denote w word w1 . .w (where .
denotes concatenation operator). solution Post correspondence problem
sequence s.t. = b . witness solution word .
technical convenience, assume (this obviously restrictive) > 1,
= , = < = b = special character (not occurring
a1 , . . . , a1 , b1 , . . . , b1 ) denoting end sequence.
6.1.2 Overview Encoding
intuition behind encoding following. show encode instance
problem schema satisable instance solution.
precisely, construct parameter n s.t. N , [/n] satisable
solution length .
rst present encoding used represent potential solutions b ;
see check really solutions. represent potential solution
w (where w = a, b) one-dimensional array length n. precisely, store
characters rather, character, pair containing index
word w occurs position word (as shall see useful
nd next character w ). instance rst index contain pair (1 , 1)
(rst word, rst character). next index contains either (1 , 2) (if |w1 | > 1, rst
word, second character) (2 , 1) (if |w1 | = 1, second word, rst character).
example, = {, , }, = (, ) = (1, 2), obtained array would
following one:
Values
Indices

(1, 1)
1

(1, 2)
2

(2, 1)
3

However, word w stored consecutive indices array. Indeed,
shall see, also need store, character w witness, indices
+1 , . . . , remaining words, occurring w w . sequence called
tail potential solution. Since length sequence unbounded, cannot
encoded simply indexed propositions: must stored array simplest
solution store indices character itself. Notice indices
words stored tail i.e. character position. Thus get:
Values
Indices

(1, 1)
1

2
2

(1, 2)
3

2
4

(2, 1)
5

easiest way proceed would store rst character witness position
0, indices remaining words position 1, 2, . . . , , second character
witness position + 1 etc. way, -th character witness would
stored position ( 1) ( + 1) following characters sequence positions
( 1) ( + 1) + 1, . . . , ( 1) ( + 1) + . character stored index , next
character would stored index + + 1. simple solution suitable
outside considered class. Indeed, requires use another parameter
(the rst parameter n: length array) also use parameter
644

fiDecidability Undecidability Results Propositional Schemata

indices (to relate character stored index one index + ),
forbidden class Ch .
Thus need nd another encoding previous array. idea store rst
character index (where assumed greater ), second character
index 2 , . . . generally -th character index 21 .
tail sequence stored indices ( + 1) 21 , . . . , ( + ) 21 .
encoding ensures index next character one index simply 2.i,
homethetic transformations precisely allowed indices Ch .
Finally, array corresponding recurrent example following one (with
= 2):
Values
Indices

1

(1, 1)
2

2
3

(1, 2)
4

2
5

6

7

(2, 1)
8

witness obtained considering characters stored indices 2,4 (= 2 2)
8 (= 222 ), namely (rst character rst word), (rst word, second character),
(second word, rst character). Obviously holes array,
simply ignored.
6.1.3 Signature
array encoded two indexed propositions: car(w, , ) t(w, ) (t stands
tail) w {a, b}, 1 , 1 |w |. intuition behind car(w, , )l
holds index l array corresponding w contains pair (, ) (representing
character w ). t(w, )l states index l array corresponding w contains
.
6.1.4 Formal Definition Encoding
Let n variable (intended denote unique parameter schema).
explained previous section, store characters array, indices
, 2, 4, etc. Intuitively, encoded another parameter, one parameter n allowed. However, encode new proposition symbol P. rst
dene two symbols p, q s.t. p holds = s.t. q holds [0, 1]. rst
schema denes q way holds exactly interval form [0, 1]:
q0 qn

n


(qi+1 qi )

i=1

last formula obviously implies q holds [1..n] must also
hold every [1..]. simply rst index q hold (this
element necessarily exists, since qn hold).
second schema denes p holds exactly successor maximal
element interval (i.e. ). Notice due previous formula must = 0
n:
n


[pi (qi1 qi )]

i=1

645

fiAravantinos, Caferra & Peltier

sake clarity, shall denote ( = ) atom p ( < ) atom
q (this makes formulae much readable).
dene variable wt s.t. wt holds exists N s.t. = .2 : wt stands
witness, wt holds index character witness solution,
explained before:
n

i=1 [((i

= ) wti ) ((i < ) wti )

(1)

((2i + 1 = ) wt2i+1 ) ((2i < ) (2i = )) (wti wt2i )]
rst line states wt holds wti false < . second line denes
value wti > : wt2i+1 always false (except 2i + 1 = ) wt2i equivalent
wti 2i > . easy induction set natural numbers, properties imply
wt holds . = .2 . Notice crucial use homothetic transformation
here.
following formula states index cannot represent two distinct characters
(pairs) sequence:
n


(car(w, , )i car(w, , )i )

i=1

every w {a, b}, (, ) [1, ]2 , [1, |w |], [1, |w |] s.t. (, ) = ( , )
Similarly, state every index contains one word sequence:
n


(t(w, )i t(w, )i ) every w {a, b}, , [1, ]2 , =

i=1

initial elements sequences corresponding b must form
(, 1) ( sequences distinct , since word |w | marks
end sequence):
n


((i = ) [1, 1](car(a, , 1)i car(b, , 1)i ))

i=1

use existential quantication intervals natural numbers sake clarity,
quantiers easily eliminated transformed nite (not iterated )
disjunctions.
next formula denes e(w) mark end sequence corresponding w.
e(w)l hold l form .2 > 0 character stored
index l rst character word (remember convention = b =
marks end witness). Besides, must ensure end sequence
eventually reached i.e. exists index l e(a)l e(b)l hold:
n


(e(a)i e(b)i )

i=1

n


((wti car(w, , 1)i ) e(w)i )

i=1

646

()

fiDecidability Undecidability Results Propositional Schemata

every w {a, b}
also ensure two sequences (i.e. words b ) identical.
suces check every index l s.t. wtl holds (i.e. every index l form
2 ), character stored l sequences b:
n


(wti (car(a, , )i car(b, , )i ))

()

i=1


every , [1, ]2 , [1, |a |], [1, |b |] s.t. = b

far, ensured one character word index stored
every index. dened starting point end two sequences
ensured two represented words identical. next (and dicult) step
ensure sequences really encode two words form b respectively.
aim, shall relate value character stored every index .2+1
one stored .2 , ensure former really successor latter
witness. Since character c represented pair (, ) denotes index
word w position c w , easy nd next character: < |w |
(i.e. c last character w ) next character simply (, + 1) (same
word w , next position + 1). = |w | (i.e. c last character w ) next
character ( , 1) denotes next word index solution sequence (word w ,
rst position).
order determine index word use fact (as explained
informal overview above) remaining indices solution stored index
.2 + 1, .2 + 2, . . .. Thus, simply need pick rst element sequence.
checking character stored .2+1 successor one .2
remains ensure indices stored .2+1 + 1, .2+1 + 2,. . . correspond
remaining part solution. < |w | sequence must actually identical
one stored .2 + 1, .2 + 2,. . . = |w | rst element sequence
must deleted (since entered new word).
next formula states index l form .2 (i.e. index s.t. wtl holds)
contains pair (, ) w contains characters .2+1 encode
next character word w , namely (, + 1). Moreover tail sequence
change, expressed using variable c(w)l (c stands copy)
specied thereafter:
n


[(wti car(w, , )i ) (car(w, , + 1)2i c(w)i+1 )]

(2)

i=1

every w {a, b}, [1, ], [1, |w | 1].
dene formula encoding copy tail. simple way proceed
would copy values stored indices l, l+1, . . . , l+1 2l+1, . . . , 2l+1.
Unfortunately cannot done simple way expressions form l + j
647

fiAravantinos, Caferra & Peltier

would required indices, forbidden class (only 1 added).
explained before, overcome problem copying indices l + 1, . . . , l + 1
2l + 2, 2l + 4, . . . , 2l + 2 2, done doubling iteration counter.
indices 2l + 1, 2l + 3, . . . , 2l + 2 1 left empty (holes). disturbing since
empty indices simply ignored. important consequence length
sequence doubled time copied (we assume value parameter
n natural number suciently large ensure enough space
array).
expressed following formula:
n


(c(w)i [t(w, )2i1 (t(w, )i t(w, )2i ) (wti+1 c(w)i+1 )])

(3)

i=1

every [1, ], w {a, b}
illustrate construction example. Let = {, , , }, = (, , )
= (1, 2, 3). second line, provide every index l pair (, )
car(a, , )l holds (if any). third line gives represented character (,, ).
fourth line provide integer t(a, )l holds. fth line gives value
c(a). indices + 2 2 empty (we assume = 3).

car
character

c(a)


(1, 1)


+1

+2

2


3


2
(1, 2)


2 + 1

2 + 2

2

2 + 3

2 + 4

3

formula (2) must c+1 . formula (3), value c(a)+1 propagated
c(a)+2 ,. . . , c(a)21 (it propagated c(a)2 since wt2 holds). Still (2),
c(a)l holds t(a, )l t(a, )2l , cells corresponding odd indices
left empty. Thus get array above.
index .2 contains pair (, ) |w | = (such 2 previous example),
one must proceed next word. aim, need know rst
character next word (after current one). holes introduced
special copying mechanism, next word necessarily index l+1. simple solution
change contents tail element contains index
word also rst character. stated following formula:
n


[wti (t(w, )i car(w, , 1)i )]

(4)

i=1

Furthermore, copy character holes preceding element.
particular case get wanted rst non-empty word.10 stated
10. Notice could well copied words index instead rst character, since index
contains information need retrieve corresponding character. However useful
following know word index stored particular cell, store
information useful problem want solve point, i.e. rst character
word.

648

fiDecidability Undecidability Results Propositional Schemata

following formula:
n


[(wti1 wti [1, ] t(w, )i1 ) (car(w, , 1)i car(w, , 1)i1 )]

(5)

i=1

every [1, ], w {a, b}
Now, pair stored (, |w |) word nal word
sequence (i.e. e(w) hold) one store 2 rst character
next word, is, due two previous formulae, character represented + 1.
previous picture must thus completed follows:

car
character



(1, 1)


+1
(2, 1)

2

+2
(3, 1)

3

2
(1, 2)


2 + 1
(2, 1)


2 + 2
(2, 1)

2

2 + 3
(3, 1)


2 + 4
(3, 1)

3

formula (4) above, t(a, )i holds car(a, , 1)i also holds.
formula (5), value car(a, , 1)l recursively propagated car(a, , 1)l1
l 1 = .2 t(a, )l1 holds . Notice character stored
every index l characters indices .2 form witness.
Thanks trick, nding next character one stored .2
trivial: simply one stored .2 + 1, which, previous formula, actually
corresponds rst position word stored ( + 1).2 (of course, also need
check character nal). expressed following formula:
n


[(wtl e(w)l car(w, , |w |)l ) (car(w, , 1)2l car(w, , 1)l+1 ) s(w)l+1 ]

l=1

every , [1, ], w {a, b}
propositional variable s(w)l+1 (s stands shift) indicates tail 2l
obtained removing rst word tail l. done follows: indices
2l + 2, . . . , 2l + 2 1 obtained copying indices l + 1, . . . , l + 1, except
rst one, left empty. c(w), indices 2l 1, . . . , 2l + 2 3 empty. s(w)
dened three following formulae.
s(w) actually erases everything nds non-empty index, expressed
rst formula: s(w)l holds indices stored 2l 2l 1 must empty
(furthermore, also check end tail reached):
n


(s(w)l wtl t(w, )2l t(w, )2l1 ) every [1, ], w {a, b}

l=1

second one propagates erasure current index empty:
649

(6)

fiAravantinos, Caferra & Peltier

n


[(s(w)l wtl+1 [1, ] t(w, )l ) s(w)l+1 ] every w {a, b}

(7)

l=1

third one states reached non-empty index go
copying everything (which done using previous variable c(w)):
n


(s(w)l [1, ] t(w, )l c(w)l+1 ) every w {a, b}

(8)

l=1

illustrate construction showing erasure works previous example:


car
character


4
(2, 1)



car
character

c(a)
s(a)

2
(1, 2)


4 + 1
(3, 1)


4 + 2
(3, 1)


2 + 1
(2, 1)


2 + 2
(2, 1)

2





4 + 3
(3, 1)


4 + 4
(3, 1)


2 + 3
(3, 1)



2 + 4
(3, 1)

3


4 + 5
(3, 1)


4 + 6
(3, 1)


4 + 7
(3, 1)


4 + 8
(3,1)

3

character stored 2 last one rst word thus remove rst
word tail solution. explained before, character stored 4
one stored 2+1, namely (2, 1), i.e. (since car(a, , 1)4 car(a, , 1)2+1 ).
Furthermore, s(a)2+1 holds. implies (6) indices 4 + 2 4 + 1
must empty. Since empty = 2 + 1 (i.e. t(a, )2+1
holds), value s(a)2+1 propagated s(a)2+2 , (7). Thus (6), indices
4 + 4 4 + 3 must also empty. time, however, t(a, 2)2+2 holds. Thus
value s(a) propagated c(a)2+3 must hold (by (8)). before, implies
remaining part sequence (i.e. cells 2 + 3, 2 + 4 t) copied (in
cells 4 + 6, 4 + 8, leaving cells 4 + 5, 4 + 7 empty) 4 reached. implies
particular t(a, 3)4+8 holds (since t(a, 3)2+4 holds). Hence car(a, 3, 1)4+8 .
Since empty l [4 + 1, . . . , 4 + 7], value car(a, 3, 1) propagated
indices 4 + 7, . . . , 4 + 1 explained before. obtain desired result, i.e. rst
word sequence (namely 2) erased rst character next word
stored 4 + 1.
Finally, order ensure obtained sequence really solution Post
correspondence problem, remains check two sequences identical, i.e.
words contained + 1, , 2 1 sequences b.
purpose dene variable rl true l < 2.
650

fiDecidability Undecidability Results Propositional Schemata

r0 rn

n


[(rl rl1 ) (l = ) (r2l1 r2l )]

()

l=1
n


[(rl (l < )) (t(a, )l t(b, )l )]

()

l=1

every [1, ]
straightforward check obtained formula Ch . reader acquainted
Posts correspondence problem shall convinced obtained formula
satisable exists solution Post problem, thus skip end
section. Otherwise give following sketch formal steps proof.
denote conjunction formulae, except formulae marked ().
rst notice satisable (for every value n). Indeed, explained before,
formulae impose that:
exists unique natural number p holds = q holds
[0, 1].
car(w, , ) t(w, ) encode (partial) functions fw , gw mapping every index [1, n]
pair (, ) (where [1, ], [1, |w |]) word index [1, ] respectively.
Moreover must fa () = (, 1) fb () = (, 1) [1.. 1].
wt holds exists N s.t. = .2 .
obviously denes partial interpretation. remaining formulae simply give values car(w, , ) , t(w, ) , c(w) , s(w) 2. easy check
distinct formulae cannot give distinct values propositional variable, hence
satisability guaranteed.
Let interpretation . Let [1..n]. dene following sequences.
hw () sequence word indices dened follows: wt+1 holds hw ()
def
empty. Otherwise, gw () = hw () = .hw ( + 1) gw () undened
def
hw () = hw ( + 1). Intuitively, hw () sequence word indices stored juste
(i.e. tail) ignoring empty cells.
jw () word dened follows: > n jw () empty. Otherwise, jw () =
def
w .jw (2) fw () pair (, ) distinct (, 1), jw () = fw () = (, 1)
def
jw () = jw (2) fw () undened. jw () denotes word stored cells , 2 . . .
array corresponding w ((, 1) marks end word).

def

fw () = (, ) kw () denotes sux length |w | + 1 word w
(notice construction must ||).
denition copying/erasing mechanism above, fw (.2 ) form (, |w |)
(i.e. end word ) hw (.2 ) = .hw (.2+1 ), fw (.2+1 ) =
651

fiAravantinos, Caferra & Peltier

( , 1) (i.e. tail equal next word followed next tail). Otherwise (i.e.
middle word) hw (.2 ) = hw (.2+1 ) fw (.2+1 ) = (, + 1)
fw (.2 ) = (, ) ( = |w |)). easy induction length jw (.2 ),
deduce jw (.2 ) prex kw (.2 ).whw (.2 ) : kw (.2 ) represents end
word considered character , whw (.2 ) concatenation words
tail.
= 0 get particular jw () prex kw ().whw () . denition
kw () = w (not depending w). Thus jw () prex w.hw () .
formulae occurring conjunction check ha () = hb () (same
sequence word indices b), ja () = jb () ja () ends
character (marking end witness).
model whole formula, jw () prex w.hw () , ending ,
thus must form w. prex hw (). Hence . solution
Posts correspondence problem.
Conversely, solution . exists, simply consider model
ha () = hb () = (this implies > ||, notice values fw (l) gw (l)
xed arbitrarily l < 2) I(n) > .2 , = |a. |. jw () prex
w.hw () . Since length jw () cannot greater one w. , jw () must end
. Thus must jw () = w. (since last character w. ). Moreover
since . solution ja () = jb (). Thus validates formulae above.
6.2 Unbounded Translation
One wonder whether decidability class regular schemata still holds
unbounded translations allowed indices, i.e. translations form +
denotes iteration counter parameter (the case Z covered regular
class). following denition theorem show answer negative.
Definition 6.3
Ct (t stands translation) set schemata satisfying following properties.
contains two parameters n, m.


Every iteration form ni=1 ni=1 , where:
contains iteration.
Every atomic formula form p.i++.m , p variable,
, {0, 1} {1, 0, 1}.
atomic propositions occurring scope iteration
form p0 pn p variable.
Theorem 6.4
set unsatisable formulae Ct recursively enumerable.
Proof
(Sketch) detail proof since similar previous one. reuse
encoding proof Theorem 6.2, except pairs (, ) array
652

fiDecidability Undecidability Results Propositional Schemata

stored indices form + instead .2 . Formally, formulae (1), (2),
(3) (6) replaced following ones, respectively:
n


[((l = ) wtl ) ((l < ) wtl ) ((l < ) (l = )) (wtl wtl+m )]

l=1

(i.e. wtl holds exists s.t. l = + m).
n


[wtl car(w, , )l (car(w, , + 1)l+m c(w)l+1 )]

l=1

(i.e. index 2l replaced l + m).
n


(c(w)l [(t(w, )l t(w, )l+m ) (wti+1 c(w)l+1 )])

l=1

n


(s(w)l wtl t(w, )l+m )



l=1

7. Conclusion
introduced rst (to best knowledge) logic reasoning iterated
propositional schemata. dened class schemata called bound-linear
satisability problem decidable. decidability proof constructive divided
two parts: rst show transform every bound-linear schema sat-equivalent
schema simpler form, called regular. proof procedure dened decide
satisability regular schemata. proof procedure sound complete w.r.t.
satisability every schema (even regular bound-linear) terminates
every regular schema. Termination relies special looping detection rule.
procedure implemented software RegStab.
class bound-linear schemata expressive enough capture specications
many important problems AI, especially automated (or interactive) theorem proving (e.g., parameterized circuit verication problems). proved even slight
relaxation conditions bound-linear schemata makes satisability problem undecidable (this shown tricky reduction Post correspondence problem).
consequence, bound-linear schemata considered canonical decidable class,
providing good compromise expressivity tractability.
future work, two ways promising. Firstly, extension
previous results particular classes
non-monadic schemata (i.e. schemata containing
nof
symbols several indices, e.g., i=1 nj=1 pi,j ) would enlarge considerably applications
propositional schemata. Secondly, extending approach expressive logics,
653

fiAravantinos, Caferra & Peltier

rst-order logic, description logics modal logics, also deserves considered.
presented results extend straightforwardly many-valued propositional logic
(provided number truth values xed nite). would allow capture
innite constraint satisfaction languages.

Acknowledgments
work partly funded project ASAP French Agence Nationale de
la Recherche (ANR-09-BLAN-0407-01). authors wish thank anonymous referees
insightful comments helped improve earlier version paper.

References
Aczel, P. (1977). Introduction Inductive Denitions. Barwise, K. J. (Ed.), Handbook
Mathematical Logic, pp. 739782. North-Holland, Amsterdam.
Aravantinos, V., Caferra, R., & Peltier, N. (2009a). DPLL proof procedure propositional iterated schemata. Workshop Structures Deduction 2009 (ESSLI),
pp. 2438.
Aravantinos, V., Caferra, R., & Peltier, N. (2009b). schemata calculus propositional
logic. TABLEAUX 09 (International Conference Automated Reasoning
Analytic Tableaux Related Methods), Vol. 5607 LNCS, pp. 3246. Springer.
Aravantinos, V., Caferra, R., & Peltier, N. (2010). Decidable Class Nested Iterated
Schemata. IJCAR 2010 (International Joint Conference Automated Reasoning),
LNCS, pp. 293308. Springer.
Baaz, M. (1999). Note generalization calculations. Theoretical Computer Science,
224, 311.
Baaz, M., & Zach, R. (1994). Short proofs tautologies using schema equivalence.
Computer Science Logic (CSL93), Vol. 832 LNCS, pp. 3335. Springer-Verlag.
Baelde, D. (2009). proof theory regular xed points. Proceedings 18th
International Conference Automated Reasoning Analytic Tableaux Related
Methods (TABLEAUX 2009), Vol. 5607 LNCS, pp. 93107. Springer.
Barendregt, H., & Wiedijk, F. (2005). challenge computer mathematics. Philosophical
Transactions Royal Society A, 363, 23512375.
Bouhoula, A., Kounalis, E., & Rusinowitch, M. (1992). SPIKE, automatic theorem
prover. Proceedings International Conference Logic Programming
Automated Reasoning (LPAR92), Vol. 624, pp. 460462. Springer-Verlag.
Boyer, R. S., & Moore, J. S. (1979). computational logic. Academic Press.
Bradeld, J., & Stirling, C. (1992). Local model checking innite state spaces. Selected
papers Second Workshop Concurrency compositionality, pp. 157174,
Essex, UK. Elsevier Science Publishers Ltd.
654

fiDecidability Undecidability Results Propositional Schemata

Bradeld, J., & Stirling, C. (2007). Modal Mu-Calculi. Blackburn, P., Benthem, J. F.
A. K. v., & Wolter, F. (Eds.), Handbook Modal Logic, Volume 3 (Studies Logic
Practical Reasoning), pp. 721756. Elsevier Science Inc., New York, NY, USA.
Brotherston, J. (2005). Cyclic Proofs First-Order Logic Inductive Denitions.
Beckert, B. (Ed.), Automated Reasoning Analytic Tableaux Related Methods:
Proceedings TABLEAUX 2005, Vol. 3702 LNAI, pp. 7892. Springer-Verlag.
Bundy, A. (2001). automation proof mathematical induction. Robinson, J. A.,
& Voronkov, A. (Eds.), Handbook Automated Reasoning, pp. 845911. Elsevier
MIT Press.
Bundy, A., van Harmelen, F., Horn, C., & Smaill, A. (1990). Oyster-Clam system.
Proceedings 10th International Conference Automated Deduction, pp.
647648, London, UK. Springer-Verlag.
Chen, H., Hsiang, J., & Kong, H. (1990). nite representations innite sequences
terms. Conditional Typed Rewriting Systems, 2nd International Workshop,
pp. 100114. Springer, LNCS 516.
Cleaveland, R. (1990). Tableau-based model checking propositional mu-calculus.
Acta Inf., 27 (9), 725747.
Comon, H. (2001). Inductionless induction. Robinson, A., & Voronkov, A. (Eds.),
Handbook Automated Reasoning, chap. 14, pp. 913962. North-Holland.
Comon, H. (1995). unication terms integer exponents. Mathematical System
Theory, 28, 6788.
Cooper, D. (1972). Theorem proving arithmetic without multiplication. Meltzer, B.,
& Michie, D. (Eds.), Machine Intelligence 7, chap. 5, pp. 9199. Edinburgh University
Press.
Davis, M., Logemann, G., & Loveland, D. (1962). Machine Program Theorem Proving.
Communication ACM, 5, 394397.
Ebbinghaus, H.-D., & Flum, J. (1999). Finite Model Theory. Perspectives Mathematical
Logic. Springer. Second Revised Enlarged Edition.
Fagin, R. (1993). Finite-Model Theory - Personal Perspective. Theoretical Computer
Science, 116, 331.
Giesl, J., & Kapur, D. (2001). Decidable classes inductive theorems. Gore, R., Leitsch,
A., & Nipkow, T. (Eds.), IJCAR, Vol. 2083 Lecture Notes Computer Science,
pp. 469484. Springer.
Gore, R. (1999). Chapter 6: Tableau Methods Modal Temporal Logics.
DAgostino, Gabbay, R Hahnle, J Posegga (Ed.), Handbook Tableau Methods,
pp. 297396. Kluwer Academic Publishers. http://arp.anu.edu.au/~ rpg (draft).
Gupta, A., & Fisher, A. L. (1993). Representation symbolic manipulation linearly
inductive boolean functions. Lightner, M. R., & Jess, J. A. G. (Eds.), ICCAD, pp.
192199. IEEE Computer Society.
Hermann, M., & Galbavy, R. (1997). Unication Innite Sets Terms schematized
Primal Grammars. Theoretical Computer Science, 176 (12), 111158.
655

fiAravantinos, Caferra & Peltier

Hetzl, S., Leitsch, A., Weller, D., & Woltzenlogel Paleo, B. (2008). Proof analysis
HLK, CERES ProofTool: Current status future directions. Sutclie G.,
Colton S., S. S. (Ed.), Workshop Empirically Successful Automated Reasoning
Mathematics (ESARM), pp. 2141.
Immerman, N. (1982). Relational queries computable polynomial time (Extended Abstract). STOC 82: Proceedings fourteenth annual ACM symposium
Theory computing, pp. 147152, New York, NY, USA. ACM.
Krajicek, J., & Pudlak, P. (1988). number proof lines size proofs
rst-order logic. Archive Mathematical Logic, pp. 6994.
Marriott, K., Nethercote, N., Rafeh, R., Stuckey, P. J., Garca de la Banda, M., & Wallace,
M. (2008). design Zinc modelling language. Constraints, 13 (3), 229267.
Orevkov, V. P. (1991). Proof schemata Hilbert-type axiomatic theories. Journal
Mathematical Sciences, 55 (2), 16101620.
Parikh, R. J. (1973). results length proofs. Transactions American
Mathematical Society, 177, 2936.
Park, D. M. (1976). Finiteness Mu-ineable. Theoretical Computer Science, 3, 173181.
Paulin-Mohring, C. (1993). Inductive Denitions system Coq - Rules Properties.
TLCA 93: Proceedings International Conference Typed Lambda Calculi
Applications, pp. 328345, London, UK. Springer-Verlag.
Smullyan, R. M. (1968). First-Order Logic. Springer.
Sprenger, C., & Dam, M. (2003). Structure Inductive Reasoning: Circular
Tree-shaped Proofs mu-Calculus. Proc. FOSSACS03, Springer LNCS, pp.
425440.
Wos, L. (1988). Automated Reasoning: 33 Basic Research Problems. Prentice Hall.
Wos, L., Overbeek, R., Lush, E., & Boyle, J. (1992). Automated Reasoning: Introduction
Applications (Second edition). McGraw-Hill.

656

fiJournal Artificial Intelligence Research 40 (2011) 729-765

Submitted 11/10; published 04/11

Exploiting Structure Weighted Model Counting
Approaches Probabilistic Inference
Wei Li

wei.li@autodesk.com

Autodesk Canada
Toronto, Ontario M5A 1J7 Canada

Pascal Poupart
Peter van Beek

ppoupart@cs.uwaterloo.ca
vanbeek@cs.uwaterloo.ca

Cheriton School Computer Science
University Waterloo
Waterloo, Ontario N2L 3G1 Canada

Abstract
Previous studies demonstrated encoding Bayesian network SAT formula performing weighted model counting using backtracking search algorithm
eective method exact inference. paper, present techniques
improving approach Bayesian networks noisy-OR noisy-MAX relations
two relations widely used practice dramatically reduce number
probabilities one needs specify. particular, present two SAT encodings
noisy-OR two encodings noisy-MAX exploit structure semantics
relations improve time space eciency, prove correctness
encodings. experimentally evaluated techniques large-scale real randomly
generated Bayesian networks. benchmarks, techniques gave speedups
two orders magnitude best previous approaches networks noisyOR/MAX relations scaled larger networks. well, techniques extend
weighted model counting approach exact inference networks previously
intractable approach.

1. Introduction
Bayesian networks fundamental building block many AI applications. Bayesian
network consists directed acyclic graph nodes represent random variables
node labeled conditional probability table (CPT) represents
strengths inuences parent nodes child node (Pearl, 1988). general,
assuming random variables domain size d, CPT child node n parents
requires one specify dn+1 probabilities. presents practical diculty led
introduction patterns CPTs require one specify many fewer parameters
(e.g., Good, 1961; Pearl, 1988; Dez & Druzdzel, 2006).
Perhaps widely used patterns practice noisy-OR relation
generalization, noisy-MAX relation (Good, 1961; Pearl, 1988). relations assume
form causal independence allow one specify CPT n parameters
case noisy-OR (d 1)2 n parameters case noisy-MAX, n
number parents node size domains random variables.
noisy-OR/MAX relations successfully applied knowledge engineering

c
2011
AI Access Foundation. rights reserved.

fiLi, Poupart, & van Beek

large real-world Bayesian networks, Quick Medical Reference-Decision Theoretic
(QMR-DT) project (Miller, Masarie, & Myers, 1986) Computer-based Patient Case
Simulation system (Parker & Miller, 1987). well, Zagorecki Druzdzel (1992) show
three real-world Bayesian networks, noisy-OR/MAX relations good
50% CPTs networks converting CPTs noisy-OR/MAX
relations gave good approximations answering probabilistic queries. surprising,
CPTs networks specied using noisy-OR/MAX assumptions
specied full CPTs. results provide additional evidence usefulness
noisy-OR/MAX relations.
consider problem exact inference Bayesian networks contain
noisy-OR/MAX relations. One method solving networks replace noisyOR/MAX full CPT representation use well-known algorithms
answering probabilistic queries variable elimination tree clustering/jointree.
However, generaland particular, networks use experimental
evaluationthis method impractical. fruitful approach solving networks
take advantage semantics noisy-OR/MAX relations improve
time space eciency (e.g., Heckerman, 1989; Olesen, Kjaerul, Jensen, Jensen, Falck,
Andreassen, & Andersen, 1989; DAmbrosio, 1994; Heckerman & Breese, 1996; Zhang &
Poole, 1996; Takikawa & DAmbrosio, 1999; Dez & Galan, 2003; Chavira, Allen, & Darwiche, 2005).
Previous studies demonstrated encoding Bayesian network SAT formula performing weighted model counting using DPLL-based algorithm
eective method exact inference, DPLL backtracking algorithm specialized
SAT includes unit propagation, conict recording, backjumping, component
caching (Sang, Beame, & Kautz, 2005a). paper, present techniques improving weighted model counting approach Bayesian networks noisy-OR
noisy-MAX relations. particular, present two CNF encodings noisy-OR two
CNF encodings noisy-MAX exploit semantics improve time
space eciency probabilistic inference. encodings, pay particular attention
reducing treewidth CNF formula. also explore alternative search ordering
heuristics DPLL-based backtracking algorithm.
experimentally evaluated encodings large-scale real randomly generated
Bayesian networks using Cachet weighted model counting solver (Sang, Bacchus, Beame,
Kautz, & Pitassi, 2004). experimental results must interpreted
care comparing encodings also implementations systems
conicting design goals, benchmarks techniques gave speedups
three orders magnitude best previous approaches networks noisy-OR
noisy-MAX. well, benchmarks many networks could
solved previous approaches within resource limits, could solved quite
quickly Cachet using encodings. Thus, noisy-OR noisy-MAX encodings
extend model counting approach exact inference networks previously
intractable approach.

730

fiExploiting Structure Probabilistic Inference

X1



X2

Xn



Figure 1: General causal structure Bayesian network noisy-OR/MAX relation,
causes X1 , . . . , Xn lead eect noisy-OR/MAX relation
node .

2. Background
section, review noisy-OR/MAX relations needed background weighted
model counting approaches exact inference Bayesian networks (for topics
see, example, Koller & Friedman, 2009; Darwiche, 2009; Chavira & Darwiche, 2008).
2.1 Patterns CPTs: Noisy-OR Noisy-MAX
noisy-OR relation one assumes dierent causes X1 , . . . , Xn leading
eect (see Figure 1), random variables assumed Booleanvalued domains. cause Xi either present absent, Xi isolation likely
cause likelihood diminished one cause present. Further,
one assumes possible causes given causes absent, eect
absent. Finally, one assumes mechanism reason inhibits Xi causing
independent mechanism reason inhibits Xj , j = i, causing .
noisy-OR relation species CPT using n parameters, q1 , . . . , qn , one parent,
qi probability false given Xi true parents
false,
(1)
P (Y = 0 | Xi = 1, Xj = 0[j,j=i]) = qi .
parameters, full CPT representation size 2n+1 generated using,

qi
(2)
P (Y = 0 | X1 , . . . , Xn ) =
iTx


P (Y = 1 | X1 , . . . , Xn ) = 1



qi

(3)

iTx

Tx = {i | Xi = 1} P (Y = 0 | X1 , . . . , Xn ) = 1 Tx empty. last condition
(when Tx empty) corresponds assumptions possible causes given
causes absent, eect absent; i.e., P (Y = 0 | X1 = 0, . . . , Xn = 0) = 1.
assumptions restrictive may rst appear. One always introduce

731

fiLi, Poupart, & van Beek

Cold

Malaria

Flu

Nausea

Headache

Figure 2: Example causal Bayesian network causes (diseases) Cold, Flu,
Malaria eects (symptoms) Nausea Headache.

additional random variable X0 parent parents. variable
X0 represents reasons could cause occur. node X0
prior probability P (X0 ) referred leak node leak probability, respectively.
follows, continue refer possible causes X1 , . . . , Xn
understood one causes could leak node.
Example 1. Consider Bayesian network shown Figure 2. Suppose random
variables Boolean representing presence absence disease symptom,
noisy-OR node Nausea node Headache, parameters
noisy-ORs given Table 1. full CPT node Nausea given by,
C
0
0
0
0
1
1
1
1

F
0
0
1
1
0
0
1
1


0
1
0
1
0
1
0
1

P (N ausea = 0 | C, F, )
1.00
0.40
0.50
0.20 = 0.5 0.4
0.60
0.24 = 0.6 0.4
0.30 = 0.6 0.5
0.12 = 0.6 0.5 0.4

P (N ausea = 1 | C, F, )
0.00
0.60
0.50
0.80
0.40
0.76
0.70
0.88

C, F , short Cold , Flu, Malaria, respectively.
alternative way view noisy-OR relation decomposed probabilistic model.
decomposed model shown Figure 3, one specify small conditional
probability table node Yi given P (Yi | Xi ), instead exponentially large
CPT given P (Y | X1 , . . . , Xn ). decomposed model, P (Yi = 0 | Xi = 0) = 1,
P (Yi = 0 | Xi = 1) = qi , CPT node deterministic given
logical relation. operator converted full CPT follows,

1, = Y1 Yn ,
P (Y | Y1 , . . . , Yn ) =
0, otherwise.

732

fiExploiting Structure Probabilistic Inference

X1

X2

Y1

Y2



Xn

Yn



OR/MAX

Figure 3: Decomposed form Bayesian network noisy-OR/MAX relation,
causes X1 , . . . , Xn lead eect noisy-OR/MAX relation node
. node double border deterministic node designated
logical relationship (OR) arithmetic relationship (MAX).

Table 1: Parameters noisy-ORs node Nausea node Headache
Bayesian network shown Figure 2, assuming random variables
Boolean.
P (Nausea = 0 | Cold = 1, Flu = 0, Malaria = 0)
P (Nausea = 0 | Cold = 0, Flu = 1, Malaria = 0)
P (Nausea = 0 | Cold = 0, Flu = 0, Malaria = 1)

=
=
=

0.6
0.5
0.4

P (Headache = 0 | Cold = 1, Flu = 0, Malaria = 0)
P (Headache = 0 | Cold = 0, Flu = 1, Malaria = 0)
P (Headache = 0 | Cold = 0, Flu = 0, Malaria = 1)

=
=
=

0.3
0.2
0.1

probability distribution eect variable given by,

n


P (Yi | Xi ) ,
P (Y | X1 , . . . , Xn ) =
=Y1 Yn

i=1

sum congurations possible values Y1 , . . . , Yn
Boolean values equal value . Similarly, Pearls (1988) decomposed
model, one specify n probabilities fully specify model (see Figure 4); i.e.,
one species prior probabilities P (Ii ), 1 n. model, causes always lead
eects unless prevented inhibited so. random variables Ii model
prevention inhibition.
two decomposed probabilistic models (Figure 3, Figure 4) shown
equivalent sense conditional probability distribution P (Y | X1 , . . . , Xn )
induced networks original distribution network shown
Figure 1. important note models would still exponentially
large CPT associated eect node deterministic node replaced
733

fiLi, Poupart, & van Beek

X1



I1

Y1









Xn

Yn





Figure 4: Pearls (1988) decomposed form noisy-OR relation. Nodes double
borders deterministic nodes designated logical relationship.

full CPT representation. words, decomposed models address ease
modeling representation issues, address eciency reasoning issues.
noisy-MAX relation (see Pearl, 1988; Good, 1961; Henrion, 1987; Dez, 1993)
generalization noisy-OR non-Boolean domains. noisy-MAX relation,
one assumes dierent causes X1 ,. . . , Xn leading eect (see
Figure 1), random variables may multi-valued (non-Boolean) domains.
domains variables assumed ordered values referred
degree severity variable. domain distinguished lowest degree
0 representing fact cause eect absent. noisy-OR relation, one
assumes possible causes given causes absent, eect absent.
Again, assumptions restrictive rst appears, one incorporate leak
node. well, one assumes mechanism reason inhibits Xi causing
independent mechanism reason inhibits Xj , j = i, causing .
Let dX number values domain random variable X. simplicity
notation without loss generality, assume domain variable X
given set integers {0, 1, . . . , dX 1}. noisy-MAX relation causes X1 , . . . ,
Xn eect species CPT using parameters,
xi
P (Y = | Xi = xi , Xj = 0[j,j=i]) = qi,y

= 1, . . . , n,

(4)

= 0, . . . , dY 1,
xi = 1, . . . , dXi 1.
domain sizes equal d, total (d 1)2 n non-redundant probabilities
must specied. parameters, full CPT representation size dn+1
generated using,

n

xi
qi,y
(5)
P (Y | X) =

i=1 =0
xi =0




P (Y 0 | X)
= 0,
P (Y = | X) =
P (Y | X) P (Y 1 | X) > 0.
734

(6)

fiExploiting Structure Probabilistic Inference

X represents certain conguration parents , X = x1 , . . . , xn ,
P (Y = 0 | X1 = 0, . . . , Xn = 0) = 1; i.e., causes absent, eect absent.
Table 2: Parameters noisy-MAX node Nausea Bayesian network shown
Figure 2, assuming diseases Boolean random variables symptom
Nausea domain {absent = 0, mild = 1, severe = 2}.
P (Nausea = absent | Cold = 1, Flu = 0, Malaria = 0)
P (Nausea = mild | Cold = 1, Flu = 0, Malaria = 0)
P (Nausea = severe | Cold = 1, Flu = 0, Malaria = 0)

=
=
=

0.7
0.2
0.1

P (Nausea = absent | Cold = 0, Flu = 1, Malaria = 0)
P (Nausea = mild | Cold = 0, Flu = 1, Malaria = 0)
P (Nausea = severe | Cold = 0, Flu = 1, Malaria = 0)

=
=
=

0.5
0.2
0.3

P (Nausea = absent | Cold = 0, Flu = 0, Malaria = 1)
P (Nausea = mild | Cold = 0, Flu = 0, Malaria = 1)
P (Nausea = severe | Cold = 0, Flu = 0, Malaria = 1)

=
=
=

0.1
0.4
0.5

Example 2. Consider Bayesian network shown Figure 2. Suppose
diseases Boolean random variables symptoms Nausea Headache
domains {absent = 0, mild = 1, severe = 2}, noisy-MAX node Nausea
node Headache, parameters noisy-MAX node Nausea given
Table 2. full CPT node Nausea given by,
C
0
0
0
0
1
1
1
1

F
0
0
1
1
0
0
1
1


0
1
0
1
0
1
0
1

P (N = | C, F, )
1.000
0.100
0.500
0.050 = 0.5 0.1
0.700
0.070 = 0.7 0.1
0.350 = 0.7 0.5
0.035 = 0.7 0.5 0.1

P (N = | C, F, )
0.000
0.400
0.200
0.300
0.200
0.380
0.280
0.280

P (N = | C, F, )
0.000
0.500
0.300
0.650
0.100
0.550
0.370
0.685

C, F , , N short variables Cold , Flu, Malaria, Nausea,
respectively, a, m, short values absent, mild, severe, respectively. example calculation, P (Nausea = mild | Cold = 0, Flu = 1, Malaria = 1) =
((0.5 + 0.2) (0.1 + 0.4)) (0.05) = 0.3 second example, P (Nausea = mild | Cold =
1, Flu = 1, Malaria = 1) = ((0.7 + 0.2) (0.5 + 0.2) (0.1 + 0.4)) (0.035) = 0.28
noisy-OR relation, alternative view noisy-MAX relation
decomposed probabilistic model (see Figure 3). decomposed model, one
specify small conditional probability table node Yi given P (Yi | Xi ),
x . models eect
P (Yi = 0 | Xi = 0) = 1 P (Yi = | Xi = x) = qi,y

735

fiLi, Poupart, & van Beek

cause Xi eect isolation; i.e., degree severity eect case
cause Xi absent causes absent. CPT node
deterministic given MAX arithmetic relation. corresponds
assumption severity degree reached eect maximum
degrees produced cause acting independently; i.e., maximum
Yi s. assumption valid eects accumulate. MAX operator
converted full CPT follows,

1, = max{Y1 , . . . , Yn },
P (Y | Y1 , . . . , Yn ) =
0, otherwise.
probability distribution eect variable given by,
n



P (Yi | Xi ) ,
P (Y | X1 , . . . , Xn ) =
=max{Y1 ,...,Yn }

i=1

sum congurations possible values Y1 , . . . , Yn
maximum values equal value . cases, however, making
CPTs explicit often possible practice, size exponential number
causes number values domains random variables.
2.2 Weighted Model Counting Probabilistic Inference
follows, consider propositional formulas conjunctive normal form (CNF).
literal Boolean variable (also called proposition) negation clause
disjunction literals. clause one literal called unit clause literal
unit clause called unit literal. propositional formula F conjunctive normal form
conjunction clauses.
Example 3. example, (x y) clause, formula,
F = (x y) (x z) (y z w) (w z v) (v u),
CNF, u, v, w, x, y, z propositions.
Given propositional formula conjunctive normal form, problem determining
whether exists variable assignment makes formula evaluate true called
Boolean satisfiability problem SAT. variable assignment makes formula
evaluate true also called model. problem counting number models
formula called model counting.
Let F denote propositional formula. use value 0 interchangeably
Boolean value false value 1 interchangeably Boolean value true. notation F |v=false represents new formula, called residual formula, obtained removing
clauses contain literal v (as clauses evaluate true) deleting
literal v clauses. Similarly, notation F |v=true represents residual formula
obtained removing clauses contain literal v deleting literal v

736

fiExploiting Structure Probabilistic Inference

clauses. Let set instantiated variables F . residual formula F |s obtained
cumulatively reducing F variables s.
Example 4. Consider propositional formula F given Example 3. Suppose
x assigned false. residual formula given by,
F |x=0 = (y) (y z) (y z w) (w z v) (v u).
clear, CNF formula satised clauses satised
clause satised least one literals equivalent 1. unit clause,
choice value literal said forced implied. process
unit propagation assigns unit literals value 1. well, formula simplied
removing variables unit literals remaining clauses removing clauses
evaluate true (i.e., residual formula obtained) process continues
looking new unit clauses updating formula unit clause remains.
Example 5. Consider propositional formula F |x=0 given Example 4, x
assigned false. unit clause (y) forces assigned false. residual
formula given by,
F |x=0,y=0 = (z) (z w) (w z v) (v u).
turn, unit clause (z) forces z assigned true. Similarly, assignments w = 1,
v = 1, u = 1 forced.
natural polynomial-time reductions Bayesian inference problem
model counting problems (Bacchus, Dalmao, & Pitassi, 2003). particular, exact
inference Bayesian networks reduced weighted model counting CNFs
(Darwiche, 2002; Littman, 1999; Sang et al., 2005a). Weighted model counting generalization model counting.
weighted model counting problem consists CNF formula F variable
v F , weight literal: weight(v) weight(v). Let assignment
value every variable formula F satises formula; i.e., model
formula. weight product weights literals s. solution
weighted model counting problem sum weights satisfying assignments;
i.e.,

weight(l),
weight(F ) =


ls

sum possible models product literals model.
Chavira Darwiche (2002, 2008) proposed encoding Bayesian network
weighted model counting propositional formula conjunctive normal form. Chavira
Darwiches encoding proceeds follows. step, illustrate encoding using
Bayesian network shown Figure 2. simplicity, assume random variables
Boolean omit node Headache. improve clarity, refer random
variables Bayesian network nodes reserve word variables
Boolean variables resulting propositional formula.
value node Bayesian network, indicator variable created,
737

fiLi, Poupart, & van Beek

C
F

:
:

IC0 , IC1 ,
IF0 , IF1 ,


N

:
:

IM0 , IM1 ,
IN0 , IN1 .

node, indicator clauses generated ensure model exactly
one corresponding indicator variables node true,
C
F

:
:

(IC0 IC1 ) (IC0 IC1 ),
(IF0 IF1 ) (IF0 IF1 ),


N

:
:

(IM0 IM1 ) (IM0 IM1 ),
(IN0 IN1 ) (IN0 IN1 ).

conditional probability table (CPT) parameter (probability)
value CPT, parameter variable created,
C
F


PC0 ,
PF0 ,
PM0 ,

:
:
:

PC1 ,
PF1 ,
PM1 ,

N

:

PN0 |C0 ,F0 ,M0 ,
. . .,
PN0 |C1 ,F1 ,M1 ,

PN1 |C0 ,F0 ,M0 ,
. . .,
PN1 |C1 ,F1 ,M1 .

parameter variable, parameter clause generated. parameter clause
asserts conjunction corresponding indicator variables implies parameter variable vice-versa,

C
F

N

:
:
:
:

IC0 PC0 ,
IF0 PF0 ,
IM0 PM0 ,
IC0 IF0 IM0 IN0 PN0 |C0 ,F0 ,M0 ,
. . .,
IC1 IF1 IM1 IN0 PN0 |C1 ,F1 ,M1 ,

IC1 PC1 ,
IF1 PF1 ,
IM1 PM1 ,
IC0 IF0 IM0 IN1 PN1 |C0 ,F0 ,M0 ,
. . .,
IC1 IF1 IM1 IN1 PN1 |C1 ,F1 ,M1 .

weight assigned literal propositional formula. positive literal
parameter variable assigned weight equal corresponding probability
entry CPT table,
C

:

F

:



:

N

:

weight(PC0 ) = P (C = 0),
weight(PC1 ) = P (C = 1),
weight(PF0 ) = P (F = 0),
weight(PF1 ) = P (F = 1),
weight(PM0 ) = P (M = 0),
weight(PM1 ) = P (M = 1),
weight(PN0 |C0 ,F0 ,M0 ) = P (N
weight(PN1 |C0 ,F0 ,M0 ) = P (N
...,
weight(PN0 |C1 ,F1 ,M1 ) = P (N
weight(PN1 |C1 ,F1 ,M1 ) = P (N

= 0 | C = 0, F = 0, = 0),
= 1 | C = 0, F = 0, = 0),
= 0 | C = 1, F = 1, = 1),
= 1 | C = 1, F = 1, = 1).

literals (both positive negative) assigned weight 1; i.e., weight(IC0 )
= weight(IC0 ) = = weight(IN1 ) = weight(IN1 ) = 1 weight(PC0 ) = =
738

fiExploiting Structure Probabilistic Inference

weight(PN1 |C1 ,F1 ,M1 ) = 1. basic idea indicator variables specify
state worldi.e., value random variable Bayesian network
weights literals multiplied together give probability
state world.
Sang, Beame, Kautz (2005a) introduced alternative encoding Bayesian
network weighted model counting CNF formula. Sang et al.s encoding creates
fewer variables clauses, size generated clauses multi-valued variables
larger. Chavira Darwiches encoding presented above, illustrate Sang
et al.s encoding using Bayesian network shown Figure 2, assuming
random variables Boolean omitting node Headache.
Chavira Darwiches encoding, node, indicator variables created
indicator clauses generated ensure model exactly one
corresponding indicator variables node true.
Let values nodes linearly ordered. CPT entry P (Y = | X)
last value domain , parameter variable Py|X
created; e.g.,
C
F


:
:
:

PC0 ,
PF0 ,
PM0 ,

N

:

PN0 |C0 ,F0 ,M0 ,
PN0 |C0 ,F1 ,M0 ,
PN0 |C1 ,F0 ,M0 ,
PN0 |C1 ,F1 ,M0 ,

PN0 |C0 ,F0 ,M1 ,
PN0 |C0 ,F1 ,M1 ,
PN0 |C1 ,F0 ,M1 ,
PN0 |C1 ,F1 ,M1 .

CPT entry P (Y = yi | X), parameter clause generated. Let ordered
domain {y1 , . . . , yk } let X = x1 , . . . , xl . yi last value
domain , clause given by,
Ix1 Ixl Py1 |X Pyi1 |X Pyi |X Iyi .
yi last value domain , clause given by,
Ix1 Ixl Py1 |X Pyk1 |X Iyk .
running example, following parameter clauses would generated,

C
F

N

:
:
:
:

PC0 IC0
PF0 IF0
PM0 IM0
IC0 IF0 IM0 PN0 |C0 ,F0 ,M0 IN0 ,
. . .,
IC1 IF1 IM1 PN0 |C1 ,F1 ,M1 IN0 ,

PC0 IC1
PF0 IF1
PM0 IM1
IC0 IF0 IM0 PN0 |C0 ,F0 ,M0 IN1 ,
. . .,
IC1 IF1 IM1 PN0 |C1 ,F1 ,M1 IN1 .

weight assigned literal propositional formula. Chavira
Darwiches encoding, weight literals indicator variables always 1.
739

fiLi, Poupart, & van Beek

weight literals parameter variable Py|X given by,
weight(Py|X ) = P (y | X),
weight(Py|X ) = 1 P (y | X).
Let F CNF encoding Bayesian network (either Chavira Darwiches
encoding Sang et al.s encoding). general query P (Q | E) network
answered by,
weight(F Q E)
,
(7)
weight(F E)
Q E propositional formulas enforce appropriate values
indicator variables correspond known values random variables.
backtracking algorithm used enumerate (weighted) models CNF formula
often referred DPLL DPLL-based (in honor Davis, Putnam, Logemann,
Loveland, authors earliest work eld: Davis & Putnam, 1960; Davis,
Logemann, & Loveland, 1962), usually includes techniques unit propagation,
conict recording, backjumping, component caching.

3. Related Work
section, relate work previously proposed methods exact inference
Bayesian networks contain noisy-OR/MAX relations.
One method solving networks replace noisy-OR/MAX full CPT
representation use well-known algorithms answering probabilistic
queries variable elimination tree clustering/jointree. However, generaland
particular, networks use experimental evaluationthis method
impractical. fruitful approach solving networks take advantage
structure semantics noisy-OR/MAX relations improve time
space eciency (e.g., Heckerman, 1989; Olesen et al., 1989; DAmbrosio, 1994; Heckerman
& Breese, 1996; Zhang & Poole, 1996; Takikawa & DAmbrosio, 1999; Dez & Galan, 2003;
Chavira et al., 2005).
Quickscore (Heckerman, 1989) rst ecient exact inference algorithm Booleanvalued two-layer noisy-OR networks. Chavira, Allen Darwiche (2005) present method
multi-layer noisy-OR networks show approach signicantly faster
Quickscore randomly generated two-layer networks. approach proceeds follows:
(i) transform noisy-OR network Bayesian network full CPTs using Pearls
decomposition (see Figure 4), (ii) translate network full CPTs CNF using
general encoding (see Section 2), (iii) simplify resulting CNF taking advantage
determinism (zero parameters one parameters), (iv) compile CNF
arithmetic circuit. One encodings noisy-OR (called WMC1) similar
indirect (but also general) proposal encoding noisy-ORs (steps (i)(iii)).
perform detailed comparison Section 4.1. experiments, perform detailed
empirical comparison approach using compilation (steps (i)(iv)) Cachet
using encodings large Bayesian networks.

740

fiExploiting Structure Probabilistic Inference

Many alternative methods proposed decompose noisy-OR/MAX
adding hidden auxiliary nodes solving using adaptations variable elimination tree clustering (e.g., Olesen et al., 1989; DAmbrosio, 1994; Heckerman & Breese,
1996; Takikawa & DAmbrosio, 1999; Dez & Galan, 2003).
Olesen et al. (1989) proposed reduce size distribution OR/MAX
operator decomposing deterministic OR/MAX node n parents set binary OR/MAX operators. method, called parent divorcing, constructs binary tree
adding auxiliary nodes Zi auxiliary nodes exactly two
parents. Heckerman (1993) presented sequential decomposition method based
adding auxiliary nodes Zi decomposing binary MAX operators. one constructs linear decomposition tree. methods require similar numbers auxiliary
nodes similarly sized CPTs. However, Takikawa DAmbrosio (1999) note, using
either parent divorcing sequential decomposition, many decomposition trees constructed original networkdepending causes orderedand
eciency query answering vary exponentially using variable elimination
tree clustering, depending particular query choice ordering.
take advantage causal independence models, Dez (1993) proposed algorithm
noisy-MAX/OR. introducing one auxiliary variable , Dezs method leads
complexity O(nd2 ) singly connected networks, n number causes
size domains random variables. However, networks loops needs
integrated local conditioning. Takikawa DAmbrosio (1999) proposed similar
multiplicative factorization approach. complexity approach O(max(2d , nd2 )).
However, Takikawa DAmbrosios approach allows ecient elimination orderings
variable elimination algorithm, Dezs method enforces restrictions
orderings. recently, Dez Galan (2003) proposed multiplicative factorization
improves previous work, advantages methods. use
auxiliary graph starting point remaining three CNF encodings (WMC2,
MAX1, MAX2). experiments, perform detailed empirical comparison
approach using variable elimination proposals large Bayesian networks.
work, build upon DPLL-based weighted model counting approach
Sang, Beame, Kautz (2005a). general encoding assumes full CPTs yields
parameter clause CPT parameter. However, approach impractical
large-scale noisy-OR/MAX networks. special-purpose encodings extend weighted
model counting approach exact inference networks previously intractable
approach.

4. Ecient Encodings Noisy-OR CNF
section, present techniques improving weighted model counting approach
Bayesian networks noisy-OR relations. particular, present two CNF encodings
noisy-OR relations exploit structure semantics. noisy-OR relation
take advantage Boolean domains simplify encodings. use running
example Bayesian network shown Figure 2. subsequent section, generalize
noisy-MAX relation.

741

fiLi, Poupart, & van Beek

4.1 Weighted CNF Encoding 1: Additive Encoding
Let causes X1 , . . . , Xn leading eect let noisy-OR relation
node (see Figure 1), random variables assumed Boolean-valued
domains.
rst weighted model encoding method (WMC1), introduce indicator variable IY indicator variable IXi parent . also introduce
parameter variable Pqi parameter qi , 1 n noisy-OR (see Equation 1).
weights variables follows,
weight(IXi ) = weight(IXi ) = 1,
weight(IY ) = weight(IY ) = 1,
weight(Pqi ) = 1 qi ,
weight(Pqi ) = qi .
noisy-OR relation encoded formula,
(IX1 Pq1 ) (IX2 Pq2 ) (IXn Pqn ) IY .

(8)

formula seen encoding Pearls well-known decomposition noisyOR (see Figure 4).
Example 6. Consider Bayesian network shown Figure 2 parameters noisy-ORs shown Table 1. WMC1 encoding introduces five
Boolean indicator variables IC , , IM , , IH , weight 1; six parameter variables P0.6 , P0.5 , P0.4 , P0.3 , P0.2 , P0.1 , weight(Pqi ) = 1 qi
weight(Pqi ) = qi . Using Equation 8, noisy-OR node Nausea encoded as,
(IC P0.6 ) (IF P0.5 ) (IM P0.4 ) .
illustrate weighted model counting formula, suppose nausea malaria
absent cold flu present (i.e., Nausea = 0, Malaria = 0, Cold = 1,
Flu = 1; corresponding indicator variables IM false IC
true). formula simplified to,
(P0.6 ) (P0.5 ) 0.
one model formula, model sets P0.6 false P0.5 false.
Hence, weighted model count formula weight(P0.6 )weight(P0.5 ) = 0.60.5
= 0.3, entry penultimate row full CPT shown Example 2.
Towards converting Equation 8 CNF, also introduce auxiliary indicator variable wi conjunction wi IXi Pqi . dramatically reduces number

742

fiExploiting Structure Probabilistic Inference

clauses generated. Equation 8 transformed into,
(IY

((w1 wn )
(IX1 Pq1 w1 )
(IX1 w1 )
(Pq1 w1 )

(IXn Pqn wn )
(IXn wn )
(Pqn wn )))

(IY

((IX1 Pq1 )

(IXn Pqn ))).

formula CNF, easily transformed CNF using distributive
law. seen WMC1 encoding also easily encode evidencei.e, IY = 0
IY = 1, formula simpliedbefore nal translation CNF. Note
made denitions auxiliary variables (i.e., wi IXi Pqi ) conditional
IY true, rather introducing separate clauses dene auxiliary
variable. allows formula simplied presence evidence
introduces wi actually needed. particular, know IY false,
clauses involving auxiliary variables wi , including denitions wi ,
disappear formula simplied.
Example 7. Consider Bayesian network shown Figure 2. illustrate
encoding evidence, suppose nausea present (i.e., Nausea = 1) headache
present (i.e., Headache = 0). corresponding constraints evidence
follows.
(9)
(IC P0.6 ) (IF P0.5 ) (IM P0.4 ) 1
(IC P0.3 ) (IF P0.2 ) (IM P0.1 ) 0

(10)

constraints converted CNF clauses. Constraint Equation 9 gives
clauses,
(w1 w2 w3 )
(IC P0.6 w1 ) (IC w1 ) (P0.6 w1 )
(IF P0.5 w2 ) (IF w2 ) (P0.5 w2 )
(IM P0.4 w3 ) (IM w3 ) (P0.4 w3 )
constraint Equation 10 gives clauses,
(IC P0.3 ) (IF P0.2 ) (IM P0.1 ).

743

fiLi, Poupart, & van Beek

show correctness encoding WMC1 noisy-OR, rst show entry
full CPT representation noisy-OR relation determined using weighted
model count encoding. always, let causes X1 , . . . , Xn leading
eect let noisy-OR relation node , random variables
Boolean-valued domains.
Lemma 1. entry full CPT representation noisy-OR node , P (Y =
| X1 = x1 , . . . , Xn = xn ), determined using weighted model count Equation 8
created using encoding WMC1.
Proof. Let FY encoding noisy-OR node using WMC1 let
set assignments indicator variables IY , IX1 , . . . , IXn corresponding desired
entry CPT (e.g., = 0, IY instantiated false; otherwise instantiated
true). Xi = 0, disjunct (IXi Pqi ) Equation 8 false would removed
residual formula FY |s ; Xi = 1, disjunct reduces (Pqi ). IY = 0,
disjuncts Equation 8 must false single model
formula. Hence,


weight(Pqi ) =
qi = P (Y = 0 | X),
weight(FY |s ) =
iTx

iTx

Tx = {i | Xi = 1} P (Y = 0 | X) = 1 Tx empty. IY = 1, least one
disjuncts Equation 8 must true are, therefore, 2|Tx | 1 models.
seen sum 2|Tx | possible assignments, weight formula 1.
Hence, subtracting one possible assignment model gives,


weight(Pqi ) = 1
qi = P (Y = 1 | X).
weight(FY |s ) = 1
iTx

iTx

noisy-OR Bayesian network set random variables Z1 , . . . , Zn Bayesian
network noisy-OR relations one Zi full CPTs
remaining nodes. next step proof correctness show entry
joint probability distribution represented noisy-OR Bayesian network
determined using weighted model counting. follows, assume noisy-OR
nodes encoded using WMC1 remaining nodes encoded using Sang et al.s
general encoding discussed Section 2.2. Similar results stated using Chavira
Darwiches general encoding.
Lemma 2. entry joint probability distribution, P (Z1 = z1 , . . . Zn = zn ), represented noisy-OR Bayesian network determined using weighted model counting
encoding WMC1.
Proof. Let F encoding Bayesian network using WMC1 noisy-OR nodes
let set assignments indicator variables IZ1 , . . . , IZn corresponding
desired entry joint probability distribution. entry joint probability

744

fiExploiting Structure Probabilistic Inference

distribution expressed product,
P (X1 , . . . , Xn ) =

n


P (Xi | parents (Xi )),

i=1

n size Bayesian network parents (Xi ) set parents Xi
directed graph; i.e., entry joint probability distribution determined
multiplying corresponding CPT entries. nodes full CPTs, determines
correct entry CPT Lemma 2 Sang et al. (2005a) nodes
noisy-ORs, determines correct probability Lemma 1 above. Thus, weight(F s)
multiplication corresponding CPT entries; i.e., entry joint probability
distribution.
nal step proof correctness show queries interest
correctly answered.
Theorem 1. Given noisy-OR Bayesian network, general queries form P (Q | E)
determined using weighted model counting encoding WMC1.
Proof. Let F CNF encoding noisy-OR Bayesian network. general query
P (Q | E) network answered by,
weight(F Q E)
P (Q E)
=
,
P (E)
weight(F E)
Q E propositional formulas enforce appropriate values indicator variables correspond known values random variables. denition,
function weight computes weighted sum solutions argument. Lemma 2,
equal sum probabilities sets assignments satisfy
restrictions Q E E, respectively, turn equal sum entries
joint probability distribution consistent Q E E, respectively.
Sang et al. (2005a) note, weighted model counting approach supports queries
evidence arbitrary propositional form queries supported
exact inference method.
WMC1 encoding noisy-OR essentially similar indirect also
general proposal Chavira Darwiche (2005) (see Darwiche, 2009, pp. 313-323
detailed exposition proposal). approach proceeds follows: (i) transform
noisy-OR network Bayesian network full CPTs using Pearls decomposition
(see Figure 4), (ii) translate network full CPTs CNF using general encoding
(see Section 2), (iii) simplify resulting CNF taking advantage determinism.
Simplifying resulting CNF proceeds follows. Suppose encoding
sentence (Ia Ib ) Pb|a . parameter corresponding Pb|a zero, sentence
replaced (Ia Ib ) Pb|a removed encoding. parameter corresponding Pb|a one, entire sentence removed encoding.
Applying method noisy-OR (see Figure 1) results following,

745

fiLi, Poupart, & van Beek

(IX1 Pq1 w1 )
(IX1 Pq1 w1 )
(IX1 Pq1 w1 )
(IX1 Pq1 w1 )
...
(IXn Pqn wn )
(IXn Pqn wn )
(IXn Pqn wn )
(IXn Pqn wn )
(IY



(w1 wn ))

(IY



((w1 wn1 wn )
(w1 wn1 wn )
...
(w1 wn1 wn ))),

simplied expression substituting equivalent literals using
fact random variables Boolean (e.g., use IX1 IX1 rather IX1 =0
IX1 =1 ). Three dierences noted. First, encoding denitions wi
conditional IY true, rather introduced separate clauses. Second,
denitions wi succinct. Third, encoding linear number
clauses conditioned IY whereas Chavira et al. encoding 2n 1 clauses.
note, however, Chavira, Allen, Darwiche (2005) discuss direct translation
noisy-OR CNF based Pearls decomposition said compactly represent
noisy-OR (i.e., exponential number clauses), specic details CNF
formula given.
4.2 Weighted CNF Encoding 2: Multiplicative Encoding
Again, let causes X1 , . . . , Xn leading eect let noisyOR relation node (see Figure 1), random variables assumed
Boolean-valued domains.
second weighted model encoding method (WMC2) takes starting point Dez
Galans (2003) directed auxiliary graph transformation Bayesian network
noisy-OR/MAX relation. Dez Galan note noisy-OR relation, Equation (6)
represented product matrices,




P (Y = 0 | X)
1 0
P (Y 0 | X)
=
.
P (Y = 1 | X)
1 1
P (Y 1 | X)
Based factorization, one integrate noisy-OR node regular Bayesian
network introducing hidden node noisy-OR node . transformation
rst creates graph set nodes arcs original network. Then,
node noisy-OR relation, add hidden node domain
, add arc , redirect arc Xi Xi , associate
factorization table,

746

fiExploiting Structure Probabilistic Inference

=0
1
1

=0
=1

=1
0
1.

auxiliary graph Bayesian network contains parameters less
0. CNF encoding methods general Bayesian networks (see Section 2) cannot
applied here.
introduce indicator variables IY IY , indicator variable IXi
parent . weights variables follows,
weight(IY ) = weight(IY ) = 1,
weight(IY ) = weight(IY ) = 1,
weight(IXi ) = weight(IXi ) = 1.
arc Xi , 1 n, create two parameter variables PX0 ,Y PX1 ,Y .
weights variables follows,
weight(PX0 ,Y )
weight(PX0 ,Y )

=
=

1,
0,

weight(PX1 ,Y )
weight(PX1 ,Y )

=
=

qi ,
1 qi .

factorization table, introduce two variables, uY wY , weights
variables given by,
weight(uY )
weight(wY )

=
=

1,
1,

weight(uY )
weight(wY )

=
=

0,
2.

rst row factorization table, generate clause,
(IY IY ),

(11)

second row, generate clauses,
(IY IY uY ) (IY IY wY ).

(12)

Finally, every parent Xi , generate clauses,
(IY IXi PX0 ,Y ) (IY IXi PX1 ,Y ).

(13)

conjunction clauses; i.e., CNF.
Example 8. Consider Bayesian network shown Figure 2 parameters noisy-ORs shown Table 1. auxiliary graph transformation shown
Figure 5. WMC2 encoding introduces seven Boolean indicator variables IC , ,
, , , ; twelve parameter variables,
IM ,
N
H
H
0
PC,N

0
PF,N

0
PM,N


1
PC,N

1
PF,N

1
PM,N


0
PC,H

0
PF,H

0
PM,H


747

1
PC,H

1
PF,H

1
PM,H
;

fiLi, Poupart, & van Beek

Cold

Flu

Malaria

N

H

Nausea

Headache

Figure 5: Dez Galans (2003) transformation noisy-OR relation applied
Bayesian network shown Figure 2.

four factorization variables uN , wN , uH , wH . noisy-OR node Nausea
encoded set clauses,

uN
wN

0
IC PC,N

0
PF,N
0
IM PM,N


1
IC PC,N

1
PF,N

1
IM PM,N


illustrate weighted model counting formula, suppose nausea malaria
absent cold flu present (i.e., Nausea = 0, Malaria = 0, Cold = 1,
Flu = 1; corresponding indicator variables IM false IC
true). formula simplified to,
1
1
0
PC,N
PF,N PM,N .

(To see this, note clauses evaluate true removed literals evaluate
false removed clause. result simplifying first clause, forced
false removed clauses.) one model formula,
model sets conjuncts true. Hence, weighted model count
1
1
0
formula weight(PC,N
) weight(PF,N ) weight(PM,N ) = 0.6 0.5 1.0 = 0.3,
entry penultimate row full CPT shown Example 2.
again, seen WMC2 also easily encode evidence CNF
formula; i.e., IY = 0 IY = 1, formula simplied.
Example 9. Consider Bayesian network shown Figure 2. illustrate
encoding evidence, suppose nausea present (i.e., Nausea = 1) headache
present (i.e., Headache = 0). WMC2 encoding results following set
clauses,

748

fiExploiting Structure Probabilistic Inference

uN
wN
IH

0
IC PC,N

0
PF,N
0
IM PM,N


1
IC PC,N

1
PF,N
1
IM PM,N


0
IC PC,H

0
PF,H
0
IM PM,H


1
IC PC,H

1
PF,H
1
IM PM,H


show correctness encoding WMC2 noisy-OR, rst show entry
full CPT representation noisy-OR relation determined using weighted
model count encoding. always, let causes X1 , . . . , Xn leading
eect let noisy-OR relation node , random variables
Boolean-valued domains.
Lemma 3. entry full CPT representation noisy-OR node , P (Y =
| X1 = x1 , . . . , Xn = xn ), determined using weighted model count Equations 1113 created using encoding WMC2.
Proof. Let FY encoding noisy-OR node using WMC2 let
set assignments indicator variables IY , IX1 , . . . , IXn corresponding desired
entry CPT. Xi = 0, clauses Equation 13 reduce (IY PX0 ,Y ),
Xi = 1, clauses reduce (IY PX1 ,Y ). IY = 0, clauses Equations 11
& 12 reduce (IY ). Hence,


weight(PX0 ,Y ))
weight(PX1 ,Y ))
weight(FY |s ) = weight(IY )
=



iTx

iTx

qi

iTx

= P (Y = 0 | X),
Tx = {i | Xi = 1} P (Y = 0 | X) = 1 Tx empty. IY = 1, clauses
Equations 11 & 12 reduce (IY uY ) (IY wY ). Hence,

qi +
weight(FY |s ) = weight(IY )weight(uY )weight(wY )
iTx

weight(IY )weight(uY )weight(wY )



iTx

weight(IY )weight(uY )weight(wY ) +
weight(IY )weight(uY )weight(wY )

qi
= 1
iTx

= P (Y = 1 | X).

749

qi +

fiLi, Poupart, & van Beek

remainder proof correctness encoding WMC2 similar
encoding WMC1.
Lemma 4. entry joint probability distribution, P (Z1 = z1 , . . . Zn = zn ), represented noisy-OR Bayesian network determined using weighted model counting
encoding WMC2.
Theorem 2. Given noisy-OR Bayesian network, general queries form P (Q | E)
determined using weighted model counting encoding WMC2.

5. Ecient Encodings Noisy-MAX CNF
section, present techniques improving weighted model counting approach
Bayesian networks noisy-MAX relations. particular, present two CNF encodings noisy-MAX relations exploit structure semantics. use
running example Bayesian network shown Figure 2.
Let causes X1 , . . . , Xn leading eect let noisy-MAX
relation node (see Figure 1), random variables may multi-valued (nonBoolean) domains. Let dX number values domain random variable
X.
WMC2 multiplicative encoding extended noisy-MAX introducing indicator variables represent variables multiple values. section,
explain extension present two noisy-MAX encodings based two dierent
weight denitions parameter variables. two noisy-MAX encodings denoted
MAX1 MAX2, respectively. begin presenting parts encodings
MAX1 MAX2 common. WMC2, two noisy-MAX encodings take
starting point Dez Galans (2003) directed auxiliary graph transformation
Bayesian network noisy-OR/MAX. Dez Galan show noisy-MAX
relation, Equation (6) factorized product matrices,
P (Y = | X) =




(y, ) P (Y | X)

(14)

=0

dY dY matrix given by,


= y,
1,

(y, ) = 1, = 1,


0,
otherwise.
noisy-MAX node , introduce dY indicator variables IY0 ... IYdY 1 ,

represent value domain , d2Y + 1 clauses ensure exactly one
variables true. WMC2, introduce hidden node domain
, corresponding indicator variables represent value domain ,
clauses ensure exactly one domain value selected model. parent
Xi , 1 n, , dene indicator variables Ii,x , x = 0, . . . , dXi 1, add

750

fiExploiting Structure Probabilistic Inference

clauses ensure exactly one indicator variables corresponding Xi
true. indicator variable negation indicator variable weight 1.
Example 10. Consider Bayesian network shown Figure 2 parameters noisy-MAX shown Table 2. node Nausea domain {absent =
0, mild = 1, severe = 2} parents Cold, Flu, Malaria Boolean valued,
MAX1 MAX2 encodings introduce Boolean indicator variables INa , INm , INs ,
, , IC , IC , , , IM , IM . weights variables
INa , INm
0
1
0
1
0
1

negations 1. Four clauses added indicator variables Nausea,
(INa INm INs )





(INa INm )
(INa INs )
(INm INs ).

Similar clauses added indicator variables hidden node N
indicator variables parents Cold, Flu, Malaria, respectively.
factorization table, introduce two auxiliary variables, uY wY ,
weights variables given by,
weight(uY )
weight(wY )

=
=

1,
1,

weight(uY )
weight(wY )

factorization table, clause added entry


add (Iy Iy uY )
1,

(y, ) = 1, add (Iy Iy wY )


0,
add (Iy Iy uY )

=
=

0,
2.

matrix,
= y,
= 1,
otherwise.

Example 11. Consider Bayesian network shown Figure 2 parameters noisy-MAX shown Table 2. Nausea domain {absent = 0, mild
= 1, severe = 2}, factorization table MN given by,
N = absent
N = mild
N = severe

N = absent
1
1
0

N = mild
0
1
1

N = severe
0
0
1.

Auxiliary variables uN wN introduced following clauses, shown row order,
would added factorization table MN ,
INa INa uN
INm INa wN
INs INa uN

uN
INa INm
uN
INm INm
wN
INs INm

INa INs uN
INm INs uN
INs INs uN .

completes description parts encodings common
MAX1 MAX2.

751

fiLi, Poupart, & van Beek

5.1 Weighted CNF Encoding 1 Noisy-MAX
rst weighted model counting encoding noisy-MAX relations (MAX1) based
additive denition noisy-MAX. Recall decomposed probabilistic model noisyMAX relation discussed end Section 2.1. shown noisy-MAX,
P (Y | X1 , . . . , Xn ) determined using,
P (Y | X1 , . . . , Xn ) =

n


P (Yi | Xi ) =

Yi i=1

n

Yi i=1
Xi =0

Xi
qi,Y


(15)

Xi
parameters noisy-MAX, sum conguwhere qi,Y

rations possible values Y1 , . . . , Yn , values less equal
value y. Note outer operator summation; hence, refer MAX1
additive encoding. Substituting Equation 14 gives,



P (Y = | X1 , . . . , Xn ) =



=0

n


Xi

(y, )
qi,Y
.



(16)

Yi i=1
Xi =0

equation encode CNF. encoding factorization table
common encodings explained above. remains encode
computation P (Y | X1 , . . . , Xn ).
parent Xi , 1 n, introduce dY indicator variables, Ii,y , represent
eect Xi , 0 dY 1, add clauses ensure exactly one
indicator variables correspond Xi true. Note indicators variables
addition indicator variables common encodings explained above.
always indicator variables, weights Ii,y Ii,y 1.
x noisy-MAX, introduce corresponding parameter
parameter qi,y
x
variable Pi,y . weight parameter variable given by,
x
x
) = qi,y
weight(Pi,y

x
weight(Pi,y
)=1

1 n, 0 dY 1, 1 x dXi 1. relation Xi
represented parameter clauses1 ,
x
(Ii,x Ii,y ) Pi,y

1 n, 0 dY 1, 1 x dXi 1.
Example 12. Consider Bayesian network shown Figure 2 parameters noisy-MAX shown Table 2. noisy-MAX node Nausea,
encoding introduces indicator variables IC,Na , IC,Nm , IC,Ns , IF,Na , IF,Nm , IF,Ns , IM,Na ,
IM,Nm , IM,Ns , weight 1, clauses,
1. improve readability, section propositional formulas sometimes written natural
non-clausal form. continue refer clauses translation clause form
straightforward.

752

fiExploiting Structure Probabilistic Inference

IC,Na IC,Nm IC,Ns
IC,Na IC,Nm
IC,Na IC,Ns
IC,Nm IC,Ns

IF,Na IF,Nm IF,Ns
IF,Na IF,Nm
IF,Na IF,Ns
IF,Nm IF,Ns

IM,Na IM,Nm IM,Ns
IM,Na IM,Nm
IM,Na IM,Ns
IM,Nm IM,Ns

well, following parameter variables associated weights would introduced,
1
) = 0.7
weight(PC,N

1
weight(PC,N
) = 0.2

1
weight(PC,Ns ) = 0.1

1
weight(PF,N
) = 0.5

1
weight(PF,N
) = 0.2

1
weight(PF,Ns ) = 0.3

1
weight(PM,N
) = 0.1

1
weight(PM,N
) = 0.4

1
weight(PM,Ns ) = 0.5,

along following parameter clauses,
1
(IC1 IC,Na ) PC,N

1
(IC1 IC,Nm ) PC,N

1
(IC1 IC,Ns ) PC,N


1
(IF1 IF,Na ) PF,N

1
(IF1 IF,Nm ) PF,N

1
(IF1 IF,Ns ) PF,N


1
(IM1 IM,Na ) PM,N

1
(IM1 IM,Nm ) PM,N

1
(IM1 IM,Ns ) PM,N


remains relate (i) indicator variables, Ii,x , represent value
parent variable Xi , x = 0, . . . , dXi 1; (ii) indicator variables, Ii,y , represent
eect Xi , = 0, . . . , dY 1; (iii) indicator variables, IY ,


represent value hidden variable , = 0, . . . , dY 1. Causal independent
clauses dene relation (i) (ii) assert cause Xi absent
(Xi = 0), Xi eect ; i.e.,
Ii,x0 Ii,y0
1 n. Value constraint clauses dene relation (ii) (iii)
assert hidden variable takes value , eect Xi cannot
takes higher degree severe value y; i.e.,
IY Ii,Yy


1 n, 0 dY 1, < dY 1.
Example 13. Consider Bayesian network shown Figure 2 parameters noisy-MAX shown Table 2. noisy-MAX node Nausea,
encoding introduces causal independence clauses,
IC0 IC,Na

IF0 IF,Na

IM0 IM,Na

value constraint clauses N = absent,
INa IC,Nm
INa IC,Ns

INa IF,Nm
INa IF,Ns

INa IM,Nm
INa IM,Ns

value constraint clauses N = mild,
IC,N



IF,N
INm


753

IM,N
INm


fiLi, Poupart, & van Beek

5.2 Weighted CNF Encoding 2 Noisy-MAX
second weighted model counting encoding noisy-MAX relations (MAX2) based
multiplicative denition noisy-MAX. Equation 5 states P (Y | X1 , . . . , Xn )
determined using,

n

xi
qi,y
(17)
P (Y | X) =
.
i=1 =0
xi =0

Note outer operator multiplication; hence refer MAX2 multiplicative
encoding. Substituting Equation 14 gives,


P (Y = | X1 , . . . , Xn ) =



=0




n


xi
(y, )
qi,y
.



(18)

i=1 =0
xi =0

equation encode CNF. encoding factorization table
common encodings explained above. remains encode
computation P (Y | X1 , . . . , Xn ).
x noisy-MAX, introduce corresponding parameter
parameter qi,y
x . weight parameter variable pre-computes summation Equavariable Pi,y
tion 17,


x
x
x
)=
qi,y
weight(Pi,y
)=1
weight(Pi,y

=0

1 n, 0 dY 1, 1 x dXi 1. relation Xi
represented parameter clauses,
x
,
(Ii,x Iy ) Pi,y

0 dY 1 0 x dXi 1.
Example 14. Consider Bayesian network shown Figure 2 parameters noisy-MAX shown Table 2. noisy-MAX node Nausea,
following parameter variables associated weights would introduced,
1
) = 0.7
weight(PC,N

1
) = 0.9
weight(PC,N

1
weight(PC,Ns ) = 1

1
weight(PF,N
) = 0.5

1
weight(PF,N
) = 0.7

1
weight(PF,Ns ) = 1

1
weight(PM,N
) = 0.1

1
weight(PM,N
) = 0.5

1
weight(PM,Ns ) = 1,

along following parameter clauses,
1
(IC1 INa ) PC,N

1
) P
(IC1 INm
C,Nm
1
(IC1 INs ) PC,N


1
(IF1 INa ) PF,N

1
) P
(IF1 INm
F,Nm
1
(IF1 INs ) PF,N


1
(IM1 INa ) PM,N

1
) P
(IM1 INm
M,Nm
1
(IM1 INs ) PM,N


stated far, encoding sucient correctly determining entry full
CPT representation noisy-MAX relation using weighted model counting. However,
754

fiExploiting Structure Probabilistic Inference

improve eciency encoding, add redundant clauses. redundant clauses
change set solutions encoding, thus change weighted model
count. do, however, increase propagation thus overall speed computation
special case causes absent. end, noisy-MAX node
, introduce auxiliary variable IvY weights given by,
weight(IvY )

=

1,

weight(IvY )

introduce clauses,

n

Ii,0 (IY0 IvY ),

n




=

0,


(IY0 IvY ),

Ii,0



clauses,


n


n



Ii,0

(Iy IvY ),




Ii,0

(Iy IvY ),



1 dY 1 1 dY 1.
Example 15. Consider Bayesian network shown Figure 2.
noisy-MAX node Nausea, auxiliary variable IvN introduced weight(IvN ) = 1
weight(IvN ) = 0 along following redundant clauses,
(IC0 IF0 IM0 ) (IN IvN )

(IC0 IF0 IM0 ) (IN IvN )

(IC0 IF0 IM0 ) (IN IvN )

(IC0 IF0 IM0 ) (INa IvN )
(IC0 IF0 IM0 ) (INm IvN )
(IC0 IF0 IM0 ) (INs IvN ).



6. Experimental Evaluation
section, empirically evaluate eectiveness encodings. use
Cachet solver2 experiments one fastest weighted model counting solvers.
compare Ace (version 2) (Chavira et al., 2005) Dez Galans (2003)
approach using variable elimination.
chose compare Ace two reasons. First, Ace well 2008 exact
inference competition (no winner declared, Ace performed better classes
problems entries). Second, methods publicly available
well competition, Smile/GeNIe (Druzdzel, 2005) Cachet using general
encoding full CPT representation, currently take computational advantage
noisy-OR noisy-MAX thus would straw algorithms. strength Ace
take advantage local structure determinism specically takes
advantage semantics noisy-OR noisy-MAX speed computation.
comparison Ace, revealing, without methodological diculties however
(see Section 6.4 discussion).
2. http://www.cs.rochester.edu/u/kautz/Cachet/index.htm

755

fiLi, Poupart, & van Beek

chose compare Dez Galans (2003) approach, consists variable elimination applied auxiliary network permits exploitation causal independence, show approach ecient previous proposals
noisy-MAX. knowledge, work subsequently superseded; i.e.,
still state-of-the-art improving variable elimination noisy-MAX exact inference. implementation Dez Galans approach publicly available,
implemented ourselves. implementation uses algebraic decision diagrams (ADDs)
(Bahar, Frohm, Gaona, Hachtel, Macii, Pardo, & Somenzi, 1993) base data structure
represent conditional probability tables. Algebraic decision diagrams permit compact
representation aggregating identical probability values speed computation exploiting context-specic independence (Boutilier, Friedman, Goldszmidt, & Koller, 1996),
taking advantage determinism caching intermediate results avoid duplicate computation. ADDs complicated table based representations, ability
exploit structure often yields speed greater incurred overhead.
fact, ADDs currently preferred data structure inference factored partially
observable Markov decision processes (Shani, Brafman, Shimony, & Poupart, 2008).
variable elimination heuristic used greedy one rst eliminates variables
appear deterministic potentials one variable (this equivalent unit propagation) eliminates variable creates smallest algebraic decision diagram
respect eliminated algebraic decision diagrams. order avoid creating
algebraic decision diagram variable searching next variable eliminate, size new algebraic decision diagram estimated smallest two upper
bounds: (i) cross product domain size variables new algebraic decision diagram (ii) product sizes (e.g., number nodes) eliminated
algebraic decision diagrams.
Good variable ordering heuristics play important role success modern DPLLbased model counting solvers. Here, evaluate two heuristics: Variable State Aware
Decaying Sum (VSADS) Tree Decomposition Variable Group Ordering (DTree).
VSADS heuristic one current best performing dynamic heuristics designed
DPLL-based model counting engines (Sang, Beame, & Kautz, 2005b). viewed
scoring system attempts satisfy recent conict clauses also considers
number occurrences variable time. Compared VSADS heuristic,
DTree heuristic (Huang & Darwiche, 2003) described mixed variable ordering
heuristic. DTree rst uses binary tree decomposition generate ordered variable groups.
decomposition done prior search. order variables within group
decided dynamically backtracking search using dynamic heuristic.
experiments performed Pentium workstation 3GHz hyperthreading CPU 2GB RAM.
6.1 Experiment 1: Random Two-Layer Networks
rst set experiments, used randomly generated two-layer networks compare
time space eciency WMC1 WMC2 encodings.
WMC1 WMC2 encodings answer probabilistic queries using Equation 7. encodings lead quick factorization given evidence encoding.

756

fiExploiting Structure Probabilistic Inference

clauses negative evidence represented compactly resulting CNF, even
large number parents. WMC2 encoding, positive evidence represented three Boolean variables (see Example 9 illustration variables
deleted kept case positive evidence), whereas WMC1 encoding requires n Boolean variables, one parent (see Example 7). WMC2
encoding, use two parameter variables (PX0 ,Y PX1 ,Y ) represent every arc,
WMC1 encoding needs one.
Table 3: Binary, two layer, noisy-OR networks 500 diseases 500 symptoms. Eect
increasing amount positive evidence (P+ ) number variables encoding
(n), treewidth encoding (width), average time solve (sec.), number
instances solved within cuto one hour (solv.), test set contained
total 30 instances. results P+ = 5, . . . , 25 similar results
P+ = 30 omitted.

P+
30
35
40
45
50
55
60

n
3686
3716
3746
3776
3806
3836
3916

WMC1
width sec.
10
0.2
11
0.6
13
21.4
14
38.8
19
75.3
22
175.2
24

solv.
30
30
30
30
30
30
17

n
6590
6605
6620
6635
6650
6665
6680

WMC2
width sec.
11
0.1
11
0.2
11
0.5
13
2.0
13
6.1
16
71.0
16

solv.
30
30
30
30
30
30
27

Ace
sec. solv.
31.7
30
32.5
30
32.7
30
35.7
30
40.9
30
166.0
30
21

random network contains 500 diseases 500 symptoms. symptom six
possible diseases uniformly distributed disease set. Table 3 shows treewidth
encoded CNF WMC1 WMC2 encodings. rst column shows amount
positive evidence symptom variables. remainder evidence variables
negative symptoms. seen although WMC1 encoding generates fewer
variables WMC2 encoding, CNF created WMC2 encoding smaller
width. probability evidence (PE) computed using tree decomposition guided
variable ordering (Huang & Darwiche, 2003) results compared Ace3 (a
detailed experimental analysis given next experiments).
6.2 Experiment 2: QMR-DT
second set experiments, used Bayesian network called QMR-DT. comparison randomly generated problems, QMR-DT presents real-world inference task
various structural sparsity properties. example, empirical distribution
diseases, small proportion symptoms connected large number diseases
(see Figure 6).
3. http://reasoning.cs.ucla.edu/ace/

757

fiLi, Poupart, & van Beek

Number symptoms

1000

100

10

1
50

100

150

200

250

300

350

400

450

500

550

Number diseases

Figure 6: Empirical distribution diseases QMR-DT Bayesian network. Approximately 80% symptoms connected less 50 diseases.

network used aQMR-DT, anonymized version QMR-DT4 . Symptom
vectors k positive symptoms generated experiment. evidence
vector, symptom variables sorted ascending order parent (disease)
number, rst k variables chosen positive symptoms, remaining symptom
variables set negative. goal method generate instances increasing
diculty.
report runtime answer probability evidence (PE) queries. also
experimented implementation Quickscore5 , found could solve
test cases shown Figure 7. approach based weighted model counting also
outperforms variable elimination QMR-DT. model counting time 2560 positive
symptoms, using WMC1 encoding VSADS dynamic variable ordering
heuristic, 25 seconds. instance could solved within one hour variable
elimination.
tested two dierent heuristics encoding: VSADS dynamic variable order
heuristic DTree (Huang & Darwiche, 2003), semi-static tree decomposition-based
heuristic. runtime using encoding DTree heuristic sum two parts:
preprocessing time DTree runtime model counting encoding.
experiment, DTree faster runtime VSADS model counting process.
However, overhead preprocessing large size networks high achieve better
overall performance.
WMC2 encoding generates twice many variables WMC1 encoding. Although WMC2 encoding promising WMC1 encoding smaller size
4. http://www.utoronto.ca/morrislab/aQMR.html
5. http://www.cs.ubc.ca/ murphyk/Software/BNT/bnt.html

758

fiExploiting Structure Probabilistic Inference

10000

Runtime (seconds)

1000


WMC2 + DTree
WMC1 + DTree
WMC1 + VSADS

100

10

1

0.1
2000

2100

2200
2300
2400
Number positive symptoms

2500

2600

Figure 7: QMR-DT Bayesian network 4075 symptoms 570 diseases. Eect
amount positive symptoms time answer probability evidence
queries, WMC1 encoding DTree variable ordering heuristic,
WMC1 encoding VSADS variable ordering heuristic, WMC2 encoding
DTree variable ordering heuristic, Dez Galans (2003) approach
using variable elimination. Ace could solve instances 500
positive symptoms within one hour limit runtime.

networks (see Table 3), WMC2 encoding less ecient WMC1 encoding.
overhead tree decomposition ordering WMC2 encoding also higher
WMC1 encoding. results also show dynamic variable ordering
work well WMC2 encoding. Model counting using WMC2 encoding
VSADS heuristic cannot solve networks amount positive evidence greater
1500 symptoms.
experimental results also show approach ecient Ace.
example, using Ace, CNF QMR-DT 30 positive symptoms creates 2.8 105
variables, 2.8 105 clauses 3.8 105 literals. Also, often requires 1GB
memory nish compilation process. WMC1 encoding, network
evidence create 4.6 104 variables, 4.6 104 clauses 1.1 105 literals.
Cachet, weighted model counting engine, needs less 250MB memory
cases solve instances. experiments, Ace could solve QMR-DT
500 positive symptoms within hour.

759

fiLi, Poupart, & van Beek

6.3 Experiment 3: Random Multi-Layer Networks
third set experiments, used randomly generated multi-layer Bayesian networks.
test randomly generated multi-layer networks, constructed set acyclic Bayesian
networks using method Dez Galan (2003): create n binary variables;
randomly select pairs nodes add arcs them, arc added
Xi Xj < j; assign noisy-OR distribution noisy-MAX distribution
node parents.
160
140


WMC1 + DTree
WMC1 + VSADS

Runtime (seconds)

120
100
80
60
40
20
0
300

310

320

330 340 350 360 370
Number hidden variables

380

390

400

Figure 8: Random noisy-OR Bayesian networks 3000 random variables. Eect
number hidden variables average time answer probability evidence
queries, WMC1 encoding VSADS variable ordering heuristic,
WMC1 encoding DTree variable ordering heuristic, Dez
Galans (2003) approach using variable elimination.

Figure 8 shows eect number hidden variables average time
answer probability evidence (PE) queries random noisy-OR Bayesian networks.
data point average 30 randomly generated instances, instance
3000 nodes total.
results two layer QMR-DT multiple layer random noisy-OR show
average, approach based weighted model counting performed signicantly
better variable elimination signicantly better Ace. approaches
benet large amount evidence, weighted model counting approach
explores determinism eciently dynamic decomposition unit propagation. comparison variable elimination, weighted model counting approach encodes
local dependencies among parameters evidence clauses/constraints.

760

fiExploiting Structure Probabilistic Inference

topological structural features CNF, connectivity, explored
dynamically DPLLs simplication process.
Heuristics based primarily conict analysis successfully applied modern
SAT solvers. However, Sang, Beame, Kautz (2005b) note model counting
often case conicts parts search tree
large numbers solutions parts heuristic based purely conict analysis
make nearly random decisions. Sang et al.s (2005b) VSADS heuristic, combines
conict analysis literal counting, avoids pitfall seen work
well large Bayesian networks large amounts evidence. DTree also good
choice due divide-and-conquer nature. However, use DTree decompose
CNF generated QMR-DT, usually rst variable group contains 500
disease variables. well, overhead preprocessing aects overall eciency
approach.
1000

ACE
MAX1
MAX2

Runtime (seconds)

100

10

1

0.1

0.01
200

250

300

350

400

450

500

550

600

650

Number arcs

Figure 9: Random noisy-MAX Bayesian networks 100 ve-valued random variables.
Eect number arcs average time answer probability evidence queries,
MAX1 encoding noisy-MAX, MAX2 encoding noisy-MAX,
Chavira, Allen, Darwiches Ace (2005).

Similarly, performed experiment 100 ve-valued random variables. Figure 9
shows eect number arcs average time answer probability evidence
(PE) queries random noisy-MAX Bayesian networks. data point average
50 randomly generated instances. seen instances CNF
encoding MAX2 performs encoding MAX1 signicantly outperforms Chavira,
Allen, Darwiches Ace (2005). recognized noisy-MAX relations,
multiplicative factorization signicant advantages additive factorization
(Takikawa & DAmbrosio, 1999; Dez & Galan, 2003). Hence, one would expect
761

fiLi, Poupart, & van Beek

CNF encoding based multiplicative factorization (encoding MAX2) would perform
better CNF encoding based additive factorization (encoding MAX1).
primary disadvantage encoding MAX1 must encode CNF summing
congurations. result, MAX1 generates much larger CNFs MAX2, including
variables clauses. encoding MAX2, weight parameter variable
represents maximum eect cause hence minimizes add computations.
6.4 Discussion
experimentally evaluated four SAT encodingsWMC1 WMC2 noisy-OR
MAX1 MAX2 noisy-MAXon variety Bayesian networks using Cachet
weighted modeling counting solver. WMC1 MAX1 encodings characterized
additive encodings WMC2 MAX2 encodings multiplicative encodings.
experiments, multiplicative encodings gave SAT instances smaller treewidth.
noisy-OR, additive encoding (WMC1) gave smaller SAT instances multiplicative encoding (WMC2). noisy-MAX, reverse additive encoding
(MAX1) gave larger SAT instances multiplicative encoding (MAX2). regards speedups, experiments noisy-OR, results mixed
encoding better; sometimes WMC1 times WMC2. experiments
noisy-MAX, results suggest multiplicative encoding (MAX2) better.
reduced treewidth reduced size MAX2 encoding important,
WMC2 able solve many instances.
also compared Dez Galans (2003) approach using variable elimination
(hereafter, D&G) Ace (Chavira et al., 2005). experiments, approach
dominated D&G Ace speedups three orders magnitude. well,
approach could solve many instances D&G Ace could solve within
resource limits. However, results interpreted care least three
reasons. First, well known eciency variable elimination sensitive
variable elimination heuristic used implemented.
careful optimize implementation use high-quality heuristic, still
possibility dierent implementation dierent heuristic would lead dierent
results. Second, Cachet, based search, designed answer single query
experiments based answering single query. However, Ace uses compilation
strategy designed answer multiple queries eciently. compilation step
take considerable number resources (both time space) payo
experimental design. Third, although Ace viewed weighted model counting
solver, comparing encodings experiments. Chavira Darwiche
(2008) note, Cachet Ace dier many ways including using dierent methods
decomposition, variable splitting, caching. well, Ace uses optimizations
Cachet not, including encoding equal parameters, eclauses (a succinct way encoding
one literal true disjunction), structured resolution. (We refer reader
Chavira & Darwiche, 2008 experimental comparison search compilation,
extensive discussion diculty comparing two approaches
advantages disadvantages.) Nevertheless, experiments demonstrated instances
noisy-OR networks (see Figure 7) noisy-MAX networks (see Figure 9) could

762

fiExploiting Structure Probabilistic Inference

solved D&G Ace within resource limits, could solved quite
quickly Cachet using encodings.

7. Conclusions Future Work
Large graphical models, QMR-DT, often intractable exact inference
large amount positive evidence. presented time space ecient CNF
encodings noisy-OR/MAX relations. also explored alternative search ordering heuristics DPLL-based backtracking algorithm encodings. experiments,
showed together techniques extend model counting approach exact inference networks previously intractable approach. well,
experimental results must interpreted care comparing
encodings also implementations systems conicting design goals,
benchmarks techniques gave speedups three orders magnitude best
previous approaches scaled larger instances. Future work could include developing specic CNF encodings causal independence relations (see Koller & Friedman,
2009, pp. 175185).

Acknowledgments
preliminary version paper appeared as: Wei Li, Pascal Poupart, Peter van
Beek. Exploiting Causal Independence Using Weighted Model Counting. Proceedings
23rd AAAI Conference Artificial Intelligence, pages 337343, 2008. authors
wish thank anonymous referees helpful comments.

References
Bacchus, F., Dalmao, S., & Pitassi, T. (2003). DPLL caching: new algorithm
#SAT Bayesian inference. Electronic Colloquium Computational Complexity,
10 (3).
Bahar, R. I., Frohm, E. A., Gaona, C. M., Hachtel, G. D., Macii, E., Pardo, A., & Somenzi,
F. (1993). Algebraic decision diagrams applications. Proceedings
1993 IEEE/ACM International Conference Computer-Aided Design (ICCAD-93),
pp. 188191.
Boutilier, C., Friedman, N., Goldszmidt, M., & Koller, D. (1996). Context-specic independence Bayesian networks. Proceedings Twelfth Conference Uncertainty
Artificial Intelligence (UAI-96), pp. 115123.
Chavira, M., Allen, D., & Darwiche, A. (2005). Exploiting evidence probabilistic inference. Proceedings 21st Conference Uncertainty Artificial Intelligence
(UAI-05), pp. 112119.
Chavira, M., & Darwiche, A. (2005). Compiling Bayesian networks local structure.
Proceedings Nineteenth International Joint Conference Artificial Intelligence
(IJCAI-05), pp. 13061312.

763

fiLi, Poupart, & van Beek

Chavira, M., & Darwiche, A. (2008). probabilistic inference weighted model counting.
Artificial Intelligence, 172 (6-7), 772799.
DAmbrosio, B. (1994). Symbolic probabilistic inference large BN2O networks. Proceedings Tenth Conference Uncertainty Artificial Intelligence (UAI-94),
pp. 128135.
Darwiche, A. (2009). Modeling Reasoning Bayesian Networks. Cambridge.
Darwiche, A. (2002). logical approach factoring belief networks. Proceedings
Eighth International Conference Principles Knowledge Representation
Reasoning (KR-02), pp. 409420.
Davis, M., Logemann, G., & Loveland, D. (1962). machine program theorem proving.
Communications ACM, 5 (7), 394397.
Davis, M., & Putnam, H. (1960). computing procedure quantication theory. J.
ACM, 7 (3), 201215.
Dez, F. J. (1993). Parameter adjustement Bayes networks. generalized noisy ORgate. Proceedings Ninth Conference Uncertainty Artificial Intelligence
(UAI-93), pp. 99105.
Dez, F. J., & Druzdzel, M. J. (2006). Canonical probabilistic models knowledge engineering. Tech. rep. CISIAD-06-01, UNED, Madrid.
Dez, F. J., & Galan, S. F. (2003). Ecient computation noisy MAX. International
J. Intelligent Systems, 18, 165177.
Druzdzel, M. J. (2005). Intelligent decision support systems based SMILE. Software 2.0,
2, 1233.
Good, I. J. (1961). causal calculus. British Journal Philosophy Science,
12 (45), 4351.
Heckerman, D. (1989). tractable inference algorithm diagnosing multiple diseases.
Proceedings Fifth Conference Uncertainty Artificial Intelligence (UAI-89),
pp. 163172.
Heckerman, D., & Breese, J. (1996). Causal independence probability assessment
inference using Bayesian networks. IEEE, Systems, Man, Cyber., 26, 826831.
Heckerman, D. (1993). Causal independence knowledge acquisition inference.
Proceedings Ninth Conference Uncertainty Artificial Intelligence (UAI93).
Henrion, M. (1987). practical issues constructing belief networks. Proceedings
Third Conference Uncertainty Artificial Intelligence (UAI-87), pp. 132139.
Huang, J., & Darwiche, A. (2003). structure-based variable ordering heuristic SAT.
Proceedings Eighteenth International Joint Conference Artificial Intelligence
(IJCAI-03), pp. 11671172.
Koller, D., & Friedman, N. (2009). Probabilistic Graphical Models: Principles Techniques. MIT Press.

764

fiExploiting Structure Probabilistic Inference

Littman, M. L. (1999). Initial experiments stochastic satisability. Proceedings
Sixteenth National Conference Artificial Intelligence (AAAI-99) (Orlando, Florida,
United States edition)., pp. 667672.
Miller, R. A., Masarie, F. E., & Myers, J. D. (1986). Quick medical reference diagnostic
assistance. Medical Computing, 3, 3448.
Olesen, K. G., Kjaerul, U., Jensen, F., Jensen, F. V., Falck, B., Andreassen, S., & Andersen,
S. K. (1989). MUNIN network median nerve: case study loops. Appl.
Artificial Intelligence, 3 (2-3), 385403.
Parker, R., & Miller, R. (1987). Using causal knowledge create simulated patient cases:
CPCS project extension INTERNIST-1. 11th Symposium Computer Applications Medical Care, pp. 473480.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference. Morgan Kaufmann.
Sang, T., Bacchus, F., Beame, P., Kautz, H., & Pitassi, T. (2004). Combining component
caching clause learning eective model counting. Proceedings 7th
International Conference Theory Applications Satisfiability Testing (SAT04).
Sang, T., Beame, P., & Kautz, H. (2005a). Solving Bayesian networks weighted model
counting. Proceedings Twentieth National Conference Artificial Intelligence (AAAI-05), pp. 110.
Sang, T., Beame, P., & Kautz, H. A. (2005b). Heuristics fast exact model counting..
Proceedings 8th International Conference Theory Applications
Satisfiability Testing (SAT-05), pp. 226240.
Shani, G., Brafman, R. I., Shimony, S. E., & Poupart, P. (2008). Ecient ADD operations
point-based algorithms. Proceedings Eighteenth International Conference
Automated Planning Scheduling (ICAPS-08), pp. 330337.
Takikawa, M., & DAmbrosio, B. (1999). Multiplicative factorization noisy-MAX.
Proceedings Fifteenth Conference Uncertainty Artificial Intelligence (UAI99), pp. 622630.
Zagorecki, A., & Druzdzel, M. J. (1992). Knowledge engineering Bayesian networks:
common noisy-MAX distributions practice?. Proceedings 10th
European Conference Artificial Intelligence (ECAI-92), pp. 482489.
Zhang, N. L., & Poole, D. (1996). Exploiting causal independence Bayesian network
inference. J. Artificial Intelligence Research, 5, 301328.

765

fiJournal Artificial Intelligence Research 40 (2011) 677-700

Submitted 09/10; published 03/11

Identifying Aspects Web-Search Queries
Fei Wu
Jayant Madhavan
Alon Halevy

wufei@google.com
jayant@google.com
halevy@google.com

Google Inc, 1600 Amphitheatre Pkwy,
Mountain View, CA 94043 USA

Abstract
Many web-search queries serve beginning exploration unknown space
information, rather looking specic web page. answer queries eectively, search engine attempt organize space relevant information
way facilitates exploration.
describe Aspector system computes aspects given query.
aspect set search queries together represent distinct information need relevant
original search query. serve eective means explore space, Aspector
computes aspects orthogonal high combined coverage.
Aspector combines two sources information compute aspects. discover
candidate aspects analyzing query logs, cluster eliminate redundancies.
use mass-collaboration knowledge base (e.g., Wikipedia) compute candidate
aspects queries occur less frequently group together aspects likely
semantically related. present user study indicates aspects
compute rated favorably three competing alternatives related searches
proposed Google, cluster labels assigned Clusty search engine, navigational
searches proposed Bing.

1. Introduction
Web-search engines today predominantly answer queries simple ranked list results.
method successful, relies assumption users information need satised single page Web. However, several studies (Broder,
2002; Rose & Levinson, 2004) alluded fact many user queries merely
beginning exploration unknown space information. queries likely
better served users provided summary relevant information space
means conveniently exploring it. paraphrase, rather nding needle
haystack, queries would benet summarizing haystack (Rajaraman,
2008). Several commercial attempts recently made provide better answers
queries, including systmes like Carrot2, Clusty, Kosmix, Yahoo!Glue.
paper describes Aspector system addresses following problem: given
exploratory search query q, compute set aspects enables convenient exploration
Web content relevant q. dene aspect set search
queries together represent distinct information need relevant original search
query, similar Wangs denition Latent Query Aspect (Wang, Chakrabarti, & Punera,
2009). example, consider queries Table 1 potential aspects.
aspect covers dierent kind information together span large amount
c
2011
AI Access Foundation. rights reserved.

fiWu, Madhavan, & Halevy

vietnam travel
travel guides
packages / agencies
visa
blogs / forums
travel advisories
weather
cities (Hanoi / Saigon /...)

kobe bryant
statistics
pictures / photos
videos / youtube
shoes
injury reports
girlfriend
trade rumors

Table 1: Potential aspects queries vietnam travel kobe bryant.

relevant information search engine users might interested in. Two simple ways
search engine utilize aspects oer related searches categorize search
results aspects relevant to. Aspects also form basis various
mashup-like interfaces, e.g., aspect pictures trigger inclusion images,
weather trigger weather report gadget. Computing aspects queries seen
rst step towards mining knowledge base, called database user intentions (Battelle,
2005). knowledge base timely culture-sensitive expression peoples interests.
Inferring knowledge base entities serve basis eective presentation
information, therefore signicant ramications search, advertising
information dissemination.
Aspector computes aspects query q using search-engine query log, augmented
information knowledge base created mass-collaboration (Wikipedia). Given
query q, related queries extracted query log candidate aspects.
logs excellent mirror users interests, also result noisy redundant
aspects, e.g., top related queries vietnam travel include vietnam visa vietnam travel
visa. Furthermore, query logs limited utility generating aspects less popular
queries, e.g., much fewer related queries laos travel vietnam travel.
describe following algorithmic innovations address challenges. First, show
redundant candidate aspects removed using search results. Second, apply
class-based label propagation bipartite graph compute high-quality aspects even
long tail less popular queries. Finally, show knowledge bases used
group candidate aspects categories represent single information need. believe
solution demonstrates interesting interplay query logs knowledge
bases yet investigated research literature.
describe detailed experimental evaluation Aspector. compare aspects
generated Aspector three possible competing approaches related searches
proposed Google.com, cluster labels proposed Clusty.com, navigational searches
proposed Bing.com. Related searches navigational searches typically also generated analysis query logs. Cluster labels generated grouping search
results original query extracting labels documents within cluster.
show aspects diverse three systems. also show
aspects span larger space information expose results
original query, additional results considered highly relevant users.
678

fiIdentifying Aspects Web-Search Queries

user study nds results Aspector preferred related searches, cluster
labels navigational searches means exploration.
Section 2 denes problem computing aspects, Section 3 considers potential alternative approaches. Section 4 describes generation candidate aspects, Section 5
describes Aspector selects aspects candidates. Section 6 describes experimental evaluation,and Section 7 describes related work. Section 8 concludes.

2. Problem Definition
begin dening scope problem address.
Queries: assume queries sequence keywords, typical searchengine interfaces. techniques meant apply arbitrary queries. focus
exploratory queries, specically, assume either entity names (e.g.,
country Vietnam) entity property name (e.g., Vietnam travel). Thus,
interested computing aspects entities general context particular
property.
paper handle problem segmenting entity property names
queries (previous work, Bergsma & Wang, 2007; Tan & Peng, 2008, addressed
problem). question identifying exploratory queries query stream also
beyond scope paper.
Aspects: aspect query q meant describe particular sense q corresponding information need. Specically, aspect represented collection
search queries related q. Given q, compute set aspects a1 , . . . , , along
scores p(ai |q) used rank them.
Since aspects collections search queries, compare aspects based search
results retrieved queries constitute them. Aspects meant capture diverse
dimensions along organize exploration entire space information
relevant query. Hence, set aspects computed query
following properties:
Orthogonality: given two aspects, a1 a2 , search results a1 a2
dierent other.
Coverage: search results provided aspects oer good overview
relevant space information.
Thus, two sets aspects computed query compared based
pairwise orthogonality constituent aspects combined coverage
aspects. evaluation aspects inherently subjective, typical area web
search. Hence, present user studies aspects computed dierent approaches
qualitatively rated large number independent users. note
compare dierent approaches computing aspects, focus dierent ways
presented users.

3. Alternative Approaches
describe Aspector generates aspects, briey mention two strawman
approaches problem explain insucient needs.
679

fiWu, Madhavan, & Halevy

Class

NBA Player

University

Wikipedia
birth date
position
birth place
college
nationality height(ft)
draft year
draft
career start height(in)
name
city
established
website
country
type
campus
state
undergrad
motto

Query Log
injury
pictures
nba
wallpaper
bio
salary
shoes
girlfriend
stats
biography
library basketball
football
athletics
alumni admissions
tuition
baseball
jobs
bookstore

Table 2: Two classes attributes Wikipedia dierent classlevel aspects computed query log.

3.1 Community-Created Knowledge Bases
Knowledge bases, especially created large community contributors,
rich source information popular entities. cover wide spectrum user
interests potentially used organize information relevant search queries.
particular, properties Infoboxes Wikipedia articles potentially used
candidate aspects. Wikipedia contains 3,500 classes 1 million entities
class average 10 attributes. Wikipedia column Table 2 shows
attributes two example classes. Freebase another community-created KB
1,500 classes.
Binary relationships recorded knowledge base fall signicantly short providing
good set aspects query. example, consider properties associated
Cambodia Wikipedia Infobox capital, flag, population, GDP, etc. None
words appear top-10 frequent queries contain word cambodia. addition,
knowledge base limited describing well dened entities. example, Cambodia
entity knowledge base, Cambodia Travel not. However, queries Web cover
much well dened entities.
underlying reason knowledge bases fall short constructors choose
attributes based traditional design principles, good aspects follow
principles. example, turns cambodia travel good aspect vietnam travel,
many people consider side trip Cambodia visiting Vietnam. However,
designing knowledge base, Cambodia would never attribute Vietnam.
Instead, knowledge base would assert Vietnam Cambodia neighbors,
include rule states X next Y, X travel may aspect
travel. Unfortunately, coming rules specifying precise preconditions
formidable task highly dependent instances applies to. example,
pakistan travel aspect india travel, even though two countries neighbors.
680

fiIdentifying Aspects Web-Search Queries

3.2 Web Documents
Another approach nding aspects cluster documents Web relevant
query q, assign extract labels cluster (Blei, Ng, & Jordan, 2003; Zeng,
He, Chen, Ma, & Ma, 2004). show experiments, main disadvantage
coverage resulting aspects may low approach considers
documents returned response original query. practice, users conduct
data exploration sessions queries, queries sessions also lead
interesting aspects might found among results original query.
Furthermore, challenging generate succinct names aspects
cluster.

4. Generating Candidate Aspects
Aspector generates candidate aspects query logs. Query logs reective
broad range user interests, less eective generating aspects infrequent
queries. rst describe generate instance-level aspects, augment
class-based aspect propagation using knowledge base.
4.1 Instance-Level Candidate Aspects
Given query q, start considering query renements super-strings
candidate aspect.
4.1.1 Query Refinements
query qj renement q, user poses qj q performing single search
task. Query logs mined identify popular renements individual queries. Search
engines typically use popular renements basis proposing related searches.
process renements follows: rst, query log segmented sessions representing sequences queries issued user single search task. Suppose fs (q, qj )
number sessions query qj occurs q, estimate renement
score pr qj normalizing fs (q, qj ) possible renements, i.e.,
fs (q, qj )
pr (qj |q) =
fs (q, qi )
Observe proposing related searches based query renements is, principle,
optimized towards goal helping users nd single page containing specic answer
(rather helping user explore space). example, top 10 renements
query NBA player yao ming includes 6 NBA players kobe bryant
michael jordan. Though related, renements necessarily best aspects
query.
4.1.2 Query Super-Strings
query qj super-string q includes q sub-string. example, vietnam
travel package super-string vietnam travel. Unlike renement, super-string qj need
681

fiWu, Madhavan, & Halevy

belong session q. fact, random selection 10 popular queries,
found average overlap 1.7 top 10 renements
top 10 super-strings. sense, super-strings explicitly related queries
renements implicitly related.
Super-strings assigned scores similar pr above, mimicking super-string
pseudo-renement, i.e., assume imaginary session q preceded superstring qj . Suppose f (qj ) number occurrences qj query logs, estimate
super-string score pss (qj |q) 1 :
pss (qj |q) =

f (qj )

f (q) + f (qi )

Aspector considers renements super-strings q candidate aspects
assigns single instance-level aspect score. candidate aspect qj , assign
score pinst follows:
pinst (qj |q) = max(pr (qj |q), pss (qj |q))
given q, normalize pinst (qj |q)s add 1.
4.2 Class-Based Aspect Propagation
Query-log analysis ineective generating instance-level candidate aspects less frequent queries. example, generate good candidate aspects vietnam travel,
laos travel. However, recommend aspects common travel
many countries Laos. use variation label-propagation algorithm named
Adsorption (Baluja, Seth, Sivakumar, Jing, Yagnik, Kumar, Ravichandran, & Aly, 2008).
rst apply query segmentation extract entity e (laos example)
property p (travel) query q. Next, use knowledge base (e.g., Wikipedia
Infobox) identify class, classes, C e (e.g., country south-east asian country
laos). construct directed bipartite graph G = (V, E, ) shown Figure 1.
nodes left instance-level query nodes laos travel, right
class-level nodes like country travel. E denotes set edges, : E R
denotes nonnegative weight function. set weights edges instance nodes
class nodes 1, weights edges class nodes instance nodes K,
design parameter controlling relative-importance two factors. goal

compute p(qj |q), aspect distribution node q.
Following work Baluja et al. (2008), nodes aspect distribution iteratively
updated linear combination neighbors, converge (this algorithm
shown equivalent performing random walk graph). Since use Wikipedia
Infobox knowledge base, instance belongs single class, two iterations
guaranteed achieve convergence. rst iteration computes class-level aspects
follows:
1
pinst (qj |q)
pclass (qj |q) =
|C| qC
1. use conservative lower bound estimate. corresponding upper bound pss (qj |q) =
exceed 1.

682

f (qj )
f (q)



fiIdentifying Aspects Web-Search Queries

Instances

Classes

vietnam travel
southeast asia travel
laos travel
country travel
canada travel

...

...

Figure 1: bipartite graph class-based aspect propagation.
second iteration smoothes aspect distribution instance node q pclass (qj |q)
follows,
pinst (qj |q) + K pclass (qj |q)
(1)
1+K
Section 6 tested eect K performance Aspector. experiments found following variation computing class-level aspects leads
slightly better results:
p(qj |q) =

pclass (qj |q) =

1
I(pinst (qj |q) > 0))
|C| qC

where, I(pinst (qj |q) > 0)) = 1 pinst (qj |q) > 0, 0 otherwise.
Table 2 shows examples top class-level aspects derived two classes compares
corresponding top attributes Wikipedia infobox. see
two sets aspects little overlap, illustrates community created
schemata fall signicantly short providing good set aspects search queries.

5. Selecting Aspects
section describes Aspector prunes set candidate aspects, groups them,
eventually ranks ordered list subset selected.
5.1 Eliminating Duplicate Aspects
often case generated aspect list contains similar candidates may
considered redundant. example, top candidate aspects query vietnam travel
include vietnam travel package, vietnam travel packages vietnam travel deal,
represent either identical similar user intents. particular, note set
web documents returned aspects search engine likely
similar.
remove redundant aspects, compute similarity matrix, {sim(ai , aj )},
every pair candidate aspects cluster based similarity.
5.1.1 Computing Aspect Similarity
Since aspects contain words, estimating similarity based simple comparison words unlikely accurate. Therefore, enrich representation
683

fiWu, Madhavan, & Halevy

aspect considering top m2 search results returned posing aspect search
query. consistent goal enabling orthogonal exploration aspects
similar top results unlikely orthogonal.
Let Di top web pages retrieved aspect ai . estimate similarity ai
aj similarity corresponding sets Di Dj . compute sim(Di , Dj ),
rst compute similarity dsim given pair web pages {di Di , dj Dj }.
use standard cosine distance TF/IDF word-vectors two
documents. computational eciency, consider head snippet
web page instead entire text contents3 .
sim(Di , Dj ) potentially estimated averaging similarities dsim(di , dj )
pairs web pages, experiment dataset, found better instead compute
average highest similarity web page. di Di , assign score:
sim(di , Dj ) = maxk dsim(di , dk ). Likewise, assign sim(Di , dj ) = maxk dsim(dk , dj ).
nal aspect similarity computed as:




sim(ai , aj ) = sim(Di , Dj ) =

sim(di , Dj )

2|Di |

+

j

sim(dj , Di )
2|Dj |

could alternatively treat Di one single document concatenating {di
Di } estimate sim(qi , qj ) corresponding dsim(Di , Dj ). computationally
ecient, quality aspects poorer.
5.1.2 Clustering Aspects
principle, apply clustering algorithm, K-means spectral clustering,
resulting aspect similarity matrix. However, algorithms often require pre-setting
number desired clusters, dicult context. addition, number
clusters also varies signicantly one query another. Note appropriate
number clusters necessarily number resulting aspects show
user.
instead apply graph-partition algorithm clustering. algorithm proceeds
creating graph nodes aspects, ai , edge connecting nodes
ai aj sim(ai , aj ) > , pre-dened threshold. connected sub
graphs treated cluster. choose label cluster aspect ak
highest p(ak |q) cluster (Formula 1).
design parameter easier set pretty stable dierent queries,
shown experiments. note similar algorithms star-clustering (Aslam,
Pelekov, & Rus, 2004) also used.
5.2 Grouping Aspects Vertical Category
many cases, even eliminating redundant aspects, nd left
aspects seemingly dierent, semantically grouped single category.
example, query vietnam travel, top non-redundant candidate aspects
2. use = 8 experiments performs well. Larger might achieve slightly better performance cost heavier computation.
3. also tired using whole document web page, slightly better performance.

684

fiIdentifying Aspects Web-Search Queries

ho chi minh city, hanoi da nang. dierent cities, principle
likely represent single information need nding information cities
Vietnam. Further, given budget xed number aspects presented
user, might make sense overwhelm list aspects denoting cities
Vietnam. Instead, single aspect named Cities presented.
community-created knowledge bases leveraged Aspector
tries identify sets related aspects consulting Wikipedia Infobox system4 .
nds multiple aspects contain dierent entities belong class Wikipedia,
creates aggregate aspect (with label class) groups together.
encounter two challenges looking Wikipedia classes entities.
First, entity appear dierent synonymous tokens. example, nyu
common acronym new york university. Currently use redirect pages Wikipedia
infer synonyms. Redirect pages Wikipedia point synonym terms principal
article. result, aspect nyu query yale university grouped harvard
university oxford university5 . Second, token refer multiple entities
belong dierent classes lead bad grouping decisions. example, HIStory
FOOD names music albums Wikipedia, history food also
aspects query vietnam. simple lookup tokens Wikipedia might lead
erroneously grouping single album group. Aspector uses disambiguation
pages Wikipedia identify tokens likely multiple senses. Infobox
class retrieved entities disambiguation pages. conservative
method improved via collaborative classication (Meesookho, Narayanan, &
Raghavendra, 2002). example, earth, moon venus aspects mars. Since
ambiguous based Wikipedia, current Aspector would treat
individual aspects. However, possible group together single planet aspect,
given three candidates planet one possible type.
5.3 Selecting Aspects
nal step Aspector selecting aspects. note absolute ranking
aspects important context, expect search results
aspects spread screen rather presented single list. However,
still need select top-k aspects present. selection top-k aspects based
original goals increasing coverage guaranteeing orthogonality.
Aspector uses score aspect, p(ai |q), measure coverage. achieve
balance coverage orthogonality, Aspector uses greedy algorithm
selects aspects ratio score p(ai |q) similarity aspects already
selected aspects. algorithm produces ranked list aspects, G.

4. ontologies like Freebase Yago also used.
5. trick used constructing bipartite graph Section 4.2 well.

685

fiWu, Madhavan, & Halevy

Input: Set = {ai }
Output: Set G

// Label aspects clusters de-duplication.
// Ranked list aspects.

Initialization: G = ;
a0 = argmaxai p(ai |q);
move a0 G;
(S = )
ai
set sim(ai , G) = maxaj G sim(ai , aj );
p(ai |q)
;
anext = argmaxai Sim(a
,G)
move anext G;
Algorithm 1: Aspector selects top-k aspects balancing coverage orthogonality.
Observe set similarity sim(ai , G) maximum similarity ai
aspects already G. termination, Aspector returns top n aspects ranked order
(in experiments used n = 8). experiments indicate balancing coverage
orthoganality leads better selection aspects simply using coverage.

6. Experiments
section evaluate system Aspector particular, answer following
questions.
Quality aspects: compare results Aspector three potential
competing systems related searches proposed Google (henceforth Grs), cluster labels
assigned Clusty search engine (Ccl), navigational searches proposed Bing
(Bns). better support exploration dierent parts space relevant information,
aspects query orthogonal other. Aspects also increase
coverage, i.e., reveal information already available original query,
still relevant it. Using combination search result analysis user
study, show aspects less similar (and hence orthogonal)
(Section 6.3), aspects able increase coverage (Section 6.4), aspects
overall rated favorably Grs, Ccl, Bns (Section 6.5).
Contributions dierent components: Aspector generates instance-level
aspects performs class-based aspect propagation, eliminates duplicates, groups
remaining ones using knowledge base. show instance-level class-level aspects
tend dierent, best results obtained judiciously combining
(Section 6.6). also show clustering algorithm able stably eliminate
duplicate aspects crossing dierent domains, grouping aspects positive
impact quality aspects (Section 6.7).
6.1 Experimental Setting
compute candidate aspects query logs, used three months worth anonymized
search logs Google.com. used snapshot English version (2008.07.24)
Wikipedia Infobox serve knowledge base. Unless otherwise mentioned, used
686

fiIdentifying Aspects Web-Search Queries

K = 0.1 class-based aspect propagation (Equation 1). describe test suite
user study.
Test Queries: focus queries entity names entity name
property name. construct test suite contains 6 sets queries: entity
names Wikipedia classes Country, NBA player, Company, Mountain, University,
one entity-property queries form Country travel. construct mix
popular rare queries, six sets select 5 queries occur frequently
query stream, 5 relatively uncommon, 5 chosen randomly class
(as long appear query logs). Thus, total 90 test queries.
experiment used random subset test queries.
User Study: part experimental analysis, performed user studies using
Amazon Mechanical Turk (Amt) system. Amt, requesters (like us) post tasks pay
anonymous registered workers respond them. Tasks structured sequence
questions workers expected respond per instructions provided
requester. example, compare two algorithms compute aspects, design
sequence tasks query two lists aspects (computed
algorithm) shown. worker rate whether one list better
similar. Amt ensures worker respond task once.
Since, workers user study completely unknown requester, less
chance bias. Amt shown eective ecient way collect data
various research purposes (Snow, OConnor, Jurafsky, & Ng, 2008; Su, Pavlov, Chow, &
Baker, 2007). experiments, used default qualication requirement workers
requires worker HIT approval rate (%) greater equal 95.
6.2 Points Comparison
Grs considered representative current approaches based mining
renements super-strings query logs. likely Grs performs
instance-level analysis attempt identify distinct user information needs.
Ccl clusters result pages assigns human-understandable labels cluster.
notably, clusters determined purely results original query,
attempt enable exploration results retrieved query. Further,
likely cluster labels extracted analysis contents result pages
(web documents). note clustering hierarchical, experiments
considered top-level labels.
Bns provides navigation searches (right Related searches result pages)
help users better explore information space. Bings goal closest spirit,
technique applies narrow set domains. note Bns sometimes
provides generic aspects (e.g., videos, images), consider those.
note neither Grs Ccl designed explicit goal computing
aspects help explore information space relevant query. However,
viewed close alternatives terms results may produce, therefore oer
two points comparison.
Table 3 shows aspects, related searches, cluster labels, navigational searches
obtained four systems example queries. rest section,
687

fiWu, Madhavan, & Halevy

Query

Mount Shasta

Yale University

Grs
volcano
national park
climbing
vortex
camping
hotels
attractions
lodging
harvard university
athletics
press
brown university
stanford university
columbia university
cornell university
duke university

Ccl
photos
hotels
real estate
weed
wilderness, california
climbing
weather, forecast
ski
school
department
library
images
publications
admissions
laboratory
alumni

Bns
image
weather
real estate
hotels
lodging
rentals
reference/wikipedia
admissions
jobs
bookstore
alumni
library
reference/wikipedia
images

Aspector
resort
weather
high school
real estate
hiking
pictures (photos)
map
ski area
press
art gallery
athletics
harvard (oxford, stanford,...)
jobs
bookstore
admissions
tuition

Table 3: Sample output Grs, Ccl, Bns, Aspector.
rst show aspects Aspector average orthogonal, increase coverage,
rated better overall Grs, Ccl Bns.
6.3 Orthogonality Aspects
establish orthogonality aspects, measure inter-aspect similarity less
similar aspects are, orthogonal are. rst describe compute
inter-aspect similarity, report values query set Aspector, Grs,
Ccl, Bns.
Section 5, used TF/IDF-based word vectors estimate aspect similarity. Using
measure establish orthogonality bias evaluation favor Aspector.
Hence, use alternate measure aspect similarity employs topic model (Blei
et al., 2003). Briey, topic models built learning probability distribution
words documents topics might underlie document. Given text fragment,
topic model used predict probability distribution topics relevant
fragment. example, text company page Google Inc., might result
topic distribution search engine, 0.15, online business, 0.08, . . .. use topic
model developed internally Google (henceforth TMG). Given two text fragments t1
t2 , compute topic similarity tsim(t1 , t2 ) cosine distance
topic distribution vectors T1 T2 .
Since aspects contain words, extend augmenting aspect
corresponding top search results (as Section 5). Given aspects a1 a2 , let D1
D2 respective top web search results. compare D1 D2 using TMG
estimate aspect similarity. Specically, compute average inter-document similarity.
sim(a1 , a2 ) =

1
k2


di D1 ,dj D2

688

tsim(di , dj )

(2)

fiIdentifying Aspects Web-Search Queries

Normalized Inter-aspect Similarity

Aspect Similarity Comparison
0.06

0.04

0.02

0

Aspector

BNS

CCL

GRS

Figure 2: results Aspector orthogonal Grs, Ccl, Bns.

Given A, set n aspects, determine inter-aspect similarity (asim) average
pair-wise aspect similarity.
asim(A) =


2
sim(ai , aj )
n(n 1) ,a


j

order make sense magnitude asim, normalize using average intraaspect similarity isim(A) obtained comparing aspect itself.
isim(A) =

1
sim(ai , ai )
|A|


Note, sim(ai , ai ) ususally equal 1 based equation 2. result normalized
inter-aspect similarity nsim.
nsim(A) =

asim(A)
isim(A)

Thus, aspects identical, nsim(A) = 1, entirely orthogonal
nsim(A) = 0.
query, retrieved number aspects (at 8) system,
Figure 2 shows average normalized inter-aspect similarity results output
system.
clearly seen, Aspector least normalized inter-aspect similarity
hence orthogonal aspects. improvement Bns (45%) likely due
grouping related aspects vertical category. improvement Grs (90%)
likely due inclusion class-based aspects grouping related aspects
vertical category. improvement Ccl (60%) likely space labels
restricted results returned original query.
689

fiWu, Madhavan, & Halevy

Urls Aspector Covered Google.com
Top1_All

Top1_Popular

Top8_All

Top8_Popular

0.5


e
r
e
vo
c 0.4
Ls
R
U
r 0.3

ct
e
p


f 0.2

n

tic
0.1
ra
F

0

0

100

200

300

400

500

# top urls Google.com

Figure 3: Fraction top web pages retrieved aspects also top 500 pages
retrieved original search query.

6.4 Increase Coverage
validate increase coverage interested answering two questions: (1)
aspects enable users reach information original query? (2)
additional information relevant user query?
6.4.1 Information
show aspects reach information, compare web pages retrieved
using aspects computed Aspector retrieved original search
query. Given, query q computed aspects A, let DN set top N web pages
retrieved Google query q. Let Dki collection top k web pages retrieved
Google aspect ai A, let Dka union Dki s. measure
fractional overlap DN Dka , i.e.,

|Dka DN |
|Dka | .

Figure 3 shows average fractional overlap Dka DN k = 1 k = 8
dierent values N (x-axis). results averaged two sets queries:
(1) 90 queries, (2) subset 30 popular queries, 10 aspects computed
query. results clearly indicate, even considering top 500 search
engine results, k = 1, 45% web pages D1a retrieved.
words, 55% web pages retrieved using aspects even top 500 (note
|D1a | 10). overlap even lower 33% considering k = 8. shows
aspects clearly able retrieve new information.
order isolate potential eects due rare queries search engines
typically propose related searches, separately consider subset popular queries.
Interestingly, nd overlaps even smaller hence aspects able
retrieve even information. likely potentially diverse
information Web popular entities.
690

fiIdentifying Aspects Web-Search Queries

Domain
country
country travel
nba player
company
university
mountain
Total

Cumulative Resp.
Cov. Covered

N

N
274 26
274 26
238 8
258 8
269 53
223 43
280 48
228 40
309 31
235 25
242 38
282 38
1612 204
1500 180



28
25
33
31
34
26
177

Url Ratings
Cov. Covered
N

N
2
28 2
0
27 0
0
27 0
2
26 1
0
26 0
2
30 2
6
164 5

Table 4: User responses indicating whether pages retrieved aspects relevant
query.

6.4.2 Relevant Information
establish information retrieved aspects fact relevant users
information needs, conducted Amt user study. query q, considered
top 10 aspects aspect consider top retrieved web page, i.e., D1a .
constructed list aspect-based results LA contained 4 results (selected random
D1a ), 2 overlapped D500 2 overlap D500 . Users
asked evaluate results (a) relevant, (b) irrelevant original
query q. order place results context, also showed LA alongside LG , top
5 regular search engine results (these rated, context).
considered 90 test queries responses 10 users case. detailed
results shown Table 4. columns N indicate whether web pages
deemed relevant not. Covered Covered columns separately consider
web pages LA covered D500 not. Cumulative
Responses columns aggregate responses users, Url Ratings columns
aggregate ratings users separately web page LA . seen,
total 177 web pages covered, deemed relevant
majority users.
results indicate overall, vast majority additional web pages retrieved
aspects deemed relevant majority users. addition, ratio relevant
not-relevant results covered not-covered web pages.
indicates additional information relevant, likely relevant
covered information.
Note coverage results also establish aspects likely span much
information space alternate schemes rely analyzing results
original query, e.g., cluster labels Clusty.
6.5 Comprehensive Performance Comparison
compare overall performance Aspector Grs, Ccl, Bns conducting
user study using Amt. separately compared Aspector
systems. case, selected random subset around 30 queries original
691

fiWu, Madhavan, & Halevy

set 90 queries. ltered queries dont return aspects systems.
query, two lists (at most) 8 aspects generated, one using Aspector
using Grs, Ccl Bns, presented Amt rater
following instructions:
query represents start session explore information topic
(presumably related query). user query, display two lists related
queries and/or properties. want compare two lists query identify
two lists enables better subsequent exploration information.
lists query presented side-by-side, user could rate one better
other, simply rate same. raters informed
source list side-by-side positioning lists randomly selected.
collected responses 15 raters query.
Tables 5, 6 7 summarize results user study. Cumulative Responses
columns aggregate responses raters queries. F, E, columns
indicate ratings favor Aspector, even ratings, Aspector (and favor
Grs Ccl) respectively. Query Ratings columns aggregate ratings
raters query, F indicating raters rated Aspector favor
systems (respectively E A).
seen Table 5, Aspector clearly outperforms Grs. improvements
likely due increased orthogonality grouping aspects vertical
category. also clear Table 6, Aspector also signicantly outperforms Ccl,
likely due increased coverage.
ascertain statistical signicance evaluation, comparison, performed standard paired t-test. individual query, considered total number
F responses responses. comparison Grs, mean perquery dierence (F-A) 10.7, i.e., average 10.7 total 15 evaluators rated
Aspector better. dierence statistically signicant two-tailed pvalue less 0.0001. comparison Ccl, mean dierence 13.1
signicant p-value less 0.0001.
Bns produces aspects small number domains. set context comparison measured breadth Bns. chose top 100 Wikipedia Infobox classes,
selected 15 entities (5 popular, 5 less common, 5 randomly) class
section 5.3. Bns provided aspects 17.6% entities. particular, Bns provided
aspects 29.4% popular entities 9.8% less common entities. Bns
provided aspects entities 48 classes, including scientist, magazine
airport. second limitation Bns provides aspects entity queries.
Hence, Bns provide aspects queries vietnam travel, seattle coee
boston rentals. third limitation Bns provides class-level aspects, though aspects may dier slightly one instance another. example,
Bns misses aspect starbucks seattle, turkey slap turkey, number
change kobe bryant.
90 queries, 41 obtain aspects Bns. Table 7 shows
Aspector Bns rated comparably w.r.t. limited set queries. advantages
Aspector come fact judiciously balances instance-level class-level
aspects. interesting point raters familiar particular
692

fiIdentifying Aspects Web-Search Queries

Domain
country
country travel
nba player
company
university
mountain
Total

Cumulative
F
E
60
7
54
17
68
5
51
14
59
11
58
15
350 69

Resp.

8
3
2
10
5
1
29

Query Ratings
F
E

4
0
1
5
0
0
5
0
0
4
0
1
5
0
0
5
0
0
28 0
2

Table 5: User responses comparing Aspector Grs.
Domain
country
country travel
nba player
company
university
mountain
Total

Cumulative
F
E
57
8
62
5
69
3
56
1
62
3
53
7
359 27

Resp.

9
0
2
12
8
7
38

Query Ratings
F
E

4
1
0
5
0
0
5
0
0
5
0
0
5
0
0
5
0
0
29 1
0

Table 6: User responses comparing Aspector Ccl.
instance, tend prefer class-level aspects. experiment, observation
sometimes gives Bns advantage.
6.6 Instance-Level Versus Class-Level Aspects
Recall Aspector balances class-level instance-level aspects given
query. Consider, example, class NBA players. 1365 players identied
Wikipedia. able identify 8 candidate instance-level aspects
126 (9.2%). 953 (69.8%) players, unable infer instance-level
aspects. However 54 class-level aspects appear least 5 instances,
Domain
country
nba player
company
university
mountain
Total

Cumulative
F
E
65
29
52
12
20
2
92
9
6
6
235 58

Resp.

56
71
53
19
18
217

Query Ratings
F
E

5
1
4
3
0
6
0
0
5
8
0
0
1
0
1
17 1
16

Table 7: User responses comparing Aspector Bns. Note result
ltering 54% testing queries Bns provides aspects, case users
always rate Aspector better.

693

fiWu, Madhavan, & Halevy

Domain
country
country travel
nba player
company
university
mountain
Total

Cumulative
F
E
12
17
12
11
10
14
12
13
17
9
10
14
73
78

Resp.

46
52
51
50
49
51
299

Query Ratings
F
E

0
0
5
0
0
5
0
0
5
0
0
5
1
0
4
0
0
5
1
0
29

Table 8: User responses comparing Aspector K = 0 K = 1.

thus giving us potentially larger pool good candidate aspects. balancing two
sources aspects, Aspector able successfully compute reasonable aspects even
less frequent queries.
compared extent class-based aspect propagation contributes
quality aspects generated. this, performed Amt user study. considered dierent values parameter K Formula 1: 0, 0.1, 1, 10, 100,
indicating progressively higher contribution class-level aspects. Aspect lists generated subset 30 queries (5 set) value K. compared two
aspect lists time, performed three sets experiments comparing (1) K = 0
K = 1 (Table 8), (2) K = 0.1 K = 10 (Table 9), K = 1 K = 100 (Table 10).
experiment used set 30 queries users asked pick
two sets aspects preferred query (same task description Section 5).
Responses collected 15 users case. Note ensure signicant dierences aspect lists compared, experiments consider consecutive K
values (e.g., 0 0.1). earlier experiment consecutive K values used,
found many queries subtle dierence hence large numbers users rated
lists comparable. number queries fewer Table 9 Table 10, since
remaining ones resulted aspect lists K values surprising
since, larger K values result increased inuence set class-based aspects.
nd aspect lists K = 1 rated signicantly better K = 0
(the mean per-query dierence (F-A) 7.53 signicant two-sided p-value less
1E-9). lists K = 10 preferred K = 0.1 (though
smaller (F-A) 2.4 p value 0.008), lists K = 100 K = 1
rated (the mean (F-A) 0.3 insignicant p value 0.8).
seem indicate clearly class-based aspects helpful improving user
experience.
However, note results might marginally over-state importance classbased aspects. users perception aspects dependent upon users
interest familiarity entity question entity, though popular,
familiar participant study, likely select class-based aspects.
hand, found universally well known entities, company
microsoft, lists instance-based aspects always preferred.
694

fiIdentifying Aspects Web-Search Queries

Domain
country
country travel
nba player
company
university
mountain
Total

Cumulative
F
E
11
15
21
23
19
21
17
24
22
26
13
11
103
120

Resp.

34
16
35
34
27
21
167

Query Ratings
F
E

0
0
4
2
1
1
1
0
4
1
0
4
2
0
3
1
0
2
7
1
18

Table 9: User responses comparing Aspector K = 0.1 K = 10.
Domain
country
country travel
nba player
company
university
mountain
Total

Cumulative
F
E
3
8
16
18
5
12
33
29
14
20
21
23
92
110

Resp.

4
11
28
13
11
31
98

Query Ratings
F
E

0
0
1
2
0
1
0
0
3
4
0
1
1
1
1
2
0
3
9
1
10

Table 10: User responses comparing Aspector K = 1 K = 100.
6.7 Eliminating Grouping Aspects
consider impact content-based clustering used identify duplicate
aspects, vertical-category-based clustering groups aspects belonging
category.
6.7.1 Duplicate Elimination
computing candidate aspects query logs, possible nd multiple aspects
dierent names, semantically same. aspects eliminated order summary cover distinct axes. explained Section 5.1,
Aspector applies graph partitioning algorithm single parameter,
similarity threshold . conjecture similarity threshold intuitive set
stable across dierent domains.
test hypothesis, randomly selected 5 queries 5 domains.
query, took top 30 aspects candidates manually created gold-standard
correct aspect clustering results. computed aspect lists queries dierent
values threshold compared results gold-standard.
use F-Measure (F ) evaluate clustering results. particular, view
clustering series decisions, one N (N 1)/2 pairs aspects.
Figure 4 plots F values dierent values threshold test
domains. found case best performance threshold values 0.25
0.4. results indicate clustering performance respect pretty stable
across domains. Hence, experiments, set single value = 0.35.
695

fiWu, Madhavan, & Halevy

Mountain

NBA_Player

Country

University

Company

0.9
0.8

F-Measure

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

Similarity threshold

Figure 4: F-Measure aspect clustering dierent values similarity threshold .
domain, best performance around 0.35.

Domain
company
university
mountain
Total

Cumulative
F
E
25
14
18
7
6
3
49
24

Resp.

6
5
6
17

Query Ratings
F
E

3
0
0
2
0
0
0
1
0
5
1
0

Table 11: User responses comparing Aspector vertical-category grouping without. F, E, responses favor, even, grouping.

6.7.2 Vertical-Category Based Grouping
addition duplicates, observed often multiple aspects might belong
vertical category. Rather represent separate aspect, summarize
aspects presenting single group. Note grouping eliminate
aspects, simply lists single aspect. 6 90 queries
dataset, Aspector able group aspects vertical category.
before, deployed Amt user study 6 test queries results
shown Table 11, F indicating number responses favor vertical grouping
(with E dened accordingly). seen, aspect lists grouping
favored comparison ones without grouping.
Currently, Aspector groups aspects vertical category
corresponding disambiguation pages Wikipedia. conservative solution avoids potential errors ambiguity exists, also misses opportunities. example,
query mount bachelor, mount hood mount baker appear separate aspects since
disambiguation pages entities. Rening grouping condition rich topic
future work.
696

fiIdentifying Aspects Web-Search Queries

7. Related Work
discuss work related area search-result organization query-log
mining.
7.1 Search Result Organization
Several works considered better organize search results. Agrawal, Gollapudi,
Halverson, Ieong (2009) classify queries documents categories return search
results considering document relevance diversity results. contrast, Aspector computes ne grained aspects instead abstract categories exploratory
queries necessary ambiguous. commercial systems like Kosmix Yahoo!Glue categorize information based type format (e.g. photo, video,
news map) retrieve top results category. Though dierent types often
approximate aspects, represent rich set semantically dierent groups
information sensitive instance-specic aspects. Carrot2 search engine
applies text clustering techniques returned search pages extracts keywords summarize cluster. Similar works done Bekkerman, Zilberstein, Allan (2007),
Blei et al. (2003), Crabtree, Andreae, Gao (2006), Wang, Blei, Heckerman
(2008). Multi-faceted search (Yee, Swearingen, Li, & Hearst, 2003) organizes collections
based set category hierarchies corresponds dierent facet. However category hierarchies requires heavy human eort construction maintenance.
Correlator system Yahoo! performs semantic tagging documents enable
mining related entities query. algorithms dont necessary discover clusters
correspond Web users search interests, dicult generate informative
cluster labels documents. use query logs complements document-based
approaches, reects searchers intentions rather intentions publishers.
Wang Zhai (2007) proposed organize search results based query logs.
represent query pseudo-document enriched clickthrough information
pick top-k similar current query, cluster aspects. Then,
classify resulting page corresponding aspect similarity. contrast,
generate aspects based idea query renements dont require aspect
current query similar clickthrough. example, query vietnam travel visa
important aspect vietnam travel, wont click-through properties.
7.2 Query-Log Mining
several eorts mine query logs interesting artifacts. Pasca Durme
(2007) extract relevant attributes classes entities query logs rather
Web documents done Bellare et al. (2006). main goal works create
knowledge base entities, hence results appropriately compared
Wikipedia Freebase.
Query renement suggestion analyze query logs predict next probable
query following current query (Cucerzan & White, 2007; Jones, Rey, Madani, & Greiner,
2006; Kraft & Zien, 2004; Velez, Wiess, Sheldon, & Giord, 1997). Hence, goal
help users nd single result page rather help navigating body relevant
697

fiWu, Madhavan, & Halevy

information. Bonchi, Castillo, Donato, Gionis (2008) proposed decompose query
small set queries whose union corresponds approximately original
query. However, experiments illustrated, constraint union resulting
pages correspond approximately original query signicantly limits available
body information expose user.
Wang et al. (2009) mine set global latent query aspects, dynamically select
top k aspects given query q help better navigate information space.
ways similar Aspector, two key dierences. First, discover
set global latent query aspect via maximizing target function, aspect
set aims apply many classes (important) queries. contrast, Aspector applies
class-based label propagation identify aspects. Therefore, aspects tend
ne-grained query(class)-specic. Second, selecting k aspects
query q, Wang et al. apply another optimization function tries cover many
original (frequent) query renements q. works ne popular queries
less popular queries query renements. experiments show
classes, long tail less popular queries.

8. Conclusions
described Aspector system computing aspects web-search queries. Aspects
intended oer axes along space information relevant query
organized, therefore enable search engines assist user exploring space.
Aspector generates candidate aspects query logs balances aspects
common classes entities vs. specic particular instances. Aspector
also eliminates duplicate aspects groups related aspects using reference ontology.
contrast purely knowledge-based approach, Aspectors results much broader
include aspects interest specic instances. contrast approach based
solely clustering results query, Aspector include aspects
represented directly querys answer.
set weights edges instances classes uniformly computing
class-based aspects. future direction compute better informed weighting functions
based available temporal, spatial contextual constraints. Another future work
allow multi-class memberships based ontologies besides Wikipedia Infobox.
incorporate aspects mainstream search engine need address two challenges. First, need reliably identify query stream queries benet
summarization approach. works (Miwa & Kando, 2007; White & Roth, 2009)
conducted area, much needs investigated. Second, done
Kosmix, need dynamically generate eective visualizations aspects.

References
Agrawal, R., Gollapudi, S., Halverson, A., & Ieong, S. (2009). Diversifying Search Results.
WSDM.
Aslam, J. A., Pelekov, E., & Rus, D. (2004). star clustering algorithm static
dynamic information organization. Journal Graph Algorithms Applicatins.
698

fiIdentifying Aspects Web-Search Queries

Baluja, S., Seth, R., Sivakumar, D., Jing, Y., Yagnik, J., Kumar, S., Ravichandran, D., &
Aly, M. (2008). Video suggestion discovery youtube: Taking random walks
view graph. WWW.
Battelle, J. (2005). Search: Google Rivals Rewrote Rules Business
Transformed Culture. Portfolio Hardcover.
Bekkerman, R., Zilberstein, S., & Allan, J. (2007). Web Page Clustering using Heuristic
Search Web Graph. IJCAI.
Bellare, K., Talukdar, P. P., Kumaran, G., Pereira, F., Liberman, M., McCallum, A., &
Dredze, M. (2006). Lightly-Supervised Attribute Extraction. NIPS.
Bergsma, S., & Wang, Q. I. (2007). Learning Noun Phrase Query Segmentation. EMNLPCoNLL.
Blei, D., Ng, A., & Jordan, M. (2003). Latent Dirichlet allocation. Journal Machine
Learning Research.
Bonchi, F., Castillo, C., Donato, D., & Gionis, A. (2008). Topical query decomposition.
KDD.
Broder, A. (2002). taxonomy web search. SIGIR Forum, 36 (2).
Crabtree, D., Andreae, P., & Gao, X. (2006). Query Directed Web Page Clustering. WI.
Cucerzan, S., & White, R. W. (2007). Query Suggestion based User Landing Pages.
SIGIR.
Jones, R., Rey, B., Madani, O., & Greiner, W. (2006). Generating query substitutions.
WWW.
Kraft, R., & Zien, J. (2004). Mining anchor text query renement. WWW.
Meesookho, C., Narayanan, S., & Raghavendra, C. S. (2002). Collaborative classication
applications sensor networks. SAMSP-Workshop.
Miwa, M., & Kando, N. (2007). Methodology capturing exploratory search processes.
CHI-Workshop.
Pasca, M., & Durme, B. V. (2007). Seek Get: Extraction Class
Attributes Query Logs. IJCAI.
Rajaraman, A. (2008).
Searching needle exploring haystack?.
http://anand.typepad.com/datawocky/2008/06/.



Rose, D. E., & Levinson, D. (2004). Understanding User Goals Web Search. WWW.
Snow, R., OConnor, B., Jurafsky, D., & Ng, A. Y. (2008). Cheap fast - good?
evaluating non-expert annotations natural language tasks. EMNLP.
Su, Q., Pavlov, D., Chow, J.-H., & Baker, W. C. (2007). Internet-scale collection humanreviewed data. WWW.
Tan, B., & Peng, F. (2008). Unsupervised query segmentation using generative language
models wikipedia. WWW.
Velez, B., Wiess, R., Sheldon, M., & Giord, D. (1997). Fast eective query renement.
SIGIR.
699

fiWu, Madhavan, & Halevy

Wang, C., Blei, D., & Heckerman, D. (2008). Continuous time dynamic topic models.
UAI.
Wang, X., Chakrabarti, D., & Punera, K. (2009). Mining Broad Latent Query Aspects
Search Sessions. KDD.
Wang, X., & Zhai, C. (2007). Learn Web Search Logs Organize Search Results.
SIGIR.
White, R. W., & Roth, R. A. (2009). Exploratory Search: Beyond Query-Response
Paradigm. Morgan Claypool Publishers.
Yee, K.-P., Swearingen, K., Li, K., & Hearst, M. (2003). Faceted metadata image search
browsing. CHI.
Zeng, H.-J., He, Q.-C., Chen, Z., Ma, W.-Y., & Ma, J. (2004). Learning cluster web
search results. SIGIR.

700

fiJournal Artificial Intelligence Research 40 (2011) 815-840

Submitted 10/10; published 04/11

Regression Conformal Prediction Nearest Neighbours
Harris Papadopoulos

h.papadopoulos@frederick.ac.cy

Computer Science Engineering Department
Frederick University
7 Y. Frederickou St., Palouriotisa
Nicosia 1036, Cyprus

Vladimir Vovk
Alex Gammerman

vovk@cs.rhul.ac.uk
alex@cs.rhul.ac.uk

Computer Learning Research Centre
Department Computer Science
Royal Holloway, University London
Egham, Surrey TW20 0EX, UK

Abstract
paper apply Conformal Prediction (CP) k -Nearest Neighbours Regression (k -NNR) algorithm propose ways extending typical nonconformity measure
used regression far. Unlike traditional regression methods produce point predictions, Conformal Predictors output predictive regions satisfy given confidence
level. regions produced Conformal Predictor automatically valid, however
tightness therefore usefulness depends nonconformity measure used
CP. effect nonconformity measure evaluates strange given example compared set examples based traditional machine learning algorithm.
define six novel nonconformity measures based k -Nearest Neighbours Regression algorithm develop corresponding CPs following original (transductive)
inductive CP approaches. comparison predictive regions produced
measures typical regression measure suggests major improvement
terms predictive region tightness achieved new measures.

1. Introduction
drawback traditional machine learning algorithms associate
predictions confidence information, instead output simple predictions. However, kind confidence information predictions paramount importance
many risk-sensitive applications used medical diagnosis (Holst, Ohlsson,
Peterson, & Edenbrandt, 1998).
course machine learning theories produce confidence information exist.
One apply theory Probably Approximately Correct learning (PAC theory, Valiant,
1984) algorithm order obtain upper bounds probability error
respect confidence level. bounds produced PAC theory though,
weak unless data set algorithm applied particularly clean,
rarely case. Nouretdinov, Vovk, Vyugin, Gammerman (2001b) demonstrated
crudeness PAC bounds applying one best bounds, Littlestone Warmuth
(Cristianini & Shawe-Taylor, 2000, Thm. 4.25, 6.8), USPS data set.
c
2011
AI Access Foundation. rights reserved.

fiPapadopoulos, Vovk, & Gammerman

Another way obtaining confidence information using Bayesian framework
producing algorithms complement individual predictions probabilistic measures
quality. order apply Bayesian framework however, one required
prior knowledge distribution generating data. correct prior
known, Bayesian methods provide optimal decisions. real world data sets though,
required knowledge available, one assume existence arbitrarily chosen
prior. case, since assumed prior may incorrect, resulting confidence levels
may also incorrect; example predictive regions output 95% confidence
level may contain true label much less 95% cases. signifies major
failure would expect confidence levels bound percentage expected errors.
experimental demonstration negative aspect Bayesian methods case
regression given Section 8, detailed experimental examination
classification regression performed Melluish, Saunders, Nouretdinov, Vovk
(2001).
different approach confidence prediction suggested Gammerman, Vapnik,
Vovk (1998) (and later greatly improved Saunders, Gammerman, & Vovk, 1999),
proposed call paper Conformal Prediction (CP). thorough analysis
CP given Vovk, Gammerman, Shafer (2005), overview presented
Gammerman Vovk (2007). Conformal Predictors built top traditional machine learning algorithms accompany predictions valid measures
confidence. Unlike Bayesian methods, CPs require assumptions
distribution data, data independently identically distributed (i.i.d.); although still strong assumption, almost universally accepted
machine learning. Even traditional algorithm CP based makes
extra assumptions true particular data set, validity predictive
regions produced CP affected. resulting predictive regions might
uninteresting, still valid, opposed misleading regions produced
Bayesian methods. Furthermore, contrast PAC methods, confidence measures
produce useful practice. Different variants CPs developed based
Support Vector Machines (Saunders et al., 1999; Saunders, Gammerman, & Vovk, 2000),
Ridge Regression (Nouretdinov, Melluish, & Vovk, 2001a; Papadopoulos, Proedrou, Vovk,
& Gammerman, 2002a), k-Nearest Neighbours classification (Proedrou, Nouretdinov,
Vovk, & Gammerman, 2002; Papadopoulos, Vovk, & Gammerman, 2002b) Neural Networks (Papadopoulos, Vovk, & Gammerman, 2007), shown give
reliable high quality confidence measures. Moreover, CP applied successfully
many problems early detection ovarian cancer (Gammerman et al., 2009),
classification leukaemia subtypes (Bellotti, Luo, Gammerman, Delft, & Saha, 2005),
diagnosis acute abdominal pain (Papadopoulos, Gammerman, & Vovk, 2009a),
prediction plant promoters (Shahmuradov, Solovyev, & Gammerman, 2005), recognition hypoxia electroencephalograms (EEGs) (Zhang, Li, Hu, Li, & Luo, 2008),
prediction network traffic demand (Dashevskiy & Luo, 2008) estimation effort
software projects (Papadopoulos, Papatheocharous, & Andreou, 2009b).
drawback original CP approach relative computational inefficiency.
due transductive nature approach, entails computations
start scratch every test example. renders unsuitable application
816

fiRegression Conformal Prediction Nearest Neighbours

large data sets. reason modification original CP approach, called
Inductive Conformal Prediction (ICP), proposed Papadopoulos et al. (2002a)
regression Papadopoulos et al. (2002b) classification. suggested name,
ICP replaces transductive inference followed original approach inductive
inference. Consequently, ICPs almost computationally efficient underlying
algorithms. achieved cost loss quality produced confidence
measures, loss negligible, especially data set question large, whereas
improvement computational efficiency significant. computational complexity
comparison original CP ICP approaches performed Papadopoulos
(2008). on, order differentiate clearly original CP ICP
approaches former called Transductive Conformal Prediction (TCP).
order apply CP (either TCP ICP) traditional algorithm one develop
nonconformity measure based algorithm. measure evaluates difference
new example set (actually multiset bag) old examples. Nonconformity
measures constructed using basis traditional algorithm CP
applied, called underlying algorithm resulting Conformal Predictor. effect
nonconformity measures assess degree new example disagrees
attribute-label relationship old examples, according underlying algorithm
CP. worth note many different nonconformity measures constructed
traditional algorithm measures defines different CP.
difference, show next section, affect validity results
produced CPs, affects efficiency.
paper interested problem regression focus k Nearest Neighbours Regression (k-NNR) underlying algorithm, one
popular machine learning techniques. first regression CPs proposed Nouretdinov et al. (2001a) following TCP approach Papadopoulos et al. (2002a) following
ICP approach, based Ridge Regression algorithm. opposed conventional point predictions, output regression CPs predictive region satisfies
given confidence level.
typical nonconformity measure used far case regression absolute
difference |yi yi |, actual label yi example predicted label yi
underlying algorithm example, given old examples training set.
propose six extensions nonconformity measure k -Nearest Neighbours Regression
develop corresponding Inductive Transductive CPs; unfortunately although
six new measures used ICP approach, two used
TCP. definitions normalize standard measure based expected accuracy
underlying algorithm example, makes width resulting predictive
regions vary accordingly. result, predictive regions produced measures
general much tighter produced standard regression measure.
paper extends previous work (Papadopoulos, Gammerman, & Vovk, 2008)
k -Nearest Neighbours Regression TCP developed using two normalized nonconformity
measures. also worth mentioning one nonconformity measure definition
presented Papadopoulos et al. (2002a) Ridge Regression ICP.
rest paper structured follows. next section discuss general
idea CPs based. Sections 3 4 describe k -Nearest Neigh817

fiPapadopoulos, Vovk, & Gammerman

bours Regression TCP ICP respectively using typical regression nonconformity
measure. Section 5 give new nonconformity measure definitions explain
rationale behind them. Section 6 analyses one new nonconformity measures
demonstrates specific assumptions gives asymptotically optimal predictive
regions. Section 7 details experimental results 3 TCPs 7 ICPs developed
based different measures, Section 8 compares methods Gaussian Process Regression (Rasmussen & Williams, 2006), one popular Bayesian
approaches. Finally, Section 9 gives conclusions discusses possible future
directions work.

2. Conformal Prediction
section briefly describe idea behind Conformal Prediction; detailed
description interested reader referred book Vovk et al. (2005). given
training set {z1 , . . . , zl } examples, zi Z pair (xi , yi ); xi Rd
vector attributes example yi R label example. also given
new unlabeled example xl+1 task state something confidence
different values label yl+1 example. mentioned Section 1
assumption (xi , yi ), = 1, 2, . . . , generated independently
probability distribution.
First let us define concept nonconformity measure. Formally, nonconformity
measure family functions : Z (n1) Z R, n = 1, 2, . . . (where Z (n1) set
multisets size n 1), assign numerical score
= ({z1 , . . . , zi1 , zi+1 , . . . , zn }, zi )

(1)

example zi , indicating different examples multiset
{z1 , . . . , zi1 , zi+1 , . . . , zn }.
mentioned Section 1 nonconformity measure based traditional
machine learning method, called underlying algorithm corresponding
CP. Given training set examples {z1 , . . . , zl+1 }, method creates prediction
rule
D{z1 ,...,zl+1 } ,
maps unlabeled example x label y. prediction rule based
examples training set, nonconformity score example zi {z1 , . . . , zl+1 }
measured disagreement predicted label
yi = D{z1 ,...,zl+1 } (xi )

(2)

actual label yi zi . Alternatively, create prediction rule
D{z1 ,...,zi1 ,zi+1 ,...,zl+1 }
using examples set except zi , measure disagreement
yi = D{z1 ,...,zi1 ,zi+1 ,...,zl+1 } (xi )
yi .
818

(3)

fiRegression Conformal Prediction Nearest Neighbours

suppose interested particular guess label xl+1 . Adding
new example (xl+1 , y) known data set {(x1 , y1 ), . . . , (xl , yl )} gives extended
set
{z1 , . . . , zl+1 } = {(x1 , y1 ), . . . , (xl+1 , y)};
(4)
notice unknown component set label y. use
nonconformity measure Al+1 compute nonconformity score
= Al+1 ({z1 , . . . , zi1 , zi+1 , . . . , zl+1 }, zi )
example zi , = 1, . . . , l + 1 (4). nonconformity score l+1
really give us information, numeric value. However, find
unusual zl+1 according Al+1 comparing l+1 nonconformity scores.
comparison performed function
#{i = 1, . . . , l + 1 : l+1 }
(5)
l+1
(we leave dependence left-hand side z1 , . . . , zl , xl+1 implicit,
1
1,
always kept mind). call output function, lies l+1
p-value y, part (4) given. important property
(5) [0, 1] probability distributions P Z,
p(y) =

P {{z1 , . . . , zl+1 } : p(yl+1 ) } ;

(6)

proof given Nouretdinov et al. (2001b). result, p-value given label
low threshold, say 0.05, would mean label highly unlikely
sets generated 5% time i.i.d. process.
Assuming could calculate p-value every possible label y, described above,
would able exclude labels p-value low threshold
(or significance level ) chance wrong. Consequently, given
confidence level 1 regression conformal predictor outputs set
{y : p(y) > },

(7)

i.e. set labels p-value greater . course would impossible
explicitly calculate p-value every possible label R. next section
describe one compute predictive region (7) efficiently k -Nearest Neighbours
Regression.
noted p-values computed CP always valid sense
satisfying (6) regardless particular algorithm nonconformity measure definition
uses. choice algorithm, nonconformity measure definition parameters
affects tightness predictive regions output CP, consequently
usefulness. demonstrate influence inadequate nonconformity measure definition
results CP, let us consider case trivial definition always returns
value given example (xi , yi ). make p-values equal 1
result predictive region R regardless required confidence level. Although
region useless since provide us information, still valid
always contain true label example. Therefore even worst case using
totally wrong nonconformity measure definition algorithm, regions produced
corresponding CP useless, never misleading.
819

fiPapadopoulos, Vovk, & Gammerman

3. k -Nearest Neighbours Regression TCP
k -Nearest Neighbours algorithms base predictions k training examples
nearest unlabeled example question according distance measure,
Euclidean distance. specifically, input vector xl+1 k -Nearest
Neighbours Regression (k -NNR) algorithm finds k nearest training examples xl+1
outputs average (in cases median also used) labels prediction.
refined form method assigns weight one k examples depending
distance xl+1 , weights determine contribution label
calculation prediction; words predicts weighted average labels.
also worth mention performance Nearest Neighbours method
enhanced use suitable distance measure kernel specific data set.
consider version k -NNR method predicts weighted
average k nearest examples. experiments used Euclidean distance,
commonly used distance measure. easy see use
kernel function different distance measure require changes
method.
mentioned Section 1 order create CP need define nonconformity measure based underlying algorithm question. First let us consider
nonconformity measure
= |yi yi |,
(8)
yi prediction k -NNR xi based examples
{(x1 , y1 ), . . . , (xi1 , yi1 ), (xi+1 , yi+1 ), . . . , (xl+1 , y)};
recall Section 2 assumed label new example xl+1 .
Following Nouretdinov et al. (2001a) Vovk et al. (2005) express nonconformity score example = 1, . . . , l + 1 piecewise-linear function
= (y) = |ai + bi y|.
define ai bi follows:
al+1 minus weighted average labels k nearest neighbours xl+1
bl+1 = 1;
l xl+1 one k nearest neighbours xi , ai yi minus labels
k 1 nearest neighbours xi {x1 , . . . , xi1 , xi+1 , . . . , xl } multiplied
corresponding weights, bi minus weight xl+1 ;
l xl+1 one k nearest neighbours xi , ai yi minus
weighted average labels k nearest neighbours xi , bi = 0.
result p-value p(y) (defined (5)) corresponding change
points (y) l+1 (y) changes sign = 1, . . . , l. means instead
calculate p-value every possible y, calculate set points
real line p-value p(y) greater given significance level , leading
feasible prediction algorithm.
820

fiRegression Conformal Prediction Nearest Neighbours

Algorithm 1: k-NNR TCP
Input: training set {(x1 , y1 ), . . . , (xl , yl )}, new example xl+1 , number nearest
neighbours k significance level .
P := {};
= 1 l + 1
Calculate ai bi example zi = (xi , yi );
bi < 0 ai := ai bi := bi ;
bi 6= bl+1 add (10) P ;
bi = bl+1 6= 0 ai 6= al+1 add (11) P ;
end
Sort P ascending order obtaining y(1) , . . . , y(u) ;
Add y(0) := y(u+1) := P ;
N (j) := 0, j = 0, . . . , u;
(j) := 0, j = 1, . . . , u;
= 1 l + 1
Si = {} (see (9)) nothing;
else Si contains one point, Si = {y(j) }
(j) := (j) + 1;
else Si interval [y(j1 ) , y(j2 ) ], j1 < j2
(z) := (z) + 1, z = j1 , . . . , j2 ;
N (z) := N (z) + 1, z = j1 , . . . , j2 1;
else Si ray (, y(j) ]
(z) := (z) + 1, z = 1, . . . , j;
N (z) := N (z) + 1, z = 0, . . . , j 1;
else Si ray [y(j) , )
(z) := (z) + 1, z = j, . . . , u;
N (z) := N (z) + 1, z = j, . . . , u;
else Si union (, y(j1 ) ] [y(j2 ) , ) two rays, j1 < j2
(z) := (z) + 1, z = 1, . . . , j1 , j2 , . . . , u;
N (z) := N (z) + 1, z = 0, . . . , j1 1, j2 , . . . , u;
else Si real line (, )
(z) := (z) + 1, z = 1, . . . , u;
N (z) := N (z) + 1, z = 0, . . . , u;
end
Output: predictive region

(j)
j: N (j) > (y(j) , y(j+1) ) {y(j) : Ml+1
> }.
l+1

821

fiPapadopoulos, Vovk, & Gammerman

= 1, . . . , l + 1, let
Si = {y : (y) l+1 (y)}
= {y : |ai + bi y| |al+1 + bl+1 y|}.

(9)

set Si (always closed) either interval, ray, union two rays, real
line, empty; also point, special case interval.
interested |ai + bi y| assume bi 0 = 1, . . . , l + 1 (if multiply
ai bi 1). bi 6= bl+1 , (y) l+1 (y) equal two points (which
may coincide):
ai al+1
ai + al+1



;
(10)
bi bl+1
bi + bl+1
case Si interval (maybe point) union two rays. bi = bl+1 6= 0,
(y) = l+1 (y) one point:


ai + al+1
,
2bi

(11)

Si ray, unless ai = al+1 case Si real line. bi = bl+1 = 0, Si
either empty real line.
calculate p-value p(y) potential label new example xl+1 , count
many Si include divide l + 1,
p(y) =

#{i = 1, . . . , l + 1 : Si }
.
l+1

(12)

increases p(y) change points (10) (11), significance level
find set p(y) > union finitely many intervals
rays. Algorithm 1 implements slightly modified version idea. creates list
points (10) (11), sorts ascending order obtaining y(1) , . . . , y(u) , adds y(0) =
beginning y(u+1) = end list, computes N (j), number
Si contain interval (y(j) , y(j+1) ), j = 0, . . . , u, (j) number Si
contain point y(j) , j = 1, . . . , u.

4. k -Nearest Neighbours Regression ICP
TCP technique follows transductive approach, computations repeated every test example. reason test example included
training set underlying algorithm TCP order calculate required
nonconformity measures. means underlying algorithm retrained every
test example, renders TCP quite computationally inefficient application large
data sets.
Inductive Conformal Predictors (ICP) based general idea described
Section 2, follow inductive approach, allows train underlying
algorithm once. achieved splitting training set (of size l) two smaller
sets, calibration set q < l examples proper training set := l q
examples. proper training set used creating prediction rule D{z1 ,...,zm }
822

fiRegression Conformal Prediction Nearest Neighbours

Algorithm 2: k-NNR ICP
Input: training set {(x1 , y1 ), . . . , (xl , yl )}, test set {xl+1 , . . . , xl+r }, number
nearest neighbours k, number calibration examples q, significance
level .
:= l q;
P := {};
= 1 q
Calculate ym+i using {(x1 , y1 ), . . . , (xm , ym )} training set;
Calculate m+i pair zm+i = (xm+i , ym+i );
Add m+i P ;
end
Sort P descending order obtaining (m+1) , . . . , (m+q) ;
:= b(q + 1)c;
g = 1 r
Calculate yl+g using {(x1 , y1 ), . . . , (xm , ym )} training set;
Output: predictive region (yl+g (m+s) , yl+g + (m+s) ).
end

examples calibration set used calculating p-value possible label
new test example. specifically, non-conformity score m+i example
zm+i calibration set {zm+1 , . . . , zm+q } calculated degree disagreement
prediction
ym+i = D{z1 ,...,zm } (xm+i )
(13)
true label ym+i . way, non-conformity score l+g (y) assumed
label new test example xl+g calculated degree disagreement
yl+g = D{z1 ,...,zm } (xl+g )

(14)

y. Notice nonconformity scores examples calibration set
need computed once. Using non-conformity scores p-value possible
label xl+g calculated
p(y) =

#{i = + 1, . . . , + q, l + g : l+g }
.
q+1

(15)

original CP approach impossible explicitly consider every possible
label R new example xl+g calculate p-value. However, nonconformity scores calibration set examples m+1 , . . . , m+q k-NNR prediction
yl+g remain fixed test example xl+g , thing changes different
values assumed label nonconformity score l+g . Therefore p(y) changes
points l+g (y) = = + 1, . . . , + q. result, confidence
level 1 need find biggest l+g (y) = p(y) > ,
give us maximum minimum p-value bigger consequently beginning end corresponding predictive region. specifically,
823

fiPapadopoulos, Vovk, & Gammerman

sort nonconformity scores calibration examples descending order obtaining
sequence
(m+1) , . . . , (m+q) ,
(16)
output predictive region
(yl+g (m+s) , yl+g + (m+s) ),

(17)

= b(q + 1)c.

(18)



whole process detailed Algorithm 2. Notice opposed Algorithm 1
computations repeated every test example, part inside
second loop repeated.
parameter q given input Algorithm 2 determines number training
examples allocated calibration set nonconformity scores
used ICP generate predictive regions. examples take
small portion training set, removal dramatically reduce
predictive ability underlying algorithm. mainly interested confidence
levels 99% 95%, calibration sizes use form q = 100n 1, n
positive integer (see (18)).

5. Normalized Nonconformity Measures
main aim work improve typical regression nonconformity measure (8)
normalizing expected accuracy underlying method. intuition
behind two examples nonconformity score defined (8)
prediction one expected accurate other,
former actually stranger latter. leads predictive regions
larger examples difficult predict smaller examples
easier predict.
first measure expected accuracy use based distance example
k nearest neighbours. Since k nearest training examples ones actually
used derive prediction underlying method example, nearer
example, accurate expect prediction be.
example zi , let us denote Ti training set used generating prediction
yi . set
Ti = {z1 , . . . , zi1 , zi+1 , . . . , zl+1 }
(19)
case TCP set
Ti = {z1 , . . . , zm }

(20)

case ICP. Furthermore, denote k nearest neighbours xi Ti
(xi1 , yi1 ), . . . , (xik , yik ).
824

(21)

fiRegression Conformal Prediction Nearest Neighbours

sum distances xi k nearest neighbours
dki =

k
X

distance(xi , xij ).

(22)

j=1

could use dki measure accuracy, fact used successfully previous
work (Papadopoulos et al., 2008). However, order make measure
consistent across different data sets use
ki =

dki
,
median({dkj : zj Ti })

(23)

compares distance example k nearest neighbours median
distances training examples k nearest neighbours. Using ki
defined nonconformity measures:
fi
fi
fi yi yi fi
fi
fi,
(24)
= fi
+ ki fi


fi
fi
fi yi yi fi
fi,
= fifi
exp(k ) fi

(25)



parameter 0 controls sensitivity measure changes ki ;
first case increasing results less sensitive nonconformity measure, second
increasing results sensitive measure. exponential function definition (25)
chosen minimum value 1, since ki always positive, grows
quickly ki increases. result, measure sensitive changes ki
big, indicates example unusually far training examples.
second measure accuracy use based different labels
examples k nearest neighbours are, measured standard deviation.
labels agree other, accurate expect prediction
k-nearest neighbours algorithm be. example xi , measure standard
deviation labels k neighbours
v
u k
u1 X
k
si =
(yij yi1,...,k )2 ,
(26)
k
j=1


yi1,...,k

k
1X
=
yij .
k

(27)

j=1

make measure consistent across data sets divide median standard
deviation k nearest neighbour labels training examples
ik =

ski
.
median({skj : zj Ti })
825

(28)

fiPapadopoulos, Vovk, & Gammerman

fashion (24) (25) defined nonconformity measures:
fi
fi
fi yi yi fi
fi
fi,
= fi
+ ik fi


fi
fi
fi yi yi fi
fi
fi,
= fi
exp( k ) fi

(29)

(30)



parameter controls sensitivity measure changes ik .
Finally combining ki ik defined nonconformity measures:
fi
fi
fi yi yi fi
fi,
fi
(31)
= fi
+ ki + ik fi


fi
fi
fi
fi
yi yi
fi
fi,
= fi
k
k
exp( ) + exp( ) fi


(32)



(31) parameter controls sensitivity measure changes ki
ik , whereas (32) two parameters , control sensitivity
changes ki ik respectively.
order use nonconformity measures k-Nearest Neighbours Regression
TCP need calculate nonconformity scores = |ai +bi y|. easily
(24) (25) computing ai bi defined Section 3 dividing
( + ki ) nonconformity measure (24) exp(ki ) nonconformity measure (25).
Unfortunately however, cannot applied nonconformity measures
defined since ik depends labels k nearest examples, change
k nearest neighbours xl+1 change y. reason TCP limited using
nonconformity measures (24) (25).
case ICP calculate nonconformity scores m+1 , . . . , m+q
calibration examples using (24), (25), (29), (30), (31) (32) instead predictive
region (17) output
(yl+g (m+s) ( + ki ), yl+g + (m+s) ( + ki )),

(33)

(yl+g (m+s) exp(ki ), yl+g + (m+s) exp(ki )),

(34)

(yl+g (m+s) ( + ik ), yl+g + (m+s) ( + ik )),

(35)

(yl+g (m+s) exp(ik ), yl+g + (m+s) exp(ik )),

(36)

(yl+g (m+s) ( + ki + ik ), yl+g + (m+s) ( + ki + ik )),

(37)

(24),
(25),
(29),
(30),
(31)
(yl+g (m+s) (exp(ki ) + exp(ik )), yl+g + (m+s) (exp(ki ) + exp(ik ))),
(32).
826

(38)

fiRegression Conformal Prediction Nearest Neighbours

6. Theoretical Analysis Nonconformity Measure (29)
section examine k-NNR ICP nonconformity measure (29) specific
assumptions show that, assumptions, predictive regions produced
asymptotically optimal; important note assumptions required
validity resulting predictive regions. chose formalize conditions
needed conclusions, would made statement far complicated.
Assume label yi generated normal distribution N (xi , x2i ), x
x smooth functions x, xi generated probability distribution
concentrated compact set whose density always greater constant
> 0, k 1, k q k. case nonconformity measure (29)
= 0
fi
fi fi
fi
fi yi yi fi fi yi xi fi
fi
fi
fi
fi,
= fi

(39)
ski fi fi xi fi
division ski median({skj : zj Ti }) ignored since latter change
within data set. values
ym+q xm+q
ym+1 xm+1
,...,
xm+1
xm+q
follow approximately standard normal distribution, new example xl+g
probability close 1
yl+g xl+g
[(m+bqc) , (m+bqc) ],
xl+g
(m+1) , . . . , (m+q) nonconformity scores m+1 , . . . , m+q sorted descending
order. result obtain region
yl+g [xl+g (m+bqc) xl+g , xl+g + (m+bqc) xl+g ],
which, one hand, close standard (and optimal various senses) prediction
interval normal model and, hand, almost identical region (35)
k-NNR ICP (recall set = 0 ik = ski ).

7. Experimental Results
methods tested six benchmark data sets UCI (Frank & Asuncion,
2010) DELVE (Rasmussen et al., 1996) repositories:
Boston Housing, lists median house prices 506 different areas Boston
$1000s. area described 13 attributes pollution crime
rate.
Abalone, concerns prediction age abalone physical measurements. data set consists 4177 examples described 8 attributes
diameter, height shell weight.
827

fiPapadopoulos, Vovk, & Gammerman

Computer Activity, collection computer systems activity measures
Sun SPARCstation 20/712 128 Mbytes memory running multiuser university department. consists 8192 examples 12 measured values,
number system buffer reads per second number system call writes
per second, random points time. task predict portion time
cpus run user mode, ranging 0 100. used small variant
data set contains 12 21 attributes.
Kin, generated realistic simulation forward dynamics
8 link all-revolute robot arm. task predict distance end-effector
target. data set consists 8192 examples described attributes like joint
positions twist angles. used 8nm variant data set contains 8
32 attributes, highly non-linear moderate noise.
Bank, generated simplistic simulator queues series banks.
task predict rate rejections, i.e. fraction customers
turned away bank open tellers full queues. data
set consists 8192 examples described 8 attributes like area population size
maximum possible length queues. 8nm variant data set used
characteristics given description Kin data set.
Pumadyn, generated realistic simulation dynamics Unimation Puma 560 robot arm. consists 8192 examples task predict
angular acceleration one robot arms links. example described
8 attributes, include angular positions, velocities torques robot
arm. 8nm variant data set used characteristics given
description Kin data set.
conducting experiments attributes data sets normalized
minimum value 0 maximum value 1. experiments consisted 10 random
runs fold cross-validation process. Based sizes Boston Housing Abalone
data sets split 10 4 folds respectively, four splint 2
folds. determining number k nearest neighbours used data set,
one third training set first fold held-out validation set base
algorithm tested set different k, using two thirds training.
number neighbours k gave smallest mean absolute error selected. Note
that, explained Section 2, choice k parameter affect
validity results produced corresponding CP, affects efficiency.
calibration set sizes set q = 100n 1 (see Section 4), n chosen
q approximately 1/10th data sets training size; case Boston
Housing data set smallest value n = 1 used. Table 1 gives number folds,
number nearest neighbours k, calibration set size q used experiments
data set, together number examples attributes consists width
range labels.
parameters nonconformity measures set cases 0.5,
seems give good results data sets measures. worth note however,
somewhat tighter predictive regions obtained adjusting corresponding
828

fiRegression Conformal Prediction Nearest Neighbours

Examples
Attributes
Label range
Folds
k
Calibration size

Boston
Housing

Abalone

Computer
Activity

Kin

Bank

Pumadyn

506
13
45
10
4
99

4177
8
28
4
16
299

8192
12
99
2
8
399

8192
8
1.42
2
7
399

8192
8
0.48
2
4
399

8192
8
21.17
2
6
399

Table 1: Main characteristics experimental setup data set.
parameter(s) measure data set. chose fix parameters 0.5 here,
show remarkable improvement predictive region widths resulting
use new nonconformity measures depend fine tuning
parameters.
Since methods output predictive regions instead point predictions, main aim
experiments check tightness regions. first two parts
Tables 2-7 report median interdecile mean widths regions produced every
data set nonconformity measure k-NNR TCP ICP 99%, 95%
90% confidence levels. chose report median interdecile mean values instead
mean avoid strong impact extremely large extremely small
regions.
third last parts Tables 2-7 check reliability obtained predictive
regions data set. done reporting percentage examples
true label inside region output corresponding method. effect
checks empirically validity predictive regions. percentages reported
close required significance levels change much different
nonconformity measures.
Figures 1-6 complement information detailed Tables 2-7 displaying boxplots
show median, upper lower quartiles, upper lower deciles
predictive region widths produced data set. chart divided three parts,
separating three confidence levels consider, part contains 10 boxplots
first three k-NNR TCP nonconformity measures (8), (24)
(25), remaining seven k-NNR ICP nonconformity measures.
transformation width values reported Tables 2-7 percentage
range possible labels represent shows general predictive regions produced
methods relatively tight. median width percentages nonconformity
measures data sets 17% 86% 99% confidence level
11% 47% 95% confidence level. consider best performing
nonconformity measure data set, worst median width percentage 99%
confidence level 61% 95% confidence level 43% (both pumadyn
data set).
comparing predictive region tightness different nonconformity measures
method Tables 2-7 Figures 1-6, one see relatively big
improvement new nonconformity measures achieve compared standard
829

fiPapadopoulos, Vovk, & Gammerman

Method/
Measure
TCP

ICP

(8)
(24)
(25)
(8)
(24)
(25)
(29)
(30)
(31)
(32)

Median Width
90%
95%
99%
12.143 17.842 33.205
11.172 14.862 24.453
10.897 14.468 24.585
13.710 19.442 38.808
11.623 16.480 30.427
11.531 16.702 30.912
11.149 15.233 36.661
10.211 14.228 34.679
10.712 14.723 28.859
10.227 13.897 29.068

Interdecile
Mean Width
90%
95%
99%
12.054 17.870 33.565
11.483 15.289 25.113
11.258 14.956 25.368
13.693 19.417 41.581
11.985 16.991 33.459
11.916 17.116 34.477
12.165 16.645 41.310
11.347 15.820 39.211
11.343 15.612 31.120
10.876 14.832 31.810

Percentage outside
predictive regions
90%
95%
99%
10.24
5.06
0.97
9.94
4.80
0.89
9.92
4.92
0.91
9.47
4.88
0.79
10.59
4.92
0.71
10.08
4.72
0.69
9.55
4.82
0.59
9.68
4.60
0.65
9.88
4.76
0.61
9.31
4.88
0.57

Table 2: tightness reliability results methods Boston Housing data
set.
Method/
Measure
(8)
(24)
(25)
(8)
(24)
(25)
(29)
(30)
(31)
(32)

TCP

ICP

Median Width
90%
95%
99%
6.685 9.267 16.109
6.213 8.487 14.211
6.034 8.278 13.949
6.705 9.486 16.628
6.200 8.305 14.012
6.057 8.205 13.922
5.837 7.987 14.394
5.731 7.926 14.631
5.936 7.999 13.999
5.838 7.962 14.028

Interdecile
Mean Width
90%
95%
99%
6.712 9.259 16.124
6.376 8.708 14.581
6.230 8.545 14.393
6.671 9.388 16.580
6.359 8.513 14.520
6.229 8.434 14.457
6.004 8.229 14.895
5.931 8.200 15.173
6.070 8.174 14.406
5.994 8.178 14.506

Percentage outside
predictive regions
90%
95%
99%
9.94
4.94
0.95
10.03
4.98
0.98
10.03
4.95
0.99
10.32
5.09
1.01
10.57
5.54
1.20
10.50
5.46
1.19
10.47
5.05
1.02
10.37
5.00
0.93
10.57
5.35
1.10
10.54
5.23
1.09

Table 3: tightness reliability results methods Abalone data set.
Method/
Measure
TCP

ICP

(8)
(24)
(25)
(8)
(24)
(25)
(29)
(30)
(31)
(32)

Median Width
90%
95%
99%
10.005 13.161 21.732
8.788 11.427 18.433
8.370 10.856 17.084
10.149 13.588 22.705
9.024 11.725 18.948
8.646 11.340 17.817
8.837 11.877 19.595
8.702 11.618 18.859
8.653 11.301 18.179
8.517 11.114 17.468

Interdecile
Mean Width
90%
95%
99%
10.009 13.113 21.679
9.238 12.017 19.372
8.924 11.572 18.207
10.245 13.467 22.577
9.483 12.333 19.918
9.206 12.067 18.953
9.031 12.145 20.114
9.013 12.031 19.522
9.020 11.789 18.983
8.914 11.627 18.264

Percentage outside
predictive regions
90%
95%
99%
9.98
4.99
0.97
9.95
4.92
0.95
9.92
4.91
0.97
9.71
4.79
0.95
9.51
4.72
0.90
9.40
4.51
0.92
9.75
4.59
0.91
9.49
4.58
0.95
9.70
4.55
0.89
9.46
4.51
0.96

Table 4: tightness reliability results methods Computer Activity data
set.

830

fiRegression Conformal Prediction Nearest Neighbours

Method/
Measure
(8)
(24)
(25)
(8)
(24)
(25)
(29)
(30)
(31)
(32)

TCP

ICP

Median Width
90%
95%
99%
0.402 0.491 0.675
0.395 0.480 0.649
0.396 0.481 0.653
0.413 0.508 0.705
0.408 0.498 0.680
0.408 0.501 0.681
0.412 0.497 0.730
0.401 0.482 0.695
0.403 0.486 0.677
0.399 0.487 0.670

Interdecile
Mean Width
90%
95%
99%
0.402 0.491 0.675
0.396 0.481 0.651
0.397 0.482 0.655
0.414 0.515 0.702
0.409 0.499 0.682
0.408 0.502 0.682
0.418 0.504 0.741
0.408 0.491 0.707
0.406 0.489 0.682
0.402 0.490 0.676

Percentage outside
predictive regions
90%
95%
99%
10.13
4.99
0.96
10.18
5.01
0.95
10.16
5.00
0.96
9.86
4.52
0.81
9.73
4.61
0.77
9.84
4.59
0.80
9.74
5.21
0.91
9.74
5.08
0.84
9.81
4.83
0.87
10.05
4.75
0.85

Table 5: tightness reliability results methods Kin data set.

Method/
Measure
(8)
(24)
(25)
(8)
(24)
(25)
(29)
(30)
(31)
(32)

TCP

ICP

Median Width
90%
95%
99%
0.135 0.201 0.342
0.121 0.170 0.265
0.123 0.173 0.270
0.142 0.209 0.361
0.122 0.178 0.274
0.125 0.182 0.282
0.096 0.151 0.306
0.084 0.137 0.272
0.096 0.146 0.247
0.092 0.143 0.249

Interdecile
Mean Width
90%
95%
99%
0.135 0.201 0.341
0.122 0.171 0.267
0.124 0.175 0.273
0.139 0.209 0.362
0.123 0.179 0.277
0.126 0.183 0.284
0.110 0.174 0.352
0.104 0.169 0.334
0.105 0.160 0.270
0.102 0.159 0.274

Percentage outside
predictive regions
90%
95%
99%
10.05
4.99
0.95
10.02
4.94
0.90
10.03
4.95
0.91
9.95
4.71
0.83
10.16
4.71
0.87
10.08
4.72
0.87
9.97
4.51
0.80
10.21
4.61
0.79
10.14
4.46
0.85
10.31
4.58
0.88

Table 6: tightness reliability results methods Bank data set.

Method/
Measure
TCP

ICP

(8)
(24)
(25)
(8)
(24)
(25)
(29)
(30)
(31)
(32)

Median Width
90%
95%
99%
7.909
9.694 13.908
7.761
9.417 13.153
7.774
9.463 13.239
8.008 10.005 13.924
7.869
9.627 13.193
7.892
9.713 13.335
7.745
9.563 14.342
7.460
9.199 13.398
7.549
9.185 13.040
7.579
9.237 12.808

Interdecile
Mean Width
90%
95%
99%
7.927 9.726 13.827
7.781 9.439 13.183
7.793 9.486 13.268
8.097 9.993 14.007
7.894 9.655 13.233
7.919 9.731 13.377
7.842 9.698 14.588
7.634 9.410 13.723
7.610 9.263 13.180
7.660 9.336 12.955

Percentage outside
predictive regions
90%
95%
99%
9.92
4.87
0.99
9.88
4.98
1.04
9.92
4.94
1.02
9.72
4.75
1.06
9.86
4.81
1.09
9.89
4.75
1.10
9.96
4.87
1.04
9.97
4.82
1.07
10.02
4.89
1.04
9.90
4.83
1.15

Table 7: tightness reliability results methods Pumadyn data set.

831

fiPapadopoulos, Vovk, & Gammerman

100
90

Region Width

80
70
60
50
40
30
20
10
0
90%

95%

99%

Confidence Level
TCP - (8)
ICP - (29)

TCP - (24)
ICP - (30)

TCP - (25)
ICP - (31)

ICP - (8)
ICP - (32)

ICP - (24)

ICP - (25)

Figure 1: Predictive region width distribution Boston housing data set.

25

Region Width

20
15
10
5
0
90%

95%

99%

Confidence Level
TCP - (8)
ICP - (29)

TCP - (24)
ICP - (30)

TCP - (25)
ICP - (31)

ICP - (8)
ICP - (32)

ICP - (24)

ICP - (25)

Figure 2: Predictive region width distribution Abalone data set.

35

Region Width

30
25
20
15
10
5
0
90%

95%

99%

Confidence Level
TCP - (8)
ICP - (29)

TCP - (24)
ICP - (30)

TCP - (25)
ICP - (31)

ICP - (8)
ICP - (32)

ICP - (24)

ICP - (25)

Figure 3: Predictive region width distribution Computer Activity data set.

832

fiRegression Conformal Prediction Nearest Neighbours

1.2

Region Width

1
0.8
0.6
0.4
0.2
0
90%

95%

99%

Confidence Level
TCP - (8)
ICP - (29)

TCP - (24)
ICP - (30)

TCP - (25)
ICP - (31)

ICP - (8)
ICP - (32)

ICP - (24)

ICP - (25)

Figure 4: Predictive region width distribution Kin data set.

1
0.9

Region Width

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
90%

95%

99%

Confidence Level
TCP - (8)
ICP - (29)

TCP - (24)
ICP - (30)

TCP - (25)
ICP - (31)

ICP - (8)
ICP - (32)

ICP - (24)

ICP - (25)

Figure 5: Predictive region width distribution Bank data set.

25

Region Width

20
15
10
5
0
90%

95%

99%

Confidence Level
TCP - (8)
ICP - (29)

TCP - (24)
ICP - (30)

TCP - (25)
ICP - (31)

ICP - (8)
ICP - (32)

ICP - (24)

ICP - (25)

Figure 6: Predictive region width distribution Pumadyn data set.

833

fiPapadopoulos, Vovk, & Gammerman

Method

B. Housing

Abalone



TCP measures
ICP (8)
ICP new measures

20 sec
0.6 sec
1.4 sec

51 - 52 min
8 sec
29 sec

2.5 - 2.7 hrs
17 - 18 sec
37 - 39 sec

Table 8: processing times k-NNR TCP ICP.

regression measure (8). almost cases new measures give smaller median
interdecile mean widths, majority cases difference quite significant.
degree improvement evident Figures 1-6 see many cases
median widths predictive regions obtained new measures even
smallest widths obtained measure (8).
comparison nonconformity measures based distances
k nearest neighbours, (24) (25), based standard deviation
labels, (29) (30), reveals regions produced latter cover much
bigger range widths. Furthermore, widths (24) (25) seem cases
tighter average (29) (30) highest confidence level 99%, whereas
opposite true 90% 95% confidence levels. also worth mentioning
measures (29) (30) ones produced predictive regions bigger
median interdecile mean widths measure (8) cases.
last two measures (31) (32), combine others, seem give tightest
predictive region widths ICP overall. 11 18 cases one two smallest
median predictive region width 1 cases one two smallest
interdecile mean width. superiority also evident figures especially
Figures 1, 5 6.
One important comparison widths regions produced
TCP ICP approaches. standard regression nonconformity measure (8)
regions TCP cases tighter ICP. due much
richer set examples TCP uses calculating predictive regions; TCP uses
whole training set opposed calibration examples used ICP. difference
predictive region tightness much bigger results Boston housing data set, since
calibration set case consisted 99 examples. also worth note
widths regions produced ICP (8) vary much corresponding
widths TCP, natural since composition calibration set changes
much bigger degree one run another composition whole training set.
compare region widths two approaches nonconformity measures
(24) (25) see that, exception Boston housing set,
similar terms distribution. shows new measures dependant
composition examples used producing predictive regions. Furthermore,
compare region widths TCP nonconformity measures (24) (25)
ICP nonconformity measures (31) (32), see many cases
regions ICP somewhat tighter, despite much smaller set examples uses
compute them. due superiority measures (31) (32).
834

fiRegression Conformal Prediction Nearest Neighbours

Finally, Table 8 report processing times two approaches. use two
rows reporting times ICP, one measure (8) one new measures,
since new measures require extra computations; i.e. finding distances
training examples k nearest neighbours and/or standard deviation
k nearest neighbour labels. also group times Computer Activity, Kin, Bank
Pumadyn data sets, almost identical consist number
examples, one column. table demonstrates huge computational efficiency
improvement ICP TCP. also shows computational overhead
involved using new nonconformity measures ICP, important,
especially baring mind degree improvement bring terms predictive region
tightness.

8. Comparison Gaussian Process Regression
section compare predictive regions produced methods
produced Gaussian Processes (GPs, Rasmussen & Williams, 2006), one
popular Bayesian machine learning approaches. first compare Gaussian Process
Regression (GPR) k-NNR CPs artificially generated data satisfy GP
prior check results GPR three data sets described Section 7,
namely Boston Housing, Abalone Computer Activity. implementation GPR
based Matlab code accompanies work Rasmussen Williams.
first set experiments generated 100 artificial data sets consisting
1000 training 1000 test examples inputs drawn uniform distribution
[10, 10]5 . labels data set generated Gaussian Process
covariance function defined sum squared exponential (SE) covariance independent noise hyperparameters (l, f , n ) = (1, 1, 0.1); i.e. unit length scale, unit
signal magnitude noise standard deviation 0.1. applied GPR
data sets using exactly covariance function hyperparameters compared
results k-NNR CPs (which take account information
data generated). Table 9 reports results 100 data sets obtained GPR methods manner Tables 2-7. case, since
data meets GPR prior, percentage labels outside predictive regions produced
GPR less equal required significance level would expect.
true regions produced methods. Also, although predictive
regions produced GPR tighter produced methods, difference
two small.
experiments three benchmark data sets performed following exactly
setting experiments two CPs, including use seed
fold-cross validation run. terms data preprocessing, normalised attributes
data set setting mean attribute 0 standard deviation 1,
also centred labels data set zero mean; preprocessing
steps advisable GPR. tried SE covariance Matern covariance
smoothness set v = 3/2 v = 5/2. case SE covariance, used
automatic relevance determination version function, allows separate
length-scale attribute determined corresponding hyperparameter. cases
835

fiPapadopoulos, Vovk, & Gammerman

Method/
Measure
GPR
TCP

ICP

(8)
(24)
(25)
(8)
(24)
(25)
(29)
(30)
(31)
(32)

Median Width
90%
95%
99%
3.306 3.940 5.178
3.332 3.999 5.277
3.322 3.982 5.306
3.322 3.975 5.290
3.344 3.978 5.264
3.346 4.016 5.329
3.337 3.994 5.302
3.333 3.989 5.292
3.331 3.993 5.280
3.340 3.995 5.308
3.332 3.990 5.279

Interdecile
Mean Width
90%
95%
99%
3.306 3.939 5.177
3.332 3.989 5.274
3.339 4.001 5.332
3.335 3.990 5.309
3.337 4.001 5.283
3.358 4.029 5.349
3.348 4.005 5.320
3.339 3.994 5.305
3.338 3.997 5.295
3.348 4.002 5.324
3.339 3.994 5.294

Percentage outside
predictive regions
90%
95%
99%
10.01
4.95
0.99
9.93
4.81
0.95
9.90
4.82
0.98
9.88
4.82
0.95
9.90
4.80
0.95
9.83
4.76
1.01
9.86
4.78
0.98
9.97
4.88
0.96
9.90
4.84
0.95
9.85
4.79
0.97
9.88
4.81
0.97

Table 9: Comparison methods Gaussian Process Regression artificial data
generated Gaussian Process.

Covariance
Function
SE
Matern v = 3/2
Matern v = 5/2

Median Width
90%
95%
99%
7.168
8.540 11.225
8.369
9.972 13.106
8.476 10.100 13.274

Interdecile
Mean Width
90%
95%
99%
7.419
8.840 11.618
8.636 10.290 13.524
8.748 10.423 13.699

Percentage outside
predictive regions
90%
95%
99%
10.28
6.70
2.98
8.02
5.04
2.65
7.71
4.88
2.61

Table 10: tightness reliability results Gaussian Process Regression Boston
Housing data set.

Covariance
Function
SE
Matern v = 3/2
Matern v = 5/2

Median Width
90%
95%
99%
6.705 7.988 10.499
6.740 8.031 10.555
6.750 8.042 10.570

Interdecile
Mean Width
90%
95%
99%
6.711 7.996 10.509
7.046 8.396 11.034
6.755 8.048 10.577

Percentage outside
predictive regions
90%
95%
99%
9.43
6.47
2.92
9.02
6.11
2.77
9.15
6.23
2.82

Table 11: tightness reliability results Gaussian Process Regression
Abalone data set.

836

fiRegression Conformal Prediction Nearest Neighbours

Covariance
Function
SE
Matern v = 3/2
Matern v = 5/2

Median Width
90%
95%
99%
8.115 9.669 12.708
8.120 9.675 12.715
8.340 9.937 13.060

Interdecile
Mean Width
90%
95%
99%
8.198
9.768 12.838
8.471 10.093 13.265
8.617 10.267 13.494

Percentage outside
predictive regions
90%
95%
99%
10.15
6.47
2.38
9.63
5.91
2.09
9.63
5.81
2.09

Table 12: tightness reliability results Gaussian Process Regression Computer Activity data set.

actual covariance function defined sum corresponding covariance
independent noise. hyperparameters adapted maximizing marginal likelihood
training set suggested Rasmussen Williams (2006); adaptation
hyperparameters using leave-one-out cross-validation produces less results.
Tables 10-12 report results obtained GRP three data sets
covariance function. comparing values reported first two parts tables
Tables 2-4 one see regions produced GPR tighter almost
cases. However, percentage predictive regions include true label
example much higher required 95% 99% confidence levels.
shows predictive regions produced GPR valid therefore
misleading correct prior known. contrary, demonstrated Section 2,
CPs produce valid predictive regions even parameters underlying algorithm used
totally wrong.

9. Conclusions
presented Transductive Inductive Conformal Predictors based k-Nearest
Neighbours Regression algorithm. addition typical regression nonconformity measure, developed six novel definitions take account expected accuracy
k-NNR algorithm example question. definitions assess expected accuracy k-NNR example based distances k nearest examples (24)
(25), standard deviation labels (29) (30), combination
two (31) (32).
experimental results obtained applying methods various data sets show
cases produce reliable predictive intervals tight enough useful
practice. Additionally, illustrate great extent new nonconformity
measure definitions improve performance transductive inductive method
terms predictive region tightness. case ICP, new measures
evaluated, definitions (31) (32) appear superior measures, giving
overall tightest predictive regions. Moreover, comparison TCP ICP
methods suggests that, dealing relatively large data sets use nonconformity
measures (31) (32) makes ICP perform equally well TCP terms predictive
region tightness, whereas vast advantage comes computational efficiency.
Finally, comparison Gaussian Process Regression (GPR) demonstrated
837

fiPapadopoulos, Vovk, & Gammerman

methods produce almost tight predictive regions GPR correct prior
known, GPR may produce misleading regions real world data
required prior knowledge available.
main future direction work development normalized nonconformity
measures like ones presented paper based popular regression techniques,
Ridge Regression Support Vector Regression. Although case Ridge
Regression one measure already defined ICP (Papadopoulos et al., 2002a),
unfortunately cannot used TCP approach; thus potentially considerable performance gain achieved definition kind TCP. Moreover,
equally important future aim application methods medical problems
provision predictive regions desirable, evaluation results
experts corresponding field.

Acknowledgments
would like thank Savvas Pericleous Haris Haralambous useful discussions.
would also like thank anonymous reviewers insightful constructive
comments. work supported part Cyprus Research Promotion Foundation
research contract PLHRO/0506/22 (Development New Conformal Prediction
Methods Applications Medical Diagnosis).

References
Bellotti, T., Luo, Z., Gammerman, A., Delft, F. W. V., & Saha, V. (2005). Qualified predictions microarray proteomics pattern diagnostics confidence machines.
International Journal Neural Systems, 15 (4), 247258.
Cristianini, N., & Shawe-Taylor, J. (2000). Introduction Support Vector Machines
Kernel-based Methods. Cambridge University Press, Cambridge.
Dashevskiy, M., & Luo, Z. (2008). Network traffic demand prediction confidence.
Proceedings IEEE Global Telecommunications Conference 2008 (GLOBECOM
2008), pp. 14531457. IEEE.
Frank, A., & Asuncion, A. (2010).
http://archive.ics.uci.edu/ml.

UCI machine learning repository.

URL

Gammerman, A., Vapnik, V., & Vovk, V. (1998). Learning transduction. Proceedings
Fourteenth Conference Uncertainty Artificial Intelligence, pp. 148156,
San Francisco, CA. Morgan Kaufmann.
Gammerman, A., Vovk, V., Burford, B., Nouretdinov, I., Luo, Z., Chervonenkis, A., Waterfield, M., Cramer, R., Tempst, P., Villanueva, J., Kabir, M., Camuzeaux, S., Timms,
J., Menon, U., & Jacobs, I. (2009). Serum proteomic abnormality predating screen
detection ovarian cancer. Computer Journal, 52 (3), 326333.
Gammerman, A., & Vovk, V. (2007). Hedging predictions machine learning: second
computer journal lecture. Computer Journal, 50 (2), 151163.
838

fiRegression Conformal Prediction Nearest Neighbours

Holst, H., Ohlsson, M., Peterson, C., & Edenbrandt, L. (1998). Intelligent computer reporting lack experience: confidence measure decision support systems. Clinical
Physiology, 18 (2), 139147.
Melluish, T., Saunders, C., Nouretdinov, I., & Vovk, V. (2001). Comparing Bayes
Typicalness frameworks. Proceedings 12th European Conference Machine
Learning (ECML01), Vol. 2167 Lecture Notes Computer Science, pp. 360371.
Springer.
Nouretdinov, I., Melluish, T., & Vovk, V. (2001a). Ridge regression confidence machine.
Proceedings 18th International Conference Machine Learning (ICML01),
pp. 385392, San Francisco, CA. Morgan Kaufmann.
Nouretdinov, I., Vovk, V., Vyugin, M. V., & Gammerman, A. (2001b). Pattern recognition
density estimation general i.i.d. assumption. Proceedings 14th
Annual Conference Computational Learning Theory 5th European Conference
Computational Learning Theory, Vol. 2111 Lecture Notes Computer Science,
pp. 337353. Springer.
Papadopoulos, H. (2008).
Inductive Conformal Prediction: Theory application neural networks.
Fritzsche, P. (Ed.), Tools Artificial Intelligence, chap. 18, pp. 315330. InTech, Vienna, Austria.
URL
http://www.intechopen.com/download/pdf/pdfs id/5294.
Papadopoulos, H., Gammerman, A., & Vovk, V. (2008). Normalized nonconformity measures regression conformal prediction. Proceedings IASTED International
Conference Artificial Intelligence Applications (AIA 2008), pp. 6469. ACTA
Press.
Papadopoulos, H., Gammerman, A., & Vovk, V. (2009a). Confidence predictions
diagnosis acute abdominal pain. Iliadis, L., Vlahavas, I., & Bramer, M. (Eds.),
Artificial Intelligence Applications & Innovations III, Vol. 296 IFIP International
Federation Information Processing, pp. 175184. Springer.
Papadopoulos, H., Papatheocharous, E., & Andreou, A. S. (2009b). Reliable confidence intervals software effort estimation. Proceedings 2nd Workshop
Artificial Intelligence Techniques Software Engineering (AISEW 2009), Vol.
475 CEUR Workshop Proceedings. CEUR-WS.org. URL http://ceur-ws.org/Vol475/AISEW2009/22-pp-211-220-208.pdf.
Papadopoulos, H., Proedrou, K., Vovk, V., & Gammerman, A. (2002a). Inductive confidence
machines regression. Proceedings 13th European Conference Machine
Learning (ECML02), Vol. 2430 Lecture Notes Computer Science, pp. 345356.
Springer.
Papadopoulos, H., Vovk, V., & Gammerman, A. (2002b). Qualified predictions large
data sets case pattern recognition. Proceedings 2002 International
Conference Machine Learning Applications (ICMLA02), pp. 159163. CSREA
Press.
839

fiPapadopoulos, Vovk, & Gammerman

Papadopoulos, H., Vovk, V., & Gammerman, A. (2007). Conformal prediction neural
networks. Proceedings 19th IEEE International Conference Tools
Artificial Intelligence (ICTAI07), Vol. 2, pp. 388395. IEEE Computer Society.
Proedrou, K., Nouretdinov, I., Vovk, V., & Gammerman, A. (2002). Transductive confidence
machines pattern recognition. Proceedings 13th European Conference
Machine Learning (ECML02), Vol. 2430 Lecture Notes Computer Science, pp.
381390. Springer.
Rasmussen, C. E., Neal, R. M., Hinton, G. E., Van Camp, D., Revow, M., Ghahramani, Z.,
Kustra, R., & Tibshirani, R. (1996). DELVE: Data evaluating learning valid
experiments. URL http://www.cs.toronto.edu/delve/.
Rasmussen, C. E., & Williams, C. K. I. (2006). Gaussian Processes Machine Learning.
MIT Press.
Saunders, C., Gammerman, A., & Vovk, V. (1999). Transduction confidence
credibility. Proceedings 16th International Joint Conference Artificial
Intelligence, Vol. 2, pp. 722726, Los Altos, CA. Morgan Kaufmann.
Saunders, C., Gammerman, A., & Vovk, V. (2000). Computationally efficient transductive
machines. Proceedings Eleventh International Conference Algorithmic
Learning Theory (ALT00), Vol. 1968 Lecture Notes Artificial Intelligence, pp.
325333, Berlin. Springer.
Shahmuradov, I. A., Solovyev, V. V., & Gammerman, A. J. (2005). Plant promoter prediction confidence estimation. Nucleic Acids Research, 33 (3), 10691076.
Valiant, L. G. (1984). theory learnable. Communications ACM, 27 (11),
11341142.
Vovk, V., Gammerman, A., & Shafer, G. (2005). Algorithmic Learning Random World.
Springer, New York.
Zhang, J., Li, G., Hu, M., Li, J., & Luo, Z. (2008). Recognition hypoxia EEG preset
confidence level based EEG analysis. Proceedings International Joint
Conference Neural Networks (IJCNN 2008), part IEEE World Congress
Computational Intelligence (WCCI 2008), pp. 30053008. IEEE.

840

fiJournal Artificial Intelligence Research 40 (2011) 767-813

Submitted 11/10; published 04/11

Scaling Heuristic Planning Relational Decision Trees
Tomas de la Rosa
Sergio Jimenez
Raquel Fuentetaja
Daniel Borrajo

TROSA @ INF. UC 3 . ES
SJIMENEZ @ INF. UC 3 . ES
RFUENTET @ INF. UC 3 . ES
DBORRAJO @ IA . UC 3 . ES

Departamento de Informatica
Universidad Carlos III de Madrid
Av. Universidad 30, Leganes, Madrid, Spain

Abstract
Current evaluation functions heuristic planning expensive compute. numerous
planning problems functions provide good guidance solution, worth
expense. However, evaluation functions misguiding planning problems large
enough, lots node evaluations must computed, severely limits scalability heuristic planners. paper, present novel solution reducing node evaluations heuristic
planning based machine learning. Particularly, define task learning search control
heuristic planning relational classification task, use off-the-shelf relational classification tool address learning task. relational classification task captures preferred action
select different planning contexts specific planning domain. planning contexts
defined set helpful actions current state, goals remaining achieved,
static predicates planning task. paper shows two methods guiding search
heuristic planner learned classifiers. first one consists using resulting classifier action policy. second one consists applying classifier generate lookahead
states within Best First Search algorithm. Experiments variety domains reveal
heuristic planner using learned classifiers solves larger problems state-of-the-art planners.

1. Introduction
last years, state-space heuristic search planning achieved significant results
become one popular paradigms automated planning. However, heuristic search
planners suffer strong scalability limitations. Even well-studied domains like Blocksworld
become challenging planners number blocks relatively large. Usually, statespace heuristic search planners based action grounding, makes state-space
explored large number objects and/or action parameters large enough. Moreover,
domain-independent heuristics expensive compute. domains heuristics
misleading, heuristic planners spend planning time computing useless node
evaluations. Even best current domain-independent heuristic functions literature,
forward chaining heuristic planners currently visit many nodes, takes considerable
time, especially due time required compute heuristic functions.
problems entail strong limitations application heuristic planners real problems. instance, logistics applications need handle hundreds objects together hundreds
vehicles locations (Florez, Garca, Torralba, Linares, Garca-Olaya, & Borrajo, 2010). Current heuristic search planners exhaust computational resources solving problem
real logistics application.
c
2011
AI Access Foundation. rights reserved.

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

classic approach dealing planning scalability issues assisting search engines
planners Domain-specific Control Knowledge (DCK). Examples planning systems
benefit knowledge TLP LAN (Bacchus & Kabanza, 2000), TALP LANNER (Doherty
& Kvarnstrom, 2001) SHOP2 (Nau, Au, Ilghami, Kuter, Murdock, Wu, & Yaman, 2003).
Nevertheless, hand-coding DCK complex task implies expertise both, planning domain search algorithm planning system. recent years
renewed interest using Machine Learning (ML) automatically extract DCK. Zimmerman
Kambhampati (2003) made comprehensive survey ML defining DCK. shown first
learning planning competition held 2008 (Learning Track), renewed interest specially
targeted heuristic planners.
paper presents approach learning DCK planning building domain-dependent
relational decision trees examples good quality solutions forward-chaining heuristic
planner. decision trees built off-the-shelf relational classification tool capture best action take possible decision planner given domain.
resulting decision trees used either policy solve planning problems directly
generate lookahead states within Best First Search (BFS) algorithm. techniques allow
planner avoid state evaluations, helps objective improving scalability.
approach implemented system called ROLLER. work improvement
previous one (De la Rosa, Jimenez, & Borrajo, 2008). Alternatively, ROLLER version
repairing relaxed plans (De la Rosa, Jimenez, Garca-Duran, Fernandez, Garca-Olaya, & Borrajo,
2009) competed Learning Track 6th International Planning Competition (IPC) held
2008. ROLLER improvements presented article mainly result lessons learned
competition, discussed later.
paper organized follows. Section 2 introduces issues need considered
designing learning system heuristic planning. help us clarify decisions made development approach. Section 3 describes ROLLER system
detail. Section 4 presents experimental results obtained variety benchmarks. Section 5
discusses improvements ROLLER system compared previous version system.
Section 6 revises related work learning DCK heuristic planning. Finally, last section
discusses conclusions future work.

2. Common Issues Learning Domain-specific Control Knowledge
designing ML process automatic acquisition DCK, one must consider
common issues, among others:
1. representation learned knowledge. Predicate logic common language
represent planning DCK planning tasks usually defined language. However, representation languages used aiming make learning DCK
effective. instance, languages describing object classes Concept
Language (Martin & Geffner, 2000) Taxonomic Syntax (Mcallester & Givan, 1989)
shown provide useful learning bias different domains.
Another representation issue selection feature space (i.e., set instance
features used representing learned knowledge training system.). feature
space able capture key knowledge domain. Traditionally, feature
768

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

space consisted predicates describing current state goals planning
task. feature space enriched extra predicates, called metapredicates,
capture extra useful information planning context applicable operators
pending goals (Veloso, Carbonell, Perez, Borrajo, Fink, & Blythe, 1995). Recently, works
learning DCK heuristic planners define metapredicates capture information
planning context heuristic planner, including example, predicates capture
actions relaxed plan given state (Yoon, Fern, & Givan, 2008).
2. learning algorithms. Inductive Logic Programming (ILP) (Muggleton & De Raedt,
1994) deals development inductive techniques learn given target concept
examples described predicate logic. planning tasks normally represented
predicate logic, ILP algorithms quite suitable DCK learning. Moreover, recent
years, ILP broadened scope cover whole spectrum ML tasks regression, clustering association analysis, extending classical propositional ML algorithms
relational framework. Consequently, ILP algorithms used heuristic planners capture DCK different forms decision rules select actions different
planning context regression rules obtain better node evaluations (Yoon et al., 2008).
3. generation training examples. success ML algorithms depends directly
quality training examples used. learning planning DCK, examples
extracted experience collected solving training problems,
representative different tasks across domain. Therefore, quality training
examples depend variety problems used training quality
solutions problems. Traditionally, training problems obtained random
generators provided parameters tune problems difficulty. way, one
find, domain, kind problems makes learning algorithm generalize
useful DCK.
4. Use learned DCK. Decisions made three issues affect quality
learned DCK. representation schemes may expressive enough capture effective DCK given domain, learning algorithm may able acquire useful
DCK within reasonable time memory requirements, set training problems may
lack significant examples key knowledge. situations, direct use
learned DCK improve scalability planner, could even decrease performance. effective way dealing problem heuristic planners integrating
learned DCK within robust strategies Best-First Search (Yoon et al., 2008)
combining domain-independent heuristic functions (Roger & Helmert, 2010).

3. ROLLER System
section describes general scheme learning DCK instantiated ROLLER
system. First, describes DCK representation followed ROLLER. Second, explains
learning algorithm used ROLLER. Third, depicts ROLLER collects good quality training
examples finally, shows different approaches scaling heuristic planning algorithms
learned DCK.
769

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

3.1 Representation Learned Knowledge: Helpful Contexts Heuristic Planning
present approach following notation specified Planning Domain Definition Language (PDDL) typed STRIPS tasks. Accordingly, definition planning domain comprises definition of:
hierarchy types.
set typed constants, CD , representing objects present tasks domain.
set empty.
set predicate symbols, P, one corresponding arity type
arguments.
set operators O, whose arguments typed variables.
Variables declared directly defining operator argument, local
operator definition. call Po set atomic formulas generated using
defined predicates P, variables defined arguments operator O, general
constants CD . Then, operator defined three sets: pre(o) Po , operator
preconditions; add(o) Po , positive effects; del(o) Po , negative effects
operator.
planning task domain tuple < C , s0 , G > C set typed
constants representing objects particular task, s0 set ground atomic
formulas describing initial state G set ground atomic formulas describing goals.
Given total set constants C = C CD , task defines finite state space finite set
instantiated operators O. state set ground atomic formulas representing
facts true s. States described following closed world assumption. instantiated
operator action operator variable replaced constant C
type. Thus, set actions generated using set constants C
set operators O. definition, solving planning task implies finding plan
sequence actions (a1 , . . . , ), ai transforms initial state state
goals achieved.
planning contexts defined ROLLER rely concepts relaxed plan heuristic
helpful actions, introduced FF planner (Hoffmann & Nebel, 2001). relaxed plan
heuristic returns integer evaluated node, number actions solution
relaxed planning task + node. + simplification original task
deletes actions ignored. idea delete-relaxation computing heuristics planning
first introduced McDermott (1996) Bonet, Loerincs Geffner (1997).
relaxed plan extracted relaxed planning graph, sequence facts
actions layers (F0 , A0 , . . . , , Ft ). first fact layer contains facts initial state.
action layer contains set applicable actions given previous fact layer. fact
layer contains set positive effects actions appearing previous layers.
process finishes goals fact layer, two consecutive facts layers
facts. last case, relaxed problems solution relaxed plan heuristic
returns infinity.
770

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

relaxed planning graph built, solution extracted backwards process.
goal appearing first time fact layer assigned set goals layer, Gi . Then,
last set goals, Gt , second set goals, G1 , goal goals set,
action selected generates goal whose layer index minimal. Afterwards,
precondition action (i.e. subgoal) included goals set corresponding first
layer fact appears. process finished, set selected actions comprises
relaxed plan.
According extraction process, FF planner marks helpful actions set actions
first layer A0 relaxed planning graph achieve subgoals next
fact layer, i.e. goals set G1 . words, helpful actions applicable actions
generate facts top-level goals problems required action relaxed plan.
Formally, set helpful actions given state defined as:
helpful (s) = {a A0 | add(a) G1 6= }
FF planner uses helpful actions search pruning technique, considered candidates selected search. Given state generates
particular set helpful actions, claim helpful actions, together remaining goals static literals planning task, encode helpful context related state.
helpful actions remaining target goals relate actions likely applied
goals need achieved. relations arise helpful actions target
goals often share arguments (problem objects). Additionally, static predicates express
facts characterize objects planning task. Identifying objects also relevant since
may shared arguments helpful actions and/or target goals.
Definition 1 helpful context state defined
H(s) = {helpful (s), target(s), static(s)}
target(s) G describes set goals achieved state s, target(s) = G
static(s) set literals always hold planning task. defined
initial state present every state given changed action. Thus,
static(s) = {p | @a : p add(a) p del(a)}.
helpful context alternative representation tuple <state, goals, applied action>,
traditionally used learning DCK planning. Helpful contexts present advantages
improving scalability heuristic planners:
domains, set helpful actions contains actions likely applied
focusing reasoning shown good strategy.
set helpful actions normally smaller set non-static literals state
(i.e., static(s)). Thus, process matching learned DCK within search obtains
benefits using compact representation.
number helpful actions normally decreases search fewer goals left.
Therefore, matching process become faster search advancing towards
goals.
771

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

3.2 Learning Algorithm: Learning Generalized Policies Relational Decision Trees
ROLLER implements two-step learning process building DCK collection examples
different helpful contexts:

1. Learning operator classifier. ROLLER builds classifier choose best operator
different helpful contexts.
2. Learning binding classifiers. operator domain, ROLLER builds classifier
choose best binding (instantiation operator) different helpful contexts.
learning process split two steps build DCK off-the-shelf learning
tools. planning action may different number arguments arguments different types (e.g. actions switch on(instrument,satellite) turn to(satellite,
direction,direction) Satellite domain) hinders definition target
classes. two-step decision process also clearer decision-making point view.
helps users understand generated DCK better focusing either decision operator apply bindings use given selected operator. learning algorithm
set learning examples two learning steps. Figure 1 shows overview
learning process ROLLER system.

Roller Learner
Training
Problems

1. operator classifier
Example
Generator

PDDL
Domain

op. examples

Relational
Classification

bind. examples

Tool

2. binding classifiers

...

language bias

Figure 1: Overview ROLLER learning process.

3.2.1 L EARNING R ELATIONAL ECISION RESS
classic approach assist decision making consists gathering significant set previous decisions building decision tree generalizes them. leaves resulting tree contain
classes (decisions make), internal nodes contain conditions lead decisions. common way build trees following Top-Down Induction Decision
Trees (TDIDT) algorithm (Quinlan, 1986). algorithm builds tree repeatedly splitting
set training examples according conditions minimize entropy examples. Traditionally, training examples described attribute-value representation. Therefore,
conditions decision trees represent tests value given attribute examples.
Nevertheless, attribute-value approach suitable representing decisions want
keep predicate logic representation. better approach represent decisions relationally,
instance, given action chosen reach certain goals given context share arguments. Recently, new algorithms building relational decision trees examples described
772

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

predicate logic facts developed. new relational learning algorithms similar
propositional ones, except (1) condition nodes tree refer attribute values,
logic queries relational facts holding training examples (2), logic queries
share variables condition nodes placed decision tree. learning algorithm
greedy search process. Since space potential relational decision trees usually huge,
search normally biased according specification syntactic restrictions called language bias.
specification contains target concept, predicates appear condition nodes
trees learning-specific knowledge type information, input output
variables predicates.
paper use tool TILDE (Blockeel & De Raedt, 1998) learning operator
binding classifiers. tool implements relational version TDIDT algorithm, although
off-the-shelf tool learning relational classifiers could used, PRO GOL (Muggleton, 1995) RIBL (Emde & Wettschereck, 1996). different learning
algorithms would provide different results, since explore classifiers space differently.
study pros cons different algorithms beyond scope paper.
comprehensive explanation current relational learning approaches please refer work De
Raedt (2008).
3.2.2 L EARNING PERATOR C LASSIFIER
inputs learning operator classifier are:
Training examples. Examples represented Prolog-like syntax consist
operator selected (the class) together helpful context (the background knowledge
terms relational learning) selected. particular, example contains:
Class. use predicate arity 3 selected encode operator chosen
context. predicate target concept learning step. first argument holds
example identifier links rest example predicates. second argument
problem identifier, links static predicates shared examples coming
planning problem. third argument example class, i.e., name
selected operator helpful context.
Helpful predicates. predicates express helpful actions contained
helpful context. predicate symbol predicates helpful ai ai
name instantiated action. arguments example problem
identifier together parameters action ai . instantiated action,
parameters constants.
Target goal predicates. represent predicates appear goals
hold current state. predicates form target goal gi
gi domain predicates. predicate also contains example problem
identifiers.
Static predicates. represent static predicates given problem. predicates shared training examples belong planning problem.
form static fact fi fi domain predicates
appear effects domain action. arguments problem identifier corresponding arguments domain predicate.
773

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

Figure 2 shows one learning example id tr01 e1 consisting selection operator switch-on associated helpful context. example used building
operator classifier Satellite domain.
% Example tr01 e1 problem tr01
selected(tr01 e1,tr01,switch on).
helpful turn to(tr01 e1,tr01,satellite0,groundstation1,star0).
helpful turn to(tr01 e1,tr01,satellite0,phenomenon2,star0).
helpful turn to(tr01 e1,tr01,satellite0,phenomenon3,star0).
helpful turn to(tr01 e1,tr01,satellite0,phenomenon4,star0).
helpful switch on(tr01 e1,tr01,instrument0,satellite0).
target goal image(tr01 e1,tr01,phenomenon3,infrared2).
target goal image(tr01 e1,tr01,phenomenon4,infrared2).
target goal image(tr01 e1,tr01,phenomenon2,spectrograph1).
% Static Predicates problem
static fact calibration target(tr01,instrument0,groundstation1).
static fact supports(tr01,instrument0,spectrograph1).
static fact supports(tr01,instrument0,infrared2).
static fact board(tr01,instrument0,satellite0).

Figure 2: Knowledge base corresponding example Satellite domain. example
id tr01 e1, links example predicates. obtained solving
training problem tr01 links rest examples problem.
selected operator helpful context switch on, corresponds one
helpful actions encoded helpful predicates example.

Language bias: bias specifies constraints arguments predicates
training examples. assume domain-specific constraint, given learning
technique domain-independent. So, bias contains restrictions argument types
restrictions ensure identifier variables added new variables
classifier generation. bias automatically extracted PDDL domain definitions
consists declaration predicates used learning example argument
types. Figure 3 shows language bias specified learning operator classifier
Satellite domain.
resulting relational decision tree represents set disjoint rules action selection
used provide advice planner: internal nodes tree contain set conditions related helpful context advice provided. leaf nodes contain
corresponding advice; case, operator select number examples covered
rule. operator select one selected often training
examples covered rule. operator classifiers learned ROLLER also advise nonhelpful actions. Given state, non-helpful actions subset applicable actions state
considered helpful actions. Certainly, actions part helpful contexts defined. However, learned operator classifiers indicate name operator select
regardless whether helpful not. Figure 4 shows operator tree learned Satellite
774

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

% ---- target concept ---predict(selected(+IdExample,+IdProblem,-Operator)).
type(selected(idex,idprob,class)).
classes([turn to,switch on,switch off,calibrate,take image]).
% ---- helpful context ---% predicates helpful actions
rmode(helpful turn to(+IdExample,+IdProblem,+-S1,+-D1,+-D2)).
type(helpful turn to(idex,idprob,satellite,direction,direction)).
rmode(helpful switch on(+IdExample,+IdProblem,+-I1,+-S1)).
type(helpful switch on(idex,idprob,instrument,satellite)).
rmode(helpful switch off(+IdExample,+IdProblem,+-I1,+-S1)).
type(helpful switch off(idex,idprob,instrument,satellite)).
rmode(helpful calibrate(+IdExample,+IdProblem,+-S1,+-I1,+-D1)).
type(helpful calibrate(idex,idprob,satellite,instrument,direction)).
rmode(helpful take image(+IdExample,+IdProblem,+-S1,+-D1,+-I1,+-M1)).
type(helpful take image(idex,idprob,satellite,direction,instrument,mode)).
% predicates target goals
rmode(target goal pointing(+IdExample,+IdProblem,+-S1,+-D1)).
type(target goal pointing(idex,idprob,satellite,direction)).
rmode(target goal image(+IdExample,+IdProblem,+-D1,+-M1)).
type(target goal image(idex,idprob,direction,mode)).
% predicates static facts
rmode(static fact board(+IdProblem,+-I1,+-S1)).
type(static fact board(idprob,instrument,satellite)).
rmode(static fact supports(+IdProblem,+-I1,+-M1)).
type(static fact supports(idprob,instrument,mode)).
rmode(static fact calibration target(+IdProblem,+-I1,+-D1)).
type(static fact calibration target(idprob,instrument,direction)).

Figure 3: Language bias learning operator classifier Satellite domain. automatically generated PDDL definition. rmode predicates indicate
used tree. type predicates indicate types particular rmode.

domain. learned decision trees branch denoted symbols +--:<yes/no>,
yes indicates next node positive answers current question indicates next
node negative answers. figure, first branch states calibrate
action set helpful actions, recommendation (in square brackets) choosing action
(i.e. calibrate). addition, branch indicates recommended action occurred 44
times training examples. Moreover, leaf node information (in double square brack775

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

ets) number times type action selected training examples covered
rule current branch. Thus, case, action calibrate selected 44
total 44 times, operators never selected. second branch says
calibrate helpful action, take image one, planner selected
take image 110 110 times. helpful calibrate take image actions helpful switch action, switch recommendation,
selected 44 59 times. tree branches interpreted similarly.
selected(-A,-B,-C)
helpful calibrate(A,B,-D,-E,-F) ?
+--yes:[calibrate] 44.0 [[turn to:0.0,switch on:0.0,switch off:0.0,
|
calibrate:44.0,take image:0.0]]
+--no: helpful take image(A,B,-G,-H,-I,-J) ?
+--yes:[take image] 110.0 [[turn to:0.0,switch on:0.0,switch off:0.0,
|
calibrate:0.0,take image:110.0]]
+--no: helpful switch on(A,B,-K,-L) ?
+--yes:[switch on] 59.0 [[turn to:15.0,switch on:44.0,
|
switch off:0.0,calibrate:0.0,
|
take image:0.0]]
+--no: [turn to] 149.0 [[turn to:149.0,switch on:0.0,
switch off:0.0,calibrate:0.0,
take image:0.0]]

Figure 4: Relational decision tree learned operator selection Satellite domain. Internal
nodes (with ? ending) queries helpful contexts. Leaf nodes (in brackets)
class number observed examples operator.

3.2.3 L EARNING B INDING C LASSIFIERS
second learning step, relational decision tree built domain operator O.
trees indicate bindings select different helpful contexts. inputs learning
binding classifier operator are:
Training examples. consist exclusively helpful contexts operator
selected, together applicable instantiations contexts. Note
given helpful context, applicable instantiations may include helpful nonhelpful actions. Helpful contexts coded exactly previous learning step.
applicable instantiations represented selected predicate. predicate target concept second learning step arguments example
problem identifiers, instantiated arguments applicable action example class (selected rejected). purpose predicate distinguish
good bad bindings operator. Figure 5 shows piece knowledge base
building binding tree corresponding action switch Satellite domain. example, id tr07 e63, resulted selection action instantiation
776

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

switch on(instrument1,satellite0). action switch on(instrument0,
satellite0) also applicable rejected planner.
Language bias: bias learning binding trees bias learning
operator tree, except includes definition selected predicate.
previous learning step, language bias learning binding tree also automatically extracted PDDL domain definition. Figure 6 shows part language bias specified
learning binding tree action switch Satellite domain.

% Example tr07 e63 problem tr07
selected switch on(tr07 e63,tr07,instrument0,satellite0,rejected).
selected switch on(tr07 e63,tr07,instrument1,satellite0,selected).
helpful switch on(tr07 e63,tr07,instrument0,satellite0).
helpful switch on(tr07 e63,tr07,instrument1,satellite0).
helpful turn to(tr07 e63,tr07,satellite0,star1,star2).
helpful turn to(tr07 e63,tr07,satellite0,star5,star2).
helpful turn to(tr07 e63,tr07,satellite0,phenomenon7,star2).
helpful turn to(tr07 e63,tr07,satellite0,phenomenon8,star2).
target goal image(tr07 e63,tr07,phenomenon8,spectrograph2).
target goal image(tr07 e63,tr07,phenomenon7,spectrograph2).
target goal image(tr07 e63,tr07,star5,image1).
% Static Predicates problem
static fact calibration target(tr07,instrument0,star1).
static fact calibration target(tr07,instrument1,star1).
static fact supports(tr07,instrument0,image1).
static fact supports(tr07,instrument1,spectrograph2).
static fact supports(tr07,instrument1,image1).
static fact supports(tr07,instrument1,image4).
static fact board(tr07,instrument0,satellite0).
static fact board(tr07,instrument1,satellite0).

Figure 5: Knowledge base corresponding example tr07 e63 obtained solving training problem tr07 Satellite domain.
result second learning step relational decision tree uninstantiated
operator O. consists set disjoint rules binding selection o. Figure 7
shows example binding tree tswitch built operator switch Satellite
domain. According tree, first branch states helpful action
switch instrument C satellite D, switch bindings (C, D) selected
planner 213 249 times. Note binding trees learned ROLLER also advise
non-helpful actions. Frequently, selected predicate matches tree queries refer
helpful predicates. cases, no-branch query may cover bindings non-helpful
actions operator.
binding trees Satellite domain refer reader Online Appendix
article, include learned DCK domains used experimental section.
777

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

% ---- target concept ---predict(selected switch on(+IdExample,+IdProblem,+INST0,+SAT1,-Class)).
type(selected switch on(idex,idprob,instrument,satellite,class)).
classes([selected,rejected]).
% ---- helpful context ----, operator classification
...

Figure 6: Part language bias learning binding tree switch action
Satellite domain.

selected switch on(-A,-B,-C,-D,-E)
helpful switch on(A,B,C,D) ?
+--yes: [selected] 249.0 [[selected:213.0,rejected:36.0]]
+--no: [rejected] 63.0 [[selected:2.0,rejected:61.0]]

Figure 7: Relational decision tree learned bindings selection switch action
Satellite domain.

many cases, decision trees somewhat complex one shown Figure 7.
instance, turn binding tree 29 nodes includes several queries target goals (e.g.,
asking pending image new pointed direction) others static facts (e.g.,
asking new pointed direction calibration target).
3.3 Generation Training Examples
ROLLER training examples instances decisions made solving training problems. order
characterize variety good solutions, decisions consider different alternatives
solving individual problem. given search tree node (state), alternatives come
possibility choosing different operators different bindings single operator,
cases assuming alternative lead equally good solutions.

Regarding binding decisions, actions alternative solutions ignored,
tagged rejected consequently introduce noise learning process. instance,
consider problem Figure 8 Satellite domain satellite, calibrated
instrument, must turn directions D1,D2 D3 order take images there. planning context, three turn actions helpful actions regarding one solution makes
learning consider one action selected two actions rejected. However, learned
knowledge always recommend helpful turn action towards direction
satellite (with corresponding calibrated instrument) take image. learn kind
knowledge, ROLLER consider three turn actions selected three actions correspond selectable actions learning correct knowledge particular planning
778

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

context. actions marked rejected learner consider selecting turn
described context bad choice.
takeimage D2

S3

S4

turnto(D2,D3)

S5

takeimage D3

turnto(D1,D2)
takeimage D1
turnto(D4,D1)

S1

turnto(D4,D2)
S0

S1

turnto(D4,D3)
S1"

...

S2

turnto(D1,D3)
S3

...

...

Figure 8: Solution path alternatives simplified Satellite problem.
Regarding operator decisions, complete training full catalogue different solutions
confuse learning process. instance, consider example problem Figure 9
goal take image direction D2. applying calibrate action s2 , necessary
switch instrument turn satellite D1 (the calibration target direction).
two actions helpful generate two different solution paths. fact, commutative.
Generalizing operator selection kinds helpful contexts difficult training
examples contain examples types (i.e. examples switch-on action situated
turn-to action vice versa). caused fact helpful
context different operators choose equally good choices.
S1
turnto(D3,D1)

switchon

S2

S0

switchon

calibrate

S3

turnto(D1,D2)

S4

takeimage D2

G

turnto(D3,D1)
S1

Figure 9: Solution path alternatives simplified Satellite problem.
ROLLER follows commitment approach generation training examples: (1) Generation solutions. Given training problem, ROLLER performs exhaustive search obtain
multiple best-cost solutions, taking account alternatives different binding choices. (2)
Selection solutions. ROLLER selects subset solutions set best-cost solutions
order reproduce particular preference operator alternatives. (3) Extraction examples solutions. ROLLER encodes selected subset solutions examples required
learning, operator classification binding classification. following sections detail ROLLER
proceeds three steps.

779

G

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

3.3.1 G ENERATION OLUTIONS
ROLLER solves training problem using Best-First Branch Bound (BFS-BnB) algorithm
extracts multiple good-quality solutions. search space explored exhaustively
within time bound, problem discarded examples generated it. Therefore,
training problems need sufficiently small. addition, training problems need representative enough generalize DCK assists ROLLER solving future problems
domain.
BFS-BnB search completed without pruning repeated states. practice, many repeated
states generated changing order among actions different solution paths. Thus, pruning
repeated states would involve tagging actions leading solutions rejected bindings,
fact true. addition, BFS-BnB algorithm prunes according evaluation
function f (n) = g(n) + h(n), g(n) node cost (in work use plan length
cost function) h(n) FF heuristic. safe way prune search space using
admissible heuristic. However, existing admissible heuristics allow ROLLER complete
exhaustive search problems reasonable size. practice, using FF heuristic produces
overestimations introduces negligible noise learning process. end
search, BFS-BnB algorithm returns set solutions best cost. solutions
used tag nodes search tree belong solutions label solution.

3.3.2 ELECTING OLUTIONS
set best-cost solutions found, ROLLER selects subset solutions used
generating training examples. Since difficult develop domain-independent criteria systematically selecting solutions reproduce operator selection particular context,
defined approach which, heuristically, prefers actions others. preferences
are:
Least-commitment preference: Prefer actions generate alternatives different solution paths.
Difficulty preference: Prefer actions reach goals sub-goals difficult
achieve. example Figure 9 instrument switched achievable
one action. hand, pointing direction D1 considered easier since
achieved actions turn to(D2,D1) turn to(D3,D1).
Given 0 = a1 , . . . , , best-cost plan planning task, compute preferences
functions depending action.
commitment (ai ) =| {a0 | a0 successors(ai ) solution(a0 )} |
function successors(ai ) returns applicable actions state si+1 function solution(a)
verifies whether action tagged part best-cost plan.
difficulty (ai ) =

min

1
| supporters(l) |

ladd(ai )

function supporters(l) = {a | l add(a)} returns set actions achieve
literal l.
780

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

Solutions ranked according preferences. ranking solution 0 =
a1 , . . . , computed weighted sum action preferences, follows:
ranking( 0 , ) =

X
i=0,...,n1

(n i)
(ai+1 )
n

n plan length one commitment difficulty . sum weighted
give importance preferences first actions plan. first action preference
value multiplied 1, second (n 1)/n, on. Otherwise, several alternatives (i.e.,
commutative actions different positions within plan) would lead ranking value.
compute ranking best-cost solutions using commitment . Ties ranking broken
ranking computed difficulty . subset solutions best ranking values
subset solutions selected generating training examples.
3.3.3 E XTRACTING E XAMPLES OLUTIONS
takes subset solutions selected previous step generates training examples. generating examples operator classification, ROLLER takes solution plans 0 =
{a1 , a2 , ..., } correspond sequence state transitions {s0 , s1 , ..., sn } generates
one learning example pair < si , ai+1 > consisting H(si ) class (i.e., operator
name action ai+1 ). See learning example shown Figure 2.
generating examples binding classification operator o, ROLLER considers
pairs < si , ai+1 > ai+1 matches operator o. learning example generated pair
< si , ai+1 > binding selection operator consists H(si ) classes
applicable actions si match o, including ai+1 . Applicable actions solution label
belong selected class applicable actions rejected class. Moreover, actions
belonging solutions top ranking still marked selected even though
nodes example generated. See learning example shown Figure 5.
ROLLER

3.4 Use Learned Knowledge: Planning Relational Decision Trees
section details make heuristic planning benefit DCK, beginning
build action orderings learned DCK. Then, explains two different search strategies
exploit orderings: (1) application DCK generalized action policy (DepthFirst H-Context Policy algorithm) (2) use DCK generate lookahead states within
Best-First Search (BFS) guided FF heuristic (H-Context Policy Lookahead-BFS algorithm).
3.4.1 RDERING ACTIONS R ELATIONAL ECISION REES
Given state s, expression app(s) denotes set actions applicable s. learned DCK
provides ordering app(s). ordering built matching action app(s) first
operator classifier corresponding binding classifier. Figure 10 shows detail
algorithm ordering applicable actions relational decision trees.
algorithm divides set applicable actions two subsets: helpful actions,
non-helpful actions. Then, matches helpful context state, i.e., H(s), tree
operator classification. matching provides leaf node contains list operators
sorted number examples covered leaf training phase (see operator
781

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

DT-Filter-Sort (A,H,T):sorted list applicable actions
A: List actions
H: Helpful Context
T: Decision Trees

selected-actions =
HA = helpful-actions(A, H)
NON-HA = \ HA
leaf-node = classify-operators-tree(T, H)
HA
priority(a) = leaf-node-operator-value(leaf-node, a)
priority(a) > 0
(selected(a),rejected(a)) = classify-bindings-tree(T, H, a)
selected(a)
selection ratio(a)= selected(a)+rejected(a)
priority(a) = priority(a) + selection ratio(a)
selected-actions = selected-actions {a}
max-HA-priority = maxaselected-actions priority(a)
NON-HA
priority(a) = leaf-node-operator-value(leaf-node,a)
priority(a) > max-HA-priority
(selected(a),rejected(a)) = classify-bindings-tree(T, H, a)
selected(a)
selection ratio(a)= selected(a)+rejected(a)
priority(a) = priority(a) + selection ratio(a)
selected-actions = selected-actions {a}
return sort(selected-actions, priority)

Figure 10: Algorithm ordering actions using relational decision trees.
classification tree Figure 4). number examples covered gives operator ordering
used prefer actions search. algorithm uses number initialize
priority value helpful action, taking value corresponding operator. algorithm
keeps helpful actions least one matching example. actions,
algorithm matches action corresponding binding classification tree. resulting leaf
binding tree returns two values: number times ground action selected,
number times rejected training phase. define selection ratio ground
action as:
selected(a)
selection ratio(a) =
selected(a) + rejected(a)
ratio represents proportion good bindings covered particular leaf binding
tree. denominator zero, selection ratio assumed zero. priority
action updated adding selection ratio. Thus, final priority action higher
782

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

actions operators operator classification tree provides higher values, i.e.
selected often training examples. Since selection ratio remains 0
1, adding number considered method breaking ties initial priority
value, using information binding classification tree.
priority non-helpful actions computed similar way except that, case,
algorithm considers actions whose initial priority (the value provided operator classification tree), higher maximum priority helpful actions. manner, capture
useful non-helpful actions. FF follows heuristic criterion classify action helpful. Although
heuristic shown useful, case may arise useful action
particular moment classified helpful. Decision trees capture information, given
recommend choosing non-helpful action. described method takes advantage
fact defines way using information applying learned knowledge. alternative approach would extend planning context new meta-predicate non-helpful
actions. However, pay variety problems domains means significantly larger contexts, causes expensive matching. Finally, selected actions
sorted order decreasing priority values. sorted list actions output algorithm.
3.4.2 H-C ONTEXT P OLICY LGORITHM
helpful context-action policy algorithm moves forward, applying state best action
according DCK. pseudo-code algorithm shown Figure 11. algorithm
maintains ordered open-list. open-list contains states expanded extracted
order. extracted, state evaluated using FF heuristic. Thus, evaluate upon
extraction nodes included open-list. evaluation provides heuristic
value state, h, set helpful actions HA, needed generate helpful
context. heuristic value used for: (1) continuing search state recognized
dead-end (h = ), (2) goal checking (h = 0). Then, helpful context generated. Subsequently, algorithm obtains set AA actions applicable state sorts using
decision trees (as shown algorithm Figure 10). result AA0 AA, sorted list
applicable actions. algorithm inserts successors generated actions AA0 beginning open-list preserving ordering (function push-ordered-list-in-open).
Furthermore, make algorithm complete robust, successors generated applicable
actions AA0 included secondary list called delayed-list. delayed list
used open-list empty. case, one node delayed-list moved
open-list then, algorithm continues extracting nodes open-list.
algorithm, node maintains pointer parent order recover solution
found. Also, node maintains g value, i.e. length path
initial state node. function push-ordered-list-in-open inserts
open list candidates that: (1) repeated states, (2) repeated states lower g
value previous one. Otherwise, repeated states pruned. type pruning guarantees
maintain node shortest solution found.
words, proposed search algorithm depth-first search delayed successors.
benefit algorithm exploits best action selection policy per783

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

Depth-First H-Context Policy (I, G, ): plan
I: Initial state
G: Goals
: Decision Trees

open-list = {I};
delayed-list = ;
open-list 6=
n = pop(open-list)
(h, HA) = evaluate(n, G) /*compute FF heuristic*/
h = /*recognized dead-end*/
continue
h = 0 /*goal state*/
return path(I, n)
H = helpful-context(HA, G, n)
AA = applicable-actions(n)
AA = DT-Filter-Sort(AA, H, )
candidates = generate-successors(n, AA)
open-list = push-ordered-list-in-open(candidates,open-list)
delayed-candidates = generate-successors(n, AA \ AA)
delayed-list = push-ordered-list(delayed-candidates, delayed-list)
open-list = delayed-list 6=
open-list = { pop(delayed-list) }
return fail

Figure 11: depth-first algorithm sorting strategy given DCK.
fect1 action ordering not. Particularly, perfect DCK directly applied
backtrack-free search inaccurate DCK force search algorithm backtrack.
3.4.3 H-C ONTEXT P OLICY L OOKAHEAD TRATEGY
many domains learned DCK may contain flaws: helpful context may expressive
enough capture good decisions, learning algorithm may able generalize well
training examples may representative enough. cases, direct application
learned DCK (without backtracking) may allow planner reach goals problem.
Poor quality learned DCK balanced guide different nature
domain-independent heuristic. successful example ObtuseWedge system (Yoon et al.,
2008) combined learned generalized policy FF heuristic. ObtuseWedge exploited
learned policy synthesize lookahead states within lookahead strategy. Lookahead states
1. perfect policy refer policy leads directly goal state. policies guaranteed perfect
given generated inductive learning.

784

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

first applied heuristic planning YAHSP planner (Vidal, 2004). intermediate
states frequently closer goal state direct descendants current state.
intermediate states added list nodes expanded used within
different search algorithms. learned policy contains flaws, lookahead states synthesized
policy may provide good guidance search. However, lookahead states
included complete search algorithm also considers ordinary successors, search
process becomes robust. general, use lookahead states forward state-space
search slightly increases branching factor search process, overall, shown
YAHSP planner IPC-2004 experiments included YAHSP paper (Vidal, 2004),
approach seems improve performance significantly.
Figure 12 shows generic algorithm using lookahead states generated policy
search. algorithm weighted Best-First Search (BFS), modification one lookahead states inserted open list expanding node.
weighted BFS, nodes expanded maintained open list ordered evaluation
function f (n) = h(n) + g(n). Apart usual arguments BFS, algorithm receives
policy (P ) horizon. horizon represents maximum number policy steps
applied generating lookahead states. experiments, use algorithm
FF heuristic h(n).

H-Context Policy Lookahead BFS (I,G,T ,horizon): plan
I: Initial state
G: Goals
: Decision Trees (policy)
horizon: horizon
open-list =
add-to-open(I)
open-list 6=
n = pop(open-list)
goal-state(n, G)
return path(I, n)
add-to-open-lookahead-successors(n, G, T, horizon)
add-to-open-standard-successors(n)
return fail

Figure 12: Generic Lookahead BFS algorithm.
heuristic evaluation, h(n), g-value, g(n), set helpful actions, also saved
node node evaluated. function add-to-open(state) evaluates
state inserts open-list, ordered increasing values evaluation function,
f (n). function also prunes repeated states, following strategy described DepthFirst H-Context Policy algorithm: repeated states higher g(n) existent one
785

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

pruned. function add-to-open-standard-successors(n) calls add-to-open
successor node n. function add-to-open-lookahead-successors explained below.
adapted generic Lookahead BFS algorithm learned DCK. particular
instantiation function add-to-open-lookahead-successors shown Figure 13.
case, lookahead states generated iteratively applying first action action ordering provided DCK. inputs algorithm current state, problem goals,
decision trees horizon. First, algorithm generates helpful context applicable
actions. helpful actions, n.HA, recovered node. Then, algorithm sorts applicable actions using decision trees (as previously shown algorithm Figure 10).
that, successor generated first action inserted open list, recursive
call successor horizon decremented one. function add-to-open returns
true argument added open list false otherwise. fact, returns
false two cases: (1) state repeated state g-value higher g-value
existent state2 (2) state recognized dead-end. ordered list becomes empty,
lookahead state generated initial node returned. occurs
horizon zero. described implementation similar lookahead strategy approach
followed ObtuseWedge, instead perform lookahead generation using helpful contexts
relational decision trees.
hand, described H-Context Policy Lookahead BFS algorithm search
perfomed set applicable actions node. However, many domains use
helpful actions shown good heuristic. One possible way prioritizing helpful
actions non-helpful actions include open list successors given helpful
actions, include remaining successors secondary list. implemented idea
following strategy used Depth-first H-Context Policy algorithm: open list
becomes empty one node passed secondary list open list, search
continues. algorithm still complete given prune successor. helpful
actions good enough, strategy save many heuristic evaluations. experiments
compare strategy previous one. intuition adequacy
strategy depends directly quality helpful actions, quality learned DCK,
accuracy heuristic particular domain.
Another technique prioritizing helpful actions BFS implemented YAHSP (Vidal,
2004) inserts two consecutive instances node open list. nodes
equal f (n) since represent state. first one contains helpful actions,
therefore, expanded, generates successors resulting actions. second
contains non-helpful actions, called rescue actions. way, successors lower
f (n) parent node sub-tree generated helpful actions expanded
successor resulting non-helpful actions.
performed preliminary experiments, obtaining similar results two described methods prioritizing helpful actions BFS: use secondary list non-helpful
actions, use rescue nodes. reason, include results first technique
experimental section. call algorithm H-Context Policy Lookahead BFS-HA.
2. state repeated g-value smaller existent one, add-to-open re-evaluate
instead takes heuristic evaluation existent state.

786

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

add-to-open-lookahead-successors (n,G,T ,horizon) :state
n: Node (state)
G: Goals
: Decision Trees (policy)
horizon: horizon
horizon = 0
return n
H = helpful-context(n.HA, G, n)
AA = applicable-actions(n)
AA0 = DT-Filter-Sort(AA, H, )
AA0 6=
= pop(AA0 )
n0 = generate-successor(n, a)
added = add-to-open(n0 )
added
goal-state(n0 , G)
return n0
return add-to-open-lookahead-successors(n0 , G, , horizon 1)
return n

Figure 13: Algorithm generating lookahead states decision trees.

4. Experimental Results
section evaluate performance ROLLER system. evaluation carried
variety domains belonging diverse IPCs: Four domains come learning track
IPC-2008 (Gold-miner, Matching Blocksworld, Parking Thoughtful). rest domains
(Blocksworld, Depots, Satellite, Rovers, Storage TPP) selected among domains
sequential tracks IPC 2000 2008 presented different structure
difficulty, available random problem generators, automatically build training sets learning DCK. domain, complete training phase
ROLLER learns corresponding DCK testing phase evaluate scalability
quality solutions found ROLLER learned DCK. Next, detail experimental
results obtained two phases. Moreover, domains give particular
details training test sets, learned DCK observed ROLLER performance.
4.1 Training Phase
domain, built training set thirty randomly generated problems. size
structure problems discussed particular details given domain.
explained section 3.2, ROLLER generates training examples solving problems
787

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

training set BFS-BnB search. set time-bound 60 seconds solve training
problem, discarding exhaustively explored time-bound. Then, ROLLER
generates training examples solutions found builds corresponding decision
trees TILDE system (Blockeel & De Raedt, 1998).
evaluate efficiency ROLLER training phase computed following metrics:
time needed solving training problems, number training examples generated
process, time spent TILDE learning decision trees number leaves
operator selection tree. last number gives clue size learned DCK. Table 1
shows results obtained domain.
Domain
Blocksworld
Depots
Gold-miner
Matching-BW
Parking
Rovers
Satellite
Storage
Thoughtful
TPP

Training
Time (s)
836.0
456.2
1156.9
865.8
105.8
528.3
19.8
136.3
883.4
995.9

Learning
Examples
2542
493
126
430
442
1011
1702
677
502
560

Learning
Time (s)
13.3
23.1
4.5
12.4
7.0
13.6
13.4
5.1
352.2
23.3

Tree
Leaves
18
13
5
23
12
24
4
6
19
6

Table 1: Experimental results training process. Training learning times shown,
well number training examples, complexity generated trees (number
leaves).

achieves shorter Learning Times, fourth column Table 1, state-of-the-art
systems learning generalized policies (Martin & Geffner, 2004; Yoon et al., 2008). Particularly,
systems implement ad-hoc learning algorithms sometimes require hours order
obtain good policies, approach needs seconds learn DCK given domain.
fact makes approach suitable architectures need on-line planning learning processes. However, learning times constant different domains, depend
number training examples (in work, number given amount different
solutions training problems), size training examples (in work size
given number arity predicates actions planning domain) training
examples structured, i.e., whether examples easily separated learning not.
ROLLER

4.2 Testing Phase
testing phase ROLLER attempts solve, domain, set thirty test problems.
problems taken evaluation set corresponding IPC. evaluation set
contains problems, thirty problems thirty hardest ones. Depots domain
exception twenty-two problems, evaluation set domain IPC-2002
788

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

contained twenty-two problems. Three experiments made testing phase.
first one evaluates ROLLERs performance DCK learned solutions training
problems ranked solution approach. second one evaluates usefulness
learned DCK third one compares ROLLER state-of-the-art planners. experiment evaluate two different dimensions solutions found ROLLER: scalability
quality. testing experiments done using 2.4 GHz processor time-bound 900
seconds3 6Gb memory-bound.
4.2.1 OLUTION R ANKING E VALUATION
experiment evaluates effect selecting solutions following approach described Section 3.3. ROLLER configurations evaluation are:
Top-Ranked Solutions: Depth-First H-Context Policy algorithm using DCK learned
sub-set top ranked solutions. use search algorithm, since performance depends quality learned DCK algorithms
using DCK.
Solutions: Depth-First H-Context Policy algorithm using DCK learned solutions obtained BFS-BnB algorithm.
Table 2 shows number problems solved configuration, also time plan
length average computed problems solved configurations. number brackets
first column number problems solved common. Top-ranked solutions configuration solved thirty problems solutions configuration, mainly due difference
21 problems Matching Blocksworld domain.
Domains
Blocksworld (30)
Depots (18)
Gold-miner (30)
Matching-BW (0)
Parking (30)
Rovers (27)
Satellite (28)
Storage (10)
Thoughtful (12)
TPP (30)
Total

Top-Ranked Solutions
Solved
Time Length
30
0,62
170,0
21
0,94
489,1
30
0,01
65,3
21


30
4,90
148,9
28
1,40
166,0
30
11,21
123,6
15
0,00
9,0
12
1,25
249,7
30
0,97
147,1
247



Solutions
Solved
Time Length
30
2,39
550,7
18
0,97
607,3
30
0,01
65,3
0


30
2,20
56,2
29
31,20
355,8
28
11,47
121,6
10
0,00
9,0
12
1,28
249,2
30
0,90
132,8
217



Table 2: Problems solved time plan length average evaluation ranking solution
heuristic.

effect selecting solutions varies across domains. instance, quite important regarding plan quality Blocksworld, Depots Rovers. Satellite domain top-ranked
solutions allow ROLLER solve two problems maintaining similar time plan length
3. 900 seconds time-bound established learning track IPC-2008.

789

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

average. Gold Miner domain, selecting solutions irrelevant equally
good solutions per problem (i.e., goal always single fact gold) fairly
top-ranked ones. Parking domain benefit selecting solutions.
Considering overall results, think selecting solutions useful heuristic improving
DCK quality many domains. remaining evaluations refer DCK used
ROLLER decision trees learned top-ranked solutions.
4.2.2 DCK U SEFULNESS E VALUATION
shown IPC Learning Track results, DCK may degrade performance base planner,
DCK incorrect. mind, designed experiment measure performance ROLLER algorithms comparing versions without DCK. made two versions
non-learning algorithms. first one empty configuration decision
tree given algorithm, thus ordering computed helpful actions, second one
systematic configuration, ordering supplied FF heuristic instead.
ROLLER configurations used comparisons are:
ROLLER: Depth-First H-Context Policy algorithm DCK learned training
phase.
ROLLER-BFS: H-Context Policy Lookahead BFS algorithm DCK learned
training phase. configuration uses horizon h = 100. choose value
basis empirical evaluations.
ROLLER-BFS-HA: modified version ROLLER - BFS helpful actions considered immediate successors. lookahead states generated original version, using also horizon.
three algorithms equivalent version empty configuration:
DF-HA (Depth-first Helpful Actions): empty DCK ROLLER corresponds depthfirst algorithm helpful actions. original algorithm, non-helpful actions
placed delayed list.
BFS: empty DCK ROLLER - BFS generate lookahead states (i.e., algorithm add-to-open-lookahead-successors Figure 12). Therefore, algorithm becomes
standard Best-first Search.
BFS-HA: modified version BFS helpful actions considered. Non-helpful
actions placed delayed list.
Previous configurations also systematic version. case action ordering computed
FF heuristic:
GR-HA (Greedy Helpful Actions): algorithm corresponds greedy search
helpful actions. node, helpful immediate successors sorted FF heuristic.
Non-helpful nodes go delayed list.
LH-BFS (Lookahead-BFS): BFS lookahead states. function DT-Filter-Sort
replaced function computes ordering using FF heuristic.
790

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

LH-BFS-HA: modified version LH - BFS helpful actions considered. Nonhelpful actions placed delayed list.
comparison, computed number problems solved scores used
IPC-2008 learning track evaluate planners performance terms CPU time quality (plan
length). time score computed follows: problem planner receives Ti /Ti
points, Ti minimum time participant used solving problem i, Ti
CPU time used planner question. 30 problem test set planner receive 30
points, higher score better. quality score computed way, replacing
L, L measures quality terms plan length. addition compute time
quality averages problems solved configurations. configuration solve
problem, taken account measure. Average measures complement scores
since give direct information commonly solved problems, scores tend benefit
configurations solve problems others not.
Table 3 shows summary results obtained DCK usefulness evaluation.
configuration compute number domains algorithm top performer
evaluated criteria (i.e., numbers solved problems, time quality scores averages). top performer domain algorithm equal better measure
rest algorithms. table, algorithm 10 points, number
evaluated domains. Global section refers overall top performers. Relative section refers
number domains configuration equal better two configurations
algorithm strategy (i.e., depth-first, best-first, best-first helpful actions). averages
commonly solved problems computed configurations solve one problem. Results show ROLLER good number solved problems speed metrics.
Regarding quality score, ROLLER ROLLER - BFS - HA best performers three domains
each. However, BFS BFS - HA obtained better results quality average.
Global
Solved Problems
Time Score
Time Average
Quality Score
Quality Average
Relative
Solved Problems
Time Score
Time Average
Quality Score
Quality Average

DEPTH-FIRST
roller gr-ha df-ha
7
2
2
8
1
0
9
1
1
3
1
0
0
0
0
8
9
9
7
5

3
1
1
3
5

2
0
1
0
0

BEST-FIRST
roller-bfs lh-bfs
1
0
0
0
1
0
1
0
1
2
7
8
9
4
1

3
1
1
4
2

bfs
1
0
0
1
3
2
1
0
2
7

HELPFUL BEST-FIRST
roller-bfs-ha lh-bfs-ha bfs-ha
5
1
1
1
0
0
1
0
0
3
1
2
0
1
5
9
9
7
7
2

3
0
1
1
1

2
1
2
2
7

Table 3: Summary DCK usefulness evaluation. column gives number domains
configuration top performer row item.

Table 4 shows number solved problems DCK usefulness evaluation. Total
row shows ROLLER configuration solved problems empty systematic
versions. Results time quality scores reported Table 9 Table 10 Appendix A.
791

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

Detailed results averages considered less interesting since many domains
common solved problems, easy problems.
Domains
Blocksworld (30)
Depots (22)
Gold-miner (30)
Matching-BW (30)
Parking (30)
Rovers (30)
Satellite (30)
Storage (30)
Thoughtful(30)
TPP (30)
Total

DEPTH-FIRST
roller gr-ha df-ha
30
1
0
21
18
18
30
0
0
21
0
0
30
25
1
28
30
30
30
23
22
15
9
10
12
15
0
30
30
30
247
151
111

BEST-FIRST
roller-bfs lh-bfs
bfs
8
0
0
20
19
13
17
17
16
14
7
14
30
11
7
26
28
11
25
22
15
19
18
20
20
14
11
16
24
9
195
160 116

HELPFUL BEST-FIRST
roller-bfs-ha lh-bfs-ha bfs-ha
8
0
0
20
20
20
30
0
0
19
10
17
30
11
9
30
30
30
30
23
23
19
10
10
23
16
12
19
26
14
228
146
135

Table 4: Problems solved DCK usefulness evaluation.

4.2.3 IME P ERFORMANCE C OMPARISON
experiment evaluates scalability ROLLER system, compared state-of-the-art planners. comparison, chosen LAMA (Richter & Westphal, 2010), winner
sequential track past IPC, FF, last IPC shown still competitive.
used three ROLLER configurations explained previous evaluation. configuration
planners are:
FF. Running Enforced Hill-Climbing (EHC) algorithm helpful actions together
complete BFS case EHC fails 4 . Though planner dates 2001 include
evaluation because, shown results IPC-2008, still competitive
state-of-the-art planners. Besides, planner extensively used planning
learning systems.
LAMA-first. winner classical track IPC-2008. configuration LAMA
modified stop finds first solution. way, comparison fair
rest configurations implement anytime behavior, i.e., continuous solution
refinement reaching time-bound). anytime behavior LAMA compared later
ROLLER performance next section.
Table 5 shows number problems solved together speed score. results
give overall view performance different planners. ROLLER solves many
problems configuration 6 10 domains achieves top speed score
seven domains. second best score belongs ROLLER - BFS - HA, solves many
problems planners six domains. LAMA-first fairly competitive, since solves seven
problems less ROLLER 13 problems ROLLER - BFS - HA. cases LAMA-first
achieves lower speed score.
4. planner actually Metric-FF running STRIPS domains. consider implementation adequate baseline
comparison ROLLER implemented code rather original FF order extend
approach planning models.

792

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

Domain (problems)
Blocksworld (30)
Depots (22)
Gold-miner (30)
Matching-BW (30)
Parking (30)
Rovers (30)
Satellite (30)
Storage (30)
Thoughtful(30)
TPP (30)
Total

ROLLER
solved
score
30
29.87
21
19.86
30
26.00
21
14.84
30
28.57
28
24.82
30
22.60
15
11.02
12
11.99
30
29.50
247
219.07

ROLLER-BFS
solved
score
8
2.47
20
11.01
17
0.03
14
1.32
30
22.72
26
13.41
25
14.61
19
12.31
20
12.38
16
14.83
195 105.09

ROLLER-BFS-HA
solved
score
8
2.40
20
11.46
30
5.35
19
1.71
30
23.60
30
16.24
30
18.33
19
16.17
23
13.09
19
13.97
228
122.32

FF
solved
0
20
27
9
24
29
22
17
14
26
188

score
0.00
8.70
0.22
0.27
0.94
5.51
5.31
10.51
8.16
6.27
45.89

LAMA-first
solved
score
17
0.17
20
3.88
29
12.24
25
20.02
23
1.69
30
18.59
28
15.66
19
9.03
20
11.29
30
9.66
241
102.23

Table 5: Problems solved speed score five configurations.

Table 6 shows average time five configurations addressing subset problems solved configurations. first column shows parenthesis number commonly
solved problems. results closely related shown Table 5. ROLLER achieves
best average time eight ten domains. also observe different configurations
good particular domains even particular problems. instance, Thoughtful
domain four problems solved configurations.
Domain (problems)
Blocksworld (7)
Depots (18)
Gold-miner (17)
Matching-BW (6)
Parking (22)
Rovers (25)
Satellite (22)
Storage (14)
Thoughtful(4)
TPP (16)

ROLLER
0.36
0.84
0.00
1.99
1.86
1.37
1.24
11.74
1.49
0.02

ROLLER-BFS
66.31
15.53
49.82
42.25
2.91
24.38
7.08
0.01
10.84
0.02

ROLLER-BFS-r
67.99
2.54
0.02
44.53
2.78
9.83
1.87
0.03
9.52
0.02

FF
4.01
0.28
74.90
74.02
42.82
18.23
0.05
14.52
0.70

LAMA-first
139.69
61.73
0.01
1.96
108.22
1.59
1.33
0.19
3.55
0.10

Table 6: Planning time averages problems solved configurations.

4.2.4 Q UALITY P ERFORMANCE C OMPARISON
experiment compares quality first solutions found solutions found
anytime behavior. anytime configuration, planners exhaust time-bound trying improve
incrementally best solution found. Three ROLLER algorithms modified configuration
best solution found far used upper-bound order prune nodes
exceed plan length. anytime behavior regular configuration LAMA. FF
anytime behavior, included anytime comparison well base
comparing quality improvements planners.
Table 7 shows quality scores first solution last solution found
anytime configurations. anytime column planner shows score variation reveals
whether planner able make relative improvements first solutions. relative
793

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

Domain
Blocksworld
Depots
Gold-miner
Matching-BW
Parking
Rovers
Satellite
Storage
Thoughtful
TPP
Total

ROLLER
first anytime
29.83
29.83
8.50
9.26
14.30
18.00
9.43
9.52
19.38
17.04
21.38
21.39
28.65
28.81
13.41
13.46
6.27
6.21
25.38
24.26
176.53
177.35

ROLLER-BFS
first anytime
8.00
8.00
12.39
17.01
11.50
17.00
13.01
12.43
24.24
23.98
21.78
21.59
23.20
23.00
15.69
18.38
15.93
15.12
14.45
15.09
160.19
171.65

ROLLER-BFS-HA
first
anytime
8.00
8.00
12.85
18.95
13.08
15.39
17.67
17.16
24.24
25.51
25.66
26.14
28.18
28.94
15.64
17.26
18.63
18.35
16.80
17.77
180.75
193.53

FF
first
0.00
19.01
27.00
8.23
21.53
28.66
21.55
16.23
13.96
23.42
179.59

relative
0.00
17.96
27.00
7.15
17.79
28.33
21.33
15.80
13.09
21.56
170.06

LAMA
first anytime
7.42
8.29
18.32
19.28
14.04
26.81
23.25
24.72
19.16
22.56
28.26
28.97
27.02
27.42
17.24
18.81
18.84
18.59
29.99
29.82
203.54
219.24

Table 7: Quality scores first solution anytime configuration evaluated planners.

FF shows score solutions compared solutions given anytime configuration
planners. FF loses points cases others able improve
solutions. two LAMA configurations obtained top score category. Nevertheless,
planner dominated domains. Furthermore, configurations achieved top quality score
first solution least one domain.
Domain
Blocksworld (7)
Depots (18)
Gold-miner (17)
Matching-BW (6)
Parking (22)
Rovers (25)
Satellite (22)
Storage (14)
Thoughtful(4)
TPP (16)

ROLLER
first
anytime
146.29
146.29
385.78
372.22
55.65
38.18
186.00
170.33
96.91
93.82
150.80
149.96
78.41
77.59
43.07
42.64
292.25
291.75
60.25
57.00

ROLLER-BFS
first
anytime
142.86
142.86
81.78
54.00
30.06
19.65
75.00
70.00
75.32
59.86
115.56
115.56
80.05
80.00
15.21
11.36
168.50
168.25
60.00
52.06

ROLLER-BFS-HA
first
anytime
142.86
142.86
76.83
43.33
47.88
39.35
76.00
69.33
75.32
54.45
114.40
112.12
80.05
77.32
15.64
13.29
168.50
164.50
60.25
49.38

FF
first

46.39
19.65
71.67
60.00
94.20
77.18
12.43
123.25
59.19

relative

46.39
19.65
71.67
60.00
94.20
77.18
12.43
123.25
59.19

LAMA
first
anytime
358.57
318.00
49.28
41.56
43.35
19.65
78.33
62.33
64.14
47.91
101.44
98.36
76.91
75.50
12.71
11.29
140.25
128.50
51.81
47.94

Table 8: Quality averages first solution anytime configuration evaluated planners.

Table 8 shows plan length average problems solved configurations. first
column shows average first solutions anytime column gives average
last solutions anytime configuration. commonly solved problems
reported Table 6. Although FF planner solved fewer problems, achieves
best average plan length seven domains. Plan length averages reveal ROLLER able
find first solutions good quality domains. ROLLER - BFS ROLLER - BFS - HA find
better quality solutions ROLLER, several domains, averages competitive
LAMA . ROLLER - BFS ROLLER - BFS - HA show better quality performance mainly due
combination learned DCK domain-independent heuristic within BFS algorithm.
following subsections discuss particular details domains. give
brief description domain together information training test sets used
experimental evaluation. domain, also analyze learned DCK obtained
794

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

results order give fine-grained interpretation observed performance. details
domains found IPC web site.5
4.2.5 B LOCKSWORLD ETAILS
Problems domain concerned configuring towers blocks using robotic arm.
training set used experiments consisted of: ten eight-block problems, ten nine-block
problems ten ten-block problems. test set consisted 30 largest typed problems
IPC-2000, 36 50 blocks.
blocksworld domain
100
ROLLER
ROLLER-BFS
ROLLER-BFS-HA
LAMA-first

Percentage solved

80

60

40

20

0
0.1

1

10
CPU Time

100

1000

Figure 14: Percentage solved problems increasing time evaluating scalability performance Blocksworld domain.
Although domain one oldest benchmarks automated planning, still challenging state-of-the-art heuristic planners. Blocksworld presents strong interaction among goals
current heuristics fail capture. particular, achieving goal domain may undo
previously satisfied goals. Therefore, crucial achieve goals specific order. DCK
learned ROLLER gives total order domain actions different contexts capturing key
knowledge, lets ROLLER achieve impressive scalability results producing good quality
solution plans. ROLLER configurations considerably better non-learning configurations.
Particularly, ROLLER solved thirty problems set DF - HA GR - HA solve
problem. ROLLER also quite good compared state-of-the-art planners. Figure 14
observe ROLLER performs two orders magnitude faster LAMA. x-axis
figure represents CPU time logarithmic scale y-axis represents percentage
solved problems particular time. Moreover, ROLLER obtained best quality score first
solution anytime evaluations. addition, average plan length common problems fairly
close best average, obtained ROLLER - BFS ROLLER - BFS - HA. BFS algorithms
5. http://idm-lab.org/wiki/icaps/index.php/Main/Competitions

795

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

scale well domain partially guided FF heuristic, considerably
underestimates distance goals. Similarly, lookahead states generated policy
discarded fail escape plateaus generated heuristic function.
analyzing learned operator tree found explanations good performance
ROLLER Blocksworld domain: operator tree clearly split two parts. first part contains decisions take arm holding block. situation, tree captures
STACK PUT-DOWN block. second part contains decisions take arm empty.
case tree captures UNSTACK PICK-UP block. second part tree,
current state search matches logical query helpful unstack(Block1,Block2)6
means tower blocks Block1 well arranged, i.e., Block1 least
one block beneath Block1 well placed. Therefore, set helpful actions compactly
encodes useful concept bad tower. kind knowledge manually defined
previous works order learn good policies Blocksworld. One approach consisted including recursive definitions new predicates, support predicates above(X,Y)
inplace(X) (Khardon, 1999). Another alternative involved changing representation language, instance concept language (Martin & Geffner, 2004) taxonomic syntax (Yoon,
Fern, & Givan, 2007). Kleene-star operator taxonomic syntax (i.e., operator defining recursion) discarded subsequent work (Yoon et al., 2008) predicate
used instead. ROLLERs ability recognize bad-towers without extra predicates arises
misplaced block tower makes UNSTACK action top block helpful, since always
part relaxed plan arm empty.
Due extraordinary performance ROLLER domain, built extra test set
clarify whether trend observed ROLLER configuration would hold larger
problems. aim, randomly generated 30 problems distributed sub-sets 50, 60, 70,
80, 90 100 blocks 5 problems sub-set. ROLLER solved 30 problems
extra test set time average 20.1 seconds per problem spending 175.3 solve
problem. Obviously, problems became difficult ROLLER number blocks increase.
4.2.6 EPOTS ETAILS
domain combination transportation domain Blocksworld domain,
crates instead blocks hoists instead robot arm. problems consist trucks
transporting crates around depots distributors. Using hoists, crates stacked onto pallets
top crates final destination. domain, 30 training problems
different combinations 2 3 locations (depots distributors), 1 2 trucks, 1 2 pallets per
location, 1 hoist per location 2 5 crates placed different configurations.
testing phase used 22 problems IPC-2002 set. hardest problem 12
locations (1 2 pallets 1 2 hoists), 6 trucks 20 crates.
ROLLER ROLLER - BFS improve performance non-learning strategies, three
configurations BFS Helpful-Action solved 20 problems. ROLLER able solve 21
problems, achieving best speed score. However, high average plan length indicates
policy producing good quality plans. ROLLER - BFS - HA obtains second best speed score
competitive plan lengths. Figure 15 shows percentage solved problems
6. explained section 3.2 logic queries ROLLER present example problem Ids. case Ids
ignored simplicity given needed matching current helpful context.

796

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

increasing CPU time (in logarithmic scale). anytime configuration, ROLLER - BFS - HA
able refine solutions, achieving quality average similar LAMA.
depots domain
100
ROLLER
ROLLER-BFS
ROLLER-BFS-HA
FF
LAMA-first

Percentage solved

80

60

40

20

0
0.01

0.1

1

10

100

1000

CPU Time

Figure 15: Percentage solved problem increasing time evaluating scalability performance Depots domain.

DCK learned domain provides inaccurate advice large planning contexts.
instance, ROLLER makes mistakes deciding crate unload several crates
loaded truck. reason inaccurate DCK training problems large
enough gain knowledge. addition, adding crates problems makes unfeasible solved BFS-BnB. Nevertheless, limitation learned DCK
evident. Depots domain undirected (i.e., actions reversible),
dead ends. Therefore, mistakes made DCK fixed additional actions, leads
worse quality plans. Besides, since first solutions rapidly found, ROLLER configurations
spend time refining solutions. reason great improvement plan average
ROLLER - BFS - HA .
4.2.7 G OLD -M INER ETAILS
objective domain navigate grid cells reaching cell containing gold.
cells occupied rocks cleared using bombs laser. domain
training set consists of: 10 problems 3 3 cells, 10 problems 4 4 cells, 10
problems 5 5 cells. domain part learning track IPC-2008 used
test set used competition. set problems ranging 5 5 7 7 cells.
Problems Gold-Miner domain solvable helpful actions alone. explains
difference number solved problems ROLLER, ROLLER - BFS - HA nonlearning counterpart. general terms, domain trivial ROLLER, ROLLER - BFS - HA (they
solved test problems less 10 seconds per problem) LAMA. Nevertheless, FF scales797

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

poorly. domain essential actions picking bombs frequently considered
helpful actions, relaxed problem solvable using laser. Consequently, FF fails
solve problems EHC requires additional BFS search. Figure 16 shows
percentage solved problems increasing CPU time. Regarding anytime evaluation,
tested configurations improved first solution found many problems.
gold-miner domain
100

Percentage solved

80

60

40

20
ROLLER
ROLLER-BFS
ROLLER-BFS-HA
FF
LAMA-first
0
0.01

0.1

1

10

100

1000

CPU Time

Figure 16: Percentage solved problems increasing time evaluating scalability performance Gold-miner domain.
domain, operator tree succeeds capturing key knowledge. initial states,
bombs laser cell, robot needs decide pick-up.
operator tree domain matches logical query candidate pickup laser(Cell)
higher ratio operator PICKUP-BOMB operator PICKUP-LASER. operator
preference allows ROLLER avoid dead ends laser destroys gold. hand,
situations laser required (i.e., destroy hard rocks) reached second choice
policy. fact implies backtracking ROLLER, additional evaluated nodes
significantly affect overall performance. preference PICKUP-BOMB
PICKUP-LASER action example selecting non-helpful actions.
4.2.8 ATCHING B LOCKSWORLD ETAILS
domain version Blocksworld designed analyze limitations relaxed plan heuristic.
version blocks polarized, either positive negative. also two polarized robot
arms. Furthermore, block placed (stack put-down actions) arm different
polarity, block becomes damaged block placed top it. However, picking
unstacking block wrong polarity seems harmless. fact makes recognizing
dead ends difficult task FF heuristic. Particularly, relaxed task blocks never
damaged. Thus, relaxed plan (and consequently set helpful actions) heuristic
estimation wrong. training set used domain consists fifteen 6-blocks problems
798

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

fifteen 8-blocks problems. used even number blocks keep problems balanced (i.e.,
half blocks polarity). testing phase used test set learning track
IPC-2008. set problems ranging 15 25 blocks.
DF - HA GR - HA solve problem, problems solvable
helpful actions alone. learned DCK recommended useful non-helpful actions, thus
ROLLER able solve 21 problems. Policy configurations perform better systematic strategies, fairly similar using lookahead strategy. fact reveals learned DCK
effective enough pay effort building lookahead states. LAMA planner
solves problems. Figure 17 shows percentage solved problems increasing
CPU time.
matching-bw domain
100
ROLLER
ROLLER-BFS
ROLLER-BFS-HA
FF
LAMA-first

Percentage solved

80

60

40

20

0
0.1

1

10
CPU Time

100

1000

Figure 17: Percentage solved problems increasing time evaluating scalability performance Matching Blocksworld domain.

ROLLER solved problems evaluating considerable number nodes plan length,
means DCK learned domain accurate. analyzing training
examples find many solution plans satisfy key knowledge domain (robot
arms unstack pick-up blocks polarity). Specifically, robot handling
top block, i.e., block blocks goal state, polarity robot
arm becomes meaningless. effect unavoidable shortest plans involve managing
top blocks efficient way ignoring polarities. examples include noise
learning make generalization complex.

4.2.9 PARKING ETAILS
domain involves parking cars street N curb locations cars double
parked, triple parked. goal move one configuration parked cars another
driving cars one curb location another. domain training set consists of: fifteen
799

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

problems six cars four curbs fifteen problems eight cars five curbs. testing
used test set learning track IPC-2008. hardest problem set 38 cars
20 curbs.
three ROLLER configurations solve problems perform significantly better nonlearning strategies. addition, three ROLLER configurations outperform FF LAMA
difference one order magnitude. reason LAMA FF low speed
scores. ROLLER configurations also consistently better systematic empty configurations. Figure 18 shows percentage solved problems increasing CPU time.
hand, three ROLLER configurations achieve first solutions suficient quality. However, solutions refined anytime evaluation, especially ROLLER - BFS - HA,
achieves top quality score plan length average fairly similar LAMA.
parking domain
100
ROLLER
ROLLER-BFS
ROLLER-BFS-HA
FF
LAMA-first

Percentage solved

80

60

40

20

0
0.1

1

10
CPU Time

100

1000

Figure 18: Percentage solved problems increasing time evaluating scalability performance Parking domain.

learned DCK domain quite effective (ROLLER rarely backtracked). operator tree perfectly classifies MOVE-CAR-TO-CURB action first tree node, asking
considered helpful action. Besides, binding tree operator selects right car asking
target goal rejecting candidates. two decisions guide planner place
car right position whenever possible. result, large number nodes evaluated,
explains scalability difference FF LAMA.
4.2.10 ROVERS ETAILS
domain simplification tasks performed autonomous exploration vehicles sent
Mars. tasks consist navigating rovers, collecting soils rocks samples, taking
images different objectives. domain training set consists of: ten problems one
rover, four waypoints, two objectives one camera; ten problems additional camera;
800

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

ten problems additional rover. Problems test set thirty largest problems
IPC-2006 set (i.e., problems 11 40). largest problem set 14 rovers 100
waypoints.
DCK strategies faster systematic empty strategies, differences significant since configurations solved problems. one hand helpful actions
Rovers domain quite good hand test set problems
big enough generate differences among approaches. Regarding planner comparison, ROLLER
achieves top performance score scales significantly better FF, solves two problems
less LAMA. Figure 19 shows percentage solved problems increasing CPU time.
Regarding anytime evaluation, planners able refine first solutions. LAMA gets
top quality score best plan length refining solutions.
rovers domain
100
ROLLER
ROLLER-BFS
ROLLER-BFS-HA
FF
LAMA-first

Percentage solved

80

60

40

20

0
0.01

0.1

1

10

100

1000

CPU Time

Figure 19: Percentage solved problems increasing time evaluating scalability performance Rovers domain.

domain, ROLLER learned imperfect DCK, manages achieve good scalability
results. DCK imperfect partially actions communicating rock, soil image analysis
applied order among them. Therefore, preferences ranking selecting
solutions fail discriminate among actions confuse learning algorithm. Since
actions could applied order, DCK mistakes seem harmless planning
time.
4.2.11 ATELLITE ETAILS
domain comprises set satellites different instruments, operate different
formats (modes). tasks consist managing instruments taking images certain targets
particular modes. domain training set consist thirty problems one satellite, two
instruments, five modes five observations. Problems test set thirty largest problems
801

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

IPC-2004 (i.e., problems 7 36). largest problem set 10 satellites, 5 modes
174 observations.
three ROLLER configurations improved number solved problems non-learning
counterpart. addition, ROLLER ROLLER - BFS - HA solved 30 problems set, two
LAMA eight FF. Figure 20 shows percentage solved problems
increasing CPU time. ROLLER ROLLER - BFS - HA achieve good quality solutions
able refine anytime evaluation, achieving plan lengths similar LAMA.
satellite domain
100
ROLLER
ROLLER-BFS
ROLLER-BFS-HA
FF
LAMA-first

Percentage solved

80

60

40

20

0
0.01

0.1

1

10

100

1000

CPU Time

Figure 20: Percentage solved problems increasing time evaluating scalability performance Satellite domain.

learned DCK captures key knowledge Satellite domain. trees shown
Figure 4 Figure 7 part learned DCK fewer training examples. domain
ROLLER ROLLER - BFS - HA perform quite similarly. reason FF heuristic
also quite accurate domain. Thus, deepest lookahead state generated learned policy
frequently selected heuristic BFS search.
4.2.12 TORAGE ETAILS
domain concerned storage set crates taking account spatial configuration depot. domain tasks comprise using hoists move crates containers
particular area depot. training set consists 30 problems 1 depot, 1 container, 1
hoist different combinations 2 3 crates 2 6 areas inside depot.
test set used 30 problems IPC-2006 set. largest problem domain 4
depots 8 areas each, 5 hoist 20 crates.
first 12 problems trivially solved configurations. Then, problem difficulty increases quickly number problem objects increases. BFS solved 20 problems, one
DCK strategy, meaning DCK lookahead strategies pay off. domain
802

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

also hard FF LAMA. Figure 21 shows percentage solved problems increasing
CPU time.
storage domain
100
ROLLER
ROLLER-BFS
ROLLER-BFS-HA
FF
LAMA-first

Percentage solved

80

60

40

20

0
0.01

0.1

1

10

100

1000

CPU Time

Figure 21: Percentage solved problems increasing time evaluating scalability performance Storage domain.

Although DCK effective, found interesting properties it. learned operator tree
compact succeeds selecting GO-IN action normally marked helpful
action.
4.2.13 HOUGHTFUL ETAILS
domain models version solitaire card game, cards visible one
turn card talon rather 3 cards time. original version, goal
game place cards ascending order corresponding suit stacks (home deck).
available random problem generator domain. Therefore, used bootstrap
problem distribution given learning track IPC-2008. set contains problems
four suits, card seven suit. test phase used 30 problems
test distribution learning IPC-2008. largest problem domain full set
standard card game.
ROLLER solves 12 problems, three fewer GR - HA . However, ROLLER - BFS ROLLER BFS - HA better number solved problems non-learning approaches. domain,
use DCK lookahead construction combined FF heuristic makes search process
robust policy mistakes. ROLLER - BFS - HA solves 23, three LAMA. Figure 22
shows percentage solved problems increasing CPU time.
BFS-BnB algorithm generating training examples able solve 12 30
problems bootstrap problem distribution. believe different bootstrap distribution smaller problems would generate accurate DCK. Additionally, even though DCK
803

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

thoughtful domain
100
ROLLER
ROLLER-BFS
ROLLER-BFS-HA
FF
LAMA-first

Percentage solved

80

60

40

20

0
0.1

1

10
CPU Time

100

1000

Figure 22: Percentage solved problems increasing time evaluating scalability performance Thoughtful domain.

lookahead strategies achieve good results, learning accurate decision trees complex
many classes (20 operators particular domain) many arguments
predicates background knowledge (up 6 parameters operator col-to-home 7
parameters operator col-to-home-b).
4.2.14 TPP ETAILS
TPP stands Traveling Purchase Problem, generalization Traveling Salesman
Problem. Tasks domain consist selecting subset markets satisfy demand
set goods. selection markets try optimize routing purchasing
costs goods. STRIPS version, graph connects markets equal costs
arcs. Nevertheless, domain still interesting difficult planners scale
increasing number goods, markets trucks. training set consists thirty problems
number goods, trucks depots varying one three load levels five
six. test set consists thirty problems used planner evaluation IPC-2006.
largest problem set 20 goods, 8 trucks, 8 markets load level six.
ROLLER , GR - HA DF - HA solved 30 problems test set, ROLLER performs faster
two, achieving similar plan lengths. Besides, ROLLER outperforms rest
planners two orders magnitude faster FF. main reason overwhelming
branching factor large problems together fact FF heuristic falls big plateaus
domain. Greedy (depth-first) approaches perform better avoid effect
plateaus. Additionally, ROLLER achieved competitive quality scores average plan length
first solution anytime evaluation. ROLLER - BFS ROLLER - BFS - HA got bad results

804

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

domain imprecision FF heuristic. Figure 23 shows percentage
solved problems increasing CPU time.
tpp domain
100

Percentage solved

80

60

40

20
ROLLER
ROLLER-BFS
ROLLER-BFS-HA
FF
LAMA-first
0
0.01

0.1

1

10

100

1000

CPU Time

Figure 23: Percentage solved problems increasing time evaluating scalability performance TPP domain.
learned DCK compact useful reducing number evaluations, shown
ROLLER performance. instance, DRIVE binding tree recognizes perfectly truck
market need go market B already truck B handling goods
market. situations, state truck B helpful action DRIVE, meaning
truck B something deliver.

5. Lessons Learned IPC
IPC-2008 included specific track planning systems benefit learning. Thirteen systems
took part track including previous version ROLLER (De la Rosa et al., 2009) achieved
7th position. version upgrade original ROLLER system (De la Rosa et al.,
2008). first version proposed EHC-Sorted algorithm alternative H-Context Policy, effective many domains. competing version tried recommend ordering
applying actions relaxed plans. idea, although initially appealing, good
choice usefulness strongly depends fact relaxed plan contains right actions. competition completed analysis ROLLER performance diagnose
strengthen weak points. system resulting improvements ROLLER version
described article. One example ROLLER improvements results obtained
Thoughtful Matching Blocksworld domains. IPC-2008, ROLLER failed solve problems Thoughtful domain solved two problems Matching Blocksworld.
reported section 4, current version ROLLER solves 23 19 problems respectively
domains. addition, current version ROLLER outperforms LAMA FF Park805

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

ing domain one order magnitude. improvements ROLLER overcome limitations
version submitted IPC-2008 three aspects:
Robustness wrong DCK. Issues discussed Section 2 decisions introduce biases learning process making learning DCK complex task. fact, competitor
IPC-2008 able learn useful DCK domains. Furthermore, many domains
learned DCK damaged performance baseline planner. case
ROLLER . described paper, strengthened ROLLER wrong DCK
proposing two versions modified BFS algorithm combine learned DCK
numerical heuristic. combination DCK heuristic makes planning process robust imperfect and/or incorrectly learned knowledge. similar approach
followed winner best learner award, BTUSE W EDGE (Yoon et al., 2008).
Efficiency baseline. overall competition winner P BP (Gerevini, Saetti, & Vallati, 2009) portfolio state-of-the-art planners learns planner settings
best ones given planning domain. result, performance competitor
never worse performance state-of-the-art planner. IPC-2008 baseline performance ROLLER far competitive state-of-the art planners
ROLLER algorithms coded LISP. overcome weakness optimized
implementation ROLLER using C code outperformed IPC-2008 results
domains.
Definition significant training sets. Training examples extracted experience
collected solving problems training set. Therefore, quality training
examples depends quality problems used training. IPC-2008 training
problems fixed organizers and, many domains, large
ROLLER system extract useful DCK. paper created training problems using
random generators build useful training sets ROLLER system domain.
Selection training examples. Relational classifiers induce set rules/trees model
regularities training data. case forward state-space search planning
best-cost solutions problem may used training data, leads alternatives confuse learner. avoid this, training data cleaned
used learning algorithm. ranking solution selection proposed article
option give learner training data clearer regularities.
Additionally, ROLLER performed poorly Sokoban N-puzzle domains. Traditionally,
useful DCK domains form numeric functions, Manhattan distance,
provides lower-bound solution length. general, action policies inaccurate
domains, lack knowledge trajectory goals. Currently, still
unable learn useful DCK ROLLER domains. possible future direction introduce
goals subgoals (e.g. landmarks) helpful context aim capturing
knowledge.

6. Related Work
approach strongly inspired way Prodigy (Veloso et al., 1995) models DCK.
Prodigy architecture, action selection two-step process: first, Prodigy selects uninstan806

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

tiated operator apply, second, selects bindings operator. selections
guided DCK form control rules (Leckie & Zukerman, 1998; Minton, 1990).
returned idea two-step action selection allows us define learning
planning DCK standard classification task therefore solve learning task
off-the-shelf classification technique relational decision trees. Nevertheless, ROLLER
need distinguish among different kinds nodes Prodigy does, ROLLER performs
standard forward heuristic search state space search nodes
type.
Relational decision trees previously used learn action policies context
Relational Reinforcement Learning (RRL) (Dzeroski, De Raedt, & Blockeel, 1998). comparison
DCK learned ROLLER, RRL action policies present two limitations solving planning problems. First, RRL learned knowledge targeted given set goals, therefore
RRL cannot directly generalize learned knowledge different goals within given domain.
Second, since training examples RRL consist explicit representations states, RRL needs
add extra background knowledge learn effective policies domains recursive predicates
Blocksworld.
Previous works learning generalized policies (Martin & Geffner, 2004; Yoon et al., 2008)
succeed addressing two limitations RRL. First, introduce planning goals
training examples. way learned policy applies set goals domain. Second,
change representation language DCK predicate logic concept language.
language makes capturing decisions related recursive concepts easier. Alternatively, ROLLER
captures effective DCK domains like Blocksworld without varying representation language.
ROLLER implicitly encodes states terms set helpful actions state. result,
ROLLER benefit directly off-the-shelf relational classifiers work predicate logic.
fact makes learning times shorter resulting policies easier read.
Recently, techniques also developed improve performance heuristic
planners:
Learning Macro-actions (Botea, Enzenberger, Muller, & Schaeffer, 2005; Coles & Smith,
2007) combination two operators considered new domain operators order reduce search tree depth. However, benefit decreases number
new macro-actions added enlarge branching factor search tree causing utility problem (Minton, 1990). approaches overcome problem, applying
filters decide applicability macro-actions (Newton, Levine, Fox, & Long,
2007). Two versions work participated learning track IPC-2008, obtaining
third fourth place. One advantage macro-actions learned knowledge
exploited planner. Thus, approaches learn generalized policies could also
benefit macro-actions. Nevertheless, far know, combination
tried improving heuristic planners.
Learning domain-specific heuristic functions: approach (Yoon, Fern, & Givan, 2006;
Xu, Fern, & Yoon, 2007), state-generalized heuristic function obtained examples
solution plans. main drawback learning domain-specific heuristic functions
result learning algorithm difficult understand humans makes
verification learned knowledge difficult. hand, learned knowledge
easy combine existing domain-independent heuristics. slightly different approach
807

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

consists learning ranking function greedy search algorithms (Xu, Fern, & Yoon,
2009, 2010). step greedy search, current node expanded child node
highest rank selected current node. case, ranking function
iteratively estimated attempt cover set solution plans greedy algorithm.
Learning task decomposition: approach learns divide planning tasks given
domain smaller subtasks easier solve. Techniques reachability analysis
landmark extraction (Hoffmann, Porteous, & Sebastia, 2004) able compute intermediate states must reached satisfying goals. However, clear
systematically exploit knowledge build good problem decompositions. Vidal et al. (2010) consider optimization problem use specialized optimization
algorithm discover good decompositions.
general, system learns planning DCK deal ambiguity training
examples, given planning state may present many good actions. Trying learn DCK
selects one action other, inherently equal, complex learning problem. cope
ambiguous training data ROLLER created function ranks solutions aim learning
kind solutions. different approach followed Xu et al. (2010) generate
training examples partially ordered plans.

7. Conclusions Future Work
presented new technique reducing number node evaluations heuristic planning based learning exploiting generalized policies. technique defines process
learning generalized policies two-step classification builds domain-specific relational decision trees capture action selected different planning contexts. work,
planning contexts specified helpful actions state, pending goals static
predicates problem. Finally, explained exploit learned policies solve
classical planning problems, applying directly combining domain independent
heuristic lookahead strategy BFS algorithm. work contributes state-of-the-art
learning-based planning three ways:
1. Representation. propose new encoding generalized policies able capture
efficient DCK using predicate logic. opposed previous works represent generalized
policies predicate logic (Khardon, 1999), representation need extra background knowledge (support predicates) learn efficient policies Blocksworld domain.
Besides, encoding states set helpful actions frequently compact furthermore, set normally decreases search fewer goals left. Thus, process
matching DCK becomes faster search advances towards goals.
2. Learning. defined task learning generalized policy two-step standard
classification task. Thus, learn generalized policy off-the-shelf tool
building relational classifiers. Results paper obtained TILDE system (Blockeel & De Raedt, 1998), tool learning relational classifiers could
used. this, advances relational classification applied straightforward
manner ROLLER learn faster better planning DCK.
808

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

3. Planning. explained extract action ordering H-Context Policy
shown use ordering reduce node evaluations: (1) algorithm Depth-First H-Context Policy allows direct application H-Context policies;
(2) H-Context Policy Lookahead BFS, combines policy domainindependent heuristic within BFS algorithm. addition, included modified
version algorithm (ROLLER - BFS - HA) considers helpful successors order
reduce number evaluations domains helpful actions good.
Experimental results show approach improved scalability baseline heuristic
planners FF LAMA (winner IPC-2008) variety IPC domains. effect
evident domains learned DCK presents good quality, e.g. Blocksworld Parking.
domains direct application learned DCK saves large amounts node evaluations
achieving impressive scalability performance. Moreover, using learned DCK combination
domain-independent heuristic BFS algorithm achieves good quality solutions.
quality learned DCK poor, planning direct application policy fails
solve many problems, mainly largest ones difficult solve without reasonable
guide. Unfortunately, current mechanism quantifying quality learned DCK
evaluating set test problems. Therefore, good compromise solution combining
learned DCK domain-independent heuristics.
domains, DCK learned ROLLER presents poor quality helpful context
able represent concepts necessary order discriminate good bad
actions. problem frequently arises arguments good action correspond
problem goals static predicates. plan study refinements definition
helpful context achieve good DCK domains. One possible direction extending
helpful context subgoal information landmarks (Hoffmann et al., 2004)
relaxed plan. Moreover, use decision trees introduces important bias learning step.
Algorithms tree learning insert new query tree produces significant
information gain. However, domains information gain obtained
conjunction two queries. Finally, currently providing learner fixed
distribution training examples. near future, plan explore learner generate
convenient distribution training examples according target planning task proposed
Fuentetaja Borrajo (2006).

Acknowledgments
work partially supported Spanish MICIIN project TIN2008-06701-C03-03
regional CAM-UC3M project CCG08-UC3M/TIC-4141.

809

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

Appendix A. DCK Usefulness Results

Domains
Blocksworld (30)
Depots (22)
Gold-miner (30)
Matching-BW (30)
Parking (30)
Rovers (30)
Satellite (30)
Storage (30)
Thoughtful(30)
TPP (30)
Total

DEPH-FIRST
roller gr-ha df-ha
29.87
0.03
0.00
19.42
7.70
3.61
28.00
0.00
0.00
20.88
0.00
0.00
28.57
1.23
0.00
25.99 10.09
7.73
27.97
2.93
1.69
11.02
8.03
8.08
11.91 13.15
0.00
29.50 10.86 11.45
233.13 54.02 32.56

BEST-FIRST
roller-bfs lh-bfs
bfs
2.47
0.00
0.00
10.51
5.32
2.45
0.04
0.05
0.00
3.82
0.98
3.90
22.72
0.26
0.01
14.58
5.52
0.14
16.09
3.05
0.08
11.53 10.56
8.97
11.30
8.90
2.31
14.83
8.67
5.00
107.89 43.31 22.86

HELPFUL BEST-FIRST
roller-bfs-ha lh-bfs-ha bfs-ha
2.40
0.00
0.00
10.98
5.27
7.08
7.35
0.00
0.00
3.72
2.20
5.81
23.60
0.26
0.04
18.12
17.17
8.21
21.93
2.68
2.90
16.12
7.00
7.00
11.89
9.05
3.04
13.97
7.54
6.13
130.08
51.17
40.21

Table 9: Problems solved DCK usefulness evaluation.

Domains
Blocksworld (30)
Depots (22)
Gold-miner (30)
Matching-BW (30)
Parking (30)
Rovers (30)
Satellite (30)
Storage (30)
Thoughtful(30)
TPP (30)
Total

DEPH-FIRST
roller
gr-ha df-ha
29.83
0.06
0.00
8.82
8.21
3.02
19.78
0.00
0.00
11.53
0.00
0.00
21.53
8.20
0.01
21.54
26.34 25.51
28.03
17.36
9.58
13.43
8.02
8.00
6.89
12.40
0.00
25.46
27.92 23.75
186.84 108.51 69.87

BEST-FIRST
roller-bfs
lh-bfs
8.00
0.00
12.68
14.84
11.50
17.00
12.76
6.35
26.92
6.33
21.94
24.63
22.60
21.48
15.59
16.87
16.56
13.35
13.94
22.04
162.49 142.89

bfs
0.00
12.37
15.41
13.84
6.14
10.75
14.64
19.23
10.60
8.71
111.69

HELPFUL BEST-FIRST
roller-bfs-ha lh-bfs-ha
bfs-ha
8.00
0.00
0.00
13.20
16.06
19.97
16.67
0.00
0.00
17.21
9.39
16.54
26.92
6.33
8.18
25.71
26.32
29.63
27.60
22.31
22.42
15.66
8.59
9.31
19.48
14.91
11.75
16.20
24.36
13.88
186.65
128.27 132.35

Table 10: Quality scores DCK usefulness evaluation.

References
Bacchus, F., & Kabanza, F. (2000). Using temporal logics express search control knowledge
planning. Artificial Intelligence, 116(1-2), 123191.
Biba, J., Saveant, P., Schoenauer, M., & Vidal, V. (2010). evolutionary metaheuristic based
state decomposition domain-independent satisficing planning. Proceedings 20th
International Conference Automated Planning Scheduling (ICAPS10) Toronto, ON,
Canada. AAAI Press.
Blockeel, H., & De Raedt, L. (1998). Top-down induction first-order logical decision trees.
Artificial Intelligence, 101(1-2), 285297.
810

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

Bonet, B., Loerincs, G., & Geffner, H. (1997). robust fast action selection mechanism
planning. Proceedings American Association Advancement Artificial
Intelligence Conference (AAAI), pp. 714719. MIT Press.
Botea, A., Enzenberger, M., Muller, M., & Schaeffer, J. (2005). Macro-FF: Improving AI planning
automatically learned macro-operators. Journal Artificial Intelligence Research, 24,
581621.
Coles, A., & Smith, A. (2007). Marvin: heuristic search planner online macro-action learning. Journal Artificial Intelligence Research, 28, 119156.
De la Rosa, T., Jimenez, S., & Borrajo, D. (2008). Learning relational decision trees guiding heuristic planning. International Conference Automated Planning Scheduling
(ICAPS).
De la Rosa, T., Jimenez, S., Garca-Duran, R., Fernandez, F., Garca-Olaya, A., & Borrajo, D.
(2009). Three relational learning approaches lookahead heuristic planning. Working
Notes ICAPS 2009 Workshop Planning Learning, pp. 3744.
De Raedt, L. (2008). Logical Relational Learning. Springer, Berlin Heidelberg.
Doherty, P., & Kvarnstrom, J. (2001). Talplanner: temporal logic based planner. AI Magazine,
22(3), 95102.
Dzeroski, S., De Raedt, L., & Blockeel, H. (1998). Relational reinforcement learning. International Workshop ILP, pp. 1122.
Emde, W., & Wettschereck, D. (1996). Relational instance-based learning. Proceedings
13th Conference Machine Learning, pp. 122130.
Florez, J. E., Garca, J., Torralba, A., Linares, C., Garca-Olaya, A., & Borrajo, D. (2010). Timiplan: application solve multimodal transportation problems. Proceedings SPARK,
Scheduling Planning Applications workshop, ICAPS10.
Fuentetaja, R., & Borrajo, D. (2006). Improving control-knowledge acquisition planning
active learning. ECML, Berlin, Germany, Vol. 4212, pp. 138149.
Gerevini, A., Saetti, A., & Vallati, M. (2009). automatically configurable portfolio-based planner
macro-actions: Pbp. Proceedings 19th International Conference Automated
Planning Scheduling, pp. 191199 Thessaloniki, Greece.
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation heuristic
search. Journal Artificial Intelligence Research, 14, 253302.
Hoffmann, J., Porteous, J., & Sebastia, L. (2004). Ordered landmarks planning. Journal
Artificial Intelligence Research, 22.
Khardon, R. (1999). Learning action strategies planning domains. Artificial Intelligence, 113,
125148.
811

fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO

Leckie, C., & Zukerman, I. (1998). Inductive learning search control rules planning. Artificial
Intelligence, 101(12), 6398.
Martin, M., & Geffner, H. (2000). Learning generalized policies planning using concept languages. International Conference Artificial Intelligence Planning Systems, AIPS00.
Martin, M., & Geffner, H. (2004). Learning generalized policies planning examples using
concept languages. Appl. Intell, 20, 919.
Mcallester, D., & Givan, R. (1989). Taxonomic syntax first order inference. Journal ACM,
40, 289300.
McDermott, D. (1996). heuristic estimator means-ends analysis planning. Proceedings
3rd Conference Artificial Intelligence Planning Systems (AIPS), pp. 142149. AAAI
Press.
Minton, S. (1990). Quantitative results concerning utility explanation-based learning. Artif.
Intell., 42(2-3), 363391.
Muggleton, S. (1995). Inverse entailment progol. New Generation Computing, 13, 245286.
Muggleton, S., & De Raedt, L. (1994). Inductive logic programming: Theory methods. Journal
Logic Programming, 19, 629679.
Nau, D., Au, T.-C., Ilghami, O., Kuter, U., Murdock, W., Wu, D., & Yaman, F. (2003). SHOP2:
HTN planning system. Journal Artificial Intelligence Research, 20, 379404.
Newton, M. A. H., Levine, J., Fox, M., & Long, D. (2007). Learning macro-actions arbitrary
planners domains. Proceedings 17th International Conference Automated
Planning Scheduling (ICAPS).
Quinlan, J. (1986). Induction decision trees. Machine Learning, 1, 81106.
Richter, S., & Westphal, M. (2010). LAMA planner: Guiding cost-based anytime planning
landmarks. Journal Artificial Intelligence Research, 39, 127177.
Roger, G., & Helmert, M. (2010). more, merrier: Combining heuristic estimators satisficing planning. Proceedings 20th International Conference Automated Planning
Scheduling (ICAPS), pp. 246249.
Veloso, M., Carbonell, J., Perez, A., Borrajo, D., Fink, E., & Blythe, J. (1995). Integrating planning
learning: PRODIGY architecture. JETAI, 7(1), 81120.
Vidal, V. (2004). lookahead strategy heuristic search planning. Proceedings 14th
International Conference Automated Planning Scheduling (ICAPS 2004), Whistler,
British Columbia, Canada, pp. 150160.
Xu, Y., Fern, A., & Yoon, S. W. (2007). Discriminative learning beam-search heuristics
planning. IJCAI 2007, Proceedings 20th IJCAI, pp. 20412046.
812

fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES

Xu, Y., Fern, A., & Yoon, S. (2009). Learning linear ranking functions beam search
application planning. Journal Machine Learning Research, 10, 15711610.
Xu, Y., Fern, A., & Yoon, S. (2010). Iterative learning weighted rule sets greedy search.
Proceedings 20th International Conference Automated Planning Scheduling
(ICAPS) Toronto, Canada.
Yoon, S., Fern, A., & Givan, R. (2006). Learning heuristic functions relaxed plans. Proceedings 16th International Conference Automated Planning Scheduling (ICAPS).
Yoon, S., Fern, A., & Givan, R. (2007). Using learned policies heuristic-search planning.
Proceedings 20th IJCAI.
Yoon, S., Fern, A., & Givan, R. (2008). Learning control knowledge forward search planning.
J. Mach. Learn. Res., 9, 683718.
Zimmerman, T., & Kambhampati, S. (2003). Learning-assisted automated planning: looking back,
taking stock, going forward. AI Magazine, 24, 73 96.

813

fiJournal Artificial Intelligence Research 40 (2011) 305-351

Submitted 07/10; published 01/11

Multimode Control Attacks Elections
Piotr Faliszewski

faliszew@agh.edu.pl

Department Computer Science
AGH University Science Technology
Krakow, Poland

Edith Hemaspaandra

eh@cs.rit.edu

Department Computer Science
Rochester Institute Technology
Rochester, NY 14623 USA

Lane A. Hemaspaandra

lane@cs.rochester.edu

Department Computer Science
University Rochester
Rochester, NY 14627 USA

Abstract
1992, Bartholdi, Tovey, Trick opened study control attacks elections
attempts improve election outcome actions adding/deleting candidates
voters. work led many results algorithms used find attacks
elections complexity-theoretic hardness results used shields
attacks. However, work line assumed attacker employs
single type attack. paper, model study case attacker
launches multipronged (i.e., multimode) attack. realistically capture
richness real-life settings. example, attacker might simultaneously try suppress
voters, attract new voters election, introduce spoiler candidate.
model provides unified framework varied attacks. constructing polynomialtime multiprong attack algorithms prove various election systems even
concerted, flexible attacks perfectly planned deterministic polynomial time.

1. Introduction
Elections central model collective decision-making: Actors (voters) preferences
among alternatives (candidates) input election rule winner (or winners
case ties) declared rule. Bartholdi, Orlin, Tovey, Trick initiated line
research whose goal protect elections various attacking actions intended skew
elections results. Bartholdi, Orlin, Tovey, Tricks strategy achieving goal
show various election systems attacking actions, even seeing whether
given set votes attack possible NP-complete. papers (Bartholdi,
Tovey, & Trick, 1989a; Bartholdi & Orlin, 1991; Bartholdi, Tovey, & Trick, 1992) consider
actions voter manipulation (i.e., situations voter misrepresents
vote obtain goal) various types election control (i.e., situations
attacker capable modifying structure election, e.g., adding deleting
either voters candidates). Since then, many researchers extended Bartholdi, Orlin,
Tovey, Tricks work providing new models, new results, new perspectives.
c
2011
AI Access Foundation. rights reserved.

fiFaliszewski, Hemaspaandra, & Hemaspaandra

best knowledge, one considered situation
attacker combines multiple standard attack types single attacklet us call
multipronged (or multimode) attack.
Studying multipronged control step direction realistically modeling
real-life scenarios. Certainly, real-life settings attacker would voluntarily limit
single type attack rather would use available means
reaching goal. example, attacker interested candidate p winning
might, time, intimidate ps dangerous competitors would
withdraw election, encourage voters support p show vote.
paper study complexity multipronged control attacks.1
Given type multiprong control, seek analyze complexity. particular,
try show either one compute polynomial time optimal attack
control type, even recognizing existence attack NP-hard. particularly
interesting ask complexity multipronged attack whose components
efficient algorithms. interested whether combined attack (a) becomes
computationally hard, (b) still polynomial-time algorithm. Regarding (a) case,
give example natural election system displays behavior. papers core
work studies (b) case shows even attacks multiple prongs many
cases planned perfect efficiency. results yield immediate consequences
individual efficient attack algorithms prong, allow compact
presentation results compact proofs. go beyond that: show
interactions prongs managed without cost move beyond
polynomial time.
papers organization follows. Section 2 discuss relevant literature.
Section 3 present standard model elections describe relevant voting systems.
Section 4 introduce multiprong control, provide initial results, show existing
immunity, vulnerability, resistance results interact model. Section 5
provide complexity analysis candidate voter control maximin elections, showing
multiprong control useful so. Section 6 consider fixed-parameter complexity multiprong control, using parameter number candidates. Section 7
provides conclusions open problems. appendix, show maximin
interesting relation Dodgson elections: candidate whose Dodgson score
m2 times Dodgson winner(s) maximin winner.

2. Related Work
Since seminal paper Bartholdi et al. (1992), much research dedicated
studying complexity control elections. Bartholdi et al. (1992) considered constructive control only, i.e., scenarios goal attacker ensure candidates
victory. Hemaspaandra, Hemaspaandra, Rothe (2007) extended work destructive case, i.e., scenarios goal prevent someone winning.
central elusive goal control research finding natural election system (with
polynomial-time winner algorithm) resistant standard types con1. fact, framework multiprong control includes unpriced bribery Faliszewski, Hemaspaandra,
Hemaspaandra (2009a), extended include manipulation.

306

fiMultimode Control Attacks Elections

trol, i.e., types control NP-hard. Hemaspaandra, Hemaspaandra,
Rothe (2009) showed exist highly resistant artificial election systems. Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2009a) showed natural
system known Copeland voting far goal mentioned above.
Erdelyi, Nowak, Rothe (2009) showed system even resistances
Copeland, slightly nonstandard voter model (see Baumeister, Erdelyi, Hemaspaandra, Hemaspaandra, & Rothe, 2010, discussion Erdelyi, Piras, & Rothe, 2010b,
2010a; Menton, 2010, related follow-up work).
Recently, researchers also started focusing parameterized complexity control
elections. Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2009a) provided several
fixed-parameter tractability results. Betzler Uhlmann (2009) Liu, Feng, Zhu,
Luan (2009) showed so-called W[1]- W[2]-hardness results control various voting rules. response conference version (Faliszewski, Hemaspaandra, & Hemaspaandra, 2009b) present paper, Liu Zhu (2010) conducted parameterized-complexity
study control maximin elections.
Going somewhat different direction, Meir, Procaccia, Rosenschein, Zohar (2008)
bridged notions constructive destructive control considering utility functions,
model obtained control results multiwinner elections. multiwinner elections
goal elect whole group people (consider, e.g., parliamentary elections) rather
single person. Elkind, Faliszewski, Slinko (2010a) Maudet, Lang,
Chevaleyre, Monnot (2010) considered two types problems related control
adding candidates case known voters would rank added
candidates.
Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2011) Brandt, Brill,
Hemaspaandra, Hemaspaandra (2010) studied control (and manipulation
bribery) so-called single-peaked domains, model overall electorate behavior
political science.
growing body work manipulation regards frequency
(non)hardness election problems (see, e.g., Conitzer & Sandholm, 2006; Friedgut, Kalai,
& Nisan, 2008; Dobzinski & Procaccia, 2008; Xia & Conitzer, 2008b, 2008a; Walsh, 2009;
Isaksson, Kindler, & Mossel, 2010). work studies whether given NP-hard election
problem (to date manipulation/winner problems studied, control problems) often solved practice (assuming distribution votes). (One however
keep mind polynomial-time algorithm solves NP-hard problem extremely frequentlyif errs sparse set formal complexity-theoretic sense
termthen P = NP, Schoning, 1986.) frequency results course
relevant ones goal protect elections manipulative actions, although
NP-hardness important step, first step towards truly broad, satisfying
security. However, paper typically take role attacker design control
algorithms fast instances.
Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2009b) Faliszewski, Hemaspaandra, Hemaspaandra (2010b) provide overview complexity-of-election
issues.
307

fiFaliszewski, Hemaspaandra, & Hemaspaandra

3. Preliminaries
section covers preliminaries elections computational complexity.
3.1 Elections
election pair (C, V ), C = {c1 , . . . , cm } set candidates V =
(v1 , . . . , vn ) collection voters. voter vi represented preference
list.2 example, three candidates, c1 , c2 , c3 , voter likes c1 most,
c2 , c3 would preference list c1 > c2 > c3 .3 Given election E = (C, V ),
NE (ci , cj ), ci , cj C 6= j, denote number voters V prefer
ci cj . adopt following convention specifying preference lists.
Convention 3.1. Listing set candidates item preference list means
listing members set increasing lexicographic order (with respect


candidates names), listing means listing members decreasing
lexicographic order (with respect candidates names).
Example 3.2. Let us give quick example convention. C = {Bob, Carol, Ted,
Alice} = {Alice, Ted, Bob}, Carol > shorthand Carol > Alice > Bob >


Ted, Carol > shorthand Carol > Ted > Bob > Alice.4
Note model used paper, assume person trying
attack election knows votes, V , are. standard model
computational studies attacks elections ever since seminal work Bartholdi
et al. (1989a, 1992) Bartholdi Orlin (1991). However, worth noting
abstract model strains connection real world. Regarding proving
lower bounds, NP-hardness results, results model actually stronger: One
showing even given full access votes, V , attacker still NP-hard
task. hand, build polynomial-time attack algorithms model,
algorithms benefiting model letting know votes are.
natural model vary situation, one always keep mind
indeed abstract model, real world itself. However, many settings,
unreasonable assume attacker might strong information
votes. information might come polls, might come door-to-door
telephone canvassing, might come voter registration contribution records,
2. also assume voter unique name. However, election systems consider
hereexcept election system Theorem 4.12are oblivious particular voter names
order votes.
3. Preference lists also called preference orders, paper use two terms interchangeably.
4. constructions use convention, using variable names objectssuch
{b1 , . . . , b3k } p onthat used candidate sets elections output
reduction. However, since election part input set candidates (which named),
actual reductions assigning name strings objects, ordering
discussed well-defined easily carried reductions. fact, context
reductions, actual (string) values bi probably already part input reduction.
(We chosen lexicographic order simply polynomial-time reductions sort things it,
reverse, without problem.)

308

fiMultimode Control Attacks Elections

might come (in intimate, human elections, votes whether one
course-based exam-based M.S. degree ones department) great familiarity
attacker voters, might come attacker vote collector.
election system mapping given election (C, V ) outputs set W , satisfying
W C, called winners election.5
focus following five voting systems: plurality, Copeland, maximin, approval,
Condorcet. (However, Section 6 appendix take detour
systems.) plurality, Copeland, maximin, approval assigns points
candidates elects receive points. Let E = (C, V ) election,
C = {c1 , . . . , cm } V = (v1 , . . . , vn ). plurality, candidate receives single
point voter ranks first. maximin, score candidate ci E
defined mincj C{ci } NE (ci , cj ). rational , 0 1, Copeland candidate
ci receives 1 point candidate cj , j 6= i, NE (ci , cj ) > NE (cj , ci )
points candidate cj , j 6= i, NE (ci , cj ) = NE (cj , ci ). is, parameter
describes value ties head-to-head majority contests. approval, instead
preference lists voters ballot 0-1 vector, entry denotes whether voter
approves corresponding candidate (gives corresponding candidate point).
example, vector (1, 0, 0, 1) means voter approves first fourth candidates,
second third. use scoreE (ci ) denote score candidate ci
election E (the particular election system used always clear context).
candidate c Condorcet winner election E = (C, V ) candidate
C holds NE (c, c0 ) > NE (c0 , c). Condorcet voting election system
winner set is, definition, exactly set Condorcet winners. follows
definition election one Condorcet winner. every election
Condorcet winner. However, notion election allows outcomes one
wins, electing Condorcet winner one otherwise winner
legal election system.

c0

5. Readers social choice background may wonder forbid case W = ,
typically done social choice framings elections. Briefly put, allowing possibility W =
standard model computational studies elections, starting seminal papers
Bartholdi, Orlin, Tovey, Trick. retaining model, results better compared
existing computational results attacks elections. fact, recent (admittedly computationally
oriented) textbook Shoham Leyton-Brown (2009, Def. 9.2.2) treats definition social choice
correspondence allowing subset candidates, including empty set (in contrast, social
choice papers, notion social choice correspondence routinely definition excludes possibility
winners). Although follow model allowing empty outcome standard
computational model allows comparison existing results, mention passing find
model, merits, attractive one, although certainly matter taste, familiarity,
comfort. model avoids building special-case exception definition allows one discuss
zero-candidates elections reason one wants to. importantly, many natural election
systems might winners. Examples include threshold election systems, including majority-rule
elections election systems often used see whether anyoneby exceeding certain percentage
approval votes group expert sports writers, instancemerits induction sports Hall
Fame year. Condorcet voting (to defined later), seminal control-of-elections paper
Bartholdi et al. (1992) treated election system, also empty winner set.

309

fiFaliszewski, Hemaspaandra, & Hemaspaandra

3.2 Computational Complexity
use standard notions complexity theory, presented, e.g., textbook Papadimitriou (1994). assume reader familiar complexity classes P
NP, polynomial-time many-one reductions, notions NP-hardness NPcompleteness. N denote {0, 1, 2, . . .}.
NP-hardness proofs paper follow reduction well-known
NP-complete problem exact cover 3-sets, known short X3C (see, e.g., Garey &
Johnson, 1979). X3C given pair (B, S), B = {b1 , . . . , b3k } set 3k
elements = {S1 , . . . , Sn } set 3-subsets B, ask whether
subset 0 exactly k elements union exactly B. call set
0 exact cover B.
Section 6, consider fixed-parameter complexity multiprong control.
idea fixed-parameter complexity measure complexity given decision problem
respect instance size (as standard complexity theory)
parameter input (in case, number candidates involved). problem
said fixed-parameter tractable, i.e., belong complexity class FPT,
standard require problem solved algorithm running time
f (j)nO(1) , n size encoding given instance, j value
parameter instance, f function. Note f
polynomially bounded even computable. However, FPT claims paper, f
computable function. is, algorithms actually achieve so-called strongly uniform
fixed-parameter tractability. point readers interested parameterized complexity to,
example, recent book Niedermeier (2006).

4. Control Multiprong Control
section introduce multiprong control, is, control types combine several
standard types control. first provide definition, proceed analyzing general
properties multiprong control, consider multiprong control election systems
complexity single-prong control already established, finally give
example election system multiprong control becomes harder
constituent prongs (assuming P 6= NP). conclude section summary
main contributions.
4.1 Definition
consider combinations control adding/deleting candidates/voters6 bribing
voters. Traditionally, bribery considered type control fits model
naturally strengthens results.
discussing control problems, must clear whether goal
attacker make preferred candidate winner, make
preferred candidate winner. clear this, standard use
term unique-winner model model goal make ones preferred
6. control types, defined Bartholdi et al. (1992) refined Hemaspaandra et al. (2007), regard
various types partitioning candidates voters.

310

fiMultimode Control Attacks Elections

candidate one winner, use term nonunique-winner model
approach goal make ones preferred candidate winner. (Note
exactly one person wins, certainly considered satisfied
control action nonunique-winner model. nonunique model name merely
means requiring winners unique.)
destructive cases are, nonunique-winner model, blocking
ones despised candidate unique winner,7 unique-winner model,
blocking ones despised candidate winner. take unique-winner model
default paper, common model studies control.
Definition 4.1. Let E election system. unique-winner,8 constructive EAC+DC+AV+DV+BV control problem given:
(a) two disjoint sets candidates, C A,
(b) two disjoint collections voters, V W , containing voters preference lists
C A,
(c) preferred candidate p C,
(d) five nonnegative integers, kAC , kDC , kAV , kDV , kBV .
ask whether possible find two sets, A0 C 0 C, two subcollections
voters, V 0 V W 0 W , that:
(e) possible ensure p unique winner E election ((C C 0 ) A0 , (V
V 0 ) W 0 ) via changing preference orders (i.e., bribing) kBV voters
(V V 0 ) W 0 ,
(f ) p
/ C 0 ,
(g) kA0 k kAC , kC 0 k kDC , kW 0 k kAV , kV 0 k kDV .
unique-winner, destructive variant problem, replace item (e) with:
possible ensure p unique winner E election ((C C 0 )A0 , (V V 0 )W 0 )
via changing preference orders kBV voters (V V 0 ) W 0 . (In addition,
destructive variant refer p despised candidate rather preferred
candidate, often denote d.)
Table 1 summarizes informal English notation used definition,
information easily available reader refer back to.
phrase AC+DC+AV+DV+BV problem name corresponds four
standard types control: adding candidates (AC), deleting candidates (DC), adding voters
(AV), deleting voters (DV), (unpriced) bribery (BV); refer five types
control basic types control. remind reader traditionally
7. often use phrase unique winner, did. reason write unique winner
rather unique winner avoid impression election necessarily (unique)
winner.
8. One straightforwardly adapt definition nonunique-winner model.

311

fiFaliszewski, Hemaspaandra, & Hemaspaandra

Notation
AC
DC
AV
DV
BV
C

V
W
kAC
kDC
kAV
kDV
kBV
p


Meaning
Control adding candidates.
Control deleting candidates.
Control adding voters.
Control deleting voters.
Control bribing voters.
set initial candidates election.
set additional candidates control agent may introduce.
collection initial voters election.
collection additional voters control agent may introduce.
bound number candidates added AC control.
bound number candidates deleted DC control.
bound number voters added AV control.
bound number voters deleted DV control.
bound number voters bribed BV control.
preferred candidate (the constructive control goal ensure p
unique winner).
despised candidate (the destructive control goal ensure
unique winner).

Table 1: Notations Definition 4.1 used frequently elsewhere.

bribery type control call basic type control sake
uniformity throughout rest paper consider such.
choose basic types, essentially
collection focus, term handy one use indicate them.
focused particular ones largely find highly attractive.
various partition control types appeared original paper control, quite
interesting, always seemed less natural us adding/deleting voters/candidates.
Bribery us also quite compellingly natural. attack known manipulation
included us among basic types, without doubt natural important
type attack elections, conclusion discuss briefly, commend
reader issue studying manipulation additional prong.
Instead considering AC, DC, AV, DV, BV, often interested
subset consider special cases AC+DC+AV+DV+BV problem.
example, write DC+AV refer variant AC+DC+AV+DV+BV problem
deleting candidates adding voters allowed. part model
assume variant, parameters relevant prongs part
input. So, example, DC+AV would kDC , kAV , C, V , W , p (only)
parts input. missing parts (e.g., DC+AV, missing parts A, kAC ,
kDV , kBV ) treated obvious way evaluating formulas Definition 4.1,
namely, missing sets treated missing constants treated 0. name
single type control, effect degenerate one standard control problems.
312

fiMultimode Control Attacks Elections

reader may naturally wonder order prongs multi-prong attack
occur. Note part (e) Definition 4.1 quietly setting order. However, almost
order interactions uninteresting (unless attacker idiotic). example,
definition allow one bribe voters one deleting, would
pointless anyway, interesting restriction attacker. Similarly,
definition allow one add voter immediately delete it, again,
take even one successful attack away attacker. Indeed, interesting
order interaction consider whether one bribe added voters, whether one
bribe voters originally election. One could argue either way,
one wanted avoid focusing one other, one could analyze everything ways.
However, definition embraces model even added voters bribed.
Note model favorable attacker. One referee commented
would unreasonable give attackers flexibility multiple attacks deny
freedom control order attacks. keeping spirit comment,
definition resolves order issue way favorable attacker,
way biased attacker. However, completeness mention
possible someperhaps highly artificialsystems might different attack
complexities model added voters cannot bribed compared model
added voters bribed.
least one way could define multiprong control. model
definition called separate-resource model, extent
use basic type control bounded separately. shared-resource model
one pool action allowances must allocated among allowed control types (so
definition would replace kAC , kDC , kAV , kDV single value, k,
require kC 0 k + kD0 k + kV 0 k + kW 0 k + the-number -of -bribed -voters k). Although one
could make various arguments model appropriate, computational
complexity related.
Theorem 4.2. polynomial-time algorithm given variant multiprong
control separate-resource model one shared-resource model
well.
Proof. Let E election system. describe idea proof example
constructive E-AC+AV problem. idea straightforwardly generalizes
set allowed control actions (complexity-theory savvy readers quickly see we,
essence, give disjunctive truth-table reduction).
given instance constructive E-AC+AV problem shared-resource
model, k limit sum number candidates voters may
add. Given polynomial-time algorithm separate-resource variant problem,
solve using following method. (If k > kAk + kW k set k = kAk + kW k.)
form sequence I0 , . . . , Ik instances separate-resource variant problem,
I` , 0 ` k, identical I, except allowed add `
candidates k ` voters. accept least one I` yes instance
separate-resource, constructive E-AC+AV problem. straightforward see
algorithm correct runs polynomial time.
313

fiFaliszewski, Hemaspaandra, & Hemaspaandra

would interesting consider variant shared-resource model various actions come different costs (e.g., adding candidate c0 might much
expensiveor difficultthan adding candidate c00 ). approach would
close spirit priced bribery Faliszewski, Hemaspaandra, Hemaspaandra (2009a).
Analysis priced control beyond scope current paper.
4.2 Susceptibility, Immunity, Vulnerability, Resistance
standard election-control (and election-bribery) literature, consider vulnerability, immunity, susceptibility, resistance control. Let E election system
let C type control.
say E susceptible constructive C control scenario
effectuating C makes someone become unique winner E election E. say
E susceptible destructive C control scenario effectuating C makes
someone stop unique winner E election E.
E immune constructive (respectively, destructive) C control E susceptible
constructive (respectively, destructive) C control.
say E vulnerable constructive (respectively, destructive) C control E susceptible constructive (respectively, destructive) C control polynomial-time
algorithm decides constructive (respectively, destructive) E-C problem. Actually,
papers vulnerability algorithms/proofs go polynomial time
produce, make implicitly clear produce, successful control action.
case even achieving so-called certifiable vulnerability Hemaspaandra et al.
(2007).
E resistant constructive (respectively, destructive) C control E susceptible
(respectively, destructive) C control constructive (respectively, destructive) E-C
problem NP-hard.
move theorems, mention two important points put
notions context. Vulnerability (within susceptible settings) polynomial-time
recognition inputs successful attacks (and those, noted
above, actually paper produce attacks), proportion inputs
attacks succeed (however, see comments references earlier paper
work studying frequency hardness issues). Also, type multiprong control
that, example, one on-its-own immune prong on-their-own vulnerable
prongs, prove immunity hold. (In cases vulnerability
hold, cases resistance might hold.) However, portion
input universe allows changes immune-on-its-own prong
prongs, one quickly (assuming winner problem given election system
polynomial-time problem) recognize one subspace inputs
determine whether one achieve ones goal (since due immunity dead
prongthat prong cannot raise us failure success).
next theorems describe multiprong control problems inherit susceptibility, immunity, vulnerability, resistance basic control types
built from. (We often write (destructive) rather (respectively, destructive),
respectively clear context.)

314

fiMultimode Control Attacks Elections

Theorem 4.3. Let E election system let C1 + + Ck variant multiprong
control (so 1 k 5 Ci basic control type). E susceptible constructive
(destructive) C1 + +Ck control E susceptible least one constructive
(destructive) C1 , . . . , Ck control.
Proof. direction trivial: attacker always choose use type
control E susceptible. direction, hard see
input election C1 + + Ck action achieve
desired change (of creating removing unique-winnerhood p, depending
case), election (not necessarily input election) one
actions alone achieves desired change. essence, view control action
type C1 + + Ck sequence operations, operation one C1 , . . . , Ck
types, thatwhen executed ordertransform input election election
goal satisfied. Thus single operation within Aand operation one
types C1 , . . . , Ck transforms election E 0 goal satisfied
election E 00 goal satisfied.
immediately following corollary.
Corollary 4.4. Let E election system let C1 + + Ck variant multiprong
control (so 1 k 5 Ci basic control type). E immune constructive
(destructive) C1 + + Ck control i, 1 k, E immune
constructive (destructive) Ci control.
next theorem show given election system vulnerable basic
type control immune another basic type control, vulnerable
two types control combined. proof theorem straightforward, need
particularly careful vulnerabilities immunities behave quite unexpectedly.
example, might seem assume election system vulnerable
AV DV also vulnerable BV, bribing particular voter
viewed first deleting voter addingin placea voter
preference order required briber. (This assumes voter
among voters add, arguing susceptibility/immunity make
assumption.) However, simple election system vulnerable AV
DV control, immune BV control. system says election
E = (C, V ), C = {c1 , . . . , cm } V = (v1 , . . . , vn ), winner candidate ci
n 1 (mod m).9
Theorem 4.5. Let E election system let C1 + + Ck + D1 + + D` variant
multiprong control (so 1 k 5, 1 ` 5, Ci Di basic control
type) E vulnerable constructive (destructive) C1 + + Ck control
i, 1 `, E immune constructive (destructive) Di control.10 E vulnerable
C1 + + Ck + D1 + + D` control.
9. course, election system neutral; permuting names candidates, evaluating
elections winners, running winners inverse permutation change
outcome election.
10. certainly k + ` 5, since immunity vulnerability mutually exclusive.

315

fiFaliszewski, Hemaspaandra, & Hemaspaandra

Proof. give proof constructive case only. proof destructive
case analogous. Let E election system statement theorem let
instance constructive E-C1 + + Ck + D1 + + D` control, contains
election E = (C, V ), information specifics control actions implement,
goal ensure candidate p unique winner. Let us first consider
case BV among C1 , . . . , Ck , D1 , . . . D` .
Let us assume collection control actions types
C1 , . . . Ck , D1 , . . . , D` , applying actions E legal within
results election EC+D p unique winner. (We take empty p
unique winner E.) split two parts, AC AD , AC contains exactly
actions types C1 , . . . , Ck , AD contains exactly actions types D1 , . . . , D` .
Since BV among control actions, straightforward see possible
apply actions AC election E obtain election EC . (To see important
consider BV, assume BV among control types C1 , . . . , Ck AV
among control types D1 , . . . , D` . case, AC might include action bribes
voter added action AD .)
claim p unique winner EC . sake contradiction, let us assume
case (note implies p unique winner E).
apply control actions AD EC , reach exactly election EC+D , p unique
winner. Yet, contradiction, Corollary 4.4 E immune
D1 + + D` . is, scenario control actions type D1 + + D`
make candidate unique winner unique winner before.
Thus possible ensure p unique winner actions type C1 + + Ck
alone. chose arbitrarily, thus instance E-C1 + + Ck + D1 + + D`
control solved algorithm considers control actions type C1 + + Ck
only. proves E vulnerable C1 + + Ck + D1 + + D` control because,
assumed, vulnerable C1 + + Ck control.
remains prove theorem case BV among control actions.
case BV among control actions AV not, AV BV
group actions (i.e., either among Ci among Di s),
straightforward see proof still works. Similarly, BV among
Di AV among Ci s, proof works well. remaining case
allowed control types include BV AV, BV among Ci AV
among Di s.
last case, proof also follows general structure previous construction,
except take care one issue: possible AC includes bribery
voters added actions AD . (We use notation main
construction.) Let VBV collection voters AC requires bribe,
added AD . form collection A0C control actions identical AC , except
includes adding voters VBV , let A0D identical AD , except
longer includes adding voters VBV . Using A0C A0D instead AC
AD , straightforward show following: possible ensure p unique
winner instance legal action type C1 + + Ck + D1 + + D` , also
possible legal action type C1 + + Ck + AV, added voter
also bribed. Thus given instance E-C1 + + Ck + D1 + + D` solve
316

fiMultimode Control Attacks Elections

using following algorithm. Let W collection voters added within
let kAV limit number voters add.
1. Let min(kAV , kW k).
2. {0, 1, . . . , t} execute next two substeps.
(a) Form instance 0 identical I, except (arbitrarily chosen) voters
W added election.
(b) Run E-C1 + + Ck algorithm instance 0 accept does.
3. algorithm accepted yet, reject.
straightforward see algorithm correct and, since E vulnerable
C1 + + Ck , works polynomial time. completes proof theorem.
Theorem 4.6. Let E election system let C1 + + Ck variant multiprong
control (so 1 k 5 Ci basic control type). i, 1 k,
E resistant constructive (destructive) Ci control, E resistant constructive
(destructive) C1 + + Ck control.
Proof. Let Ci control type E resistant. Since E susceptible constructive (destructive) Ci control, follows Theorem 4.3 E susceptible constructive
(destructive) C1 + + Ck control. since E-Ci constructive (destructive) control
problem essentially (give take syntax) embedded subproblem E-C1 + + Ck
control problem, follows E resistant C1 + + Ck control.
combining results obtained far Section 4.2, obtain simple tool
allows us classify large number multiprong control problems based properties
prongs. theoremalong forthcoming Classification Rule A,
shows apply result well-behaved election systemsis central result
paper.
Theorem 4.7. Let E election system let C1 + + Ck variant multiprong
control (so 1 k 5 Ci basic control type), Ci , 1 k,
E resistant, vulnerable, immune constructive (destructive) Ci control.
i, 1 k, E resistant constructive (destructive) Ci control E
resistant constructive (destructive) C1 + + Ck control. Otherwise, i,
1 k, E immune constructive (destructive) Ci control (1 k),
immune constructive (destructive) C1 + + Ck control. Otherwise, E vulnerable
constructive (destructive) multiprong control consisting individual prongs
among Ci E vulnerable constructive (destructive) control, E
vulnerable constructive (destructive) C1 + + Ck control.
avoid confusion, stress throughout ones reading corollary,
one must either always use constructive case must always use destructive
caseone cannot mix match. Also, third otherwise really otherwise;
claim assumes first case (that least one resistance) hold.
317

fiFaliszewski, Hemaspaandra, & Hemaspaandra

vulnerability/resistance/immunity information five individual prongs
completely determine vulnerability/resistance/immunity holds 25 1
multiprong settings? would satisfying so. However, later results
paper show case, since prove two vulnerable prongs
combine yield resistance (Theorem 4.12) also combine yield vulnerability (e.g.,
Theorem 4.10). (It even plausible may exist cases two vulnerable prongs
combine yield multiprong case that, certainly susceptible due Theorem 4.3 (i.e.,
immunity impossible case), neither P NP-hard, i.e., neither vulnerable
resistant.)
However, every voting system certain common, nice property,
5 individual prongs vulnerability/resistance/immunity status mechanically read
25 1 multiprong results. nice property following.
Definition 4.8. say election system E constructive (destructive)
vulnerability-combining variant C1 + +Ck multiprong control (so 1 k 5
Ci basic control type) holds i, 1 k, E vulnerable
constructive (destructive) Ci control, E vulnerable constructive (destructive)
C1 + + Ck control.
systems constructive (destructive) vulnerability-combining, straightforward see Theorem 4.7 used read 25 1 multiprong cases, given
status five underlying prongs.
one practice establish system constructive (destructive)
vulnerability-combining? One could try brute force, looking collection
vulnerable prongs. However, better path follow. One look
vulnerable prongs together, prove (if happens case) yield vulnerability. Note successfully implies immediately vulnerability holds
every nonempty subset prongs. true follows following claim.
Proposition 4.9. Let E election system let C1 , . . . , Ck , 1 k 5, collection
basic control types. i, 1 k, E susceptible constructive (destructive)
Ci control, E vulnerable constructive (destructive) C1 + + Ck control,
nonempty subset K {C1 , . . . , Ck }, E vulnerable constructive (destructive)
multiprong control involving exactly prongs K.
Proof. Let notation statement proposition, let K
nonempty subset {C1 , . . . , Ck }. Theorem 4.3, E susceptible constructive (destructive) multiprong control constructive (destructive) control type consisting
exactly prongs K. Es vulnerability constructive (destructive) C1 + + Ck
control, polynomial-time algorithm constructive (destructive) multiprong control involving exactly prongs K: suffices use algorithm constructive
(destructive) C1 + + Ck multiprong control, bounds extent
nonoccurring prongs used set 0.
Motivated discussion Proposition 4.9, Sections 4.3 5
show plurality, Condorcet, Copeland (for rational , 0 1), approval,
318

fiMultimode Control Attacks Elections

maximin indeed constructive vulnerability-combining destructive vulnerabilitycombining. Thus systems analyzed 25 1 constructive cases
25 1 destructive cases multiprong control. Namely, constructive (destructive)
vulnerability-combining election system E variant C1 + + Ck , 1 k 5,
constructive (destructive) multiprong control i, 1 k, E either
resistant, vulnerable, immune constructive (destructive) Ci control, use
following simple rule (which refer back Classification Rule A) classify
constructive (destructive) C1 + + Ck multiprong control (note: correctness
third part classification vulnerability-combining property E
relied on):
1. E resistant least one control prongs, resistant whole
attack.
2. E immune prongs, immune whole attack.
3. neither holds, E vulnerable whole attack.
general, consider partition cases control paper. However, make
exception next example, shows even types control given
election system immune may prove useful multiprong control. constructive control
partition candidates (reminder: basic control type) ties-eliminate
model (PC-TE control type), given election E = (C, V ) preferred candidate
p C, ask whether possible find partition (C1 , C2 ) C (i.e., C1 C2 = C
C1 C2 = ) p winner following two-round election: first find
winner sets, W1 W2 , elections (C1 , V ) (C2 , V ). W1 (W2 ) contains
one candidate, set W1 = (W2 = ), since ties eliminate model.
candidates win election (W1 W2 , V ) winners overall two-stage
election.
Now, let us look constructive approval-AC+PC-TE control, (by definition, let
us say) first add new candidates perform partition action. consider
approval election two candidates, p c, p 50 approvals c 100.
also allowed add candidate c0 , 100 approvals. Note impossible
make p unique winner adding c0 . Exercising partition action alone
ensure ps victory either. However, combining AC PC-TE job. first
add c0 election partition candidates {p} {c, c0 } then, due
ties-eliminate rule, p becomes unique winner. rather interesting even though
approval immune constructive AC control, cases one apply AC
control open possibility effectively using types control.
example perhaps surprising light Theorem 4.5. essence, proof
theorem argue election system vulnerable basic control type
C immune basic control type D, also vulnerable control
type C + D. proved theorem showing safely disregard actions
type (assuming C include BV control type). example shows
proof approach would work considered PC-TE addition basic control
types.
319

fiFaliszewski, Hemaspaandra, & Hemaspaandra

4.3 Combining Vulnerabilities
previous section considered case separate prongs multiprong control
problem different computational properties, e.g., resistant, vulnerable, immune. section consider case election system
vulnerable prong separately, show vulnerabilities combine within
election systems control results obtained previous papers (see Table 5).
particular, next theorem show election systems considered
Bartholdi et al. (1992), Hemaspaandra et al. (2007), Faliszewski, Hemaspaandra,
Hemaspaandra, Rothe (2009a), constructive vulnerabilities AC, DC, AV, DV,
BV combine vulnerabilities, destructive vulnerabilities AC, DC, AV, DV,
BV combine vulnerabilities.11 Using (and additional discussion correctly
handle possibility P = NP), soon conclude election system
studied three papers constructive vulnerability-combining destructive
vulnerability-combining.
Theorem 4.10. (a) Plurality vulnerable constructive AV+DV+BV control
destructive AV+DV+BV control. (b) Condorcet approval vulnerable
AC+AV+DV+BV destructive control. (c) rational , 0 1, Copeland
vulnerable destructive AC+DC control.12
Proof. (a) Let us consider instance constructive plurality-AV+DV+BV control
want ensure candidate ps victory: enough add voters vote
p (or many allowed) then, loop, keep deleting voters vote
candidate p highest score, p candidate
highest score exceeded limit voters delete. Finally, loop, keep
bribing voters vote candidate p highest score vote p,
p candidate highest score exceeded limit voters
bribe. p becomes unique winner via procedure, accept. Otherwise reject.
omit straightforward proof destructive case.
(b) Let instance destructive Condorcet-AC+AV+DV+BV, goal
prevent candidate p Condorcet winner (we assume p Condorcet
winner control action performed). enough ensure candidate
c wins head-to-head contest p. algorithm works follows.
Let C set candidates originally election let set candidates
add (we take = allowed add candidates).
c (C A) {p} following:
1. Add many voters prefer c p possible.
11. Constructive bribery plurality constructive bribery approval considered Faliszewski, Hemaspaandra, Hemaspaandra (2009a) constructive destructive bribery Copeland
studied Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2009a). Theorem 4.10
wein effectgive polynomial-time algorithms destructive bribery plurality, approval,
Condorcet. Constructive Condorcet-BV NP-complete implicitly shown Faliszewski,
Hemaspaandra, Hemaspaandra, Rothe (2009a, Theorem 3.2).
12. Regarding types among AC, DC, AV, DV, BV mentioned part theorem,
plurality resistant constructive destructive AC DC, Condorcet approval immune
constructive AC destructive DC, rational , 0 1, Copeland resistant
five constructive basic types control destructive AV, DV, BV (see Table 5 references).

320

fiMultimode Control Attacks Elections

2. Delete many voters prefer p c possible.
3. Among remaining voters prefer p c, bribe many possible rank c
first.
actions c wins head-to-head contest p accept.
c (C A) {p} leads acceptance, reject. straightforward see
algorithm correct runs polynomial time. (We point enough add
single candidate, candidate c prevents p winning, happens
member A).
case approval, algorithm works similarly, except following differences:
add voters approve c p. delete voters approve p
c. remaining voter vi , still exceeded bribing limit, vi approves
p c, bribe vi reverse approvals p c. (Note
exceed bribing limit procedure, means voter approves p
also approves c thus p unique winner.) actions lead p
unique winner, accept. accept c (C A) {p}, reject.
(c) idea combine Copeland destructive-AC destructive-DC algorithms (Faliszewski, Hemaspaandra, Hemaspaandra, & Rothe, 2009a). give full
proof sake completeness.
Let us fix rational value , 0 1. Given election E candidate c
election, write scoreE (c) denote Copeland score c. Let instance
destructive Copeland -AC+DC control, election E = (C, V ),
add kAC spoiler candidates set A, delete kDC
candidates. goal ensure despised candidate C unique winner.
algorithm based following simple observation Faliszewski, Hemaspaandra,
Hemaspaandra, Rothe (2009a). candidate c C:
score(C,V ) (c) =

X

score({c,c0 },V ) (c).

c0 C{c}

goal prevent candidate unique winner. unique winner,
immediately accept. Otherwise, seek candidate c C ensure
cs score least high d. Thus c C following.
1. c A, kAC > 0, add c election (and c kAC = 0, proceed
next c).
2. long still add candidates, keep executing following operation:
candidate c0 value a(c0 ) = score({c,c0 },V ) (c)score({d,c0 },V ) (d)
positive, add candidate c00 A, a(c00 ) highest.
3. long still delete candidates, keep executing following operation:
candidate c0 C value r(c0 ) = score({d,c0 },V ) (d) score({c,c0 },V ) (c)
positive, delete candidate c00 C, r(c00 ) highest.
4. steps unique winner, accept.
321

fiFaliszewski, Hemaspaandra, & Hemaspaandra

accept c C A, reject.
straightforward see never delete candidate added. Also,
straightforward see algorithm works polynomial time, correct.
Correctness follows fact (a) main loop algorithm, dealing
candidate c C A, addition candidate deletion candidate
increases difference score c score much possible,
(b) order adding/deleting candidates irrelevant.
theorem, comments preceding it, bit care regarding
possibility P = NP, obtain following claim.
Theorem 4.11. Plurality, Condorcet, Copeland (for rational , 0 1), approval constructive vulnerability-combining destructive vulnerability-combining.
Proof. Immune prongs never vulnerable. P 6= NP resistant prongs cannot
vulnerable, already done previous theorem. P = NP, possible
resistant prongs also vulnerable. Indeed, systems discussion
proof, resistant prongs basic control types happen NP
vulnerable P = NP. However, straightforward see P = NP,
particular election systems holds vulnerable constructive (destructive)
basic prongswhich case nonimmune basic constructive
(destructive) prongswhen combined yield multiprong constructive (destructive) control
type vulnerability holds.
established Theorem 4.11 (soon-to-come) results Section 5, natural
election systems discussed far paper vulnerability-combining
constructive setting destructive setting. natural wonder whether
necessary consequence model multiprong control whether fact
election system combining two control types system vulnerable
yields multipronged control problem system resistant. Theorem 4.12 shows
latter case, even natural election system.
thirteenth century, Ramon Llull proposed election system could used
choose popes leaders monastic orders (see Hagele & Pukelsheim, 2001; McLean
& Lorrey, 2006). system, voters choose winner among (so,
candidates voters). Apart that, Llulls voting system basically
Copeland1 , version Copeland richly rewards ties. Formally, define
voting system OriginalLlull follows: election E = (C, V ), set names
V , denote names(V ), equal C, winners.
Otherwise, candidate c C winner Copeland1 winner. Note
single-prong AC AV control OriginalLlull make much sense,
come surprise OriginalLlull vulnerable constructive AC control
constructive AV control. addition, show (by renaming padding)
Copeland1 -AV reduced OriginalLlull1 -AC+AV. Since Copeland1 resistant
constructive control adding voters (Faliszewski, Hemaspaandra, Hemaspaandra, &
Rothe, 2009a), leads following theorem.
Theorem 4.12. OriginalLlull vulnerable constructive AC control constructive
AV control resistant constructive AC+AV control.
322

fiMultimode Control Attacks Elections

Proof. immediate OriginalLlull susceptible constructive AC, AV,
(by Theorem 4.3) AC+AV control. also straightforward see constructive
OriginalLlull-AC (AV) control P: possible add candidates (voters)
set voter names equal set candidates, check preferred candidate unique Copeland1 winner. possible, reject.
show, via reduction constructive Copeland1 -AV control (which
NP-hard Faliszewski, Hemaspaandra, Hemaspaandra, & Rothe, 2009a) constructive
OriginalLlull-AC+AV control NP-hard. Let C set candidates, let V W
two disjoint collections voters preference lists C, let p C preferred
candidate, k element N. question whether exists subcollection
W 0 W size k p unique Copeland1 winner (C, V W 0 ). Without
loss generality, assume V empty.
show pad election. OriginalLlull election nontrivial,
certainly need number candidates voters (later, also rename
voters candidates). kV k < kCk, want add
collection new dummy voters V 0 kV k + kV 0 k = kCk adding V 0
election change relative Copeland1 scores candidates.
accomplished letting half voters V 0 vote C (recall Convention 3.1) half


voters V 0 vote C . course, done kV 0 k even.
So, following. kV k < kCk, add collection new voters V 0
kV 0 k = kCk kV k kCk kV k even, kV 0 k = kCk kV k + 1 kCk kV k
odd. kV k kCk, let V 0 = . Half voters V 0 vote C half


voters V 0 vote C . addition, introduce set new candidates
kCk + kAk = kV k + kV 0 k + kW k. Note always possible, since kV k + kV 0 k kCk.
extend votes voters (in V , V 0 , W ) C taking preference
order C following candidates fixed, arbitrary order. Note
effect candidates never winners.
Let W 0 W , A0 A, E = (C, V W 0 ), E 0 = (C A0 , V V 0 W 0 ). straightforward
see following hold (recall V empty).
1. A0 , score1E 0 (d) kA0 k 1.
2. c C, score1E 0 (c) = score1E (c) + kA0 k.
3. c, c0 C, c 6= c0 , score1E (c) score1E (c0 ) = score1E 0 (c) score1E 0 (c0 ).
4. p unique Copeland1 winner E p unique Copeland1 winner
E0.
ready define reduction. Name voters names(V V 0 ) C
names(V V 0 W ) = C A. map (C, V, W, p, k) (C, A, V V 0 , W, p, kAk, k).
claim p made unique Copeland1 winner (C, V ) adding k
voters W p made unique OriginalLlull winner (C, V V 0 )
adding (an unlimited number of) candidates k voters W .
First suppose W 0 subcollection W size k p
unique Copeland1 winner (C, V W 0 ). Let A0 set candidates
323

fiFaliszewski, Hemaspaandra, & Hemaspaandra

C A0 = names(V V 0 W 0 ). item 4 above, p unique Copeland1 winner
(C A0 , V V 0 W 0 ), thus p unique OriginalLlull winner (C A0 , V V 0 W 0 ).
converse, suppose exist A0 W 0 W kW 0 k k,
p unique OriginalLlull winner (C A0 , V V 0 W 0 ). p unique
Copeland1 winner (C A0 , V V 0 W 0 ), and, item 4, p unique Copeland1 winner
(C, V W 0 ).
Thus reduction correct and, since computed polynomial time,
proof complete.
following corollary, since OriginalLlull neutral (permuting names
candidates, evaluating elections winners, running winners
inverse permutation affect outcome election) anonymous
(permuting names voters affect outcome election).13
Corollary 4.13. exists neutral anonymous election system E E
vulnerable constructive AC control constructive AV control resistant
constructive AC+AV control.
Something might seem bit strange Theorem 4.12. all, says
powerful chairone add candidates add votersfaces harder task
would faced weaker chairsay, one add candidates. important
thing keep mind, understand strange, different chairs
facing (correspondingly) different problems. powerful type chair asked
determine whether specified amounts adding candidates voters goal
met, weaker type chair asked whether specified amount adding
candidates goal met. Thus paradoxical former problem
higher complexity latter. (After all, powerful solution-finderone
allowed use assignmentseeking find satisfying assignment input Boolean
formulas facing NP-hard task, weak solution-finderone allowed find
solutions 2011 variables assigned Falseseeking find input Boolean
formulas satisfying assignment, exists, 2011 variables assigned
False faces polynomial-time task, due natural brute-force approach.)
4.4 Summary
summarize main contributions Section 4. try motivate
interpret results, rather summarize results are, reader
easily jump back section reference.
13. notion anonymity stated standard one literature. avoid confusion,
mention earlier version (Faliszewski, Hemaspaandra, & Hemaspaandra, 2010a) paper used
much stronger definition anonymityone required one able permute voter
names one-to-one map set names yet outcome change. Let us
call notion voter-superanonymity. OriginalLlull satisfy stronger notion. However,
earlier version paperby sneakily building preference orders voters names
candidatesconstructed highly artificial system neutral, anonymous (in sense
present paper), voter-superanonymous, two vulnerable prongs combined
yielded resistance (Faliszewski et al., 2010a). contrast, Theorem 4.12/Corollary 4.13 provides
jump vulnerability resistance preexisting, natural voting system neutral
anonymous.

324

fiMultimode Control Attacks Elections

C1
R
R
R


V

C2
R
V


V
V

C1 + C2
R
R
R

V
susceptible (i.e., I)

Table 2: example applying Theorem 4.7. Let E election system. consider
two basic types constructive (destructive) control, C1 C2 , E
either resistant (R), immune (I), vulnerable (V). table shows C1 + C2
control E inherits properties prongs. Note Theorem 4.7
give results case E vulnerable C1 C2
(although Theorem 4.3 susceptibility must hold). see this, note
vulnerability-combining systems putting together two vulnerable prongs leads
two-pronged control problem system vulnerable.
examples voting systems combining two vulnerable prongs leads
resistant two-pronged control problem (see Theorem 4.12).

Section 4.1, introduced model multiprong control, allows attacker
use several types control jointly, either try make given candidate unique winner
(constructive control), try prevent given candidate unique winner
(destructive control).
Section 4.2 focused following issue: Let E election system. Let
C1 + + Ck variant multiprong control (so 1 k 5 Ci basic
control type). Suppose know, Ci , 1 k, whether E resistant, immune,
vulnerable constructive (destructive) control type Ci . extent
alone tell whether E resistant, immune, vulnerable constructive (destructive)
C1 + + Ck multiprong control? Theorem 4.7 paragraphs following provide
detailed answer. example applying Theorem 4.7, Table 2 show properties
two control prongs, C1 C2 , combine properties two-pronged C1 + C2 control.
Simply stated, Theorem 4.7 (for systems prong happens immune
vulnerable resistantand include essentially reasonable, natural election systems polynomial-time winner problems) gives read-off-the-answer classification multiprong cases, except system multiple vulnerable constructive
prongs multiple vulnerable destructive prongs. handle case, case
systems (where prong happens immune vulnerable resistant)
multiple vulnerable constructive (destructive) prongs, defined notion constructive (destructive) vulnerability-combining election systems, provided Classification
Rule simple rule classifies multiprong control cases. also provided handy
tool, Proposition 4.9, proving election system vulnerability-combining.
conjecture almost natural systems vulnerability-combining.
Finally, Section 4.3 considered several natural election systems control
already studied (namely, plurality, Condorcet, Copeland (for rational ,
325

fiFaliszewski, Hemaspaandra, & Hemaspaandra

Election system

Plurality
Condorcet
Copeland , 0 1
Approval
Maximin

results combine multiprong vulnerability immune vulnerable entries
column Table 5
Constructive
Destructive
AV+DV+BV
AV+DV+BV
AC+DC
AC+DC+AV+DV+BV
(none)
AC+DC
AC+DC
AC+DC+AV+DV+BV
DC
AC+DC

Table 3: Summary vulnerability results multiprong control plurality, Condorcet, Copeland , approval voting systems. Regarding five basic control
types, summarize column Table 5 least one
vulnerable entry, established multiprong combination
immunity vulnerability entries column remains vulnerable. results obtained combining Theorem 4.10 Theorem 4.7 (with Theorem 4.7
letting us add basic control types given system immune).
sake completeness, also included analogous results regarding maximin, Section 5.

0 1), approval), systems proved system
constructive vulnerability-combining destructive vulnerability-combining (see
Theorem 4.11 formal result; Table 3 summarizes actual combinations
play unless P = NP). Nonetheless, Theorem 4.12 shown ancient
election system OriginalLlull two vulnerable prongs combine yield resistance;
unless P = NP, OriginalLlull vulnerability-combining.

5. Control Maximin
section initiate study control maximin election system. Maximin
loosely related Copeland voting sense defined terms
pairwise head-to-head contests. addition, unweighted coalitional manipulation problem maximin Copeland ( 6= 0.5) exhibits behavior: P one
manipulator NP-complete two manipulators (Xia, Zuckerman, Procaccia,
Conitzer, & Rosenschein, 2009; Faliszewski, Hemaspaandra, & Schnoor, 2008, 2010). Thus
one might wonder whether systems similar regard resistances
control. fact, interesting differences.
straightforward see maximin susceptible basic types constructive
destructive control. so, Theorem 4.3, show vulnerability constructive
(destructive) C control suffices give polynomial-time algorithm decides
constructive (destructive) E-C problem, show resistance constructive (destructive)
C control suffices show constructive (destructive) E-C problem NP-hard.
consequence analysis given following subsections, maximin
constructive vulnerability-combining destructive vulnerability-combining.
326

fiMultimode Control Attacks Elections

Theorem 5.1. Maximin constructive vulnerability-combining destructive
vulnerability-combining.
Proof. discussion analysis provided proof Theorem 4.11 apply here,
except relying underpinning work provided later section. constructive
case degenerate, among basic prongs one interest (although
briefly discuss special extra prong later). Even destructive case,
two basic prongs resistant.
5.1 Candidate Control Maximin
Let us focus candidate control maximin, is, AC DC control
types, constructive destructive setting. case Copeland ,
0 1, maximin resistant control adding candidates.
Theorem 5.2. Maximin resistant constructive AC control.
Proof. give reduction X3C. Let (B, S), B = {b1 , . . . , b3k } set
3k elements = {S1 , . . . , Sn } set 3-subsets B, input X3C instance.
form election E = (C A, V ), C = B {p}, = {a1 , . . . , }, V =
(v1 , . . . , v2n+2 ). (Candidates spoiler candidates, attacker
ability add election (C, V ).)
Voters V following preferences. Si S, voter vi reports preference

list p > B Si > ai > Si > {ai } voter vn+i reports preference list {ai } > ai >






Si > B Si > p. Voter v2n+1 reports p > > B voter v2n+2 reports B > p > .
claim set A0 kA0 k k p unique winner
(C A0 , V ) (B, S) yes instance X3C.
show claim, let E 0 = (C, V ). pair distinct elements bi , bj B,
NE 0 (bi , bj ) = n+1, NE 0 (p, bi ) = n+1, NE 0 (bi , p) = n+1. is, candidates
E 0 tie. consider set A00 A, kA00 k k, election E 00 = (C A00 , V ). Values
NE 00 NE 0 pair candidates {p}B. pair distinct
elements ai , aj A00 , NE 00 (p, ai ) = n + 2, NE 00 (ai , p) = n, NE 00 (ai , aj ) = n + 1.
bi B aj A00

NE 00 (bi , aj ) =

n
n+1

bi Sj ,
bi
/ Sj ,

and, course, NE 00 (aj , bi ) = 2n + 2 NE 00 (bi , aj ). Thus, definition maximin,
following scores E 00 : (a) scoreE 00 (p) = n + 1, (b) aj A00 , scoreE 00 (aj ) = n,
(c) bi B,

n
(aj A00 )[bi Sj ],
scoreE 00 (bi ) =
n + 1 otherwise.
A00 corresponds family 00 3-sets j, 1 j n, 00
contains set Sj A00 contains aj . Since kA00 k k, straightforward see
p unique winner E 00 00 exact cover B.
327

fiFaliszewski, Hemaspaandra, & Hemaspaandra

Copeland , 0 1, resistant constructive AC control, {0, 1},
Copeland vulnerable constructive control adding unlimited number candidates. turns maximin. However, interestingly, contrast Copeland,
maximin also vulnerable DC control.
Rather proving that, prove bit more: moment
discuss different control type, ACu , consider one five basic
types. ACu control (called control adding unlimited number candidates)
like control adding candidates, except (by definition) limit number
candidates addin effect, one requires kAC = kAk.14 show maximin
vulnerable DC control fact even ACu +DC control. Intuitively, constructive ACu +DC control add many candidates possible (because adding
candidate generally decreases candidates scores, making preferred candidates
way victory easier) delete candidates stand candidates way
(i.e., whose existence blocks preferred candidates score increasing). Studying
constructive ACu +DC control maximin jointly leads compact, coherent algorithm.
consider control types separately, would give two fairly similar
algorithms obtaining weaker result.
Theorem 5.3. Maximin vulnerable constructive ACu +DC control.
Proof. give polynomial-time algorithm constructive maximin-ACu +DC control.
input contains election E = (C, V ), set spoiler candidates A, preferred
candidate p C, nonnegative integer kDC . Voters V preference lists
candidates C A. ask whether exist sets A0 C 0 C (a)
kC 0 k kDC (b) p unique winner election ((C C 0 ) A0 , V ). kDC kCk 1,
accept immediately delete candidates p. Otherwise, use
following algorithm.
Preparation. rename candidates C C = {p, c1 , . . . , cm } =
{cm+1 , . . . , cm+m0 }. Let E 0 = (C A, V ) let P = {NE 0 (p, ci ) | ci C A}.
is, P contains values candidate p may obtain scores upon deleting
candidates E 0 . k P , let Q(k) = {ci | ci C A{p}NE 0 (p, ci ) < k}.
Intuitively, Q(k) set candidates E 0 prevent p least k
points.
14. control type ACu historical interest used control adding candidates
notion seminal paper control. However, following suggestion Faliszewski, Hemaspaandra,
Hemaspaandra, Rothe (2007), AC used work recent years; natural
choice since analogous three add/delete voter/candidate control types. addition
Theorem 5.3s result constructive case, mention passing maximins vulnerability
destructive AC (see Theorem 5.4 light Proposition 4.9) implies also vulnerable ACu .
Readers wishing know results hold prong ACu election systems covered
paper find summarized table Faliszewski et al. (2010a)except 6= 0.5
cases Copeland , cases Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2009a)
referred to. entire set tools Section 4.2 framed around five basic control types,
try weave ACu framework. mention tools apply well type
also, would prove special hurdle incorporate framework. Still, feel
AC (not ACu ) far attractive way frame control adding candidates
addition compelling.

328

fiMultimode Control Attacks Elections

Main loop. k P , algorithm tests whether deleting kDC candidates C number candidates possible ensure p
obtains exactly k points becomes unique winner E 0 . Let us fix value
k P . build set candidates delete. Initially, set = Q(k).
straightforward see deleting candidates Q(k) necessary sufficient
condition p score k. However, deleting candidates Q(k) necessarily
sufficient ensure p unique winner candidates scores greater
equal k may exist. execute following loop (which call fixing
loop):
1. Set E 00 = ((C A) D, V ).
2. Pick candidate (C A) scoreE 00 (d) k (break loop
candidate exists).
3. Add jump back Step 1.
accept C kDC proceed next value k otherwise.15 none
values k P leads acceptance reject.
Let us briefly explain algorithm correct. straightforward see
maximin adding candidate c election increase candidates
scores, deleting candidate election decrease candidates
scores. Thus, deleting candidates Q(k) still candidates p
k points more, way ensure ps victorywithout explicitly trying increase
ps scoreis deleting candidates. Also, note way ensure p
exactly k points deleting candidates Q(k).
Note execution fixing loop, score p might increase
value k 0 > k. happens, means impossible ensure ps victory
keeping score equal k. However, need change k k 0
iteration main loop consider k 0 different iteration.
Maximin also vulnerable destructive AC+DC control. proof relies fact
(a) way prevent despised candidate winning maximin election
via adding spoiler candidates way adding two
candidates, (b) adding candidate cannot increase score candidate
added one, (c) deleting candidate cannot decrease score candidate
deleted one. essence, algorithm performs brute-force search
candidates add uses constructive maximin-DC control algorithm
Theorem 5.3.
Theorem 5.4. Maximin vulnerable destructive AC+DC control.
Proof. remind reader part definition destructive control deleting
candidates one cannot simply delete ones despised candidate.
15. accept, implicitly describes control action ensures ps victory: delete
C candidates C add candidates D.

329

fiFaliszewski, Hemaspaandra, & Hemaspaandra

first give algorithm destructive maximin-AC argue
combined algorithm Theorem 5.3 solve destructive maximin-AC+DC
polynomial time.
Let us first focus destructive AC problem. input election E =
(C, V ), C = {d, c1 , . . . , cm } V = (v1 , . . . , vn ), spoiler candidate set =
{cm+1 , . . . , cm0 }, nonnegative integer kAC . voters preference orders
C A. goal ensure unique winner E via adding kAC
candidates A.
Let us assume exists set A0 unique winner
election E 0 = (C A0 , V ). Since unique winner E 0 , exists candidate
c0 C A0 scoreE 0 (c0 ) scoreE 0 (d). Also, definition maximin,
candidate d0 C A0 scoreE 0 (d) = NE 0 (d, d0 ). consequence,
unique winner election E 00 = (C {c0 , d0 }, V ). reason scoreE 00 (d) = scoreE 0 (d)
(because E 0 E 00 contain d0 ) scoreE 00 (c0 ) scoreE 0 (c0 ) (because adding
remaining A0 {c0 , d0 } candidates E 00 increase c0 score). Thus, test whether
possible ensure unique winner E, suffices test whether
set A00 kA00 k min(2, kAC ) unique winner (C A00 , V ).
Note test carried polynomial time.
Let us consider AC+DC case. input goal before,
except also given nonnegative integer kDC allowed delete
kDC candidates. describe algorithm. set {c0 , d0 } two
candidates, {c0 , d0 } (C A) {d} execute following steps.
1. check kA {c0 , d0 }k kAC (and proceed next {c0 , d0 }
case).
2. compute set C {d, c0 , d0 }, kDk kDC , maximizes scoreE 0 (c0 ),
E 0 = ((C {c0 , d0 }) D, V ).
3. unique winner E 0 = ((C {c0 , d0 }) D, V ), accept.
reject accept {c0 , d0 } (C A) {d}.
intended role d0 lower score keep fixed level, while,
course, intended role c0 defeat d. reasoning analogous AC
case, see need add two candidates. Thus, given {c0 , d0 },
remains compute appropriate set D. essence, manner
constructive AC+DC case.
Let k positive integer. set D(k) = {ci C {c0 , d0 , d} | NE (c0 , ci ) < k}
pick = D(i), large possible (but larger kV k) kDk kDC .
Deleting candidates maximizes score c0 , given cannot delete d0 (we
cannot delete definition control deleting candidates, cannotor,
precisely, want todelete d0 role d0 algorithm keep
score check). straightforward see computed polynomial
time.
330

fiMultimode Control Attacks Elections

5.2 Control Adding Deleting Voters Maximin
section consider complexity constructive destructive AV DV control types. (We consider bribery, BV, next section; recall paper,
bribery basic control type, though usually treated separately literature.)
previous section seen maximin vulnerable basic types constructive destructive candidate control except constructive control adding candidates
(constructive AC control). situation regarding voter control quite different:
shown next three theorems, maximin resistant basic types constructive
destructive voter control.
Theorem 5.5. Maximin resistant constructive destructive AV control.
Proof. first give NP-hardness proof constructive case
describe modify destructive case.
give reduction X3C problem constructive maximin-AV problem.
input X3C instance (B, S), B = {b1 , . . . , b3k } set 3k distinct elements
= {S1 , . . . , Sn } family n 3-element subsets B. Without loss generality,
assume k 1. reduction outputs following instance. election
E = (C, V ), C = B {p, d} V = (v1 , . . . , v4k ). 2k voters
preference order > B > p, k voters preference order p > B > d, k voters
preference order p > > B. addition, collection W = (w1 , . . . , wn ) voters
added, ith voter, 1 n, preference order
B Si > p > Si > d.
claim subcollection W 0 W kW 0 k k p unique
winner election (C, V W 0 ) (B, S) yes instance X3C.
straightforward verify bi B holds NE (p, bi ) = 2k,
NE (p, d) = 2k. Thus scoreE (p) = 2k. Similarly, straightforward verify
scoreE (d) = 2k, bi B, scoreE (bi ) k. Let W 00 subcollection W
kW 00 k k let E 00 = (C, V W 00 ). bi B holds scoreE 00 (bi )
2k. Since voter W ranks least desirable candidate, scoreE 00 (d) = 2k.
ps score election E 00 ? exists candidate bi B voter
wj W 00 prefers p bi , scoreE 00 (p) = 2k (because NE 00 (p, bi ) = 2k). Otherwise,
scoreE 00 (p) 2k + 1. Thus p unique winner E 00 W 00 corresponds
exact cover B. proves claim and, reduction straightforwardly seen
computable polynomial time, concludes proof constructive maximin-AC
case.
show destructive maximin-AC NP-hard, use reduction, except
remove V single voter preference list p > B > d, set task
preventing unique winner. Removing p > B > voter V ensures
start adding candidates, score 2k (and score cannot changed),
p score 2k 1 (and p needs get one point extra candidate increase
score prevent unique winner), bi B score
k 1 (thus candidate B obtain score higher 2k 1 via adding
k candidates W ). reasoning constructive case proves
reduction correctly reduces X3C destructive maximin-AV.
331

fiFaliszewski, Hemaspaandra, & Hemaspaandra

Theorem 5.6. Maximin resistant constructive destructive DV control.
Proof. first show NP-hardness constructive maximin-DV control
argue modify construction obtain result destructive case.
reduction X3C. Let (B, S) input X3C instance, B =
{b1 , . . . , b3k }, = {S1 , . . . , Sn }, i, 1 n, kSi k = 3. Without loss
generality, assume n k 3 (if n < k contain cover B,
k 2 solve problem brute force). form election E = (C, V ),
0 ), V 00 = (v 00 , . . . , v 00
C = B {p, d} V = V 0 V 00 , V 0 = (v10 , . . . , v2n
1
2nk+2 ).
0
i, 1 n, voter vi preference order
> B Si > p > Si
0
voter vn+i
preference order




> Si > p > B Si .
Among voters V 00 have: 2 voters preference order p > > B, n k voters
preference order p > B > d, n voters preference order B > p > d. claim
possible ensure p unique winner election E via deleting k
voters (B, S) yes instance X3C.
Via routine calculation see candidates election E following scores:
1. scoreE (d) = 2n (because NE (d, p) = 2n bi B, NE (d, bi ) = 2n + 2),
2. scoreE (p) = 2nk +2 (because NE (p, d) = 2nk +2 bi B, NE (p, bi ) =
2n k + 2),
3. bi B, scoreE (bi ) 2n k (because NE (bi , d) = 2n k).
voters deleted, unique winner k 2 points p. Via
deleting k voters possible decrease ds score k points. Let W
collection voters p unique winner E 0 = (C, V W ). partition
W W 0 W 00 , W 0 contains members W belong V 0 W 00
contains members W belong V 00 . claim W 00 empty.
sake contradiction let us assume W 00 6= . Let E 00 = (C, V W 00 ). Since every
voter V 00 prefers p d, NE 00 (p, d) = NE (p, d) kW 00 k and, result,
scoreE 00 (p) scoreE (p)kW 00 k. addition, assuming W 00 empty, straightforward
observe scoreE 00 (d) scoreE (d) kW 00 k + 1 (the reason deleting
single member V 00 decrease ds score). is, that:
scoreE 00 (p) 2n k + 2 kW 00 k,
scoreE 00 (d) 2n + 1 kW 00 k.
E 00 , least k 1 points p. Since kW 00 k 1, delete
k 1 voters W 0 election E 00 . p unique winner E 0 ,
contradiction.
Thus W contains members V 0 only. Since ranked first every vote V 0 , deleting
voters W decreases ds score exactly kW k. Further, deleting voters W certainly
decreases ps score least one point. Thus deleting voters W have:
332

fiMultimode Control Attacks Elections

1. scoreE 0 (d) = 2n kW k,
2. scoreE 0 (p) 2n k + 2 1 = 2n k + 1.
consequence, possibility p unique winner deleting voters W
kW k = k equality item 2 above. straightforward verify
equality holds W contains k voters among v10 , . . . , vn0 correspond
exact cover B via sets (recall k 3). proves reduction
correct, since reduction straightforwardly seen computable polynomial
time, completes proof NP-hardness constructive maximin-DV control.
Let us consider destructive case. Let (B, S) input X3C instance (with B
constructive case). form election E = (C, V ) identical one
00
created constructive case, except V 00 = (v100 , . . . , v2nk
) set voters
preference orders follows: one voter preference order p > > B, n k
voters preference order p > B > d, n 1 voters preference order B > p > d.
(That is, compared constructive case, remove one voter preference order
p > > B one preference order B > p > d.) straightforward see
unique winner election E claim prevented
unique winner via deleting k voters exact cover B
k sets S.
Via routine calculation, straightforward verify scoreE (d) = 2n,
scoreE (p) = 2n k. former holds NE (d, p) = 2n NE (d, bi ) = 2n + 1
latter holds NE (p, d) = 2n k candidate bi B
NE (p, bi ) = 2n k + 1. addition, candidate bi B score 2n k 1.
Thus possible ensure unique winner via deleting k voters
exactly k voters deletion would decrease score
k points would decrease ps score. Let us assume collection voters
exists let W collection. Since every voter V 00 prefers p d, note W
contain voter V 00 . Thus W contains exactly k voters V 0 . Since
bi B NE (p, bi ) = 2n k + 1, bi B W contains one voter
prefers p bi . Since kBk = 3k k 3, implies W contains exactly
collection voters corresponding exact cover B sets S. completes
proof destructive case.
5.3 Bribery Maximin
move bribery maximin. Given previous results, surprising
maximin resistant constructive bribery destructive bribery. proof
application UV technique Faliszewski, Hemaspaandra, Hemaspaandra,
Rothe (2009a). informally, idea build election way ensures
briber limited bribing voters rank two special candidates ahead
preferred one.
Theorem 5.7. Maximin resistant constructive destructive BV control.
Proof. proofs follow via reductions X3C. reduction constructive case
almost identical one constructive case thus consider cases
parallel.
333

fiFaliszewski, Hemaspaandra, & Hemaspaandra

reductions work follows. Let (B, S) instance X3C, B =
{b1 , . . . , b3k } set 3k distinct elements, = {S1 , . . . , Sn } family 3-element
subsets B. (Without loss generality, assume n > k > 1. case,
trivial verify (B, S) yes instance X3C.) construct set candidates
C = {p, d, s} B, p preferred candidate (the goal constructive setting
ensure p unique winner) despised candidate (the goal destructive
setting prevent unique winner). construct six collections voters,
V 1 , V 2 , V 3 , V 4 , V 5 , V 6 , follows:
1 . i, 1 n, voters v 1 v 1
1. V 1 contains 2n voters, v11 , . . . , v2n

i+n
following preference orders:

vi1 : > > Si > p > B Si



1
vn+i
: B Si > p > Si > > s.
2 . i, 1 k, voters v 2 v 2
2. V 2 contains 2k voters, v12 , . . . , v2k

i+k
following preference orders:

vi2 : > > p > B


2
vk+i
: B > > p > s.
3 . i, 1 k, voters v 3 v 3
3. V 3 contains 2k voters, v13 , . . . , v2k

i+k
following preference orders:

vi3 : > > p > B


3
: B > > p > d.
vk+i
4 . i, 1 2k, voters v 4 v 4
4. V 4 contains 4k voters, v14 , . . . , v4k

i+2k
following preference orders:

vi4 : > B > p >


4
v2k+i
: > p > > B.
5. V 5 contains 2 voters, v15 , v25 following preference orders
v15 : > B > p >


v25 : > B > p > s.
6. V 6 contains single voter, v16 , preference order p > > > B.
form two elections, Ec Ed , Ec = (C, V 1 V 6 ) Ed = (C, V 1
V 5 ); is, Ec Ed identical except Ed contain single voter
V 6 . Ec contains 2n + 8k + 3 voters Ed contains 2n + 8k + 2 voters. Values NEc
NEd pair candidates given Table 4.
334

fiMultimode Control Attacks Elections

(a) Values NEc (, ).

p


B

p

n + 5k + 1
n + 5k + 1
n + 4k + 2


n + 3k + 2

4k + 1
n + 2k + 1


n + 3k + 2
2n + 4k + 2

n + 4k + 1

B
n + 4k + 1
n + 6k + 2
n + 4k + 2
n + 4k + 2

(b) Values NEd (, ).

p


B

p

n + 5k + 1
n + 5k + 1
n + 4k + 2


n + 3k + 1

4k + 1
n + 2k + 1


n + 3k + 1
2n + 4k + 1

n + 4k + 1

B
n + 4k
n + 6k + 1
n + 4k + 1
n + 4k + 1

Table 4: Values NEc (, ) NEd (, ) pair candidates. Let E one Ec , Ed .
entry row c0 {p, d, s} column c00 {p, d, s}, c0 6= c00 , appropriate
table gives value NE (c0 , c00 ). row B column B adopt
following convention. c {p, d, s} bi B, entry row B
column c equal NE (bi , c). c {p, d, s} bi B,
entry row c column B equal NE (c, bi ). two distinct bi , bj B,
entry row B column B upper bound NE (bi , bj ). (For Ed
entry is, fact, exact.)

constructive case, claim possible ensure p unique winner
election Ec bribing k voters (B, S) yes instance X3C.
Let us prove claim. inspecting Table 4, recalling n > k > 1, see
scoreEc (p) = n + 3k + 2, scoreEc (d) = n + 5k + 1, scoreEc (s) = 4k + 1,
bi B, scoreEc (bi ) n + 2k + 1. is, prior bribing, unique winner
p second highest score.
straightforward see bribing k voters, briber change
candidates score points. Thus, bribery successful, briber
bribe exactly k voters way ds score decreases n + 4k + 1 ps score
increases n + 4k + 2. achieve this, briber find collection V 0 voters
kV 0 k = k,
1. voter V 0 ranks p s,
2. bi B, voter V 0 ranks p bi .
voters satisfy first condition v11 , . . . , vn1 , v12 , . . . , vk2 , v13 , . . . , vk3 . Further,
among voters v11 , . . . , vn1 rank p member B and, fact,
i, 1 n, vi1 ranks p exactly three members B. Thus straightforward
see k voters v11 , . . . , vn1 , v12 , . . . , vk2 , v13 , . . . , vk3 satisfy second condition
correspond naturally cover B sets S. (Note suffices briber
bribes voters V 0 rank p first without changing votes way,
335

fiFaliszewski, Hemaspaandra, & Hemaspaandra

changing votes way ranking p first necessary.) result,
possible ensure p winner Ec bribing k voters (B, S)
yes instance X3C. direction, straightforward verify (B, S)
yes instance X3C bribing k voters v11 , . . . , vn1 correspond cover
B rank p first suffices ensure p unique winner. completes proof
constructive case.
destructive case, claim possible ensure unique
winner Ed (B, S) yes instance X3C. proof analogous
constructive case: suffices note p candidate possibly tie
victory d. rest proof proceeds constructive case.

6. Fixed-Parameter Tractability
section consider parameterized complexity multipronged control, particular, case assume number candidates small constant.
Elections candidates natural. example, many countries presidential
elections involve handful candidates.
main result section many natural election systems E (formally,
election systems whose winner determination problem expressed via integer linear program certain form), holds E-AC+DC+AV+DV+BV control
problem fixed-parameter tractable (is complexity class FPT) parameter
number candidates, constructive setting destructive setting.
result combines significantly enhances FPT results literature, particular, papers Faliszewski, Hemaspaandra, Hemaspaandra (2009a)
Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2009a), model
inspiration section. also make explicit automatic path results
implicit work two papers cited previous sentence. path
helpful letting many future analyses done tool-application exercises,
rather case-by-case challenges.
present paper paper pick type pattern earlier
work mentioned, present definition results building that. Independently
present paper, Dorn Schlotter (2010) done different, bribery-related
context.
section focus exclusively number candidates parameter.
is, parameter number candidates initially election plus number
candidates (if any) set potential additional candidates. is, terms
variables using describe multiprong control parameter kCk + kAk.
mention researchers sometimes analyze parameterizations. example,
Liu et al. (2009), Liu Zhu (2010), Betzler Uhlmann (2009) consider
parameter amount change one allowed use (e.g., number candidates one add), Bartholdi, Tovey, Trick (1989b), Betzler Uhlmann (2009),
Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2009a) study parameter
number voters (and also sometimes number candidates). parameters
sometimes used considering so-called possible winner problem (see, e.g., Betzler
& Dorn, 2009; Betzler, Hemmann, & Niedermeier, 2009). However, view parameter
336

fiMultimode Control Attacks Elections

number candidates essential natural one. proceed
discussion fixed-parameter tractability, number candidates
parameter.
Let us consider election system E set C = {c1 , . . . , cm } candidates.
exactly m! preference orders candidates C refer o1 , . . . , om! .
Let us assume E anonymous (i.e., winners E election depend
order votes names voters, onlyfor preference order oi
number votes preference order). define predicate win E (cj , n1 , . . . , nm! )
true ci unique winner E elections C = {c1 , . . . , cm },
i, 1 m!, exactly ni voters preference order oi . rest
section, inequalities always use one four operators >, , <,
.16
Definition 6.1. say anonymous election system E unique-winner (nonuniquewinner) integer-linear-program implementable set candidates C = {c1 , . . . , cm }
candidate cj C exists set linear inequalities variables n1 , . . . , nm!
that:
1. integer assignment n1 = n1 , . . ., nm! = nm! satisfies S, ni belongs
N,17
2. computed (i.e., obtained) time polynomial m!,18
3. (n1 , . . . , nm! ) Nm! , (a) holds (b) holds, (a)
(b) follows:
(a) satisfied assignment n1 = n1 , . . ., nm! = nm! .
(b) cj unique winner (is winner) E election i, 1
m!, exactly ni voters preference order oi , oi ith
preference order set C.
16. allow strict nonstrict inequalities. Since allow integer solutions, straightforward
simulate strict inequalities nonstrict ones simulate nonstrict inequalities strict ones,
cases simply adding 1 appropriate side inequality. could equally well
allowed strict, nonstrict, inequalities.
17. straightforward put m! inequalities enforcing condition. condition
help us make electoral part definition meaningful, i.e., avoid problems
restriction final part definition lets us avoid discussing negative numbers voters.
18. mention passing m! part definition changed computable
mm
function m, e.g., mm
, would still obtain FPT results, still would hold even
strengthened version FPT f f (parameter) InputsizeO(1) required
computable. However, due m! number preference orders candidates,
obtainable time polynomial m! practice particularly common case.
also mention passing FPT-establishing framework section results
yields, similarly case work mentioned earlier (Faliszewski, Hemaspaandra, & Hemaspaandra, 2009a; Faliszewski, Hemaspaandra, Hemaspaandra, & Rothe, 2009a), apply
model votes input list ballots, one per person, also hold so-called
succinct model (see Faliszewski, Hemaspaandra, & Hemaspaandra, 2009a; Faliszewski, Hemaspaandra, Hemaspaandra, & Rothe, 2009a), given votes individual ballots
binary numbers providing number voters preference order (or occurring
preference order).

337

fiFaliszewski, Hemaspaandra, & Hemaspaandra

slight abuse notation, integer-linear-program implementable election systems E simply refer set linear inequalities Definition 6.1
win E (cj , n1 , . . . , nm! ). particular set candidates always clear context.
Naturally, straightforward adapt Definition 6.1 apply approval voting,
sake brevity so.
aware natural systems integer-linear-program unique-winner
implementable yet integer-linear-program nonunique-winner implementable, vice
versa. paper focus unique winner model reader may wonder
defined nonunique winner variant integer-linear-program implementability.
answer that, see later section, useful notion dealing
destructive control.
class election systems integer-linear-program implementable remarkably broad. example, variously implicit consequence results Faliszewski,
Hemaspaandra, Hemaspaandra (2009a) plurality, veto, Borda, Dodgson,
polynomial-time computable (in number candidates) family scoring protocols
integer-linear-program implementable.19 many election systemse.g., Kemeny
voting (Kemeny, 1959; Young & Levenglick, 1978) Copeland votingit clear
whether integer-linear-program implementable, similar approaches
useful us. return issue end section.
Theorem 6.2. Let E integer-linear-program unique-winner implementable election
system. number candidates parameter, constructive E-AC+DC+AV+DV+BV
FPT.
Proof. Let (C, A, V, W, p, kAC , kDC , kAV , kDV , kBV ) input instance constructive E-AC+DC+AV+DV+BV control problem, described Definition 4.1. Let C =
{p, c1 , . . . , cm0 } = {a1 , . . . , am00 }. parameter, total number candidates,
K
= m0 +m00 +1. subset K C let oK
1 , . . . , okKk! mean kKk! preference
orders K.
idea algorithm perform exhaustive search subsets
candidates K, K C A, K check whether (a) possible obtain K
C deleting kDC candidates adding kAC candidates A, (b)
possible ensure p unique winner election (K, V ) deleting kDV
voters, adding kAV voters W , bribing kBV voters. Given K, step
(a) straightforwardly implemented polynomial time. implement step (b),
introduce linear integer program P (K), satisfiable step (b) holds.
Let us fix K C describe integer linear program P (K).
assume p K legal delete p (and would pointless, given
want ensure victory). interpret preference orders voters V
W limited candidate set K. use following constants program.
19. Let number candidates. scoring protocol vector nonnegative integers satisfying
1 2 . candidate receives points vote ranks ith
position, candidate(s) points win. Many election systems viewed families
scoring protocols. example, plurality defined scoring protocols form (1, 0, . . . , 0), veto
defined scoring protocols form (1, . . . , 1, 0), Borda defined scoring protocols
form (m 1, 2, . . . , 0), number candidates.

338

fiMultimode Control Attacks Elections

i, 1 kKk!, let nVi number voters V preference order oK
,
K . P (K) contains
let nW


number

voters

W

preference
order



following variables (described together intended interpretation):
Variables av1 , . . . , avkKk! . i, 1 kKk!, interpret avi number
voters preference oK
add W .
Variables dv1 , . . . , dvkKk! . i, 1 kKk!, interpret dvi number
voters preference oK
delete V .
Variables bv1,1 , bv1,2 , . . . , bv1,kKk! , bv2,1 , . . . , bvkKk!,kKk! . i, j, 1 i, j
kKk!, interpret bvi,j number voters preference oK
that, case
6= j, bribe switch preference order oK
,
or,

case

=
j,

leave unbribed.
j
P (K) contains following constraints.
1. variables nonnegative values.
2. variable avi , 1 kKk!, enough voters W preference
order oK
added. is, i, 1 kKk!, constraint
avi nW
. Altogether, add kAV voters constraint
PkKk!
i=1 avi kAV .
3. variable dvi , 1 kKk!, enough voters V preference
order oK
deleted. is, i, 1 kKk!, constraint
dvi nVi . Altogether, delete kDV voters constraint
PkKk!
i=1 dvi kDV .
4. variable bvi,j , 1 i, j kKk!, enough voters preference oK

PkKk!
bribed. is, i, 1 kKk!, constraint j=1 bvi,j =
nVi + avi dvi (the equality comes fact i, 1 kKk!, bvi,i
number voters preference oK
bribe). Altogether,
bribe kBV voters also constraint


kKk! kKk!
kKk!
X X
X

bvi,j
bvi,i kBV .
i=1 j=1

i=1

5. Candidate p unique winner election executed adding,
deleting, bribing voters. Using fact E integer-linear-program uniquewinner implementable, express win E (p, `1 , . . . , `kKk! ), subPkKk!
stitute `j , 1 j kKk!, i=1 bvi,j (note that, previous constraints,
variables describing bribery already take account adding deleting voters).
legal integer-linear-program constraint win E (p, `1 , . . . , `kKk! ) simply
conjunction linear inequalities `1 , . . . , `kKk! .
number variables number inequalities P (K) polynomially
bounded m!. Keeping mind Definitions 4.1 6.1, straightforward see program P (K) exactly expect to. testing whether P (K) satisfiable (i.e.,
339

fiFaliszewski, Hemaspaandra, & Hemaspaandra

integer solution, framework integer linear program) FPT,
respect number candidates parametrization, using Lenstras
(1983) algorithm. Thus complete FPT algorithm E-AC+DC+AV+DV+BV
problem works follows. subset K C includes p execute
following two steps:
1. Check whether possible obtain K C deleting kDC candidates
adding kAC candidates A.
2. Form linear program P (K) check whether integral solutions using
algorithm Lenstra (1983). Accept so.
trying sets K accepted, reject.
previous discussion, algorithm correct. Also, since (a) exactly
m1
2
sets K try, (b) executing first step done time polynomial
m, (c) second step FPT (given parameter), constructive
E-AC+DC+AV+DV+BV FPT parameter m.
Theorem 6.2 deals constructive control only. However, using proof, straightforward prove destructive variant result. say election system
strongly voiced (Hemaspaandra et al., 2007) holds whenever least one
candidate, least one winner.20
Corollary 6.3. Let E strongly voiced, integer-linear-program nonunique-winner implementable election system. Destructive E-AC+DC+AV+DV+BV FPT parameter number candidates.
see corollary holds, enough note strongly voiced election
systems candidate prevented unique winner
candidate made (possibly nonunique) winner (see, e.g., Footnote 5 Hemaspaandra et al., 2007, relevant discussion). Thus prove Corollary 6.3, simply
use algorithm candidate despised one sees whether
candidate made (perhaps nonunique) winner, made (perhaps
nonunique) winner, declares destructive control achievable. (And precise integer linear
programming feasibility problem solution given Lenstras algorithm reveal action achieves control.) done FPT using algorithm proof
Theorem 6.2, adapted work nonunique-winner problem (this trivial given
Corollary 6.3 assumes E integer-linear-program nonunique-winner implementable).
Let us go back issue election systems may integer-linearprogram implementable. example, let us consider maximin. Let E = (C, V )
election, C = {c1 , . . . , cm } V = (v1 , . . . , vn ). before, o1 , . . . , om!
mean m! possible preference orders C, i, 1 m!, ni
20. Please recall Footnote 5. papers model elections, one matches
previous papers studying control, notion election allow election system
inputs winner. However, mention social choice world, formalizations elections
typically build definition exclusion possibility winners,
world, strongly voiced would seem strange concept explicitly define require, built
general definition start.

340

fiMultimode Control Attacks Elections

mean number voters V report preference order oi . ci cj C,
ci 6= cj , let O(ci , cj ) set preference orders C ci preferred cj . Let
k = (k1 , . . . , km ) vector nonnegative integers i, 1 m, holds
1 ki m. vector k candidate c` C define (c` , k1 , . . . , km )
following set linear integer inequalities:
1. candidate ci , maximin score P
equal NE (ci ,P
cki ). is,
i, j, 1 i, j m, 6= j, constraint ok O(ci ,ck ) nk ok O(ci ,cj ) nk


2. c` highest maximin score election E thus P
unique winner
E. is, i, 1 m, 6= `, constraint
ok O(c` ,ck` ) nk >
P
ok O(ci ,ck ) nk .


straightforward see c` unique maximin winner E
vector k = (k1 , . . . , km ) inequalities (c` , k1 , . . . , km ) satisfied. also
straightforward modify construction handle nonunique winner case.
Since O(mm ) vectors k try (c` , k1 , . . . , km ) contains O(m2 )
inequalities, straightforward modify proof Theorem 6.2 work maximin:
Assuming one interested ensuring candidate c` victory, one simply replace
program P (K) proof Theorem 6.2 family programs include
different (c` , k1 , . . . , km ) testing c` won. one would accept
satisfiable. Thus following result.
Corollary
6.4. Constructive AC+DC+AV+DV+BV control destructive
AC+DC+AV+DV+BV control FPT maximin parameter number
candidates.
construction winner problem maximin viewed as, effect, disjunction set integer linear programs. constructions winner
problem already obtained Kemeny elections21 Faliszewski, Hemaspaandra, Hemaspaandra (2009a) Copeland elections Faliszewski, Hemaspaandra,
Hemaspaandra, Rothe (2009a). Thus following theorem.
21. definition one notion Kemeny voting system voting preference
orders (so ties within voters preferences allowed) allowed values Kemeny consensus
(soon defined) also limited preference orders. notion original
papers (Kemeny, 1959; Young & Levenglick, 1978), rather notion Kemeny elections used
Faliszewski, Hemaspaandra, Hemaspaandra (2009a), mention following
Saari Merlin (2000) notion Kemeny elections; interestingly, Hemaspaandra, Spakowski,
Vogel (2005) ensure main result, complexity winner problem
Kemeny elections, holds cases, use real care make hold. So,
said, Kemeny elections (as used paper) defined follows. Let E = (C, V )
election, C = {c1 , . . . , cm } V = (v1 , . . . , vn ). preference order r voter vi ,
1 n, let d(r, vi ) number inversions r preference order vi (i.e.,
number pairs candidates {ci ,P
cj } ranked vi r opposite order). Kemeny score
preference order r defined n
i=1 d(r, vi ). preference order r said Kemeny consensus
Kemeny score lowest (tied lowest finethe lowest unique) among
preference orders C. candidate ci Kemeny winner ci ranked first Kemeny
consensus.

341

fiFaliszewski, Hemaspaandra, & Hemaspaandra

Corollary 6.5. number candidates parameter, constructive
AC+DC+AV+DV+BV control destructive AC+DC+AV+DV+BV control
FPT Kemeny and, rational , 0 1, Copeland .
conclude important caveat. FPT algorithms section
broad coverage, practice would difficult use running
time depends (the fixed-value parameter) fast-growing way Lenstras
algorithm large multiplicative constant polynomial running time. Thus
results section best interpreted indicating that, multipronged control
setting, impossible prove non-FPT-ness (and impossible prove fixedparameter hardness terms levels so-called W hierarchy fixed-parameter
complexity, unless hierarchy collapses FPT). one interested truly practically
implementing multipronged control attack, one probably devise problem-specific
algorithm rather using generally applicable FPT construction.

7. Conclusions
paper motivated desire move study control step direction
better capturing real-life scenarios. particular, attackers tend artificially
limit one type attack, rather may well pull employ every
trick playbook. studied control attacks (including even (unpriced)
bribery, first time, within framework control) multiple attack prongs
pursued attacker.
paper shown approachcombining various types control multiprong control attacksis useful. example, allows us express control vulnerability
results proofs compact way, obtain vulnerability results stronger
would obtained single prongs alone (and immediately imply prior results,
single prongs). central contribution paper provides
broad set tools allow one, immunity/vulnerability/resistance basic
control prongs, almost always determine complexity combinations prongs.
systems basic prong immune, vulnerable, resistant, blind spot
machinery cases multiple vulnerable prongs,
showed underlying prongs simply determine complexity
multiprong combination. Even case, systems discussed
paper, indeed broad class systems (vulnerability-combining systems)
expect include nearly natural systems, show classify even
face difficulty. provide useful tool help researchers prove additional
systems vulnerability-combining. Section 4.4 summarizes that. Table 5 summarizes results regarding five election systems focused paper; see
also Tables 2 3.
However, also seen exists natural election system, OriginalLlull,
unless P = NP constructive vulnerability-combining. system vulnerable
constructive AC control constructive AV control yet resistant constructive
AC+AV control.
342

fiMultimode Control Attacks Elections

Control type

AC
DC
AV
DV
BV

plurality
Con.
R
R
V
V
V

Des.
R
R
V
V
V

Condorcet
Con.

V
R
R
R

Des.
V

V
V
V

Copeland ,
0 1
Con.
Des.
R
V
R
V
R
R
R
R
R
R

approval
Con.

V
R
R
R

Des.
V

V
V
V

maximin
Con.
R
V
R
R
R

Des.
V
V
R
R
R

Table 5: Resistance basic control types five main election systems studied
paper. table, means system immune given control type, R
means resistance, V means vulnerability. Constructive results AC, DC,
AV, DV plurality Condorcet due Bartholdi et al. (1992)
corresponding destructive results due Hemaspaandra et al. (2007).
results AC, DC, AV, DV approval due Hemaspaandra et al.
(2007). results regarding Copeland due Faliszewski, Hemaspaandra,
Hemaspaandra, Rothe (2009a). Constructive bribery results plurality
approval due Faliszewski, Hemaspaandra, Hemaspaandra (2009a),
constructive bribery result Condorcet implicit work Faliszewski,
Hemaspaandra, Hemaspaandra, Rothe (2009a). remaining entries
(i.e., results regarding maximin, destructive bribery results plurality,
approval, Condorcet) due paper (and bold-italic table).
main contribution paper, however, analysis multiprong control
types. particular, constructive (or destructive) collections prongs
systems combine specified Classification Rule Section 4.2.
holds due Theorem 4.7, paragraphs immediately following it, fact
prove five systems table constructive vulnerabilitycombining destructive vulnerability-combining (Theorems 4.11 5.1).

also shown far fixed-parameter tractability goes, least respect
parameter number candidates, broad class election systems vulnerable
full attack basic prongs, namely, AC+DC+AV+DV+BV control attack.
Finally, appendix, prove candidate whose Dodgson score
kCk2 times Dodgson winners score maximin winner.
paper studies multipronged control prongs may include various standard
types control bribery. However, straightforward see framework
naturally extended include manipulation, commend direction
interested reader (and mention passing Section 4 Faliszewski, Hemaspaandra, &
Hemaspaandra, 2009a, find connection bribery manipulation).
so, one would allow votersthe manipulatorsto blank preference
orders and, voters included election, controlling agent would
decide fill in. (That is, controlling agent model would
control control aspects manipulation aspects.) interesting
model controlling agent might able add manipulative voters (if
manipulators among voters added) even choose delete (it may
343

fiFaliszewski, Hemaspaandra, & Hemaspaandra

seem deleting manipulators never useful Zuckerman, Procaccia, & Rosenschein,
2009, give example deleting manipulator necessary make ones favorite
candidate winner Copeland election).
mention natural involved open direction study multipronged control
setting multiple controlling agents, different goal,
controlling different prong. setting, interesting consider game-theoretic
scenarios well situations which, example, one controlling agents seeking
action succeed regardless action attacker. Another important
direction following. Section 6 specific (namely, fixed-parameter) case
studies sets quite flexible framework classifying broad range control-attack
problems polynomial time. would interesting see highly flexible
schemes matching results one find broadly classify control complexity
elections general case (for motivation, see example work broadly classifying
manipulation complexity scoring protocols, Hemaspaandra & Hemaspaandra, 2007;
Conitzer, Sandholm, & Lang, 2007; Procaccia & Rosenschein, 2007).

Acknowledgments
Supported part NSF grants CCF-0426761, IIS-0713061, CCF-0915792, Polish
Ministry Science Higher Education grant N-N206-378637, Foundation Polish Sciences Homing/Powroty program, AGH University Science Technology grant
11.11.120.865, ESFs EUROCORES program LogICCC, Friedrich Wilhelm Bessel
Research Awards Edith Hemaspaandra Lane A. Hemaspaandra. preliminary version (Faliszewski, Hemaspaandra, & Hemaspaandra, 2009b) paper appeared
proceedings 21st International Joint Conference Artificial Intelligence, July 2009.
helpful comments suggestions, deeply indebted JAIR handling
editor Vincent Conitzer, Edith Elkind, anonymous IJCAI JAIR referees.

Appendix A. Connection Maximin Voting Dodgson Voting
Section 5 focused control maximin voting. appendix, focus different
facet maximin voting, namely, show connection maximin famous
voting rule (i.e., election system) Dodgson.
Dodgson voting, proposed 19th century Charles Lutwidge Dodgson (1876),22
works follows. Let E = (C, V ) election, C = {c1 , . . . , cm } V =
(v1 , . . . , vn ). candidate ci C, Dodgson score ci , denoted scoreD
E (ci ),
smallest number sequential swaps adjacent candidates preference lists voters
V needed make ci become Condorcet winner. candidates lowest
score Dodgson elections winners. is, Dodgson defined system elect
candidates closest Condorcet winners sense adjacent-swaps
distance. Although Dodgsons eighteenth-century election system directly defined
terms distance, remains ongoing interest understanding classes voting rules
captured various distance-based frameworks (see, e.g., Meskanen & Nurmi,
2008; Elkind, Faliszewski, & Slinko, 2009, 2010c, 2010b).
22. Dodgson better known Lewis Carroll, renowned author Alices Adventures Wonderland.

344

fiMultimode Control Attacks Elections

Unfortunately, known deciding whether given candidate winner according Dodgsons rule quite complex. fact, Hemaspaandra, Hemaspaandra, Rothe
(1997), strengthening NP-hardness result Bartholdi et al. (1989b), showed
problem complete parallelized access NP. is, complete p2 level
polynomial hierarchy. Nonetheless, many researchers sought efficient ways
computing Dodgson winners, example using frequently correct heuristics (Homan
& Hemaspaandra, 2009; McCabe-Dansted, Pritchard, & Slinko, 2008), fixed-parameter
tractability (see Bartholdi et al., 1989b; Faliszewski, Hemaspaandra, & Hemaspaandra,
2009a; Betzler, Guo, & Niedermeier, 2010, discussion Footnote 17 Faliszewski,
Hemaspaandra, Hemaspaandra, & Rothe, 2009a), approximation algorithms Dodgson scores (Caragiannis, Covey, Feldman, Homan, Kaklamanis, Karanikolas, Procaccia, &
Rosenschein, 2009).
addition high computational cost determining winners, Dodgsons rule
often criticized basic properties one would expect good voting rule
have. example, Dodgsons rule weak-Condorcet consistent (Brandt et al.,
2010)equivalently, satisfy Fishburns strict Condorcet principleand
satisfy homogeneity monotonicity (see Brandt, 2009, surveys number
defects Dodgsons rule). provide definitions latter two notions (in former
case case need here, namely, anonymous rules), relevant
section.
Homogeneity. say anonymous voting rule R homogeneous positive
integer k election E = (C, V ), C = {c1 , . . . , cm } V = (v1 , . . . , vn ),
holds R winner set E E 0 = (C, V 0 ), V 0 =
(v1 , . . . , v1 , v2 , . . . , v2 , . . . , vn , . . . , vn ).
| {z } | {z }
| {z }
k

k

k

Monotonicity. say voting rule R monotone election E = (C, V ),
C = {c1 , . . . , cm } V = (v1 , . . . , vn ), holds candidate ci C
winner E ci also winner election E 0 identical E
except voters rank ci higher (without changing relative order
remaining candidates).
Continuing Caragiannis et al. (2009) line research approximately computing Dodgson scores, Caragiannis, Kaklamanis, Karanikolas, Procaccia (2010) devised approximation algorithm computing Dodgson scores that, given election
E = (C, V ), C = {c1 , . . . , cm } V = (v1 , . . . , vn ) candidate ci C, computes polynomial time nonnegative integer scE (ci ) scoreD
E (ci ) scE (ci )

scE (ci ) = O(m log m) scoreE (ci ). is, algorithm given Caragiannis et al. (2010)
is, natural sense, O(m log m)-approximation Dodgson score.23 algorithm
23. Throughout section, use notion f (m)-approximation g sense typically used
dealing minimization problems. is, mean approximation outputs value
least g f (m) g. slightly informal (i.e., sloppy) regarding interplay
notation Big-Oh notation; however, sloppiness quite standard type
cause confusion. assume type input g type input approximation
clear context; paper, cases, arguments election E candidate ci .

345

fiFaliszewski, Hemaspaandra, & Hemaspaandra

additional properties: one defines voting rule elect candidates
lowest scores according algorithm, voting rule Condorcet consistent (i.e.,
Condorcet winner exists, one winner voting
rule), homogeneous, monotone.
mentioned result Caragiannis et al. (2010) interesting. next theorem
show maximinwhich like Caragiannis et al. rule Condorcet-consistent,
homogeneous, monotonealso elects candidates are, certain different yet
precise sense, close Dodgson winners. interesting maximin often
considered quite different Dodgsons rule. proof inspired
Caragiannis et al. (2010).
Theorem A.1. Let E = (C, V ) election let W C set candidates
win E according maximin rule. Let = kCk let = minci C scoreD
E (ci ).

2
ci W holds scoreE (ci ) s.
Proof. Let us fix election E = (C, V ) C = {c1 , . . . cm } V = (v1 , . . . , vn ).
two candidates ci , cj C define df E (ci , cj ) smallest number k
k voters V changed preference order rank ci ahead cj , ci would
preferred cj half voters. Note ci , cj C
df E (ci , cj ) > 0
jnk
NE (ci , cj ) + df E (ci , cj ) =
+ 1.
2
candidate ci C define sc0E (ci )
sc0E (ci ) = m2 max{df E (ci , cj ) | cj C {ci }}.
prove sc0 m2 -approximation Dodgson score.
0
2

Lemma A.2. ci C holds scoreD
E (ci ) scE (ci ) scoreE (ci ).

Proof. Let us fix ci C. see secondP
inequality lemma statement

holds, note max{df E (ci , cj ) | cj C {ci }}
cj C{ci } df E (ci , cj ) scoreE (ci )
candidate ck we, least, perform df E (ci , ck ) swaps ensure
ci defeats ck majority head-to-head contest. Thus, multiplying m2 ,
m2 max{df E (ci , cj ) | cj C {ci }} m2 scoreD
E (ci ).
Let us consider first inequality. Let ck candidate C {ci }. make
sure ci ranked higher ck half voters, shift ci
first position preference lists max{df E (ci , cj ) | cj C {ci }} df E (ci , ck )
voters (or, remaining voters less max{df E (ci , cj ) | cj C {ci }} voters
rank ci top choice). requires adjacent swaps per voter. Since
1 candidates C {ci }, m2 max{df E (ci , cj ) | cj C {ci }} adjacent swaps
certainly sufficient make ci Condorcet winner.
(Lemma A.2)
remains show candidate ci maximin winner E sc0E (ci )
minimal. Fortunately, straightforward see. candidate ci Condorcet
winner E unique maximin winner unique
346

fiMultimode Control Attacks Elections

candidate ci sc0E (ci ) = 0. Let us assume Condorcet winner E. Let
us fix candidate ci C let ck C {ci } candidate sc0E (ci ) =
m2 df E (ci , ck ). is, df E (ci , ck ) = max{df E (ci , cj ) | cj C {ci }} df E (ci , ck ) > 0.
Due last fact choice ck , df E (ci , ck ) = n2 + 1 NE (ci , ck )
jnk
NE (ci , ck ) =
+ 1 df E (ci , ck ) = min NE (ci , cj ) = scoreE (ci ),
2
cj C{ci }
scoreE (ci ) maximin score ci E. Thus candidate ci lowest
value sc0E (ci ) also highest maximin score.
Theorem A.1 says every maximin winners Dodgson score less Dodgson score Dodgson winner(s) (that fact course holds trivially),
m2 times Dodgson score Dodgson winner(s). is, proven
candidate whose Dodgson score m2 times Dodgson winner(s)
maximin winner.

References
Bartholdi, III, J., & Orlin, J. (1991). Single transferable vote resists strategic voting. Social
Choice Welfare, 8 (4), 341354.
Bartholdi, III, J., Tovey, C., & Trick, M. (1989a). computational difficulty manipulating election. Social Choice Welfare, 6 (3), 227241.
Bartholdi, III, J., Tovey, C., & Trick, M. (1989b). Voting schemes
difficult tell election. Social Choice Welfare, 6 (2), 157165.
Bartholdi, III, J., Tovey, C., & Trick, M. (1992). hard control election?
Mathematical Computer Modeling, 16 (8/9), 2740.
Baumeister, D., Erdelyi, G., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2010).
Computational aspects approval voting. Laslier, J., & Sanver, M. (Eds.), Handbook Approval Voting, pp. 199251. Springer.
Betzler, N., & Dorn, B. (2009). Towards dichotomy finding possible winners elections based scoring rules. Proceedings 34th International Symposium
Mathematical Foundations Computer Science, pp. 124136. Springer-Verlag Lecture
Notes Computer Science #5734.
Betzler, N., Guo, J., & Niedermeier, R. (2010). Parameterized computational complexity
Dodgson Young elections. Information Computation, 208 (2), 165177.
Betzler, N., Hemmann, S., & Niedermeier, R. (2009). multivariate complexity analysis
determining possible winners given incomplete votes. Proceedings 21st
International Joint Conference Artificial Intelligence, pp. 5358. AAAI Press.
Betzler, N., & Uhlmann, J. (2009). Parameterized complexity candidate control elections related digraph problems. Theoretical Computer Science, 410 (52), 4353.
Black, D. (1958). Theory Committees Elections. Cambridge University Press.
Brandt, F. (2009). remarks Dodgsons voting rule. Mathematical Logic Quarterly,
55 (4), 460463.
347

fiFaliszewski, Hemaspaandra, & Hemaspaandra

Brandt, F., Brill, M., Hemaspaandra, E., & Hemaspaandra, L. (2010). Bypassing combinatorial protections: Polynomial-time algorithms single-peaked electorates. Proceedings 24th AAAI Conference Artificial Intelligence, pp. 715722. AAAI
Press.
Caragiannis, I., Covey, J., Feldman, M., Homan, C., Kaklamanis, C., Karanikolas, N., Procaccia, A., & Rosenschein, J. (2009). approximability Dodgson Young
elections. Proceedings 20th Annual ACM-SIAM Symposium Discrete
Algorithms, pp. 10581067. Society Industrial Applied Mathematics.
Caragiannis, I., Kaklamanis, C., Karanikolas, N., & Procaccia, A. (2010). Socially desirable
approximations Dodgsons voting rule. Proceedings 11th ACM Conference
Electronic Commerce, pp. 253262. ACM Press.
Conitzer, V., & Sandholm, T. (2006). Nonexistence voting rules usually hard
manipulate. Proceedings 21st National Conference Artificial Intelligence,
pp. 627634. AAAI Press.
Conitzer, V., Sandholm, T., & Lang, J. (2007). elections candidates
hard manipulate? Journal ACM, 54 (3), Article 14.
Dobzinski, S., & Procaccia, A. (2008). Frequent manipulability elections: case two
voters. Proceedings 4th International Workshop Internet Network
Economics, pp. 653664. Springer-Verlag Lecture Notes Computer Science #5385.
Dodgson, C. (1876). method taking votes two issues. Pamphlet printed
Clarendon Press, Oxford, headed yet published (see discussions
McLean & Urken, 1995, Black, 1958, reprint paper).
Dorn, B., & Schlotter, I. (2010). Multivariate complexity analysis swap bribery.
Proceedings 5th International Symposium Parameterized Exact Computation, pp. 107122. Springer-Verlag Lecture Notes Computer Science #6478.
Elkind, E., Faliszewski, P., & Slinko, A. (2009). distance rationalizability voting
rules. Proceedings 12th Conference Theoretical Aspects Rationality
Knowledge, pp. 108117. ACM Press.
Elkind, E., Faliszewski, P., & Slinko, A. (2010a). Cloning elections. Proceedings
24th AAAI Conference Artificial Intelligence, pp. 768773. AAAI Press.
Elkind, E., Faliszewski, P., & Slinko, A. (2010b). Good rationalizations voting rules.
Proceedings 24th AAAI Conference Artificial Intelligence, pp. 774779.
AAAI Press.
Elkind, E., Faliszewski, P., & Slinko, A. (2010c). role distances defining voting
rules. Proceedings 9th International Conference Autonomous Agents
Multiagent Systems, pp. 375382. International Foundation Autonomous Agents
Multiagent Systems.
Erdelyi, G., Nowak, M., & Rothe, J. (2009). Sincere-strategy preference-based approval
voting fully resists constructive control broadly resists destructive control. Mathematical Logic Quarterly, 55 (4), 425443.
348

fiMultimode Control Attacks Elections

Erdelyi, G., Piras, L., & Rothe, J. (2010a). Bucklin voting broadly resistant control.
Tech. rep. arXiv:1005.4115 [cs.GT], arXiv.org.
Erdelyi, G., Piras, L., & Rothe, J. (2010b). Control complexity fallback voting. Tech.
rep. arXiv:1004.3398 [cs.GT], arXiv.org.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2009a). hard bribery
elections? Journal Artificial Intelligence Research, 35, 485532.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2009b). Multimode attacks
elections. Proceedings 21st International Joint Conference Artificial Intelligence, pp. 128133. AAAI Press.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2010a). Multimode control attacks
elections. Tech. rep. arXiv:1007.1800 [cs.GT], Computing Research Repository,
http://arXiv.org/corr/.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2010b). Using complexity
protect elections. Communications ACM, 53 (11), 7482.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2007). Llull
Copeland voting broadly resist bribery control. Proceedings 22nd AAAI
Conference Artificial Intelligence, pp. 724730. AAAI Press.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009a). Llull
Copeland voting computationally resist bribery constructive control. Journal
Artificial Intelligence Research, 35, 275341.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009b). richer understanding complexity election systems. Ravi, S., & Shukla, S. (Eds.), Fundamental Problems Computing: Essays Honor Professor Daniel J. Rosenkrantz,
pp. 375406. Springer.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2011). shield
never was: Societies single-peaked preferences open manipulation
control. Information Computation, 209 (2), 89107.
Faliszewski, P., Hemaspaandra, E., & Schnoor, H. (2008). Copeland voting: Ties matter.
Proceedings 7th International Conference Autonomous Agents Multiagent Systems, pp. 983990. International Foundation Autonomous Agents
Multiagent Systems.
Faliszewski, P., Hemaspaandra, E., & Schnoor, H. (2010). Manipulation Copeland elections. Proceedings 9th International Conference Autonomous Agents
Multiagent Systems, pp. 367374. International Foundation Autonomous Agents
Multiagent Systems.
Friedgut, E., Kalai, G., & Nisan, N. (2008). Elections manipulated often. Proceedings 49th IEEE Symposium Foundations Computer Science, pp. 243249.
IEEE Computer Society.
Garey, M., & Johnson, D. (1979). Computers Intractability: Guide Theory
NP-Completeness. W. H. Freeman Company.
349

fiFaliszewski, Hemaspaandra, & Hemaspaandra

Hagele, G., & Pukelsheim, F. (2001). electoral writings Ramon Llull. Studia Lulliana,
41 (97), 338.
Hemaspaandra, E., & Hemaspaandra, L. (2007). Dichotomy voting systems. Journal
Computer System Sciences, 73 (1), 7383.
Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (1997). Exact analysis Dodgson
elections: Lewis Carrolls 1876 voting system complete parallel access NP.
Journal ACM, 44 (6), 806825.
Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2007). Anyone him: complexity
precluding alternative. Artificial Intelligence, 171 (56), 255285.
Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009). Hybrid elections broaden
complexity-theoretic resistance control. Mathematical Logic Quarterly, 55 (4), 397
424.
Hemaspaandra, E., Spakowski, H., & Vogel, J. (2005). complexity Kemeny elections.
Theoretical Computer Science, 349 (3), 382391.
Homan, C., & Hemaspaandra, L. (2009). Guarantees success frequency algorithm finding Dodgson-election winners. Journal Heuristics, 15 (4), 403423.
Isaksson, M., Kindler, G., & Mossel, E. (2010). geometry manipulationA quantitative proof GibbardSatterthwaite Theorem. Proceedings 51st IEEE
Symposium Foundations Computer Science, pp. 319328. IEEE Computer Society Press.
Kemeny, J. (1959). Mathematics without numbers. Daedalus, 88, 577591.
Lenstra, Jr., H. (1983). Integer programming fixed number variables. Mathematics
Operations Research, 8 (4), 538548.
Liu, H., Feng, H., Zhu, D., & Luan, J. (2009). Parameterized computational complexity
control problems voting systems. Theoretical Computer Science, 410 (2729),
27462753.
Liu, H., & Zhu, D. (2010). Parameterized complexity control problems maximin
election. Information Processing Letters, 110 (10), 383388.
Maudet, N., Lang, J., Chevaleyre, Y., & Monnot, J. (2010). Possible winners new
candidates added: case scoring rules. Proceedings 24th AAAI
Conference Artificial Intelligence, pp. 762767. AAAI Press.
McCabe-Dansted, J., Pritchard, G., & Slinko, A. (2008). Approximability Dodgsons
rule. Social Choice Welfare, 31 (2), 311330.
McLean, I., & Lorrey, H. (2006). Voting medieval papacy religious orders. Report
2006-W12, Nuffield College Working Papers Politics, Oxford, Great Britain.
McLean, I., & Urken, A. (1995). Classics Social Choice. University Michigan Press.
Meir, R., Procaccia, A., Rosenschein, J., & Zohar, A. (2008). complexity strategic
behavior multi-winner elections. Journal Artificial Intelligence Research, 33,
149178.
350

fiMultimode Control Attacks Elections

Menton, C. (2010).
Normalized range voting broadly resists control.
arXiv:1005.5698 [cs.GT], arXiv.org.

Tech. rep.

Meskanen, T., & Nurmi, H. (2008). Closeness counts social choice. Braham, M., &
Steffen, F. (Eds.), Power, Freedom, Voting. Springer-Verlag.
Niedermeier, R. (2006). Invitation Fixed-Parameter Algorithms. Oxford University Press.
Papadimitriou, C. (1994). Computational Complexity. Addison-Wesley.
Procaccia, A., & Rosenschein, J. (2007). Junta distributions average-case complexity
manipulating elections. Journal Artificial Intelligence Research, 28, 157181.
Saari, D., & Merlin, V. (2000). geometric examination Kemenys rule. Social Choice
Welfare, 17 (3), 403438.
Schoning, U. (1986). Complete sets closeness complexity classes. Mathematical
Systems Theory, 19 (1), 2942.
Shoham, Y., & Leyton-Brown, K. (2009). Multiagent Systems: Algorithmic, GameTheoretic, Logical Foundations. Cambridge University Press.
Walsh, T. (2009). really hard manipulation problems? phase transition
manipulating veto rule. Proceedings 21st International Joint Conference
Artificial Intelligence, pp. 324329. AAAI Press.
Xia, L., & Conitzer, V. (2008a). Generalized scoring rules frequency coalitional
manipulability. Proceedings 9th ACM Conference Electronic Commerce,
pp. 109118. ACM Press.
Xia, L., & Conitzer, V. (2008b). sufficient condition voting rules frequently
manipulable. Proceedings 9th ACM Conference Electronic Commerce,
pp. 99108. ACM Press.
Xia, L., Zuckerman, M., Procaccia, A., Conitzer, V., & Rosenschein, J. (2009). Complexity
unweighted manipulation common voting rules. Proceedings 21st
International Joint Conference Artificial Intelligence, pp. 348353. AAAI Press.
Young, H., & Levenglick, A. (1978). consistent extension Condorcets election principle.
SIAM Journal Applied Mathematics, 35 (2), 285300.
Zuckerman, M., Procaccia, A., & Rosenschein, J. (2009). Algorithms coalitional
manipulation problem. Artificial Intelligence, 173 (2), 392412.

351

fiJournal Articial Intelligence Research 40 (2011) 57-93

Submitted 08/10; published 01/11

False-Name Manipulations Weighted Voting Games
Haris Aziz

aziz@in.tum.de

Institut fur Informatik
Technische Universitat Munchen, Germany

Yoram Bachrach

yorambac@gmail.com

Microsoft Research
Cambridge, UK

Edith Elkind

eelkind@ntu.edu.sg

School Physical Mathematical Sciences
Nanyang Technological University, Singapore

Mike Paterson

msp@dcs.warwick.ac.uk

Department Computer Science
University Warwick, UK

Abstract
Weighted voting classic model cooperation among agents decision-making
domains. games, player weight, coalition players wins
game total weight meets exceeds given quota. players power games
usually directly proportional weight, measured power index,
prominent among ShapleyShubik index Banzhaf index.
paper, investigate much player change power, measured
ShapleyShubik index Banzhaf index, means false-name manipulation,
i.e., splitting weight among two identities. indices, provide upper
lower bounds eect weight-splitting. show checking whether
benecial split exists NP-hard, discuss ecient algorithms restricted cases
problem, well randomized algorithms general case. also provide
experimental evaluation algorithms.
Finally, examine related forms manipulative behavior, annexation,
player subsumes players, merging, several players unite one.
characterize computational complexity manipulations provide limits
eects. Banzhaf index, describe new paradox, term
Annexation Non-monotonicity Paradox.

1. Introduction
Collaboration cooperative decision-making important issues many types interactions among self-interested agents (Ephrati & Rosenschein, 1997). many situations,
agents must take joint decision leading certain outcome, may dierent
impact agents. standard well-studied way means
voting, recent years, lot research applications voting
multiagent systems well computational aspects various voting procedures (see
Faliszewski & Procaccia, 2010). One key issues domain measure
power voter, i.e., impact nal outcome. particular, question
becomes important agents decide distribute payos resulting
c
2011
AI Access Foundation. rights reserved.

fiAziz, Bachrach, Elkind, & Paterson

joint action: natural approach would pay agent according
contribution, i.e., voting power.
issue traditionally studied within framework weighted voting games (WVGs)
(Taylor & Zwicker, 1999), provide model decision-making many political
legislative bodies (Leech, 2002; Laruelle & Widgren, 1998; Algaba, Bilbao, & Fernandez,
2007), also investigated context multiagent systems (Elkind, Goldberg, Goldberg, & Wooldridge, 2008b, 2007). game, agents
weight, coalition agents wins game sum weights participants
meets exceeds certain quota. numerous examples multiagent systems
captured weighted voting games. example, agents weights may correspond amount resources (time, money, battery power) contribute,
quota may indicate amount resources needed complete given task. Alternatively, weight may indicator agents experience seniority, voting
procedure may designed take account characteristics.
Clearly, larger weight makes easier player aect outcome. However, players power always proportional weight. example, quota
high winning coalition one includes players, intuitively,
players equal power, irrespective weight. idea formalized using
concept power index, systematic way measuring players inuence
weighted voting game. several ways dene power indices. One popular approaches relies fact weighted voting games form subclass coalitional
games, therefore one use terminology solution concepts
developed context general coalitional games. particular, important notion
coalitional games Shapley value (Shapley, 1953), classic method
distributing gains grand coalition general coalitional games. Shapley
value natural interpretation context weighted voting, known
ShapleyShubik power index (Shapley & Shubik, 1954). Another well-known power
index, introduced specically context weighted voting games,
Banzhaf index (Banzhaf, 1965). several power indices proposed
(e.g., see Johnston, 1978; Deegan & Packel, 1978; Holler & Packel, 1983), Shapley
Shubik power index Banzhaf power index usually viewed two standard
approaches measuring players power weighted voting games, widely
studied normative computational perspective.
suggested above, power indices measure players power used determine payos. However, applicable real-world scenarios, approach
payo division resistant dishonest behavior, manipulation, participating players. paper study eects particular form manipulation
weighted voting games, namely, false-name voting. manipulation, player splits
weight fake agent enters game. manipulations
virtually impossible detect open anonymous environments internet.
also occur legislative bodies, political parties vote bills. bodies,
elections held every several years determine weight party voting
bill. elections held, party may split two smaller parties.
likely supporters party would somehow split two new parties,
total weight new parties equal original party. choosing
58

fiFalse-Name Manipulations WVGs

suitable platform, original party decide weight would split
two new parties.
weight-splitting manipulation change total weight identities
cheating agent, power (as measured ShapleyShubik power index
Banzhaf index) may change. Therefore, behavior presents challenge designers
multiagent systems rely weighted voting. main goal paper
measure eects false-name voting analyze computational feasibility. also
examine related scenarios players merging order increase joint power,
one player annexing another one.
main results follows:
precisely quantify worst-case eect false-name voting agents payos.
Namely, show n-player game splitting two false identities
increase agents payo factor 2 ShapleyShubik index
Banzhaf index. Moreover, bound asymptotically tight.
hand, show false-name manipulation decrease agents payo
factor (n) indices.
demonstrate nding successful manipulation trivial task proving
indices NP-hard verify benecial split exists. However,
show weights polynomially bounded, problem solved
polynomial time, discuss ecient randomized algorithms problem.
present similar NP-hardness results case players merging single
new player. Interestingly, case player annexing one players,
contrast ShapleyShubik index Banzhaf index. Whereas
ShapleyShubik index, annexing always benecial, checking whether annexing
benecial case Banzhaf index NP-hard. However benecial
player annexes player bigger weight. also present new paradox called
Annexation Non-monotonicity Paradox, shows annexing small
player useful annexing big player.
complement theoretical results experiments indicate expected
fractions positive negative false-name manipulations weighted voting games
randomly selected weights.
1.1 Related Work
Weighted voting games date back least John von Neumann Oskar Morgenstern,
developed theory monumental book Theory Games Economic
Behavior (von Neumann & Morgenstern, 1944). Subsequently, WVGs analyzed
extensively game theory literature (see, instance, Taylor & Zwicker, 1999).
seminal paper, Shapley (1953) considered coalitional games question fair
allocation utility gained grand coalition. solution concept introduced
paper became known Shapley value game. subsequent paper (Shapley
& Shubik, 1954) studies Shapley value context simple coalitional games,
usually referred ShapleyShubik power index. Banzhaf power index
59

fiAziz, Bachrach, Elkind, & Paterson

originally introduced Banzhaf (1965); somewhat dierent denition later proposed
Dubey Shapley (1979). paper, make use Banzhafs original denition,
appropriate context payo division.
power indices well studied. Stran (1977) shows index
reects certain conditions voting body. Laruelle (1999) describes certain axioms
characterize two indices, well several others. indices used analyze
voting structures European Union Council Ministers IMF (Machover
& Felsenthal, 2001; Leech, 2002).
applicability power indices measuring political power various domains
raised question nding tractable ways compute them. However, problem
appears computationally hard. Indeed, naive algorithm calculating Shapley
value (or ShapleyShubik power index) considers permutations players
hence runs exponential time. Moreover, Papadimitriou Yannakakis (1994) show
computing Shapley value weighted voting games #P-complete. result
extended Matsui Matsui (2001), show calculating Banzhaf index
weighted voting games also NP-hard. Furthermore, Faliszewski Hemaspaandra
(2009) show comparing players power two dierent weighted voting games
PP-complete indices.
Despite hardness results, several papers show compute power indices
restricted domains, discuss ways approximate them. include generating
functions approach (Mann & Shapley, 1962), trades required storage running time,
Owens multilinear extension (MLE) approach (Owen, 1975) Monte Carlo simulation
approaches (Mann & Shapley, 1960; Fatima, Wooldridge, & Jennings, 2007; Bachrach,
Markakis, Resnick, Procaccia, Rosenschein, & Saberi, 2010). Matsui Matsui (2000)
provide good survey algorithms calculating power indices weighted voting games.
Many approaches work well practice, justies use indices
payo distribution schemes multiagent domains.
useful succinct model coalitional voting games, WVGs attracted
lot interest multiagent community. number papers considered
problem designing WVGs desirable properties (Aziz, Paterson, & Leech, 2007;
Fatima, Wooldridge, & Jennings, 2008; de Keijzer, Klos, & Zhang, 2010). Simple games
obtained combining multiple weighted voting games examined
Elkind et al. (2008b) Faliszewski, Elkind, Wooldridge (2009). Another well-studied
topic computing various stability-related solution concepts WVGs extensions
(Elkind et al., 2007; Elkind & Pasechnik, 2009; Elkind, Chalkiadakis, & Jennings, 2008a).
False-name manipulations open anonymous environments examined
dierent domains auctions (Yokoo, 2007; Iwasaki, Kempe, Saito, Salek, & Yokoo,
2007) coalitional games (Yokoo, Conitzer, Sandholm, Ohta, & Iwasaki, 2005; Ohta,
Iwasaki, Yokoo, Maruono, Conitzer, & Sandholm, 2006; Ohta, Conitzer, Satoh, Iwasaki, &
Yokoo, 2008). latter domain, characteristic function provide
enough information analyze false-name manipulation. deal issue, Yokoo
et al. (2005) introduced framework player subset skills,
characteristic function assigns values subset skills. model seen
special case framework; however, due special properties weighted voting games
able obtain much stronger results general case.
60

fiFalse-Name Manipulations WVGs

phenomenon considered paper studied political scientists
economists name paradox size (Shapley, 1973; Brams, 1975; Felsenthal
& Machover, 1998); however, neither quantitative computational aspects
considered. Felsenthal Machover also discuss number paradoxes
weighted voting games; Laruelle Valenciano (2005) give overview recent
work paradoxes weighted voting. Occurrences paradoxes voting bodies
considered Kilgour Levesque (1984),van Deemen Rusinowska (2003), Leech
Leech (2005). Another form manipulation WVGs recently studied
Zuckerman, Faliszewski, Bachrach, Elkind (2008), analyze center might
change players power modifying quota even weights xed.
1.2 Follow-up Work
Many results appear paper previously presented AAMAS conference (Bachrach & Elkind, 2008; Aziz & Paterson, 2009). Inspired work, Lasisi
Allan (2010) recently undertaken experimental analysis false-name manipulations weighted voting games. also considered less popular power indices,
DeeganPackel index. another follow-up paper, Rey Rothe (2010) investigate false-name manipulations weighted voting games respect probabilistic
Banzhaf index, i.e., one suggested Dubey Shapley (1979). Although probabilistic Banzhaf index useful measuring actual probability inuencing
decision, framework using power indices share resources power,
probabilistic Banzhaf index normalized.

2. Preliminaries Notation
start introducing notions used throughout paper.
2.1 Coalitional Games
coalitional game G = (N, v) given set players N = {1, . . . , n}, characteristic function v : 2N R, maps subset, coalition, players real value.
value total utility players guarantee working together.
coalitional game G = (N, v) called monotone v(S) v(T ) . Further,
G called simple monotone v take values 0 1, i.e., v : 2N {0, 1}.
games, say coalition N wins v(S) = 1, loses v(S) = 0.
player critical, pivotal, coalition adding player turns
losing coalition winning coalition: v(S) = 0, v(S {i}) = 1. player veto
player necessary forming winning coalition, i.e., v(S) = 0 N \ {i}
(for monotone games, equivalent requiring v(N \ {i}) = 0).
2.2 Weighted Voting Games
weighted voting game G simple game described vector players weights
w = (w1 , . . . , wn ) (R+ )n quota q R+ . write G = [q; w1 , . . . , wn ], G = [q; w].
games, coalition winning
total weight meets exceeds quota. Formally,
N v(S) = 1 wi q v(S) = 0 otherwise. often
61

fiAziz, Bachrach, Elkind, & Paterson


write w(S) denote total weight coalition S, i.e., w(S) = wi . Also, set
wmax = maxi=1,...,n wi . make standard assumption w(N ) q, i.e.,
grand coalition winning. Note q = w(N ), player N veto player.
2.3 Power Indices
player, ShapleyShubik index Banzhaf index determined
players expected marginal contribution possible coalitions; however, two
indices make use dierent probabilistic models.
ShapleyShubik index specialization Shapley valuea classic solution concept
coalitional gamesto simple games. detail, let n set possible
permutations (orderings) n players. n one-to-one mapping {1, . . . , n}
{1, . . . , n}. Denote (i) set predecessors player , i.e., (i) = {j |
(j) < (i)}. Shapley value i-th player game G = (N, v) denoted
(G) given following expression:
1
[v(S (i) {i}) v(S (i))].
(1)
(G) =
n!
n

occasionally abuse notation say player pivotal permutation
pivotal coalition (i).
ShapleyShubik power index simply Shapley value simple coalitional
game (and therefore rest paper use terms interchangeably).
games value coalition either 0 1, formula (1) simply counts
fraction orderings players player critical coalition formed
predecessors. ShapleyShubik power index thus reects assumption
forming coalition, ordering players entering coalition equal
probability occurring, expresses probability player critical.
contrast, Banzhaf index computes probability player critical
assumption coalitions players equally likely. Formally, given game
G = (N, v), N denote (G) number coalitions
critical game G. Banzhaf index player WVG G = (N, v)
(G)
.
jN j (G)

(G) =

exist several approaches determining players inuence
game, ShapleyShubik index Banzhaf index many useful properties
make convenient work with. make use three properties,
namely, normalization property, symmetry property, dummy player property. normalization property simply states sum ShapleyShubik indices (or
Banzhaf indices) players equal 1. symmetry property says two players
i, j make contribution coalition, i.e., v(S {i}) = v(S {j})
N \ {i, j}, equal values index. dummy player property claims
dummy player indices equal 0, player called dummy
contributes nothing coalition, i.e., N v(S {i}) = v(S).
easy verify denitions ShapleyShubik index Banzhaf
index properties.
62

fiFalse-Name Manipulations WVGs

3. Weight-Splitting: Examples
real-world situations modeled weighted voting games, players may able split,
dividing resources (weight) arbitrarily among new identities. payo would
distributed among agents according power resulting game. Intuitively, total payment obtained new identities equal payo
original player split. However, demonstrate
case payo distributed according either ShapleyShubik index
Banzhaf index.
rst show players use weight-splitting increase power.
Example 1. [Advantageous splitting] Consider WVG [6; 2, 2, 2]. symmetry,
player Banzhaf index 1/3, ShapleyShubik index 1/3. last
player splits two players, new game [6; 2, 2, 1, 1]. game,
original game, winning coalition grand coalition, hence players
equally powerful. Thus, split-up players Banzhaf index 1/4 each, well
ShapleyShubik index 1/4 each, i.e., weight-splitting increases manipulators power
factor (2 1/4)/(1/3) = 3/2 according indices.
However, weight-splitting may also harmful.
Example 2. [Disadvantageous splitting] Consider WVG [5; 2, 2, 2]. Again, symmetry, player Banzhaf index 1/3, ShapleyShubik index 1/3.
last player splits two players, new game [5; 2, 2, 1, 1]. new
players pivotal exactly one coalition, players weight 2 pivotal
three coalitions. Thus, new players Banzhaf index 1/8 each. Similarly,
new players pivotal permutation appears third
position, followed new player, i.e., new players ShapleyShubik index
2/24 = 1/12. Thus, weight splitting decreases players power factor 4/3
according Banzhaf index factor 2 according ShapleyShubik index.
Finally, weight-splitting may eect players power.
Example 3. [Neutral splitting] Consider WVG [4; 2, 2, 2]. previous examples, symmetry, player Banzhaf index 1/3, ShapleyShubik index
1/3. last player splits two players, new game [4; 2, 2, 1, 1].
game, new players pivotal 2 coalitions, players weight
2 pivotal 4 coalitions. Thus, split-up players Banzhaf index 1/6 each.
Similarly, new players pivotal permutation appears
third position, followed one players weight 2. exactly 4
permutations, ShapleyShubik index new players 1/6.
2 1/6 = 1/3, i.e., according indices, players total power change.
examples presented far, weight-splitting eect Shapley
Shubik index Banzhaf index manipulator. show
always case.
Example 4. Consider WVG [5; 2, 1, 1, 1, 1]. game, rst player pivotal
permutation appears last second-to-last position, earlier positions.
63

fiAziz, Bachrach, Elkind, & Paterson

Thus, ShapleyShubik index 2/5. Further, player pivotal coalition
contains three four players weight 1, i.e., 5 coalitions. hand,
player weight 1 pivotal coalition contains player weight 2 well
two players weight 1, i.e., 3 coalitions. Thus Banzhaf index rst
player given 5/(5 + 4 3) = 5/17.
Now, rst player splits two players weight one, resulting game
players weight. Therefore, value indices 1/6,
hence total power manipulator 1/3.
remains observe 2/5 > 1/3, 5/17 < 1/3, i.e., weight-splitting hurts
manipulator payo distributed according ShapleyShubik index, helps
Banzhaf index used. Further, example generalized weighted
voting game form [n; 2, 1, . . . , 1], n 1 players weight 1 n 5:
game, weight-splitting lowers payo rst player according
2
, increases payo according Banzhaf
ShapleyShubik index n2 n+1
n
2
index (n1)2 +1 n+1 .

4. Splitting: Bounds Manipulation
seen player increase decrease total payo splitting
weight. subsection, provide upper lower bounds much change
payo so. restrict attention case splitting two identities;
general case briey discussed Section 9.
simplify notation, rest section assume original game
G = [q; w1 , . . . , wn ] manipulator player n, splits two new identities n
n , resulting new game G . rst consider case ShapleyShubik index,
followed analysis Banzhaf index.
4.1 ShapleyShubik Index
start providing tight upper bound benets manipulation.
Theorem 5. game G = [q; w1 , . . . , wn ] split n n n ,
2n
n (G ) + n (G ) n+1
n (G), i.e., manipulator cannot gain factor
2n/(n + 1) < 2 splitting weight two identities. Moreover, bound tight,
i.e., exists game player n increases payo factor 2n/(n + 1)
splitting two identities.
Proof. Fix split n n n . Let n1 set permutations rst
n 1 players. Consider n1 . Let P () set permutations
players G obtained inserting n n . Let n+1 set
permutations players G n n pivotal . Finally, let P (, k)
subset P () n+1 consists permutations P () least
one players n n appears k-th (k + 1)-st element
pivotal . Every permutation n+1 appears one sets P (, k)
64

fiFalse-Name Manipulations WVGs

, k,
n (G ) + n (G ) =


|n+1 |
1
|P (, k)|.

(n + 1)!
(n + 1)!
,k

hand, hard see |P (, k)| 2n , k: two
ways place n n k-th (k +1)-st element , n1 permutations
P (, k) n appears k-th element , n adjacent it,
n 1 permutations P (, k) n appears k-th element ,
n adjacent it. Moreover, P (, k) empty, n pivotal
permutation f (, k) obtained inserting n k-th element . Further,
(1 , k1 ) = (2 , k2 ) f (1 , k1 ) = f (2 , k2 ). Hence,
n (G)

1
n!


,k:P (,k)=

1

1
n+1
|P (, k)|
(n (G ) + n (G )).
n! 2n
2n
,k

2n
n (G) 2n (G), i.e., manipulator cannot
conclude n (G ) + n (G ) n+1
gain factor 2n/(n + 1) < 2 splitting weight two identities.
see bound tight, consider game G = [2n; 2, 2, . . . , 2] suppose
one players (say, n) decides split two identities n n resulting game
G = [2n; 2, . . . , 2, 1, 1]. games winning coalition consists players,
2n
n (G).
n (G) = 1/n, n (G ) = n (G ) = 1/(n + 1), i.e., n (G ) + n (G ) = n+1

seen player increase payo factor 2
splitting weight two identities. contrast, show player
decrease payo factor (n) so. shows would-be manipulator
careful deciding whether split weight, motivates algorithmic
questions studied next two sections.
Theorem 6. game G = [q; w1 , . . . , wn ] split n n n ,
n (G ) + n (G ) n+1
2 n (G), i.e., manipulator cannot lose factor
(n + 1)/2 splitting weight two identities. Moreover, bound tight,
Proof. prove rst part theorem, x split n n n consider
permutation players G n pivotal . easy see
least one n n pivotal permutation f () obtained replacing
n n n (in order). Similarly, least one n n pivotal
permutation g() obtained replacing n n n (in order). Moreover,
permutations players G distinct, i.e., , g() = f ( ),
= implies f () = f ( ), g() = g( ). Hence, n set permutations
players G n pivotal , n+1 set permutations
players G n n pivotal , |n+1 | 2|n |
n (G ) + n (G ) =

|n+1 |
2|n |
2

=
n (G).
(n + 1)!
(n + 1)!
n+1

see bound tight, consider game G = [2n 1; 2, 2, . . . , 2] suppose
one players (say, n) decides split two identities n n resulting
65

fiAziz, Bachrach, Elkind, & Paterson

game G = [2n 1; 2, . . . , 2, 1, 1]. original game G, winning coalition
consists players, n (G) = 1/n. Now, consider permutation
players G . claim n pivotal appears n-th
position , followed n . Indeed, (n ) = n, (n ) = n + 1, players
rst n 1 positions weight 2, w(S (n )) = 2n 2, w(S (n ) {n }) = 2n 1.
Conversely, (n ) = n + 1, w(S (n )) = 2n 1 = q, (n ) n 1,
w(S (n ) {n }) 2(n 1). Finally, (n ) = n, (n ) = n + 1,
w(S (n ) {n }) = 2n 2 < q. Consequently, n pivotal (n 1)! permutations, and,
argument, n also pivotal (a disjoint set of) (n 1)! permutations. Hence,
2
n (G ) + n (G ) = 2(n1)!
(n+1)! = n+1 n (G).
4.2 Banzhaf Index
Banzhaf index, obtain similar bounds maximum gains losses
weight-splitting manipulation.
Theorem 7. game G = [q; w1 , . . . , wn ] split n n n ,
n (G ) + n (G ) 2n (G). Moreover, bound asymptotically tight.
Proof. Assume player n splits n n wn wn . Consider losing
coalition C n critical G. w(C) < q w(C) + wn = w(C) + wn + wn .
following possibilities:
q w(C) wn . case n n critical C G .
wn < q w(C) wn . case n critical C {n } C G .
q w(C) > wn . case n critical C {n } n critical C {n }
G .
Therefore n (G ) + n (G ) = 2n (G) case.
consider player N \ {n}. Suppose critical coalition C G.
n C, also critical coalition C = C \ {n} {n , n } G .
hand, n C, also remains critical C G . Hence (G) (G ). Moreover,
may also critical coalitions G contain one n n ,
inequality general equality. Thus,
n (G ) + n (G ) =



2n (G) +

2n (G)


\{n} (G

)

2n (G)

2n (G) + \{n} (G)
n (G) +

2n (G)


\{n} (G)

= 2n (G).

see boundis tight,
consider WVG
n2G = [n 1; 1, . . . , 1, 2] n players.

n (G) = n 1 + n1
(G)
=
1
+


= n. Therefore,

2
2
n1
n1+ 2
n
n1
n2 = 2
n (G) =
1/n.
n 4n + 8
n 1 + 2 + (n 1)(1 + 2 )
66

fiFalse-Name Manipulations WVGs

player n splits two players n n weights 1 each, resulting
1
. Thus large n, n (G ) + n (G ) =
game G Banzhaf index player n+1
2
n+1 2n (G).
also bound damage incurred weight-splitting.
Theorem 8. game G = [q; w1 , . . . , wn ] split n n n ,
n (G ) + n (G ) n1 n (G).
Proof. Suppose player n splits two players n n weights wn wn ,
respectively. assume without loss generality wn wn . Now, consider
arbitrary player = n, let
Ti = {S N \ {i} | w(S) < q, w(S) + wi q},
Si = {S N \ {n, i} {n , n } | w(S) < q, w(S) + wi q}.
(G) = |Ti |, (G ) = |Si |. Further, set
Si1 = {S Si | pivotal \ {n , n }},

Si2 = {S Si | pivotal \ {n , n } n S, n S},

Si3 = {S Si | pivotal \ {n , n } n S, n S},
Si4 = {S Si | pivotal \ {n , n } n , n S}.

claim Si = 4j=1 Sij . Indeed, Si1 , pivotal S, \{n , n },
hence must case {n , n } =
; sets included Si1 Si2 Si3 .


Si , let f (S) = \ {n , n }, g(S) = \ {n , n } {n}. Si1 ,
f (S) Ti , set Ti 4 sets f (S) = , i.e.,
|f 1 (T )| 4. Further, Si4 implies g(S) Ti , |g 1 (T )| 1 Ti . Finally,
g(S ) = f (S ) , Si . Taken together, observations imply
|Si1 | + |Si4 | 4|Ti | = 4i (G).
Now, consider Si2 . w(S) < q, w(S) + wi < q, w(S) + wi + wn q.
Hence, n critical {i}. Similarly, Si3 , follows n critical {i}.
Therefore, |Si2 | + |Si3 | n (G ) + n (G ). obtain
(G ) = |Si |

4

j=1

|Sij | 4i (G) + n (G ) + n (G ) = 4i (G) + 2n (G),

last equality follows proof Theorem 7. Thus, obtain
n (G ) + n (G ) =



2n (G) +

2n (G)


2n (G) + 4
2n

\{n} (G

)

2n (G)
\{n} (G) + 2(n 1)n (G)



2 (G)
(G)
n
=
.

(G)
n


67

fiAziz, Bachrach, Elkind, & Paterson

clear bound given Theorem 8 tight, next example shows
splitting two
players decrease players payo according Banzhaf index
n
.
factor almost 2
Example 9. Consider WVG G = [3k; 1, . . . , 1, 4k] n = 2k players. Let N1
set players weight 1, i.e., N1 = {1, . . . , n 1}. easy see player n
critical coalition, players dummies, n (G) = 1.
suppose player n splits new identities n n weights wn = wn = 2k.
player n critical coalition G , case either n S,
k |S N1 | n 1 n S, 0 |S N1 | k 1. Thus,




(G ) = (G ) =
n

n


n

n1
i=0



= 2n1 .

Moreover, player weight 1 critical coalition G , coalition must
include exactly oneof n n well k 1 n 2 players N1 \ {i}. Thus,
(G ) = 2 2k2
asymptotics
k1 < n. Using standard formulas

2k2
2
4k1 . obtain
central binomial coecient, approximate 2 k1 2 (2k1)


2 2n1



n (G ) + n (G )

2n1

+

2n1

2



=

2
+ (n 1) (n1)
2n1
2 + n 1 2




2
.
n

5. Complexity Finding Benecial Split
examine problem nding benecial weight split weighted voting games
computational perspective. Ideally, manipulator would like nd payomaximizing split, i.e., way split weight among two identities results
maximal total payo. less ambitious goal decide whether exists
manipulation increases manipulators payo. However, turns even
problem computationally hard. rest section, show checking whether
exists payo-increasing split NP-hard ShapleyShubik index
Banzhaf index; holds even player allowed use two identities. is,
spirit groundbreaking papers Bartholdi Orlin (1991) Bartholdi,
Tovey, Trick (1989, 1992), show computational complexity acts barrier
manipulative behavior.
formally dene computational problems, require weights
quota original game new game integers given binary, i.e.,
allow integer splits. remark assumption entirely without loss
generality: games player benet fractional split
integer split. One example given game [3; 1, 1, 1],
non-trivial integer splits available players, but, similarly Example 1,
player increase power factor 3/2 splitting two players weight
1/2. However, real-life settings usually natural bound granularity
weights: weight number supporters given party, needs
68

fiFalse-Name Manipulations WVGs

integer, monetary contribution player, usually integer
number dollars (or, least, cents), i.e., assumption reects real-life constraints.
ready dene problems.
Name: Beneficial-SS-Split
Instance: (G, ) G = [q; w1 , . . . , wn ] weighted voting game {1, . . . , n}.
Question: way player split
w sub-players 1 , . . . ,
weight
) > (G)?
new game G holds

(G

j=1 j
denition Beneficial-BI-Split similar.
Name: Beneficial-BI-Split
Instance: (G, ) G = [q; w1 , . . . , wn ] weighted voting game {1, . . . , n}.
Question: way player split
w sub-players 1 , . . . ,
weight


new game G holds j=1 j (G ) > (G)?
Note looking strictly benecial manipulation, i.e., one increases
manipulators total payo, rather one simply harmful.
prove Beneficial-SS-Split Beneficial-BI-Split NP-hard.
hardness results based reductions following classic NP-hard problem:
Name: Partition
Instance: set k integer weights = {a1 , . . . , ak }.
Question: possible
partition
two subsets P1 A, P2 P1 P2 = ,


P1 P2 = A, ai P1 ai = ai P2 ai ?
rst prove simple lemma used NP-hardness proofs
paper.
Lemma 10. Let = {a1 , . . . , ak } no-instance Partition.
weighted
. . , wn ] n > k, wi = 8ai = 1, . . . , k, q = 4 ai ai +
voting game G = [q; w1 , .
r, 0 < r < 4, ni=k+1 wi < 4, holds players k + 1, . . . , n dummies,
hence ShapleyShubik Banzhaf indices equal 0.
Proof. Consider player k < n set N \ {i}. show
pivotal S.
Set N0 = {1, . . . , k} let S0 = N0 . set N0 partitioned two
equal-weight subsets can, either w(S0 ) < w(N0 )/2, w(S0 ) > w(N0 )/2.
Moreover, weights players N0 multiples 8, w(N0 )/2 multiple 4.
Similarly, weight S0 multiple 8. Hence, w(S0 ) < w(N0 )/2, follows
w(S0 ) w(N0 )/2 4 w(S {i}) < w(N0 )/2 4 + 4 < q. Therefore, v(S) = 0,
v(S {i}) = 0, i.e., pivotal S. hand, w(S0 ) > w(N0 )/2,
w(S0 ) w(N0 )/2 + 4 > q, S0 winning coalition. Therefore, pivotal
case well.
Theorem 11. Beneficial-BI-Split NP-hard, remains NP-hard even player
split two players equal weights.
Proof. Given instance Partition = {a1 , . . . , ak }, construct aweighted voting
game G = [q; w1 , . . . , wn ] n = k + 1 players follows. let X = ai ai , set
wi = 8ai = 1, . . . , n 1, wn = 2, q = 4X + 2. Also, set = n. Since wn = 2,
69

fiAziz, Bachrach, Elkind, & Paterson

integer split available player n two identities n n weight 1
each. Let G = [q; w1 , . . . , wn1 , 1, 1] resulting game.
no-instance Partition, Lemma 10 implies player n dummy,
and, moreover, splits sub-players, sub-players also dummies. Therefore
(G, ) no-instance Beneficial-BI-Split.
let us assume yes-instance Partition. Let x denote number
coalitions N \ {n} weight 4X. n (G) = x. = 1, . . . , n 1, let
Si = {S N \ {n, i} | w(S) < 4X, w(S) + wi q},

set yi = |Si |. Also, set = n1
i=1 yi .
Consider player < n. Observe exactly half x subsets {1, . . . , n 1}
weight 4X contain i. subset , player pivotal (T \ {i}) {n}. Further,
coalition Si , player pivotal {n}. Therefore < n
(G) = x2 + 2yi . obtain
n (G) =

x
.
x + (n 1) x2 + 2y

hand, new game G n (G ) = n (G ) = x. Moreover,
< n (G ) = x2 + 4yi , since coalition Si corresponds 4 coalitions
pivotal, namely, S, {n }, {n }, {n , n }. Thus,
n (G ) + n (G ) =

2x
> n (G),
2x + (n 1) x2 + 4y

last inequality holds since x > 0. Thus, yes-instance Partition corresponds yes-instance Beneficial-BI-Split.
consider problem nding benecial split ShapleyShubik index.
Theorem 12. Beneficial-SS-Split NP-hard, remains NP-hard even player
split two players equal weights.

Proof. Given instance = {a1 , . . . , ak } Partition, set X = ai ai , create
weighted voting game G = [4X + 3; 8a1 , . . . , 8ak , 1, 2] n = k + 2 players. Also, set
N0 = {1, . . . , n 2}.
no-instance Partition, Lemma 10 implies player n dummy,
splits several players, dummies, too. Thus,
constructed no-instance Beneficial SS-Split.
Now, suppose yes-instance Partition. Let P1 , P2 partition
A, w(P1 ) = w(P2 ). corresponds partition S, N0 \ N0 ,
ai P1 ; observe w(S) = w(N0 \ S). Set = |S|, |N0 \ S| = n 2.
easy see n critical {n 1} well (N0 \ S) {n 1}.
(s + 1)!(n 2 s)! permutations 1, . . . , n put n directly permutation
{n 1}. Similarly, s!(n 1 s)! permutations putting n directly
permutation (N0 \ S) {n 1}. Thus, partition P = P1i , P2i , |P1i | = s,
70

fiFalse-Name Manipulations WVGs

least (s + 1)!(n 2 s)! + s!(n 1 s)! distinct permutations n critical.
hand, argued above, subset N0 w(S) = w(N0 )/2,
n critical {n 1}, since either w(S) w(N0 )/2 4 < q 3
w(S) w(N0 )/2 + 4 > q.
Let P set partitions A, partition counted once, i.e.,
P contains exactly one P1 , P2 P2 , P1 . P = P1i , P2i P, denote
|P1i | = si . total n! permutations players G. Thus, ShapleyShubik
index n G
(si + 1)!(n 2 si )! + si !(n 1 si )!
=
n (G) =
n!

P P

si !(n 2 si )!(si + 1 + n 1 si )
=
n!


P P

nsi !(n 2 si )!
si !(n 2 si )!
=
.
n!
(n 1)!



P P

P P

consider happens n splits two players, n n wn =
wn = 1, resulting game G = [4X + 3; 8a1 , . . . , 8ak , 1, 1, 1].
Again, let P1 , P2 , |P1 | = si , |P2 | = n si , partition w(P1 ) = w(P2 ),
let S, N0 \ corresponding partition N0 . (si + 2)!(n 2 si )!
permutations place n directly permutation {n 1, n }, n
critical them. Similarly, n critical si !(n si )! permutations place
n directly permutation (N0 \ S) {n 1, n }.
Thus, partition P = P1i , P2i |P1i | = si , corresponds (si + 2)!(n 2
si )! + si !(n si )! distinct permutations n critical. symmetry, (si +
2)!(n 2 si )! + si !(n si )! distinct permutations n critical. n + 1
players G , total (n + 1)! permutations players. Thus partition
)!
ShapleyShubik index n G,
P = P1i , P2i , |P1i | = si , contributes si !(n2s
(n1)!
)!+si !(nsi )!
2 (si +2)!(n2s
sum ShapleyShubik indices n n G .
(n+1)!
show partition P

2

(si + 2)!(n 2 si )! + si !(n si )!
si !(n 2 si )!
>
.
(n + 1)!
(n 1)!

(2)

Summing inequalities partitions P implies n (G ) + n (G ) > n (G),
desired. prove inequality (2), note simplied
2

(s + 1)(s + 2) + (n 1 s)(n s)
> 1,
n(n + 1)

use instead si simplify notation, or, equivalently,
2(s + 1)(s + 2) + 2(n 1 s)(n s) n(n + 1) > 0.
Now, observe
2(s + 1)(s + 2) + 2(n 1 s)(n s) n(n + 1) = (n 2 2s)2 + n > 0
71

fiAziz, Bachrach, Elkind, & Paterson

n > 0. proves inequality (2) n > 0. follows yesinstance Partition, player n always gains splitting two players weight 1, i.e.,
(G, n) yes-instance Beneficial-SS-Split.
Remark 13. veried proofs go even allow noninteger splits, i.e., hardness results independent integrality assumption. Further, note shown Beneficial-BI-Split Beneficial-SS-Split
NP, i.e., proved problems NP-complete. two
reasons this. First, allow splits arbitrary number identities,
candidate solutions may exponentially many new players (e.g., player weight
wi split wi players weight 1). Second, even circumvent issue
considering splits polynomial number identities, clear verify
polynomial time whether particular split benecial. fact, since computing power
indices weighted voting games #P-hard, quite possible problems
NP.

6. Computing Benecial Splits
Section 5, shown hard even test benecial split exists, let alone
nd optimal split. seen positive result, since complexity nding
benecial splits serves barrier kind manipulative behavior. However, turns
many cases manipulators overcome problem. precisely,
follows show certain restricted domains manipulators nd benecial splits
two identities polynomial time. consider manipulation algorithms work
approximating ShapleyShubik index (rather calculating precisely).
6.1 Examples
subsection, describe two scenarios one players always increase
payo splitting. examples rely rather severe constraints
players weights threshold, practical weighted voting scenarios satisfy
constraints.
Example 14. hard see Example 1 generalized weighted
voting game w(N ) = q; games sometimes called unanimity games. Even
generally, player always increase payo weight-splitting threshold
set high winning coalition must include players; holds
ShapleyShubik index Banzhaf index. Indeed, consider class weighted voting
games G = [q; w] characterized following condition: w(N ) < q w(N ),
= min{mini wi , wmax /2}. condition mini wi ensures players
present winning coalitions, index value player 1/n. Now, suppose
player largest weight wi = wmax splits weight (almost) equally
two identities, i.e., sets wi = wi /2, wi = wi /2. also wmax /2,
winning coalition still include players. Therefore, new game payo
player 1/(n + 1), hence split increases total payo manipulator
factor 2n/(n + 1).
72

fiFalse-Name Manipulations WVGs

Example 15. second example specic ShapleyShubik index. example,
small player benet manipulation presence large players, long
threshold suciently high. Formally, consider class weighted voting games
form G = [q; w], wi , = 1, . . . , n 1, multiples integer A,
threshold q form + b, b < A, b < wn < min{2b 1, A}. Suppose
winning coalitions size least n/2 + 1.
condition holds renumber
players w1 w2 wn1 require q > i=1,...,n/2 wi .
Now, suppose player n pivotal least one coalition game (if weights
small multiples A, condition checked easily). Consider permutation
n pivotal . w(S (n)) = . Indeed, w(S (n)) > ,
w(S (n)) + > q, coalition (n) need player n win.
hand, w(S (n)) < , w(S (n)) A, w(S (n)) + wn < + b = q.
|
Let P set permutations; n (G) = |P
n! .
suppose n decides split weight two new identities n n
setting wn = b 1, wn = wn b + 1; note wn , wn < b. Consider permutation
. Suppose n occurs k-th position permutation. assumption,
k n/2 + 1. construct 2k permutations j , j , j = 1, . . . , k, follows.
permutations, players 1, . . . , n 1 appear order . Moreover,
j , player n occurs j-th position, player n occurs (k + 1)-st position.
Similarly, j , player n occurs j-th position, player n occurs (k + 1)-st
position.
Observe n pivotal j , j = 1, . . . , k. Indeed, total weight players
precede n j +wn < q, w(Sj (n ){n }) > q. Similarly, w(Sj (n )) < q,
n pivotal j , j = 1, . . . , k. Hence, total number permutations
1, . . . , n 1, n , n either n n pivotal least 2k|P | (n + 2)|P |,
|
|P |
total ShapleyShubik index players least (n+2)|P
(n+1)! > n! = n (G). Hence,
split strictly benecial player n.
addition scenarios discussed above, Fatima et al. (2007) describe several classes
voting games ShapleyShubik indices players computed polynomial time; Aziz Paterson (2008) prove similar results Banzhaf index. Clearly,
manipulators weight polynomially bounded, original game well
games result manipulator splitting two identities easy, i.e., belong
one classes considered Fatima et al. Aziz Paterson, problem nding
benecial two-way split solved polynomial time. However, examples illustrate player may able decide whether benecial split even cannot
compute payo prior manipulation.
6.2 Pseudopolynomial Approximation Algorithms
hardness reductions Section 5 Partition. problem known
NP-hard, hardness relies crucially fact weights elements
represented binary. Indeed, weights given unary, dynamic
programming-based algorithm problem runs time polynomial size
input (such algorithms usually referred pseudopolynomial ). particular,
weights polynomial n, running time algorithm polynomial n.
73

fiAziz, Bachrach, Elkind, & Paterson

many natural voting domains weights players large, scenario
quite realistic. therefore natural ask exists pseudopolynomial algorithm
problem nding benecial split.
turns answer question indeed positive long
constant upper bound K number identities manipulator use
weights required integers. see this, recall pseudopolynomial algorithm computing ShapleyShubik index player weighted voting
game (Matsui & Matsui, 2000). algorithm based dynamic programming:
weight W 1 k n, calculates number coalitions size k
weight W . Thus, easily adapted work Banzhaf index well.
One use algorithm Matsui Matsui (2000) nd benecial split
(1)
player weight wi game G follows. Consider possible splits wi = wi +
(K)
(j)
+ wi , wi N j = 1, . . . , K. number splits (wi )K ,
polynomial n constant K. Evaluate ShapleyShubik indices (respectively,
Banzhaf indices) new players split return yes least
one splits results increased total payo. Let A(G) running time
algorithm Matsui Matsui instance G. running time algorithm
O((wi )K K A(G)), clearly pseudopolynomial.
consider general setting, weight manipulator
polynomially bounded, weights players large. simplify
presentation, limit case two-way splits ShapleyShubik index;
however, approach also applies splits constant number identities
Banzhaf index. use high-level approach previous case, i.e.,
considering possible splits (because weight restriction, polynomially
many them), computing indices new players split. However,
implement latter step exactly, would take exponential time. Therefore,
version algorithm, replace algorithm Matsui Matsui
approximation algorithm computing ShapleyShubik index. Several algorithms
known; see, e.g., work Mann Shapley (1960), Fatima et al. (2007), Bachrach
et al. (2010). use algorithms black-box fashion. Namely, assume
given procedure Shapley(G, i, , ) given values > 0
> 0 outputs number v probability 1 satises |v (G)| runs
time poly(n log wmax , 1/, 1/). show use procedure design
algorithm nding benecial split relate performance algorithm
Shapley(G, i, , ).
algorithm given Figure 1. takes parameters inputs, uses
procedure Shapley(G, i, , ) subroutine. algorithm outputs yes nds split
whose total estimated payo exceeds payo manipulator original game
least 3. easily modied output (approximately) optimal split.
Proposition 16. probability 1 3, output algorithm satises following: (i) algorithm outputs yes, (G, i) admits benecial integer split; (ii)
Conversely, integer split increases payo manipulator
6, algorithm outputs yes. Moreover, running time algorithm
polynomial nwi , 1/, 1/.
74

fiFalse-Name Manipulations WVGs

FindSplit(G = [q; w], i, , );
v =Shapley(G, i, , );
j = 0, . . . , wi
wi = j, wi = wi j;
G = [q; w1 , . . . , wi1 , wi , wi , wi+1 , . . . , wn ];
v = Shapley(G , , , ), v =Shapley(G , , , );
v = v + v ;
v > v + 3 return yes;
return no;
Figure 1: Algorithm FindSplit(G = [q; w], i, , )
Proof. Suppose algorithm outputs yes. Consider quantities v , v v
computed algorithm. P rob[v < (G) ] < , P rob[v > (G ) + ] < ,
P rob[v > (G ) + ] < . Hence, probability least 1 3, v + v > v + 3,
(G) + (G ) + 2 > (G) + 3, or, equivalently, (G ) + (G ) > (G).
Conversely, suppose benecial split form (wi , wi ) improves
player payo least 6. before, probability least 1 3
v (G) + step j = wi holds v (G ) , v (G ) .
v = v + v (G ) + (G ) 2 > (G) + 6 2 v + 3, algorithm
output yes.
algorithm guarantee nding successful manipulation, possible
control approximation quality (at cost increasing running time),
successful manipulation found high probability.
Thus see manipulators several ways overcome computational
diculty nding optimal manipulation. Hence, measures required avoid
manipulations.

7. Merging Annexation
Instead player splitting smaller players, players may merge single
entity. However, situation dierent game-theoretic perspective,
involves coordinated actions several would-be manipulators decide
split (increased) total payo. case players merging gain advantage,
examine two cases. One annexation one player takes voting weight
players. annexation advantageous payo new merged coalition
new game greater payo annexer original game. case
voluntary merging players merge become bloc new payo exceeds
sum individual payos.
weighted voting game G, denote game results merging
players coalition G&S ; set players new game (N \S){&S},
characteristic function denoted v&S . dene computational problems
75

fiAziz, Bachrach, Elkind, & Paterson

checking whether exist benecial voluntary merge annexation respect
ShapleyShubik index.
Name: Beneficial-SS-Merge
Instance: (G, S) G = [q; w1 , . . . , wn ] weighted voting game {1, . . . , n}.
Question: coalition merges form new game G&S , &S (G&S ) > (G)?
Name: Beneficial-SS-Annexation
Instance: (G, S, i) G = [q; w1 , . . . , wn ] weighted voting game, 1 n,
{1, . . . , n} \ {i}.
Question: annexes form new game G&(S{i}) , &(S{i}) (G&(S{i}) ) > (G)?
easily adapt denitions Banzhaf index; refer resulting problems Beneficial-BI-Merge Beneficial-BI-Annexation. rst
consider issues related annexation, followed analysis merging.
7.1 Merging
case splitting, expect hard nd benecial merge. following
theorem conrms intuition.
Theorem 17. Beneficial-SS-Merge Beneficial-BI-Merge NP-hard.
voting
Proof. Given instance Partition = {a1 , . . . , ak }, construct weighted

game G = [q; w1 , . . . , wn ] n = k + 3 players follows. set X = 4 ki=1 ai let
wi = 8ai = 1, . . . , n 3, wn2 = wn1 = wn = 1, q = X + 2. argue
yes-instance Partition (G, {n 1, n}) yes-instance
Beneficial-SS-Merge Beneficial-BI-Merge.
no-instance Partition, Lemma 10 players n n 1
dummies, even merge together, new player &{n 1, n} remains dummy
new game G&{n1,n} . Thus, case (G, {n 1, n}) no-instance
problems.
let us assume yes-instance Partition. rst consider
case ShapleyShubik index, followed analysis Banzhaf index.
Set N0 = {1, . . . , n 3}. Let P1 , P2 partition A, let S, N0 \
corresponding partition N0 . Set = |S|, |N0 \ S| = n 3. Player n critical
{n 2} {n 1}, well (N0 \ S) {n 2} (N0 \ S) {n 1}. Thus,
partition P = P1 , P2 , |P1 | = s, exactly 4(s + 1)!(n 2 s)! distinct
permutations n critical. Further, easy see n critical
permutation. symmetry, true n 1. Thus, partition P1 , P2
sum ShapleyShubik indices n 1
|P1 | = contributes 8 (s+1)!(n2s)!
n!
n.
Now, consider game G&{n1,n} . Consider partition S, N0 \ N0 |S0 | =
corresponds partition P1 , P2 A. Player &{n 1, n} critical
{n 2}, well N0 \ (N0 \ S) {n 2}. Thus, partition P1 , P2
+ 2 (s+1)!(n3s)!
ShapleyShubik index
|P1 | = contributes 2 s!(n2s)!
(n1)!
(n1)!
76

fiFalse-Name Manipulations WVGs

&{n 1, n}. remains show
8

(s + 1)!(n 2 s)!
s!(n 2 s)!
(s + 1)!(n 3 s)!
<2
+2
.
n!
(n 1)!
(n 1)!

inequality simplied 4(s + 1)(n 2 s) < n(n 2 + + 1) = n(n 1),
equivalent 0 < n(n 1) 4(s + 1)(n 2 s) = (n 2s 3)2 + n 1.
inequality clearly holds n 1. Hence, n1 (G) + n (G) < &{n1,n} (G&{n1,n} ), i.e.,
(G, {n 1, n}) yes-instance Beneficial-SS-Merge started
yes-instance Partition.
show true Banzhaf index. Let x denote number
coalitions N0 weight 4X. n2 (G) = n1 (G) = n (G) = 2x. = 1, . . . , k,
let
Si = {S N0 \ {i} | w(S) < 4X, w(S) + wi q},

set yi = |Si |. Also, set = ki=1 yi .
Consider player N0 . Observe exactly half x subsets N0 weight 4X
contain i. set , player pivotal (T \ {i}) {n 2, n 1}, (T \ {i}) {n
2, n}, (T \ {i}) {n 1, n}, (T \ {i}) {n 2, n 1, n}. Further, coalition Si ,
player pivotal coalition form , {n2, n1, n}. Therefore
2x
N0 (G) = 4x
2 + 8yi . Thus, n1 (G) = n (G) = 6x+2kx+8y .
new game G&{n1,n} , &{n1,n} (G&{n1,n} ) = 2x, n2 (G&{n1,n} ) =
0. Now, consider player N0 coalition N0 weight 4X contains i.
Player pivotal (T \ {i}) {&{n 1, n}} (T \ {i}) {n 2, &{n 1, n}}.
well coalition form , Si {n 2, &{n 1, n}}.
Hence, (G&{n1,n} ) = 2x
2 + 4yi .
obtain
2x
4x
&{n1,n} (G&{n1,n} ) =
>
= n1 (G) + n (G).
2x + kx + 4y
6x + 2kx + 8y
Thus, (G, {n 1, n}) yes-instance Beneficial-BI-Merge started
yes-instance Partition.
7.2 Annexation
Felsenthal Machover (1998) prove annexation never disadvantageous respect
ShapleyShubik index. completeness, give simple proof fact.
Proposition 18. weighted voting game G set players N , N ,
N \ {i} (G) &(S{i}) (G&(S{i}) ).
Proof. give proof case |S| = 1, i.e., = {j} j N \ {i}; general
case follows easily induction. Let set permutations N
critical G; (G) = |i |/n!. , let f () permutation
players N&{i,j} obtained deleting j replacing new player
&{i, j}. player &{i, j} pivotal f (). Moreover, permutation
N&{i,j} |f 1 ()| = n. Hence,
&{i,j} (G&{i,j} )

|{f () | }|
||/n
=
= (G).
(n 1)!
(n 1)!
77

fiAziz, Bachrach, Elkind, & Paterson

However Felsenthal Machover (1998) show that, case Banzhaf index,
annexation could disadvantageous; refer phenomenon Bloc Paradox.
provide 13-player WVG case, simplest example
could nd. improve result describing 7-player WVG annexation
disadvantageous.
Example 19. Consider weighted voting game [11; 6, 5, 1, 1, 1, 1, 1]. game, player 1
pivotal coalition involves player 2 subset remaining players,
well coalition {3, . . . , 7}, i.e., 33 coalitions. Player 2 pivotal coalition
involves player 1 4 remaining players, i.e., 31 coalitions. Finally,
players weight 1 pivotal coalition includes player 1 rest
33
0.47826.
players weight 1. Thus, Banzhaf index player 1 equals 33+31+5
player 1 annexes one players weight 1, new game [11; 7, 5, 1, 1, 1, 1].
Applying reasoning above, obtain player 1 pivotal 17 coalitions,
player 2 pivotal 15 coalition, remaining players pivotal exactly one
17
coalition, Banzhaf index player 1 new game 17+15+4
0.47222 < 0.47826.
shown annexation disadvantageous case Banzhaf
index. One would least expect Banzhaf index payo annexing another
player monotone power annexed player. Surprisingly, case.
is, show exists weighted voting game G = [q; w1 , . . . , wn ]
i, j, k {1, . . . , n} wj > wk , &{i,j} (G&{i,j} ) < &{i,k} (G&{i,k} ).
refer phenomenon Annexation Non-monotonicity Paradox. Observe
distinct Bloc Paradox: former choosing two given
players annex, latter choosing annexing given player
annexing player all.
Example 20. Consider weighted voting game [9; 3, 3, 2, 1, 1, 1]. Suppose rst player
1 annexes player 2 form game [9; 6, 2, 1, 1, 1]. game, player 1 pivotal
1 coalition include player 2, 7 coalitions include player 2, i.e., 8
coalitions. Further, player 2 pivotal 6 coalitions, remaining players
8
pivotal 2 coalitions. Thus, Banzhaf index player 1 8+6+6
= 0.4.
Now, suppose player 1 annexes player 3 form game [9; 5, 3, 1, 1, 1].
game, player 1 pivotal 7 coalitions, player 2 pivotal 7 coalitions,
remaining players pivotal 1 coalition. Thus, Banzhaf index player 1
7
0.411765 > 0.4.
game 7+7+3
contrast, ShapleyShubik index monotone respect annexation.
Proposition 21. weighted voting game G = [q; w1 , . . . , wn ] i, j, k
{1, . . . , n} wj wk &{i,j} (G&{i,j} ) &{i,k} (G&{i,k} ).
Proof. Consider permutation N&{i,k} &{i, k} pivotal. Let
permutation N&{i,j} obtained replacing &{i, k} &{i, j} j k. Since
w&{i,j} w&{i,k} , player j appears player &{i, k}, player &{i, j}
pivotal . hand, player j appears player &{i, k},
78

fiFalse-Name Manipulations WVGs

w(S (&{i, j})) w(S (&{i, k})) < q, w(S (&{i, j}) {&{i, j}}) = w(S (&{i, k})
{&{i, k}}) q, &{i, j} pivotal case well. Hence, permutation
&{i, k} pivotal corresponds distinct permutation &{i, j} pivotal,
i.e., &{i,j} (G&{i,j} ) &{i,k} (G&{i,k} ).
bound gains losses annexation, observe player increase
payo (with respect indices) much 1. happens dummy
player annexes suciently large player coalition players. hand,
Theorem 7 immediately implies that, player annexes player j game G,
&{i,j} (G&{i,j} ) 12 (i (G) + j (G)). following useful corollary.
Corollary 22. weighted voting game G set players N i, j N
&{i,j} (G&{i,j} ) 12 (G), i.e., player decrease payo
factor 2 annexing another player. Moreover, wi wj , &{i,j} (G&{i,j} ) (G),
show determining whether player benet annexing given
coalition (with respect Banzhaf index) NP-hard.
Theorem 23. Beneficial-BI-Annexation NP-hard.
Proof. proof similar Theorem 11. Given instance Partition =
{a1 , . . . , ak }, construct
weighted voting game G = [q; w1 , . . . , wn ] n = k+2 players
follows. let X = ai ai , set wi = 8ai = 1, . . . , n 2, wn1 = wn = 1
q = 4X + 2.
Lemma 10, no-instance Partition, players n 1 n
dummies, n remains dummy even annexes n 1. Now, suppose
yes-instance Partition. Let x denote number coalitions N \ {n 1, n}
weight 4X. n1 = n (G) = x. = 1, . . . , n 2, let
Si = {S N \ {n 1, n, i} | w(S) < 4X, w(S) + wi q},

set yi = |Si |. Also, set = n2
i=1 yi .
calculations proof Theorem 11 show
x
2x+(n2) x2 +4y ,
x
= x+(n2)
x
+2y .
2

n (G) =
&{n,n1} (G&{n,n1} )

Since x > 0, implies n (G) < &{n,n1} (G&{n,n1} ). Hence, (G, {n 1}, n)
yes-instance Beneficial-BI-Annexation started yesinstance Partition.
conclude section analyzing benets merging annexation unanimity games, i.e., games q = w(N ).
Proposition 24. unanimity game, advantageous player annex
arbitrary coalition, respect ShapleyShubik index Banzhaf index.
However, group players increase total payo (as measured either
indices) merging.
79

fiAziz, Bachrach, Elkind, & Paterson

Proof. game players equal value index annexa1
. However,
tion. Hence, annexes coalition size s, power increases n1 ns

1
merging reduces total power players coalition size n ns
.
remark Proposition 24 generalizes game player veto
player.

8. Empirical Analysis
analyze false-name splitting manipulations empirically. constructed
system randomly constructing weighted voting games examined changes
ShapleyShubik index Banzhaf index occur agents split weights
false identities. briey describe simulation system, game construction
power index calculations, present empirical evidence obtained.
8.1 Simulation System Settings
weighted voting games constructed rst randomly choosing number
players game. Then, weights players drawn N (, 2 ),
normal distribution mean variance 2 . weights rounded
nearest integer, make sure game integer weights. threshold
game chosen uniformly random 0 sum players weights
w = w(N ), rounded nearest integer. experiments, used
mean = 200 weights, several values standard deviation
set {5, 10, 15, . . . , 50}. number players n chosen uniformly random
set {5, 6, 7, . . . , 24}.
Power indices computationally hard compute exactly (Papadimitriou & Yannakakis, 1994; Matsui & Matsui, 2001), tractably approximated using several
methods. used approximation method Bachrach et al. (2010). algorithm estimates power indices returns result probably approximately
correct, discussed Section 6. Given game players true power index
, given target accuracy level condence level , algorithm returns
approximation probability least 1 | | (i.e.
result approximately correct, within distance correct value). algorithm works drawing sample k permutations (or coalitions), testing whether
target player critical them. test runs time linear number
agents, total running time O(kn log W ). Bachrach et al. show achieve
condence level accuracy level , suces take k = ln(2/)/(22 ). Thus
total running time logarithmic condence quadratic accuracy,
approach tractable even high accuracy condence. used = 0.00001
= 0.001, power estimated accurately. system implemented
C#, results experiments stored SQL database. Since power
indices approximated accurately, single experiment take several seconds.
tests required tens thousands experiments, used compute cluster
250 cores experiments.
80

fiFalse-Name Manipulations WVGs

theoretical results show testing benecial split hard, might create
impression nding benecial manipulation hard practice. empirical
experiments designed see whether indeed case. naive method
manipulator use try many possible splits two identities, constant
intervals. words manipulator whose weight w try 2s splits splitting
2w
3w
3w
weight ( ws , w ws ), ( 2w
, w ), ( , w ) on. Although certainly
complete coverage space possible manipulations, experiments
tried simple algorithm based idea. Since weights integers,
tried splitting weights two false identities, examined integer
splits. example, agent weight wi = 10, attempted splitting weights
w1 = 9, w1 = 1, w1 = 8, w1 = 2, w1 = 7, w1 = 3 on. experiment
recorded details game, number benecial splits (power increase)
harmful splits (power decrease). split considered benecial, increase
power twice accuracy level. Thus, results presented understate
number positive splits. results examine proportion experiments
found least one benecial manipulation, well proportion
splits benecial (out integer splits).
8.2 Empirical Results
rst present results regarding ShapleyShubik index. First foremost,
results indicate weighted voting domain manipulable, least method
generating random weighted voting games. values tried variance
player weights number players game, 95.5% experiments
even naive manipulation algorithm managed uncover least one benecial
manipulation. indicates games enough try integer splits (or
splits uniform intervals) use tractable method approximating power indices
uncover benecial manipulations. Figures 2 3 indicate proportion experiments
algorithm succeeds nding benecial split, function variance
players weights number players, respectively. appears success rate
algorithm slightly increases variance increases. obvious trend appears
number players.
One might tempted think benecial splits quite common, experiments least one benecial split. However, turns splits harmful
splits. tested settings, less 40% splits benecial splits.
settings, harmful splits accounted 70% splits. Figure 4 Figure 5,
indicate proportion benecial splits, function variance players weights
number players, respectively.
also examined distribution proportion benecial splits across
experiments. generated games, benecial splits quite rare, less
single percent splits benecial. generated games, benecial splits
common case, 99% splits benecial. Figure 6 shows distribution
(histogram) proportion benecial splits, across games. create gure,
games partitioned 200 bins, according proportion benecial splits
game. bin size 0.5% (e.g., proportion benecial manipulations
81

fiAziz, Bachrach, Elkind, & Paterson

Figure 2: Proportion experiments naive algorithm nds benecial split
dierent variances players weights (ShapleyShubik index)

Figure 3: Proportion experiments naive algorithm nds benecial split
dierent numbers players (ShapleyShubik index)

82

fiFalse-Name Manipulations WVGs

Figure 4: Proportion benecial splits dierent variances players weights (Shapley
Shubik index)

Figure 5: Proportion benecial splits dierent numbers players (ShapleyShubik
index)

83

fiAziz, Bachrach, Elkind, & Paterson

Figure 6: Distribution (histogram) proportion positive splits across games
(ShapleyShubik index)

100-th bin 0.5 0.55). value X axis Figure 6 proportion
benecial splits (the bin), axis number experiments falling
category. Figure 6 shows games ones benecial splits rare
harmful splits, distribution long tail, even games almost
splits benecial uncommon.
turn examine Banzhaf index. case ShapleyShubik index,
Banzhaf index weighted voting domain susceptible manipulation.
tested settings, 92.5% experiments manipulation algorithm
managed uncover least one benecial manipulation (slightly less 95.5%
ShapleyShubik index). proportion experiments algorithm nds
benecial split respect Banzhaf index shown Figure 7 (for dierent values
variance) Figure 8 (for dierent number players).
Similarly case ShapleyShubik index, Banzhaf index benecial splits
less common case, splits harmful splits, less 45%
splits benecial, typically 40% benecial splits (slightly higher
ShapleyShubik index). Unlike ShapleyShubik index, Banzhaf index,
proportion benecial splits among splits increases variance (Figure 9).
However, proportion clear trend regard number players
(Figure 10).
distribution proportion benecial splits across games Banzhaf index
seems quite similar ShapleyShubik index (see Figure 11). Again,
games, majority splits harmful, distribution long tail, many
84

fiFalse-Name Manipulations WVGs

Figure 7: Proportion experiments naive algorithm nds benecial split
dierent variances players weights (Banzhaf index)

Figure 8: Proportion experiments naive algorithm nds benecial split
dierent numbers players (Banzhaf index)

85

fiAziz, Bachrach, Elkind, & Paterson

Figure 9: Proportion benecial splits dierent variances players weights (Banzhaf
index)

Figure 10: Proportion benecial splits dierent numbers players (Banzhaf index)

86

fiFalse-Name Manipulations WVGs

Figure 11: Distribution (histogram) proportion positive splits across games
(Banzhaf index)

games mostly benecial splits. Although distribution seems similar
ShapleyShubik index, tail distribution seems slightly fatter Banzhaf
index.
conclude, experiments indices present similar picture. games
generated model, mostly harmful splits. However, many experiments
many positive splits, even almost splits benecial. Games
trying integer splits yield successful manipulation rare,
although exist. Thus, games generated model, even extremely
simple manipulation algorithm nds benecial splits. conclude despite hardness
results paper, practice believe quite easy nd splits, thus
believe attacks pose real problem many settings.

9. Splitting Two Identities
far, mostly discussed gain (or loss) player achieve splitting
two identities. However, also possible player use three false names.
Potentially, number identities player use large weight (and
weights required integers, even innite). would interesting see
results hold general setting. example, computational
hardness result holds splits number identities, algorithmic results
previous section apply splits constant number new identities. obvious
open problem design pseudopolynomial algorithm nding benecial integer
87

fiAziz, Bachrach, Elkind, & Paterson

split number identities, prove problem NP-hard even small
weights (i.e., weights polynomial n). Another question interest
extend upper lower bounds Section 4 setting.
One might think nding benecial split k 2 identities easier nding
one uses exactly two identities: all, two-way split transformed
split three players two players non-zero weight. However,
turns restrict attention non-trivial splits, i.e., one
new players non-zero weight, longer case.
Example 25. Consider game G = [6; 5, 5]. game, winning coalition
includes players, ShapleyShubik indices given 1 (G) = 2 (G) = 1/2.
Suppose player 2 splits two identities 2 2 . selection integer
weights w2 > 0, w2 > 0 satisfy w2 + w2 = 5, new game G = [6; 5, w2 , w2 ]
2 (G ) = 2 (G ) = 1/3. Indeed, game player pivotal permutation
occurs second position, happens probability 1/3. Hence,
non-trivial split two identities increases payo second player factor
(2/3)/(1/2) = 4/3.
Now, suppose second player splits 5 new players weight 1 each.
new game, player 1 pivotal permutation occur
rst position permutation, ShapleyShubik index 5/6. Consequently,
sum ShapleyShubik indices remaining players (i.e., new identities player 2)
1/6. Therefore, split decreases payo player 2 factor 3. summarize,
non-trivial integer split 2 identities benecial player 2, integer split
5 identities positive weight harmful him.
Remark 26. Example 25 generalized games form GN = [N + 1; N, N ]
arbitrary integer N > 0. reasoning shows one players decides
split N new players weight 1 each, increases ShapleyShubik index
player N/(N + 1) hence decreases total payo splitting player
factor (N + 1)/2. representation size game polynomial log N ,
decrease exponential description size.

10. Conclusions
considered false-name manipulations weighted voting games respect
payo schemes based ShapleyShubik index Banzhaf index. also
considered manipulation via annexation voluntary merging respect payo
schemes. examined limits manipulation (Table 1) complexity
manipulation (Table 2), complemented theoretical investigation empirical
analysis.
shown that, scenarios considered paper, testing whether
benecial manipulation exists NP-hard. One may ask whether hardness results
provide adequate barrier manipulation, given power indices
hard compute. words, dont simultaneously assume weights small
(and hence computing indices easy) large (and hence manipulation hard)?
resolve apparent contradiction, note power indices considered paper
88

fiFalse-Name Manipulations WVGs

2
n+1 (G)

Bounds
(G ) + (G )

2n
n+1 (G)

(G) (G&({i}S) ) 1.
1
n+1 (G)

(G ) + (G ) 2i (G)

(G)
2

(G&({i,j}) ) 1.

Reference
Theorems 5 6
Proposition 18
Theorems 7 8
Corollary 22

Table 1: Bounds eects false-name manipulations WVGs

Splitting
Merging
Annexation
Splitting unanimity game
Merging unanimity game
Annexation unanimity game
(Felsenthal

Banzhaf index
NP-hard
NP-hard
NP-hard
advantageous
disadvantageous
advantageous

ShapleyShubik index
NP-hard
NP-hard
advantageous
advantageous
disadvantageous
advantageous

& Machover, 1998)

Table 2: Complexity false-name manipulations WVGs
correspond voting power, players may try increase voting power
weight-splitting manipulation even cannot compute it. Also, power index
used compute payments, center, performs computation, may
computational power individual players.
experimental results show that, moderately large weights, weight-splitting manipulation easy practice. However, algorithm relies considering integer splits,
i.e., running time least linear manipulators weight. interesting open question whether case benecial split exists, found testing
number splits logarithmic manipulators weight.
results indicate ShapleyShubik index Banzhaf index behave similarly respect false-name manipulation; however, ShapleyShubik index appears
desirable solution concept annexation decrease payo
player. Exploring solution concepts behavior respect false-name
manipulation natural next step; particularly suitable solution consider could
nucleolus, always exists also unique.
study weighted voting many applications, political science
multiagent systems. several possible interpretations identity-splitting
contexts, obtaining higher share grand coalitions gains
distributed according ShapleyShubik index Banzhaf index, obtaining
political power splitting political party several parties similar political platforms. rst case, false-name manipulation hard detect open anonymous
89

fiAziz, Bachrach, Elkind, & Paterson

environments, thus eective. second case, manipulation done
using legitimate tools political conduct. Therefore, conjecture false-name manipulation widespread real world may become serious issue multiagent
systems. therefore important develop better understanding eects
behavior and/or design methods preventing it.

Acknowledgments
Haris Aziz Mike Paterson partially supported DIMAP (the Centre Discrete
Mathematics Applications). DIMAP funded UK EPSRC grant
EP/D063191/1. Partial support Azizs research also provided Deutsche
Forschungsgemeinschaft grants BR-2312/6-1 (within European Science Foundations EUROCORES program LogICCC) BR 2312/3-2. Edith Elkind partially
supported ESRC grant ES/F035845/1 Singapore NRF Research Fellowship 2009-08.

References
Algaba, E., Bilbao, J. M., & Fernandez, J. R. (2007). distribution power
European Constitution. European Journal Operational Research, 176 (3), 1752
1755.
Aziz, H., & Paterson, M. (2008). Computing voting power easy weighted voting games.
CoRR, abs/0811.2497.
Aziz, H., & Paterson, M. (2009). False name manipulations weighted voting games:
splitting, merging annexation. Proceedings 8th International Joint Conference Autonomous Agents Multi-Agent Systems (AAMAS), pp. 409416.
Aziz, H., Paterson, M., & Leech, D. (2007). Ecient algorithm designing weighted
voting games. Proceedings 11th IEEE International Multitopic Conference,
pp. 16. IEEE Computer Society.
Bachrach, Y., & Elkind, E. (2008). Divide conquer: False-name manipulations
weighted voting games. Proceedings 7th International Joint Conference
Autonomous Agents Multi-Agent Systems (AAMAS), pp. 975982.
Bachrach, Y., Markakis, E., Resnick, E., Procaccia, A. D., Rosenschein, J. S., & Saberi, A.
(2010). Approximating power indices: theoretical empirical analysis. Autonomous
Agents Multi-Agent Systems, 20 (2), 105122.
Banzhaf, J. F. (1965). Weighted voting doesnt work. Rutgers Law Review, 19, 317343.
Bartholdi, J., & Orlin, J. (1991). Single transferable vote resists strategic voting. Social
Choice Welfare, 8 (4), 341354.
Bartholdi, J., Tovey, C., & Trick, M. (1989). computational diculty manipulating
election. Social Choice Welfare, 6 (3), 227241.
Bartholdi, J., Tovey, C., & Trick, M. (1992). hard control election?. Mathematical Computer Modeling, 16 (8/9), 2740.
90

fiFalse-Name Manipulations WVGs

Brams, S. (1975). Game Theory Politics. Free Press, New York.
de Keijzer, B., Klos, T., & Zhang, Y. (2010). Enumeration exact design weighted
voting games. Proceedings 9th International Joint Conference Autonomous
Agents Multi-Agent Systems (AAMAS), pp. 391398.
Deegan, J., & Packel, E. W. (1978). new index power simple n-person games.
International Journal Game Theory, 7, 113123.
Dubey, P., & Shapley, L. S. (1979). Mathematical properties Banzhaf power index.
Mathematics Operations Research, 4 (2), 99131.
Elkind, E., Chalkiadakis, G., & Jennings, N. R. (2008a). Coalition structures weighted
voting games. Proceedings 18th European Conference Articial Intelligence
(ECAI), pp. 393397.
Elkind, E., Goldberg, L. A., Goldberg, P., & Wooldridge, M. (2008b). dimensionality
voting games. Proceedings 23rd AAAI Conference Articial Intelligence
(AAAI), pp. 6974. AAAI Press.
Elkind, E., Goldberg, L. A., Goldberg, P. W., & Wooldridge, M. J. (2007). Computational
complexity weighted threshold games. Proceedings 22nd AAAI Conference
Articial Intelligence (AAAI), pp. 718723. AAAI Press.
Elkind, E., & Pasechnik, D. (2009). Computing nucleolus weighted voting games.
Proceedings 20th Annual ACM-SIAM Symposium Discrete Algorithms
(SODA), pp. 327335.
Ephrati, E., & Rosenschein, J. (1997). heuristic technique multi-agent planning.
Annals Mathematics Articial Intelligence, 20 (14), 1367.
Faliszewski, P., Elkind, E., & Wooldridge, M. (2009). Boolean combinations weighted
voting games. Proceedings 8th International Joint Conference Autonomous
Agents Multi-Agent Systems (AAMAS), pp. 185192.
Faliszewski, P., & Hemaspaandra, L. A. (2009). complexity power-index comparison.
Theoretical Computer Science, 410 (1), 222245.
Faliszewski, P., & Procaccia, A. (2010). AIs war manipulation: winning?. AI
Magazine, 31 (4).
Fatima, S. S., Wooldridge, M., & Jennings, N. R. (2007). randomized method
Shapley value voting game. Proceedings 6th International Joint
Conference Autonomous Agents Multi-Agent Systems (AAMAS), pp. 18.
Fatima, S. S., Wooldridge, M., & Jennings, N. R. (2008). anytime approximation method
inverse Shapley value problem. Proceedings 7th International Joint
Conference Autonomous Agents Multi-Agent Systems (AAMAS), pp. 935942.
Felsenthal, D., & Machover, M. (1998). Measurement Voting Power. Edward Elgar
Publishing, Cheltenham, UK.
Holler, M. J., & Packel, E. W. (1983). Power, luck right index. Journal Economics,
43, 2129.
91

fiAziz, Bachrach, Elkind, & Paterson

Iwasaki, A., Kempe, D., Saito, Y., Salek, M., & Yokoo, M. (2007). False-name-proof mechanisms hiring team. Proceedings 3rd International Workshop Internet
Network Economics (WINE), pp. 245256.
Johnston, R. J. (1978). measurement power: reactions Laver. Environment Planning A, 10, 907914.
Kilgour, D. M., & Levesque, T. J. (1984). Canadian constitutional amending formula:
Bargaining past future. Public Choice, 44 (3), 457480.
Laruelle, A. (1999). choice power index. Working papers, serie AD 1999-10,
Instituto Valenciano de Investigaciones Economicas.
Laruelle, A., & Valenciano, F. (2005). critical reappraisal voting power paradoxes.
Public Choice, 125, 1741.
Laruelle, A., & Widgren, M. (1998). allocation voting power among EU states
fair?. Public Choice, 94 (3-4), 317339.
Lasisi, R., & Allan, V. (2010). False name manipulations weighted voting games: Susceptibility power indices. Thirteenth International Workshop Trust
Agent Societies (TRUST), pp. 139150.
Leech, D. (2002). Voting power governance International Monetary Fund.
Annals Operations Research, 109 (1), 375397.
Leech, D., & Leech, R. (2005). Power vs weight IMF governance: possible benecial implications united European bloc vote. Buira, A. (Ed.), Reforming
Governance IMF World Bank, pp. 251282. Anthem Press.
Machover, M., & Felsenthal, D. S. (2001). Treaty Nice qualied majority voting.
Social Choice Welfare, 18 (3), 431464.
Mann, I., & Shapley, L. S. (1960). Values large games, IV: Evaluating electoral college
Montecarlo techniques. Rand Corporation, RM-2651.
Mann, I., & Shapley, L. S. (1962). Values large games, VI: Evaluating electoral college
exactly. Rand Corporation, RM-3158.
Matsui, T., & Matsui, Y. (2000). survey algorithms calculating power indices
weighted majority games. Journal Operations Research Society Japan, 43 (1),
7186.
Matsui, Y., & Matsui, T. (2001). NP-completeness calculating power indices weighted
majority games. Theoretical Computer Science, 263 (1-2), 305310.
Ohta, N., Conitzer, V., Satoh, Y., Iwasaki, A., & Yokoo, M. (2008). Anonymity-proof
Shapley value: extending Shapley value coalitional games open environments.
Proceedings 7th International Joint Conference Autonomous Agents
Multi-Agent Systems (AAMAS), pp. 927934.
Ohta, N., Iwasaki, A., Yokoo, M., Maruono, K., Conitzer, V., & Sandholm, T. (2006).
compact representation scheme coalitional games open anonymous environments. Proceedings 21st AAAI Conference Articial Intelligence (AAAI),
pp. 697702.
92

fiFalse-Name Manipulations WVGs

Owen, G. (1975). Multilinear extensions Banzhaf value. Naval Research Logistics
Quarterly, 22 (4), 741750.
Papadimitriou, C. H., & Yannakakis, M. (1994). complexity bounded rationality.
Proceedings 26th Annual ACM Symposium Theory Computing
(STOC), pp. 726733. ACM.
Rey, A., & Rothe, J. (2010). Complexity merging splitting probabilistic
banzhaf power index weighted voting games. 19th European Conference
Articial Intelligence (ECAI 2010), pp. 10211022.
Shapley, L. S. (1953). value n-person games. Kuhn, H. W., & Tucker, A. W. (Eds.),
Contributions Theory Games, II, pp. 307317. Princeton University Press.
Shapley, L. S. (1973). Political science: Voting bargaining games. Selby, H. A. (Ed.),
Notes Lectures Mathematics Behavioral Science, pp. 3792. Mathematical
Association America.
Shapley, L. S., & Shubik, M. (1954). method evaluating distribution power
committee system. American Political Science Review, 48 (3), 787792.
Stran, P. D. (1977). Homogeneity, independence power indices. Public Choice, 30,
107118.
Taylor, A., & Zwicker, W. (1999). Simple Games: Desirability Relations, Trading, Pseudoweightings. Princeton University Press, New Jersey.
van Deemen, A., & Rusinowska, A. (2003). Paradoxes voting power dutch politics.
Public Choice, 115 (13), 109137.
von Neumann, J., & Morgenstern, O. (1944). Theory Games Economic Behavior.
Princeton University Press.
Yokoo, M. (2007). False-name bids combinatorial auctions. SIGecom Exchanges, 7 (1),
4851.
Yokoo, M., Conitzer, V., Sandholm, T., Ohta, N., & Iwasaki, A. (2005). Coalitional games
open anonymous environments. Proceedings 20th AAAI Conference
Articial Intelligence (AAAI), pp. 509515.
Zuckerman, M., Faliszewski, P., Bachrach, Y., & Elkind, E. (2008). Manipulating quota
weighted voting games. Proceedings 23rd AAAI Conference Articial
Intelligence (AAAI), pp. 215220.

93

fiJournal Artificial Intelligence Research 40 (2011) 175-219

Submitted 09/10; published 01/11

Second-Order Consistencies
Christophe Lecoutre
Stphane Cardon

lecoutre@cril.fr
cardon@cril.fr

CRIL-CNRS UMR 8188
Universit Lille-Nord de France, Artois
rue de luniversit
SP 16, F-62307 Lens, France

Julien Vion

julien.vion@univ-valenciennes.fr

LAMIH-CNRS FRE 3304
Universit Lille-Nord de France, UVHC
F-59313 Valenciennes Cedex 9, France

Abstract
paper, propose comprehensive study second-order consistencies (i.e.,
consistencies identifying inconsistent pairs values) constraint satisfaction. build
full picture relationships existing four basic second-order consistencies,
namely path consistency (PC), 3-consistency (3C), dual consistency (DC) 2-singleton
arc consistency (2SAC), well conservative strong variants. Interestingly, dual
consistency original property established using outcome enforcement generalized arc consistency (GAC), makes rather easy obtain since
constraint solvers typically maintain GAC search. binary constraint networks,
DC equivalent PC, restriction existing constraints, called conservative dual
consistency (CDC), strictly stronger traditional conservative consistencies derived
path consistency, namely partial path consistency (PPC) conservative path consistency (CPC). introducing general algorithm enforce strong (C)DC, present
results experimentation wide range benchmarks demonstrate
interest (conservative) dual consistency. particular, show enforcing (C)DC
search clearly improves performance MAC (the algorithm maintains GAC
search) several binary non-binary structured problems.

1. Introduction
Many decision problems combinatorial nature, modelled using finite
domain variables connected constraints. models formally represented constraint networks (CNs) finding solution model instance NP-complete
constraint satisfaction problem (CSP). CSP usually solved systematic backtrack search, fundamental technique artificial intelligence. considerable
efforts last three decades improve practical efficiency backtrack search.
Consistencies properties constraint networks exploited (enforced), search, filter search space problem instances inference. Currently,
successful consistencies domain filtering consistencies (Debruyne & Bessiere,
2001; Bessiere, Stergiou, & Walsh, 2008). Common consistencies binary CNs arc
consistency (AC, Mackworth, 1977) singleton arc consistency (SAC, Bessiere & Dec
2011
AI Access Foundation. rights reserved.

fiLecoutre, Cardon, & Vion

bruyne, 2005). Example consistencies non-binary CNs generalized arc consistency
(GAC, Mohr & Masini, 1988) pairwise inverse consistency (PWIC, Stergiou & Walsh,
2006). Consistencies typically allow identification nogoods. nogood instantiation variables cannot lead solution. Identifying relevant nogoods
soon possible exploring search space instance recognized essential
component backtracking search algorithm. domain-filtering consistency also called
first-order consistency, meaning detects inconsistent values (1-sized nogoods):
values safely removed domains variables.
paper concerned second-order consistencies locally identify inconsistent
pairs values. studied second-order consistency path consistency (PC, Montanari, 1974; Mackworth, 1977). now, path consistency, generally higher order
consistencies, rather neglected designers developers general constraint solvers.
somewhat surprising since, many tractable classes, strong path consistency (path
consistency combined arc consistency) sufficient condition determine satisfiability (e.g., see Dechter, 1992; van Beek, 1992; Cooper, Cohen, & Jeavons, 1994; Zhang
& Yap, 2006). Neglecting higher order consistencies may partly due somewhat
limited scope classes: exciting progress area recent (e.g.,
see Green & Cohen, 2008). However, path consistency important role temporal reasoning. Indeed, classes interval algebra, path consistency adapted
temporal constraint networks (Allen, 1983) sufficient decide satisfiability. Another
possible reason low practical interest path consistency, discrete constraint
satisfaction field, path consistency enforcement modifies constraint relations,
importantly, modifies structure constraint graph. pair values
(a, b) variables (x, y) found path-inconsistent, information recorded
within constraint network; constraint binding x y, new one inserted, thus changing constraint graph. example, instance scen-11 radio
link frequency assignment problem (Cabon, de Givry, Lobjois, Schiex, & Warners, 1999)
involves 680 variables 4,103 constraints.
Enforcing second-order consistency

network could worst create 680

4,103
=
226,757 new constraints, would
2
really counter-productive time space. main apparent drawback path
consistency avoided adopting conservative approach, search inconsistent pairs values restricted existing constraints. called conservative path
consistency (CPC, Debruyne, 1999) restricted paths length 2 constraint
graph, partial path consistency (PPC, Bliek & Sam-Haroud, 1999) restricted
paths arbitrary length constraint graph; CPC PPC equivalent
constraint graph triangulated.
paper, study path consistency well three basic second-order consistencies 3-consistency (3C, Freuder, 1978), dual consistency (DC, Lecoutre, Cardon,
& Vion, 2007a) 2-singleton arc consistency (2SAC, Bessiere, Coletta, & Petit, 2005).
binary constraint networks, DC equivalent PC McGregor (1979) proposed DC-like
algorithm establish (strong) path consistency considering weaker conservative
variants, show conservative dual consistency (CDC) strictly stronger PPC
CPC: CDC filter inconsistent pairs values (from existing constraints)
PPC CPC. build full picture qualitative relationships existing
second-order consistencies (including stronger 2SAC property, conserva176

fiSecond-Order Consistencies

tive restrictions strong variants studied consistencies) binary CNs
non-binary CNs.
Interestingly enough, (conservative) dual consistency benefits nice features:
(1) (C)DC built top GAC, implementing filtering algorithm enforce
rather easy, (2) reason, optimizations achieved GAC algorithms
last years come free, (3) guarantee GAC enforced CN verifies
property (C)DC leaves property unchanged. theoretical study
followed presentation general algorithm enforce strong (C)DC
experimental study show practical interest using (C)DC (during preprocessing
step) solving binary non-binary problem instances search algorithm
MAC (Sabin & Freuder, 1994).
paper organized follows. Section 2 introduces technical background
constraint networks, nogoods consistencies. Section 3, introduce (basic, conservative strong) second-order consistencies, focus path consistency
possible misunderstanding it. qualitative study second-order consistencies
conducted Section 4. algorithm enforce (C)DC proposed Section 5,
experimental results presented Section 6. Finally, conclude.

2. Technical Background
section provides technical background constraint networks consistencies.
2.1 Constraint Networks
(finite) constraint network (CN) P composed finite set n variables, denoted
vars(P ), finite set e constraints, denoted cons(P ). variable x
associated domain, denoted dom(x), contains finite set values
assigned x. constraint c involves ordered set variables, called scope c
denoted scp(c). defined relation, denoted rel(c), contains set
tuples allowed variables involved c. arity constraint c size
scp(c). maximum domain size maximum arity given CN denoted
r, respectively. binary constraint involves exactly 2 variables, non-binary
constraint strictly 2 variables. binary CN contains binary constraints
whereas non-binary CN contains least one non-binary constraint.
initial domain variable x denoted dominit (x) whereas current domain
x CN P denoted domP (x) simply dom(x) context
unambiguous. initial relation constraint c denoted relinit (c) whereas
current relation denoted relP (c) simply rel(c). constraint c universal iff
relinit (c) = xscp(c) dominit (x); universal constraint imposes restriction. consider
variable x, always dom(x) dominit (x), constraint c,
always rel(c) relinit (c). simplify, pair (x, a) x vars(P ) dom(x)
called (current) value P . Without loss generality, consider CNs
involve neither unary constraints (i.e., constraints involving unique variable)
177

fiLecoutre, Cardon, & Vion

constraints similar scope CNs normalized (Apt, 2003; Bessiere, 2006). set
normalized CNs neither unary constraints universal constraints1 denoted P.
instantiation set X = {x1 , . . . , xk } variables set {(x1 , a1 ), . . . , (xk , ak )}
1..k, ai dominit (xi ) ; set X variables occurring denoted
vars(I) value ai denoted I[xi ]. instantiation CN P
instantiation set X vars(P ); complete iff vars(I) = vars(P ), partial otherwise.
valid P iff (x, a) I, domP (x). instantiation covers constraint c iff
scp(c) vars(I), satisfies constraint c scp(c) = {x1 , . . . , xr } iff (1) covers c
(2) tuple (a1 , . . . , ar ) allowed c, i.e., (a1 , . . . , ar ) rel(c), 1..r, ai = I[xi ].
support (resp., conflict) constraint c valid instantiation scp(c) satisfies
(resp., satisfy) c. instantiation CN P locally consistent iff (1) valid
P (2) every constraint P covered satisfied I. locally inconsistent
otherwise. solution P complete instantiation P locally consistent.
instantiation CN P globally inconsistent, nogood, iff cannot extended
solution P . globally consistent otherwise. refer standard nogoods (e.g.,
see Dechter, 2003); differ nogoods coming justifications (Schiex & Verfaillie,
1994) generalized ones (Katsirelos & Bacchus, 2003). Two CNs P P 0 defined
variables equivalent iff solutions.
CN said satisfiable iff admits least one solution. Constraint Satisfaction Problem (CSP) NP-complete task determining whether given CN
satisfiable not. Thus, CSP instance defined CN solved either finding
solution proving unsatisfiability. many cases, CSP instance solved
using combination search inferential simplification (Dechter, 2003; Lecoutre, 2009).
solve CSP instance, depth-first search algorithm backtracking applied,
step search, variable assignment performed followed filtering process called constraint propagation. Constraint propagation algorithms enforce
consistency property, identify record explicit nogoods CNs. identified
nogoods size 1, correspond inconsistent values.
usual refer properties (hyper)graphs associated
CN. one hand, constraint (hyper)graph, also called macro-structure,
associated (normalized) CN P consists n vertices corresponding variables
P also e (hyper)edges corresponding constraints P : (hyper)edge connects
vertices corresponding variables scope constraint represents.
hand, compatibility (hyper)graph, also called micro-structure (Jgou, 1993),
associated normalized CN P contains one vertex per value P one (hyper)edge
per constraint support. corresponds n-partite hypergraph one part
variable. Sometimes, incompatibility (hyper)graphs used authors (hyper)edges
correspond conflicts instead supports. paper, (hyper)edges supports (resp.,
conflicts) drawn using solid (resp., dashed) lines.
sometimes helpful use homogeneous representation CN, wherein domains
also constraints replaced nogoods. nogood representation CN set
nogoods, one every value removed initial domain variable one
1. theoretical study, universal constraints safely ignored. practice, universal constraint
c CN P may artificially considered non-universal: choose variable x scp(c) consider
dummy value dominit (x) \ domP (x) relinit (c) forbids one tuple involving (x, ).

178

fiSecond-Order Consistencies

e
every tuple forbidden constraint.
precisely, nogood representation
x


variable x set instantiations {(x, a)} | dominit (x) \ dom(x) . nogood
representation
ce constraint c, withscp(c) = {x1 , . . . , xr}, theoset instantiations
n
Q
init (x) \ rel(c) . nogood repre{(x1 , a1 ) , . . . , (xr , ar )} | (a1 , . . . , ar )
xscp(c) dom

sentation Pe CN P set instantiations





e
xvars(P ) x



e .
ccons(P ) c


Instantiations Pe explicit nogoods P (recorded domains constraints).
Notice nogood superset another one, subsumed. Intuitively, nogood
subsumed relevant less general least another one, two
CNs nogood-equivalent related definition Definition 3.11 work Bessiere
(2006) canonical form, i.e., represent exactly set
unsubsumed nogoods. relate CNs, introduce general partial order.2 Let P
P 0 two CNs defined variables (i.e., vars(P ) = vars(P 0 )), P 0 P
f0 Pe P 0 P iff P
f0 ) Pe . (P, ) partially ordered set (poset)
iff P
reflexive, antisymmetric (remember CN P involve universal constraints)
transitive. CNs normalized unary universal constraint present,
therefore one manner discard (or remove) instantiation given
CN, equivalently record new explicit nogood CN. Given CN P P,
instantiation P , P \ denotes CN P 0 P vars(P 0 ) = vars(P ),
f0 = Pe {I}. P \ operation retracts P builds new CN,
P
necessarily set constraints. Let us show P 0 built. Pe ,
course P 0 = P \ = P : means instantiation already
explicit nogood P . interesting case
/ Pe . corresponds value
variable x, i.e., = {(x, a)}, suffices remove dom(x). corresponds
tuple allowed constraint c P , suffices remove tuple rel(c). Otherwise,
must introduce new constraint whose associated relation contains possible tuples
(built initial domains) except one corresponds instantiation I. Note
removing tuple relation rel(c) problem practice constraint
c defined intension (i.e., predicate). However, binary nogoods (our concern),
real problem because, except variables large domains,
always possible translate (efficiently) intensional constraint extension.
2.2 Consistencies
consistency general property CN. consistency holds CN P ,
say P -consistent. two consistencies, CN P said +consistent iff P -consistent -consistent. consistency nogood-identifying
iff reason CN P -consistent instantiations,
Pe , identified globally inconsistent . instantiations correspond (new
identified) nogoods said -inconsistent (on P ). kth-order consistency
nogood-identifying consistency allows identification nogoods size k,
k 1 integer. kth-order consistency confused k-consistency
(Freuder, 1978, 1982): k-consistency holds iff every locally consistent instantiation
2. partial order general enough purpose, note sophisticated partial orders (or
preorders) exist (e.g., taking account subsumed nogoods).

179

fiLecoutre, Cardon, & Vion

set k 1 variables extended locally consistent instantiation involving
additional variable. terminology, (k 1)th-order consistency.
domain-filtering consistency first-order consistency. conservative consistency
nogood-identifying consistency that, every given CN P , every -inconsistent
instantiation P corresponds tuple currently allowed explicit constraint P .
compare pruning capability consistencies, introduce preorder (see Debruyne
& Bessiere, 2001). consistency stronger (or equal to) iff whenever holds
CN P , also holds P . strictly stronger iff stronger
exists least one CN P holds P . consistencies
cannot ordered (none stronger another), say incomparable.
briefly introduce formal characterization constraint propagation, based
concept stability (following Lecoutre, 2009). formalism also related
previous works local consistencies rules iteration (e.g., see Montanari & Rossi,
1991; Apt, 1999, 2003; Bessiere, 2006). usually possible enforce CN P
computing greatest -consistent CN smaller equal P , preserving set
solutions. consistency well-behaved CN P P, set {P 0 P | P 0
-consistent P 0 P } admits greatest element, denoted (P ), equivalent
P called -closure P . Enforcing CN P means computing (P ),
algorithm enforces called -algorithm. property stability useful
proving nogood-identifying consistency well-behaved.
nogood-identifying consistency stable iff every CN P P, every CN P 0 P
f0
P 0 P every -inconsistent instantiation P , either P
0
-inconsistent P ; second condition stability given Lecoutre (2009) holds
f0
necessarily choice poset paper. fact either P
0
-inconsistent P guarantees -inconsistent instantiation CN
missed CN made tighter: either discarded (has become explicit nogood
P 0 ) remains -inconsistent.
Theorem 1. (Lecoutre, 2009) stable nogood-identifying consistency well-behaved.
stability nogood-identifying consistency provides general procedure
computing -closure CN: iteratively discard (in order) -inconsistent instantiations fixed point reached. Provided procedure sound (each removal
corresponds -inconsistent instantiation) complete (each -inconsistent instantiation removed), procedure guaranteed compute -closures. generally,
different reduction rules used, must shown correct, monotonic inflationary. benefit generic iteration algorithm (Apt, 2003, Lemmas 7.5,
7.8 Theorem 7.11). Stability union also proved domain-filtering
consistency, thus guaranteeing fixed point (Bessiere, 2006). interesting result follows:
Proposition 1. Let two well-behaved (nogood-identifying) consistencies.
stronger iff every CN P P, (P ) (P ).
conclude section well-known domain-filtering consistencies. First, let
us introduce generalized arc consistency (GAC). support (resp., conflict) value
(x, a) P constraint c involving x support (resp., conflict) c
I[x] = a. value (x, a) P GAC-consistent iff exists support (x, a) every
180

fiSecond-Order Consistencies

constraint P involving x. P GAC-consistent iff every value P GAC-consistent.
also say constraint c GAC-consistent iff every variable x scp(c) every
value dom(x), (x, a) GAC-consistent. binary CNs, GAC referred AC (Arc
Consistency). Second, introduce singleton consistencies (Debruyne & Bessiere,
1997b; Prosser, Stergiou, & Walsh, 2000). domain variable P empty, P
clearly unsatisfiable, denoted P = . CN P |x=a obtained P
removing every value b 6= dom(x). value (x, a) P SAC-consistent (SAC stands
Singleton Arc Consistent3 ) iff GAC (P |x=a ) 6= (this called singleton check).
value (x, a) P BiSAC-consistent iff GAC (P ia |x=a ) 6= , P ia CN obtained
removing every value (y, b) P 6= x (x, a)
/ GAC(P |y=b ) (Bessiere
& Debruyne, 2008). P SAC-consistent (respectively, BiSAC-consistent) iff every value
P SAC-consistent (respectively, BiSAC-consistent). BiSAC strictly stronger
SAC, strictly stronger GAC; BiSAC also strictly weaker strong
path consistency (Bessiere & Debruyne, 2008). GAC, SAC BiSAC well-behaved;
example, SAC (P ) denotes SAC-closure CN P .

3. Second-Order Consistencies
section, introduce second-order consistencies. First, start
famous one: path consistency. Then, clarify aspects path consistency
sometimes misrepresented literature, introduce known restricted forms.
Finally, introduce 3-consistency, dual consistency, 2-singleton arc consistency well
conservative strong variants.
3.1 Path Consistency
Among consistencies allow us identify inconsistent pairs values, path consistency plays central role. Introduced Montanari (1974), definition sometimes
misinterpreted. problem arises around definition path, must
understood sequence variables, sequence variables corresponds
path constraint graph. ambiguity probably comes Montanaris original
paper, reasoning path consistency achieved respect complete (or
completion of) constraint graphs, although footnote original paper indicates:
path network sequence vertices. vertex occur
path even consecutive positions.
precise definition path thus required. definition path used
Montanari (1974), Mackworth (1977) Debruyne (1998), definition graphpath used, example, Tsang (1993) Bessiere (2006). path arbitrary
sequence variables, graph-path defined sequence variables
binary constraint exists two variables adjacent sequence. binary
CN P , graph-path thus path constraint graph P . non-binary CN P ,
non-binary constraints discarded (ignored) path resulting constraint
graph graph-path. important note given variable may occur several
times path (and so, graph-path). Figure 1 gives illustration.
3. limit number acronyms, use SAC binary non-binary CNs.

181

fiLecoutre, Cardon, & Vion

Definition 1 (Path). Let P CN.
path P sequence hx1 , . . . , xk variables P x1 6= xk k 2;
path variable x1 variable xk , k 1 length path.
graph-path P path hx1 , . . . , xk P 1..k 1, c cons(P ) |
scp(c) = {xi , xi+1 }.
closed (graph-)path P (graph-)path hx1 , . . . , xk P c cons(P ) |
scp(c) = {x1 , xk }.

v

z

x
w



Figure 1: constraint graph binary CN P . hv, z, xi hv, y, w, yi paths P .
hv, z, y, wi closed path P . hv, x, yi graph-path P . hv, x, wi
hz, x, v, w, x, yi two closed graph-paths P .
central concept consistent paths defined follows:
Definition 2 (Consistent Path). Let P CN.
instantiation {(x1 , a1 ), (xk , ak )} P consistent path hx1 , . . . , xk P iff
exists tuple ki=1 dom(xi ) [x1 ] = a1 , [xk ] = ak 1..k1,
{(xi , [xi ]), (xi+1 , [xi+1 ])} locally consistent instantiation4 P . tuple
said support {(x1 , a1 ), (xk , ak )} hx1 , . . . , xk (in P ).
path hx1 , . . . , xk P consistent iff every locally consistent instantiation
{x1 , xk } P consistent hx1 , . . . , xk i.
example Figure 2, hv, z, xi consistent path P since locally
consistent instantiation {(v, a), (x, b)} find b dom(z) {(v, a), (z, b)}
locally consistent (this trivial since implicit universal binary constraint
v z) {(x, b), (z, b)} locally consistent. Similarly, second locally consistent
instantiation {(v, b), (x, a)} extended z. closed graph-path hv, x, wi
4. xi = xi+1 , necessarily [xi ] = [xi+1 ] instantiation cannot contain two distinct pairs
involving variable.

182

fiSecond-Order Consistencies

consistent; locally consistent instantiation {(v, b), (w, a)} cannot extended x. One
might surprised hz, x, v, w, x, yi consistent. important note
free select different values x along path. example, locally consistent
instantiation {(z, b), (y, a)}, find support = (b, b, a, b, a, a) hz, x, v, w, x, yi.
tuple belongs dom(z) dom(x) dom(v) dom(w) dom(x) dom(y), satisfies
[z] = b, [y] = encountered binary constraints along path. Along path
first (x, b) subsequently (x, a).


v



b

z
b

b

b
w

b

x






Figure 2: compatibility graph binary CN P (whose constraint graph given
Figure 1). hv, z, xi consistent path P . closed graph-path hv, x, wi
consistent contrary hz, x, v, w, x, yi.
introduce historical definition path consistency (PC, Montanari, 1974;
Mackworth, 1977).
Definition 3 (Path Consistency). CN P path-consistent, denoted PC-consistent, iff
every path P consistent.
definition valid non-binary CNs. Simply, non-binary constraints ignored,
Dechter (2003) Bessiere (2006) do, since Definition 2, pairs variables
considered. Montanari shown sufficient consider paths length two (i.e.,
sequences three variables) only. Note necessary constraint graph
complete (but, path consistency enforced, resulting CN may become
complete).
Theorem 2. (Montanari, 1974) CN P path-consistent iff every 2-length path P
(i.e., every sequence three variables) consistent.
leads following classical definition:
Definition 4 (Path Consistency). Let P CN.
instantiation5 {(x, a), (y, b)} P path-consistent, denoted PC-consistent, iff
2-length path-consistent, say, iff exists value c domain
every third variable z P {(x, a), (z, c)} {(y, b), (z, c)} locally
5. paper, refer instantiation form {(x, a), (y, b)}, assume x 6= y.

183

fiLecoutre, Cardon, & Vion

consistent; {(x, a), (y, b)} path-consistent, said path-inconsistent
PC-inconsistent.
P path-consistent iff every locally consistent instantiation {(x, a), (y, b)} P
path-consistent.
3.2 Deep Path Consistency
Now, show path consistency may easily misinterpreted, introduce consistency forms related PC. first natural question is: restrict attention
graph-paths (see Definition 1)? answer given following observation.
Observation 1. CNs, following properties equivalent:
(a) every path consistent
(b) every graph-path consistent
Proof. Consider, example, CN depicted Figure 3. CN path-consistent
since locally consistent instantiation {(x, b), (z, a)} consistent path hx, y, zi.
limit attention graph-paths, consist variables x
(for example, hx, yi, hx, y, x, yi, . . . ) local inconsistency.
x


b



z




Figure 3: CN P three variables one constraint (between x y). P
path-consistent. However, graph-path built consistent.
However, binary CN connected constraint graph (i.e., constraint graph
composed single connected component), restriction graph-paths valid.
Proposition 2. Let P binary CN P 6= constraint graph P
connected. P path-consistent iff every graph-path P consistent.
Proof. one direction (), immediate. P path-consistent, definition
every path P consistent, including graph-paths.
direction (), show every graph-path P consistent,
every 2-length path P consistent (and thus P path-consistent using Theorem 2).
practical terms, consider locally consistent instantiation {(x, a), (y, b)} show
third variable z P , following property P r(z) holds: c dom(z)
{(x, a), (z, c)} {(y, b), (z, c)} locally consistent instantiations.
variable z three cases must considered, depending existence constraints cxz ,
x z (i.e., scp(cxz ) = {x, z}), cyz , z.
184

fiSecond-Order Consistencies

(a) constraints exist: thus exists graph-path hx, z, yi path
consistent hypothesis, property P r(z) holds.
(b) Neither constraint exist: P 6= implies dom(z) 6= , thus P r(z) holds cxz
cyz implicit universal.
(c) constraint cxz exists (similarly, constraint cyz exists): constraint graph connected, exists least one graph-path z y,
consequently graph-path x form hx, z, . . . , yi. means
value dom(z) compatible (x, a), using hypothesis
(every graph-path consistent). value also compatible (y, b)
implicit universal constraint z y. Hence, P r(z) holds.
Unsurprisingly (because Observation 1), binary CN P every 2-length
graph-path P consistent, necessarily path-consistent. course, special
case constraint graph complete, CN path-consistent every path
P also graph-path P .
Observation 2. CNs, following properties equivalent:
(a) every graph-path consistent
(b) every 2-length graph-path consistent
Proof. See Figure 4.



v



b

z
b

b

b
w

b

x






Figure 4: Every 2-length graph-path CN (whose constraint graph given Figure
1) consistent. graph-path hx, w, v, x, zi consistent {(x, a), (z, a)}.

following proposition 2-length graph-paths.
Proposition 3. Let P binary CN P 6= P arc-consistent. P
path-consistent iff every 2-length graph-path P consistent.
Proof. proof similar proof Proposition 2 considering 2-length graph-paths
instead graph-paths. case (c) demonstration differs.
185

fiLecoutre, Cardon, & Vion

(c) constraint cxz exists (similarly, constraint cyz exists): P arcconsistent, exists value dom(z) compatible (x, a).
implicit universal constraint z y, value also compatible
(y, b). Hence, P r(z) holds.
Theorem 2 Propositions 2 3 suggest historical definition path consistency appropriate since corresponds strongest form detection local inconsistencies using concept path (even considering graph-paths may seem natural
considering paths). Unfortunately, path consistency sometimes misinterpreted. example, Definition 3-11 work Tsang (1993) links PC graph-paths,
Proposition 3.39 work Bessiere (2006) links PC 2-length graph-paths,
Observations 1 2 (with Figure 4) show equivalent Montanaris definition. However, true check path consistency practice, need consider
2-length graph-paths, provided binary constraints arc-consistent.
Two different relation-filtering consistencies related path consistency defined terms closed graph-paths. first partial path consistency (partial PC
PPC, Bliek & Sam-Haroud, 1999) second conservative path consistency (conservative PC CPC, Debruyne, 1999).
Definition 5 (Partial Path Consistency). CN P partially path-consistent, denoted
PPC-consistent, iff every closed graph-path P consistent.
Definition 6 (Conservative Path Consistency). CN P conservative path-consistent,
denoted CPC-consistent, iff every closed 2-length graph-path P consistent.
binary constraints, PPC CPC equivalent constraint graph
triangulated: PPC initially introduced build filtering algorithm operates
triangulated graphs. graph triangulated (or chordal) iff every cycle composed four
vertices chord, edge joining two vertices adjacent
cycle.
Proposition 4. (Bliek & Sam-Haroud, 1999) Let P binary CN P triangulated
constraint graph. P PPC-consistent iff P CPC-consistent.
Enforcing path consistency simply means discarding path-inconsistent instantiations
(i.e., recording new explicit nogoods size two) since know P C-closure, denoted
PC (P ), CN P exists (path consistency well-behaved). enforce path consistency
may necessary introduce new binary constraints, thus path consistency
conservative consistency. PPC CPC differ existing constraints altered.
additional weak forms path consistency, find directional path consistency (Dechter
& Pearl, 1988; Tsang, 1993) pivot consistency (David, 1995),
discussed paper. Although consistencies attractive controlling
practical inference effort situations, consistencies require introduction
variable ordering, restricts applicability.
Finally, two domain-filtering consistencies related path consistency also
defined: restricted path consistency (RPC, Berlandier, 1995) max-restricted path consistency (MaxRPC, Debruyne & Bessiere, 1997a). MaxRPC strictly stronger RPC
186

fiSecond-Order Consistencies

defined follows: value (x, a) CN P max-restricted path consistent, denoted MaxRPC-consistent, iff every binary constraint cxy P involving x, exists
locally consistent instantiation {(x, a), (y, b)} scp(cxy ) = {x, y} every
additional variable z P , exists value c dom(z) {(x, a), (z, c)}
{(y, b), (z, c)} locally consistent. CN P MaxRPC-consistent iff every value
P MaxRPC-consistent.
3.3 Additional Second-Order Consistencies
section, introduce second-order consistencies defined independently
path consistency. First, recall 3-consistency (3C, Freuder, 1978).
Definition 7 (3-consistency). Let P CN.
instantiation {(x, a), (y, b)} P 3-consistent, denoted 3C-consistent, iff
exists value c domain every third variable z P {(x, a), (y, b), (z, c)}
locally consistent.
P 3-consistent iff every locally consistent instantiation {(x, a), (y, b)} P 3consistent.
Note difference path consistency (see Definition 4): here, instantiation
size 3 must locally consistent (instead two instantiations size 2). known
3C equivalent PC ternary constraint present.
introduce dual consistency (Lecoutre et al., 2007a). Dual consistency, whose
idea initially used McGregor (1979), records inconsistent pairs values identified successive singleton checks. like singleton arc consistency, dual consistency
built top generalized arc consistency. Informally, CN dual-consistent iff
pair values locally consistent detected inconsistent assigning either
two values enforcing GAC. simplify, write (x, a) P iff (x, a) value
P , i.e., x vars(P ) domP (x); P = , consider every pair (x, a),
(x, a)
/ P.
Definition 8 (Dual Consistency). Let P CN.
instantiation {(x, a), (y, b)} P dual-consistent, denoted DC-consistent, iff
(y, b) GAC (P |x=a ) (x, a) GAC (P |y=b ).
P DC-consistent iff every locally consistent instantiation {(x, a), (y, b)} P
DC-consistent.
may interested checks based two simultaneous decisions (variable assignments): obtain 2-singleton arc consistency (2SAC, Bessiere et al., 2005).
Definition 9 (2-Singleton Arc Consistency). Let P CN.
instantiation {(x, a), (y, b)} P 2-singleton arc-consistent, denoted 2SACconsistent, iff GAC (P |{x=a,y=b} ) 6= .
187

fiLecoutre, Cardon, & Vion

P 2SAC-consistent iff every locally consistent instantiation {(x, a), (y, b)} P
2SAC-consistent.
3-consistency, dual consistency 2-singleton arc consistency second-order consistencies, conservative restrictions naturally derived follows.
Definition 10 (Conservative Second-Order Consistency). Let P CN,
consistency {3C, DC, 2SAC}.
instantiation {(x, a), (y, b)} P conservative -consistent, denoted C-consistent,
iff either @c cons(P ) | scp(c) = {x, y} {(x, a), (y, b)} -consistent.
P C-consistent iff every locally consistent instantiation {(x, a), (y, b)} P
C-consistent.
Thus, obtain three new second-order consistencies called conservative 3-consistency
(C3C), conservative dual consistency (CDC, Lecoutre et al., 2007a) conservative 2singleton arc consistency (C2SAC). illustrate difference consistency
conservative restriction C, let us consider CN P vars(P ) = {w, x, y, z}
cons(P ) = {cwx , cwz , cxyz }, subscripts indicate constraint scopes. reviews (locally
consistent instantiations of) six possible distinct pairs variables whereas C
reviews two pairs (w, x) (w, z).
shall also interested strong variants second-order consistencies additionally guarantee generalized arc consistency. example, binary CN strong pathconsistent, denoted sPC-consistent, iff arc-consistent path-consistent; CN
strong dual-consistent, denoted sDC-consistent iff GAC-consistent DCconsistent. s3C, s2SAC, sPPC, sCPC, sCDC, sC3C, sC2SAC defined similarly.
Definition 11 (Strong Second-Order Consistency). Let second-order consistency.
CN P strong -consistent, denoted s-consistent, iff P GAC+-consistent, i.e.,
GAC-consistent -consistent.
strong second-order consistency identifies -inconsistent values (nogoods
size one) -inconsistent pairs values (nogoods size two). Strictly speaking,
second-order consistency first+second order consistency.
important note closure CN computed second-order
consistencies mentioned far. consistencies proved stable,
consequently well-behaved.
Proposition 5. PC, 3C, DC, 2SAC, PPC, CPC, C3C, CDC, C2SAC, well
strong variants, consistencies well-behaved.
Sketch proof. Following Theorem 1, sufficient show mentioned consistencies stable (see Page 180). consistency among mentioned
proposition, instantiation -inconsistent CN P , necessarily
explicit nogood CN P 0 smaller equal P , -inconsistent P 0 .
example, suppose = {(x, a), (y, b)} DC-inconsistent P . means
f0 , must show
(y, b)
/ GAC (P |x=a ) (x, a)
/ GAC (P |y=b ).
/ P
0
DC-inconsistent P . necessarily (y, b)
/ GAC (P 0 |x=a ) GAC (P |x=a )
(x, a)
/ GAC (P 0 |y=b ) GAC (P |y=b ) P 0 P . Hence, DC-inconsistent
0
P.
188

fiSecond-Order Consistencies

4. Relationships Second-Order Consistencies
section studies qualitative relationships second-order consistencies
presented, namely path consistency, 3-consistency, dual consistency, 2-singleton arc
consistency, conservative strong variants. section composed three
parts (subsections). start relationships basic second-order consistencies
(PC, 3C, DC, 2SAC). Then, focus relationships including conservative restrictions
(PPC, CPC, C3C, CDC, C2SAC). Finally, finish strong second-order consistencies
(sPC, s3C, sDC, s2SAC, sPPC, sCPC, sC3C, sCDC, sC2SAC).
previous works (Lecoutre et al., 2007a, 2007b), study limited binary
CNs. paper, generalize results CNs arity, although results
given specifically binary CNs non-binary CNs. precision given,
results hold set possible binary non-binary CNs (i.e., CNs constraints
arbitrary arity).
4.1 Results Basic Second-Order Consistencies
start strongest (basic) second-order consistency paper, namely 2SAC.
Proposition 6. 2SAC strictly stronger DC, strictly stronger 3C.
Proof. Let P CN = {(x, a), (y, b)} locally consistent instantiation P .
one hand, DC-inconsistent either (y, b)
/ GAC (P |x=a ) (x, a)
/
GAC (P |y=b ), necessarily entails GAC (P |{x=a,y=b} ) = . Consequently, 2SACinconsistent, follows 2SAC stronger DC. hand, 3Cinconsistent z vars(P ) | c dom(z), {(x, a), (y, b), (z, c)} locally consistent.
CN P 0 = GAC (P |{x=a,y=b} ), necessarily dom(z) = (because x
assigned GAC enforced), thus P 0 = . means 2SAC-inconsistent,
follows 2SAC stronger 3C. Strictness proved Figure 5 shows
binary CN DC-consistent, 3C-consistent 2SAC-consistent.6
binary CNs, DC equivalent PC. could predicted since McGregor proposed AC-based algorithm establish sPC (1979). show 2 steps.
Proposition 7. DC strictly stronger PC.
Proof. Let P CN = {(x, a), (y, b)} locally consistent instantiation P .
path-inconsistent z vars(P ) | c dom(z), {(x, a), (z, c)} {(y, b), (z, c)}
locally consistent (see Definition 4). case, know (y, b)
/ GAC (P|x=a ) since
enforcing GAC P|x=a , every value c remaining dom(z) {(x, a), (z, c)}
consistent. Necessarily, hypothesis, remaining values incompatible
(y, b), thus b removed dom(y) enforcing GAC. Hence dual-inconsistent,
follows DC stronger PC. Strictness proved Figure 6 shows
non-binary CN PC-consistent DC-consistent.
Proposition 8. binary CNs, DC equivalent PC.
6. result, well Figures 9 12, computer-checked.

189

fiLecoutre, Cardon, & Vion

w

c

w

x

b
b



c

x

b
b









b
z



b
c

b


c

z

(a) compatibility graph P .

w



c

w

b



c



c

(b) incompatibility graph P .

x

b

b

c

x

b
b









b
z





b
c

c

b


z

(c) {(w, b), (x, a)} DC-consistent
(x, a) GAC(P |w=b ) (and similarly,
(w, b) GAC(P |x=a )).

b
c

c



(d) {(w, b), (x, a)} 2SAC-inconsistent GAC(P |{w=b,x=a} ) = .

Figure 5: CN P sDC-consistent (and s3C-consistent) C2SAC-consistent.
Dotted circles lines correspond deleted values tuples.

Proof. Proposition 7, know DC stronger PC. Now, show that,
binary CNs, PC stronger DC, therefore conclude DC PC
equivalent. Let P binary CN = {(x, a), (y, b)} locally consistent instantiation
P . dual-inconsistent (y, b)
/ AC (P|x=a ), symmetrically (x, a)
/ AC (P|y=b ).
consider first case.
Let us consider filtering procedure F iteratively removes (in order) values P|x=a successively found arc-inconsistent fixpoint.
procedure guaranteed compute AC (P|x=a ) (cf. Apt, 2003; Lecoutre, 2009). Let H(k)
following induction hypothesis: (z, c) one k first values removed F,
190

fiSecond-Order Consistencies

w

b

b

x









z

b

b



Figure 6: CN P two ternary constraints cwxy cwxz rel(cwxy ) =
{(a, a, a), (b, b, b)} rel(cwxz ) = {(a, b, a), (b, a, b)}. P also involves binary constraint cyz . P sPC-consistent CDC-consistent. Indeed,
{(y, a), (z, a)} DC-inconsistent since GAC (P |y=a ) = .

f0 P 0 = PC (P ), i.e., {(x, a), (z, c)} either initially locally
{(x, a), (z, c)} P
inconsistent identified path-inconsistent (possibly propagation).
show H(1) holds. (z, c) first value removed F, means (z, c)
support binary constraint involving z second variable w. {(x, a), (z, c)}
locally inconsistent, H(1) holds trivially. Otherwise, necessarily w 6= x (because
would mean (z, c) compatible (x, a) since assigned x,
{(x, a), (z, c)} initially locally inconsistent). Therefore {(x, a), (z, c)} clearly
support path hx, w, zi thus path-inconsistent.
assume H(k) true show H(k + 1) holds. (z, c) k + 1th
value removed F, means removal involves constraint binding z
another variable w. value (z, c) support constraint, thus every value
dom(w) initially supporting (z, c), any, one k first values removed F.
f0 P 0 = PC (P ).
hypothesis means value b, {(x, a), (w, b)} P
f
0
case, deduce {(x, a), (z, c)} P and, special case, identify
path-inconsistent. Consequently, every locally consistent instantiation P
f0 P 0 = PC (P ). deduce PC (P ) DC(P )
Pf00 P 00 = DC(P ) also P
also Proposition 1 PC stronger DC binary CNs.

Now, consider 3-consistency. binary CNs, well-known 3-consistency
equivalent path consistency. So, 3C also equivalent DC (since DC equivalent
PC). non-binary CNs, following relationships PC DC.
Proposition 9. non-binary CNs, 3C incomparable DC, strictly stronger
PC.
Proof. non-binary CNs, 3C strictly stronger PC (e.g., see Dechter, 2003, p. 69)
3C also checks ternary constraints. comparing 3C DC, appears
3C cannot stronger DC CN composed one quaternary constraint
191

fiLecoutre, Cardon, & Vion

GAC-consistent necessarily 3-consistent (since binary ternary
constraints) DC-consistent. hand, DC cannot stronger 3C
Figure 7 shows non-binary CN DC-consistent 3-consistent (there
way extending {(x, a), (y, a)} z). Hence, 3C DC incomparable.

x





b


b



b

c

z

Figure 7: CN P sDC-consistent C3C-consistent (because {(x, a), (y, a)}
3-consistent). dashed hyperedge corresponds nogood {(x, a), (y, a),
(z, b)}, i.e., ternary constraint cxyz forbidding tuple (a, a, b).

4.2 Results Conservative Second-Order Consistencies
Now, consider conservative variants basic second-order consistencies. first
immediate result conservative consistencies made strictly weaker
unrestricted forms. However, worthwhile mention (strong) PPC shown
equivalent (strong) PC binary convex CNs triangulated constraint graphs (Bliek
& Sam-Haroud, 1999).
Proposition 10. 2SAC, DC, 3C PC respectively strictly stronger C2SAC,
CDC, C3C PPC+CPC.
Proof. definition, conservative consistencies weaker. Strictness proved Figure 8
shows binary CN C2SAC-consistent (and CDC-consistent, C3C-consistent,
PPC-consistent, CPC-consistent) PC-consistent (and 3C-consistent, DCconsistent 2SAC-consistent).
Proposition 11. PC, DC 3C incomparable C2SAC.
Proof. one hand, PC cannot stronger C2SAC since Figure 5 shows binary
CN PC-consistent C2SAC-consistent. hand, C2SAC cannot
stronger PC since Figure 8 shows binary CN C2SAC-consistent
PC-consistent. conclude PC C2SAC incomparable. also valid
DC 3C since binary CNs mentioned proof (and PC=DC=3C binary
CNs).
Proposition 12. C2SAC strictly stronger CDC, strictly stronger C3C.
192

fiSecond-Order Consistencies

Proof. proof similar Proposition 6, considering initially locally consistent
instantiation = {(x, a), (y, b)} CDC-inconsistent (and next C3C-inconsistent)
x linked constraint.
w

b

b

x









z

b

b



Figure 8: CN (no constraint binds w x z) sC2SAC-consistent
(and CDC+C3C+PPC+CPC-consistent), PC-consistent (and 2SACconsistent). example, {(x, a), (z, b)} path-consistent.

Proposition 13. CDC strictly stronger PPC.
Proof. Assume CN P CDC-consistent consider closed graph-path hx1 , . . . , xp
P . every locally consistent instantiation {(x1 , a1 ), (xp , ap )} P , (xp , ap ) P 0
P 0 = GAC (P |x1 =a1 ) since P CDC-consistent. also implies P 0 6= . Therefore,
context P 0 , exists least one value domain since P 0 generalized
arc-consistent, clearly value (xp1 , ap1 ) P 0 compatible (xp , ap ), value
(xp2 , ap2 ) P 0 compatible (xp1 , ap1 ), . . . , value (x1 , a01 ) P 0 compatible
0
(x2 , a2 ). domP (x1 ) = {a1 }, a01 = a1 , thus locally consistent
instantiation {(x1 , a1 ), (xp , ap )} consistent closed graph-path hx1 , . . . , xp P .
Hence P PPC-consistent, thus CDC stronger PPC.
fact CDC strictly stronger PPC shown CN P depicted
Figure 9. Figure 9(c), P shown CDC-inconsistent locally consistent
instantiation {(x, a), (y, b)} dual-inconsistent: (y, b)
/ AC (P |x=a ). Figure 9(d), P
shown CPC-consistent because, example, locally consistent instantiation
{(x, a), (y, b)} consistent 2-length graph-paths linking x y, namely, hx, z, yi
hx, w, yi. Here, constraint graph triangulated, means CPC equivalent
PPC. Hence deduce result.
Proposition 14. non-binary CNs, CDC incomparable C3C.
Proof. CDC cannot stronger C3C since Figure 7 shows non-binary CN
CDC-consistent C3C-consistent. Now, consider CN Figure 9 extended
single ternary constraint involving new variables. CN remains C3C-consistent (because
193

fiLecoutre, Cardon, & Vion



x




b



z



b

x

b


w



w

v

c

b



b


b

b

(b) incompatibility graph P .



x




b



z



b

x

b


w

v

c

(a) compatibility graph P (no constraint
binds x v).

z



b


b

b

b

w

v


b

b
c

(c) P CDC-consistent. see
(y, b)
/ AC (P |x=a ). Thus, locally consistent
instantiation {(x, a), (y, b)} dual-inconsistent.

z





b
c


b


b

b

v

(d) P sCPC-consistent (and hence sPPCconsistent since P triangulated). (closed)
2-length graph-path P linking x consistent. shown {(x, a), (y, b)}.

Figure 9: Example binary CN P sPPC-consistent (and sC3C-consistent)
CDC-consistent.

194

fiSecond-Order Consistencies

binary constraint new variables), still CDC-consistent.
Hence, C3C cannot stronger CDC, CDC C3C incomparable.
Proposition 15. binary CNs, PPC strictly stronger C3C. non-binary CNs,
PPC incomparable C3C.
Proof. 1) Let P binary CN PPC-consistent (and different
weak restriction). consider locally consistent instantiation {(x, a), (y, b)}
P (such binary constraint involving x y) show every third variable z P , following property P r(z) holds: c dom(z)
{(x, a), (z, c)} {(y, b), (z, c)} locally consistent instantiations, equivalent {(x, a), (y, b), (z, c)} locally consistent since P binary. P r holds,
{(x, a), (y, b)} C3C-consistent. variable z, 3 cases must considered, depending existence constraints cxz , x z, cyz , z.
(a) constraints exist: thus, exists graph-path hx, z, yi path
consistent hypothesis, necessarily property P r(z) holds.
(b) Neither constraint exist: P 6= implies dom(z) 6= , thus P r(z) holds cxz
cyz implicit universal.
(c) constraint cxz exists (similarly, constraint cyz exists). Consider
graph-path hx, z, x, yi. hypothesis, graph-path consistent. Hence,
exists value c dom(z) {(x, a), (z, c)} locally consistent. also know
that{(y, b), (z, c)} locally consistent constraint
z. conclude P r(z) holds PPC stronger C3C binary CNs.
Figure 10 proves strictness showing CN C3C-consistent PPC-consistent.
2) non-binary CNs, Figure 7 shows PPC cannot stronger C3C: CN
PPC-consistent C3C-consistent. Now, consider CN Figure 10 extended
single ternary constraint involving new variables. CN remains C3C-consistent (because
binary constraint new variables), still PPC-consistent.
Hence, C3C cannot stronger PPC, PPC C3C incomparable.
Proposition 16. C3C strictly stronger CPC.
Proof. Let P CN C3C-consistent. Let hx, z, yi closed 2-length graph-path
P {(x, a), (y, b)} locally consistent instantiation P . P C3Cconsistent, know exists value c dom(z) {(x, a), (y, b), (z, c)}
locally consistent. Consequently, exists value c dom(z) {(x, a), (z, c)}
{(y, b), (z, c)} locally consistent. deduce path hx, z, yi consistent,
thus P CPC-consistent C3C stronger CPC. Figure 11 proves strictness
showing binary CN CPC-consistent (there 3-clique) C3C-consistent.

Proposition 17. PPC strictly stronger CPC.
195

fiLecoutre, Cardon, & Vion

w

b

x

b








b

z

b



Figure 10: CN (no constraint binds w x z) sC3C-consistent (and
sCPC-consistent, BiSAC-consistent) PPC-consistent. example,
{(x, a), (w, a)} PPC-consistent.
x


b



z




Figure 11: binary CN P two constraints (no constraint exists z). P
CPC-consistent C3C-consistent.

Proof. PPC stronger CPC definition. Moreover, binary CN Figure 10
CPC-consistent PPC-consistent. 3-clique constraint
graph, CN trivially CPC-consistent.
Proposition 18. non-binary CNs, PC incomparable CDC.
Proof. one hand, consider CN Figure 8 extended single ternary GACconsistent constraint involving new variables. additionnal constraint GACconsistent, CN remains CDC-consistent. However, PC-consistent. deduce
CDC cannot stronger PC (on non-binary CNS). hand, Figure
6 proves PC cannot stronger CDC: P PC-consistent (because
one binary constraint) CDC-consistent ({(y, a), (z, a)} CDC-inconsistent).
conclude non-binary CNs, PC CDC incomparable.
4.3 Results Strong Second-Order Consistencies
studying relationships existing strong variants second-order consistencies, observe that, binary case, enforcing AC path-consistent CN sufficient
196

fiSecond-Order Consistencies

obtain strong path-consistent CN. well-known fact also true general case
DC, CDC, 2SAC C2SAC. define (P ) ((P )).
Proposition 19. binary CN P , AC PC (P ) = sPC (P ).
Proof. PC (P ), every locally consistent instantiation {(x, a), (y, b)} support
every third variable z. Hence, every value PC (P ) locally consistent instantiation
arc-consistent. Consequently, AC enforced PC (P ), value present locally
consistent instantiation (of size 2) removed, PC preserved.
Proposition 20. CN P , GAC DC (P ) = sDC (P ), GAC CDC (P ) =
sCDC (P ), GAC 2SAC (P ) = s2SAC (P ) GAC C2SAC (P ) = sC2SAC (P ).
Proof. Let P 0 = DC (P ) P 00 = GAC (P 0 ). singleton check GAC (P 00 |x=a ) P 00 ,
GAC (P 00 |x=a ) = GAC (GAC (P 0 )|x=a ) = GAC (P 0 |x=a ). means result
singleton check (x, a) P 00 result singleton check
(x, a) P 0 . Since P 0 DC-consistent, deduce DC(P 00 ) = P 00 . P 00
GAC-consistent DC-consistent, P 00 = GAC DC(P ) = sDC(P ). similar
proof holds CDC , 2SAC C2SAC .
shown schema previous propositions hold CPC
PPC (Lecoutre, 2009). example, binary CNs P , AC CPC (P ) 6=
sCPC (P ). Unsurprisingly, relationships preserved strong variants considered.
Proposition 21. Let two second-order consistencies. stronger
stronger s.
Proposition 22. have:
(a) s2SAC strictly stronger sDC, strictly stronger s3C.
(b) sDC strictly stronger sPC.
(c) s3C strictly stronger sPC.
(d) s2SAC, sDC, s3C, sPC respectively strictly stronger sC2SAC, sCDC,
sC3C, sPPC+sCPC.
(e) sC2SAC strictly stronger sCDC, strictly stronger sC3C.
(f) sCDC strictly stronger sPPC.
(g) sPPC strictly stronger sCPC.
Proof. illustrative CNs introduced previously GAC-consistent (except Figure 11),
thus using Proposition 21, suffices consider: (a) Proposition 6 Figure 5 strictness, (b) Proposition 7 Figure 6 strictness, (c) Proposition 9 Figure 7
strictness, (d) Proposition 10 Figure 8 strictness, (e) Proposition 12 Figure 5
strictness, (f) Proposition 13 Figure 9 strictness, (g) Proposition 17 Figure
10 strictness.
197

fiLecoutre, Cardon, & Vion

following result indicates C3C CPC quite close properties. arcconsistent CNs, equivalent.
Proposition 23. binary CNs, sC3C equivalent sCPC.
Proof. Propositions 16 21, know sC3C stronger sCPC. Now,
show that, binary CNs, sCPC stronger sC3C. proof similar
Proposition 15 considering binary CN initially sCPC-consistent. case (c)
demonstration differs:
(c) constraint cxz exists (similarly, constraint cyz exists): P arcconsistent, exists value dom(z) compatible (x, a).
implicit universal constraint z y, value also compatible
(y, b). Hence, P r(z) holds.
Proposition 24. sPC, sDC s3C incomparable sC2SAC.
Proof. proof Proposition 11, CNs Figures 5 8 GAC-consistent.
Proposition 25. non-binary CNs, sPC incomparable sCDC.
Proof. proof Proposition 18, CNs Figures 8 6 GAC-consistent.
Finally, conclude section establishing connections SAC.
Proposition 26. sDC strictly stronger SAC+CDC
Proof. Let P CN sDC-consistent. Assume value (x, a) P SACinconsistent. means P 0 = GAC (P |x=a ) = , every value (y, b),
(y, b)
/ P 0 (recall value belongs ). P DC-consistent hypothesis,
nogoods recorded P meaning every variable y, binary constraint
cxy forbidding tuple involving (x, a). deduce (x, a) GAC-inconsistent,
contradicts hypothesis (P sDC-consistent), shows sDC stronger SAC.
know DC strictly stronger CDC, deduce sDC stronger
SAC+CDC. prove strictness, suffices build CN SAC-consistent, CDCconsistent DC-consistent (e.g., see Figure 8).
Proposition 27. binary CNs, sCDC strictly stronger SAC.
Proof. Let P binary CN sCDC-consistent. Assume value (x, a) P
SAC-inconsistent. means AC (P |x=a ) = . P AC-consistent (since P
sCDC-consistent hypothesis), necessarily x involved (at least) binary constraint
c (otherwise propagation possible deduce AC (P |x=a ) = ). Consequently,
tuple allowed c involving (x, a) since P CDC-consistent (because P 0 = ,
every value (y, b), consider (y, b)
/ P 0 ). deduce (x, a) AC-inconsistent.
contradiction shows sCDC stronger SAC. prove strictness, suffices
observe sCDC reasons inconsistent values pairs values.
Proposition 28. binary CNs, SAC+CDC equivalent sCDC. non-binary CNs,
SAC+CDC strictly stronger sCDC.
198

fiSecond-Order Consistencies




b

c

e



f

g

u

b
c



c
b

v

w

c

b
c

b



x





e

c
b






b

c



e

z

Figure 12: CN sCDC-consistent BiSAC-consistent: (z, c) BiSACconsistent, value appears none singleton tests AC (P |v=a ),
AC (P |v=b ) AC (P |v=c ).

Proof. Clearly, SAC+CDC stronger sCDC since SAC stronger GAC (and
sCDC GAC+CDC). hand, sCDC trivially stronger CDC
know Proposition 27 sCDC stronger SAC binary CNs. deduce that,
binary CNs, sCDC stronger SAC+CDC, SAC+CDC equivalent
sCDC. non-binary CNs, show strictness, let us consider non-binary CN depicted
Figure 6, binary constraint cyz eliminated. new obtained CN GACconsistent, CDC-consistent (since binary constraints), thus sCDCconsistent, SAC-consistent GAC (P |y=a ) = .
Proposition 29. binary CNs, sCDC incomparable BiSAC.
Proof. one hand, BiSAC cannot stronger sCDC since Figure 9 shows binary
CN BiSAC-consistent (note every value belongs least one solution)
CDC-consistent. hand, sCDC cannot stronger BiSAC since Figure 12
199

fiLecoutre, Cardon, & Vion

C2SAC

2SAC

s2SAC

sC2SAC

3C=DC=PC

s3C=sDC=sPC

BiSAC

CDC

sCDC=SAC+CDC

SAC

PPC

sPPC

MaxRPC

C3C

sCPC=sC3C

AC=2C

CPC
(a) Consistencies restricted binary CNs.

C2SAC

2SAC

s2SAC

3C

DC

sDC

SAC+CDC

PC

CDC

sCDC

sPC

C3C

PPC

sPPC

CPC

sCPC

SAC
GAC

(b) Consistencies CNs constraints arbitrary arity.

strictly stronger

incomparable

= equivalent

Figure 13: Summary relationships consistencies.
shows binary CN sCDC-consistent BiSAC-consistent. conclude
sCDC BiSAC incomparable.

results given general case (i.e., CNs constraints arbitrary arity)
also hold binary CNs considered. case Propositions 6, 10, 11,
12, 13, 16, 17, 22 (except cases (b) (c)), 24 26 binary CNs used
proofs. Figure 13 shows relationships (strong) second-order consistencies
introduced paper, focus binary CNs Figure 13(a). Figure 13(b),
sake clarity, s3C, sC3C, sC2SAC inserted.
200

fiSecond-Order Consistencies

5. Algorithm Enforce s(C)DC
section, present general algorithm enforce strong (conservative) dual consistency. algorithm valid binary non-binary CNs. algorithm called
sCDC1 used enforce sCDC, sDC1 used enforce sDC. Actually,
non-binary CNs, sCDC1 algorithm enforces SAC+CDC, strictly stronger
sCDC. extra strength comes free exploitation singleton checks
used enforce CDC.
Algorithm 1: sCDC1/sDC1(P ): Boolean
Input/Output: CN P ; sCDC (SAC+CDC) sDC enforced P
Result: true iff P strong (conservative) dual-consistent
1
2
3
4
5
6
7
8
9
10
11
12

P GAC (P )
P = return false
x first(vars(P ))
marker x
repeat
reviseVariable(P, x)
P GAC (P )
P = return false
marker x

// GAC initially enforced

// GAC maintained

x nextCircular(x, vars(P ))
x = marker
return true

Algorithm 1 establishes strong (conservative) dual consistency given CN P .
learnxxx function called Line 9 Algorithm 2, used Algorithm 1, specialized
either learnpart (Algorithm 3) enforce sCDC (SAC+CDC non-binary CNs omit
precision on) learnf ull (Algorithm 4) enforce sDC P . Basically,
Algorithm 1 performs successive singleton checks fixed point reached, returns
true iff P strong (conservative) dual-consistent, i.e., iff sCDC (P ) 6= (with learnpart )
sDC (P ) 6= (with learnf ull ). GAC enforced line 1, variable considered
turn main loop establish consistency. first(vars(P )) first variable
P lexicographical order, nextCircular(x, vars(P )) variable P right
x any, first(vars(P )) otherwise. two functions allow circular iteration
variables P . example, vars(P ) = {x, y, z}, iteration form x, y, z,
x, y, z. . . course, possible control order variables one iteration
next using heuristic.
reviseVariable function (Algorithm 2) revises given variable x means strong
(conservative) dual consistency, i.e., explores possible inferences respect x
performing singleton checks values dom(x). achieve this, GAC enforced
P |x=a value domain x (Line 3). SAC-inconsistent,
removed domain x (Line 5). Otherwise (Lines 7 10), every variable 6= x
P least one value deleted constraint propagation, try learn nogoods
201

fiLecoutre, Cardon, & Vion

Algorithm 2: reviseVariable(P ,x): Boolean

10

effective false
foreach value domP (x)
P 0 GAC (P |x=a )
// singleton check (x, a)
0
P =
remove domP (x)
// SAC-inconsistent value
effective true
else
0
foreach variable vars(P ) | 6= x domP (y) 6= domP (y)
0
learnxxx (P, (x, a), y, domP (y) \ domP (y))
effective true

11

return effective

1
2
3
4
5
6
7
8
9

Algorithm 3: learnpart (P , (x, a), y, Deleted): Boolean
1
2
3
4
5
6
7
8

cxy cons(P ) | scp(cxy ) = {x, y}
conflicts
foreach b Deleted | (a, b) relP (cxy )
conflicts conflicts {(a, b)}

// CDC-inconsistent pair

conflicts 6=
relP (cxy ) relP (cxy ) \ conflicts
return true
return false

Algorithm 4: learnf ull (P , (x, a), y, Deleted): Boolean
1
2
3
4
5
6
7

cxy cons(P ) | scp(cxy ) = {x, y}
conflicts
foreach b Deleted | (a, b) relP (cxy )
conflicts conflicts {(a, b)}

// CDC-inconsistent pair

conflicts 6=
relP (cxy ) relP (cxy ) \ conflicts
return true

12

else
conflicts {(a, b) | b Deleted}
// DC-inconsistent pairs
Let cxy new constraint that:
scp(cxy ) = {x, y}
rel(cxy ) = (dominit (x) dominit (y)) \ conflicts
cons(P ) cons(P ) {cxy }
return true

13

return false

8
9
10

11

202

fiSecond-Order Consistencies

means functions learnpart learnf ull ; set values deleted propagation passed
last parameter (in practice, using stack handle domains trailing mechanism,
need explicitly compute set deleted values). revision effective
x value tuple deleted (possibly inserting new constraint). Boolean
variable effective introduced track revision effectiveness. revision x
effective, reviseVariable returns true Line 6 Algorithm 1, GAC re-established
(Line 7). domain relation wipe-out detected Line 8. marker, initialized
first variable vars(P ) (Line 4) updated whenever inferences performed
(Line 9), manages termination.
Algorithms 3 4 discard identified binary nogoods correspond CDCinconsistent pairs values constraint cxy exists: every tuple (a, b) b
deleted value (i.e., b present P P 0 ) (a, b) present relP (cxy )
removed relP (cxy ). enforcing sDC (with learnf ull ) binary constraint
exists x y, new constraint created. constraint enforces set
nogoods corresponding DC-inconsistent pairs values involving (x, a) variable y.
new constraint accepts every pair values except identified
0
conflicts. Notice know least one conflict since domP (y) 6= domP (y)
line 8 Algorithm 2.
Proposition 30. Algorithm sCDC1 enforces sCDC binary CNs SAC+CDC
non-binary CNs; Algorithm sDC1 enforces sDC.
Proof. First, inference performed Algorithm 2 Line 5 learnpart /learnf ull
correct: inferences correspond clearly identified SAC-inconsistent values (C)DCinconsistent pairs values. inference directly performed Algorithm 1 Lines 1
7 also safe corresponds removing GAC-inconsistent values; remember
overall algorithm enforces strong (C)DC, SAC+CDC (and SAC stronger
GAC). fact possible inferences performed guaranteed fact
time revision effective, marker used Algorithm 1 updated; see Line 9.
Also, inference performed respect pair (x, a) effect GAC (P |x=b ),
b value domain variable x. Indeed, b assigned x,
values current domain x automatically removed. Combined
enforcement GAC, assignment new value x makes previous inferences related
values x without effect. reason iterate values
x Line 2 Algorithm 2 unique pass.
One pass Algorithm 1 means calling reviseVariable exactly per variable.
Proposition 31. One pass Algorithm 1 worst-case time complexity O(enrdr+1 )
learnpart (i.e., sCDC1) O(enrdr+1 + n3 d3 ) learnf ull (i.e., sDC1).
Proof. optimal worst-case time complexity enforcing GAC O(erdr ) (Mohr &
Masini, 1988). worst-case time complexity Lines 810 Algorithm 2 O(nd)
learn methods. Besides,
learnpart , new constraint inserted P , worst-case time complexity
one pass Algorithm 1 O(nd (erdr + nd)). reduces O(enrdr+1 )
203

fiLecoutre, Cardon, & Vion

weak assumption n er (otherwise, variables would involved
constraint);
learnf ull , consider O(n2 ) additional binary constraints may
added algorithm. So, obtain O(enrdr+1 + n3 d3 ).
binary constraints (r = 2, entails e < n2 ), obtain:
Corollary 1. binary CNs, one pass Algorithm 1 admits worst-case time complexity
O(end3 ) learnpart O(n3 d3 ) learnf ull .
P already s(C)DC-consistent, several passes Algorithm 1 necessary.
Thus,
learnpart , number passes bounded O(ed2 ); one tuple removed
new pass. worst-case time complexity Algorithm 1 O(e2 nrdr+3 )
(O(e2 nd5 ) binary CNs);
learnf ull , number passes bounded O(n2 d2 ); one tuple removed
new pass. resulting worst-case time complexity O(en3 rdr+3 +n5 d5 )
(O(n5 d5 ) binary CNs).
overall time complexity Algorithm 1 seems rather high observed
often fixed point quickly reached practice (i.e., number passes
empirically tends constant). also note sDC1 (i.e., Algorithm 1
learnf ull ), possible limit cost enforcing GAC singleton check. Indeed,
singleton check pair (x, a) performed, every nogood size 2 including (x, a)
identified recorded CN P . means last instruction
iteration foreach loop starting Line 2 Algorithm 2, P
assigning x, applying forward checking (any non-binary version, Bessiere,
Meseguer, Freuder, & Larrosa, 2002) enough enforce GAC: need consider
binary constraints involving x delete values consistent (x, a).
studied paper Lecoutre et al. (2007b).
Finally, worthwhile mention Algorithm 1 require specific data
structure. data structures required underlying (G)AC algorithm(s)
representation CNs. eb denotes number binary constraints
given CN, sCDC1 may require O(eb d2 ) additional space store new nogoods
(if binary constraints initially given intension example). sDC1 require O(n2 d2 )
additional space, may serious drawback solving certain problems.

6. Experimental Results
show practical interest strong second-order consistencies, particular s(C)DC,
conducted several extensive experiments Oracle Java 6 VMs running cluster
Intel Xeon 3.0 GHz 1 GiB RAM Linux. this, implemented sCPC,
sCDC sDC algorithms constraint solver AbsCon. implementations
sCPC8, directly derived PC8 (Chmeiss & Jgou, 1998), sCDC1 sDC1 correspond Algorithm 1 learnpart learnf ull , respectively. refinements
204

fiSecond-Order Consistencies

algorithm sDC1, proposed Lecoutre et al. (2007b), also possible
considered paper, mainly optimizations rather marginal (a speedup 10 % problems) respect main concern: showing enforcing
s(C)DC search may pay off.
AbsCon solver also features SAC preprocessing algorithms. used SAC1 (Bessiere
& Debruyne, 2005) SAC3 (Lecoutre & Cardon, 2005) algorithms experiments.
AbsCon, algorithms used enforce (G)AC AC3bit+rm (Lecoutre & Vion, 2008)
binary constraints, GAC3rm (Lecoutre & Hemery, 2007) non-binary constraints
defined intension, STR2 (Lecoutre, 2008) non-binary constraints extension.
Besides, possible, optimization based reasoning cardinality conflict
sets (Boussemart, Hemery, Lecoutre, & Sais, 2004b) used. course, SAC1, SAC3,
sCDC1 sDC1 also benefit efficiency underlying (G)AC algorithms.
6.1 Preprocessing Performance Random Problems
first evaluate performance various consistencies algorithms random instances. Random CNs generated using Model B (Gent, MacIntyre, Prosser, Smith,
& Walsh, 2001) comply five parameters: number variables n, size
domains d, arity constraints r (r = 2 experiment), density ,7
tightness (proportion tuples forbidden constraint).
100
AC
sCPC
SAC
sCDC
sDC
Inverse

Density [%]

80
60
40
20

20

40

60

80

20

Tightness [%]

40

60

80

100

Tightness [%]

(a) n = 50, = 10

(b) n = 50, = 50

Figure 14: Phase transition various consistencies random binary CNs.
Figure 14 gives quantitative information relative strength AC, sCPC,
SAC, sCDC sDC (= sPC) enforced random binary CNs n = 50 variables
{10, 50} values per domain. plot figures represents position
phase transition given consistency generated instances; 50 instances
generated (, t) pair, recall phase transition consistency
occurs 50 % generated instances detected unsatisfiable enforcing
7. density determines number constraints e =

205

n
r



fiCPU time [s]

Lecoutre, Cardon, & Vion

sPC8
sDC1
sCPC8
sCDC1

100

50

80
60
40

0

20

10

0
55

5
0
60

65
70
Tightness

60
65
Tightness

70

75

(a) = 50, = 50 %

(b) = 50, = 100 %

CPU time [s]

400
300
200

300

100

200

0
40
30
20
10
0
70

100
0
68
72

74
76
Tightness

78

70
72
Tightness

74

80

(c) = 90, = 50 %

(d) = 90, = 100 %

Figure 15: Mean CPU time (in seconds) enforcing various second-order consistencies
binary random CNs (n = 50).

206

fiSecond-Order Consistencies

. Phase transition inverse consistency also plotted baseline: CN inverseconsistent, (1, n)-consistent, iff value belongs least one solution. obtained
results show sCPC rather close sCDC random instances, except
tightness ranges 40% 70%. Surprisingly, difference sCDC
sDC weak even visible graphs. Also, see second-order
consistencies become closer inverse consistency size domains lower.
Figure 15 compares CPU times required establish sPC, sDC, sCPC sCDC,
binary random CNs, using algorithms sPC8, sDC1, sCPC8 sCDC1, respectively.
value t, 50 instances generated, either 50 values (topmost figures)
90 values (bottommost figures) per variable. Leftmost pictures represent performances
CNs density = 50 % rightmost pictures CNs complete constraint
graphs. latter case, consistencies equivalent; plots sDC1
sPC8 given. results quite informative. one hand, illustrate
high performance s(C)DC algorithms respect state-of-the-art s(C)PC
algorithms, performance gap often one order magnitude dense problems.
hand, obtained results show establishing sDC much harder
enforcing sCDC.
6.2 Impact Second-Order Consistency Preprocessing MAC
Now, turn complete search algorithms. One popular (systematic) search
algorithms solve CNs called MAC (Sabin & Freuder, 1994). MAC interleaves inference
search since step depth-first exploration backtracking, (generalized)
arc consistency maintained.8 step search, MAC uses variable ordering
heuristic select next variable instantiated. Two representative variable ordering
heuristics dynamic heuristic dom/ddeg (Bessiere & Rgin, 1996) adaptive heuristic dom/wdeg (Boussemart, Hemery, Lecoutre, & Sais, 2004a). Today, enforcing
(strong) second-order consistencies search (basically, variable assignment)
seems unrealistic. However, enforcing consistencies preprocessing stage
running MAC issue deserves addressed; section, attempt
provide insight regard. denotes consistency enforcing algorithm applied
preprocessing, denoted -MAC. experimentation conducted
consists comparing MAC, SAC1-MAC (and also SAC3-MAC), sCPC8-MAC, sCDC1MAC sDC1-MAC; called variants MAC. allows us assess
practical impact enforcing (strong) second-order consistencies preprocessing many
series structured (i.e., random) binary non-binary instances. series well
description found http://www.cril.fr/~lecoutre/benchmarks.html.
briefly introduce main features series (listed alphabetical order).
aim: series instances Boolean variables ternary constraints. Initially,
generated Boolean formulas DIMACS CNF (Conjunctive Normal Form) format.
bqwh: series satisfiable balanced quasi-group instances holes (Gomes & Shmoys,
2002); domains variables small (usually, values) constraints binary.
8. simplicity, shall use acronym MAC whatever arity constraints is.

207

fiLecoutre, Cardon, & Vion

composed: series instances randomly composed main (under-constrained) fragment
auxiliary fragments (Lecoutre, Boussemart, & Hemery, 2004); 10
values per domain constraints binary.
driver: series planning instances costs converted WCSP (Weighted CSP)
CSP; domains variables small (usually, values) constraints binary.
ehi: series SAT instances converted CSP using dual method described
Bacchus (2000); 7 values per domain constraints binary.
langford: series (generalized version the) Langford problem; domains variables usually small (up 150 values) constraints binary.
os-taillard: series Open-Shop scheduling instances generated J. Vion Taillards
paper (1993); domains large constraints binary.
primes: series instances involving prime numbers generated M. van Dongen; domains
variables small constraints non-binary.
qcp / qwh: series Quasi-group Completion Problem (QCP) Quasi-group
Holes problem (QWH); domains large constraints binary.
queensKnights: series academic instances queens knights put chessboard (Boussemart et al., 2004a); domains large constraints binary.
radar: realistic radar surveillance problems generated following model Swedish
institute computer science (SICS); domains small constraints non-binary.
renault-mod: series instances generated K. Stergiou Renault Megane configuration problem; domains diverse constraints non-binary.
sadeh: series containing five sets job-shop scheduling instances studied Sadeh &
Fox (1996); domains large constraints binary.
scens11: series containing hard variants original scen11 instance Radio Link
Frequency Assignment Problem (RLFAP, Cabon et al., 1999); domains small
constraints binary.
series: series all-interval series problem; domains diverse constraints
binary ternary.
ruler: series Golomb Ruler problem; domains small constraints
binary, ternary quaternary.
tsp: series generated R. Szymanek Travelling Salesperson problem; domains
large constraints binary ternary.
Tables 1 3 show results obtained different variants
MAC (the third column MAC alone) equipped variable ordering heuristics
dom/ddeg dom/wdeg, respectively. series, number nbs instances solved
five variants MAC within alloted time (20 minutes) well total
number nb instances given form nbs /nb column #Inst. mean CPU
times displayed two tables computed nbs instances identified
series; variant solves additional instances, indicated brackets
preceded + symbol. interesting note SAC3 algorithm (Lecoutre &
Cardon, 2005) sometimes permits discover lucky solutions preprocessing due
greedy nature. happens, show increased number solved instances
behind /. example, Table 1, first row indicates 12 instances set
208

fiSecond-Order Consistencies

MAC preprocessing =
Series

#Inst



SAC1/3

sCPC8

sCDC1

aim-100
aim-200
bqwh-15
bqwh-18
composed-25
composed-75
driver
ehi-85
ehi-90
langford-2
langford-3
langford-4
os-taillard-4
os-taillard-5
os-taillard-7
primes-10
primes-15
primes-20
qcp-10
qcp-15
qcp-20
queensKnights
qwh-10
qwh-15
qwh-20
radar-8-24
radar-8-30
radar-9-28
renault-mod
sadeh
scens11
series
ruler
tsp-20
tsp-25

12/24
6/24
100/100
99/100
15/50
3/40
7/7
99/100
94/100
16/24
16/24
14/24
29/30
10/30
6/30
25/32
20/32
20/32
14/15
5/15
0/15
6/18
10/10
10/10
0/15
34/50
35/50
12/50
46/50
16/46
0/11
10/25
17/28
15/15
13/15

100
262
1.77
55.9
121
0.6
44.0
197
251
1.44
49.6
(+1) 25.0
(+1) 13.6
(+5) 13.1
(+2) 64.5
45.3
(+2) 3.01
3.60
(+1) 18.1
(+4) 212

97.9
0.77
5.95

(+4) 12.9
(+1) 3.5
90.7
(+1) 36.4
(+11) 4.52

44.5
(+1) 77.3
6.63
(+2) 84.8

(+2) 65.6
(+7) 263

1.63
54.6
(+35) 0.89
(+37) 0.73
11.4
(+1) 1.47
(+6) 1.46
1.73
47.4
29.0
(+1) 1.85
(+9/10) 6.58
(+2/3) 75.2
92.4
12.6
(+2) 76.6
(+1) 18.6
(+4) 214

(+11) 0.74
0.76
11.7

(+5) 20.9
(+4) 35.1
(+5) 1.58
(+2) 4.05
(+11/22) 5.71

45.9
(+1) 70.8
8.27
(+2) 72.2

106
273
1.37
(+1) 33.3
(+35) 0.97
(+37) 0.8
9.74
(+1) 1.84
(+6) 1.88
36.9
38.9
(+1) 38.0
(+1) 5.79
(+9) 103
247
45.0
(+2) 3.09
3.77
(+1) 19.8
(+3) 172

(+6) 0.82
0.93
8.56
(+3)
(+4) 13.7
(+1) 3.75
93.5
(+1) 36.8
(+11) 10.1
(+3)
47.6
(+1) 70.1
8.08
(+2) 97.1

(+2) 68.1
(+7) 265

1.19
29.3
(+35) 1.1
(+37) 0.8
8.48
(+1) 1.32
(+6) 1.3
3.77
25.7
(+1) 21.8
(+1) 2.15
(+8) 65.2
77.0
91.1
15.8
(+2) 87.9
(+1) 18.4
(+3) 168

(+11) 0.64
0.82
7.2
(+4)
(+5) 14.2
(+3) 3.6
(+5) 1.35
(+2) 9.30
(+12) 4.10
(+3)
43.6
88.9
19.6
(+2) 63.9

54.2
16.4
3.5
(+1) 26.3
(+35) 1.2
(+37) 1.1
53.9
(+1) 1.41
(+6) 1.4
3.29
26.0
(+1) 21.7
3.10
(+10) 94.8
(+3) 118
(+1) 86.2
(+2) 13.9
(+2) 73.4
18.4
(+1) 129

(+11) 0.69
1.10
3.34
(+8)
(+4) 3.09
(+4) 20.2
(+5) 1.33
(+1) 20.6
(+13) 78.8
(+3)
(+15) 0.83
(+1) 62.4
63.7
223

+36

+148/161

+129

+152

+178

(+1)

sDC1
(+3)
(+10)

Table 1: Mean cpu time (in seconds) solve instances different series (time-out 1,200
per instance) -MAC-dom/ddeg.

209

fiLecoutre, Cardon, & Vion

MAC preprocessing =
Instances
aim-100-1-6-sat

bqwh-18-141-30

driver-02c-sat

driver-09-sat

langford-4-15

os-taillard-5-95-2

primes-15-20-2-3

primes-20-20-3-3

scen11-f12

renault-mod-8

series-12


cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del

sCPC8

50.9 (0)
25
655 K
0-0
180 (0.01)
31
1,682 K
6-0
2.34 (0.03)
35
5,278
64 - 0
222 (0.05)
57
215 K
162 - 0
254 (0.03)
32
1,056 K
1,620 - 0
> 1,200

46.6 (0.01)
25
655 K
0-0
66.2 (0.11)
31
643 K
6 - 182
3.68 (1.23)
43
3,277
64 - 9,439
52.7 (20.9)
135
14,284
162 - 63,163
287 (79.2)
52
197 K
1,620 - 517 K
> 1,200

1.81 (0.32)
29
122
657 - 0
> 1,200

1.77 (0.27)
29
122
657 - 0
> 1,200

>1200

15.3 (11.5)
53
240
6,324 - 419 K
24.5 (0.04)
67
179 K
22 - 0
12.9 (0.10)
29
106 K
0-0

24.0 (0.05)
67
179 K
22 - 0
12.2 (0.01)
29
106 K
0-0

sCDC1
0.38 (0.03)
25
100
100 - 0
92.2 (0.20)
31
845 K
9 - 207
3.66 (2.33)
39
988
343 - 5,336
10.3 (8.2)
73
650
2,175 - 22,590
215 (7.61)
40
197 K
1,620 - 517 K
9.06 (6.56)
32
3,204
570 - 384 K
16.5 (15.4)
29
104
766 - 0
188 (178)
29
175
602 - 0
7.95 (4.84)
49
18
6,768 - 306 K
8.05 (6.07)
67
0
95 - 0
12.0 (0.26)
29
106 K
0-0

sDC1
0.47 (0.12)
25
100
100 - 231 (200)
49.5 (0.31)
35
443 K
9 - 585 (296)
15.0 (13.3)
66
505
343 - 31 K (7 K)
61.1 (58.6)
217
650
2 K - 117 K (19 K)
215 (7.45)
40
197 K
1,620 - 517 K (0)
15.1 (12.1)
40
2,562
570 - 1 (175)
22.1 (21.4)
29
101
766 - 2,491 (46)
153 (141)
29
181
653 - 18,804 (96)
13.7 (10.4)
96
18
7 K - 351 K (3 K)
7.84 (6.8)
101
0
72 - 11 K (1,719)
0.81 (0.33)
29
23
0 - 310 (110)

Table 2: Detailed results various instances (time-out 1,200 per instance) MAC-dom/ddeg.
210

fiSecond-Order Consistencies

MAC preprocessing =
Series
aim-100
aim-200
bqwh-15
bqwh-18
composed-25
composed-75
driver
ehi-85
ehi-90
langford-2
langford-3
langford-4
os-taillard-4
os-taillard-5
os-taillard-7
primes-10
primes-15
primes-20
qcp-10
qcp-15
qcp-20
queensKnight
qwh-10
qwh-15
qwh-20
radar-8-24
radar-8-30
radar-9-28
renault-mod
sadeh
scens11
series
ruler
tsp-20
tsp-25

#Inst



SAC1/3

24/24
24/24
100/100
100/100
50/50
40/40
7/7
100/100
100/100
16/24
16/24
14/24
30/30
28/30
11/30
26/32
22/32
21/32
15/15
15/15
0/15
7/18
10/10
10/10
10/10
50/50
50/50
27/50
50/50
37/46
9/12
10/25
19/28
15/15
13/15

0.97
6.86
0.99
5.37
0.70
1.02
3.14
1.96
1.97
1.47
56.2
26.5
1.08
40.5
(+3) 70.0
71.1
(+1) 2.43
(+2) 13.4
0.71
43.1
(+3)
(+1) 2.57
0.69
1.67
152
26.6
1.43
(+1) 90.2
1.65
(+1) 13.1
95.4
(+1) 12.6
(+2) 16.2
3.91
(+2) 20.9
+17

sCPC8

sCDC1

sDC1

0.90
1.94
1.12
3.87
0.69
0.86
10.7
1.44
1.57
1.75
57.6
(+0/1) 29.1
1.74
(+1) 65.0
(+3/9) 76.5
(+0/2) 73.6
(+2/1) 27.2
(+1/2) 82.9
0.84
16.8
(+3/4)
(+10) 0.83
0.81
2.27
125
27.6
37.3
(+2/10) 37.9
2.72
(+1/7) 25.1
(+0/1) 54.6
(+0/1) 1.76
(+1/0) 46.3
6.09
(+2) 28.4

1.05
7.13
1.05
4.04
0.82
0.94
8.43
1.87
2.00
39.8
46.4
44.0
5.66
52.0
(+1) 266
71.9
(+1) 2.34
(+2) 13.8
0.88
62.8
(+3)
(+5) 0.88
1.41
2.54
96.0
26.5
1.55
(+1) 88.9
1.88
(+1) 18.8
109
(+1) 13.5
(+2) 24.0
4.48
(+2) 25.4

1.01
3.33
0.98
3.93
0.84
1.02
8.2
1.30
1.40
3.36
34.6
27.5
1.89
(+2) 45.5
(+1) 103
78.5
(+2) 16.2
(+1) 91.0
0.77
60.8
(+4)
(+10) 0.64
0.76
1.72
73.2
27.9
2.11
(+2) 71.5
7.94
(+3) 33.2
81.6
16.3
(+1) 66.0
18.1
(+2) 59.0

0.84
1.25
1.39
3.71
0.82
0.96
55.7
1.31
1.36
3.32
32.9
28.3
2.57
(+2) 48.4
(+4) 145
97.6
(+2) 14.5
(+2) 75.9
0.91
31.1
(+3)
(+10) 0.66
1.01
1.64
41.4
26.4
2.10
(+2) 67.5
11.8
(+6) 48.8
172
(+15) 0.79
(+1) 41.6
69.1
271

+26/51

+19

+28

+47

Table 3: Mean cpu time (in seconds) solve instances different series (time-out 1,200
per instance) -MAC-dom/wdeg.

211

fiLecoutre, Cardon, & Vion

MAC preprocessing =
Instances
e0ddr1-4

e0ddr1-5

qcp-15-120-2

qcp-20-187-11

scen11-f8

scen11-f6

series-14

series-25

tsp-20-75

os-taill-7-100-8

os-taill-7-105-9

cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del
cpu (pcpu)
mem
nodes
del v - del


1.35 (0.01)
32
50
0-0
125 (0.01)
32
1,245 K
0-0
93 (0.04)
32
955 K
1,276 - 0
2.33 (0.15)
37
4,898
2,913 - 0
6.93 (0.06)
37
15,640
4,992 - 0
37.2 (0.05)
37
204 K
3,660 - 0
93.2 (0.01)
29
689 K
0-0
> 1,200

sCPC8
5.25 (4.0)
32
50
0-0
121 (4.17)
32
1,245 K
0-0
34.8 (0.36)
36
308 K
1,276 - 302
> 1,200

31.2 (26.5)
57
2,214
4,992 - 365 K
74.8 (33.9)
57
167 K
3,660 - 415 K
101 (0.16)
29
689 K
0-0
> 1,200

sCDC1
3.05 (1.8)
32
50
0 - 8,546
3.19 (1.94)
32
75
0 - 7,006
36.0 (0.33)
36
333 K
1,282 - 177
2.4 (0.58)
45
3,435
2,930 - 325
8.39 (4.6)
53
2,214
4,992 - 366 K
45.9 (4.47)
53
167 K
3,660 - 416 K
125 (0.2)
29
914 K
0-0
> 1,200

3.32 (0.13)
35
6,926
21 K - 0
165 (0.01)
49
667 K
0-0
9.43 (0.01)
46
4,210
0-0

4.04 (0.36)
51
6,926
21 K - 0
378 (361)
53
42,499
0 - 58
336 (256)
50
179 K
0 - 4,328

26.9 (25.7)
47
1,631
22 K - 27 K
24.8 (8.4)
49
42,499
0 - 58
86.2 (8.4)
50
179 K
0 - 4,328

sDC1
8.57 (7.3)
60
50
0 - 531 K (927)
9.08 (7.7)
60
56
0 - 529 K (922)
2.41 (0.45)
40
706
1,282 - 418 (189)
2.66 (0.98)
81
2,099
2,930 - 1,091 (583)
12.3 (6.85)
89
6,106
4,992 - 389 K (757)
74.4 (6.46)
89
260 K
3,660 - 443 K (757)
0.91 (0.41)
29
27
0 - 444 (156)
3.16 (2.34)
41
49
0 - 1,610 (552)
90.0 (81.3)
197
2,064
22 K - 895 K (1.4 K)
31.2 (8.8)
53
51,403
0 - 60 (1)
16.2 (9.4)
50
49
0 - 11,072 (20)

Table 4: Detailed results various instances (time-out 1,200 per instance) MAC-dom/wdeg.
212

fiSecond-Order Consistencies

24 instances series aim-200 solved five variants MAC.
sDC1-MAC solves 12 instances mean CPU time computed 54.2 seconds,
additionally solves 3 instances series (within 20 minutes). Note
series, mean CPU time best variant MAC printed bold face:
best variant one solves highest number instances within 20 minutes
case equality, one smallest mean CPU time.
Tables 2 4 provide details solving various instances enforcing second-order
consistencies preprocessing. problem instance, total CPU time solve
given (this > 1,200 instance cannot solved within 20 minutes) well
time taken enforce consistency preprocessing (pcpu brackets). Additional
information concern memory requirement (expressed MiB), number explored
nodes number values tuples deleted preprocessing (del v del t). sDC1,
also put number new binary constraints brackets. example, Table
2, solving instance aim-100-1-6-sat, sDC1-MAC needs 0.47 (0.12 preprocessing),
25 MiB memory, explores 100 nodes, deletes 100 values 231 tuples preprocessing
(while adding 200 new binary constraints).
Table 1 clearly shows heuristic dom/ddeg used, real interest
making strong propagation effort preprocessing many problems. Although MAC
remains efficient approach series (e.g., langford-2 tsp-20), sCDC1-MAC
sDC1-MAC proved robust MAC. example, series aim200, radar-9-28 series, sDC1-MAC largely outperforms MAC. Overall, sDC1-MAC solves
178 36 = 142 instances MAC. sCDC1-MAC SAC1/3-MAC comparable
terms number solved instances. However, series (e.g., langford-3
bqwh-18), sCDC1-MAC clearly better SAC1/3-MAC, even reverse true
series (e.g., renault-mod sadeh). also interesting note sCPC8MAC almost always outperformed sCDC1-MAC sDC1-MAC. expected
result, sCPC weaker sCDC (and fortiori sDC), s(C)DC algorithms benefit
underlying highly optimized (G)AC algorithms. series, adding new binary
constraints order collect identified nogoods size 2 may counterproductive.
conservative consistency sCDC better option sDC. example,
case driver tsp-25 series.
results given Table 2 show dramatic effect strong consistency preprocessing instances. example, enforcing sCDC sDC, MAC able
directly find solution aim-100-1-6-sat. also case sDC1-MAC series-12.
However, sDC1 may require significant amount additional memory (to record new constraints). may explain relative inefficiency sDC1-MAC instances driver-02csat, driver-09-sat scen11-f12, compared sCDC1-MAC. Note renault-mod-8,
sCDC1 sDC1 alone sufficient detect unsatisfiability (the number visited nodes
0). However, unsatisfiability instance proved differently (i.e., following different propagation paths), explain 95 72 values respectively deleted
sCDC sDC enforced.
Table 3 confirms MAC equipped heuristic dom/wdeg far robust
dom/ddeg, initially claimed Boussemart et al. (2004a). result, series, enforcing strong consistency (i.e. consistency stronger GAC) preprocessing
limited impact. Nevertheless, overall, sDC1-MAC still increases robustness
213

fiLecoutre, Cardon, & Vion

solver. Concerning SAC3-MAC, important note good behaviour due
opportunistic mechanism finding solutions, inference capability
shown results SAC1-MAC: SAC1-MAC solves 26 additional instances 51
SAC3-MAC. sCDC1-MAC outperformed sDC1-MAC, note series,
remains good option perturbate heuristic adding new constraints (e.g., compare number nodes solving instances scen11-f6 scen11-f8
Table 4) overhead preprocessing limited (compare example preprocessing
time sCDC1 sDC1 e0ddr1-4 tsp-20-75 Table 4).
lessons learned experimental study? first one enforcing s(C)DC time far efficient enforcing s(C)PC. first
experimental attempts (not presented paper) enforce s(C)2SAC show
expensive approach, believe s(C)DC is, now, best second-order
consistency enforced preprocessing.
second unsurprising lesson problems enforcing s(C)DC
cost-effective. Basically, cost enforcing s(C)DC mainly depends total number
values tested9 well time complexity underlying GAC algorithm(s).
non-binary constraints, time complexity enforcing GAC usually increases
arity constraints extensional constraints, time complexity enforcing
GAC usually depends size tables. consequence, problem involves
constraints large arity and/or large tables, enforcing s(C)DC may become penalizing.
case renault-mod, tsp-20 tsp-25 series Table 3.
third lesson enforcing sDC preprocessing tends make MAC algorithm
robust. confirm this, Figure 16 shows two cactus-shaped plots give
insight relative performance variants MAC whole range tested
problem instances. plots show establishing sDC searching solution
using MAC enhances robustness solver, especially variable ordering
heuristic fails. dom/ddeg variable ordering heuristic, plain MAC almost always
worse MAC second-order consistency established preprocessing.
better dom/wdeg variable ordering heuristic, enforcing second-order consistency
interesting hardest problems, require 50 seconds solved.
zoom Figure 16(b) MAC versus sDC1-MAC shows trend reversed:
50 seconds, sDC1-MAC solves instances MAC.
conclude section experiment hardest instances RLFAP
series scens11 (see e.g., results http://www.cril.fr/{CPAI06,CPAI08,CPAI09}).
Using variable ordering heuristic dom/wdeg, ran plain MAC, MAC symmetrybreaking method described Lecoutre & Tabary (2009, denoted MACSB here), s(C)DCMAC, finally MAC inference mechanisms. Enforcing sCDC permits reduce
size search tree developed MAC instances, sDC, less
obvious (the added constraints perturbate heuristic), shown Table 5. Interestingly, joint use symmetry-breaking method reveals quite efficient here.
Using inference mechanisms, unsatisfiability instances proved without search effort (0 nodes sCDC1-MACSB sDC1-MACSB columns). Note
SAC-MACSB builds search tree problems, even possible solve
9. example, discarded fapp series problem instances, consistencies based singleton
checks clearly adapted huge number values.

214

fiSecond-Order Consistencies

1,200
MAC
sCPC8-MAC
SAC1-MAC
sCDC1-MAC
SAC3-MAC
sDC1-MAC

CPU time [s]

1,000
800
600
400
200
0
500

550

600

650

700

750

800

850

900

950

1,000 1,050 1,100

950

1,000 1,050 1,100

Number solved instances
(a) dom/ddeg

1,200

CPU time [s]

1,000
800
600

100
80
60
40
20

400

0
900

950

1,000

1,050

200
0
500

550

600

650

700

750

800

850

900

Number solved instances
(b) dom/wdeg

Figure 16: Number instances (out full set 1,237 instances) solved
within given amount CPU time variants MAC (e.g., 870 instances
solved within 1,200 MAC-dom/ddeg).

215

fiLecoutre, Cardon, & Vion

instance scen11-f1 SAC1-MACSB (or SAC3-MACSB ) equipped heuristic
dom/ddeg, within 20 minutes.
sCDC1Instance
scen11-f1
scen11-f2
scen11-f3
scen11-f4
scen11-f6
scen11-f8

MAC
cpu
nodes
cpu
nodes
cpu
nodes
cpu
nodes
cpu
nodes
cpu
nodes

> 1,200
> 1,200
> 1,200
542
3,381 K
60.1
348 K
6.0
14,077

MACSB

MAC

52.8
267 K
24.3
108 K
11.0
35,979
7.9
11,246
3.8
2,226
3.8
1,847

> 1,200
> 1,200
> 1,200
438
2,095 K
41.9
163 K
9.94
5,021

sDC1-

MACSB
10.0
0
7.6
0
5.8
0
6.0
0
4.3
0
5.3
0

MAC
> 1,200
> 1,200
> 1,200
808
3,362 K
65.1
215 K
11.1
4,518

MACSB
12.3
0
9.7
0
6.8
0
5.9
0
4.6
0
4.3
0

Table 5: Cost running (-)MAC-dom/wdeg hardest instances RLFAP series
scens11. MACSB MAC automatic global symmetry-breaking method.

7. Conclusion
paper intended give better picture second-order consistencies. purpose, studied theoretical relationships existing four basic second-order
consistencies (and variants), shown reasonably enforced search. However, next generation constraint solvers, tractable
classes CSP instances certainly identified exploited search,
order close, example, certain nodes search tree polynomial time. several theoretical results relate global consistency second-order consistencies (e.g.,
strong 3-consistency), increase importance second-order consistencies.
practical terms, advantages using (conservative) dual consistency.
Algorithms enforce strong (C)DC rather easy implement, made efficient highly optimized underlying GAC algorithms. Used preprocessing, reveal
improve robustness constraint solver several hard structured problems. (C)2SAC
stronger (C)DC, naive approach establishing requires several passes
O(n2 d2 ) enforcements GAC, makes ineffective. perspective work
devise efficient algorithms (C)2SAC could competitive (C)DC ones.
Finally, multi-core processors become increasingly common, parallel constraint solving become useful. near future, may imagine strong
second-order consistencies could used basic components (with strong inference capabilities) parallel solvers.
216

fiSecond-Order Consistencies

Acknowledgments
paper extended revised version earlier works (Lecoutre et al., 2007a, 2007b).
would like thank anonymous reviewers constructive remarks.

References
Allen, J. (1983). Maintaining knowledge temporal intervals. Communications
ACM, 26 (11), 832843.
Apt, K. (1999). essence constraint propagation. Theoretical Computer Science,
221 (1-2), 179210.
Apt, K. (2003). Principles Constraint Programming. Cambridge University Press.
Bacchus, F. (2000). Extending Forward Checking. Proceedings CP00, pp. 3551.
Berlandier, P. (1995). Improving domain filtering using restricted path consistency.
Proceedings IEEE-CAIA95.
Bessiere, C. (2006). Constraint propagation. Handbook Constraint Programming,
chap. 3. Elsevier.
Bessiere, C., Coletta, R., & Petit, T. (2005). Apprentissage de contraintes globales implicites. Proceedings JFPC05, pp. 249258.
Bessiere, C., & Debruyne, R. (2005). Optimal suboptimal singleton arc consistency
algorithms. Proceedings IJCAI05, pp. 5459.
Bessiere, C., & Debruyne, R. (2008). Theoretical analysis singleton arc consistency
extensions. Artificial Intelligence, 172 (1), 2941.
Bessiere, C., Meseguer, P., Freuder, E., & Larrosa, J. (2002). Forward Checking
non-binary constraint satisfaction. Artificial Intelligence, 141, 205224.
Bessiere, C., & Rgin, J. (1996). MAC combined heuristics: two reasons forsake FC
(and CBJ?) hard problems. Proceedings CP96, pp. 6175.
Bessiere, C., Stergiou, K., & Walsh, T. (2008). Domain filtering consistencies non-binary
constraints. Artificial Intelligence, 72 (6-7), 800822.
Bliek, C., & Sam-Haroud, D. (1999). Path consistency triangulated constraint graphs.
Proceedings IJCAI99, pp. 456461.
Boussemart, F., Hemery, F., Lecoutre, C., & Sais, L. (2004a). Boosting systematic search
weighting constraints. Proceedings ECAI04, pp. 146150.
Boussemart, F., Hemery, F., Lecoutre, C., & Sais, L. (2004b). Support inference generic
filtering. Proceedings CP04, pp. 721725.
Cabon, B., de Givry, S., Lobjois, L., Schiex, T., & Warners, J. (1999). Radio Link Frequency
Assignment. Constraints, 4 (1), 7989.
Chmeiss, A., & Jgou, P. (1998). Efficient path-consistency propagation. International
Journal Artificial Intelligence Tools, 7 (2), 121142.
Cooper, M., Cohen, D., & Jeavons, P. (1994). Characterising tractable constraints. Artificial
Intelligence, 65, 347361.
217

fiLecoutre, Cardon, & Vion

David, P. (1995). Using pivot consistency decompose solve functional CSPs. Journal
Artificial Intelligence Research, 2, 447474.
Debruyne, R. (1998). Consistances locales pour les problmes de satisfaction de contraintes
de grande taille. Ph.D. thesis, Universite Montpellier II.
Debruyne, R. (1999). strong local consistency constraint satisfaction. Proceedings
ICTAI99, pp. 202209.
Debruyne, R., & Bessiere, C. (1997a). restricted path consistency max-restricted
path consistency. Proceedings CP97, pp. 312326.
Debruyne, R., & Bessiere, C. (1997b). practical filtering techniques constraint
satisfaction problem. Proceedings IJCAI97, pp. 412417.
Debruyne, R., & Bessiere, C. (2001). Domain filtering consistencies. Journal Artificial
Intelligence Research, 14, 205230.
Dechter, R. (1992). local global consistency. Artificial Intelligence, 55 (1), 87108.
Dechter, R. (2003). Constraint processing. Morgan Kaufmann.
Dechter, R., & Pearl, J. (1988). Network-based heuristics constraint satisfaction problems. Artificial Intelligence, 34 (1), 138.
Freuder, E. (1978). Synthesizing constraint expressions. Communication ACM,
21 (11), 958965.
Freuder, E. (1982). sufficient condition backtrack-free search. Journal ACM,
29 (1), 2432.
Gent, I., MacIntyre, E., Prosser, P., Smith, B., & Walsh, T. (2001). Random constraint
satisfaction: flaws structure. Constraints, 6 (4), 345372.
Gomes, C., & Shmoys, D. (2002). Completing quasigroups latin squares: structured
graph coloring problem. Proceedings Computational Symposium Graph Coloring Generalization.
Green, M., & Cohen, D. (2008). Domain permutation reduction constraint satisfaction
problems. Artificial Intelligence, 172, 10941118.
Jgou, P. (1993). Decomposition domains based micro-structure finite
constraint-satisfaction problems. Proceedings AAAI93, pp. 731736.
Katsirelos, G., & Bacchus, F. (2003). Unrestricted nogood recording CSP search.
Proceedings CP03, pp. 873877.
Lecoutre, C. (2008). Optimization simple tabular reduction table constraints.
Proceedings CP08, pp. 128143.
Lecoutre, C. (2009). Constraint networks: techniques algorithms. ISTE/Wiley.
Lecoutre, C., Boussemart, F., & Hemery, F. (2004). Backjump-based techniques versus
conflict-directed heuristics. Proceedings ICTAI04, pp. 549557.
Lecoutre, C., & Cardon, S. (2005). greedy approach establish singleton arc consistency.
Proceedings IJCAI05, pp. 199204.
218

fiSecond-Order Consistencies

Lecoutre, C., Cardon, S., & Vion, J. (2007a). Conservative dual consistency. Proceedings
AAAI07, pp. 237242.
Lecoutre, C., Cardon, S., & Vion, J. (2007b). Path consistency dual consistency.
Proceedings CP07, pp. 438452.
Lecoutre, C., & Hemery, F. (2007). study residual supports arc consistency.
Proceedings IJCAI07, pp. 125130.
Lecoutre, C., & Tabary, S. (2009). Lightweight detection variable symmetries constraint satisfaction. Proceedings ICTAI09, pp. 193197.
Lecoutre, C., & Vion, J. (2008). Enforcing arc consistency using bitwise operations. Constraint Programming Letters, 2, 2135.
Mackworth, A. (1977). Consistency networks relations. Artificial Intelligence, 8 (1),
99118.
McGregor, J. (1979). Relational consistency algorithms application finding
subgraph graph isomorphisms. Information Sciences, 19, 229250.
Mohr, R., & Masini, G. (1988). Good old discrete relaxation. Proceedings ECAI88,
pp. 651656.
Montanari, U. (1974). Network constraints : Fundamental properties applications
picture processing. Information Science, 7, 95132.
Montanari, U., & Rossi, F. (1991). Constraint relaxation may perfect. Artificial Intelligence, 48 (2), 143170.
Prosser, P., Stergiou, K., & Walsh, T. (2000). Singleton consistencies. Proceedings
CP00, pp. 353368.
Sabin, D., & Freuder, E. (1994). Contradicting conventional wisdom constraint satisfaction. Proceedings CP94, pp. 1020.
Sadeh, N., & Fox, M. (1996). Variable value ordering heuristics job shop
scheduling constraint satisfaction problem. Artificial Intelligence, 86, 141.
Schiex, T., & Verfaillie, G. (1994). Nogood recording static dynamic constraint
satisfaction problems. International Journal Artificial Intelligence Tools, 3 (2), 187
207.
Stergiou, K., & Walsh, T. (2006). Inverse consistencies non-binary constraints.
Proceedings ECAI06, pp. 153157.
Taillard, E. (1993). Benchmarks basic scheduling problems. European journal operations research, 64, 278295.
Tsang, E. (1993). Foundations constraint satisfaction. Academic Press.
van Beek, P. (1992). minimality decomposability constraint networks.
Proceedings AAAI92, pp. 447452.
Zhang, Y., & Yap, R. (2006). Set intersection consistency constraint networks.
Journal Artificial Intelligence Research, 27, 441464.

219

fiJournal Artificial Intelligence Research 40 (2011) 415468

Submitted 9/10; published 2/11

On-line Planning Scheduling:
Application Controlling Modular Printers
Wheeler Ruml

ruml cs.unh.edu

Department Computer Science
University New Hampshire
33 Academic Way
Durham, NH 03824 USA

Minh Binh
Rong Zhou
Markus P. J. Fromherz

minhdo parc.com
rzhou parc.com
fromherz parc.com

Palo Alto Research Center
3333 Coyote Hill Road
Palo Alto, CA 94304 USA

Abstract
present case study artificial intelligence techniques applied control
production printing equipment. Like many real-world applications, complex domain requires high-speed autonomous decision-making robust continual operation.
knowledge, work represents first successful industrial application embedded
domain-independent temporal planning. system handles execution failures multiobjective preferences. heart on-line algorithm combines techniques
state-space planning partial-order scheduling. suggest general architecture may prove useful applications intelligent systems operate continual,
on-line settings. system used drive several commercial prototypes
enabled new product architecture industrial partner. compared
state-of-the-art off-line planners, system hundreds times faster often finds
better plans. experience demonstrates domain-independent AI planning based
heuristic search flexibly handle time, resources, replanning, multiple objectives
high-speed practical application without requiring hand-coded control knowledge.

1. Introduction
sustaining goal artificial intelligence develop techniques enabling autonomous
agents robustly achieve multiple interacting goals dynamic environment. goal
intellectually attractive. also happens align perfectly needs
many commercial manufacturing plants. paper, focus one particular manufacturing setting: high-speed digital production printing systems. large machines use
xerography print requested images individual sheets paper. Unlike traditional
continuous-feed offset presses, digital printers treat sheet differently: feeding different types sizes media, printing different kinds images, performing different
preparatory finishing operations. Often, single integrated machine transform
blank sheets complete document, bound book folded bill sealed
envelope. sometimes even possible process different kinds jobs simultaneously
c
2011
AI Access Foundation. rights reserved.

fiRuml, Do, Zhou, & Fromherz

equipment. printer controller must plan quickly reliably; otherwise expensive human intervention required. Designing high-performance yet cost-effective
controller machines made difficult current trend towards increased
modularity, customers system unique includes components
appropriate needs. working closely Xerox
Corporation explore architectures printing systems composed literally hundreds modules, possibly including multiple specialized printing modules, working
together high speed.
paper, demonstrate techniques artificial intelligence used
control machines. Requests print jobs become goals system achieve,
various actuators mechanisms machine become actions resources used
achieving goals, sensors provide feedback action execution state
system. provide high productivity (and thus high return investment
equipment owner), planning control techniques must fast produce optimal
near-optimal plans. reduce need operator oversight allow use
complex mechanisms, system must autonomous autonomic possible.
operators make mistakes even highly-engineered system modules fail,
system must cope execution failure unexpected events.
system must work legacy modules order commercially viable, architecture
must tolerate components direct control.
meet requirements, present novel architecture on-line planning, execution, replanning synthesizes techniques state-space planning (Ghallab, Nau,
& Traverso, 2004) partial-order scheduling (Smith & Cheng, 1993). develop new
heuristic evaluation functions temporal planning incorporate effects
resource constraints. Although domain-independent AI planning often regarded
expensive use soft real-time setting, system achieves good performance without
hand-coded control rules, despite additional requirements reasoning temporal actions resources. avoiding domain-dependent search control knowledge,
becomes possible use planner run different printing systems full productivity. success system enabled new modular product architecture
span multiple markets. Much previous work brought constraint-based scheduling
daily use print shops offices world-wide (Fromherz, Saraswat, & Bobrow, 1999;
Fromherz, Bobrow, & de Kleer, 2003), work bring domain-independent temporal
planning continual widespread use everyday people. approach practical
efficient, showcases flexibility inherent viewing planning heuristic search.
discussing application context detail, present overview
system, followed detailed discussion major aspects: nominal planning, exception handling, multiple objectives. go, present empirical measurements
demonstrating large printing systems controlled system meeting
real-time requirements. particular, Section 4.4.1 describes comparison stateof-the-art generic off-line planners demonstrates planner finds plans hundreds
times faster often higher quality, on-line appendix provides videos
planner controlling hardware prototype. integrated approach on-line
planning scheduling allows us achieve high throughput even complex systems.
416

fiOn-line Planning Scheduling Modular Printers

Figure 1: prototype modular printer built PARC. system composed approximately 170 individually controlled modules, including four print engines.

conclude paper summary general lessons derived building
application.

2. Application Context
analogy parallel systems RAID storage, approach modular printing
systems called Rack Mounted Printing (RMP). RMP system seen network
transports linking multiple printing engines. transports known media
path. Figure 1 shows four-engine prototype printer built Palo Alto Research Center
(PARC) 170 independently controlled modules. Figure 2 provides schematic
side view, showing many possible paper paths linking paper feeders possible
output trays. (Video 1 on-line appendix, nominal simulation, presents animation
Figure 2.) Multiple feeders allow blank sheets enter printer high rate
multiple finishers allow several print jobs run simultaneously. redundant paths
machine enables graceful degradation performance modules fail.
building system relatively small modules, enable easy reconfiguration
417

fiRuml, Do, Zhou, & Fromherz

Figure 2: schematic side view modular printer indicating feeders, paper path,
output trays.

components add new modules functionality. Achieving benefits, however, poses
considerable control challenge.
modular printing domain reminiscent mass customization, massproduced products closely tailored personalized individual customers needs.
also similar package routing logistics problems. control perspective,
involves planning scheduling series sheet requests arrive asynchronously
time front-end print-job submission rendering engine. system runs
high speed, several sheet requests arriving per second, possibly many hours.
sheet request completely describes attributes desired final product. may
several different sequences actions used print given sheet. example,
Figure 2, blank sheet may fed either two feeders, routed
one four print engines (or combination two four engines
case duplex printing) either finisher (unless sheet part on-going
print job).
on-line planning problem complicated fact many sheets in-flight
simultaneously plan new sheet must interfere sheets.
actions require use physical printer components, planning later sheets must take
account resource commitments plans already released production.
modern printers highly configurable, execute large variety jobs potentially
simultaneously, large variety constraints feasible plans, hard-coded
locally-reactive plans suffice (Fromherz et al., 1999). fact, printer engineers
Xerox delight uncovering situations products competing manufacturers,
use model-based planning, attempt execute infeasible plans.
418

fiprinter
model

Translator

On-line Planning Scheduling Modular Printers

domain
description

Planner

failures

Translator

problem
description
sheet
description

constraints

STN

plans
time info
itineraries

goals

Plan Manager

rejections,
failures,
updates

Machine
Controller

Figure 3: system architecture, planning system indicated dashed box.

planning system must decide print requested sheets quickly possible
thus must determine plan schedule sheet end time
plan finishes last minimized. words, planner attempts minimize
makespan combined global plan sheets, essence optimizing systems
overall throughput. Typically many feasible plans given sheet request;
problem quickly find one minimizes . optimal plan sheet depends
sheet request, also resource commitments present previouslyplanned sheets. legal series actions always easily scheduled pushing
far future, entire printer become completely idle, course
desirable. on-line task set sheets grows time passes
plan execution (i.e., printing) interleaves plan creation. fact,
real-world wall clock end time want minimize production
sheet cannot start planned, speed planner affects value
plan! However, system often runs full capacity, thus planner usually need
plan rate sheets completed, may several per second.
challenging, domain also forgiving: feasible schedules found quickly,
sub-optimal plans acceptable, plan execution relatively reliable.
printer controller works on-line real-time continual planning environment
three on-going processes: 1) on-line arrival new goals; 2) planning known goals;
3) execution previously synthesized plans. Figure 3 shows inputs outputs
planning system, domain model sheet requests entering left
communication low-level control system right. plan manager
responsible tracking status goal invoking planner necessary.
planning execution occur sequentially given sheet, processes
usually interleaved different sheets. Figure 4 sketches different steps
sheet-plan life cycle managed plan manager. Specifically, upon receiving, sheets
put unplanned first-in-first-out queue (sheets 6 7). sheet planner picks
one sheet time unplanned queue tries find route-plan
sheet (sheet 5). plan found put queue plans havent yet
sent printer controller (sheets 3 4). Another plan manager process regularly
checks planned queue decide earliest starting time plan queue
419

fiRuml, Do, Zhou, & Fromherz

sheet 1
sheet 2
sheet 5

sheet 3

sheet 6

start time

sheet 7

sheet 4

sheet
ddescriptions
ti

yet
planned


planned

planned,
unsent

sent
printer

Figure 4: Stages life sheet planning system.
close enough current wall-clock time send plans printer controller
execution (sheets 1 2). Note figure, time advances downward plans
starting earlier higher figure. Sheets 1, 2, 3 finish order; sheets 4 5
belongs different job scheduled run concurrently.
application, additional negotiation step plan issued
planning system plan committed. First, plan step proposed
machine controller modules involved. individual hardware modules
steps accept proposed actions, plan committed. discuss below,
commitment means modules become responsible notifying controller fail
complete action realize able perform planned action
future. plan confirmed, planner cannot modify it. thus
benefit releasing plans machine controller start times approach.
modules confirm, machine controller notifies planning system
proposed plan rejected, system must produce new plan. negotiation
process one reason must find complete plan starting execution.
module limited number discrete actions perform, transforming
sheet known deterministic way. many actions, planner allowed
control duration within range spanning three orders magnitude (milliseconds
seconds). example, planner may choose transport sheet faster slower
module order avoid collisions. Actions may split sheet two pieces
join multiple sheets different paths printer together. means single
printed sheet must created single blank sheet size, thereby conflating
sheets material allowing plans linear sequence actions. domain,
adjacent actions must meet time; sheets cannot left lingering inside printer
action completed must immediately begin transported next location.
Sheets grouped print jobs. job ordered set sheets, must
eventually arrive destination order submitted.
Multiple jobs may production simultaneously, although sheets different
420

fiOn-line Planning Scheduling Modular Printers

jobs allowed interleave single destination, number concurrent jobs
limited number destinations (i.e., finisher trays).
Currently, Xerox uses constraint-based scheduler control high-end midrange printers (Fromherz et al., 1999). scheduler enumerates possible plans
machine starts stores database. printing requests arrive on-line,
scheduler picks first feasible plan database uses temporal constraint
processing schedule actions. decoupling planning scheduling insufficient
complex machines two reasons. First, number possible plans large
generate ahead time, indeed becomes infinite loops present, printer
shown Figure 2. Second, precompiled plans poor choices given existing
sheets system. example, sheets fed different feeders depending
previous sheets fed, large are, long dwell
print engines (which function sheet thickness material). high
performance, must integrate planning scheduling on-line fashion.
Occasionally module break down, failing perform committed action. Modules
also take off-line intentionally, example perform internal re-calibration
diagnosis. Modules may added subtracted system information
passed machine controller planning system right side Figure 3.
vision RMP system provide highest possible level productivity
safe, including running long periods degraded capabilities.1 Meeting
mandate context highly modular systems means precomputing limited set
canonical plans limiting on-line computation scheduling desirable.
large system 200 modules, infeasibly many possible degraded configurations
consider. Depending capabilities machines, number possible sheet
requests may also make plan precomputation infeasible. Furthermore, even best precomputed plan given sheet may suboptimal given current resource commitments
printing machine.
summarize, domain finite-state, fully-observable, specifies classical goals
achievement. However, planning on-line additional goals arriving asynchronously.
Actions real-valued durations use resources. Plans new goals must respect
resource allocations previous plans. Execution failures domain model changes
occur on-line, rare.

3. System Overview
complete printing system encompasses many components, including print-job submission,
print-job management planning, sheet management planning, image rendering
distribution, low-level module control, media handling hardware, exception handling.
paper focuses planning issues sheet level, including exception handling.
discussing one issue great detail, section provides overview
topics involve sheet planning directly, including hardware control exception
handling.
1. example, safety operator, system continue use module whose access
cover opened, even hypothetically possible repair one portion module
another use.

421

fiRuml, Do, Zhou, & Fromherz

Time Step
1

2

3

4

5

6

Feed 1 2
Print

1

Loop
Finish

2

2

2

2

1
2

2
1

1

3

4

1

2

5

2
2

1

2

Figure 5: Two different schedules printing duplex sheet (2) simplex sheet (1):
launching sheets order improves throughput.

Figure 3 shows basic architecture planning system communicates
machine controller. overall objective minimize makespan
combined global plan sheets, essence optimizing systems throughput.
approximate planning one sheet time, objective sheet
finish quickly possible respecting ordering constraints may
sheets. Sheets optimally planned individual basis, order arrival, without
reconsidering plans selected previous sheets. figure, plan manager calls
planner sheet records resulting plan. mitigate restrictiveness
greedy scheme, represent action times using temporal constraints instead absolute
times. constraints stored simple temporal network (Dechter, Meiri, & Pearl,
1991), marked STN figure. maintaining temporal flexibility long possible,
shift plans older sheets later time make room starting new sheet earlier
improves overall machine throughput. may sound like rare case,
quite common. Figure 5 illustrates how, simplex (single-sided) cover sheet followed
duplex (double-sided) sheet, faster overall launch second sheet first.
Although basic architecture specifically adapted on-line setting, planner uses domain-dependent search control knowledge. Furthermore, mix goaldecomposable planning cross-goal resource constraints quite common, believe
framework useful AI system needs interleave real-time decision
making, planning, execution, robot operations.
3.1 Planning
implemented temporal planner using architecture adapted
on-line domain. see below, large number potential plans given
sheet close interaction plans schedules means much
better process scheduling constraints planning process allow focus
planning actions executed soon. planner uses state-space regression,
temporal information stored STN. STN records feasible interval
time point plan. Time points restricted occur specific single times
posted constraints demand it. planner maintains partial orders
different actions plans different sheets STN conducting
422

fiOn-line Planning Scheduling Modular Printers

On-linePlanner
1. plan next sheet
2. unsent plan starts soon,
3.
foreach plan, oldest imminent one
4.
clamp time points earliest possible times
5.
release plan machine controller
PlanSheet
6. search queue {final state}
7. loop:
8.
dequeue promising node
9.
initial state, return
10. foreach applicable action
11.
apply action
12.
add temporal constraints
13.
foreach potential resource conflict
14.
generate orderings conflicting actions
15
enqueue feasible child nodes
Figure 6: Outline hybrid planner
backward state-space search, seen hybrid state-space search
partial-order planning. sketch planner given Figure 6. outer loop
corresponds plan manager Figure 3.
planning new sheet, outer loop checks queue planned sheets see
begin soon (step 2). imperative recheck queue periodic
basis, soon defined constant amount current time
assume time plan next sheet smaller constant.
value constant depends domain specifics communication delay
module preparation time currently selected manually. assumption violated,
interrupt planning next sheet start later. plans released
executed, resource contention decrease, time plan new sheet
decrease well. important new temporal constraints added outer loop
planning individual sheets, propagation affect feasible sheet end
times thus could invalidate previously computed search node evaluations planning
underway.
maintaining partial orderings actions seems necessary mitigate
one-sheet-at-a-time greedy strategy, planning individual sheets need necessarily
take form state-space regression. considered forward search strategy,
employed many modern planners FF (Hoffmann & Nebel, 2001) LAMA
(Richter, Helmert, & Westphal, 2008). Initial investigation preliminary empirical comparisons showed progression planner easier implement easier extend
handle additional domain complexities, performance regression planner (using
heuristic) significantly better many problems domain. seems
423

fiRuml, Do, Zhou, & Fromherz

due mainly temporal constraint enforcing given sheet end
end time previous sheets batch. constraint interacts well
searching backward goal, immediately constraining end time plan.
Together constraint actions must abut time, many possible orderings
resolving resource contention immediately ruled out. example, current sheet
cannot transported destination previous sheet batch.
addition, orderings may immediately push end time plan even later,
informing node evaluation function.
planner searches forward direction benefits slightly avoiding logical
states unreachable initial state. However, without similar temporal
constraint first action plan, resource allocation orderings pruned
branching due resource contention increases direct proportion number
plans previous sheets maintained plan manager. Furthermore, end time
plan rarely changes far planning processes, making heuristic less
useful. short, first sheet, performance forward backward planners
similar, number plans managed plan manager increases, backward
planner seems perform better.
Due details machine controller software, planner must release plans
machine controller order sheet requests submitted.
means sheets submitted imminent sheet must released along (step
3). stage allowable intervals sheets time points forcibly reduced
specific absolute times (step 4). Sensibly enough, ask point occur exactly
earliest possible time. temporal network uses complete algorithm
maintain allowable window time point (a variation Cervoni, Cesta, & Oddi,
1994), guaranteed propagation caused temporal clamping process
introduce inconsistencies. clamping happens plans issued; thus
face on-line dispatchability problem Muscettola, Morris, Tsamardinos
(1998).
current on-line setting, even though plan multiple sheets belonging
different jobs, build plans single sheet time. Even many submitted
sheets waiting planned, strategy reasonable given sheets arrived sequence
and, arrival last sheet, know many sheets job
planner receive individual sheet specifications. Waiting sheets
known impractical many production jobs, billing payroll, involve jobs
many thousands sheets run multiple days.
3.2 Control
shown Figure 2, system consists two feeders left, two finishing trays
right, four print engines one four quadrants printer.
three high-speed sheet highways connect feeders finisher trays.
Sheets traveling top bottom highways routed print engines
on-ramps off-ramps. increased modularity, highways
on- off-ramps made two types modules: straight-through modules
three-way modules. module processor: Texas Instruments F2811
424

fiOn-line Planning Scheduling Modular Printers

Figure 7: control system architecture.

DSP. modules run distributed algorithms state estimation control
communicate via five controller-area network (CAN) buses, plus
dedicated data-logging bus debugging purposes. Modules quadrant
printer reside bus, except four print engines,
separate bus. Sheets moved roller actuators, called nips, driven
independently-controlled stepper motors. sensory feedback, nip equipped
edge-detection sensor sides nip. three-way module, three
solenoids drive flipper actuators direct sheet along different paths.
Figure 7 shows control system architecture, implements hierarchical approach distributed plan execution sheet controller manages module
controllers currently, soon be, contact sheet. Thus sheet
controller group membership dynamic life cycle sheet, starting
feeder way finisher tray. soon new sheet sent machine controller, corresponding sheet controller created resides centralized processor,
even though module controllers manages reside locally modules themselves.
Note module controller may processing commands multiple sheet controllers,
case module controller middle Figure 7. still contact
first sheet, soon contact second sheet.
sheet span multiple modules printer, different nips acting
sheet must tightly synchronized order avoid damaging jamming sheet.
However, achieving exact synchronization network uncertain communication
delays stringent bandwidth challenging. Moreover, one must consider limited
computation power module design synchronization scheme. example,
controller sample time set 2 milliseconds. Thus, anything takes longer 2
milliseconds compute within sampling period work. eliminate effects
uncertain network delays, control system uses delay equalizer, buffers sensory
feedback messages apply time, make sure sensor information used
time members group module controllers sheet. save
bandwidth needed synchronization, controller uses internal models (or estimators)
keep track states controllers network order limit need
425

fiRuml, Do, Zhou, & Fromherz

communications (Crawford, Hindi, Zhou, & Larner, 2009; Hindi, Crawford, & Fromherz,
2005).
limited network bandwidth fundamental impact choice control algorithm. Initially, linear-quadratic-gaussian (LQG) (Franklin, Powell, & Workman, 1997)
controller used, nice property solution constitutes linear dynamic feedback control law easily computed. However, bandwidth requirements
LQG controller, necessitates dozen way points per sheet
sent network, prompted adoption different kind controller based
proximate time optimal servo (PTOS) (Hindi, Crawford, Zhou, & Eldershaw, 2008;
Franklin et al., 1997), consumes much less bandwidth. comparison, PTOS
controller reduces number intermediate way points dozen two
per sheet. Since PTOS based time optimal control uses either maximum acceleration deceleration reach target control state, also maximizes temporal
flexibility planning actions planner use, thus improving overall
throughput printer.
3.3 Previous Work
much interest last 15 years integration planning scheduling techniques. HSTS (Muscettola, 1994) IxTeT (Ghallab & Laruelle, 1994) examples systems select order actions necessary reach goal, also
specify precise execution times actions. Visopt ShopFloor system Bartak
(2002) uses constraint logic programming approach incorporate aspects planning
scheduling. Europa system Frank Jonsson (2003) uses novel representation based attributes intervals. system use domain representations
quite different mainstream PDDL language (Fox & Long, 2003) used planning
research designed off-line use, rather controlling system
continual execution.
currently great interest extending planning scheduling techniques handle complexities found real industrial applications. example, PDDL
extended handle continuous quantities durative actions. additional
dimensions planning complexity besides expressivity, however. work complements
trend current planning research extend expressiveness focusing middle ground planning scheduling. domain semantics printing
complex job shop scheduling simpler many ways PDDL2.1. Choice
actions perform important domain, managing resource conflicts equally
important. classical scheduling, resource constraints essential printer
modules often cannot perform multiple actions once. action selection sequencing also required given sheet usually achieved using several different
sequences actions.
domain formalization lies partial-order scheduling temporal PDDL.
optimal actions needed fulfill given print-job request may vary depending sheets machine, sequence actions predetermined
classical scheduling formulations job-shop scheduling resource-constrained
project scheduling expressive enough. domain clearly subsumes job-shop
426

fiOn-line Planning Scheduling Modular Printers

flow-shop scheduling: precedence constraints encoded unique preconditions
effects. Open shop scheduling, one choose order predetermined set
actions job, capture notion alternative sequences actions
thus also limited. positive planning theories Palacios Geffner (2002) allow actions real-valued durations allocate resources, cannot delete
atoms. means cannot capture even simple transformations like movement
fundamental domain. fact, optimal plans domain may even involve executing action multiple times, something always unnecessary
purely positive domain. However, numeric effects full durative action generality
PDDL2.1 necessary.
on-line nature task unambiguous objective function,
additional trade-off domain planning time execution time
absent much prior work planning scheduling. setting set sheets
revealed incrementally time, unlike classical temporal planning entire
problem instance available once. contrast much work continual planning
(desJardins, Durfee, Ortiz, & Wolverton, 1999), tight constraints domain require
produce complete plan sheet execution begin. domain
emphasizes on-line decision making, received limited attention date.
objective complete known print jobs soon possible, taking long
synthesize slightly shorter plan worse quickly finding near-optimal solution.
especially true rerouting in-flight sheets exception handling.
Although present system temporal planner, fits easily tradition
constraint-based scheduling (Smith & Cheng, 1993; Policella, Cesta, Oddi, & Smith,
2007). main difference actions time points resource allocations added
incrementally rather present start search process. central
process identifying temporal conflicts, posting constraints resolve them, computing
bounds guide search remains same. approach, attempt maintain
conflict-free schedule rather allowing contention accumulate carefully
choosing conflicts resolve first. approach perhaps similar spirit
taken IxTeT system (Ghallab & Laruelle, 1994).
basic approach coordinating separate state-space searches via temporal constraints may well suitable on-line planning domains. planning individual
print jobs managing multiple plans time, strategy similar spirit
planners partition goals subgoals later merge plans individual goals (Wah
& Chen, 2003; Koehler & Hoffmann, 2000). framework, even though print job
planned locally, plan manager along global temporal database ensures
temporal resource inconsistencies step search. would
interesting see strategy could used solve partitionable STRIPS planning
problems effectively.

4. Nominal Sheet Planning
sheet planner builds plan sheet job using combination regression
state-space planning partial-order scheduling. plans adding one module action
time, starting finisher sequence actions reaches feeder. Adding
427

fiRuml, Do, Zhou, & Fromherz

action sheets itinerary (i.e., plan) causes resource allocations made
resources required execution action. Given media path redundancies
RMP, planner usually faces multiple choices action add planning
step. organize search, planner uses best-first A* search planning-graph
heuristic, adjusted resource conflicts, estimates promising plan suffix
is. Unlike traditional regression planners, maintain maximum flexibility, action times
start end action resource allocation represented
flexible time points instead absolute times. Temporal constraints used represent
durations actions resolve resource contention imposing orderings among actions.
planner attempts minimize makespan combined global plan sheets,
essence optimizing systems throughput. planner uses domain-dependent
search control knowledge, allowing us use planner run different printing
systems full productivity.
4.1 Domain Language
used two-tiered approach represent RMP domain. highest level,
use specialized language makes easier Xerox engineers model printers.
language specifies printer configurations components connected
other. Basic components different capabilities components grouped
hierarchical structure. model files format automatically translated
variation PDDL2.1, fed planner. automatic translation
process instantiates primitive modules converts modules capabilities
durative actions. movement sheet marking actions directly
translated printer model traditional logical preconditions effects test
modify attributes sheet. Following spirit compositionality earlier work
(Fromherz et al., 1999), model system automatically synthesized
models individual components.
PDDL, distinguish two types input planner. planning
begins, domain description containing predicate action templates provided.
problem descriptions arrive on-line, containing initial goal states, sets
literals describing starting desired configurations. action representation
similar durative actions PDDL2.1, notable difference use
explicit representation resources. Actions specify exclusive use different types
resources time intervals specified relative actions start end time. Executing
one action may involve allocating multiple resources various types as: unit-capacity,
multi-capacity, cyclic, state resources. actions also specify real-valued duration
bounds. is, one specify upper lower bounds let planner choose
desired duration action. critical modeling controllable-speed paper
paths, useful practice. PDDL allows specification duration
ranges, aware IPC benchmark general-purpose planner
supports it.
summarize, core part domain file set actions, corresponds
capability component printer 4-tuple = hPre, Eff, dur, Alloci,
where:
428

fiOn-line Planning Scheduling Modular Printers

PrintSimplexAndInvert(?sheet, ?side, ?color, ?image)
preconditions: Location(?sheet, Printer1-Input)
Blank(?sheet)
SideUp(?sheet,?side)
Opposite(?side, ?other-side)
CanPrint(MarkingEngine, ?color)
effects: Location(?sheet, Printer1-Output)
Location(?sheet, Printer1-Input)
HasImage(?sheet,?side,?image)
Blank(?sheet)
SideUp(?sheet, ?side)
SideUp(?sheet,?other-side)
duration: [13.2 seconds, 15.0 seconds]
set-up time: 0.1 second
allocations: MarkingEngine ?start + 5.9 3.7 seconds
Figure 8: simple action specification.
Pre Eff sets literals representing actions preconditions effects.
dur pair hlower, upperi scalars representing upper lower bounds
action duration.
Alloc set triplets hres, offset, duri indicating action starting time sa
uses resource res interval [sa + offset, sa + offset + dur]. constraints
different types resources are:
Unit-capacity: type resource non-sharable thus allocations
given resource type overlap. provides good model
physical space common type resource used planner.
Cyclic: cyclic resource one special type unit-capacity resources
repeated durations resources unavailable
actions selected planner. example, unavailable durations may
represent routine automatic maintenance modules.
Multi-capacity: upper-bound maximum number allocations
given resource type overlap. Moreover, allocations follow
first-in-first-out order. Thus, two allocations A1 = [sA1 , eA1 ]
A2 = [sA2 , eA2 ] sA1 sA2 implies eA1 eA2 .
State resource: resource labeled using one set states. Allocations resource type overlap require
resource state.
simple example given Figure 8. Set-up time refers required time
action committed execution beginscertain actions require extensive
preparation part module sheet arrives action really
429

fiRuml, Do, Zhou, & Fromherz

background:
initial:

goal:

print job ID:

Sheet-23
Location(Sheet-23, Some-Feeder)
Blank(Sheet-23)
SideUp(Sheet-23,Side 1)
Location(Sheet-23, Upper-Finisher)
HasImage(Sheet-23, Side 1, Image 1)
HasImage(Sheet-23, Side 2, Image 2)
Color(Sheet-23, Side 1, Color)
Color(Sheet-23, Side 2, Black & White)
5

Figure 9: sample sheet specification.
performed. resource usage, PrintSimplexAndInvert action Figure 8 specifies
exclusive use MarkingEngine 5.9 seconds start action 3.7
seconds later. Printer modules multiple independent resources actions
short allocation durations relative overall action duration work multiple
sheets simultaneously. PDDL, arbitrary predicates made hold start,
end, duration action. expressivity needed domain
thus assume simple semantics similar using TGP planner Smith
Weld (1999) which: (1) delete effects happen start; (2) add effects happen
end; (3) preconditions deleted start; (4) preconditions
deleted all. addition sheet-dependent literals, sometimes convenient
specify actions using preconditions refer literals independent
particular goals sought. background knowledge domain supplied
separately machine specification, although could also compiled action
specifications. example, possible colors engines put sheet paper
(e.g., Black&White, Color, Custom Color) default sides papers (e.g., Front, Back)
specified way. represented similarly constant concept PDDL.
addition static domain description, on-line sheet requests modeled
initial goal state pairs describing starting desired sheet configurations.
new initial/goal pair defines new object (the sheet) associated literals
planner track. Specifically, problem description particular sheet 4-tuple
hJob, Initial, Goal, Backgroundi, Job id print job sheet belongs
Initial, Goal, Background sets literals.
simple example sheet specification given Figure 9. example, Some-Feeder
virtual location sheet sources placed Upper-Finisher one particular
finisher sheets belong print job 5 need routed to. terms Figure 3,
feeder location literal added goal plan manager, maintains
table active jobs finisher assigned each. Finisher assignment handled
extracting finisher selected planner plan first sheet job.
finishing requires actions plan actions never reconsidered (only
rescheduled), planner never reconsider jobs finisher assignment, even hasnt
begun production yet.
430

fiOn-line Planning Scheduling Modular Printers

Given domain description (top left Figure 3) low-level delay constant tdelay
capturing latency machine controller software, planner accepts stream
sheets arriving asynchronously time. Note sheets may belong different print
jobs printed parallel; within print job, sheets need routed
finisher (among multiple finishers) finish order. stream corresponds
standard notion PDDL problem instance. sheet, planner must eventually
return plan: sequence actions labeled start times (in absolute wall clock time)
transform initial state goal state. allocations made
unit-capacity resource multiple actions must overlap time (state multi-capacity
resources different constraints described earlier). Happily, plans individual sheets
independent except interactions resources. Additional constraints
planner include:
plans sheets print job id must finish destination,
plans sheets print job id must finish order
jobs submitted,
first action plan must begin sooner tdelay seconds issued
planner (with tdelay represents delays communication negotiation
printer module controller),
subsequent actions must begin times obey duration constraints specified
previous action (thus assumed previous action ends
next action starts).
4.2 Temporal Reasoning
Printer control rich temporal domain real-time constraints: (i) wall-clock
time plans individual sheets, (2) plans different sheets, (3) planner machine controller. Thus, fast temporal constraint propagation,
consistency checking, querying extremely important planner. maintain
temporal constraints using Simple Temporal Network (STN) (Dechter et al., 1991),
represented box named STN Figure 3. Essentially, network contains set
temporal time points ti constraints form lb ti tj ub .
time points managed STN include action start end times resource allocation
start end times. Temporal constraints maintained STN are:
constraints wall-clock action start time;
action start end times within action duration range;
constraints action start time resource allocation action;
conflicts various types resources.
use A* search strategy maintains multiple open search nodes,
separate STN node. Temporal constraints added appropriate STN
search node expanded. Whenever new constraint added, propagation tightens
431

fiRuml, Do, Zhou, & Fromherz

Planning Time (in seconds)

IDPC
AC-3

4

2

0
20

40

60

80

100

Sheet Number

Figure 10: Simple arc consistency faster incremental directed path consistency
maintaining STNs.

upper lower bounds domain affected time point. lead
memory usage extra overhead, allows us deal temporal
constraint retraction, needed single STN used multiple search nodes.
Retracting temporal constraints STN complicated time consuming process.
planner must run indefinitely, perform garbage collection time points
STN sheet planning episodes, harvesting lie past.
time points flexible plans belong sent machine
controller. planning new sheet, plan manager checks queue planned
sheets see could begin soon. are, plans released
machine controller execute. New temporal constraints added freeze
start end times actions belonging plans sent controller. time points
frozen earliest possible wall-clock time indicated STN based
constraint set. constraints cause significant propagation turn (1) freeze
start end times resource allocations related actions frozen plans;
(2) tighten starting times actions remaining plans.
original representation STN complete matrix time relations updated
all-pairs shortest paths (Dechter et al., 1991) much inefficient purposes.
implemented two versions STN. One uses incremental directed path
consistency (IDPC) algorithm (Chleq, 1995), may change values edges
constraint graph well introduce new edges requires linear time find
minimum maximum interval two time points database.
uses arc consistency (Cervoni et al., 1994) maintains point minimum
432

fiOn-line Planning Scheduling Modular Printers

maximum times t0 , reference time point. latter method, one cannot
easily obtain exact relations arbitrary time points, relations t0 .
However, long inconsistency efficiently detected constraints added,
need query relations arbitrary pairs points, efficiency gains
welcome. New arcs never added network propagation existing
ones modified, means copying network new search node
entail copying arcs. Figure 10 attests, results dramatic time
savings technique used current implementation. improved
implementation (1) using change flags facilitate faster cycle detection temporal
consistency checking (2) converting times durations integer values (with user
defined precision) eliminate rounding effects increase speed.
4.3 Planning Sheet
planning individual sheets, regressed state representation contains state
sheet, may partially specified. A* search used find optimal plan
current sheet, context previous sheets. optimal plan
sheet found, resource allocations STN used plan passed back
plan manager become basis planning next sheet.
One unusual feature planning approach seamlessly integrate planning
scheduling. Starting times actions fixed merely constrained temporal
ordering constraints STN. insist potential overlaps allocations
resource resolved immediately, resulting potentially multiple children
single action choice. allows temporal propagation update action time bounds
guide plan search. plan single sheet totally-ordered sequence
actions, partial orders actions belong plans different sheets
represent resource conflict resolutions.
4.3.1 State Representation
plan must feasible context previous plans, state contains
information current sheet previous plans. specifically, state
3-tuple hLiterals, Tdb, Rsrcsi which:
Literals describes regressed logical state current sheet. distinguish
literals whose status true, false, unknown (Le, Baral, Zhang, & Tran, 2004).
distinction false unknown literals important domain may fine-grained restrictions acceptable values unspecified
attributes sheet. example, sheet first given print job,
finisher representing final location sheet unknown
finisher allocated another print job plan sheet
executed. discuss below, allow regression match unknown literals
true false effects actions; sense unknown function like dont
care. implementation, represent explicitly literals currently
true whose value unknown, false literals represented implicitly.
433

fiRuml, Do, Zhou, & Fromherz

Tdb temporal database represented simple temporal network (STN) containing
known time points current constraints them. includes constraints different plans, actions plan, well
wall-clock time. Examples time points include start/end times actions
resource allocations. soon plan given sheet sent machine
(sheets 1 2 Figure 4), time points associated plan Tdb
longer allowed float clamped lower bounds. time points
flexible.
Rsrcs set current resource allocations, representing commitments made
plans previous sheets partial plan current sheet. resource
allocation form hres, tp , tp res particular resource tp1 , tp2
two time points Tdb representing duration res allocated action.
Note multiple resources domain resource
multiple (overlapping non-overlapping depending resource type) resource
allocations. implementation, maintain ordered list allocations
resource, recent oldest.
essence, state contains information reflecting strategy planner: hybrid state-space sequential temporal regression search partial order scheduling.
Literals action start end time-points represent temporal-planning regressed
state Rsrcs temporal orderings competing resource allocations represent partial-order scheduling constraints actions plans different sheets.
4.3.2 Branching Applicable Actions
regressed logical state planner 3-tuple L = hLt , Lf , Lu Lt , Lf ,
Lu disjoint sets literals true, false, unknown, respectively. Pre+ (a)
Pre (a) sets positive negative preconditions Add(a) Del(a)
sets positive negative effects action a, regression rules used
determine action applicability update state literals are:
Applicability Action applicable literal set L (1) none effects inconsistent L (2) preconditions modified effects


consistent L. formally, (1) (Add(a) Lf = ) (Del(a) Lt = ), (2)


(Pre+ (a) Lf Del(a)) (Pre (a) Lt Add(a)).

many planning settings, additional criterion applicability added withT
destroying completeness: least one effect must match L ((Add(a) Lt 6=

) (Del(a) Lf 6= )). necessarily valid setting adding
no-op action may give time existing resource allocation run out,
enabling actions used might lead shorter plan.

Update regression L = hLt , Lf , Lu applicable action derived undoing effects unioning result preconditions. given literal
l modified effect a, status unknown regressed state unless
also specified corresponding precondition (e.g., l precondition a).
434

fiOn-line Planning Scheduling Modular Printers

formally, (1) Lt = (Lt \ Add(a)) Pre+ (a); (2) Lf = (Lf \ Del(a))



3) Lu = (Lu (Add(a) Del(a))) \ (Pre+ (a) Pre (a))




Pre (A);

Given |Lf | usually much larger |Lt | |Lu | domain, explicitly store
Lt Lu current implementation use closed-world assumption imply
literals belong Lf . modeling translator provide Xerox engineers
modeling printers encourages effects mentioned preconditions, reducing
growth number unknown literals. example, x Add(a) x P (a).
Although usually case domain, note goal
state always fully specified (with unknown literals) every actions effects
corresponding preconditions, regressed states would fully specified. One could
simplify logical state representation L = hLt , Lf simplify regression rules
Applicability Action applicable iff effects match L: Add(a) Lt
Del(a) Lf .
Update Regressing hLt , Lf gives h(Lt \Add(a))



Del(A), (Lf \Del(a))



Add(a)i

plan considered complete literals unify desired initial state (step 9
Figure 6). optimal plan sheet found, temporal database used
plan passed back outer loop Figure 6 becomes basis planning
next sheet. feasible windows maintained around time points plan
plan released machine controller, subsequent plans allowed make
earlier allocations resources push actions earlier plans later.
ordering leads earlier end time newer goal, selected. provides
way complex job j2 submitted simple job j1 start execution
printer earlier j1 . order starts allowed long sheets print
job finish correct order. often provide important productivity gains.
4.3.3 Branching Resource Allocation Orderings
first step creating regressed states branch actions applicable
L, applying candidate action fact result multiple child nodes due
resource contention. scheduling algorithms use complex reasoning disjunctive
constraints avoid premature branching ordering decisions might well resolved
propagation (Baptiste & Pape, 1995). take different approach, insisting
potential overlaps allocations resource resolved immediately. Temporal
constraints posted order potentially overlapping allocations changes
propagate action times. many action durations relatively rigid typical
printers, aggressive commitment propagate cause changes potential end
times plan, immediately helping guide search process. multiple orderings
may possible, may many resulting child search nodes.
example, Figure 4, assume current candidate action searching
plan sheet 5 uses resource r duration [s, e]. also assume
n actions plans sheets 14 also use r, implying n existing
non-overlapping resource allocations [s1 , e1 ]....[sn , en ] corresponding time points
temporal database. trying allocate r a, one obvious consistent choice
435

fiRuml, Do, Zhou, & Fromherz

end time
new plan

earliest
start time
next actio


planning
start time

estimated length
plan come
(PG + Res. Conflict)

predicted
planning
time

end time
prev. plan
job

end time
plans

length
plan far

t1

t2

t3

t4

STN: plan starting time constraint

t5

t6

t7

STN: sheet ordering constraint

Branching actions, resource conflicts +
STN: resource contention constraints

Figure 11: Important time points constructing evaluating plan.
putting previous allocations adding temporal constraint en s.
However, also gaps existing allocations [si , ei ], allowing us post
constraints ei e si+1 . possible allocation r generates
distinct child node search space. action use several different resources
r, number branches potentially quite large. However, immediately resolving
potential overlaps allocations resource avoids introduction disjunctions
temporal network, maintaining tractability temporal constraint propagation.
summary, every branch planners search space, modify logical state
branching relevant actions potentially introduce different temporal constraints
order resolve resource contention. branch results different irrevocable
choice reflected final plan, state node planners search tree
unique. Therefore, need consider problem duplicating search effort
due reaching state two different search paths.
4.3.4 Heuristic Estimation
potential plan suffix, lower bound computed remaining makespan,
order guide planners A* search. Figure 11 illustrates heuristic estimate
used. figure, planning start time (t1 ) refers wall-clock time
planning process started earliest-start-time = current wall-clock time + predicted planning time (t2 ) estimated time find plan current sheet
thus earliest time action scheduled begin. Note practice,
machine controller communication negotiation time also added predicted
planning time. hypothetical start time plan found (t3 ) constrained
happen earliest possible wall-clock plan execution time (t2 t3 ). plan constrained end previous sheets print job (t5 t6 ),
necessarily constrained start plans previous sheets. start time
next action added regressed partial plan (t4 ) constrained occur least
436

fiOn-line Planning Scheduling Modular Printers

hypothetical plan starting time (t3 + t4 ) heuristic value
makespan remaining plan complete current regressed partial-plan.
overall objective minimize earliest possible end time plans, including
sheet planning for. indicated lower-bound floating
time point t7 Figure 11. time point constrained end time points
sheets planned one currently planned. current
sheet, represented constraints t6 t7 shown Figure 11. t6
constrained end completion time planned sheets
print job, constraint essentially pushes t7 sheets current print
job end. support objective function, primary criterion evaluating promise
partial plan (step 8 Figure 6) estimate earliest possible happening time
t7 , indicated STN embedded search node, constraints shown
Figure 11 added current branch.
key duration affects t7 heuristic estimate lower bound
additional makespan required complete current regressed plan. heuristic value
indicated Figure 11 estimated remaining makespan t3 t4 . adding
constraint t2 t3 , insertion may thus change earliest time subsequent time
points t4 , t5 , t6 t7 . may also introduce inconsistency temporal database,
case safely abandon plan. Given current plan end
end time previous sheets print job (t5 t6 ), objective function
minimize t7 without causing inconsistency temporal database. break ties
favor of:
smaller t6 (e.g., end time current print job)
smaller predicted makespan (t6 t3 )
larger currently realized makespan (t6 t4 ). analogous breaking ties
f (n) A* search larger g(n), thus encourages extension plans
nearer goal.
performance search-based planner heavily depends quality
heuristic estimating makespan-to-go. estimate building temporal planning
graph adjustment logical mutex resource contentions. rest
section, discuss details computed. Overall, want effective
planning heuristic is:
Admissible: maintaining high plan quality (high productivity printer)
important criterion customer.
Informed easy compute: cases, allowed fraction
second find feasible plan. delay finding plan delay plan start
execution time thus reduce overall productivity.
derive admissible estimate duration required achieve given set goals
G initial state, perform dynamic programming explicit representation
bi-level temporal planning graph, described TGP system (Smith
& Weld, 1999). TGP, planning graph represented fact level action
437

fiRuml, Do, Zhou, & Fromherz

level. Starting initial state time = 0, graph grown forward time
actions activated preconditions satisfied non-mutex.
three types mutual exclusion relations (fact-fact, fact-action, action-action)
propagated graph building process. graph expansion phase alternates
plan extraction phase starting time point goals appear nonmutex graph.
graph expansion algorithm, action fact f , store first times
ta tf optimistically occur f optimistically achieved.
correspond first times f appear temporal planning graph.
mutex propagation, also store first time point pair facts hf1 , f2
achieved together pair actions ha1 , a2 execute together. planning
graph, first time points hf1 , f2 ha1 , a2 become non-mutex.
implementation, fact-action mutex fact f action converted action
mutex hnoopf , ai, discuss later.
1. begin: f, a, f1 , f2 , a1 , a2 : ta = tf = thf1 ,f2 = tha1 ,a2 = .
2. Let initial state: f, f1 , f2 : tf = 0, thf1 ,f2 = 0.
3. Dynamically update values ta , tf , thf1 ,f2 , tha1 ,a2 starting initial state
time = 0 follows:
ta = max (setup time(a),

max

f P rec(a)

tf ,

max

f1 ,f2 P rec(a)

thf1 ,f2 )

tf = min (ta + dur(a))

(2)

f Eff(a)

thf1 ,f2 = min (tha1 ,a2 +

max

(dur(a1 ), dur(a2 )))

f1 Eff(a1 ),f2 Eff(a2 )

tha1 ,a2 = max (ta1 , ta2 ,

max

f1 P rec(a1 ),f2 P rec(a2 )

(1)

thf1 ,f2 )

(3)

(4)

updates done increasing order time, usual planning-graph
building algorithms.
4. Stop g G : tg < g1 , g2 G : thg1 ,g2i < reach fixed point.
equations (1)-(4) shown above, actions include noop actions
normal planning graph. actions start time point fact first
achieved. mutex relation noop action equivalent fact-action
mutex described Smith Weld (1999). overall plan sheets
highly parallel, plan single sheet sequential. Therefore, currently use
serial version temporal planning graph, also faster build consumes
less memory. version, two non-noop actions always mutex other.
Therefore, need store reason action mutexes thus value
tha1 ,a2 eq.(4) applicable mutexes noop real action.
438

fiOn-line Planning Scheduling Modular Printers

implementation, build graph starting = 0 putting events (1) activating
action (updating ta ); (2) activating fact (updating tf ); (3) removing fact mutex
(updating thf1 ,f2 ), ordered time occur. event trigger new events
happen later time. example, adding new fact f removing fact mutex hf1 , f2
activate actions supported f f1 f2 , activating action add
events activating facts Effect(a) and/or removing fact mutexes Effect(a)
noop (facts) mutex P recond(a). also explicitly store factfact mutex timing values thf1 ,f2 none action mutexes tha1 ,a2 , instead reasoning
on-the-fly.
time goals achieved pair-wise non-mutex heuristic value
estimating remaining makespan achieve goal state (see Figure 11).
regression planners (Haslum & Geffner, 2001; Nguyen, Kambhampati, & Nigenda, 2002)
compute heuristic (until fixed point reached) planning process
begins, case, planning graph expansion process may revisited goals representing regressed state appear non-mutex graph fixed point
reached previous round expansion. pair-wise mutexes taken
account building graph, estimated value underestimate makespan
plan achieve goal. Therefore, returned value planning graph
lead underestimate (admissible heuristic) objective function (overall
end time t7 ) tie breakers (current sheet end time t6 current estimated makespan
t6 t3 ) described above. Therefore, using estimate, planner return plan p
optimal end time (minimum t7 ) p also minimum makespan among
plans end time.
Incorporating resource mutexes planning graph discussed assumes
printer empty. Thus, create planning graph similar procedure
used off-line planner assume interference relations occur
actions related given sheet planning for. machine empty,
heuristic generally correct simple sheets simplex printing nearly correct
complicated sheets duplex printing.
However, time, printer empty plans sheets
either (1) executing; (2) found planner havent sent machine
controller yet. plans involve resource allocations, either fixed time points (for (1))
still flexible ones (for (2)). find effective heuristic scenarios
machine busy, take account resource mutexes, thus incorporating scheduling
resource contention constraints temporal planning graph. Figure 12 shows
pseudo-code algorithm. key observation that, find earliest time ta
action possibly execute, necessary condition
preconditions appear non-mutex planning graph also resource
conflict resource r used current allocations r (given previous
plans external processes.)
shown example action description Figure 8, resource allocation
action represented triple hr, o, di. starts sa , means resource
r used sa + duration d, normally different duration
da a. example, lone resource usage action PrintSimplexAndInvert Fig439

fiRuml, Do, Zhou, & Fromherz

1. Resource types: r1 , r2 , ....rn
2. resource allocations: {R1 , R2 , ....Rn }
Ri = {[si1 , ei1 ], [si2 , ei2 ], ...[sim , eim ]} ordered list allocations ri
Function CheckEarliest(r, t, d)
3.
r: resource
4.
t: earliest time intend use r
5.
d: duration intend use r
6.
R = {[s1 , e1 ], [s2 , e2 ], ...[sm , em ]}: current allocations r.
7.
tmin : earliest time non-conflict allocation r; initialize to: tmin
8.
allocation l = [sk , ek ] R check
9.
reserve r duration l starts: Latest(sk ) > tmin +
10.
go line 14
11.
else move forward next possible opening end allocation
12.
tmin Earliest(ek )
13. end for;
14. return(tmin )
end function;
Building temporal planning graph
15. consider adding action planning graph
16. Initialize ta earliest time P rec(a) achieved non-mutex (eq.1)
17. Resource allocations a: Ra = {hr1 , o1 , d1 i, hr2 , o2 , d2 i, ..., hrn , , dn i}
18. allocation l = hrk , ok , dk check earliest non-conflict time l
19.
ta CheckEarliest(ri , ta + oi , di ) oi
20. end for;
21. add action temporal planning graph ta
goals appear non pairwise mutex;
Figure 12: Building temporal planning graph adjustments resource conflicts.
ure 8 (M arkingEngine, 5.9, 3.7). Lines 17-19 Figure 12 show building
graph, action preconditions satisfied ta , algorithm goes
resources used a. resource allocation hr, o, di, calls function
CheckEarliest(r, ta +o, d) update ta , earliest executable time start without
overlapping previous resource allocations r. pseudo-code function
CheckEarliest(r, t, d) self-explanatory try find earliest time point
slot allocation r duration without overlapping
previous allocations r.
Figure 13 shows one example demonstrate algorithm. example, try
find starting time action a, needs two unit-capacity resource allocations
hr1 , o1 , d1 hr2 , o2 , d2 shown top-left corner. Assume building
graph, preconditions first achieved non-mutex time t1 . Referring
Figure 13, fixed allocations r1 allocations (1), (2), and(3) r2 (1)
440

fiOn-line Planning Scheduling Modular Printers

sA

A:
r1

dA

o1

d1

r2

o2
(1)

r1

eA

d2
(2)

(3)

(1)

r2

t3

d2

o2

o1

t2

(4)

(3)

(2)

d1

t1

(4)

t4

t5

Figure 13: Example action starting time adjustment using resource contentions
(2). flexible allocations, shown upper/lower bound constraints (4) r1
(3) (4) r2 . Starting t1 , first time point allocate r1
duration d1 without overlapping previous allocations, fixed flexible, t3 .
Thus, adjust new earliest possible starting time t2 = t3 o1 t1 . Given
new earliest possible starting time ta = t2 , find earliest time point t2
allocate resource r2 t5 . Given t4 = t5 o2 t2 , take
t4 final earliest starting time activate action t4 graph (instead
original value t1 )2 .
resource mutexes, starting times actions adjusted higher time
points preconditions achieved, thus time point tG
goals appear non-mutex graph underestimation makespan
remaining plan (value t4 t3 Figure 11). Thus, tG higher summation
durations actions optimal (serial) plan. However, tG still underestimates
first time achieve goals thus still admissible heuristic
main objective function minimizing end time current printing sheets (minimizing
t7 Figure 11). However, use resource mutexes, heuristic
estimate end time (t7 ) tie-breaker plan makespan (t6 t3 ) admissible
resource mutexes, estimate t7 admissible tie-breaker t6 t3
2. Note go resource allocations given action one time (lines 18-20 Figure 12).
Therefore, even action Figure 13 added t4 , still potential conflict resource
r1 consumed (with existing allocation (3) r1 ). However, repeating procedure
(lines 18-20 Figure 12) multiple times fixed point reached (and potentially returning better
heuristic estimate), seek balance heuristic quality heuristic computation time.

441

fiRuml, Do, Zhou, & Fromherz

time (sec)

2
no-mutex
logical mutex
log + res mutex
productivity level

1.5

1

0.5

0
1

4

7 10 13 16 19 22 25 28 31 34 37 40 43 46 49

Figure 14: Performance prototype built industrial partner.

inadmissible. Thus, A* algorithm still guaranteed find optimal solution,
minimizing plan end-time, final solution guaranteed shortest
duration among plans finish earliest.
4.4 Evaluation Nominal Planning
collaboration Xerox, deployed planner control three physical prototype multi-engine printers. deployments successful planner
also used simulation control hundreds hypothetical printer configurations.
planner written Objective Caml, dialect ML, communicates job
submitter machine controller using ASCII text sockets. planner also
communicate plan visualizer graphically display plans. first two videos
on-line appendix show planner controlling prototype depicted Figures 1
2 full productivity, using visualizer (video 1, nominal simulation)
hardware (video 2, nominal hardware). full description videos found
textual appendix paper. shortest single plan machine 25 actions.
Given many sheets printer given time planner
plan ahead, plan manager consistently manages dozens plans hundreds actions. planning, planner needs temporal reasoning regarding conflict
actions current plans hundreds actions previous plans. Even so,
planner consistently average produces plans within 0.27 seconds required keep
printer running full productivity (220 pages/minute). one complex
current Xerox commercial products, planner regularly find optimal plan within
0.01 seconds plan ahead hundreds sheets. ability use domain-independent
planning techniques allows us use planner different configurations, without needing hand-tuned control rules. rest section, elaborate
results.
442

fiOn-line Planning Scheduling Modular Printers

time (sec)

10
nomutex
logical mutex
log + res mutex
productivity level

1
1

6

11

16

21

26

31

36

41

46

0.1

0.01

jobs
Figure 15: Performance current prototype built us shown Figure 1. Note
time plotted logarithmically.

Figure 14 15 show performance planner two complex
parallel printer prototypes built Xerox us. productivity levels higher
printer class currently market. figure, show
CPU time consumed per-sheet basic test using planner print job
50 sheets: (1) without mutexes; (2) serial temporal planning graph mutexes;
(3) combination logical resource mutexes; (4) baseline requirement
planners performance match printers full productivity. prototypes
investigated using planner either simpler complicated used theoretical investigations only. rest section, refer first printer
(results shown Figure 14) Configuration 1 (results shown Figure 15)
Configuration 2.
Configuration 1 printer Figure 14 simpler one, 25 main components
(including four print engines), 35 action schemata, nominal productivity 170 sheets
per minute, leading timing requirement planner around 60/170 = 0.353 sec
planning sheet. shortest possible plan simplest simplex sheet contains 8
actions. normally 10 sheets flight time thus planner
needs handle interaction around 100 actions. However, planner typically
intended plan many sheets ahead number interactions often much higher.
printer built run industrial partner. figure, show without
mutex, planner starts taking base time 0.353 second around sheet 20
consistently takes higher limit around sheet 40. However, logical
resource mutexes, planner consistently returns plans within much shorter time
required. average, planner logical mutex takes average 0.0732 second
find plan combination logical resource mutex helps reduce average
planning time 0.0458 second (1.6x improvement). Without mutexes, planner takes
average 0.4191 seconds keep full productivity printer.
443

fiRuml, Do, Zhou, & Fromherz

Configuration 2 printer tested Figure 15 complicated one.
212 action schemata shortest possible plan contains 16 actions. printer
generally handles 20 sheets time planner needs regularly reason
interactions 300-400 actions. productivity level
printer 220 pages-per-minute, leads base running time planner
60/220 = 0.27 second planning single sheet. wider gap performance
different versions planners, show timing results printer log scale.
Without using mutexes, planner quickly overruns time limit sheets
grows 10 seconds around sheet 35, stopped experiment.
mutexes (logical, resource) planner generally takes less 0.3 second find plan.
However, occasionally planner takes longer. usually plans ahead around
10 sheets releasing plans lower level controller, occasional jumps planning
time dont prevent planner achieving full productivity printer practice.
planner averages 0.1336 second logical mutexes 0.0928 second (1.44x
improvement) used conjunction resource mutexes.
results Figure 14 15 indicate average planning time individual
sheets increases number previous sheets. due fact planner
generally plans faster speed printer print. Thus, number
print requests received increases, number plans unsent queue (i.e., planned
for, sent machine yet) increases. increases resource contention
branching factor searching new plan, leads increment planning
time. Eventually, number lookahead sheets reaches point planning time
equals planners productivity dynamic equilibrium reached. planning time
strictly increase linearly accordance number sheets planned,
rather shows oscillating pattern. due complex interaction
on-line processes planning, freezing time points found plan, plan execution.
lead easier planning problems sheets, depending
sheets interact sheet currently planned.
noted Smith Weld (1999) work based building
planning graph mutex propagation costly, experience. fact,
printer rather empty, total planning time, subsumes graph
mutex building time less 0.01 second. believe due simpler mutex
propagation rule planner fact sequential plan sheet makes
actions mutex step. resource mutex reasoning time optimized
logical mutex implementation improved, seem significant
impediment intended application.
results presented indicate optimal-per-sheet strategy seems
efficient enough, work needed assess drop quality would experienced greedy strategy, always placing current sheets resource
allocations previous sheet. Similarly, lull sheet submissions,
might beneficial plan multiple sheets together, backtracking possible
plans first order find overall faster plan pair together. Sheets
planned whose plans released printer represent opportunities
reconsideration light newer sheets submitted recently.
444

fiOn-line Planning Scheduling Modular Printers

#
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

LPG
Span
Time
9.3
0.01
13.3
0.02
26.6
0.08
15.2
0.07
21.3
0.12
22.4
0.23
30.3
8.73
19.6
52.55
24.2
16.69
23.0
20.02
29.7
40.14
18.3 138.53
42.6
29.09
34.9 427.41
35.3
18.95

SGPlan
Span
Time
8.3
0.45
9.3 308.46
-

Hybrid
Span
Time
8.3 < 0.001
9.4 < 0.001
9.9
0.02
10.6
0.02
11.1
0.03
11.8
0.03
12.3
0.04
13.0
0.06
13.5
0.07
14.2
0.07
14.7
0.08
15.4
0.09
15.9
0.18
16.6
0.21
17.1
0.28

Table 1: Comparison LPG, SGPlan, hybrid planner, showing makespan
plans found (Span) planning times (Time) seconds problems
various numbers sheets (#).

4.4.1 Scaling Generic Planners
Although planner certain features, controllable action durations,
beyond capabilities existing planners, still interesting compare offline systems validate new approach. existing generic systems could solve basic
printing control problems well, might possible extend them, rather developing
specialized planner architecture described above. Therefore, built tool
automatically convert custom domain language PDDL2.1 temporal planning
language, allowing us test current state-of-the-art planners.
domain must simplified fit limitations PDDL, observe
even simplified problems easy solve state-of-the-art academic planners
SGPlan (Chen, Hsu, & Wah, 2006) LPG (Gerevini, Saetti, & Serina, 2003),
winners 2004 2006 International Planning Competitions. Since planners
cannot solve problem Configuration 2 machine Figure 2, tested
much simpler Configuration 1 machine. tested monochrome job
15 simplex sheets, already stretched limits LPG SGPlan. planner
plan ahead hundreds sheets machine. seen Table 1, SGPlan
took 5 minutes find two-sheet plan took planner less
0.001 second find. Compared SGPlan, LPG much faster, although quality
plan LPG finds much worse. average, LPG returns plans 86% longer makespan
400 times slower planner. objective function minimizing
wall-clock finishing time (which combines planning time plan makespan), planner
1000x better planners small printer configuration.
445

fiRuml, Do, Zhou, & Fromherz

addition faster, hybrid planner also predictable. LPGs planning
time much higher variance sometimes takes longer plan smaller job
bigger one. example, took LPG 22 times longer plan 14-sheet job
Table 1 15-sheet job. makes unsuitable real-time on-line
planning, depends accurate estimation planning times efficient temporal
event management.
4.4.2 2008 International Planning Competition
version printing domain used 6th International Planning Competition
(IPC6), held 2008 results presented ICAPS-08 conference.
allowed us evaluate planner many state-of-the-art systems. deterministic
part competition three tracks:
1. sequential objective function minimizing total cost actions plan
2. temporal objective function minimizing plan makespan.
3. net benefit objective function minimizing trade-off total goal
utility action cost.
three tracks, emphasis finding good solution quality. Thus, planner
running time part overall scoring metric. Specifically, planner given
30 minutes run particular planning instance. cost plan returned within
time limit used calculate score particular planner particular
instance. score given instance cost best known solution / cost generated
plan, cost generating plan infinite. total 30 instances
domain thus maximum score competitor achieve 30 (if solutions
returned best quality among competitors, equal best known solution
generated specialized solver).
Real-world planners often demonstrated complex domains spacecraft
mobile robot control difficult simulate thus make awkward benchmarks.
popular temporal planning benchmark domains off-line sense
planners speed affect solution quality. remains need simple yet
realistic benchmark domain combines elements planning scheduling, especially
on-line setting. step toward bridging gap, organizers IPC6 elected
use PARC printer domain two tracks: sequential temporal. temporal track
natural fit due default objective function maximizing printers
productivity, equals minimizing makespan plan finishing print-job
requests. sequential track, minimizing total printing cost used. action
certain cost value using expensive color print engine print black&white
page costs using monochrome print engine. However, cost trade-off may
clear-cut feeder, blank sheets originally reside, closer color
print engine monochrome engine.
Even though internal representation planner, used starting
point competition domain description, far PDDL representation,
difficulties creating competition domain file problem set.
446

fiOn-line Planning Scheduling Modular Printers

C3
18.00

DAE1
14.45

DAE2
5.80

DTGPlan
16.44

F Fah
16.00

h
F Fsa
23.00

LAMA
20.93

PlanA
0.00

SGP 6
24.39

Upwards
26.91

baseline
26.53

Table 2: Scores IPC6 Sequential Satisficing Track
on-line continual nature domain fact constraints
multiple resource allocations action sequential finishing order sheets
job caused blowup problem size using pure PDDL, organizers
to: 1) remove approximate certain constraints original domain; 2) model
less complex machines. Overall, three different printers modeled. first one
simpler four-engine (two color two mono) Configuration 1 machine described
Section 4.4. second one stripped version using half (one color
one mono) first printer. third one another variation one mono
one color printer. first two printers rather symmetric design third one
asymmetric. three significantly simpler fixture built PARC. helped
IPC organizers model actions accurately possible, thus even though
printer configurations hypothetical, reflect characteristics real hardware.
problem files, reduce complexity, print requests single job
multiple sheets used. sheets randomly set either simplex (one-sided print)
duplex (two-sided print) image also randomly selected either mono
color. number sheets varies 1 20. Given print-job request particular
printer configuration, competing planner needed find plan lowest total printing
cost sequential track (matching effectively image requirement print
engine capabilities) smallest makespan temporal track (synchronizing effectively
different print engines). actual competition, problems ranging
1-10 sheets used three modeled printers simplex sheets
used biggest printer (4-engine version) make problems difficult
majority participants.
problems used two tracks (more details below), used planner
described paper provide best known solutions score competing planners.
temporal planning track, ran planner default objective function
maximizing machines productivity. sequential track, ran planner
objective function minimizing printing cost, described later Section 6.1. Given
plan representation different planner standard format used
IPC, post-processing step needed convert one format another. Note
plans returned planner, temporal buffers related time
points, inter-sheet gaps. post-processing step remove small
temporal buffers, needed PDDL plans valid. Therefore, competing
temporal planners could theoretically return shorter makespans planner. However,
results described show planner still superior competing
planners terms plan quality. organizers officially reveal plan running
time unofficial results showed planner also much faster competing
planners solving problems.
Tables 2, 3, 4 show IPC results three sub-tracks PARC printer
domain used: sequential satisficing, sequential optimal, temporal satisficing.
447

fiRuml, Do, Zhou, & Fromherz

CFDP
3

CO-Plan
5

CPT3
17

Gamer
0

HSP0
14

HSPF
16

MIPS-XXL
7

PlanA
0

Upwards
0

baseline
10

Table 3: Scores IPC6 Sequential Optimal Track
CPT3
17.38

DAE1
11.93

DAE2
6.81

SGPlan 6
11.04

TFD
5.67

TLP-GP
1.73

baseline
13.87

Table 4: Scores IPC6 Temporal Satisficing Track

planners score would 30 tracks given used provide best known
solutions tracks. baseline planner sequential optimizing track based
blind search optimal cost, sequential satisficing track FF planner,
temporal satisficing Metric-FF planner followed greedy scheduler.
sequential satisficing planners performed well, mostly due fact problems
sequential tracks easy solve, competitors perform well
tracks. reason sequential optimal planners perform well could
solve many problems among 30 selected. temporal satisficing tracks,
planners could solve large number instances, quality plans returned
plans high, thus leading low overall scores. short, results
2008 International Planning Competition reinforced early study indicating generic
off-line planners competitive on-line hybrid system application.
Together, provide evidence demands setting warrant specialized
approach.

5. Exception Handling
maintaining high productivity, thus high return investment,
common important objective, means thing equipment owners
care about. reduce need operator oversight expertise allow use
complex mechanisms, system must autonomic possible. operators
make mistakes even highly-engineered system modules fail, system must
cope execution failure. crucial part RMP value proposition.
example, imagine printer copier never seems jam, runs little slower
month goes on. month, someone opens covers, removes jammed
sheets, system back full productivity. RMP systems planner
used control designed fulfill vision partial productivity subset
modules down. make transition transparent user (and thus increase
perceived reliability system), concentrating developing exception
handling techniques minimize user interventions without stopping slowing
machine. Current products perform exception handling using rules hard-coded
machine module. technique works well simple straight-line systems, would
limited small predefined subset failures complex topologies. modular
RMP systems, astronomical number different printer configurations
failure possibilities, require general exception handling approach.
448

fiOn-line Planning Scheduling Modular Printers

addition, system must work legacy modules order commercially viable, architecture must tolerate components direct control
give rise unexpected events. handle several different exception types
plan rejection (by machine controller), model updates (i.e., modules capabilities go
off-line), sheet jams.
Since plans system tightly interact various scheduling temporal
constraints, whether belong print job, exception affecting
single plan affect executability plans final job integrity. Plans
different stages life cycle need analyzed treated differently (see Figure 16).
Simple exceptions plan rejection model updates handled discarding
recently made plans rolling back state planner sheets
planned. implementation uses non-destructive data structures make efficient.
Execution failures sheet jams require elaborate handling. unsent plans
canceled, need new plans sheets already in-flight time
exception occurs. replanning reuse much nominal planning system,
requires special modifications discuss detail below. section, first
provide overview various types exceptions handle plan
manager reacts them; concentrate hardest part exception handling
framework: finding new set consistent plans in-flight sheets.
5.1 Related Work
several previously-proposed frameworks handling exceptions uncertainty
plan execution. Markov decision processes (Boutilier, Dean, & Hanks, 1999) contingency planning (Pryor & Collins, 1996) build plans policies robust uncertain environment. Planners built techniques normally slow, especially real-time
dynamic environment complex temporal constraints like ours. suitable
domain exceptions happen frequently, need responded
quickly. Fox, Gerevini, Long, Serina (2006) discuss trade-off replanning
plan-repair strategies handling execution failure. algorithms work off-line,
instead on-line real-time environment ours, target different
objective function (in case, plan stability). CASPER system JPL (Chien, Knight,
Stechert, Sherwood, & Rabideau, 1999) uses iterative repairs continuously modify
update plans adjust dynamic environment. Unlike system, CASPER uses
domain control-rules thus less flexible replanning decision also needed
quickly domain (in case, sub-second).
5.2 Basic Exception Handling
planner handle several types exceptions. Figure 16 extends system architecture diagram Figure 3 shows solid lines possible steps replanning
process. general, exception occurs, machine controller sends planner
message real time detailing exception. planner cancels plans
created sent printer controller execute. corresponding
goals rolled back unplanned queue. planner time also tries
find new plans sheets moving printer avoid exceptions.
449

fiRuml, Do, Zhou, & Fromherz

printer model (off!line
p
(
)

Planner
STN
plans
fl ibl
flexible
start time

sheet
descriptions
(on!line)

recreate goals

new plans
l
unplanned

planning

planned/unsent

Plan Manager

sent

fixed!time plans

exceptions
p

Figure 16: System architecture, showing steps involved nominal planning (dashed
lines) replanning (solid lines).

new plans found sent machine controller replace ones
executing.
Next, discuss detail different exception types.
Plan Rejection: plan sent machine controller execute, controller
may reject plan one relevant modules cannot commit executing requested
action time defined planner. rejections rare, caused
module constraints outside scope planners model. example,
printer engine may need time bring toner proper temperaturea state variable
constraint currently modeled system. plan rejected, planner
cancel plans unsent queue, addition recently sent rejected plan.
goals corresponding plans rolled back unplanned queue. Even
plans directly affected error message also need canceled rolled
back plans made commitments made rejected
plan.
Module Update: Machine modules go -line due hardware failure,
sheet jam, benign event, running paper feed tray, unmodeled
process, print engine self-adjustment. Similarly, come on-line
repaired, adjusted, otherwise made ready. happens, module controller
send message planner indicating modules capabilities
on/off. given capability turned off, planner remove corresponding
action consideration future planning episodes. given capability turned on,
planner add action set future planning episodes.
Break-in-Future: module changes status capabilities
off, currently executing unsent plans using module may become invalid.
case, module controller send messages planner indicating plans
450

fiOn-line Planning Scheduling Modular Printers

affected. planner cancel affected unsent plans subsequent plans move
goals back unplanned queue. plans executing thus correspond
sheets already fed machine, planner needs find new plans
affected sheets get correct finisher tray without going
affected modules. next section describes detail reroute in-flight
sheets.
Broken: type exception happens one sheets jammed system.
broken messages sent planner include ids sheets jammed
thus cannot reused rerouted failure. sheets jam,
normally also disable modules thus broken message normally accompanied
several module update messages, described above. handling broken
exception similar handling break-in-future exception many respects:
involves canceling unsent plans finding new plans in-flight sheets. However,
main differences are: (1) in-flight sheets jammed cannot rerouted; (2)
critically, jammed sheets break print job integrity. discuss detail next.
5.3 In-flight Sheet Replanning
section, discuss problem finding new set plans in-flight sheets
sheet jammed module used plans broken. constraints
make replanning challenging nominal planning are:
Sheets cannot stop slow planner searches new plans inflight sheets. Thus, planner takes much time find new plans, jams
and/or module failures cascade.
newly found plans flexible starting times nominal planning
case, start location sheets projected
plans found. new locations depend actual replanning time
planner.
in-flight sheets occurring later print job jammed sheet
rerouted purge tray. sheets jobs without jammed sheets still need
finish correct finisher tray order.
Replanning involves four main steps: (1) create new goals in-flight sheets; (2)
predict (an upper bound on) replanning time; (3) project sheets according
original trajectory predicted planning time find future locations,
form new initial state replanning problem; (4) find plans sheets
salvageable (those possible avoid broken modules jammed sheets
time), satisfying constraints listed above.
5.3.1 Example
provide concrete example illustrating replanning procedure. Figures 17 & 18
show scenario three in-flight sheets: S1.1 S1.2 belong
print job planned go finisher 2 (in middle); sheet S2.1 belongs
451

fiRuml, Do, Zhou, & Fromherz

1.2
1.1

Finisher 1
Finisher 2
P
Purge
tray

2.1

Figure 17: Replanning Example (before jam): sheet 1.1 1.2 planned enter finisher
2, sheet 2.1 finisher 1.

1.2
1.1

Finisher 1
Finisher 2
Purge Tray

2.1

Figure 18: Replanning Example (after jam): sheet 1.1 jammed, requires planner reroute sheet 1.2 purge tray reroute sheet 2.1 circumvent
jammed sheet going finisher 1.

different print job scheduled go finisher 1. third finisher purge tray.
original routes indicated dashed lines Figure 17. Assume S1.1
jammed. According original routes, have: (1) S1.2 arrive finisher tray
out-of-order (because S1.1 arrive it); (2) S2.1 crash module
S1.1 jammed. Therefore, need find new plans two sheets S1.2
instead go purge tray S2.1 goes around S1.1 . Finding plans takes time
given cannot stop slow S1.2 S1.2 finding new plans them,
two sheets continue original trajectories new locations,
452

fiOn-line Planning Scheduling Modular Printers

sheet 1
plan 2
plan 1

...
plan 3

sheet 2

plan 4

...
plan 1

plan 2

plan 3

Figure 19: Chaining many searches together gives search tree potentially infinite
branching factor.
circled Figure 18. there, machine controller apply new plans, indicated
figure solid lines, order guarantee print-job integrity avoiding
cascading failures. replanning done, planner generate fresh plans
re-create S1.1 S1.2 .
example shows one replanning strategy new goal out-of-order
sheet S1.2 set go purge tray. default strategy replanner tries
clear machine finish replanning process quickly possible return
normal operation. However, scenarios printing media expensive
content confidential purging sheets desirable. scenarios,
also experimented different strategy purge S1.2 keeps
machine (for example, looping holding pattern) waiting S1.1
reprinted, S1.2 routed original finisher. modification necessary
implement strategy system change way replanning goals end-time
constraints generated. tested strategy successfully small number
sheets, although sheets could saved one allowed slow transports.
5.3.2 Chained BFS
normal operation, planner uses A* find plan given sheet end
soonest, given (temporally flexible) plans previous sheets. plan always exists
scheduled sufficiently far future. rerouting, problem different. must
find jointly feasible plans many in-flight sheets possible. cannot greedily plan
one sheet time, committing irrevocably plans previous sheets,
plan selected one sheet might render subsequent sheets infeasible. cannot happen
nominal planning, later sheets always feasible scheduled sufficiently far
future. replanning, however, forced confront true multi-body
planning problem.
considered two strategies solve problem. first simply plan
joint action space sheets. would result large branching factor
clear us design effective heuristic evaluation function. chose different
approach, retain view planning sheet individually using
heuristic search. However, overlay additional search top this, depicted
Figure 19. high-level search, branching node represents situation
selected certain specific plans previous sheets time select plan
453

fiRuml, Do, Zhou, & Fromherz

ChainedBFS (problems)
1. problems empty, return success
2. p remove first problem problems
3. initialize openlist p
4. repeat openlist empty node limit reached:
5.
n best node openlist
6.
n goal, call ChainedBFS remaining problems
7.
expand n, adding children openlist
Figure 20: Sketch Chained Best-First Search depth-first strategy.
additional sheet. children node represent commitments different possible
plans additional sheet. considering different paths high-level search
tree, consider different combinations plans different sheets. call
approach chained best-first search. current implementation, sheets replanned
original order, approximation increasing distance exit, correlates
increasing flexibility. alternative approach replan order urgency
defined time left reroute sheet becomes unsalvageable.
children node represent possible plans returned best-first
search, children available once. Instead, individual sheet-level planning
search encounter goal nodes one time. cannot terminate search
find first goal node single-sheet planning guarantee
sheet-plan reaching first goal make subsequent sheets feasible. Finding plan
single sheet merely results new branch high-level space, retain
completeness must retain ability continue search uncover additional
possible plans. fact, printers contain loops paper path,
may infinite number possible plans given sheet. Fundamentally, highlevel search must explore tree nodes expanded incrementally branching
factor potentially infinite.
identified three possible strategies searching tree infinite branching factor.
first best-first approach, one formulates traditional heuristic evaluation
function high-level nodes. nodes represent commitments complete plans
subset in-flight sheets, heuristic function needs estimate probability
plans allow feasible plans remaining sheets found. infinite
branching factor could handled using Partial-Expansion A* (Yoshizumi, Miura, & Ishida,
2000), although would require non-trivial lower bound heuristic value
plans yet found. clear us might done.
second possible strategy considered limited discrepancy search (Korf, 1996). Unlike
depth-first search, limited discrepancy search doesnt necessarily visit children
node, potentially infinite us. disadvantage method that,
revisit node many times different discrepancy bounds, suffer
considerable node regeneration overhead.
third strategy, one used implementation, perhaps simplest:
depth-first search. Figure 20 shows pseudo-code sketch. fixed number
sheets replan, high-level search tree bounded depth. cope potentially
454

fiOn-line Planning Scheduling Modular Printers

infinite branching factor, impose limit number nodes low-level sheet
planning search may expand. avoids danger searching forever one high-level
node without finding another goal, reminiscent iterative broadening (Ginsberg
& Harvey, 1992). guide sheet-level planning, use heuristic minimizes
plan duration. attempts minimize resource use machine maximize
probability sheets feasible plans.
5.4 Evaluation
now, exception handling strategies current production printers to:
(1) stop production ask operator remove sheets (2) use machine-specific
customized local rules purge sheets system. work first demonstrate
automatic exception handling rely machine-specific control rules.
planner handle two easiest types exception: Plan Reject Module
Update without difficulties. Break-In-Future Broken exceptions,
currently reroute fly five sheets machine shown Figure 1.
number may seem low, recall replanning harder nominal planning
factor exponential number in-flight sheets. simpler prototype systems
Xerox fewer (but larger) modules, four print engines, aggregate throughput
180 pages-per-minute, planner able successfully reroute reroutable sheets
different jams happen. demonstrated replanning technology real-time
allowing people come either turn on/off modules, jam sheets intentionally,
sometimes right sheets hit broken module. Upon receiving error messages
machine controller, planner fast enough reroute sheets around
failed modules jammed sheets correct locations. addition experimenting
physical hardware built PARC Xerox, also tested replanning
simulation, connecting planner visualizer instead machine controller.
on-line appendix contains two videos planner performing in-flight rerouting
PARC prototype, simulation (Video 3, replanning simulation) hardware
(Video 4, replanning hardware).
addition testing replanning framework different hypothetical printer configurations different fault modes, also investigated different exception handling
strategies. example, printing media expensive replanning objective
function switched default objective function finish replanning quickly
possible (which lead many purged sheets) saving many sheets possible (which
lead longer replanning time) planner able successfully route
2 out-of-order sheets long routes (that may contain loops) system waiting
jammed sheet printed routed correct finisher tray.
achievement replanning five sheets large RMP machine may seem
impressive, want point that: (1) planner reroute reroutable sheets
simpler machines (which still much complex biggest multi-engine printer
Xerox currently market); (2) large machine complex automated
planningthe last two IPC winners SGPLan LPG cannot even find plan single
sheet nominal planning using PDDL2.1 version printer domain.
455

fiRuml, Do, Zhou, & Fromherz

6. Handling Multiple Objectives
second major extension nominal planning aimed better meeting shop owners
needs nominal case. point, planners objective run
multi-engine reconfigurable printers full productivity, optimizing machine throughput.
Productivity, important, one many optimization criteria
naturally exist real-world planning scheduling applications like printer control
domain. section, describe several additional objective functions
pointed important industrial partner, discuss extended
planning framework handle them.
modular system multiple print engines, one might want optimize cost
printing choosing print black-only pages monochrome engines avoid using
expensive color engines. Also, one might want optimize image quality choosing
print pages document print engines whose current marking gamuts
similar. printer controller needs give operators ability trade
conflicting objectives maintaining robust operation. meet challenges using
(1) optimization objective combines separate estimates productivity printing
cost, (2) multiple heuristic look-ups efficiently handle image quality consistency
constraints. contrast explicit multi-objective optimization, planner
would return selection non-dominated solutions Pareto frontier, presumably
human choose from, planner needs select single solution execution,
need combine multiple criteria single objective. planner built
atop generic state-space heuristic search, need design new comparison function
order search nodes. addition linear combinations objectives, relatively easy
us handle tiered criteria using tie-breaking strategies.
several academic domain-independent planners GRT (Refanidis &
Vlahavas, 2003) LPG (Gerevini, Saetti, & Serina, 2008) optimize multiple objectives trade-off planning time plan quality. Standard planning
languages, especially PDDL3 (Gerevini & Long, 2006), allow specifying complex objective
functions weighted-sum format (as framework). planner also based
domain-independent planning technology uses extension PDDL, works
dynamic on-line continual environment interacts physical machine,
off-line abstracted environment like previous planners.
6.1 Optimizing Printing Cost
systems heterogeneous print engines, cost printing given page depends
engines used. example, generally costlier print black-and-white
page color engine monochrome one. Thus, minimize overall printing cost,
one use engines lowest printing cost still satisfy image type
quality requirements given print job. so, subset available
engines used printing job thus overall productivity may reduced.
strike balance machine productivity printing cost, implemented objective trade productivity cost vice versa. show
combining different performance criteria single objective, optimization
framework works well single-objective planning efficiently applied
456

fiOn-line Planning Scheduling Modular Printers

multi-objective case. main steps required extend planner
supporting single objective multiple objectives.
Step 1: Extend planners representation machine capabilities model action cost.
Specifically, added cost field representing cost executing capability.
addition, overall objective field user-supplied weights two
objectives: obj = min w1 + w2 c, end time c accumulated total
cost printing sheets.
Step 2: Create one heuristic estimation function objectives. find
best route given sheet, estimate good potential route according
objective functions. Finishing time estimated using temporal planning graph
adjusted resource conflicts, described Section 4.3.4. estimate total plan
execution cost, use dynamic programming starting initial state (i.e., sheet
feeder) compute total cost reach different reachable states. computation similar cost propagation planning graph Sapa planner (Do &
Kambhampati, 2002).
Step 3: Extend search algorithm considering multiple objectives simultaneously.
estimations total time cost combined using user-supplied weights (as
described Step 1) compare nodes best-first A* search algorithm. Given
heuristics time cost admissible, like single objective planner, planner
guaranteed find optimal solution given sheet. weights given,
planner chooses prioritize objectives. example, planner first find plan
lowest cost, break ties favoring plans higher productivity,
favoring one lower wear tear, on. mechanism implemented
fully integrated planner. default option weights specified
optimize productivity break ties total cost.
6.2 Planning Image Quality Consistency
Maintaining image consistency across set heterogeneous print engines especially
important multi-engine printing system. planner achieves enforcing additional image-consistency constraints searching optimal plan. color science,
(in)consistency two colors measured function, often denoted E, calculates distance two device-independent color space.
exist variety functions (the popular called E2000; see Green,
2002), planning purpose suffices assume given two engines, E
function returns non-negative real-valued scalar, called E distance, measures
discrepancy perceived color result printing image two engines.
facing pages (i.e., pages face bound book magazine)
sensitive image-consistency issues, thus consider following constraints
planner:
1. facing-page constraints require facing pages job printed
print engine
2. E constraints allow engines within maximum E distance print
facing pages
457

fiRuml, Do, Zhou, & Fromherz

Given reality two engines E distance zero, facing-page
constraints viewed special case E constraints maximum E
distance set zero. Thus, need focus latter, general.
enforce E constraints, planner keeps track set print capabilities
used print front side sheet, constrained print action
applied back side previous sheet. Since first sheet job
previous sheet, set print capabilities eligible printing front side unconstrained
(i.e., equal entire set print capabilities). subsequent sheets job,
however, subset print capabilities allowed. subset computed based
E constraints including capabilities engines whose E distance
print engine printed back side previous sheet less equal
maximum distance. cases, determined on-line,
E distance pair engines drift time. Thus, planner maintains
on-line version pairwise E-distance matrix engines printer.
adding extra image-consistency constraints reduce brute-force search
space (if constraints make set reachable states smaller), practice found
often makes search problem harder, heuristic computed unconstrained problem, still admissible, longer informative. improve accuracy
heuristic, planner computes temporal planning-graph heuristic legal
combinations print capabilities used print one side sheet,
stores multiple lookup tables, one combination. heuristic estimate
search node needed, planner calculates index lookup table based
state description (e.g., sheet location, monochrome color printing), much
way lookups done pattern databases (Culberson & Schaeffer, 1998).
implementation, hash table hash tables used store multiple lookup tables,
given sheet relevant hash table(s) loaded sheet planned,
set eligible print actions known fixed time.
Since limited number ways printing single face sheet,
approach improving heuristic accuracy little overhead yet significantly reduce
time takes find itinerary. Interestingly, approach also used
improve accuracy heuristic handling exceptions jammed sheets
block paper paths engines, unblocked engines eligible
printing sheets, creating planning problems similar enforcing E constraints.
example, one set E distance blocked engine infinity, effectively
forces sheets go unblocked engines, computational savings comes
use accurate heuristic built specifically particular set
unblocked engines, instead nominal-case heuristic assumes engine blocked.
6.2.1 Planning Constrained Action Set
algorithmic perspective, approach planning image-quality consistency
corresponds solving constrained planning problem reduced set actions (compared unconstrained version). Given planning problem k actions, one create O(2k ) different versions constrained problem. Thus, pre-computing temporal
planning-graph heuristic possible subsets actions quickly become infeasible
458

fiOn-line Planning Scheduling Modular Printers

k increases. describe general solution strikes balance heuristic
accuracy space overhead storing multiple lookup tables, one subset
actions. idea limit m, maximum number actions removed
unconstrained problem, compute heuristic lookup tables constrained
problems. example, usually feasible enumerate constrained problems
one two actions removed action set. compute heuristic
value state constrained problem included pre-computed set,
algorithm consults lookup tables whose removed actions form subset actions removed constrained problem, returns maximum value heuristic
estimate state, since value returned lookup tables admissible.
formally, let h(s|P ) admissible heuristic estimate state constrained problem set actions P removed original action set A,
let maximum number actions removed constrained problems
heuristic pre-computed. heuristic estimate h(s|P ) calculated follows,
h(s|P ) =

(

h(s|P )
maxQP

|Q|=m

|P |
h(s|Q) otherwise

new heuristic resembles hm family admissible heuristics (Haslum & Geffner,
2000), limits maximum cardinality set atoms considered
construction heuristic. difference heuristic considers set removed
actions, whereas hm heuristic considers set satisfied atoms. heuristic also
seen kind multiple pattern database (Holte, Felner, Newton, Meshulam, & Furcy,
2006) one take maximum set heuristic estimates without losing
admissibility, although based action-space abstraction (multiple) pattern
databases based state-space abstraction.
6.3 Evaluation
test ability planner trade machine productivity printing
cost, tested model four-engine prototype printer built Xerox.
better test bed trade-off investigation printer mixed set printer
engines (two color two black-and-white engines) instead four identical black engines
PARC prototype system. Moreover, engines aligned asymmetrically
thus paths leading different engines slightly different. modeled
costs different components consultation Xerox engineers. especially
interested modeling cost print black pages different engines: printing
expensive color engines costs cheaper monochrome engines.
varying weights two objective functions, able show that:
(1) increasing weight given productivity results printer utilization four
engines; (2) increasing weight saving printing cost leads reductions number
unnecessary costly printing, thus fewer black sheets printed color engines.
observe trade-off modules similar functionality well,
different feeders, finishers, paper paths. example, increasing weight saving
costs lowers number sheets fed expensive faster feeder.
also tested search hypothetical printers mixed components similar
459

fiRuml, Do, Zhou, & Fromherz

results observed. also observed moving single multiple objectives
slow planner thus affect overall productivity.
also tested performance planner image-consistency planning.
model printer used four monochrome engines, two faster lowquality engines, remaining two slower high-quality engines. four engines
connected asymmetric paper paths. ran simulation 20-sheet
job requires using two high-quality engines double-sided printing.
done certain E constraints, prevent planner choosing two
low-quality engines. Since particularly interested effect heuristic
search performance, tested planner without using multiple lookup tables,
made significant difference number node expansions A* search
planning times. average, multiple lookup table heuristic used, planner
expands 1783 nodes per sheet; whereas using heuristic computed unconstrained problem, grossly underestimates remaining makespan constrained
problems, needs 6458 node expansions find plan. terms running time, one
uses multiple lookup tables 60% faster using naive heuristic.
One future direction investigate different objective entirely: wear tear.
objective, one would like different machines plant used amount
long term. However, machines often cycled idle long
period cycling introduces wear, one would like recently-used machines
selected soon short term. Although implementation currently supports
throughput cost, easily extensible support additional objectives.

7. Deployment
process building deploying planner, utilized many off-the-shelf techniques academic research planning, extending, integrating form fast
on-line planner/scheduler. section, list important lessons learned
describe ancillary tools necessary develop deploy planner.
hope useful application developers academic researchers
planning.
7.1 Lessons Learned
Modeling important. mean two respects. First, important
end-users printers modeled specialized representation machine
modules connections main themes language.
discussed Section 4.1, representation compiled planner input
language, taking capabilities different modules along inter-connections
producing action schemata. process, set machine capabilities compiled
higher number action schemata ground parameters.
discussion users industrial partners, feel machine-centric language
involving modules, machine instances, inter-connections easier understand
accept, compiled-down representation makes much easier us adopt
STRIPS planning techniques.
460

fiOn-line Planning Scheduling Modular Printers

Second, also found that, understood search algorithm (regression
three-value state representation) heuristics (planning graph mutexes) used
planner, could manipulate modeling actions, goals, initial states
produce quite different computational results. Consider simple example action a12 =
move(l1 , l2 ) moves object location l1 l2 . common form STRIPS
representation action P re(a12 ) = { at(l1 )} Effect(a12 ) = {at(l1 ), at(l2 )}.
Recall use three-value representation literal values true,
false, unknown. Regressing (partial) state s1 = {at(l2 )} using a12 get us state
s2 = {at(l1 ), U nknown(at(l2 )) regressable actions move(l3 , l1 )
move(l3 , l2 ). normal regression rules may consider move(l3 , l2 )
lead optimal length plan, regressing s2 move(l3 , l2 ) cause
inconsistency. fact, domain like ours, branch regressable actions
scenarios need buy time free resource allocations.
Note example, sophisticated techniques discover invariants TIM (Fox
& Long, 1998) DISCOPLAN (Gerevini & Schuert, 1998) discover object
single location time thus s2 regressable
action move(l3 , l2 ). However, eliminate branch simply adding precondition
at(l2 ) action description a12 make sure goal state, location
goal false. Generating extra child node propagating constraints
domain expensive because, addition logical part, state representation
includes temporal resource databases. cutting number generated
nodes important, partially accomplished careful modeling.
Similarly, adding removing predicates domain description great
effects heuristic estimation derived planning graph mutex propagation. experienced scenario adding two extra predicates representing subgoal
completion modeling domain slightly differently achieved speedup nearly 10x
printer configurations.
manipulations reminiscent work Rintanen (2000), showed
domain advice expressed linear temporal logic, dont move package
destination, could compiled planning operators domain using conditional
effects, leading great gains planning efficiency. However, want emphasize
highly configurable systems like ours, dangerous encode explicit action choices
pruning domain. hard guarantee completeness optimality
maintained possible job mixes failure combinations. (For example, looping
sheet may free resource allow job complete earlier.) approach
encode domain physics, is, things universally true domain
help keep search within reachable states, control rules sense
heuristic action selections, condition, choose action. point
physics represented differently, even limited STRIPS, finding right
match chosen search strategy dramatically affect planners performance.
application developers, work fixed benchmark domain representation
allows us exploit another dimension modeling improve planners performance.
suitable planning algorithm depends application specifications.
Even formulating domain using extension STRIPS, went several
461

fiRuml, Do, Zhou, & Fromherz

implementations different planning algorithms settling current one. first
version lifted partial-order planner, still think elegant algorithm.
implemented grounded forward state space planner, approach
dominated planning competitions. However, discussed Section 3.1, realized
combination constraint sheets print job finished
order objective function minimizing finishing time suitable forward
state-space search. finally settled backward state-space framework, much
faster domain. lesson drew approach works
best wide range benchmark domains competition mean
best choice given application; doesnt work, mean less
popular approaches cannot significantly better. Therefore, understanding domain,
important constraints involved, objective function, different planning
algorithms work help selecting suitable strategy. Looking competition
results replacement understanding variety applicable planning algorithms.
fast robust temporal reasoner important. planner,
even though source code Simple Temporal Network (STN) totals less 200
lines code, critical handling temporal relations actions resource allocations within single plan different plans. real-world application
various temporal constraints delays take account, communication, setup time, machine controller coordination, time synchronization delays
planner components overall control architecture, ensuring temporal
consistency one important tasks necessary keeping planner running
without interruption long period time. explicit temporal reasoner also
helped us uniformly represent manage start end times actions different
types resource allocations. also allowed us smoothly extend handling fixed
duration actions action variable durations, extend regular resource allocations resource allocations caused external events cyclic resources allocation
uncontrollable processes. domain, variable action durations context-independent
different actions refuel Logistics domain used competition.
havent noticed many planners competition explicit general-purpose
temporal reasoner, except IxTeT(Ghallab & Laruelle, 1994). However, would like
emphasize real-world setting planner needs coordinate
software expects face various time constraints delays, critical.
many uses planner. Besides main job controlling different
printers, planner also used extensively system analysis purposes. Thus,
planner tested (1) different printer designs help decide better ones;
(2) printers various broken modules test reliability printer.
analyses help product group decide printer built given purpose.
example, customer ran extensive test consisting 11,760 different planner runs
variations single printer configuration. Among runs, used planner
test different combinations possible broken points, different print-job mixes, changed
speeds different modules. Another use test performance upstream
job submission sequencing methods. direct accurate way evaluate job
sequencer run long print-job mix (thousands sheets more) planner
462

fiOn-line Planning Scheduling Modular Printers

measure total makespan. Recently, completed print-job mix 50,000 sheets
without break, intensive regular real-life printer operation.
experiences, learned many potential applications
planner beyond direct machine control.
Exception handling. Given planner interacts parts either
higher lower control hierarchy, exceptions come many forms. believe
similar exceptions would occur applications planner interacts
physical world. robust exception handling (such replanning) important,
found much less research topic compared branches domainindependent planning.
hope observations help researchers develop planning techniques
closer needed real-world applications also useful
considering deploying AI planning applications.
7.2 Ancillary Tools
course building system, developed number ancillary tools around
core planning scheduling software. Among tools, notable piece
visualizer, simulates movement sheet inside printer real time. Like
planner, visualizer adopts model-based principle make machineindependent possible. itinerary given discrete sequence actions,
single time stamp prescribes start time action, linear interpolation
used compute position sheet current simulation time somewhere
start times two consecutive actions. visualizer works one
following two modes: on-line mode accepts live itineraries sent planner
sockets, off-line mode reads previously recorded itineraries file stored
disk.
separate visualization engine specific designs printer, developed
simple module definition language describing dimensions module type,
locations input output ports within modules local coordinate system,
travel distance pair input output ports, optionally customized
drawing function used render type modules screen. Besides
definition module types, visualizer needs know location well orientation
module machine-wide coordinate system. possible specify
information manually, developed another ancillary tool called visualizer preprocessor used automate laborious yet error-prone task. tool,
user needs specify location orientation one module, called seed
module, locations orientations (directly indirectly
connected) modules deduced based connectivity graph modules.
machines one feasible configuration, tool find possible solutions
store multiple files used later visualizer. Besides nominal
case, visualizer also simulate various exceptions paper jams break-infuture scenarios. long-term vision visualizer become design, debug,
verification tool manufacturer, well GUI console end user operates
printer.
463

fiRuml, Do, Zhou, & Fromherz

make easier run tests modular printers, also developed wrapper
program glues together planner controller (or visualizer). takes
input set pre-defined test scenarios specified succinct syntax (e.g., 10sc means
print 10 single-sided color sheets). support simulation pre-fabricated exceptions,
sends special messages visualizer contains information
sheet jam occur. also supports simultaneous printing jobs printers
multiple finishers, uses round robin algorithm draw sheets jobs
rate maintain fairness. facilitate remote testing debugging, wrapper program
uses sockets communicate machine controller (or visualizer).

8. Conclusion
described real-world domain requires novel on-line integration planning
scheduling formalized using temporal extension STRIPS falls
partial-order scheduling temporal PDDL. presented hybrid planner uses
state-space regression per-sheet basis, using temporal constraint network
maintain flexibility partial orderings representing resource conflicts plans
different sheets. system successfully controlled three hardware prototypes
outperforms state-of-the-art planners domain. domain-dependent search control
heuristics necessary control printer composed 170 modules real time.
described extensions handle two critical issues: (1) real-time execution failures;
(2) objective functions beyond productivity. successfully demonstrated fast
replanning multiple objective handling three physical prototype printers many
potential printer configurations simulation.
work provides example AI planning scheduling find real-world
application exotic domains spacecraft mobile robot control, also
common down-to-earth problems manufacturing process control. modular
printer domain representative wider class AI applications require continual
on-line decision-making. novel combination fast continual temporal planning
techniques, shown artificial intelligence successfully enable robust, highperformance, autonomous operation without hand-coded control knowledge.

Acknowledgments
Much work done first author Palo Alto Research Center.
Preliminary results project published Ruml, Do, Fromherz (2005),
Ruml (2006), Do, Ruml, Zhou (2008) summarized Do, Ruml,
Zhou (2008). authors would like thank members Embedded Reasoning
Area PARC, especially Lara Crawford, Haitham Hindi, Johan de Kleer, Lukas Kuhn,
well Danny Bobrow, David Biegelsen, Craig Eldershaw, Dave Duff help
contributions project. industrial collaborators provided domain
expertise invaluable helping us simplify frame application useful
way. Wed like especially thank Bob Lofthus Ron Root enthusiasm
perseverance Steve Hoover supporting project.
464

fiOn-line Planning Scheduling Modular Printers

Appendix A: Video
on-line appendix JAIR website contains four movies system action:
1. nominal-simulation.mp4: shows one simplex job 200 sheets run simulation PARC prototype printer shown Figure 1. planner keeps four
print engines busy, achieving full productivity system.
2. nominal-hardware.wmv: shows two simplex jobs run simultaneously using
four engines PARC hardware prototype. two feeders left
two simple finishing trays right. Red lights machine modules show
position sheets. (Background time synchronization indicated periodic
blinking.) lower left corner, schematic visualization shows sheets
moving machine, one job colored blue red.
3. replanning-simulation.mp4: show simple exceptions handling scenario simulation. Blue sheets red sheets belong different jobs. second sheet blue
job jams. third sheet, already in-flight, rerouted middle purge tray
fresh plans initiated recreate sheets. red job continues uninterrupted.
4. replanning-hardware.wmv: demonstrates two exception handling scenarios.
first shows simple on-line replanning. sheet launched, button pushed
module sheet headed toward, mark module broken.
initiates replanning, sheet routed around failed module. second
modules button pushed, marking failed thereby blocking finishing tray
sheet headed toward. sheet rerouting emerges
remaining finishing tray.
second scenario, module broken already contains first sheet
two-sheet job. replanner fast enough reroute second sheet around
jammed first sheet purge tray. original two sheets planned
scratch arrive lower finishing tray.

References
Baptiste, P., & Pape, C. L. (1995). theoretical experimental comparison constraint
propagation techniques disjunctive scheduling. Proceedings IJCAI-95, pp.
600606.
Bartak, R. (2002). Visopt shopfloor: edge planning scheduling. Proceedings
Conference Principles Practice Constraint Programming (CP-02), pp.
587602.
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research,
11, 191.
Cervoni, R., Cesta, A., & Oddi, A. (1994). Managing dynamic temporal constraint networks.
Proceedings AIPS-94, pp. 1318.
465

fiRuml, Do, Zhou, & Fromherz

Chen, Y., Hsu, C.-W., & Wah, B. (2006). Temporal planning using subgoal partitioning
resolution sgplan. Journal Artificial Intelligence Research, 26, 323369.
Chien, S. A., Knight, R., Stechert, A., Sherwood, R., & Rabideau, G. (1999). Using iterative repair improve responsiveness planning scheduling autonomous
spacecraft. Proc. IJCAI.
Chleq, N. (1995). Efficient algorithms networks quantitative temporal constraints.
Proceedings Constraints-95, pp. 4045.
Crawford, L., Hindi, H., Zhou, R., & Larner, D. (2009). Synchronized control large-scale
networked distributed printing system. Proceedings 2009 IEEE International
Conference Robotics Automation (ICRA-06).
Culberson, J., & Schaeffer, J. (1998). Pattern databases. Computational Intelligence, 14 (3),
318334.
Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence, 49, 6195.
desJardins, M. E., Durfee, E. H., Ortiz, Jr., C. L., & Wolverton, M. J. (1999). survey
research distributed, continual planning. AI Magazine, 20 (4), 1322.
Do, M., Ruml, W., & Zhou, R. (2008). On-line planning scheduling: application
controlling modular printers. Proceedings AAAI-08.
Do, M. B., & Kambhampati, S. (2002). Sapa: multi-objective metric temporal planer.
Journal Artificial Intelligence Research, 20, 155194.
Do, M. B., & Ruml, W. (2006). Lessons learned applying domain-independent planning
high-speed manufacturing. Proceedings ICAPS-06, pp. 370373.
Do, M. B., Ruml, W., & Zhou, R. (2008). Planning modular printers: Beyond productivity. Proceedings Eighteenth International Conference Automated
Planning Scheduling (ICAPS).
Fox, M., Gerevini, A., Long, D., & Serina, I. (2006). Plan stability: Replanning versus plan
repair. Proc. ICAPS-06, pp. 212221.
Fox, M., & Long, D. (1998). automatic inference state invariants TIM. Journal
Artificial Intelligence Research, 9, 367421.
Fox, M., & Long, D. (2003). PDDL2.1: extension PDDL expressing temporal
planning domains. Journal Artificial Intelligence Research, 20, 61124.
Frank, J., & Jonsson, A. (2003). Constraint-based attribute interval planning. Constraints, 8, 339364.
Franklin, G., Powell, J., & Workman, M. (1997). Digital Control Dynamic Systems.
Prentice Hall.
Fromherz, M. P. J., Bobrow, D. G., & de Kleer, J. (2003). Model-based computing
design control reconfigurable systems. AI Magazine, 24 (4), 120130.
Fromherz, M. P. J., Saraswat, V. A., & Bobrow, D. G. (1999). Model-based computing:
Developing flexible machine control software. Artificial Intelligence, 114 (12), 157
202.
466

fiOn-line Planning Scheduling Modular Printers

Gerevini, A., & Long, D. (2006). Preferences soft constraints pddl3. Workshop
Preferences Soft Constraints Planning, ICAPS06.
Gerevini, A., Saetti, A., & Serina, I. (2003). Planning stochastic local search
temporal action graphs lpg. Journal Artificial Intelligence Research, 20, 239290.
Gerevini, A., Saetti, A., & Serina, I. (2008). approach efficient planning numerical
fluents multi-criteria plan quality. Artificial Intelligence, 172, 899944.
Gerevini, A., & Schuert, L. (1998). Inferring state constraints domain-independent
planning. Proceedings Fifteenth National Conference Artificial Intelligence
(AAAI).
Ghallab, M., & Laruelle, H. (1994). Representation control IxTeT, temporal
planner. Proceedings AIPS-94, pp. 6167.
Ghallab, M., Nau, D., & Traverso, P. (2004). Automated Planning Theory Practice.
Morgan Kaufmann, San Francisco.
Ginsberg, M. L., & Harvey, W. D. (1992). Iterative broadening. Artificial Intelligence, 55,
367383.
Green, P. (2002). Colorimetry colour difference. Green, P., & MacDonald, L. (Eds.),
Color Engineering, pp. 4977. Wiley.
Haslum, P., & Geffner, H. (2000). Admissible heuristics optimal planning. Proceedings
AIPS, pp. 140149.
Haslum, P., & Geffner, H. (2001). Heuristic planning time resources. Proceedings
ECP-01.
Hindi, H., Crawford, L., & Fromherz, M. (2005). Synchronization state based control
processes delayed asynchronous measurements. Proc. Decision
Control, 2005 2005 European Control Conference. CDC-ECC 05, pp. 63706375.
Hindi, H., Crawford, L., Zhou, R., & Eldershaw, C. (2008). Efficient waypoint tracking
hybrid controllers double integrators using classical time optimal control. Proc.
47th IEEE Conference Decision Control, 2008 (CDC 2008).
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation
heuristic search. Journal Artificial Intelligence Research, 14, 253302.
Holte, R., Felner, A., Newton, J., Meshulam, R., & Furcy, D. (2006). Maximizing
multiple pattern databases speeds heuristic search. Artificial Intelligence, 170 (16
- 17), 11231136.
Koehler, J., & Hoffmann, J. (2000). reasonable forced goal orderings use
agenda-driven planning algorithm. Journal Artificial Intelligence Research,
12, 338386.
Korf, R. E. (1996). Improved limited discrepancy search. Proceedings AAAI-96, pp.
286291. MIT Press.
Le, T. C., Baral, C., Zhang, X., & Tran, S. (2004). Regression respect sensing
actions partial states. Proceedings AAAI-04.
467

fiRuml, Do, Zhou, & Fromherz

Muscettola, N. (1994). HSTS: Integrating planning scheduling. Zweben, M., & Fox,
M. S. (Eds.), Intelligent Scheduling, chap. 6, pp. 169212. Morgan Kaufmann.
Muscettola, N., Morris, P., & Tsamardinos, I. (1998). Reformulating temporal plans
efficient execution. Proceedings Conference Principles Knowledge Representation Reasoning (KR-98).
Nguyen, X., Kambhampati, S., & Nigenda, R. S. (2002). Planning graph basis
derive heuristics plan synthesis state space csp search. Artificial Intelligence,
135 (1-2), 73124.
Palacios, H., & Geffner, H. (2002). Planning branch bound: constraint programming implementation. Proceedings CLEI-02.
Policella, N., Cesta, A., Oddi, A., & Smith, S. F. (2007). precedence constraint posting
partial order schedules. AI Communications, 20 (3), 163180.
Pryor, L., & Collins, G. (1996). Planning contingencies: decision-based approach.
Journal Artificial Intelligence Research, 4, 287339.
Refanidis, I., & Vlahavas, I. (2003). Multiobjective heuristic state-space planning. Artificial
Intelligence, 145, 132.
Richter, S., Helmert, M., & Westphal, M. (2008). Landmarks revisited. Proceedings
AAAI-08, pp. 975982.
Rintanen, J. (2000). Incorporation temporal logic control plan operators. Proceedings Fourteenth European Conference Artificial Intelligence (ECAI-2000),
pp. 526530.
Ruml, W., Do, M. B., & Fromherz, M. P. J. (2005). On-line planning scheduling
high-speed manufacturing. Proceedings ICAPS-05, pp. 3039.
Smith, D. E., & Weld, D. S. (1999). Temporal planning mutual exclusion reasoning.
Proceedings IJCAI-99, pp. 326333.
Smith, S. F., & Cheng, C.-C. (1993). Slack-based heuristics constraint satisfaction
scheduling. Proceedings AAAI-93, pp. 139144.
Wah, B. W., & Chen, Y. (2003). Partitioning temporal planning problems mixed
space using theory extended saddle points. IEEE International Conference
Tools Artificial Intelligence.
Yoshizumi, T., Miura, T., & Ishida, T. (2000). A* partial expansion large branching
factor problems. Proceedings AAAI-2000, pp. 923929.

468

fiJournal Artificial Intelligence Research 40 (2011) 269-304

Submitted 7/10; published 1/11

Iterated Belief Change Due Actions Observations
Aaron Hunter

hunter@cs.sfu.ca

British Columbia Institute Technology
Burnaby, BC, Canada

James P. Delgrande

jim@cs.sfu.ca

Simon Fraser University
Burnaby, BC, Canada

Abstract
action domains agents may erroneous beliefs, reasoning effects actions involves reasoning belief change. paper, use transition
system approach reason evolution agents beliefs actions executed. actions cause agent perform belief revision others cause agent
perform belief update, interaction revision update nonelementary. present set rationality properties describing interaction
revision update, introduce new class belief change operators reasoning
alternating sequences revisions updates. belief change operators
characterized terms natural shifting operation total pre-orderings interpretations. compare approach related work iterated belief change due action,
conclude directions future research.

1. Introduction
interested modeling belief change caused executing alternating
sequence actions observations. Roughly, agents perform belief update following actions agents perform belief revision following observations. However, date
little explicit consideration iterated belief change results observation follows sequence actions. paper, address belief change context
sequences following form.
(InitialBeliefs) (Action) (Observation) (Action) (Observation)

(1)

assume effects actions completely specified infallible. illustrate
belief change caused kind alternating sequence simply determined straightforward iteration updates revisions. main issue
plausible examples observation lead agent revise
initial belief state, rather current belief state. goal provide general
methodology computing iterated belief change due alternating sequences actions
observations.
1.1 Contributions Existing Research
paper extension previous work (Hunter & Delgrande, 2005). focus
action domains involving single agent execute actions make observations.
assumed every change state world due execution action,
c
2011
AI Access Foundation. rights reserved.

fiHunter & Delgrande

assumed set available actions given. context, two
possible explanations erroneous belief. First, erroneous belief due
incorrect initial belief. Second, erroneous belief due execution hidden
exogenous action. focus primarily first case, since explicitly concerned
single agent scenario. briefly describe contributions make area
belief change caused actions.
One contribution explicitly specify precise properties hold whenever action followed observation. state properties style
AGM postulates belief revision (Alchourron, Gardenfors, & Makinson, 1985),
argue properties hold action domain involving single agent
perfect knowledge actions executed. properties iterated belief change
specify natural generalization AGM postulates; such, easily
justified action domains involving given AGM operator. show
simple examples clear action history plays role interpretation
observation. Therefore, necessary formalize role action history
determining appropriate belief change. However, problem explicitly
addressed related work. best knowledge, work first attempt
formally specifying high-level interaction belief update belief revision
caused actions.
second contribution, give specific methodology combining belief update
operator belief revision operator single formalism. particular, define new
class belief change operators, called belief evolution operators. belief evolution operator
takes two arguments: set states alternating sequence actions observations.
belief evolution operator defined respect fixed update operator
fixed AGM revision operator . Informally, following correspondence
hA1 , 1 , . . . , , n A1 1 n .
basic idea simply translate observations conditions initial beliefs.
manner, define iterated belief change operator respects interaction
properties handles example problems appropriately.
Formally, demonstrate belief evolution operators characterized
natural shifting underlying AGM revision operator. sense, view
iterated belief change modified form revision. general perspective,
belief evolution methodology useful combining action formalism AGM
revision operator. Hence, view belief evolution improved methodology
adding revision operator action formalism.
third contribution work provide mechanism evaluating
performance existing epistemic action formalisms regards iterated belief change.
common past work extend existing action formalism simply adding
formal representation knowledge belief. done, example, action
language (Lobo, Mendez, & Taylor, 2001; Son & Baral, 2001) well Situation
Calculus (SitCalc) (Shapiro, Pagnucco, Lesperance, & Levesque, 2000). easy see
extensions fail satisfy interaction properties, sensing actions
extended languages provide appropriate model iterated belief change.
hand, suggest SitCalc consider action history appropriately.
270

fiIterated Belief Change Due Actions Observations

general, argue simply extending action formalism belief revision operator
sufficient. show approaches either lack formal machinery required
reasoning iterated belief change, make substantive implicit assumptions.
work illustrates role action formalism plays reasoning belief change.
also becomes clear additional assumptions must made order reason
iterated belief change due actions observations. making role action
formalism salient, better evaluate suitability existing formalisms particular
applications.

2. Preliminaries
section, introduce preliminary notation definitions related reasoning
action reasoning belief change. also introduce motivating example
used throughout paper.
2.1 Motivating Example
introduce Moores litmus paper problem (Moore, 1985) motivating example.
problem, beaker containing either acid base, agent
holding piece white litmus paper dipped beaker determine
contents. litmus paper turn red placed acid turn blue
placed base. problem provide formal model belief change
occurs agent uses litmus paper test contents beaker.
Intuitively, litmus paper problem seems require agent revise initial
beliefs response observation later point time. example, suppose
agent dips paper sees paper turns red. observation
causes agent believe beaker contains acid now, also causes agent
believe beaker contained acid dipping. refer process
prior revision, since agent revises beliefs prior point time. kind
phenomenon explicitly discussed many formalisms reasoning belief
change caused action. return problem periodically introduce
formal approach belief change.
2.2 Basic Notation Terminology
assume propositional signature composed finite set atomic propositional symbols.
use primitive propositional connectives {, }, denotes classical negation
denotes implication. Conjunction, disjunction equivalence defined
usual manner, denoted , , respectively. formula propositional
combination atomic symbols. literal either atomic propositional symbol,
atomic propositional symbol preceded negation symbol. Let Lits denote set
literals fixed signature.
interpretation propositional signature P function assigns every atomic
symbol truth value. set interpretations P denoted 2P . satisfaction
relation |= defined formula usual recursive definition. formula
271

fiHunter & Delgrande

, define || set interpretations |= , say
satisfiable || 6= .
belief state subset 2P . think belief state expressing proposition.
Informally, agent belief state believes actual world represented one
interpretations . observation also set interpretations. intuition
observation provides evidence actual world set . order
maintain superficial distinction, use Greek letter range observations
Greek letter range belief states, possible subscripts case.
2.3 Transition Systems
action signature pair hA, Fi A, F non-empty sets symbols. call
set action symbols, call F set fluent symbols. Formally, fluent
symbols F propositional variables. action symbols denote actions
agent may perform. effects actions specified transition system.
Definition 1 transition system action signature = hA, Fi pair hS, Ri

1. set propositional interpretations F,
2. R S.
set called set states R transition relation. (s, A, s0 ) R,
think state s0 possible resulting state could occur action executed
state s. exactly one possible resulting state s0 executed
S, say deterministic. refer fluent symbols true false
assigned values f , respectively. Transition systems visualized
directed graphs, node labeled state edge labeled
element A. terms notation, uppercase letter A, possibly subscripted,
range actions. use notation denote finite sequence action symbols
indeterminate length. Also, given sequence actions = hA1 , . . . , i, write
;A s0 indicate path s0 follows edges labeled
actions A1 , . . . , .
useful introduce symbol denote null action never changes
state world. used periodically formal results. Also, technical
reasons, assume throughout paper every action executable every state.
transition system specify effects particular action particular state,
assume state change action executed. tantamount
adding self loops every action every state transition given.
Example litmus paper problem represented action signature
h{dip}, {Red , Blue, Acid }i.
Intuitively, fluent symbols Red Blue represent colour litmus paper,
fluent symbol Acid indicates whether beaker contains acid not.
action available dip litmus paper beaker
272

fiIterated Belief Change Due Actions Observations

{Acid }



dip

dip

?

?

{Blue}

{Red , Acid }

Figure 1: Litmus Test
interest readability, adopt notational convention discussion
litmus paper problem. particular, let set V propositional fluent symbols
stand interpretation symbols V assigned value true
symbols assigned value false. Hence, set {Red} used denote
interpretation I(Red) = true, I(Blue) = f alse I(Acid) = f alse.
standard representation literature reasoning action effects. stress,
however, defining states manner; simply using convention
litmus paper example facilitates specification interpretation
small set fluent symbols. clear, throughout paper, states actually defined
terms interpretations sets propositional variables.
effects dipping litmus paper problem given transition system
Figure 1. Note included possible states figure; included
states change action executed. assume state remains
unchanged dipping action performed states omitted figure.

2.4 Belief Update
Belief update belief change occurs new information acquired regarding
change state world. One standard approach belief update Katsuno
Mendelzon approach (1991), describes belief update terms set rationality
postulates. postulates typically referred KM postulates,
analyzed, reformulated, criticized several subsequent papers (Boutilier, 1995;
Peppas, Nayak, Pagnucco, Foo, Kwok, & Prokopenko, 1996; Lang, 2006). Much
discussion focused distinction belief update belief revision,
introduce next section.
paper, adopt approach belief update beliefs updated
action rather formula. Intuitively, executing action A, agent updates
belief state projecting every state state s0 would result action
executed state s.
273

fiHunter & Delgrande

Definition 2 Let = hS, Ri transition system. update function : 2S 2S
defined follows
= {s0 | (s, A, s0 ) R }.
operation actually form action progression; argued elsewhere
standard account belief update understood special case kind
progression (Lang, 2006). advantage approach provides simple
representation belief change occurs following action conditional effects.
Example litmus paper problem, agent believes litmus paper white,
known whether beaker contains acid base. Hence, initial belief state
consists two interpretations specified follows:
= {, {Acid }}.
executing dip action, new belief state dip consists possible outcomes
dip action. Hence, new belief state contains two interpretations. first,
Red true rest fluents false. second interpretation, Blue
Acid true, rest fluents false. Thus, following dip action, agent
believes either liquid base litmus paper red liquid acid
litmus paper blue. determine outcome occurred, agent must
observe actual color paper.

2.5 Belief Revision
term belief revision refers process agent incorporates new information
prior beliefs. section, briefly sketch influential approach
belief revision: AGM approach Alchourron, Gardenfors Makinson (1985).
AGM approach belief revision provide specific recipe revision. Instead,
set rationality postulates given belief change operator satisfies
postulates called AGM belief revision operator.
Let F propositional signature. belief set deductively closed set formulas
F. Let + denote so-called belief expansion operator, defined setting
K + deductive closure K {}. Let function maps belief set
formula new belief set. say AGM belief revision operator
satisfies following postulates every K .
[AGM1]
[AGM2]
[AGM3]
[AGM4]
[AGM5]
[AGM6]
[AGM7]
[AGM8]

K deductively closed
K
K K +
6 K, K + K
K = L iff |=
|= , K = K
K ( ) (K ) +
6 K , (K ) + K ( )

274

fiIterated Belief Change Due Actions Observations

main intuition behind AGM postulates new information given
must incorporated, along much K consistently possible. AGM
postulates provide simple set conditions intuitively plausible restrictions
belief revision operators. Moreover, postulates completely determine specific semantics
revision terms pre-orderings interpretations (Katsuno & Mendelzon, 1992).
defer discussion semantics 5, describe context new
belief change operator.
Note presented AGM postulates traditional setting, beliefs
observations given sets propositional formulae. contrast, represent beliefs
observations sets interpretations. However, since work finite language,
easy translate two approaches provide translations
required.
Example litmus paper problem, suppose paper turns red dipping.
need represent observation suitable manner revision. stated 2.2
observation set interpretations. Informally, observation set
interepretations considered plausible observation.
litmus paper example, observation paper red represented set
interpretations Red true.
need revise current beliefs observation represents information.
Recall current belief state
dip = {{Blue}, {Red , Acid }}.
Since also represent observations sets interpretations, observation
paper red given set defined follows
= {{Red , Acid }, {Red }, {Red , Blue, Acid }, {Red , Blue}}.
Note observation consistent current belief state, intersection
non-empty. Therefore, [AGM3] [AGM4], follows AGM revision operator
define revised belief state intersection. Hence, AGM revision
operator , final belief state
{{Red , Acid }}.
So, dipping litmus paper observing paper red, correctly believe
beaker contains acid.

3. Belief Update Preceding Belief Revision
stated previously, interested belief change due alternating sequence
actions observations. easiest example consists single action followed
single observation. However, throughout paper, assume actions infallible,
actions infallible effects actions completely specified.
275

fiHunter & Delgrande

{Litmus}
dip
?

{Litmus, Blue}

{Litmus, Acid }

{Acid }



dip

dip

?

?

{Litmus, Red , Acid }



dip
?

{Acid }

Figure 2: Extended Litmus Test
assumption, sequence actions difficult handle single action.
such, simplest interesting case consider given expression form
A1 .

(2)

case, since single observation, focus entirely interaction
revision update. general case involving several observations complicated
fact implicitly requires form iterated revision. formalism handles
general case, initial focus problems form (2). next
section, consider example problem illustrate natural
solution requires initial state revised later point time.
use phrase iterated belief change refer scenario beliefs
agent change result multiple sequential events. somewhat non-standard
use term, literature iterated belief change concerned
(difficult) problem iterated belief revision. constrast, consider problems
form 2 instances iterated belief change sequence events leading
change beliefs.
3.1 Extended Litmus Paper Problem
extend litmus paper problem. extended problem like original, except
allow possibility paper litmus paper; might simply
piece plain white paper. order provide formal representation problem,
need extend transition system used represent original problem introducing
new fluent symbol Litmus. Informally, Litmus true case paper actually
litmus paper.
action signature hA, Fi consists = {dip} F = {Red , Blue, Acid , Litmus}.
assume transition system action effects given Figure 2, assume given
AGM revision operator .
describe sequence events informally. Initially, agent believes paper
piece litmus paper, agent unsure contents beaker. test
contents, agent dips paper beaker. dipping, agent looks
paper observes still white. interested determining plausible final
belief state.
276

fiIterated Belief Change Due Actions Observations

give formal representation problem. initial belief state
= {{Litmus}, {Litmus, Acid }}.
dipping paper beaker, update belief state follows:
dip = {{Litmus, Blue}, {Litmus, Red , Acid }}.
point, agent looks paper sees neither blue red.
observation represented following set worlds:
= {, {Litmus}, {Acid }, {Litmus, Acid }}.
naive suggestion simply revise dip . However, guaranteed
give correct result. possible, example, define AGM operator gives
following final belief state:
0 = {{Litmus}, {Litmus, Acid }}.
case, agent believes piece paper white litmus paper. clearly
plausible final belief state.
Informally, paper litmus paper, must either red blue dipping
action performed. Hence, neither {Litmus} {Litmus, Acid } plausible state
dipping; simply revising observation may give belief state incorrect
revision operator encode constraint. final belief state consist
entirely states possible consequences dipping. Even particular AGM
operator give plausible final belief state example, process
final beliefs obtained sound. kind example, observation
dipping actually giving information initial belief state. such, intuition
rational agent revise initial belief state case.
suggest rational agent reason follows. dipping paper
seeing change colour, agent conclude paper never
litmus paper begin with. initial belief state modified reflect new
belief calculating effects dipping action. approach ensures
final belief state possible outcome dipping. end experiment,
agent believe paper litmus paper agent
definite beliefs regarding contents beaker. Hence, propose
plausible final belief state set
{, {Acid }}.
simple example serves illustrate fact sometimes useful agent
revise prior belief states face new knowledge. order formalize intuition
greater generality, need introduce new formal machinery.
277

fiHunter & Delgrande

3.2 Interaction Revision Update
section, give set formal properties expect hold update
followed revision. properties overly restrictive provide
basis categorical semantics; simply provide point discussion comparison.
underlying assumption action histories infallible. recent observation always incorporated, provided consistent history actions
executed. Hence, properties discuss expected hold action
domains failed actions exogenous actions.
briefly present underlying intuitions. Let belief state, let
sequence actions, let observation. interested situation
agent initial belief state , executed, observed
actual state must . adopt shorthand notation abbreviation
sequential update element A. three distinct cases consider.
1. -states A.
2. -states A, -states 2F A.
3. -states possible executing A.
Case (1) situation observation allows agent refine knowledge
world. observation , agent believe plausible states
states also . words, agent adopt belief
state ( A) .
case (2), agent conclude actual state initially .
conclusion based underlying assumption action sequence cannot fail,
additional assumption new observation incorporated whenever
possible. assumptions satisfied modifying initial belief state
performing update. Informally, would like modify initial belief state
minimally manner ensures true executing A. case
occurs extended litmus paper problem.
Case (3) problematic, suggests agent incorrect information: either observation incorrect sequence incorrect. assuming
action histories infallible. such, observation must weakened manner order remain consistent A. cases natural weakening,
may necessary abandon observation completely. single observation,
approach take. view single observation disjunctive constraint
possible states world, assume observation meaning respect
non-member states. such, agent discovers actual state world
included observation, observation offer information all.
consider multiple observations, taken flexible approach allows
agent select minimal repair sequence observations.
Let sets states, let sequence actions, let update operator
Definition 2, let AGM revision operator. formalize intuitions
following conditions hold update followed revision.

278

fiIterated Belief Change Due Actions Observations

Interaction Properties
P1. (2F A) 6= ,
P2. (2F A) = , =
P3. ( A)
P4. ( A) 6= , ( A)
P5. 2F
give motivation property. P1 straightforward AGM-type assertion
must hold revising , provided possible executing A. P2 handles
situation impossible -world executing A. case,
simply discard observation . Together, P1 P2 formalize underlying assumption
failed actions.
P3 P4 assert revising equivalent taking intersection ,
provided intersection non-empty. similar AGM postulates asserting
revisions correspond expansions, provided observation consistent
knowledge base.
P5 provides justification revising prior belief states face new knowledge.
asserts that, revising , must still belief state possible
consequence executing A. cases, way ensure holds
executing modify initial belief state. remark P5 indicate
initial belief state modified.
worth noting interaction properties make mention minimal change
respect belief state . notion minimal change implicit
revision operator , notion change respect measure plausibility
completely independent stated properties.
3.3 Representing Histories
Transition systems suitable representing Markovian action effects; is, action
effects depend action executed current state world. However,
extended litmus paper problem, saw outcome observation may
depend prior belief states. Even action effects Markovian, follow
changes belief Markovian. such, need introduce formal machinery
representing histories. interested historical evolution agents beliefs,
along actions executed. order so, need introduce trajectories
belief states, observations, actions. given action signature hA, F i, use
following terminology.
1. belief trajectory n-tuple h0 , . . . , n1 belief states.
2. observation trajectory n-tuple = h1 , . . . , n 2S .
3. action trajectory n-tuple = hA1 , . . . , Ai A.
Note that, matter convention, start indices 0 belief trajectories
start indices 1 observation action trajectories. rationale
convention clear later. also adopt convention hinted definitions,
279

fiHunter & Delgrande

whereby ith component observation trajectory denoted ,
ith component action trajectory denoted Ai .
remark belief trajectory agents subjective view world
changed. Hence, belief trajectory represents agents current beliefs world
history, historical account agent believed point time.
example, extended litmus paper problem, end experiment agent
believes never holding piece litmus paper. fact agent
believed holding litmus paper different issue, one represented
formal conception belief trajectory.
define notion consistency observation trajectories action trajectories. intuition observation trajectory consistent action trajectory
observation possible, given actions (Aj )ji
executed.
Definition 3 Let = h1 , . . . , n observation trajectory let = hA1 , . . . ,
action trajectory. say consistent belief
trajectory h0 , . . . , n that, 1 n,
1.
2. = i1 Ai .
consistent , write A||.
pair consisting action trajectory observation trajectory gives complete
picture agents view history world. such, useful introduce
following terminology.
Definition 4 world view length n pair W = hA, i, action trajectory
observation trajectory, length n. say W consistent A||.

4. Belief Evolution
interested providing formal treatment alternating action/observation sequences form
A1 1 n .
(3)
Note implicit tendency associate operators expression
form left right, gives following expression:
(. . . (( A1 ) 1 ) ) n .

(4)

extended litmus paper problem illustrates association lead unsatisfactory results. such, would like propose alternative method evaluating
expressions form (3). However, discussing expressions form directly
somewhat misleading, since preclude interpretation (4). order make
explicit computing successive updates revisions, introduce new
belief evolution operator . Intuitively, simply allows us associate information
incorporated manner closer following informal expression:
(A1 , 1 , . . . , , n ).
280

(5)

fiIterated Belief Change Due Actions Observations

Note update revision operators disappeared; left expression
groups actions observations single sequence, suggesting information
incorporated simultaneously. However, order observations actions
still significant. Moreover, important keep mind defined respect
given update revision operators. new operator introduced primarily give us
formal tool make explicit interpreting expressions form (3)
default interpretation (4).
formal definition presented following sections, use
exact syntax informal expression (5). actual definition, belief evolution
operator takes belief state world view arguments. Also, value returned
single belief state; belief trajectory. However, (5) provides important underlying
intuition.
4.1 Infallible Observations
section, define assumption observations always correct.
Formally, amounts restriction world views considered. particular,
need consider inconsistent world views. easy see inconsistent world
view possible assumption action histories observations
infallible.
Let s1 (A) denote set states s0 (s0 , A, s) R. call s1 (A)
pre-image respect A. following definition generalizes idea give
pre-image set states respect sequence actions.
Definition 5 Let deterministic transition system, let = hA1 , . . . , let
observation. Define 1 (A) = {s | ;A s0 s0 }.
Hence, actual world element following action sequence A,
initial state world must 1 (A).
illustrative purposes, useful consider world views length 1. Suppose
initial belief state , action observation . Without formally defining
belief evolution operator , give intuitive interpretation expression
form
hhAi, hii = h0 , 1 i.
agent knows actual world final point time, must
1 . Moreover, agent believe 1 possible result executing
0 . words, must 0 1 (A). things equal, agent
would like keep much possible. order incorporate 1 (A) keeping
much possible, agent revise 1 (A). suggests following
solution.
1. 0 = 1 (A),
2. 1 = 0 A.
reasoning applied world views length greater 1. idea
trace every observation back precondition initial belief state. revising
281

fiHunter & Delgrande

initial belief state preconditions, subsequent belief state determined
standard update operation.
following formal definition . definition, n let Ai
denote subsequence actions hA1 , . . . , Ai i.
Definition 6 Let belief state, let update operator, let AGM revision
operator, let action trajectory length n let observation trajectory
length n A||. Define
hA, = h0 , . . . , n

1. 0 =



1
(Ai )

2. 1, = 0 A1 Ai .
remark intersection observation preconditions definition 0 nonempty, A||.
following propositions immediate, demonstrate action sequences length 1, operator reduces either revision update. proposition,
assume A||.
Proposition 1 Let belief state, let = hAi let = h2F i.
hA, = h, Ai.
Proof Recall assume every action executable every state. follows
(2F )1 (A) = 2F . Therefore
hA, = h 2F , ( 2F ) Ai
= h, Ai.
2
next result, recall null action never changes state world.
Proposition 2 Let belief state, let = hi let = hi.
hA, = h , i.
Proof

Since change state, follows 1 () = . Therefore
hA, = h , ( )
= h , i.

2

282

fiIterated Belief Change Due Actions Observations

Hence, original revision update operators retrieved operator.
such, reasonable compute iterated belief change due action terms belief
evolution.
demonstrate belief evolution provides reasonable approach computing
outcome sequence actions observations. stress computing updates
revisions succession provide reasonable solution many cases. such,
want define outcome sequence updates revisions terms belief
evolution operator. Given , define iterated belief change

final belief state belief trajectory
hhAi, hii.
adopt somewhat confusing convention temporarily order prove belief
evolution provides semantics iterated belief change satisfies interaction properties.
generally, consider sequence n actions followed single observation .
case, define n observation trajectory consisting n 1 instances 2F
followed final observation . define iterated belief change

final belief state belief trajectory
hA, n i.
Proposition 3 Let action trajectory let observation. A||n ,
iterated belief change defined satisfies interaction properties P1-P5.
Proof

Let belief state. convention outlined above,
= ( 1 (A)) A.

demonstrate definition satisfies P1-P5.
P1. (2F A) 6= , ( A) .
Note antecedent true n consistent. following
inclusions:
( 1 (A)) 1 (A) .
first inclusion holds [AGM2] plus fact update satisfies (X ) X A.
second inclusion holds definition pre-image. Hence, consequent true.
P2. (2F A) = , ( A) =
antecedent false, since n consistent.

283

fiHunter & Delgrande

P3. ( A) ( A)
Suppose ( A) . s0 maps s0 s. Hence,
s0 1 (A). follows [AGM2] s0 1 (A). Since maps s0 s,
( 1 (A)) A.
P4. ( A) 6= , ( A) ( A)
Suppose ( A) 6= . state mapped sequence A.
Hence 1 (A) 6= . [AGM3] [AGM4], follows 1 (A) = 1 (A).
suppose ( 1 (A)) A. exists s0 1 (A) maps
s0 s. s0 1 (A). implies .
P5. ( A) 2F
immediate, ( 1 (A)) 2F (X ) = (X ) (Y ).
2
three preceding propositions demonstrate suitability natural operator
reasoning interaction revision update.
use belief evolution operator give appropriate treatment litmus
paper problem.
Example Consider extended litmus paper problem, let
= {, {Litmus}, {Acid }, {Litmus, Acid }}.
Hence, world view W = hhdipi, hii represents dipping action followed observation paper still white. obtained metric transition system defined
Hamming distance transitions Figure 2, final belief state W
given
1 (dip) dip = {, {Acid }} dip
= {, {Acid }}.
calculation consistent original intuitions, agent revises initial
belief state updating dip action. ensures final belief
state possible outcome dipping. Moreover, initial belief state revised
pre-image final observation, means modified little possible
still guaranteeing final observation feasible. Note also final belief
state given calculation intuitively reasonable. simply indicates contents
beaker still unknown, agent believes paper litmus paper.
Hence, belief evolution operator employs plausible procedure returns desirable
result.

4.2 Fallible Observations
section, consider belief evolution case observations may incorrect.
Formally, means interested determining outcome belief evolution
284

fiIterated Belief Change Due Actions Observations

inconsistent world views. case, cannot simply take intersection
observation pre-images, intersection may empty. basic idea behind
approach define belief evolution respect external notion reliability
observation.
start defining belief evolution general case, respect total
pre-order elements observation trajectory . order define pre-order,
assume given function r maps element integer. actual
value r(i ) particularly important; function r used impose ordering
observations. interpret
r(i ) < r(j )
mean reliable j . case, consistency restored
discarding either j , j discarded. ranking function observations
may obtained several ways. example, may induced ordering
possible observations, indicating reliability sensing information.
hand, pre-order might simply encode general convention dealing sequential
observations. example, cases may reasonable prefer recent
observation earlier observation.
basic approach following. Given observation trajectory
consistent A, discard observations manner gives us consistent world
view. precise, discarding observation context means replace
2F . discard observations rather weaken them, view content
observation atomic proposition. guided two basic principles. First,
things equal, would like keep much consistently possible.
Second, observations must discarded, try keep
reliable. informal sketch mind, define w(), set trajectories
obtained discarding observations .
Definition 7 Let observation trajectory length n, let set
observation trajectories length n. define:
w() = {0 | 0 1 n, i0 = i0 = 2F }.
interested finding trajectories w() consistent A,
differing minimally . following definition, observation trajectories equal
length n, write 0 shorthand notation indicate i0 every
1 n.
Definition 8 world view hA, i:
hA, = {0 w() | A||0 00 w() 00 0 , A||00 }.
0 hA, 0 consistent A, becomes inconsistent
discarded observations re-introduced. Therefore elements 0 hA,
differ minimally , minimal defined terms set-containment.1
use reliability ordering observations define reliability ordering
observation trajectories.
1. Note reasonable notion minimality could employed here. One natural
alternative would consider minimal change terms cardinality. case, trajectory differs

285

fiHunter & Delgrande

Definition 9 0 , 00 hA, , write 00 < 0 j
1. k < j < n, r(i ) = k i0 = i00 .
2. exists r(i ) = j i00 i0 .
3. exist r(i ) = j i0 i00 .
Informally, 00 < 0 00 retains reliable observations 0 . minimal trajectories ordering are, therefore, retain plausible observations.
Definition 10 set repairs world view hA, respect reliability function
r given by:
Rep(A, ) = {0 hA, | 00 hA, 00 < 0 }.
Note Rep(A, ) may contain several observation trajectories. Moreover, trajectory
Rep(A, ) consistent A, minimally discarding observations keeping
reliable observations possible.
Definition 6, defined consistent world views. inconsistent world views,
use following definition.
Definition 11 Let belief state, let action history, let observation
trajectory, let r reliability function. consistent , then:
hA, = { hA, 0 | 0 Rep(A, )}.
definition well-formed, 0 Rep(A, ) implies A||0 . Note outcome
belief evolution case set belief trajectories.
adopt following convention. hA, = {0 }, write hA, = 0 .
|Rep(A, )| = 1, belief evolution yields unique belief trajectory. natural
examples case.
Proposition 4 Let hA, world view length n. Let r reliability function
6= j implies r(i ) 6= r(j ) 1 i, j n. |Rep(A, )| = 1.
Proof Note hA, 6= , always possible find trajectory consistent
discarding observations . follows immediately Rep(A, )
non-empty. Hence |Rep(A, )| 1.
suppose exist 0 00 0 Rep(A, ), 00 Rep(A, )
0
6= 00 . Thus
{i | i0 6= i00 } =
6 .
Let j {i | i0 6= i00 } r(j ) minimal. assumption, j unique.
j0 = j , 0 < 00 contradicts 00 Rep(A, ). j0 = 2F , 00 < 0
minimally case minimal number observations discarded. reasonable
arguments containment approach cardinality approach, depending context.
Neither approach clear theoretical advantage, development virtually identical.
determined paper better served presenting containment approach detail, rather
presenting series duplicate results different conceptions minimality.

286

fiIterated Belief Change Due Actions Observations

contradicts 0 Rep(A, ). Therefore, 0 = 00 . follows |Rep(A, )| 1,
two elements Rep(A, ) distinct. 2
Thus r assigns unique value observation, belief evolution yields unique
outcome. return fact next section.
cases belief evolution yield unique result, skeptical approach
defined taking union initial belief states. Recall 0 first element
trajectory . define
[
0 = {00 | 0 Rep(A, )}.
unique belief trajectory defined computing effects actions.
trajectory general enough include outcome every minimal repair. kind
skeptical approach appropriate situations.
4.3 Recency
One well-known approach dealing sequences observations give precedence
recent information (Nayak, 1994; Papini, 2001). Given observation trajectory ,
preference recent information represented framework defining r
r(i ) = i. purposes, recency provides concrete reliability ordering
observations, facilitates presentation examples comparison related
formalisms. such, throughout remainder paper, use denote belief
evolution operator defined respect function r.
stress preference recent information convention adopt
simplifies exposition, note convention subject
criticism (Delgrande, Dubois, & Lang, 2006). Note that, Proposition 4, belief evolution
recency convention defines unique belief trajectory outcome. such,
belief evolution recency convention also defines specific approach iterated
revision. sequence several observations interspersed null actions longer
computed simply applying single shot revision operator several times. explore
approach iterated revision implicit belief evolution operators 6.2.
conclude section useful result. Thus far, applying operator requires
tracing action preconditions back initial state revision, applying action effects
get complete history. concerned final belief state,
many cases need go much effort. following proposition,
helpful think 2F null observation provides new information.
Proposition 5 Let belief state, let action trajectory length n let
belief state A. observation trajectory n 1 observations
2F followed single observation , final belief state hA, ( A) .
Proof

definition, final belief state hA,
( 1 (A)) A.

Since A, intersection 1 (A) non-empty. [AGM3] [AGM4],
follows
1 (A) = 1 (A)
287

fiHunter & Delgrande

therefore
( 1 (A)) = ( 1 (A)) A.
Clearly, right hand side equality equal ( A) . Again, since A,
follows [AGM3] [AGM4] ( A) . 2
proposition indicates that, given single observation consistent
actions executed, simply revise outcome actions
get correct final belief state.

5. Defining Belief Evolution Orderings Interpretations
next two sections, provide characterization belief evolution operators terms
total pre-orders interpretations. restrict attention case involving one action
followed one observation. result extends easily case involving n actions
followed one observation, action sequences length n simply define new set
transitions states. Since prove characterization arbitrary action signature,
allowing n actions prior single observation difficult allowing one
action. present case single action, simplifies exposition allowing
us avoid introducing sequences null observations interspersed actions.
remark result extend directly case involving several observations,
introduce axiomatic account reliability observation.
First, need delineate general class belief change functions.
Definition 12 combined belief change operator function
: 2S hA, 2S 2S .
Hence, combined belief change operator takes belief state ordered pair hA,
input, returns new belief state.
fixed update operator fixed revision operator , consider following
postulates.

I1 (2F A) 6= , hA,
= 1 (A) A.

I2 (2F A) = , hA,
= A.
abuse notation letting hA, denote final belief state corresponding
belief trajectory, get following result. proposition, refer
belief evolution operator defined update operator revision operator. clear,
refers belief evolution operator obtained Definitions 6 11.
Proposition 6 Let belief update operator let belief revision operator.
belief evolution operator defined , satisfies I1 I2.
Proof Let belief evolution operator corresponding . (2F A) 6= ,

hA,
= 1 (A) definition. Hence satisfies I1. Suppose,

hand, (2F A) = . case 1 (A) = . Therefore, hA,
= 2F = A.
satisfies I2.
288

fiIterated Belief Change Due Actions Observations

prove converse, suppose satisfies I1 I2. Let belief evolution
operator defined . Suppose (2F A) 6= . follows
hA, = 1

= hA,


(since consistent)
(by I1)

suppose (2F A) = .
hA, = 2F

= hA,


(since consistent)
(by I2)

completes proof. 2
Hence, postulates I1 I2 provide complete syntactic description belief evolution.
characterization make easier state representation result next section.
5.1 Translations Orderings
fixed transition system , would like provide characterization combined
belief change functions represent belief evolution operators . characterization defined terms total pre-orderings interpretations. First need
introduce basic characterization AGM revision operators terms total pre-orders,
due Katsuno Mendelzon (1992). presentation differs slightly original
define revision operators sets states rather formulas.
Definition 13 (Katsuno & Mendelzon, 1992) Given belief state , total pre-order
interpretations called faithful ranking respect case following
conditions hold:
s1 , s2 , s1 = s2 .
s1 s2 6 , s1 < s2 .
Hence, faithful ranking simply total pre-order minimal elements
members . order simplify discussion, introduce following notation.
set states ordering superset :
min(, ) = {s | -minimal among interpretations )}.
following definition characterizes AGM revision operators terms pre-orders
interpretations.
Proposition 7 (Katsuno & Mendelzon, 1992) Given belief state , revision operator
satisfies AGM postulates exists faithful ranking respect
set interpretations :
= min(, ).
remainder section, extend result characterize belief evolution operators.
Assume given fixed transition system = hS, Ri defining update operator
. following definition gives natural progression operation pre-orderings.
289

fiHunter & Delgrande

Definition 14 faithful ranking respect action, define
s1 s2
exist t1 , t2 (t1 , A, s1 ) R (t2 , A, s2 ) R).
t1 t2 .
Note generally total pre-order may case
states possible outcomes action A. Hence partial pre-order.
think shifted ordering, minimal elements A.
following definition associates combined revision operator faithful ranking.
Definition 15 Let faithful ranking respect . combined belief change
operator associated following:

min(, ) (2F A) 6=

hA,
=

otherwise.
Note operator takes observation action inputs, returns new
belief state. prove class functions definable manner coincides
exactly class belief evolution operators.
first prove every faithful ranking defines belief evolution operator.
Proposition 8 Let faithful ranking respect let combined
belief change operator defined . satisfies I1 I2.
Proof Let action, let observation, let AGM revision operator
defined Proposition 7. prove satisfies I1 I2 respect .
Suppose (2F A) 6= ,

hA,
= min(, ).
remark that, definition,
= 1 (A) A.
So:

hA,
= min(1 (A) A, )
= min(1 (A), )
definition :
1 (A) = min(1 (A), )
follows

hA,
= ( 1 (A))
proves I1 holds.
(2F A) = , definition:

hA,
= A.
Hence I2 satisfied. 2
prove converse.
290

fiIterated Belief Change Due Actions Observations

Proposition 9 Let operator satisfying I1 I2 AGM revision function
. Given belief state , faithful ranking combined belief
change operator defined .
Proof

Proposition 7, faithful ranking respect
= min(, )

. Fix particular let action symbol. Suppose (2F A) 6= .
So, I1:

hA,
= 1 (A) A.
definition , equal
min(1 (A), )
equivalent to:
min(1 (A) A, )
Simplifying first argument, get:
min(, )
wanted show.
suppose (2F A) = then,

hA,
=

(by I2)

completes proof. 2
Hence, class belief evolution operators characterized simply shifting
total pre-order defines revision operator. characterization essentially
corollary Katsuno Mendelzons representation result AGM revision. However,
approach represent significant departure iterative approach applying
update revision operators. result demonstrates progression
beliefs actions applied level pre-order used
revision. manner, relative likelihood states shifted appropriately
action executed. ensures later revisions use ordering would
used initially, captures intuition execution actions change
priori likelihood initial states world.

6. Comparison Related Work
Many action formalisms define action effects Markovian. case, example,
action languages like (Gelfond & Lifschitz, 1998). action formalisms kind
supplemented sensing actions, natural tendency compute epistemic
change computing effects ontic actions sensing actions succession.
implicit approach iterated belief change caused actions epistemic extensions
(Lobo et al., 2001; Son & Baral, 2001). seen strategy appropriate
291

fiHunter & Delgrande

litmus-type problems. However, mean formalisms
used reasoning iterated belief change due action. simply means
care must taken define iterated change correctly.
Belief evolution seen formalism competition Markovian formalisms; seen methodology extending Markovian formalisms address
iterated belief change. revision update operators given explicitly, definition corresponding belief evolution operator straightforward. true even
formalisms basic operators relatively sophisticated, defined
multi-agent belief structures Herzig, Lang Marquis (2004).
6.1 Situation Calculus
section, compare work extended version SitCalc explicitly
represents beliefs agents. assume reader familiar SitCalc (Levesque,
Pirri, & Reiter, 1998), provide brief introduction notation use.
terms SitCalc action theory range domain includes situations
actions. fluent predicate takes situation final argument. SitCalc
action theory includes action precondition axiom action symbol, successor
state axiom fluent symbol, well foundational axioms SitCalc.
Informally, situation represents state world, along complete history
actions executed. distinguished constant S0 represents
initial situation, distinguished function symbol represents execution
action. Every situation term written follows:
do(An , do(An1 , . . . , do(A1 , S0 ) . . . ).
simplify notation, abbreviate situation do([A1 , . . . , ], S0 ).
clarify results follow, adopt following convention. Expressions
do(A, s) used syntactic variables ranging situation terms.
also need refer explicitly semantic objects denoted terms given first-order
interpretation situation calculus theory. Hence, let sM denote situation
denoted situation term first-order interpretation M. adopt
convention denote extensions predicate symbols interpretation.
SitCalc extended include representation belief (Shapiro et al., 2000).
extension includes distinguished fluent symbol B represents accessibility
relation situations, similar used modal logics belief. extension also
includes distinguished function symbol pl assigns numeric value situation.
function pl plausibility function, intended interpretation pl(s1 ) < pl(s2 )
s1 plausible s2 . formula Bel(, s) expresses fact
believed situation s, defined follows:
Bel(, s) s0 [B(s0 , s) (s00 B(s00 , s) pl(s0 ) pl(s00 ))] [s0 ].
formula states believed true every B-accessible
situation assigned minimal pl-value. words, believed true
plausible worlds considered possible.
292

fiIterated Belief Change Due Actions Observations

Note accessibility relation B used define formula init(s) defines
set initial situations:
init(s) B(s, S0 ).
set situations initially believed possible pl-minimal elements init. Since
init formula one free variable, defines set situations given first-order
theory. let initM denote set situations satisfy init interpretation
M. successor state axiom pl straightforward, guarantees following
condition:
pl(do(a, s)) = pl(s).
order express successor state axiom B, convenient distinguish
ontic actions change state world, sensing actions simply give
agent information world. ontic actions, successor state axiom B
guarantees following:
B(s0 , do(A, s)) s00 (B(s00 , s)) s0 = do(A, s00 ).
axiom states accessible executing accessible
world results executing state considered possible. effects binary sensing actions given special sensing predicate SF (Levesque,
1996). purposes, sufficient restrict attention sensing actions
simply determine truth value single fluent symbol. sensing actions, successor state axiom B says s0 B-related do(O, s) case s0 agrees
value sensed fluent symbol. effects sensing actions SitCalc define
approach belief revision satisfies five AGM postulates (Shapiro et al., 2000).
order compare belief change SitCalc belief evolution, need express
situations terms states. order simplify discussion, restrict attention
SitCalc action theories every fluent symbol unary, exception
distinguished accessibility fluent B. say SitCalc theory elementary
satisfies following conditions:
1. set fluent symbols F {B}, F F unary.
2. complete.
3. Every interpretation |= following properties:
(a) |= init(S0 ).
(b) |{x | initM (x)}| = 2|F| .
(c) |= init(s1 ) init(s2 ) s1 6= s2 , fluent symbol F F
|= F (si ) exactly one s1 s2 .
Elementary SitCalc theories essentially categorical set initial situations.
Given model elementary SitCalc theory, situation sM defines propositional
293

fiHunter & Delgrande

interpretation IsM set F unary fluent symbols. Specifically, situation
sM , define IsM follows:
IsM |= F F (sM ).
also use idea associate belief state every situation sM . ease
readability, following definition omit superscript situation terms
fluent symbols right hand side:
[
(s,M) = {Is0 | B(s0 , s) (s00 B(s00 , s) pl(s0 ) pl(s00 ))}.
Hence (s,M) set states minimal plausibility among situations
B -accessible sM .
model elementary SitCalc theory , define belief update, belief revision
belief evolution. ontic action symbol A, define follows.
(s,M) = (do(A,s),M) .
Note plausibility function plM defines total pre-order initial situations.
Since initial situations 1-1 correspondence interpretations F, follows
plM defines total pre-order interpretations F. Let denote AGM
revision operator corresponding ordering. Finally, let denote belief evolution
operator obtained . ease readability, omit subscript
theory clear.
order state main result concisely, introduce simplifying notation. Let
sensing action symbol fluent symbol FO , let suitable first-order
interpretation. define set propositional interpretations F follows:

{I | |= F0 }, FOM (sM )

Os =
{I | |= F0 }, otherwise
Inuitively OsM set interpretations agree IsM value fluent
FO . following result, let (s,M) hA, stand final belief state given
belief evolution operation.
Proposition 10 Let elementary SitCalc theory, let |= let
evolution operator induced M. sensing action ontic action, then:
(do([A,O],S0 ),M) = (S0 ,M) hA, OSM0 )i.
Proof Without loss generality, assume |= FO (do(A, S0 )). words,
assume FO holds situation resulting executing action A.
assumption, must prove
(do([A,O],S0 ),M) = (S0 ,M) |FO |1 (A) A.
FO happens false executing A, changes required proof obvious.
Note |= B(s, do([A, O], S0 )) case:
294

fiIterated Belief Change Due Actions Observations


1. = do(A, s1 ) s1 B (sM
1 , S0 ),

2. FOM (s).
Suppose (do([A,O],S0 ),M) . follows = IsM situation term
satisfies conditions (1) (2), also property sM plM -minimal among
situations B accessible do([A, O], S0 )M . Consider situation term s1
condition (1). Clearly IsM
|FO |1 (A), |= FO (do(A, s0 )). suppose
1
exists s2 following properties:
1. IsM
|FO |1 (A)
2
2. |= B(do([A, O], s2 ), do([A, O]), S0 ))

3. plM (sM
2 ) < pl (s1 ).

successor state axiom pl, follows
plM (do(A, s2 )M ) < plM (do(A, s1 )M ) = plM (sM ).
contradicts plM -minimality sM among situations B accessible

do([A, O], S0 )M . Therefore, s2 . sM
1 pl -minimal among situations
satisfy first two properties defining s2 .
Recall elementary, every propositional interpretation |FO |1 (A)
equal ItM initial situation t. Note that, |FO |1 (A), = ItM
satisfies points (1) (2) specification s2 above. |FO |1 (A) less
IsM
total pre-order interpretations defined plM , situation also
1
satisfies third condition. seen possible. So,
pl total

pre-order interpretations defined pl , have:
IsM
1

min(|FO |1 (A),
pl )
= (S0 ,M) |FO |1 (A)

(by definition)

then, since sM = do(A, s1 )M :
IsM (S0 ,M) |FO |1 (A) A.
(do([A,O],S0 ),M) (S0 ,M) |FO |1 (A) A.
direction, suppose (S0 ,M) |FO |1 (A) A.
0 (S0 ,M) |FO |1 (A) 0 = I. 0 = IsM plM -minimal
situation sM initM |= FO (do(A, s)). Since sM initM , follows
|= B(do(A, s), do(A, S0 )).
Moreover, since |= FO (do(A, s)), follows
|= B(do([A, O], s), do([A, O], S0 )).
suppose situation term s1 |= B(s1 , do([A, O], S0 ))


initM
plM (sM
1 ) < pl (do(A, s)) . follows immediately s2
295

fiHunter & Delgrande

do([A, O], s2 )M = sM
1 . Moreover, successor state axiom pl,
(sM ). However, since sM initM , contradicts plM minimality
plM (sM
)
<
pl
2
2
sM among initial situations. sM
1 . Therefore Ido(A,s) do([A,O],S0 ) .

Recall Ido(A,s)
= IsM = I. Therefore, (do([A,O],S0 ),M) . 2
Skimming details, preceding proof simply relies condition |=
pl(do(a, s)) = pl(s) every epistemic SitCalc model. fact plausibility values
persist following execution actions equivalent restricting belief change always
revising initial belief state, determining final belief state simply computing
ontic action effects. Hence, semantics revision actions SitCalc framed
instance belief evolution. suggest important point discussing
belief change SitCalc. original description approach, belief change
due sensing action identified belief revision (Shapiro et al., 2000).
view, fact sensing actions satisfy AGM postulates seen
problem approach. However, explicit fact belief
change SitCalc form belief evolution, longer problem.
expect AGM postulates satisfied, need concerned interaction
ontic actions sensing actions.
conclude section remarking belief evolution operators one
expressive advantage epistemic extension SitCalc. epistemic extension
considered, information obtained sensing actions always correct.
result, sensible consider revising F followed F . contrast,
belief evolution, simply handled keeping reliable observation. Hence,
belief evolution able deal unreliable perception straightforward manner
possible SitCalc. remark however, inconsistent observations
treated later extension SitCalc postulating exogenous actions account
inconsistent sensing information (Shapiro & Pagnucco, 2004).
6.2 Iterated Belief Revision
Recall null action change state world. consider
action domains agents perform , sequential belief revision special case
belief evolution.
Observation 1 , unique belief state 0
h, = h0 , . . . , 0 i.
Since every action null, unique belief state 0 belief state results
sequence observations. section, consider belief evolution operators
perspective well-known Darwiche-Pearl postulates iterated revision (Darwiche &
Pearl, 1997).
First, important note belief evolution define iterated revision
simple sequence AGM revision operations. According Definition 11, inconsistencies
observations resolved keeping reliable observations. default,
take recency measure reliability. illustrate, consider simple example.
296

fiIterated Belief Change Due Actions Observations

following expression, let denote complement
hh, i, h, ii.
example, observation followed observation . final belief state
obtained performing two single-shot revisions, however. According Definition
11 recency ordering, first observation discarded inconsistent
recent observation. such, final belief state operation .
Hence, approach iterated revision implicit belief evolution naive
iteration. therefore reasonable ask implicit iterated revision operator satisfies
existing rationality postulates.
state Darwiche-Pearl postulates terms possible worlds. Let , ,
sets possible worlds. Darwiche-Pearl postulates follows.
Darwiche-Pearl Postulates
[DP1] , ( ) = .
[DP2] , ( ) = .
[DP3] , ( ) .
[DP4] 6 , ( ) 6 .
would like determine postulates hold perform belief evolution
null actions.
define iterated revision operator obtained follows:
=def h, h, ii.

(6)

course true apply AGM operator left successively.
adopt convention definition iterated revision allows us ask
Darwiche-Pearl postulates hold. critical remark, however, using
notational convention defines iterated revision terms belief evolution.
Given introduce new notational convention even ask DarwichePearl postulates hold, one might question concerned postulates.
words, important check belief evolution operators satisfy key
properties iterated belief revision? stance postulates matter belief
evolution en using belief evolution operators iterated revision
accident. Although focus iterated sequences actions observations,
cases actions null clearly looking case iterated
revision. would problematic belief evolution handled cases poorly, would
like ensure instances iterated revision handled appropriately. One way
assess appropriateness checking Darwiche-Pearl postulates hold.
next result relies following crucial observation. 6= ,

( ) 6=
=

otherwise
observation follows immediately definition belief evolution. using
expression, prove following result.
297

fiHunter & Delgrande

Proposition 11 Let belief evolution operator let 6= . iterated
revision operator given (6) satisfies Darwiche-Pearl postulates.
Proof Note 1 () = 1 () = . Since 6= , need show DP
postulates satisfied , defined observation above.
[DP1], suppose . Since 6= , follows 6= hence
= ( ). = , right hand side equal .
[DP2], suppose . Hence, = desired conclusion follows
immediately.
[DP3], suppose . Since 6= , follows [AGM5] 6= .
exists . since , since .
Hence 6= , therefore
= ( ) .
[DP4], suppose 6 . exists .
follows , 6= . Translating possible worlds, postulate [AGM7] says
following:
6 , ( ) ( ).
Since ( ) , implies ( ). then, since 6= follows
definition . Hence . Therefore 6 .
2
well known many AGM revision operators satisfy Darwiche-Pearl
postulates applied succession. Proposition 11 shows that, even start
single-shot revision operator, approach iterated revision induced belief evolution
always Darwiche-Pearl operator.
easy demonstrate belief evolution also satisfies so-called recalcitrance
postulate introduced Nayak, Pagnucco Peppas (2003). Rephrased terms possible worlds belief evolution, recalcitrance following property:
(Recalcitrance) 6= , ( h, h, i) .
known DP1, DP2, (Recalcitrance) characterize Nayaks lexicographic iterated revision operator epistemic states (Booth & Meyer, 2006). follows
approach iterated revision also satisfies independence postulate introduced
independently Jin Thielscher (2007) well Booth Meyer (2006).
gives complete characterization iterated revision operator implicit belief
evolution, perspective Darwiche-Pearl tradition.
6.3 Lehmann Postulates
section, consider belief evolution perspective Lehmanns postulates
(1995). Given observation trajectories O0 , let O0 denote concatenation
two sequences. observation, write shorthand hi. Finally,
remainder section write abbreviation final belief state
h, Oi. Translated notation, Lehmann postulates follows.
298

fiIterated Belief Change Due Actions Observations

Lehmann Postulates
[L2] (O ) .
[L3] (O ) , .
[L4] , (O O0 ) = (O O0 ).
[L5] , (O O0 ) = (O O0 ).
[L6] (O ) 6 , (O O0 ) = (O O0 ).
[L7] (O ) (O ).
start postulate [L2] remain consistent original numbering. However,
omit Lehmanns first postulate states sequences observed formulas define
consistent theory. Since work directly sets states rather formulas, kind
postulate necessary.
perspective iterated belief change, interesting distinction
approach Lehmanns approach seen looking postulates [L4]-[L6]. Lehmann
views [L4]-[L6] dealing superfluous revisions (Lehmann, 1995). example,
postulate [L4], observation superfluous revising observations
already leads agent believe actual state . such, observing
provide new information. postulate [L4] suggests observations
may discarded. kind reasoning supported belief evolution,
observation may take new meaning following future observations. Postulates [L5]
[L6] problematic similar reasons.
present counterexample illustrates postulates [L4]-[L6] fail belief
evolution.
Example
follows:

Let s1 , s2 , s3 states action signature. Define , , O0
= {s1 }
= {s2 , s3 }
= {s3 }
= h{s3 }i
O0 = h{s1 , s2 }i

demonstrate [L4]-[L6] fail example.
Let belief evolution operator obtained update operator
AGM revision operator . Note
= {s1 } {s3 } = {s3 } .
However,
(O O0 ) = {s1 } {s1 , s2 } = {s1 }
(O O0 ) = {s1 } {s2 } = {s2 }.
Hence (O O0 ) 6= (O O0 ), violates [L4]. Since = O, also violates
[L5].
299

fiHunter & Delgrande

Let = {s1 , s3 }. following equalities refute [L6].
(O ) = {s3 } 6
(O O0 ) = {s1 }
(O O0 ) = {s2 }.

preceding example demonstrates [L4]-[L6] hold belief evolution;
however, perhaps abstract illustrate intuitive problem. level
commonsense reasoning, instructive imagine situation involving certain bird
either red, yellow black. Postulate [L4] says following informal sequences lead
belief state:
Believe(bird red) + Observe(black, red yellow)
Believe(bird red) + Observe(black, yellow black, red yellow)
However, see sequences perspective belief
evolution operators. sequences, first observation discarded2 . first case,
agent left keep initial belief bird red consistent
final observation. contrast, second case, final two observations
combined suggest bird yellow. Following intuitions AGM revision,
agent believes bird yellow. Similar bird colour arguments used
demonstrate whey [L5] [L6] fail belief evolution.
Although [L4]-[L6] hold, construct weaker versions hold.
claimed reason postulates fail future observations may affect
interpretation observations initially superfluous. avoid problem,
modify postulates removing observations follow superfluous observation.
Weakening gives following postulates:
Weak Lehmann Postulates
[L4 ] 6=
, = (O ).

[L5 ] , (O ) = (O ).
[L6 ] (O ) 6 , (O ) = (O ).
[L4]-[L6] replaced [L4 ]-[L6 ], belief evolution satisfies resulting set
postulates.
Proposition 12 Let belief evolution operator, let 6= let observation
trajectory component non-empty. satisfies [L2], [L3], [L4 ], [L5 ],
[L6 ], [L7].
2. first observation discarded assumption recent information takes precedence.
discussed previously, committed assumption, useful purpose
comparison iterated belief revision.

300

fiIterated Belief Change Due Actions Observations

Proof Since 6= , (O ) = . Hence (O ) ,
proves [L2].
[L3], suppose (O T) . suppose
O.
definition,

means





(O).

postulate
[AGM7],


(
(O))


( (O) ). ( (O) ) = (O ), follows . Therefore
.

Suppose
6= . definition, = (O). Since 6=
,
follows (O ) = ( (O) ). equalities mind, following
results prove [L4 ] holds:
\

(O) ( (O))
(since )

( (O) )
(by [AGM7])


(O)
(by [AGM8])
clear [L5 ] holds, simply assumption implies
= .
[L6 ], suppose (O ) 6 . follows 6= . definition,
means (O ) = (O ), desired result.
Since = , follows definition (O ) = (O ). 2

Hence, consider influence observations occur future,
belief evolution defines approach iterated revision satisfies Lehmann
postulates deal empty belief states.
conclude brief remark assumption non-empty
Propositions 11 12. framework, action histories take precedence observations. such, empty observations discarded inconsistent every
sequence actions. true even case sequence null actions.
accept treatment inconsistent observations, allows inconsistency
treated uniform manner.

7. Discussion
presented transition system framework reasoning belief change due
actions observations. suggested agents perform belief update following
action, perform belief revision following observation. showed
interaction update revision non-elementary. Consequently
specified agent consider history actions incorporating new
observation. contrast, existing formalisms reasoning epistemic action effects
either ignore interaction revision update deal implicitly.
Hence, provided explicit treatment phenomenon always
recognised related formalisms.
fundamental idea motivating work interpretation observation
may depend preceding sequence actions. treatment iterated belief change
includes two main components. First, introduce set postulates capture
intuitions appropriate treatment observation following sequence actions.
301

fiHunter & Delgrande

Informally, postulates capture intuitions AGM revision domains actions
may occur. Second, introduce belief evolution operators give concrete recipe
combining given update operator given revision operator. Belief evolution operators
satisfy postulates, along standard postulates iterated revision.
class problems appropriate belief evolution described
ordering action histories. Let A1 , 1 , . . . , , n alternating sequence actions
observations. Let denote total pre-order elements sequence. Belief
evolution suitable problems underlying ordering given follows,
permutation p1 , . . . , pn 1, . . . , n.

A1

..
. p 1 p 2 p n



Hence belief evolution appropriate total pre-order observations,
including case observations considered equally reliable. However,
addressed case action histories may incorrect.
framed results transition system framework, primarily
provides simple representation action effects. However, results translated
related action formalisms well. example, comparison SitCalc,
illustrated revision actions SitCalc implicitly defined terms belief
evolution. results provide general account interaction actions
observations, grounded context transition systems.
worth noting belief evolution operators model specific reasoning problem
addressed general formalisms. example, work,
explored use arbitrary plausibility rankings actions observations
reason iterated belief change (Hunter & Delgrande, 2006). Moreover, even
distinction revision update understood pragmatic distinction
modelling certain kinds reasoning. single generic notion belief change
defined belief revision belief update special cases (Kern-Isberner,
2008). perspective, iterated belief change due action simply one particular
instance; instance belief change operations subject certain constraints encode effects actions. believe important instance
worthy detailed study, important aware framed
understood general level.
several directions future research. One direction deals implementation belief evolution solver. previously explored use Answer Set
Planning develop solver iterated belief change (Hunter, Delgrande, & Faber, 2007),
believe approach could developed. Another important direction
future research involves relaxing assumption action histories correct. realistic action domains, agents may incorrect actions occurred.
domains, always reasonable discard observation inconsistent
perceived action history. Instead, agent consider likelihood
observation correct well likelihood action history correct. Hence,
plausible histories determined considering relative plausibility
302

fiIterated Belief Change Due Actions Observations

action observation. Belief evolution operators seen specific case kind
reasoning, action occurrences always plausible observations.

References
Alchourron, C., Gardenfors, P., & Makinson, D. (1985). logic theory change:
Partial meet functions contraction revision. Journal Symbolic Logic, 50 (2),
510530.
Booth, R., & Meyer, T. (2006). Admissible restrained revision. Journal Artificial
Intelligence Research, 26, 127151.
Boutilier, C. (1995). Generalized update: Belief change dynamic settings. Proceedings
Fourteenth International Joint Conference Artificial Intelligence (IJCAI
1995), pp. 15501556.
Darwiche, A., & Pearl, J. (1997). logic iterated belief revision. Artificial Intelligence, 89 (1-2), 129.
Delgrande, J., Dubois, D., & Lang, J. (2006). Iterated revision prioritized merging.
Proceedings 10th International Conference Principles Knowledge Representation Reasoning (KR2006).
Gelfond, M., & Lifschitz, V. (1998). Action languages. Linkoping Electronic Articles
Computer Information Science, 3 (16), 116.
Herzig, A., Lang, J., & Marquis, P. (2004). Revision update multi-agent belief
structures. Proceedings LOFT 6.
Hunter, A., & Delgrande, J. (2005). Iterated belief change: transition system approach.
Proceedings International Joint Conference Artificial Intelligence (IJCAI05),
pp. 460465.
Hunter, A., & Delgrande, J. (2006). Belief change context fallible actions observations. Proceedings National Conference Artificial Intelligence(AAAI06).
Hunter, A., Delgrande, J., & Faber, J. (2007). Using answer sets solve belief change
problems. Proceedings 9th International Conference Logic Programming
Non Monotonic Reasoning (LPNMR 2007).
Jin, Y., & Thielscher, M. (2007). Iterated belief revision, revised. Artificial Intelligence,
171 (1), 118.
Katsuno, H., & Mendelzon, A. (1991). difference updating knowledge base
revising it. Proceedings Second International Conference Principles
Knowledge Representation Reasoning (KR 1991), pp. 387394.
Katsuno, H., & Mendelzon, A. (1992). Propositional knowledge base revision minimal
change. Artificial Intelligence, 52 (2), 263294.
Kern-Isberner, G. (2008). Linking iterated belief change operations nonmonotonic reasoning. Proceedings 11th International Conference Principles Knowledge
Representation Reasoning (KR2008).
303

fiHunter & Delgrande

Lang, J. (2006). time, revision, update. Proceedings 11th International
Workshop Non-Monotonic Reasoning (NMR 2006).
Lehmann, D. (1995). Belief revision, revised. Proceedings Fourteenth International
Joint Conference Artificial Intelligence (IJCAI95), pp. 15341541.
Levesque, H. (1996). planning presence sensing?. Proceedings
Thirteenth National Conference Artificial Intelligence (AAAI96), pp. 11391146.
Levesque, H., Pirri, F., & Reiter, R. (1998). Foundations situation calculus.
Linkoping Electronic Articles Computer Information Science, 3 (18), 118.
Lobo, J., Mendez, G., & Taylor, S. (2001). Knowledge action description language
A. Theory Practice Logic Programming, 1 (2), 129184.
Moore, R. (1985). formal theory knowledge action. Hobbs, J., & Moore, R.
(Eds.), Formal Theories Commonsense World, pp. 319358. Ablex Publishing.
Nayak, A. (1994). Iterated belief change based epistemic entrenchment. Erkenntnis, 41,
353390.
Nayak, A., Pagnucco, M., & Peppas, P. (2003). Dynamic belief change operators. Artificial
Intelligence, 146, 193228.
Papini, O. (2001). Iterated revision operations stemming history agents
observations. Rott, H., & Williams, M. (Eds.), Frontiers Belief Revision, pp.
279301. Kluwer Academic Publishers.
Peppas, P., Nayak, A., Pagnucco, M., Foo, N., Kwok, R., & Prokopenko, M. (1996). Revision
vs. update: Taking closer look. Proceedings Twelfth European Conference
Artificial Intelligence (ECAI96), pp. 9599.
Shapiro, S., & Pagnucco, M. (2004). Iterated belief change exogenous actions
situation calculus. Proceedings Sixteenth European Conference Artificial
Intelligence (ECAI04), pp. 878882.
Shapiro, S., Pagnucco, M., Lesperance, Y., & Levesque, H. (2000). Iterated belief change
situation calculus. Proceedings Seventh International Conference
Principles Knowledge Representation Reasoning (KR 2000), pp. 527538.
Morgan Kaufmann Publishers.
Son, T., & Baral, C. (2001). Formalizing sensing actions: transition function based
approach. Artificial Intelligence, 125 (1-2), 1991.

304

fiJournal Artificial Intelligence Research 40 (2011) 95-142

Submitted 07/10; published 01/11

Monte-Carlo AIXI Approximation
Joel Veness

joelv@cse.unsw.edu.au

University New South Wales National ICT Australia

Kee Siong Ng

keesiong.ng@gmail.com

Australian National University

Marcus Hutter

marcus.hutter@anu.edu.au

Australian National University National ICT Australia

William Uther

william.uther@nicta.com.au

National ICT Australia University New South Wales

David Silver

davidstarsilver@googlemail.com

Massachusetts Institute Technology

Abstract
paper introduces principled approach design scalable general reinforcement
learning agent. approach based direct approximation AIXI, Bayesian optimality
notion general reinforcement learning agents. Previously, unclear whether theory
AIXI could motivate design practical algorithms. answer hitherto open question
armative, providing first computationally feasible approximation AIXI agent.
develop approximation, introduce new Monte-Carlo Tree Search algorithm along
agent-specific extension Context Tree Weighting algorithm. Empirically, present set
encouraging results variety stochastic partially observable domains. conclude
proposing number directions future research.

1. Introduction
Reinforcement Learning (Sutton & Barto, 1998) popular influential paradigm agents
learn experience. AIXI (Hutter, 2005) Bayesian optimality notion reinforcement learning agents unknown environments. paper introduces evaluates practical reinforcement
learning agent directly inspired AIXI theory.
1.1 General Reinforcement Learning Problem
Consider agent exists within unknown environment. agent interacts
environment cycles. cycle, agent executes action turn receives observation
reward. information available agent history previous interactions.
general reinforcement learning problem construct agent that, time, collects much
reward possible (unknown) environment.
1.2 AIXI Agent
AIXI agent mathematical solution general reinforcement learning problem.
achieve generality, environment assumed unknown computable function; i.e.
c
2011
AI Access Foundation. rights reserved.

fiVeness, Ng, Hutter, Uther, & Silver

observations rewards received agent, given past actions, computed
program running Turing machine. AIXI agent results synthesis two ideas:
1. use finite-horizon expectimax operation sequential decision theory action
selection;
2. extension Solomonos universal induction scheme (Solomono, 1964) future prediction agent context.
formally, let U(q, a1 a2 . . . ) denote output universal Turing machine U supplied
program q input a1 a2 . . . , N finite lookahead horizon, (q) length bits
program q. action picked AIXI time t, executed actions a1 a2 . . . at1
received sequence observation-reward pairs o1 r1 o2 r2 . . . ot1 rt1 environment,
given by:



= arg max
. . . max
[rt + + rt+m ]
2(q) .
(1)


ot rt

at+m

q:U(q,a1 ...at+m )=o1 r1 ...ot+m rt+m

ot+m rt+m

Intuitively, agent considers sum total reward possible futures steps
ahead, weighs complexity programs consistent agents past
generate future, picks action maximises expected future rewards. Equation (1)
embodies one line major ideas Bayes, Ockham, Epicurus, Turing, von Neumann, Bellman,
Kolmogorov, Solomono. AIXI agent rigorously shown Hutter (2005) optimal
many dierent senses word. particular, AIXI agent rapidly learn accurate
model environment proceed act optimally achieve goal.
Accessible overviews AIXI agent given Legg (2008) Hutter (2007).
complete description agent found work Hutter (2005).
1.3 AIXI Principle
AIXI agent asymptotically computable, means algorithmic solution
general reinforcement learning problem. Rather best understood Bayesian optimality
notion decision making general unknown environments. such, role general AI research viewed in, example, way minimax empirical risk minimisation
principles viewed decision theory statistical machine learning research. principles
define optimal behaviour computational complexity issue, provide important theoretical guidance design practical algorithms. paper demonstrates,
first time, practical agent built AIXI theory.
1.4 Approximating AIXI
seen Equation (1), two parts AIXI. first expectimax search
future call planning. second use Bayesian mixture
Turing machines predict future observations rewards based past experience; call
learning. parts need approximated computational tractability. many
dierent approaches one try. paper, opted use generalised version UCT
algorithm (Kocsis & Szepesvari, 2006) planning generalised version Context Tree
Weighting algorithm (Willems, Shtarkov, & Tjalkens, 1995) learning. combination ideas,
together attendant theoretical experimental results, form main contribution
paper.
96

fiA Monte-Carlo AIXI Approximation

1.5 Paper Organisation
paper organised follows. Section 2 introduces notation definitions use
describe environments accumulated agent experience, including familiar notions reward,
policy value functions setting. Section 3 describes general Bayesian approach
learning model environment. Section 4 presents Monte-Carlo Tree Search procedure
use approximate expectimax operation AIXI. followed description
Context Tree Weighting algorithm generalised use agent setting
Section 5. put two ideas together Section 6 form AIXI approximation algorithm.
Experimental results presented Sections 7. Section 8 provides discussion related
work limitations current approach. Section 9 highlights number areas future
investigation.

2. Agent Setting
section introduces notation terminology use describe strings agent experience, true underlying environment agents model true environment.
Notation. string x1 x2 . . . xn length n denoted x1:n . prefix x1: j x1:n , j n,
denoted x j x< j+1 . notation generalises blocks symbols: e.g. ax1:n denotes
a1 x1 a2 x2 . . . xn ax< j denotes a1 x1 a2 x2 . . . j1 x j1 . empty string denoted .
concatenation two strings r denoted sr.
2.1 Agent Setting
(finite) action, observation, reward spaces denoted A, O, R respectively. Also,
X denotes joint perception space R.
Definition 1. history h element (A X) (A X) A.
following definition states environment takes form probability distribution
possible observation-reward sequences conditioned actions taken agent.
Definition 2. environment sequence conditional probability functions {0 , 1 , 2 , . . . },
n : Density (Xn ), satisfies

a1:n x<n : n1 (x<n | a<n ) =
n (x1:n | a1:n ).
(2)
xn X

base case, 0 ( | ) = 1.
Equation (2), called chronological condition (Hutter, 2005), captures natural constraint
action eect earlier perceptions x<n . convenience, drop index n n
onwards.
Given environment , define predictive probability
(xn | ax<n ) :=

(x1:n | a1:n )
(x<n | a<n )

(3)

a1:n x1:n (x<n | a<n ) > 0. follows
(x1:n | a1:n ) = (x1 | a1 )(x2 | ax1 a2 ) (xn | ax<n ).
97

(4)

fiVeness, Ng, Hutter, Uther, & Silver

Definition 2 used two distinct ways. first means describing true underlying
environment. may unknown agent. Alternatively, use Definition 2 describe
agents subjective model environment. model typically learnt, often
approximation true environment. make distinction clear, refer
agents environment model talking agents model environment.
Notice ( | h) arbitrary function agents previous history h. definition
environment suciently general encapsulate wide variety environments, including standard
reinforcement learning setups MDPs POMDPs.
2.2 Reward, Policy Value Functions
cast familiar notions reward, policy value (Sutton & Barto, 1998) setup.
agents goal accumulate much reward lifetime. precisely,
agent seeks policy allow maximise expected future reward fixed, finite,
arbitrarily large horizon N. instantaneous reward values assumed bounded.
Formally, policy function maps history action. define Rk (aort ) := rk
1 k t, following definition expected future value agent acting
particular policy:
Definition 3. Given history ax1:t , m-horizon expected future reward agent acting
policy : (A X) respect environment is:
t+m

fifi


fi


(5)
v (, ax1:t ) := E
Ri (axt+m ) fifi x1:t ,
i=t+1

< k + m, ak := (ax<k ). quantity vm
(, ax1:t at+1 ) defined similarly, except
at+1 longer defined .
optimal policy policy maximises expected future reward. maximal
achievable expected future reward agent history h environment looking steps ahead


Vm (h) := vm
( , h). easy see h (A X) ,
Vm (h)

= max
at+1


xt+1

(xt+1 | hat+1 ) max
at+m


xt+m

t+m

(xt+m | haxt+1:t+m1 at+m )



ri .

(6)

i=t+1

convenience, often refer Equation (6) expectimax operation. Furthermore,
m-horizon optimal action at+1 time + 1 related expectimax operation
at+1 = arg max Vm (ax1:t at+1 ).
at+1

(7)

Equations (5) (6) modified handle discounted reward, however focus
finite-horizon case since aligns AIXI allows simplified presentation.

3. Bayesian Agents
mentioned earlier, Definition 2 used describe agents subjective model true
environment. Since assuming agent initially know true environment,
98

fiA Monte-Carlo AIXI Approximation

desire subjective models whose predictive performance improves agent gains experience.
One way provide model take Bayesian perspective. Instead committing
single fixed environment model, agent uses mixture environment models. requires
committing class possible environments (the model class), assigning initial weight
possible environment (the prior), subsequently updating weight model using Bayes
rule (computing posterior) whenever experience obtained. process learning
thus implicit within Bayesian setup.
mechanics procedure reminiscent Bayesian methods predict sequences
(single typed) observations. key dierence agent setup prediction may
also depend previous agent actions. incorporate using action conditional
definitions identities Section 2.


Definition 4. Given countable model class := {1 , 2 , . . . } prior weight w0 > 0



w0 = 1, mixture environment model (x1:n | a1:n ) :=
w0 (x1:n | a1:n ).


next proposition allows us use mixture environment model whenever use
environment model.
Proposition 1. mixture environment model environment model.
Proof. a1:n x<n Xn1






(x1:n | a1:n ) =
w0 (x1:n | a1:n ) =
w0
(x1:n | a1:n ) = (x<n | a<n )
xn X

xn X



xn X

final step follows application Equation (2) Definition 4.



importance Proposition 1 become clear context planning environment
models, described Section 4.
3.1 Prediction Mixture Environment Model
mixture environment model environment model, simply use:
(x1:n | a1:n )
(8)
(xn | ax<n ) =
(x<n | a<n )
predict next observation reward pair. Equation (8) also expressed terms convex
combination model predictions, model weighted posterior,

w0 (x1:n | a1:n )



=
w (xn | ax<n ),
(xn | ax<n ) =
w0 (x<n | a<n ) n1


posterior weight


wn1

environment model given


w (x<n | a<n )

wn1 := 0
= Pr( | ax<n )
w0 (x<n | a<n )

(9)



|M| finite, Equations (8) (3.1) maintained online O(|M|) time using
fact
(x1:n | a1:n ) = (x<n | a<n )(xn | ax<n a),
follows Equation (4), incrementally maintain likelihood term model.
99

fiVeness, Ng, Hutter, Uther, & Silver

3.2 Theoretical Properties
show good model (unknown) environment M, agent using
mixture environment model


(x1:n | a1:n ) :=
w0 (x1:n | a1:n )
(10)


predict well. proof adaptation work Hutter (2005). present full
proof instructive directly relevant many dierent kinds practical Bayesian
agents.
First state useful entropy inequality.
Lemma 1 (Hutter, 2005). Let {yi } {zi } two probability distributions, i.e. yi 0, zi 0,


yi = zi = 1.


yi
(yi zi )2
yi ln .
zi


Theorem 1. Let true environment. -expected squared dierence bounded
follows. n N, a1:n ,
n


(
)2
{
}

(x<k | a<k ) (xk | ax<k ak ) (xk | ax<k ak ) min ln w0 + D1:n ( ) ,


k=1 x1:k

D1:n ( ) :=


x1:n

1:n | a1:n )
(x1:n | a1:n ) ln (x
(x1:n | a1:n ) KL divergence ( | a1:n ) ( | a1:n ).

Proof. Combining Sections 3.2.8 5.1.3 work Hutter (2005) get
n


(
)2
(x<k | a<k ) (xk | ax<k ak ) (xk | ax<k ak )

k=1 x1:k

=


n

k=1 x<k
n


(x<k | a<k )

(
xk

(x<k | a<k )



k=1 x<k

n


(xk | ax<k ak ) (xk | ax<k ak )

(xk | ax<k ak ) ln

xk

(xk | ax<k ak )
(xk | ax<k ak )

(xk | ax<k ak )
(xk | ax<k ak )
k=1 x1:k
n (
) (x | ax )

k
<k k
=
(x1:n | a1:n ) ln
(x
|
ax
ak )
k
<k
x
k=1 x
=

1:k

=

n


(x1:k | a1:k ) ln

=

x1:n

=


x1:n

[Lemma 1]
[Equation (3)]
[Equation (2)]

k+1:n

(x1:n | a1:n ) ln

k=1 x1:n



)2

(x1:n | a1:n )

n

k=1

(x1:n | a1:n ) ln

ln

(xk | ax<k ak )
(xk | ax<k ak )
(xk | ax<k ak )
(xk | ax<k ak )

(x1:n | a1:n )
(x1:n | a1:n )

[Equation (4)]

100

fiA Monte-Carlo AIXI Approximation

[

]
(x1:n | a1:n ) (x1:n | a1:n )
=
(x1:n | a1:n ) ln
[arbitrary M]
(x1:n | a1:n ) (x1:n | a1:n )
x1:n

(x1:n | a1:n )
(x1:n | a1:n )
=
(x1:n | a1:n ) ln
+
(x1:n | a1:n ) ln
(x1:n | a1:n ) x
(x1:n | a1:n )
x1:n
1:n

(x1:n | a1:n )
D1:n ( ) +
(x1:n | a1:n ) ln
[Definition 4]
w
x1:n
0 (x1:n | a1:n )




= D1:n ( ) ln w0 .
Since inequality holds arbitrary M, holds minimising .



Theorem 1, take supremum n r.h.s limit n l.h.s.
supn D1:n ( ) < minimising , infinite sum l.h.s finite
(xk | ax<k ak ) converges suciently fast (xk | ax<k ak ) k probability 1, hence
predicts rapid convergence. long D1:n ( ) = o(n), still converges
weaker Cesaro sense. contrapositive statement tells us fails predict
environment well, good model M.
3.3 AIXI: Universal Bayesian Agent
Theorem 1 motivates construction Bayesian agents use rich model classes. AIXI
agent seen limiting case viewpoint, using largest model class expressible
Turing machine.
Note AIXI handle stochastic environments since Equation (1) shown formally equivalent



= arg max
. . . max
[rt + + rt+m ]
2K() (x1:t+m | a1:t+m ),
(11)


ot rt

at+m

MU

ot+m rt+m

(x1:t+m | a1 . . . at+m ) probability observing x1 x2 . . . xt+m given actions a1 a2 . . . at+m ,
class MU consists enumerable chronological semimeasures (Hutter, 2005), includes
computable , K() denotes Kolmogorov complexity (Li & Vitanyi, 2008) respect
U. case environment computable function

U (x1:t | a1:t ) :=
2K() (x1:t | a1:t ),
(12)
MU

Theorem 1 shows n N a1:n ,
n


(
)2
(x<k | a<k ) (xk | ax<k ak ) U (xk | ax<k ak ) K() ln 2.

(13)

k=1 x1:k

3.4 Direct AIXI Approximation
position describe approach AIXI approximation. prediction, seek
computationally ecient mixture environment model replacement U . Ideally,
retain U bias towards simplicity generality. achieved placing
suitable Ockham prior set candidate environment models.
101

fiVeness, Ng, Hutter, Uther, & Silver

planning, seek scalable algorithm can, given limited set resources, compute
approximation expectimax action given
at+1 = arg max VmU (ax1:t at+1 ).
at+1

main diculties course computational. next two sections introduce two algorithms used (partially) fulfill criteria. subsequent combination
constitute AIXI approximation.

4. Expectimax Approximation Monte-Carlo Tree Search
Nave computation expectimax operation (Equation 6) takes O(|A X|m ) time, unacceptable
tiny values m. section introduces UCT, generalisation popular MonteCarlo Tree Search algorithm UCT (Kocsis & Szepesvari, 2006), used approximate
finite horizon expectimax operation given environment model . environment model
subsumes MDPs POMDPs, UCT eectively extends UCT algorithm wider class
problem domains.
4.1 Background
UCT proven particularly eective dealing dicult problems containing large state
spaces. requires generative model given state-action pair (s, a) produces subsequent state-reward pair (s , r) distributed according Pr(s , r | s, a). successively sampling
trajectories state space, UCT algorithm incrementally constructs search tree,
node containing estimate value state. Given enough time, estimates
converge true values.
UCT algorithm realised replacing notion state UCT agent history
h (which always sucient statistic) using environment model predict next
percept. main subtlety extension history condition percept
probability (or | h) needs updated search. reflect extra information
agent hypothetical future point time. Furthermore, Proposition 1 allows UCT
instantiated mixture environment model, directly incorporates model uncertainty
agent planning process. gives (in principle, provided model class contains
true environment ignoring issues limited computation) well known Bayesian solution
exploration/exploitation dilemma; namely, reduction model uncertainty would lead
higher expected future reward, UCT would recommend information gathering action.
4.2 Overview
UCT best-first Monte-Carlo Tree Search technique iteratively constructs search tree
memory. tree composed two interleaved types nodes: decision nodes chance nodes.
correspond alternating max sum operations expectimax operation.
node tree corresponds history h. h ends action, chance node; h ends
observation-reward pair, decision node. node contains statistical estimate
future reward.
Initially, tree starts single decision node containing |A| children. Much like existing
MCTS methods (Chaslot, Winands, Uiterwijk, van den Herik, & Bouzy, 2008a), four
102

fiA Monte-Carlo AIXI Approximation

a1

o1

o2

a2

a3

o3

o4

future reward estimate

Figure 1: UCT search tree
conceptual phases single iteration UCT. first selection phase, search
tree traversed root node existing leaf chance node n. second expansion
phase, new decision node added child n. third simulation phase,
rollout policy conjunction environment model used sample possible future
path n fixed distance root reached. Finally, backpropagation phase
updates value estimates node reverse trajectory leading back root. Whilst
time remains, four conceptual operations repeated. time limit reached,
approximate best action selected looking value estimates children root
node.
selection phase, action selection decision nodes done using policy balances
exploration exploitation. policy two main eects:
gradually move estimates future reward towards maximum attainable future
reward agent acted optimally.
cause asymmetric growth search tree towards areas high predicted reward,
implicitly pruning large parts search space.
future reward leaf nodes estimated choosing actions according heuristic policy
total actions made agent, search horizon. heuristic
estimate helps agent focus exploration useful parts search tree, practice
allows much larger horizon brute-force expectimax search.
UCT builds sparse search tree sense observations added chance nodes
generated along sample path. full-width expectimax search tree would
sparse; possible stochastic outcome would represented distinct node search
tree. expectimax, branching factor chance nodes thus |O|, means searching
even moderate sized intractable.
Figure 1 shows example UCT tree. Chance nodes denoted stars. Decision nodes
denoted circles. dashed lines star node indicate children
expanded. squiggly line base leftmost leaf denotes execution rollout
policy. arrows proceeding node indicate flow information back tree;
defined detail below.
103

fiVeness, Ng, Hutter, Uther, & Silver

4.3 Action Selection Decision Nodes
decision node always contain |A| distinct children, chance nodes. Associated
decision node representing particular history h value function estimate, V(h).
selection phase, child need picked exploration. Action selection
MCTS poses classic exploration/exploitation dilemma. one hand need allocate enough
visits children ensure accurate estimates them, hand
need allocate enough visits maximal action ensure convergence node value
maximal child node.
Like UCT, UCT recursively uses UCB policy (Auer, 2002) n-armed bandit setting
decision node determine action needs exploration. Although uniform
logarithmic regret bound longer carries across bandit setting, UCB policy
shown work well practice complex domains computer Go (Gelly & Wang, 2006)
General Game Playing (Finnsson & Bjornsson, 2008). policy advantage ensuring
decision node, every action eventually gets explored infinite number times,
best action selected exponentially often actions lesser utility.
Definition 5. visit count (h) decision node h number times h sampled
UCT algorithm. visit count chance node found taking action h defined
similarly, denoted (ha).
Definition 6. Suppose remaining search horizon instantaneous reward bounded
interval [, ]. Given node representing history h search tree, action picked
UCB action selection policy is:



(h))

1

V(ha) + C log(T
(ha) > 0;
m()
(ha)
(14)
aUCB (h) := arg max

aA

otherwise,
C R positive parameter controls ratio exploration exploitation.
multiple maximal actions, one chosen uniformly random.
Note need linear scaling V(ha) Definition 6 UCB policy
applicable rewards confined [0, 1] interval.
4.4 Chance Nodes
Chance nodes follow immediately action selected decision node. chance
node ha following decision node h contains estimate future utility denoted V(ha).
Also associated chance node ha density ( | ha) observation-reward pairs.
action performed node h, ( | ha) sampled generate next
observation-reward pair or. seen before, node haor added child
ha.
4.5 Estimating Future Reward Leaf Nodes
leaf decision node encountered depth k < tree, means estimating future
reward remaining k time steps required. MCTS methods use heuristic rollout policy

estimate sum future rewards
i=k ri . involves sampling action (h),
104

fiA Monte-Carlo AIXI Approximation

sampling percept ( | ha), appending aor current history h repeating
process horizon reached. procedure described Algorithm 4. natural baseline
policy random , chooses action uniformly random time step.
number simulations tends infinity, structure UCT search tree converges
full depth expectimax tree. occurs, rollout policy longer used UCT.
implies asymptotic value function estimates UCT invariant choice
. practice, time limited, enough simulations performed grow full
expectimax tree. Therefore, choice rollout policy plays important role determining
overall performance UCT. Methods learning online discussed future work
Section 9. Unless otherwise stated, subsequent results use random .
4.6 Reward Backup
selection phase completed, path nodes n1 n2 . . . nk , k m, traversed
root search tree n1 leaf nk . 1 j k, statistics maintained
history hn j associated node n j updated follows:
V(hn j )

(hn j )
(hn j ) + 1


1
ri
(hn j ) + 1 i= j


V(hn j ) +

(hn j ) (hn j ) + 1

(15)
(16)

Equation (15) computes mean return. Equation (16) increments visit counter. Note
backup operation applied decision chance nodes.
4.7 Pseudocode
pseudocode UCT algorithm given.
percept received, Algorithm 1 invoked determine approximate best
action. simulation corresponds single call Sample Algorithm 1. performing
number simulations, search tree whose root corresponds current history h constructed. tree contain estimates Vm (ha) A. available thinking time
exceeded, maximising action ah := arg maxaA Vm (ha) retrieved BestAction. Importantly,
Algorithm 1 anytime, meaning approximate best action always available. allows
agent eectively utilise available computational resources decision.
Algorithm 1 UCT(h, m)
Require: history h
Require: search horizon N
Initialise()
repeat
3:
Sample(, h, m)
4: time
5: return BestAction(, h)
1:

2:

simplicity exposition, Initialise understood simply clear entire search tree
. practice, possible carry across information one time step another.
105

fiVeness, Ng, Hutter, Uther, & Silver

search tree obtained end time t, aor agents actual action experience time
t, keep subtree rooted node (hao) make search tree t+1
use beginning next time step. remainder nodes deleted.
Algorithm 2 describes recursive routine used sample single future trajectory. uses
SelectAction routine choose moves decision nodes, invokes Rollout routine
unexplored leaf nodes. Rollout routine picks actions according rollout policy
(remaining) horizon reached, returning accumulated reward. complete trajectory
length simulated, value estimates updated node traversed per Section 4.6.
Notice recursive calls Lines 6 11 append recent percept action
history argument.
Algorithm 2 Sample(, h, m)
Require: search tree
Require: history h
Require: remaining search horizon N
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:

= 0
return 0
else (h) chance node
Generate (o, r) (or | h)
Create node (hor) (hor) = 0
reward r + Sample(, hor, 1)
else (h) = 0
reward Rollout(h, m)
else
SelectAction(, h)
reward Sample(, ha, m)
end
1
[reward + (h)V(h)]
V(h) (h)+1
(h) (h) + 1
return reward

action chosen SelectAction specified UCB policy described Definition 6.
selected child explored before, new node added search tree. constant
C parameter used control shape search tree; lower values C create deep,
selective search trees, whilst higher values lead shorter, bushier trees. UCB automatically focuses
attention best looking action way sample estimate V (h) converges V (h),
whilst still exploring alternate actions suciently often guarantee best action
eventually found.
4.8 Consistency UCT
Let true underlying environment. establish link expectimax value
Vm (h) estimate Vm (h) computed UCT algorithm.
Kocsis Szepesvari (2006) show appropriate choice C, UCT algorithm
consistent finite horizon MDPs. interpreting histories Markov states, general agent
106

fiA Monte-Carlo AIXI Approximation

Algorithm 3 SelectAction(, h)
Require: search tree
Require: history h
Require: exploration/exploitation constant C

7:

U = {a : (ha) = 0}
U , {}
Pick U uniformly random
Create node (ha)
return
else

{
}
log(T (h))
1
return arg max m() V(ha) + C
(ha)

8:

end

1:
2:
3:
4:
5:
6:

aA

Algorithm 4 Rollout(h, m)
Require: history h
Require: remaining search horizon N
Require: rollout function
1:
2:
3:
4:
5:
6:
7:
8:

reward 0
= 1
Generate (h)
Generate (o, r) (or | ha)
reward reward + r
h haor
end
return reward

problem reduces finite horizon MDP. means results Kocsis Szepesvari
(2006) directly applicable. Restating main consistency result notation,
(
)
h lim Pr |Vm (h) Vm (h)| = 1,
(h)

(17)

is, Vm (h) Vm (h) probability 1. Furthermore, probability suboptimal action
(with respect Vm ()) picked UCT goes zero limit. Details analysis
found work Kocsis Szepesvari (2006).
4.9 Parallel Implementation UCT
Monte-Carlo Tree Search routine, Algorithm 1 easily parallelised. main idea
concurrently invoke Sample routine whilst providing appropriate locking mechanisms
interior nodes search tree. highly scalable parallel implementation beyond scope
paper, worth noting ideas applicable high performance Monte-Carlo Go programs
(Chaslot, Winands, & Herik, 2008b) easily transferred setting.
107

fiVeness, Ng, Hutter, Uther, & Silver

5. Model Class Approximation using Context Tree Weighting
turn attention construction ecient mixture environment model suitable
general reinforcement learning problem. computation issue, would sucient
first specify large model class M, use Equations (8) (3.1) online prediction.
problem approach least O(|M|) time required process new piece
experience. simply slow enormous model classes required general agents.
Instead, section describe predict O(log log |M|) time, using mixture environment
model constructed adaptation Context Tree Weighting algorithm.
5.1 Context Tree Weighting
Context Tree Weighting (CTW) (Willems et al., 1995; Willems, Shtarkov, & Tjalkens, 1997)
ecient theoretically well-studied binary sequence prediction algorithm works well
practice (Begleiter, El-Yaniv, & Yona, 2004). online Bayesian model averaging algorithm
computes, time point t, probability

Pr(y1:t ) =
Pr(M) Pr(y1:t | M),
(18)


y1:t binary sequence seen far, prediction sux tree (Rissanen, 1983; Ron,
Singer, & Tishby, 1996), Pr(M) prior probability M, summation prediction sux trees bounded depth D. huge class, covering D-order Markov processes.

nave computation (18) takes time O(22 ); using CTW, computation requires O(D) time.
section, outline two ways CTW generalised compute probabilities
form

Pr(x1:t | a1:t ) =
Pr(M) Pr(x1:t | M, a1:t ),
(19)


x1:t percept sequence, a1:t action sequence, prediction sux tree
(18). generalisations allow CTW used mixture environment model.
5.2 Krichevsky-Trofimov Estimator
start brief review KT estimator (Krichevsky & Trofimov, 1981) Bernoulli
distributions. Given binary string y1:t zeros b ones, KT estimate probability
next symbol follows:
b + 1/2
a+b+1
= 0 | y1:t ) := 1 Prkt (Yt+1 = 1 | y1:t ).

Prkt (Yt+1 = 1 | y1:t ) :=
Prkt (Yt+1

(20)
(21)

KT estimator obtained via Bayesian analysis putting uninformative (Jereys
Beta(1/2,1/2)) prior Pr() 1/2 (1 )1/2 parameter [0, 1] Bernoulli distribution. (20)-(21), obtain following expression block probability string:
Prkt (y1:t ) = Prkt (y1 | )Prkt (y2 | y1 ) Prkt (yt | y<t )

= b (1 )a Pr() d.
108

fiA Monte-Carlo AIXI Approximation

?
???0


??


?
1 = 0.1
?? 0
1
??

?


1

01 = 0.3

00 = 0.5

Figure 2: example prediction sux tree
Since Prkt (s) depends number zeros ones b string s, let 0a 1b denote
string zeroes b ones,
Prkt (s) = Prkt (0as 1bs ) =

1/2(1 + 1/2) (a 1/2)1/2(1 + 1/2) (b 1/2)
.
(a + b )!

(22)

write Prkt (a, b) denote Prkt (0a 1b ) following. quantity Prkt (a, b) updated
incrementally (Willems et al., 1995) follows:
+ 1/2
Prkt (a, b)
a+b+1
b + 1/2
Prkt (a, b),
Prkt (a, b + 1) =
a+b+1

Prkt (a + 1, b) =

(23)
(24)

base case Prkt (0, 0) = 1.
5.3 Prediction Sux Trees
next describe prediction sux trees, form variable-order Markov models.
following, work binary trees left edges labeled 1 right
edges labeled 0. node binary tree identified string {0, 1}
follows: represents root node M; n {0, 1} node M, n1 n0 represent
left right child node n respectively. set Ms leaf nodes L(M) {0, 1} form
complete prefix-free set strings. Given binary string y1:t depth M, define
M(y1:t ) := yt yt1 . . . yt , (unique) positive integer yt yt1 . . . yt L(M).
words, M(y1:t ) represents sux y1:t occurs tree M.
Definition 7. prediction sux tree (PST) pair (M, ), binary tree associated
leaf node l probability distribution {0, 1} parametrised l . call
model PST parameter PST, accordance terminology
Willems et al. (1995).
prediction sux tree (M, ) maps binary string y1:t , depth M,
probability distribution M(y1:t ) ; intended meaning M(y1:t ) probability
next bit following y1:t 1. example, PST shown Figure 2 maps string 1110
M(1110) = 01 = 0.3, means next bit 1110 1 probability 0.3.
practice, use prediction sux trees binary sequence prediction, need learn
model parameter prediction sux tree data. deal model-learning
part later. Assuming model PST known/given, parameter PST learnt
using KT estimator follows. start l := Prkt (1 | ) = 1/2 leaf node l M.
109

fiVeness, Ng, Hutter, Uther, & Silver

depth M, first bits y1:d input sequence set aside use initial
context variable h denoting bit sequence seen far set y1:d . repeat
following steps long needed:
1. predict next bit using distribution M(h) ;
2. observe next bit y, update M(h) using Formula (20) incrementing either b according
value y, set h := hy.
5.4 Action-Conditional PST
describes PST used binary sequence prediction. agent setting,
reduce problem predicting history sequences general non-binary alphabets
predicting bit representations sequences. Furthermore, ever condition actions. achieved appending bit representations actions input sequence without
corresponding update KT estimators. ideas formalised.
convenience, assume without loss generality |A| = 2lA |X| = 2lX
lA , lX > 0. Given A, denote = a[1, lA ] = a[1]a[2] . . . a[lA ] {0, 1}lA
bit representation a. Observation reward symbols treated similarly. Further, bit
representation symbol sequence x1:t denoted x1:t = x1 x2 . . . xt .
action-conditional sequence prediction using PST given model M, start
l := Prkt (1 | ) = 1/2 leaf node l M. also set aside suciently long initial
portion binary history sequence corresponding first cycles initialise variable
h usual. following steps repeated long needed:
1. set h := ha, current selected action;
2. := 1 lX
(a) predict next bit using distribution M(h) ;
(b) observe next bit x[i], update M(h) using Formula (20) according value x[i],
set h := hx[i].
Let model prediction sux tree, a1:t action sequence, x1:t Xt
observation-reward sequence, h := ax1:t . node n M, define h M,n
h M,n := hi1 hi2 hik

(25)

1 i1 < i2 < < ik and, i, {i1 , i2 , . . . ik } hi observation-reward bit
n prefix M(h1:i1 ). words, h M,n consists observation-reward bits
context n. Thus following expression probability x1:t given a1:t :
Pr(x1:t | M, a1:t ) =
=




Pr(xi | M, ax<i ai )

i=1
lX



Pr(xi [ j] | M, ax<i ai xi [1, j 1])

i=1 j=1

=



Prkt (h M,n ).

nL(M)

110

(26)

fiA Monte-Carlo AIXI Approximation

last step follows grouping individual probability terms according node
n L(M) bit falls observing Equation (22). deals actionconditional prediction using single PST. show perform ecient actionconditional prediction using Bayesian mixture PSTs. First specify prior PST models.
5.5 Prior Models PSTs
prior Pr(M) := 2D (M) derived natural prefix coding tree structure PST.
coding scheme works follows: given model PST maximum depth D, pre-order
traversal tree performed. time internal node encountered, write 1.
time leaf node encountered, write 0 depth leaf node less D; otherwise
write nothing. example, = 3, code model shown Figure 2 10100;
= 2, code model 101. cost (M) model length code,
given number nodes minus number leaf nodes depth D. One
show

2D (M) = 1,
MC

C set models prediction sux trees depth D; i.e. prefix code
complete. remark another way describing coding scheme Willems
et al. (1995). Note choice prior imposes Ockham-like penalty large PST structures.
5.6 Context Trees
following data structure key ingredient Action-Conditional CTW algorithm.
Definition 8. context tree depth perfect binary tree depth attached
node (both internal leaf) probability {0, 1} .
node probabilities context tree estimated data using KT estimator
node. process update context tree history sequence similar PST, except that:
1. probabilities node path root leaf traversed observed bit
updated;
2. maintain block probabilities using Equations (22) (24) instead conditional probabilities.
process best understood example. Figure 3 (left) shows context tree depth
two. expositional reasons, show binary sequences nodes; node probabilities
computed these. Initially, binary sequence node empty. Suppose 1001
history sequence. Setting aside first two bits 10 initial context, tree middle
Figure 3 shows processing third bit 0. tree right tree
processing fourth bit 1. practice, course store counts
zeros ones instead complete subsequences node because, saw earlier (22),
Prkt (s) = Prkt (a , b ). Since node probabilities completely determined input sequence,
shall henceforth speak unambiguously context tree seeing sequence.
context tree depth seeing sequence h following important properties:
1. model every PST depth obtained context tree pruning
appropriate subtrees treating leaf nodes;
111

fiVeness, Ng, Hutter, Uther, & Silver

?
???0

?


?

??0 1 ???0
1
?
??


?



1

1











?
?? 0
1
??





01 ?

0?

?? 0
??
?

1



0

?? 0
??


1

0?

?? 0
??
?







?
?? 0
1
??





01 ?

1



0

?? 0
??
?

1

Figure 3: depth-2 context tree (left); trees processing two bits (middle right)
2. block probability h computed PST depth obtained
node probabilities context tree via Equation (26).
properties, together application distributive law, form basis highly
ecient Action Conditional CTW algorithm. formalise insights.
5.7 Weighted Probabilities
weighted probability Pnw node n context tree seeing h := ax1:t defined
inductively follows:



n leaf node;
Prkt (hT,n )
Pnw :=
(27)

1
1
n0
n1
Prkt (hT,n ) + Pw Pw otherwise,
2
2
hT,n defined (25).
Lemma 2 (Willems et al., 1995). Let depth-D context tree seeing h := ax1:t .
node n depth d,


Pnw =
2Dd (M)
Prkt (hT,nn ).
(28)
n L(M)

MC Dd

Proof. proof proceeds induction d. statement clearly true leaf nodes
depth D. Assume statement true nodes depth + 1, 0 < D. Consider
node n depth d. Letting = d,
1
1
Pnw = Prkt (hT,n ) + Pn0
Pn1
2
2 w w







1
1



d+1 (M)

(M)


d+1



= Prkt (hT,n ) +
2
Prkt (hT,n0n )
2
Prkt (hT,n1n )




2
2 MC
MCd+1
n L(M)
n L(M)
d+1








1
(d+1 (M1 )+d+1 (M2 )+1)
2
Prkt (hT,n0n )
Prkt (hT,n1n )
= Prkt (hT,n ) +


2
M1 Cd+1 M2 Cd+1
n L(M1 )
n L(M2 )


1
[
= Prkt (hT,n ) +
2d ( M1 M2 )
Prkt (hT,nn )
2

[
[
n L( M1 M2 )
M1 M2 Cd


Dd (M)
=
2
Prkt (hT,nn ),
MC Dd

n L(M)

M[
1 M2 denotes tree C whose left right subtrees M1 M2 respectively.
112



fiA Monte-Carlo AIXI Approximation

5.8 Action Conditional CTW Mixture Environment Model
corollary Lemma 2 root node context tree seeing h := ax1:t ,



Prkt (hT,l )
(29)
Pw =
2D (M)
MC

=



lL(M)
(M)

(30)

2D (M) Pr(x1:t | M, a1:t ),

(31)

MC

=





Prkt (h M,l )

2

lL(M)

MC

last step follows Equation (26). Equation (31) shows quantity computed
Action-Conditional CTW algorithm exactly mixture environment model. Note
conditional probability always defined, CTW assigns non-zero probability sequence.
sample conditional probability, simply sample individual bits xt one one.
summary, prediction using Action-Conditional CTW, set aside suciently long
initial portion binary history sequence corresponding first cycles initialise
variable h repeat following steps long needed:
1. set h := ha, current selected action;
2. := 1 lX
(a) predict next bit using weighted probability Pw ;
(b) observe next bit x[i], update context tree using h x[i], calculate new
weighted probability Pw , set h := hx[i].
5.9 Incorporating Type Information
One drawback Action-Conditional CTW algorithm potential loss type information
mapping history string binary encoding. type information may needed
predicting well domains. Although always possible choose binary encoding scheme
type information inferred depth limited context tree, would desirable
remove restriction agent work arbitrary encodings percept space.
One option would define action-conditional version multi-alphabet CTW (Tjalkens,
Shtarkov, & Willems, 1993), alphabet consisting entire percept space. downside
approach lose ability exploit structure within percept.
critical dealing large observation spaces, noted McCallum (1996). key
dierence U-Tree USM algorithms former could discriminate
individual components within observation, whereas latter worked symbol level.
shall see Section 7, property helpful dealing larger problems.
Fortunately, possible get best worlds. describe technique
incorporates type information whilst still working bit level. trick chain together k :=
lX action conditional PSTs, one bit percept space, appropriately overlapping
binary contexts. precisely, given history h, context ith PST recent
+ 1 bits bit-level history string hx[1, 1]. ensure percept bit dependent
portion h, + 1 (instead D) bits used. Thus denote PST
113

fiVeness, Ng, Hutter, Uther, & Silver

model ith bit percept x Mi , joint model M, have:
Pr(x1:t | M, a1:t ) =
=




Pr(xi | M, ax<i ai )

i=1

k


Pr(xi [ j] | j , ax<i ai xi [1, j 1])

(32)

i=1 j=1

=

k


Pr(x1:t [ j] | j , x1:t [ j], a1:t )

j=1

x1:t [i] denotes x1 [i]x2 [i] . . . xt [i], x1:t [i] denotes x1 [i]x2 [i] . . . xt [i], xt [ j] denoting
xt [1] . . . xt [ j 1]xt [ j + 1] . . . xt [k]. last step follows swapping two products (32)
using notation refer product probabilities jth bit percept xi ,
1 t.
next place prior space factored PST models C C D+k1 assuming
factor independent, giving
k


Pr(M) = Pr(M1 , . . . , Mk ) =

2

Di (Mi )

=2



k

i=1

Di (Mi )

,

i=1

Di := + 1. induces following mixture environment model


(x1:t | a1:t ) :=

2



k

i=1

Di (Mi )

Pr(x1:t | M, a1:t ).

(33)

MC D1 C Dk

rearranged product eciently computable mixtures, since
(x1:t | a1:t ) =







M1 C D1

2



k

i=1

k
Di (Mi )

Mk C Dk

Pr(x1:t [ j] | j , x1:t [ j], a1:t )

j=1




k



j (M j )

=
2
Pr(x
[
j]
|

,
x
[
j],

)
.
1:t
j 1:t
1:t


(34)

j=1 j C j

Note factor within Equation (34), result analogous Lemma 2 established
appropriately modifying Lemma 2s proof take account one bit per percept
predicted. leads following scheme incrementally maintaining Equation (33):
1. Initialise h , 1. Create k context trees.
2. Determine action . Set h hat .
3. Receive xt . bit xt [i] xt , update ith context tree xt [i] using history
hx[1, 1] recompute Pw using Equation (27).
4. Set h hxt , + 1. Goto 2.
refer technique Factored Action-Conditional CTW, FAC-CTW algorithm
short.
114

fiA Monte-Carlo AIXI Approximation

5.10 Convergence True Environment
show FAC-CTW performs well class stationary n-Markov environments. Importantly, includes class Markov environments used state-based reinforcement learning,
recent action/observation pair (at , xt1 ) sucient statistic prediction
xt .
Definition 9. Given n N, environment said n-Markov > n, a1:t ,
x1:t Xt h (A X)tn1
(xt | ax<t ) = (xt | hxtn axtn+1:t1 ).

(35)

Furthermore, n-Markov environment said stationary ax1:n an+1 (A X)n A,
h, h (A X) ,
( | hax1:n an+1 ) = ( | h ax1:n an+1 ).
(36)
easy see stationary n-Markov environment represented product
suciently large, fixed parameter PSTs. Theorem 1 states predictions made mixture
environment model converge true environment model class contains
model suciently close true environment. However, stationary n-Markov environment
model contained within model class FAC-CTW, since model updates parameters
KT-estimators data seen. Fortunately, problem, since updating
produces models suciently close stationary n-Markov environment Theorem 1
meaningful.
Lemma 3. model class used FAC-CTW context depth D, environment
expressible product k := lX fixed parameter PSTs (M1 , 1 ), . . . , (Mk , k ) maximum depth
( | a1:n ) Pr( | (M1 , . . . , Mk ), a1:n ) n N, a1:n ,
(

k


n
D1:n ( || )
|L(M j )|
|L(M j )|
j=1
{


(z) :=

z
1
2

log z + 1




)

0z<1
z 1.

Proof. n N, a1:n ,


(x1:n | a1:n )
(x1:n | a1:n )
x1:n
k

j=1 Pr(x1:n [ j] | j , j , x1:n [ j], a1:n )
=
(x1:n | a1:n ) ln k
x1:n
j=1 Pr(x1:n [ j] | j , x1:n [ j], a1:n )

D1:n ( || ) =



(x1:n | a1:n ) ln

k


Pr(x1:n [ j] | j , j , x1:n [ j], a1:n )
Pr(x1:n [ j] | j , x1:n [ j], a1:n )
x1:n
j=1
)
(
k


n

(x1:n | a1:n )
|L(M j )|
|L(M j )|
x
j=1
=

(x1:n | a1:n )

ln

1:n

115

(37)

fiVeness, Ng, Hutter, Uther, & Silver

(

k


n
=
|L(M j )|
|L(M j )|
j=1

)

Pr(x1:n [ j] | j , j , x1:n [ j], a1:n ) denotes probability fixed parameter PST (M j , j )
generating sequence x1:n [ j] bound introduced (37) work Willems et al.
(1995).

unknown environment stationary n-Markov, Lemma 3 Theorem 1
applied FAC-CTW mixture environment model . Together imply cumulative expected squared dierence bounded O(log n). Also, per cycle -expected
squared dierence goes zero rapid rate O(log n/n). allows us
conclude FAC-CTW (with suciently large context depth) perform well class
stationary n-Markov environments.
5.11 Summary
described two dierent ways CTW extended define large
eciently computable mixture environment model. first complete derivation
Action-Conditional CTW algorithm first presented work Veness, Ng, Hutter, Silver
(2010). second introduction FAC-CTW algorithm, improves upon ActionConditional CTW automatically exploiting type information available within agent setting.
rest paper make extensive use FAC-CTW algorithm, clarity
define
k Di (Mi )
(x1:t | a1:t ) :=
2 i=1
Pr(x1:t | M, a1:t ).
(38)
MC D1 C Dk

Also recall using mixture environment model, conditional probability xt given
ax<t
(x1:t | a1:t )
(xt | ax<t ) =
,
(x<t | a<t )
follows directly Equation (3). generate percept conditional probability
distribution, simply sample lX bits, one one, .
5.12 Relationship AIXI
moving on, examine relationship AIXI model class approximation.
Using place Equation (6), optimal action agent time t, experienced
ax1:t1 , given
t+m
(x1:t | a1:t )
(x1:t+m | a1:t+m )
r

= arg max
max


at+m
(x<t | a<t )
(x<t+m | a<t+m ) i=t
xt
xt+m
t+m t+m

(x1:i | a1:i )

r
= arg max
max




at+m
(x<i | a<i )
xt
xt+m i=t
i=t
t+m

(x1:t+m | a1:t+m )
r
= arg max
max



at+m
(x<t | a<t )
x
x
i=t


t+m

116

fiA Monte-Carlo AIXI Approximation

= arg max



xt

t+m

r (x
max

1:t+m | a1:t+m )

at+m
xt+m

i=t

t+m


r
= arg max
max




at+m

xt

xt+m

i=t



2



k

i=1

Di (Mi )

Pr(x1:t+m | M, a1:t+m ).

MC D1 C Dk

Contrast (39) Equation (11) reproduce here:
t+m



r
. . . max
2K() (x1:t+m | a1:t+m ),
= arg max




xt

at+m

xt+m

(39)

i=t

(40)



class enumerable chronological semimeasures, K() denotes Kolmogorov complexity . two expressions share prior enforces bias towards simpler
models. main dierence subexpression describing mixture model class.
AIXI uses mixture enumerable chronological semimeasures. scaled
(factored) mixture prediction sux trees setting. Although model class used AIXI
completely general, also incomputable. approximation restricted model class
gain desirable computational properties FAC-CTW.

6. Putting Together
approximate AIXI agent, MC-AIXI(fac-ctw), realised instantiating UCT algorithm
= . additional properties combination discussed.
6.1 Convergence Value
show using place true environment expectimax operation leads
good behaviour stationary n-Markov. result combines Lemma 3
adaptation work Hutter (2005, Thm. 5.36). analysis, assume instantaneous rewards non-negative (with loss generality), FAC-CTW used suciently
large context depth, maximum life agent b N fixed bounded planning
horizon mt := min(H, b + 1) used time t, H N specifying maximum planning
horizon.
Theorem 2. Using FAC-CTW algorithm, every policy , true environment expressible product k PSTs (M1 , 1 ), . . . , (Mk , k ), b N,

(
)
k
k
b
[(



)2 ]

b
mt
mt
3 2

E x<t v (, ax<t ) v (, ax<t ) 2H rmax Di (Mi ) +
|L(M j )|

|L(M
)|
j
i=1
j=1
t=1

rmax maximum instantaneous reward, defined Lemma 3 vm
(, ax<t )
value policy defined Definition 3.

Proof. First define (xi: j | a1: j , x<i ) := (x1: j | a1: j )/(x<i | a<i ) < j , environment model
let at:mt actions chosen times mt .
fifi
fifi
fi
fifi
fifi
fi
fi

fi (rt + + rm ) [(xt:m | a1:m , x<t ) (xt:m | a1:m , x<t )]fififi
fivt (, ax<t ) vm
(, ax<t )fi = fifi





fifi
fi xt:mt
117

fiVeness, Ng, Hutter, Uther, & Silver





fi
fi
(rt + + rmt ) fifi(xt:mt | a1:mt , x<t ) (xt:mt | a1:mt , x<t )fifi

xt:mt



mt rmax

fi
fifi(x | , x ) (x | , x )fififi
t:mt
1:mt <t
t:mt
1:mt <t
xt:mt

=: mt rmax At:mt ( || ).
Applying bound, property absolute distance (Hutter, 2005, Lemma 3.11) chain rule
KL-divergence (Cover & Thomas, 1991, p. 24) gives
b


b
[(

)2 ]
]
[
mt
2 2

(,
ax
)
(,
ax
)

v


r
E x<t At:mt ( || )2
E x<t vm
<t
<t

max

t=1

t=1
2
2H 2 rmax

b


]
[
2
E x<t Dt:mt ( || ) = 2H 2 rmax



[
]
E x<i Di:i ( || )

t=1 i=t

t=1
2
2H 3 rmax

mt
b


b


[
]
2
E x<t Dt:t ( || ) = 2H 3 rmax
D1:b ( || ),

t=1

Di: j ( || ) := xi: j (xi: j | a1: j , x<i ) ln((xi: j | a1: j , x<i )/(xi: j | a1: j , x<i )). final inequality
uses fact particular Di:i ( || ) term appears H times preceding double
sum. define ( | a1:b ) := Pr( | (M1 , . . . , Mk ), a1:b )
[
]

(x1:b | a1:b ) (x1:b | a1:b )
D1:b ( || ) =
(x1:b | a1:b ) ln
(x1:b | a1:b ) (x1:b | a1:b )
x1:b


(x1:b | a1:b )
(x1:b | a1:b )
=
(x1:b | a1:b ) ln
+
(x1:b | a1:b ) ln
(x1:b | a1:b ) x
(x1:b | a1:b )
x1:b
1:b

(x1:b | a1:b )
D1:b ( ) +
(x1:b | a1:b ) ln
w0 (x1:b | a1:b )
x1:b
= D1:b ( ) +

k


Di (Mi )

i=1

w0



k


Di (Mi )


:= 2
final inequality follows dropping contribution
Equation (38). Using Lemma 3 bound D1:b ( ) gives desired result.

i=1

fixed H, Theorem 2 shows cumulative expected squared dierence true
values bounded term grows rate O(log b). average expected squared
log b
dierence two values goes zero rate O( b ). implies
suciently large b, value estimates using place converge fixed policy .
Importantly, includes fixed horizon expectimax policy respect .
6.2 Convergence Optimal Policy
section presents result n-Markov environments ergodic stationary. Intuitively, class environments never allow agent make mistake
longer recover. Thus environments agent learns mistakes hope
achieve long-term average reward approach optimality.
118

fiA Monte-Carlo AIXI Approximation

Definition 10. n-Markov environment said ergodic exists policy
every sub-history (A X)n possible occurs infinitely often (with probability 1) history
generated agent/environment pair (, ).
Definition 11. sequence policies {1 , 2 , . . . } said self optimising respect model
class
1
1
v (m , ) Vm () 0
M.
(41)


self optimising policy long-term average expected future reward optimal
policy environment M. general, policies cannot exist model classes.
restrict attention set stationary, ergodic n-Markov environments since
modeled eectively FAC-CTW. ergodicity property ensures possible
percepts precluded due earlier actions agent. stationarity property ensures
environment suciently well behaved PST learn fixed set parameters.
prove lemma preparation main result.
Lemma 4. stationary, ergodic n-Markov environment modeled finite, ergodic MDP.
Proof. Given ergodic n-Markov environment , associated action space percept space
X, equivalent, finite MDP (S , A, T, R) constructed defining state space
:= (A X)n , action space := A, transition probability (s, ) := (o r | hsa)
reward function Ra (s, ) := r , sux formed deleting leftmost
action/percept pair sao r h arbitrary history (A X) . (s, ) well defined
arbitrary h since stationary, therefore Eq. (36) applies. Definition 10 implies derived
MDP ergodic.

Theorem 3. Given mixture environment model model class consisting
{ of} countable
set stationary, ergodic n-Markov environments, sequence policies 1 , 2 , . . .


b (ax<t ) := arg max Vbt+1 (ax<t )


(42)

1 b, self-optimising respect model class M.
Proof. applying Lemma 4 M, equivalent model class N finite, ergodic MDPs
produced. know Hutter (2005, Thm. 5.38) sequence policies N
self-optimising exists. implies existence corresponding sequence policies
self-optimising.
{
} Using work Hutter (2005, Thm. 5.29), implies sequence
policies 1 , 2 , . . . self optimising.

Theorem 3 says choosing suciently large lifespan b, average reward agent

following policy b made arbitrarily close optimal average reward respect
true environment.
Theorem 3 consistency UCT algorithm (17) give support claim
MC-AIXI(fac-ctw) agent self-optimising respect class stationary, ergodic, nMarkov environments. argument isnt completely rigorous, since usage KT-estimator
implies model class FAC-CTW contains uncountable number models. conclusion entirely unreasonable however. justification countable mixture PSTs
119

fiVeness, Ng, Hutter, Uther, & Silver

behaving similarly FAC-CTW mixture formed replacing PST leaf node KTestimator finely grained, discrete Bayesian mixture predictor. interpretation,
floating point implementation KT-estimator would correspond computationally feasible
approximation above.
results used proof Theorem 3 found works Hutter (2002b)
Legg Hutter (2004). interesting area future research would investigate whether
self-optimising result similar work Hutter (2005, Thm. 5.29) holds continuous mixtures.
6.3 Computational Properties
FAC-CTW algorithm grows context tree data structure dynamically. context depth
D, O(tD log(|O||R|)) nodes set context trees cycles. practice,
considerably less log(|O||R|)2D , number nodes fully grown set
context trees. time complexity FAC-CTW also impressive; O(Dm log(|O||R|)) generate
percepts needed perform single UCT simulation O(D log(|O||R|)) process
new piece experience. Importantly, quantities dependent t, means
performance agent degrade time. Thus reasonable run agent
online setting millions cycles. Furthermore, FAC-CTW exact algorithm,
suer approximation issues plague sample based approaches Bayesian learning.
6.4 Ecient Combination FAC-CTW UCT
Earlier, showed FAC-CTW used online setting. additional property however
needed ecient use within UCT. Sample invoked, FAC-CTW computed
set context trees history length t. complete trajectory sampled, FAC-CTW
contain set context trees history length + m. original set context
trees needs restored. Saving copying original context trees unsatisfactory,
rebuilding scratch O(tD log(|O||R|)) time. Luckily, original set context trees
recovered eciently traversing history time + reverse, performing inverse
update operation aected nodes relevant context tree, bit
sample trajectory. takes O(Dm log(|O||R|)) time. Alternatively, copy write implementation
used modify context trees simulation phase, modified copies
context node discarded Sample invoked again.
6.5 Exploration/Exploitation Practice
Bayesian belief updating combines well expectimax based planning. Agents using combination, AIXI MC-AIXI(fac-ctw), automatically perform information gathering
actions expected reduction uncertainty would lead higher expected future reward. Since
AIXI mathematical notion, simply take large initial planning horizon b, e.g. maximal
lifespan, cycle choose greedily respect Equation (1) using remaining
horizon b + 1. Unfortunately case MC-AIXI(fac-ctw), situation complicated
issues limited computation.
theory, MC-AIXI(fac-ctw) agent could always perform action recommended
UCT. practice however, performing expectimax operation remaining horizon bt+1
feasible, even using Monte-Carlo approximation. Instead use large fixed search hori120

fiA Monte-Carlo AIXI Approximation

Environment

Perform action real world

Record new sensor information
... Past Observation/Reward Action

... Past

Record Action

Observation/Reward

MC-AIXI
approximate AIXI agent

Refine environment model

a1

o1

o2

a2

a3

o3

o4

Update Bayesian Mixture Models

+

-

-

-

+

-

future reward estimate

.......
Simple

Complex

Large Prior

Small Prior

Determine best action

Figure 4: MC-AIXI agent loop

zon aord computationally, occasionally force exploration according heuristic policy. intuition behind choice many domains, good behaviour achieved
using small amount planning dynamics domain known. Note still
possible UCT recommend exploratory action, benefits information
realised within limited planning horizon. Thus, limited amount exploration help
agent avoid local optima respect present set beliefs underlying environment. online reinforcement learning algorithms SARSA() (Sutton & Barto, 1998),
U-Tree (McCallum, 1996) Active-LZ (Farias, Moallemi, Van Roy, & Weissman, 2010) employ
similar strategies.

6.6 Top-level Algorithm
time step, MC-AIXI(fac-ctw) first invokes UCT routine fixed horizon estimate value candidate action. action chosen according policy
balances exploration exploitation, -Greedy Softmax (Sutton & Barto, 1998).
action communicated environment, responds observation-reward pair.
agent incorporates information using FAC-CTW algorithm cycle repeats.
Figure 4 gives overview agent/environment interaction loop.
121

fiVeness, Ng, Hutter, Uther, & Silver

Domain
1d-maze
Cheese Maze
Tiger
Extended Tiger
4 4 Grid
TicTacToe
Biased Rock-Paper-Scissor
Kuhn Poker
Partially Observable Pacman

|A|
2
4
3
4
4
9
3
2
4

|O|
1
16
3
3
1
19683
3
6
216

Aliasing
yes
yes
yes
yes
yes


yes
yes

Noisy


yes
yes


yes
yes


Uninformative
yes



yes





Table 1: Domain characteristics

7. Experimental Results
measure agents performance across number dierent domains. particular,
focused learning solving well-known benchmark problems POMDP literature.
Given full POMDP model, computation optimal policy POMDPs
dicult. However, requirement learn model environment,
well find good policy online, significantly increases diculty problems.
agents perspective, domains contain perceptual aliasing, noise, partial information, inherent
stochastic elements.
7.1 Domains
test domains described. characteristics summarized Table 1.
1d-maze. 1d-maze simple problem work Cassandra, Kaelbling, Littman
(1994). agent begins random, non-goal location within 1 4 maze. choice
two actions: left right. action transfers agent adjacent cell exists, otherwise
eect. agent reaches third cell left, receives reward 1. Otherwise
receives reward 0. distinguishing feature problem observations
uninformative; every observation regardless agents actual location.
Cheese Maze. well known problem due McCallum (1996). agent mouse inside
two dimensional maze seeking piece cheese. agent choose one four actions:
move up, down, left right. agent bumps wall, receives penalty 10.
agent finds cheese, receives reward 10. movement free cell gives penalty
1. problem depicted graphically Figure 5. number cell represents
decimal equivalent four bit binary observation (0 free neighbouring cell, 1 wall)
mouse receives cell. problem exhibits perceptual aliasing single observation
potentially ambiguous.
Tiger. another familiar domain work Kaelbling, Littman, Cassandra
(1995). environment dynamics follows: tiger pot gold hidden behind
one two doors. Initially agent starts facing doors. agent choice one three
actions: listen, open left door, open right door. agent opens door hiding
122

fiA Monte-Carlo AIXI Approximation

Figure 5: cheese maze
tiger, suers -100 penalty. opens door pot gold, receives reward 10.
agent performs listen action, receives penalty 1 observation correctly
describes tiger 0.85 probability.
Extended Tiger. problem setting similar Tiger, except agent begins sitting
chair. actions available agent are: stand, listen, open left door, open
right door. agent successfully open one two doors, must stand up. However,
listen action provides information tigers whereabouts agent sitting
down. Thus necessary agent plan intricate series actions sees
optimal solution. reward structure slightly modified simple Tiger problem,
agent gets reward 30 finding pot gold.
4 4 Grid. agent restricted 4 4 grid world. move either up, down, right
left. agent moves bottom right corner, receives reward 1, randomly
teleported one remaining 15 cells. moves cell bottom right
corner cell, receives reward 0. agent attempts move non-existent cell,
remains location. Like 1d-maze, problem also uninformative much
larger scale. Although domain simple, require subtlety part agent.
correct action depends agent tried previous time steps. example,
agent repeatedly moved right received positive reward, chances
receiving positive reward moving increased.
TicTacToe. domain, agent plays repeated games TicTacToe opponent
moves randomly. agent wins game, receives reward 2. draw, agent
receives reward 1. loss penalises agent 2. agent makes illegal move,
moving top already filled square, receives reward 3. legal move
end game earns reward.
Biased Rock-Paper-Scissors. domain taken work Farias et al. (2010).
agent repeatedly plays Rock-Paper-Scissor opponent slight, predictable bias
strategy. opponent round playing rock previous cycle, always
play rock next cycle; otherwise pick action uniformly random. agents
observation recently chosen action opponent. receives reward 1 win,
0 draw 1 loss.
123

fiVeness, Ng, Hutter, Uther, & Silver

Kuhn Poker. next domain involves playing Kuhn Poker (Kuhn, 1950; Hoehn, Southey, Holte,
& Bulitko, 2005) opponent playing Nash strategy. Kuhn Poker simplified, zerosum, two player poker variant uses deck three cards: King, Queen Jack. Whilst
considerably less sophisticated popular poker variants Texas Holdem, well-known
strategic concepts blung slow-playing remain characteristic strong play.
setup, agent acts second series rounds. Two actions, pass bet, available
player. bet action requires player put extra chip play. beginning
round, player puts chip play. opponent decides whether pass bet;
betting win round agent subsequently passes, otherwise showdown occur.
showdown, player highest card wins round. opponent passes, agent
either bet pass; passing leads immediately showdown, whilst betting requires opponent
either bet force showdown, pass let agent win round uncontested. winner
round gains reward equal total chips play, loser receives penalty equal
number chips put play round. end round, chips removed
play another round begins.
Kuhn Poker known optimal solution. first player playing Nash strategy,
1
second player obtain average reward 18
per round.

Partially Observable Pacman. domain partially observable version classic Pacman game. agent must navigate 17 17 maze eat pills distributed across
maze. Four ghosts roam maze. move initially random, Manhattan
distance 5 Pacman, whereupon aggressively pursue Pacman
short duration. maze structure game original arcade game, however
Pacman agent hampered partial observability. Pacman unaware maze structure
receives 4-bit observation describing wall configuration current location. also
know exact location ghosts, receiving 4-bit observations indicating whether
ghost visible (via direct line sight) four cardinal directions. addition,
locations food pellets unknown except 3-bit observation indicates whether food
smelt within Manhattan distance 2, 3 4 Pacmans location, another 4-bit
observation indicating whether food direct line sight. final single bit indicates
whether Pacman eects power pill. start episode, food pellet
placed probability 0.5 every empty location grid. agent receives penalty
1 movement action, penalty 10 running wall, reward 10 food
pellet eaten, penalty 50 caught ghost, reward 100 collecting food.
multiple events occur, total reward cumulative, i.e. running wall
caught would give penalty 60. episode resets agent caught collects
food.
Figure 6 shows graphical representation partially observable Pacman domain.
problem largest domain consider, unknown optimal policy. main purpose
domain show scaling properties agent challenging problem. Note
domain fundamentally dierent Pacman domain used (Silver & Veness, 2010).
addition using dierent observation space, also assume true environment
known a-priori.
124

fiA Monte-Carlo AIXI Approximation

Figure 6: screenshot (converted black white) PacMan domain
7.2 Experimental Setup
evaluate performance MC-AIXI(fac-ctw) agent. help put results
perspective, implemented directly compared two competing algorithms
model-based general reinforcement learning literature: U-Tree (McCallum, 1996) Active-LZ
(Farias et al., 2010). two algorithms described page 133 Section 8. FAC-CTW
subsumes Action Conditional CTW, evaluate paper; results using Action Conditional CTW found previous work (Veness et al., 2010). performance agent
using FAC-CTW worse cases slightly better previous results.
agent communicates environment binary channel. cycle begins
agent sending action environment, responds percept x. cycle
repeated. fixed number bits used encode action, observation reward spaces
domain. specified Table 2. constraint placed agent interprets
observation component; e.g., could done either bit symbol level. rewards
encoded naively, i.e. bits corresponding reward interpreted unsigned integers.
Negative rewards handled (without loss generality) osetting rewards
guaranteed non-negative. osets removed reported results.
process gathering results three agents broken two phases: model
learning model evaluation. model learning phase involves running agent
exploratory policy build model environment. learnt model evaluated
various points time running agent without exploration 5000 cycles reporting
average reward per cycle. precisely, time average reward per cycle defined
1 t+5000
5000 i=t+1 ri , ri reward received cycle i. two separate phases reduces
influence agents earlier exploratory actions reported performance.
experiments performed dual quad-core Intel 2.53Ghz Xeon 24 gigabytes memory.
Table 3 outlines parameters used MC-AIXI(fac-ctw) model learning phase.
context depth parameter specifies maximal number recent bits used FAC-CTW.
UCT search horizon specified parameter m. Larger increase capabilities agent, expense linearly increasing computation time; values represent
125

fiVeness, Ng, Hutter, Uther, & Silver

Domain
1d-maze
Cheese Maze
Tiger
Extended Tiger
4 4 Grid
TicTacToe
Biased Rock-Paper-Scissor
Kuhn Poker
Partially Observable Pacman

bits
1
2
2
2
2
4
2
1
2

bits
1
4
2
3
1
18
2
4
16

R bits
1
5
7
8
1
3
2
3
8

Table 2: Binary encoding domains

Domain
1d-maze
Cheese Maze
Tiger
Extended Tiger
4 4 Grid
TicTacToe
Biased Rock-Paper-Scissor
Kuhn Poker
Partial Observable Pacman


32
96
96
96
96
64
32
42
96


10
8
5
4
12
9
4
2
4


0.9
0.999
0.99
0.99
0.9
0.9999
0.999
0.99
0.9999


0.99
0.9999
0.9999
0.99999
0.9999
0.999999
0.99999
0.9999
0.99999

UCT Simulations
500
500
500
500
500
500
500
500
500

Table 3: MC-AIXI(fac-ctw) model learning configuration

appropriate compromise two competing dimensions problem domain.
Exploration model learning phase controlled parameters. time t,
MC-AIXI(fac-ctw) explores random action probability . model evaluation
phase, exploration disabled, results recorded varying amounts experience
search eort.
Active-LZ algorithm fully specified work Farias et al. (2010). contains
two parameters, discount rate policy balances exploration exploitation.
model learning phase, discount rate 0.99 -Greedy exploration (with = 0.95)
used. Smaller exploration values (such 0.05, 0.2, 0.5) tried, well policies
decayed time, surprisingly gave slightly worse performance testing.
sanity check, confirmed implementation could reproduce experimental results
reported work Farias et al. (2010). model evaluation phase, exploration
disabled.
situation somewhat complicated U-Tree, general agent framework completely specified algorithm. Due absence publicly available reference
implementation, number implementation-specific decisions made. included
choice splitting criteria, far back time criteria could applied, frequency
126

fiA Monte-Carlo AIXI Approximation

Domain
1d-maze
Cheese Maze
Tiger
Extended Tiger
4 4 Grid
TicTacToe
Biased Rock-Paper-Scissor
Kuhn Poker


0.05
0.2
0.1
0.05
0.05
0.05
0.05
0.05

Test Fringe
100
100
100
200
100
1000
100
200


0.05
0.05
0.05
0.01
0.05
0.01
0.05
0.05

Table 4: U-Tree model learning configuration
fringe tests, choice p-value Kolmogorov-Smirnov test, exploration/exploitation
policy learning rate. main design decisions listed below:
split could made action, status single bit observation.
maximum number steps backwards time utile distinction could made
set 5.
frequency fringe tests maximised given realistic resource constraints. choices
allowed 5 104 cycles interaction completed domain within 2 days
training time.
Splits tried order temporally recent temporally distant.
-Greedy exploration strategy used, tuned separately domain.
learning rate tuned domain.
help make comparison fair possible, eort made tune U-Trees parameters
domain. final choices model learning phase summarised Table 4.
model evaluation phase, exploration testing fringe disabled.
Source Code. code U-Tree, Active-LZ MC-AIXI(fac-ctw) implementations
found at: http://jveness.info/software/mcaixi_jair_2010.zip.
7.3 Results
Figure 7 presents main set results. graph shows performance agent
accumulates experience. performance MC-AIXI(fac-ctw) matches exceeds U-Tree
Active-LZ test domains. Active-LZ steadily improved experience, however learnt significantly slowly U-Tree MC-AIXI(fac-ctw). U-Tree performed
well domains, however overhead testing splits limited ability run long
periods time. reason data points U-Tree missing graphs
Figure 7. highlights advantage algorithms take constant time per cycle,
MC-AIXI(fac-ctw) Active-LZ. Constant time isnt enough however, especially large
observation spaces involved. Active-LZ works symbol level, algorithm given
Farias et al. (2010) requiring exhaustive enumeration percept space cycle.
possible reasonable time larger TicTacToe domain, Active-LZ result
127

fiVeness, Ng, Hutter, Uther, & Silver

Domain
1d Maze
Cheese Maze
Tiger
Extended Tiger
4 4 Grid
TicTacToe
Biased RPS
Kuhn Poker

Experience
5 103
2.5 103
2.5 104
5 104
2.5 104
5 105
1 104
5 106

UCT Simulations
250
500
25000
25000
500
2500
5000
250

Search Time per Cycle
0.1s
0.5s
10.6s
12.6s
0.3s
4.1s
2.5s
0.1s

Table 5: Resources required (near) optimal performance MC-AIXI(fac-ctw)
presented. illustrates important advantage MC-AIXI(fac-ctw) U-Tree,
ability exploit structure within single observation.
Figure 8 shows performance MC-AIXI(fac-ctw) number UCT simulations
varies. results domain based model learnt 5 104 cycles experience,
except case TicTacToe 5 105 cycles used. results could compared
across domains, average reward per cycle normalised interval [0, 1]. expected,
domains included significant planning component (such Tiger Extended Tiger) required
search eort. Good performance domains obtained using 1000 simulations.
Given sucient number UCT simulations cycles interaction, performance
MC-AIXI(fac-ctw) agent approaches optimality test domains. amount resources
needed near optimal performance domain model evaluation phase listed
Table 5. Search times also reported. shows MC-AIXI(fac-ctw) agent
realistically used present day workstation.
7.4 Discussion
small state space induced U-Tree benefit limiting number parameters
need estimated data. dramatically speed model-learning process.
contrast, Active-LZ approach require number parameters proportional number distinct contexts. one reasons Active-LZ exhibits slow convergence
practice. problem much less pronounced approach two reasons. First, Ockham prior CTW ensures future predictions dominated PST structures seen
enough data trustworthy. Secondly, value function estimation decoupled process
context estimation. Thus reasonable expect UCT make good local decisions provided
FAC-CTW predict well. downside however approach requires search action
selection. Although UCT anytime algorithm, practice computation (at least small
domains) required per cycle compared approaches like Active-LZ U-Tree act greedily
respect estimated global value function.
U-Tree algorithm well motivated, unlike Active-LZ approach, lacks theoretical performance guarantees. possible U-Tree prematurely converge locally optimal
state representation heuristic splitting criterion never recover. Furthermore,
splitting heuristic contains number configuration options dramatically influence
performance (McCallum, 1996). parameter sensitivity somewhat limits algorithms
128

fiA Monte-Carlo AIXI Approximation

Learning Scalability - 1d Maze
MC-AIXI

U-Tree

Active-LZ

Learning Scalability - Cheese Maze
Optimal

MC-AIXI

U-Tree

0.5

0.4
0.3

0.2
0.1

100

0

-2
-4

-6
-8

1000

10000

100

100000

1000

U-Tree

Active-LZ

Optimal

MC-AIXI

U-Tree

Active-LZ

Optimal

10

5

0

Average Reward per Cycle

Average Reward per Cycle

100000

Learning Scalability - Extended Tiger

Learning Scalability - Tiger
MC-AIXI

10000

Experience (cycles)

Experience (cycles)

-5

-10
-15

-20
-25

-30

0

-10
-20

-30
-40
-50

100

1000

10000

100

100000

1000

Experience (cycles)

U-Tree

10000

100000

Experience (cycles)

Learning Scalability - TicTacToe

Learning Scalability - 4x4 Grid
MC-AIXI

Active-LZ

MC-AIXI

Optimal

U-Tree

Optimal

1
Average Reward per Cycle

0.3
Average Reward per Cycle

Optimal

-10

0

0.25
0.2
0.15

0.1
0.05

0.5

0
-0.5

-1
-1.5
-2

0
100

1000

10000

100

100000

1000

10000

Learning Scalability - Kuhn Poker
MC-AIXI

U-Tree

100000

1000000

Experience (cycles)

Experience (cycles)

Active-LZ

Learning Scalability - Rock-Paper-Scissors
Optimal

MC-AIXI

0.1

0.3

0.05

0.25

Average Reward per Cycle

Average Reward per Cycle

Active-LZ

2
Average Reward per Cycle

Average Reward per Cycle

0.6

0
-0.05
-0.1
-0.15
-0.2

U-Tree

Active-LZ

Optimal

0.2
0.15

0.1
0.05

0
-0.05

100

1000

10000

100000

1000000

100

Experience (cycles)

1000

10000
Experience (cycles)

Figure 7: Average Reward per Cycle vs Experience
129

100000

1000000

fiVeness, Ng, Hutter, Uther, & Silver

Normalised Average Reward per Cycle

Search Scalability
1
0.9
0.8
0.7

Optimal
Tiger
4x4 Grid
1d Maze
Extended Tiger
TicTacToe
Cheese Maze
Biased RPS
Kuhn Poker

0.6
0.5
0.4
0.3
0.2
0.1
0

25

250

2500

25000

Simulations

Figure 8: Performance versus UCT search eort

applicability general reinforcement learning problem. Still, results suggest
investigation frameworks motivated along lines U-Tree warranted.
7.5 Comparison 1-ply Rollout Planning
investigate performance UCT comparison adaptation well-known
1-ply rollout-based planning technique Bertsekas Castanon (1999). setting, works
follows: given history h, estimate V(ha) constructed action A, averaging
returns many length simulations initiated ha. first action simulation
sampled uniformly random A, whilst remaining actions selected according
heuristic rollout policy. sucient number simulations completed,
action highest estimated value selected. Unlike UCT, procedure doesnt build
tree, guaranteed converge depth expectimax solution. practice however,
especially noisy highly stochastic domains, rollout-based planning significantly improve
performance existing heuristic rollout policy (Bertsekas & Castanon, 1999).
Table 6 shows performance (given average reward per cycle) diers UCT
replaced 1-ply rollout planner. amount experience collected agent, well
total number rollout simulations, Table 5. UCT 1-ply planner
use search horizon, heuristic rollout policy (each action chosen uniformly random)
total number simulations decision. reasonable, since although UCT
slightly higher overhead compared 1-ply rollout planner, dierence negligible
taking account cost simulating future trajectories using FAC-CTW. Also, similar
previous experiments, 5000 cycles greedy action selection used evaluate performance
FAC-CTW + 1-ply rollout planning combination.
130

fiA Monte-Carlo AIXI Approximation

Domain
1d Maze
Cheese Maze
Tiger
Extended Tiger
4x4 Grid
TicTacToe
Biased RPS
Kuhn Poker

MC-AIXI(fac-ctw)
0.50
1.28
1.12
3.97
0.24
0.60
0.25
0.06

FAC-CTW + 1-ply MC
0.50
1.25
1.11
-0.97
0.24
0.59
0.20
0.06

Table 6: Average reward per cycle: UCT versus 1-ply rollout planning
Importantly, UCT never gives worse performance 1-ply rollout planner,
domains (shown bold) performs better. UCT algorithm provides way performing multistep planning whilst retaining considerable computational advantages rollout based methods.
particular, UCT able construct deep plans regions search space
probability mass concentrated small set possible percepts. structure
exists, UCT automatically exploit it. worst case environment highly noisy
stochastic, performance similar rollout based planning. Interestingly,
many domains empirical performance 1-ply rollout planning matched UCT.
believe byproduct modest set test domains, multi-step planning less
important learning accurate model environment.
7.6 Performance Challenging Domain
performance MC-AIXI(fac-ctw) also evaluated challenging Partially Observable
Pacman domain. enormous problem. Even true environment known, planning
would still dicult due 1060 distinct underlying states.
first evaluated performance MC-AIXI(fac-ctw) online. discounted -Greedy policy, chose random action time probability used. parameters
instantiated := 0.9999 := 0.99999. exploring, action determined
UCT using 500 simulations. Figure 10 shows average reward per cycle average
reward across recent 5000 cycles.
performance learnt model evaluated performing 5000 steps greedy
action selection, various time points, whilst varying number simulations used UCT.
Figure 9 shows obtained results. agents performance scales number cycles
interaction amount search eort. results Figure 9 using 500 simulations higher
Figure 10 since performance longer aected exploration policy earlier
behavior based inferior learnt model.
Visual inspection1 Pacman shows agent, whilst playing perfectly, already
learnt number important concepts. knows run walls. knows seek
food limited information provided sensors. knows run away avoid
chasing ghosts. main subtlety hasnt learnt yet aggressively chase ghosts
eaten red power pill. Also, behaviour sometimes become temporarily erratic
1. See http://jveness.info/publications/pacman_jair_2010.wmv graphical demonstration

131

fiVeness, Ng, Hutter, Uther, & Silver

Scaling Properties - Partially Observable Pacman
500 simulations

1000 simulations

2000 simulations

5000 simulations

Average Reward per Cycle

2
1
0
-1

-2
-3
-4

2500

25000

250000

Experience (cycles)

Figure 9: Scaling properties challenging domain
stuck long corridor nearby food visible ghosts. Still, ability perform
reasonably large domain exhibit consistent improvements makes us optimistic
ability MC-AIXI(fac-ctw) agent scale extra computational resources.

8. Discussion
discuss related work limitations current approach.
8.1 Related Work
several attempts studying computational properties AIXI. work
Hutter (2002a), asymptotically optimal algorithm proposed that, parallel, picks runs
fastest program enumeration provably correct programs given well-defined problem. similar construction runs programs length less l time less per cycle
picks best output (in sense maximising provable lower bound true value)
results optimal time bounded AIXItl agent (Hutter, 2005, Chp.7). Like Levin search (Levin,
1973), algorithms practical general cases applied successfully
(e.g., see Schmidhuber, 1997; Schmidhuber, Zhao, & Wiering, 1997; Schmidhuber, 2003, 2004).
tiny domains, universal learning computationally feasible brute-force search. work
Poland Hutter (2006), behaviour AIXI compared universal predicting-withexpert-advice algorithm (Poland & Hutter, 2005) repeated 2 2 matrix games shown
exhibit dierent behaviour. Monte-Carlo algorithm proposed Pankov (2008) samples
programs according algorithmic probability way approximating Solomonos universal prior. closely related algorithm speed prior sampling (Schmidhuber, 2002).
move discussion model-based general reinforcement learning literature.
early influential work Utile Sux Memory (USM) algorithm described McCallum
132

fiA Monte-Carlo AIXI Approximation

Online Performance - Partially Observable Pacman
Running Average

5k Rolling Average

2
0
-2
-4
-6
-8
-10
-12
-14
0

50000

100000

150000

200000

250000

Experience (Cycles)

Figure 10: Online performance challenging domain

(1996). USM uses sux tree partition agents history space distinct states, one
leaf sux tree. Associated state/leaf Q-value, updated incrementally
experience like Q-learning (Watkins & Dayan, 1992). history-partitioning sux tree
grown incremental fashion, starting single leaf node beginning. leaf
sux tree split history sequences fall leaf shown exhibit statistically
dierent Q-values. USM algorithm works well number tasks could deal effectively noisy environments. Several extensions USM deal noisy environments
investigated work Shani Brafman (2004) Shani (2007).
U-Tree (McCallum, 1996) online agent algorithm attempts discover compact
state representation raw stream experience. main dierence U-Tree
USM U-Tree discriminate individual components within observation.
allows U-Tree eectively handle larger observation spaces ignore potentially irrelevant
components observation vector. state represented leaf sux tree
maps history sequences states. experience gathered, state representation refined
according heuristic built around Kolmogorov-Smirnov test. heuristic tries limit
growth sux tree places would allow better prediction future reward. Value
Iteration used time step update value function learnt state representation,
used agent action selection.
Active-LZ (Farias et al., 2010) combines Lempel-Ziv based prediction scheme dynamic
programming control produce agent provably asymptotically optimal environment n-Markov. algorithm builds context tree (distinct context tree built CTW),
node containing accumulated transition statistics value function estimate. estimates refined time, allowing Active-LZ agent steadily increase performance.
Section 7, showed agent compared favourably Active-LZ.
BLHT algorithm (Suematsu, Hayashi, & Li, 1997; Suematsu & Hayashi, 1999) uses symbol
level PSTs learning (unspecified) dynamic programming based algorithm control.
BLHT uses probable model prediction, whereas use mixture model, admits
133

fiVeness, Ng, Hutter, Uther, & Silver

much stronger convergence result. distinction usage Ockham prior instead
uniform prior PST models.
Predictive state representations (PSRs) (Littman, Sutton, & Singh, 2002; Singh, James, &
Rudary, 2004; Rosencrantz, Gordon, & Thrun, 2004) maintain predictions future experience.
Formally, PSR probability distribution agents future experience, given past experience. subset predictions, core tests, provide sucient statistic future
experience. PSRs provide Markov state representation, represent track agents state
partially observable environments, provide complete model worlds dynamics. Unfortunately, exact representations state impractical large domains, form approximation typically required. Topics improved learning discovery algorithms PSRs
currently active areas research. recent results Boots, Siddiqi, Gordon (2010) appear
particularly promising.
Temporal-dierence networks (Sutton & Tanner, 2004) form predictive state representation agents state approximated abstract predictions. predictions
future observations, also predictions future predictions. set interconnected
predictions known question network. Temporal-dierence networks learn approximate
model worlds dynamics: given current predictions, agents action, observation
vector, provide new predictions next time-step. parameters model, known
answer network, updated time-step temporal-dierence learning.
promising recent results applying TD-Networks prediction (but control) small POMDPs
given (Makino, 2009).
model-based Bayesian Reinforcement Learning (Strens, 2000; Poupart, Vlassis, Hoey, &
Regan, 2006; Ross, Chaib-draa, & Pineau, 2008; Poupart & Vlassis, 2008), distribution
(PO)MDP parameters maintained. contrast, maintain exact Bayesian mixture PSTs,
variable-order Markov models. UCT algorithm shares similarities Bayesian
Sparse Sampling (Wang, Lizotte, Bowling, & Schuurmans, 2005). main dierences estimating leaf node values rollout function using UCB policy direct search.
8.2 Limitations
current AIXI approximation two main limitations.
first limitation restricted model class used learning prediction. agent
perform poorly underlying environment cannot predicted well PST bounded depth.
Prohibitive amounts experience required large PST model needed accurate
prediction. example, would unrealistic think current AIXI approximation could
cope real-world image audio data.
second limitation unless planning horizon unrealistically small, full
Bayesian solution (using UCT mixture environment model) exploration/exploitation
dilemma computationally intractable. agent needs augmented heuristic
exploration/exploitation policy practice. Although prevent agent obtaining
optimal performance test domains, better solution may required challenging
problems. MDP setting, considerable progress made towards resolving exploration/exploitation issue. particular, powerful PAC-MDP approaches exist model-based
model-free reinforcement learning agents (Brafman & Tennenholtz, 2003; Strehl, Li, Wiewiora,
134

fiA Monte-Carlo AIXI Approximation

Impact Learnt Rollouts - Cheese Maze
1

Average Reward per Cycle

0
-1
-2
-3
500 simulations - Learnt
-4

500 simulations - Uniform
100 simulations - Learnt

-5

100 simulations - Uniform
-6
100

1000

10000

100000

Experience (cycles)

Figure 11: Online performance using learnt rollout policy Cheese Maze

Langford, & Littman, 2006; Strehl, Li, & Littman, 2009). remains seen whether similar
principled approaches exist history-based Bayesian agents.

9. Future Scalability
list ideas make us optimistic future scalability approach.
9.1 Online Learning Rollout Policies UCT
important parameter UCT choice rollout policy. MCTS methods Computer
Go, well known search performance improved using knowledge-based rollout
policies (Gelly, Wang, Munos, & Teytaud, 2006). general agent setting, would thus
desirable gain benefits expert design online learning.
conducted preliminary experiments area. CTW-based method
used predict high-level actions chosen online UCT. learnt distribution replaced
previous uniformly random rollout policy. Figure 11 shows results using learnt rollout
policy cheese maze. domains tested exhibited similar behaviour. Although
work remains, clear even current simple learning scheme significantly improve
performance UCT.
Although first attempts promising, thorough investigation required.
likely rollout policy learning methods adversarial games, investigated
Silver Tesauro (2009), adapted setting. would also interesting try apply
form search bootstrapping (Veness, Silver, Uther, & Blair, 2009) online. addition, one
could also look ways modify UCB policy used UCT automatically take advantage
learnt rollout knowledge, similar heuristic techniques used computer Go (Gelly & Silver,
2007).
135

fiVeness, Ng, Hutter, Uther, & Silver

9.2 Combining Mixture Environment Models
key property mixture environment models composed. Given two mixture
environment models 1 2 , model classes M1 M2 respectively, easy show
convex combination
(x1:n | a1:n ) := 1 (x1:n | a1:n ) + (1 )2 (x1:n | a1:n )
mixture environment model union M1 M2 . Thus principled way
expanding general predictive power agents use kind direct AIXI approximation.
9.3 Richer Notions Context FAC-CTW
Instead using recent bits current history h, FAC-CTW algorithm
generalised use set boolean functions h define current context. formalise
notion, give examples might help agent applications.
Definition 12. Let P = {p0 , p1 , . . . , pm } set predicates (boolean functions) histories
h (AX)n , n 0. P-model binary tree internal node labeled predicate
P left right outgoing edges node labeled True False respectively.
P-tree pair (MP , ) MP P-model associated leaf node l MP
probability distribution {0, 1} parametrised l .
P-tree (MP , ) represents function g histories probability distributions {0, 1}
usual way. history h, g(h) = lh , lh leaf node reached pushing h
model MP according whether satisfies predicates internal nodes lh
distribution lh . notion P-context tree specified, leading natural
generalisation Definition 8.
Action-Conditional CTW FAC-CTW algorithms generalised work
P-context trees natural way. Importantly, result analogous Lemma 2 established,
means desirable computational properties CTW retained. provides
powerful way extending notion context agent applications. example, suitable choice predicate class P, prediction sux trees (Definition 7) looping sux trees
(Holmes & Jr, 2006) represented P-trees. also opens possibility using rich
logical tree models (Blockeel & De Raedt, 1998; Kramer & Widmer, 2001; Lloyd, 2003; Ng, 2005;
Lloyd & Ng, 2007) place prediction sux trees.
9.4 Incorporating CTW Extensions
several noteworthy ways original CTW algorithm extended. finite depth
limit context tree removed (Willems, 1998), without increasing asymptotic space
overhead algorithm. Although increases worst-case time complexity generating
symbol O(D) linear length history, average-case performance may still
sucient good performance agent setting. Furthermore, three additional model classes,
significantly larger one used CTW, presented work Willems, Shtarkov,
Tjalkens (1996). could made action conditional along lines FAC-CTW
derivation. Unfortunately, online prediction general classes exponential
context depth D. Investigating whether ideas applied restricted sense
would interesting direction future research.
136

fiA Monte-Carlo AIXI Approximation

9.5 Parallelization UCT
performance agent dependent amount thinking time allowed time
step. important property UCT naturally parallel. completed prototype
parallel implementation UCT promising scaling results using 4 8 processing
cores. confident improvements implementation allow us solve
problems agents planning ability main limitation.
9.6 Predicting Multiple Levels Abstraction
FAC-CTW algorithm reduces task predicting single percept prediction
binary representation. Whilst reasonable first attempt AIXI approximation, worth
emphasising subsequent attempts need work exclusively low level.
example, recall FAC-CTW algorithm obtained chaining together lX actionconditional binary predictors. would straightforward apply similar technique chain
together multiple k-bit action-conditional predictors, k > 1. k bits could interpreted
many ways: e.g. integers, floating point numbers, ASCII characters even pixels. observation, along convenient property mixture environment models composed, opens
possibility constructing sophisticated, hierarchical mixture environment models.

10. Conclusion
paper presents first computationally feasible general reinforcement learning agent directly scalably approximates AIXI ideal. Although well established theoretically,
previously unclear whether AIXI theory could inspire design practical agent algorithms. work answers question armative: empirically, approximation achieves
strong performance theoretically, characterise range environments
agent expected perform well.
develop approximation, introduced two new algorithms: UCT, Monte-Carlo expectimax approximation technique used online Bayesian approach general reinforcement learning problem FAC-CTW, generalisation powerful CTW algorithm agent setting. addition, highlighted number interesting research directions
could improve performance current agent; particular, model class expansion
online learning heuristic rollout policies UCT.
hope work generates interest broader artificial intelligence community AIXI theory general reinforcement learning agents.

Acknowledgments
authors thank Alan Blair, Thomas Degris-Dard, Evan Greensmith, Bernhard Hengst, Ramana
Kumar, John Lloyd, Hassan Mahmud, Malcolm Ryan, Scott Sanner, Rich Sutton, Eric Wiewiora,
Frans Willems anonymous reviewers helpful comments feedback. work received support Australian Research Council grant DP0988049. NICTA funded
Australian Governments Department Communications, Information Technology,
Arts Australian Research Council Backing Australias Ability ICT Research
Centre Excellence programs.
137

fiVeness, Ng, Hutter, Uther, & Silver

References
Auer, P. (2002). Using confidence bounds exploitation-exploration trade-os. Journal Machine Learning Research, 3, 397422.
Begleiter, R., El-Yaniv, R., & Yona, G. (2004). prediction using variable order Markov models.
Journal Artificial Intelligence Research, 22, 385421.
Bertsekas, D. P., & Castanon, D. A. (1999). Rollout algorithms stochastic scheduling problems.
Journal Heuristics, 5(1), 89108.
Blockeel, H., & De Raedt, L. (1998). Top-down induction first-order logical decision trees.
Artificial Intelligence, 101(1-2), 285297.
Boots, B., Siddiqi, S. M., & Gordon, G. J. (2010). Closing learning-planning loop predictive state representations. Proceedings 9th International Conference Autonomous
Agents Multiagent Systems: volume 1 - Volume 1, AAMAS 10, pp. 13691370 Richland,
SC. International Foundation Autonomous Agents Multiagent Systems.
Brafman, R. I., & Tennenholtz, M. (2003). R-max - general polynomial time algorithm nearoptimal reinforcement learning. Journal Machine Learning Research, 3, 213231.
Cassandra, A. R., Kaelbling, L. P., & Littman, M. L. (1994). Acting optimally partially observable
stochastic domains. AAAI, pp. 10231028.
Chaslot, G.-B., Winands, M., Uiterwijk, J., van den Herik, H., & Bouzy, B. (2008a). Progressive
strategies Monte-Carlo Tree Search. New Mathematics Natural Computation, 4(3),
343357.
Chaslot, G. M., Winands, M. H., & Herik, H. J. (2008b). Parallel monte-carlo tree search.
Proceedings 6th International Conference Computers Games, pp. 6071 Berlin,
Heidelberg. Springer-Verlag.
Cover, T. M., & Thomas, J. A. (1991). Elements information theory. Wiley-Interscience, New
York, NY, USA.
Farias, V., Moallemi, C., Van Roy, B., & Weissman, T. (2010). Universal reinforcement learning.
Information Theory, IEEE Transactions on, 56(5), 2441 2454.
Finnsson, H., & Bjornsson, Y. (2008). Simulation-based approach general game playing.
AAAI, pp. 259264.
Gelly, S., & Silver, D. (2007). Combining online oine learning UCT. Proceedings
17th International Conference Machine Learning, pp. 273280.
Gelly, S., & Wang, Y. (2006). Exploration exploitation Go: UCT Monte-Carlo Go. NIPS
Workshop On-line trading Exploration Exploitation.
Gelly, S., Wang, Y., Munos, R., & Teytaud, O. (2006). Modification UCT patterns
Monte-Carlo Go. Tech. rep. 6062, INRIA, France.
138

fiA Monte-Carlo AIXI Approximation

Hoehn, B., Southey, F., Holte, R. C., & Bulitko, V. (2005). Eective short-term opponent exploitation simplified poker. AAAI, pp. 783788.
Holmes, M. P., & Jr, C. L. I. (2006). Looping sux tree-based inference partially observable
hidden state. ICML, pp. 409416.
Hutter, M. (2002a). fastest shortest algorithm well-defined problems. International
Journal Foundations Computer Science., 13(3), 431443.
Hutter, M. (2002b). Self-optimizing Pareto-optimal policies general environments based
Bayes-mixtures. Proceedings 15th Annual Conference Computational Learning
Theory (COLT 2002), Lecture Notes Artificial Intelligence. Springer.
Hutter, M. (2005). Universal Artificial Intelligence: Sequential Decisions Based Algorithmic
Probability. Springer.
Hutter, M. (2007). Universal algorithmic intelligence: mathematical topdown approach.
Artificial General Intelligence, pp. 227290. Springer, Berlin.
Kaelbling, L. P., Littman, M. L., & Cassandra, A. R. (1995). Planning acting partially
observable stochastic domains. Artificial Intelligence, 101, 99134.
Kocsis, L., & Szepesvari, C. (2006). Bandit based Monte-Carlo planning. ECML, pp. 282293.
Kramer, S., & Widmer, G. (2001). Inducing classification regression trees first order logic.
Dzeroski, S., & Lavrac, N. (Eds.), Relational Data Mining, chap. 6. Springer.
Krichevsky, R., & Trofimov, V. (1981). performance universal coding. IEEE Transactions
Information Theory, IT-27, 199207.
Kuhn, H. W. (1950). simplified two-person poker. Contributions Theory Games, pp.
97103.
Legg, S., & Hutter, M. (2004). Ergodic MDPs admit self-optimising policies. Tech. rep. IDSIA-2104, Dalle Molle Institute Artificial Intelligence (IDSIA).
Legg, S. (2008). Machine Super Intelligence. Ph.D. thesis, Department Informatics, University
Lugano.
Levin, L. A. (1973). Universal sequential search problems. Problems Information Transmission,
9, 265266.
Li, M., & Vitanyi, P. (2008). Introduction Kolmogorov Complexity Applications (Third
edition). Springer.
Littman, M., Sutton, R., & Singh, S. (2002). Predictive representations state. NIPS, pp.
15551561.
Lloyd, J. W. (2003). Logic Learning: Learning Comprehensible Theories Structured Data.
Springer.
139

fiVeness, Ng, Hutter, Uther, & Silver

Lloyd, J. W., & Ng, K. S. (2007). Learning modal theories. Proceedings 16th International
Conference Inductive Logic Programming, LNAI 4455, pp. 320334.
Makino, T. (2009). Proto-predictive representation states simple recurrent temporaldierence networks. ICML, pp. 697704.
McCallum, A. K. (1996). Reinforcement Learning Selective Perception Hidden State.
Ph.D. thesis, University Rochester.
Ng, K. S. (2005). Learning Comprehensible Theories Structured Data. Ph.D. thesis,
Australian National University.
Pankov, S. (2008). computational approximation AIXI model. AGI, pp. 256267.
Poland, J., & Hutter, M. (2005). Defensive universal learning experts. Proc. 16th International Conf. Algorithmic Learning Theory, Vol. LNAI 3734, pp. 356370. Springer.
Poland, J., & Hutter, M. (2006). Universal learning repeated matrix games. Tech. rep. 18-05,
IDSIA.
Poupart, P., & Vlassis, N. (2008). Model-based bayesian reinforcement learning partially observable domains. ISAIM.
Poupart, P., Vlassis, N., Hoey, J., & Regan, K. (2006). analytic solution discrete bayesian
reinforcement learning. ICML 06: Proceedings 23rd international conference
Machine learning, pp. 697704 New York, NY, USA. ACM.
Rissanen, J. (1983). universal data compression system. IEEE Transactions Information
Theory, 29(5), 656663.
Ron, D., Singer, Y., & Tishby, N. (1996). power amnesia: Learning probabilistic automata
variable memory length. Machine Learning, 25(2), 117150.
Rosencrantz, M., Gordon, G., & Thrun, S. (2004). Learning low dimensional predictive representations. Proceedings twenty-first International Conference Machine Learning,
p. 88 New York, NY, USA. ACM.
Ross, S., Chaib-draa, B., & Pineau, J. (2008). Bayes-adaptive POMDPs. Platt, J., Koller, D.,
Singer, Y., & Roweis, S. (Eds.), Advances Neural Information Processing Systems 20, pp.
12251232. MIT Press, Cambridge, MA.
Schmidhuber, J., Zhao, J., & Wiering, M. A. (1997). Shifting inductive bias success-story
algorithm, adaptive Levin search, incremental self-improvement. Machine Learning, 28,
105130.
Schmidhuber, J. (1997). Discovering neural nets low Kolmogorov complexity high generalization capability. Neural Networks, 10(5), 857873.
Schmidhuber, J. (2002). speed prior: new simplicity measure yielding near-optimal computable predictions. Proc. 15th Annual Conf. Computational Learning Theory, pp.
216228.
140

fiA Monte-Carlo AIXI Approximation

Schmidhuber, J. (2003). Bias-optimal incremental problem solving. Advances Neural Information Processing Systems 15, pp. 15711578. MIT Press.
Schmidhuber, J. (2004). Optimal ordered problem solver. Machine Learning, 54, 211254.
Shani, G. (2007). Learning Solving Partially Observable Markov Decision Processes. Ph.D.
thesis, Ben-Gurion University Negev.
Shani, G., & Brafman, R. (2004). Resolving perceptual aliasing presence noisy sensors.
NIPS.
Silver, D., & Tesauro, G. (2009). Monte-carlo simulation balancing. ICML 09: Proceedings
26th Annual International Conference Machine Learning, pp. 945952 New York,
NY, USA. ACM.
Silver, D., & Veness, J. (2010). Monte-Carlo Planning Large POMDPs. Advances Neural
Information Processing Systems (NIPS). appear.
Singh, S., James, M., & Rudary, M. (2004). Predictive state representations: new theory
modeling dynamical systems. UAI, pp. 512519.
Solomono, R. J. (1964). formal theory inductive inference: Parts 1 2. Information
Control, 7, 122 224254.
Strehl, A. L., Li, L., & Littman, M. L. (2009). Reinforcement learning finite MDPs: PAC analysis.
Journal Machine Learning Research, 10, 24132444.
Strehl, A. L., Li, L., Wiewiora, E., Langford, J., & Littman, M. L. (2006). PAC model-free reinforcement learning. ICML 06: Proceedings 23rd international conference
Machine learning, pp. 881888 New York, NY, USA. ACM.
Strens, M. (2000). Bayesian framework reinforcement learning. ICML, pp. 943950.
Suematsu, N., & Hayashi, A. (1999). reinforcement learning algorithm partially observable
environments using short-term memory. NIPS, pp. 10591065.
Suematsu, N., Hayashi, A., & Li, S. (1997). Bayesian approach model learning nonMarkovian environment. ICML, pp. 349357.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press.
Sutton, R. S., & Tanner, B. (2004). Temporal-dierence networks. NIPS.
Tjalkens, T. J., Shtarkov, Y. M., & Willems, F. M. J. (1993). Context tree weighting: Multi-alphabet
sources. Proceedings 14th Symposium Information Theory Benelux.
Veness, J., Ng, K. S., Hutter, M., & Silver, D. (2010). Reinforcement Learning via AIXI Approximation. Proceedings Conference Association Advancement
Artificial Intelligence (AAAI).
Veness, J., Silver, D., Uther, W., & Blair, A. (2009). Bootstrapping Game Tree Search.
Neural Information Processing Systems (NIPS).
141

fiVeness, Ng, Hutter, Uther, & Silver

Wang, T., Lizotte, D. J., Bowling, M. H., & Schuurmans, D. (2005). Bayesian sparse sampling
on-line reward optimization. ICML, pp. 956963.
Watkins, C., & Dayan, P. (1992). Q-learning. Machine Learning, 8, 279292.
Willems, F., Shtarkov, Y., & Tjalkens, T. (1997). Reflections Context Tree Weighting
Method: Basic properties. Newsletter IEEE Information Theory Society, 47(1).
Willems, F. M. J. (1998). context-tree weighting method: Extensions. IEEE Transactions
Information Theory, 44, 792798.
Willems, F. M. J., Shtarkov, Y. M., & Tjalkens, T. J. (1996). Context weighting general finitecontext sources. IEEE Trans. Inform. Theory, 42, 421514.
Willems, F. M., Shtarkov, Y. M., & Tjalkens, T. J. (1995). context tree weighting method: Basic
properties. IEEE Transactions Information Theory, 41, 653664.

142

fiJournal Artificial Intelligence Research 40 (2011) 25-56

Submitted 06/10; published 01/11

Logical Study Partial Entailment
Yi Zhou
Yan Zhang

yzhou@scm.uws.edu.au
yan@scm.uws.edu.au

Intelligent Systems Laboratory
School Computing Mathematics
University Western Sydney, NSW, Australia

Abstract
introduce novel logical notionpartial entailmentto propositional logic. contrast classical entailment, formula P partially entails another formula Q
respect background formula set intuitively means circumstance ,
P true part Q also true. distinguish three different kinds
partial entailments formalize using extended notion prime implicant.
study semantic properties, show that, surprisingly, partial entailments fail
many simple inference rules. Then, study related computational properties,
indicate partial entailments relatively difficult computed. Finally,
consider potential application partial entailments reasoning rational agents.

1. Introduction
standard propositional logic, classical entailment distinguish among formulas
entail another formula. example, let x, z three atoms.
neither x z classically entails x y. However, x seems intuitively closer x
z. reason that, x considered union two parts x y,
x exactly one them. hand, z completely irrelevant x y.
example motivates us consider notion partial entailment. comparison classical entailment, partial entailment intends capture partial satisfaction
relationship two formulas respect background theory. standard propositional logic, formula P entails another formula Q respect formula set
intuitively means circumstance , P true Q also true.
contrast, formula P partially entails another formula Q respect formula set
intuitively means that, circumstance , P true part Q
also true. Partial entailment widely used everyday life. example, suppose
student Laura wants get score HD subjects mathematics physics
final examination. cannot achieve them, could also satisfied
achieve one them. least, better achieving none.
Let us consider example. Suppose background formula set empty
objective formula x y. Consider following four formulas: x, x z, x
z. Clearly, none formulas classically entails x y. However, x, x z x
entail x, regarded part x y. contrast, z irrelevant x y. Thus,
one conclude that, extent, x, x z x partially satisfy x z
not.
c
2011
AI Access Foundation. rights reserved.

fiZhou & Zhang

One may observe exists difference x x z partially
satisfying x y. is, x z contains new atom z, irrelevant x y.
hand, x exactly part x y. words, x z contains irrelevancy
(namely z) partially satisfying x x not. Another observation
x y. Although entails x (a part x y), also entails y, contradicts
(also part x y). words, x side effect (namely y) besides
partially satisfying x y.
background theory crucial partial entailment. example, consider z
x again. Suppose background formula set empty. case, z
partially satisfy x y. background formula set turns {z x}, z
partially satisfy x since background theory, z holds, x holds well.
Based observations intuitions, paper, formalize notion partial entailment two formulas respect background theory
propositional language. Moreover, distinguish three different kinds partial entailments, namely weak partial entailment, partial entailment strong partial entailment.
intuitions summarized Table 1. course, require partial
satisfaction two formulas. However, weak partial entailment may allow
irrelevancies side effects, whilst partial entailment prohibits side effects still may
allow irrelevancies, strong partial entailment strongest one prohibits
irrelevancies.
Table 1: Intuitions partial entailments
weak partial entailment
partial entailment
strong partial entailment

partial satisfaction
yes
yes
yes

irrelevancy
allowed
allowed


side effect
allowed



paper organized follows. next section, formalize three different kinds
partial entailments using extended notion prime implicant, discuss
semantic properties. Section 3, focus computational complexities decision
problems relation prime implicant partial entailments, ranging special
cases general case. compare notion partial entailments
related notions AI literature Section 4. Section 5, show notions
partial entailments applied formalize partial goal satisfaction reasoning
rational agents. Finally, draw conclusions Section 6.

2. Partial Entailment
restrict discussions within propositional language, denoted L. Formulas L
composed recursively finite set Atom atoms (also called variables) {>, }
standard connectives . connectives , , defined usual. Literals
atoms negations. use lower case letters denote atoms literals, upper
case letters denote formulas, lower Greek letters denote literal sets, upper Greek
26

fiA Logical Study Partial Entailment

letters denote formula sets respectively. write l denote complementary literal
literal l, denote set complementary literals literals . write
Atom(l), Atom(P ), Atom() Atom() denote sets atoms occurring literal
l, formula P , literal set formula set respectively.
say literal set assignment set atoms (assignment
short = Atom) atom x A, exactly one x x . Notice
literal l assignment also considered formulas. convenience,
henceforth, l also denote corresponding formulas clear
context. entailment relation |= notion model defined standard
way. set formulas said consistent least one model, otherwise,
said inconsistent. theory set formulas closed |=. Let set
formulas. deductive closure , denoted h(), minimal theory (in sense
set inclusion) containing . convenience, also use denote theory
h() clear context.
write P |l denote formula obtained P simultaneously replacing every
occurrence x > () l form x (x). consistent literal set (i.e.
6 x Atom s.t. x x ), = {l1 , l2 , ..., lk }, write P | denote
formula (((P |l1 )|l2 )|...)|lk .
2.1 Simple Case
begin define notions partial entailments two formulas respect
background formula set considering rather simple case. is, two
formulas consistent conjunctions literals background formula set assumed
empty.
Definition 1 Let 0 two consistent sets literals.
say weakly partially entails 0 0 6= .
say partially entails 0 0 6= 0 = .
say strongly partially entails 0 0 .
Definition 1 simply follows intuitions presented introduction section (see
Table 1). simple case, 0 consistent set literals. Thus, parts 0
regarded elements (or subsets) 0 . Recall intuitive sense partial
satisfaction. is, holds, parts 0 hold well. means
exists part 0 , subset . Clearly, precisely captured
0 6= , exactly definition weak partial entailment simple case.
partial entailment, forbid side effects based partial satisfaction. Again, since 0
consistent set literals, side effects 0 regarded complementary
literal elements (or subsets) 0 . Hence, side effects 0 means
mention complementary literal elements (or subsets) 0 . Clearly,
precisely captured 0 = , 0 set complementary literals
elements 0 . Together 0 6= , forms definition partial entailment
simple case.
27

fiZhou & Zhang

Finally, consider strong partial entailment. require additionally
irrelevancy. irrelevancies 0 considered atoms (or literals)
mentioned 0 . Hence, irrelevancy 0 means atom
(or literal) mentioned 0 . Formally, precisely captured
Atom() Atom( 0 ) (or 0 ). Whatever case is, together two conditions
0 6= 0 = , equivalent 0 6= , definition
strong partial entailment simple case.
Example 1 Recall example proposed introduction section. According Definition 1, easy check x, x x z weakly partially entail x z
not; x x z partially entail x x z not; x strongly partially
entails x x y, x z z not. results coincide intuitions
observations discussed introduction section.
Comparing weak partial entailment partial entailment, one may observe x
weakly partially entails xy partially entail xy. discussed,
side effect x y. Comparing partial entailment strong partial entailment,
one may observe x z partially entails x strongly partially entail
x y. Again, coincides discussions since z irrelevancy x y. 2
interesting phenomenon relationships partial entailments
classical entailment. simple case, easy see classically entails 0 ,
partially entails 0 . Also, weakly partially entails 0 . means classical
entailment special case (weak) partial entailment extent. However,
hold strong partial entailment. instance, x classically entails x,
strongly partially entail x since irrelevancy respect x.
first glance, seems result strange sense term partial
entailment generalization classical entailment. However, mean
classical entailment also prohibits side effects irrelevancies. Thus, intuitive
sense, one conclude classical entailment special case weak
partial entailment, may mutually different partial entailment strong partial
entailment. Interestingly, show later, classical entailment indeed prohibits side
effects. means classical entailment special case partial entailment well.
However, classical entailment may allow irrelevancy (e.g., x classically entails x
irrelevancy x). Hence, roughly speaking, classical entailment special case
partial entailment weak partial entailment, classical entailment strong partial
entailment mutually different.
Definition 1 gives basic impression notions partial entailments.
following, consider extend three notions partial entailments general sense,
two formulas arbitrary formulas background arbitrary set
formulas.
2.2 Prime Implicant
order define partial entailments general case, use Quines notion prime implicant (Quine, 1952), widely used many areas logic computer
28

fiA Logical Study Partial Entailment

science. excellent survey prime implicant dual prime implicate due
Marquis (2000).
Roughly speaking, prime implicant formula minimal set (in sense
set inclusion) literals entails formula. notion prime implicant
relativized respect background formula set follows.
Definition 2 (Relativized prime implicant) literal set prime implicant
formula P respect formula set if:
1. consistent.
2. |= P .
3. exist literal set 0 satisfies two conditions.
set prime implicants P respect denoted P I(, P ). convenience, omit empty.
Intuitively, prime implicant P w.r.t. minimal set information needed
order satisfy P circumstance . Condition 1 requires set information feasible, i.e., must consistent background formula set. Condition
2 means set information implicant, i.e., indeed powerful enough
satisfy P w.r.t. . Finally, condition 3 requires set information prime, i.e.,
minimal set information satisfying P w.r.t. .
Example 2 According Definition 2, prime implicant x {x, y},
x two prime implicants, namely {x} {y}. background formula set indeed
plays important role. Clearly, x unique prime implicant {x}. However, {y} also
prime implicant x respect background formula set {y x}. 2
well known relativized notion prime implicant similar notion
logic-based abduction (Eiter & Gottlob, 1995; Selman & Levesque, 1990; Eiter & Makino,
2007). different characterizations abduction literature. Here, consider
one well-studied forms (Selman & Levesque, 1990; Eiter & Makino, 2007).
Definition 3 (Selman & Levesque, 1990) Let theory, F formula H set
literals. (abductive) explanation F respect H minimal set
H that:
1. consistent,
2. |= F .
Following definitions, observed relativized notion prime
implicant abduction simply transformed other. precisely, suppose
theory, F formula H set literals. Let Lit set literals
language. Then, prime implicant F w.r.t. iff abductive explanation
F respect Lit. Conversely, abductive explanation F respect
H iff prime implicant F w.r.t. mentions literals H.
29

fiZhou & Zhang

Another closely related notion prime implicant dual, called prime implicate,
also interests many areas well. Roughly speaking, prime implicate
propositional formula P minimal clause (i.e., disjunction literals) entailed P .
easy see conjunction set literals prime implicant formula
P disjunction complementary literals elements
prime implicate P . Prime implicate also relativized background formula
set well (Marquis, 2000). omit definition since mainly focused prime
implicant paper.
Many properties relation prime implicate discussed summarized Marquis (2000). surprisingly, similar results hold prime implicant well.
following, recall important properties relation relativized notion
prime implicant, used later paper.
Proposition 1 Let finite set formulas, P formula set literals.
V
prime implicant P w.r.t. iff consistent prime implicant P ,
V
conjunction formulas .
Proposition 2 Let P formula, set formulas literal set
consistent |= P . exists 0 0 prime implicant
P respect .
Proposition 3 Let P formula, formula set literal set. prime
implicant P w.r.t. , exists assignment 0 0 0
model P .
Together Proposition 2, Proposition 3 indicates correspondence relationship
models P w.r.t. prime implicants P w.r.t. . Suppose
model P consistent . Then, according Proposition 2,
exists subset , prime implicant P w.r.t. . Conversely, according
Proposition 3, every prime implicant P w.r.t. extended model
P .
Proposition 4 Let P formula set formulas. |= P
P I(, P ) = ; |= P P I(, P ) = {}.
Proposition 5 Let P Q two formulas set formulas. |= P Q iff
P I(, P ) = P I(, Q).
conclude, prime implicants formula P w.r.t. formula set play two roles.
Cases: one hand, exists assignment satisfying P , according
Proposition 2, exists subset prime implicant P w.r.t. .
hand, prime implicant P w.r.t. , according Proposition
3, extended assignment satisfying P . means
prime implicants P w.r.t. corresponding possible worlds (assignments)
satisfying P . Intuitively, corresponding cases
make P true w.r.t. , i.e., ways achieve P .
30

fiA Logical Study Partial Entailment

Parts: Suppose prime implicant P w.r.t. l literal . Then,
|= P \{l} 6|= P . mentioned above, considered way
(case) achieve P w.r.t. . Then, intuitively, l plays essential role achieving
P w.r.t. via . Without l, longer way achieve P . shows
elements essential. words, minimal way achieve
P , none elements thrown away. Thus, literals
considered parts P w.r.t. .
roles prime implicants exploited notions partial entailments
introduced following.
2.3 Definitions Partial Entailments
Based notion prime implicant, formalize three kinds partial entailments.
weakest strongest, weak partial entailment, partial entailment
strong partial entailment respectively.
Definition 4 (Weak partial entailment) formula P weakly partially entails formula Q respect formula set , denoted P W
Q, if:
1. P I(, P ) empty.
2. P I(, P ), exists 0 P I(, Q), 0 6= .
Definition 5 (Partial entailment) formula P partially entails formula Q respect formula set , denoted P Q, if:
1. P I(, P ) empty.
2. P I(, P ), exists 0 P I(, Q), 0 6= 0 =
.
Definition 6 (Strong partial entailment) formula P strongly partially entails formula Q respect formula set , denoted P Q, if:
1. P I(, P ) empty.
2. P I(, P ), exists 0 P I(, Q), 0 .
W
write P 6W
Q case P Q, similar partial entailment
strong partial entailment. convenience, omit empty.
Clearly, definitions generalizations Definition 1 proposed Section 2.1 since
unique prime implicant literal set itself. Note difference among
definitions partial entailments indeed presented Section 2.1 simple case.
Definitions 4-6 require literal set P I(, P ), exists literal
set P I(, Q) two literal sets satisfy corresponding relationships
presented Definition 1 respectively.
Let us take closer look condition 2 Definition 4. Recall intuitive sense
partial satisfaction again, is, P true , parts Q hold well.

31

fiZhou & Zhang

discussed Section 2.2, prime implicants P w.r.t. represent cases
make P true . Also, prime implicants Q w.r.t. capture idea
part Q . Hence, condition 2 means that, intuitively, cases
P true (captured prime implicants P w.r.t. ), exists
way achieve Q (captured prime implicant Q w.r.t. ),
former partially satisfies latter (reduced simple case Definition 1). addition,
condition 1 Definition 4 ensures exists least one situation. intuitive
senses Definitions 5 6 explained similar way.
Example 3 Let background theory {x y, z y}. Consider two formulas P =
(x r) (y s) Q = (x z) (x s). prime implicants P w.r.t.
follows: {x, r}, {y, s}, {r, s}, {z, s}, {y, r} {x, s}. Notice {y, r} prime
implicant P w.r.t. although literal even occur P .
hand, prime implicants Q w.r.t. follows: {x, z}, {x, s} {z, s}. Notice
{x, y, s} prime implicant Q w.r.t. since {x, s} subset also
satisfies Q .
According definitions, P weakly partially entail Q w.r.t.
since prime implicant {y, r} P w.r.t. intersection
prime implicants Q w.r.t. . Also, P (strongly) partially entail
Q w.r.t. either. Conversely, Q (weakly) partially entails P w.r.t. , whilst
strongly partially entail P w.r.t. . 2
Note possible relations two formulas w.r.t. background
formula set using extended notion prime implicant. paper, defining
partial entailments, use style definition sense require
literal sets P I(, P ), exists literal set P I(, Q) two literal
sets satisfy conditions Definition 1 respectively. Recall intuition partial
entailments, requires cases, P true context ,
part Q true context . naturally suggests style definition
definitions partial entailments (i.e. Definitions 4-6), -part captures
cases achieving P context , -part associates possibility
achieving Q context case P . addition, condition
item 2 Definitions 4-6 ensures that, case, P partially achieves Q w.r.t. via
two literal sets.
reason choose style definition partial entailments also
explained analogously classical entailment. Note formula P classically entails
another formula Q w.r.t. background theory iff models P w.r.t. , also
model Q w.r.t. .
Certainly, possible styles, including , . instance,
style definition weakest case be: exists P I(, P )
0 P I(, Q), 0 6= . Although definitions might interesting useful
elsewhere, fail capture basic idea partial satisfaction.
Example 4 Consider two formulas x z x y. former two prime implicants,
namely {x} {z}, latter unique prime implicant, namely {x, y}.
use style definition, x z (weakly, strongly) partially entails x y. However,
32

fiA Logical Study Partial Entailment

intuitive {z} achieves x z true irrelevant x y.
words, assignment {x, y, z} satisfies x z x y. Hence, exists case
x z true none parts x true.
Consider formula x y, two prime implicants, {x} {y}. take
style definition one, formula (weakly, strongly) partially entail
itself. obviously intuitive. 2
Another feasible direction definitions switch formulas P Q. instance,
switched- style definition weakest case is: P I(, Q), exists
0 P I(, P ) 0 6= . definition, corresponding switched-,
style definitions, fail capture basic idea partial satisfaction either. Again,
recall intuition partial entailments. is, P true (under context ),
part Q true well (under context ). Similar classical entailment,
naturally suggests order P Q definitions partial entailments. Also,
switched- (switched-) style definition () style definition.
shown Example 4, suitable defining notions partial entailments.
understand switched- style switched- style definitions fail capturing
partial entailments, let us consider following example.
Example 5 Consider two formulas x x. former two prime implicants,
namely {x, y} {x, y}, latter unique prime implicant, namely {x}.
take switched- style definition, x (weakly, strongly) partially entails
x. However, intuitive {x, y} achieves x also achieves x.
Hence, exists case x true x false.
Again, consider formula x y. two prime implicants, namely {x} {y}.
Intuitively, formula (weakly, strongly) partially entail itself. However,
case apply switched- style definition. 2
One fundamental properties relationships among three notions partial
entailments. following proposition shows weak partial entailment weaker
partial entailment, weaker strong partial entailment. However,
observations Example 1, converses hold general.
Proposition 6 (Basic relationships among partial entailments) Let P , Q two formulas formula set. P Q, P Q; P Q, P W
Q.
worth mentioning that, definitions partial entailments, P I(, P ) required
empty exclude case P inconsistent background theory
. underlying intuition partial entailments require real connections
two formulas w.r.t. background theory. Let us take closer look item 2
definitions. basic idea partial entailments prime implicant P w.r.t.
, exists prime implicant Q w.r.t. two literal sets satisfy that,
instance, intersection empty. words, P partially entails Q w.r.t.
via two literal sets. However, item 2 exclude case
prime implicant P w.r.t. . case, item 2 still holds. However, cannot say
P partially entails Q w.r.t. via two literal sets two literals sets
33

fiZhou & Zhang

exist all. Hence, require additional item 1 make sure P I(, P )
empty.
Then, formulas P inconsistent , P (weakly, strongly) partially
entail formula Q. Also, formulas P entailed , P (weakly, strongly)
partially entail formula Q. However, reasons two cases different.
former, reason P I(, P ) empty (see Proposition 4), thus P excluded
item 1 definitions. latter, reason P I(, P ) = {} (see Proposition
4 again), thus prime implicant P w.r.t. intersections prime
implicants. say formula P trivial respect background formula set
|= P |= P . Otherwise, say P nontrivial respect . following
proposition shows trivial formula neither (weakly, strongly) partially entail
formula, (weakly, strongly) partially entailed formulas.
Proposition 7 (Non-Triviality) Let formula set P Q two formulas.
P trivial w.r.t. , P 6 Q Q 6 P . assertion holds weak partial
entailment strong partial entailment well.
Proposition 8 (Extension Classical Entailment) Let formula set P
Q two formulas nontrivial w.r.t. . |= P Q, P Q. Also, P W
Q.
Proposition 8 shows partial entailment extension classical entailment
considering nontrivial formulas, weak partial entailment. converses hold.
simple example, x (weakly) partially entails x x classically entail x y.
Note strong partial entailment classical entailment mutually different.
example, x classically entails x x strongly partially entail x. Conversely,
x strongly partially entails xy x classically entail xy. demonstrated
Section 2.1, reason strong partial entailment prohibits irrelevancy whilst classical
entailment not.
addition, strong partial entailment captures notion part broader sense.
words, formula P strongly partially entails formula Q respect
background formula set , P considered part Q w.r.t. .
sense, also explains classical entailment necessarily imply strong partial
entailment. However, explanation seems suggest way around. is,
P strongly partially entails Q w.r.t. (i.e., P part Q w.r.t. ), Q classically
entails P w.r.t. . fact, case either. example, x strongly partially
entails (x y) (y z), (x y) (y z) classically entails x. reason
formula may contain disjunctive information. restricted simple case
discussed Section 2.1, indeed case. is, given two consistent literal sets
0 , strongly partially entails 0 0 classically entails .
2.4 Semantic Properties
subsection, extensively study semantic properties relation three
kinds partial entailments. reasons interested properties
twofold. Firstly, provide deeper understandings partial entailments work.
see later, surprisingly, many simple inference rules fail partial entailments. Secondly, properties illustrate similarities/differences among three kinds partial
34

fiA Logical Study Partial Entailment

entailments, well similarities/differences partial entailments classical
entailment.
consider collection inference rules. considered important
many kinds philosophical logics knowledge representation logics, others likely
hold partial entailments. Let 0 two sets formulas, P , Q R formulas
x atoms. subsection, assume formulas nontrivial w.r.t.
background theory.1 Here, use > denote kinds partial entailments
respect . inferences rules considered listed follows:
Ref: (Reflexivity) P > P , meaning formula partially entails w.r.t. background theory.
LE: (Left Equivalence) |= P R P > Q, R > Q, meaning two
formulas equivalent background theory, play role
partial entailments left side.
RE: (Right Equivalence) |= Q R P > Q, P > R, meaning two
formulas equivalent background theory, play role
partial entailments right side.
BE: (Background theory Equivalence) |= 0 0 |= , P > Q iff P >0 Q,
meaning two background theories equivalent, play role
partial entailments.
Rev: (Relevancy) P > Q, Atom(P ) Atom(Q) 6= , meaning one formula
partially entails another w.r.t. empty background theory, atom sets used
two formulas respectively must disjoint.
Tran: (Transitivity) P > Q Q > R, P > R, meaning partial entailment
relation among formulas ordering propositional language.
AS: (Atom Substitution) P > Q, P (x/y) > Q(x/y),2 meaning atoms
partial entailment relation replaced atoms.
LO: (Left Or) P > Q R > Q, P R > Q, meaning two formulas
partially entail another one, disjunction partially entails formula
well.
LS: (Left Strengthening) |= P R R > Q, P > Q, meaning
formula partially entails another, formula strengthened former
partially entail latter well.
RA: (Right And) P > Q P > R, P > R Q, meaning two
formulas partially entailed another formula, conjunction
partially entailed formula well.
1. trivial formulas interesting partial entailments (see Proposition 7).
2. Here, P (x/y) formula obtained P simultaneously replacing every occurrence atom x
y, similar Q(x/y).

35

fiZhou & Zhang

Table 2: Properties partial entailments
Ref
LE


Rev
* Tran

LO
* LS
RA
RO
Mono
LN
RN

weak partial entailment
yes
yes
yes
yes
yes



yes






partial entailment
yes
yes
yes
yes
yes










strong partial entailment
yes
yes
yes
yes
yes
yes









RO: (Right Or) P > Q, P > Q R, meaning formula partially entails
another, partially entail disjunction latter formula
formulas.
Mono: (Monotonicity) 0 |= P > Q, P >0 Q, meaning adding
information background theory preserves partial entailment relations.
LN: (Left Negation) P > Q, P 6> Q, meaning impossible
formula negation partially entail another formula.
RN: (Right Negation) P > Q, P 6> Q, meaning impossible
formula negation partially entailed another formula.
Suppose define relation > P Q classical entailment, i.e.,
|= P Q. Then, satisfies inference rules proposed above. However, following
proposition shows partial entailments fail many them.
Proposition 9 Table 2 summarizes whether three kinds partial entailments satisfy
inference rules considered above.
Table 2 illustrates similarities differences among three kinds partial
entailments. results inference rules. However, Transitivity (Tran) Left Strengthening (LS) (highlighted symbol Table 2)
two exceptions. Transitivity (Tran) holds strong partial entailment partial
entailment weak partial entailment. Left Strengthening (LS) holds weak partial
entailment partial entailment strong partial entailment. Finally, weak
36

fiA Logical Study Partial Entailment

partial entailment partial entailment extensions classical entailment sense
considered Proposition 8, strong partial entailment not.
Also, Table 2 illustrates similarities differences partial entailments
classical entailment. mentioned above, inference rules hold classical
entailment. However, case partial entailments. means partial
entailments actually behave quite different classical entailment. Among inference
rules, Transitivity important one. hold partial entailment weak
partial entailment since allow irrelevancies. Nevertheless, Transitivity holds strong
partial entailment. However, strong partial entailment even dissimilar classical
entailment since mutually different.
Table 2 also indicates easy capture properties notions
partial entailments due fact fail simple inference rules (see
Table 2). Meanwhile, properties, (e.g. Tran, LN RN), may seem intuitive
partial entailments. However, turns hold general according
formal definitions.
Certainly, one consider inference rules, instance, Contraposition. is,
P > Q, Q P . One check Contraposition hold three
kinds partial entailments either.
2.5 Discussions
One may doubt whether partial entailments directly captured within classical propositional logic. example, one may define partial entailment follows. formula P
partially entails formula Q w.r.t. formula set iff exists formula R
{R} 6|= Q {P, R} |= Q. However, definition cannot capture partial satisfaction. fact, every formula P 6|= P Q, always exists formula
V
R (Let R P Q). Even restrict R consistent literal sets, definition
capture partial satisfaction either. instance, x partially entail x
according definition since (x y) |= x y. However, conclusion counterintuitive. alternative possibility, since P partially entails Q intuitively means
P entails parts Q, one may define partial entailment as: formula P partially
entails formula Q iff exists Q0 Q00 |= Q Q0 Q00 , Q00 6|= Q0
P |= Q0 . However, definition fails capture essence partial entailment either.
instance, according definition, x partially entails since |= (xy)(xy),
x 6|= x y, x |= x y.
According definitions partial entailments, x (weakly, strongly) partially entails
x x y. One may conclude result indicates conjunction
disjunction play similar role partial entailments. However, case.
example, reasons x partially entails x x partially entails x
completely different. former case, reason x part x y,
latter case, reason x classically entails x y. fact, conjunction disjunction
play totally different roles partial entailments. instance, x partially entails x,
x not. examples easily found.
37

fiZhou & Zhang

Another evidence illustrate differences conjunction disjunction
consider another special case partial entailments restricting formulas clauses,
i.e., disjunction literals, assuming background theory empty.
Proposition 10 Let 0 two non-valid clauses (i.e., disjunctions two consistent
sets literals). following statements equivalent.
1. subset 0 represented two sets literals.
2. classically entails 0 .
3. weakly partially entails 0 .
4. partially entails 0 .
5. strongly partially entails 0 .
Proposition 10 states setting, classical entailment three kinds
partial entailments coincide. Compared Proposition 10 Definition 1, disjunction
conjunction quite different partial entailments.
mentioned earlier, Substitution principle hold three kinds
partial entailments general. means that, partial entailments, atoms indeed
play different role formulas. instance, x (weakly, strongly) partially entails x y.
However, necessary case P partially entails P Q. shows difference
partial entailments classical entailment due fact Substitution
principle holds standard propositional logic.

3. Complexity Analysis
section, analyze complexity issues relation extended notion prime
implicant three kinds partial entailments. assume readers familiar
basic notions computational complexity. details found
textbook Papadimitriou (1994).
Here, briefly recall complexity classes. DP widely used complexity class,
contains languages L L = L1 L2 , L1 NP L2 coNP.
polynomial hierarchy defined recursively follows:
P0 := P0 := P0 := P,
P

Pi+1 := P , 0,
P

Pi+1 := N P , 0,
P

Pi+1 := coN P , 0.
P

instance, P3 = P 2 complexity class languages recognizable
polynomial time deterministic Turing Machine equipped P2 oracle. particular, P3 [O(log n)] subset P3 restricting uses oracle within logarithmical times. Gottlob (1995) showed complexity classes P3 P3 [O(log n)]
38

fiA Logical Study Partial Entailment

coincide so-called P2 -dag P2 -tree respectively. Intuitively, P2 -dag acyclic
directed graph dependent queries P2 oracles. nodes queries whilst edges
represent dependency relationships among nodes. P2 -tree P2 -dag tree.
mainly investigate following decision problems, general case
restricted cases:
PRIC(, P, ) : (Prime Implicant Checking) determine whether literal set prime
implicant formula P w.r.t. formula set .
LEPR(, P, l) : (Literal Existence Prime Implicants) determine whether literal l
least one prime implicant formula P w.r.t. formula set .
LAPR(, P, l) : (Literal Prime Implicants) determine whether literal l
prime implicants formula P w.r.t. formula set .
WPE(, P, Q) : (Weak Partial Entailment) determine whether P weakly partially entails Q
w.r.t. .
PE(, P, Q) : (Partial Entailment) determine whether P partially entails Q w.r.t. .
SPE(, P, Q) : (Strong Partial Entailment) determine whether P strongly partially entails
Q w.r.t. .
convenience, omit empty.
first three decision problems concerned relativized notion prime
implicant, others concerned notions partial entailments. main
focuses paper course latter ones, former ones needed
intermediate steps.
Note complexity results related prime implicant found
followed existing results literature (see details Appendix). instance,
shown Marquis (2000) (Propositions 3.27 3.32), checking whether literal set (with
without background theory) prime implicate formula DP complete. Another
result comes Proposition 10 Lang et al. (2003) checking whether literal
least one prime implicant formula NP complete. Also, consequence
correspondence prime implicant abduction, many complexity results related
abduction borrowed studying prime implicant. instance, shown
Appendix, checking whether literal l one prime implicants F respect
exactly task relevance checking abduction.
However, main focus paper, partial entailments defined upon prime
implicant (i.e. abduction). Although existing results conclude computational
complexity results related prime implicant, reveal much information
complexities partial entailments.
3.1 Empty Background Theory
start complexity analysis background formula set empty. following
proposition shows complexity results relation prime implicant background
theory empty. mentioned above, first two results follow existing results
literature.
39

fiZhou & Zhang

Proposition 11 computational complexities relation prime implicant empty
background theory summarized Table 3.

Table 3: Complexity results prime implicant: empty background theory
PRIC(P, )
LEPR(P, l)
LAPR(P, l)

DP complete
NP complete
DP complete

Based computational analysis prime implicant, following proposition
presents complete result complexity results relation three kinds partial
entailments background theory empty.3
Proposition 12 computational complexities relation partial entailments
empty background theory summarized Table 4. Here, l literal, set
literals P Q formulas.

Table 4: Complexity results partial entailments: empty background theory
(l, P )
(P, l)
(, P )
(P, )
(P, Q)

NP
DP
NP
DP
P2

WPE
complete
complete
complete
complete
complete

NP
DP
NP
DP
P2

PE
complete
complete
complete
complete
complete

SPE
NP complete
coNP complete
P2 complete
coNP complete
P3 complete

Let us take closer look Table 4. First all, shows easy task
compute notions partial entailments, even background theory empty.
instance, check whether formula (weakly) partially entails another formula
second level polynomial hierarchy. surprisingly, task strong partial
entailment even difficult, third level polynomial hierarchy.
Also, Table 4, one conclude computational complexities increase
forms formulas become complicated. instance, checking whether literal
strongly partially entails formula NP complete. extending literal literal
set, becomes P2 complete. task turns P3 complete extending
antecedent arbitrary formula. Interestingly, weak partial entailment partial
entailment, matter considering partially entailing formula partially entailed
formula, turning literal literal set increase complexity. However,
3. Clearly, antecedent consequent restricted literal sets, corresponding
decision problems relation three kinds partial entailments solved linear time.

40

fiA Logical Study Partial Entailment

strong partial entailment, case partially entailed formula
partially entailing formula.
Finally, observed that, background theory empty, weak partial
entailment partial entailment computational complexities, strong
partial entailment acts differently. Interestingly, based basic assumptions
complexity theory, checking strong partial entailment relationship sometimes easier
rest two (e.g. compare SPE(P, ) PE(P, )), sometimes difficult (e.g.
compare SPE(P, Q) PE(P, Q)).
application scenarios, background theory simply set facts,
represented set literals. Hence, interested computational complexities
special case. shall see later, much simpler general case
background theory arbitrary set formulas.
following proposition indicates that, fortunately, turning background formula
set literal set increase computational complexities three kinds
partial entailments.
Proposition 13 complexity results Tables 3 4 remain background theory set literals.
3.2 General Background Theory
Finally, face general case, background theory arbitrary formula
set. consider general cases six decision problems. One reason
background theory general setting already. Another reason that, even single
literal, might exist many different prime implicants respect arbitrary
background theory.
Proposition 14 computational complexities relation partial entailments general case summarized Table 5.4

Table 5: Complexity results: general case
PRIC(, P, )
LEPR(, P, l)
LAPR(, P, l)
WPE(, P, Q)
PE(, P, Q)
SPE(, P, Q)

empty
DP complete
NP complete
DP complete
P2 complete
P2 complete
P3 complete

arbitrary
DP complete
P2 complete
P2 complete
P3 [O(log n)]/ P2 hard/ P2 hard
P3 / P2 hard/ P2 hard
P3 complete

According Table 5, complexities prime implicant checking strong partial
entailment checking remain allowing arbitrary background theory,
4. Here, also present corresponding computational complexity results background theory
empty order compare directly.

41

fiZhou & Zhang

complexities increase decision problems. instance, checking whether
literal one (or all) prime implicant(s) formula increases NP complete (DP
complete, resp.) P2 complete (P2 complete, resp.) background theory turns
arbitrary one. Also, complexities checking weak partial entailment partial
entailment general case increase little two problems P2
P2 hard. However, corresponding complexity strong partial entailment remains
since already P3 hard special case background theory empty.
shown Table 5, WPE(, P, Q) PE(, P, Q) P2 hard P2 hard.
shows neither P2 complete P2 complete based basic assumptions
complexity theory. conjecture WPE(, P, Q) P3 [O(log n)] complete
PE(, P, Q) P3 complete. However, verify this, advanced techniques, e.g.
raising technique proposed Liberatore (2007), needed.

4. Related Work
section 2, discussed relationships partial entailments classical entailment. Here, consider relationships partial entailments
related notions literature, including family notions relevance relatives, formula-variable independence (Boutilier, 1994; Lang et al., 2003), relevance
formulas (Lakemeyer, 1995, 1997), novelty (Marquis, 1991) probabilistic positive relevance (Zhou & Chen, 2006), partial satisfaction formula (Lieberherr &
Specker, 1981; Kappeli & Scheder, 2007).
4.1 Formula-Variable Independence
Lang et al. (2003) defined notion formula-variable independence formula
set atoms. Roughly speaking, formula independent set atoms
formula rewritten another one mentions atoms set atoms.
Definition 7 (Lang et al., 2003) formula F variable-independent set V
variables iff exists formula G |= F G Atom(G) V = .
Also, Lang et al. proved variable-independence coincides notions influenceability introduced Boutilier (1994) relevance formula set atoms
introduced Lakemeyer (1997).
shown Lang et al. (2003), notion formula-variable independence
reformulated prime implicant. Here, show reformulated weak partial
entailment well.
Proposition 15 Let F formula V set atoms. following statements
equivalent:
1. F variable-independent V .
2. literals l V V , l prime implicants F .
3. literals l V V , l weakly partially entail F .
42

fiA Logical Study Partial Entailment

4.2 Forms Relevance
Lakemeyer also introduced forms relevance well, including strict relevance, explanatory relevance relevance two subject matters (Lakemeyer, 1997).
Definition 8 (Lakemeyer, 1997) formula F strictly relevant set V atoms
iff every prime implicate F contains least one atom V .
following proposition shows strict relevance reformulated prime
implicant weak partial entailment well.
Proposition 16 Let F formula V = {x1 , . . . , xn } set atoms. following
statements equivalent.
1. F strictly relevant V .
2. F weakly partially entails (x1 . . . xn ) (x1 . . . xn ).
Definition 9 (Lakemeyer, 1997) formula F explanatory relevant set V
atoms w.r.t. formula set iff exists minimal abductive explanation F w.r.t.
mentions variable V .
definition explanatory relevance reformulated prime implicant.
is, F explanatory relevant V w.r.t. iff exists l V V l
least one prime implicants F w.r.t. .
4.3 Relevance Formulas
pointed Lakemeyer (1997), interesting consider relevance formulas
respect background theory. Here, propose definition relevance
two formulas respect background theory using prime implicant.
Definition 10 formula P relevant formula Q respect formula set iff
exists prime implicant P w.r.t. prime implicant 0 Q w.r.t.
0 6= .
Definition 10 looks similar definition weak partial entailment (See Definition 4). major difference two definitions weak partial entailment
defined style, whilst relevance defined style. precisely,
former, require prime implicants P w.r.t. , exists prime
implicant Q w.r.t. intersection empty. However, latter,
require exists prime implicant P w.r.t. exists prime
implicant Q w.r.t. satisfying condition.
However, weak partial entailment serve strict notion relevance two
formulas respect background theory. is, formula P strictly relevant
another formula Q respect formula set P weakly partially entails
Q w.r.t. . Clearly, strict version relevance formulas w.r.t. background
theory based weak partial entailment implies normal one defined Definition 10,
converse hold general.
43

fiZhou & Zhang

4.4 Novelty Novelty-Based Independence
notion novelty (Marquis, 1991) defined two formulas respect
formula set well.
Definition 11 (Marquis, 1991) formula P new positive (new negative) another
formula Q respect formula set iff exists prime implicant Q (Q)
respect {P }, prime implicant Q (Q) respect .
addition, notion independence, namely novelty-based independence (also known
separability, see Levesque, 1998), two formulas defined based novelty (Lang,
Liberatore, & Marquis, 2002).
Definition 12 (Lang et al., 2002) Two formulas P Q (novelty-based) independent iff P new negative Q w.r.t. >.
Intuitively, P new Q w.r.t. means adding new information P
background theory influences Q Q. Although novelty partial
entailments defined using notion prime implicant, essentially
different. instance, (non)novelty-based independence satisfies Symmetry. is,
P (non)novelty-based independent Q, Q (non)novelty-based independent
P . However, (weak, strong) partial entailment satisfy Symmetry. instance,
x (weakly, strongly) partially satisfies x y, converse hold. another
example, x (weakly, strongly) partially entails x y. However, x new positive
(negative) x y. Also, x new positive (negative) x. However, x
(weakly, strongly) partially entail x.
4.5 Probabilistic Positive Relevance
Another approach formalize certain kind usefulness probabilistic positive relevance
(Zhou & Chen, 2006), based probability distributions. basic idea positive relevance is: formula P positive relevant another formula Q respect
background formula set iff probability distributions P r, P r(Q|{P }) P r(Q|).
Although positive relevance looks similar partial entailments, probability distribution highly related prime implicant (Lang et al., 2002), underlying intuition
semantic properties positive relevance partial entailments quite different.
instance, according definition positive relevance Zhou Chen (2006),
x positive relevant x. However, x (weakly, strongly) partially entail
x. Generally speaking, positive relevance (defined based probability distributions),
Symmetry holds. is, P positive relevant Q w.r.t. Q positive
relevant P w.r.t. . However, hold kinds partial entailments.
4.6 Partial Satisfaction CNF
term partial satisfaction also used satisfaction subset set clauses
(Lieberherr & Specker, 1981; Kappeli & Scheder, 2007). CNF formula (i.e. conjunction
clauses) said k-satisfiable every subformula containing k clauses
satisfiable.
44

fiA Logical Study Partial Entailment

Although term partial satisfaction used k-satisfaction partial entailments, represents different intuitive meanings. former, part means subset
formula (i.e. set clauses), latter, means subset prime implicant formula. Hence, partial entailments k-satisfaction basically irrelevant.
Moreover, k-satisfaction concerned particular (CNF) formula, partial
entailments concerned relationship two formulas (w.r.t. background
theory).

5. Partial Goal Satisfaction
traditional logic based approach rational agency, agents always try find actions
completely achieve goals. successful, agents would choose wait
nothing. idea usually formalized using classical entailment. However,
always case agents find perfect action (think real world
live in). situation, sometimes useful agents something
towards goals rather waiting, actions partially satisfying
agents goal rational candidates. Here, partial entailments may serve
logic foundation.
Example 6 Let us consider example. Suppose Laura wants milk cereal
breakfast. However, three choices available breakfast menu.
Choice1 milk offered.
Choice2 Milk bread offered.
Choice3 bread offered.
Due current information, none choices completely satisfies Lauras goal.
Then, do? 2
Here, argue that, circumstance, also rational agents choose
actions partially achieving goal according belief, action
completely achieving goal.
important allow actions partially achieving agents goal rational
candidates. First all, rationality performing actions solid since
make goal closer agents nothing better do. Hence, choosing
actions useful agents goal reasonable waiting. Also,
environment dynamic nature. cases, agents choose actions
partially achieving goal, might lose chance achieve goal forever.
frequently happens everyday life cannot seize opportunities.
formalize partial achievement actions goals agents belief
using notion partial entailments proposed Section 2. natural since
partial entailments precisely capture partial satisfaction relations two formulas
respect background theory. apply partial entailments formalize partial goal
satisfaction, treat background theory agents belief, consequent
agents goal antecedent consequences action. One obstacle
45

fiZhou & Zhang

represent actions consequences. Here, address issue, simply use triples
Hoare logic represent actions.5
Again, restrict discussions within propositional language. goal
belief agents represented propositional formula set propositional formulas
respectively. action triple hP re(), , P ost()i, label called body
action, P re() P ost() two propositional formulas called precondition
postcondition action respectively. Next, show traditional idea
complete goal satisfaction idea partial goal satisfaction formalized
setting.
Definition 13 (Complete goal satisfaction) Let agents belief G agents
goal. Let set candidate actions. action completely achieves agents
goal G according belief iff:
1. |= P re().
2. {P ost()} consistent.
3. |= P ost() G.
Definition 13 means agents belief satisfies precondition action
believes postcondition action entails goal, action completely
achieves goal belief. Partial goal satisfaction formalized similar way
except partial entailments used instead classical entailment.
Definition 14 (Partial goal satisfaction) Let agents belief G agents
goal. Let set candidate actions. action (weakly, strongly) partially
achieves agents goal G according belief iff:
1. |= P re().

2. P ost()(W
, ) G.

Definition 14 means agents belief satisfies precondition action
believes postcondition action partially entails goal, action
partially achieves goal belief.
Example 7 Consider Example 6 proposed previously. formalize example, use x,
z represent milk, cereal bread respectively. Then,
Lauras belief empty since background knowledge; goal represented
x y; preconditions three actions take three choices respectively
empty well represented >, postcondition three cases
represented x, x z z respectively. According Definition 13, none three
actions completely achieves goal x y. However, according Definition 14, take
Choice1 Choice2 (weakly) partially achieve goal. particular, take Choice1
strongly partially achieves goal, whilst take Choice3 partially achieve
goal sense. 2
5. Here, use simple action theory demonstrate notion partial entailments
used formalizing partial goal satisfaction. problems represent actions agents
general deal frame problem scope paper.

46

fiA Logical Study Partial Entailment

problem arises kind partial goal satisfaction rational agents. first
glance, seems partial entailment appropriate purpose. Weak partial
entailment may contain side effects acceptable, whilst strong partial entailment
strict powerful actions excluded. However, believe better
leave agent designers. One may choose different kinds partial goal satisfaction
different application domains, e.g., strong partial entailment irrelevancies
side effects crucial issues, partial entailment side effects unacceptable
irrelevancies not, weak partial entailment looser cases.
worth mentioning partial goal satisfaction proposes one possible solution
dealing situations agents cannot find plan completely achieve
goal. neither solution necessarily perfectly rational.
situations, actions achieving parts agents goal may lose chances
achieve parts, might unacceptable agents.
Also, actions partially achieving agents goal rational candidates
compulsory. quite different fact action rational candidate
agents really choose perform it. Partial goal satisfaction explains
rationality actions partially achieving goals. problem particular
action chosen perform among actions partially achieving agents
goal another research topic beyond scope paper.
Another approach handling situations explicitly represent agents full
preferences among combinations goals. instance, Example 6, Laura may
following full preferences among candidate goals:
{M ilk, Cereal} > {M ilk} > {Cereal} > {},
> represents preference relation. Lauras original goal (i.e. ilk Cereal)
cannot achieved, intends achieve second best candidate goal (i.e. ilk)
according preference. observed partial goal satisfaction always
consistent full preference approach, instance, preference Laura
turns {M ilk, Cereal} > {} > {M ilk} > {Cereal}. Although sharing similarities,
two approaches essentially different. First all, full preference requires additional
information, partial goal satisfaction not. Moreover, expensive represent
full preference agents. Since number possible combinations goals exponential respect size goals, represent full preference requires double
exponential number new information. Last least, usually difficult obtain
full preferences agents. Hence, believe full preference approach
partial goal satisfaction approach advantages disadvantages
dealing situations perfect actions achieve agents goal.
idea partial satisfaction goals discussed elsewhere AI literature
(Haddawy & Hanks, 1992; Smith, 2004; Do, Benton, van den Briel, & Kambhampati, 2007).
One approach called partial satisfaction planning (Smith, 2004; et al., 2007).
partial satisfaction planning, agents find plans, instead completely achieving goals,
partially achieve goals. Since agents goals AI planning, particularly
STRIPS-like planning, usually represented conjunctions small pieces subgoals,
formalized finding plans achieve subsets subgoals. fact,
special case partial entailments sense partial entailment dealing
47

fiZhou & Zhang

arbitrary propositional formulas. Another approach due Haddawy Hanks (1992).
approach, agents goals represented groups candidate goals
associated real number [0, 1] represent degree chances
satisfying goal. plan satisfying candidate goal number 1 full satisfaction
plan satisfying candidate goal number (0, 1) (e.g., 0.5) partial
satisfaction. several differences approach partial entailments.
Firstly, partial entailments, objective formula represented single formula
instead set candidate variations. Secondly, numerical degree satisfaction
introduced partial entailments. Finally, partial entailments, partial satisfaction
relationships come internal structures formulas.
Finally, would like mention application scenario discussed partial
entailments reasoning rational agents classical AI planning, e.g. STRIPS.
main reason agents goal beliefs formalized literal sets rather
arbitrary formulas STRIPS planning, main focus paper introduce
notions partial entailments propositional logic general. Nevertheless, since checking
partial entailments restricted antecedent, consequent background
theory literal sets done linear time, interesting apply partial
entailments AI planning. would like leave future investigations.

6. Concluding Remarks
paper, introduced new logical notionpartial entailmentto propositional logic.
distinguished three different kinds partial entailments (See Table 1) based
notion prime implicant. weakest strongest, weak partial entailment,
partial entailment strong partial entailment respectively. investigated
semantic properties partial entailments (See Table 2). results demonstrate
properties partial entailments difficult captured since many simple inference
rules hold. also investigated computational complexity partial entailments
(See Tables 4 5). complexity results surprising interesting. instance,
checking strong partial entailment P3 complete, even background theory
empty. indicates although definitions partial entailments look simple,
easy compute them.
showed notions partial entailments serve foundation formalizing partial goal satisfaction reasoning rational agents. Another potential application scenario, mentioned previous work (Zhou, van der Torre, & Zhang, 2008),
goal weakening using strong partial entailment. agent needs modify
goal, choose weakened one strongly partially entails original goal
respect agents belief. strong partial entailment preserves
important parts original goal. However, sophisticated work needed
develop goal weakening framework. Also, mentioned previously, interesting
apply partial entailments AI planning, formulas syntactically restricted
computation task partial entailment may become easier.
Another direction future work lies computing partial entailments. course,
important task develop algorithm directly purpose. However, alternative
48

fiA Logical Study Partial Entailment

approach identify tractable subclasses checking partial entailments since
general complexities relatively high.

Acknowledgments
preliminary results paper published (Zhou & Chen, 2004; Zhou et al.,
2008). grateful Xiaoping Chen Leon van der Torre inspirations
contributions works. also grateful Jerome Lang valuable
comments earlier draft paper, would like thank anonymous
reviewers valuable comments well. authors partially supported
Australian Research Council (ARC) Discovery Projects grant (DP0988396).

Appendix A. Selected Proofs6
Proposition 8 (Extension Classical Entailment) Let formula set P
Q two formulas nontrivial w.r.t. . |= P Q, P Q. Also, P W
Q.
Proof: first prove P Q. Let prime implicant P w.r.t. .
|= P . Since |= P Q, |= Q. Proposition 2,
subset 0 0 prime implicant Q w.r.t. . Thus 0 . Due
non-triviality P Q, 0 6= 0 = . shows P Q.
According Proposition 6, P W
Q. 2

Proposition 9 Table 2 summarizes whether three kinds partial entailments satisfy
inference rules considered above.
Proof: Here, give proofs counterexamples results.
Relevancy, according Definition 5, exists P I(P ) 0 P I(Q)
0 6= . Therefore, Atom()Atom( 0 ) 6= . follows Atom(P )Atom(Q) 6=
since Atom() Atom(P ) Atom( 0 ) Atom(Q). Similar weak partial entailment
strong partial entailment.
Transitivity strong partial entailment, let prime implicant P w.r.t. .
Since P Q, exists literal set 1 consistent 1 P I(, Q)
1 . Moreover, since Q R, exists literal set 2 consistent
2 P I(, R) 1 2 . Hence, 2 . shows P R.
Note Transitivity hold either partial entailment weak partial entailment. instance, x x x y, x 6 y. Similarly, x W x
x W y, x 6W y. reason partial entailment weak partial entailment
fail transitivity allow irrelevancies. example, although x partially entails y, contains x, irrelevant y, exactly reason x
partially entails x y.
6. present proofs here. others relatively simple, found full
version, available http://www.scm.uws.edu.au/~yzhou/papers/partial-entailment-full-version.pdf .

49

fiZhou & Zhang

Left Strengthening weak partial entailment, let prime implicant P w.r.t.
. Then, |= P . follows |= R since |= P R. Proposition 2,
subset 1 , prime implicant R w.r.t. . Moreover, R W
Q. Then,
exists prime implicant 2 Q w.r.t. 1 2 6= . Thus, 2 6= .
shows P W
Q.
Note Left Strengthening hold either partial entailment strong partial
entailment. example, x x x x y, x 6S x
x 6 x y. reason strong partial entailment partial entailment fail Left
Strengthening prohibit side effects since strengthening part left side
could side effect right side, e.g., example.
Left Negation Right Negation hold three kinds partial entailments. example, x x (weakly, strongly) partially entail x y. Meanwhile,
x (weakly, strongly) partially entails x (x y). 2

Proposition 11 computational complexities relation prime implicant summarized Table 3.
Proof: first result proved similarly Proposition 3.27 work Marquis
(2000), second one follows directly Proposition 10 work Lang et al.
(2003). last result, easy prove l occurs prime implicants P iff
P satisfied |= P l. immediately proves membership assertion.
Hardness follows fact P satisfiable Q unsatisfiable iff x prime
implicants (x P ) (x Q), x new atom. 2

Proposition 12 computational complexities relation partial entailments
empty background theory summarized Table 4. Here, l literal, set
literals P Q formulas.
Proof: membership WPE(, P), let = {l1 , ..., lk }. weakly partially entails
P exists li , 1 k li one prime implicant P .
Proposition 11, problem NP.
membership PE(, P), first prove literal set partially entails
formula P iff assignment 1 Atom\Atom() assignment 2
Atom() 1 |= P 1 2 |= P . : Definition 5,
prime implicant 0 P 0 6= 0 = . Let l 0 .
0 \{l} {l} 6|= P . extended assignment 0 Atom, satisfies
P . Let 1 0 Atom(1 ) = Atom\Atom(); let 2 0 Atom(2 ) = Atom().
Clearly, 1 |= P 1 2 |= P . : Proposition 2, prime implicant
0 P 0 1 . follows 0 6= 0 = . Hence,
partially entails P . Hence, following algorithm determines whether partially entails
P : 1. simultaneously guess two literal sets 1 2 ; 2. check whether 1 2 together
satisfy conditions. Step 2 done polynomial time. Therefore,
PE(, P) NP.
50

fiA Logical Study Partial Entailment

SPE(, P), membership easily shown following algorithm: 1. guess consistent literal set 0 ; 2. check whether 0 prime implicant P ; 3. yes, check whether
subset 0 . Proposition 11, step 2 requires N P oracle. Hence, problem
P2 . hardness, construct reduction 2 QBF . Let X two disjoint
sets atoms P formula Atom(P ) X . Let = {y1 , y2 , ..., yk }; T1
y1 ... yk ; T2 y1 ... yk ; x two new atoms different X ; Q
(xy P )(xy T1 )(xy T2 ). prove XY P holds xy
strongly partially entails Q. Suppose XY P holds. Then, exists assignment
0 X 0 |= P . Proposition 2, exists 1 0 1
prime implicant P . Therefore, {x, y} 1 |= Q. addition, {x} 1 6|= Q. Otherwise,
{x} 1 |= (x P ) (x T1 ) (x T2 ). follows {x} 1 |= T1 ,
contradiction. Symmetrically, {y} 1 6|= Q. Moreover, l 1 , {x, y} 1 \{l} 6|= Q
since 1 prime implicant P . shows {x, y} 1 prime implicant Q.
Hence, x strongly partially entails Q. hand, suppose x strongly
partially entails Q. Then, exists prime implicant Q including x y.
Let {x, y} 1 . Therefore 1 |= P . 1 6|= T1 . Otherwise, {x} 1 |= Q.
shows {x, y} 1 prime implicant Q, contradiction. Symmetrically,
1 6|= T2 . shows Atom(1 ) X. Moreover, {x, y} 1 |= Q. follows
{x, y} 1 |= x P . Therefore 1 |= P . Let 0 assignment X
1 0 . Then, 0 |= P . shows XY P holds.
membership WPE(P, ), P weakly partially entails iff a) P satisfiable, b)
assignments 1 Atom\Atom(), 1 6|= P , equivalent |= P .
prove this, suppose P weakly partially entails . Then, P satisfiable. assume
exists 1 1 |= P . Proposition 2, exists 2 1
2 prime implicant P . However, 2 = , contradiction.
hand, suppose three conditions hold. Then, prime implicants 1
P , 1 6= . Otherwise, 1 extended assignment 2 Atom
2 |= P . However, 2 , contradiction. Hence, WPE(P, ) DP.
membership PE(P, ), let = {l1 , . . . , ln }. Then, P partially entails iff
prime implicant 0 P , a) 0 = , b) 0 6= iff a) i, (1 n), li
prime implicants P , b) P weakly partially entails . Hence,
Proposition 11 result weak partial entailment, problem DP .
membership SPE(P, ), let = {l1 , . . . , ln }, Atom(P )\Atom() = {x1 , . . ., xm }.
P strongly partially entails iff prime implicants P subsets iff
i, (1 n), li prime implicants P j, (1 j m), xj (xj )
prime implicants P . Proposition 11, problem coNP.
WPE(P, Q), membership shown following algorithm, determines
whether P weakly partially entail Q: 1. guess consistent literal set ; 2. check
whether prime implicant P ; 3. yes, check whether weakly partially
entail Q. Proposition 11 case WPE(, P), steps 2 3 require N P
oracle. Hence, problem P2 . hardness, construct reduction 2QBF .
Let X two disjoint sets atoms P formula Atom(P ) X .
Let = {y1 , y2 , ..., yk }. Formula (y1 ... yk ) (y1 ... yk ). prove
XY P holds P weakly partially entail . Suppose XY P
holds. Then, exists assignment 1 X 1 |= P . Proposition
51

fiZhou & Zhang

2, exists prime implicant 2 P 2 1 . Clearly, prime
implicant 3 2 3 6= . hand, suppose P
weakly partially entail . Then, exists prime implicant 1 P
prime implicants 2 , 1 2 = . follows Atom(1 ) X. Then, 1
extended assignment 3 X 3 |= P . Hence, XY P holds.
PE(P, Q), membership shown following algorithm, determines
whether P partially entail Q: 1. guess consistent literal set ; 2. check whether
prime implicant P ; 3. yes, check whether partially entail Q.
Proposition 11 case PE(, P), steps 2 3 require N P oracle. Hence,
problem P2 . hardness, construct reduction 2 QBF . Let X
two disjoint sets atoms P formula Atom(P ) X . Let
X = {x1 , x2 , ..., xk }; X 0 = {x01 , x02 , ..., x0k } k new atoms different Atom. Formula K
(x1 x01 ) (x2 x02 ) ... (xk x0k ). prove XY P holds x K
partially entails x P , x new atom. Notice prime implicants K
form 0 , ( 0 ) assignment X (X 0 ) i, (1 k),
xi iff x0i 0 (xi iff x0i 0 ). suppose x K partially entails x P .
Then, assignments 0 X, {x} 0 00 partially entails x P . Therefore,
exists assignment 1 {x} 0 00 1 |= x P . follows
0 1 |= P . shows XY P holds. hand, suppose XY P
holds. Then, assignments 0 X, exists assignment 1 ,
0 1 |= P . Therefore, prime implicants {x} 0 00 x K, exists
assignment 1 {x} 0 00 1 |= x P . Moreover, exists
assignment 2 = {x} 0 00 {x} X X 0 , 2 1 |= (x P ). Hence,
x K partially entails x P .
Finally SPE(P, Q), membership shown following algorithm, determines whether P strongly partially entail Q: 1. guess consistent literal set
; 2. check whether prime implicant P ; 3. yes, check whether doesnt
strongly partially entails Q. Proposition 11, step 2 requires N P oracle;
case SPE(, P), step 3 requires P2 oracle. Hence, problem P3 .
hardness, construct reduction 3 QBF . Let X, Z three disjoint sets atoms P formula Atom(P ) X Z. Suppose
X = {x1 , x2 , ..., xk }. Let X 0 = {x01 , x02 , ..., x0k } k new atoms. Let K formula
(x1 x01 ) (x2 x02 ) ... (xk x0k ). Suppose Z = {z1 , z2 , ..., zk }. Let T1
z1 ... zk T2 z1 ... zk respectively. Let R formula x K Q
formula (x P K) (x T1 K) (x T2 K) respectively, x
two new atoms. Next, prove XY ZP holds R strongly
partially entails Q. proof tedious. one hand, suppose XY ZP holds.
Given prime implicant R form {x, y} 0 , assignment
X 0 corresponding assignment X 0 . Then, exists assignment 1
1 |= P . Therefore, {x, y} 0 1 |= x P K. follows
{x, y} 0 1 |= Q. Proposition 2, exists subset 2 {x, y} 0 1 ,
prime implicant Q. x 2 . Otherwise, {y} 0 1 |= Q.
Therefore {y} 0 1 |= x T2 , contradiction. Symmetrically, 2 . Moreover,
atom l 0 , l 2 since 2 |= K. Therefore {x, y} 0 2 .
shows prime implicants R, exists prime implicant Q
52

fiA Logical Study Partial Entailment

former subset latter. Hence, R strongly partially entails Q.
hand, suppose R strongly partially entails Q. Notice assignments
X, {x, y} 0 prime implicant R. Therefore, prime implicant Q
contains {x, y} 0 . Let {x, y} 0 1 , Atom(1 ) Z.
Therefore, 1 |= P . 1 6|= T1 . Otherwise, {x} 0 1 |= Q,
contradiction. Symmetrically, 1 6|= T2 . shows Atom(1 ) . Thus, 1
extended assignment 2 . {x, y} 0 2 |= Q. Therefore
{x, y} 0 2 |= x P K. Hence, 2 |= P . shows assignments
X, exists assignment 2 , 2 |= P . is, XY ZP
holds. 2
Proposition 13 complexity results Tables 3 4 remain background theory set literals.
Proof: assertion follows directly following fact:
Suppose P formula consistent set literals. Then, P I(, P ) =
P I(P |).
one hand, suppose 1 P I(, P ). Then, according definition, 1
consistent 1 |= P . Atom(1 ) Atom() = . Otherwise, suppose
l Atom(1 ) Atom(), 1 \{l} |= P . Also, 1 \{l} consistent.
shows 1 prime implicant P w.r.t. , contradiction. Moreover, 1 |= P .
follows 1 |= P |. addition, exist 2 1 2 |= P |.
Otherwise, 2 |= P 2 consistent. shows 1 prime implicant
P w.r.t. , contradiction. Hence, 1 prime implicant P |. hand,
suppose 1 prime implicant P |. Then, Atom(1 ) Atom() empty since
Atom(P |) Atom() empty. addition, 1 |= P since 1 |= P |. Thus, 1
consistent. Moreover, exist 2 1 2 |= P . Otherwise,
2 |= P |. shows 1 prime implicant P |, contradiction. Hence, 1
prime implicant P w.r.t. . 2
Proposition 14 computational complexities relation partial entailment general
case summarized Table 5.
Proof: DP completeness PRIC(, P, ) follows directly Proposition 1
DP completeness PRIC(P, ). also proved similar way techniques
introduced Marquis (2000) proving DP completeness corresponding decision problem prime implicate (see Marquis, 2000, Proposition 3.36).
LEPR(, P, l), membership easy guessing literal set checking l
P I(, P ). hardness, shown XY P iff x one elements
P I(, F ), = {(x P (y1 yk ))}, F = x P (y1 yk ) x
(y1 yk ), x new atom. proof tedious. outline basic
ideas follows.
x one elements P I(, F )
53

fiZhou & Zhang

iff
V
V
V
, x , 6|= , |= F 0 , 0 6|= F .
iff
V
V
V
1 , 1 {x} 6|= , 1 {x} |= F 1 6|= F . (Notice 1 {x}
necessarily mentioned above.)
iff
V
V
V
1 , 1 6|= ( )|x, 1 |= ( )|x F |x 1 6|= ( )|x F |x.
iff
1 , 1 6|= P (y1 yk ), 1 |= P 1 6|= y1 yk .
iff
XY P holds. fact, hardness result also follows P2 completeness checking
relevance abductive reasoning (see Eiter & Gottlob, 1995, Thm. 4.11).
LAPR(, P, l), membership shown following algorithm, determines whether l prime implicants P w.r.t. : 1. guess literal set ;
2. check prime implicant P w.r.t. ; 3. yes, check l . According result prime implicant checking, problem P2 . Thus,
original problem P2 . harness, prove similar way
proof P2 hardness LEPR(, P, l). Indeed, one prove XY P
iff x one elements P I(, F ), = {(x z P (y1 yk ))},
F = x z P (y1 yk ) x z (y1 yk ), x z two new
atoms. Moreover, x one elements P I(, F ) iff x elements
P I(, F ) since every element P I(, F ) contains either x x. shows determining whether literal prime implicants formula w.r.t. formula set
P2 hard. follows LAPR(, P, l) P2 hard.
WPE(, P, Q), P2 hardness follows directly Proposition 12. P2 hardness
implied hardness proof P2 hardness LEPR(, P, l) noticing
prime implicant x w.r.t. {x} itself. membership, let us first consider
following algorithm, determines whether P weakly partially entail Q
w.r.t. : 1. compute literals occur least one prime implicants Q
w.r.t. ; 2. check whether prime implicant P w.r.t. , contain
literals computed step 1. According result P2 hardness
LEPR(, P, l), step 1 requires linear calls P2 oracle. addition, step 2 requires
one recall P2 oracle based results obtained step 1. this, need
guess consistent literal set, check prime implicant P w.r.t.
contains literals computed step 1. algorithm converted P2 -tree,
root corresponding P2 call step 2, children corresponding
linear P2 calls step 1 computing literals. Thus, according P2 -tree
techniques introduced Gottlob (1995), WPE(, P, Q) P3 [O(log n)].
PE(, P, Q), P2 hardness P2 hardness shown similar
way corresponding tasks weak partial entailment. membership, following
algorithm determines whether exists prime implicant 0 Q w.r.t. ,
0 = 0 6= : 1. guess literal set 0 ; 2. check 0 prime implicant
Q w.r.t. ; 3. check 0 satisfy conditions. According result
prime implicant checking, step 2 requires calls NP oracle. Thus, decision
problem P2 . Based result, following algorithm determines whether P
54

fiA Logical Study Partial Entailment

partially entail Q w.r.t. : 1. guess literal set ; 2. check prime implicant
P w.r.t. ; 3. check exists prime implicant 0 Q w.r.t. 0 =
0 6= . easy see problem P3 . Thus, original problem
P3 .
Finally, SPE(, P, Q), hardness follows directly Proposition 12, membership
shown similar way membership task partial entailment.
2

References
Boutilier, C. (1994). Toward logic qualitative decision theory. Proceedings KR94,
pp. 7586.
Do, M. B., Benton, J., van den Briel, M., & Kambhampati, S. (2007). Planning goal
utility dependencies.. Proceedings IJCAI07, pp. 18721878.
Eiter, T., & Gottlob, G. (1995). complexity logic-based abduction. Journal
ACM, 42 (1), 342.
Eiter, T., & Makino, K. (2007). computing abductive explanations propositional horn theory. Journal ACM, 54 (5).
Gottlob, G. (1995). NP trees Carnaps modal logic. Journal ACM, 42 (2),
421457.
Haddawy, P., & Hanks, S. (1992). Representations decision-theoretic planning: Utility
functions deadline goals. Proceedings KR92, pp. 7182.
Kappeli, C., & Scheder, D. (2007). Partial satisfaction k-satisfiable formulas. Electronic
Notes Discrete Mathematics, 29, 497501.
Lakemeyer, G. (1995). logical account relevance.. Proceedings IJCAI95, pp.
853861.
Lakemeyer, G. (1997). Relevance epistemic perspective. Artificial Intelligence,
97 (1-2), 137167.
Lang, J., Liberatore, P., & Marquis, P. (2002). Conditional independence propositional
logic. Artificial Intelligence, 141 (1/2), 79121.
Lang, J., Liberatore, P., & Marquis, P. (2003). Propositional independence: Formulavariable independence forgetting. Journal Artificial Intelligence Research, 18,
391443.
Levesque, H. J. (1998). completeness result reasoning incomplete first-order
knowledge bases. Proceedings KR98, pp. 1423.
Liberatore, P. (2007). Raising hardness result. CoRR, abs/0708.4170.
Lieberherr, K. J., & Specker, E. (1981). Complexity partial satisfaction. Journal
ACM, 28 (2), 411421.
Marquis, P. (1991). Novelty revisited. Proceedings ISMIS91, pp. 550559.
55

fiZhou & Zhang

Marquis, P. (2000). Consequence finding algorithms. Kohlas, J., & Moral, S. (Eds.),
Handbook Defeasible Reasoning Uncertainty Management Systems, Volume 5:
Algorithms Uncertainty Defeasible Reasoning, pp. 41145. Kluwer, Dordrecht.
Papadimitriou, C. H. (1994). Computational Complexity. Addison-Wesley.
Quine, W. (1952). problem simplifying truth functions. American Mathematical
Monthly, 59 (8), 521531.
Selman, B., & Levesque, H. J. (1990). Abductive default reasoning: computational
core. AAAI, pp. 343348.
Smith, D. E. (2004). Choosing objectives over-subscription planning.. Proceedings
ICAPS04, pp. 393401.
Zhou, Y., & Chen, X. (2004). Partial implication semantics desirable propositions..
Proceedings KR04, pp. 606612.
Zhou, Y., & Chen, X. (2006). Toward formalizing usefulness propositional language..
Proceedings KSEM06, LNAI 4092, pp. 650661.
Zhou, Y., van der Torre, L., & Zhang, Y. (2008). Partial goal satisfaction goal change:
weak strong partial implication, logical properties, complexity. Proceedings
AAMAS08, pp. 413420.

56

fi
