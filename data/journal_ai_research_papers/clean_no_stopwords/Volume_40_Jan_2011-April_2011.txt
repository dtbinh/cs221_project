Journal Artificial Intelligence Research 40 (2011) 523-570Submitted 9/10; published 2/11Efficient Planning Uncertainty Macro-actionsRuijieRUIJIE @ CSAIL . MIT. EDUComputer Science Artificial Intelligence LaboratoryMassachusetts Institute TechnologyCambridge, 02139 USAEmma BrunskillEMMA @ CS . BERKELEY. EDUElectrical Engineering Computer Science DepartmentUniversity California, BerkeleyBerkeley, CA 94709 USANicholas RoyNICKROY @ CSAIL . MIT. EDUComputer Science Artificial Intelligence LaboratoryMassachusetts Institute TechnologyCambridge, 02139 USAAbstractDeciding act partially observable environments remains active area research.Identifying good sequences decisions particularly challenging good control performancerequires planning multiple steps future domains many states. Towards addressingchallenge, present online, forward-search algorithm called Posterior Belief Distribution (PBD). PBD leverages novel method calculating posterior distribution beliefsresult sequence actions taken, given set observation sequences couldreceived process. method allows us efficiently evaluate expected rewardsequence primitive actions, refer macro-actions. present formal analysisapproach, examine performance two large simulation experiments: scientific exploration target monitoring domain. also demonstrate algorithm used controlreal robotic helicopter target monitoring experiment, suggests approachpractical potential planning real-world, large partially observable domains multi-steplookahead required achieve good performance.1. IntroductionConsider autonomous helicopter tasked protecting ships anchored busy harbor.time step, helicopter must know anything moving close ships guarding,due sensor limits, helicopter cannot observe whole harbor once. waykeep ships safe keep moving continuously throughout harbor, keeping trackmoving agents. helicopter well senses another boat moved closeone charges, false alarms costly. helicopters controller must decidemove around, report when, order maximize performance.problem requires decision-making uncertain, partially observable domain, common challenge agent operating real-world environment. helicopter problemdescribed example general class problems particularly difficult two reasons.First, make decision, agent must take consideration present estimate location orientation targets. quantities typically real-valued.c2011AI Access Foundation. rights reserved.fiH E , B RUNSKILL , & ROYstandard terminology Markov decision processes (MDPs), state space consists largenumber continuous variables. Second, make decision now, agent must reasonestimate state world may change many time steps future, differentpossible helicopter target actions. problem many variables consider longtime horizon plan suffers curse dimensionality curse history (Pineau,Gordon, & Thrun, 2003a). refer problems large long.paper present new planning algorithm large, long, partially observable MDPs(POMDPs), target monitoring example. Beyond target monitoring, numerousproblems, scientific exploration extreme environments autonomous management retirement portfolios, may posed large, long POMDPs.Though substantial progress POMDP planning last decade,approaches still struggle scale large domains described many state variables,variable may take large infinite number potential values. Symbolic Perseus (Poupart,2005) used find good solution hand-washing domain 11 state variables,variable took relatively small number values (at 10 values). Recently onlineforward search approaches used achieve encouraging performance large1POMDPs, work Ross, Chaib-draa Pineau (2008b) Paquet, Tobin Chaibdraa (2005). However, cost performing generic forward search scales exponentiallysearch horizon. target monitoring example described large solvedoffline approaches, but, demonstrate later, also requires long horizon search achievegood performance, limiting effectiveness standard forward search long problems.effort towards scaling large, long, partially observable decision making, introduce Posterior Belief Distribution (PBD) algorithm. PBD leverages insight certainenvironments specific structure, distribution belief states (which turn distributions states) arise fixed sequence actions computed efficientlyanalytically. distribution beliefs, posterior belief distribution, allows us scale large,long POMDP problems using efficient forward search temporally-extended action sequences,refer macro-actions. PBD selects action current belief planningrestricted policy space defined input macro-action set, re-plans selectedaction taken new observation received. Note implies policy executednecessarily equal policy space used planning, since first step macroaction executed re-planning performed. characteristic PBD similarreceding horizon controllers (RHC) (such Mayne, Rawlings, Rao, & Scokaert, 2000; Kuwata& How, 2004). RHCs consider finite-horizon policy space performing planning,execute much longer horizon repeatedly re-planning.paper demonstrate PBD algorithm achieves good performance large, longPOMDP problems either outside scope prior approaches, prior approaches fail find good quality policies. experimental results demonstrate PBD performswell attractive computational cost several large, long simulation problems, includingvariant ROCKSAMPLE POMDP benchmark problem (Smith & Simmons, 2005) simulated target monitoring example. also demonstrate PBD algorithm real-world versiontarget monitoring problem, use robotic helicopter platform monitor multipleground vehicles (Section 6.4). demonstration suggests PBD practical potential real1. Unless otherwise specified, describe domain large referring domain describedvalues number state variables, variable take many infinite number values.524fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONSrobotic domains. paper, macro-actions assumed provided domain expert2 ;however, decouple impact specific choice macro-actions, also provide experimental results modify alternate approaches (including state-of-the-art planner) usemacro-actions, still find performance advantages presented methods.rest paper organized follows. Section 2 first provides brief backgroundplanning uncertainty using forward search. introduce PBD algorithm Section 3, consider slight variant PBD applicable larger set domains Section 4.Section 5 provide formal analysis PBD algorithm, Section 6 presentexperimental results. present related work Section 7 finally conclude Section 8.2. Background: Planning Uncertainty using Forward SearchFormally, assume decision-making state-uncertainty problem consists following known components:set states. state consists assignment values L statevariables, sl . domain state variable may either discrete continuous.set actions (controls) A, either discrete continuous.Z set observations z Z, either discrete continuous.p(s |s, a) transition function (also known dynamics model) encodes probability transitioning state taking action state s. assume dynamicssatisfy Markov assumption new state function immediately priorstate action.p(z|s) observation function (also known measurement sensor model) encodesprobability receiving observation z state s.3b0 distribution possible initial states, b0 (s) probability initialstate s. distribution known initial belief state, well-formed distributionsums one across states.r(s, a) reward (or cost) function describes utility agent receives takingaction state s. Slightly abusing notation, r(b, a) expected reward taking actiongiven distribution current states (belief) b.discount factor determines weights immediate rewards relative rewardsreceived later time step.states fully observable. Instead, every time step, agent receives observation taking action. agent must therefore make decisions based prior historyobservations received, z1:t , actions taken, a1:t , time t. world statesassumed Markov, instead maintaining ever-expanding list past observations2. work demonstrated automatically construct good macro-actions smallerPOMDPs (He, Brunskill, & Roy, 2010b). Integrating two lines work interesting area future workoutside scope paper.3. easy extend framework allow observation depend prior state, action, posterior state.525fiH E , B RUNSKILL , & ROYactions, sufficient statistic, known belief bt (s), used summarize probabilityworld state given past history,bt (s) = P r(st = s|a0 , z1 , . . . , zt1 , at1 , zt ).(1)agent therefore plan based current belief state, rather past actionsobservations (Smallwood & Sondik, 1973). example, target monitoring problemintroduced Section 1, agent maintains belief possible locations target.agent updates belief step, taking action receiving observation z (suchcamera image far target), using Bayes filter:Zp(s |s, a)b(s)ds(2)b (s ) = (b, a, z) = p(z|a, )sS(b, a, z) represents belief update function normalization constant.planning problem compute policy : b a, mapping belief statesactions, maximizes expected sum future4 discounted utilities:"#X= argmaxE[r(bi )] ,(3)i=1E[r(bi )] denotes expected reward time step given actions specifiedpossible observations received.Many POMDP solvers, Smith Simmons (2005), Porta, Vlassis, Spaan,Poupart (2006) Kurniawati, Hsu, Lee (2008), perform POMDP planning offlinecalculating value function belief space V : b R. V (b) expected total rewardstarting belief state b following optimal policy5 ,Zp(z|b, a)V ( (b, a, z)) ,(4)V (b) = max r(b, a) +aAzZRp(z|b, a) = p(z|s, a)b(s)ds. Given value function belief space, policyextracted finding action maximizes Equation 4.Instead computing value function entire belief space advance acting, takealternate approach planning online, explicitly computing policy (that is, action)current belief. particular, action selected performing fixed-horizon forward searchused estimate values possible action choices starting currentbelief. action-selection approach closely related methods controls community,including Model Predictive/Receding Horizon Control, forward search also received recentattention AI POMDP community (see recent survey Ross, Pineau, Paquet, & Chaibdraa, 2008a).select action current belief, generic forward search approaches compute lookahead AND-OR tree (Figure 1). goal tree estimate value taking4. assume paper interested problems infinite horizon. problem finitehorizon, discount factor set 1, forward search process (which shortly describe)search depth problems finite horizon.5. often intractable compute, practice value function often approximate.526fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONSFigure 1: forward search tree. actions, z observations, b beliefs. b0 initialbelief, bi,j refers jth belief leaf node depth i.possible actions current belief b, order take action greatest value. Givenroot belief b, tree constructed first branching possible actions root.action, tree branches possible observations. distinct action-observationcombination, compute resulting internal belief would occur action-observationtrajectory followed using Equation 2. process alternately branching actions observations repeated finite depth. depth, known search horizon, determinesfar future effects actions considered selecting possible actionroot (current) belief state.tree constructed, value actions root computed propagating rewards beliefs leaf nodes back root. Starting leaf noderewards, take expectation observations. add expected immediate rewardtaking parent action, next take maximum reward across sibling action nodes.process repeated way root node. expected rewards maximized acrossactions summed across observations agent choose action take, mustoptimize expected distribution observations.planning phase, forward search procedure executes action rootlargest value, receives observation. Given previous belief, action taken,observation received, new belief computed using Equation 2. forward search planningprocess repeats, new belief root node. Re-planning every time step enablesagent condition action selected actual observation received.number attractive characteristics online, forward-search framework. First,computational effort directed towards belief states reachable current beliefdifferent actions. property enables forward search planner compute meaningfulpolicy arbitrarily large environment, since subset environment relevantpoint. Second, online, forward-search fits well systems need good, time constrainedsolutions large amount advance computation possible. Lastly, forward search527fiH E , B RUNSKILL , & ROYcompute explicit representation value function, advantagefactored domains belief updating immediate expected reward calculations relativelysimple, value function complex represent.6However, computational cost generic forward search still scale cost belief updating immediate expected reward calculations, multiplied number tree nodesgrows exponentially search horizon. costs belief updating calculatingimmediate expected reward typically scale either linearly exponentially numberstate variables size respective domains, depending independence relationsamong state variables. state variables continuously-valued, therefore takeinfinite number values, typically need employ parametric compressedrepresentation order make calculations tractable. number tree nodes scales exponentially horizon according O((|A||Z|)H ), |A| |Z| number actionsobservations respectively H search horizon. Therefore, standard forward search approaches typically struggle many state variables and/or state variables largedomains large H-step lookahead necessary achieve good performance.One approach accelerating planning large, long horizon problems use temporallyextended macro-actions, technique used successfully fully observable settingsyears (Sutton, Precup, & Singh, 1999). limited exploration ideaspartially observable settings (exceptions include Theocharous & Kaelbling, 2003; Hsiao,Lozano-Perez, & Kaelbling, 2008; Kurniawati, Du, Hsu, & Lee, 2009). work definemacro-action finite open-loop sequence primitive actions executed without regardobservations received execution action sequence. example, targetmonitoring problem, one macro-action could helicopter travel key region,might involve sequence individual turns straight line moves. restricting action spaceset length L macro-actions, number expanded nodes due action branching factorreduced from|A|H |A|H set length L (or longer) macro-actions,7H = HL macro-action horizon depth .2.1 Macro-action Constructionsmall set macro-actions evaluated search, restricted action spaceresult significant computational savings due smaller exponent H (vs. H) computational complexity expression. However, restriction also result poor algorithmic performance macro-actions evaluated unsuitable. paper, assumemacro-actions provided domain expert part comprehensive strategy scalinglarge problems multi-step lookahead. macro-actions use experimental results consist open-loop policies function properties belief statemacro-action originated, either computed stored offline computed onlineevery timestep. details provided experimental section.reliance domain knowledge paper similar prior work fully observablecommunity separately investigated potential advantage macro-actions turning6. example domain one state space set independent variables, rewardaggregate function variables.7. macro-action depth refers number macro-actions executed sequence root belief nodeleaves.528fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONSchallenge learning macro-actions (see work Sutton et al., 1999 overviewone particular formalism). Although constructing macro-actions automatically beyond scopepaper, presented related work domain-independent algorithm (PUMA) automatically generates macro-actions planning partially observable domains (He et al., 2010b).Borrowing notion sub-goal states fully-observable planning literature (McGovern,1998; Stolle & Precup, 2002), PUMA uses heuristic macro-actions designed takeagent, fully-observable model, possible start state current beliefsub-goal state. PUMA algorithm tested variations experimental domainsused paper, encourage reader refer above-mentioned paperdetails.Regardless set macro-actions generated, several key computational challengesremain scale macro-action forward-search large, long environments. First, recall numbernodes generic forward search scales O(|A|H |Z|H ). Using macro-actions reduces firstterm product, directly change second term, number tree nodes stillexponential function search horizon H. Second, using macro-actions directlyalleviate cost performing belief updates expected reward computations tree node,computational costs substantial large domains. central contributionpaper method efficiently analytically computing result macro-action givenpossible observation sequence received execution. allow us use temporallyextended actions scale certain types large, long POMDPs.3. Posterior Belief Distribution Algorithmplan macro-actions forward search manner, must compute expected reward received macro-action, well expected future value taking macro-action.reward planner expect receive macro-action expected sum rewards posterior beliefs agent reach action macro-action.However, process complicated fact posterior belief also result receivingobservation. agent know observations received macroaction, cannot compute single posterior belief reached macro-action, thereforecannot compute expected reward.course, easy solution consider possible observations, compute expectedreward possible beliefs result possible observations could receivedmacro-action. computing expected reward observation node, AND-ORtree constructed forward search implicitly computes expectation possible observation sequences. But, computing expected reward macro-action requires enumeratingpossible observation sequences could experienced execution, evaluationmacro-action grow intractable quickly (see Figure 2(a)). number observation sequencesconsidered grow exponentially length macro-action, enumeratingpossible observations may even feasible domains continuous observations. One alternative may sample observation sequences given macro-action (Figure 2(b)), samplinglikely still computationally intensive due per-sample cost performing belief updateexpected reward calculation step sampled observation sequence.avoid computational burden realizing sometimes possible analyticallyrepresent distribution posterior beliefs. given sequence actions, need529fiH E , B RUNSKILL , & ROY(a) Exhaustive(b) Sampled(c) AnalyticFigure 2: Three methods represent resulting set beliefs single macro-action. (a)possible observations expanded. (b) subset possible observation trajectoriessampled. (c) Compute analytic distribution posterior beliefs, couldgenerated via exhaustive enumeration possible observation sequences.b0 initial belief, bi,j refers j th belief leaf node depth i.expected reward actions; cannot compute distribution states ahead time,compute distribution state distributions, still compute expected reward.graphical depiction process shown Figure 2(c). analytically computing distributionbeliefs, avoid exponential explosion potential observation sequences (asfunction macro-action length), also costly step performing many individual beliefupdates along possible observation sequences.define bdist posterior distribution beliefs macro-action. shownext subsection (3.1) parametric form model beliefalways Gaussian, distribution posterior beliefs Gaussian Gaussianbeliefs, illustrated Figure 3. property follows fact future beliefsGaussian. random variables described distribution posterior beliefs thereforemeans covariances posterior beliefs. case, bdist consists expressiondistribution belief means expression distribution covariancesmacro-action. show means distributed according Gaussiancovariances delta function single covariance, allowing us represent entiredistribution beliefs Gaussian distribution beliefs means single belief covariance.Section 3.2 show analytically compute expected rewarddistribution beliefs resulting macro-action certain classes reward functions. Givenability analytically compute distribution posterior beliefs, show Section 5computational complexity forward search reduced function macro-action horizonH: macro-actions length 2 (L 2) see significantly faster searchlong horizons.530fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONSFigure 3: Distribution posterior beliefs. a) single Gaussian posterior belief resultincorporating observation sequence. b) possible observation sequences,distribution posterior means Gaussian (black line), posterior mean,Gaussian (blue curve) describes agents posterior belief.3.1 Exact Computation Posterior Belief DistributionLet us assume moment agents belief exactly represented Gaussiandistribution continuous state space, observation transition modelslinear-Gaussian. Formally, state transition observation models represented follows:N (0, P )st = Ast1 + Bat + ,N (0, Q)zt = Cst + ,(5)(6)B dynamics matrices, C observation matrix, P covarianceGaussian dynamics process Q covariance measurement noise.state-transition observation models normally distributed linear functionsstate, Kalman filter (1960) provides closed-form solution posterior beliefstates, N (t , ) given prior belief states, N (t1 , t1 ),= + Kt (zt Ct )= At1 + Bat= At1 + P= (C Q1 C +1)1 ,(7)(8)N (f, F ) D-dimensional Gaussian mean f covariance matrix F ,Kt = C (Ct C + Q)1 Kalman gain mean covarianceaction taken incorporating measurement.key interest represent distribution possible beliefs could result takingparticular action, receiving possible observations. Note current setup,posterior beliefs Gaussians, therefore completely characterized meancovariance. derive expression distribution posterior belief means,possible observation, prior distribution beliefs simply delta functionsingle belief. first re-express observation modelzt N (Cst , Q)531(9)fiH E , B RUNSKILL , & ROYuse compute expression probability observation given beliefmean, p(zt |t ), marginalizing st N (t , ),R(10)p(zt |t ) = p(zt |st )p(st |t )dst= N (Ct , Ct C + Q).(11)perform linear transformations obtain expression distribution posterior means, potential observation:zt N (Ct , Ct C + Q)zt Ct N (0, Ct C + Q)Kt (zt Ct )+ Kt (zt Ct )N (0, Kt (Ct C + Q)KtT )N (t , Kt (Ct C + Q)KtT )N (t , Kt (Ct C + Q)KtT )N (t , C KtT )(12)(13)(14)(15)(16)(17)Equation 17 computed substituting definition Kalman gain.point, somewhat unusual change occurred, , mean distributionitself, random variable. Without knowing value particular observationoccurs primitive action, cannot deterministically predict posterior mean belief.8However, model probability specific belief state, effectively meanscompute distribution belief means covariances . Equation 17 showsdistribution belief means normally distributed , covariancedepends prior covariance observation model parameters. Sampling meandistribution equivalent selecting particular observation.presented formula calculating posterior distribution belief meansone action, possible observation. wish show posterior distributionbeliefs means sequence actions remains Gaussian distribution. allow uscompute analytic expression posterior distribution beliefs could resultmacro-action. therefore require method iteratively use Equation 17 order computeposterior distribution beliefs complete macro-action possible observationsequence.first combine process measurement updates single primitive action belief update order get expression posterior belief means terms prior belief mean.marginalize , theR posterior belief transition update observationupdate, using p(t |t1 ) = p(t |t )p(t |t1 )dt . deterministic function t1 (seeEquation 7a), p(t |t1 ) simply delta function, means p(t |t1 ) identicalEquation 17 substituting using Equation 7a:p(t |t1 ) = N (At1 + Bat , C KtT ).(18)one-step belief update, belief mean prior time step, t1 , assumed knownvalue. However, macro-action, first primitive action taken, posterior be8. Note show later section deterministically predict posterior belief covariance.distribution Dirac delta independent specific observation received.532fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONSlief mean depend received observation. absence knowledge received observation, instead distribution belief means. Therefore, second primitive action macro-action, prior belief given Gaussian t1 N (mt1 , t1 )mt1 t1 random variables. order compute probability distribution, must integrate distribution prior belief means t1 :Z(19)p(t |t1 )p(t1 |mt1 , t1 )dt1 .p(t |mt1 , t1 ) =t1Since terms inside integral Gaussian distributions, analytically combinetwo Gaussians, one independent t1 one dependent t1 . Integrating t1 , done Equations 9-11, find mean posterior beliefmeans conveniently still Gaussian distribution function prior mean beliefmeans covariance:N (Amt1 + Bat , At1 + C KtT )(20)N (mt , )(21)mt = Amt1 + Bat = At1 + C KtT . Equation 20 usedpredict posterior mean distribution multi-step action sequence. Assuming agentcurrently time particular prior mean (which also express Gaussianzero covariance, N (t , 0)), posterior mean action sequence time stepsdistributed follows:t+D N (mt+D , t:t+D )(22)mt+D = f (t1 , A, B, at+1:t+D )= mt+D1 + B at+DXADi Bat+i ,= AD mt +(23)(24)(25)i=1t:t+D=t+DXAt+Di CiT DiT (At+Di )T .(26)i=tNote mt+D depend observations; gives mean distribution beliefsmight result received observations. mt+D dependent state-transition modelparameters calculated via recursive update along action sequence.consider covariance posterior beliefs may result taking macroaction. Recall single belief, posterior covariance taking primitive actionreceiving particular observation calculated using Equation 8. Note formula independent actual received observation zt , prior t1 posterior mean . Formally,533fiH E , B RUNSKILL , & ROYproperty exists Fisher information associated observation model independentspecific observations. Therefore, posterior covariance observation sequenceknown length calculated closed form given prior covariance, without needing knowobservations received along way.specify form bdist , posterior distribution beliefs macro-action:bdist (t+T , ) = N (f (t1 , A, B, at:t+T ), t:T ) (, )(27)bdist (t+T , ) probability arriving posterior belief b = N (t+T , ) takingparticular macro-action, Equation 22 defines distribution belief means, computediteratively applying Equation 8. expression shows problems linear-Gaussianstate-transition observation models, exactly calculate distribution posterior beliefsassociated macro-action.3.2 Calculating Expected Rewardprior section outlined procedure calculating posterior set beliefs macroaction. reason compute distribution turn able calculate expected rewardmacro-action, used compute best action current belief.calculate expected reward macro-action, start considering expected rewardstarting particular belief state b0 executing L-length macro-action consistingactions a1 , a2 , . . . , aL . may expressedZr(b0 , a1:L ) = r(b0 , a1 ) +p(z1 |b0 , a)Q(ba1 ,z1 , a2:L )(28)z1ba1 ,z1represent updated belief taking action a1 receiving obserwhere usedvation z1 b0 , a2:L represent macro-action consisting second L-th primitiveactions macro-action a, Q(ba1 ,z1 , a2:L ) represent future expected reward takingremaining actions belief ba1 ,z1 . Recursively expanding second term Equation 28obtain following expressionZp(z1 |b0 , a1 )r(ba1 ,z1 , a2 ) +r(b0 , a1:L ) = r(b0 , a1 ) +z1Z2p(z1 |b0 , a1 )p(z2 |ba1 ,z1 , a2 )r(ba1 ,z1 ,a2 ,z2 , a3 ) +(29)z1 ,z2L1Zz1 ,...,zL"L1i=1p(zi |ba1 ,z1 ,...,ai1 ,zi1#, ai ) r(ba1 ,...aL1 ,zL1 , aL ). (30)first term Equation 29 represents expected reward taking first primitive actionmacro-action initial belief state. remaining terms represent expectedreward i-th primitive action macro-action, expectation takenpossible 1 length sequences observations could received point (aswell standard integration state space). Equation 27 closed formexpression distribution belief states possible sequence primitive actions.use re-express Equation 29 function distributions beliefs:r(b0 , a1:L ) = r(b0 , a1 ) +LXi=2534i1 r(bi1dist , ai )(31)fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONSbi1dist used represent posterior distribution beliefs results takingfirst 1 primitive actions macro action a. Slightly abusing notation, r(bdist , ai ) representsexpected reward taking action ai given posterior distribution beliefs bdist ,expressedZ Zb(s)bdist (b)r(s, ai )dsdb.(32)r(bdist , ai ) =bCombining Equations 31 32, see expected reward macro-actioncalculated sum expected reward taking primitive action posteriordistribution beliefs step along macro-action.Recall prior section posterior distribution beliefs factoredGaussian distribution belief means (Equation 22), Dirac delta distributionbelief covariances (since beliefs identical covariances):bdist (, ) = N (|ma , )(, )(33)mean belief means primitive action a, covariance beliefmeans primitive action a, covariance belief state primitive action a.belief state Gaussian,b(s) = N (s|, ),re-express rewardZ Zr(s, a)N (s|, )N (|ma , )(, )dsddr(bdist , a) =,Z Zr(s, a)N (s|, )N (|ma , )dds,=(34)(35)(36)second line follows due Dirac delta distribution belief covariances. Expanding formula N (s|, ) see identical formula N (|s, ):11exp( (s )1 (s )T )N/222||11exp( ( s)1 ( s)T )=22||Nd /2= N (|s, ).N (s|, ) =Therefore, substitute equivalent expression yieldZ Zr(s, a)N (|s, )N (|ma , )dds.r(bdist , a) =(37)(38)(39)(40)Completing square exponent, re-express product two GaussiansZ Zr(s, a)N (s|ma , + )N (|c, C)dds,(41)r(bdist , a) =535fiH E , B RUNSKILL , & ROY1 1C = (1c = C(ma (a )1 + 1+ (a ) )). integrate getZr(s, a)N (s|ma , + )ds.(42)r(bdist , a) =reward model weighted sum Nr Gaussians,r(s, a) =NrXj=1wj N (s|j , j ),(43)integral Equation 42 evaluated closed formZ XNrr(bdist , a) =wj N (s|j , j )N (s|ma , + )ds(44)j=1=NrXj=1wj N (j |ma , j + +)ZN (s|c1 , C1 ),(45)completed square exponent, defined new constants C1 = (1j +1 111(a + ) ) c1 = C1 (j j + (a + ) ). Integrating obtain analyticexpression expected reward primitive action distribution beliefs:r(bdist , a) =NrXj=1wj N (j |ma , j + + ).(46)similar closed-form expression available reward model polynomial functionstate,r(s, a) =NrXwj sj ,(47)j=1instead weighted sum Gaussians. Substituting Equation 47 Equation 42 yieldsZ XNrr(bdist , a) =wj sj N (s|ma , + )dsj=1=NrXj=1wjZsj N (s|ma , + )ds.(48)Therefore, evaluating expected reward involves calculating first Nr moments Gaussiandistribution. moments analytic expression Gaussian mean covariance.9 So, reward models either weighted sum Gaussians, polynomialfunctions state space, expected reward macro-action (Equation 28) computedanalytically.arbitrary reward models may possible analytically compute expectedreward taking primitive action particular distribution beliefs. cases,approximate expectation Equation 42 sampling.9. Gaussian distribution completely described first two moments; higher order moments simplyfunctions first two moments.536fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONSFigure 4: PBD, individual beliefs b sampled posterior distribution beliefs bdist ,implicitly sampling particular observation trajectory. best macro-actionselected sampled posterior belief. sum taken sampled beliefs,corresponding sum implicitly sampled observation sequences. Here,bi refers beliefs macro-action depth i.3.3 Branching Posterior Beliefsfar discussed compute posterior distribution beliefs ariseexecuting single macro-action, compute expected reward associateddistribution. planning wish compute value taking single macroaction, sequences macro-actions. allows us consider scenarios muchfuture, useful selecting best action take current belief. example,consider large office space domain robot trying navigate goal location,macro-actions go end hallway turn left right. Assuming robot startsfar goal location, series macro-actions likely needed order reachgoal, therefore important forward search consider search horizonmultiple macro-actions.However, constructing forward search tree, immediately clear evaluatebranch three end macro-action. closed form expressionposterior distribution beliefs end macro-action. posterior set representsdistribution beliefs possible given possible observation sequences could receivedmacro-actions execution. However, different individual posterior beliefs, differentsubsets posterior belief distribution, may associated different best subsequent macroactions tree, different individual posterior beliefs implicitly result receivingdifferent set observations macro-action execution may reveal important information environment result different best subsequent macro-actions. Thoughmotivation behind macro-actions reasonable act open-loop fashion limited537fiH E , B RUNSKILL , & ROYAlgorithm 1 Forward Search Macro-ActionsRequire: Initial belief b0 , Discount factor , Macro-action search depth H, Sampling number Ns1: 02: loop3:Compute set macro-actions4:macro-action ai5:Q(bt , ai ) = E XPAND(ai , bt , , H, Ns ) {See Algorithm 2}6:end7:Execute first action a1 = argmaxa Q(bt , a)8:Obtain new observation zt reward rt9:bt+1 = (bt , , zt )10:tt+111: end looptime period, received observation sequence provide information underlying belieflikely useful selecting future macro-actions.Since know advance subsets posterior beliefs associatedbest subsequent macro-action, instead sample posterior belief distribution,evaluate future macro-actions samples (see Figure 4 illustration). Samplingposterior belief equivalent implicitly sampling observation sequence planned macroaction, without actually perform belief updates along action-observation trajectory.Note potential space observation sequences grows exponentially macro-actionlength. posterior distribution beliefs Gaussian, properties completelydescribed mean covariance, means posterior distribution beliefstypically much lower dimension observation sequence space. Experimentallysee much better performance sampling posterior belief distribution samplingspace observation sequences. sampled beliefs essentially form non-parametric,particle estimate posterior distribution beliefs present taking macro-action.number samples Ns goes infinity, sampled distribution become arbitrarilygood approximation full posterior distribution beliefs. covariance Dirac deltadistribution, sampling needed posterior mean distribution, generating posterior beliefsamples associating posterior mean sample posterior covariance t+T .3.4 PBD Algorithm Summaryready present PBD forward search algorithm (Algorithm 1). Given currentbelief, select action constructing macro-action forward search tree. Placing currentbelief root, expand possible macro-action (Algorithm 2), computing expectedreward resulting posterior set beliefs. sample fixed number posterior beliefs.Forward search proceeds sampled beliefs. repeat processfixed horizon depth select action current belief estimating value, startingsearch leaf nodes. executing action, observation received, newbelief state computed. whole process repeats new belief state. Note PBDever select actions first action macro-action. primitive actions538fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONSAlgorithm 2 E XPAND Expand Macro-actions via PBD1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:Input: Macro-action a, Belief state bt , Discount factor , Macro-action search depth H,No. posterior belief samples per macro-action NsH = 0return 0else {Expand Macro-action a={a1 , . . . , aL }}Ra = 0bdist = btj = 1 LRa = Ra + r(bdist , aj )Update posterior distribution beliefs bdistend= 1 NsSample posterior mean ni according N (mt+T , t+T )bi N (ni , t+T )Generate next set macro-actions AnextAnextanextnextQ(bi , ai ) = E XPAND(anext,bi ,,H 1,Ns )endV = Ra + N1s L maxanextQ(bi , anext))endreturn Vendconsidered, number macro-actions evaluated root belief every timestepmust least size primitive action space, primitive action mustfirst action least one macro-action.4. Approximate Computation Posterior Belief DistributionsPBD algorithm described far assumes transition observation functions linear functions state Gaussian noise. functions non-linear, traditionalKalman filter model longer provides exact belief update, PBD algorithm, distribution posterior beliefs cannot calculated exactly. section briefly describeextension PBD algorithm handle wider class observation models, namely parametric models members exponential family distributions (Barndorff-Nielsen, 1979).non-linear transition models, exist techniques extended Kalman filter approximate posterior Gaussian; however, formally consider incorporatingtechniques PBD algorithm here.choose consider exponential family observation models since family includes widearray distributions, Gaussian, Bernoulli, Poisson distributions, certain appealing mathematical properties. particular, leverage work West, Harrison Migon (1985)constructed linear-Gaussian models approximate non-Gaussian exponential family observation model neighborhood conditional mode, st |zt . used approximate539fiH E , B RUNSKILL , & ROYlinear-Gaussian observation mode traditional Kalman filter, maintain closed-form Gaussianrepresentation posterior belief, creating exponential family Kalman Filter (efKF). completeness include West et al.s derivation filter Appendix A, present mainequations here.Constructing approximate linear-Gaussian observation model requires computationfirst two moments distribution linearization around mean estimate every timestep. exponential family observation model represented follows,p(zt |t ) = exp(ztT (t ) + (zt )),= W (st )(49)st hidden state system, (t ) canonical parameter normalization factor distribution, W (.) maps states canonical parameter values. W (.)also known canonical link function, depends particular member exponentialfamily.first two moments distribution (West et al., 1985)(t ) fifiE(zt |t ) = =fi=W (t )2 (t ) fifiV ar(zt |t ) = =fitT =W (t )(50)derivatives exponential family distributions normalization factor,linearized = W (t ).Given action-observation sequence, posterior mean agents belief efKFupdated according= At1 + Bat= At1 + P= + Kt (zt W (t )),(51)=(52)1(t+ YtT Yt )1 ,Kt = Yt (Yt YtT + t1 )1 efKF Kalman gain, zt = t1 (t zt )projection fiof observation onto parameter space exponential family observationtfimodel. Yt =st st =t gradient exponential family distributions canonical parameter,linearized .incorporate results compute modified form posterior belief meancovariance distributions, represented Equations 8 22 observationmodel linear Gaussian. Now, exponential family observation models, posterior beliefcovariance comes Equation 52. expression distribution posterior meansmodified based efKF equations:t+T N (f (t1 , At:t+T , Bt:t+T , at:t+T ),t+TXYiT KiT ).(53)i=tworth noting contrast prior expressions posterior belief distribution(Equations 8 22), exact completely independent received observations,Equations 52 53 longer independent observations obtained observation model parameters linearized prior mean . Hence parametersindependent observation obtained macro-action sequence length 1,540fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONSlonger macro-action, observation model parameters depend prior observations obtained.approximate update linearizing mean prior mean distribution mtstep along action sequence, rather true prior belief mean . shortly seestill obtain good experimental results using approximation.alternate popular approach non-Gaussian systems use particle filter representsystem state. However, high dimensional, continuous environments similar ones consideredpaper, particle filters often suffer particle depletion, require large numberparticles accurately capture posterior. costs belief updating expected rewardcalculations scale number particles. contrast, approximate PBD computationcomputational complexity exact PBD computation, demonstratelater sections scale polynomially number state dimensions.approximate method computing posterior distribution beliefs usedsubstitute exactly calculating posterior distribution beliefs PBD algorithm.5. Analysisprovide formal analysis accuracy computational complexity PBD algorithm. Throughout section assume belief states represented exactly Gaussiandistributions: words, assume linear-Gaussian system. following sectionsdemonstrate experimentally PBD algorithm useful wider variety problemsusing EKF efKF described Section 4, incorporating error approximatefiltering techniques analysis algorithm topic future research.5.1 PerformancePBD selects actions performing limited-horizon forward search using restricted policy spaceinduced macro-actions. However, execution, first step macro-actiontaken. observation received, belief state updated, planning repeatedresulting belief. taking first primitive action, system may take sequencesactions correspond known macro-actions, effectively expandingconsidered policy space. result, performance least good actually executingentire macro-action. However, would useful determine claims madebelief-action values calculated part PBD algorithm. Obviously, received rewardsexecuted policy always less equal optimal policys rewards, sincepolicy space considered planning smaller full policy space. However, valuescalculated PBD algorithm approximate values due approximations (suchsampling subset posterior beliefs) made computation process. provelinear-Gaussian systems, values computed PBD, minus additional epsilon term dueapproximations incurred sampling subset posterior beliefs macro-action,probabilistically guaranteed lower bound true optimal values. purposeanalysis assume rewards scaled lie 0 1. maximumnumber macro-actions.Theorem 5.1 Given linear-Gaussian system, initial belief b, > 0,reward model either weighted sum Gaussians, polynomial function, following541fiH E , B RUNSKILL , & ROYlower bound optimal value b holdsVP BD (b) H V (b)q2HVmax(M Ns )probability least 1 , H =)), Vmaxmax +Ns log(10bound maximum value , VP BD (b) best value computed b PBD planningalgorithm.H V11 (Proof First recall PBD algorithm macro-action, subset possible posterior beliefs sampled posterior belief distribution, tree expanded.Note equivalent implicitly sampling subset observation trajectories mightreceived macro-action: sampled posterior belief corresponds beliefwould result following macro-action receiving particular sequence observations.Consider alternate variant macro-action forward search observation sequencesexhaustively enumerated11 : is, macro-action length L, |Z|L possible observationsequences expanded. case, forward search tree constructed precisely subsetfull POMDP forward search tree, since macro-actions mean subset actionsexpanded. Therefore, computed values alternate algorithm directly lower boundoptimal finite-horizon value, since policy space considered strict subset fulloptimal finite-horizon policy space.However, computational reasons, macro-action tree node, subset observation sequences sampled, results averaged across observation sequences.observation sequences happen lead higher rewards may be, chance, disproportionatelysampled, resulting VP BD value could upper bound true optimal value. However,probabilistically bound error induced observation sampling,Prior work Kearns, Mansour Ng (2002) proved bounds MDP state values computed using sampled-states forward search given certain constraints number samples,horizon forward search. McAllester Singh (1999) extended ideas POMDPs,showing similar bounds calculated values POMDP belief state could computedsufficient number observations sampled, forward search computedsufficiently large horizon. results applied little modification PBD algorithm. Essentially consider new meta-POMDP available actionsmacro-actions, observations sequences primitive observations. Since computeexpected reward macro-actions analytically (due assumed form reward model),errors evaluating root belief node values macro-action policy come limited sampling observation trajectories, performing finite horizon lookahead. priorresults McAllester Singh directly apply meta-POMDP, therefore, values computed PBD.obtain final result, depart slightly presentation Kearns, Mansour Ngsought compute number samples required, horizon required, ensureresulting root state-action values within specified bound true value. contrast,seek compute resulting error input number samples Ns fixed horizon H.10. maximum value trivially upper bounded maxs,a r(s, a)/(1 ).11. possible finite number observations.542fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONSproof Kearns, Mansour Ng, show error calculated Hhorizon state-action value QH (b, a) true infinite-horizon policy value Q(b, a)|QH (b, a) Q(b, a)| H Vmax +1(54)probability least 12(M Ns )H exp(2 Ns /Vmax).solve Equation 55 , yield2Vmax(M Ns )H.logNs(55)(56)Substituting Equation 56 Equation 54 re-arranging yields desired result.reward macro-action cannot analytically computed, approximate valuesampling Nr samples primitive action along length-L macro-action. inputcompute probabilistic bound resulting error approximate valueprimitive action using Chernoffs bound. Using union bound, probability true errorexceed threshold primitive action along macro-action L ,resulting error sum error primitive action. error (and probabilityerror) easily incorporated extend Theorem 1 case generic reward models.Note Theorem 1 states high probability VP BD H lower boundoptimal value: provide tight bound close computed VP BDoptimal value. state alternate way, H provides bound error introducedsampling observation sequences, PBD still designed search limited policyspace, defined macro-actions chosen used forward search. Therefore generalcomputed values, even large number observation sequences sampled, maysubstantially less value optimal policy.5.2 Computational ComplexityOne central contributions work providing efficient macro-action forward searchalgorithm scale long horizons large problems. analyze computationalcomplexity approach. computational cost function two operations: computing posterior distribution beliefs, computing expected reward distributionbeliefs. shortly see, computational complexity operations polynomialfunction state space dimension.12 low order relationship possible due particular parametric representation employed posterior distribution beliefs: representingposterior distribution beliefs Gaussian requires number parameters scalesquadratically number state dimensions.13 PBD therefore able scale large domains. computational complexity results summarized Table 1. Throughout analysis12. multiple independent state variables, factors, complexity increases linearly numberindependent factors.13. represent Gaussian X dimensions requires X-dimensional vector specify mean, O(X 2 ) parameters specify covariance.543fiH E , B RUNSKILL , & ROYpresume macro-actions selected computed advance; general,cost computing domain-relevant macro-actions depend particular domain,analyze possible additional computational cost incurred macro-actionconstruction.5.2.1 C OMPLEXITYG AUSSIAN B ELIEF U PDATINGL ENGTH L ACRO - ACTIONcomputation posterior distribution beliefs resulting macro-action presented Equation 53, consists set matrix multiplications inversions. Matrix multiplication O(D2 ) computation, state space dimension. Matrix inversiondone O(D3 ) time. Therefore computational cost performing single update posterior belief states O(D3 ) operation. update must performed primitiveaction length-L macro-action a, resulting computational costO(LD3 )(57)single macro-action.Section 4 presented set equations (Equations 50- 53) use approximatelycompute posterior distribution beliefs observation model Gaussian,exponential family. equations consist set matrix multiplications, costsingle update, cost updating length-L macro-action O(D3 )O(LD3 ), respectively.145.2.2 C OMPLEXITY NALYTICALLY C OMPUTINGL ACRO - ACTIONE XPECTED R EWARDL ENGTHsecond component computational cost comes evaluate expected rewardmacro-action. reward weighted sum Nr Gaussians, specified Equation 43,operation involves evaluating value Nr L Gaussians particular fixed points. EvaluatingD-dimensional Gaussian single point O(D3 ) operation, due inverse covariancemust computed. cost performing operation Nr L times simply O(Nr LD3 ).Therefore total cost evaluating expected reward macro-action reward modelweighted sum Nr Gaussians is:O(LD3 (Nr + 1)).(58)instead reward model Nr -th degree polynomial function state, expectedreward calculation consists cost calculating Nr -moments D-dimensional Gaussiandistribution (Equation 48). Assume without loss generality computing Nr -thcentral moment D-dimensional Gaussian: non-central moment always convertedcentral moment adding subtracting mean term. Let Nr -th central moment denotemoments form E[(s1 E[s1 ])2 (s2 E[s2 ]) . . . (sD E[sD ])] E[(s2 E[s2 ])Nr ],ij denote ij-th entry covariance matrix. work Triantafyllopoulos (2003)know Nr odd, central Nr -th moments zero, Nr even (Nr = 2k) Nr -th14. actual computational cost higher efKF filter since additional operations must performed linkobservation parameter space, operations similarly cubic lower functions statespace dimension.544fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONScentral moments decomposed sum products k covariance terms. example,four-dimensional Gaussian, one fourth central moments (k = 2, 4 = 2k)Xij kl (59)E[(s1 1 )(s2 2 )(s3 3 )(s4 4 )] = 12 34 + 14 23 + 13 24 =1,2,3,4sum taken permutations product pairs (in case, 12/34, 14/23, 13/24).2k-th central moment,XE[(si1 E[si1 ])(sj1 E[sj1 ]) . . . (sik E[sik ])(sjk E[sjk ])] =i1 j1 i2 j2 . . . ik jk (60)sum taken permutations product pairs. sum yields (Nr1)!/(2k1 (k 1)!) terms consist covariance elements power k.particular central moment, cost independent dimension state space. Thereforecost dominated number terms, grows slightly less O(Nr !).also additional cost original polynomial central moment calculation,involve Nr D-dimensional matrix multiplications, yielding cost O(Nr D2 ).summary, cost computing expected reward reward polynomial functionO(L(D3 + Nr ! + Nr D2 )).5.2.3 C OMPLEXITY(61)C ONDITIONAL ACRO - ACTION P LANNING (PBD)Sampling beliefs posterior distribution beliefs requires sampling multivariateGaussian distribution belief means, accomplish computing Choleskydecomposition covariance matrix, = AAT , O(D3 ) operation. belief meangenerated first constructing D-dimensional vector q, consisting independent samplesstandard (scalar) normal distribution. sample desired multivariate GaussianN (s|, ) simply + Aq. Sampling Ns times involves one-time cost computingCholesky decomposition plus matrix-vector multiplication sample, yielding costO(D3 + Ns D2 ).(62)procedure performed every branch point forward search tree (in words,macro-action nodes except tree leaves). concreteness, consider horizon twomacro-actions (H = 2). expanding |A| macro-actions, sample Nsbeliefs. resulting belief state, expand |A| macro-actions: referback Figure 4 illustration. computational complexity sum costhorizon one two:O(|A|(LD3 Nr + Ns D2 + D3 ) + |A|2 Ns LD3 Nr ) = O(|A|(Ns D2 + D3 ) + |A|2 Ns LD3 C), (63)second expression derived considering higher order terms. general,computational complexity selecting action using PBD considering future horizonH macro-actionsO(|A|H1 NsH2 (Ns D2 + D3 ) + |A|H NsH1 LD3 C).545(64)fiH E , B RUNSKILL , & ROYAlgorithmPBD Analytic Expected RewardPBD Arbitrary Reward ModelComputational ComplexiyO(|A|H1 NsH2 (Ns D2 + D3 ) + |A|H NsH1 LD3 C) (Eqn.O(|A|H NsH LD3 + |A|H NsH LD2 ) (Eqn. 66)Table 1: Computational complexity selecting action using PBD algorithm closely relatedalternatives. number state dimensions, H macro-action forward searchhorizon, Ns number sampled beliefs. Slightly abusing notation, also useNs represent number sampled states, case arbitrary reward models.5.2.4 C OMPLEXITYPBDRBITRARY R EWARD ODELSarbitrary reward models possible analytically compute expected reward.Instead expected reward primitive action within macro-action approximated sampling D-dimensional states estimating expected reward averagingreward sampled state.15 cost sampling Ns states multivariate GaussianO(D3 + Ns D2 ) operation (from Equation 62). Assuming calculating rewardsample takes time linear state dimension, sampling rewards adds additionalO(D3 + Ns D2 D) = O(D3 (Ns + 1))(65)cost primitive action within macro-action, yielding total complexity PBD planningreward sampling of:O(|A|H NsH LD3 + |A|H NsH LD2 ).(66)6. Experimental Resultssection test algorithm planning uncertainty problems. PBD algorithmassumes transition models problem domains approximated linear Gaussians.results problems inspired two different research communities, scientific explorationPOMDP literature (Smith & Simmons, 2005) target monitoring sensor resourcemanagement domain, suggest numerous domains satisfy assumption. generally,using linear Gaussian dynamics models common approximation controls community,used approximate even complex dynamics physiological changesinvolved glucose control diabetics (Patek, Breton, Chen, Solomon, & Kovatchev, 2007).Despite different origins state space representations two problemsshortly present results for, involve reasoning multiple steps future ordermake good decisions large domain. PBD algorithm outperforms existing approachessettings. also demonstrate algorithm target monitoring problem actual15. Note rewards bounded, given , sampling sufficient number samples Ns = f (, ),guarantees estimate expected reward primitive action -close true expected value,probability least 1 . proof simple application Hoeffdings inequality (1963). Ns setestimated reward primitive action L close true expected primitive action rewardprobability least 1 , triangle inequality union bound guarantee expected reward entirelength-L macro-action -close true expected reward macro-action probability least 1 .54664)fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONShelicopter platform, underscoring applicability algorithm real-world domains.results macro-action search horizon H chosen empirically given computational constraints,common forward search approaches. explicitly explore performance changessearch horizon varied Table 3. use domain-specific estimate future nodevalue search tree leaf nodes: domains may easier specify macro-actionsheuristic value function, side benefit PBD able efficiently search sufficientdepths heuristic required.6.1 Generic Baselinesproblems compare PBD algorithm state-of-the-art approaches relevantresearch community POMDP planners sensor resource management algorithms scientific exploration target monitoring problems respectively.fully examine impact analytically computing posterior distribution beliefs,also constructed variety algorithms currently exist literature. algorithms given access hand-coded macro-actions used PBD algorithm.first constructed comparison algorithms use macro-action forward search sampleobservation trajectories rather working posterior distribution beliefs. Samplingobservation sequences produces particle approximation resulting distribution beliefs,thereby providing baseline algorithm use analytic representation posteriorbelief distribution. algorithms referred macro-action discrete (MAD) algorithmunderlying state space discrete, macro-action continuous (MAC) algorithmstate space continuous.also implemented offline point-based POMDP solver given access macroactions used forward search algorithms.16 Specifically, modified state-of-the-artPOMDP planner SARSOP (Kurniawati et al., 2008) algorithm Approximate POMDP Planning (APPL) Toolkit17 incorporated macro-actions guide sampling belief pointsused point-based value backups. Instead SARSOP algorithm using performancebounds guide sampling point-based beliefs, modified SARSOP algorithm usesmacro-action sampled, same-length observation sequence generate additional point-basedbelief samples. implementation also modified version MiGS (Kurniawati et al.,2009) authors. However, due offline, point-based nature modified algorithm, able evaluate algorithm two five problem domains usedpaper.Finally, considered experimental comparison open-loop version PBD,conditioning received observations ever performed; however, initial experiments suggestedvariant performed poorly domains interest, explorefurther.6.2 Rocksamplescientific exploration ROCKSAMPLE problem benchmark POMDP problem proposedSmith Simmons (2005), subsequently extended FieldVisionRockSample (FVRS)16. formal discussion differences offline point-based online forward search POMDP algorithms, refer reader survey paper Ross et al. (2008a).17. Approximate POMDP Planning Toolkit. http://bigbird.comp.nus.edu.sg/pmwiki/farm/appl/547fiH E , B RUNSKILL , & ROY(a) ISRS(8,5)(b) SARSOP policy(c) PBD policyFigure 5: Information Search Rocksample (ISRS) problem. (a) Initial (hidden) problem state.agent (pink square) explores samples rocks (circles) world. White circles correspond rocks positive value, black otherwise. Yellow squares indicate locationsrock information beacons. blue sidebar exit region. Red lines indicatepaths taken agent executing (b) SARSOP (c) PBD policies. seeSARSOP policy explores rocks beacons; cannot search far enoughahead model value beacons. contrast, PBD plan visits beaconsheads directly high-value rocks.problem Ross Chaib-draa (2007). Initial experiments domains revealed searching shallow depth sufficient obtain good policies. interest domainsrequire long-horizon lookahead, created new variant ROCKSAMPLE problemcalled Information Search Rocksample (ISRS) problem, shown Figure 5(a). ISRS agentexplores samples k rocks n n grid world. positions agent (pink square)rocks (circles) fully observable, value rock (good bad) unknownagent. every time step, agent receives binary observation value rock.accuracy observation depends agents proximity rocksagents proximity rock information beacons (yellow squares), correspondparticular rock (for example, information beacons could mountain tops offer particularly good view far geologic formation). key characteristic ISRS presentROCKSAMPLE FVRS rock information beacons locationsrock themselves. Unlike previous ROCKSAMPLE formulations, information gathering rewardexploitation require different actions ISRS.agent gets fixed positive reward collecting good rock (white circle), negative rewardcollecting bad rock (black circle), smaller positive reward exiting problem (theblue sidebar right). discount factor = 0.99 encourages agent collect rewardssooner. actions zero rewards.observation model Bernoulli distribution noise distribution scaleddistance beacon, that:p(zi,t |si , rt , RBi ) =(0.5 + (si 0.5)20.5 (si 0.5)2548krt RBi k2D0krt RBi k2D0zi,t = 1zi,t = 0(67)fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONSzi,tsirtRBiD0binary {0 1} observation value rock time t,true value {0 1} rock,agents position time t,location information beacon associated rock i,tuning parameter controls quickly accuracy observationsdecrease greater distance agent beacon.example, information beacon, agent, absolute certainty, receives observationmatches true value corresponding rock, whereas distance agentbeacon infinite, agent receives accurate observation 0.5 probability.variants ROCKSAMPLE problem, including new ISRS problem, formulateddiscrete state, action observation sets. allow use PBD MAC algorithms,approximate agents belief rocks value Gaussian distribution [0,1]state space, take advantage efKF presented Section 4 represent ROCKSAMPLEproblems Bernoulli observation model (Equation 67: see Appendix B details).macro-action finite, open-loop sequence primitive actions. ROCKSAMPLEproblem, five primitive actions: single steps four cardinal directions rocksampling action. Recall agents position fully observable actions deterministic.Using domain knowledge, macro-actions considered particular belief state macroactions that, given agents current position, consist sequence actions enablesagent move rock, information beacon, nearest exit. results 2k + 1macro-actions considered forward search every belief node. agent operatesgrid world, may multiple action sequences same, shortest distance twogrid squares: macro-action considered one agent would move diagonallypossible, replicate agents shortest path movement continuous map. addition,agent currently rock (which fully observable), additional macro-actionsagent first collects rock executing one 2k + 1 default macro-actions considered,resulting twice many macro-actions. set macro-actions therefore varies everybelief node.18 ISRS problem 5 rocks 8 8 grid world, average macro-actionlength 4.76, minimum maximum macro-action length 1 12 respectively.ROCKSAMPLE family problems originates POMDP literature, comparedmacro-action algorithms existing state-of-the-art POMDP solvers: fast upper-boundQMDP (Littman, Cassandra, & Kaelbling, 1995), point-based offline value-iteration techniquesHSVI2 (Smith & Simmons, 2005) SARSOP (Kurniawati et al., 2008), well RTBSS (Paquet, Chaib-draa, & Ross, 2006), online, factored, forward search algorithm. also evaluatedmodified version SARSOP algorithm given access macro-actions usedforward search macro-action algorithms. Since approaches, including own, approximations, also include upper bound value fully observable problem.Table 2 compares performance different algorithms ISRS problem. algorithm tested 10 different initial conditions (which rocks high valuedlow valued), scenario tested 20 times. HSVI2 SARSOP algorithms executed offline range durations,19 forward search algorithms allowed search18. However, two belief nodes agent position, macro-actions identical.19. offline execution durations HSVI2 SARSOP chosen empirically. HSVI2 able searchsolutions ISRS[8,5] problem 1,000s offline running memory. found valuescomputed SARSOP remained constant 25,000s.549fiH E , B RUNSKILL , & ROYAvg rewardsQMDPHSVI2SARSOPSARSOP(macros)RTBSS (d5, s10)RTBSS (d7, s2)RTBSS (d10, s1)MAC (d3,s50)MAD (d3,s50)PBD (d3,s50)Fully observable1.11 0.156.78 0.628.46 0.7018.78 1.599.78 0.4912.41 0.4615.39 0.4513.68 0.6515.88 0.5414.76 0.5721.37ISRS[8,5]Onlinetime (s)0.00010.0510.0700.01517.643.287.035715.394.811.26N.A.Offlinetime (s)3.031000250001000000000N.A.Table 2: ISRS results. HSVI2 SARSOP executed offline range durations.forward search algorithms, numbers brackets represent search depth (d)number posterior beliefs obtained (s) end action/macro-action. Onlinetime indicates average time taken planner return decision every time step.Standard error values shown.pre-defined depths. Here, depth refers primitive action depth RTBSS algorithm,macro-action depth macro-action algorithms (MAC, PBD MAD). addition,pre-defined number samples used obtain posterior beliefs every action/macro-action.abuse notation slightly using samples refer observations RTBSS algorithm,observation sequences MAD MAC algorithms, samples posterior beliefdistribution PBD algorithm.also attempted allow RTBSS algorithm search primitive action searchdepth macro-action algorithms average, i.e. 4.76 3 14, reducing numberobservations sampled per action. found even 1 observation sampled peraction, RTBSS could achieve search depth 10 reasonable computation time.macro-action algorithms significantly better benchmark solvers.Figure 5(b) 5(c) compare policies generated SARSOP algorithm PBD algorithm ISRS problem. SARSOP HSVI2 explore parts belief space guidedupper bound belief-action values. long lookahead required realize visiting beaconsrocks higher value visiting rocks, many iterations therefore substantialcomputation time required SARSOP HSVI2 sample beliefs leadcomputing higher-value policy. considerable offline computation time provided, SARSOP HSVI2 discover valuable agent make detour informationbeacons approaching rocks. Instead, directly approach rocks make decisionsbased noisy observations obtained due large distance informationbeacons.RTBSS algorithm reasonably well able search deep enough,emphasizing need planning uncertainty algorithms search far future orderperform well. Nevertheless, amount online planning time available, MADalgorithm still outperforms RTBSS algorithm. Macro-actions allow algorithms uncover550fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONSMACMADPBDDepth 1, Samples 50AvgOnlinerewardstime(s)4.61004.61004.6100Depth 2, Samples 50AvgOnlinerewardstime(s)9.630.770.0227.510.840.00837.730.770.002Depth 3, Samples 50AvgOnlinerewardstime(s)13.680.65 15.3915.880.54 4.8114.760.57 1.26Depth 4, Samples 20AvgOnlinerewardstime(s)15.071.62 660.5017.430.78 225.7415.820.77 75.06Table 3: Performance macro-action algorithms different macro-action depth ISRS.depth 4, smaller number posterior beliefs sampled computational reasons.potential value moving information beacon without incurring computational costprimitive-action forward search; allows macro-action forward search approaches performbetter prior primitive-action approaches. Figure 5(c) shows PBD agents policy involvesvisiting information beacons gather information rocks good(white circles), traveling rocks sample them. domain, MAD betterPBD algorithm since problem specification made discrete states, whereasparametric approaches must approximate world models planning. addition, fullyfactored nature problem domain, state rock value independent, keepscomputational requirements MAD algorithm relatively small.Similarly, SARSOP algorithm modified incorporate hand-coded macroactions, offline, point-based algorithm performed much better existing offline approaches,including SARSOP algorithm without access macro-actions. result re-emphasizeswell-designed macro-actions valuable generating good policies partially observabledomains. However, problem domains, especially large, factored domainsinterest paper, represented solved offline manner, shall shortly seebenefit PBD settings.also performed additional analysis three macro-action forward search algorithms.Table 3 compares different rewards obtained macro-action algorithms different macroaction depths, well time taken planner return decision every time step.sharp performance jump occurs macro-action search depth increased 2 3emphasizes need search longer horizon ISRS problem good policygenerated. However, computational cost algorithms also increases exponentiallymacro-action search depth. table also illustrates small loss performance inducedapproximating discrete problem continuous representation either MAC PBD,substantial increase computational speed using PBD.Next examine relative performance computational cost PBD, MAC MAD,number samples changes (Table 4) search depth 3. Recall PBD algorithmsamples posterior belief node search tree, evaluates expected futurereward subsequent macro-actions sample. Different regions posterior belief spacemay plan use different subsequent macro-actions, allowing planner implicitly conditionplans received observations. However, sampling used partition posterior beliefspace assign different actions different beliefs introduces source approximation erroradditional computational complexity. predicted earlier computational complexityanalysis, PBD scales best three algorithms number samples increases, since551fiH E , B RUNSKILL , & ROYMACMADPBD5 SamplesAvgOnlinerewardstime(s)12.760.54 0.1515.310.52 0.05612.920.57 0.03550 SamplesAvgOnlinerewardstime(s)13.680.65 15.3915.880.54 4.8114.760.57 1.26100 SamplesAvgOnlinerewardstime(s)12.470.70 58.9015.570.66 20.7214.560.59 4.52500 SamplesAvgOnlinerewardstime(s)12.942.57 1732.5216.322.18 552.6415.361.15 108.64Table 4: Performance macro-action algorithms ISRS depth 3 different numberssamples.(b) ISRS(100,30)(a) ISRS(15,6)Avg rewardsSARSOPSARSOP(macros)RTBSS(d7,s2)RTBSS(d10,s1)MAC(d3,s20)MAD(d3,s20)PBD(d3,s20)Fully obs.9.43 1.0311.42 0.498.37 0.559.35 0.6515.94 0.9217.57 0.8217.00 0.8330.95Onlinetime (s)0.000060.000064.9810.917.012.740.58N.A.Offlinetime (s)1000090000000N.A.Avg rewardsSARSOPSARSOP(macros)MAC(d3,s5)MAD(d3,s5)PBD(d3,s5)Fully obs.N.A.N.A.42.64 3.7851.70 3.4643.68 2.0066.61Onlinetime (s)N.A.N.A.310.05101.9260.81N.A.Table 5: Performance larger ISRS problemsperform belief updates along sampled trajectory explicitly. general, performanceimproves samples, although improvement statistically significant ISRSproblem. However, decision-making uncertainty problem requires large numberposterior beliefs sampled every macro-action, PBD algorithm results consistentlyfaster performance number samples. again, MAD slight performanceedge due approximation discrete ISRS problem continuous variables implicitPBD, difference significant.macro-action forward search nature algorithm also allows us scale much largerversions ROCKSAMPLE problem, since unlike offline techniques, unnecessary generatepolicy spans entire belief space. compared algorithms two additional ISRSproblems 16 16 grid 6 rocks, 100 100 grid 30 rocks.problem domains large benchmark solvers originallyused comparison, though SARSOP RTBSS algorithms could implementedISRS[15,6] problem domain. Table 5(a) shows performance SARSOP forward searchalgorithms ISRS[15,6] problem domain. modified SARSOP algorithm incorporates macro-actions ran memory computing policy offline 900s. forward search macro-action algorithms better able concentrate computational resourcesreachable belief space agents current belief, forward search macro-action algorithmsperform much better SARSOP algorithm modified version incorporatesmacro-actions. Similarly, forward search single-action RTBSS algorithm performed reasonably well ISRS[8,5] problem search depth sufficiently large, algorithm552fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONSFigure 6: TARGET ONITOR problem. helicopter must track multiple targets moving noisydynamics. field-of-view agents sensor (shaded circle) increasesagents altitude.unable search sufficiently deep reasonable time larger ISRS[15,6] problem, resultingpoorer performance forward search macro-action algorithms.implemented macro-action algorithms ISRS[100,30] problem domain,far exceeds problem solved traditional POMDP solver, including modifiedSARSOP algorithm incorporates macro-actions. Table 5(b) compares results threemacro-action algorithms fully observable value, provides strict upper boundmaximum possible reward problem. large problems also underscore valuemacro-actions limit branching factor forward search.6.3 Target Monitoringnext consider target monitoring problem related studied sensor resource management literature (Scott, Harris, & Chong, 2009). problem (Figure 6), helicopter agenttrack multiple targets moving independently noisy dynamics. helicopteroperates 3D space, targets move 2D ground plane. helicopter equippeddownward-facing camera monitoring environment, target within fieldof-view camera sensor, agent receives noisy observation location orientationtarget. assume simplicity observations target unique, allowing usignore data association problem addressed elsewhere.noise associated agents observation target depends agents positionrelative target. helicopter close ground observe small region, determine position objects within small region high level accuracy.helicopter flies higher altitude, view wider region environment,553fiH E , B RUNSKILL , & ROYGreedyWT-SingleWT-MacroNBOMAC(d2,s10)MAD(d2,s3)PBD(d2,s10)GreedyWT-SingleWT-MacroNBOMAC(d2,s10)MAD(d2,s3)PBD(d2,s10)1 TargetAvg rewardsOnline time (s)-21.50 7.650.065765.14 8.640.0007564.64 8.280.00076-5.80 7.920.05141.73 6.964.731.27 5.231.6636.21 6.520.893 Targets-18.00 7.150.46-23.52 10.890.00080-10.53 17.120.00037-8.27 8.840.6337.89 12.4970.91-1.86 5.1926.9655.78 13.8413.022 TargetsAvg rewardsOnline time (s)-26.50 5.000.19-27.03 8.060.00068-19.05 7.640.00042-10.78 6.950.2146.67 18.9122.130.97 5.828.4668.00 16.654.338 Targets-95.00 23.372.01-71.17 14.530.00063-52.98 21.740.00025-5.98 18.005.7883.86 25.65711.6727.36 14.74432.13120.80 25.77 132.50Table 6: TARGET ONITOR Results. Run 200 time steps.measurements less precise. Similarly, closer helicopter particular target,accurate helicopters observation target expected be. Reflecting intuition,use Gaussian observation model noise covariance function positionhelicopter target: details sensor model provided Appendix C. One desirableattribute sensor model helicopter uncertain targets location, evenhelicopter close targets mean location, single observation unlikely localizetarget. target location uncertain, low probability target withinhelicopters field view.agents pose fully observable, though actions takes subject small amountadditive Gaussian noise. result, unlike ROCKSAMPLE domains, open-loop naturemacro-actions means planner cannot perfectly predict vehicles pose endmacro-action. targets motion determined translational rotational velocities.model provides agent prior velocities, every time step, targets truevelocities additive functions fixed input controls Gaussian noise. parametricformulation, agent maintains Gaussian belief targets state, order compareMAD, discretize continuous state spaces agents targets positions, maintainprobability distribution discrete target state. Due computational memory constraints,100m 100m 20m target monitoring problem x, z directions, limiteddiscretization 10m resolution x, directions, 5m z direction, 45 angularresolution.focus particular decision-theoretic version sensor resource management problem,time step agent must decide targets inside area interest.areas interest indicated yellow squares Figure 6. agent receives positivereward successfully reports target interest region, negative reward wronglydecides target region, reward decides target region,regardless targets actual state. Small costs incurred agents motion. callTARGET ONITOR problem.554fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONSGiven current location agent, macro-actions generated computing sequence actions enable agent move particular altitude meanstarget belief. particular desired destination, macro-action constructed first computing shortest path agents current desired location, dividing pathprimitive actions based maximum length primitive action. also includedhovering macro-action consists hovering agents current location four time steps.Note agents current location fully-observable, purpose generating macroactions, assume primitive actions noise-free. Hence, primitive action,helicopter assumed move mean expected change. Similar ROCKSAMPLE problem,although macro-actions generated according policy relies domain knowledge,macro-actions evaluated forward-search algorithms open-loop sequencesprimitive actions. compare forward search macro-action algorithms range intuitive strategies prior approaches. first algorithm greedy strategy, returnsprimitive action results largest expected reward next step. next two approachesWorst Target (WT) policies, hand-coded policies traveling targetlargest uncertainty targets tracked. intuition agents goalgeneral localize targets environment. two algorithms differ based whetheragent chooses new target travel time step (WT-single), re-plansreached target initially chosen (WT-macro). Finally, compared algorithmnominal belief optimization (NBO) algorithm proposed Scott, Harris Chong (2009).NBO algorithm also assumes Kalman filter model target monitoring problem, ratherconsidering entire distribution posterior beliefs, likely posterior belief action considered. algorithm, likely posterior belief Gaussian beliefupdate given posterior mean without incorporating observations, covariancegiven linearizing likely mean step. Although original algorithm usesoptimization approach search action sequences, modify NBO algorithmadopting forward search approach, evaluating macro-action based likely posterior belief.20Table 6 presents results TARGET ONITOR problem, comparing algorithms scenarios different number targets. results demonstrate PBD algorithm,closed form representation distribution posterior beliefs action, finds significantly better policy alternate approaches. Figure 7 demonstrates typical policy executedPBD algorithm. agent begins middle grid world, approaches targethigh altitude (Figure 7(b)), maximizing likelihood localizing target. none targetsseem approaching region interest, agent hovers position conserve energy(Figure 7(c)). one targets may potentially entering region interest, agentfocuses target, tracking carefully ensure knows target exactlyregion interest (Figure 7(d),(e)). agent subsequently travels high altitude repeatsprocess localizing another target potential rewards (Figure 7(f)).Considering entire distribution posterior beliefs, rather maximum likelihoodposterior belief, valuable agent able reason possibility20. noted authors, NBO algorithm focuses new method approximating Q-value, ratheroptimization techniques. adopt generic search approach performing optimization, authorsalso point forward-search POMDP algorithms good search techniques Q-value approximationscould incorporated. use forward search NBO Q-value approximation affect results.555fiH E , B RUNSKILL , & ROY(a)(b)(c)(d)(e)(f)Figure 7: Snapshots PBD policy executed. black circle indicates field-of-viewagents sensor, directly proportionate agents height. sizeerror ellipses indicate agents uncertainty associated target timestep. agent alternates flying high altitude maximize likelihoodobserving targets (b),(f) focusing single target near/has entered areainterest (e).target could within region interest. contrast, NBO approach considerslikely posterior belief, seek localize target mean belief appearsheading region interest. consideration entire distribution posteriorbeliefs necessarily incurs greater computational cost, demonstrate Section 6.4 abletrack two targets real-time using implementation PBD algorithmoptimized speed.Table 6 also shows PBD algorithm directly computes distribution posterior beliefs macro-action, computational cost PBD algorithm significantly lowerMAC algorithm. MAC algorithm suffers greater computational cost generatesset posterior beliefs macro-action sampling observation sequences explicitlyperforming belief updating along sample trajectory. addition, TARGET ITOR problem state space fundamentally continuous, resolution state space556fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS(a) Quadrotor helicopter(b) Multiple cars tracked. (c) Helicopter tracking cararea interestFigure 8: TARGET ONITOR demonstration helicopter. helicopter simultaneouslytrack two cars report whenever either car enters area interest.discretization achievable given computational memory constraints still unable capture inherent characteristics target monitoring problem, resulting poor performanceMAD TARGET ONITOR problem.single-target case, also observed result PBD algorithm worsehand-coded policy agent traveling target largest uncertainty (WT-single).problem involves single target, policy equates agent hoversole target every step, optimal policy single target case. contrast, observeMAC PBD algorithms return policies result agent periodically leavingtarget fly higher altitude, resulting greater noise observations corresponding lossrewards average. restricting MAC PBD algorithms planning macro-actions,restrict set plans agent consider order search deeper, rather shorterconditional plan conditioned observations primitive action. Even thoughagent re-plans every time step, without conditional plan, agent executing MACPBD algorithms execute safe policy fly higher altitude, maximizeslikelihood keeping target well-localized unable condition actions basedsubsequent observations. example highlights trade-off make considering smallerclass policies (those expressed chains macro-actions) compared fullpolicy set. simple problems, single-target TARGET ONITOR problem, policyrestriction clearly limitation, macro-action algorithms perform significantly betterbenchmark approaches multiple targets, scenarios arguablycomplicated require sophisticated planning algorithms.6.4 Real-world Helicopter ExperimentsFinally, proof concept, demonstrate PBD algorithm live instantiationTARGET ONITOR problem. motivating application monitoring problem involvement (He et al., 2010a) 1st US-Asian Demonstration Assessment Micro Aerial Vehicle(MAV) Unmanned Ground Vehicle (UGV) Technology (MAV08 competition). missionhostage rescue scenario, aerial vehicle guide ground units hostage building avoiding enemy guard vehicle. aerial vehicle therefore plan paths order557fiH E , B RUNSKILL , & ROYFigure 9: helicopter (blue/red cross) uses onboard laser scanner localize itself. downward pointing camera used observe ground targets. figure, cameraimage onboard camera projected onto ground plane.able monitor different ground objects report whenever arrivedarea interest.demonstrate scenario actual helicopter platform monitoring multiple ground vehicles indoor environment (Figure 8b). previous work (He, Prentice, & Roy, 2008; Bachrach,He, & Roy, 2009), developed quadrotor helicopter (Figure 8a) capable autonomousflight unstructured unknown indoor environments. helicopter uses laser rangefinderlocalize environment.mounted downward-facing camera make observations target. Since target detection focus paper, ground vehicles known, distinctive color,detected distinguished easily simple blob detection algorithm. Given helicoptersposition world image coordinates detected object, able recoverestimate position orientation target observation global coordinates. helicopterreceived observation target target within cameras field-of-view,although helicopter platform hovered relatively stably, slight oscillations persisted,resulted noisier observations helicopter flying higher altitudes. Hence, helicopter choose actions balanced obtaining accurate observations lowaltitudes larger field-of-view flying high.Two ground vehicles driven autonomously environment open-loop control,helicopter plan actions would accurately localize targets. replicateTARGET ONITOR problem, marked three areas interest helicopter558fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONS(a)(b)(c)(d)Figure 10: Birds eye-view snapshots helicopters trajectory (red), based policy generatedPBD algorithm. helicopter (blue/red cross) alternates observingwhite (b,d) blue (c) cars order accurately report either car areainterest. area field-of-view agents camera sensor varies directlyheight agent flying at.WT-SingleNBOPBD# Target entry detections114# True target entries746Flight time (s)484.15435.25474.64Dist. traveled (m)243.36247.01282.51Table 7: Performance algorithms real-world helicopter experiment. Ground truth foundusing overhead video camera.predict every time step targets within areas (Figure 8c). applied PBDalgorithm plan paths helicopter maximized likelihood could accuratelyreport whenever target area interest. However, rather sending open-loop controlactions helicopter, simulation experiments, safety reasons closedloop around position helicopter, sending desired waypoints wanted helicopternavigate to. helicopters true state world actually partially observable,helicopter rely onboard laser scanner localize position environment.Figure 9 shows 3D view helicopter monitors reports locationsground targets. helicopter flew around environment, obtained observations target,used update agents belief targets. Figure 10 provides snapshotshelicopter executing plan computed online PBD algorithm. helicopter exhibited similar behaviors observed simulation experiments. helicopteralternated two targets environment report either target areainterest. agent large uncertainty particular targets location, would also flyhigher altitude order increase sensor field-of-view, thereby maximizing likelihoodable re-localize targets. video complete system action availableat: http://groups.csail.mit.edu/rrg/index.php?n=Main.Videos.559fiH E , B RUNSKILL , & ROYcoarse measure achieved reward, evaluated well helicopter running PBDmonitoring target entered area interest, compared WT-SingleNBO algorithms. ground truth number times targets actually entered areasinterests trial found using video camera mounted overhead environment.Table 7 indicates PBD algorithm much better job monitoring targets positionsWT-Single NBO algorithms. particular, observed WT-SingleNBO algorithms seldom took advantage ability increase agents sensor field-ofview agent fly higher altitude. agent applying two algorithms thereforehigher probability losing track targets completely.7. Related WorkDecision-making uncertainty states partially observable commonly discussed Partially Observable Markov Decision Process (POMDP) framework, thoughproblem also analyzed research domains similar assumptions.beyond scope paper provide comprehensive survey POMDP techniques, pointbased methods HSVI2 (Smith & Simmons, 2005) SARSOP (Kurniawati et al., 2008)often considered state-of-the-art offline methods, leveraging piece-wise convex aspectsvalue function perform value updates selected beliefs. approaches assume discretestate representation, offline approaches use parametric representations proposedcontinuous-valued state spaces (Brooks, Makarenko, Williams, & Durrant-Whyte, 2006; Brunskill, Kaelbling, Lozano-Perez, & Roy, 2008; Porta et al., 2006). Hoey Poupart (2005)also addressed continuous observation spaces finding lossless partitions observation space.Recent work Bonet Geffner (2009) suggests alternate point-based approaches usetabular representations value function may also competitive prior point-based approaches used -vector representations, alternate representation may usefulcontinuous domains. ideas paper closely related body online, forwardsearch POMDP techniques compute action current belief, recentlysurveyed Ross et al. (2008a).Macro-actions considered depth within fully observable Markov decision process community, typically known options (Sutton et al., 1999), posed partsemi-Markov decision process (Mahadevan, Marchalleck, Das, & Gosavi, 1997). priorformalisms temporally-extended actions include closed-loop policies persist termination state achieved. would interesting explore future richer notionsmacro-actions could incorporated approach.Several offline POMDP approaches use macro-actions Pineau, Gordon,Thrun (2003b), Hansen Zhou (2003), Charlin, Poupart, Shioda (2007), Foka Trahanias (2007), Theocharous Kaelbling (2003) Kurniawati et al. (2009). Pineau et al.sPolCA+ (2003b) algorithm uses hierarchical approach solving discrete-state POMDPs. Similarly, Hansen Zhou (2003) propose hierarchical controllers exploit user-specified hierarchy planning, Charlin et al. (2007) provide method automatically discoveringproblem hierarchy. Yu, Chuang, Gerkey, Gordon Ng (2005) provide optimal algorithmplanning observations available. Foka Trahaniass (2007) solution involves buildinghierarchy nested representations solutions. focus discrete-state problems, particularly navigation applications. Theocharous Kaelblings (2003) discrete-state reinforcementlearning approach samples observation trajectories solves expected reward discrete560fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONSset belief points using function approximation. Kurniawati et al. (2009) recently used macroactions guide sampling belief points use offline point-based POMDP solver.However, prior macro-action POMDP approaches compute value function off-line,aimed scaling large domains, struggle environments consideredpaper. exception work Hsiao colleagues (2008, 2010) used formmacro-actions robot manipulation tasks involve large state space. focuswork robust manipulation uncertainty, work considers shorthorizon action trajectories. Except work Kurniawati et al. (2009), macroaction POMDP approaches, like PBD algorithm, assume macro-actions provideddomain expert.sensor resource management domain, planning uncertainty techniques usedcontext planning sensor placements track single multiple targets. Existing algorithmsoften adopt myopic, greedy strategy comes planning (Krause & Guestrin, 2007),notable exceptions include work Scott et al. (2009) Kreucher, Hero III, Kastella,Chang (2004). Kreucher et al. describe multi-target tracking problem, non-myopicsensor management necessary multi-target tracking. authors use particle filter approachrepresent agents belief targets location, seek find paths resultgreatest KL divergence density measurement. look aheadone action, algorithm uses Monte Carlo sampling generate possible observation outcomes.also provide information-directed path searching scheme reduce complexityMonte Carlo sampling, well value heuristics help direct search. possibleinsights could used combination macro-action formulationstrengthen approaches. experimental section compared approach workScott et al. (2009), directly formulated target tracking POMDP, proposed NominalBelief Optimization (NBO) algorithm computes likely belief action deeperforward search. contrast, algorithm explicitly computes entire set possible posteriorbeliefs macro-action. Recently two groups (Erez & Smart, 2010; Platt, Tedrake, LozanoPerez, & Kaelbling, 2010) independently proposed approach lies middlespectrum: beliefs updated assuming likely observation received,variance increased. contrast, approach represents resulting belief may fairlypeaked, mean beliefs may spread out. complete representation mayadvantageous sharp changes reward function.stated introduction, finite-horizon forward search, act, re-plan strategy PBDfollows seen instance Model Predictive Control/Receding Horizon Control(MPC/ RHC) framework controls community. Examples MPC RHC includework Kuwata (2004), Bellingham, Richards, (2002), Richards, Kuwata,(2003). special case RHC control Certainty Equivalence Control, CEC (see Bertsekas, 2007 overview). fully observable systems, CEC first assumes stochastic operations (such transitions) take expected value, solves finite-horizon deterministiccontrol problem. CEC may applied partially observable environments first samplinginitial state belief state. Though CEC efficient large domains, key limitation use partially observable environments CEC-style controller never takeinformation-gathering actions. Returning generic class MPC approaches, knowledgeprior model predictive controllers used macro-actions developed notion pos561fiH E , B RUNSKILL , & ROYterior distribution beliefs, enables PBD approach scale large uncertain domainsmulti-step lookahead required.8. Conclusionpaper presented Posterior Belief Distribution algorithm. PBD forwardsearch algorithm large (consisting many variables, take many values)partially observable domains. PBD analytically efficiently computes resulting distributionposterior belief states possible sequence actions. allows computational costevaluating reward associated macro-action tractable, leverage enable longer horizon lookahead search online planning. presented theoreticalexperimental results evaluating performance computational cost macro-action algorithms. algorithms applied problem domains span multiple research communities,consistently performed better prior approaches large domains require multi-steplookahead good performance. Finally, demonstrated algorithm real robotic helicopter, underscoring applicability algorithm planning real-world, long-horizon,partially observable domains.9. AcknowledgmentsRuijie He, E. Brunskill N. Roy supported National Science Foundation (NSF)Division Information Intelligent Systems (IIS) Grant #0546467 OfficeNaval Research Decentralized Reasoning Reduced Information Spaces project,Contract # N00014-09-1-1052.wish thank Finale Doshi-Velez, Alborz Geramifard, Josh Joseph, Brandon Luders, JavierVelez, Matthew Walter valuable discussions feedback. Daniel Gurdan, Jan StumpfMarkus Achtelik provided quadrotor helicopter support Ascending Technologies. Abraham Bachrach, Anton De Winter, Garrett Hemann, Albert Huang, Samuel Prenticeassisted development software hardware helicopter demonstration.also appreciate early POMDP forward search discussions Leslie Pack Kaelbling TomasLozano-Perez.Appendix A: Exponential Family Kalman FilterBuilding statistical economics research time-series analysis non-Gaussian observations (Durbin& Koopman, 2000), present Kalman filter equivalent systems linear-Gaussian statetransitions observation models belong exponential family distributions.state-transition observation models represented follows:st = st1 + Bt + ,p(zt |t ) =exp(ztT(t ) + (zt )),st1 N (t1 , t1 ),= W (st ).N (0, Pt )(68)(69)state-transition model, st systems hidden state, control actions, Btlinear transition matrices, state-transition Gaussian noise covariance Pt .observation model belongs exponential family distributions. (t )canonical parameter normalization factor distribution, W (.) maps statescanonical parameter values. W (.) depends particular member exponential family.562fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONSease notation, let(zt |t ) = log p(zt |t ) = ztT + (t ) + (zt ).(70)Following traditional Kalman filter, process update written= t1 ATt + Pt ,= t1 + Bt ,(71)mean covariances posterior belief process updatemeasurement udpate. measurement update, seek find conditional mode= arg max p(st |zt )(72)st= arg max p(zt |st )b(st )(Bayes rule)st(73)= arg max p(zt |t )b(st )(74)st11= arg max exp(Jt ), Jt = log p(zt |t ) + (st )T (st )st2Jt fifi(zt , )10==+ (t ).fist st =tstTaking derivative = W (st ) prior mean , letfiW (st ) fifi.Yt =st fist =t(76)(77)(zt |t )Similarly, performing Taylor expansion= W (t ),fifi2 (zt |t ) fifi(zt |t ) (zt |t ) fifi=+(t )fitT fit =t=t(zt |t )=t + (t )fifi(zt + (t ) (zt ))fifi,==tfi(t ) fifizt=fi(75)(Eqn. 70)(78)(79)(80)(81)=t=t ztfi2 (zt |t ) fifi=fi=t(t ).(82)(83)=t(84)Plugging Equations 82 84 Equation 79, Equation 76,1YtT (t zt + (t )) = (t )1YtT (t1 (t zt ) + ) = (t )1YtT ((t t1 (t zt )) ) =t (t )1YtT (zt W (st )) =t (t ),563(85)(86)(87)(88)fiH E , B RUNSKILL , & ROYzt = (t t1 (t zt )) projection observation onto parameter spaceexponential family distribution, independent st . Equation 88 substituted usingEquation 69.Mean UpdateUsing Equation 88 substituting st ,1(t ) = YtT (zt W (t ))==Linearizing W (st ) ,YtTYtT(89)(zt W (t )) + W (t ) W (t )(zt W (t )) YtT (W (t ) W (t )).W (st ) = W (t ) + W (st )st =t (st )1(t= W (t ) + Yt (t )) = YtT (zt W (t )) YtT Yt (t )YtT (zt W (t )) ===1(t + YtT Yt )(t1(t )YtT (zt W (t )),)(90)(91)(92)(93)(94)(95)(96)(97)YtT = Kt Kalman gain non-Gaussian exponential family distributions. Viastandard transformation, Kalman gain written terms covariances ,Kt = YtT (Yt YtT + t1 )1(98)= + Kt (zt W (t )).(99)Covariance UpdateGiven Gaussian posterior belief,2Js2tinverse covariance agents belief2Js2t1=(t (st ) YtT (zt W (st )))x1= + YtT Yt1==1(t+ YtT Yt )1 .(100)(101)(102)(103)Appendix B. Rock Sample Observation ModelRocksample problem, Bernoulli observation function written follows. Recallrt agents position time t, RBi location information beacon associatedrock i, zi,t binary observation value rock time t, si,t true value564fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONSrock time t. let di,t =k rt RBi k2 ,p(zi,t |RVi,t = si,t , rt , RBi )(104)= (0.5 + (si,t 0.5)2di,t /D0 )zi,t (0.5 (si,t 0.5)2di,t /D0 )1zi,t(105)= exp(zi,t ln(106)0.5)2di,t /D00.5 + (si,t+ ln(0.5 (si,t 0.5)2di,t /D0 ))0.5 (si,t 0.5)2di,t /D0= exp(zi,t (t )).(107)therefore parameters exponential family observation modeli,t = W (si,t , rt , RBi )= ln(108)0.5 + (si,t 0.5)2di,t /D00.5 (si,t 0.5)2di,t /D0(109)i,t = ln(0.5 (si,t 0.5)2di,t /D0 )= ln(exp(i,t ) + 1).derive derivatives Yi,t i,tfiW (si,t , rt , RBi ) fifiYt =fisi,tsi,t =mi,t(111)(112)fi0.5 + (si,t 0.5)2di,t /D0 fifi=lnsi,t 0.5 (si,t 0.5)2di,t /D0 fisi,t =mi,t=(110)(113)12di,t /D0/D0.5 + (mi,t 0.5)2 i,t 0 0.5 (mi,t 0.5)2di,t /D0(114)si,t mean belief used linearization. Sincei,t = ln(exp(i,t ) + 1),(115)i,tfi2 bi,t fifi=2 fii,ti,t =i,t=exp(i,t )exp(i,t ) + 1(116)exp(2i,t )(exp(i,t ) + 1)2.(117)Appendix C. Target Tracking Observation Modeladopt observation model target tracking target observation obtained Gaussian noise noise covariance zi function position helicopter targeti:xizxizyi = f yi + N (0, zi )zizi = g(xi , yi , xa , ya , ha ),565fiH E , B RUNSKILL , & ROYFigure 11: observation noise covariance function height helicopter, distancehelicopter mean target belief, covariance targetbelief. lower altitudes, helicopter make better observations targets closeit, limited field vision. higher heights, helicopter see larger areaeven close targets noisily observed.xi , yi , pose target i, xa , ya , ha correspond agents position heightenvironment. zxi , zyi , zi observation target image coordinates.covariance function specifiedxixaxixayiyayiyag(xi , yi , xa , ya , ha ) = C1 ha + C2+ C3 ,haC1 , C2 C3 constants.generic belief update expression target position, si = [xi ; yi ; ], unknown,ZZb (si ) p(z|si , a, zi )p(si |si , a)b(si )dsi s.t.b (si )dsi = 1,sisimeans possible si would associated different covariance zi . Performingintegration exactly would keep distribution Gaussian. Instead, approximate observation model computing single expected covariance zi given current belief distribution:Zb(si )zi (si )dsi .zi = E[zi ] =siSubstituting exact expressions covariance function belief actiontaken incorporating measurement, ba (s) N (si |, ), get:!Z fiC2xi fifixaxixaxi+ C3 dxi dyi .E[zi ] = N,C1 hayi fi xy xyyayiyayiha566fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONSadding subtracting xy second term, reducesC2E[zi ] = C1 ha +haC2xaxaxyxyxy+yayahaxy , xy refer translational components agents belief.contrast simpler observation models, observation model desirable characteristictargets location uncertain, namely covariance xy large, eventargets mean location close helicopters mean location, expected benefit receivingobservation (in terms reducing targets uncertainty) still small. property comesautomatically derivation, since E[zi ] includes current target covariance xy .Figure 11 provides illustration expected covariance different locations targetrelative agent, agent heights, target belief covariances.ReferencesBachrach, A., He, R., & Roy, N. (2009). Autonomous flight unstructured unknown indoorenvironments. Proceedings European Micro Aerial Vehicle (EMAV) Conference.Barndorff-Nielsen, O. (1979). Information exponential families statistical theory. BulletinAmerican Mathematics Society, 273, 667668.Bellingham, J., Richards, A., & How, J. (2002). Receding horizon control autonomous aerialvehicles. Proceedings American Control Conference (ACC), Vol. 5, pp. 37413746.Bertsekas, D. (2007). Dynamic Programming Optimal Control, vol. 1 & 2, 2nd. Athena Scientific.Bonet, B., & Geffner, H. (2009). Solving POMDPs: RTDP-Bel vs. point-based algorithms. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 16411646.Brooks, A., Makarenko, A., Williams, S., & Durrant-Whyte, H. (2006). Parametric POMDPsplanning continuous state spaces. Robotics Autonomous Systems, 54(11), 887897.Brunskill, E., Kaelbling, L., Lozano-Perez, T., & Roy, N. (2008). Continuous-state POMDPshybrid dynamics. Proceedings International Symposium Artificial IntelligenceMathematics (ISAIM).Charlin, L., Poupart, P., & Shioda, R. (2007). Automated hierarchy discovery planningpartially observable environments. Advances Neural Information Processing Systems(NIPS).Durbin, J., & Koopman, S. (2000). Time series analysis non-Gaussian observations based statespace models classical Bayesian perspectives. Journal Royal StatisticalSociety: Series B (Methodological), 62(1), 356.Erez, T., & Smart, W. (2010). Scalable Method Solving High-Dimensional ContinuousPOMDPs Using Local Approximation. Proceedings Conference UncertaintyArtificial Intelligence (UAI).Foka, A., & Trahanias, P. (2007). Real-time hierarchical POMDPs autonomous robot navigation.Robotics Autonomous Systems, 55(7), 561571.567fiH E , B RUNSKILL , & ROYHansen, E., & Zhou, R. (2003). Synthesis hierarchical finite-state controllers POMDPs.Proceedings Thirteenth International Conference Automated Planning Scheduling (ICAPS).He, R., Bachrach, A., Achtelik, M., Geramifard, A., Gurdan, D., Prentice, S., Stumpf, J., & Roy,N. (2010a). design use micro air vehicle track avoid adversaries.International Journal Robotics Research, 29(5), 529546.He, R., Brunskill, E., & Roy, N. (2010b). PUMA: planning uncertainty macro-actions.Proceedings Association Advancement Artificial Intelligence (AAAI).He, R., Prentice, S., & Roy, N. (2008). Planning information space quadrotor helicopterGPS-denied environments. Proceedings International Conference RoboticsAutomation (ICRA), pp. 18141820.Hoeffding, W. (1963). Probability inequalities sums bounded random variables. JournalAmerican Statistical Association, 58(301), 1330.Hoey, J., & Poupart, P. (2005). Solving POMDPs continuous large discrete observationspaces. Proceedings International Joint Conference Artificial Intelligence (IJCAI).Hsiao, K., Kaelbling, L., & Lozano-Perez, T. (2010). Task-driven tactile exploration. ProceedingsRobotics: Science Systems (RSS).Hsiao, K., Lozano-Perez, T., & Kaelbling, L. (2008). Robust belief-based execution manipulation programs. Proceedings Workshop Algorithmic Foundations Robotics(WAFR).Kalman, R. E. (1960). new approach linear filtering prediction problems. TransactionsASMEJournal Basic Engineering, 82(Series D), 3545.Kearns, M., Mansour, Y., & Ng, A. (2002). sparse sampling algorithm near-optimal planninglarge Markov decision processes. Machine Learning, 49(2-3), 193209.Krause, A., & Guestrin, C. (2007). Near-optimal observation selection using submodular functions.Proceedings National Conference Artificial Intelligence (AAAI), Vol. 22, pp.16501654.Kreucher, C., Hero III, A., Kastella, K., & Chang, D. (2004). Efficient methods non-myopicsensor management multitarget tracking. Proceedings IEEE ConferenceDecision Control (CDC), Vol. 1, pp. 722727.Kurniawati, H., Du, Y., Hsu, D., & Lee, W. (2009). Motion planning uncertainty robotictasks long time horizons. Proceedings International Symposium RoboticsResearch (ISRR).Kurniawati, H., Hsu, D., & Lee, W. (2008). SARSOP: Efficient point-based POMDP planningapproximating optimally reachable belief spaces. Proceedings Robotics: ScienceSystems (RSS).Kuwata, Y., & How, J. (2004). Three dimensional receding horizon control UAVs. Proceedings AIAA Guidance, Navigation, Control Conference Exhibit (GNC), pp.1619.568fiE FFICIENT P LANNING U NCERTAINTY ACRO - ACTIONSLittman, M., Cassandra, A., & Kaelbling, L. (1995). Learning policies partially observableenvironments: scaling up. Proceedings Twlfth International Conference MachineLearning (ICML), pp. 362370.Mahadevan, S., Marchalleck, N., Das, T., & Gosavi, A. (1997). Self-improving factory simulationusing continuous-time average-reward reinforcement learning. Proceedings International Conference Machine Learning (ICML), pp. 202210.Mayne, D. Q., Rawlings, J. B., Rao, C. V., & Scokaert, P. O. M. (2000). Constrained model predictive control: Stability optimality. Automatica, 36, 789814.McAllester, D., & Singh, S. (1999). Approximate planning factored POMDPs using belief statesimplification. Proceedings Conference Uncertainty Artificial Intelligence(UAI), pp. 409416.McGovern, A. (1998). acQuire-macros: algorithm automatically learning macro-actions.NIPS 98 Workshop Abstraction Hierarchy Reinforcement Learning.Paquet, S., Chaib-draa, B., & Ross, S. (2006). Hybrid POMDP algorithms. Workshop MultiAgent Sequential Decision Making Uncertain Domains (MSDM), pp. 133147.Paquet, S., Tobin, L., & Chaib-draa, B. (2005). online POMDP algorithm complex multiagent environments. Proceedings Conference Autonomous agents Multiagentsystems (AAMAS), pp. 970977.Patek, S., Breton, M., Chen, Y., Solomon, C., & Kovatchev, B. (2007). Linear quadratic gaussianbased closed-loop control type 1 diabetes. Journal Diabetes Science Technology,1.Pineau, J., Gordon, G., & Thrun, S. (2003a). Point-based value iteration: anytime algorithmPOMDPs. Proceedings International Joint Conference Artificial Intelligence(IJCAI), Vol. 18, pp. 10251032.Pineau, J., Gordon, G., & Thrun, S. (2003b). Policy-contingent abstraction robust robot control.Proceedings Conference Uncertainty Artificial Intelligence (UAI).Platt, R., Tedrake, R., Lozano-Perez, T., & Kaelbling, L. (2010). Belief space planning assumingmaximum likelihood observations. Proceedings Robotics: Science Systems (RSS).Porta, J., Vlassis, N., Spaan, M., & Poupart, P. (2006). Point-based value iteration continuousPOMDPs. Journal Machine Learning Research, 7, 23292367.Poupart, P. (2005). Exploiting Structure Efficiently Solve Large Scale Partially ObservableMarkov Decision Processes. Ph.D. thesis, University Toronto.Richards, A., Kuwata, Y., & How, J. (2003). Experimental demonstrations real-time MILP control. Proceeding AIAA Guidance, Navigation, Control Conference (GNC).Ross, S., & Chaib-draa, B. (2007). AEMS: anytime online search algorithm approximatepolicy refinement large POMDPs. Proceedings International Joint ConferenceArtificial Intelligence (IJCAI), pp. 25922598.Ross, S., Pineau, J., Paquet, S., & Chaib-draa, B. (2008a). Online planning algorithms POMDPs.Journal Artificial Intelligence Research, 32(1), 663704.569fiH E , B RUNSKILL , & ROYRoss, S., Chaib-draa, B., & Pineau, J. (2008b). Bayesian reinforcement learning continuousPOMDPs application robot navigation. Proceedings International Conference Robotics Automation (ICRA). IEEE.Scott, A., Harris, Z., & Chong, E. (2009). POMDP framework coordinated guidanceautonomous UAVs multitarget tracking. EURASIP Journal Advances Signal Processing, 2009, 117.Smallwood, R., & Sondik, E. (1973). optimal control partially observable Markov processesfinite horizon. Operations Research, 21(5), 10711088.Smith, T., & Simmons, R. (2005). Point-based POMDP algorithms: Improved analysis implementation. Proceedings Conference Uncertainty Artificial Intelligence (UAI).Stolle, M., & Precup, D. (2002). Learning options reinforcement learning. Lecture NotesComputer Science, 212223.Sutton, R., Precup, D., & Singh, S. (1999). MDPs semi-MDPs: frameworktemporal abstraction reinforcement learning. Artificial Intelligence, 112, 181211.Theocharous, G., & Kaelbling, L. (2003). Approximate planning POMDPs macro-actions.Advances Neural Processing Information Systems (NIPS).Triantafyllopoulos, K. (2003). central moments multidimensional Gaussian distribution. Mathematical Scientist, 28, 125128.West, M., Harrison, P., & Migon, H. (1985). Dynamic generalized linear models Bayesianforecasting. Journal American Statistical Association, 80(389), 7383.Yu, C., Chuang, J., Gerkey, B., Gordon, G., & Ng, A. (2005). Open-loop plans multi-robotPOMDPs. Tech. rep., Stanford University.570fiJournal Artificial Intelligence Research 40 (2011) 657-676Submitted 12/10; published 03/11Complexity Integer Bound PropagationLucas Bordeauxlucasb@microsoft.comMicrosoft Research, 7 J J Thomson Avenue, CB30FBCambridge, UNITED KINGDOMGeorge Katsirelosgkatsi@gmail.comLRI, Universite Paris-Sud 11Paris, FRANCENina Narodytskaninan@cse.unsw.edu.auNICTA Neville Roach LaboratoryUniversity New South Wales223 Anzac Parade Kensington NSW 2052, AUSTRALIAMoshe Y. Vardivardi@cs.rice.eduRice University, P. O. Box 1892Houston, TX 77251-1892, U.S.A.AbstractBound propagation important Artificial Intelligence technique used ConstraintProgramming tools deal numerical constraints. typically embedded withinsearch procedure (branch prune) used every node search tree narrowsearch space, critical fast. procedure invokes constraintpropagators common fixpoint reached, known algorithmspseudo-polynomial worst-case time complexity: fast indeed variablessmall numerical range, well-known problem prohibitivelyslow ranges large. important question therefore whether stronglypolynomial algorithms exist compute common bound consistent fixpoint setconstraints. paper answers question. particular show fixpointcomputation fact NP-complete, even restricted binary linear constraints.1. Introduction Overview Main ResultsConstraint solvers typically solve problems interleaving search propagation. Propagation iterative procedure which, iteration, propagates every constraintproblem narrow domains variables. iteration stops constraintchanges domains variables. case, propagation reached common fixpoint constraints. iterative algorithm guaranteed compute fixpointpolynomial time propagating constraint takes polynomial time domainsvariables defined lists values. often, however, inconvenient infeasible list values explicitly: instead domains defined lower upper bounds.focus representation, variables taking integer values. setting,computing fixpoint iterative algorithm may require exponential time evenconstraint propagated polynomial time. show exponential behavioursimply due iterative algorithm suboptimal; rather intrinsicc2011AI Access Foundation. rights reserved.fiBordeaux, Katsirelos, Narodytska, & Vardiproblem computing fixpoint, NP-complete even system constraintsrestricted binary linear inequality constraints.1.1 Bound Propagation Slow Convergenceillustrate behaviour iterative fixpoint algorithm using system two constraints:x + = 7, x + 1 2y,initial bounds:x [0, 5], [0, 10]possible trace fixpoint computation following. lower boundinitially 0 constraint x + = 7 deduce cannot take values 0 1:does, sum < 7, even fix x highest allowed value. Thereforeintervals narrowed x [0, 5], [2, 10]. Similarly:x + = 7,x + 1 2y,backx + = 7,deduce:deduce:and:deduce:x [0, 5],x [3, 5],x [3, 5],x [4, 5],[2, 7];[2, 7];[2, 3];[2, 3].point reached common fixpoint constraints, cannotdeduce domains need narrowed further.algorithm, however, exhibits slow convergence behaviour even deceivingly simpleexamples as:x < y, < xinitial bounds:x [0, 108 ], [0, 108 ](1)iterative algorithm fixpoint computation shrinks bounds one unititeration, means 108 iterations required reach fixpoint,case empty. slow convergence fact exponential size problemrepresentation, log(108 ) bits enough represent bound. behaviourlimited artificial examples previous one fact happens timesolving problems large numerical ranges. severely limits application CPareas software verification theorem proving large ranges needed (e.g.,whole 32-bit integer range).Due importance problem, efforts made alleviate slow convergence, notably Jaffar, Maher, Stuckey, Yap (1994), Lhomme, Gottlieb, Rueher,Taillibert (1996), Lebbah Lhomme (2002), Leconte Berstel (2006); proposedalgorithmic improvements prevent slow convergence specific cases. Fully addressingslow convergence problem would require strongly polynomial algorithm fixpointcomputation. Therefore question is: algorithm exist, bound propagation fact intractable?1.2 Prior Complexity Results PropagationStandard propagation algorithms iterative processes apply propagators, i.e., narrowing functions associated constraint, reaching fixpoint. complexitytherefore determined two complementary questions:658fiThe Complexity Integer Bound PropagationQ1: hard compute propagator?Q2: hard find common fixpoint propagators?complexity constraint propagation sense extremely well-studied,results aware bound propagation deal Question 1 only. priorhardness results showed complex constraints cannot polynomial-timepropagators reaching certain levels consistency. Two results are:Given linear equality observed (Yuanlin & Yap, 2000; Choi, Harvey,Lee, & Stuckey, 2006) propagator reaches arc consistency bound(Z)consistency1 needs solve knapsack problem, NP-complete weaksense. reason propagators linear constraints used practice either reachweaker consistency bound(R) consistency, restricted smalldomains, proposed instance Trick (2001).Results Bessiere (2006) prove even bounded-arity (two-variable) constraintsconstructed checking bound(Z) consistency NP-complete.Question 2 makes sense, course, common case propagatorspolynomial-time computable (if not, computing common fixpoint cannoteasy general). known fact case standard, iterative propagationalgorithms often take exponential number steps reach fixpoint practice,mentioned illustrated Section 1.1. leaves open question whether betteralgorithms exist fixpoint computation is, fact, intrinsically hard.1.3 Main Resultspaper consider simple, common propagators address Question 2.show general even surprisingly simple propagators lead fixpoint computation problem NP-hard. explains standard, iterative fixpointcomputation algorithms exponential worst-case practice, also shows unlikely exists algorithm better worst case. particular importantclass simple propagators whose fixpoint computation NP-hard bound(R) consistency propagators linear constraints (Proposition 1). ubiquitous constraints,weak widely used propagators constraints. Many problemsuse numerical computations large domains tend include least linear constraints,therefore cases slow convergence avoidable. neverthelessidentify one case: coefficients linear constraints unit (1 absolutevalue), bound(R) consistency obtained polynomial time non-standardpropagation algorithm based Linear Programming. also study types basicnumerical constraints: multiplication max.1.4 OutlineSection 2 summarize required material Constraint Satisfaction Problemsbound propagation. Section 3 focuses linear constraints. prove1. give formal definitions bound(R) bound(Z) consistency Section 2.2.659fiBordeaux, Katsirelos, Narodytska, & Vardiaforementioned Proposition 1, identify restricted forms linear constraintspropagation tractable. Section 4 presents results basic propagators:quadratic constraints, hardness result strengthened holds even fixednumber variables; max constraints, fixpoint computation interesting complexity(between P NP-complete) proved equivalent important open problem;last comment max-closed constraints. conclude Section 5.2. Formal Backgroundsection summarize required material Constraint Satisfaction Problemsbound propagation. details material found papers e.g. SchulteCarlsson (2006), Bessiere (2006).2.1 Constraint Satisfaction ProblemsConstraint Satisfaction Problem (CSP) triple hX, D, Ci, where: X = {x1 xn }set variables, = {D1 Dn } set finite domains (finite sets values), onevariable, C set constraints. paper consider discrete domains:elements integers. moment simply define constraints generallylogical predicates subsets X; later paper consider specific typesconstraints, instance linear ones. assignment function assigns value(xi ) Di every variable xi . solution CSP assignment satisfiesconstraints. Throughout paper, keep following conventions:n = |X| denotes number variables;= |C| number constraints;= maxi1..n |Di | size largest domain.important note Di may represented interval, rather explicitset values. work, consider domains represented intervals: domainform Di = [li , ui ], li ui lower upper bounds domain.2.2 Propagators Notions Bound Consistencyconstraints problem associated propagators. (In settingbe, general, several propagators per constraint.) follow classical presentationpropagators operators lattice, initiated work Benhamou (1996)details found papers Apt (1999), Schulte Carlsson (2006):propagator function narrow domains (some of) variables, removingvalues cannot appear solution. Thus, talk current domainvariable xi , result narrowed application one propagators.+denote xcurrent lower bound xi xi current upper bound. xi+xi initially set initial bounds li , ui remain afterwards constrained+li xxi ui . denote Cartesian product intervals [li , ui ]1..n.660fiThe Complexity Integer Bound PropagationDefinition 1 (Propagator) propagator constraint k 1..m function f :P(D) P(D), is:monotone, i.e., A0 f (A0 ) f (A);contracting, i.e., f (A) A;correct, i.e., point \ f (A) satisfies constraint.restrict propagators polynomial-time computable. Bound consistency propagators additionally restricted elements P(D) representableCartesian products intervals, plus special value .Several types propagators used numerical constraints; propagatorscharacterized level consistency enforce. Since restrictedfocus interval domains, present bound consistency. two main variantsbound(Z) bound(R) consistency:Definition 2 (Bound(Z|R) support) bound(Z) (bound(R)) support constraint k+assignment integer (real) values variables X x(xi ) xi1..n satisfies constraint k.Definition 3 (Bound(Z|R) consistency) constraint k bound(Z) (bound(R)) consistent iff every variable xi X, exists bound(Z) (bound(R)) support+ + (x ) = x+ .(xi ) = xbound(Z) (bound(R)) supportdifference two easily understood example:Example 1 Consider constraint 2x + 2y + 3z = 4.intervals x, y, z [0, 1] bound(R) consistent since integer boundsreal-valued support: x = 0 supported tuple (x = 0, = 1, z = 2/3);z = 1 = 0 tuple (x = 1/2, = 0, z = 1); x = 1, = 1 z = 0tuple (x = 1, = 1, z = 0).intervals are, however, bound(Z) consistent: integer solution(x = 1, = 1, z = 0), means bound(Z) consistency would reduce boundsx [1, 1], [1, 1], z [0, 0].Bound(Z) consistency requires check existence integer-valued support,classes constraints linear equalities propagator would needsolve NP-complete problem. Since focus computation common fixpointsimple operators, consider bound(R) consistency paper. noted previouslyliterature (Schulte & Stuckey, 2005), bound(R) consistency fact boundconsistency implemented primitive constraints, precisely oftenone propagators easy compute general large domains.rest paper focus several main basic types numerical constraints (inparticular linear ones), give details bound(R) consistency propagatorsobtained constraints. cases consider propagators simpleindeed.661fiBordeaux, Katsirelos, Narodytska, & Vardi:=change := truechangechange := falseforeach f FoldA :== f (A)6= oldA change := truedonedoneFigure 1: simple fixpoint computation algorithm.2.3 FixpointsPropagators monotone narrowing operators, thus may consider problem identifying greatest common fixpoint set propagators.Definition 4 (Greatest Common Fixpoint) greatest common fixpoint gfp(F )set propagators F largest Cartesian product intervalsoperator f F , f (A) = A.two computational problems related fixpoints:Function Problem: Effectively compute gfp(F );Decision Problem: Decide whether gfp(F ) 6= , i.e., whether exists (nonempty) fixpoint. (Note definition propagators implies f () =f F . Therefore always common fixpoint.) words: propagatorsstabilize non-empty domains?often complexity work mostly focus Decision problem paper.reason basic complexity classes (NP particular) defined decisionproblems, hardness results decision problem also imply functionproblem hard. place refer function problem section,describe basic greatest fixpoint computation algorithm.algorithm computing gfp(F ) specified Fig. 1. presented simplestform, excludes several possible optimizations related, particular, factconstraints necessarily deal variables. (These optimizations well-knownorthogonal discussion paper.) algorithm initialize Cartesian+product domains D, words initially x= li xi = ui ,1..n; simply apply propagators stable state reached, i.e.,propagator shrinks domain further. reader verify algorithm specifiesformally reasoning presented informally introductory example (Sec. 1.1).662fiThe Complexity Integer Bound Propagation2.4 Complexity Upper Bound Fixpoint Propagationworst-case time upper bound fixpoint computation analyzed follows2 .Let p = |F | number propagators. (Note general onepropagators per constraint, i.e., p m.) enter loop nd times sinceevery new iteration must reduce least one bound one unit, timeforeach loop entered p times. Overall algorithm therefore terminatesnumber propagator applications of:O(npd).words, fact exponential number bits encoding: complexitywritten O(np2b ), b number bits bound encoding. despitefact propagator polynomial size encoding. algorithmscalled pseudo-polynomial. contrast algorithms truly polynomial numberbits encoding, i.e., whose worst-case time complexity O((n, m, log d)),polynomial , called strongly polynomial (Papadimitiou, 1994). problempseudo-polynomial algorithm problem scales linearly sizedomains, may exponentially large. Since propagators considertake strongly polynomial time, analyis upper bound summarized follows:Observation 1 naive fixpoint computation algorithm (Fig. 1) always terminatespseudo-polynomial-time.question whether strongly polynomial algorithms exist. rest paperfocusses question, several classes propagators.3. Linear Constraintssection consider linear inequalities, i.e., set constraints C containsinequalities form:Xai,k xi ck ,k 1...m(2)i1...nck ai,k integers. convenient introduce extra notation:denote si,k sign ith term constraint k, i.e.,:si,k =(+ ai,k 0ai,k < 0(3)Moreover, given sign {, +}, sign defined + =otherwise. sign +s simply denote s. notation terms ai,k xi i,k+s+ai,k xi i,k simply represent smallest largest elements set {ai,k v | v [x, xi ]}.2. papers give explicit upper bounds complexity computing fixpoint set boundconsistency propagators. earliest reference aware work Lhomme (1993);considers constraints reals assumes finite precision (floating points), analysis directlyadapts discrete intervals.663fiBordeaux, Katsirelos, Narodytska, & Vardi3.1 Bound(R) Consistency Propagators Linear Inequalitiesbriefly summarize material need bound(R) consistency case linearinequalities. refer reader literature details, particular papersHarvey Stuckey (2003), Schulte Carlsson (2006), Bessiere (2006), AptZoeteweij (2007) substantial material bound(R) consistency linear constraints.Also interest works show improve bound propagation long linearconstraints (Harvey & Schimpf, 2002; Katriel, Sellmann, Upfal, & Van Hentenryck, 2007).Consider variable xi . bound xi i,k bound(R) inconsistent w.r.t. kth inequalitysystem iff: even fix terms maximum, obtain somethinglower ck . bound consistent opposite true i.e., iff:+s1,ka1,k x1+ssi,k+ . . . + ai1,k xi1i1,k + ai,k xi+sn,k+s+ ai+1,k xi+1i+1,k + . . . + an,k xnck(4)call bound consistency inequality variable xi w.r.t. constraint k.bound consistency propagator linear inequality simply shrinks boundsvariable xi . Let:X+saj,k xj j,kqi,k = ckj[1,n], j6=iminimal quantity reached ai,k xi i,k satisfy bound consistencyinequality (in words: xi bound consistent w.r.t. constraint k iff ai,k xi i,k qi,k ).(bound(R) consistency) propagator associated constraint k 1..m variable1..n function reduces bound xi closest bound consistent value.defined following pseudo-code:ai,k > 0 x:=Li,k :ai,k < 0x+:=ljmax x,minx+,qi,kai,kqi,kai,k(5)k(The propagator nothing ai,k = 0.)3.2 NP-completeness Integer Fixpoint Computationprove propagators Li,k introduced previous sub-section (Eq. 5),although simple considered independently, give rise complex fixpoints.precisely, show NP-completeness following decision problem:Decision Problem 1 (Bound(R)-Consistency Linear Constraints)INPUT: CSP whose set constraints C linear inequalities.QUESTION: Let F = {Li,k : 1..n, k 1..m} set bound(R) consistency propagators associated CSP. propagators F non-empty common fixpoint?3.2.1 Characterising Fixpoints Inequalitiesfirst observation bounds obtained fixpoint reached characterizedbound consistency conditions Eq. 4. words fixpoint reached iff664fiThe Complexity Integer Bound Propagation+lower upper bounds xxi satisfy following inequalities, variableconstraint k:+s+s1,k+s+s+ .. + ai1,k xi1i1,k + ai,k xi i,k + ai+1,k xi+1i+1,k + .. + an,k xn n,k cka1,k x1lixx+k 1 . . . m, 1 . . . n1 . . . nui(6)clear Decision Problem 1 answered positively iff integer values+bounds xxi , 1..n, satisfy Linear Program 6. (If fixpoint existsbounds given fixpoint satisfy inequalities within initial boundsli , ui . Conversely inequalities satisfied fixpoint.)first consequence Decision Problem 1 membership NP straightforward since solvable Integer Programming.3.2.2 Linear Inequalities Two-Variables-Per-inequalitykey understanding Decision Problem 1 hard connect fixpoint computationspecial case Integer (Linear) Programming constraints Two VariablesPer Inequality (TVPI LP terminology, see Bar-Yehuda & Rawitz, 2001):Definition 5 TVPI instance constraints n variables Integer LinearProgram following form:(ak xik + bk xjk ck k 1 . . .li xi ui1 . . . na, b, c vectors arbitrary (possibly negative) integers.feasibility TVPI constraints NP-complete3 decided pseudopolynomial time. early pseudo-polynomial time algorithm found workAspvall Shiloach (1980); algorithm essentially reduces problem 2-SATinstance size d, solvable linear time (the overall algorithm thereforeruns pseudo-polynomial time, also pseudo-polynomial space requirement).particularly relevant algorithm TVPI constraints proposed work BarYehuda Rawitz (2001). algorithm pseudo-polynomial time complexitylow, strongly polynomial space requirements. Interestingly, algorithm essentially usesbound propagation (in fact, precisely bound(R) consistency), embeds amountsbacktrack-free search parallel improvement allows amortize overallruntime.seems suggest strong relation propagation TVPI constraints;particular one could easily mistaken believe propagation decision proceduresystems TVPI constraints. say propagation provides decision procedureclass constraints propagation fails exactly constraints unsatisfiable (in3. focus feasibility only. optimization problem, i.e., optimizing linear functionTVPI constraints, strongly NP-hard, i.e., NP-hard even bounded domain sizes (in fact domains{0, 1} enough), trivially encodes Max-2SAT (Bar-Yehuda & Rawitz, 2001).665fiBordeaux, Katsirelos, Narodytska, & Vardiwords: existence bound consistent state suffices guarantee existencesolution). usual condition guarantees backtrack-free search;propagation rarely achieves general case fact decision procedureTVPI constraints:Example 2 Consider problem x + = 1, x = x, [0, 1]. probleminconsistent yet bound(R) consistent (and also, fact, bound(Z) consistent).prove main result need identify restricted case TVPI constraintsfixpoint computation indeed decision procedure. particular casemonotone TVPI constraints, two variables inequality coefficientsopposite signs, i.e., problem following form:Definition 6 monotone TVPI instance constraints n variables Integer Linear Program following form:(ak xik bk xjk ck k 1 . . .li xi ui1 . . . nak 0, bk 0, k 1 . . . m.prove NP-hardness result monotone TVPI constraints, usingfollowing result:Theorem 1 (Lagarias, 1985) feasibility Two-Variable-Per-Inequality monotone Integer Programming NP-complete.3.2.3 NP-hardnessprove Decision Problem 1 NP-hard. already know NP,therefore state main result bound(R) consistency linear constraints as:Proposition 1 Decision problem 1 NP-complete.Proof. show fixpoint computation decides systems monotone TVPI constraints.Consider monotone TVPI instance Q form given Def. 6. want showequivalence: Q integer solution iff set bound(R) consistency propagatorsobtained Q non-empty common fixpoint.Q integer solution means exist integer values vi variablexi satisfying li vi ui and, k 1 . . . m:ak vik bk vjk ck(7)+exists common fixpoint means bounds x, xi , found+1 . . . n, satisfying li xi xi ui and, k 1 . . . m:ak xik bk xjk ck+ak x +ik bk xjk ck(8)(These simply constraints Eq. 6 variable xik (left) xjk (right),rewritten taking account > 0, b > 0.)666fiThe Complexity Integer Bound Propagationprove two directions iff:Consider integer solution Q variable xi takes value vi . easy++verify bounds x= xi = vi satisfy li xi xi ui Eq. 8.+Consider bound consistent state described bounds x, xi . easy verifysolution v defined vi = x+, 1 . . . n satisfies li vi ui Eq. 7.means reduce problem monotone TVPI feasibility existencefixpoint, Decision Problem 1 therefore NP-hard. 2Note NP-hardness result Decision Problem 1 holds even (monotone)TVPI constraints, pseudo-polynomial upper bound Section 2.4 holds generallinear constraints unbounded sizes; said earlier membership NP also validgeneral linear constraints.3.3 Comment Linear Equalitiesbeginning section focused linear inequalities reasonsbecome clear sub-section. Readers may wonder whether considering equalitieswould make difference. short answer no.Pfirst observation inequality i1...n ai xi c directly encodedPPequality i1...n ai xi = c new variable ranging [0, u] u > ai xi+si ,bijection solutions two constraints. Therefore problempropagating inequalities reduces problem propagating equalities, NPcompleteness result still holds problems whose linear constraints equalities (ormix equalities / inequalities).second observation following: focus bound(R) consistency,Ppropagation obtained equality i1...n ai xi = c one obtained usingPPtwo constraints i1...n ai xi c i1...n ai xi c. reason convenientassume constraints homogeneous form, restrict linearinequalities4 .3.4 Tractable Classes Linear ConstraintsIntractable problems often become tractable additional restrictions imposedtopology constraint graph, constraints themselves. subsectionidentify one significant class linear constraints propagated stronglypolynomial time, based restriction coefficients constraints.initial observation one source complexity propagators Li,k Eq.5 use rounding: update variables bounds, obtainvariables real value rounded upwards lower bounds downwards upperbounds. effects rounding noticed previous authors used optimize4. Note also case inequalities propagators bound(Z) consistencybound(R) consistency. Since want propagators polynomial-time computable, case wantavoid however bound(Z) consistency linear equalities, cannot define polynomial-timecomputable propagators unless P=NP.667fiBordeaux, Katsirelos, Narodytska, & Vardipropagation (Harvey & Stuckey, 2003). Rounding effectively means propagation stabilizes integral solutions Linear Programs. Linear Programs questionspecific form, intractability due integrality. Therefore sub-section(1) observe remove rounding, problem becomes tractable; (2) useobservation show coefficients unit (i.e., belong {1, 0, +1}),effectively rounding, means tractability result holds.3.4.1 Linear Propagators without Roundingconsider operators similar Eq. 5 without rounding, wordsassociate linear constraints following operators:ai,k > 0 x:=Si,k :ai,k < 0x+:=qi,kmax x, ai,kminqi,kx+, ai,k(9)Even initial bounds integers assumed throughout paper,operators general reduce bounds real-values. Note propagatorseffectively used deal variables real-valued domain, indeed usedConstraint Programming community (Behamou & Granvilliers, 2006)Operations Research community, different terminology used (Feasibility-BasedBounds Tightening, see e.g. Belotti, Cafieri, Lee & Liberti, 2010).decision problem focus whether exist real-valued boundsfixpoint. note problem tractable; similar result reportedindependently work Belotti, Cafieri, Lee, Liberti (2010).Decision Problem 2 (Fixpoint Continuous Linear Propagators)INPUT: CSP whose set constraints C linear inequalities.QUESTION: set real-valued propagators F = {Si,k : 1..n, k 1..m} associated C common fixpoint?Observation 2 Decision problem 2 decided Linear Programming.easy see fixpoints operators Si,k exactly real-valued solutionssystem linear constraints Eq. 6. Note careful statementObservation 2: whether Linear Programming strongly polynomial fact longstanding open question (Smale, 1998). best polynomial-time LP algorithms are,encouragingly, time complexity O((n, m, b)) polynomial , bnumber bits number encodingthis looks strongly polynomial (Khachian, 1979).catch: complexity counted number operations, operationsrationals principle expand size numbers (repeated multiplicationsblow-up representation exponentially). However, practical purposes, typical LPimplementations prevent blow-up number representation limiting precisionb bits throughout execution; solvability Linear Programming widely regardedsynonymous strong tractability, provably sub-exponential LP algorithms exist(Matousek, Sharir, & Welzl, 1996). words, Observation 2 really readcarefully phrased way say Problem 2 efficiently solvable practice.668fiThe Complexity Integer Bound Propagation3.4.2 Linear Constraints Unit Coefficientsunit linear constraint usual form i1...n ai,k xi ck additionalrestriction coefficient ai,k chosen {1, 0, +1}. introductory exampleslow convergence (Eq. 1) (particularly simple) example unit linear constraints,slow convergence could particular case avoided. Note consideringlinear unit constraints number variables. special case unit constraintswidely studied class unit-TVPI constraints (i.e., unit TVPI).perhaps important class linear constraints whose integer feasibilitysolved strongly polynomial time, see instance work Jaffar et al. (1994).PProposition 2 constraints unit coefficients, Decision Problem 1decided Linear Programming.Proof. LP is, course, form given Eq. 6. observation is, short,rounding needed coefficients unit.precisely, Cartesian product intervals A, let L(A) = i,k Li,k (A)S(A) = i,k Si,k (A). show coefficients unit (as defined)bounds initial Cartesian product integral, Lt (D) = (D),0. first note bounds Lt (D) integral since originalstate integral bounds operator L applies rounding. equalityLt (D) = (D) proved induction t. = 0, Lt (D) = (D) = D.induction hypothesis holds step t, t+1 (D) = S(S (D)) = S(Lt (D)).t+1 (D) = L(Lt (D)) = Lt+1 (D) Lt (D) integral bounds, hence applying LCartesian product gives result. (In Eq. 5 qi,k integral caseai,k unit therefore division qi,k /ai,k gives integer, meanspropagators Li,k rounding return result non-rounded propagators Si,kEq. 9.)Lt (D) = (D), 0 easy see gfp{Li,k } = gfp{Si,k }.domains finite Lt (D) stabilizes finite t. particular t, Lt (D)greatest fixpoint L greatest Cartesian product (D) also greatestfixpoint S. 2Note general Linear Programming necessarily find integer solutionssystem Eq. 6; result shows LP find solution iff integer one+exists. want actually compute largest consistent bounds xxi certain+variable xi , simply minimize xi maximize xi constraints Eq. 6.previous proof shows extremal values integral.3.4.3 Tractable Cases?interesting consider whether properties make propagation solvablestrongly polynomial time. respect restrictions constraint graph,nevertheless reasons pessimistic: note feasibility monotone TVPI IntegerProgramming remains NP-complete strict restrictions constraint graph,shown work Hochbaum Naor (1994). suggests restrictionsunlikely lead interesting tractable classes fixpoint computation.669fiBordeaux, Katsirelos, Narodytska, & VardiRegarding restrictions coefficients, note general NP-completeness(monotone) TVPI constraints assumes coefficients ak , bk , ck arbitrary.Unit restriction imposes, contrary, strongest restriction coefficients:absolute value 1. impose general bound absolute valuesone may wonder whether problem exhibits form fixed-parameter tractability.leave question open future work.4. Generalizations Non-Linear ConstraintsProposition 1, fixpoint computation numerical constraints basic commonlinear constraints intractable. Several cases non-linear constraints nevertheless interest. First, show simplest possible type polynomials (a singlesquaring operation) added linear constraints, general hardness resultstrengthened. Second, interesting note enrich unit linear constraintssimple min max constraints, fixpoint computation equivalent puzzling openproblem discussed recently theorem-proving literature. Last, briefly commentconnections results tractability max-closed constraints.4.1 Quadratic Constraintspurposes section sufficient enrich linear constraint language(constraints form given Eq. 2) squaring constraints form:xi = x2jalso sufficient restrict non-negative values variables xi xj , i.e.,0 li ui 0 lj uj . setting bound(R) consistency propagatorsdefined following instructions:x:= max(xi , xjxj:=max(xj ,2qx)++x+:= min(xi , xjx+j):=min(x+j ,q2x+))words fixpoints integer solutions following bound consistencyinequalities:xxj2;+x+xj2;xjqx;x+jqx+(10)simple quadratic constraints added language linear constraints,NP-completeness result strengthened: problem NP-complete evenconsidering bounded(!) number variables constraints; fact one TVPI constraintone squaring constraint. due fact fixpoint computation convergesstate encodes complex number-theoretic problem.Proposition 3 Given CSP 3 variables 2 constraints a1 x1 + a2 x2 = c, x1 = x23 ,determining whether associated bound(R) consistency propagators fixpointNP-complete.670fiThe Complexity Integer Bound PropagationProof. Membership NP straightforward. show hardness result specialcase ai 0, {1, 2, 3} focus, said, positive intervals. first notebound consistency inequalities (Eq. 10) squaring constraint x1 = x232++ 2satisfied iff x1 = (x3 ) x1 = (x3 ) since focus integer bounds. (This propertysquaring propagator noticed slightly different form Schulte & Stuckey, 2005).propagation viewpoint equality a1 x1 + a2 x2 = c seen two inequalitiesa1 x1 + a2 x2 c a1 x1 a2 x2 c whose bound consistent inequalities (Eq. 4)++effectively satisfied iff a1 x1 + a2 x2 = c a1 x1 + a2 x2 = c.rely theorem (Manders & Adleman, 1978) shows deciding whetherequation form a1 x23 + a2 x2 = c integer solutions, a1 , a2 cnon-negative integers, NP-complete. reduce problem existence boundconsistent bounds conjunction a1 x1 + a2 x2 = c, x1 = x23 initial bounds l1 = l2 =l3 = 0 u1 = u2 = u3 = c. need show fixpoint computation completesystema bound consistent state found iff original equation solution:original equation solution, i.e., pair non-negative integer values++2hv2 , v3 satisfying a1 v32 + a2 v2 = c, define x1 = x1 = v3 , x2 = x2 = v2 ,++x3 = x3 = v3 . bounds 0 xi xi c satisfy boundconsistency conditions Eq. 10 Eq. 4.2+conjunction bound consistent state, i.e., bounds x, xi Eq. 10Eq. 4 satisfied, solution v defined v2 = x+2 v3 = x3 satisfies2original equation a1 v3 + a2 v2 = c.4.2 Connections Max-Atom ProblemAnother common type primitive non-linear constraints form:xh = max(xi , xj )bound(R) consistency propagators constraint following (Schulte &Stuckey, 2005):+ +x+:= min(xi , xh )xh := max(xh , xi , xj )+ +++ ++x+h := min(xh , max(xi , xj )) xj := min(xj , xh )(In fact strictly reach bound(R) consistency one would need additionally checkwhether bounds xh empty intersection bounds one max-edvariables, say xi , case essentially impose constraint xj = xh ;purposes section simpler formulation equivalent.) wordsfixpoints characterized following inequalities:+ +x+h max(xi , xj )+x+xh+x+j xhxh xixh xjfixpoint computation max constraints mixed unit linear constraints interestingcomplexity open problem. Note rounding use671fiBordeaux, Katsirelos, Narodytska, & Vardicoefficients definition bound consistency inequalities, therefore complexityarising rounding NP-complete variants propagation arise here.open problem connect called Max-Atom work Bezem, Nieuwenhuis,Rodrguez-Carbonell (2008); see reference prior problems interestshown equivalent Max-Atom. max-atom constraint form: max(xi , xj )+c xh .work reported Bezem et al. (2008) shows number results feasibilityconjunctions max-atom constraints: (1) significant complexity differenceinteger real feasibility; (2) problem decided pseudo-polynomialtime using amounts fixpoint computation algorithm; (3) problem shortproofs unsatisfiability therefore NPcoNP; meansdifferent nature NP-complete variants. fact, recent result (Atserias &Maneva, 2010) shows complexity Max-Atom equivalent well-known openproblems called mean-payoff games, turn connections important openquestions model-checking: parity games, class games reducible mean-payoff games,equivalent model-checking problem -calculus (Emerson, Jutla, & Sistla, 1993;Jurdzinski, 1998).draw simple connection follows observation bound+ +consistency inequalities upper bounds include constraint x+h max(xi , xj )encode max-atom constraints almost directly.Proposition 4 Bound(R) consistency combination unit linear max constraintssolved polynomial time Max-Atom also solved polynomial time.Proof. reduce Max-Atom instance variables xi , 1 . . . n constraintsfixpoint computation problem simply introduce one fresh variable yk , k 1 . . . m.Let kth constraint form max(xik , xjk ) + ck xhk , rewrites conjunctionmax(xik , xjk ) = yk , yk + ck xhk . lower bounds variables fixed 0Pupper bounds need set k1...m ck small model property (Lemma 2)paper Bezem et al. (2008). bound consistency equations upper bounds directlyencode problem. 24.3 Max-Closed Constraintslast note connection results class max-closed constraintsintroduced Jeavons Cooper (1995) (more in, e.g., Petke & Jeavons, 2009).constraint R(x1 , . . . , xn ) max-closed whenever two solutions hv1 . . . vnhw1 . . . wn i, maximum defined hmax(v1 , w1 ), . . . , max(vn , wn )i also solution.Results Jeavons Cooper (1995) show max-closed constraints tractable:system constraints max-closed, feasibility determined polynomialtime. However note result essentially assumes explicit (or table) representationconstraint, i.e., assumed constraint defined explicitly listingtuples solutions it. contrast important types constraintsnumerical constraints considered paper implicitly defined: knowlist solutions R(x1 , . . . , xn ) verify efficiently whether particular tupleaccepted constraint.672fiThe Complexity Integer Bound PropagationImplicitly-defined max-closed constraints played important role paper:monotone TVPI constraints, considered Section 3.2 Max-atom constraintsconsidered Section 4.2, max-closed, shown respectively Hochbaum Naor(1994), Bezem et al. (2008). sharp contrast case explicitly-defined constraints, resolution implicitly-defined max-closed constraints therefore pseudopolynomial fact intractable, shown special case monotone TVPIconstraints:Observation 3 feasibility implicitly-defined max-closed constraints NP-complete.shown Section 3.2 particular example monotone TVPI constraints,even fixpoint computation implicitly defined max-closed constraints is, fact, NPcomplete general.5. ConclusionReasoning intervals introduced AI literature works Cleary (1987),Davis (1987)5 . substantial body AI work ensued (see, e.g. Hyvonen, 1992);bound computation used finite-domain CP solvers (Schulte & Carlsson,2006).paper theoretically investigated complexity computing commonfixpoint set bound consistency propagators. shown evenpropagators simple, fixpoint computation used algorithmscomplex, indeed NP-complete even restricted constraint class linearmonotone inequalities two variables per inequality. also considered specialclasses constraints, like quadratic constraints max constraints. Finally, identifiedclass constraints, namely, linear inequalities unit coefficients, allows tractablefixpoint computation algorithm.Bound propagation successful widely used technique Constraint Programing.large literature propagating single constraints (Van Hoeve & Katriel, 2006;Bessiere, 2006; Rossi, van Beek, & Walsh, 2006) perhaps surprise priorstudy exists complexity fixpoint computation. NP-completeness fixpointcomputation simple types constraints fundamental somewhat surprisingresult, one sheds light slow convergence phenomena.result also puts bound propagation map AI computational problems:together knapsack constraints forms learning neural nets (Schaeffer &Yannakakis, 1991), one important AI problems awarepseudo-polynomial complexity yet intractable.AcknowledgmentsPreliminary results Bordeaux, Hamadi, Vardi (2007) showed NP-completenesspropagation case quadratic constraints considered (Prop. 3).5. often, good case made similar ideas already present earlier work, particularwork Lauriere (1978). Interval computations course also used areas fixpointcomputation methods consider relate broader theme interval arithmetic pioneered Moore(1966).673fiBordeaux, Katsirelos, Narodytska, & Vardipaper thoroughly revised version whose central result linear constraints newgeneral. Part work done G. Katsirelos, N. NarodytskaM. Vardi visiting Microsoft Research, Cambridge. Part work doneG. Katsirelos employed NICTA, Australia. NICTA funded AustralianGovernments Department Broadband, Communications, Digital EconomyAustralian Research Council. work partially supported ANR UNLOCproject: ANR 08-BLAN-0289-01. Discussions Youssef Hamadi Claude-Guy Quimper gratefully acknowledged. Thanks also anonymous reviewers whose feedbackhelped improve paper.ReferencesApt, K. R. (1999). essence constraint propagation. Theoretical Computer Science(TCS), 221 (1-2), 179210.Apt, K. R., & Zoeteweij, P. (2007). analysis arithmetic constraints integer intervals.Constraints, 12 (4), 429468.Aspvall, B., & Shiloach, Y. (1980). polynomial time algorithm solving systemslinear inequalities two variables per inequality. SIAM J. Computing, 9 (4),827845.Atserias, A., & Maneva, E. (2010). Mean-payoff games max-atom problem. Tech.rep., Universitat Politecnica de Catalunya.Bar-Yehuda, R., & Rawitz, D. (2001). Efficient algorithms integer programs twovariables per constraint. Algorithmica, 29 (4), 595609.Behamou, F., & Granvilliers, L. (2006). Continuous interval constraints. Rossi, F.,van Beek, P., & Walsh, T. (Eds.), Handbook Constraint Programming, chap. 16.Elsevier.Belotti, P., Cafieri, S., Lee, J., & Liberti, L. (2010). Feasibility-based bounds tightening viafixed points. Proc. Int. Conf. Combinatorial Optimization Applications(COCOA), p. Appear.Benhamou, F. (1996). Heterogeneous constraint solving. Proc. Int. Conf. AlgebraicLogic Programming (ALP), pp. 6276.Bessiere, C. (2006). Constraint propagation. Rossi, F., van Beek, P., & Walsh, T. (Eds.),Handbook Constraint Programming, chap. 3. Elsevier.Bezem, M., Nieuwenhuis, R., & Rodrguez-Carbonell, E. (2008). max-atom problemrelevance. Proc. Int. Conf. Logic Programming, Artificial Intelligence Reasoning (LPAR), pp. 4761.Bordeaux, L., Hamadi, Y., & Vardi, M. Y. (2007). analysis slow convergenceinterval propagation. Proc. Int. Conf. Principles Practice ConstraintProgramming (CP), pp. 790797.674fiThe Complexity Integer Bound PropagationChoi, C. W., Harvey, W., Lee, J. H. M., & Stuckey, P. J. (2006). Finite domain boundsconsistency revisited. Australian Conf. Artificial Intelligence, pp. 4958.Cleary, J. G. (1987). Logical arithmetic. Future Computing Systems, 2 (2), 125149.Davis, E. (1987). Constraint propagation interval labels. Artificial Intelligence, 32 (3),281331.Emerson, E. A., Jutla, C. S., & Sistla, A. P. (1993). model-checking fragments-calculus. Proc. Int. Conf. Computer-Aided Verification (CAV), pp. 385396.Harvey, W., & Schimpf, J. (2002). Bound consistency techniques long linear constraints.Proc. CP workshop Techniques Implementing Constraint PropgrammingSystems (TRICS).Harvey, W., & Stuckey, P. J. (2003). Improving linear constraint propagation changingconstraint representation. Constraints, 8 (2), 173207.Hochbaum, D. S., & Naor, J. (1994). Simple fast algorithms linear integerprograms two variables per inequality. SIAM J. Computing, 23 (6), 11791192.Hyvonen, E. (1992). Constraint reasoning based interval arithmetic: tolerancepropagation approach. Artificial Intelligence, 58 (1-3), 71112.Jaffar, J., Maher, M. J., Stuckey, P. J., & Yap, R. H. C. (1994). Beyond finite domains.Proc. Int. Workshop Principles Practice Constraint Programming(PPCP), pp. 8694.Jeavons, P., & Cooper, M. C. (1995). Tractable constraints ordered domains. ArtificialIntelligence, 79 (2), 327339.Jurdzinski, M. (1998). Deciding winner parity games co-UP. Inf. Process.Lett., 68 (3), 119124.Katriel, I., Sellmann, M., Upfal, E., & Van Hentenryck, P. (2007). Propagating knapsackconstraints sublinear time. Proc. (North Amer.) Nat. Conf. ArtificialIntelligence (AAAI), pp. 231236.Khachian, L. (1979). polynomial algorithm linear programming. Doklady Akad. USSR,244, 10931096.Lagarias, J. C. (1985). computational complexity simultaneous diophantine approximation problems. SIAM J. Computing, 14 (1), 196209.Lauriere, J.-L. (1978). language program stating solving combinatorialproblems. Artificial Intelligence, 10 (1), 29127.Lebbah, Y., & Lhomme, O. (2002). Accelerating filtering techniques numeric CSPs.Artificial Intelligence, 139 (1), 109132.675fiBordeaux, Katsirelos, Narodytska, & VardiLeconte, M., & Berstel, B. (2006). Extending CP solver congruences domainsprogram verification. CP Workshop Software Testing, Verification Analysis,pp. 2233.Lhomme, O. (1993). Consistency techniques numeric CSPs. Proc. Int. Joint. Conf.Artificial Intelligence (IJCAI), pp. 232238.Lhomme, O., Gottlieb, A., Rueher, M., & Taillibert, P. (1996). Boosting intervalnarrowing algorithm. Proc.of Joint Int. Conf. Symp. Logic Programming(JICSLP), pp. 378392. MIT Press.Manders, K. L., & Adleman, L. M. (1978). NP-complete decision problems binaryquadratics. J. Computer System Sciences, 16 (2), 168184.Matousek, J., Sharir, M., & Welzl, E. (1996). subexponential bound linear programming. Algorithmica, 16 (4/5), 498516.Moore, R. E. (1966). Interval Analysis. Prentice-Hall.Papadimitiou, C. (1994). Computational Complexity. Addison Wesley.Petke, J., & Jeavons, P. (2009). Tractable benchmarks constraint programming. Tech.rep. CS-RR-09-07, Oxford University Computing Laboratory.Rossi, F., van Beek, P., & Walsh, T. (2006). Handbook Constraint Programming. Elsevier.Schaeffer, A. A., & Yannakakis, M. (1991). Simple local search problems hardsolve. SIAM J. Computing, 20 (1), 5687.Schulte, C., & Carlsson, M. (2006). Finite domain constraint programming. Rossi, F.,van Beek, P., & Walsh, T. (Eds.), Handbook Constraint Programming, chap. 14.Elsevier.Schulte, C., & Stuckey, P. J. (2005). bounds domain propagation leadsearch space?. ACM Trans. Programming Languages Systems(TOPLAS), 27 (3), 388425.Smale, S. (1998). Mathematical problems next century. Mathematical Intelligencer,20, 715.Trick, M. A. (2001). dynamic programming approach consistency propagationknapsack constraints. Proc. Int. Conf. Integration AI TechniquesCP Combinatorial Optimisation Problems (CP-AI-OR).Van Hoeve, W.-J., & Katriel, I. (2006). Global constraints. Rossi, F., Van Beek, P., &Walsh, T. (Eds.), Handbook Constraint Programming, chap. 6. Elsevier.Yuanlin, Z., & Yap, R. H. C. (2000). Arc consistency n-ary monotonic linear constraints. Proc. Int. Conf. Principles Practice Constraint Programming(CP), pp. 470483.676fiJournal Artificial Intelligence Research 40 (2011) 143174Submitted 07/10; published 01/11Automated Search Impossibility TheoremsSocial Choice Theory: Ranking Sets ObjectsChristian GeistUlle Endrisscgeist@gmx.netulle.endriss@uva.nlInstitute Logic, Language ComputationUniversity AmsterdamPostbus 942421090 GE AmsterdamNetherlandsAbstractpresent method using standard techniques satisfiability checking automatically verify discover theorems area economic theory known rankingsets objects. key question area, important applications socialchoice theory decision making uncertainty, extend agents preferences number objects preference relation nonempty sets objects.Certain combinations seemingly natural principles kind preference extensionresult logical inconsistencies, led number important impossibilitytheorems. first prove general result shows wide range principles, characterised syntactic form expressed many-sorted first-orderlogic, impossibility exhibited fixed (small) domain size necessarily extendgeneral case. show formulate candidates impossibility theoremsfixed domain size propositional logic, turn enables us automatically search(general) impossibility theorems using SAT solver. applied space 20principles preference extension familiar literature, method yields total84 impossibility theorems, including known nontrivial new results.1. Introductionarea economic theory known ranking sets objects (Barbera, Bossert, & Pattanaik, 2004; Kannai & Peleg, 1984) addresses question extend preference relation defined certain individual objects preference relation defined nonemptysets objects. question important applications. instance, agentuncertain effects two alternative actions, may want rank relativedesirability two sets possible outcomes corresponding two actions.absence probability distribution possible outcomes, principles methodsdeveloped literature ranking sets objects guide kind decision making (complete) uncertainty (e.g., see Gravel, Marchant, & Sen, 2008; Ben Larbi,Konieczny, & Marquis, 2010). second example applications voting theory.want analyse incentives voter manipulate election, i.e., obtainbetter election outcome misrepresenting true preferences ballotsheet, need able reason preferences case election producetie return set winners (e.g., see Gardenfors, 1976; Duggan & Schwartz, 2000;c2011AI Access Foundation. rights reserved.fiGeist & EndrissTaylor, 2002). scenarios, decision making uncertainty manipulationelections sets tied winners, agents assumed preferences simpleobjects (states world, election outcomes) need extend setsobjects able use extended preferences guide decisions.One line research applied axiomatic method, practised particular socialchoice theory (Gaertner, 2009), problem ranking sets objects formulatedcertain principles extending preferences set preferences axioms. instance,dominance axiom states prefer set {x} set whenever preferindividual object x element (and {x} case x worseelement A); independence axiom states prefer set set B,preference get inverted add new object x sets.intuition, Kannai Peleg (1984) shown that, domain least sixobjects, impossible rank sets objects manner satisfies dominanceindependence. original seminal result field, since 1984small number additional impossibility theorems established.paper develop method automatically search impossibility theoremslike Kannai-Peleg Theorem, enable us verify correctness known resultsdiscover new ones. number reasons useful. First,ability discover new theorems clearly useful whenever theorems (potentially)interesting. also verification known results merits: verification increaseconfidence correctness result (the manual proof may tediousprone errors); verification forces us fully formalise problem domain,often result deeper understanding subtleties; verification theorems newfields (here social economic sciences) help advance discipline automatedreasoning providing new test cases challenges.first time techniques logic automated reasoningapplied modelling verifying results economic theory. briefly reviewnumber recent contributions applying tools social choice theory, closelyrelated problem domain focus paper. lot work concentratedArrows Theorem, establishes impossibility aggregating preferencesgroup agents manner satisfies certain seemingly natural principles (Arrow, 1963;Gaertner, 2009). Agotnes, van der Hoek, Wooldridge (2010), instance, introducemodal logic modelling preferences aggregation, Grandi Endriss(2009) show Arrows Theorem equivalent statement certain setsentences classical first-order logic possess finite model.Besides formally modelling problem domain theorem, alsonumber attempts automatically re-prove Arrows Theorem. One approachencode individual steps known proofs higher-order logic verifycorrectness proofs proof checker. Examples line workcontributions Wiedijk (2007), formalised proof Arrows TheoremMizar proof checker, Nipkow (2009), using Isabellesystem. particularly interesting approach due Tang Lin (2009). authorsfirst prove two lemmas reduce general claim Arrows Theorem statementpertaining special case two agents three alternatives. showstatement equivalently modelled (large) set clauses propositional144fiAutomated Search Impossibility Theorems Social Choice Theorylogic. inconsistency set clauses verified using SAT solver,turn (together lemmas) proves full theorem. Tang Lin ableextend method verification number results social choicetheory also shown method serve useful tool support(semi-automatic) testing hypotheses search new results (Tang & Lin, 2009;Tang, 2010).1 contributions neatly fit broad heading computationalsocial choice, discipline concerned study computational aspects socialchoice, application computational techniques problems social choice theory,integration methods social choice theory AI areas computerscience (Chevaleyre, Endriss, Lang, & Maudet, 2007).starting point developing method automatically proving impossibility theorems area ranking sets objects work Tang Lin (2009).adapted extended approach follows. Rather proving new lemmareducing general impossibility impossibility small domain everytheorem want verify, first contribution broadly applicable result,Preservation Theorem, entails combinations axioms satisfying certainsyntactic conditions, impossibility established domain (small) fixedsize n unravel full impossibility theorem domains size n. ableformulate result, introduce many-sorted first-order logic expressing axiomsrelating preferences individual objects preferences sets objects.able express axioms literature language, facilitates fullyautomated search impossibility theorems within space axioms.show impossibility theorems regarding extension preferencesmodelled propositional logic, provided size domain fixed. Given Preservation Theorem, inconsistency found help SAT solver immediatelycorresponds general impossibility theorem. implemented kind automated theorem search scheduling algorithm exhaustively searches spacepotential impossibility theorems given set axioms given critical domain size n.Together number heuristics pruning search space, approach representspractical method verifying existing discovering new impossibility theorems.Finally, applied method search space defined 20 important preference extension axioms literature, exhaustively searchedspace (of around one million possible combinations) domains eight objects.search resulted 84 (minimal) impossibility theorems. theorem states,particular n 8 particular set axioms , exists preference orderingnonempty sets objects satisfies axioms nobjects domain. 84 theorems minimal sense strict subsetwould still result impossibility (at given domain size n) senseaxioms satisfied domain fewer n objects.84 impossibility theorems found include known results (such Kannai-PelegTheorem), simple consequences known results, well new nontrivial theoremsconstitute relevant contributions literature ranking sets objects. Oneimpossibility combining independence weakened form dominance1. See work Lin (2007) outline general methodology well several examplesapplications domains social choice theory.145fiGeist & Endrisstwo axioms known simple uncertainty aversion simple top monotonicity (seeAppendix A). particularly interesting, (in context characterisationparticular type set preference orders) set axioms previouslyclaimed consistent (Bossert, Pattanaik, & Xu, 2000). later foundmistake, corrected Arlegi (2003), even work establish actual impossibility theorem. certainly demonstrates nontrivial natureproblem. interesting theorems discovered method include variantsKannai-Peleg Theorem involving weakened versions independence axiom, impossibility theorems rely dominance axiom (which integral componentresults field), impossibility theorems critical domainsize n different featuring known results literature.remainder paper organised follows. Section 2 introduces formalframework ranking sets objects recalls seminal result field, KannaiPeleg Theorem. Section 3 prove Preservation Theorem, allows us reducegeneral impossibilities small instances. Section 4 shows model smallinstance sets clauses propositional logic. Building insights, Section 5finally presents method automatically search impossibility theorems, well84 impossibility theorems able obtain using method. Section 6concludes brief summary discussion possible directions future work.Appendix provides list 20 axioms used automated theorem search.reader find additional detail, regarding method impossibility theoremsdiscovered, Masters thesis first author (Geist, 2010).2. Ranking Sets ObjectsRanking sets objects deals question agent rank sets objects,given preferences individual objects. Answers question dependconcrete interpretation assigned sets (Barbera et al., 2004):Complete uncertainty. interpretation, sets considered containingmutually exclusive alternatives final outcome selected laterstage, agent influence selection procedure.Opportunity sets. Here, again, sets contain mutually exclusive alternatives,time agent pick final outcome set herself.Sets final outcomes. setting, sets contain compatible objects assumed materialise simultaneously (i.e., agent receive together).Suppose agent prefers object x object y. first interpretationreasonable assume rank {x} (receiving x certainty) {x, y}(receiving either x y). second interpretation might indifferent{x} {x, y}, simply pick x latter set. third interpretation,finally, might prefer {x, y}, give top x. paper, focusidea complete uncertainty, studied three. importantapplication interpretation voting theory: want analyse whether voterincentive manipulate election often reason preferences146fiAutomated Search Impossibility Theorems Social Choice Theoryalternative outcomes, producing set tied winning candidates (Gardenfors,1976; Duggan & Schwartz, 2000; Taylor, 2002).Next, introduce notation mathematical framework usually employed treatproblems field ranking sets objects (e.g., see Barbera et al., 2004),present aforementioned Kannai-Peleg Theorem detail (Kannai & Peleg, 1984).2.1 Formal FrameworkLet X (usually finite) set alternatives (or objects), (preference) orderdefined. order assumed linear, i.e., reflexive, complete, transitive>,i.e., x >antisymmetric binary relation. denote strict componentx. interpretationxxxconsidered least good decision maker.Similarly, binary relation set nonempty subsets X (denotedX := 2X \{}). relation assumed weak order (reflexive, complete,transitive); later on, however, proof method allow explore weaker assumptionsregarding , too. Like above, use strict component . Additionally,also define indifference relation setting B B B A.X write max(A) maximal element respectmin(A) minimal element respect .2.2 Kannai-Peleg TheoremKannai Peleg (1984) probably first treat specific problem extendingpreferences elements subsets problem right axiomaticfashion. previous work, authors regarded problem side issueproblems, particularly analysis manipulation elections (e.g., seeFishburn, 1972; Gardenfors, 1976), merely axiomatised specific methods extensionwithout considering general problem (e.g., see Packard, 1979).Kannai-Peleg Theorem makes use two axioms, plausibleinterpretation complete uncertainty. First, Gardenfors principle(Gardenfors, 1976, 1979), also known dominance. principle consists two partsrequireselements given set,(1) adding element, strictly better (>)given set produces strictly better set respect order ,elements given set,(2) adding element, strictly worse (<)given set produces strictly worse set respect order .Formally, Gardenfors principle (GF) written following two axioms:(GF1)(GF2)a) {x}((a A)x >a) {x}((a A)x <x X X ,x X X .Second, monotonicity principle called independence, states that,set strictly better another one, adding alternative (whichcontained either sets before) sets simultaneously reverse strict147fiGeist & Endrissorder. equivalent way stating (in light completeness order)require least non-strict preference remains original strict preference (suchbecomes ). formal statement reads follows:(IND)B {x} B {x}A, B X x X \ (A B).get main theorem, present lemma, also due Kannai Peleg(1984). says specific rankings satisfy conditions (GF) (IND).Lemma 1. satisfies Gardenfors principle (GF) independence (IND),{max(A), min(A)} X .Proof. Let nonempty subset X. |A| 2 lemma holds triviallyreflexivity since = {max(A), min(A)}. suppose |A| 3 define:= A\max(A). Note that, |A| 3, set nonempty thus {min(A)} ={min(A )}. repeated application (GF1) get {min(A)} = {min(A )} .add max(A) sides, showing {min(A), max(A)} (IND).completely analogous way get {min(A), max(A)} A+ {min(A)} = (GF2)(IND), A+ := \ min(A).is, Lemma 1 shows ranking subsets completely determinedworst best elements. ready state prove theorem.Theorem 1 (Kannai Peleg, 1984). Let X linearly ordered set |X| 6.exists weak order X satisfying Gardenfors principle (GF) independence (IND).Proof. Let xi , {1, 2, . . . , 6} denote six distinct elements X orderedrespect index, i.e., x1 >x2 >x3 >x4 >x5 >x6 . way contraby >diction, suppose exists weak order X satisfying Gardenfors principle (GF)independence (IND). first claim{x2 , x5 } {x3 }.(1)order prove claim, suppose contrary case, completeness{x3 } {x2 , x5 }. then, (IND), include x6 , yields {x3 , x6 }{x2 , x5 , x6 }. Note together Lemma 1 (and transitivity) implies{x3 , x4 , x5 , x6 } {x2 , x3 , x4 , x5 , x6 },contradicting (GF1). Thus, claim (1) must true follows {x3 } {x3 , x4 }{x4 } (which consequence Gardenfors principle) together transitivity{x2 , x5 } {x4 }. Using (IND) again, add (the far unused) x1 get {x1 , x2 , x5 }{x1 , x4 }. before, fill intermediate elements sets obtain,Lemma 1 transitivity, {x1 , x2 , x3 , x4 , x5 } {x1 , x2 , x3 , x4 }, timecontradicts (GF2).148fiAutomated Search Impossibility Theorems Social Choice TheoryPut differently, Kannai-Peleg Theorem says Gardenfors principle (GF)independence (IND) inconsistent domain six elements. Thus,way extending linear order set least six objects weak ordercollection nonempty sets objects. Kannai-Peleg Theoremalso referred impossibility theorem.Many axioms discussed literature aware two impossibility theorems regarding choice complete uncertainty (Barbera et al., 2004).selection 20 important axioms found Appendix A.3. Reduction Impossibilities Small InstancesKannai-Peleg Theorem applies set X least six elements,proof given (which closely follows original proof Kannai Peleg) worksexhibiting case exactly six elements. fact impossibility theoremapplies larger domains well clear particular case. goalsection prove approach elevated general proof technique:prove general impossibility theorem sufficient establish impossibilities smallinstance. Specifically, prove call Preservation Theorem, sayscertain axioms preserved specific substructures. corollary theoremuniversal reduction step, says non-existence satisfying relationsmall domain shows larger satisfying relation exist either.2work framework mathematical logic order access syntactic well semantic features axioms. Section 3.1, first describe many-sortedlanguage specific problem ranking sets objects, apply techniquesmodel theory prove Preservation Theorem, Section 3.2, universalreduction step corollary. universal step powerful enough cateraxioms literature able formalise language, includinglisted Appendix A.3.1 Many-Sorted Logic Set Preferencesnatural well-understood language problem domain many-sorted (first-order)logic, has, compared first-order logic, different quantifiers (allowingquantification different domains containing elements respective sort),still reducible first-order logic. Apart quantifiers, many-sorted logic practically equivalent first-order logic thus many results (e.g., soundness, completeness,compactness, Lowenheim-Skolem properties, etc.) transferred first-order logicdirectly proven (Manzano, 1996; Enderton, 1972).Many-sorted logic characterised use set different sorts S.structure (or model ) many-sorted logic like one first-order logic,2. universal reduction step plays similar role inductive lemmas Tang Lin (2009) playwork computer-aided proof Arrows Theorem theorems social choice theory.important difference domain ranking sets objects able prove singleresult, allows us perform reductions wide range problems, Tang Linprove new (albeit similar) lemmas every new result tackled.149fiGeist & Endrissseparate domains doms (A) sort instead one single domain.corresponding quantifiers sort s, equipped intuitive semantics:|= x(x) |= (a) doms (A),|= x(x) |= (a) doms (A).that, many-sorted logic analogous first-order logic slight difference separate variable, function, relation symbols different sortscombinations sorts.case, two sorts (S = {, }): elements () sets ().typedemand relation type h, well two relationsh, h, i, respectively. later interpreted usual membershiprelation linear weak orders, respectively. one many relationsfunctions signature, use following time again:Relations:, type h, (intuitively: set inclusion)disjoint, type h, (intuitively: true iff sets disjoint)evencard, type hi (intuitively: true iff cardinality set even)equalcard, type h, (intuitively: true sets cardinality)Functions:, type h, , (intuitively: set union){}, type h, (intuitively: transforms element singleton set)replaceInBy, type h, , (intuitively: replace element set anotherelement; e.g., (A \ {a}) {b})call language many-sorted logic (with two sorts signaturecontaining exactly relations functions) MSLSP (Many-Sorted Logic SetPreferences). Notation-wise sometimes use (the common) infix notationcertain relations functions. instance write B, A, B{x} instead (A, B), (a, A), (A, B) {}(x), respectively. Furthermore,sometimes use negated symbols like x/ (x A) well strict relation symbols(yx), respectively.mean B (B A) xB x >Generally, use (standard model-theoretic) notation Hodges (1997).MSLSP expressive enough formulate many axioms literature (including20 axioms Appendix A) example give representations principleindependence Gardenfors principle (see Section 2.2):Example 1. (IND) formulated MSLSP:B x [(x/ (A B) B) {x} B {x}]150fiAutomated Search Impossibility Theorems Social Choice TheoryExample 2. (GF) formulated MSLSP:a)) {x} A]x [( a(a x >x)) {x}]x [( a(a >axioms, however, straightforward representations MSLSP.concept weak preference dominance, proposed (in slightly stronger form) Sen(1991), example axiom:(WPD)[(|A| = |B| exists bijective function : B(a) B two sets A, B X .Even though obvious way express axiom MSLSP, Puppe (1995)showed (WPD) actually equivalent axiom much closer formalism,calls preference-basedness easily seen expressible MSLSP.3(A \ {a}) {b} X , A, b(PB)b/ A,might, however, case axioms expressible MSLSP all.have, instance, able translate axiom neutrality (Nitzan & Pattanaik,1984; Pattanaik & Peleg, 1984), says manner ranking liftedobjects sets objects depend names objects. axiomusually defined terms function objects objects postulatesinvariant , .whenever(x)(y)x (y)(x)(NEU)xx A, B][A B (A) (B) B (B) (A)]two sets A, B X injective mapping : B X.3.2 Preservation Theorem Universal Reduction Stepfamous Los-Tarski Theorem classical model theory offers weak version resultgoing prove.4 does, however, cover certain axioms thereforefind stronger result classical model theory offer. idea ablepreserve larger class axioms making use problem-specific features: like,instance, element-set framework. Thus, define concepts structure setpreferences well subset-consistent substructures:Definition 1. MSLSP-structure B structure set preferences fulfilsfollowing criteria:`replaceInBy(a, A, b)3. b b/ Ab4. exact statement theorem (for first-order logic) can, example, found Hodges book(1997) Corollary 2.4.2 proof idea relatively simple: contradiction suffices show1 -formulas preserved embeddings (Hodges, 1997, Thm 2.4.1). proof latter proceedsinduction complexity formula critical case existential quantifiercause trouble witnesses lost moving larger structure.151fiGeist & Endriss1. dom (B) 2dom (B) , i.e., domain sort contains sets elementsdomain sort .2. relation symbol type h, interpreted natural way.substructure structure set preferences B structure set preferences,too, called subset-consistent substructure.Note substructure structure set preferences B=B |dom(A) ,i.e., symbol must interpreted restriction interpretation B. Hence,sufficient fulfill first condition subset-consistent substructure B.two semantic conditions suffice extending Los-Tarski Theorem largerclass axioms. axioms treat? Let us lookfollowing (purely syntactic) definition first explain reasons choosingparticular class.Definition 2. class existentially set-guarded (ESG) formulas smallest classMSLSP-formulas recursively defined follows:quantifier-free formulas ESG,(x) 0 (x) ESG, (x) := ( 0 )(x) well 0 (x) := ( 0 )(x)ESG,(y, x) ESG, (x) := y(y, x) ESG sort {, },(y, x) ESG, (x) := y(y t(x) (y, x)), term sortoccur x, ESG.atomic formulas t(x) last condition called set-guards respectivequantifiers.class ESG formulas consists MSLSP-formulas contain set-guardedexistential quantifiers sort , existential quantifiers sort all.Note write (x), necessarily mean containsvariables sequence x = (x0 , x1 , x2 , . . . ), (free) variablesamong x. also use notation [a], sequence elements,mean elements a0 , a1 , a2 , . . . assigned variables x0 , x1 , x2 , . . . .Intuitively, following: axioms allow existential quantifiers (butelements, i.e., sort ) long guarded sub-formulas sayingrespective witness belongs set. sets also unions sets formeddifferent way term t. important part moving structuresubstructure set-guard guarantees witness existential quantifierlost. witness within set (as required set-guard)situated substructure.explain give formal proof claim, let us lookexamples ESG non-ESG sentences:152fiAutomated Search Impossibility Theorems Social Choice TheoryExample 3. axiom (GF1) (and similarly (GF2)) ESG sentence:a(aa(ax[ a(axa)x(quantifier-free)(adding )a) {x}xa) {x} A]x( quantifier-free)(adding ).Considering last line example, one understand removing elements X affect axiom. universal quantifiers restrictiondomain problem anyway. also existential witness lost: supposeremoved set A, would set itself, -domaincontain sets elements -domain (by Definition 1). removedneed witness anymore.one cannot allow arbitrary existential quantifiers without set-guardsseen considering following example, shows simple sentence (withunguarded existential quantifiers) preserved substructures.Example 4. MSLSP-sentence (axiom)x z [x 6= x 6= z 6= z] ,says least three distinct elements -domain structureset preferences, clearly preserved substructures: holds structuresset preferences B least three elements dom (B), fails holdsubstructures less three elements dom (A).examples reader developed understanding ESGsentences preserved substructures cannot allow much more. formalproof Preservation Theorem explain first part further.Note that, apart case existential quantifier, proof essentiallyidentical one direction proof Los-Tarski Theorem many-sorted logic,carried model-theoretic grounds alone. last partproof (the induction step existential quantifier) requires syntactic restriction(to ESG sentences) well semantic restriction (to subset-consistent substructures),latter allow particular problem domain.Theorem 2 (Preservation Theorem). ESG sentences preserved subset-consistentsubstructures, i.e., subset-consistent substructure structure set preferencesB B |= implies |= ESG sentence .Proof. prove stronger statement ESG formulas (instead sentences) inductioncomplexity formula:subset-consistent substructure structure set preferences BB |= [a] implies |= [a] ESG formula (x) tupleelements dom(A) (matching types x).153fiGeist & Endrisslet B structure set preferences subset-consistent substructure A, let (x)ESG formula and, furthermore, let tuple elements dom(A) (matchingtypes x).Quantifier-free Formulas: (x) quantifier-free, routine tedious proof leadsdesired results. One carry nested inductions complexity termsformulas, examples proofs found textbook Model Theory(e.g., see Hodges, 1997, Theorem 1.3.1). First, one shows one induction termsinterpreted substructure interpreted superstructure B, i.e.,tA [a] = tB [a](2)terms t(x). practically immediately follows definition substructure.one proceeds another induction proving atomic formulas holdhold B, i.e.,|= [a] B |= [a](3)atomic formulas (x). typical example, suppose (x) formR(s(x), t(x)), R relation symbol s(x) well t(x) terms (matchingtype R). Assume |= R(s[a], t[a]), i.e., holds RA (sA [a], tA [a]). (2)equivalent RA (sB [a], tB [a]). Since furthermore RA = RB |dom(A) , evenequivalence RB (sB [a], tB [a]), another way saying B |= R(s[a], t[a]).Finally, one proves claim quantifier-free formula carrying inductionsteps conjunction , disjunction negation . Note steprequired directions (3).Conjunction Disjunction: show part conjunction here; onedisjunction completely analogous. (x) form (x) 0 (x) furthermoreB |= [a], [a] 0 [a] must true B. induction hypothesis,carries get |= [a] 0 [a].Universal Quantification: (x) form y(y, x) sort {, }furthermore B |= [a], b sort doms (B) B |= (b, a). Sincedoms (A) doms (B) use induction hypothesis obtain |= (b, a)b doms (A). saying |= y(y, a), i.e., |= [a].Existential Quantification: (x) form y[y t(x) (y, x)], t(x)term sort occur x, furthermore B |= [a], must existelement b dom (B)B |= (y t(x) (y, x)) [b, a], i.e., B |= t(x)[b, a] B |= [b, a].Hence, show b -domain B, followsinduction hypothesis also|= [b, a],since (b, a) tuple elements A.interpreted naturally structure set preferences B and, additionally,cannot occur x, statement B |= t(x)[b, a] boils b tB [a],equivalentb tA [a](4)154fiAutomated Search Impossibility Theorems Social Choice Theorysince tA [a] = tB [a], stated (2).fact b element dom (A) (and dom (B)) implied[a] dom (A), together subset-consistent substructure:()b tA [a] dom (A) 2dom (A)= b tA [a] 2dom (A)= b tA [a] dom (A),() marks point subset-consistency used.Hence, can, indicated before, apply induction hypothesis B |= [b, a]obtain |= [b, a]. Together b tA [a] follows|= y(y t(x) (y, x))[a].way done proof stronger claim (about formulas),implies claim theorem (about sentences).almost ready apply theorem setting. Note first, however,theorem hold axioms ESG, also axiomsequivalent ESG sentence structures set preferences (the reasontruth value structure). refer axiomsESG-equivalent axioms. particular applies sentences logically equivalent(i.e., equivalent structures) ESG sentence.Now, finally state prove corollary applying general result particularproblem domain ranking sets objects.Corollary 1 (Universal Reduction Step). Let set ESG (or ESG-equivalent) axiomslet n N natural number. If, linearly ordered set n elements,exists binary relation = 2Y \ {} satisfying , also linearly ordered setX n elements binary relation X = 2X \ {} satisfies .Proof. Let set ESG (or ESG-equivalent) axioms let n N naturalnumber. Assume linearly ordered set n elements, exists binaryrelation = 2Y \ {} satisfying . way contradiction, suppose X linearlyordered set |X| > n binary relation X = 2X \ {} satisfies .view X X structure set preferences define subset-consistent substructurerestricting X X domain X, |Y | = n := 2Y \ {}.Preservation Theorem ESG(-equivalent) axioms preserved subset-consistentsubstructure Y. Hence, must linearly ordered set (as order axioms ESG)and, furthermore, binary relation satisfying . Contradiction!Remark. say given set ESG axioms, deserves explanation. mean axioms ESG MSLSP. One consider additional relationsfunctions added signature, holds hidden challenges.instance, possible include predicate isWholeSet, true wholedomain only, function ()c complement, even constant symbol X referring whole domain, since three would (in natural interpretation) prevent155fiGeist & Endrisssubstructure: example, X, isWholeSet(Y ) (orequivalently, = X) false X X , true Y. Similarly, run problemsincluding functions like , \ ()c , (in natural interpretation)functions strict sense structure like X X produce empty set,X . Therefore, attention paid adding new relationfunction symbols language order capture axioms.basis Corollary 1 finally hoping for: orderprove new impossibility theorems check existing ones, look basecases (as long axioms involved expressible MSLSP ESG-equivalent).shall see next, small instances efficiently checked computer.4. Representing Small Instances Propositional Logicsmall instances, reduce impossibilities to, need checkedcomputer. requires clever approach direct check far expensive.therefore modify extend technique due Tang Lin (2009).remarkable Tang Lin (2009) able formulate base caseArrows Theorem propositional logic, even though axioms intuitivelysecond-order statements. trick used introduce situations namespreference profiles, transforms second-order axioms first-order statements,(because finiteness base case) translated propositionallogic. going use similar approach since axioms ranking sets objectsstated (somewhat enriched)5 second-order format, too. setting ranking setsobjects will, however, require different treatment (which going discusssequel) since also apply functions like union () singleton set ({}) setselements, respectively, whereas functions needed applied Tang Linssituations. Instead coding operations sets within propositional language,let program generates final formula handle them.section, first show translate axioms ranking sets objectspropositional logic explain instantiate instances axioms fixeddomain sizes computer.4.1 Conversion Propositional Logicexample, consider Kannai-Peleg Theorem (Theorem 1). lightuniversal reduction step (Corollary 1), proving theorem reduces proving small basecase exactly six elements:Lemma 2 (Base case Kannai-Peleg Theorem). Let X linearly ordered setexactly 6 elements. exists weak order X satisfying Gardenforsprinciple (GF) independence (IND).might seem tempting perform direct check involved axioms weakorders nonempty subsets six-element space. This, however, seenpractically impossible around 1.525 1097 orderings (Sloane, 2010, integer5. also order (i.e., relation) sets.156fiAutomated Search Impossibility Theorems Social Choice Theorysequence A000670). Therefore, stick idea transforming axiomsKannai-Peleg Theorem propositional logic checked SATsolver, usually operates propositional formulas conjunctive normal form (CNF)only. describe following instances axioms, like ones statedAppendix A, converted language.sufficient formalisation two kinds propositions only: w(A, B)l(x, y) (corresponding propositional variables wA,B lx,y ) intended meaningsranked least high B weak order (or short: B), x ranked(or short: xy), respectively. example,least high linear orderbase case Kannai-Peleg Theorem leads maximum |X |2 + |X|2 =(26 1)2 + 62 = 4005 different propositional variables.indicated earlier, axioms linear weak orders X X , respectively,entirely unproblematic contain first-order quantifications and, thus,easily transformed. example, include transformation transitivityaxiom orders sets:(TRANS )(A X )(B X )(C X ) [A B B C C]^ ^ ^[wA,B wB,C wA,C ] .=AX BX CXNote, that, due finiteness X (and thus X ), derived formulas actuallyfinite objects therefore instantiated hand (requiring lot effort) usingcomputer. Furthermore, little work needed convert CNF.axioms, like (GF) (IND), appear difficult transformfunctions like singleton set {} : X X set union : X X X , occurwithin axioms. fact, however, simple conversion techniqueapplied since going take care (and similar) functions automaticallycomputer program instantiation axioms. brieflydescribed Section 4.2 treat terms like Bcorresponding objects functions range, i.e., images respective functions.example, leads following conversion (GF1):(GF1)a) {x} A](A X )(x X)[((a A)x >"!#^ ^^lx,a la,x wA{x},A wA,A{x}=AX xXaA"!^ ^_AX xXaAlx,a la,x!wA{x},A!_lx,a la,x!#wA,A{x},aAlast step serves purpose converting CNF.remaining problematic parts formula propositional variable index{x}, disjunction domain criterion A. order write formulaexplicitly (which need able feed SAT solver) determineset represented A{x} also decide whether X. differentwords, need explicit access elements set also able157fiGeist & Endrissmanipulate them. would theoretically possible hand; practically, however,instantiation formula far large written manually. Therefore,need computer program final conversion step, going describefollowing section.second example, consider axiom independence (IND), alsotransformed fashion first using finiteness replace quantifiers,normalising formula CNF:(IND)(A, B X )(x X \ (A B)) [A B {x} B {x}]^^(wA,B wB,A ) wA{x},B{x}=A,BXxXx(AB)/^^A,BXxXx(AB)/wA,B wB,A wA{x},B{x} .problematic terms x/ (A B), {x} B {x}. But, see,like critical terms mentioned handled program.method translation easily extends axioms, particularlisted Appendix (Geist, 2010).4.2 Instantiation Axioms Computerindicated above, make use computer program order write formulasderived explicitly. briefly discuss ideas implementation and,particular, methods employed cater previously problematic expressions,{x} A. Full details implementation given Geist (2010).widely used SAT solvers work input files written according DIMACSCNF format (DIMACS, 1993). words, format requires propositional variables represented natural numbers (starting 1, since 0 used separator)minus (-) front negated literals. Furthermore, whole file needsCNF; contain exactly one clause per line.achieve formulation axioms target format, main idea fixenumeration propositional variables (of type lx,y wA,B x, XA, B X ) first enumerating sets elements, subsequently combining pairsusing pairing function. Functions relations like union elementdefined operate numbers directly, quantifiers translated conjunctivedisjunctive iterations respective domains. all, easily readable codeused instantiate axioms.Since numberings items consideration (here: elements, sets laterpropositional variables) form core implementation, start translation process first fixing (arbitrary) numbering n elements x X, i.e., bijectivefunction cn : X {0, 1, . . . , n 1}.6 Kannai-Peleg Theorem six elements,instance, codes hence range 0 5.6. contrast propositional variables, numbering constraints elementsnumbers allowed start 0.158fiAutomated Search Impossibility Theorems Social Choice Theoryspecify corresponding numbering sets X . requires specialattention want define way treating problematic terms(as mentioned above) easy possible. natural way lookingset characteristic function converting corresponding finite string zerosones natural number. allows us perform operations codes sets directlyhence straightforward instantiate formulas Appendix automatically.needs done translating specific source code style. Quantifierscorrespond -loops elements sets, respectively, restrictionsquantification domain well operations elements sets taken carefunctions operating codes sets elements directly.5. Automated Exhaustive Theorem SearchSection 4 described generate (long) formula propositional logic representingsmall instances impossibility theorems ranking sets objects. Let us denoteformula . formula describes model linear order universegiven number elements weak order satisfying given set axioms setnonempty subsets universe. model exists, satisfying assignment (theexplicit description orders) and, thus, (complete) SAT solver discover(assuming time memory bounds). If, conversely, modelexist exactly statement impossibility theorem unsatisfiableand, again, SAT solver able detect (assuming, again, timememory bounds).universal reduction step (Corollary 1), full impossibility theorem thereforeequivalent lemma form formula unsatisfiable.example, feeding KP (a description base case Kannai-Peleg Theoremgenerated program) SAT solver zChaff (SAT Research Group, PrincetonUniversity, 2007) returns correct result (UNSAT) 5 seconds thusautomatic verification theorem complete.Using technique single theorems likely produce good results mighthelpful tool practical perspective, more: going presentmethod fully automated exhaustive theorem search impossibility theorems.theorem search will, given set axioms, systematically check subsetsinconsistent smallest domain size onwards impossibilities occur, thereby automatically identifying impossibility theorems given axiomsproduce.7 sense, search method exhaustive space given axioms.test fruitfulness approach ran search set 20 axiomsliterature (Barbera et al., 2004), list describe Appendix A. searchalgorithm returned total 84 impossibilities, known already (andhence automatically verified), others immediate consequences known results,others surprising new. search method alsorun arbitrary ESG axioms field ranking sets objects, including,instance, ones interpretation sets opportunity sets decision7. Since practical reasons check base cases certain domain size |X| = n, couldtheoretically impossibilities hidden occur larger domain sizes onwards.159fiGeist & Endrissmaker select favourite outcome, or, similarly, axioms caseassuming agent receives whole set alternatives (see Section 2).remainder section, first describe method automated theoremsearch list discuss impossibilities found.5.1 Approachsearch method systematically decides whether combinations given axioms compatible incompatible. therefore following refer axiom subsets problems,particular domain size speak problem instance.generation problem instance computer program (as describedSection 4.2) instance passed SAT solver, returns whetherpossible impossible one. implemented interfaces commonly used solversPrecoSAT (Biere, 2010) zChaff (SAT Research Group, Princeton University, 2007).latter provides additional layer verification generating proof tracechecked using external tools, former usually faster practice,extra feature.could run program possible problem instances given setaxioms maximal domain size individually collect results. Note, however,space 20 axioms maximal domain size eight elements, alreadydeal total (220 1) 8 8, 400, 000 problem instances.requires running time one second,8 whole job would take roughly 100 days.Therefore, designed scheduler makes sure axiom subsets treateddomain sizes sensible order. order check problem instancesbig effect overall running time one make use combination fourdifferent effects:(1) set axioms inconsistent domain size |X| = n, also inconsistentlarger domain sizes |X| > n (Corollary 1),(2) set axioms inconsistent domain size |X| = n, also (axiom)supersets inconsistent domain size |X| = n,(3) set axioms consistent domain size |X| = n, also consistentsmaller domain sizes |X| < n. (Theorem 2),(4) set axioms consistent domain size |X| = n, also (axiom) subsetsconsistent domain size |X| = n.Since larger instances require exponentially time (there exponentiallyvariables satisfiability problem due exponentially subsets X ), startsearch smallest domain size completely solving level movenext domain size.9 new level, problems considered stillstatus possible condition (1) above.8. tests, especially larger instances required much time solved average.9. reason condition (3) helpful practice.160fiAutomated Search Impossibility Theorems Social Choice Theorylevel, soon find impossibility, can, condition (2), markaxiom supersets impossible current domain size (if foundimpossible smaller domain size already). order use mechanism efficientlypossible, must check small axiom sets first. also dual approach startinglarge axiom sets marking axiom subsets compatible soon findpossibility (condition 4), option. experiments, found best performanceachieved combining two approaches decided run searchalternating directions (switching every 15 minutes):10 large axiom sets small onesway around.practical point view, implementation comes limitationsable treat 21 axioms time (stack overflows occurred largeraxiom sets) domain size eight elements (due memory limits SATsolvers). better memory management improved versions SAT solvers,(practical) boundaries extendable further.5.2 Resultstheorem search (checking problem instances domain size eight) yields total84 minimal impossibility theorems space 20 selected axioms. resultsminimal two senses:corresponding axiom set minimal respect set inclusion, i.e., propersubsets compatible given domain size;domain size minimal, i.e., smaller domain sizes given axiom setstill compatible.Counting total number incompatible axiom sets (i.e., including supersets), find312,432 inconsistent axiom sets one million possible combinations.whole experiment required running time roughly one day handlingnearly 8.5 million instances.11 order externally verify many impossibilitiespossible, used solver zChaff, create computer-verifiable proof trace,instances domain size 7, switched faster solver PrecoSAT,feature, instances (exponentially larger) domain size 8.12Table 1 list minimal impossibilities search method able find (andhence are) domain sizes 8. Recall that, Corollary 1,directly correspond full impossibility results (from given domain size upwards).results presented ascending order minimal domain size, ascending ordernumber axioms involved second criterion, stronger easiergrasp impossibilities higher table. axioms abbreviated names listedAppendix A.10. Switching every 15 minutes turned result good performance, attemptedsystematically optimise parameter.11. experiment performed Intel Xeon 2,26 GHz octo-core machine using one core5GB available 24GB memory. machine part Dutch national compute cluster Lisa.12. five impossibilities occurring domain size 8 onwards therefore verifiedexternally. Using zChaff instances (and subsequently verifying them) would alsopossible, slower factor 10.161fiREFLCOMPLTRANSEXTSDomGF1GF2INDstrictINDSUAvSUApSTopMonSBotMontopINDbotINDdisINDXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXContinued. . .Table 1: Results automated exhaustive theorem searchspace 20 axioms (including orders).162MCLIN333333344444444444444444444444444444444444evenExtSize123456789101112131415161718192021222324252627282930313233343536373839404142intINDNo.Geist & EndrissfiNo.SizeLINREFLCOMPLTRANSEXTSDomGF1GF2INDstrictINDSUAvSUApSTopMonSBotMontopINDbotINDdisINDintINDevenExtMCAutomated Search Impossibility Theorems Social Choice Theory434445464748495051525354555657585960616263646566676869707172737475767778798081828384455555555555566666666666666666666667788888XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXTable 1: Results automated exhaustive theorem searchspace 20 axioms (including orders).163fiGeist & EndrissObserving results, first note impossibilities occurtested domain sizes larger 2 onwards. novel right sinceimpossibilities |X| k, k {3, 4, 6} known.results differ much level appeal interestingness.find impossibilities least five (potentially overlapping) categories, namely knownresults, variations known results, direct consequences results, straightforwardresults, and, importantly, new results.previously known results easily recognise among ones list:Kannai-Peleg Theorem corresponds Impossibility No. 57; impossibility theoremBarbera Pattanaik (1984) found Impossibility No. 1.aware one known impossibility interpretation completeuncertainty, could unfortunately encode framework since usesaxiom neutrality (see Section 3.1). variant Kannai-Peleg Theorem presentedBarbera et al. (2004), number elements lowered fouradding aforementioned axiom.Variations known results also easy spot keeping axioms fixedbrowsing results involving these. Impossibilities No. 80 No. 10, instance,variations Kannai-Peleg Theorem, former weakening axiomsmakes impossibility occur larger domain size. latter variationdirection: additional axiom (SUAv) causes impossibility domain size 4elements already. many variations known theorems found (e.g.,No. 33, 37, 40, etc.).used set axioms certain axioms imply others, expectresults direct consequences others. particular, every result involving(weak) form independence also occur standard strict independenceonly, similarly simple dominance, weaker form Gardenfors principle.Examples results Impossibilities No. 3 (implied No. 1) ImpossibilityNo. 9 (implied No. 28).Straightforward results could find one: Impossibility No. 2 says binaryrelation cannot fulfill (SUAv) (SUAp), reflect contradictory principlesuncertainty aversion uncertainty appeal. immediate (especially examiningexact statement axioms).left new, i.e., previously unknown, results. quitethem, differ interesting are. instance,reasonable postulate (GF1) (GF2), makes new Impossibility No. 11fascinating all. also find results like Impossibilities No. 52 No. 56,combination axioms appears reasonable yet leads impossibility.return results below. let us moment shiftperspective problems, i.e., combinations axioms, special role individualaxioms respect results. one hand, axiom (LIN ) linear orderX occurs impossibilities. means impossibility without axiom(on given axiom space domain size 8). could anticipated:axioms say anythinguse empty relation X ,anymore hence cannot incompatible. Also note impossibility withoutform independence (straightforward) Impossibility No. 2. hand,164fiAutomated Search Impossibility Theorems Social Choice Theoryaxioms (evenExt) (REFL ) occur impossibility. Therefore,conclude must particularly well-compatible axioms. putdifferently, adding given set axioms cause impossibility.axiom (intIND) intermediate independence contained discovered impossibilitiesdomain sizes 7 8 (and cause impossibilities sizes 5 below).axiom involved somewhat larger instances makes great deal sense intuitively:application axiom add two elements (one above, oneset apply to), expected larger domain sizes necessarycontradiction.following discuss obtained impossibilities also provideexample manual proof. able quickly construct manual proofstheorems discussed underpins usefulness theorem search heuristic,even sceptic may willing accept output SAT solver rigorousproof.13 Knowing impossible axiom sets critical domain sizes beforehand simplifiedconstruction manual proofs significantly. Additionally, one run searchprogram slightly modified axioms, get even better understandingborderline lies possible impossible, alsoassistance choosing right steps proving results hand.even one application program searching manual proof: one runinstances single axioms left inspect orders satisfying remainingaxioms order understand structural properties imply.5.2.1 Unintuitive ImpossibilityLet us start striking result. Theorem 3 important paper Bossertet al. (2000) states axioms (SDom), (IND), (SUAv) (STopMon) characteriseso-called min-max ordering, definedmax(B) .min(B) min(A) = min(B) max(A)mnx B min(A) >theorem also covers dual result max-min ordering (characterizedaxioms (SDom), (IND), (SUAp), (SBotMon)).reader check contradicts results theorem search sinceaxiom sets among impossibility theorems Table 1 (ImpossibilitiesNo. 16 19). Indeed, turns proofs Bossert et al. (2000) flawedArlegi (2003) pointed three years later. Arlegi, however, notes minmax max-min orderings satisfy axiom independence (IND), i.e.,orders cannot characterized axioms (SDom), (IND), (SUAv), (STopMon), (SDom),(IND), (SUAp), (SBotMon), respectively. shows unintuitiveness findings (ascontrary believed time), yield counterexampleoriginal publication: additionally get four axioms considerationinconsistent (in presence transitivity) hence transitive binary relationwhatsoever satisfy them. give manual proof result.13. included one example manual proof here. complete set given Geist (2010).165fiGeist & EndrissTheorem 3 (Impossibility No. 16). Let X linearly ordered set |X| 4.exists transitive binary relation X satisfying simple dominance (SDom), independence (IND), simple uncertainty aversion (SUAv), simple top monotonicity (STopMon).Proof. Let xi , {1, 2, 3, 4} denote four distinct elements X ordered >x4 . way contradiction, supposex3 >x2 >respect index, i.e., x1 >exists transitive binary relation X satisfying simple dominance (SDom), independence(IND), simple uncertainty aversion (SUAv), simple top monotonicity (STopMon).x3x2 >one hand, follows simple uncertainty aversion applied x1 >{x2 } {x1 , x3 }, adding x4 sets yields (by independence):{x2 , x4 } {x1 , x3 , x4 }.(5)x4 ) show {x3 , x4 }hand, use simple dominance (applied x3 >{x4 },{x1 , x3 , x4 } {x1 , x4 }(6)x2 >x4follows independence. Furthermore, simple top monotonicity applied x1 >directly gives {x1 , x4 } {x2 , x4 }, able combine (6) transitivity.thus obtain{x1 , x3 , x4 } {x2 , x4 },directly contradicts (5).Note four axioms used proof above, necessaryresult also logically independent following automaticallyx2 >x3 >x4 ):constructed examples weak orders show (let X = {x1 , x2 , x3 , x4 } x1 >1. weak order given{x1 } {x2 } {x3 } {x4 } {x1 , x2 } {x1 , x3 } {x2 , x3 } {x1 , x4 } {x2 , x4 }{x3 , x4 } {x1 , x2 , x3 } {x1 , x2 , x4 } {x1 , x3 , x4 } {x2 , x3 , x4 } {x1 , x2 , x3 , x4 }satisfies (IND), (SUAv), (STopMon), (SDom).2. weak order given{x1 } {x1 , x2 } {x2 } {x1 , x3 } {x2 , x3 } {x3 } {x1 , x2 , x3 } {x1 , x4 }{x2 , x4 } {x1 , x2 , x4 } {x3 , x4 } {x4 } {x1 , x3 , x4 } {x2 , x3 , x4 } {x1 , x2 , x3 , x4 }satisfies (SDom), (SUAv), (STopMon), (IND).3. weak order given{x1 } {x1 , x2 } {x1 , x3 } {x1 , x2 , x3 } {x2 } {x2 , x3 } {x3 } {x1 , x4 }{x1 , x2 , x4 } {x1 , x3 , x4 } {x1 , x2 , x3 , x4 } {x2 , x4 } {x2 , x3 , x4 } {x3 , x4 } {x4 }satisfies (SDom), (IND), (STopMon), (SUAv).4. weak order given{x1 } {x1 , x2 } {x2 } {x1 , x3 } {x1 , x2 , x3 } {x2 , x3 } {x3 } {x1 , x4 }{x1 , x3 , x4 } {x2 , x4 } {x1 , x2 , x4 } {x2 , x3 , x4 } {x1 , x2 , x3 , x4 } {x3 , x4 } {x4 }satisfies (SDom), (IND), (SUAv), (STopMon).166fiAutomated Search Impossibility Theorems Social Choice Theoryalso seen subset four axioms suffices characterisemin-max ordering. subset containing (IND) rejected immediately since (IND)violated min-max ordering (as noted earlier), subset containingcannot suffice characterisation either, since example 2 differs min-maxordering mnx (in {x2 , x3 , x4 } mnx {x1 , x2 , x3 , x4 }).Finally, emphasise fact neither reflexivity completeness usedproof Theorem 3 (as also indicated Table 1). Thus, impossibility alreadyholds arbitrary transitive binary relations instead weak orders.5.2.2 Variations Kannai-Peleg TheoremImpossibility No. 9 offers interesting variation Kannai-Peleg Theorem tradesadditional axiom (simple uncertainty aversion) impossibility occurring domain size 4 rather 6 elements.Theorem 4 (Impossibility No. 9). Let X linearly ordered set |X| 4.exists transitive binary relation X satisfying Gardenfors principle (GF),independence (IND) simple uncertainty aversion (SUAv).impossibility result also holds simple uncertainty appeal (SUAp) placesimple uncertainty aversion (SUAv); Impossibility No. 12.even closer look Table 1, see evenstronger form Theorem 4: Impossibility No. 28 corresponds axioms (GF),(SUAv), (botIND), (topIND) impossible domain size 4 on. contrast (IND),axioms (botIND) (topIND) allow principle independence certain situationsonly: element added ranked elements sets,respectively.14 Therefore, immediately following stronger version Theorem 4.Theorem 5 (Impossibility No. 28). Let X linearly ordered set |X| 4.exists transitive binary relation X satisfying Gardenfors principle (GF), bottom(botIND) well top independence (topIND), simple uncertainty aversion (SUAv).interesting insight obtained comparing Impossibility No. 48previous result. shows us drop second Gardenfors axiom addone element domain, i.e., |X| 5. exact result following:Theorem 6 (Impossibility No. 48). Let X linearly ordered set |X| 5.exists transitive binary relation X satisfying first axiom Gardenforsprinciple (GF1), bottom (botIND) well top independence (topIND), simple uncertainty aversion (SUAv).Alternatively, could replaced (botIND) (disIND) (No. 51), (topIND)(intIND), then, however, requiring least seven elements domain (No. 78).Two variants Kannai-Peleg Theorem found Impossibilities No. 8081, considered strengthenings original theorem containweaker versions independence only. strengthening, however, comes cost14. Actually, already original proof Kannai-Peleg Theorem (Kannai & Peleg, 1984)weaker forms (IND) used (cf. also Impossibility No. 61).167fiGeist & Endrissimpossibility starting domain size eight elements instead six. formindependence remains combination intermediate, disjoint, bottom topindependence, respectively, (even together) weaker standard independence.5.2.3 Impossibilities without Dominanceexisting impossibilities literature aware involve Gardenfors principle(GF) least simple dominance (SDom). let us consider kinds resultsobtain without dominance principle.striking impossibility without principle dominance i.e., without either (GF)(SDom) Impossibility No. 52: axioms strict independence (strictIND), simple uncertainty aversion (SUAv), monotone consistency (MC) incompatiblepresence completeness transitivity domain size 5 on.Theorem 7 (Impossibility No. 52). Let X linearly ordered set |X| 5.exists weak order X satisfying strict independence (strictIND), simple uncertaintyaversion (SUAv) monotone consistency (MC).One might tempted think impossibility mostly due problems(SUAv) (MC) since seem express contrary ideas: whereas (SUAv) favours small setslarge ones, (MC) tells us unions two sets preferred least onesets. actually even characterisation result min-max ordering Arlegi(2003) involving axioms (SUAv) (MC), demonstrating natural orderingfulfils two axioms. Therefore, see consideredunreasonable axioms act together.found quite variants impossibility. According results,completeness could replaced simple bottom monotonicity (Impossibility No. 53)even dropped price one element domain (ImpossibilityNo. 56). Alternatively, one weaken strict independence either bottom disjointindependence shrink domain one element, price adding axiomsimple top monotonicity (Impossibilities No. 26 27, respectively). seeminglyvariant obtained trading axiom extension (EXT) smaller domain.is, however, direct consequence Impossibilities No. 26 27, respectively, since (EXT)(strictIND) together imply (STopMon).Since strict independence considered relatively strong axiom, ImpossibilityNo. 26 (and corresponding No. 27) worth emphasising well, postulateweak form independence.Theorem 8 (Impossibility No. 26). Let X linearly ordered set |X| 4.exists transitive binary relation X satisfying bottom independence (botIND),simple uncertainty aversion (SUAv), simple top monotonicity (STopMon) monotone consistency (MC).result comes quite surprise since Arlegi (2003) characterises min-maxordering axiom set including (SUAv), (STopMon), (MC) (as well twoaxioms). follows adding tiny bit independence three axioms turnspossibility general impossibility.168fiAutomated Search Impossibility Theorems Social Choice Theory6. Conclusionpresented method automatically verifying discovering theoremssubarea economic theory concerned problem formulating principles liftingpreferences individual objects preferences nonempty sets objects.theorems question impossibility theorems establish certain combinationsprinciples (called axioms) inconsistent. method three components:general result, universal reduction step (a corollary Preservation Theorem), shows combination axioms, meeting certain conditions,inconsistent fixed domain size n, also inconsistent domainn objects. conditions axioms applicability resultpurely syntactic: axiom (equivalent to) existentially set-guarded (ESG)sentence many-sorted logic set preferences (MSLSP) qualifies.method translating axioms propositional formulas CNF, methodinstantiating axioms computer fixed domain size. allows usverify small instances impossibility theorem using SAT solver. Togetheruniversal reduction step, constitutes proof respective impossibility theorem also larger domain sizes.scheduling algorithm search large space axiom combinations differentdomain sizes. This, finally, allows us systematically search discover newimpossibility theorems.applied method set 20 axioms proposedliterature means formalising various principles ranking sets objectssets interpreted representing mutually exclusive alternatives objectselected manner cannot influenced decision maker (so-called completeuncertainty). yield total 84 (minimal) impossibility theorems, includingknown results new theorems. commented interestingprevious section. results clearly demonstrate power method.work extended number ways. First, method appliedsets axioms (including axioms order types linear weak orders).Implementing axioms done quickly, long covereduniversal reduction step, results read short computation. Especiallyopportunity sets, knowledge impossibility results known,potential success high.Second, method implementation refined further. wouldattractive integrate parser read language MSLSP axiomslonger transformed coded hand. idea implementdependencies axioms. would make sure absolutely minimalresults returned, whereas results trivial consequences others(since axioms immediately implied others).Third, case particular combination axioms lead impossibility,may possible use output SAT solver infer useful informationclass set preference orderings satisfying axioms. preliminary stepsdirection already taken (Geist, 2010).169fiGeist & EndrissFinally, tentative suggestion, would interesting exploreextent method adapted different disciplines problem domains.starting point might Preservation Theorem, potentially still strengthened larger class axioms. One could try find exact borderline liesformulas preserved certain substructures not.arbitrary first-order models done famous Los-Tarski Theorem,class structures set preferences still open question.Acknowledgmentswould like thank Umberto Grandi three anonymous JAIR reviewers hosthelpful comments suggestions earlier versions paper.Appendix A. List Axiomsappendix provide complete list axioms used theorem searchpresented Section 5. axioms (or variations thereof) referencesfound survey Barbera et al. (2004).first axioms given order axioms. one, axioms describ X, another, ones describing weak order X = 2X \{}.ing linear orderformer denoted (LIN ), whereas latter split threecomponents reflexivity (REFL ), completeness (COMPL ) transitivity (TRANS ),treated separate axioms order investigate parts actually necessaryimpossibilities. axioms intuitive form are:(LIN )(REFL )x x Xxyxx 6= Xxyyzxz x, y, z Xxyyx x = x, XxX(reflexivity)(completeness)(transitivity)(antisymmetry)(reflexivity)(COMPL )B B 6= B X(TRANS )B B C C A, B, C X(completeness)(transitivity)Next axiom extension, natural requirement thus alsoimplied axioms (e.g., Gardenfors principle):(EXT){x} {y} x, Xxset axioms included search one dealing conceptdominance, i.e., idea adding object x set objects dominated(or dominating) object x produces better (or worse) set, respectively. chosewell-known Gardenfors principle (GF), introduced Section 2.2 already,170fiAutomated Search Impossibility Theorems Social Choice Theorywell weaker version Barbera (1977) called simple dominance (SDom), restricts(GF) small sets:(GF1)(GF2)(SDom)a) {x} x X X((a A)x >a) {x} x X X((a A)x <({x} {x, y} {x, y} {y}) x, Xx>Independence axioms also commonly postulated especially weaker variantsversions thereof, like bottom, top, disjoint intermediate independence, frequentlyplay role characterisation results (e.g., see Pattanaik & Peleg, 1984; Nitzan & Pattanaik, 1984). decided include standard independence (as already introducedSection 2.2), stronger version (strictIND), implies strict preferences,weaker versions, viz. bottom (botIND), top (topIND), disjoint (disIND) intermediateindependence (intIND), apply certain combinations sets elements.(IND)B {x} B {x} A, B X x X \ (A B)(strictIND)B {x} B {x} A, B X x X \ (A B)(botIND)B {x} B {x} A, B Xx Bx X \ (A B) >(topIND)B {x} B {x} A, B XBx X \ (A B) x >(disIND)B {x} B {x} A, B X ,B = , x X \ (A B)(intIND)B {x, y} B {x, y} A, B X x, X \ (A B)z z >z Bx >Bossert (1997) introduced axioms describing attitude decision maker towardsuncertainty. formalise weakenings axioms apply small sets only, sincesufficient characterisation results like Arlegi (2003). Uncertaintyaversion postulates decision maker will, alternative x, (strictly) preferalternative set containing better worse alternative. Uncertainty appeal,hand, says ranking way around: setbetter worse element (strictly) preferred single element x.(SUAv)(SUAp)yy(x >yy(x >z) {y} {x, z} x, y, z X>z) {x, z} {y} x, y, z X>Arlegi (2003) also uses two monotonicity axioms, called simple top bottom monotonicity. underlying idea simple: given two alternatives, better get betterone two together third element (instead worse onethird element). two variants axiom apply alternativesranked higher (top) third alternative, ranked lower (bottom), respectively.(STopMon)(SBotMon){x, z} {y, z} x, y, z X x >z >zx>z {x, y} {x, z} x, y, z X x >x >zy>171fiGeist & Endrissrather odd axiom principle even-numbered extension equivalence. saysthat, sets even number elements, decision maker indifferentwhether set added two distinct singleton sets, alsoindifferent whether added union two singleton sets. Even thoughlacks intuitive support, axiom useful (together principles)characterises median-based ordering proposed Nitzan Pattanaik (1984).(evenExt)(A {x} {x} {y} {y}) {x, y} {x, y}X , |A| even, x, X \final axiom list monotone consistency (MC), put forwardArlegi (2003) characterise (in connection axioms) min-max ordering (seealso Section 5.2). (MC) expresses set objects least good anotherset B, union two least good latter. impliescomplete binary relations equivalent potentially worse set B strictlybetter union two. Intuitively, means adding alternatives(weakly preferred) set set B, decision maker maintains alternativesB plus ones contained A, weakly preferred B. Thus,process produce set strictly worse B.(MC)B B B A, B XAlthough (MC) appears similar first axiom Gardenfors principle,fact quite different since dictate existence strict preferences.ReferencesAgotnes, T., van der Hoek, W., & Wooldridge, M. (2010). logic preferencejudgment aggregation. Journal Autonomous Agents Multiagent Systems. (Inpress)Arlegi, R. (2003). note Bossert, Pattanaik Xus Choice complete uncertainty: axiomatic characterization decision rules. Economic Theory, 22 (1),219225.Arrow, K. J. (1963). Social choice individual values. Yale University Press, New Haven.Cowles Foundation Monograph 12.Barbera, S. (1977). manipulation social choice mechanisms leavemuch chance. Econometrica, 45 (7), 15731588.Barbera, S., Bossert, W., & Pattanaik, P. K. (2004). Ranking sets objects. S. Barbera,P. J. Hammond, & C. Seidl (Eds.), Handbook utility theory (Vol. II: Extensions,pp. 893977). Kluwer Academic Publishers, Dordrecht.Barbera, S., & Pattanaik, P. K. (1984). Extending order set power set:remarks Kannai Pelegs approach. Journal Economic Theory, 32 (1),185191.Ben Larbi, R., Konieczny, S., & Marquis, P. (2010). characterization optimality criteriadecision making complete ignorance. Proceedings 12th InternationalConference Principles Knowledge Representation Reasoning (KR-2010).AAAI Press.172fiAutomated Search Impossibility Theorems Social Choice TheoryBiere, A. (2010). PrecoSAT. Available http://fmv.jku.at/precosat/.Bossert, W. (1997). Uncertainty aversion nonprobabilistic decision models. MathematicalSocial Sciences, 34 (3), 191203.Bossert, W., Pattanaik, P. K., & Xu, Y. (2000). Choice complete uncertainty:Axiomatic characterizations decision rules. Economic Theory, 16 (2), 295312.Chevaleyre, Y., Endriss, U., Lang, J., & Maudet, N. (2007). short introductioncomputational social choice. Proceedings 33rd Conference Current TrendsTheory Practice Computer Science (SOFSEM-2007) (pp. 5169). SpringerVerlag.DIMACS. (1993). DIMACS satisfiability suggested format. Available ftp://dimacs.rutgers.edu/pub/challenge/satisfiability/doc/satformat.dvi. Center Discrete Mathematics & Theoretical Computer Science.Duggan, J., & Schwartz, T. (2000). Strategic manipulation without resoluteness sharedbeliefs: Gibbard-Satterthwaite generalized. Social Choice Welfare, 17 (1), 8593.Enderton, H. B. (1972). mathematical introduction logic. Academic Press.Fishburn, P. C. (1972). Even-chance lotteries social choice theory. Theory Decision,3 (1), 1840.Gaertner, W. (2009). primer social choice theory: Revised edition. Oxford UniversityPress, USA.Gardenfors, P. (1976). Manipulation social choice functions. Journal EconomicTheory, 13 (2), 217228.Gardenfors, P. (1979). definitions manipulation social choice functions. J. J. Laffont (Ed.), Aggregation revelation preferences (pp. 2936). North-Holland.Geist, C. (2010). Automated search impossibility theorems choice theory: Ranking setsobjects. M.Sc. thesis. Institute Logic, Language Computation. UniversityAmsterdam.Grandi, U., & Endriss, U. (2009). First-order logic formalisation Arrows Theorem.Proceedings 2nd International Workshop Logic, Rationality Interaction(LORI-2009) (pp. 133146). Springer-Verlag.Gravel, N., Marchant, T., & Sen, A. (2008). Ranking completely uncertain decisionsuniform expected utility criterion. Presented 3rd World Congress GameTheory Society, Evanston, IL.Hodges, W. (1997). shorter model theory. Cambridge University Press.Kannai, Y., & Peleg, B. (1984). note extension order set powerset. Journal Economic Theory, 32 (1), 172175.Lin, F. (2007). Finitely-verifiable classes sentences. Presented 8th InternationalSymposium Logical Formalizations Commonsense Reasoning, Stanford, CA.Manzano, M. (1996). Extensions first-order logic. Cambridge University Press.Nipkow, T. (2009). Social choice theory HOL. Journal Automated Reasoning, 43 (3),289304.Nitzan, S. I., & Pattanaik, P. K. (1984). Median-based extensions orderingset power set: axiomatic characterization. Journal Economic Theory,34 (2), 252261.173fiGeist & EndrissPackard, D. J. (1979). Preference relations. Journal Mathematical Psychology, 19 (3),295306.Pattanaik, P. K., & Peleg, B. (1984). axiomatic characterization lexicographicmaximin extension ordering set power set. Social ChoiceWelfare, 1 (2), 113122.Puppe, C. (1995). Freedom choice rational decisions. Social Choice Welfare,12 (2), 137153.SAT Research Group, Princeton University. (2007). zChaff. Available http://www.princeton.edu/chaff/zchaff.html.Sen, A. (1991). Welfare, preference freedom. Journal Econometrics, 50 (1-2), 1529.Sloane, N. J. A. (Ed.). (2010). on-line encyclopedia integer sequences (OEIS).Published electronically http://www.research.att.com/njas/sequences/.Tang, P. (2010). Computer-aided theorem discovery new adventure applicationeconomic theory. Ph.D. thesis. Hong Kong University Science Technology.Tang, P., & Lin, F. (2009). Computer-aided proofs Arrows impossibilitytheorems. Artificial Intelligence, 173 (11), 10411053.Taylor, A. D. (2002). manipulability voting systems. American MathematicalMonthly, 109 (4), 321337.Wiedijk, F. (2007). Arrows Impossibility Theorem. Formalized Mathematics, 15 (4), 171174.174fiJournal Artificial Intelligence Research 40 (2011) 375413Submitted 06/10; published 02/11Evaluating Temporal Graphs Built Texts via Transitive ReductionXavier TannierXTANNIER @ LIMSI . FRLIMSI-CNRS Univ. Paris-SudB.P. 13391403 ORSAY Cedex, FrancePhilippe MullerMULLER @ IRIT. FRALPAGE-INRIA Toulouse UniversityIRIT, Univ. Paul Sabatier118 Route de NarbonneF-31062 Toulouse Cedex 04, FranceAbstractTemporal information focus recent attention information extraction, leadingstandardization effort, particular task relating events text. task raisesproblem comparing two annotations given text, relations events storyintrinsically interdependent cannot evaluated separately. proper evaluation measurealso crucial context machine learning approach problem. Finding commoncomparison referent text level obvious, argue favor shift eventbased measures measures unique textual object, minimal underlying temporal graph,formally transitive reduction graph relations event boundaries. supportinvestigation properties synthetic data well-know temporal corpus.1. IntroductionTemporal processing texts somewhat recent field methodological point view, eventhough temporal semantics long tradition, dating back least 1940s (Reichenbach, 1947).theoretical formal linguistic approaches temporal interpretation discourse levelactive late 1980s early 1990s (Kamp & Reyle, 1993; Asher & Lascarides,1993; Steedman, 1995; Webber, 1988), empirical approaches less frequent, naturallanguage processing systems evaluated beyond instances (Grover, Hitzeman, & Moens,1995; Kameyama, Passonneau, & Poesio, 1993; Passonneau, 1988; Song & Cohen, 1991).Temporal information essential interpretation text thus crucial applicationssummarization information extraction, received growing attention 2000s (Mani,Pustejovsky, & Gaizauskas, 2005) lead standardization effort TimeMLinitiative (Saur, Littman, Knippen, Gaizauskas, Setzer, & Pustejovsky, 2006). address central part task, namely evaluating extraction network temporal relationsevents described text. Since temporal information easily broken local bits information, many equivalent ways express ordering events. Human annotationthus notoriously difficult (Setzer, Gaizauskas, & Hepple, 2006) comparisons annotations cannot rely simple precision/recall-type measures. given practice nowadayscompute sort transitive closure network/graph constraints temporal events(usually expressed well-known Allen algebra (Allen, 1983), sub-algebra), eithercompare sets simple temporal relations deduced standard precisionrecall, measure agreement relations, including disjunctions information (Verhagen, Gaizauskas, Schilder, Hepple, Katz, & Pustejovsky, 2007). reasoning model also usedc2011AI Access Foundation. rights reserved.fiTANNIER & ULLERXXXmeetsstartsXoverlaps XXequalsXfinishesFigure 1: Allen relations. relation r inverse relation ri.help build representations temporal situations imposing global constraints top localdecision problems (Chambers & Jurafsky, 2008a; Tatu & Srikanth, 2008; Bramsen, Deshpande, Lee,& Barzilay, 2006).take different route here, extracting single referent graph, minimal graph constraints. number ways argue basing graph relationsevent boundaries. aim accomplish two things so: find grapheasy compute, eliminate bias introduced measures take accountcombinatorial aspect agreement transitive closure graphs.next section presents detail usual way comparing annotation graphstemporal entities extracted text, problems raises. argue comparing eventboundaries instead events define two new metrics apply type information.focus convex relations, tractable sub-algebra Allen relations covers human annotations.Finally, present empirical study behavior measures generated dataTimeBank Corpus (Pustejovsky, Hanks, Saur, See, Gaizauskas, Setzer, Radev, Sundheim, Day,Ferro, & Lazo, 2003) support claim practicality methodology.2. Comparing Temporal Constraint NetworksWork temporal annotation texts strongly relies Allens interval algebra. Allen representstime events intervals, states 13 basic relations hold intervals (seeFigure 1 Table 1), considering every possible ordering interval endpoints. binaryrelations, existing amongst intervals collection (in case, corresponding temporal entitiestext), define graph nodes intervals edges labelled setrelations may hold pair nodes. relations mutually exclusive. TimeMLspecification linguistic temporal annotation uses Allen relations different names,projects either use subset groupings relations (see below).interested paper evaluating systems annotating texts temporal relations holdingevents temporal expressions events. example, consider following text,extracted TimeBank corpus:376fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTIONRelationbJmJoJsJdJIfJ= JMeaningJmeets Joverlaps Jstarts JJfinishes Jequals JEndpoint relationsI2 < J1I2 = J1(I1 < J1 ) (I2 < J2 ) (J1 < I2 )(I1 = J1 ) (I2 < J2 )(J1 < I1 ) (I2 < J2 )(J1 < I1 ) (I2 = J2 )(I1 = J1 ) (I2 = J2 )Inverse relationbimioisidifiTable 1: Allen relations. relation r inverse relation ri. interval starts I1 endsI2 .(1)wasnt twenty years first astronauts chosene1 NASA finally includede2 six women, scientists, pilots. woman actuallycharge missione3 nowt1 .correct annotation temporal relations could given graph shown Figure 2.relations could explicited, i.e. e1 bt1 , complete evaluation could consider possible edges.chosen_e1bincluded_e2bfinow_t1charge mission_e3Figure 2: Example annotation example 1.Precision recall evaluations often performed graphs relations eventstext however, subproblem ordering pairs successively described events (Mani &Schiffman, 2005; Verhagen et al., 2007) even same-sentence events (Lapata & Lascarides, 2006)(in example, e1 b e2 e3 f t1 1 ). main reason choice difficulty task,even human beings, assigning temporal relations large text (Setzer et al., 2006). Anotherissue evaluation full temporal graphs open question. discussedsection, metrics traditionally used task, namely recall precision metrics (either strictrelaxed), raise specific problems still addressed.detail important notions concerning temporal networks comparison networks. example relations given section expressed terms Allen algebra, whoseset relations abbreviations recalled Table 1. Here, use classical symbols <> order temporal points.2.1 Temporal ClosureTemporal closure inferential closure mechanism consists composing known pairs temporal relations order obtain new relations, fixed point. E.g.: b B C B,1. Exceptions exist, work Mani et al. (2006) Mani et al. (2007).377fiTANNIER & ULLER%bbidibbb{b, o, m, di, fi}bibibi{bi, oi, di, mi, si}{b, o, m, d, }{bi, oi, mi, d, f}{o, oi, d, s, f, di, si, fi, =}dibbidiTable 2: Composition Allen relations.b C; operation lead disjunction relations, example b B B Cb C C C C C. also noted A{b, o, m, d, s}C.consider generalized relations, i.e. set R disjunctions basic temporal relations,seen set base relations, set union intersection composition relationsdefine algebra R (the algebra subsets set Allen relations). Compositionrelations operation generalizes inferences basic relations sets relations. Takingprevious example, B B C, = {t1 , t2 , ...tk } = {s1 , s2 , ...sm }, ti ,si base relations:[= {t1 , t2 , ...tk } {s1 , s2 , ...sm } = (ti sj )i,jcomposition relations computed 13x13 compositions base relations.table composition rules Allen algebra found work Allen (1983) Rodriguez et al. (2004), sample basic relations given Table 2. new relationsexpress new intrinsic constraints, make temporal situation explicit. alsomake information precise, disjunctions inferred edge intersectedcombine inferences different compositions.constraint propagation algorithm ensures existing temporal relations addednetwork, labelling inconsistency (Allen, 1983). path-consistency algorithm sound,complete, detect cases inconsistency. See simple version presentedAlgorithm 1. efficient versions also developed (Vilain, Kautz, & van Beek, 1990),put use experiments, main focus here.desirable compare temporal graphs without performing temporal closure them.Indeed, several ways encode temporal information graph, shown(very simple) example Figure 3. Closure seen computationally simple way explicitingtemporal information annotation, allowing precise comparisons. temporalclosure also produces redundant information, lead evaluation issues, explainedSection 2.4.paper, call G temporal closure (also called saturated graph) graph G.=<B<C=<B<C=<B<CFigure 3: Three identical annotations. last one result temporal closure.378fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTIONAlgorithm 1 Temporal closureLet U = disjunction 13 Allen relations,Rm,n = current relation nodes nprocedure CLOSURE(G)A=G.edges()N=G.vertices()changed = Truechangedchanged = Falsepairs nodes (i, j) N Nk N ((i, k) (k, j) A). composition via kR1i,j = (Ri,k Rk,j ). find info (i,j)edge (a relation R2i,j ) existed j R2i,j = UendRi,j = R1i,j R2i,j. intersect new already knownRi,j = error. inconsistency detectedelse Ri,j = U nothing. new informationelseupdate edge (i,j)changed = Trueendendendendend procedure379fiTANNIER & ULLERA1<A2<==C1<C2<B1<B2Figure 4: Endpoint graph (same temporal information Figure 3).2.2 Time Point Algebra Convex RelationsInterval graphs converted easily graphs points (Vilain et al., 1990), eventsplit beginning ending point; mapping Allen relations point relationsgiven Table 1. leads smaller set simple relations: equality (=) precedence(< >), simpler algebra, 7 consistent sets ({<},{<, =},{=},{<, =, >},{>},{>=}, {<, >} set denotes disjunction relations). point algebra obtained fourrelations r1 ... r4 hold endpoints two intervals J started Ib Jbended Ie Je respectively. four relations Ib r1 Jb , Ie r2 Je , Ib r3 Je Ie r4 Jb .Converting Allen graph endpoint graph thus straightforward. Figure 4 shows pointgraph equivalent interval graph Figure 3.interval algebra, pairs point relations combined temporal closurecomputed way. relation two time points continuous assignedset simple relations convex (Vilain et al., 1990).so-called convex relation corresponds cases relations r1 r4 assigned one6 possible relations {<}, {<, =}, {=}, {<, =, >}, {>}, {>=}2 , considered conceptual neighbors (Freksa, 1992). Using relations endpoints restricts interval relations setsAllen relations conceptual neighbors. means encode relations mayvague intervals endpoints convex subsets time-line. Figure 5shows Allen relations conceptual neighbors. Another useful way seeing conceptual neighbors considering continuous transformations interval endpoints time-line:relation r holds two intervals I1 I2 , moving continuously endpointschange relation conceptual neighbor r. instance, conceptual transformationcannot change situation I1 starts I2 situation I1 < I2 without going (atleast) intermediary situations I1 overlaps I2 I1 meets I2 .Finally, instead 213 possible disjunctive relations Allen algebra, set correspondinginterval convex relations reduced 82. corresponding sub-algebra tractable, problem satisfiability set constraints sound complete polynomial time algorithm3 .Moreover, ensure uniqueness minimal graphs, defined describedpaper.important note temporal graph built annotated text contains convexrelations, since graph generated finite set base relations (annotators allowed2. 7 relations described above, except {<, >}, also noted 6=. 6 relations form sub-algebra: compositionsdisjunctions relations disjunctions relations.3. See work Schilder (1997) complete presentation within natural language processing perspective.380fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION<foieqfidimi>siFigure 5: Temporal relations conceptual neighborsuse disjunctions), since set convex relations stable composition thus formssub-algebra.2.3 Strict Relaxed Recall Precisiongeneral case, humans systems may assign disjunctions atomic relationstwo events (i.e. b B B), directly indirectly (after saturation). way reducevagueness even exact relation known.presence disjunctions raises question score relations partlycorrect, like b B B instead b B reverse. response issue, differentvariations usual precision recall measures proposed.strict measure counts exact matching success, example score 0 latterexample.However, argued evaluation measure take better account close matches.example, suppose gold standard relation B b B. system choosesdisjunction b B B, must rewarded less b B > B nothing.system vaguer correct, annotation logical consequence standard annotation.proposed (Muller & Tannier, 2004) gradual measure might call temporalprecision recall. Si,j (possibly disjunctive) relation j given systemKi,j (possibly disjunctive) gold standard, then:Ptemp i,j =Card( Si,j Ki,j )Card( Ki,j )Rtemp i,j =Card( Si,j Ki,j )Card( Si,j )Card(Gi,j ) = number atomic relations present disjunction. Thus, example, system S1 answered overlaps j get:Ptemp i,j,S1 =Card({b, o} {b} )=1Card( {b} )Rtemp i,j,S1 =Card({b, o} {b} )1=Card({b, o})2S2 answered get Ptemp i,j,S2 = Rtemp i,j,S2 = 0.381fiTANNIER & ULLERfinal precision (resp. recall) average number relations given system(resp. reference):j=ni=n XXPtemp =j=ni=n XXPtemp i,ji=1 j=i+1Card(S)Rtemp =Rtemp i,ji=1 j=i+1Card(K)Similar measures also used TempEval evaluation campaign 2007 (Verhagen et al., 2007), reduced set relations : before, overlaps overlaps.measures called relaxed recall precision. use words strict relaxeddesignate two ways score temporal relations.2.4 Relative Importance Relationsshown above, temporal closure necessary order able compare properly two temporalgraphs. temporal graph, relations importance. Applying basic recallprecision scores (either strict relaxed) closed temporal graphs enough. Considersimple graph examples Figure 6, first graph K gold standard. S1 containstwo relations, six K. seems unfair consider recall score 62 , since addingone relation (B b C) would enough infer others. intuitive recall would around 23 .counts many relations missing order recover whole annotation graph.Still, even suppose way distinguish unambiguously major relations (solidlines K) minor (deducible) relations (dashed lines), would enough. Indeed, graphS2 finds relation B b D. relation minor K, found composingrelations; S2 , case, relation actually carries piece information mustrewarded. However, even amount temporal information brought S2 S3 seemsequivalent, S3 get higher score. Indeed, amount missing relations (needed inferfull graph) much lower S3 (only C b missing) S2 . Finally, S4 get betterrecall one. General cases involving relations obviously much complex.kind problems could found co-reference task MUC-6, co-referencelinks define equivalence relation. thus necessary specify pair-wise co-referencerelations retrieve them, consequences evaluation recall. addressedconsidering spanning tree graph co-reference enough evaluate recalllinks (Vilain, Burger, Aberdeen, Connolly, & Hirschman, 1995). equivalence classconsidered, consisting n entities, n 1 links enough define class, recall error dependsnumber missing links needed reconnect equivalence class. Recall class1 n1. Precision defined symmetrically. much simpler framework, similarproblem redundancy.42.5 Minimal Graphssaid previous section, good, insufficient way deal relative importance graphrelations would work called major relations, minimal graph.consider temporal graph minimal graph graph G if:4. MUC measures problems later addressed measures B3 CEAF,relevance evaluation temporal graph. main issue tendency favor prediction co-referencelink every pair mentions; counterpart temporal case since event pairs linked differentrelations different inferential properties, opposed one equivalence relation.382fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTIONKBCS1BCS2BCS3BCS4BCFigure 6: metric deal with. K reference annotations, Si candidate annotations. S4 better S1 S3 , better S2 . Solid lines indicate annotatedrelations, dashed lines indicate relations inferred annotated relations. eventsrelated relation here.1. temporal closure leads temporal information G.2. relation removed graph without breaking first property.Unfortunately, unique minimal graph exist general case, particularAllen relations. Rodriguez et al. (2004) propose way find minimal graphs given temporalgraph. algorithm first finds core relations, relations every minimal graph, intersecting derivations, computes possible remaining combinations order findcomposing minimal graph.example, relation RA,B B, derivations RA,C RC,B , RA,D RD,B ,RA,E RE,B , etc. intersection derived relations equals RA,B , means RA,Bcore relation, since obtained composing relations. Otherwise, relationcore relation, since removing always leads loss information. way kernelobtained ensures uniqueness.However, second part procedure (compute remaining combinations) computationallyimpractical, even medium-sized graphs, since every subset relations must considereddetermine minimal graph top core relations. authors detail much empiricalinvestigations, offering support usability method. Moreover, leadunique graph could compared reference.Going back evaluation, Tannier Muller (2008) suggest comparison graphscore relations, easy compute give good idea important relationsgraph. core relations contain information provided closed graphs,383fiTANNIER & ULLERFigure 7: Recall behavior removing information vs. ideal behavior.measures core graphs approximation assessed. paper,propose method obtain unique graph respecting constraints mentioned Section 2.4.2.6 Behavior Existing Metricsstated work Tannier Muller (2008), recall measure expected decreaselinear way amount information decreases. Otherwise, evaluation measures couldnon-gradual changes complicate comparisons models. Besides, expect amount information grow roughly proportionally number events text.behavior evaluated comparing given annotation annotationtemporal information taken out.Figure 7 shows recall measures evolve removing relations temporal graph,relations present. shows different values strict recall according proportionrelations kept graph, well ideal = x line. considered illustrationconsequences annotator forgetting annotate relations, respect idealreference.slope reveals two major drawbacks, leading lack stability metric:non-linear progression curve intuitively correspond expectgood metric: example, system provides 60% correct information system B, system get 60% better recall.shown later, parabolic shape due irregular redundancy sparsenesshuman annotation. Then, two systems providing amount correct informationget different recall values, depending whether human annotation informationredundant not.Figure presents idealized case; thorough experiments done whole TimeBank corpus (Pustejovsky et al., 2003) explained details Section 6. now, enoughnote measure decreases parabolic way, since annotators roughly tag O(n) relationsn number events, inferred relations O(n2 ), number edges n nodes.384fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTIONA1B1<A2<C1<C2B2Figure 8: Endpoint graph merges (same temporal information Figure 4). Gray dashed arcstrivial relations coming definitions endpoints (C1 starts C, C2 ends C).Full graphs contain redundant information, recall thus decreases artificial, irregular waysremoved. hypothesis working minimal graphs suppress redundancy lead controlled behavior.Moreover, fact reference graphs contain O(n2 ) relations closure biases evaluationtowards larger texts (or least texts containing large clusters related events).3. Proposed New Metricconfronting graph gold standard, similarity measure necessary. Many similaritymeasures exist two graphs many-to-many correspondence found nodesgraphs (Sorlin, 2006).Node matching, major problem graph comparison general, difficultcase, since consider graphs annotate events expressions5 .traditional similarity function two graphs following (Sorlin, 2006):sim(K, G) =f (K um G) g(splits(m))f (K G)K um G set relations shared graphs according node matching function m,K G union K G relations, splits(m) number node splits imposedmatching obtain graph mapped (see examples later). Functions f g dependtypes graphs applications.kind metrics appropriate temporal relations, transitivity relations implies different features; also, metrics symmetrical, whereas two distinct recall-precision-like values desirable. adapted general idea two functions split nodesrelation similarity, arrived algorithm described below.3.1 Transitive Reduction Endpoint Graphaddress problem finding minimal graphs take account relative importancerelations, take inspiration work Dubois Schwer (2000) two main ideas. First,graphs saturated (i.e. temporal closure applied), converted endpoint graphs. Second,two nodes linked equality relation merged together (this help guarantee uniquenessminimal graph, see below), useful procedure point-based graph (van Beek, 1992). Figure 8presents graph Figure 3 transformation. resulting point graph saturated,definition composition event relations Allens algebra.Recall graph consider built convex annotations, i.e. cannot <> relation two points. keep relations < without loss information, since> obtained symmetry.5. case, creating fictitious unlinked nodes one graph enough.385fiTANNIER & ULLERspecifications, graph boils directed graph transitive relationedge two points x means x y. coherent graph thus acyclic, sincecollapse equal points single nodes. important note consequence, edgetransitive closure labelled equality relation only. Thus see problemsearching transitive reduction graph labelled transitive relation (butkeep additional information edges precisely labelled < insteaddisjunctive ). important minimal graph transitive reductiongraph, transitive reduction directed acyclic graph unique (Aho, Garey, & Ullman, 1972;La Poutr & van Leeuwen, 1988). transitive reduction graph G definition subgraphcorresponding minimal set edges (with respect inclusion) transitiveclosure G, i.e. minimal graph G0 G0 subgraph G G0 = G Gtransitive closure G. simply determined G /(G G ). Algorithm 2 details simplecomputation transitive reduction Figure 9 shows illustration proceduresimple transitive graph. Figure 10 shows process initial endpoint graph <labels, minimal graph, via transitive reduction unlabelled graph.Algorithm 2 Transitive reduction simple computationprocedure COMPOSE(G). find relations inferable othersnewRels={}base_rels= { x x G.edges() x.relation() {<, }}one base_relsrelated ={x x G.edges() x.source()=one.target() x.relation() {<, } }relatedrelation = compose(one.relation(),other.relation())newRels.add(Edge(one.source(),other.target(),relation))endendreturn newRelsend procedureprocedure RANSITIVE - REDUCTION(G)G = closure(G)non_min=compose(G)one non_minG.edges().remove(one)endone G.edges(). remove relations deduced compositionone!=before one!=before_or_equalsG.edges().remove(one). keep <, remove symmetric relationsendendend procedure386fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTION1+41+54235+7756186+7(b)(a)(c)Figure 9: Transitive reduction acyclic graph; (a) initial closure transitive relationgraph; (b) set edges obtained composition edges (a), examples composition edge; (c) transitive reduction, difference(a) (b).387fiTANNIER & ULLER<<<<=<<=<<(b)(a)<=<<=<(d)(c)Figure 10: Transitive reduction point-based graph; (a) initial annotation transformedgraph events endpoints; (b) corresponding graph every label , (c)transitive reduction (d) final minimal graph precise initial information reported.388fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTIONcall:Major relations, relations transitive reduction, Gmaj .Minor relations, relations temporal closure present transitive reduction, i.e. G Gmaj .Formally:Let G = {(x, y, R)/R {<, }}, temporal point graph, saturated respect relation < . G = GLet E(G) = {(x, y)/R, (x, y, R) G}, unlabelled corresponding graph. function fassociates (x, y, R) G (x, y) E(G) obvious bijection, original graph Gone relation holding two vertices. E(G) = f (G). Since G closed,E(G).Let P roj(G0 , G) = {(x, y, R) G/(x, y) G0 } projection unlabelled graphlabelled one. function associating edge (x, y) G0 (x, y, R) G inverse f , f 1 .P roj(G0 , G) = f 1 (G0 ), obviously P roj(E(G), G)) = G.enough prove E(G) (or G) graph transitive, acyclic relation proveE(G) unique transitive reduction (Aho et al., 1972).First, E(G) transitive: let (x, y) E(G) (y, z) E(G) (x, y, <) (x, y,) G (y, z, <) (y, z, ) G four possibilities infer either (x, z, <)(x, z, ) G (because < transitive, transitive x < z x < z implyx < z); words composition < <, i.e. ((< ) = ( <) = (<))(x, z) also E(G) E(G) graph transitive relation. reason saidkeeping record < relations considering G graph change graphproperty.Second, G acyclic since < irreflexive, x < z implies x < z waycycles G paths x z ... x. case inferx = = z = ... nodes would merged beforehand. E(G) also acyclic (itexactly edges G).So, E(G) acyclic transitive thus admits unique transitive reduction E(G)tr .Since graphs G E(G) exactly edges, necessarily reductions, thus unique transitive reduction. project back original relationsG E(G)tr , (P roj(E(G)tr , G)), properly labelled reduction G.3.2 Temporal Recall Precisionidea compare minimal graphs. Temporal closure used well.showed Section 2.4, reference minor relations still rewarded redundantevaluated graph. However, must carry lower weight.Minor relations considered temporal recall, precision. reasonrecall evaluates proportion reference relations found system, systemfind minor relations without major relations produced reference (see B bS4 example, Figure 6). opposite, precision evaluates proportion system relationsreference graph, minor (i.e. deducible) relations found system definitionredundant.recall-like measure combination two values. Given K reference graph Gevaluated graph:389fiTANNIER & ULLERmajor temporal recall rate reference major relations (Kmaj ) found G .minor temporal recall rate reference minor relations (K Kmaj ) found Gmaj .first case, temporal closure applied G, since reason restrain searchgood relations evaluated graph. second case, transitive reduction Gmajconsidered; reference minor relations must rewarded minor G (case B bexample S2 , Figure 6). G minor relations already assessed major relations(case b C example S4 ).final value temporal recall weighted sum two figures.precision-like measure single value corresponding ratio correct relationsGmaj total number relations. G minor relations must considered precision. Unlike recall reference major relations may retrieved system, precisionnecessarily considers major relations system. Minor relations redundant.precision well recall, merge must considered relation way,corresponds = relation.3.3 Notationsnote:G K event graphs, K reference (key);Gpt K pt , corresponding endpoint graphs, equals points merged.(N, R) set nodes relations graph G, mutatis mutandis others.examples, non-trivial relations listed. Trivial relations involving twopoints interval. example, A1 < A2 Figure 8 trivial, thus considered.figures, trivial relations dashed gray lines. Non-trivial relations node listenough find full graph.temporal closure G noted G .transitive reduction G noted Gmaj .3.4 Temporal Recall Precisionnew metrics temporal recall precision rely notions defined above. respectrecall value, shown important distinguish major relations, i.e. relationsbelong minimal graph, other, minor relations. suggest computerecall two steps. Precision concerned issue.3.4.1 G RAPH VALUESLets consider Gpt set merged nodes relations (N pt , Rpt ) evaluated respectptptreference K pt = (NK, RK). need take account number relations expressedoriginal point graph nodes merged (called value(Gpt )), number equalities expressed merged nodes, node_values(Gpt ), plus number relations relation_value(Gpt ).Then:pt )value(Gpt ) = node_value(G+ relation_value(Gpt )Ppt=ni N pt (|m(ni )| 1) + |R |= |N | 2 |N pt |+ |Rpt |390fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTIONHere, m(ni ) number points merged node (m points node correspond 1merges). Similarly, compute value reference graph.pairing nodes evaluated graph reference graph must takenaccount. Lets call split operation mapping one node reference graph manynodes evaluated one, conflation, converse operation. map graphs, firstneed split node reference evaluated graph nodesmaybe extra nodes, conflate, necessary, remaining nodes evaluated nodes (seeSections 4 5 illustration). split like = relation provided referenceevaluated graph. conflation = wrongly predicted evaluated graph.Therefore, number correct answers evaluated graph, correct value vc , numbercorrect = < relations6 . number correct = node value - nb conflations,number correct < relation value - wrongly predicted relations (errors).simple way calculating number splits necessary match two graphs G1 G2count node x G1 number different nodes G2 intersect x. one,node mapped directly, otherwise 1 splits needed. Thus:P|split(K pt , Gpt )| = xN pt |{y N pt /x 6= }|Knumber conflation necessary match G1 G2 also number splits necessary matchG2 G1, so:|conf lation(K pt , Gpt )| = |split(Gpt , K pt )|vc (Gpt ) ====correct equalities + correct precedences(node_value(Gpt ) conflations)) + (relation_value(Gpt ) errors)v(Gpt ) (|conf lation(K pt , Gpt )| + errors)v(Gpt ) (|split(Gpt , K pt )| + |R RK |/|R|)3.4.2 EMPORAL R ECALL P RECISIONprecision value deals errors (incorrect relations) conflations correct value vc .hand, recall value must take account misses (reference relations missedptpoint-based reference, G = Gptgraph) splits. simplicity, lets note K = KKgraph evaluate. Kmaj Gmaj transitive reductions these. define:Major temporal recall Rt (G) number reference major relations found G .Rt (G) =Rt (G) =v(Kmaj ) (splits + misses)v(Kmaj )v(Kmaj ) (|split(K, G)| + |(RK R )/RK |)v(Kmaj )misses number relations Kmaj missed G splits number splits(a split missed = relation).6. consider course non trivial relations.391fiTANNIER & ULLERSymmetrically, Temporal precision P (G) ratio correct value Gmaj ,vc (Gmaj ), full value v(Gmaj ).P (G) =P (G) =v(Gmaj ) (conf lations + errors)v(Gmaj )vc (Gmaj )v(Gmaj )But, already stated, minor relations also taken account. considermajor recall, systems find minor (but correct) relations disadvantaged. casesystem S2 Figure 6 (B b correct minor). add minor temporal recall:Minor temporal recall rt (G) proportion reference minor relations (K Kmaj ) foundGmaj . Minor relations seeked minimal evaluated graph. Indeed, alreadysaid, comparing two relations non-minimal graphs redundant, since major relationsproduced already taken account.Full temporal recall R could defined value pair (Rt (G), rt (G)), preferablycombination:R(G) = Rt (G) +1rt (G)v(Kmaj )(2)formula, ensure one single major relation better minor onesrecall exceed 1 (see next Section).symmetrical precision property, i.e. proportion system minor relations existingreference, always null. System minor relations are, definition, always redundant.temporal precision need two-fold figure.tool computing different precision recall values (strict, relaxed, core, wellnew one) made available paper7 . accepts several input formats, including TimeML.computed data also available, instructions reproduce experiments presented endpaper.3.4.3 YNTHESISEvaluating interval graph G gold reference K achieved following steps:1. Perform transitive closure G K.2. Convert graphs endpoint graphs.3. Merge equality relations single nodes.4. Perform transitive reduction.5. Compute values temporal recall precision.7. http://www.irit.fr/~Philippe.Muller/resources.html392fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTIONcostly operation first one, common standard evaluation procedure; time O(|N |3 ) worst case algorithm 1 page 379, N set eventslargest graph G K. straightforwardly linear number relationsgraph (conversion endpoints, merge equalities closed graph), worse O(|N |2 )transitive reduction (one composition relations graph set difference),computation number splits conflations. Overall, whole procedure dominatedfirst step, common evaluation procedures task. proposition thuschange worst-case complexity evaluation procedure.3.4.4 B OUNDARIESTemporal precision. Temporal precision value 0 1 since vr (G) v(G) (errorsconflations zero positive).Temporal recall.Major recall 0 1.1, minor recall rt (G) = 0, relations Gmaj already Kmaj (andcannot K Kmaj ). case temporal recall cannot exceed 1.1,Rt (G) (v(Kmaj ) 1)/v(Kmaj ). Yet,stays 1.1v(Kmaj ) rt (G)<1v(Kmaj ) ,full temporal recallThus 0 R(G) 1.order make measure clearer, present metric detail developing basicexample transitive closure made simple relations (the 13 basic Allen relations),turn general case closure made convex temporal relations (disjunctionsneighboring Allen relations).3.4.5 IMPLE E XAMPLESTemporal recall precision described lead expected values sample graphspictured Figure 6 analyzed Section 2.4.Figure 11 recalls graphs details temporal recall values (givenv(Kmaj ) = 3). precision, graph Si , P (Si ) = 1.attentive reader would note system providing minor relations, < C, <B < C, i.e. half deducible relations, would get recall 0.33, could seem unfair.However, even three relations present, three others still missing (the number missingrelations graph relation all). Moreover, fact minor relations getbetter score one major relation condition boundaries go 1. Finally,case rare affect general behavior metric.sophisticated examples provided following sections.4. First Simple Case: Non-Disjunctive Allen RelationsConsider sample graph K1 made Allen non-disjunctive relations (see also graph Figure 12):393fiTANNIER & ULLERKBCS1BCR(S1 ) = 3(1+0)+ 03 = 0.673(2 major relations, 1 missing)S2BC1R(S2 ) = 3(2+0)+ 33= 0.443(1 major 1 minor relations)R(S3 ) = 3(1+0)+ 03 = 0.673(2 major 1 redundant minor relations)1R(S4 ) = 3(1+0)+ 33= 0.773(2 major 1 non-redundant minorrelations)S3S4BCBCFigure 11: Temporal recall simple graphs, compared reference K.B C Ebi bBbiK1 =Cb bfEFbbeficonversion relations endpoints leads following graph, eventsplit A1 A2. Edges labelled since relation < considered point.A1K1majC1C2B1E1A2B2E2D1D2F1F2Figure 12: Reference simple relations, K1maj .Note merging equal nodes equivalent labelling arcs =, lattercase minimal graph would unique more. example, necessary choiceA1 < A2, B1 < A2 E1 < A2 would lead three equivalent different graphs.Consider reference K1 compared following graph G1 (Figure 13; bold edgescorrect relations, thin edges wrong relations, dashed edges trivial relations, i.e. involvingtwo endpoints interval).Following notations defined Section 3.3:list nodes graphs K1maj G1maj are:394fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTIONG1majC1B1C2A1B2D1A2E1F1E2F2D2Figure 13: Evaluated graph simple relations, G1maj .K1maj : N 1 = {C1, C2, (A1, B1, E1), A2, (B2, D1, F 1), (E2, D2, F 2)} : 6 nodesG1maj : N 2 = {C1, B1, C2, (A1, B2), A2, (D1, E1, F 1), (E2, F 2), D2} : 8 nodesNon-trivial relations are:K1maj : R1 = {[C2; (A1, B1, E1)], [A2; (B2, D1, F 1)]} : 2 relationsG1maj : R2 = {[C1; B1], [B1; C2], [C2; (A1, B2)], [A2; (D1, E1, F 1)],[(E2, F 2); D2]}] : 5 relationstemporal closures Gi computed listed (bold relations addedminimal graph, i.e. K1 K1maj G1 G1maj ). Relations line sharearguments (at least one point common argument). Figures 14 15 also representclosures.K1[C2; (A1, B1, E1)][A2; (B2, D1, F 1)][C1; (A1, B1, E1)][C1; A2][C1; (B2, D1, F1)][C1; (E2, D2, F2)][C2; A2][C2; (B2, D1, F1)][A2; (E2, D2, F2)][C2; (E2, D2, F2)]G1[C2; (A1, B2)][A2; (D1, E1, F 1)][C1; B1][C1; A2][C1; (A1, B2)][C1; (D1, E1, F1)][C1; D2][C1; (E2, F2)][C2; A2][C2; (D1, E1, F1)][A2; (E2, F2)][A2; D2][C2; (E2, F2)][C2; D2][B1; C2][(E2, F 2); D2][B1; A2][B1; (D1, E1, F1)][B1; (E2, F2)][B1; D2][(A1, B2); (D1, E1, F1)][(A1, B2); (E2, F2)][(A1, B2); D2]pairing nodes list splits conflations needed match sets nodesalso computed (see also Figure 16):395fiTANNIER & ULLERK1A1C1C2A2B1E1B2E2D1D2F1F2Figure 14: Temporal closure K1 . Dotted relations represent K1 K1maj .G1C1B1A1C2B2D1A2E1F1E2F2D2Figure 15: Temporal closure G1 . Dotted relations represent G1 Gmaj .(A1, B1, E1)K1 : 2 splits (breaking 2 equality relations); (B2, D1, F 1)K1 : 1 split(D1 F 1 stay together G1); (E2, D2, F 2)K1 : 1 split(A1, B2)G1 : 1 conflation (joining two nodes); (D1, E1, F 1)G1 : 1 conflation (joining E1two others); (E2, F 2)G1 : nothing (already together K1)Total: 4 splits 2 conflations.stated above, edge correct relation correct least one pair pointsnodes. example, relation {A2}G1 {D1, E1, F 1}G1 correct {A2}K1{B2, D1, F 1}K1 , even sub-relation A2 < E1 true. latter relation penalized anyway split necessary matching graphs.definitions lead following values;Graph values:v(K1maj ) = node value + relation value = 6 + 2 = 8v(G1maj ) = 4 + 5 = 9Correct value G1:vc (G1maj ) = (node value conf lations) + (relation value errors)= v(G1maj ) (conf lations + errors)= 9 (2 + 2) = 5Major temporal recall:Rt (G1) ==v(K1maj ) (misses + splits)v(K1maj )8 (0 + 4)= 0.58Minor temporal recall: rt (G1) = 28 = 0.25(this corresponds [C1; {A1, B1, E1}] [C2; (B2, D1, F 1)]).396fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTIONA1K1C1C2A2B1E1splitsplitsC1B1C2splitA1B2A2merg.G1(afterconations)C1B1E2D2F1F2splitsplitE1D1E2F1F2D2merg.D1A1C2B2D1A2B2E1F1E2F2D2Figure 16: Split conflation operations K1 G1.Full temporal recall:R(G1) = (R(G1), r(G1))= (0.5, 0.25)R(G1) = Rt (G1) += 0.5 +1rt (G1)v(Kmaj )0.25= 0.538Temporal precisionP (G1) ==vc (Gmaj )v(Gmaj )5= 0.5695. Disjunctive Convex Relationsapply metric sets convex relations. Convex relations set relationsconceptual neighbors, encode relations may vague intervals endpointsconvex subsets time-line (see Section 2.2).Building minimal graph follows procedure explained (transitive reduction).measures differ choose strict scoring scheme (see Section 2.3).relaxed scheme, disjunctions, becomes necessary apply weighting procedure; responselonger assigned binary value (0 1), example one values Table 3, mannersimilar done TempEval (Verhagen et al., 2007).shown table, relaxed measure effect misses values vc (a relationget half-point), also conflation split values (where half-points also possible).397fiTANNIER & ULLER%Rel.Repres.<B10>BB<<, =B0.5B<>B<B<, =B=<=0( 12 -split)0B10.50.5( 12 -split)00(disjunction)<, =<B0.50.5( 12 -confl.)(disjunction)00100.5(disjunction)010.5(disjunction)<, =0.50( 12 -confl.)0.50.5(disjunction)(disjunction)1Table 3: Example weights relaxed measures.Consider new reference K2 convex relations (see also Figure 17):BCEF{bi, mi, oi, f i, =, f, di, si} bbB{di, si, oi, mi, bi}Cb {d, s, o, m, b }bf{s, =, si}E{di, f i, o}characteristics K2 are:7 nodes 6 events (5 equality relations)2 relations: [C2 A2], [A2 < {B2, D1, F 1}]K2 =[C2 A2], [A2 < {B2, D1, F 1}], C1 < A2, C1 < {B2, D1, F1}, C1 < {E2, D2},C1 < F2, C2 < {B2, D1, F1}, C2 < {E2, D2}, C2 < F2, {A1, B1, E1} < F2,A2 < {E2, D2}, A2 < F2v(K2maj ) = (12 7) + 2 = 7.Let us consider evaluated graph G2 (Figure 18) has:10 nodes 6 events (2 equality relations)5 relations: [C1 D1], [D2 < C2], [C2 A2], [{A1, B1} E1], [A2 < {B2, F 1}]G2 = [C1 D1], [D2 < C2], [C2 A2], [{A1, B1} E1], [A2 < {B2, F 1}],[C1 < D2], [C1 < A2], [C1 < {B2, F1}], [C1 < F2], [D1 < C2], [D1 < A2],[D1 < {B2, F1}],[D1 < F2],[D2 < A2],[D2 < {B2, F1}],[D2 < F2],[C2 < {B2, F1}], [C2 < F2], [A2 < F2], [{A1, B1} < F2], [{A1, B1} < E2]v(G2maj ) = (12 10) + 5 = 7.398fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTIONA1B1E1K2majC1<E2<<,=<A2B2<D1<F1D2F2C2Figure 17: Reference convex relations, K2maj .C1<,=D1<D2<C2<,=A1G2maj<B1A2<B2F1<F2<,= (1/2-split)E1<E2Figure 18: Evaluated graph convex relations, G2maj .conflation number splits 2.5. half-split comes factE1 may equal {A1, B1}, edge.application measures leads following values:Rt (G2) =7 (0 + 2.5)= 0.647rt (G2) = 0R(G2) = 0.64vc (G2) = (12 + 2 1/2) + 2 = 15two half-points vc (G2) hold relations C1 D1 (instead C1 < D1 reference)B1 E1 (instead B1 = E1 reference).example, following Table 3, see E1 leaving group {A1, B1, E1} costshalf-point recall value, relation B1 E1, correct imprecise, gets half-pointprecision. results seem logical behaviors measure.6. Experimentspush change evaluation measures temporal annotation graphs motivatedbeginning paper examples show undesirable side effects common399fiTANNIER & ULLERevaluation procedures. present thorough methodology, aiming evaluateevaluation procedure itself. used two kinds data purpose. Obviously, testcompare measures freely available temporal annotated data provided TimeBankcorpus. also introduce set artificially built temporal graphs, controlrelevant parameters. TimeBank annotations rather heterogenous, human annotators makemistakes, forget relations, introduce inconsistencies, thus creating fair amount noise. Besides,wanted test aspects temporal annotation easier generate scratch. Onefactor amount information present annotation. seen resultannotation less underspecified: relation events simple, preciserelation, disjunction simple relations. size graph also probably important,somewhat hidden human annotations, really relevant object consideringinferred information connected component. Small subgraphs nodes allowlot inferences, bias want study probably happens certainthreshold. human annotations, size subgraphs vary lot, common eventsrelated one two events, even graph enriched inferenceprocedures.main experiment performed study behavior commonly adopted measuresproposal based comparison annotation weakened version itself.graph, remove portion event-event relations random, use measures estimateloss information. Obviously, interesting recall-like measures, precisionaffected. vary amount removed information steps, relations vague: eventually,universal disjunction hold two events text. designed another experimentwatch also behavior precision measures : instead removing relations, disturbed graphchanging simple relation another one (simulating error annotation, way).meaningful keep graph consistent time.follows, present results synthetic graphs (6.1) TimeBankdata (6.2).6.1 Artificial Graphsorder control amount information present temporal graph, built setartificial temporal graphs following way:given number events E, temporal graph built randomly choosing set Einteger pairs (bi , ei ), within given range N , level indeterminacy I,width around boundaries bi ei .pair events (i, j), determine temporal relation intervals, considering endpoints lie anywhere interval [bi I/2, bi + I/2][ei I/2, ei + I/2], endpoints j lie anywhere interval [bj I/2, bj + I/2][ej I/2, ej + I/2].graph closed, leading N = (E (E 1))/2 relations.Events considered intervals uncertainty endpoints, comparablegraph built text, give rise possibly disjunctive relations generatedevents. graph thus contain kind convex (possibly disjunctive) Allen relations.example generated events provided Figure 19. varying N I, control400fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTIONbeginningE5endE5E5E4E3E2E1015101520Figure 19: Example random artificial graph N = 20 (X-axis), E = 5 = 3 (maximumuncertainty endpoint). indeterminacy leads disjunctive relations, example ((E5 < E3) (E5 meets E3) (E5 overlaps E3)). building graphsrepresentation, relations disjunctive graph fully connected,case real data like TimeBank.amount vagueness information put graph. smaller N is, tighter modelgenerate, likely vague boundaries intersect, creating disjunctive relations.larger also contributes vaguer representation. quantify amount vagueness vmuch relations disjunctive graph:P1redges(G) 1 |r|v=|edges(G)|r edge graph |r| number simple Allen relations disjunction(i.e.: r = {b, o}, |r| = 2).Figure 20 shows different values strict recall temporal recall (called point recall)according proportion relations kept graph, lines joining values derivedgraphs.interesting note curves based minimal graphs almost linear, simpler measures decrease slowly first sharply, parabolic way. analyze(Section 6.2.2) difference y=x.shows overall effect observable roughly every graph considered. effecteven marked number events higher.also compare point-based measure relaxed recall measure, similar measureused TempEval campaign computes overlap simple disjunctiverelations every edge graph. also want see behavior measure based coreset relations extracted annotation previous work (Tannier & Muller, 2008).see Figure 21 measure behaves linearly point-based one. Here,plotted estimates parabolic regression data set, clarity. others measures show clearly parabolic behaviors, different undesirable effects: relaxed recall muchpermissive information actually provided (since disjunction relations,401fiTANNIER & ULLERexperiment : remove1.0experiment : remove1.0strict recallid0.60.6score0.8score0.8recall/point graphid0.40.40.20.20.00.00.20.4% modified0.60.80.00.01.00.20.4% modified0.60.81.0Figure 20: Behaviors graph 30 events, strict recall (left) point-based recall (right).carry information, gets non-zero score), recall respect core relations similarstrict recall, surprisingly even less linear. effect stronger numberevents increases.experiment : remove1.2recall/corestrict recallrecall/point graphrelaxed recallid1.0score0.80.60.40.20.00.00.20.4% modified0.60.81.0Figure 21: Parabolic regressions recall measures considered (30 event graphs).Finally, Figure 22 shows influence different levels vagueness annotation (andthus underlying temporal description) measures used. plotted experiment(recall respect quantity information removed) vagueness considered graphs third parameter. surface shown departure y=x line,readabilitys sake.observe less vague temporal descriptions values mainly y=xline parabolic measures, vaguer data show less obvious parabolic behavior, sometimes402fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTIONline. curves point-based recall seems insensitive aspect, consistentaverage behavior already discussed.0.80.8recall/point graph0.6strict recall0.40.2d0.2isjunc 0.4tion le 0.6vel0.80.80.60.20.4 ovedemr%0.60.40.2dis0.2junct 0.4ion le 0.6vel0.80.80.60.20.4 ved% remFigure 22: Influence vagueness annotation behavior different measures (30event graphs), strict recall left point recall right.6.2 TimeBank Corpuspresenting results evaluations real annotated data TimeBank corpus,show characteristics temporal graphs induced annotations. helps understanddifferences behavior observe synthetic temporal graphsecological ones.6.2.1 NALYSIS IME BANK C ORPUSTimeBank corpus consists 186 news report document (for 65, 000 tokens). madenews articles Associated Press, Wall Street Journal, L.A. Times SanJos Mercury News, transcripts broadcast news CNN, ABC, VOA. documentsinitially collected DUC ACE evaluation campaigns. corpus version 1.1available http://www.timeml.org/site/timebank/timebank.html.8Documents annotated using TimeML standard tagging events states, dates, times,durations, temporal relations well various aspectual modalities. entitiesalso tagged attributes: tense, aspect verbs, values dates durations, normalizedaccording ISO standard 8601.Eventualities denoted verbs, nouns, adjectives prepositional phrases.temporal relations encode topological information time intervals occurring eventualities, using relations equivalent Allen relations, although different names.TimeML standard specifies relations events, anchoring events times (dates,hours) relations times. 7000 annotated relations temporalentities. Additions set proposed (Bethard, Martin, & Klingenstein, 2007), ordercomplete annotations. noted Setzer (2001), tagging temporal relations hard8. somewhat cleaned-up version, 1.2, available via Linguistic Data Consortium. used freely availableversion, checking recent version exhibit significant differences experiments.403fiTANNIER & ULLERFigure 23: Frequencies TimeBank texts respect number temporal entities.ModeConsistent annotationsAverage number relationsAverage nb components/textComponent Average sizeMax component average sizeRaw186435.287.9419.64+time-time relations186587.155.8927.04Saturated1311345.287.9419.64Saturated + t-t1462817.155.8927.04Table 4: Timebank1.1 statistics (Average number temporal entities=42)annotators, tend miss relations, produce inconsistent annotations.obvious sizes texts increase, since number possible links grows squarenumber temporal entities. Figure 23 shows distribution events among texts.annotators could expected keep track possible relations events small texts,task probably different numerous larger texts, noted tend produce sets disconnected temporal subgraphs majority corpus (Chambers & Jurafsky,2008b).Table 4 shows two important consequences considering relations inferred annotation: (a) lot annotations TimeBank 1.1 actually inconsistent temporal graphsaturated using procedures introduced earlier paper (b) text gives rise several connected components various sizes. worse compute missing (but obvious) relationsdates whose values fully specified (noted t-t table). seen, procedurechecking consistency say set relations globally inconsistent, without hintrelation(s) isolated repair situation. texts thus ignoredevaluations.fact temporal graphs texts actually split components differentsizes consequences considering size referent graph: fully connected graphn entities n (n 1)/2 non-vague edges saturation, text scatteredannotations might yield relation much smaller graph.compared number relations present minimal graph obtained transitivereduction number temporal closure interval-based graph, respectnumber events present text, whole TimeBank Corpus 1.1. (Figure 24). Figure,point corresponds text, number events along x-axis number relations404fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTIONreference used evaluation given measure along y-axis. appears minimalgraph grows roughly linearly expected (the variance due variable multiple branchinglot uncertainty). hand, temporal closure annotation larger, muchirregular, greater variance number events grows. even worserelaxed measures necessarily consider every possible edge two events, even thoughmight bear non-informative vague relations consisting disjunction many relations.Note however reference size quadratic number events, due high numbersmall self-connected components, noted previous paragraph.taken account considering evaluation entire corpus, deciding contribution made one text, set temporal relations. casestrict recall, practice add edges temporal closures, possibly giving giventext weight proportional square number events. Micro-averaging resultstext probably desirable either, giving much importance small texts relations.reference size linear number events solves problem, providing sortsmoothing respect factor.influence size reference graph size1200strict recallrecall/point graphrelaxed recally=xid1000size reference8006004002000050100150200nb events250300350400Figure 24: Number relations considered reference vs. number events texts, according measure used.405fiTANNIER & ULLER6.2.2 EASURES IME BANKRecall performed experiments TimeBank synthetic data,observe phenomenon (a linear decrease point recall), raw results muchirregular (Figure 25), larger unstability almost relations removed.Note synthetic graph measures values mainly y=x line,variation, annotated data show kind parabolic behavior line.main difference reference structured. way generated graphs builtensures fully connected, relations saturated graphs consideredreference, since reason distinguish subset particular. hand,human-annotated corpus, removed relations set initial relations taggedannotators.first case (artificial data), reference graph resistant removal randomrelations, since redundancy, extreme manner: enough relationsremoved information actually lost. leads parabolic curve y=xline, showing redundancy improperly assessed regular recall. point graph immuneeffect since relevant relations isolated first.natural graphs contrary, annotation fragile: annotators tend putmuch redundant information annotation. Then, removing removes alsolot inferred relations time (in quadratic quantity). would problemevaluation could stick annotated relations everyone tagged event pairs. But,already noticed, case. consider system trying build temporal graphtext scratch, reason provide event pairs reference.reason, soon redundancy broken removing relations, recall improperly fallsfaster y=x does. Again, point-based graphs isolate likely underlying modelsbehavior thus controlled.Remember also level vagueness influences shape curves, humanannotations less specified thus highly disjunctive.also assume human choices, annotating, important. Annotated relationsprobably regarded central annotators, hence close ideal core set, especially sinceannotators tend minimize number relations tag. assumption verifiedexperiments human assessments.Precision estimate behavior precision measures, slightly changed experimentswitching relations different ones, thus disturbing initial graph, tryingkeep consistent. Again, number times, averaged results pointssimilar rates undisturbed relations. result, shown Figure 26, restricted smaller valueschange, since increase proportion changed relations, graph gets closer purelyrandom annotation. arbitrarily kept values 0 40% relations changed random.course, without control kind change allowed, generate lot differenttypes modifications, minor well totally change inferences drawnannotation. reflected huge variance results observed detailed data(not shown here), even close origin, i.e. unchanged graph. Still, experiment seemsconfirm point-based measure follows closely ideal y=x function, wouldstable others, previous caveat variance.System prediction Finally, last indication importance evaluation methodology,made comparison behavior measures predictions real system.406fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTIONexperiment : remove1.00.8experiment : remove1.0strict recallstrict recallidrecall/point graphrecall/point graphid0.8score0.6score0.60.40.40.20.20.00.00.20.4% modified0.60.80.00.01.00.20.4% modified0.60.81.0Figure 25: Behavior recall measures TimeBank according amount temporal information removed, (left) strict recall (right) recall point-based graph, solid linesshowing parabolic regression.experiment : disturbprecision/point graphrelaxed precisionsimple precisionid1.00.8score0.60.40.20.00.00.20.4% modified0.60.81.0Figure 26: Linear regression precision measures according amount temporal informationdisturbed reference (TimeBank) range 0-40%407fiTANNIER & ULLERrather tricky issue, since want see measure distinguishes better method others,way evaluating better method measure want assess.motivation set experiments presented above. Still, legitimate wonderleast observe differences context real system. One must cautiousconclusions drawn this. order so, took implementationtemporal relation classifier reproducing standard work, instance work Mani etal. (2006), used one authors another study (Denis & Muller, 2010). appliedTimeBank 1.1, checked correlations usual (strict) precision/recallcounterparts based transitive reduction. Figure 27 shows relations scorestext, subfigure precision one recall. spearman correlation, estimatesone variable monotonically related without assumption, 0.86 precision,0.61 recall, high significance levels (p < 1020 ). tentative interpretationmake obviously related, types measures show lot variancedifferent texts, obviously sensitive differences predictions. Texts indeedordered differently different sets measures. especially true recall. alsonote point-based scores generally higher, easily explained since relationsevent correct relations endpoints correct time. Inferences stillmuddy waters yield different results respect, could interesting investigatedifferences detail.Correlation precision point precision base classifier TB 1.11.0Correlation recall point recall base classifier TB 1.10.90.80.80.7pt_recallpt_precision0.60.60.40.50.40.30.20.20.10.00.00.20.4precision0.60.80.00.01.00.20.4recall0.60.81.0Figure 27: Correlations classical measures proposal. Precisions left, recalls right.7. ConclusionComparing temporal constraints graphs crucial task extracting temporal informationtexts, evaluation point view perspective incorporating global constraintsstatistical learning procedures.argue comparison measures devoid biases inherent commonlyused comparisons closures Allen-based temporal graphs. measure defined transitivereductions graph (partially) ordered interval endpoints. Transitive reduction conceptuallyintuitive, easy compute unique cases considered. shown empiricallybehavior kind measure appropriate goals mind.408fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTIONclaim ordering interval endpoints considered annotation providedhumans, translation possible useful. remains unclear could alsoacceptable way presenting temporal information humans, resulting minimal graphscould meaningfully re-translated interval-based relations. claim either pointrelations target automated procedures extract temporal information. bulkwork done event relation classification deals primarily extended intervals,literature temporal semantics (Steedman, 1997; Kamp & Reyle, 1993).plan check assumption procedure translating interval constraints endpoint constraints could useful task learning temporal constraints integration globalconstraints (for instance good indication close two temporal situations may be).also useful designing distances structures order make structured predictions,manner similar done tree kernels syntactic parsing (Collins & Duffy, 2002).far automated attempts aim predicting relations given event-pairs,rely local learning strategy take account temporal constraints wholetext. exceptions (Chambers & Jurafsky, 2008b; Bramsen et al., 2006) make use subsetsrelations, instance subset {before, after}, relation considered vague.able use integer linear programming using transitivity constraints temporal order.simplicity could preserved endpoint translation full algebra.issues presented relevant also graph-based representations natural language processing tasks, long inference issues: instance discourse representationsoften build set rhetorical relations segments (Marcu & Echihabi, 2002). Inferenceproperties relations remain investigated, automated processes still quite rare (butsee works Sagae, 2009; Wellner, Pustejovsky, Havasi, Rumshisky, & Saur, 2006; Subba & Di Eugenio, 2009), however widely adopted structures behave like partial orders (narrative chains,topic elaborations) thus follow patterns investigated. case partial annotations partial agreement, finding minimally equivalent representation could usedcomparison.limitations methodological study also limitations knowledgeway human readers process temporal information, whole, found texts.best knowledge, psycholinguistics literature little interest specific question.Work exists local temporal interpretation, i.e. way temporal order two eventsdetermined, respect linguistic extra-linguistic factors (Zwaan & Razdvansky, 2001).global context, studies focussed way reader builds situation correspondingtext (Speer, Zacks, & Reynolds, 2007; Zwaan, 2008), temporal, spatial, causal aspects,seems events grouped time-frames, sets events causal relations, comprehensionshifts one time-frame representation another. approaches right, readers buildmental models correspond situation given time-frame, explicitly recordrelations time-frames. could explain structure lot annotations (a set smallconnected components), say much nature knowledge represented.remains seen investigations process human comprehension could beneficialcomputationally oriented approaches process.8. Acknowledgmentswork benefited tremendously helpful feedback several colleagues, mainly PierreZweigenbaum Pascal Denis, Nicholas Asher. Pascal Denis also contributed development temporal tools used work, allowed us use results system409fiTANNIER & ULLERdeveloped Philippe Muller temporal relation identification. also thank Michel Gagnon,suggested comparison annotation degraded version evaluationmeasure, long time ago.ReferencesAho, A., Garey, M., & Ullman, J. (1972). Transitive Reduction Directed Graph. SIAMJournal Computing, 1(2), 131137.Allen, J. (1983). Maintaining Knowledge Temporal Intervals. Communications ACM,832843.Asher, N., & Lascarides, A. (1993). Temporal interpretation, discourse relations, commonsenseentailment. Linguistics Philosophy, 16, 437493.Bethard, S., Martin, J. H., & Klingenstein, S. (2007). Timelines text: Identification syntactic temporal relations. International Conference Semantic Computing, pp. 1118, LosAlamitos, CA, USA. IEEE Computer Society.Bramsen, P., Deshpande, P., Lee, Y. K., & Barzilay, R. (2006). Inducing temporal graphs. Proceedings 2006 Conference Empirical Methods Natural Language Processing, pp.189198, Sydney, Australia.Chambers, N., & Jurafsky, D. (2008a). Unsupervised Learning Narrative Event Chains. Proceedings ACL-08: HLT, pp. 789797, Columbus, Ohio. Association Computational Linguistics, Morristown, NJ, USA.Chambers, N., & Jurafsky, D. (2008b). Jointly combining implicit constraints improves temporal ordering. Proceedings 2008 Conference Empirical Methods Natural LanguageProcessing, pp. 698706, Honolulu, Hawaii. Association Computational Linguistics, Morristown, NJ, USA.Collins, M., & Duffy, N. (2002). New ranking algorithms parsing tagging: Kernelsdiscrete structures, voted perceptron. Proceedings 40th Annual MeetingAssociation Computational Linguistics, pp. 263270, Philadelphia, Pennsylvania, USA. Association Computational Linguistics.Denis, P., & Muller, P. (2010). Comparison different algebras inducing temporal structuretexts. Proceedings Coling 2010, pp. 250258, Beijing.Dubois, M. F., & Schwer, S. R. (2000). Classification topologique des ensembles convexes de Allen.Proceedings Reconnaissance des Formes et Intelligence Artificielle (RFIA), Vol. III, pp.5968.Freksa, C. (1992). Temporal reasoning based semi-intervals. Artificial Intelligence, 54(1-2), 199227.Grover, C., Hitzeman, J., & Moens, M. (1995). Algorithms analysing temporal structurediscourse. Sixth International Conference European Chapter AssociationComputational Linguistics. ACL.Kameyama, M., Passonneau, R., & Poesio, M. (1993). Temporal centering. Proceedings ACL1993, pp. 7077.Kamp, H., & Reyle, U. (1993). Discourse Logic. Kluwer Academic Publishers.410fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTIONLa Poutr, J., & van Leeuwen, J. (1988). Maintenance transitive closures transitive reductionsgraphs. Gttler, H., & Schneider, H.-J. (Eds.), Graph-Theoretic Concepts ComputerScience, Vol. 314 Lecture Notes Computer Science, pp. 106120. Springer Berlin / Heidelberg.Lapata, M., & Lascarides, A. (2006). Learning Sentence-internal Temporal Relations. JournalArtificial Intelligence Research, 27, 85117.Mani, I., Pustejovsky, J., & Gaizauskas, R. (Eds.). (2005). Language Time: Reader. OxfordUniversity Press.Mani, I., & Schiffman, B. (2005). Temporally Anchoring Ordering Events News. Pustejovsky, J., & Gaizauskas, R. (Eds.), Time end Event Recognition Natural Language. JohnBenjamin.Mani, I., Verhagen, M., Wellner, B., Lee, C. M., & Pustejovsky, J. (2006). Machine learningtemporal relations. Proceedings 21st International Conference ComputationalLinguistics 44th Annual Meeting Association Computational Linguistics, pp.753760, Sydney, Australia. Association Computational Linguistics.Mani, I., Wellner, B., Verhagen, M., & Pustejovsky, J. (2007). Three Approaches Learning TLINKsTimeML. Tech. rep., Computer Science Department, Brandeis University. Waltham, USA.Marcu, D., & Echihabi, A. (2002). unsupervised approach recognizing discourse relations.Proceedings 40th Annual Meeting Association Computational Linguistics, pp.368375, Philadelphia, Pennsylvania, USA. Association Computational Linguistics.Muller, P., & Tannier, X. (2004). Annotating measuring temporal relations texts. Proceedings20th International Conference Computational Linguistics (Coling 04), pp. 5056,Geneva, Switzerland. COLING.Passonneau, R. J. (1988). computational model semantics tense aspect. ComputationalLinguistics, 14(2), 4460.Pustejovsky, J., Hanks, P., Saur, R., See, A., Gaizauskas, R., Setzer, A., Radev, D., Sundheim, B.,Day, D., Ferro, L., & Lazo, M. (2003). TIMEBANK Corpus. Proceedings CorpusLinguistics, pp. 647656, Lancaster University, UK.Reichenbach, H. (1947). Elements Symbolic Logic. McMillan, New York.Rodrguez, A., de Weghe, N. V., & Maeyer, P. D. (2004). Simplifying Sets Events SelectingTemporal Relations. Geographic Information Science, Third International Conference, GIScience 2004, Vol. 3234/2004 Lecture Notes Computer Science, pp. 269284, Adelphi,MD, USA. Springer Berlin / Heidelberg.Sagae, K. (2009). Analysis discourse structure syntactic dependencies data-driven shiftreduce parsing. Proceedings 11th International Conference Parsing Technologies(IWPT09), Paris, France.Saur, R., Littman, J., Knippen, R., Gaizauskas, R., Setzer, A., & Pustejovsky, J. (2006). TimeMLAnnotation Guidelines, Version 1.2.1.. http://timeml.org/site/.Schilder, F. (1997). hierarchy convex relations. Proceedings 4th International WorkshopTemporal Representation Reasoning (TIME 97), pp. 8693, Washington, DC, USA.IEEE Computer Society.411fiTANNIER & ULLERSetzer, A. (2001). Temporal Information Newswire Articles: Annotation Scheme CorpusStudy. Ph.D. thesis, University Sheffield, UK.Setzer, A., Gaizauskas, R., & Hepple, M. (2006). Role Inference Temporal AnnotationAnalysis Text. Language Resources Evaluation, 39, 243265.Song, F., & Cohen, R. (1991). Tense interpretation context narrative. ProceedingsAAAI91, pp. 131136.Sorlin, S. (2006). Mesurer la similarit de graphes. Ph.D. thesis, Universit Claude Bernard, Lyon I.Speer, N., Zacks, J., & Reynolds, J. (2007). Human brain activity time-locked narrative eventboundaries. Psychological Science, 18(5), 449.Steedman, M. (1997). Temporality. van Benthem, J., & ter Meulen, A. (Eds.), Handbook LogicLanguage. Elsevier.Steedman, M. (1995). Dynamic semantics tense aspect. Proceedings IJCAI95, pp.12921298.Subba, R., & Di Eugenio, B. (2009). effective discourse parser uses rich linguistic information.Proceedings Human Language Technologies: 2009 Annual Conference NorthAmerican Chapter Association Computational Linguistics, pp. 566574, Boulder,Colorado. Association Computational Linguistics.Tannier, X., & Muller, P. (2008). Evaluation Metrics Automatic Temporal Annotation Texts.ELRA (Ed.), Proceedings Sixth International Language Resources Evaluation(LREC08).Tatu, M., & Srikanth, M. (2008). Experiments Reasoning Temporal RelationsEvents. Proceedings og 22nd International Conference Computational Linguistics(Coling 2008), pp. 857864, Manchester, UK.van Beek, P. (1992). Reasoning qualitative temporal information. Artificial Intelligence, 58(13), 297326.Verhagen, M., Gaizauskas, R., Schilder, F., Hepple, M., Katz, G., & Pustejovsky, J. (2007). SemEval2007 - 15: TempEval Temporal Relation Identification. Proceedings SemEval workshopACL 2007, Prague, Czech Republic. Association Computational Linguistics, Morristown,NJ, USA.Vilain, M., Burger, J., Aberdeen, J., Connolly, D., & Hirschman, L. (1995). model-theoretic coreference scoring scheme. MUC6 95: Proceedings 6th conference Message understanding, pp. 4552, Columbia, Maryland, USA. Association Computational Linguistics,Morristown, NJ, USA.Vilain, M., Kautz, H., & van Beek, P. (1990). Constraint propagation algorithms temporal reasoning: revised report. Readings qualitative reasoning physical systems, pp. 373381.Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.Webber, B. L. (1988). Tense discourse anaphor. Computational Linguistics, 14(2), 6173.Wellner, B., Pustejovsky, J., Havasi, C., Rumshisky, A., & Saur, R. (2006). Classification discoursecoherence relations: exploratory study using multiple knowledge sources. Proceedings7th SIGdial Workshop Discourse Dialogue, pp. 117125, Sydney, Australia. Association Computational Linguistics.412fiE VALUATING EMPORAL G RAPHS VIA RANSITIVE R EDUCTIONZwaan, R. A., & Razdvansky, G. A. (2001). Time narrative comprehension. Schram, D., &Steen, G. (Eds.), Psychology Sociology Literature. John Benjamins, Amsterdam.Zwaan, R. (2008). Time language, situation models, mental simulations. Language Learning,58(s1), 1326.413fiJournal Articial Intelligence Research 40 (2011) 571-598Submitted 11/10; published 03/11Multiagent Learning Large Anonymous GamesIan A. Kashkash@seas.harvard.eduCenter Research Computation SocietyHarvard UniversityEric J. Friedmanejf27@cornell.eduDepartment Operations ResearchInformation EngineeringCornell UniversityJoseph Y. Halpernhalpern@cs.cornell.eduDepartment Computer ScienceCornell UniversityAbstractlarge systems, important agents learn act eectively, sophisticatedmulti-agent learning algorithms generally scale. alternative approach ndrestricted classes games simple, ecient algorithms converge. shownstage learning eciently converges Nash equilibria large anonymous games bestreply dynamics converge. Two features identied improve convergence. First,rather making learning dicult, agents actually benecial manysettings. Second, providing agents statistical information behavior otherssignicantly reduce number observations needed.1. IntroductionDesigners distributed systems frequently unable determine agentsystem behave, optimal behavior depends users preferencesactions others. natural approach agents use learning algorithm.Many multiagent learning algorithms proposed including simple strategy updateprocedures ctitious play (Fudenberg & Levine, 1998), multiagent versions Qlearning (Watkins & Dayan, 1992), no-regret algorithms (Cesa-Bianchi & Lugosi, 2006).goal work help designers distributed systems understandlearning practical. discuss Section 2, existing algorithms generally unsuitablelarge distributed systems. distributed system, agent limited viewactions agents. Algorithms require knowing, example, strategy chosenevery agent cannot implemented. Furthermore, size distributed systems requiresfast convergence. Users may use system short periods time conditionssystem change time, practical algorithm system thousands millionsusers needs convergence rate sublinear number agents. Existingalgorithms tend provide performance guarantees polynomial even exponential.Finally, large number agents system guarantees noise. Agentsmake mistakes behave unexpectedly. Even agent changes strategy,still noise agent payos. example, gossip protocol match dierentc2011AI Access Foundation. rights reserved.fiKash, Friedman, & Halpernagents round round; congestion underlying network may eect message delaysagents. learning algorithm needs robust noise.nding algorithm satises requirements arbitrary games maydicult, distributed systems characteristics make problem easier. First,involve large number agents. agents may seem make learningharderafter all, possible interactions. However, advantageoutcome action typically depends weakly agents do.makes outcomes robust noise. large number agents also make less usefulagent try inuence others; becomes better policy try learn optimalresponse. contrast, small number agents, agent attempt guide learningagents outcome benecial him.Second, distributed systems often anonymous; matter something, rather many agents it. example, congestion link,experience single agent depend sending packets,many sent. Anonymous games long history economics literature(e.g., Blonski, 2001) subject recent interest computer scienceliterature (Daskalakis & Papadimitriou, 2007; Gradwohl & Reingold, 2008).Finally, perhaps importantly, distributed system system designercontrols game agents playing. gives us somewhat dierent perspectivework, takes game given. need solve hard problemnding ecient algorithm games. Instead, nd algorithms workeciently interesting classes games, us interesting means typegames system designer might wish agents play. games well behaved,since would strange design system agents decisions inuenceagents pathological ways.Section 3, show stage learning (Friedman & Shenker, 1998) robust, implementable minimal information, converges eciently interesting classgames. algorithm, agents divide rounds game series stages.stage, agent uses xed strategy except occasionally explores. endstage, agent chooses strategy next stage whatever strategyhighest average reward current stage. prove that, appropriate conditions,large system stage learners follow (approximate) best-reply dynamics1 despite errorsexploration.games best-reply dynamics converge, theorem guarantees learnersplay approximate Nash equilibrium. contrast previous results, convergence guarantee scales poorly number agents, theorem guarantees convergence nite amount time innite number agents. assumptionbest-reply dynamics converge strong one, many interesting games converge best-reply dynamics, including dominance-solvable games, games monotone bestreplies, max-solvable games (Nisan, Schapira, & Zohar, 2008). class max-solvablegames particular includes many important games Transmission Control Protocol(TCP) congestion control, interdomain routing Border Gateway Protocol (BGP),cost-sharing games, stable-roommates games (Nisan, Schapira, Valiant, & Zohar, 2011).1. paper, consider best-reply dynamics agents update strategy time.results best-reply dynamics assume agents update strategy one time.572fiMultiagent Learning Large Anonymous GamesMarden, Arslan, Shamma (2007a) observed convergence best-reply dynamics often property games humans design (although observationslightly dierent notion best-reply dynamics). Moreover, convergence best-reply dynamics weaker assumption common assumption made mechanism designliterature, games interest dominant strategies (each agent strategyoptimal matter agents do).Simulation results, presented Section 4, show convergence fast practice:system thousands agents converge thousand rounds. Furthermore,identify two factors determine rate quality convergence. One numberagents: agents makes noise system consistent agentslearn using fewer observations. giving agents statistical informationbehavior agents; speed convergence order magnitude. Indeed,even noisy statistical information agent behavior, relatively easyobtain disseminate, signicantly improve performance.theoretical results limited stage learning, provide intuitionwell behaved learning algorithms also converge. simulations,include two learning algorithms, bear out. Furthermore, demonstrateapplicability stage learning realistic settings, simulate results learningscrip system (Kash, Friedman, & Halpern, 2007). results demonstrate stagelearning robust factors churn (agents joining leaving system)asynchrony (agents using stages dierent lengths). However, stage learning robustchanges. include simulations games small number agents, gamesanonymous, games continuous. games violateassumptions theoretical results; simulations show that, games, stagelearning converges slowly all.Finally, participants system necessarily behave expected. learninguseful real system, needs robust behavior. Section 5, showcontinuity utility functions key property makes stage learning robustByzantine behavior small fraction agents.2. Related WorkOne approach learning play games generalize reinforcement learning algorithmsQ-learning (Watkins & Dayan, 1992). One nice feature approachhandle games state, important distributed systems. Q-learning,agent associates value state-action pair. chooses action state ,updates value (, ) based reward received best valueachieve resulting state (max ( , )). generalizing multiple agents,become vectors state action every agent max replacedprediction behavior agents. Dierent algorithms use dierent predictions;example, Nash-Q uses Nash equilibrium calculation (Hu & Wellman, 2003). Seework Shoham, Powers, Grenager (2003) survey.Unfortunately, algorithms converge slowly large distributed system.algorithm needs experience possible action prole many times guarantee convergence. So, agents strategies, naive convergence time ( ). Even573fiKash, Friedman, & Halpernbetter representation anonymous games, convergence time still ( ) (typically). also fundamental problem approach: assumes information agent unlikely have. order know value update,agent must learn action chosen every agent. practice, agent learnsomething actions agents directly interacts, unlikelygain much information actions agents.Another approach no-regret learning, agents choose strategy roundguarantees regret choices low. Hart Mas-Colell (2000)present learning procedure converges correlated equilibrium 2 given knowledge payos every action would round. also provide variant algorithm requires information agents actualpayos (Hart & Mas-Colell, 2001). However, guarantee convergence withincorrelated equilibrium requires (/2 log ), still slow large systems. Furthermore, convergence guarantee distribution play converges equilibrium;strategies individual learners converge. Many no-regret algorithmsexist (Blum & Mansour, 2007). Section 4, use Exp3 algorithm (Auer, CesaBianchi, Freund, & Schapire, 2002). achieve even better convergence restrictedsettings. example, Blum, Even-Dar, Ligett (2006) showed routing gamescontinuum no-regret learners approximate Nash equilibrium nite amounttime. Jafari, Greenwald, Gondek, Ercal (2001) showed no-regret learners convergeNash equilibrium dominance solvable, constant sum, general sum 2 2 games.Foster Young (2006) use stage-learning procedure converges Nash equilibrium two-player games. Germano Lugosi (2007) showed converges generic-player games (games best replies unique). Young (2009) uses similar algorithm without explicit stages also converges generic -player games. Ratherselecting best replies, algorithms agents choose new actions randomlyequilibrium. Unfortunately, algorithms involve searching whole strategy space,convergence time exponential. Another algorithm uses stages providestable learning environment ESRL algorithm coordinated exploration (Verbeeck,Nowe, Parent, & Tuyls, 2007).Marden, Arslan, Shamma (2007b) Marden, Young, Arslan, Shamma (2009)use algorithm experimentation best replies without explicit stagesconverges weakly acyclic games, best-reply dynamics converge agents moveone time, rather moving once, assume here. Convergence basedexistence sequence exploration moves lead equilibrium.agents explore probability , analysis gives convergence time (1/ ).Furthermore, guarantee requires suciently small agents essentially exploreone time, needs (1/).Adlakha, Johari, Weintraub, Goldsmith (2010) independently given conditionsexistence oblivious equilibrium, mean eld equilibrium, stochasticgames. model require game large, anonymous, continuous. oblivious equilibrium, player reacts average states2. Correlated equilibrium general solution concept Nash equilibrium (see Osborne & Rubenstein, 1994); every Nash equilibrium correlated equilibrium, may correlated equilibriaNash equilibria.574fiMultiagent Learning Large Anonymous Gamesstrategies players rather exact values. However, model assumesplayers payo depends state players actions. AdlakhaJohari (2010) consider stochastic games strategic complementarities showmean eld equilibria exist, best-reply dynamics converge, myopic learning dynamics(which require knowledge aggregate states players) nd them.long history work examining simple learning procedures ctitiousplay (Fudenberg & Levine, 1998), agent makes best response assumingplayers strategy characterized empirical frequency observedmoves. contrast algorithms convergence guarantees general games, algorithms fail converge many games. classes games converge,tend rapidly. However, work area assumes actionsagents observed agents, agents know payo matrix, payos deterministic. recent approach tradition based Win Learn Fast principle,limited convergence guarantees often performs well practice (Bowling &Veloso, 2001). Hopkins (1999) showed many procedures converge symmetricgames innite number learners, although results provide guaranteesrate convergence.also body empirical work convergence learning algorithmsmultiagent settings. Q-learning empirical success pricing games (Tesauro &Kephart, 2002), -player cooperative games (Claus & Boutilier, 1998), grid worldgames (Bowling, 2000). Greenwald al. (2001) showed number algorithms,including stage learning, converge variety simple games. Marden et al. (2009) foundalgorithm converged must faster congestion game theoretical analysiswould suggest. theorem suggests explanation empirical observations: bestreply dynamics converge games. theorem applies directlystage learning, provides intuition algorithms learn quickly enoughchange behavior slowly enough rapidly converge Nash equilibrium practice.3. Theoretical Resultssection present theoretical analysis model. provide supportsimulations following section.3.1 Large Anonymous Gamesinterested anonymous games countably many agents. Assumingcountably many agents simplies proofs; straightforward extend resultsgames large nite number agents. model adapted Blonski (2001). Formally, large anonymous game characterized tuple = (, , , Pr).countably innite set agents.nite set actions agent choose (for simplicity, assumeagent choose set actions).(), set probability distributions , two useful interpretations.rst set mixed actions. abuse notation denote575fiKash, Friedman, & Halpernmixed action probability 1 . round agent chooses onemixed actions. second interpretation () fractionagents choosing action . important notion anonymity,says agents utility depend many agents chooseaction rather chooses it.= { : ()} set (mixed) action proles (i.e. actionagent chooses). Given mixed action every agent, want know fractionagents end choosing action . , let ()() denote probabilityagent plays according () ().We express fractionagents choose action lim (1/) =0 ()(), limit exists.limit exists actions , let () give value limit. proles use determined simple random process.proles , strong law large numbers (SLLN) guarantees probability1 well dened. Thus typically well dened (using similar limits) ustalk fraction agents something.nite set payos agents receive.Pr : () ( ) denotes distribution payos resultsagent performs action agents follow action prole . use probabilitydistribution payos rather payo model fact agent payos maychange even agent changes strategy. expected utility agentperformsmixed action agents follow action distribution (, ) =() Pr, (). denition Pr terms () ratherensures game anonymous. require Pr (and thus ) Lipschitzcontinuous.3 deniteness, use L1 norm notion distancespecifying continuity (the L1 distance two vectors sum absolutevalues dierences component). Note formulation assumesagents share common utility function. assumption relaxed allowagents nite number types, show Appendix A.example large anonymous game one where, round, agent playstwo-player game opponent chosen random. random matching gamescommon literature (e.g., Hopkins, 1999), meaning opponent chosenrandom made formal (Boylan, 1992). game, set actionstwo-player game set payos game. every agent choosesaction, distribution opponent actions characterized (). Let ,denote payo agent plays agent plays . utilitymixed action given distribution(, ) =()( ), ., 23. Lipschitz continuity imposes additional constraint constant Pr(, )Pr(, )/ 1 . Intuitively, ensures distribution outcomeschange fast. standard assumption easily seen hold gamestypically considered literature.576fiMultiagent Learning Large Anonymous Games3.2 Best-Reply DynamicsGiven game action distribution , natural goal agent playaction maximizes expected utility respect : argmax (, ). callaction best reply . practical amount time, agent may dicultydetermining two actions close expected utilities better, allowagents choose actions close best replies. best reply ,-best reply ( , ) + (, ). may one -best reply;denote set -best replies ABR ().single agent looking best reply; every agent trying nd onetime. agents start action distribution 0 , ndbest reply new action distribution 1 . assume 0 () = 1/ (agentschoose initial strategy uniformly random), results apply distributionused determine initial strategy. say sequence (0 , 1 , . . .) -bestreply sequence support +1 subset ABR ( ); +1 gives positiveprobability approximate best replies . best-reply sequence convergesexists > , = . Note particularlystrong notion convergence require converge nite timemerely limit. game may innitely many best-reply sequences, sayapproximate best-reply dynamics converge exists > 0 every -bestreply sequence converges. limit distribution determines mixed strategy-Nash equilibrium (i.e. support subset ( )).main result shows learners successfully learn large anonymous gamesapproximate best-reply dynamics converge. number stages needed convergedetermined number best replies needed sequence converges. possible design games long best-reply sequences, practice gamesshort sequences. One condition guarantees 0 degenerate actiondistributions (i.e., distributions assign probability 1 ) uniquebest replies. case, best replies equilibrium reached,assumed agents utility function. Furthermore,games distinction -best replies best replies irrelevant; suciently small , -best reply best reply. hard show propertydegenerate strategies unique best replies generic; holds almost every game.3.3 Stage Learnersagent wants nd best reply may know set payos , mappingactions distributions payos Pr, action distribution (and, indeed,may changing time), use type learning algorithm learnit. approach divide play game sequence stages. stage,agent almost always plays xed action , also explores actions.end stage, chooses new next stage based learned.important feature approach agents maintain actions entire stage,stage provides stable environment agents learn. simplifyresults, specify way exploring learning within stage (originally describedFriedman & Shenker, 1998), results generalize reasonable learning577fiKash, Friedman, & Halpernalgorithm used learn within stage. (We discuss reasonable Section 6.)section, show that, given suitable parameter, stage agentslearned best reply environment stage.Given game , round agent needs select mixed action , .agents use strategies denote , , () = 1 ( = ) =/( 1). Thus, , agent almost always plays , probability exploresstrategies uniformly random. Thus far specied informationagent use choose ,. Dierent games may provide dierent information.require agent know previous actions previous payos.precisely, < , knows action () (which determined , )payos () (which determined Pr(, , ), action distributionround ; note assume agent knows .) Using information,express average value action previous = 1/2 rounds (the lengthstage).4 Let (, , ) = { < () = }set recent roundsplayed . average value (, , ) = (,,) ()/(, , )(, , ) > 0 0 otherwise. need value timesmultiples , convenience dene arbitrary times .say agent -stage learner chooses actions follows. = 0,chosen random { }. nonzero multiple , , = (, )(, ) = argmax (, , ). Otherwise, , = ,1 . Thus, within stage, mixedaction xed; end stage updates use action highest averagevalue previous stage.evolution game played stage learners deterministic; agent choosesrandom ,0 sequence () () observes also random. However,countably innite set agents, use SLLN make statements overallbehavior game. Let () = ,. run game consists sequence triples( , , ). SLLN guarantees probability 1 fraction agents choosestrategy (). Similarly, fraction agents chose receivepayo Pr(, )() probability 1.make notion stage precise, refer sequence tuples( , , ) . . . ((+1) 1 , (+1) 1 , (+1) 1 ) stage run. stagestationary action distribution denote . ,(+1) = ABR ( ),say agent learned -best reply stage run. following lemma shows, suciently small , agents learn -best reply.Lemma 3.1. large anonymous games , action proles, approximations > 0,probabilities error > 0, exists > 0 < ,agents -stage learners, least 1 fraction agents learn -best replystage .Proof. (Sketch) average, agent using strategy plays action (1 ) timesstage plays actions /( 1) times each. large, realized numbertimes played close expectation value high probability. Thus,suciently large, average payo action exponentially close4. use exponent 2 arbitrary. require expected number times strategyexplored increases decreases.578fiMultiagent Learning Large Anonymous Gamestrue expected value (via standard Hoeding bound sums i.i.d. random variables),thus learner correctly identify action approximately highest expectedpayo probability least 1 . SLLN, least 1 fraction agentslearn -best reply. detailed version proof general setting foundwork Friedman Shenker (1998).3.4 Convergence TheoremThus far dened large anonymous games approximate best-reply dynamicsconverge. agents game -stage learners, sequence 0 , 1 , . . .action distributions run game best-reply sequence, close.action used agents time action usedapproximate best reply sequence.order prove this, need dene close. denition based error rateexploration rate introduces noise . Intuitively, distribution closeif, changing strategies fraction agents agents explorefraction time, go action prole corresponding action distributionone corresponding distribution . Note denition symmetric.denition, identies (pure) action agent using leads ,allows fraction agents use action, incorporates factagent exploring, strategy (the agent usually plays exploresprobability ).Denition 3.2. Action distribution (, )-close exist , ,that:= = ;() ;1 2 (this allows fraction agents play dierent strategy);, () = () = .use nal requirement ensures two distributions (, )-closealso ( , )-close . example asymmetrydenition, (0, ) close , reverse true. (, )-closenessuseful distance measure analysis, unnatural notion distance specifyingcontinuity , used L1 norm. following simple lemma showsdistinction unimportant; suciently (, )-close close accordingL1 measure well.Lemma 3.3. (, )-close ,1 2( + ).Proof. Since (, )-close , exist , , Denition 3.2. Considerdistributions = , , = . view three distributions vectors,calculate L1 distances. Denition 3.2, 1 2. 1 2fraction agents explore. Thus triangle inequality, L1 distance2( + ).579fiKash, Friedman, & Halpernassumed approximate best reply sequences converge,run game agents actually learning approximate best replies .following lemma shows distinction matter suciently close.Lemma 3.4. exists (, )-close , > 0, > 0,+ < ABR (/2) () ABR ().Proof. Let maximum Lipschitz constants (, ) (one constant) = /(8). (, )-close , (, ) (, )1 2/(8) = /4 Lemma 3.3.Let/ ABR () argmax ( , ). (, ) + < ( , ). Combininggives (, ) + /2 < ( , ). Thus/ ABR/2 ().Lemmas 3.1 3.4 give requirements (, ). statement theorem, call(, ) -acceptable satisfy requirements lemmas /2 -best-replysequences converge .Theorem 3.5. Let large anonymous game approximate best-reply dynamicsconverge let (, ) -acceptable . agents -stage learners then,runs, exists -best-reply sequence 0 , 1 , . . . stage least 1fraction learn best reply probability 1.Proof. 0 = 0 (both uniform distribution), 0 (, )-close . Assume(, )-close . Lemma 3.1 least 1 fraction learn /2-best reply .Lemma 3.4, -best reply . Thus +1 (, )-close +1 .Theorem 3.5 guarantees nite number stages, agents closeapproximate Nash equilibrium prole. Specically, (, )-close -Nashequilibrium prole . Note means actually -Nash equilibriumlarger depends ,,, Lipschitz constant .three requirements practical learning algorithm require minimalinformation, converge quickly large system, robust noise. Stage learningrequires agent know payos, rst condition satised. Theorem 3.5 shows satises two requirements. Convergence guaranteednite number stages. number stages depends game, Section 3.2argued many cases quite small. Finally, robustness comes toleratingfraction errors. proofs assumed errors due learning,analysis noise sources churn agentsmaking errors. discuss issue Section 6.4. Simulation Resultssection, discuss experimental results demonstrate practicality learninglarge anonymous games. Theorem 3.5 guarantees convergence suciently smallexploration probability , decreasing also increases , length stage.rst set experiments shows necessary values quite reasonablepractice. theorem applies stage learning, analysis provides intuition580fiMultiagent Learning Large Anonymous Gamesreasonable algorithm changes slowly enough learners chancelearn best replies converge well. demonstrate this, also implemented twolearning algorithms, also quickly converged.theoretical results make two signicant predictions factors inuencerate convergence. Lemma 3.1 tells us length stage determinednumber times strategy needs explored get accurate estimatevalue. Thus, amount information provided observation large eectrate convergence. example, random matching game, agents payoprovides information strategy one agent. hand,receives expected payo matched, single observation provides informationentire distribution strategies. latter case agent learn manyfewer observations. related prediction agents lead fasterconvergence, particularly games payos determined average behavioragents, variance payos due exploration mistakes decreasesnumber agents increases. experimental results illustrate phenomena.game used rst set experiments, like many simple games used testlearning algorithms, symmetric. Hopkins (1999) showed many learning algorithmswell behaved symmetric games large populations. demonstratemain results due something symmetry, also tested stage learningasymmetric game, observed convergence even small population.explore applicability stage learning practical setting violatesnumber assumptions theorem, implemented variant stage learninggame based scrip system (Kash et al., 2007). demonstrate applicabilityapproach real systems, included experiments churn (agents leavingreplaced new agents) agents learning dierent rates.Finally, give examples games large, anonymous, continuous, provide simulations showing stage learners learn far slowlygames satisfy hypotheses Theorem 3.5, learn playequilibrium all. examples demonstrate assumptions essentialresults.4.1 Contribution Gamerst set experiments, agents play contribution game (also called Diamondtype search model work Milgrom & Roberts, 1990). contribution game,two agents choose strategies 0 19, indicating much eort contributecollective enterprise. value agent depends much contributes, wellmuch agent contributes. contributes contributionagent , utility 4 ( 5)3 . round game, agentpaired random agent play contribution game. game, best-replydynamics converge within 4 stages starting distribution.implemented three learning algorithms run game. implementationstage learners described Section 3.3, = 0.05. Rather taking lengthstage 1/2 , set = 2500 suciently long stages value , ratherdecreasing stages long enough. second algorithm based581fiKash, Friedman, & Halpern62 Agents10 Agents100 AgentsDistance Equilibrium54321001234Time54x 10Figure 1: Stage learners random matching.3.52 Agents10 Agents100 AgentsDistance Equilibrium32.521.510.50123Time454x 10Figure 2: Hart Mas-Colell random matching.Hart Mas-Colell (2001), improvements suggested Greenwald, Friedman,Shenker (2001). algorithm takes parameters (the exploration probability).used = 16 = 0.05. nal learning algorithm Exp3 (Auer et al., 2002).set , exploration probability, 0.05. algorithm requires payosnormalized lie [0, 1]. Since choices strategies lead large negativepayos, naive normalization leads almost every payo close 1. betterperformance, normalized payos payos fell range [0, 1]outside set 0 1 appropriate.results three algorithms shown Figures 1, 2, 3. curveshows distance equilibrium function number rounds populationagents given size using given learning algorithm. results averagedten runs. Since payos nearby strategies close, want notion distancetake account agents playing 7 closer equilibrium (8) thanthose playingzero. Therefore, consider expected distance equilibrium:() 8.determine , counted number times action taken length582fiMultiagent Learning Large Anonymous Games52 Agents10 Agents100 Agents4.5Distance Equilibrium43.532.521.510.501234Time54x 10Figure 3: Exp3 random matching.62 Agents10 Agents100 AgentsDistance Equilibrium5432100123Time454x 10Figure 4: Stage learning average-based payos.stage, practice distance never zero due mistakes exploration.ease presentation, graph shows populations size 100; similar resultsobtained populations 5000 agents.stage learning, increasing population size dramatic impact. twoagents, mistakes best replies results mistakes cause behavior quitechaotic. ten agents, agents successfully learn, although mistakes suboptimalstrategies quite frequent. one hundred agents, agents converge quicklynear equilibrium strategies signicant mistakes rare.Despite lack theoretical guarantees, two algorithms also converge, althoughsomewhat slowly. long-run performance Exp3 similar stage learning.Hart Mas-Colells algorithm asymptotic convergence guarantees, tendsconverge slowly practice tuned tight convergence. get convergereasonable amount time tuned parameters accept somewhat weaker convergence(although particular game shown dierence convergence dramatic).583fiKash, Friedman, & Halpern1.82 Agents10 Agents100 Agents1.6Distance Equilibrium1.41.210.80.60.40.2000.511.5Time22.54x 10Figure 5: Stage learners congestion game.Convergence stage learning random-matching game takes approximately 10,000rounds, slow many applications. system design requires typematching, makes learning problematic. However, results Figure 4 suggestlearning could done much faster system designer could supply agentsinformation. suggests collecting statistical information behavioragents may critical feature ensuring fast convergence. model scenario,consider related game where, rather matched random opponent,agents contribute project reward based average contributionagents. results stage learning game shown Figure 4.much information available agents observation, able cutlength stage factor 10. number stages needed reach equilibriumremained essentially same. Convergence tighter well; mistakes rarealmost distance equilibrium due exploration.4.2 Congestion Gamedierent game, tested performance stage learners congestion game.game models situation two agents share network link. gain utilityproportional transmission rate link, penalized based resultingcongestion experience. game asymmetric two dierent typesagents place dierent values transmission rate. game described detailGreenwald, Friedman, Shenker (2001), showed no-regret learners ablend equilibrium game. extension theoretical results gamesmultiple types presenting Appendix A.Figure 5 shows stage learners able learn quickly game, usingstages length 250 even though randomly matched playertype. dierent types agents dierent equilibrium strategies,distance measure use treat observed distribution strategiesequilibrium distribution vectors compute L1 distance.584fiMultiagent Learning Large Anonymous Games1Fraction Playing Equilibrium Strategy0.90.80.70.60.50.40.3Capacity 2Capacity 4Capacity 50.20.100510Number Stages1520Figure 6: Stage learners TCP-like game.4.3 TCP-like Gameprevious example, considered random-matching game two agentsdierent types share link. consider game large number agents shareseveral links (this game variant congestion control game studied Nisan et al.,2011).three types agents using network. agent chooses integer ratetransmit 0 10. Links network maximum average rateagents transmit; exceeded share capacity evenly among agents.agents utility overall transmission rate network minus penaltytrac dropped due congestion. agent attempts transmit rateactual rate penalty 0.5( ).5agents share link average capacity 5. One third agentsconstrained sharing link average capacity 2 another third share linkaverage capacity 4. game unique equilibrium agents rstthird choose rate 2, agents second third choose rate 4, agentsnal third choose rate 9 (so overall average rate 5). results gamebest-reply dynamics converge stages uniform starting distribution.Figure 6 shows results 90 learners (30 type) = 50000 = 0.01,averaged ten runs. Agents constrained average capacity two quickly learnequilibrium strategy, followed average capacity four. Agents constrainedaverage capacity learn equilibrium strategy, sawtooth patternsmall fraction alternately plays 10 rather 9. because, exploration,actually optimal small number agents play 10. noticeable fractionso, 9 uniquely optimal. demonstrates that, strictly speaking, gamesatisfy continuity requirement. equilibrium, demand bandwidth exactlyequal supply. Thus, small changes demand agents due explorationlarge eect amount actually demanded thus payos5. penalty used work Nisan et al. (2011); using avoids tie-breaking issuesconsider.585fiKash, Friedman, & Halpern1Fraction Playing Equilibrium Strategy0.90.80.70.60.50.40.3Type 1Type 2Type 30.20.100510Number Stages1520Figure 7: Stage learners random TCP-like games.various strategies. However, structure game play still tendsremain close equilibrium terms rates agents choose.addition specic parameters mentioned above, also ran 100 simulationsthree capacities randomly chosen integer 0 10. Figure 7shows that, average, results similar. three types agents share commonconstraint; type 1 type 2 additional constraint. Unsurprisingly, sincetwo types symmetric results almost identical. three types demonstratesawtooth behavior, type 3 runs due examples like Figure 6fewer constraints gives agents exibility. primarily comes runstype 1 type 2 constraints larger overall constraint (i.e.overall constraint matters). Thus three types ability benet resourcesdemanded agents explore.4.4 Scrip System Gamemotivation work help designers distributed systems understandlearning practical. order demonstrate stage learning could appliedsetting, tested variant stage learners model scrip system usedKash et al. (2007). model, agents pay agents provide serviceturn provide service earn money pay future service. Agents may placedierent values receiving service (), incur dierent costs provide service (), discountfuture utility dierent rates (), dierent availabilities provide service ().used single type agent parameters = 1.0, = 0.05, = 0.9, = 1, averageamount money per agent = 1, stages 200 rounds per agent (only one agentmakes request round).model large anonymous game whether agent provideservice depends much money currently has. Thus, stage learning speciedwork, take account current state (stochastic) game.Despite this, still implement variant stage learning: x strategystage end stage use algorithm designed game determine586fiMultiagent Learning Large Anonymous Games1.610 Agents100 Agents1.4Distance Equilibrium1.210.80.60.40.200.20.40.60.811.21.41.61.8Time24x 10Figure 8: Stage learners scrip system.1.610 Agents100 Agents1.4Distance Equilibrium1.210.80.60.40.200.20.40.60.811.2Time1.41.61.824x 10Figure 9: scrip system churn.new strategy best reply agent observed. algorithm worksestimating agents probabilities making request chosen volunteerround, uses probabilities compute optimal policy. Figure 8shows quite eective. distance measure used based directly measuringdistance agents chosen (threshold) strategy equilibrium strategy, sinceunlike previous games impossible directly infer agents strategy roundsolely decision whether volunteer. Note number roundsnormalized based number agents Figure 8 later gures; stages actuallylasted ten times long 100 agents.Real systems static population learning agents. demonstraterobustness stage learning churn, replaced ten percent agents new agentsrandomly chosen initial strategies end period. Figure 9 shows,essentially eect convergence.587fiKash, Friedman, & Halpern1.610 Agents100 Agents1.4Distance Equilibrium1.210.80.60.40.200.20.40.60.811.2Time1.41.61.824x 10Figure 10: scrip system dierent stage lengths.Finally, real system often unreasonable expect agents able updatestrategies time. Figure 10 shows half agents use stages222 rounds per agent rather 200 signicant eect convergence.64.5 Learning Counterexamplesrst glance, Theorem 3.5 may seem trivial. game best-reply dynamicsguaranteed converge, seems obvious agents attempt nd best repliessuccessfully nd reach equilibrium. However, show section,fact alone sucient. particular, three key features gamesstudythat large, anonymous, continuousare required theoremhold.First, game small number agents, mistake made singleagent could quite important, point learning essentially start over.So, results converted results probability nonenite number agents make mistake given stage, expected time reachequilibrium following algorithm signicantly longer best-reply dynamicswould suggest. following example game number best repliesneeded reach equilibrium approximately number strategies, experimentalresults show number stages needed stage learners nd equilibriumsignicantly longer. (We conjecture fact learning time exponentially longer.)contrast, Theorem 3.5 guarantees that, games satisfying requirements, numberstages needed equal number best replies.Consider game three agents, , set actions, {0, 1, . . . , }.utility functions agents symmetric; rst agents utility function givenfollowing table:6. general expect small variations stage lengths aect convergence; however largeenough dierences result non-Nash convergence. See work Greenwald et al. (2001)simulations analysis.588fiMultiagent Learning Large Anonymous Gamesactions(0, , )(, , )(0, 1, 0)(0, 0, 1)(1, 1, 0)(1, 0, 1)(, , )(, , )(, , )(, , )payo1000111010conditions= either > 1 > 1= > 0 either > 1 > 1= + 1= + 1 <=Agents learning best replies viewed climbing ladder. best reply(, , ) ( + 1, + 1, + 1) agents reach (, , ), Nash equilibrium.However, mistake made, agents essentially start over. see works,suppose agents (3, 3, 3) next stage one makes mistakeselect (5, 4, 4). leads best reply sequence (5, 0, 0), (1, 0, 0), (1, 1, 1),point agents begin climbing again. somewhat complicated structure payosnear 0 ensures agents begin climbing arbitrary patterns mistakes.typical run, + 2 stages best replies needed reach equilibrium: one stageinitial randomly-chosen strategies, one stage three agents switch strategy 0,stages climbing. exact number stages vary two agents chooseinitial strategy, never greater + 3.following table gives number rounds (averaged ten runs) stage learnersgame rst reach equilibrium. number strategies varies, lengthstage = 100( + 1), exploration probability = 0.05.rounds reach47.0919.31425.81939.52437.329102.734169.439246.6= 4, stage learners typically require + 2 stages, occasional error raisingaverage slightly. 9 24, majority runs feature least one agentmaking mistake, number stages required closer 2. = 29 up,many opportunities agents make mistake, number stages requiredaverage range 3 6. Thus learning slower best-reply dynamics,disparity grows number strategies increases.small modication example shows problems arise gamesanonymous. non-anonymous game large number agents, payosdepend entirely actions small number agents. example, splitset agents three disjoint sets, 0 , 1 , 2 , choose agents 0 0 , 1 1 ,589fiKash, Friedman, & Halpern10.90.8Fraction Playing 00.70.60.510 agents100 agents1000 agents0.40.30.20.100510Number Stages1520Figure 11: Stage learners discontinuous game.2 2 . Again, agent chooses action {0, . . . , }. payos agents 0, 1,2 determined above; everyone 0 gets payo 0, everyone 1gets payo 1, everyone 2 gets payo 2. Again, convergenceequilibrium signicantly slower best-reply dynamics.Finally, consider following game, large anonymous, satisfycontinuity requirement. set actions = {0, 1}, agent always receivespayo = {0, 1, 10}. agent chooses action 0, payo always 1 (Pr0, (1) = 1).chooses action 1, payo 10 every agent chooses action 1, 10 everyagent chooses action 0, 0 otherwise (Pr1,(1,0) (10) = 1, Pr1,(0,1) (10) = 1,Pr1, (0) = 1) {(1, 0), (0, 1)}).game, suppose approximate best-reply dynamics start (0.5, 0.5) (each actionchosen half agents). coordinated, unique approximate bestreply agents action 0, one best reply, action distribution (1, 0).Since agents coordinated, another round approximate best replies leadsequilibrium (0, 1). agents stage learners, rst stage learnapproximate best reply (0.5, 0.5) (exploration change action prolecase), adopt mixed action 0 : playing 0 probability 1 1probability . Thus, even agents make mistake, action distribution nextstage least fraction playing action 1. Thus unique approximate bestreply action 0; stage learners stuck 0, never reach equilibrium1.Figure 11 shows fraction times strategy 0 played stage (averagedten runs) 10, 100, 1000 agents ( = 100 = 0.05). ten agents,initial mistakes made, stage 10 strategy 0 played 2.5%time runs, corresponds fraction time expect see simplyexploration. 100 agents see another sawtooth pattern agentsstuck playing 0, alternating rounds small fraction plays 1. happensbecause, rounds playing 0, small fraction lucky explore 1agents explore. result, adopt strategy 1 next stage. However,not, following stage agents return playing 0. oscillating590fiMultiagent Learning Large Anonymous Gamesbehavior observed learning contexts, example among competing myopicpricebots (Kephart, Hanson, & Greenwald, 2000). 1000 agents, lucky agentsquite rare, essentially agents constantly stuck playing 0.5. Learning Byzantine Agentspractice, learning algorithms need robust presence agentsfollowing algorithm. seen stage learning large anonymous gamesrobust agents learn instead follow xed strategy stage.analysis, agents simply treated agents made mistakeprevious stage. However, agent need follow xed strategy; agent attemptinginterfere learning malicious reasons personal gain likely adaptstrategy time. However, show section, stage learning also handlemanipulation large anonymous games.Gradwohl Reingold (2008) examined several classes games introducednotion stable equilibrium one change strategy small fractionagents small eect payo agents. denitiongames nite number agents, easily adapted notion largeanonymous game. take notion step characterize game, ratherequilibrium, stable every strategy stable.Denition 5.1. large anonymous game (, )-stable , ()1 , (, ) (, ) .One class games consider -continuous games. -continuity essentiallyversion Lipschitz continuity nite games, easy show large anonymousgames stable, amount manipulation tolerated dependsLipschitz constants agents utility functions.Lemma 5.2. large anonymous games , exists constant, (, / )-stableProof. , (, ) Lipschitz continuous constant (, )(, )/ 1 . Take = max . 1/ ,(, ) (, ) 11()( ).Gradwohl Reingold (2008) show stable equilibria several nice properties.small fraction agents deviate, payos agent decrease muchrelative equilibrium. Additionally, following strategies still approximate591fiKash, Friedman, & Halpernequilibrium despite deviation. Finally, means strategies still constituteapproximate equilibrium even asynchronous play causes strategies fractionagents revealed others.show that, game stable, learning also robust actions smallfraction Byzantine agents. following lemma adapts Lemma 3.1 show that,stage, agents learn approximate best replies despite actions Byzantine agents.Thus agents successfully reach equilibrium, shown Theorem 3.5.state lemma, need dene actions Byzantine agent.Byzantine agents, stage would stationary strategycorresponding fraction agents choosing action . fraction Byzantine agentschange actions arbitrarily round, eectactions agents. Thus, Byzantine agents cause observed fractionagents choosing strategy round 1 < 2. refersequence , . . . , ( +1)1 condition holds consistentsequence. say agents learn -best reply stage , mean, actions playersstrategy learn approximate best replywould used Byzantine players, actual action prole,includes strategies used Byzantine players.Lemma 5.3. large anonymous games , action distributions , approximations> 0, probabilities error > 0, fractions agents < /6 , exists > 0< , , consistent sequences , . . . , ( +1)1 , agents-stage learners, least 1 fraction agents learn -best replystage despite fraction Byzantine agents.Proof. Consider agent round stage . agents stage learnersaction distribution would = . However, Byzantine agents changed2. Fix action . Lemma 5.2,(, ) (, ) 2 <2=63means Byzantine agents adjust agents expected estimate valueaction /3. Let best reply (the action used stage learnersstage ). round stage ,( , ) ( , ) <.3action -best reply,( , ) (, ) = (( , ) (, ) + ((, ) (, )) >2=.33Thus, regardless actions fraction Byzantine agents, agent expectedestimate value exceeds expected estimate value least /3.Using Hoeding bounds before, suciently large , estimates exponentiallyclose expectations, probability least 1 , select bestaction -best reply. SLLN, means least 1 fractionagents learn -best reply.592fiMultiagent Learning Large Anonymous GamesThus, Lemma 5.3 shows, stage learners learn despite agents learning incorrect values, also tolerate suciently small number agents behavingarbitrarily.6. Discussionresults show natural learning algorithm learn eciently interesting class games, many issues merit exploration.6.1 Learning Algorithmstheorem assumes agents use simple rule learning within stage:average value payos received. However, certainly rules estimating value action; used long rule guaranteeserrors made arbitrarily rare given sucient time. also necessary restrictagents stage learning. Stage learning guarantees stationary environment periodtime, strict behavior may needed practical. approaches,exponentially discounting weight observations (Greenwald et al., 2001; Mardenet al., 2009) Win Learn Fast (Bowling & Veloso, 2001) allow algorithm focuslearning recent observations provide stable environment agentslearn.6.2 Update Rulesaddition using dierent algorithms estimate values actions, learner couldalso change way uses values update behavior. example, ratherbasing new strategy last stage, could base entire historystages use rule spirit ctitious play. Since games ctitiousplay converges best-reply dynamics not, could extend results anotherinteresting class games, long errors period accumulate time.Another possibility update probabilistically use tolerance determine whetherupdate (see, e.g., Foster & Young, 2006; Hart & Mas-Colell, 2001). could allowconvergence games best-reply dynamics oscillate decrease fraction agentsmake mistakes system reaches equilibrium.6.3 Model Assumptionsmodel makes several unrealistic assumptions, notably countablymany agents share utility function. Essentially results holdslarge, nite number agents, adding error terms. particular, sincealways small probability every agent makes mistake time,prove 1 fraction agents make errors rounds,agents spend time playing equilibrium strategies.also implicitly assumed set agents xed. Figure 9 shows,could easily allow churn. natural strategy newly arriving agents pickrandom use next stage. agents this, follows convergenceunaected: treat new agents part fraction made mistake593fiKash, Friedman, & Halpernlast stage. Furthermore, tells us newly arriving agents catch quickly.single stage, new agents guaranteed learned best reply probabilityleast 1 .Finally, assumed agents utility function. resultseasily extended include nite number dierent types agents,utility function, since SLLN applied type agent. extensiondiscussed Appendix A. believe results hold even set possibletypes innite. happen, example, agents utility depends valuationdrawn interval. However, care needed dene best-reply sequencescase.6.4 StateOne common feature distributed systems addressed theoretical portionwork state. saw scrip system Section 4.4, agents current stateoften important factor choosing optimal action.principle, could extend framework games state: stageagent chooses policy usually follow explores actions probability .agent could use o-policy algorithm (one agent learn withoutcontrolling sequence observations; see Kaelbling, Littman, & Moore, 1996 examples) learn optimal policy use next stage. One major problemapproach standard algorithms learn slowly purposes. example, Q-learning (Watkins & Dayan, 1992) typically needs observe state-action pairhundreds times practice. low exploration probability means expected/ rounds needed explore pair even large. Ecient learning requiresspecialized algorithms make better use structure problem. However, use specialized algorithms makes providing general guarantee convergencedicult. Another problem that, even agent explores actionpossible local states, payo receives depend states agents,thus actions chose. need property game guaranteedistribution states sense well behaved. Adlakha Joharis (2010) workmean eld equilibria gives one condition. setting, use publicly availablestatistics might provide solution problems.6.5 Mixed EquilibriaAnother restriction results agents learn pure strategies. One wayaddress discretize mixed strategy space (see, e.g., Foster & Young, 2006).one resulting strategies suciently close equilibrium strategy bestreply dynamics converge discretized strategies, expect agents convergenear-equilibrium distribution strategies. empirical success usingapproach learn play rock-paper-scissors.594fiMultiagent Learning Large Anonymous Games7. ConclusionLearning distributed systems requires algorithms scalable thousands agentsimplemented minimal information actions agents.general-purpose multiagent learning algorithms fail one requirements.shown stage learning ecient solution large anonymous gamesapproximate best-reply dynamics lead approximate pure strategy Nash equilibria.Many interesting classes games property, frequently found designedgames. contrast previous work, time convergence guaranteed theoremincrease number agents. system designers nd appropriategame satisfying properties base systems, condentnodes eciently learn appropriate behavior.results also highlight two factors aid convergence. First, learners often improves performance. learners, noise introduced payosexploration mistakes becomes consistent. Second, information typically improves performance. Publicly available statistics observed behavioragents allow agent learn eectively making fewer local observations.simulations demonstrate eects two factors, well results generalizesituations learning algorithms, churn, asynchrony, Byzantine behavior.7.1 Acknowledgmentswork done IK Cornell University. EF, IK, JH supportedpart NSF grant ITR-0325453. JH also supported part NSF grant IIS-0812045AFOSR grants FA9550-08-1-0438 FA9550-05-1-0055. EF also supportedpart NSF grant CDI-0835706.Appendix A. Multiple Typessection, extend denition large anonymous game settingsagents may dierent utility functions. so, introduce notion type.Agents utilities may depend type fraction type taking action.results rely strong law large numbers, restrict set typesnite. Formally, large anonymous game types characterized tuple =(, , , , , Pr). dene , , , before. remaining terms:nite set agent types.: function mapping agent type.before, () set probability distributions , viewedset mixed actions available agent. now, describe fractionagents type choosing action, must use element () .Pr : () ( ) determines distribution payos resultsagent type performs action agents follow action prole .expected utility agent type performs mixed action agents595fiKash, Friedman, & Halpernfollow action distribution (, , ) = () Pr,, (). before,require Pr (and thus ) Lipschitz continuous.revised denitions -best reply, -Nash equilibrium, -best-reply sequence, convergence approximate best-reply dynamics, (, )-close follow naturallyrevised denitions . Lemma 3.1 applies type agent separately, shows small fraction type learn approximate bestreply stage. Lemma 3.3 Lemma 3.4 hold given revised denitions. Thus Theorem 3.5, combines these, also still holds.ReferencesAdlakha, S., & Johari, R. (2010). Mean eld equilibrium dynamic games complementarities. IEEE Conference Decision Control (CDC).Adlakha, S., Johari, R., Weintraub, G. Y., & Goldsmith, A. (2010). Mean eld analysislarge population stochastic games. IEEE Conference Decision Control(CDC).Auer, P., Cesa-Bianchi, N., Freund, Y., & Schapire, R. E. (2002). nonstochastic multiarmed bandit problem. SIAM Journal Computing, 32 (1), 4877.Blonski, M. (2001). Equilibrium characterization large anonymous games. Tech. rep.,U. Mannheim.Blum, A., Even-Dar, E., & Ligett, K. (2006). Routing without regret: convergenceNash equilibria regret-minimizing algorithms routing games. 25th ACMSymp. Principles Distributed Computing (PODC), pp. 4552.Blum, A., & Mansour, Y. (2007). Learning, regret minimization, equilibria. Nisan,N., Roughgarden, T., Tardos, E., & Vazirani, V. (Eds.), Algorithmic Game Theory,pp. 79102. Cambridge University Press.Bowling, M. H. (2000). Convergence problems general-sum multiagent reinforcementlearning. 17th Int. Conf. Machine Learning (ICML 2000), pp. 8994.Bowling, M. H., & Veloso, M. M. (2001). Rational convergent learning stochasticgames. 17th Int. Joint Conference Articial Intelligence (IJCAI 2001), pp.10211026.Boylan, R. T. (1992). Laws large numbers dynamical systems randomly matchedindviduals. Journal Economic Theory, 57, 473504.Cesa-Bianchi, N., & Lugosi, G. (2006). Prediction, Learning Games. Cambridge University Press.Claus, C., & Boutilier, C. (1998). dynamics reinforcement learning cooperativemultiagent systems. AAAI-97 Workshop Multiagent Learning, pp. 746752.Daskalakis, C., & Papadimitriou, C. H. (2007). Computing equilibria anonymous games.48th Annual IEEE Symposium Foundations Computer Science (FOCS 2007),pp. 8393.596fiMultiagent Learning Large Anonymous GamesFoster, D. P., & Young, P. (2006). Regret testing: Learning play Nash equilibrium withoutknowing opponent. Theoretical Economics, 1, 341367.Friedman, E. J., & Shenker, S. (1998). Learning implementation internet. Tech.rep., Cornell University.Fudenberg, D., & Levine, D. (1998). Theory Learning Games. MIT Press.Germano, F., & Lugosi, G. (2007). Global Nash convergence Foster Youngs regrettesting. Games Economic Behavior, 60 (1), 135154.Gradwohl, R., & Reingold, O. (2008). Fault tolerance large games. Proc. 9th ACMConference Electronic Commerce (EC 2008), pp. 274283.Greenwald, A., Friedman, E. J., & Shenker, S. (2001). Learning networks contexts:Experimental results simulations. Games Economic Behavior, 35 (1-2), 80123.Hart, S., & Mas-Colell, A. (2000). simple adaptive procedure leading correlated equilibrium. Econometrica, 68 (5), 11271150.Hart, S., & Mas-Colell, A. (2001). reinforecement learning procedure leading correlatedequilibrium. Debreu, G., Neuefeind, W., & Trockel, W. (Eds.), Economic Essays,pp. 181200. Springer.Hopkins, E. (1999). Learning, matching, aggregation. Games Economic Behavior,26, 79110.Hu, J., & Wellman, M. P. (2003). Nash Q-learning general-sum stochastic games. JournalMachine Learning Research, 4, 10391069.Jafari, A., Greenwald, A. R., Gondek, D., & Ercal, G. (2001). no-regret learning,ctitious play, nash equilibrium. Proc. Eighteenth International ConferenceMachine Learning (ICML), pp. 226233.Kaelbling, L. P., Littman, M. L., & Moore, A. P. (1996). Reinforcement learning: survey.J. Artif. Intell. Res. (JAIR), 4, 237285.Kash, I. A., Friedman, E. J., & Halpern, J. Y. (2007). Optimizing scrip systems: Eciency,crashes, hoarders altruists. Eighth ACM Conference Electronic Commerce(EC 2007), pp. 305315.Kephart, J. O., Hanson, J. E., & Greenwald, A. R. (2000). Dynamic pricing softwareagents. Computer Networks, 32 (6), 731752.Marden, J. R., Arslan, G., & Shamma, J. S. (2007a). Connections cooperativecontrol potential games. Proc. 2007 European Control Conference (ECC).Marden, J. R., Arslan, G., & Shamma, J. S. (2007b). Regret based dynamics: convergenceweakly acyclic games. 6th Int. Joint Conf. Autonomous Agents MultiagentSystems (AAMAS), pp. 4249.Marden, J. R., Young, H. P., Arslan, G., & Shamma, J. S. (2009). Payo-based dynamicsmulti-player weakly acyclic games. SIAM Journal Control Optimization,48 (1), 373396.597fiKash, Friedman, & HalpernMilgrom, P., & Roberts, J. (1990). Rationalizability, learning, equilibrium gamesstrategic complement- arities. Econometrica, 58 (6), 12551277.Nisan, N., Schapira, M., Valiant, G., & Zohar, A. (2011). Best-response mechanisms.Proc. Second Syposium Innovations Computer Science (ICS). Appear.Nisan, N., Schapira, M., & Zohar, A. (2008). Asynchronous best-reply dynamics.Proc. 4th International Workshop Internet Netwrok Economics (WINE), pp.531538.Osborne, M., & Rubenstein, A. (1994). Course Game Theory. MIT Press.Shoham, Y., Powers, R., & Grenager, T. (2003). Multi-agent reinforcement learning:critical survey. Tech. rep., Stanford.Tesauro, G., & Kephart, J. O. (2002). Pricing agent economies using multi-agent Qlearning. Autonomous Agents Multi-Agent Systems, 5 (3), 289304.Verbeeck, K., Nowe, A., Parent, J., & Tuyls, K. (2007). Exploring selsh reinforcementlearning repeated games stochastic rewards. Journal Autonomous AgentsMulti-agent Systems, 14, 239269.Watkins, C. J., & Dayan, P. (1992). Technical note Q-learning. Machine Learning, 8,279292.Young, H. P. (2009). Learning trial error. Games Economic Behavior, 65 (2),626643.598fiJournal Artificial Intelligence Research 40 (2011) 353-373Submitted 07/10; published 01/11Clause-Learning Algorithms Many RestartsBounded-Width ResolutionAlbert Atseriasatserias@lsi.upc.eduUniversitat Politecnica de CatalunyaBarcelona, SpainJohannes Klaus Fichtefichte@kr.tuwien.ac.atVienna University TechnologyVienna, AustriaMarc Thurleymarc.thurley@googlemail.comUniversity California BerkeleyBerkeley, USAAbstractoffer new understanding aspects practical SAT-solvers basedDPLL unit-clause propagation, clause-learning, restarts. analyzingconcrete algorithm claim faithful practical solvers do. particular,making new decision restart, solver repeatedly applies unit-resolutionrule saturation, leaves component mercy non-determinism exceptinternal randomness. prove perhaps surprising fact that, althoughsolver explicitly designed it, high probability ends behaving width-kresolution O(n2k+2 ) conflicts restarts, n numbervariables. words, width-k resolution thought O(n2k+2 ) restartsunit-resolution rule learning.1. Introductiondiscovery method introduce practically feasible clause learning non-chronological backtracking DPLL-based solvers layed foundation sometimes calledmodern SAT-solving (Silva & Sakallah, 1996; Bayardo & Schrag, 1997). methodsset ground new effective implementations (Moskewicz, Madigan, Zhao, Zhang, &Malik, 2001) spawned tremendous gains efficiency SAT-solvers manypractical applications. great somewhat unexpected success seemed contradictwidely assumed intractability SAT, time uncovered needformal understanding capabilities limitations underlying methods.Several different approaches suggested literature developing rigorous understanding. Among find proof-complexity approach, capturespower SAT-solvers terms propositional proof systems (Beame, Kautz, & Sabharwal, 2003, 2004; Hertel, Bacchus, Pitassi, & Gelder, 2008; Pipatsrisawat & Darwiche,2009), rewriting approach, provides useful handle reasonproperties underlying algorithms correctness (Nieuwenhuis, Oliveras, &Tinelli, 2006). approaches, SAT-solvers viewed algorithms searchproofs underlying proof system propositional logic. view mind,illuminating understand proof system underlying modern solvers alwaysc2011AI Access Foundation. rights reserved.fiAtserias, Fichte, & Thurleysubsystem resolution (Beame et al., 2003). particular, means performance never beat resolution lower bounds, time provides manyexplicit examples SAT-solvers require exponential time. Complementingresult idealized SAT-solver relies non-determinism apply techniquesbest possible way able perform good general resolution (weak formsstatement first established Beame et al., 2003, 2004; Hertel et al., 2008,current form Pipatsrisawat & Darwiche, 2009). Beame et al. (2004) put it,negative proof complexity results uncover examples inherent intractability evenperfect choice strategies, positive proof complexity results give hope findinggood choice strategy.work add new perspective kind rigorous result. try avoidnon-deterministic choices components abstract solver still get positive proofcomplexity results. main finding concrete family SAT-solversrely non-determinism besides mild randomness least powerful bounded-widthresolution. precise proof-complexity result unit-propagation rulestandard learning scheme considered state-of-the-art solvers, totally random decision strategy needs O(k 2 ln(kn)n2k+1 ) conflicts deterministic restartsdetect unsatisfiability CNF formula n variables width-k resolutionrefutation, probability least 1/2. Remarkably, analysis provide exact expression upper bound holds values n k particular boundget asymptotic. Another remarkable feature analysis insensitivewhether algorithm implements non-chronological backtracking heuristic-based decisions provided restarts often enough, provided performs totally random decisionsoften enough. details given Section 2.result nice theoretical consequences, shall sketch briefly.First, although explicitly designed purpose, SAT-solvers able solve instances 2-SAT polynomial time since every unsatisfiable 2-CNF formula resolutionrefutation width two. strongly, result interpreted showing widthk resolution simulated O(k 2 ln(kn)n2k+1 ) rounds unit-clause propagation.knowledge, tight connection width-k resolution repeated applicationwidth-one methods unknown before. Another consequence SAT-solversable solve formulas bounded branch-width (and hence bounded treewidth) polynomial time. elaborate later paper. Finally, partial automatizabilityresults Ben-Sasson Wigderson (1999), follows SAT-solvers able solveformulas polynomial-size tree-like resolution proofs quasipolynomial time,formulas polynomial-size general resolution proofs subexponential time.Concerning techniques, perhaps surprising proof main resultproceed showing width-k refutation learned algorithm.know produced proof much larger width. thing showevery width-k clause refutation absorbed algorithm, meansbehaves learned, even though might not. particular, literalcomplement absorbed, algorithm correctly declares formulaunsatisfiable. sort analysis main technical contribution paper.354fiClause-Learning Algorithms1.1 Related Workfirst attempt compare power SAT-solvers power resolutionproof system made Beame et al. (2003, 2004). main positive resultwork clause learning specific learning scheme without restartsprovide exponentially shorter proofs proper refinements resolution tree,regular, positive resolution. Furthermore, show modification standardsolver allow multiple assignments variable would able simulate generalresolution efficiently, assuming ideal decision strategy. Following work showedrequirement multiple assignments variable technical issueavoided given CNF formula pre-processed appropriately (Hertel et al., 2008).work avoid two maneuvers introducing concept clause-absorptionhelp us analyze standard algorithms directly.Interestingly, clauses logical consequences input formulas, conceptclause-absorption turns dual concept 1-empowerment introducedindependently Pipatsrisawat Darwiche (2009)1 . used 1-empowerment showSAT-solvers without conceptual modification operation able simulategeneral resolution efficiently, assuming ideal decision strategy. comparison,goal settles weaker simulation result, bounded-width resolution instead generalresolution, rely non-determinism ideal decision. showtotally random decision strategy good enough purpose, provided restart oftenenough. complete point, worth noting non-automatizability resultsAlekhnovich Razborov (2008) indicate cannot expect efficient simulationgeneral resolution completely avoid non-determinism time.fact concepts discovered independently adds confidence beliefplay role subsequent studies power SAT-solvers. Indeed,techniques recently extended show SAT-solvers totally random decisionstrategy able efficiently simulate local consistency techniques general constraintsatisfaction problems (Jeavons & Petke, 2010).1.2 OrganizationSection 2 introduce basic notation define algorithm analyze. alsodiscuss dependence results choice learning scheme, restart policydecision strategy used algorithm. Section 3 starts elementaryfacts runs algorithm, continues key definitions absorptionbeneficial rounds, analysis running time algorithm. Section 4contains discussion consequences, including implications formulas boundedtreewidth.2. Clause Learning Algorithmssection define algorithm discuss choice components.start preliminary definitions.1. Note that, originally, weaker version 1-empowerment introduced Pipatsrisawat Darwiche(2008).355fiAtserias, Fichte, & Thurley2.1 PreliminariesLet V = {v1 , . . . , vn } fixed set propositional variables. literal propositionalvariable x negation x. use notation x0 x x1 x. Note xadefined way assignment x = satisfies it. {0, 1}, also use1 a, literal ` = xa use ` x1a . clause set literals,formula conjunctive normal form (CNF-formula) set clauses. widthclause number literals it. following, formulas setvariables V every clause contains literals variables V .two clauses = {x, `1 , . . . , `r } B = {x, `01 , . . . , `0s } define resolventB x Res(A, B, x) = {`1 , . . . , `r , `01 , . . . , `0s }. variable resolve on, x,implicit simply write Res(A, B). clause may contain literal negation. Noteresolvent Res(A, B, x) B x still well-defined case. resolutionrefutation CNF formula F sequence clauses C1 , . . . , Cm Cm =clause Ci sequence either belongs F resolvent previous clausessequence. length refutation number clauses sequence.clause C, variable x, truth value {0, 1}, restriction C x =constant 1 literal xa belongs C, C \ {x1a } otherwise. write C|x=arestriction C x = a.partial assignment sequence assignments (x1 = a1 , . . . , xr = ar )variables distinct. Let partial assignment. say satisfies literal xacontains x = a. say falsifies contains x = 1 a. C clause, letC| result applying restrictions x1 = a1 , . . . , xr = ar C. Clearly ordermatter. say satisfies C satisfies least one literals; i.e.,C| = 1. say falsifies C falsifies literals; i.e., C| = . setclauses, let D| denote result applying restriction clause D,removing resulting 1s. call D| residual set clauses.2.2 Definition Algorithmstate sequence assignments (x1 = a1 , . . . , xr = ar ) variablesdistinct assignments marked decisions. use notation xi = aidenote assignment xi = ai decision assignment. case xi calleddecision variable. rest assignments called implied assignments. usedenote states. empty state one without assignments. Define decision levelassignment xi = ai number decision assignments (x1 = a1 , . . . , xi = ai ).convenient, identify state underlying partial assignmentdecision marks ignored.2.2.1 Operationalgorithm maintains current state current set clauses D. fourmodes operation DEFAULT, CONFLICT, UNIT, DECISION. algorithm startsDEFAULT mode empty state current state given CNF formulacurrent set clauses:356fiClause-Learning AlgorithmsDEFAULT. sets variables satisfies clauses D, stop outputSAT together current state S. Otherwise, D|S contains empty clause,move CONFLICT mode. Otherwise, D|S contains unit clause, move UNITmode. Finally, control reaches point, move DECISION mode.CONFLICT. Apply learning scheme add new clause C D. C emptyclause, stop output UNSAT. Otherwise, apply restart policy decide whethercontinue restart DEFAULT mode current initializedempty state. case continue further, repeatedly remove assignmentstail long C|S = , go UNIT mode.UNIT. unit clause {xa } D|S , add x = go back DEFAULTmode.DECISION. Apply decision strategy determine decision x = addedgo back DEFAULT mode.guarantee correctness termination, learning scheme always add clause Clogical consequence D, C|S = holds time added,contains one variable maximum decision level. hard seeproperties prevent clause learned twice, since number clausesvariables finite, implies termination. Clauses characteristicsalways exist include asserting clauses (Zhang, Madigan, Moskewicz, & Malik,2001) discussed Section 2.3.3.well-known DPLL-procedure precursor algorithm where, CONFLICTmode, learning scheme never adds new clause, restart policy dictaterestart all, assignments removed tail latest decisionassignment, say x = a, replaced x = 1 a. say DPLL-procedurebacktracks latest decision. contrast, modern SAT-solvers implement learningschemes backtrack literal, determined learned clause, necessarily latest decision. called non-chronological backtracking. Besides learningschemes non-chronological backtracking, modern SAT-solvers also implement restartpolicies appropriate decision strategies. discuss choice componentsalgorithm Section 2.3.2.2.2 Runs AlgorithmConsider run algorithm started DEFAULT mode empty state initialset clauses D, either clause falsified variables set. run calledcomplete round started represent sequence states S0 , . . . , Smalgorithm goes through, S0 empty state Sm stateeither variables set, falsified clause found. generally, roundinitial segment S0 , . . . , Sr complete round state either D|Sr containsempty clause D|Sr contain unit clause. D|Sr contains empty clausesay round conclusive. round conclusive call inconclusive.357fiAtserias, Fichte, & Thurleyterm inconclusive means reflect fact clause learned round.particular, (complete) round ends satisfying assignment inconclusive2 .round S0 , . . . , Sr , note {1, . . . , r}, state Si extends Si1 exactlyone assignment form xi = ai xi = ai depending whether UNIT DECISIONexecuted iteration; mode assigns variables. leadconfusion, identify round last state interpreted partial assignment.particular, say round satisfies clause C C|Sr = 1, falsifiesC|Sr = .2.3 Restart Policy, Learning Scheme, Decision Strategyfollowing discuss choice learning scheme, restart policydecision strategy used algorithm. discussion particularly focusdependence results choice.2.3.1 Restart Policyrestart policy determines whether restart search clause learned.important characteristic need restart policy dictaterestarts often enough. particular, analysis work equally well aggressive restart policies, one dictates restart every conflict,less aggressive strategy allows bounded number conflicts restarts.fact analysis insensitive follow monotonicity propertyperformance algorithm prove Lemma 5. precisely,follow monotonicity lemma decide use policy allows c > 1conflicts restart, upper bound number required restartsdecrease (or stay same). upper bound number conflicts wouldappear multiplied factor c, even though truth might even decreasewell. simplicity exposition, rest paper assume restartpolicy dictates restart every conflict.2.3.2 Decision Strategydecision strategy determines variable assigned next, value. Again,important characteristic need decision strategyallow round totally random decisions often enough. Here, totally random decisiondefined follows: current state algorithm S, choose variable xuniformly random among variables V appear S, value{0, 1} also uniformly random independently choice x. Thus, analysisactually applies decision strategy allows bounded number roundsheuristic-based decisions totally random ones. precisely, allow say c > 1rounds non-random decisions random ones, number required restartsconflicts would appear multiplied factor c. follow2. Let us note definitions round, conclusive round inconclusive round differ slightlygiven conference version paper (Atserias, Fichte, & Thurley, 2009). currentdefinitions make concepts robust.358fiClause-Learning Algorithmsmonotonicity lemma referred above. said, simplicity exposition assumefollowing every decision totally random.2.3.3 Learning Schemelearning scheme determines clause added set clausesconflict occurs. Let S0 , . . . , Sr conclusive round started set clausesends falsifying clause D. Let xi = ai xi = ai i-th assignmentround. annotate Si clause Ai reverse induction {1, . . . , r}:1. Let Ar+1 clause falsified Sr .2. r xi = ai decision, let Ai = Ai+1 .3. r xi = ai implied, let Bi clause Bi |Si1unit clause {xai }, let Ai = Res(Ai+1 , Bi , xi ) clauses resolvablexi , let Ai = Ai+1 otherwise.quite clear construction Ai resolution proof clausesD. fact, resolution proof linear even trivial sense Beame et al.(2004). call clause Ai conflict clause. denotes maximum decision levelassignments Sr , conflict clause called asserting clause contains exactlyone variable decision level d. Asserting clauses, originally defined Zhang et al. (2001),capture properties conflict clauses learned virtually modern SAT-solver.brevity, describe two concrete learning schemes detail. schemes seework Zhang et al. (2001).Decision learning scheme adds clause A1 current set clausesconflict. hard check A1 asserting clause. Furthermore, every literalA1 negation decision literal Sr ; important later on.1UIP learning scheme, stands 1st Unique Implication Point, one addsclause Ai r maximal subject condition Ai assertingclause.following assume, tacitly, algorithm employs assertinglearning scheme, is, one whose learned clauses always asserting, exceptempty clause.2.3.4 Clause Bookkeepingmentioned analysis relies crucially assumption learnedclauses never removed current set clauses. However, practical SAT-solversperiodically delete learned clauses save memory avoid overheadintroduce. Thus interesting question whether results made workwithout assumption. respect, strong proof-complexity results Nordstrom(2009) showing every small-width resolution refutation made worksmall clause-space seems indicate assumption similar indeed needed.Another remark worth making point concerns width learned clauses.Since goal show algorithm simulate small-width resolution, seemsnatural ask whether restrict learning scheme learn clauses small width359fiAtserias, Fichte, & Thurleyonly. mentioned introduction, analysis seem allow it. Moreover,recent results Ben-Sasson Johannsen (2010) show that, general, learning shortclauses provably weaker scheme learning arbitrarily long clauses. Thus,examples Ben-Sasson Johannsen (2010) small-width resolutionrefutations therefore show keeping long clauses actually requiredcase, conceivable might.3. Analysis Algorithmsection analyze running time algorithm. this,however, introduce key technical concepts absorption beneficialrounds, study important properties.3.1 Runs AlgorithmLet R R0 rounds, let C clause. say R0 subsumes R if, decisionmarks, every assignment R appears also R0 . say R R0 agree Crestrictions R R0 variables C equal: every variable C either unassignedboth, assigned value both. say R branches C decisionvariables R variables C. Note properties agree C branches Cdepend set variables C. define clauses simplify notationlater on.prove two rather technical lemmas. goal show inconclusive roundsrobust respect order assignments made. example, firstlemma shows inconclusive round subsumes round agreesdecisions. fact need slightly stronger claim involves rounds twodifferent sets clauses.Lemma 1. Let D0 sets clauses D0 , let C clause, let R0inconclusive round started D0 . Then, every round R started branchesC agrees R0 C, holds R0 subsumes R.Proof. Let R = (S0 , . . . , Sr ). induction i, prove every {0, . . . , r}, everyassignment Si also made R0 . = 0 nothing prove since S0 = . Let> 0 assume every assignment Si1 also made R0 . Let x = x =last assignment Si . Since R R0 agree C R branches C, every decisionassignment made R also made R0 . takes care case x = a. Supposelast assignment x = Si implied. means exists clauseA|Si1 = {xa }. Since D0 every assignment made Si1 alsomade R0 , necessarily x = appears R0 R0 inconclusive cannot leaveunit clauses unset.next lemma shows universal quantifier conclusion previouslemma void. addition, round chosen inconclusive.Lemma 2. Let D0 sets clauses D0 , let C clause, let R0inconclusive round started D0 . Then, exists inconclusive round R startedbranches C agrees R0 C, R0 subsumes R.360fiClause-Learning AlgorithmsProof. Let R0 = (T0 , . . . , Tt ). Define {0, . . . , t} set indices i-thassignment R0 assigns variable C. I, let xi = ai xi = ai i-thassignment R0 .construct round R = (S0 , . . . , Ss ) started inductively. AssociatedSj set Ij indices xi left unassigned Sj . Recall S0empty state definition. Hence I0 = I. define following process:1. Sj falsifies clause sets variables V set = j stop.2. Otherwise, unit clause {xa } D|Sj let Sj+1 Sj plus x = a.3. Otherwise, Ij non-empty, let minimum element Ij , let Sj+1obtained adding decision xi = ai Sj .none cases applies set = j stop process.construction R valid round started D. Let us see R0 subsumes R: letset literals made true decisions R. construction, R R0 agreehence R0 subsumes R Lemma 1. Furthermore, R inconclusive: D0R0 inconclusive, D|R0 contain empty clause, R0 subsumesR, also D|R contain empty clause. Further, every variable C belongsV R inconclusive, process stops = . Together fact R0subsumes R, shows R R0 agree C. Note finally R branches Cconstruction.3.2 AbsorptionOne key feature definition round inconclusive, residual setclauses contain unit clauses and, particular, closed unit propagation.means inconclusive round R started D, clause Rfalsifies literals one, R must satisfy remaining literal, hencewell. Besides D, clauses may property, important enoughdeserve definition:Definition 3 (Absorption). Let set clauses, let non-empty clause letxa literal A. say absorbs xa every inconclusive round startedfalsifies \ {xa } assigns x a. say absorbs absorbs everyliteral A.Naturally, absorbs xa also say absorbed xa .Intuitively, one way think absorbed clauses learned implicitly. restsection devoted make intuition precise. now, let us noteinconclusive rounds started D, every clause absorbed. agreesgiven intuition since absence inconclusive rounds means unit-clause propagationapplied produces empty clause. section also show notionclause-absorption tightly connected concept 1-empowerment independentlyintroduced Pipatsrisawat Darwiche (2009).361fiAtserias, Fichte, & Thurley3.2.1 Properties Absorptioncontinue, let us discuss key properties absorption. argued alreadyevery clause absorbed D. give example showing may absorbclauses. Let set consisting three clausesbbcb e.example, clause c belong absorbed since every inconclusive round sets = 0 must set c = 1 unit-propagation, every inconclusiveround sets c = 0 must set = 1 also unit-propagation. may absorbclauses saw, note every non-empty clause absorbed logicalconsequence D. write |= C, every satisfying assignment satisfies C.Lemma 4. Let set clauses let C non-empty clause. absorbs C,|= C.Proof. Let full assignment satisfies clauses D. want showsatisfies C well. Let R = (S0 , . . . , Sr ) complete round algorithm startedsets decision variables set S. induction {0, . . . , r},show Si follow R stopped conflict thereforeSr = S. particular R inconclusive, falsifies literals C one, mustsatisfy remaining one C absorbed. Since R sets variables C Sr = S,means satisfies C.remains show Si every i. = 0 nothing show sinceS0 = . Fix > 0 assume Si1 S. Let x = x = last assignmentSi . case x = taken care assumption decision variables R setS. Suppose last assignment x = implied. means existsclause A|Si1 = {xa }. Since satisfies Si1 S, necessarily xset S.Next, let us see converse lemma hold; namely, seeevery implied clause absorbed. previous example, instance, notebde consequence (resolve first third clause a) absorbed(consider inconclusive round = 0, e = 0).One interesting property illustrated example C resolventtwo absorbed clauses B, C absorbed literal `, ` appearsB. example above, absorb b e b, b appearsclauses b b e D, whose resolvent precisely b e.prove general fact next section objects study non-absorbedresolvents absorbed clauses.Next show three key monotonicity properties clause-absorption, firstone motivated definition.Lemma 5. Let E sets clauses let B non-empty clauses.following hold:1. belongs D, absorbs A,362fiClause-Learning Algorithms2. B absorbs A, absorbs B,3. E absorbs A, E absorbs A.Proof. prove 1. assume contradiction literal ` inconclusiveround S0 , . . . , Sr started falsifies A\{`} satisfy A. roundinconclusive, cannot A|Sr = , means A|Sr = {`}, contradictiondefinition round.proof 2. let ` literal B define B 0 = B \ {`}. consider twodifferent cases. `/ B 0 and, absorbed D, inconclusiveround falsifies B 0 . Thus B absorbed case. ` A, let A0 = \ {`} letS0 , . . . , Sr inconclusive round started falsifies B 0 . falsifies A0satisfies absorption. Thus satisfies B, B absorbed case well.remains prove 3. Let ` literal A0 = \ {`}. Let R0inconclusive round started E falsifies A0 . Lemma 2, inconclusiveround R started falsifies A0 subsumed R0 . absorbedD, see R (and hence R0 ) satisfies A.3.2.2 Absorption Empowermentnext goal show absorption empowerment dual notions. assignments , write every assignment also . Let us reproducedefinition 1-empowerment work Pipatsrisawat Darwiche (2009), slightlyadapted better suit notation terminology.Definition 6 (1-Empowerment Pipatsrisawat & Darwiche, 2009). Let setclauses, let C non-empty clause let xa literal C. Let assignmentsets = 1 b every literal b C \ {xa }. say C 1-empowering via xarespect D, following three conditions met:1. C logical consequence D; i.e. |= C,2. repeated applications unit-clause propagation D| yield empty clause,3. repeated applications unit-clause propagation D| assign x a.also say xa empowering literal C. say C 1-empowering1-empowering via literal C.preliminary version definition given Pipatsrisawat Darwiche (2008)second three conditions required.definition absorption, see non-empty clause absorbedset clauses D, inconclusive round R started literal xaR falsifies \ {xa } satisfy {xa }. logical consequenceD, witnesses precisely fact 1-empowering via xa . showconverse also true:Lemma 7. Let set clauses, let C non-empty clause |= C,let xa literal C. Then, C 1-empowering via xa respectabsorb C xa .363fiAtserias, Fichte, & ThurleyProof. Let C 0 = C\{xa }. Assume first absorb C xa . Let R = (S0 , . . . , Sr )inconclusive round started witnessing fact, i.e. Sr falsifies C 0assign x = a. particular Sr . Furthermore, every unit clause {y b } D|= b Sr , R inconclusive round. straightforward induction,see every obtained repeated applications unit-clause propagationD| also satisfies Sr . directly implies conditions 2. 3. definition1-empowerment. Condition 1. met assumption.converse, assume C 1-empowering via xa respect D.show inconclusive round started falsifies C 0 assignx = a. Let R = (S0 , . . . , Sr ) round started every decision assignmentchosen falsify literal C 0 , that, among rounds property, assignsmany literals C 0 possible. Clearly maximal round exists since onemake decision meets property.shall show R round seek. {0, . . . , r}, letmaximal assignment Si , let obtained repeated applicationsunit-clause propagation D|i , let subset assignmentsalso Si . particular Si . shall prove, induction i, Si henceSi = .base case = 0 trivial since S0 = . Assume > 0 Si1 i1 .i-th assignment Si decision assignment, construction falsifies literalC 0 hence belongs . also belongs , required.i-th assignment Si implied distinguish two cases: whether also belongsnot. implied assignment also , , required.implied assignment , = i1 hence = i1 . then, sinceSi1 i1 induction hypothesis i1 i1 , unit clause responsibledefinition Si appears process forming i1 hence process forming. Therefore assignment also .completes induction shows, particular, Sr = r . point 2.definition 1-empowerment, R inconclusive. Furthermore, point 3. definition1-empowerment, Sr assign x = a. remains show Sr falsifies C 0 . Firstnote that, maximality R fact R inconclusive, every literal C 0assigned R. Moreover, since decision assignments R chosen falsifyliterals C 0 , suffices show implied assignments R satisfy literalC 0 . Thus, suppose contradiction = b implied assigned Rb literal C 0 . Let {0, . . . , r} {y b } unit-clause D|Si . SinceSi Sr r assigned 1 b , unit-clause {y b } D|Si appearsempty clause closure unit-clause propagation D| ; contradicts point 2.definition 1-empowerment completes proof.Let us note point condition 1. definition 1-empowermentdropped, hypothesis |= C also dropped Lemma 7. wouldmake 1-empowerment absorption literally dual other.364fiClause-Learning Algorithms3.3 Beneficial Roundsshall study key situation explains algorithm possibly simulateresolution proofs. Consider resolvent C = Res(A, B) two absorbed clauses Bitself, however, absorbed. goal study A, B C look likecase. start showing C absorbed literal ` C, `appears B. property held key discovering concept clauseabsorption relevance simulation resolution proofs. similar connectionclause learning observed Pipatsrisawat Darwiche (2008), also pointedcondition literal C appears B known mergeresolution (Andrews, 1968).Lemma 8. Let set clauses, let B two resolvable clauses absorbedD, let C = Res(A, B). ` literal C absorb C `, `appears B.Proof. Let C = Res(A, B, y), let A0 = \ {y} B 0 = B \ {y}. Let` = xa literal C assume absorb C `. existsinconclusive round R falsifies C \ {xa } set x a. Since ` belongs CC = A0 B 0 ` belongs B, both. belongs both,done. Otherwise, assume without loss generality belongsB. case R falsifies B \ {y}, since B absorbed, set 0 R. Rfalsifies \ {xa }, since absorbed, x set R. contradicts choiceR x set a.continue showing situation interest, always exist beneficialround algorithm predicts eventual absorption.Definition 9 (Beneficial Round). Let set clauses, let non-empty clause,let xa literal A, let R inconclusive round started D. say Rbeneficial xa falsifies \ {xa }, branches \ {xa }, leaves x unassigned,yields conclusive round extended decision x = . conclusive round obtainedextending R x = also called beneficial xa . say R beneficialbeneficial literal A.words, round started beneficial xa witnessabsorb xa , minimal property, yet yields conflictx set wrong value. Thus, informally, beneficial round witnessalmost absorbs xa .Lemma 10. Let set clauses, let B two resolvable clausesabsorbed D, let C = Res(A, B). C non-empty absorbed D,round started beneficial C.Proof. identify literal xa C able build beneficial round Cxa .Let C = Res(A, B, y), let A0 = \ {y} B 0 = B \ {y}. Cnon-empty absorbed D, literal xa C inconclusive round R0365fiAtserias, Fichte, & Thurleystarted falsifies C 0 = C \ {xa } set x a. Also x assignedR0 since otherwise would falsify C, C = A0 B 0 absorbsB, would satisfied R0 . shows x unassigned R0 .Let R inconclusive round started obtained applying Lemma 2C 0 given inconclusive round R0 . claim R beneficial C xa :round R falsifies C 0 , agrees R0 C 0 . Also R branches C 0 and, R0 subsumesR, leaves x unassigned. Finally, note R R0 also agree \ {y} B \ {y}.Hence extending round R decision x = yields conclusive round; otherwisewould satisfied since B absorbed D.3.4 Main Technical Lemmastart analyzing number complete rounds takes resolventtwo absorbed clauses absorbed function width. However, trivialfirst determine number complete rounds takes sufficient prerequisiteabsorption occurs: beneficial round.Lemma 11. Let set clauses, let B two resolvable clausesabsorbed non-empty resolvent C = Res(A, B). Let n totalnumber variables D, k width C. every 1, let R0 , . . . , Rt1 denoteconsecutive complete rounds algorithm started D, let D0 , . . . , Dt1denote intermediate sets clauses. Then, probability none Ri beneficialkC none Di absorbs C et/(4n ) .Proof. Let R0 , . . . , Rt1 denote consecutive complete rounds algorithm startedD, let D0 , . . . , Dt1 intermediate sets clauses. particular D0 =Ri round started Di . every {0, . . . , 1} let Ri event Ribeneficial let Di event Di absorb C. want computeupper bound joint probability events. Note"t1# t1 "# t1 "#j1fi j1fi\\fi \fiPrRi =Pr Rj Dj fiRiPr Rj fi DjRi(1)i=0j=0i=0j=0i=0Hence, shall give appropriate upper bounds factors right hand sideinequality. this, let us first bound Pr Rj | Dj , Rj1 , Dj1 , . . . , R0 , D0below. conditions Dj , Rj1 , Dj1 , . . . , R0 , D0 , Lemma 10 impliesinconclusive round R started Dj beneficial C xa C.probability Rj beneficial C bounded probability Rjbeneficial C xa . therefore bound latter below.First let us compute lower bound probability first k 1 decisionsdecision strategy chosen falsify C \ {xa } k-th choice x = a. probabilitychoices made leastk1k211(k 1)!1k.kk2n2(n 1)2(n k + 2)2(n k + 1)2 n4nNote round started Dj follows choices may even abledecisions corresponding assignments may implied. However,366fiClause-Learning Algorithmsdecision x = made, round following choices perform decisionsagree R C \ {xa } therefore stay subsumed R every new decision,Lemma 1. particular, right decision x = inconclusive, falsifyC \ {xa }, leave x unset. Also Lemma 1 performed assignmentsR order, therefore addition x = make conclusive. followsprobability round beneficial C xa bigger.Consequently, probability Rj conditional Dj , Rj1 , Dj1 , . . . , R0 , D0 bounded1 4n1k . Therefore, equation (1)Pr"t1\i=0#Ri1k1 ket/(4n )4nsecond inequality used fact 1 + x ex every real number x.3.5 Boundstools given above, able prove main result paper:simulation width-k resolution algorithm. shall first give proofalgorithm employing Decision learning scheme. proof easierinstructive, also get slightly better bounds special case. Afterwards,see result asserting learning schemes general.3.5.1 Decision Schemefact makes Decision easier analyze that, learning scheme,occurrence beneficial round immediately yields absorption next step. Indeed,R beneficial C, branches C, means clause learnedcomplete round subset C. particular means next set clausesabsorb subset C, hence C well Lemma 5. obtain following resultdirect consequence Lemma 11.Lemma 12. Let set clauses, let B two resolvable clausesabsorbed non-empty resolvent C = Res(A, B). Let n totalnumber variables k width C. Then, 1, using Decisionlearning scheme, probability C absorbed current set clauseskrestarts et/(4n ) .Proof. Let R0 , . . . , Rt1 denote consecutive complete rounds algorithm startedD, let D0 , . . . , Dt intermediate sets clauses. particular D0 =Ri round started Di . every {0, . . . , 1} let Ri eventRi beneficial C let Di event Di absorb C. oneRi beneficial C, Di+1 absorbs C. see this, note R branchesC, clause Ci learned Ri satisfies Ci C. Hence Di+1 absorbs Ci CLemma 5. Further, Dt also absorbs C, one Di absorbs Lemma5. Hence,probability C absorbed Dt bounded Pr[ t1i=0 Ri Di ].k)t/(4nLemma 11 implies bounded e.367fiAtserias, Fichte, & ThurleyTheorem 13. Let F set clauses n variables resolution refutationwidth k length m. probability least 1/2, algorithm started F , usingDecision learning scheme, learns empty clause 4m ln(4m)nk conflictsrestarts.Proof. resolution refutation must terminate application resolution ruleform Res(x, x). show ` = x ` = x, probability{`} absorbed current set clauses 4m ln(4m)nk restarts 1/4.Thus, {x} {x} absorbed probability least 1/2. case,straightforward every complete round algorithm conclusive. particular,round make decision conclusive, case emptyclause learned.Let C1 , C2 , . . . , Cr = {`} resolution proof {`} included width-kresolution refutation F . particular r m1 every Ci non-empty widthk. Let D0 , D1 , . . . , Ds sequence clause-sets produced algorithm= rt = d4 ln(4r)nk e. every {0, . . . , r}, let Ei event everyclause initial segment C1 , . . . , Ci absorbed Dit , let E negation. NotePr[ E0 ] = 1 vacuously hence Pr[ E 0 ] = 0. > 0, bound probabilityEi hold conditional Ei1 cases. Let pi = Pr[ E | Ei1 ] probability.Ci clause F , pi = 0 Lemma 5. Ci derived two previous clauses,kpi et/(4n ) Lemma 12, 1/(4r) choice t.law total probability givesPr E = Pr E | Ei1 Pr [Ei1 ] + Pr E | E i1 Pr E i1Pr E | Ei1 + Pr E i1 .PAdding {1, . . . , r}, together Pr E 0 = 0, gives Pr E r ri=1 pir14r = 4 . Since probability Cr absorbed Drt bounded Pr[ E r ],proof follows.3.5.2 Asserting Learning Schemes Generalshall study algorithm applying arbitrary asserting learning scheme.analysis bit complex Decision scheme since general clauselearned complete round R cannot assumed subset decisions R.Therefore show resolvent eventually absorbed little detour.note proof overcome similar difficulties as, inspired by3 , proofProposition 2 work Pipatsrisawat Darwiche (2009).need preparation. Let C clause set clauses. Let WC,Ddenote set literals ` C exists inconclusive round startedbeneficial C `. Let u`,C,D denote number variables left unassignedinconclusive round started beneficial C `. roundexists, define u`,C,D = 0. Note number well-defined, follows easily3. thank anonymous reviewer pointing original proof Proposition 2 workPipatsrisawat Darwiche (2009) contained error corrected version paperwebpage. proof affected error.368fiClause-Learning AlgorithmsLemma 1 every inconclusive round started beneficial C ` leavesnumber variables unassigned. Further, defineuC,D =Xu`,C,D .`WC,DNote C absorbed D, WC,D = . Moreover, hypothesisLemma 10, converse also true. Analogously, C absorbed D, uC,D = 0and, hypothesis Lemma 10, converse also true.Lemma 14. Let D0 sets clauses D0 . Let B two resolvableclauses absorbed D, let C = Res(A, B). Then, WC,D0 WC,D u`,C,D0u`,C,D ` WC,D .Proof. WC,D0 = , nothing shown. Otherwise, xa WC,D0 , startshowing xa belongs WC,D . Let R0 inconclusive round started D0beneficial C `. Application Lemma 2 R0 C \{xa } yields inconclusive roundR started following properties: R0 subsumes R, agree C \ {xa },R branches C \ {xa }. show R beneficial C xa , remainsprove extending R x = yields conclusive round. Let R round definedextension. Let C = Res(A, B, y). R falsifies B \ {y} \ {y}.absorption, R cannot inconclusive, otherwise, would satisfied R .proves WC,D0 WC,D .Now, show u`,C,D0 u`,C,D every ` WC,D . ` belong WC,D0nothing shown since u`,C,D0 = 0 case. Otherwise, let R0 R inconclusiverounds beneficial C ` R0 started D0 R started D.Lemma 1, R0 subsumes R, finishes proof.Lemma 15. Let set clauses, let B two resolvable clausesabsorbed D, let C = Res(A, B). Let R conclusive round started letD0 obtained adding asserting clause learned R. C emptyR beneficial C ` C, u`,C,D0 < u`,C,D uC,D0 < uC,D .Proof. Lemma 14 already know uC,D0 uC,D u`,C,D0 u`,C,D . Therefore,suffices demonstrate that, presence R, second inequality strict.hypothesis, R beneficial C `. Let C 0 asserting clause learned R.Let R unique inconclusive round contained R beneficial C `;round contain last decision made R. Lemma 1, numberassignments made two rounds started beneficial C `same. Hence, number variables left unassigned R equals u`,C,D , u`,C,D 1since least one variable unset.u`,C,D0 = 0 already u`,C,D0 < u`,C,D . Therefore, assume u`,C,D0 1.particular, exists inconclusive round R0 started D0 beneficial C`. Lemma 1 round R0 subsumes R . definition asserting clauses, C 0 |Runit clause, since C 0 belongs D0 , absorbed D0 hence R0 satisfies C 0 .proves R0 sets least one variable R therefore u`,C,D0 < u`,C,D .369fiAtserias, Fichte, & Thurleytwo technical lemmas hand ready state prove analogueLemma 12 arbitrary asserting learning schemes.Lemma 16. Let set clauses, let B two resolvable clausesabsorbed non-empty resolvent C = Res(A, B). Let n totalnumber variables let k width C. Then, 1, using arbitraryasserting learning scheme, probability C absorbed current set clauseskkn restarts kn et/(4n ) .Proof. Let b = uC,D , = bt, let D0 , . . . , Ds sequence sets clausesproduced algorithm, starting D0 = D. every {0, . . . , b}, let Xi = uC,Ditlet Ei event Xi b i.bound probability C absorbed Dbt above. Sinceevent implies Xb 6= 0, suffices bound Pr[ E b ]. Note Pr[ E0 ] = 1 vacuouslyhence Pr[ E 0 ] = 0. > 0, bound probability Ei hold. lawtotal probability givesPr E = Pr E | Ei1 Pr [Ei1 ] + Pr E | E i1 Pr E i1Pr E | Ei1 + Pr E i1 .Let pi = Pr[ E | Ei1 ] note Pr[ E | Xi1 < b + 1 ] = 0. Hence piPr[ E | Xi1 = b + 1 ]. Consider sequence D(i1)t+1 , . . . , Dit sets clausescorresponding complete rounds algorithm. Conditional Xi1 = b + 1,event E implies Xi = Xi1 6= 0 hence none sets clauses absorbsC. Furthermore, Lemma 15, none corresponding rounds beneficial C. Thus,kLemma 11, pi et/(4n ) . Adding {1, . . . , r}, togetherPbkPr E 0 = 0, gives Pr E b i=1 pi b et/(4n ) . Lemma follows necessarilyb kn.able prove main theorem.Theorem 17. Let F set clauses n variables resolution refutation widthk length m. probability least 1/2, algorithm started F , using arbitrary asserting learning scheme, learns empty clause 4km ln(4knm)nk+1conflicts restarts.Proof. proof analogous proof Theorem 13 Lemma 16 playing roleLemma 12, choosing = d4 ln(4m kn)nk e now.4. Consequencestotal number clauses width k n variables bounded 2k nk ,2nk every n k. Therefore, F n variables resolution refutation widthk, may assume length 4nk following estimatekkkXXn 1n1+2n = 1 + 2n4nk .2n1i=0i=1obtain following consequence Theorem 17.370fiClause-Learning AlgorithmsCorollary 18. Let F set clauses n variables resolution refutationwidth k. probability least 1/2, algorithm started F , using arbitraryasserting learning scheme, learns empty clause 16k(k + 1) ln(16kn)n2k+1conflicts restarts.application Corollary 18 that, even though explicitly definedpurpose, algorithm used decide satisfiability CNF formulas treewidthk time O(k 2 log(kn)n2k+3 ). follows known fact every unsatisfiable formula treewidth k resolution refutation width k + 1(Alekhnovich & Razborov, 2002; Dalmau, Kolaitis, & Vardi, 2002; Atserias & Dalmau,2008).interested producing satisfying assignment exists, proceedself-reducibility: assign variables one time, running algorithm log2 (n) + 1 timesassignment detect current partial assignment cannot extendedfurther, case choose complementary value variable. usefact F treewidth k, F |x=a also treewidth k.analysis, note since run algorithm correct probability least1/2, new assignment correct probability least1 2(log2 (n)+1) = 11.2nmeans iterations correct probability least (1running time algorithm O(k 2 (log(kn))2 n2k+4 ).1 n2n )12.Acknowledgmentsthank Martin Grohe suggesting problem comparing power SAT-solversbounded-width resolution. also thank Knot Pipatsrisawat Adnan Darwichepointing connection 1-empowering absorption. Thanks alsoPeter Jeavons comments conference version paper, anonymousreferees detailed comments.first author supported part CYCIT TIN2007-68005-C04-03. secondauthor supported part European Research Council (ERC), Grant 239962.third author supported part fellowship within Postdoc-ProgrammeGerman Academic Exchange Service (DAAD). preliminary version paper appearedProceedings 12th International Conference Theory ApplicationsSatisfiability Testing, SAT09 (Atserias et al., 2009).ReferencesAlekhnovich, M., & Razborov, A. A. (2002). Satisfiability, branch-width Tseitin tautologies. Proceedings 43rd Symposium Foundations Computer Science(FOCS 2002), pp. 593603. IEEE Computer Society.Alekhnovich, M., & Razborov, A. A. (2008). Resolution automatizable unless W[P]tractable. SIAM J. Comput., 38 (4), 13471363.371fiAtserias, Fichte, & ThurleyAndrews, P. B. (1968). Resolution merging. J. ACM, 15 (3), 367381.Atserias, A., & Dalmau, V. (2008). combinatorial characterization resolution width.J. Comput. Syst. Sci., 74 (3), 323334.Atserias, A., Fichte, J. K., & Thurley, M. (2009). Clause-learning algorithms manyrestarts bounded-width resolution. Kullmann, O. (Ed.), Proceedings 12thInternational Conference Theory Applications Satisfiability Testing (SAT),Vol. 5584 Lecture Notes Computer Science, pp. 114127. Springer.Bayardo, R. J., & Schrag, R. C. (1997). Using CSP look-back techniques solve real-worldSAT instances. Proceedings Fourtheenth National Conference ArtificialIntelligence (AAAI97), pp. 203208.Beame, P., Kautz, H. A., & Sabharwal, A. (2003). Understanding power clauselearning. Gottlob, G., & Walsh, T. (Eds.), Proceedings Eighteenth International Joint Conference Artificial Intelligence (IJCAI-03), pp. 11941201. MorganKaufmann.Beame, P., Kautz, H. A., & Sabharwal, A. (2004). Towards understanding harnessingpotential clause learning. J. Artif. Intell. Res. (JAIR), 22, 319351.Ben-Sasson, E., & Johannsen, J. (2010). Lower bounds width-restricted clause learningsmall width formulas. Strichman, O., & Szeider, S. (Eds.), Proceedings 13thInternational Conference Theory Applications Satisfiability Testing (SAT),Vol. 6175 Lecture Notes Computer Science, pp. 1629. Springer.Ben-Sasson, E., & Wigderson, A. (1999). Short proofs narrow - resolution made simple.Proceedings Thirty-First Annual ACM Symposium Theory Computing(STOC 1999), pp. 517526.Dalmau, V., Kolaitis, P. G., & Vardi, M. Y. (2002). Constraint satisfaction, boundedtreewidth, finite-variable logics. CP 02: Proceedings 8th InternationalConference Principles Practice Constraint Programming, pp. 310326, London, UK. Springer-Verlag.Fox, D., & Gomes, C. P. (Eds.). (2008). Proceedings Twenty-Third AAAI ConferenceArtificial Intelligence, AAAI 2008, Chicago, Illinois, USA, July 13-17, 2008. AAAIPress.Hertel, P., Bacchus, F., Pitassi, T., & Gelder, A. V. (2008). Clause learning effectivelyp-simulate general propositional resolution.. Fox, & Gomes (Fox & Gomes, 2008),pp. 283290.Jeavons, P., & Petke, J. (2010). Local consistency sat-solvers. Proceedings16th International Conference Principles Practice Constraint Programming- CP 2010, Vol. 6308 Lecture Notes Computer Science, pp. 398413. Springer.Moskewicz, M. W., Madigan, C. F., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineering efficient SAT solver. Proceedings 38th Design Automation Conference(DAC01).Nieuwenhuis, R., Oliveras, A., & Tinelli, C. (2006). Solving SAT SAT Modulo Theories: abstract DavisPutnamLogemannLoveland procedure DPLL(T).Journal ACM, 53 (6), 937977.372fiClause-Learning AlgorithmsNordstrom, J. (2009). Narrow proofs may spacious: Separating space widthresolution. SIAM J. Comput., 39 (1), 59121.Pipatsrisawat, K., & Darwiche, A. (2008). new clause learning scheme efficient unsatisfiability proofs.. Fox, & Gomes (Fox & Gomes, 2008), pp. 14811484.Pipatsrisawat, K., & Darwiche, A. (2009). power clause-learning SAT solversrestarts. Gent, I. P. (Ed.), Proceedings 15th International ConferencePrinciples Practice Constraint Programming - CP 2009, Vol. 5732 LectureNotes Computer Science, pp. 654668. Springer.Silva, J. P. M., & Sakallah, K. A. (1996). Grasp - new search algorithm satisfiability.Proceedings IEEE/ACM International Conference Computer-Aided Design,pp. 220227.Zhang, L., Madigan, C. F., Moskewicz, M. W., & Malik, S. (2001). Efficient conflict drivenlearning boolean satisfiability solver. International Conference ComputerAided Design (ICCAD01), pp. 279285.373fiJournal Artificial Intelligence Research 40 (2011) 221-267Submitted 06/10; published 01/11Probabilistic Approach Maintaining TrustBased EvidenceYonghong Wangyhwang@andrew.cmu.eduRobotics InstituteCarnegie Mellon University5000 Forbes AvePittsburgh, PA 15213 USAChung-Wei HangMunindar P. Singhchang@ncsu.edusingh@ncsu.eduDepartment Computer ScienceNorth Carolina State UniversityRaleigh, NC 27695-8206 USAAbstractLeading agent-based trust models address two important needs. First, showagent may estimate trustworthiness another agent based prior interactions.Second, show agents may share knowledge order cooperatively assesstrustworthiness others. However, real-life settings, information relevant trustusually obtained piecemeal, once. Unfortunately, problem maintainingtrust drawn little attention. Existing approaches handle trust updates heuristic,principled, manner.paper builds formal model considers probability certainty twodimensions trust. proposes mechanism using agent update amounttrust places agents ongoing basis. paper shows via simulationproposed approach (a) provides accurate estimates trustworthiness agentschange behavior frequently; (b) captures dynamic behavior agents.paper includes evaluation based real dataset drawn Amazon Marketplace,leading e-commerce site.1. IntroductionLet us consider applications domains electronic commerce, social networks, collaborative games, virtual worlds populated multiple virtual characters.applications exhibit two important common features: (1) naturally involve multipleentities, real (humans businesses) fictional; (2) entities areor behaveareautonomous heterogeneous. reason, view entitiescomputational surrogates agents. success agent application, evaluated termsquality experience enjoyed user economic value derived business, depends felicitous interactions among agents. Since agents functionallyautonomous, felicity interactions cannot centrally ensured. Further,agent usually limited knowledge others interacts. Therefore,agent relies upon notion trust identify agents interact.c2011AI Access Foundation. rights reserved.fiWang, Hang, & SinghGiven intended applications, narrow scope agents provideconsume services, also share information regarding trustworthinessagents. assume agent behaves according fixed type, meaning althoughbehavior could complex, trustworthiness based incentives sanctionsmight receive, behavior different toward different participants. Oneimagine settings service encounters service provider selectivelyfavor customers. Hence, purpose trust model distinguish goodbad agents, directly cause agents behave good manner. Further,assume setting empirical, meaning agents base extent trustothers upon outcomes prior interactions. level trust agent Alice placesagent Bob viewed Alices prediction Bob providing good service outcomefuture. empirically reliable, Alice estimate Bobs trustworthiness basedpast experience Bob. (1) parties agent deals mayalter behavior (2) agent receives information parties incrementally,important agent able update assessments trust.one would expect important subject, several researchers developedformal ways represent reason trust. Interestingly, however, existing approachesconcentrate maintain representations. might seem researchersbelieve heuristic approach would adequate. typical approach basedexponential discounting, requires programmer hand-tune parametersdiscount factor.paper contributes model method updating trust ratings light incremental evidence. Specifically, develops principled, mathematical approach maintaining trust historically (as way evaluate agents provide services) socially (asway evaluate agents provide information agents). Further, papershows avoid hand-tuned parameter.1.1 Technical Motivationcommon way estimate trustworthiness provider evaluate probabilityfuture service outcome good based number good service outcomesprovider past. However, traditional scalar representation (i.e., probability)cannot distinguish getting one good outcome two interactions, getting100 good outcomes 200 interactions. But, intuitively, significant differenceterms confidence one would place two scenarios.reason, modern trust models define trust terms probability certaintygood outcome (Jsang & Ismail, 2002; Wang & Singh, 2007; Gomez, Carbo, & Earle,2007; Teacy, Patel, Jennings, & Luck, 2006; Harbers, Verbrugge, Sierra, & Debenham, 2007;Paradesi, Doshi, & Swaika, 2009). certainty measure confidence agentmay place trust information. Computing certainty help agent filterparties insufficient information, even nominally probabilitygood outcome high. general, certainty trust value (a) increaseamount information increases fixed probability, (b) decrease numberconflicts increases fixed total number experiences (Wang & Singh, 2010).222fiA Probabilistic Approach Maintaining Trust Based EvidenceOpen systems dynamic distributed. words, agent often needsselect service provider previous interaction. Referral networksenable agents collect trust information service providers distributed manner(Yu & Singh, 2002; Procaccia, Bachrach, & Rosenschein, 2007). referral network,agent requests agents, called referrers, provide trust information serviceprovider. referrer lacks direct experience service provider, may referanother (prospective) referrer. Existing trust models (e.g., Barber & Kim, 2001), specifyagent may aggregate trust information multiple sources (which could includecombination referrals direct interactions).view referrals services referrers provide. Consequently,agent ought able estimate referrers trustworthiness based qualityreferrals provides. However, existing trust models lack principled mechanismupdate trust placed referrer.Besides, reflect dynamism agents time, discount factor neededhelp trust models provide accurate predictions future behavior (Zacharia & Maes, 2000;Huynh, Jennings, & Shadbolt, 2006). low discount factor, past behavior forgottenquickly estimated trustworthiness reflects recent behavior. Conversely,high discount factor, estimated trustworthiness considers emphasizes long-termoverall behavior rated agent. Different discount factors yield different accuracybehavior predictions. Choosing proper discount factor different types agentsvaried settings involves crucial trade-off accuracy evidence. trade-off,however, drawn much attention trust research community.propose probabilistic approach updating trust builds Wang Singhs(2010) probability-certainty trust model. trust update method enriches WangSinghs trust model two ways. First, trust update applies estimating trustworthiness referrers based referrals provide. Second, method adjustsdiscount factor dynamically updating dynamism agents without requiringmanual tuning.select Wang Singhs trust model supports featurescrucial purposes. One, defines trustworthiness agent evidence space,representing trust using probability certainty. Two, defines certaintyamount trust placed agent increases amount evidence (if extentconflict held constant) decreases increasing conflict (if amount evidenceheld constant). Three, supports operators propagating trust referrals. WangSingh (2006) define mathematical operators propagating trust. incorporateoperators bases addressing specific technical problems computing trustupdates discounting referrers provide erroneous referrals.1.2 Contributionspaper proposes principled, evidence-based approach agent updateamount trust places another agent. introduces formal definitions updatingtrust placed studies mathematical properties. achieve self-tuning approachtrust updates, paper proposes new notion trust history, contrasttraditional notion discounting history via hand-tuned discount factor. paper223fiWang, Hang, & Singhevaluates proposed approach (1) conceptually via comparison existing approachesterms formal properties (2) via simulation different agent behavior profiles;(3) respect data real-life marketplace. main outcomesapproachrequire fine-tuning parameters hand, thereby reducingburden system administrator programmer, also expanding rangepotential applications include behavior profiles agentsknown ahead time.Yields precision estimating probability component trust.Yields appropriate level certainty component trust existingapproaches. particular, recognizes effect conflict evidencecompute certainty based certainty input information.robust agents provide wrong information.1.3 Organizationrest paper organized follows. Section 2 provides essential technicalbackground approach. Section 3 introduces general model trust updateuniformly handles historical social updates. Section 4 introduces series trustupdate methods culminating proposed method. Section 5 evaluates methodstheoretical grounds establishing theorems regarding desirable undesirableproperties. Section 6 specifies historical social update scenarios precisely. Section 7conducts extensive experimental evaluation methods, including simulationsevaluation using real marketplace data Amazon. Section 8 studies literature. Section 9 concludes discussion directions future work. Appendixpresents proofs theorems.2. Background Probabilistic Trust Representationsection introduces key background Wang Singhs (2007) approachnecessary understanding present contribution.2.1 Probability-Certainty Distribution FunctionConsidering binary event hr, si, r represent number positivenegative outcomes, respectively. Let x [0, 1] probability positive outcome.posterior probability evidence hr, si conditional probability x givenhr, si (Casella & Berger, 1990). conditional probability x given hr, sif (x|hr, si) =R1g(hr,si|x)f (x)g(hr,si|x)f (x)dxR1xr (1x)sxr (1x)s dx0=0224fiA Probabilistic Approach Maintaining Trust Based Evidenceg(hr, si|x) =r+s rx (1 x)s .rPCDF vs r65r=20,s=4certainty4r=8,s=23r=4,s=12r=0,s=01000.10.20.30.40.50.6probability0.70.80.91.0Figure 1: Examples probability-certainty distribution functions, varying r s.f (x) probability distribution function x, probabilitypositive outcome. signatureR 1 f given f : [0, 1] 7 [0, ). fprobability density, 0 f (x)dx = 1. Following Jsang (2001), interpretprobability probability probability-certainty distribution function(PCDF). probability probabilitypositive outcome lies [x1 , x2 ] equalsR1R x2f(x)dx0= 1. Figure 1 gives examples f (x)10x1 f (x)dx. mean value fdifferent numbers positive negative outcomes. Noticeevidence (i.e., hr, si = h0, 0i), obtain uniform distribution. evidence mounts,distribution becomes focused around expected value.aside, notice although consider integral values rexamples, actual values r would usually integral effectdiscounting information received others remembered past interactions.particular, possible total evidence positive less one, i.e., 0 < r +s <1.2.2 Trust RepresentationJsangs approach, Wang Singhs model represents trust valuesevidence belief spaces. evidence space, trust value form hr, si,r + > 0. Here, r 0 number positive experiences (that, say, agent Aliceagent Bob) 0 number negative experiences Bob. r225fiWang, Hang, & Singhrreal numbers. Given hr, si, = r+sexpected value probability positiveoutcome r + > 0 set = 0.5 r + = 0. belief space, trustvalue modeled triple belief, disbelief, uncertainty weights, hb, d, ui,b, d, u greater 0 b + + u = 1. intuitive terms, certainty c = 1 urepresents confidence placed probability. Trust values translatedevidence belief space.Wang Singh (2007) differ Jsang (2001) definition certainty. WangSinghs definition based following intuition. Figure 1 shows hr, si = h0, 0iknow nothing, f uniform distribution probabilities x. is, f (x) = 1x [0, 1] 0 elsewhere. reflects Bayesian intuition assuming equiprobableprior. Intuitively, uniform distribution certainty 0. additional knowledgeacquired, probability mass shifts f (x) 1 values x1 values x. reason, Wang Singh (2007) define certaintyarea uniform distribution f (x) = 1.Definition 1 certainty based evidence hr, si, givenc(r, s) ==R112120R10|f (x) 1|dxr| R 1(xr (1x)sx (1x) dx01|dxCertainty10.90.80.70.60.50.40.30.201002003004005006007008009001000Total number transactions ratio positive negative fixedFigure 2: Certainty increases mounting evidence provided amount conflictevidence held constant. X-axis measures total number outcomes,equally positive negative.Conflict evidence setting means evidence positivenegative. Thus conflict maximized r = minimized r zero.Wang Singh (2007) prove certainty increases total number transactionsincreases conflict fixed, Figure 2. also show certainty decreasesconflict increases total number transactions fixed, Figure 3.226fiA Probabilistic Approach Maintaining Trust Based Evidence0.940.92Certainty0.90.880.860.840.802.80.780.760.740102030405060708090100Number positive transactions total number transactions fixedFigure 3: Certainty decreases increasing conflict provided amount evidenceheld constant. X-axis measures number positive outcomesfixed total number outcomes.2.3 Trust Propagationreal-life settings, agent (a prospective client) may lack direct experience anotheragent (a prospective service provider) considers interacting. case,client ask referrers trust referrals. referrer lacks direct experience, mayrefer referrers, on. essential idea behind referral networks.calculate trust referral networks? Many researchers studiedtrust propagation. chosen framework, Wang Singh (2006) define mathematicaloperators propagating trust, leverage present goals.Wang Singh (2006) provide concatenation operator (similar Jsangs, 1998,recommendation operator) enables client C compute much trustplace service provider based direct experience referrer R referralprovided R. idea that, compute trust S, C simply concatenatestrust R Rs report S. Definition 2 captures Wang Singhs concatenationoperator. setting, let MR = hrR , sR agent Cs trust referrer R. Here, cRcertainty determined trust value. Further, let MS = hr , Rsreport trust provider S. amount trust placed Cgiven MR MS .Definition 2 Concatenation . Let MR = hbR , dR , uR MS = hb , , u two trustvalues. MR MS = hbR b , bR , 1 bR b bR i.handle situation C collects trust information onesource, use Jsangs aggregation operator (Jsang, 2001; Wang & Singh, 2007),simply sums available evidence pro con. C use operator combine independent reports trust place S. Definition 3 captures aggregation operator.setting, Mi = hri , si would trust C would place based exactly227fiWang, Hang, & Singhone path C S. paths mutually independent, i.e., nonoverlapping, Csaggregate trust would given M1 . . . Mk .Definition 3 Aggregation . Let M1 = hr1 , s1 M2 = hr2 , s2 two trust values.Then, M1 M2 = hr1 + r2 , s1 + s2 i.3. General Model Updating Trustobserved above, existing trust models provide suitable trust updatemethod agent may maintain trust places another agent. model,trust updates arise two major settings, consolidate universal modeltrust update. settings follows.Trust update referrers, wherein agent updates trust places referrerbased accurate referrals are. way agent maintainsocial relationship referrer.Trust update trust history, wherein agent updates trust placesservice provider tuning relative weight (discount factor) assigned serviceproviders past behavior respect current behavior. wayagent accommodate dynamism service provider.TargetTrust!rR , sR "RCompareCClientEstimated Trust!r , "Actual Trust!r, s"SourceFigure 4: Schematic illustration generalized trust update approach. ThroughoutrR, = r r+s , R = rRr+spaper, use = r+sRInterestingly, approach treats settings variations common theme,term general model updating trust. Figure 4 presents model,summarizes process consisting following steps based client C, target R,service provider S. client C seeks update amount trust hrR , sR Cplaces target R.C estimates Rs trustworthiness (before update) hrR , sR i.R reports Ss trustworthiness hr , i.delivers outcome C obtains direct information estimate actual trustworthiness hr, si S.228fiA Probabilistic Approach Maintaining Trust Based EvidenceUsing information (apparent) trustworthiness S, C determinesaccuracy estimated trust value previously received R. Based, empiricalmeasure Rs accuracy, C updates trust places R hrRRgrounds.Trust update methods differentiated compare estimatedactual trust values. rest section discusses general structure trust updateinvestigates trust update methods along shortcomings. Section 4introduces preferred approach.Let us follow setting Figure 4. accuracy estimated trust value definedcloseness estimated trust value hr , actual trust value hr, si. Insteadinterpreting transaction (one estimation trust target) either goodbad, interpret q good 1 q bad transactions. Notice good badpresent context target providing estimates refers accuracy otherwiseestimates respect actual outcomes client receives service provider.Thus targets estimate could good bad independently whether actual serviceoutcome good bad.Thus, q reflects close estimation hr , actual trust hr, si. require0 q 1 ranging perfectly inaccurate perfectly accurate referral. weightassign estimation increase certainty. example, supposeactual trustworthiness h10, 0i. Say, one target RA estimates Ss trustworthinessh0, 1i another target RB estimates h0, 100i. estimates agreetrustworthy, RA claims much lower certainty (c(0, 1) = 0.25) RB(c(0, 100) = 0.99). RA punished less RB estimates turninaccurate. And, similarly, rewarding case accuracy. Therefore, insteadtreating transaction one transaction, treat c transactions, c < 1certainty estimation. is, interpret estimation c q goodc (1 q) bad transactions.addition, discount past transaction age (Zacharia & Maes, 2000; ?,?, ?, ?, ?). let hrR , sR trust placed R C; hr , estimation, updated trust placed R C. Algorithm 1 presentsc = c(r , ); hrRRmodular specification generic trust update approach, highlighting key inputsoutputs. Let temporal discount factor. Based actual observations hr, si,let q represent accurate estimation p represent bad estimation is.specific approaches consider differ computes measureaccuracy, q.Note assume client updates trust referral conductedtransactions service provider, r + > 0 case. hr, si = h0, 0i,client cannot update trust according formulation, since discount updatecertainty hr, si hr, si = h0, 0i, certainty 0. matterhrR , sR = 0 update method. initialize hrR , sR predefinednumber, example, h1, 1i h0, 0i. initial value corresponds prior distributiontrust. uniform distribution corresponds initial setting hrR , sR h0, 0i.also set prior deem fit system. trust update referrers,initialize hrR , sR h1, 1i (to suggest client willing consider referral229fiWang, Hang, & SinghAlgorithm 1: generalUpdate: Abstract method revise trust placed targetR.input q, p, , c , hrR , sR i;rR c q;sR c p;r + (1 )r ;rRRRsR sR + (1 )sR ;, i;return hrRRreferrer) hr, si h0, 0i (to suggest client prior experienceprovider). perform trust update client done transactionsservice provider (i.e., r+s > 0). trust history setting, initialize hrR , sRh0.9, 0.1i (to suggest client trust past experience little confidence)hr, si h0, 0i (to suggest client prior experience provider).let us consider certainty density function based hr, si, reflectsactual trustworthiness S. Here, f (x) probability (density) quality serviceprovided x.xr (1 x)sf (x) = R 1(1)r (1 x)s dxx0density maximizes x = meaning likely provide service outcomequality . Consider probability density function based estimationhr , i, Rs estimate Ss trustworthiness reflects Rs assessmentquality provide. words, R expects provide service outcomelikely quality x = .4. Trust Update Based Average AccuracyBased background, study trust update problem systematically.analyze shortcomings series approaches, culminating approachyields characteristics desire.4.1 Linear Update ShortcomingsLinear common trust update method, serves baseline comparison. Lineardefines accuracy absolute difference quality estimated trustvalue hr , quality actual trust value hr, si. is,q = 1 | |(2)Using Equation 2, construct two trust update methods, Linear-WS Jsang,inserting q defined Linear general trust update model described Algorithm 1. Note that, Linear-WS Jsang use trust representations separatedefinitions certainty, thereby yielding different trust update methods. Linear-WS,shown Algorithm 2, adopts Wang Singhs notion certainty underlying trust (Definition 1), whereas Algorithm 3 depicts Jsang trust update method, certainty230fiA Probabilistic Approach Maintaining Trust Based Evidencec defined rr+s+s +2 (Jsang, 2001). Jsang (1998) defines certainty rr+s+s +1 ,yields little difference later work Jsang (2001) trust update. motivationintroducing Linear-WS help distinguish benefit trust update methodsbenefit using Wang Singhs static trust representation. show below, Linear-WS (which combines Wang Singhs static model heuristic update)performs worse proposed update methods, thereby establishing proposedmethods yield benefits beyond static model incorporate.shortcoming Linear consider certainty. Consider agentreports h0.1, 0.1i service provider little information providerreports h90, 10i later gathered additional information. Suppose serviceproviders quality service indeed 0.9. agent accorded hightrust, since reports correct trust value service provider high certaintyreports wrong trust value low certainty. words, updating trustagent, second referral given weight first one. However,Linear treats referrals thus ends wrong updated trust valueagent.Algorithm 2: Linear-WS: trust update method revise trust placed targetR.input hr, si, hr , i, , hrR , sR i;rr+srr +q 1 | |c c(r , )return generalUpdate(q, 1 q, , c , hrR , sR i);Algorithm 3: Jsang: trust update method revise trust placed agent R.input hr, si, hr , i, , hrR , sR i;r+1r+s+2r + 1r + + 2q 1 | |cr +r + + 2return generalUpdate(q, 1 q, , c , hrR , sR i);231fiWang, Hang, & Singh4.2 Update Based Max-Certainty ShortcomingsHang, Wang, Singh (2008) proposed Max-Certainty trust update method,applies Wang Singhs trust representation. Max-Certainty supports interestingfeatures, suffers shortcomings, present approach avoids. MaxCertainty follows general update model Section 3, defines q Algorithm 4.Algorithm 4: Max-Certainty: trust update method revise trust placedtarget R.input hr, si, hr , i, , hrR , sR i;rr+srr +qr (1 )sr (1 )sc c(r , )return generalUpdate(q, 1 q, , c , hrR , sR i);intuition behind Algorithm 4s definition q follows. Equation 1,)q = ff(() , since provide service likely qualitylikely quality . is, q measures ratio likelihoodsservice provided qualities , respectively. words, measureaccuracy q ratio probability computed estimate R respectprobability computed measurement made C itself. Figure 5 illustratescomputation.malicious target (such referrer) present setting one wrongover-confidentthat is, agent exaggerates amount evidence claimsbehind report service provider. Although Max-Certainty tells us likelytarget R trustworthy, sensitive malicious targets. Since combinedtrust naturally weighed amount evidence, trust report malicious targetmay falsely dominate truthful reports based apparently smaller amount evidence.Max-Certainty, takes C long time pinpoint malicious target. example, suppose actual trustworthiness h2, 1i R reports h5, 5i. AccordingMax-Certainty, hrR , sR = h0.37, 0.07i. R reported trust h1000, 1000i,hrR , SR would equal h0.79, 0.15i. words, Max-Certainty treats new evidenceconfirmatory. Instead, claim report h1000, 1000i bad exaggerates available evidence thus highly misleading effect. particular, mayend overriding many accurate reports (of lower certainty). Therefore, considerreport h1000, 1000i inaccurate, treat evidence disconfirmatory.observation leads following update approaches.update formula based Max-Certainty, let Rs trust hr, si. r +rlarge, formula highly sensitive, since PCDF maximized x = = r+s,232fiA Probabilistic Approach Maintaining Trust Based Evidence3.5.53cerp2rnbblen0.f81q2nen1.5reccernenf1prbbl0.6q0.500.10.20.30.40prb.50bl.60.70.80.91.0Figure 5: Illustration trust update method Max-Certainty hr, si = h8, 2ihr , = h6, 4i.decreases quickly x deviates (in words, close x = , magnitudeslope high). example, let (actual) trustworthiness h800, 200i.referrer reports h19, 6i, predicts quality 0.76. quite closeactual quality S, namely, 0.80. However, Max-Certainty yields hrR , sR = h0.06, 0.58i,indicates Max-Certainty treats poor estimation.4.3 Update Based Sensitivity Shortcomingsforegoing leads us another update method, term Sensitivity. intuition underlying Sensitivity identified Teacy et al. (2006). motivate Sensitivity,consider Rs estimate, probability quality equals p, givenl(p) = R 10pr (1 p)sxr (1 x)s dxClearly, l(p) maximizes , means R estimates quality serviceprovided likely . normalize l( ) 1,q =r (1 )sr (1 )s(3)measures likely Rs assessment would quality service provider .Figure 6 illustrates formulas using hr, si = h8, 2i hr , = h6, 4i. Returning previous example, hrR , sR = h0.01, 0.93i, means Sensitivityconsiders h1000, 1000i inaccurate reportas should.Although Sensitivity improves Max-Certainty, like Max-Certainty, remains susceptible excessively sensitive number transactions large. numerical233fiWang, Hang, & Singh32.5ccernen0.ernen0.8621qnecerneenfuncn1.5bn(6,4)nrec10.5q00.10.20.30.40prb.50bl.60.70.80.91.0Figure 6: Illustration trust update method based Sensitivity hr, si = h8, 2ihr , = h6, 4i. Thus = 0.8 = 0.6.example susceptibility Sensitivity presented Section 4.2. Let trustworthiness h800, 200i, whereas referrer reports h190, 60i. method,incorporates uncertainty, yields hrR , sR = h0.24, 0.55i. words, treats referral bad. However, 190/(190 + 60) = 0.76 quite close 800/(800 + 200) = 0.80,indicates ought treated good referralhence discrepancy.problem Sensitivity treats referral disconfirmed evidencesimply referrer confident even though referral accurate. Theorem 3Section 5 demonstrates problem, general setting.bottom-line Max-Certainty Sensitivity produce undesirable results.4.4 Average Accuracy Disregarding Uncertaintyforegoing discussion leads us penultimate step coming desiredapproach. final approach (detailed Section 4.5) consider averageaccuracy estimations. present variant simpler twodisregards uncertainty inherent belief regarding source S.Suppose idealization actual trustworthiness source equals h, 1, 0i, expressed belief-disbelief-uncertainty triple. case arises knowsure source provide quality service referral probability .Therefore, uncertainty 0, indicating ideal case.Figure 7 shows, suppose target reports trust value service providerhr , i. Let c = c(r , ) certainty based hr , i. PCDF hr , meanstarget estimates provider produce quality x (0, 1) certaintyf (x):f (x) = R 10xr (1 x)sxr (1 x)s dx234fiA Probabilistic Approach Maintaining Trust Based Evidenceproviders actual quality x = . square estimation error x(x )2 . multiply square error certainty f (x), integratex 0 1 obtain average square estimation error. squareroot integration yields average error. is, calculate errorestimation according following formula:vuR 1u xr (1 x)s (x )2 dxe = 0 R1r0 x (1 x) dx3certainty density2.52certainty density functionbased (6,4)1.510.500.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0probabilityFigure 7: Illustration average trust update method r = 6 = 4, = 0.8(dashed line). error e average length arrows.many ways compute average errors, including L1 L norms,on. use L2 norm simple mathematical properties. choiceunique common one (the variance) convenient manipulatemathematically.give alternative definition q based e, i.e., q = 1 e.PCDF corresponding estimation hrR , sR i, see q corresponds averageaccuracy estimation. updated estimate trustworthiness hrR , sR R basedq usual manner Algorithm 1.4.5 Average Accuracy Incorporating UncertaintyLet us consider complex variant method, uses qdefinition above, explicitly incorporates uncertainty inherent beliefregarding S. Treating trust placed belief function uncertainty corresponding hr, si evidence space, would like discount updates rR sRadditional factor certainty actual observations hr, si made C.235fiWang, Hang, & SinghAlgorithm 5: Average- : trust update method revise trust placed agent R.input hr, si, hr , i, , hrR , sR i;rr+sc c(r, s)q =1(r(r + 1)(s + 1)r + 1 2) ++s +2(r + + 2)2 (r + + 3)c c(r , )c = ccreturn generalUpdate(q, 1 q, , c , hrR , sR i);words, would begin definition q discount certaintydetermined hr, si. Algorithm 5 captures intuition.reason consider certainty certain actual qualityS, certain evaluate targets estimation either,discount update additional factor c. Returning previous example, lettrustworthiness h800, 200i, whereas target reports h19, 6i. method,incorporates uncertainty, yields hrR , sR = h0.53, 0.06i, indicatesreport good estimationas supposed since 19/(19 + 6) = 0.76,quite close 800/(800 + 200) = 0.8. Therefore, close , matter largetotal number transactions is, method considers targets estimationconfirmative. holds true general, Theorem 4 Section 5 shows.4.6 Understanding Trade Offsfollowing tables illustrate pros cons update method. compareaccuracy measurements q used Max-Certainty (Algorithm 4), Sensitivity (Equation 3),Average- (Algorithm 5).Table 1 summarizes various situations interest, especially Max-CertaintySensitivity cannot handle well. explained Section 4.3, r + large, MaxCertainty highly sensitive, thus treats good report bad. r + large,Sensitivity highly sensitive, also treats good report bad.Table 2 provides numerical examples corresponding situations specified Table 1.table, let actual quality service provider 0.50 quality indicatedreferral 0.55.4.7 Estimating Certaintyevaluate methods respect ability infer trackcertainty incoming trust reports. Figure 8 compares q values produced differenttrust update methods. -axis q, calculated different trust update methodsintroduced above. estimates quality fixed 0.55 r + , amount236fiA Probabilistic Approach Maintaining Trust Based EvidenceTable 1: Comparing effectiveness trust update methods conceptually.Caser+srsmallAccuracy+Max-CertaintySensitivityLinearAverage-smallgoodgoodfairgoodsmalllargegoodpoorgoodgoodlargesmallpoorgoodfairgoodlargelargepoorpoorgoodgoodTable 2: Trust update methods comparison via numerical examples.Casehr, sihr ,h1, 1iAccuracy (q)Max-CertaintySensitivityLinearAverage-h1.1, 0.9i0.990.990.950.78h1, 1ih220, 180i0.990.130.950.95h200, 200ih1.1, 0.9i0.130.990.950.78h200, 200ih220, 180i0.130.130.950.95evidence estimate, increases. left right plots show resulting qactual quality hr, si = h1, 1i, hr, si = h200, 200i, respectively. Linear always high,independent certainty report. Max-Certainty over-estimates q r +s lowunder-estimates q r + high, vary certainty. Averagesestimate q reflects certainty reports cases.4.8 Methods SummarizedFigure 9 illustrates trust update methods compare, including Jsang, LinearWS, Max-Certainty, Sensitivity, Average-. categorize methods respectaccuracy measurements underlying trust representation. Regardingaccuracy measurement technique, Jsang Linear-WS measure accuracy basedlinear approach. Max-Certainty, Sensitivity, Average- defines specificaccuracy measurement. approaches Jsang follow Wang Singhstrust representation.5. Theoretical Evaluation Accuracy Measurement Techniquessection evaluates trust update methods theoretical terms consolidatingimportant technical results. may skipped first reading. section seeksgive technical intuitions results.237fiWang, Hang, & Singh110.90.950.80.90.70.60.85qq0.50.80.40.750.7Average0.3MaxCertaintyLinearWS0.20.650AverageMaxCertaintyLinearWS0.14080120160200240280320360004004080120160200240280320360400r+sr+sFigure 8: Comparison trust update methods based accuracy measurements q.graphs use fixed referral expected quality = 0.55 vary amountreported evidence r + . actual quality values hr, si low (set h1, 1ileft graph) high (set h200, 200i right graph), respectively.Linear-WSMax-CertaintySensitivityAverage-AccuracyMeasurementLinearMax-CertaintySensitivityAverageTrustRepresentationJsangJsangWang & SinghGeneralUpdateFigure 9: Trust update methods specified terms trust representationaccuracy measurement methods.Figure 9 shows, trust update method three main components. accuracymeasurement technique main contribution paper, one evaluatetheoretically.5.1 Bounded Rangeexplained above, update q means estimate treated q good1 q bad transactions. range bounded merely serves sanity checkdefinitions. Theorem 1 establishes accuracy measurement definitionsconsider.238fiA Probabilistic Approach Maintaining Trust Based EvidenceDefinition 4 Let trust update method compute q based description. saytrust update method bounded if, inputs,0q1Theorem 1 four definitions accuracy q given Equation 2, Algorithm 4,Algorithm 5, Equation 3 satisfies boundedness.Proof : range trivially bounded Linear. Max-Certainty Sensitivityrmethods, show PCDF function, f () achieves maximum x = = r+s,(x)0 1. Average, first show |x | less 1,ff ()show rest integral 1.rR1 r20 xR (1x) (x) dx.Specifically, need show 0 e 1, e = 1q =1 r0x (1x) dxSince (x ) 1 0 x 1. Thus obtainR1xr (1x)s (x)2 dxR1xr (1x)s dxR 10 rx (1x)s dx= 1.R01 r0 x (1x) dxR 1 rx (1x)s dxSince R01 r=0 x (1x) dx01, obtain0 e 1.25.2 Monotonicityintroduce important property trust updates, term monotonicity.Monotonicity means fixed trust estimate , farther actual qualityservice provider quality predicted estimate larger resultingcorrection. Here, correction corresponds inversely q Algorithm 1. words,monotonicity means error greater, correction due trust update largerwell.Definition 5 Let trust update method compute q1 q2 (corresponding = 1= 2 , respectively) based description. define methodmonotonic 1 < 2 < < 2 < 1 , trust estimate(0, 1),q 1 < q2Theorem 2 establishes accuracy measurement definitions considersatisfy monotonicity.Theorem 2 four definitions accuracy q given Equation 2, Algorithm 4,Equation 3, Algorithm 5 satisfies monotonicity.Proof : Linear trivially seen monotonic. prove Max-CertaintySensitivity monotonic, need show PCDF function increasingrr) decreasing x ( r+s, 1). show showing derivativex (0, r+s239fiWang, Hang, & SinghrrPCDF function positive x (0, r+s) negative x ( r+s, 1).r+1prove Average monotonic, use Theorem 5 let c = r+s+2 .specifically, theorem equivalent showing q() increasing0 < < r r+s decreasing r r+s < < 1, q defined Equation 3.Definition 3, q() =r (1)s, = ( r r+s )r ( r s+s )s . Hence,r r1(1)s r (1)s 1r 1 (1)s 1 (r (1)s )r 1 (1)s 1 (r (r +s )).q () ===Thus q () > 0 0 < < r r+s q () < 0 r r+s < < 1.Hence q() increasing 0 < < r r+s decreasing r r+s < < 1.prove monotonicity Max-Certainty, equivalent show q() increasingrr0 < < r+sdecreasing r+s< < 1, q defined Algorithm 4.rest proof above.2Calculated quality estimate q0.5Average accuracy methodSensitivity method0.40.30.20.100.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0Estimated probabilityFigure 10: Monotonicity update methods illustrated: here, trust update methodcalculates quality estimate q given fixed trust estimate hr , = h2, 8i,[0, 1.0].Figure 10 shows Average method Sensitivity method satisfy property.Max-Certainty method Sensitivity method except uses r, insteadr , . Thus, figure Max-Certainty would Figure 10 provided user = 2 = 8.5.3 Sensitivity Problemsproperty sensitivity alludes problem trust update methods face.idea overly sensitive update method creates unjustifiably large updates.result, trust placed oscillate rapidly, leading near chaotic conditions.240fiA Probabilistic Approach Maintaining Trust Based EvidenceFollowing Figure 4, Definition 6 specifies means update method asymptotically sensitive. intuition behind Definition 6 amount evidence usedassess trustworthiness source goes up, causes potentially erratic updatesamount trust placed target R. Notice Definition 6 undesirableproperty.Definition 6 Let trust update method compute q based referral hr , actualexperience hr, si. assume 6= . define trust update methodasymptotically sensitive fixed, least one followingholds:limq=0r +slim q = 0r+sTheorem 3 establishes Max-Certainty Sensitivity satisfy asymptotic sensitivity.means methods susceptible sensitivity problems amountevidence judge target increases.Theorem 3 Algorithm 4 Equation 3 satisfy asymptotic sensitivity.Proof sketch: Max-Certainty method, let f (x) PCDF function. wantr, x 6= .show f () goes infinity f (x) goes zero, = r+sq=f ( )f ()goes infinity r + goes infinity 6= .1Calculated quality estimateCalculated quality estimate0.50.40.30.20.10.80.60.450100150Total number transactions: r+s200(a) r + goes 1 200, qualitycalculated Max-Certainty falls.Average Accuracy MethodSensitivity methodQuality calculated sensitivity method0.200Quality calculatedaverage accuracy method204060Total number referred transactions: r+s80(b) r + goes 1 200, quality calculated Sensitivity falls whereasquality calculated Average risesslightly.Figure 11: Evaluating update methods respect quality. graphs, = 0.6,= 0.5.241fiWang, Hang, & SinghFigure 11(a) shows Max-Certainty suffers asymptotic sensitivity totalnumber observations r+s becomes large. And, Figure 11(b) shows Sensitivity suffersasymptotic sensitivity total number transactions estimate becomes large.fixed, Average Sensitivity depend total numbertransactions r +s . Figure 11(b), quality calculated Sensitivity goes 1 0quality calculated Average goes 0.73 0.90. demonstratesSensitivity suffers asymptotic sensitivity since treats good estimate badone r + becomes large, whereas Average suffer problem.Definition 7 captures opposite intuition sensitivity accuracy measurement q converges difference observed reported probabilities. Theorem 4 shows Average, contrast Max-Certainty Sensitivity, susceptiblesensitivity thus robust methods.Definition 7 Let trust update method compute q based description.define method convergent fixed ,limr +sq = 1 | |Theorem 4 Following Figure 4, fixed, Average method convergent.Proof sketch: convergence Average follows naturally Theorem 5, givenbelow.5.4 Calculating Average Accuracyfollowing formula shows calculate Average. important featureformula closed form calculating updates. exact requirecomputing integrals, expensive compute numerically. Hence,computational respect too, method superior Max-Certainty Sensitivity.Theorem 5 Let q defined Algorithm 5.2r + 1(r + 1)(s + 1)q =1+r +s +2(r + + 2)2 (r + + 3)R1r!s!Proof sketch: need show 0 xr (1 x)s = (r+s+1)!. accomplish via integration parts. boundary terms zeros. detailsAppendix.summarize technical results, find methods consider satisfyproperty accuracy measure lying within range [0, 1]. Max-CertaintySensitivity satisfy undesirable property asymptotic sensitivity, whereas LinearAverage satisfy oppositedesirableproperty converging toward actual measureaccuracy. advantage Average Linear shows respect speedlearning, demonstrate simulation studies.6. Trust Update Scenariosdiscuss two use case scenarios apply trust update.242fiA Probabilistic Approach Maintaining Trust Based Evidence6.1 Trust Update ReferrersExisting trust models lack update methods agent update extent trustplaces referrer, based referrals referrer gives. general, trustworthinessreferrer best estimated based accurate referrals are.ReferrerClients trust ReferrerMR = !rR , sR "RReferrers referralMS = !r , "CompareCClientClients actual experiencesService Provider= !r, s"Figure 12: Illustration trust update referrers.accuracy determined comparing referrals observed trustworthinesssource, illustrated Figure 12. process mirrors exactly process describedFigure 4, target referrer.6.2 Trust CombinationReferrersClients trust ReferrerR1Referrers referralR2CClientR3Service ProviderClients actual experiencesFigure 13: Illustration trust combination.client C determined amount trust places service providerbased referrals referrers Ri , C consolidates trust estimates usingpropagation operators introduced Section 2.3. Figure 13 shows situation oneclient, three referrers, one service provider. C predicts trustworthiness serviceprovider based information received three referrers. C would makeprediction selecting service providertypically, obtained sufficientdirect experience S.C uses concatenation operator discount trust report receivedreferrer according Cs trust referrer.C uses aggregation operator combine discounted trust reports. combined trust report yields Cs estimated trust service provider.243fiWang, Hang, & Singh6.3 Trust Update Trust Historyaccommodate updating trust placed service provider, introduce ideatrust history. imagine ghost target reflecting clients previous leveltrust specific service provider. ghost target, essence, estimates outcomeobtained service provider. Based estimate (and others), client mayestimate trust provider. client evaluates ghost target parreal referrer.HistoryTrust HistoryMR = !rR , sR "RPast BehaviorMS = !r , "CompareCClientCurrent Behavior= !r, s"Service ProviderFigure 14: Illustration trust update trust history.Figure 14 illustrates scenario instantiation general model trustupdates, Section 3. essential idea client tries estimate muchtrust place past information provider. manner, avoid hardcoding discount factor weigh past information. Instead, trust placed historyserves dynamically computed discount factor tells us much weigh past.Algorithm 6 describes method, Average-, calculates discount factor dynamically trust history. Average- similar Average-. main differencetwo whereas Average- applies referrers setting, Average- appliestrust history setting (both settings introduced Section 3).Algorithm 6, first, compare current behavior hr , past behaviorhr, si determine consistent behavior provider is. current behavior hr , close past behavior hr, si, trust history increases; otherwise,decreases. closeness measured method averageAccuracy, defined Algorithm 5. trust placed history, hrR , sR i, reflects static behavior is.Thus, probability trust history used discount factor ,high new behavior consistent past low not. Here,initially set hrR , sR h0.9, 0.1i, i.e., client trusts past experience small amountconfidence. initially set hr, si h0, 0i, trust update clientdone transactions service provider.key point distinction approach trust placed history hrR , sRfixed discount factor; based much history matches subsequenttransactions. sources behavior changes lot cannot accurately predictedhistory, trust placed history becomes low, historical informationconsequently discounted greater extent. result, net past evidencebrought bear prediction goes addition evidence includingconflict would otherwise. Thus certainty resulting prediction lowernew information agrees past.244fiA Probabilistic Approach Maintaining Trust Based EvidenceAlgorithm 6: Average-: Yields discount factor based Cs prior experiencesS.input hr, si, hr , i, hrR , sR i;rr+sc c(r, s)c c(r , )vuR 1u xr (1 x)s (x )2 dxq 1 0 R 1r0 x (1 x) dxrRrR + cc (1 q)sR sR + cc qrR+rRRrT r + rsT +return hrT , sT i;7. Experimental Evaluationevaluate approach via simulations supplement theoretical analysis.consider following main hypotheses study.Hypothesis 1: Effectiveness Average trust history worse predictionexisting approaches variety possible behaviors service providers (Section 7.2,Section 7.3, Section 7.4, Section 7.5).Hypothesis 2: tuning Average trust history offer accuracy similartraditional approaches without requiring tuning parameters (Section 7.4Section 7.5).Hypothesis 3: Dynamism detection certainty computed Average trusthistory reflects dynamism service providers. (Section 7.4).divide simulations two parts. first part evaluates effectivenesstrust update method. Section 7.2 compares approach three modelspredicting behavior based estimated trustworthiness referrers. Section 7.3shows trustworthiness estimated approach identifies honest maliciousreferrers, yields accurate reports regarding service providers.second part simulation shows benefits using trust history. Section 7.4compares trust update without trust history predicting behavior different245fiWang, Hang, & Singhprofiles. Section 7.5 shows effectiveness trust history real dataset AmazonMarketplace.begin Section 7.1 introducing behavior profiles accuracy metricthroughout evaluation.7.1 Behavior Profiles Accuracy Metricsconduct simulation studies evaluate trust update method. end,introduce interesting behavior profiles providers capture variety situationsarise practice. profile simply means formal characterization behaviortype agent. use agent profiles evaluate effectiveness approachesdifferent kinds agents.Table 3: Behavior tracking different behavior profiles used Sections 7.2 7.4.ProfileExampleProbabilityAmazon ratingsPeriodicRestaurant(lunchdinner)Behavior Function Xt1.0 90%0.0 10%1.0 (t/2 mod 2) 10.0 otherwiseDampingScam artistRandomStock marketU (0, 1)Random WalkFlightpriceticketXt1 + U (1, 1)MomentumFlightpriceticketXt1 + U (1, 1) + [Xt1 Xt2 ]1.0 /20.0 otherwiseinclude following behavior profiles study. Table 3 summarizesprofiles Figure 15 shows resulting behaviors schematically. define profilesformally, introduce Xt , behavior function represent probability providinggood service timestep t. Here, U (1, 1) represents uniform distribution [1, 1].parameters real numbers 0 1. timestep t, calculateXt first, next determine quality service based Xt .Probability captures providers travel agency seller Amazon Marketplace. instance, travel agency might able fulfill passengers requestpleasure trip booking certain probability.Random emulates totally unpredictable service.246fiA Probabilistic Approach Maintaining Trust Based EvidenceQuality1Quality100123456789101234Timestep567891089108910Timestep(a) Probability(b) PeriodicQuality1Quality100123456789101234Timestep567Timestep(c) Damping(d) RandomQuality1Quality100123456789101Timestep234567Timestep(e) Random Walk(f) MomentumFigure 15: Behavior profiles shown schematically.Periodic describes service changes behavior regularly. example, restaurantmay employ experienced waiters dinner, novices lunch.Damping models agents turn bad building reputation.Random Walk generalizes providers whose current behavior depends highlyimmediately previous behavior. example, quality service providedhotel would depend upon recent investments infrastructure staff training;thus next quality service would show dependence previous qualityservice.Momentum similar Random Walk except current behavior depends highlytwo immediately previous steps.247fiWang, Hang, & SinghAmong profiles, Probability, Damping, Random Walk yield predictable behaviors others next outcome relates closely previous outcome.Conversely, Random, Periodic, Momentum less predictable.introduce average prediction error E measure effectiveness updatemethod. idea update method makes prediction timestepcompare prediction trustworthiness observed client.Definition 8 Let hrt , st hrt , st predicted observed behaviors timestep t.Define usual. Then, average prediction error E total timestepsequals:PT| |E = t=17.2 Predicting Referrers Different Behavior Profilesconduct simulation study demonstrate effectiveness trust update method.Table 4 shows, simulation includes study Average- (our approach fixeddiscount factor ) along three trust models: Max-Certainty, Linear-WS,Jsang.Table 4: Trust update methods compared Section 7.2.Update MethodDescriptionStatic ModelLinear-WS (Algorithm 2)Linear fixedWang SinghJsang (Algorithm 3)Linear fixedJsangMax-Certainty (Algorithm 4)Max-Certainty fixedWang SinghAverage- (Algorithm 5)Average fixedWang Singhexperiment, 100 timesteps, client conducts 50transactions service provider. concreteness, simulations, set hrR , sRhr, si h1, 1i h0, 0i study. initial value reflects intuitionclient might place little trust stranger (as referrer), knowledgeservice provider.first simulation compares Average- trust update method methods.simulation, one client C one service provider S. timestep, Cobtains referral referrer R S, performs 50 transactions S.Using various trust update methods, C updates estimate trustworthinessR based comparing referral R gave Cs actual experience. behaviorreferrer R defined using profiles. Note using different randomness,Random Walk Momentum generating behavior profile yieldssimilar results. show one example particular set profile parameters.Figure 16 shows average prediction error trust update methods discountfactors = 0.00, 0.01, . . . , 1.00 behavior profiles. example,predictable profiles Probability, Damping, Random Walk, Momentum, high248fiA Probabilistic Approach Maintaining Trust Based Evidence110.90.90.80.8AverageMaxCertaintyLinearWSJosang0.60.7Prediction errorPrediction error0.70.50.40.60.50.40.30.30.20.20.100AverageMaxCertaintyLinearWSJosang0.10.10.20.30.40.50.60.70.80.90010.10.2(a) Probability0.80.70.80.910.80.910.80.910.7Prediction errorPrediction error0.6AverageMaxCertaintyLinearWSJosang0.90.70.60.50.40.60.50.40.30.30.20.20.10.10.10.20.30.40.50.60.70.80.90010.10.2(c) Damping0.30.40.50.60.7(d) Random11AverageMaxCertaintyLinearWSJosang0.90.8AverageMaxCertaintyLinearWSJosang0.90.80.7Prediction error0.7Prediction error0.51AverageMaxCertaintyLinearWSJosang0.80.60.50.40.60.50.40.30.30.20.20.1000.4(b) Periodic10.9000.30.10.10.20.30.40.50.60.70.80.9001(e) Random Walk0.10.20.30.40.50.60.7(f) MomentumFigure 16: Prediction errors various discount factors. Although Average-dominate graphs, yields competitive results, whereas othersfail least cases.discount factor yields better predictions focuses recent results, even thoughsacrifices large amount evidence. Conversely, less predictable profilesPeriodic Random, difficult determine best discount factor,appears depend extraneous factors random seed chosen.249fiWang, Hang, & Singh110.90.90.80.80.70.7Trust referrerTrust referrerRecall Average one update methods considers certainty.However, deficiency Max-Certainty Linear overcome multiplying certaintyhrR , sR i. result, difference average prediction errors significant.Section 4.6 describes cases Max-Certainty fails predicate accurately.context Probability Random profiles, probability-certainty densitydistribution steep (indicating strong evidence), small difference basedobserved trustworthiness based referral yield significant punishmentMax-Certainty.highlight advantages Average-, create two new profiles: RumorHonest. Rumor referrer provides accurate reports first exaggerates evidencesecond half simulation. Suppose actual experience h4, 1i. exaggeratedreferral might be, example, h40, 10i. Honest referrer provides referrals whosestrength depends experience. accommodate situationbeginning may sufficient experience provider: Honest referrerwould provide neutral referrals low certainty.Figure 17 shows estimated trustworthiness, respectively, referrer followingRumor referrer following Honest profile. Rumor referrer provides fair referralsbeginning begins exaggerate later simulation. Honest referrerprovides fair referrals throughout: little certainty beginning generallygreater certainty later simulation. Rumor, Average- detects exaggerationlowers trust placed referrer accordingly. However, approachessensitive exaggeration. Honest, Average- punish referrereven though referral inaccurate beginning. referrer gathers enoughexperience provides good reports, trust placed built accordingly. MaxCertainty suffers case, because, discussed Section 4.6, punishes Honestreports turning false.0.60.50.40.30.100102030405060Timestep0.50.40.3AverageMaxCertaintyLinearWSJosang0.20.6AverageMaxCertaintyLinearWSJosang0.20.17080900100(a) Rumor0102030405060Timestep708090100(b) HonestFigure 17: Trust (with discount factor = 0.2) placed Rumor (exaggerates timestep50) Honest (has little knowledge timestep 50) profiles time.result shows approach Average- (a) punishes exaggeration (latersimulation) (b) stays neutral evidence low confidence (atbeginning simulation).250fiA Probabilistic Approach Maintaining Trust Based EvidenceSummaryforegoing shows Average effective evaluating trustworthiness referrersvarious behavior profiles. Average provides competitive predictions behaviorprofiles, whereas approaches either suffer profiles fail provideaccurate predictions. Hence, conclude supports Hypothesis 1: Effectiveness.7.3 Identifying Robust Malicious ReferrersReferrers might honest cooperative. simulation verifies evenreferrers maliciously provide trust reports indicating falsely exaggerated amount evidence, long client access good referrers, obtain good overallestimate trustworthiness service provider. experiment involves one clientagent, one service provider, two referrers: one good throughout one goodfirst 50 timesteps turns bad.0.95Actual trust service provider: 0.90.9Clients estimated trustservice providerTrust0.850.80.750.701020304050 60Time708090 100Figure 18: Estimated versus actual trustworthiness service provider based referralstwo referrers, one good throughout one compromised midway.Figure 18 shows case where, one good referrer counterbalance one malicious referrer, client predict trustworthiness service provider accurately.service provider offers good outcome probability 0.90 times.trustworthiness estimated service provider actual trustworthiness50th timestep, one referrers turns bad, result estimatedrops 0.71. estimate returns 0.88 five timestepsincreases slowly back 0.90.Figure 19 shows amount trust placed good corrupted referrers.trust placed good referrer begins 0.90 increases nearly 1.trust placed corrupted referrer begins 0.90 reaches 0.9850th timestep, drops quickly 0.15 ten timesteps. drop trustcorrupted referrer key return accuracy overall assessmentservice provider.251fiWang, Hang, & Singh1Trust placed good referrer0.8Trust0.60.40.2Trust placed damping referrer01020304050 60Time708090100Figure 19: Trust placed good referrer versus trust placed corrupted referrer.Summaryforegoing shows Average effective identifying malicious referrers. Besides,Average provides accurate predictions despite erroneous reports malicious referrers.Hence, conclude supports Hypothesis 1: Effectiveness.7.4 Predicting Agents Different Behavior Profiles using Trust Historyevaluate effectiveness trust history tracking different behaving agents.simulation, one client C one service provider S. 100 timesteps,C performs 50 transactions S. behavior service provider definedusing profiles Table 3. Using three different approaches, update estimatetrustworthiness predict future behavior based estimate. scenario,set hrR , sR (in Definition 8) h0.9, 0.1i study. initial value reflectsintuition whereas client would place fair amount trust past experience(as history), might place little trust stranger (as referrer Section 7.2).Table 5: Trust update methods compared Section 7.4.Update MethodDescriptionStatic ModelAmazondiscountWang SinghAverage- (Algorithm 5)Discount past fixedWang SinghAverage- (Algorithm 6)Discount past trust historyWang SinghTable 5 shows three approaches compared simulation. approachesdiscount past experience differently. Amazon, like marketplace web sites Amazon eBay, retains past experience; Average- decays past informationfixed discount factor ; and, Average- decays past information dynamicallycomputed trust history. example, suppose C h40, 10i h25, 25i first twotimesteps. Amazon estimates trustworthiness h40 + 25, 10 + 25i. Average- yields252fiA Probabilistic Approach Maintaining Trust Based Evidenceh40 + 25, 10 + 25i, fixed value [0, 1]. see Amazon special caseAverage- = 0. Average- uses adaptive discount factor based trusthistory. Figure 20 shows average prediction error methods discount factor= 0.00, 0.01, . . . , 1 behavior profiles defined Table 3.11AmazonAverageAverage0.80.80.70.70.60.50.40.60.50.40.30.30.20.20.10.1000.10.20.30.40.50.60.70.80.9AmazonAverageAverage0.9Prediction errorPrediction error0.90010.10.2(a) Probability10.80.70.7Prediction errorPrediction error0.60.70.80.910.60.50.40.60.50.40.30.30.20.20.10.10.10.20.30.40.50.60.70.80.9AmazonAverageAverage0.90010.10.2(c) Damping0.30.40.50.60.70.80.91(d) Random11AmazonAverageAverage0.90.80.80.70.70.60.50.40.60.50.40.30.30.20.20.10.10.10.20.30.40.50.60.70.80.9AmazonAverageAverage0.9Prediction errorPrediction error0.51AmazonAverageAverage0.8000.4(b) Periodic0.9000.3001(e) Random Walk0.10.20.30.40.50.60.70.80.91(f) MomentumFigure 20: Prediction error various discount factors (lower better). graph,Amazon Average- yield horizontal lines since take discountfactor input.253fiWang, Hang, & SinghProbability, Average- dominates Average- different values . RecallProbability performs poorly while. happens, Average- adaptsdynamically increasing discount factor. Subsequently, Average- adjusts discountfactor back lower value behavior becomes predictable. adjustmentyields better predictions fixed discount factor. Note Probability yields behavior quite similar real-life agents. example sellers Amazon Marketplace,discuss Section 7.5.observed above, profiles predictable others. example,Damping, Random Walk, Momentum, next outcome significantly depends uponprevious outcomes. cases, discounting old information using high valueyields predictions improved accuracy. However, although Average- high discountfactors provides highly accurate predictions, high discount factors yield low certaintyconcomitant tendency consider recent evidence resultsreduced evidence, shown Figure 21.profiles, especially Random Periodic, less predictable. Random,need overall information (high ) make best prediction. Periodic, higherlower values yield lower error values middle, although errorunacceptably high: error exceeds 0.50. Note Periodic changes quality backforth every two timesteps. Using = 1 yields perfect prediction Periodic staysworst error immediately following timestep (because alternationPeriodic). Conversely, using = 0 considers overall behavior: predicts 0.50time except initial several warmup timesteps. values yieldserror close 0.50. Periodic case behavior cannot predictedapproaches. However, Periodic realistic practical cases providerfollowed would gain much utilityAverage- detect unstable behaviorplaces low trust history thus yielding low certainty. client C reactaccordingly.Figure 21 compares certainty Amazon, Average-, Average- respectyields best trust prediction. Recall certainty reflects two facts: (1)amount evidence collected, (2) conflict evidence. first halfexperiment, conflict clients observations. Therefore, example,Damping, certainty Average- goes history discount decreases (andevidence increases). referrer turns bad middle experiment,certainty drops dramatically, partly conflict evidence partlybecause, using high discount factor discount old evidence significantly, Average essence reduces amount evidence considers. Conversely, certaintyAverage- fixed fixed discount factor, except conflict occursmiddle, certainty falls briefly. profiles Random Periodic,Average- yields lower certainty Average-, behavior unpredictable.low certainty trust prediction guide client C interact targetbehavior unpredictable.254fi110.90.90.80.8Certainty trust providerCertainty trust providerProbabilistic Approach Maintaining Trust Based Evidence0.70.60.50.40.3AmazonAverageAverage0.20.100102030405060Timestep0.70.60.50.40.3AmazonAverageAverage0.20.1708090010001020110.90.90.80.80.70.60.5AmazonAverageAverage0.40.330405060Timestep708090010010.90.80.8Certainty trust providerCertainty trust provider10.70.60.50.40.30AmazonAverageAverage0102030405060Timestep7080901008090100AmazonAverageAverage0102030405060Timestep(d) Random0.90.11000.3(c) Damping0.2900.40.120800.50.210700.60.105060Timestep0.70.2040(b) PeriodicCertainty trust providerCertainty trust provider(a) Probability300.70.60.50.40.3AmazonAverageAverage0.20.17080900100(e) Random Walk0102030405060Timestep70(f) MomentumFigure 21: Certainty trust prediction various discount approaches. graphshows certainty values Amazon, Average- (choosing yieldsaccurate prediction), Average- approaches.Summaryforegoing shows Average trust history effective tracking variousdynamic behaviors. Average trust history provides competitive predictions without255fiWang, Hang, & Singhprior knowledge behaviors tuning parameter. Besides, certaintyAverage trust history served indicator dynamism behavior.Hence, conclude supports Hypothesis 1: Effectiveness; Hypothesis 2:tuning; Hypothesis 3: Dynamism detection.7.5 Predicting Amazon Marketplace Data using Trust Historyorder evaluate effectiveness method predicting data real world,studied manually collected feedback profiles five sellers Amazon. sellersobtained 60, 107, 180, 235, 452 feedbacks, respectively. feedback integer1 5. treat feedback equaling quality service seller providedrated transaction. precisely, normalize rating {1, 2, 3, 4, 5}{0, 0.25, 0.5, 0.75, 1} treat normalized rating probability obtained tentransactions. example, rating 5 translated h10, 0i rating 2 translatedh2.5, 7.5i. timestep, current feedback predicted using feedbackspast. example, consider seller receives feedbacks 3, 1, 2, 4, respectively,first four timesteps. use feedbacks basis predicting nextfeedback. simple approach, supported Amazon, use averagefeedbacks predict fifth feedback. example, would predict feedback(3 + 1 + 2 + 4)/4 = 2.50. Suppose fifth timestep, seller actually receivesfeedback 3. Thus prediction error would 0.50. approach weighsfeedback given past equally.0.04.14H0.3rcunfcr9refr01.0vergeprecnerrrv0.38u0.370.360.35ngrunhr.rrreFrfxehrcunpprch,egheergeprecnerrrnuvrhencunre=w0.82,ergeerrr0.3539vev0.340.330.320.310.3000.10.20.30.h40r.c50unfc.60.70.80.91.0rFigure 22: Prediction error feedback Amazon seller. Trust history versus differenthistory discount factors.Alternatively, may discount history factor [0, 1]. example,= 0.90, 3 3 + 1 2 + 2 1 + 4 0 )/( 3 + 2 + + 1), equals1 0.93 + 2 0.92 + 3 0.9 + 4)/(0.93 + 0.92 + 0.9 + 1) = 2.56. scheme,case, prediction error would 0.44. use different discount factor256fiA Probabilistic Approach Maintaining Trust Based Evidencehistory, would general obtain different prediction error. experiment,normalize feedback real number [0, 1]. is, feedback 1, 2, 3, 4,5 corresponds trust value 0, 0.25, 0.50, 0.75, 1, respectively. compareprediction error using trust history prediction error using specifieddiscount factor. Figure 22 shows, using fixed discount history, discountfactor 0.82, average error prediction lowest, 0.35. general,error would higher unless happened correctly guess optimal discount factor.contrast, using trust history, average prediction error 0.34, turnslower using specific fixed discount factor (Hypothesis 1 ).important engineering challenge facing traditional approaches that, sincerequire fixed discount factor history parameter, need manually tunediscount factor application scenario. tuning limits applicabilitytraditional approaches substantially. contrast, method uses trust historyautomatically adapts agents changing behavior, thus require manualtuning (Hypothesis 2 ).Summaryforegoing shows Average trust history effective tracking ratingsAmazon without tuning parameters. Hence, conclude supportsHypothesis 1: Effectiveness Hypothesis 2: tuning.7.6 Summarizing Experimental Resultsresults twofold. First, Section 7.2, show Average provides competitiveaccuracy measurement referrals. deal various behavior effectively, detectexaggerated reports, forgive referrers trust information (Hypothesis 1 ). Section 7.3 demonstrates trust update method identifies malicious referrer providesaccurate report referrals containing false information (Hypothesis 1 ). Second,show effectiveness benefits trust history. Section 7.4 presents trusthistory tracks various artificial behavior competitively without parameter tuning (Hypotheses 1 2 ). show trust history preserve greater amount evidenceapproaches thereby provide additional information dynamismservice provider (Hypothesis 3 ). Section 7.5 shows works well practicalbehavior real datasets (Hypothesis 1 ).Although Average- accurate method circumstances (Hypothesis1 ), consider Average- best solution among methods. Average- requirestuning discount factor. two main advantages tunehand.Tuning discount factor difficult variety reasons. nontrivialdetermine providers behavior profile. difficult determine best valuespecific profile maintain value even agent changes profiledynamically. Using dynamically changing discount factor adaptkinds profiles.257fiWang, Hang, & Singhdynamically tuning discount factor, Average- provide dynamic certaintyinformation, reflects predictability referrers (Hypothesis 3 ).provider changes behavior frequently, certainty computed trust historybuild up. Knowing certainty may affect agents decision-makingstrategy. Even probability high, provider may trusted, due lowcertainty. Conversely, using discount factor cannot provide informationdiscounts history equally regardless conflict (Hypothesis 3 ).8. LiteratureTrust models widely studied (Sabater & Sierra, 2005; Jsang, Ismail, & Boyd,2007). focus well-known trust models also ones study trustupdate evaluate trustworthiness referrers based referrals.Beta Reputation System (BRS) (Jsang & Ismail, 2002) SPORAS (Zacharia &Maes, 2000) two trust models support idea discount factor. definefixed damping factor control much past experience discounted.similar , manually coded discount factor experiments. approach,discount factor automatically tuned based dynamic agent behavioris. Besides, BRS SPORAS fail provide trust update mechanism updateestimated trustworthiness agents based accuracy trust informationprovide.FIRE (Huynh et al., 2006) REGRET (Sabater & Sierra, 2002) two trust modelsconsider trust information individual social aspects. FIRE estimatestrust four sources: interactions, roles, witnesses, certified reputations. trustinformation REGRET includes individual social dimensions. However, FIREREGRET lack trust update mechanism. Although FIRE cope dynamism, experiments, Huynh et al. assume agent behavior involves minorchanges extremely low probability. trust update approach copes variouskinds dynamism. evaluate trust update introducing several dynamic behaviorprofiles. experiments show trust update provides accurate trust estimationvariety natural behavior profiles.Teacy et al. (2006) develop Travos, one trust models based beta distribution. Travos calculates trust based direct experience trust informationthird parties. Travos also provides mechanism measure accuracy referrals. Givenreferral hr , (i.e., beta distribution), Travos divides probability density severaldisjoint intervals. Suppose probability actual experience hr, si lies interval k.accuracy referral defined probability density ratio interval kintervals. Similar Sensitivity, accuracy measurement suffers numbertransactions large. Besides, number intervals requires human tuning. Teacy etal. suggest good trust model satisfy three requirements: providecomparable trust metric without personal experience; provide confidencemeasure; able assess reliability trust information sources discount information provided unreliable sources. approach satisfies threerequirements good trust model. Besides, approach makes assumptionagent behavior. However, Travos assumes agent behavior remains unchanged time.258fiA Probabilistic Approach Maintaining Trust Based EvidenceTeacy et al. agree time-based behavioral strategy necessary agents dealdynamic behavior. using automatically adjusted discount factor, approachprovides time-based strategy dealing variety dynamic behavior profiles.Fullam Barber (2007) study choose trust direct experience(experience-based) referrals (reputation-based). adopt reinforcement learning learn parameter controls aggregate information experience-basedreputation-based trust. Based reward client gains transactions,Fullam Barber dynamically update weights reputation providers (referrers)linear manner. Wang Vassileva (2003) present Bayesian network-based trustreputation model peer-to-peer networks. model also treats trust update linearmanner. predefine fixed discount factor discount past information. approachupdates trust based probability theory. show approach performs betterlinear-based trust update approach theoretically experimentally.Ries Heinemann (2008) propose CertainTrust, similar Jsangs approach.define trust terms numbers positive negative experiences.certainty reflect conflict evidence, reflects amount evidence.Trust propagated using two operators: consensus (our aggregation) discounting (ourconcatenation). Context dependence supported predefining maximum amountexpected evidence, trivial. Ries Heinemann update trust two ways.update trust feedback f (a scalar 1 1), increment numberpositive experiences (1 + f )/2 increment number negative experiences(1 f )/2. alternative update trust placed agent based accuracyrecommendations provides. accuracy recommendations definedtendency actual behavior. Ries Heinemann adopt aging factor analogousdiscount factor. aging factor normalizes trust values exceed predefinedmaximum number experiences. aging factor defined usednormalization. shown Section 7, using fixed aging factors poorly deals variouskinds behavior profiles parameters require human tuning. contrast,approach track dynamic behavior well adjust discount factor baseddynamic agents are.Khosravifar, Gomrokchi, Bentahar (2009) design maintenance-based trust model.define timely relevance factor discount past experience updating trust.timely relevance factor reflects time difference current timetime last update. amount discounted information determined domaindependent variable , similar discount factor discussed paper.high, past experience forgotten faster. low, trust values tendconsider overall experience. However, Khosravifar et al.s timely relevance factor requiresmanual tuning, also common limitation trust update methodsdiscount factor. discount factor Average- requires manual tuning.Poyraz (Sensoy, Zhang, Yolum, & Cohen, 2009) trust-based service selection approach. Poyraz calculates estimated trustworthiness web services baseddirect experience referrals. Poyraz filters referrals provided untrustworthy advisors (i.e., referrers). assesses trustworthiness advisors based private creditpublic credit. private credit evaluated comparing consumers actual experience referral. comparison produces either satisfactory unsatisfactory259fiWang, Hang, & Singhassessment based consumers preferences. consumer lacks experience,public credit calculated comparing referral advisors referrals.referral deviates majority, advisor considered untrustworthy. Poyraz alsoprovides time window discard old trust information. approach compares actualexperience referrals based probability density rather consumers preferences.discount old trust information using discount factor. Instead manually adjustsize time window, discount factor automatically tuned based dynamicagent behavior is.Paradesi et al. (2009) incorporate trust based certainty work web servicecomposition. Like approach, definition trust certainty based WangSinghs (2007) approach. trust framework, Wisp, Paradesi et al. study fourtypes frequently encountered web service flows composition. provide operatorscalculate trust certainty composed web service case. Paradesi et al.smethod update trust intuitive based Wang Singh Jsangs approach:simply adds number positive number negative transactions separately.Importantly, consider history discount effect aging information,here. manner, Paradesi et al.s work complements proposed approach,could refined adopt sophisticated definitions trust update.Mistry, Gursel, Sen (2009) estimate reputation scores sensor nodes based measurement accuracy sensor networks. framework, parent node receives reportschildren nodes. Based aggregated (average) report, parent evaluatestrustworthiness children. parent compares aggregated report sensed datachild, calculates error based Wilcoxon Signed Rank Test(Wilcoxon, 1945). reputation child reflects new evidence (the error) basedtwo update schemes, -reputation (Jsang & Ismail, 2002) Q-learning (Watkins &Dayan, 1992). -reputation Q-learning schemes use fixed parameter (discountfactor -reputation learning rate Q-learning) exponentially discountpast evidence, similar general update (Algorithm 1). update schemesrequire manual tuning thus lack ability dealing dynamism.Vogiatzis, MacGillivray, Chli (2010) build trust framework Hidden MarkovModels. apply probabilistic model estimate quality service providervarying behavior. important differences approachours. Vogiatzis et al. assume changes behavior service provider slowlyvarying described Wiener process quality sequence. Wiener processanalogous Brownian motion supports properties well-motivatedtalking service providers. example, requires behavior serviceprovider mean 0 deviation proportional time (that is, offerquality average beginning). model makes senseBrownian motion apply agents may vary quality service dueenvironmental effects well investments infrastructure, motivated above. Further,Vogiatzis et al. make additional unjustified assumptions opinionshonest provider normal distribution mean true quality opinionsdishonest provider uniform distribution. Thus, approach modelsagents randomly decision making, apply agents deliberately260fiA Probabilistic Approach Maintaining Trust Based Evidenceprovide extremely high extremely low referrals. Overall, model Vogiatzis et al.limited practical applicability connection services agents.Vogiatzis et al. (2010) evaluate approach respect two types behaviors:static damping. treat dynamism extensively defining six dynamic behaviorprofiles show approach performs profiles. However, definitionreputation target (referrer) satisfies required mathematical propertiesrigorous. use heuristics update trust referrals. justified heuristicsproving models satisfy important mathematical properties, example,farther referrals believed actual quality service provider, higherupdate (q Algorithm 1) trust placed referrer. model computationally efficient. excessive need computation big shortcoming Vogiatziset al.s traditional approaches. example, order estimate qualityservice provider varying behavior, based 100 transactions, Vogiatzis et al.sapproach would need calculate multiple integrals dimension 100. efficiencywould suffer calculating honesty multiple opinion providers.Hazard Singh (2010) identify axiomatize common intuitions trustviewed perspective incentives agents. relate trustworthiness agent discounts future payoffs: trustworthy agentslonger time horizon, intuition also shared Smith desJardins (2009).approaches complementary deal agents strategicallyalter behavior whereas concern agents fixed type, whose provided quality service attempt estimate. Also, incentives perspective, JurcaFaltings (2007) study mechanisms ensure agents offer truthful feedback others.approach deals incorporate new evidence maintaining trust rating.approach applies settings one sanction false reporters thus promotegood behavior.9. Conclusions Directionspaper proposes approach perform trust updates. makes following contributions. One, problem updating trust placed referrers continuing basis,develops mathematically well-justified probabilistic approach performing updates.Importantly, approach works top conceptually simple representation trustreflects common intuitions trust evidence. Further, proposed approachalthough cast heuristic calculating trust updates evaluated (alongcompeting heuristics) mathematical grounds properties monotonicitysensitivity. Two, paper adapts referrals approach updating trust providermodeling trust assessments referrals history prior interactions. Three,paper shows proposed approach yields performance compares wellexisting approaches without requiring hand tuning parameters common previousapproaches.investigations opened interesting natural directions future study.First, obvious theme experimental evaluation. would instructiveconsider additional types agents, instance, discriminative agents. Second, promisingline inquiry relating decision-making strategies agents compare261fiWang, Hang, & Singhtrust estimates service selection. would interesting examine discountingpast, showed above, relates discounting valuations future. Third, certainsettings, especially widespread sharing information, updating trust estimatessignificant dynamical effects. Hazard (2010) studied dynamical propertiesvarious mechanisms without explicitly considering referrals. instructivecombine approach his.Fourth, current definition accommodate multivalued eventstell us referral overestimates underestimates quality service provider.Multivalued events useful practical cases. Further, underestimate mightdesirable overestimatein former case, get pleasant surprise,although always ideal would miss selecting good providersunderestimation. begun address suitable representation trust.However, would nontrivial provide appropriate updating methods.Acknowledgmentsthank Chris Hazard Scott Gerard helpful comments. Chris provided datasetuse study. work partially supported U.S. Army Research Office (ARO) grant W911NF-08-1-0105 managed NCSU Secure Open SystemsInitiative (SOSI) partially sponsored Army Research Laboratory Network Sciences Collaborative Technology Alliance (NS-CTA) Cooperative AgreementNumber W911NF-09-2-0053.Appendix A. Proofs TheoremsLemma 6Z1rxr (1 x)s dx =01r+s+1r+s+1ii=1Proof:integrationparts.RR 1 r usedx = 1 xr d( 1 (1 x)s+1 )x(1x)00R 1 s+1xr (1x)s+1 1r= s+1 |0 + s+1 0 xr1 (1 x)s+1 dxR 1 r1r= s+1(1 x)s+1 dx0 x=R1r(r1)1r+s dx= (r+s)(r+s1)(s+1)0 (1 x)rQ1= r+s+1r+s+1i .2i=1Lemma 7 Given r above,vu ruYrlim=rr + r + 1(1 + )+1i=1r positive integer.262fiA Probabilistic Approach Maintaining Trust Based EvidenceProof: lemma used next lemma, show right side equationapproaches constant, equation duplicated roots, two rootsequation approach duplicated root.rQlimr 1r lnr+r+1ii=1=limr 1rln(=1r+r+1i )i=1 i=1rrQQ= limr 1r ln(=rrQQ1r+i )i=1 i=1i=rPlimr 1rln r+ii=1i=rPlimr 1rln +rri=1R1x0 ln +x dxln (1+)+1==Therefore,limrrrQi=1r+r+1iLemma 8 Let =r=.(1+)+12fixed. Let A(r) B(r) two values x satisfyxr (1 x)r=cR1r (1 x)rx0c > 0.lim A(r) = lim B(r) =rr(4)11+(5)r positive integer.Proof: idea show A(r) B(r) two roots equation g(x) = (r).limr (r) = equation g(x) = duplicated roots ,limr A(r) = limr B(r) =A(r) B(r)two roots equationqR1x(1 x) = r c 0 xr (1 x)r dxsince qR1limr r c 0 xr (1 x)r dxrQ1= limr r c r+r+1r+r+1i (by Lemma 6)i=1= (1+)+1 (by Lemma 7)11(1 1+)= 1+since x(1 x) achievesmaximum x =equation11x(1 x) = 1+(1 1+)Therefore,limr A(r) = limr B(r) =11+ .11+ ,x =11+root2263fiWang, Hang, & SinghLemma 9 Let =rr+s= r + s. Let fixed c 6= .lim Rlim Rct (1 c)(1)t=0xt (1 x)(1)t dx(6)(1 )(1)t=xt (1 x)(1)t dx(7)(1)t(1x)Proof: Let f (x) = R xxt (1x)(1)t dxProof Equation 6:Without losing generality, assume 0 < c < .> 0, let A(t) B(t) defined Equation 4 c = . AccordingLemma 8, > 0 c < A(t) < > . Since f (c) < f (A(t)) = ,f (c) < . Thus > 0, > 0,> , proves Equation 6.Proof Equation 7:(1)tR c (1c)xt (1x)(1)t dx<N > 0, let A(t) B(t) defined Equation 4 c = 0.50. Sincef (x) < f (A(t)) = 0.50 x < A(t) f (x) < f (B(t)) = 0.50 x > B(t).R A(t)R1R1f (x)dx + B(t) f (x)dx < 0 0.50dx = 0.50.0R1R A(t)R B(t)R1Thus A(t) f (x)dx = 0 f (x)dx 0 f (x)dx B(t) f (x)dxR1R A(t)1 0 f (x)dx B(t) f (x)dx > 0.50 Since f (x) f () x (A(t), B(t)).Thus obtain (B(t) A(t))f () > 0.501According Lemma 8, > 0 B(t) A(t) < 2N> .Thus f () > 0.50/(B(t) A(t)) > N > .Therefore, N > 0, > 0 f () > N > , provesEquation 7.2Proof Theorem3r (1)sf ()q = r (1=)f ( )Lemma 9, limt f () = 0 limt f ( ) = ,limt q = 0.case Sensitivity above.Proof Theorem 4 Let = r + . Theorem 5, equivalent prover + 1 2(r + 1)(s + 1)lim () += | |r +s +2(r + + 2)2 (r + + 3)q(r +1)(s +1)2limt ( r r+s+1+2 ) + (r +s +2)2 (r +s +3)q)+1)+1)2 + (t +1)(t(1= limt ( tt+2(t+2)2 (t+3)2= | |+1= limtsince limt tt+2Proof Theorem 5(t +1)(t(1 )+1)(t+2)2 (t+3)264=02fiA Probabilistic Approach Maintaining Trust Based Evidencelemma 6,R1xr (1 x)s (x )2 dxR1= 0 xr (1 x)s (x2 2x + 2 )dxR1= 0 xr +2 (1 x)s 2xr +1 (1 x)s + 2 xr (1 x)s dx0=(r +2)!s !(r +s +3)!rRq =1=1=1=12qq+1)!s !r !s !22 (r(r +s+2)! + (r +s +1)!10xr (1x)s (x)2 dxR1r0 x (1x) dx(r +1)!s !(r +2)!s !r !s !2 (r +s +2)! +2 (r +s+1)!(r +s +3)!r !s !(r +s +1)!(r +1)(r +2)(r +s +2)(r +s +3)(r +1)(s +1)(r +s +2)2 (r +s +3)2 2 r r+s+1+2 +(r +12r +s +2 )+ReferencesBarber, K. S., & Kim, J. (2001). Belief revision process based trust: Agents evaluatingreputation information sources. Falcone, R., Singh, M. P., & Tan, Y.-H. (Eds.),Trust Cyber-Societies, Vol. 2246 LNAI, pp. 7382, Berlin. Springer.Casella, G., & Berger, R. L. (1990). Statistical Inference. Duxbury Press, Pacific Grove,CA.Fullam, K., & Barber, K. S. (2007). Dynamically learning sources trust information:experience vs. reputation. Proceedings 6th International Conference Autonomous Agents Multiagent Systems (AAMAS), pp. 10621069, Honolulu, HI,USA. IFAAMAS.Gomez, M., Carbo, J., & Earle, C. B. (2007). Honesty trust revisited: advantagesneutral others cognitive models. Autonomous Agents Multi-AgentSystems, 15 (3), 313335.Hang, C.-W., Wang, Y., & Singh, M. P. (2008). adaptive probabilistic trust modelevaluation. Proceedings 7th International Conference AutonomousAgents MultiAgent Systems (AAMAS), pp. 14851488, Estoril, Portugal. IFAAMAS. Short paper.Harbers, M., Verbrugge, R., Sierra, C., & Debenham, J. (2007). examinationinformation-based approach trust. MALLOW Workshop Coordination, Organization, Institutions Norms agent systems (COIN), pp. 101112, Durham,UK. Springer-Verlag.Hazard, C. J. (2010). Trust Reputation Multiagent Systems: Strategies Dynamics Reference Electronic Commerce. Ph.D. thesis, Department ComputerScience, North Carolina State University.265fiWang, Hang, & SinghHazard, C. J., & Singh, M. P. (2010). Intertemporal discount factors measuretrustworthiness electronic commerce. IEEE Transactions Knowledge DataEngineering. press.Huynh, T. D., Jennings, N. R., & Shadbolt, N. R. (2006). integrated trust reputationmodel open multi-agent systems. Autonomous Agents Multi-Agent Systems,13 (2), 119154.Jsang, A. (1998). subjective metric authentication. Quisquater, J.-J., Deswarte,Y., Meadows, C., & Gollmann, D. (Eds.), Proceedings 5th European SymposiumResearch Computer Security (ESORICS), Lecture Notes Computer Science,pp. 329344, Louvain-la-Neuve, Belgium. Springer.Jsang, A. (2001). logic uncertain probabilities. International Journal Uncertainty,Fuzziness Knowledge-Based Systems (IJUFKS), 9 (3), 279311.Jsang, A., & Ismail, R. (2002). Beta reputation system. Proceedings 15thBled Electronic Commerce Conference, pp. 324337, Bled, Slovenia.Jsang, A., Ismail, R., & Boyd, C. (2007). survey trust reputation systemsonline service provision. Decision Support Systems, 43 (2), 618644.Jurca, R., & Faltings, B. (2007). Obtaining reliable feedback sanctioning reputationmechanisms. Journal Artificial Intelligence Research (JAIR), 29, 391419.Khosravifar, B., Gomrokchi, M., & Bentahar, J. (2009). Maintenance-based trust multiagent systems. Sierra, C., Castelfranchi, C., Decker, K. S., & Sichman, J. S. (Eds.),Proceedings 8th International Conference Autonomous Agents Multiagent Systems (AAMAS), Vol. 2, pp. 10171024, Budapest, Hungary. IFAAMAS.Mistry, O., Gursel, A., & Sen, S. (2009). Comparing trust mechanisms monitoringaggregator nodes sensor networks. Sierra, C., Castelfranchi, C., Decker, K. S., &Sichman, J. S. (Eds.), Proceedings 8th International Conference AutonomousAgents Multiagent Systems (AAMAS), Vol. 2, pp. 985992, Budapest, Hungary.IFAAMAS.Paradesi, S., Doshi, P., & Swaika, S. (2009). Integrating behavioral trust web service compositions. Proceedings 7th IEEE International Conference Web Services(ICWS), pp. 453460, Los Angeles, CA, USA. IEEE Computer Society.Procaccia, A. D., Bachrach, Y., & Rosenschein, J. S. (2007). Gossip-based aggregationtrust decentralized reputation systems. Veloso, M. M. (Ed.), Proceedings20th International Joint Conference Artificial Intelligence (IJCAI), pp. 14701475,Hyderabad, India. IJCAI.Ries, S., & Heinemann, A. (2008). Analyzing robustness CertainTrust. Proceedings2nd Joint iTrust PST Conference Privacy, Trust ManagementSecurity, IFIP International Federation Information Processing, pp. 5167, Boston,MA, USA. Springer.Sabater, J., & Sierra, C. (2002). Reputation social network analysis multi-agentsystems. Proceedings 1st International Joint Conference AutonomousAgents Multiagent Systems (AAMAS), pp. 475482, Bologna, Italy. ACM Press.266fiA Probabilistic Approach Maintaining Trust Based EvidenceSabater, J., & Sierra, C. (2005). Review computational trust reputation models.Artificial Intelligence Review, 24 (1), 3360.Sensoy, M., Zhang, J., Yolum, P., & Cohen, R. (2009). Poyraz: Context-aware serviceselection deception. Computational Intelligence, 25 (4), 335366.Smith, M. J., & desJardins, M. (2009). Learning trust competence commitmentagents. Autonomous Agents Multi-Agent Systems, 18 (1), 3682.Teacy, W. T. L., Patel, J., Jennings, N. R., & Luck, M. (2006). TRAVOS: Trustreputation context inaccurate information sources. Autonomous AgentsMulti-Agent Systems, 12 (2), 183198.Vogiatzis, G., MacGillivray, I., & Chli, M. (2010). probabilistic model trustreputation. van der Hoek, W., Kaminka, G. A., Lesperance, Y., Luck, M., & Sen,S. (Eds.), Proceedings 9th International Conference Autonomous AgentsMultiagent Systems (AAMAS), Vol. 1, pp. 225232, Toronto, Canada. IFAAMAS.Wang, Y., & Vassileva, J. (2003). Trust reputation model peer-to-peer networks.Shahmehri, N., Graham, R. L., & Caronni, G. (Eds.), Proceedings 3rd International Conference Peer-to-Peer Computing (P2P), pp. 150157, Linkoping,Sweden. IEEE Computer Society.Wang, Y., & Singh, M. P. (2006). Trust representation aggregation distributedagent system. Proceedings 21st National Conference Artificial Intelligence(AAAI), pp. 14251430, Boston, MA, USA. AAAI Press.Wang, Y., & Singh, M. P. (2007). Formal trust model multiagent systems. Veloso,M. M. (Ed.), Proceedings 20th International Joint Conference ArtificialIntelligence (IJCAI), pp. 15511556, Hyderabad, India. IJCAI.Wang, Y., & Singh, M. P. (2010). Evidence-based trust: mathematical model gearedmultiagent systems. ACM Transactions Autonomous Adaptive Systems(TAAS), 5 (4), 14:114:28.Watkins, C., & Dayan, P. (1992). Q-learning. Machine Learning, 8 (3), 279292.Wilcoxon, F. (1945). Individual comparisons ranking methods. Biometrics Bulletin,1 (6), 8083.Yu, B., & Singh, M. P. (2002). Distributed reputation management electronic commerce.Computational Intelligence, 18 (4), 535549.Zacharia, G., & Maes, P. (2000). Trust management reputation mechanisms. Applied Artificial Intelligence, 14 (9), 881907.267fiJournal Artificial Intelligence Research 40 (2011) 469521Submitted 06/10; published 02/11Narrowing Modeling Gap:Cluster-Ranking Approach Coreference ResolutionAltaf RahmanVincent Ngaltaf@hlt.utdallas.eduvince@hlt.utdallas.eduHuman Language Technology Research InstituteUniversity Texas Dallas800 West Campbell Road; Mail Station EC31Richardson, TX 75080-3021 U.S.A.AbstractTraditional learning-based coreference resolvers operate training mention-pairmodel determining whether two mentions coreferent not. Though conceptuallysimple easy understand, mention-pair model linguistically rather unappealinglags far behind heuristic-based coreference models proposed pre-statisticalNLP era terms sophistication. Two independent lines recent research attempted improve mention-pair model, one acquiring mention-ranking modelrank preceding mentions given anaphor, training entity-mentionmodel determine whether preceding cluster coreferent given mention.propose cluster-ranking approach coreference resolution, combines strengthsmention-ranking model entity-mention model, therefore theoreticallyappealing models. addition, seek improve cluster rankersvia two extensions: (1) lexicalization (2) incorporating knowledge anaphoricityjointly modeling anaphoricity determination coreference resolution. Experimental results ACE data sets demonstrate superior performance cluster rankerscompeting approaches well effectiveness two extensions.1. IntroductionNoun phrase (NP) coreference resolution task identifying NPs (or mentionsACE terminology1 ) text dialogue refer real-world entity concept.computational perspective, coreference clustering task, goal partitioningset mentions coreference clusters cluster containsmentions co-referring. mathematical perspective, coreference relationequivalence relation defined pair mentions, satisfies reflexivity, symmetry,transitivity. Following previous work coreference resolution, use termanaphoric describe mention part coreference chain headchain. Given anaphoric mention mk , antecedent mk mention coreferentmk precedes associated text, set candidate antecedents mkconsists mentions precede mk .21. precisely, mention instance reference entity real world. article,treat terms mention noun phrase synonymous use interchangeably.2. Note definitions somewhat overloaded. Linguistically, anaphor noun phrasedepends antecedent semantic interpretation. Hence, Barack Obama anaphoricdefinition formal definition.c2011AI Access Foundation. rights reserved.fiRahman & Ngresearch focus computational coreference resolution exhibited gradual shiftheuristic-based approaches machine learning approaches past decade. shiftattributed part advent statistical natural language processing (NLP)era, part public availability coreference-annotated corpora producedresult MUC-6 MUC-7 conferences series ACE evaluations. Oneinfluential machine learning approaches coreference resolution classificationbased approach, coreference recast binary classification task (e.g., Aone &Bennett, 1995; McCarthy & Lehnert, 1995). Specifically, classifier trainedcoreference-annotated data used determine whether pair mentions co-referringnot. However, pairwise classifications produced classifier (which commonly known mention-pair model) may satisfy transitivity property inherentcoreference relation, since possible model classify (A,B) coreferent,(B,C) coreferent, (A,C) coreferent. result, separate clustering mechanism needed coordinate possibly contradictory pairwise classification decisionsconstruct partition given mentions.mention-pair model significantly influenced learning-based coreference researchpast fifteen years. fact, many recently published coreference papersstill based classical learning-based coreference model (e.g., Bengtson & Roth, 2008;Stoyanov, Gilbert, Cardie, & Riloff, 2009). Despite popularity, model leasttwo major weaknesses. First, since candidate antecedent mention resolved(henceforth active mention) considered independently others, modeldetermines good candidate antecedent relative active mention,good candidate antecedent relative candidates. words, failsanswer critical question candidate antecedent probable. Second,limitations expressiveness: information extracted two mentionsalone may sufficient making informed coreference decision, especiallycandidate antecedent pronoun (which semantically empty) mention lacksdescriptive information gender (e.g., Clinton).Recently, coreference researchers investigated alternative models coreferenceaim address aforementioned weaknesses mention-pair model. addressfirst weakness, researchers proposed mention-ranking model. model determines candidate antecedent probable given active mention imposingranking candidate antecedents (e.g., Denis & Baldridge, 2007b, 2008; Iida, Inui,& Matsumoto, 2009). Ranking arguably natural formulation coreference resolution classification, ranker allows candidate antecedents consideredsimultaneously therefore directly captures competition among them. Another desirable consequence exists natural resolution strategy ranking approach:mention resolved candidate antecedent highest rank. contrastsclassification-based approaches, many clustering algorithms employedco-ordinate pairwise coreference decisions (because unclear one best).address second weakness, researchers proposed entity-mention coreferencemodel (e.g., Luo, Ittycheriah, Jing, Kambhatla, & Roukos, 2004; Yang, Su, Zhou, & Tan,2004; Yang, Su, Lang, Tan, & Li, 2008). Unlike mention-pair model, entity-mentionmodel trained determine whether active mention belongs preceding, possiblypartially-formed, coreference cluster. Hence, employ cluster-level features (i.e., fea470fiA Cluster-Ranking Approach Coreference Resolutiontures defined subset mentions preceding cluster), makesexpressive mention-pair model.entity-mention model mention-ranking model conceptually simpleextensions mention-pair model, born nearly ten years mention-pairmodel proposed, particular, contributions under-estimated:paved new way thinking supervised modeling coreference representssignificant departure mention-pair counterpart, many yearslearning-based coreference model NLP researchers. proposal two modelsfacilitated part advances statistical modeling natural languages: statisticalNLP models evolved capturing local information global information,employing classification-based models ranking-based models. contextcoreference resolution, entity-mention model enables us compute features basedvariable number mentions, mention-ranking model enables us rank variablenumber candidate antecedents. Nevertheless, neither models addressesweaknesses mention-pair model satisfactorily: mention-ranking model allowscandidate antecedents ranked compared simultaneously, enableuse cluster-level features; hand, entity-mention model employcluster-level features, allow candidates considered simultaneously.Motivated part observation, propose learning-based approach coreference resolution theoretically appealing mention-ranking modelentity-mention model: cluster-ranking approach. Specifically, recast coreference problem determining set preceding coreference clustersbest link active mention using learned cluster-ranking model. essence,cluster-ranking model combines strengths mention-ranking model entitymention model, addresses weaknesses associated mention-pair model.cluster-ranking model appears conceptually simple natural extension entity-mention model mention-ranking model, believesimplicity stems primarily choice presentation concepts easiestreader understand. particular, note mental processes involveddesign cluster-ranking model means simple way modelpresented: requires analysis strengths weaknesses existingapproaches learning-based coreference resolution connection them,also formulation view entity-mention model mention-rankingmodel addressing two complementary weaknesses mention-pair model. believesignificance cluster-ranking model lies bridging two rather independentlines learning-based coreference research going past years,one involving entity-mention model mention-ranking model.addition, seek improve cluster-ranking model two sources linguistic knowledge. First, propose exploit knowledge anaphoricity (i.e., knowledgewhether mention anaphoric not). Anaphoricity determination means newproblem, neither use anaphoricity information improve coreference resolution. innovation lies way learn knowledge anaphoricity. Specifically,previous work typically adopted pipeline coreference architecture,anaphoricity determination performed prior coreference resolution resultinginformation used prevent coreference system resolving mentions de471fiRahman & Ngtermined non-anaphoric (for overview, see work Poesio, Uryupina, Vieira,Alexandrov-Kabadjov, & Goulart, 2004), propose model jointly learning anaphoricity determination coreference resolution. Note major weakness pipelinearchitecture lies fact errors anaphoricity determination could propagatedcoreference resolver, possibly leading deterioration coreference performance(Ng & Cardie, 2002a). joint model potential solution error-propagationproblem.Second, examine kind linguistic features exploited majorityexisting supervised coreference resolvers: word pairs composed strings (orhead nouns) active mention one preceding mentions. Intuitively,word pairs contain useful information. example, may help improve precisionmodel, allowing learner learn moderate probabilityanaphoric, contrary taken phrase contrary neveranaphoric. may also help improve recall, allowing learner determine,instance, airline carrier coreferent. Hence, offer convenientmeans attack one major problems coreference research: identifying coreferentcommon nouns lexically dissimilar semantically related. Noteextremely easy compute, even so-called cheap features stringmatching grammatical features (Yang, Zhou, Su, & Tan, 2003), majorityexisting supervised coreference systems unlexicalized hence exploitingthem. Somewhat unexpectedly, however, researchers lexicalize coreferencemodels employing word pairs features (e.g., Luo et al., 2004; Daume III & Marcu, 2005;Bengtson & Roth, 2008), feature analysis experiments indicate lexical featuresbest marginally useful. instance, Luo et al. Daume III Marcu reportleaving lexical features feature ablation experiments causes ACE valuedrop 0.8 0.7, respectively. previous attempts lexicalization merelyappend word pairs conventional coreference feature set, goal investigatewhether make better use lexical features learning-based coreference resolution.sum up, propose cluster-ranking approach coreference resolution jointmodel exploiting anaphoricity information, investigate role lexicalizationlearning-based coreference resolution. Besides empirically demonstrating clusterranking model significantly outperforms competing approaches ACE 2005 coreferencedata set, two extensions model, namely lexicalization joint modeling,effective improving performance, believe work makes four contributionscoreference resolution:Narrowing modeling gap. machine learning approaches coreference resolution received lot attention since mid-1990s, mention-pair modelheavily influenced learning-based coreference research decade, yetmodel lags far behind heuristic-based coreference models proposed 1980s1990s terms sophistication. particular, notion ranking traced backcentering algorithms (for information, see books Mitkov, 2002; Walker, Joshi,& Prince, 1998), idea behind ranking preceding clusters (in heuristic manner)found Lappin Leasss (1994) influential paper pronoun resolution.cluster-ranking model completely close gap simplicity machinelearning approaches sophistication heuristic approaches coreference resolu472fiA Cluster-Ranking Approach Coreference Resolutiontion, believe represents important step towards narrowing gap. Anotherimportant gap cluster-ranking model helps bridge two independent lineslearning-based coreference research going past years, oneinvolving entity-mention model mention-ranking model.Promoting use ranking models. mention-ranking modelempirically shown outperform mention-pair model (Denis & Baldridge, 2007b, 2008),former received much attention among coreference researchers should.particular, mention-pair model continues popularly used investigatedpast years mention-ranking model. believe lack excitementranking-based approaches coreference resolution attributed least partlack theoretical understanding ranking, previous work ranking-based coreferenceresolution employed ranking algorithms essentially black box. Without openingblack box, could difficult researchers appreciate subtle differenceranking classification. attempt promote use ranking-based models,provide brief history use ranking coreference resolution (Section 2),tease apart differences classification ranking showing constrainedoptimization problem support vector machine (SVM) attempts solve classificationbased ranking-based coreference models (Section 3).Gaining better understanding existing learning-based coreference models.Recall lexicalization one two linguistic knowledge sources proposeuse improve cluster-ranking model. Note lexicalization appliedcluster-ranking model, essentially learning-based coreference models. However,mentioned before, vast majority existing coreference resolvers unlexicalized.fact, mention-ranking model shown improve mention-pair modelunlexicalized feature set. attempt gain additional insights behaviordifferent learning-based coreference models, compare performance lexicalizedfeature set. Furthermore, analyze via experiments involving feature ablationdata source adaptability, well report performance resolving different typesanaphoric expressions.Providing implementation cluster-ranking model. stimulateresearch ranking-based approaches coreference resolution, facilitate usecoreference information high-level NLP applications, make software implements cluster-ranking model publicly available.3rest article organized follows. Section 2 provides overview useranking coreference resolution. Section 3 describes baseline coreference models:mention-pair model, entity-mention model, mention-ranking model.discuss cluster-ranking approach joint model anaphoricity determinationcoreference resolution Section 4. Section 5 provides details lexicalizecoreference models. present evaluation results experimental analyses differentaspects coreference models Section 6 Section 7, respectively. Finally,conclude Section 8.3. software available http://www.hlt.utdallas.edu/~ altaf/cherrypicker/.473fiRahman & Ng2. Ranking Approaches Coreference Resolution: Bit Historyranking theoretically empirically better formulation learning-based coreference resolution classification, mention-ranking model popularlyused investigated mention-pair counterpart since proposed. promoteranking-based coreference models, set stage discussion learningbased coreference models next section, provide section brief historyuse ranking heuristic-based learning-based coreference resolution.broader sense, many heuristic anaphora coreference resolvers rankingbased. example, find antecedent anaphoric pronoun, Hobbss (1978) seminal syntax-based resolution algorithm considers sentences given text reverseorder, starting sentence pronoun resides searching potentialantecedents corresponding parse trees left-to-right, breadth-first mannerobeys binding agreement constraints. Hence, keep searching beginningtext reached (i.e., stop even algorithm proposes antecedent),obtain ranking candidate antecedents pronoun consideration, rank candidate determined order proposedalgorithm. fact, rank antecedent obtained via method commonlyknown Hobbss distance, used linguistic feature statisticalpronoun resolvers (e.g., Ge, Hale, & Charniak, 1998; Charniak & Elsner, 2009). general,search-based resolution algorithms like Hobbss consider candidate antecedents particular order (typically) propose first candidate satisfies linguistic constraintsantecedent.Strictly speaking, however, may want consider heuristic resolution algorithmranking-based algorithm considers candidate antecedents simultaneously,example assigning rank score candidate selecting highest-rankedhighest-scored candidate antecedent. Even stricter definitionranking, still many heuristic resolvers ranking-based. resolverstypically assign rank score candidate antecedent based number factors,knowledge sources, propose one highest rank scoreantecedent (e.g., Carbonell & Brown, 1988; Cardie & Wagstaff, 1999). factor belongsone two types: constraints preferences (Mitkov, 1998). Constraints must satisfiedtwo mentions posited coreferent. Examples constraints include gendernumber agreement, binding constraints, semantic compatibility. Preferences indicate likelihood candidate antecedent. preference factors measurecompatibility anaphor candidate (e.g., syntactic parallelism favors candidates grammatical role anaphor), preference factorscomputed based candidate only, typically capturing salience candidate.constraint preference manually assigned weight indicating importance.instance, gender disagreement typically assigned weight , indicatingcandidate anaphor must agree gender, whereas preference factors typicallyfinite weight. score candidate obtained summing weightsfactors associated candidate.ranking-based resolution algorithms assign score candidate antecedent. Rather, simply impose ranking candidates based salience.474fiA Cluster-Ranking Approach Coreference ResolutionPerhaps representative family algorithms employ salience rank candidates centering algorithms (for descriptions specific centering algorithms, seework Grosz, Joshi, & Weinstein, 1983, 1995; Walker et al., 1998; Mitkov, 2002),salience mention, typically estimated using grammatical role, used rankforward-looking centers.work related Lappin Leass (1994), whose goal perform pronoun resolution assigning anaphoric pronoun highest-ranked precedingcluster, therefore heuristic cluster-ranking model. Like many heuristic-basedresolvers, Lappin Leasss algorithm identifies highest-ranked preceding clusteractive mention first applying set linguistic constraints filter candidate antecedents grammatically incompatible active mention, rankingpreceding clusters, contain mentions survive filtering process, usingsalience factors. Examples salience factors include sentence recency (whether preceding cluster contains mention appears sentence currently processed),subject emphasis (whether cluster contains mention subject position), existential emphasis (whether cluster contains mention predicate nominalexistential construction), accusative emphasis (whether cluster contains mentionappears verbal complement accusative case). salience factor associatedmanually-assigned weight indicates importance relative factors,score cluster sum weights salience factors applicablecluster. Lappin Leasss paper widely read paper pronoun resolution,cluster ranking aspect algorithm rarely emphasized. fact,aware recent work learning-based coreference resolution establishesconnection entity-mention model Lappin Leasss algorithm.Despite conceptual similarities, cluster-ranking model Lappin Leasss(1994) algorithm differ several respects. First, Lappin Leass tackle pronoun resolution rather full coreference task. Second, apply linguistic constraintsfilter incompatible candidate antecedents, resolution strategy learned without applying hand-coded constraints separate filtering step. Third, attemptcompute salience preceding cluster respect active mention, attemptdetermine compatibility cluster active mention, using factorsdetermine salience also lexical grammatical compatibility, instance.Finally, algorithm heuristic-based, weights associated saliencefactor encoded manually rather learned, unlike system.first paper learning-based coreference resolution written Connolly, Burger,Day (1994) published year Lappin Leasss (1994) paper.Contrary common expectation, coreference model paper proposes rankingbased model, influential mention-pair model. main idea behind Connolly etal.s approach convert problem ranking N candidate antecedents setpairwise ranking problems, involves ranking exactly two candidates.rank two candidates, classifier trained using training set instancecorresponds active mention well two candidate antecedents possessesclass value indicates two candidates better. idea certainly aheadtime, embodied many advanced ranking algorithms developedmachine learning information retrieval communities past years.475fiRahman & Nglater re-invented almost time, independently, Yang et al. (2003)Iida, Inui, Takamura, Matsumoto (2003), refer twin-candidate modeltournament model, respectively. name twin-candidate model motivatedfact model considers two candidates time, whereas name tournamentmodel assigned ranking two candidates viewed tournament(with higher-ranked candidate winning tournament) candidate winslargest number tournaments chosen antecedent active mention.bit history rarely mentioned literature, reveals three somewhat interestingperhaps surprising facts. First, ranking first applied train coreference modelsmuch earlier people typically think. Second, despite first learning-basedcoreference model, Connolly et al.s ranking-based model theoretically appealingclassification-based mention-pair model, later shown Yang et al.Iida et al.. empirically better well. Finally, despite theoretical empiricalsuperiority, Connolly et al.s model largely ignored NLP community receivedattention re-invented nearly decade later, time periodmention-pair counterpart essentially dominated learning-based coreference research.4conclude section making important observation distinction classification ranking applies discriminative models generative models.Generative models try capture true conditional probability event. context coreference resolution, probability mention particularantecedent referring particular entity (i.e., preceding cluster). Since probabilities normalize, similar ranking objective: system trying raiseprobability mention refers correct antecedent entity expenseprobabilities refers other. Thus, antecedent version generativecoreference model proposed Ge et al. (1998) resembles mention-ranking model,entity version proposed Haghighi Klein (2010) similar spiritcluster-ranking model.3. Baseline Coreference Modelssection, describe three coreference models serve baselines:mention-pair model, entity-mention model, mention-ranking model. illustrative purposes, use text segment shown Figure 1. mentionsegment annotated [m]cidmid , mid mention id cid id clusterbelongs. see, mentions partitioned four sets, BarackObama, his, one cluster, remaining mentions cluster.4. may possible (and perhaps crucial) determine mention-pair model receivedlot attention Connolly et al.s model, since days academic paperscould accessed easily electronic form, speculate publication venue played role:Connolly et al.s work published New Methods Language Processing conference 1994(and later book chapter 1997), whereas mention-pair model introduced AoneBennetts (1995) paper McCarthy Lehnerts (1995) paper, appeared proceedingstwo comparatively higher-profile AI conferences: ACL 1995 IJCAI 1995.476fiA Cluster-Ranking Approach Coreference Resolution[Barack Obama]11 nominated [Hillary Rodham Clinton]22 [[his]13 secretary state]34 [Monday]45 .[He]16 ...Figure 1: illustrative example3.1 Mention-Pair Modelnoted before, mention-pair model classifier decides whetheractive mention mk coreferent candidate antecedent mj . instance i(mj , mk )represents mj mk . implementation, instance consists 39 features shownTable 1. features largely employed state-of-the-art learning-basedcoreference systems (e.g., Soon, Ng, & Lim, 2001; Ng & Cardie, 2002b; Bengtson & Roth,2008), computed automatically. seen, features divided fourblocks. first two blocks consist features describe properties mj mk ,respectively, last two blocks features describe relationship mjmk . classification associated training instance either positive negative,depending whether mj mk coreferent.one training instance created pair mentions, negative instanceswould significantly outnumber positives, yielding skewed class distributiontypically adverse effect model training. result, subset mentionpairs generated training. Following Soon et al. (2001), create (1) positiveinstance anaphoric mention mk closest antecedent mj ; (2) negativeinstance mk paired intervening mentions, mj+1 , mj+2 , . . . , mk1 .running example shown Figure 1, three training instances generated He:i(Monday, He), i(secretary state, He), i(his, He). first two instanceslabeled negative, last one labeled positive. train mention-pairmodel, use SVM learning algorithm SVMlight package (Joachims, 1999).5mentioned introduction, previous work learning-based coreferenceresolution typically treats underlying machine learner simply black-box tool,choose provide reader overview SVMs, learner employingwork. Note self-contained overview, means comprehensiveintroduction maximum-margin learning: goal provide readerdetails believe needed understand difference classificationranking perhaps appreciate importance ranking.6begin with, assume given data set consisting positively labeledpoints, class value +1, negatively labeled points, class5. Since SVMlight assumes real-valued features, cannot operate features multiple discrete valuesdirectly. Hence, need convert features shown Table 1 equivalent set featuresused directly SVMlight . uniformity, perform conversion featureTable 1 (rather multi-valued features) follows: create one binary-valued featureSVMlight feature-value pair derived feature set Table 1. example,pronoun 1 two values, N. derive two binary-valued features, pronoun 1=Ypronoun 1=N. One value 1 value 0 instance.6. overview theory maximum-margin learning, refer reader Burgess (1998)tutorial.477fiRahman & NgFeatures describing mj , candidate antecedent1 pronoun 1mj pronoun; else N2 subject 1mj subject; else N3 nested 1mj nested NP; else NFeatures describing mk , mention resolved4 number 2singular plural, determined using lexiconmale, female, neuter, unknown, determined using list5 gender 2common first namesmk pronoun; else N6 pronoun 27 nested 2mk nested NP; else N8 semclass 2semantic class mk ; one person, location, organization, date, time, money, percent, object, others, determined using WordNet (Fellbaum, 1998) Stanford NE recognizer (Finkel, Grenager, & Manning, 2005)9 animacy 2mk determined human animal WordNet NErecognizer; else Nnominative case mk pronoun; else NA. E.g.,10 pro type 2feature valueFeatures describing relationship mj , candidate antecedent mk ,mention resolved11 head matchC mentions head noun; else12 str matchC mentions string; else13 substr matchC one mention substring other; elseC mentions pronominal string; else14 pro str match15 pn str matchC mentions proper names string; else16 nonpro str match C two mentions non-pronominalstring; else17 modifier matchC mentions modifiers; NA onedont modifier; elseC mentions pronominal either pronoun18 pro type matchdifferent respect case; NA least onepronominal; else19 numberC mentions agree number; disagree; NAnumber one mentions cannot determined20 genderC mentions agree gender; disagree; NA genderone mentions cannot determined21 agreementC mentions agree gender number; disagreenumber gender; else NA22 animacyC mentions match animacy; dont; NAanimacy one mentions cannot determinedC mentions pronouns; neither pronouns; else NA23 pronouns24 proper nounsC mentions proper nouns; neither proper nouns;else NA25 maximalnpC two mentions maximial NP projection; else26 spanC neither mention spans other; else27 indefiniteC mk indefinite NP appositive relationship;else28 appositiveC mentions appositive relationship; else29 copularC mentions copular construction; else478fiA Cluster-Ranking Approach Coreference ResolutionFeatures describing relationship mj , candidate antecedent mk ,mention resolved (continued previous page)30 semclassC mentions semantic class (where setsemantic classes considered enumerated descriptionsemclass 2 feature); dont; NA semantic classinformation one mentions cannot determined31 aliasC one mention abbreviation acronym other; else32 distancebinned values sentence distance mentionsAdditional features describing relationship mj , candidate antecedentmk , mention resolved33 numberconcatenation number 2 feature values mj mk .E.g., mj Clinton mk they, feature value singularplural, since mj singular mk plural34 genderconcatenation gender 2 feature values mj mk35 pronounconcatenation pronoun 2 feature values mj mk36 nestedconcatenation nested 2 feature values mj mk37 semclassconcatenation semclass 2 feature values mj mk38 animacyconcatenation animacy 2 feature values mj mkconcatenation pro type 2 feature values mj mk39 pro typeTable 1: Feature set coreference resolution. Non-relational features describe mentioncases take value Yes No. Relational features describe relationshiptwo mentions indicate whether Compatible, IncompatibleApplicable.value 1. used classification mode, SVM learner aims learn hyperplane(i.e., linear classifier) separates positive points negative points.one hyperplane achieves zero training error, learner choosehyperplane maximizes margin separation (i.e., distancehyperplane training example closest it), larger margin provenprovide better generalization unseen data (Vapnik, 1995). formally, maximummargin hyperplane defined w x b = 0, x feature vector representingarbitrary data point, w (a weight vector) b (a scalar) parameterslearned solving following constrained optimization problem:Optimization Problem 1: Hard-Margin SVM Classificationarg minsubject1kwk22yi (w xi b) 1,1 n,yi {+1, 1} class i-th training point xi . Note data pointxi , exactly one linear constraint optimization problem ensures xicorrectly classified. particular, using value 1 right side inequality479fiRahman & Ngconstraint ensures certain distance (i.e., margin) xi hyperplane.shown margin inversely proportional length weight vector.Hence, minimizing length weight vector equivalent maximizing margin.resulting SVM classifier known hard-margin SVM: margin harddata point correct side hyperplane.However, cases data set linearly separable, hyperplaneperfectly separate positives negatives, result,constrained optimization problem solution. Instead asking SVMlearner give return solution, solve relaxed version problemalso consider hyperplanes produce non-zero training errors potential solutions.words, modify linear constraints associated data pointtraining errors allowed. However, modify linear constraintsleave objective function is, learner search maximum-marginhyperplane regardless training error produces. Since training error correlatespositively generalization error, crucial objective function also takeconsideration training error hyperplane large margin low trainingerror found. However, non-trivial maximize margin minimizetraining error simultaneously, since training error typically increases maximizemargin. result, need find trade-off two criteria, resultingobjective function linear combination margin size training error.formally, find optimal hyperplane solving following constrained optimizationproblem:Optimization Problem 2: Soft-Margin SVM Classificationarg minX1kwk2 + C2subjectyi (w xi b) 1 , 1 n.before, yi {+1, 1} class i-th training point xi . C regularizationparameter balances training error margin size. Finally, non-negative slackvariable represents degree misclassification xi ; particular, > 1,data point wrong side hyperplane. SVM allows data pointsappear wrong side hyperplane, also known soft-margin SVM.Given optimization problem, rely training algorithm employed SVMlightfinding optimal hyperplane.training, resulting SVM classifier used clustering algorithm identifyantecedent mention test text. Specifically, active mention comparedturn preceding mention. pair, test instance created trainingpresented SVM classifier, returns value indicates likelihoodtwo mentions coreferent. Mention pairs class values 0 consideredcoreferent; otherwise pair considered coreferent. Following Soon et al. (2001),apply closest-first linking regime antecedent selection: given active mention mk ,480fiA Cluster-Ranking Approach Coreference Resolutionselect antecedent closest preceding mention classified coreferentmk . mk classified coreferent preceding mention, considerednon-anaphoric (i.e., antecedent selected mk ).3.2 Entity-Mention ModelUnlike mention-pair model, entity-mention model classifier decides whetheractive mention mk belongs partial coreference cluster cj precedes mk .training instance, i(cj , mk ), represents cj mk . features instancedivided two types: (1) features describe mk (i.e, shown second blockTable 1), (2) cluster-level features, describe relationship cjmk . cluster-level feature created feature employed mention-pairmodel applying logical predicate. example, given number feature (i.e., feature#19 Table 1), determines whether two mentions agree number, applypredicate create cluster-level feature value yes mk agreesnumber mentions cj otherwise. Motivated previous work (Luoet al., 2004; Culotta, Wick, & McCallum, 2007; Yang et al., 2008), create cluster-levelfeatures mention-pair features using four commonly-used logical predicates: none,most-false, most-true, all. Specifically, feature x shown last twoblocks Table 1, first convert x equivalent set binary-valued featuresmulti-valued. Then, resulting binary-valued feature xb , create four binaryvalued cluster-level features: (1) none-xb true xb false mkmention cj ; (2) most-false-xb true xb true mk less half(but least one) mentions cj ; (3) most-true-xb true xb truemk least half (but all) mentions cj ; (4) all-xb true xbtrue mk mention cj . Hence, xb , exactly one fourcluster-level features evaluates true.7Following Yang et al. (2008), create (1) positive instance anaphoric mentionmk preceding cluster cj belongs; (2) negative instance mkpaired preceding cluster whose last mention appears mk closestantecedent (i.e., last mention cj ). Consider running example. Threetraining instances generated He: i({Monday}, He), i({secretary state}, He),i({Barack Obama, his}, He). first two instances labeled negative,last one labeled positive. mention-pair model, trainentity-mention model using SVM learner.Since entity-mention model classifier, use SVMlight classificationmode, resulting constrained optimization problem essentially Optimization Problem 2, except training example xi represents active mentionone preceding clusters rather two mentions.7. Note cluster-level feature also represented probabilistic feature. Specifically, recallfour logical predicates partitions [0,1] interval. predicate evaluates true givencluster-level feature depends probability obtained computation feature. Insteadapplying logical predicates convert probability one four discrete values,simply use probability value cluster-level feature. However, choose employprobabilistic representation, preliminary experiments indicated using probabilistic featuresyielded slightly worse results using logical features.481fiRahman & Ngtraining, resulting classifier used identify preceding cluster mentiontest text. Specifically, mentions processed left-to-right manner.active mention mk , test instance created mk preceding clustersformed far. test instances presented classifier. Finally, adoptclosest-first clustering regime, linking mk closest preceding cluster classifiedcoreferent mk . mk classified coreferent preceding cluster,considered non-anaphoric. Note partial clusters preceding mk formedincrementally based predictions classifier first k 1 mentions;gold-standard coreference information used formation.3.3 Mention-Ranking Modelnoted before, ranking model imposes ranking candidate antecedentsactive mention mk . train ranking-model, use SVM ranker-learning algorithmJoachimss (2002) SVMlight package.Like mention-pair model, training instance i(mj , mk ) represents mkpreceding mention mj . fact, features represent instance methodcreating training instances identical employed mention-pair model.difference lies labeling training instances. Assuming Sk settraining instances created anaphoric mention mk , rank value i(mj , mk ) Skrank mj among competing candidate antecedents, 2 mj closestantecedent mk , 1 otherwise.8 exemplify, consider running example.mention-pair model, three training instances generated He: i(Monday,He), i(secretary state, He), i(his, He). third instance rank value 2,remaining two rank value 1.first glance, seems training set generated learning mentionranking model, identical one learning mention-pair model, instancerepresents two mentions labeled one two possible values. Since previous workranking-based coreference resolution attempt clarify differencetwo, believe could difficult reader appreciate idea usingranking coreference resolution.Let us first describe difference classification ranking high level,beginning training sets employed mention-ranking model mentionpair model. difference label associated instance trainingmention-ranking model rank value, whereas label associated instancetraining mention-pair model class value. specifically, since ranking SVMlearns rank set candidate antecedents, relative ranks two candidates,rather absolute rank candidate, matter training process.words, point view ranking SVM, training set instance #1rank value 2 instance #2 rank value 1 functionally equivalent one#1 rank value 10 #2 rank value 5, assuming remaininginstances generated anaphor two training sets identicalrank value 1 10.8. larger rank value implies better rank SVMlight .482fiA Cluster-Ranking Approach Coreference ResolutionNext, take closer look ranker-training process. denote training setcreated described . addition, assume instancedenoted (xjk , yjk ), xjk feature vector created anaphoric mentionmk candidate antecedent mj , yjk rank value. training ranker,SVM ranker-learning algorithm derives training set original training setfollows. Specifically, every pair training instances (xik , yik ) (xjk , yjk )yik 6= yjk , create new training instance (xijk , yijk ) , xijk = xik xjk ,yijk {+1, 1} 1 xik larger rank value xjk (and 1 otherwise). way,creation resembles Connolly et al.s (1994) pairwise ranking approach sawSection 2, convert ranking problem pairwise classification problem.9goal ranker-learning algorithm, then, find hyperplane minimizesnumber misclassifications . Note since yijk {+1, 1}, class valueinstance depends relative ranks two candidate antecedents,absolute rank values.Given conversion ranking problem pairwise classification problem,constrained optimization problem SVM ranker-learning algorithm attemptssolve, described below, similar Optimization Problem 2:Optimization Problem 3: Soft-Margin SVM RankingX1ijkarg min kwk2 + C2subjectyijk (w (xik xjk ) b) 1 ijk ,ijk non-negative slack variable represents degree misclassificationxijk , C regularization parameter balances training error margin size.Two points deserve mention. First, optimization problem equivalent oneclassification SVM pairwise difference feature vectors xik xjk . result,training algorithm used solve Optimization Problem 2 also applicableoptimization problem. Second, number linear inequality constraintsgenerated document optimization problems training mention-pairmodel entity-mention model quadratic number mentions d,number constraints generated ranking SVM cubic number mentions,since instance represents three (rather two) mentions.training, mention-ranking model applied rank candidate antecedentsactive mention test text follows. Given active mention mk , follow DenisBaldridge (2008) use independently-trained classifier determine whether mknon-anaphoric. so, mk resolved. Otherwise, create test instances mkpairing preceding mentions. test instances presentedranker, computes rank value instance taking dot product9. main difference training set employed Connolly et al.s approach, instance formed taking difference feature vectors two instances , whereasConnolly et al.s training set, instance formed concatenating feature vectors twoinstances .483fiRahman & Nginstance vector weight vector. preceding mention assigned largestvalue ranker selected antecedent mk . Ties broken preferringantecedent closest distance mk .anaphoricity classifier used resolution step trained using publicly-availableimplementation10 maximum entropy (MaxEnt) modeling. instance correspondsmention represented 26 features deemed useful distinguishinganaphoric non-anaphoric mentions (see Table 2 details). Linguistically,features broadly divided three types: string-matching, grammatical,semantic. either relational feature, compares mention onepreceding mentions, non-relational feature, encodes certain linguistic propertymention whose anaphoricity determined (e.g., NP type, number, definiteness).4. Coreference Cluster Rankingsection, describe cluster-ranking approach NP coreference. notedbefore, approach aims combine strengths entity-mention modelmention-ranking model.4.1 Training Applying Cluster Rankerease exposition, describe subsection train apply clusterranking model used pipeline architecture, anaphoricity determinationperformed prior coreference resolution. next subsection, showtwo tasks learned jointly.Recall cluster-ranking model ranks set preceding clusters activemention mk . Since cluster-ranking model hybrid mention-ranking modelentity-mention model, way trained applied also hybridtwo. particular, instance representation employed cluster-ranking modelidentical used entity-mention model, training instance i(cj , mk )represents preceding cluster cj anaphoric mention mk consists clusterlevel features formed predicates. Unlike entity-mention model, however,cluster-ranking model, (1) training instance created anaphoric mention mkpreceding clusters; (2) since training model ranking clusters,assignment rank values training instances similar mention-rankingmodel. Specifically, rank value training instance i(cj , mk ) created mkrank cj among competing clusters, 2 mk belongs cj , 1 otherwise.train cluster-ranking model, use SVM learner ranking mode, resultingconstrained optimization problem essentially Optimization Problem3, except training example xijk represents active mention mk twopreceding clusters, ci cj , rather two preceding mentions.Applying learned cluster ranker test text similar applying mentionranking model. Specifically, mentions processed left-to-right manner.active mention mk , first apply independently-trained classifier determine mknon-anaphoric. so, mk resolved. Otherwise, create test instances mk10. See http://homepages.inf.ed.ac.uk/s0450736/maxent_toolkit.html.484fiA Cluster-Ranking Approach Coreference ResolutionFeature TypeLexicalFeaturestr matchhead matchGrammatical(NP type)uppercasedefinitedemonstrativeindefinitequantifiedarticleGrammatical(NPproperty/relationshippronounproper nounbare singularbare pluralembeddedappositiveprednomnumbercontains pnGrammatical(SyntacticPattern)n2npnpn nadj nnum nnesing nSemanticaliasDescriptionexists mention mj preceding mk that,discarding determiners, mj mk string; elseN.exists mention mj preceding mk mjmk head; else N.mk entirely uppercase; else N.mk starts the; else N.mk starts demonstrative this, that,these, those; else N.mk starts an; else N.mk starts quantifiers every, some, all,most, many, much, few, none; else N.definite mk definite NP; quantified mk quantified NP; else indefinite.mk pronoun; else N.mk proper noun; else N.mk singular start article; else N.mk plural start article; else N.mk prenominal modifier; else N.mk first two mentions appositiveconstruction; else N.mk first two mentions predicate nominalconstruction; else N.singular mk singular number; plural mk pluralnumber; unknown number information cannotdetermined.mk proper noun contains proper noun; elseN.mk starts followed exactly one commonnoun; else N.mk starts followed exactly two commonnouns; else N.mk starts followed exactly proper noun;else N.mk starts followed exactly proper nouncommon noun; else N.mk starts followed exactly adjectivecommon noun; else N.mk starts followed exactly cardinalcommon noun; else N.mk starts followed exactly named entity;else N.mk starts followed singular NP containing proper noun; else N.exists mention mj preceding mk mjmk aliases; else N.Table 2: Feature set anaphoricity determination. instance represents single mention,mk , characterized 26 features.485fiRahman & Ngpairing preceding clusters. test instances presentedranker, mk linked cluster assigned highest value ranker. Tiesbroken preferring cluster whose last mention closest distance mk . Notepartial clusters preceding mk formed incrementally based predictionsranker first k 1 mentions.4.2 Joint Anaphoricity Determination Coreference Resolutioncluster ranker described used determine preceding clusteranaphoric mention linked to, cannot used determine whether mention anaphoric not. reason simple: training instances generatedanaphoric mentions. Hence, jointly learn anaphoricity determination coreferenceresolution, must train ranker using instances generated anaphoricnon-anaphoric mentions.Specifically, training ranker, provide active mention optionstart new cluster creating additional instance (1) contains features solelydescribe active mention (i.e., features shown second block Table 1), (2)highest rank value among competing clusters (i.e., 2) non-anaphoriclowest rank value (i.e., 1) otherwise. main advantage jointly learning two tasksallows ranking model evaluate possible options active mention(i.e., whether resolve it, so, preceding cluster best) simultaneously.Essentially method applied jointly learn two tasks mentionranking model.training, resulting cluster ranker processes mentions test textleft-to-right manner. active mention mk , create test instances pairingpreceding clusters. allow possibility mk non-anaphoric,create additional test instance contains features solely describe activemention (similar training step above). test instancespresented ranker. additional test instance assigned highest rank valueranker, mk classified non-anaphoric resolved. Otherwise,mk linked cluster highest rank, ties broken preferringantecedent closest mk . before, partial clusters preceding mk formedincrementally based predictions ranker first k 1 mentions.Finally, note model jointly learning anaphoricity determination coreference resolution different recent attempts perform joint inference anaphoricitydetermination coreference resolution using integer linear programming (ILP),anaphoricity classifier coreference classifier trained independently other,ILP applied postprocessing step jointly infer anaphoricity coreference decisions consistent (e.g., Denis & Baldridge, 2007a).Joint inference different joint-learning approach, allows two taskslearned jointly independently.5. Lexicalization Coreference ResolutionNext, investigate role lexicalization (i.e., use word pairs linguistic features)learning-based coreference resolution. motivation behind investigation two486fiA Cluster-Ranking Approach Coreference Resolutionfold. First, lexical features easy compute yet under-investigatedcoreference resolution. particular, attempts made employtrain mention-pair model (e.g., Luo et al., 2004; Daume III & Marcu, 2005;Bengtson & Roth, 2008). contrast, want determine whether improveperformance cluster-ranking model. Second, mention-pair modelmention-ranking model compared respect non-lexical feature set(Denis & Baldridge, 2007b, 2008), clear perform relativetrained lexical features. desire answer question,allow us gain additional insights strengths weaknesseslearning-based coreference models.Recall introduction previous attempts lexicalizing mention-pairmodel show lexical features best marginally useful. Hence, one goalsdetermine whether make better use lexical features learning-basedcoreference resolver. particular, unlike aforementioned attempts lexicalization,simply append word pairs conventional coreference feature set consistingstring-matching, grammatical, semantic, distance (i.e., proximity-based) features (e.g.,feature set shown Table 1), investigate model exploits lexical featurescombination small subset conventional coreference features.would allow us better understanding significance conventionalfeatures. example, features encode agreement gender, number, semanticclass two mentions employed virtually learning-based coreference resolver,never question whether better alternatives features. couldbuild lexicalized coreference model without commonly-used featuresobserve performance deterioration, would imply conventional featuresreplaceable, prototypical way building learning-based coreferencesystem.question is: small subset conventional features usecombination lexical features? mentioned above, since one advantageslexical features extremely easy compute, desire conventionalfeatures also easy compute, especially require dictionarycompute. see, choose use two features, alias featuredistance feature (see features 31 32 Table 1), rely off-the-shelf namedentity (NE) recognizer compute NE types.Note, however, usefulness lexical features could limited part datasparseness: many word pairs appear training data may appear testdata. employing conventional features described (e.g., distance)help alleviate problem, seek improve generalizability introducingtwo types features: semi-lexical unseen features. henceforth referfeature set comprises two types features, lexical features, alias feature,distance feature Lexical feature set. addition, refer featureset shown Table 1 Conventional feature set.first describe Lexical feature set training mention-pair modelmention-ranking model (Section 5.1). that, show create cluster-levelfeatures feature set training entity-mention model cluster-ranking487fiRahman & Ngmodel, well issues training joint model anaphoricity determination coreference resolution (Section 5.2).5.1 Lexical Feature SetUnlike previous work lexicalizing learning-based coreference models, Lexical featureset consists four types features: lexical features, semi-lexical features, unseen features,well two conventional features (namely, alias distance).compute features, preprocess training text randomly replacing 10%nominal mentions (i.e., common nouns) label unseen. mention mkreplaced unseen, mentions string mk also replacedunseen. test text preprocessed differently: simply replace mentions whosestrings seen training data unseen. Hence, artificially creating unseenlabels training text allow learner learn handle unseen wordstest text, potentially improving generalizability.preprocessing, compute features instance. Assumingtraining mention-pair model mention-ranking model, instance correspondstwo mentions, mj mk , mj precedes mk text. featuresdivided four groups: unseen, lexical, semi-lexical, conventional. describingfeatures, two points deserve mention. First, least one mj mk unseen,lexical, semi-lexical, conventional features created them, since featuresinvolving unseen mention likely misleading learner sensemay yield incorrect generalizations training set. Second, since use SVMtraining testing, instance contain number features, unless otherwisestated, feature value 1.Unseen feature. mj mk unseen, determine whetherstring. so, create unseen-same feature; otherwise, create unseendiff feature. one unseen, feature created.Lexical feature. create lexical feature mj mk , orderedpair consisting heads mentions. pronoun common noun, headassumed last word mention11 ; proper noun, head takenentire noun phrase.Semi-lexical features. features aim improve generalizability. Specifically,exactly one mj mk tagged NE Stanford NE recognizer (Finkel et al.,2005), create semi-lexical feature identical lexical feature described above,except NE replaced NE label (i.e., person, location, organization).mentions NEs, check whether string. so, createfeature *ne*-same, *ne* replaced corresponding NE label. Otherwise,check whether NE tag word-subset match (i.e., whether11. see evaluation section, mention extractor trained extract base NPs. Hence,heuristic extracting head nouns arguably overly simplistic, appliedrecursive NPs (e.g., NPs contain prepositional phrases), phrases likelymake mistakes. However, desire better extraction accuracy, extract head nounssyntactic parsers provide head information, Collinss (1999) parser.488fiA Cluster-Ranking Approach Coreference Resolutionword tokens one mention appear others list tokens). so, create feature*ne*-subsame, *ne* replaced NE label. Otherwise, create featureconcatenation NE labels two mentions.Conventional features. improve generalizability, incorporate two easy-tocompute features Conventional feature set: alias distance.5.2 Feature GenerationLexical feature set training mention-pair model mentionranking model, describe two extensions feature set needed(1) train entity-mention model cluster-ranking model, (2) perform jointlearning anaphoricity determination coreference resolution.first extension concerns generation cluster-level features entity-mentionmodel cluster-level model. Recall Section 3.2 create cluster-level features given Conventional feature set, first convert feature employedmention-pair model equivalent set binary-valued features, createcluster-level feature resulting binary-valued features. hand,given Lexical feature set, method producing cluster-level features applicable two conventional features (i.e., alias distance), also appearConventional feature set. unseen, lexical, semi-lexical feature, createfeature active mention mention preceding cluster, describedSection 5.112 , value feature number times appears instance. Encoding feature values frequency rather binary values allows us capturecluster-level information shallow manner.second extension concerns generation features representing additionalinstance created training joint version mention-ranking modelcluster-ranking model. Recall Section 4.2 Conventional feature setused, represented additional instance using features computed solelyactive mention. hand, given Lexical feature set, longeruse method representing additional instance, featureLexical feature set computed solely active mention. result,represent additional instance using one feature, null-x, x headactive mention, help learner learn x likely non-anaphoric.6. Evaluationevaluation driven following questions, focusing (1) comparison amongdifferent learning-based coreference models, (2) effect lexicalizationmodels. Specifically:learning-based coreference models (namely, mention-pair model,entity-mention model, mention-ranking model, cluster-ranking model)compare other?12. Strictly speaking, resulting feature cluster-level feature, computed activemention one mentions preceding cluster.489fiRahman & Ngjoint modeling anaphoricity determination coreference resolution offerbenefits pipeline architecture, anaphoricity performed priorcoreference resolution?lexicalized coreference models perform better unlexicalized counterparts?rest section, first describe experimental setup (Section 6.1),show performance four models, including effect lexicalizationjoint modeling whenever applicable, three different feature sets (Section 6.2).6.1 Experimental Setupbegin providing details data sets, automatic mention extractionmethod, scoring programs.6.1.1 Corpususe ACE 2005 coreference corpus released LDC, consists 599training documents used official ACE evaluation.13 ensure diversity, corpuscreated selecting documents six different sources: Broadcast News (BN), BroadcastConversations (BC), Newswire (NW), Webblog (WB), Usenet (UN), ConversationalTelephone Speech (CTS). number documents belonging source shownTable 3.Data set# documentsBN226BC60NW106WL119UN49CTS39Table 3: Statistics ACE 2005 corpus6.1.2 Mention Extractionevaluate coreference model using system mentions. extract system mentionstest text, trained mention extractor training texts. Following Florianet al. (2004), recast mention extraction sequence labeling task, assigntoken test text label indicates whether begins mention, insidemention, outside mention. Hence, learn extractor, create one traininginstance token training text derive class value (one b, i, o)annotated data. instance represents wi , token consideration,consists 29 linguistic features, many modeled systems Bikel,Schwartz, Weischedel (1999) Florian et al. (2004), described below.Lexical (7):Tokens window 7: {wi3 , . . . , wi+3 }.Capitalization (4): Determine whether wi IsAllCap, IsInitCap, IsCapPeriod,IsAllLower.13. Since participate ACE 2005, access official test set.490fiA Cluster-Ranking Approach Coreference ResolutionMorphological (8): wi prefixes suffixes length one, two, three, four.Grammatical (1): part-of-speech (POS) tag wi obtained using Stanford loglinear POS tagger (Toutanova, Klein, Manning, & Singer, 2003).Semantic (1): named entity (NE) tag wi obtained using Stanford CRF-basedNE recognizer (Finkel et al., 2005).Dictionaries (8): employ eight dictionary-based features indicate presenceabsence wi particular dictionary. eight dictionaries contain pronouns (77entries), common words words names (399.6k), person names (83.6k),person titles honorifics (761), vehicle words (226), location names (1.8k), companynames (77.6k), nouns extracted WordNet hyponyms person (6.3k).employ CRF++14 , C++ implementation conditional random fields, trainingmention detector training set. Overall, detector achieves F-measure86.7 (86.1 recall, 87.2 precision) test set. extracted mentions usedsystem mentions coreference experiments.6.1.3 Scoring Programsscore output coreference model, employ two scoring programs, B3 (Bagga& Baldwin, 1998) 3 -CEAF15 (Luo, 2005), address inherent weaknessesMUC scoring program (Vilain, Burger, Aberdeen, Connolly, & Hirschman, 1995).16B3 CEAF score response (i.e., system-generated) partition, R, key(i.e., gold-standard) partition, K, report coreference performance terms recall,precision, F-measure. B3 first computes recall precision mention, mk ,follows:recall(mk ) =|Rmk Kmk ||Rmk Kmk |, precision(mk ) =,|Kmk ||Rmk |Rmk coreference cluster containing mk R, Kmk coreference clustercontaining mk K. computes overall recall (resp. precision) averagingper-mention recall (resp. precision) scores.hand, CEAF first constructs optimal one-to-one mappingclusters key partition response partition. Specifically, assumeK = {K1 , K2 , . . . , Km } set clusters key partition, R = {R1 , R2 , . . . , Rn }set clusters response partition. compute recall, CEAF first computesscore cluster, Ki , K follows:score(Ki ) = |Ki Rj |,14. Available http://crfpp.sourceforge.net15. CEAF two versions: 3 -CEAF 4 -CEAF. two versions differ similarity twoaligned clusters computed. refer reader Luos (2005) paper details. 3 -CEAF chosencommonly-used version CEAF.16. Briefly, MUC scoring program suffers two often-cited weaknesses. First, link-based measure,reward successful identification singleton clusters, since mentions clusterslinked mentions. Second, tends under-penalize partitions overly large clusters.See work Bagga Baldwin (1998), Luo (2005), Recasens Hovy (2011) details.491fiRahman & NgRj cluster Ki mapped optimal one-to-one mapping,constructed efficiently using Kuhn-Munkres algorithm (Kuhn, 1955). NoteKi mapped cluster R, score(Ki ) = 0. CEAF computes recallsumming score cluster K dividing sum number mentionsK. Precision computed manner, except reverse rolesK R.complication arises B3 used score response partition containing systemmentions. Recall B3 constructs mapping mentions responsekey. Hence, response generated using gold-standard mentions,every mention response mapped mention key vice versa.words, twinless (i.e., unmapped) mentions (Stoyanov et al., 2009).case system mentions used, original description B3specify twinless mentions scored (Bagga & Baldwin, 1998). addressproblem, set per-mention recall precision twinless mention zero,regardless whether mention appears key response. Note CEAFcompare partitions twinless mentions without modification, since operatesaligning clusters, mentions.Additionally, apply preprocessing step response partition scoring it:remove twinless system mentions singletons. reasonsimple: since coreference resolver successfully identified mentions singletons,penalized, removing allows us avoid penalty. Noteremove twinless (as opposed all) system mentions singletons: allowsus reward resolver successful identification singleton mentions twins.hand, retain (1) twinless system mentions non-singletons (asresolver penalized identifying spurious coreference relations) (2) twinlessmentions key partition (as want ensure resolver makes correctcoreference non-coreference decisions them).176.2 Resultsshowing results learning-based coreference models, let us consider headmatch baseline, commonly-used heuristic baseline coreference resolution.posits two mentions coreferent head nouns match. Head nounsdetermined described Section 5.1: head proper noun string entiremention, whereas head pronoun common noun last word mention.Since one goals examine effect lexicalization coreference model,head match baseline provide information well one simplestkinds string matching. Results baseline, shown row 1 Table 4, expressedterms recall (R), precision (P), F-measure (F) obtained via B3 CEAF.see Table 4, baseline achieves F-measure scores 54.9 49.6 accordingB3 CEAF, respectively.17. addition method described here, number methods proposed addressmapping problem. refer reader work Enrique, Gonzalo, Artiles, Verdejo (2009),Stoyanov et al. (2009), Cai Strube (2010) details.492fiA Cluster-Ranking Approach Coreference ResolutionNext, train evaluate learning-based coreference models using five-fold crossvalidation. data set si shown Table 3, partition documents sifive folds approximately equal size, si1 , . . . , si5 . train coreference modelfour folds use generate coreference chains documents remainingfold, repeating step five times fold used test fold exactly once.that, apply B3 CEAF entire set automatically coreference-annotateddocuments obtain scores Table 4. discuss results learningbased coreference models obtained used combination three feature sets:Conventional feature set (Section 6.2.1), Lexical feature set (Section 6.2.2),Combined feature set, composed features Conventional Lexical(Section 6.2.3).6.2.1 Results Using Conventional Featuresgauge performance cluster-ranking model, employ baselines mentionpair model, entity-mention model, mention-ranking model.mention-pair baseline. train first learning-based baseline, mentionpair model, using SVM learning algorithm implemented SVMlight package.18see row 2 Table 4, mention-pair model achieves F-measure scores58.6 (B3 ) 54.4 (CEAF), represent statistically significant improvement 3.7%4.8% F-measure corresponding results head match baseline.19entity-mention baseline. Next, train second learning-based baseline,entity-mention model, using SVM learner. see row 3 Table 4,baseline achieves F-measure scores 58.9 (B3 ) 54.8 (CEAF), represent smallstatistically significant improvements mention-pair model. significant performance difference perhaps particularly surprising given improved expressivenessentity-mention model mention-pair model.mention-ranking baseline. third baseline mention-ranking model,trained using ranker-learning algorithm SVMlight . identify non-anaphoric mentions, employ two methods. first method, follow Denis Baldridge (2008)adopt pipeline architecture, train MaxEnt classifier anaphoricity determination independently mention ranker training set using 26 featuresdescribed Section 3.3. apply resulting classifier test text filter nonanaphoric mentions prior coreference resolution. Results pipeline mention rankershown row 4 Table 4. see, ranker achieves F-measure scores 57.7(B3 ) 53.0 (CEAF), yielding significant performance deterioration comparisonentity-mention baseline.second method, perform anaphoricity determination jointly coreferenceresolution using method described Section 4.2. discussed joint learningmethod context cluster ranking, easy see methodequally applicable mention-ranking model. Results mention ranker using18. subsequent uses SVM learner, set parameters default values.particular, employ linear kernel obtain results article.19. statistical significance results article obtained using paired t-test, p < 0.05.493fiRahman & NgR44.1B3P72.9CEAFPF60.8 49.61Coreference ModelHead matchF54.9R41.9234567Using Conventional feature setMention-pair model49.7 71.4 58.6Entity-mention model49.9 71.7 58.9Mention-ranking model (Pipeline)48.1 72.1 57.7Mention-ranking model (Joint)49.1 76.1 59.7Cluster-ranking model (Pipeline)49.9 71.6 58.8Cluster-ranking model (Joint)51.1 73.3 60.249.551.051.752.953.454.160.559.254.459.254.660.254.454.853.055.954.057.08910111213Using Lexical feature setMention-pair model53.0 75.3 62.2Entity-mention model53.1 75.8 62.5Mention-ranking model (Pipeline)55.7 67.5 61.0Mention-ranking model (Joint)56.6 73.1 63.8Cluster-ranking model (Pipeline)51.0 67.1 58.0Cluster-ranking model (Joint)51.3 75.7 61.155.655.756.358.553.153.362.062.262.065.055.358.658.658.859.061.654.155.8141516171819Using CombinedMention-pair model50.4Entity-mention model50.5Mention-ranking model (Pipeline)50.6Mention-ranking model (Joint)49.9Cluster-ranking model (Pipeline)52.9Cluster-ranking model (Joint)54.353.854.154.154.757.557.661.962.361.861.462.164.357.557.957.757.959.760.8feature73.173.474.679.370.975.1set59.659.860.361.360.663.0Table 4: Five-fold cross-validation coreference results obtained using B3 CEAF.best F-measure achieved feature set/scoring program combination boldfaced.joint architecture shown row 5 Table 4. see, ranker achieves Fmeasure scores 59.7 (B3 ) 55.9 (CEAF), represent significant improvementsentity-mention model pipeline counterpart. resultsdemonstrate superiority joint mention-ranking model entity-mention model,substantiate hypothesis joint modeling offers benefits pipeline modeling.cluster-ranking model. Finally, evaluate cluster-ranking model.mention-ranking baselines, employ pipeline architecture joint architecture anaphoricity determination. Results shown rows 6 7 Table 4,respectively, two architectures. see, pipeline architecture yields Fmeasure scores 58.8 (B3 ) 54.0 (CEAF), represent significant improvementmention ranker adopting pipeline architecture. joint architecture,cluster ranker achieves F-measure scores 60.2 (B3 ) 57.0 (CEAF). also rep494fiA Cluster-Ranking Approach Coreference Resolutionresents significant improvement mention ranker adopting joint architecture,best baselines. Taken together, results demonstrate superioritycluster ranker mention ranker. Finally, fact joint cluster ranker performssignificantly better pipeline counterpart provides empirical supportbenefits joint modeling pipeline modeling.6.2.2 Results Using Lexical FeaturesNext, evaluate learning-based coreference models using Lexical features. Resultsshown rows 813 Table 4. comparison results obtained using Conventional features, see different trend: joint mention-ranking model replacescluster-ranking model best-performing model. Moreover, improvementsecond best-performing model, entity-mention model according B3pipeline mention-ranking model according CEAF, statistically significant regardlessscoring program used. closer examination results reveals employingLexical rather Conventional features substantially improves performancemention-ranking model: comparison unlexicalized joint mention-ranking model(row 5), F-measure scores lexicalized joint mention-ranking model (row 11) rise4.1% (B3 ) 5.7% (CEAF). increase F-measure attributed primarilysubstantial rise recall, even though also large increase CEAF precision.Besides joint mention-ranking model, mention-pair model entity-mentionmodel also benefit substantially Conventional features replaced Lexical features: see F-measure scores increase 3.6% (B3 ) 4.2% (CEAF)mention-pair model, 3.6% (B3 ) 4.0% (CEAF) entity-mention model.gains F-measure two models attributed large increasesrecall precision. hand, joint cluster-ranking model alwaysimprove replace Conventional features Lexical features. fact,performance difference cluster-ranking model entity-mention modelstatistically indistinguishable. Finally, see benefits jointly learning anaphoricitydetermination coreference resolution again: joint version mentionranking model used rather pipeline version (compare rows 10 11),F-measure scores rise significantly 2.8% (B3 ) 2.6% (CEAF). Similarly clusterranking model: joint version improves pipeline version significantly 3.1% (B3 )1.7% (CEAF) F-measure.Overall, results somewhat unexpected: recall Lexical featuresknowledge-lean, consisting lexical, semi-lexical, unseen features, welltwo Conventional features. particular, employ conventional coreferencefeatures encode agreement gender number. implies many existingimplementations mention-pair model, entity-mention model, mentionranking model, unlexicalized rely heavily conventional features,making effective use labeled data. Perhaps importantly, results indicatecoreference models perform well (and fact better) even without conventionalcoreference features. Since Lexical computed extremely easily,readily applied languages, another advantage feature set.hand, interesting see versions cluster-ranking model exhibit495fiRahman & Ngless dramatic changes performance replace Conventional featuresLexical features.6.2.3 Results Using Combined FeaturesSince Conventional features Lexical features represent two fairly different sourcesknowledge, examine whether improve coreference models combiningtwo feature sets. Results coreference models using Combined featuresshown rows 1419 Table 4. results exhibit essentially trendobtained Conventional features, joint cluster-ranking model performingbest mention-pair model performing worst. fact, joint cluster-rankingmodel yields significantly better performance used Combined featuresConventional features Lexical features alone. Similarly pipelinecluster-ranking model, achieves significantly better performance Combinedfeatures Conventional Lexical features. results seem suggestcluster-ranking model able exploit potentially different sources informationprovided two feature sets improve performance. addition, demonstratebenefits joint modeling: mention-ranking model, joint version improvespipeline version significantly 1.0% (B3 ) 0.2% (CEAF) F-measure;cluster-ranking model, joint version improves pipeline counterpart significantly2.4% (B3 ) 1.1% (CEAF) F-measure.remaining coreference models exhibit drop performance Combinedfeatures used lieu Lexical features. results seem suggestcluster-ranking model offers robust performance face changes underlying feature set coreference models, feature selection, issueunder-explored coreference resolution, may crucial employ coreference models.20 Perhaps importantly, despite fact Conventional featuresLexical features represent two fairly different sources information,cluster-ranking model unable exploit potentially richer amount informationcontained Combined feature set. Hence, virtually linguistic featuresrecently developed supervised coreference resolution evaluated usingmention-pair model (see, example, work Strube, Rapp, & Muller, 2002; Ji,Westbrook, & Grishman, 2005; Ponzetto & Strube, 2006), utility features maybetter demonstrated using cluster-ranking model.natural question is: joint cluster-ranking model compare existingcoreference systems? Since participate ACE evaluations,access official test sets compare model ACEparticipating coreference systems. comparison complicated factexisting coreference systems evaluated different data sets, including twoMUC data sets (MUC-6, 1995; MUC-7, 1998) various ACE data sets (e.g., ACE-2,ACE 2003, ACE 2004, ACE 2005), well different partitions given data set.knowledge, coreference model evaluated testdata Haghighi Kleins (2010) unsupervised coreference model. model20. fact, Ng Cardie (2002b), Strube Muller (2003), Ponzetto Strube (2006) showmention-pair model improved using feature selection.496fiA Cluster-Ranking Approach Coreference Resolutionrecently shown surpass performance Stoyanov et al.s (2009) system,one best existing implementations mention-pair model. testdata, Haghighi Kleins model achieves B3 F-measure 62.7, achievesB3 F-measure 62.8.21 results provide suggestive evidence cluster-rankingmodel achieves performance comparable one best existing coreferencemodels.Nevertheless, caution results allow one claim anythingfact model compares favorably Haghighi Kleins (2010) model.instance, one cannot claim model better achieves levelperformance without using labeled data. reasons (1) mentionsused two models coreference process extracted differently (2)linguistic features employed two models way features computedalso different other. Since previous work shown linguisticpreprocessing steps considerable impact performance resolver (Barbu& Mitkov, 2001; Stoyanov et al., 2009), possible one model employed featuresmentions model currently using, results would different.Hence, one fairly compare two coreference models, evaluatedset mentions (rather set documents) given accessset knowledge sources, essentially way compare variouslearning-based coreference models article.7. Experimental Analysesattempt gain insights different aspects coreference models,conduct additional experiments analyses. Rather report five-fold cross-validationresults, section report results one fold (i.e., fold designate testset) use remaining four folds solely training.7.1 Improving Classification-Based Coreference ModelsGiven generally poorer performance classification-based coreference models, natural question is: improved? answer question, investigate whethermodels improved employing different clustering algorithm differentlearning algorithm. reasons decision focus two dimensions.First, noted introduction, one weaknesses modelsclear clustering algorithm offers best performance. Given observation,examine whether improve models replacing Soon et al.s (2001)closest-first linking regime best-first linking strategy, shownoffer better performance mention-pair model MUC data sets (Ng & Cardie,2002b). Second, discussed end Section 2, may able achieveadvantage ranking classification-based models employing learning algorithmoptimizes conditional probabilities instead 0/1 decisions. Motivated observation, examine whether improve classification-based models trainingusing MaxEnt, employs likelihood-based loss function. Note MaxEnt one21. Note Haghighi Klein report CEAF scores paper.497fiRahman & Ngpopular learning algorithms training coreference models (see, example,Morton, 2000; Kehler, Appelt, Taylor, & Simma, 2004; Ponzetto & Strube, 2006; Denis &Baldridge, 2008; Finkel & Manning, 2008; Ng, 2009).evaluate two modifications, apply isolation combinationtwo classification-based models (i.e., mention-pair model entity-mentionmodel) trained using three different feature sets (i.e., Conventional, Lexical, Combined). train MaxEnt-based coreference models using YASMET22 ,follow Ng Cardies (2002b) implementation best-first clustering algorithm.Specifically, among candidate antecedents preceding clusters classifiedcoreferent active mention mk , best-first clustering links mk likely one.MaxEnt model, pair classified coreferent classification value0.5, likely antecedent/preceding cluster mk onehighest probability coreference mk . SVMlight -trained model, pairclassified coreferent classification value 0, likelyantecedent/preceding cluster mk one positive classificationvalue.Table 5 presents B3 CEAF results two classification-based coreference modelstrained using two learning algorithms (i.e., SVM MaxEnt) usedcombination two clustering algorithms (i.e., closest-first clustering best-firstclustering). study choice clustering algorithm impacts performance,compare results closest-first clustering best-first clustering Table 5combination learning algorithm, feature set, coreference model, scoringprogram. instance, comparing rows 1 2 Table 5 enables us examinetwo clustering algorithms better mention-pair model trainedConventional feature set two learners. Overall, see fairly consistenttrend: best-first clustering yields results slightly worse obtained usingclosest-first clustering, regardless choice clustering algorithm, learningalgorithm, feature set, scoring program. first glance, results seemcontradictory Ng Cardie (2002b), demonstrate superiority bestfirst clustering closest-first clustering coreference resolution. speculatecontradictory results attributed two reasons. First, best-first clusteringexperiments, still employed Soon et al.s (2001) training instance selection method,created positive training instance anaphoric mention closestantecedent/preceding cluster, unlike Ng Cardie, claim proposed bestfirst clustering successful, however, different method training instance selectionwould needed. particular, propose use confident antecedent,rather closest antecedent, generate positive instances anaphoric mention.Second, Ng Cardie demonstrate success best-first clustering MUC datasets, possible success may carry ACE data sets. Additionalexperiments needed determine reason, however.22. See http://www.fjoch.com/YASMET.html. reason YASMET chosen providescapability rank, allows us compare results MaxEnt-trained classification modelsranking models. See work Ravichandran, Hovy, Och (2003) discussion differencestraining two types MaxEnt models.498fiA Cluster-Ranking Approach Coreference ResolutionCoreference ModelRSVMPFRMaxEntPF1234B3 results using Conventional featureMention-pair model (Closest first)46.2 72.0 56.2Mention-pair model (Best first)45.7 71.0 55.6Entity-mention model (Closest first) 46.8 72.5 56.8Entity-mention model (Best first)46.3 72.1 56.3set59.659.259.759.355.354.855.955.157.356.957.757.15678B3 results using Lexical feature setMention-pair model (Closest first)52.8 73.0 61.2Mention-pair model (Best first)52.1 72.1 60.5Entity-mention model (Closest first) 52.8 73.6 61.2Entity-mention model (Best first)52.4 72.2 60.852.852.152.852.264.664.264.664.358.157.558.257.6Combined feature set49.1 73.2 58.850.348.7 72.8 58.349.349.5 73.2 59.1 50.549.1 72.7 58.650.165.965.266.165.657.056.157.356.813141516CEAF results using Conventional feature setMention-pair model (Closest first)48.5 55.3 51.651.4Mention-pair model (Best first)48.1 54.9 51.251.1Entity-mention model (Closest first) 49.5 55.8 52.551.4Entity-mention model (Best first)49.2 55.1 51.951.156.556.156.756.253.853.453.953.517181920CEAF results usingMention-pair model (Closest first)Mention-pair model (Best first)Entity-mention model (Closest first)Entity-mention model (Best first)56.856.257.456.955.154.655.354.921222324CEAF results using CombinedMention-pair model (Closest first)53.8 60.0Mention-pair model (Best first)53.1 59.7Entity-mention model (Closest first) 54.1 60.9Entity-mention model (Best first)53.7 60.356.355.856.856.255.555.055.955.39101112B3 results usingMention-pair model (Closest first)Mention-pair model (Best first)Entity-mention model (Closest first)Entity-mention model (Best first)(a) B3 resultsLexical feature set54.6 61.2 57.753.554.2 60.7 57.353.154.9 61.7 58.1 53.554.5 61.1 57.653.1feature56.756.257.356.8set54.954.355.154.5(b) CEAF3 resultsTable 5: SVM vs. MaxEnt results classification-based coreference models. one-foldB3 CEAF scores obtained training coreference models using SVM MaxEnt.best F-measure achieved feature set/scoring program combination boldfaced.499fiRahman & NgNext, examine whether minimizing likelihood-based loss via MaxEnt training insteadSVMs classification loss would enable us achieve advantage ranking(and hence leads better performance), compare two columns Table 5.see, Conventional feature set used, MaxEnt outperforms SVM, regardlesschoice clustering algorithm, scoring program, coreference model.hand, Lexical features Combined features used, SVM outperformsMaxEnt consistently. Overall, mixed results seem suggest whether MaxEntoffers better performance SVM extent dependent underlying featureset.7.2 Performance Maximum-Entropy-Based Ranking Modelsprior work suggests MaxEnt-based ranking may provide better gains SVMbased ranking, since generate reliable confidence values dynamically adjustrelative ranks according baseline results (e.g., Ji, Rudin, & Grishman, 2006). determine whether case coreference resolution, conduct experimentstrain ranking-based coreference models using ranker-learning algorithm YASMET.B3 CEAF results mention-ranking model cluster-ranking modeltrained using MaxEnt combination three different feature sets (i.e., Conventional,Lexical, Combined) shown MaxEnt column Table 6. comparison,also show corresponding results obtained via SVM-based ranking table(see SVM column). Comparing two columns, see mixed results: 24experiments involve ranking models, MaxEnt-based ranking outperforms SVM-basedranking six them. words, results suggest coreference task,SVM-based ranking generally better MaxEnt-based ranking.7.3 Accuracy Anaphoricity DeterminationSection 6.2, saw joint ranking model always performs significantly betterpipeline counterpart. words, joint modeling coreference anaphoricityimproves coreference resolution. natural question is: joint modeling also improveanaphoricity determination?answer question, measure accuracy anaphoricity information resulting pipeline modeling joint modeling. Recall pipeline modeling, relyoutput anaphoricity classifier trained independently coreferencesystem uses anaphoricity information (see Section 3.3). accuracy classifier test set shown Acc column row 1 Table 7. addition,show table recall (R), precision (P), F-measure (F) identifying anaphoricmentions. see, classifier achieves accuracy 81.1 F-measure score83.8.hand, joint modeling, compute accuracy anaphoricitydetermination output joint coreference model. Specifically, given outputjoint model, determine mentions resolved preceding antecedentnot. Assuming mention resolved anaphoric oneresolved non-anaphoric, compute accuracy anaphoricity determination500fiA Cluster-Ranking Approach Coreference ResolutionCoreference ModelRSVMPFRMaxEntPF1234B3 results using Conventional featureMention-ranking model (Pipeline)46.7 71.5 56.5Mention-ranking model (Joint)47.6 74.8 58.2Cluster-ranking model (Pipeline)53.6 59.5 56.4Cluster-ranking model (Joint)52.2 73.8 61.2set58.759.151.752.159.159.369.970.658.859.259.360.05678B3 results using Lexical feature setMention-ranking model (Pipeline)53.8 68.3 60.1Mention-ranking model (Joint)54.6 72.8 62.4Cluster-ranking model (Pipeline)51.7 68.2 58.8Cluster-ranking model (Joint)52.9 73.4 61.556.656.348.448.061.164.466.672.958.860.156.157.8Combined feature set49.8 72.6 59.151.450.5 77.6 61.252.553.8 71.2 61.354.154.4 74.8 62.8 54.568.370.367.568.358.760.160.160.6Conventional feature set49.4 55.7 52.451.550.5 56.3 53.251.853.6 59.5 56.453.155.2 61.6 58.2 53.256.656.958.759.353.954.255.856.19101112B3 results usingMention-ranking model (Pipeline)Mention-ranking model (Joint)Cluster-ranking model (Pipeline)Cluster-ranking model (Joint)(a) B3 results13141516CEAF results usingMention-ranking model (Pipeline)Mention-ranking model (Joint)Cluster-ranking model (Pipeline)Cluster-ranking model (Joint)17181920CEAF results usingMention-ranking model (Pipeline)Mention-ranking model (Joint)Cluster-ranking model (Pipeline)Cluster-ranking model (Joint)Lexical feature set54.7 59.8 57.155.756.9 63.3 59.9 55.452.7 58.4 55.450.955.0 61.4 58.150.556.660.752.356.656.157.951.553.321222324CEAF resultsMention-ranking model (Pipeline)Mention-ranking model (Joint)Cluster-ranking model (Pipeline)Cluster-ranking model (Joint)Combined feature set53.7 58.8 56.154.9 61.7 58.155.1 60.1 57.458.4 65.1 61.658.756.360.062.555.955.557.959.553.454.956.156.7(b) CEAF resultsTable 6: SVM vs. MaxEnt results ranking-basd coreference models. one-fold B3CEAF scores obtained training coreference models using SVM MaxEnt. bestF-measure achieved feature set/scoring program combination boldfaced.501fiRahman & Ng1234567Source Anaphoricity InformationAnaphoricity ClassifierMention-ranking (Conventional)Cluster-ranking (Conventional)Mention-ranking (Lexical)Cluster-ranking (Lexical)Mention-ranking (Combined)Cluster-ranking (Combined)Acc81.178.781.984.283.179.183.1R87.683.187.888.387.984.387.4P80.379.380.482.181.879.182.1F83.881.283.985.184.781.684.6Table 7: Anaphoricity determination results.well precision, recall, F-measure identifying anaphoric mentions. Sinceperformance numbers derived output joint model, computetwo joint ranking models (i.e., mention-ranking modelcluster-ranking model) used combination three coreference featuresets (i.e., Conventional, Lexical, Combined). results six sets performancenumbers, shown rows 27 Table 4. see, accuracies range78.7 84.2, F-measure scores range 81.2 85.1.comparison results anaphoricity classifier shown row 1, seejoint modeling improves performance anaphoricity determination except twocases, namely, mention-ranking/Conventional mention-ranking/Combined.words, two cases, joint modeling benefits coreference resolution anaphoricity determination. seems counter-intuitive one achieve better coreferenceperformance lower accuracy determining anaphoricity, difficultsee reason: joint model trained maximize pairwise ranking accuracy,presumably correlates coreference performance, whereas anaphoricity classifier trained maximize accuracy determining anaphoricity mention,may always correlation coreference performance. words,improvements anaphoricity accuracy generally necessarily imply correspondingimprovements clustering-level coreference accuracy.Finally, important bear mind conclusions drawn regardingpipeline joint modeling based results anaphoricity classifier trained26 features. possible different conclusions could drawn trainedanaphoricity classifier different set features. Therefore, interesting future directionwould improve anaphoricity classifier employing additional features,proposed Uryupina (2003). may also able derive sophisticated featuresharnessing recent advances lexical semantics research, specifically using methodsphrase clustering (e.g., Lin & Wu, 2009), lexical chain discovery (e.g., Morris & Hirst,1991), paraphrase discovery (see survey papers Androutsopoulos & Malakasiotis,2010; Madnani & Dorr, 2010).502fiA Cluster-Ranking Approach Coreference Resolution7.4 Joint Inference Versus Joint Learning Mention-Pair Modelmentioned end Section 4.2, joint modeling anaphoricity determinationcoreference resolution fundamentally different joint inference two tasks.Recall joint inference using ILP, anaphoricity classifier coreference classifiertrained independently other, ILP applied postprocessing stepjointly infer anaphoricity coreference decisions consistent(e.g., Denis & Baldridge, 2007a). subsection, investigate joint learningcompares joint inference anaphoricity determination coreference resolution.Let us begin overview ILP approach proposed Denis Baldridge(2007a) joint inference anaphoricity determination coreference resolution.ILP approach motivated observation output anaphoricity modelcoreference model given document satisfy certain constraints.instance, coreference model determines mention mk coreferentmentions associated text, anaphoricity model determinemk non-anaphoric. practice, however, since two models trained independentlyother, constraints cannot enforced.Denis Baldridge (2007a) provide ILP framework jointly determining anaphoricity coreference decisions given set mentions based probabilities providedanaphoricity model PA mention-pair coreference model PC ,resulting joint decisions satisfy desired constraints respecting much possible probabilistic decisions made independently-trained PA PC . Specifically, ILP program composed objective function optimized subjectset linear constraints, created test text follows. Letset mentions D, P set mention pairs formed (i.e., P ={(mj , mk ) | mj , mk M, j < k}). ILP program set indicator variables.case, one binary-valued variable anaphoricity decision coreferencedecision made ILP solver. Following Denis Baldridges notation, useyk denote anaphoricity decision mention mk , xhj,ki denote coreferencedecision involving mentions mj mk . addition, variable associatedassignment cost. Specifically, let cChj,ki = log(PC (mj , mk )) cost setting xhj,kiC1, chj,ki = log(1 PC (mj , mk )) complementary cost setting xhj,ki 0.similarly define cost associated yk , letting cAk = log(PA (mk ))=log(1P(m))complementarycost settingcost setting yk 1, cAkkyk 0. Given costs, aim optimize following objective function:minXCcChj,ki xhj,ki + chj,ki (1 xhj,ki ) +XcAk yk + ck (1 yk )mk(mj ,mk )Psubject set manually-specified linear constraints. Denis Baldridge specify fourtypes constraints: (1) indicator variable take value 0 1; (2) mjmk coreferent (xhj,ki =1), mk anaphoric (yk =1); (3) mk anaphoric (yk =1),must coreferent preceding mention mj ; (4) mk non-anaphoric,cannot coreferent mention.Two points deserve mention. First, minimizing objective function, sinceassignment cost expressed negative logarithm value. Second, since transitivity503fiRahman & Ngguaranteed constraints23 , use closest-link clustering algorithmput two mentions posited coreferent cluster. Notebest-link clustering strategy applicable here, since binary decision assignedpair mentions ILP solver. use lp solve24 , publicly-available ILP solver,solve program.B3 CEAF results performing joint inference outputs anaphoricitymodel mention-pair model using ILP shown Joint Inference columnTables 8a 8b, respectively, rows correspond results obtained trainingcoreference models different feature sets. Since one goals compare jointinference joint learning, also show Joint Learning column resultsjoint mention-ranking model, anaphoricity determination coreference resolutionlearned joint fashion. Note reason using mention-ranking model(rather cluster-ranking model) joint model want ensurefair comparison joint learning joint inference much possible: chosencluster-ranking model joint model, difference joint learning resultsjoint inference results could caused increased expressivenesscluster-ranking model. Finally, better understand whether mention-pair modelbenefits joint inference using ILP, show Inference column relevantmention-pair model results Table 4, output model postprocessedinference mechanism.Table 8, see joint learning results substantially betterjoint inference results, except one case (Conventional/CEAF), two achievecomparable performance. Previous work Roth (2002) Roth Yih (2004)suggested often effective learn simple local models use complicatedintegration strategies make sure constraints output satisfied learnmodels satisfy constraints directly. results imply truecoreference task.Comparing joint inference Inference results Table 8, seemention-pair model benefit application ILP. fact, performancedeteriorates ILP used. results inconsistent reported DenisBaldridge (2007a), show joint inference using ILP improve mentionpair model. speculate inconsistency accures fact DenisBaldridge evaluate ILP approach true mentions (i.e., gold-standard mentions),evaluate system mentions. Additional experiments needed determinereason, however.7.5 Data Source AdaptabilityOne may argue since train test model documents datasource (i.e., model trained documents BC tested documents23. Finkel Manning (2008) show formulate linear constraints ILP solver outputscoreference decisions satisfy transitivity. However, since number additional constraints neededguarantee transitivity grows cubically number mentions previous work showsadditional constraints yield substantial performance improvements appliedsystem mentions (Ng, 2009), decided employ experiments.24. Available http://lpsolve.sourceforge.net/504fiA Cluster-Ranking Approach Coreference Resolution123Feature SetConventionalLexicalCombinedJoint LearningRPF47.6 74.8 58.254.6 72.8 62.450.5 77.6 61.2Joint InferenceRPF58.2 55.9 57.049.1 70.1 57.853.2 56.9 54.9R59.652.850.3InferencePF55.3 57.364.6 58.165.9 57.0R51.453.554.9InferencePF56.5 53.856.8 55.156.3 55.5(a) B3 results123Feature SetConventionalLexicalCombinedJoint LearningRPF50.5 56.3 53.256.9 63.3 59.954.9 61.7 58.1Joint InferenceRPF49.7 57.5 53.350.6 58.6 54.353.2 56.9 54.9(b) CEAF resultsTable 8: Joint learning vs. joint inference results. joint modeling results obtainedusing mention-ranking model. joint inference results obtained applying ILPanaphoricity classifier mention-pair model. inference results producedmention-pair model. coreference models trained using MaxEnt.BC, example), surprising lexicalization helps, since word pairstraining set likely found test set training test textsdata source. examine whether models employ Lexical featuressuffer trained tested different data sources, perform set datasource adaptability experiments, apply coreference model trainedLexical features documents one data source documents data sources.Here, show results obtained using mention-ranking model, primarilyyielded best performance Lexical features among learning-based coreferencemodels. comparison, also show data source adaptability results obtained usingmention-ranking model trained (non-lexical) Conventional feature set.B3 CEAF F-measure scores experiments shown Tables 9a9b, left half right half table contain lexicalized mention-rankingmodel results unlexicalized mention-ranking model results, respectively. rowcorresponds data source model trained, except last two rows,explain shortly. column corresponds test set particular datasource.answer question whether performance coreference model employsLexical features deteriorate trained tested different data sources,look diagonal entries left half Tables 9a 9b, containresults obtained lexicalized mention-ranking model trained testeddocuments source. model indeed performs worse trainedtested documents different sources, diagonal entry containhighest score among entries column. see left halftwo tables, large extent correct: four six diagonal entries containhighest scores respective columns according scoring programs. provides505fiRahman & NgLexical featuresPPPP TestTrain PPPPBCBNCTSNWUNWLMaxMinStd. Dev.Conventional featuresBCBNCTS NW UNWLBCBNCTS NW UNWL56.557.655.555.656.456.42.10.7661.063.561.162.162.862.82.51.0158.760.762.756.760.058.56.02.0766.667.065.959.267.368.79.53.3652.151.851.851.552.751.51.20.4555.959.758.455.357.356.54.41.6455.158.459.555.759.255.14.42.0963.862.864.260.364.264.03.91.5264.263.561.965.462.963.43.51.1857.255.454.956.456.355.92.30.8159.158.759.258.559.059.00.70.2652.852.553.652.153.252.71.50.53(a) B3 resultsLexical featuresPPPP TestTrain PPPPBCBNCTSNWUNWLMaxMinStd. Dev.Conventional featuresBCBNCTS NW UNWLBCBNCTS NW UNWL52.053.851.950.552.553.43.31.1857.261.358.658.960.361.14.11.6055.558.862.053.358.355.78.73.0765.766.064.854.567.067.112.74.8246.045.944.745.546.045.71.30.5049.354.852.349.251.350.45.62.1152.755.256.552.656.251.45.12.1460.860.161.056.560.861.14.61.7761.560.558.462.759.359.84.31.5556.554.153.754.655.755.02.81.0453.152.953.852.752.852.91.10.4049.148.050.048.448.850.12.10.85(b) CEAF resultsTable 9: Results data source adaptability. row shows results obtained trainingmention ranking model data set shown first column row, columncorresponds test set particular data source. best result obtained test settwo coreference models boldfaced.suggestive evidence answer question affirmative. Nevertheless, lookright half two tables, show results obtained using unlexicalizedmention-ranking model, see similar, perhaps weaker, trend: according CEAF,four six diagonal entries contain highest scores respective columns,according B3 , two six diagonal entries exhibit trend. Hence, factmodel performs worse trained tested different data sources cannotattributed solely lexicalization.Perhaps informative question is: lexicalized models trained different datasources exhibit varied performance given test set (composed documentssource) unlexicalized models trained different data sources? affirmativeanswer question provide empirical support hypothesis lexicalizedmodel fits data trained unlexicalized counterpart. answerquestion, compute column two models (1) differencehighest lowest scores (see MaxMin row), (2) standarddeviation six scores corresponding column (see Std. Dev. row).506fiA Cluster-Ranking Approach Coreference Resolutioncompare corresponding columns two coreference models, see exceptBN, lexicalized model exhibit varied performance given test setunlexicalized model according scoring programs, regardless whethermeasuring variation using MaxMin standard deviation.7.6 Feature Analysissubsection, analyze effects linguistic features performancecoreference models. Given large number models trained threefeature sets, feasible us analyze features model featureset. Since cluster-ranking model, used Combined feature set, yieldsbest performance, analyze features. addition, since Lexical featuresyielded good performance mention-ranking model, would informative seeLexical features greatest contribution performance. result,perform feature analysis two model/feature set combinations.Although identified two particular model/feature set combinations, actuallytotal 12 model/feature set combinations: recall except row 1, rowTable 4 shows aggregated result six data sets, trained one modeldata set. words, two combinations selected above,six learned models. reduce number models need analyze yet maximizeinsights gain, choose analyze models trained data setstwo fairly different domains: Newswire (NW) Broadcast News (BN).next question is: analyze features? apply backward elimination feature selection algorithm (see survey paper Blum & Langley, 1997),starts full feature set removes iteration feature whose removalyields best system performance. Despite greedy nature, algorithm runs timequadratic number features, making computationally expensive runfeature sets. reduce computational cost, divide features feature typesapply backward elimination eliminate one feature type per iteration.features grouped follows. Lexical feature set, divide featuresfive types: (1) unseen features, (2) lexical features, (3) semi-lexical features, (4) distance, (5) alias. words, division corresponds roughly one describedSection 5.1, except put two conventional features two different groups,since linguistically one positional feature semantic feature.Combined feature set, divide features seven groups, first fouridentical division Lexical features above. remaining features,divide string-matching features, comprise features 1118 Table 1;grammatical features, comprise features 17, 910, 1929, 3336, 3839;semantic features, comprise features 8, 30, 31. Note alias, semantic feature Lexical feature set, combined semantic featuresConventional feature set form semantic feature type.Results shown Tables 1013. Specifically, Tables 10a 10b show B3CEAF F-measure scores feature analysis experiments involving mention-rankingmodel, using Lexical feature set NW data set. table, first row showssystem would perform class features removed. remove least507fi60.660.159.260.762.453.159.760.963.360.161.864.663.5eenUnsliaistcei-lexicalSeLexicalRahman & Ng65.258.444.753.454.756.055.053.555.660.755.358.761.759.3eenUnsliaistceLexicalSei-lexical(a) B3 results62.1(b) CEAF resultsTable 10: Feature analysis results (in terms F-measure scores) mention-rankingmodel using Lexical features NW data set. feature types used trainmodel, B3 CEAF F-measure scores 65.4 62.7, respectively.important feature class (i.e., feature class whose removal yields best performance),next row shows adjusted system would perform without remainingclass. According scoring programs, removing unseen features yields leastdrop performance (note caption full feature set, B3 score65.4 CEAF score 62.7). fact, two scorers agree lexicalsemi-lexical features important unseen, alias, distance features.Nevertheless, results suggest five feature types important, since bestperformance achieved using full feature set.Tables 11a 11b show B3 CEAF F-measure scores feature analysisexperiments involving cluster-ranking model, using Combined feature set NWdata set. Recall Combined feature set, seven types features.see, two scorers agree completely order features removed.particular, important features lexical semi-lexical features,whereas least important features present Lexical featureset, namely, grammatical, string-matching, semantic features. suggestslexical features general important non-lexical featuresused combination. somewhat surprising, non-lexical featurescommonly-used features coreference resolution, whereas Lexical featurescomparatively much less investigated coreference researchers. Nevertheless, unlikesaw Table 10, feature types appear relevant, Table 11a, see508fi57.658.659.963.9icalchgticSe59.760.262.4Gra58.558.858.957.563.8istceUnseeni-lexical59.760.461.162.361.967.2Strin54.756.658.958.363.263.2SeLexicalCluster-Ranking Approach Coreference Resolution59.661.160.455.656.958.860.0icalchgticSe57.758.560.1Gra56.957.658.256.760.0istceUnseeni-lexical53.354.357.157.255.361.9Strin50.250.651.451.057.957.9SeLexical(a) B3 results58.460.658.7(b) CEAF resultsTable 11: Feature analysis results (in terms F-measure) cluster-ranking modelusing Combined features NW data set. feature types used trainmodel, B3 CEAF F-measure scores 64.6 62.3, respectively.best B3 F-measure score 67.2, achieved using lexical features.represents 2.6% absolute gain F-measure model trained sevenfeature types, suggesting learning-based coreference model could improved via featureselection.Next, investigate whether similar trends observed models traineddifferent source: Broadcast News. Specifically, show Tables 12a 12b B3CEAF F-measure scores feature analysis experiments involving mentionranking model, using Lexical feature set BN data set. Table 11,see two scorers agree completely order featuresremoved. fact, similar observed Table 10 (on NW data set),scorers determine lexical semi-lexical features important,whereas distance alias features least important, although five featuretypes appear relevant according scorers.Finally, show Tables 13a 13b B3 CEAF F-measure scores featureanalysis experiments involving cluster-ranking model, using Combined feature set509fi53.453.452.352.962.762.361.261.660.959.961.762.962.9liaeenUnsistcei-lexicalSeLexicalRahman & Ng63.447.147.144.945.559.659.157.457.558.657.858.059.960.0liaeenUnsistcei-lexicalSeLexical(a) B3 results61.2(b) CEAF resultsTable 12: Feature analysis results (in terms F-measure) mention-ranking modelusing Lexical features BN data set. feature types used trainmodel, B3 CEAF F-measure scores 63.5 61.3, respectively.BN data set. Tables 11 12, two scorers agree completely orderfeatures removed. far feature contribution concerned, twotables resemble Tables 11a 11b: cases, lexical, semi-lexical, unseenfeatures important; string-matching grammatical featuresleast important; semantic distance features middle. case,however, seven feature types seem relevant, best performance achievedusing full feature set according scorers. Perhaps interestingly, numberscolumn generally increasing move column. meansfeature type becomes progressively less useful remove feature types.also suggests interactions different feature types non-trivialfeature type may useful presence another feature type.summary, results two data sets (NW BN) two scoring programs demonstrate (1) general feature types crucial overall performance, (2)little-investigated Lexical features contribute overall performancecommonly-used Conventional features.7.7 Resolution Performancegain additional insights results, analyze behavior coreferencemodels different types anaphoric expressions trained differentfeature sets. Specifically, partition mentions different resolution classes.510fiaticalch51.853.356.6gistcetic51.254.360.661.3Gra52.353.956.659.561.3SeUnseeni-lexical52.754.256.960.457.460.6Strin54.755.255.455.556.956.9SeLexicalCluster-Ranking Approach Coreference Resolution53.955.654.8icalch47.150.058.5gistcetic44.351.054.057.7Gra45.250.754.957.057.1SeUnseeni-lexical45.751.352.956.750.555.4Strin44.444.345.546.348.548.6SeLexical(a) B3 results46.451.852.1(b) CEAF resultsTable 13: Feature analysis results (in terms F-measure) cluster-ranking modelusing Combined features BN data set. feature types used trainmodel, B3 CEAF F-measure scores 63.6 61.3, respectively.previous work focused mainly three rather coarse-grained resolution classes (namely,pronouns, proper nouns, common nouns), follow Stoyanov et al. (2009) subdivideclass three fine-grained classes. worth mentioning none Stoyanov etal.s classes corresponds non-anaphoric expressions. Since believe non-anaphoricexpressions play important role analysis performance coreferencemodel, propose three additional classes correspond non-anaphoric pronouns,non-anaphoric proper nouns, non-anaphoric common nouns. Finally, certaintypes anaphoric pronouns (e.g., wh-pronouns) fall Stoyanov etal.s pronoun categories. fill gap, create another category servesdefault category anaphoric pronouns covered Stoyanov et al.s classes.results 13 resolution classes, discussed detail.Proper nouns. Four classes defined proper nouns. (1) e: proper noun assignedexact string match class preceding mention twocoreferent string; (2) p: proper noun assigned partial stringmatch class preceding mention two coreferent511fiRahman & Ngcontent words common; (3) n: proper noun assigned string match classpreceding mention two coreferent contentwords common; (4) na: proper noun assigned non-anaphor classcoreferent preceding mention.Common nouns. Four analogous resolution classes defined mentions whose headcommon noun: (5) e; (6) p; (7) n; (8) na.Pronouns. three pronoun classes. (9) 1+2: 1st 2nd person pronouns; (10)G3: gendered 3rd person pronouns (e.g., she); (11) U3: ungendered 3rd person pronouns;(12) oa: anaphoric pronouns belong (9), (10), (11); (13) na:non-anaphoric pronouns.Next, score resolution class. Unlike Stoyanov et al. (2009), use modifiedversion MUC scorer, employ B3 . reasons MUC scorer (1)reward singleton clusters, (2) inflate systems performance clustersoverly large. compute score class C, process mentions test textleft-to-right manner. mention encountered, check whether belongs C.so, use coreference model decide resolve it. Otherwise, use oraclemake correct resolution decision25 (so end mistakes attributedincorrect resolution mentions C, thus allowing us directly measureimpact overall performance). test documents processed, computeB3 F-measure score mentions belong C.Performance resolution class, aggregated test sets six datasources way before, shown Table 14, provides nice diagnosisstrengths weaknesses coreference model used combinationfeature set. also show table percentage mentions belongingclass name class, abbreviate name model follows: HMcorresponds head match baseline, whereas MP, EM, MR, CR denote mentionpair model, entity-mention model, mention-ranking model, cluster-rankingmodel, respectively. ranking model two versions, pipeline version (denotedP) joint version (denoted J).points deserve mention. Recall Table 4 Conventional featuresused, joint mention-ranking model performs better mention-pair modelentity-mention model. Comparing row 5 rows 2 3 Table 14,see improvements attributed primarily better handling one proper25. oracle determines mention anaphoric antecedents cluster(because model previously made mistake), employ following heuristic selectantecedent resolve mention to: try resolve closest preceding antecedentbelong class C, antecedent exists, resolve closest preceding antecedentbelongs class C. reason behind heuristics preference preceding antecedentbelong class C simple: since resolving mention using oracle, want chooseantecedent allows us maximize overall score; resolving mention antecedentbelong C likely yield better score resolving antecedentbelongs C, since former resolved using oracle latter not. heuristicapplies trying use oracle resolve mention preceding cluster: first attemptresolve closest preceding cluster containing mention belong C,antecedent exists, resolve closest preceding cluster containing mention belongs C.512fiA Cluster-Ranking Approach Coreference ResolutionProper nounspnna1.63.213.9e6.3Common nounspnna0.34.719.2Class%e15.21HM68.333.034.463.548.1234567MPEMMR-PMR-JCR-PCR-J69.669.978.379.479.979.935.435.941.142.542.543.935.635.932.733.434.234.4Using65.865.876.076.475.976.78910111213MPEMMR-PMR-JCR-PCR-J78.879.178.379.575.376.441.941.866.467.165.768.432.132.440.741.340.441.1Using Lexical feature set78.6 66.5 54.2 24.1 77.678.4 66.5 54.7 24.1 77.975.8 53.2 60.7 28.3 83.376.3 54.4 61.1 28.6 83.576.6 50.2 61.4 30.3 81.977.2 50.8 63.2 31.1 83.1141516171819MPEMMR-PMR-JCR-PCR-J73.873.976.477.278.379.940.140.650.952.361.362.038.839.233.334.741.542.4Using67.6 55.968.2 56.380.7 53.482.0 54.378.3 60.979.1 62.8PronounsU3oa5.14.41+215.1G34.950.746.341.723.255.7Conventional feature set56.1 54.7 24.0 70.4 53.857.3 55.1 24.3 70.9 54.248.5 58.3 27.2 78.2 54.148.2 59.0 27.6 78.5 54.464.1 58.6 27.1 80.8 57.965.0 59.2 27.4 82.1 58.655.656.057.157.761.862.546.146.444.945.849.750.724.124.622.723.025.626.351.951.761.662.258.159.755.555.762.162.660.361.957.457.860.662.361.062.644.144.147.347.950.651.824.324.229.131.336.237.661.862.161.862.666.367.058.658.758.359.562.162.760.761.656.159.565.566.249.349.644.345.851.452.827.626.225.826.534.735.558.158.366.467.162.764.455.624.768.1Combined feature set54.8 25.0 73.755.8 25.0 74.455.4 23.2 78.956.8 24.7 80.955.4 24.4 79.356.8 25.5 79.9na6.1Table 14: B3 F-measure scores different resolution classes.noun class (e) three classes correspond non-anaphoric mentions (na).results indicate important take account non-anaphoric mentionsanalyzing performance coreference model. time, seejoint mention-ranking model resolve type e common nouns wellmention-pair model entity-mention model. Also, results rows 5 7 indicatejoint cluster-ranking model better joint mention-ranking model duebetter handling type e common nouns, non-anaphoric common nouns,well anaphoric pronouns.Next, recall Table 4 Lexical features used lieu Conventional features, mention-pair model, entity-mention model, joint mentionranking model exhibit significant improvements performance. mention-pairmodel entity-mention model, improvements stem primarily better handling three proper noun classes (e,p,na), two common noun classes (e,na), nonanaphoric pronouns (compare rows 2 8 well rows 3 9 Table 14). jointmention-ranking model, hand, improvements accrue better handlingtwo proper noun classes (p,n), two common classes (e,na), anaphoric pronouns,513fiRahman & Ngseen rows 5 11. joint cluster-ranking model showoverall improvement switch Conventional Lexical features (compare rows 713), resulting models behave differently. Specifically, using Lexical features,model gets worse handling one proper noun class (e) one common noun class (e),better handling another proper noun class (n), two common noun classes (p,n),one anaphoric pronoun class (1+2), non-anaphoric pronouns.Finally, recall Combined features used lieu Lexical features,cluster-ranking model show deterioration performance. mention-pairmodel entity-mention model, deterioration performance attributedpoorer handling two proper noun classes (e,na), two common noun classes (e,na),non-anaphoric pronouns, although better handling one proper nounclass (n) anaphoric pronouns (compare rows 8 14 well rows 9 15Table 14). Overall, poorer handling anaphoricity appears major factor responsibleperformance deterioration. joint mention-ranking model, reasonsperformance deterioration slightly different: comparing rows 11 17, see poorerhandling two proper noun classes (p,n), three common noun classes (p,n,na),anaphoric pronouns, although better handling non-anaphoric proper nounspronouns. mentioned before, two versions cluster-ranking model improvetrained Combined features. However, improvements stemimprovements classes (compare rows 12 18 well rows 13 19).instance, replacing Lexical features Combined features jointcluster-ranking model, see improvements two proper noun classes (e,na), one commonnoun class (e), several pronoun classes (1+2,G3,U3), performance drops anotherproper noun class (p), three common noun classes (p,n,na), two pronoun classes(oa,na).Overall, results provide us additional insights strengths weaknesses learning-based coreference model well directions future work. particular, even two models yield similar overall performance, quite differentresolution class level. Since single coreference model outperformsothers resolution classes, may beneficial apply ensemble approach,anaphor belonging particular resolution class resolved model offersbest performance class.8. ConclusionsMitkov (2001, p. 122) puts it, coreference resolution difficult, intractableproblem, researchers making steady progress improving machine learning approaches problem past fifteen years. progress slow, however.Despite deficiencies, mention-pair model widely thought learningbased coreference model almost decade. entity-mention model mentionranking model emerged mention-pair model dominated learning-basedcoreference research nearly ten years. Although two models conceptually simple, represent significant departure mention-pair model new waythinking alternative models coreference designed. cluster-rankingmodel advances learning-based coreference research theoretically combining514fiA Cluster-Ranking Approach Coreference Resolutionstrengths two models, thereby addressing two commonly cited weaknessesmention-pair model. bridges gap two independent lines learningbased coreference research one concerning entity-mention modelmention-ranking model going past years, also narrows modeling gap sophistication rule-based coreference modelssimplicity learning-based coreference models. Empirically, shown usingACE 2005 coreference data set cluster-ranking model acquired jointly learninganaphoricity determination coreference resolution surpasses performance severalcompeting approaches, including mention-pair model, entity-mention model,mention-ranking model. Perhaps equally importantly, cluster-ranking modelmodel considered profitably exploit information provided twofairly different sources information, Conventional features Lexical features.ranking natural formulation coreference resolution classification,ranking-based coreference models popularly used influentialmention-pair model. One goals article promote application rankingtechniques coreference resolution. Specifically, attempted clarify difference classification-based ranking-based coreference models showing constrainedoptimization problem SVM learner needs solve type models, hopinghelp reader appreciate importance ranking coreference resolution. addition, provided ample empirical evidence ranking-based modelssuperior classification-based models coreference resolution.Another contribution work lies empirical demonstration benefitslexicalizing learning-based coreference models. previous work showed lexicalization provides marginal benefits coreference model, showed lexicalization significantly improve mention-pair model, entity-mention model,mention-ranking model, point approach even surpass performancecluster-ranking model. Interestingly, showed models benefit lexicalization conventional coreference features used. challengescommon belief prototypical set linguistic features (e.g., gendernumber agreement) must used constructing learning-based coreference systems.addition, feature analysis experiments indicated conventional features contributed less overall performance rarely studied lexical features jointcluster-ranking coreference model two types features used combination.Finally, examined performance coreference model resolving mentionsbelonging different resolution classes. found even two models achieve similaroverall performance, quite different resolution class level. Overall,results provide us additional insights strengths weaknesses learningbased coreference model well promising directions future research.Bibliographic NotePortions work previously presented conference publication (Rahman &Ng, 2009). current article extends work several ways, notably: (1)overview literature ranking approaches coreference resolution (Section 2); (2)detailed explanation difference classification ranking (Section 3); (3)515fiRahman & Nginvestigation issues lexicalizing coreference models (Section 5); (4) in-depthanalysis different aspects coreference system (Section 7).Acknowledgmentsauthors acknowledge support National Science Foundation (NSF) grant IIS0812261. thank three anonymous reviewers insightful comments unanimously recommending article publication JAIR. opinions, findings, conclusions recommendations expressed article authorsnecessarily reflect views official policies, either expressed implied, NSF.ReferencesAndroutsopoulos, I., & Malakasiotis, P. (2010). survey paraphrasing textualentailment methods. Journal Artificial Intelligence Research, 38 , 135187.Aone, C., & Bennett, S. W. (1995). Evaluating automated manual acquisitionanaphora resolution strategies. Proceedings 33rd Annual MeetingAssociation Computational Linguistics (ACL), pp. 122129.Bagga, A., & Baldwin, B. (1998). Algorithms scoring coreference chains. ProceedingsLinguistic Coreference Workshop First International ConferenceLanguage Resources Evaluation (LREC), pp. 563566.Barbu, C., & Mitkov, R. (2001). Evaluation tool rule-based anaphora resolution methods. Proceedings 39th Annual Meeting Association ComputationalLinguistics (ACL), pp. 3441.Bengtson, E., & Roth, D. (2008). Understanding values features coreferenceresolution. Proceedings 2008 Conference Empirical Methods NaturalLanguage Processing (EMNLP), pp. 294303.Berger, A. L., Della Pietra, S. A., & Della Pietra, V. J. (1996). maximum entropyapproach natural language processing. Computational Linguistics, 22 (1), 3971.Bikel, D. M., Schwartz, R., & Weischedel, R. M. (1999). algorithm learns whatsname. Machine Learning: Special Issue Natural Language Learning, 34 (13),211231.Blum, A., & Langley, P. (1997). Selection relevant features examples machinelearning. Artificial Intelligence, 97 (12), 245271.Burges, C. J. C. (1998). tutorial support vector machines pattern recognition.Data Mining Knowledge Discovery, 2 (2), 121167.Cai, J., & Strube, M. (2010). Evaluation metrics end-to-end coreference resolutionsystems. Proceedings 11th Annual SIGdial Meeting Discourse Dialogue(SIGDIAL), pp. 2836.Carbonell, J., & Brown, R. (1988). Anaphora resolution: multi-strategy approach.Proceedings 12th International Conference Computational Linguistics (COLING), pp. 96101.516fiA Cluster-Ranking Approach Coreference ResolutionCardie, C., & Wagstaff, K. (1999). Noun phrase coreference clustering. Proceedings1999 Joint SIGDAT Conference Empirical Methods Natural LanguageProcessing Large Corpora (EMNLP/VLC), pp. 8289.Charniak, E., & Elsner, M. (2009). EM works pronoun anaphora resolution. Proceedings 12th Conference European Chapter Association Computational Linguistics (EACL), pp. 148156.Collins, M. J. (1999). Head-Driven Statistical Models Natural Language Parsing. Ph.D.thesis, Department Computer Information Science, University Pennsylvania,Philadelphia, PA.Connolly, D., Burger, J. D., & Day, D. S. (1994). machine learning approach anaphoricreference. Proceedings International Conference New Methods LanguageProcessing, pp. 255261.Culotta, A., Wick, M., & McCallum, A. (2007). First-order probabilistic models coreference resolution. Human Language Technologies 2007: Conference NorthAmerican Chapter Association Computational Linguistics; ProceedingsMain Conference (NAACL HLT), pp. 8188.Daume III, H., & Marcu, D. (2005). large-scale exploration effective global featuresjoint entity detection tracking model. Proceedings Human LanguageTechnology Conference Conference Empirical Methods Natural LanguageProcessing (HLT/EMNLP), pp. 97104.Denis, P., & Baldridge, J. (2007a). Global, joint determination anaphoricity coreference resolution using integer programming. Human Language Technologies 2007:Conference North American Chapter Association ComputationalLinguistics; Proceedings Main Conference (NAACL HLT), pp. 236243.Denis, P., & Baldridge, J. (2007b). ranking approach pronoun resolution. ProceedingsTwentieth International Conference Artificial Intelligence (IJCAI), pp. 15881593.Denis, P., & Baldridge, J. (2008). Specialized models ranking coreference resolution.Proceedings 2008 Conference Empirical Methods Natural LanguageProcessing (EMNLP), pp. 660669.Enrique, A., Gonzalo, J., Artiles, J., & Verdejo, F. (2009). comparison extrinsic clustering evaluation metrics based formal constraints. Information Retrieval, 12 (4),461486.Fellbaum, C. (1998). WordNet: electronic lexical database. MIT Press, Cambridge, MA.Finkel, J. R., Grenager, T., & Manning, C. (2005). Incorporating non-local informationinformation extraction systems Gibbs sampling. Proceedings 43rd AnnualMeeting Association Computational Linguistics (ACL), pp. 363370.Finkel, J. R., & Manning, C. (2008). Enforcing transitivity coreference resolution.Proceedings ACL-08: HLT Short Papers (Companion Volume), pp. 4548.Florian, R., Hassan, H., Ittycheriah, A., Jing, H., Kambhatla, N., Luo, X., Nicolov, N., &Roukos, S. (2004). statistical model multilingual entity detection tracking.HLT-NAACL 2004: Main Proceedings, pp. 18.517fiRahman & NgGe, N., Hale, J., & Charniak, E. (1998). statistical approach anaphora resolution.Proceedings Sixth Workshop Large Corpora (WVLC), pp. 161170.Grosz, B. J., Joshi, A. K., & Weinstein, S. (1983). Providing unified account definite noun phrases discourse. Proceedings 21th Annual MeetingAssociation Computational Linguistics (ACL), pp. 4450.Grosz, B. J., Joshi, A. K., & Weinstein, S. (1995). Centering: framework modelinglocal coherence discourse. Computational Linguistics, 21 (2), 203226.Haghighi, A., & Klein, D. (2010). Coreference resolution modular, entity-centeredmodel. Human Language Technologies: 2010 Annual Conference NorthAmerican Chapter Association Computational Linguistics (NAACL HLT),pp. 385393.Hobbs, J. (1978). Resolving pronoun references. Lingua, 44, 311338.Iida, R., Inui, K., & Matsumoto, Y. (2009). Capturing salience trainable cachemodel zero-anaphora resolution. Proceedings Joint Conference 47thAnnual Meeting ACL 4th International Joint Conference NaturalLanguage Processing AFNLP (ACL-IJCNLP), pp. 647655.Iida, R., Inui, K., Takamura, H., & Matsumoto, Y. (2003). Incorporating contextual cuestrainable models coreference resolution. Proceedings EACL WorkshopComputational Treatment Anaphora.Ji, H., Rudin, C., & Grishman, R. (2006). Re-Ranking algorithms name tagging.Proceedings Workshop Computationally Hard Problems Joint InferenceSpeech Language Processing, pp. 4956.Ji, H., Westbrook, D., & Grishman, R. (2005). Using semantic relations refine coreferencedecisions. Proceedings Human Language Technology Conference ConferenceEmpirical Methods Natural Language Processing (HLT/EMNLP), pp. 1724.Joachims, T. (1999). Making large-scale SVM learning practical. Scholkopf, B., Burges,C., & Smola, A. (Eds.), Advances Kernel Methods Support Vector Learning, pp.4456. MIT Press, Cambridge, MA.Joachims, T. (2002). Optimizing search engines using clickthrough data. ProceedingsEighth ACM SIGKDD International Conference Knowledge DiscoveryData Mining (KDD), pp. 133142.Kehler, A., Appelt, D., Taylor, L., & Simma, A. (2004). (non)utility predicateargument frequencies pronoun interpretation. Proceedings Human Language Technology Conference North American Chapter AssociationComputational Linguistics (HLT/NAACL), pp. 289296.Kuhn, H. W. (1955). Hungarian method assignment problem. Naval ResearchLogistics Quarterly, 2, 8397.Lappin, S., & Leass, H. (1994). algorithm pronominal anaphora resolution. Computational Linguistics, 20 (4), 535562.Lin, D., & Wu, X. (2009). Phrase clustering discriminative learning. ProceedingsJoint Conference 47th Annual Meeting ACL 4th International518fiA Cluster-Ranking Approach Coreference ResolutionJoint Conference Natural Language Processing AFNLP (ACL-IJCNLP), pp.10301038.Luo, X. (2005). coreference resolution performance metrics. Proceedings HumanLanguage Technology Conference Conference Empirical Methods NaturalLanguage Processing (HLT/EMNLP), pp. 2532.Luo, X., Ittycheriah, A., Jing, H., Kambhatla, N., & Roukos, S. (2004). mentionsynchronous coreference resolution algorithm based Bell tree. Proceedings42nd Annual Meeting Association Computational Linguistics (ACL),pp. 135142.Madnani, N., & Dorr, B. (2010). Generating phrasal sentential paraphrases: surveydata-driven methods. Computational Linguistics, 36 (3), 341387.McCarthy, J., & Lehnert, W. (1995). Using decision trees coreference resolution. Proceedings Fourteenth International Conference Artificial Intelligence (IJCAI),pp. 10501055.Mitkov, R. (1998). Robust pronoun resolution limited knowledge. Proceedings36th Annual Meeting Association Computational Linguistics 17thInternational Conference Computational Linguistics (COLING/ACL), pp. 869875.Mitkov, R. (2001). Outstanding issues anaphora resolution. Gelbukh, A. (Ed.),Computational Linguistics Intelligent Text Processing, pp. 110125. Springer.Mitkov, R. (2002). Anaphora Resolution. Longman.Morris, J., & Hirst, G. (1991). Lexical cohesion computed thesaural relationsindicator struture text. Computational Linguistics, 17 (1), 2148.Morton, T. (2000). Coreference NLP applications. Proceedings 38th AnnualMeeting Association Computational Linguistics (ACL).MUC-6 (1995). Proceedings Sixth Message Understanding Conference (MUC-6).Morgan Kaufmann, San Francisco, CA.MUC-7 (1998). Proceedings Seventh Message Understanding Conference (MUC-7).Morgan Kaufmann, San Francisco, CA.Ng, V. (2009). Graph-cut-based anaphoricity determination coreference resolution.Proceedings 2009 Conference North American Chapter AssociationComputational Linguistics: Human Language Technologies (NAACL HLT), pp.575583.Ng, V., & Cardie, C. (2002a). Identifying anaphoric non-anaphoric noun phrasesimprove coreference resolution. Proceedings 19th International ConferenceComputational Linguistics (COLING), pp. 730736.Ng, V., & Cardie, C. (2002b). Improving machine learning approaches coreference resolution. Proceedings 40th Annual Meeting Association ComputationalLinguistics (ACL), pp. 104111.519fiRahman & NgPoesio, M., Uryupina, O., Vieira, R., Alexandrov-Kabadjov, M., & Goulart, R. (2004).Discourse-new detectors definite description resolution: survey preliminaryproposal. Proeedings ACL Workshop Reference Resolution.Ponzetto, S. P., & Strube, M. (2006). Exploiting semantic role labeling, WordNetWikipedia coreference resolution. Proceedings Human Language Technology Conference Conference North American Chapter AssociationComputational Linguistics (HLT/NAACL), pp. 192199.Rahman, A., & Ng, V. (2009). Supervised models coreference resolution. Proceedings 2009 Conference Empirical Methods Natural Language Processing(EMNLP), pp. 968977.Ravichandran, D., Hovy, E., & Och, F. J. (2003). Statistical QA - classifier vs. re-ranker:Whats difference? Proceedings ACL 2003 Workshop MultilingualSummarization Question Answering, pp. 6975.Recasens, M., & Hovy, E. (2011). BLANC: Implementing Rand Index coreferenceresolution. Natural Language Engineering (to appear).Roth, D. (2002). Reasoning classifiers.. Proceedings 13th European ConferenceMachine Learning (ECML), pp. 506510.Roth, D., & Yih, W.-T. (2009). linear programming formulation global inferencenatural language tasks.. Proceedings Eighth Conference ComputationalNatural Language Learning (CoNLL), pp. 18.Soon, W. M., Ng, H. T., & Lim, D. C. Y. (2001). machine learning approach coreferenceresolution noun phrases. Computational Linguistics, 27 (4), 521544.Stoyanov, V., Gilbert, N., Cardie, C., & Riloff, E. (2009). Conundrums noun phrasecoreference resolution: Making sense state-of-the-art. ProceedingsJoint Conference 47th Annual Meeting ACL 4th InternationalJoint Conference Natural Language Processing AFNLP (ACL-IJCNLP), pp.656664.Strube, M., & Muller, C. (2003). machine learning approach pronoun resolutionspoken dialogue. Proceedings 41st Annual Meeting AssociationComputational Linguistics (ACL), pp. 168175.Strube, M., Rapp, S., & Muller, C. (2002). influence minimum edit distancereference resolution. Proceedings 2002 Conference Empirical MethodsNatural Language Processing (EMNLP), pp. 312319.Toutanova, K., Klein, D., Manning, C. D., & Singer, Y. (2003). Feature-rich part-of-speechtagging cyclic dependency network. HLT-NAACL 2003: ProceedingsMain Conference, pp. 173180.Uryupina, O. (2003). High-precision identification discourse new unique nounphrases. Proceedings 41st Annual Meeting Association Computational Linguistics: Companion Volume, pp. 8086.Vapnik, V. N. (1995). Nature Statistical Learning. Springer, New York.520fiA Cluster-Ranking Approach Coreference ResolutionVilain, M., Burger, J., Aberdeen, J., Connolly, D., & Hirschman, L. (1995). modeltheoretic coreference scoring scheme. Proceedings Sixth Message Understanding Conference (MUC-6), pp. 4552.Walker, M., Joshi, A., & Prince, E. (Eds.). (1998). Centering Theory Discourse. OxfordUniversity Press.Yang, X., Su, J., Lang, J., Tan, C. L., & Li, S. (2008). entity-mention modelcoreference resolution inductive logic programming. Proceedings 46thAnnual Meeting Association Computational Linguistics: Human LanguageTechnologies (ACL-08: HLT), pp. 843851.Yang, X., Su, J., Zhou, G., & Tan, C. L. (2004). NP-cluster based approach coreferenceresolution. Proceedings 20th International Conference ComputationalLinguistics (COLING), pages 226232.Yang, X., Zhou, G., Su, J., & Tan, C. L. (2003). Coreference resolution using competitivelearning approach. Proceedings 41st Annual Meeting AssociationComputational Linguistics (ACL), pp. 176183.521fiJournal Artificial Intelligence Research 40 (2011) 1-24Submitted 09/10; published 01/11Non-Deterministic PoliciesMarkovian Decision ProcessesMahdi Milani FardJoelle Pineaummilan1@cs.mcgill.cajpineau@cs.mcgill.caReasoning Learning LaboratorySchool Computer Science, McGill UniversityMontreal, QC, CanadaAbstractMarkovian processes long used model stochastic environments. Reinforcement learning emerged framework solve sequential planning decision-makingproblems environments. recent years, attempts made apply methodsreinforcement learning construct decision support systems action selectionMarkovian environments. Although conventional methods reinforcement learningproved useful problems concerning sequential decision-making, cannot applied current form decision support systems, medical domains,suggest policies often highly prescriptive leave little room usersinput. Without ability provide flexible guidelines, unlikely methodsgain ground users systems.paper introduces new concept non-deterministic policies allow flexibility users decision-making process, constraining decisions remain nearoptimal solutions. provide two algorithms compute non-deterministic policiesdiscrete domains. study output running time method setsynthetic real-world problems. experiment human subjects, showhumans assisted hints based non-deterministic policies outperform human-onlycomputer-only agents web navigation task.1. IntroductionPlanning decision-making well studied AI community. Intelligentagents designed developed act in, interact with, variety environments. usually involves sensing environment, making decision usingintelligent inference mechanism, performing action environment (Russell & Norvig, 2003). Often times, process involves level learning, alongdecision-making process, make agent efficient performing intendedgoal.Reinforcement Learning (RL) branch AI tries develop computationalapproach solving problem learning interaction. RL processlearning dohow map situations actionsso maximize numericalreward signal (Sutton & Barto, 1998). Many methods developed solveRL problem different types environments different types agents. However,work RL focused autonomous agents robots softwareagents. RL controllers thus designed issue single action time-stepc2011AI Access Foundation. rights reserved.fiMilani Fard & Pineauexecuted acting agent. past years, methods developedRL community started used sequential decision support systems (Murphy,2005; Pineau, Bellemare, Rush, Ghizaru, & Murphy, 2007; Thapa, Jung, & Wang, 2005;Hauskrecht & Fraser, 2000). many systems, human makes finaldecision. Usability acceptance issues thus become important cases.RL methods therefore require level adaptation used decision supportsystems. adaptations main contribution paper.Medical domains among cases RL needs adaptation. AlthoughRL framework correctly models sequential decision-making complex medical scenarios, including long-term treatment design, standard RL methods cannot appliedmedical settings current form lack flexibility suggestions.requirements are, course, specific medical domains and, instance, mightneeded aircraft controller provides suggestions pilot.important difference decision support system classical RL problemstems fact decision support system, acting agent often humanbeing, course his/her decision process. Therefore, assumptioncontroller send one clear commanding signal acting agentappropriate. accurate assume aspect decision-making processinfluenced user system.view decision process particularly relevant two different situations.First, many practical cases, exact model system. Instead,may noisy model built finite number interactions environment.leads type uncertainty usually referred extrinsic uncertainty.RL algorithms ignore uncertainty assume model perfect. Howeverlook closely, performance optimal action based imperfect model mightstatistically different next best action. Bayesian approaches lookedproblem providing confidence measure agents performance (Mannor, Simester,Sun, & Tsitsiklis, 2007). cases acting agent human being, useconfidence measures provide user complete set actions, mightoptimal enough evidence differentiate. useruse his/her expertise make final decision. methods guaranteesuggestions provided system statistically meaningful plausible.hand, even complete knowledge systemidentify optimal action, might still actions roughly equalperformance. point, decision near-optimal options could leftacting agentnamely human using decision support system.could many advantages, ranging better user experience, increased robustnessflexibly. Among near-optimal solutions, user select based domainknowledge, preferences, captured system. instance,medical diagnosis system suggests treatments, providing physician severaloptions might useful final decision could made based knowledgepatients medical status, preferences regarding side effects.Throughout paper address latter issue combination theoreticalempirical investigations. introduce new concept non-deterministic policiescapture decision-making process intended decision support systems. policies2fiNon-Deterministic Policies Markovian Decision Processesinvolve suggesting set actions, non-deterministic choice madeuser. apply formulation solve problem finding near-optimal policiesprovide flexible suggestions user.particular, investigate suggest several actions acting agent,providing performance guarantees worst-case analysis. Section 2 introducesnecessary technical background material. Section 3 defines concept non-deterministicpolicies related concepts. Section 4 addresses problem providing choiceacting agent keeping near-optimality guarantees performance worst-casescenario. propose two algorithms solve problems provide approximationtechniques speed computation larger domains.Methods introduced paper general enough apply decision support system observable Markovian environment. empirical investigations focusprimarily sequential decision-making problems clinical domains, systemprovide suggestions best treatment options patients. decisionsprovided sequence treatment phases. systems specifically interestingoften times, different treatment options seem provide slightly different results. Therefore, providing physician several suggestions would beneficialimproving usability system performance final decision.2. Definitions Notationssection introduces main notions behind sequential decision-making mathematical formulations used RL.2.1 Markov Decision ProcessesMarkov Decision Process (MDP) model system dynamics sequential decisionproblems involves probabilistic uncertainty future states system (Bellman,1957). MDPs used model interactions agent observableMarkovian environment. system assumed state given time.agent observes state performs action accordingly. system makestransition next state agent receives reward.Formally, MDP defined 5-tuple (S, A, T, R, ):States: set states. state usually captures complete configurationsystem. state system known, future systemindependent previous system transitions. means statesystem sufficient statistic history system.Actions: : 2A set actions allowed state setactions. A(s) set actions agent choose from, interactingsystem state s.Transition Probabilities: : [0, 1] defines transition probabilitiessystem. function specifies likely end state, givencurrent state specific action performed agent. Transition probabilities3fiMilani Fard & Pineauspecified based Markovian assumption. is, state systemtime denoted st action time , have:Pr(st+1 |at , st , at1 , at1 , . . . , a0 , s0 ) = P r(st+1 |at , st ).(1)focus homogeneous processes system dynamics independenttime. Thus transition function stationary respect time:def(s, a, s0 ) = P r(st+1 = s0 |at = a, st = s).(2)Rewards: R : R [0, 1] probabilistic reward model. Dependingcurrent state system action taken, agent receive rewarddrawn model. focus homogeneous processes which, again,reward distribution change time. reward time denotedrt , have:rt R(st , ).(3)Depending domain, reward could deterministic stochastic. usegeneral stochastic model throughout paper. mean distributiondenoted R(s, a).Discount Factor: [0, 1) discount rate used calculate long-termreturn.agent starts initial state s0 S. time step t, action A(st )taken agent. system makes transition st+1 (st , ) agentreceives immediate reward rt R(st , ).goal agent maximize discounted sum rewards planninghorizon h (could infinite). usually referred return (denoted D):D=hXrt .(4)t=0finite horizon case, sum taken horizon limit discount factorset 1. However, infinite horizon case discount factor less1 return finite value. return process dependsstochastic transitions rewards, well actions taken agent.Often times transition structure MDP contains loop non-zero probability. transition graph modeled directed acyclic graph (DAG).class MDPs interesting includes multi-step decision-making finite horizons,found medical domains.2.2 Policy Value Functionpolicy way defining agents action selection respect changesenvironment. (probabilistic) policy MDP mapping state spacedistribution action space:: [0, 1].4(5)fiNon-Deterministic Policies Markovian Decision Processesdeterministic policy policy defines single action per state. is, (s)A(s). later introduce notion non-deterministic policies MDPs dealsets actions.agent interacts environment takes actions according policy.value function policy defined expectation return givenagent acts according policy:"#XdefV (s) = E[D (s)] = Ert |s0 = s, = (st ) .(6)t=0Using linearity expectation, write expression recursiveform, known Bellman equation (Bellman, 1957):"#XX00V (s) =(s, a) R(s, a) +(s, a, )V (s ) .(7)s0aAvalue function used primary measure performance muchRL literature. are, however, ideas take risk variancereturn account measure optimality (Heger, 1994; Sato & Kobayashi, 2000).common criteria, though, assume agent trying find policymaximizes value function. policy referred optimal policy.also define value function state-action pairs. usually referredQ-function, Q-value, pair. definition:"#Xdef(8)Q (s, a) = E[D (s, a)] = Ert |s0 = s, a0 = a, 1 : = (st ) .t=0is, Q-value expectation return, given agent starts states, takes action a, follows policy . Q-function also satisfies Bellmanequation:XXQ (s, a) = R(s, a) +(s, a, s0 )(s0 , a0 )Q (s0 , a0 ),(9)s0a0rewritten as:Q (s, a) = R(s, a) +X(s, a, s0 )V (s0 ).(10)s0Q-function often used compare optimality different actions given fixedsubsequent policy.2.3 Planning Algorithms Optimalityoptimal policy, denoted , defined policy maximizes valuefunction initial state:= argmax V (s0 ).5(11)fiMilani Fard & Pineaushown (Bellman, 1957) MDP, exists optimal deterministic policy worse policy MDP. value optimalpolicy V satisfies Bellman optimality equation:"#XV (s) = max R(s, a) +(s, a, s0 )V (s0 ) .(12)aAs0deterministic optimal policy follows this:"#X00(s) = argmax R(s, a) +(s, a, )V (s ) .aA(13)s0Alternatively write equations Q-function:XQ (s, a) = R(s, a) +(s, a, s0 )V (s0 ).(14)s0Thus V (s) = maxa Q (s, a) (s) = argmaxa Q (s, a).Much literature RL focused finding optimal policy. manymethods developed policy optimization. One way find optimal policy solveBellman optimality equation use Eqn 13 choose actions. Bellmanoptimality equation formulated simple linear program (Bertsekas, 1995):minV V, subjectPV (s) R(s, a) + s0 (s, a, s0 )V (s0 ) s, a,(15)represents initial distribution states. solution problem optimal value function. Notice V represented matrix formequation. known linear programs solved polynomial time (Karmarkar,1984). However, solving might become impractical large (or infinite) state spaces.Therefore often times methods based dynamic programming preferred linearprogramming solution.3. Non-Deterministic Policies: Definition Motivationbegin section considering problem decision-making sequential decisionsupport systems. Recently, MDPs emerged useful frameworks optimizing actionchoices context medical decision support systems (Schaefer, Bailey, Shechter, &Roberts, 2004; Hauskrecht & Fraser, 2000; Magni, Quaglini, Marchetti, & Barosi, 2000;Ernst, Stan, Concalves, & Wehenkel, 2006). Given adequate MDP model (or datasource), many methods used find good action-selection policy. policyusually deterministic stochastic function. policies types face substantialbarrier terms gaining acceptance medical community, highlyprescriptive leave little room doctors input. problems are, course,specific medical domain present application actionsexecuted human. cases, may preferable provide several equivalently6fiNon-Deterministic Policies Markovian Decision Processesgood action choices, agent pick among accordingheuristics preferences.address problem, work introduces notion non-deterministic policy,function mapping state set actions, acting agentchoose.Definition 1. non-deterministic policy MDP (S, A, T, R, ) functionmaps state non-empty set actions denoted (s) A(s).agent choose action (s) whenever MDP state s.Definition 2. size non-deterministicpolicy , denoted ||, sumPcardinality action sets : || = |(s)|.following sections discuss two scenarios non-deterministic policiesuseful. show used implement robust decision supportsystems statistical guarantees performance.3.1 Providing Choice Acting AgentEven cases complete knowledge dynamics planning problemhand, accurately calculate actions utilities, might desirableprovide user optimal choice action time step. domains,difference utility top actions may substantial. medicaldecision-making, instance, difference may medically significant basedgiven state variables.cases, seems natural let user decide top actions,using his/her expertise domain. results injection domainknowledge decision-making process, thus making robust practical.decisions based facts known user incorporated automatedplanning system. also based preferences might change case case.instance, doctor get several recommendations treat patientmaximize chance remission, decide medication apply consideringalso patients medical record, preferences regarding side effects, medical expenses.idea providing choice user accompanied reasonable guarantees performance final decision, regardless choice made user.notion near-optimality enforced make sure actions never farbest possible option. guarantees enforced providing worst-case analysisdecision process.3.2 Handling Model Uncertaintymany practical cases complete knowledge system hand. Instead,may get set trajectories collected system according specific policy.cases, may given chance choose policy (in on-line active RL),cases may access data fixed policy. medicaltrials, particular, data usually collected according randomized policy, fixed aheadtime consultation clinical researchers.7fiMilani Fard & PineauGiven set sample trajectories, either build model domain (in modelbased approaches) directly estimate utility different actions (with model-free approaches). However models estimates always accurateobserve finite amount data. many cases, data may sparse incompleteuniquely identify best option. is, difference performance measuredifferent actions statistically significant.cases might useful let user decide final choiceactions enough evidence differentiate.comes assumption user identify best choice amongrecommended. task therefore provide user small set actionsalmost surely include optimal one.paper focus problem providing flexible policies nearoptimal performance. Using non-deterministic policies handling model uncertainty remains interesting future work.4. Near-Optimal Non-Deterministic PoliciesOften times, beneficial provide user decision support system setnear-optimal solutions. MDPs, would suggest set near-optimal actionsuser let user make decision among proposed actions. notionnear-optimality therefore set possible policies consistentproposed actions. is, matter action chosen among proposedoptions state, final performance close optimal policy.constraint suggests worst-case analysis decision-making process. Therefore,opt guarantee performance action selection consistent non-deterministicpolicy putting near-optimality constraint worst-case selection actionsuser.Definition 3. (worst-case) value state-action pair (s, a) according nondeterministic policy MDP = (S, A, T, R, ) given recursive definition:X00 0QM (s, a) = R(s, a) +(s, a, ) min QM (s , ) ,(16)a0 (s0 )s0worst-case expected return allowed set actions.Definition 4. define (worst-case) value state according non (s), be:deterministic policy , denoted VMmin Q(s, a).(17)a(s)calculate value non-deterministic policy, construct evaluation MDP,0 = (S, A0 , R0 , T, ), A0 = R0 = R.Theorem 1. negated value non-deterministic policy equaloptimal policy evaluation MDP:Q(s, a) = QM 0 (s, a).8(18)fiNon-Deterministic Policies Markovian Decision ProcessesProof. show QM 0 satisfies Bellman optimality equation 0 ,negated values satisfy Eqn 16 :XQM 0 (s, a) = R0 (s, a) +(s, a, s0 ) maxQM 0 (s0 , a0 )(19)00s0QM 0 (s, a) = R0 (s, a)X(s, a, s0 ) maxQM 0 (s0 , a0 )00(20)(s, a, s0 ) min QM 0 (s0 , a0 ),(21)s0QM 0 (s, a) = R(s, a) +Xs0a0 (s0 )equivalent Eqn 16 Q(s, a) = QM 0 (s, a).means policy evaluation non-deterministic policy achievedmethod finds optimal policy MDP.Definition 5. non-deterministic policy said augmented state-action pair(s, a), denoted 0 = + (s, a), satisfies:((s0 ),s0 6=0 (s0 ) =(22)(s0 ) {a}, s0 = s.policy achieved number augmentations policy 0 , sayincludes 0 .Definition 6. non-deterministic policy said non-augmentable accordingconstraint satisfies , state-action pair (s, a), + (s, a)satisfy .paper working constraints particular property:policy satisfy , policy includes satisfy .refer constraints monotonic. One constraint -optimality,discussed next section.4.1 -Optimal Non-Deterministic PoliciesDefinition 7. non-deterministic policy MDP said -optimal,[0, 1], have1 :VM(s) (1 )VM(s), S.(23)thought constraint space non-deterministic policies, setensure worst-case expected return within range optimal value.Theorem 2. -optimality constraint monotonic.1. MDP literature, -optimality defined additive constraint (QQM ) (Kearns& Singh, 2002). derivations analogous case. chose multiplicative constraintcleaner derivations.9fiMilani Fard & PineauProof. Suppose -optimal. augmentation 0 = + (s, a), have:X000 0 0Q(s,a)=R(s,a)+(s,a,)minQ(s,)s0a0 0 (s0 )X00 0 0(s, a, ) min QM (s , )R(s, a) +s0a0 (s0 )Q(s, a),implies:0VM(s) VM(s).-optimal, means 0 -optimal either value functiondecrease policy augmentation.intuitively, follows fact adding options cannot increaseminimum utility former worst case choice still available augmentation.Definition 8. conservative -optimal non-deterministic policy MDPpolicy non-augmentable according following constraint:XR(s, a) +(s, a, s0 )(1 )VM(s0 ) (1 )VM(s), (s).(24)s0constraint indicates add actions policy whose reward plus(1 ) future optimal return within sub-optimal margin. ensuresnon-deterministic policy -optimal using inequality:XQ(s, a, s0 )(1 )VM(s0 ) ,(25)(s, a) R(s, a) +s0instead solving Eqn 16 using inequality constraint Eqn 23. Applying Eqn 24guarantees non-deterministic policy -optimal may still augmentableaccording Eqn 23, hence name conservative.also shown conservative policy unique.two different conservative policies, union would conservative,violates assumption non-augmentable according Eqn 24.Definition 9. non-augmentable -optimal non-deterministic policy MDPpolicy non-augmentable according constraint Eqn 23.non-deterministic policy adding actions violates nearoptimality constraint worst-case performance. search -optimal policies,non-augmentable one locally maximal size. means although policymight largest among -optimal policies, cannot add actionswithout removing actions, hence locally maximal reference.non-augmentable -optimal policy includes conservative policy.always add conservative policy policy remain within bound.10fiNon-Deterministic Policies Markovian Decision ProcessesHowever, non-augmentable -optimal policies necessarily unique,locally maximal size.remainder section, focus problem searching spacenon-augmentable -optimal policies, maximize criteria. Specifically,aim find non-deterministic policies give acting agent options stayingwithin acceptable sub-optimal margin.present example clarifies concepts introduced far. simplifypresentation example, assume deterministic transitions. However, conceptsapply well probabilistic MDP. Figure 1 shows example MDP. labelsarcs show action names corresponding rewards shown parentheses.assume ' 1 = 0.05. Figure 2 shows optimal policy MDP.conservative -optimal non-deterministic policy MDP shown Figure 3.Figure 1: Example MDPFigure 2: Optimal policyFigure 3: Conservative -optimal policyFigure 4: Two non-augmentable -optimal policiesFigure 4 includes two possible non-augmentable -optimal policies. Although policies Figure 4 -optimal, union -optimal. due factadding option one states removes possibility adding options11fiMilani Fard & Pineaustates, illustrates local changes policy always appropriatesearching space -optimal policies.4.2 Optimization Criteriaformalize problem finding -optimal non-deterministic policy termsoptimization problem. several optimization criteria formulated,still complying -optimality constraint.Maximizing size policy: According criterion, seek nonaugmentable -optimal policies biggest overall size (Def 2). providesoptions agent still keeping -optimal guarantees. algorithmsproposed later sections use optimization criterion. Notice solutionoptimization problem non-augmentable according -optimal constraint,maximizes overall size policy.variant this, try maximize sum log size actionsets:Xlog |(s)|.(26)sSenforces even distribution choice action set. However,using basic case maximizing overall size easier optimizationproblem.Maximizing margin: aim maximize margin non-deterministicpolicy :max (),(27)where:() = minsSminQ(s, a) Q(s, ) .0a(s),a0 (s)/(28)optimization criterion useful one wants find clear separationgood bad actions state.Minimizing uncertainty: learn models datauncertainty optimal action state. use variance estimation value function (Mannor, Simester, Sun, & Tsitsiklis, 2004) alongZ-Test get confidence level comparisons find probabilitywrong order comparing actions according values. Let Qvalue true model Q empirical estimate based datasetD. aim minimize uncertainty non-deterministic policy :min (),(29)where:() = maxsSmaxa(s),a0 (s)/12P r Q(s, a) < Q(s, a0 )|D.(30)fiNon-Deterministic Policies Markovian Decision ProcessesNotice last two criteria defined space -optimal policies,non-augmentable ones.following sections provide algorithms solve first optimization problemmentioned above, aims maximize size policy. focus criterionseems appropriate medical decision support systems, desirableacceptability system find policies provide much choice possibleacting agent. Developing algorithms address two optimization criteriaremains interesting open problem.4.3 Maximal -Optimal Policyexact computational complexity finding maximal -optimal policy yet known.problem certainly NP, one find value non-deterministic policypolynomial time solving evaluation MDP linear program. suspectproblem NP-complete, yet find reduction known NP-completeproblem.order find largest -optimal policy, present two algorithms. first presentMixed Integer Program (MIP) formulation problem, present search algorithm uses monotonic property -optimal constraint. MIP methoduseful general theoretical formulation problem, search algorithmpotential extensions heuristics.4.3.1 Mixed Integer Programming SolutionRecall formulate problem finding optimal deterministic policyMDP simple linear program (Bertsekas, 1995):minV V, subjectPV (s) R(s, a) + s0 (s, a, s0 )V (s0 ) s, a,(31)thought initial distribution states. solutionproblem optimal value function (V ). Similarly, computed V usingEqn 31, problem searching optimal non-deterministic policy accordingsize criterion rewritten Mixed Integer Program:2maxV, (T V + (Vmax Vmin )eTs ea ), subjectV (s) (1 )V (s)P(s, a) > 0P00V (s) R(s, a) + s0 (s, a, )V (s ) + Vmax (1 (s, a)) s, a.(32)overloading notation define binary matrix representing policy,(s, a) 1 (s), 0 otherwise. define Vmax = Rmax /(1 )Vmin = Rmin /(1 ). es column vectors 1 appropriate dimensions.first set constraints makes sure stay within optimal return.2. Note MIP, unlike standard LP MDPs, choice affect solution casestie size .13fiMilani Fard & Pineausecond set constraints ensures least one action selected per state. thirdset ensures state-action pairs chosen policy, Bellmanconstraint holds, otherwise, constant Vmax makes constraint trivial. Noticesolution problem maximizes || result non-augmentable.Theorem 3. solution mixed integer program Eqn 32 non-augmentableaccording -optimality constraint.Proof. First, notice solution -optimal, due first set constraints(worst-case) value function. show non-augmentable, counter argument,suppose could add state-action pair solution , still staying suboptimal margin. adding pair, objective function increased (Vmax Vmin ),bigger possible decrease V term, thus objectiveimproved, conflicts solution.use MIP solver solve problem. Note howevermake use monotonic nature constraints. general purpose MIP solver couldend searching space possible non-deterministic policies, wouldrequire running time exponential number state-action pairs (O(2|S||A|+ )).4.3.2 Heuristic SearchAlternatively, develop heuristic search algorithm find maximal -optimal policy.make use monotonic property -optimal policies narrowsearch. start computing conservative policy. augment arrivenon-augmentable policy. also make use fact policy -optimal,neither policy includes it, thus cut search treepoint.Table 1: Heuristic search algorithm find -optimal policies maximum sizeFunction getOptimal(, startIndex, )startIndex |S||A|(s, a) pi/ (s) & V ( + (s, a)) (1 )V0 getOptimal ( + (s, a), + 1, )g(0 ) > g(o )0endendendreturnalgorithm presented Table 1 one-sided recursive depth-first-search algorithmsearches space plausible non-deterministic policies maximize functiong(). assume ordering set state-action pairs {pi } =14fiNon-Deterministic Policies Markovian Decision Processes{(sj , ak )}. ordering chosen according heuristic along mechanismcut parts search space. V optimal value function functionV returns value non-deterministic policy calculated solvingcorresponding evaluation MDP.make call function passing conservative policystarting first state-action pair: getOptimal(m , 0, ).asymptotic running time algorithm O((|S||A|)d (tm + tg )),maximum size -optimal policy minus size conservative policy, tmtime solve original MDP (polynomial relevant parameters), tg timecalculate function g. Although worst-case running time still exponentialnumber state-action pairs, run-time much less search space sufficientlysmall. |A| term due fact check possible augmentationsstate. Note algorithm searches space -optimal policies rathernon-augmentable ones. set function g() = ||, algorithmreturn biggest non-augmentable -optimal policy.search improved using heuristics order state-action pairsprune search. One also start search policy ratherconservative policy. potentially useful constraintsproblem.4.3.3 Directed Acyclic Transition GraphsOne way narrow search add action maximum valuestate s, ignore rest actions adding top action result values-optimality bound:!0 = +s, argmax Q (s, a) .a(s)/modified algorithm follows:Table 2: Modified heuristic search algorithm augmentation rule Eqn 33.Function getOptimal(, )(s) 6= A(s)argmaxa(s)Q (s, a)/V ( + (s, a)) (1 )V0 getOptimal ( + (s, a), )g(0 ) > g(o )0endendendreturn15(33)fiMilani Fard & Pineaualgorithm Table 2 leads running time O(|S|d (tm + tg )). Howeverguarantee see non-augmentable policies. due factadding action, order values might change. transition structure MDPcontains loop non-zero probability (transition graph directed acyclic, i.e. DAG),heuristic produce optimal result cutting search time.Theorem 4. MDPs DAG transition structure, algorithm Table 2 generate non-augmentable -optimal policies would generated full search.Proof. prove this, first notice sort DAG topological sort. Therefore, arrange states levels, state make transitions statesfuture level. easy see adding actions state non-deterministicpolicy change worst-case value past levels. effectQ-values current level future level.given non-augmentable -optimal policy generated full search,sequence augmentations generated policy. permutation sequencewould create policy intermediate polices -optimal. rearrange sequence add actions reverse order level.point mentioned above, Q-value actions point addedchange target policy realized. Therefore actions Q-valuesminimum value must policy, otherwise add them, conflictstarget policy non-augmentable. Since actions certain Q-valuemust added, add order. Therefore target policy realizedrule Eqn 33.transition structure DAG, one might partial evaluationaugmented policy approximate value adding actions, possiblybackups rather using original Q-values. offers possibility trading-offcomputation time better solutions.5. Empirical Resultsevaluate framework proposed algorithms, first test MIP searchformulations MDPs created randomly, test search algorithm real-worldtreatment design scenario. Finally, conduct experiment computer-aided webnavigation task human subjects assess usefulness non-deterministic policiesassisting human decision-making.5.1 Random MDPsfirst experiment, aim study non-deterministic policies changevalue two algorithms compare terms running time. begin,generated random MDPs 5 states 4 actions. transitions deterministic(chosen uniformly random) rewards random values 0 1, exceptone states reward 10 one actions; set 0.95. MIPmethod implemented MATLAB CPLEX.16fiNon-Deterministic Policies Markovian Decision Processes=0= 0.01= 0.02= 0.03Figure 5: MIP solution different values {0, 0.01, 0.02, 0.03}. labelsedges action indices, followed corresponding immediate rewards.Figure 5 shows solution MIP defined Eqn 32 particular randomlygenerated MDP. see size non-deterministic policy increases performance threshold relaxed. see even small values severalactions included policy state. course result Q-valuesclose other. property typical many medical scenarios differenttreatments provide slightly different results.compare running time MIP solver search algorithm, constructedrandom MDPs described state-action pairs. Figure 6 shows runningtime averaged 20 different random MDPs 5 states, assuming = 0.01 (whichallows several solutions). expected, algorithms running time exponentialnumber state-action pairs (note exponential scale time axis).running time search algorithm bigger constant factor (possibly due naiveimplementation), smaller exponent base, results faster asymptoticrunning time. Even exponential running time, one still use search algorithmsolve problems hundred state-action pairs. sufficientmany practical domains, including real-world medical decision scenarios shownnext section.observe effect choice running time algorithms, fixsize random MDPs 7 states 5 actions state, change17fiMilani Fard & PineauFigure 6: Running time MIP search algorithm function numberstate-action pairs = 0.01.value measure running time algorithms 100 trials. Figure 7 showsaverage running time algorithms different values . expected,search algorithm go deeper search tree optimality threshold relaxedrunning time thus increase. running time MIP method,hand, remains relativity constant exhaustively searches space possiblenon-deterministic policies. results representative relative behaviourtwo approaches range problems.Figure 7: Running time MIP search algorithm function , 7 states5 actions. Many actions included policy = 0.02.5.2 Medical Decision-makingdemonstrate non-deterministic policies used presented medicaldomain, tested full search algorithm MDP constructed medical decisionmaking task involving real patient data. data collected part large (4000+patients) multi-step randomized clinical trial, designed investigate comparative effectiveness different treatments provided sequentially patients suffering depression(Fava et al., 2003). goal find treatment plan maximizes chance18fiNon-Deterministic Policies Markovian Decision Processesremission. dataset includes large number measured outcomes. currentexperiment, focus numerical score called Quick Inventory Depressive Symptomatology (QIDS), used study assess levels depression (includingpatients achieved remission). purposes experiment, discretizeQIDS scores (which range 5 27) uniformly quartiles, assume this,along treatment step (up 4 steps allowed), completely describe patients state. Note underlying transition graph treated DAG,study limited four steps treatment action choices change steps.19 actions (treatments) total. reward 1 given patient achievesremission (at step) reward 0 given otherwise. transition rewardmodels estimated empirically medical database using frequentist approach.Table 3: Policy running time full search algorithm medical problem.= 0.02= 0.015= 0.01=0118.712.33.51.4CTSERBUPCIT+BUSCTSERCTCT9 QIDS < 12CIT+BUPCIT+CTCIT+BUPCIT+CTCIT+BUPCIT+BUPVENCIT+BUSCTVENCIT+BUSVENVEN12 QIDS < 1616 QIDS 27CTCIT+CTCTCIT+CTCTCIT+CTCTTime (seconds)5 < QIDS < 9Table 3 shows non-deterministic policy obtained state secondstep trial (each acronym refers specific treatment). computed usingsearch algorithm, assuming different values . Although problem tractableMIP formulation (304 state-action pairs), full search space -optimal policiesstill possible. Table 3 also shows running time algorithm, expected,increases relax threshold . Here, use heuristics. However,underlying transition graph DAG, could use heuristic discussed previoussection (Eqn 33) get policies even faster.interesting question set priori. practice, doctor may usefull table guideline, using smaller values he/she wants relydecision support system, larger values relying his/her assessments.believe particular presentation non-deterministic policies could usedaccepted clinicians, excessively prescriptive keeps physicianpatient decision cycle. contrast traditional notion policiesreinforcement learning, often leaves place physicians intervention.19fiMilani Fard & Pineau5.3 Human Subject InteractionFinally, conduct experiment assess usefulness non-deterministic policieshuman subjects. Ideally, would like conduct experiments medical settingsphysicians, studies costly difficult conduct given requireparticipation many medical professionals. therefore study non-deterministic policieseasier domain constructing web-based game played computerhuman (either jointly separately).game defined follows. user given target word asked navigatearound pages Wikipedia visit pages contain target word. userclick word page. system uses Google search Wiki websiteclicked word keyword current page (the choice keyworddiscussed later). randomly chooses one top eight search results movespage. process mimics hyperlink structure web (extendinghyperlink structure Wiki make target words easily reachable).user given ten attempts asked reach many pages target wordpossible. similar game used another work infer semantic distancesconcepts (West, Pineau, & Precup, 2009). game, however, designed waycomputer model provide results similar human player thus enable usassess effectiveness computer-aided decisions non-deterministic policies.construct task CD version Wikipedia (Schools-Wikipedia, 2009),structured manageable version Wikipedia intended use schools. testapproach also need build MDP model task. done using empirical datafollows. First, use Latent Dirichlet Allocation (LDA) using Gibbs sampling (Griffiths& Steyvers, 2004) divide pages Wikipedia 20 topics. topic correspondsstate MDP. LDA algorithm identifies topic set keywordsoccur often pages topic. define sets keywordsaction (20 actions totals, corresponding 20 keywords). randomly navigatearound Wiki using protocol described (with computer playerclicks LDA keywords) collect 200,000 transitions. use observed data buildtransition reward model MDP (the reward 1 hit 0 otherwise).specific choices LDA parameter number states actionsMDP made way best policy provided model comparableperformance human player.Using Amazon Mechanical Turk (MTurk, 2010), consider three experimental conditions task. one experiment, given target, computer chooses word(uniformly random) set keywords (the action) comes optimalpolicy MDP model. another experiment, human subjects choose clickword without help. Finally, test domain human userscomputer highlights, hints, words come non-deterministic policy= 0.1. record time taken process number times target wordobserved (number hits). Table 4 summarizes average outcomes experimentfour target words (we used seven target words, could collect enough datathem). also include p-value t-test comparing results humanagents without hints. computer score averaged 1000 runs.20fiNon-Deterministic Policies Markovian Decision ProcessesTable 4: Comparison different agents web navigation task. t-testnumber hits human player uses hints one not.TargetComputerHumanHuman hintt-TestMarriage1.88 hits1.94 hits103 seconds(86 subjects)2.63 hits93 seconds(86 subjects)0.0124.86 hits91 seconds(67 subjects)5.61 hits84 seconds(97 subjects)0.0493.67 hits85 seconds(98 subjects)4.39 hits89 seconds(83 subjects)0.0143.18 hits96 seconds(92 subjects)3.42 hits85 seconds(123 subjects)0.46(1000 runs)Military4.72 hits(1000 runs)Book3.77 hits(1000 runs)Animal2.50 hits(1000 runs)first three target words, performance computer agent closehuman user, observe providing hints user results statistically significantincrease number hits. fact see computer-aided human outperformscomputer human agents. shows non-deterministic policiesprovide means inject human domain knowledge computer models wayfinal outcome superior decision-making solely performed one party.last word, computer model working poorly, judging low hit rate. Thus,surprising see hints provide much help human agentcase (as seen non-significant p-value). also observe general speedup(for three targets) time taken agent choose click words,shows usefulness non-deterministic policies accelerating humansubjects decision-making process.6. Discussionpaper introduces new concept non-deterministic policies potential usedecision support systems based Markovian processes. context, investigateassumption decision-making system return single optimal actionrelaxed, instead return set near-optimal actions.Non-deterministic policies inherently different stochastic policies. Stochasticpolicies assume randomized action selection strategy specific probabilities,whereas non-deterministic policies impose constraint. thus use bestcase worst-case analysis non-deterministic policies highlight different scenarioshuman user.21fiMilani Fard & Pineaubenefits non-deterministic policies sequential decision-making two-fold.First, several actions difference performance negligible,report actions near-optimal options. instance, medical setting,difference outcome two treatment options might medicallysignificant. case, may beneficial provide near-optimal options.makes system robust user-friendly. medical decision-makingprocess, instance, physician make final decision among near-optimaloptions based side effects burden, patients preferences, expense, criteriacaptured model used decision support system. key constraint,however, make sure regardless final choice actions, performanceexecuted policy always bounded near optimal. framework, propertymaintained -optimality guarantee worst-case scenario.Another potential use non-deterministic action sets Markovian decision processes capture uncertainties optimality actions. Often times, amountdata models constructed sufficient clearly identify single optimalaction. forced chose one action optimal one, might highchance making wrong decision. However, given chance provide setpossibly-optimal actions, ensure include promising optionscutting obviously bad ones. setting, task trim action set muchpossible providing guarantee optimal action still among toppossible options.solve first problem, paper introduces two algorithms find flexible nearoptimal policies. First derive exact solution MIP formulation find maximal-optimal policy. MIP solution is, however, computationally expensivescale large domains. describe search algorithm solve problemless computational cost. algorithm fast enough applied real world medicaldomains. also show use heuristics search algorithm find solutionDAG structures even faster. heuristic search also provide approximate solutionsgeneral case.Another way scale problem larger domains approximate solutionMIP program relaxing constraints. One relax constraintsallow non-integral solutions penalize objective values away 0 1.study approximation methods remains interesting direction future work.idea non-deterministic policies introduces wide range new problemsresearch topics. Section 4, discuss idea near optimal non-deterministic policiesaddress problem finding one largest action set. mentioned,optimization criteria might useful decision support systems.include maximizing decision margin (the margin worst selected actionbest one selected), alternatively minimizing uncertainty wrong selection.Formalizing problems MIP formulation, incorporating heuristicsearch, might prove useful.evidenced human interaction experiments, non-deterministic policies substantially improve outcome planning decision-making tasks humanuser assisted robust computer-generated plan. Allowing several suggestionsstep provides effective way incorporating domain knowledge human side22fiNon-Deterministic Policies Markovian Decision Processesdecision-making process. medical domains physicians domain knowledgeoften hard capture computer model, collaborative model decision-makingnon-deterministic policies could offer powerful framework selecting effective,clinically acceptable, treatment strategies.Acknowledgmentsauthors wish thank A. John Rush (Duke-NUS Graduate Medical School), SusanA. Murphy (University Michigan), Doina Precup (McGill University) helpfuldiscussions regarding work. Funding provided National Institutes Health(grant R21 DA019800) NSERC Discovery Grant program.ReferencesBellman, R. (1957). Dynamic Programming. Princeton University Press.Bertsekas, D. (1995). Dynamic Programming Optimal Control, Vol 2. Athena Scientific.Ernst, D., Stan, G. B., Concalves, J., & Wehenkel, L. (2006). Clinical data based optimalSTI strategies HIV: reinforcement learning approach. ProceedingsFifteenth Machine Learning conference Belgium Netherlands (Benelearn),pp. 6572.Fava, M., Rush, A., Trivedi, M., Nierenberg, A., Thase, M., Sackeim, H., Quitkin, F., Wisniewski, S., Lavori, P., Rosenbaum, J., & Kupfer, D. (2003). Background rationalesequenced treatment alternatives relieve depression (STAR* D) study. Psychiatric Clinics North America, 26 (2), 457494.Griffiths, T. L., & Steyvers, M. (2004). Finding scientific topics. Proceedings NationalAcademy Sciences, 101 (Suppl. 1), 52285235.Hauskrecht, M., & Fraser, H. (2000). Planning treatment ischemic heart diseasepartially observable Markov decision processes. Artificial Intelligence Medicine,18 (3), 221244.Heger, M. (1994). Consideration risk reinforcement learning. ProceedingsEleventh International Conference Machine Learning (ICML), pp. 105111.Karmarkar, N. (1984). new polynomial-time algorithm linear programming. Combinatorica, 4 (4), 373395.Kearns, M., & Singh, S. (2002). Near-optimal reinforcement learning polynomial time.Machine Learning, 49.Magni, P., Quaglini, S., Marchetti, M., & Barosi, G. (2000). Deciding intervene:Markov decision process approach. International Journal Medical Informatics,60 (3), 237253.Mannor, S., Simester, D., Sun, P., & Tsitsiklis, J. N. (2004). Bias variance valuefunction estimation. Proceedings Twenty-First International ConferenceMachine Learning (ICML), pp. 308322.23fiMilani Fard & PineauMannor, S., Simester, D., Sun, P., & Tsitsiklis, J. N. (2007). Bias variance approximation value function estimates. Management Science, 53 (2), 308322.MTurk (2010). Amazon mechanical turk. http://www.mturk.com/.Murphy, S. A. (2005). experimental design development adaptive treatmentstrategies. Statistics Medicine, 24 (10), 14551481.Pineau, J., Bellemare, M. G., Rush, A. J., Ghizaru, A., & Murphy, S. A. (2007). Constructing evidence-based treatment strategies using methods computer science. DrugAlcohol Dependence, 88 (Supplement 2), S52 S60.Russell, S. J., & Norvig, P. (2003). Artificial Intelligence: Modern Approach (SecondEdition). Prentice Hall.Sato, M., & Kobayashi, S. (2000). Variance-penalized reinforcement learning risk-averseasset allocation. Proceedings Second International Conference IntelligentData Engineering Automated Learning, Data Mining, Financial Engineering,Intelligent Agents, pp. 244249. Springer-Verlag.Schaefer, A., Bailey, M., Shechter, S., & Roberts, M. (2004). Handbook OperationsResearch / Management Science Applications Health Care, chap. Medical decisionsusing Markov decision processes. Kluwer Academic Publishers.Schools-Wikipedia (2009).wikipedia.org/.2008/9 wikipedia selection schools.http://schools-Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction (AdaptiveComputation Machine Learning). MIT Press.Thapa, D., Jung, I., & Wang, G. (2005). Agent based decision support system using reinforcement learning emergency circumstances. Lecture Notes ComputerScience, 3610, 888.West, R., Pineau, J., & Precup, D. (2009). Wikispeedia: online game inferringsemantic distances concepts. Proceedings Twenty-First InternationalJont Conference Artifical Intelligence (IJCAI), pp. 15981603, San Francisco, CA,USA. Morgan Kaufmann Publishers Inc.24fiJournal Artificial Intelligence Research 40 (2011) 701-728Submitted 10/10; published 4/11Computing Small Unsatisfiable CoresSatisfiability Modulo TheoriesAlessandro Cimatticimatti@fbk.euFBK-IRST,Via Sommarive 18, 38123 Povo, Trento, ItalyAlberto Griggiogriggio@fbk.euFBK-IRST,Via Sommarive 18, 38123 Povo, Trento, ItalyRoberto Sebastianirseba@disi.unitn.itDISI, Universita di Trento,Via Sommarive 14, 38123 Povo, Trento, ItalyAbstractproblem finding small unsatisfiable cores SAT formulas recently receivedlot interest, mostly applications formal verification. However, propositionallogic often expressive enough representing many interesting verification problems,naturally addressed framework Satisfiability Modulo Theories,SMT. Surprisingly, problem finding unsatisfiable cores SMT receivedlittle attention literature.paper present novel approach problem, called Lemma-Liftingapproach. main idea combine SMT solver external propositionalcore extractor. SMT solver produces theory lemmas found search,dynamically lifting suitable amount theory information Boolean level.core extractor called Boolean abstraction original SMT problemtheory lemmas. results unsatisfiable core original SMT problem,remaining theory lemmas removed.approach conceptually interesting, several advantages practice.fact, extremely simple implement update, interfacedevery propositional core extractor plug-and-play manner, benefit freeunsat-core reduction techniques made available.evaluated algorithm extensive empirical test SMT-LIBbenchmarks, confirms validity potential approach.1. Motivations Goalslast decade witnessed impressive advance efficiency SAT techniques, brought large previously-intractable problems reach stateof-the-art SAT solvers. consequence, SAT solvers fundamental tool manyindustrial-strength applications, including formal verification design flows hardwaresystems, equivalence, property checking, ATPG. particular, one relevant problems context, thanks many important applications, findingsmall unsatisfiable cores, is, small unsatisfiable subsets unsatisfiable sets clauses.c2011AI Access Foundation. rights reserved.fiCimatti, Griggio, & SebastianiExamples applications include use SAT instead BDDs unbounded symbolicmodel checking (McMillan, 2002), automatic predicate discovery abstraction refinementframeworks (McMillan & Amla, 2003; Wang, Kim, & Gupta, 2007), decision procedures(Bryant, Kroening, Ouaknine, Seshia, Strichman, & Brady, 2009), under-approximationrefinement context bounded model checking multi-threaded systems (Grumberg,Lerda, Strichman, & Theobald, 2005), debugging design errors circuits (Suelflow, Fey,Bloem, & Drechsler, 2008). reason, problem finding small unsat coresSAT addressed many authors recent years (Zhang & Malik, 2003; Goldberg & Novikov, 2003; Lynce & Marques-Silva, 2004; Oh, Mneimneh, Andraus, Sakallah,& Markov, 2004; Mneimneh, Lynce, Andraus, Marques-Silva, & Sakallah, 2005; Huang,2005; Dershowitz, Hanna, & Nadel, 2006; Zhang, Li, & Shen, 2006; Biere, 2008; Gershman,Koifman, & Strichman, 2008; van Maaren & Wieringa, 2008; Asn, Nieuwenhuis, Oliveras,& Rodrguez Carbonell, 2008; Nadel, 2010).formalism plain propositional logic, however, often suitable expressiveenough representing many real-world problems, including verification RTLdesigns, real-time hybrid control systems, analysis proof obligationssoftware verification. problems naturally expressible satisfiability problems decidable first-order theories Satisfiability Modulo Theories, SMT. Efficient SMTsolvers developed last five years, called lazy SMT solvers, combineConflict-Driven Clause Learning (CDCL) SAT solver based DPLL algorithm (Davis& Putnam, 1960; Davis, Logemann, & Loveland, 1962; Marques-Silva & Sakallah, 1996;Zhang & Malik, 2002) hereafter simply DPLL ad-hoc decision proceduresmany theories interest (see, e.g., Nieuwenhuis, Oliveras, & Tinelli, 2006; Barrett& Tinelli, 2007; Bruttomesso, Cimatti, Franzen, Griggio, & Sebastiani, 2008; Dutertre &de Moura, 2006; de Moura & Bjrner, 2008).Surprisingly, problem finding unsatisfiable cores SMT received virtuallyattention literature. Although SMT tools compute unsat cores, doneeither byproduct general task producing proofs, modifyingembedded DPLL solver apply basic propositional techniques produce unsatcore. particular, aware work aiming producing small unsatisfiablecores SMT.paper present novel approach addressing problem, callLemma-Lifting approach. main idea combine SMT solver externalpropositional core extractor. SMT solver stores returns theory lemmasprove order refute input formula; external core extractor calledBoolean abstraction original SMT problem theory lemmas.algorithm based following two key observations: i) theory lemmas discoveredSMT solver search valid clauses theory consideration,therefore affect satisfiability formula ; ii) conjunctionoriginal SMT formula theory lemmas propositionally unsatisfiable.Therefore, external (Boolean) core extractor finds unsatisfiable core (the Booleanabstraction of) conjunction original formula theory lemmas,refined back subset original clauses simply removing (theBoolean abstractions of) theory lemmas. result unsatisfiable core originalSMT problem.702fiComputing Small Unsatisfiable Cores Satisfiability Modulo TheoriesAlthough simple principle, approach conceptually interesting: basically,SMT solver used dynamically lift suitable amount theory informationBoolean level. Furthermore, approach several advantages practice: first,extremely simple implement update; second, effective finding small cores;third, core extraction prone complex SMT reasoning; finally, interfacedevery propositional core extractor plug-and-play manner, benefit freeunsat-core reduction techniques made available.evaluated approach extensive empirical test SMT-LIB benchmarks, terms effectiveness (reduction size cores) efficiency (executiontime). results confirm validity versatility approach.byproduct, also produced extensive insightful evaluationmain Boolean unsat-core-generation tools currently available.Content. paper organized follows. 2 3 provide backgroundknowledge techniques SAT SMT (2), extraction unsatisfiable coresSAT SMT (3). 4 present discuss new approach algorithm.5 present comment empirical tests. 6 conclude, suggestingfuture developments.2. SAT SMTsetting standard first order logic. 0-ary function symbol called constant.term first-order term built function symbols variables. t1 , . . . , tn termsp predicate symbol, p(t1 , . . . , tn ) atom. formula builtusual way universal existential quantifiers, Boolean connectives, atoms.literal either atom negation. call formula quantifier-freecontain quantifiers, ground contain free variables. clause disjunctionliterals. formula said conjunctive normal form (CNF) conjunctionclauses. every non-CNF formula , equisatisfiable CNF formula generatedpolynomial time (Tseitin, 1983).also assume usual first-order notions interpretation, satisfiability, validity,logical consequence, theory, given, e.g., Enderton (1972). write |=denote formula logical consequence (possibly infinite) set formulas.first-order theory, , set first-order sentences. structure model theorysatisfies every sentence . formula satisfiable (or -satisfiable)satisfiable model . (We sometimes use word -formula ground formulainterested determining -satisfiability.)follows, little abuse notation, might sometimes denote conjunctionsliterals l1 . . . ln sets {l1 , . . . , ln } vice versa. {l1 , . . . , ln }, might writemean l1 . . . ln . Moreover, following terminology SAT SMTcommunities, shall refer predicates arity zero propositional variables,uninterpreted constants theory variables.Given first-order theory (ground) satisfiability problem decidable,call theory solver , -solver, tool able decide satisfiabilitysets/conjunctions ground atomic formulas negations theory literals literals language . input set -literals -unsatisfiable,703fiCimatti, Griggio, & Sebastiani1.2.3.4.5.6.7.8.9.10.11.12.13.14.SatValue DPLL (formula , assignment ) {(1) {decide next branch(, );(1) {status = deduce(, );(status == sat)return sat;else (status == conflict) {hblevel, = analyze conflict(, );(blevel < 0) return unsat;else backtrack(blevel, , , );}else break;}}}Figure 1: Schema modern DPLL engine.typical -solver returns unsat, also returns subset -literalsfound -unsatisfiable. ( hereafter called theory conflict set, theoryconflict clause.) -satisfiable, -solver returns sat, may alsoable discover one (or more) deductions formWn{l1 , . . . , ln } |=T l, s.t. {l1 , . . . , ln }l unassigned -literal. so, call ( i=1 li l) theory-deduction clause.Importantly, notice theory-conflict clauses theory-deduction clauses valid. call theory lemmas -lemmas.Satisfiability Modulo (the) Theory SMT (T ) problem decidingsatisfiability Boolean combinations propositional atoms theory atoms. Examplesuseful theories equality uninterpreted functions (EU F), difference logic (DL)linear arithmetic (LA), either reals (LA(Q)) integers (LA(Z)), theoryarrays (AR), bit vectors (BV), combinations. call SMT (T ) tooltool able decide SMT (T ). Notice that, unlike -solver, SMT (T ) tool musthandle also Boolean connectives.Hereafter adopt following terminology notation. symbols , denote-formulas, , denote sets -literals; p , p denote propositional formulas, p ,p denote sets propositional literals, interpreted truth assignmentsvariables.2.1 Propositional Satisfiability DPLL Algorithmstate-of-the-art SAT procedures evolutions Davis-Putnam-Longeman-Loveland(DPLL) procedure (Davis & Putnam, 1960; Davis et al., 1962). high-level schemamodern DPLL engine, adapted description given Zhang Malik (2002),704fiComputing Small Unsatisfiable Cores Satisfiability Modulo Theories1.2.3.4.5.6.7.8.9.SatValue Lazy SMT Solver (T -formula ) {p = 2P();(DPLL(p , p ) == sat) {h, = -solver(P2T (p ))( == sat) return sat;p = p 2P();};return unsat;};Figure 2: simplified schema lazy SMT (T ) procedures.reported Figure 1.1 Boolean formula CNF; assignment initiallyempty, updated stack-based manner.main loop, decide next branch(, ) chooses unassigned literal laccording heuristic criterion, adds . (This operation called decision, lcalled decision literal end number decision literals operation calleddecision level l.) inner loop, deduce(, ) iteratively deduces literals l derivingcurrent assignment updates accordingly; step repeated eithersatisfies , falsifies , literals deduced, returning sat, conflictunknown respectively. (The iterative application Boolean deduction steps deducealso called Boolean Constraint Propagation, BCP.) first case, DPLL returns sat.second case, analyze conflict(, ) detects subset caused conflict(conflict set) decision level blevel backtrack. blevel < 0, conflict existseven without branching, DPLL returns unsat. Otherwise, backtrack(blevel, , )adds clause (learning) backtracks blevel (backjumping), updatingaccordingly. (E.g., popular 1st-UIP schema, backtracks smallest blevelone literal assigned, hence deduces negation remainingliteral applying BCP learned clause ; see Zhang, Madigan, Moskewicz, & Malik,2001.) third case, DPLL exits inner loop, looking next decision.much deeper description modern DPLL-based SAT solvers, refer reader,e.g., work Zhang Malik (2002).2.2 Lazy Techniques SMTidea underlying every lazy SMT (T ) procedure (a complete set of) truthassignments propositional abstraction enumerated checked satisfiability ; procedure either returns sat one -satisfiable truth assignment found,returns unsat otherwise.introduce following notation. 2P bijective function (theory propositional), called Boolean (or propositional) abstraction, maps propositional variablesthemselves, ground -atoms fresh propositional variables, homomorphic1. remark many details provided critical understanding rest paper,mentioned sake completeness.705fiCimatti, Griggio, & Sebastianiw.r.t. Boolean operators set inclusion. function P2T (propositional theory), called refinement, inverse 2P. (E.g., 2P({((x 3) A3 ), (A2(x = z))}) = {(B1 A3 ), (A2 B2 )}, B1 B2 fresh propositional variables,P2T ({A1 , A2 , B1 , B2 }) = {A1 , A2 , (x 3), (x = z)}.) follows, shalluse p superscript denoting Boolean abstraction formula/truth assignment(e.g., p denotes 2P(), denotes P2T (p )). Given -formula , saypropositionally unsatisfiable 2P() |= . .Figure 2 presents simplified schema lazy SMT (T ) procedure, called off-lineschema. propositional abstraction p input formula given inputSAT solver based DPLL algorithm (Davis et al., 1962; Zhang & Malik, 2002),either decides p unsatisfiable, hence -unsatisfiable, returnssatisfying assignment p ; latter case, P2T (p ) given input -solver.P2T (p ) found -consistent, -consistent. not, -solver returns conflictset caused -inconsistency P2T (p ); abstraction -lemma ,2P(), added clause p . DPLL solver restarted scratchresulting formula.Practical implementations follow elaborated schema, called on-line schema(see Barrett, Dill, & Stump, 2002; Audemard, Bertoli, Cimatti, Kornilowicz, & Sebastiani,2002; Flanagan, Joshi, Ou, & Saxe, 2003). before, p given input modifiedversion DPLL, satisfying assignment p found, refinement pfed -solver; found -consistent, -consistent; otherwise, -solverreturns conflict set caused -inconsistency P2T (p ). clausep added conjunction p , either temporarily permanently (T -learning), and,rather starting DPLL scratch, algorithm backtracks highest pointsearch one literals p unassigned (T -backjumping), thereforevalue (propositionally) implied others p .important variant schema (Nieuwenhuis et al., 2006) buildingmixed Boolean+theory conflict clause, starting p applying backwardtraversal implication graph built DPLL (Zhang et al., 2001), onestandard conditions (e.g., 1st UIP Zhang et al., 2001) achieved.important optimizations early pruning theory propagation: -solverinvoked also (the refinement of) intermediate assignment : found unsatisfiable, procedure backtrack, since extension -satisfiable;not, -solver performs deduction {l1 , . . . , ln } |=T l s.t. {l1 , . . . , lnW} ,2P(l) unit-propagated, Boolean abstraction -lemma ( ni=1 li l)learned.on-line lazy SMT (T ) schema coarse description procedures underlyingstate-of-the-art lazy SMT (T ) tools like, e.g., BarceLogic, CVC3, MathSAT, Yices,Z3. interested reader pointed to, e.g., work Nieuwenhuis et al. (2006), BarrettTinelli (2007), Bruttomesso et al. (2008), Dutertre de Moura (2006), de MouraBjrner (2008), details references, work Sebastiani (2007)Barrett, Sebastiani, Seshia, Tinelli (2009) survey.706fiComputing Small Unsatisfiable Cores Satisfiability Modulo Theories3. Extracting Unsatisfiable CoresWithout loss generality, following consider formulas CNF. Givenunsatisfiable CNF formula , say unsatisfiable CNF formula unsatisfiablecore iff = 0 (possibly empty) CNF formula 0 . Intuitively, subsetclauses causing unsatisfiability . unsatisfiable core minimal iffformula obtained removing clauses satisfiable. minimum unsatcore minimal unsat core smallest possible cardinality.3.1 Techniques Unsatisfiable-Core Extraction SATlast years, several algorithms computing small, minimal minimum unsatisfiable cores propositional formulas proposed. approach ZhangMalik (2003) Goldberg Novikov (2003), computed byproductDPLL-based proof-generation procedure. computed unsat core simply collectionoriginal clauses DPLL solver used derive empty clause resolution. returned core minimal general, reduced iteratingalgorithm fixpoint, using input iteration core computedprevious one. algorithm Gershman et al. (2008), instead, manipulates resolutionproof shrink size core, using also fixpoint iteration Zhang Malik(2003) enhance quality results. Oh et al. (2004) present algorithmcompute minimal unsat cores. technique based modifications standard DPLLengine, works adding extra variables (selectors) original clauses,performing branch-and-bound algorithm modified formula. procedurepresented Huang (2005) extracts minimal cores using BDD manipulation techniques,removing one clause time remaining core minimal. constructionminimal core Dershowitz et al. (2006) also uses resolution proofs, works iteratively removing proof one input clause time, longer possibleprove inconsistency. clause removed, resolution proof modified preventfuture use clause.far computation minimum unsatisfiable cores concerned, algorithm Lynce Marques-Silva (2004) searches unsat cores input problem;done introducing selector variables original clauses, increasingsearch space DPLL solver include also variables; then, (one of) unsatisfiable subformulas smallest number selectors assigned true returned.approach described Mneimneh et al. (2005) instead based branch-and-boundalgorithm exploits relation maximal satisfiability minimum unsatisfiability. relation used also procedure Zhang et al. (2006),instead based genetic algorithm.3.2 Techniques Unsatisfiable-Core Extraction SMTbest knowledge, literature explicitly addressing problemcomputing unsatisfiable cores SMT 2 . However, four SMT solvers (i.e. CVC3, Barrett &Tinelli, 2007, MathSAT, Bruttomesso et al., 2008, Yices, Dutertre & de Moura, 20062. Except previous short version present paper (Cimatti, Griggio, & Sebastiani, 2007).707fiCimatti, Griggio, & Sebastiani((x = 0) (x = 1))LA(Z)((x = 0) (x = 1) A2 )((x = 0) (x = 1) A1 )((x = 0) (x = 1) A2 )((x = 0) A1 A2 )((x = 0) A2 )(A1 (y = 2))(A1 A2 )((y = 2) A2 )((y = 2) (y < 0))LA(Z)(A2 (y < 0))((y = 1) (y < 0))LA(Z)(y < 0)(A2 (y = 1))((y < 0) (y = 1))((y < 0))Figure 3: Resolution proof SMT formula (1) found MathSAT. Boxed clausescorrespond unsatisfiable core.Z3, de Moura & Bjrner, 2008) support unsat core generation3 . following, describeunderlying approaches, generalize techniques propositional UC extraction.preliminarily remark none solvers aims producing minimal minimumunsat cores, anything reduce size.Strictly related work, Liffiton Sakallah (2008) presented general techniqueenumerating minimal unsatisfiable subsets given inconsistent set constraints,implemented tool CAMUS. Although description propertiesalgorithms focuses pure SAT, authors remark approach extends easilySMT, implemented inside CAMUS SMT version procedure.Therefore following briefly describe also approach.3.2.1 Proof-Based UC Extraction.CVC3 MathSAT run proof-producing mode, compute unsatisfiable coresbyproduct generation proofs. Similarly approach Zhang Malik(2003), idea analyze proof unsatisfiability backwards, returnunsatisfiable core collection assumptions (i.e. clauses originalproblem) used proof derive contradiction.3. information reported computation unsat cores CVC3, Yices Z3 comesprivate communications authors user manual CVC3.708fiComputing Small Unsatisfiable Cores Satisfiability Modulo TheoriesExample 1 order show described approaches work, consider small unsatisfiable SMT (T ) formula, LA(Z):((x = 0) (x = 1) A1 ) ((x = 0) (x = 1) A2 ) ((x = 0) (x = 1) A2 )(A2 (y = 1)) (A1 (x + > 3)) (y < 0) (A2 (x = 4))((y = 2) A1 ) (x 0), (1)x real variables A1 A2 Booleans.proof-based approach, resolution proof unsatisfiability builtsearch. E.g., Figure 3 shows proof tree found MathSAT. leaves treeeither original clauses (boxed Figure) LA(Z)-lemmas (denoted LA(Z)suffix). unsatisfiable core built collecting original clauses appearingleaves proof. case, is:{((x = 0) (x = 1) A1 ), ((x = 0) (x = 1) A2 ), ((x = 0) (x = 1) A2 ),(A2 (y = 1)), (y < 0), ((y = 2) A1 )}. (2)case, unsat core minimal.3.2.2 Assumption-Based UC Extractionapproach used Yices (Dutertre & de Moura, 2006) Z3 (de Moura & Bjrner,2008) adaptation method Lynce Marques-Silva (2004): clauseCi problem, new Boolean selector variable Si created; then, Ci replaced(Si Ci ); finally, starting search Si forced true. way,conflict decision level zero found DPLL solver conflict clause containsselector variables, unsat core returned union clauses whose selectorsappear conflict clause.Example 2 Consider formula (1) Example 1. assumption-based approach, 9 input clauses augmented extra variable Si , assertedtrue beginning search. formula therefore becomes:^Si(S1 ((x = 0) (x = 1) A1 )) (S2 ((x = 0) (x = 1) A2 ))(S3 ((x = 0) (x = 1) A2 )) (S4 (A2 (y = 1)))(3)(S5 (A1 (x + > 3))) (S6 (y < 0))(S7 (A2 (x = 4))) (S8 ((y = 2) A1 )) (S9 (x 0))final conflict clause generated conflict analysis (Zhang et al., 2001) is:S1 S2 S3 S4 S6 S7 S8 ,4. using Yices.7094(4)fiCimatti, Griggio, & Sebastianicorresponding following unsat core:{((x = 0) (x = 1) A1 ), ((x = 0) (x = 1) A2 ), ((x = 0) (x = 1) A2 ),(A2 (y = 1)), (y < 0), (A2 (x = 4)), ((y = 2) A1 )}. (5)Notice minimal, presence redundant clause (A2 (xy =4)), corresponding S7 final conflict clause (4).Remark 1 idea behind two techniques illustrated essentially same.exploit implication graph built DPLL conflict analysis detect subsetinput clauses used decide unsatisfiability. main differenceproof-based approach done explicitly constructing proof tree,activation-based one done implicitly labeling original clauses.deeper comparison two approaches (and variants them),refer reader work Asn et al. (2008) Nadel (2010).3.2.3 CAMUS Approach Extracting Minimal UCs.completely different approach, aiming generating minimal UCs giveninconsistent set propositional clauses , presented Liffiton Sakallah (2008)implemented tool CAMUS. nutshell, approach works two distinct phases:(a) enumerate set Minimal Correction Subsets (MCSs) . 5 performed specialized algorithm, using backend engine incremental SAT solverable handle also AtMost constraints;(b) enumerate set U minimal UCs minimal hitting sets set .also performed specialized algorithm. Alternatively, another algorithmproduce one minimal UC much less effort.important notice sets U returned exponentially big wrt.size . Thus, procedure may produce exponential amount MCSs phase(a) producing one UC. extent, authors provide also modifiedefficient version technique, sacrifice completeness approach.refer reader work Liffiton Sakallah (2008) detailed explanationtechnique features.mentioned above, although description algorithms focuses pure SAT,authors remark approach extends easily SMT, implementedinside CAMUS version algorithm working also SMT, using Yices backendSMT solver. Unfortunately, provide details extension. 65. MCS unsatisfiable set constraint complement set maximal consistent subset: \ consistent and, every Ci , \ ( \ Ci ) inconsistent (Liffiton & Sakallah, 2008).6. See 10 Conclusions Future Work. article Liffiton Sakallah (2008).710fiComputing Small Unsatisfiable Cores Satisfiability Modulo TheoriesExample 3 Consider LA(Z)-formula (1) Example 1 form clause setdef=c1c2c3c4c5c6c7c8c9:::::::::(x = 0) (x = 1) A1 ,(x = 0) (x = 1) A2 ,(x = 0) (x = 1) A2 ,A2 (y = 1),A1 (x + > 3),(y < 0),A2 (x = 4),(y = 2) A1 ,(x 0).(6)run (6), CAMUS returns following two minimal UCs:defuc1 =c1 :c2 :c3 :c4 :c:5c6 :def(x = 0) (x = 1) A1 ,(x = 0) (x = 1) A2 ,(x = 0) (x = 1) A2 ,,A2 (y = 1),A1 (x + > 3),(y < 0)uc2 =c1 :c2 :c3 :c4 :c :6c8 :(x = 0) (x = 1) A1 ,(x = 0) (x = 1) A2 ,(x = 0) (x = 1) A2 ,A2 (y = 1),(y < 0),(y = 2) A1.(7)(Notice uc2 identical UC found Example 1.)understand Liffiton Sakallah (2008) that, order produce uc1 uc2 ,CAMUS enumerates first (not necessarily order) following set MCSs:{{c1 }, {c2 }, {c3 }, {c4 }, {c6 }, {c5 , c8 }}(8)computes uc1 uc2 minimal hitting sets (8).Notice (8) set MCSs , \ {c5 } \ {c8 } LA(Z)-inconsistent,{A1 = , A2 = , x = 1, = 3} |=LA(Z) \ {c1 },{A1 = , A2 = , x = 2, = 6} |=LA(Z) \ {c2 },{A1 = , A2 = , x = 0, = 4} |=LA(Z) \ {c3 },{A1 = , A2 = >, x = 0, = 1} |=LA(Z) \ {c4 },{A1 = , A2 = >, x = 3, = 1}|=LA(Z) \ {c6 },{A1 = >, A2 = , x = 1, = 1} |=LA(Z) \ {c5 , c8 }.Moreover, contains MCSs also \ {c9 }, \ {c5 , c9 } \ {c8 , c9 }LA(Z)-inconsistent.4. Novel Approach Building Unsatisfiable Cores SMTpresent novel approach, called Lemma-Lifting approach, unsatisfiablecore computed posteriori w.r.t. execution SMT solver, formula found -unsatisfiable. done means external (and possiblyoptimized) propositional unsat core extractor.711fiCimatti, Griggio, & Sebastiani4.1 Main Ideasfollowing, assume lazy SMT (T ) procedure run unsatisfiable set SMT (T ) clauses =def {C1 , . . . , Cn }, D1 , . . . , Dk denote-lemmas, theory-conflict theory-deduction clauses, returned -solver run. (Notice that, definition, -lemmas -validclauses.) case mixed Boolean+theory-conflict clauses (Nieuwenhuis et al., 2006) (see2.2), -lemmas returned -solver used computemixed Boolean+theory-conflict clause, including initial theory-conflict clausetheory-deduction clauses corresponding theory-propagation steps performed. 7assumptions, two simple facts hold.(i) Since -lemmas Di valid , affect -satisfiability formula:( Di ) |=T |=T .(ii) conjunction-lemmas D1 , . . . , Dk propositionally unsatisfiable:Vn2P( i=1 Di ) |= .Fact (i) self-evident. Fact (ii) termination condition lazy SMT toolsinput formula -unsatisfiable. InVthe off-line schema Figure 2, procedure endsDPLL establishes 2P( ni=1 Di ) unsatisfiable, Di negationtheory-conflict set returned i-th call -solver. Fact (ii) generalizeson-line schema, noticing -backjumping theory-conflict clause Di producesanalogous effect re-invoking DPLL p 2P(Di ), whilst theory propagationdeduction {l1 , . . . , lk }W|=T l seen form unit propagation theorydeduction clause 2P ( li l).Example 4 Consider formula (1) Example 1. order decide unsatisfiability, MathSAT generates following set LA(Z)-lemmas:{((x = 1) (x = 0)), ((y = 2) (y < 0)), ((y = 1) (y < 0))}. (9)Notice LA(Z)-valid (fact (i)). Then, Boolean abstraction (1)conjoined Boolean abstraction LA(Z)-lemmas, resulting followingpropositional formula:(B1 B2 A1 ) (B1 B2 A2 ) (B1 B2 A2 ) (A2 B3 )(A1 B4 ) B5 (A2 B6 ) (B7 A1 ) B8(B2 B1 ) (B7 B5 ) (B3 B5 ), (10)where:B1B2B3B4def= 2P(x = 0)def= 2P(x = 1)def= 2P(y = 1)def= 2P(x + > 3)B5B6B7B8def= 2P(y < 0)= 2P(x = 4)def= 2P(y = 2)def= 2P(x 0).def7. case, SMT solver provide original -lemmas feature using mixedBoolean+theory-conflict clauses active, latter feature disabled.712fiComputing Small Unsatisfiable Cores Satisfiability Modulo Theoriespropositional formula (10) unsatisfiable (fact (ii)), demonstrated followingresolution proof.(B2 B1 )(B1 B2 A1 )(B1 B2 A2 )(B1 B2 A2 )(B1 A1 A2 )(B1 A2 )(B7 A1 )(A1 A2 )(B7 A2 )(B7 B5 )(A2 B5 )(B3 B5 )(A2 B3 )(B5 B3 )B5B5Fact (ii) holds also SMT tools learn mixed Boolean+theory-clausesF1 , . . . , Fn (instead -lemmas), obtained -lemmasVD1 , . . . , Dn backwardtraversalimplication graph. fact, case, 2P( ni=1 Fi ) |= holds. SinceVn Vi=1 Di |= ni=1 Fi , way Fi built, 8 (ii) holds.SMT tools implement theory-propagation slightly different way (e.g. BarceLogic, Nieuwenhuis et al., 2006). l1 , . . . , ln |=T l, instead learning -lemmal1 . . . ln l unit-propagating l it, simply propagate value l, withoutlearning clause. propagation leads conflict later search,theory-deduction clause learned used conflict-analysis. validity fact (ii)affected optimization, -lemmas used conflict analysisneeded hold (Nieuwenhuis et al., 2006).Overall, variants on-line schema, embedded DPLL engine builds eitherexplicitly implicitly resolution refutation Boolean abstraction conjunctionoriginal clauses -lemmas returned -solver. Thus fact (ii) holds.4.2 Extracting SMT Cores Lifting Theory LemmasFacts (i) (ii) discussed 4.1 suggest new approach generation unsatisfiablecores SMT. main idea theory lemmas used SMT searchlifted Boolean clauses, unsat core extracted purely propositionalcore extractor. Therefore, call technique Lemma-Lifting approach.algorithm presented Figure 4. procedure -Unsat Core receivesinput set clauses =def {C1 , . . . , Cn } invokes lazy SMT (T ) toolLazy SMT Solver, instructed store somewhere -lemmas returnedVi18. clause 2P(Fi ) obtained resolving clause 2P(Di ) clauses 2P( j=1Fj ),Vi1VnVn2P(F)|=2P(F).Thus,induction,2P()|=2P(j=1 Vji=1i=1 Fi ),Vnn|=F.i=1i=1713fiCimatti, Griggio, & SebastianiInput clauses:Result:{C1 , . . . , Cn }sat/unsat-unsat core:0 }{C10 , . . . , CmLazy SMT Solver-valid clauses:{D10 , . . . , Dj0 }Stored -Lemmas:{D1 , . . . , Dk }Boolean abstraction:Refinement:2PP2TBoolean unsatcore:2P({C1 , . . . , Cn , D1 , . . . , Dk })0 , 0 , . . . , 0 })2P({C10 , . . . , Cm1jBoolean Unsat Core ExtractorhSatValue,Clause seti -Unsat Core(Clause set ) {// {C1 , . . . , Cn }(Lazy SMT Solver() == sat)return hsat,i;// D1 , . . . , Dk -lemmas stored Lazy SMT Solverp =Boolean Unsat Core Extractor(T 2P({C1 , . . . , Cn , D1 , . . . , Dk }));0 , 0 , . . . , 0 }));// p 2P({C10 , . . . , Cm1j0 }i;return hunsat,{C10 , . . . , Cm}Figure 4: Schema -Unsat Core procedure: architecture (above) algorithm (below).-solver, namely D1 , . . . , Dk . Lazy SMT Solver returns sat, whole procedurereturns sat. Otherwise, Boolean abstraction {C1 , . . . , Cn , D1 , . . . , Dk }, inconsistent (ii), fed external tool Boolean Unsat Core, ablereturn Boolean unsat core p input. construction, p Boolean ab0 , 0 , . . . , 0 } s.t. {C 0 , . . . , C 0 } {C , . . . , C }straction clause set {C10 , . . . , Cm1n11j000 , 0 , . . . , 0 } {D1 , . . . , Dj } {D1 , . . . , Dk }. p unsatisfiable, {C10 , . . . , Cm1junsatisfiable. (i), -valid clauses D10 , . . . , Dj0 role -unsatisfiability0 , 0 , . . . , 0 }, thrown away, procedure returns{C10 , . . . , Cm1j0 }.unsat -unsatisfiable core {C10 , . . . , CmNotice resulting -unsatisfiable core guaranteed minimal, evenBoolean Unsat Core returns minimal Boolean unsatisfiable cores. fact, might0 }\{C 0 } -unsatisfiable C 0 even though 2P({C 0 , . . . , C 0 }\case {C10 , . . . , Cm1{Ci0 }) satisfiable, truth assignments p satisfying latterP2T (p ) -unsatisfiable.714fiComputing Small Unsatisfiable Cores Satisfiability Modulo TheoriesExample 5 Consider unsatisfiable SMT formula LA(Z):((x = 0) (x = 1)) ((x = 0) (x = 1)) ((x = 0) (x = 1))((x = 0) (x = 1))propositional abstraction 2P():2P() (B1 B2 ) (B1 B2 ) (B1 B2 ) (B1 B2 ).Then, 2P() minimal Boolean unsatisfiable core itself, minimal coreLA(Z), since last clause valid theory, hence safely dropped.procedure implemented simply modifying SMT solverstore -lemmas interfacing state-of-the-art Boolean unsat coreextractor used external black-box device. Moreover, SMT solver provideset -lemmas output, whole procedure may reduce control deviceinterfacing SMT solver Boolean core extractor black-box externaldevices.Remark 2 Notice storing -lemmas mean learning them, is,SMT solver required add -lemmas formula search. Instead, instance sufficient store ad-hoc data structure, evendump file. causes overhead Boolean search SMTsolver, imposes constraint lazy strategy adopted (e.g., offline/online, permanent/temporary learning, usage mixed Boolean+theory conflict clauses, etc.).Example 6 again, consider formula (1) Example 1, corresponding formula(10) Example 4, Boolean abstraction (1) LA(Z)-lemmas (9) foundMathSAT search. Lemma-Lifting approach, (10) given inputexternal Boolean unsat core device. resulting propositional unsatisfiable core is:{(B1 B2 A1 ), (B1 B2 A2 ), (B1 B2 A2 ), (A2 B3 ), B5 ,(B7 A1 ), (B2 B1 ), (B7 B5 ), (B3 B5 )},corresponds (via P2T ) to:{((x = 0) (x = 1) A1 ), ((x = 0) (x = 1) A2 ), ((x = 0) (x = 1) A2 ),(A2 (y = 1)), B5 , ((y = 2) A1 ),((x = 1) (x = 0)), ((y = 2) (y < 0)), ((y = 1) (y < 0))}.Since last three clauses included LA(Z)-lemmas, thus LA(Z)-valid,eliminated. resulting core consists first 6 clauses. case,core turns minimal, identical modulo reordering computedMathSAT proof-tracing (see Example 1).observed end previous section, technique works also SMT toollearns mixed Boolean+theory clauses (provided original -lemmas stored),715fiCimatti, Griggio, & Sebastianiuses lazy theory deduction Nieuwenhuis et al. (2006). Moreover, works also-lemmas contain new atoms (i.e. atoms appear ), approachesFlanagan et al. (2003), Barrett, Nieuwenhuis, Oliveras, Tinelli (2006), sinceFacts (ii) (i) hold also case.side observation, remark technique works also per-constraintencoding eager SMT approach Goel, Sajid, Zhou, Aziz, Singhal (1998), Strichman, Seshia, Bryant (2002). eager SMT approach, input -formulatranslated equi-satisfiable Boolean formula, SAT solver used checksatisfiability. per-constraint-encoding Goel et al. (1998) Strichman et al.(2002), resulting Boolean formula conjunction propositional abstraction pformula propositional abstraction conjunction-valid clauses. Therefore, plays role -lemmas lazy approach,approach still works. idea falls scope work, expandedfurther.4.3 DiscussionDespite simplicity, proposed approach appealing several reasons.First, extremely simple implement. building unsat cores delegatedexternal device, fully decoupled internal DPLL-based enumerator.Therefore, need implementing internal unsat core constructormodify embedded Boolean device. Every possible external device interfacedplug-and-play manner simply exchanging couple DIMACS files9 .Second, approach fully compatible optimizations carried coreextractor Boolean level: every original clause Boolean unsat core deviceable drop, also dropped final formula. Notably, involves also Booleanunsat-core techniques could difficult adapt SMT setting (andimplement within SMT solver), ones based genetic algorithms (Zhanget al., 2006).Third, benefits free research propositional unsat-core extraction, sincetrivial update: novel, efficient effective Boolean unsat coredevice available, used plug-and-play way. require modifyingDPLL engine embedded SMT solver.One may remark that, principle, number -lemmas generated solver huge, storing -lemmas might cause memory-exhaustion problemsgeneration Boolean formulas big handled Boolean unsatcore extractor. practice, however, real problem. fact, even hardestSMT formulas reach current lazy SMT solvers rarely need generating105 -lemmas, whereas current Boolean unsat core extractors handle formulasorder 106 107 clauses. fact, notice default choice MathSAT learn-lemmas permanently anyway, never encountered problems duefact. Intuitively, unlike plain SAT, lazy SMT computational effort typicallydominated search theory , number clauses storedreasonable amount memory, fed SAT solver, typically much9. DIMACS standard format representing Boolean CNF formulas.716fiComputing Small Unsatisfiable Cores Satisfiability Modulo Theoriesbigger number calls -solver overall accomplished withinreasonable amount time.Like SMT unsat-core techniques adopted current SMT solvers, alsonovel approach resulting -unsatisfiable core guaranteed minimal,even Boolean Unsat Core returns minimal Boolean unsatisfiable cores. However,Lemma-Lifting technique possible perform reductions doneconsidering Boolean skeleton formula. Although generalenough guarantee minimality, still significant gain, shall shownext section. Moreover, notice also possible obtain minimal UCs iterativelycalling one SMT core extractor, time dropping one (or more) clause(s) currentUC checking -inconsistency. minimization technique orthogonal wrt.SMT core-extractor adopted, investigated here.5. Empirical Evaluationcarried extensive experimental evaluation Lemma-Lifting approach.implemented approach within MathSAT (Bruttomesso et al., 2008) system.MathSAT extended interface external Boolean unsatisfiable core extractors (UCE) exchange Boolean formulas relative cores form files DIMACSformat. (No modification needed storage -lemmas, MathSATalready learn permanently them.)tried eight different external UCEs, namely Amuse (Oh et al., 2004), PicoSAT(Biere, 2008), Eureka (Dershowitz et al., 2006), MiniUnsat (van Maaren & Wieringa,2008), MUP (Huang, 2005), Trimmer (Gershman et al., 2008), ZChaff (Zhang & Malik,2003), tool proposed Zhang et al. (2006) (called Genetic here).tools explicitly target core size reduction (or minimality), exception PicoSAT,conceived speeding core generation, claims minimality. fact,PicoSAT turned fastest least effective reducing sizecores. reasons, adopted baseline choice, ideal starting pointevaluating trade-off efficiency (in execution time) effectiveness (in coresize reduction). Thus, start evaluating approach using PicoSAT externalUCE (5.1) investigate usage effective though expensiveUCEs ( 5.2).experiments performed subset SMT-LIB (Ranise & Tinelli,2006) benchmarks. used total 561 -unsatisfiable problems, taken QF UF(126), QF IDL (89), QF RDL (91), QF LIA (135) QF LRA (120) divisions, selectedusing criteria used annual SMT competition. particular, benchmarksselected randomly available instances SMT-LIB, giving higherprobability real-world instances, opposed randomly generated handcrafted ones.(See http://www.smtcomp.org/ additional details.)used preprocessor convert instances CNF (when required),cases translate SMT language native language particularSMT solver. 1010. particular, CVC3 Yices compute unsatisfiable cores problems givennative format.717fiCimatti, Griggio, & Sebastiani100100PicoSAT time1000PicoSAT time10001010.11010.10.11101001000Total time0.11101001000MathSAT timeFigure 5: Overhead PicoSAT wrt. total execution time MathSAT+PicoSAT(left) wrt. execution time MathSAT (right).tests performed 2.66 GHz Intel Xeon machines 16 GB RAMrunning Linux. tested instance (unless explicitly stated otherwise) timeoutset 600 seconds, memory limit 2 GB. Boolean UCEs,used default configurations.5.1 Costs Effectiveness Unsat-Core Extraction Using PicoSATtwo scatter plots Figure 5 give first insight price Lemma-Liftingapproach pay running external UCE. plot left comparesexecution time PicoSAT total time MathSAT+PicoSAT, whilst plotright shows comparison time PicoSAT MathSATsolving time only. two figures, clearly seen that, except cases,time required PicoSAT much lower even negligible wrt. MathSAT solvingtime. Notice also price payed case unsatisfiable benchmarks.analyze approach respect size unsat cores returned.compare baseline implementation approach, MathSAT+PicoSAT,MathSAT+ProofBasedUC (i.e. MathSAT proof tracing), CVCLite (Barrett &Tinelli, 2007), 11 Yices. 12 also performed comparison (the SMT versionof) CAMUS (Liffiton & Sakallah, 2008), running SingleMUS mode (generateone minimal UC, CAMUS-one hereafter). also tried run CAMUS AllMUSmode (generate minimal UCs), encountered unexpected results (in11. tried use newer CVC3, difficulties extraction unsatisfiable coresit. Therefore, reverted older CVCLite experiments.12. CVCLite version 20061231 Yices version 1.0.19.718fiComputing Small Unsatisfiable Cores Satisfiability Modulo TheoriesCore/Problem size ratioMathSAT+PicoSATMathSAT+ProofBasedUC111/21/21/51/51/101/101/1001/1001/10001/10001010010001000010000010Core/Problem size ratioYices10010001000010000010000100000CVCLite111/21/21/51/51/101/101/1001/1001/10001/100010100100010000100000101001000CAMUS-one1Core/Problem size ratio1/21/51/101/1001/100010100100010000100000Size problem (# clauses)Size problem (# clauses)Figure 6: Ratio size original formula unsat core computedvarious solvers.719fiCimatti, Griggio, & SebastianiCVCLite w.u.c.MathSAT+ProofBasedUCMathSAT+PicoSATMathSAT+PicoSAT33223/23/2112/32/31/21/21/31/31010010001000010000010100Yices w.u.c.100010000100000CAMUS-oneMathSAT+PicoSATMathSAT+PicoSAT33223/23/2112/32/31/21/21/31/310100100010000core size ratioCVCLite w.u.c.MathSAT+PicoSATMathSAT+ProofBasedUCMathSAT+PicoSATYices w.u.c.MathSAT+PicoSATCAMUS-oneMathSAT+PicoSAT100000101001000100001000001st quartilemedianmean3rd quartile1.001.161.331.361.001.031.091.100.971.031.081.090.881.021.321.18Figure 7: Comparison size unsat cores computed MathSAT+PicoSATCVCLite, MathSAT+ProofBasedUC, Yices unsatcores CAMUS-one, statistics unsat core ratios.Points middle line values greater 1.00 mean better core qualityMathSAT+PicoSAT, vice versa.executions generated MUSes larger unsat cores foundtools13 ), exclude experiments.13. surprising because, definition, output produced CAMUS AllMUS modealways contain UCs minimum size, thus smaller foundtools. Therefore, explanation results, apart conjecturing presencebug CAMUS, incorrect use side (although followed indications authors),720fiComputing Small Unsatisfiable Cores Satisfiability Modulo Theoriesorder allow CAMUS-one terminate significant amount samples,run increased timeout 1800 seconds. Even so, CAMUS-one able produce one UC within timeout 144 formulas 561. record, MathSAT+PicoSAT, MathSAT+ProofBasedUC, CVCLite, Yices solved withintimeout 474, 503, 253 494 problems 561 respectively.Notice present comparison time different toolssignificant determining relative cost unsat-core computation, since (i)former four tools time completely dominated solving time,varies lot solver solver (even within MathSAT, proof production requires settingad-hoc options, may result significantly-different solving times since differentsearch space explored); (ii) comparison CAMUS terms speed wouldfair, since ultimate goal CAMUS enumerate mimimal UCs,first runs very-expensive step enumerating MCSs (see 3.2).Figure 6 shows absolute reduction size performed different solvers:x-axis displays size (number clauses) problem, whilst y-axis displaysratio size unsat core size problem. instance, pointvalue 1/10 means unsatisfiability due 10% problemclauses.Figure 7(top) shows relative comparisons data Figure 6. plot comparesMathSAT+PicoSAT solvers. plots, shall callcore-ratio plots, following meaning: x-axis displays size (numberclauses) problem, whilst y-axis displays ratio size unsatcore computed CVCLite, MathSAT+ProofBasedUC, Yices CAMUS-onecomputed MathSAT+PicoSAT. instance, point value 1/2 meansunsat core computed current solver half size computedMathSAT+PicoSAT; values 1 mean smaller core MathSAT+PicoSAT.core-ratio plots, consider instances solvers terminated successfully, since interested size cores computed,execution times. Figure 7(bottom) reports statistics ratios unsat core sizescomputed two different solvers.comment order. results reported CAMUS-one quite surprisingwrt. expectations, since CAMUS-one supposed return minimal UC,would expect greater reductions core sizes. explained factminimal UC produced CAMUS-one necessarily minimum. fact,manually verified samples biggest core-size ratio UCs returnedCAMUS-one actually minimal, although significantly bigger returnedMathSAT+PicoSAT.Overall, results presented show that, even using Boolean UCE PicoSAT,least effective reducing size cores, effectiveness baselineversion approach slightly better tools.activation default incomplete heuristics CAMUS use order copecombinatorial explosion number MCSs UCs generated (see 3.2.)721fiCimatti, Griggio, & Sebastianireductioncore sizeexecution timewrt. baseline1310001/22Amuse1/51003/21/1011/100102/311/21/31/10000.110100100010000100000101001000100001000000.111010010000.111010010000.111010010001310001/221/51003/2Genetic1/1011/100102/311/21/31/10000.11010010001000010000010100100010000100000131000Eureka1/221/51003/21/1011/100102/311/21/31/10000.11010010001000010000010100100010000100000Figure 8: Comparison core sizes (left), core ratios (middle) run times (right)using different propositional unsat core extractors. core-ratio plots (2ndcolumn), X-axis represents size problem, Y-axis representsratio size cores computed two systems: pointmiddle line means better quality baseline system. scatterplots (3rd column), baseline system (MathSAT+PicoSAT) alwaysX-axis.5.2 Impact Costs Effectiveness Using Different Boolean Unsat CoreExtractorssecond part experimental evaluation compare results obtained usingdifferent UCEs terms costs effectiveness reducing size core. showthat, depending UCE used, possible reduce significantly size cores,trade core quality speed execution (and vice versa), implementation722fiComputing Small Unsatisfiable Cores Satisfiability Modulo Theoriesreductioncore sizeexecution timewrt. baseline131000MiniUnsat1/221/51003/21/1011/100102/311/21/31/10000.110100100010000100000101001000100001000000.111010010000.111010010000.11101001000131000Trimmer1/221/51003/21/1011/100102/311/21/31/10000.11010010001000010000010100100010000100000131000ZChaff1/221/51003/21/1011/100102/311/21/31/10000.11010010001000010000010100100010000100000Figure 9: Comparison core sizes (left), core ratios (middle) run times (right)using different propositional unsat core extractors (continued).effort. compare baseline configuration MathSAT+PicoSAT, sixconfigurations, calling different propositional UCE.results collected Figures 8-9. first column shows absolute reductionsize performed tool (as Figure 6). second column shows core-ratio plotscomparing configuration baseline one using PicoSAT (as Figure 7,points 1.00 meaning better performance current configuration). Finally,scatter plots third column compare execution times (with PicoSAT alwaysX-axis). evaluated six configurations use, respectively, Amuse (Oh et al.,2004), Genetic (Zhang et al., 2006), Eureka (Dershowitz et al., 2006), MiniUnsat (vanMaaren & Wieringa, 2008), Trimmer (Gershman et al., 2008), ZChaff (Zhang &Malik, 2003), baseline configuration, using PicoSAT. also comparedMUP (Huang, 2005), stop experiments memory exhaustion723fiCimatti, Griggio, & SebastianiCVCLite w.u.c.MathSAT+ProofBasedUCMathSAT+EurekaMathSAT+Eureka33223/23/2112/32/31/21/21/31/31010010001000010000010Yices w.u.c.100100010000100000CAMUS-oneMathSAT+EurekaMathSAT+Eureka33223/23/2112/32/31/21/21/31/310100100010000core size ratioCVCLite w.u.c.MathSAT+EurekaMathSAT+ProofBasedUCMathSAT+EurekaYices w.u.c.MathSAT+EurekaCAMUS-oneMathSAT+Eureka100000101001000100001000001st quartilemedianmean3rd quartile1.031.321.551.731.031.171.271.351.001.161.281.340.981.051.411.26Figure 10: Ratios unsat-core sizes computed MathSAT+EurekaCVCLite, MathSAT+ProofBasedUC, Yices CAMUS-one.Points middle line values greater 1.00 mean better corequality MathSAT+Eureka, vice versa.problems. Looking second column, notice Eureka, followed MiniUnsatZChaff, seems effective reducing size final unsat cores,1/3 size obtained plain PicoSAT. Looking third column,notice Genetic, Amuse, MiniUnsat ZChaff, part Eureka,efficiency degrades drastically, many problems cannot solved within timeout.Trimmer performance gap dramatic, still order magnitudeslower baseline version.724fiComputing Small Unsatisfiable Cores Satisfiability Modulo TheoriesFinally, Figure 10 compare effectiveness MathSAT+Eureka,effective extractor Figures 8-9, directly three solvers, CVCLite,MathSAT+ProofBasedUC Yices, CAMUS. (Also compareresults Figure 7.) gain core reduction wrt. previous state-of-the-artSMT core-reduction techniques evident.important notice that, due limited know-how, used Boolean UCEsdefault configurations. Therefore, believe even better results, termseffectiveness efficiency, could obtained means accurate tuningparameters core extractors.side remark, notice results Figures 8-9 produced byproductinsightful evaluation main Boolean unsat-core-generation tools currently available.extent, notice performances MUP (Huang, 2005) Genetic (Zhanget al., 2006) seem rather poor; PicoSAT (Biere, 2008) definitely fastest tool, thoughleast effective reducing size final core; opposite side, Eureka(Dershowitz et al., 2006) effective task, pays fee terms CPUtime; Trimmer (Gershman et al., 2008) represents good compromise effectivenessefficiency.6. Conclusionspresented novel approach generating small unsatisfiable cores SMT,computes posteriori, relying external propositional unsat core extractor.technique simple concept, straightforward implement update. Moreover, benefits free advancements propositional unsat core computation.experimental results shown that, using different core extractors, possiblereduce significantly size cores trade core quality speed execution (andvice versa), implementation effort.byproduct, also produced insightful evaluation main Booleanunsat-core-generation tools currently available.Acknowledgmentswish thank Mark Liffiton help CAMUS tool. also thankanonymous referees helpful suggestions.A. Griggio supported part European Communitys FP7/2007-2013 grantagreement Marie Curie FP7 - PCOFUND-GA-2008-226070 progetto Trentino, projectAdaptation.R. Sebastiani supported part SRC GRC Custom Research Project 2009-TJ1880 WOLFLING.ReferencesAsn, R., Nieuwenhuis, R., Oliveras, A., & Rodrguez Carbonell, E. (2008). Efficient Generation Unsatisfiability Proofs Cores SAT. Cervesato, I., Veith, H., &Voronkov, A. (Eds.), Proceedings LPAR08, Vol. 5330 LNCS, pp. 1630. Springer.725fiCimatti, Griggio, & SebastianiAudemard, G., Bertoli, P., Cimatti, A., Kornilowicz, A., & Sebastiani, R. (2002). SATBased Approach Solving Formulas Boolean Linear Mathematical Propositions. Proc. CADE2002., Vol. 2392 LNAI. Springer.Barrett, C., Nieuwenhuis, R., Oliveras, A., & Tinelli, C. (2006). Splitting DemandSAT Modulo Theories.. Hermann, M., & Voronkov, A. (Eds.), LPAR, Vol. 4246LNCS, pp. 512526. Springer.Barrett, C., & Tinelli, C. (2007). CVC3. Damm, W., & Hermanns, H. (Eds.), CAV, Vol.4590 LNCS, pp. 298302. Springer.Barrett, C. W., Dill, D. L., & Stump, A. (2002). Checking Satisfiability First-OrderFormulas Incremental Translation SAT. Brinksma, E., & Larsen, K. G. (Eds.),Computer Aided Verification, 14th International Conference, CAV 2002, Copenhagen,Denmark, July 27-31, 2002, Proceedings, Vol. 2404 LNCS, pp. 236249. Springer.Barrett, C. W., Sebastiani, R., Seshia, S. A., & Tinelli, C. (2009). Satisfiability modulotheories. Biere, A., Heule, M., & van Maaren, H. (Eds.), Handbook Satisfiability.IOS Press.Biere, A. (2008). Picosat essentials. Journal Satisfiability, Boolean Modeling Computation (JSAT), 4, 7597.Bruttomesso, R., Cimatti, A., Franzen, A., Griggio, A., & Sebastiani, R. (2008).MathSAT 4 SMT Solver. Gupta, A., & Malik, S. (Eds.), CAV, Vol. 5123 LNCS,pp. 299303. Springer.Bryant, R. E., Kroening, D., Ouaknine, J., Seshia, S. A., Strichman, O., & Brady, B. (2009).abstraction-based decision procedure bit-vector arithmetic. Int. J. Softw. ToolsTechnol. Transf., 11 (2), 95104.Cimatti, A., Griggio, A., & Sebastiani, R. (2007). Simple Flexible Way ComputingSmall Unsatisfiable Cores SAT Modulo Theories.. Marques-Silva, J., & Sakallah,K. A. (Eds.), SAT, Vol. 4501 LNCS, pp. 334339. Springer.Davis, M., & Putnam, H. (1960). computing procedure quantification theory. JournalACM, 7, 201215.Davis, M., Logemann, G., & Loveland, D. W. (1962). machine program theoremproving.. Commun. ACM, 5 (7), 394397.de Moura, L., & Bjrner, N. (2008). Z3: Efficient SMT Solver. Ramakrishnan, C. R.,& Rehof, J. (Eds.), TACAS, Vol. 4963 LNCS, pp. 337340. Springer.Dershowitz, N., Hanna, Z., & Nadel, A. (2006). Scalable Algorithm Minimal Unsatisfiable Core Extraction.. Proceedings SAT06, Vol. 4121 LNCS. Springer.Dutertre, B., & de Moura, L. (2006). Fast Linear-Arithmetic Solver DPLL(T).Proc. CAV06, Vol. 4144 LNCS. Springer.Enderton, H. (1972). Mathematical Introduction Logic. Academic Pr.Flanagan, C., Joshi, R., Ou, X., & Saxe, J. B. (2003). Theorem Proving Using Lazy ProofExplication.. Jr., W. A. H., & Somenzi, F. (Eds.), CAV, Vol. 2725 LNCS, pp.355367. Springer.726fiComputing Small Unsatisfiable Cores Satisfiability Modulo TheoriesGershman, R., Koifman, M., & Strichman, O. (2008). approach extracting smallunsatisfiable core. Formal Methods System Design, 33 (1-3), 127.Goel, A., Sajid, K., Zhou, H., Aziz, A., & Singhal, V. (1998). BDD Based ProceduresTheory Equality Uninterpreted Functions.. Hu, A. J., & Vardi, M. Y.(Eds.), CAV, Vol. 1427 LNCS, pp. 244255. Springer.Goldberg, E. I., & Novikov, Y. (2003). Verification Proofs Unsatisfiability CNFFormulas. Proceedings 2003 Design, Automation Test Europe ConferenceExposition (DATE 2003), pp. 886891. IEEE Computer Society.Grumberg, O., Lerda, F., Strichman, O., & Theobald, M. (2005).Proof-guidedunderapproximation-widening multi-process systems. SIGPLAN Not., 40 (1), 122131.Huang, J. (2005). MUP: minimal unsatisfiability prover. Proceedings ASP-DAC 05.ACM Press.Liffiton, M., & Sakallah, K. (2008). Algortithms Computing Minimal UnsatisfiableSubsets Constraints. Journal Automated Reasoning, 40 (1).Lynce, I., & Marques-Silva, J. P. (2004). Computing Minimum Unsatisfiable Cores.SAT 2004 - Seventh International Conference Theory ApplicationsSatisfiability Testing, 10-13 May 2004, Vancouver, BC, Canada, Online Proceedings.Marques-Silva, J. P., & Sakallah, K. A. (1996). GRASP - new Search AlgorithmSatisfiability. Proc. ICCAD96.McMillan, K. L. (2002). Applying SAT Methods Unbounded Symbolic Model Checking.Brinksma, E., & Larsen, K. G. (Eds.), Proceedings CAV02, Vol. 2404 LNCS,pp. 250264. Springer.McMillan, K. L., & Amla, N. (2003). Automatic abstraction without counterexamples.Garavel, H., & Hatcliff, J. (Eds.), Proceedings TACAS03, Vol. 2619 LNCS, pp.217. Springer.Mneimneh, M. N., Lynce, I., Andraus, Z. S., Marques-Silva, J. P., & Sakallah, K. A. (2005).Branch-and-Bound Algorithm Extracting Smallest Minimal Unsatisfiable Formulas.. Proc. SAT05, Vol. 3569 LNCS. Springer.Nadel, A. (2010). Boosting Minimal Unsatisfiable Core Extraction. Bloem, R., & Sharygina, N. (Eds.), Proceedings 10th International Conference Formal MethodsComputer-Aided Design (FMCAD2010), pp. 221229.Nieuwenhuis, R., Oliveras, A., & Tinelli, C. (2006). Solving SAT SAT Modulo Theories:abstract DavisPutnamLogemannLoveland procedure DPLL(T). J.ACM, 53 (6), 937977.Oh, Y., Mneimneh, M. N., Andraus, Z. S., Sakallah, K. A., & Markov, I. L. (2004).Amuse: Minimally-Unsatisfiable Subformula Extractor. Proceedings DAC04.ACM/IEEE.Ranise, S., & Tinelli, C. (2006). Satisfiability Modulo Theories Library (SMT-LIB).www.SMT-LIB.org.727fiCimatti, Griggio, & SebastianiSebastiani, R. (2007). Lazy Satisfiability Modulo Theories. Journal Satisfiability, BooleanModeling Computation, JSAT, Volume 3.Strichman, O., Seshia, S. A., & Bryant, R. E. (2002). Deciding Separation FormulasSAT. Brinksma, E., & Larsen, K. G. (Eds.), CAV, Vol. 2404 LNCS, pp. 209222.Springer.Suelflow, A., Fey, G., Bloem, R., & Drechsler, R. (2008). Using unsatisfiable cores debugmultiple design errors. Proceedings GLSVLSI08, pp. 7782, New York, NY,USA. ACM.Tseitin, G. S. (1983). complexity derivation propositional calculus. AutomationReasoning: Classical Papers Computational Logic 1967-1970Studies Constructive Mathematics Mathematical Logic, Part 2, 2. Originally published 1970.van Maaren, H., & Wieringa, S. (2008). Finding Guaranteed MUSes Fast. SAT, Vol.4996 LNCS, pp. 291304. Springer.Wang, C., Kim, H., & Gupta, A. (2007). Hybrid CEGAR: combining variable hidingpredicate abstraction. Proceedings ICCAD07, pp. 310317, Piscataway, NJ,USA. IEEE Press.Zhang, J., Li, S., & Shen, S. (2006). Extracting Minimum Unsatisfiable Cores GreedyGenetic Algorithm.. Proceedings ACAI, Vol. 4304 LNCS. Springer.Zhang, L., Madigan, C. F., Moskewicz, M. H., & Malik, S. (2001). Efficient conflict drivenlearning boolean satisfiability solver. Proceedings ICCAD 01. IEEE Press.Zhang, L., & Malik, S. (2002). quest efficient boolean satisfiability solvers..Voronkov, A. (Ed.), CADE, Vol. 2392 LNCS, pp. 295313. Springer.Zhang, L., & Malik, S. (2003). Extracting Small Unsatisfiable Cores UnsatisfiableBoolean Formulas. Proceedings 6th International Conference TheoryApplications Satisfiability Testing (SAT2003).728fiJournal Articial Intelligence Research 40 (2011) 599-656Submitted 11/10; published 03/11Decidability Undecidability ResultsPropositional SchemataVincent AravantinosRicardo CaferraNicolas PeltierVincent.Aravantinos@imag.frRicardo.Caferra@imag.frNicolas.Peltier@imag.frUniversite de Grenoble (LIG/CNRS)Bat. IMAG C, 220, rue de la Chimie38400 Saint Martin dHeres, FranceAbstractdene logic propositional formula schemata addingsyntaxpropositional logic indexed propositions (e.g., pi ) iteratedconnectivesrangingnintervals parameterized arithmetic variables (e.g., i=1 pi , n parameter ).satisability problem shown undecidable new logic, introducegeneral class schemata, called bound-linear, problem becomes decidable. result obtained reduction particular class schemata called regular,provide sound complete terminating proof procedure. schematacalculus (called stab) allows one capture proof patterns corresponding large classproblems specied propositional logic. also show satisability problem becomes undecidable slight extensions class, thus demonstratingbound-linear schemata represent good compromise expressivity decidability.1. Introductionable solve classes problems possibly eciently elegantly strongly dependslanguage specied. decisive lot applicationsArticial Intelligence. One language long used humans schemata.general characterizations notion schema would useless, focusedparticular class schemata arising naturally practice, quite expressive (asshown) good computational properties. schemata generatedunbounded repetitions patterns, call iterated schemata.motivate approach via example, frequently used well-knownAI community: circuit verication. Circuit verication problems often modeledsequences propositional problems parameterized natural number n encodessize data (e.g., number bits, number layers circuit, etc.). callsequences iterated schemata, simply schemata. typical example n-bit sequentialadder circuit i.e. circuit computes sum two bit-vectors length n.circuit built composing n 1-bit adders. ith bits operand written piqi . ri ith bit result ci+1 carried next bit (thus c1 = 0).set notations ( denotes exclusive or):Sumi (p, q, c, r) = ri (pi qi ) cidefc2011AI Access Foundation. rights reserved.fiAravantinos, Caferra & PeltierCarryi (p, q, c) = ci+1 (pi qi ) (ci pi ) (ci qi ).defformula:defAdder(p, q, c, r) =nSumi (p, q, c, r)i=1nCarryi (p, q, c) c1i=1constraint n 1, schematises adder circuit (it states r encodes sump q). Adder contains iterations ranging intervals depending n. n instantiatednatural number expression reduces propositional formula. Thereforeinstance schema solved propositional logic. However, provingschema unsatisable (or satisable) every instance n much harder.problem cannot specied propositional logic and, shall see, evenscope rst-order logic. expressed higher order logics well-knownlanguages less suitable automation (see Section 3 details).iteration schemata ubiquitous formalized reasoning. Problems nitedomains specied generic propositional formulae tting pattern,parameter (nite unbounded) size domain. Among patterns,corresponding pigeonhole principle, Ramsey theory, coloring graphs problemsconstraint programming specications n-queens problem (Marriott, Nethercote,Rafeh, Stuckey, Garca de la Banda, & Wallace, 2008) mentioned. Iteratedschemata also extremely useful formalization mathematical proofs,allow one express innite proof sequences, avoid, instance, explicituse induction principle. idea used, e.g., work Hetzl, Leitsch,Weller, Woltzenlogel Paleo (2008).paper present rst (to best knowledge) thorough analysispropositional iterated schemata. dene logic handling arithmetic variables, indexedpropositions iterated connectives. satisability problem obviously semi-decidablesense (straightforward) algorithm exists enumerate satisable schemata(i.e. schemata satisable instance). However set (unrestricted) unsatisableschemata recursively enumerable. Thus restrict particular classschemata, called bound-linear provide decision procedure class.procedure based reduction simple class schemata, called regular,tableaux-based proof procedure presented. provide undecidabilityresults (rather natural) extensions class.rest paper structured follows.Section 2 introduce logic (syntax semantics) handling propositionalschemata establish basic properties. propositional symbolsindexed arithmetic expressions (e.g., pn+1 ) containing arithmetic variables.variables either parameters (i.e.free variables),bound variables introducedgeneralized connectives form bi=a bi=a . connectives read[a, b] [a, b], a, b arithmetic expressions possibly containing (freebound) variables. restrict monadic schemata (i.e. propositions600fiDecidability Undecidability Results Propositional Schemataindexed one expression) linear arithmetic expressions1 .introduce particular subclass schemata, called bound-linear. Intuitively, schemabound-linear every arithmetic expression occurring contains onebound variable. Furthermore, coecient variable expression1 (or 0). Thus expressions 1, n, 2n + 2 allowed (where nparameter bound variable), 2i + j (where i, j bound)not. coecient parameter n constrained.Section 3 contains brief survey existing work propositional schemata well(informal) comparisons related logics.Section 4 introduce simpler class schemata, called regular, providealgorithm transform every bound-linear schema (sat-)equivalent regularschema.Section 5 tableaux-based proof procedure, called stab (standing schematatableaux), introduced reasoning propositional schemata. proof procedure sound complete (w.r.t. satisability) terminates every regularschema. Together results Section 4 implies class boundlinear schemata decidable.Section 6 shows relaxing slightly conditions bound-linear schematamakes satisability problem undecidable. Thus class seen canonical, good trade-o expressivity, simplicity denitiondecidability.Finally, Section 7 summarizes results provides lines future work.2. Schemata Propositional Formulaesection, introduce syntax semantics propositional schemata.2.1 Syntaxset linear arithmetic expressions (denoted N ) built usual signature0, s, +, xed countably innite set arithmetic variables V, quotientedusual properties arithmetic symbols (e.g., n + s(0) + n + s(s(s(0)))n + n + s(s(s(s(0)))) assumed equivalent). usual, (0) denoted+ . . . + ( times) .i. n arithmetic variable denote Nn setarithmetic expressions form .n + , Z (with possibly = 0)Nn set expressions form n + Z. Obviously Nn Nn N .n + , n + Nn write n + n + .1. one two conditions hold satisability problem trivially undecidable.instance, Post correspondence problem easily encoded schemata non monadicvariables (Aravantinos, Caferra, & Peltier, 2009b). Similarly, non linear arithmetic expressionsconsidered 10th Hilberts problem encoded.601fiAravantinos, Caferra & Peltiersake readability, adopt following conventions. Integers denotedGreek letters , , , 2 , natural numbers , arithmetic variables i, j, k, n,propositional variables p, q, r (with indices). Arithmetic expressions denoteda,b,c,d.Schematadenoted,.denotegenericiterationconnectives.Definition 2.1 (Indexed propositions)Let P xed countably innite set propositional symbols. indexed propositionexpression form pa p P linear arithmetic expression (theindex ). indexed proposition pa s.t. Z called propositional variable. literalindexed proposition negation.contrast previous work (Aravantinos et al., 2009b) consider monadicpropositions, i.e. every proposition one index.Definition 2.2 (Schemata)set formula schemata smallest set satisfying following properties., formula schemata.a, b integer expressions < b formula schema.indexed proposition formula schema.1 , 2 schemata 1 2 , 1 2 1 formula schemata.formulab containing <, a, b N , arithmeticb schemavariable, i=a i=a formula schemata.Notice that, denition, every schema mustbe nite. Schemataform < b, pa, called atoms. Schemata form bi=a bi=a called iterations,b bounds iteration b length (notice b may containvariables). schema arithmetic formula contains iteration every atomoccurring form , < b. particular, every boolean combinationarithmetic atoms schema. b (or b a) = b used abbreviations(b < a) (b < a) (a < b) respectively. arithmetic expressions, arithmeticformulae taken arithmetic equivalence, e.g., n = 1 n < 2n > 0 consideredidentical. usual priority rules apply disambiguate reading formula schemata.Analogouslyrst-order logic quantiers,n iteration operators highest priorityn(e.g., i=1 pi pn p1 read ( i=1 pi ) (pn p1 )).Example 2.3= q1ni=1pi+2n2n+1(qnj qj+1 ) n 0formula schema.j=n)n (2n+1q1 , pi , qj qj+1 indexed propositions.p(qq)i+2nnjj+1i=1j=n2n+1j=n (qnj qj+1 ) iterations occurring S.2. slightly unusual convention used avoid confusion arithmetic variables integers.602fiDecidability Undecidability Results Propositional SchemataRemark 2.4Noticenarithmetic atoms forman < b occurnoutside iterations,i.e. n 1 i=1 pi allowed, neither i=1 (i 3 pi ) i=1 (n 1 pi ).restriction used simplify technicalities. shall see Denition 2.5(semanticsschemata), arithmetic atom form < b equivalent schema bi=a+1 .variable bound contains iteration form bi=a ( { , }),free (or parameter ) occurrence scopeiteration bi=a . on, assume thatno variable simultaneously freebound schema (thus schematasuchpn 10n=1 pn well-formed)bi=a j=c (where , { , }) two distinct iterations occurringj distinct.substitution function mapping every arithmetic variable linear arithmeticexpression. write [a1 /i1 , . . . , /i ] substitution mapping respectively i1 , . . . ,a1 , . . . , . application substitution schema (or arithmetic expression)dened usual denoted . Notice arithmetic expressionsubstitution mapping every variable ground term (i.e. term variable)integer (since identify, e.g., 2 1 1).previous notation also used denote replacement subexpressions:schema, expression (schema arithmetic expression) occurringexpression type , [ /] denotes formula obtained replacingoccurrences .2.2 Semanticsinterpretation schemata language function mapping every integer variableinteger every propositional variable truth value F. interpretationsubstitution, denote interpretation dened follows:defcoincide every propositional variable every variable n, I(n) = I(n). Considerinstance following interpretation I:n 7 57 2p1 7p2 7 Fp3 7 Fp4 7 F603fiAravantinos, Caferra & Peltierwhose denition unsignicant (integer propositional) variables. Let alsosubstitution {n 7 n 1, 7 2}. is:n 7 47 0p1 7p2 7 Fp3 7 Fp4 7 Finterpretation, denote restriction V, i.e. substitutionmapping every variable n I(n). arithmetic expression, denote JaKIexpression aI . Since aI ground, (equivalent to) integer.Definition 2.5 (Semantics)truth value JKI propositional schema interpretation inductively denedas:JKI = T, JKI = FJa < bKI = JaKI < JbKI .Jpa KI = I(pJaKI ) p P.JKI = JKI = F.J KI = JKI = J KI = T.J KI = JKI = J KI = T.J bi=a KI = integer s.t. JaKI JbKI JKI[/i] = T.Jbi=a KI= every integer s.t. JaKI JbKI : JKI[/i] = T.schema satisable interpretation s.t. JKI = T. called model(written |= ). Two schemata , equivalent (written ) |= |= .sat-equivalent (written ) satisableunsatisable.following, assume every free variable n every model, I(n) N. ensured explicitly adding arithmetic atom n 0 3 .Let following system rewrite rules:3. Thus assume parameters mapped natural numbers. convention convenientallows one use mathematical induction parameters (see Section 5.2). restrictive sinceschema n Z could replaced (equivalent) disjunction schemata n 0[m/n] 0 (i.e. case n negative, every occurrence n simply replacedm).604fiDecidability Undecidability Results Propositional Schematai=i=S=i=i=( 1i= ) [/i]1( i= ) [/i],,,,Z,Z,Z,Z,<<instance following formula:p13(pi pi+1 )i=1rewritten into:p1 (p1 p2 ) (p2 p3 ) (p3 p4 )Notice rule applies p1 ni=1 (pi pi+1 ) upper bound iterationcontains parameter. actually designed used schemas whose parametersinstantiated number.Proposition 2.6convergent preserves equivalence.ProofTermination immediate since length iteration strictly decreases step.Conuence obvious since critical pairs trivially joinable. fact obtainedschema equivalent original one straightforward consequence Denition 2.5.denote (unique) normal form . substitution mapping everyfree variable natural number, called propositional realization .trivially semi-decidable know schema satisable:Proposition 2.7set satisable schemata recursively enumerable.ProofDenition 2.5, every interpretation every schema , (I |= )(I |= ), = . Thus satisable exists substitutionsatisable. prove exists algorithm checking satisability. Proposition 2.6, . denition , contains freevariable. Let bi=a outermost iteration . denition b must ground,thus one rules applies impossible. Thus contains iterationhence propositional formula (in usual sense) built set propositionalvariables. Consequently, exists algorithm check whether formulasatisable not. Since set ground substitutions recursively enumerable,since satisable satisable least one substitution , impliessemi-decidable check whether satisable not.605fiAravantinos, Caferra & Peltierevery schema every substitution denote [] formula .every arithmetic expression (possibly containing bound variables) schema ,compute interval [min (a), max (a)] min (a), max (a) arithmetic expressions containing variables free . intuition always belongsinterval. Lemma 2.8 formalizes property.integer variable free min (a) = max (a) = a.defdefform b + c min (a) = min (b) + min (c) max (a) = max (b) +max (c).defdefform b max (a) = min (b) min (a) = max (b).defdefbound variable, occurring iteration form bi=a min (i) =defmin (a) max (i) = max (b).defground substitution -expansion another ground substitution subschema every variable bound , (i) [(min (i)), (max (i))](since , ground, expressions (i), (min (i)), (max (i)) considered integers). intuition behind -expansions following: substitution aectbound variables schema; values given bound variablesunsignicant; contrary, denition -expansion imposes that:1. value given variable bound indeed falls set valuestake context ;2. value given variable free one given .W.r.t. substitution application, dierence . next lemmashows importance -expansions.Lemma 2.8Let schema let variable (possibly bound) occurring . expressionsmin (i) max (i) well-dened. Moreover, every ground substitutionatoms p occurring [] exist atom pa occurring -expansionpa s.t. (a) = .Proofimmediate consequence Denition 2.5 (by straightforward inductiondepth schema).write IC () (standing Interval Constraints) conjunction arithmeticconstraints form min (i) max (i) variable bound .IC () extended setsschemata handling conjunctions.Consider, e.g., = p0 n1i=1 (pi+1 qi ). have: min (i) = 1 max (i) = n 1.Consider furthermore = {n 7 4} p = p3 . take pa = pi+1 (which indeedoccurs ) = {n 7 4, 7 2}.see informally use -expansions: allow, sense, makeconnection propositional variable occurring instance schemaindexed proposition comes from.606fiDecidability Undecidability Results Propositional Schemata2.3 Class Bound-Linear Schematashall see (in, e.g., Theorem 6.2) satisability problem undecidable schemata.order characterize decidable subclass, introduce following denition:Definition 2.9schema bound-linear following conditions hold:1. contains one free arithmetic variable n (called parameter ).2. Every non arithmetic atom form p.n+.i+ p P boundvariable, , Z {1, 0, 1}.3. bi=a iteration (where { , }) a, b respectively form.n + .n + + .j , , , Z, {1, 0, 1} j bound variable.class comprehensive enough respect decidable satisability. keypoint indices iteration bounds contain one bound variable.Furthermore, coecient variable must 1 (or 0).2.4 Expressiveness Bound-Linear Schemataorder show evidence class bound-linear schemata articialnarrow one, provide section examples problems naturallyencoded bound-linear schemata.easy check schema Adder(p, q, c, r) dened Introduction (formalizing sequential adder) bound-linear. Various properties circuit encoded.instance, following schema checks 0 (left) neutral element:(Adder(p, q, c, r)nnpi )i=1(ri qi )i=1schema checks adder function i.e. sum two operandsunique.n(Adder(p, q, c, r) Adder(p, q, c , r ))(ri ri )i=1next one checks commutative:(Adder(p, q, c, r) Adder(q, p, c , r ))n(ri ri )i=1Many similar circuits formalized similar way, carry look-aheadadder (a faster version n-bit adder reduces amount time requiredcompute carry bits):defCLA-Adder(p, q, c) =n(ri ((pi qi ) ci ))i=1n(ci+1 (pi qi ) (ci (pi qi )))i=1607fiAravantinos, Caferra & Peltierequivalence two denitions encoded follows:(Adder(p, q, c, r) CLA-Adder(p, q, c , r ))n(ri ri )i=1Comparison two natural numbers easily formalized, e.g. rn holds p q:r0n(ri (ri1 (pi qi ) pi qi ))i=1composing previous schemata, (quantier-free) formula Presburger arithmeticencoded.generally, one formalize every circuit composed serially putting together nlayers basic circuit. circuits usually dened inductively,easily encoded formalism formula form:(p0 base )n1(pi+1 ind ),i=0base ind formulae corresponding base case inductive case,respectively. ind contains occurrences pi encodes basic circuitcomposed sequence. course, complex circuits, pi may replaced vectorbits pi , qi , ri dened inductively pi1 , qi1 , ri1 ,. . . . inductively-denedcircuits appear frequently practice (Gupta & Fisher, 1993).index proposition denotes time, various nite state sequentialsystems encoded. state system described set propositionalvariables, pi encodes value p step i. parameter n denotes numbersteps transformation (which assumed nite unbounded). transitionfunction state + 1 easily formalized bound-linear schema.instance, inclusion two automata encoded (the parameter lengthrun). provide another example. Consider register three cells p, q, rassume two possible actions rl rr rotate values cellsleft right respectively. behavior system modeled followingschema (the propositions rli rri indicate action applied step i). First L(i)expresses state registers time depending state time 1,rli applied it:L(i) rli ((pi qi1 ) (qi ri1 ) (ri pi1 ))R(i) similar rr:R(i) rri ((pi ri1 ) (qi pi1 ) (ri qi1 ))Finally, state holds time:nnL(i)i=1ni=1608R(i)fiDecidability Undecidability Results Propositional Schemataexpress properties registers. instance, following formula statesn rotations right followed n rotations left equivalent identity:(2nni=1rri2nrli ) (p0 p2n ) (q0 q2n ) (r0 r2n )i=n+13. Related WorkDierent forms schemata used several authors, either propositional logic(Baaz & Zach, 1994) rst-order logic obtain results proof theory, particular related number proof lines (Parikh, 1973; Baaz, 1999; Krajicek & Pudlak,1988; Orevkov, 1991). Parikh (1973) presents notion schematic systems, Baaz (1999)uses concept unication, Krajicek Pudlak (1988) introduce notion proofskeleton, similar schema, Orevkov (1991) studies schemata rst-orderHilbert-type system. Pragmatically, schemata successfully used, e.g., solvingopen questions equivalential calculus (i.e. eld formal logic concernednotion equivalence) theorem-prover Otter (Wos, Overbeek, Lush, & Boyle,1992). However, best knowledge, formal handling schemataobject level never considered. Although notion schema recognizedimportant one, deserves applied works opinion. Sometimes schematasuciently emphasized, e.g., work Barendregt Wiedijk (2005) nicedeep analysis challenge computer mathematics given. authors overviewstate art (by describing comparing powerful existing systems use)structuring proofs explicitly mentioned (maybe feature includedcall mathematical style support reasoning gaps). approachschemata clear way structuring proofs also help overcomeone obstacles automation reasoning pointed Wos (1988), i.e. sizededuction steps.exist term languages expressive enough denote iteration schemataintroduced Denition 2.2: particular, term schematisation languages useddenote innite sequences structurally similar terms formulae. instanceprimal grammarn (Hermann & Galbavy, 1997) f (n) (p(n) f (n 1)), f (0) denotesiteration i=1 pi . worth mentioning iteration cannot denotedterm schematisation languages (Chen, Hsiang, & Kong, 1990; Comon, 1995)inductive context constant. However, term schematisation languages allowreason iterations (they useful represent them).Encoding schemata first-order logic natural idea, interpreting iteratedconnectives bounded quantiers. Additional axiomsbeadded express arithmeticproperties needed. instance schema ( ni=1 pi ) ( ni=1 pi ) encodedi.(1 n p(i)) i.(1 n p(i)) obviously unsatisable.However, since inductive domains cannot dened rst-order logic, translationnecessarily introduces unintended interpretations hence yield completeprocedure (satisability always preserved, although unsatisability obtainedformulanecessarily entails unsatisability original one). instance, schemap0 ni=1 (pi1 pi )pn translated p(0)i.(1 ii np(i1) p(i)p(n)),609fiAravantinos, Caferra & Peltieractually satisable (we know n N way expressproperty). order obtain unsatisable formula, inductive axioms mustadded allow (necessarily restricted) applications induction principle.particular case, proof obtained simple induction using inductivelemma i.(i n p(i)), thus could add axiom: [q(0)i.(q(i) q(i+1))] i.q(i)q(i) n p(i). axiom, easy check previous formulabecomes unsatisable. However, general case hard determine priori rightaxiom (if one). Actually termination proof Section 5 implicitly provides waydetermine candidate axioms (for particular class regular schemata): every loopingnode tableaux constructed proof procedure stab (see Section 5) correspondsapplication induction principle, hence induction axiom. terminationproof precisely shows size inductive lemmata bounded, thus wholeset potential induction axioms could principle computed added formulabeginning search. practical interest transformationobviously highly questionable.Several procedures designed proving inductive theorems, (Boyer &Moore, 1979; Bouhoula, Kounalis, & Rusinowitch, 1992; Comon, 2001; Bundy, van Harmelen, Horn, & Smaill, 1990; Bundy, 2001). Since schemata seen explicit wayhandling mathematical induction, using proof procedures provingnatural idea. general, induction used dene terms (e.g., recursive functions operating inductive data structures), whereas case formulae denedinductively. Obviously problem could solved using appropriate encodingformulae. However decidability results inductive theorem provingknown classes (Giesl & Kapur, 2001) expressive enough encode propositionalschemata. Notice systems concentrate universal quantications,handle iterated conjunctions (which interpreted universal quanticationnite domain) iterated disjunctions (i.e. analogous existential quantications). Adding existential quantication inductive theorem proving knowndicult problem. inductive theorem provers designed prove universal theoremsform x. quantier-free formula (usually clause) variablesx range set (nite) terms. context, would contain nite quantication(over intervals constrained n), corresponding iterated connectives. particular,schemata may several models, thus implicit induction (Comon, 2001) (which explicitlyrequires underlying Herbrand model unique) cannot (directly) used.course, problems overcome encoding interpretations terms (forinstance vectors ordered lists truth values) schemata functions mappingevery interpretation truth value. inductive theorem provers may used proveinductive properties functions (showing instance value everyinterpretation). However provers complete (due well-known theoreticallimitations) thus practical interest encoding unclear. instance,tried use theorem prover acl2 prove validity benchmarksconsidered Section 5, fails non trivial examples. conjecturedue eciency problems, additional inductive lemmata needed,hard determine advance.610fiDecidability Undecidability Results Propositional Schematadenitions also remind reader fixed point logics.Indeediterated schemata obviously particular cases xed points, e.g., schema ni=1 pimight represented (X(i).i 0(p(i)X(i1)))(n). standard xed point logic(propositional) modal -calculus (Bradeld & Stirling, 2007) many temporallogics encoded, e.g., LTL CTL. However involved logic dierentactually simpler theoretical point view. Indeed modal -calculusdecidable (and thus complete) whereas shall see Section 6 iterated schemata(nor complete). Furthermore, language allows one use complex(though carefully restricted) arithmetic operations denition iterations,indices bounds. instance may relate truth values twopropositions whose index arbitrary far (such pi pni ). faraware, operations cannot directly encoded propositional -calculus.Actually iterated schemata share much least fixpoint logic, LFP (Immerman, 1982), studied nite model theory (Fagin, 1993; Ebbinghaus & Flum, 1999):LFP logic allowing iterate rst-order formulae maintaining constant numbervariables. However know calculus deciding satisabilityLFP. see two reasons this: rst, LFP undecidable complete, secondpurposes logic mainly theoretical, hence fact research eldfocussed decision procedures subclasses. contrast propositional calculus, first-order -calculus (Park, 1976) clearlyembeds iterated schemata (allowinginstance xed-point expression ni=1 pi ), published research seemsfocused identication complete subclasses. similar expressive powerone also nds logics inductive denitions (Aczel, 1977) quite widespreadproof assistants (Paulin-Mohring, 1993), range automated theoremprovers. far know study complete subclass xed point logicswork Baelde (2009), iterated schemata denitely lie classreduced it.shall see Section 5.2, completeness bound-linear schemata (or preciselyregular schemata) lies detection cycles proof search. ideanew, used, e.g., tableaux methods dealing modal logics transitive frames(Gore, 1999), -calculi (Cleaveland, 1990; Bradeld & Stirling, 1992). However cycledetection work quite dierent use prove induction. Noticeparticular cannot general ensure termination (contrarily methods).relevant consider method particular instance cyclic proofs,studied proof theory precisely context proofs induction. worksBrotherston (2005), Sprenger Dam (2003), shown cyclic proofs seempowerful systems dealing classically induction. particular advantage cyclicproofs nding invariant needed, making particularly suited automation. However, studies essentially theoreticalcompleteness results particular subclasses.summarize, known decidable logics (such propositional -calculus) even semidecidable ones rst-order logic expressive enough directly embed iteratedschemata, whereas suciently expressive (such xpoint higher orderlogics) suitable automation. Together potential applications mentionedSection 2.4, justies opinion interest considered language.611fiAravantinos, Caferra & Peltier4. Reduction Regular Schematasection reduce satisability problem bound-linear schemata (see Denition2.9) much simpler class schemata, called regular. class dened follows:Definition 4.1schema is:every iteration bi=a occurring , contain iteration (i.e.iterations cannot nested ).bounded propagation every atom occurs iteration bi=aform pi+ Z. Since number atoms nite, exist , Zs.t. every atom pi+ occurring iteration [, ]. , calledpropagation limits.aligned [c, d] iterations occurring form di=c (i.e. iterationsmust bounds).regular unique parameter n at, bounded propagationaligned [, n ] , Z.example, schema Adder dened Introduction regular, lastexample Section 2.4 (three cells register shift) not. Obviously, every regular schemaalso bound-linear (see Denition 2.9). dene algorithm transforms everybound-linear schema sat-equivalent regular one. result somewhat surprisingclass regular schemata seems much simpler bound-linear schemata.sense, points regular schemata canonical decidable class schemata.4.1 Overview Transformation Algorithmrst give informal overview algorithm reducing every bound-linear schemaregular one, together examples illustrating transformation steps.high level description intended help reader grasp intuitive ideas behindformal denitions technical explanations provided next section.transformation divided several steps.rst step elimination iterationsn occurringn inside iteration. Considerinstance following schema : i=1 (pi j=1 qj ). reader checkbound-linearbut non regular. easy transform sat-equivalentregular schema: since nj=1 qj depend counter i, one simplyreplacenformula new propositional variable radd equivalencerj=1 qjnnoutside iteration. yields schema: i=1 (pi r) (r j=1 qj ),clearly regular sat-equivalent (but equivalent) . processgeneralized; however, replacing iteration proposition possibleiteration containsnnvariable boundn original schema. Considerschema: : i=1 j=1 (pi qj ). j=1 (pi qj ) cannot replacedvariable r, since depends i. solution get variable pi containing612fiDecidability Undecidability Results Propositional Schematatheiteration nj=1 (pi qj ):pi involve j, easily seenturn nj=1 (pi qj ) pi nj=1 qj . transformation generalizedusing case-splitting: indeed, well-known every formula equivalent(r [/r]) (r [/r]),every propositional variabler. Applyingnndecompositionscheme j=1 (pi qj ) pi get:) (pij=1 (pi qjnnn(q))(p(q)),i.e.(byusualtransformations):jjj=1j=1j=1 (pinnqj ) (pi j=1 qj )pi . Afterwards, remaining iteration j=1 qj replacednew variable r.decomposition scheme explained applied every variable occurringiteration, containing counter iteration. denitionbound-linear schemata, propositional symbols one index index contains one bound variable, thus technique actually removes everyatom containing counter variable distinct one considered iteration.However, remove variables occurinthe bound iteration.defConsider instance following formula: = ni=1 ij=1 qj . occursbound iteration thus cannotremoved previous technique.idea encode formula j=1 qj new variable ri , denedinductivelyfollows: r0 ri+1 ri qi+1 . expressed schema:(rr0 n1i=0 i+1 (ri qi+1 )).Notice ri needs dened = 0, . . . , n rangesinterval [1, n] .order get regular schema one guarantee every iteration rangesinterval form [, n ] (where Z). actuallysimple2nensure unfoldingshiftingiterations.instanceschemai=1 pi2nnnntransformed i=1 pi i=n+1 pi i=1 pi i=1 pi+n . Similarlyn1n1n1ni=2 pi pn q1 j=2 qj get iterations denedi=2 pi j=1 qj reducedinterval.major dierence regular schemata bound-linear ones that,regular schema, indexed variablesoccurring inside iteration cannot containparameters (e.g., iteration ni=1 pi+n forbidden). Thereforereplace every variable form p.n+i new variable qi , depending i.problem order preserve sat-equivalence, one also encoderelation variables. instance, assume pn+i replaced qip2nj replaced rj . obviously, must qi rj n+i = 2nj, i.e.qi rni . step may problematic general innitely manyaxioms. However, dening translation carefully, show actuallynitely many equivalences required. aim, assumeinitial coecient parameter even every index (see Denition 4.2),easy ensure case splitting. maximal number overlapsnewly dened variable actually bounded (this shown crucial lemma 4.6).instance, formula ni=0 (pi p2ni ) replaced ni=0 (pi qi ) (pn qn ).qi denotes atom p2ni equivalence encodes fact qn p2nn = pn .613fiAravantinos, Caferra & PeltierSince ranges interval [0..n] equation relevant w.r.t.(e.g. p0 q2n useless).algorithm transforming every bound-linear schema sat-equivalent regular schema specied sequence rewriting rules, operating schematapreserving sat-equivalence. rules depicted Figure 1. must appliedorder presentation. shall see Section 4.3, rewrite system terminates (inexponential time). Moreover satisability preserved irreducible schemata regular(see Section 4.4).4.2 Formal Definition Algorithmgive detailed precise description transformation algorithm (readers interested technical details skip section). assume initialschema satises following condition:Definition 4.2bound-linear schema normalized coecient parameter n evenexpression occurring formula (either index symbol P bounditeration).Considering exclusively normalized schemata restrictive schemasatisfying property replaced [2n/n] [2n + 1/n] (e.g. p3n turnedp6n p6n+3 ). obtained schema obviously sat-equivalent normalized4 .use normalized schemata explained later (see Remark 4.7).Remark 4.3property normalized useful algorithm Figure 1 welldened. schema obtained application algorithm actually normalized general.explain details dierent steps transformation.4.2.1 Elimination Nested Iterationsexplained Section 4.1, rst step remove iterations bi=a occurring insideanother iteration dj=c . done rules 1 , 2 , 3 , 4 . 2 moves bi=aintroducing new variable p explained before. possible containfree variable except parameter n. Removing variables preciselyrole 1 :1bi=a (pc bi=a [/pc ]) (pc bi=a [/pc ])variables c free bi=a , pc occursevery iteration dj=c containing bi=a , pc contains either jvariable bound dj=c .4. two formulae equivalent general. instance, = pn , interpretationdefdefdened I(n) = 1 I(p ) = = 1 validates pn obviously p2n p2n+1 .614fiDecidability Undecidability Results Propositional Schemata1233445678910bi=a(pc bi=a [/pc ]) (pc bi=a [/pc ])variables c free bi=a , pc occursevery iteration dj=c containing bi=a , pc contains either jvariable bound dj=c .(p bi=a ) [p/bi=a ]p fresh symbol, global schema, bi=a occurs iterationcontains free variable except n.ab1j=min (j) pjmax (j)b+jj=ab(pj (pj1 [b + j/i])) ([pj / i=a ])b+jp fresh symbol, i=a occurs iteration , j bound ,a, b contain free variable except n, global schema.ab1j=min (j) pjmax (j)b+jj=ab(pj (pj1 [b + j/i])) ([pj / i=a ])b+jp fresh symbol, i=a occurs iteration , j bound ,a, b contain free variable except n, global schema.max (j)j=ba+1 pjbabjj=min (j) (pj (pj+1 [b j/i])) ([pj / i=a ])bjp fresh symbol, i=a occurs iteration , j bound ,a, b contain free variable except n, global schema.max (j)j=ba+1 pjbabjj=min (j) (pj (pj+1 [)/b j]) ([pj / i=a ])bjp fresh symbol, i=a occurs iteration , j bound ,a, b contain free variable except n, global schema.().n.ni=[i + .n/i]i=.n+= 0, Z.[]n70 . . . []n7 (n > [/.n])i=contains .n,,,Z,<0{,},i== = = .=(( 1).n [ /.n]) ([]n70 . . . []n7 )i=.ncontains iteration i= > 1,(1).ni=ni=1 [i + ( 1).n /i], { , },= , = = .=1 , =nni=i= [n i/i]indices variables form (2 + 1).n + c, c Ni .()contains variable p occurring V V + ,() dened Denitions 4.4, 4.5 Lemma 4.6.n(n < + )i=(n + n1+[i + /i] [n /i])i=maximal lower bound iteration occurringwhole formula= = ,minimal upper bound,= , = = = , = .Figure 1: Transformation Regular Schemata615fiAravantinos, Caferra & Peltierrule aims eliminating, body iteration bi=a , every variable distinctiteration counter (unique) parameter n. feasibleindex contain two variables distinct n (by denition bound-linear schemata).implies indexed variables containing arithmetic variable distinctn cannot contain thus taken iteration bi=a case splitting.Notice rule 1 increase exponentially size formula.contains free variable except n i, bi=a may taken globaliteration dj=c renaming. easy bounds iteration dependn, case bi=a contains free variable except n, thus may replacedfresh variable p equivalence p bi=a may added axiom.done rule 2 :2(p bi=a ) [p/bi=a ]p fresh symbol, global schema, bi=a occurs iterationcontains free variable except n.Things getbounds iteration contain bound variable j (e.g.,complicatedschema nj=1 (qi ji=1 ri )) case iteration cannot takenj cannot eliminated 1 . Notice that, case, lower bound cannot containj coecient j upper bound b must 1. case, bi=areplaced new variable pj dened inductively. instance previousexample, ji=1 ri replaced variable pj dened follows: p0 nj=1 [pj (rj pj1 )].transformation formally specied rules 3 (if coecient j 1) 4(if coecient j 1). Notice denotes global schema, pj mustdened every j [min (j), max (j)].3ab1j=min (j) pjmax (j)j=ab(pj(pj1 [b + j/i])) ([pj / b+ji=a ])b+jp fresh symbol, i=a occurs iteration , j bound ,a, b contain free variable except n, global schema.max (j)j=ba+1 pjbjbaj=min (j) (pj (pj+1 [b j/i])) ([pj / i=a ])p fresh symbol, bji=a occurs iteration , j bound ,a, b contain free variable except n, global schema.rules 3 4dened similar way (see Figure 1).44.2.2 Transforming every Iteration Iterations IntervalsForm [, n ]next step ensure every iteration bi=a , integer bform n , constant (initially b must form 2..n +(since initial schema normalized iteration contained inside another onebound variable occurs upper bound). rst point easily performed616fiDecidability Undecidability Results Propositional Schemataappropriate translation iteration counter (rule 5 ):5.ni=.n+= 0, Z.().ni=[i + .n/i]ensure coecient n b positive. Fortunately, coecientnegative N s.t. every interpretation s.t. I(n) > , interval[I(a), I(b)] empty, case bi=a either (depending ). Sincevalue n positive, exist nitely many values n s.t. iteration non empty.One eliminate iteration considering cases separately. donerule 6 :6[]n70 . . . []n7 (n > [/.ni= ]).ncontains i= , , , Z, < 0 { , },= = = .=Finally, obtain desired result (recursively) decomposing iteration intervalform [, .n + ] (where > 1) two smaller intervals [, ( 1).n + ][( 1).n + + 1, .n + ]. Obviously, possible ( 1).n + , thuscase ( 1).n + < must considered separately. easy achieve, sincecase nitely many possible values n, namely 0, 1, . . . ,1 .7(( 1).n [ /.ni= ]) ([]n70 . . . []n7 ).ncontains iteration i= > 1,(1).ni=ni=1 [i + ( 1).n /i], { , },== , = = .1 , =4.2.3 Removing Parameter Indices Iterationsnext phase consists removing indexed variables form p.n+.i+Z either = 0 = 1 (to get variables indexed expressions form+ only). rst ensure even. Although initially coecient everyoccurrence n even, property hold anymore pointrule 7 . Suppose variable p(2+1).n+c , c contain n, occurs iterationbi=a . (since schema normalized) variable must introducedrule 7 shifted ( ).n (by denition 7 ). shiftapplied every index containing (by denition 7 ), i.e. every index variableoccurring bi=a (otherwise iteration would reducible 1 ). consequenceevery index iteration odd coecient n. Hence add n indexretrieve even coecients iteration. Fortunately commutativity ,iteration bi=a equivalent bai=0 [b i/i]. case b form nZ applying transformationprecisely adds n index(and substracts). instance, iteration ni=1 (pn+i pni ) replaced n1i=0 (p2ni pi) .idea formalized rule 8 :8nni=i= [n i/i]indices variables form (2 + 1).n + c, c Ni .617fiAravantinos, Caferra & Peltiercoecient n every indexed variable even, introduce, every variable++p every integer , two new (fresh) variables p p s.t. pa pa denoterespectively p2..n+a p2..na Ni Z i.e. form .i ++{0, 1}, Z (rule 9 ). index pa contain n anymore. Furthermore,index pa contains +i instead i. Thus transformation indeed achievesgoal however preserve sat-equivalence two variables p2.n+ap2.nb (respectively p2.n+a p2.n+b , p2.na p2.nb ) s.t. 2.n + = 2.n b(respectively 2.n + = 2.n + b 2.n = 2.n b) may replaced distinct+++variables pa pb (respectively pa pb , pa pb ). Notice importantdistinguish sign + front b, integers expressionsNi Z. order preserve sat-equivalence one would explicitly add followingaxioms schema:+2.n + = 2.n (p p )++2.n + = 2.n + (p p )2.n = 2.n (p p )every tuple (, , , ) Z4 .transformation problematic, exist innitely many formulae.Fortunately, add equivalences, concerning propositional variables occur propositional realization schema. shall see,set (denoted ()) nite, expression , ranges setform [, ] [n , n + ], N.formally, let V + V two disjoint subsets P, distinct symbolsalready occurring considered formula. assume every pair (p, ) p+variable occurring formula integer mapped two variables p V ++p V . pi pi denote atoms p2.n+i p2.ni respectively.denote schema obtained replacing every variable form p2.n+a+(where Ni N bound variable i) pa variable form p2.napa (in cases may = 0, moreover, = 0 replacement may++done arbitrarily p0 p0 ). Notice atoms form pa pa ,Ni N bound variable i. 9 dened follows:9 ()contains variable p occurring V V + ,() dened Denitions 4.4, 4.5 Lemma 4.6.4.2.4 Aligning IterationsFinally, remains ensure iterations bounds. pointevery iteration form ni= , Z. Let , greatest integers , .n1= = , unfold iteration once, yielding i=[n/i].n1n1+translation iteration counter, i=equivalent i=[i + /i].lower bound obtained iteration identical length618fiDecidability Undecidability Results Propositional Schematadecreased. repeated obtain iteration interval [ , ]. rule10 formalizes transformation:10ni=(n < + )(n + n1+[i + /i] [n /i])i=maximal lower bound iteration occurringwhole formula= = ,minimal upper bound,= , = = = , = .4.2.5 Definition ()dicult part transformation removal variable n indexperformed rule 9 , precisely denition (). establishresults ensuring feasability transformation.Definition 4.4denote set schemata form:+++2.n + = 2.n b (pa pb )2.n + = 2.n + b (pa pb )2.n = 2.n b (pa pb ), Z, a, b Nn Z.set innite. Thus add restriction:Definition 4.5Let schema containing unique parameter n. schema (p q) occurringsaid relevant w.r.t. following conditions hold:p q syntactically identical.exists natural number s.t. [/n] true [/n] contains p[/n]q[/n]occur itself. instance, take =n Notice p qn necessarily+2020+i=1 (p2ni pi ). =i=1 (pi pi ). 2n n = 4 (pn p4 )+easily seen relevant, however p2n p04 occur .next lemma provides simple necessary condition relevant equivalences. also shows every schema number relevant equivalences nite(up equivalence).Lemma 4.6Let schema containing unique parameter n. Assume coecient nn+even every index every iteration form i=, , Z619fiAravantinos, Caferra & Peltier(, may depend iteration). Let greatest natural number occurring(possibly coecient n expression form ).+every relevant formula form 2.n + = 2.n b (pa pb ), 2.n + =++2.n + b (pa pb ) 2.n = 2.n b (pa pb ) , have, everyN: , [, ] a[/n], b[/n] [2, 6] [ 2, + 2].ProofLet stand substitution [/n]. denition relevant formula, must exist+++N pa pb (respectively pb ) occur [] (but notice pa , pb+pb necessarily occur ). Furthermore must 2. + = 2. b(resp. 2. + = 2. + b).Since coecient n even every index since a, b Nn Z, 2, 2necessarily occur . Thus , [/2, /2] [, ].++Moreover, Lemma 2.8, exist two atoms pa pb (respectively pb )+occur two -expansions pa pb (respectively pb ) s.t.= b = b . denition, , b come replacement++proposition p2.n+a (resp. p2.nb p2.n+b ) pka (resp. pkb pkb ). Thusb contain n. Thus b either Z (and case musta, b [, ] [2, + 2]) respectively form + +bound variable , Z. since , -expansions, [min (i), max (i)]. min (i) = max (i) = n + n + .Thus a, b [2, + 2].Assume 2. + = 2. b. + b = 2.( )..++ b 0. Since a, b 2, deduce a, b 2. Thusa, b [2, 6].> + b 2. Since + 2 b + 2 must2 b 2. Thus a, b [ 2, + 2].Now, assume 2. + = 2. + b. b = 2.( )..= must = b. contradicts rst condition Denition4.5 (the indexed variables cannot syntactically identical).< b > 2. possible > 2 + b > 2 2, hence+ 2 > 2 2, i.e. 4 > . since must a, b [2, + 2] deducea, b [2, 6].proof symmetric > .Finally 2. = 2. b b = 2.( ). proof follows exactlyprevious case.Lemma 4.6 implies set relevant formulae nite (up equivalence). Indeed,suces instantiate , every integer [, ] a, b either elements [, 6]620fiDecidability Undecidability Results Propositional Schemataexpressions form n + , integer [2, 2]. Thus denote() nite subset containing relevant formulae (up equivalence). seteasily computed applying Lemma 4.6, using rened criteria possible, thusopt generic denition.Remark 4.7fact coecient n even (see Denition 4.2 normalized schemata)essential point. arbitrary coecients allowed n, coecients 22 must replaced respectively. second item proofLemma 4.6 obtain + b (instead + b 2). Thus get eventually, b > 2 (instead 2). means a, b range interval[2, + 2] instead [, 6] [ 2, + 2]. interval unbounded, thus ()innite (even equivalence).instance, suppose allowcoecient n (i.e. odd oreven)++1p.n+ turned p . Consider = ni=1 (pi pni ). get: = ni=0 (p0i p1i ).+equivalence p0i p1ni obviously needed every [1, n], cannotexpressed nite number equivalences.hand, allow normalizedschemata, i.e. even coecientsn2n7 ) = i=1 (pin,(pi p2ni ) hence(byrst turn = i=1n1(p2ni pi ).p2ni ) ni=1 (pn+i pni ), (by 8 ) = ni=1 (pi p2ni ) i=0+10+= ni=1 (p0i p1i ) n1i=0 (pi pi ). equivalence needed simple case.Lemma 4.8Let schema containing unique parameter n s.t. every iteration formn+i= , , Z. satisable () satisable.ProofLet interpretation satisfying . Let = I(n). dene interpretation J+follows: J (n) = every pair integers (, ): J (p ) = I(p2.+ ) =defdefJ (p ) = I(p2. ) = . denition , J |= . obtainedreplacing every atom form p2.n+a (respectively p2.na ) Ni Z++(for bound variable i) pa (respectively pa ). denition J , J |= pdef|= p2.n+ J |= p |= p2.n . Since |= clear J |= .Thus J |= ().Conversely, let |= (). Let = I(n). Let J interpretation dened++deffollows. J (n) = , J (p2.+ ) = I(p ) p occurs []I , J (p2. ) = I(p )p occurs []I . easy check J well-dened since |= () ()+contains necessary equivalences. denition, pa (respectively pa ) occursp2.n+a (respectively p2.n+a ) occurs . Thus, since |= J |= .4.3 Termination Complexitysection, investigate complexity transformation algorithm showexponential. every schema , denote || size , i.e. numbersymbols occurring . denotes system rewrite rules Figure 1.621fiAravantinos, Caferra & PeltierTheorem 4.9Let normalized bound-linear schema. normal form w.r.t. computedO(2|| ) rewriting steps. Moreover, || = O(2|| ).Proofrst notice rules always applied sequentially: easy check rulecannot introduce formula previous rule applies. Thus consider rulesequence.First, consider rule 1 . call 1 -atoms atoms pc rule possiblyapplies, i.e. atom occurring iteration bi=a containing iterationcounter i. rule removes atom occurring iteration containingiteration counter. Due control (i.e. application conditions rules), atomsatisfying condition introduced formula (indeed, atom pc occursiteration then, second application condition rule, must containcorresponding iteration counter iteration). Therefore, number applicationsrule iteration bounded number 1 -atoms contains. Since ruleduplicates considered iteration total number applications rule bounded2m , total number 1 -atoms. Obviously ||.sucient prove second result, i.e. size formulaO(2|| ), since application rule double size formula (which wouldyield double exponential blow-up since 2m rule applications). Consider setleaf positions considered formula. position p set, denote |p|length p rp number possible applications rule 1 along p.application rule 1 removes positions p set (those correspondingleaves subformula rule applied) replaces new positionsp1 , . . . , p . number positions length possibly increase. However,remark rule increase length positions 2 (by addingdisjunction conjunctions), i.e. [1, ], |p | |p| + 2. Furthermore, numberrp necessarily decreases: [1, ], rp < rp . Consequently, value |p| + 2 rp cannotincrease (i.e. [1, ], |p | + 2 rp |p| + 2 rp ), implies lengthnal positions (when rp = 0) lower |pmax | + 2 rmax , rmax denotesmaximal number possible applications rule 1 along position initialformula (i.e. max rp initial formula) pmax position maximallength initial formula. |pmax | rmax O(||), thus depth nalformula O(||), implies size O(2|| ).consider rules. First analyze transformation due singleapplication rules (then analyze number applications).Since proofs dierent cases actual similar, consider ruleseparately, rather factorize part analysis.application rule 2 increases size formula constantnumber symbols, since xed number new connectives added partformula duplicated.application rules 3 , 3 , 4 , 4 , 5 , 8 10 adds constant numbernew connectives formula replaces occurrence counter622fiDecidability Undecidability Results Propositional Schemataformula expression form b + j, b j, + .n n i. sizeexpressions bounded size original formula, thus size formulaincreases quadratically (since number occurrences also bound sizeformula).consider rules 6 7 . rules introduce constant number newconnectives occurrences atoms duplicate times subformula .value bounded natural number occurs , thus sizeformula increases polynomially (since natural numbers encoded unary termss(. . . (s(0)) . . .) setting, hence bounded size formula noticewould case numbers encoded sequences digits5 ).Thus show number applications rulespolynomially bounded size initial formula. again, distinguish severalcases:rules 2 , 3 , 3 , 4 , 4 apply iterations occurring inside another iteration.application rule, iteration replaced atom, hence removedoutermost iteration. rule introduces new iterations, howeveroccur root level, outside scope iteration. Thus total numberpossible applications rules bounded number iterations initiallyoccurring inside another iteration, hence ||.rules 5 , 6 8 apply iteration: 5 applies iterationlower bound contain n gets rid occurrence n lowerbound. 6 applies iterations upper bound contains n replacesiterations purely propositional formulae. 8 applies coecient nevery index odd. Since rule adds n index, applicationrule, coecient n must even rule cannot applyiteration.rule 7 decreases value coecient n upper bound 1. Thusnumber applications rule 7 iteration lower initialvalue (which bound size formulae since integers encodedterms). Similarly, since 10 unfolds iteration iteration length nobtained, number applications rule 10 iteration boundvalue + + .Finally, rule 9 applies whole schema. rule adds conjunction equivalence schema, Lemma 4.6, size conjunctionpolynomially bounded greatest natural number occurring schema,hence size formula.every schema , denote normal form w.r.t. rules .5. Actually translation doubly exponential case.623fiAravantinos, Caferra & Peltier4.4 Soundness Completenessprove rules preserve sat-equivalence every irreducible formularegular. need two propositions below:Lemma 4.10Let , schemata. Let interpretation every groundsubstitution parameters every -expansion , , have:JKI = J KI . JKI = J[ /]KI .Proofproof induction . contain proof trivial. =[ /] = . denition JKI = JI KI J KI = J KI . groundsubstitution parameters = thus course -expansion. Thus JI KI = J KI hence JKI = J KI .Assume = . J[ /]KI = J [ /]KI = J KI (by induction).Thus J[ /]KI = JKI . proof similar = (1 2 ) = (1 2 ).assume = bi=a . |= every integer [JaKI , JbKI ]defI[/i] |= . Let substitution (i) = (x) = (x) x = i.Let -expansion . denition [Jmin (i)KI , Jmax (i)KI ], thusalso -expansion . Therefore JKI = J KI , hence JKI[/i] = J KI[/i](since contain i). Consequently, induction hypothesis,J KI[/i] = J [ /]KI[/i] . Hence |= every integer [JaKI , JbKI ]I[/i] |= [ /] i.e. |= [ /]. proof similar = bi=a .Lemma 4.11every schema every indexed proposition p contain variablebound :(p [/p]) (p [/p])Proofp p hence distributivity (p ) (p ). showevery interpretation I, Jp KI = Jp [/p]KI . JpKI = F p p [/p]false I. Otherwise, Lemma 4.10, JKI = J[/p]KI . Similarly,Jp KI = Jp [/p]KI . Hence (p [/p]) (p [/p]).Theorem 4.12Let normalized bound-linear schema. satisable satisable.Proofproof inspection dierent rules (see denition rulesnotations):1 . proof direct application Lemma 4.11.2 . every model , one construct interpretation J (p bi=a )[p/bi=a ] interpreting p Jbi=a KI . denition J |= (p bi=a ).624fiDecidability Undecidability Results Propositional SchemataSince |= J |= . Lemma 4.10 deduce |= [p/bi=a ]. HenceJ |= (p bi=a ) [p/bi=a ].Conversely, model (p bi=a )[p/bi=a ], due rst conjunctbi=a p truth value hence since |= [p/bi=a ], deduce|= , Lemma 4.10.3 . Assume |= . Let J extension obtained interpreting pb+J i=aKI . Lemma 4.10 J |= ([pj / b+ji=a ]). Furthermore denitionb+semantics, J i=a KI = F Jb+aKI < 0 hence J |= p < ab.Thus J |= pab1 ab1j=min (j) (pj pab1 ). Furthermore, every JabKI ,b+J i=a KI = either J b+1KI = J[b + /j]KI = T. Hence Jp KI =i=amax (j)either Jp1 KI = J[b + /j]KI = T. Therefore |= j=ab(pj (pj1 )).ab1max (j)Conversely, let model pab1 j=min(pj pab1 ) j=ab(pj(j)b+j(pj1 [b + j/i])) ([pj / i=a ]). show induction |= (pb+i=a ) every [Jmin (j)KI , Jmax (j)KI ]:b+< Ja bKI denition J i=aKI = F. Moreover rst twoconjuncts previous formula must Jp KI = F.[b+/i]KI . Hence inductionKI = J b+1Otherwise, J b+i=ai=ab+hypothesis: J i=a KI = Jp1 KI [b + /i], third conjunctformula above, get: J b+i=a KI = Jp KI .Lemma 4.10 deduce |= . proofs rules 3 , 4 4similar..n+5 . Assume = (the case = similar). denition |= i=.n+exists [J.n + KI , J.n + KI ] |= [/i], i.e. exists().n+[JKI , J().n+KI ] |= [+J.nKI /i], i.e. |= i=[i+.n/i].6 . assume = = (the case = , = similar). Sinceassume I(n) 0 every parameter n, |= (n = 0. . .n = n > )hence equivalent to: (n = 0 . . . n = n > ) . distributivity get(n = 0). . . (n = )(n > ). .n+empty (thus equivalenti=) I(n) > , hence, Lemma 4.10, (n = 0 ) . . . (n =) (n > [/ .n+]). every [0, ], n = |= []n7 ,i=hence |= []n70 . . . []n7 (n > [/ .n+]).i=Conversely, |= []n7 holds, straightforwardly extended modeln = interpreting n . Thus model []n70 . . . []n7 (n >[/ .n+]) exists model , 6 preserves satisability.i=7 . Again, assume = = . (( 1).n+ < ( 1).n +) hence (( 1).n + < (( 1).n + ) (( 1).n +) (( 1).n + < ). Since parameters interpreted natural625fiAravantinos, Caferra & Peltiernumbers, |= ( 1).n + < I(n) [0,1 ]. denitionJKI = J[]n7I(n) KI . |= ( 1).n + then, unfolding, J .n+KI =i=(1).n+(1).n+.n+nJ i=i=(1).n++1 KI = J i=i=1 [i + ( 1).n + /i]KI .Hence 7 preserves satisability.8 : proof similar one 6 .soundness rule 9 direct consequence Lemma 4.8.n10 . assume = = . i=(n < + ni= )(nnn+ i= ). every interpretation I, I(n) < + J i= KI = Fthus n < + n(n < + ). I(n) + , J ni=i= KInJ[/i] i=+1 KI . Furthermore translation iteration counternni=+1i=+1 + [i + /i]. Hence 10 preserves equivalence.Theorem 4.13Let normalized bound-linear schema. regular.ProofFirstly, remark application rules bound-linear schema generatesschema still bound-linear. Notice however obtained schema normalizedgeneral.Let bound-linear formula, irreducible . Assume obtainednormalized schema application rules . need proveregular.rst prove contains nested iteration. Let = bi=a iterationoccurring . Assume contains iteration dj=c . W.l.o.g. assumecontains iteration (otherwise could simply take = ). irreducibility w.r.t.rule 1 , indices must contain j. denition class bound-linearschemata, implies indices cannot contain i. j occurs onerule 3 ,3 , 4 4 applies. Consequently free variable dj=c n. Thus rule2 applies impossible irreducibility.remark iterations bi=a , Z b form n +Z. Indeed, contains n rule 5 applies coecient n bdierent 1 rule 6 7 applies.rule 8 eliminates indexed propositions coecient n odd (sinceinitial schema normalized, indexed variables necessarily introducedrule 7 , thus must occur iteration indices iteration mustodd coecient front n).9 eliminates variables form p2.na , Z Ni N,bound variable i, replaces variables indexed a.Finally 10 ensures iterations bounds.626fiDecidability Undecidability Results Propositional Schemata5. STAB: Decision Procedure Regular Schematashown transform bound linear schema regular one, showsatisability problem decidable regular schemata. done providingset block tableaux rules (Smullyan, 1968) complete w.r.t. satisability.rules concise natural, and, compared naive procedure described proofProposition 2.7, much ecient terminate often (see endSection 5.1). procedure called stab (standing schemata tableaux). Noticeapplies schema (not regular ones). assume (w.l.o.g) schematanegative normal form.5.1 Inference RulesDefinition 5.1 (Tableau)tableau tree s.t. node N occurring labeled set schemata written(N ).usual tableau generated another tableau applying extension rules.PLet r =rule P denotes set schemata (the premises),C1 . . . CC1 , . . . , C denote conclusions. Let N leaf tree . subset (N )matches P extend tableau adding children N , labeledC (T (N ) \ S) = 1, . . . , matching substitution. leaf Nclosed set arithmetic formulae (i.e. schemata containing atoms form. . . < . . . iteration) (N ) unsatisable. detected using decisionprocedures arithmetic without multiplication (Cooper, 1972).Definition 5.2 (Extension rules)extension rules stab dened follows.usual rules propositional tableaux:():():Rules proper schemata (iteration rules)6 :bbi=a(Iterated ):bab1i=a [b/i]i=ab<a(Iterated ):bab1i=a [b/i]6. right branch conclusion Iterated rule required, e.g., detectsatisable n = 0.627ni=1fiAravantinos, Caferra & Peltierclosure rule adds constraints needed branch closed. ruleapplied = b already occur branch.pa(Closure):pbpa , pb , = bstab without loop detection rule described next section already betterstraightforward procedure introduced proof Proposition 2.7. First, terminates cases schema unsatisable (whereas naive procedure neverterminates case, unless schemanis unsatisable propositional formula).trivially case schema i=1 n 1, propositionallyunsatisable.Second, nd model much faster naive procedure. Consider,e.g., ( 10000p)(p ) unsatisable formula. case stab immediatelyi=nnds model n > 10000 p interpreted F.Remark 5.3Using tableaux-based system deciding regular schemata may seem surprising, sinceDPLL procedures (Davis, Logemann, & Loveland, 1962) usually ecient propositional logic. However, extending procedures schemata straightforward.main problem evaluating atom schema immediate, since atom maywell appear realization schema without appearing schema itself. Thus,contrast propositional case, sucient replace syntacticallyatomntruth value. instance, atom p2 (implicitly) appears schemai=1 pinp)n1n > 1. Thusevaluatingpto,say,Fwouldyieldtwodistinctbranches:(2i=1n(p1 i=3 pi ) n > 1. Thus one would dene rules operating deep positionsschema order unfold iterations instantiate counter variablesneeded. contrast, tableaux method operates formulae occurring root levelcompares literals instantiated (using unfolding). makesprocedure much easier dene reason (in particular termination behavioreasier control). Actually DPLL procedure schemata presented previouswork (Aravantinos, Caferra, & Peltier, 2009a, 2010), much complicatedcalculus presented here.course, one could combine iteration rules tableaux procedure SATsolver used black box could charge purely propositional part.However also straightforward, mainly due fact partial evaluationneeded propagate values propositional variables iterations.5.2 Discarding Infinite Derivations: Looping Rulestab terminate general. reason iteration is, general, innitelyunfolded iteration rules.n Assume instance propositional unsatisableformula.startingn i=1 one could derive innite sequence formulaeform n1,...,i=1i=1 , every N. introduce loop detection ruleaims improving termination behavior stab. Detecting looping naturalway avoid divergence: if, extending tableau, nd schemaalready seen, possibly shift arithmetic variables, need628fiDecidability Undecidability Results Propositional Schemataconsider stop procedure. loopings also interpretedwell-foundedness arguments inductive proof.Definition 5.4 (Looping)shift substitution mapping every variable n expression form n ,N s.t. least one variable n s.t. n < n (which always case sincemay = 0).I, J two interpretations, write < J exists shift s.t. J = I.Let , two schemata (or sets schemata). write |=s every model, exists J < s.t. J |= .Let N, N two nodes tableau . N loops N (N ) |=s (N ).existing work cyclic proofs, N sometimes called bud node Ncompanion node N (Brotherston, 2005). leaf loops, treated closedleaf (though necessarily unsatisable). distinguish particular case closedleaf usual one, say blocked (blocked leaves closed). NoticeN N may dierent branches, thus looping may occur often, allowingsimplications.Example5.5Let = { ni=1 pi } = { ni=2 qi }. Intuitively, structure:stab behave similarly formulae. relation |=s supposed formalizenotion. show example case, expected, i.e.|=s . Indeed, consider model . construct interpretation J follows:defdefJ (n) = I(n) 1 every [1, J (n)], J (p ) = I(q+1 ). Since |= exists[2, I(n)] I(q ) = T. Thus exists [1, I(n)1] I(q+1 ) = T,i.e. exists [1, J (n)] J (p ) = T. Therefore J |= .Proposition 5.6Let schema. satisable model minimal w.r.t. < (i.e.every interpretation J , J < J |= ).ProofLet V set parameters . Notice V nite. every interpretationdenote I(V ) integer: I(V ) = nV I(n). Since assumed I(n) N everyvariable n, deduce I(V ) 0.Let model I(V ) minimal. Since truth valuedepend values variables V , may assume n V, I(n) =0. Let J model J < I. denition exists shiftJ = I. every arithmetic variable n, n = n n , n N; furthermore,exists least one variable > 0. Thus J (n) = I((n)) I(n)J (m) < I(m). Consequently must J (V ) I(V ), thus J (V ) = I(V ) (since I(V )minimal). denition, entails n = 0 every n V . Thus V ,case I(m) = 0 hence J (m) < 0 impossible (since assume parametersinterpreted natural numbers).defapply looping rule practice one nd shift check implicationholds. Unfortunately, relation |=s obviously undecidable (for instance = ,629fiAravantinos, Caferra & Peltiereasily checked |=s unsatisable, shall see Section 6satisability problem undecidable propositional schemata). Thus, following,shall use much stronger criterion sucient purpose. obvious solutionwould use set inclusion: indeed, |=s exists shift s.t. . However,criterion strong, following example shows.Example 5.7schema = pn (pn qn ) q0 ni=1 (qi qi1 ) obviously unsatisable.reader easily check stab generates innite sequence sets schemataform:n{pn , qn , q0 , qn1 , . . . , qn ,(qi qi1 )}, Ni=1None sets contains previous one shift n indexedproposition pn must occur every set.Thus introduce renement set inclusion based purity principle. pureliteral rule standard propositional theorem proving. consists evaluating literalL formula (in NNF) complement L occur . literalcalled pure. well-known operation preserves satisability may allowmany simplications.show extend pure literal rule schemata. conditions Lstrengthenedorder take iterations account. instance, L = pn2ncontains i=1 pi L pure , since pi complement L = n (andsince 1 n 2n). hand p2n+1 may pure (since 2n + 1 [1, 2n]).every set schematadenote N conjunction purely arithmeticdefformulae : N = , arithmetic .7Definition 5.8 (Pure literal)literal pa (respectively pa ) pure set schemata every occurrenceliteral pb (respectively pb ) , arithmetic formula N IC ()a = b unsatisable8 .Definition 5.9Let , two sets schemata. write exists shift setparameters s.t. every :Either arithmetic formula N |= .pure literal ..rst third items correspond roughly set inclusion (up arithmetic properties). second item deals . corresponds informalidea pure literal removed. course important one.7. possible improvement would add N formulae obvious logical consequences .instance, = {pn (n > 1), p1 } N would contain n > 1. would make notionpure literal slightly general, e.g., pn would pure , case currentdenition.8. See page 606 denition IC ().630fiDecidability Undecidability Results Propositional SchemataExample 5.10n1Let = {n 0, pn+1 , pn , ni=1 (pi pi1 ), p0 } = {n 1, pn1 , i=1(pipi1 ), p0 }. . Indeed, consider shift = {n 7 n 1}. denition N = {n 1}. (n 0) = n 1 0 n 1, thus N |= (n 0). Sincen 0 [1, n], ppn+1 , thus pn+1 pure . Finally,cannot identicalpn = pn1 ni=1 (pi pi1 ) = n1i=1 (pi pi1 ) .show decidable. First all, trivial syntactic equalitydecidable shown following denition proposition:Definition 5.11Let U(, ) arithmetic formula dened follows:= pa = pb U(, ) = (a = b).def= (a b) = (c d) (with {, <}) U(, ) = (a = c) (b = d).def= = U(, ) = U( , ).= (1 2 ) (with {, }) = (1 2 ) U(, ) = U (1 , 1 )U(2 , 2 ).= bi=a = di=c U(, ) = (a = c) (b = d) U( , ).defOtherwise U(, ) = .defProposition 5.12Let , two schemata. every substitution , U(, ) validsyntactically identical.Proofstraightforward induction formulae.prove decidability :Proposition 5.13decidable.ProofSince linear arithmetic decidable, possible check whether literal pureset formulae . pure literals simply removed (sincesatisfy second condition Denition 5.9). One nd shift everyremaining formula satises rst third condition. Let n1 , . . . , n variables, . Let substitution mapping every parameter n (1 ) n l ,l distinct variables occurring , . One check existssubstitution mapping every variable l integer that:[1, ], (l ) 0 [1, ], (l ) > 0. Since xed, conditionstated arithmetic formula.631fiAravantinos, Caferra & Peltierevery formula , one following conditions holds:arithmetic formula N |= , i.e. formula n1 , . . . , n .Nvalid.occurs . holds contains formula ,identical every value parameters, i.e., Proposition 5.12,n1 , . . . , nk .U(, ) valid.Since every condition equivalent arithmetic formula, whole conditionexpressed arithmetic formula (taking conjunction formulae corresponding). formula satisable exists substitution satisfying desired property. proof follows straightforwardly decidabilitylinear arithmetic.prove stronger relation |=s .Proposition 5.14Let , two sets schemata. |=s .ProofLet shift satisfying conditions Denition 5.9. Let interpretationsatisfying . Let = . show exists J < s.t. J |= , i.e.exists shift s.t. J = J |= . Equivalently, show existsmodel J , i.e. = convenient. Let J interpretation s.t. J (L) =defL literal pure J (L) = I(L) otherwise. Let .show J |= . distinguish three cases, according three items Denition5.9.N |= , since |= since J coincide every arithmeticvariable must J |= .literal pure pure , thus J |= denition., |= . Thus every literal pure must pure .complementary literals cannot occur [] . Since J coincideliterals since negative normal form, must J |= .Consequently J |= , hence J |= .strictly less general |=s evidenced following:Example5.155.5).Let = { ni=1 pi } = { ni=2 pi }. shownn|=s (see ExamplenHowever, , since shift ( i=1 pi ) = i=2 pi (thisobvious since 1 cannot equal 2 whatever ).5.3 Examplesproving soundness, completeness termination stab, provideexamples tableaux.632fiDecidability Undecidability Results Propositional Schemata(n 0) p0n 0, p0 ,n(1)i=1 (pi1ni=1 (pi1pi ) pnpi ), pnn = 0n1i=1n1(pi1 pi )pn1 pnpn1n<1pn(1)n = nFigure 2: Simple Example Closed Tableau5.3.1 Simple ExampleLet following formula: (n 0) p0 ni=1 (pi1 pi ) pn .construct tableau . First -rule applies transform conjunctionset schemata. closure rule appliespn p0 , yielding constraint n = 0.iteration rule applies schema ni=1 (pi1 pi ), yielding two branches.rst onecorresponds case iteration non empty unfolded,yielding n1i=1 (pi1 pi ) pn1 pn second one corresponds caseiteration empty (hence true), yielding constraint n < 1. latter branchclosed immediately due constraints n 0 n = 0. former branch,-rule applies formula pn1 pn , yielding two branches pn1 pnrespectively. closure rule applies latter one, yielding unsatisable constraintn = n hence branch closed. last remaining branch loops initial one,shift n 7 n 1. obtained tableau depicted Figure 2. Closed leaves (resp.blocked leaves looping ) marked (resp. ()). new (w.r.t. previousblock) formulae presented blocks.5.3.2 n-Bit Addersection provide slightly complicated example. use stab provesimple property n-bit Adder dened Introduction. aim proving+ 0 = A. SAT-solver easily refute formula xed n (say n = 10).prove n N. simple example chosen sake readabilityconciseness, notice commutativity associativity n-bit adder could proven(see Section 5.7).express fact second operand null: ni=1 qi , factresult equals rst operand: ni=1 (pi ri ), gives ni=1 (pi ri ) refutation.633fiAravantinos, Caferra & Peltiernn1nc1n1n1i=1 Sumi(1)i=1 Sumii=1 Carryini=1ni=1c1Sumni=1 Carryin1i=1 qiqin1n1i=1 Sumin1i=1 pi rin1i=1 Carryin1i=1 qipn rnn1pi riCarrynqnc1SumnCarrynqn(1)rncnpnqnrnpncn(2)qn(2)(2)n11n2i=1 CarryiCarryn1n1n1<1cnc1n2(pn1 qn1 ) (cn1 pn1 ) (cn1 qn1 )pn1 qn1cn1 pn1cn1pn1cn1 qn1rn1(2)Figure 3: Closed Tableau + 0 =want prove Adderschema regular.ni=1 qini=1 (piri ) unsatisable. Noticecorresponding tableau sketched Figure 3. Sequences propositional extensionrules detailed.634fiDecidability Undecidability Results Propositional SchemataExplanations.rst big step decomposesiterations. branching dueni=1 pi ri : rst pn rn ,then n1. right branch loopsi=1 pi rnn1steps iterated conjunctions i=1 . . . contain i=1. . . left one extendedpropositional rules (the reader easily check Sumn , Carryn , pn rn qnindeed lead presented branches, notice cn must hold, otherwise wouldpn rn ).(2) start decomposing iterations second time. Iterations aligned[1, n 1] introduce constraints i.e. either n 1 1 (rst branch)n 1 < 1 (second branch). second case, introduced constraint impliesn = 1, thus cn = c1 closes branch. rst case decompose Carryn1consider various cases. Twotrivially discarded imply qn1 , whereaseasily obtain qn1 unfolding ni=1 qi . remains one case easilyseen loop (2). branch (2 ) similar (2).5.4 Soundness Completenessleaf irreducible extension rule applies it. derivation (possibly innite)sequence tableaux (T )I s.t. either [0, ] 0, N s.t.\ {0}, obtained T1 applying one extension rules. derivationfair either s.t. contains irreducible closed leafevery closed blocked leaf N s.t. rule applied N(i.e. leaf freezed).Definition 5.16 (Tableau Semantics)every node N tableau , (N ) interpreted conjunction elements.satised interpretation exists leaf N s.t. |= (N ).Lemma 5.17tableau obtained applying one extension rules leaf N tableau|= (N ) exists leaf N s.t. N child N|= (N ) (i.e. rules sound invertible).ProofObvious, inspection extension rules.Lemma 5.18leaf N irreducible closed satisable.ProofdefLet set arithmetic formulae (N ) = (N ) \ . N closedsatisable (by denition), let solution . contains formulaliteral, one extension rules applies deletes , impossible. LetcT (N ) number pairs pa , pb (N ) s.t. interpretation validatings.t. JaKI = JbKI . cT (N ) = 0, closure rule applies pa , pb impossible.Hence cT (N ) = 0 particular implies propositionally satisable (i.e.contains pair complementary literals). Thus (N ) satisable denitionsatisable.635fiAravantinos, Caferra & PeltierTheorem 5.19 (Soundness Completeness w.r.t. Satisfiability)Let (T )I derivation.exists s.t. contains irreducible, closed leaf T0 satisable.derivation fair T0 satisable exist leafirreducible neither closed blocked.Proofrst item (i.e. soundness) follows Lemmata 5.17 5.18.prove procedure complete w.r.t. satisability (the second item). Letinterpretation schema. dene mI () follows:mI () = 0 arithmetic atom (i.e. atom form . . . < . . .).defmI () = 1 indexed proposition negation, .defmI (1 2 ) = mI (1 ) + mI (2 ) {, }.defmI (bi=a ) = 2 JbKI < JaKIdefdefmI (bi=a ) = + 2 + = mI[/] () { , }, = JaKI , = JbKI ,.set, mI () = {mI () | }. tableau N leafdefmI (N, ) = (mI (T (N )), cT (N )) cT (N ) dened proof Lemma 5.18.measure ordered using multiset lexicographic extensions usual orderingnatural numbers. Thus, obviously well-founded. need following:defLemma 5.20Let interpretation. Let tableau. deduced applyingextension rule leaf N s.t. |= (N ), every child N N s.t.|= (N ), mI (N , ) < mI (N, ).Proofrules except iteration rule closure rule replace formula simpler ones,hence easy see mI (T (N )) decreases. iteration rules replace iterationlength either disjunction/conjunction iterated disjunction/conjunctionlength 1, smaller formula. Since > 1, mI (T (N )) decreases. closurerule aect mI (T (N )) obviously decreases cT (N ).Let model T0 . Proposition 5.6, assume minimal w.r.tordering < introduced Denition 5.4.Lemma 5.17, I, contains leaf N s.t. |= (N ). Let s.t.mI (N , ) minimal ( exists since mI (Ni , Ti ) well-founded). Assume rule appliedN derivation, tableau . Lemma 5.17 child N Ns.t. |= (N ). Lemma 5.20 mI (N , ) < mI (Nk , ) impossible.Thus rule applied N . Assume N blocked. exists node Ns.t. N loops N . Denition 5.4 exists interpretation J s.t. J |= N636fiDecidability Undecidability Results Propositional SchemataJ <V I. Lemma 5.17 (only implication), J |= T0 , contradictsminimality I. Since derivation fair, N irreducible (or another leafirreducible). Furthermore, N cannot closed since satisable (I |= (N )).worth emphasizing stab sound complete (w.r.t. satisability)schema, bound-linear regular ones. termination result nextsection holds regular schemata.5.5 Termination Regular Schemataconsider following strategy ST applying extension rules:propositional extension rules, looping closure rules applied soonpossible leaves, highest priority. rules obviously terminateschema.iteration rules applied iterations maximal length (w.r.t. naturalordering arithmetic expressions). instancescheman partialn1npqiterationrulesapplyrstiterationji=1j=1i=1 pi .relation introduced Section 5.2 used block looping nodes.Theorem 5.21ST terminates every regular schema.ProofLet , , , Z regular schema aligned [, n ], propagation limits , .Assume innite branch constructed. denition strategy,time, last ranks every iteration unfolded iteration rules. Thusremaining iterations form narithmetic constrainti=n + 1 0, i.e. n + + 1.on, consider nodes irreducible w.r.t. propositional rules.show nite set formulae generated stab, shift n.consequence looping rule must apply, worst possible formulaegenerated.arithmetic formulae occurring initial formula must form .n >.n < . last ranks unfolded, constraint n + + 1must added. Thus suciently big, .n > equivalent .n <equivalent . Thus every arithmetic formula occurring initial formula eitherfalse redundant w.r.t. n + + 1. remaining arithmetic formulae mustintroduced closure rule (since iterations contain occurrence <).necessarily form = b a, b arithmetic expressions (appearingindices formula derivation). a, b contain n, a, b Z= b equivalent either . Thus consider case containsn b Z. occurs initial formula must form .n +, Z. Since n + + 1, suciently big, disequation .n + = bmust false. occur initial formula must come ( )thunfolding iteration, [0, 1]. Since (by denition regular schema)637fiAravantinos, Caferra & Peltierindices form + , [, ], disequation actually formn + + = b, [, ], [0, 1] (since iteration counter mayreplaced n , n 1, . . . , n + 1) b occurs initial formula.previous equation equivalent , then, since constraint n ++1,must [0, b + 1 ]. Hence nitely many formulae,translation n 7 n .Now, consider non arithmetic formulae occurring branch. schematamust either iterations literals (by irreducibility w.r.t. propositional extensionrules).iterations form n, ni=i= iteration occurringinitial formula. Obviously, number iterations nite translationn 7 n .literals occurring branch (but scope iteration) eitherliterals initial schema literals introduced previous applications iterationrules. former indexed expressions form n + , Zlatter n + , [ + 1, + ].literal indexed expression n + outside [ + , n + ],must pure every iteration, hence (by irreducibility w.r.t. closure rule) mustpure node. Actually, large enough then, arithmetic constraints,n + cannot [ + , n + ] = 0. Indeed, negative,suces take > ++ 1 ensure n + < + , otherwiseenough n + > n + (as , n 1). Thus every literal indexedinteger terms form pure, since denition index cannot uniableindex occurring iteration (after unfolding).Similarly literals indexed expressions form n + > pure,thus may assume [, ]. Consequently nitely many literalsshift n 7 n .implies number possible schemata obtained unfolding stepsnite, translation n. pigeonhole principle, looping rule necessarilyapplies point branch, contradicts initial assumption innitebranch constructed.Termination strategy also ensures fairness:Lemma 5.22derivation constructed ST (applied irreducibility) fair.ProofLet (T )I derivation constructed ST. Since ST terminates, cannotinnite derivation, thus necessarily form [0, ] N. denition,every node either blocked closed irreducible (the strategy appliedirreducibility). contains closed irreducible leaf proof completed (bydenition notion fairness). Otherwise, consider . Let Nirreducible, closed blocked leaf occurring . Assumes.t. rule applied N (which would contradict denition fairness).means extension possibly aect N , thus N must also occur nal tableau638fiDecidability Undecidability Results Propositional Schemata(and labeled set schemata ). Thus N must closedirreducible. Moreover cannot blocked , since rule aect nodesbranch behind N . impossible since nodes must either blockedclosed irreducible.immediate corollary, following:Theorem 5.23satisability problem decidable bound-linear schemata.ProofTheorems 4.12 4.13, every bound-linear schema transformed satequivalent regular one. Theorem 5.21 shows stab terminates every regular schema,hence Theorem 5.19 Lemma 5.22, stab used decide satisabilityproblem regular schemata.ne analysis previous termination proof ensures solve satisability problem regular schemata exponential time (if natural numbers writtenunary notation). seen furthermore (Theorem 4.9) translation boundlinear schemata regular ones exponential, conclude satisabilityproblem bound-linear schemata solved double exponential time.5.6 Model Buildingexistence non closed irreducible branch ensures root schema satisable,shown Theorem 4.12. arithmetic constraints branch specify possiblevalues parameter. remaining formulae must literals, since extension rulesapply complex formula (in particular, iteration schema).literals specify truth value propositional variables exactly usual casepropositional logic (the value propositional variables appear branchmay chosen arbitrarily). Since branch closed, cannot contain paircomplementary literals.illustrate construction simple example. consider following tableau:pn , q2 , r1 ,n 1,n1i=1ni=1 (piqi ri )n 1, pn qn rn(pi qi ri )pn , qn , rnn 1,n2i=1pi qi ri...n 1 1, pn1 qn1 rn1pn1 , qn1 , rn1n 1 = n, n 1 = 2, n 1 = 1(1)639n = nfiAravantinos, Caferra & Peltierbranch (1) irreducible. contains following formulae: pn , q2 , r1 , n1 1,pn1 , qn1 , rn1 , n 1 = n, n 1 = 2, n 1 = 1. value n determinednding solution arithmetic constraints. choose instance solutionn = 4. instantiation get remaining formulae: {p4 , q2 , r1 , p3 , q3 , r3 },gives instance following interpretation p, q r: p true = 4 q , rtrue = 3. easy check obtained interpretation satises initialschema.possible extension simple algorithm would be, given tableau, computesymbolic representation whole set models root schema. set innitemust dened induction. closed irreducible branches correspond concretemodels, base cases, whereas loops correspond inductive construction rules.rules take model construct new model J strictly greater cardinality (thevalues parameters increase strictly). would require dene formal languagedenoting sets interpretations (one could use, e.g., automata recognizing sequencestuples Boolean values).5.7 Systemdecision procedure implemented program (called RegStab) freelyavailable web page http://regstab.forge.ocamlcore.org/. written OCamlsuccessfully tested MacOSX (10.5), Win32 (Windows XP SP3) GNU Linux(Ubuntu 9.04) x86 platforms. system comes manual including installationusage instructions description input syntax. Functions dened makeinput le readable (see Sum(i) Carry(i) below). input leadder example Section 5.3.2.// A+0=Alet Sum(i)let Carry(i)let Adderlet NullBlet Conclusion:=:=:=:=:=S_i <-> (A_i (+) B_i (+) C_i)C_i+1 <-> (A_i /\ B_i \/ C_i /\ A_i \/ C_i /\ B_i)/\i=1..n (Sum(i) /\ Carry(i)) /\ ~C_1/\i=1..n ~B_i\/i=1..n (A_i (+) S_i)Adder() /\ NullB() /\ Conclusion()software simply prints status schema (satisable unsatisable). Optionsprovided get information search space (number inference rules,depth unfolding etc.), see manual details. additional tool oered expandschema propositional formula DIMACS format (by xing value n).Figure 4 gives examples problems solved RegStabcorresponding running times (please refer distribution input les additionalinformation).example output, proving 0 neutral element carry-propagateadder. ran system verbose mode, prints useful informationsearch: number application extension rules, number closed looping leaves,unfolding depth set lemmata (companion nodes).640fiDecidability Undecidability Results Propositional SchemataRipple-carry adderx+0=xcommutativityassociativity3+4=7x + = z1 x + = z2 z1 = z2Carry-propagate adderx+0=xcommutativityassociativityequivalence two dierent denitions adderequivalence ripple-carry adderComparisons bit-vectorsx0Symmetry (i.e. x x x = y)Totality (i.e. x > x y)Transitivity12Presburger arithmetic bit vectorsx+y xx1 x2 x3 x1 + x2 + x3 +x1 x2 y1 y2 x1 + y1 x2 + y2x1 x2 x3 y1 y2 y3 x1 + y1 x2 + y2 x3 + y31x+y 5x3y 4iterations factorizedautomatainclusionnPi ni=1 Pii=1P1 ni=1 (Pi Pi + 1) Pn+1 |n 0model checking safety propertyFigure 4: Experimental Results6410.017s0.267s28.902s2.719s0.490s0.016s0.165s8.522s0.164s0.194s0.004s0.009s0.006s0.011s0.010s0.026s1m42s2.949s46m57s7m9s2m14s2.324s0.001s0.001s5.251sfiAravantinos, Caferra & PeltierConjecture:(((/\i=1..n ((S_i <-> ((A_i (+) B_i) (+) C_i)) /\(C_i+1 <-> (((A_i /\ B_i) \/ (C_i /\ A_i))\/ (C_i /\ B_i))))) /\ ~C_1) /\ (/\i=1..n ~B_i)) /\(\/i=1..n (A_i (+) S_i))Applications tableau rules:/\: 67\/: 84(+): 38<->: 32->: 0Iterated /\: 12Iterated \/: 3------Total propositional rules: 221Total iterated rules:15Number closed leaves: 137Number looping leaves: 30Number lemmas:4Maximum number unfoldings: 3(if number surprising, notice tableauconstructed depth-first)Lemmas:[\/i=1..n (A_i (+) S_i) ; /\i=1..n ((S_i <-> ((A_i (+) B_i) (+) C_i))/\ (C_i+1 <-> (((A_i /\ B_i) \/ (C_i /\ A_i)) \/ (C_i /\ B_i)))) ;/\i=1..n ~B_i ; ~C_1][\/i=1..n-1 (A_i (+) S_i) ; /\i=1..n-1 ((S_i <-> ((A_i (+) B_i) (+) C_i))/\ (C_i+1 <-> (((A_i /\ B_i) \/ (C_i /\ A_i)) \/ (C_i /\ B_i)))) ;/\i=1..n-1 ~B_i ; ~C_n ; ~C_1] (n > 0)[/\i=1..n-2 ((S_i <-> ((A_i (+) B_i) (+) C_i)) /\ (C_i+1 <-> (((A_i /\ B_i)\/ (C_i /\ A_i)) \/ (C_i /\ B_i)))) ;/\i=1..n-2 ~B_i ; C_n-1 ; ~C_1] (n > 1)[\/i=1..n-2 (A_i (+) S_i) ; /\i=1..n-2 ((S_i <-> ((A_i (+) B_i) (+) C_i))/\ (C_i+1 <-> (((A_i /\ B_i) \/ (C_i /\ A_i)) \/ (C_i /\ B_i)))) ;/\i=1..n-2 ~B_i ; C_n-1 ; ~C_1] (n > 1)UNSATISFIABLE642fiDecidability Undecidability Results Propositional Schemata6. Undecidability Resultsprovide undecidability results two natural extensions class regularschemata.6.1 Homothetic Transformations Iteration Countersconsider class schemata Ch dened follows.Definition 6.1Ch (h stands homothetic) set schemata satisfying following properties:contains one parameter n.Every iteration form ni=1 ni=1 , where:contains iteration.Every atomic formula belongs {pi , p2i , pi1 , p2i1 } p variable.atomic formulae occurring scope iterationform p0 pn p variable9 .Ch rather simple close class regular schemata. oneparameter n, iterations bounds 1 n, nested iterationindices symbol P must ane images iteration counter.dierence regular class that, Ch coecient iteration counterindexed variables may equal 2 whereas must equal 0 1 regular schemata.Thus regular schemata contain translations iteration counter, whereas Ch mayinvolve (very simple) homothetic transformations.Due closeness, one could expect satisability problem decidableCh , next theorem shows case.Theorem 6.2set unsatisable formulae Ch recursively enumerable.proof Theorem 6.2 dicult remaining part section devotedit. precisely, shall prove Post correspondence problem encodedCh . Notice problem easily encoded general schemata (Aravantinoset al., 2009b), whereas, here, whole diculty proof lies strong restrictionsimposed Ch . Observe dicult proof really worth one would easily believeallowing multiplication constant unsignicant change.6.1.1 Notationsrst recall basic denitions introduce useful notations. Letalphabet. Let natural number. Let = (a1 , . . . , ) b = (b1 , . . . , b ) twosequences words . w {a, b} [1, ], |w | denotes length w wdenotes -th character word w (1 |w |).9. Notice p0 pn occur scope negation.643fiAravantinos, Caferra & Peltier= (1 , . . . , ) sequence indices [1, ] w = (w1 , . . . , w ) -tuplewords (where w {a, b}) denote w word w1 . .w (where .denotes concatenation operator). solution Post correspondence problemsequence s.t. = b . witness solution word .technical convenience, assume (this obviously restrictive) > 1,= , = < = b = special character (not occurringa1 , . . . , a1 , b1 , . . . , b1 ) denoting end sequence.6.1.2 Overview Encodingintuition behind encoding following. show encode instanceproblem schema satisable instance solution.precisely, construct parameter n s.t. N , [/n] satisablesolution length .rst present encoding used represent potential solutions b ;see check really solutions. represent potential solutionw (where w = a, b) one-dimensional array length n. precisely, storecharacters rather, character, pair containing indexword w occurs position word (as shall see usefulnd next character w ). instance rst index contain pair (1 , 1)(rst word, rst character). next index contains either (1 , 2) (if |w1 | > 1, rstword, second character) (2 , 1) (if |w1 | = 1, second word, rst character).example, = {, , }, = (, ) = (1, 2), obtained array wouldfollowing one:ValuesIndices(1, 1)1(1, 2)2(2, 1)3However, word w stored consecutive indices array. Indeed,shall see, also need store, character w witness, indices+1 , . . . , remaining words, occurring w w . sequence calledtail potential solution. Since length sequence unbounded, cannotencoded simply indexed propositions: must stored array simplestsolution store indices character itself. Notice indiceswords stored tail i.e. character position. Thus get:ValuesIndices(1, 1)122(1, 2)324(2, 1)5easiest way proceed would store rst character witness position0, indices remaining words position 1, 2, . . . , , second characterwitness position + 1 etc. way, -th character witness wouldstored position ( 1) ( + 1) following characters sequence positions( 1) ( + 1) + 1, . . . , ( 1) ( + 1) + . character stored index , nextcharacter would stored index + + 1. simple solution suitableoutside considered class. Indeed, requires use another parameter(the rst parameter n: length array) also use parameter644fiDecidability Undecidability Results Propositional Schemataindices (to relate character stored index one index + ),forbidden class Ch .Thus need nd another encoding previous array. idea store rstcharacter index (where assumed greater ), second characterindex 2 , . . . generally -th character index 21 .tail sequence stored indices ( + 1) 21 , . . . , ( + ) 21 .encoding ensures index next character one index simply 2.i,homethetic transformations precisely allowed indices Ch .Finally, array corresponding recurrent example following one (with= 2):ValuesIndices1(1, 1)223(1, 2)42567(2, 1)8witness obtained considering characters stored indices 2,4 (= 2 2)8 (= 222 ), namely (rst character rst word), (rst word, second character),(second word, rst character). Obviously holes array,simply ignored.6.1.3 Signaturearray encoded two indexed propositions: car(w, , ) t(w, ) (t standstail) w {a, b}, 1 , 1 |w |. intuition behind car(w, , )lholds index l array corresponding w contains pair (, ) (representingcharacter w ). t(w, )l states index l array corresponding w contains.6.1.4 Formal Definition EncodingLet n variable (intended denote unique parameter schema).explained previous section, store characters array, indices, 2, 4, etc. Intuitively, encoded another parameter, one parameter n allowed. However, encode new proposition symbol P. rstdene two symbols p, q s.t. p holds = s.t. q holds [0, 1]. rstschema denes q way holds exactly interval form [0, 1]:q0 qnn(qi+1 qi )i=1last formula obviously implies q holds [1..n] must alsohold every [1..]. simply rst index q hold (thiselement necessarily exists, since qn hold).second schema denes p holds exactly successor maximalelement interval (i.e. ). Notice due previous formula must = 0n:n[pi (qi1 qi )]i=1645fiAravantinos, Caferra & Peltiersake clarity, shall denote ( = ) atom p ( < ) atomq (this makes formulae much readable).dene variable wt s.t. wt holds exists N s.t. = .2 : wt standswitness, wt holds index character witness solution,explained before:ni=1 [((i= ) wti ) ((i < ) wti )(1)((2i + 1 = ) wt2i+1 ) ((2i < ) (2i = )) (wti wt2i )]rst line states wt holds wti false < . second line denesvalue wti > : wt2i+1 always false (except 2i + 1 = ) wt2i equivalentwti 2i > . easy induction set natural numbers, properties implywt holds . = .2 . Notice crucial use homothetic transformationhere.following formula states index cannot represent two distinct characters(pairs) sequence:n(car(w, , )i car(w, , )i )i=1every w {a, b}, (, ) [1, ]2 , [1, |w |], [1, |w |] s.t. (, ) = ( , )Similarly, state every index contains one word sequence:n(t(w, )i t(w, )i ) every w {a, b}, , [1, ]2 , =i=1initial elements sequences corresponding b must form(, 1) ( sequences distinct , since word |w | marksend sequence):n((i = ) [1, 1](car(a, , 1)i car(b, , 1)i ))i=1use existential quantication intervals natural numbers sake clarity,quantiers easily eliminated transformed nite (not iterated )disjunctions.next formula denes e(w) mark end sequence corresponding w.e(w)l hold l form .2 > 0 character storedindex l rst character word (remember convention = b =marks end witness). Besides, must ensure end sequenceeventually reached i.e. exists index l e(a)l e(b)l hold:n(e(a)i e(b)i )i=1n((wti car(w, , 1)i ) e(w)i )i=1646()fiDecidability Undecidability Results Propositional Schemataevery w {a, b}also ensure two sequences (i.e. words b ) identical.suces check every index l s.t. wtl holds (i.e. every index l form2 ), character stored l sequences b:n(wti (car(a, , )i car(b, , )i ))()i=1every , [1, ]2 , [1, |a |], [1, |b |] s.t. = bfar, ensured one character word index storedevery index. dened starting point end two sequencesensured two represented words identical. next (and dicult) stepensure sequences really encode two words form b respectively.aim, shall relate value character stored every index .2+1one stored .2 , ensure former really successor latterwitness. Since character c represented pair (, ) denotes indexword w position c w , easy nd next character: < |w |(i.e. c last character w ) next character simply (, + 1) (sameword w , next position + 1). = |w | (i.e. c last character w ) nextcharacter ( , 1) denotes next word index solution sequence (word w ,rst position).order determine index word use fact (as explainedinformal overview above) remaining indices solution stored index.2 + 1, .2 + 2, . . .. Thus, simply need pick rst element sequence.checking character stored .2+1 successor one .2remains ensure indices stored .2+1 + 1, .2+1 + 2,. . . correspondremaining part solution. < |w | sequence must actually identicalone stored .2 + 1, .2 + 2,. . . = |w | rst element sequencemust deleted (since entered new word).next formula states index l form .2 (i.e. index s.t. wtl holds)contains pair (, ) w contains characters .2+1 encodenext character word w , namely (, + 1). Moreover tail sequencechange, expressed using variable c(w)l (c stands copy)specied thereafter:n[(wti car(w, , )i ) (car(w, , + 1)2i c(w)i+1 )](2)i=1every w {a, b}, [1, ], [1, |w | 1].dene formula encoding copy tail. simple way proceedwould copy values stored indices l, l+1, . . . , l+1 2l+1, . . . , 2l+1.Unfortunately cannot done simple way expressions form l + j647fiAravantinos, Caferra & Peltierwould required indices, forbidden class (only 1 added).explained before, overcome problem copying indices l + 1, . . . , l + 12l + 2, 2l + 4, . . . , 2l + 2 2, done doubling iteration counter.indices 2l + 1, 2l + 3, . . . , 2l + 2 1 left empty (holes). disturbing sinceempty indices simply ignored. important consequence lengthsequence doubled time copied (we assume value parametern natural number suciently large ensure enough spacearray).expressed following formula:n(c(w)i [t(w, )2i1 (t(w, )i t(w, )2i ) (wti+1 c(w)i+1 )])(3)i=1every [1, ], w {a, b}illustrate construction example. Let = {, , , }, = (, , )= (1, 2, 3). second line, provide every index l pair (, )car(a, , )l holds (if any). third line gives represented character (,, ).fourth line provide integer t(a, )l holds. fth line gives valuec(a). indices + 2 2 empty (we assume = 3).carcharacterc(a)(1, 1)+1+2232(1, 2)2 + 12 + 222 + 32 + 43formula (2) must c+1 . formula (3), value c(a)+1 propagatedc(a)+2 ,. . . , c(a)21 (it propagated c(a)2 since wt2 holds). Still (2),c(a)l holds t(a, )l t(a, )2l , cells corresponding odd indicesleft empty. Thus get array above.index .2 contains pair (, ) |w | = (such 2 previous example),one must proceed next word. aim, need know rstcharacter next word (after current one). holes introducedspecial copying mechanism, next word necessarily index l+1. simple solutionchange contents tail element contains indexword also rst character. stated following formula:n[wti (t(w, )i car(w, , 1)i )](4)i=1Furthermore, copy character holes preceding element.particular case get wanted rst non-empty word.10 stated10. Notice could well copied words index instead rst character, since indexcontains information need retrieve corresponding character. However usefulfollowing know word index stored particular cell, storeinformation useful problem want solve point, i.e. rst characterword.648fiDecidability Undecidability Results Propositional Schematafollowing formula:n[(wti1 wti [1, ] t(w, )i1 ) (car(w, , 1)i car(w, , 1)i1 )](5)i=1every [1, ], w {a, b}Now, pair stored (, |w |) word nal wordsequence (i.e. e(w) hold) one store 2 rst characternext word, is, due two previous formulae, character represented + 1.previous picture must thus completed follows:carcharacter(1, 1)+1(2, 1)2+2(3, 1)32(1, 2)2 + 1(2, 1)2 + 2(2, 1)22 + 3(3, 1)2 + 4(3, 1)3formula (4) above, t(a, )i holds car(a, , 1)i also holds.formula (5), value car(a, , 1)l recursively propagated car(a, , 1)l1l 1 = .2 t(a, )l1 holds . Notice character storedevery index l characters indices .2 form witness.Thanks trick, nding next character one stored .2trivial: simply one stored .2 + 1, which, previous formula, actuallycorresponds rst position word stored ( + 1).2 (of course, also needcheck character nal). expressed following formula:n[(wtl e(w)l car(w, , |w |)l ) (car(w, , 1)2l car(w, , 1)l+1 ) s(w)l+1 ]l=1every , [1, ], w {a, b}propositional variable s(w)l+1 (s stands shift) indicates tail 2lobtained removing rst word tail l. done follows: indices2l + 2, . . . , 2l + 2 1 obtained copying indices l + 1, . . . , l + 1, exceptrst one, left empty. c(w), indices 2l 1, . . . , 2l + 2 3 empty. s(w)dened three following formulae.s(w) actually erases everything nds non-empty index, expressedrst formula: s(w)l holds indices stored 2l 2l 1 must empty(furthermore, also check end tail reached):n(s(w)l wtl t(w, )2l t(w, )2l1 ) every [1, ], w {a, b}l=1second one propagates erasure current index empty:649(6)fiAravantinos, Caferra & Peltiern[(s(w)l wtl+1 [1, ] t(w, )l ) s(w)l+1 ] every w {a, b}(7)l=1third one states reached non-empty index gocopying everything (which done using previous variable c(w)):n(s(w)l [1, ] t(w, )l c(w)l+1 ) every w {a, b}(8)l=1illustrate construction showing erasure works previous example:carcharacter4(2, 1)carcharacterc(a)s(a)2(1, 2)4 + 1(3, 1)4 + 2(3, 1)2 + 1(2, 1)2 + 2(2, 1)24 + 3(3, 1)4 + 4(3, 1)2 + 3(3, 1)2 + 4(3, 1)34 + 5(3, 1)4 + 6(3, 1)4 + 7(3, 1)4 + 8(3,1)3character stored 2 last one rst word thus remove rstword tail solution. explained before, character stored 4one stored 2+1, namely (2, 1), i.e. (since car(a, , 1)4 car(a, , 1)2+1 ).Furthermore, s(a)2+1 holds. implies (6) indices 4 + 2 4 + 1must empty. Since empty = 2 + 1 (i.e. t(a, )2+1holds), value s(a)2+1 propagated s(a)2+2 , (7). Thus (6), indices4 + 4 4 + 3 must also empty. time, however, t(a, 2)2+2 holds. Thusvalue s(a) propagated c(a)2+3 must hold (by (8)). before, impliesremaining part sequence (i.e. cells 2 + 3, 2 + 4 t) copied (incells 4 + 6, 4 + 8, leaving cells 4 + 5, 4 + 7 empty) 4 reached. impliesparticular t(a, 3)4+8 holds (since t(a, 3)2+4 holds). Hence car(a, 3, 1)4+8 .Since empty l [4 + 1, . . . , 4 + 7], value car(a, 3, 1) propagatedindices 4 + 7, . . . , 4 + 1 explained before. obtain desired result, i.e. rstword sequence (namely 2) erased rst character next wordstored 4 + 1.Finally, order ensure obtained sequence really solution Postcorrespondence problem, remains check two sequences identical, i.e.words contained + 1, , 2 1 sequences b.purpose dene variable rl true l < 2.650fiDecidability Undecidability Results Propositional Schematar0 rnn[(rl rl1 ) (l = ) (r2l1 r2l )]()l=1n[(rl (l < )) (t(a, )l t(b, )l )]()l=1every [1, ]straightforward check obtained formula Ch . reader acquaintedPosts correspondence problem shall convinced obtained formulasatisable exists solution Post problem, thus skip endsection. Otherwise give following sketch formal steps proof.denote conjunction formulae, except formulae marked ().rst notice satisable (for every value n). Indeed, explained before,formulae impose that:exists unique natural number p holds = q holds[0, 1].car(w, , ) t(w, ) encode (partial) functions fw , gw mapping every index [1, n]pair (, ) (where [1, ], [1, |w |]) word index [1, ] respectively.Moreover must fa () = (, 1) fb () = (, 1) [1.. 1].wt holds exists N s.t. = .2 .obviously denes partial interpretation. remaining formulae simply give values car(w, , ) , t(w, ) , c(w) , s(w) 2. easy checkdistinct formulae cannot give distinct values propositional variable, hencesatisability guaranteed.Let interpretation . Let [1..n]. dene following sequences.hw () sequence word indices dened follows: wt+1 holds hw ()defempty. Otherwise, gw () = hw () = .hw ( + 1) gw () undeneddefhw () = hw ( + 1). Intuitively, hw () sequence word indices stored juste(i.e. tail) ignoring empty cells.jw () word dened follows: > n jw () empty. Otherwise, jw () =defw .jw (2) fw () pair (, ) distinct (, 1), jw () = fw () = (, 1)defjw () = jw (2) fw () undened. jw () denotes word stored cells , 2 . . .array corresponding w ((, 1) marks end word).deffw () = (, ) kw () denotes sux length |w | + 1 word w(notice construction must ||).denition copying/erasing mechanism above, fw (.2 ) form (, |w |)(i.e. end word ) hw (.2 ) = .hw (.2+1 ), fw (.2+1 ) =651fiAravantinos, Caferra & Peltier( , 1) (i.e. tail equal next word followed next tail). Otherwise (i.e.middle word) hw (.2 ) = hw (.2+1 ) fw (.2+1 ) = (, + 1)fw (.2 ) = (, ) ( = |w |)). easy induction length jw (.2 ),deduce jw (.2 ) prex kw (.2 ).whw (.2 ) : kw (.2 ) represents endword considered character , whw (.2 ) concatenation wordstail.= 0 get particular jw () prex kw ().whw () . denitionkw () = w (not depending w). Thus jw () prex w.hw () .formulae occurring conjunction check ha () = hb () (samesequence word indices b), ja () = jb () ja () endscharacter (marking end witness).model whole formula, jw () prex w.hw () , ending ,thus must form w. prex hw (). Hence . solutionPosts correspondence problem.Conversely, solution . exists, simply consider modelha () = hb () = (this implies > ||, notice values fw (l) gw (l)xed arbitrarily l < 2) I(n) > .2 , = |a. |. jw () prexw.hw () . Since length jw () cannot greater one w. , jw () must end. Thus must jw () = w. (since last character w. ). Moreoversince . solution ja () = jb (). Thus validates formulae above.6.2 Unbounded TranslationOne wonder whether decidability class regular schemata still holdsunbounded translations allowed indices, i.e. translations form +denotes iteration counter parameter (the case Z covered regularclass). following denition theorem show answer negative.Definition 6.3Ct (t stands translation) set schemata satisfying following properties.contains two parameters n, m.Every iteration form ni=1 ni=1 , where:contains iteration.Every atomic formula form p.i++.m , p variable,, {0, 1} {1, 0, 1}.atomic propositions occurring scope iterationform p0 pn p variable.Theorem 6.4set unsatisable formulae Ct recursively enumerable.Proof(Sketch) detail proof since similar previous one. reuseencoding proof Theorem 6.2, except pairs (, ) array652fiDecidability Undecidability Results Propositional Schematastored indices form + instead .2 . Formally, formulae (1), (2),(3) (6) replaced following ones, respectively:n[((l = ) wtl ) ((l < ) wtl ) ((l < ) (l = )) (wtl wtl+m )]l=1(i.e. wtl holds exists s.t. l = + m).n[wtl car(w, , )l (car(w, , + 1)l+m c(w)l+1 )]l=1(i.e. index 2l replaced l + m).n(c(w)l [(t(w, )l t(w, )l+m ) (wti+1 c(w)l+1 )])l=1n(s(w)l wtl t(w, )l+m )l=17. Conclusionintroduced rst (to best knowledge) logic reasoning iteratedpropositional schemata. dened class schemata called bound-linearsatisability problem decidable. decidability proof constructive dividedtwo parts: rst show transform every bound-linear schema sat-equivalentschema simpler form, called regular. proof procedure dened decidesatisability regular schemata. proof procedure sound complete w.r.t.satisability every schema (even regular bound-linear) terminatesevery regular schema. Termination relies special looping detection rule.procedure implemented software RegStab.class bound-linear schemata expressive enough capture specicationsmany important problems AI, especially automated (or interactive) theorem proving (e.g., parameterized circuit verication problems). proved even slightrelaxation conditions bound-linear schemata makes satisability problem undecidable (this shown tricky reduction Post correspondence problem).consequence, bound-linear schemata considered canonical decidable class,providing good compromise expressivity tractability.future work, two ways promising. Firstly, extensionprevious results particular classesnon-monadic schemata (i.e. schemata containingnofsymbols several indices, e.g., i=1 nj=1 pi,j ) would enlarge considerably applicationspropositional schemata. Secondly, extending approach expressive logics,653fiAravantinos, Caferra & Peltierrst-order logic, description logics modal logics, also deserves considered.presented results extend straightforwardly many-valued propositional logic(provided number truth values xed nite). would allow captureinnite constraint satisfaction languages.Acknowledgmentswork partly funded project ASAP French Agence Nationale dela Recherche (ANR-09-BLAN-0407-01). authors wish thank anonymous refereesinsightful comments helped improve earlier version paper.ReferencesAczel, P. (1977). Introduction Inductive Denitions. Barwise, K. J. (Ed.), HandbookMathematical Logic, pp. 739782. North-Holland, Amsterdam.Aravantinos, V., Caferra, R., & Peltier, N. (2009a). DPLL proof procedure propositional iterated schemata. Workshop Structures Deduction 2009 (ESSLI),pp. 2438.Aravantinos, V., Caferra, R., & Peltier, N. (2009b). schemata calculus propositionallogic. TABLEAUX 09 (International Conference Automated ReasoningAnalytic Tableaux Related Methods), Vol. 5607 LNCS, pp. 3246. Springer.Aravantinos, V., Caferra, R., & Peltier, N. (2010). Decidable Class Nested IteratedSchemata. IJCAR 2010 (International Joint Conference Automated Reasoning),LNCS, pp. 293308. Springer.Baaz, M. (1999). Note generalization calculations. Theoretical Computer Science,224, 311.Baaz, M., & Zach, R. (1994). Short proofs tautologies using schema equivalence.Computer Science Logic (CSL93), Vol. 832 LNCS, pp. 3335. Springer-Verlag.Baelde, D. (2009). proof theory regular xed points. Proceedings 18thInternational Conference Automated Reasoning Analytic Tableaux RelatedMethods (TABLEAUX 2009), Vol. 5607 LNCS, pp. 93107. Springer.Barendregt, H., & Wiedijk, F. (2005). challenge computer mathematics. PhilosophicalTransactions Royal Society A, 363, 23512375.Bouhoula, A., Kounalis, E., & Rusinowitch, M. (1992). SPIKE, automatic theoremprover. Proceedings International Conference Logic ProgrammingAutomated Reasoning (LPAR92), Vol. 624, pp. 460462. Springer-Verlag.Boyer, R. S., & Moore, J. S. (1979). computational logic. Academic Press.Bradeld, J., & Stirling, C. (1992). Local model checking innite state spaces. Selectedpapers Second Workshop Concurrency compositionality, pp. 157174,Essex, UK. Elsevier Science Publishers Ltd.654fiDecidability Undecidability Results Propositional SchemataBradeld, J., & Stirling, C. (2007). Modal Mu-Calculi. Blackburn, P., Benthem, J. F.A. K. v., & Wolter, F. (Eds.), Handbook Modal Logic, Volume 3 (Studies LogicPractical Reasoning), pp. 721756. Elsevier Science Inc., New York, NY, USA.Brotherston, J. (2005). Cyclic Proofs First-Order Logic Inductive Denitions.Beckert, B. (Ed.), Automated Reasoning Analytic Tableaux Related Methods:Proceedings TABLEAUX 2005, Vol. 3702 LNAI, pp. 7892. Springer-Verlag.Bundy, A. (2001). automation proof mathematical induction. Robinson, J. A.,& Voronkov, A. (Eds.), Handbook Automated Reasoning, pp. 845911. ElsevierMIT Press.Bundy, A., van Harmelen, F., Horn, C., & Smaill, A. (1990). Oyster-Clam system.Proceedings 10th International Conference Automated Deduction, pp.647648, London, UK. Springer-Verlag.Chen, H., Hsiang, J., & Kong, H. (1990). nite representations innite sequencesterms. Conditional Typed Rewriting Systems, 2nd International Workshop,pp. 100114. Springer, LNCS 516.Cleaveland, R. (1990). Tableau-based model checking propositional mu-calculus.Acta Inf., 27 (9), 725747.Comon, H. (2001). Inductionless induction. Robinson, A., & Voronkov, A. (Eds.),Handbook Automated Reasoning, chap. 14, pp. 913962. North-Holland.Comon, H. (1995). unication terms integer exponents. Mathematical SystemTheory, 28, 6788.Cooper, D. (1972). Theorem proving arithmetic without multiplication. Meltzer, B.,& Michie, D. (Eds.), Machine Intelligence 7, chap. 5, pp. 9199. Edinburgh UniversityPress.Davis, M., Logemann, G., & Loveland, D. (1962). Machine Program Theorem Proving.Communication ACM, 5, 394397.Ebbinghaus, H.-D., & Flum, J. (1999). Finite Model Theory. Perspectives MathematicalLogic. Springer. Second Revised Enlarged Edition.Fagin, R. (1993). Finite-Model Theory - Personal Perspective. Theoretical ComputerScience, 116, 331.Giesl, J., & Kapur, D. (2001). Decidable classes inductive theorems. Gore, R., Leitsch,A., & Nipkow, T. (Eds.), IJCAR, Vol. 2083 Lecture Notes Computer Science,pp. 469484. Springer.Gore, R. (1999). Chapter 6: Tableau Methods Modal Temporal Logics.DAgostino, Gabbay, R Hahnle, J Posegga (Ed.), Handbook Tableau Methods,pp. 297396. Kluwer Academic Publishers. http://arp.anu.edu.au/~ rpg (draft).Gupta, A., & Fisher, A. L. (1993). Representation symbolic manipulation linearlyinductive boolean functions. Lightner, M. R., & Jess, J. A. G. (Eds.), ICCAD, pp.192199. IEEE Computer Society.Hermann, M., & Galbavy, R. (1997). Unication Innite Sets Terms schematizedPrimal Grammars. Theoretical Computer Science, 176 (12), 111158.655fiAravantinos, Caferra & PeltierHetzl, S., Leitsch, A., Weller, D., & Woltzenlogel Paleo, B. (2008). Proof analysisHLK, CERES ProofTool: Current status future directions. Sutclie G.,Colton S., S. S. (Ed.), Workshop Empirically Successful Automated ReasoningMathematics (ESARM), pp. 2141.Immerman, N. (1982). Relational queries computable polynomial time (Extended Abstract). STOC 82: Proceedings fourteenth annual ACM symposiumTheory computing, pp. 147152, New York, NY, USA. ACM.Krajicek, J., & Pudlak, P. (1988). number proof lines size proofsrst-order logic. Archive Mathematical Logic, pp. 6994.Marriott, K., Nethercote, N., Rafeh, R., Stuckey, P. J., Garca de la Banda, M., & Wallace,M. (2008). design Zinc modelling language. Constraints, 13 (3), 229267.Orevkov, V. P. (1991). Proof schemata Hilbert-type axiomatic theories. JournalMathematical Sciences, 55 (2), 16101620.Parikh, R. J. (1973). results length proofs. Transactions AmericanMathematical Society, 177, 2936.Park, D. M. (1976). Finiteness Mu-ineable. Theoretical Computer Science, 3, 173181.Paulin-Mohring, C. (1993). Inductive Denitions system Coq - Rules Properties.TLCA 93: Proceedings International Conference Typed Lambda CalculiApplications, pp. 328345, London, UK. Springer-Verlag.Smullyan, R. M. (1968). First-Order Logic. Springer.Sprenger, C., & Dam, M. (2003). Structure Inductive Reasoning: CircularTree-shaped Proofs mu-Calculus. Proc. FOSSACS03, Springer LNCS, pp.425440.Wos, L. (1988). Automated Reasoning: 33 Basic Research Problems. Prentice Hall.Wos, L., Overbeek, R., Lush, E., & Boyle, J. (1992). Automated Reasoning: IntroductionApplications (Second edition). McGraw-Hill.656fiJournal Artificial Intelligence Research 40 (2011) 729-765Submitted 11/10; published 04/11Exploiting Structure Weighted Model CountingApproaches Probabilistic InferenceWei Liwei.li@autodesk.comAutodesk CanadaToronto, Ontario M5A 1J7 CanadaPascal PoupartPeter van Beekppoupart@cs.uwaterloo.cavanbeek@cs.uwaterloo.caCheriton School Computer ScienceUniversity WaterlooWaterloo, Ontario N2L 3G1 CanadaAbstractPrevious studies demonstrated encoding Bayesian network SAT formula performing weighted model counting using backtracking search algorithmeective method exact inference. paper, present techniquesimproving approach Bayesian networks noisy-OR noisy-MAX relationstwo relations widely used practice dramatically reduce numberprobabilities one needs specify. particular, present two SAT encodingsnoisy-OR two encodings noisy-MAX exploit structure semanticsrelations improve time space eciency, prove correctnessencodings. experimentally evaluated techniques large-scale real randomlygenerated Bayesian networks. benchmarks, techniques gave speedupstwo orders magnitude best previous approaches networks noisyOR/MAX relations scaled larger networks. well, techniques extendweighted model counting approach exact inference networks previouslyintractable approach.1. IntroductionBayesian networks fundamental building block many AI applications. Bayesiannetwork consists directed acyclic graph nodes represent random variablesnode labeled conditional probability table (CPT) representsstrengths inuences parent nodes child node (Pearl, 1988). general,assuming random variables domain size d, CPT child node n parentsrequires one specify dn+1 probabilities. presents practical diculty ledintroduction patterns CPTs require one specify many fewer parameters(e.g., Good, 1961; Pearl, 1988; Dez & Druzdzel, 2006).Perhaps widely used patterns practice noisy-OR relationgeneralization, noisy-MAX relation (Good, 1961; Pearl, 1988). relations assumeform causal independence allow one specify CPT n parameterscase noisy-OR (d 1)2 n parameters case noisy-MAX, nnumber parents node size domains random variables.noisy-OR/MAX relations successfully applied knowledge engineeringc2011AI Access Foundation. rights reserved.fiLi, Poupart, & van Beeklarge real-world Bayesian networks, Quick Medical Reference-Decision Theoretic(QMR-DT) project (Miller, Masarie, & Myers, 1986) Computer-based Patient CaseSimulation system (Parker & Miller, 1987). well, Zagorecki Druzdzel (1992) showthree real-world Bayesian networks, noisy-OR/MAX relations good50% CPTs networks converting CPTs noisy-OR/MAXrelations gave good approximations answering probabilistic queries. surprising,CPTs networks specied using noisy-OR/MAX assumptionsspecied full CPTs. results provide additional evidence usefulnessnoisy-OR/MAX relations.consider problem exact inference Bayesian networks containnoisy-OR/MAX relations. One method solving networks replace noisyOR/MAX full CPT representation use well-known algorithmsanswering probabilistic queries variable elimination tree clustering/jointree.However, generaland particular, networks use experimentalevaluationthis method impractical. fruitful approach solving networkstake advantage semantics noisy-OR/MAX relations improvetime space eciency (e.g., Heckerman, 1989; Olesen, Kjaerul, Jensen, Jensen, Falck,Andreassen, & Andersen, 1989; DAmbrosio, 1994; Heckerman & Breese, 1996; Zhang &Poole, 1996; Takikawa & DAmbrosio, 1999; Dez & Galan, 2003; Chavira, Allen, & Darwiche, 2005).Previous studies demonstrated encoding Bayesian network SAT formula performing weighted model counting using DPLL-based algorithmeective method exact inference, DPLL backtracking algorithm specializedSAT includes unit propagation, conict recording, backjumping, componentcaching (Sang, Beame, & Kautz, 2005a). paper, present techniques improving weighted model counting approach Bayesian networks noisy-ORnoisy-MAX relations. particular, present two CNF encodings noisy-OR twoCNF encodings noisy-MAX exploit semantics improve timespace eciency probabilistic inference. encodings, pay particular attentionreducing treewidth CNF formula. also explore alternative search orderingheuristics DPLL-based backtracking algorithm.experimentally evaluated encodings large-scale real randomly generatedBayesian networks using Cachet weighted model counting solver (Sang, Bacchus, Beame,Kautz, & Pitassi, 2004). experimental results must interpretedcare comparing encodings also implementations systemsconicting design goals, benchmarks techniques gave speedupsthree orders magnitude best previous approaches networks noisy-ORnoisy-MAX. well, benchmarks many networks couldsolved previous approaches within resource limits, could solved quitequickly Cachet using encodings. Thus, noisy-OR noisy-MAX encodingsextend model counting approach exact inference networks previouslyintractable approach.730fiExploiting Structure Probabilistic InferenceX1X2XnFigure 1: General causal structure Bayesian network noisy-OR/MAX relation,causes X1 , . . . , Xn lead eect noisy-OR/MAX relationnode .2. Backgroundsection, review noisy-OR/MAX relations needed background weightedmodel counting approaches exact inference Bayesian networks (for topicssee, example, Koller & Friedman, 2009; Darwiche, 2009; Chavira & Darwiche, 2008).2.1 Patterns CPTs: Noisy-OR Noisy-MAXnoisy-OR relation one assumes dierent causes X1 , . . . , Xn leadingeect (see Figure 1), random variables assumed Booleanvalued domains. cause Xi either present absent, Xi isolation likelycause likelihood diminished one cause present. Further,one assumes possible causes given causes absent, eectabsent. Finally, one assumes mechanism reason inhibits Xi causingindependent mechanism reason inhibits Xj , j = i, causing .noisy-OR relation species CPT using n parameters, q1 , . . . , qn , one parent,qi probability false given Xi true parentsfalse,(1)P (Y = 0 | Xi = 1, Xj = 0[j,j=i]) = qi .parameters, full CPT representation size 2n+1 generated using,qi(2)P (Y = 0 | X1 , . . . , Xn ) =iTxP (Y = 1 | X1 , . . . , Xn ) = 1qi(3)iTxTx = {i | Xi = 1} P (Y = 0 | X1 , . . . , Xn ) = 1 Tx empty. last condition(when Tx empty) corresponds assumptions possible causes givencauses absent, eect absent; i.e., P (Y = 0 | X1 = 0, . . . , Xn = 0) = 1.assumptions restrictive may rst appear. One always introduce731fiLi, Poupart, & van BeekColdMalariaFluNauseaHeadacheFigure 2: Example causal Bayesian network causes (diseases) Cold, Flu,Malaria eects (symptoms) Nausea Headache.additional random variable X0 parent parents. variableX0 represents reasons could cause occur. node X0prior probability P (X0 ) referred leak node leak probability, respectively.follows, continue refer possible causes X1 , . . . , Xnunderstood one causes could leak node.Example 1. Consider Bayesian network shown Figure 2. Suppose randomvariables Boolean representing presence absence disease symptom,noisy-OR node Nausea node Headache, parametersnoisy-ORs given Table 1. full CPT node Nausea given by,C00001111F0011001101010101P (N ausea = 0 | C, F, )1.000.400.500.20 = 0.5 0.40.600.24 = 0.6 0.40.30 = 0.6 0.50.12 = 0.6 0.5 0.4P (N ausea = 1 | C, F, )0.000.600.500.800.400.760.700.88C, F , short Cold , Flu, Malaria, respectively.alternative way view noisy-OR relation decomposed probabilistic model.decomposed model shown Figure 3, one specify small conditionalprobability table node Yi given P (Yi | Xi ), instead exponentially largeCPT given P (Y | X1 , . . . , Xn ). decomposed model, P (Yi = 0 | Xi = 0) = 1,P (Yi = 0 | Xi = 1) = qi , CPT node deterministic givenlogical relation. operator converted full CPT follows,1, = Y1 Yn ,P (Y | Y1 , . . . , Yn ) =0, otherwise.732fiExploiting Structure Probabilistic InferenceX1X2Y1Y2XnYnOR/MAXFigure 3: Decomposed form Bayesian network noisy-OR/MAX relation,causes X1 , . . . , Xn lead eect noisy-OR/MAX relation node. node double border deterministic node designatedlogical relationship (OR) arithmetic relationship (MAX).Table 1: Parameters noisy-ORs node Nausea node HeadacheBayesian network shown Figure 2, assuming random variablesBoolean.P (Nausea = 0 | Cold = 1, Flu = 0, Malaria = 0)P (Nausea = 0 | Cold = 0, Flu = 1, Malaria = 0)P (Nausea = 0 | Cold = 0, Flu = 0, Malaria = 1)===0.60.50.4P (Headache = 0 | Cold = 1, Flu = 0, Malaria = 0)P (Headache = 0 | Cold = 0, Flu = 1, Malaria = 0)P (Headache = 0 | Cold = 0, Flu = 0, Malaria = 1)===0.30.20.1probability distribution eect variable given by,nP (Yi | Xi ) ,P (Y | X1 , . . . , Xn ) ==Y1 Yni=1sum congurations possible values Y1 , . . . , YnBoolean values equal value . Similarly, Pearls (1988) decomposedmodel, one specify n probabilities fully specify model (see Figure 4); i.e.,one species prior probabilities P (Ii ), 1 n. model, causes always leadeects unless prevented inhibited so. random variables Ii modelprevention inhibition.two decomposed probabilistic models (Figure 3, Figure 4) shownequivalent sense conditional probability distribution P (Y | X1 , . . . , Xn )induced networks original distribution network shownFigure 1. important note models would still exponentiallylarge CPT associated eect node deterministic node replaced733fiLi, Poupart, & van BeekX1I1Y1XnYnFigure 4: Pearls (1988) decomposed form noisy-OR relation. Nodes doubleborders deterministic nodes designated logical relationship.full CPT representation. words, decomposed models address easemodeling representation issues, address eciency reasoning issues.noisy-MAX relation (see Pearl, 1988; Good, 1961; Henrion, 1987; Dez, 1993)generalization noisy-OR non-Boolean domains. noisy-MAX relation,one assumes dierent causes X1 ,. . . , Xn leading eect (seeFigure 1), random variables may multi-valued (non-Boolean) domains.domains variables assumed ordered values referreddegree severity variable. domain distinguished lowest degree0 representing fact cause eect absent. noisy-OR relation, oneassumes possible causes given causes absent, eect absent.Again, assumptions restrictive rst appears, one incorporate leaknode. well, one assumes mechanism reason inhibits Xi causingindependent mechanism reason inhibits Xj , j = i, causing .Let dX number values domain random variable X. simplicitynotation without loss generality, assume domain variable Xgiven set integers {0, 1, . . . , dX 1}. noisy-MAX relation causes X1 , . . . ,Xn eect species CPT using parameters,xiP (Y = | Xi = xi , Xj = 0[j,j=i]) = qi,y= 1, . . . , n,(4)= 0, . . . , dY 1,xi = 1, . . . , dXi 1.domain sizes equal d, total (d 1)2 n non-redundant probabilitiesmust specied. parameters, full CPT representation size dn+1generated using,nxiqi,y(5)P (Y | X) =i=1 =0xi =0P (Y 0 | X)= 0,P (Y = | X) =P (Y | X) P (Y 1 | X) > 0.734(6)fiExploiting Structure Probabilistic InferenceX represents certain conguration parents , X = x1 , . . . , xn ,P (Y = 0 | X1 = 0, . . . , Xn = 0) = 1; i.e., causes absent, eect absent.Table 2: Parameters noisy-MAX node Nausea Bayesian network shownFigure 2, assuming diseases Boolean random variables symptomNausea domain {absent = 0, mild = 1, severe = 2}.P (Nausea = absent | Cold = 1, Flu = 0, Malaria = 0)P (Nausea = mild | Cold = 1, Flu = 0, Malaria = 0)P (Nausea = severe | Cold = 1, Flu = 0, Malaria = 0)===0.70.20.1P (Nausea = absent | Cold = 0, Flu = 1, Malaria = 0)P (Nausea = mild | Cold = 0, Flu = 1, Malaria = 0)P (Nausea = severe | Cold = 0, Flu = 1, Malaria = 0)===0.50.20.3P (Nausea = absent | Cold = 0, Flu = 0, Malaria = 1)P (Nausea = mild | Cold = 0, Flu = 0, Malaria = 1)P (Nausea = severe | Cold = 0, Flu = 0, Malaria = 1)===0.10.40.5Example 2. Consider Bayesian network shown Figure 2. Supposediseases Boolean random variables symptoms Nausea Headachedomains {absent = 0, mild = 1, severe = 2}, noisy-MAX node Nauseanode Headache, parameters noisy-MAX node Nausea givenTable 2. full CPT node Nausea given by,C00001111F0011001101010101P (N = | C, F, )1.0000.1000.5000.050 = 0.5 0.10.7000.070 = 0.7 0.10.350 = 0.7 0.50.035 = 0.7 0.5 0.1P (N = | C, F, )0.0000.4000.2000.3000.2000.3800.2800.280P (N = | C, F, )0.0000.5000.3000.6500.1000.5500.3700.685C, F , , N short variables Cold , Flu, Malaria, Nausea,respectively, a, m, short values absent, mild, severe, respectively. example calculation, P (Nausea = mild | Cold = 0, Flu = 1, Malaria = 1) =((0.5 + 0.2) (0.1 + 0.4)) (0.05) = 0.3 second example, P (Nausea = mild | Cold =1, Flu = 1, Malaria = 1) = ((0.7 + 0.2) (0.5 + 0.2) (0.1 + 0.4)) (0.035) = 0.28noisy-OR relation, alternative view noisy-MAX relationdecomposed probabilistic model (see Figure 3). decomposed model, onespecify small conditional probability table node Yi given P (Yi | Xi ),x . models eectP (Yi = 0 | Xi = 0) = 1 P (Yi = | Xi = x) = qi,y735fiLi, Poupart, & van Beekcause Xi eect isolation; i.e., degree severity eect casecause Xi absent causes absent. CPT nodedeterministic given MAX arithmetic relation. correspondsassumption severity degree reached eect maximumdegrees produced cause acting independently; i.e., maximumYi s. assumption valid eects accumulate. MAX operatorconverted full CPT follows,1, = max{Y1 , . . . , Yn },P (Y | Y1 , . . . , Yn ) =0, otherwise.probability distribution eect variable given by,nP (Yi | Xi ) ,P (Y | X1 , . . . , Xn ) ==max{Y1 ,...,Yn }i=1sum congurations possible values Y1 , . . . , Ynmaximum values equal value . cases, however, makingCPTs explicit often possible practice, size exponential numbercauses number values domains random variables.2.2 Weighted Model Counting Probabilistic Inferencefollows, consider propositional formulas conjunctive normal form (CNF).literal Boolean variable (also called proposition) negation clausedisjunction literals. clause one literal called unit clause literalunit clause called unit literal. propositional formula F conjunctive normal formconjunction clauses.Example 3. example, (x y) clause, formula,F = (x y) (x z) (y z w) (w z v) (v u),CNF, u, v, w, x, y, z propositions.Given propositional formula conjunctive normal form, problem determiningwhether exists variable assignment makes formula evaluate true calledBoolean satisfiability problem SAT. variable assignment makes formulaevaluate true also called model. problem counting number modelsformula called model counting.Let F denote propositional formula. use value 0 interchangeablyBoolean value false value 1 interchangeably Boolean value true. notation F |v=false represents new formula, called residual formula, obtained removingclauses contain literal v (as clauses evaluate true) deletingliteral v clauses. Similarly, notation F |v=true represents residual formulaobtained removing clauses contain literal v deleting literal v736fiExploiting Structure Probabilistic Inferenceclauses. Let set instantiated variables F . residual formula F |s obtainedcumulatively reducing F variables s.Example 4. Consider propositional formula F given Example 3. Supposex assigned false. residual formula given by,F |x=0 = (y) (y z) (y z w) (w z v) (v u).clear, CNF formula satised clauses satisedclause satised least one literals equivalent 1. unit clause,choice value literal said forced implied. processunit propagation assigns unit literals value 1. well, formula simpliedremoving variables unit literals remaining clauses removing clausesevaluate true (i.e., residual formula obtained) process continueslooking new unit clauses updating formula unit clause remains.Example 5. Consider propositional formula F |x=0 given Example 4, xassigned false. unit clause (y) forces assigned false. residualformula given by,F |x=0,y=0 = (z) (z w) (w z v) (v u).turn, unit clause (z) forces z assigned true. Similarly, assignments w = 1,v = 1, u = 1 forced.natural polynomial-time reductions Bayesian inference problemmodel counting problems (Bacchus, Dalmao, & Pitassi, 2003). particular, exactinference Bayesian networks reduced weighted model counting CNFs(Darwiche, 2002; Littman, 1999; Sang et al., 2005a). Weighted model counting generalization model counting.weighted model counting problem consists CNF formula F variablev F , weight literal: weight(v) weight(v). Let assignmentvalue every variable formula F satises formula; i.e., modelformula. weight product weights literals s. solutionweighted model counting problem sum weights satisfying assignments;i.e.,weight(l),weight(F ) =lssum possible models product literals model.Chavira Darwiche (2002, 2008) proposed encoding Bayesian networkweighted model counting propositional formula conjunctive normal form. ChaviraDarwiches encoding proceeds follows. step, illustrate encoding usingBayesian network shown Figure 2. simplicity, assume random variablesBoolean omit node Headache. improve clarity, refer randomvariables Bayesian network nodes reserve word variablesBoolean variables resulting propositional formula.value node Bayesian network, indicator variable created,737fiLi, Poupart, & van BeekCF::IC0 , IC1 ,IF0 , IF1 ,N::IM0 , IM1 ,IN0 , IN1 .node, indicator clauses generated ensure model exactlyone corresponding indicator variables node true,CF::(IC0 IC1 ) (IC0 IC1 ),(IF0 IF1 ) (IF0 IF1 ),N::(IM0 IM1 ) (IM0 IM1 ),(IN0 IN1 ) (IN0 IN1 ).conditional probability table (CPT) parameter (probability)value CPT, parameter variable created,CFPC0 ,PF0 ,PM0 ,:::PC1 ,PF1 ,PM1 ,N:PN0 |C0 ,F0 ,M0 ,. . .,PN0 |C1 ,F1 ,M1 ,PN1 |C0 ,F0 ,M0 ,. . .,PN1 |C1 ,F1 ,M1 .parameter variable, parameter clause generated. parameter clauseasserts conjunction corresponding indicator variables implies parameter variable vice-versa,CFN::::IC0 PC0 ,IF0 PF0 ,IM0 PM0 ,IC0 IF0 IM0 IN0 PN0 |C0 ,F0 ,M0 ,. . .,IC1 IF1 IM1 IN0 PN0 |C1 ,F1 ,M1 ,IC1 PC1 ,IF1 PF1 ,IM1 PM1 ,IC0 IF0 IM0 IN1 PN1 |C0 ,F0 ,M0 ,. . .,IC1 IF1 IM1 IN1 PN1 |C1 ,F1 ,M1 .weight assigned literal propositional formula. positive literalparameter variable assigned weight equal corresponding probabilityentry CPT table,C:F::N:weight(PC0 ) = P (C = 0),weight(PC1 ) = P (C = 1),weight(PF0 ) = P (F = 0),weight(PF1 ) = P (F = 1),weight(PM0 ) = P (M = 0),weight(PM1 ) = P (M = 1),weight(PN0 |C0 ,F0 ,M0 ) = P (Nweight(PN1 |C0 ,F0 ,M0 ) = P (N...,weight(PN0 |C1 ,F1 ,M1 ) = P (Nweight(PN1 |C1 ,F1 ,M1 ) = P (N= 0 | C = 0, F = 0, = 0),= 1 | C = 0, F = 0, = 0),= 0 | C = 1, F = 1, = 1),= 1 | C = 1, F = 1, = 1).literals (both positive negative) assigned weight 1; i.e., weight(IC0 )= weight(IC0 ) = = weight(IN1 ) = weight(IN1 ) = 1 weight(PC0 ) = =738fiExploiting Structure Probabilistic Inferenceweight(PN1 |C1 ,F1 ,M1 ) = 1. basic idea indicator variables specifystate worldi.e., value random variable Bayesian networkweights literals multiplied together give probabilitystate world.Sang, Beame, Kautz (2005a) introduced alternative encoding Bayesiannetwork weighted model counting CNF formula. Sang et al.s encoding createsfewer variables clauses, size generated clauses multi-valued variableslarger. Chavira Darwiches encoding presented above, illustrate Sanget al.s encoding using Bayesian network shown Figure 2, assumingrandom variables Boolean omitting node Headache.Chavira Darwiches encoding, node, indicator variables createdindicator clauses generated ensure model exactly onecorresponding indicator variables node true.Let values nodes linearly ordered. CPT entry P (Y = | X)last value domain , parameter variable Py|Xcreated; e.g.,CF:::PC0 ,PF0 ,PM0 ,N:PN0 |C0 ,F0 ,M0 ,PN0 |C0 ,F1 ,M0 ,PN0 |C1 ,F0 ,M0 ,PN0 |C1 ,F1 ,M0 ,PN0 |C0 ,F0 ,M1 ,PN0 |C0 ,F1 ,M1 ,PN0 |C1 ,F0 ,M1 ,PN0 |C1 ,F1 ,M1 .CPT entry P (Y = yi | X), parameter clause generated. Let ordereddomain {y1 , . . . , yk } let X = x1 , . . . , xl . yi last valuedomain , clause given by,Ix1 Ixl Py1 |X Pyi1 |X Pyi |X Iyi .yi last value domain , clause given by,Ix1 Ixl Py1 |X Pyk1 |X Iyk .running example, following parameter clauses would generated,CFN::::PC0 IC0PF0 IF0PM0 IM0IC0 IF0 IM0 PN0 |C0 ,F0 ,M0 IN0 ,. . .,IC1 IF1 IM1 PN0 |C1 ,F1 ,M1 IN0 ,PC0 IC1PF0 IF1PM0 IM1IC0 IF0 IM0 PN0 |C0 ,F0 ,M0 IN1 ,. . .,IC1 IF1 IM1 PN0 |C1 ,F1 ,M1 IN1 .weight assigned literal propositional formula. ChaviraDarwiches encoding, weight literals indicator variables always 1.739fiLi, Poupart, & van Beekweight literals parameter variable Py|X given by,weight(Py|X ) = P (y | X),weight(Py|X ) = 1 P (y | X).Let F CNF encoding Bayesian network (either Chavira Darwichesencoding Sang et al.s encoding). general query P (Q | E) networkanswered by,weight(F Q E),(7)weight(F E)Q E propositional formulas enforce appropriate valuesindicator variables correspond known values random variables.backtracking algorithm used enumerate (weighted) models CNF formulaoften referred DPLL DPLL-based (in honor Davis, Putnam, Logemann,Loveland, authors earliest work eld: Davis & Putnam, 1960; Davis,Logemann, & Loveland, 1962), usually includes techniques unit propagation,conict recording, backjumping, component caching.3. Related Worksection, relate work previously proposed methods exact inferenceBayesian networks contain noisy-OR/MAX relations.One method solving networks replace noisy-OR/MAX full CPTrepresentation use well-known algorithms answering probabilisticqueries variable elimination tree clustering/jointree. However, generalandparticular, networks use experimental evaluationthis methodimpractical. fruitful approach solving networks take advantagestructure semantics noisy-OR/MAX relations improve timespace eciency (e.g., Heckerman, 1989; Olesen et al., 1989; DAmbrosio, 1994; Heckerman& Breese, 1996; Zhang & Poole, 1996; Takikawa & DAmbrosio, 1999; Dez & Galan, 2003;Chavira et al., 2005).Quickscore (Heckerman, 1989) rst ecient exact inference algorithm Booleanvalued two-layer noisy-OR networks. Chavira, Allen Darwiche (2005) present methodmulti-layer noisy-OR networks show approach signicantly fasterQuickscore randomly generated two-layer networks. approach proceeds follows:(i) transform noisy-OR network Bayesian network full CPTs using Pearlsdecomposition (see Figure 4), (ii) translate network full CPTs CNF usinggeneral encoding (see Section 2), (iii) simplify resulting CNF taking advantagedeterminism (zero parameters one parameters), (iv) compile CNFarithmetic circuit. One encodings noisy-OR (called WMC1) similarindirect (but also general) proposal encoding noisy-ORs (steps (i)(iii)).perform detailed comparison Section 4.1. experiments, perform detailedempirical comparison approach using compilation (steps (i)(iv)) Cachetusing encodings large Bayesian networks.740fiExploiting Structure Probabilistic InferenceMany alternative methods proposed decompose noisy-OR/MAXadding hidden auxiliary nodes solving using adaptations variable elimination tree clustering (e.g., Olesen et al., 1989; DAmbrosio, 1994; Heckerman & Breese,1996; Takikawa & DAmbrosio, 1999; Dez & Galan, 2003).Olesen et al. (1989) proposed reduce size distribution OR/MAXoperator decomposing deterministic OR/MAX node n parents set binary OR/MAX operators. method, called parent divorcing, constructs binary treeadding auxiliary nodes Zi auxiliary nodes exactly twoparents. Heckerman (1993) presented sequential decomposition method basedadding auxiliary nodes Zi decomposing binary MAX operators. one constructs linear decomposition tree. methods require similar numbers auxiliarynodes similarly sized CPTs. However, Takikawa DAmbrosio (1999) note, usingeither parent divorcing sequential decomposition, many decomposition trees constructed original networkdepending causes orderedandeciency query answering vary exponentially using variable eliminationtree clustering, depending particular query choice ordering.take advantage causal independence models, Dez (1993) proposed algorithmnoisy-MAX/OR. introducing one auxiliary variable , Dezs method leadscomplexity O(nd2 ) singly connected networks, n number causessize domains random variables. However, networks loops needsintegrated local conditioning. Takikawa DAmbrosio (1999) proposed similarmultiplicative factorization approach. complexity approach O(max(2d , nd2 )).However, Takikawa DAmbrosios approach allows ecient elimination orderingsvariable elimination algorithm, Dezs method enforces restrictionsorderings. recently, Dez Galan (2003) proposed multiplicative factorizationimproves previous work, advantages methods. useauxiliary graph starting point remaining three CNF encodings (WMC2,MAX1, MAX2). experiments, perform detailed empirical comparisonapproach using variable elimination proposals large Bayesian networks.work, build upon DPLL-based weighted model counting approachSang, Beame, Kautz (2005a). general encoding assumes full CPTs yieldsparameter clause CPT parameter. However, approach impracticallarge-scale noisy-OR/MAX networks. special-purpose encodings extend weightedmodel counting approach exact inference networks previously intractableapproach.4. Ecient Encodings Noisy-OR CNFsection, present techniques improving weighted model counting approachBayesian networks noisy-OR relations. particular, present two CNF encodingsnoisy-OR relations exploit structure semantics. noisy-OR relationtake advantage Boolean domains simplify encodings. use runningexample Bayesian network shown Figure 2. subsequent section, generalizenoisy-MAX relation.741fiLi, Poupart, & van Beek4.1 Weighted CNF Encoding 1: Additive EncodingLet causes X1 , . . . , Xn leading eect let noisy-OR relationnode (see Figure 1), random variables assumed Boolean-valueddomains.rst weighted model encoding method (WMC1), introduce indicator variable IY indicator variable IXi parent . also introduceparameter variable Pqi parameter qi , 1 n noisy-OR (see Equation 1).weights variables follows,weight(IXi ) = weight(IXi ) = 1,weight(IY ) = weight(IY ) = 1,weight(Pqi ) = 1 qi ,weight(Pqi ) = qi .noisy-OR relation encoded formula,(IX1 Pq1 ) (IX2 Pq2 ) (IXn Pqn ) IY .(8)formula seen encoding Pearls well-known decomposition noisyOR (see Figure 4).Example 6. Consider Bayesian network shown Figure 2 parameters noisy-ORs shown Table 1. WMC1 encoding introduces fiveBoolean indicator variables IC , , IM , , IH , weight 1; six parameter variables P0.6 , P0.5 , P0.4 , P0.3 , P0.2 , P0.1 , weight(Pqi ) = 1 qiweight(Pqi ) = qi . Using Equation 8, noisy-OR node Nausea encoded as,(IC P0.6 ) (IF P0.5 ) (IM P0.4 ) .illustrate weighted model counting formula, suppose nausea malariaabsent cold flu present (i.e., Nausea = 0, Malaria = 0, Cold = 1,Flu = 1; corresponding indicator variables IM false ICtrue). formula simplified to,(P0.6 ) (P0.5 ) 0.one model formula, model sets P0.6 false P0.5 false.Hence, weighted model count formula weight(P0.6 )weight(P0.5 ) = 0.60.5= 0.3, entry penultimate row full CPT shown Example 2.Towards converting Equation 8 CNF, also introduce auxiliary indicator variable wi conjunction wi IXi Pqi . dramatically reduces number742fiExploiting Structure Probabilistic Inferenceclauses generated. Equation 8 transformed into,(IY((w1 wn )(IX1 Pq1 w1 )(IX1 w1 )(Pq1 w1 )(IXn Pqn wn )(IXn wn )(Pqn wn )))(IY((IX1 Pq1 )(IXn Pqn ))).formula CNF, easily transformed CNF using distributivelaw. seen WMC1 encoding also easily encode evidencei.e, IY = 0IY = 1, formula simpliedbefore nal translation CNF. Notemade denitions auxiliary variables (i.e., wi IXi Pqi ) conditionalIY true, rather introducing separate clauses dene auxiliaryvariable. allows formula simplied presence evidenceintroduces wi actually needed. particular, know IY false,clauses involving auxiliary variables wi , including denitions wi ,disappear formula simplied.Example 7. Consider Bayesian network shown Figure 2. illustrateencoding evidence, suppose nausea present (i.e., Nausea = 1) headachepresent (i.e., Headache = 0). corresponding constraints evidencefollows.(9)(IC P0.6 ) (IF P0.5 ) (IM P0.4 ) 1(IC P0.3 ) (IF P0.2 ) (IM P0.1 ) 0(10)constraints converted CNF clauses. Constraint Equation 9 givesclauses,(w1 w2 w3 )(IC P0.6 w1 ) (IC w1 ) (P0.6 w1 )(IF P0.5 w2 ) (IF w2 ) (P0.5 w2 )(IM P0.4 w3 ) (IM w3 ) (P0.4 w3 )constraint Equation 10 gives clauses,(IC P0.3 ) (IF P0.2 ) (IM P0.1 ).743fiLi, Poupart, & van Beekshow correctness encoding WMC1 noisy-OR, rst show entryfull CPT representation noisy-OR relation determined using weightedmodel count encoding. always, let causes X1 , . . . , Xn leadingeect let noisy-OR relation node , random variablesBoolean-valued domains.Lemma 1. entry full CPT representation noisy-OR node , P (Y =| X1 = x1 , . . . , Xn = xn ), determined using weighted model count Equation 8created using encoding WMC1.Proof. Let FY encoding noisy-OR node using WMC1 letset assignments indicator variables IY , IX1 , . . . , IXn corresponding desiredentry CPT (e.g., = 0, IY instantiated false; otherwise instantiatedtrue). Xi = 0, disjunct (IXi Pqi ) Equation 8 false would removedresidual formula FY |s ; Xi = 1, disjunct reduces (Pqi ). IY = 0,disjuncts Equation 8 must false single modelformula. Hence,weight(Pqi ) =qi = P (Y = 0 | X),weight(FY |s ) =iTxiTxTx = {i | Xi = 1} P (Y = 0 | X) = 1 Tx empty. IY = 1, least onedisjuncts Equation 8 must true are, therefore, 2|Tx | 1 models.seen sum 2|Tx | possible assignments, weight formula 1.Hence, subtracting one possible assignment model gives,weight(Pqi ) = 1qi = P (Y = 1 | X).weight(FY |s ) = 1iTxiTxnoisy-OR Bayesian network set random variables Z1 , . . . , Zn Bayesiannetwork noisy-OR relations one Zi full CPTsremaining nodes. next step proof correctness show entryjoint probability distribution represented noisy-OR Bayesian networkdetermined using weighted model counting. follows, assume noisy-ORnodes encoded using WMC1 remaining nodes encoded using Sang et al.sgeneral encoding discussed Section 2.2. Similar results stated using ChaviraDarwiches general encoding.Lemma 2. entry joint probability distribution, P (Z1 = z1 , . . . Zn = zn ), represented noisy-OR Bayesian network determined using weighted model countingencoding WMC1.Proof. Let F encoding Bayesian network using WMC1 noisy-OR nodeslet set assignments indicator variables IZ1 , . . . , IZn correspondingdesired entry joint probability distribution. entry joint probability744fiExploiting Structure Probabilistic Inferencedistribution expressed product,P (X1 , . . . , Xn ) =nP (Xi | parents (Xi )),i=1n size Bayesian network parents (Xi ) set parents Xidirected graph; i.e., entry joint probability distribution determinedmultiplying corresponding CPT entries. nodes full CPTs, determinescorrect entry CPT Lemma 2 Sang et al. (2005a) nodesnoisy-ORs, determines correct probability Lemma 1 above. Thus, weight(F s)multiplication corresponding CPT entries; i.e., entry joint probabilitydistribution.nal step proof correctness show queries interestcorrectly answered.Theorem 1. Given noisy-OR Bayesian network, general queries form P (Q | E)determined using weighted model counting encoding WMC1.Proof. Let F CNF encoding noisy-OR Bayesian network. general queryP (Q | E) network answered by,weight(F Q E)P (Q E)=,P (E)weight(F E)Q E propositional formulas enforce appropriate values indicator variables correspond known values random variables. denition,function weight computes weighted sum solutions argument. Lemma 2,equal sum probabilities sets assignments satisfyrestrictions Q E E, respectively, turn equal sum entriesjoint probability distribution consistent Q E E, respectively.Sang et al. (2005a) note, weighted model counting approach supports queriesevidence arbitrary propositional form queries supportedexact inference method.WMC1 encoding noisy-OR essentially similar indirect alsogeneral proposal Chavira Darwiche (2005) (see Darwiche, 2009, pp. 313-323detailed exposition proposal). approach proceeds follows: (i) transformnoisy-OR network Bayesian network full CPTs using Pearls decomposition(see Figure 4), (ii) translate network full CPTs CNF using general encoding(see Section 2), (iii) simplify resulting CNF taking advantage determinism.Simplifying resulting CNF proceeds follows. Suppose encodingsentence (Ia Ib ) Pb|a . parameter corresponding Pb|a zero, sentencereplaced (Ia Ib ) Pb|a removed encoding. parameter corresponding Pb|a one, entire sentence removed encoding.Applying method noisy-OR (see Figure 1) results following,745fiLi, Poupart, & van Beek(IX1 Pq1 w1 )(IX1 Pq1 w1 )(IX1 Pq1 w1 )(IX1 Pq1 w1 )...(IXn Pqn wn )(IXn Pqn wn )(IXn Pqn wn )(IXn Pqn wn )(IY(w1 wn ))(IY((w1 wn1 wn )(w1 wn1 wn )...(w1 wn1 wn ))),simplied expression substituting equivalent literals usingfact random variables Boolean (e.g., use IX1 IX1 rather IX1 =0IX1 =1 ). Three dierences noted. First, encoding denitions wiconditional IY true, rather introduced separate clauses. Second,denitions wi succinct. Third, encoding linear numberclauses conditioned IY whereas Chavira et al. encoding 2n 1 clauses.note, however, Chavira, Allen, Darwiche (2005) discuss direct translationnoisy-OR CNF based Pearls decomposition said compactly representnoisy-OR (i.e., exponential number clauses), specic details CNFformula given.4.2 Weighted CNF Encoding 2: Multiplicative EncodingAgain, let causes X1 , . . . , Xn leading eect let noisyOR relation node (see Figure 1), random variables assumedBoolean-valued domains.second weighted model encoding method (WMC2) takes starting point DezGalans (2003) directed auxiliary graph transformation Bayesian networknoisy-OR/MAX relation. Dez Galan note noisy-OR relation, Equation (6)represented product matrices,P (Y = 0 | X)1 0P (Y 0 | X)=.P (Y = 1 | X)1 1P (Y 1 | X)Based factorization, one integrate noisy-OR node regular Bayesiannetwork introducing hidden node noisy-OR node . transformationrst creates graph set nodes arcs original network. Then,node noisy-OR relation, add hidden node domain, add arc , redirect arc Xi Xi , associatefactorization table,746fiExploiting Structure Probabilistic Inference=011=0=1=101.auxiliary graph Bayesian network contains parameters less0. CNF encoding methods general Bayesian networks (see Section 2) cannotapplied here.introduce indicator variables IY IY , indicator variable IXiparent . weights variables follows,weight(IY ) = weight(IY ) = 1,weight(IY ) = weight(IY ) = 1,weight(IXi ) = weight(IXi ) = 1.arc Xi , 1 n, create two parameter variables PX0 ,Y PX1 ,Y .weights variables follows,weight(PX0 ,Y )weight(PX0 ,Y )==1,0,weight(PX1 ,Y )weight(PX1 ,Y )==qi ,1 qi .factorization table, introduce two variables, uY wY , weightsvariables given by,weight(uY )weight(wY )==1,1,weight(uY )weight(wY )==0,2.rst row factorization table, generate clause,(IY IY ),(11)second row, generate clauses,(IY IY uY ) (IY IY wY ).(12)Finally, every parent Xi , generate clauses,(IY IXi PX0 ,Y ) (IY IXi PX1 ,Y ).(13)conjunction clauses; i.e., CNF.Example 8. Consider Bayesian network shown Figure 2 parameters noisy-ORs shown Table 1. auxiliary graph transformation shownFigure 5. WMC2 encoding introduces seven Boolean indicator variables IC , ,, , , ; twelve parameter variables,IM ,NHH0PC,N0PF,N0PM,N1PC,N1PF,N1PM,N0PC,H0PF,H0PM,H7471PC,H1PF,H1PM,H;fiLi, Poupart, & van BeekColdFluMalariaNHNauseaHeadacheFigure 5: Dez Galans (2003) transformation noisy-OR relation appliedBayesian network shown Figure 2.four factorization variables uN , wN , uH , wH . noisy-OR node Nauseaencoded set clauses,uNwN0IC PC,N0PF,N0IM PM,N1IC PC,N1PF,N1IM PM,Nillustrate weighted model counting formula, suppose nausea malariaabsent cold flu present (i.e., Nausea = 0, Malaria = 0, Cold = 1,Flu = 1; corresponding indicator variables IM false ICtrue). formula simplified to,110PC,NPF,N PM,N .(To see this, note clauses evaluate true removed literals evaluatefalse removed clause. result simplifying first clause, forcedfalse removed clauses.) one model formula,model sets conjuncts true. Hence, weighted model count110formula weight(PC,N) weight(PF,N ) weight(PM,N ) = 0.6 0.5 1.0 = 0.3,entry penultimate row full CPT shown Example 2.again, seen WMC2 also easily encode evidence CNFformula; i.e., IY = 0 IY = 1, formula simplied.Example 9. Consider Bayesian network shown Figure 2. illustrateencoding evidence, suppose nausea present (i.e., Nausea = 1) headachepresent (i.e., Headache = 0). WMC2 encoding results following setclauses,748fiExploiting Structure Probabilistic InferenceuNwNIH0IC PC,N0PF,N0IM PM,N1IC PC,N1PF,N1IM PM,N0IC PC,H0PF,H0IM PM,H1IC PC,H1PF,H1IM PM,Hshow correctness encoding WMC2 noisy-OR, rst show entryfull CPT representation noisy-OR relation determined using weightedmodel count encoding. always, let causes X1 , . . . , Xn leadingeect let noisy-OR relation node , random variablesBoolean-valued domains.Lemma 3. entry full CPT representation noisy-OR node , P (Y =| X1 = x1 , . . . , Xn = xn ), determined using weighted model count Equations 1113 created using encoding WMC2.Proof. Let FY encoding noisy-OR node using WMC2 letset assignments indicator variables IY , IX1 , . . . , IXn corresponding desiredentry CPT. Xi = 0, clauses Equation 13 reduce (IY PX0 ,Y ),Xi = 1, clauses reduce (IY PX1 ,Y ). IY = 0, clauses Equations 11& 12 reduce (IY ). Hence,weight(PX0 ,Y ))weight(PX1 ,Y ))weight(FY |s ) = weight(IY )=iTxiTxqiiTx= P (Y = 0 | X),Tx = {i | Xi = 1} P (Y = 0 | X) = 1 Tx empty. IY = 1, clausesEquations 11 & 12 reduce (IY uY ) (IY wY ). Hence,qi +weight(FY |s ) = weight(IY )weight(uY )weight(wY )iTxweight(IY )weight(uY )weight(wY )iTxweight(IY )weight(uY )weight(wY ) +weight(IY )weight(uY )weight(wY )qi= 1iTx= P (Y = 1 | X).749qi +fiLi, Poupart, & van Beekremainder proof correctness encoding WMC2 similarencoding WMC1.Lemma 4. entry joint probability distribution, P (Z1 = z1 , . . . Zn = zn ), represented noisy-OR Bayesian network determined using weighted model countingencoding WMC2.Theorem 2. Given noisy-OR Bayesian network, general queries form P (Q | E)determined using weighted model counting encoding WMC2.5. Ecient Encodings Noisy-MAX CNFsection, present techniques improving weighted model counting approachBayesian networks noisy-MAX relations. particular, present two CNF encodings noisy-MAX relations exploit structure semantics. userunning example Bayesian network shown Figure 2.Let causes X1 , . . . , Xn leading eect let noisy-MAXrelation node (see Figure 1), random variables may multi-valued (nonBoolean) domains. Let dX number values domain random variableX.WMC2 multiplicative encoding extended noisy-MAX introducing indicator variables represent variables multiple values. section,explain extension present two noisy-MAX encodings based two dierentweight denitions parameter variables. two noisy-MAX encodings denotedMAX1 MAX2, respectively. begin presenting parts encodingsMAX1 MAX2 common. WMC2, two noisy-MAX encodings takestarting point Dez Galans (2003) directed auxiliary graph transformationBayesian network noisy-OR/MAX. Dez Galan show noisy-MAXrelation, Equation (6) factorized product matrices,P (Y = | X) =(y, ) P (Y | X)(14)=0dY dY matrix given by,= y,1,(y, ) = 1, = 1,0,otherwise.noisy-MAX node , introduce dY indicator variables IY0 ... IYdY 1 ,represent value domain , d2Y + 1 clauses ensure exactly onevariables true. WMC2, introduce hidden node domain, corresponding indicator variables represent value domain ,clauses ensure exactly one domain value selected model. parentXi , 1 n, , dene indicator variables Ii,x , x = 0, . . . , dXi 1, add750fiExploiting Structure Probabilistic Inferenceclauses ensure exactly one indicator variables corresponding Xitrue. indicator variable negation indicator variable weight 1.Example 10. Consider Bayesian network shown Figure 2 parameters noisy-MAX shown Table 2. node Nausea domain {absent =0, mild = 1, severe = 2} parents Cold, Flu, Malaria Boolean valued,MAX1 MAX2 encodings introduce Boolean indicator variables INa , INm , INs ,, , IC , IC , , , IM , IM . weights variablesINa , INm010101negations 1. Four clauses added indicator variables Nausea,(INa INm INs )(INa INm )(INa INs )(INm INs ).Similar clauses added indicator variables hidden node Nindicator variables parents Cold, Flu, Malaria, respectively.factorization table, introduce two auxiliary variables, uY wY ,weights variables given by,weight(uY )weight(wY )==1,1,weight(uY )weight(wY )factorization table, clause added entryadd (Iy Iy uY )1,(y, ) = 1, add (Iy Iy wY )0,add (Iy Iy uY )==0,2.matrix,= y,= 1,otherwise.Example 11. Consider Bayesian network shown Figure 2 parameters noisy-MAX shown Table 2. Nausea domain {absent = 0, mild= 1, severe = 2}, factorization table MN given by,N = absentN = mildN = severeN = absent110N = mild011N = severe001.Auxiliary variables uN wN introduced following clauses, shown row order,would added factorization table MN ,INa INa uNINm INa wNINs INa uNuNINa INmuNINm INmwNINs INmINa INs uNINm INs uNINs INs uN .completes description parts encodings commonMAX1 MAX2.751fiLi, Poupart, & van Beek5.1 Weighted CNF Encoding 1 Noisy-MAXrst weighted model counting encoding noisy-MAX relations (MAX1) basedadditive denition noisy-MAX. Recall decomposed probabilistic model noisyMAX relation discussed end Section 2.1. shown noisy-MAX,P (Y | X1 , . . . , Xn ) determined using,P (Y | X1 , . . . , Xn ) =nP (Yi | Xi ) =Yi i=1nYi i=1Xi =0Xiqi,Y(15)Xiparameters noisy-MAX, sum conguwhere qi,Yrations possible values Y1 , . . . , Yn , values less equalvalue y. Note outer operator summation; hence, refer MAX1additive encoding. Substituting Equation 14 gives,P (Y = | X1 , . . . , Xn ) ==0nXi(y, )qi,Y.(16)Yi i=1Xi =0equation encode CNF. encoding factorization tablecommon encodings explained above. remains encodecomputation P (Y | X1 , . . . , Xn ).parent Xi , 1 n, introduce dY indicator variables, Ii,y , representeect Xi , 0 dY 1, add clauses ensure exactly oneindicator variables correspond Xi true. Note indicators variablesaddition indicator variables common encodings explained above.always indicator variables, weights Ii,y Ii,y 1.x noisy-MAX, introduce corresponding parameterparameter qi,yxvariable Pi,y . weight parameter variable given by,xx) = qi,yweight(Pi,yxweight(Pi,y)=11 n, 0 dY 1, 1 x dXi 1. relation Xirepresented parameter clauses1 ,x(Ii,x Ii,y ) Pi,y1 n, 0 dY 1, 1 x dXi 1.Example 12. Consider Bayesian network shown Figure 2 parameters noisy-MAX shown Table 2. noisy-MAX node Nausea,encoding introduces indicator variables IC,Na , IC,Nm , IC,Ns , IF,Na , IF,Nm , IF,Ns , IM,Na ,IM,Nm , IM,Ns , weight 1, clauses,1. improve readability, section propositional formulas sometimes written naturalnon-clausal form. continue refer clauses translation clause formstraightforward.752fiExploiting Structure Probabilistic InferenceIC,Na IC,Nm IC,NsIC,Na IC,NmIC,Na IC,NsIC,Nm IC,NsIF,Na IF,Nm IF,NsIF,Na IF,NmIF,Na IF,NsIF,Nm IF,NsIM,Na IM,Nm IM,NsIM,Na IM,NmIM,Na IM,NsIM,Nm IM,Nswell, following parameter variables associated weights would introduced,1) = 0.7weight(PC,N1weight(PC,N) = 0.21weight(PC,Ns ) = 0.11weight(PF,N) = 0.51weight(PF,N) = 0.21weight(PF,Ns ) = 0.31weight(PM,N) = 0.11weight(PM,N) = 0.41weight(PM,Ns ) = 0.5,along following parameter clauses,1(IC1 IC,Na ) PC,N1(IC1 IC,Nm ) PC,N1(IC1 IC,Ns ) PC,N1(IF1 IF,Na ) PF,N1(IF1 IF,Nm ) PF,N1(IF1 IF,Ns ) PF,N1(IM1 IM,Na ) PM,N1(IM1 IM,Nm ) PM,N1(IM1 IM,Ns ) PM,Nremains relate (i) indicator variables, Ii,x , represent valueparent variable Xi , x = 0, . . . , dXi 1; (ii) indicator variables, Ii,y , representeect Xi , = 0, . . . , dY 1; (iii) indicator variables, IY ,represent value hidden variable , = 0, . . . , dY 1. Causal independentclauses dene relation (i) (ii) assert cause Xi absent(Xi = 0), Xi eect ; i.e.,Ii,x0 Ii,y01 n. Value constraint clauses dene relation (ii) (iii)assert hidden variable takes value , eect Xi cannottakes higher degree severe value y; i.e.,IY Ii,Yy1 n, 0 dY 1, < dY 1.Example 13. Consider Bayesian network shown Figure 2 parameters noisy-MAX shown Table 2. noisy-MAX node Nausea,encoding introduces causal independence clauses,IC0 IC,NaIF0 IF,NaIM0 IM,Navalue constraint clauses N = absent,INa IC,NmINa IC,NsINa IF,NmINa IF,NsINa IM,NmINa IM,Nsvalue constraint clauses N = mild,IC,NIF,NINm753IM,NINmfiLi, Poupart, & van Beek5.2 Weighted CNF Encoding 2 Noisy-MAXsecond weighted model counting encoding noisy-MAX relations (MAX2) basedmultiplicative denition noisy-MAX. Equation 5 states P (Y | X1 , . . . , Xn )determined using,nxiqi,y(17)P (Y | X) =.i=1 =0xi =0Note outer operator multiplication; hence refer MAX2 multiplicativeencoding. Substituting Equation 14 gives,P (Y = | X1 , . . . , Xn ) ==0nxi(y, )qi,y.(18)i=1 =0xi =0equation encode CNF. encoding factorization tablecommon encodings explained above. remains encodecomputation P (Y | X1 , . . . , Xn ).x noisy-MAX, introduce corresponding parameterparameter qi,yx . weight parameter variable pre-computes summation Equavariable Pi,ytion 17,xxx)=qi,yweight(Pi,y)=1weight(Pi,y=01 n, 0 dY 1, 1 x dXi 1. relation Xirepresented parameter clauses,x,(Ii,x Iy ) Pi,y0 dY 1 0 x dXi 1.Example 14. Consider Bayesian network shown Figure 2 parameters noisy-MAX shown Table 2. noisy-MAX node Nausea,following parameter variables associated weights would introduced,1) = 0.7weight(PC,N1) = 0.9weight(PC,N1weight(PC,Ns ) = 11weight(PF,N) = 0.51weight(PF,N) = 0.71weight(PF,Ns ) = 11weight(PM,N) = 0.11weight(PM,N) = 0.51weight(PM,Ns ) = 1,along following parameter clauses,1(IC1 INa ) PC,N1) P(IC1 INmC,Nm1(IC1 INs ) PC,N1(IF1 INa ) PF,N1) P(IF1 INmF,Nm1(IF1 INs ) PF,N1(IM1 INa ) PM,N1) P(IM1 INmM,Nm1(IM1 INs ) PM,Nstated far, encoding sucient correctly determining entry fullCPT representation noisy-MAX relation using weighted model counting. However,754fiExploiting Structure Probabilistic Inferenceimprove eciency encoding, add redundant clauses. redundant clauseschange set solutions encoding, thus change weighted modelcount. do, however, increase propagation thus overall speed computationspecial case causes absent. end, noisy-MAX node, introduce auxiliary variable IvY weights given by,weight(IvY )=1,weight(IvY )introduce clauses,nIi,0 (IY0 IvY ),n=0,(IY0 IvY ),Ii,0clauses,nnIi,0(Iy IvY ),Ii,0(Iy IvY ),1 dY 1 1 dY 1.Example 15. Consider Bayesian network shown Figure 2.noisy-MAX node Nausea, auxiliary variable IvN introduced weight(IvN ) = 1weight(IvN ) = 0 along following redundant clauses,(IC0 IF0 IM0 ) (IN IvN )(IC0 IF0 IM0 ) (IN IvN )(IC0 IF0 IM0 ) (IN IvN )(IC0 IF0 IM0 ) (INa IvN )(IC0 IF0 IM0 ) (INm IvN )(IC0 IF0 IM0 ) (INs IvN ).6. Experimental Evaluationsection, empirically evaluate eectiveness encodings. useCachet solver2 experiments one fastest weighted model counting solvers.compare Ace (version 2) (Chavira et al., 2005) Dez Galans (2003)approach using variable elimination.chose compare Ace two reasons. First, Ace well 2008 exactinference competition (no winner declared, Ace performed better classesproblems entries). Second, methods publicly availablewell competition, Smile/GeNIe (Druzdzel, 2005) Cachet using generalencoding full CPT representation, currently take computational advantagenoisy-OR noisy-MAX thus would straw algorithms. strength Acetake advantage local structure determinism specically takesadvantage semantics noisy-OR noisy-MAX speed computation.comparison Ace, revealing, without methodological diculties however(see Section 6.4 discussion).2. http://www.cs.rochester.edu/u/kautz/Cachet/index.htm755fiLi, Poupart, & van Beekchose compare Dez Galans (2003) approach, consists variable elimination applied auxiliary network permits exploitation causal independence, show approach ecient previous proposalsnoisy-MAX. knowledge, work subsequently superseded; i.e.,still state-of-the-art improving variable elimination noisy-MAX exact inference. implementation Dez Galans approach publicly available,implemented ourselves. implementation uses algebraic decision diagrams (ADDs)(Bahar, Frohm, Gaona, Hachtel, Macii, Pardo, & Somenzi, 1993) base data structurerepresent conditional probability tables. Algebraic decision diagrams permit compactrepresentation aggregating identical probability values speed computation exploiting context-specic independence (Boutilier, Friedman, Goldszmidt, & Koller, 1996),taking advantage determinism caching intermediate results avoid duplicate computation. ADDs complicated table based representations, abilityexploit structure often yields speed greater incurred overhead.fact, ADDs currently preferred data structure inference factored partiallyobservable Markov decision processes (Shani, Brafman, Shimony, & Poupart, 2008).variable elimination heuristic used greedy one rst eliminates variablesappear deterministic potentials one variable (this equivalent unit propagation) eliminates variable creates smallest algebraic decision diagramrespect eliminated algebraic decision diagrams. order avoid creatingalgebraic decision diagram variable searching next variable eliminate, size new algebraic decision diagram estimated smallest two upperbounds: (i) cross product domain size variables new algebraic decision diagram (ii) product sizes (e.g., number nodes) eliminatedalgebraic decision diagrams.Good variable ordering heuristics play important role success modern DPLLbased model counting solvers. Here, evaluate two heuristics: Variable State AwareDecaying Sum (VSADS) Tree Decomposition Variable Group Ordering (DTree).VSADS heuristic one current best performing dynamic heuristics designedDPLL-based model counting engines (Sang, Beame, & Kautz, 2005b). viewedscoring system attempts satisfy recent conict clauses also considersnumber occurrences variable time. Compared VSADS heuristic,DTree heuristic (Huang & Darwiche, 2003) described mixed variable orderingheuristic. DTree rst uses binary tree decomposition generate ordered variable groups.decomposition done prior search. order variables within groupdecided dynamically backtracking search using dynamic heuristic.experiments performed Pentium workstation 3GHz hyperthreading CPU 2GB RAM.6.1 Experiment 1: Random Two-Layer Networksrst set experiments, used randomly generated two-layer networks comparetime space eciency WMC1 WMC2 encodings.WMC1 WMC2 encodings answer probabilistic queries using Equation 7. encodings lead quick factorization given evidence encoding.756fiExploiting Structure Probabilistic Inferenceclauses negative evidence represented compactly resulting CNF, evenlarge number parents. WMC2 encoding, positive evidence represented three Boolean variables (see Example 9 illustration variablesdeleted kept case positive evidence), whereas WMC1 encoding requires n Boolean variables, one parent (see Example 7). WMC2encoding, use two parameter variables (PX0 ,Y PX1 ,Y ) represent every arc,WMC1 encoding needs one.Table 3: Binary, two layer, noisy-OR networks 500 diseases 500 symptoms. Eectincreasing amount positive evidence (P+ ) number variables encoding(n), treewidth encoding (width), average time solve (sec.), numberinstances solved within cuto one hour (solv.), test set containedtotal 30 instances. results P+ = 5, . . . , 25 similar resultsP+ = 30 omitted.P+30354045505560n3686371637463776380638363916WMC1width sec.100.2110.61321.41438.81975.322175.224solv.30303030303017n6590660566206635665066656680WMC2width sec.110.1110.2110.5132.0136.11671.016solv.30303030303027Acesec. solv.31.73032.53032.73035.73040.930166.03021random network contains 500 diseases 500 symptoms. symptom sixpossible diseases uniformly distributed disease set. Table 3 shows treewidthencoded CNF WMC1 WMC2 encodings. rst column shows amountpositive evidence symptom variables. remainder evidence variablesnegative symptoms. seen although WMC1 encoding generates fewervariables WMC2 encoding, CNF created WMC2 encoding smallerwidth. probability evidence (PE) computed using tree decomposition guidedvariable ordering (Huang & Darwiche, 2003) results compared Ace3 (adetailed experimental analysis given next experiments).6.2 Experiment 2: QMR-DTsecond set experiments, used Bayesian network called QMR-DT. comparison randomly generated problems, QMR-DT presents real-world inference taskvarious structural sparsity properties. example, empirical distributiondiseases, small proportion symptoms connected large number diseases(see Figure 6).3. http://reasoning.cs.ucla.edu/ace/757fiLi, Poupart, & van BeekNumber symptoms100010010150100150200250300350400450500550Number diseasesFigure 6: Empirical distribution diseases QMR-DT Bayesian network. Approximately 80% symptoms connected less 50 diseases.network used aQMR-DT, anonymized version QMR-DT4 . Symptomvectors k positive symptoms generated experiment. evidencevector, symptom variables sorted ascending order parent (disease)number, rst k variables chosen positive symptoms, remaining symptomvariables set negative. goal method generate instances increasingdiculty.report runtime answer probability evidence (PE) queries. alsoexperimented implementation Quickscore5 , found could solvetest cases shown Figure 7. approach based weighted model counting alsooutperforms variable elimination QMR-DT. model counting time 2560 positivesymptoms, using WMC1 encoding VSADS dynamic variable orderingheuristic, 25 seconds. instance could solved within one hour variableelimination.tested two dierent heuristics encoding: VSADS dynamic variable orderheuristic DTree (Huang & Darwiche, 2003), semi-static tree decomposition-basedheuristic. runtime using encoding DTree heuristic sum two parts:preprocessing time DTree runtime model counting encoding.experiment, DTree faster runtime VSADS model counting process.However, overhead preprocessing large size networks high achieve betteroverall performance.WMC2 encoding generates twice many variables WMC1 encoding. Although WMC2 encoding promising WMC1 encoding smaller size4. http://www.utoronto.ca/morrislab/aQMR.html5. http://www.cs.ubc.ca/ murphyk/Software/BNT/bnt.html758fiExploiting Structure Probabilistic Inference10000Runtime (seconds)1000WMC2 + DTreeWMC1 + DTreeWMC1 + VSADS1001010.120002100220023002400Number positive symptoms25002600Figure 7: QMR-DT Bayesian network 4075 symptoms 570 diseases. Eectamount positive symptoms time answer probability evidencequeries, WMC1 encoding DTree variable ordering heuristic,WMC1 encoding VSADS variable ordering heuristic, WMC2 encodingDTree variable ordering heuristic, Dez Galans (2003) approachusing variable elimination. Ace could solve instances 500positive symptoms within one hour limit runtime.networks (see Table 3), WMC2 encoding less ecient WMC1 encoding.overhead tree decomposition ordering WMC2 encoding also higherWMC1 encoding. results also show dynamic variable orderingwork well WMC2 encoding. Model counting using WMC2 encodingVSADS heuristic cannot solve networks amount positive evidence greater1500 symptoms.experimental results also show approach ecient Ace.example, using Ace, CNF QMR-DT 30 positive symptoms creates 2.8 105variables, 2.8 105 clauses 3.8 105 literals. Also, often requires 1GBmemory nish compilation process. WMC1 encoding, networkevidence create 4.6 104 variables, 4.6 104 clauses 1.1 105 literals.Cachet, weighted model counting engine, needs less 250MB memorycases solve instances. experiments, Ace could solve QMR-DT500 positive symptoms within hour.759fiLi, Poupart, & van Beek6.3 Experiment 3: Random Multi-Layer Networksthird set experiments, used randomly generated multi-layer Bayesian networks.test randomly generated multi-layer networks, constructed set acyclic Bayesiannetworks using method Dez Galan (2003): create n binary variables;randomly select pairs nodes add arcs them, arc addedXi Xj < j; assign noisy-OR distribution noisy-MAX distributionnode parents.160140WMC1 + DTreeWMC1 + VSADSRuntime (seconds)120100806040200300310320330 340 350 360 370Number hidden variables380390400Figure 8: Random noisy-OR Bayesian networks 3000 random variables. Eectnumber hidden variables average time answer probability evidencequeries, WMC1 encoding VSADS variable ordering heuristic,WMC1 encoding DTree variable ordering heuristic, DezGalans (2003) approach using variable elimination.Figure 8 shows eect number hidden variables average timeanswer probability evidence (PE) queries random noisy-OR Bayesian networks.data point average 30 randomly generated instances, instance3000 nodes total.results two layer QMR-DT multiple layer random noisy-OR showaverage, approach based weighted model counting performed signicantlybetter variable elimination signicantly better Ace. approachesbenet large amount evidence, weighted model counting approachexplores determinism eciently dynamic decomposition unit propagation. comparison variable elimination, weighted model counting approach encodeslocal dependencies among parameters evidence clauses/constraints.760fiExploiting Structure Probabilistic Inferencetopological structural features CNF, connectivity, exploreddynamically DPLLs simplication process.Heuristics based primarily conict analysis successfully applied modernSAT solvers. However, Sang, Beame, Kautz (2005b) note model countingoften case conicts parts search treelarge numbers solutions parts heuristic based purely conict analysismake nearly random decisions. Sang et al.s (2005b) VSADS heuristic, combinesconict analysis literal counting, avoids pitfall seen workwell large Bayesian networks large amounts evidence. DTree also goodchoice due divide-and-conquer nature. However, use DTree decomposeCNF generated QMR-DT, usually rst variable group contains 500disease variables. well, overhead preprocessing aects overall eciencyapproach.1000ACEMAX1MAX2Runtime (seconds)1001010.10.01200250300350400450500550600650Number arcsFigure 9: Random noisy-MAX Bayesian networks 100 ve-valued random variables.Eect number arcs average time answer probability evidence queries,MAX1 encoding noisy-MAX, MAX2 encoding noisy-MAX,Chavira, Allen, Darwiches Ace (2005).Similarly, performed experiment 100 ve-valued random variables. Figure 9shows eect number arcs average time answer probability evidence(PE) queries random noisy-MAX Bayesian networks. data point average50 randomly generated instances. seen instances CNFencoding MAX2 performs encoding MAX1 signicantly outperforms Chavira,Allen, Darwiches Ace (2005). recognized noisy-MAX relations,multiplicative factorization signicant advantages additive factorization(Takikawa & DAmbrosio, 1999; Dez & Galan, 2003). Hence, one would expect761fiLi, Poupart, & van BeekCNF encoding based multiplicative factorization (encoding MAX2) would performbetter CNF encoding based additive factorization (encoding MAX1).primary disadvantage encoding MAX1 must encode CNF summingcongurations. result, MAX1 generates much larger CNFs MAX2, includingvariables clauses. encoding MAX2, weight parameter variablerepresents maximum eect cause hence minimizes add computations.6.4 Discussionexperimentally evaluated four SAT encodingsWMC1 WMC2 noisy-ORMAX1 MAX2 noisy-MAXon variety Bayesian networks using Cachetweighted modeling counting solver. WMC1 MAX1 encodings characterizedadditive encodings WMC2 MAX2 encodings multiplicative encodings.experiments, multiplicative encodings gave SAT instances smaller treewidth.noisy-OR, additive encoding (WMC1) gave smaller SAT instances multiplicative encoding (WMC2). noisy-MAX, reverse additive encoding(MAX1) gave larger SAT instances multiplicative encoding (MAX2). regards speedups, experiments noisy-OR, results mixedencoding better; sometimes WMC1 times WMC2. experimentsnoisy-MAX, results suggest multiplicative encoding (MAX2) better.reduced treewidth reduced size MAX2 encoding important,WMC2 able solve many instances.also compared Dez Galans (2003) approach using variable elimination(hereafter, D&G) Ace (Chavira et al., 2005). experiments, approachdominated D&G Ace speedups three orders magnitude. well,approach could solve many instances D&G Ace could solve withinresource limits. However, results interpreted care least threereasons. First, well known eciency variable elimination sensitivevariable elimination heuristic used implemented.careful optimize implementation use high-quality heuristic, stillpossibility dierent implementation dierent heuristic would lead dierentresults. Second, Cachet, based search, designed answer single queryexperiments based answering single query. However, Ace uses compilationstrategy designed answer multiple queries eciently. compilation steptake considerable number resources (both time space) payoexperimental design. Third, although Ace viewed weighted model countingsolver, comparing encodings experiments. Chavira Darwiche(2008) note, Cachet Ace dier many ways including using dierent methodsdecomposition, variable splitting, caching. well, Ace uses optimizationsCachet not, including encoding equal parameters, eclauses (a succinct way encodingone literal true disjunction), structured resolution. (We refer readerChavira & Darwiche, 2008 experimental comparison search compilation,extensive discussion diculty comparing two approachesadvantages disadvantages.) Nevertheless, experiments demonstrated instancesnoisy-OR networks (see Figure 7) noisy-MAX networks (see Figure 9) could762fiExploiting Structure Probabilistic Inferencesolved D&G Ace within resource limits, could solved quitequickly Cachet using encodings.7. Conclusions Future WorkLarge graphical models, QMR-DT, often intractable exact inferencelarge amount positive evidence. presented time space ecient CNFencodings noisy-OR/MAX relations. also explored alternative search ordering heuristics DPLL-based backtracking algorithm encodings. experiments,showed together techniques extend model counting approach exact inference networks previously intractable approach. well,experimental results must interpreted care comparingencodings also implementations systems conicting design goals,benchmarks techniques gave speedups three orders magnitude bestprevious approaches scaled larger instances. Future work could include developing specic CNF encodings causal independence relations (see Koller & Friedman,2009, pp. 175185).Acknowledgmentspreliminary version paper appeared as: Wei Li, Pascal Poupart, Peter vanBeek. Exploiting Causal Independence Using Weighted Model Counting. Proceedings23rd AAAI Conference Artificial Intelligence, pages 337343, 2008. authorswish thank anonymous referees helpful comments.ReferencesBacchus, F., Dalmao, S., & Pitassi, T. (2003). DPLL caching: new algorithm#SAT Bayesian inference. Electronic Colloquium Computational Complexity,10 (3).Bahar, R. I., Frohm, E. A., Gaona, C. M., Hachtel, G. D., Macii, E., Pardo, A., & Somenzi,F. (1993). Algebraic decision diagrams applications. Proceedings1993 IEEE/ACM International Conference Computer-Aided Design (ICCAD-93),pp. 188191.Boutilier, C., Friedman, N., Goldszmidt, M., & Koller, D. (1996). Context-specic independence Bayesian networks. Proceedings Twelfth Conference UncertaintyArtificial Intelligence (UAI-96), pp. 115123.Chavira, M., Allen, D., & Darwiche, A. (2005). Exploiting evidence probabilistic inference. Proceedings 21st Conference Uncertainty Artificial Intelligence(UAI-05), pp. 112119.Chavira, M., & Darwiche, A. (2005). Compiling Bayesian networks local structure.Proceedings Nineteenth International Joint Conference Artificial Intelligence(IJCAI-05), pp. 13061312.763fiLi, Poupart, & van BeekChavira, M., & Darwiche, A. (2008). probabilistic inference weighted model counting.Artificial Intelligence, 172 (6-7), 772799.DAmbrosio, B. (1994). Symbolic probabilistic inference large BN2O networks. Proceedings Tenth Conference Uncertainty Artificial Intelligence (UAI-94),pp. 128135.Darwiche, A. (2009). Modeling Reasoning Bayesian Networks. Cambridge.Darwiche, A. (2002). logical approach factoring belief networks. ProceedingsEighth International Conference Principles Knowledge RepresentationReasoning (KR-02), pp. 409420.Davis, M., Logemann, G., & Loveland, D. (1962). machine program theorem proving.Communications ACM, 5 (7), 394397.Davis, M., & Putnam, H. (1960). computing procedure quantication theory. J.ACM, 7 (3), 201215.Dez, F. J. (1993). Parameter adjustement Bayes networks. generalized noisy ORgate. Proceedings Ninth Conference Uncertainty Artificial Intelligence(UAI-93), pp. 99105.Dez, F. J., & Druzdzel, M. J. (2006). Canonical probabilistic models knowledge engineering. Tech. rep. CISIAD-06-01, UNED, Madrid.Dez, F. J., & Galan, S. F. (2003). Ecient computation noisy MAX. InternationalJ. Intelligent Systems, 18, 165177.Druzdzel, M. J. (2005). Intelligent decision support systems based SMILE. Software 2.0,2, 1233.Good, I. J. (1961). causal calculus. British Journal Philosophy Science,12 (45), 4351.Heckerman, D. (1989). tractable inference algorithm diagnosing multiple diseases.Proceedings Fifth Conference Uncertainty Artificial Intelligence (UAI-89),pp. 163172.Heckerman, D., & Breese, J. (1996). Causal independence probability assessmentinference using Bayesian networks. IEEE, Systems, Man, Cyber., 26, 826831.Heckerman, D. (1993). Causal independence knowledge acquisition inference.Proceedings Ninth Conference Uncertainty Artificial Intelligence (UAI93).Henrion, M. (1987). practical issues constructing belief networks. ProceedingsThird Conference Uncertainty Artificial Intelligence (UAI-87), pp. 132139.Huang, J., & Darwiche, A. (2003). structure-based variable ordering heuristic SAT.Proceedings Eighteenth International Joint Conference Artificial Intelligence(IJCAI-03), pp. 11671172.Koller, D., & Friedman, N. (2009). Probabilistic Graphical Models: Principles Techniques. MIT Press.764fiExploiting Structure Probabilistic InferenceLittman, M. L. (1999). Initial experiments stochastic satisability. ProceedingsSixteenth National Conference Artificial Intelligence (AAAI-99) (Orlando, Florida,United States edition)., pp. 667672.Miller, R. A., Masarie, F. E., & Myers, J. D. (1986). Quick medical reference diagnosticassistance. Medical Computing, 3, 3448.Olesen, K. G., Kjaerul, U., Jensen, F., Jensen, F. V., Falck, B., Andreassen, S., & Andersen,S. K. (1989). MUNIN network median nerve: case study loops. Appl.Artificial Intelligence, 3 (2-3), 385403.Parker, R., & Miller, R. (1987). Using causal knowledge create simulated patient cases:CPCS project extension INTERNIST-1. 11th Symposium Computer Applications Medical Care, pp. 473480.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference. Morgan Kaufmann.Sang, T., Bacchus, F., Beame, P., Kautz, H., & Pitassi, T. (2004). Combining componentcaching clause learning eective model counting. Proceedings 7thInternational Conference Theory Applications Satisfiability Testing (SAT04).Sang, T., Beame, P., & Kautz, H. (2005a). Solving Bayesian networks weighted modelcounting. Proceedings Twentieth National Conference Artificial Intelligence (AAAI-05), pp. 110.Sang, T., Beame, P., & Kautz, H. A. (2005b). Heuristics fast exact model counting..Proceedings 8th International Conference Theory ApplicationsSatisfiability Testing (SAT-05), pp. 226240.Shani, G., Brafman, R. I., Shimony, S. E., & Poupart, P. (2008). Ecient ADD operationspoint-based algorithms. Proceedings Eighteenth International ConferenceAutomated Planning Scheduling (ICAPS-08), pp. 330337.Takikawa, M., & DAmbrosio, B. (1999). Multiplicative factorization noisy-MAX.Proceedings Fifteenth Conference Uncertainty Artificial Intelligence (UAI99), pp. 622630.Zagorecki, A., & Druzdzel, M. J. (1992). Knowledge engineering Bayesian networks:common noisy-MAX distributions practice?. Proceedings 10thEuropean Conference Artificial Intelligence (ECAI-92), pp. 482489.Zhang, N. L., & Poole, D. (1996). Exploiting causal independence Bayesian networkinference. J. Artificial Intelligence Research, 5, 301328.765fiJournal Artificial Intelligence Research 40 (2011) 677-700Submitted 09/10; published 03/11Identifying Aspects Web-Search QueriesFei WuJayant MadhavanAlon Halevywufei@google.comjayant@google.comhalevy@google.comGoogle Inc, 1600 Amphitheatre Pkwy,Mountain View, CA 94043 USAAbstractMany web-search queries serve beginning exploration unknown spaceinformation, rather looking specic web page. answer queries eectively, search engine attempt organize space relevant informationway facilitates exploration.describe Aspector system computes aspects given query.aspect set search queries together represent distinct information need relevantoriginal search query. serve eective means explore space, Aspectorcomputes aspects orthogonal high combined coverage.Aspector combines two sources information compute aspects. discovercandidate aspects analyzing query logs, cluster eliminate redundancies.use mass-collaboration knowledge base (e.g., Wikipedia) compute candidateaspects queries occur less frequently group together aspects likelysemantically related. present user study indicates aspectscompute rated favorably three competing alternatives related searchesproposed Google, cluster labels assigned Clusty search engine, navigationalsearches proposed Bing.1. IntroductionWeb-search engines today predominantly answer queries simple ranked list results.method successful, relies assumption users information need satised single page Web. However, several studies (Broder,2002; Rose & Levinson, 2004) alluded fact many user queries merelybeginning exploration unknown space information. queries likelybetter served users provided summary relevant information spacemeans conveniently exploring it. paraphrase, rather nding needlehaystack, queries would benet summarizing haystack (Rajaraman,2008). Several commercial attempts recently made provide better answersqueries, including systmes like Carrot2, Clusty, Kosmix, Yahoo!Glue.paper describes Aspector system addresses following problem: givenexploratory search query q, compute set aspects enables convenient explorationWeb content relevant q. dene aspect set searchqueries together represent distinct information need relevant original searchquery, similar Wangs denition Latent Query Aspect (Wang, Chakrabarti, & Punera,2009). example, consider queries Table 1 potential aspects.aspect covers dierent kind information together span large amountc2011AI Access Foundation. rights reserved.fiWu, Madhavan, & Halevyvietnam traveltravel guidespackages / agenciesvisablogs / forumstravel advisoriesweathercities (Hanoi / Saigon /...)kobe bryantstatisticspictures / photosvideos / youtubeshoesinjury reportsgirlfriendtrade rumorsTable 1: Potential aspects queries vietnam travel kobe bryant.relevant information search engine users might interested in. Two simple wayssearch engine utilize aspects oer related searches categorize searchresults aspects relevant to. Aspects also form basis variousmashup-like interfaces, e.g., aspect pictures trigger inclusion images,weather trigger weather report gadget. Computing aspects queries seenrst step towards mining knowledge base, called database user intentions (Battelle,2005). knowledge base timely culture-sensitive expression peoples interests.Inferring knowledge base entities serve basis eective presentationinformation, therefore signicant ramications search, advertisinginformation dissemination.Aspector computes aspects query q using search-engine query log, augmentedinformation knowledge base created mass-collaboration (Wikipedia). Givenquery q, related queries extracted query log candidate aspects.logs excellent mirror users interests, also result noisy redundantaspects, e.g., top related queries vietnam travel include vietnam visa vietnam travelvisa. Furthermore, query logs limited utility generating aspects less popularqueries, e.g., much fewer related queries laos travel vietnam travel.describe following algorithmic innovations address challenges. First, showredundant candidate aspects removed using search results. Second, applyclass-based label propagation bipartite graph compute high-quality aspects evenlong tail less popular queries. Finally, show knowledge bases usedgroup candidate aspects categories represent single information need. believesolution demonstrates interesting interplay query logs knowledgebases yet investigated research literature.describe detailed experimental evaluation Aspector. compare aspectsgenerated Aspector three possible competing approaches related searchesproposed Google.com, cluster labels proposed Clusty.com, navigational searchesproposed Bing.com. Related searches navigational searches typically also generated analysis query logs. Cluster labels generated grouping searchresults original query extracting labels documents within cluster.show aspects diverse three systems. also showaspects span larger space information expose resultsoriginal query, additional results considered highly relevant users.678fiIdentifying Aspects Web-Search Queriesuser study nds results Aspector preferred related searches, clusterlabels navigational searches means exploration.Section 2 denes problem computing aspects, Section 3 considers potential alternative approaches. Section 4 describes generation candidate aspects, Section 5describes Aspector selects aspects candidates. Section 6 describes experimental evaluation,and Section 7 describes related work. Section 8 concludes.2. Problem Definitionbegin dening scope problem address.Queries: assume queries sequence keywords, typical searchengine interfaces. techniques meant apply arbitrary queries. focusexploratory queries, specically, assume either entity names (e.g.,country Vietnam) entity property name (e.g., Vietnam travel). Thus,interested computing aspects entities general context particularproperty.paper handle problem segmenting entity property namesqueries (previous work, Bergsma & Wang, 2007; Tan & Peng, 2008, addressedproblem). question identifying exploratory queries query stream alsobeyond scope paper.Aspects: aspect query q meant describe particular sense q corresponding information need. Specically, aspect represented collectionsearch queries related q. Given q, compute set aspects a1 , . . . , , alongscores p(ai |q) used rank them.Since aspects collections search queries, compare aspects based searchresults retrieved queries constitute them. Aspects meant capture diversedimensions along organize exploration entire space informationrelevant query. Hence, set aspects computed queryfollowing properties:Orthogonality: given two aspects, a1 a2 , search results a1 a2dierent other.Coverage: search results provided aspects oer good overviewrelevant space information.Thus, two sets aspects computed query compared basedpairwise orthogonality constituent aspects combined coverageaspects. evaluation aspects inherently subjective, typical area websearch. Hence, present user studies aspects computed dierent approachesqualitatively rated large number independent users. notecompare dierent approaches computing aspects, focus dierent wayspresented users.3. Alternative Approachesdescribe Aspector generates aspects, briey mention two strawmanapproaches problem explain insucient needs.679fiWu, Madhavan, & HalevyClassNBA PlayerUniversityWikipediabirth datepositionbirth placecollegenationality height(ft)draft yeardraftcareer start height(in)namecityestablishedwebsitecountrytypecampusstateundergradmottoQuery Loginjurypicturesnbawallpaperbiosalaryshoesgirlfriendstatsbiographylibrary basketballfootballathleticsalumni admissionstuitionbaseballjobsbookstoreTable 2: Two classes attributes Wikipedia dierent classlevel aspects computed query log.3.1 Community-Created Knowledge BasesKnowledge bases, especially created large community contributors,rich source information popular entities. cover wide spectrum userinterests potentially used organize information relevant search queries.particular, properties Infoboxes Wikipedia articles potentially usedcandidate aspects. Wikipedia contains 3,500 classes 1 million entitiesclass average 10 attributes. Wikipedia column Table 2 showsattributes two example classes. Freebase another community-created KB1,500 classes.Binary relationships recorded knowledge base fall signicantly short providinggood set aspects query. example, consider properties associatedCambodia Wikipedia Infobox capital, flag, population, GDP, etc. Nonewords appear top-10 frequent queries contain word cambodia. addition,knowledge base limited describing well dened entities. example, Cambodiaentity knowledge base, Cambodia Travel not. However, queries Web covermuch well dened entities.underlying reason knowledge bases fall short constructors chooseattributes based traditional design principles, good aspects followprinciples. example, turns cambodia travel good aspect vietnam travel,many people consider side trip Cambodia visiting Vietnam. However,designing knowledge base, Cambodia would never attribute Vietnam.Instead, knowledge base would assert Vietnam Cambodia neighbors,include rule states X next Y, X travel may aspecttravel. Unfortunately, coming rules specifying precise preconditionsformidable task highly dependent instances applies to. example,pakistan travel aspect india travel, even though two countries neighbors.680fiIdentifying Aspects Web-Search Queries3.2 Web DocumentsAnother approach nding aspects cluster documents Web relevantquery q, assign extract labels cluster (Blei, Ng, & Jordan, 2003; Zeng,He, Chen, Ma, & Ma, 2004). show experiments, main disadvantagecoverage resulting aspects may low approach considersdocuments returned response original query. practice, users conductdata exploration sessions queries, queries sessions also leadinteresting aspects might found among results original query.Furthermore, challenging generate succinct names aspectscluster.4. Generating Candidate AspectsAspector generates candidate aspects query logs. Query logs reectivebroad range user interests, less eective generating aspects infrequentqueries. rst describe generate instance-level aspects, augmentclass-based aspect propagation using knowledge base.4.1 Instance-Level Candidate AspectsGiven query q, start considering query renements super-stringscandidate aspect.4.1.1 Query Refinementsquery qj renement q, user poses qj q performing single searchtask. Query logs mined identify popular renements individual queries. Searchengines typically use popular renements basis proposing related searches.process renements follows: rst, query log segmented sessions representing sequences queries issued user single search task. Suppose fs (q, qj )number sessions query qj occurs q, estimate renementscore pr qj normalizing fs (q, qj ) possible renements, i.e.,fs (q, qj )pr (qj |q) =fs (q, qi )Observe proposing related searches based query renements is, principle,optimized towards goal helping users nd single page containing specic answer(rather helping user explore space). example, top 10 renementsquery NBA player yao ming includes 6 NBA players kobe bryantmichael jordan. Though related, renements necessarily best aspectsquery.4.1.2 Query Super-Stringsquery qj super-string q includes q sub-string. example, vietnamtravel package super-string vietnam travel. Unlike renement, super-string qj need681fiWu, Madhavan, & Halevybelong session q. fact, random selection 10 popular queries,found average overlap 1.7 top 10 renementstop 10 super-strings. sense, super-strings explicitly related queriesrenements implicitly related.Super-strings assigned scores similar pr above, mimicking super-stringpseudo-renement, i.e., assume imaginary session q preceded superstring qj . Suppose f (qj ) number occurrences qj query logs, estimatesuper-string score pss (qj |q) 1 :pss (qj |q) =f (qj )f (q) + f (qi )Aspector considers renements super-strings q candidate aspectsassigns single instance-level aspect score. candidate aspect qj , assignscore pinst follows:pinst (qj |q) = max(pr (qj |q), pss (qj |q))given q, normalize pinst (qj |q)s add 1.4.2 Class-Based Aspect PropagationQuery-log analysis ineective generating instance-level candidate aspects less frequent queries. example, generate good candidate aspects vietnam travel,laos travel. However, recommend aspects common travelmany countries Laos. use variation label-propagation algorithm namedAdsorption (Baluja, Seth, Sivakumar, Jing, Yagnik, Kumar, Ravichandran, & Aly, 2008).rst apply query segmentation extract entity e (laos example)property p (travel) query q. Next, use knowledge base (e.g., WikipediaInfobox) identify class, classes, C e (e.g., country south-east asian countrylaos). construct directed bipartite graph G = (V, E, ) shown Figure 1.nodes left instance-level query nodes laos travel, rightclass-level nodes like country travel. E denotes set edges, : E Rdenotes nonnegative weight function. set weights edges instance nodesclass nodes 1, weights edges class nodes instance nodes K,design parameter controlling relative-importance two factors. goalcompute p(qj |q), aspect distribution node q.Following work Baluja et al. (2008), nodes aspect distribution iterativelyupdated linear combination neighbors, converge (this algorithmshown equivalent performing random walk graph). Since use WikipediaInfobox knowledge base, instance belongs single class, two iterationsguaranteed achieve convergence. rst iteration computes class-level aspectsfollows:1pinst (qj |q)pclass (qj |q) =|C| qC1. use conservative lower bound estimate. corresponding upper bound pss (qj |q) =exceed 1.682f (qj )f (q)fiIdentifying Aspects Web-Search QueriesInstancesClassesvietnam travelsoutheast asia travellaos travelcountry travelcanada travel......Figure 1: bipartite graph class-based aspect propagation.second iteration smoothes aspect distribution instance node q pclass (qj |q)follows,pinst (qj |q) + K pclass (qj |q)(1)1+KSection 6 tested eect K performance Aspector. experiments found following variation computing class-level aspects leadsslightly better results:p(qj |q) =pclass (qj |q) =1I(pinst (qj |q) > 0))|C| qCwhere, I(pinst (qj |q) > 0)) = 1 pinst (qj |q) > 0, 0 otherwise.Table 2 shows examples top class-level aspects derived two classes comparescorresponding top attributes Wikipedia infobox. seetwo sets aspects little overlap, illustrates community createdschemata fall signicantly short providing good set aspects search queries.5. Selecting Aspectssection describes Aspector prunes set candidate aspects, groups them,eventually ranks ordered list subset selected.5.1 Eliminating Duplicate Aspectsoften case generated aspect list contains similar candidates mayconsidered redundant. example, top candidate aspects query vietnam travelinclude vietnam travel package, vietnam travel packages vietnam travel deal,represent either identical similar user intents. particular, note setweb documents returned aspects search engine likelysimilar.remove redundant aspects, compute similarity matrix, {sim(ai , aj )},every pair candidate aspects cluster based similarity.5.1.1 Computing Aspect SimilaritySince aspects contain words, estimating similarity based simple comparison words unlikely accurate. Therefore, enrich representation683fiWu, Madhavan, & Halevyaspect considering top m2 search results returned posing aspect searchquery. consistent goal enabling orthogonal exploration aspectssimilar top results unlikely orthogonal.Let Di top web pages retrieved aspect ai . estimate similarity aiaj similarity corresponding sets Di Dj . compute sim(Di , Dj ),rst compute similarity dsim given pair web pages {di Di , dj Dj }.use standard cosine distance TF/IDF word-vectors twodocuments. computational eciency, consider head snippetweb page instead entire text contents3 .sim(Di , Dj ) potentially estimated averaging similarities dsim(di , dj )pairs web pages, experiment dataset, found better instead computeaverage highest similarity web page. di Di , assign score:sim(di , Dj ) = maxk dsim(di , dk ). Likewise, assign sim(Di , dj ) = maxk dsim(dk , dj ).nal aspect similarity computed as:sim(ai , aj ) = sim(Di , Dj ) =sim(di , Dj )2|Di |+jsim(dj , Di )2|Dj |could alternatively treat Di one single document concatenating {diDi } estimate sim(qi , qj ) corresponding dsim(Di , Dj ). computationallyecient, quality aspects poorer.5.1.2 Clustering Aspectsprinciple, apply clustering algorithm, K-means spectral clustering,resulting aspect similarity matrix. However, algorithms often require pre-settingnumber desired clusters, dicult context. addition, numberclusters also varies signicantly one query another. Note appropriatenumber clusters necessarily number resulting aspects showuser.instead apply graph-partition algorithm clustering. algorithm proceedscreating graph nodes aspects, ai , edge connecting nodesai aj sim(ai , aj ) > , pre-dened threshold. connected subgraphs treated cluster. choose label cluster aspect akhighest p(ak |q) cluster (Formula 1).design parameter easier set pretty stable dierent queries,shown experiments. note similar algorithms star-clustering (Aslam,Pelekov, & Rus, 2004) also used.5.2 Grouping Aspects Vertical Categorymany cases, even eliminating redundant aspects, nd leftaspects seemingly dierent, semantically grouped single category.example, query vietnam travel, top non-redundant candidate aspects2. use = 8 experiments performs well. Larger might achieve slightly better performance cost heavier computation.3. also tired using whole document web page, slightly better performance.684fiIdentifying Aspects Web-Search Queriesho chi minh city, hanoi da nang. dierent cities, principlelikely represent single information need nding information citiesVietnam. Further, given budget xed number aspects presenteduser, might make sense overwhelm list aspects denoting citiesVietnam. Instead, single aspect named Cities presented.community-created knowledge bases leveraged Aspectortries identify sets related aspects consulting Wikipedia Infobox system4 .nds multiple aspects contain dierent entities belong class Wikipedia,creates aggregate aspect (with label class) groups together.encounter two challenges looking Wikipedia classes entities.First, entity appear dierent synonymous tokens. example, nyucommon acronym new york university. Currently use redirect pages Wikipediainfer synonyms. Redirect pages Wikipedia point synonym terms principalarticle. result, aspect nyu query yale university grouped harvarduniversity oxford university5 . Second, token refer multiple entitiesbelong dierent classes lead bad grouping decisions. example, HIStoryFOOD names music albums Wikipedia, history food alsoaspects query vietnam. simple lookup tokens Wikipedia might leaderroneously grouping single album group. Aspector uses disambiguationpages Wikipedia identify tokens likely multiple senses. Infoboxclass retrieved entities disambiguation pages. conservativemethod improved via collaborative classication (Meesookho, Narayanan, &Raghavendra, 2002). example, earth, moon venus aspects mars. Sinceambiguous based Wikipedia, current Aspector would treatindividual aspects. However, possible group together single planet aspect,given three candidates planet one possible type.5.3 Selecting Aspectsnal step Aspector selecting aspects. note absolute rankingaspects important context, expect search resultsaspects spread screen rather presented single list. However,still need select top-k aspects present. selection top-k aspects basedoriginal goals increasing coverage guaranteeing orthogonality.Aspector uses score aspect, p(ai |q), measure coverage. achievebalance coverage orthogonality, Aspector uses greedy algorithmselects aspects ratio score p(ai |q) similarity aspects alreadyselected aspects. algorithm produces ranked list aspects, G.4. ontologies like Freebase Yago also used.5. trick used constructing bipartite graph Section 4.2 well.685fiWu, Madhavan, & HalevyInput: Set = {ai }Output: Set G// Label aspects clusters de-duplication.// Ranked list aspects.Initialization: G = ;a0 = argmaxai p(ai |q);move a0 G;(S = )aiset sim(ai , G) = maxaj G sim(ai , aj );p(ai |q);anext = argmaxai Sim(a,G)move anext G;Algorithm 1: Aspector selects top-k aspects balancing coverage orthogonality.Observe set similarity sim(ai , G) maximum similarity aiaspects already G. termination, Aspector returns top n aspects ranked order(in experiments used n = 8). experiments indicate balancing coverageorthoganality leads better selection aspects simply using coverage.6. Experimentssection evaluate system Aspector particular, answer followingquestions.Quality aspects: compare results Aspector three potentialcompeting systems related searches proposed Google (henceforth Grs), cluster labelsassigned Clusty search engine (Ccl), navigational searches proposed Bing(Bns). better support exploration dierent parts space relevant information,aspects query orthogonal other. Aspects also increasecoverage, i.e., reveal information already available original query,still relevant it. Using combination search result analysis userstudy, show aspects less similar (and hence orthogonal)(Section 6.3), aspects able increase coverage (Section 6.4), aspectsoverall rated favorably Grs, Ccl, Bns (Section 6.5).Contributions dierent components: Aspector generates instance-levelaspects performs class-based aspect propagation, eliminates duplicates, groupsremaining ones using knowledge base. show instance-level class-level aspectstend dierent, best results obtained judiciously combining(Section 6.6). also show clustering algorithm able stably eliminateduplicate aspects crossing dierent domains, grouping aspects positiveimpact quality aspects (Section 6.7).6.1 Experimental Settingcompute candidate aspects query logs, used three months worth anonymizedsearch logs Google.com. used snapshot English version (2008.07.24)Wikipedia Infobox serve knowledge base. Unless otherwise mentioned, used686fiIdentifying Aspects Web-Search QueriesK = 0.1 class-based aspect propagation (Equation 1). describe test suiteuser study.Test Queries: focus queries entity names entity nameproperty name. construct test suite contains 6 sets queries: entitynames Wikipedia classes Country, NBA player, Company, Mountain, University,one entity-property queries form Country travel. construct mixpopular rare queries, six sets select 5 queries occur frequentlyquery stream, 5 relatively uncommon, 5 chosen randomly class(as long appear query logs). Thus, total 90 test queries.experiment used random subset test queries.User Study: part experimental analysis, performed user studies usingAmazon Mechanical Turk (Amt) system. Amt, requesters (like us) post tasks payanonymous registered workers respond them. Tasks structured sequencequestions workers expected respond per instructions providedrequester. example, compare two algorithms compute aspects, designsequence tasks query two lists aspects (computedalgorithm) shown. worker rate whether one list bettersimilar. Amt ensures worker respond task once.Since, workers user study completely unknown requester, lesschance bias. Amt shown eective ecient way collect datavarious research purposes (Snow, OConnor, Jurafsky, & Ng, 2008; Su, Pavlov, Chow, &Baker, 2007). experiments, used default qualication requirement workersrequires worker HIT approval rate (%) greater equal 95.6.2 Points ComparisonGrs considered representative current approaches based miningrenements super-strings query logs. likely Grs performsinstance-level analysis attempt identify distinct user information needs.Ccl clusters result pages assigns human-understandable labels cluster.notably, clusters determined purely results original query,attempt enable exploration results retrieved query. Further,likely cluster labels extracted analysis contents result pages(web documents). note clustering hierarchical, experimentsconsidered top-level labels.Bns provides navigation searches (right Related searches result pages)help users better explore information space. Bings goal closest spirit,technique applies narrow set domains. note Bns sometimesprovides generic aspects (e.g., videos, images), consider those.note neither Grs Ccl designed explicit goal computingaspects help explore information space relevant query. However,viewed close alternatives terms results may produce, therefore oertwo points comparison.Table 3 shows aspects, related searches, cluster labels, navigational searchesobtained four systems example queries. rest section,687fiWu, Madhavan, & HalevyQueryMount ShastaYale UniversityGrsvolcanonational parkclimbingvortexcampinghotelsattractionslodgingharvard universityathleticspressbrown universitystanford universitycolumbia universitycornell universityduke universityCclphotoshotelsreal estateweedwilderness, californiaclimbingweather, forecastskischooldepartmentlibraryimagespublicationsadmissionslaboratoryalumniBnsimageweatherreal estatehotelslodgingrentalsreference/wikipediaadmissionsjobsbookstorealumnilibraryreference/wikipediaimagesAspectorresortweatherhigh schoolreal estatehikingpictures (photos)mapski areapressart galleryathleticsharvard (oxford, stanford,...)jobsbookstoreadmissionstuitionTable 3: Sample output Grs, Ccl, Bns, Aspector.rst show aspects Aspector average orthogonal, increase coverage,rated better overall Grs, Ccl Bns.6.3 Orthogonality Aspectsestablish orthogonality aspects, measure inter-aspect similarity lesssimilar aspects are, orthogonal are. rst describe computeinter-aspect similarity, report values query set Aspector, Grs,Ccl, Bns.Section 5, used TF/IDF-based word vectors estimate aspect similarity. Usingmeasure establish orthogonality bias evaluation favor Aspector.Hence, use alternate measure aspect similarity employs topic model (Bleiet al., 2003). Briey, topic models built learning probability distributionwords documents topics might underlie document. Given text fragment,topic model used predict probability distribution topics relevantfragment. example, text company page Google Inc., might resulttopic distribution search engine, 0.15, online business, 0.08, . . .. use topicmodel developed internally Google (henceforth TMG). Given two text fragments t1t2 , compute topic similarity tsim(t1 , t2 ) cosine distancetopic distribution vectors T1 T2 .Since aspects contain words, extend augmenting aspectcorresponding top search results (as Section 5). Given aspects a1 a2 , let D1D2 respective top web search results. compare D1 D2 using TMGestimate aspect similarity. Specically, compute average inter-document similarity.sim(a1 , a2 ) =1k2di D1 ,dj D2688tsim(di , dj )(2)fiIdentifying Aspects Web-Search QueriesNormalized Inter-aspect SimilarityAspect Similarity Comparison0.060.040.020AspectorBNSCCLGRSFigure 2: results Aspector orthogonal Grs, Ccl, Bns.Given A, set n aspects, determine inter-aspect similarity (asim) averagepair-wise aspect similarity.asim(A) =2sim(ai , aj )n(n 1) ,ajorder make sense magnitude asim, normalize using average intraaspect similarity isim(A) obtained comparing aspect itself.isim(A) =1sim(ai , ai )|A|Note, sim(ai , ai ) ususally equal 1 based equation 2. result normalizedinter-aspect similarity nsim.nsim(A) =asim(A)isim(A)Thus, aspects identical, nsim(A) = 1, entirely orthogonalnsim(A) = 0.query, retrieved number aspects (at 8) system,Figure 2 shows average normalized inter-aspect similarity results outputsystem.clearly seen, Aspector least normalized inter-aspect similarityhence orthogonal aspects. improvement Bns (45%) likely duegrouping related aspects vertical category. improvement Grs (90%)likely due inclusion class-based aspects grouping related aspectsvertical category. improvement Ccl (60%) likely space labelsrestricted results returned original query.689fiWu, Madhavan, & HalevyUrls Aspector Covered Google.comTop1_AllTop1_PopularTop8_AllTop8_Popular0.5erevoc 0.4LsRUr 0.3ctepf 0.2ntic0.1raF00100200300400500# top urls Google.comFigure 3: Fraction top web pages retrieved aspects also top 500 pagesretrieved original search query.6.4 Increase Coveragevalidate increase coverage interested answering two questions: (1)aspects enable users reach information original query? (2)additional information relevant user query?6.4.1 Informationshow aspects reach information, compare web pages retrievedusing aspects computed Aspector retrieved original searchquery. Given, query q computed aspects A, let DN set top N web pagesretrieved Google query q. Let Dki collection top k web pages retrievedGoogle aspect ai A, let Dka union Dki s. measurefractional overlap DN Dka , i.e.,|Dka DN ||Dka | .Figure 3 shows average fractional overlap Dka DN k = 1 k = 8dierent values N (x-axis). results averaged two sets queries:(1) 90 queries, (2) subset 30 popular queries, 10 aspects computedquery. results clearly indicate, even considering top 500 searchengine results, k = 1, 45% web pages D1a retrieved.words, 55% web pages retrieved using aspects even top 500 (note|D1a | 10). overlap even lower 33% considering k = 8. showsaspects clearly able retrieve new information.order isolate potential eects due rare queries search enginestypically propose related searches, separately consider subset popular queries.Interestingly, nd overlaps even smaller hence aspects ableretrieve even information. likely potentially diverseinformation Web popular entities.690fiIdentifying Aspects Web-Search QueriesDomaincountrycountry travelnba playercompanyuniversitymountainTotalCumulative Resp.Cov. CoveredNN274 26274 26238 8258 8269 53223 43280 48228 40309 31235 25242 38282 381612 2041500 180282533313426177Url RatingsCov. CoveredNN228 2027 0027 0226 1026 0230 26164 5Table 4: User responses indicating whether pages retrieved aspects relevantquery.6.4.2 Relevant Informationestablish information retrieved aspects fact relevant usersinformation needs, conducted Amt user study. query q, consideredtop 10 aspects aspect consider top retrieved web page, i.e., D1a .constructed list aspect-based results LA contained 4 results (selected randomD1a ), 2 overlapped D500 2 overlap D500 . Usersasked evaluate results (a) relevant, (b) irrelevant originalquery q. order place results context, also showed LA alongside LG , top5 regular search engine results (these rated, context).considered 90 test queries responses 10 users case. detailedresults shown Table 4. columns N indicate whether web pagesdeemed relevant not. Covered Covered columns separately considerweb pages LA covered D500 not. CumulativeResponses columns aggregate responses users, Url Ratings columnsaggregate ratings users separately web page LA . seen,total 177 web pages covered, deemed relevantmajority users.results indicate overall, vast majority additional web pages retrievedaspects deemed relevant majority users. addition, ratio relevantnot-relevant results covered not-covered web pages.indicates additional information relevant, likely relevantcovered information.Note coverage results also establish aspects likely span muchinformation space alternate schemes rely analyzing resultsoriginal query, e.g., cluster labels Clusty.6.5 Comprehensive Performance Comparisoncompare overall performance Aspector Grs, Ccl, Bns conductinguser study using Amt. separately compared Aspectorsystems. case, selected random subset around 30 queries original691fiWu, Madhavan, & Halevyset 90 queries. ltered queries dont return aspects systems.query, two lists (at most) 8 aspects generated, one using Aspectorusing Grs, Ccl Bns, presented Amt raterfollowing instructions:query represents start session explore information topic(presumably related query). user query, display two lists relatedqueries and/or properties. want compare two lists query identifytwo lists enables better subsequent exploration information.lists query presented side-by-side, user could rate one betterother, simply rate same. raters informedsource list side-by-side positioning lists randomly selected.collected responses 15 raters query.Tables 5, 6 7 summarize results user study. Cumulative Responsescolumns aggregate responses raters queries. F, E, columnsindicate ratings favor Aspector, even ratings, Aspector (and favorGrs Ccl) respectively. Query Ratings columns aggregate ratingsraters query, F indicating raters rated Aspector favorsystems (respectively E A).seen Table 5, Aspector clearly outperforms Grs. improvementslikely due increased orthogonality grouping aspects verticalcategory. also clear Table 6, Aspector also signicantly outperforms Ccl,likely due increased coverage.ascertain statistical signicance evaluation, comparison, performed standard paired t-test. individual query, considered total numberF responses responses. comparison Grs, mean perquery dierence (F-A) 10.7, i.e., average 10.7 total 15 evaluators ratedAspector better. dierence statistically signicant two-tailed pvalue less 0.0001. comparison Ccl, mean dierence 13.1signicant p-value less 0.0001.Bns produces aspects small number domains. set context comparison measured breadth Bns. chose top 100 Wikipedia Infobox classes,selected 15 entities (5 popular, 5 less common, 5 randomly) classsection 5.3. Bns provided aspects 17.6% entities. particular, Bns providedaspects 29.4% popular entities 9.8% less common entities. Bnsprovided aspects entities 48 classes, including scientist, magazineairport. second limitation Bns provides aspects entity queries.Hence, Bns provide aspects queries vietnam travel, seattle coeeboston rentals. third limitation Bns provides class-level aspects, though aspects may dier slightly one instance another. example,Bns misses aspect starbucks seattle, turkey slap turkey, numberchange kobe bryant.90 queries, 41 obtain aspects Bns. Table 7 showsAspector Bns rated comparably w.r.t. limited set queries. advantagesAspector come fact judiciously balances instance-level class-levelaspects. interesting point raters familiar particular692fiIdentifying Aspects Web-Search QueriesDomaincountrycountry travelnba playercompanyuniversitymountainTotalCumulativeFE6075417685511459115815350 69Resp.832105129Query RatingsFE40150050040150050028 02Table 5: User responses comparing Aspector Grs.Domaincountrycountry travelnba playercompanyuniversitymountainTotalCumulativeFE578625693561623537359 27Resp.902128738Query RatingsFE41050050050050050029 10Table 6: User responses comparing Aspector Ccl.instance, tend prefer class-level aspects. experiment, observationsometimes gives Bns advantage.6.6 Instance-Level Versus Class-Level AspectsRecall Aspector balances class-level instance-level aspects givenquery. Consider, example, class NBA players. 1365 players identiedWikipedia. able identify 8 candidate instance-level aspects126 (9.2%). 953 (69.8%) players, unable infer instance-levelaspects. However 54 class-level aspects appear least 5 instances,Domaincountrynba playercompanyuniversitymountainTotalCumulativeFE6529521220292966235 58Resp.5671531918217Query RatingsFE51430600580010117 116Table 7: User responses comparing Aspector Bns. Note resultltering 54% testing queries Bns provides aspects, case usersalways rate Aspector better.693fiWu, Madhavan, & HalevyDomaincountrycountry travelnba playercompanyuniversitymountainTotalCumulativeFE121712111014121317910147378Resp.465251504951299Query RatingsFE0050050050051040051029Table 8: User responses comparing Aspector K = 0 K = 1.thus giving us potentially larger pool good candidate aspects. balancing twosources aspects, Aspector able successfully compute reasonable aspects evenless frequent queries.compared extent class-based aspect propagation contributesquality aspects generated. this, performed Amt user study. considered dierent values parameter K Formula 1: 0, 0.1, 1, 10, 100,indicating progressively higher contribution class-level aspects. Aspect lists generated subset 30 queries (5 set) value K. compared twoaspect lists time, performed three sets experiments comparing (1) K = 0K = 1 (Table 8), (2) K = 0.1 K = 10 (Table 9), K = 1 K = 100 (Table 10).experiment used set 30 queries users asked picktwo sets aspects preferred query (same task description Section 5).Responses collected 15 users case. Note ensure signicant dierences aspect lists compared, experiments consider consecutive Kvalues (e.g., 0 0.1). earlier experiment consecutive K values used,found many queries subtle dierence hence large numbers users ratedlists comparable. number queries fewer Table 9 Table 10, sinceremaining ones resulted aspect lists K values surprisingsince, larger K values result increased inuence set class-based aspects.nd aspect lists K = 1 rated signicantly better K = 0(the mean per-query dierence (F-A) 7.53 signicant two-sided p-value less1E-9). lists K = 10 preferred K = 0.1 (thoughsmaller (F-A) 2.4 p value 0.008), lists K = 100 K = 1rated (the mean (F-A) 0.3 insignicant p value 0.8).seem indicate clearly class-based aspects helpful improving userexperience.However, note results might marginally over-state importance classbased aspects. users perception aspects dependent upon usersinterest familiarity entity question entity, though popular,familiar participant study, likely select class-based aspects.hand, found universally well known entities, companymicrosoft, lists instance-based aspects always preferred.694fiIdentifying Aspects Web-Search QueriesDomaincountrycountry travelnba playercompanyuniversitymountainTotalCumulativeFE111521231921172422261311103120Resp.341635342721167Query RatingsFE0042111041042031027118Table 9: User responses comparing Aspector K = 0.1 K = 10.Domaincountrycountry travelnba playercompanyuniversitymountainTotalCumulativeFE38161851233291420212392110Resp.4112813113198Query RatingsFE0012010034011112039110Table 10: User responses comparing Aspector K = 1 K = 100.6.7 Eliminating Grouping Aspectsconsider impact content-based clustering used identify duplicateaspects, vertical-category-based clustering groups aspects belongingcategory.6.7.1 Duplicate Eliminationcomputing candidate aspects query logs, possible nd multiple aspectsdierent names, semantically same. aspects eliminated order summary cover distinct axes. explained Section 5.1,Aspector applies graph partitioning algorithm single parameter,similarity threshold . conjecture similarity threshold intuitive setstable across dierent domains.test hypothesis, randomly selected 5 queries 5 domains.query, took top 30 aspects candidates manually created gold-standardcorrect aspect clustering results. computed aspect lists queries dierentvalues threshold compared results gold-standard.use F-Measure (F ) evaluate clustering results. particular, viewclustering series decisions, one N (N 1)/2 pairs aspects.Figure 4 plots F values dierent values threshold testdomains. found case best performance threshold values 0.250.4. results indicate clustering performance respect pretty stableacross domains. Hence, experiments, set single value = 0.35.695fiWu, Madhavan, & HalevyMountainNBA_PlayerCountryUniversityCompany0.90.8F-Measure0.70.60.50.40.30.20.1000.10.20.30.40.50.60.70.80.9Similarity thresholdFigure 4: F-Measure aspect clustering dierent values similarity threshold .domain, best performance around 0.35.DomaincompanyuniversitymountainTotalCumulativeFE2514187634924Resp.65617Query RatingsFE300200010510Table 11: User responses comparing Aspector vertical-category grouping without. F, E, responses favor, even, grouping.6.7.2 Vertical-Category Based Groupingaddition duplicates, observed often multiple aspects might belongvertical category. Rather represent separate aspect, summarizeaspects presenting single group. Note grouping eliminateaspects, simply lists single aspect. 6 90 queriesdataset, Aspector able group aspects vertical category.before, deployed Amt user study 6 test queries resultsshown Table 11, F indicating number responses favor vertical grouping(with E dened accordingly). seen, aspect lists groupingfavored comparison ones without grouping.Currently, Aspector groups aspects vertical categorycorresponding disambiguation pages Wikipedia. conservative solution avoids potential errors ambiguity exists, also misses opportunities. example,query mount bachelor, mount hood mount baker appear separate aspects sincedisambiguation pages entities. Rening grouping condition rich topicfuture work.696fiIdentifying Aspects Web-Search Queries7. Related Workdiscuss work related area search-result organization query-logmining.7.1 Search Result OrganizationSeveral works considered better organize search results. Agrawal, Gollapudi,Halverson, Ieong (2009) classify queries documents categories return searchresults considering document relevance diversity results. contrast, Aspector computes ne grained aspects instead abstract categories exploratoryqueries necessary ambiguous. commercial systems like Kosmix Yahoo!Glue categorize information based type format (e.g. photo, video,news map) retrieve top results category. Though dierent types oftenapproximate aspects, represent rich set semantically dierent groupsinformation sensitive instance-specic aspects. Carrot2 search engineapplies text clustering techniques returned search pages extracts keywords summarize cluster. Similar works done Bekkerman, Zilberstein, Allan (2007),Blei et al. (2003), Crabtree, Andreae, Gao (2006), Wang, Blei, Heckerman(2008). Multi-faceted search (Yee, Swearingen, Li, & Hearst, 2003) organizes collectionsbased set category hierarchies corresponds dierent facet. However category hierarchies requires heavy human eort construction maintenance.Correlator system Yahoo! performs semantic tagging documents enablemining related entities query. algorithms dont necessary discover clusterscorrespond Web users search interests, dicult generate informativecluster labels documents. use query logs complements document-basedapproaches, reects searchers intentions rather intentions publishers.Wang Zhai (2007) proposed organize search results based query logs.represent query pseudo-document enriched clickthrough informationpick top-k similar current query, cluster aspects. Then,classify resulting page corresponding aspect similarity. contrast,generate aspects based idea query renements dont require aspectcurrent query similar clickthrough. example, query vietnam travel visaimportant aspect vietnam travel, wont click-through properties.7.2 Query-Log Miningseveral eorts mine query logs interesting artifacts. Pasca Durme(2007) extract relevant attributes classes entities query logs ratherWeb documents done Bellare et al. (2006). main goal works createknowledge base entities, hence results appropriately comparedWikipedia Freebase.Query renement suggestion analyze query logs predict next probablequery following current query (Cucerzan & White, 2007; Jones, Rey, Madani, & Greiner,2006; Kraft & Zien, 2004; Velez, Wiess, Sheldon, & Giord, 1997). Hence, goalhelp users nd single result page rather help navigating body relevant697fiWu, Madhavan, & Halevyinformation. Bonchi, Castillo, Donato, Gionis (2008) proposed decompose querysmall set queries whose union corresponds approximately originalquery. However, experiments illustrated, constraint union resultingpages correspond approximately original query signicantly limits availablebody information expose user.Wang et al. (2009) mine set global latent query aspects, dynamically selecttop k aspects given query q help better navigate information space.ways similar Aspector, two key dierences. First, discoverset global latent query aspect via maximizing target function, aspectset aims apply many classes (important) queries. contrast, Aspector appliesclass-based label propagation identify aspects. Therefore, aspects tendne-grained query(class)-specic. Second, selecting k aspectsquery q, Wang et al. apply another optimization function tries cover manyoriginal (frequent) query renements q. works ne popular queriesless popular queries query renements. experiments showclasses, long tail less popular queries.8. Conclusionsdescribed Aspector system computing aspects web-search queries. Aspectsintended oer axes along space information relevant queryorganized, therefore enable search engines assist user exploring space.Aspector generates candidate aspects query logs balances aspectscommon classes entities vs. specic particular instances. Aspectoralso eliminates duplicate aspects groups related aspects using reference ontology.contrast purely knowledge-based approach, Aspectors results much broaderinclude aspects interest specic instances. contrast approach basedsolely clustering results query, Aspector include aspectsrepresented directly querys answer.set weights edges instances classes uniformly computingclass-based aspects. future direction compute better informed weighting functionsbased available temporal, spatial contextual constraints. Another future workallow multi-class memberships based ontologies besides Wikipedia Infobox.incorporate aspects mainstream search engine need address two challenges. First, need reliably identify query stream queries benetsummarization approach. works (Miwa & Kando, 2007; White & Roth, 2009)conducted area, much needs investigated. Second, doneKosmix, need dynamically generate eective visualizations aspects.ReferencesAgrawal, R., Gollapudi, S., Halverson, A., & Ieong, S. (2009). Diversifying Search Results.WSDM.Aslam, J. A., Pelekov, E., & Rus, D. (2004). star clustering algorithm staticdynamic information organization. Journal Graph Algorithms Applicatins.698fiIdentifying Aspects Web-Search QueriesBaluja, S., Seth, R., Sivakumar, D., Jing, Y., Yagnik, J., Kumar, S., Ravichandran, D., &Aly, M. (2008). Video suggestion discovery youtube: Taking random walksview graph. WWW.Battelle, J. (2005). Search: Google Rivals Rewrote Rules BusinessTransformed Culture. Portfolio Hardcover.Bekkerman, R., Zilberstein, S., & Allan, J. (2007). Web Page Clustering using HeuristicSearch Web Graph. IJCAI.Bellare, K., Talukdar, P. P., Kumaran, G., Pereira, F., Liberman, M., McCallum, A., &Dredze, M. (2006). Lightly-Supervised Attribute Extraction. NIPS.Bergsma, S., & Wang, Q. I. (2007). Learning Noun Phrase Query Segmentation. EMNLPCoNLL.Blei, D., Ng, A., & Jordan, M. (2003). Latent Dirichlet allocation. Journal MachineLearning Research.Bonchi, F., Castillo, C., Donato, D., & Gionis, A. (2008). Topical query decomposition.KDD.Broder, A. (2002). taxonomy web search. SIGIR Forum, 36 (2).Crabtree, D., Andreae, P., & Gao, X. (2006). Query Directed Web Page Clustering. WI.Cucerzan, S., & White, R. W. (2007). Query Suggestion based User Landing Pages.SIGIR.Jones, R., Rey, B., Madani, O., & Greiner, W. (2006). Generating query substitutions.WWW.Kraft, R., & Zien, J. (2004). Mining anchor text query renement. WWW.Meesookho, C., Narayanan, S., & Raghavendra, C. S. (2002). Collaborative classicationapplications sensor networks. SAMSP-Workshop.Miwa, M., & Kando, N. (2007). Methodology capturing exploratory search processes.CHI-Workshop.Pasca, M., & Durme, B. V. (2007). Seek Get: Extraction ClassAttributes Query Logs. IJCAI.Rajaraman, A. (2008).Searching needle exploring haystack?.http://anand.typepad.com/datawocky/2008/06/.Rose, D. E., & Levinson, D. (2004). Understanding User Goals Web Search. WWW.Snow, R., OConnor, B., Jurafsky, D., & Ng, A. Y. (2008). Cheap fast - good?evaluating non-expert annotations natural language tasks. EMNLP.Su, Q., Pavlov, D., Chow, J.-H., & Baker, W. C. (2007). Internet-scale collection humanreviewed data. WWW.Tan, B., & Peng, F. (2008). Unsupervised query segmentation using generative languagemodels wikipedia. WWW.Velez, B., Wiess, R., Sheldon, M., & Giord, D. (1997). Fast eective query renement.SIGIR.699fiWu, Madhavan, & HalevyWang, C., Blei, D., & Heckerman, D. (2008). Continuous time dynamic topic models.UAI.Wang, X., Chakrabarti, D., & Punera, K. (2009). Mining Broad Latent Query AspectsSearch Sessions. KDD.Wang, X., & Zhai, C. (2007). Learn Web Search Logs Organize Search Results.SIGIR.White, R. W., & Roth, R. A. (2009). Exploratory Search: Beyond Query-ResponseParadigm. Morgan Claypool Publishers.Yee, K.-P., Swearingen, K., Li, K., & Hearst, M. (2003). Faceted metadata image searchbrowsing. CHI.Zeng, H.-J., He, Q.-C., Chen, Z., Ma, W.-Y., & Ma, J. (2004). Learning cluster websearch results. SIGIR.700fiJournal Artificial Intelligence Research 40 (2011) 815-840Submitted 10/10; published 04/11Regression Conformal Prediction Nearest NeighboursHarris Papadopoulosh.papadopoulos@frederick.ac.cyComputer Science Engineering DepartmentFrederick University7 Y. Frederickou St., PalouriotisaNicosia 1036, CyprusVladimir VovkAlex Gammermanvovk@cs.rhul.ac.ukalex@cs.rhul.ac.ukComputer Learning Research CentreDepartment Computer ScienceRoyal Holloway, University LondonEgham, Surrey TW20 0EX, UKAbstractpaper apply Conformal Prediction (CP) k -Nearest Neighbours Regression (k -NNR) algorithm propose ways extending typical nonconformity measureused regression far. Unlike traditional regression methods produce point predictions, Conformal Predictors output predictive regions satisfy given confidencelevel. regions produced Conformal Predictor automatically valid, howevertightness therefore usefulness depends nonconformity measure usedCP. effect nonconformity measure evaluates strange given example compared set examples based traditional machine learning algorithm.define six novel nonconformity measures based k -Nearest Neighbours Regression algorithm develop corresponding CPs following original (transductive)inductive CP approaches. comparison predictive regions producedmeasures typical regression measure suggests major improvementterms predictive region tightness achieved new measures.1. Introductiondrawback traditional machine learning algorithms associatepredictions confidence information, instead output simple predictions. However, kind confidence information predictions paramount importancemany risk-sensitive applications used medical diagnosis (Holst, Ohlsson,Peterson, & Edenbrandt, 1998).course machine learning theories produce confidence information exist.One apply theory Probably Approximately Correct learning (PAC theory, Valiant,1984) algorithm order obtain upper bounds probability errorrespect confidence level. bounds produced PAC theory though,weak unless data set algorithm applied particularly clean,rarely case. Nouretdinov, Vovk, Vyugin, Gammerman (2001b) demonstratedcrudeness PAC bounds applying one best bounds, Littlestone Warmuth(Cristianini & Shawe-Taylor, 2000, Thm. 4.25, 6.8), USPS data set.c2011AI Access Foundation. rights reserved.fiPapadopoulos, Vovk, & GammermanAnother way obtaining confidence information using Bayesian frameworkproducing algorithms complement individual predictions probabilistic measuresquality. order apply Bayesian framework however, one requiredprior knowledge distribution generating data. correct priorknown, Bayesian methods provide optimal decisions. real world data sets though,required knowledge available, one assume existence arbitrarily chosenprior. case, since assumed prior may incorrect, resulting confidence levelsmay also incorrect; example predictive regions output 95% confidencelevel may contain true label much less 95% cases. signifies majorfailure would expect confidence levels bound percentage expected errors.experimental demonstration negative aspect Bayesian methods caseregression given Section 8, detailed experimental examinationclassification regression performed Melluish, Saunders, Nouretdinov, Vovk(2001).different approach confidence prediction suggested Gammerman, Vapnik,Vovk (1998) (and later greatly improved Saunders, Gammerman, & Vovk, 1999),proposed call paper Conformal Prediction (CP). thorough analysisCP given Vovk, Gammerman, Shafer (2005), overview presentedGammerman Vovk (2007). Conformal Predictors built top traditional machine learning algorithms accompany predictions valid measuresconfidence. Unlike Bayesian methods, CPs require assumptionsdistribution data, data independently identically distributed (i.i.d.); although still strong assumption, almost universally acceptedmachine learning. Even traditional algorithm CP based makesextra assumptions true particular data set, validity predictiveregions produced CP affected. resulting predictive regions mightuninteresting, still valid, opposed misleading regions producedBayesian methods. Furthermore, contrast PAC methods, confidence measuresproduce useful practice. Different variants CPs developed basedSupport Vector Machines (Saunders et al., 1999; Saunders, Gammerman, & Vovk, 2000),Ridge Regression (Nouretdinov, Melluish, & Vovk, 2001a; Papadopoulos, Proedrou, Vovk,& Gammerman, 2002a), k-Nearest Neighbours classification (Proedrou, Nouretdinov,Vovk, & Gammerman, 2002; Papadopoulos, Vovk, & Gammerman, 2002b) Neural Networks (Papadopoulos, Vovk, & Gammerman, 2007), shown givereliable high quality confidence measures. Moreover, CP applied successfullymany problems early detection ovarian cancer (Gammerman et al., 2009),classification leukaemia subtypes (Bellotti, Luo, Gammerman, Delft, & Saha, 2005),diagnosis acute abdominal pain (Papadopoulos, Gammerman, & Vovk, 2009a),prediction plant promoters (Shahmuradov, Solovyev, & Gammerman, 2005), recognition hypoxia electroencephalograms (EEGs) (Zhang, Li, Hu, Li, & Luo, 2008),prediction network traffic demand (Dashevskiy & Luo, 2008) estimation effortsoftware projects (Papadopoulos, Papatheocharous, & Andreou, 2009b).drawback original CP approach relative computational inefficiency.due transductive nature approach, entails computationsstart scratch every test example. renders unsuitable application816fiRegression Conformal Prediction Nearest Neighbourslarge data sets. reason modification original CP approach, calledInductive Conformal Prediction (ICP), proposed Papadopoulos et al. (2002a)regression Papadopoulos et al. (2002b) classification. suggested name,ICP replaces transductive inference followed original approach inductiveinference. Consequently, ICPs almost computationally efficient underlyingalgorithms. achieved cost loss quality produced confidencemeasures, loss negligible, especially data set question large, whereasimprovement computational efficiency significant. computational complexitycomparison original CP ICP approaches performed Papadopoulos(2008). on, order differentiate clearly original CP ICPapproaches former called Transductive Conformal Prediction (TCP).order apply CP (either TCP ICP) traditional algorithm one developnonconformity measure based algorithm. measure evaluates differencenew example set (actually multiset bag) old examples. Nonconformitymeasures constructed using basis traditional algorithm CPapplied, called underlying algorithm resulting Conformal Predictor. effectnonconformity measures assess degree new example disagreesattribute-label relationship old examples, according underlying algorithmCP. worth note many different nonconformity measures constructedtraditional algorithm measures defines different CP.difference, show next section, affect validity resultsproduced CPs, affects efficiency.paper interested problem regression focus k Nearest Neighbours Regression (k-NNR) underlying algorithm, onepopular machine learning techniques. first regression CPs proposed Nouretdinov et al. (2001a) following TCP approach Papadopoulos et al. (2002a) followingICP approach, based Ridge Regression algorithm. opposed conventional point predictions, output regression CPs predictive region satisfiesgiven confidence level.typical nonconformity measure used far case regression absolutedifference |yi yi |, actual label yi example predicted label yiunderlying algorithm example, given old examples training set.propose six extensions nonconformity measure k -Nearest Neighbours Regressiondevelop corresponding Inductive Transductive CPs; unfortunately althoughsix new measures used ICP approach, two usedTCP. definitions normalize standard measure based expected accuracyunderlying algorithm example, makes width resulting predictiveregions vary accordingly. result, predictive regions produced measuresgeneral much tighter produced standard regression measure.paper extends previous work (Papadopoulos, Gammerman, & Vovk, 2008)k -Nearest Neighbours Regression TCP developed using two normalized nonconformitymeasures. also worth mentioning one nonconformity measure definitionpresented Papadopoulos et al. (2002a) Ridge Regression ICP.rest paper structured follows. next section discuss generalidea CPs based. Sections 3 4 describe k -Nearest Neigh817fiPapadopoulos, Vovk, & Gammermanbours Regression TCP ICP respectively using typical regression nonconformitymeasure. Section 5 give new nonconformity measure definitions explainrationale behind them. Section 6 analyses one new nonconformity measuresdemonstrates specific assumptions gives asymptotically optimal predictiveregions. Section 7 details experimental results 3 TCPs 7 ICPs developedbased different measures, Section 8 compares methods Gaussian Process Regression (Rasmussen & Williams, 2006), one popular Bayesianapproaches. Finally, Section 9 gives conclusions discusses possible futuredirections work.2. Conformal Predictionsection briefly describe idea behind Conformal Prediction; detaileddescription interested reader referred book Vovk et al. (2005). giventraining set {z1 , . . . , zl } examples, zi Z pair (xi , yi ); xi Rdvector attributes example yi R label example. also givennew unlabeled example xl+1 task state something confidencedifferent values label yl+1 example. mentioned Section 1assumption (xi , yi ), = 1, 2, . . . , generated independentlyprobability distribution.First let us define concept nonconformity measure. Formally, nonconformitymeasure family functions : Z (n1) Z R, n = 1, 2, . . . (where Z (n1) setmultisets size n 1), assign numerical score= ({z1 , . . . , zi1 , zi+1 , . . . , zn }, zi )(1)example zi , indicating different examples multiset{z1 , . . . , zi1 , zi+1 , . . . , zn }.mentioned Section 1 nonconformity measure based traditionalmachine learning method, called underlying algorithm correspondingCP. Given training set examples {z1 , . . . , zl+1 }, method creates predictionruleD{z1 ,...,zl+1 } ,maps unlabeled example x label y. prediction rule basedexamples training set, nonconformity score example zi {z1 , . . . , zl+1 }measured disagreement predicted labelyi = D{z1 ,...,zl+1 } (xi )(2)actual label yi zi . Alternatively, create prediction ruleD{z1 ,...,zi1 ,zi+1 ,...,zl+1 }using examples set except zi , measure disagreementyi = D{z1 ,...,zi1 ,zi+1 ,...,zl+1 } (xi )yi .818(3)fiRegression Conformal Prediction Nearest Neighbourssuppose interested particular guess label xl+1 . Addingnew example (xl+1 , y) known data set {(x1 , y1 ), . . . , (xl , yl )} gives extendedset{z1 , . . . , zl+1 } = {(x1 , y1 ), . . . , (xl+1 , y)};(4)notice unknown component set label y. usenonconformity measure Al+1 compute nonconformity score= Al+1 ({z1 , . . . , zi1 , zi+1 , . . . , zl+1 }, zi )example zi , = 1, . . . , l + 1 (4). nonconformity score l+1really give us information, numeric value. However, findunusual zl+1 according Al+1 comparing l+1 nonconformity scores.comparison performed function#{i = 1, . . . , l + 1 : l+1 }(5)l+1(we leave dependence left-hand side z1 , . . . , zl , xl+1 implicit,11,always kept mind). call output function, lies l+1p-value y, part (4) given. important property(5) [0, 1] probability distributions P Z,p(y) =P {{z1 , . . . , zl+1 } : p(yl+1 ) } ;(6)proof given Nouretdinov et al. (2001b). result, p-value given labellow threshold, say 0.05, would mean label highly unlikelysets generated 5% time i.i.d. process.Assuming could calculate p-value every possible label y, described above,would able exclude labels p-value low threshold(or significance level ) chance wrong. Consequently, givenconfidence level 1 regression conformal predictor outputs set{y : p(y) > },(7)i.e. set labels p-value greater . course would impossibleexplicitly calculate p-value every possible label R. next sectiondescribe one compute predictive region (7) efficiently k -Nearest NeighboursRegression.noted p-values computed CP always valid sensesatisfying (6) regardless particular algorithm nonconformity measure definitionuses. choice algorithm, nonconformity measure definition parametersaffects tightness predictive regions output CP, consequentlyusefulness. demonstrate influence inadequate nonconformity measure definitionresults CP, let us consider case trivial definition always returnsvalue given example (xi , yi ). make p-values equal 1result predictive region R regardless required confidence level. Althoughregion useless since provide us information, still validalways contain true label example. Therefore even worst case usingtotally wrong nonconformity measure definition algorithm, regions producedcorresponding CP useless, never misleading.819fiPapadopoulos, Vovk, & Gammerman3. k -Nearest Neighbours Regression TCPk -Nearest Neighbours algorithms base predictions k training examplesnearest unlabeled example question according distance measure,Euclidean distance. specifically, input vector xl+1 k -NearestNeighbours Regression (k -NNR) algorithm finds k nearest training examples xl+1outputs average (in cases median also used) labels prediction.refined form method assigns weight one k examples dependingdistance xl+1 , weights determine contribution labelcalculation prediction; words predicts weighted average labels.also worth mention performance Nearest Neighbours methodenhanced use suitable distance measure kernel specific data set.consider version k -NNR method predicts weightedaverage k nearest examples. experiments used Euclidean distance,commonly used distance measure. easy see usekernel function different distance measure require changesmethod.mentioned Section 1 order create CP need define nonconformity measure based underlying algorithm question. First let us considernonconformity measure= |yi yi |,(8)yi prediction k -NNR xi based examples{(x1 , y1 ), . . . , (xi1 , yi1 ), (xi+1 , yi+1 ), . . . , (xl+1 , y)};recall Section 2 assumed label new example xl+1 .Following Nouretdinov et al. (2001a) Vovk et al. (2005) express nonconformity score example = 1, . . . , l + 1 piecewise-linear function= (y) = |ai + bi y|.define ai bi follows:al+1 minus weighted average labels k nearest neighbours xl+1bl+1 = 1;l xl+1 one k nearest neighbours xi , ai yi minus labelsk 1 nearest neighbours xi {x1 , . . . , xi1 , xi+1 , . . . , xl } multipliedcorresponding weights, bi minus weight xl+1 ;l xl+1 one k nearest neighbours xi , ai yi minusweighted average labels k nearest neighbours xi , bi = 0.result p-value p(y) (defined (5)) corresponding changepoints (y) l+1 (y) changes sign = 1, . . . , l. means insteadcalculate p-value every possible y, calculate set pointsreal line p-value p(y) greater given significance level , leadingfeasible prediction algorithm.820fiRegression Conformal Prediction Nearest NeighboursAlgorithm 1: k-NNR TCPInput: training set {(x1 , y1 ), . . . , (xl , yl )}, new example xl+1 , number nearestneighbours k significance level .P := {};= 1 l + 1Calculate ai bi example zi = (xi , yi );bi < 0 ai := ai bi := bi ;bi 6= bl+1 add (10) P ;bi = bl+1 6= 0 ai 6= al+1 add (11) P ;endSort P ascending order obtaining y(1) , . . . , y(u) ;Add y(0) := y(u+1) := P ;N (j) := 0, j = 0, . . . , u;(j) := 0, j = 1, . . . , u;= 1 l + 1Si = {} (see (9)) nothing;else Si contains one point, Si = {y(j) }(j) := (j) + 1;else Si interval [y(j1 ) , y(j2 ) ], j1 < j2(z) := (z) + 1, z = j1 , . . . , j2 ;N (z) := N (z) + 1, z = j1 , . . . , j2 1;else Si ray (, y(j) ](z) := (z) + 1, z = 1, . . . , j;N (z) := N (z) + 1, z = 0, . . . , j 1;else Si ray [y(j) , )(z) := (z) + 1, z = j, . . . , u;N (z) := N (z) + 1, z = j, . . . , u;else Si union (, y(j1 ) ] [y(j2 ) , ) two rays, j1 < j2(z) := (z) + 1, z = 1, . . . , j1 , j2 , . . . , u;N (z) := N (z) + 1, z = 0, . . . , j1 1, j2 , . . . , u;else Si real line (, )(z) := (z) + 1, z = 1, . . . , u;N (z) := N (z) + 1, z = 0, . . . , u;endOutput: predictive region(j)j: N (j) > (y(j) , y(j+1) ) {y(j) : Ml+1> }.l+1821fiPapadopoulos, Vovk, & Gammerman= 1, . . . , l + 1, letSi = {y : (y) l+1 (y)}= {y : |ai + bi y| |al+1 + bl+1 y|}.(9)set Si (always closed) either interval, ray, union two rays, realline, empty; also point, special case interval.interested |ai + bi y| assume bi 0 = 1, . . . , l + 1 (if multiplyai bi 1). bi 6= bl+1 , (y) l+1 (y) equal two points (whichmay coincide):ai al+1ai + al+1;(10)bi bl+1bi + bl+1case Si interval (maybe point) union two rays. bi = bl+1 6= 0,(y) = l+1 (y) one point:ai + al+1,2bi(11)Si ray, unless ai = al+1 case Si real line. bi = bl+1 = 0, Sieither empty real line.calculate p-value p(y) potential label new example xl+1 , countmany Si include divide l + 1,p(y) =#{i = 1, . . . , l + 1 : Si }.l+1(12)increases p(y) change points (10) (11), significance levelfind set p(y) > union finitely many intervalsrays. Algorithm 1 implements slightly modified version idea. creates listpoints (10) (11), sorts ascending order obtaining y(1) , . . . , y(u) , adds y(0) =beginning y(u+1) = end list, computes N (j), numberSi contain interval (y(j) , y(j+1) ), j = 0, . . . , u, (j) number Sicontain point y(j) , j = 1, . . . , u.4. k -Nearest Neighbours Regression ICPTCP technique follows transductive approach, computations repeated every test example. reason test example includedtraining set underlying algorithm TCP order calculate requirednonconformity measures. means underlying algorithm retrained everytest example, renders TCP quite computationally inefficient application largedata sets.Inductive Conformal Predictors (ICP) based general idea describedSection 2, follow inductive approach, allows train underlyingalgorithm once. achieved splitting training set (of size l) two smallersets, calibration set q < l examples proper training set := l qexamples. proper training set used creating prediction rule D{z1 ,...,zm }822fiRegression Conformal Prediction Nearest NeighboursAlgorithm 2: k-NNR ICPInput: training set {(x1 , y1 ), . . . , (xl , yl )}, test set {xl+1 , . . . , xl+r }, numbernearest neighbours k, number calibration examples q, significancelevel .:= l q;P := {};= 1 qCalculate ym+i using {(x1 , y1 ), . . . , (xm , ym )} training set;Calculate m+i pair zm+i = (xm+i , ym+i );Add m+i P ;endSort P descending order obtaining (m+1) , . . . , (m+q) ;:= b(q + 1)c;g = 1 rCalculate yl+g using {(x1 , y1 ), . . . , (xm , ym )} training set;Output: predictive region (yl+g (m+s) , yl+g + (m+s) ).endexamples calibration set used calculating p-value possible labelnew test example. specifically, non-conformity score m+i examplezm+i calibration set {zm+1 , . . . , zm+q } calculated degree disagreementpredictionym+i = D{z1 ,...,zm } (xm+i )(13)true label ym+i . way, non-conformity score l+g (y) assumedlabel new test example xl+g calculated degree disagreementyl+g = D{z1 ,...,zm } (xl+g )(14)y. Notice nonconformity scores examples calibration setneed computed once. Using non-conformity scores p-value possiblelabel xl+g calculatedp(y) =#{i = + 1, . . . , + q, l + g : l+g }.q+1(15)original CP approach impossible explicitly consider every possiblelabel R new example xl+g calculate p-value. However, nonconformity scores calibration set examples m+1 , . . . , m+q k-NNR predictionyl+g remain fixed test example xl+g , thing changes differentvalues assumed label nonconformity score l+g . Therefore p(y) changespoints l+g (y) = = + 1, . . . , + q. result, confidencelevel 1 need find biggest l+g (y) = p(y) > ,give us maximum minimum p-value bigger consequently beginning end corresponding predictive region. specifically,823fiPapadopoulos, Vovk, & Gammermansort nonconformity scores calibration examples descending order obtainingsequence(m+1) , . . . , (m+q) ,(16)output predictive region(yl+g (m+s) , yl+g + (m+s) ),(17)= b(q + 1)c.(18)whole process detailed Algorithm 2. Notice opposed Algorithm 1computations repeated every test example, part insidesecond loop repeated.parameter q given input Algorithm 2 determines number trainingexamples allocated calibration set nonconformity scoresused ICP generate predictive regions. examples takesmall portion training set, removal dramatically reducepredictive ability underlying algorithm. mainly interested confidencelevels 99% 95%, calibration sizes use form q = 100n 1, npositive integer (see (18)).5. Normalized Nonconformity Measuresmain aim work improve typical regression nonconformity measure (8)normalizing expected accuracy underlying method. intuitionbehind two examples nonconformity score defined (8)prediction one expected accurate other,former actually stranger latter. leads predictive regionslarger examples difficult predict smaller exampleseasier predict.first measure expected accuracy use based distance examplek nearest neighbours. Since k nearest training examples ones actuallyused derive prediction underlying method example, nearerexample, accurate expect prediction be.example zi , let us denote Ti training set used generating predictionyi . setTi = {z1 , . . . , zi1 , zi+1 , . . . , zl+1 }(19)case TCP setTi = {z1 , . . . , zm }(20)case ICP. Furthermore, denote k nearest neighbours xi Ti(xi1 , yi1 ), . . . , (xik , yik ).824(21)fiRegression Conformal Prediction Nearest Neighbourssum distances xi k nearest neighboursdki =kXdistance(xi , xij ).(22)j=1could use dki measure accuracy, fact used successfully previouswork (Papadopoulos et al., 2008). However, order make measureconsistent across different data sets useki =dki,median({dkj : zj Ti })(23)compares distance example k nearest neighbours mediandistances training examples k nearest neighbours. Using kidefined nonconformity measures:fififi yi yi fififi,(24)= fi+ ki fifififi yi yi fifi,= fifiexp(k ) fi(25)parameter 0 controls sensitivity measure changes ki ;first case increasing results less sensitive nonconformity measure, secondincreasing results sensitive measure. exponential function definition (25)chosen minimum value 1, since ki always positive, growsquickly ki increases. result, measure sensitive changes kibig, indicates example unusually far training examples.second measure accuracy use based different labelsexamples k nearest neighbours are, measured standard deviation.labels agree other, accurate expect predictionk-nearest neighbours algorithm be. example xi , measure standarddeviation labels k neighboursvu ku1 Xksi =(yij yi1,...,k )2 ,(26)kj=1yi1,...,kk1X=yij .k(27)j=1make measure consistent across data sets divide median standarddeviation k nearest neighbour labels training examplesik =ski.median({skj : zj Ti })825(28)fiPapadopoulos, Vovk, & Gammermanfashion (24) (25) defined nonconformity measures:fififi yi yi fififi,= fi+ ik fifififi yi yi fififi,= fiexp( k ) fi(29)(30)parameter controls sensitivity measure changes ik .Finally combining ki ik defined nonconformity measures:fififi yi yi fifi,fi(31)= fi+ ki + ik fififififiyi yififi,= fikkexp( ) + exp( ) fi(32)(31) parameter controls sensitivity measure changes kiik , whereas (32) two parameters , control sensitivitychanges ki ik respectively.order use nonconformity measures k-Nearest Neighbours RegressionTCP need calculate nonconformity scores = |ai +bi y|. easily(24) (25) computing ai bi defined Section 3 dividing( + ki ) nonconformity measure (24) exp(ki ) nonconformity measure (25).Unfortunately however, cannot applied nonconformity measuresdefined since ik depends labels k nearest examples, changek nearest neighbours xl+1 change y. reason TCP limited usingnonconformity measures (24) (25).case ICP calculate nonconformity scores m+1 , . . . , m+qcalibration examples using (24), (25), (29), (30), (31) (32) instead predictiveregion (17) output(yl+g (m+s) ( + ki ), yl+g + (m+s) ( + ki )),(33)(yl+g (m+s) exp(ki ), yl+g + (m+s) exp(ki )),(34)(yl+g (m+s) ( + ik ), yl+g + (m+s) ( + ik )),(35)(yl+g (m+s) exp(ik ), yl+g + (m+s) exp(ik )),(36)(yl+g (m+s) ( + ki + ik ), yl+g + (m+s) ( + ki + ik )),(37)(24),(25),(29),(30),(31)(yl+g (m+s) (exp(ki ) + exp(ik )), yl+g + (m+s) (exp(ki ) + exp(ik ))),(32).826(38)fiRegression Conformal Prediction Nearest Neighbours6. Theoretical Analysis Nonconformity Measure (29)section examine k-NNR ICP nonconformity measure (29) specificassumptions show that, assumptions, predictive regions producedasymptotically optimal; important note assumptions requiredvalidity resulting predictive regions. chose formalize conditionsneeded conclusions, would made statement far complicated.Assume label yi generated normal distribution N (xi , x2i ), xx smooth functions x, xi generated probability distributionconcentrated compact set whose density always greater constant> 0, k 1, k q k. case nonconformity measure (29)= 0fifi fififi yi yi fi fi yi xi fififififi,= fi(39)ski fi fi xi fidivision ski median({skj : zj Ti }) ignored since latter changewithin data set. valuesym+q xm+qym+1 xm+1,...,xm+1xm+qfollow approximately standard normal distribution, new example xl+gprobability close 1yl+g xl+g[(m+bqc) , (m+bqc) ],xl+g(m+1) , . . . , (m+q) nonconformity scores m+1 , . . . , m+q sorted descendingorder. result obtain regionyl+g [xl+g (m+bqc) xl+g , xl+g + (m+bqc) xl+g ],which, one hand, close standard (and optimal various senses) predictioninterval normal model and, hand, almost identical region (35)k-NNR ICP (recall set = 0 ik = ski ).7. Experimental Resultsmethods tested six benchmark data sets UCI (Frank & Asuncion,2010) DELVE (Rasmussen et al., 1996) repositories:Boston Housing, lists median house prices 506 different areas Boston$1000s. area described 13 attributes pollution crimerate.Abalone, concerns prediction age abalone physical measurements. data set consists 4177 examples described 8 attributesdiameter, height shell weight.827fiPapadopoulos, Vovk, & GammermanComputer Activity, collection computer systems activity measuresSun SPARCstation 20/712 128 Mbytes memory running multiuser university department. consists 8192 examples 12 measured values,number system buffer reads per second number system call writesper second, random points time. task predict portion timecpus run user mode, ranging 0 100. used small variantdata set contains 12 21 attributes.Kin, generated realistic simulation forward dynamics8 link all-revolute robot arm. task predict distance end-effectortarget. data set consists 8192 examples described attributes like jointpositions twist angles. used 8nm variant data set contains 832 attributes, highly non-linear moderate noise.Bank, generated simplistic simulator queues series banks.task predict rate rejections, i.e. fraction customersturned away bank open tellers full queues. dataset consists 8192 examples described 8 attributes like area population sizemaximum possible length queues. 8nm variant data set usedcharacteristics given description Kin data set.Pumadyn, generated realistic simulation dynamics Unimation Puma 560 robot arm. consists 8192 examples task predictangular acceleration one robot arms links. example described8 attributes, include angular positions, velocities torques robotarm. 8nm variant data set used characteristics givendescription Kin data set.conducting experiments attributes data sets normalizedminimum value 0 maximum value 1. experiments consisted 10 randomruns fold cross-validation process. Based sizes Boston Housing Abalonedata sets split 10 4 folds respectively, four splint 2folds. determining number k nearest neighbours used data set,one third training set first fold held-out validation set basealgorithm tested set different k, using two thirds training.number neighbours k gave smallest mean absolute error selected. Notethat, explained Section 2, choice k parameter affectvalidity results produced corresponding CP, affects efficiency.calibration set sizes set q = 100n 1 (see Section 4), n chosenq approximately 1/10th data sets training size; case BostonHousing data set smallest value n = 1 used. Table 1 gives number folds,number nearest neighbours k, calibration set size q used experimentsdata set, together number examples attributes consists widthrange labels.parameters nonconformity measures set cases 0.5,seems give good results data sets measures. worth note however,somewhat tighter predictive regions obtained adjusting corresponding828fiRegression Conformal Prediction Nearest NeighboursExamplesAttributesLabel rangeFoldskCalibration sizeBostonHousingAbaloneComputerActivityKinBankPumadyn50613451049941778284162998192129928399819281.4227399819280.48243998192821.1726399Table 1: Main characteristics experimental setup data set.parameter(s) measure data set. chose fix parameters 0.5 here,show remarkable improvement predictive region widths resultinguse new nonconformity measures depend fine tuningparameters.Since methods output predictive regions instead point predictions, main aimexperiments check tightness regions. first two partsTables 2-7 report median interdecile mean widths regions produced everydata set nonconformity measure k-NNR TCP ICP 99%, 95%90% confidence levels. chose report median interdecile mean values insteadmean avoid strong impact extremely large extremely smallregions.third last parts Tables 2-7 check reliability obtained predictiveregions data set. done reporting percentage examplestrue label inside region output corresponding method. effectchecks empirically validity predictive regions. percentages reportedclose required significance levels change much differentnonconformity measures.Figures 1-6 complement information detailed Tables 2-7 displaying boxplotsshow median, upper lower quartiles, upper lower decilespredictive region widths produced data set. chart divided three parts,separating three confidence levels consider, part contains 10 boxplotsfirst three k-NNR TCP nonconformity measures (8), (24)(25), remaining seven k-NNR ICP nonconformity measures.transformation width values reported Tables 2-7 percentagerange possible labels represent shows general predictive regions producedmethods relatively tight. median width percentages nonconformitymeasures data sets 17% 86% 99% confidence level11% 47% 95% confidence level. consider best performingnonconformity measure data set, worst median width percentage 99%confidence level 61% 95% confidence level 43% (both pumadyndata set).comparing predictive region tightness different nonconformity measuresmethod Tables 2-7 Figures 1-6, one see relatively bigimprovement new nonconformity measures achieve compared standard829fiPapadopoulos, Vovk, & GammermanMethod/MeasureTCPICP(8)(24)(25)(8)(24)(25)(29)(30)(31)(32)Median Width90%95%99%12.143 17.842 33.20511.172 14.862 24.45310.897 14.468 24.58513.710 19.442 38.80811.623 16.480 30.42711.531 16.702 30.91211.149 15.233 36.66110.211 14.228 34.67910.712 14.723 28.85910.227 13.897 29.068InterdecileMean Width90%95%99%12.054 17.870 33.56511.483 15.289 25.11311.258 14.956 25.36813.693 19.417 41.58111.985 16.991 33.45911.916 17.116 34.47712.165 16.645 41.31011.347 15.820 39.21111.343 15.612 31.12010.876 14.832 31.810Percentage outsidepredictive regions90%95%99%10.245.060.979.944.800.899.924.920.919.474.880.7910.594.920.7110.084.720.699.554.820.599.684.600.659.884.760.619.314.880.57Table 2: tightness reliability results methods Boston Housing dataset.Method/Measure(8)(24)(25)(8)(24)(25)(29)(30)(31)(32)TCPICPMedian Width90%95%99%6.685 9.267 16.1096.213 8.487 14.2116.034 8.278 13.9496.705 9.486 16.6286.200 8.305 14.0126.057 8.205 13.9225.837 7.987 14.3945.731 7.926 14.6315.936 7.999 13.9995.838 7.962 14.028InterdecileMean Width90%95%99%6.712 9.259 16.1246.376 8.708 14.5816.230 8.545 14.3936.671 9.388 16.5806.359 8.513 14.5206.229 8.434 14.4576.004 8.229 14.8955.931 8.200 15.1736.070 8.174 14.4065.994 8.178 14.506Percentage outsidepredictive regions90%95%99%9.944.940.9510.034.980.9810.034.950.9910.325.091.0110.575.541.2010.505.461.1910.475.051.0210.375.000.9310.575.351.1010.545.231.09Table 3: tightness reliability results methods Abalone data set.Method/MeasureTCPICP(8)(24)(25)(8)(24)(25)(29)(30)(31)(32)Median Width90%95%99%10.005 13.161 21.7328.788 11.427 18.4338.370 10.856 17.08410.149 13.588 22.7059.024 11.725 18.9488.646 11.340 17.8178.837 11.877 19.5958.702 11.618 18.8598.653 11.301 18.1798.517 11.114 17.468InterdecileMean Width90%95%99%10.009 13.113 21.6799.238 12.017 19.3728.924 11.572 18.20710.245 13.467 22.5779.483 12.333 19.9189.206 12.067 18.9539.031 12.145 20.1149.013 12.031 19.5229.020 11.789 18.9838.914 11.627 18.264Percentage outsidepredictive regions90%95%99%9.984.990.979.954.920.959.924.910.979.714.790.959.514.720.909.404.510.929.754.590.919.494.580.959.704.550.899.464.510.96Table 4: tightness reliability results methods Computer Activity dataset.830fiRegression Conformal Prediction Nearest NeighboursMethod/Measure(8)(24)(25)(8)(24)(25)(29)(30)(31)(32)TCPICPMedian Width90%95%99%0.402 0.491 0.6750.395 0.480 0.6490.396 0.481 0.6530.413 0.508 0.7050.408 0.498 0.6800.408 0.501 0.6810.412 0.497 0.7300.401 0.482 0.6950.403 0.486 0.6770.399 0.487 0.670InterdecileMean Width90%95%99%0.402 0.491 0.6750.396 0.481 0.6510.397 0.482 0.6550.414 0.515 0.7020.409 0.499 0.6820.408 0.502 0.6820.418 0.504 0.7410.408 0.491 0.7070.406 0.489 0.6820.402 0.490 0.676Percentage outsidepredictive regions90%95%99%10.134.990.9610.185.010.9510.165.000.969.864.520.819.734.610.779.844.590.809.745.210.919.745.080.849.814.830.8710.054.750.85Table 5: tightness reliability results methods Kin data set.Method/Measure(8)(24)(25)(8)(24)(25)(29)(30)(31)(32)TCPICPMedian Width90%95%99%0.135 0.201 0.3420.121 0.170 0.2650.123 0.173 0.2700.142 0.209 0.3610.122 0.178 0.2740.125 0.182 0.2820.096 0.151 0.3060.084 0.137 0.2720.096 0.146 0.2470.092 0.143 0.249InterdecileMean Width90%95%99%0.135 0.201 0.3410.122 0.171 0.2670.124 0.175 0.2730.139 0.209 0.3620.123 0.179 0.2770.126 0.183 0.2840.110 0.174 0.3520.104 0.169 0.3340.105 0.160 0.2700.102 0.159 0.274Percentage outsidepredictive regions90%95%99%10.054.990.9510.024.940.9010.034.950.919.954.710.8310.164.710.8710.084.720.879.974.510.8010.214.610.7910.144.460.8510.314.580.88Table 6: tightness reliability results methods Bank data set.Method/MeasureTCPICP(8)(24)(25)(8)(24)(25)(29)(30)(31)(32)Median Width90%95%99%7.9099.694 13.9087.7619.417 13.1537.7749.463 13.2398.008 10.005 13.9247.8699.627 13.1937.8929.713 13.3357.7459.563 14.3427.4609.199 13.3987.5499.185 13.0407.5799.237 12.808InterdecileMean Width90%95%99%7.927 9.726 13.8277.781 9.439 13.1837.793 9.486 13.2688.097 9.993 14.0077.894 9.655 13.2337.919 9.731 13.3777.842 9.698 14.5887.634 9.410 13.7237.610 9.263 13.1807.660 9.336 12.955Percentage outsidepredictive regions90%95%99%9.924.870.999.884.981.049.924.941.029.724.751.069.864.811.099.894.751.109.964.871.049.974.821.0710.024.891.049.904.831.15Table 7: tightness reliability results methods Pumadyn data set.831fiPapadopoulos, Vovk, & Gammerman10090Region Width8070605040302010090%95%99%Confidence LevelTCP - (8)ICP - (29)TCP - (24)ICP - (30)TCP - (25)ICP - (31)ICP - (8)ICP - (32)ICP - (24)ICP - (25)Figure 1: Predictive region width distribution Boston housing data set.25Region Width2015105090%95%99%Confidence LevelTCP - (8)ICP - (29)TCP - (24)ICP - (30)TCP - (25)ICP - (31)ICP - (8)ICP - (32)ICP - (24)ICP - (25)Figure 2: Predictive region width distribution Abalone data set.35Region Width30252015105090%95%99%Confidence LevelTCP - (8)ICP - (29)TCP - (24)ICP - (30)TCP - (25)ICP - (31)ICP - (8)ICP - (32)ICP - (24)ICP - (25)Figure 3: Predictive region width distribution Computer Activity data set.832fiRegression Conformal Prediction Nearest Neighbours1.2Region Width10.80.60.40.2090%95%99%Confidence LevelTCP - (8)ICP - (29)TCP - (24)ICP - (30)TCP - (25)ICP - (31)ICP - (8)ICP - (32)ICP - (24)ICP - (25)Figure 4: Predictive region width distribution Kin data set.10.9Region Width0.80.70.60.50.40.30.20.1090%95%99%Confidence LevelTCP - (8)ICP - (29)TCP - (24)ICP - (30)TCP - (25)ICP - (31)ICP - (8)ICP - (32)ICP - (24)ICP - (25)Figure 5: Predictive region width distribution Bank data set.25Region Width2015105090%95%99%Confidence LevelTCP - (8)ICP - (29)TCP - (24)ICP - (30)TCP - (25)ICP - (31)ICP - (8)ICP - (32)ICP - (24)ICP - (25)Figure 6: Predictive region width distribution Pumadyn data set.833fiPapadopoulos, Vovk, & GammermanMethodB. HousingAbaloneTCP measuresICP (8)ICP new measures20 sec0.6 sec1.4 sec51 - 52 min8 sec29 sec2.5 - 2.7 hrs17 - 18 sec37 - 39 secTable 8: processing times k-NNR TCP ICP.regression measure (8). almost cases new measures give smaller medianinterdecile mean widths, majority cases difference quite significant.degree improvement evident Figures 1-6 see many casesmedian widths predictive regions obtained new measures evensmallest widths obtained measure (8).comparison nonconformity measures based distancesk nearest neighbours, (24) (25), based standard deviationlabels, (29) (30), reveals regions produced latter cover muchbigger range widths. Furthermore, widths (24) (25) seem casestighter average (29) (30) highest confidence level 99%, whereasopposite true 90% 95% confidence levels. also worth mentioningmeasures (29) (30) ones produced predictive regions biggermedian interdecile mean widths measure (8) cases.last two measures (31) (32), combine others, seem give tightestpredictive region widths ICP overall. 11 18 cases one two smallestmedian predictive region width 1 cases one two smallestinterdecile mean width. superiority also evident figures especiallyFigures 1, 5 6.One important comparison widths regions producedTCP ICP approaches. standard regression nonconformity measure (8)regions TCP cases tighter ICP. due muchricher set examples TCP uses calculating predictive regions; TCP useswhole training set opposed calibration examples used ICP. differencepredictive region tightness much bigger results Boston housing data set, sincecalibration set case consisted 99 examples. also worth notewidths regions produced ICP (8) vary much correspondingwidths TCP, natural since composition calibration set changesmuch bigger degree one run another composition whole training set.compare region widths two approaches nonconformity measures(24) (25) see that, exception Boston housing set,similar terms distribution. shows new measures dependantcomposition examples used producing predictive regions. Furthermore,compare region widths TCP nonconformity measures (24) (25)ICP nonconformity measures (31) (32), see many casesregions ICP somewhat tighter, despite much smaller set examples usescompute them. due superiority measures (31) (32).834fiRegression Conformal Prediction Nearest NeighboursFinally, Table 8 report processing times two approaches. use tworows reporting times ICP, one measure (8) one new measures,since new measures require extra computations; i.e. finding distancestraining examples k nearest neighbours and/or standard deviationk nearest neighbour labels. also group times Computer Activity, Kin, BankPumadyn data sets, almost identical consist numberexamples, one column. table demonstrates huge computational efficiencyimprovement ICP TCP. also shows computational overheadinvolved using new nonconformity measures ICP, important,especially baring mind degree improvement bring terms predictive regiontightness.8. Comparison Gaussian Process Regressionsection compare predictive regions produced methodsproduced Gaussian Processes (GPs, Rasmussen & Williams, 2006), onepopular Bayesian machine learning approaches. first compare Gaussian ProcessRegression (GPR) k-NNR CPs artificially generated data satisfy GPprior check results GPR three data sets described Section 7,namely Boston Housing, Abalone Computer Activity. implementation GPRbased Matlab code accompanies work Rasmussen Williams.first set experiments generated 100 artificial data sets consisting1000 training 1000 test examples inputs drawn uniform distribution[10, 10]5 . labels data set generated Gaussian Processcovariance function defined sum squared exponential (SE) covariance independent noise hyperparameters (l, f , n ) = (1, 1, 0.1); i.e. unit length scale, unitsignal magnitude noise standard deviation 0.1. applied GPRdata sets using exactly covariance function hyperparameters comparedresults k-NNR CPs (which take account informationdata generated). Table 9 reports results 100 data sets obtained GPR methods manner Tables 2-7. case, sincedata meets GPR prior, percentage labels outside predictive regions producedGPR less equal required significance level would expect.true regions produced methods. Also, although predictiveregions produced GPR tighter produced methods, differencetwo small.experiments three benchmark data sets performed following exactlysetting experiments two CPs, including use seedfold-cross validation run. terms data preprocessing, normalised attributesdata set setting mean attribute 0 standard deviation 1,also centred labels data set zero mean; preprocessingsteps advisable GPR. tried SE covariance Matern covariancesmoothness set v = 3/2 v = 5/2. case SE covariance, usedautomatic relevance determination version function, allows separatelength-scale attribute determined corresponding hyperparameter. cases835fiPapadopoulos, Vovk, & GammermanMethod/MeasureGPRTCPICP(8)(24)(25)(8)(24)(25)(29)(30)(31)(32)Median Width90%95%99%3.306 3.940 5.1783.332 3.999 5.2773.322 3.982 5.3063.322 3.975 5.2903.344 3.978 5.2643.346 4.016 5.3293.337 3.994 5.3023.333 3.989 5.2923.331 3.993 5.2803.340 3.995 5.3083.332 3.990 5.279InterdecileMean Width90%95%99%3.306 3.939 5.1773.332 3.989 5.2743.339 4.001 5.3323.335 3.990 5.3093.337 4.001 5.2833.358 4.029 5.3493.348 4.005 5.3203.339 3.994 5.3053.338 3.997 5.2953.348 4.002 5.3243.339 3.994 5.294Percentage outsidepredictive regions90%95%99%10.014.950.999.934.810.959.904.820.989.884.820.959.904.800.959.834.761.019.864.780.989.974.880.969.904.840.959.854.790.979.884.810.97Table 9: Comparison methods Gaussian Process Regression artificial datagenerated Gaussian Process.CovarianceFunctionSEMatern v = 3/2Matern v = 5/2Median Width90%95%99%7.1688.540 11.2258.3699.972 13.1068.476 10.100 13.274InterdecileMean Width90%95%99%7.4198.840 11.6188.636 10.290 13.5248.748 10.423 13.699Percentage outsidepredictive regions90%95%99%10.286.702.988.025.042.657.714.882.61Table 10: tightness reliability results Gaussian Process Regression BostonHousing data set.CovarianceFunctionSEMatern v = 3/2Matern v = 5/2Median Width90%95%99%6.705 7.988 10.4996.740 8.031 10.5556.750 8.042 10.570InterdecileMean Width90%95%99%6.711 7.996 10.5097.046 8.396 11.0346.755 8.048 10.577Percentage outsidepredictive regions90%95%99%9.436.472.929.026.112.779.156.232.82Table 11: tightness reliability results Gaussian Process RegressionAbalone data set.836fiRegression Conformal Prediction Nearest NeighboursCovarianceFunctionSEMatern v = 3/2Matern v = 5/2Median Width90%95%99%8.115 9.669 12.7088.120 9.675 12.7158.340 9.937 13.060InterdecileMean Width90%95%99%8.1989.768 12.8388.471 10.093 13.2658.617 10.267 13.494Percentage outsidepredictive regions90%95%99%10.156.472.389.635.912.099.635.812.09Table 12: tightness reliability results Gaussian Process Regression Computer Activity data set.actual covariance function defined sum corresponding covarianceindependent noise. hyperparameters adapted maximizing marginal likelihoodtraining set suggested Rasmussen Williams (2006); adaptationhyperparameters using leave-one-out cross-validation produces less results.Tables 10-12 report results obtained GRP three data setscovariance function. comparing values reported first two parts tablesTables 2-4 one see regions produced GPR tighter almostcases. However, percentage predictive regions include true labelexample much higher required 95% 99% confidence levels.shows predictive regions produced GPR valid thereforemisleading correct prior known. contrary, demonstrated Section 2,CPs produce valid predictive regions even parameters underlying algorithm usedtotally wrong.9. Conclusionspresented Transductive Inductive Conformal Predictors based k-NearestNeighbours Regression algorithm. addition typical regression nonconformity measure, developed six novel definitions take account expected accuracyk-NNR algorithm example question. definitions assess expected accuracy k-NNR example based distances k nearest examples (24)(25), standard deviation labels (29) (30), combinationtwo (31) (32).experimental results obtained applying methods various data sets showcases produce reliable predictive intervals tight enough usefulpractice. Additionally, illustrate great extent new nonconformitymeasure definitions improve performance transductive inductive methodterms predictive region tightness. case ICP, new measuresevaluated, definitions (31) (32) appear superior measures, givingoverall tightest predictive regions. Moreover, comparison TCP ICPmethods suggests that, dealing relatively large data sets use nonconformitymeasures (31) (32) makes ICP perform equally well TCP terms predictiveregion tightness, whereas vast advantage comes computational efficiency.Finally, comparison Gaussian Process Regression (GPR) demonstrated837fiPapadopoulos, Vovk, & Gammermanmethods produce almost tight predictive regions GPR correct priorknown, GPR may produce misleading regions real world datarequired prior knowledge available.main future direction work development normalized nonconformitymeasures like ones presented paper based popular regression techniques,Ridge Regression Support Vector Regression. Although case RidgeRegression one measure already defined ICP (Papadopoulos et al., 2002a),unfortunately cannot used TCP approach; thus potentially considerable performance gain achieved definition kind TCP. Moreover,equally important future aim application methods medical problemsprovision predictive regions desirable, evaluation resultsexperts corresponding field.Acknowledgmentswould like thank Savvas Pericleous Haris Haralambous useful discussions.would also like thank anonymous reviewers insightful constructivecomments. work supported part Cyprus Research Promotion Foundationresearch contract PLHRO/0506/22 (Development New Conformal PredictionMethods Applications Medical Diagnosis).ReferencesBellotti, T., Luo, Z., Gammerman, A., Delft, F. W. V., & Saha, V. (2005). Qualified predictions microarray proteomics pattern diagnostics confidence machines.International Journal Neural Systems, 15 (4), 247258.Cristianini, N., & Shawe-Taylor, J. (2000). Introduction Support Vector MachinesKernel-based Methods. Cambridge University Press, Cambridge.Dashevskiy, M., & Luo, Z. (2008). Network traffic demand prediction confidence.Proceedings IEEE Global Telecommunications Conference 2008 (GLOBECOM2008), pp. 14531457. IEEE.Frank, A., & Asuncion, A. (2010).http://archive.ics.uci.edu/ml.UCI machine learning repository.URLGammerman, A., Vapnik, V., & Vovk, V. (1998). Learning transduction. ProceedingsFourteenth Conference Uncertainty Artificial Intelligence, pp. 148156,San Francisco, CA. Morgan Kaufmann.Gammerman, A., Vovk, V., Burford, B., Nouretdinov, I., Luo, Z., Chervonenkis, A., Waterfield, M., Cramer, R., Tempst, P., Villanueva, J., Kabir, M., Camuzeaux, S., Timms,J., Menon, U., & Jacobs, I. (2009). Serum proteomic abnormality predating screendetection ovarian cancer. Computer Journal, 52 (3), 326333.Gammerman, A., & Vovk, V. (2007). Hedging predictions machine learning: secondcomputer journal lecture. Computer Journal, 50 (2), 151163.838fiRegression Conformal Prediction Nearest NeighboursHolst, H., Ohlsson, M., Peterson, C., & Edenbrandt, L. (1998). Intelligent computer reporting lack experience: confidence measure decision support systems. ClinicalPhysiology, 18 (2), 139147.Melluish, T., Saunders, C., Nouretdinov, I., & Vovk, V. (2001). Comparing BayesTypicalness frameworks. Proceedings 12th European Conference MachineLearning (ECML01), Vol. 2167 Lecture Notes Computer Science, pp. 360371.Springer.Nouretdinov, I., Melluish, T., & Vovk, V. (2001a). Ridge regression confidence machine.Proceedings 18th International Conference Machine Learning (ICML01),pp. 385392, San Francisco, CA. Morgan Kaufmann.Nouretdinov, I., Vovk, V., Vyugin, M. V., & Gammerman, A. (2001b). Pattern recognitiondensity estimation general i.i.d. assumption. Proceedings 14thAnnual Conference Computational Learning Theory 5th European ConferenceComputational Learning Theory, Vol. 2111 Lecture Notes Computer Science,pp. 337353. Springer.Papadopoulos, H. (2008).Inductive Conformal Prediction: Theory application neural networks.Fritzsche, P. (Ed.), Tools Artificial Intelligence, chap. 18, pp. 315330. InTech, Vienna, Austria.URLhttp://www.intechopen.com/download/pdf/pdfs id/5294.Papadopoulos, H., Gammerman, A., & Vovk, V. (2008). Normalized nonconformity measures regression conformal prediction. Proceedings IASTED InternationalConference Artificial Intelligence Applications (AIA 2008), pp. 6469. ACTAPress.Papadopoulos, H., Gammerman, A., & Vovk, V. (2009a). Confidence predictionsdiagnosis acute abdominal pain. Iliadis, L., Vlahavas, I., & Bramer, M. (Eds.),Artificial Intelligence Applications & Innovations III, Vol. 296 IFIP InternationalFederation Information Processing, pp. 175184. Springer.Papadopoulos, H., Papatheocharous, E., & Andreou, A. S. (2009b). Reliable confidence intervals software effort estimation. Proceedings 2nd WorkshopArtificial Intelligence Techniques Software Engineering (AISEW 2009), Vol.475 CEUR Workshop Proceedings. CEUR-WS.org. URL http://ceur-ws.org/Vol475/AISEW2009/22-pp-211-220-208.pdf.Papadopoulos, H., Proedrou, K., Vovk, V., & Gammerman, A. (2002a). Inductive confidencemachines regression. Proceedings 13th European Conference MachineLearning (ECML02), Vol. 2430 Lecture Notes Computer Science, pp. 345356.Springer.Papadopoulos, H., Vovk, V., & Gammerman, A. (2002b). Qualified predictions largedata sets case pattern recognition. Proceedings 2002 InternationalConference Machine Learning Applications (ICMLA02), pp. 159163. CSREAPress.839fiPapadopoulos, Vovk, & GammermanPapadopoulos, H., Vovk, V., & Gammerman, A. (2007). Conformal prediction neuralnetworks. Proceedings 19th IEEE International Conference ToolsArtificial Intelligence (ICTAI07), Vol. 2, pp. 388395. IEEE Computer Society.Proedrou, K., Nouretdinov, I., Vovk, V., & Gammerman, A. (2002). Transductive confidencemachines pattern recognition. Proceedings 13th European ConferenceMachine Learning (ECML02), Vol. 2430 Lecture Notes Computer Science, pp.381390. Springer.Rasmussen, C. E., Neal, R. M., Hinton, G. E., Van Camp, D., Revow, M., Ghahramani, Z.,Kustra, R., & Tibshirani, R. (1996). DELVE: Data evaluating learning validexperiments. URL http://www.cs.toronto.edu/delve/.Rasmussen, C. E., & Williams, C. K. I. (2006). Gaussian Processes Machine Learning.MIT Press.Saunders, C., Gammerman, A., & Vovk, V. (1999). Transduction confidencecredibility. Proceedings 16th International Joint Conference ArtificialIntelligence, Vol. 2, pp. 722726, Los Altos, CA. Morgan Kaufmann.Saunders, C., Gammerman, A., & Vovk, V. (2000). Computationally efficient transductivemachines. Proceedings Eleventh International Conference AlgorithmicLearning Theory (ALT00), Vol. 1968 Lecture Notes Artificial Intelligence, pp.325333, Berlin. Springer.Shahmuradov, I. A., Solovyev, V. V., & Gammerman, A. J. (2005). Plant promoter prediction confidence estimation. Nucleic Acids Research, 33 (3), 10691076.Valiant, L. G. (1984). theory learnable. Communications ACM, 27 (11),11341142.Vovk, V., Gammerman, A., & Shafer, G. (2005). Algorithmic Learning Random World.Springer, New York.Zhang, J., Li, G., Hu, M., Li, J., & Luo, Z. (2008). Recognition hypoxia EEG presetconfidence level based EEG analysis. Proceedings International JointConference Neural Networks (IJCNN 2008), part IEEE World CongressComputational Intelligence (WCCI 2008), pp. 30053008. IEEE.840fiJournal Artificial Intelligence Research 40 (2011) 767-813Submitted 11/10; published 04/11Scaling Heuristic Planning Relational Decision TreesTomas de la RosaSergio JimenezRaquel FuentetajaDaniel BorrajoTROSA @ INF. UC 3 . ESSJIMENEZ @ INF. UC 3 . ESRFUENTET @ INF. UC 3 . ESDBORRAJO @ IA . UC 3 . ESDepartamento de InformaticaUniversidad Carlos III de MadridAv. Universidad 30, Leganes, Madrid, SpainAbstractCurrent evaluation functions heuristic planning expensive compute. numerousplanning problems functions provide good guidance solution, worthexpense. However, evaluation functions misguiding planning problems largeenough, lots node evaluations must computed, severely limits scalability heuristic planners. paper, present novel solution reducing node evaluations heuristicplanning based machine learning. Particularly, define task learning search controlheuristic planning relational classification task, use off-the-shelf relational classification tool address learning task. relational classification task captures preferred actionselect different planning contexts specific planning domain. planning contextsdefined set helpful actions current state, goals remaining achieved,static predicates planning task. paper shows two methods guiding searchheuristic planner learned classifiers. first one consists using resulting classifier action policy. second one consists applying classifier generate lookaheadstates within Best First Search algorithm. Experiments variety domains revealheuristic planner using learned classifiers solves larger problems state-of-the-art planners.1. Introductionlast years, state-space heuristic search planning achieved significant resultsbecome one popular paradigms automated planning. However, heuristic searchplanners suffer strong scalability limitations. Even well-studied domains like Blocksworldbecome challenging planners number blocks relatively large. Usually, statespace heuristic search planners based action grounding, makes state-spaceexplored large number objects and/or action parameters large enough. Moreover,domain-independent heuristics expensive compute. domains heuristicsmisleading, heuristic planners spend planning time computing useless nodeevaluations. Even best current domain-independent heuristic functions literature,forward chaining heuristic planners currently visit many nodes, takes considerabletime, especially due time required compute heuristic functions.problems entail strong limitations application heuristic planners real problems. instance, logistics applications need handle hundreds objects together hundredsvehicles locations (Florez, Garca, Torralba, Linares, Garca-Olaya, & Borrajo, 2010). Current heuristic search planners exhaust computational resources solving problemreal logistics application.c2011AI Access Foundation. rights reserved.fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJOclassic approach dealing planning scalability issues assisting search enginesplanners Domain-specific Control Knowledge (DCK). Examples planning systemsbenefit knowledge TLP LAN (Bacchus & Kabanza, 2000), TALP LANNER (Doherty& Kvarnstrom, 2001) SHOP2 (Nau, Au, Ilghami, Kuter, Murdock, Wu, & Yaman, 2003).Nevertheless, hand-coding DCK complex task implies expertise both, planning domain search algorithm planning system. recent yearsrenewed interest using Machine Learning (ML) automatically extract DCK. ZimmermanKambhampati (2003) made comprehensive survey ML defining DCK. shown firstlearning planning competition held 2008 (Learning Track), renewed interest speciallytargeted heuristic planners.paper presents approach learning DCK planning building domain-dependentrelational decision trees examples good quality solutions forward-chaining heuristicplanner. decision trees built off-the-shelf relational classification tool capture best action take possible decision planner given domain.resulting decision trees used either policy solve planning problems directlygenerate lookahead states within Best First Search (BFS) algorithm. techniques allowplanner avoid state evaluations, helps objective improving scalability.approach implemented system called ROLLER. work improvementprevious one (De la Rosa, Jimenez, & Borrajo, 2008). Alternatively, ROLLER versionrepairing relaxed plans (De la Rosa, Jimenez, Garca-Duran, Fernandez, Garca-Olaya, & Borrajo,2009) competed Learning Track 6th International Planning Competition (IPC) held2008. ROLLER improvements presented article mainly result lessons learnedcompetition, discussed later.paper organized follows. Section 2 introduces issues need considereddesigning learning system heuristic planning. help us clarify decisions made development approach. Section 3 describes ROLLER systemdetail. Section 4 presents experimental results obtained variety benchmarks. Section 5discusses improvements ROLLER system compared previous version system.Section 6 revises related work learning DCK heuristic planning. Finally, last sectiondiscusses conclusions future work.2. Common Issues Learning Domain-specific Control Knowledgedesigning ML process automatic acquisition DCK, one must considercommon issues, among others:1. representation learned knowledge. Predicate logic common languagerepresent planning DCK planning tasks usually defined language. However, representation languages used aiming make learning DCKeffective. instance, languages describing object classes ConceptLanguage (Martin & Geffner, 2000) Taxonomic Syntax (Mcallester & Givan, 1989)shown provide useful learning bias different domains.Another representation issue selection feature space (i.e., set instancefeatures used representing learned knowledge training system.). featurespace able capture key knowledge domain. Traditionally, feature768fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REESspace consisted predicates describing current state goals planningtask. feature space enriched extra predicates, called metapredicates,capture extra useful information planning context applicable operatorspending goals (Veloso, Carbonell, Perez, Borrajo, Fink, & Blythe, 1995). Recently, workslearning DCK heuristic planners define metapredicates capture informationplanning context heuristic planner, including example, predicates captureactions relaxed plan given state (Yoon, Fern, & Givan, 2008).2. learning algorithms. Inductive Logic Programming (ILP) (Muggleton & De Raedt,1994) deals development inductive techniques learn given target conceptexamples described predicate logic. planning tasks normally representedpredicate logic, ILP algorithms quite suitable DCK learning. Moreover, recentyears, ILP broadened scope cover whole spectrum ML tasks regression, clustering association analysis, extending classical propositional ML algorithmsrelational framework. Consequently, ILP algorithms used heuristic planners capture DCK different forms decision rules select actions differentplanning context regression rules obtain better node evaluations (Yoon et al., 2008).3. generation training examples. success ML algorithms depends directlyquality training examples used. learning planning DCK, examplesextracted experience collected solving training problems,representative different tasks across domain. Therefore, quality trainingexamples depend variety problems used training qualitysolutions problems. Traditionally, training problems obtained randomgenerators provided parameters tune problems difficulty. way, onefind, domain, kind problems makes learning algorithm generalizeuseful DCK.4. Use learned DCK. Decisions made three issues affect qualitylearned DCK. representation schemes may expressive enough capture effective DCK given domain, learning algorithm may able acquire usefulDCK within reasonable time memory requirements, set training problems maylack significant examples key knowledge. situations, direct uselearned DCK improve scalability planner, could even decrease performance. effective way dealing problem heuristic planners integratinglearned DCK within robust strategies Best-First Search (Yoon et al., 2008)combining domain-independent heuristic functions (Roger & Helmert, 2010).3. ROLLER Systemsection describes general scheme learning DCK instantiated ROLLERsystem. First, describes DCK representation followed ROLLER. Second, explainslearning algorithm used ROLLER. Third, depicts ROLLER collects good quality trainingexamples finally, shows different approaches scaling heuristic planning algorithmslearned DCK.769fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO3.1 Representation Learned Knowledge: Helpful Contexts Heuristic Planningpresent approach following notation specified Planning Domain Definition Language (PDDL) typed STRIPS tasks. Accordingly, definition planning domain comprises definition of:hierarchy types.set typed constants, CD , representing objects present tasks domain.set empty.set predicate symbols, P, one corresponding arity typearguments.set operators O, whose arguments typed variables.Variables declared directly defining operator argument, localoperator definition. call Po set atomic formulas generated usingdefined predicates P, variables defined arguments operator O, generalconstants CD . Then, operator defined three sets: pre(o) Po , operatorpreconditions; add(o) Po , positive effects; del(o) Po , negative effectsoperator.planning task domain tuple < C , s0 , G > C set typedconstants representing objects particular task, s0 set ground atomicformulas describing initial state G set ground atomic formulas describing goals.Given total set constants C = C CD , task defines finite state space finite setinstantiated operators O. state set ground atomic formulas representingfacts true s. States described following closed world assumption. instantiatedoperator action operator variable replaced constant Ctype. Thus, set actions generated using set constants Cset operators O. definition, solving planning task implies finding plansequence actions (a1 , . . . , ), ai transforms initial state stategoals achieved.planning contexts defined ROLLER rely concepts relaxed plan heuristichelpful actions, introduced FF planner (Hoffmann & Nebel, 2001). relaxed planheuristic returns integer evaluated node, number actions solutionrelaxed planning task + node. + simplification original taskdeletes actions ignored. idea delete-relaxation computing heuristics planningfirst introduced McDermott (1996) Bonet, Loerincs Geffner (1997).relaxed plan extracted relaxed planning graph, sequence factsactions layers (F0 , A0 , . . . , , Ft ). first fact layer contains facts initial state.action layer contains set applicable actions given previous fact layer. factlayer contains set positive effects actions appearing previous layers.process finishes goals fact layer, two consecutive facts layersfacts. last case, relaxed problems solution relaxed plan heuristicreturns infinity.770fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REESrelaxed planning graph built, solution extracted backwards process.goal appearing first time fact layer assigned set goals layer, Gi . Then,last set goals, Gt , second set goals, G1 , goal goals set,action selected generates goal whose layer index minimal. Afterwards,precondition action (i.e. subgoal) included goals set corresponding firstlayer fact appears. process finished, set selected actions comprisesrelaxed plan.According extraction process, FF planner marks helpful actions set actionsfirst layer A0 relaxed planning graph achieve subgoals nextfact layer, i.e. goals set G1 . words, helpful actions applicable actionsgenerate facts top-level goals problems required action relaxed plan.Formally, set helpful actions given state defined as:helpful (s) = {a A0 | add(a) G1 6= }FF planner uses helpful actions search pruning technique, considered candidates selected search. Given state generatesparticular set helpful actions, claim helpful actions, together remaining goals static literals planning task, encode helpful context related state.helpful actions remaining target goals relate actions likely appliedgoals need achieved. relations arise helpful actions targetgoals often share arguments (problem objects). Additionally, static predicates expressfacts characterize objects planning task. Identifying objects also relevant sincemay shared arguments helpful actions and/or target goals.Definition 1 helpful context state definedH(s) = {helpful (s), target(s), static(s)}target(s) G describes set goals achieved state s, target(s) = Gstatic(s) set literals always hold planning task. definedinitial state present every state given changed action. Thus,static(s) = {p | @a : p add(a) p del(a)}.helpful context alternative representation tuple <state, goals, applied action>,traditionally used learning DCK planning. Helpful contexts present advantagesimproving scalability heuristic planners:domains, set helpful actions contains actions likely appliedfocusing reasoning shown good strategy.set helpful actions normally smaller set non-static literals state(i.e., static(s)). Thus, process matching learned DCK within search obtainsbenefits using compact representation.number helpful actions normally decreases search fewer goals left.Therefore, matching process become faster search advancing towardsgoals.771fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO3.2 Learning Algorithm: Learning Generalized Policies Relational Decision TreesROLLER implements two-step learning process building DCK collection examplesdifferent helpful contexts:1. Learning operator classifier. ROLLER builds classifier choose best operatordifferent helpful contexts.2. Learning binding classifiers. operator domain, ROLLER builds classifierchoose best binding (instantiation operator) different helpful contexts.learning process split two steps build DCK off-the-shelf learningtools. planning action may different number arguments arguments different types (e.g. actions switch on(instrument,satellite) turn to(satellite,direction,direction) Satellite domain) hinders definition targetclasses. two-step decision process also clearer decision-making point view.helps users understand generated DCK better focusing either decision operator apply bindings use given selected operator. learning algorithmset learning examples two learning steps. Figure 1 shows overviewlearning process ROLLER system.Roller LearnerTrainingProblems1. operator classifierExampleGeneratorPDDLDomainop. examplesRelationalClassificationbind. examplesTool2. binding classifiers...language biasFigure 1: Overview ROLLER learning process.3.2.1 L EARNING R ELATIONAL ECISION RESSclassic approach assist decision making consists gathering significant set previous decisions building decision tree generalizes them. leaves resulting tree containclasses (decisions make), internal nodes contain conditions lead decisions. common way build trees following Top-Down Induction DecisionTrees (TDIDT) algorithm (Quinlan, 1986). algorithm builds tree repeatedly splittingset training examples according conditions minimize entropy examples. Traditionally, training examples described attribute-value representation. Therefore,conditions decision trees represent tests value given attribute examples.Nevertheless, attribute-value approach suitable representing decisions wantkeep predicate logic representation. better approach represent decisions relationally,instance, given action chosen reach certain goals given context share arguments. Recently, new algorithms building relational decision trees examples described772fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REESpredicate logic facts developed. new relational learning algorithms similarpropositional ones, except (1) condition nodes tree refer attribute values,logic queries relational facts holding training examples (2), logic queriesshare variables condition nodes placed decision tree. learning algorithmgreedy search process. Since space potential relational decision trees usually huge,search normally biased according specification syntactic restrictions called language bias.specification contains target concept, predicates appear condition nodestrees learning-specific knowledge type information, input outputvariables predicates.paper use tool TILDE (Blockeel & De Raedt, 1998) learning operatorbinding classifiers. tool implements relational version TDIDT algorithm, althoughoff-the-shelf tool learning relational classifiers could used, PRO GOL (Muggleton, 1995) RIBL (Emde & Wettschereck, 1996). different learningalgorithms would provide different results, since explore classifiers space differently.study pros cons different algorithms beyond scope paper.comprehensive explanation current relational learning approaches please refer work DeRaedt (2008).3.2.2 L EARNING PERATOR C LASSIFIERinputs learning operator classifier are:Training examples. Examples represented Prolog-like syntax consistoperator selected (the class) together helpful context (the background knowledgeterms relational learning) selected. particular, example contains:Class. use predicate arity 3 selected encode operator chosencontext. predicate target concept learning step. first argument holdsexample identifier links rest example predicates. second argumentproblem identifier, links static predicates shared examples comingplanning problem. third argument example class, i.e., nameselected operator helpful context.Helpful predicates. predicates express helpful actions containedhelpful context. predicate symbol predicates helpful ai ainame instantiated action. arguments example problemidentifier together parameters action ai . instantiated action,parameters constants.Target goal predicates. represent predicates appear goalshold current state. predicates form target goal gigi domain predicates. predicate also contains example problemidentifiers.Static predicates. represent static predicates given problem. predicates shared training examples belong planning problem.form static fact fi fi domain predicatesappear effects domain action. arguments problem identifier corresponding arguments domain predicate.773fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJOFigure 2 shows one learning example id tr01 e1 consisting selection operator switch-on associated helpful context. example used buildingoperator classifier Satellite domain.% Example tr01 e1 problem tr01selected(tr01 e1,tr01,switch on).helpful turn to(tr01 e1,tr01,satellite0,groundstation1,star0).helpful turn to(tr01 e1,tr01,satellite0,phenomenon2,star0).helpful turn to(tr01 e1,tr01,satellite0,phenomenon3,star0).helpful turn to(tr01 e1,tr01,satellite0,phenomenon4,star0).helpful switch on(tr01 e1,tr01,instrument0,satellite0).target goal image(tr01 e1,tr01,phenomenon3,infrared2).target goal image(tr01 e1,tr01,phenomenon4,infrared2).target goal image(tr01 e1,tr01,phenomenon2,spectrograph1).% Static Predicates problemstatic fact calibration target(tr01,instrument0,groundstation1).static fact supports(tr01,instrument0,spectrograph1).static fact supports(tr01,instrument0,infrared2).static fact board(tr01,instrument0,satellite0).Figure 2: Knowledge base corresponding example Satellite domain. exampleid tr01 e1, links example predicates. obtained solvingtraining problem tr01 links rest examples problem.selected operator helpful context switch on, corresponds onehelpful actions encoded helpful predicates example.Language bias: bias specifies constraints arguments predicatestraining examples. assume domain-specific constraint, given learningtechnique domain-independent. So, bias contains restrictions argument typesrestrictions ensure identifier variables added new variablesclassifier generation. bias automatically extracted PDDL domain definitionsconsists declaration predicates used learning example argumenttypes. Figure 3 shows language bias specified learning operator classifierSatellite domain.resulting relational decision tree represents set disjoint rules action selectionused provide advice planner: internal nodes tree contain set conditions related helpful context advice provided. leaf nodes containcorresponding advice; case, operator select number examples coveredrule. operator select one selected often trainingexamples covered rule. operator classifiers learned ROLLER also advise nonhelpful actions. Given state, non-helpful actions subset applicable actions stateconsidered helpful actions. Certainly, actions part helpful contexts defined. However, learned operator classifiers indicate name operator selectregardless whether helpful not. Figure 4 shows operator tree learned Satellite774fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES% ---- target concept ---predict(selected(+IdExample,+IdProblem,-Operator)).type(selected(idex,idprob,class)).classes([turn to,switch on,switch off,calibrate,take image]).% ---- helpful context ---% predicates helpful actionsrmode(helpful turn to(+IdExample,+IdProblem,+-S1,+-D1,+-D2)).type(helpful turn to(idex,idprob,satellite,direction,direction)).rmode(helpful switch on(+IdExample,+IdProblem,+-I1,+-S1)).type(helpful switch on(idex,idprob,instrument,satellite)).rmode(helpful switch off(+IdExample,+IdProblem,+-I1,+-S1)).type(helpful switch off(idex,idprob,instrument,satellite)).rmode(helpful calibrate(+IdExample,+IdProblem,+-S1,+-I1,+-D1)).type(helpful calibrate(idex,idprob,satellite,instrument,direction)).rmode(helpful take image(+IdExample,+IdProblem,+-S1,+-D1,+-I1,+-M1)).type(helpful take image(idex,idprob,satellite,direction,instrument,mode)).% predicates target goalsrmode(target goal pointing(+IdExample,+IdProblem,+-S1,+-D1)).type(target goal pointing(idex,idprob,satellite,direction)).rmode(target goal image(+IdExample,+IdProblem,+-D1,+-M1)).type(target goal image(idex,idprob,direction,mode)).% predicates static factsrmode(static fact board(+IdProblem,+-I1,+-S1)).type(static fact board(idprob,instrument,satellite)).rmode(static fact supports(+IdProblem,+-I1,+-M1)).type(static fact supports(idprob,instrument,mode)).rmode(static fact calibration target(+IdProblem,+-I1,+-D1)).type(static fact calibration target(idprob,instrument,direction)).Figure 3: Language bias learning operator classifier Satellite domain. automatically generated PDDL definition. rmode predicates indicateused tree. type predicates indicate types particular rmode.domain. learned decision trees branch denoted symbols +--:<yes/no>,yes indicates next node positive answers current question indicates nextnode negative answers. figure, first branch states calibrateaction set helpful actions, recommendation (in square brackets) choosing action(i.e. calibrate). addition, branch indicates recommended action occurred 44times training examples. Moreover, leaf node information (in double square brack775fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJOets) number times type action selected training examples coveredrule current branch. Thus, case, action calibrate selected 44total 44 times, operators never selected. second branch sayscalibrate helpful action, take image one, planner selectedtake image 110 110 times. helpful calibrate take image actions helpful switch action, switch recommendation,selected 44 59 times. tree branches interpreted similarly.selected(-A,-B,-C)helpful calibrate(A,B,-D,-E,-F) ?+--yes:[calibrate] 44.0 [[turn to:0.0,switch on:0.0,switch off:0.0,|calibrate:44.0,take image:0.0]]+--no: helpful take image(A,B,-G,-H,-I,-J) ?+--yes:[take image] 110.0 [[turn to:0.0,switch on:0.0,switch off:0.0,|calibrate:0.0,take image:110.0]]+--no: helpful switch on(A,B,-K,-L) ?+--yes:[switch on] 59.0 [[turn to:15.0,switch on:44.0,|switch off:0.0,calibrate:0.0,|take image:0.0]]+--no: [turn to] 149.0 [[turn to:149.0,switch on:0.0,switch off:0.0,calibrate:0.0,take image:0.0]]Figure 4: Relational decision tree learned operator selection Satellite domain. Internalnodes (with ? ending) queries helpful contexts. Leaf nodes (in brackets)class number observed examples operator.3.2.3 L EARNING B INDING C LASSIFIERSsecond learning step, relational decision tree built domain operator O.trees indicate bindings select different helpful contexts. inputs learningbinding classifier operator are:Training examples. consist exclusively helpful contexts operatorselected, together applicable instantiations contexts. Notegiven helpful context, applicable instantiations may include helpful nonhelpful actions. Helpful contexts coded exactly previous learning step.applicable instantiations represented selected predicate. predicate target concept second learning step arguments exampleproblem identifiers, instantiated arguments applicable action example class (selected rejected). purpose predicate distinguishgood bad bindings operator. Figure 5 shows piece knowledge basebuilding binding tree corresponding action switch Satellite domain. example, id tr07 e63, resulted selection action instantiation776fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REESswitch on(instrument1,satellite0). action switch on(instrument0,satellite0) also applicable rejected planner.Language bias: bias learning binding trees bias learningoperator tree, except includes definition selected predicate.previous learning step, language bias learning binding tree also automatically extracted PDDL domain definition. Figure 6 shows part language bias specifiedlearning binding tree action switch Satellite domain.% Example tr07 e63 problem tr07selected switch on(tr07 e63,tr07,instrument0,satellite0,rejected).selected switch on(tr07 e63,tr07,instrument1,satellite0,selected).helpful switch on(tr07 e63,tr07,instrument0,satellite0).helpful switch on(tr07 e63,tr07,instrument1,satellite0).helpful turn to(tr07 e63,tr07,satellite0,star1,star2).helpful turn to(tr07 e63,tr07,satellite0,star5,star2).helpful turn to(tr07 e63,tr07,satellite0,phenomenon7,star2).helpful turn to(tr07 e63,tr07,satellite0,phenomenon8,star2).target goal image(tr07 e63,tr07,phenomenon8,spectrograph2).target goal image(tr07 e63,tr07,phenomenon7,spectrograph2).target goal image(tr07 e63,tr07,star5,image1).% Static Predicates problemstatic fact calibration target(tr07,instrument0,star1).static fact calibration target(tr07,instrument1,star1).static fact supports(tr07,instrument0,image1).static fact supports(tr07,instrument1,spectrograph2).static fact supports(tr07,instrument1,image1).static fact supports(tr07,instrument1,image4).static fact board(tr07,instrument0,satellite0).static fact board(tr07,instrument1,satellite0).Figure 5: Knowledge base corresponding example tr07 e63 obtained solving training problem tr07 Satellite domain.result second learning step relational decision tree uninstantiatedoperator O. consists set disjoint rules binding selection o. Figure 7shows example binding tree tswitch built operator switch Satellitedomain. According tree, first branch states helpful actionswitch instrument C satellite D, switch bindings (C, D) selectedplanner 213 249 times. Note binding trees learned ROLLER also advisenon-helpful actions. Frequently, selected predicate matches tree queries referhelpful predicates. cases, no-branch query may cover bindings non-helpfulactions operator.binding trees Satellite domain refer reader Online Appendixarticle, include learned DCK domains used experimental section.777fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO% ---- target concept ---predict(selected switch on(+IdExample,+IdProblem,+INST0,+SAT1,-Class)).type(selected switch on(idex,idprob,instrument,satellite,class)).classes([selected,rejected]).% ---- helpful context ----, operator classification...Figure 6: Part language bias learning binding tree switch actionSatellite domain.selected switch on(-A,-B,-C,-D,-E)helpful switch on(A,B,C,D) ?+--yes: [selected] 249.0 [[selected:213.0,rejected:36.0]]+--no: [rejected] 63.0 [[selected:2.0,rejected:61.0]]Figure 7: Relational decision tree learned bindings selection switch actionSatellite domain.many cases, decision trees somewhat complex one shown Figure 7.instance, turn binding tree 29 nodes includes several queries target goals (e.g.,asking pending image new pointed direction) others static facts (e.g.,asking new pointed direction calibration target).3.3 Generation Training ExamplesROLLER training examples instances decisions made solving training problems. ordercharacterize variety good solutions, decisions consider different alternativessolving individual problem. given search tree node (state), alternatives comepossibility choosing different operators different bindings single operator,cases assuming alternative lead equally good solutions.Regarding binding decisions, actions alternative solutions ignored,tagged rejected consequently introduce noise learning process. instance,consider problem Figure 8 Satellite domain satellite, calibratedinstrument, must turn directions D1,D2 D3 order take images there. planning context, three turn actions helpful actions regarding one solution makeslearning consider one action selected two actions rejected. However, learnedknowledge always recommend helpful turn action towards directionsatellite (with corresponding calibrated instrument) take image. learn kindknowledge, ROLLER consider three turn actions selected three actions correspond selectable actions learning correct knowledge particular planning778fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REEScontext. actions marked rejected learner consider selecting turndescribed context bad choice.takeimage D2S3S4turnto(D2,D3)S5takeimage D3turnto(D1,D2)takeimage D1turnto(D4,D1)S1turnto(D4,D2)S0S1turnto(D4,D3)S1"...S2turnto(D1,D3)S3......Figure 8: Solution path alternatives simplified Satellite problem.Regarding operator decisions, complete training full catalogue different solutionsconfuse learning process. instance, consider example problem Figure 9goal take image direction D2. applying calibrate action s2 , necessaryswitch instrument turn satellite D1 (the calibration target direction).two actions helpful generate two different solution paths. fact, commutative.Generalizing operator selection kinds helpful contexts difficult trainingexamples contain examples types (i.e. examples switch-on action situatedturn-to action vice versa). caused fact helpfulcontext different operators choose equally good choices.S1turnto(D3,D1)switchonS2S0switchoncalibrateS3turnto(D1,D2)S4takeimage D2Gturnto(D3,D1)S1Figure 9: Solution path alternatives simplified Satellite problem.ROLLER follows commitment approach generation training examples: (1) Generation solutions. Given training problem, ROLLER performs exhaustive search obtainmultiple best-cost solutions, taking account alternatives different binding choices. (2)Selection solutions. ROLLER selects subset solutions set best-cost solutionsorder reproduce particular preference operator alternatives. (3) Extraction examples solutions. ROLLER encodes selected subset solutions examples requiredlearning, operator classification binding classification. following sections detail ROLLERproceeds three steps.779GfiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJO3.3.1 G ENERATION OLUTIONSROLLER solves training problem using Best-First Branch Bound (BFS-BnB) algorithmextracts multiple good-quality solutions. search space explored exhaustivelywithin time bound, problem discarded examples generated it. Therefore,training problems need sufficiently small. addition, training problems need representative enough generalize DCK assists ROLLER solving future problemsdomain.BFS-BnB search completed without pruning repeated states. practice, many repeatedstates generated changing order among actions different solution paths. Thus, pruningrepeated states would involve tagging actions leading solutions rejected bindings,fact true. addition, BFS-BnB algorithm prunes according evaluationfunction f (n) = g(n) + h(n), g(n) node cost (in work use plan lengthcost function) h(n) FF heuristic. safe way prune search space usingadmissible heuristic. However, existing admissible heuristics allow ROLLER completeexhaustive search problems reasonable size. practice, using FF heuristic producesoverestimations introduces negligible noise learning process. endsearch, BFS-BnB algorithm returns set solutions best cost. solutionsused tag nodes search tree belong solutions label solution.3.3.2 ELECTING OLUTIONSset best-cost solutions found, ROLLER selects subset solutions usedgenerating training examples. Since difficult develop domain-independent criteria systematically selecting solutions reproduce operator selection particular context,defined approach which, heuristically, prefers actions others. preferencesare:Least-commitment preference: Prefer actions generate alternatives different solution paths.Difficulty preference: Prefer actions reach goals sub-goals difficultachieve. example Figure 9 instrument switched achievableone action. hand, pointing direction D1 considered easier sinceachieved actions turn to(D2,D1) turn to(D3,D1).Given 0 = a1 , . . . , , best-cost plan planning task, compute preferencesfunctions depending action.commitment (ai ) =| {a0 | a0 successors(ai ) solution(a0 )} |function successors(ai ) returns applicable actions state si+1 function solution(a)verifies whether action tagged part best-cost plan.difficulty (ai ) =min1| supporters(l) |ladd(ai )function supporters(l) = {a | l add(a)} returns set actions achieveliteral l.780fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REESSolutions ranked according preferences. ranking solution 0 =a1 , . . . , computed weighted sum action preferences, follows:ranking( 0 , ) =Xi=0,...,n1(n i)(ai+1 )nn plan length one commitment difficulty . sum weightedgive importance preferences first actions plan. first action preferencevalue multiplied 1, second (n 1)/n, on. Otherwise, several alternatives (i.e.,commutative actions different positions within plan) would lead ranking value.compute ranking best-cost solutions using commitment . Ties ranking brokenranking computed difficulty . subset solutions best ranking valuessubset solutions selected generating training examples.3.3.3 E XTRACTING E XAMPLES OLUTIONStakes subset solutions selected previous step generates training examples. generating examples operator classification, ROLLER takes solution plans 0 ={a1 , a2 , ..., } correspond sequence state transitions {s0 , s1 , ..., sn } generatesone learning example pair < si , ai+1 > consisting H(si ) class (i.e., operatorname action ai+1 ). See learning example shown Figure 2.generating examples binding classification operator o, ROLLER considerspairs < si , ai+1 > ai+1 matches operator o. learning example generated pair< si , ai+1 > binding selection operator consists H(si ) classesapplicable actions si match o, including ai+1 . Applicable actions solution labelbelong selected class applicable actions rejected class. Moreover, actionsbelonging solutions top ranking still marked selected even thoughnodes example generated. See learning example shown Figure 5.ROLLER3.4 Use Learned Knowledge: Planning Relational Decision Treessection details make heuristic planning benefit DCK, beginningbuild action orderings learned DCK. Then, explains two different search strategiesexploit orderings: (1) application DCK generalized action policy (DepthFirst H-Context Policy algorithm) (2) use DCK generate lookahead states withinBest-First Search (BFS) guided FF heuristic (H-Context Policy Lookahead-BFS algorithm).3.4.1 RDERING ACTIONS R ELATIONAL ECISION REESGiven state s, expression app(s) denotes set actions applicable s. learned DCKprovides ordering app(s). ordering built matching action app(s) firstoperator classifier corresponding binding classifier. Figure 10 shows detailalgorithm ordering applicable actions relational decision trees.algorithm divides set applicable actions two subsets: helpful actions,non-helpful actions. Then, matches helpful context state, i.e., H(s), treeoperator classification. matching provides leaf node contains list operatorssorted number examples covered leaf training phase (see operator781fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJODT-Filter-Sort (A,H,T):sorted list applicable actionsA: List actionsH: Helpful ContextT: Decision Treesselected-actions =HA = helpful-actions(A, H)NON-HA = \ HAleaf-node = classify-operators-tree(T, H)HApriority(a) = leaf-node-operator-value(leaf-node, a)priority(a) > 0(selected(a),rejected(a)) = classify-bindings-tree(T, H, a)selected(a)selection ratio(a)= selected(a)+rejected(a)priority(a) = priority(a) + selection ratio(a)selected-actions = selected-actions {a}max-HA-priority = maxaselected-actions priority(a)NON-HApriority(a) = leaf-node-operator-value(leaf-node,a)priority(a) > max-HA-priority(selected(a),rejected(a)) = classify-bindings-tree(T, H, a)selected(a)selection ratio(a)= selected(a)+rejected(a)priority(a) = priority(a) + selection ratio(a)selected-actions = selected-actions {a}return sort(selected-actions, priority)Figure 10: Algorithm ordering actions using relational decision trees.classification tree Figure 4). number examples covered gives operator orderingused prefer actions search. algorithm uses number initializepriority value helpful action, taking value corresponding operator. algorithmkeeps helpful actions least one matching example. actions,algorithm matches action corresponding binding classification tree. resulting leafbinding tree returns two values: number times ground action selected,number times rejected training phase. define selection ratio groundaction as:selected(a)selection ratio(a) =selected(a) + rejected(a)ratio represents proportion good bindings covered particular leaf bindingtree. denominator zero, selection ratio assumed zero. priorityaction updated adding selection ratio. Thus, final priority action higher782fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REESactions operators operator classification tree provides higher values, i.e.selected often training examples. Since selection ratio remains 01, adding number considered method breaking ties initial priorityvalue, using information binding classification tree.priority non-helpful actions computed similar way except that, case,algorithm considers actions whose initial priority (the value provided operator classification tree), higher maximum priority helpful actions. manner, captureuseful non-helpful actions. FF follows heuristic criterion classify action helpful. Althoughheuristic shown useful, case may arise useful actionparticular moment classified helpful. Decision trees capture information, givenrecommend choosing non-helpful action. described method takes advantagefact defines way using information applying learned knowledge. alternative approach would extend planning context new meta-predicate non-helpfulactions. However, pay variety problems domains means significantly larger contexts, causes expensive matching. Finally, selected actionssorted order decreasing priority values. sorted list actions output algorithm.3.4.2 H-C ONTEXT P OLICY LGORITHMhelpful context-action policy algorithm moves forward, applying state best actionaccording DCK. pseudo-code algorithm shown Figure 11. algorithmmaintains ordered open-list. open-list contains states expanded extractedorder. extracted, state evaluated using FF heuristic. Thus, evaluate uponextraction nodes included open-list. evaluation provides heuristicvalue state, h, set helpful actions HA, needed generate helpfulcontext. heuristic value used for: (1) continuing search state recognizeddead-end (h = ), (2) goal checking (h = 0). Then, helpful context generated. Subsequently, algorithm obtains set AA actions applicable state sorts usingdecision trees (as shown algorithm Figure 10). result AA0 AA, sorted listapplicable actions. algorithm inserts successors generated actions AA0 beginning open-list preserving ordering (function push-ordered-list-in-open).Furthermore, make algorithm complete robust, successors generated applicableactions AA0 included secondary list called delayed-list. delayed listused open-list empty. case, one node delayed-list movedopen-list then, algorithm continues extracting nodes open-list.algorithm, node maintains pointer parent order recover solutionfound. Also, node maintains g value, i.e. length pathinitial state node. function push-ordered-list-in-open insertsopen list candidates that: (1) repeated states, (2) repeated states lower gvalue previous one. Otherwise, repeated states pruned. type pruning guaranteesmaintain node shortest solution found.words, proposed search algorithm depth-first search delayed successors.benefit algorithm exploits best action selection policy per783fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJODepth-First H-Context Policy (I, G, ): planI: Initial stateG: Goals: Decision Treesopen-list = {I};delayed-list = ;open-list 6=n = pop(open-list)(h, HA) = evaluate(n, G) /*compute FF heuristic*/h = /*recognized dead-end*/continueh = 0 /*goal state*/return path(I, n)H = helpful-context(HA, G, n)AA = applicable-actions(n)AA = DT-Filter-Sort(AA, H, )candidates = generate-successors(n, AA)open-list = push-ordered-list-in-open(candidates,open-list)delayed-candidates = generate-successors(n, AA \ AA)delayed-list = push-ordered-list(delayed-candidates, delayed-list)open-list = delayed-list 6=open-list = { pop(delayed-list) }return failFigure 11: depth-first algorithm sorting strategy given DCK.fect1 action ordering not. Particularly, perfect DCK directly appliedbacktrack-free search inaccurate DCK force search algorithm backtrack.3.4.3 H-C ONTEXT P OLICY L OOKAHEAD TRATEGYmany domains learned DCK may contain flaws: helpful context may expressiveenough capture good decisions, learning algorithm may able generalize welltraining examples may representative enough. cases, direct applicationlearned DCK (without backtracking) may allow planner reach goals problem.Poor quality learned DCK balanced guide different naturedomain-independent heuristic. successful example ObtuseWedge system (Yoon et al.,2008) combined learned generalized policy FF heuristic. ObtuseWedge exploitedlearned policy synthesize lookahead states within lookahead strategy. Lookahead states1. perfect policy refer policy leads directly goal state. policies guaranteed perfectgiven generated inductive learning.784fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REESfirst applied heuristic planning YAHSP planner (Vidal, 2004). intermediatestates frequently closer goal state direct descendants current state.intermediate states added list nodes expanded used withindifferent search algorithms. learned policy contains flaws, lookahead states synthesizedpolicy may provide good guidance search. However, lookahead statesincluded complete search algorithm also considers ordinary successors, searchprocess becomes robust. general, use lookahead states forward state-spacesearch slightly increases branching factor search process, overall, shownYAHSP planner IPC-2004 experiments included YAHSP paper (Vidal, 2004),approach seems improve performance significantly.Figure 12 shows generic algorithm using lookahead states generated policysearch. algorithm weighted Best-First Search (BFS), modification one lookahead states inserted open list expanding node.weighted BFS, nodes expanded maintained open list ordered evaluationfunction f (n) = h(n) + g(n). Apart usual arguments BFS, algorithm receivespolicy (P ) horizon. horizon represents maximum number policy stepsapplied generating lookahead states. experiments, use algorithmFF heuristic h(n).H-Context Policy Lookahead BFS (I,G,T ,horizon): planI: Initial stateG: Goals: Decision Trees (policy)horizon: horizonopen-list =add-to-open(I)open-list 6=n = pop(open-list)goal-state(n, G)return path(I, n)add-to-open-lookahead-successors(n, G, T, horizon)add-to-open-standard-successors(n)return failFigure 12: Generic Lookahead BFS algorithm.heuristic evaluation, h(n), g-value, g(n), set helpful actions, also savednode node evaluated. function add-to-open(state) evaluatesstate inserts open-list, ordered increasing values evaluation function,f (n). function also prunes repeated states, following strategy described DepthFirst H-Context Policy algorithm: repeated states higher g(n) existent one785fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJOpruned. function add-to-open-standard-successors(n) calls add-to-opensuccessor node n. function add-to-open-lookahead-successors explained below.adapted generic Lookahead BFS algorithm learned DCK. particularinstantiation function add-to-open-lookahead-successors shown Figure 13.case, lookahead states generated iteratively applying first action action ordering provided DCK. inputs algorithm current state, problem goals,decision trees horizon. First, algorithm generates helpful context applicableactions. helpful actions, n.HA, recovered node. Then, algorithm sorts applicable actions using decision trees (as previously shown algorithm Figure 10).that, successor generated first action inserted open list, recursivecall successor horizon decremented one. function add-to-open returnstrue argument added open list false otherwise. fact, returnsfalse two cases: (1) state repeated state g-value higher g-valueexistent state2 (2) state recognized dead-end. ordered list becomes empty,lookahead state generated initial node returned. occurshorizon zero. described implementation similar lookahead strategy approachfollowed ObtuseWedge, instead perform lookahead generation using helpful contextsrelational decision trees.hand, described H-Context Policy Lookahead BFS algorithm searchperfomed set applicable actions node. However, many domains usehelpful actions shown good heuristic. One possible way prioritizing helpfulactions non-helpful actions include open list successors given helpfulactions, include remaining successors secondary list. implemented ideafollowing strategy used Depth-first H-Context Policy algorithm: open listbecomes empty one node passed secondary list open list, searchcontinues. algorithm still complete given prune successor. helpfulactions good enough, strategy save many heuristic evaluations. experimentscompare strategy previous one. intuition adequacystrategy depends directly quality helpful actions, quality learned DCK,accuracy heuristic particular domain.Another technique prioritizing helpful actions BFS implemented YAHSP (Vidal,2004) inserts two consecutive instances node open list. nodesequal f (n) since represent state. first one contains helpful actions,therefore, expanded, generates successors resulting actions. secondcontains non-helpful actions, called rescue actions. way, successors lowerf (n) parent node sub-tree generated helpful actions expandedsuccessor resulting non-helpful actions.performed preliminary experiments, obtaining similar results two described methods prioritizing helpful actions BFS: use secondary list non-helpfulactions, use rescue nodes. reason, include results first techniqueexperimental section. call algorithm H-Context Policy Lookahead BFS-HA.2. state repeated g-value smaller existent one, add-to-open re-evaluateinstead takes heuristic evaluation existent state.786fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REESadd-to-open-lookahead-successors (n,G,T ,horizon) :staten: Node (state)G: Goals: Decision Trees (policy)horizon: horizonhorizon = 0return nH = helpful-context(n.HA, G, n)AA = applicable-actions(n)AA0 = DT-Filter-Sort(AA, H, )AA0 6== pop(AA0 )n0 = generate-successor(n, a)added = add-to-open(n0 )addedgoal-state(n0 , G)return n0return add-to-open-lookahead-successors(n0 , G, , horizon 1)return nFigure 13: Algorithm generating lookahead states decision trees.4. Experimental Resultssection evaluate performance ROLLER system. evaluation carriedvariety domains belonging diverse IPCs: Four domains come learning trackIPC-2008 (Gold-miner, Matching Blocksworld, Parking Thoughtful). rest domains(Blocksworld, Depots, Satellite, Rovers, Storage TPP) selected among domainssequential tracks IPC 2000 2008 presented different structuredifficulty, available random problem generators, automatically build training sets learning DCK. domain, complete training phaseROLLER learns corresponding DCK testing phase evaluate scalabilityquality solutions found ROLLER learned DCK. Next, detail experimentalresults obtained two phases. Moreover, domains give particulardetails training test sets, learned DCK observed ROLLER performance.4.1 Training Phasedomain, built training set thirty randomly generated problems. sizestructure problems discussed particular details given domain.explained section 3.2, ROLLER generates training examples solving problems787fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJOtraining set BFS-BnB search. set time-bound 60 seconds solve trainingproblem, discarding exhaustively explored time-bound. Then, ROLLERgenerates training examples solutions found builds corresponding decisiontrees TILDE system (Blockeel & De Raedt, 1998).evaluate efficiency ROLLER training phase computed following metrics:time needed solving training problems, number training examples generatedprocess, time spent TILDE learning decision trees number leavesoperator selection tree. last number gives clue size learned DCK. Table 1shows results obtained domain.DomainBlocksworldDepotsGold-minerMatching-BWParkingRoversSatelliteStorageThoughtfulTPPTrainingTime (s)836.0456.21156.9865.8105.8528.319.8136.3883.4995.9LearningExamples254249312643044210111702677502560LearningTime (s)13.323.14.512.47.013.613.45.1352.223.3TreeLeaves1813523122446196Table 1: Experimental results training process. Training learning times shown,well number training examples, complexity generated trees (numberleaves).achieves shorter Learning Times, fourth column Table 1, state-of-the-artsystems learning generalized policies (Martin & Geffner, 2004; Yoon et al., 2008). Particularly,systems implement ad-hoc learning algorithms sometimes require hours orderobtain good policies, approach needs seconds learn DCK given domain.fact makes approach suitable architectures need on-line planning learning processes. However, learning times constant different domains, dependnumber training examples (in work, number given amount differentsolutions training problems), size training examples (in work sizegiven number arity predicates actions planning domain) trainingexamples structured, i.e., whether examples easily separated learning not.ROLLER4.2 Testing Phasetesting phase ROLLER attempts solve, domain, set thirty test problems.problems taken evaluation set corresponding IPC. evaluation setcontains problems, thirty problems thirty hardest ones. Depots domainexception twenty-two problems, evaluation set domain IPC-2002788fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REEScontained twenty-two problems. Three experiments made testing phase.first one evaluates ROLLERs performance DCK learned solutions trainingproblems ranked solution approach. second one evaluates usefulnesslearned DCK third one compares ROLLER state-of-the-art planners. experiment evaluate two different dimensions solutions found ROLLER: scalabilityquality. testing experiments done using 2.4 GHz processor time-bound 900seconds3 6Gb memory-bound.4.2.1 OLUTION R ANKING E VALUATIONexperiment evaluates effect selecting solutions following approach described Section 3.3. ROLLER configurations evaluation are:Top-Ranked Solutions: Depth-First H-Context Policy algorithm using DCK learnedsub-set top ranked solutions. use search algorithm, since performance depends quality learned DCK algorithmsusing DCK.Solutions: Depth-First H-Context Policy algorithm using DCK learned solutions obtained BFS-BnB algorithm.Table 2 shows number problems solved configuration, also time planlength average computed problems solved configurations. number bracketsfirst column number problems solved common. Top-ranked solutions configuration solved thirty problems solutions configuration, mainly due difference21 problems Matching Blocksworld domain.DomainsBlocksworld (30)Depots (18)Gold-miner (30)Matching-BW (0)Parking (30)Rovers (27)Satellite (28)Storage (10)Thoughtful (12)TPP (30)TotalTop-Ranked SolutionsSolvedTime Length300,62170,0210,94489,1300,0165,321304,90148,9281,40166,03011,21123,6150,009,0121,25249,7300,97147,1247SolutionsSolvedTime Length302,39550,7180,97607,3300,0165,30302,2056,22931,20355,82811,47121,6100,009,0121,28249,2300,90132,8217Table 2: Problems solved time plan length average evaluation ranking solutionheuristic.effect selecting solutions varies across domains. instance, quite important regarding plan quality Blocksworld, Depots Rovers. Satellite domain top-rankedsolutions allow ROLLER solve two problems maintaining similar time plan length3. 900 seconds time-bound established learning track IPC-2008.789fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJOaverage. Gold Miner domain, selecting solutions irrelevant equallygood solutions per problem (i.e., goal always single fact gold) fairlytop-ranked ones. Parking domain benefit selecting solutions.Considering overall results, think selecting solutions useful heuristic improvingDCK quality many domains. remaining evaluations refer DCK usedROLLER decision trees learned top-ranked solutions.4.2.2 DCK U SEFULNESS E VALUATIONshown IPC Learning Track results, DCK may degrade performance base planner,DCK incorrect. mind, designed experiment measure performance ROLLER algorithms comparing versions without DCK. made two versionsnon-learning algorithms. first one empty configuration decisiontree given algorithm, thus ordering computed helpful actions, second onesystematic configuration, ordering supplied FF heuristic instead.ROLLER configurations used comparisons are:ROLLER: Depth-First H-Context Policy algorithm DCK learned trainingphase.ROLLER-BFS: H-Context Policy Lookahead BFS algorithm DCK learnedtraining phase. configuration uses horizon h = 100. choose valuebasis empirical evaluations.ROLLER-BFS-HA: modified version ROLLER - BFS helpful actions considered immediate successors. lookahead states generated original version, using also horizon.three algorithms equivalent version empty configuration:DF-HA (Depth-first Helpful Actions): empty DCK ROLLER corresponds depthfirst algorithm helpful actions. original algorithm, non-helpful actionsplaced delayed list.BFS: empty DCK ROLLER - BFS generate lookahead states (i.e., algorithm add-to-open-lookahead-successors Figure 12). Therefore, algorithm becomesstandard Best-first Search.BFS-HA: modified version BFS helpful actions considered. Non-helpfulactions placed delayed list.Previous configurations also systematic version. case action ordering computedFF heuristic:GR-HA (Greedy Helpful Actions): algorithm corresponds greedy searchhelpful actions. node, helpful immediate successors sorted FF heuristic.Non-helpful nodes go delayed list.LH-BFS (Lookahead-BFS): BFS lookahead states. function DT-Filter-Sortreplaced function computes ordering using FF heuristic.790fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REESLH-BFS-HA: modified version LH - BFS helpful actions considered. Nonhelpful actions placed delayed list.comparison, computed number problems solved scores usedIPC-2008 learning track evaluate planners performance terms CPU time quality (planlength). time score computed follows: problem planner receives Ti /Tipoints, Ti minimum time participant used solving problem i, TiCPU time used planner question. 30 problem test set planner receive 30points, higher score better. quality score computed way, replacingL, L measures quality terms plan length. addition compute timequality averages problems solved configurations. configuration solveproblem, taken account measure. Average measures complement scoressince give direct information commonly solved problems, scores tend benefitconfigurations solve problems others not.Table 3 shows summary results obtained DCK usefulness evaluation.configuration compute number domains algorithm top performerevaluated criteria (i.e., numbers solved problems, time quality scores averages). top performer domain algorithm equal better measurerest algorithms. table, algorithm 10 points, numberevaluated domains. Global section refers overall top performers. Relative section refersnumber domains configuration equal better two configurationsalgorithm strategy (i.e., depth-first, best-first, best-first helpful actions). averagescommonly solved problems computed configurations solve one problem. Results show ROLLER good number solved problems speed metrics.Regarding quality score, ROLLER ROLLER - BFS - HA best performers three domainseach. However, BFS BFS - HA obtained better results quality average.GlobalSolved ProblemsTime ScoreTime AverageQuality ScoreQuality AverageRelativeSolved ProblemsTime ScoreTime AverageQuality ScoreQuality AverageDEPTH-FIRSTroller gr-ha df-ha722810911310000899753113520100BEST-FIRSTroller-bfs lh-bfs10001010127894131142bfs1001321027HELPFUL BEST-FIRSTroller-bfs-ha lh-bfs-ha bfs-ha511100100312015997723011121227Table 3: Summary DCK usefulness evaluation. column gives number domainsconfiguration top performer row item.Table 4 shows number solved problems DCK usefulness evaluation. Totalrow shows ROLLER configuration solved problems empty systematicversions. Results time quality scores reported Table 9 Table 10 Appendix A.791fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJODetailed results averages considered less interesting since many domainscommon solved problems, easy problems.DomainsBlocksworld (30)Depots (22)Gold-miner (30)Matching-BW (30)Parking (30)Rovers (30)Satellite (30)Storage (30)Thoughtful(30)TPP (30)TotalDEPTH-FIRSTroller gr-ha df-ha301021181830002100302512830303023221591012150303030247151111BEST-FIRSTroller-bfs lh-bfsbfs800201913171716147143011726281125221519182020141116249195160 116HELPFUL BEST-FIRSTroller-bfs-ha lh-bfs-ha bfs-ha800202020300019101730119303030302323191010231612192614228146135Table 4: Problems solved DCK usefulness evaluation.4.2.3 IME P ERFORMANCE C OMPARISONexperiment evaluates scalability ROLLER system, compared state-of-the-art planners. comparison, chosen LAMA (Richter & Westphal, 2010), winnersequential track past IPC, FF, last IPC shown still competitive.used three ROLLER configurations explained previous evaluation. configurationplanners are:FF. Running Enforced Hill-Climbing (EHC) algorithm helpful actions togethercomplete BFS case EHC fails 4 . Though planner dates 2001 includeevaluation because, shown results IPC-2008, still competitivestate-of-the-art planners. Besides, planner extensively used planninglearning systems.LAMA-first. winner classical track IPC-2008. configuration LAMAmodified stop finds first solution. way, comparison fairrest configurations implement anytime behavior, i.e., continuous solutionrefinement reaching time-bound). anytime behavior LAMA compared laterROLLER performance next section.Table 5 shows number problems solved together speed score. resultsgive overall view performance different planners. ROLLER solves manyproblems configuration 6 10 domains achieves top speed scoreseven domains. second best score belongs ROLLER - BFS - HA, solves manyproblems planners six domains. LAMA-first fairly competitive, since solves sevenproblems less ROLLER 13 problems ROLLER - BFS - HA. cases LAMA-firstachieves lower speed score.4. planner actually Metric-FF running STRIPS domains. consider implementation adequate baselinecomparison ROLLER implemented code rather original FF order extendapproach planning models.792fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REESDomain (problems)Blocksworld (30)Depots (22)Gold-miner (30)Matching-BW (30)Parking (30)Rovers (30)Satellite (30)Storage (30)Thoughtful(30)TPP (30)TotalROLLERsolvedscore3029.872119.863026.002114.843028.572824.823022.601511.021211.993029.50247219.07ROLLER-BFSsolvedscore82.472011.01170.03141.323022.722613.412514.611912.312012.381614.83195 105.09ROLLER-BFS-HAsolvedscore82.402011.46305.35191.713023.603016.243018.331916.172313.091913.97228122.32FFsolved020279242922171426188score0.008.700.220.270.945.515.3110.518.166.2745.89LAMA-firstsolvedscore170.17203.882912.242520.02231.693018.592815.66199.032011.29309.66241102.23Table 5: Problems solved speed score five configurations.Table 6 shows average time five configurations addressing subset problems solved configurations. first column shows parenthesis number commonlysolved problems. results closely related shown Table 5. ROLLER achievesbest average time eight ten domains. also observe different configurationsgood particular domains even particular problems. instance, Thoughtfuldomain four problems solved configurations.Domain (problems)Blocksworld (7)Depots (18)Gold-miner (17)Matching-BW (6)Parking (22)Rovers (25)Satellite (22)Storage (14)Thoughtful(4)TPP (16)ROLLER0.360.840.001.991.861.371.2411.741.490.02ROLLER-BFS66.3115.5349.8242.252.9124.387.080.0110.840.02ROLLER-BFS-r67.992.540.0244.532.789.831.870.039.520.02FF4.010.2874.9074.0242.8218.230.0514.520.70LAMA-first139.6961.730.011.96108.221.591.330.193.550.10Table 6: Planning time averages problems solved configurations.4.2.4 Q UALITY P ERFORMANCE C OMPARISONexperiment compares quality first solutions found solutions foundanytime behavior. anytime configuration, planners exhaust time-bound trying improveincrementally best solution found. Three ROLLER algorithms modified configurationbest solution found far used upper-bound order prune nodesexceed plan length. anytime behavior regular configuration LAMA. FFanytime behavior, included anytime comparison well basecomparing quality improvements planners.Table 7 shows quality scores first solution last solution foundanytime configurations. anytime column planner shows score variation revealswhether planner able make relative improvements first solutions. relative793fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJODomainBlocksworldDepotsGold-minerMatching-BWParkingRoversSatelliteStorageThoughtfulTPPTotalROLLERfirst anytime29.8329.838.509.2614.3018.009.439.5219.3817.0421.3821.3928.6528.8113.4113.466.276.2125.3824.26176.53177.35ROLLER-BFSfirst anytime8.008.0012.3917.0111.5017.0013.0112.4324.2423.9821.7821.5923.2023.0015.6918.3815.9315.1214.4515.09160.19171.65ROLLER-BFS-HAfirstanytime8.008.0012.8518.9513.0815.3917.6717.1624.2425.5125.6626.1428.1828.9415.6417.2618.6318.3516.8017.77180.75193.53FFfirst0.0019.0127.008.2321.5328.6621.5516.2313.9623.42179.59relative0.0017.9627.007.1517.7928.3321.3315.8013.0921.56170.06LAMAfirst anytime7.428.2918.3219.2814.0426.8123.2524.7219.1622.5628.2628.9727.0227.4217.2418.8118.8418.5929.9929.82203.54219.24Table 7: Quality scores first solution anytime configuration evaluated planners.FF shows score solutions compared solutions given anytime configurationplanners. FF loses points cases others able improvesolutions. two LAMA configurations obtained top score category. Nevertheless,planner dominated domains. Furthermore, configurations achieved top quality scorefirst solution least one domain.DomainBlocksworld (7)Depots (18)Gold-miner (17)Matching-BW (6)Parking (22)Rovers (25)Satellite (22)Storage (14)Thoughtful(4)TPP (16)ROLLERfirstanytime146.29146.29385.78372.2255.6538.18186.00170.3396.9193.82150.80149.9678.4177.5943.0742.64292.25291.7560.2557.00ROLLER-BFSfirstanytime142.86142.8681.7854.0030.0619.6575.0070.0075.3259.86115.56115.5680.0580.0015.2111.36168.50168.2560.0052.06ROLLER-BFS-HAfirstanytime142.86142.8676.8343.3347.8839.3576.0069.3375.3254.45114.40112.1280.0577.3215.6413.29168.50164.5060.2549.38FFfirst46.3919.6571.6760.0094.2077.1812.43123.2559.19relative46.3919.6571.6760.0094.2077.1812.43123.2559.19LAMAfirstanytime358.57318.0049.2841.5643.3519.6578.3362.3364.1447.91101.4498.3676.9175.5012.7111.29140.25128.5051.8147.94Table 8: Quality averages first solution anytime configuration evaluated planners.Table 8 shows plan length average problems solved configurations. firstcolumn shows average first solutions anytime column gives averagelast solutions anytime configuration. commonly solved problemsreported Table 6. Although FF planner solved fewer problems, achievesbest average plan length seven domains. Plan length averages reveal ROLLER ablefind first solutions good quality domains. ROLLER - BFS ROLLER - BFS - HA findbetter quality solutions ROLLER, several domains, averages competitiveLAMA . ROLLER - BFS ROLLER - BFS - HA show better quality performance mainly duecombination learned DCK domain-independent heuristic within BFS algorithm.following subsections discuss particular details domains. givebrief description domain together information training test sets usedexperimental evaluation. domain, also analyze learned DCK obtained794fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REESresults order give fine-grained interpretation observed performance. detailsdomains found IPC web site.54.2.5 B LOCKSWORLD ETAILSProblems domain concerned configuring towers blocks using robotic arm.training set used experiments consisted of: ten eight-block problems, ten nine-blockproblems ten ten-block problems. test set consisted 30 largest typed problemsIPC-2000, 36 50 blocks.blocksworld domain100ROLLERROLLER-BFSROLLER-BFS-HALAMA-firstPercentage solved8060402000.1110CPU Time1001000Figure 14: Percentage solved problems increasing time evaluating scalability performance Blocksworld domain.Although domain one oldest benchmarks automated planning, still challenging state-of-the-art heuristic planners. Blocksworld presents strong interaction among goalscurrent heuristics fail capture. particular, achieving goal domain may undopreviously satisfied goals. Therefore, crucial achieve goals specific order. DCKlearned ROLLER gives total order domain actions different contexts capturing keyknowledge, lets ROLLER achieve impressive scalability results producing good qualitysolution plans. ROLLER configurations considerably better non-learning configurations.Particularly, ROLLER solved thirty problems set DF - HA GR - HA solveproblem. ROLLER also quite good compared state-of-the-art planners. Figure 14observe ROLLER performs two orders magnitude faster LAMA. x-axisfigure represents CPU time logarithmic scale y-axis represents percentagesolved problems particular time. Moreover, ROLLER obtained best quality score firstsolution anytime evaluations. addition, average plan length common problems fairlyclose best average, obtained ROLLER - BFS ROLLER - BFS - HA. BFS algorithms5. http://idm-lab.org/wiki/icaps/index.php/Main/Competitions795fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJOscale well domain partially guided FF heuristic, considerablyunderestimates distance goals. Similarly, lookahead states generated policydiscarded fail escape plateaus generated heuristic function.analyzing learned operator tree found explanations good performanceROLLER Blocksworld domain: operator tree clearly split two parts. first part contains decisions take arm holding block. situation, tree capturesSTACK PUT-DOWN block. second part contains decisions take arm empty.case tree captures UNSTACK PICK-UP block. second part tree,current state search matches logical query helpful unstack(Block1,Block2)6means tower blocks Block1 well arranged, i.e., Block1 leastone block beneath Block1 well placed. Therefore, set helpful actions compactlyencodes useful concept bad tower. kind knowledge manually definedprevious works order learn good policies Blocksworld. One approach consisted including recursive definitions new predicates, support predicates above(X,Y)inplace(X) (Khardon, 1999). Another alternative involved changing representation language, instance concept language (Martin & Geffner, 2004) taxonomic syntax (Yoon,Fern, & Givan, 2007). Kleene-star operator taxonomic syntax (i.e., operator defining recursion) discarded subsequent work (Yoon et al., 2008) predicateused instead. ROLLERs ability recognize bad-towers without extra predicates arisesmisplaced block tower makes UNSTACK action top block helpful, since alwayspart relaxed plan arm empty.Due extraordinary performance ROLLER domain, built extra test setclarify whether trend observed ROLLER configuration would hold largerproblems. aim, randomly generated 30 problems distributed sub-sets 50, 60, 70,80, 90 100 blocks 5 problems sub-set. ROLLER solved 30 problemsextra test set time average 20.1 seconds per problem spending 175.3 solveproblem. Obviously, problems became difficult ROLLER number blocks increase.4.2.6 EPOTS ETAILSdomain combination transportation domain Blocksworld domain,crates instead blocks hoists instead robot arm. problems consist truckstransporting crates around depots distributors. Using hoists, crates stacked onto palletstop crates final destination. domain, 30 training problemsdifferent combinations 2 3 locations (depots distributors), 1 2 trucks, 1 2 pallets perlocation, 1 hoist per location 2 5 crates placed different configurations.testing phase used 22 problems IPC-2002 set. hardest problem 12locations (1 2 pallets 1 2 hoists), 6 trucks 20 crates.ROLLER ROLLER - BFS improve performance non-learning strategies, threeconfigurations BFS Helpful-Action solved 20 problems. ROLLER able solve 21problems, achieving best speed score. However, high average plan length indicatespolicy producing good quality plans. ROLLER - BFS - HA obtains second best speed scorecompetitive plan lengths. Figure 15 shows percentage solved problems6. explained section 3.2 logic queries ROLLER present example problem Ids. case Idsignored simplicity given needed matching current helpful context.796fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REESincreasing CPU time (in logarithmic scale). anytime configuration, ROLLER - BFS - HAable refine solutions, achieving quality average similar LAMA.depots domain100ROLLERROLLER-BFSROLLER-BFS-HAFFLAMA-firstPercentage solved8060402000.010.11101001000CPU TimeFigure 15: Percentage solved problem increasing time evaluating scalability performance Depots domain.DCK learned domain provides inaccurate advice large planning contexts.instance, ROLLER makes mistakes deciding crate unload several cratesloaded truck. reason inaccurate DCK training problems largeenough gain knowledge. addition, adding crates problems makes unfeasible solved BFS-BnB. Nevertheless, limitation learned DCKevident. Depots domain undirected (i.e., actions reversible),dead ends. Therefore, mistakes made DCK fixed additional actions, leadsworse quality plans. Besides, since first solutions rapidly found, ROLLER configurationsspend time refining solutions. reason great improvement plan averageROLLER - BFS - HA .4.2.7 G OLD -M INER ETAILSobjective domain navigate grid cells reaching cell containing gold.cells occupied rocks cleared using bombs laser. domaintraining set consists of: 10 problems 3 3 cells, 10 problems 4 4 cells, 10problems 5 5 cells. domain part learning track IPC-2008 usedtest set used competition. set problems ranging 5 5 7 7 cells.Problems Gold-Miner domain solvable helpful actions alone. explainsdifference number solved problems ROLLER, ROLLER - BFS - HA nonlearning counterpart. general terms, domain trivial ROLLER, ROLLER - BFS - HA (theysolved test problems less 10 seconds per problem) LAMA. Nevertheless, FF scales797fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJOpoorly. domain essential actions picking bombs frequently consideredhelpful actions, relaxed problem solvable using laser. Consequently, FF failssolve problems EHC requires additional BFS search. Figure 16 showspercentage solved problems increasing CPU time. Regarding anytime evaluation,tested configurations improved first solution found many problems.gold-miner domain100Percentage solved80604020ROLLERROLLER-BFSROLLER-BFS-HAFFLAMA-first00.010.11101001000CPU TimeFigure 16: Percentage solved problems increasing time evaluating scalability performance Gold-miner domain.domain, operator tree succeeds capturing key knowledge. initial states,bombs laser cell, robot needs decide pick-up.operator tree domain matches logical query candidate pickup laser(Cell)higher ratio operator PICKUP-BOMB operator PICKUP-LASER. operatorpreference allows ROLLER avoid dead ends laser destroys gold. hand,situations laser required (i.e., destroy hard rocks) reached second choicepolicy. fact implies backtracking ROLLER, additional evaluated nodessignificantly affect overall performance. preference PICKUP-BOMBPICKUP-LASER action example selecting non-helpful actions.4.2.8 ATCHING B LOCKSWORLD ETAILSdomain version Blocksworld designed analyze limitations relaxed plan heuristic.version blocks polarized, either positive negative. also two polarized robotarms. Furthermore, block placed (stack put-down actions) arm differentpolarity, block becomes damaged block placed top it. However, pickingunstacking block wrong polarity seems harmless. fact makes recognizingdead ends difficult task FF heuristic. Particularly, relaxed task blocks neverdamaged. Thus, relaxed plan (and consequently set helpful actions) heuristicestimation wrong. training set used domain consists fifteen 6-blocks problems798fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REESfifteen 8-blocks problems. used even number blocks keep problems balanced (i.e.,half blocks polarity). testing phase used test set learning trackIPC-2008. set problems ranging 15 25 blocks.DF - HA GR - HA solve problem, problems solvablehelpful actions alone. learned DCK recommended useful non-helpful actions, thusROLLER able solve 21 problems. Policy configurations perform better systematic strategies, fairly similar using lookahead strategy. fact reveals learned DCKeffective enough pay effort building lookahead states. LAMA plannersolves problems. Figure 17 shows percentage solved problems increasingCPU time.matching-bw domain100ROLLERROLLER-BFSROLLER-BFS-HAFFLAMA-firstPercentage solved8060402000.1110CPU Time1001000Figure 17: Percentage solved problems increasing time evaluating scalability performance Matching Blocksworld domain.ROLLER solved problems evaluating considerable number nodes plan length,means DCK learned domain accurate. analyzing trainingexamples find many solution plans satisfy key knowledge domain (robotarms unstack pick-up blocks polarity). Specifically, robot handlingtop block, i.e., block blocks goal state, polarity robotarm becomes meaningless. effect unavoidable shortest plans involve managingtop blocks efficient way ignoring polarities. examples include noiselearning make generalization complex.4.2.9 PARKING ETAILSdomain involves parking cars street N curb locations cars doubleparked, triple parked. goal move one configuration parked cars anotherdriving cars one curb location another. domain training set consists of: fifteen799fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJOproblems six cars four curbs fifteen problems eight cars five curbs. testingused test set learning track IPC-2008. hardest problem set 38 cars20 curbs.three ROLLER configurations solve problems perform significantly better nonlearning strategies. addition, three ROLLER configurations outperform FF LAMAdifference one order magnitude. reason LAMA FF low speedscores. ROLLER configurations also consistently better systematic empty configurations. Figure 18 shows percentage solved problems increasing CPU time.hand, three ROLLER configurations achieve first solutions suficient quality. However, solutions refined anytime evaluation, especially ROLLER - BFS - HA,achieves top quality score plan length average fairly similar LAMA.parking domain100ROLLERROLLER-BFSROLLER-BFS-HAFFLAMA-firstPercentage solved8060402000.1110CPU Time1001000Figure 18: Percentage solved problems increasing time evaluating scalability performance Parking domain.learned DCK domain quite effective (ROLLER rarely backtracked). operator tree perfectly classifies MOVE-CAR-TO-CURB action first tree node, askingconsidered helpful action. Besides, binding tree operator selects right car askingtarget goal rejecting candidates. two decisions guide planner placecar right position whenever possible. result, large number nodes evaluated,explains scalability difference FF LAMA.4.2.10 ROVERS ETAILSdomain simplification tasks performed autonomous exploration vehicles sentMars. tasks consist navigating rovers, collecting soils rocks samples, takingimages different objectives. domain training set consists of: ten problems onerover, four waypoints, two objectives one camera; ten problems additional camera;800fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REESten problems additional rover. Problems test set thirty largest problemsIPC-2006 set (i.e., problems 11 40). largest problem set 14 rovers 100waypoints.DCK strategies faster systematic empty strategies, differences significant since configurations solved problems. one hand helpful actionsRovers domain quite good hand test set problemsbig enough generate differences among approaches. Regarding planner comparison, ROLLERachieves top performance score scales significantly better FF, solves two problemsless LAMA. Figure 19 shows percentage solved problems increasing CPU time.Regarding anytime evaluation, planners able refine first solutions. LAMA getstop quality score best plan length refining solutions.rovers domain100ROLLERROLLER-BFSROLLER-BFS-HAFFLAMA-firstPercentage solved8060402000.010.11101001000CPU TimeFigure 19: Percentage solved problems increasing time evaluating scalability performance Rovers domain.domain, ROLLER learned imperfect DCK, manages achieve good scalabilityresults. DCK imperfect partially actions communicating rock, soil image analysisapplied order among them. Therefore, preferences ranking selectingsolutions fail discriminate among actions confuse learning algorithm. Sinceactions could applied order, DCK mistakes seem harmless planningtime.4.2.11 ATELLITE ETAILSdomain comprises set satellites different instruments, operate differentformats (modes). tasks consist managing instruments taking images certain targetsparticular modes. domain training set consist thirty problems one satellite, twoinstruments, five modes five observations. Problems test set thirty largest problems801fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJOIPC-2004 (i.e., problems 7 36). largest problem set 10 satellites, 5 modes174 observations.three ROLLER configurations improved number solved problems non-learningcounterpart. addition, ROLLER ROLLER - BFS - HA solved 30 problems set, twoLAMA eight FF. Figure 20 shows percentage solved problemsincreasing CPU time. ROLLER ROLLER - BFS - HA achieve good quality solutionsable refine anytime evaluation, achieving plan lengths similar LAMA.satellite domain100ROLLERROLLER-BFSROLLER-BFS-HAFFLAMA-firstPercentage solved8060402000.010.11101001000CPU TimeFigure 20: Percentage solved problems increasing time evaluating scalability performance Satellite domain.learned DCK captures key knowledge Satellite domain. trees shownFigure 4 Figure 7 part learned DCK fewer training examples. domainROLLER ROLLER - BFS - HA perform quite similarly. reason FF heuristicalso quite accurate domain. Thus, deepest lookahead state generated learned policyfrequently selected heuristic BFS search.4.2.12 TORAGE ETAILSdomain concerned storage set crates taking account spatial configuration depot. domain tasks comprise using hoists move crates containersparticular area depot. training set consists 30 problems 1 depot, 1 container, 1hoist different combinations 2 3 crates 2 6 areas inside depot.test set used 30 problems IPC-2006 set. largest problem domain 4depots 8 areas each, 5 hoist 20 crates.first 12 problems trivially solved configurations. Then, problem difficulty increases quickly number problem objects increases. BFS solved 20 problems, oneDCK strategy, meaning DCK lookahead strategies pay off. domain802fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REESalso hard FF LAMA. Figure 21 shows percentage solved problems increasingCPU time.storage domain100ROLLERROLLER-BFSROLLER-BFS-HAFFLAMA-firstPercentage solved8060402000.010.11101001000CPU TimeFigure 21: Percentage solved problems increasing time evaluating scalability performance Storage domain.Although DCK effective, found interesting properties it. learned operator treecompact succeeds selecting GO-IN action normally marked helpfulaction.4.2.13 HOUGHTFUL ETAILSdomain models version solitaire card game, cards visible oneturn card talon rather 3 cards time. original version, goalgame place cards ascending order corresponding suit stacks (home deck).available random problem generator domain. Therefore, used bootstrapproblem distribution given learning track IPC-2008. set contains problemsfour suits, card seven suit. test phase used 30 problemstest distribution learning IPC-2008. largest problem domain full setstandard card game.ROLLER solves 12 problems, three fewer GR - HA . However, ROLLER - BFS ROLLER BFS - HA better number solved problems non-learning approaches. domain,use DCK lookahead construction combined FF heuristic makes search processrobust policy mistakes. ROLLER - BFS - HA solves 23, three LAMA. Figure 22shows percentage solved problems increasing CPU time.BFS-BnB algorithm generating training examples able solve 12 30problems bootstrap problem distribution. believe different bootstrap distribution smaller problems would generate accurate DCK. Additionally, even though DCK803fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJOthoughtful domain100ROLLERROLLER-BFSROLLER-BFS-HAFFLAMA-firstPercentage solved8060402000.1110CPU Time1001000Figure 22: Percentage solved problems increasing time evaluating scalability performance Thoughtful domain.lookahead strategies achieve good results, learning accurate decision trees complexmany classes (20 operators particular domain) many argumentspredicates background knowledge (up 6 parameters operator col-to-home 7parameters operator col-to-home-b).4.2.14 TPP ETAILSTPP stands Traveling Purchase Problem, generalization Traveling SalesmanProblem. Tasks domain consist selecting subset markets satisfy demandset goods. selection markets try optimize routing purchasingcosts goods. STRIPS version, graph connects markets equal costsarcs. Nevertheless, domain still interesting difficult planners scaleincreasing number goods, markets trucks. training set consists thirty problemsnumber goods, trucks depots varying one three load levels fivesix. test set consists thirty problems used planner evaluation IPC-2006.largest problem set 20 goods, 8 trucks, 8 markets load level six.ROLLER , GR - HA DF - HA solved 30 problems test set, ROLLER performs fastertwo, achieving similar plan lengths. Besides, ROLLER outperforms restplanners two orders magnitude faster FF. main reason overwhelmingbranching factor large problems together fact FF heuristic falls big plateausdomain. Greedy (depth-first) approaches perform better avoid effectplateaus. Additionally, ROLLER achieved competitive quality scores average plan lengthfirst solution anytime evaluation. ROLLER - BFS ROLLER - BFS - HA got bad results804fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REESdomain imprecision FF heuristic. Figure 23 shows percentagesolved problems increasing CPU time.tpp domain100Percentage solved80604020ROLLERROLLER-BFSROLLER-BFS-HAFFLAMA-first00.010.11101001000CPU TimeFigure 23: Percentage solved problems increasing time evaluating scalability performance TPP domain.learned DCK compact useful reducing number evaluations, shownROLLER performance. instance, DRIVE binding tree recognizes perfectly truckmarket need go market B already truck B handling goodsmarket. situations, state truck B helpful action DRIVE, meaningtruck B something deliver.5. Lessons Learned IPCIPC-2008 included specific track planning systems benefit learning. Thirteen systemstook part track including previous version ROLLER (De la Rosa et al., 2009) achieved7th position. version upgrade original ROLLER system (De la Rosa et al.,2008). first version proposed EHC-Sorted algorithm alternative H-Context Policy, effective many domains. competing version tried recommend orderingapplying actions relaxed plans. idea, although initially appealing, goodchoice usefulness strongly depends fact relaxed plan contains right actions. competition completed analysis ROLLER performance diagnosestrengthen weak points. system resulting improvements ROLLER versiondescribed article. One example ROLLER improvements results obtainedThoughtful Matching Blocksworld domains. IPC-2008, ROLLER failed solve problems Thoughtful domain solved two problems Matching Blocksworld.reported section 4, current version ROLLER solves 23 19 problems respectivelydomains. addition, current version ROLLER outperforms LAMA FF Park805fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJOing domain one order magnitude. improvements ROLLER overcome limitationsversion submitted IPC-2008 three aspects:Robustness wrong DCK. Issues discussed Section 2 decisions introduce biases learning process making learning DCK complex task. fact, competitorIPC-2008 able learn useful DCK domains. Furthermore, many domainslearned DCK damaged performance baseline planner. caseROLLER . described paper, strengthened ROLLER wrong DCKproposing two versions modified BFS algorithm combine learned DCKnumerical heuristic. combination DCK heuristic makes planning process robust imperfect and/or incorrectly learned knowledge. similar approachfollowed winner best learner award, BTUSE W EDGE (Yoon et al., 2008).Efficiency baseline. overall competition winner P BP (Gerevini, Saetti, & Vallati, 2009) portfolio state-of-the-art planners learns planner settingsbest ones given planning domain. result, performance competitornever worse performance state-of-the-art planner. IPC-2008 baseline performance ROLLER far competitive state-of-the art plannersROLLER algorithms coded LISP. overcome weakness optimizedimplementation ROLLER using C code outperformed IPC-2008 resultsdomains.Definition significant training sets. Training examples extracted experiencecollected solving problems training set. Therefore, quality trainingexamples depends quality problems used training. IPC-2008 trainingproblems fixed organizers and, many domains, largeROLLER system extract useful DCK. paper created training problems usingrandom generators build useful training sets ROLLER system domain.Selection training examples. Relational classifiers induce set rules/trees modelregularities training data. case forward state-space search planningbest-cost solutions problem may used training data, leads alternatives confuse learner. avoid this, training data cleanedused learning algorithm. ranking solution selection proposed articleoption give learner training data clearer regularities.Additionally, ROLLER performed poorly Sokoban N-puzzle domains. Traditionally,useful DCK domains form numeric functions, Manhattan distance,provides lower-bound solution length. general, action policies inaccuratedomains, lack knowledge trajectory goals. Currently, stillunable learn useful DCK ROLLER domains. possible future direction introducegoals subgoals (e.g. landmarks) helpful context aim capturingknowledge.6. Related Workapproach strongly inspired way Prodigy (Veloso et al., 1995) models DCK.Prodigy architecture, action selection two-step process: first, Prodigy selects uninstan806fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REEStiated operator apply, second, selects bindings operator. selectionsguided DCK form control rules (Leckie & Zukerman, 1998; Minton, 1990).returned idea two-step action selection allows us define learningplanning DCK standard classification task therefore solve learning taskoff-the-shelf classification technique relational decision trees. Nevertheless, ROLLERneed distinguish among different kinds nodes Prodigy does, ROLLER performsstandard forward heuristic search state space search nodestype.Relational decision trees previously used learn action policies contextRelational Reinforcement Learning (RRL) (Dzeroski, De Raedt, & Blockeel, 1998). comparisonDCK learned ROLLER, RRL action policies present two limitations solving planning problems. First, RRL learned knowledge targeted given set goals, thereforeRRL cannot directly generalize learned knowledge different goals within given domain.Second, since training examples RRL consist explicit representations states, RRL needsadd extra background knowledge learn effective policies domains recursive predicatesBlocksworld.Previous works learning generalized policies (Martin & Geffner, 2004; Yoon et al., 2008)succeed addressing two limitations RRL. First, introduce planning goalstraining examples. way learned policy applies set goals domain. Second,change representation language DCK predicate logic concept language.language makes capturing decisions related recursive concepts easier. Alternatively, ROLLERcaptures effective DCK domains like Blocksworld without varying representation language.ROLLER implicitly encodes states terms set helpful actions state. result,ROLLER benefit directly off-the-shelf relational classifiers work predicate logic.fact makes learning times shorter resulting policies easier read.Recently, techniques also developed improve performance heuristicplanners:Learning Macro-actions (Botea, Enzenberger, Muller, & Schaeffer, 2005; Coles & Smith,2007) combination two operators considered new domain operators order reduce search tree depth. However, benefit decreases numbernew macro-actions added enlarge branching factor search tree causing utility problem (Minton, 1990). approaches overcome problem, applyingfilters decide applicability macro-actions (Newton, Levine, Fox, & Long,2007). Two versions work participated learning track IPC-2008, obtainingthird fourth place. One advantage macro-actions learned knowledgeexploited planner. Thus, approaches learn generalized policies could alsobenefit macro-actions. Nevertheless, far know, combinationtried improving heuristic planners.Learning domain-specific heuristic functions: approach (Yoon, Fern, & Givan, 2006;Xu, Fern, & Yoon, 2007), state-generalized heuristic function obtained examplessolution plans. main drawback learning domain-specific heuristic functionsresult learning algorithm difficult understand humans makesverification learned knowledge difficult. hand, learned knowledgeeasy combine existing domain-independent heuristics. slightly different approach807fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJOconsists learning ranking function greedy search algorithms (Xu, Fern, & Yoon,2009, 2010). step greedy search, current node expanded child nodehighest rank selected current node. case, ranking functioniteratively estimated attempt cover set solution plans greedy algorithm.Learning task decomposition: approach learns divide planning tasks givendomain smaller subtasks easier solve. Techniques reachability analysislandmark extraction (Hoffmann, Porteous, & Sebastia, 2004) able compute intermediate states must reached satisfying goals. However, clearsystematically exploit knowledge build good problem decompositions. Vidal et al. (2010) consider optimization problem use specialized optimizationalgorithm discover good decompositions.general, system learns planning DCK deal ambiguity trainingexamples, given planning state may present many good actions. Trying learn DCKselects one action other, inherently equal, complex learning problem. copeambiguous training data ROLLER created function ranks solutions aim learningkind solutions. different approach followed Xu et al. (2010) generatetraining examples partially ordered plans.7. Conclusions Future Workpresented new technique reducing number node evaluations heuristic planning based learning exploiting generalized policies. technique defines processlearning generalized policies two-step classification builds domain-specific relational decision trees capture action selected different planning contexts. work,planning contexts specified helpful actions state, pending goals staticpredicates problem. Finally, explained exploit learned policies solveclassical planning problems, applying directly combining domain independentheuristic lookahead strategy BFS algorithm. work contributes state-of-the-artlearning-based planning three ways:1. Representation. propose new encoding generalized policies able captureefficient DCK using predicate logic. opposed previous works represent generalizedpolicies predicate logic (Khardon, 1999), representation need extra background knowledge (support predicates) learn efficient policies Blocksworld domain.Besides, encoding states set helpful actions frequently compact furthermore, set normally decreases search fewer goals left. Thus, processmatching DCK becomes faster search advances towards goals.2. Learning. defined task learning generalized policy two-step standardclassification task. Thus, learn generalized policy off-the-shelf toolbuilding relational classifiers. Results paper obtained TILDE system (Blockeel & De Raedt, 1998), tool learning relational classifiers couldused. this, advances relational classification applied straightforwardmanner ROLLER learn faster better planning DCK.808fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REES3. Planning. explained extract action ordering H-Context Policyshown use ordering reduce node evaluations: (1) algorithm Depth-First H-Context Policy allows direct application H-Context policies;(2) H-Context Policy Lookahead BFS, combines policy domainindependent heuristic within BFS algorithm. addition, included modifiedversion algorithm (ROLLER - BFS - HA) considers helpful successors orderreduce number evaluations domains helpful actions good.Experimental results show approach improved scalability baseline heuristicplanners FF LAMA (winner IPC-2008) variety IPC domains. effectevident domains learned DCK presents good quality, e.g. Blocksworld Parking.domains direct application learned DCK saves large amounts node evaluationsachieving impressive scalability performance. Moreover, using learned DCK combinationdomain-independent heuristic BFS algorithm achieves good quality solutions.quality learned DCK poor, planning direct application policy failssolve many problems, mainly largest ones difficult solve without reasonableguide. Unfortunately, current mechanism quantifying quality learned DCKevaluating set test problems. Therefore, good compromise solution combininglearned DCK domain-independent heuristics.domains, DCK learned ROLLER presents poor quality helpful contextable represent concepts necessary order discriminate good badactions. problem frequently arises arguments good action correspondproblem goals static predicates. plan study refinements definitionhelpful context achieve good DCK domains. One possible direction extendinghelpful context subgoal information landmarks (Hoffmann et al., 2004)relaxed plan. Moreover, use decision trees introduces important bias learning step.Algorithms tree learning insert new query tree produces significantinformation gain. However, domains information gain obtainedconjunction two queries. Finally, currently providing learner fixeddistribution training examples. near future, plan explore learner generateconvenient distribution training examples according target planning task proposedFuentetaja Borrajo (2006).Acknowledgmentswork partially supported Spanish MICIIN project TIN2008-06701-C03-03regional CAM-UC3M project CCG08-UC3M/TIC-4141.809fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJOAppendix A. DCK Usefulness ResultsDomainsBlocksworld (30)Depots (22)Gold-miner (30)Matching-BW (30)Parking (30)Rovers (30)Satellite (30)Storage (30)Thoughtful(30)TPP (30)TotalDEPH-FIRSTroller gr-ha df-ha29.870.030.0019.427.703.6128.000.000.0020.880.000.0028.571.230.0025.99 10.097.7327.972.931.6911.028.038.0811.91 13.150.0029.50 10.86 11.45233.13 54.02 32.56BEST-FIRSTroller-bfs lh-bfsbfs2.470.000.0010.515.322.450.040.050.003.820.983.9022.720.260.0114.585.520.1416.093.050.0811.53 10.568.9711.308.902.3114.838.675.00107.89 43.31 22.86HELPFUL BEST-FIRSTroller-bfs-ha lh-bfs-ha bfs-ha2.400.000.0010.985.277.087.350.000.003.722.205.8123.600.260.0418.1217.178.2121.932.682.9016.127.007.0011.899.053.0413.977.546.13130.0851.1740.21Table 9: Problems solved DCK usefulness evaluation.DomainsBlocksworld (30)Depots (22)Gold-miner (30)Matching-BW (30)Parking (30)Rovers (30)Satellite (30)Storage (30)Thoughtful(30)TPP (30)TotalDEPH-FIRSTrollergr-ha df-ha29.830.060.008.828.213.0219.780.000.0011.530.000.0021.538.200.0121.5426.34 25.5128.0317.369.5813.438.028.006.8912.400.0025.4627.92 23.75186.84 108.51 69.87BEST-FIRSTroller-bfslh-bfs8.000.0012.6814.8411.5017.0012.766.3526.926.3321.9424.6322.6021.4815.5916.8716.5613.3513.9422.04162.49 142.89bfs0.0012.3715.4113.846.1410.7514.6419.2310.608.71111.69HELPFUL BEST-FIRSTroller-bfs-ha lh-bfs-habfs-ha8.000.000.0013.2016.0619.9716.670.000.0017.219.3916.5426.926.338.1825.7126.3229.6327.6022.3122.4215.668.599.3119.4814.9111.7516.2024.3613.88186.65128.27 132.35Table 10: Quality scores DCK usefulness evaluation.ReferencesBacchus, F., & Kabanza, F. (2000). Using temporal logics express search control knowledgeplanning. Artificial Intelligence, 116(1-2), 123191.Biba, J., Saveant, P., Schoenauer, M., & Vidal, V. (2010). evolutionary metaheuristic basedstate decomposition domain-independent satisficing planning. Proceedings 20thInternational Conference Automated Planning Scheduling (ICAPS10) Toronto, ON,Canada. AAAI Press.Blockeel, H., & De Raedt, L. (1998). Top-down induction first-order logical decision trees.Artificial Intelligence, 101(1-2), 285297.810fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REESBonet, B., Loerincs, G., & Geffner, H. (1997). robust fast action selection mechanismplanning. Proceedings American Association Advancement ArtificialIntelligence Conference (AAAI), pp. 714719. MIT Press.Botea, A., Enzenberger, M., Muller, M., & Schaeffer, J. (2005). Macro-FF: Improving AI planningautomatically learned macro-operators. Journal Artificial Intelligence Research, 24,581621.Coles, A., & Smith, A. (2007). Marvin: heuristic search planner online macro-action learning. Journal Artificial Intelligence Research, 28, 119156.De la Rosa, T., Jimenez, S., & Borrajo, D. (2008). Learning relational decision trees guiding heuristic planning. International Conference Automated Planning Scheduling(ICAPS).De la Rosa, T., Jimenez, S., Garca-Duran, R., Fernandez, F., Garca-Olaya, A., & Borrajo, D.(2009). Three relational learning approaches lookahead heuristic planning. WorkingNotes ICAPS 2009 Workshop Planning Learning, pp. 3744.De Raedt, L. (2008). Logical Relational Learning. Springer, Berlin Heidelberg.Doherty, P., & Kvarnstrom, J. (2001). Talplanner: temporal logic based planner. AI Magazine,22(3), 95102.Dzeroski, S., De Raedt, L., & Blockeel, H. (1998). Relational reinforcement learning. International Workshop ILP, pp. 1122.Emde, W., & Wettschereck, D. (1996). Relational instance-based learning. Proceedings13th Conference Machine Learning, pp. 122130.Florez, J. E., Garca, J., Torralba, A., Linares, C., Garca-Olaya, A., & Borrajo, D. (2010). Timiplan: application solve multimodal transportation problems. Proceedings SPARK,Scheduling Planning Applications workshop, ICAPS10.Fuentetaja, R., & Borrajo, D. (2006). Improving control-knowledge acquisition planningactive learning. ECML, Berlin, Germany, Vol. 4212, pp. 138149.Gerevini, A., Saetti, A., & Vallati, M. (2009). automatically configurable portfolio-based plannermacro-actions: Pbp. Proceedings 19th International Conference AutomatedPlanning Scheduling, pp. 191199 Thessaloniki, Greece.Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation heuristicsearch. Journal Artificial Intelligence Research, 14, 253302.Hoffmann, J., Porteous, J., & Sebastia, L. (2004). Ordered landmarks planning. JournalArtificial Intelligence Research, 22.Khardon, R. (1999). Learning action strategies planning domains. Artificial Intelligence, 113,125148.811fiD E LA ROSA , J IMENEZ , F UENTETAJA & B ORRAJOLeckie, C., & Zukerman, I. (1998). Inductive learning search control rules planning. ArtificialIntelligence, 101(12), 6398.Martin, M., & Geffner, H. (2000). Learning generalized policies planning using concept languages. International Conference Artificial Intelligence Planning Systems, AIPS00.Martin, M., & Geffner, H. (2004). Learning generalized policies planning examples usingconcept languages. Appl. Intell, 20, 919.Mcallester, D., & Givan, R. (1989). Taxonomic syntax first order inference. Journal ACM,40, 289300.McDermott, D. (1996). heuristic estimator means-ends analysis planning. Proceedings3rd Conference Artificial Intelligence Planning Systems (AIPS), pp. 142149. AAAIPress.Minton, S. (1990). Quantitative results concerning utility explanation-based learning. Artif.Intell., 42(2-3), 363391.Muggleton, S. (1995). Inverse entailment progol. New Generation Computing, 13, 245286.Muggleton, S., & De Raedt, L. (1994). Inductive logic programming: Theory methods. JournalLogic Programming, 19, 629679.Nau, D., Au, T.-C., Ilghami, O., Kuter, U., Murdock, W., Wu, D., & Yaman, F. (2003). SHOP2:HTN planning system. Journal Artificial Intelligence Research, 20, 379404.Newton, M. A. H., Levine, J., Fox, M., & Long, D. (2007). Learning macro-actions arbitraryplanners domains. Proceedings 17th International Conference AutomatedPlanning Scheduling (ICAPS).Quinlan, J. (1986). Induction decision trees. Machine Learning, 1, 81106.Richter, S., & Westphal, M. (2010). LAMA planner: Guiding cost-based anytime planninglandmarks. Journal Artificial Intelligence Research, 39, 127177.Roger, G., & Helmert, M. (2010). more, merrier: Combining heuristic estimators satisficing planning. Proceedings 20th International Conference Automated PlanningScheduling (ICAPS), pp. 246249.Veloso, M., Carbonell, J., Perez, A., Borrajo, D., Fink, E., & Blythe, J. (1995). Integrating planninglearning: PRODIGY architecture. JETAI, 7(1), 81120.Vidal, V. (2004). lookahead strategy heuristic search planning. Proceedings 14thInternational Conference Automated Planning Scheduling (ICAPS 2004), Whistler,British Columbia, Canada, pp. 150160.Xu, Y., Fern, A., & Yoon, S. W. (2007). Discriminative learning beam-search heuristicsplanning. IJCAI 2007, Proceedings 20th IJCAI, pp. 20412046.812fiS CALING H EURISTIC P LANNING R ELATIONAL ECISION REESXu, Y., Fern, A., & Yoon, S. (2009). Learning linear ranking functions beam searchapplication planning. Journal Machine Learning Research, 10, 15711610.Xu, Y., Fern, A., & Yoon, S. (2010). Iterative learning weighted rule sets greedy search.Proceedings 20th International Conference Automated Planning Scheduling(ICAPS) Toronto, Canada.Yoon, S., Fern, A., & Givan, R. (2006). Learning heuristic functions relaxed plans. Proceedings 16th International Conference Automated Planning Scheduling (ICAPS).Yoon, S., Fern, A., & Givan, R. (2007). Using learned policies heuristic-search planning.Proceedings 20th IJCAI.Yoon, S., Fern, A., & Givan, R. (2008). Learning control knowledge forward search planning.J. Mach. Learn. Res., 9, 683718.Zimmerman, T., & Kambhampati, S. (2003). Learning-assisted automated planning: looking back,taking stock, going forward. AI Magazine, 24, 73 96.813fiJournal Artificial Intelligence Research 40 (2011) 305-351Submitted 07/10; published 01/11Multimode Control Attacks ElectionsPiotr Faliszewskifaliszew@agh.edu.plDepartment Computer ScienceAGH University Science TechnologyKrakow, PolandEdith Hemaspaandraeh@cs.rit.eduDepartment Computer ScienceRochester Institute TechnologyRochester, NY 14623 USALane A. Hemaspaandralane@cs.rochester.eduDepartment Computer ScienceUniversity RochesterRochester, NY 14627 USAAbstract1992, Bartholdi, Tovey, Trick opened study control attacks electionsattempts improve election outcome actions adding/deleting candidatesvoters. work led many results algorithms used find attackselections complexity-theoretic hardness results used shieldsattacks. However, work line assumed attacker employssingle type attack. paper, model study case attackerlaunches multipronged (i.e., multimode) attack. realistically capturerichness real-life settings. example, attacker might simultaneously try suppressvoters, attract new voters election, introduce spoiler candidate.model provides unified framework varied attacks. constructing polynomialtime multiprong attack algorithms prove various election systems evenconcerted, flexible attacks perfectly planned deterministic polynomial time.1. IntroductionElections central model collective decision-making: Actors (voters) preferencesamong alternatives (candidates) input election rule winner (or winnerscase ties) declared rule. Bartholdi, Orlin, Tovey, Trick initiated lineresearch whose goal protect elections various attacking actions intended skewelections results. Bartholdi, Orlin, Tovey, Tricks strategy achieving goalshow various election systems attacking actions, even seeing whethergiven set votes attack possible NP-complete. papers (Bartholdi,Tovey, & Trick, 1989a; Bartholdi & Orlin, 1991; Bartholdi, Tovey, & Trick, 1992) consideractions voter manipulation (i.e., situations voter misrepresentsvote obtain goal) various types election control (i.e., situationsattacker capable modifying structure election, e.g., adding deletingeither voters candidates). Since then, many researchers extended Bartholdi, Orlin,Tovey, Tricks work providing new models, new results, new perspectives.c2011AI Access Foundation. rights reserved.fiFaliszewski, Hemaspaandra, & Hemaspaandrabest knowledge, one considered situationattacker combines multiple standard attack types single attacklet us callmultipronged (or multimode) attack.Studying multipronged control step direction realistically modelingreal-life scenarios. Certainly, real-life settings attacker would voluntarily limitsingle type attack rather would use available meansreaching goal. example, attacker interested candidate p winningmight, time, intimidate ps dangerous competitors wouldwithdraw election, encourage voters support p show vote.paper study complexity multipronged control attacks.1Given type multiprong control, seek analyze complexity. particular,try show either one compute polynomial time optimal attackcontrol type, even recognizing existence attack NP-hard. particularlyinteresting ask complexity multipronged attack whose componentsefficient algorithms. interested whether combined attack (a) becomescomputationally hard, (b) still polynomial-time algorithm. Regarding (a) case,give example natural election system displays behavior. papers corework studies (b) case shows even attacks multiple prongs manycases planned perfect efficiency. results yield immediate consequencesindividual efficient attack algorithms prong, allow compactpresentation results compact proofs. go beyond that: showinteractions prongs managed without cost move beyondpolynomial time.papers organization follows. Section 2 discuss relevant literature.Section 3 present standard model elections describe relevant voting systems.Section 4 introduce multiprong control, provide initial results, show existingimmunity, vulnerability, resistance results interact model. Section 5provide complexity analysis candidate voter control maximin elections, showingmultiprong control useful so. Section 6 consider fixed-parameter complexity multiprong control, using parameter number candidates. Section 7provides conclusions open problems. appendix, show maximininteresting relation Dodgson elections: candidate whose Dodgson scorem2 times Dodgson winner(s) maximin winner.2. Related WorkSince seminal paper Bartholdi et al. (1992), much research dedicatedstudying complexity control elections. Bartholdi et al. (1992) considered constructive control only, i.e., scenarios goal attacker ensure candidatesvictory. Hemaspaandra, Hemaspaandra, Rothe (2007) extended work destructive case, i.e., scenarios goal prevent someone winning.central elusive goal control research finding natural election system (withpolynomial-time winner algorithm) resistant standard types con1. fact, framework multiprong control includes unpriced bribery Faliszewski, Hemaspaandra,Hemaspaandra (2009a), extended include manipulation.306fiMultimode Control Attacks Electionstrol, i.e., types control NP-hard. Hemaspaandra, Hemaspaandra,Rothe (2009) showed exist highly resistant artificial election systems. Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2009a) showed naturalsystem known Copeland voting far goal mentioned above.Erdelyi, Nowak, Rothe (2009) showed system even resistancesCopeland, slightly nonstandard voter model (see Baumeister, Erdelyi, Hemaspaandra, Hemaspaandra, & Rothe, 2010, discussion Erdelyi, Piras, & Rothe, 2010b,2010a; Menton, 2010, related follow-up work).Recently, researchers also started focusing parameterized complexity controlelections. Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2009a) provided severalfixed-parameter tractability results. Betzler Uhlmann (2009) Liu, Feng, Zhu,Luan (2009) showed so-called W[1]- W[2]-hardness results control various voting rules. response conference version (Faliszewski, Hemaspaandra, & Hemaspaandra, 2009b) present paper, Liu Zhu (2010) conducted parameterized-complexitystudy control maximin elections.Going somewhat different direction, Meir, Procaccia, Rosenschein, Zohar (2008)bridged notions constructive destructive control considering utility functions,model obtained control results multiwinner elections. multiwinner electionsgoal elect whole group people (consider, e.g., parliamentary elections) rathersingle person. Elkind, Faliszewski, Slinko (2010a) Maudet, Lang,Chevaleyre, Monnot (2010) considered two types problems related controladding candidates case known voters would rank addedcandidates.Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2011) Brandt, Brill,Hemaspaandra, Hemaspaandra (2010) studied control (and manipulationbribery) so-called single-peaked domains, model overall electorate behaviorpolitical science.growing body work manipulation regards frequency(non)hardness election problems (see, e.g., Conitzer & Sandholm, 2006; Friedgut, Kalai,& Nisan, 2008; Dobzinski & Procaccia, 2008; Xia & Conitzer, 2008b, 2008a; Walsh, 2009;Isaksson, Kindler, & Mossel, 2010). work studies whether given NP-hard electionproblem (to date manipulation/winner problems studied, control problems) often solved practice (assuming distribution votes). (One howeverkeep mind polynomial-time algorithm solves NP-hard problem extremely frequentlyif errs sparse set formal complexity-theoretic sensetermthen P = NP, Schoning, 1986.) frequency results courserelevant ones goal protect elections manipulative actions, althoughNP-hardness important step, first step towards truly broad, satisfyingsecurity. However, paper typically take role attacker design controlalgorithms fast instances.Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2009b) Faliszewski, Hemaspaandra, Hemaspaandra (2010b) provide overview complexity-of-electionissues.307fiFaliszewski, Hemaspaandra, & Hemaspaandra3. Preliminariessection covers preliminaries elections computational complexity.3.1 Electionselection pair (C, V ), C = {c1 , . . . , cm } set candidates V =(v1 , . . . , vn ) collection voters. voter vi represented preferencelist.2 example, three candidates, c1 , c2 , c3 , voter likes c1 most,c2 , c3 would preference list c1 > c2 > c3 .3 Given election E = (C, V ),NE (ci , cj ), ci , cj C 6= j, denote number voters V preferci cj . adopt following convention specifying preference lists.Convention 3.1. Listing set candidates item preference list meanslisting members set increasing lexicographic order (with respectcandidates names), listing means listing members decreasinglexicographic order (with respect candidates names).Example 3.2. Let us give quick example convention. C = {Bob, Carol, Ted,Alice} = {Alice, Ted, Bob}, Carol > shorthand Carol > Alice > Bob >Ted, Carol > shorthand Carol > Ted > Bob > Alice.4Note model used paper, assume person tryingattack election knows votes, V , are. standard modelcomputational studies attacks elections ever since seminal work Bartholdiet al. (1989a, 1992) Bartholdi Orlin (1991). However, worth notingabstract model strains connection real world. Regarding provinglower bounds, NP-hardness results, results model actually stronger: Oneshowing even given full access votes, V , attacker still NP-hardtask. hand, build polynomial-time attack algorithms model,algorithms benefiting model letting know votes are.natural model vary situation, one always keep mindindeed abstract model, real world itself. However, many settings,unreasonable assume attacker might strong informationvotes. information might come polls, might come door-to-doortelephone canvassing, might come voter registration contribution records,2. also assume voter unique name. However, election systems considerhereexcept election system Theorem 4.12are oblivious particular voter namesorder votes.3. Preference lists also called preference orders, paper use two terms interchangeably.4. constructions use convention, using variable names objectssuch{b1 , . . . , b3k } p onthat used candidate sets elections outputreduction. However, since election part input set candidates (which named),actual reductions assigning name strings objects, orderingdiscussed well-defined easily carried reductions. fact, contextreductions, actual (string) values bi probably already part input reduction.(We chosen lexicographic order simply polynomial-time reductions sort things it,reverse, without problem.)308fiMultimode Control Attacks Electionsmight come (in intimate, human elections, votes whether onecourse-based exam-based M.S. degree ones department) great familiarityattacker voters, might come attacker vote collector.election system mapping given election (C, V ) outputs set W , satisfyingW C, called winners election.5focus following five voting systems: plurality, Copeland, maximin, approval,Condorcet. (However, Section 6 appendix take detoursystems.) plurality, Copeland, maximin, approval assigns pointscandidates elects receive points. Let E = (C, V ) election,C = {c1 , . . . , cm } V = (v1 , . . . , vn ). plurality, candidate receives singlepoint voter ranks first. maximin, score candidate ci Edefined mincj C{ci } NE (ci , cj ). rational , 0 1, Copeland candidateci receives 1 point candidate cj , j 6= i, NE (ci , cj ) > NE (cj , ci )points candidate cj , j 6= i, NE (ci , cj ) = NE (cj , ci ). is, parameterdescribes value ties head-to-head majority contests. approval, insteadpreference lists voters ballot 0-1 vector, entry denotes whether voterapproves corresponding candidate (gives corresponding candidate point).example, vector (1, 0, 0, 1) means voter approves first fourth candidates,second third. use scoreE (ci ) denote score candidate cielection E (the particular election system used always clear context).candidate c Condorcet winner election E = (C, V ) candidateC holds NE (c, c0 ) > NE (c0 , c). Condorcet voting election systemwinner set is, definition, exactly set Condorcet winners. followsdefinition election one Condorcet winner. every electionCondorcet winner. However, notion election allows outcomes onewins, electing Condorcet winner one otherwise winnerlegal election system.c05. Readers social choice background may wonder forbid case W = ,typically done social choice framings elections. Briefly put, allowing possibility W =standard model computational studies elections, starting seminal papersBartholdi, Orlin, Tovey, Trick. retaining model, results better comparedexisting computational results attacks elections. fact, recent (admittedly computationallyoriented) textbook Shoham Leyton-Brown (2009, Def. 9.2.2) treats definition social choicecorrespondence allowing subset candidates, including empty set (in contrast, socialchoice papers, notion social choice correspondence routinely definition excludes possibilitywinners). Although follow model allowing empty outcome standardcomputational model allows comparison existing results, mention passing findmodel, merits, attractive one, although certainly matter taste, familiarity,comfort. model avoids building special-case exception definition allows one discusszero-candidates elections reason one wants to. importantly, many natural electionsystems might winners. Examples include threshold election systems, including majority-ruleelections election systems often used see whether anyoneby exceeding certain percentageapproval votes group expert sports writers, instancemerits induction sports HallFame year. Condorcet voting (to defined later), seminal control-of-elections paperBartholdi et al. (1992) treated election system, also empty winner set.309fiFaliszewski, Hemaspaandra, & Hemaspaandra3.2 Computational Complexityuse standard notions complexity theory, presented, e.g., textbook Papadimitriou (1994). assume reader familiar complexity classes PNP, polynomial-time many-one reductions, notions NP-hardness NPcompleteness. N denote {0, 1, 2, . . .}.NP-hardness proofs paper follow reduction well-knownNP-complete problem exact cover 3-sets, known short X3C (see, e.g., Garey &Johnson, 1979). X3C given pair (B, S), B = {b1 , . . . , b3k } set 3kelements = {S1 , . . . , Sn } set 3-subsets B, ask whethersubset 0 exactly k elements union exactly B. call set0 exact cover B.Section 6, consider fixed-parameter complexity multiprong control.idea fixed-parameter complexity measure complexity given decision problemrespect instance size (as standard complexity theory)parameter input (in case, number candidates involved). problemsaid fixed-parameter tractable, i.e., belong complexity class FPT,standard require problem solved algorithm running timef (j)nO(1) , n size encoding given instance, j valueparameter instance, f function. Note fpolynomially bounded even computable. However, FPT claims paper, fcomputable function. is, algorithms actually achieve so-called strongly uniformfixed-parameter tractability. point readers interested parameterized complexity to,example, recent book Niedermeier (2006).4. Control Multiprong Controlsection introduce multiprong control, is, control types combine severalstandard types control. first provide definition, proceed analyzing generalproperties multiprong control, consider multiprong control election systemscomplexity single-prong control already established, finally giveexample election system multiprong control becomes harderconstituent prongs (assuming P 6= NP). conclude section summarymain contributions.4.1 Definitionconsider combinations control adding/deleting candidates/voters6 bribingvoters. Traditionally, bribery considered type control fits modelnaturally strengthens results.discussing control problems, must clear whether goalattacker make preferred candidate winner, makepreferred candidate winner. clear this, standard useterm unique-winner model model goal make ones preferred6. control types, defined Bartholdi et al. (1992) refined Hemaspaandra et al. (2007), regardvarious types partitioning candidates voters.310fiMultimode Control Attacks Electionscandidate one winner, use term nonunique-winner modelapproach goal make ones preferred candidate winner. (Noteexactly one person wins, certainly considered satisfiedcontrol action nonunique-winner model. nonunique model name merelymeans requiring winners unique.)destructive cases are, nonunique-winner model, blockingones despised candidate unique winner,7 unique-winner model,blocking ones despised candidate winner. take unique-winner modeldefault paper, common model studies control.Definition 4.1. Let E election system. unique-winner,8 constructive EAC+DC+AV+DV+BV control problem given:(a) two disjoint sets candidates, C A,(b) two disjoint collections voters, V W , containing voters preference listsC A,(c) preferred candidate p C,(d) five nonnegative integers, kAC , kDC , kAV , kDV , kBV .ask whether possible find two sets, A0 C 0 C, two subcollectionsvoters, V 0 V W 0 W , that:(e) possible ensure p unique winner E election ((C C 0 ) A0 , (VV 0 ) W 0 ) via changing preference orders (i.e., bribing) kBV voters(V V 0 ) W 0 ,(f ) p/ C 0 ,(g) kA0 k kAC , kC 0 k kDC , kW 0 k kAV , kV 0 k kDV .unique-winner, destructive variant problem, replace item (e) with:possible ensure p unique winner E election ((C C 0 )A0 , (V V 0 )W 0 )via changing preference orders kBV voters (V V 0 ) W 0 . (In addition,destructive variant refer p despised candidate rather preferredcandidate, often denote d.)Table 1 summarizes informal English notation used definition,information easily available reader refer back to.phrase AC+DC+AV+DV+BV problem name corresponds fourstandard types control: adding candidates (AC), deleting candidates (DC), adding voters(AV), deleting voters (DV), (unpriced) bribery (BV); refer five typescontrol basic types control. remind reader traditionally7. often use phrase unique winner, did. reason write unique winnerrather unique winner avoid impression election necessarily (unique)winner.8. One straightforwardly adapt definition nonunique-winner model.311fiFaliszewski, Hemaspaandra, & HemaspaandraNotationACDCAVDVBVCVWkACkDCkAVkDVkBVpMeaningControl adding candidates.Control deleting candidates.Control adding voters.Control deleting voters.Control bribing voters.set initial candidates election.set additional candidates control agent may introduce.collection initial voters election.collection additional voters control agent may introduce.bound number candidates added AC control.bound number candidates deleted DC control.bound number voters added AV control.bound number voters deleted DV control.bound number voters bribed BV control.preferred candidate (the constructive control goal ensure punique winner).despised candidate (the destructive control goal ensureunique winner).Table 1: Notations Definition 4.1 used frequently elsewhere.bribery type control call basic type control sakeuniformity throughout rest paper consider such.choose basic types, essentiallycollection focus, term handy one use indicate them.focused particular ones largely find highly attractive.various partition control types appeared original paper control, quiteinteresting, always seemed less natural us adding/deleting voters/candidates.Bribery us also quite compellingly natural. attack known manipulationincluded us among basic types, without doubt natural importanttype attack elections, conclusion discuss briefly, commendreader issue studying manipulation additional prong.Instead considering AC, DC, AV, DV, BV, often interestedsubset consider special cases AC+DC+AV+DV+BV problem.example, write DC+AV refer variant AC+DC+AV+DV+BV problemdeleting candidates adding voters allowed. part modelassume variant, parameters relevant prongs partinput. So, example, DC+AV would kDC , kAV , C, V , W , p (only)parts input. missing parts (e.g., DC+AV, missing parts A, kAC ,kDV , kBV ) treated obvious way evaluating formulas Definition 4.1,namely, missing sets treated missing constants treated 0. namesingle type control, effect degenerate one standard control problems.312fiMultimode Control Attacks Electionsreader may naturally wonder order prongs multi-prong attackoccur. Note part (e) Definition 4.1 quietly setting order. However, almostorder interactions uninteresting (unless attacker idiotic). example,definition allow one bribe voters one deleting, wouldpointless anyway, interesting restriction attacker. Similarly,definition allow one add voter immediately delete it, again,take even one successful attack away attacker. Indeed, interestingorder interaction consider whether one bribe added voters, whether onebribe voters originally election. One could argue either way,one wanted avoid focusing one other, one could analyze everything ways.However, definition embraces model even added voters bribed.Note model favorable attacker. One referee commentedwould unreasonable give attackers flexibility multiple attacks denyfreedom control order attacks. keeping spirit comment,definition resolves order issue way favorable attacker,way biased attacker. However, completeness mentionpossible someperhaps highly artificialsystems might different attackcomplexities model added voters cannot bribed compared modeladded voters bribed.least one way could define multiprong control. modeldefinition called separate-resource model, extentuse basic type control bounded separately. shared-resource modelone pool action allowances must allocated among allowed control types (sodefinition would replace kAC , kDC , kAV , kDV single value, k,require kC 0 k + kD0 k + kV 0 k + kW 0 k + the-number -of -bribed -voters k). Although onecould make various arguments model appropriate, computationalcomplexity related.Theorem 4.2. polynomial-time algorithm given variant multiprongcontrol separate-resource model one shared-resource modelwell.Proof. Let E election system. describe idea proof exampleconstructive E-AC+AV problem. idea straightforwardly generalizesset allowed control actions (complexity-theory savvy readers quickly see we,essence, give disjunctive truth-table reduction).given instance constructive E-AC+AV problem shared-resourcemodel, k limit sum number candidates voters mayadd. Given polynomial-time algorithm separate-resource variant problem,solve using following method. (If k > kAk + kW k set k = kAk + kW k.)form sequence I0 , . . . , Ik instances separate-resource variant problem,I` , 0 ` k, identical I, except allowed add `candidates k ` voters. accept least one I` yes instanceseparate-resource, constructive E-AC+AV problem. straightforward seealgorithm correct runs polynomial time.313fiFaliszewski, Hemaspaandra, & Hemaspaandrawould interesting consider variant shared-resource model various actions come different costs (e.g., adding candidate c0 might muchexpensiveor difficultthan adding candidate c00 ). approach wouldclose spirit priced bribery Faliszewski, Hemaspaandra, Hemaspaandra (2009a).Analysis priced control beyond scope current paper.4.2 Susceptibility, Immunity, Vulnerability, Resistancestandard election-control (and election-bribery) literature, consider vulnerability, immunity, susceptibility, resistance control. Let E election systemlet C type control.say E susceptible constructive C control scenarioeffectuating C makes someone become unique winner E election E. sayE susceptible destructive C control scenario effectuating C makessomeone stop unique winner E election E.E immune constructive (respectively, destructive) C control E susceptibleconstructive (respectively, destructive) C control.say E vulnerable constructive (respectively, destructive) C control E susceptible constructive (respectively, destructive) C control polynomial-timealgorithm decides constructive (respectively, destructive) E-C problem. Actually,papers vulnerability algorithms/proofs go polynomial timeproduce, make implicitly clear produce, successful control action.case even achieving so-called certifiable vulnerability Hemaspaandra et al.(2007).E resistant constructive (respectively, destructive) C control E susceptible(respectively, destructive) C control constructive (respectively, destructive) E-Cproblem NP-hard.move theorems, mention two important points putnotions context. Vulnerability (within susceptible settings) polynomial-timerecognition inputs successful attacks (and those, notedabove, actually paper produce attacks), proportion inputsattacks succeed (however, see comments references earlier paperwork studying frequency hardness issues). Also, type multiprong controlthat, example, one on-its-own immune prong on-their-own vulnerableprongs, prove immunity hold. (In cases vulnerabilityhold, cases resistance might hold.) However, portioninput universe allows changes immune-on-its-own prongprongs, one quickly (assuming winner problem given election systempolynomial-time problem) recognize one subspace inputsdetermine whether one achieve ones goal (since due immunity deadprongthat prong cannot raise us failure success).next theorems describe multiprong control problems inherit susceptibility, immunity, vulnerability, resistance basic control typesbuilt from. (We often write (destructive) rather (respectively, destructive),respectively clear context.)314fiMultimode Control Attacks ElectionsTheorem 4.3. Let E election system let C1 + + Ck variant multiprongcontrol (so 1 k 5 Ci basic control type). E susceptible constructive(destructive) C1 + +Ck control E susceptible least one constructive(destructive) C1 , . . . , Ck control.Proof. direction trivial: attacker always choose use typecontrol E susceptible. direction, hard seeinput election C1 + + Ck action achievedesired change (of creating removing unique-winnerhood p, dependingcase), election (not necessarily input election) oneactions alone achieves desired change. essence, view control actiontype C1 + + Ck sequence operations, operation one C1 , . . . , Cktypes, thatwhen executed ordertransform input election electiongoal satisfied. Thus single operation within Aand operation onetypes C1 , . . . , Ck transforms election E 0 goal satisfiedelection E 00 goal satisfied.immediately following corollary.Corollary 4.4. Let E election system let C1 + + Ck variant multiprongcontrol (so 1 k 5 Ci basic control type). E immune constructive(destructive) C1 + + Ck control i, 1 k, E immuneconstructive (destructive) Ci control.next theorem show given election system vulnerable basictype control immune another basic type control, vulnerabletwo types control combined. proof theorem straightforward, needparticularly careful vulnerabilities immunities behave quite unexpectedly.example, might seem assume election system vulnerableAV DV also vulnerable BV, bribing particular voterviewed first deleting voter addingin placea voterpreference order required briber. (This assumes voteramong voters add, arguing susceptibility/immunity makeassumption.) However, simple election system vulnerable AVDV control, immune BV control. system says electionE = (C, V ), C = {c1 , . . . , cm } V = (v1 , . . . , vn ), winner candidate cin 1 (mod m).9Theorem 4.5. Let E election system let C1 + + Ck + D1 + + D` variantmultiprong control (so 1 k 5, 1 ` 5, Ci Di basic controltype) E vulnerable constructive (destructive) C1 + + Ck controli, 1 `, E immune constructive (destructive) Di control.10 E vulnerableC1 + + Ck + D1 + + D` control.9. course, election system neutral; permuting names candidates, evaluatingelections winners, running winners inverse permutation changeoutcome election.10. certainly k + ` 5, since immunity vulnerability mutually exclusive.315fiFaliszewski, Hemaspaandra, & HemaspaandraProof. give proof constructive case only. proof destructivecase analogous. Let E election system statement theorem letinstance constructive E-C1 + + Ck + D1 + + D` control, containselection E = (C, V ), information specifics control actions implement,goal ensure candidate p unique winner. Let us first considercase BV among C1 , . . . , Ck , D1 , . . . D` .Let us assume collection control actions typesC1 , . . . Ck , D1 , . . . , D` , applying actions E legal withinresults election EC+D p unique winner. (We take empty punique winner E.) split two parts, AC AD , AC contains exactlyactions types C1 , . . . , Ck , AD contains exactly actions types D1 , . . . , D` .Since BV among control actions, straightforward see possibleapply actions AC election E obtain election EC . (To see importantconsider BV, assume BV among control types C1 , . . . , Ck AVamong control types D1 , . . . , D` . case, AC might include action bribesvoter added action AD .)claim p unique winner EC . sake contradiction, let us assumecase (note implies p unique winner E).apply control actions AD EC , reach exactly election EC+D , p uniquewinner. Yet, contradiction, Corollary 4.4 E immuneD1 + + D` . is, scenario control actions type D1 + + D`make candidate unique winner unique winner before.Thus possible ensure p unique winner actions type C1 + + Ckalone. chose arbitrarily, thus instance E-C1 + + Ck + D1 + + D`control solved algorithm considers control actions type C1 + + Ckonly. proves E vulnerable C1 + + Ck + D1 + + D` control because,assumed, vulnerable C1 + + Ck control.remains prove theorem case BV among control actions.case BV among control actions AV not, AV BVgroup actions (i.e., either among Ci among Di s),straightforward see proof still works. Similarly, BV amongDi AV among Ci s, proof works well. remaining caseallowed control types include BV AV, BV among Ci AVamong Di s.last case, proof also follows general structure previous construction,except take care one issue: possible AC includes briberyvoters added actions AD . (We use notation mainconstruction.) Let VBV collection voters AC requires bribe,added AD . form collection A0C control actions identical AC , exceptincludes adding voters VBV , let A0D identical AD , exceptlonger includes adding voters VBV . Using A0C A0D instead ACAD , straightforward show following: possible ensure p uniquewinner instance legal action type C1 + + Ck + D1 + + D` , alsopossible legal action type C1 + + Ck + AV, added voteralso bribed. Thus given instance E-C1 + + Ck + D1 + + D` solve316fiMultimode Control Attacks Electionsusing following algorithm. Let W collection voters added withinlet kAV limit number voters add.1. Let min(kAV , kW k).2. {0, 1, . . . , t} execute next two substeps.(a) Form instance 0 identical I, except (arbitrarily chosen) votersW added election.(b) Run E-C1 + + Ck algorithm instance 0 accept does.3. algorithm accepted yet, reject.straightforward see algorithm correct and, since E vulnerableC1 + + Ck , works polynomial time. completes proof theorem.Theorem 4.6. Let E election system let C1 + + Ck variant multiprongcontrol (so 1 k 5 Ci basic control type). i, 1 k,E resistant constructive (destructive) Ci control, E resistant constructive(destructive) C1 + + Ck control.Proof. Let Ci control type E resistant. Since E susceptible constructive (destructive) Ci control, follows Theorem 4.3 E susceptible constructive(destructive) C1 + + Ck control. since E-Ci constructive (destructive) controlproblem essentially (give take syntax) embedded subproblem E-C1 + + Ckcontrol problem, follows E resistant C1 + + Ck control.combining results obtained far Section 4.2, obtain simple toolallows us classify large number multiprong control problems based propertiesprongs. theoremalong forthcoming Classification Rule A,shows apply result well-behaved election systemsis central resultpaper.Theorem 4.7. Let E election system let C1 + + Ck variant multiprongcontrol (so 1 k 5 Ci basic control type), Ci , 1 k,E resistant, vulnerable, immune constructive (destructive) Ci control.i, 1 k, E resistant constructive (destructive) Ci control Eresistant constructive (destructive) C1 + + Ck control. Otherwise, i,1 k, E immune constructive (destructive) Ci control (1 k),immune constructive (destructive) C1 + + Ck control. Otherwise, E vulnerableconstructive (destructive) multiprong control consisting individual prongsamong Ci E vulnerable constructive (destructive) control, Evulnerable constructive (destructive) C1 + + Ck control.avoid confusion, stress throughout ones reading corollary,one must either always use constructive case must always use destructivecaseone cannot mix match. Also, third otherwise really otherwise;claim assumes first case (that least one resistance) hold.317fiFaliszewski, Hemaspaandra, & Hemaspaandravulnerability/resistance/immunity information five individual prongscompletely determine vulnerability/resistance/immunity holds 25 1multiprong settings? would satisfying so. However, later resultspaper show case, since prove two vulnerable prongscombine yield resistance (Theorem 4.12) also combine yield vulnerability (e.g.,Theorem 4.10). (It even plausible may exist cases two vulnerable prongscombine yield multiprong case that, certainly susceptible due Theorem 4.3 (i.e.,immunity impossible case), neither P NP-hard, i.e., neither vulnerableresistant.)However, every voting system certain common, nice property,5 individual prongs vulnerability/resistance/immunity status mechanically read25 1 multiprong results. nice property following.Definition 4.8. say election system E constructive (destructive)vulnerability-combining variant C1 + +Ck multiprong control (so 1 k 5Ci basic control type) holds i, 1 k, E vulnerableconstructive (destructive) Ci control, E vulnerable constructive (destructive)C1 + + Ck control.systems constructive (destructive) vulnerability-combining, straightforward see Theorem 4.7 used read 25 1 multiprong cases, givenstatus five underlying prongs.one practice establish system constructive (destructive)vulnerability-combining? One could try brute force, looking collectionvulnerable prongs. However, better path follow. One lookvulnerable prongs together, prove (if happens case) yield vulnerability. Note successfully implies immediately vulnerability holdsevery nonempty subset prongs. true follows following claim.Proposition 4.9. Let E election system let C1 , . . . , Ck , 1 k 5, collectionbasic control types. i, 1 k, E susceptible constructive (destructive)Ci control, E vulnerable constructive (destructive) C1 + + Ck control,nonempty subset K {C1 , . . . , Ck }, E vulnerable constructive (destructive)multiprong control involving exactly prongs K.Proof. Let notation statement proposition, let Knonempty subset {C1 , . . . , Ck }. Theorem 4.3, E susceptible constructive (destructive) multiprong control constructive (destructive) control type consistingexactly prongs K. Es vulnerability constructive (destructive) C1 + + Ckcontrol, polynomial-time algorithm constructive (destructive) multiprong control involving exactly prongs K: suffices use algorithm constructive(destructive) C1 + + Ck multiprong control, bounds extentnonoccurring prongs used set 0.Motivated discussion Proposition 4.9, Sections 4.3 5show plurality, Condorcet, Copeland (for rational , 0 1), approval,318fiMultimode Control Attacks Electionsmaximin indeed constructive vulnerability-combining destructive vulnerabilitycombining. Thus systems analyzed 25 1 constructive cases25 1 destructive cases multiprong control. Namely, constructive (destructive)vulnerability-combining election system E variant C1 + + Ck , 1 k 5,constructive (destructive) multiprong control i, 1 k, E eitherresistant, vulnerable, immune constructive (destructive) Ci control, usefollowing simple rule (which refer back Classification Rule A) classifyconstructive (destructive) C1 + + Ck multiprong control (note: correctnessthird part classification vulnerability-combining property Erelied on):1. E resistant least one control prongs, resistant wholeattack.2. E immune prongs, immune whole attack.3. neither holds, E vulnerable whole attack.general, consider partition cases control paper. However, makeexception next example, shows even types control givenelection system immune may prove useful multiprong control. constructive controlpartition candidates (reminder: basic control type) ties-eliminatemodel (PC-TE control type), given election E = (C, V ) preferred candidatep C, ask whether possible find partition (C1 , C2 ) C (i.e., C1 C2 = CC1 C2 = ) p winner following two-round election: first findwinner sets, W1 W2 , elections (C1 , V ) (C2 , V ). W1 (W2 ) containsone candidate, set W1 = (W2 = ), since ties eliminate model.candidates win election (W1 W2 , V ) winners overall two-stageelection.Now, let us look constructive approval-AC+PC-TE control, (by definition, letus say) first add new candidates perform partition action. considerapproval election two candidates, p c, p 50 approvals c 100.also allowed add candidate c0 , 100 approvals. Note impossiblemake p unique winner adding c0 . Exercising partition action aloneensure ps victory either. However, combining AC PC-TE job. firstadd c0 election partition candidates {p} {c, c0 } then, dueties-eliminate rule, p becomes unique winner. rather interesting even thoughapproval immune constructive AC control, cases one apply ACcontrol open possibility effectively using types control.example perhaps surprising light Theorem 4.5. essence, prooftheorem argue election system vulnerable basic control typeC immune basic control type D, also vulnerable controltype C + D. proved theorem showing safely disregard actionstype (assuming C include BV control type). example showsproof approach would work considered PC-TE addition basic controltypes.319fiFaliszewski, Hemaspaandra, & Hemaspaandra4.3 Combining Vulnerabilitiesprevious section considered case separate prongs multiprong controlproblem different computational properties, e.g., resistant, vulnerable, immune. section consider case election systemvulnerable prong separately, show vulnerabilities combine withinelection systems control results obtained previous papers (see Table 5).particular, next theorem show election systems consideredBartholdi et al. (1992), Hemaspaandra et al. (2007), Faliszewski, Hemaspaandra,Hemaspaandra, Rothe (2009a), constructive vulnerabilities AC, DC, AV, DV,BV combine vulnerabilities, destructive vulnerabilities AC, DC, AV, DV,BV combine vulnerabilities.11 Using (and additional discussion correctlyhandle possibility P = NP), soon conclude election systemstudied three papers constructive vulnerability-combining destructivevulnerability-combining.Theorem 4.10. (a) Plurality vulnerable constructive AV+DV+BV controldestructive AV+DV+BV control. (b) Condorcet approval vulnerableAC+AV+DV+BV destructive control. (c) rational , 0 1, Copelandvulnerable destructive AC+DC control.12Proof. (a) Let us consider instance constructive plurality-AV+DV+BV controlwant ensure candidate ps victory: enough add voters votep (or many allowed) then, loop, keep deleting voters votecandidate p highest score, p candidatehighest score exceeded limit voters delete. Finally, loop, keepbribing voters vote candidate p highest score vote p,p candidate highest score exceeded limit votersbribe. p becomes unique winner via procedure, accept. Otherwise reject.omit straightforward proof destructive case.(b) Let instance destructive Condorcet-AC+AV+DV+BV, goalprevent candidate p Condorcet winner (we assume p Condorcetwinner control action performed). enough ensure candidatec wins head-to-head contest p. algorithm works follows.Let C set candidates originally election let set candidatesadd (we take = allowed add candidates).c (C A) {p} following:1. Add many voters prefer c p possible.11. Constructive bribery plurality constructive bribery approval considered Faliszewski, Hemaspaandra, Hemaspaandra (2009a) constructive destructive bribery Copelandstudied Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2009a). Theorem 4.10wein effectgive polynomial-time algorithms destructive bribery plurality, approval,Condorcet. Constructive Condorcet-BV NP-complete implicitly shown Faliszewski,Hemaspaandra, Hemaspaandra, Rothe (2009a, Theorem 3.2).12. Regarding types among AC, DC, AV, DV, BV mentioned part theorem,plurality resistant constructive destructive AC DC, Condorcet approval immuneconstructive AC destructive DC, rational , 0 1, Copeland resistantfive constructive basic types control destructive AV, DV, BV (see Table 5 references).320fiMultimode Control Attacks Elections2. Delete many voters prefer p c possible.3. Among remaining voters prefer p c, bribe many possible rank cfirst.actions c wins head-to-head contest p accept.c (C A) {p} leads acceptance, reject. straightforward seealgorithm correct runs polynomial time. (We point enough addsingle candidate, candidate c prevents p winning, happensmember A).case approval, algorithm works similarly, except following differences:add voters approve c p. delete voters approve pc. remaining voter vi , still exceeded bribing limit, vi approvesp c, bribe vi reverse approvals p c. (Noteexceed bribing limit procedure, means voter approves palso approves c thus p unique winner.) actions lead punique winner, accept. accept c (C A) {p}, reject.(c) idea combine Copeland destructive-AC destructive-DC algorithms (Faliszewski, Hemaspaandra, Hemaspaandra, & Rothe, 2009a). give fullproof sake completeness.Let us fix rational value , 0 1. Given election E candidate celection, write scoreE (c) denote Copeland score c. Let instancedestructive Copeland -AC+DC control, election E = (C, V ),add kAC spoiler candidates set A, delete kDCcandidates. goal ensure despised candidate C unique winner.algorithm based following simple observation Faliszewski, Hemaspaandra,Hemaspaandra, Rothe (2009a). candidate c C:score(C,V ) (c) =Xscore({c,c0 },V ) (c).c0 C{c}goal prevent candidate unique winner. unique winner,immediately accept. Otherwise, seek candidate c C ensurecs score least high d. Thus c C following.1. c A, kAC > 0, add c election (and c kAC = 0, proceednext c).2. long still add candidates, keep executing following operation:candidate c0 value a(c0 ) = score({c,c0 },V ) (c)score({d,c0 },V ) (d)positive, add candidate c00 A, a(c00 ) highest.3. long still delete candidates, keep executing following operation:candidate c0 C value r(c0 ) = score({d,c0 },V ) (d) score({c,c0 },V ) (c)positive, delete candidate c00 C, r(c00 ) highest.4. steps unique winner, accept.321fiFaliszewski, Hemaspaandra, & Hemaspaandraaccept c C A, reject.straightforward see never delete candidate added. Also,straightforward see algorithm works polynomial time, correct.Correctness follows fact (a) main loop algorithm, dealingcandidate c C A, addition candidate deletion candidateincreases difference score c score much possible,(b) order adding/deleting candidates irrelevant.theorem, comments preceding it, bit care regardingpossibility P = NP, obtain following claim.Theorem 4.11. Plurality, Condorcet, Copeland (for rational , 0 1), approval constructive vulnerability-combining destructive vulnerability-combining.Proof. Immune prongs never vulnerable. P 6= NP resistant prongs cannotvulnerable, already done previous theorem. P = NP, possibleresistant prongs also vulnerable. Indeed, systems discussionproof, resistant prongs basic control types happen NPvulnerable P = NP. However, straightforward see P = NP,particular election systems holds vulnerable constructive (destructive)basic prongswhich case nonimmune basic constructive(destructive) prongswhen combined yield multiprong constructive (destructive) controltype vulnerability holds.established Theorem 4.11 (soon-to-come) results Section 5, naturalelection systems discussed far paper vulnerability-combiningconstructive setting destructive setting. natural wonder whethernecessary consequence model multiprong control whether factelection system combining two control types system vulnerableyields multipronged control problem system resistant. Theorem 4.12 showslatter case, even natural election system.thirteenth century, Ramon Llull proposed election system could usedchoose popes leaders monastic orders (see Hagele & Pukelsheim, 2001; McLean& Lorrey, 2006). system, voters choose winner among (so,candidates voters). Apart that, Llulls voting system basicallyCopeland1 , version Copeland richly rewards ties. Formally, definevoting system OriginalLlull follows: election E = (C, V ), set namesV , denote names(V ), equal C, winners.Otherwise, candidate c C winner Copeland1 winner. Notesingle-prong AC AV control OriginalLlull make much sense,come surprise OriginalLlull vulnerable constructive AC controlconstructive AV control. addition, show (by renaming padding)Copeland1 -AV reduced OriginalLlull1 -AC+AV. Since Copeland1 resistantconstructive control adding voters (Faliszewski, Hemaspaandra, Hemaspaandra, &Rothe, 2009a), leads following theorem.Theorem 4.12. OriginalLlull vulnerable constructive AC control constructiveAV control resistant constructive AC+AV control.322fiMultimode Control Attacks ElectionsProof. immediate OriginalLlull susceptible constructive AC, AV,(by Theorem 4.3) AC+AV control. also straightforward see constructiveOriginalLlull-AC (AV) control P: possible add candidates (voters)set voter names equal set candidates, check preferred candidate unique Copeland1 winner. possible, reject.show, via reduction constructive Copeland1 -AV control (whichNP-hard Faliszewski, Hemaspaandra, Hemaspaandra, & Rothe, 2009a) constructiveOriginalLlull-AC+AV control NP-hard. Let C set candidates, let V Wtwo disjoint collections voters preference lists C, let p C preferredcandidate, k element N. question whether exists subcollectionW 0 W size k p unique Copeland1 winner (C, V W 0 ). Withoutloss generality, assume V empty.show pad election. OriginalLlull election nontrivial,certainly need number candidates voters (later, also renamevoters candidates). kV k < kCk, want addcollection new dummy voters V 0 kV k + kV 0 k = kCk adding V 0election change relative Copeland1 scores candidates.accomplished letting half voters V 0 vote C (recall Convention 3.1) halfvoters V 0 vote C . course, done kV 0 k even.So, following. kV k < kCk, add collection new voters V 0kV 0 k = kCk kV k kCk kV k even, kV 0 k = kCk kV k + 1 kCk kV kodd. kV k kCk, let V 0 = . Half voters V 0 vote C halfvoters V 0 vote C . addition, introduce set new candidateskCk + kAk = kV k + kV 0 k + kW k. Note always possible, since kV k + kV 0 k kCk.extend votes voters (in V , V 0 , W ) C taking preferenceorder C following candidates fixed, arbitrary order. Noteeffect candidates never winners.Let W 0 W , A0 A, E = (C, V W 0 ), E 0 = (C A0 , V V 0 W 0 ). straightforwardsee following hold (recall V empty).1. A0 , score1E 0 (d) kA0 k 1.2. c C, score1E 0 (c) = score1E (c) + kA0 k.3. c, c0 C, c 6= c0 , score1E (c) score1E (c0 ) = score1E 0 (c) score1E 0 (c0 ).4. p unique Copeland1 winner E p unique Copeland1 winnerE0.ready define reduction. Name voters names(V V 0 ) Cnames(V V 0 W ) = C A. map (C, V, W, p, k) (C, A, V V 0 , W, p, kAk, k).claim p made unique Copeland1 winner (C, V ) adding kvoters W p made unique OriginalLlull winner (C, V V 0 )adding (an unlimited number of) candidates k voters W .First suppose W 0 subcollection W size k punique Copeland1 winner (C, V W 0 ). Let A0 set candidates323fiFaliszewski, Hemaspaandra, & HemaspaandraC A0 = names(V V 0 W 0 ). item 4 above, p unique Copeland1 winner(C A0 , V V 0 W 0 ), thus p unique OriginalLlull winner (C A0 , V V 0 W 0 ).converse, suppose exist A0 W 0 W kW 0 k k,p unique OriginalLlull winner (C A0 , V V 0 W 0 ). p uniqueCopeland1 winner (C A0 , V V 0 W 0 ), and, item 4, p unique Copeland1 winner(C, V W 0 ).Thus reduction correct and, since computed polynomial time,proof complete.following corollary, since OriginalLlull neutral (permuting namescandidates, evaluating elections winners, running winnersinverse permutation affect outcome election) anonymous(permuting names voters affect outcome election).13Corollary 4.13. exists neutral anonymous election system E Evulnerable constructive AC control constructive AV control resistantconstructive AC+AV control.Something might seem bit strange Theorem 4.12. all, sayspowerful chairone add candidates add votersfaces harder taskwould faced weaker chairsay, one add candidates. importantthing keep mind, understand strange, different chairsfacing (correspondingly) different problems. powerful type chair askeddetermine whether specified amounts adding candidates voters goalmet, weaker type chair asked whether specified amount addingcandidates goal met. Thus paradoxical former problemhigher complexity latter. (After all, powerful solution-finderoneallowed use assignmentseeking find satisfying assignment input Booleanformulas facing NP-hard task, weak solution-finderone allowed findsolutions 2011 variables assigned Falseseeking find input Booleanformulas satisfying assignment, exists, 2011 variables assignedFalse faces polynomial-time task, due natural brute-force approach.)4.4 Summarysummarize main contributions Section 4. try motivateinterpret results, rather summarize results are, readereasily jump back section reference.13. notion anonymity stated standard one literature. avoid confusion,mention earlier version (Faliszewski, Hemaspaandra, & Hemaspaandra, 2010a) paper usedmuch stronger definition anonymityone required one able permute voternames one-to-one map set names yet outcome change. Let uscall notion voter-superanonymity. OriginalLlull satisfy stronger notion. However,earlier version paperby sneakily building preference orders voters namescandidatesconstructed highly artificial system neutral, anonymous (in sensepresent paper), voter-superanonymous, two vulnerable prongs combinedyielded resistance (Faliszewski et al., 2010a). contrast, Theorem 4.12/Corollary 4.13 providesjump vulnerability resistance preexisting, natural voting system neutralanonymous.324fiMultimode Control Attacks ElectionsC1RRRVC2RVVVC1 + C2RRRVsusceptible (i.e., I)Table 2: example applying Theorem 4.7. Let E election system. considertwo basic types constructive (destructive) control, C1 C2 , Eeither resistant (R), immune (I), vulnerable (V). table shows C1 + C2control E inherits properties prongs. Note Theorem 4.7give results case E vulnerable C1 C2(although Theorem 4.3 susceptibility must hold). see this, notevulnerability-combining systems putting together two vulnerable prongs leadstwo-pronged control problem system vulnerable.examples voting systems combining two vulnerable prongs leadsresistant two-pronged control problem (see Theorem 4.12).Section 4.1, introduced model multiprong control, allows attackeruse several types control jointly, either try make given candidate unique winner(constructive control), try prevent given candidate unique winner(destructive control).Section 4.2 focused following issue: Let E election system. LetC1 + + Ck variant multiprong control (so 1 k 5 Ci basiccontrol type). Suppose know, Ci , 1 k, whether E resistant, immune,vulnerable constructive (destructive) control type Ci . extentalone tell whether E resistant, immune, vulnerable constructive (destructive)C1 + + Ck multiprong control? Theorem 4.7 paragraphs following providedetailed answer. example applying Theorem 4.7, Table 2 show propertiestwo control prongs, C1 C2 , combine properties two-pronged C1 + C2 control.Simply stated, Theorem 4.7 (for systems prong happens immunevulnerable resistantand include essentially reasonable, natural election systems polynomial-time winner problems) gives read-off-the-answer classification multiprong cases, except system multiple vulnerable constructiveprongs multiple vulnerable destructive prongs. handle case, casesystems (where prong happens immune vulnerable resistant)multiple vulnerable constructive (destructive) prongs, defined notion constructive (destructive) vulnerability-combining election systems, provided ClassificationRule simple rule classifies multiprong control cases. also provided handytool, Proposition 4.9, proving election system vulnerability-combining.conjecture almost natural systems vulnerability-combining.Finally, Section 4.3 considered several natural election systems controlalready studied (namely, plurality, Condorcet, Copeland (for rational ,325fiFaliszewski, Hemaspaandra, & HemaspaandraElection systemPluralityCondorcetCopeland , 0 1ApprovalMaximinresults combine multiprong vulnerability immune vulnerable entriescolumn Table 5ConstructiveDestructiveAV+DV+BVAV+DV+BVAC+DCAC+DC+AV+DV+BV(none)AC+DCAC+DCAC+DC+AV+DV+BVDCAC+DCTable 3: Summary vulnerability results multiprong control plurality, Condorcet, Copeland , approval voting systems. Regarding five basic controltypes, summarize column Table 5 least onevulnerable entry, established multiprong combinationimmunity vulnerability entries column remains vulnerable. results obtained combining Theorem 4.10 Theorem 4.7 (with Theorem 4.7letting us add basic control types given system immune).sake completeness, also included analogous results regarding maximin, Section 5.0 1), approval), systems proved systemconstructive vulnerability-combining destructive vulnerability-combining (seeTheorem 4.11 formal result; Table 3 summarizes actual combinationsplay unless P = NP). Nonetheless, Theorem 4.12 shown ancientelection system OriginalLlull two vulnerable prongs combine yield resistance;unless P = NP, OriginalLlull vulnerability-combining.5. Control Maximinsection initiate study control maximin election system. Maximinloosely related Copeland voting sense defined termspairwise head-to-head contests. addition, unweighted coalitional manipulation problem maximin Copeland ( 6= 0.5) exhibits behavior: P onemanipulator NP-complete two manipulators (Xia, Zuckerman, Procaccia,Conitzer, & Rosenschein, 2009; Faliszewski, Hemaspaandra, & Schnoor, 2008, 2010). Thusone might wonder whether systems similar regard resistancescontrol. fact, interesting differences.straightforward see maximin susceptible basic types constructivedestructive control. so, Theorem 4.3, show vulnerability constructive(destructive) C control suffices give polynomial-time algorithm decidesconstructive (destructive) E-C problem, show resistance constructive (destructive)C control suffices show constructive (destructive) E-C problem NP-hard.consequence analysis given following subsections, maximinconstructive vulnerability-combining destructive vulnerability-combining.326fiMultimode Control Attacks ElectionsTheorem 5.1. Maximin constructive vulnerability-combining destructivevulnerability-combining.Proof. discussion analysis provided proof Theorem 4.11 apply here,except relying underpinning work provided later section. constructivecase degenerate, among basic prongs one interest (althoughbriefly discuss special extra prong later). Even destructive case,two basic prongs resistant.5.1 Candidate Control MaximinLet us focus candidate control maximin, is, AC DC controltypes, constructive destructive setting. case Copeland ,0 1, maximin resistant control adding candidates.Theorem 5.2. Maximin resistant constructive AC control.Proof. give reduction X3C. Let (B, S), B = {b1 , . . . , b3k } set3k elements = {S1 , . . . , Sn } set 3-subsets B, input X3C instance.form election E = (C A, V ), C = B {p}, = {a1 , . . . , }, V =(v1 , . . . , v2n+2 ). (Candidates spoiler candidates, attackerability add election (C, V ).)Voters V following preferences. Si S, voter vi reports preferencelist p > B Si > ai > Si > {ai } voter vn+i reports preference list {ai } > ai >Si > B Si > p. Voter v2n+1 reports p > > B voter v2n+2 reports B > p > .claim set A0 kA0 k k p unique winner(C A0 , V ) (B, S) yes instance X3C.show claim, let E 0 = (C, V ). pair distinct elements bi , bj B,NE 0 (bi , bj ) = n+1, NE 0 (p, bi ) = n+1, NE 0 (bi , p) = n+1. is, candidatesE 0 tie. consider set A00 A, kA00 k k, election E 00 = (C A00 , V ). ValuesNE 00 NE 0 pair candidates {p}B. pair distinctelements ai , aj A00 , NE 00 (p, ai ) = n + 2, NE 00 (ai , p) = n, NE 00 (ai , aj ) = n + 1.bi B aj A00NE 00 (bi , aj ) =nn+1bi Sj ,bi/ Sj ,and, course, NE 00 (aj , bi ) = 2n + 2 NE 00 (bi , aj ). Thus, definition maximin,following scores E 00 : (a) scoreE 00 (p) = n + 1, (b) aj A00 , scoreE 00 (aj ) = n,(c) bi B,n(aj A00 )[bi Sj ],scoreE 00 (bi ) =n + 1 otherwise.A00 corresponds family 00 3-sets j, 1 j n, 00contains set Sj A00 contains aj . Since kA00 k k, straightforward seep unique winner E 00 00 exact cover B.327fiFaliszewski, Hemaspaandra, & HemaspaandraCopeland , 0 1, resistant constructive AC control, {0, 1},Copeland vulnerable constructive control adding unlimited number candidates. turns maximin. However, interestingly, contrast Copeland,maximin also vulnerable DC control.Rather proving that, prove bit more: momentdiscuss different control type, ACu , consider one five basictypes. ACu control (called control adding unlimited number candidates)like control adding candidates, except (by definition) limit numbercandidates addin effect, one requires kAC = kAk.14 show maximinvulnerable DC control fact even ACu +DC control. Intuitively, constructive ACu +DC control add many candidates possible (because addingcandidate generally decreases candidates scores, making preferred candidatesway victory easier) delete candidates stand candidates way(i.e., whose existence blocks preferred candidates score increasing). Studyingconstructive ACu +DC control maximin jointly leads compact, coherent algorithm.consider control types separately, would give two fairly similaralgorithms obtaining weaker result.Theorem 5.3. Maximin vulnerable constructive ACu +DC control.Proof. give polynomial-time algorithm constructive maximin-ACu +DC control.input contains election E = (C, V ), set spoiler candidates A, preferredcandidate p C, nonnegative integer kDC . Voters V preference listscandidates C A. ask whether exist sets A0 C 0 C (a)kC 0 k kDC (b) p unique winner election ((C C 0 ) A0 , V ). kDC kCk 1,accept immediately delete candidates p. Otherwise, usefollowing algorithm.Preparation. rename candidates C C = {p, c1 , . . . , cm } ={cm+1 , . . . , cm+m0 }. Let E 0 = (C A, V ) let P = {NE 0 (p, ci ) | ci C A}.is, P contains values candidate p may obtain scores upon deletingcandidates E 0 . k P , let Q(k) = {ci | ci C A{p}NE 0 (p, ci ) < k}.Intuitively, Q(k) set candidates E 0 prevent p least kpoints.14. control type ACu historical interest used control adding candidatesnotion seminal paper control. However, following suggestion Faliszewski, Hemaspaandra,Hemaspaandra, Rothe (2007), AC used work recent years; naturalchoice since analogous three add/delete voter/candidate control types. additionTheorem 5.3s result constructive case, mention passing maximins vulnerabilitydestructive AC (see Theorem 5.4 light Proposition 4.9) implies also vulnerable ACu .Readers wishing know results hold prong ACu election systems coveredpaper find summarized table Faliszewski et al. (2010a)except 6= 0.5cases Copeland , cases Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2009a)referred to. entire set tools Section 4.2 framed around five basic control types,try weave ACu framework. mention tools apply well typealso, would prove special hurdle incorporate framework. Still, feelAC (not ACu ) far attractive way frame control adding candidatesaddition compelling.328fiMultimode Control Attacks ElectionsMain loop. k P , algorithm tests whether deleting kDC candidates C number candidates possible ensure pobtains exactly k points becomes unique winner E 0 . Let us fix valuek P . build set candidates delete. Initially, set = Q(k).straightforward see deleting candidates Q(k) necessary sufficientcondition p score k. However, deleting candidates Q(k) necessarilysufficient ensure p unique winner candidates scores greaterequal k may exist. execute following loop (which call fixingloop):1. Set E 00 = ((C A) D, V ).2. Pick candidate (C A) scoreE 00 (d) k (break loopcandidate exists).3. Add jump back Step 1.accept C kDC proceed next value k otherwise.15 nonevalues k P leads acceptance reject.Let us briefly explain algorithm correct. straightforward seemaximin adding candidate c election increase candidatesscores, deleting candidate election decrease candidatesscores. Thus, deleting candidates Q(k) still candidates pk points more, way ensure ps victorywithout explicitly trying increaseps scoreis deleting candidates. Also, note way ensure pexactly k points deleting candidates Q(k).Note execution fixing loop, score p might increasevalue k 0 > k. happens, means impossible ensure ps victorykeeping score equal k. However, need change k k 0iteration main loop consider k 0 different iteration.Maximin also vulnerable destructive AC+DC control. proof relies fact(a) way prevent despised candidate winning maximin electionvia adding spoiler candidates way adding twocandidates, (b) adding candidate cannot increase score candidateadded one, (c) deleting candidate cannot decrease score candidatedeleted one. essence, algorithm performs brute-force searchcandidates add uses constructive maximin-DC control algorithmTheorem 5.3.Theorem 5.4. Maximin vulnerable destructive AC+DC control.Proof. remind reader part definition destructive control deletingcandidates one cannot simply delete ones despised candidate.15. accept, implicitly describes control action ensures ps victory: deleteC candidates C add candidates D.329fiFaliszewski, Hemaspaandra, & Hemaspaandrafirst give algorithm destructive maximin-AC arguecombined algorithm Theorem 5.3 solve destructive maximin-AC+DCpolynomial time.Let us first focus destructive AC problem. input election E =(C, V ), C = {d, c1 , . . . , cm } V = (v1 , . . . , vn ), spoiler candidate set ={cm+1 , . . . , cm0 }, nonnegative integer kAC . voters preference ordersC A. goal ensure unique winner E via adding kACcandidates A.Let us assume exists set A0 unique winnerelection E 0 = (C A0 , V ). Since unique winner E 0 , exists candidatec0 C A0 scoreE 0 (c0 ) scoreE 0 (d). Also, definition maximin,candidate d0 C A0 scoreE 0 (d) = NE 0 (d, d0 ). consequence,unique winner election E 00 = (C {c0 , d0 }, V ). reason scoreE 00 (d) = scoreE 0 (d)(because E 0 E 00 contain d0 ) scoreE 00 (c0 ) scoreE 0 (c0 ) (because addingremaining A0 {c0 , d0 } candidates E 00 increase c0 score). Thus, test whetherpossible ensure unique winner E, suffices test whetherset A00 kA00 k min(2, kAC ) unique winner (C A00 , V ).Note test carried polynomial time.Let us consider AC+DC case. input goal before,except also given nonnegative integer kDC allowed deletekDC candidates. describe algorithm. set {c0 , d0 } twocandidates, {c0 , d0 } (C A) {d} execute following steps.1. check kA {c0 , d0 }k kAC (and proceed next {c0 , d0 }case).2. compute set C {d, c0 , d0 }, kDk kDC , maximizes scoreE 0 (c0 ),E 0 = ((C {c0 , d0 }) D, V ).3. unique winner E 0 = ((C {c0 , d0 }) D, V ), accept.reject accept {c0 , d0 } (C A) {d}.intended role d0 lower score keep fixed level, while,course, intended role c0 defeat d. reasoning analogous ACcase, see need add two candidates. Thus, given {c0 , d0 },remains compute appropriate set D. essence, mannerconstructive AC+DC case.Let k positive integer. set D(k) = {ci C {c0 , d0 , d} | NE (c0 , ci ) < k}pick = D(i), large possible (but larger kV k) kDk kDC .Deleting candidates maximizes score c0 , given cannot delete d0 (wecannot delete definition control deleting candidates, cannotor,precisely, want todelete d0 role d0 algorithm keepscore check). straightforward see computed polynomialtime.330fiMultimode Control Attacks Elections5.2 Control Adding Deleting Voters Maximinsection consider complexity constructive destructive AV DV control types. (We consider bribery, BV, next section; recall paper,bribery basic control type, though usually treated separately literature.)previous section seen maximin vulnerable basic types constructive destructive candidate control except constructive control adding candidates(constructive AC control). situation regarding voter control quite different:shown next three theorems, maximin resistant basic types constructivedestructive voter control.Theorem 5.5. Maximin resistant constructive destructive AV control.Proof. first give NP-hardness proof constructive casedescribe modify destructive case.give reduction X3C problem constructive maximin-AV problem.input X3C instance (B, S), B = {b1 , . . . , b3k } set 3k distinct elements= {S1 , . . . , Sn } family n 3-element subsets B. Without loss generality,assume k 1. reduction outputs following instance. electionE = (C, V ), C = B {p, d} V = (v1 , . . . , v4k ). 2k voterspreference order > B > p, k voters preference order p > B > d, k voterspreference order p > > B. addition, collection W = (w1 , . . . , wn ) votersadded, ith voter, 1 n, preference orderB Si > p > Si > d.claim subcollection W 0 W kW 0 k k p uniquewinner election (C, V W 0 ) (B, S) yes instance X3C.straightforward verify bi B holds NE (p, bi ) = 2k,NE (p, d) = 2k. Thus scoreE (p) = 2k. Similarly, straightforward verifyscoreE (d) = 2k, bi B, scoreE (bi ) k. Let W 00 subcollection WkW 00 k k let E 00 = (C, V W 00 ). bi B holds scoreE 00 (bi )2k. Since voter W ranks least desirable candidate, scoreE 00 (d) = 2k.ps score election E 00 ? exists candidate bi B voterwj W 00 prefers p bi , scoreE 00 (p) = 2k (because NE 00 (p, bi ) = 2k). Otherwise,scoreE 00 (p) 2k + 1. Thus p unique winner E 00 W 00 correspondsexact cover B. proves claim and, reduction straightforwardly seencomputable polynomial time, concludes proof constructive maximin-ACcase.show destructive maximin-AC NP-hard, use reduction, exceptremove V single voter preference list p > B > d, set taskpreventing unique winner. Removing p > B > voter V ensuresstart adding candidates, score 2k (and score cannot changed),p score 2k 1 (and p needs get one point extra candidate increasescore prevent unique winner), bi B scorek 1 (thus candidate B obtain score higher 2k 1 via addingk candidates W ). reasoning constructive case provesreduction correctly reduces X3C destructive maximin-AV.331fiFaliszewski, Hemaspaandra, & HemaspaandraTheorem 5.6. Maximin resistant constructive destructive DV control.Proof. first show NP-hardness constructive maximin-DV controlargue modify construction obtain result destructive case.reduction X3C. Let (B, S) input X3C instance, B ={b1 , . . . , b3k }, = {S1 , . . . , Sn }, i, 1 n, kSi k = 3. Without lossgenerality, assume n k 3 (if n < k contain cover B,k 2 solve problem brute force). form election E = (C, V ),0 ), V 00 = (v 00 , . . . , v 00C = B {p, d} V = V 0 V 00 , V 0 = (v10 , . . . , v2n12nk+2 ).0i, 1 n, voter vi preference order> B Si > p > Si0voter vn+ipreference order> Si > p > B Si .Among voters V 00 have: 2 voters preference order p > > B, n k voterspreference order p > B > d, n voters preference order B > p > d. claimpossible ensure p unique winner election E via deleting kvoters (B, S) yes instance X3C.Via routine calculation see candidates election E following scores:1. scoreE (d) = 2n (because NE (d, p) = 2n bi B, NE (d, bi ) = 2n + 2),2. scoreE (p) = 2nk +2 (because NE (p, d) = 2nk +2 bi B, NE (p, bi ) =2n k + 2),3. bi B, scoreE (bi ) 2n k (because NE (bi , d) = 2n k).voters deleted, unique winner k 2 points p. Viadeleting k voters possible decrease ds score k points. Let Wcollection voters p unique winner E 0 = (C, V W ). partitionW W 0 W 00 , W 0 contains members W belong V 0 W 00contains members W belong V 00 . claim W 00 empty.sake contradiction let us assume W 00 6= . Let E 00 = (C, V W 00 ). Since everyvoter V 00 prefers p d, NE 00 (p, d) = NE (p, d) kW 00 k and, result,scoreE 00 (p) scoreE (p)kW 00 k. addition, assuming W 00 empty, straightforwardobserve scoreE 00 (d) scoreE (d) kW 00 k + 1 (the reason deletingsingle member V 00 decrease ds score). is, that:scoreE 00 (p) 2n k + 2 kW 00 k,scoreE 00 (d) 2n + 1 kW 00 k.E 00 , least k 1 points p. Since kW 00 k 1, deletek 1 voters W 0 election E 00 . p unique winner E 0 ,contradiction.Thus W contains members V 0 only. Since ranked first every vote V 0 , deletingvoters W decreases ds score exactly kW k. Further, deleting voters W certainlydecreases ps score least one point. Thus deleting voters W have:332fiMultimode Control Attacks Elections1. scoreE 0 (d) = 2n kW k,2. scoreE 0 (p) 2n k + 2 1 = 2n k + 1.consequence, possibility p unique winner deleting voters WkW k = k equality item 2 above. straightforward verifyequality holds W contains k voters among v10 , . . . , vn0 correspondexact cover B via sets (recall k 3). proves reductioncorrect, since reduction straightforwardly seen computable polynomialtime, completes proof NP-hardness constructive maximin-DV control.Let us consider destructive case. Let (B, S) input X3C instance (with Bconstructive case). form election E = (C, V ) identical one00created constructive case, except V 00 = (v100 , . . . , v2nk) set voterspreference orders follows: one voter preference order p > > B, n kvoters preference order p > B > d, n 1 voters preference order B > p > d.(That is, compared constructive case, remove one voter preference orderp > > B one preference order B > p > d.) straightforward seeunique winner election E claim preventedunique winner via deleting k voters exact cover Bk sets S.Via routine calculation, straightforward verify scoreE (d) = 2n,scoreE (p) = 2n k. former holds NE (d, p) = 2n NE (d, bi ) = 2n + 1latter holds NE (p, d) = 2n k candidate bi BNE (p, bi ) = 2n k + 1. addition, candidate bi B score 2n k 1.Thus possible ensure unique winner via deleting k votersexactly k voters deletion would decrease scorek points would decrease ps score. Let us assume collection votersexists let W collection. Since every voter V 00 prefers p d, note Wcontain voter V 00 . Thus W contains exactly k voters V 0 . Sincebi B NE (p, bi ) = 2n k + 1, bi B W contains one voterprefers p bi . Since kBk = 3k k 3, implies W contains exactlycollection voters corresponding exact cover B sets S. completesproof destructive case.5.3 Bribery Maximinmove bribery maximin. Given previous results, surprisingmaximin resistant constructive bribery destructive bribery. proofapplication UV technique Faliszewski, Hemaspaandra, Hemaspaandra,Rothe (2009a). informally, idea build election way ensuresbriber limited bribing voters rank two special candidates aheadpreferred one.Theorem 5.7. Maximin resistant constructive destructive BV control.Proof. proofs follow via reductions X3C. reduction constructive casealmost identical one constructive case thus consider casesparallel.333fiFaliszewski, Hemaspaandra, & Hemaspaandrareductions work follows. Let (B, S) instance X3C, B ={b1 , . . . , b3k } set 3k distinct elements, = {S1 , . . . , Sn } family 3-elementsubsets B. (Without loss generality, assume n > k > 1. case,trivial verify (B, S) yes instance X3C.) construct set candidatesC = {p, d, s} B, p preferred candidate (the goal constructive settingensure p unique winner) despised candidate (the goal destructivesetting prevent unique winner). construct six collections voters,V 1 , V 2 , V 3 , V 4 , V 5 , V 6 , follows:1 . i, 1 n, voters v 1 v 11. V 1 contains 2n voters, v11 , . . . , v2ni+nfollowing preference orders:vi1 : > > Si > p > B Si1vn+i: B Si > p > Si > > s.2 . i, 1 k, voters v 2 v 22. V 2 contains 2k voters, v12 , . . . , v2ki+kfollowing preference orders:vi2 : > > p > B2vk+i: B > > p > s.3 . i, 1 k, voters v 3 v 33. V 3 contains 2k voters, v13 , . . . , v2ki+kfollowing preference orders:vi3 : > > p > B3: B > > p > d.vk+i4 . i, 1 2k, voters v 4 v 44. V 4 contains 4k voters, v14 , . . . , v4ki+2kfollowing preference orders:vi4 : > B > p >4v2k+i: > p > > B.5. V 5 contains 2 voters, v15 , v25 following preference ordersv15 : > B > p >v25 : > B > p > s.6. V 6 contains single voter, v16 , preference order p > > > B.form two elections, Ec Ed , Ec = (C, V 1 V 6 ) Ed = (C, V 1V 5 ); is, Ec Ed identical except Ed contain single voterV 6 . Ec contains 2n + 8k + 3 voters Ed contains 2n + 8k + 2 voters. Values NEcNEd pair candidates given Table 4.334fiMultimode Control Attacks Elections(a) Values NEc (, ).pBpn + 5k + 1n + 5k + 1n + 4k + 2n + 3k + 24k + 1n + 2k + 1n + 3k + 22n + 4k + 2n + 4k + 1Bn + 4k + 1n + 6k + 2n + 4k + 2n + 4k + 2(b) Values NEd (, ).pBpn + 5k + 1n + 5k + 1n + 4k + 2n + 3k + 14k + 1n + 2k + 1n + 3k + 12n + 4k + 1n + 4k + 1Bn + 4kn + 6k + 1n + 4k + 1n + 4k + 1Table 4: Values NEc (, ) NEd (, ) pair candidates. Let E one Ec , Ed .entry row c0 {p, d, s} column c00 {p, d, s}, c0 6= c00 , appropriatetable gives value NE (c0 , c00 ). row B column B adoptfollowing convention. c {p, d, s} bi B, entry row Bcolumn c equal NE (bi , c). c {p, d, s} bi B,entry row c column B equal NE (c, bi ). two distinct bi , bj B,entry row B column B upper bound NE (bi , bj ). (For Edentry is, fact, exact.)constructive case, claim possible ensure p unique winnerelection Ec bribing k voters (B, S) yes instance X3C.Let us prove claim. inspecting Table 4, recalling n > k > 1, seescoreEc (p) = n + 3k + 2, scoreEc (d) = n + 5k + 1, scoreEc (s) = 4k + 1,bi B, scoreEc (bi ) n + 2k + 1. is, prior bribing, unique winnerp second highest score.straightforward see bribing k voters, briber changecandidates score points. Thus, bribery successful, briberbribe exactly k voters way ds score decreases n + 4k + 1 ps scoreincreases n + 4k + 2. achieve this, briber find collection V 0 voterskV 0 k = k,1. voter V 0 ranks p s,2. bi B, voter V 0 ranks p bi .voters satisfy first condition v11 , . . . , vn1 , v12 , . . . , vk2 , v13 , . . . , vk3 . Further,among voters v11 , . . . , vn1 rank p member B and, fact,i, 1 n, vi1 ranks p exactly three members B. Thus straightforwardsee k voters v11 , . . . , vn1 , v12 , . . . , vk2 , v13 , . . . , vk3 satisfy second conditioncorrespond naturally cover B sets S. (Note suffices briberbribes voters V 0 rank p first without changing votes way,335fiFaliszewski, Hemaspaandra, & Hemaspaandrachanging votes way ranking p first necessary.) result,possible ensure p winner Ec bribing k voters (B, S)yes instance X3C. direction, straightforward verify (B, S)yes instance X3C bribing k voters v11 , . . . , vn1 correspond coverB rank p first suffices ensure p unique winner. completes proofconstructive case.destructive case, claim possible ensure uniquewinner Ed (B, S) yes instance X3C. proof analogousconstructive case: suffices note p candidate possibly tievictory d. rest proof proceeds constructive case.6. Fixed-Parameter Tractabilitysection consider parameterized complexity multipronged control, particular, case assume number candidates small constant.Elections candidates natural. example, many countries presidentialelections involve handful candidates.main result section many natural election systems E (formally,election systems whose winner determination problem expressed via integer linear program certain form), holds E-AC+DC+AV+DV+BV controlproblem fixed-parameter tractable (is complexity class FPT) parameternumber candidates, constructive setting destructive setting.result combines significantly enhances FPT results literature, particular, papers Faliszewski, Hemaspaandra, Hemaspaandra (2009a)Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2009a), modelinspiration section. also make explicit automatic path resultsimplicit work two papers cited previous sentence. pathhelpful letting many future analyses done tool-application exercises,rather case-by-case challenges.present paper paper pick type pattern earlierwork mentioned, present definition results building that. Independentlypresent paper, Dorn Schlotter (2010) done different, bribery-relatedcontext.section focus exclusively number candidates parameter.is, parameter number candidates initially election plus numbercandidates (if any) set potential additional candidates. is, termsvariables using describe multiprong control parameter kCk + kAk.mention researchers sometimes analyze parameterizations. example,Liu et al. (2009), Liu Zhu (2010), Betzler Uhlmann (2009) considerparameter amount change one allowed use (e.g., number candidates one add), Bartholdi, Tovey, Trick (1989b), Betzler Uhlmann (2009),Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2009a) study parameternumber voters (and also sometimes number candidates). parameterssometimes used considering so-called possible winner problem (see, e.g., Betzler& Dorn, 2009; Betzler, Hemmann, & Niedermeier, 2009). However, view parameter336fiMultimode Control Attacks Electionsnumber candidates essential natural one. proceeddiscussion fixed-parameter tractability, number candidatesparameter.Let us consider election system E set C = {c1 , . . . , cm } candidates.exactly m! preference orders candidates C refer o1 , . . . , om! .Let us assume E anonymous (i.e., winners E election dependorder votes names voters, onlyfor preference order oinumber votes preference order). define predicate win E (cj , n1 , . . . , nm! )true ci unique winner E elections C = {c1 , . . . , cm },i, 1 m!, exactly ni voters preference order oi . restsection, inequalities always use one four operators >, , <,.16Definition 6.1. say anonymous election system E unique-winner (nonuniquewinner) integer-linear-program implementable set candidates C = {c1 , . . . , cm }candidate cj C exists set linear inequalities variables n1 , . . . , nm!that:1. integer assignment n1 = n1 , . . ., nm! = nm! satisfies S, ni belongsN,172. computed (i.e., obtained) time polynomial m!,183. (n1 , . . . , nm! ) Nm! , (a) holds (b) holds, (a)(b) follows:(a) satisfied assignment n1 = n1 , . . ., nm! = nm! .(b) cj unique winner (is winner) E election i, 1m!, exactly ni voters preference order oi , oi ithpreference order set C.16. allow strict nonstrict inequalities. Since allow integer solutions, straightforwardsimulate strict inequalities nonstrict ones simulate nonstrict inequalities strict ones,cases simply adding 1 appropriate side inequality. could equally wellallowed strict, nonstrict, inequalities.17. straightforward put m! inequalities enforcing condition. conditionhelp us make electoral part definition meaningful, i.e., avoid problemsrestriction final part definition lets us avoid discussing negative numbers voters.18. mention passing m! part definition changed computablemmfunction m, e.g., mm, would still obtain FPT results, still would hold evenstrengthened version FPT f f (parameter) InputsizeO(1) requiredcomputable. However, due m! number preference orders candidates,obtainable time polynomial m! practice particularly common case.also mention passing FPT-establishing framework section resultsyields, similarly case work mentioned earlier (Faliszewski, Hemaspaandra, & Hemaspaandra, 2009a; Faliszewski, Hemaspaandra, Hemaspaandra, & Rothe, 2009a), applymodel votes input list ballots, one per person, also hold so-calledsuccinct model (see Faliszewski, Hemaspaandra, & Hemaspaandra, 2009a; Faliszewski, Hemaspaandra, Hemaspaandra, & Rothe, 2009a), given votes individual ballotsbinary numbers providing number voters preference order (or occurringpreference order).337fiFaliszewski, Hemaspaandra, & Hemaspaandraslight abuse notation, integer-linear-program implementable election systems E simply refer set linear inequalities Definition 6.1win E (cj , n1 , . . . , nm! ). particular set candidates always clear context.Naturally, straightforward adapt Definition 6.1 apply approval voting,sake brevity so.aware natural systems integer-linear-program unique-winnerimplementable yet integer-linear-program nonunique-winner implementable, viceversa. paper focus unique winner model reader may wonderdefined nonunique winner variant integer-linear-program implementability.answer that, see later section, useful notion dealingdestructive control.class election systems integer-linear-program implementable remarkably broad. example, variously implicit consequence results Faliszewski,Hemaspaandra, Hemaspaandra (2009a) plurality, veto, Borda, Dodgson,polynomial-time computable (in number candidates) family scoring protocolsinteger-linear-program implementable.19 many election systemse.g., Kemenyvoting (Kemeny, 1959; Young & Levenglick, 1978) Copeland votingit clearwhether integer-linear-program implementable, similar approachesuseful us. return issue end section.Theorem 6.2. Let E integer-linear-program unique-winner implementable electionsystem. number candidates parameter, constructive E-AC+DC+AV+DV+BVFPT.Proof. Let (C, A, V, W, p, kAC , kDC , kAV , kDV , kBV ) input instance constructive E-AC+DC+AV+DV+BV control problem, described Definition 4.1. Let C ={p, c1 , . . . , cm0 } = {a1 , . . . , am00 }. parameter, total number candidates,K= m0 +m00 +1. subset K C let oK1 , . . . , okKk! mean kKk! preferenceorders K.idea algorithm perform exhaustive search subsetscandidates K, K C A, K check whether (a) possible obtain KC deleting kDC candidates adding kAC candidates A, (b)possible ensure p unique winner election (K, V ) deleting kDVvoters, adding kAV voters W , bribing kBV voters. Given K, step(a) straightforwardly implemented polynomial time. implement step (b),introduce linear integer program P (K), satisfiable step (b) holds.Let us fix K C describe integer linear program P (K).assume p K legal delete p (and would pointless, givenwant ensure victory). interpret preference orders voters VW limited candidate set K. use following constants program.19. Let number candidates. scoring protocol vector nonnegative integers satisfying1 2 . candidate receives points vote ranks ithposition, candidate(s) points win. Many election systems viewed familiesscoring protocols. example, plurality defined scoring protocols form (1, 0, . . . , 0), vetodefined scoring protocols form (1, . . . , 1, 0), Borda defined scoring protocolsform (m 1, 2, . . . , 0), number candidates.338fiMultimode Control Attacks Electionsi, 1 kKk!, let nVi number voters V preference order oK,K . P (K) containslet nWnumbervotersWpreferenceorderfollowing variables (described together intended interpretation):Variables av1 , . . . , avkKk! . i, 1 kKk!, interpret avi numbervoters preference oKadd W .Variables dv1 , . . . , dvkKk! . i, 1 kKk!, interpret dvi numbervoters preference oKdelete V .Variables bv1,1 , bv1,2 , . . . , bv1,kKk! , bv2,1 , . . . , bvkKk!,kKk! . i, j, 1 i, jkKk!, interpret bvi,j number voters preference oKthat, case6= j, bribe switch preference order oK,or,case=j,leave unbribed.jP (K) contains following constraints.1. variables nonnegative values.2. variable avi , 1 kKk!, enough voters W preferenceorder oKadded. is, i, 1 kKk!, constraintavi nW. Altogether, add kAV voters constraintPkKk!i=1 avi kAV .3. variable dvi , 1 kKk!, enough voters V preferenceorder oKdeleted. is, i, 1 kKk!, constraintdvi nVi . Altogether, delete kDV voters constraintPkKk!i=1 dvi kDV .4. variable bvi,j , 1 i, j kKk!, enough voters preference oKPkKk!bribed. is, i, 1 kKk!, constraint j=1 bvi,j =nVi + avi dvi (the equality comes fact i, 1 kKk!, bvi,inumber voters preference oKbribe). Altogether,bribe kBV voters also constraintkKk! kKk!kKk!X XXbvi,jbvi,i kBV .i=1 j=1i=15. Candidate p unique winner election executed adding,deleting, bribing voters. Using fact E integer-linear-program uniquewinner implementable, express win E (p, `1 , . . . , `kKk! ), subPkKk!stitute `j , 1 j kKk!, i=1 bvi,j (note that, previous constraints,variables describing bribery already take account adding deleting voters).legal integer-linear-program constraint win E (p, `1 , . . . , `kKk! ) simplyconjunction linear inequalities `1 , . . . , `kKk! .number variables number inequalities P (K) polynomiallybounded m!. Keeping mind Definitions 4.1 6.1, straightforward see program P (K) exactly expect to. testing whether P (K) satisfiable (i.e.,339fiFaliszewski, Hemaspaandra, & Hemaspaandrainteger solution, framework integer linear program) FPT,respect number candidates parametrization, using Lenstras(1983) algorithm. Thus complete FPT algorithm E-AC+DC+AV+DV+BVproblem works follows. subset K C includes p executefollowing two steps:1. Check whether possible obtain K C deleting kDC candidatesadding kAC candidates A.2. Form linear program P (K) check whether integral solutions usingalgorithm Lenstra (1983). Accept so.trying sets K accepted, reject.previous discussion, algorithm correct. Also, since (a) exactlym12sets K try, (b) executing first step done time polynomialm, (c) second step FPT (given parameter), constructiveE-AC+DC+AV+DV+BV FPT parameter m.Theorem 6.2 deals constructive control only. However, using proof, straightforward prove destructive variant result. say election systemstrongly voiced (Hemaspaandra et al., 2007) holds whenever least onecandidate, least one winner.20Corollary 6.3. Let E strongly voiced, integer-linear-program nonunique-winner implementable election system. Destructive E-AC+DC+AV+DV+BV FPT parameter number candidates.see corollary holds, enough note strongly voiced electionsystems candidate prevented unique winnercandidate made (possibly nonunique) winner (see, e.g., Footnote 5 Hemaspaandra et al., 2007, relevant discussion). Thus prove Corollary 6.3, simplyuse algorithm candidate despised one sees whethercandidate made (perhaps nonunique) winner, made (perhapsnonunique) winner, declares destructive control achievable. (And precise integer linearprogramming feasibility problem solution given Lenstras algorithm reveal action achieves control.) done FPT using algorithm proofTheorem 6.2, adapted work nonunique-winner problem (this trivial givenCorollary 6.3 assumes E integer-linear-program nonunique-winner implementable).Let us go back issue election systems may integer-linearprogram implementable. example, let us consider maximin. Let E = (C, V )election, C = {c1 , . . . , cm } V = (v1 , . . . , vn ). before, o1 , . . . , om!mean m! possible preference orders C, i, 1 m!, ni20. Please recall Footnote 5. papers model elections, one matchesprevious papers studying control, notion election allow election systeminputs winner. However, mention social choice world, formalizations electionstypically build definition exclusion possibility winners,world, strongly voiced would seem strange concept explicitly define require, builtgeneral definition start.340fiMultimode Control Attacks Electionsmean number voters V report preference order oi . ci cj C,ci 6= cj , let O(ci , cj ) set preference orders C ci preferred cj . Letk = (k1 , . . . , km ) vector nonnegative integers i, 1 m, holds1 ki m. vector k candidate c` C define (c` , k1 , . . . , km )following set linear integer inequalities:1. candidate ci , maximin score Pequal NE (ci ,Pcki ). is,i, j, 1 i, j m, 6= j, constraint ok O(ci ,ck ) nk ok O(ci ,cj ) nk2. c` highest maximin score election E thus Punique winnerE. is, i, 1 m, 6= `, constraintok O(c` ,ck` ) nk >Pok O(ci ,ck ) nk .straightforward see c` unique maximin winner Evector k = (k1 , . . . , km ) inequalities (c` , k1 , . . . , km ) satisfied. alsostraightforward modify construction handle nonunique winner case.Since O(mm ) vectors k try (c` , k1 , . . . , km ) contains O(m2 )inequalities, straightforward modify proof Theorem 6.2 work maximin:Assuming one interested ensuring candidate c` victory, one simply replaceprogram P (K) proof Theorem 6.2 family programs includedifferent (c` , k1 , . . . , km ) testing c` won. one would acceptsatisfiable. Thus following result.Corollary6.4. Constructive AC+DC+AV+DV+BV control destructiveAC+DC+AV+DV+BV control FPT maximin parameter numbercandidates.construction winner problem maximin viewed as, effect, disjunction set integer linear programs. constructions winnerproblem already obtained Kemeny elections21 Faliszewski, Hemaspaandra, Hemaspaandra (2009a) Copeland elections Faliszewski, Hemaspaandra,Hemaspaandra, Rothe (2009a). Thus following theorem.21. definition one notion Kemeny voting system voting preferenceorders (so ties within voters preferences allowed) allowed values Kemeny consensus(soon defined) also limited preference orders. notion originalpapers (Kemeny, 1959; Young & Levenglick, 1978), rather notion Kemeny elections usedFaliszewski, Hemaspaandra, Hemaspaandra (2009a), mention followingSaari Merlin (2000) notion Kemeny elections; interestingly, Hemaspaandra, Spakowski,Vogel (2005) ensure main result, complexity winner problemKemeny elections, holds cases, use real care make hold. So,said, Kemeny elections (as used paper) defined follows. Let E = (C, V )election, C = {c1 , . . . , cm } V = (v1 , . . . , vn ). preference order r voter vi ,1 n, let d(r, vi ) number inversions r preference order vi (i.e.,number pairs candidates {ci ,Pcj } ranked vi r opposite order). Kemeny scorepreference order r defined ni=1 d(r, vi ). preference order r said Kemeny consensusKemeny score lowest (tied lowest finethe lowest unique) amongpreference orders C. candidate ci Kemeny winner ci ranked first Kemenyconsensus.341fiFaliszewski, Hemaspaandra, & HemaspaandraCorollary 6.5. number candidates parameter, constructiveAC+DC+AV+DV+BV control destructive AC+DC+AV+DV+BV controlFPT Kemeny and, rational , 0 1, Copeland .conclude important caveat. FPT algorithms sectionbroad coverage, practice would difficult use runningtime depends (the fixed-value parameter) fast-growing way Lenstrasalgorithm large multiplicative constant polynomial running time. Thusresults section best interpreted indicating that, multipronged controlsetting, impossible prove non-FPT-ness (and impossible prove fixedparameter hardness terms levels so-called W hierarchy fixed-parametercomplexity, unless hierarchy collapses FPT). one interested truly practicallyimplementing multipronged control attack, one probably devise problem-specificalgorithm rather using generally applicable FPT construction.7. Conclusionspaper motivated desire move study control step directionbetter capturing real-life scenarios. particular, attackers tend artificiallylimit one type attack, rather may well pull employ everytrick playbook. studied control attacks (including even (unpriced)bribery, first time, within framework control) multiple attack prongspursued attacker.paper shown approachcombining various types control multiprong control attacksis useful. example, allows us express control vulnerabilityresults proofs compact way, obtain vulnerability results strongerwould obtained single prongs alone (and immediately imply prior results,single prongs). central contribution paper providesbroad set tools allow one, immunity/vulnerability/resistance basiccontrol prongs, almost always determine complexity combinations prongs.systems basic prong immune, vulnerable, resistant, blind spotmachinery cases multiple vulnerable prongs,showed underlying prongs simply determine complexitymultiprong combination. Even case, systems discussedpaper, indeed broad class systems (vulnerability-combining systems)expect include nearly natural systems, show classify evenface difficulty. provide useful tool help researchers prove additionalsystems vulnerability-combining. Section 4.4 summarizes that. Table 5 summarizes results regarding five election systems focused paper; seealso Tables 2 3.However, also seen exists natural election system, OriginalLlull,unless P = NP constructive vulnerability-combining. system vulnerableconstructive AC control constructive AV control yet resistant constructiveAC+AV control.342fiMultimode Control Attacks ElectionsControl typeACDCAVDVBVpluralityCon.RRVVVDes.RRVVVCondorcetCon.VRRRDes.VVVVCopeland ,0 1Con.Des.RVRVRRRRRRapprovalCon.VRRRDes.VVVVmaximinCon.RVRRRDes.VVRRRTable 5: Resistance basic control types five main election systems studiedpaper. table, means system immune given control type, Rmeans resistance, V means vulnerability. Constructive results AC, DC,AV, DV plurality Condorcet due Bartholdi et al. (1992)corresponding destructive results due Hemaspaandra et al. (2007).results AC, DC, AV, DV approval due Hemaspaandra et al.(2007). results regarding Copeland due Faliszewski, Hemaspaandra,Hemaspaandra, Rothe (2009a). Constructive bribery results pluralityapproval due Faliszewski, Hemaspaandra, Hemaspaandra (2009a),constructive bribery result Condorcet implicit work Faliszewski,Hemaspaandra, Hemaspaandra, Rothe (2009a). remaining entries(i.e., results regarding maximin, destructive bribery results plurality,approval, Condorcet) due paper (and bold-italic table).main contribution paper, however, analysis multiprong controltypes. particular, constructive (or destructive) collections prongssystems combine specified Classification Rule Section 4.2.holds due Theorem 4.7, paragraphs immediately following it, factprove five systems table constructive vulnerabilitycombining destructive vulnerability-combining (Theorems 4.11 5.1).also shown far fixed-parameter tractability goes, least respectparameter number candidates, broad class election systems vulnerablefull attack basic prongs, namely, AC+DC+AV+DV+BV control attack.Finally, appendix, prove candidate whose Dodgson scorekCk2 times Dodgson winners score maximin winner.paper studies multipronged control prongs may include various standardtypes control bribery. However, straightforward see frameworknaturally extended include manipulation, commend directioninterested reader (and mention passing Section 4 Faliszewski, Hemaspaandra, &Hemaspaandra, 2009a, find connection bribery manipulation).so, one would allow votersthe manipulatorsto blank preferenceorders and, voters included election, controlling agent woulddecide fill in. (That is, controlling agent model wouldcontrol control aspects manipulation aspects.) interestingmodel controlling agent might able add manipulative voters (ifmanipulators among voters added) even choose delete (it may343fiFaliszewski, Hemaspaandra, & Hemaspaandraseem deleting manipulators never useful Zuckerman, Procaccia, & Rosenschein,2009, give example deleting manipulator necessary make ones favoritecandidate winner Copeland election).mention natural involved open direction study multipronged controlsetting multiple controlling agents, different goal,controlling different prong. setting, interesting consider game-theoreticscenarios well situations which, example, one controlling agents seekingaction succeed regardless action attacker. Another importantdirection following. Section 6 specific (namely, fixed-parameter) casestudies sets quite flexible framework classifying broad range control-attackproblems polynomial time. would interesting see highly flexibleschemes matching results one find broadly classify control complexityelections general case (for motivation, see example work broadly classifyingmanipulation complexity scoring protocols, Hemaspaandra & Hemaspaandra, 2007;Conitzer, Sandholm, & Lang, 2007; Procaccia & Rosenschein, 2007).AcknowledgmentsSupported part NSF grants CCF-0426761, IIS-0713061, CCF-0915792, PolishMinistry Science Higher Education grant N-N206-378637, Foundation Polish Sciences Homing/Powroty program, AGH University Science Technology grant11.11.120.865, ESFs EUROCORES program LogICCC, Friedrich Wilhelm BesselResearch Awards Edith Hemaspaandra Lane A. Hemaspaandra. preliminary version (Faliszewski, Hemaspaandra, & Hemaspaandra, 2009b) paper appearedproceedings 21st International Joint Conference Artificial Intelligence, July 2009.helpful comments suggestions, deeply indebted JAIR handlingeditor Vincent Conitzer, Edith Elkind, anonymous IJCAI JAIR referees.Appendix A. Connection Maximin Voting Dodgson VotingSection 5 focused control maximin voting. appendix, focus differentfacet maximin voting, namely, show connection maximin famousvoting rule (i.e., election system) Dodgson.Dodgson voting, proposed 19th century Charles Lutwidge Dodgson (1876),22works follows. Let E = (C, V ) election, C = {c1 , . . . , cm } V =(v1 , . . . , vn ). candidate ci C, Dodgson score ci , denoted scoreDE (ci ),smallest number sequential swaps adjacent candidates preference lists votersV needed make ci become Condorcet winner. candidates lowestscore Dodgson elections winners. is, Dodgson defined system electcandidates closest Condorcet winners sense adjacent-swapsdistance. Although Dodgsons eighteenth-century election system directly definedterms distance, remains ongoing interest understanding classes voting rulescaptured various distance-based frameworks (see, e.g., Meskanen & Nurmi,2008; Elkind, Faliszewski, & Slinko, 2009, 2010c, 2010b).22. Dodgson better known Lewis Carroll, renowned author Alices Adventures Wonderland.344fiMultimode Control Attacks ElectionsUnfortunately, known deciding whether given candidate winner according Dodgsons rule quite complex. fact, Hemaspaandra, Hemaspaandra, Rothe(1997), strengthening NP-hardness result Bartholdi et al. (1989b), showedproblem complete parallelized access NP. is, complete p2 levelpolynomial hierarchy. Nonetheless, many researchers sought efficient wayscomputing Dodgson winners, example using frequently correct heuristics (Homan& Hemaspaandra, 2009; McCabe-Dansted, Pritchard, & Slinko, 2008), fixed-parametertractability (see Bartholdi et al., 1989b; Faliszewski, Hemaspaandra, & Hemaspaandra,2009a; Betzler, Guo, & Niedermeier, 2010, discussion Footnote 17 Faliszewski,Hemaspaandra, Hemaspaandra, & Rothe, 2009a), approximation algorithms Dodgson scores (Caragiannis, Covey, Feldman, Homan, Kaklamanis, Karanikolas, Procaccia, &Rosenschein, 2009).addition high computational cost determining winners, Dodgsons ruleoften criticized basic properties one would expect good voting rulehave. example, Dodgsons rule weak-Condorcet consistent (Brandt et al.,2010)equivalently, satisfy Fishburns strict Condorcet principleandsatisfy homogeneity monotonicity (see Brandt, 2009, surveys numberdefects Dodgsons rule). provide definitions latter two notions (in formercase case need here, namely, anonymous rules), relevantsection.Homogeneity. say anonymous voting rule R homogeneous positiveinteger k election E = (C, V ), C = {c1 , . . . , cm } V = (v1 , . . . , vn ),holds R winner set E E 0 = (C, V 0 ), V 0 =(v1 , . . . , v1 , v2 , . . . , v2 , . . . , vn , . . . , vn ).| {z } | {z }| {z }kkkMonotonicity. say voting rule R monotone election E = (C, V ),C = {c1 , . . . , cm } V = (v1 , . . . , vn ), holds candidate ci Cwinner E ci also winner election E 0 identical Eexcept voters rank ci higher (without changing relative orderremaining candidates).Continuing Caragiannis et al. (2009) line research approximately computing Dodgson scores, Caragiannis, Kaklamanis, Karanikolas, Procaccia (2010) devised approximation algorithm computing Dodgson scores that, given electionE = (C, V ), C = {c1 , . . . , cm } V = (v1 , . . . , vn ) candidate ci C, computes polynomial time nonnegative integer scE (ci ) scoreDE (ci ) scE (ci )scE (ci ) = O(m log m) scoreE (ci ). is, algorithm given Caragiannis et al. (2010)is, natural sense, O(m log m)-approximation Dodgson score.23 algorithm23. Throughout section, use notion f (m)-approximation g sense typically useddealing minimization problems. is, mean approximation outputs valueleast g f (m) g. slightly informal (i.e., sloppy) regarding interplaynotation Big-Oh notation; however, sloppiness quite standard typecause confusion. assume type input g type input approximationclear context; paper, cases, arguments election E candidate ci .345fiFaliszewski, Hemaspaandra, & Hemaspaandraadditional properties: one defines voting rule elect candidateslowest scores according algorithm, voting rule Condorcet consistent (i.e.,Condorcet winner exists, one winner votingrule), homogeneous, monotone.mentioned result Caragiannis et al. (2010) interesting. next theoremshow maximinwhich like Caragiannis et al. rule Condorcet-consistent,homogeneous, monotonealso elects candidates are, certain different yetprecise sense, close Dodgson winners. interesting maximin oftenconsidered quite different Dodgsons rule. proof inspiredCaragiannis et al. (2010).Theorem A.1. Let E = (C, V ) election let W C set candidateswin E according maximin rule. Let = kCk let = minci C scoreDE (ci ).2ci W holds scoreE (ci ) s.Proof. Let us fix election E = (C, V ) C = {c1 , . . . cm } V = (v1 , . . . , vn ).two candidates ci , cj C define df E (ci , cj ) smallest number kk voters V changed preference order rank ci ahead cj , ci wouldpreferred cj half voters. Note ci , cj Cdf E (ci , cj ) > 0jnkNE (ci , cj ) + df E (ci , cj ) =+ 1.2candidate ci C define sc0E (ci )sc0E (ci ) = m2 max{df E (ci , cj ) | cj C {ci }}.prove sc0 m2 -approximation Dodgson score.02Lemma A.2. ci C holds scoreDE (ci ) scE (ci ) scoreE (ci ).Proof. Let us fix ci C. see secondPinequality lemma statementholds, note max{df E (ci , cj ) | cj C {ci }}cj C{ci } df E (ci , cj ) scoreE (ci )candidate ck we, least, perform df E (ci , ck ) swaps ensureci defeats ck majority head-to-head contest. Thus, multiplying m2 ,m2 max{df E (ci , cj ) | cj C {ci }} m2 scoreDE (ci ).Let us consider first inequality. Let ck candidate C {ci }. makesure ci ranked higher ck half voters, shift cifirst position preference lists max{df E (ci , cj ) | cj C {ci }} df E (ci , ck )voters (or, remaining voters less max{df E (ci , cj ) | cj C {ci }} votersrank ci top choice). requires adjacent swaps per voter. Since1 candidates C {ci }, m2 max{df E (ci , cj ) | cj C {ci }} adjacent swapscertainly sufficient make ci Condorcet winner.(Lemma A.2)remains show candidate ci maximin winner E sc0E (ci )minimal. Fortunately, straightforward see. candidate ci Condorcetwinner E unique maximin winner unique346fiMultimode Control Attacks Electionscandidate ci sc0E (ci ) = 0. Let us assume Condorcet winner E. Letus fix candidate ci C let ck C {ci } candidate sc0E (ci ) =m2 df E (ci , ck ). is, df E (ci , ck ) = max{df E (ci , cj ) | cj C {ci }} df E (ci , ck ) > 0.Due last fact choice ck , df E (ci , ck ) = n2 + 1 NE (ci , ck )jnkNE (ci , ck ) =+ 1 df E (ci , ck ) = min NE (ci , cj ) = scoreE (ci ),2cj C{ci }scoreE (ci ) maximin score ci E. Thus candidate ci lowestvalue sc0E (ci ) also highest maximin score.Theorem A.1 says every maximin winners Dodgson score less Dodgson score Dodgson winner(s) (that fact course holds trivially),m2 times Dodgson score Dodgson winner(s). is, provencandidate whose Dodgson score m2 times Dodgson winner(s)maximin winner.ReferencesBartholdi, III, J., & Orlin, J. (1991). Single transferable vote resists strategic voting. SocialChoice Welfare, 8 (4), 341354.Bartholdi, III, J., Tovey, C., & Trick, M. (1989a). computational difficulty manipulating election. Social Choice Welfare, 6 (3), 227241.Bartholdi, III, J., Tovey, C., & Trick, M. (1989b). Voting schemesdifficult tell election. Social Choice Welfare, 6 (2), 157165.Bartholdi, III, J., Tovey, C., & Trick, M. (1992). hard control election?Mathematical Computer Modeling, 16 (8/9), 2740.Baumeister, D., Erdelyi, G., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2010).Computational aspects approval voting. Laslier, J., & Sanver, M. (Eds.), Handbook Approval Voting, pp. 199251. Springer.Betzler, N., & Dorn, B. (2009). Towards dichotomy finding possible winners elections based scoring rules. Proceedings 34th International SymposiumMathematical Foundations Computer Science, pp. 124136. Springer-Verlag LectureNotes Computer Science #5734.Betzler, N., Guo, J., & Niedermeier, R. (2010). Parameterized computational complexityDodgson Young elections. Information Computation, 208 (2), 165177.Betzler, N., Hemmann, S., & Niedermeier, R. (2009). multivariate complexity analysisdetermining possible winners given incomplete votes. Proceedings 21stInternational Joint Conference Artificial Intelligence, pp. 5358. AAAI Press.Betzler, N., & Uhlmann, J. (2009). Parameterized complexity candidate control elections related digraph problems. Theoretical Computer Science, 410 (52), 4353.Black, D. (1958). Theory Committees Elections. Cambridge University Press.Brandt, F. (2009). remarks Dodgsons voting rule. Mathematical Logic Quarterly,55 (4), 460463.347fiFaliszewski, Hemaspaandra, & HemaspaandraBrandt, F., Brill, M., Hemaspaandra, E., & Hemaspaandra, L. (2010). Bypassing combinatorial protections: Polynomial-time algorithms single-peaked electorates. Proceedings 24th AAAI Conference Artificial Intelligence, pp. 715722. AAAIPress.Caragiannis, I., Covey, J., Feldman, M., Homan, C., Kaklamanis, C., Karanikolas, N., Procaccia, A., & Rosenschein, J. (2009). approximability Dodgson Youngelections. Proceedings 20th Annual ACM-SIAM Symposium DiscreteAlgorithms, pp. 10581067. Society Industrial Applied Mathematics.Caragiannis, I., Kaklamanis, C., Karanikolas, N., & Procaccia, A. (2010). Socially desirableapproximations Dodgsons voting rule. Proceedings 11th ACM ConferenceElectronic Commerce, pp. 253262. ACM Press.Conitzer, V., & Sandholm, T. (2006). Nonexistence voting rules usually hardmanipulate. Proceedings 21st National Conference Artificial Intelligence,pp. 627634. AAAI Press.Conitzer, V., Sandholm, T., & Lang, J. (2007). elections candidateshard manipulate? Journal ACM, 54 (3), Article 14.Dobzinski, S., & Procaccia, A. (2008). Frequent manipulability elections: case twovoters. Proceedings 4th International Workshop Internet NetworkEconomics, pp. 653664. Springer-Verlag Lecture Notes Computer Science #5385.Dodgson, C. (1876). method taking votes two issues. Pamphlet printedClarendon Press, Oxford, headed yet published (see discussionsMcLean & Urken, 1995, Black, 1958, reprint paper).Dorn, B., & Schlotter, I. (2010). Multivariate complexity analysis swap bribery.Proceedings 5th International Symposium Parameterized Exact Computation, pp. 107122. Springer-Verlag Lecture Notes Computer Science #6478.Elkind, E., Faliszewski, P., & Slinko, A. (2009). distance rationalizability votingrules. Proceedings 12th Conference Theoretical Aspects RationalityKnowledge, pp. 108117. ACM Press.Elkind, E., Faliszewski, P., & Slinko, A. (2010a). Cloning elections. Proceedings24th AAAI Conference Artificial Intelligence, pp. 768773. AAAI Press.Elkind, E., Faliszewski, P., & Slinko, A. (2010b). Good rationalizations voting rules.Proceedings 24th AAAI Conference Artificial Intelligence, pp. 774779.AAAI Press.Elkind, E., Faliszewski, P., & Slinko, A. (2010c). role distances defining votingrules. Proceedings 9th International Conference Autonomous AgentsMultiagent Systems, pp. 375382. International Foundation Autonomous AgentsMultiagent Systems.Erdelyi, G., Nowak, M., & Rothe, J. (2009). Sincere-strategy preference-based approvalvoting fully resists constructive control broadly resists destructive control. Mathematical Logic Quarterly, 55 (4), 425443.348fiMultimode Control Attacks ElectionsErdelyi, G., Piras, L., & Rothe, J. (2010a). Bucklin voting broadly resistant control.Tech. rep. arXiv:1005.4115 [cs.GT], arXiv.org.Erdelyi, G., Piras, L., & Rothe, J. (2010b). Control complexity fallback voting. Tech.rep. arXiv:1004.3398 [cs.GT], arXiv.org.Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2009a). hard briberyelections? Journal Artificial Intelligence Research, 35, 485532.Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2009b). Multimode attackselections. Proceedings 21st International Joint Conference Artificial Intelligence, pp. 128133. AAAI Press.Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2010a). Multimode control attackselections. Tech. rep. arXiv:1007.1800 [cs.GT], Computing Research Repository,http://arXiv.org/corr/.Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2010b). Using complexityprotect elections. Communications ACM, 53 (11), 7482.Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2007). LlullCopeland voting broadly resist bribery control. Proceedings 22nd AAAIConference Artificial Intelligence, pp. 724730. AAAI Press.Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009a). LlullCopeland voting computationally resist bribery constructive control. JournalArtificial Intelligence Research, 35, 275341.Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009b). richer understanding complexity election systems. Ravi, S., & Shukla, S. (Eds.), Fundamental Problems Computing: Essays Honor Professor Daniel J. Rosenkrantz,pp. 375406. Springer.Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2011). shieldnever was: Societies single-peaked preferences open manipulationcontrol. Information Computation, 209 (2), 89107.Faliszewski, P., Hemaspaandra, E., & Schnoor, H. (2008). Copeland voting: Ties matter.Proceedings 7th International Conference Autonomous Agents Multiagent Systems, pp. 983990. International Foundation Autonomous AgentsMultiagent Systems.Faliszewski, P., Hemaspaandra, E., & Schnoor, H. (2010). Manipulation Copeland elections. Proceedings 9th International Conference Autonomous AgentsMultiagent Systems, pp. 367374. International Foundation Autonomous AgentsMultiagent Systems.Friedgut, E., Kalai, G., & Nisan, N. (2008). Elections manipulated often. Proceedings 49th IEEE Symposium Foundations Computer Science, pp. 243249.IEEE Computer Society.Garey, M., & Johnson, D. (1979). Computers Intractability: Guide TheoryNP-Completeness. W. H. Freeman Company.349fiFaliszewski, Hemaspaandra, & HemaspaandraHagele, G., & Pukelsheim, F. (2001). electoral writings Ramon Llull. Studia Lulliana,41 (97), 338.Hemaspaandra, E., & Hemaspaandra, L. (2007). Dichotomy voting systems. JournalComputer System Sciences, 73 (1), 7383.Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (1997). Exact analysis Dodgsonelections: Lewis Carrolls 1876 voting system complete parallel access NP.Journal ACM, 44 (6), 806825.Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2007). Anyone him: complexityprecluding alternative. Artificial Intelligence, 171 (56), 255285.Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009). Hybrid elections broadencomplexity-theoretic resistance control. Mathematical Logic Quarterly, 55 (4), 397424.Hemaspaandra, E., Spakowski, H., & Vogel, J. (2005). complexity Kemeny elections.Theoretical Computer Science, 349 (3), 382391.Homan, C., & Hemaspaandra, L. (2009). Guarantees success frequency algorithm finding Dodgson-election winners. Journal Heuristics, 15 (4), 403423.Isaksson, M., Kindler, G., & Mossel, E. (2010). geometry manipulationA quantitative proof GibbardSatterthwaite Theorem. Proceedings 51st IEEESymposium Foundations Computer Science, pp. 319328. IEEE Computer Society Press.Kemeny, J. (1959). Mathematics without numbers. Daedalus, 88, 577591.Lenstra, Jr., H. (1983). Integer programming fixed number variables. MathematicsOperations Research, 8 (4), 538548.Liu, H., Feng, H., Zhu, D., & Luan, J. (2009). Parameterized computational complexitycontrol problems voting systems. Theoretical Computer Science, 410 (2729),27462753.Liu, H., & Zhu, D. (2010). Parameterized complexity control problems maximinelection. Information Processing Letters, 110 (10), 383388.Maudet, N., Lang, J., Chevaleyre, Y., & Monnot, J. (2010). Possible winners newcandidates added: case scoring rules. Proceedings 24th AAAIConference Artificial Intelligence, pp. 762767. AAAI Press.McCabe-Dansted, J., Pritchard, G., & Slinko, A. (2008). Approximability Dodgsonsrule. Social Choice Welfare, 31 (2), 311330.McLean, I., & Lorrey, H. (2006). Voting medieval papacy religious orders. Report2006-W12, Nuffield College Working Papers Politics, Oxford, Great Britain.McLean, I., & Urken, A. (1995). Classics Social Choice. University Michigan Press.Meir, R., Procaccia, A., Rosenschein, J., & Zohar, A. (2008). complexity strategicbehavior multi-winner elections. Journal Artificial Intelligence Research, 33,149178.350fiMultimode Control Attacks ElectionsMenton, C. (2010).Normalized range voting broadly resists control.arXiv:1005.5698 [cs.GT], arXiv.org.Tech. rep.Meskanen, T., & Nurmi, H. (2008). Closeness counts social choice. Braham, M., &Steffen, F. (Eds.), Power, Freedom, Voting. Springer-Verlag.Niedermeier, R. (2006). Invitation Fixed-Parameter Algorithms. Oxford University Press.Papadimitriou, C. (1994). Computational Complexity. Addison-Wesley.Procaccia, A., & Rosenschein, J. (2007). Junta distributions average-case complexitymanipulating elections. Journal Artificial Intelligence Research, 28, 157181.Saari, D., & Merlin, V. (2000). geometric examination Kemenys rule. Social ChoiceWelfare, 17 (3), 403438.Schoning, U. (1986). Complete sets closeness complexity classes. MathematicalSystems Theory, 19 (1), 2942.Shoham, Y., & Leyton-Brown, K. (2009). Multiagent Systems: Algorithmic, GameTheoretic, Logical Foundations. Cambridge University Press.Walsh, T. (2009). really hard manipulation problems? phase transitionmanipulating veto rule. Proceedings 21st International Joint ConferenceArtificial Intelligence, pp. 324329. AAAI Press.Xia, L., & Conitzer, V. (2008a). Generalized scoring rules frequency coalitionalmanipulability. Proceedings 9th ACM Conference Electronic Commerce,pp. 109118. ACM Press.Xia, L., & Conitzer, V. (2008b). sufficient condition voting rules frequentlymanipulable. Proceedings 9th ACM Conference Electronic Commerce,pp. 99108. ACM Press.Xia, L., Zuckerman, M., Procaccia, A., Conitzer, V., & Rosenschein, J. (2009). Complexityunweighted manipulation common voting rules. Proceedings 21stInternational Joint Conference Artificial Intelligence, pp. 348353. AAAI Press.Young, H., & Levenglick, A. (1978). consistent extension Condorcets election principle.SIAM Journal Applied Mathematics, 35 (2), 285300.Zuckerman, M., Procaccia, A., & Rosenschein, J. (2009). Algorithms coalitionalmanipulation problem. Artificial Intelligence, 173 (2), 392412.351fiJournal Articial Intelligence Research 40 (2011) 57-93Submitted 08/10; published 01/11False-Name Manipulations Weighted Voting GamesHaris Azizaziz@in.tum.deInstitut fur InformatikTechnische Universitat Munchen, GermanyYoram Bachrachyorambac@gmail.comMicrosoft ResearchCambridge, UKEdith Elkindeelkind@ntu.edu.sgSchool Physical Mathematical SciencesNanyang Technological University, SingaporeMike Patersonmsp@dcs.warwick.ac.ukDepartment Computer ScienceUniversity Warwick, UKAbstractWeighted voting classic model cooperation among agents decision-makingdomains. games, player weight, coalition players winsgame total weight meets exceeds given quota. players power gamesusually directly proportional weight, measured power index,prominent among ShapleyShubik index Banzhaf index.paper, investigate much player change power, measuredShapleyShubik index Banzhaf index, means false-name manipulation,i.e., splitting weight among two identities. indices, provide upperlower bounds eect weight-splitting. show checking whetherbenecial split exists NP-hard, discuss ecient algorithms restricted casesproblem, well randomized algorithms general case. also provideexperimental evaluation algorithms.Finally, examine related forms manipulative behavior, annexation,player subsumes players, merging, several players unite one.characterize computational complexity manipulations provide limitseects. Banzhaf index, describe new paradox, termAnnexation Non-monotonicity Paradox.1. IntroductionCollaboration cooperative decision-making important issues many types interactions among self-interested agents (Ephrati & Rosenschein, 1997). many situations,agents must take joint decision leading certain outcome, may dierentimpact agents. standard well-studied way meansvoting, recent years, lot research applications votingmultiagent systems well computational aspects various voting procedures (seeFaliszewski & Procaccia, 2010). One key issues domain measurepower voter, i.e., impact nal outcome. particular, questionbecomes important agents decide distribute payos resultingc2011AI Access Foundation. rights reserved.fiAziz, Bachrach, Elkind, & Patersonjoint action: natural approach would pay agent accordingcontribution, i.e., voting power.issue traditionally studied within framework weighted voting games (WVGs)(Taylor & Zwicker, 1999), provide model decision-making many politicallegislative bodies (Leech, 2002; Laruelle & Widgren, 1998; Algaba, Bilbao, & Fernandez,2007), also investigated context multiagent systems (Elkind, Goldberg, Goldberg, & Wooldridge, 2008b, 2007). game, agentsweight, coalition agents wins game sum weights participantsmeets exceeds certain quota. numerous examples multiagent systemscaptured weighted voting games. example, agents weights may correspond amount resources (time, money, battery power) contribute,quota may indicate amount resources needed complete given task. Alternatively, weight may indicator agents experience seniority, votingprocedure may designed take account characteristics.Clearly, larger weight makes easier player aect outcome. However, players power always proportional weight. example, quotahigh winning coalition one includes players, intuitively,players equal power, irrespective weight. idea formalized usingconcept power index, systematic way measuring players inuenceweighted voting game. several ways dene power indices. One popular approaches relies fact weighted voting games form subclass coalitionalgames, therefore one use terminology solution conceptsdeveloped context general coalitional games. particular, important notioncoalitional games Shapley value (Shapley, 1953), classic methoddistributing gains grand coalition general coalitional games. Shapleyvalue natural interpretation context weighted voting, knownShapleyShubik power index (Shapley & Shubik, 1954). Another well-known powerindex, introduced specically context weighted voting games,Banzhaf index (Banzhaf, 1965). several power indices proposed(e.g., see Johnston, 1978; Deegan & Packel, 1978; Holler & Packel, 1983), ShapleyShubik power index Banzhaf power index usually viewed two standardapproaches measuring players power weighted voting games, widelystudied normative computational perspective.suggested above, power indices measure players power used determine payos. However, applicable real-world scenarios, approachpayo division resistant dishonest behavior, manipulation, participating players. paper study eects particular form manipulationweighted voting games, namely, false-name voting. manipulation, player splitsweight fake agent enters game. manipulationsvirtually impossible detect open anonymous environments internet.also occur legislative bodies, political parties vote bills. bodies,elections held every several years determine weight party votingbill. elections held, party may split two smaller parties.likely supporters party would somehow split two new parties,total weight new parties equal original party. choosing58fiFalse-Name Manipulations WVGssuitable platform, original party decide weight would splittwo new parties.weight-splitting manipulation change total weight identitiescheating agent, power (as measured ShapleyShubik power indexBanzhaf index) may change. Therefore, behavior presents challenge designersmultiagent systems rely weighted voting. main goal papermeasure eects false-name voting analyze computational feasibility. alsoexamine related scenarios players merging order increase joint power,one player annexing another one.main results follows:precisely quantify worst-case eect false-name voting agents payos.Namely, show n-player game splitting two false identitiesincrease agents payo factor 2 ShapleyShubik indexBanzhaf index. Moreover, bound asymptotically tight.hand, show false-name manipulation decrease agents payofactor (n) indices.demonstrate nding successful manipulation trivial task provingindices NP-hard verify benecial split exists. However,show weights polynomially bounded, problem solvedpolynomial time, discuss ecient randomized algorithms problem.present similar NP-hardness results case players merging singlenew player. Interestingly, case player annexing one players,contrast ShapleyShubik index Banzhaf index. WhereasShapleyShubik index, annexing always benecial, checking whether annexingbenecial case Banzhaf index NP-hard. However benecialplayer annexes player bigger weight. also present new paradox calledAnnexation Non-monotonicity Paradox, shows annexing smallplayer useful annexing big player.complement theoretical results experiments indicate expectedfractions positive negative false-name manipulations weighted voting gamesrandomly selected weights.1.1 Related WorkWeighted voting games date back least John von Neumann Oskar Morgenstern,developed theory monumental book Theory Games EconomicBehavior (von Neumann & Morgenstern, 1944). Subsequently, WVGs analyzedextensively game theory literature (see, instance, Taylor & Zwicker, 1999).seminal paper, Shapley (1953) considered coalitional games question fairallocation utility gained grand coalition. solution concept introducedpaper became known Shapley value game. subsequent paper (Shapley& Shubik, 1954) studies Shapley value context simple coalitional games,usually referred ShapleyShubik power index. Banzhaf power index59fiAziz, Bachrach, Elkind, & Patersonoriginally introduced Banzhaf (1965); somewhat dierent denition later proposedDubey Shapley (1979). paper, make use Banzhafs original denition,appropriate context payo division.power indices well studied. Stran (1977) shows indexreects certain conditions voting body. Laruelle (1999) describes certain axiomscharacterize two indices, well several others. indices used analyzevoting structures European Union Council Ministers IMF (Machover& Felsenthal, 2001; Leech, 2002).applicability power indices measuring political power various domainsraised question nding tractable ways compute them. However, problemappears computationally hard. Indeed, naive algorithm calculating Shapleyvalue (or ShapleyShubik power index) considers permutations playershence runs exponential time. Moreover, Papadimitriou Yannakakis (1994) showcomputing Shapley value weighted voting games #P-complete. resultextended Matsui Matsui (2001), show calculating Banzhaf indexweighted voting games also NP-hard. Furthermore, Faliszewski Hemaspaandra(2009) show comparing players power two dierent weighted voting gamesPP-complete indices.Despite hardness results, several papers show compute power indicesrestricted domains, discuss ways approximate them. include generatingfunctions approach (Mann & Shapley, 1962), trades required storage running time,Owens multilinear extension (MLE) approach (Owen, 1975) Monte Carlo simulationapproaches (Mann & Shapley, 1960; Fatima, Wooldridge, & Jennings, 2007; Bachrach,Markakis, Resnick, Procaccia, Rosenschein, & Saberi, 2010). Matsui Matsui (2000)provide good survey algorithms calculating power indices weighted voting games.Many approaches work well practice, justies use indicespayo distribution schemes multiagent domains.useful succinct model coalitional voting games, WVGs attractedlot interest multiagent community. number papers consideredproblem designing WVGs desirable properties (Aziz, Paterson, & Leech, 2007;Fatima, Wooldridge, & Jennings, 2008; de Keijzer, Klos, & Zhang, 2010). Simple gamesobtained combining multiple weighted voting games examinedElkind et al. (2008b) Faliszewski, Elkind, Wooldridge (2009). Another well-studiedtopic computing various stability-related solution concepts WVGs extensions(Elkind et al., 2007; Elkind & Pasechnik, 2009; Elkind, Chalkiadakis, & Jennings, 2008a).False-name manipulations open anonymous environments examineddierent domains auctions (Yokoo, 2007; Iwasaki, Kempe, Saito, Salek, & Yokoo,2007) coalitional games (Yokoo, Conitzer, Sandholm, Ohta, & Iwasaki, 2005; Ohta,Iwasaki, Yokoo, Maruono, Conitzer, & Sandholm, 2006; Ohta, Conitzer, Satoh, Iwasaki, &Yokoo, 2008). latter domain, characteristic function provideenough information analyze false-name manipulation. deal issue, Yokooet al. (2005) introduced framework player subset skills,characteristic function assigns values subset skills. model seenspecial case framework; however, due special properties weighted voting gamesable obtain much stronger results general case.60fiFalse-Name Manipulations WVGsphenomenon considered paper studied political scientistseconomists name paradox size (Shapley, 1973; Brams, 1975; Felsenthal& Machover, 1998); however, neither quantitative computational aspectsconsidered. Felsenthal Machover also discuss number paradoxesweighted voting games; Laruelle Valenciano (2005) give overview recentwork paradoxes weighted voting. Occurrences paradoxes voting bodiesconsidered Kilgour Levesque (1984),van Deemen Rusinowska (2003), LeechLeech (2005). Another form manipulation WVGs recently studiedZuckerman, Faliszewski, Bachrach, Elkind (2008), analyze center mightchange players power modifying quota even weights xed.1.2 Follow-up WorkMany results appear paper previously presented AAMAS conference (Bachrach & Elkind, 2008; Aziz & Paterson, 2009). Inspired work, LasisiAllan (2010) recently undertaken experimental analysis false-name manipulations weighted voting games. also considered less popular power indices,DeeganPackel index. another follow-up paper, Rey Rothe (2010) investigate false-name manipulations weighted voting games respect probabilisticBanzhaf index, i.e., one suggested Dubey Shapley (1979). Although probabilistic Banzhaf index useful measuring actual probability inuencingdecision, framework using power indices share resources power,probabilistic Banzhaf index normalized.2. Preliminaries Notationstart introducing notions used throughout paper.2.1 Coalitional Gamescoalitional game G = (N, v) given set players N = {1, . . . , n}, characteristic function v : 2N R, maps subset, coalition, players real value.value total utility players guarantee working together.coalitional game G = (N, v) called monotone v(S) v(T ) . Further,G called simple monotone v take values 0 1, i.e., v : 2N {0, 1}.games, say coalition N wins v(S) = 1, loses v(S) = 0.player critical, pivotal, coalition adding player turnslosing coalition winning coalition: v(S) = 0, v(S {i}) = 1. player vetoplayer necessary forming winning coalition, i.e., v(S) = 0 N \ {i}(for monotone games, equivalent requiring v(N \ {i}) = 0).2.2 Weighted Voting Gamesweighted voting game G simple game described vector players weightsw = (w1 , . . . , wn ) (R+ )n quota q R+ . write G = [q; w1 , . . . , wn ], G = [q; w].games, coalition winningtotal weight meets exceeds quota. Formally,N v(S) = 1 wi q v(S) = 0 otherwise. often61fiAziz, Bachrach, Elkind, & Patersonwrite w(S) denote total weight coalition S, i.e., w(S) = wi . Also, setwmax = maxi=1,...,n wi . make standard assumption w(N ) q, i.e.,grand coalition winning. Note q = w(N ), player N veto player.2.3 Power Indicesplayer, ShapleyShubik index Banzhaf index determinedplayers expected marginal contribution possible coalitions; however, twoindices make use dierent probabilistic models.ShapleyShubik index specialization Shapley valuea classic solution conceptcoalitional gamesto simple games. detail, let n set possiblepermutations (orderings) n players. n one-to-one mapping {1, . . . , n}{1, . . . , n}. Denote (i) set predecessors player , i.e., (i) = {j |(j) < (i)}. Shapley value i-th player game G = (N, v) denoted(G) given following expression:1[v(S (i) {i}) v(S (i))].(1)(G) =n!noccasionally abuse notation say player pivotal permutationpivotal coalition (i).ShapleyShubik power index simply Shapley value simple coalitionalgame (and therefore rest paper use terms interchangeably).games value coalition either 0 1, formula (1) simply countsfraction orderings players player critical coalition formedpredecessors. ShapleyShubik power index thus reects assumptionforming coalition, ordering players entering coalition equalprobability occurring, expresses probability player critical.contrast, Banzhaf index computes probability player criticalassumption coalitions players equally likely. Formally, given gameG = (N, v), N denote (G) number coalitionscritical game G. Banzhaf index player WVG G = (N, v)(G).jN j (G)(G) =exist several approaches determining players inuencegame, ShapleyShubik index Banzhaf index many useful propertiesmake convenient work with. make use three properties,namely, normalization property, symmetry property, dummy player property. normalization property simply states sum ShapleyShubik indices (orBanzhaf indices) players equal 1. symmetry property says two playersi, j make contribution coalition, i.e., v(S {i}) = v(S {j})N \ {i, j}, equal values index. dummy player property claimsdummy player indices equal 0, player called dummycontributes nothing coalition, i.e., N v(S {i}) = v(S).easy verify denitions ShapleyShubik index Banzhafindex properties.62fiFalse-Name Manipulations WVGs3. Weight-Splitting: Examplesreal-world situations modeled weighted voting games, players may able split,dividing resources (weight) arbitrarily among new identities. payo woulddistributed among agents according power resulting game. Intuitively, total payment obtained new identities equal payooriginal player split. However, demonstratecase payo distributed according either ShapleyShubik indexBanzhaf index.rst show players use weight-splitting increase power.Example 1. [Advantageous splitting] Consider WVG [6; 2, 2, 2]. symmetry,player Banzhaf index 1/3, ShapleyShubik index 1/3. lastplayer splits two players, new game [6; 2, 2, 1, 1]. game,original game, winning coalition grand coalition, hence playersequally powerful. Thus, split-up players Banzhaf index 1/4 each, wellShapleyShubik index 1/4 each, i.e., weight-splitting increases manipulators powerfactor (2 1/4)/(1/3) = 3/2 according indices.However, weight-splitting may also harmful.Example 2. [Disadvantageous splitting] Consider WVG [5; 2, 2, 2]. Again, symmetry, player Banzhaf index 1/3, ShapleyShubik index 1/3.last player splits two players, new game [5; 2, 2, 1, 1]. newplayers pivotal exactly one coalition, players weight 2 pivotalthree coalitions. Thus, new players Banzhaf index 1/8 each. Similarly,new players pivotal permutation appears thirdposition, followed new player, i.e., new players ShapleyShubik index2/24 = 1/12. Thus, weight splitting decreases players power factor 4/3according Banzhaf index factor 2 according ShapleyShubik index.Finally, weight-splitting may eect players power.Example 3. [Neutral splitting] Consider WVG [4; 2, 2, 2]. previous examples, symmetry, player Banzhaf index 1/3, ShapleyShubik index1/3. last player splits two players, new game [4; 2, 2, 1, 1].game, new players pivotal 2 coalitions, players weight2 pivotal 4 coalitions. Thus, split-up players Banzhaf index 1/6 each.Similarly, new players pivotal permutation appearsthird position, followed one players weight 2. exactly 4permutations, ShapleyShubik index new players 1/6.2 1/6 = 1/3, i.e., according indices, players total power change.examples presented far, weight-splitting eect ShapleyShubik index Banzhaf index manipulator. showalways case.Example 4. Consider WVG [5; 2, 1, 1, 1, 1]. game, rst player pivotalpermutation appears last second-to-last position, earlier positions.63fiAziz, Bachrach, Elkind, & PatersonThus, ShapleyShubik index 2/5. Further, player pivotal coalitioncontains three four players weight 1, i.e., 5 coalitions. hand,player weight 1 pivotal coalition contains player weight 2 welltwo players weight 1, i.e., 3 coalitions. Thus Banzhaf index rstplayer given 5/(5 + 4 3) = 5/17.Now, rst player splits two players weight one, resulting gameplayers weight. Therefore, value indices 1/6,hence total power manipulator 1/3.remains observe 2/5 > 1/3, 5/17 < 1/3, i.e., weight-splitting hurtsmanipulator payo distributed according ShapleyShubik index, helpsBanzhaf index used. Further, example generalized weightedvoting game form [n; 2, 1, . . . , 1], n 1 players weight 1 n 5:game, weight-splitting lowers payo rst player according2, increases payo according BanzhafShapleyShubik index n2 n+1n2index (n1)2 +1 n+1 .4. Splitting: Bounds Manipulationseen player increase decrease total payo splittingweight. subsection, provide upper lower bounds much changepayo so. restrict attention case splitting two identities;general case briey discussed Section 9.simplify notation, rest section assume original gameG = [q; w1 , . . . , wn ] manipulator player n, splits two new identities nn , resulting new game G . rst consider case ShapleyShubik index,followed analysis Banzhaf index.4.1 ShapleyShubik Indexstart providing tight upper bound benets manipulation.Theorem 5. game G = [q; w1 , . . . , wn ] split n n n ,2nn (G ) + n (G ) n+1n (G), i.e., manipulator cannot gain factor2n/(n + 1) < 2 splitting weight two identities. Moreover, bound tight,i.e., exists game player n increases payo factor 2n/(n + 1)splitting two identities.Proof. Fix split n n n . Let n1 set permutations rstn 1 players. Consider n1 . Let P () set permutationsplayers G obtained inserting n n . Let n+1 setpermutations players G n n pivotal . Finally, let P (, k)subset P () n+1 consists permutations P () leastone players n n appears k-th (k + 1)-st elementpivotal . Every permutation n+1 appears one sets P (, k)64fiFalse-Name Manipulations WVGs, k,n (G ) + n (G ) =|n+1 |1|P (, k)|.(n + 1)!(n + 1)!,khand, hard see |P (, k)| 2n , k: twoways place n n k-th (k +1)-st element , n1 permutationsP (, k) n appears k-th element , n adjacent it,n 1 permutations P (, k) n appears k-th element ,n adjacent it. Moreover, P (, k) empty, n pivotalpermutation f (, k) obtained inserting n k-th element . Further,(1 , k1 ) = (2 , k2 ) f (1 , k1 ) = f (2 , k2 ). Hence,n (G)1n!,k:P (,k)=11n+1|P (, k)|(n (G ) + n (G )).n! 2n2n,k2nn (G) 2n (G), i.e., manipulator cannotconclude n (G ) + n (G ) n+1gain factor 2n/(n + 1) < 2 splitting weight two identities.see bound tight, consider game G = [2n; 2, 2, . . . , 2] supposeone players (say, n) decides split two identities n n resulting gameG = [2n; 2, . . . , 2, 1, 1]. games winning coalition consists players,2nn (G).n (G) = 1/n, n (G ) = n (G ) = 1/(n + 1), i.e., n (G ) + n (G ) = n+1seen player increase payo factor 2splitting weight two identities. contrast, show playerdecrease payo factor (n) so. shows would-be manipulatorcareful deciding whether split weight, motivates algorithmicquestions studied next two sections.Theorem 6. game G = [q; w1 , . . . , wn ] split n n n ,n (G ) + n (G ) n+12 n (G), i.e., manipulator cannot lose factor(n + 1)/2 splitting weight two identities. Moreover, bound tight,Proof. prove rst part theorem, x split n n n considerpermutation players G n pivotal . easy seeleast one n n pivotal permutation f () obtained replacingn n n (in order). Similarly, least one n n pivotalpermutation g() obtained replacing n n n (in order). Moreover,permutations players G distinct, i.e., , g() = f ( ),= implies f () = f ( ), g() = g( ). Hence, n set permutationsplayers G n pivotal , n+1 set permutationsplayers G n n pivotal , |n+1 | 2|n |n (G ) + n (G ) =|n+1 |2|n |2=n (G).(n + 1)!(n + 1)!n+1see bound tight, consider game G = [2n 1; 2, 2, . . . , 2] supposeone players (say, n) decides split two identities n n resulting65fiAziz, Bachrach, Elkind, & Patersongame G = [2n 1; 2, . . . , 2, 1, 1]. original game G, winning coalitionconsists players, n (G) = 1/n. Now, consider permutationplayers G . claim n pivotal appears n-thposition , followed n . Indeed, (n ) = n, (n ) = n + 1, playersrst n 1 positions weight 2, w(S (n )) = 2n 2, w(S (n ) {n }) = 2n 1.Conversely, (n ) = n + 1, w(S (n )) = 2n 1 = q, (n ) n 1,w(S (n ) {n }) 2(n 1). Finally, (n ) = n, (n ) = n + 1,w(S (n ) {n }) = 2n 2 < q. Consequently, n pivotal (n 1)! permutations, and,argument, n also pivotal (a disjoint set of) (n 1)! permutations. Hence,2n (G ) + n (G ) = 2(n1)!(n+1)! = n+1 n (G).4.2 Banzhaf IndexBanzhaf index, obtain similar bounds maximum gains lossesweight-splitting manipulation.Theorem 7. game G = [q; w1 , . . . , wn ] split n n n ,n (G ) + n (G ) 2n (G). Moreover, bound asymptotically tight.Proof. Assume player n splits n n wn wn . Consider losingcoalition C n critical G. w(C) < q w(C) + wn = w(C) + wn + wn .following possibilities:q w(C) wn . case n n critical C G .wn < q w(C) wn . case n critical C {n } C G .q w(C) > wn . case n critical C {n } n critical C {n }G .Therefore n (G ) + n (G ) = 2n (G) case.consider player N \ {n}. Suppose critical coalition C G.n C, also critical coalition C = C \ {n} {n , n } G .hand, n C, also remains critical C G . Hence (G) (G ). Moreover,may also critical coalitions G contain one n n ,inequality general equality. Thus,n (G ) + n (G ) =2n (G) +2n (G)\{n} (G)2n (G)2n (G) + \{n} (G)n (G) +2n (G)\{n} (G)= 2n (G).see boundis tight,consider WVGn2G = [n 1; 1, . . . , 1, 2] n players.n (G) = n 1 + n1(G)=1+= n. Therefore,22n1n1+ 2nn1n2 = 2n (G) =1/n.n 4n + 8n 1 + 2 + (n 1)(1 + 2 )66fiFalse-Name Manipulations WVGsplayer n splits two players n n weights 1 each, resulting1. Thus large n, n (G ) + n (G ) =game G Banzhaf index player n+12n+1 2n (G).also bound damage incurred weight-splitting.Theorem 8. game G = [q; w1 , . . . , wn ] split n n n ,n (G ) + n (G ) n1 n (G).Proof. Suppose player n splits two players n n weights wn wn ,respectively. assume without loss generality wn wn . Now, considerarbitrary player = n, letTi = {S N \ {i} | w(S) < q, w(S) + wi q},Si = {S N \ {n, i} {n , n } | w(S) < q, w(S) + wi q}.(G) = |Ti |, (G ) = |Si |. Further, setSi1 = {S Si | pivotal \ {n , n }},Si2 = {S Si | pivotal \ {n , n } n S, n S},Si3 = {S Si | pivotal \ {n , n } n S, n S},Si4 = {S Si | pivotal \ {n , n } n , n S}.claim Si = 4j=1 Sij . Indeed, Si1 , pivotal S, \{n , n },hence must case {n , n } =; sets included Si1 Si2 Si3 .Si , let f (S) = \ {n , n }, g(S) = \ {n , n } {n}. Si1 ,f (S) Ti , set Ti 4 sets f (S) = , i.e.,|f 1 (T )| 4. Further, Si4 implies g(S) Ti , |g 1 (T )| 1 Ti . Finally,g(S ) = f (S ) , Si . Taken together, observations imply|Si1 | + |Si4 | 4|Ti | = 4i (G).Now, consider Si2 . w(S) < q, w(S) + wi < q, w(S) + wi + wn q.Hence, n critical {i}. Similarly, Si3 , follows n critical {i}.Therefore, |Si2 | + |Si3 | n (G ) + n (G ). obtain(G ) = |Si |4j=1|Sij | 4i (G) + n (G ) + n (G ) = 4i (G) + 2n (G),last equality follows proof Theorem 7. Thus, obtainn (G ) + n (G ) =2n (G) +2n (G)2n (G) + 42n\{n} (G)2n (G)\{n} (G) + 2(n 1)n (G)2 (G)(G)n=.(G)n67fiAziz, Bachrach, Elkind, & Patersonclear bound given Theorem 8 tight, next example showssplitting twoplayers decrease players payo according Banzhaf indexn.factor almost 2Example 9. Consider WVG G = [3k; 1, . . . , 1, 4k] n = 2k players. Let N1set players weight 1, i.e., N1 = {1, . . . , n 1}. easy see player ncritical coalition, players dummies, n (G) = 1.suppose player n splits new identities n n weights wn = wn = 2k.player n critical coalition G , case either n S,k |S N1 | n 1 n S, 0 |S N1 | k 1. Thus,(G ) = (G ) =nnnn1i=0= 2n1 .Moreover, player weight 1 critical coalition G , coalition mustinclude exactly oneof n n well k 1 n 2 players N1 \ {i}. Thus,(G ) = 2 2k2asymptoticsk1 < n. Using standard formulas2k224k1 . obtaincentral binomial coecient, approximate 2 k1 2 (2k1)2 2n1n (G ) + n (G )2n1+2n12=2+ (n 1) (n1)2n12 + n 1 22.n5. Complexity Finding Benecial Splitexamine problem nding benecial weight split weighted voting gamescomputational perspective. Ideally, manipulator would like nd payomaximizing split, i.e., way split weight among two identities resultsmaximal total payo. less ambitious goal decide whether existsmanipulation increases manipulators payo. However, turns evenproblem computationally hard. rest section, show checking whetherexists payo-increasing split NP-hard ShapleyShubik indexBanzhaf index; holds even player allowed use two identities. is,spirit groundbreaking papers Bartholdi Orlin (1991) Bartholdi,Tovey, Trick (1989, 1992), show computational complexity acts barriermanipulative behavior.formally dene computational problems, require weightsquota original game new game integers given binary, i.e.,allow integer splits. remark assumption entirely without lossgenerality: games player benet fractional splitinteger split. One example given game [3; 1, 1, 1],non-trivial integer splits available players, but, similarly Example 1,player increase power factor 3/2 splitting two players weight1/2. However, real-life settings usually natural bound granularityweights: weight number supporters given party, needs68fiFalse-Name Manipulations WVGsinteger, monetary contribution player, usually integernumber dollars (or, least, cents), i.e., assumption reects real-life constraints.ready dene problems.Name: Beneficial-SS-SplitInstance: (G, ) G = [q; w1 , . . . , wn ] weighted voting game {1, . . . , n}.Question: way player splitw sub-players 1 , . . . ,weight) > (G)?new game G holds(Gj=1 jdenition Beneficial-BI-Split similar.Name: Beneficial-BI-SplitInstance: (G, ) G = [q; w1 , . . . , wn ] weighted voting game {1, . . . , n}.Question: way player splitw sub-players 1 , . . . ,weightnew game G holds j=1 j (G ) > (G)?Note looking strictly benecial manipulation, i.e., one increasesmanipulators total payo, rather one simply harmful.prove Beneficial-SS-Split Beneficial-BI-Split NP-hard.hardness results based reductions following classic NP-hard problem:Name: PartitionInstance: set k integer weights = {a1 , . . . , ak }.Question: possiblepartitiontwo subsets P1 A, P2 P1 P2 = ,P1 P2 = A, ai P1 ai = ai P2 ai ?rst prove simple lemma used NP-hardness proofspaper.Lemma 10. Let = {a1 , . . . , ak } no-instance Partition.weighted. . , wn ] n > k, wi = 8ai = 1, . . . , k, q = 4 ai ai +voting game G = [q; w1 , .r, 0 < r < 4, ni=k+1 wi < 4, holds players k + 1, . . . , n dummies,hence ShapleyShubik Banzhaf indices equal 0.Proof. Consider player k < n set N \ {i}. showpivotal S.Set N0 = {1, . . . , k} let S0 = N0 . set N0 partitioned twoequal-weight subsets can, either w(S0 ) < w(N0 )/2, w(S0 ) > w(N0 )/2.Moreover, weights players N0 multiples 8, w(N0 )/2 multiple 4.Similarly, weight S0 multiple 8. Hence, w(S0 ) < w(N0 )/2, followsw(S0 ) w(N0 )/2 4 w(S {i}) < w(N0 )/2 4 + 4 < q. Therefore, v(S) = 0,v(S {i}) = 0, i.e., pivotal S. hand, w(S0 ) > w(N0 )/2,w(S0 ) w(N0 )/2 + 4 > q, S0 winning coalition. Therefore, pivotalcase well.Theorem 11. Beneficial-BI-Split NP-hard, remains NP-hard even playersplit two players equal weights.Proof. Given instance Partition = {a1 , . . . , ak }, construct aweighted votinggame G = [q; w1 , . . . , wn ] n = k + 1 players follows. let X = ai ai , setwi = 8ai = 1, . . . , n 1, wn = 2, q = 4X + 2. Also, set = n. Since wn = 2,69fiAziz, Bachrach, Elkind, & Patersoninteger split available player n two identities n n weight 1each. Let G = [q; w1 , . . . , wn1 , 1, 1] resulting game.no-instance Partition, Lemma 10 implies player n dummy,and, moreover, splits sub-players, sub-players also dummies. Therefore(G, ) no-instance Beneficial-BI-Split.let us assume yes-instance Partition. Let x denote numbercoalitions N \ {n} weight 4X. n (G) = x. = 1, . . . , n 1, letSi = {S N \ {n, i} | w(S) < 4X, w(S) + wi q},set yi = |Si |. Also, set = n1i=1 yi .Consider player < n. Observe exactly half x subsets {1, . . . , n 1}weight 4X contain i. subset , player pivotal (T \ {i}) {n}. Further,coalition Si , player pivotal {n}. Therefore < n(G) = x2 + 2yi . obtainn (G) =x.x + (n 1) x2 + 2yhand, new game G n (G ) = n (G ) = x. Moreover,< n (G ) = x2 + 4yi , since coalition Si corresponds 4 coalitionspivotal, namely, S, {n }, {n }, {n , n }. Thus,n (G ) + n (G ) =2x> n (G),2x + (n 1) x2 + 4ylast inequality holds since x > 0. Thus, yes-instance Partition corresponds yes-instance Beneficial-BI-Split.consider problem nding benecial split ShapleyShubik index.Theorem 12. Beneficial-SS-Split NP-hard, remains NP-hard even playersplit two players equal weights.Proof. Given instance = {a1 , . . . , ak } Partition, set X = ai ai , createweighted voting game G = [4X + 3; 8a1 , . . . , 8ak , 1, 2] n = k + 2 players. Also, setN0 = {1, . . . , n 2}.no-instance Partition, Lemma 10 implies player n dummy,splits several players, dummies, too. Thus,constructed no-instance Beneficial SS-Split.Now, suppose yes-instance Partition. Let P1 , P2 partitionA, w(P1 ) = w(P2 ). corresponds partition S, N0 \ N0 ,ai P1 ; observe w(S) = w(N0 \ S). Set = |S|, |N0 \ S| = n 2.easy see n critical {n 1} well (N0 \ S) {n 1}.(s + 1)!(n 2 s)! permutations 1, . . . , n put n directly permutation{n 1}. Similarly, s!(n 1 s)! permutations putting n directlypermutation (N0 \ S) {n 1}. Thus, partition P = P1i , P2i , |P1i | = s,70fiFalse-Name Manipulations WVGsleast (s + 1)!(n 2 s)! + s!(n 1 s)! distinct permutations n critical.hand, argued above, subset N0 w(S) = w(N0 )/2,n critical {n 1}, since either w(S) w(N0 )/2 4 < q 3w(S) w(N0 )/2 + 4 > q.Let P set partitions A, partition counted once, i.e.,P contains exactly one P1 , P2 P2 , P1 . P = P1i , P2i P, denote|P1i | = si . total n! permutations players G. Thus, ShapleyShubikindex n G(si + 1)!(n 2 si )! + si !(n 1 si )!=n (G) =n!P Psi !(n 2 si )!(si + 1 + n 1 si )=n!P Pnsi !(n 2 si )!si !(n 2 si )!=.n!(n 1)!P PP Pconsider happens n splits two players, n n wn =wn = 1, resulting game G = [4X + 3; 8a1 , . . . , 8ak , 1, 1, 1].Again, let P1 , P2 , |P1 | = si , |P2 | = n si , partition w(P1 ) = w(P2 ),let S, N0 \ corresponding partition N0 . (si + 2)!(n 2 si )!permutations place n directly permutation {n 1, n }, ncritical them. Similarly, n critical si !(n si )! permutations placen directly permutation (N0 \ S) {n 1, n }.Thus, partition P = P1i , P2i |P1i | = si , corresponds (si + 2)!(n 2si )! + si !(n si )! distinct permutations n critical. symmetry, (si +2)!(n 2 si )! + si !(n si )! distinct permutations n critical. n + 1players G , total (n + 1)! permutations players. Thus partition)!ShapleyShubik index n G,P = P1i , P2i , |P1i | = si , contributes si !(n2s(n1)!)!+si !(nsi )!2 (si +2)!(n2ssum ShapleyShubik indices n n G .(n+1)!show partition P2(si + 2)!(n 2 si )! + si !(n si )!si !(n 2 si )!>.(n + 1)!(n 1)!(2)Summing inequalities partitions P implies n (G ) + n (G ) > n (G),desired. prove inequality (2), note simplied2(s + 1)(s + 2) + (n 1 s)(n s)> 1,n(n + 1)use instead si simplify notation, or, equivalently,2(s + 1)(s + 2) + 2(n 1 s)(n s) n(n + 1) > 0.Now, observe2(s + 1)(s + 2) + 2(n 1 s)(n s) n(n + 1) = (n 2 2s)2 + n > 071fiAziz, Bachrach, Elkind, & Patersonn > 0. proves inequality (2) n > 0. follows yesinstance Partition, player n always gains splitting two players weight 1, i.e.,(G, n) yes-instance Beneficial-SS-Split.Remark 13. veried proofs go even allow noninteger splits, i.e., hardness results independent integrality assumption. Further, note shown Beneficial-BI-Split Beneficial-SS-SplitNP, i.e., proved problems NP-complete. tworeasons this. First, allow splits arbitrary number identities,candidate solutions may exponentially many new players (e.g., player weightwi split wi players weight 1). Second, even circumvent issueconsidering splits polynomial number identities, clear verifypolynomial time whether particular split benecial. fact, since computing powerindices weighted voting games #P-hard, quite possible problemsNP.6. Computing Benecial SplitsSection 5, shown hard even test benecial split exists, let alonend optimal split. seen positive result, since complexity ndingbenecial splits serves barrier kind manipulative behavior. However, turnsmany cases manipulators overcome problem. precisely,follows show certain restricted domains manipulators nd benecial splitstwo identities polynomial time. consider manipulation algorithms workapproximating ShapleyShubik index (rather calculating precisely).6.1 Examplessubsection, describe two scenarios one players always increasepayo splitting. examples rely rather severe constraintsplayers weights threshold, practical weighted voting scenarios satisfyconstraints.Example 14. hard see Example 1 generalized weightedvoting game w(N ) = q; games sometimes called unanimity games. Evengenerally, player always increase payo weight-splitting thresholdset high winning coalition must include players; holdsShapleyShubik index Banzhaf index. Indeed, consider class weighted votinggames G = [q; w] characterized following condition: w(N ) < q w(N ),= min{mini wi , wmax /2}. condition mini wi ensures playerspresent winning coalitions, index value player 1/n. Now, supposeplayer largest weight wi = wmax splits weight (almost) equallytwo identities, i.e., sets wi = wi /2, wi = wi /2. also wmax /2,winning coalition still include players. Therefore, new game payoplayer 1/(n + 1), hence split increases total payo manipulatorfactor 2n/(n + 1).72fiFalse-Name Manipulations WVGsExample 15. second example specic ShapleyShubik index. example,small player benet manipulation presence large players, longthreshold suciently high. Formally, consider class weighted voting gamesform G = [q; w], wi , = 1, . . . , n 1, multiples integer A,threshold q form + b, b < A, b < wn < min{2b 1, A}. Supposewinning coalitions size least n/2 + 1.condition holds renumberplayers w1 w2 wn1 require q > i=1,...,n/2 wi .Now, suppose player n pivotal least one coalition game (if weightssmall multiples A, condition checked easily). Consider permutationn pivotal . w(S (n)) = . Indeed, w(S (n)) > ,w(S (n)) + > q, coalition (n) need player n win.hand, w(S (n)) < , w(S (n)) A, w(S (n)) + wn < + b = q.|Let P set permutations; n (G) = |Pn! .suppose n decides split weight two new identities n nsetting wn = b 1, wn = wn b + 1; note wn , wn < b. Consider permutation. Suppose n occurs k-th position permutation. assumption,k n/2 + 1. construct 2k permutations j , j , j = 1, . . . , k, follows.permutations, players 1, . . . , n 1 appear order . Moreover,j , player n occurs j-th position, player n occurs (k + 1)-st position.Similarly, j , player n occurs j-th position, player n occurs (k + 1)-stposition.Observe n pivotal j , j = 1, . . . , k. Indeed, total weight playersprecede n j +wn < q, w(Sj (n ){n }) > q. Similarly, w(Sj (n )) < q,n pivotal j , j = 1, . . . , k. Hence, total number permutations1, . . . , n 1, n , n either n n pivotal least 2k|P | (n + 2)|P |,||P |total ShapleyShubik index players least (n+2)|P(n+1)! > n! = n (G). Hence,split strictly benecial player n.addition scenarios discussed above, Fatima et al. (2007) describe several classesvoting games ShapleyShubik indices players computed polynomial time; Aziz Paterson (2008) prove similar results Banzhaf index. Clearly,manipulators weight polynomially bounded, original game wellgames result manipulator splitting two identities easy, i.e., belongone classes considered Fatima et al. Aziz Paterson, problem ndingbenecial two-way split solved polynomial time. However, examples illustrate player may able decide whether benecial split even cannotcompute payo prior manipulation.6.2 Pseudopolynomial Approximation Algorithmshardness reductions Section 5 Partition. problem knownNP-hard, hardness relies crucially fact weights elementsrepresented binary. Indeed, weights given unary, dynamicprogramming-based algorithm problem runs time polynomial sizeinput (such algorithms usually referred pseudopolynomial ). particular,weights polynomial n, running time algorithm polynomial n.73fiAziz, Bachrach, Elkind, & Patersonmany natural voting domains weights players large, scenarioquite realistic. therefore natural ask exists pseudopolynomial algorithmproblem nding benecial split.turns answer question indeed positive longconstant upper bound K number identities manipulator useweights required integers. see this, recall pseudopolynomial algorithm computing ShapleyShubik index player weighted votinggame (Matsui & Matsui, 2000). algorithm based dynamic programming:weight W 1 k n, calculates number coalitions size kweight W . Thus, easily adapted work Banzhaf index well.One use algorithm Matsui Matsui (2000) nd benecial split(1)player weight wi game G follows. Consider possible splits wi = wi +(K)(j)+ wi , wi N j = 1, . . . , K. number splits (wi )K ,polynomial n constant K. Evaluate ShapleyShubik indices (respectively,Banzhaf indices) new players split return yes leastone splits results increased total payo. Let A(G) running timealgorithm Matsui Matsui instance G. running time algorithmO((wi )K K A(G)), clearly pseudopolynomial.consider general setting, weight manipulatorpolynomially bounded, weights players large. simplifypresentation, limit case two-way splits ShapleyShubik index;however, approach also applies splits constant number identitiesBanzhaf index. use high-level approach previous case, i.e.,considering possible splits (because weight restriction, polynomiallymany them), computing indices new players split. However,implement latter step exactly, would take exponential time. Therefore,version algorithm, replace algorithm Matsui Matsuiapproximation algorithm computing ShapleyShubik index. Several algorithmsknown; see, e.g., work Mann Shapley (1960), Fatima et al. (2007), Bachrachet al. (2010). use algorithms black-box fashion. Namely, assumegiven procedure Shapley(G, i, , ) given values > 0> 0 outputs number v probability 1 satises |v (G)| runstime poly(n log wmax , 1/, 1/). show use procedure designalgorithm nding benecial split relate performance algorithmShapley(G, i, , ).algorithm given Figure 1. takes parameters inputs, usesprocedure Shapley(G, i, , ) subroutine. algorithm outputs yes nds splitwhose total estimated payo exceeds payo manipulator original gameleast 3. easily modied output (approximately) optimal split.Proposition 16. probability 1 3, output algorithm satises following: (i) algorithm outputs yes, (G, i) admits benecial integer split; (ii)Conversely, integer split increases payo manipulator6, algorithm outputs yes. Moreover, running time algorithmpolynomial nwi , 1/, 1/.74fiFalse-Name Manipulations WVGsFindSplit(G = [q; w], i, , );v =Shapley(G, i, , );j = 0, . . . , wiwi = j, wi = wi j;G = [q; w1 , . . . , wi1 , wi , wi , wi+1 , . . . , wn ];v = Shapley(G , , , ), v =Shapley(G , , , );v = v + v ;v > v + 3 return yes;return no;Figure 1: Algorithm FindSplit(G = [q; w], i, , )Proof. Suppose algorithm outputs yes. Consider quantities v , v vcomputed algorithm. P rob[v < (G) ] < , P rob[v > (G ) + ] < ,P rob[v > (G ) + ] < . Hence, probability least 1 3, v + v > v + 3,(G) + (G ) + 2 > (G) + 3, or, equivalently, (G ) + (G ) > (G).Conversely, suppose benecial split form (wi , wi ) improvesplayer payo least 6. before, probability least 1 3v (G) + step j = wi holds v (G ) , v (G ) .v = v + v (G ) + (G ) 2 > (G) + 6 2 v + 3, algorithmoutput yes.algorithm guarantee nding successful manipulation, possiblecontrol approximation quality (at cost increasing running time),successful manipulation found high probability.Thus see manipulators several ways overcome computationaldiculty nding optimal manipulation. Hence, measures required avoidmanipulations.7. Merging AnnexationInstead player splitting smaller players, players may merge singleentity. However, situation dierent game-theoretic perspective,involves coordinated actions several would-be manipulators decidesplit (increased) total payo. case players merging gain advantage,examine two cases. One annexation one player takes voting weightplayers. annexation advantageous payo new merged coalitionnew game greater payo annexer original game. casevoluntary merging players merge become bloc new payo exceedssum individual payos.weighted voting game G, denote game results mergingplayers coalition G&S ; set players new game (N \S){&S},characteristic function denoted v&S . dene computational problems75fiAziz, Bachrach, Elkind, & Patersonchecking whether exist benecial voluntary merge annexation respectShapleyShubik index.Name: Beneficial-SS-MergeInstance: (G, S) G = [q; w1 , . . . , wn ] weighted voting game {1, . . . , n}.Question: coalition merges form new game G&S , &S (G&S ) > (G)?Name: Beneficial-SS-AnnexationInstance: (G, S, i) G = [q; w1 , . . . , wn ] weighted voting game, 1 n,{1, . . . , n} \ {i}.Question: annexes form new game G&(S{i}) , &(S{i}) (G&(S{i}) ) > (G)?easily adapt denitions Banzhaf index; refer resulting problems Beneficial-BI-Merge Beneficial-BI-Annexation. rstconsider issues related annexation, followed analysis merging.7.1 Mergingcase splitting, expect hard nd benecial merge. followingtheorem conrms intuition.Theorem 17. Beneficial-SS-Merge Beneficial-BI-Merge NP-hard.votingProof. Given instance Partition = {a1 , . . . , ak }, construct weightedgame G = [q; w1 , . . . , wn ] n = k + 3 players follows. set X = 4 ki=1 ai letwi = 8ai = 1, . . . , n 3, wn2 = wn1 = wn = 1, q = X + 2. argueyes-instance Partition (G, {n 1, n}) yes-instanceBeneficial-SS-Merge Beneficial-BI-Merge.no-instance Partition, Lemma 10 players n n 1dummies, even merge together, new player &{n 1, n} remains dummynew game G&{n1,n} . Thus, case (G, {n 1, n}) no-instanceproblems.let us assume yes-instance Partition. rst considercase ShapleyShubik index, followed analysis Banzhaf index.Set N0 = {1, . . . , n 3}. Let P1 , P2 partition A, let S, N0 \corresponding partition N0 . Set = |S|, |N0 \ S| = n 3. Player n critical{n 2} {n 1}, well (N0 \ S) {n 2} (N0 \ S) {n 1}. Thus,partition P = P1 , P2 , |P1 | = s, exactly 4(s + 1)!(n 2 s)! distinctpermutations n critical. Further, easy see n criticalpermutation. symmetry, true n 1. Thus, partition P1 , P2sum ShapleyShubik indices n 1|P1 | = contributes 8 (s+1)!(n2s)!n!n.Now, consider game G&{n1,n} . Consider partition S, N0 \ N0 |S0 | =corresponds partition P1 , P2 A. Player &{n 1, n} critical{n 2}, well N0 \ (N0 \ S) {n 2}. Thus, partition P1 , P2+ 2 (s+1)!(n3s)!ShapleyShubik index|P1 | = contributes 2 s!(n2s)!(n1)!(n1)!76fiFalse-Name Manipulations WVGs&{n 1, n}. remains show8(s + 1)!(n 2 s)!s!(n 2 s)!(s + 1)!(n 3 s)!<2+2.n!(n 1)!(n 1)!inequality simplied 4(s + 1)(n 2 s) < n(n 2 + + 1) = n(n 1),equivalent 0 < n(n 1) 4(s + 1)(n 2 s) = (n 2s 3)2 + n 1.inequality clearly holds n 1. Hence, n1 (G) + n (G) < &{n1,n} (G&{n1,n} ), i.e.,(G, {n 1, n}) yes-instance Beneficial-SS-Merge startedyes-instance Partition.show true Banzhaf index. Let x denote numbercoalitions N0 weight 4X. n2 (G) = n1 (G) = n (G) = 2x. = 1, . . . , k,letSi = {S N0 \ {i} | w(S) < 4X, w(S) + wi q},set yi = |Si |. Also, set = ki=1 yi .Consider player N0 . Observe exactly half x subsets N0 weight 4Xcontain i. set , player pivotal (T \ {i}) {n 2, n 1}, (T \ {i}) {n2, n}, (T \ {i}) {n 1, n}, (T \ {i}) {n 2, n 1, n}. Further, coalition Si ,player pivotal coalition form , {n2, n1, n}. Therefore2xN0 (G) = 4x2 + 8yi . Thus, n1 (G) = n (G) = 6x+2kx+8y .new game G&{n1,n} , &{n1,n} (G&{n1,n} ) = 2x, n2 (G&{n1,n} ) =0. Now, consider player N0 coalition N0 weight 4X contains i.Player pivotal (T \ {i}) {&{n 1, n}} (T \ {i}) {n 2, &{n 1, n}}.well coalition form , Si {n 2, &{n 1, n}}.Hence, (G&{n1,n} ) = 2x2 + 4yi .obtain2x4x&{n1,n} (G&{n1,n} ) =>= n1 (G) + n (G).2x + kx + 4y6x + 2kx + 8yThus, (G, {n 1, n}) yes-instance Beneficial-BI-Merge startedyes-instance Partition.7.2 AnnexationFelsenthal Machover (1998) prove annexation never disadvantageous respectShapleyShubik index. completeness, give simple proof fact.Proposition 18. weighted voting game G set players N , N ,N \ {i} (G) &(S{i}) (G&(S{i}) ).Proof. give proof case |S| = 1, i.e., = {j} j N \ {i}; generalcase follows easily induction. Let set permutations Ncritical G; (G) = |i |/n!. , let f () permutationplayers N&{i,j} obtained deleting j replacing new player&{i, j}. player &{i, j} pivotal f (). Moreover, permutationN&{i,j} |f 1 ()| = n. Hence,&{i,j} (G&{i,j} )|{f () | }|||/n== (G).(n 1)!(n 1)!77fiAziz, Bachrach, Elkind, & PatersonHowever Felsenthal Machover (1998) show that, case Banzhaf index,annexation could disadvantageous; refer phenomenon Bloc Paradox.provide 13-player WVG case, simplest examplecould nd. improve result describing 7-player WVG annexationdisadvantageous.Example 19. Consider weighted voting game [11; 6, 5, 1, 1, 1, 1, 1]. game, player 1pivotal coalition involves player 2 subset remaining players,well coalition {3, . . . , 7}, i.e., 33 coalitions. Player 2 pivotal coalitioninvolves player 1 4 remaining players, i.e., 31 coalitions. Finally,players weight 1 pivotal coalition includes player 1 rest330.47826.players weight 1. Thus, Banzhaf index player 1 equals 33+31+5player 1 annexes one players weight 1, new game [11; 7, 5, 1, 1, 1, 1].Applying reasoning above, obtain player 1 pivotal 17 coalitions,player 2 pivotal 15 coalition, remaining players pivotal exactly one17coalition, Banzhaf index player 1 new game 17+15+40.47222 < 0.47826.shown annexation disadvantageous case Banzhafindex. One would least expect Banzhaf index payo annexing anotherplayer monotone power annexed player. Surprisingly, case.is, show exists weighted voting game G = [q; w1 , . . . , wn ]i, j, k {1, . . . , n} wj > wk , &{i,j} (G&{i,j} ) < &{i,k} (G&{i,k} ).refer phenomenon Annexation Non-monotonicity Paradox. Observedistinct Bloc Paradox: former choosing two givenplayers annex, latter choosing annexing given playerannexing player all.Example 20. Consider weighted voting game [9; 3, 3, 2, 1, 1, 1]. Suppose rst player1 annexes player 2 form game [9; 6, 2, 1, 1, 1]. game, player 1 pivotal1 coalition include player 2, 7 coalitions include player 2, i.e., 8coalitions. Further, player 2 pivotal 6 coalitions, remaining players8pivotal 2 coalitions. Thus, Banzhaf index player 1 8+6+6= 0.4.Now, suppose player 1 annexes player 3 form game [9; 5, 3, 1, 1, 1].game, player 1 pivotal 7 coalitions, player 2 pivotal 7 coalitions,remaining players pivotal 1 coalition. Thus, Banzhaf index player 170.411765 > 0.4.game 7+7+3contrast, ShapleyShubik index monotone respect annexation.Proposition 21. weighted voting game G = [q; w1 , . . . , wn ] i, j, k{1, . . . , n} wj wk &{i,j} (G&{i,j} ) &{i,k} (G&{i,k} ).Proof. Consider permutation N&{i,k} &{i, k} pivotal. Letpermutation N&{i,j} obtained replacing &{i, k} &{i, j} j k. Sincew&{i,j} w&{i,k} , player j appears player &{i, k}, player &{i, j}pivotal . hand, player j appears player &{i, k},78fiFalse-Name Manipulations WVGsw(S (&{i, j})) w(S (&{i, k})) < q, w(S (&{i, j}) {&{i, j}}) = w(S (&{i, k}){&{i, k}}) q, &{i, j} pivotal case well. Hence, permutation&{i, k} pivotal corresponds distinct permutation &{i, j} pivotal,i.e., &{i,j} (G&{i,j} ) &{i,k} (G&{i,k} ).bound gains losses annexation, observe player increasepayo (with respect indices) much 1. happens dummyplayer annexes suciently large player coalition players. hand,Theorem 7 immediately implies that, player annexes player j game G,&{i,j} (G&{i,j} ) 12 (i (G) + j (G)). following useful corollary.Corollary 22. weighted voting game G set players N i, j N&{i,j} (G&{i,j} ) 12 (G), i.e., player decrease payofactor 2 annexing another player. Moreover, wi wj , &{i,j} (G&{i,j} ) (G),show determining whether player benet annexing givencoalition (with respect Banzhaf index) NP-hard.Theorem 23. Beneficial-BI-Annexation NP-hard.Proof. proof similar Theorem 11. Given instance Partition ={a1 , . . . , ak }, constructweighted voting game G = [q; w1 , . . . , wn ] n = k+2 playersfollows. let X = ai ai , set wi = 8ai = 1, . . . , n 2, wn1 = wn = 1q = 4X + 2.Lemma 10, no-instance Partition, players n 1 ndummies, n remains dummy even annexes n 1. Now, supposeyes-instance Partition. Let x denote number coalitions N \ {n 1, n}weight 4X. n1 = n (G) = x. = 1, . . . , n 2, letSi = {S N \ {n 1, n, i} | w(S) < 4X, w(S) + wi q},set yi = |Si |. Also, set = n2i=1 yi .calculations proof Theorem 11 showx2x+(n2) x2 +4y ,x= x+(n2)x+2y .2n (G) =&{n,n1} (G&{n,n1} )Since x > 0, implies n (G) < &{n,n1} (G&{n,n1} ). Hence, (G, {n 1}, n)yes-instance Beneficial-BI-Annexation started yesinstance Partition.conclude section analyzing benets merging annexation unanimity games, i.e., games q = w(N ).Proposition 24. unanimity game, advantageous player annexarbitrary coalition, respect ShapleyShubik index Banzhaf index.However, group players increase total payo (as measured eitherindices) merging.79fiAziz, Bachrach, Elkind, & PatersonProof. game players equal value index annexa1. However,tion. Hence, annexes coalition size s, power increases n1 ns1merging reduces total power players coalition size n ns.remark Proposition 24 generalizes game player vetoplayer.8. Empirical Analysisanalyze false-name splitting manipulations empirically. constructedsystem randomly constructing weighted voting games examined changesShapleyShubik index Banzhaf index occur agents split weightsfalse identities. briey describe simulation system, game constructionpower index calculations, present empirical evidence obtained.8.1 Simulation System Settingsweighted voting games constructed rst randomly choosing numberplayers game. Then, weights players drawn N (, 2 ),normal distribution mean variance 2 . weights roundednearest integer, make sure game integer weights. thresholdgame chosen uniformly random 0 sum players weightsw = w(N ), rounded nearest integer. experiments, usedmean = 200 weights, several values standard deviationset {5, 10, 15, . . . , 50}. number players n chosen uniformly randomset {5, 6, 7, . . . , 24}.Power indices computationally hard compute exactly (Papadimitriou & Yannakakis, 1994; Matsui & Matsui, 2001), tractably approximated using severalmethods. used approximation method Bachrach et al. (2010). algorithm estimates power indices returns result probably approximatelycorrect, discussed Section 6. Given game players true power index, given target accuracy level condence level , algorithm returnsapproximation probability least 1 | | (i.e.result approximately correct, within distance correct value). algorithm works drawing sample k permutations (or coalitions), testing whethertarget player critical them. test runs time linear numberagents, total running time O(kn log W ). Bachrach et al. show achievecondence level accuracy level , suces take k = ln(2/)/(22 ). Thustotal running time logarithmic condence quadratic accuracy,approach tractable even high accuracy condence. used = 0.00001= 0.001, power estimated accurately. system implementedC#, results experiments stored SQL database. Since powerindices approximated accurately, single experiment take several seconds.tests required tens thousands experiments, used compute cluster250 cores experiments.80fiFalse-Name Manipulations WVGstheoretical results show testing benecial split hard, might createimpression nding benecial manipulation hard practice. empiricalexperiments designed see whether indeed case. naive methodmanipulator use try many possible splits two identities, constantintervals. words manipulator whose weight w try 2s splits splitting2w3w3wweight ( ws , w ws ), ( 2w, w ), ( , w ) on. Although certainlycomplete coverage space possible manipulations, experimentstried simple algorithm based idea. Since weights integers,tried splitting weights two false identities, examined integersplits. example, agent weight wi = 10, attempted splitting weightsw1 = 9, w1 = 1, w1 = 8, w1 = 2, w1 = 7, w1 = 3 on. experimentrecorded details game, number benecial splits (power increase)harmful splits (power decrease). split considered benecial, increasepower twice accuracy level. Thus, results presented understatenumber positive splits. results examine proportion experimentsfound least one benecial manipulation, well proportionsplits benecial (out integer splits).8.2 Empirical Resultsrst present results regarding ShapleyShubik index. First foremost,results indicate weighted voting domain manipulable, least methodgenerating random weighted voting games. values tried varianceplayer weights number players game, 95.5% experimentseven naive manipulation algorithm managed uncover least one benecialmanipulation. indicates games enough try integer splits (orsplits uniform intervals) use tractable method approximating power indicesuncover benecial manipulations. Figures 2 3 indicate proportion experimentsalgorithm succeeds nding benecial split, function varianceplayers weights number players, respectively. appears success ratealgorithm slightly increases variance increases. obvious trend appearsnumber players.One might tempted think benecial splits quite common, experiments least one benecial split. However, turns splits harmfulsplits. tested settings, less 40% splits benecial splits.settings, harmful splits accounted 70% splits. Figure 4 Figure 5,indicate proportion benecial splits, function variance players weightsnumber players, respectively.also examined distribution proportion benecial splits acrossexperiments. generated games, benecial splits quite rare, lesssingle percent splits benecial. generated games, benecial splitscommon case, 99% splits benecial. Figure 6 shows distribution(histogram) proportion benecial splits, across games. create gure,games partitioned 200 bins, according proportion benecial splitsgame. bin size 0.5% (e.g., proportion benecial manipulations81fiAziz, Bachrach, Elkind, & PatersonFigure 2: Proportion experiments naive algorithm nds benecial splitdierent variances players weights (ShapleyShubik index)Figure 3: Proportion experiments naive algorithm nds benecial splitdierent numbers players (ShapleyShubik index)82fiFalse-Name Manipulations WVGsFigure 4: Proportion benecial splits dierent variances players weights (ShapleyShubik index)Figure 5: Proportion benecial splits dierent numbers players (ShapleyShubikindex)83fiAziz, Bachrach, Elkind, & PatersonFigure 6: Distribution (histogram) proportion positive splits across games(ShapleyShubik index)100-th bin 0.5 0.55). value X axis Figure 6 proportionbenecial splits (the bin), axis number experiments fallingcategory. Figure 6 shows games ones benecial splits rareharmful splits, distribution long tail, even games almostsplits benecial uncommon.turn examine Banzhaf index. case ShapleyShubik index,Banzhaf index weighted voting domain susceptible manipulation.tested settings, 92.5% experiments manipulation algorithmmanaged uncover least one benecial manipulation (slightly less 95.5%ShapleyShubik index). proportion experiments algorithm ndsbenecial split respect Banzhaf index shown Figure 7 (for dierent valuesvariance) Figure 8 (for dierent number players).Similarly case ShapleyShubik index, Banzhaf index benecial splitsless common case, splits harmful splits, less 45%splits benecial, typically 40% benecial splits (slightly higherShapleyShubik index). Unlike ShapleyShubik index, Banzhaf index,proportion benecial splits among splits increases variance (Figure 9).However, proportion clear trend regard number players(Figure 10).distribution proportion benecial splits across games Banzhaf indexseems quite similar ShapleyShubik index (see Figure 11). Again,games, majority splits harmful, distribution long tail, many84fiFalse-Name Manipulations WVGsFigure 7: Proportion experiments naive algorithm nds benecial splitdierent variances players weights (Banzhaf index)Figure 8: Proportion experiments naive algorithm nds benecial splitdierent numbers players (Banzhaf index)85fiAziz, Bachrach, Elkind, & PatersonFigure 9: Proportion benecial splits dierent variances players weights (Banzhafindex)Figure 10: Proportion benecial splits dierent numbers players (Banzhaf index)86fiFalse-Name Manipulations WVGsFigure 11: Distribution (histogram) proportion positive splits across games(Banzhaf index)games mostly benecial splits. Although distribution seems similarShapleyShubik index, tail distribution seems slightly fatter Banzhafindex.conclude, experiments indices present similar picture. gamesgenerated model, mostly harmful splits. However, many experimentsmany positive splits, even almost splits benecial. Gamestrying integer splits yield successful manipulation rare,although exist. Thus, games generated model, even extremelysimple manipulation algorithm nds benecial splits. conclude despite hardnessresults paper, practice believe quite easy nd splits, thusbelieve attacks pose real problem many settings.9. Splitting Two Identitiesfar, mostly discussed gain (or loss) player achieve splittingtwo identities. However, also possible player use three false names.Potentially, number identities player use large weight (andweights required integers, even innite). would interesting seeresults hold general setting. example, computationalhardness result holds splits number identities, algorithmic resultsprevious section apply splits constant number new identities. obviousopen problem design pseudopolynomial algorithm nding benecial integer87fiAziz, Bachrach, Elkind, & Patersonsplit number identities, prove problem NP-hard even smallweights (i.e., weights polynomial n). Another question interestextend upper lower bounds Section 4 setting.One might think nding benecial split k 2 identities easier ndingone uses exactly two identities: all, two-way split transformedsplit three players two players non-zero weight. However,turns restrict attention non-trivial splits, i.e., onenew players non-zero weight, longer case.Example 25. Consider game G = [6; 5, 5]. game, winning coalitionincludes players, ShapleyShubik indices given 1 (G) = 2 (G) = 1/2.Suppose player 2 splits two identities 2 2 . selection integerweights w2 > 0, w2 > 0 satisfy w2 + w2 = 5, new game G = [6; 5, w2 , w2 ]2 (G ) = 2 (G ) = 1/3. Indeed, game player pivotal permutationoccurs second position, happens probability 1/3. Hence,non-trivial split two identities increases payo second player factor(2/3)/(1/2) = 4/3.Now, suppose second player splits 5 new players weight 1 each.new game, player 1 pivotal permutation occurrst position permutation, ShapleyShubik index 5/6. Consequently,sum ShapleyShubik indices remaining players (i.e., new identities player 2)1/6. Therefore, split decreases payo player 2 factor 3. summarize,non-trivial integer split 2 identities benecial player 2, integer split5 identities positive weight harmful him.Remark 26. Example 25 generalized games form GN = [N + 1; N, N ]arbitrary integer N > 0. reasoning shows one players decidessplit N new players weight 1 each, increases ShapleyShubik indexplayer N/(N + 1) hence decreases total payo splitting playerfactor (N + 1)/2. representation size game polynomial log N ,decrease exponential description size.10. Conclusionsconsidered false-name manipulations weighted voting games respectpayo schemes based ShapleyShubik index Banzhaf index. alsoconsidered manipulation via annexation voluntary merging respect payoschemes. examined limits manipulation (Table 1) complexitymanipulation (Table 2), complemented theoretical investigation empiricalanalysis.shown that, scenarios considered paper, testing whetherbenecial manipulation exists NP-hard. One may ask whether hardness resultsprovide adequate barrier manipulation, given power indiceshard compute. words, dont simultaneously assume weights small(and hence computing indices easy) large (and hence manipulation hard)?resolve apparent contradiction, note power indices considered paper88fiFalse-Name Manipulations WVGs2n+1 (G)Bounds(G ) + (G )2nn+1 (G)(G) (G&({i}S) ) 1.1n+1 (G)(G ) + (G ) 2i (G)(G)2(G&({i,j}) ) 1.ReferenceTheorems 5 6Proposition 18Theorems 7 8Corollary 22Table 1: Bounds eects false-name manipulations WVGsSplittingMergingAnnexationSplitting unanimity gameMerging unanimity gameAnnexation unanimity game(FelsenthalBanzhaf indexNP-hardNP-hardNP-hardadvantageousdisadvantageousadvantageousShapleyShubik indexNP-hardNP-hardadvantageousadvantageousdisadvantageousadvantageous& Machover, 1998)Table 2: Complexity false-name manipulations WVGscorrespond voting power, players may try increase voting powerweight-splitting manipulation even cannot compute it. Also, power indexused compute payments, center, performs computation, maycomputational power individual players.experimental results show that, moderately large weights, weight-splitting manipulation easy practice. However, algorithm relies considering integer splits,i.e., running time least linear manipulators weight. interesting open question whether case benecial split exists, found testingnumber splits logarithmic manipulators weight.results indicate ShapleyShubik index Banzhaf index behave similarly respect false-name manipulation; however, ShapleyShubik index appearsdesirable solution concept annexation decrease payoplayer. Exploring solution concepts behavior respect false-namemanipulation natural next step; particularly suitable solution consider couldnucleolus, always exists also unique.study weighted voting many applications, political sciencemultiagent systems. several possible interpretations identity-splittingcontexts, obtaining higher share grand coalitions gainsdistributed according ShapleyShubik index Banzhaf index, obtainingpolitical power splitting political party several parties similar political platforms. rst case, false-name manipulation hard detect open anonymous89fiAziz, Bachrach, Elkind, & Patersonenvironments, thus eective. second case, manipulation doneusing legitimate tools political conduct. Therefore, conjecture false-name manipulation widespread real world may become serious issue multiagentsystems. therefore important develop better understanding eectsbehavior and/or design methods preventing it.AcknowledgmentsHaris Aziz Mike Paterson partially supported DIMAP (the Centre DiscreteMathematics Applications). DIMAP funded UK EPSRC grantEP/D063191/1. Partial support Azizs research also provided DeutscheForschungsgemeinschaft grants BR-2312/6-1 (within European Science Foundations EUROCORES program LogICCC) BR 2312/3-2. Edith Elkind partiallysupported ESRC grant ES/F035845/1 Singapore NRF Research Fellowship 2009-08.ReferencesAlgaba, E., Bilbao, J. M., & Fernandez, J. R. (2007). distribution powerEuropean Constitution. European Journal Operational Research, 176 (3), 17521755.Aziz, H., & Paterson, M. (2008). Computing voting power easy weighted voting games.CoRR, abs/0811.2497.Aziz, H., & Paterson, M. (2009). False name manipulations weighted voting games:splitting, merging annexation. Proceedings 8th International Joint Conference Autonomous Agents Multi-Agent Systems (AAMAS), pp. 409416.Aziz, H., Paterson, M., & Leech, D. (2007). Ecient algorithm designing weightedvoting games. Proceedings 11th IEEE International Multitopic Conference,pp. 16. IEEE Computer Society.Bachrach, Y., & Elkind, E. (2008). Divide conquer: False-name manipulationsweighted voting games. Proceedings 7th International Joint ConferenceAutonomous Agents Multi-Agent Systems (AAMAS), pp. 975982.Bachrach, Y., Markakis, E., Resnick, E., Procaccia, A. D., Rosenschein, J. S., & Saberi, A.(2010). Approximating power indices: theoretical empirical analysis. AutonomousAgents Multi-Agent Systems, 20 (2), 105122.Banzhaf, J. F. (1965). Weighted voting doesnt work. Rutgers Law Review, 19, 317343.Bartholdi, J., & Orlin, J. (1991). Single transferable vote resists strategic voting. SocialChoice Welfare, 8 (4), 341354.Bartholdi, J., Tovey, C., & Trick, M. (1989). computational diculty manipulatingelection. Social Choice Welfare, 6 (3), 227241.Bartholdi, J., Tovey, C., & Trick, M. (1992). hard control election?. Mathematical Computer Modeling, 16 (8/9), 2740.90fiFalse-Name Manipulations WVGsBrams, S. (1975). Game Theory Politics. Free Press, New York.de Keijzer, B., Klos, T., & Zhang, Y. (2010). Enumeration exact design weightedvoting games. Proceedings 9th International Joint Conference AutonomousAgents Multi-Agent Systems (AAMAS), pp. 391398.Deegan, J., & Packel, E. W. (1978). new index power simple n-person games.International Journal Game Theory, 7, 113123.Dubey, P., & Shapley, L. S. (1979). Mathematical properties Banzhaf power index.Mathematics Operations Research, 4 (2), 99131.Elkind, E., Chalkiadakis, G., & Jennings, N. R. (2008a). Coalition structures weightedvoting games. Proceedings 18th European Conference Articial Intelligence(ECAI), pp. 393397.Elkind, E., Goldberg, L. A., Goldberg, P., & Wooldridge, M. (2008b). dimensionalityvoting games. Proceedings 23rd AAAI Conference Articial Intelligence(AAAI), pp. 6974. AAAI Press.Elkind, E., Goldberg, L. A., Goldberg, P. W., & Wooldridge, M. J. (2007). Computationalcomplexity weighted threshold games. Proceedings 22nd AAAI ConferenceArticial Intelligence (AAAI), pp. 718723. AAAI Press.Elkind, E., & Pasechnik, D. (2009). Computing nucleolus weighted voting games.Proceedings 20th Annual ACM-SIAM Symposium Discrete Algorithms(SODA), pp. 327335.Ephrati, E., & Rosenschein, J. (1997). heuristic technique multi-agent planning.Annals Mathematics Articial Intelligence, 20 (14), 1367.Faliszewski, P., Elkind, E., & Wooldridge, M. (2009). Boolean combinations weightedvoting games. Proceedings 8th International Joint Conference AutonomousAgents Multi-Agent Systems (AAMAS), pp. 185192.Faliszewski, P., & Hemaspaandra, L. A. (2009). complexity power-index comparison.Theoretical Computer Science, 410 (1), 222245.Faliszewski, P., & Procaccia, A. (2010). AIs war manipulation: winning?. AIMagazine, 31 (4).Fatima, S. S., Wooldridge, M., & Jennings, N. R. (2007). randomized methodShapley value voting game. Proceedings 6th International JointConference Autonomous Agents Multi-Agent Systems (AAMAS), pp. 18.Fatima, S. S., Wooldridge, M., & Jennings, N. R. (2008). anytime approximation methodinverse Shapley value problem. Proceedings 7th International JointConference Autonomous Agents Multi-Agent Systems (AAMAS), pp. 935942.Felsenthal, D., & Machover, M. (1998). Measurement Voting Power. Edward ElgarPublishing, Cheltenham, UK.Holler, M. J., & Packel, E. W. (1983). Power, luck right index. Journal Economics,43, 2129.91fiAziz, Bachrach, Elkind, & PatersonIwasaki, A., Kempe, D., Saito, Y., Salek, M., & Yokoo, M. (2007). False-name-proof mechanisms hiring team. Proceedings 3rd International Workshop InternetNetwork Economics (WINE), pp. 245256.Johnston, R. J. (1978). measurement power: reactions Laver. Environment Planning A, 10, 907914.Kilgour, D. M., & Levesque, T. J. (1984). Canadian constitutional amending formula:Bargaining past future. Public Choice, 44 (3), 457480.Laruelle, A. (1999). choice power index. Working papers, serie AD 1999-10,Instituto Valenciano de Investigaciones Economicas.Laruelle, A., & Valenciano, F. (2005). critical reappraisal voting power paradoxes.Public Choice, 125, 1741.Laruelle, A., & Widgren, M. (1998). allocation voting power among EU statesfair?. Public Choice, 94 (3-4), 317339.Lasisi, R., & Allan, V. (2010). False name manipulations weighted voting games: Susceptibility power indices. Thirteenth International Workshop TrustAgent Societies (TRUST), pp. 139150.Leech, D. (2002). Voting power governance International Monetary Fund.Annals Operations Research, 109 (1), 375397.Leech, D., & Leech, R. (2005). Power vs weight IMF governance: possible benecial implications united European bloc vote. Buira, A. (Ed.), ReformingGovernance IMF World Bank, pp. 251282. Anthem Press.Machover, M., & Felsenthal, D. S. (2001). Treaty Nice qualied majority voting.Social Choice Welfare, 18 (3), 431464.Mann, I., & Shapley, L. S. (1960). Values large games, IV: Evaluating electoral collegeMontecarlo techniques. Rand Corporation, RM-2651.Mann, I., & Shapley, L. S. (1962). Values large games, VI: Evaluating electoral collegeexactly. Rand Corporation, RM-3158.Matsui, T., & Matsui, Y. (2000). survey algorithms calculating power indicesweighted majority games. Journal Operations Research Society Japan, 43 (1),7186.Matsui, Y., & Matsui, T. (2001). NP-completeness calculating power indices weightedmajority games. Theoretical Computer Science, 263 (1-2), 305310.Ohta, N., Conitzer, V., Satoh, Y., Iwasaki, A., & Yokoo, M. (2008). Anonymity-proofShapley value: extending Shapley value coalitional games open environments.Proceedings 7th International Joint Conference Autonomous AgentsMulti-Agent Systems (AAMAS), pp. 927934.Ohta, N., Iwasaki, A., Yokoo, M., Maruono, K., Conitzer, V., & Sandholm, T. (2006).compact representation scheme coalitional games open anonymous environments. Proceedings 21st AAAI Conference Articial Intelligence (AAAI),pp. 697702.92fiFalse-Name Manipulations WVGsOwen, G. (1975). Multilinear extensions Banzhaf value. Naval Research LogisticsQuarterly, 22 (4), 741750.Papadimitriou, C. H., & Yannakakis, M. (1994). complexity bounded rationality.Proceedings 26th Annual ACM Symposium Theory Computing(STOC), pp. 726733. ACM.Rey, A., & Rothe, J. (2010). Complexity merging splitting probabilisticbanzhaf power index weighted voting games. 19th European ConferenceArticial Intelligence (ECAI 2010), pp. 10211022.Shapley, L. S. (1953). value n-person games. Kuhn, H. W., & Tucker, A. W. (Eds.),Contributions Theory Games, II, pp. 307317. Princeton University Press.Shapley, L. S. (1973). Political science: Voting bargaining games. Selby, H. A. (Ed.),Notes Lectures Mathematics Behavioral Science, pp. 3792. MathematicalAssociation America.Shapley, L. S., & Shubik, M. (1954). method evaluating distribution powercommittee system. American Political Science Review, 48 (3), 787792.Stran, P. D. (1977). Homogeneity, independence power indices. Public Choice, 30,107118.Taylor, A., & Zwicker, W. (1999). Simple Games: Desirability Relations, Trading, Pseudoweightings. Princeton University Press, New Jersey.van Deemen, A., & Rusinowska, A. (2003). Paradoxes voting power dutch politics.Public Choice, 115 (13), 109137.von Neumann, J., & Morgenstern, O. (1944). Theory Games Economic Behavior.Princeton University Press.Yokoo, M. (2007). False-name bids combinatorial auctions. SIGecom Exchanges, 7 (1),4851.Yokoo, M., Conitzer, V., Sandholm, T., Ohta, N., & Iwasaki, A. (2005). Coalitional gamesopen anonymous environments. Proceedings 20th AAAI ConferenceArticial Intelligence (AAAI), pp. 509515.Zuckerman, M., Faliszewski, P., Bachrach, Y., & Elkind, E. (2008). Manipulating quotaweighted voting games. Proceedings 23rd AAAI Conference ArticialIntelligence (AAAI), pp. 215220.93fiJournal Artificial Intelligence Research 40 (2011) 175-219Submitted 09/10; published 01/11Second-Order ConsistenciesChristophe LecoutreStphane Cardonlecoutre@cril.frcardon@cril.frCRIL-CNRS UMR 8188Universit Lille-Nord de France, Artoisrue de luniversitSP 16, F-62307 Lens, FranceJulien Vionjulien.vion@univ-valenciennes.frLAMIH-CNRS FRE 3304Universit Lille-Nord de France, UVHCF-59313 Valenciennes Cedex 9, FranceAbstractpaper, propose comprehensive study second-order consistencies (i.e.,consistencies identifying inconsistent pairs values) constraint satisfaction. buildfull picture relationships existing four basic second-order consistencies,namely path consistency (PC), 3-consistency (3C), dual consistency (DC) 2-singletonarc consistency (2SAC), well conservative strong variants. Interestingly, dualconsistency original property established using outcome enforcement generalized arc consistency (GAC), makes rather easy obtain sinceconstraint solvers typically maintain GAC search. binary constraint networks,DC equivalent PC, restriction existing constraints, called conservative dualconsistency (CDC), strictly stronger traditional conservative consistencies derivedpath consistency, namely partial path consistency (PPC) conservative path consistency (CPC). introducing general algorithm enforce strong (C)DC, presentresults experimentation wide range benchmarks demonstrateinterest (conservative) dual consistency. particular, show enforcing (C)DCsearch clearly improves performance MAC (the algorithm maintains GACsearch) several binary non-binary structured problems.1. IntroductionMany decision problems combinatorial nature, modelled using finitedomain variables connected constraints. models formally represented constraint networks (CNs) finding solution model instance NP-completeconstraint satisfaction problem (CSP). CSP usually solved systematic backtrack search, fundamental technique artificial intelligence. considerableefforts last three decades improve practical efficiency backtrack search.Consistencies properties constraint networks exploited (enforced), search, filter search space problem instances inference. Currently,successful consistencies domain filtering consistencies (Debruyne & Bessiere,2001; Bessiere, Stergiou, & Walsh, 2008). Common consistencies binary CNs arcconsistency (AC, Mackworth, 1977) singleton arc consistency (SAC, Bessiere & Dec2011AI Access Foundation. rights reserved.fiLecoutre, Cardon, & Vionbruyne, 2005). Example consistencies non-binary CNs generalized arc consistency(GAC, Mohr & Masini, 1988) pairwise inverse consistency (PWIC, Stergiou & Walsh,2006). Consistencies typically allow identification nogoods. nogood instantiation variables cannot lead solution. Identifying relevant nogoodssoon possible exploring search space instance recognized essentialcomponent backtracking search algorithm. domain-filtering consistency also calledfirst-order consistency, meaning detects inconsistent values (1-sized nogoods):values safely removed domains variables.paper concerned second-order consistencies locally identify inconsistentpairs values. studied second-order consistency path consistency (PC, Montanari, 1974; Mackworth, 1977). now, path consistency, generally higher orderconsistencies, rather neglected designers developers general constraint solvers.somewhat surprising since, many tractable classes, strong path consistency (pathconsistency combined arc consistency) sufficient condition determine satisfiability (e.g., see Dechter, 1992; van Beek, 1992; Cooper, Cohen, & Jeavons, 1994; Zhang& Yap, 2006). Neglecting higher order consistencies may partly due somewhatlimited scope classes: exciting progress area recent (e.g.,see Green & Cohen, 2008). However, path consistency important role temporal reasoning. Indeed, classes interval algebra, path consistency adaptedtemporal constraint networks (Allen, 1983) sufficient decide satisfiability. Anotherpossible reason low practical interest path consistency, discrete constraintsatisfaction field, path consistency enforcement modifies constraint relations,importantly, modifies structure constraint graph. pair values(a, b) variables (x, y) found path-inconsistent, information recordedwithin constraint network; constraint binding x y, new one inserted, thus changing constraint graph. example, instance scen-11 radiolink frequency assignment problem (Cabon, de Givry, Lobjois, Schiex, & Warners, 1999)involves 680 variables 4,103 constraints.Enforcing second-order consistencynetwork could worst create 6804,103=226,757 new constraints, would2really counter-productive time space. main apparent drawback pathconsistency avoided adopting conservative approach, search inconsistent pairs values restricted existing constraints. called conservative pathconsistency (CPC, Debruyne, 1999) restricted paths length 2 constraintgraph, partial path consistency (PPC, Bliek & Sam-Haroud, 1999) restrictedpaths arbitrary length constraint graph; CPC PPC equivalentconstraint graph triangulated.paper, study path consistency well three basic second-order consistencies 3-consistency (3C, Freuder, 1978), dual consistency (DC, Lecoutre, Cardon,& Vion, 2007a) 2-singleton arc consistency (2SAC, Bessiere, Coletta, & Petit, 2005).binary constraint networks, DC equivalent PC McGregor (1979) proposed DC-likealgorithm establish (strong) path consistency considering weaker conservativevariants, show conservative dual consistency (CDC) strictly stronger PPCCPC: CDC filter inconsistent pairs values (from existing constraints)PPC CPC. build full picture qualitative relationships existingsecond-order consistencies (including stronger 2SAC property, conserva176fiSecond-Order Consistenciestive restrictions strong variants studied consistencies) binary CNsnon-binary CNs.Interestingly enough, (conservative) dual consistency benefits nice features:(1) (C)DC built top GAC, implementing filtering algorithm enforcerather easy, (2) reason, optimizations achieved GAC algorithmslast years come free, (3) guarantee GAC enforced CN verifiesproperty (C)DC leaves property unchanged. theoretical studyfollowed presentation general algorithm enforce strong (C)DCexperimental study show practical interest using (C)DC (during preprocessingstep) solving binary non-binary problem instances search algorithmMAC (Sabin & Freuder, 1994).paper organized follows. Section 2 introduces technical backgroundconstraint networks, nogoods consistencies. Section 3, introduce (basic, conservative strong) second-order consistencies, focus path consistencypossible misunderstanding it. qualitative study second-order consistenciesconducted Section 4. algorithm enforce (C)DC proposed Section 5,experimental results presented Section 6. Finally, conclude.2. Technical Backgroundsection provides technical background constraint networks consistencies.2.1 Constraint Networks(finite) constraint network (CN) P composed finite set n variables, denotedvars(P ), finite set e constraints, denoted cons(P ). variable xassociated domain, denoted dom(x), contains finite set valuesassigned x. constraint c involves ordered set variables, called scope cdenoted scp(c). defined relation, denoted rel(c), contains settuples allowed variables involved c. arity constraint c sizescp(c). maximum domain size maximum arity given CN denotedr, respectively. binary constraint involves exactly 2 variables, non-binaryconstraint strictly 2 variables. binary CN contains binary constraintswhereas non-binary CN contains least one non-binary constraint.initial domain variable x denoted dominit (x) whereas current domainx CN P denoted domP (x) simply dom(x) contextunambiguous. initial relation constraint c denoted relinit (c) whereascurrent relation denoted relP (c) simply rel(c). constraint c universal iffrelinit (c) = xscp(c) dominit (x); universal constraint imposes restriction. considervariable x, always dom(x) dominit (x), constraint c,always rel(c) relinit (c). simplify, pair (x, a) x vars(P ) dom(x)called (current) value P . Without loss generality, consider CNsinvolve neither unary constraints (i.e., constraints involving unique variable)177fiLecoutre, Cardon, & Vionconstraints similar scope CNs normalized (Apt, 2003; Bessiere, 2006). setnormalized CNs neither unary constraints universal constraints1 denoted P.instantiation set X = {x1 , . . . , xk } variables set {(x1 , a1 ), . . . , (xk , ak )}1..k, ai dominit (xi ) ; set X variables occurring denotedvars(I) value ai denoted I[xi ]. instantiation CN Pinstantiation set X vars(P ); complete iff vars(I) = vars(P ), partial otherwise.valid P iff (x, a) I, domP (x). instantiation covers constraint c iffscp(c) vars(I), satisfies constraint c scp(c) = {x1 , . . . , xr } iff (1) covers c(2) tuple (a1 , . . . , ar ) allowed c, i.e., (a1 , . . . , ar ) rel(c), 1..r, ai = I[xi ].support (resp., conflict) constraint c valid instantiation scp(c) satisfies(resp., satisfy) c. instantiation CN P locally consistent iff (1) validP (2) every constraint P covered satisfied I. locally inconsistentotherwise. solution P complete instantiation P locally consistent.instantiation CN P globally inconsistent, nogood, iff cannot extendedsolution P . globally consistent otherwise. refer standard nogoods (e.g.,see Dechter, 2003); differ nogoods coming justifications (Schiex & Verfaillie,1994) generalized ones (Katsirelos & Bacchus, 2003). Two CNs P P 0 definedvariables equivalent iff solutions.CN said satisfiable iff admits least one solution. Constraint Satisfaction Problem (CSP) NP-complete task determining whether given CNsatisfiable not. Thus, CSP instance defined CN solved either findingsolution proving unsatisfiability. many cases, CSP instance solvedusing combination search inferential simplification (Dechter, 2003; Lecoutre, 2009).solve CSP instance, depth-first search algorithm backtracking applied,step search, variable assignment performed followed filtering process called constraint propagation. Constraint propagation algorithms enforceconsistency property, identify record explicit nogoods CNs. identifiednogoods size 1, correspond inconsistent values.usual refer properties (hyper)graphs associatedCN. one hand, constraint (hyper)graph, also called macro-structure,associated (normalized) CN P consists n vertices corresponding variablesP also e (hyper)edges corresponding constraints P : (hyper)edge connectsvertices corresponding variables scope constraint represents.hand, compatibility (hyper)graph, also called micro-structure (Jgou, 1993),associated normalized CN P contains one vertex per value P one (hyper)edgeper constraint support. corresponds n-partite hypergraph one partvariable. Sometimes, incompatibility (hyper)graphs used authors (hyper)edgescorrespond conflicts instead supports. paper, (hyper)edges supports (resp.,conflicts) drawn using solid (resp., dashed) lines.sometimes helpful use homogeneous representation CN, wherein domainsalso constraints replaced nogoods. nogood representation CN setnogoods, one every value removed initial domain variable one1. theoretical study, universal constraints safely ignored. practice, universal constraintc CN P may artificially considered non-universal: choose variable x scp(c) considerdummy value dominit (x) \ domP (x) relinit (c) forbids one tuple involving (x, ).178fiSecond-Order Consistencieseevery tuple forbidden constraint.precisely, nogood representationxvariable x set instantiations {(x, a)} | dominit (x) \ dom(x) . nogoodrepresentationce constraint c, withscp(c) = {x1 , . . . , xr}, theoset instantiationsnQinit (x) \ rel(c) . nogood repre{(x1 , a1 ) , . . . , (xr , ar )} | (a1 , . . . , ar )xscp(c) domsentation Pe CN P set instantiationsexvars(P ) xe .ccons(P ) cInstantiations Pe explicit nogoods P (recorded domains constraints).Notice nogood superset another one, subsumed. Intuitively, nogoodsubsumed relevant less general least another one, twoCNs nogood-equivalent related definition Definition 3.11 work Bessiere(2006) canonical form, i.e., represent exactly setunsubsumed nogoods. relate CNs, introduce general partial order.2 Let PP 0 two CNs defined variables (i.e., vars(P ) = vars(P 0 )), P 0 Pf0 Pe P 0 P iff Pf0 ) Pe . (P, ) partially ordered set (poset)iff Preflexive, antisymmetric (remember CN P involve universal constraints)transitive. CNs normalized unary universal constraint present,therefore one manner discard (or remove) instantiation givenCN, equivalently record new explicit nogood CN. Given CN P P,instantiation P , P \ denotes CN P 0 P vars(P 0 ) = vars(P ),f0 = Pe {I}. P \ operation retracts P builds new CN,Pnecessarily set constraints. Let us show P 0 built. Pe ,course P 0 = P \ = P : means instantiation alreadyexplicit nogood P . interesting case/ Pe . corresponds valuevariable x, i.e., = {(x, a)}, suffices remove dom(x). correspondstuple allowed constraint c P , suffices remove tuple rel(c). Otherwise,must introduce new constraint whose associated relation contains possible tuples(built initial domains) except one corresponds instantiation I. Noteremoving tuple relation rel(c) problem practice constraintc defined intension (i.e., predicate). However, binary nogoods (our concern),real problem because, except variables large domains,always possible translate (efficiently) intensional constraint extension.2.2 Consistenciesconsistency general property CN. consistency holds CN P ,say P -consistent. two consistencies, CN P said +consistent iff P -consistent -consistent. consistency nogood-identifyingiff reason CN P -consistent instantiations,Pe , identified globally inconsistent . instantiations correspond (newidentified) nogoods said -inconsistent (on P ). kth-order consistencynogood-identifying consistency allows identification nogoods size k,k 1 integer. kth-order consistency confused k-consistency(Freuder, 1978, 1982): k-consistency holds iff every locally consistent instantiation2. partial order general enough purpose, note sophisticated partial orders (orpreorders) exist (e.g., taking account subsumed nogoods).179fiLecoutre, Cardon, & Vionset k 1 variables extended locally consistent instantiation involvingadditional variable. terminology, (k 1)th-order consistency.domain-filtering consistency first-order consistency. conservative consistencynogood-identifying consistency that, every given CN P , every -inconsistentinstantiation P corresponds tuple currently allowed explicit constraint P .compare pruning capability consistencies, introduce preorder (see Debruyne& Bessiere, 2001). consistency stronger (or equal to) iff whenever holdsCN P , also holds P . strictly stronger iff strongerexists least one CN P holds P . consistenciescannot ordered (none stronger another), say incomparable.briefly introduce formal characterization constraint propagation, basedconcept stability (following Lecoutre, 2009). formalism also relatedprevious works local consistencies rules iteration (e.g., see Montanari & Rossi,1991; Apt, 1999, 2003; Bessiere, 2006). usually possible enforce CN Pcomputing greatest -consistent CN smaller equal P , preserving setsolutions. consistency well-behaved CN P P, set {P 0 P | P 0-consistent P 0 P } admits greatest element, denoted (P ), equivalentP called -closure P . Enforcing CN P means computing (P ),algorithm enforces called -algorithm. property stability usefulproving nogood-identifying consistency well-behaved.nogood-identifying consistency stable iff every CN P P, every CN P 0 Pf0P 0 P every -inconsistent instantiation P , either P0-inconsistent P ; second condition stability given Lecoutre (2009) holdsf0necessarily choice poset paper. fact either P0-inconsistent P guarantees -inconsistent instantiation CNmissed CN made tighter: either discarded (has become explicit nogoodP 0 ) remains -inconsistent.Theorem 1. (Lecoutre, 2009) stable nogood-identifying consistency well-behaved.stability nogood-identifying consistency provides general procedurecomputing -closure CN: iteratively discard (in order) -inconsistent instantiations fixed point reached. Provided procedure sound (each removalcorresponds -inconsistent instantiation) complete (each -inconsistent instantiation removed), procedure guaranteed compute -closures. generally,different reduction rules used, must shown correct, monotonic inflationary. benefit generic iteration algorithm (Apt, 2003, Lemmas 7.5,7.8 Theorem 7.11). Stability union also proved domain-filteringconsistency, thus guaranteeing fixed point (Bessiere, 2006). interesting result follows:Proposition 1. Let two well-behaved (nogood-identifying) consistencies.stronger iff every CN P P, (P ) (P ).conclude section well-known domain-filtering consistencies. First, letus introduce generalized arc consistency (GAC). support (resp., conflict) value(x, a) P constraint c involving x support (resp., conflict) cI[x] = a. value (x, a) P GAC-consistent iff exists support (x, a) every180fiSecond-Order Consistenciesconstraint P involving x. P GAC-consistent iff every value P GAC-consistent.also say constraint c GAC-consistent iff every variable x scp(c) everyvalue dom(x), (x, a) GAC-consistent. binary CNs, GAC referred AC (ArcConsistency). Second, introduce singleton consistencies (Debruyne & Bessiere,1997b; Prosser, Stergiou, & Walsh, 2000). domain variable P empty, Pclearly unsatisfiable, denoted P = . CN P |x=a obtained Premoving every value b 6= dom(x). value (x, a) P SAC-consistent (SAC standsSingleton Arc Consistent3 ) iff GAC (P |x=a ) 6= (this called singleton check).value (x, a) P BiSAC-consistent iff GAC (P ia |x=a ) 6= , P ia CN obtainedremoving every value (y, b) P 6= x (x, a)/ GAC(P |y=b ) (Bessiere& Debruyne, 2008). P SAC-consistent (respectively, BiSAC-consistent) iff every valueP SAC-consistent (respectively, BiSAC-consistent). BiSAC strictly strongerSAC, strictly stronger GAC; BiSAC also strictly weaker strongpath consistency (Bessiere & Debruyne, 2008). GAC, SAC BiSAC well-behaved;example, SAC (P ) denotes SAC-closure CN P .3. Second-Order Consistenciessection, introduce second-order consistencies. First, startfamous one: path consistency. Then, clarify aspects path consistencysometimes misrepresented literature, introduce known restricted forms.Finally, introduce 3-consistency, dual consistency, 2-singleton arc consistency wellconservative strong variants.3.1 Path ConsistencyAmong consistencies allow us identify inconsistent pairs values, path consistency plays central role. Introduced Montanari (1974), definition sometimesmisinterpreted. problem arises around definition path, mustunderstood sequence variables, sequence variables correspondspath constraint graph. ambiguity probably comes Montanaris originalpaper, reasoning path consistency achieved respect complete (orcompletion of) constraint graphs, although footnote original paper indicates:path network sequence vertices. vertex occurpath even consecutive positions.precise definition path thus required. definition path usedMontanari (1974), Mackworth (1977) Debruyne (1998), definition graphpath used, example, Tsang (1993) Bessiere (2006). path arbitrarysequence variables, graph-path defined sequence variablesbinary constraint exists two variables adjacent sequence. binaryCN P , graph-path thus path constraint graph P . non-binary CN P ,non-binary constraints discarded (ignored) path resulting constraintgraph graph-path. important note given variable may occur severaltimes path (and so, graph-path). Figure 1 gives illustration.3. limit number acronyms, use SAC binary non-binary CNs.181fiLecoutre, Cardon, & VionDefinition 1 (Path). Let P CN.path P sequence hx1 , . . . , xk variables P x1 6= xk k 2;path variable x1 variable xk , k 1 length path.graph-path P path hx1 , . . . , xk P 1..k 1, c cons(P ) |scp(c) = {xi , xi+1 }.closed (graph-)path P (graph-)path hx1 , . . . , xk P c cons(P ) |scp(c) = {x1 , xk }.vzxwFigure 1: constraint graph binary CN P . hv, z, xi hv, y, w, yi paths P .hv, z, y, wi closed path P . hv, x, yi graph-path P . hv, x, wihz, x, v, w, x, yi two closed graph-paths P .central concept consistent paths defined follows:Definition 2 (Consistent Path). Let P CN.instantiation {(x1 , a1 ), (xk , ak )} P consistent path hx1 , . . . , xk P iffexists tuple ki=1 dom(xi ) [x1 ] = a1 , [xk ] = ak 1..k1,{(xi , [xi ]), (xi+1 , [xi+1 ])} locally consistent instantiation4 P . tuplesaid support {(x1 , a1 ), (xk , ak )} hx1 , . . . , xk (in P ).path hx1 , . . . , xk P consistent iff every locally consistent instantiation{x1 , xk } P consistent hx1 , . . . , xk i.example Figure 2, hv, z, xi consistent path P since locallyconsistent instantiation {(v, a), (x, b)} find b dom(z) {(v, a), (z, b)}locally consistent (this trivial since implicit universal binary constraintv z) {(x, b), (z, b)} locally consistent. Similarly, second locally consistentinstantiation {(v, b), (x, a)} extended z. closed graph-path hv, x, wi4. xi = xi+1 , necessarily [xi ] = [xi+1 ] instantiation cannot contain two distinct pairsinvolving variable.182fiSecond-Order Consistenciesconsistent; locally consistent instantiation {(v, b), (w, a)} cannot extended x. Onemight surprised hz, x, v, w, x, yi consistent. important notefree select different values x along path. example, locally consistentinstantiation {(z, b), (y, a)}, find support = (b, b, a, b, a, a) hz, x, v, w, x, yi.tuple belongs dom(z) dom(x) dom(v) dom(w) dom(x) dom(y), satisfies[z] = b, [y] = encountered binary constraints along path. Along pathfirst (x, b) subsequently (x, a).vbzbbbwbxFigure 2: compatibility graph binary CN P (whose constraint graph givenFigure 1). hv, z, xi consistent path P . closed graph-path hv, x, wiconsistent contrary hz, x, v, w, x, yi.introduce historical definition path consistency (PC, Montanari, 1974;Mackworth, 1977).Definition 3 (Path Consistency). CN P path-consistent, denoted PC-consistent, iffevery path P consistent.definition valid non-binary CNs. Simply, non-binary constraints ignored,Dechter (2003) Bessiere (2006) do, since Definition 2, pairs variablesconsidered. Montanari shown sufficient consider paths length two (i.e.,sequences three variables) only. Note necessary constraint graphcomplete (but, path consistency enforced, resulting CN may becomecomplete).Theorem 2. (Montanari, 1974) CN P path-consistent iff every 2-length path P(i.e., every sequence three variables) consistent.leads following classical definition:Definition 4 (Path Consistency). Let P CN.instantiation5 {(x, a), (y, b)} P path-consistent, denoted PC-consistent, iff2-length path-consistent, say, iff exists value c domainevery third variable z P {(x, a), (z, c)} {(y, b), (z, c)} locally5. paper, refer instantiation form {(x, a), (y, b)}, assume x 6= y.183fiLecoutre, Cardon, & Vionconsistent; {(x, a), (y, b)} path-consistent, said path-inconsistentPC-inconsistent.P path-consistent iff every locally consistent instantiation {(x, a), (y, b)} Ppath-consistent.3.2 Deep Path ConsistencyNow, show path consistency may easily misinterpreted, introduce consistency forms related PC. first natural question is: restrict attentiongraph-paths (see Definition 1)? answer given following observation.Observation 1. CNs, following properties equivalent:(a) every path consistent(b) every graph-path consistentProof. Consider, example, CN depicted Figure 3. CN path-consistentsince locally consistent instantiation {(x, b), (z, a)} consistent path hx, y, zi.limit attention graph-paths, consist variables x(for example, hx, yi, hx, y, x, yi, . . . ) local inconsistency.xbzFigure 3: CN P three variables one constraint (between x y). Ppath-consistent. However, graph-path built consistent.However, binary CN connected constraint graph (i.e., constraint graphcomposed single connected component), restriction graph-paths valid.Proposition 2. Let P binary CN P 6= constraint graph Pconnected. P path-consistent iff every graph-path P consistent.Proof. one direction (), immediate. P path-consistent, definitionevery path P consistent, including graph-paths.direction (), show every graph-path P consistent,every 2-length path P consistent (and thus P path-consistent using Theorem 2).practical terms, consider locally consistent instantiation {(x, a), (y, b)} showthird variable z P , following property P r(z) holds: c dom(z){(x, a), (z, c)} {(y, b), (z, c)} locally consistent instantiations.variable z three cases must considered, depending existence constraints cxz ,x z (i.e., scp(cxz ) = {x, z}), cyz , z.184fiSecond-Order Consistencies(a) constraints exist: thus exists graph-path hx, z, yi pathconsistent hypothesis, property P r(z) holds.(b) Neither constraint exist: P 6= implies dom(z) 6= , thus P r(z) holds cxzcyz implicit universal.(c) constraint cxz exists (similarly, constraint cyz exists): constraint graph connected, exists least one graph-path z y,consequently graph-path x form hx, z, . . . , yi. meansvalue dom(z) compatible (x, a), using hypothesis(every graph-path consistent). value also compatible (y, b)implicit universal constraint z y. Hence, P r(z) holds.Unsurprisingly (because Observation 1), binary CN P every 2-lengthgraph-path P consistent, necessarily path-consistent. course, specialcase constraint graph complete, CN path-consistent every pathP also graph-path P .Observation 2. CNs, following properties equivalent:(a) every graph-path consistent(b) every 2-length graph-path consistentProof. See Figure 4.vbzbbbwbxFigure 4: Every 2-length graph-path CN (whose constraint graph given Figure1) consistent. graph-path hx, w, v, x, zi consistent {(x, a), (z, a)}.following proposition 2-length graph-paths.Proposition 3. Let P binary CN P 6= P arc-consistent. Ppath-consistent iff every 2-length graph-path P consistent.Proof. proof similar proof Proposition 2 considering 2-length graph-pathsinstead graph-paths. case (c) demonstration differs.185fiLecoutre, Cardon, & Vion(c) constraint cxz exists (similarly, constraint cyz exists): P arcconsistent, exists value dom(z) compatible (x, a).implicit universal constraint z y, value also compatible(y, b). Hence, P r(z) holds.Theorem 2 Propositions 2 3 suggest historical definition path consistency appropriate since corresponds strongest form detection local inconsistencies using concept path (even considering graph-paths may seem naturalconsidering paths). Unfortunately, path consistency sometimes misinterpreted. example, Definition 3-11 work Tsang (1993) links PC graph-paths,Proposition 3.39 work Bessiere (2006) links PC 2-length graph-paths,Observations 1 2 (with Figure 4) show equivalent Montanaris definition. However, true check path consistency practice, need consider2-length graph-paths, provided binary constraints arc-consistent.Two different relation-filtering consistencies related path consistency defined terms closed graph-paths. first partial path consistency (partial PCPPC, Bliek & Sam-Haroud, 1999) second conservative path consistency (conservative PC CPC, Debruyne, 1999).Definition 5 (Partial Path Consistency). CN P partially path-consistent, denotedPPC-consistent, iff every closed graph-path P consistent.Definition 6 (Conservative Path Consistency). CN P conservative path-consistent,denoted CPC-consistent, iff every closed 2-length graph-path P consistent.binary constraints, PPC CPC equivalent constraint graphtriangulated: PPC initially introduced build filtering algorithm operatestriangulated graphs. graph triangulated (or chordal) iff every cycle composed fourvertices chord, edge joining two vertices adjacentcycle.Proposition 4. (Bliek & Sam-Haroud, 1999) Let P binary CN P triangulatedconstraint graph. P PPC-consistent iff P CPC-consistent.Enforcing path consistency simply means discarding path-inconsistent instantiations(i.e., recording new explicit nogoods size two) since know P C-closure, denotedPC (P ), CN P exists (path consistency well-behaved). enforce path consistencymay necessary introduce new binary constraints, thus path consistencyconservative consistency. PPC CPC differ existing constraints altered.additional weak forms path consistency, find directional path consistency (Dechter& Pearl, 1988; Tsang, 1993) pivot consistency (David, 1995),discussed paper. Although consistencies attractive controllingpractical inference effort situations, consistencies require introductionvariable ordering, restricts applicability.Finally, two domain-filtering consistencies related path consistency alsodefined: restricted path consistency (RPC, Berlandier, 1995) max-restricted path consistency (MaxRPC, Debruyne & Bessiere, 1997a). MaxRPC strictly stronger RPC186fiSecond-Order Consistenciesdefined follows: value (x, a) CN P max-restricted path consistent, denoted MaxRPC-consistent, iff every binary constraint cxy P involving x, existslocally consistent instantiation {(x, a), (y, b)} scp(cxy ) = {x, y} everyadditional variable z P , exists value c dom(z) {(x, a), (z, c)}{(y, b), (z, c)} locally consistent. CN P MaxRPC-consistent iff every valueP MaxRPC-consistent.3.3 Additional Second-Order Consistenciessection, introduce second-order consistencies defined independentlypath consistency. First, recall 3-consistency (3C, Freuder, 1978).Definition 7 (3-consistency). Let P CN.instantiation {(x, a), (y, b)} P 3-consistent, denoted 3C-consistent, iffexists value c domain every third variable z P {(x, a), (y, b), (z, c)}locally consistent.P 3-consistent iff every locally consistent instantiation {(x, a), (y, b)} P 3consistent.Note difference path consistency (see Definition 4): here, instantiationsize 3 must locally consistent (instead two instantiations size 2). known3C equivalent PC ternary constraint present.introduce dual consistency (Lecoutre et al., 2007a). Dual consistency, whoseidea initially used McGregor (1979), records inconsistent pairs values identified successive singleton checks. like singleton arc consistency, dual consistencybuilt top generalized arc consistency. Informally, CN dual-consistent iffpair values locally consistent detected inconsistent assigning eithertwo values enforcing GAC. simplify, write (x, a) P iff (x, a) valueP , i.e., x vars(P ) domP (x); P = , consider every pair (x, a),(x, a)/ P.Definition 8 (Dual Consistency). Let P CN.instantiation {(x, a), (y, b)} P dual-consistent, denoted DC-consistent, iff(y, b) GAC (P |x=a ) (x, a) GAC (P |y=b ).P DC-consistent iff every locally consistent instantiation {(x, a), (y, b)} PDC-consistent.may interested checks based two simultaneous decisions (variable assignments): obtain 2-singleton arc consistency (2SAC, Bessiere et al., 2005).Definition 9 (2-Singleton Arc Consistency). Let P CN.instantiation {(x, a), (y, b)} P 2-singleton arc-consistent, denoted 2SACconsistent, iff GAC (P |{x=a,y=b} ) 6= .187fiLecoutre, Cardon, & VionP 2SAC-consistent iff every locally consistent instantiation {(x, a), (y, b)} P2SAC-consistent.3-consistency, dual consistency 2-singleton arc consistency second-order consistencies, conservative restrictions naturally derived follows.Definition 10 (Conservative Second-Order Consistency). Let P CN,consistency {3C, DC, 2SAC}.instantiation {(x, a), (y, b)} P conservative -consistent, denoted C-consistent,iff either @c cons(P ) | scp(c) = {x, y} {(x, a), (y, b)} -consistent.P C-consistent iff every locally consistent instantiation {(x, a), (y, b)} PC-consistent.Thus, obtain three new second-order consistencies called conservative 3-consistency(C3C), conservative dual consistency (CDC, Lecoutre et al., 2007a) conservative 2singleton arc consistency (C2SAC). illustrate difference consistencyconservative restriction C, let us consider CN P vars(P ) = {w, x, y, z}cons(P ) = {cwx , cwz , cxyz }, subscripts indicate constraint scopes. reviews (locallyconsistent instantiations of) six possible distinct pairs variables whereas Creviews two pairs (w, x) (w, z).shall also interested strong variants second-order consistencies additionally guarantee generalized arc consistency. example, binary CN strong pathconsistent, denoted sPC-consistent, iff arc-consistent path-consistent; CNstrong dual-consistent, denoted sDC-consistent iff GAC-consistent DCconsistent. s3C, s2SAC, sPPC, sCPC, sCDC, sC3C, sC2SAC defined similarly.Definition 11 (Strong Second-Order Consistency). Let second-order consistency.CN P strong -consistent, denoted s-consistent, iff P GAC+-consistent, i.e.,GAC-consistent -consistent.strong second-order consistency identifies -inconsistent values (nogoodssize one) -inconsistent pairs values (nogoods size two). Strictly speaking,second-order consistency first+second order consistency.important note closure CN computed second-orderconsistencies mentioned far. consistencies proved stable,consequently well-behaved.Proposition 5. PC, 3C, DC, 2SAC, PPC, CPC, C3C, CDC, C2SAC, wellstrong variants, consistencies well-behaved.Sketch proof. Following Theorem 1, sufficient show mentioned consistencies stable (see Page 180). consistency among mentionedproposition, instantiation -inconsistent CN P , necessarilyexplicit nogood CN P 0 smaller equal P , -inconsistent P 0 .example, suppose = {(x, a), (y, b)} DC-inconsistent P . meansf0 , must show(y, b)/ GAC (P |x=a ) (x, a)/ GAC (P |y=b )./ P0DC-inconsistent P . necessarily (y, b)/ GAC (P 0 |x=a ) GAC (P |x=a )(x, a)/ GAC (P 0 |y=b ) GAC (P |y=b ) P 0 P . Hence, DC-inconsistent0P.188fiSecond-Order Consistencies4. Relationships Second-Order Consistenciessection studies qualitative relationships second-order consistenciespresented, namely path consistency, 3-consistency, dual consistency, 2-singleton arcconsistency, conservative strong variants. section composed threeparts (subsections). start relationships basic second-order consistencies(PC, 3C, DC, 2SAC). Then, focus relationships including conservative restrictions(PPC, CPC, C3C, CDC, C2SAC). Finally, finish strong second-order consistencies(sPC, s3C, sDC, s2SAC, sPPC, sCPC, sC3C, sCDC, sC2SAC).previous works (Lecoutre et al., 2007a, 2007b), study limited binaryCNs. paper, generalize results CNs arity, although resultsgiven specifically binary CNs non-binary CNs. precision given,results hold set possible binary non-binary CNs (i.e., CNs constraintsarbitrary arity).4.1 Results Basic Second-Order Consistenciesstart strongest (basic) second-order consistency paper, namely 2SAC.Proposition 6. 2SAC strictly stronger DC, strictly stronger 3C.Proof. Let P CN = {(x, a), (y, b)} locally consistent instantiation P .one hand, DC-inconsistent either (y, b)/ GAC (P |x=a ) (x, a)/GAC (P |y=b ), necessarily entails GAC (P |{x=a,y=b} ) = . Consequently, 2SACinconsistent, follows 2SAC stronger DC. hand, 3Cinconsistent z vars(P ) | c dom(z), {(x, a), (y, b), (z, c)} locally consistent.CN P 0 = GAC (P |{x=a,y=b} ), necessarily dom(z) = (because xassigned GAC enforced), thus P 0 = . means 2SAC-inconsistent,follows 2SAC stronger 3C. Strictness proved Figure 5 showsbinary CN DC-consistent, 3C-consistent 2SAC-consistent.6binary CNs, DC equivalent PC. could predicted since McGregor proposed AC-based algorithm establish sPC (1979). show 2 steps.Proposition 7. DC strictly stronger PC.Proof. Let P CN = {(x, a), (y, b)} locally consistent instantiation P .path-inconsistent z vars(P ) | c dom(z), {(x, a), (z, c)} {(y, b), (z, c)}locally consistent (see Definition 4). case, know (y, b)/ GAC (P|x=a ) sinceenforcing GAC P|x=a , every value c remaining dom(z) {(x, a), (z, c)}consistent. Necessarily, hypothesis, remaining values incompatible(y, b), thus b removed dom(y) enforcing GAC. Hence dual-inconsistent,follows DC stronger PC. Strictness proved Figure 6 showsnon-binary CN PC-consistent DC-consistent.Proposition 8. binary CNs, DC equivalent PC.6. result, well Figures 9 12, computer-checked.189fiLecoutre, Cardon, & Vionwcwxbbcxbbbzbcbcz(a) compatibility graph P .wcwbcc(b) incompatibility graph P .xbbcxbbbzbccbz(c) {(w, b), (x, a)} DC-consistent(x, a) GAC(P |w=b ) (and similarly,(w, b) GAC(P |x=a )).bcc(d) {(w, b), (x, a)} 2SAC-inconsistent GAC(P |{w=b,x=a} ) = .Figure 5: CN P sDC-consistent (and s3C-consistent) C2SAC-consistent.Dotted circles lines correspond deleted values tuples.Proof. Proposition 7, know DC stronger PC. Now, show that,binary CNs, PC stronger DC, therefore conclude DC PCequivalent. Let P binary CN = {(x, a), (y, b)} locally consistent instantiationP . dual-inconsistent (y, b)/ AC (P|x=a ), symmetrically (x, a)/ AC (P|y=b ).consider first case.Let us consider filtering procedure F iteratively removes (in order) values P|x=a successively found arc-inconsistent fixpoint.procedure guaranteed compute AC (P|x=a ) (cf. Apt, 2003; Lecoutre, 2009). Let H(k)following induction hypothesis: (z, c) one k first values removed F,190fiSecond-Order ConsistencieswbbxzbbFigure 6: CN P two ternary constraints cwxy cwxz rel(cwxy ) ={(a, a, a), (b, b, b)} rel(cwxz ) = {(a, b, a), (b, a, b)}. P also involves binary constraint cyz . P sPC-consistent CDC-consistent. Indeed,{(y, a), (z, a)} DC-inconsistent since GAC (P |y=a ) = .f0 P 0 = PC (P ), i.e., {(x, a), (z, c)} either initially locally{(x, a), (z, c)} Pinconsistent identified path-inconsistent (possibly propagation).show H(1) holds. (z, c) first value removed F, means (z, c)support binary constraint involving z second variable w. {(x, a), (z, c)}locally inconsistent, H(1) holds trivially. Otherwise, necessarily w 6= x (becausewould mean (z, c) compatible (x, a) since assigned x,{(x, a), (z, c)} initially locally inconsistent). Therefore {(x, a), (z, c)} clearlysupport path hx, w, zi thus path-inconsistent.assume H(k) true show H(k + 1) holds. (z, c) k + 1thvalue removed F, means removal involves constraint binding zanother variable w. value (z, c) support constraint, thus every valuedom(w) initially supporting (z, c), any, one k first values removed F.f0 P 0 = PC (P ).hypothesis means value b, {(x, a), (w, b)} Pf0case, deduce {(x, a), (z, c)} P and, special case, identifypath-inconsistent. Consequently, every locally consistent instantiation Pf0 P 0 = PC (P ). deduce PC (P ) DC(P )Pf00 P 00 = DC(P ) also Palso Proposition 1 PC stronger DC binary CNs.Now, consider 3-consistency. binary CNs, well-known 3-consistencyequivalent path consistency. So, 3C also equivalent DC (since DC equivalentPC). non-binary CNs, following relationships PC DC.Proposition 9. non-binary CNs, 3C incomparable DC, strictly strongerPC.Proof. non-binary CNs, 3C strictly stronger PC (e.g., see Dechter, 2003, p. 69)3C also checks ternary constraints. comparing 3C DC, appears3C cannot stronger DC CN composed one quaternary constraint191fiLecoutre, Cardon, & VionGAC-consistent necessarily 3-consistent (since binary ternaryconstraints) DC-consistent. hand, DC cannot stronger 3CFigure 7 shows non-binary CN DC-consistent 3-consistent (thereway extending {(x, a), (y, a)} z). Hence, 3C DC incomparable.xbbbczFigure 7: CN P sDC-consistent C3C-consistent (because {(x, a), (y, a)}3-consistent). dashed hyperedge corresponds nogood {(x, a), (y, a),(z, b)}, i.e., ternary constraint cxyz forbidding tuple (a, a, b).4.2 Results Conservative Second-Order ConsistenciesNow, consider conservative variants basic second-order consistencies. firstimmediate result conservative consistencies made strictly weakerunrestricted forms. However, worthwhile mention (strong) PPC shownequivalent (strong) PC binary convex CNs triangulated constraint graphs (Bliek& Sam-Haroud, 1999).Proposition 10. 2SAC, DC, 3C PC respectively strictly stronger C2SAC,CDC, C3C PPC+CPC.Proof. definition, conservative consistencies weaker. Strictness proved Figure 8shows binary CN C2SAC-consistent (and CDC-consistent, C3C-consistent,PPC-consistent, CPC-consistent) PC-consistent (and 3C-consistent, DCconsistent 2SAC-consistent).Proposition 11. PC, DC 3C incomparable C2SAC.Proof. one hand, PC cannot stronger C2SAC since Figure 5 shows binaryCN PC-consistent C2SAC-consistent. hand, C2SAC cannotstronger PC since Figure 8 shows binary CN C2SAC-consistentPC-consistent. conclude PC C2SAC incomparable. also validDC 3C since binary CNs mentioned proof (and PC=DC=3C binaryCNs).Proposition 12. C2SAC strictly stronger CDC, strictly stronger C3C.192fiSecond-Order ConsistenciesProof. proof similar Proposition 6, considering initially locally consistentinstantiation = {(x, a), (y, b)} CDC-inconsistent (and next C3C-inconsistent)x linked constraint.wbbxzbbFigure 8: CN (no constraint binds w x z) sC2SAC-consistent(and CDC+C3C+PPC+CPC-consistent), PC-consistent (and 2SACconsistent). example, {(x, a), (z, b)} path-consistent.Proposition 13. CDC strictly stronger PPC.Proof. Assume CN P CDC-consistent consider closed graph-path hx1 , . . . , xpP . every locally consistent instantiation {(x1 , a1 ), (xp , ap )} P , (xp , ap ) P 0P 0 = GAC (P |x1 =a1 ) since P CDC-consistent. also implies P 0 6= . Therefore,context P 0 , exists least one value domain since P 0 generalizedarc-consistent, clearly value (xp1 , ap1 ) P 0 compatible (xp , ap ), value(xp2 , ap2 ) P 0 compatible (xp1 , ap1 ), . . . , value (x1 , a01 ) P 0 compatible0(x2 , a2 ). domP (x1 ) = {a1 }, a01 = a1 , thus locally consistentinstantiation {(x1 , a1 ), (xp , ap )} consistent closed graph-path hx1 , . . . , xp P .Hence P PPC-consistent, thus CDC stronger PPC.fact CDC strictly stronger PPC shown CN P depictedFigure 9. Figure 9(c), P shown CDC-inconsistent locally consistentinstantiation {(x, a), (y, b)} dual-inconsistent: (y, b)/ AC (P |x=a ). Figure 9(d), Pshown CPC-consistent because, example, locally consistent instantiation{(x, a), (y, b)} consistent 2-length graph-paths linking x y, namely, hx, z, yihx, w, yi. Here, constraint graph triangulated, means CPC equivalentPPC. Hence deduce result.Proposition 14. non-binary CNs, CDC incomparable C3C.Proof. CDC cannot stronger C3C since Figure 7 shows non-binary CNCDC-consistent C3C-consistent. Now, consider CN Figure 9 extendedsingle ternary constraint involving new variables. CN remains C3C-consistent (because193fiLecoutre, Cardon, & Vionxbzbxbwwvcbbbb(b) incompatibility graph P .xbzbxbwvc(a) compatibility graph P (no constraintbinds x v).zbbbbwvbbc(c) P CDC-consistent. see(y, b)/ AC (P |x=a ). Thus, locally consistentinstantiation {(x, a), (y, b)} dual-inconsistent.zbcbbbv(d) P sCPC-consistent (and hence sPPCconsistent since P triangulated). (closed)2-length graph-path P linking x consistent. shown {(x, a), (y, b)}.Figure 9: Example binary CN P sPPC-consistent (and sC3C-consistent)CDC-consistent.194fiSecond-Order Consistenciesbinary constraint new variables), still CDC-consistent.Hence, C3C cannot stronger CDC, CDC C3C incomparable.Proposition 15. binary CNs, PPC strictly stronger C3C. non-binary CNs,PPC incomparable C3C.Proof. 1) Let P binary CN PPC-consistent (and differentweak restriction). consider locally consistent instantiation {(x, a), (y, b)}P (such binary constraint involving x y) show every third variable z P , following property P r(z) holds: c dom(z){(x, a), (z, c)} {(y, b), (z, c)} locally consistent instantiations, equivalent {(x, a), (y, b), (z, c)} locally consistent since P binary. P r holds,{(x, a), (y, b)} C3C-consistent. variable z, 3 cases must considered, depending existence constraints cxz , x z, cyz , z.(a) constraints exist: thus, exists graph-path hx, z, yi pathconsistent hypothesis, necessarily property P r(z) holds.(b) Neither constraint exist: P 6= implies dom(z) 6= , thus P r(z) holds cxzcyz implicit universal.(c) constraint cxz exists (similarly, constraint cyz exists). Considergraph-path hx, z, x, yi. hypothesis, graph-path consistent. Hence,exists value c dom(z) {(x, a), (z, c)} locally consistent. also knowthat{(y, b), (z, c)} locally consistent constraintz. conclude P r(z) holds PPC stronger C3C binary CNs.Figure 10 proves strictness showing CN C3C-consistent PPC-consistent.2) non-binary CNs, Figure 7 shows PPC cannot stronger C3C: CNPPC-consistent C3C-consistent. Now, consider CN Figure 10 extendedsingle ternary constraint involving new variables. CN remains C3C-consistent (becausebinary constraint new variables), still PPC-consistent.Hence, C3C cannot stronger PPC, PPC C3C incomparable.Proposition 16. C3C strictly stronger CPC.Proof. Let P CN C3C-consistent. Let hx, z, yi closed 2-length graph-pathP {(x, a), (y, b)} locally consistent instantiation P . P C3Cconsistent, know exists value c dom(z) {(x, a), (y, b), (z, c)}locally consistent. Consequently, exists value c dom(z) {(x, a), (z, c)}{(y, b), (z, c)} locally consistent. deduce path hx, z, yi consistent,thus P CPC-consistent C3C stronger CPC. Figure 11 proves strictnessshowing binary CN CPC-consistent (there 3-clique) C3C-consistent.Proposition 17. PPC strictly stronger CPC.195fiLecoutre, Cardon, & VionwbxbbzbFigure 10: CN (no constraint binds w x z) sC3C-consistent (andsCPC-consistent, BiSAC-consistent) PPC-consistent. example,{(x, a), (w, a)} PPC-consistent.xbzFigure 11: binary CN P two constraints (no constraint exists z). PCPC-consistent C3C-consistent.Proof. PPC stronger CPC definition. Moreover, binary CN Figure 10CPC-consistent PPC-consistent. 3-clique constraintgraph, CN trivially CPC-consistent.Proposition 18. non-binary CNs, PC incomparable CDC.Proof. one hand, consider CN Figure 8 extended single ternary GACconsistent constraint involving new variables. additionnal constraint GACconsistent, CN remains CDC-consistent. However, PC-consistent. deduceCDC cannot stronger PC (on non-binary CNS). hand, Figure6 proves PC cannot stronger CDC: P PC-consistent (becauseone binary constraint) CDC-consistent ({(y, a), (z, a)} CDC-inconsistent).conclude non-binary CNs, PC CDC incomparable.4.3 Results Strong Second-Order Consistenciesstudying relationships existing strong variants second-order consistencies, observe that, binary case, enforcing AC path-consistent CN sufficient196fiSecond-Order Consistenciesobtain strong path-consistent CN. well-known fact also true general caseDC, CDC, 2SAC C2SAC. define (P ) ((P )).Proposition 19. binary CN P , AC PC (P ) = sPC (P ).Proof. PC (P ), every locally consistent instantiation {(x, a), (y, b)} supportevery third variable z. Hence, every value PC (P ) locally consistent instantiationarc-consistent. Consequently, AC enforced PC (P ), value present locallyconsistent instantiation (of size 2) removed, PC preserved.Proposition 20. CN P , GAC DC (P ) = sDC (P ), GAC CDC (P ) =sCDC (P ), GAC 2SAC (P ) = s2SAC (P ) GAC C2SAC (P ) = sC2SAC (P ).Proof. Let P 0 = DC (P ) P 00 = GAC (P 0 ). singleton check GAC (P 00 |x=a ) P 00 ,GAC (P 00 |x=a ) = GAC (GAC (P 0 )|x=a ) = GAC (P 0 |x=a ). means resultsingleton check (x, a) P 00 result singleton check(x, a) P 0 . Since P 0 DC-consistent, deduce DC(P 00 ) = P 00 . P 00GAC-consistent DC-consistent, P 00 = GAC DC(P ) = sDC(P ). similarproof holds CDC , 2SAC C2SAC .shown schema previous propositions hold CPCPPC (Lecoutre, 2009). example, binary CNs P , AC CPC (P ) 6=sCPC (P ). Unsurprisingly, relationships preserved strong variants considered.Proposition 21. Let two second-order consistencies. strongerstronger s.Proposition 22. have:(a) s2SAC strictly stronger sDC, strictly stronger s3C.(b) sDC strictly stronger sPC.(c) s3C strictly stronger sPC.(d) s2SAC, sDC, s3C, sPC respectively strictly stronger sC2SAC, sCDC,sC3C, sPPC+sCPC.(e) sC2SAC strictly stronger sCDC, strictly stronger sC3C.(f) sCDC strictly stronger sPPC.(g) sPPC strictly stronger sCPC.Proof. illustrative CNs introduced previously GAC-consistent (except Figure 11),thus using Proposition 21, suffices consider: (a) Proposition 6 Figure 5 strictness, (b) Proposition 7 Figure 6 strictness, (c) Proposition 9 Figure 7strictness, (d) Proposition 10 Figure 8 strictness, (e) Proposition 12 Figure 5strictness, (f) Proposition 13 Figure 9 strictness, (g) Proposition 17 Figure10 strictness.197fiLecoutre, Cardon, & Vionfollowing result indicates C3C CPC quite close properties. arcconsistent CNs, equivalent.Proposition 23. binary CNs, sC3C equivalent sCPC.Proof. Propositions 16 21, know sC3C stronger sCPC. Now,show that, binary CNs, sCPC stronger sC3C. proof similarProposition 15 considering binary CN initially sCPC-consistent. case (c)demonstration differs:(c) constraint cxz exists (similarly, constraint cyz exists): P arcconsistent, exists value dom(z) compatible (x, a).implicit universal constraint z y, value also compatible(y, b). Hence, P r(z) holds.Proposition 24. sPC, sDC s3C incomparable sC2SAC.Proof. proof Proposition 11, CNs Figures 5 8 GAC-consistent.Proposition 25. non-binary CNs, sPC incomparable sCDC.Proof. proof Proposition 18, CNs Figures 8 6 GAC-consistent.Finally, conclude section establishing connections SAC.Proposition 26. sDC strictly stronger SAC+CDCProof. Let P CN sDC-consistent. Assume value (x, a) P SACinconsistent. means P 0 = GAC (P |x=a ) = , every value (y, b),(y, b)/ P 0 (recall value belongs ). P DC-consistent hypothesis,nogoods recorded P meaning every variable y, binary constraintcxy forbidding tuple involving (x, a). deduce (x, a) GAC-inconsistent,contradicts hypothesis (P sDC-consistent), shows sDC stronger SAC.know DC strictly stronger CDC, deduce sDC strongerSAC+CDC. prove strictness, suffices build CN SAC-consistent, CDCconsistent DC-consistent (e.g., see Figure 8).Proposition 27. binary CNs, sCDC strictly stronger SAC.Proof. Let P binary CN sCDC-consistent. Assume value (x, a) PSAC-inconsistent. means AC (P |x=a ) = . P AC-consistent (since PsCDC-consistent hypothesis), necessarily x involved (at least) binary constraintc (otherwise propagation possible deduce AC (P |x=a ) = ). Consequently,tuple allowed c involving (x, a) since P CDC-consistent (because P 0 = ,every value (y, b), consider (y, b)/ P 0 ). deduce (x, a) AC-inconsistent.contradiction shows sCDC stronger SAC. prove strictness, sufficesobserve sCDC reasons inconsistent values pairs values.Proposition 28. binary CNs, SAC+CDC equivalent sCDC. non-binary CNs,SAC+CDC strictly stronger sCDC.198fiSecond-Order ConsistenciesbcefgubccbvwcbcbxecbbcezFigure 12: CN sCDC-consistent BiSAC-consistent: (z, c) BiSACconsistent, value appears none singleton tests AC (P |v=a ),AC (P |v=b ) AC (P |v=c ).Proof. Clearly, SAC+CDC stronger sCDC since SAC stronger GAC (andsCDC GAC+CDC). hand, sCDC trivially stronger CDCknow Proposition 27 sCDC stronger SAC binary CNs. deduce that,binary CNs, sCDC stronger SAC+CDC, SAC+CDC equivalentsCDC. non-binary CNs, show strictness, let us consider non-binary CN depictedFigure 6, binary constraint cyz eliminated. new obtained CN GACconsistent, CDC-consistent (since binary constraints), thus sCDCconsistent, SAC-consistent GAC (P |y=a ) = .Proposition 29. binary CNs, sCDC incomparable BiSAC.Proof. one hand, BiSAC cannot stronger sCDC since Figure 9 shows binaryCN BiSAC-consistent (note every value belongs least one solution)CDC-consistent. hand, sCDC cannot stronger BiSAC since Figure 12199fiLecoutre, Cardon, & VionC2SAC2SACs2SACsC2SAC3C=DC=PCs3C=sDC=sPCBiSACCDCsCDC=SAC+CDCSACPPCsPPCMaxRPCC3CsCPC=sC3CAC=2CCPC(a) Consistencies restricted binary CNs.C2SAC2SACs2SAC3CDCsDCSAC+CDCPCCDCsCDCsPCC3CPPCsPPCCPCsCPCSACGAC(b) Consistencies CNs constraints arbitrary arity.strictly strongerincomparable= equivalentFigure 13: Summary relationships consistencies.shows binary CN sCDC-consistent BiSAC-consistent. concludesCDC BiSAC incomparable.results given general case (i.e., CNs constraints arbitrary arity)also hold binary CNs considered. case Propositions 6, 10, 11,12, 13, 16, 17, 22 (except cases (b) (c)), 24 26 binary CNs usedproofs. Figure 13 shows relationships (strong) second-order consistenciesintroduced paper, focus binary CNs Figure 13(a). Figure 13(b),sake clarity, s3C, sC3C, sC2SAC inserted.200fiSecond-Order Consistencies5. Algorithm Enforce s(C)DCsection, present general algorithm enforce strong (conservative) dual consistency. algorithm valid binary non-binary CNs. algorithm calledsCDC1 used enforce sCDC, sDC1 used enforce sDC. Actually,non-binary CNs, sCDC1 algorithm enforces SAC+CDC, strictly strongersCDC. extra strength comes free exploitation singleton checksused enforce CDC.Algorithm 1: sCDC1/sDC1(P ): BooleanInput/Output: CN P ; sCDC (SAC+CDC) sDC enforced PResult: true iff P strong (conservative) dual-consistent123456789101112P GAC (P )P = return falsex first(vars(P ))marker xrepeatreviseVariable(P, x)P GAC (P )P = return falsemarker x// GAC initially enforced// GAC maintainedx nextCircular(x, vars(P ))x = markerreturn trueAlgorithm 1 establishes strong (conservative) dual consistency given CN P .learnxxx function called Line 9 Algorithm 2, used Algorithm 1, specializedeither learnpart (Algorithm 3) enforce sCDC (SAC+CDC non-binary CNs omitprecision on) learnf ull (Algorithm 4) enforce sDC P . Basically,Algorithm 1 performs successive singleton checks fixed point reached, returnstrue iff P strong (conservative) dual-consistent, i.e., iff sCDC (P ) 6= (with learnpart )sDC (P ) 6= (with learnf ull ). GAC enforced line 1, variable consideredturn main loop establish consistency. first(vars(P )) first variableP lexicographical order, nextCircular(x, vars(P )) variable P rightx any, first(vars(P )) otherwise. two functions allow circular iterationvariables P . example, vars(P ) = {x, y, z}, iteration form x, y, z,x, y, z. . . course, possible control order variables one iterationnext using heuristic.reviseVariable function (Algorithm 2) revises given variable x means strong(conservative) dual consistency, i.e., explores possible inferences respect xperforming singleton checks values dom(x). achieve this, GAC enforcedP |x=a value domain x (Line 3). SAC-inconsistent,removed domain x (Line 5). Otherwise (Lines 7 10), every variable 6= xP least one value deleted constraint propagation, try learn nogoods201fiLecoutre, Cardon, & VionAlgorithm 2: reviseVariable(P ,x): Boolean10effective falseforeach value domP (x)P 0 GAC (P |x=a )// singleton check (x, a)0P =remove domP (x)// SAC-inconsistent valueeffective trueelse0foreach variable vars(P ) | 6= x domP (y) 6= domP (y)0learnxxx (P, (x, a), y, domP (y) \ domP (y))effective true11return effective123456789Algorithm 3: learnpart (P , (x, a), y, Deleted): Boolean12345678cxy cons(P ) | scp(cxy ) = {x, y}conflictsforeach b Deleted | (a, b) relP (cxy )conflicts conflicts {(a, b)}// CDC-inconsistent pairconflicts 6=relP (cxy ) relP (cxy ) \ conflictsreturn truereturn falseAlgorithm 4: learnf ull (P , (x, a), y, Deleted): Boolean1234567cxy cons(P ) | scp(cxy ) = {x, y}conflictsforeach b Deleted | (a, b) relP (cxy )conflicts conflicts {(a, b)}// CDC-inconsistent pairconflicts 6=relP (cxy ) relP (cxy ) \ conflictsreturn true12elseconflicts {(a, b) | b Deleted}// DC-inconsistent pairsLet cxy new constraint that:scp(cxy ) = {x, y}rel(cxy ) = (dominit (x) dominit (y)) \ conflictscons(P ) cons(P ) {cxy }return true13return false891011202fiSecond-Order Consistenciesmeans functions learnpart learnf ull ; set values deleted propagation passedlast parameter (in practice, using stack handle domains trailing mechanism,need explicitly compute set deleted values). revision effectivex value tuple deleted (possibly inserting new constraint). Booleanvariable effective introduced track revision effectiveness. revision xeffective, reviseVariable returns true Line 6 Algorithm 1, GAC re-established(Line 7). domain relation wipe-out detected Line 8. marker, initializedfirst variable vars(P ) (Line 4) updated whenever inferences performed(Line 9), manages termination.Algorithms 3 4 discard identified binary nogoods correspond CDCinconsistent pairs values constraint cxy exists: every tuple (a, b) bdeleted value (i.e., b present P P 0 ) (a, b) present relP (cxy )removed relP (cxy ). enforcing sDC (with learnf ull ) binary constraintexists x y, new constraint created. constraint enforces setnogoods corresponding DC-inconsistent pairs values involving (x, a) variable y.new constraint accepts every pair values except identified0conflicts. Notice know least one conflict since domP (y) 6= domP (y)line 8 Algorithm 2.Proposition 30. Algorithm sCDC1 enforces sCDC binary CNs SAC+CDCnon-binary CNs; Algorithm sDC1 enforces sDC.Proof. First, inference performed Algorithm 2 Line 5 learnpart /learnf ullcorrect: inferences correspond clearly identified SAC-inconsistent values (C)DCinconsistent pairs values. inference directly performed Algorithm 1 Lines 17 also safe corresponds removing GAC-inconsistent values; rememberoverall algorithm enforces strong (C)DC, SAC+CDC (and SAC strongerGAC). fact possible inferences performed guaranteed facttime revision effective, marker used Algorithm 1 updated; see Line 9.Also, inference performed respect pair (x, a) effect GAC (P |x=b ),b value domain variable x. Indeed, b assigned x,values current domain x automatically removed. Combinedenforcement GAC, assignment new value x makes previous inferences relatedvalues x without effect. reason iterate valuesx Line 2 Algorithm 2 unique pass.One pass Algorithm 1 means calling reviseVariable exactly per variable.Proposition 31. One pass Algorithm 1 worst-case time complexity O(enrdr+1 )learnpart (i.e., sCDC1) O(enrdr+1 + n3 d3 ) learnf ull (i.e., sDC1).Proof. optimal worst-case time complexity enforcing GAC O(erdr ) (Mohr &Masini, 1988). worst-case time complexity Lines 810 Algorithm 2 O(nd)learn methods. Besides,learnpart , new constraint inserted P , worst-case time complexityone pass Algorithm 1 O(nd (erdr + nd)). reduces O(enrdr+1 )203fiLecoutre, Cardon, & Vionweak assumption n er (otherwise, variables would involvedconstraint);learnf ull , consider O(n2 ) additional binary constraints mayadded algorithm. So, obtain O(enrdr+1 + n3 d3 ).binary constraints (r = 2, entails e < n2 ), obtain:Corollary 1. binary CNs, one pass Algorithm 1 admits worst-case time complexityO(end3 ) learnpart O(n3 d3 ) learnf ull .P already s(C)DC-consistent, several passes Algorithm 1 necessary.Thus,learnpart , number passes bounded O(ed2 ); one tuple removednew pass. worst-case time complexity Algorithm 1 O(e2 nrdr+3 )(O(e2 nd5 ) binary CNs);learnf ull , number passes bounded O(n2 d2 ); one tuple removednew pass. resulting worst-case time complexity O(en3 rdr+3 +n5 d5 )(O(n5 d5 ) binary CNs).overall time complexity Algorithm 1 seems rather high observedoften fixed point quickly reached practice (i.e., number passesempirically tends constant). also note sDC1 (i.e., Algorithm 1learnf ull ), possible limit cost enforcing GAC singleton check. Indeed,singleton check pair (x, a) performed, every nogood size 2 including (x, a)identified recorded CN P . means last instructioniteration foreach loop starting Line 2 Algorithm 2, Passigning x, applying forward checking (any non-binary version, Bessiere,Meseguer, Freuder, & Larrosa, 2002) enough enforce GAC: need considerbinary constraints involving x delete values consistent (x, a).studied paper Lecoutre et al. (2007b).Finally, worthwhile mention Algorithm 1 require specific datastructure. data structures required underlying (G)AC algorithm(s)representation CNs. eb denotes number binary constraintsgiven CN, sCDC1 may require O(eb d2 ) additional space store new nogoods(if binary constraints initially given intension example). sDC1 require O(n2 d2 )additional space, may serious drawback solving certain problems.6. Experimental Resultsshow practical interest strong second-order consistencies, particular s(C)DC,conducted several extensive experiments Oracle Java 6 VMs running clusterIntel Xeon 3.0 GHz 1 GiB RAM Linux. this, implemented sCPC,sCDC sDC algorithms constraint solver AbsCon. implementationssCPC8, directly derived PC8 (Chmeiss & Jgou, 1998), sCDC1 sDC1 correspond Algorithm 1 learnpart learnf ull , respectively. refinements204fiSecond-Order Consistenciesalgorithm sDC1, proposed Lecoutre et al. (2007b), also possibleconsidered paper, mainly optimizations rather marginal (a speedup 10 % problems) respect main concern: showing enforcings(C)DC search may pay off.AbsCon solver also features SAC preprocessing algorithms. used SAC1 (Bessiere& Debruyne, 2005) SAC3 (Lecoutre & Cardon, 2005) algorithms experiments.AbsCon, algorithms used enforce (G)AC AC3bit+rm (Lecoutre & Vion, 2008)binary constraints, GAC3rm (Lecoutre & Hemery, 2007) non-binary constraintsdefined intension, STR2 (Lecoutre, 2008) non-binary constraints extension.Besides, possible, optimization based reasoning cardinality conflictsets (Boussemart, Hemery, Lecoutre, & Sais, 2004b) used. course, SAC1, SAC3,sCDC1 sDC1 also benefit efficiency underlying (G)AC algorithms.6.1 Preprocessing Performance Random Problemsfirst evaluate performance various consistencies algorithms random instances. Random CNs generated using Model B (Gent, MacIntyre, Prosser, Smith,& Walsh, 2001) comply five parameters: number variables n, sizedomains d, arity constraints r (r = 2 experiment), density ,7tightness (proportion tuples forbidden constraint).100ACsCPCSACsCDCsDCInverseDensity [%]806040202040608020Tightness [%]406080100Tightness [%](a) n = 50, = 10(b) n = 50, = 50Figure 14: Phase transition various consistencies random binary CNs.Figure 14 gives quantitative information relative strength AC, sCPC,SAC, sCDC sDC (= sPC) enforced random binary CNs n = 50 variables{10, 50} values per domain. plot figures represents positionphase transition given consistency generated instances; 50 instancesgenerated (, t) pair, recall phase transition consistencyoccurs 50 % generated instances detected unsatisfiable enforcing7. density determines number constraints e =205nrfiCPU time [s]Lecoutre, Cardon, & VionsPC8sDC1sCPC8sCDC1100508060400201005550606570Tightness6065Tightness7075(a) = 50, = 50 %(b) = 50, = 100 %CPU time [s]400300200300100200040302010070100068727476Tightness787072Tightness7480(c) = 90, = 50 %(d) = 90, = 100 %Figure 15: Mean CPU time (in seconds) enforcing various second-order consistenciesbinary random CNs (n = 50).206fiSecond-Order Consistencies. Phase transition inverse consistency also plotted baseline: CN inverseconsistent, (1, n)-consistent, iff value belongs least one solution. obtainedresults show sCPC rather close sCDC random instances, excepttightness ranges 40% 70%. Surprisingly, difference sCDCsDC weak even visible graphs. Also, see second-orderconsistencies become closer inverse consistency size domains lower.Figure 15 compares CPU times required establish sPC, sDC, sCPC sCDC,binary random CNs, using algorithms sPC8, sDC1, sCPC8 sCDC1, respectively.value t, 50 instances generated, either 50 values (topmost figures)90 values (bottommost figures) per variable. Leftmost pictures represent performancesCNs density = 50 % rightmost pictures CNs complete constraintgraphs. latter case, consistencies equivalent; plots sDC1sPC8 given. results quite informative. one hand, illustratehigh performance s(C)DC algorithms respect state-of-the-art s(C)PCalgorithms, performance gap often one order magnitude dense problems.hand, obtained results show establishing sDC much harderenforcing sCDC.6.2 Impact Second-Order Consistency Preprocessing MACNow, turn complete search algorithms. One popular (systematic) searchalgorithms solve CNs called MAC (Sabin & Freuder, 1994). MAC interleaves inferencesearch since step depth-first exploration backtracking, (generalized)arc consistency maintained.8 step search, MAC uses variable orderingheuristic select next variable instantiated. Two representative variable orderingheuristics dynamic heuristic dom/ddeg (Bessiere & Rgin, 1996) adaptive heuristic dom/wdeg (Boussemart, Hemery, Lecoutre, & Sais, 2004a). Today, enforcing(strong) second-order consistencies search (basically, variable assignment)seems unrealistic. However, enforcing consistencies preprocessing stagerunning MAC issue deserves addressed; section, attemptprovide insight regard. denotes consistency enforcing algorithm appliedpreprocessing, denoted -MAC. experimentation conductedconsists comparing MAC, SAC1-MAC (and also SAC3-MAC), sCPC8-MAC, sCDC1MAC sDC1-MAC; called variants MAC. allows us assesspractical impact enforcing (strong) second-order consistencies preprocessing manyseries structured (i.e., random) binary non-binary instances. series welldescription found http://www.cril.fr/~lecoutre/benchmarks.html.briefly introduce main features series (listed alphabetical order).aim: series instances Boolean variables ternary constraints. Initially,generated Boolean formulas DIMACS CNF (Conjunctive Normal Form) format.bqwh: series satisfiable balanced quasi-group instances holes (Gomes & Shmoys,2002); domains variables small (usually, values) constraints binary.8. simplicity, shall use acronym MAC whatever arity constraints is.207fiLecoutre, Cardon, & Vioncomposed: series instances randomly composed main (under-constrained) fragmentauxiliary fragments (Lecoutre, Boussemart, & Hemery, 2004); 10values per domain constraints binary.driver: series planning instances costs converted WCSP (Weighted CSP)CSP; domains variables small (usually, values) constraints binary.ehi: series SAT instances converted CSP using dual method describedBacchus (2000); 7 values per domain constraints binary.langford: series (generalized version the) Langford problem; domains variables usually small (up 150 values) constraints binary.os-taillard: series Open-Shop scheduling instances generated J. Vion Taillardspaper (1993); domains large constraints binary.primes: series instances involving prime numbers generated M. van Dongen; domainsvariables small constraints non-binary.qcp / qwh: series Quasi-group Completion Problem (QCP) Quasi-groupHoles problem (QWH); domains large constraints binary.queensKnights: series academic instances queens knights put chessboard (Boussemart et al., 2004a); domains large constraints binary.radar: realistic radar surveillance problems generated following model Swedishinstitute computer science (SICS); domains small constraints non-binary.renault-mod: series instances generated K. Stergiou Renault Megane configuration problem; domains diverse constraints non-binary.sadeh: series containing five sets job-shop scheduling instances studied Sadeh &Fox (1996); domains large constraints binary.scens11: series containing hard variants original scen11 instance Radio LinkFrequency Assignment Problem (RLFAP, Cabon et al., 1999); domains smallconstraints binary.series: series all-interval series problem; domains diverse constraintsbinary ternary.ruler: series Golomb Ruler problem; domains small constraintsbinary, ternary quaternary.tsp: series generated R. Szymanek Travelling Salesperson problem; domainslarge constraints binary ternary.Tables 1 3 show results obtained different variantsMAC (the third column MAC alone) equipped variable ordering heuristicsdom/ddeg dom/wdeg, respectively. series, number nbs instances solvedfive variants MAC within alloted time (20 minutes) well totalnumber nb instances given form nbs /nb column #Inst. mean CPUtimes displayed two tables computed nbs instances identifiedseries; variant solves additional instances, indicated bracketspreceded + symbol. interesting note SAC3 algorithm (Lecoutre &Cardon, 2005) sometimes permits discover lucky solutions preprocessing duegreedy nature. happens, show increased number solved instancesbehind /. example, Table 1, first row indicates 12 instances set208fiSecond-Order ConsistenciesMAC preprocessing =Series#InstSAC1/3sCPC8sCDC1aim-100aim-200bqwh-15bqwh-18composed-25composed-75driverehi-85ehi-90langford-2langford-3langford-4os-taillard-4os-taillard-5os-taillard-7primes-10primes-15primes-20qcp-10qcp-15qcp-20queensKnightsqwh-10qwh-15qwh-20radar-8-24radar-8-30radar-9-28renault-modsadehscens11seriesrulertsp-20tsp-2512/246/24100/10099/10015/503/407/799/10094/10016/2416/2414/2429/3010/306/3025/3220/3220/3214/155/150/156/1810/1010/100/1534/5035/5012/5046/5016/460/1110/2517/2815/1513/151002621.7755.91210.644.01972511.4449.6(+1) 25.0(+1) 13.6(+5) 13.1(+2) 64.545.3(+2) 3.013.60(+1) 18.1(+4) 21297.90.775.95(+4) 12.9(+1) 3.590.7(+1) 36.4(+11) 4.5244.5(+1) 77.36.63(+2) 84.8(+2) 65.6(+7) 2631.6354.6(+35) 0.89(+37) 0.7311.4(+1) 1.47(+6) 1.461.7347.429.0(+1) 1.85(+9/10) 6.58(+2/3) 75.292.412.6(+2) 76.6(+1) 18.6(+4) 214(+11) 0.740.7611.7(+5) 20.9(+4) 35.1(+5) 1.58(+2) 4.05(+11/22) 5.7145.9(+1) 70.88.27(+2) 72.21062731.37(+1) 33.3(+35) 0.97(+37) 0.89.74(+1) 1.84(+6) 1.8836.938.9(+1) 38.0(+1) 5.79(+9) 10324745.0(+2) 3.093.77(+1) 19.8(+3) 172(+6) 0.820.938.56(+3)(+4) 13.7(+1) 3.7593.5(+1) 36.8(+11) 10.1(+3)47.6(+1) 70.18.08(+2) 97.1(+2) 68.1(+7) 2651.1929.3(+35) 1.1(+37) 0.88.48(+1) 1.32(+6) 1.33.7725.7(+1) 21.8(+1) 2.15(+8) 65.277.091.115.8(+2) 87.9(+1) 18.4(+3) 168(+11) 0.640.827.2(+4)(+5) 14.2(+3) 3.6(+5) 1.35(+2) 9.30(+12) 4.10(+3)43.688.919.6(+2) 63.954.216.43.5(+1) 26.3(+35) 1.2(+37) 1.153.9(+1) 1.41(+6) 1.43.2926.0(+1) 21.73.10(+10) 94.8(+3) 118(+1) 86.2(+2) 13.9(+2) 73.418.4(+1) 129(+11) 0.691.103.34(+8)(+4) 3.09(+4) 20.2(+5) 1.33(+1) 20.6(+13) 78.8(+3)(+15) 0.83(+1) 62.463.7223+36+148/161+129+152+178(+1)sDC1(+3)(+10)Table 1: Mean cpu time (in seconds) solve instances different series (time-out 1,200per instance) -MAC-dom/ddeg.209fiLecoutre, Cardon, & VionMAC preprocessing =Instancesaim-100-1-6-satbqwh-18-141-30driver-02c-satdriver-09-satlangford-4-15os-taillard-5-95-2primes-15-20-2-3primes-20-20-3-3scen11-f12renault-mod-8series-12cpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - delsCPC850.9 (0)25655 K0-0180 (0.01)311,682 K6-02.34 (0.03)355,27864 - 0222 (0.05)57215 K162 - 0254 (0.03)321,056 K1,620 - 0> 1,20046.6 (0.01)25655 K0-066.2 (0.11)31643 K6 - 1823.68 (1.23)433,27764 - 9,43952.7 (20.9)13514,284162 - 63,163287 (79.2)52197 K1,620 - 517 K> 1,2001.81 (0.32)29122657 - 0> 1,2001.77 (0.27)29122657 - 0> 1,200>120015.3 (11.5)532406,324 - 419 K24.5 (0.04)67179 K22 - 012.9 (0.10)29106 K0-024.0 (0.05)67179 K22 - 012.2 (0.01)29106 K0-0sCDC10.38 (0.03)25100100 - 092.2 (0.20)31845 K9 - 2073.66 (2.33)39988343 - 5,33610.3 (8.2)736502,175 - 22,590215 (7.61)40197 K1,620 - 517 K9.06 (6.56)323,204570 - 384 K16.5 (15.4)29104766 - 0188 (178)29175602 - 07.95 (4.84)49186,768 - 306 K8.05 (6.07)67095 - 012.0 (0.26)29106 K0-0sDC10.47 (0.12)25100100 - 231 (200)49.5 (0.31)35443 K9 - 585 (296)15.0 (13.3)66505343 - 31 K (7 K)61.1 (58.6)2176502 K - 117 K (19 K)215 (7.45)40197 K1,620 - 517 K (0)15.1 (12.1)402,562570 - 1 (175)22.1 (21.4)29101766 - 2,491 (46)153 (141)29181653 - 18,804 (96)13.7 (10.4)96187 K - 351 K (3 K)7.84 (6.8)101072 - 11 K (1,719)0.81 (0.33)29230 - 310 (110)Table 2: Detailed results various instances (time-out 1,200 per instance) MAC-dom/ddeg.210fiSecond-Order ConsistenciesMAC preprocessing =Seriesaim-100aim-200bqwh-15bqwh-18composed-25composed-75driverehi-85ehi-90langford-2langford-3langford-4os-taillard-4os-taillard-5os-taillard-7primes-10primes-15primes-20qcp-10qcp-15qcp-20queensKnightqwh-10qwh-15qwh-20radar-8-24radar-8-30radar-9-28renault-modsadehscens11seriesrulertsp-20tsp-25#InstSAC1/324/2424/24100/100100/10050/5040/407/7100/100100/10016/2416/2414/2430/3028/3011/3026/3222/3221/3215/1515/150/157/1810/1010/1010/1050/5050/5027/5050/5037/469/1210/2519/2815/1513/150.976.860.995.370.701.023.141.961.971.4756.226.51.0840.5(+3) 70.071.1(+1) 2.43(+2) 13.40.7143.1(+3)(+1) 2.570.691.6715226.61.43(+1) 90.21.65(+1) 13.195.4(+1) 12.6(+2) 16.23.91(+2) 20.9+17sCPC8sCDC1sDC10.901.941.123.870.690.8610.71.441.571.7557.6(+0/1) 29.11.74(+1) 65.0(+3/9) 76.5(+0/2) 73.6(+2/1) 27.2(+1/2) 82.90.8416.8(+3/4)(+10) 0.830.812.2712527.637.3(+2/10) 37.92.72(+1/7) 25.1(+0/1) 54.6(+0/1) 1.76(+1/0) 46.36.09(+2) 28.41.057.131.054.040.820.948.431.872.0039.846.444.05.6652.0(+1) 26671.9(+1) 2.34(+2) 13.80.8862.8(+3)(+5) 0.881.412.5496.026.51.55(+1) 88.91.88(+1) 18.8109(+1) 13.5(+2) 24.04.48(+2) 25.41.013.330.983.930.841.028.21.301.403.3634.627.51.89(+2) 45.5(+1) 10378.5(+2) 16.2(+1) 91.00.7760.8(+4)(+10) 0.640.761.7273.227.92.11(+2) 71.57.94(+3) 33.281.616.3(+1) 66.018.1(+2) 59.00.841.251.393.710.820.9655.71.311.363.3232.928.32.57(+2) 48.4(+4) 14597.6(+2) 14.5(+2) 75.90.9131.1(+3)(+10) 0.661.011.6441.426.42.10(+2) 67.511.8(+6) 48.8172(+15) 0.79(+1) 41.669.1271+26/51+19+28+47Table 3: Mean cpu time (in seconds) solve instances different series (time-out 1,200per instance) -MAC-dom/wdeg.211fiLecoutre, Cardon, & VionMAC preprocessing =Instancese0ddr1-4e0ddr1-5qcp-15-120-2qcp-20-187-11scen11-f8scen11-f6series-14series-25tsp-20-75os-taill-7-100-8os-taill-7-105-9cpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - delcpu (pcpu)memnodesdel v - del1.35 (0.01)32500-0125 (0.01)321,245 K0-093 (0.04)32955 K1,276 - 02.33 (0.15)374,8982,913 - 06.93 (0.06)3715,6404,992 - 037.2 (0.05)37204 K3,660 - 093.2 (0.01)29689 K0-0> 1,200sCPC85.25 (4.0)32500-0121 (4.17)321,245 K0-034.8 (0.36)36308 K1,276 - 302> 1,20031.2 (26.5)572,2144,992 - 365 K74.8 (33.9)57167 K3,660 - 415 K101 (0.16)29689 K0-0> 1,200sCDC13.05 (1.8)32500 - 8,5463.19 (1.94)32750 - 7,00636.0 (0.33)36333 K1,282 - 1772.4 (0.58)453,4352,930 - 3258.39 (4.6)532,2144,992 - 366 K45.9 (4.47)53167 K3,660 - 416 K125 (0.2)29914 K0-0> 1,2003.32 (0.13)356,92621 K - 0165 (0.01)49667 K0-09.43 (0.01)464,2100-04.04 (0.36)516,92621 K - 0378 (361)5342,4990 - 58336 (256)50179 K0 - 4,32826.9 (25.7)471,63122 K - 27 K24.8 (8.4)4942,4990 - 5886.2 (8.4)50179 K0 - 4,328sDC18.57 (7.3)60500 - 531 K (927)9.08 (7.7)60560 - 529 K (922)2.41 (0.45)407061,282 - 418 (189)2.66 (0.98)812,0992,930 - 1,091 (583)12.3 (6.85)896,1064,992 - 389 K (757)74.4 (6.46)89260 K3,660 - 443 K (757)0.91 (0.41)29270 - 444 (156)3.16 (2.34)41490 - 1,610 (552)90.0 (81.3)1972,06422 K - 895 K (1.4 K)31.2 (8.8)5351,4030 - 60 (1)16.2 (9.4)50490 - 11,072 (20)Table 4: Detailed results various instances (time-out 1,200 per instance) MAC-dom/wdeg.212fiSecond-Order Consistencies24 instances series aim-200 solved five variants MAC.sDC1-MAC solves 12 instances mean CPU time computed 54.2 seconds,additionally solves 3 instances series (within 20 minutes). Noteseries, mean CPU time best variant MAC printed bold face:best variant one solves highest number instances within 20 minutescase equality, one smallest mean CPU time.Tables 2 4 provide details solving various instances enforcing second-orderconsistencies preprocessing. problem instance, total CPU time solvegiven (this > 1,200 instance cannot solved within 20 minutes) welltime taken enforce consistency preprocessing (pcpu brackets). Additionalinformation concern memory requirement (expressed MiB), number explorednodes number values tuples deleted preprocessing (del v del t). sDC1,also put number new binary constraints brackets. example, Table2, solving instance aim-100-1-6-sat, sDC1-MAC needs 0.47 (0.12 preprocessing),25 MiB memory, explores 100 nodes, deletes 100 values 231 tuples preprocessing(while adding 200 new binary constraints).Table 1 clearly shows heuristic dom/ddeg used, real interestmaking strong propagation effort preprocessing many problems. Although MACremains efficient approach series (e.g., langford-2 tsp-20), sCDC1-MACsDC1-MAC proved robust MAC. example, series aim200, radar-9-28 series, sDC1-MAC largely outperforms MAC. Overall, sDC1-MAC solves178 36 = 142 instances MAC. sCDC1-MAC SAC1/3-MAC comparableterms number solved instances. However, series (e.g., langford-3bqwh-18), sCDC1-MAC clearly better SAC1/3-MAC, even reverse trueseries (e.g., renault-mod sadeh). also interesting note sCPC8MAC almost always outperformed sCDC1-MAC sDC1-MAC. expectedresult, sCPC weaker sCDC (and fortiori sDC), s(C)DC algorithms benefitunderlying highly optimized (G)AC algorithms. series, adding new binaryconstraints order collect identified nogoods size 2 may counterproductive.conservative consistency sCDC better option sDC. example,case driver tsp-25 series.results given Table 2 show dramatic effect strong consistency preprocessing instances. example, enforcing sCDC sDC, MAC abledirectly find solution aim-100-1-6-sat. also case sDC1-MAC series-12.However, sDC1 may require significant amount additional memory (to record new constraints). may explain relative inefficiency sDC1-MAC instances driver-02csat, driver-09-sat scen11-f12, compared sCDC1-MAC. Note renault-mod-8,sCDC1 sDC1 alone sufficient detect unsatisfiability (the number visited nodes0). However, unsatisfiability instance proved differently (i.e., following different propagation paths), explain 95 72 values respectively deletedsCDC sDC enforced.Table 3 confirms MAC equipped heuristic dom/wdeg far robustdom/ddeg, initially claimed Boussemart et al. (2004a). result, series, enforcing strong consistency (i.e. consistency stronger GAC) preprocessinglimited impact. Nevertheless, overall, sDC1-MAC still increases robustness213fiLecoutre, Cardon, & Vionsolver. Concerning SAC3-MAC, important note good behaviour dueopportunistic mechanism finding solutions, inference capabilityshown results SAC1-MAC: SAC1-MAC solves 26 additional instances 51SAC3-MAC. sCDC1-MAC outperformed sDC1-MAC, note series,remains good option perturbate heuristic adding new constraints (e.g., compare number nodes solving instances scen11-f6 scen11-f8Table 4) overhead preprocessing limited (compare example preprocessingtime sCDC1 sDC1 e0ddr1-4 tsp-20-75 Table 4).lessons learned experimental study? first one enforcing s(C)DC time far efficient enforcing s(C)PC. firstexperimental attempts (not presented paper) enforce s(C)2SAC showexpensive approach, believe s(C)DC is, now, best second-orderconsistency enforced preprocessing.second unsurprising lesson problems enforcing s(C)DCcost-effective. Basically, cost enforcing s(C)DC mainly depends total numbervalues tested9 well time complexity underlying GAC algorithm(s).non-binary constraints, time complexity enforcing GAC usually increasesarity constraints extensional constraints, time complexity enforcingGAC usually depends size tables. consequence, problem involvesconstraints large arity and/or large tables, enforcing s(C)DC may become penalizing.case renault-mod, tsp-20 tsp-25 series Table 3.third lesson enforcing sDC preprocessing tends make MAC algorithmrobust. confirm this, Figure 16 shows two cactus-shaped plots giveinsight relative performance variants MAC whole range testedproblem instances. plots show establishing sDC searching solutionusing MAC enhances robustness solver, especially variable orderingheuristic fails. dom/ddeg variable ordering heuristic, plain MAC almost alwaysworse MAC second-order consistency established preprocessing.better dom/wdeg variable ordering heuristic, enforcing second-order consistencyinteresting hardest problems, require 50 seconds solved.zoom Figure 16(b) MAC versus sDC1-MAC shows trend reversed:50 seconds, sDC1-MAC solves instances MAC.conclude section experiment hardest instances RLFAPseries scens11 (see e.g., results http://www.cril.fr/{CPAI06,CPAI08,CPAI09}).Using variable ordering heuristic dom/wdeg, ran plain MAC, MAC symmetrybreaking method described Lecoutre & Tabary (2009, denoted MACSB here), s(C)DCMAC, finally MAC inference mechanisms. Enforcing sCDC permits reducesize search tree developed MAC instances, sDC, lessobvious (the added constraints perturbate heuristic), shown Table 5. Interestingly, joint use symmetry-breaking method reveals quite efficient here.Using inference mechanisms, unsatisfiability instances proved without search effort (0 nodes sCDC1-MACSB sDC1-MACSB columns). NoteSAC-MACSB builds search tree problems, even possible solve9. example, discarded fapp series problem instances, consistencies based singletonchecks clearly adapted huge number values.214fiSecond-Order Consistencies1,200MACsCPC8-MACSAC1-MACsCDC1-MACSAC3-MACsDC1-MACCPU time [s]1,00080060040020005005506006507007508008509009501,000 1,050 1,1009501,000 1,050 1,100Number solved instances(a) dom/ddeg1,200CPU time [s]1,0008006001008060402040009009501,0001,0502000500550600650700750800850900Number solved instances(b) dom/wdegFigure 16: Number instances (out full set 1,237 instances) solvedwithin given amount CPU time variants MAC (e.g., 870 instancessolved within 1,200 MAC-dom/ddeg).215fiLecoutre, Cardon, & Vioninstance scen11-f1 SAC1-MACSB (or SAC3-MACSB ) equipped heuristicdom/ddeg, within 20 minutes.sCDC1Instancescen11-f1scen11-f2scen11-f3scen11-f4scen11-f6scen11-f8MACcpunodescpunodescpunodescpunodescpunodescpunodes> 1,200> 1,200> 1,2005423,381 K60.1348 K6.014,077MACSBMAC52.8267 K24.3108 K11.035,9797.911,2463.82,2263.81,847> 1,200> 1,200> 1,2004382,095 K41.9163 K9.945,021sDC1-MACSB10.007.605.806.004.305.30MAC> 1,200> 1,200> 1,2008083,362 K65.1215 K11.14,518MACSB12.309.706.805.904.604.30Table 5: Cost running (-)MAC-dom/wdeg hardest instances RLFAP seriesscens11. MACSB MAC automatic global symmetry-breaking method.7. Conclusionpaper intended give better picture second-order consistencies. purpose, studied theoretical relationships existing four basic second-orderconsistencies (and variants), shown reasonably enforced search. However, next generation constraint solvers, tractableclasses CSP instances certainly identified exploited search,order close, example, certain nodes search tree polynomial time. several theoretical results relate global consistency second-order consistencies (e.g.,strong 3-consistency), increase importance second-order consistencies.practical terms, advantages using (conservative) dual consistency.Algorithms enforce strong (C)DC rather easy implement, made efficient highly optimized underlying GAC algorithms. Used preprocessing, revealimprove robustness constraint solver several hard structured problems. (C)2SACstronger (C)DC, naive approach establishing requires several passesO(n2 d2 ) enforcements GAC, makes ineffective. perspective workdevise efficient algorithms (C)2SAC could competitive (C)DC ones.Finally, multi-core processors become increasingly common, parallel constraint solving become useful. near future, may imagine strongsecond-order consistencies could used basic components (with strong inference capabilities) parallel solvers.216fiSecond-Order ConsistenciesAcknowledgmentspaper extended revised version earlier works (Lecoutre et al., 2007a, 2007b).would like thank anonymous reviewers constructive remarks.ReferencesAllen, J. (1983). Maintaining knowledge temporal intervals. CommunicationsACM, 26 (11), 832843.Apt, K. (1999). essence constraint propagation. Theoretical Computer Science,221 (1-2), 179210.Apt, K. (2003). Principles Constraint Programming. Cambridge University Press.Bacchus, F. (2000). Extending Forward Checking. Proceedings CP00, pp. 3551.Berlandier, P. (1995). Improving domain filtering using restricted path consistency.Proceedings IEEE-CAIA95.Bessiere, C. (2006). Constraint propagation. Handbook Constraint Programming,chap. 3. Elsevier.Bessiere, C., Coletta, R., & Petit, T. (2005). Apprentissage de contraintes globales implicites. Proceedings JFPC05, pp. 249258.Bessiere, C., & Debruyne, R. (2005). Optimal suboptimal singleton arc consistencyalgorithms. Proceedings IJCAI05, pp. 5459.Bessiere, C., & Debruyne, R. (2008). Theoretical analysis singleton arc consistencyextensions. Artificial Intelligence, 172 (1), 2941.Bessiere, C., Meseguer, P., Freuder, E., & Larrosa, J. (2002). Forward Checkingnon-binary constraint satisfaction. Artificial Intelligence, 141, 205224.Bessiere, C., & Rgin, J. (1996). MAC combined heuristics: two reasons forsake FC(and CBJ?) hard problems. Proceedings CP96, pp. 6175.Bessiere, C., Stergiou, K., & Walsh, T. (2008). Domain filtering consistencies non-binaryconstraints. Artificial Intelligence, 72 (6-7), 800822.Bliek, C., & Sam-Haroud, D. (1999). Path consistency triangulated constraint graphs.Proceedings IJCAI99, pp. 456461.Boussemart, F., Hemery, F., Lecoutre, C., & Sais, L. (2004a). Boosting systematic searchweighting constraints. Proceedings ECAI04, pp. 146150.Boussemart, F., Hemery, F., Lecoutre, C., & Sais, L. (2004b). Support inference genericfiltering. Proceedings CP04, pp. 721725.Cabon, B., de Givry, S., Lobjois, L., Schiex, T., & Warners, J. (1999). Radio Link FrequencyAssignment. Constraints, 4 (1), 7989.Chmeiss, A., & Jgou, P. (1998). Efficient path-consistency propagation. InternationalJournal Artificial Intelligence Tools, 7 (2), 121142.Cooper, M., Cohen, D., & Jeavons, P. (1994). Characterising tractable constraints. ArtificialIntelligence, 65, 347361.217fiLecoutre, Cardon, & VionDavid, P. (1995). Using pivot consistency decompose solve functional CSPs. JournalArtificial Intelligence Research, 2, 447474.Debruyne, R. (1998). Consistances locales pour les problmes de satisfaction de contraintesde grande taille. Ph.D. thesis, Universite Montpellier II.Debruyne, R. (1999). strong local consistency constraint satisfaction. ProceedingsICTAI99, pp. 202209.Debruyne, R., & Bessiere, C. (1997a). restricted path consistency max-restrictedpath consistency. Proceedings CP97, pp. 312326.Debruyne, R., & Bessiere, C. (1997b). practical filtering techniques constraintsatisfaction problem. Proceedings IJCAI97, pp. 412417.Debruyne, R., & Bessiere, C. (2001). Domain filtering consistencies. Journal ArtificialIntelligence Research, 14, 205230.Dechter, R. (1992). local global consistency. Artificial Intelligence, 55 (1), 87108.Dechter, R. (2003). Constraint processing. Morgan Kaufmann.Dechter, R., & Pearl, J. (1988). Network-based heuristics constraint satisfaction problems. Artificial Intelligence, 34 (1), 138.Freuder, E. (1978). Synthesizing constraint expressions. Communication ACM,21 (11), 958965.Freuder, E. (1982). sufficient condition backtrack-free search. Journal ACM,29 (1), 2432.Gent, I., MacIntyre, E., Prosser, P., Smith, B., & Walsh, T. (2001). Random constraintsatisfaction: flaws structure. Constraints, 6 (4), 345372.Gomes, C., & Shmoys, D. (2002). Completing quasigroups latin squares: structuredgraph coloring problem. Proceedings Computational Symposium Graph Coloring Generalization.Green, M., & Cohen, D. (2008). Domain permutation reduction constraint satisfactionproblems. Artificial Intelligence, 172, 10941118.Jgou, P. (1993). Decomposition domains based micro-structure finiteconstraint-satisfaction problems. Proceedings AAAI93, pp. 731736.Katsirelos, G., & Bacchus, F. (2003). Unrestricted nogood recording CSP search.Proceedings CP03, pp. 873877.Lecoutre, C. (2008). Optimization simple tabular reduction table constraints.Proceedings CP08, pp. 128143.Lecoutre, C. (2009). Constraint networks: techniques algorithms. ISTE/Wiley.Lecoutre, C., Boussemart, F., & Hemery, F. (2004). Backjump-based techniques versusconflict-directed heuristics. Proceedings ICTAI04, pp. 549557.Lecoutre, C., & Cardon, S. (2005). greedy approach establish singleton arc consistency.Proceedings IJCAI05, pp. 199204.218fiSecond-Order ConsistenciesLecoutre, C., Cardon, S., & Vion, J. (2007a). Conservative dual consistency. ProceedingsAAAI07, pp. 237242.Lecoutre, C., Cardon, S., & Vion, J. (2007b). Path consistency dual consistency.Proceedings CP07, pp. 438452.Lecoutre, C., & Hemery, F. (2007). study residual supports arc consistency.Proceedings IJCAI07, pp. 125130.Lecoutre, C., & Tabary, S. (2009). Lightweight detection variable symmetries constraint satisfaction. Proceedings ICTAI09, pp. 193197.Lecoutre, C., & Vion, J. (2008). Enforcing arc consistency using bitwise operations. Constraint Programming Letters, 2, 2135.Mackworth, A. (1977). Consistency networks relations. Artificial Intelligence, 8 (1),99118.McGregor, J. (1979). Relational consistency algorithms application findingsubgraph graph isomorphisms. Information Sciences, 19, 229250.Mohr, R., & Masini, G. (1988). Good old discrete relaxation. Proceedings ECAI88,pp. 651656.Montanari, U. (1974). Network constraints : Fundamental properties applicationspicture processing. Information Science, 7, 95132.Montanari, U., & Rossi, F. (1991). Constraint relaxation may perfect. Artificial Intelligence, 48 (2), 143170.Prosser, P., Stergiou, K., & Walsh, T. (2000). Singleton consistencies. ProceedingsCP00, pp. 353368.Sabin, D., & Freuder, E. (1994). Contradicting conventional wisdom constraint satisfaction. Proceedings CP94, pp. 1020.Sadeh, N., & Fox, M. (1996). Variable value ordering heuristics job shopscheduling constraint satisfaction problem. Artificial Intelligence, 86, 141.Schiex, T., & Verfaillie, G. (1994). Nogood recording static dynamic constraintsatisfaction problems. International Journal Artificial Intelligence Tools, 3 (2), 187207.Stergiou, K., & Walsh, T. (2006). Inverse consistencies non-binary constraints.Proceedings ECAI06, pp. 153157.Taillard, E. (1993). Benchmarks basic scheduling problems. European journal operations research, 64, 278295.Tsang, E. (1993). Foundations constraint satisfaction. Academic Press.van Beek, P. (1992). minimality decomposability constraint networks.Proceedings AAAI92, pp. 447452.Zhang, Y., & Yap, R. (2006). Set intersection consistency constraint networks.Journal Artificial Intelligence Research, 27, 441464.219fiJournal Artificial Intelligence Research 40 (2011) 415468Submitted 9/10; published 2/11On-line Planning Scheduling:Application Controlling Modular PrintersWheeler Rumlruml cs.unh.eduDepartment Computer ScienceUniversity New Hampshire33 Academic WayDurham, NH 03824 USAMinh BinhRong ZhouMarkus P. J. Fromherzminhdo parc.comrzhou parc.comfromherz parc.comPalo Alto Research Center3333 Coyote Hill RoadPalo Alto, CA 94304 USAAbstractpresent case study artificial intelligence techniques applied controlproduction printing equipment. Like many real-world applications, complex domain requires high-speed autonomous decision-making robust continual operation.knowledge, work represents first successful industrial application embeddeddomain-independent temporal planning. system handles execution failures multiobjective preferences. heart on-line algorithm combines techniquesstate-space planning partial-order scheduling. suggest general architecture may prove useful applications intelligent systems operate continual,on-line settings. system used drive several commercial prototypesenabled new product architecture industrial partner. comparedstate-of-the-art off-line planners, system hundreds times faster often findsbetter plans. experience demonstrates domain-independent AI planning basedheuristic search flexibly handle time, resources, replanning, multiple objectiveshigh-speed practical application without requiring hand-coded control knowledge.1. Introductionsustaining goal artificial intelligence develop techniques enabling autonomousagents robustly achieve multiple interacting goals dynamic environment. goalintellectually attractive. also happens align perfectly needsmany commercial manufacturing plants. paper, focus one particular manufacturing setting: high-speed digital production printing systems. large machines usexerography print requested images individual sheets paper. Unlike traditionalcontinuous-feed offset presses, digital printers treat sheet differently: feeding different types sizes media, printing different kinds images, performing differentpreparatory finishing operations. Often, single integrated machine transformblank sheets complete document, bound book folded bill sealedenvelope. sometimes even possible process different kinds jobs simultaneouslyc2011AI Access Foundation. rights reserved.fiRuml, Do, Zhou, & Fromherzequipment. printer controller must plan quickly reliably; otherwise expensive human intervention required. Designing high-performance yet cost-effectivecontroller machines made difficult current trend towards increasedmodularity, customers system unique includes componentsappropriate needs. working closely XeroxCorporation explore architectures printing systems composed literally hundreds modules, possibly including multiple specialized printing modules, workingtogether high speed.paper, demonstrate techniques artificial intelligence usedcontrol machines. Requests print jobs become goals system achieve,various actuators mechanisms machine become actions resources usedachieving goals, sensors provide feedback action execution statesystem. provide high productivity (and thus high return investmentequipment owner), planning control techniques must fast produce optimalnear-optimal plans. reduce need operator oversight allow usecomplex mechanisms, system must autonomous autonomic possible.operators make mistakes even highly-engineered system modules fail,system must cope execution failure unexpected events.system must work legacy modules order commercially viable, architecturemust tolerate components direct control.meet requirements, present novel architecture on-line planning, execution, replanning synthesizes techniques state-space planning (Ghallab, Nau,& Traverso, 2004) partial-order scheduling (Smith & Cheng, 1993). develop newheuristic evaluation functions temporal planning incorporate effectsresource constraints. Although domain-independent AI planning often regardedexpensive use soft real-time setting, system achieves good performance withouthand-coded control rules, despite additional requirements reasoning temporal actions resources. avoiding domain-dependent search control knowledge,becomes possible use planner run different printing systems full productivity. success system enabled new modular product architecturespan multiple markets. Much previous work brought constraint-based schedulingdaily use print shops offices world-wide (Fromherz, Saraswat, & Bobrow, 1999;Fromherz, Bobrow, & de Kleer, 2003), work bring domain-independent temporalplanning continual widespread use everyday people. approach practicalefficient, showcases flexibility inherent viewing planning heuristic search.discussing application context detail, present overviewsystem, followed detailed discussion major aspects: nominal planning, exception handling, multiple objectives. go, present empirical measurementsdemonstrating large printing systems controlled system meetingreal-time requirements. particular, Section 4.4.1 describes comparison stateof-the-art generic off-line planners demonstrates planner finds plans hundredstimes faster often higher quality, on-line appendix provides videosplanner controlling hardware prototype. integrated approach on-lineplanning scheduling allows us achieve high throughput even complex systems.416fiOn-line Planning Scheduling Modular PrintersFigure 1: prototype modular printer built PARC. system composed approximately 170 individually controlled modules, including four print engines.conclude paper summary general lessons derived buildingapplication.2. Application Contextanalogy parallel systems RAID storage, approach modular printingsystems called Rack Mounted Printing (RMP). RMP system seen networktransports linking multiple printing engines. transports known mediapath. Figure 1 shows four-engine prototype printer built Palo Alto Research Center(PARC) 170 independently controlled modules. Figure 2 provides schematicside view, showing many possible paper paths linking paper feeders possibleoutput trays. (Video 1 on-line appendix, nominal simulation, presents animationFigure 2.) Multiple feeders allow blank sheets enter printer high ratemultiple finishers allow several print jobs run simultaneously. redundant pathsmachine enables graceful degradation performance modules fail.building system relatively small modules, enable easy reconfiguration417fiRuml, Do, Zhou, & FromherzFigure 2: schematic side view modular printer indicating feeders, paper path,output trays.components add new modules functionality. Achieving benefits, however, posesconsiderable control challenge.modular printing domain reminiscent mass customization, massproduced products closely tailored personalized individual customers needs.also similar package routing logistics problems. control perspective,involves planning scheduling series sheet requests arrive asynchronouslytime front-end print-job submission rendering engine. system runshigh speed, several sheet requests arriving per second, possibly many hours.sheet request completely describes attributes desired final product. mayseveral different sequences actions used print given sheet. example,Figure 2, blank sheet may fed either two feeders, routedone four print engines (or combination two four enginescase duplex printing) either finisher (unless sheet part on-goingprint job).on-line planning problem complicated fact many sheets in-flightsimultaneously plan new sheet must interfere sheets.actions require use physical printer components, planning later sheets must takeaccount resource commitments plans already released production.modern printers highly configurable, execute large variety jobs potentiallysimultaneously, large variety constraints feasible plans, hard-codedlocally-reactive plans suffice (Fromherz et al., 1999). fact, printer engineersXerox delight uncovering situations products competing manufacturers,use model-based planning, attempt execute infeasible plans.418fiprintermodelTranslatorOn-line Planning Scheduling Modular PrintersdomaindescriptionPlannerfailuresTranslatorproblemdescriptionsheetdescriptionconstraintsSTNplanstime infoitinerariesgoalsPlan Managerrejections,failures,updatesMachineControllerFigure 3: system architecture, planning system indicated dashed box.planning system must decide print requested sheets quickly possiblethus must determine plan schedule sheet end timeplan finishes last minimized. words, planner attempts minimizemakespan combined global plan sheets, essence optimizing systemsoverall throughput. Typically many feasible plans given sheet request;problem quickly find one minimizes . optimal plan sheet dependssheet request, also resource commitments present previouslyplanned sheets. legal series actions always easily scheduled pushingfar future, entire printer become completely idle, coursedesirable. on-line task set sheets grows time passesplan execution (i.e., printing) interleaves plan creation. fact,real-world wall clock end time want minimize productionsheet cannot start planned, speed planner affects valueplan! However, system often runs full capacity, thus planner usually needplan rate sheets completed, may several per second.challenging, domain also forgiving: feasible schedules found quickly,sub-optimal plans acceptable, plan execution relatively reliable.printer controller works on-line real-time continual planning environmentthree on-going processes: 1) on-line arrival new goals; 2) planning known goals;3) execution previously synthesized plans. Figure 3 shows inputs outputsplanning system, domain model sheet requests entering leftcommunication low-level control system right. plan managerresponsible tracking status goal invoking planner necessary.planning execution occur sequentially given sheet, processesusually interleaved different sheets. Figure 4 sketches different stepssheet-plan life cycle managed plan manager. Specifically, upon receiving, sheetsput unplanned first-in-first-out queue (sheets 6 7). sheet planner picksone sheet time unplanned queue tries find route-plansheet (sheet 5). plan found put queue plans havent yetsent printer controller (sheets 3 4). Another plan manager process regularlychecks planned queue decide earliest starting time plan queue419fiRuml, Do, Zhou, & Fromherzsheet 1sheet 2sheet 5sheet 3sheet 6start timesheet 7sheet 4sheetddescriptionstiyetplannedplannedplanned,unsentsentprinterFigure 4: Stages life sheet planning system.close enough current wall-clock time send plans printer controllerexecution (sheets 1 2). Note figure, time advances downward plansstarting earlier higher figure. Sheets 1, 2, 3 finish order; sheets 4 5belongs different job scheduled run concurrently.application, additional negotiation step plan issuedplanning system plan committed. First, plan step proposedmachine controller modules involved. individual hardware modulessteps accept proposed actions, plan committed. discuss below,commitment means modules become responsible notifying controller failcomplete action realize able perform planned actionfuture. plan confirmed, planner cannot modify it. thusbenefit releasing plans machine controller start times approach.modules confirm, machine controller notifies planning systemproposed plan rejected, system must produce new plan. negotiationprocess one reason must find complete plan starting execution.module limited number discrete actions perform, transformingsheet known deterministic way. many actions, planner allowedcontrol duration within range spanning three orders magnitude (millisecondsseconds). example, planner may choose transport sheet faster slowermodule order avoid collisions. Actions may split sheet two piecesjoin multiple sheets different paths printer together. means singleprinted sheet must created single blank sheet size, thereby conflatingsheets material allowing plans linear sequence actions. domain,adjacent actions must meet time; sheets cannot left lingering inside printeraction completed must immediately begin transported next location.Sheets grouped print jobs. job ordered set sheets, musteventually arrive destination order submitted.Multiple jobs may production simultaneously, although sheets different420fiOn-line Planning Scheduling Modular Printersjobs allowed interleave single destination, number concurrent jobslimited number destinations (i.e., finisher trays).Currently, Xerox uses constraint-based scheduler control high-end midrange printers (Fromherz et al., 1999). scheduler enumerates possible plansmachine starts stores database. printing requests arrive on-line,scheduler picks first feasible plan database uses temporal constraintprocessing schedule actions. decoupling planning scheduling insufficientcomplex machines two reasons. First, number possible plans largegenerate ahead time, indeed becomes infinite loops present, printershown Figure 2. Second, precompiled plans poor choices given existingsheets system. example, sheets fed different feeders dependingprevious sheets fed, large are, long dwellprint engines (which function sheet thickness material). highperformance, must integrate planning scheduling on-line fashion.Occasionally module break down, failing perform committed action. Modulesalso take off-line intentionally, example perform internal re-calibrationdiagnosis. Modules may added subtracted system informationpassed machine controller planning system right side Figure 3.vision RMP system provide highest possible level productivitysafe, including running long periods degraded capabilities.1 Meetingmandate context highly modular systems means precomputing limited setcanonical plans limiting on-line computation scheduling desirable.large system 200 modules, infeasibly many possible degraded configurationsconsider. Depending capabilities machines, number possible sheetrequests may also make plan precomputation infeasible. Furthermore, even best precomputed plan given sheet may suboptimal given current resource commitmentsprinting machine.summarize, domain finite-state, fully-observable, specifies classical goalsachievement. However, planning on-line additional goals arriving asynchronously.Actions real-valued durations use resources. Plans new goals must respectresource allocations previous plans. Execution failures domain model changesoccur on-line, rare.3. System Overviewcomplete printing system encompasses many components, including print-job submission,print-job management planning, sheet management planning, image renderingdistribution, low-level module control, media handling hardware, exception handling.paper focuses planning issues sheet level, including exception handling.discussing one issue great detail, section provides overviewtopics involve sheet planning directly, including hardware control exceptionhandling.1. example, safety operator, system continue use module whose accesscover opened, even hypothetically possible repair one portion moduleanother use.421fiRuml, Do, Zhou, & FromherzTime Step123456Feed 1 2Print1LoopFinish222212211341252212Figure 5: Two different schedules printing duplex sheet (2) simplex sheet (1):launching sheets order improves throughput.Figure 3 shows basic architecture planning system communicatesmachine controller. overall objective minimize makespancombined global plan sheets, essence optimizing systems throughput.approximate planning one sheet time, objective sheetfinish quickly possible respecting ordering constraints maysheets. Sheets optimally planned individual basis, order arrival, withoutreconsidering plans selected previous sheets. figure, plan manager callsplanner sheet records resulting plan. mitigate restrictivenessgreedy scheme, represent action times using temporal constraints instead absolutetimes. constraints stored simple temporal network (Dechter, Meiri, & Pearl,1991), marked STN figure. maintaining temporal flexibility long possible,shift plans older sheets later time make room starting new sheet earlierimproves overall machine throughput. may sound like rare case,quite common. Figure 5 illustrates how, simplex (single-sided) cover sheet followedduplex (double-sided) sheet, faster overall launch second sheet first.Although basic architecture specifically adapted on-line setting, planner uses domain-dependent search control knowledge. Furthermore, mix goaldecomposable planning cross-goal resource constraints quite common, believeframework useful AI system needs interleave real-time decisionmaking, planning, execution, robot operations.3.1 Planningimplemented temporal planner using architecture adaptedon-line domain. see below, large number potential plans givensheet close interaction plans schedules means muchbetter process scheduling constraints planning process allow focusplanning actions executed soon. planner uses state-space regression,temporal information stored STN. STN records feasible intervaltime point plan. Time points restricted occur specific single timesposted constraints demand it. planner maintains partial ordersdifferent actions plans different sheets STN conducting422fiOn-line Planning Scheduling Modular PrintersOn-linePlanner1. plan next sheet2. unsent plan starts soon,3.foreach plan, oldest imminent one4.clamp time points earliest possible times5.release plan machine controllerPlanSheet6. search queue {final state}7. loop:8.dequeue promising node9.initial state, return10. foreach applicable action11.apply action12.add temporal constraints13.foreach potential resource conflict14.generate orderings conflicting actions15enqueue feasible child nodesFigure 6: Outline hybrid plannerbackward state-space search, seen hybrid state-space searchpartial-order planning. sketch planner given Figure 6. outer loopcorresponds plan manager Figure 3.planning new sheet, outer loop checks queue planned sheets seebegin soon (step 2). imperative recheck queue periodicbasis, soon defined constant amount current timeassume time plan next sheet smaller constant.value constant depends domain specifics communication delaymodule preparation time currently selected manually. assumption violated,interrupt planning next sheet start later. plans releasedexecuted, resource contention decrease, time plan new sheetdecrease well. important new temporal constraints added outer loopplanning individual sheets, propagation affect feasible sheet endtimes thus could invalidate previously computed search node evaluations planningunderway.maintaining partial orderings actions seems necessary mitigateone-sheet-at-a-time greedy strategy, planning individual sheets need necessarilytake form state-space regression. considered forward search strategy,employed many modern planners FF (Hoffmann & Nebel, 2001) LAMA(Richter, Helmert, & Westphal, 2008). Initial investigation preliminary empirical comparisons showed progression planner easier implement easier extendhandle additional domain complexities, performance regression planner (usingheuristic) significantly better many problems domain. seems423fiRuml, Do, Zhou, & Fromherzdue mainly temporal constraint enforcing given sheet endend time previous sheets batch. constraint interacts wellsearching backward goal, immediately constraining end time plan.Together constraint actions must abut time, many possible orderingsresolving resource contention immediately ruled out. example, current sheetcannot transported destination previous sheet batch.addition, orderings may immediately push end time plan even later,informing node evaluation function.planner searches forward direction benefits slightly avoiding logicalstates unreachable initial state. However, without similar temporalconstraint first action plan, resource allocation orderings prunedbranching due resource contention increases direct proportion numberplans previous sheets maintained plan manager. Furthermore, end timeplan rarely changes far planning processes, making heuristic lessuseful. short, first sheet, performance forward backward plannerssimilar, number plans managed plan manager increases, backwardplanner seems perform better.Due details machine controller software, planner must release plansmachine controller order sheet requests submitted.means sheets submitted imminent sheet must released along (step3). stage allowable intervals sheets time points forcibly reducedspecific absolute times (step 4). Sensibly enough, ask point occur exactlyearliest possible time. temporal network uses complete algorithmmaintain allowable window time point (a variation Cervoni, Cesta, & Oddi,1994), guaranteed propagation caused temporal clamping processintroduce inconsistencies. clamping happens plans issued; thusface on-line dispatchability problem Muscettola, Morris, Tsamardinos(1998).current on-line setting, even though plan multiple sheets belongingdifferent jobs, build plans single sheet time. Even many submittedsheets waiting planned, strategy reasonable given sheets arrived sequenceand, arrival last sheet, know many sheets jobplanner receive individual sheet specifications. Waiting sheetsknown impractical many production jobs, billing payroll, involve jobsmany thousands sheets run multiple days.3.2 Controlshown Figure 2, system consists two feeders left, two finishing traysright, four print engines one four quadrants printer.three high-speed sheet highways connect feeders finisher trays.Sheets traveling top bottom highways routed print engineson-ramps off-ramps. increased modularity, highwayson- off-ramps made two types modules: straight-through modulesthree-way modules. module processor: Texas Instruments F2811424fiOn-line Planning Scheduling Modular PrintersFigure 7: control system architecture.DSP. modules run distributed algorithms state estimation controlcommunicate via five controller-area network (CAN) buses, plusdedicated data-logging bus debugging purposes. Modules quadrantprinter reside bus, except four print engines,separate bus. Sheets moved roller actuators, called nips, drivenindependently-controlled stepper motors. sensory feedback, nip equippededge-detection sensor sides nip. three-way module, threesolenoids drive flipper actuators direct sheet along different paths.Figure 7 shows control system architecture, implements hierarchical approach distributed plan execution sheet controller manages modulecontrollers currently, soon be, contact sheet. Thus sheetcontroller group membership dynamic life cycle sheet, startingfeeder way finisher tray. soon new sheet sent machine controller, corresponding sheet controller created resides centralized processor,even though module controllers manages reside locally modules themselves.Note module controller may processing commands multiple sheet controllers,case module controller middle Figure 7. still contactfirst sheet, soon contact second sheet.sheet span multiple modules printer, different nips actingsheet must tightly synchronized order avoid damaging jamming sheet.However, achieving exact synchronization network uncertain communicationdelays stringent bandwidth challenging. Moreover, one must consider limitedcomputation power module design synchronization scheme. example,controller sample time set 2 milliseconds. Thus, anything takes longer 2milliseconds compute within sampling period work. eliminate effectsuncertain network delays, control system uses delay equalizer, buffers sensoryfeedback messages apply time, make sure sensor information usedtime members group module controllers sheet. savebandwidth needed synchronization, controller uses internal models (or estimators)keep track states controllers network order limit need425fiRuml, Do, Zhou, & Fromherzcommunications (Crawford, Hindi, Zhou, & Larner, 2009; Hindi, Crawford, & Fromherz,2005).limited network bandwidth fundamental impact choice control algorithm. Initially, linear-quadratic-gaussian (LQG) (Franklin, Powell, & Workman, 1997)controller used, nice property solution constitutes linear dynamic feedback control law easily computed. However, bandwidth requirementsLQG controller, necessitates dozen way points per sheetsent network, prompted adoption different kind controller basedproximate time optimal servo (PTOS) (Hindi, Crawford, Zhou, & Eldershaw, 2008;Franklin et al., 1997), consumes much less bandwidth. comparison, PTOScontroller reduces number intermediate way points dozen twoper sheet. Since PTOS based time optimal control uses either maximum acceleration deceleration reach target control state, also maximizes temporalflexibility planning actions planner use, thus improving overallthroughput printer.3.3 Previous Workmuch interest last 15 years integration planning scheduling techniques. HSTS (Muscettola, 1994) IxTeT (Ghallab & Laruelle, 1994) examples systems select order actions necessary reach goal, alsospecify precise execution times actions. Visopt ShopFloor system Bartak(2002) uses constraint logic programming approach incorporate aspects planningscheduling. Europa system Frank Jonsson (2003) uses novel representation based attributes intervals. system use domain representationsquite different mainstream PDDL language (Fox & Long, 2003) used planningresearch designed off-line use, rather controlling systemcontinual execution.currently great interest extending planning scheduling techniques handle complexities found real industrial applications. example, PDDLextended handle continuous quantities durative actions. additionaldimensions planning complexity besides expressivity, however. work complementstrend current planning research extend expressiveness focusing middle ground planning scheduling. domain semantics printingcomplex job shop scheduling simpler many ways PDDL2.1. Choiceactions perform important domain, managing resource conflicts equallyimportant. classical scheduling, resource constraints essential printermodules often cannot perform multiple actions once. action selection sequencing also required given sheet usually achieved using several differentsequences actions.domain formalization lies partial-order scheduling temporal PDDL.optimal actions needed fulfill given print-job request may vary depending sheets machine, sequence actions predeterminedclassical scheduling formulations job-shop scheduling resource-constrainedproject scheduling expressive enough. domain clearly subsumes job-shop426fiOn-line Planning Scheduling Modular Printersflow-shop scheduling: precedence constraints encoded unique preconditionseffects. Open shop scheduling, one choose order predetermined setactions job, capture notion alternative sequences actionsthus also limited. positive planning theories Palacios Geffner (2002) allow actions real-valued durations allocate resources, cannot deleteatoms. means cannot capture even simple transformations like movementfundamental domain. fact, optimal plans domain may even involve executing action multiple times, something always unnecessarypurely positive domain. However, numeric effects full durative action generalityPDDL2.1 necessary.on-line nature task unambiguous objective function,additional trade-off domain planning time execution timeabsent much prior work planning scheduling. setting set sheetsrevealed incrementally time, unlike classical temporal planning entireproblem instance available once. contrast much work continual planning(desJardins, Durfee, Ortiz, & Wolverton, 1999), tight constraints domain requireproduce complete plan sheet execution begin. domainemphasizes on-line decision making, received limited attention date.objective complete known print jobs soon possible, taking longsynthesize slightly shorter plan worse quickly finding near-optimal solution.especially true rerouting in-flight sheets exception handling.Although present system temporal planner, fits easily traditionconstraint-based scheduling (Smith & Cheng, 1993; Policella, Cesta, Oddi, & Smith,2007). main difference actions time points resource allocations addedincrementally rather present start search process. centralprocess identifying temporal conflicts, posting constraints resolve them, computingbounds guide search remains same. approach, attempt maintainconflict-free schedule rather allowing contention accumulate carefullychoosing conflicts resolve first. approach perhaps similar spirittaken IxTeT system (Ghallab & Laruelle, 1994).basic approach coordinating separate state-space searches via temporal constraints may well suitable on-line planning domains. planning individualprint jobs managing multiple plans time, strategy similar spiritplanners partition goals subgoals later merge plans individual goals (Wah& Chen, 2003; Koehler & Hoffmann, 2000). framework, even though print jobplanned locally, plan manager along global temporal database ensurestemporal resource inconsistencies step search. wouldinteresting see strategy could used solve partitionable STRIPS planningproblems effectively.4. Nominal Sheet Planningsheet planner builds plan sheet job using combination regressionstate-space planning partial-order scheduling. plans adding one module actiontime, starting finisher sequence actions reaches feeder. Adding427fiRuml, Do, Zhou, & Fromherzaction sheets itinerary (i.e., plan) causes resource allocations maderesources required execution action. Given media path redundanciesRMP, planner usually faces multiple choices action add planningstep. organize search, planner uses best-first A* search planning-graphheuristic, adjusted resource conflicts, estimates promising plan suffixis. Unlike traditional regression planners, maintain maximum flexibility, action timesstart end action resource allocation representedflexible time points instead absolute times. Temporal constraints used representdurations actions resolve resource contention imposing orderings among actions.planner attempts minimize makespan combined global plan sheets,essence optimizing systems throughput. planner uses domain-dependentsearch control knowledge, allowing us use planner run different printingsystems full productivity.4.1 Domain Languageused two-tiered approach represent RMP domain. highest level,use specialized language makes easier Xerox engineers model printers.language specifies printer configurations components connectedother. Basic components different capabilities components groupedhierarchical structure. model files format automatically translatedvariation PDDL2.1, fed planner. automatic translationprocess instantiates primitive modules converts modules capabilitiesdurative actions. movement sheet marking actions directlytranslated printer model traditional logical preconditions effects testmodify attributes sheet. Following spirit compositionality earlier work(Fromherz et al., 1999), model system automatically synthesizedmodels individual components.PDDL, distinguish two types input planner. planningbegins, domain description containing predicate action templates provided.problem descriptions arrive on-line, containing initial goal states, setsliterals describing starting desired configurations. action representationsimilar durative actions PDDL2.1, notable difference useexplicit representation resources. Actions specify exclusive use different typesresources time intervals specified relative actions start end time. Executingone action may involve allocating multiple resources various types as: unit-capacity,multi-capacity, cyclic, state resources. actions also specify real-valued durationbounds. is, one specify upper lower bounds let planner choosedesired duration action. critical modeling controllable-speed paperpaths, useful practice. PDDL allows specification durationranges, aware IPC benchmark general-purpose plannersupports it.summarize, core part domain file set actions, correspondscapability component printer 4-tuple = hPre, Eff, dur, Alloci,where:428fiOn-line Planning Scheduling Modular PrintersPrintSimplexAndInvert(?sheet, ?side, ?color, ?image)preconditions: Location(?sheet, Printer1-Input)Blank(?sheet)SideUp(?sheet,?side)Opposite(?side, ?other-side)CanPrint(MarkingEngine, ?color)effects: Location(?sheet, Printer1-Output)Location(?sheet, Printer1-Input)HasImage(?sheet,?side,?image)Blank(?sheet)SideUp(?sheet, ?side)SideUp(?sheet,?other-side)duration: [13.2 seconds, 15.0 seconds]set-up time: 0.1 secondallocations: MarkingEngine ?start + 5.9 3.7 secondsFigure 8: simple action specification.Pre Eff sets literals representing actions preconditions effects.dur pair hlower, upperi scalars representing upper lower boundsaction duration.Alloc set triplets hres, offset, duri indicating action starting time sauses resource res interval [sa + offset, sa + offset + dur]. constraintsdifferent types resources are:Unit-capacity: type resource non-sharable thus allocationsgiven resource type overlap. provides good modelphysical space common type resource used planner.Cyclic: cyclic resource one special type unit-capacity resourcesrepeated durations resources unavailableactions selected planner. example, unavailable durations mayrepresent routine automatic maintenance modules.Multi-capacity: upper-bound maximum number allocationsgiven resource type overlap. Moreover, allocations followfirst-in-first-out order. Thus, two allocations A1 = [sA1 , eA1 ]A2 = [sA2 , eA2 ] sA1 sA2 implies eA1 eA2 .State resource: resource labeled using one set states. Allocations resource type overlap requireresource state.simple example given Figure 8. Set-up time refers required timeaction committed execution beginscertain actions require extensivepreparation part module sheet arrives action really429fiRuml, Do, Zhou, & Fromherzbackground:initial:goal:print job ID:Sheet-23Location(Sheet-23, Some-Feeder)Blank(Sheet-23)SideUp(Sheet-23,Side 1)Location(Sheet-23, Upper-Finisher)HasImage(Sheet-23, Side 1, Image 1)HasImage(Sheet-23, Side 2, Image 2)Color(Sheet-23, Side 1, Color)Color(Sheet-23, Side 2, Black & White)5Figure 9: sample sheet specification.performed. resource usage, PrintSimplexAndInvert action Figure 8 specifiesexclusive use MarkingEngine 5.9 seconds start action 3.7seconds later. Printer modules multiple independent resources actionsshort allocation durations relative overall action duration work multiplesheets simultaneously. PDDL, arbitrary predicates made hold start,end, duration action. expressivity needed domainthus assume simple semantics similar using TGP planner SmithWeld (1999) which: (1) delete effects happen start; (2) add effects happenend; (3) preconditions deleted start; (4) preconditionsdeleted all. addition sheet-dependent literals, sometimes convenientspecify actions using preconditions refer literals independentparticular goals sought. background knowledge domain suppliedseparately machine specification, although could also compiled actionspecifications. example, possible colors engines put sheet paper(e.g., Black&White, Color, Custom Color) default sides papers (e.g., Front, Back)specified way. represented similarly constant concept PDDL.addition static domain description, on-line sheet requests modeledinitial goal state pairs describing starting desired sheet configurations.new initial/goal pair defines new object (the sheet) associated literalsplanner track. Specifically, problem description particular sheet 4-tuplehJob, Initial, Goal, Backgroundi, Job id print job sheet belongsInitial, Goal, Background sets literals.simple example sheet specification given Figure 9. example, Some-Feedervirtual location sheet sources placed Upper-Finisher one particularfinisher sheets belong print job 5 need routed to. terms Figure 3,feeder location literal added goal plan manager, maintainstable active jobs finisher assigned each. Finisher assignment handledextracting finisher selected planner plan first sheet job.finishing requires actions plan actions never reconsidered (onlyrescheduled), planner never reconsider jobs finisher assignment, even hasntbegun production yet.430fiOn-line Planning Scheduling Modular PrintersGiven domain description (top left Figure 3) low-level delay constant tdelaycapturing latency machine controller software, planner accepts streamsheets arriving asynchronously time. Note sheets may belong different printjobs printed parallel; within print job, sheets need routedfinisher (among multiple finishers) finish order. stream correspondsstandard notion PDDL problem instance. sheet, planner must eventuallyreturn plan: sequence actions labeled start times (in absolute wall clock time)transform initial state goal state. allocations madeunit-capacity resource multiple actions must overlap time (state multi-capacityresources different constraints described earlier). Happily, plans individual sheetsindependent except interactions resources. Additional constraintsplanner include:plans sheets print job id must finish destination,plans sheets print job id must finish orderjobs submitted,first action plan must begin sooner tdelay seconds issuedplanner (with tdelay represents delays communication negotiationprinter module controller),subsequent actions must begin times obey duration constraints specifiedprevious action (thus assumed previous action endsnext action starts).4.2 Temporal ReasoningPrinter control rich temporal domain real-time constraints: (i) wall-clocktime plans individual sheets, (2) plans different sheets, (3) planner machine controller. Thus, fast temporal constraint propagation,consistency checking, querying extremely important planner. maintaintemporal constraints using Simple Temporal Network (STN) (Dechter et al., 1991),represented box named STN Figure 3. Essentially, network contains settemporal time points ti constraints form lb ti tj ub .time points managed STN include action start end times resource allocationstart end times. Temporal constraints maintained STN are:constraints wall-clock action start time;action start end times within action duration range;constraints action start time resource allocation action;conflicts various types resources.use A* search strategy maintains multiple open search nodes,separate STN node. Temporal constraints added appropriate STNsearch node expanded. Whenever new constraint added, propagation tightens431fiRuml, Do, Zhou, & FromherzPlanning Time (in seconds)IDPCAC-342020406080100Sheet NumberFigure 10: Simple arc consistency faster incremental directed path consistencymaintaining STNs.upper lower bounds domain affected time point. leadmemory usage extra overhead, allows us deal temporalconstraint retraction, needed single STN used multiple search nodes.Retracting temporal constraints STN complicated time consuming process.planner must run indefinitely, perform garbage collection time pointsSTN sheet planning episodes, harvesting lie past.time points flexible plans belong sent machinecontroller. planning new sheet, plan manager checks queue plannedsheets see could begin soon. are, plans releasedmachine controller execute. New temporal constraints added freezestart end times actions belonging plans sent controller. time pointsfrozen earliest possible wall-clock time indicated STN basedconstraint set. constraints cause significant propagation turn (1) freezestart end times resource allocations related actions frozen plans;(2) tighten starting times actions remaining plans.original representation STN complete matrix time relations updatedall-pairs shortest paths (Dechter et al., 1991) much inefficient purposes.implemented two versions STN. One uses incremental directed pathconsistency (IDPC) algorithm (Chleq, 1995), may change values edgesconstraint graph well introduce new edges requires linear time findminimum maximum interval two time points database.uses arc consistency (Cervoni et al., 1994) maintains point minimum432fiOn-line Planning Scheduling Modular Printersmaximum times t0 , reference time point. latter method, one cannoteasily obtain exact relations arbitrary time points, relations t0 .However, long inconsistency efficiently detected constraints added,need query relations arbitrary pairs points, efficiency gainswelcome. New arcs never added network propagation existingones modified, means copying network new search nodeentail copying arcs. Figure 10 attests, results dramatic timesavings technique used current implementation. improvedimplementation (1) using change flags facilitate faster cycle detection temporalconsistency checking (2) converting times durations integer values (with userdefined precision) eliminate rounding effects increase speed.4.3 Planning Sheetplanning individual sheets, regressed state representation contains statesheet, may partially specified. A* search used find optimal plancurrent sheet, context previous sheets. optimal plansheet found, resource allocations STN used plan passed backplan manager become basis planning next sheet.One unusual feature planning approach seamlessly integrate planningscheduling. Starting times actions fixed merely constrained temporalordering constraints STN. insist potential overlaps allocationsresource resolved immediately, resulting potentially multiple childrensingle action choice. allows temporal propagation update action time boundsguide plan search. plan single sheet totally-ordered sequenceactions, partial orders actions belong plans different sheetsrepresent resource conflict resolutions.4.3.1 State Representationplan must feasible context previous plans, state containsinformation current sheet previous plans. specifically, state3-tuple hLiterals, Tdb, Rsrcsi which:Literals describes regressed logical state current sheet. distinguishliterals whose status true, false, unknown (Le, Baral, Zhang, & Tran, 2004).distinction false unknown literals important domain may fine-grained restrictions acceptable values unspecifiedattributes sheet. example, sheet first given print job,finisher representing final location sheet unknownfinisher allocated another print job plan sheetexecuted. discuss below, allow regression match unknown literalstrue false effects actions; sense unknown function like dontcare. implementation, represent explicitly literals currentlytrue whose value unknown, false literals represented implicitly.433fiRuml, Do, Zhou, & FromherzTdb temporal database represented simple temporal network (STN) containingknown time points current constraints them. includes constraints different plans, actions plan, wellwall-clock time. Examples time points include start/end times actionsresource allocations. soon plan given sheet sent machine(sheets 1 2 Figure 4), time points associated plan Tdblonger allowed float clamped lower bounds. time pointsflexible.Rsrcs set current resource allocations, representing commitments madeplans previous sheets partial plan current sheet. resourceallocation form hres, tp , tp res particular resource tp1 , tp2two time points Tdb representing duration res allocated action.Note multiple resources domain resourcemultiple (overlapping non-overlapping depending resource type) resourceallocations. implementation, maintain ordered list allocationsresource, recent oldest.essence, state contains information reflecting strategy planner: hybrid state-space sequential temporal regression search partial order scheduling.Literals action start end time-points represent temporal-planning regressedstate Rsrcs temporal orderings competing resource allocations represent partial-order scheduling constraints actions plans different sheets.4.3.2 Branching Applicable Actionsregressed logical state planner 3-tuple L = hLt , Lf , Lu Lt , Lf ,Lu disjoint sets literals true, false, unknown, respectively. Pre+ (a)Pre (a) sets positive negative preconditions Add(a) Del(a)sets positive negative effects action a, regression rules useddetermine action applicability update state literals are:Applicability Action applicable literal set L (1) none effects inconsistent L (2) preconditions modified effectsconsistent L. formally, (1) (Add(a) Lf = ) (Del(a) Lt = ), (2)(Pre+ (a) Lf Del(a)) (Pre (a) Lt Add(a)).many planning settings, additional criterion applicability added withTdestroying completeness: least one effect must match L ((Add(a) Lt 6=) (Del(a) Lf 6= )). necessarily valid setting addingno-op action may give time existing resource allocation run out,enabling actions used might lead shorter plan.Update regression L = hLt , Lf , Lu applicable action derived undoing effects unioning result preconditions. given literall modified effect a, status unknown regressed state unlessalso specified corresponding precondition (e.g., l precondition a).434fiOn-line Planning Scheduling Modular Printersformally, (1) Lt = (Lt \ Add(a)) Pre+ (a); (2) Lf = (Lf \ Del(a))3) Lu = (Lu (Add(a) Del(a))) \ (Pre+ (a) Pre (a))Pre (A);Given |Lf | usually much larger |Lt | |Lu | domain, explicitly storeLt Lu current implementation use closed-world assumption implyliterals belong Lf . modeling translator provide Xerox engineersmodeling printers encourages effects mentioned preconditions, reducinggrowth number unknown literals. example, x Add(a) x P (a).Although usually case domain, note goalstate always fully specified (with unknown literals) every actions effectscorresponding preconditions, regressed states would fully specified. One couldsimplify logical state representation L = hLt , Lf simplify regression rulesApplicability Action applicable iff effects match L: Add(a) LtDel(a) Lf .Update Regressing hLt , Lf gives h(Lt \Add(a))Del(A), (Lf \Del(a))Add(a)iplan considered complete literals unify desired initial state (step 9Figure 6). optimal plan sheet found, temporal database usedplan passed back outer loop Figure 6 becomes basis planningnext sheet. feasible windows maintained around time points planplan released machine controller, subsequent plans allowed makeearlier allocations resources push actions earlier plans later.ordering leads earlier end time newer goal, selected. providesway complex job j2 submitted simple job j1 start executionprinter earlier j1 . order starts allowed long sheets printjob finish correct order. often provide important productivity gains.4.3.3 Branching Resource Allocation Orderingsfirst step creating regressed states branch actions applicableL, applying candidate action fact result multiple child nodes dueresource contention. scheduling algorithms use complex reasoning disjunctiveconstraints avoid premature branching ordering decisions might well resolvedpropagation (Baptiste & Pape, 1995). take different approach, insistingpotential overlaps allocations resource resolved immediately. Temporalconstraints posted order potentially overlapping allocations changespropagate action times. many action durations relatively rigid typicalprinters, aggressive commitment propagate cause changes potential endtimes plan, immediately helping guide search process. multiple orderingsmay possible, may many resulting child search nodes.example, Figure 4, assume current candidate action searchingplan sheet 5 uses resource r duration [s, e]. also assumen actions plans sheets 14 also use r, implying n existingnon-overlapping resource allocations [s1 , e1 ]....[sn , en ] corresponding time pointstemporal database. trying allocate r a, one obvious consistent choice435fiRuml, Do, Zhou, & Fromherzend timenew planearlieststart timenext actioplanningstart timeestimated lengthplan come(PG + Res. Conflict)predictedplanningtimeend timeprev. planjobend timeplanslengthplan fart1t2t3t4STN: plan starting time constraintt5t6t7STN: sheet ordering constraintBranching actions, resource conflicts +STN: resource contention constraintsFigure 11: Important time points constructing evaluating plan.putting previous allocations adding temporal constraint en s.However, also gaps existing allocations [si , ei ], allowing us postconstraints ei e si+1 . possible allocation r generatesdistinct child node search space. action use several different resourcesr, number branches potentially quite large. However, immediately resolvingpotential overlaps allocations resource avoids introduction disjunctionstemporal network, maintaining tractability temporal constraint propagation.summary, every branch planners search space, modify logical statebranching relevant actions potentially introduce different temporal constraintsorder resolve resource contention. branch results different irrevocablechoice reflected final plan, state node planners search treeunique. Therefore, need consider problem duplicating search effortdue reaching state two different search paths.4.3.4 Heuristic Estimationpotential plan suffix, lower bound computed remaining makespan,order guide planners A* search. Figure 11 illustrates heuristic estimateused. figure, planning start time (t1 ) refers wall-clock timeplanning process started earliest-start-time = current wall-clock time + predicted planning time (t2 ) estimated time find plan current sheetthus earliest time action scheduled begin. Note practice,machine controller communication negotiation time also added predictedplanning time. hypothetical start time plan found (t3 ) constrainedhappen earliest possible wall-clock plan execution time (t2 t3 ). plan constrained end previous sheets print job (t5 t6 ),necessarily constrained start plans previous sheets. start timenext action added regressed partial plan (t4 ) constrained occur least436fiOn-line Planning Scheduling Modular Printershypothetical plan starting time (t3 + t4 ) heuristic valuemakespan remaining plan complete current regressed partial-plan.overall objective minimize earliest possible end time plans, includingsheet planning for. indicated lower-bound floatingtime point t7 Figure 11. time point constrained end time pointssheets planned one currently planned. currentsheet, represented constraints t6 t7 shown Figure 11. t6constrained end completion time planned sheetsprint job, constraint essentially pushes t7 sheets current printjob end. support objective function, primary criterion evaluating promisepartial plan (step 8 Figure 6) estimate earliest possible happening timet7 , indicated STN embedded search node, constraints shownFigure 11 added current branch.key duration affects t7 heuristic estimate lower boundadditional makespan required complete current regressed plan. heuristic valueindicated Figure 11 estimated remaining makespan t3 t4 . addingconstraint t2 t3 , insertion may thus change earliest time subsequent timepoints t4 , t5 , t6 t7 . may also introduce inconsistency temporal database,case safely abandon plan. Given current plan endend time previous sheets print job (t5 t6 ), objective functionminimize t7 without causing inconsistency temporal database. break tiesfavor of:smaller t6 (e.g., end time current print job)smaller predicted makespan (t6 t3 )larger currently realized makespan (t6 t4 ). analogous breaking tiesf (n) A* search larger g(n), thus encourages extension plansnearer goal.performance search-based planner heavily depends qualityheuristic estimating makespan-to-go. estimate building temporal planninggraph adjustment logical mutex resource contentions. restsection, discuss details computed. Overall, want effectiveplanning heuristic is:Admissible: maintaining high plan quality (high productivity printer)important criterion customer.Informed easy compute: cases, allowed fractionsecond find feasible plan. delay finding plan delay plan startexecution time thus reduce overall productivity.derive admissible estimate duration required achieve given set goalsG initial state, perform dynamic programming explicit representationbi-level temporal planning graph, described TGP system (Smith& Weld, 1999). TGP, planning graph represented fact level action437fiRuml, Do, Zhou, & Fromherzlevel. Starting initial state time = 0, graph grown forward timeactions activated preconditions satisfied non-mutex.three types mutual exclusion relations (fact-fact, fact-action, action-action)propagated graph building process. graph expansion phase alternatesplan extraction phase starting time point goals appear nonmutex graph.graph expansion algorithm, action fact f , store first timesta tf optimistically occur f optimistically achieved.correspond first times f appear temporal planning graph.mutex propagation, also store first time point pair facts hf1 , f2achieved together pair actions ha1 , a2 execute together. planninggraph, first time points hf1 , f2 ha1 , a2 become non-mutex.implementation, fact-action mutex fact f action converted actionmutex hnoopf , ai, discuss later.1. begin: f, a, f1 , f2 , a1 , a2 : ta = tf = thf1 ,f2 = tha1 ,a2 = .2. Let initial state: f, f1 , f2 : tf = 0, thf1 ,f2 = 0.3. Dynamically update values ta , tf , thf1 ,f2 , tha1 ,a2 starting initial statetime = 0 follows:ta = max (setup time(a),maxf P rec(a)tf ,maxf1 ,f2 P rec(a)thf1 ,f2 )tf = min (ta + dur(a))(2)f Eff(a)thf1 ,f2 = min (tha1 ,a2 +max(dur(a1 ), dur(a2 )))f1 Eff(a1 ),f2 Eff(a2 )tha1 ,a2 = max (ta1 , ta2 ,maxf1 P rec(a1 ),f2 P rec(a2 )(1)thf1 ,f2 )(3)(4)updates done increasing order time, usual planning-graphbuilding algorithms.4. Stop g G : tg < g1 , g2 G : thg1 ,g2i < reach fixed point.equations (1)-(4) shown above, actions include noop actionsnormal planning graph. actions start time point fact firstachieved. mutex relation noop action equivalent fact-actionmutex described Smith Weld (1999). overall plan sheetshighly parallel, plan single sheet sequential. Therefore, currently useserial version temporal planning graph, also faster build consumesless memory. version, two non-noop actions always mutex other.Therefore, need store reason action mutexes thus valuetha1 ,a2 eq.(4) applicable mutexes noop real action.438fiOn-line Planning Scheduling Modular Printersimplementation, build graph starting = 0 putting events (1) activatingaction (updating ta ); (2) activating fact (updating tf ); (3) removing fact mutex(updating thf1 ,f2 ), ordered time occur. event trigger new eventshappen later time. example, adding new fact f removing fact mutex hf1 , f2activate actions supported f f1 f2 , activating action addevents activating facts Effect(a) and/or removing fact mutexes Effect(a)noop (facts) mutex P recond(a). also explicitly store factfact mutex timing values thf1 ,f2 none action mutexes tha1 ,a2 , instead reasoningon-the-fly.time goals achieved pair-wise non-mutex heuristic valueestimating remaining makespan achieve goal state (see Figure 11).regression planners (Haslum & Geffner, 2001; Nguyen, Kambhampati, & Nigenda, 2002)compute heuristic (until fixed point reached) planning processbegins, case, planning graph expansion process may revisited goals representing regressed state appear non-mutex graph fixed pointreached previous round expansion. pair-wise mutexes takenaccount building graph, estimated value underestimate makespanplan achieve goal. Therefore, returned value planning graphlead underestimate (admissible heuristic) objective function (overallend time t7 ) tie breakers (current sheet end time t6 current estimated makespant6 t3 ) described above. Therefore, using estimate, planner return plan poptimal end time (minimum t7 ) p also minimum makespan amongplans end time.Incorporating resource mutexes planning graph discussed assumesprinter empty. Thus, create planning graph similar procedureused off-line planner assume interference relations occuractions related given sheet planning for. machine empty,heuristic generally correct simple sheets simplex printing nearly correctcomplicated sheets duplex printing.However, time, printer empty plans sheetseither (1) executing; (2) found planner havent sent machinecontroller yet. plans involve resource allocations, either fixed time points (for (1))still flexible ones (for (2)). find effective heuristic scenariosmachine busy, take account resource mutexes, thus incorporating schedulingresource contention constraints temporal planning graph. Figure 12 showspseudo-code algorithm. key observation that, find earliest time taaction possibly execute, necessary conditionpreconditions appear non-mutex planning graph also resourceconflict resource r used current allocations r (given previousplans external processes.)shown example action description Figure 8, resource allocationaction represented triple hr, o, di. starts sa , means resourcer used sa + duration d, normally different durationda a. example, lone resource usage action PrintSimplexAndInvert Fig439fiRuml, Do, Zhou, & Fromherz1. Resource types: r1 , r2 , ....rn2. resource allocations: {R1 , R2 , ....Rn }Ri = {[si1 , ei1 ], [si2 , ei2 ], ...[sim , eim ]} ordered list allocations riFunction CheckEarliest(r, t, d)3.r: resource4.t: earliest time intend use r5.d: duration intend use r6.R = {[s1 , e1 ], [s2 , e2 ], ...[sm , em ]}: current allocations r.7.tmin : earliest time non-conflict allocation r; initialize to: tmin8.allocation l = [sk , ek ] R check9.reserve r duration l starts: Latest(sk ) > tmin +10.go line 1411.else move forward next possible opening end allocation12.tmin Earliest(ek )13. end for;14. return(tmin )end function;Building temporal planning graph15. consider adding action planning graph16. Initialize ta earliest time P rec(a) achieved non-mutex (eq.1)17. Resource allocations a: Ra = {hr1 , o1 , d1 i, hr2 , o2 , d2 i, ..., hrn , , dn i}18. allocation l = hrk , ok , dk check earliest non-conflict time l19.ta CheckEarliest(ri , ta + oi , di ) oi20. end for;21. add action temporal planning graph tagoals appear non pairwise mutex;Figure 12: Building temporal planning graph adjustments resource conflicts.ure 8 (M arkingEngine, 5.9, 3.7). Lines 17-19 Figure 12 show buildinggraph, action preconditions satisfied ta , algorithm goesresources used a. resource allocation hr, o, di, calls functionCheckEarliest(r, ta +o, d) update ta , earliest executable time start withoutoverlapping previous resource allocations r. pseudo-code functionCheckEarliest(r, t, d) self-explanatory try find earliest time pointslot allocation r duration without overlappingprevious allocations r.Figure 13 shows one example demonstrate algorithm. example, tryfind starting time action a, needs two unit-capacity resource allocationshr1 , o1 , d1 hr2 , o2 , d2 shown top-left corner. Assume buildinggraph, preconditions first achieved non-mutex time t1 . ReferringFigure 13, fixed allocations r1 allocations (1), (2), and(3) r2 (1)440fiOn-line Planning Scheduling Modular PrinterssAA:r1dAo1d1r2o2(1)r1eAd2(2)(3)(1)r2t3d2o2o1t2(4)(3)(2)d1t1(4)t4t5Figure 13: Example action starting time adjustment using resource contentions(2). flexible allocations, shown upper/lower bound constraints (4) r1(3) (4) r2 . Starting t1 , first time point allocate r1duration d1 without overlapping previous allocations, fixed flexible, t3 .Thus, adjust new earliest possible starting time t2 = t3 o1 t1 . Givennew earliest possible starting time ta = t2 , find earliest time point t2allocate resource r2 t5 . Given t4 = t5 o2 t2 , taket4 final earliest starting time activate action t4 graph (insteadoriginal value t1 )2 .resource mutexes, starting times actions adjusted higher timepoints preconditions achieved, thus time point tGgoals appear non-mutex graph underestimation makespanremaining plan (value t4 t3 Figure 11). Thus, tG higher summationdurations actions optimal (serial) plan. However, tG still underestimatesfirst time achieve goals thus still admissible heuristicmain objective function minimizing end time current printing sheets (minimizingt7 Figure 11). However, use resource mutexes, heuristicestimate end time (t7 ) tie-breaker plan makespan (t6 t3 ) admissibleresource mutexes, estimate t7 admissible tie-breaker t6 t32. Note go resource allocations given action one time (lines 18-20 Figure 12).Therefore, even action Figure 13 added t4 , still potential conflict resourcer1 consumed (with existing allocation (3) r1 ). However, repeating procedure(lines 18-20 Figure 12) multiple times fixed point reached (and potentially returning betterheuristic estimate), seek balance heuristic quality heuristic computation time.441fiRuml, Do, Zhou, & Fromherztime (sec)2no-mutexlogical mutexlog + res mutexproductivity level1.510.50147 10 13 16 19 22 25 28 31 34 37 40 43 46 49Figure 14: Performance prototype built industrial partner.inadmissible. Thus, A* algorithm still guaranteed find optimal solution,minimizing plan end-time, final solution guaranteed shortestduration among plans finish earliest.4.4 Evaluation Nominal Planningcollaboration Xerox, deployed planner control three physical prototype multi-engine printers. deployments successful planneralso used simulation control hundreds hypothetical printer configurations.planner written Objective Caml, dialect ML, communicates jobsubmitter machine controller using ASCII text sockets. planner alsocommunicate plan visualizer graphically display plans. first two videoson-line appendix show planner controlling prototype depicted Figures 12 full productivity, using visualizer (video 1, nominal simulation)hardware (video 2, nominal hardware). full description videos foundtextual appendix paper. shortest single plan machine 25 actions.Given many sheets printer given time plannerplan ahead, plan manager consistently manages dozens plans hundreds actions. planning, planner needs temporal reasoning regarding conflictactions current plans hundreds actions previous plans. Even so,planner consistently average produces plans within 0.27 seconds required keepprinter running full productivity (220 pages/minute). one complexcurrent Xerox commercial products, planner regularly find optimal plan within0.01 seconds plan ahead hundreds sheets. ability use domain-independentplanning techniques allows us use planner different configurations, without needing hand-tuned control rules. rest section, elaborateresults.442fiOn-line Planning Scheduling Modular Printerstime (sec)10nomutexlogical mutexlog + res mutexproductivity level11611162126313641460.10.01jobsFigure 15: Performance current prototype built us shown Figure 1. Notetime plotted logarithmically.Figure 14 15 show performance planner two complexparallel printer prototypes built Xerox us. productivity levels higherprinter class currently market. figure, showCPU time consumed per-sheet basic test using planner print job50 sheets: (1) without mutexes; (2) serial temporal planning graph mutexes;(3) combination logical resource mutexes; (4) baseline requirementplanners performance match printers full productivity. prototypesinvestigated using planner either simpler complicated used theoretical investigations only. rest section, refer first printer(results shown Figure 14) Configuration 1 (results shown Figure 15)Configuration 2.Configuration 1 printer Figure 14 simpler one, 25 main components(including four print engines), 35 action schemata, nominal productivity 170 sheetsper minute, leading timing requirement planner around 60/170 = 0.353 secplanning sheet. shortest possible plan simplest simplex sheet contains 8actions. normally 10 sheets flight time thus plannerneeds handle interaction around 100 actions. However, planner typicallyintended plan many sheets ahead number interactions often much higher.printer built run industrial partner. figure, show withoutmutex, planner starts taking base time 0.353 second around sheet 20consistently takes higher limit around sheet 40. However, logicalresource mutexes, planner consistently returns plans within much shorter timerequired. average, planner logical mutex takes average 0.0732 secondfind plan combination logical resource mutex helps reduce averageplanning time 0.0458 second (1.6x improvement). Without mutexes, planner takesaverage 0.4191 seconds keep full productivity printer.443fiRuml, Do, Zhou, & FromherzConfiguration 2 printer tested Figure 15 complicated one.212 action schemata shortest possible plan contains 16 actions. printergenerally handles 20 sheets time planner needs regularly reasoninteractions 300-400 actions. productivity levelprinter 220 pages-per-minute, leads base running time planner60/220 = 0.27 second planning single sheet. wider gap performancedifferent versions planners, show timing results printer log scale.Without using mutexes, planner quickly overruns time limit sheetsgrows 10 seconds around sheet 35, stopped experiment.mutexes (logical, resource) planner generally takes less 0.3 second find plan.However, occasionally planner takes longer. usually plans ahead around10 sheets releasing plans lower level controller, occasional jumps planningtime dont prevent planner achieving full productivity printer practice.planner averages 0.1336 second logical mutexes 0.0928 second (1.44ximprovement) used conjunction resource mutexes.results Figure 14 15 indicate average planning time individualsheets increases number previous sheets. due fact plannergenerally plans faster speed printer print. Thus, numberprint requests received increases, number plans unsent queue (i.e., plannedfor, sent machine yet) increases. increases resource contentionbranching factor searching new plan, leads increment planningtime. Eventually, number lookahead sheets reaches point planning timeequals planners productivity dynamic equilibrium reached. planning timestrictly increase linearly accordance number sheets planned,rather shows oscillating pattern. due complex interactionon-line processes planning, freezing time points found plan, plan execution.lead easier planning problems sheets, dependingsheets interact sheet currently planned.noted Smith Weld (1999) work based buildingplanning graph mutex propagation costly, experience. fact,printer rather empty, total planning time, subsumes graphmutex building time less 0.01 second. believe due simpler mutexpropagation rule planner fact sequential plan sheet makesactions mutex step. resource mutex reasoning time optimizedlogical mutex implementation improved, seem significantimpediment intended application.results presented indicate optimal-per-sheet strategy seemsefficient enough, work needed assess drop quality would experienced greedy strategy, always placing current sheets resourceallocations previous sheet. Similarly, lull sheet submissions,might beneficial plan multiple sheets together, backtracking possibleplans first order find overall faster plan pair together. Sheetsplanned whose plans released printer represent opportunitiesreconsideration light newer sheets submitted recently.444fiOn-line Planning Scheduling Modular Printers#123456789101112131415LPGSpanTime9.30.0113.30.0226.60.0815.20.0721.30.1222.40.2330.38.7319.652.5524.216.6923.020.0229.740.1418.3 138.5342.629.0934.9 427.4135.318.95SGPlanSpanTime8.30.459.3 308.46-HybridSpanTime8.3 < 0.0019.4 < 0.0019.90.0210.60.0211.10.0311.80.0312.30.0413.00.0613.50.0714.20.0714.70.0815.40.0915.90.1816.60.2117.10.28Table 1: Comparison LPG, SGPlan, hybrid planner, showing makespanplans found (Span) planning times (Time) seconds problemsvarious numbers sheets (#).4.4.1 Scaling Generic PlannersAlthough planner certain features, controllable action durations,beyond capabilities existing planners, still interesting compare offline systems validate new approach. existing generic systems could solve basicprinting control problems well, might possible extend them, rather developingspecialized planner architecture described above. Therefore, built toolautomatically convert custom domain language PDDL2.1 temporal planninglanguage, allowing us test current state-of-the-art planners.domain must simplified fit limitations PDDL, observeeven simplified problems easy solve state-of-the-art academic plannersSGPlan (Chen, Hsu, & Wah, 2006) LPG (Gerevini, Saetti, & Serina, 2003),winners 2004 2006 International Planning Competitions. Since plannerscannot solve problem Configuration 2 machine Figure 2, testedmuch simpler Configuration 1 machine. tested monochrome job15 simplex sheets, already stretched limits LPG SGPlan. plannerplan ahead hundreds sheets machine. seen Table 1, SGPlantook 5 minutes find two-sheet plan took planner less0.001 second find. Compared SGPlan, LPG much faster, although qualityplan LPG finds much worse. average, LPG returns plans 86% longer makespan400 times slower planner. objective function minimizingwall-clock finishing time (which combines planning time plan makespan), planner1000x better planners small printer configuration.445fiRuml, Do, Zhou, & Fromherzaddition faster, hybrid planner also predictable. LPGs planningtime much higher variance sometimes takes longer plan smaller jobbigger one. example, took LPG 22 times longer plan 14-sheet jobTable 1 15-sheet job. makes unsuitable real-time on-lineplanning, depends accurate estimation planning times efficient temporalevent management.4.4.2 2008 International Planning Competitionversion printing domain used 6th International Planning Competition(IPC6), held 2008 results presented ICAPS-08 conference.allowed us evaluate planner many state-of-the-art systems. deterministicpart competition three tracks:1. sequential objective function minimizing total cost actions plan2. temporal objective function minimizing plan makespan.3. net benefit objective function minimizing trade-off total goalutility action cost.three tracks, emphasis finding good solution quality. Thus, plannerrunning time part overall scoring metric. Specifically, planner given30 minutes run particular planning instance. cost plan returned withintime limit used calculate score particular planner particularinstance. score given instance cost best known solution / cost generatedplan, cost generating plan infinite. total 30 instancesdomain thus maximum score competitor achieve 30 (if solutionsreturned best quality among competitors, equal best known solutiongenerated specialized solver).Real-world planners often demonstrated complex domains spacecraftmobile robot control difficult simulate thus make awkward benchmarks.popular temporal planning benchmark domains off-line senseplanners speed affect solution quality. remains need simple yetrealistic benchmark domain combines elements planning scheduling, especiallyon-line setting. step toward bridging gap, organizers IPC6 electeduse PARC printer domain two tracks: sequential temporal. temporal tracknatural fit due default objective function maximizing printersproductivity, equals minimizing makespan plan finishing print-jobrequests. sequential track, minimizing total printing cost used. actioncertain cost value using expensive color print engine print black&whitepage costs using monochrome print engine. However, cost trade-off mayclear-cut feeder, blank sheets originally reside, closer colorprint engine monochrome engine.Even though internal representation planner, used startingpoint competition domain description, far PDDL representation,difficulties creating competition domain file problem set.446fiOn-line Planning Scheduling Modular PrintersC318.00DAE114.45DAE25.80DTGPlan16.44F Fah16.00hF Fsa23.00LAMA20.93PlanA0.00SGP 624.39Upwards26.91baseline26.53Table 2: Scores IPC6 Sequential Satisficing Trackon-line continual nature domain fact constraintsmultiple resource allocations action sequential finishing order sheetsjob caused blowup problem size using pure PDDL, organizersto: 1) remove approximate certain constraints original domain; 2) modelless complex machines. Overall, three different printers modeled. first onesimpler four-engine (two color two mono) Configuration 1 machine describedSection 4.4. second one stripped version using half (one colorone mono) first printer. third one another variation one monoone color printer. first two printers rather symmetric design third oneasymmetric. three significantly simpler fixture built PARC. helpedIPC organizers model actions accurately possible, thus even thoughprinter configurations hypothetical, reflect characteristics real hardware.problem files, reduce complexity, print requests single jobmultiple sheets used. sheets randomly set either simplex (one-sided print)duplex (two-sided print) image also randomly selected either monocolor. number sheets varies 1 20. Given print-job request particularprinter configuration, competing planner needed find plan lowest total printingcost sequential track (matching effectively image requirement printengine capabilities) smallest makespan temporal track (synchronizing effectivelydifferent print engines). actual competition, problems ranging1-10 sheets used three modeled printers simplex sheetsused biggest printer (4-engine version) make problems difficultmajority participants.problems used two tracks (more details below), used plannerdescribed paper provide best known solutions score competing planners.temporal planning track, ran planner default objective functionmaximizing machines productivity. sequential track, ran plannerobjective function minimizing printing cost, described later Section 6.1. Givenplan representation different planner standard format usedIPC, post-processing step needed convert one format another. Noteplans returned planner, temporal buffers related timepoints, inter-sheet gaps. post-processing step remove smalltemporal buffers, needed PDDL plans valid. Therefore, competingtemporal planners could theoretically return shorter makespans planner. However,results described show planner still superior competingplanners terms plan quality. organizers officially reveal plan runningtime unofficial results showed planner also much faster competingplanners solving problems.Tables 2, 3, 4 show IPC results three sub-tracks PARC printerdomain used: sequential satisficing, sequential optimal, temporal satisficing.447fiRuml, Do, Zhou, & FromherzCFDP3CO-Plan5CPT317Gamer0HSP014HSPF16MIPS-XXL7PlanA0Upwards0baseline10Table 3: Scores IPC6 Sequential Optimal TrackCPT317.38DAE111.93DAE26.81SGPlan 611.04TFD5.67TLP-GP1.73baseline13.87Table 4: Scores IPC6 Temporal Satisficing Trackplanners score would 30 tracks given used provide best knownsolutions tracks. baseline planner sequential optimizing track basedblind search optimal cost, sequential satisficing track FF planner,temporal satisficing Metric-FF planner followed greedy scheduler.sequential satisficing planners performed well, mostly due fact problemssequential tracks easy solve, competitors perform welltracks. reason sequential optimal planners perform well couldsolve many problems among 30 selected. temporal satisficing tracks,planners could solve large number instances, quality plans returnedplans high, thus leading low overall scores. short, results2008 International Planning Competition reinforced early study indicating genericoff-line planners competitive on-line hybrid system application.Together, provide evidence demands setting warrant specializedapproach.5. Exception Handlingmaintaining high productivity, thus high return investment,common important objective, means thing equipment ownerscare about. reduce need operator oversight expertise allow usecomplex mechanisms, system must autonomic possible. operatorsmake mistakes even highly-engineered system modules fail, system mustcope execution failure. crucial part RMP value proposition.example, imagine printer copier never seems jam, runs little slowermonth goes on. month, someone opens covers, removes jammedsheets, system back full productivity. RMP systems plannerused control designed fulfill vision partial productivity subsetmodules down. make transition transparent user (and thus increaseperceived reliability system), concentrating developing exceptionhandling techniques minimize user interventions without stopping slowingmachine. Current products perform exception handling using rules hard-codedmachine module. technique works well simple straight-line systems, wouldlimited small predefined subset failures complex topologies. modularRMP systems, astronomical number different printer configurationsfailure possibilities, require general exception handling approach.448fiOn-line Planning Scheduling Modular Printersaddition, system must work legacy modules order commercially viable, architecture must tolerate components direct controlgive rise unexpected events. handle several different exception typesplan rejection (by machine controller), model updates (i.e., modules capabilities gooff-line), sheet jams.Since plans system tightly interact various scheduling temporalconstraints, whether belong print job, exception affectingsingle plan affect executability plans final job integrity. Plansdifferent stages life cycle need analyzed treated differently (see Figure 16).Simple exceptions plan rejection model updates handled discardingrecently made plans rolling back state planner sheetsplanned. implementation uses non-destructive data structures make efficient.Execution failures sheet jams require elaborate handling. unsent planscanceled, need new plans sheets already in-flight timeexception occurs. replanning reuse much nominal planning system,requires special modifications discuss detail below. section, firstprovide overview various types exceptions handle planmanager reacts them; concentrate hardest part exception handlingframework: finding new set consistent plans in-flight sheets.5.1 Related Workseveral previously-proposed frameworks handling exceptions uncertaintyplan execution. Markov decision processes (Boutilier, Dean, & Hanks, 1999) contingency planning (Pryor & Collins, 1996) build plans policies robust uncertain environment. Planners built techniques normally slow, especially real-timedynamic environment complex temporal constraints like ours. suitabledomain exceptions happen frequently, need respondedquickly. Fox, Gerevini, Long, Serina (2006) discuss trade-off replanningplan-repair strategies handling execution failure. algorithms work off-line,instead on-line real-time environment ours, target differentobjective function (in case, plan stability). CASPER system JPL (Chien, Knight,Stechert, Sherwood, & Rabideau, 1999) uses iterative repairs continuously modifyupdate plans adjust dynamic environment. Unlike system, CASPER usesdomain control-rules thus less flexible replanning decision also neededquickly domain (in case, sub-second).5.2 Basic Exception Handlingplanner handle several types exceptions. Figure 16 extends system architecture diagram Figure 3 shows solid lines possible steps replanningprocess. general, exception occurs, machine controller sends plannermessage real time detailing exception. planner cancels planscreated sent printer controller execute. correspondinggoals rolled back unplanned queue. planner time also triesfind new plans sheets moving printer avoid exceptions.449fiRuml, Do, Zhou, & Fromherzprinter model (off!linep()PlannerSTNplansfl iblflexiblestart timesheetdescriptions(on!line)recreate goalsnew planslunplannedplanningplanned/unsentPlan Managersentfixed!time plansexceptionspFigure 16: System architecture, showing steps involved nominal planning (dashedlines) replanning (solid lines).new plans found sent machine controller replace onesexecuting.Next, discuss detail different exception types.Plan Rejection: plan sent machine controller execute, controllermay reject plan one relevant modules cannot commit executing requestedaction time defined planner. rejections rare, causedmodule constraints outside scope planners model. example,printer engine may need time bring toner proper temperaturea state variableconstraint currently modeled system. plan rejected, plannercancel plans unsent queue, addition recently sent rejected plan.goals corresponding plans rolled back unplanned queue. Evenplans directly affected error message also need canceled rolledback plans made commitments made rejectedplan.Module Update: Machine modules go -line due hardware failure,sheet jam, benign event, running paper feed tray, unmodeledprocess, print engine self-adjustment. Similarly, come on-linerepaired, adjusted, otherwise made ready. happens, module controllersend message planner indicating modules capabilitieson/off. given capability turned off, planner remove correspondingaction consideration future planning episodes. given capability turned on,planner add action set future planning episodes.Break-in-Future: module changes status capabilitiesoff, currently executing unsent plans using module may become invalid.case, module controller send messages planner indicating plans450fiOn-line Planning Scheduling Modular Printersaffected. planner cancel affected unsent plans subsequent plans movegoals back unplanned queue. plans executing thus correspondsheets already fed machine, planner needs find new plansaffected sheets get correct finisher tray without goingaffected modules. next section describes detail reroute in-flightsheets.Broken: type exception happens one sheets jammed system.broken messages sent planner include ids sheets jammedthus cannot reused rerouted failure. sheets jam,normally also disable modules thus broken message normally accompaniedseveral module update messages, described above. handling brokenexception similar handling break-in-future exception many respects:involves canceling unsent plans finding new plans in-flight sheets. However,main differences are: (1) in-flight sheets jammed cannot rerouted; (2)critically, jammed sheets break print job integrity. discuss detail next.5.3 In-flight Sheet Replanningsection, discuss problem finding new set plans in-flight sheetssheet jammed module used plans broken. constraintsmake replanning challenging nominal planning are:Sheets cannot stop slow planner searches new plans inflight sheets. Thus, planner takes much time find new plans, jamsand/or module failures cascade.newly found plans flexible starting times nominal planningcase, start location sheets projectedplans found. new locations depend actual replanning timeplanner.in-flight sheets occurring later print job jammed sheetrerouted purge tray. sheets jobs without jammed sheets still needfinish correct finisher tray order.Replanning involves four main steps: (1) create new goals in-flight sheets; (2)predict (an upper bound on) replanning time; (3) project sheets accordingoriginal trajectory predicted planning time find future locations,form new initial state replanning problem; (4) find plans sheetssalvageable (those possible avoid broken modules jammed sheetstime), satisfying constraints listed above.5.3.1 Exampleprovide concrete example illustrating replanning procedure. Figures 17 & 18show scenario three in-flight sheets: S1.1 S1.2 belongprint job planned go finisher 2 (in middle); sheet S2.1 belongs451fiRuml, Do, Zhou, & Fromherz1.21.1Finisher 1Finisher 2PPurgetray2.1Figure 17: Replanning Example (before jam): sheet 1.1 1.2 planned enter finisher2, sheet 2.1 finisher 1.1.21.1Finisher 1Finisher 2Purge Tray2.1Figure 18: Replanning Example (after jam): sheet 1.1 jammed, requires planner reroute sheet 1.2 purge tray reroute sheet 2.1 circumventjammed sheet going finisher 1.different print job scheduled go finisher 1. third finisher purge tray.original routes indicated dashed lines Figure 17. Assume S1.1jammed. According original routes, have: (1) S1.2 arrive finisher trayout-of-order (because S1.1 arrive it); (2) S2.1 crash moduleS1.1 jammed. Therefore, need find new plans two sheets S1.2instead go purge tray S2.1 goes around S1.1 . Finding plans takes timegiven cannot stop slow S1.2 S1.2 finding new plans them,two sheets continue original trajectories new locations,452fiOn-line Planning Scheduling Modular Printerssheet 1plan 2plan 1...plan 3sheet 2plan 4...plan 1plan 2plan 3Figure 19: Chaining many searches together gives search tree potentially infinitebranching factor.circled Figure 18. there, machine controller apply new plans, indicatedfigure solid lines, order guarantee print-job integrity avoidingcascading failures. replanning done, planner generate fresh plansre-create S1.1 S1.2 .example shows one replanning strategy new goal out-of-ordersheet S1.2 set go purge tray. default strategy replanner triesclear machine finish replanning process quickly possible returnnormal operation. However, scenarios printing media expensivecontent confidential purging sheets desirable. scenarios,also experimented different strategy purge S1.2 keepsmachine (for example, looping holding pattern) waiting S1.1reprinted, S1.2 routed original finisher. modification necessaryimplement strategy system change way replanning goals end-timeconstraints generated. tested strategy successfully small numbersheets, although sheets could saved one allowed slow transports.5.3.2 Chained BFSnormal operation, planner uses A* find plan given sheet endsoonest, given (temporally flexible) plans previous sheets. plan always existsscheduled sufficiently far future. rerouting, problem different. mustfind jointly feasible plans many in-flight sheets possible. cannot greedily planone sheet time, committing irrevocably plans previous sheets,plan selected one sheet might render subsequent sheets infeasible. cannot happennominal planning, later sheets always feasible scheduled sufficiently farfuture. replanning, however, forced confront true multi-bodyplanning problem.considered two strategies solve problem. first simply planjoint action space sheets. would result large branching factorclear us design effective heuristic evaluation function. chose differentapproach, retain view planning sheet individually usingheuristic search. However, overlay additional search top this, depictedFigure 19. high-level search, branching node represents situationselected certain specific plans previous sheets time select plan453fiRuml, Do, Zhou, & FromherzChainedBFS (problems)1. problems empty, return success2. p remove first problem problems3. initialize openlist p4. repeat openlist empty node limit reached:5.n best node openlist6.n goal, call ChainedBFS remaining problems7.expand n, adding children openlistFigure 20: Sketch Chained Best-First Search depth-first strategy.additional sheet. children node represent commitments different possibleplans additional sheet. considering different paths high-level searchtree, consider different combinations plans different sheets. callapproach chained best-first search. current implementation, sheets replannedoriginal order, approximation increasing distance exit, correlatesincreasing flexibility. alternative approach replan order urgencydefined time left reroute sheet becomes unsalvageable.children node represent possible plans returned best-firstsearch, children available once. Instead, individual sheet-level planningsearch encounter goal nodes one time. cannot terminate searchfind first goal node single-sheet planning guaranteesheet-plan reaching first goal make subsequent sheets feasible. Finding plansingle sheet merely results new branch high-level space, retaincompleteness must retain ability continue search uncover additionalpossible plans. fact, printers contain loops paper path,may infinite number possible plans given sheet. Fundamentally, highlevel search must explore tree nodes expanded incrementally branchingfactor potentially infinite.identified three possible strategies searching tree infinite branching factor.first best-first approach, one formulates traditional heuristic evaluationfunction high-level nodes. nodes represent commitments complete planssubset in-flight sheets, heuristic function needs estimate probabilityplans allow feasible plans remaining sheets found. infinitebranching factor could handled using Partial-Expansion A* (Yoshizumi, Miura, & Ishida,2000), although would require non-trivial lower bound heuristic valueplans yet found. clear us might done.second possible strategy considered limited discrepancy search (Korf, 1996). Unlikedepth-first search, limited discrepancy search doesnt necessarily visit childrennode, potentially infinite us. disadvantage method that,revisit node many times different discrepancy bounds, sufferconsiderable node regeneration overhead.third strategy, one used implementation, perhaps simplest:depth-first search. Figure 20 shows pseudo-code sketch. fixed numbersheets replan, high-level search tree bounded depth. cope potentially454fiOn-line Planning Scheduling Modular Printersinfinite branching factor, impose limit number nodes low-level sheetplanning search may expand. avoids danger searching forever one high-levelnode without finding another goal, reminiscent iterative broadening (Ginsberg& Harvey, 1992). guide sheet-level planning, use heuristic minimizesplan duration. attempts minimize resource use machine maximizeprobability sheets feasible plans.5.4 Evaluationnow, exception handling strategies current production printers to:(1) stop production ask operator remove sheets (2) use machine-specificcustomized local rules purge sheets system. work first demonstrateautomatic exception handling rely machine-specific control rules.planner handle two easiest types exception: Plan Reject ModuleUpdate without difficulties. Break-In-Future Broken exceptions,currently reroute fly five sheets machine shown Figure 1.number may seem low, recall replanning harder nominal planningfactor exponential number in-flight sheets. simpler prototype systemsXerox fewer (but larger) modules, four print engines, aggregate throughput180 pages-per-minute, planner able successfully reroute reroutable sheetsdifferent jams happen. demonstrated replanning technology real-timeallowing people come either turn on/off modules, jam sheets intentionally,sometimes right sheets hit broken module. Upon receiving error messagesmachine controller, planner fast enough reroute sheets aroundfailed modules jammed sheets correct locations. addition experimentingphysical hardware built PARC Xerox, also tested replanningsimulation, connecting planner visualizer instead machine controller.on-line appendix contains two videos planner performing in-flight reroutingPARC prototype, simulation (Video 3, replanning simulation) hardware(Video 4, replanning hardware).addition testing replanning framework different hypothetical printer configurations different fault modes, also investigated different exception handlingstrategies. example, printing media expensive replanning objectivefunction switched default objective function finish replanning quicklypossible (which lead many purged sheets) saving many sheets possible (whichlead longer replanning time) planner able successfully route2 out-of-order sheets long routes (that may contain loops) system waitingjammed sheet printed routed correct finisher tray.achievement replanning five sheets large RMP machine may seemimpressive, want point that: (1) planner reroute reroutable sheetssimpler machines (which still much complex biggest multi-engine printerXerox currently market); (2) large machine complex automatedplanningthe last two IPC winners SGPLan LPG cannot even find plan singlesheet nominal planning using PDDL2.1 version printer domain.455fiRuml, Do, Zhou, & Fromherz6. Handling Multiple Objectivessecond major extension nominal planning aimed better meeting shop ownersneeds nominal case. point, planners objective runmulti-engine reconfigurable printers full productivity, optimizing machine throughput.Productivity, important, one many optimization criterianaturally exist real-world planning scheduling applications like printer controldomain. section, describe several additional objective functionspointed important industrial partner, discuss extendedplanning framework handle them.modular system multiple print engines, one might want optimize costprinting choosing print black-only pages monochrome engines avoid usingexpensive color engines. Also, one might want optimize image quality choosingprint pages document print engines whose current marking gamutssimilar. printer controller needs give operators ability tradeconflicting objectives maintaining robust operation. meet challenges using(1) optimization objective combines separate estimates productivity printingcost, (2) multiple heuristic look-ups efficiently handle image quality consistencyconstraints. contrast explicit multi-objective optimization, plannerwould return selection non-dominated solutions Pareto frontier, presumablyhuman choose from, planner needs select single solution execution,need combine multiple criteria single objective. planner builtatop generic state-space heuristic search, need design new comparison functionorder search nodes. addition linear combinations objectives, relatively easyus handle tiered criteria using tie-breaking strategies.several academic domain-independent planners GRT (Refanidis &Vlahavas, 2003) LPG (Gerevini, Saetti, & Serina, 2008) optimize multiple objectives trade-off planning time plan quality. Standard planninglanguages, especially PDDL3 (Gerevini & Long, 2006), allow specifying complex objectivefunctions weighted-sum format (as framework). planner also baseddomain-independent planning technology uses extension PDDL, worksdynamic on-line continual environment interacts physical machine,off-line abstracted environment like previous planners.6.1 Optimizing Printing Costsystems heterogeneous print engines, cost printing given page dependsengines used. example, generally costlier print black-and-whitepage color engine monochrome one. Thus, minimize overall printing cost,one use engines lowest printing cost still satisfy image typequality requirements given print job. so, subset availableengines used printing job thus overall productivity may reduced.strike balance machine productivity printing cost, implemented objective trade productivity cost vice versa. showcombining different performance criteria single objective, optimizationframework works well single-objective planning efficiently applied456fiOn-line Planning Scheduling Modular Printersmulti-objective case. main steps required extend plannersupporting single objective multiple objectives.Step 1: Extend planners representation machine capabilities model action cost.Specifically, added cost field representing cost executing capability.addition, overall objective field user-supplied weights twoobjectives: obj = min w1 + w2 c, end time c accumulated totalcost printing sheets.Step 2: Create one heuristic estimation function objectives. findbest route given sheet, estimate good potential route accordingobjective functions. Finishing time estimated using temporal planning graphadjusted resource conflicts, described Section 4.3.4. estimate total planexecution cost, use dynamic programming starting initial state (i.e., sheetfeeder) compute total cost reach different reachable states. computation similar cost propagation planning graph Sapa planner (Do &Kambhampati, 2002).Step 3: Extend search algorithm considering multiple objectives simultaneously.estimations total time cost combined using user-supplied weights (asdescribed Step 1) compare nodes best-first A* search algorithm. Givenheuristics time cost admissible, like single objective planner, plannerguaranteed find optimal solution given sheet. weights given,planner chooses prioritize objectives. example, planner first find planlowest cost, break ties favoring plans higher productivity,favoring one lower wear tear, on. mechanism implementedfully integrated planner. default option weights specifiedoptimize productivity break ties total cost.6.2 Planning Image Quality ConsistencyMaintaining image consistency across set heterogeneous print engines especiallyimportant multi-engine printing system. planner achieves enforcing additional image-consistency constraints searching optimal plan. color science,(in)consistency two colors measured function, often denoted E, calculates distance two device-independent color space.exist variety functions (the popular called E2000; see Green,2002), planning purpose suffices assume given two engines, Efunction returns non-negative real-valued scalar, called E distance, measuresdiscrepancy perceived color result printing image two engines.facing pages (i.e., pages face bound book magazine)sensitive image-consistency issues, thus consider following constraintsplanner:1. facing-page constraints require facing pages job printedprint engine2. E constraints allow engines within maximum E distance printfacing pages457fiRuml, Do, Zhou, & FromherzGiven reality two engines E distance zero, facing-pageconstraints viewed special case E constraints maximum Edistance set zero. Thus, need focus latter, general.enforce E constraints, planner keeps track set print capabilitiesused print front side sheet, constrained print actionapplied back side previous sheet. Since first sheet jobprevious sheet, set print capabilities eligible printing front side unconstrained(i.e., equal entire set print capabilities). subsequent sheets job,however, subset print capabilities allowed. subset computed basedE constraints including capabilities engines whose E distanceprint engine printed back side previous sheet less equalmaximum distance. cases, determined on-line,E distance pair engines drift time. Thus, planner maintainson-line version pairwise E-distance matrix engines printer.adding extra image-consistency constraints reduce brute-force searchspace (if constraints make set reachable states smaller), practice foundoften makes search problem harder, heuristic computed unconstrained problem, still admissible, longer informative. improve accuracyheuristic, planner computes temporal planning-graph heuristic legalcombinations print capabilities used print one side sheet,stores multiple lookup tables, one combination. heuristic estimatesearch node needed, planner calculates index lookup table basedstate description (e.g., sheet location, monochrome color printing), muchway lookups done pattern databases (Culberson & Schaeffer, 1998).implementation, hash table hash tables used store multiple lookup tables,given sheet relevant hash table(s) loaded sheet planned,set eligible print actions known fixed time.Since limited number ways printing single face sheet,approach improving heuristic accuracy little overhead yet significantly reducetime takes find itinerary. Interestingly, approach also usedimprove accuracy heuristic handling exceptions jammed sheetsblock paper paths engines, unblocked engines eligibleprinting sheets, creating planning problems similar enforcing E constraints.example, one set E distance blocked engine infinity, effectivelyforces sheets go unblocked engines, computational savings comesuse accurate heuristic built specifically particular setunblocked engines, instead nominal-case heuristic assumes engine blocked.6.2.1 Planning Constrained Action Setalgorithmic perspective, approach planning image-quality consistencycorresponds solving constrained planning problem reduced set actions (compared unconstrained version). Given planning problem k actions, one create O(2k ) different versions constrained problem. Thus, pre-computing temporalplanning-graph heuristic possible subsets actions quickly become infeasible458fiOn-line Planning Scheduling Modular Printersk increases. describe general solution strikes balance heuristicaccuracy space overhead storing multiple lookup tables, one subsetactions. idea limit m, maximum number actions removedunconstrained problem, compute heuristic lookup tables constrainedproblems. example, usually feasible enumerate constrained problemsone two actions removed action set. compute heuristicvalue state constrained problem included pre-computed set,algorithm consults lookup tables whose removed actions form subset actions removed constrained problem, returns maximum value heuristicestimate state, since value returned lookup tables admissible.formally, let h(s|P ) admissible heuristic estimate state constrained problem set actions P removed original action set A,let maximum number actions removed constrained problemsheuristic pre-computed. heuristic estimate h(s|P ) calculated follows,h(s|P ) =(h(s|P )maxQP|Q|=m|P |h(s|Q) otherwisenew heuristic resembles hm family admissible heuristics (Haslum & Geffner,2000), limits maximum cardinality set atoms consideredconstruction heuristic. difference heuristic considers set removedactions, whereas hm heuristic considers set satisfied atoms. heuristic alsoseen kind multiple pattern database (Holte, Felner, Newton, Meshulam, & Furcy,2006) one take maximum set heuristic estimates without losingadmissibility, although based action-space abstraction (multiple) patterndatabases based state-space abstraction.6.3 Evaluationtest ability planner trade machine productivity printingcost, tested model four-engine prototype printer built Xerox.better test bed trade-off investigation printer mixed set printerengines (two color two black-and-white engines) instead four identical black enginesPARC prototype system. Moreover, engines aligned asymmetricallythus paths leading different engines slightly different. modeledcosts different components consultation Xerox engineers. especiallyinterested modeling cost print black pages different engines: printingexpensive color engines costs cheaper monochrome engines.varying weights two objective functions, able show that:(1) increasing weight given productivity results printer utilization fourengines; (2) increasing weight saving printing cost leads reductions numberunnecessary costly printing, thus fewer black sheets printed color engines.observe trade-off modules similar functionality well,different feeders, finishers, paper paths. example, increasing weight savingcosts lowers number sheets fed expensive faster feeder.also tested search hypothetical printers mixed components similar459fiRuml, Do, Zhou, & Fromherzresults observed. also observed moving single multiple objectivesslow planner thus affect overall productivity.also tested performance planner image-consistency planning.model printer used four monochrome engines, two faster lowquality engines, remaining two slower high-quality engines. four enginesconnected asymmetric paper paths. ran simulation 20-sheetjob requires using two high-quality engines double-sided printing.done certain E constraints, prevent planner choosing twolow-quality engines. Since particularly interested effect heuristicsearch performance, tested planner without using multiple lookup tables,made significant difference number node expansions A* searchplanning times. average, multiple lookup table heuristic used, plannerexpands 1783 nodes per sheet; whereas using heuristic computed unconstrained problem, grossly underestimates remaining makespan constrainedproblems, needs 6458 node expansions find plan. terms running time, oneuses multiple lookup tables 60% faster using naive heuristic.One future direction investigate different objective entirely: wear tear.objective, one would like different machines plant used amountlong term. However, machines often cycled idle longperiod cycling introduces wear, one would like recently-used machinesselected soon short term. Although implementation currently supportsthroughput cost, easily extensible support additional objectives.7. Deploymentprocess building deploying planner, utilized many off-the-shelf techniques academic research planning, extending, integrating form faston-line planner/scheduler. section, list important lessons learneddescribe ancillary tools necessary develop deploy planner.hope useful application developers academic researchersplanning.7.1 Lessons LearnedModeling important. mean two respects. First, importantend-users printers modeled specialized representation machinemodules connections main themes language.discussed Section 4.1, representation compiled planner inputlanguage, taking capabilities different modules along inter-connectionsproducing action schemata. process, set machine capabilities compiledhigher number action schemata ground parameters.discussion users industrial partners, feel machine-centric languageinvolving modules, machine instances, inter-connections easier understandaccept, compiled-down representation makes much easier us adoptSTRIPS planning techniques.460fiOn-line Planning Scheduling Modular PrintersSecond, also found that, understood search algorithm (regressionthree-value state representation) heuristics (planning graph mutexes) usedplanner, could manipulate modeling actions, goals, initial statesproduce quite different computational results. Consider simple example action a12 =move(l1 , l2 ) moves object location l1 l2 . common form STRIPSrepresentation action P re(a12 ) = { at(l1 )} Effect(a12 ) = {at(l1 ), at(l2 )}.Recall use three-value representation literal values true,false, unknown. Regressing (partial) state s1 = {at(l2 )} using a12 get us states2 = {at(l1 ), U nknown(at(l2 )) regressable actions move(l3 , l1 )move(l3 , l2 ). normal regression rules may consider move(l3 , l2 )lead optimal length plan, regressing s2 move(l3 , l2 ) causeinconsistency. fact, domain like ours, branch regressable actionsscenarios need buy time free resource allocations.Note example, sophisticated techniques discover invariants TIM (Fox& Long, 1998) DISCOPLAN (Gerevini & Schuert, 1998) discover objectsingle location time thus s2 regressableaction move(l3 , l2 ). However, eliminate branch simply adding preconditionat(l2 ) action description a12 make sure goal state, locationgoal false. Generating extra child node propagating constraintsdomain expensive because, addition logical part, state representationincludes temporal resource databases. cutting number generatednodes important, partially accomplished careful modeling.Similarly, adding removing predicates domain description greateffects heuristic estimation derived planning graph mutex propagation. experienced scenario adding two extra predicates representing subgoalcompletion modeling domain slightly differently achieved speedup nearly 10xprinter configurations.manipulations reminiscent work Rintanen (2000), showeddomain advice expressed linear temporal logic, dont move packagedestination, could compiled planning operators domain using conditionaleffects, leading great gains planning efficiency. However, want emphasizehighly configurable systems like ours, dangerous encode explicit action choicespruning domain. hard guarantee completeness optimalitymaintained possible job mixes failure combinations. (For example, loopingsheet may free resource allow job complete earlier.) approachencode domain physics, is, things universally true domainhelp keep search within reachable states, control rules senseheuristic action selections, condition, choose action. pointphysics represented differently, even limited STRIPS, finding rightmatch chosen search strategy dramatically affect planners performance.application developers, work fixed benchmark domain representationallows us exploit another dimension modeling improve planners performance.suitable planning algorithm depends application specifications.Even formulating domain using extension STRIPS, went several461fiRuml, Do, Zhou, & Fromherzimplementations different planning algorithms settling current one. firstversion lifted partial-order planner, still think elegant algorithm.implemented grounded forward state space planner, approachdominated planning competitions. However, discussed Section 3.1, realizedcombination constraint sheets print job finishedorder objective function minimizing finishing time suitable forwardstate-space search. finally settled backward state-space framework, muchfaster domain. lesson drew approach worksbest wide range benchmark domains competition meanbest choice given application; doesnt work, mean lesspopular approaches cannot significantly better. Therefore, understanding domain,important constraints involved, objective function, different planningalgorithms work help selecting suitable strategy. Looking competitionresults replacement understanding variety applicable planning algorithms.fast robust temporal reasoner important. planner,even though source code Simple Temporal Network (STN) totals less 200lines code, critical handling temporal relations actions resource allocations within single plan different plans. real-world applicationvarious temporal constraints delays take account, communication, setup time, machine controller coordination, time synchronization delaysplanner components overall control architecture, ensuring temporalconsistency one important tasks necessary keeping planner runningwithout interruption long period time. explicit temporal reasoner alsohelped us uniformly represent manage start end times actions differenttypes resource allocations. also allowed us smoothly extend handling fixedduration actions action variable durations, extend regular resource allocations resource allocations caused external events cyclic resources allocationuncontrollable processes. domain, variable action durations context-independentdifferent actions refuel Logistics domain used competition.havent noticed many planners competition explicit general-purposetemporal reasoner, except IxTeT(Ghallab & Laruelle, 1994). However, would likeemphasize real-world setting planner needs coordinatesoftware expects face various time constraints delays, critical.many uses planner. Besides main job controlling differentprinters, planner also used extensively system analysis purposes. Thus,planner tested (1) different printer designs help decide better ones;(2) printers various broken modules test reliability printer.analyses help product group decide printer built given purpose.example, customer ran extensive test consisting 11,760 different planner runsvariations single printer configuration. Among runs, used plannertest different combinations possible broken points, different print-job mixes, changedspeeds different modules. Another use test performance upstreamjob submission sequencing methods. direct accurate way evaluate jobsequencer run long print-job mix (thousands sheets more) planner462fiOn-line Planning Scheduling Modular Printersmeasure total makespan. Recently, completed print-job mix 50,000 sheetswithout break, intensive regular real-life printer operation.experiences, learned many potential applicationsplanner beyond direct machine control.Exception handling. Given planner interacts parts eitherhigher lower control hierarchy, exceptions come many forms. believesimilar exceptions would occur applications planner interactsphysical world. robust exception handling (such replanning) important,found much less research topic compared branches domainindependent planning.hope observations help researchers develop planning techniquescloser needed real-world applications also usefulconsidering deploying AI planning applications.7.2 Ancillary Toolscourse building system, developed number ancillary tools aroundcore planning scheduling software. Among tools, notable piecevisualizer, simulates movement sheet inside printer real time. Likeplanner, visualizer adopts model-based principle make machineindependent possible. itinerary given discrete sequence actions,single time stamp prescribes start time action, linear interpolationused compute position sheet current simulation time somewherestart times two consecutive actions. visualizer works onefollowing two modes: on-line mode accepts live itineraries sent plannersockets, off-line mode reads previously recorded itineraries file storeddisk.separate visualization engine specific designs printer, developedsimple module definition language describing dimensions module type,locations input output ports within modules local coordinate system,travel distance pair input output ports, optionally customizeddrawing function used render type modules screen. Besidesdefinition module types, visualizer needs know location well orientationmodule machine-wide coordinate system. possible specifyinformation manually, developed another ancillary tool called visualizer preprocessor used automate laborious yet error-prone task. tool,user needs specify location orientation one module, called seedmodule, locations orientations (directly indirectlyconnected) modules deduced based connectivity graph modules.machines one feasible configuration, tool find possible solutionsstore multiple files used later visualizer. Besides nominalcase, visualizer also simulate various exceptions paper jams break-infuture scenarios. long-term vision visualizer become design, debug,verification tool manufacturer, well GUI console end user operatesprinter.463fiRuml, Do, Zhou, & Fromherzmake easier run tests modular printers, also developed wrapperprogram glues together planner controller (or visualizer). takesinput set pre-defined test scenarios specified succinct syntax (e.g., 10sc meansprint 10 single-sided color sheets). support simulation pre-fabricated exceptions,sends special messages visualizer contains informationsheet jam occur. also supports simultaneous printing jobs printersmultiple finishers, uses round robin algorithm draw sheets jobsrate maintain fairness. facilitate remote testing debugging, wrapper programuses sockets communicate machine controller (or visualizer).8. Conclusiondescribed real-world domain requires novel on-line integration planningscheduling formalized using temporal extension STRIPS fallspartial-order scheduling temporal PDDL. presented hybrid planner usesstate-space regression per-sheet basis, using temporal constraint networkmaintain flexibility partial orderings representing resource conflicts plansdifferent sheets. system successfully controlled three hardware prototypesoutperforms state-of-the-art planners domain. domain-dependent search controlheuristics necessary control printer composed 170 modules real time.described extensions handle two critical issues: (1) real-time execution failures;(2) objective functions beyond productivity. successfully demonstrated fastreplanning multiple objective handling three physical prototype printers manypotential printer configurations simulation.work provides example AI planning scheduling find real-worldapplication exotic domains spacecraft mobile robot control, alsocommon down-to-earth problems manufacturing process control. modularprinter domain representative wider class AI applications require continualon-line decision-making. novel combination fast continual temporal planningtechniques, shown artificial intelligence successfully enable robust, highperformance, autonomous operation without hand-coded control knowledge.AcknowledgmentsMuch work done first author Palo Alto Research Center.Preliminary results project published Ruml, Do, Fromherz (2005),Ruml (2006), Do, Ruml, Zhou (2008) summarized Do, Ruml,Zhou (2008). authors would like thank members Embedded ReasoningArea PARC, especially Lara Crawford, Haitham Hindi, Johan de Kleer, Lukas Kuhn,well Danny Bobrow, David Biegelsen, Craig Eldershaw, Dave Duff helpcontributions project. industrial collaborators provided domainexpertise invaluable helping us simplify frame application usefulway. Wed like especially thank Bob Lofthus Ron Root enthusiasmperseverance Steve Hoover supporting project.464fiOn-line Planning Scheduling Modular PrintersAppendix A: Videoon-line appendix JAIR website contains four movies system action:1. nominal-simulation.mp4: shows one simplex job 200 sheets run simulation PARC prototype printer shown Figure 1. planner keeps fourprint engines busy, achieving full productivity system.2. nominal-hardware.wmv: shows two simplex jobs run simultaneously usingfour engines PARC hardware prototype. two feeders lefttwo simple finishing trays right. Red lights machine modules showposition sheets. (Background time synchronization indicated periodicblinking.) lower left corner, schematic visualization shows sheetsmoving machine, one job colored blue red.3. replanning-simulation.mp4: show simple exceptions handling scenario simulation. Blue sheets red sheets belong different jobs. second sheet bluejob jams. third sheet, already in-flight, rerouted middle purge trayfresh plans initiated recreate sheets. red job continues uninterrupted.4. replanning-hardware.wmv: demonstrates two exception handling scenarios.first shows simple on-line replanning. sheet launched, button pushedmodule sheet headed toward, mark module broken.initiates replanning, sheet routed around failed module. secondmodules button pushed, marking failed thereby blocking finishing traysheet headed toward. sheet rerouting emergesremaining finishing tray.second scenario, module broken already contains first sheettwo-sheet job. replanner fast enough reroute second sheet aroundjammed first sheet purge tray. original two sheets plannedscratch arrive lower finishing tray.ReferencesBaptiste, P., & Pape, C. L. (1995). theoretical experimental comparison constraintpropagation techniques disjunctive scheduling. Proceedings IJCAI-95, pp.600606.Bartak, R. (2002). Visopt shopfloor: edge planning scheduling. ProceedingsConference Principles Practice Constraint Programming (CP-02), pp.587602.Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions computational leverage. Journal Artificial Intelligence Research,11, 191.Cervoni, R., Cesta, A., & Oddi, A. (1994). Managing dynamic temporal constraint networks.Proceedings AIPS-94, pp. 1318.465fiRuml, Do, Zhou, & FromherzChen, Y., Hsu, C.-W., & Wah, B. (2006). Temporal planning using subgoal partitioningresolution sgplan. Journal Artificial Intelligence Research, 26, 323369.Chien, S. A., Knight, R., Stechert, A., Sherwood, R., & Rabideau, G. (1999). Using iterative repair improve responsiveness planning scheduling autonomousspacecraft. Proc. IJCAI.Chleq, N. (1995). Efficient algorithms networks quantitative temporal constraints.Proceedings Constraints-95, pp. 4045.Crawford, L., Hindi, H., Zhou, R., & Larner, D. (2009). Synchronized control large-scalenetworked distributed printing system. Proceedings 2009 IEEE InternationalConference Robotics Automation (ICRA-06).Culberson, J., & Schaeffer, J. (1998). Pattern databases. Computational Intelligence, 14 (3),318334.Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artificial Intelligence, 49, 6195.desJardins, M. E., Durfee, E. H., Ortiz, Jr., C. L., & Wolverton, M. J. (1999). surveyresearch distributed, continual planning. AI Magazine, 20 (4), 1322.Do, M., Ruml, W., & Zhou, R. (2008). On-line planning scheduling: applicationcontrolling modular printers. Proceedings AAAI-08.Do, M. B., & Kambhampati, S. (2002). Sapa: multi-objective metric temporal planer.Journal Artificial Intelligence Research, 20, 155194.Do, M. B., & Ruml, W. (2006). Lessons learned applying domain-independent planninghigh-speed manufacturing. Proceedings ICAPS-06, pp. 370373.Do, M. B., Ruml, W., & Zhou, R. (2008). Planning modular printers: Beyond productivity. Proceedings Eighteenth International Conference AutomatedPlanning Scheduling (ICAPS).Fox, M., Gerevini, A., Long, D., & Serina, I. (2006). Plan stability: Replanning versus planrepair. Proc. ICAPS-06, pp. 212221.Fox, M., & Long, D. (1998). automatic inference state invariants TIM. JournalArtificial Intelligence Research, 9, 367421.Fox, M., & Long, D. (2003). PDDL2.1: extension PDDL expressing temporalplanning domains. Journal Artificial Intelligence Research, 20, 61124.Frank, J., & Jonsson, A. (2003). Constraint-based attribute interval planning. Constraints, 8, 339364.Franklin, G., Powell, J., & Workman, M. (1997). Digital Control Dynamic Systems.Prentice Hall.Fromherz, M. P. J., Bobrow, D. G., & de Kleer, J. (2003). Model-based computingdesign control reconfigurable systems. AI Magazine, 24 (4), 120130.Fromherz, M. P. J., Saraswat, V. A., & Bobrow, D. G. (1999). Model-based computing:Developing flexible machine control software. Artificial Intelligence, 114 (12), 157202.466fiOn-line Planning Scheduling Modular PrintersGerevini, A., & Long, D. (2006). Preferences soft constraints pddl3. WorkshopPreferences Soft Constraints Planning, ICAPS06.Gerevini, A., Saetti, A., & Serina, I. (2003). Planning stochastic local searchtemporal action graphs lpg. Journal Artificial Intelligence Research, 20, 239290.Gerevini, A., Saetti, A., & Serina, I. (2008). approach efficient planning numericalfluents multi-criteria plan quality. Artificial Intelligence, 172, 899944.Gerevini, A., & Schuert, L. (1998). Inferring state constraints domain-independentplanning. Proceedings Fifteenth National Conference Artificial Intelligence(AAAI).Ghallab, M., & Laruelle, H. (1994). Representation control IxTeT, temporalplanner. Proceedings AIPS-94, pp. 6167.Ghallab, M., Nau, D., & Traverso, P. (2004). Automated Planning Theory Practice.Morgan Kaufmann, San Francisco.Ginsberg, M. L., & Harvey, W. D. (1992). Iterative broadening. Artificial Intelligence, 55,367383.Green, P. (2002). Colorimetry colour difference. Green, P., & MacDonald, L. (Eds.),Color Engineering, pp. 4977. Wiley.Haslum, P., & Geffner, H. (2000). Admissible heuristics optimal planning. ProceedingsAIPS, pp. 140149.Haslum, P., & Geffner, H. (2001). Heuristic planning time resources. ProceedingsECP-01.Hindi, H., Crawford, L., & Fromherz, M. (2005). Synchronization state based controlprocesses delayed asynchronous measurements. Proc. DecisionControl, 2005 2005 European Control Conference. CDC-ECC 05, pp. 63706375.Hindi, H., Crawford, L., Zhou, R., & Eldershaw, C. (2008). Efficient waypoint trackinghybrid controllers double integrators using classical time optimal control. Proc.47th IEEE Conference Decision Control, 2008 (CDC 2008).Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generationheuristic search. Journal Artificial Intelligence Research, 14, 253302.Holte, R., Felner, A., Newton, J., Meshulam, R., & Furcy, D. (2006). Maximizingmultiple pattern databases speeds heuristic search. Artificial Intelligence, 170 (16- 17), 11231136.Koehler, J., & Hoffmann, J. (2000). reasonable forced goal orderings useagenda-driven planning algorithm. Journal Artificial Intelligence Research,12, 338386.Korf, R. E. (1996). Improved limited discrepancy search. Proceedings AAAI-96, pp.286291. MIT Press.Le, T. C., Baral, C., Zhang, X., & Tran, S. (2004). Regression respect sensingactions partial states. Proceedings AAAI-04.467fiRuml, Do, Zhou, & FromherzMuscettola, N. (1994). HSTS: Integrating planning scheduling. Zweben, M., & Fox,M. S. (Eds.), Intelligent Scheduling, chap. 6, pp. 169212. Morgan Kaufmann.Muscettola, N., Morris, P., & Tsamardinos, I. (1998). Reformulating temporal plansefficient execution. Proceedings Conference Principles Knowledge Representation Reasoning (KR-98).Nguyen, X., Kambhampati, S., & Nigenda, R. S. (2002). Planning graph basisderive heuristics plan synthesis state space csp search. Artificial Intelligence,135 (1-2), 73124.Palacios, H., & Geffner, H. (2002). Planning branch bound: constraint programming implementation. Proceedings CLEI-02.Policella, N., Cesta, A., Oddi, A., & Smith, S. F. (2007). precedence constraint postingpartial order schedules. AI Communications, 20 (3), 163180.Pryor, L., & Collins, G. (1996). Planning contingencies: decision-based approach.Journal Artificial Intelligence Research, 4, 287339.Refanidis, I., & Vlahavas, I. (2003). Multiobjective heuristic state-space planning. ArtificialIntelligence, 145, 132.Richter, S., Helmert, M., & Westphal, M. (2008). Landmarks revisited. ProceedingsAAAI-08, pp. 975982.Rintanen, J. (2000). Incorporation temporal logic control plan operators. Proceedings Fourteenth European Conference Artificial Intelligence (ECAI-2000),pp. 526530.Ruml, W., Do, M. B., & Fromherz, M. P. J. (2005). On-line planning schedulinghigh-speed manufacturing. Proceedings ICAPS-05, pp. 3039.Smith, D. E., & Weld, D. S. (1999). Temporal planning mutual exclusion reasoning.Proceedings IJCAI-99, pp. 326333.Smith, S. F., & Cheng, C.-C. (1993). Slack-based heuristics constraint satisfactionscheduling. Proceedings AAAI-93, pp. 139144.Wah, B. W., & Chen, Y. (2003). Partitioning temporal planning problems mixedspace using theory extended saddle points. IEEE International ConferenceTools Artificial Intelligence.Yoshizumi, T., Miura, T., & Ishida, T. (2000). A* partial expansion large branchingfactor problems. Proceedings AAAI-2000, pp. 923929.468fiJournal Artificial Intelligence Research 40 (2011) 269-304Submitted 7/10; published 1/11Iterated Belief Change Due Actions ObservationsAaron Hunterhunter@cs.sfu.caBritish Columbia Institute TechnologyBurnaby, BC, CanadaJames P. Delgrandejim@cs.sfu.caSimon Fraser UniversityBurnaby, BC, CanadaAbstractaction domains agents may erroneous beliefs, reasoning effects actions involves reasoning belief change. paper, use transitionsystem approach reason evolution agents beliefs actions executed. actions cause agent perform belief revision others cause agentperform belief update, interaction revision update nonelementary. present set rationality properties describing interactionrevision update, introduce new class belief change operators reasoningalternating sequences revisions updates. belief change operatorscharacterized terms natural shifting operation total pre-orderings interpretations. compare approach related work iterated belief change due action,conclude directions future research.1. Introductioninterested modeling belief change caused executing alternatingsequence actions observations. Roughly, agents perform belief update following actions agents perform belief revision following observations. However, datelittle explicit consideration iterated belief change results observation follows sequence actions. paper, address belief change contextsequences following form.(InitialBeliefs) (Action) (Observation) (Action) (Observation)(1)assume effects actions completely specified infallible. illustratebelief change caused kind alternating sequence simply determined straightforward iteration updates revisions. main issueplausible examples observation lead agent reviseinitial belief state, rather current belief state. goal provide generalmethodology computing iterated belief change due alternating sequences actionsobservations.1.1 Contributions Existing Researchpaper extension previous work (Hunter & Delgrande, 2005). focusaction domains involving single agent execute actions make observations.assumed every change state world due execution action,c2011AI Access Foundation. rights reserved.fiHunter & Delgrandeassumed set available actions given. context, twopossible explanations erroneous belief. First, erroneous belief dueincorrect initial belief. Second, erroneous belief due execution hiddenexogenous action. focus primarily first case, since explicitly concernedsingle agent scenario. briefly describe contributions make areabelief change caused actions.One contribution explicitly specify precise properties hold whenever action followed observation. state properties styleAGM postulates belief revision (Alchourron, Gardenfors, & Makinson, 1985),argue properties hold action domain involving single agentperfect knowledge actions executed. properties iterated belief changespecify natural generalization AGM postulates; such, easilyjustified action domains involving given AGM operator. showsimple examples clear action history plays role interpretationobservation. Therefore, necessary formalize role action historydetermining appropriate belief change. However, problem explicitlyaddressed related work. best knowledge, work first attemptformally specifying high-level interaction belief update belief revisioncaused actions.second contribution, give specific methodology combining belief updateoperator belief revision operator single formalism. particular, define newclass belief change operators, called belief evolution operators. belief evolution operatortakes two arguments: set states alternating sequence actions observations.belief evolution operator defined respect fixed update operatorfixed AGM revision operator . Informally, following correspondencehA1 , 1 , . . . , , n A1 1 n .basic idea simply translate observations conditions initial beliefs.manner, define iterated belief change operator respects interactionproperties handles example problems appropriately.Formally, demonstrate belief evolution operators characterizednatural shifting underlying AGM revision operator. sense, viewiterated belief change modified form revision. general perspective,belief evolution methodology useful combining action formalism AGMrevision operator. Hence, view belief evolution improved methodologyadding revision operator action formalism.third contribution work provide mechanism evaluatingperformance existing epistemic action formalisms regards iterated belief change.common past work extend existing action formalism simply addingformal representation knowledge belief. done, example, actionlanguage (Lobo, Mendez, & Taylor, 2001; Son & Baral, 2001) well SituationCalculus (SitCalc) (Shapiro, Pagnucco, Lesperance, & Levesque, 2000). easy seeextensions fail satisfy interaction properties, sensing actionsextended languages provide appropriate model iterated belief change.hand, suggest SitCalc consider action history appropriately.270fiIterated Belief Change Due Actions Observationsgeneral, argue simply extending action formalism belief revision operatorsufficient. show approaches either lack formal machinery requiredreasoning iterated belief change, make substantive implicit assumptions.work illustrates role action formalism plays reasoning belief change.also becomes clear additional assumptions must made order reasoniterated belief change due actions observations. making role actionformalism salient, better evaluate suitability existing formalisms particularapplications.2. Preliminariessection, introduce preliminary notation definitions related reasoningaction reasoning belief change. also introduce motivating exampleused throughout paper.2.1 Motivating Exampleintroduce Moores litmus paper problem (Moore, 1985) motivating example.problem, beaker containing either acid base, agentholding piece white litmus paper dipped beaker determinecontents. litmus paper turn red placed acid turn blueplaced base. problem provide formal model belief changeoccurs agent uses litmus paper test contents beaker.Intuitively, litmus paper problem seems require agent revise initialbeliefs response observation later point time. example, supposeagent dips paper sees paper turns red. observationcauses agent believe beaker contains acid now, also causes agentbelieve beaker contained acid dipping. refer processprior revision, since agent revises beliefs prior point time. kindphenomenon explicitly discussed many formalisms reasoning beliefchange caused action. return problem periodically introduceformal approach belief change.2.2 Basic Notation Terminologyassume propositional signature composed finite set atomic propositional symbols.use primitive propositional connectives {, }, denotes classical negationdenotes implication. Conjunction, disjunction equivalence definedusual manner, denoted , , respectively. formula propositionalcombination atomic symbols. literal either atomic propositional symbol,atomic propositional symbol preceded negation symbol. Let Lits denote setliterals fixed signature.interpretation propositional signature P function assigns every atomicsymbol truth value. set interpretations P denoted 2P . satisfactionrelation |= defined formula usual recursive definition. formula271fiHunter & Delgrande, define || set interpretations |= , saysatisfiable || 6= .belief state subset 2P . think belief state expressing proposition.Informally, agent belief state believes actual world represented oneinterpretations . observation also set interpretations. intuitionobservation provides evidence actual world set . ordermaintain superficial distinction, use Greek letter range observationsGreek letter range belief states, possible subscripts case.2.3 Transition Systemsaction signature pair hA, Fi A, F non-empty sets symbols. callset action symbols, call F set fluent symbols. Formally, fluentsymbols F propositional variables. action symbols denote actionsagent may perform. effects actions specified transition system.Definition 1 transition system action signature = hA, Fi pair hS, Ri1. set propositional interpretations F,2. R S.set called set states R transition relation. (s, A, s0 ) R,think state s0 possible resulting state could occur action executedstate s. exactly one possible resulting state s0 executedS, say deterministic. refer fluent symbols true falseassigned values f , respectively. Transition systems visualizeddirected graphs, node labeled state edge labeledelement A. terms notation, uppercase letter A, possibly subscripted,range actions. use notation denote finite sequence action symbolsindeterminate length. Also, given sequence actions = hA1 , . . . , i, write;A s0 indicate path s0 follows edges labeledactions A1 , . . . , .useful introduce symbol denote null action never changesstate world. used periodically formal results. Also, technicalreasons, assume throughout paper every action executable every state.transition system specify effects particular action particular state,assume state change action executed. tantamountadding self loops every action every state transition given.Example litmus paper problem represented action signatureh{dip}, {Red , Blue, Acid }i.Intuitively, fluent symbols Red Blue represent colour litmus paper,fluent symbol Acid indicates whether beaker contains acid not.action available dip litmus paper beaker272fiIterated Belief Change Due Actions Observations{Acid }dipdip??{Blue}{Red , Acid }Figure 1: Litmus Testinterest readability, adopt notational convention discussionlitmus paper problem. particular, let set V propositional fluent symbolsstand interpretation symbols V assigned value truesymbols assigned value false. Hence, set {Red} used denoteinterpretation I(Red) = true, I(Blue) = f alse I(Acid) = f alse.standard representation literature reasoning action effects. stress,however, defining states manner; simply using conventionlitmus paper example facilitates specification interpretationsmall set fluent symbols. clear, throughout paper, states actually definedterms interpretations sets propositional variables.effects dipping litmus paper problem given transition systemFigure 1. Note included possible states figure; includedstates change action executed. assume state remainsunchanged dipping action performed states omitted figure.2.4 Belief UpdateBelief update belief change occurs new information acquired regardingchange state world. One standard approach belief update KatsunoMendelzon approach (1991), describes belief update terms set rationalitypostulates. postulates typically referred KM postulates,analyzed, reformulated, criticized several subsequent papers (Boutilier, 1995;Peppas, Nayak, Pagnucco, Foo, Kwok, & Prokopenko, 1996; Lang, 2006). Muchdiscussion focused distinction belief update belief revision,introduce next section.paper, adopt approach belief update beliefs updatedaction rather formula. Intuitively, executing action A, agent updatesbelief state projecting every state state s0 would result actionexecuted state s.273fiHunter & DelgrandeDefinition 2 Let = hS, Ri transition system. update function : 2S 2Sdefined follows= {s0 | (s, A, s0 ) R }.operation actually form action progression; argued elsewherestandard account belief update understood special case kindprogression (Lang, 2006). advantage approach provides simplerepresentation belief change occurs following action conditional effects.Example litmus paper problem, agent believes litmus paper white,known whether beaker contains acid base. Hence, initial belief stateconsists two interpretations specified follows:= {, {Acid }}.executing dip action, new belief state dip consists possible outcomesdip action. Hence, new belief state contains two interpretations. first,Red true rest fluents false. second interpretation, BlueAcid true, rest fluents false. Thus, following dip action, agentbelieves either liquid base litmus paper red liquid acidlitmus paper blue. determine outcome occurred, agent mustobserve actual color paper.2.5 Belief Revisionterm belief revision refers process agent incorporates new informationprior beliefs. section, briefly sketch influential approachbelief revision: AGM approach Alchourron, Gardenfors Makinson (1985).AGM approach belief revision provide specific recipe revision. Instead,set rationality postulates given belief change operator satisfiespostulates called AGM belief revision operator.Let F propositional signature. belief set deductively closed set formulasF. Let + denote so-called belief expansion operator, defined settingK + deductive closure K {}. Let function maps belief setformula new belief set. say AGM belief revision operatorsatisfies following postulates every K .[AGM1][AGM2][AGM3][AGM4][AGM5][AGM6][AGM7][AGM8]K deductively closedKK K +6 K, K + KK = L iff |=|= , K = KK ( ) (K ) +6 K , (K ) + K ( )274fiIterated Belief Change Due Actions Observationsmain intuition behind AGM postulates new information givenmust incorporated, along much K consistently possible. AGMpostulates provide simple set conditions intuitively plausible restrictionsbelief revision operators. Moreover, postulates completely determine specific semanticsrevision terms pre-orderings interpretations (Katsuno & Mendelzon, 1992).defer discussion semantics 5, describe context newbelief change operator.Note presented AGM postulates traditional setting, beliefsobservations given sets propositional formulae. contrast, represent beliefsobservations sets interpretations. However, since work finite language,easy translate two approaches provide translationsrequired.Example litmus paper problem, suppose paper turns red dipping.need represent observation suitable manner revision. stated 2.2observation set interpretations. Informally, observation setinterepretations considered plausible observation.litmus paper example, observation paper red represented setinterpretations Red true.need revise current beliefs observation represents information.Recall current belief statedip = {{Blue}, {Red , Acid }}.Since also represent observations sets interpretations, observationpaper red given set defined follows= {{Red , Acid }, {Red }, {Red , Blue, Acid }, {Red , Blue}}.Note observation consistent current belief state, intersectionnon-empty. Therefore, [AGM3] [AGM4], follows AGM revision operatordefine revised belief state intersection. Hence, AGM revisionoperator , final belief state{{Red , Acid }}.So, dipping litmus paper observing paper red, correctly believebeaker contains acid.3. Belief Update Preceding Belief Revisionstated previously, interested belief change due alternating sequenceactions observations. easiest example consists single action followedsingle observation. However, throughout paper, assume actions infallible,actions infallible effects actions completely specified.275fiHunter & Delgrande{Litmus}dip?{Litmus, Blue}{Litmus, Acid }{Acid }dipdip??{Litmus, Red , Acid }dip?{Acid }Figure 2: Extended Litmus Testassumption, sequence actions difficult handle single action.such, simplest interesting case consider given expression formA1 .(2)case, since single observation, focus entirely interactionrevision update. general case involving several observations complicatedfact implicitly requires form iterated revision. formalism handlesgeneral case, initial focus problems form (2). nextsection, consider example problem illustrate naturalsolution requires initial state revised later point time.use phrase iterated belief change refer scenario beliefsagent change result multiple sequential events. somewhat non-standarduse term, literature iterated belief change concerned(difficult) problem iterated belief revision. constrast, consider problemsform 2 instances iterated belief change sequence events leadingchange beliefs.3.1 Extended Litmus Paper Problemextend litmus paper problem. extended problem like original, exceptallow possibility paper litmus paper; might simplypiece plain white paper. order provide formal representation problem,need extend transition system used represent original problem introducingnew fluent symbol Litmus. Informally, Litmus true case paper actuallylitmus paper.action signature hA, Fi consists = {dip} F = {Red , Blue, Acid , Litmus}.assume transition system action effects given Figure 2, assume givenAGM revision operator .describe sequence events informally. Initially, agent believes paperpiece litmus paper, agent unsure contents beaker. testcontents, agent dips paper beaker. dipping, agent lookspaper observes still white. interested determining plausible finalbelief state.276fiIterated Belief Change Due Actions Observationsgive formal representation problem. initial belief state= {{Litmus}, {Litmus, Acid }}.dipping paper beaker, update belief state follows:dip = {{Litmus, Blue}, {Litmus, Red , Acid }}.point, agent looks paper sees neither blue red.observation represented following set worlds:= {, {Litmus}, {Acid }, {Litmus, Acid }}.naive suggestion simply revise dip . However, guaranteedgive correct result. possible, example, define AGM operator givesfollowing final belief state:0 = {{Litmus}, {Litmus, Acid }}.case, agent believes piece paper white litmus paper. clearlyplausible final belief state.Informally, paper litmus paper, must either red blue dippingaction performed. Hence, neither {Litmus} {Litmus, Acid } plausible statedipping; simply revising observation may give belief state incorrectrevision operator encode constraint. final belief state consistentirely states possible consequences dipping. Even particular AGMoperator give plausible final belief state example, processfinal beliefs obtained sound. kind example, observationdipping actually giving information initial belief state. such, intuitionrational agent revise initial belief state case.suggest rational agent reason follows. dipping paperseeing change colour, agent conclude paper neverlitmus paper begin with. initial belief state modified reflect newbelief calculating effects dipping action. approach ensuresfinal belief state possible outcome dipping. end experiment,agent believe paper litmus paper agentdefinite beliefs regarding contents beaker. Hence, proposeplausible final belief state set{, {Acid }}.simple example serves illustrate fact sometimes useful agentrevise prior belief states face new knowledge. order formalize intuitiongreater generality, need introduce new formal machinery.277fiHunter & Delgrande3.2 Interaction Revision Updatesection, give set formal properties expect hold updatefollowed revision. properties overly restrictive providebasis categorical semantics; simply provide point discussion comparison.underlying assumption action histories infallible. recent observation always incorporated, provided consistent history actionsexecuted. Hence, properties discuss expected hold actiondomains failed actions exogenous actions.briefly present underlying intuitions. Let belief state, letsequence actions, let observation. interested situationagent initial belief state , executed, observedactual state must . adopt shorthand notation abbreviationsequential update element A. three distinct cases consider.1. -states A.2. -states A, -states 2F A.3. -states possible executing A.Case (1) situation observation allows agent refine knowledgeworld. observation , agent believe plausible statesstates also . words, agent adopt beliefstate ( A) .case (2), agent conclude actual state initially .conclusion based underlying assumption action sequence cannot fail,additional assumption new observation incorporated wheneverpossible. assumptions satisfied modifying initial belief stateperforming update. Informally, would like modify initial belief stateminimally manner ensures true executing A. caseoccurs extended litmus paper problem.Case (3) problematic, suggests agent incorrect information: either observation incorrect sequence incorrect. assumingaction histories infallible. such, observation must weakened manner order remain consistent A. cases natural weakening,may necessary abandon observation completely. single observation,approach take. view single observation disjunctive constraintpossible states world, assume observation meaning respectnon-member states. such, agent discovers actual state worldincluded observation, observation offer information all.consider multiple observations, taken flexible approach allowsagent select minimal repair sequence observations.Let sets states, let sequence actions, let update operatorDefinition 2, let AGM revision operator. formalize intuitionsfollowing conditions hold update followed revision.278fiIterated Belief Change Due Actions ObservationsInteraction PropertiesP1. (2F A) 6= ,P2. (2F A) = , =P3. ( A)P4. ( A) 6= , ( A)P5. 2Fgive motivation property. P1 straightforward AGM-type assertionmust hold revising , provided possible executing A. P2 handlessituation impossible -world executing A. case,simply discard observation . Together, P1 P2 formalize underlying assumptionfailed actions.P3 P4 assert revising equivalent taking intersection ,provided intersection non-empty. similar AGM postulates assertingrevisions correspond expansions, provided observation consistentknowledge base.P5 provides justification revising prior belief states face new knowledge.asserts that, revising , must still belief state possibleconsequence executing A. cases, way ensure holdsexecuting modify initial belief state. remark P5 indicateinitial belief state modified.worth noting interaction properties make mention minimal changerespect belief state . notion minimal change implicitrevision operator , notion change respect measure plausibilitycompletely independent stated properties.3.3 Representing HistoriesTransition systems suitable representing Markovian action effects; is, actioneffects depend action executed current state world. However,extended litmus paper problem, saw outcome observation maydepend prior belief states. Even action effects Markovian, followchanges belief Markovian. such, need introduce formal machineryrepresenting histories. interested historical evolution agents beliefs,along actions executed. order so, need introduce trajectoriesbelief states, observations, actions. given action signature hA, F i, usefollowing terminology.1. belief trajectory n-tuple h0 , . . . , n1 belief states.2. observation trajectory n-tuple = h1 , . . . , n 2S .3. action trajectory n-tuple = hA1 , . . . , Ai A.Note that, matter convention, start indices 0 belief trajectoriesstart indices 1 observation action trajectories. rationaleconvention clear later. also adopt convention hinted definitions,279fiHunter & Delgrandewhereby ith component observation trajectory denoted ,ith component action trajectory denoted Ai .remark belief trajectory agents subjective view worldchanged. Hence, belief trajectory represents agents current beliefs worldhistory, historical account agent believed point time.example, extended litmus paper problem, end experiment agentbelieves never holding piece litmus paper. fact agentbelieved holding litmus paper different issue, one representedformal conception belief trajectory.define notion consistency observation trajectories action trajectories. intuition observation trajectory consistent action trajectoryobservation possible, given actions (Aj )jiexecuted.Definition 3 Let = h1 , . . . , n observation trajectory let = hA1 , . . . ,action trajectory. say consistent belieftrajectory h0 , . . . , n that, 1 n,1.2. = i1 Ai .consistent , write A||.pair consisting action trajectory observation trajectory gives completepicture agents view history world. such, useful introducefollowing terminology.Definition 4 world view length n pair W = hA, i, action trajectoryobservation trajectory, length n. say W consistent A||.4. Belief Evolutioninterested providing formal treatment alternating action/observation sequences formA1 1 n .(3)Note implicit tendency associate operators expressionform left right, gives following expression:(. . . (( A1 ) 1 ) ) n .(4)extended litmus paper problem illustrates association lead unsatisfactory results. such, would like propose alternative method evaluatingexpressions form (3). However, discussing expressions form directlysomewhat misleading, since preclude interpretation (4). order makeexplicit computing successive updates revisions, introduce newbelief evolution operator . Intuitively, simply allows us associate informationincorporated manner closer following informal expression:(A1 , 1 , . . . , , n ).280(5)fiIterated Belief Change Due Actions ObservationsNote update revision operators disappeared; left expressiongroups actions observations single sequence, suggesting informationincorporated simultaneously. However, order observations actionsstill significant. Moreover, important keep mind defined respectgiven update revision operators. new operator introduced primarily give usformal tool make explicit interpreting expressions form (3)default interpretation (4).formal definition presented following sections, useexact syntax informal expression (5). actual definition, belief evolutionoperator takes belief state world view arguments. Also, value returnedsingle belief state; belief trajectory. However, (5) provides important underlyingintuition.4.1 Infallible Observationssection, define assumption observations always correct.Formally, amounts restriction world views considered. particular,need consider inconsistent world views. easy see inconsistent worldview possible assumption action histories observationsinfallible.Let s1 (A) denote set states s0 (s0 , A, s) R. call s1 (A)pre-image respect A. following definition generalizes idea givepre-image set states respect sequence actions.Definition 5 Let deterministic transition system, let = hA1 , . . . , letobservation. Define 1 (A) = {s | ;A s0 s0 }.Hence, actual world element following action sequence A,initial state world must 1 (A).illustrative purposes, useful consider world views length 1. Supposeinitial belief state , action observation . Without formally definingbelief evolution operator , give intuitive interpretation expressionformhhAi, hii = h0 , 1 i.agent knows actual world final point time, must1 . Moreover, agent believe 1 possible result executing0 . words, must 0 1 (A). things equal, agentwould like keep much possible. order incorporate 1 (A) keepingmuch possible, agent revise 1 (A). suggests followingsolution.1. 0 = 1 (A),2. 1 = 0 A.reasoning applied world views length greater 1. ideatrace every observation back precondition initial belief state. revising281fiHunter & Delgrandeinitial belief state preconditions, subsequent belief state determinedstandard update operation.following formal definition . definition, n let Aidenote subsequence actions hA1 , . . . , Ai i.Definition 6 Let belief state, let update operator, let AGM revisionoperator, let action trajectory length n let observation trajectorylength n A||. DefinehA, = h0 , . . . , n1. 0 =1(Ai )2. 1, = 0 A1 Ai .remark intersection observation preconditions definition 0 nonempty, A||.following propositions immediate, demonstrate action sequences length 1, operator reduces either revision update. proposition,assume A||.Proposition 1 Let belief state, let = hAi let = h2F i.hA, = h, Ai.Proof Recall assume every action executable every state. follows(2F )1 (A) = 2F . ThereforehA, = h 2F , ( 2F ) Ai= h, Ai.2next result, recall null action never changes state world.Proposition 2 Let belief state, let = hi let = hi.hA, = h , i.ProofSince change state, follows 1 () = . ThereforehA, = h , ( )= h , i.2282fiIterated Belief Change Due Actions ObservationsHence, original revision update operators retrieved operator.such, reasonable compute iterated belief change due action terms beliefevolution.demonstrate belief evolution provides reasonable approach computingoutcome sequence actions observations. stress computing updatesrevisions succession provide reasonable solution many cases. such,want define outcome sequence updates revisions terms beliefevolution operator. Given , define iterated belief changefinal belief state belief trajectoryhhAi, hii.adopt somewhat confusing convention temporarily order prove beliefevolution provides semantics iterated belief change satisfies interaction properties.generally, consider sequence n actions followed single observation .case, define n observation trajectory consisting n 1 instances 2Ffollowed final observation . define iterated belief changefinal belief state belief trajectoryhA, n i.Proposition 3 Let action trajectory let observation. A||n ,iterated belief change defined satisfies interaction properties P1-P5.ProofLet belief state. convention outlined above,= ( 1 (A)) A.demonstrate definition satisfies P1-P5.P1. (2F A) 6= , ( A) .Note antecedent true n consistent. followinginclusions:( 1 (A)) 1 (A) .first inclusion holds [AGM2] plus fact update satisfies (X ) X A.second inclusion holds definition pre-image. Hence, consequent true.P2. (2F A) = , ( A) =antecedent false, since n consistent.283fiHunter & DelgrandeP3. ( A) ( A)Suppose ( A) . s0 maps s0 s. Hence,s0 1 (A). follows [AGM2] s0 1 (A). Since maps s0 s,( 1 (A)) A.P4. ( A) 6= , ( A) ( A)Suppose ( A) 6= . state mapped sequence A.Hence 1 (A) 6= . [AGM3] [AGM4], follows 1 (A) = 1 (A).suppose ( 1 (A)) A. exists s0 1 (A) mapss0 s. s0 1 (A). implies .P5. ( A) 2Fimmediate, ( 1 (A)) 2F (X ) = (X ) (Y ).2three preceding propositions demonstrate suitability natural operatorreasoning interaction revision update.use belief evolution operator give appropriate treatment litmuspaper problem.Example Consider extended litmus paper problem, let= {, {Litmus}, {Acid }, {Litmus, Acid }}.Hence, world view W = hhdipi, hii represents dipping action followed observation paper still white. obtained metric transition system definedHamming distance transitions Figure 2, final belief state Wgiven1 (dip) dip = {, {Acid }} dip= {, {Acid }}.calculation consistent original intuitions, agent revises initialbelief state updating dip action. ensures final beliefstate possible outcome dipping. Moreover, initial belief state revisedpre-image final observation, means modified little possiblestill guaranteeing final observation feasible. Note also final beliefstate given calculation intuitively reasonable. simply indicates contentsbeaker still unknown, agent believes paper litmus paper.Hence, belief evolution operator employs plausible procedure returns desirableresult.4.2 Fallible Observationssection, consider belief evolution case observations may incorrect.Formally, means interested determining outcome belief evolution284fiIterated Belief Change Due Actions Observationsinconsistent world views. case, cannot simply take intersectionobservation pre-images, intersection may empty. basic idea behindapproach define belief evolution respect external notion reliabilityobservation.start defining belief evolution general case, respect totalpre-order elements observation trajectory . order define pre-order,assume given function r maps element integer. actualvalue r(i ) particularly important; function r used impose orderingobservations. interpretr(i ) < r(j )mean reliable j . case, consistency restoreddiscarding either j , j discarded. ranking function observationsmay obtained several ways. example, may induced orderingpossible observations, indicating reliability sensing information.hand, pre-order might simply encode general convention dealing sequentialobservations. example, cases may reasonable prefer recentobservation earlier observation.basic approach following. Given observation trajectoryconsistent A, discard observations manner gives us consistent worldview. precise, discarding observation context means replace2F . discard observations rather weaken them, view contentobservation atomic proposition. guided two basic principles. First,things equal, would like keep much consistently possible.Second, observations must discarded, try keepreliable. informal sketch mind, define w(), set trajectoriesobtained discarding observations .Definition 7 Let observation trajectory length n, let setobservation trajectories length n. define:w() = {0 | 0 1 n, i0 = i0 = 2F }.interested finding trajectories w() consistent A,differing minimally . following definition, observation trajectories equallength n, write 0 shorthand notation indicate i0 every1 n.Definition 8 world view hA, i:hA, = {0 w() | A||0 00 w() 00 0 , A||00 }.0 hA, 0 consistent A, becomes inconsistentdiscarded observations re-introduced. Therefore elements 0 hA,differ minimally , minimal defined terms set-containment.1use reliability ordering observations define reliability orderingobservation trajectories.1. Note reasonable notion minimality could employed here. One naturalalternative would consider minimal change terms cardinality. case, trajectory differs285fiHunter & DelgrandeDefinition 9 0 , 00 hA, , write 00 < 0 j1. k < j < n, r(i ) = k i0 = i00 .2. exists r(i ) = j i00 i0 .3. exist r(i ) = j i0 i00 .Informally, 00 < 0 00 retains reliable observations 0 . minimal trajectories ordering are, therefore, retain plausible observations.Definition 10 set repairs world view hA, respect reliability functionr given by:Rep(A, ) = {0 hA, | 00 hA, 00 < 0 }.Note Rep(A, ) may contain several observation trajectories. Moreover, trajectoryRep(A, ) consistent A, minimally discarding observations keepingreliable observations possible.Definition 6, defined consistent world views. inconsistent world views,use following definition.Definition 11 Let belief state, let action history, let observationtrajectory, let r reliability function. consistent , then:hA, = { hA, 0 | 0 Rep(A, )}.definition well-formed, 0 Rep(A, ) implies A||0 . Note outcomebelief evolution case set belief trajectories.adopt following convention. hA, = {0 }, write hA, = 0 .|Rep(A, )| = 1, belief evolution yields unique belief trajectory. naturalexamples case.Proposition 4 Let hA, world view length n. Let r reliability function6= j implies r(i ) 6= r(j ) 1 i, j n. |Rep(A, )| = 1.Proof Note hA, 6= , always possible find trajectory consistentdiscarding observations . follows immediately Rep(A, )non-empty. Hence |Rep(A, )| 1.suppose exist 0 00 0 Rep(A, ), 00 Rep(A, )06= 00 . Thus{i | i0 6= i00 } =6 .Let j {i | i0 6= i00 } r(j ) minimal. assumption, j unique.j0 = j , 0 < 00 contradicts 00 Rep(A, ). j0 = 2F , 00 < 0minimally case minimal number observations discarded. reasonablearguments containment approach cardinality approach, depending context.Neither approach clear theoretical advantage, development virtually identical.determined paper better served presenting containment approach detail, ratherpresenting series duplicate results different conceptions minimality.286fiIterated Belief Change Due Actions Observationscontradicts 0 Rep(A, ). Therefore, 0 = 00 . follows |Rep(A, )| 1,two elements Rep(A, ) distinct. 2Thus r assigns unique value observation, belief evolution yields uniqueoutcome. return fact next section.cases belief evolution yield unique result, skeptical approachdefined taking union initial belief states. Recall 0 first elementtrajectory . define[0 = {00 | 0 Rep(A, )}.unique belief trajectory defined computing effects actions.trajectory general enough include outcome every minimal repair. kindskeptical approach appropriate situations.4.3 RecencyOne well-known approach dealing sequences observations give precedencerecent information (Nayak, 1994; Papini, 2001). Given observation trajectory ,preference recent information represented framework defining rr(i ) = i. purposes, recency provides concrete reliability orderingobservations, facilitates presentation examples comparison relatedformalisms. such, throughout remainder paper, use denote beliefevolution operator defined respect function r.stress preference recent information convention adoptsimplifies exposition, note convention subjectcriticism (Delgrande, Dubois, & Lang, 2006). Note that, Proposition 4, belief evolutionrecency convention defines unique belief trajectory outcome. such,belief evolution recency convention also defines specific approach iteratedrevision. sequence several observations interspersed null actions longercomputed simply applying single shot revision operator several times. exploreapproach iterated revision implicit belief evolution operators 6.2.conclude section useful result. Thus far, applying operator requirestracing action preconditions back initial state revision, applying action effectsget complete history. concerned final belief state,many cases need go much effort. following proposition,helpful think 2F null observation provides new information.Proposition 5 Let belief state, let action trajectory length n letbelief state A. observation trajectory n 1 observations2F followed single observation , final belief state hA, ( A) .Proofdefinition, final belief state hA,( 1 (A)) A.Since A, intersection 1 (A) non-empty. [AGM3] [AGM4],follows1 (A) = 1 (A)287fiHunter & Delgrandetherefore( 1 (A)) = ( 1 (A)) A.Clearly, right hand side equality equal ( A) . Again, since A,follows [AGM3] [AGM4] ( A) . 2proposition indicates that, given single observation consistentactions executed, simply revise outcome actionsget correct final belief state.5. Defining Belief Evolution Orderings Interpretationsnext two sections, provide characterization belief evolution operators termstotal pre-orders interpretations. restrict attention case involving one actionfollowed one observation. result extends easily case involving n actionsfollowed one observation, action sequences length n simply define new settransitions states. Since prove characterization arbitrary action signature,allowing n actions prior single observation difficult allowing oneaction. present case single action, simplifies exposition allowingus avoid introducing sequences null observations interspersed actions.remark result extend directly case involving several observations,introduce axiomatic account reliability observation.First, need delineate general class belief change functions.Definition 12 combined belief change operator function: 2S hA, 2S 2S .Hence, combined belief change operator takes belief state ordered pair hA,input, returns new belief state.fixed update operator fixed revision operator , consider followingpostulates.I1 (2F A) 6= , hA,= 1 (A) A.I2 (2F A) = , hA,= A.abuse notation letting hA, denote final belief state correspondingbelief trajectory, get following result. proposition, referbelief evolution operator defined update operator revision operator. clear,refers belief evolution operator obtained Definitions 6 11.Proposition 6 Let belief update operator let belief revision operator.belief evolution operator defined , satisfies I1 I2.Proof Let belief evolution operator corresponding . (2F A) 6= ,hA,= 1 (A) definition. Hence satisfies I1. Suppose,hand, (2F A) = . case 1 (A) = . Therefore, hA,= 2F = A.satisfies I2.288fiIterated Belief Change Due Actions Observationsprove converse, suppose satisfies I1 I2. Let belief evolutionoperator defined . Suppose (2F A) 6= . followshA, = 1= hA,(since consistent)(by I1)suppose (2F A) = .hA, = 2F= hA,(since consistent)(by I2)completes proof. 2Hence, postulates I1 I2 provide complete syntactic description belief evolution.characterization make easier state representation result next section.5.1 Translations Orderingsfixed transition system , would like provide characterization combinedbelief change functions represent belief evolution operators . characterization defined terms total pre-orderings interpretations. First needintroduce basic characterization AGM revision operators terms total pre-orders,due Katsuno Mendelzon (1992). presentation differs slightly originaldefine revision operators sets states rather formulas.Definition 13 (Katsuno & Mendelzon, 1992) Given belief state , total pre-orderinterpretations called faithful ranking respect case followingconditions hold:s1 , s2 , s1 = s2 .s1 s2 6 , s1 < s2 .Hence, faithful ranking simply total pre-order minimal elementsmembers . order simplify discussion, introduce following notation.set states ordering superset :min(, ) = {s | -minimal among interpretations )}.following definition characterizes AGM revision operators terms pre-ordersinterpretations.Proposition 7 (Katsuno & Mendelzon, 1992) Given belief state , revision operatorsatisfies AGM postulates exists faithful ranking respectset interpretations := min(, ).remainder section, extend result characterize belief evolution operators.Assume given fixed transition system = hS, Ri defining update operator. following definition gives natural progression operation pre-orderings.289fiHunter & DelgrandeDefinition 14 faithful ranking respect action, defines1 s2exist t1 , t2 (t1 , A, s1 ) R (t2 , A, s2 ) R).t1 t2 .Note generally total pre-order may casestates possible outcomes action A. Hence partial pre-order.think shifted ordering, minimal elements A.following definition associates combined revision operator faithful ranking.Definition 15 Let faithful ranking respect . combined belief changeoperator associated following:min(, ) (2F A) 6=hA,=otherwise.Note operator takes observation action inputs, returns newbelief state. prove class functions definable manner coincidesexactly class belief evolution operators.first prove every faithful ranking defines belief evolution operator.Proposition 8 Let faithful ranking respect let combinedbelief change operator defined . satisfies I1 I2.Proof Let action, let observation, let AGM revision operatordefined Proposition 7. prove satisfies I1 I2 respect .Suppose (2F A) 6= ,hA,= min(, ).remark that, definition,= 1 (A) A.So:hA,= min(1 (A) A, )= min(1 (A), )definition :1 (A) = min(1 (A), )followshA,= ( 1 (A))proves I1 holds.(2F A) = , definition:hA,= A.Hence I2 satisfied. 2prove converse.290fiIterated Belief Change Due Actions ObservationsProposition 9 Let operator satisfying I1 I2 AGM revision function. Given belief state , faithful ranking combined beliefchange operator defined .ProofProposition 7, faithful ranking respect= min(, ). Fix particular let action symbol. Suppose (2F A) 6= .So, I1:hA,= 1 (A) A.definition , equalmin(1 (A), )equivalent to:min(1 (A) A, )Simplifying first argument, get:min(, )wanted show.suppose (2F A) = then,hA,=(by I2)completes proof. 2Hence, class belief evolution operators characterized simply shiftingtotal pre-order defines revision operator. characterization essentiallycorollary Katsuno Mendelzons representation result AGM revision. However,approach represent significant departure iterative approach applyingupdate revision operators. result demonstrates progressionbeliefs actions applied level pre-order usedrevision. manner, relative likelihood states shifted appropriatelyaction executed. ensures later revisions use ordering wouldused initially, captures intuition execution actions changepriori likelihood initial states world.6. Comparison Related WorkMany action formalisms define action effects Markovian. case, example,action languages like (Gelfond & Lifschitz, 1998). action formalisms kindsupplemented sensing actions, natural tendency compute epistemicchange computing effects ontic actions sensing actions succession.implicit approach iterated belief change caused actions epistemic extensions(Lobo et al., 2001; Son & Baral, 2001). seen strategy appropriate291fiHunter & Delgrandelitmus-type problems. However, mean formalismsused reasoning iterated belief change due action. simply meanscare must taken define iterated change correctly.Belief evolution seen formalism competition Markovian formalisms; seen methodology extending Markovian formalisms addressiterated belief change. revision update operators given explicitly, definition corresponding belief evolution operator straightforward. true evenformalisms basic operators relatively sophisticated, definedmulti-agent belief structures Herzig, Lang Marquis (2004).6.1 Situation Calculussection, compare work extended version SitCalc explicitlyrepresents beliefs agents. assume reader familiar SitCalc (Levesque,Pirri, & Reiter, 1998), provide brief introduction notation use.terms SitCalc action theory range domain includes situationsactions. fluent predicate takes situation final argument. SitCalcaction theory includes action precondition axiom action symbol, successorstate axiom fluent symbol, well foundational axioms SitCalc.Informally, situation represents state world, along complete historyactions executed. distinguished constant S0 representsinitial situation, distinguished function symbol represents executionaction. Every situation term written follows:do(An , do(An1 , . . . , do(A1 , S0 ) . . . ).simplify notation, abbreviate situation do([A1 , . . . , ], S0 ).clarify results follow, adopt following convention. Expressionsdo(A, s) used syntactic variables ranging situation terms.also need refer explicitly semantic objects denoted terms given first-orderinterpretation situation calculus theory. Hence, let sM denote situationdenoted situation term first-order interpretation M. adoptconvention denote extensions predicate symbols interpretation.SitCalc extended include representation belief (Shapiro et al., 2000).extension includes distinguished fluent symbol B represents accessibilityrelation situations, similar used modal logics belief. extension alsoincludes distinguished function symbol pl assigns numeric value situation.function pl plausibility function, intended interpretation pl(s1 ) < pl(s2 )s1 plausible s2 . formula Bel(, s) expresses factbelieved situation s, defined follows:Bel(, s) s0 [B(s0 , s) (s00 B(s00 , s) pl(s0 ) pl(s00 ))] [s0 ].formula states believed true every B-accessiblesituation assigned minimal pl-value. words, believed trueplausible worlds considered possible.292fiIterated Belief Change Due Actions ObservationsNote accessibility relation B used define formula init(s) definesset initial situations:init(s) B(s, S0 ).set situations initially believed possible pl-minimal elements init. Sinceinit formula one free variable, defines set situations given first-ordertheory. let initM denote set situations satisfy init interpretationM. successor state axiom pl straightforward, guarantees followingcondition:pl(do(a, s)) = pl(s).order express successor state axiom B, convenient distinguishontic actions change state world, sensing actions simply giveagent information world. ontic actions, successor state axiom Bguarantees following:B(s0 , do(A, s)) s00 (B(s00 , s)) s0 = do(A, s00 ).axiom states accessible executing accessibleworld results executing state considered possible. effects binary sensing actions given special sensing predicate SF (Levesque,1996). purposes, sufficient restrict attention sensing actionssimply determine truth value single fluent symbol. sensing actions, successor state axiom B says s0 B-related do(O, s) case s0 agreesvalue sensed fluent symbol. effects sensing actions SitCalc defineapproach belief revision satisfies five AGM postulates (Shapiro et al., 2000).order compare belief change SitCalc belief evolution, need expresssituations terms states. order simplify discussion, restrict attentionSitCalc action theories every fluent symbol unary, exceptiondistinguished accessibility fluent B. say SitCalc theory elementarysatisfies following conditions:1. set fluent symbols F {B}, F F unary.2. complete.3. Every interpretation |= following properties:(a) |= init(S0 ).(b) |{x | initM (x)}| = 2|F| .(c) |= init(s1 ) init(s2 ) s1 6= s2 , fluent symbol F F|= F (si ) exactly one s1 s2 .Elementary SitCalc theories essentially categorical set initial situations.Given model elementary SitCalc theory, situation sM defines propositional293fiHunter & Delgrandeinterpretation IsM set F unary fluent symbols. Specifically, situationsM , define IsM follows:IsM |= F F (sM ).also use idea associate belief state every situation sM . easereadability, following definition omit superscript situation termsfluent symbols right hand side:[(s,M) = {Is0 | B(s0 , s) (s00 B(s00 , s) pl(s0 ) pl(s00 ))}.Hence (s,M) set states minimal plausibility among situationsB -accessible sM .model elementary SitCalc theory , define belief update, belief revisionbelief evolution. ontic action symbol A, define follows.(s,M) = (do(A,s),M) .Note plausibility function plM defines total pre-order initial situations.Since initial situations 1-1 correspondence interpretations F, followsplM defines total pre-order interpretations F. Let denote AGMrevision operator corresponding ordering. Finally, let denote belief evolutionoperator obtained . ease readability, omit subscripttheory clear.order state main result concisely, introduce simplifying notation. Letsensing action symbol fluent symbol FO , let suitable first-orderinterpretation. define set propositional interpretations F follows:{I | |= F0 }, FOM (sM )Os ={I | |= F0 }, otherwiseInuitively OsM set interpretations agree IsM value fluentFO . following result, let (s,M) hA, stand final belief state givenbelief evolution operation.Proposition 10 Let elementary SitCalc theory, let |= letevolution operator induced M. sensing action ontic action, then:(do([A,O],S0 ),M) = (S0 ,M) hA, OSM0 )i.Proof Without loss generality, assume |= FO (do(A, S0 )). words,assume FO holds situation resulting executing action A.assumption, must prove(do([A,O],S0 ),M) = (S0 ,M) |FO |1 (A) A.FO happens false executing A, changes required proof obvious.Note |= B(s, do([A, O], S0 )) case:294fiIterated Belief Change Due Actions Observations1. = do(A, s1 ) s1 B (sM1 , S0 ),2. FOM (s).Suppose (do([A,O],S0 ),M) . follows = IsM situation termsatisfies conditions (1) (2), also property sM plM -minimal amongsituations B accessible do([A, O], S0 )M . Consider situation term s1condition (1). Clearly IsM|FO |1 (A), |= FO (do(A, s0 )). suppose1exists s2 following properties:1. IsM|FO |1 (A)22. |= B(do([A, O], s2 ), do([A, O]), S0 ))3. plM (sM2 ) < pl (s1 ).successor state axiom pl, followsplM (do(A, s2 )M ) < plM (do(A, s1 )M ) = plM (sM ).contradicts plM -minimality sM among situations B accessibledo([A, O], S0 )M . Therefore, s2 . sM1 pl -minimal among situationssatisfy first two properties defining s2 .Recall elementary, every propositional interpretation |FO |1 (A)equal ItM initial situation t. Note that, |FO |1 (A), = ItMsatisfies points (1) (2) specification s2 above. |FO |1 (A) lessIsMtotal pre-order interpretations defined plM , situation also1satisfies third condition. seen possible. So,pl totalpre-order interpretations defined pl , have:IsM1min(|FO |1 (A),pl )= (S0 ,M) |FO |1 (A)(by definition)then, since sM = do(A, s1 )M :IsM (S0 ,M) |FO |1 (A) A.(do([A,O],S0 ),M) (S0 ,M) |FO |1 (A) A.direction, suppose (S0 ,M) |FO |1 (A) A.0 (S0 ,M) |FO |1 (A) 0 = I. 0 = IsM plM -minimalsituation sM initM |= FO (do(A, s)). Since sM initM , follows|= B(do(A, s), do(A, S0 )).Moreover, since |= FO (do(A, s)), follows|= B(do([A, O], s), do([A, O], S0 )).suppose situation term s1 |= B(s1 , do([A, O], S0 ))initMplM (sM1 ) < pl (do(A, s)) . follows immediately s2295fiHunter & Delgrandedo([A, O], s2 )M = sM1 . Moreover, successor state axiom pl,(sM ). However, since sM initM , contradicts plM minimalityplM (sM)<pl22sM among initial situations. sM1 . Therefore Ido(A,s) do([A,O],S0 ) .Recall Ido(A,s)= IsM = I. Therefore, (do([A,O],S0 ),M) . 2Skimming details, preceding proof simply relies condition |=pl(do(a, s)) = pl(s) every epistemic SitCalc model. fact plausibility valuespersist following execution actions equivalent restricting belief change alwaysrevising initial belief state, determining final belief state simply computingontic action effects. Hence, semantics revision actions SitCalc framedinstance belief evolution. suggest important point discussingbelief change SitCalc. original description approach, belief changedue sensing action identified belief revision (Shapiro et al., 2000).view, fact sensing actions satisfy AGM postulates seenproblem approach. However, explicit fact beliefchange SitCalc form belief evolution, longer problem.expect AGM postulates satisfied, need concerned interactionontic actions sensing actions.conclude section remarking belief evolution operators oneexpressive advantage epistemic extension SitCalc. epistemic extensionconsidered, information obtained sensing actions always correct.result, sensible consider revising F followed F . contrast,belief evolution, simply handled keeping reliable observation. Hence,belief evolution able deal unreliable perception straightforward mannerpossible SitCalc. remark however, inconsistent observationstreated later extension SitCalc postulating exogenous actions accountinconsistent sensing information (Shapiro & Pagnucco, 2004).6.2 Iterated Belief RevisionRecall null action change state world. consideraction domains agents perform , sequential belief revision special casebelief evolution.Observation 1 , unique belief state 0h, = h0 , . . . , 0 i.Since every action null, unique belief state 0 belief state resultssequence observations. section, consider belief evolution operatorsperspective well-known Darwiche-Pearl postulates iterated revision (Darwiche &Pearl, 1997).First, important note belief evolution define iterated revisionsimple sequence AGM revision operations. According Definition 11, inconsistenciesobservations resolved keeping reliable observations. default,take recency measure reliability. illustrate, consider simple example.296fiIterated Belief Change Due Actions Observationsfollowing expression, let denote complementhh, i, h, ii.example, observation followed observation . final belief stateobtained performing two single-shot revisions, however. According Definition11 recency ordering, first observation discarded inconsistentrecent observation. such, final belief state operation .Hence, approach iterated revision implicit belief evolution naiveiteration. therefore reasonable ask implicit iterated revision operator satisfiesexisting rationality postulates.state Darwiche-Pearl postulates terms possible worlds. Let , ,sets possible worlds. Darwiche-Pearl postulates follows.Darwiche-Pearl Postulates[DP1] , ( ) = .[DP2] , ( ) = .[DP3] , ( ) .[DP4] 6 , ( ) 6 .would like determine postulates hold perform belief evolutionnull actions.define iterated revision operator obtained follows:=def h, h, ii.(6)course true apply AGM operator left successively.adopt convention definition iterated revision allows us askDarwiche-Pearl postulates hold. critical remark, however, usingnotational convention defines iterated revision terms belief evolution.Given introduce new notational convention even ask DarwichePearl postulates hold, one might question concerned postulates.words, important check belief evolution operators satisfy keyproperties iterated belief revision? stance postulates matter beliefevolution en using belief evolution operators iterated revisionaccident. Although focus iterated sequences actions observations,cases actions null clearly looking case iteratedrevision. would problematic belief evolution handled cases poorly, wouldlike ensure instances iterated revision handled appropriately. One wayassess appropriateness checking Darwiche-Pearl postulates hold.next result relies following crucial observation. 6= ,( ) 6==otherwiseobservation follows immediately definition belief evolution. usingexpression, prove following result.297fiHunter & DelgrandeProposition 11 Let belief evolution operator let 6= . iteratedrevision operator given (6) satisfies Darwiche-Pearl postulates.Proof Note 1 () = 1 () = . Since 6= , need show DPpostulates satisfied , defined observation above.[DP1], suppose . Since 6= , follows 6= hence= ( ). = , right hand side equal .[DP2], suppose . Hence, = desired conclusion followsimmediately.[DP3], suppose . Since 6= , follows [AGM5] 6= .exists . since , since .Hence 6= , therefore= ( ) .[DP4], suppose 6 . exists .follows , 6= . Translating possible worlds, postulate [AGM7] saysfollowing:6 , ( ) ( ).Since ( ) , implies ( ). then, since 6= followsdefinition . Hence . Therefore 6 .2well known many AGM revision operators satisfy Darwiche-Pearlpostulates applied succession. Proposition 11 shows that, even startsingle-shot revision operator, approach iterated revision induced belief evolutionalways Darwiche-Pearl operator.easy demonstrate belief evolution also satisfies so-called recalcitrancepostulate introduced Nayak, Pagnucco Peppas (2003). Rephrased terms possible worlds belief evolution, recalcitrance following property:(Recalcitrance) 6= , ( h, h, i) .known DP1, DP2, (Recalcitrance) characterize Nayaks lexicographic iterated revision operator epistemic states (Booth & Meyer, 2006). followsapproach iterated revision also satisfies independence postulate introducedindependently Jin Thielscher (2007) well Booth Meyer (2006).gives complete characterization iterated revision operator implicit beliefevolution, perspective Darwiche-Pearl tradition.6.3 Lehmann Postulatessection, consider belief evolution perspective Lehmanns postulates(1995). Given observation trajectories O0 , let O0 denote concatenationtwo sequences. observation, write shorthand hi. Finally,remainder section write abbreviation final belief stateh, Oi. Translated notation, Lehmann postulates follows.298fiIterated Belief Change Due Actions ObservationsLehmann Postulates[L2] (O ) .[L3] (O ) , .[L4] , (O O0 ) = (O O0 ).[L5] , (O O0 ) = (O O0 ).[L6] (O ) 6 , (O O0 ) = (O O0 ).[L7] (O ) (O ).start postulate [L2] remain consistent original numbering. However,omit Lehmanns first postulate states sequences observed formulas defineconsistent theory. Since work directly sets states rather formulas, kindpostulate necessary.perspective iterated belief change, interesting distinctionapproach Lehmanns approach seen looking postulates [L4]-[L6]. Lehmannviews [L4]-[L6] dealing superfluous revisions (Lehmann, 1995). example,postulate [L4], observation superfluous revising observationsalready leads agent believe actual state . such, observingprovide new information. postulate [L4] suggests observationsmay discarded. kind reasoning supported belief evolution,observation may take new meaning following future observations. Postulates [L5][L6] problematic similar reasons.present counterexample illustrates postulates [L4]-[L6] fail beliefevolution.Examplefollows:Let s1 , s2 , s3 states action signature. Define , , O0= {s1 }= {s2 , s3 }= {s3 }= h{s3 }iO0 = h{s1 , s2 }idemonstrate [L4]-[L6] fail example.Let belief evolution operator obtained update operatorAGM revision operator . Note= {s1 } {s3 } = {s3 } .However,(O O0 ) = {s1 } {s1 , s2 } = {s1 }(O O0 ) = {s1 } {s2 } = {s2 }.Hence (O O0 ) 6= (O O0 ), violates [L4]. Since = O, also violates[L5].299fiHunter & DelgrandeLet = {s1 , s3 }. following equalities refute [L6].(O ) = {s3 } 6(O O0 ) = {s1 }(O O0 ) = {s2 }.preceding example demonstrates [L4]-[L6] hold belief evolution;however, perhaps abstract illustrate intuitive problem. levelcommonsense reasoning, instructive imagine situation involving certain birdeither red, yellow black. Postulate [L4] says following informal sequences leadbelief state:Believe(bird red) + Observe(black, red yellow)Believe(bird red) + Observe(black, yellow black, red yellow)However, see sequences perspective beliefevolution operators. sequences, first observation discarded2 . first case,agent left keep initial belief bird red consistentfinal observation. contrast, second case, final two observationscombined suggest bird yellow. Following intuitions AGM revision,agent believes bird yellow. Similar bird colour arguments useddemonstrate whey [L5] [L6] fail belief evolution.Although [L4]-[L6] hold, construct weaker versions hold.claimed reason postulates fail future observations may affectinterpretation observations initially superfluous. avoid problem,modify postulates removing observations follow superfluous observation.Weakening gives following postulates:Weak Lehmann Postulates[L4 ] 6=, = (O ).[L5 ] , (O ) = (O ).[L6 ] (O ) 6 , (O ) = (O ).[L4]-[L6] replaced [L4 ]-[L6 ], belief evolution satisfies resulting setpostulates.Proposition 12 Let belief evolution operator, let 6= let observationtrajectory component non-empty. satisfies [L2], [L3], [L4 ], [L5 ],[L6 ], [L7].2. first observation discarded assumption recent information takes precedence.discussed previously, committed assumption, useful purposecomparison iterated belief revision.300fiIterated Belief Change Due Actions ObservationsProof Since 6= , (O ) = . Hence (O ) ,proves [L2].[L3], suppose (O T) . supposeO.definition,means(O).postulate[AGM7],((O))( (O) ). ( (O) ) = (O ), follows . Therefore.Suppose6= . definition, = (O). Since 6=,follows (O ) = ( (O) ). equalities mind, followingresults prove [L4 ] holds:\(O) ( (O))(since )( (O) )(by [AGM7])(O)(by [AGM8])clear [L5 ] holds, simply assumption implies= .[L6 ], suppose (O ) 6 . follows 6= . definition,means (O ) = (O ), desired result.Since = , follows definition (O ) = (O ). 2Hence, consider influence observations occur future,belief evolution defines approach iterated revision satisfies Lehmannpostulates deal empty belief states.conclude brief remark assumption non-emptyPropositions 11 12. framework, action histories take precedence observations. such, empty observations discarded inconsistent everysequence actions. true even case sequence null actions.accept treatment inconsistent observations, allows inconsistencytreated uniform manner.7. Discussionpresented transition system framework reasoning belief change dueactions observations. suggested agents perform belief update followingaction, perform belief revision following observation. showedinteraction update revision non-elementary. Consequentlyspecified agent consider history actions incorporating newobservation. contrast, existing formalisms reasoning epistemic action effectseither ignore interaction revision update deal implicitly.Hence, provided explicit treatment phenomenon alwaysrecognised related formalisms.fundamental idea motivating work interpretation observationmay depend preceding sequence actions. treatment iterated belief changeincludes two main components. First, introduce set postulates captureintuitions appropriate treatment observation following sequence actions.301fiHunter & DelgrandeInformally, postulates capture intuitions AGM revision domains actionsmay occur. Second, introduce belief evolution operators give concrete recipecombining given update operator given revision operator. Belief evolution operatorssatisfy postulates, along standard postulates iterated revision.class problems appropriate belief evolution describedordering action histories. Let A1 , 1 , . . . , , n alternating sequence actionsobservations. Let denote total pre-order elements sequence. Beliefevolution suitable problems underlying ordering given follows,permutation p1 , . . . , pn 1, . . . , n.A1... p 1 p 2 p nHence belief evolution appropriate total pre-order observations,including case observations considered equally reliable. However,addressed case action histories may incorrect.framed results transition system framework, primarilyprovides simple representation action effects. However, results translatedrelated action formalisms well. example, comparison SitCalc,illustrated revision actions SitCalc implicitly defined terms beliefevolution. results provide general account interaction actionsobservations, grounded context transition systems.worth noting belief evolution operators model specific reasoning problemaddressed general formalisms. example, work,explored use arbitrary plausibility rankings actions observationsreason iterated belief change (Hunter & Delgrande, 2006). Moreover, evendistinction revision update understood pragmatic distinctionmodelling certain kinds reasoning. single generic notion belief changedefined belief revision belief update special cases (Kern-Isberner,2008). perspective, iterated belief change due action simply one particularinstance; instance belief change operations subject certain constraints encode effects actions. believe important instanceworthy detailed study, important aware framedunderstood general level.several directions future research. One direction deals implementation belief evolution solver. previously explored use Answer SetPlanning develop solver iterated belief change (Hunter, Delgrande, & Faber, 2007),believe approach could developed. Another important directionfuture research involves relaxing assumption action histories correct. realistic action domains, agents may incorrect actions occurred.domains, always reasonable discard observation inconsistentperceived action history. Instead, agent consider likelihoodobservation correct well likelihood action history correct. Hence,plausible histories determined considering relative plausibility302fiIterated Belief Change Due Actions Observationsaction observation. Belief evolution operators seen specific case kindreasoning, action occurrences always plausible observations.ReferencesAlchourron, C., Gardenfors, P., & Makinson, D. (1985). logic theory change:Partial meet functions contraction revision. Journal Symbolic Logic, 50 (2),510530.Booth, R., & Meyer, T. (2006). Admissible restrained revision. Journal ArtificialIntelligence Research, 26, 127151.Boutilier, C. (1995). Generalized update: Belief change dynamic settings. ProceedingsFourteenth International Joint Conference Artificial Intelligence (IJCAI1995), pp. 15501556.Darwiche, A., & Pearl, J. (1997). logic iterated belief revision. Artificial Intelligence, 89 (1-2), 129.Delgrande, J., Dubois, D., & Lang, J. (2006). Iterated revision prioritized merging.Proceedings 10th International Conference Principles Knowledge Representation Reasoning (KR2006).Gelfond, M., & Lifschitz, V. (1998). Action languages. Linkoping Electronic ArticlesComputer Information Science, 3 (16), 116.Herzig, A., Lang, J., & Marquis, P. (2004). Revision update multi-agent beliefstructures. Proceedings LOFT 6.Hunter, A., & Delgrande, J. (2005). Iterated belief change: transition system approach.Proceedings International Joint Conference Artificial Intelligence (IJCAI05),pp. 460465.Hunter, A., & Delgrande, J. (2006). Belief change context fallible actions observations. Proceedings National Conference Artificial Intelligence(AAAI06).Hunter, A., Delgrande, J., & Faber, J. (2007). Using answer sets solve belief changeproblems. Proceedings 9th International Conference Logic ProgrammingNon Monotonic Reasoning (LPNMR 2007).Jin, Y., & Thielscher, M. (2007). Iterated belief revision, revised. Artificial Intelligence,171 (1), 118.Katsuno, H., & Mendelzon, A. (1991). difference updating knowledge baserevising it. Proceedings Second International Conference PrinciplesKnowledge Representation Reasoning (KR 1991), pp. 387394.Katsuno, H., & Mendelzon, A. (1992). Propositional knowledge base revision minimalchange. Artificial Intelligence, 52 (2), 263294.Kern-Isberner, G. (2008). Linking iterated belief change operations nonmonotonic reasoning. Proceedings 11th International Conference Principles KnowledgeRepresentation Reasoning (KR2008).303fiHunter & DelgrandeLang, J. (2006). time, revision, update. Proceedings 11th InternationalWorkshop Non-Monotonic Reasoning (NMR 2006).Lehmann, D. (1995). Belief revision, revised. Proceedings Fourteenth InternationalJoint Conference Artificial Intelligence (IJCAI95), pp. 15341541.Levesque, H. (1996). planning presence sensing?. ProceedingsThirteenth National Conference Artificial Intelligence (AAAI96), pp. 11391146.Levesque, H., Pirri, F., & Reiter, R. (1998). Foundations situation calculus.Linkoping Electronic Articles Computer Information Science, 3 (18), 118.Lobo, J., Mendez, G., & Taylor, S. (2001). Knowledge action description languageA. Theory Practice Logic Programming, 1 (2), 129184.Moore, R. (1985). formal theory knowledge action. Hobbs, J., & Moore, R.(Eds.), Formal Theories Commonsense World, pp. 319358. Ablex Publishing.Nayak, A. (1994). Iterated belief change based epistemic entrenchment. Erkenntnis, 41,353390.Nayak, A., Pagnucco, M., & Peppas, P. (2003). Dynamic belief change operators. ArtificialIntelligence, 146, 193228.Papini, O. (2001). Iterated revision operations stemming history agentsobservations. Rott, H., & Williams, M. (Eds.), Frontiers Belief Revision, pp.279301. Kluwer Academic Publishers.Peppas, P., Nayak, A., Pagnucco, M., Foo, N., Kwok, R., & Prokopenko, M. (1996). Revisionvs. update: Taking closer look. Proceedings Twelfth European ConferenceArtificial Intelligence (ECAI96), pp. 9599.Shapiro, S., & Pagnucco, M. (2004). Iterated belief change exogenous actionssituation calculus. Proceedings Sixteenth European Conference ArtificialIntelligence (ECAI04), pp. 878882.Shapiro, S., Pagnucco, M., Lesperance, Y., & Levesque, H. (2000). Iterated belief changesituation calculus. Proceedings Seventh International ConferencePrinciples Knowledge Representation Reasoning (KR 2000), pp. 527538.Morgan Kaufmann Publishers.Son, T., & Baral, C. (2001). Formalizing sensing actions: transition function basedapproach. Artificial Intelligence, 125 (1-2), 1991.304fiJournal Artificial Intelligence Research 40 (2011) 95-142Submitted 07/10; published 01/11Monte-Carlo AIXI ApproximationJoel Venessjoelv@cse.unsw.edu.auUniversity New South Wales National ICT AustraliaKee Siong Ngkeesiong.ng@gmail.comAustralian National UniversityMarcus Huttermarcus.hutter@anu.edu.auAustralian National University National ICT AustraliaWilliam Utherwilliam.uther@nicta.com.auNational ICT Australia University New South WalesDavid Silverdavidstarsilver@googlemail.comMassachusetts Institute TechnologyAbstractpaper introduces principled approach design scalable general reinforcementlearning agent. approach based direct approximation AIXI, Bayesian optimalitynotion general reinforcement learning agents. Previously, unclear whether theoryAIXI could motivate design practical algorithms. answer hitherto open questionarmative, providing first computationally feasible approximation AIXI agent.develop approximation, introduce new Monte-Carlo Tree Search algorithm alongagent-specific extension Context Tree Weighting algorithm. Empirically, present setencouraging results variety stochastic partially observable domains. concludeproposing number directions future research.1. IntroductionReinforcement Learning (Sutton & Barto, 1998) popular influential paradigm agentslearn experience. AIXI (Hutter, 2005) Bayesian optimality notion reinforcement learning agents unknown environments. paper introduces evaluates practical reinforcementlearning agent directly inspired AIXI theory.1.1 General Reinforcement Learning ProblemConsider agent exists within unknown environment. agent interactsenvironment cycles. cycle, agent executes action turn receives observationreward. information available agent history previous interactions.general reinforcement learning problem construct agent that, time, collects muchreward possible (unknown) environment.1.2 AIXI AgentAIXI agent mathematical solution general reinforcement learning problem.achieve generality, environment assumed unknown computable function; i.e.c2011AI Access Foundation. rights reserved.fiVeness, Ng, Hutter, Uther, & Silverobservations rewards received agent, given past actions, computedprogram running Turing machine. AIXI agent results synthesis two ideas:1. use finite-horizon expectimax operation sequential decision theory actionselection;2. extension Solomonos universal induction scheme (Solomono, 1964) future prediction agent context.formally, let U(q, a1 a2 . . . ) denote output universal Turing machine U suppliedprogram q input a1 a2 . . . , N finite lookahead horizon, (q) length bitsprogram q. action picked AIXI time t, executed actions a1 a2 . . . at1received sequence observation-reward pairs o1 r1 o2 r2 . . . ot1 rt1 environment,given by:= arg max. . . max[rt + + rt+m ]2(q) .(1)ot rtat+mq:U(q,a1 ...at+m )=o1 r1 ...ot+m rt+mot+m rt+mIntuitively, agent considers sum total reward possible futures stepsahead, weighs complexity programs consistent agents pastgenerate future, picks action maximises expected future rewards. Equation (1)embodies one line major ideas Bayes, Ockham, Epicurus, Turing, von Neumann, Bellman,Kolmogorov, Solomono. AIXI agent rigorously shown Hutter (2005) optimalmany dierent senses word. particular, AIXI agent rapidly learn accuratemodel environment proceed act optimally achieve goal.Accessible overviews AIXI agent given Legg (2008) Hutter (2007).complete description agent found work Hutter (2005).1.3 AIXI PrincipleAIXI agent asymptotically computable, means algorithmic solutiongeneral reinforcement learning problem. Rather best understood Bayesian optimalitynotion decision making general unknown environments. such, role general AI research viewed in, example, way minimax empirical risk minimisationprinciples viewed decision theory statistical machine learning research. principlesdefine optimal behaviour computational complexity issue, provide important theoretical guidance design practical algorithms. paper demonstrates,first time, practical agent built AIXI theory.1.4 Approximating AIXIseen Equation (1), two parts AIXI. first expectimax searchfuture call planning. second use Bayesian mixtureTuring machines predict future observations rewards based past experience; calllearning. parts need approximated computational tractability. manydierent approaches one try. paper, opted use generalised version UCTalgorithm (Kocsis & Szepesvari, 2006) planning generalised version Context TreeWeighting algorithm (Willems, Shtarkov, & Tjalkens, 1995) learning. combination ideas,together attendant theoretical experimental results, form main contributionpaper.96fiA Monte-Carlo AIXI Approximation1.5 Paper Organisationpaper organised follows. Section 2 introduces notation definitions usedescribe environments accumulated agent experience, including familiar notions reward,policy value functions setting. Section 3 describes general Bayesian approachlearning model environment. Section 4 presents Monte-Carlo Tree Search procedureuse approximate expectimax operation AIXI. followed descriptionContext Tree Weighting algorithm generalised use agent settingSection 5. put two ideas together Section 6 form AIXI approximation algorithm.Experimental results presented Sections 7. Section 8 provides discussion relatedwork limitations current approach. Section 9 highlights number areas futureinvestigation.2. Agent Settingsection introduces notation terminology use describe strings agent experience, true underlying environment agents model true environment.Notation. string x1 x2 . . . xn length n denoted x1:n . prefix x1: j x1:n , j n,denoted x j x< j+1 . notation generalises blocks symbols: e.g. ax1:n denotesa1 x1 a2 x2 . . . xn ax< j denotes a1 x1 a2 x2 . . . j1 x j1 . empty string denoted .concatenation two strings r denoted sr.2.1 Agent Setting(finite) action, observation, reward spaces denoted A, O, R respectively. Also,X denotes joint perception space R.Definition 1. history h element (A X) (A X) A.following definition states environment takes form probability distributionpossible observation-reward sequences conditioned actions taken agent.Definition 2. environment sequence conditional probability functions {0 , 1 , 2 , . . . },n : Density (Xn ), satisfiesa1:n x<n : n1 (x<n | a<n ) =n (x1:n | a1:n ).(2)xn Xbase case, 0 ( | ) = 1.Equation (2), called chronological condition (Hutter, 2005), captures natural constraintaction eect earlier perceptions x<n . convenience, drop index n nonwards.Given environment , define predictive probability(xn | ax<n ) :=(x1:n | a1:n )(x<n | a<n )(3)a1:n x1:n (x<n | a<n ) > 0. follows(x1:n | a1:n ) = (x1 | a1 )(x2 | ax1 a2 ) (xn | ax<n ).97(4)fiVeness, Ng, Hutter, Uther, & SilverDefinition 2 used two distinct ways. first means describing true underlyingenvironment. may unknown agent. Alternatively, use Definition 2 describeagents subjective model environment. model typically learnt, oftenapproximation true environment. make distinction clear, referagents environment model talking agents model environment.Notice ( | h) arbitrary function agents previous history h. definitionenvironment suciently general encapsulate wide variety environments, including standardreinforcement learning setups MDPs POMDPs.2.2 Reward, Policy Value Functionscast familiar notions reward, policy value (Sutton & Barto, 1998) setup.agents goal accumulate much reward lifetime. precisely,agent seeks policy allow maximise expected future reward fixed, finite,arbitrarily large horizon N. instantaneous reward values assumed bounded.Formally, policy function maps history action. define Rk (aort ) := rk1 k t, following definition expected future value agent actingparticular policy:Definition 3. Given history ax1:t , m-horizon expected future reward agent actingpolicy : (A X) respect environment is:t+mfififi(5)v (, ax1:t ) := ERi (axt+m ) fifi x1:t ,i=t+1< k + m, ak := (ax<k ). quantity vm(, ax1:t at+1 ) defined similarly, exceptat+1 longer defined .optimal policy policy maximises expected future reward. maximalachievable expected future reward agent history h environment looking steps aheadVm (h) := vm( , h). easy see h (A X) ,Vm (h)= maxat+1xt+1(xt+1 | hat+1 ) maxat+mxt+mt+m(xt+m | haxt+1:t+m1 at+m )ri .(6)i=t+1convenience, often refer Equation (6) expectimax operation. Furthermore,m-horizon optimal action at+1 time + 1 related expectimax operationat+1 = arg max Vm (ax1:t at+1 ).at+1(7)Equations (5) (6) modified handle discounted reward, however focusfinite-horizon case since aligns AIXI allows simplified presentation.3. Bayesian Agentsmentioned earlier, Definition 2 used describe agents subjective model trueenvironment. Since assuming agent initially know true environment,98fiA Monte-Carlo AIXI Approximationdesire subjective models whose predictive performance improves agent gains experience.One way provide model take Bayesian perspective. Instead committingsingle fixed environment model, agent uses mixture environment models. requirescommitting class possible environments (the model class), assigning initial weightpossible environment (the prior), subsequently updating weight model using Bayesrule (computing posterior) whenever experience obtained. process learningthus implicit within Bayesian setup.mechanics procedure reminiscent Bayesian methods predict sequences(single typed) observations. key dierence agent setup prediction mayalso depend previous agent actions. incorporate using action conditionaldefinitions identities Section 2.Definition 4. Given countable model class := {1 , 2 , . . . } prior weight w0 > 0w0 = 1, mixture environment model (x1:n | a1:n ) :=w0 (x1:n | a1:n ).next proposition allows us use mixture environment model whenever useenvironment model.Proposition 1. mixture environment model environment model.Proof. a1:n x<n Xn1(x1:n | a1:n ) =w0 (x1:n | a1:n ) =w0(x1:n | a1:n ) = (x<n | a<n )xn Xxn Xxn Xfinal step follows application Equation (2) Definition 4.importance Proposition 1 become clear context planning environmentmodels, described Section 4.3.1 Prediction Mixture Environment Modelmixture environment model environment model, simply use:(x1:n | a1:n )(8)(xn | ax<n ) =(x<n | a<n )predict next observation reward pair. Equation (8) also expressed terms convexcombination model predictions, model weighted posterior,w0 (x1:n | a1:n )=w (xn | ax<n ),(xn | ax<n ) =w0 (x<n | a<n ) n1posterior weightwn1environment model givenw (x<n | a<n )wn1 := 0= Pr( | ax<n )w0 (x<n | a<n )(9)|M| finite, Equations (8) (3.1) maintained online O(|M|) time usingfact(x1:n | a1:n ) = (x<n | a<n )(xn | ax<n a),follows Equation (4), incrementally maintain likelihood term model.99fiVeness, Ng, Hutter, Uther, & Silver3.2 Theoretical Propertiesshow good model (unknown) environment M, agent usingmixture environment model(x1:n | a1:n ) :=w0 (x1:n | a1:n )(10)predict well. proof adaptation work Hutter (2005). present fullproof instructive directly relevant many dierent kinds practical Bayesianagents.First state useful entropy inequality.Lemma 1 (Hutter, 2005). Let {yi } {zi } two probability distributions, i.e. yi 0, zi 0,yi = zi = 1.yi(yi zi )2yi ln .ziTheorem 1. Let true environment. -expected squared dierence boundedfollows. n N, a1:n ,n()2{}(x<k | a<k ) (xk | ax<k ak ) (xk | ax<k ak ) min ln w0 + D1:n ( ) ,k=1 x1:kD1:n ( ) :=x1:n1:n | a1:n )(x1:n | a1:n ) ln (x(x1:n | a1:n ) KL divergence ( | a1:n ) ( | a1:n ).Proof. Combining Sections 3.2.8 5.1.3 work Hutter (2005) getn()2(x<k | a<k ) (xk | ax<k ak ) (xk | ax<k ak )k=1 x1:k=nk=1 x<kn(x<k | a<k )(xk(x<k | a<k )k=1 x<kn(xk | ax<k ak ) (xk | ax<k ak )(xk | ax<k ak ) lnxk(xk | ax<k ak )(xk | ax<k ak )(xk | ax<k ak )(xk | ax<k ak )k=1 x1:kn () (x | ax )k<k k=(x1:n | a1:n ) ln(x|axak )k<kxk=1 x=1:k=n(x1:k | a1:k ) ln=x1:n=x1:n[Lemma 1][Equation (3)][Equation (2)]k+1:n(x1:n | a1:n ) lnk=1 x1:n)2(x1:n | a1:n )nk=1(x1:n | a1:n ) lnln(xk | ax<k ak )(xk | ax<k ak )(xk | ax<k ak )(xk | ax<k ak )(x1:n | a1:n )(x1:n | a1:n )[Equation (4)]100fiA Monte-Carlo AIXI Approximation[](x1:n | a1:n ) (x1:n | a1:n )=(x1:n | a1:n ) ln[arbitrary M](x1:n | a1:n ) (x1:n | a1:n )x1:n(x1:n | a1:n )(x1:n | a1:n )=(x1:n | a1:n ) ln+(x1:n | a1:n ) ln(x1:n | a1:n ) x(x1:n | a1:n )x1:n1:n(x1:n | a1:n )D1:n ( ) +(x1:n | a1:n ) ln[Definition 4]wx1:n0 (x1:n | a1:n )= D1:n ( ) ln w0 .Since inequality holds arbitrary M, holds minimising .Theorem 1, take supremum n r.h.s limit n l.h.s.supn D1:n ( ) < minimising , infinite sum l.h.s finite(xk | ax<k ak ) converges suciently fast (xk | ax<k ak ) k probability 1, hencepredicts rapid convergence. long D1:n ( ) = o(n), still convergesweaker Cesaro sense. contrapositive statement tells us fails predictenvironment well, good model M.3.3 AIXI: Universal Bayesian AgentTheorem 1 motivates construction Bayesian agents use rich model classes. AIXIagent seen limiting case viewpoint, using largest model class expressibleTuring machine.Note AIXI handle stochastic environments since Equation (1) shown formally equivalent= arg max. . . max[rt + + rt+m ]2K() (x1:t+m | a1:t+m ),(11)ot rtat+mMUot+m rt+m(x1:t+m | a1 . . . at+m ) probability observing x1 x2 . . . xt+m given actions a1 a2 . . . at+m ,class MU consists enumerable chronological semimeasures (Hutter, 2005), includescomputable , K() denotes Kolmogorov complexity (Li & Vitanyi, 2008) respectU. case environment computable functionU (x1:t | a1:t ) :=2K() (x1:t | a1:t ),(12)MUTheorem 1 shows n N a1:n ,n()2(x<k | a<k ) (xk | ax<k ak ) U (xk | ax<k ak ) K() ln 2.(13)k=1 x1:k3.4 Direct AIXI Approximationposition describe approach AIXI approximation. prediction, seekcomputationally ecient mixture environment model replacement U . Ideally,retain U bias towards simplicity generality. achieved placingsuitable Ockham prior set candidate environment models.101fiVeness, Ng, Hutter, Uther, & Silverplanning, seek scalable algorithm can, given limited set resources, computeapproximation expectimax action givenat+1 = arg max VmU (ax1:t at+1 ).at+1main diculties course computational. next two sections introduce two algorithms used (partially) fulfill criteria. subsequent combinationconstitute AIXI approximation.4. Expectimax Approximation Monte-Carlo Tree SearchNave computation expectimax operation (Equation 6) takes O(|A X|m ) time, unacceptabletiny values m. section introduces UCT, generalisation popular MonteCarlo Tree Search algorithm UCT (Kocsis & Szepesvari, 2006), used approximatefinite horizon expectimax operation given environment model . environment modelsubsumes MDPs POMDPs, UCT eectively extends UCT algorithm wider classproblem domains.4.1 BackgroundUCT proven particularly eective dealing dicult problems containing large statespaces. requires generative model given state-action pair (s, a) produces subsequent state-reward pair (s , r) distributed according Pr(s , r | s, a). successively samplingtrajectories state space, UCT algorithm incrementally constructs search tree,node containing estimate value state. Given enough time, estimatesconverge true values.UCT algorithm realised replacing notion state UCT agent historyh (which always sucient statistic) using environment model predict nextpercept. main subtlety extension history condition perceptprobability (or | h) needs updated search. reflect extra informationagent hypothetical future point time. Furthermore, Proposition 1 allows UCTinstantiated mixture environment model, directly incorporates model uncertaintyagent planning process. gives (in principle, provided model class containstrue environment ignoring issues limited computation) well known Bayesian solutionexploration/exploitation dilemma; namely, reduction model uncertainty would leadhigher expected future reward, UCT would recommend information gathering action.4.2 OverviewUCT best-first Monte-Carlo Tree Search technique iteratively constructs search treememory. tree composed two interleaved types nodes: decision nodes chance nodes.correspond alternating max sum operations expectimax operation.node tree corresponds history h. h ends action, chance node; h endsobservation-reward pair, decision node. node contains statistical estimatefuture reward.Initially, tree starts single decision node containing |A| children. Much like existingMCTS methods (Chaslot, Winands, Uiterwijk, van den Herik, & Bouzy, 2008a), four102fiA Monte-Carlo AIXI Approximationa1o1o2a2a3o3o4future reward estimateFigure 1: UCT search treeconceptual phases single iteration UCT. first selection phase, searchtree traversed root node existing leaf chance node n. second expansionphase, new decision node added child n. third simulation phase,rollout policy conjunction environment model used sample possible futurepath n fixed distance root reached. Finally, backpropagation phaseupdates value estimates node reverse trajectory leading back root. Whilsttime remains, four conceptual operations repeated. time limit reached,approximate best action selected looking value estimates children rootnode.selection phase, action selection decision nodes done using policy balancesexploration exploitation. policy two main eects:gradually move estimates future reward towards maximum attainable futurereward agent acted optimally.cause asymmetric growth search tree towards areas high predicted reward,implicitly pruning large parts search space.future reward leaf nodes estimated choosing actions according heuristic policytotal actions made agent, search horizon. heuristicestimate helps agent focus exploration useful parts search tree, practiceallows much larger horizon brute-force expectimax search.UCT builds sparse search tree sense observations added chance nodesgenerated along sample path. full-width expectimax search tree wouldsparse; possible stochastic outcome would represented distinct node searchtree. expectimax, branching factor chance nodes thus |O|, means searchingeven moderate sized intractable.Figure 1 shows example UCT tree. Chance nodes denoted stars. Decision nodesdenoted circles. dashed lines star node indicate childrenexpanded. squiggly line base leftmost leaf denotes execution rolloutpolicy. arrows proceeding node indicate flow information back tree;defined detail below.103fiVeness, Ng, Hutter, Uther, & Silver4.3 Action Selection Decision Nodesdecision node always contain |A| distinct children, chance nodes. Associateddecision node representing particular history h value function estimate, V(h).selection phase, child need picked exploration. Action selectionMCTS poses classic exploration/exploitation dilemma. one hand need allocate enoughvisits children ensure accurate estimates them, handneed allocate enough visits maximal action ensure convergence node valuemaximal child node.Like UCT, UCT recursively uses UCB policy (Auer, 2002) n-armed bandit settingdecision node determine action needs exploration. Although uniformlogarithmic regret bound longer carries across bandit setting, UCB policyshown work well practice complex domains computer Go (Gelly & Wang, 2006)General Game Playing (Finnsson & Bjornsson, 2008). policy advantage ensuringdecision node, every action eventually gets explored infinite number times,best action selected exponentially often actions lesser utility.Definition 5. visit count (h) decision node h number times h sampledUCT algorithm. visit count chance node found taking action h definedsimilarly, denoted (ha).Definition 6. Suppose remaining search horizon instantaneous reward boundedinterval [, ]. Given node representing history h search tree, action pickedUCB action selection policy is:(h))1V(ha) + C log(T(ha) > 0;m()(ha)(14)aUCB (h) := arg maxaAotherwise,C R positive parameter controls ratio exploration exploitation.multiple maximal actions, one chosen uniformly random.Note need linear scaling V(ha) Definition 6 UCB policyapplicable rewards confined [0, 1] interval.4.4 Chance NodesChance nodes follow immediately action selected decision node. chancenode ha following decision node h contains estimate future utility denoted V(ha).Also associated chance node ha density ( | ha) observation-reward pairs.action performed node h, ( | ha) sampled generate nextobservation-reward pair or. seen before, node haor added childha.4.5 Estimating Future Reward Leaf Nodesleaf decision node encountered depth k < tree, means estimating futurereward remaining k time steps required. MCTS methods use heuristic rollout policyestimate sum future rewardsi=k ri . involves sampling action (h),104fiA Monte-Carlo AIXI Approximationsampling percept ( | ha), appending aor current history h repeatingprocess horizon reached. procedure described Algorithm 4. natural baselinepolicy random , chooses action uniformly random time step.number simulations tends infinity, structure UCT search tree convergesfull depth expectimax tree. occurs, rollout policy longer used UCT.implies asymptotic value function estimates UCT invariant choice. practice, time limited, enough simulations performed grow fullexpectimax tree. Therefore, choice rollout policy plays important role determiningoverall performance UCT. Methods learning online discussed future workSection 9. Unless otherwise stated, subsequent results use random .4.6 Reward Backupselection phase completed, path nodes n1 n2 . . . nk , k m, traversedroot search tree n1 leaf nk . 1 j k, statistics maintainedhistory hn j associated node n j updated follows:V(hn j )(hn j )(hn j ) + 11ri(hn j ) + 1 i= jV(hn j ) +(hn j ) (hn j ) + 1(15)(16)Equation (15) computes mean return. Equation (16) increments visit counter. Notebackup operation applied decision chance nodes.4.7 Pseudocodepseudocode UCT algorithm given.percept received, Algorithm 1 invoked determine approximate bestaction. simulation corresponds single call Sample Algorithm 1. performingnumber simulations, search tree whose root corresponds current history h constructed. tree contain estimates Vm (ha) A. available thinking timeexceeded, maximising action ah := arg maxaA Vm (ha) retrieved BestAction. Importantly,Algorithm 1 anytime, meaning approximate best action always available. allowsagent eectively utilise available computational resources decision.Algorithm 1 UCT(h, m)Require: history hRequire: search horizon NInitialise()repeat3:Sample(, h, m)4: time5: return BestAction(, h)1:2:simplicity exposition, Initialise understood simply clear entire search tree. practice, possible carry across information one time step another.105fiVeness, Ng, Hutter, Uther, & Silversearch tree obtained end time t, aor agents actual action experience timet, keep subtree rooted node (hao) make search tree t+1use beginning next time step. remainder nodes deleted.Algorithm 2 describes recursive routine used sample single future trajectory. usesSelectAction routine choose moves decision nodes, invokes Rollout routineunexplored leaf nodes. Rollout routine picks actions according rollout policy(remaining) horizon reached, returning accumulated reward. complete trajectorylength simulated, value estimates updated node traversed per Section 4.6.Notice recursive calls Lines 6 11 append recent percept actionhistory argument.Algorithm 2 Sample(, h, m)Require: search treeRequire: history hRequire: remaining search horizon N1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:= 0return 0else (h) chance nodeGenerate (o, r) (or | h)Create node (hor) (hor) = 0reward r + Sample(, hor, 1)else (h) = 0reward Rollout(h, m)elseSelectAction(, h)reward Sample(, ha, m)end1[reward + (h)V(h)]V(h) (h)+1(h) (h) + 1return rewardaction chosen SelectAction specified UCB policy described Definition 6.selected child explored before, new node added search tree. constantC parameter used control shape search tree; lower values C create deep,selective search trees, whilst higher values lead shorter, bushier trees. UCB automatically focusesattention best looking action way sample estimate V (h) converges V (h),whilst still exploring alternate actions suciently often guarantee best actioneventually found.4.8 Consistency UCTLet true underlying environment. establish link expectimax valueVm (h) estimate Vm (h) computed UCT algorithm.Kocsis Szepesvari (2006) show appropriate choice C, UCT algorithmconsistent finite horizon MDPs. interpreting histories Markov states, general agent106fiA Monte-Carlo AIXI ApproximationAlgorithm 3 SelectAction(, h)Require: search treeRequire: history hRequire: exploration/exploitation constant C7:U = {a : (ha) = 0}U , {}Pick U uniformly randomCreate node (ha)returnelse{}log(T (h))1return arg max m() V(ha) + C(ha)8:end1:2:3:4:5:6:aAAlgorithm 4 Rollout(h, m)Require: history hRequire: remaining search horizon NRequire: rollout function1:2:3:4:5:6:7:8:reward 0= 1Generate (h)Generate (o, r) (or | ha)reward reward + rh haorendreturn rewardproblem reduces finite horizon MDP. means results Kocsis Szepesvari(2006) directly applicable. Restating main consistency result notation,()h lim Pr |Vm (h) Vm (h)| = 1,(h)(17)is, Vm (h) Vm (h) probability 1. Furthermore, probability suboptimal action(with respect Vm ()) picked UCT goes zero limit. Details analysisfound work Kocsis Szepesvari (2006).4.9 Parallel Implementation UCTMonte-Carlo Tree Search routine, Algorithm 1 easily parallelised. main ideaconcurrently invoke Sample routine whilst providing appropriate locking mechanismsinterior nodes search tree. highly scalable parallel implementation beyond scopepaper, worth noting ideas applicable high performance Monte-Carlo Go programs(Chaslot, Winands, & Herik, 2008b) easily transferred setting.107fiVeness, Ng, Hutter, Uther, & Silver5. Model Class Approximation using Context Tree Weightingturn attention construction ecient mixture environment model suitablegeneral reinforcement learning problem. computation issue, would sucientfirst specify large model class M, use Equations (8) (3.1) online prediction.problem approach least O(|M|) time required process new pieceexperience. simply slow enormous model classes required general agents.Instead, section describe predict O(log log |M|) time, using mixture environmentmodel constructed adaptation Context Tree Weighting algorithm.5.1 Context Tree WeightingContext Tree Weighting (CTW) (Willems et al., 1995; Willems, Shtarkov, & Tjalkens, 1997)ecient theoretically well-studied binary sequence prediction algorithm works wellpractice (Begleiter, El-Yaniv, & Yona, 2004). online Bayesian model averaging algorithmcomputes, time point t, probabilityPr(y1:t ) =Pr(M) Pr(y1:t | M),(18)y1:t binary sequence seen far, prediction sux tree (Rissanen, 1983; Ron,Singer, & Tishby, 1996), Pr(M) prior probability M, summation prediction sux trees bounded depth D. huge class, covering D-order Markov processes.nave computation (18) takes time O(22 ); using CTW, computation requires O(D) time.section, outline two ways CTW generalised compute probabilitiesformPr(x1:t | a1:t ) =Pr(M) Pr(x1:t | M, a1:t ),(19)x1:t percept sequence, a1:t action sequence, prediction sux tree(18). generalisations allow CTW used mixture environment model.5.2 Krichevsky-Trofimov Estimatorstart brief review KT estimator (Krichevsky & Trofimov, 1981) Bernoullidistributions. Given binary string y1:t zeros b ones, KT estimate probabilitynext symbol follows:b + 1/2a+b+1= 0 | y1:t ) := 1 Prkt (Yt+1 = 1 | y1:t ).Prkt (Yt+1 = 1 | y1:t ) :=Prkt (Yt+1(20)(21)KT estimator obtained via Bayesian analysis putting uninformative (JereysBeta(1/2,1/2)) prior Pr() 1/2 (1 )1/2 parameter [0, 1] Bernoulli distribution. (20)-(21), obtain following expression block probability string:Prkt (y1:t ) = Prkt (y1 | )Prkt (y2 | y1 ) Prkt (yt | y<t )= b (1 )a Pr() d.108fiA Monte-Carlo AIXI Approximation????0???1 = 0.1?? 01???101 = 0.300 = 0.5Figure 2: example prediction sux treeSince Prkt (s) depends number zeros ones b string s, let 0a 1b denotestring zeroes b ones,Prkt (s) = Prkt (0as 1bs ) =1/2(1 + 1/2) (a 1/2)1/2(1 + 1/2) (b 1/2).(a + b )!(22)write Prkt (a, b) denote Prkt (0a 1b ) following. quantity Prkt (a, b) updatedincrementally (Willems et al., 1995) follows:+ 1/2Prkt (a, b)a+b+1b + 1/2Prkt (a, b),Prkt (a, b + 1) =a+b+1Prkt (a + 1, b) =(23)(24)base case Prkt (0, 0) = 1.5.3 Prediction Sux Treesnext describe prediction sux trees, form variable-order Markov models.following, work binary trees left edges labeled 1 rightedges labeled 0. node binary tree identified string {0, 1}follows: represents root node M; n {0, 1} node M, n1 n0 representleft right child node n respectively. set Ms leaf nodes L(M) {0, 1} formcomplete prefix-free set strings. Given binary string y1:t depth M, defineM(y1:t ) := yt yt1 . . . yt , (unique) positive integer yt yt1 . . . yt L(M).words, M(y1:t ) represents sux y1:t occurs tree M.Definition 7. prediction sux tree (PST) pair (M, ), binary tree associatedleaf node l probability distribution {0, 1} parametrised l . callmodel PST parameter PST, accordance terminologyWillems et al. (1995).prediction sux tree (M, ) maps binary string y1:t , depth M,probability distribution M(y1:t ) ; intended meaning M(y1:t ) probabilitynext bit following y1:t 1. example, PST shown Figure 2 maps string 1110M(1110) = 01 = 0.3, means next bit 1110 1 probability 0.3.practice, use prediction sux trees binary sequence prediction, need learnmodel parameter prediction sux tree data. deal model-learningpart later. Assuming model PST known/given, parameter PST learntusing KT estimator follows. start l := Prkt (1 | ) = 1/2 leaf node l M.109fiVeness, Ng, Hutter, Uther, & Silverdepth M, first bits y1:d input sequence set aside use initialcontext variable h denoting bit sequence seen far set y1:d . repeatfollowing steps long needed:1. predict next bit using distribution M(h) ;2. observe next bit y, update M(h) using Formula (20) incrementing either b accordingvalue y, set h := hy.5.4 Action-Conditional PSTdescribes PST used binary sequence prediction. agent setting,reduce problem predicting history sequences general non-binary alphabetspredicting bit representations sequences. Furthermore, ever condition actions. achieved appending bit representations actions input sequence withoutcorresponding update KT estimators. ideas formalised.convenience, assume without loss generality |A| = 2lA |X| = 2lXlA , lX > 0. Given A, denote = a[1, lA ] = a[1]a[2] . . . a[lA ] {0, 1}lAbit representation a. Observation reward symbols treated similarly. Further, bitrepresentation symbol sequence x1:t denoted x1:t = x1 x2 . . . xt .action-conditional sequence prediction using PST given model M, startl := Prkt (1 | ) = 1/2 leaf node l M. also set aside suciently long initialportion binary history sequence corresponding first cycles initialise variableh usual. following steps repeated long needed:1. set h := ha, current selected action;2. := 1 lX(a) predict next bit using distribution M(h) ;(b) observe next bit x[i], update M(h) using Formula (20) according value x[i],set h := hx[i].Let model prediction sux tree, a1:t action sequence, x1:t Xtobservation-reward sequence, h := ax1:t . node n M, define h M,nh M,n := hi1 hi2 hik(25)1 i1 < i2 < < ik and, i, {i1 , i2 , . . . ik } hi observation-reward bitn prefix M(h1:i1 ). words, h M,n consists observation-reward bitscontext n. Thus following expression probability x1:t given a1:t :Pr(x1:t | M, a1:t ) ==Pr(xi | M, ax<i ai )i=1lXPr(xi [ j] | M, ax<i ai xi [1, j 1])i=1 j=1=Prkt (h M,n ).nL(M)110(26)fiA Monte-Carlo AIXI Approximationlast step follows grouping individual probability terms according noden L(M) bit falls observing Equation (22). deals actionconditional prediction using single PST. show perform ecient actionconditional prediction using Bayesian mixture PSTs. First specify prior PST models.5.5 Prior Models PSTsprior Pr(M) := 2D (M) derived natural prefix coding tree structure PST.coding scheme works follows: given model PST maximum depth D, pre-ordertraversal tree performed. time internal node encountered, write 1.time leaf node encountered, write 0 depth leaf node less D; otherwisewrite nothing. example, = 3, code model shown Figure 2 10100;= 2, code model 101. cost (M) model length code,given number nodes minus number leaf nodes depth D. Oneshow2D (M) = 1,MCC set models prediction sux trees depth D; i.e. prefix codecomplete. remark another way describing coding scheme Willemset al. (1995). Note choice prior imposes Ockham-like penalty large PST structures.5.6 Context Treesfollowing data structure key ingredient Action-Conditional CTW algorithm.Definition 8. context tree depth perfect binary tree depth attachednode (both internal leaf) probability {0, 1} .node probabilities context tree estimated data using KT estimatornode. process update context tree history sequence similar PST, except that:1. probabilities node path root leaf traversed observed bitupdated;2. maintain block probabilities using Equations (22) (24) instead conditional probabilities.process best understood example. Figure 3 (left) shows context tree depthtwo. expositional reasons, show binary sequences nodes; node probabilitiescomputed these. Initially, binary sequence node empty. Suppose 1001history sequence. Setting aside first two bits 10 initial context, tree middleFigure 3 shows processing third bit 0. tree right treeprocessing fourth bit 1. practice, course store countszeros ones instead complete subsequences node because, saw earlier (22),Prkt (s) = Prkt (a , b ). Since node probabilities completely determined input sequence,shall henceforth speak unambiguously context tree seeing sequence.context tree depth seeing sequence h following important properties:1. model every PST depth obtained context tree pruningappropriate subtrees treating leaf nodes;111fiVeness, Ng, Hutter, Uther, & Silver????0????0 1 ???01????11??? 01??01 ?0??? 0???10?? 0??10??? 0?????? 01??01 ?10?? 0???1Figure 3: depth-2 context tree (left); trees processing two bits (middle right)2. block probability h computed PST depth obtainednode probabilities context tree via Equation (26).properties, together application distributive law, form basis highlyecient Action Conditional CTW algorithm. formalise insights.5.7 Weighted Probabilitiesweighted probability Pnw node n context tree seeing h := ax1:t definedinductively follows:n leaf node;Prkt (hT,n )Pnw :=(27)11n0n1Prkt (hT,n ) + Pw Pw otherwise,22hT,n defined (25).Lemma 2 (Willems et al., 1995). Let depth-D context tree seeing h := ax1:t .node n depth d,Pnw =2Dd (M)Prkt (hT,nn ).(28)n L(M)MC DdProof. proof proceeds induction d. statement clearly true leaf nodesdepth D. Assume statement true nodes depth + 1, 0 < D. Considernode n depth d. Letting = d,11Pnw = Prkt (hT,n ) + Pn0Pn122 w w11d+1 (M)(M)d+1= Prkt (hT,n ) +2Prkt (hT,n0n )2Prkt (hT,n1n )22 MCMCd+1n L(M)n L(M)d+11(d+1 (M1 )+d+1 (M2 )+1)2Prkt (hT,n0n )Prkt (hT,n1n )= Prkt (hT,n ) +2M1 Cd+1 M2 Cd+1n L(M1 )n L(M2 )1[= Prkt (hT,n ) +2d ( M1 M2 )Prkt (hT,nn )2[[n L( M1 M2 )M1 M2 CdDd (M)=2Prkt (hT,nn ),MC Ddn L(M)M[1 M2 denotes tree C whose left right subtrees M1 M2 respectively.112fiA Monte-Carlo AIXI Approximation5.8 Action Conditional CTW Mixture Environment Modelcorollary Lemma 2 root node context tree seeing h := ax1:t ,Prkt (hT,l )(29)Pw =2D (M)MC=lL(M)(M)(30)2D (M) Pr(x1:t | M, a1:t ),(31)MC=Prkt (h M,l )2lL(M)MClast step follows Equation (26). Equation (31) shows quantity computedAction-Conditional CTW algorithm exactly mixture environment model. Noteconditional probability always defined, CTW assigns non-zero probability sequence.sample conditional probability, simply sample individual bits xt one one.summary, prediction using Action-Conditional CTW, set aside suciently longinitial portion binary history sequence corresponding first cycles initialisevariable h repeat following steps long needed:1. set h := ha, current selected action;2. := 1 lX(a) predict next bit using weighted probability Pw ;(b) observe next bit x[i], update context tree using h x[i], calculate newweighted probability Pw , set h := hx[i].5.9 Incorporating Type InformationOne drawback Action-Conditional CTW algorithm potential loss type informationmapping history string binary encoding. type information may neededpredicting well domains. Although always possible choose binary encoding schemetype information inferred depth limited context tree, would desirableremove restriction agent work arbitrary encodings percept space.One option would define action-conditional version multi-alphabet CTW (Tjalkens,Shtarkov, & Willems, 1993), alphabet consisting entire percept space. downsideapproach lose ability exploit structure within percept.critical dealing large observation spaces, noted McCallum (1996). keydierence U-Tree USM algorithms former could discriminateindividual components within observation, whereas latter worked symbol level.shall see Section 7, property helpful dealing larger problems.Fortunately, possible get best worlds. describe techniqueincorporates type information whilst still working bit level. trick chain together k :=lX action conditional PSTs, one bit percept space, appropriately overlappingbinary contexts. precisely, given history h, context ith PST recent+ 1 bits bit-level history string hx[1, 1]. ensure percept bit dependentportion h, + 1 (instead D) bits used. Thus denote PST113fiVeness, Ng, Hutter, Uther, & Silvermodel ith bit percept x Mi , joint model M, have:Pr(x1:t | M, a1:t ) ==Pr(xi | M, ax<i ai )i=1kPr(xi [ j] | j , ax<i ai xi [1, j 1])(32)i=1 j=1=kPr(x1:t [ j] | j , x1:t [ j], a1:t )j=1x1:t [i] denotes x1 [i]x2 [i] . . . xt [i], x1:t [i] denotes x1 [i]x2 [i] . . . xt [i], xt [ j] denotingxt [1] . . . xt [ j 1]xt [ j + 1] . . . xt [k]. last step follows swapping two products (32)using notation refer product probabilities jth bit percept xi ,1 t.next place prior space factored PST models C C D+k1 assumingfactor independent, givingkPr(M) = Pr(M1 , . . . , Mk ) =2Di (Mi )=2ki=1Di (Mi ),i=1Di := + 1. induces following mixture environment model(x1:t | a1:t ) :=2ki=1Di (Mi )Pr(x1:t | M, a1:t ).(33)MC D1 C Dkrearranged product eciently computable mixtures, since(x1:t | a1:t ) =M1 C D12ki=1kDi (Mi )Mk C DkPr(x1:t [ j] | j , x1:t [ j], a1:t )j=1kj (M j )=2Pr(x[j]|,x[j],).1:tj 1:t1:t(34)j=1 j C jNote factor within Equation (34), result analogous Lemma 2 establishedappropriately modifying Lemma 2s proof take account one bit per perceptpredicted. leads following scheme incrementally maintaining Equation (33):1. Initialise h , 1. Create k context trees.2. Determine action . Set h hat .3. Receive xt . bit xt [i] xt , update ith context tree xt [i] using historyhx[1, 1] recompute Pw using Equation (27).4. Set h hxt , + 1. Goto 2.refer technique Factored Action-Conditional CTW, FAC-CTW algorithmshort.114fiA Monte-Carlo AIXI Approximation5.10 Convergence True Environmentshow FAC-CTW performs well class stationary n-Markov environments. Importantly, includes class Markov environments used state-based reinforcement learning,recent action/observation pair (at , xt1 ) sucient statistic predictionxt .Definition 9. Given n N, environment said n-Markov > n, a1:t ,x1:t Xt h (A X)tn1(xt | ax<t ) = (xt | hxtn axtn+1:t1 ).(35)Furthermore, n-Markov environment said stationary ax1:n an+1 (A X)n A,h, h (A X) ,( | hax1:n an+1 ) = ( | h ax1:n an+1 ).(36)easy see stationary n-Markov environment represented productsuciently large, fixed parameter PSTs. Theorem 1 states predictions made mixtureenvironment model converge true environment model class containsmodel suciently close true environment. However, stationary n-Markov environmentmodel contained within model class FAC-CTW, since model updates parametersKT-estimators data seen. Fortunately, problem, since updatingproduces models suciently close stationary n-Markov environment Theorem 1meaningful.Lemma 3. model class used FAC-CTW context depth D, environmentexpressible product k := lX fixed parameter PSTs (M1 , 1 ), . . . , (Mk , k ) maximum depth( | a1:n ) Pr( | (M1 , . . . , Mk ), a1:n ) n N, a1:n ,(knD1:n ( || )|L(M j )||L(M j )|j=1{(z) :=z12log z + 1)0z<1z 1.Proof. n N, a1:n ,(x1:n | a1:n )(x1:n | a1:n )x1:nkj=1 Pr(x1:n [ j] | j , j , x1:n [ j], a1:n )=(x1:n | a1:n ) ln kx1:nj=1 Pr(x1:n [ j] | j , x1:n [ j], a1:n )D1:n ( || ) =(x1:n | a1:n ) lnkPr(x1:n [ j] | j , j , x1:n [ j], a1:n )Pr(x1:n [ j] | j , x1:n [ j], a1:n )x1:nj=1)(kn(x1:n | a1:n )|L(M j )||L(M j )|xj=1=(x1:n | a1:n )ln1:n115(37)fiVeness, Ng, Hutter, Uther, & Silver(kn=|L(M j )||L(M j )|j=1)Pr(x1:n [ j] | j , j , x1:n [ j], a1:n ) denotes probability fixed parameter PST (M j , j )generating sequence x1:n [ j] bound introduced (37) work Willems et al.(1995).unknown environment stationary n-Markov, Lemma 3 Theorem 1applied FAC-CTW mixture environment model . Together imply cumulative expected squared dierence bounded O(log n). Also, per cycle -expectedsquared dierence goes zero rapid rate O(log n/n). allows usconclude FAC-CTW (with suciently large context depth) perform well classstationary n-Markov environments.5.11 Summarydescribed two dierent ways CTW extended define largeeciently computable mixture environment model. first complete derivationAction-Conditional CTW algorithm first presented work Veness, Ng, Hutter, Silver(2010). second introduction FAC-CTW algorithm, improves upon ActionConditional CTW automatically exploiting type information available within agent setting.rest paper make extensive use FAC-CTW algorithm, claritydefinek Di (Mi )(x1:t | a1:t ) :=2 i=1Pr(x1:t | M, a1:t ).(38)MC D1 C DkAlso recall using mixture environment model, conditional probability xt givenax<t(x1:t | a1:t )(xt | ax<t ) =,(x<t | a<t )follows directly Equation (3). generate percept conditional probabilitydistribution, simply sample lX bits, one one, .5.12 Relationship AIXImoving on, examine relationship AIXI model class approximation.Using place Equation (6), optimal action agent time t, experiencedax1:t1 , givent+m(x1:t | a1:t )(x1:t+m | a1:t+m )r= arg maxmaxat+m(x<t | a<t )(x<t+m | a<t+m ) i=txtxt+mt+m t+m(x1:i | a1:i )r= arg maxmaxat+m(x<i | a<i )xtxt+m i=ti=tt+m(x1:t+m | a1:t+m )r= arg maxmaxat+m(x<t | a<t )xxi=tt+m116fiA Monte-Carlo AIXI Approximation= arg maxxtt+mr (xmax1:t+m | a1:t+m )at+mxt+mi=tt+mr= arg maxmaxat+mxtxt+mi=t2ki=1Di (Mi )Pr(x1:t+m | M, a1:t+m ).MC D1 C DkContrast (39) Equation (11) reproduce here:t+mr. . . max2K() (x1:t+m | a1:t+m ),= arg maxxtat+mxt+m(39)i=t(40)class enumerable chronological semimeasures, K() denotes Kolmogorov complexity . two expressions share prior enforces bias towards simplermodels. main dierence subexpression describing mixture model class.AIXI uses mixture enumerable chronological semimeasures. scaled(factored) mixture prediction sux trees setting. Although model class used AIXIcompletely general, also incomputable. approximation restricted model classgain desirable computational properties FAC-CTW.6. Putting Togetherapproximate AIXI agent, MC-AIXI(fac-ctw), realised instantiating UCT algorithm= . additional properties combination discussed.6.1 Convergence Valueshow using place true environment expectimax operation leadsgood behaviour stationary n-Markov. result combines Lemma 3adaptation work Hutter (2005, Thm. 5.36). analysis, assume instantaneous rewards non-negative (with loss generality), FAC-CTW used sucientlylarge context depth, maximum life agent b N fixed bounded planninghorizon mt := min(H, b + 1) used time t, H N specifying maximum planninghorizon.Theorem 2. Using FAC-CTW algorithm, every policy , true environment expressible product k PSTs (M1 , 1 ), . . . , (Mk , k ), b N,()kkb[()2 ]bmtmt3 2E x<t v (, ax<t ) v (, ax<t ) 2H rmax Di (Mi ) +|L(M j )||L(M)|ji=1j=1t=1rmax maximum instantaneous reward, defined Lemma 3 vm(, ax<t )value policy defined Definition 3.Proof. First define (xi: j | a1: j , x<i ) := (x1: j | a1: j )/(x<i | a<i ) < j , environment modellet at:mt actions chosen times mt .fifififififififififififi (rt + + rm ) [(xt:m | a1:m , x<t ) (xt:m | a1:m , x<t )]fifififivt (, ax<t ) vm(, ax<t )fi = fififififi xt:mt117fiVeness, Ng, Hutter, Uther, & Silverfifi(rt + + rmt ) fifi(xt:mt | a1:mt , x<t ) (xt:mt | a1:mt , x<t )fifixt:mtmt rmaxfififi(x | , x ) (x | , x )fififit:mt1:mt <tt:mt1:mt <txt:mt=: mt rmax At:mt ( || ).Applying bound, property absolute distance (Hutter, 2005, Lemma 3.11) chain ruleKL-divergence (Cover & Thomas, 1991, p. 24) givesbb[()2 ]][mt2 2(,ax)(,ax)vrE x<t At:mt ( || )2E x<t vm<t<tmaxt=1t=122H 2 rmaxb][2E x<t Dt:mt ( || ) = 2H 2 rmax[]E x<i Di:i ( || )t=1 i=tt=122H 3 rmaxmtbb[]2E x<t Dt:t ( || ) = 2H 3 rmaxD1:b ( || ),t=1Di: j ( || ) := xi: j (xi: j | a1: j , x<i ) ln((xi: j | a1: j , x<i )/(xi: j | a1: j , x<i )). final inequalityuses fact particular Di:i ( || ) term appears H times preceding doublesum. define ( | a1:b ) := Pr( | (M1 , . . . , Mk ), a1:b )[](x1:b | a1:b ) (x1:b | a1:b )D1:b ( || ) =(x1:b | a1:b ) ln(x1:b | a1:b ) (x1:b | a1:b )x1:b(x1:b | a1:b )(x1:b | a1:b )=(x1:b | a1:b ) ln+(x1:b | a1:b ) ln(x1:b | a1:b ) x(x1:b | a1:b )x1:b1:b(x1:b | a1:b )D1:b ( ) +(x1:b | a1:b ) lnw0 (x1:b | a1:b )x1:b= D1:b ( ) +kDi (Mi )i=1w0kDi (Mi ):= 2final inequality follows dropping contributionEquation (38). Using Lemma 3 bound D1:b ( ) gives desired result.i=1fixed H, Theorem 2 shows cumulative expected squared dierence truevalues bounded term grows rate O(log b). average expected squaredlog bdierence two values goes zero rate O( b ). impliessuciently large b, value estimates using place converge fixed policy .Importantly, includes fixed horizon expectimax policy respect .6.2 Convergence Optimal Policysection presents result n-Markov environments ergodic stationary. Intuitively, class environments never allow agent make mistakelonger recover. Thus environments agent learns mistakes hopeachieve long-term average reward approach optimality.118fiA Monte-Carlo AIXI ApproximationDefinition 10. n-Markov environment said ergodic exists policyevery sub-history (A X)n possible occurs infinitely often (with probability 1) historygenerated agent/environment pair (, ).Definition 11. sequence policies {1 , 2 , . . . } said self optimising respect modelclass11v (m , ) Vm () 0M.(41)self optimising policy long-term average expected future reward optimalpolicy environment M. general, policies cannot exist model classes.restrict attention set stationary, ergodic n-Markov environments sincemodeled eectively FAC-CTW. ergodicity property ensures possiblepercepts precluded due earlier actions agent. stationarity property ensuresenvironment suciently well behaved PST learn fixed set parameters.prove lemma preparation main result.Lemma 4. stationary, ergodic n-Markov environment modeled finite, ergodic MDP.Proof. Given ergodic n-Markov environment , associated action space percept spaceX, equivalent, finite MDP (S , A, T, R) constructed defining state space:= (A X)n , action space := A, transition probability (s, ) := (o r | hsa)reward function Ra (s, ) := r , sux formed deleting leftmostaction/percept pair sao r h arbitrary history (A X) . (s, ) well definedarbitrary h since stationary, therefore Eq. (36) applies. Definition 10 implies derivedMDP ergodic.Theorem 3. Given mixture environment model model class consisting{ of} countableset stationary, ergodic n-Markov environments, sequence policies 1 , 2 , . . .b (ax<t ) := arg max Vbt+1 (ax<t )(42)1 b, self-optimising respect model class M.Proof. applying Lemma 4 M, equivalent model class N finite, ergodic MDPsproduced. know Hutter (2005, Thm. 5.38) sequence policies Nself-optimising exists. implies existence corresponding sequence policiesself-optimising.{} Using work Hutter (2005, Thm. 5.29), implies sequencepolicies 1 , 2 , . . . self optimising.Theorem 3 says choosing suciently large lifespan b, average reward agentfollowing policy b made arbitrarily close optimal average reward respecttrue environment.Theorem 3 consistency UCT algorithm (17) give support claimMC-AIXI(fac-ctw) agent self-optimising respect class stationary, ergodic, nMarkov environments. argument isnt completely rigorous, since usage KT-estimatorimplies model class FAC-CTW contains uncountable number models. conclusion entirely unreasonable however. justification countable mixture PSTs119fiVeness, Ng, Hutter, Uther, & Silverbehaving similarly FAC-CTW mixture formed replacing PST leaf node KTestimator finely grained, discrete Bayesian mixture predictor. interpretation,floating point implementation KT-estimator would correspond computationally feasibleapproximation above.results used proof Theorem 3 found works Hutter (2002b)Legg Hutter (2004). interesting area future research would investigate whetherself-optimising result similar work Hutter (2005, Thm. 5.29) holds continuous mixtures.6.3 Computational PropertiesFAC-CTW algorithm grows context tree data structure dynamically. context depthD, O(tD log(|O||R|)) nodes set context trees cycles. practice,considerably less log(|O||R|)2D , number nodes fully grown setcontext trees. time complexity FAC-CTW also impressive; O(Dm log(|O||R|)) generatepercepts needed perform single UCT simulation O(D log(|O||R|)) processnew piece experience. Importantly, quantities dependent t, meansperformance agent degrade time. Thus reasonable run agentonline setting millions cycles. Furthermore, FAC-CTW exact algorithm,suer approximation issues plague sample based approaches Bayesian learning.6.4 Ecient Combination FAC-CTW UCTEarlier, showed FAC-CTW used online setting. additional property howeverneeded ecient use within UCT. Sample invoked, FAC-CTW computedset context trees history length t. complete trajectory sampled, FAC-CTWcontain set context trees history length + m. original set contexttrees needs restored. Saving copying original context trees unsatisfactory,rebuilding scratch O(tD log(|O||R|)) time. Luckily, original set context treesrecovered eciently traversing history time + reverse, performing inverseupdate operation aected nodes relevant context tree, bitsample trajectory. takes O(Dm log(|O||R|)) time. Alternatively, copy write implementationused modify context trees simulation phase, modified copiescontext node discarded Sample invoked again.6.5 Exploration/Exploitation PracticeBayesian belief updating combines well expectimax based planning. Agents using combination, AIXI MC-AIXI(fac-ctw), automatically perform information gatheringactions expected reduction uncertainty would lead higher expected future reward. SinceAIXI mathematical notion, simply take large initial planning horizon b, e.g. maximallifespan, cycle choose greedily respect Equation (1) using remaininghorizon b + 1. Unfortunately case MC-AIXI(fac-ctw), situation complicatedissues limited computation.theory, MC-AIXI(fac-ctw) agent could always perform action recommendedUCT. practice however, performing expectimax operation remaining horizon bt+1feasible, even using Monte-Carlo approximation. Instead use large fixed search hori120fiA Monte-Carlo AIXI ApproximationEnvironmentPerform action real worldRecord new sensor information... Past Observation/Reward Action... PastRecord ActionObservation/RewardMC-AIXIapproximate AIXI agentRefine environment modela1o1o2a2a3o3o4Update Bayesian Mixture Models+---+-future reward estimate.......SimpleComplexLarge PriorSmall PriorDetermine best actionFigure 4: MC-AIXI agent loopzon aord computationally, occasionally force exploration according heuristic policy. intuition behind choice many domains, good behaviour achievedusing small amount planning dynamics domain known. Note stillpossible UCT recommend exploratory action, benefits informationrealised within limited planning horizon. Thus, limited amount exploration helpagent avoid local optima respect present set beliefs underlying environment. online reinforcement learning algorithms SARSA() (Sutton & Barto, 1998),U-Tree (McCallum, 1996) Active-LZ (Farias, Moallemi, Van Roy, & Weissman, 2010) employsimilar strategies.6.6 Top-level Algorithmtime step, MC-AIXI(fac-ctw) first invokes UCT routine fixed horizon estimate value candidate action. action chosen according policybalances exploration exploitation, -Greedy Softmax (Sutton & Barto, 1998).action communicated environment, responds observation-reward pair.agent incorporates information using FAC-CTW algorithm cycle repeats.Figure 4 gives overview agent/environment interaction loop.121fiVeness, Ng, Hutter, Uther, & SilverDomain1d-mazeCheese MazeTigerExtended Tiger4 4 GridTicTacToeBiased Rock-Paper-ScissorKuhn PokerPartially Observable Pacman|A|243449324|O|1163311968336216AliasingyesyesyesyesyesyesyesNoisyyesyesyesyesUninformativeyesyesTable 1: Domain characteristics7. Experimental Resultsmeasure agents performance across number dierent domains. particular,focused learning solving well-known benchmark problems POMDP literature.Given full POMDP model, computation optimal policy POMDPsdicult. However, requirement learn model environment,well find good policy online, significantly increases diculty problems.agents perspective, domains contain perceptual aliasing, noise, partial information, inherentstochastic elements.7.1 Domainstest domains described. characteristics summarized Table 1.1d-maze. 1d-maze simple problem work Cassandra, Kaelbling, Littman(1994). agent begins random, non-goal location within 1 4 maze. choicetwo actions: left right. action transfers agent adjacent cell exists, otherwiseeect. agent reaches third cell left, receives reward 1. Otherwisereceives reward 0. distinguishing feature problem observationsuninformative; every observation regardless agents actual location.Cheese Maze. well known problem due McCallum (1996). agent mouse insidetwo dimensional maze seeking piece cheese. agent choose one four actions:move up, down, left right. agent bumps wall, receives penalty 10.agent finds cheese, receives reward 10. movement free cell gives penalty1. problem depicted graphically Figure 5. number cell representsdecimal equivalent four bit binary observation (0 free neighbouring cell, 1 wall)mouse receives cell. problem exhibits perceptual aliasing single observationpotentially ambiguous.Tiger. another familiar domain work Kaelbling, Littman, Cassandra(1995). environment dynamics follows: tiger pot gold hidden behindone two doors. Initially agent starts facing doors. agent choice one threeactions: listen, open left door, open right door. agent opens door hiding122fiA Monte-Carlo AIXI ApproximationFigure 5: cheese mazetiger, suers -100 penalty. opens door pot gold, receives reward 10.agent performs listen action, receives penalty 1 observation correctlydescribes tiger 0.85 probability.Extended Tiger. problem setting similar Tiger, except agent begins sittingchair. actions available agent are: stand, listen, open left door, openright door. agent successfully open one two doors, must stand up. However,listen action provides information tigers whereabouts agent sittingdown. Thus necessary agent plan intricate series actions seesoptimal solution. reward structure slightly modified simple Tiger problem,agent gets reward 30 finding pot gold.4 4 Grid. agent restricted 4 4 grid world. move either up, down, rightleft. agent moves bottom right corner, receives reward 1, randomlyteleported one remaining 15 cells. moves cell bottom rightcorner cell, receives reward 0. agent attempts move non-existent cell,remains location. Like 1d-maze, problem also uninformative muchlarger scale. Although domain simple, require subtlety part agent.correct action depends agent tried previous time steps. example,agent repeatedly moved right received positive reward, chancesreceiving positive reward moving increased.TicTacToe. domain, agent plays repeated games TicTacToe opponentmoves randomly. agent wins game, receives reward 2. draw, agentreceives reward 1. loss penalises agent 2. agent makes illegal move,moving top already filled square, receives reward 3. legal moveend game earns reward.Biased Rock-Paper-Scissors. domain taken work Farias et al. (2010).agent repeatedly plays Rock-Paper-Scissor opponent slight, predictable biasstrategy. opponent round playing rock previous cycle, alwaysplay rock next cycle; otherwise pick action uniformly random. agentsobservation recently chosen action opponent. receives reward 1 win,0 draw 1 loss.123fiVeness, Ng, Hutter, Uther, & SilverKuhn Poker. next domain involves playing Kuhn Poker (Kuhn, 1950; Hoehn, Southey, Holte,& Bulitko, 2005) opponent playing Nash strategy. Kuhn Poker simplified, zerosum, two player poker variant uses deck three cards: King, Queen Jack. Whilstconsiderably less sophisticated popular poker variants Texas Holdem, well-knownstrategic concepts blung slow-playing remain characteristic strong play.setup, agent acts second series rounds. Two actions, pass bet, availableplayer. bet action requires player put extra chip play. beginninground, player puts chip play. opponent decides whether pass bet;betting win round agent subsequently passes, otherwise showdown occur.showdown, player highest card wins round. opponent passes, agenteither bet pass; passing leads immediately showdown, whilst betting requires opponenteither bet force showdown, pass let agent win round uncontested. winnerround gains reward equal total chips play, loser receives penalty equalnumber chips put play round. end round, chips removedplay another round begins.Kuhn Poker known optimal solution. first player playing Nash strategy,1second player obtain average reward 18per round.Partially Observable Pacman. domain partially observable version classic Pacman game. agent must navigate 17 17 maze eat pills distributed acrossmaze. Four ghosts roam maze. move initially random, Manhattandistance 5 Pacman, whereupon aggressively pursue Pacmanshort duration. maze structure game original arcade game, howeverPacman agent hampered partial observability. Pacman unaware maze structurereceives 4-bit observation describing wall configuration current location. alsoknow exact location ghosts, receiving 4-bit observations indicating whetherghost visible (via direct line sight) four cardinal directions. addition,locations food pellets unknown except 3-bit observation indicates whether foodsmelt within Manhattan distance 2, 3 4 Pacmans location, another 4-bitobservation indicating whether food direct line sight. final single bit indicateswhether Pacman eects power pill. start episode, food pelletplaced probability 0.5 every empty location grid. agent receives penalty1 movement action, penalty 10 running wall, reward 10 foodpellet eaten, penalty 50 caught ghost, reward 100 collecting food.multiple events occur, total reward cumulative, i.e. running wallcaught would give penalty 60. episode resets agent caught collectsfood.Figure 6 shows graphical representation partially observable Pacman domain.problem largest domain consider, unknown optimal policy. main purposedomain show scaling properties agent challenging problem. Notedomain fundamentally dierent Pacman domain used (Silver & Veness, 2010).addition using dierent observation space, also assume true environmentknown a-priori.124fiA Monte-Carlo AIXI ApproximationFigure 6: screenshot (converted black white) PacMan domain7.2 Experimental Setupevaluate performance MC-AIXI(fac-ctw) agent. help put resultsperspective, implemented directly compared two competing algorithmsmodel-based general reinforcement learning literature: U-Tree (McCallum, 1996) Active-LZ(Farias et al., 2010). two algorithms described page 133 Section 8. FAC-CTWsubsumes Action Conditional CTW, evaluate paper; results using Action Conditional CTW found previous work (Veness et al., 2010). performance agentusing FAC-CTW worse cases slightly better previous results.agent communicates environment binary channel. cycle beginsagent sending action environment, responds percept x. cyclerepeated. fixed number bits used encode action, observation reward spacesdomain. specified Table 2. constraint placed agent interpretsobservation component; e.g., could done either bit symbol level. rewardsencoded naively, i.e. bits corresponding reward interpreted unsigned integers.Negative rewards handled (without loss generality) osetting rewardsguaranteed non-negative. osets removed reported results.process gathering results three agents broken two phases: modellearning model evaluation. model learning phase involves running agentexploratory policy build model environment. learnt model evaluatedvarious points time running agent without exploration 5000 cycles reportingaverage reward per cycle. precisely, time average reward per cycle defined1 t+50005000 i=t+1 ri , ri reward received cycle i. two separate phases reducesinfluence agents earlier exploratory actions reported performance.experiments performed dual quad-core Intel 2.53Ghz Xeon 24 gigabytes memory.Table 3 outlines parameters used MC-AIXI(fac-ctw) model learning phase.context depth parameter specifies maximal number recent bits used FAC-CTW.UCT search horizon specified parameter m. Larger increase capabilities agent, expense linearly increasing computation time; values represent125fiVeness, Ng, Hutter, Uther, & SilverDomain1d-mazeCheese MazeTigerExtended Tiger4 4 GridTicTacToeBiased Rock-Paper-ScissorKuhn PokerPartially Observable Pacmanbits122224212bits14231182416R bits157813238Table 2: Binary encoding domainsDomain1d-mazeCheese MazeTigerExtended Tiger4 4 GridTicTacToeBiased Rock-Paper-ScissorKuhn PokerPartial Observable Pacman329696969664324296108541294240.90.9990.990.990.90.99990.9990.990.99990.990.99990.99990.999990.99990.9999990.999990.99990.99999UCT Simulations500500500500500500500500500Table 3: MC-AIXI(fac-ctw) model learning configurationappropriate compromise two competing dimensions problem domain.Exploration model learning phase controlled parameters. time t,MC-AIXI(fac-ctw) explores random action probability . model evaluationphase, exploration disabled, results recorded varying amounts experiencesearch eort.Active-LZ algorithm fully specified work Farias et al. (2010). containstwo parameters, discount rate policy balances exploration exploitation.model learning phase, discount rate 0.99 -Greedy exploration (with = 0.95)used. Smaller exploration values (such 0.05, 0.2, 0.5) tried, well policiesdecayed time, surprisingly gave slightly worse performance testing.sanity check, confirmed implementation could reproduce experimental resultsreported work Farias et al. (2010). model evaluation phase, explorationdisabled.situation somewhat complicated U-Tree, general agent framework completely specified algorithm. Due absence publicly available referenceimplementation, number implementation-specific decisions made. includedchoice splitting criteria, far back time criteria could applied, frequency126fiA Monte-Carlo AIXI ApproximationDomain1d-mazeCheese MazeTigerExtended Tiger4 4 GridTicTacToeBiased Rock-Paper-ScissorKuhn Poker0.050.20.10.050.050.050.050.05Test Fringe10010010020010010001002000.050.050.050.010.050.010.050.05Table 4: U-Tree model learning configurationfringe tests, choice p-value Kolmogorov-Smirnov test, exploration/exploitationpolicy learning rate. main design decisions listed below:split could made action, status single bit observation.maximum number steps backwards time utile distinction could madeset 5.frequency fringe tests maximised given realistic resource constraints. choicesallowed 5 104 cycles interaction completed domain within 2 daystraining time.Splits tried order temporally recent temporally distant.-Greedy exploration strategy used, tuned separately domain.learning rate tuned domain.help make comparison fair possible, eort made tune U-Trees parametersdomain. final choices model learning phase summarised Table 4.model evaluation phase, exploration testing fringe disabled.Source Code. code U-Tree, Active-LZ MC-AIXI(fac-ctw) implementationsfound at: http://jveness.info/software/mcaixi_jair_2010.zip.7.3 ResultsFigure 7 presents main set results. graph shows performance agentaccumulates experience. performance MC-AIXI(fac-ctw) matches exceeds U-TreeActive-LZ test domains. Active-LZ steadily improved experience, however learnt significantly slowly U-Tree MC-AIXI(fac-ctw). U-Tree performedwell domains, however overhead testing splits limited ability run longperiods time. reason data points U-Tree missing graphsFigure 7. highlights advantage algorithms take constant time per cycle,MC-AIXI(fac-ctw) Active-LZ. Constant time isnt enough however, especially largeobservation spaces involved. Active-LZ works symbol level, algorithm givenFarias et al. (2010) requiring exhaustive enumeration percept space cycle.possible reasonable time larger TicTacToe domain, Active-LZ result127fiVeness, Ng, Hutter, Uther, & SilverDomain1d MazeCheese MazeTigerExtended Tiger4 4 GridTicTacToeBiased RPSKuhn PokerExperience5 1032.5 1032.5 1045 1042.5 1045 1051 1045 106UCT Simulations250500250002500050025005000250Search Time per Cycle0.1s0.5s10.6s12.6s0.3s4.1s2.5s0.1sTable 5: Resources required (near) optimal performance MC-AIXI(fac-ctw)presented. illustrates important advantage MC-AIXI(fac-ctw) U-Tree,ability exploit structure within single observation.Figure 8 shows performance MC-AIXI(fac-ctw) number UCT simulationsvaries. results domain based model learnt 5 104 cycles experience,except case TicTacToe 5 105 cycles used. results could comparedacross domains, average reward per cycle normalised interval [0, 1]. expected,domains included significant planning component (such Tiger Extended Tiger) requiredsearch eort. Good performance domains obtained using 1000 simulations.Given sucient number UCT simulations cycles interaction, performanceMC-AIXI(fac-ctw) agent approaches optimality test domains. amount resourcesneeded near optimal performance domain model evaluation phase listedTable 5. Search times also reported. shows MC-AIXI(fac-ctw) agentrealistically used present day workstation.7.4 Discussionsmall state space induced U-Tree benefit limiting number parametersneed estimated data. dramatically speed model-learning process.contrast, Active-LZ approach require number parameters proportional number distinct contexts. one reasons Active-LZ exhibits slow convergencepractice. problem much less pronounced approach two reasons. First, Ockham prior CTW ensures future predictions dominated PST structures seenenough data trustworthy. Secondly, value function estimation decoupled processcontext estimation. Thus reasonable expect UCT make good local decisions providedFAC-CTW predict well. downside however approach requires search actionselection. Although UCT anytime algorithm, practice computation (at least smalldomains) required per cycle compared approaches like Active-LZ U-Tree act greedilyrespect estimated global value function.U-Tree algorithm well motivated, unlike Active-LZ approach, lacks theoretical performance guarantees. possible U-Tree prematurely converge locally optimalstate representation heuristic splitting criterion never recover. Furthermore,splitting heuristic contains number configuration options dramatically influenceperformance (McCallum, 1996). parameter sensitivity somewhat limits algorithms128fiA Monte-Carlo AIXI ApproximationLearning Scalability - 1d MazeMC-AIXIU-TreeActive-LZLearning Scalability - Cheese MazeOptimalMC-AIXIU-Tree0.50.40.30.20.11000-2-4-6-81000100001001000001000U-TreeActive-LZOptimalMC-AIXIU-TreeActive-LZOptimal1050Average Reward per CycleAverage Reward per Cycle100000Learning Scalability - Extended TigerLearning Scalability - TigerMC-AIXI10000Experience (cycles)Experience (cycles)-5-10-15-20-25-300-10-20-30-40-501001000100001001000001000Experience (cycles)U-Tree10000100000Experience (cycles)Learning Scalability - TicTacToeLearning Scalability - 4x4 GridMC-AIXIActive-LZMC-AIXIOptimalU-TreeOptimal1Average Reward per Cycle0.3Average Reward per CycleOptimal-1000.250.20.150.10.050.50-0.5-1-1.5-20100100010000100100000100010000Learning Scalability - Kuhn PokerMC-AIXIU-Tree1000001000000Experience (cycles)Experience (cycles)Active-LZLearning Scalability - Rock-Paper-ScissorsOptimalMC-AIXI0.10.30.050.25Average Reward per CycleAverage Reward per CycleActive-LZ2Average Reward per CycleAverage Reward per Cycle0.60-0.05-0.1-0.15-0.2U-TreeActive-LZOptimal0.20.150.10.050-0.051001000100001000001000000100Experience (cycles)100010000Experience (cycles)Figure 7: Average Reward per Cycle vs Experience1291000001000000fiVeness, Ng, Hutter, Uther, & SilverNormalised Average Reward per CycleSearch Scalability10.90.80.7OptimalTiger4x4 Grid1d MazeExtended TigerTicTacToeCheese MazeBiased RPSKuhn Poker0.60.50.40.30.20.1025250250025000SimulationsFigure 8: Performance versus UCT search eortapplicability general reinforcement learning problem. Still, results suggestinvestigation frameworks motivated along lines U-Tree warranted.7.5 Comparison 1-ply Rollout Planninginvestigate performance UCT comparison adaptation well-known1-ply rollout-based planning technique Bertsekas Castanon (1999). setting, worksfollows: given history h, estimate V(ha) constructed action A, averagingreturns many length simulations initiated ha. first action simulationsampled uniformly random A, whilst remaining actions selected accordingheuristic rollout policy. sucient number simulations completed,action highest estimated value selected. Unlike UCT, procedure doesnt buildtree, guaranteed converge depth expectimax solution. practice however,especially noisy highly stochastic domains, rollout-based planning significantly improveperformance existing heuristic rollout policy (Bertsekas & Castanon, 1999).Table 6 shows performance (given average reward per cycle) diers UCTreplaced 1-ply rollout planner. amount experience collected agent, welltotal number rollout simulations, Table 5. UCT 1-ply planneruse search horizon, heuristic rollout policy (each action chosen uniformly random)total number simulations decision. reasonable, since although UCTslightly higher overhead compared 1-ply rollout planner, dierence negligibletaking account cost simulating future trajectories using FAC-CTW. Also, similarprevious experiments, 5000 cycles greedy action selection used evaluate performanceFAC-CTW + 1-ply rollout planning combination.130fiA Monte-Carlo AIXI ApproximationDomain1d MazeCheese MazeTigerExtended Tiger4x4 GridTicTacToeBiased RPSKuhn PokerMC-AIXI(fac-ctw)0.501.281.123.970.240.600.250.06FAC-CTW + 1-ply MC0.501.251.11-0.970.240.590.200.06Table 6: Average reward per cycle: UCT versus 1-ply rollout planningImportantly, UCT never gives worse performance 1-ply rollout planner,domains (shown bold) performs better. UCT algorithm provides way performing multistep planning whilst retaining considerable computational advantages rollout based methods.particular, UCT able construct deep plans regions search spaceprobability mass concentrated small set possible percepts. structureexists, UCT automatically exploit it. worst case environment highly noisystochastic, performance similar rollout based planning. Interestingly,many domains empirical performance 1-ply rollout planning matched UCT.believe byproduct modest set test domains, multi-step planning lessimportant learning accurate model environment.7.6 Performance Challenging Domainperformance MC-AIXI(fac-ctw) also evaluated challenging Partially ObservablePacman domain. enormous problem. Even true environment known, planningwould still dicult due 1060 distinct underlying states.first evaluated performance MC-AIXI(fac-ctw) online. discounted -Greedy policy, chose random action time probability used. parametersinstantiated := 0.9999 := 0.99999. exploring, action determinedUCT using 500 simulations. Figure 10 shows average reward per cycle averagereward across recent 5000 cycles.performance learnt model evaluated performing 5000 steps greedyaction selection, various time points, whilst varying number simulations used UCT.Figure 9 shows obtained results. agents performance scales number cyclesinteraction amount search eort. results Figure 9 using 500 simulations higherFigure 10 since performance longer aected exploration policy earlierbehavior based inferior learnt model.Visual inspection1 Pacman shows agent, whilst playing perfectly, alreadylearnt number important concepts. knows run walls. knows seekfood limited information provided sensors. knows run away avoidchasing ghosts. main subtlety hasnt learnt yet aggressively chase ghostseaten red power pill. Also, behaviour sometimes become temporarily erratic1. See http://jveness.info/publications/pacman_jair_2010.wmv graphical demonstration131fiVeness, Ng, Hutter, Uther, & SilverScaling Properties - Partially Observable Pacman500 simulations1000 simulations2000 simulations5000 simulationsAverage Reward per Cycle210-1-2-3-4250025000250000Experience (cycles)Figure 9: Scaling properties challenging domainstuck long corridor nearby food visible ghosts. Still, ability performreasonably large domain exhibit consistent improvements makes us optimisticability MC-AIXI(fac-ctw) agent scale extra computational resources.8. Discussiondiscuss related work limitations current approach.8.1 Related Workseveral attempts studying computational properties AIXI. workHutter (2002a), asymptotically optimal algorithm proposed that, parallel, picks runsfastest program enumeration provably correct programs given well-defined problem. similar construction runs programs length less l time less per cyclepicks best output (in sense maximising provable lower bound true value)results optimal time bounded AIXItl agent (Hutter, 2005, Chp.7). Like Levin search (Levin,1973), algorithms practical general cases applied successfully(e.g., see Schmidhuber, 1997; Schmidhuber, Zhao, & Wiering, 1997; Schmidhuber, 2003, 2004).tiny domains, universal learning computationally feasible brute-force search. workPoland Hutter (2006), behaviour AIXI compared universal predicting-withexpert-advice algorithm (Poland & Hutter, 2005) repeated 2 2 matrix games shownexhibit dierent behaviour. Monte-Carlo algorithm proposed Pankov (2008) samplesprograms according algorithmic probability way approximating Solomonos universal prior. closely related algorithm speed prior sampling (Schmidhuber, 2002).move discussion model-based general reinforcement learning literature.early influential work Utile Sux Memory (USM) algorithm described McCallum132fiA Monte-Carlo AIXI ApproximationOnline Performance - Partially Observable PacmanRunning Average5k Rolling Average20-2-4-6-8-10-12-14050000100000150000200000250000Experience (Cycles)Figure 10: Online performance challenging domain(1996). USM uses sux tree partition agents history space distinct states, oneleaf sux tree. Associated state/leaf Q-value, updated incrementallyexperience like Q-learning (Watkins & Dayan, 1992). history-partitioning sux treegrown incremental fashion, starting single leaf node beginning. leafsux tree split history sequences fall leaf shown exhibit statisticallydierent Q-values. USM algorithm works well number tasks could deal effectively noisy environments. Several extensions USM deal noisy environmentsinvestigated work Shani Brafman (2004) Shani (2007).U-Tree (McCallum, 1996) online agent algorithm attempts discover compactstate representation raw stream experience. main dierence U-TreeUSM U-Tree discriminate individual components within observation.allows U-Tree eectively handle larger observation spaces ignore potentially irrelevantcomponents observation vector. state represented leaf sux treemaps history sequences states. experience gathered, state representation refinedaccording heuristic built around Kolmogorov-Smirnov test. heuristic tries limitgrowth sux tree places would allow better prediction future reward. ValueIteration used time step update value function learnt state representation,used agent action selection.Active-LZ (Farias et al., 2010) combines Lempel-Ziv based prediction scheme dynamicprogramming control produce agent provably asymptotically optimal environment n-Markov. algorithm builds context tree (distinct context tree built CTW),node containing accumulated transition statistics value function estimate. estimates refined time, allowing Active-LZ agent steadily increase performance.Section 7, showed agent compared favourably Active-LZ.BLHT algorithm (Suematsu, Hayashi, & Li, 1997; Suematsu & Hayashi, 1999) uses symbollevel PSTs learning (unspecified) dynamic programming based algorithm control.BLHT uses probable model prediction, whereas use mixture model, admits133fiVeness, Ng, Hutter, Uther, & Silvermuch stronger convergence result. distinction usage Ockham prior insteaduniform prior PST models.Predictive state representations (PSRs) (Littman, Sutton, & Singh, 2002; Singh, James, &Rudary, 2004; Rosencrantz, Gordon, & Thrun, 2004) maintain predictions future experience.Formally, PSR probability distribution agents future experience, given past experience. subset predictions, core tests, provide sucient statistic futureexperience. PSRs provide Markov state representation, represent track agents statepartially observable environments, provide complete model worlds dynamics. Unfortunately, exact representations state impractical large domains, form approximation typically required. Topics improved learning discovery algorithms PSRscurrently active areas research. recent results Boots, Siddiqi, Gordon (2010) appearparticularly promising.Temporal-dierence networks (Sutton & Tanner, 2004) form predictive state representation agents state approximated abstract predictions. predictionsfuture observations, also predictions future predictions. set interconnectedpredictions known question network. Temporal-dierence networks learn approximatemodel worlds dynamics: given current predictions, agents action, observationvector, provide new predictions next time-step. parameters model, knownanswer network, updated time-step temporal-dierence learning.promising recent results applying TD-Networks prediction (but control) small POMDPsgiven (Makino, 2009).model-based Bayesian Reinforcement Learning (Strens, 2000; Poupart, Vlassis, Hoey, &Regan, 2006; Ross, Chaib-draa, & Pineau, 2008; Poupart & Vlassis, 2008), distribution(PO)MDP parameters maintained. contrast, maintain exact Bayesian mixture PSTs,variable-order Markov models. UCT algorithm shares similarities BayesianSparse Sampling (Wang, Lizotte, Bowling, & Schuurmans, 2005). main dierences estimating leaf node values rollout function using UCB policy direct search.8.2 Limitationscurrent AIXI approximation two main limitations.first limitation restricted model class used learning prediction. agentperform poorly underlying environment cannot predicted well PST bounded depth.Prohibitive amounts experience required large PST model needed accurateprediction. example, would unrealistic think current AIXI approximation couldcope real-world image audio data.second limitation unless planning horizon unrealistically small, fullBayesian solution (using UCT mixture environment model) exploration/exploitationdilemma computationally intractable. agent needs augmented heuristicexploration/exploitation policy practice. Although prevent agent obtainingoptimal performance test domains, better solution may required challengingproblems. MDP setting, considerable progress made towards resolving exploration/exploitation issue. particular, powerful PAC-MDP approaches exist model-basedmodel-free reinforcement learning agents (Brafman & Tennenholtz, 2003; Strehl, Li, Wiewiora,134fiA Monte-Carlo AIXI ApproximationImpact Learnt Rollouts - Cheese Maze1Average Reward per Cycle0-1-2-3500 simulations - Learnt-4500 simulations - Uniform100 simulations - Learnt-5100 simulations - Uniform-6100100010000100000Experience (cycles)Figure 11: Online performance using learnt rollout policy Cheese MazeLangford, & Littman, 2006; Strehl, Li, & Littman, 2009). remains seen whether similarprincipled approaches exist history-based Bayesian agents.9. Future Scalabilitylist ideas make us optimistic future scalability approach.9.1 Online Learning Rollout Policies UCTimportant parameter UCT choice rollout policy. MCTS methods ComputerGo, well known search performance improved using knowledge-based rolloutpolicies (Gelly, Wang, Munos, & Teytaud, 2006). general agent setting, would thusdesirable gain benefits expert design online learning.conducted preliminary experiments area. CTW-based methodused predict high-level actions chosen online UCT. learnt distribution replacedprevious uniformly random rollout policy. Figure 11 shows results using learnt rolloutpolicy cheese maze. domains tested exhibited similar behaviour. Althoughwork remains, clear even current simple learning scheme significantly improveperformance UCT.Although first attempts promising, thorough investigation required.likely rollout policy learning methods adversarial games, investigatedSilver Tesauro (2009), adapted setting. would also interesting try applyform search bootstrapping (Veness, Silver, Uther, & Blair, 2009) online. addition, onecould also look ways modify UCB policy used UCT automatically take advantagelearnt rollout knowledge, similar heuristic techniques used computer Go (Gelly & Silver,2007).135fiVeness, Ng, Hutter, Uther, & Silver9.2 Combining Mixture Environment Modelskey property mixture environment models composed. Given two mixtureenvironment models 1 2 , model classes M1 M2 respectively, easy showconvex combination(x1:n | a1:n ) := 1 (x1:n | a1:n ) + (1 )2 (x1:n | a1:n )mixture environment model union M1 M2 . Thus principled wayexpanding general predictive power agents use kind direct AIXI approximation.9.3 Richer Notions Context FAC-CTWInstead using recent bits current history h, FAC-CTW algorithmgeneralised use set boolean functions h define current context. formalisenotion, give examples might help agent applications.Definition 12. Let P = {p0 , p1 , . . . , pm } set predicates (boolean functions) historiesh (AX)n , n 0. P-model binary tree internal node labeled predicateP left right outgoing edges node labeled True False respectively.P-tree pair (MP , ) MP P-model associated leaf node l MPprobability distribution {0, 1} parametrised l .P-tree (MP , ) represents function g histories probability distributions {0, 1}usual way. history h, g(h) = lh , lh leaf node reached pushing hmodel MP according whether satisfies predicates internal nodes lhdistribution lh . notion P-context tree specified, leading naturalgeneralisation Definition 8.Action-Conditional CTW FAC-CTW algorithms generalised workP-context trees natural way. Importantly, result analogous Lemma 2 established,means desirable computational properties CTW retained. providespowerful way extending notion context agent applications. example, suitable choice predicate class P, prediction sux trees (Definition 7) looping sux trees(Holmes & Jr, 2006) represented P-trees. also opens possibility using richlogical tree models (Blockeel & De Raedt, 1998; Kramer & Widmer, 2001; Lloyd, 2003; Ng, 2005;Lloyd & Ng, 2007) place prediction sux trees.9.4 Incorporating CTW Extensionsseveral noteworthy ways original CTW algorithm extended. finite depthlimit context tree removed (Willems, 1998), without increasing asymptotic spaceoverhead algorithm. Although increases worst-case time complexity generatingsymbol O(D) linear length history, average-case performance may stillsucient good performance agent setting. Furthermore, three additional model classes,significantly larger one used CTW, presented work Willems, Shtarkov,Tjalkens (1996). could made action conditional along lines FAC-CTWderivation. Unfortunately, online prediction general classes exponentialcontext depth D. Investigating whether ideas applied restricted sensewould interesting direction future research.136fiA Monte-Carlo AIXI Approximation9.5 Parallelization UCTperformance agent dependent amount thinking time allowed timestep. important property UCT naturally parallel. completed prototypeparallel implementation UCT promising scaling results using 4 8 processingcores. confident improvements implementation allow us solveproblems agents planning ability main limitation.9.6 Predicting Multiple Levels AbstractionFAC-CTW algorithm reduces task predicting single percept predictionbinary representation. Whilst reasonable first attempt AIXI approximation, worthemphasising subsequent attempts need work exclusively low level.example, recall FAC-CTW algorithm obtained chaining together lX actionconditional binary predictors. would straightforward apply similar technique chaintogether multiple k-bit action-conditional predictors, k > 1. k bits could interpretedmany ways: e.g. integers, floating point numbers, ASCII characters even pixels. observation, along convenient property mixture environment models composed, openspossibility constructing sophisticated, hierarchical mixture environment models.10. Conclusionpaper presents first computationally feasible general reinforcement learning agent directly scalably approximates AIXI ideal. Although well established theoretically,previously unclear whether AIXI theory could inspire design practical agent algorithms. work answers question armative: empirically, approximation achievesstrong performance theoretically, characterise range environmentsagent expected perform well.develop approximation, introduced two new algorithms: UCT, Monte-Carlo expectimax approximation technique used online Bayesian approach general reinforcement learning problem FAC-CTW, generalisation powerful CTW algorithm agent setting. addition, highlighted number interesting research directionscould improve performance current agent; particular, model class expansiononline learning heuristic rollout policies UCT.hope work generates interest broader artificial intelligence community AIXI theory general reinforcement learning agents.Acknowledgmentsauthors thank Alan Blair, Thomas Degris-Dard, Evan Greensmith, Bernhard Hengst, RamanaKumar, John Lloyd, Hassan Mahmud, Malcolm Ryan, Scott Sanner, Rich Sutton, Eric Wiewiora,Frans Willems anonymous reviewers helpful comments feedback. work received support Australian Research Council grant DP0988049. NICTA fundedAustralian Governments Department Communications, Information Technology,Arts Australian Research Council Backing Australias Ability ICT ResearchCentre Excellence programs.137fiVeness, Ng, Hutter, Uther, & SilverReferencesAuer, P. (2002). Using confidence bounds exploitation-exploration trade-os. Journal Machine Learning Research, 3, 397422.Begleiter, R., El-Yaniv, R., & Yona, G. (2004). prediction using variable order Markov models.Journal Artificial Intelligence Research, 22, 385421.Bertsekas, D. P., & Castanon, D. A. (1999). Rollout algorithms stochastic scheduling problems.Journal Heuristics, 5(1), 89108.Blockeel, H., & De Raedt, L. (1998). Top-down induction first-order logical decision trees.Artificial Intelligence, 101(1-2), 285297.Boots, B., Siddiqi, S. M., & Gordon, G. J. (2010). Closing learning-planning loop predictive state representations. Proceedings 9th International Conference AutonomousAgents Multiagent Systems: volume 1 - Volume 1, AAMAS 10, pp. 13691370 Richland,SC. International Foundation Autonomous Agents Multiagent Systems.Brafman, R. I., & Tennenholtz, M. (2003). R-max - general polynomial time algorithm nearoptimal reinforcement learning. Journal Machine Learning Research, 3, 213231.Cassandra, A. R., Kaelbling, L. P., & Littman, M. L. (1994). Acting optimally partially observablestochastic domains. AAAI, pp. 10231028.Chaslot, G.-B., Winands, M., Uiterwijk, J., van den Herik, H., & Bouzy, B. (2008a). Progressivestrategies Monte-Carlo Tree Search. New Mathematics Natural Computation, 4(3),343357.Chaslot, G. M., Winands, M. H., & Herik, H. J. (2008b). Parallel monte-carlo tree search.Proceedings 6th International Conference Computers Games, pp. 6071 Berlin,Heidelberg. Springer-Verlag.Cover, T. M., & Thomas, J. A. (1991). Elements information theory. Wiley-Interscience, NewYork, NY, USA.Farias, V., Moallemi, C., Van Roy, B., & Weissman, T. (2010). Universal reinforcement learning.Information Theory, IEEE Transactions on, 56(5), 2441 2454.Finnsson, H., & Bjornsson, Y. (2008). Simulation-based approach general game playing.AAAI, pp. 259264.Gelly, S., & Silver, D. (2007). Combining online oine learning UCT. Proceedings17th International Conference Machine Learning, pp. 273280.Gelly, S., & Wang, Y. (2006). Exploration exploitation Go: UCT Monte-Carlo Go. NIPSWorkshop On-line trading Exploration Exploitation.Gelly, S., Wang, Y., Munos, R., & Teytaud, O. (2006). Modification UCT patternsMonte-Carlo Go. Tech. rep. 6062, INRIA, France.138fiA Monte-Carlo AIXI ApproximationHoehn, B., Southey, F., Holte, R. C., & Bulitko, V. (2005). Eective short-term opponent exploitation simplified poker. AAAI, pp. 783788.Holmes, M. P., & Jr, C. L. I. (2006). Looping sux tree-based inference partially observablehidden state. ICML, pp. 409416.Hutter, M. (2002a). fastest shortest algorithm well-defined problems. InternationalJournal Foundations Computer Science., 13(3), 431443.Hutter, M. (2002b). Self-optimizing Pareto-optimal policies general environments basedBayes-mixtures. Proceedings 15th Annual Conference Computational LearningTheory (COLT 2002), Lecture Notes Artificial Intelligence. Springer.Hutter, M. (2005). Universal Artificial Intelligence: Sequential Decisions Based AlgorithmicProbability. Springer.Hutter, M. (2007). Universal algorithmic intelligence: mathematical topdown approach.Artificial General Intelligence, pp. 227290. Springer, Berlin.Kaelbling, L. P., Littman, M. L., & Cassandra, A. R. (1995). Planning acting partiallyobservable stochastic domains. Artificial Intelligence, 101, 99134.Kocsis, L., & Szepesvari, C. (2006). Bandit based Monte-Carlo planning. ECML, pp. 282293.Kramer, S., & Widmer, G. (2001). Inducing classification regression trees first order logic.Dzeroski, S., & Lavrac, N. (Eds.), Relational Data Mining, chap. 6. Springer.Krichevsky, R., & Trofimov, V. (1981). performance universal coding. IEEE TransactionsInformation Theory, IT-27, 199207.Kuhn, H. W. (1950). simplified two-person poker. Contributions Theory Games, pp.97103.Legg, S., & Hutter, M. (2004). Ergodic MDPs admit self-optimising policies. Tech. rep. IDSIA-2104, Dalle Molle Institute Artificial Intelligence (IDSIA).Legg, S. (2008). Machine Super Intelligence. Ph.D. thesis, Department Informatics, UniversityLugano.Levin, L. A. (1973). Universal sequential search problems. Problems Information Transmission,9, 265266.Li, M., & Vitanyi, P. (2008). Introduction Kolmogorov Complexity Applications (Thirdedition). Springer.Littman, M., Sutton, R., & Singh, S. (2002). Predictive representations state. NIPS, pp.15551561.Lloyd, J. W. (2003). Logic Learning: Learning Comprehensible Theories Structured Data.Springer.139fiVeness, Ng, Hutter, Uther, & SilverLloyd, J. W., & Ng, K. S. (2007). Learning modal theories. Proceedings 16th InternationalConference Inductive Logic Programming, LNAI 4455, pp. 320334.Makino, T. (2009). Proto-predictive representation states simple recurrent temporaldierence networks. ICML, pp. 697704.McCallum, A. K. (1996). Reinforcement Learning Selective Perception Hidden State.Ph.D. thesis, University Rochester.Ng, K. S. (2005). Learning Comprehensible Theories Structured Data. Ph.D. thesis,Australian National University.Pankov, S. (2008). computational approximation AIXI model. AGI, pp. 256267.Poland, J., & Hutter, M. (2005). Defensive universal learning experts. Proc. 16th International Conf. Algorithmic Learning Theory, Vol. LNAI 3734, pp. 356370. Springer.Poland, J., & Hutter, M. (2006). Universal learning repeated matrix games. Tech. rep. 18-05,IDSIA.Poupart, P., & Vlassis, N. (2008). Model-based bayesian reinforcement learning partially observable domains. ISAIM.Poupart, P., Vlassis, N., Hoey, J., & Regan, K. (2006). analytic solution discrete bayesianreinforcement learning. ICML 06: Proceedings 23rd international conferenceMachine learning, pp. 697704 New York, NY, USA. ACM.Rissanen, J. (1983). universal data compression system. IEEE Transactions InformationTheory, 29(5), 656663.Ron, D., Singer, Y., & Tishby, N. (1996). power amnesia: Learning probabilistic automatavariable memory length. Machine Learning, 25(2), 117150.Rosencrantz, M., Gordon, G., & Thrun, S. (2004). Learning low dimensional predictive representations. Proceedings twenty-first International Conference Machine Learning,p. 88 New York, NY, USA. ACM.Ross, S., Chaib-draa, B., & Pineau, J. (2008). Bayes-adaptive POMDPs. Platt, J., Koller, D.,Singer, Y., & Roweis, S. (Eds.), Advances Neural Information Processing Systems 20, pp.12251232. MIT Press, Cambridge, MA.Schmidhuber, J., Zhao, J., & Wiering, M. A. (1997). Shifting inductive bias success-storyalgorithm, adaptive Levin search, incremental self-improvement. Machine Learning, 28,105130.Schmidhuber, J. (1997). Discovering neural nets low Kolmogorov complexity high generalization capability. Neural Networks, 10(5), 857873.Schmidhuber, J. (2002). speed prior: new simplicity measure yielding near-optimal computable predictions. Proc. 15th Annual Conf. Computational Learning Theory, pp.216228.140fiA Monte-Carlo AIXI ApproximationSchmidhuber, J. (2003). Bias-optimal incremental problem solving. Advances Neural Information Processing Systems 15, pp. 15711578. MIT Press.Schmidhuber, J. (2004). Optimal ordered problem solver. Machine Learning, 54, 211254.Shani, G. (2007). Learning Solving Partially Observable Markov Decision Processes. Ph.D.thesis, Ben-Gurion University Negev.Shani, G., & Brafman, R. (2004). Resolving perceptual aliasing presence noisy sensors.NIPS.Silver, D., & Tesauro, G. (2009). Monte-carlo simulation balancing. ICML 09: Proceedings26th Annual International Conference Machine Learning, pp. 945952 New York,NY, USA. ACM.Silver, D., & Veness, J. (2010). Monte-Carlo Planning Large POMDPs. Advances NeuralInformation Processing Systems (NIPS). appear.Singh, S., James, M., & Rudary, M. (2004). Predictive state representations: new theorymodeling dynamical systems. UAI, pp. 512519.Solomono, R. J. (1964). formal theory inductive inference: Parts 1 2. InformationControl, 7, 122 224254.Strehl, A. L., Li, L., & Littman, M. L. (2009). Reinforcement learning finite MDPs: PAC analysis.Journal Machine Learning Research, 10, 24132444.Strehl, A. L., Li, L., Wiewiora, E., Langford, J., & Littman, M. L. (2006). PAC model-free reinforcement learning. ICML 06: Proceedings 23rd international conferenceMachine learning, pp. 881888 New York, NY, USA. ACM.Strens, M. (2000). Bayesian framework reinforcement learning. ICML, pp. 943950.Suematsu, N., & Hayashi, A. (1999). reinforcement learning algorithm partially observableenvironments using short-term memory. NIPS, pp. 10591065.Suematsu, N., Hayashi, A., & Li, S. (1997). Bayesian approach model learning nonMarkovian environment. ICML, pp. 349357.Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press.Sutton, R. S., & Tanner, B. (2004). Temporal-dierence networks. NIPS.Tjalkens, T. J., Shtarkov, Y. M., & Willems, F. M. J. (1993). Context tree weighting: Multi-alphabetsources. Proceedings 14th Symposium Information Theory Benelux.Veness, J., Ng, K. S., Hutter, M., & Silver, D. (2010). Reinforcement Learning via AIXI Approximation. Proceedings Conference Association AdvancementArtificial Intelligence (AAAI).Veness, J., Silver, D., Uther, W., & Blair, A. (2009). Bootstrapping Game Tree Search.Neural Information Processing Systems (NIPS).141fiVeness, Ng, Hutter, Uther, & SilverWang, T., Lizotte, D. J., Bowling, M. H., & Schuurmans, D. (2005). Bayesian sparse samplingon-line reward optimization. ICML, pp. 956963.Watkins, C., & Dayan, P. (1992). Q-learning. Machine Learning, 8, 279292.Willems, F., Shtarkov, Y., & Tjalkens, T. (1997). Reflections Context Tree WeightingMethod: Basic properties. Newsletter IEEE Information Theory Society, 47(1).Willems, F. M. J. (1998). context-tree weighting method: Extensions. IEEE TransactionsInformation Theory, 44, 792798.Willems, F. M. J., Shtarkov, Y. M., & Tjalkens, T. J. (1996). Context weighting general finitecontext sources. IEEE Trans. Inform. Theory, 42, 421514.Willems, F. M., Shtarkov, Y. M., & Tjalkens, T. J. (1995). context tree weighting method: Basicproperties. IEEE Transactions Information Theory, 41, 653664.142fiJournal Artificial Intelligence Research 40 (2011) 25-56Submitted 06/10; published 01/11Logical Study Partial EntailmentYi ZhouYan Zhangyzhou@scm.uws.edu.auyan@scm.uws.edu.auIntelligent Systems LaboratorySchool Computing MathematicsUniversity Western Sydney, NSW, AustraliaAbstractintroduce novel logical notionpartial entailmentto propositional logic. contrast classical entailment, formula P partially entails another formula Qrespect background formula set intuitively means circumstance ,P true part Q also true. distinguish three different kindspartial entailments formalize using extended notion prime implicant.study semantic properties, show that, surprisingly, partial entailments failmany simple inference rules. Then, study related computational properties,indicate partial entailments relatively difficult computed. Finally,consider potential application partial entailments reasoning rational agents.1. Introductionstandard propositional logic, classical entailment distinguish among formulasentail another formula. example, let x, z three atoms.neither x z classically entails x y. However, x seems intuitively closer xz. reason that, x considered union two parts x y,x exactly one them. hand, z completely irrelevant x y.example motivates us consider notion partial entailment. comparison classical entailment, partial entailment intends capture partial satisfactionrelationship two formulas respect background theory. standard propositional logic, formula P entails another formula Q respect formula setintuitively means circumstance , P true Q also true.contrast, formula P partially entails another formula Q respect formula setintuitively means that, circumstance , P true part Qalso true. Partial entailment widely used everyday life. example, supposestudent Laura wants get score HD subjects mathematics physicsfinal examination. cannot achieve them, could also satisfiedachieve one them. least, better achieving none.Let us consider example. Suppose background formula set emptyobjective formula x y. Consider following four formulas: x, x z, xz. Clearly, none formulas classically entails x y. However, x, x z xentail x, regarded part x y. contrast, z irrelevant x y. Thus,one conclude that, extent, x, x z x partially satisfy x znot.c2011AI Access Foundation. rights reserved.fiZhou & ZhangOne may observe exists difference x x z partiallysatisfying x y. is, x z contains new atom z, irrelevant x y.hand, x exactly part x y. words, x z contains irrelevancy(namely z) partially satisfying x x not. Another observationx y. Although entails x (a part x y), also entails y, contradicts(also part x y). words, x side effect (namely y) besidespartially satisfying x y.background theory crucial partial entailment. example, consider zx again. Suppose background formula set empty. case, zpartially satisfy x y. background formula set turns {z x}, zpartially satisfy x since background theory, z holds, x holds well.Based observations intuitions, paper, formalize notion partial entailment two formulas respect background theorypropositional language. Moreover, distinguish three different kinds partial entailments, namely weak partial entailment, partial entailment strong partial entailment.intuitions summarized Table 1. course, require partialsatisfaction two formulas. However, weak partial entailment may allowirrelevancies side effects, whilst partial entailment prohibits side effects still mayallow irrelevancies, strong partial entailment strongest one prohibitsirrelevancies.Table 1: Intuitions partial entailmentsweak partial entailmentpartial entailmentstrong partial entailmentpartial satisfactionyesyesyesirrelevancyallowedallowedside effectallowedpaper organized follows. next section, formalize three different kindspartial entailments using extended notion prime implicant, discusssemantic properties. Section 3, focus computational complexities decisionproblems relation prime implicant partial entailments, ranging specialcases general case. compare notion partial entailmentsrelated notions AI literature Section 4. Section 5, show notionspartial entailments applied formalize partial goal satisfaction reasoningrational agents. Finally, draw conclusions Section 6.2. Partial Entailmentrestrict discussions within propositional language, denoted L. Formulas Lcomposed recursively finite set Atom atoms (also called variables) {>, }standard connectives . connectives , , defined usual. Literalsatoms negations. use lower case letters denote atoms literals, uppercase letters denote formulas, lower Greek letters denote literal sets, upper Greek26fiA Logical Study Partial Entailmentletters denote formula sets respectively. write l denote complementary literalliteral l, denote set complementary literals literals . writeAtom(l), Atom(P ), Atom() Atom() denote sets atoms occurring literall, formula P , literal set formula set respectively.say literal set assignment set atoms (assignmentshort = Atom) atom x A, exactly one x x . Noticeliteral l assignment also considered formulas. convenience,henceforth, l also denote corresponding formulas clearcontext. entailment relation |= notion model defined standardway. set formulas said consistent least one model, otherwise,said inconsistent. theory set formulas closed |=. Let setformulas. deductive closure , denoted h(), minimal theory (in senseset inclusion) containing . convenience, also use denote theoryh() clear context.write P |l denote formula obtained P simultaneously replacing everyoccurrence x > () l form x (x). consistent literal set (i.e.6 x Atom s.t. x x ), = {l1 , l2 , ..., lk }, write P | denoteformula (((P |l1 )|l2 )|...)|lk .2.1 Simple Casebegin define notions partial entailments two formulas respectbackground formula set considering rather simple case. is, twoformulas consistent conjunctions literals background formula set assumedempty.Definition 1 Let 0 two consistent sets literals.say weakly partially entails 0 0 6= .say partially entails 0 0 6= 0 = .say strongly partially entails 0 0 .Definition 1 simply follows intuitions presented introduction section (seeTable 1). simple case, 0 consistent set literals. Thus, parts 0regarded elements (or subsets) 0 . Recall intuitive sense partialsatisfaction. is, holds, parts 0 hold well. meansexists part 0 , subset . Clearly, precisely captured0 6= , exactly definition weak partial entailment simple case.partial entailment, forbid side effects based partial satisfaction. Again, since 0consistent set literals, side effects 0 regarded complementaryliteral elements (or subsets) 0 . Hence, side effects 0 meansmention complementary literal elements (or subsets) 0 . Clearly,precisely captured 0 = , 0 set complementary literalselements 0 . Together 0 6= , forms definition partial entailmentsimple case.27fiZhou & ZhangFinally, consider strong partial entailment. require additionallyirrelevancy. irrelevancies 0 considered atoms (or literals)mentioned 0 . Hence, irrelevancy 0 means atom(or literal) mentioned 0 . Formally, precisely capturedAtom() Atom( 0 ) (or 0 ). Whatever case is, together two conditions0 6= 0 = , equivalent 0 6= , definitionstrong partial entailment simple case.Example 1 Recall example proposed introduction section. According Definition 1, easy check x, x x z weakly partially entail x znot; x x z partially entail x x z not; x strongly partiallyentails x x y, x z z not. results coincide intuitionsobservations discussed introduction section.Comparing weak partial entailment partial entailment, one may observe xweakly partially entails xy partially entail xy. discussed,side effect x y. Comparing partial entailment strong partial entailment,one may observe x z partially entails x strongly partially entailx y. Again, coincides discussions since z irrelevancy x y. 2interesting phenomenon relationships partial entailmentsclassical entailment. simple case, easy see classically entails 0 ,partially entails 0 . Also, weakly partially entails 0 . means classicalentailment special case (weak) partial entailment extent. However,hold strong partial entailment. instance, x classically entails x,strongly partially entail x since irrelevancy respect x.first glance, seems result strange sense term partialentailment generalization classical entailment. However, meanclassical entailment also prohibits side effects irrelevancies. Thus, intuitivesense, one conclude classical entailment special case weakpartial entailment, may mutually different partial entailment strong partialentailment. Interestingly, show later, classical entailment indeed prohibits sideeffects. means classical entailment special case partial entailment well.However, classical entailment may allow irrelevancy (e.g., x classically entails xirrelevancy x). Hence, roughly speaking, classical entailment special casepartial entailment weak partial entailment, classical entailment strong partialentailment mutually different.Definition 1 gives basic impression notions partial entailments.following, consider extend three notions partial entailments general sense,two formulas arbitrary formulas background arbitrary setformulas.2.2 Prime Implicantorder define partial entailments general case, use Quines notion prime implicant (Quine, 1952), widely used many areas logic computer28fiA Logical Study Partial Entailmentscience. excellent survey prime implicant dual prime implicate dueMarquis (2000).Roughly speaking, prime implicant formula minimal set (in senseset inclusion) literals entails formula. notion prime implicantrelativized respect background formula set follows.Definition 2 (Relativized prime implicant) literal set prime implicantformula P respect formula set if:1. consistent.2. |= P .3. exist literal set 0 satisfies two conditions.set prime implicants P respect denoted P I(, P ). convenience, omit empty.Intuitively, prime implicant P w.r.t. minimal set information neededorder satisfy P circumstance . Condition 1 requires set information feasible, i.e., must consistent background formula set. Condition2 means set information implicant, i.e., indeed powerful enoughsatisfy P w.r.t. . Finally, condition 3 requires set information prime, i.e.,minimal set information satisfying P w.r.t. .Example 2 According Definition 2, prime implicant x {x, y},x two prime implicants, namely {x} {y}. background formula set indeedplays important role. Clearly, x unique prime implicant {x}. However, {y} alsoprime implicant x respect background formula set {y x}. 2well known relativized notion prime implicant similar notionlogic-based abduction (Eiter & Gottlob, 1995; Selman & Levesque, 1990; Eiter & Makino,2007). different characterizations abduction literature. Here, considerone well-studied forms (Selman & Levesque, 1990; Eiter & Makino, 2007).Definition 3 (Selman & Levesque, 1990) Let theory, F formula H setliterals. (abductive) explanation F respect H minimal setH that:1. consistent,2. |= F .Following definitions, observed relativized notion primeimplicant abduction simply transformed other. precisely, supposetheory, F formula H set literals. Let Lit set literalslanguage. Then, prime implicant F w.r.t. iff abductive explanationF respect Lit. Conversely, abductive explanation F respectH iff prime implicant F w.r.t. mentions literals H.29fiZhou & ZhangAnother closely related notion prime implicant dual, called prime implicate,also interests many areas well. Roughly speaking, prime implicatepropositional formula P minimal clause (i.e., disjunction literals) entailed P .easy see conjunction set literals prime implicant formulaP disjunction complementary literals elementsprime implicate P . Prime implicate also relativized background formulaset well (Marquis, 2000). omit definition since mainly focused primeimplicant paper.Many properties relation prime implicate discussed summarized Marquis (2000). surprisingly, similar results hold prime implicant well.following, recall important properties relation relativized notionprime implicant, used later paper.Proposition 1 Let finite set formulas, P formula set literals.Vprime implicant P w.r.t. iff consistent prime implicant P ,Vconjunction formulas .Proposition 2 Let P formula, set formulas literal setconsistent |= P . exists 0 0 prime implicantP respect .Proposition 3 Let P formula, formula set literal set. primeimplicant P w.r.t. , exists assignment 0 0 0model P .Together Proposition 2, Proposition 3 indicates correspondence relationshipmodels P w.r.t. prime implicants P w.r.t. . Supposemodel P consistent . Then, according Proposition 2,exists subset , prime implicant P w.r.t. . Conversely, accordingProposition 3, every prime implicant P w.r.t. extended modelP .Proposition 4 Let P formula set formulas. |= PP I(, P ) = ; |= P P I(, P ) = {}.Proposition 5 Let P Q two formulas set formulas. |= P Q iffP I(, P ) = P I(, Q).conclude, prime implicants formula P w.r.t. formula set play two roles.Cases: one hand, exists assignment satisfying P , accordingProposition 2, exists subset prime implicant P w.r.t. .hand, prime implicant P w.r.t. , according Proposition3, extended assignment satisfying P . meansprime implicants P w.r.t. corresponding possible worlds (assignments)satisfying P . Intuitively, corresponding casesmake P true w.r.t. , i.e., ways achieve P .30fiA Logical Study Partial EntailmentParts: Suppose prime implicant P w.r.t. l literal . Then,|= P \{l} 6|= P . mentioned above, considered way(case) achieve P w.r.t. . Then, intuitively, l plays essential role achievingP w.r.t. via . Without l, longer way achieve P . showselements essential. words, minimal way achieveP , none elements thrown away. Thus, literalsconsidered parts P w.r.t. .roles prime implicants exploited notions partial entailmentsintroduced following.2.3 Definitions Partial EntailmentsBased notion prime implicant, formalize three kinds partial entailments.weakest strongest, weak partial entailment, partial entailmentstrong partial entailment respectively.Definition 4 (Weak partial entailment) formula P weakly partially entails formula Q respect formula set , denoted P WQ, if:1. P I(, P ) empty.2. P I(, P ), exists 0 P I(, Q), 0 6= .Definition 5 (Partial entailment) formula P partially entails formula Q respect formula set , denoted P Q, if:1. P I(, P ) empty.2. P I(, P ), exists 0 P I(, Q), 0 6= 0 =.Definition 6 (Strong partial entailment) formula P strongly partially entails formula Q respect formula set , denoted P Q, if:1. P I(, P ) empty.2. P I(, P ), exists 0 P I(, Q), 0 .Wwrite P 6WQ case P Q, similar partial entailmentstrong partial entailment. convenience, omit empty.Clearly, definitions generalizations Definition 1 proposed Section 2.1 sinceunique prime implicant literal set itself. Note difference amongdefinitions partial entailments indeed presented Section 2.1 simple case.Definitions 4-6 require literal set P I(, P ), exists literalset P I(, Q) two literal sets satisfy corresponding relationshipspresented Definition 1 respectively.Let us take closer look condition 2 Definition 4. Recall intuitive sensepartial satisfaction again, is, P true , parts Q hold well.31fiZhou & Zhangdiscussed Section 2.2, prime implicants P w.r.t. represent casesmake P true . Also, prime implicants Q w.r.t. capture ideapart Q . Hence, condition 2 means that, intuitively, casesP true (captured prime implicants P w.r.t. ), existsway achieve Q (captured prime implicant Q w.r.t. ),former partially satisfies latter (reduced simple case Definition 1). addition,condition 1 Definition 4 ensures exists least one situation. intuitivesenses Definitions 5 6 explained similar way.Example 3 Let background theory {x y, z y}. Consider two formulas P =(x r) (y s) Q = (x z) (x s). prime implicants P w.r.t.follows: {x, r}, {y, s}, {r, s}, {z, s}, {y, r} {x, s}. Notice {y, r} primeimplicant P w.r.t. although literal even occur P .hand, prime implicants Q w.r.t. follows: {x, z}, {x, s} {z, s}. Notice{x, y, s} prime implicant Q w.r.t. since {x, s} subset alsosatisfies Q .According definitions, P weakly partially entail Q w.r.t.since prime implicant {y, r} P w.r.t. intersectionprime implicants Q w.r.t. . Also, P (strongly) partially entailQ w.r.t. either. Conversely, Q (weakly) partially entails P w.r.t. , whilststrongly partially entail P w.r.t. . 2Note possible relations two formulas w.r.t. backgroundformula set using extended notion prime implicant. paper, definingpartial entailments, use style definition sense requireliteral sets P I(, P ), exists literal set P I(, Q) two literalsets satisfy conditions Definition 1 respectively. Recall intuition partialentailments, requires cases, P true context ,part Q true context . naturally suggests style definitiondefinitions partial entailments (i.e. Definitions 4-6), -part capturescases achieving P context , -part associates possibilityachieving Q context case P . addition, conditionitem 2 Definitions 4-6 ensures that, case, P partially achieves Q w.r.t. viatwo literal sets.reason choose style definition partial entailments alsoexplained analogously classical entailment. Note formula P classically entailsanother formula Q w.r.t. background theory iff models P w.r.t. , alsomodel Q w.r.t. .Certainly, possible styles, including , . instance,style definition weakest case be: exists P I(, P )0 P I(, Q), 0 6= . Although definitions might interesting usefulelsewhere, fail capture basic idea partial satisfaction.Example 4 Consider two formulas x z x y. former two prime implicants,namely {x} {z}, latter unique prime implicant, namely {x, y}.use style definition, x z (weakly, strongly) partially entails x y. However,32fiA Logical Study Partial Entailmentintuitive {z} achieves x z true irrelevant x y.words, assignment {x, y, z} satisfies x z x y. Hence, exists casex z true none parts x true.Consider formula x y, two prime implicants, {x} {y}. takestyle definition one, formula (weakly, strongly) partially entailitself. obviously intuitive. 2Another feasible direction definitions switch formulas P Q. instance,switched- style definition weakest case is: P I(, Q), exists0 P I(, P ) 0 6= . definition, corresponding switched-,style definitions, fail capture basic idea partial satisfaction either. Again,recall intuition partial entailments. is, P true (under context ),part Q true well (under context ). Similar classical entailment,naturally suggests order P Q definitions partial entailments. Also,switched- (switched-) style definition () style definition.shown Example 4, suitable defining notions partial entailments.understand switched- style switched- style definitions fail capturingpartial entailments, let us consider following example.Example 5 Consider two formulas x x. former two prime implicants,namely {x, y} {x, y}, latter unique prime implicant, namely {x}.take switched- style definition, x (weakly, strongly) partially entailsx. However, intuitive {x, y} achieves x also achieves x.Hence, exists case x true x false.Again, consider formula x y. two prime implicants, namely {x} {y}.Intuitively, formula (weakly, strongly) partially entail itself. However,case apply switched- style definition. 2One fundamental properties relationships among three notions partialentailments. following proposition shows weak partial entailment weakerpartial entailment, weaker strong partial entailment. However,observations Example 1, converses hold general.Proposition 6 (Basic relationships among partial entailments) Let P , Q two formulas formula set. P Q, P Q; P Q, P WQ.worth mentioning that, definitions partial entailments, P I(, P ) requiredempty exclude case P inconsistent background theory. underlying intuition partial entailments require real connectionstwo formulas w.r.t. background theory. Let us take closer look item 2definitions. basic idea partial entailments prime implicant P w.r.t., exists prime implicant Q w.r.t. two literal sets satisfy that,instance, intersection empty. words, P partially entails Q w.r.t.via two literal sets. However, item 2 exclude caseprime implicant P w.r.t. . case, item 2 still holds. However, cannot sayP partially entails Q w.r.t. via two literal sets two literals sets33fiZhou & Zhangexist all. Hence, require additional item 1 make sure P I(, P )empty.Then, formulas P inconsistent , P (weakly, strongly) partiallyentail formula Q. Also, formulas P entailed , P (weakly, strongly)partially entail formula Q. However, reasons two cases different.former, reason P I(, P ) empty (see Proposition 4), thus P excludeditem 1 definitions. latter, reason P I(, P ) = {} (see Proposition4 again), thus prime implicant P w.r.t. intersections primeimplicants. say formula P trivial respect background formula set|= P |= P . Otherwise, say P nontrivial respect . followingproposition shows trivial formula neither (weakly, strongly) partially entailformula, (weakly, strongly) partially entailed formulas.Proposition 7 (Non-Triviality) Let formula set P Q two formulas.P trivial w.r.t. , P 6 Q Q 6 P . assertion holds weak partialentailment strong partial entailment well.Proposition 8 (Extension Classical Entailment) Let formula set PQ two formulas nontrivial w.r.t. . |= P Q, P Q. Also, P WQ.Proposition 8 shows partial entailment extension classical entailmentconsidering nontrivial formulas, weak partial entailment. converses hold.simple example, x (weakly) partially entails x x classically entail x y.Note strong partial entailment classical entailment mutually different.example, x classically entails x x strongly partially entail x. Conversely,x strongly partially entails xy x classically entail xy. demonstratedSection 2.1, reason strong partial entailment prohibits irrelevancy whilst classicalentailment not.addition, strong partial entailment captures notion part broader sense.words, formula P strongly partially entails formula Q respectbackground formula set , P considered part Q w.r.t. .sense, also explains classical entailment necessarily imply strong partialentailment. However, explanation seems suggest way around. is,P strongly partially entails Q w.r.t. (i.e., P part Q w.r.t. ), Q classicallyentails P w.r.t. . fact, case either. example, x strongly partiallyentails (x y) (y z), (x y) (y z) classically entails x. reasonformula may contain disjunctive information. restricted simple casediscussed Section 2.1, indeed case. is, given two consistent literal sets0 , strongly partially entails 0 0 classically entails .2.4 Semantic Propertiessubsection, extensively study semantic properties relation threekinds partial entailments. reasons interested propertiestwofold. Firstly, provide deeper understandings partial entailments work.see later, surprisingly, many simple inference rules fail partial entailments. Secondly, properties illustrate similarities/differences among three kinds partial34fiA Logical Study Partial Entailmententailments, well similarities/differences partial entailments classicalentailment.consider collection inference rules. considered importantmany kinds philosophical logics knowledge representation logics, others likelyhold partial entailments. Let 0 two sets formulas, P , Q R formulasx atoms. subsection, assume formulas nontrivial w.r.t.background theory.1 Here, use > denote kinds partial entailmentsrespect . inferences rules considered listed follows:Ref: (Reflexivity) P > P , meaning formula partially entails w.r.t. background theory.LE: (Left Equivalence) |= P R P > Q, R > Q, meaning twoformulas equivalent background theory, play rolepartial entailments left side.RE: (Right Equivalence) |= Q R P > Q, P > R, meaning twoformulas equivalent background theory, play rolepartial entailments right side.BE: (Background theory Equivalence) |= 0 0 |= , P > Q iff P >0 Q,meaning two background theories equivalent, play rolepartial entailments.Rev: (Relevancy) P > Q, Atom(P ) Atom(Q) 6= , meaning one formulapartially entails another w.r.t. empty background theory, atom sets usedtwo formulas respectively must disjoint.Tran: (Transitivity) P > Q Q > R, P > R, meaning partial entailmentrelation among formulas ordering propositional language.AS: (Atom Substitution) P > Q, P (x/y) > Q(x/y),2 meaning atomspartial entailment relation replaced atoms.LO: (Left Or) P > Q R > Q, P R > Q, meaning two formulaspartially entail another one, disjunction partially entails formulawell.LS: (Left Strengthening) |= P R R > Q, P > Q, meaningformula partially entails another, formula strengthened formerpartially entail latter well.RA: (Right And) P > Q P > R, P > R Q, meaning twoformulas partially entailed another formula, conjunctionpartially entailed formula well.1. trivial formulas interesting partial entailments (see Proposition 7).2. Here, P (x/y) formula obtained P simultaneously replacing every occurrence atom xy, similar Q(x/y).35fiZhou & ZhangTable 2: Properties partial entailmentsRefLERev* TranLO* LSRAROMonoLNRNweak partial entailmentyesyesyesyesyesyespartial entailmentyesyesyesyesyesstrong partial entailmentyesyesyesyesyesyesRO: (Right Or) P > Q, P > Q R, meaning formula partially entailsanother, partially entail disjunction latter formulaformulas.Mono: (Monotonicity) 0 |= P > Q, P >0 Q, meaning addinginformation background theory preserves partial entailment relations.LN: (Left Negation) P > Q, P 6> Q, meaning impossibleformula negation partially entail another formula.RN: (Right Negation) P > Q, P 6> Q, meaning impossibleformula negation partially entailed another formula.Suppose define relation > P Q classical entailment, i.e.,|= P Q. Then, satisfies inference rules proposed above. However, followingproposition shows partial entailments fail many them.Proposition 9 Table 2 summarizes whether three kinds partial entailments satisfyinference rules considered above.Table 2 illustrates similarities differences among three kinds partialentailments. results inference rules. However, Transitivity (Tran) Left Strengthening (LS) (highlighted symbol Table 2)two exceptions. Transitivity (Tran) holds strong partial entailment partialentailment weak partial entailment. Left Strengthening (LS) holds weak partialentailment partial entailment strong partial entailment. Finally, weak36fiA Logical Study Partial Entailmentpartial entailment partial entailment extensions classical entailment senseconsidered Proposition 8, strong partial entailment not.Also, Table 2 illustrates similarities differences partial entailmentsclassical entailment. mentioned above, inference rules hold classicalentailment. However, case partial entailments. means partialentailments actually behave quite different classical entailment. Among inferencerules, Transitivity important one. hold partial entailment weakpartial entailment since allow irrelevancies. Nevertheless, Transitivity holds strongpartial entailment. However, strong partial entailment even dissimilar classicalentailment since mutually different.Table 2 also indicates easy capture properties notionspartial entailments due fact fail simple inference rules (seeTable 2). Meanwhile, properties, (e.g. Tran, LN RN), may seem intuitivepartial entailments. However, turns hold general accordingformal definitions.Certainly, one consider inference rules, instance, Contraposition. is,P > Q, Q P . One check Contraposition hold threekinds partial entailments either.2.5 DiscussionsOne may doubt whether partial entailments directly captured within classical propositional logic. example, one may define partial entailment follows. formula Ppartially entails formula Q w.r.t. formula set iff exists formula R{R} 6|= Q {P, R} |= Q. However, definition cannot capture partial satisfaction. fact, every formula P 6|= P Q, always exists formulaVR (Let R P Q). Even restrict R consistent literal sets, definitioncapture partial satisfaction either. instance, x partially entail xaccording definition since (x y) |= x y. However, conclusion counterintuitive. alternative possibility, since P partially entails Q intuitively meansP entails parts Q, one may define partial entailment as: formula P partiallyentails formula Q iff exists Q0 Q00 |= Q Q0 Q00 , Q00 6|= Q0P |= Q0 . However, definition fails capture essence partial entailment either.instance, according definition, x partially entails since |= (xy)(xy),x 6|= x y, x |= x y.According definitions partial entailments, x (weakly, strongly) partially entailsx x y. One may conclude result indicates conjunctiondisjunction play similar role partial entailments. However, case.example, reasons x partially entails x x partially entails xcompletely different. former case, reason x part x y,latter case, reason x classically entails x y. fact, conjunction disjunctionplay totally different roles partial entailments. instance, x partially entails x,x not. examples easily found.37fiZhou & ZhangAnother evidence illustrate differences conjunction disjunctionconsider another special case partial entailments restricting formulas clauses,i.e., disjunction literals, assuming background theory empty.Proposition 10 Let 0 two non-valid clauses (i.e., disjunctions two consistentsets literals). following statements equivalent.1. subset 0 represented two sets literals.2. classically entails 0 .3. weakly partially entails 0 .4. partially entails 0 .5. strongly partially entails 0 .Proposition 10 states setting, classical entailment three kindspartial entailments coincide. Compared Proposition 10 Definition 1, disjunctionconjunction quite different partial entailments.mentioned earlier, Substitution principle hold three kindspartial entailments general. means that, partial entailments, atoms indeedplay different role formulas. instance, x (weakly, strongly) partially entails x y.However, necessary case P partially entails P Q. shows differencepartial entailments classical entailment due fact Substitutionprinciple holds standard propositional logic.3. Complexity Analysissection, analyze complexity issues relation extended notion primeimplicant three kinds partial entailments. assume readers familiarbasic notions computational complexity. details foundtextbook Papadimitriou (1994).Here, briefly recall complexity classes. DP widely used complexity class,contains languages L L = L1 L2 , L1 NP L2 coNP.polynomial hierarchy defined recursively follows:P0 := P0 := P0 := P,PPi+1 := P , 0,PPi+1 := N P , 0,PPi+1 := coN P , 0.Pinstance, P3 = P 2 complexity class languages recognizablepolynomial time deterministic Turing Machine equipped P2 oracle. particular, P3 [O(log n)] subset P3 restricting uses oracle within logarithmical times. Gottlob (1995) showed complexity classes P3 P3 [O(log n)]38fiA Logical Study Partial Entailmentcoincide so-called P2 -dag P2 -tree respectively. Intuitively, P2 -dag acyclicdirected graph dependent queries P2 oracles. nodes queries whilst edgesrepresent dependency relationships among nodes. P2 -tree P2 -dag tree.mainly investigate following decision problems, general caserestricted cases:PRIC(, P, ) : (Prime Implicant Checking) determine whether literal set primeimplicant formula P w.r.t. formula set .LEPR(, P, l) : (Literal Existence Prime Implicants) determine whether literal lleast one prime implicant formula P w.r.t. formula set .LAPR(, P, l) : (Literal Prime Implicants) determine whether literal lprime implicants formula P w.r.t. formula set .WPE(, P, Q) : (Weak Partial Entailment) determine whether P weakly partially entails Qw.r.t. .PE(, P, Q) : (Partial Entailment) determine whether P partially entails Q w.r.t. .SPE(, P, Q) : (Strong Partial Entailment) determine whether P strongly partially entailsQ w.r.t. .convenience, omit empty.first three decision problems concerned relativized notion primeimplicant, others concerned notions partial entailments. mainfocuses paper course latter ones, former ones neededintermediate steps.Note complexity results related prime implicant foundfollowed existing results literature (see details Appendix). instance,shown Marquis (2000) (Propositions 3.27 3.32), checking whether literal set (withwithout background theory) prime implicate formula DP complete. Anotherresult comes Proposition 10 Lang et al. (2003) checking whether literalleast one prime implicant formula NP complete. Also, consequencecorrespondence prime implicant abduction, many complexity results relatedabduction borrowed studying prime implicant. instance, shownAppendix, checking whether literal l one prime implicants F respectexactly task relevance checking abduction.However, main focus paper, partial entailments defined upon primeimplicant (i.e. abduction). Although existing results conclude computationalcomplexity results related prime implicant, reveal much informationcomplexities partial entailments.3.1 Empty Background Theorystart complexity analysis background formula set empty. followingproposition shows complexity results relation prime implicant backgroundtheory empty. mentioned above, first two results follow existing resultsliterature.39fiZhou & ZhangProposition 11 computational complexities relation prime implicant emptybackground theory summarized Table 3.Table 3: Complexity results prime implicant: empty background theoryPRIC(P, )LEPR(P, l)LAPR(P, l)DP completeNP completeDP completeBased computational analysis prime implicant, following propositionpresents complete result complexity results relation three kinds partialentailments background theory empty.3Proposition 12 computational complexities relation partial entailmentsempty background theory summarized Table 4. Here, l literal, setliterals P Q formulas.Table 4: Complexity results partial entailments: empty background theory(l, P )(P, l)(, P )(P, )(P, Q)NPDPNPDPP2WPEcompletecompletecompletecompletecompleteNPDPNPDPP2PEcompletecompletecompletecompletecompleteSPENP completecoNP completeP2 completecoNP completeP3 completeLet us take closer look Table 4. First all, shows easy taskcompute notions partial entailments, even background theory empty.instance, check whether formula (weakly) partially entails another formulasecond level polynomial hierarchy. surprisingly, task strong partialentailment even difficult, third level polynomial hierarchy.Also, Table 4, one conclude computational complexities increaseforms formulas become complicated. instance, checking whether literalstrongly partially entails formula NP complete. extending literal literalset, becomes P2 complete. task turns P3 complete extendingantecedent arbitrary formula. Interestingly, weak partial entailment partialentailment, matter considering partially entailing formula partially entailedformula, turning literal literal set increase complexity. However,3. Clearly, antecedent consequent restricted literal sets, correspondingdecision problems relation three kinds partial entailments solved linear time.40fiA Logical Study Partial Entailmentstrong partial entailment, case partially entailed formulapartially entailing formula.Finally, observed that, background theory empty, weak partialentailment partial entailment computational complexities, strongpartial entailment acts differently. Interestingly, based basic assumptionscomplexity theory, checking strong partial entailment relationship sometimes easierrest two (e.g. compare SPE(P, ) PE(P, )), sometimes difficult (e.g.compare SPE(P, Q) PE(P, Q)).application scenarios, background theory simply set facts,represented set literals. Hence, interested computational complexitiesspecial case. shall see later, much simpler general casebackground theory arbitrary set formulas.following proposition indicates that, fortunately, turning background formulaset literal set increase computational complexities three kindspartial entailments.Proposition 13 complexity results Tables 3 4 remain background theory set literals.3.2 General Background TheoryFinally, face general case, background theory arbitrary formulaset. consider general cases six decision problems. One reasonbackground theory general setting already. Another reason that, even singleliteral, might exist many different prime implicants respect arbitrarybackground theory.Proposition 14 computational complexities relation partial entailments general case summarized Table 5.4Table 5: Complexity results: general casePRIC(, P, )LEPR(, P, l)LAPR(, P, l)WPE(, P, Q)PE(, P, Q)SPE(, P, Q)emptyDP completeNP completeDP completeP2 completeP2 completeP3 completearbitraryDP completeP2 completeP2 completeP3 [O(log n)]/ P2 hard/ P2 hardP3 / P2 hard/ P2 hardP3 completeAccording Table 5, complexities prime implicant checking strong partialentailment checking remain allowing arbitrary background theory,4. Here, also present corresponding computational complexity results background theoryempty order compare directly.41fiZhou & Zhangcomplexities increase decision problems. instance, checking whetherliteral one (or all) prime implicant(s) formula increases NP complete (DPcomplete, resp.) P2 complete (P2 complete, resp.) background theory turnsarbitrary one. Also, complexities checking weak partial entailment partialentailment general case increase little two problems P2P2 hard. However, corresponding complexity strong partial entailment remainssince already P3 hard special case background theory empty.shown Table 5, WPE(, P, Q) PE(, P, Q) P2 hard P2 hard.shows neither P2 complete P2 complete based basic assumptionscomplexity theory. conjecture WPE(, P, Q) P3 [O(log n)] completePE(, P, Q) P3 complete. However, verify this, advanced techniques, e.g.raising technique proposed Liberatore (2007), needed.4. Related Worksection 2, discussed relationships partial entailments classical entailment. Here, consider relationships partial entailmentsrelated notions literature, including family notions relevance relatives, formula-variable independence (Boutilier, 1994; Lang et al., 2003), relevanceformulas (Lakemeyer, 1995, 1997), novelty (Marquis, 1991) probabilistic positive relevance (Zhou & Chen, 2006), partial satisfaction formula (Lieberherr &Specker, 1981; Kappeli & Scheder, 2007).4.1 Formula-Variable IndependenceLang et al. (2003) defined notion formula-variable independence formulaset atoms. Roughly speaking, formula independent set atomsformula rewritten another one mentions atoms set atoms.Definition 7 (Lang et al., 2003) formula F variable-independent set Vvariables iff exists formula G |= F G Atom(G) V = .Also, Lang et al. proved variable-independence coincides notions influenceability introduced Boutilier (1994) relevance formula set atomsintroduced Lakemeyer (1997).shown Lang et al. (2003), notion formula-variable independencereformulated prime implicant. Here, show reformulated weak partialentailment well.Proposition 15 Let F formula V set atoms. following statementsequivalent:1. F variable-independent V .2. literals l V V , l prime implicants F .3. literals l V V , l weakly partially entail F .42fiA Logical Study Partial Entailment4.2 Forms RelevanceLakemeyer also introduced forms relevance well, including strict relevance, explanatory relevance relevance two subject matters (Lakemeyer, 1997).Definition 8 (Lakemeyer, 1997) formula F strictly relevant set V atomsiff every prime implicate F contains least one atom V .following proposition shows strict relevance reformulated primeimplicant weak partial entailment well.Proposition 16 Let F formula V = {x1 , . . . , xn } set atoms. followingstatements equivalent.1. F strictly relevant V .2. F weakly partially entails (x1 . . . xn ) (x1 . . . xn ).Definition 9 (Lakemeyer, 1997) formula F explanatory relevant set Vatoms w.r.t. formula set iff exists minimal abductive explanation F w.r.t.mentions variable V .definition explanatory relevance reformulated prime implicant.is, F explanatory relevant V w.r.t. iff exists l V V lleast one prime implicants F w.r.t. .4.3 Relevance Formulaspointed Lakemeyer (1997), interesting consider relevance formulasrespect background theory. Here, propose definition relevancetwo formulas respect background theory using prime implicant.Definition 10 formula P relevant formula Q respect formula set iffexists prime implicant P w.r.t. prime implicant 0 Q w.r.t.0 6= .Definition 10 looks similar definition weak partial entailment (See Definition 4). major difference two definitions weak partial entailmentdefined style, whilst relevance defined style. precisely,former, require prime implicants P w.r.t. , exists primeimplicant Q w.r.t. intersection empty. However, latter,require exists prime implicant P w.r.t. exists primeimplicant Q w.r.t. satisfying condition.However, weak partial entailment serve strict notion relevance twoformulas respect background theory. is, formula P strictly relevantanother formula Q respect formula set P weakly partially entailsQ w.r.t. . Clearly, strict version relevance formulas w.r.t. backgroundtheory based weak partial entailment implies normal one defined Definition 10,converse hold general.43fiZhou & Zhang4.4 Novelty Novelty-Based Independencenotion novelty (Marquis, 1991) defined two formulas respectformula set well.Definition 11 (Marquis, 1991) formula P new positive (new negative) anotherformula Q respect formula set iff exists prime implicant Q (Q)respect {P }, prime implicant Q (Q) respect .addition, notion independence, namely novelty-based independence (also knownseparability, see Levesque, 1998), two formulas defined based novelty (Lang,Liberatore, & Marquis, 2002).Definition 12 (Lang et al., 2002) Two formulas P Q (novelty-based) independent iff P new negative Q w.r.t. >.Intuitively, P new Q w.r.t. means adding new information Pbackground theory influences Q Q. Although novelty partialentailments defined using notion prime implicant, essentiallydifferent. instance, (non)novelty-based independence satisfies Symmetry. is,P (non)novelty-based independent Q, Q (non)novelty-based independentP . However, (weak, strong) partial entailment satisfy Symmetry. instance,x (weakly, strongly) partially satisfies x y, converse hold. anotherexample, x (weakly, strongly) partially entails x y. However, x new positive(negative) x y. Also, x new positive (negative) x. However, x(weakly, strongly) partially entail x.4.5 Probabilistic Positive RelevanceAnother approach formalize certain kind usefulness probabilistic positive relevance(Zhou & Chen, 2006), based probability distributions. basic idea positive relevance is: formula P positive relevant another formula Q respectbackground formula set iff probability distributions P r, P r(Q|{P }) P r(Q|).Although positive relevance looks similar partial entailments, probability distribution highly related prime implicant (Lang et al., 2002), underlying intuitionsemantic properties positive relevance partial entailments quite different.instance, according definition positive relevance Zhou Chen (2006),x positive relevant x. However, x (weakly, strongly) partially entailx. Generally speaking, positive relevance (defined based probability distributions),Symmetry holds. is, P positive relevant Q w.r.t. Q positiverelevant P w.r.t. . However, hold kinds partial entailments.4.6 Partial Satisfaction CNFterm partial satisfaction also used satisfaction subset set clauses(Lieberherr & Specker, 1981; Kappeli & Scheder, 2007). CNF formula (i.e. conjunctionclauses) said k-satisfiable every subformula containing k clausessatisfiable.44fiA Logical Study Partial EntailmentAlthough term partial satisfaction used k-satisfaction partial entailments, represents different intuitive meanings. former, part means subsetformula (i.e. set clauses), latter, means subset prime implicant formula. Hence, partial entailments k-satisfaction basically irrelevant.Moreover, k-satisfaction concerned particular (CNF) formula, partialentailments concerned relationship two formulas (w.r.t. backgroundtheory).5. Partial Goal Satisfactiontraditional logic based approach rational agency, agents always try find actionscompletely achieve goals. successful, agents would choose waitnothing. idea usually formalized using classical entailment. However,always case agents find perfect action (think real worldlive in). situation, sometimes useful agents somethingtowards goals rather waiting, actions partially satisfyingagents goal rational candidates. Here, partial entailments may servelogic foundation.Example 6 Let us consider example. Suppose Laura wants milk cerealbreakfast. However, three choices available breakfast menu.Choice1 milk offered.Choice2 Milk bread offered.Choice3 bread offered.Due current information, none choices completely satisfies Lauras goal.Then, do? 2Here, argue that, circumstance, also rational agents chooseactions partially achieving goal according belief, actioncompletely achieving goal.important allow actions partially achieving agents goal rationalcandidates. First all, rationality performing actions solid sincemake goal closer agents nothing better do. Hence, choosingactions useful agents goal reasonable waiting. Also,environment dynamic nature. cases, agents choose actionspartially achieving goal, might lose chance achieve goal forever.frequently happens everyday life cannot seize opportunities.formalize partial achievement actions goals agents beliefusing notion partial entailments proposed Section 2. natural sincepartial entailments precisely capture partial satisfaction relations two formulasrespect background theory. apply partial entailments formalize partial goalsatisfaction, treat background theory agents belief, consequentagents goal antecedent consequences action. One obstacle45fiZhou & Zhangrepresent actions consequences. Here, address issue, simply use triplesHoare logic represent actions.5Again, restrict discussions within propositional language. goalbelief agents represented propositional formula set propositional formulasrespectively. action triple hP re(), , P ost()i, label called bodyaction, P re() P ost() two propositional formulas called preconditionpostcondition action respectively. Next, show traditional ideacomplete goal satisfaction idea partial goal satisfaction formalizedsetting.Definition 13 (Complete goal satisfaction) Let agents belief G agentsgoal. Let set candidate actions. action completely achieves agentsgoal G according belief iff:1. |= P re().2. {P ost()} consistent.3. |= P ost() G.Definition 13 means agents belief satisfies precondition actionbelieves postcondition action entails goal, action completelyachieves goal belief. Partial goal satisfaction formalized similar wayexcept partial entailments used instead classical entailment.Definition 14 (Partial goal satisfaction) Let agents belief G agentsgoal. Let set candidate actions. action (weakly, strongly) partiallyachieves agents goal G according belief iff:1. |= P re().2. P ost()(W, ) G.Definition 14 means agents belief satisfies precondition actionbelieves postcondition action partially entails goal, actionpartially achieves goal belief.Example 7 Consider Example 6 proposed previously. formalize example, use x,z represent milk, cereal bread respectively. Then,Lauras belief empty since background knowledge; goal representedx y; preconditions three actions take three choices respectivelyempty well represented >, postcondition three casesrepresented x, x z z respectively. According Definition 13, none threeactions completely achieves goal x y. However, according Definition 14, takeChoice1 Choice2 (weakly) partially achieve goal. particular, take Choice1strongly partially achieves goal, whilst take Choice3 partially achievegoal sense. 25. Here, use simple action theory demonstrate notion partial entailmentsused formalizing partial goal satisfaction. problems represent actions agentsgeneral deal frame problem scope paper.46fiA Logical Study Partial Entailmentproblem arises kind partial goal satisfaction rational agents. firstglance, seems partial entailment appropriate purpose. Weak partialentailment may contain side effects acceptable, whilst strong partial entailmentstrict powerful actions excluded. However, believe betterleave agent designers. One may choose different kinds partial goal satisfactiondifferent application domains, e.g., strong partial entailment irrelevanciesside effects crucial issues, partial entailment side effects unacceptableirrelevancies not, weak partial entailment looser cases.worth mentioning partial goal satisfaction proposes one possible solutiondealing situations agents cannot find plan completely achievegoal. neither solution necessarily perfectly rational.situations, actions achieving parts agents goal may lose chancesachieve parts, might unacceptable agents.Also, actions partially achieving agents goal rational candidatescompulsory. quite different fact action rational candidateagents really choose perform it. Partial goal satisfaction explainsrationality actions partially achieving goals. problem particularaction chosen perform among actions partially achieving agentsgoal another research topic beyond scope paper.Another approach handling situations explicitly represent agents fullpreferences among combinations goals. instance, Example 6, Laura mayfollowing full preferences among candidate goals:{M ilk, Cereal} > {M ilk} > {Cereal} > {},> represents preference relation. Lauras original goal (i.e. ilk Cereal)cannot achieved, intends achieve second best candidate goal (i.e. ilk)according preference. observed partial goal satisfaction alwaysconsistent full preference approach, instance, preference Lauraturns {M ilk, Cereal} > {} > {M ilk} > {Cereal}. Although sharing similarities,two approaches essentially different. First all, full preference requires additionalinformation, partial goal satisfaction not. Moreover, expensive representfull preference agents. Since number possible combinations goals exponential respect size goals, represent full preference requires doubleexponential number new information. Last least, usually difficult obtainfull preferences agents. Hence, believe full preference approachpartial goal satisfaction approach advantages disadvantagesdealing situations perfect actions achieve agents goal.idea partial satisfaction goals discussed elsewhere AI literature(Haddawy & Hanks, 1992; Smith, 2004; Do, Benton, van den Briel, & Kambhampati, 2007).One approach called partial satisfaction planning (Smith, 2004; et al., 2007).partial satisfaction planning, agents find plans, instead completely achieving goals,partially achieve goals. Since agents goals AI planning, particularlySTRIPS-like planning, usually represented conjunctions small pieces subgoals,formalized finding plans achieve subsets subgoals. fact,special case partial entailments sense partial entailment dealing47fiZhou & Zhangarbitrary propositional formulas. Another approach due Haddawy Hanks (1992).approach, agents goals represented groups candidate goalsassociated real number [0, 1] represent degree chancessatisfying goal. plan satisfying candidate goal number 1 full satisfactionplan satisfying candidate goal number (0, 1) (e.g., 0.5) partialsatisfaction. several differences approach partial entailments.Firstly, partial entailments, objective formula represented single formulainstead set candidate variations. Secondly, numerical degree satisfactionintroduced partial entailments. Finally, partial entailments, partial satisfactionrelationships come internal structures formulas.Finally, would like mention application scenario discussed partialentailments reasoning rational agents classical AI planning, e.g. STRIPS.main reason agents goal beliefs formalized literal sets ratherarbitrary formulas STRIPS planning, main focus paper introducenotions partial entailments propositional logic general. Nevertheless, since checkingpartial entailments restricted antecedent, consequent backgroundtheory literal sets done linear time, interesting apply partialentailments AI planning. would like leave future investigations.6. Concluding Remarkspaper, introduced new logical notionpartial entailmentto propositional logic.distinguished three different kinds partial entailments (See Table 1) basednotion prime implicant. weakest strongest, weak partial entailment,partial entailment strong partial entailment respectively. investigatedsemantic properties partial entailments (See Table 2). results demonstrateproperties partial entailments difficult captured since many simple inferencerules hold. also investigated computational complexity partial entailments(See Tables 4 5). complexity results surprising interesting. instance,checking strong partial entailment P3 complete, even background theoryempty. indicates although definitions partial entailments look simple,easy compute them.showed notions partial entailments serve foundation formalizing partial goal satisfaction reasoning rational agents. Another potential application scenario, mentioned previous work (Zhou, van der Torre, & Zhang, 2008),goal weakening using strong partial entailment. agent needs modifygoal, choose weakened one strongly partially entails original goalrespect agents belief. strong partial entailment preservesimportant parts original goal. However, sophisticated work neededdevelop goal weakening framework. Also, mentioned previously, interestingapply partial entailments AI planning, formulas syntactically restrictedcomputation task partial entailment may become easier.Another direction future work lies computing partial entailments. course,important task develop algorithm directly purpose. However, alternative48fiA Logical Study Partial Entailmentapproach identify tractable subclasses checking partial entailments sincegeneral complexities relatively high.Acknowledgmentspreliminary results paper published (Zhou & Chen, 2004; Zhou et al.,2008). grateful Xiaoping Chen Leon van der Torre inspirationscontributions works. also grateful Jerome Lang valuablecomments earlier draft paper, would like thank anonymousreviewers valuable comments well. authors partially supportedAustralian Research Council (ARC) Discovery Projects grant (DP0988396).Appendix A. Selected Proofs6Proposition 8 (Extension Classical Entailment) Let formula set PQ two formulas nontrivial w.r.t. . |= P Q, P Q. Also, P WQ.Proof: first prove P Q. Let prime implicant P w.r.t. .|= P . Since |= P Q, |= Q. Proposition 2,subset 0 0 prime implicant Q w.r.t. . Thus 0 . Duenon-triviality P Q, 0 6= 0 = . shows P Q.According Proposition 6, P WQ. 2Proposition 9 Table 2 summarizes whether three kinds partial entailments satisfyinference rules considered above.Proof: Here, give proofs counterexamples results.Relevancy, according Definition 5, exists P I(P ) 0 P I(Q)0 6= . Therefore, Atom()Atom( 0 ) 6= . follows Atom(P )Atom(Q) 6=since Atom() Atom(P ) Atom( 0 ) Atom(Q). Similar weak partial entailmentstrong partial entailment.Transitivity strong partial entailment, let prime implicant P w.r.t. .Since P Q, exists literal set 1 consistent 1 P I(, Q)1 . Moreover, since Q R, exists literal set 2 consistent2 P I(, R) 1 2 . Hence, 2 . shows P R.Note Transitivity hold either partial entailment weak partial entailment. instance, x x x y, x 6 y. Similarly, x W xx W y, x 6W y. reason partial entailment weak partial entailmentfail transitivity allow irrelevancies. example, although x partially entails y, contains x, irrelevant y, exactly reason xpartially entails x y.6. present proofs here. others relatively simple, found fullversion, available http://www.scm.uws.edu.au/~yzhou/papers/partial-entailment-full-version.pdf .49fiZhou & ZhangLeft Strengthening weak partial entailment, let prime implicant P w.r.t.. Then, |= P . follows |= R since |= P R. Proposition 2,subset 1 , prime implicant R w.r.t. . Moreover, R WQ. Then,exists prime implicant 2 Q w.r.t. 1 2 6= . Thus, 2 6= .shows P WQ.Note Left Strengthening hold either partial entailment strong partialentailment. example, x x x x y, x 6S xx 6 x y. reason strong partial entailment partial entailment fail LeftStrengthening prohibit side effects since strengthening part left sidecould side effect right side, e.g., example.Left Negation Right Negation hold three kinds partial entailments. example, x x (weakly, strongly) partially entail x y. Meanwhile,x (weakly, strongly) partially entails x (x y). 2Proposition 11 computational complexities relation prime implicant summarized Table 3.Proof: first result proved similarly Proposition 3.27 work Marquis(2000), second one follows directly Proposition 10 work Lang et al.(2003). last result, easy prove l occurs prime implicants P iffP satisfied |= P l. immediately proves membership assertion.Hardness follows fact P satisfiable Q unsatisfiable iff x primeimplicants (x P ) (x Q), x new atom. 2Proposition 12 computational complexities relation partial entailmentsempty background theory summarized Table 4. Here, l literal, setliterals P Q formulas.Proof: membership WPE(, P), let = {l1 , ..., lk }. weakly partially entailsP exists li , 1 k li one prime implicant P .Proposition 11, problem NP.membership PE(, P), first prove literal set partially entailsformula P iff assignment 1 Atom\Atom() assignment 2Atom() 1 |= P 1 2 |= P . : Definition 5,prime implicant 0 P 0 6= 0 = . Let l 0 .0 \{l} {l} 6|= P . extended assignment 0 Atom, satisfiesP . Let 1 0 Atom(1 ) = Atom\Atom(); let 2 0 Atom(2 ) = Atom().Clearly, 1 |= P 1 2 |= P . : Proposition 2, prime implicant0 P 0 1 . follows 0 6= 0 = . Hence,partially entails P . Hence, following algorithm determines whether partially entailsP : 1. simultaneously guess two literal sets 1 2 ; 2. check whether 1 2 togethersatisfy conditions. Step 2 done polynomial time. Therefore,PE(, P) NP.50fiA Logical Study Partial EntailmentSPE(, P), membership easily shown following algorithm: 1. guess consistent literal set 0 ; 2. check whether 0 prime implicant P ; 3. yes, check whethersubset 0 . Proposition 11, step 2 requires N P oracle. Hence, problemP2 . hardness, construct reduction 2 QBF . Let X two disjointsets atoms P formula Atom(P ) X . Let = {y1 , y2 , ..., yk }; T1y1 ... yk ; T2 y1 ... yk ; x two new atoms different X ; Q(xy P )(xy T1 )(xy T2 ). prove XY P holds xystrongly partially entails Q. Suppose XY P holds. Then, exists assignment0 X 0 |= P . Proposition 2, exists 1 0 1prime implicant P . Therefore, {x, y} 1 |= Q. addition, {x} 1 6|= Q. Otherwise,{x} 1 |= (x P ) (x T1 ) (x T2 ). follows {x} 1 |= T1 ,contradiction. Symmetrically, {y} 1 6|= Q. Moreover, l 1 , {x, y} 1 \{l} 6|= Qsince 1 prime implicant P . shows {x, y} 1 prime implicant Q.Hence, x strongly partially entails Q. hand, suppose x stronglypartially entails Q. Then, exists prime implicant Q including x y.Let {x, y} 1 . Therefore 1 |= P . 1 6|= T1 . Otherwise, {x} 1 |= Q.shows {x, y} 1 prime implicant Q, contradiction. Symmetrically,1 6|= T2 . shows Atom(1 ) X. Moreover, {x, y} 1 |= Q. follows{x, y} 1 |= x P . Therefore 1 |= P . Let 0 assignment X1 0 . Then, 0 |= P . shows XY P holds.membership WPE(P, ), P weakly partially entails iff a) P satisfiable, b)assignments 1 Atom\Atom(), 1 6|= P , equivalent |= P .prove this, suppose P weakly partially entails . Then, P satisfiable. assumeexists 1 1 |= P . Proposition 2, exists 2 12 prime implicant P . However, 2 = , contradiction.hand, suppose three conditions hold. Then, prime implicants 1P , 1 6= . Otherwise, 1 extended assignment 2 Atom2 |= P . However, 2 , contradiction. Hence, WPE(P, ) DP.membership PE(P, ), let = {l1 , . . . , ln }. Then, P partially entails iffprime implicant 0 P , a) 0 = , b) 0 6= iff a) i, (1 n), liprime implicants P , b) P weakly partially entails . Hence,Proposition 11 result weak partial entailment, problem DP .membership SPE(P, ), let = {l1 , . . . , ln }, Atom(P )\Atom() = {x1 , . . ., xm }.P strongly partially entails iff prime implicants P subsets iffi, (1 n), li prime implicants P j, (1 j m), xj (xj )prime implicants P . Proposition 11, problem coNP.WPE(P, Q), membership shown following algorithm, determineswhether P weakly partially entail Q: 1. guess consistent literal set ; 2. checkwhether prime implicant P ; 3. yes, check whether weakly partiallyentail Q. Proposition 11 case WPE(, P), steps 2 3 require N Poracle. Hence, problem P2 . hardness, construct reduction 2QBF .Let X two disjoint sets atoms P formula Atom(P ) X .Let = {y1 , y2 , ..., yk }. Formula (y1 ... yk ) (y1 ... yk ). proveXY P holds P weakly partially entail . Suppose XY Pholds. Then, exists assignment 1 X 1 |= P . Proposition51fiZhou & Zhang2, exists prime implicant 2 P 2 1 . Clearly, primeimplicant 3 2 3 6= . hand, suppose Pweakly partially entail . Then, exists prime implicant 1 Pprime implicants 2 , 1 2 = . follows Atom(1 ) X. Then, 1extended assignment 3 X 3 |= P . Hence, XY P holds.PE(P, Q), membership shown following algorithm, determineswhether P partially entail Q: 1. guess consistent literal set ; 2. check whetherprime implicant P ; 3. yes, check whether partially entail Q.Proposition 11 case PE(, P), steps 2 3 require N P oracle. Hence,problem P2 . hardness, construct reduction 2 QBF . Let Xtwo disjoint sets atoms P formula Atom(P ) X . LetX = {x1 , x2 , ..., xk }; X 0 = {x01 , x02 , ..., x0k } k new atoms different Atom. Formula K(x1 x01 ) (x2 x02 ) ... (xk x0k ). prove XY P holds x Kpartially entails x P , x new atom. Notice prime implicants Kform 0 , ( 0 ) assignment X (X 0 ) i, (1 k),xi iff x0i 0 (xi iff x0i 0 ). suppose x K partially entails x P .Then, assignments 0 X, {x} 0 00 partially entails x P . Therefore,exists assignment 1 {x} 0 00 1 |= x P . follows0 1 |= P . shows XY P holds. hand, suppose XY Pholds. Then, assignments 0 X, exists assignment 1 ,0 1 |= P . Therefore, prime implicants {x} 0 00 x K, existsassignment 1 {x} 0 00 1 |= x P . Moreover, existsassignment 2 = {x} 0 00 {x} X X 0 , 2 1 |= (x P ). Hence,x K partially entails x P .Finally SPE(P, Q), membership shown following algorithm, determines whether P strongly partially entail Q: 1. guess consistent literal set; 2. check whether prime implicant P ; 3. yes, check whether doesntstrongly partially entails Q. Proposition 11, step 2 requires N P oracle;case SPE(, P), step 3 requires P2 oracle. Hence, problem P3 .hardness, construct reduction 3 QBF . Let X, Z three disjoint sets atoms P formula Atom(P ) X Z. SupposeX = {x1 , x2 , ..., xk }. Let X 0 = {x01 , x02 , ..., x0k } k new atoms. Let K formula(x1 x01 ) (x2 x02 ) ... (xk x0k ). Suppose Z = {z1 , z2 , ..., zk }. Let T1z1 ... zk T2 z1 ... zk respectively. Let R formula x K Qformula (x P K) (x T1 K) (x T2 K) respectively, xtwo new atoms. Next, prove XY ZP holds R stronglypartially entails Q. proof tedious. one hand, suppose XY ZP holds.Given prime implicant R form {x, y} 0 , assignmentX 0 corresponding assignment X 0 . Then, exists assignment 11 |= P . Therefore, {x, y} 0 1 |= x P K. follows{x, y} 0 1 |= Q. Proposition 2, exists subset 2 {x, y} 0 1 ,prime implicant Q. x 2 . Otherwise, {y} 0 1 |= Q.Therefore {y} 0 1 |= x T2 , contradiction. Symmetrically, 2 . Moreover,atom l 0 , l 2 since 2 |= K. Therefore {x, y} 0 2 .shows prime implicants R, exists prime implicant Q52fiA Logical Study Partial Entailmentformer subset latter. Hence, R strongly partially entails Q.hand, suppose R strongly partially entails Q. Notice assignmentsX, {x, y} 0 prime implicant R. Therefore, prime implicant Qcontains {x, y} 0 . Let {x, y} 0 1 , Atom(1 ) Z.Therefore, 1 |= P . 1 6|= T1 . Otherwise, {x} 0 1 |= Q,contradiction. Symmetrically, 1 6|= T2 . shows Atom(1 ) . Thus, 1extended assignment 2 . {x, y} 0 2 |= Q. Therefore{x, y} 0 2 |= x P K. Hence, 2 |= P . shows assignmentsX, exists assignment 2 , 2 |= P . is, XY ZPholds. 2Proposition 13 complexity results Tables 3 4 remain background theory set literals.Proof: assertion follows directly following fact:Suppose P formula consistent set literals. Then, P I(, P ) =P I(P |).one hand, suppose 1 P I(, P ). Then, according definition, 1consistent 1 |= P . Atom(1 ) Atom() = . Otherwise, supposel Atom(1 ) Atom(), 1 \{l} |= P . Also, 1 \{l} consistent.shows 1 prime implicant P w.r.t. , contradiction. Moreover, 1 |= P .follows 1 |= P |. addition, exist 2 1 2 |= P |.Otherwise, 2 |= P 2 consistent. shows 1 prime implicantP w.r.t. , contradiction. Hence, 1 prime implicant P |. hand,suppose 1 prime implicant P |. Then, Atom(1 ) Atom() empty sinceAtom(P |) Atom() empty. addition, 1 |= P since 1 |= P |. Thus, 1consistent. Moreover, exist 2 1 2 |= P . Otherwise,2 |= P |. shows 1 prime implicant P |, contradiction. Hence, 1prime implicant P w.r.t. . 2Proposition 14 computational complexities relation partial entailment generalcase summarized Table 5.Proof: DP completeness PRIC(, P, ) follows directly Proposition 1DP completeness PRIC(P, ). also proved similar way techniquesintroduced Marquis (2000) proving DP completeness corresponding decision problem prime implicate (see Marquis, 2000, Proposition 3.36).LEPR(, P, l), membership easy guessing literal set checking lP I(, P ). hardness, shown XY P iff x one elementsP I(, F ), = {(x P (y1 yk ))}, F = x P (y1 yk ) x(y1 yk ), x new atom. proof tedious. outline basicideas follows.x one elements P I(, F )53fiZhou & ZhangiffVVV, x , 6|= , |= F 0 , 0 6|= F .iffVVV1 , 1 {x} 6|= , 1 {x} |= F 1 6|= F . (Notice 1 {x}necessarily mentioned above.)iffVVV1 , 1 6|= ( )|x, 1 |= ( )|x F |x 1 6|= ( )|x F |x.iff1 , 1 6|= P (y1 yk ), 1 |= P 1 6|= y1 yk .iffXY P holds. fact, hardness result also follows P2 completeness checkingrelevance abductive reasoning (see Eiter & Gottlob, 1995, Thm. 4.11).LAPR(, P, l), membership shown following algorithm, determines whether l prime implicants P w.r.t. : 1. guess literal set ;2. check prime implicant P w.r.t. ; 3. yes, check l . According result prime implicant checking, problem P2 . Thus,original problem P2 . harness, prove similar wayproof P2 hardness LEPR(, P, l). Indeed, one prove XY Piff x one elements P I(, F ), = {(x z P (y1 yk ))},F = x z P (y1 yk ) x z (y1 yk ), x z two newatoms. Moreover, x one elements P I(, F ) iff x elementsP I(, F ) since every element P I(, F ) contains either x x. shows determining whether literal prime implicants formula w.r.t. formula setP2 hard. follows LAPR(, P, l) P2 hard.WPE(, P, Q), P2 hardness follows directly Proposition 12. P2 hardnessimplied hardness proof P2 hardness LEPR(, P, l) noticingprime implicant x w.r.t. {x} itself. membership, let us first considerfollowing algorithm, determines whether P weakly partially entail Qw.r.t. : 1. compute literals occur least one prime implicants Qw.r.t. ; 2. check whether prime implicant P w.r.t. , containliterals computed step 1. According result P2 hardnessLEPR(, P, l), step 1 requires linear calls P2 oracle. addition, step 2 requiresone recall P2 oracle based results obtained step 1. this, needguess consistent literal set, check prime implicant P w.r.t.contains literals computed step 1. algorithm converted P2 -tree,root corresponding P2 call step 2, children correspondinglinear P2 calls step 1 computing literals. Thus, according P2 -treetechniques introduced Gottlob (1995), WPE(, P, Q) P3 [O(log n)].PE(, P, Q), P2 hardness P2 hardness shown similarway corresponding tasks weak partial entailment. membership, followingalgorithm determines whether exists prime implicant 0 Q w.r.t. ,0 = 0 6= : 1. guess literal set 0 ; 2. check 0 prime implicantQ w.r.t. ; 3. check 0 satisfy conditions. According resultprime implicant checking, step 2 requires calls NP oracle. Thus, decisionproblem P2 . Based result, following algorithm determines whether P54fiA Logical Study Partial Entailmentpartially entail Q w.r.t. : 1. guess literal set ; 2. check prime implicantP w.r.t. ; 3. check exists prime implicant 0 Q w.r.t. 0 =0 6= . easy see problem P3 . Thus, original problemP3 .Finally, SPE(, P, Q), hardness follows directly Proposition 12, membershipshown similar way membership task partial entailment.2ReferencesBoutilier, C. (1994). Toward logic qualitative decision theory. Proceedings KR94,pp. 7586.Do, M. B., Benton, J., van den Briel, M., & Kambhampati, S. (2007). Planning goalutility dependencies.. Proceedings IJCAI07, pp. 18721878.Eiter, T., & Gottlob, G. (1995). complexity logic-based abduction. JournalACM, 42 (1), 342.Eiter, T., & Makino, K. (2007). computing abductive explanations propositional horn theory. Journal ACM, 54 (5).Gottlob, G. (1995). NP trees Carnaps modal logic. Journal ACM, 42 (2),421457.Haddawy, P., & Hanks, S. (1992). Representations decision-theoretic planning: Utilityfunctions deadline goals. Proceedings KR92, pp. 7182.Kappeli, C., & Scheder, D. (2007). Partial satisfaction k-satisfiable formulas. ElectronicNotes Discrete Mathematics, 29, 497501.Lakemeyer, G. (1995). logical account relevance.. Proceedings IJCAI95, pp.853861.Lakemeyer, G. (1997). Relevance epistemic perspective. Artificial Intelligence,97 (1-2), 137167.Lang, J., Liberatore, P., & Marquis, P. (2002). Conditional independence propositionallogic. Artificial Intelligence, 141 (1/2), 79121.Lang, J., Liberatore, P., & Marquis, P. (2003). Propositional independence: Formulavariable independence forgetting. Journal Artificial Intelligence Research, 18,391443.Levesque, H. J. (1998). completeness result reasoning incomplete first-orderknowledge bases. Proceedings KR98, pp. 1423.Liberatore, P. (2007). Raising hardness result. CoRR, abs/0708.4170.Lieberherr, K. J., & Specker, E. (1981). Complexity partial satisfaction. JournalACM, 28 (2), 411421.Marquis, P. (1991). Novelty revisited. Proceedings ISMIS91, pp. 550559.55fiZhou & ZhangMarquis, P. (2000). Consequence finding algorithms. Kohlas, J., & Moral, S. (Eds.),Handbook Defeasible Reasoning Uncertainty Management Systems, Volume 5:Algorithms Uncertainty Defeasible Reasoning, pp. 41145. Kluwer, Dordrecht.Papadimitriou, C. H. (1994). Computational Complexity. Addison-Wesley.Quine, W. (1952). problem simplifying truth functions. American MathematicalMonthly, 59 (8), 521531.Selman, B., & Levesque, H. J. (1990). Abductive default reasoning: computationalcore. AAAI, pp. 343348.Smith, D. E. (2004). Choosing objectives over-subscription planning.. ProceedingsICAPS04, pp. 393401.Zhou, Y., & Chen, X. (2004). Partial implication semantics desirable propositions..Proceedings KR04, pp. 606612.Zhou, Y., & Chen, X. (2006). Toward formalizing usefulness propositional language..Proceedings KSEM06, LNAI 4092, pp. 650661.Zhou, Y., van der Torre, L., & Zhang, Y. (2008). Partial goal satisfaction goal change:weak strong partial implication, logical properties, complexity. ProceedingsAAMAS08, pp. 413420.56fi